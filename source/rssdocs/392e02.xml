<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3156448125311748</id>
            <title>DeepSeek破圈，AI商业化临界点是如何被打开的？</title>
            <link>https://www.36kr.com/p/3156448125311748</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156448125311748</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:57:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <DeepSeek, AI商业化, 技术民主化, 硅谷>
<br>
<br>
总结: DeepSeek在春节期间引发了广泛关注，成为AI商业化的重要突破口。自ChatGPT掀起大模型浪潮以来，尽管许多模型相继推出，但真正的商业化落地仍面临挑战。DeepSeek通过高质量的技术讨论和跨领域的广泛应用，成功打破了技术壁垒，推动了AI的技术民主化进程。其开源模型的发布吸引了大量专业博主的深入讨论，进一步提升了公众对DeepSeek的关注和使用。通过与用户的高频互动，DeepSeek不仅实现了用户规模的激增，也为AI商业化的成功奠定了基础。 </div>
                        <hr>
                    
                    <p>DeepSeek在这个春节假期卷翻了硅谷，我们注意到，对于模型和应用的讨论很多，但鲜有人追问：DeepSeek的现象级爆火，为AI商业化撕开了怎样的突破口？</p>
  <p>要知道，自从ChatGPT在2023年初掀起大模型浪潮，此后全球各色模型轮番登场、百舸争流，但AI大模型的商业化落地，始终与技术突破存在一定的时差。有的大模型在发布会之后就乏人问津，也有模厂黯然退出了预训练。</p>
  <p>DeepSeek不仅让全球看到了国产AI的技术能力，而且发现，技术破圈之后的商业化生命力也格外澎湃，服务器的繁忙、云厂商/行业伙伴的积极接入，都让人们对深度求索这家科创企业的商业未来格外期待。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9bfc39e4a9654706a8e0bb8f4cc687e3@000000_oswg192297oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而回顾DeepSeek的破圈之路，我们发现一个独特地方，那就是关于DeepSeek的技术讨论，在质量、广度、深度上有碾压式的突破，由此带来了大众广泛使用的技术民主化进程，为DeepSeek的破圈铺平了道路，也为AI商业化开辟了出路。</p>
  <p>我们今天就来聊聊，DeepSeek破圈背后的助推力，以及给AI商业化带来哪些启发。</p>
  <h2><strong>01 出圈锚点：高质量信源，穿过信息迷雾</strong></h2>
  <p>无论是ChatGPT的大语言模型，还是DeepSeek-R1为代表的推理模型，都有着较高的认知门槛。普通人想要了解和触碰这些大厂实验室里的高岭之花，必须走过“拳打硅谷、脚踢华尔街”的标题党，穿过AIGC胡编乱造的信息迷雾，找到那些真实、理性、客观的信源，作为进入技术世界的锚点。</p>
  <p>简单梳理一下DeepSeek的出圈过程，会发现有大量专业博主，成为技术传播的锚点。</p>
  <p><strong>首先，长期关注AI的技术博主，提前技术跟踪、研判与预热，不断消除着大众对技术的认知误差。</strong></p>
  <p>早在2024年中，不少技术从业者已经开始在社交平台，交流讨论DeepSeek V2模型的潜力，这家低调的AI初创公司初现峥嵘。</p>
  <p>2024年12月，DeepSeek新模型V3版本流出，科技博主@阑夕 就曾发起话题，聊起了中国AI卷到硅谷，也提到了春晚刷屏的宇树机器人。早在大众惊叹DeepSeek之前，这些身处行业中心的从业者早已感知到了产业风向的变化。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8a34bbdcfc6844fe866eb78398b4f09f@000000_oswg273329oswg1080oswg412_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>最关键的节点，是2025年1月，DeepSeek-V3和R1开源。</strong>这是AI业内的大事件，但开源跟大众乃至社会有什么关系呢？一大批技术博主，在开放讨论平台，挥舞起了理性分析的思想手术刀。</p>
  <p>包括@梁斌penny、@海辛Hyacinth、@伯克利_尤洋、@高飞 等，都对技术论文、模型架构、创新性等展开深度讨论，将晦涩难懂的技术/论文进行了细致拆解，大众和媒体开始关注到此次国产AI创新的独特之处，密集讨论DeepSeek。此后，DeepSeek热搜推陈出新，热度持续上升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ed402ac0345b419698a5d315342e5ba7@000000_oswg216566oswg1080oswg411_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这些专业博主，是了解AI的高质量信源，也是绝大多数普通人触碰AI的第一个锚点。他们的高质量讨论与思考，成为DeepSeek破圈的头号助力和原点。</p>
  <h2><strong>02 领域破壁：用跨界讨论的广度，打开认知边界</strong></h2>
  <p>DeepSeek之前，也有不少国产模型可以媲美海外产品，但受限于科技企业“重研发、轻营销”的思维惯性，营销手段主要是在模型发布时发一下PR通稿、在技术社区上传一下技术文档、榜单跑分等，讨论度不高、热度难持续。</p>
  <p><strong>反观DeepSeek的出圈，除了模型本身的性能先进之外，与大规模的跨领域碰撞，是分不开的。</strong></p>
  <p>如果说技术博主挥舞的是思想手术刀，那么更广泛的普通博主/大V/KOL等则手握着“DeepSeek+领域”的破壁机，拓展了AI应用落地的边界。</p>
  <p>有人打开了DeepSeek的讨论广度。技术论文解读是最基础的，在此之外，很快涌现出了多种角度的解读。</p>
  <p>比如很多网友看到了DeepSeek-R1的神奇，但自己从没用过推理模型，担心不好上手，科技博主@数字生命卡兹克 在除夕当天发布了《DeepSeek的提示词技巧，就是没有技巧》，打消了普通人的使用顾虑，在春节长假期间给DeepSeek上了一波热度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d804a639fd844bf691cb2e3890447275@000000_oswg346468oswg1080oswg711_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当大众好奇为什么DeepSeek这一次能震撼硅谷时，资深技术专家阮一峰@ruanyf 分享的DeepSeek创始人梁文峰谈开源，是网上关于“开源力量颠覆AI产业格局”较早的讨论之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0d1d76ac712748838a3bc7ad7218b321@000000_oswg97447oswg585oswg235_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>@海辛Hyacinth 则从团队管理的角度，认为DeepSeek 的年轻化团队意味着AI时代论资排辈会越来越少……</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b8dd6542b4f240588cb62bcf5465336a@000000_oswg46076oswg756oswg352_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这些多元化角度的讨论充分打开，延续了DeepSeek的热度。</p>
  <p>上述讨论，进一步激发了多个行业领域博主开始关注DeepSeek，讨论DeepSeek，延伸出了DeepSeek与场景的多种结合方式。</p>
  <p>比如编剧@汪海林，探讨基于推理模型的AIGC，给剧本创作带来的颠覆；博主@零重力瓦力，用“AI解题像学霸写作业”类比大模型思维链，让推理模型不再是悬浮的概念，成了人人可上手的工具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_13ec665e136e42b5abe465ea1095840e@000000_oswg143797oswg1080oswg345_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一个个行业领域的跨界碰撞，让DeepSeek的创意应用喷薄而出，成为DeepSeek出圈的新一轮推动力，带动了更多领域用户的参与讨论，打开了AI商业化的边界。</p>
  <h2><strong>03 技术生命力：以高频率互动，深耕商业化沃土</strong></h2>
  <p>爆火之后，流量倏忽而来、倏忽而去的事并不少见。AI商业化的终极考验，在于将现象级事件转化为可持续的商业动能。这可能吗？</p>
  <p>近年来，智能终端、新能源汽车、国产3A游戏等，都是创造了巨大商业价值的国产科技突破。<strong>从中，我们可以发现科技产品的生命力从何而来：</strong></p>
  <p><strong>一是靠人，依托个人IP化、网红化持续引流。</strong>以小米汽车为例，雷军亲自挂帅，在个人微博等社交媒体，事无巨细分享，与网友高频互动，带动了巨量关注。也吸引了车企、科技企业创始人纷纷从幕后走到台前，将技术产品变成大众谈资。</p>
  <p><strong>二是靠产品</strong>，以竞争激烈的手机市场为例，近年来手机厂商营销上更接地气，主打一个听劝，“用户要什么就给什么”，让手机创新不再是产品经理的闭门造车，而是定制话题，与用户展开共创，vivo、OPPO都借助社交平台来优化产品，实现了增长。</p>
  <p><strong>三是靠口碑</strong>，DeepSeek的爆火也让人注意到了《黑神话：悟空》背后的游戏科学、宇树机器人等科创企业，它们的产品都是从发烧友推崇的小众产品，<strong>通过社交媒体的口碑传播，迅速蔓延到大众视野，在全球为中国科技赢得了声誉。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f1ed250dd1db45c4b6e7424671497b5d@000000_oswg144598oswg1080oswg763_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不难发现，在长周期、重投入的科技领域，爆红是偶然，长红靠深耕。汽车企业、手机厂商都将内容社交平台，作为品牌重地，通过与潜在用户保持长期、高频率的互动，将社交流量池转化为商业沃土。</p>
  <p>AI行业，当然也不能例外。</p>
  <p><strong>DeepSeek的爆火出圈，正在于打破了海外AI的使用封锁，让全民都能用上先进推理模型，将AI变成全民都在聊、都在用的工具，热搜话题多达200多个。</strong></p>
  <p>春节期间，我们看到了大量普通人与DeepSeek的互动，美妆博主用DeepSeek定制护肤方案；父母在亲子交流中用DeepSeek生成“高情商回复”；冲浪乐子人用DeepSeek“锐评”各类新闻事件……各种意想不到的玩法，都成为AI技术与现实的碰撞时刻。在200+热搜话题中，DeepSeek裂变成了一场全民参与的AI应用实验。</p>
  <p>在这场全民讨论和使用的热潮中，DeepSeek通过口碑传播，不断拉新，用户规模激增。在此基础上，可以获取大量真实互动的数据，可以优化模型产品的使用效果，进一步拉开与其他模型的差距。</p>
  <p>与竞价砸钱买量的传统营销方式不同，DeepSeek的出圈路径，是热搜话题设置讨论议题——技术/行业头部博主打开讨论角度——大量用户参与众测的组合式传播。一步步引导真实用户加入讨论、互动和反馈。</p>
  <p>饱和式的全民参与，让DeepSeek的增长飞轮开始转动，成为DeepSeek出圈的最大一股推动力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ad40fa90f7d74c7893599cf0a7a6f354@000000_oswg58988oswg1080oswg483_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这也提醒我们，让AI走向大众的技术民主化，是商业化成功的前提。</p>
  <p><strong>从技术特性来看</strong>，AI不同于传统的互联网应用和科技产品，后者推出时就是完整形态，而很多AI模型和产品需要先推出再找PMF，在跟用户的迭代互动中不断成长、成熟起来。所以，AI产品必须重视全民参与，至少要有目标用户群的重度参与。</p>
  <p><strong>从市场竞争来看</strong>，AI产品处于排位剧烈动荡的拉新周期，基础模型又需要规模效应，所以竞争白热化，没有声量相当于“等死”，AI企业必须不断制造大众对技术的关注与讨论。OpenAI去年底为期12天的技术发布，就通过话题设置，吸引了全球关注。</p>
  <p>此前，AI领域的技术交流，大多集中在开发者扎堆的极客技术社区，或者AI大厂的开发者社区，与企业客户的闭门交流，缺乏与C端消费者在社交平台互动的经验。</p>
  <p><strong>但是，以大模型为基础的AI应用，开始逐渐转变营销思路。</strong>以豆包、文小言、kimi等为代表的这一批大模型应用，都越来越强调C端传播，用户数成为产品生命力的重要指标。DeepSeek的出圈，则一举打破了海外推理模型的使用封锁线，让先进AI技术可以为大众所见、所聊、所用。这是技术民主化的最佳例证，也是AI实现商业成功的必经之路。</p>
  <p>面对DeepSeek掀起的AI民主化浪潮，全球AI企业或许都面临一个关键选择：是被DeepSeek热潮悄无声息地淹没，还是加速拥抱亿万普通人。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzUxNTUyMjE4Mw==&amp;mid=2247526123&amp;idx=1&amp;sn=ceaa57356d2b4356e55bf618f40f56fa&amp;chksm=f87d83192dbd9eca16e8131ac0c0105b04905c741274c0b3093daa4de1ac9a57063ba18e9f1e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“脑极体”（ID：unity007）</a>，作者：藏狐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156472468560390</id>
            <title>春节后最强三大ETF浮现：人形机器人、黄金、哪吒</title>
            <link>https://www.36kr.com/p/3156472468560390</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156472468560390</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:56:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: A股投资, ETF板块, 机器人, 黄金股  
<br><br>  
总结: 本文分析了春节后A股市场的投资轮动风格，指出机器人ETF、黄金股ETF和游戏动漫等TMT主题ETF成为年内涨幅领先的板块。机器人ETF因春晚节目“机器人扭秧歌”而受到关注，年内涨幅达到18.14%。黄金股ETF受国际金价上涨影响，年内涨幅近13%。此外，《哪吒之魔童闹海》的成功票房推动了游戏动漫相关ETF的上涨。文章还探讨了机器人行业的长期投资机会及黄金市场的前景。 </div>
                        <hr>
                    
                    <p>A股投资轮动风格向来以快制胜，春节后两个交易日，2月6日，年内涨幅超过10%的三大ETF板块已经浮出水面。</p>
  <p>具体来看，<strong>一是机器人ETF板块。</strong>春晚大火的“机器人扭秧歌”，春节后机器人ETF迎来大爆发，年内回报率超过黄金相关主题ETF，成为第一。嘉实机器人指数ETF单日涨幅达到8.27%，年内涨幅18.14%登顶；</p>
  <p><strong>二是黄金股等ETF。</strong>国际金价在节后一度升至每盎司2900美元上方，连创纪录，对于黄金而言，已是疯狂行情。有业内人士调侃，高盛对于黄金将在2026年中期达到3000美元的预测还是太保守了。截至目前，黄金股ETF年内涨幅近13%。</p>
  <p><strong>三是游戏动漫、软件等TMT主题ETF。</strong>2月6日12时，《哪吒之魔童闹海》以57.76亿元票房（含预售）登顶中国票房榜第一名。该影片的出品方光线传媒在影片上映后受益显著，春节后两个交易日累计涨幅41.66%，股价创近4年新高。《哪吒》撬动游戏动漫、软件等ETF年内收益率超过10%。</p>
  <p>三条投资主线既明，当前产业处于什么发展阶段？将如何映射到投资端？接下来又将面临哪些机会？基金经理们带来最新解读与展望。</p>
  <h2><strong>机器人是10年大级别beta机会，还是短期止盈？</strong></h2>
  <p>2025年蛇年春晚的舞台上，一群穿着花棉袄的机器人在现场扭起了秧歌，机器人们还会变换队形、舞动身体，多角度转手绢。“机器人扭秧歌”登上热搜，这些机器人来自国产机器人生产商。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f6af220b388c4ea194042d4b55438b1a@5888275_oswg108763oswg1080oswg725_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>机器人扭秧歌与春晚的组合，赛博朋克风格的节目让人印象深刻，也在节后迅速进入投资者的布局视野。仅仅两个交易日，机器人相关ETF组团登顶年内股票ETF涨幅榜。</p>
  <p>2月6日，嘉实机器人指数ETF涨幅达到8.27%，年内涨幅18.14%。溢价也达到2.47%，可见资金热度。此外，天弘、银华、华夏、国泰等旗下机器人ETF年内涨幅也达到15%，当前也具有不同程度的溢价。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6eeddf5abb184338a8f79fb59fcdc9a2@5888275_oswg50380oswg1080oswg238_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>重点关注机器人方向的永赢先进制造基金经理张璐介绍，以前机器人板块觉得产业链还处于极早期距离落地还有较长时间，同时板块股票数量、行业催化都比较有限，所以机器人板块的行情往往持续性不强。但是机器人板块从2024年四季度开始发生了一些根本性的变化，板块持续演绎，核心是有三点原因：一是超预期的国内外人形机器人进展；二是2025年人形机器人量产元年；三是政策端的支持。</p>
  <p>“除了国内人形机器人厂商进展超预期，2024年10月10日，We Robot大会上，10余个特斯拉擎天柱机器人在现场端茶倒水、跳舞、互动，整体呈现更加灵活与智能，直播3小时中，不存在任何差错，展现了极强的工程实力。”张璐表示，去年12月以来我们看到了大量的新进入玩家开始布局机器人行业，包括汽车、电新、家电、互联网领域的传统巨头，机器人板块股票数量也在快速增长，行业扩圈明显。</p>
  <p>在量产方面，平安基金基金经理张荫先也表示认同，他认为，后续很快会迎来“机器人”新物种的量产时刻，这个赛道也将会是未来数年最受资本市场关注的赛道之一。</p>
  <p>赛道火热之余，投资者更为关心的还是行情的持续性。张璐直言，<strong>人形机器人板块是未来10年大级别beta机会。从产业角度，机器人行业的“Iphone时刻”或将来临。对于行情的判断上，机器人板块近期已逐渐从主题转变为具有长期向上趋势的成长板块。</strong>无论是机构还是游资，整体活跃度较高，此外板块内标的的扩散程度、资金容纳度均有提升。综合来看，机器人板块预期可能会成为中长期反复活跃、中枢不断提升的板块，具有较高的成长性。</p>
  <p>在投资机会的挖掘上，张荫先认为可从两个方面着手，一是寻找在机器人业务中存在较高概率进入供应链的公司，二是积极挖掘并布局主业基本面有改善、同时新拓展机器人业务的优秀公司，这类公司会在新材料、新工艺、新设计方案中有望脱颖而出，让原有的产品在新的机器人领域中获得新应用场景、实现0-1的新突破，进而获得估值及业绩的双击机会。</p>
  <p>当基金经理喊出人形机器人板块是未来10年大级别beta机会的时候，也有游资表示，今天减仓了部分机器人概念。“产业的长期看好与短期的止盈并不矛盾。”</p>
  <p>从资金变动方向来看，2月5日，8只机器人ETF合计资金净流出约1亿元，有一定的止盈迹象，年内资金净流入则达11亿元，其中，华夏机器人ETF净流入最多，超过10亿。</p>
  <h2><strong>国际金价触及3000美元还要用多久？</strong></h2>
  <p>2月5日，COMEX黄金一度升至2900美元/盎司关口上方，今年以来，国际金价已经连续突破2800美元、2900美元关口。换算成国内金饰价格或更为直观，2月6日，周大福、六福珠宝、潮宏基、周生生等足金饰品价格每克已经接近870元。</p>
  <p>2月6日，COMEX黄金价格略有回落，年内涨幅仍高达8.82%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3c5d585d7275484ab1d9ef0d7973f392@5888275_oswg99703oswg1080oswg1321_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>金价上涨，叠加众多金矿龙头公司纷纷发布2024年报业绩预增公告，被称为“金价放大器”的黄金股ETF紧随机器人ETF之后，成为年内增长第二的板块。多只黄金股ETF年内涨幅超过12%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1a274904219e4a4ca028cb3f438a2f2d@5888275_oswg80181oswg1080oswg420_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于黄金股大涨的原因，永赢黄金股ETF基金经理刘庭宇表示，黄金股会受到黄金价格与国内金矿产业公司的双重影响，假期金价上涨反映了投资者对关税政策不确定性的担忧和对全球经济疲软背景下降息周期延续的预期，当前龙头金矿公司按市盈率估值计算仍处于历史中枢下沿，后续估值修复可期，未来有望在量价齐升的戴维斯双击周期中继续起到“金价放大器”的作用。</p>
  <p>“还有一个角度也值得大家关注，近期特朗普家族频繁发行新品类数字货币，导致数字货币市场降温、比特币大跌，部分资金或从数字货币回流黄金市场。”刘庭宇分析称。</p>
  <p>2024年也是黄金投资的大年，当年黄金股ETF涨幅超过27%，今年仅仅过去一个月，相关ETF涨幅已经接近去年全年涨幅的三分之一，接下来该如何配置？在华安基金看来，黄金依然是2025年值得重视的大类资产，原因有四：</p>
  <p>第一，实际利率对黄金的定价有望回归，包括全球经济增速放缓，以及美国面临中长期的再通胀问题。</p>
  <p>第二，逆全球化背景下，为了应对通胀和金融危机，央行有望延续购金节奏。</p>
  <p>第三，黄金在大类资产维度的低相关性，叠加当前低利率环境，凸显出重要配置价值。</p>
  <p>第四，黄金长期增长的本质依然是货币属性，对抗美元信用，当前美国的债务压力和高利率环境在加剧信用风险。</p>
  <p>在黄金相关ETF则越涨越买，2月5日，黄金相关ETF合计净流入5.66亿元，不过拉长年内来看，资金在黄金相关ETF流出近20亿元。</p>
  <h2><strong>《哪吒》撬动游戏动漫等概念ETF大涨</strong></h2>
  <p>《哪吒》票房以58亿元登顶，再次成为游戏动漫等主题上涨的重要驱动事件，不仅最新票房预测达到87亿元，带飞出品方两连板光线传媒，联名手办售罄的泡泡玛特、出版官方绘本的中信出版，乃至提供动漫渲染服务的丝路视觉等上市公司纷纷受到投资者关注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7f42f552db6e40f69f1253b88500d1ea@5888275_oswg97642oswg830oswg1396_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>优质影片内容对票房拉动效果明显，大IP模式之下，影视、动漫、游戏以及软件等TMT主题均受益，华夏游戏ETF、国泰游戏ETF以及华泰柏瑞游戏动漫ETF等大涨之后，年内涨幅也超过11%。</p>
  <p>银河证券研报指出，春节档影片几乎都是国产IP电影或者续作，高价值IP的电影续作不断推进将激励更多新的优秀IP涌现，有望赋能整个电影IP及周边的授权、衍生、开发系列产业链，国产电影的IP品牌效应已经初步显现。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Xz-ErPBYm1oVa41wZ2Toqg" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”</a>，作者：闫军，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156472198584834</id>
            <title>人形机器人短期大涨超50%，基金经理：未来10年大级别机会</title>
            <link>https://www.36kr.com/p/3156472198584834</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156472198584834</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:56:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人形机器人, 产业发展, 投资机会, 政策支持  
<br><br>  
总结: 2025年将是人形机器人量产元年，国内外企业积极布局，相关政策支持不断增强。机器人板块在春节后迎来连续上涨，涨幅已超过50%。多位基金经理认为，机器人行业正在经历根本性变化，未来将成为中长期活跃的成长板块。人形机器人不仅能解放双手，还将全方位赋能人类生活，市场潜力巨大。随着技术进步和产业链完善，预计将迎来“机器人”新物种的量产时刻。 </div>
                        <hr>
                    
                    <p>2025年蛇年春晚的舞台上，一群穿着花棉袄的机器人扭秧歌，让其背后的产商——宇树科技屡登热搜，<strong>人形机器人“一日千里”般的产业发展情形也进入大众的视野。</strong></p>
  <p>受多个利好消息刺激，<strong>春节后两个交易日，机器人板块迎来连续上涨行情：</strong>国泰、华夏、天弘、银华旗下中证机器人ETF在2月5日上涨超4%，截至发稿，相关产品今日涨幅也已近3%。而自去年924行情以来，这一板块涨幅已超过50%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_37fcfdbfaa2a4a26bab1b6cda2c452da@5888275_oswg107332oswg808oswg545_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>多位基金经理认为，机器人板块从2024年四季度开始发生了一些根本性的变化，其板块持续演绎的核心逻辑在于：<strong>超预期的国内外人形机器人进展，2025年将是人形机器人量产元年，政策端支持。</strong></p>
  <p>在业内人士看来，机器人板块预期可能会成为中长期反复活跃、中枢不断提升的板块，具有较高的成长性。<strong>该板块是未来10年大级别beta机会，</strong>它的闪耀登场远不止解放双手那么简单，可能是未来不可多得的，如同当年消费电子中苹果产业链、特斯拉电动车产业链——现象级的长坡厚雪大赛道。</p>
  <h2><strong>人形机器人迎“升浪”</strong></h2>
  <p>经过一个春节的酝酿，人形机器人已进入大众视野，相关产业的巨大发展潜力也为人所熟知。</p>
  <p>一方面，国内企业如华为、宇树科技等积极布局人形机器人；另一方面，国际巨头如特斯拉、英伟达等公司的人形机器人项目正在快速推进，预计2025年将进入有限生产阶段，机器人新创企业Figure更是在2月5日宣布终止与OpenAI合作，并豪言将在30天内推出“ 颠覆人形机器人行业 ”的创新成果。</p>
  <p>受此刺激，春节后首个交易日，机器人板块涨幅居前，国泰、华夏、天弘、银华旗下中证机器人ETF在上涨均超4%。在2月6日开盘后，相关产品继续上涨，截至发稿，上述产品涨幅均在3%左右。</p>
  <p>鉴于人形机器人概念活跃，关注度持续提升，<strong>多家上市公司在互动平台回应研发情况及相关布局：</strong></p>
  <p>经纬股份：公司业务目前不涉及电力巡检机器人和四足巡检机器人；</p>
  <p>精工科技：碳纤维在人形机器人领域的应用优势明显，随着人形机器人产业的快速发展和规模化生产，碳纤维的需求预计将呈现显著增长态势；</p>
  <p>宜安科技：公司密切关注智能机器人领域的技术和产业发展动态，并将结合公司自身战略规划和市场需求进行业务拓展和布局；</p>
  <p>豪森智能：公司现已构建汽车现代智能工业装配线，建立人形机器人智能制造创新中心，完成大连基地与常州基地人形机器人开发双布局，开展多场景人形机器人应用训练和测试技术开发，通过20余年积累的汽车核心零部件装备生产线工艺数据快速迁移到人形机器人智能体开发中，加快了人形机器人在工业制造场景的落地；</p>
  <p>机器人：工业机器人和人形机器人从产品形态、产品结构、技术及应用的侧重等有一定差异，目前公司在3D视觉、力感知等工业机器人领域的核心技术方面有技术积累优势，未来将视需求在融合上述技术的基础上，围绕AI大模型、智能视觉感知、数字孪生、结构仿生等前沿、空白技术领域进行研发投入，积极布局人工智能前沿领域，相关工作在有序推进，尚处于研究初期阶段……</p>
  <h2><strong>板块持续演绎的核心逻辑</strong></h2>
  <p>在国内，有穿着花棉袄的机器人扭秧歌；国外，则有特斯拉擎天柱机器人在“We Robot”大会上端茶倒水、跳舞、互动，还在感恩节随机扔发网球、完美接球。</p>
  <p>从实际情况看，2024年12月以来，大量新进场的玩家开始布局机器人行业，包括汽车、电新、家电、互联网领域的传统巨头，机器人板块股票数量也在快速增长，行业扩圈明显。</p>
  <p>股价层面，从2024年924行情以来，机器人板块的涨幅已来到50%以上，天弘中证机器人ETF、易方达国证机器人产业ETF、景顺长城国证机器人产业ETF涨幅分别达53.93%、53.61%、53.04%，其余中证机器人ETF涨幅也都超51%。</p>
  <p>“以前觉得机器人板块产业链还处于极早期距离落地还有较长时间，同时板块股票数量、行业催化都比较有限，所以机器人板块的行情往往持续性不强。”永赢先进制造基金经理张璐表示。但他看到，机器人板块从2024年四季度开始发生了一些根本性的变化，板块持续演绎。</p>
  <p>他认为，核心原因有三点：一是超预期的国内外人形机器人进展；二是2025年将是人形机器人量产元年：一方面，是特斯拉计划2025年开始对内量产，目标1万台，另一方面，国内多家机器人厂商都推出了自己的量产时间规划，2025年或将看到整个行业1-N的开端；三是政策端支持，近年来，中央和地方政府密集出台政策，全面支持人形机器人产业的发展，为其技术突破、应用推广和产业链完善提供了强有力的保障。</p>
  <p>浦银安盛高端装备基金经理李浩玄直言，过去短短几个月内，人形机器人的产品性能有快速提升，尤其在灵巧手和动作泛化程度上进步显著；国内外几乎所有的科技和制造巨头都在进入这个产业，彻底定调明确了行业趋势，也粉碎了此前的诸多质疑。</p>
  <p>在供应链上，除了原有的核心玩家，新进入者众多。尤其是本身具有技术积淀的自动化和汽零公司基本都在积极投身其中。中国制造快速反应迭代的优势显现。在股价层面，由于一致预期的建立，人形机器人板块涨幅可观，且标的快速“扩圈”，相比2022年和2023年的行情，正在逐步从主题概念过渡到产业投资。</p>
  <p>在此背景下，他在四季度将仓位更多地集中到具备高确定性的标的上，以产业的思路重仓具有真正核心技术、卡位优势和供应链能力的公司。除了上游的核心零部件，还配置了稀缺的具有本体制造和强大品牌力的人形机器人主机厂商。“总的来说，我们将坚持把握行业大趋势，过滤短期情绪波动，战略性重仓扎根核心品种。”</p>
  <h2><strong>机器人行业的“iPhone 时刻”或将来临</strong></h2>
  <p>近期，机器人板块已逐渐从主题转变为具有长期向上趋势的成长板块。不论是机构还是游资，整体活跃度较高，此外板块内标的的扩散程度、资金容纳度均有提升。</p>
  <p>“综合来看，机器人板块预期可能会成为中长期反复活跃、中枢不断提升的板块，具有较高的成长性。”张璐表示。</p>
  <p>他认为，2025年开始，一大批国内外厂商都将进军人形机器人产业，部分公司可能推出现象级机器人产品并开始进行小规模量产，机器人行业的“iPhone 时刻”或将来临。</p>
  <p>在他看来，人形机器人板块是未来10年大级别beta机会。<strong>它的闪耀登场远不止解放双手那么简单，无论从情感陪伴还是物理支持都将全方位赋能人类的生活。</strong>马斯克多次阐述愿景：未来人类和人形机器人的比例将不止是 1：1，有较大可能超过人类数量，渗透率的天花板高且想象空间大。“终局来看，假设是100亿台机器人的市场，如果2万美金一台，会形成200万亿美元的终局大市场。如果所有企业按照终局估值，在未来都会带来庞大增长。”</p>
  <p>值得一提的是，<strong>人形机器人相较于其他行业壁垒较高，涉及到多学科的融合、软硬件的协同，所以对入局的资金、技术、资源整合都有相对较高的要求。</strong>而且产业链从上游到核心零部件和系统零部件，到中游的机器人本体和系统集成，到下游的终端应用，产业链长且复杂。机器人。</p>
  <p>“因此，人形机器人可能是未来不可多得的，如同当年消费电子中苹果产业链、特斯拉电动车产业链——现象级的长坡厚雪大赛道。”而随着人形机器人量产接近，张璐也将重点关注拥有供应链优势、技术具有护城河、价值量较大的优质人形机器人产业链公司，包括机器人总成商、丝杠及设备、减速器、传感器、电机、灵巧手等。</p>
  <p>兴银先进制造智选基金经理罗怡达亦表示，2025年，我们将看到人形机器人开始走向小批量量产，具备完全AI能力的人形机器人将离现实越来越近。“科技的发展将改变我们的生活，这里面蕴含了大量的先进制造产业链机会，中国的企业在相关产业链上有重要的卡位优势，我们积极挖掘其中受益产业趋势且性价比合适的标的进行布局。”</p>
  <p><strong>“我们预计很快会迎来‘机器人’新物种的量产时刻，这个赛道也将会是未来数年最受资本市场关注的赛道之一。”</strong>平安基金经理张荫先称，一方面，他将寻找在机器人业务中存在较高概率进入供应链的公司，另一方面积极挖掘并布局主业基本面有改善、同时新拓展机器人业务的优秀公司。</p>
  <p>“这类公司会在新材料、新工艺、新设计方案中有望脱颖而出，让原有的产品在新的机器人领域中获得新应用场景、实现0-1的新突破，进而获得估值及业绩的双击机会。”张荫先表示。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/WO9Mb56ELXWJlaAdKxPINQ" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”</a>，作者：沈述红，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156437179357954</id>
            <title>苹果机器人首次曝光，一个有情绪会蹦迪的“台灯”，皮克斯动画照进现实</title>
            <link>https://www.36kr.com/p/3156437179357954</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156437179357954</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:56:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <皮克斯, ELEGNT, 机器人, 情感表达>
<br>
<br>
总结: 1986年，皮克斯的短片《顽皮跳跳灯》展示了无表情的台灯通过动作传达情感，成为皮克斯的吉祥物。苹果推出的ELEGNT机器人，旨在让非拟人化机器具备肢体语言和情感表达，提升人机交互的生动性。ELEGNT通过上下文学习能力，能够根据实时场景调整动作，表现出情感和态度。尽管ELEGNT在情感表达上表现出色，但其效率低于传统机器人，引发了对机器人设计方向的思考。未来，ELEGNT可能会在智能家居中得到应用，成为更具普适性的技术。 </div>
                        <hr>
                    
                    <p>1986 年，皮克斯在一场计算机图形讨论会上放映了最新动画《顽皮跳跳灯》，片中两个蹦蹦跳跳的台灯没有表情，没有对白，只凭借扭头、伸展等等的动作，用 2 分钟就向观众展示了自己的鲜明个性和情感。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_827ccc547b3e4bb6931f11dbe2cf29dd@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种前所未见的动画形式，不仅震撼了在场所有人，还助力这部短片拿下奥斯卡提名，也成为了现在每一部皮克斯电影都不会缺席的吉祥物。&nbsp;</p>
  <p>而将近 40 年后的今天，和皮克斯渊源颇深的苹果，成功将这个动画史上最具里程碑意义的角色，带到了现实世界当中。&nbsp;</p>
  <h2><strong>有情感的「小台灯」&nbsp;</strong></h2>
  <p>今天，苹果在其机器学习网站，公布了一项机器人研究成果 「ELEGNT」，目前的原型机器是一个台灯形态的设备。&nbsp;</p>
  <p>ELEGNT 的名字取得非常巧妙：形似单词「elegant（优雅）」，符合这项技术的表现；而全称很长：a framework of <strong>E</strong>xpressive and functiona <strong>L</strong>&nbsp;mov <strong>E</strong>ment desi <strong>G</strong>n for&nbsp; <strong>N</strong>on-anthropomorphic robot，翻译过来就是「一种用于非拟人化机器人的表达性和功能性运动设计框架」。&nbsp;</p>
  <p>看起来有点抽象？其实核心意思很简单：苹果做的不是春晚舞台上的人形机器人， <strong>而是让一些非人形机器，比如一个台灯，懂得「肢体语言」。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_210501355b474ce9b699221235d4127a@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这个「懂」不单单是「理解」人类的手势操作， <strong>而是机器人做出反应时，也会补充一些动作细节，让交互有「生命感」。</strong></p>
  <p>传统的机器人，完成指令的方式是一条直线，程序设定好的动作幅度精准到不会多出一毫米。&nbsp;</p>
  <p>而 ELEGNT 是一条曲线，过程中会表达意图、显示注意力、展示态度、表达情绪，也就是说会小小地「演」一下。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8286f79424f24421be010e5ec72548c8@000000_oswg37458oswg1024oswg573_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>比如，用户下达指令的时候， ELEGNT 会「看着」用户，时不时歪歪头和点头，仿佛自己真的在认真听讲，而实际上没有这些动作，机器人也能通过麦克风正常录音和分析。&nbsp;</p>
  <p>用户问机器人天气，它会先向窗户的方向探探头，然后再进行回答，但其实它只是上网检索了一下天气数据。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_db522a7d1a2a4ba2b03061843530d7a7@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>如果机器人够不着需要识别的物体，它还会垂下脑袋摇摇头。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0accbf1b7f2a4ab0871d09fcf03f8a7f@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>比较可爱的是放音乐的时候，机器人会跟着节拍一起蹦迪，看起来真就像是皮克斯电影的桥段。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_622cfd766bdd45af9b9b4826c5303c51@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一样的台灯形态和动作，很容易让人想起 2023 年小米发布的一个名为「皮皮灯」的产品，同样能「摇头晃脑」，有「喜怒哀乐」的情绪表达。&nbsp;</p>
  <p>不过这个皮皮灯的实现原理要简单许多，主要是设定好的程序，动作幅度也比较死板，总体来说比较像噱头。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3cb99bdc0d4d437cbb9db8bc075a84f6@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：知乎 @J 法老&nbsp;</p>
  <p>ELEGNT 背后的技术要复杂得多， <strong>运用了大语言模型的上下文学习能力，能够「察言观色」</strong>，根据实时交互场景调整动作模式。在交互中，ELEGNT 会主动问用户远足能不能带上自己，如果被拒绝，它就会低下头，给人一种很难过的感觉。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1ea45f25131549d88db9e0c2a947a091@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>ELEGNT 还结合人类反馈优化，目前能够生成 10 种不同的肢体语言序列，并控制好每个动作的时间和幅度，实现情感表达和任务完成效率的平衡。&nbsp;</p>
  <p>当然，高度拟人化的 ELEGNT，背后也存在一定的伦理问题：可能会引起用户的情感投射，甚至依赖，尤其是在儿童和一些脆弱群体当中。&nbsp;</p>
  <p>由于测试的时间太短，测试人员也不够多，无法验证 ELEGNT 表达动作会不会存在程式化的问题，长期使用有可能会导致用户审美疲劳，影响交互的有效性。&nbsp;</p>
  <h2><strong>机器人也需要「人味」&nbsp;</strong></h2>
  <p>从苹果的演示对比视频可以发现，ELEGNT 机器人虽然可爱，但它的效率比「打直球」的普通机器人要低很多，前者还在探头探脑的时候，后者早已经给出用户需要的答案。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_339384dd4e9b4c41b0f0bcd3b4524325@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>这似乎和机器人的初衷有点背道而驰。让机器人进入我们的工作和生活，本应该是为了更好更快地帮我们干活，而 ELEGNT 问个天气都要等它先演一番，这么一想，苹果好像「方向错了」？&nbsp;</p>
  <p>技术是冰冷的。当你还在欣喜于 Deepseek 能帮你高效完成工作，可能你已经快要被它取代；工厂里越来越多的机器人身影，意味着更多人类失去岗位。&nbsp;</p>
  <p>而苹果变 AI 为 Apple Intelligence，玩一点文字游戏来掩盖技术的无情一面；而对于机器人，苹果的思路更加开阔。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_03209b452cb94c0087f51539662b2abd@000000_oswg62808oswg1024oswg538_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Apple Intelligence 多彩的界面和 logo 也是为了显得更友好 &nbsp;</p>
  <p>虽然不如人形机器人那么火，但这两年「机器宠物」的概念也开始兴起：卡西欧的 Moflin 卖断货，CES 上的 Ropet 成功刷屏。这些毛绒绒的小机器人，主要的功能就是卖萌，和生成一些「情感」。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f0f86755445c40c899f56423c673eb1e@000000_oswg51112oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Ropet&nbsp;</p>
  <p>&nbsp;</p>
  <p>ELEGNT 就有点像电子宠物和实用机器人的结合，它能一边卖萌，一边完成任务。论文中也提到，情感优先的机器人，能够降低人类的认知负荷，让用户更乐于主动去进行交互，特别是在社交场景中。&nbsp;</p>
  <p>不是只有苹果在想办法为机器人增加活人感。马斯克的人形机器人 TeslaBot，已经会和用户玩剪刀石头布；宇树科技也让机器人穿上大花袄扭秧歌，登上春晚大舞台。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d49e3d3b69934aae8110b9f042e05e3b@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">TeslaBot&nbsp;</p>
  <p>&nbsp;</p>
  <p>只是，这些外壳冰冷、动作机械的机器人，再怎么模仿人类，目前都还是差了点意思。ELEGNT 直接另辟蹊径，利用了我们对皮克斯动画角色的集体记忆，加上完成度相当不错的机器动作，首次亮相就成功走进不少人的内心。&nbsp;</p>
  <p>The Verge 评论区，已经有网友对 ELEGNT 给出高度评价：&nbsp;</p>
  <p><strong>我已经不想养一只狗了，我现在想养一盏台灯。&nbsp;</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3ae65fc1c9234598a57a979468303024@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">「我爱台灯」&nbsp;</p>
  <p>论文中更严谨的样本研究显示，带有情感表达的 ELEGNT ， <strong>在 6 个任务的评分中都高于没有情感表达的版本，前者几乎获得后者两倍的平均得分；并且 ELEGNT 放音乐时蹦迪的表现让人印象非常深刻。</strong></p>
  <p>比起人形机器人，ELEGNT 是一个更具普适性的技术，因为它可以用于那些非人形的低自由度机器人中。今天是一盏台灯，明天可能就是苹果的 HomePod，到最后可能整个家都变成迪士尼的公主城堡，每个家具都有自己的情感，一个人住也能热热闹闹的。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2eea7672bcf143c5a9d3c4f56bf9b79d@000000_oswg62392oswg612oswg380_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">未来的智能家居说不定长这样&nbsp;</p>
  <p>虽然这些技术目前还只是学术成果，但它们实装到产品上的日子或许不会太远。从去年开始，非常多的信息源都报道称， <strong>苹果正在开发智能家用机器人，可能会是一个带了个显示屏的 HomePod 设备，或者是带有机械臂的 iPad</strong>，有点像经典的 iMac G4， <strong>有望于 2026 或 2027 年推出。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_33dd6ab8bf5547caa6535560c1a9513e@000000_oswg477685oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">苹果新智能家居假想图，图源：MacRumors&nbsp;</p>
  <p>根据此前的爆料，这个带显示屏的 HomePod 可能会支持自动转向，始终将屏幕对准用户，并且能识别手势操作，听起来就很适合 ELEGNT 大显身手。&nbsp;</p>
  <p>iPhone 一年比一年无聊，万众期待的 Vision Pro 、Apple 智能实际体验乏善可陈。据称，家用机器人很可能成为苹果的「Next Big Thing」，用来打下苹果目前表现平平的智能家居市场。&nbsp;</p>
  <p>Amazon、Google 不是没有类似的探索，但用户接受度并不高，主要是因为这些设备笨重又不智能；步步紧逼的老对手三星，也已经宣布了今年正式发布家用机器人，外观同样主打「可爱风」。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fe8372f7273b40a198fdff3302992695@000000_oswg32770oswg1024oswg683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">三星将于今年发布智能家用机器人 Ballie&nbsp;</p>
  <p>苹果这次能不能再次成功「后发制人」的问题，只有时间能作答，但至少 ELEGNT 让我久违地感觉一个苹果产品 <strong>「非常有趣」</strong>。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_39882456c0f449fca50451264ac66391@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&amp;mid=2652396195&amp;idx=1&amp;sn=a8784ca45776b2a107026a224d786886&amp;chksm=9ac149f833c00485a271c39d469787ceac1e552fa2e8b97ae45c999dad1dc5630babb5d454ce&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“爱范儿”（ID：ifanr）</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156473943300872</id>
            <title>免费功能卷翻付费版ChatGPT，欧洲AI新贵叫板OpenAI</title>
            <link>https://www.36kr.com/p/3156473943300872</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156473943300872</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:55:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Le Chat, Mistral AI, 闪电回答, 代码解释器  
<br><br>  
总结: Mistral AI推出了全新升级的AI助手Le Chat，支持iOS和Android，并引入了“闪电回答”功能，响应速度可达每秒1000字。Le Chat还具备代码解释器、图像生成、高级文档分析等多项功能，且大部分功能免费提供。与其他AI助手相比，Le Chat在速度和功能上力求竞争，未来还将推出企业版。用户可以通过Le Chat进行个性化学习和目标跟踪，提升使用体验。 </div>
                        <hr>
                    
                    <p>“欧洲OpenAI”<strong>Mistral AI</strong>有新动作了！</p>
  <p><strong>Le Chat</strong>（法语“猫”）<strong>全新升级</strong>，官方自称它是“您生活和工作的终极AI助手”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3f8b17c1daf84b6b9be421edb8e159ef@5888275_oswg172265oswg1080oswg794_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从今天开始，Le Chat上线移动端，<strong>iOS和Android都支持</strong>，不久也将对企业私有基础设施开放。</p>
  <p>功能方面，Le Chat升级主打极速响应，Mistral AI开发者关系主管原话是这样婶儿的：</p>
  <blockquote>
   <p>Le Chat的推理、反思和响应速度超过任何其它聊天助手，可达每秒~1000words。</p>
  </blockquote>
  <p>这个功能被命名为“<strong>闪电回答</strong>”（Flash Answers）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7b73275383894adfb9e1ad4af9754330@5888275_oswg199720oswg1080oswg381_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_47567994c6814735ba28b83c809c8be6@5888275_oswg75794oswg1026oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有多快？</p>
  <p>来看Le Chat与Claude、ChatGPT的对比，同样是用Python编写贪吃蛇游戏，Le Chat刚开始就结束，速度达1100tok/s，Claude速度120tok/s，ChatGPT为85tok/s。</p>
  <p>除了速度快，Le Chat还引入了<strong>代码解释器</strong>功能，加上原有的图像生成、高级文档与图像分析、网页搜索、Canvas等，Mistral AI势要和ChatGPT、Claude等卷到底。</p>
  <p>要知道，Canvas等功能在ChatGPT那儿是要付费的，而Le Chat直接免费就能玩，包括“闪电回答”也是免费的。</p>
  <p>而付费版在免费版的功能基础上，外加不限量访问最高性能模型和网页浏览、可选择不与Mistral AI共享数据等权限。Mistral AI表示还将推出私有预览的企业版（Enterprise）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e118db2eace5479f9f66040d39f7cf25@5888275_oswg248250oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这波操作把网友看懵:</p>
  <blockquote>
   <p>不明白你们为什么要和ChatGPT/Claude竞争，很烧钱，不是吗？</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4140813507ce49c88dc546fe9da31ff6@5888275_oswg96794oswg1080oswg197_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网友评论区底下直呼：</p>
  <blockquote>
   <p>还需要MacOS app～</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_64ae19dc5c1d4370bc857be9344d09fd@5888275_oswg72517oswg1080oswg228_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <blockquote>
   <p>AI公司一个周内互相超越。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_01d3160769b24456af6f02b5f709e1af@5888275_oswg108378oswg1080oswg263_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>Le Chat功能一览</strong></h2>
  <p>再具体来看看Le Chat这波新增的代码解释器功能，Le Chat现已具备高级编码功能。</p>
  <p>它使用户能够执行沙箱代码、进行科学分析、创建可视化以及运行模拟。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4eedd0d263ad4e199ac08e1f7bf013f5@5888275_oswg44775oswg1080oswg480_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>比如prompt：</strong>你能解释一下泰勒级数近似的原理吗？给一些正弦函数的例子。</p>
  <p>Le Chat解释时会附带插图说明（Illustration）：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c847ad49734d4dddb7e82e8319789c32@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>支持验证代码：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_45d797eb5fcd4ddc805270caba54ef94@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用代码解释器分析CSV数据也不成问题：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_31ac9c4d31df49d287d2e5016cd476a2@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e847be28d4434c07a5ebfa58fdbc1b2a@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Le Chat图像生成功能由Flux Ultra驱动，支持画文字：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_82f64fb772af4f4482b34e07c1972501@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也有热门网页搜索功能，附带信息源：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8f0db68de8f24799bf0e8d54739de282@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>文档理解功能，对论文的理解可以精准到某张图，比如可以让它解释Figure 2的abcd都表示啥：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2f16b81e6b8941aa9f33b63bf94001e5@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此之外，官方还表示即将对所有用户开放“<strong>记忆</strong>”（Memories）功能，可选择性开启。</p>
  <p>它可以了解记住用户偏好，重新发现很久以前的对话，由此能提供个性化学习，跟踪用户实现目标的进度。</p>
  <p>比如它能记起你之前提到新年目标是在接下来的6个月内将体脂率从22%降至12%，然后帮你制定月度计划：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_cccf7d9ef0504b2190fe2aa0511cffaa@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>总之，ChatGPT有的，都得有。</p>
  <p>这就不得不提ChatGPT的会员专属高级界面Canvas功能，Le Chat免费，能够帮助用户从0-1进行创作。</p>
  <p>比如，计划未来四周内在巴黎向另一半求婚，已经买了戒指，但还没有计划其它的细节，请求创建一个详细的视觉时间线以保持事情的进展有序。</p>
  <p>Le Chat的规划是酱婶儿的，有单独界面展示生成的文稿，也有代码以及可视化。</p>
  <p>Le Chat还有一个功能是可以创建并在对话中@智能体，智能执行任务：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e8e7104dce0b4fd7b88f42c43c2fbb5c@5888275_oswg41290oswg1080oswg433_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>比如使用Le Chat智能体追踪个人财务，自动化安排日程：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3986ded4ba454590b24b9b756dd32e79@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>都能get可视化图表的那种：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_381d6cf1fde549069bf6442ea23485ef@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Le Chat全新升级后，网友们也已经开始玩起来了。</p>
  <p>有网友尝试一番过后反馈确实很快：</p>
  <p>感兴趣的童鞋可以亲自试试～</p>
  <p>参考链接：</p>
  <p>[1]https://x.com/sophiamyang/status/1887517050697842899</p>
  <p>[2]https://x.com/onetwoval/status/1887547069956845634</p>
  <p>[3]https://x.com/MistralAI/status/1887517520040448510</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/K_krY5nLog3dFaQFWIhXdw" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156478097889800</id>
            <title>杭州跑出50亿未来独角兽：年入8.12亿</title>
            <link>https://www.36kr.com/p/3156478097889800</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156478097889800</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:55:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 盘兴数智, IPO, SaaS, 在线营销  
<br><br>  
总结: 盘兴数智是一家专注于智能电商SaaS运营解决方案的公司，近期向港交所递交IPO申请。其前身为浙江独角兽企业盘石信息，现估值达到50.49亿元。公司主要产品包括线上营销解决方案和SaaS服务，线上营销解决方案在2024年前9个月占总收入的91%。随着内容电商平台的崛起，行业增长迅速，预计市场规模将持续扩大。盘兴数智通过两轮融资获得资本市场青睐，财务表现也显著提升。 </div>
                        <hr>
                    
                    <p>近日，来自浙江杭州的企业——盘兴数智向港交所递表，全力冲刺IPO。</p>
  <p>盘兴数智是一家专注于提供智能电商SaaS（软件即服务）运营解决方案的公司。它借助先进的技术和海量的数据，助力企业实现更高效的运营与管理，尤其在电商、制造业等领域。</p>
  <p>盘兴数智的前身是浙江独角兽企业盘石信息（估值110亿元）的RockySaaS事业部。如今，它的估值也达到50.49亿元。</p>
  <p>盘兴数智究竟是一家怎样神奇的公司呢？</p>
  <h2><strong>01</strong></h2>
  <p>浙江盘兴数智科技股份有限公司（以下简称“盘兴数智”）的创始人是田宁先生，出生在浙江湖州。</p>
  <p>1999年，还在浙江大学动物科学专业读大三的田宁和两位同学一起凑了10万元启动资金，创立了浙江大学盘石计算机网络技术有限公司，这也是浙江大学首家由在校大学生创办的企业，田宁也因此被冠以“浙江省大学生创业第一人”的称号。</p>
  <p>盘石计算机开始准备做教培咨询，但很快把钱烧完了，之后转向销售计算机硬件，还承接了省内多项电子政务项目，挣到了第一桶金。</p>
  <p>2004年，田宁创立了盘石信息，以精准、定向网络营销分析技术为基础，做企业网络营销服务提供商。</p>
  <p>2011年，云计算概念渐兴起，SaaS也开始进入大众视野。田宁带领盘石信息正式切入SaaS赛道。</p>
  <p>随后，盘石信息深入挖掘“盘石云”大数据，逐步形成了RockySaaS、Rockyplay、直播电商、智慧城市、数字科技、新消费和信用云七大业务板块，打造出了基于盘石大数据交互链接的商业生态平台 。</p>
  <p>2017年，为了更好地专注于RockySaaS（企业级SaaS服务）业务，盘石信息创建全资子公司盘兴数智，将该业务分立出来。</p>
  <p>2018年，盘兴数智调整业务布局，将发展重心聚焦于国内SaaS市场。盘兴数智先后以127.13万元和261.76万元，收购了SCRM服务供货商杭州清柳和定制软件开发商北京远景，并实现控股。</p>
  <p>2021年，直播带货这一新兴业态爆火，盘兴数智成立天津禾越，进一步拓展在线营销业务，将业务范围延伸至抖音及快手的直播电子商务领域。</p>
  <p>至此，盘兴数智成功转型为一家提供在线营销解决方案、与办公室自动化系统及电子商务系统定制开发相关软件服务的供货商。</p>
  <p>在业务不断拓展的同时，盘兴数智获得资本市场的青睐。</p>
  <p>2021年和2024年，相继获得两轮融资，浙江大学教育基金会、南京景衍等纷纷斥资入股。经过这两轮融资，盘兴数智的估值达到了50.49亿元。</p>
  <h2><strong>02</strong></h2>
  <p>盘兴数智的主要产品包括线上营销解决方案和SaaS服务。</p>
  <p>其中，线上营销解决方案涵盖一站式服务、流量获取服务、直播电子商务服务等多个方面，主要作用是帮助客户获取线上流量、提升品牌曝光度，进而促进产品销售。2024年前9个月，该业务收入达到6.13亿元，占公司总收入的91%，成为公司营收的主要来源。</p>
  <p>而SaaS服务则包括云端软件供应、短讯服务、定制软件开发等，旨在为企业提供全方位的数字化运营支持。2024年前9个月，SaaS服务收入为5709万元，占比8.5%。</p>
  <p>在财务表现上，2022年，盘兴数智营收为4.91亿元，期内利润为667万元；到了2023年，营收跃升至8.12亿元，同比增长超过65%，期内利润也大幅增加至2516万元；2024年前9个月，营收达到6.73亿元，已超过2022年全年水平，上年同期营收为4.37亿元，同比增长54% ，期内利润为2201万元，上年同期为847万元。</p>
  <p>盘兴数智所处的赛道是在线营销和SaaS服务赛道，值得注意的是，内容电商平台（如抖音、快手）的崛起成为推动行业增长的重要因素。</p>
  <p>招股书称，这些平台凭借优质内容和强大的社交属性，吸引了大量消费者，具备良好的引流条件。内容电商平台的线上营销解决方案服务市场规模从2018年的36亿元增至2023年的1507亿元，复合年均增长率达到惊人的111.0%。预计到2028年，市场规模将达到5746亿元，复合年均增长率为30.7%。</p>
  <p>此外，随着去中心化电商平台在中国电子商务市场中的地位日益重要。去中心化电商平台的交易额从2018年的0.8万亿元增至2023年的4.1万亿元，复合年均增长率为38.7%。商家逐渐意识到在这些平台上发展终端客户和维护“私域流量”的重要性，这也进一步推动了对线上营销解决方案服务的需求。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI0NzAzNTUwMQ==&amp;mid=2652511929&amp;idx=3&amp;sn=94fd5c13208b02bd97e387088f0719ef&amp;chksm=f3f40ab8b1d22c8b15ef77799196251491d3fe2fd52a370dfb722624adfbc2a926ee2ebf7e54&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“铅笔道”（ID：pencilnews）</a>，作者：不说谎的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156482137135618</id>
            <title>历史分水岭：DeepSeek GitHub星数超越OpenAI，大佬揭秘仅用450美元训推理模型</title>
            <link>https://www.36kr.com/p/3156482137135618</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156482137135618</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:55:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, GitHub, 推理模型, 开源社区  
<br><br>  
总结: DeepSeek项目在GitHub上的Star数超越了OpenAI，成为开源AI历史上的里程碑。DeepSeek-V3的热度迅速上升，用户热情高涨，导致其暂停API充值。关于DeepSeek的谣言被专家辟谣，澄清了其与CUDA的关系及训练成本的误解。DeepSeek-R1和V3的发布将推动推理模型的发展，机器学习专家Sebastian Raschka对其方法论给予高度评价，并提出了提升LLM推理能力的四种方法。即使在预算有限的情况下，模型蒸馏和新方法如旅程学习也为推理模型的研究提供了新的可能性。 </div>
                        <hr>
                    
                    <p>刚刚，DeepSeek的GitHub星数，超越了OpenAI！V3的Star数，如今已经碾压OpenAI最热门的项目。机器学习大神的一篇硬核博文，直接帮我们揭秘了如何仅用450美元，训出一个推理模型。</p>
  <p>就在刚刚，历史性的一刻出现了。</p>
  <p>DeepSeek项目在GitHub平台上的Star数，已经超越了OpenAI。</p>
  <p>热度最高的DeepSeek-V3，Star数如今已达7.7万。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e8a7df8f5c3c403484be715a7d746a66@5888275_oswg184840oswg1080oswg473_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>做出这一发现的网友们，第一时间截下了图</p>
  <p>可以说，这是开源AI历史上的一个里程碑！</p>
  <p>而DeepSeek-R1，更是仅用了3周时间，就超越了「openai-cookbook」。</p>
  <p>前有App Store登顶，今有GitHub超越，网友们高呼：永远不要低估开源社区的力量！</p>
  <p>如今，DeepSeek的势头越来越猛。</p>
  <p>相信大家都发现，DeepSeek的服务器简直要爆了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_053e6c6e93c248e2861d79bf3b7a3240@5888275_oswg75551oswg1080oswg341_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>甚至就在昨天，DeepSeek还不得不官宣：暂停API充值。</p>
  <p>原因当然就是因为，用户的热情实在太火爆，服务器真扛不住了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a81723b15be24340b5a782944ce2dad5@5888275_oswg136953oswg1080oswg393_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最近，关于DeepSeek的一些流传甚广的说法，也纷纷有专家辟谣了。</p>
  <h2><strong>澄清一：DeepSeek绕过了CUDA架构</strong></h2>
  <p>其中一个广为流传的说法是DeepSeek绕过了CUDA。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_68a6354c1562472aa5e41c4d936cf5de@5888275_oswg204538oswg1080oswg406_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这源于DeepSeek的论文中提到，模型采用了PTX编程，通过这样的定制优化，让模型能更好地释放底层硬件的性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_84edc924446148a086440325365f478b@5888275_oswg374665oswg1080oswg369_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>「我们采用定制的PTX（并行线程执行）指令并自动调整通信块大小，这大大减少了L2缓存的使用和对其他SM的干扰」</p>
  <p>严谨来说，DeepSeek通过编写PTX解决了跨芯片通信瓶颈，虽然复杂，但降低了开销、提升了效率。</p>
  <p>本质上，PTX仍然是位于CUDA驱动层内部的一个组件，是英伟达CUDA编程模型的一部分，能将CUDA源代码（C/C++）转变为机器指令的一个中间阶段。</p>
  <p>在运行时，PTX会进一步被编译成在GPU上运行的最终机器码（SASS）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_85390a64b00b439694951c077dbf7dac@5888275_oswg156306oswg825oswg535_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而DeepSeek团队的聪明之处就在于，用这种方法能更好地实现对底层硬件的编程和调用。</p>
  <p>这种主动优化，无论在H800还是H100上都能提高通信互联效率。</p>
  <p>因此，DeepSeek仍然没有摆脱CUDA生态。</p>
  <h2><strong>澄清二：R1的训练成本，绝不仅仅是600万美元！</strong></h2>
  <p>而关于DeepSeek-R1的另一个谣言，就是R1的训练成本大约是600万美元。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_01462dbc311d4b7396caf1b6755e3b2d@5888275_oswg286936oswg1080oswg335_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之所以有这个说法，来源于DeepSeek-V3论文中的相关论述</p>
  <p>开发者大神Sebastian指出，很多人都混淆了DeepSeek-V3和DeepSeek-R1。（前者要早1个月）</p>
  <p>其中，DeepSeek-V3中宣称的550万美元，是基于GPU成本、GPU小时数、数据集规模和模型规模等估算出来的。</p>
  <p>但DeepSeek团队从没公开过R1确切的GPU小时数或开发成本，目前已有的任何成本估算都只是猜测。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f2b2cc61afaf41b59cdaf7a912f7e668@5888275_oswg67686oswg1080oswg429_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此之外，Stability AI前研究总监Tanishq Mathew Abraham也在最近的博文中指出，R1在V3基础上进行的强化学习，以及最终训练前团队的大量的小规模实验和消融研究都未包含在内。</p>
  <p>更何况还有研究者的薪资，据传已经跟OpenAI、Anthropic等顶级机构的薪资相当（高达100万美元）。</p>
  <h2><strong>V3和R1，开启推理模型大变局</strong></h2>
  <p>DeepSeek V3和R1发布后，将怎样搅动此后的LLM江湖？&nbsp;</p>
  <p>预算紧张的情况下，怎么开发推理模型？</p>
  <p>最近，机器学习大神Sebastian Raschka的这篇长篇博文，为我们做出了硬核预测，并且破除了不少民间对DeepSeek的误解。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3d1da8e26cea4084abe346e6ac9622a0@5888275_oswg58375oswg1080oswg208_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Sebastian表示，很多人都来询问自己对DeepSeek-R1的看法。</p>
  <p>在他看来，这是一项了不起的成就。</p>
  <p>作为一名研究工程师，他非常欣赏那份详细的研究报告，它让自己对方法论有了更深入的了解。</p>
  <p>最令人着迷的收获之一，就是推理如何从纯强化学习行为中产生。</p>
  <p>甚至，DeepSeek是在MIT许可下开源模型的，比Meta的Llama模型限制更少，令人印象深刻。</p>
  <p>在本文中，Sebastian介绍了构建推理模型的四种方法，来提升LLM的推理能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c92b491b84474bffbcf8cb26a1df1a0b@5888275_oswg205805oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>图中总结了DeepSeek R1的训练流程。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3d7cab1b0df4446c8ded5f8dad94ead5@5888275_oswg229200oswg1080oswg862_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>（1）DeepSeek-R1-Zero：该模型基于2024年12月发布的DeepSeek-V3。研究团队采用RL进行训练，并使用了两种奖励类型。这种方式称为冷启动训练，因为它没有采用RLHF中的SFT步骤。</p>
  <p>（2）DeepSeek-R1：这是DeepSeek的旗舰推理模型，构建于DeepSeek-R1-Zero基础上。团队通过额外的SFT阶段和进一步的RL训练，对模型进行了优化。</p>
  <p>（3）DeepSeek-R1-Distill：利用前述步骤中生成的SFT数据，团队对Qwen和Llama模型进行了微调，以增强它们的推理能力。尽管不是传统意义上的蒸馏，但该过程是用DeepSeek-R1的输出，来训练较小的模型（Llama 8B和70B，Qwen 1.5B–30B）。</p>
  <h2><strong>构建推理模型的四种方法</strong></h2>
  <h3><strong>推理时扩展</strong></h3>
  <p>想要提升LLM的推理能力，或者是其他任何能力，有一种方法叫推理时扩展，就是在推理过程中增加计算资源，让输出的结果质量更高。&nbsp;</p>
  <p>人类在解决复杂问题时，如果思考时间更充裕，往往能给出更好的答案。</p>
  <p>有一种推理时扩展的简单方法，是巧妙的运用提示工程。思维链（CoT）提示法是一个经典例子，在处理复杂问题时，通常能得到更准确的结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3cfd8d03fbad47ca84b8ac017759e21e@5888275_oswg224303oswg1080oswg283_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一种推理时扩展的方法是使用投票和搜索策略。</p>
  <p>一个简单的例子是多数投票方法，让LLM生成多个答案，然后通过投票选出正确答案。</p>
  <p>同样，也可以使用束搜索（beam search）和其他搜索算法来生成更好的响应。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f898d6b3eefc44439d3fb3cd9df2602e@5888275_oswg297214oswg1080oswg620_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>推测OpenAI的o1和o3模型使用了推理时扩展。此外，o1和o3可能还运用了与DeepSeek R1类似的RL流程来训练。</p>
  <h3><strong>纯强化学习（RL）</strong></h3>
  <p>DeepSeek R1论文中的一个亮点是，推理行为可以通过纯强化学习（RL）产生。</p>
  <p>通常在RL训练之前，会先进行SFT，但DeepSeek-R1-Zero完全通过RL训练，没有初始的SFT阶段。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_70a21bc16707423a9af0d27ba21bdcc6@5888275_oswg238015oswg1080oswg868_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepSeek-R1-Zero的一个关键区别是它跳过了SFT阶段。</p>
  <p>在奖励机制上，DeepSeek没有采用基于人类偏好的奖励模型，而是采用了准确性奖励和格式奖励。</p>
  <p>- 准确性奖励，是用LeetCode编译器来验证编程答案，并用确定性系统评估数学回答。</p>
  <p>- 格式奖励，则靠LLM评判器，保证回答符合预期格式，比如把推理步骤放在标签里。</p>
  <p>让人意外的是，靠这种方法，LLM就能发展出基本的推理能力。</p>
  <p>研究人员观察到「顿悟时刻」：模型开始在回答中生成推理过程，即使没有专门训练它这么做。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2a2d0fbf74ae4788aff30fde35a5454f@5888275_oswg295140oswg1080oswg628_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>尽管R1-Zero并不是性能最优的推理模型，但它通过生成中间的思考步骤展示了推理能力。这证明用纯强化学习（RL）开发推理模型是可行的。</p>
  <h3><strong>监督微调和强化学习（SFT+RL）</strong></h3>
  <p>旗舰模型DeepSeek-R1通过结合额外的SFT和RL，提升了模型的推理表现。</p>
  <p>在RL之前进行SFT是常见的做法，标准的RLHF流程就是如此。OpenAI的o1模型很可能也是用类似方法开发的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_90ff3b4a341e4f859659b8f8d08148fe@5888275_oswg214162oswg1080oswg858_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如图所示，团队用DeepSeek-R1-Zero生成了冷启动SFT数据。通过指令微调训练模型，接着又进行了一轮RL。</p>
  <p>在这一轮RL中，保留了DeepSeek-R1-Zero的准确性奖励和格式奖励，还新增了一致性奖励，来避免语言混杂。</p>
  <p>RL结束后，又开始新一轮SFT数据收集。在这个阶段，用最新的模型生成了60万条CoT SFT示例，同时用DeepSeek-V3基础模型创建了另外20万条SFT示例。</p>
  <p>上述样本随后被用于另一轮RL训练。在这个阶段，对于数学和编程问题，还是用基于规则的方法进行准确性奖励。对于其他类型的问题，则用人类偏好标签来评判。</p>
  <p>经过多轮训练，DeepSeek-R1的性能有了显著提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b668665104594be8a944dd3c32454a8f@5888275_oswg184916oswg1080oswg340_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>纯监督微调（SFT）和蒸馏</strong></h3>
  <p>到目前为止，已经介绍了三种用于改进LLM推理能力的方法，最后是模型「蒸馏」。</p>
  <p>这里「蒸馏」是指用较大LLM生成的数据集对较小的LLM（如Llama 8B和70B以及Qwen 2.5模型，范围从0.5B到32B）进行指令微调。</p>
  <p>实际上，这个蒸馏过程中的SFT数据集，和之前用来训练DeepSeek-R1的数据集是一样的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_89a37e3671ed468cb93df4a7c0fd4a6b@5888275_oswg228206oswg1080oswg862_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为什么开发蒸馏模型？可能有两个关键原因：</p>
  <p>1 &nbsp;<strong>较小的模型更高效。</strong>小模型运行成本更低，还能在配置较低的硬件上运行。对研究人员来说很有吸引力。</p>
  <p>2 &nbsp;<strong>纯SFT的案例研究。</strong>这些模型展示了在没有RL的情况下，单纯靠SFT能把模型优化到什么程度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_69019d62c1754baa86755ba7d8b8fb25@5888275_oswg376470oswg1080oswg558_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>团队将DeepSeek-R1-Zero中的纯RL方法直接应用于Qwen-32B。</p>
  <p>结果表明，对于较小的模型，蒸馏远比纯RL更有效。</p>
  <p>仅靠RL可能不足以让小模型具备强大的推理能力，在高质量推理数据上进行SFT，或许是对小模型更有效的策略。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0e47ed19b45f40ea9d1aba31e32b24d0@5888275_oswg161520oswg1080oswg304_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接下来一个有趣的方向是把RL+SFT和推理时扩展结合起来，OpenAI的o1很有可能是这样做的，只不过它可能基于一个比DeepSeek-R1更弱的基础模型。</p>
  <h2><strong>R1和o1相比如何？</strong></h2>
  <p>Sebastian认为，DeepSeek-R1和OpenAI o1大致在同一水平。&nbsp;</p>
  <p>不过引人注目的一点是，DeepSeek-R1在推理时间上更高效。</p>
  <p>这就揭示了二者的区别：DeepSeek可能在训练过程中投入了更多，而OpenAI更依赖于o1的推理时扩展。</p>
  <p>而很难直接比较两个模型的难点，就在于OpenAI并没有披露太多关于o1的信息。</p>
  <p>现在关于o1，还有很多未解之谜。</p>
  <p>比如，o1也是一个MoE吗？它究竟有多大？</p>
  <p>或许，o1只是GPT-4o的一个略微改进版本，加上最小量的强化学习和微调，仅在推理时进行大规模scaling？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4eeb194c75d54f749af0ad10494c1a25@5888275_oswg64875oswg1080oswg217_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不了解这些细节，是很难直接比较的。</p>
  <h2><strong>预算只有几十万美元，能开发推理模型吗</strong></h2>
  <p>不过，想开发一个DeepSeek-R1这样的推理模型，哪怕是基于开放权重的基础模型，也可能需要几十万美元甚至更多资金。&nbsp;</p>
  <p>这对预算有限的研究人员或工程师来说，实在是望而却步。</p>
  <p>好消息是：蒸馏能开辟新路径！</p>
  <p>模型蒸馏提供了一个更具成本效益的替代方案。</p>
  <p>DeepSeek团队的R1蒸馏模型证明了这一点，尽管这些模型比DeepSeek-R1小得多，推理表现却强得惊人。</p>
  <p>不过，这种方法也不是完全没有成本。他们的蒸馏过程用了80万条SFT样本，这需要大量的计算资源。</p>
  <p>有趣的是，就在DeepSeek-R1发布的前几天，关于Sky-T1的文章中，一个团队用1.7万条SFT样本，就训练出了一个32B参数的开放权重模型。</p>
  <p>总成本仅有450美元，甚至比大多数人AI会议的注册费还低。</p>
  <p>Sky-T1的表现和o1大致相当，考虑到它的训练成本，着实令人惊叹。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_91a6dde7299f453fada01720ef6e0e90@5888275_oswg139899oswg1080oswg451_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">项目链接：https://novasky-ai.github.io/posts/sky-t1/</p>
  <h3><strong>预算有限的纯强化学习：TinyZero</strong></h3>
  <p>TinyZero是3B参数的模型，它借鉴了DeepSeek-R1-Zero的方法，其训练成本不到30美元。</p>
  <p>令人意外的是，尽管只有3B参数，TinyZero仍展现出一些突现的自我验证能力，这证明了小模型通过纯RL也能产生推理能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_92dea5f6ffb648b7a16ccfb9c4a38f3d@5888275_oswg593621oswg1080oswg664_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这两个项目表明，即使预算有限，也可以进行有趣的推理模型研究。</p>
  <p>两者都借鉴了DeepSeek-R1的方法，一种聚焦于纯RL（TinyZero），另一种聚焦于纯SFT（Sky-T1）。</p>
  <h3><strong>超越传统SFT：旅程学习</strong></h3>
  <p>旅程学习被视作捷径学习的替代方案。捷径学习是传统的指令微调方法，模型仅通过正确的解题路径来训练。</p>
  <p>旅程学习不仅包括正确的解题路径，还包括错误的解题路径，让模型从错误中学习。</p>
  <p>这种方法和TinyZero在纯RL训练中展现的自我验证能力有相通之处，不过它完全依靠SFT来优化模型。让模型接触错误推理路径及修正过程。</p>
  <p>旅程学习或许有助于加强自我纠错能力，提升推理模型的可靠性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e8ee1b12653c454386ba6bf5c94b1afd@5888275_oswg215255oswg1080oswg524_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文链接：https://arxiv.org/abs/2410.18982</p>
  <p>这一方向对于未来的研究极具吸引力，特别是在低预算的推理模型开发场景中，RL方法可能由于计算成本过高而难以落地。</p>
  <p>当前在推理模型领域正有诸多有趣的研究，Sebastian充满期待地表示：相信在未来几个月，还会看到更多令人兴奋的成果！</p>
  <p>参考资料：&nbsp;</p>
  <p>https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&nbsp;</p>
  <p>https://www.tanishq.ai/blog/posts/deepseek-delusions.html&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/RpkiXldGPnoR6GJaujYbgg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156464642382600</id>
            <title>从CES到春晚舞台 京东热卖的智能机器人都有哪些黑科技？</title>
            <link>https://www.36kr.com/p/3156464642382600</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156464642382600</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:42:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人形机器人, 智能产品, 消费者需求, AI技术  
<br><br>  
总结: 2025年，京东通过“人机数码3C BOT奇遇季”活动，展示了多款人形机器人和智能产品，满足消费者在生活、工作和学习中的需求。活动期间，京东与多家科技品牌合作，推出了教育陪伴、安全守护和效率提升等功能的机器人，帮助消费者解决实际问题。此外，京东还提供了AI相关图书，帮助消费者了解机器人技术。未来，京东将继续关注用户需求，深化与机器人品牌的合作，推出更多智能产品。 </div>
                        <hr>
                    
                    <p>从CES 2025的热门焦点，到春晚舞台C位，再到跳起《APT》、成为火遍全网的表情包，2025年的开年阶段，包括宇树科技等品牌在内的人形机器人彻底出圈。京东同步开启了“人机数码3C BOT奇遇季”活动，携手前沿科技品牌带来了诸多智能机器人产品，可满足消费者生活、工作、学习等诸多场景中的使用需求，消费者打开京东搜“3C数码机器人”或“春晚同品牌机器人”即可进入活动会场浏览下单。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_25b0a83c93da4016ae39107b5c0e576d@1267484143_oswg272545oswg456oswg367_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>京东一早便关注到机器人的广泛应用场景，并提前布局，陆续引入了包括宇树科技、蔚蓝科技、时空壶、云深处等品牌在内的多款机器人产品。值得一提的是，在CES 2025期间，京东采销曾深入展会现场，与宇树科技的Unitree G1、Unitree H两款人形机器人，元萝卜的AI下棋机器人，云深处科技的绝影X30 Pro、Lite 3两款智能四足仿生机器人等深度互动，为消费者展现了智能机器人各种令人震撼的灵活表现，并第一时间将智能机器人新品上线，为用户带来全新的科技体验。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1d011b5968794edd8813c51bac19a418@1267484143_oswg980715oswg1175oswg880_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p>如今智能机器人都有哪些种类，它们分别都具备何种功能呢？本次京东上线的人机数码3C BOT奇遇季活动，不仅汇聚了海量智能机器人产品，也针对许多消费者的疑问进行了详细科普。其中，教育陪伴机器人能根据孩子的学习进度和兴趣推荐适合的学习内容，激发孩子学习兴趣；安全守护机器人可以充当家庭的安全卫士，通过摄像头进行远程监控，让消费者随时随地了解家中的安全情况；效率提升机器人可以自动完成拖地、擦窗、烹饪、用户指引等多种工作，让消费者能从这些工作中脱离出来，更高效地完成生活工作目标。</p>
  <p>对于不了解机器人产品的消费者，京东还上线了学习AI专区，提供了多种多样AI相关的图书产品，帮助消费者解锁AI机器人从入门操作到核心技术的完整知识链。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5c60b70a3315428da337fada0b4883b9@1267484143_oswg450564oswg990oswg436_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>具体到产品层面，宇树Go2-Pro长续航机器狗在GPT大模型加持和大规模的AI模拟训练基础上，能帮助孩子在人文历史、算术猜谜、知识问答等多种方面有所成长，简单易上手的图形化编程功能还能率先开发孩子的创新意识。在此前京东3C数码采销直播间“神奇红马甲探展CES”72小时不间断直播中，消费者跟着京东采销，云观看到了Go2机器人上下楼梯、跳跃、倒立等高难度动作展现，不少消费者在直播间留言感叹“太神奇了”。此外，蔚蓝阿尔法机器狗、大疆DJI机甲大师、可立宝Loona机器狗等多款产品也在教育陪伴方面有着出色表现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6b9020bbb23247369fb8df9b6b4b33b7@1267484143_oswg238986oswg472oswg910_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>随着消费需求愈加多元化，如今消费者对安全守护的需求覆盖了宠物、儿童、老人等多个群体，活动会场中的enabot一诺宠物陪伴机、PICKFUNAI看宠小助手、星空大白AI定制机器人、enabot EBO SE全屋移动监控摄像头、萤石RK2Pro智能机器人等产品能满足消费者对于儿童、老人、宠物的看护需求，更精准地实现安全守护。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e0558bacf6c44aa2b9fd1afd3015e248@1267484143_oswg361349oswg514oswg975_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>在效率提升方面，科梦奇迎宾讲解接待机器人、欧克森全自动双向喷水擦窗机器人、添可智能料理机、乐天派智能桌面机器人、科沃斯擦窗机器人、广库全自动写字机器人能帮助消费者完成客户或用户接待、日常家务、烹饪、撰写材料等基础工作，让消费者能以更高的效率投入更重要的工作中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_412900040a43417f851fb2563c6ebe7d@1267484143_oswg348657oswg576oswg1101_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>除上述新款智能机器人外，消费者还可在京东购买《AI时代：弯道超车新思维》、《奇点更近》等AI相关图书产品，更深入地了解AI机器人科学原理和知识链路，从机器人小白成为机器人高手。</p>
  <p>从CES 2025京东采销探展，再到上线人机数码3C BOT奇遇季活动，京东始终关注用户的消费需求和行业的前沿发展，第一时间为消费者带来科技新品，让每位来京东的消费者都能更快尝鲜自己心仪的机器人产品。未来，京东也将持续深化与各大机器人品牌的合作，为消费者带来更多更智能、更灵活、更全能的机器人产品。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156419972660742</id>
            <title>大厂“拥抱”Deepseek，打不过就加入？</title>
            <link>https://www.36kr.com/p/3156419972660742</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156419972660742</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:22:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, Deepseek, 开源, 技术创新  
<br><br>  
总结: 文章讨论了人工智能在春节期间成为社交热点，特别是Deepseek的崛起。Deepseek以低成本和高性能颠覆了传统大模型行业，吸引了国内外科技巨头的关注。其开源策略和创新的模型训练方法使其在技术上取得了显著突破，成为行业的“变量”。尽管面临安全性和政策争议，Deepseek的出现为大模型行业带来了新的机遇和挑战，推动了整个生态的发展。 </div>
                        <hr>
                    
                    <p>这个春节，人工智能无疑成为了社交话题的C位，前有人形机器人在春晚跳扭秧歌而出圈，后有“Deepseek”的强势崛起。</p>
  <p>网友们疯狂涌入Deepseek，有人找Deepseek算命，有人问Deepseek怎样才能暴富，还有科技金融行业的打工人，年还没有过完，就得忙着加班写研报、测试模型。</p>
  <p>但海外市场对此却态度微妙，OpenAI一度宣称Deepseek“偷窃”了其“技术成果”，但一转头，微软、英伟达等大厂都宣布在自家产品中接入Deepseek，OpenAI CEO山姆·奥特曼更表示Deepseek的R1模型“令人印象深刻”。</p>
  <p>国内的互联网巨头们也没有错失这波Deepseek的热度，2月6日，有道正式宣布全面拥抱DeepSeek-R1。此外，Hi Echo、有道智云、QAnything等产品也将全面接入DeepSeek的推理能力，并于近日陆续升级。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e851d5d2e4784fdf96f8590c8e5f2166@5333136_oswg375561oswg731oswg1016_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一时之间，这场AI大模型的技术迭代，不知不觉就演变成全球科技行业的现象级事件，Deepseek也被视为引领大模型行业从“大而全”到“小而美”的全新变量。</p>
  <p>但热闹过后，Deepseek还需要回答更多的新问题，全球大模型行业该如何抓住“变革的火花”，或许才是接下来的关键。</p>
  <h2><strong>01 三大变量引爆Deepseek</strong></h2>
  <p>在普通用户看来，Deepseek是在此次中美大模型技术之争中“一战成名”，但更早之前，Deepseek便已经因为“价格便宜”而被AI圈广泛关注。</p>
  <p>去年中，国内大模型行业大打“价格战”，但第一个“挑起战火”的并非阿里、百度等大厂，而是Deepseek，彼时其新推出的DeepSeek-V2价格仅为 GPT-4-Turbo 的百分之一左右。</p>
  <p>此次“降价”也让Deepseek被冠以“AI界拼多多”之称，但相较于大厂们的“以价换市场”的惯常做法，Deepseek对于“降价”并没有太多压力，因为其降价之后也仍有利润。</p>
  <p>事实上，这才是Deepseek能够震惊全球科技界的主要原因，其能够以更低的成本换来更高的性能，颠覆了过去大模型行业依靠堆显卡、堆资本来发展AI的“Scaling law”。</p>
  <p>这是因为Deepseek的模型训练路径不同于传统通用大模型，以ChatGPT为代表的传统AI，主要采用监督微调（简称 SFT）作为大模型训练的核心环节，即通过人工标注数据进行监督训练，再结合强化学习进行优化，本质上大模型并不会思考，只是通过模仿人类思维方式来提升推理能力。</p>
  <p>但在1月底发布的Deepseek-R1-Zero却颠覆了这一规则，其对模型架构进行了全方位创新，通过单纯的强化学习（RL）训练实现推理能力。简单来说，SFT是人类生成数据，机器学习；而RL是机器生成数据，机器学习。</p>
  <p>除此以外，据每日财经新闻报道，DeepSeek创新性地同时使用了FP8、MLA（多头潜在注意力）和MoE（利用混合专家架构）三种技术。</p>
  <p>其中，相较于其他模型使用的MoE架构，DeepSeek-V3的更为精简有效，其就像是医院的“分诊制度”，可以将大模型拆分成多个“专家”，训练时分工协作，推理时根据任务分配给最适合的专家模块。据悉，Deepseek能够将无效训练从传统模型的90%降低至60%。</p>
  <p>在Deepseek-R1发布后，一位Meta员工在美国匿名职场社区teamblind上留言，称Deepseek最近的一系列动作让Meta的生成式AI团队陷入了恐慌。</p>
  <p>据这位员工爆料，“Meta一个负责AI项目的高管年薪拿出来，就足够训练Deepseek了”。据每日经济新闻报道，Deepseek R1的预训练费用只有557.6万美元，还不到OpenAI GPT-4o模型训练成本的十分之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8d92248ee8bc4fba9fc0d2f15654d91f@5333136_oswg268894oswg1108oswg838_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但从实际性能来看，Deepseek-R1已经能够比肩OpenAI-o1正式版，特别是在数学、代码、自然语言推理等任务上。</p>
  <p>在美国数学竞赛（AMC）以及全球顶级编程竞赛（codeforces）等权威评测中，DeepSeek-R1-Lite-Preview 模型已经大幅超越了 GPT-4o 等顶尖模型，有三项成绩还领先于 OpenAI o1-preview。</p>
  <p>除了“低成本、高算力”这一突破之外，Deepseek之所以在这个春节“燃起来”，还因为其竟然不是出自传统的大厂，而是一家量化基金公司。</p>
  <p>Deepseek成立于2023年12月，在此之前，其创始人梁文锋于2015年便成立了名为“幻方量化”的量化对冲基金，可以说Deepseek的前身其实是服务于量化交易的。</p>
  <p>这样的背景也为Deepseek增添了更多“看点”，比如梁文锋之所以不差钱，是因为其在量化交易上赚得风生水起，网友甚至戏称Deepseek的训练成本是来自于造空英伟达。</p>
  <p>还有背靠千亿量化基金的梁文锋，明明可以选择轻松躺赚，却选择投身到全球创新的浪潮里，他坦言“对AGI的好奇与探索比商业回报更具驱动力”，这种一往无前的“理想主义”，想让也让Deepseek的“故事”变得更加动人。</p>
  <h2><strong>02 大厂打不过就加入</strong></h2>
  <p>不过，技术上的逆袭，尚不足以彻底震惊科技界，真正引爆Deepseek的变量，其实是“开源”。据悉，Deepseek已经把模型架构和参数开源，在大模型公司普遍选择闭源的当下，训练数据的开源在业界少有先例。</p>
  <p>梁文锋曾在媒体采访中表示，“过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。我们的出发点不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。”</p>
  <p>从商业角度来看，“开源”是不是一个更佳的策略，尚难以下定论。毕竟训练模型需要成本，招揽用户也需要推广费用，从此前字节豆包大规模投放广告、kimi多次接受融资就可以看出，大模型公司有自己的难处。</p>
  <p>但对于中国大模型行业来说，或许正是梁文锋的“理想主义”，才让Deepseek能够成为颠覆行业格局的“变量”。</p>
  <p>一方面，开源将能吸引更多大厂和技术人才加入，通过共建共创让Deepseek变得更加强大，从而推动整个人工智能大模型生态的发展，形成一个全新的生态。</p>
  <p>梁文锋曾对媒体表示，公司未来不会像OpenAI一样选择从开源走向闭源，“我们认为先有一个强大的技术生态更重要” 。</p>
  <p>另一方面，对于以OpenAI为代表的竞争对手来说，这也是一个致命的打击。毕竟，当一个旗鼓相当的，还是免费的产品出现在消费者面前，大家难免就会进行比较，谁的性价比更高，谁的性能更优秀，都需要实打实的使用效果来验证，而不仅仅只是“吹泡沫”。</p>
  <p>而率先作出选择的，便是一众海外大厂，目前包括英伟达、英特尔、亚马逊、微软、AMD、等海外科技大厂，均宣布在自家产品中接入Deepseek。</p>
  <p>值得一提的是，欧美多国对于Deepseek的安全性、隐私问题依然存在质疑。美国多位官员表示正在对Deepseek开展国家安全调查，包括国防部、国会和NASA等部门均被要求禁用Deepseek。</p>
  <p>此外，据彭博社等媒体报道，微软还曾调查 OpenAI 技术输出的数据是否被中国的Deepseek团队以未经授权的方式获取，比如通过“蒸馏技术”非法获取其模型输出数据。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_881bc69f6d574b33ad204879ab0839cc@5333136_oswg280855oswg1108oswg1128_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但在这些争议尚未解决之前，大厂们显然已经迫不及待想要加入Deepseek生态，本质上还是基于“利益至上”的原则。</p>
  <p>据斯坦福大学计算机科学系和电子工程系副教授吴恩达表示，OpenAI - o1模型每百万输出token 的成本为60美元，而Deepseek-R1 则仅需 2.19 美元，这接近30倍的成本差距，相信大厂们也会算账。</p>
  <p>其次则是生态效应，吴恩达认为，“降价”+“开源”正在将基础模型层商品化，为应用开发者创造了巨大的机遇。尽早加入这一生态，让自家大模型与之相结合，也有望带来更多创新体验，“收拢”部分DeepSeek用户的需求。</p>
  <p>因此，除了海外大厂之外，诸如阿里云、百度云等国内大厂也开始集中接入Deepseek，在各自平台提供的适配服务，打不过就加入，才能共享创新红利。</p>
  <h2><strong>03 乘上Deepseek的东风</strong></h2>
  <p>事实上，在开春爆火的Deepseek，不仅为大模型行业带来了一阵“春风”，对于普通用户来说，也带来了更多新机会。</p>
  <p>第一批利用Deepseek搞钱的人已经出现了，跟彼时横空出世的ChatGPT一样，面对更加智能、更加高效的大模型，AI取代人类的焦虑感，再次成为收割用户的“武器”。</p>
  <p>社交平台上已经出现了不少“如何使用Deepseek进行XXX”的课程，面向社交媒体、电商、广告等不同行业的应用和变现。</p>
  <p>当然，学习新知识肯定是没错的，但相较于被焦虑感“收割”，并沦为大V私域流量中的一员，大家不妨根据自己的实际工作和擅长内容，先上手试用一下Deepseek。</p>
  <p>目前来看，Deepseek在技术上确实有意想不到的突破，对于普通用户来说，其能够展示思维链全过程，更方便人类与AI交流，业内人士甚至称之为当前最好用的开源模型，但也不需要过度“神化”Deepseek。</p>
  <p>首先，从使用体验来看，Deepseek尚无法承受蜂拥而至的流量。其实，Deepseek在年前便已经小范围的“爆火”，其当时尚能同时使用深度思考和联网功能，输出的文章框架和成文确实比较惊艳。</p>
  <p>但随着使用者不断增多，目前Deepseek已经关闭了联网功能，整理输出质量有较大的下降，且大部分时间Deepseek都呈现“服务繁忙”的状态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b1c84842499e49c093f6dc24b96b62d4@5333136_oswg92743oswg1108oswg768_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>虽然梁文锋曾表示“商业化”不是当前首要考虑的问题，但按私募基金的体量来推算“幻方”的资金规模，千亿规模不等于千亿资金体量，“幻方”只是在千亿规模上收取管理费，其跟大厂之间的资金差距还是很大的。</p>
  <p>但要继续维持C端的使用体验，Deepseek必然需要烧钱，后续如何补充资金，还是调整使用模式，梁文锋都需要提出更明确的打法。</p>
  <p>其次，目前Deepseek在图文、视频方面的能力是缺失的，现阶段要说Deepseek能够与头部闭源模型直接打擂台，恐怕还为时尚早。</p>
  <p>不过，其发展也给Open AI，以及更多垂直模型带来了压力，相信将能在一定程度上推动整个大模型生态的发展。</p>
  <p>最后，Deepseek依然面临着政策、数据安全等争议，要走向全球依然是漫漫长路；此外，其在计算资源与算力方面依然受限，这意味着国产硬件还需要继续努力，才能支撑软件的不断创新。</p>
  <p>当然，对于全球大模型行业来说，有竞争才有动力，就像智能手机行业一样，参与者多了，行业盘子就会越来越多，也才有机会爆发出更多的机会。</p>
  <p>Deepseek的出现就像是国内大模型行业的一点“火花”，既是思维碰撞的突破，也是灵感乍现的瞬间。接下来，相信还需要国内大模型行业在软硬件方面的持续创新，才能抓住这一机遇，让中国科技行业能够从“跟随者”向“引领者”进发。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/EKAaKXY2oPJ-cqnDUuNGNg" rel="noopener noreferrer nofollow" target="_blank">“新媒科技评论”</a>，作者：新媒编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156289666964231</id>
            <title>DeepSeek 在人工智能全球化战略下需要面对的几个难题</title>
            <link>https://www.36kr.com/p/3156289666964231</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156289666964231</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:21:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据隐私, 地缘政治, 市场信任, 可持续性  
<br><br>  
总结: DeepSeek自2024年底以来成为生成式人工智能的焦点，但面临多重挑战。首先，数据隐私问题可能影响其国际客户的信任，尤其是在严格的法律环境中。其次，地缘政治紧张局势可能限制其获取资源和市场扩展。市场认知方面，DeepSeek需克服低成本模式带来的信任问题。长期维持低价的可持续性也存在风险，可能影响其研发和服务质量。此外，竞争激烈的市场环境和复杂的监管框架也给DeepSeek带来压力。 </div>
                        <hr>
                    
                    <p>自 2024 年底以来，DeepSeek 已成为生成式人工智能的焦点，并发布了迄今为止最出色的两个模型 DeepSeek-V3 和 DeepSeek-R1。OpenAI 作为生成式人工智能的代表，已退居谷歌、Facebook 等其他巨头的后方。</p>
  <p>但我认为 DeepSeek应考虑应对以下问题实现全球化战略：</p>
  <h2><strong>数据隐私问题</strong></h2>
  <p>DeepSeek 是一家中国公司，在数据隐私方面可能会面临越来越多的质疑，尤其是在处理敏感信息时。对用户数据如何处理、存储以及可能与政府实体共享的担忧可能会阻碍国际客户。</p>
  <p>在数据隐私法严格的地区，例如欧盟（GDPR）或美国，DeepSeek 可能会在确保合规性方面遇到挑战。</p>
  <p>如果客户认为他们的数据可能被未经授权的一方或政府访问，他们可能会选择避免使用 DeepSeek 的服务，从而限制其市场范围。</p>
  <h2><strong>地缘政治问题</strong></h2>
  <p>DeepSeek 的运营<strong>环境对地缘政治极为敏感。</strong>由于中国与美国和欧盟等其他主要科技市场之间的紧张关系持续存在，DeepSeek 的运营可能会受到贸易限制、关税或制裁的阻碍。</p>
  <p>例如，如果美国或欧盟实施限制获取先进计算硬件的法规，或限制关键技术的出口，DeepSeek 可能难以获取扩大业务规模所需的资源。</p>
  <p>此外，各国可能会基于国家安全考虑阻止或监管 DeepSeek 服务的使用，从而影响其全球扩张的能力。</p>
  <h2><strong>市场认知和信任</strong></h2>
  <p>尽管 DeepSeek 提供具有成本效益的解决方案，但它可能难以获得与 OpenAI 和 Google 等更成熟的公司同等程度的信任。潜在客户可能会对提供明显更便宜服务的公司持怀疑态度，认为其质量可能较低或可靠性较低。</p>
  <p>打造强大的品牌并赢得客户信任可能会很困难，特别是如果 DeepSeek 被视为“低预算”选择而不是创新领导者的话。</p>
  <h2><strong>低成本模式的可持续性</strong></h2>
  <p>DeepSeek 的商业模式大大削弱了 OpenAI 等竞争对手，吸引了人们的注意并占据了市场份额。然而，<strong>长期维持如此低的价格可能具有挑战性。</strong></p>
  <p>开发、维护和改进 AI 模型的成本非常高昂，需要对研究、人才和计算资源进行投资。<strong>为了保持低价，DeepSeek 需要不断寻找降低成本的方法，</strong>但随着公司规模的扩大，这种方法可能难以为继。</p>
  <p><strong>另外，其低成本模式还</strong>存在无法产生足够收入来资助进一步发展的风险，这可能迫使 DeepSeek 提高价格或降低服务质量以保持盈利。</p>
  <p>如果竞争对手已经拥有更强大的财力支持，在产品供应方面表现出色或设法降低成本，那么 DeepSeek 可能难以参与竞争。</p>
  <h2><strong>竞争市场动态</strong></h2>
  <p>人工智能领域挤满了主要参与者，包括 OpenAI、Google DeepMind 和 Microsoft。随着越来越多的公司进入生成式人工智能领域，DeepSeek 可能会发现很难脱颖而出或保持竞争优势。</p>
  <p>虽然 DeepSeek 最初凭借低成本定价策略取得了成功，但许多 AI 公司正在大力投资研发和云基础设施。这些竞争对手在模型准确率和功能集方面都可能超越 DeepSeek。</p>
  <p>如果 DeepSeek 未能跟上创新的步伐，或者无法找到大幅扩展其技术的方法，其市场份额可能会被更大、更成熟的公司抢走。</p>
  <h2><strong>监管挑战：</strong></h2>
  <p>在多个国家开展业务需要遵守各种复杂的监管框架。特别是，人工智能是一个受到严格审查的行业，其公平性、透明度和问责制备受关注。</p>
  <p>在某些司法管辖区，规范人工智能部署的新法律（例如欧盟的《人工智能法案》）可能会迫使 DeepSeek 修改或限制其产品，从而使得在遵守这些法规的同时保持有竞争力的价格变得更加困难。</p>
  <h2><strong>缺乏多样化</strong></h2>
  <p>DeepSeek 专注于提供低成本的 AI 解决方案，这可能会限制其收入来源多元化的能力。该公司可能会过度依赖某个细分市场（例如，生成式 AI 服务），而错失其他领域的增长机会。</p>
  <p>如果对生成式人工智能的需求放缓或面临竞争加剧，DeepSeek 可能会因缺乏明确的多元化计划而陷入困境。</p>
  <h2><strong>可扩展性问题</strong></h2>
  <p>尽管 DeepSeek 已经开发出高效的模型，但将其扩展到更广泛的企业级应用可能会带来挑战。AI 模型需要强大的计算能力才能大规模运行，而 DeepSeek 在服务大型客户或处理复杂的实时数据时可能难以保持成本效益。</p>
  <p>如果 DeepSeek 无法在不产生难以承受的成本的情况下有效扩展其基础设施，其业务可能会面临巨大的财务压力。</p>
  <h2><strong>免费的可持续</strong></h2>
  <p>大多数中国人工智能产品/模型，无论是 Kling AI 还是 MiniMax，都是开始免费提供服务，然后收取高额费用。</p>
  <p>因此看起来 DeepSeek 可能走上了同一条道路，因为在消费者甚至企业硬件上运行 DeepSeek-V3 和 Deep-Seek-R1 是不可能的。</p>
  <p>因此，即使开源，对大多数 AI 供应商来说也可能没有多大用处，而且 DeepSeek 可能很快就会增加 API 成本。</p>
  <h2><strong>最后</strong></h2>
  <p>虽然 DeepSeek 在生成式人工智能领域确实掀起了波澜，但其长期可持续性仍是一个问题。地缘政治紧张局势、监管障碍和不可持续的低成本模式可能会严重挑战其增长轨迹。再加上建立信任、扩展基础设施和与老牌科技巨头竞争的复杂性，很明显 DeepSeek 未来面临着重大障碍。然而，这些只是我的观点，而且考虑到目前的情况，DeepSeek 应尽快加强应对措施的制定。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzIwOTIyMDE1NA==&amp;mid=2247502236&amp;idx=1&amp;sn=89e5f882fceca7a506809d2f5c49324a&amp;chksm=966f9f55b7e41de96ddabd81b81d5f15cc07599d60114ebdf64af35bc790f88e42689be099eb&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“数据驱动智能”（ID：Data_0101）</a>，作者：晓晓，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156393016842758</id>
            <title>DeepSeek引爆AI，国产GPU集体撑腰</title>
            <link>https://www.36kr.com/p/3156393016842758</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156393016842758</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:12:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, 人工智能, 开源模型, 国产芯片  
<br><br>  
总结: DeepSeek是一家专注于高性能、低成本AI模型的公司，其最新发布的DeepSeek-V3和DeepSeek-R1模型在AI领域引起了广泛关注。DeepSeek-V3采用6710亿参数的MoE架构，处理速度是前一版本的三倍，而DeepSeek-R1则适合轻量级部署。DeepSeek的优势在于其低成本和高效能，训练成本仅为GPT-4的二十分之一，同时支持开源和灵活部署，促进了技术共享。随着DeepSeek的成功，国产芯片公司也迎来了新的发展机遇，推动了国产AI芯片的市场应用和生态建设。 </div>
                        <hr>
                    
                    <p>近日，想必诸多用户都怀揣着这样的疑惑：我的手机为何频频推送关于DeepSeek的资讯？这 DeepSeek 究竟是什么？它又为何能在问世之际，就引发如此热烈的关注与轰动？</p>
  <p>DeepSeek，全称杭州深度求索人工智能基础技术研究有限公司，其起源于一家中国的对冲基金公司High-Flyer。2023年5月High-Flyer剥离出一个独立实体，也就是DeepSeek。这是一家致力于打造高性能、低成本的 AI 模型。它的目标是让 AI 技术更加普惠，让更多人能够用上强大的 AI 工具。</p>
  <h2><strong>DeepSeek-V3与DeepSeek-R1的核心差异</strong></h2>
  <p>去年12月26日，DeepSeek AI正式发布了其最新的大型语言模型DeepSeek-V3。这款开源模型采用了高达6710亿参数的MoE架构，每秒能够处理60个token，比V2快了3倍。一经发布，就在 AI 领域引起了轩然大波。</p>
  <p>时隔不足一个月，在今年1月20日，深度求索又正式发布推理大模型DeepSeek-R1。DeepSeek-R1的发布，再次震撼业界！</p>
  <p>1月27日，DeepSeek应用登顶苹果中国区和美国区应用商店免费App下载排行榜。1月31日，英伟达、亚马逊和微软这三家美国科技巨头，在同一天宣布接入DeepSeek-R1。</p>
  <p>关于DeepSeek-V3与DeepSeek-R1-Distill 蒸馏模型的区别：</p>
  <p><strong>DeepSeek-V3</strong></p>
  <p>适合复杂任务处理和高精度场景，如长文档分析、多模态推理、科研计算等。</p>
  <p>支持千卡级训练，满足超大规模集群分布式训练需求。</p>
  <p><strong>DeepSeek-R1-Distill 蒸馏模型</strong></p>
  <p>适合轻量级部署和资源受限场景，如边缘设备推理、中小企业快速验证 AI 应用。</p>
  <p>在显存和算力要求上更为灵活，适配入门级硬件 。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6be9495964914ca19ec7bd82c9894a35@000000_oswg88780oswg1080oswg430_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：Gitee AI</p>
  <p>近日，硅谷顶尖风险投资家、a16Z联合创始人Marc Andreessen发文引用SensorTower数据：目前DeepSeek日活用户数已经达到了ChatGPT的23%，并且应用每日下载量接近500万。</p>
  <p>2月5日，京东云宣布正式上线DeepSeek-R1和DeepSeek-V3模型，支持公有云在线部署、专混私有化实例部署两种模式。前几日，阿里云、百度智能云、华为云、腾讯云、火山引擎、天翼云已接入了DeepSeek模型。海外的亚马逊AWS、微软Azure等云巨头同样官宣支持。</p>
  <p>那么，DeepSeek究竟是以何种独特魅力，赢得了广大用户的青睐与喜爱呢？</p>
  <h2><strong>DeepSeek的两大优势</strong></h2>
  <p>市场热捧的产品，往往有个显著共性：能帮用户降本增效。这，同样是 DeepSeek 的优势所在。</p>
  <p><strong>首先在低成本与高效能方面</strong>，DeepSeek-V3的训练成本仅为557.6万美元（约为GPT-4的二十分之一），却能在逻辑推理、代码生成等任务中达到与GPT-4o、Claude-3.5-Sonnet相近的性能，甚至超越部分开源模型（如Llama-3.1-405B）。其技术核心在于算法优化（如MoE架构、动态学习率调度器）和数据效率提升，而非依赖算力堆叠。</p>
  <p>作为对比，GPT-5一次为期6个月的训练仅计算成本就高达约5亿美元。</p>
  <p><strong>其次，开源与灵活部署也是DeepSeek的突出优势之一。</strong>DeepSeek选择将模型权重开源，并公开训练细节，这为全球的AI研究者打开了一扇通往模型内部的大门，让他们能够深入了解模型的训练过程、所采用的算法以及遇到的问题和解决方案。</p>
  <p>360集团创始人周鸿祎指出，DeepSeek真正践行了开放的精神。与OpenAI等关闭模式平台相比，DeepSeek允许开发者利用其开源模型进行技术挖掘和创新，这是对技术共享理念的有力支持。OpenAI虽然以“开源”自居，但随着商业化的推进，越来越多地选择封闭式策略，这与其创立初衷背道而驰。</p>
  <p>此外，周鸿祎特别提到DeepSeek的模型蒸馏技术，他认为这是一种极具前瞻性的实践。在他看来，DeepSeek对模型蒸馏的开放态度，展示了其自信与无私。相较之下，OpenAI对用户蒸馏其模型的限制，显示出其对竞争对手的排斥和对自身优势的维护。</p>
  <h2><strong>DeepSeek所需的GPU，主要来源于英伟达</strong></h2>
  <p>早期对AI技术和硬件基础设施的战略投资，为DeepSeek的成功奠定了基础。</p>
  <p>据SemiAnalysis评估，DeepSeek拥有大约50,000个Hopper架构的GPU，其中包括10,000个H800和10,000个H100型号。此外，他们还订购了大量的H20型号GPU，这些GPU专为中国市场设计。尽管H800与H100具有相同的计算能力，但其网络带宽较低。H20是当前唯一对中国模型提供商可用的型号。这些GPU不仅用于DeepSeek，也服务于High-Flyer，地理上分散部署，支持交易、推理、训练和研究等多种任务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_10f38e4a222e48b9ae928b07e84b7282@000000_oswg249918oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>至于DeepSeek如何获得如此多数量的Hopper GPU。</p>
  <p>早在2021年High-Flyer就看好AI的发展潜力并果断投资购买了10,000个A100 GPU，用于大规模模型训练实验。这项战略决策后来被证明是非常成功的，为公司带来了显著的竞争优势。</p>
  <p>在1月25日新年前，AMD就官宣将DeepSeek-V3模型集成到了Instinct MI300X GPU上。</p>
  <p>随后在1月31日，AI芯片龙头英伟达也官宣其NVIDIA NIM微服务预览版对于DeepSeek-R1模型的支持。NIM微服务基于HGX H200系统，每秒能够处理3872个tokens。开发者们可以调用API进行测试和试验，该API后续会作为英伟达AI企业软件平台的一部分提供。</p>
  <p>同日，英特尔宣布DeepSeek能够在搭载酷睿处理器的AI PC上离线使用。在酷睿Ultra 200H（Arrow Lake H）平台上，DeepSeek-R1-1.5B模型能够本地离线运行，做翻译、做会议纪要、进行文档撰写等任务。</p>
  <p><strong>要知道DeepSeek 在算力芯片受限的不利因素下，达到OpenAI等顶级模型的水平，是国内AI生态级的突破。</strong>如今，随着 DeepSeek 这类模型的发展，对 GPU 需求持续攀升。国产 GPU 厂商也敏锐捕捉到这一机遇，正在积极进行适配工作。他们深知，适配成功不仅能助力 DeepSeek 等模型更好地发展，也能为自身打开更广阔的市场空间，提升国产 GPU 在 AI 领域的影响力。</p>
  <h2><strong>11大国产AI芯片公司，宣布适配DeepSeek</strong></h2>
  <p>仅在2月1日至2月7日这短短7天内，就有11家国产AI芯片公司宣布完成对 DeepSeek 的适配 。</p>
  <h3><strong>DeepSeek系列新模型正式上线昇腾社区</strong></h3>
  <p>2月1日，华为云宣布与硅基流动联合首发并上线基于华为云昇腾云服务的DeepSeek R1/V3推理服务。得益于自研推理加速引擎加持，该服务支持部署的DeepSeek模型可获得持平全球高端GPU部署模型的效果。</p>
  <p>2月5日，华为宣布，DeepSeek-R1、DeepSeek-V3、DeepSeek-V2、Janus-Pro于2月4日正式上线昇腾社区，支持一键获取DeepSeek系列模型，支持昇腾硬件平台上开箱即用，推理快速部署，带来更快、更高效、更便捷的AI开发和应用体验。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4335f38cdb9940459734d1912fe0c9ef@000000_oswg200014oswg830oswg564_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>摩尔线程实现对DeepSeek蒸馏模型推理服务的高效部署</strong></h3>
  <p>2月4日，摩尔线程发文称已快速实现对DeepSeek蒸馏模型推理服务的高效部署，旨在赋能更多开发者基于摩尔线程全功能GPU进行AI应用创新。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ba007f382df54daeb38e1286b566087d@000000_oswg239003oswg866oswg474_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，用户也可以基于MTT S80和MTT S4000进行DeepSeek-R1蒸馏模型的推理部署。</p>
  <p>通过DeepSeek提供的蒸馏模型，能够将大规模模型的能力迁移至更小、更高效的版本，在国产GPU上实现高性能推理。摩尔线程基于自研全功能GPU，通过开源与自研双引擎方案，快速实现了对DeepSeek蒸馏模型的推理服务部署，为用户和社区提供高质量服务。</p>
  <h3><strong>DeepSeek V3和R1模型完成海光DCU适配并正式上线</strong></h3>
  <p>2月4日晚间，海光信息宣布公司技术团队成功完成DeepSeek V3和R1模型与海光DCU（深度计算单元）的适配，并正式上线。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a6740696b09344418900b42258196c28@000000_oswg306384oswg875oswg1278_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepSeek V3和R1模型采用了Multi-Head Latent Attention（MLA）、DeepSeekMoE、多令牌预测、FP8混合精度训练等创新技术，显著提升了模型的训练效率和推理性能。</p>
  <p>DCU是海光信息推出的高性能GPGPU架构AI加速卡，致力于为行业客户提供自主可控的全精度通用AI加速计算解决方案。凭借卓越的算力性能和完备的软件生态，DCU已在科教、金融、医疗、政务、智算中心等多个领域实现规模化应用。</p>
  <p>随着海光等专注于 GPU 研发的公司纷纷表示已完成对 DeepSeek V3 的适配。从这一现象来看，DeepSeek 模型在业界或许正逐渐获得较高的认可度与通用性。</p>
  <p>那么，<strong>海光 DCU 的哪些硬件特性和架构设计使得它能够很好地支持 DeepSeek V3 和 R1 模型的高效运行？</strong></p>
  <p>有业内人士表示，海光DCU采用了GPGPU架构，从而保证在面对新型应用的时候具备极好的兼容性与适配性；同时DCU配套的软件栈也经过了多年的积累，相应软件生态成熟丰富，在与新模型、应用适配的时候具备完备的软件支撑能力。以上共同保障了对于DeepSeek V3/R1为代表的新模型能够提供高效的兼容与支撑能力。</p>
  <p>值得注意的是，海光本次适配并没有用到额外的中间层工具，依托现有DCU软件栈就可以实现快速的支撑。这主要得益于DCU的GPGPU架构通用性和自身对主流生态的良好兼容，从而大幅提升了大模型等人工智能应用的部署效率。</p>
  <h3><strong>天数智芯联合Gitee AI正式上线DeepSeek R1模型服务</strong></h3>
  <p>2月4日，天数智芯与 Gitee AI 联合发布消息，在双方的高效协作下，仅用时一天，便成功完成了与 DeepSeek R1 的适配工作，并且已正式上线多款大模型服务，其中包括 DeepSeek R1-Distill-Qwen-1.5B、DeepSeek R1-Distill-Qwen-7B、DeepSeek R1-Distill-Qwen-14B等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9101192f343d406f8b6de7014dbe3c7e@000000_oswg258702oswg744oswg484_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>Gitee AI与沐曦携手首发DeepSeek R1系列千问蒸馏模型</strong></h3>
  <p>2月2日，Gitee AI 正式推出了四个轻量级版本的 DeepSeek 模型，分别为 DeepSeek-R1-Distill-Qwen-1.5B、DeepSeek-R1-Distill-Qwen-7B、DeepSeek-R1-Distill-Qwen-14B 和 DeepSeek-R1-Distill-Qwen-32B。尤为引人注目的是，这些模型均部署在国产沐曦曦云 GPU 上。</p>
  <p>上文曾提到，与全尺寸 DeepSeek 模型相比，较小尺寸的 DeepSeek 蒸馏版本模型更适合企业内部实施部署，可以降低落地成本。</p>
  <p>同时，这次Deepseek R1 模型 + 沐曦曦云 GPU + Gitee AI 平台，更是实现了从芯片到平台，从算力到模型全国产研发。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4482b73eb5614ed1bd2cff8d4c19b763@000000_oswg172576oswg1080oswg445_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随后在2月5日 Gitee AI宣布再次将DeepSeek-V3满血版（671B）上线到平台上（满血版目前仅供大家体验用途）。这也是 Gitee AI 继全套千问蒸馏模型上线沐曦 GPU 卡之后的又一大的更新。</p>
  <h3><strong>壁仞AI算力平台上线DeepSeek R1蒸馏模型推理服务，支持云端体验</strong></h3>
  <p>2月5日，壁仞科技宣布，凭借自主研发的壁砺系列GPU产品出色的兼容性能，只用数个小时，就完成对DeepSeek R1全系列蒸馏模型的支持，涵盖从1.5B到70B各等级参数版本，包括LLaMA蒸馏模型和千问蒸馏模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8865a3cee48d4f5bae14dbd29329c8eb@000000_oswg74841oswg582oswg636_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，壁仞科技已构建起从底层硬件到模型服务的完整AI技术栈，可为中小企业和研究机构提供“芯片+模型”的端到端解决方案。</p>
  <h3><strong>云天励飞DeepEdge10已完成DeepSeek R1系列模型适配</strong></h3>
  <p>2月5日，云天励飞宣布，其芯片团队完成 DeepEdge10 “算力积木”芯片平台与DeepSeek-R1-Distill-Qwen-1.5B、DeepSeek-R1-Distill-Qwen-7B、DeepSeek-R1-Distill-Llama-8B大模型的适配，可以交付客户使用。DeepSeek-R1-Distill-Qwen-32B、DeepSeek-R1-Distill-Llama-70B大模型、DeepSeek V3/R1 671B MoE大模型也在有序适配中。适配完成后，DeepEdge10芯片平台将在端、边、云全面支持DeepSeek全系列模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8fd837d8085b4fed8b5f7e5c35aaddbc@000000_oswg140562oswg1074oswg380_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_27ed50ecaeca4d0a8135f2c90a47d7e1@000000_oswg81197oswg742oswg268_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepEdge10系列芯片是专门针对大模型时代打造的芯片，支持包括 Transformer 模型、BEV 模型、CV 大模型、LLM 大模型等各类不同架构的主流模型；基于自主可控的先进国产工艺打造，采用独特的“算力积木”架构，可灵活满足不同场景对算力的需求，为大模型推理提供强大动力。</p>
  <h3><strong>基于太初T100加速卡2小时适配DeepSeek-R1系列模型</strong></h3>
  <p>2月5日，太初元碁Tecorigin表示，基于通用的异构众核芯片架构和深厚的软件生态积累，在太初T100加速卡上仅用2小时便完成DeepSeek-R1系列模型的适配工作，快速上线包括DeepSeek-R1-Distill-Qwen-7B在内的多款大模型服务，为人工智能应用的创新发展提供了强有力的技术支撑和自动可控的算力设施保障。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_73d3dd97317c45fa85ca700b6e64b9bf@000000_oswg128060oswg970oswg437_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，太初元碁正积极携手京算、是石科技、神威数智、龙芯中科等合作伙伴，全力打造DeepSeek系列模型的云端推理平台。企业用户只需通过简单的操作，即可在云端快速获取太初T100加速卡的强大推理能力，轻松实现智能化转型，提升生产效率和创新能力，以在激烈的市场竞争中脱颖而出。同时，太初元碁也联合龙芯中科提供面向政务信创的国密云端推理平台，以满足信创刚需。</p>
  <h3><strong>燧原科技实现全国各地智算中心DeepSeek的全量推理服务部署</strong></h3>
  <p>2月6日，燧原科技宣布完成对DeepSeek全量模型的高效适配，包括DeepSeek-R1/V3 671B原生模型、DeepSeek-R1-Distill-Qwen-1.5B/7B/14B/32B、DeepSeek R1-Distill-Llama-8B/70B等蒸馏模型。整个适配进程中，燧原AI加速卡的计算能力得到充分利用，能够快速处理海量数据，同时其稳定性为模型的持续优化和大规模部署提供了坚实的基础。</p>
  <p>目前，DeepSeek的全量模型已在庆阳、无锡、成都等智算中心完成了数万卡的快速部署，将为客户及合作伙伴提供高性能计算资源，提升模型推理效率，同时降低使用门槛，大幅节省硬件成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8a8f419509954303bac9c525c46c7120@000000_oswg294209oswg1080oswg516_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>昆仑芯全面适配DeepSeek</strong></h3>
  <p>2月6日，昆仑芯科技宣布，在DeepSeek-V3/R1上线不久，昆仑芯便率先完成全版本模型适配，这其中包括DeepSeek MoE 模型及其蒸馏的Llama/Qwen等小规模dense模型。</p>
  <p>昆仑芯P800可以较好的支撑DeepSeek系列MoE模型大规模训练任务，全面支持MLA、多专家并行等特性，仅需32台即可支持模型全参训练，高效完成模型持续训练和微调。</p>
  <p>P800显存规格优于同类主流GPU20%-50%，对MoE架构更加友好，且率先支持8bit推理，单机8卡即可运行 671B 模型。正因如此，昆仑芯相较同类产品更加易于部署，同时可显著降低运行成本，轻松完成DeepSeek-V3/R1全版本推理任务。</p>
  <h3><strong>龙芯处理器成功运行DeepSeek大模型</strong></h3>
  <p>2 月 7 日，龙芯中科宣布， 日前，龙芯联合太初元碁等产业伙伴，仅用 2 小时即在太初 T100 加速卡上完成 DeepSeek-R1 系列模型的适配工作，快速上线包含 DeepSeek-R1-Distill-Qwen-7B 在内的多款大模型服务。</p>
  <p>此外，采用龙芯3A6000处理器的诚迈信创电脑和望龙电脑已实现本地部署DeepSeek，部署后无需依赖云端服务器，避免了因网络波动或服务器过载导致的服务中断，可高效完成文档处理、数据分析、内容创作等多项工作，显著提升工作效率。</p>
  <h2><strong>DeepSeek给国产芯片公司，带来新契机</strong></h2>
  <p>DeepSeek 的横空出世宛如一颗投入平静湖面的石子，在行业中激起层层涟漪，为国产芯片公司带来新的发展契机。</p>
  <p><strong>首先，随着大模型应用的遍地开花，对芯片的需求也水涨船高。</strong>无论是模型训练时所需的强大算力，还是推理过程中对低延迟、高效率的追求，都为国产芯片公司打开了新的市场空间。以往，由于高昂的大模型使用成本，许多潜在的应用场景被抑制，如今 DeepSeek 打破了这一僵局，国产芯片公司得以凭借自身产品在新兴的细分市场中崭露头角，满足不同行业对于大模型运算的芯片需求。</p>
  <p><strong>其次，DeepSeek 大模型与国产 AI 芯片适配的逐步成熟，是另一个关键契机。</strong>此前，国产 AI 芯片在发展过程中，常面临与主流大模型适配度不佳的问题，这限制了其市场推广与应用拓展。而 DeepSeek 的出现改变了这一局面，它为国产 AI 芯片提供了一个更为契合的适配平台。</p>
  <p>当国产 AI 芯片能够与 DeepSeek 大模型良好适配后，可以加快国产 AI 芯片在国内大模型训练端和推理端的应用，使得国产芯片在本土市场中获得更多实践机会，通过不断优化和改进，提升产品性能。</p>
  <p><strong>最后，随着 DeepSeek 与国产芯片的适配，将与其他国产软硬件厂商形成协同效应，构建起完整的生态闭环</strong>，这将推动国产芯片在人工智能领域的应用，加速国产芯片生态体系的建设。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247788670&amp;idx=1&amp;sn=0bfe8a56872bbb9e66c0ef7f100ea3eb&amp;chksm=c0bb70d10d33a104ad87ab95da8c6d8483660a1eefe0c981fe2a494038c54d9fb2893ce2e0e6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：丰宁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156406783662855</id>
            <title>英伟达联手MIT清北发布SANA 1.5，线性扩散Transformer再刷文生图新SOTA</title>
            <link>https://www.36kr.com/p/3156406783662855</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156406783662855</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:12:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: SANA 1.5, 线性扩散Transformer, 模型扩展, 文本生成图像  
<br><br>  
总结: SANA 1.5是一种高效可扩展的线性扩散Transformer，针对文本生成图像任务提出了三项创新：高效的模型增长策略、深度剪枝和推理时扩展策略。这些创新显著降低了训练和推理成本，同时提升了生成质量。研究者通过有效的模型增长策略，保留小模型的知识，减少了60%的训练时间。深度剪枝技术实现了高效的模型压缩，而推理时扩展策略则通过重复采样提升了生成质量。实验结果表明，SANA 1.5在GenEval基准测试中达到了最先进的性能，证明了高效扩展不仅依赖于增加模型容量。 </div>
                        <hr>
                    
                    <blockquote>
   <p>SANA 1.5是一种高效可扩展的线性扩散Transformer，针对文本生成图像任务进行了三项创新：高效的模型增长策略、深度剪枝和推理时扩展策略。这些创新不仅大幅降低了训练和推理成本，还在生成质量上达到了最先进的水平。</p>
  </blockquote>
  <p>近年来，文本生成图像的技术不断突破，但随着模型规模的扩大，计算成本也随之急剧上升。</p>
  <p>为此，英伟达联合MIT、清华、北大等机构的研究人员提出了一种高效可扩展的线性扩散Transformer——SANA，在大幅降低计算需求的情况下，还能保持有竞争力的性能。</p>
  <p>SANA1.5在此基础上，聚焦了两个关键问题：</p>
  <ol>
   <li>线性扩散Transformer的可扩展性如何？</li>
   <li>在扩展大规模线性DiT时，怎样降低训练成本？</li>
  </ol>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2c1e9b502df2433d83b69e74bfa74e6c@5888275_oswg134388oswg1080oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文链接：https://arxiv.org/pdf/2501.18427</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8271efceb7894e3e83253f62e50b7e46@5888275_oswg148404oswg1080oswg566_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>SANA 1.5：高效模型扩展三大创新</strong></h2>
  <p>SANA 1.5在SANA 1.0（已被ICLR 2025接收）的基础上，有三项关键创新。</p>
  <p>首先，研究者提出了一种高效的模型增长策略，使得SANA可以从1.6B（20层）扩展到4.8B（60层）参数，同时显著减少计算资源消耗，并结合了一种节省内存的8位优化器。</p>
  <p>与传统的从头开始训练大模型不同，通过有策略地初始化额外模块，可以让大模型保留小模型的先验知识。与从头训练相比，这种方法能减少60%的训练时间。</p>
  <p>其二，引入了模型深度剪枝技术，实现了高效的模型压缩。通过识别并保留关键的块，实现高效的模型压缩，然后通过微调快速恢复模型质量，实现灵活的模型配置。</p>
  <p>其三，研究者提出了一种推理期间扩展策略，引入了重复采样策略，使得SANA在推理时通过计算而非参数扩展，使小模型也能达到大模型的生成质量。</p>
  <p>通过生成多个样本，并利用基于视觉语言模型（VLM）的选择机制，将GenEval分数从0.72提升至0.80。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fe479b5a5bf14ac0aadb3e371fea96cf@5888275_oswg225366oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与从头开始训练大模型不同，研究者首先将一个包含N个Transformer层的基础模型扩展到N+M层（在实验中，N=20，M=40），同时保留其学到的知识。</p>
  <p>在推理阶段，采用两种互补的方法，实现高效部署：</p>
  <ul>
   <li>模型深度剪枝机制：识别并保留关键的Transformer块，从而在小的微调成本下，实现灵活的模型配置。</li>
   <li>推理时扩展策略：借助重复采样和VLM引导选择，在计算资源和模型容量之间权衡。</li>
  </ul>
  <p>同时，内存高效CAME-8bit优化器让单个消费级GPU上微调十亿级别的模型成为可能。</p>
  <p>下图展示了这些组件如何在不同的计算资源预算下协同工作，实现高效扩展。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c159c61f836e42e4b34261b61092c516@5888275_oswg302617oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>模型增长</strong></h3>
  <p>研究者提出一种高效的模型增长策略，目的是对预训练的DiT模型进行扩展，把它从𝑁层增加到𝑁+𝑀层，同时保留模型已经学到的知识。</p>
  <p>研究过程中，探索了三种初始化策略，最终选定部分保留初始化方法。这是因为该方法既简单又稳定。</p>
  <p>在这个策略里，预训练的N层继续发挥特征提取的作用，而新增加的M层一开始是随机初始化，从恒等映射起步，慢慢学习优化特征表示。</p>
  <p>实验结果显示，与循环扩展和块扩展策略相比，这种部分保留初始化方法在训练时的动态表现最为稳定。</p>
  <h3><strong>模型剪枝</strong></h3>
  <p>本文提出了一种模型深度剪枝方法，能高效地将大模型压缩成各种较小的配置，同时保持模型质量。</p>
  <p>受Minitron启发，通过输入输出相似性模式分析块的重要性：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a64f2637c8a94e0c9ac4facf58149c2b@5888275_oswg43528oswg968oswg238_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这里的</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6a87418389444d9ab3760eab308f25fb@5888275_oswg1968oswg140oswg98_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>表示第i个transformer的第t个token。</p>
  <p>模型的头部和尾部块的重要性较高，而中间层的输入和输出特征相似性较高，表明这些层主要用于逐步优化生成的结果。根据排序后的块重要性，对transformer块进行剪枝。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_94c41970fb9a46d49f14794ead94a0b5@5888275_oswg68926oswg1080oswg318_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>剪枝会逐步削弱高频细节，因为，在剪枝后进一步微调模型，以弥补信息损失。</p>
  <p>使用与大模型相同的训练损失来监督剪枝后的模型。剪枝模型的适配过程非常简单，仅需100步微调，剪枝后的1.6B参数模型就能达到与完整的4.8B参数模型相近的质量，并且优于SANA 1.0的1.6B模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d5c86982327b44eebacc56282cd7616f@5888275_oswg644438oswg1080oswg621_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>推理时扩展</strong></h3>
  <p>SANA 1.5经过充分训练，在高效扩展的基础上，生成能力有了显著提升。受LLM推理时扩展的启发，研究者也想通过这种方式，让SANA 1.5表现得更好。</p>
  <p>对SANA和很多扩散模型来说，增加去噪步数是一种常见的推理时扩展方法。但实际上，这个方法不太理想。一方面，新增的去噪步骤没办法修正之前出现的错误；另一方面，生成质量很快就会达到瓶颈。</p>
  <p>相较而言，增加采样次数是更有潜力的方向。</p>
  <p>研究者用视觉语言模型（VLM）来判断生成图像和文本提示是否匹配。他们以NVILA-2B为基础模型，专门制作了一个数据集对其进行微调。</p>
  <p>微调后的VLM能自动比较并评价生成的图像，经过多轮筛选，选出排名top-N的候选图像。这不仅确保了评选结果的可靠性，还能有效过滤与文本提示不匹配的图像。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_97d5d108c9c540a49b5d0c1e8ed19a62@5888275_oswg217969oswg1080oswg336_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>模型增长、模型深度剪枝和推理扩展，构成了一个高效的模型扩展框架。三种方法协同配合，证明了精心设计的优化策略，远比单纯增加参数更有效。</p>
  <ul>
   <li>模型增长策略探索了更大的优化空间，挖掘出更优质的特征表示。</li>
   <li>模型深度剪枝精准识别并保留了关键特征，从而实现高效部署。</li>
   <li>推理时间扩展表明，当模型容量有限时，借助额外的推理时间和计算资源，能让模型达到与大模型相似甚至更好的效果。</li>
  </ul>
  <p>为了实现大模型的高效训练与微调，研究者对CAME进行扩展，引入按块8位量化，从而实现CAME-8bit优化器。</p>
  <p>CAME-8bit相比AdamW-32bit减少了约8倍的内存使用，同时保持训练的稳定性。</p>
  <p>该优化器不仅在预训练阶段效果显著，在单GPU微调场景中更是意义非凡。用RTX 4090这样的消费级GPU，就能轻松微调SANA 4.8B。</p>
  <p>研究揭示了高效扩展不仅仅依赖于增加模型容量。通过充分利用小模型的知识，并设计模型的增长-剪枝，更高的生成质量并不一定需要更大的模型。</p>
  <h2><strong>SANA 1.5 评估结果</strong></h2>
  <p>实验表明，SANA 1.5的训练收敛速度比传统方法（扩大规模并从头开始训练）快2.5倍。</p>
  <p>训练扩展策略将GenEval分数从0.66提升至0.72，并通过推理扩展将其进一步提高至0.80，在GenEval基准测试中达到了最先进的性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a1bb16c5689e450486b46f7a78f10ed1@5888275_oswg927471oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>模型增长</strong></h3>
  <p>将SANA-4.8B与当前最先进的文本生成图像方法进行了比较，结果如表所示。</p>
  <p>从SANA-1.6B到4.8B的扩展带来了显著的改进：GenEval得分提升0.06（从0.66增加到0.72），FID降低0.34（从5.76降至5.42），DPG得分提升0.2（从84.8增加到85.0）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9fc29fa915b54cb3bdd76c36bb0397d6@5888275_oswg124945oswg1067oswg511_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>和当前最先进的方法相比，SANA-4.8B模型的参数数量少很多，却能达到和大模型一样甚至更好的效果。</p>
  <p>SANA-4.8B的GenEval得分为0.72，接近Playground v3的0.76。</p>
  <p>在运行速度上，SANA-4.8B的延迟比FLUX-dev（23.0秒）低5.5倍；吞吐量为0.26样本/秒，是FLUX-dev（0.04样本/秒）的6.5倍，这使得SANA-4.8B在实际应用中更具优势。</p>
  <h3><strong>模型剪枝</strong></h3>
  <p>为了和SANA 1.0（1.6B）公平比较，此次训练的SANA 1.5（4.8B）模型，没有用高质量数据做监督微调。</p>
  <p>所有结果都是针对512×512尺寸的图像评估得出的。经过修剪和微调的模型，仅用较低的计算成本，得分就达到了0.672，超过了从头训练模型的0.664。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_400a67a9bb3644bea313653fa45295e5@5888275_oswg55847oswg1080oswg209_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>推理时扩展</strong></h3>
  <p>将推理扩展应用于SANA 1.5（4.8B）模型，并在GenEval基准上与其他大型图像生成模型进行了比较。</p>
  <p>通过从2048张生成的图像中选择样本，经过推理扩展的模型在整体准确率上比单张图像生成提高了8%，在「颜色」「位置」和「归属」子任务上提升明显。</p>
  <p>不仅如此，借助推理时扩展，SANA 1.5（4.8B）模型的整体准确率比Playground v3 (24B）高4%。</p>
  <p>结果表明，即使模型容量有限，提高推理效率，也能提升模型生成图像的质量和准确性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9c1c538b017f43579aebe7b85d8e09d0@5888275_oswg134803oswg1080oswg316_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>SANA：超高效文生图</strong></h2>
  <p>在这里介绍一下之前的SANA工作。</p>
  <p>SANA是一个超高效的文本生成图像框架，能生成高达4096×4096分辨率的图像，不仅画质清晰，还能让图像和输入文本精准匹配，而且生成速度超快，在笔记本电脑的GPU上就能运行。</p>
  <p>SANA为何如此强大？这得益于它的创新设计：</p>
  <ul>
   <li><strong>深度压缩自动编码器：</strong>传统自动编码器压缩图像的能力有限，一般只能压缩8倍。而SANA的自动编码器能达到32倍压缩，大大减少了潜在tokens数量，计算效率也就更高了。</li>
   <li><strong>线性DiT：</strong>SANA用线性注意力替换了DiT中的标准注意力。在处理高分辨率图像时，速度更快，还不会降低图像质量。</li>
   <li><strong>仅解码文本编码器：</strong>SANA不用T5做文本编码器了，而是采用现代化的小型仅解码大模型。同时，通过上下文学习，设计出更贴合实际需求的指令，让生成的图像和输入文本对应得更好。</li>
   <li><strong>高效训练与采样：</strong>SANA提出了Flow-DPM-Solver方法，减少了采样步骤。再配合高效的字幕标注与选取，让模型更快收敛。</li>
  </ul>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8aaacb9ffdc2488d90295c3561efea23@5888275_oswg713619oswg1080oswg437_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>经过这些优化，SANA-0.6B表现十分出色。</p>
  <p>它生成图像的质量和像Flux-12B这样的现代大型扩散模型差不多，但模型体积缩小了20倍，数据处理能力却提升了100倍以上。</p>
  <p>SANA-0.6B运行要求不高，在只有16GB显存的笔记本GPU上就能运行，生成一张1024×1024分辨率的图像，用时不到1秒。</p>
  <p>这意味着，创作者们用普通的笔记本电脑，就能轻松制作高质量图像，大大降低了内容创作的成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9209501a86ec4a6c8d95c1300ee57030@5888275_oswg98438oswg1080oswg297_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究者提出新的深度压缩自动编码器，将压缩比例提升到32倍，和压缩比例为8倍的自动编码器相比，F32自动编码器生成的潜在tokens减少了16倍。</p>
  <p>这一改进对于高效训练和超高分辨率图像生成，至关重要。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fffa358e9ee341e0a0bd517533c340f8@5888275_oswg1319164oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究者提出一种全新的线性DiT，用线性注意力替代传统的二次复杂度注意力，将计算复杂度从原本的O(N²) 降低至O(N)。另一方面，在MLP层引入3×3深度可分卷积，增强潜在tokens的局部信息。</p>
  <p>在生成效果上，线性注意力与传统注意力相当，在生成4K图像时，推理延迟降低了1.7倍。Mix-FFN结构让模型无需位置编码，也能生成高质量图像，这让它成为首个无需位置嵌入的DiT变体。</p>
  <p>在文本编码器的选择上，研究者选用了仅解码的小型大语言模型Gemma，以此提升对提示词的理解与推理能力。相较于CLIP和T5，Gemma在文本理解和指令执行方面表现更为出色。</p>
  <p>为充分发挥Gemma的优势，研究者优化训练稳定性，设计复杂人类指令，借助Gemma的上下文学习能力，进一步提高了图像与文本的匹配质量。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6d7c14a6602841c7b698412ed8f42aea@5888275_oswg481782oswg1080oswg834_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究者提出一种自动标注与训练策略，借助多个视觉语言模型（VLM）生成多样化的重新描述文本。然后，运用基于CLIPScore的策略，筛选出CLIPScore较高的描述，以此增强模型的收敛性和对齐效果。</p>
  <p>在推理环节，相较于Flow-Euler-Solver，Flow-DPM-Solver将推理步骤从28-50步缩减至14-20步，不仅提升了速度，生成效果也更为出色。</p>
  <p><strong>参考资料：</strong></p>
  <p>https://huggingface.co/papers/2501.18427</p>
  <p>https://x.com/xieenze_jr/status/1885510823767875799</p>
  <p>https://nvlabs.github.io/SANA/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/UvOoDGvzAFjA3ImXXVlktw" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：英智 好困，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156439091730944</id>
            <title>我们应如何看待DeepSeek的557.6万美元训练成本？</title>
            <link>https://www.36kr.com/p/3156439091730944</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156439091730944</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:12:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 算法效率, DeepSeek-V3, 训练成本, AI企业  
<br><br>  
总结: 本文讨论了中国AI企业在算法效率方面的优势，特别是DeepSeek-V3模型的训练成本显著低于同类美国模型。张钹指出，中国企业对算法效率的重视源于其生存需求，而美国企业则因算力强大而相对宽松。DeepSeek-V3的训练成本为557.6万美元，但未包括隐性成本，且其训练效率通过优化算法、框架和硬件得以提升。尽管DeepSeek的成功引发了外界的误读，但其创新和努力是推动其发展的核心因素。 </div>
                        <hr>
                    
                    <p>三个月前，我们和中国科学院院士、清华大学计算机系教授张钹曾经聊过一个话题：“为什么在提高算法效率上中国人会做得更好？”</p>
  <p>张钹告诉我们：“<strong>对中国企业来讲，算法效率是生命攸关的</strong>，我们必须全力以赴。也许因为美国人有强大的算力，算法效率对他们来说只是锦上添花而已。”</p>
  <p>当时，我们对这句话感受还不是很深，直到后来看到了DeepSeek-V3技术报告里的这张表格。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_894e588f84bf42b68bc34b2222a1e4cf@5888275_oswg26044oswg821oswg177_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">DeepSeek-V3的训练成本（假设H800的租赁价格为2美元/GPU小时），图片来源：DeepSeek-V3技术报告&nbsp;</p>
  <p>简单来说，DeepSeek-V3仅使用了2048块英伟达H800 GPU，耗费了557.6万美元就完成了训练，相比同等规模的模型（如GPT-4、GPT-4o、Llama 3.1），训练成本大幅降低。</p>
  <p>这样说没有错，但在复杂的舆论场中也引发了一些误读。比如，“中国AI企业用几百万美元的成本打败了美国AI企业数亿美元的投入”“成本仅为国外三十分之一，硅谷恐慌”。</p>
  <p>这种误读有一些客观原因，因为OpenAI、Meta官方从来没有公布过GPT-4、GPT-4o、Llama 3.1的训练成本，多数人对模型训练成本构成也并不熟悉，但误读背后更多还是主观原因——情绪。</p>
  <p>AI大模型领域，中国AI企业一直是一个“追随者”的角色，这次有了和硅谷巨头“掰手腕”的机会，就像霍元甲站上了与西洋力士的比武台，谁不想叫声好呢？</p>
  <p><strong>这种情绪本身没有错，但也在一定程度上模糊了DeepSeek团队在算法、框架和硬件上的优化协同设计的价值</strong>，而这正是DeepSeek-V3降本增效的关键。</p>
  <h2><strong>01 训练成本差距是否有那么大？</strong></h2>
  <p>我们查阅了技术报告，DeepSeek只公布了基座模型V3的训练成本，并没有公布推理模型R1的训练成本。</p>
  <p>DeepSeek-V3技术报告显示，该模型的正式训练成本包括三个阶段：<strong>预训练（pre-training）、扩展上下文（context extension）、后训练（post-training），共计557.6万美元。</strong></p>
  <p><strong>但是这557.6万美元的训练成本并不包括前期研究以及关于架构、算法或数据的消融实验所产生的成本。</strong></p>
  <p>前期研究、消融实验属于“隐性成本”，但不容忽视。</p>
  <p>在一个AI企业正式训练一个模型之前，需要进行大量的前期研究，包括对算法的理论研究、对硬件性能的探索、对数据集的分析等。</p>
  <p>而消融实验（Ablation Study）是一种在机器学习和深度学习中广泛使用的分析方法，用于评估模型各个组件或特征的重要性及其对模型整体性能的影响。</p>
  <p>消融实验就像是在玩“减法游戏”或者“排除法”，通过逐一移除或修改模型的某些部分，观察模型性能的变化，从而确定每个部分的相对重要性。</p>
  <p>另外，在训练模型之前还会有一定的试错成本。</p>
  <p>为什么说这些成本是“隐性成本”？</p>
  <p>因为大模型前期研发往往分散在数月甚至数年中，难以量化统计；消融实验可能反复进行，但最终仅保留最优方案，失败案例的成本常被忽视；企业通常不会公开内部研发细节（如试错次数），导致外部估算会产生偏差。</p>
  <p><strong>除了“隐性成本”，不同的成本计算方式也会产生不一样的结果。</strong></p>
  <p>DeepSeek-V3这557.6万美元训练成本是怎么计算的呢？按照DeepSeek-V3技术报告的逻辑，我们简单列了一个公式：</p>
  <blockquote>
   <p>训练耗费的时长（GPU小时）×H800每GPU小时的租赁价格（美元）=DeepSeek-V3训练成本（美元）</p>
  </blockquote>
  <p>正式训练耗费的时长包括：预训练阶段耗费266.4万（2664K）GPU小时，扩展上下文长度阶段耗费11.9万（119K）GPU小时，后训练阶段耗费0.5万（5K）GPU小时，因此DeepSeek-V3的正式训练共耗费278.8万（2788K）GPU小时。</p>
  <p>而DeepSeek在技术报告中假设H800每GPU小时的租赁价格为2美元，这样DeepSeek-V3训练成本就是：</p>
  <blockquote>
   <p>2,788,000×2=5,576,000（美元）</p>
  </blockquote>
  <p>需要注意的是，这里是按<strong>GPU小时</strong>而不是<strong>GPU个数</strong>计算，单价是按<strong>GPU租赁价格计算</strong>而不是<strong>GPU购买价格计算</strong>。</p>
  <p>换种方式计算训练成本，结果就会很不一样。</p>
  <p>比如，为了训练Llama 3.1 405B，Meta使用了超过1.6万个英伟达H100 GPU，如果按照H100 GPU的购买价格计算，这样计算下来的训练成本就已高达数亿美元。</p>
  <p>我们也可以按照DeepSeek-V3一样的租赁逻辑计算。</p>
  <p>尽管Meta没有透露Llama 3.1具体的训练成本，但是其技术报告显示，Llama 3.1 405B的预训练（此处说的是预训练时间而非完整训练时间）为54天。那么，Llama 3.1 405B预训练阶段耗费的GPU小时为：</p>
  <blockquote>
   <p>天数×24小时×H100 GPU个数=预训练阶段耗费的GPU小时</p>
   <p>54×24×16,000=20,736,000</p>
  </blockquote>
  <p>Llama 3.1 405B是2024年7月推出的，如果按照2024年初海外市场H100 GPU每GPU小时的租赁价格2.8美元（参考价格，会浮动）计算，那么<strong>其预训练成本约为5800万美元。相比之下，DeepSeek-V3的532.8万美元预训练成本的确是大幅降低了。</strong></p>
  <p>而OpenAI官方从来没有公布过其训练成本，但是我们可以从侧面推算。</p>
  <p>英伟达CEO黄仁勋在NVIDIA GTC 2024主题演讲中介绍，<strong>如果要训练一个有1.8万亿参数的GPT模型，用Hopper（H100）的话，需要约8000个GPU，耗电15兆瓦，用时90天，大约需要三个月。</strong></p>
  <p>虽然黄仁勋没有明说，但根据此前多个渠道的爆料信息，这个1.8万亿参数的GPT模型就是GPT-4。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1c0ff7c877ae4b839016aa093cf6e094@5888275_oswg359451oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">黄仁勋在NVIDIA GTC 2024 主题演讲，图片来源：英伟达B站账号&nbsp;</p>
  <p>黄仁勋在演讲中解释道：“这样就可以训练出这种开创性的AI模型，这显然没有人们想象中那么昂贵，但是8000个GPU仍然是一大笔投资。”</p>
  <p>我们同样可以按照租赁逻辑估算一下与GPT-4规模相当模型训练成本。为什么说估算？因为H100是2022年3月发布的GPU，但实际大规模供货和云服务商部署通常在2022年底至2023年初才开始，而GPT-4在2023年3月发布，所以GPT-4的训练更多还是依靠A100。</p>
  <p>假设在2024年初，也就是黄仁勋发表演讲之前，<strong>训练一个与GPT-4规模相当的大模型</strong>，其训练成本是：</p>
  <blockquote>
   <p>天数×24小时×H100 GPU个数=训练阶耗费的GPU小时</p>
   <p>90×24×8,000=17,280,000（小时）</p>
   <p>训练耗费的GPU小时×H100每GPU小时的租赁价格=训练成本</p>
   <p>17,280,000×2.8=48,384,000（美元）</p>
  </blockquote>
  <p><strong>大约4800万美元的训练费用</strong>，的确如黄仁勋所说“没有人们想象中那么昂贵”。</p>
  <p>而据SemiAnalysis在2023年7月发布的分析报告，OpenAI在GPT-4的训练中使用了约2.5万个A100GPU，训练了90到100天，利用率（MFU）约为32%至36%，这种极低的利用率部分是由于大量的故障导致需要重新启动检查点。如果每个A100 GPU的使用成本大约为每小时1美元，<strong>那么仅此次训练的成本将达到约6300万美元。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_918f231763784300810201856d257a93@5888275_oswg416449oswg1080oswg465_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：SemiAnalysis&nbsp;</p>
  <p>DeepSeek-V3对标的Claude 3.5 Sonnet的训练成本又是多少呢？此前Anthropic也没有公布Claude 3.5 Sonnet的训练成本，但Anthropic CEO达里奥·阿莫迪（Dario Amodei）近期在一篇评价DeepSeek的文章中透露，<strong>Claude 3.5 Sonnet训练成本在数千万美元（cost a few $10M's to train）</strong>，他还特意说：“我不会给出具体的数字。”</p>
  <p>“A few”在英语里通常指3到5个，所以我们<strong>估计Claude 3.5 Sonnet的训练费用在3000万到5000万美元之间。</strong></p>
  <p>我们统一按照DeepSeek-V3的GPU租赁逻辑计算，不考虑其他“隐性成本”，可以发现，<strong>DeepSeek-V3的训练成本相比其对标模型训练成本大幅降低，但没有到某些人说的“几十分之一”的夸张程度。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c3fbca472091403fae7a206a4a7a90b4@5888275_oswg277004oswg1080oswg748_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>需要注意的是，随着技术和市场的发展，GPU租赁价格的降低使得企业和研究机构能够以更低的成本配置更多的GPU，从而让模型训练降本增效。</p>
  <p>企业还可以用更先进的GPU降低训练的能耗。</p>
  <blockquote>
   <p>还记得黄仁勋举的例子吗？如果要训练一个有1.8万亿参数的GPT模型，用Hopper（H100）的话，需要约8000个GPU，耗电15兆瓦，用时90天；如果用Blackwell（GB200）的话，需要2000个GPU，耗电仅需4兆瓦，约为Hopper的四分之一。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_19c5ba83907344cba79a53aba4282d23@5888275_oswg212098oswg834oswg901_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：英伟达&nbsp;</p>
  <p>这是先进GPU带来的效率提升，但是国内AI企业由于管控，无法获得最先进的GPU，又是靠什么来实现降本增效呢？</p>
  <blockquote>
   <p>Meta技术报告显示，Llama 3.1 405B的预训练时长54天，使用了15万亿（15T）的tokens以及1.6万个英伟达H100 GPU进行训练。</p>
  </blockquote>
  <p>DeepSeek-V3在预训练阶段，使用了14.8万亿（14.8T）的tokens进行训练，预训练耗时也是54天，DeepSeek-V3技术报告里也说的是“不到两个月”：</p>
  <blockquote>
   <p>预训练阶段耗费的GPU小时÷H800 GPU个数÷24小时=天数</p>
   <p>2,664,000÷2048÷24≈54（天）</p>
  </blockquote>
  <p>但是，DeepSeek-V3仅使用了2048块英伟达H800 GPU，尽管可能存在利用率的差异，但这与Llama 3.1 405B训练使用的1.6万个英伟达H100 GPU形成了鲜明对比。而且H800是英伟达为了满足出口限制而设计的GPU，性能低于H100。</p>
  <p>也就是说，DeepSeek-V3在GPU比Llama 3.1 405B用得少，GPU性能也更弱的情况下，在相同的时间，完成了与Llama 3.1 405B差不多的训练量。</p>
  <p>DeepSeek-V3技术报告里的这句话“<strong>DeepSeek-V3每训练一万亿（trillion）个token仅需18万（180K）H800&nbsp;GPU小时</strong>”成为了关键。</p>
  <p>DeepSeek-V3大幅提升了模型训练效率。</p>
  <h2><strong>02 DeepSeek如何降本增效？</strong></h2>
  <p>DeepSeek-V3是一个混合专家模型 (Mixed Expert Models，以下简称MoE) ，旨在通过整合多个模型或“专家”的预测来提升整体模型性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_89bd3322c519407eac19f610abea1fdd@5888275_oswg95273oswg966oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：DeepSeek-V3技术报告&nbsp;</p>
  <p>清华大学计算机系长聘教授、高性能计算研究所所长翟季冬在《夜话DeepSeek：技术原理与未来方向》直播中介绍，之前发布的一些MoE模型，采用的是<strong>“专家数很少、每个专家很大”</strong>的架构，但是DeepSeek采用的是<strong>“大量细粒度的专家”</strong>。</p>
  <p>“大量细粒度的专家”可以更灵活地处理各种输入数据，提高模型的适应性和泛化能力。由于每个专家的规模小，计算效率更高，训练和存储成本也相对较低。不过，由于专家数量众多，可能会导致模型的管理和调度变得更加复杂。</p>
  <p>翟季冬分析，为了提升DeepSeek-V3的模型训练效率，DeepSeek团队在四个方面进行了优化，分别是：<strong>负载均衡优化、通信优化、内存优化、计算优化</strong>。</p>
  <p><strong>首先是负载均衡优化。</strong>在MoE架构中，负载均衡指的是将输入数据合理分配给各个专家，使得每个专家都能充分发挥其性能，同时避免某些专家过度负载而其他专家空闲。</p>
  <p>负载均衡是MoE训练中的非常大的挑战，如果处理不好，那么模型在一个大规模GPU集群训练时，利用率就很难提升上去。</p>
  <p>DeepSeek团队为了解决负载均衡的挑战，创新提出了“Auxiliary-loss-free（无辅助损失）”负载均衡方案。</p>
  <p>在传统的MoE中，为了保证各个专家的负载均衡，通常会引入一个Auxiliary Loss（辅助损失）。这个Auxiliary Loss会强制让每个专家处理的任务量尽量均匀。但它可能会让模型在优化过程中过于关注负载均衡，而忽略了模型本身的性能。</p>
  <p>而DeepSeek的Auxiliary-Loss-Free方案，<strong>不依赖额外的辅助损失，而是在每个token的专家分配过程中直接施加一个bias（偏差值）来实现负载均衡，从而实现动态调整专家的负载。</strong></p>
  <p>由于这种bias的引入已经在专家选择的过程中起到了调控作用，使得各专家之间的token分配趋向均衡，因此就不再需要设计和调节额外的辅助损失项来“强制”负载平衡。这不仅简化了训练目标，也避免了因辅助损失权重设置不当而可能引入的训练不稳定问题。</p>
  <p>简单来说，<strong>这就类似红绿灯路口</strong>，Auxiliary loss就是固定时长的红绿灯，车流量大了，路口通行效率会降低；而Auxiliary-Loss-Free中的bias就是可以根据实时车流量动态调整时长的红绿灯，基于当前状态（交通流量或专家负载）动态调整资源分配，以达到整体平衡和高效利用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b9f0ae3691234cceb86b6eede16cfde3@5888275_oswg72090oswg957oswg545_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">负载均衡优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>第二是通信优化。</strong>在MoE训练中，使用专家并行会引入非常大的All to All通信开销。</p>
  <p>什么是All to All通信开销？</p>
  <p>假设在一个MoE中，有10个专家，每个专家被放置在一个独立的计算节点上。在训练过程中，每个专家需要与其他所有专家进行数据交换，以更新模型参数和同步训练状态。这种情况下，每个节点都需要与其他9个节点进行通信，形成了All to All的通信模式。随着专家数量的增加，通信开销也会显著增加，导致训练效率下降。</p>
  <p>DeepSeek-V3就包括1个共享专家和256个路由专家，它采用的并行训练策略：16路流水线并行、64路专家并行，跨8个物理节点。</p>
  <p><strong>DeepSeek团队为了降低通信开销，提出了DualPipe算法。</strong></p>
  <p><strong>DualPipe算法的核心创新就是能够将计算和通信阶段重叠进行。</strong>在传统的训练过程中，计算和通信是分开进行的，这会导致GPU在等待数据传输时出现空闲期，即所谓的 “流水线气泡”（pipeline bubbles）。DualPipe算法通过确保在一个微批量（micro-batch）被计算的同时，另一个微批量可以进行通信，精细地编排计算和通信，从而最大限度地减少这些空闲期，提高GPU的利用率。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_074173ab32d143be82d54df302e054df@5888275_oswg322986oswg986oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">通信优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>DualPipe算法还采用了双向流水线机制，同时从流水线的两端处理微批量。</strong>这种策略确保了在整个训练过程中GPU始终保持活跃。通过这种方式，DeepSeek能够保持良好的计算与通信比例，减少延迟，提高吞吐量。</p>
  <p>“这里有一个需要注意的点，如果采用双向流水线，要在GPU显存里存两份模型参数。大模型训练内存使用非常重要，为了解决这个问题，它采用了64路的专家并行，双流水可以非常有效地降低流水线bubble。”翟季冬说。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_40a1b49467194c6990866eaacafff0d8@5888275_oswg74515oswg961oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">通信优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p>此外，DeepSeek的通信优化还包括跨节点通信优化以及Warp Specialization技术。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_52733754fbfc450399f10663b79f1366@5888275_oswg500012oswg989oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">通信优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>第三是内存优化。</strong>包括了重计算、使用CPU内存和参数共享。</p>
  <p>大模型训练往往存在显存瓶颈。重计算的核心思想是在前向传播过程中，只保留少量关键的中间结果，而将其余的中间结果释放掉。当在反向传播过程中需要用到这些已释放的中间结果时，再重新执行前向传播中的相应部分来计算得到。<strong>这种方法通过增加一定的计算量，显著降低了内存消耗，是一种“以时间换空间”的策略。</strong></p>
  <p>这可以理解为一种在大模型训练过程中“偷懒”的技巧。</p>
  <p>同时，DeepSeek还把一些数据，包括像模型参数的指数移动平均（EMA），存到CPU内存，从而节约GPU显存；将主模型与MTP（Multi-Token Prediction）模块的output head和embedding部署在相同节点，最大化地共享参数空间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_531b3e1722fb4174af5c7f9c455ed4e8@5888275_oswg392274oswg987oswg564_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">内存优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>第四是计算优化。</strong>为了提升训练效率，DeepSeek采用了混合精度训练策略。</p>
  <p>DeepSeek引入了英伟达FP8混合精度训练框架，并首次在超大规模模型上验证了其有效性。通过支持FP8计算和存储，DeepSeek实现了加速训练和减少GPU内存使用。FP8训练在相同加速平台上的峰值性能显著超越FP16/BF16，并且模型参数越大，训练加速效果越好。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_989c8ec6cc3c4e578e83c0f7b21731f6@5888275_oswg70865oswg952oswg538_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">计算优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p>总的来说，翟季冬认为：DeepSeek充分挖掘了算法、软件、硬件性能，实现了协同创新；其软件相对灵活，软件赋能硬件，弥补了硬件的很多限制；优秀的系统软件能够充分释放底层硬件的潜力。</p>
  <p>DeepSeek正是通过这一步步的优化，让整个模型的训练效率得到提升，并降低训练成本。</p>
  <h2><strong>03 “小米加步枪”式的成功</strong></h2>
  <p>经历了春节假期的喧嚣，我们对于DeepSeek的讨论应趋向理性。</p>
  <p><strong>我们不应神话DeepSeek，也不要因为外部的贬低而看轻DeepSeek，这些都对DeepSeek团队不公平。其实，DeepSeek就是一种“小米加步枪”式的成功。</strong></p>
  <p>行云集成电路创始人季宇最近跟我们聊起DeepSeek时说，创新的意识其实国内根本不缺，但缺乏Known-Why的创新往往会走向类似赌徒的歧途。</p>
  <p>“创新不是简简单单的不一样的技术路线，国内其实不缺乏创新性和天马行空的想象，其实无论AI行业还是算力芯片行业，都有无数走非Transformer架构、走非GPU架构、非冯诺伊曼架构的差异化路线，但是基本都陷入了用差异化的技术路线主流技术路线替代品的逻辑里。”季宇说。</p>
  <p>但是DeepSeek的创新是一步一个脚印的。</p>
  <p>季宇告诉我们，第一性原理思考问题很多人都在讲，但实际上非常困难。<strong>第一性原理需要深入推敲，需要对每个论断的边界条件，需要深入考虑各个层级技术的细节。</strong></p>
  <p>“之前跟在DeepSeek的一个师弟交流，梁老板（DeepSeek创始人梁文锋）对他写的CUDA Kernel里每个线程具体在干什么事情都非常清楚，只有这样才能从全局视角去思考突围的方式，真正把创新做成。”季宇说。</p>
  <p>这一点在另一位投资人那里也得到了印证。这位投资人去年曾问DeepSeek的人：“为什么你们的模型做得好？”</p>
  <p><strong>DeepSeek的人回答，因为我们老板自己在读论文、写代码、搞招聘。</strong></p>
  <p>关于DeepSeek的成功，你可以说他们有丰富的GPU储备，可以说他们对模型架构进行了创新，但其成功内核往往是朴实而简单的。</p>
  <p>DeepSeek创始人梁文锋去年接受《暗涌》采访时说过的一句话，既谦虚又意味深长。</p>
  <p>他说：“我们不是有意成为一条鲶鱼，只是不小心成了一条鲶鱼。”</p>
  <p>**参考资料：&nbsp;</p>
  <p>DeepSeek-V3 Technical Report,DeepSeek&nbsp;</p>
  <p>The Llama 3 Herd of Models,Meta&nbsp;</p>
  <p>GPT-4 Architecture, Infrastructure, Training Dataset, Costs, Vision, MoE,SemiAnalysis&nbsp;</p>
  <p>《夜话DeepSeek：技术原理与未来方向》，中国计算机学会青年计算机科学与技术论坛（CCF YOCSEF）</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/elQbehCVT8an2jC4unBHdQ" rel="noopener noreferrer nofollow" target="_blank">“甲子光年”</a>，作者：王博，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156441710664192</id>
            <title>大神卡帕西拿DeepSeek R1讲强化学习，最新大模型内部机制视频爆火，“没有技术背景也能看懂”</title>
            <link>https://www.36kr.com/p/3156441710664192</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156441710664192</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:11:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 卡帕西, 大语言模型, 教育, Eureka Labs  
<br><br>  
总结: Andrej Karpathy发布了一个三个半小时的视频课程，深入解析了大语言模型如ChatGPT的内部工作机制，适合没有技术背景的观众。课程涵盖了模型的预训练、监督微调和强化学习等多个阶段，并通过具体示例讲解了模型的原理和应用。卡帕西强调了教育的重要性，并创办了Eureka Labs，旨在通过AI与教师的共生，提升教育的可及性和质量。他的课程受到了广泛关注，吸引了众多网友熬夜观看。 </div>
                        <hr>
                    
                    <p>宣布全职搞教育的AI大神<strong>Andrej Karpathy</strong>（卡帕西），新年第一课来了——</p>
  <p>发布<strong>三个半小时视频课</strong>，深入解析了ChatGPT等大语言模型的<strong>内部工作机制</strong>，其中涵盖模型开发的完整训练过程、如何在实际应用中最有效地使用它们，还有AI未来发展趋势。</p>
  <p>卡帕西强调，这次是为大众准备的，<strong>即使没有技术背景也能看懂</strong>！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_adefebd91e2b448a977b819500c1a55f@5888275_oswg406445oswg594oswg1308_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他在视频中深入浅出用大量具体示例，如GPT-2、Llama 3.1等，完整讲述了大模型的原理。</p>
  <p>当红炸子鸡<strong>DeepSeek</strong>也没落下，成为一大重点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8fd74341a7a14e74a15882604677881c@5888275_oswg409823oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>卡帕西课程的含金量无需多言，刚一发就被网友团团围住，熬夜也要看的那种。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ed01df6f177043828bf135be87239c91@5888275_oswg46205oswg784oswg170_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网友们表示，接下来三个半小时就这样过了：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_93cf055cb9934c238652f2a55292c21f@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <blockquote>
   <p>你知道，Karpathy发布新视频，一整天都会变得非常美好，每个视频都是金矿！</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1c6238417432410fb78d89de548db78a@5888275_oswg40747oswg794oswg146_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>机器学习工程师Rohan Paul看后也表示其中有关于ChatGPT内部工作机制最简洁明了的解释。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_10ebc63993ea46e590731fcd38b3dc3c@5888275_oswg210573oswg784oswg706_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>话不多说了，以下是重点知识点，文末有完整视频～</p>
  <h2><strong>重点一览</strong></h2>
  <p>用过类似ChatGPT等工具的人可能都会有这样的疑问：</p>
  <p>这个文本框背后是什么？你可以在里面输入任何内容并按回车，但我们应该输入什么？这些生成的词又是什么意思？这一切是如何工作的？你究竟在与什么交流？</p>
  <p>卡帕西在视频中详细解答了这些问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5db56c07cbc24e1a85623d70a5a7e2f0@5888275_oswg47233oswg1080oswg246_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他从如何构建这样一个LLM展开，详细讲解了所有阶段：</p>
  <p><strong>预训练：</strong>数据、分词、Transformer神经网络的输入/输出及内部机制、推理、GPT-2训练示例、Llama 3.1基础推理示例。</p>
  <p><strong>监督微调：</strong>对话数据、“LLM心理学”：幻觉、工具使用、知识/工作记忆、自我认知、模型需要token来思考、拼写、参差不齐的智力。</p>
  <p><strong>强化学习：</strong>熟能生巧、DeepSeek-R1、AlphaGo、基于人类反馈的强化学习（RLHF）。</p>
  <h4><strong>预训练</strong></h4>
  <p>首先是预训练阶段，使模型拥有丰富的知识。</p>
  <p>预训练的第一步是<strong>下载和处理互联网数据</strong>。目标是从互联网的公开资源中获取大量且种类多样的文本、高质量文档，例如FineWeb。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7941792ce5804062b8ad02dc83db257f@5888275_oswg239456oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>第二步是<strong>文本提取</strong>。</p>
  <p>爬虫获取的是网页的原始HTML代码，需要过滤和处理提取出网页文本，去除导航和无关内容。</p>
  <p>还要进行语言过滤，例如只保留英语占比超过65%的网页，不同公司会根据需求决定保留的语言种类，如果过滤掉所有的西班牙语，那么模型之后在西班牙语上的表现就可能不会很好。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c05368351a454034959bdc1b6f0f5415@5888275_oswg310204oswg1080oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之后，还会进行去重、移除个人身份信息等进一步的过滤步骤，最终得到大规模的文本数据，进入训练集。</p>
  <p>接下来要做的是在这些数据上训练神经网络。在将文本输入神经网络之前，需要将文本转换为一维符号序列。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ae4ee428cd3c40e58c50a676cf840695@5888275_oswg917908oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>通过字节对编码（BPE）算法，将常见的字节组合成新符号，从而减少序列长度并增加符号词汇量。tokenization是将文本转换为符号序列的过程，不同的输入文本会根据tokenization规则生成不同的符号序列。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4760f96ae02c4e7290c693a48410ce90@5888275_oswg858801oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>训练神经网络时，从数据集中随机抽取token作为输入，并预测下一个token。神经网络的输出是下一个token出现的概率分布。</p>
  <p>通过训练过程不断更新网络参数，使预测结果与实际数据的统计模式一致。</p>
  <p>神经网络内部是一个复杂的数学表达式，输入token序列与网络参数混合，经过多层变换后输出预测结果。现代神经网络结构，如Transformer，具有大量参数和复杂的内部结构，但本质上是通过优化参数来使预测结果与训练数据匹配。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ac9646a4c2d34ff2ac7974bc009e8b07@5888275_oswg250614oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>训练过程需要强大的计算资源支持，依赖高性能GPU集群，这些硬件能够高效处理大规模并行计算任务，加速模型的训练和优化。随着技术的发展，训练成本逐渐降低，但大规模模型的训练仍然需要大量的计算资源投入。</p>
  <p>卡帕西在视频中以GPT-2为例讨论了训练，包括其参数、上下文长度和训练成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_08f57f8ddbe04d94ade541631826625a@5888275_oswg487532oswg1080oswg624_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之后他又以Llama 3为例讨论了基础语言模型的属性，它可以生成类似于互联网文档的token序列，并将知识存储在其参数中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fe64f174864445aebf0530248cfc3659@5888275_oswg564398oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然而，模型的输出具有随机性，每次生成的结果可能不同，且模型可能会过度记忆训练数据中的某些内容，导致输出与训练数据高度相似，甚至直接复述某些条目。</p>
  <p>这种现象在实际应用中可能会带来问题，例如模型可能无法区分事实和虚假信息，因为它只是基于训练数据的统计规律进行生成。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_cf36f74d4fa04d4586cf3fe06723ac34@5888275_oswg233426oswg1080oswg595_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>预训练阶段，模型通过大量互联网文档数据学习生成文本的能力，输出为基础模型，它能够生成与互联网文档统计特性相似的token序列，但本身并不是一个能够回答问题的“助手”。</p>
  <p>所以还需要后训练。</p>
  <h3><strong>后训练</strong></h3>
  <p>在后训练阶段，模型通过学习人类标注的对话数据来调整其行为，从而能够生成符合人类期望的回答。数据集规模较小，训练时间也相对较短。</p>
  <p>早期的对话数据集（如InstructGPT）主要由人类标注人员手工创建，但随着技术的发展，现代的对话数据集越来越多地利用现有的语言模型来生成初始回答，然后由人类进行编辑和优化。这些数据集可能包含数百万条对话，覆盖广泛的主题和领域。</p>
  <p>具体来说，后训练包括监督微调（SFT）和强化学习（RL）。</p>
  <p>在监督微调阶段，模型通过创建对话数据集，学习<strong>如何与人类进行多轮对话</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1d20ffea974f494e85374a49f9b6faa8@5888275_oswg268309oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>例如，OpenAI的InstructGPT论文详细介绍了如何通过人类标注者创建对话数据集。</p>
  <p>强化学习阶段，目的是让模型<strong>通过实践和试错来发现解决问题的最佳方法</strong>。</p>
  <p>卡帕西用人类在学校学习的过程类比。预训练相当于阅读课本中的背景知识，微调相当于学习专家提供的解题方法，而强化学习则相当于通过练习题来巩固知识，自己探索解题步骤。</p>
  <p>具体来说，模型会尝试多种不同的解题方法，这些方法可能来自不同的prompt。之后评估解决方案，检查每个解决方案是否正确。正确的解决方案会被标记为“好”，错误的解决方案会被标记为“坏”。</p>
  <p>模型会根据正确答案的解决方案进行训练，强化那些能够得到正确答案的解决方案。这类似于学生在练习中发现有效的方法后，会更多地使用这些方法。</p>
  <p>强化学习和人类标注相比，人类标注者在创建训练数据时，很难知道哪种解决方案最适合模型。人类标注者可能会注入模型不理解的知识，或者忽略模型已有的知识，导致模型难以理解。而强化学习让模型通过试错来自主发现适合自己的解决方案。</p>
  <p>模型会尝试多种路径，找到能够可靠地达到正确答案的解决方案。</p>
  <p>卡帕西用具体示例讨论了强化学习在大语言模型中的应用及其重要性，特别是<strong>DeepSeek</strong>最近发布的论文引发了公众对这一领域的关注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_702732cfe2b24eb8b0a4c7758212c41f@5888275_oswg311578oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他还讲了人类反馈的强化学习（RLHF）工作原理及其优缺点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fb5748c8c2f6411b857f2099c9d24f61@5888275_oswg185375oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后卡帕西提到了多模态模型的发展，模型能够将音频、图像和文本转化为tokens，并在同一个模型中同时处理。</p>
  <p>这种多模态能力将使模型能够进行更自然的交互，例如理解语音指令、处理图像内容等。</p>
  <p>目前局限性在于，模型执行任务时，通常是被动地接收任务并完成，无法像人类那样在长时间内持续、连贯地执行复杂任务。</p>
  <p>未来可能会出现能够持续执行任务的Agent，可以在长时间内执行任务，并定期向人类报告进度。人类将成为这些Agent的监督者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1a40f12dbf0946aabe2136ec78860496@5888275_oswg164256oswg1080oswg347_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>持续专注于教育的AI大牛</strong></h2>
  <p>卡帕西曾任特斯拉AI主管，之后去了OpenAI，去年2月从OpenAI离职。</p>
  <p>他在整个AI届拥有超高人气，很大一部分来自于他的课程。</p>
  <p>包括他自己的早期博客文字分享和后来的一系列Youtube视频教程，他还与李飞飞合作开设的的斯坦福大学首个深度学习课程CS231n《卷积神经网络与视觉识别》。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_723bf9db59804aa49b4c36a34f594049@5888275_oswg299850oswg1080oswg332_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今天不少学者和创业者，都是跟着他入门的。</p>
  <p>卡帕西对教育的热情，甚至可以追溯到学生时期在网上教大家玩魔方。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_05e3998cb8754de08dc9499ecf43c57c@5888275_oswg230719oswg1080oswg303_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>去年7月，从OpenAI离职的卡帕西突然官宣创业，搞了一家AI原生的新型学校——<strong>Eureka Labs</strong>。</p>
  <p>怎么理解AI原生？</p>
  <p>想象一下与费曼一起学习高质量教材，费曼会在每一步中1对1指导你。</p>
  <p>不幸的是，即使每个学科都能找到一位像费曼这样的大师，他们也无法分身亲自辅导地球上的80亿人。</p>
  <p>但AI可以，而且AI有无限的耐心，精通世界上所有的语言。</p>
  <p>所以卡帕西要打造“教师+人工智能的共生”，可以在一个通用平台上运行整个课程。</p>
  <blockquote>
   <p>如果我们成功了，任何人都将易于学习任何东西，扩大教育这个概念本身的“范围”和“程度”。</p>
  </blockquote>
  <p>目前在EurekaLabs的官方GitHub账号上也有相关课程了，手把手带你构建一个类似ChatGPT的故事生成大模型，感兴趣的童鞋可以去一睹为快。</p>
  <p>视频链接：https://www.youtube.com/watch?v=7kVfqmGtDL8</p>
  <p>参考链接：https://x.com/karpathy/status/1887211193099825254</p>
  <p>Eureka Labs：eurekalabs.aigithub.com/EurekaLabsAI</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/lBc0-8ByRxJ3JBJpMcfzkQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156431180667657</id>
            <title>为什么BAT没做出DeepSeek</title>
            <link>https://www.36kr.com/p/3156431180667657</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156431180667657</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:05:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, AI应用, 开源策略, 创新团队  
<br><br>  
总结: DeepSeek的迅速崛起在于其团队多年的深耕与技术积累，成功吸引了大量用户，日活用户在上线20天内突破2000万，成为全球增速最快的AI应用。与传统大厂依赖现有业务体系不同，DeepSeek以创新为核心，敢于从零开始，推动技术前沿的发展。创始人梁文锋强调中国AI不能永远处于跟随地位，必须实现原创与创新。DeepSeek的成功也促使大厂重新思考其创新逻辑，面临技术话语权的挑战。 </div>
                        <hr>
                    
                    <p>一夜之间，DeepSeek抢走了几乎所有国产大模型的风头。</p>
  <p>过去一年，无论是在C端出圈的Kimi，还是后在居上的豆包，无论是用户日活早早突破2亿的文心一言，还是登顶全球开源第一的通义千问，与DeepSeek给全球科技圈带来的震动相比，都逊色不少。</p>
  <p>这并非是一众国产大模型不给力，而实在是DeepSeek太优秀了。</p>
  <p>以前国内大厂一直讨论的是，距离OpenAI到底有多少年差距，但在DeepSeeK这里，却是另一番景象。市场热议的是DeepSeeK是否已经干翻了OpenAI，其所代表的开源路线，已经在倒逼OpenAI CEO山姆·奥尔特曼进行反思：“我个人认为，在这个问题上我们站在历史的错误一边。现在需要想出一个不同的开源策略。”</p>
  <p>DeepSeek的横空出世，其带来的影响不仅是在行业内，同样也更在C端市场。</p>
  <p>数据显示，仅仅上线20天，DeepSeek的日活就突破了2000万大关，成为全球增速最快的AI应用。与之相比，ChatGPT突破1500万大关花了244天，而DeepSeek仅用了18天。上线20天后的DeepSeek日活已达2215万，是ChatGPT日活用户的41.6%，并远超豆包日活用户的1695万。</p>
  <p>这是一场极其夸张的AI风暴，并且跟以往截然不同的是，这是一家真正由中国创业公司主导引发的AI风暴。</p>
  <p>问题在于，为什么是DeepSeek？</p>
  <p>要知道，过去两年国内主流的互联网大厂都在大模型赛道上投入重兵，也都跑出了不少产品，市场也普遍抱有期待，希望其中有谁能早上追上OpenAI，与硅谷AI一较高下。</p>
  <p>但最终破局的，却是DeepSeek，大厂没做到的，它反而实现了。</p>
  <h2><strong>深耕已久</strong></h2>
  <p>本质上DeepSeek当下的爆火，是一种厚积之下的爆发。</p>
  <p>虽说此次DeepSeek是一鸣惊人，但其团队早就在AI领域布局多年，时间线上甚至比大厂还早，布局宽度以及深度，也丝毫不比大厂差多少。</p>
  <p>公开数据显示，DeepSeek，由知名私募巨头幻方量化孕育而生，创始人为梁文锋。</p>
  <p>事实上，早在大学期间，即便在当时，人工智能还是一个空有理论并无实质的概念，但梁文锋无比笃信，“人工智能一定会改变世界”。</p>
  <p>这也成为了其创业以来的终极愿景。</p>
  <p>2015年梁文锋创办幻方，这是是国内最早使用人工智能进行量化交易的公司，2016年第一份由深度学习生成的交易仓位上线执行，2017 年全面应用深度学习技术进行交易。</p>
  <p>到了2018年，幻方官网将“把AI确定为公司的主要发展方向”写入公司大事，再一年，幻方干脆改变了组织架构，成立了幻方AI，对外自我介绍时总说自己是一家以大规模深度学习基础研究与应用为核心的人工智能公司。</p>
  <p>自2019年至2021年间，幻方相继自主研发了“萤火一号”与“萤火二号”AI集群，其中“萤火二号”投资达到10亿元，极大提升算力支持。同时，幻方也积极招募了一批算法科学家。而创始人梁文锋本人，则每天也都在写代码、跑代码。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_db730cb023e046fc9a5e5ea91e779bc5@5888275_oswg47005oswg899oswg673_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>技术上，一直在稳步储备，基建上，更是没有落下。</p>
  <p>可能很少有人能预料到，2023年当ChatGPT横空出世时，市场突然发现在国内，拥有高性能GPU芯片最多的不是人工智能公司，而是梁文锋旗下的幻方量化。</p>
  <p>彼时根据国盛证券研报，在云算力端，当时除了几家互联网公司（商汤、百度、腾讯、字节、阿里），就只有幻方有超过1万张A100芯片储备。</p>
  <p>足见，幻方对AI的投入，对比大厂，丝毫不落下风。</p>
  <h2><strong>反套路</strong></h2>
  <p>还有就是，以梁文锋为代表的DeepSeek创业团队的锐气。</p>
  <p>互联网大厂的AI战略往往依附于现有业务体系。腾讯的AI需服务于社交与游戏生态，阿里的AI需嵌入电商和云计算场景。这种业务协同逻辑，固然能快速商业化，却也框定了技术演进的路径——资源投入越多，越倾向于优化既有模式，而非另辟蹊径。</p>
  <p>而背靠幻方的DeepSeek，既有强大的财力支持，又有身为创业者敢于“从零开始”，不怕试错的勇气。这让DeepSeek只需要沿着创新的信念，一路蹚过去。</p>
  <p>对于创新，梁文锋的态度是非常坚决的——“过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。”</p>
  <p>“我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。”</p>
  <p>而如何实现创新，则是抛弃惯性的反套路。</p>
  <p>最直接的体现，就是在团队组成上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_70b2574b9e2d4ab989ae74cdeb5f5ef6@5888275_oswg615331oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来自于幻方官网</p>
  <p>国内大厂在进入大模型赛道上，通常倾向于去海外挖人，引入技术大牛，快速拉起一个团队，然后大干快上。而DeepSeek团队组多由本土一些Top高校的应届毕业生组成，不看经验资历，选人的标准一直都是热爱和好奇心。</p>
  <p>同时在工作机制上，“我们一般不前置分工，而是自然分工。每个人有自己独特的成长经历，都是自带想法的，不需要push他。探索过程中，他遇到问题，自己就会拉人讨论。不过当一个idea显示出潜力，我们也会自上而下地去调配资源。”</p>
  <p>“如果有想法，每个人随时可以调用训练集群的卡无需审批。同时因为不存在层级和跨部门，也可以灵活调用所有人，只要对方也有兴趣。”</p>
  <p>换句话说，大厂的组织架构，本质是一台精密运转的“效率机器”。但颠覆性创新的诞生，需要的恰恰是反效率的“失控”。</p>
  <p>而DeepSeek正做到了这一点。</p>
  <p>AI蓝媒汇也就为什么大厂没有做出DeepSeeK的问题，向DeepSeek提问，后者表示，本质上是组织惯性、商业化压力与技术路径共同作用的结果，并称：</p>
  <blockquote>
   <p>这场由开源模型引发的技术革命，正在倒逼大厂重新思考创新逻辑。若无法跳出既有框架，其技术话语权或将进一步削弱。&nbsp;</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d51d94661eba4efcab89ef03e32f5350@5888275_oswg229371oswg1080oswg1804_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/2d13vfq93sW9Ig63VrcpcQ" rel="noopener noreferrer nofollow" target="_blank">“AI蓝媒汇”</a>，作者：叶二，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156440683322121</id>
            <title>200亿，佛山要出资了</title>
            <link>https://www.36kr.com/p/3156440683322121</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156440683322121</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:05:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 产业基金, 佛山, 新兴产业, 投资  
<br><br>  
总结: 佛山市发布了总规模200亿元的佛山新动能产业基金，旨在推动新兴产业发展和产业转型升级。该基金将通过直接投资、母子基金和专项基金的形式，重点关注新型电力系统、机器人、新能源汽车等战略性新兴产业。佛山正处于新旧动能转换的关键阶段，设立产业基金有助于促进资本要素在金融市场和实体产业之间的流通。未来，佛山将发挥国资投资引领作用，确保投资的可持续性，推动传统与新兴产业的协调发展。 </div>
                        <hr>
                    
                    <p>产业基金开始热闹了。</p>
  <p>投资界-解码LP获悉，佛山市高质量发展大会日前召开，总规模200亿元的佛山新动能产业基金发布，连同N支市场化产业投资基金，组成佛山新动能产业基金体系。</p>
  <p>回顾过去一年，千亿产业基金接踵而至，城市之间发力新兴产业的迫切心情溢于言表。新年伊始，这场攸关城市命运的产业竞赛仍在继续。</p>
  <h2><strong>佛山发力：200亿，存续期15年</strong></h2>
  <p>佛山新动能产业基金体系具体有哪些内容？</p>
  <p>公告显示，该体系包括设立1支佛山新动能产业基金和N支市场化产业投资基金。其中，佛山新动能产业基金总规模200亿元，首期规模40亿元，存续期长达15年，彰显耐心资本。基金管理人则由佛山市国资委实控的佛山市金融投资控股有限公司担任。</p>
  <p>该基金以新动能命名，即向新质生产力要发展新动力。据悉，基金将通过“直接投资+母子基金+专项基金”的形式，重点聚焦产业链补链延链强链，着重投向三大重点领域——</p>
  <p>一是产业发展引导方向，重点投向新型电力系统装备、机器人、新能源汽车、新能源、新材料、新型储能、半导体芯片、新型显示、医药健康、低空经济等战略性新兴产业领域以及绿色氢能、生成式人工智能、细胞和基因治疗等未来产业领域的链主企业；</p>
  <p>二是科技创新专项方向，重点投向具备明显创新属性和成长潜力的种子期、初创期企业或项目；</p>
  <p>三是产业转型并购方向，重点投向先进制造业和传统优势产业的成长期、成熟期项目。</p>
  <p>而配套的N支市场化产业投资基金，将通过整合存量资源、引入社会资本联合设立。通过二者结合，佛山市将发挥市级统筹、国资投资引领作用，支持科技创新和产业转型升级。具体说来，即计划通过5年左右时间，推动形成覆盖企业全生命周期、突出重点投向、在市场上有一定影响力、规模不低于1200亿元的产业基金矩阵，通过“投大投强”“投早投小”“投稳投增”相结合，不断塑造发展新动能新优势。</p>
  <p>为何要打造这样的产业基金体系？据了解，佛山正处于新旧动能转换的关键阶段，民间资金十分充裕，金融机构本外币存款余额近3万亿元，位居全国地级市前列，但其转化为资本要素的动力却明显不足。</p>
  <p>而产业基金的设立，则有利于畅通资本要素在金融市场和实体产业之间的流通渠道，推动更好融入全国统一大市场建设；同时聚焦重大战略、重点领域和市场不能充分发挥作用的薄弱环节，推动产融深度对接，发挥基金引领带动作用，支持现代化产业体系建设，加快培育发展新质生产力。</p>
  <p>接下来，佛山将发挥国资投资引领作用，最大限度让这些民间资金动起来、活起来，作为“耐心资本”和“战略资本”倒逼佛山产业结构调整，实现传统与新兴产业“两条腿走路”，以更长期主义的方式，确保投资可持续性。</p>
  <h2><strong>吹响产业号角</strong></h2>
  <p>人勤春来早，新的产业竞赛已经在开工第一天打响。</p>
  <p>正如今年广东在全省高质量发展大会上表示，将一手抓传统产业、优势产业巩固优化，一手抓新兴产业、未来产业培育壮大，聚焦人工智能和机器人两大领域集中发力，建设更具国际竞争力的现代化产业体系。</p>
  <p>同时，广东发布《广东省建设现代化产业体系2025年行动计划》，直接提出充分用好私募股权基金、耐心资本作用，巩固提升20个战略性产业集群，抢先布局发展人工智能、机器人、低空经济、生物制造等新兴产业和未来产业，打造更多万亿元级、千亿元级产业集群，迫切心情不言而喻。</p>
  <p>还有江苏。去年通过江苏省战略性新兴产业母基金，接连组建两批产业专项基金，出资超过900亿。而在日前召开的“一中心一基地一枢纽”建设推进会中，江苏省再次强调：更大力度发展新兴产业和未来产业，紧扣“51010”战略性新兴产业体系，深入开展强链补链延链，打造一批世界级战略性新兴产业集群。</p>
  <p>此前以3000亿“3+N”杭州产业基金集群出圈，杭州也在日前会议上将发展新质生产力、强化创新产业布局视作重要目标。Deepseek总部所在的拱墅区，将在今年引进五大产业生态圈重点项目15个、亿元以上产业项目60个，推进高新技术产业投资增长；走出宇树科技的滨江区，则以产业创新牵引新型工业化，壮大人工智能等产业集群，争创省级人形机器人未来产业先导区；而培育了游戏科学、云深处科技的西湖区，力争人工智能、生命健康、空天信息三大产业产值达2200亿元。</p>
  <p>湖南则召开招商引资工作座谈会，提出创新招商方法，结合湖南实际积极探索产业链招商、平台招商等好机制好办法，吸引更多生产要素，延续去年成立金芙蓉、推动“4X4”产业体系发展的节奏；重庆“新春第一会”实施以“33618”现代制造业集群为核心的现代化产业体系做大做强行动，推动优势主导产业、新兴产业未来产业、传统产业“智改数转绿色化”、现代服务业4个“集聚成势”。</p>
  <p>目之所及，浩浩荡荡。</p>
  <p>创投兴则产业兴，产业兴则城市强。新春号角吹响，谁能在新一轮产业争夺战中勇立潮头，谁就能在下一轮城市洗牌中抢占先机。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/e30DiJxqEG5lsfAZwgwOgQ" rel="noopener noreferrer nofollow" target="_blank">“解码LP”</a>，作者：岳笑笑，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156441158327046</id>
            <title>2025年首月开户数披露，超去年6个月份</title>
            <link>https://www.36kr.com/p/3156441158327046</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156441158327046</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:04:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: A股, 新开户, 投资者, 政策红利  
<br><br>  
总结: 2025年1月，A股市场个人投资者新开账户达156.3888万户，显示出市场稳健开局。尽管较2024年部分月份有所回落，但市场情绪依然热情。2025年新开户趋势将受到政策红利、科技投资和资金结构优化等多重因素影响。年轻投资者的涌入和机构资金的长期布局将共同塑造市场新格局。政策的持续释放和科技主线的共振将推动开户增长，A股市场正经历从规模扩张向高质量发展的转变。 </div>
                        <hr>
                    
                    <p>上交所最新披露2025年1月A股新开股票账户数据。</p>
  <blockquote>
   <p>数据显示，2025年1月个人投资者新开A股账户达156.3888万户，机构投资者新开户数为0.6097万户。尽管较2024年部分月份的高点有所回落，但这一数据仍显示出市场在新年开局阶段的稳健态势。</p>
  </blockquote>
  <p>如何看156万的开户数据？2024年有6个月新开户数在150万以上，结合春节因素，可见2025年开年的市场情绪相对热情。这其中，2024年最低开户数是在8月份，仅新增开户99万户，其他低于150万户的月份分别为2月（129万户）、4月（147万户）、5月（126万户）、6月（107万户）、7月（115万户）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0d7dd47f7dca4bd7b132453af9ed2850@5888275_oswg247732oswg1080oswg837_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>展望2025全年，A股新开户趋势将受政策红利释放、科技投资主线及长期资金入市资金结构优化等多重因素影响，年轻投资者的涌入与机构资金的长期布局，将共同塑造更具活力的市场新格局。</p>
  <h2><strong>2025年1月A股新开户平稳开局</strong></h2>
  <blockquote>
   <p>根据上交所披露的《股票账户新开户状况表》，2025年1月A股市场个人新开户数环比2024年12月的198.0910万户下降约21%，同比去年1月下降19.74%，这其中一个重要因素在于2025年春节假期部分在1月。春节假期是一个重要影响因素，去年2月的129.1945万户开户就是一个相对低位。</p>
  </blockquote>
  <p>机构投资者方面，0.6097万户的开户数较2024年12月的0.8194万户有所减少，但较2024年全年均值0.6457万户（机构A股开户数全年累计7.7488万户）仍处于合理区间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5d0a9348530f4d4ea926cdaac1c39844@5888275_oswg99928oswg1080oswg319_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值得注意的是，B股市场的新开户数进一步萎缩。2025年1月个人B股新开户仅0.0390万户，机构B股开户0.0017万户，延续了近年来B股市场流动性不足、投资者兴趣转移的趋势。</p>
  <h2><strong>2025年A股新开户趋势将受多重因素影响</strong></h2>
  <p>2025年开年新开户数的平稳开局，为全年市场发展奠定了基础。展望全年，A股新开户趋势将受政策延续性、科技投资主线及资金结构优化等多重因素影响。</p>
  <p>一方面，政策红利持续释放，提振市场信心，证监会2025年重点工作明确“稳字当头”，包括深化投融资改革、支持科技创新等，叠加个人养老金入市扩大，长期资金增量可期。此外，外资券商加速布局（如高盛、城堡证券申请牌照），外资流入与境内资金形成合力，进一步吸引机构和个人投资者入场。</p>
  <p>另一方面，科技主线与年轻化需求将共振。数据显示，高风险偏好的“Z世代”投资者占比翻倍，其偏好ETF、量化产品等工具，推动被动投资占比提升。政策对“新质生产力”的倾斜（如AI、机器人）或成为2025年开户增长的新引擎。</p>
  <p>与此同时，A股资金供需将持续优化，2025年预计险资等增量资金规模达千亿元级别，ETF持续成为主力增量来源，为散户提供低门槛入场渠道。同时，减持新规抑制大股东抛售，解禁规模低位运行，市场稳定性增强，有利于吸引中长期投资者。</p>
  <p>当下A股市场正经历从规模扩张向高质量发展的深刻转变。新开户数据的稳健增长，既是市场活力的体现，也是投资者对中国经济长期向好的信心投票。未来，在政策红利释放、科技创新驱动、国际化进程提速的多重助力下，A股有望成为全球资本配置的重要目的地，为投资者创造可持续的价值回报。</p>
  <h2><strong>回顾：政策催化2024年开户潮</strong></h2>
  <p>回顾2024年，A股新开户数据呈现明显的“波浪式”特征。从全年来看，个人投资者新开A股账户累计达2492.1440万户，机构账户7.7488万户，其中，2024年10月个人开户数飙升至683.9747万户，单月数据远超其他月份，成为全年最大亮点。</p>
  <p>2024年9月，一揽子政策组合拳落地，直接推动10月新开户数飙升至683.97万户，单月数据超过前五个月总和。政策红利释放叠加股市赚钱效应，吸引大量新股民入场，券商一度因“开户潮”加班应对。</p>
  <p>从开户结构来看，2024新开户投资者中，“85后”和“90后”占比超六成，“00后”参与度快速提升，30岁以下投资者占比从政策前的15%跃升至30%。线上开户渠道（如支付宝接入）成为重要推手，凸显年轻群体对便捷化服务的偏好。</p>
  <p>2024年新增开户从开户渠道、年龄段、入金情况、投资品种以及投资方向等方面，都展现出多样化。不同年龄段的投资者通过多元化的开户渠道涌入市场，各自有着不同的投资风格和偏好。在入金和投资方向上，虽然整体表现出一定的谨慎，但也不乏对市场热点和政策导向的积极响应。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/mzy57s9nEs-oyYPOtu5I5g" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”</a>，作者：王晨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156396318129670</id>
            <title>Deep Seek爆火后，AI军备竞赛2.0要来了吗？</title>
            <link>https://www.36kr.com/p/3156396318129670</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156396318129670</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:57:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <Deep Seek, 人工智能, AI军备竞赛, 薪资待遇>
<br>
<br>
总结: Deep Seek在春节期间引发了广泛关注，成为中美苹果免费应用排行榜的第一名，超越了Chat GPT。其以低训练成本实现与顶级AI模型相媲美的性能，促使科技股大幅波动。多家科技巨头宣布与Deep Seek合作，显示出市场对其技术的认可。Deep Seek的团队薪资待遇较高，吸引了大量人才，尤其是在AI领域。与此同时，Deep Seek也面临着仿冒网站和不法课程的挑战，提醒用户提高警惕。 </div>
                        <hr>
                    
                    <p>在春节期间，唯一能和“赛博秧歌队”争抢热度的选手，或许只有Deep Seek了。</p>
  <p>毕竟前者为我们带来了来自硅基生命的“生理震撼”；后者为我们带来了来自硅基生命的“智力震撼”。</p>
  <h2><strong>AI军备竞赛 2.0要来了</strong></h2>
  <p>作为一家人工智能初创企业，来自杭州的深度求索可谓在春节期间出尽了风头。</p>
  <p>1月27日，该公司旗下应用Deep Seek冲上中美苹果免费应用排行榜第一名，在力压Chat GPT成为各地用户心目中的“AI一哥”之余，为美国科技股带来了行业巨震。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_798e252aede341009aedff1bd2dcde07@5322854_oswg149080oswg646oswg520_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在数据层面，芯片巨头英伟达当日股价暴跌近17%、半导体公司AMD股价下跌6%、博通公司股价下跌17%，微软、Meta、谷歌母公司Alphabet等耳熟能详的名字，也均在本起事件中出现了不同程度的股价波动。</p>
  <p>究其原因，是因为DeepSeek-V3以极低的训练成本换来了同Claude Sonnet 3.5、GPT-4o等业内顶级模型相媲美的性能。用摆在眼前的产品让世界各地的AI企业、科技公司意识到盲目堆积算力本质上是一种“力大砖飞”的行为，是对公司资金储备、投资人注资的盲目消耗。</p>
  <p>毕竟除DeepSeek-V3外，在两个月内研发、基础计算能力投资不到600万美元的DeepSeek-R1同样可以和那些花费数亿、数十亿美元所研发的模型“掰掰手腕”。 再一次用实力证明了“足够精巧的算法”可以实现性能与成本的平衡，让人工智能模型的开发成本不再以“亿”为单位。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5ac1ba5d205e4c03add677c57355d73a@5322854_oswg690582oswg660oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>市场是敏锐的，即便Deep Seek刚刚引发了美国科技股巨震，但这仍不能撼动海外企业同其合作的热情。</p>
  <p>江苏省科协在2月6日发布的文章指出，目前英伟达、微软、亚马逊这三家老牌科技巨头，已经宣布了自己和Deep Seek达成合作的消息，正式决定接入DeepSeek-R1用以提升自己在AI时代的产品竞争力。</p>
  <p>另在国内市场。</p>
  <p>人民邮电报在2月7日发布的文章也指出，三大运营商（中国移动、中国联通、中国电信）已宣布全面接入Deep Seek，并希望将其同自身平台、资源相融合。以此在打通Deep Seek多场景、多产品应用生态的同时，加速“AI普惠”这一愿景的实现进程。</p>
  <h2><strong>Deep Seek薪资待遇曝光</strong></h2>
  <p>在这段时间里引发网友关注的，不仅有Deep Seek系列模型的交互能力，还有Deep Seek团队成员的工资待遇。</p>
  <p>通过对Deep Seek的母公司幻方量化进行调研，有媒体发现其当下招聘的重心分别为数据研发工程师、深度学习研究员、核心系统研发工程师，工作地点则多在杭州或北京。</p>
  <p>在薪资待遇层面，公司除采用“14薪”制度外，还为大部分岗位提供了2万+/月的起薪。至于“深度学习研究员（AGI）”这类人才竞争更激烈的岗位，其月薪待遇更是被推上了8-10万/月。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a021e114e11f485a9ea9a5c3a3e1be47@5322854_oswg143034oswg694oswg552_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此以外，在Deep Seek团队内薪资相对较高的岗位还有数据研发工程师、核心系统研发工程师，其薪资范围分别在4-7万/月、7-8万/月。甚至AGI岗位实习生的工资也高达500-1000/每天，算下来可轻松实现“月薪上万”的人生目标。</p>
  <p>值得一提的是，此前雷军以千万年薪为代价挖来的“AI天才少女”罗福莉，其另一层身份便是Deep Seek团队的前成员（她曾以深度学习研究员的身份参与了DeepSeek-V2的开发项目）。雷军将罗福莉招致麾下担任小米AI大模型团队领导者的决定，也在一定程度上向我们展现了当下各科技公司对Deep Seek成员的认可度如何。</p>
  <p>《2024年度人才迁徙报告》指出，在2024年的TOP 20热招岗位中，有5个同AI相关场景有关。其中算法工程师、大模型算法、自然语言处理、人工智能工程师等岗位均属于热门职位。</p>
  <p>另截止到2024年12月，中国的生成式人工智能产品用户规模已高达2.49亿人，约占整体人口的17.7%。在巨大的用户需求、用户规模面前，当前就业市场的大模型、人工智能相关人才储备也略显不足。以至于有行业报告预测在2030年，中国的AI人才缺口将高达400万。</p>
  <p>以上种种信息也让我们意识到，在未来相当长的一段时间内，不仅人工智能专业会成为广大学生的T1级选择；其相关赛道员工的待遇，也将随着用户规模、需求的进一步放大而成为众人羡慕的对象。</p>
  <h2><strong>AI也逃不过人红是非多</strong></h2>
  <p>俗话说人红是非多，AI也不例外。</p>
  <p>爆火的Deep Seek不仅吸引了投资者和常规用户的目光，还吸引到了一小撮不怀好意的人。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2b3e6414a93b435887ca332bd8fb7cc2@5322854_oswg60555oswg915oswg420_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2月6日，奇安信发布报告表示在2024年12月1日-2025年2月3日这一区间内，共出现了2650个仿冒Deep Seek的网站。而这些躲在“山寨网站”背后的人，或是希望借Deep Seek之名窃取个人信息，或是欲披着Deep Seek的“马甲”去传播恶意软件骗取订阅费用。</p>
  <p>另除注册钓鱼网站外，目前市面上还有大量打着“Deep Seek带你躺着赚钱” “如何用Deep Seek赚到100万”等旗号的付费课程。甚至连AI爱好者平日里进行交流的社区，也有人趁机推出了Deep Seek的付费交流群，以“缴纳会员费和业内大佬互动交流”的名义进行敛财。</p>
  <p>这些情况的出现，也在提醒着我们对于普通人而言，想要玩好Deep Seek的第一步也是最重要的一步，就是学会甄别互联网上的信息，帮自己规避那些山寨网站和把“割韭菜”三个字写在脸上的付费教程。</p>
  <p>正如中国通信标准化协会互动媒体标准推进委员会副主席包冉所言，普通用户根本不需要去购买所谓的教程，因为使用Deep Seek不需要再像之前一样打磨提示词，现在各大主流AI都可以直接用自然语言与其交流。</p>
  <p>在过去，AI付费教程崛起的核心概念便是信息差的存在。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_02df10e948a344c7b7be03c1b1e69005@5322854_oswg138144oswg536oswg654_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>由于技术的相对不成熟，当时的模型往往需要用户输入特定的指令集才能得到应有的反馈。所以人们才会去总结自己和AI对话的经验，将其编撰成特定的话术和行文格式，帮助小白用户提升自己的使用体验。</p>
  <p>但随着模型蒸馏、数据训练进程的全面展开，今天Deep Seek的对话能力已经得到了充分升级。所谓的“结构化对话教程”已经成为了过去式，用户只需要进行简单的口语化、日常化指示就能得到自己想要的反馈。</p>
  <p>更别提市面上有不少AI培训课的内容仅仅是对互联网公开信息的拼凑，部分卖家完全不在乎内容的质量如何，他们不过是想赶在“淘金热”到来之际发上一笔“铲子财”罢了。</p>
  <p><strong>参考：</strong></p>
  <p>江苏省科协：三家企业同日宣布接入 DeepSeek，AI 领域竞争进入新阶段</p>
  <p>人民邮电报：三大运营商全面接入DeepSeek加速AI普惠发展进程</p>
  <p>上海杨浦：DeepSeek高薪招人：实习生月入上万，研究员年薪百万！这类人才缺口400万→</p>
  <p>齐鲁壹点：2000多个山寨DeepSeek网站出现，DeepSeek回应来了！</p>
  <p>极目新闻：第一波用DeepSeek“搞钱”的人出现了</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA5MTI5NDgxNA==&amp;tempkey=MTMwOF9ocVUyV2d3Y2xtZzlQd0FkWFhMYkhaOG9BcVY2eVJDRXgwTnJyQ2x2TlRXX1JmbUI1cjRacHBONENmVDFwRWxaNVljRncyV1VXc0IyaHJfRW5MdUhma2ZGeDRYTTkwa0h1cUU2N0oxZVg0anBvMmpXM0dGLWtqaF82akV2NUhFVXo2UExWLWhiN1kzcGpQLW9Ha0FOcE1CQ0lmanByRnpmQUdjd25Rfn4%3D&amp;chksm=0afe0cab3d8985bd05203c857d14b54f5e6ae4eacbd9381364d929ef2ebb922113177d158630&amp;scene=0&amp;xtrack=1&amp;subscene=7#wechat_redirect" rel="noopener noreferrer nofollow" target="_blank">“互联网那些事”</a>，作者：互联网那些事，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156385750368002</id>
            <title>15年来，“谷歌们”与中国未“脱钩”</title>
            <link>https://www.36kr.com/p/3156385750368002</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156385750368002</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:54:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <谷歌, 反垄断, 出海, 开源>
<br>
<br>
总结: 文章讨论了谷歌在中国市场的反垄断调查及其与中国企业的商业关系。尽管谷歌在2010年退出中国市场，但其在华收入依然增长，尤其是与字节跳动的合作。文章还提到，Tiktok等中国企业在全球市场的迅速崛起，显示出中国企业出海的趋势与能力。与此同时，开源技术的合作也在不断深化，尤其是在安卓生态中，中国企业通过开源降低了开发成本并推动了技术进步。整体来看，全球化与技术合作仍是推动商业发展的重要因素。 </div>
                        <hr>
                    
                    <p>2月4日，市场监管总局官方宣布，对谷歌公司展开反垄断调查。没错，就是美国那个谷歌，虽然新闻不少，但好像跟中国用户没什么关系，他怎么就垄断了？</p>
  <p>媒体分析，谷歌的“垄断”可以涉及在线广告领域，也可能涉及安卓手机系统方面。</p>
  <p>这条新闻唤起了很多人一个久远的回忆。2010年，谷歌宣布退出中国市场，谷歌搜索搬至香港。因此，谷歌好像错过了中国移动互联网大爆发的黄金时代。</p>
  <p>与谷歌境遇相似，全球规模和市值最大的企业中，市值1.76万亿美元的Meta（Facebook）和市值2.5万亿美元的亚马逊 —— 一个挤破头也没有挤进中国市场，一个节节败退，已经停止运营。</p>
  <p>但是，商业与技术总是卷起狂风，难以阻挡。从2010年到现在这15年来，谷歌、Meta、亚马逊与中国从未“脱钩”，因为大家共同活在历史的进程中。</p>
  <h2>出海浪潮下，商业合作永不眠</h2>
  <p>2018年是一个有趣的年份。这一份，特朗普正式对华发起了贸易战。中美的经贸关系进入了一个新阶段，很多人断言，中美关系“再也回不去了”。</p>
  <p>然而，也就是这一年，据The information 报道，谷歌在华收入增长60%，成为了过去15年间增长最快的一年。</p>
  <p>为什么这一年增长如此迅猛？当年，谷歌最大的中国客户是字节跳动，那正是抖音海外版Tiktok强势出海的时候。那年谷歌在大中华区（中国大陆+港澳台）收入30多亿美元，其中，字节跳动向谷歌支付了3亿美元，占10%。</p>
  <p>Tiktok在2018年开启了疯狂出海之旅。谷歌旗下的YouTube，Meta旗下的Facebook、Instagram以及面向年轻人的社交平台Snap上疯狂投放广告。 MediaRadar 数据，2018至2020年三年间，Tiktok的全球营销总费用高达50亿美元。</p>
  <p>疯狂营销的同时，Tiktok也迎来了疯狂的增长。2018年，Tiktok的月活用户同比增长近3倍。Statista数据，2024年4月，Tiktok月活用户数超过15.82亿，成为全球第5大最受欢迎的社交App，前4名分别是Facebook、YouTube、Instagram和WhatsApp。</p>
  <p>明明开打贸易战，为什么Tiktok仍能迅猛出海？其实，2018年，抖音的月活用户突破5亿，正式超越快手，成为中国最大的短视频平台。于是，验证了产品和商业模式之后，抖音的创始人张一鸣相信，地球人其实都一样，挡不住短视频和推荐算法的诱惑，所以挥师出海。</p>
  <p>基于自身和行业的需求出海，而并不受到贸易战的影响，这是2018年中国企业出海的一个新特点。</p>
  <p>Tiktok也是中国企业加速出海的缩影。过去15年，中国企业不再局限于做跨国企业的供货商。他们走向消费市场，直面消费者。谷歌、Facebook，就是中国企业出海的最大广告平台，亚马逊，则是中国商品的最大海外销售平台。三者分工合作，联通全球市场。</p>
  <p>谷歌、Meta、亚马逊都在中国大陆保留了团队。从公开信息上看，谷歌的团队规模最大，广告营销团队就超过100人，全国有20多个广告中心。在北京海淀区的融科资讯大厦，谷歌中国办公室占据了5-7层。同时，谷歌在中国还有庞大的代理商体系。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_09cdb147c53242f19814c90b190d449b@14303255_oswg241668oswg1080oswg958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（谷歌中国办公室位于北京海淀的融科大厦，据悉，AI明星企业深度求索的北京办公室，也在这座楼里。）</p>
  <p>不过，谷歌退出中国市场，也留下了后遗症。一位做线上营销的朋友说，跟客户推荐在谷歌做营销，有两个难点，一是客户以为google已经退出中国了，二是以为google只有搜索引擎。</p>
  <p>除了搜索引擎，谷歌系的Youtube、Google Play应用商店，Meta旗下的Facebook、Instagram、WhatsApp和Messenger，以及全球最大的电商平台亚马逊，都是重要的在线营销平台。</p>
  <p>不管怎么说，出海企业利用三巨头阵地，走向海外市场。中国企业的拿手好戏，就是通过广告营销和买量，推动新的应用快速起步。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fed272f296134992831315df0bc90f11@14303255_oswg62377oswg1034oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（Temu在超级碗投放的广告）</p>
  <p>外媒曾经震惊到，拼多多旗下的Temu2023年在美国进行了30亿美元的广告投放（伯恩斯坦研究公司估算数据），而另一家市场机构Morketing则把Temu列为了2023年美国十大广告主之一，排在迪士尼之前。</p>
  <p>Temu的核心广告语是“像亿万富翁一样购物”，通过程序化广告等不同的投放方式，这句话不断投放到各类社交媒体上，投放到网页广告上，甚至投放到美国春晚“超级碗”上，并根据数据反馈不断优化效果。</p>
  <p>与Temu在海外相爱相杀的是服饰电商Shein。Shein是互联网版的Zara，通过快速模仿，并快速在instagram、facebook上请网红带货，迅速走红。</p>
  <p>Shein是互联网版的Zara，通过以女装为主的快时尚服饰起家，它充分利用Instagram、Facebook、YouTube等主流社交媒体平台，联合各路网红，进行品牌推广。Shein打通了“种草+电商”的模式闭环，吸引了大量年轻消费者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0fe4f5cbd7b3409dbf1bda9f694ac662@14303255_oswg58404oswg803oswg319_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（Shein在海外的增长数据）</p>
  <p>尽管Shein经常被称为“新加坡公司”，但其供应链、制造和研发核心仍然在中国。2023年，Shein登上了全球购物App下载榜的首位。有预测称，Shein2025年的营收将达到585亿美元，并可能在今年一季度以505亿英镑的估值在伦敦证交所上市。</p>
  <p>Temu和Shein，二者背靠的都是全球规模最大，生产能力最强的制造业大国，面向的又是北美这个全球最大的消费市场。2018年以来，虽然贸易战从未停下，但随着2020年“口罩”后的美联储大放水，中国对外贸易顺差加大，Temu和Shein无疑顺应了这一历史进程。</p>
  <p>同样，还有众多中国品牌也参与到这一进程中。不过，他们无力像Shein那样自建网络平台，通过亚马逊销售一直是首选。</p>
  <p>2021年，B站网红UP主“老师好我叫何同学”改装了一款升降办公桌，加上了可移动的无线充电接口、蓝牙音箱等一系列智能化改装和设计，视频迅速走红。这款升降桌的原型来自上市公司乐歌股份，乐歌的股价随之涨停。</p>
  <p>此前，乐歌股份在国内并不出圈，它是一家典型的在海外先富起来的中国品牌。乐歌旗下的品牌flexispot一直在亚马逊升降桌品类中稳居榜首。</p>
  <p>类似这样的品牌很多，大疆无人机、安克Anker等，在智能家居设备（如扫地机器人）、家电、手机配件、服饰等品类上，中国产品都已经打响了品牌。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8273910399bc4c60aa5bf4e8ace621ac@14303255_oswg404846oswg1080oswg683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图片说明：亚马逊销售的大疆无人机）</p>
  <p>更多白牌产品，则通过跨境电商卖家的努力，同样在亚马逊畅销。据Marketplace Pulse的研究，中国卖家占亚马逊美国站TOP卖家的近50%。</p>
  <p>近年，中国的娱乐产品正在冲击欧美市场。中国游戏行业出已经成风之外，过去两年，短剧也冒出了头。</p>
  <p>用大众文化产品冲击美国市场，这是过去一百年，中国人难以想象的一种变化。这大概也论证了，人类在底层需求上是相通的。</p>
  <p>谷歌、Meta和亚马逊，无论自己的C端业务在国内发展的情况如何，始终抓紧中国市场。</p>
  <p>早在10年前，白熊观察员作为财经记者，一直在跟踪跨境电商发展。在深圳，一个跨境电商行业协会主办的年会上，谷歌、亚马逊和Meta的销售代表，先后在不同的分论坛上登场演讲，推销自己的产品和服务。</p>
  <p>活动的主要参会者，是广东、福建等地数以百名各类跨境电商企业的老板们。</p>
  <p>那正是奥巴马时代，经历了08年金融危机后，美联储开足水龙头，持续放水。另一方面，具备超强制造能力的中国企业，生产的产品在国内难以消化，出海仍然是最佳选择。</p>
  <p>虽然也有一些类似乐歌、安克这样的企业，在出海成功后，又杀回了国内市场，但更多的企业还是在加速出海。某种程度上说，2021年以前，中国消费者的消费欲主要在楼市上，2021年之后，中国消费者对房子的消费欲突然就消失了，而且并没挪到别的地方——虽然大家还是愿意看《哪吒2》这样的好电影，但“内需”确实不够理想，这种现状也引发了无数争议。</p>
  <p>国信证券研报数据，从2019年起，谷歌、Meta和亚马逊三巨头在全球广告市场（不包括中国地区）的占比从41%增长到60%左右。这形成了事实上的垄断。彭博社预计，2024年谷歌的广告收入为2639亿美元，Meta预计为1595亿美元，亚马逊预计为563亿美元。</p>
  <p>特别值得注意的是亚马逊，依靠电商广告收入增长，它最近三年的年复合增长率达到60%。</p>
  <p>三巨头的成功中，中国的企业贡献不少。Meta首席财务官Susan Li曾在财报会上表示，“2023年度，来自中国客户的广告投放方投入构成了Meta总收入的10%，并贡献了Meta 5%的收入增量。其中，在线电商和电子游戏公司是中国厂商的投放主力。”</p>
  <p>亚马逊的数据显示，中国企业贡献了第三方服务收入（2023年为1400亿美元）的“很大一部分”。同时，中国品牌出海也是亚马逊广告收入增长的重要动力。</p>
  <p>不过谷歌没有透露来自中国的收入占比。这两天有自媒体称，中国企业出海广告有“67%流向谷歌系平台”，这个数据很可能是AI编造的，因为谷歌的广告市场份额只有不到三成。另一方面，中国企业更是在不断开拓新的阵地，避免对合作伙伴形成依赖。2019年，Tiktok是美国年轻人喜爱的社交应用Snap最大的广告主，同时它在线下也进行了大规模的推广。</p>
  <p>此外，谷歌云和AWS等云服务与中国企业的合作也不断深化。据公开报道，谷歌云与国内多家企业联合推出AI、大数据等解决方案；亚马逊AWS帮助中国企业实现全球云部署，合作规模已达数十亿美元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0ac5dded6e664dafa508e74663820c41@14303255_oswg254327oswg361oswg501_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当然，中国企业的崛起，也在挑战着三巨头的垄断地位。</p>
  <p>Tiktok顶着美国政府的封禁大棒，也成为了重要的广告投放平台。据《晚点LatePost》报道，2021年Tiktok的广告收入约为40亿美元，而市场机构测算，2023年它的广告收入可能已达到132亿美元，2024年预计能有300亿美元。随着Tiktok等平台的崛起，2022年以来，谷歌和Meta在美国市场的广告份额已经跌破了50%。</p>
  <p>Temu和Shein的崛起，已经强烈冲击了美国同行。第三方数据，Temu用了三年时间杀到了美国电商的第六名，并占据了17%的美国市场份额。Shein成为美国五大在线时尚电商之一，占据快时尚服饰在线消费市场的40%份额。</p>
  <p>这本应该是商业社会的常态，竞争与合作永远是共生的，也永远不会停歇。然而，今年特朗普再次上台之后，贸易战跟七年前已不可同日而语。就在昨天，白宫叫停了中国寄往美国的“邮政小包”免税政策。通过邮政小包，以较低的运费将商品卖到美国，这正是跨境电商控制成本的秘诀。尽管这个政策维持了半天就暂停了，</p>
  <p>历史虽然常常相似，但很少真正重复，这一次又会如何发展？</p>
  <h2>技术合作，在开源的旗帜下</h2>
  <p>近年，国产手机崛起，已经一统除了苹果之外的手机市场，似乎已经没有谷歌什么事，当然我说的是在国内。</p>
  <p>但安卓，仍然是大家绕不过去的名字。有人说，谷歌可能是中国用户最多的美国公司。不过这个说法很不准确，因为安卓本身是一个开源生态。</p>
  <p>开源社区起源于1980年代，开源软件往往会公开源代码，参与者可以自由查看、修改和分发。开源社区不仅有各类技术极客，也有各种科技企业。包括谷歌、Meta和亚马逊三巨头，也包括许多中国企业。企业积极参与开源生态，因为这是一种把蛋糕做大的方式。</p>
  <p>2007 年 11 月，Google 联合 84 家硬件制造商、软件开发商、电信运营商及芯片供应商成立了开放手持设备联盟（Open Handset Alliance），并打造了Android开放平台。</p>
  <p>2007年，正是全球化快速扩张阶段，中国等新兴国家不断融入世界贸易体系，这也是WTO作用最大化的阶段。与此同时，移动互联网时代兴起，新兴国家也在积极参与信息技术的变革，安卓开源操作系统为新兴国家参与移动互联网时代提供了便利，在经济和技术变革进程交织推进的时代里，它得到了各国的积极响应。</p>
  <p>不过，也就是2007年，中、印、俄、巴西等国家展开了多次双边和多边会谈，这为2009年“金砖国家峰人”（BRICS）做好的准备，新兴国家开始争取更大的话语权。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c0508a0270b0496e964b8450869d6777@14303255_oswg15950oswg600oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Android 的核心——AOSP，允许任何人免费使用、修改和再分发，全球的开发者和厂商都可以在此基础上定制和改进自己的操作系统。</p>
  <p>所以，谷歌虽然主导了安卓操作系统，但并不拥有安卓的用户。因为随着市场发展，单纯使用原生安卓并不足以形成竞争优势。国内企业借助安卓的开源生态，大幅定制用户界面和系统功能，形成了如 MIUI（小米）、EMUI（华为）、ColorOS（OPPO）、Funtouch OS（vivo）等品牌定制系统。这些系统在视觉和交互体验上更加符合中国消费者的审美和使用习惯。</p>
  <p>目前安卓生态已经成为了移动市场的绝对主流。安卓的市场份额，从2008年的不到1%增长到如今绝占85%。中国的主流手机厂商，都是安卓生态的一部分，即使像华为如今开始了自研手机操作系统。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5e9f101805e54fcb8f95305895d05b2a@14303255_oswg25118oswg1011oswg324_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>共建生态，本质就是一种全球的技术合作。</p>
  <p>以前有一种论调：在安卓的开源生态领域，中国企业贡献不大，因为安卓系统的底层代码，绝大多数是谷歌、高通、三星等企业贡献的，中国企业参与甚少。</p>
  <p>这是事实的一部分，而非全部。中国企业确实在参与安卓生态。对于中国企业来说，利用开源安卓系统，低操了作系统开发的成本和风险，企业可以将更多资源投入到软件优化和生态服务构建中。</p>
  <p>中国企业也在应用层、服务和中间件开发等做了不少开发，繁荣了安卓生态。</p>
  <p>例如，华为开发的EROFS文件系统，通过透明压缩和只读设计提升了手机启动速度和安全性，这个文件体系统已经开源。</p>
  <p>小米则利用MiCode平台，开源了大量内核定制、MACE神经网络计算框架、Open-Falcon监控系统和Pegasus分布式存储系统。</p>
  <p>开源可以说是一种商业选择，但也确实是一种技术文化。</p>
  <p>但是伴随着全球化成长起来的技术文化传统，遇到了新的问题。在贸易战加剧的背景下，“脱钩”成为媒体的高频词。高层在博弈，大众很担忧，所以，研发更加“自主可控”，更加“安全”的信息操作系统，变成一种必然。</p>
  <p>华为率先推出了完全自研的鸿蒙操作系统，并最终脱离安卓生态，其它厂商也开始跟进。安卓联盟虽然没有瓦解，但很少有厂商主动宣传。</p>
  <p>但这并不意味着开源合作时代的终结，相反，可能才刚刚开始。随着生成式AI时代的到来，开源成了通往人工智能殿堂的一条大道。中国也成为了少数站在生成式AI开源前沿的国家。</p>
  <p>在安卓时代，谷歌、高通完善安卓底层源代码，华为、小米研大量新应用，这似乎是一种理所应当的局面。这种局面在AI大模型时代刚刚到来的时候，也沿用了下去，甚至像朱啸虎这样的资深投资人，把这种模式当成最合适的道路。不过，没过多久，中国的工程师们就不再只局限于“做应用”了。</p>
  <p>2022年，当ChatGPT横扫AI大模型领域之时，也是闭源大模型遥遥领先于开源之日。那时，Meta及其创始人扎克伯格，却成了开源领域的旗手。扎克伯格率先将Llama1、Llama2模型开源，其中Llama2模型是当时全球最大的开源模型，性能上也接近ChatGPT4.</p>
  <p>为什么是他？这可以说是Meta的一种商业策略，也可以说是扎克伯格技术极客的底色。尽管在Facebook成功后，扎克伯格经常被媒体当作唯利是图的奸商。在生成式AI时代，扎克伯格对于技术前沿展现了很强的判断力。之后，更多的开源大模型涌在市场上，中国也出现了大模型“六小龙”等把研发AI大模型当成方向，而不只是做应用的公司。</p>
  <p>当然，热闹之下鱼龙混杂。也有一些公司，似乎在将Llama等开源模型改头换面，包装成“自研”的大模型，也就是所谓“套壳”。当时有一种说法叫“百模大战”，各类企业都号称做出了自己的“大模型”，但最后发现，套壳相当普遍。</p>
  <p>阿里巴巴前副总裁贾扬清就曾爆料了一家这样的企业，有人挖掘出，这家公司疑为李开复的创业项目“零一万物”的中英双语大模型“YI”。不过李开复很快发声称，不存在套壳、抄袭等行为，是从零开始训练，只是沿用了Llama的架构。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_94b285c8fa7543e48d2b68eb3aa2ba6d@14303255_oswg128659oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（Llama的本义是“羊驼”，颇有喜感的名字，图片为豆包AI生成）</p>
  <p>不管怎么说，如今，中国企业成为AI大模型领域开源生态最重要的贡献者。例如，2023年，阿里的通义千问Qwen大模型打响了开源第一枪。之后阿里将Qwen大模型各类不同的版本进行了全家桶式的开源。业界普遍认为，阿里开源的Qwen全家桶，性能不逊于Llama。</p>
  <p>刚刚过去的这个春节，中国AI企业深度求索的开源大模型DeepSeek-R1引发生成式AI领域的一次地震，AI大模型算是一次真正意义上的“出圈”。DeepSeek-R1也是一个开源大模型。</p>
  <p>DeepSeek-R1 在工程技术方面实现了一次突破，采用高效的模型压缩与优化技术，证明了可以用更少的算力，实现更强的性能，显著降低了训练与部署成本。</p>
  <p>开源生态正在越来越强盛。2月6日，有“AI教母”之称的李飞飞及其团队，号称只用了不到50美元，就训练出一个名为S1的模型，它在数学和编码能力能够比肩OpenAI的o1和DeepSeek的R1等尖端推理模型。研究人员表示，s1是通过蒸馏法由谷歌推理模型Gemini 2.0 Flash Thinking Experimental提炼出来的，谷歌的Flashi Thinking正是谷歌发布的一个具备很强能力的开源模型。</p>
  <p>此前，一直坚守闭源模型领域李彦宏在发布上说，“开源模型会越来越落后”。这个观点引发了很大的争议，现实给了他一个新的回应。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_765bc4dd9cb740e68d02aca2b2510c27@14303255_oswg37582oswg655oswg452_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图片为文心一言发布会截图）</p>
  <p>开源的繁荣，为人们提供了更多的探索玩法。其实，DeepSeek此前发布的V3版本大模型已经引发了业界的广泛关注。不同类型的优秀开源大模型，甚至可以通过技术手段进行整合。</p>
  <p>例如，DeepSeek-R1-Distil-Qwen-7B就是基于Qwen-7B进行蒸馏优化的推理模型，其参数量为7B，专注于数学、代码和推理任务，它利用R1模型将通义千问的Qwen核心能力提取并得到更小的模型，同时显著利用的DeepSeek-R1系列模型在推理速度和资源消耗上的优势。</p>
  <p>DeepSeek-R1-Distil-Qwen-7B不仅免费开放，还支持开发者进行修改和二次开发。一位金融公司的IT负责人向白熊观察员证实，这种小模型已经被它们应用在需要快速反应的数据分析领域。</p>
  <p>开源生态的重要价值，不仅在于提供了有用的东西，还在于避免踩雷。在信息不畅通的时代，“重复造轮子”是一个常态，前人走的坑，后人却需要再走一遍，浪费了大量的时间、金钱和精力。</p>
  <p>DeepSeek的成功，就是中国企业在研发过程中首次站到前沿技术的潮头，去探索未知的领域，主动试错，主动“蹚雷”。DeepSeek的成果，将给行业带来很多新的启发。</p>
  <p>另一方面，DeepSeek的创始人梁文锋在接受采访的时候说，要实现AGI，不按照Llama的结构走，这样才能在有限的资源下，实现更强的模型能力。梁文锋踩在了前人的肩膀上，实现了一次跨越。</p>
  <p>政治局势的变化，不仅引起贸易战，更引发了“技术战”。美国等一些国家的政客开始呼吁审查DeepSeek，开源生态的未来也蒙上了一层阴影。</p>
  <p>从历史上看，每一次技术革命后，技术扩散都是必然，问题是时间。</p>
  <h2>白熊观察：</h2>
  <p>从历史和现实看，全球化可能是个无法真正逆转的过程。全球化推动了商业和技术的发展，它也让人们紧密联系到了一起。</p>
  <p>过去三十年，全球化是全球技术进步、商业繁荣最重要的推动力之一，少数国家没有汇入全球化浪潮，不管嘴上怎么说自己国民生活幸福，天天被太阳照耀，恐怕都难以让人羡慕。</p>
  <p>如今，全球化陷入暂时的波折，一些人以狭隘的政治利益为借口，破坏全球化合作，制造分裂和对抗，这恐怕是一股逆流。</p>
  <p>是的，我说的就是美国的特朗普。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/sdm6pxVxls0k-eJpURUjVg?token=846157393&amp;lang=zh_CN" rel="noopener noreferrer nofollow" target="_blank">“白熊观察员”</a>，作者：白熊观察员，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156385170521858</id>
            <title>Meta内部信息泄露，6款AI产品将到来，国内厂商如何应对？</title>
            <link>https://www.36kr.com/p/3156385170521858</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156385170521858</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:50:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, AI可穿戴设备, 内部备忘录, 竞争市场  
<br><br>  
总结: Meta首席技术官安德鲁·博斯沃思在内部备忘录中透露，Reality Labs部门计划在2025年推出6款AI可穿戴设备，以增强销售和用户参与度。备忘录强调2025年将是Meta的重要一年，尽管2024年已取得成功，但仍需进一步发展。国内厂商在Meta Ray-Ban智能眼镜热销后，面临激烈竞争，需依靠产品力和渠道合作来生存。各家厂商正通过提升硬实力和与传统眼镜品牌的合作，力争在即将到来的百镜大战中脱颖而出。 </div>
                        <hr>
                    
                    <blockquote>
   <p>泄露的不止是信息，还有Meta的野心</p>
  </blockquote>
  <p>近日，一份Meta泄露的内部备忘录被披露，该备忘录是由 Meta 首席技术官安德鲁·博斯沃思 (Andrew Bosworth) 撰写，备忘录中预告了其 Reality Labs 部门预计会推出6款AI可穿戴设备，以此扩大此前由Meta Ray-Ban所带来的优势。</p>
  <p>众所周知，得益于多模态 AI 大模型的推动，Ray-Ban Meta 的热销刺激，2025年 AI智能眼镜市场热度空前，众多厂商都在为百镜大战做着准备，而面对Meta的6款AI产品，最终谁能成功站稳脚步呢?</p>
  <h2><strong>Meta放大招，6款AI 可穿戴设备</strong></h2>
  <p>据Business Insider分享，这份备忘录的标题为“2025：伟大之年”，于去年 11 月发送给 Reality Labs 员工。这份备忘录很长，包含不少公司励志演讲以及2025年的大致计划。</p>
  <p>Reality Labs是Meta旗下负责Quest头显和Horizon软件平台、Ray-Ban Meta智能眼镜技术、以及AR眼镜和sEMG腕带输入设备研发的部门。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_effef0cb365f4f578d9257542451ce00@813924438_oswg130204oswg692oswg368_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在备忘录中，Bosworth称2025年是“我在Reality Labs八年来最关键的一年”，并告诉员工他们将推出6款左右的AI可穿戴设备来“推动销售、用户留存和参与度的全面增长”。“从数据上看，2024年是我们迄今为止最成功的一年，但我们并没有沾沾自喜，因为我们知道这还远远不够。我们还没有真正在世界上留下印记”，他宣称。</p>
  <p>从字面上理解，Bosworth 的备忘录中表明 Meta 有六款 AI 可穿戴设备——而且听起来它们都将于今年推出。结合此前的消息，Meta可能预计在 2025 年推出的产品可能包括：</p>
  <p><strong>1、马克·扎克伯格预告的第三代 Meta Ray-Ban 智能眼镜：</strong>据知情人士透露，新眼镜将在单侧镜片内嵌小型显示屏，虽然未透露具体规格，但结合"支持拍摄预览"的功能描述，行业推测该显示屏将采用全彩技术。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_53c8c61124b84edd96efcaac2384e6cd@813924438_oswg395720oswg648oswg518_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>2、AI 智能眼镜的 Oakley 版本：</strong>彭博社记者马克·古尔曼报道称，Meta和EssilorLuxottica计划在今年晚些时候通过Oakley Meta眼镜来扩展其智能眼镜产品阵容，Oakley眼镜的摄像头则位于中央，面向“骑行者和运动员”用户。</p>
  <p><strong>3、腕带：</strong>此前有消息称Meta正在测试一种让用户依靠腕带来控制眼镜的方法。该公司曾讨论过将该配件与Hypernova眼镜放在同一个盒子中，后者的镜框镜腿上也将有触摸控制。如果腕带配件不符合要求，镜腿方法将成为标准输入方法。这款腕带控制器类似于Meta去年展示的Orion原型AR眼镜所使用的控制器。</p>
  <p><strong>4、带有摄像头的耳机：</strong>去年The Information报道了Meta Platforms正在探索开发带有摄像头的AI耳机，这种耳机可能会用于识别物体和翻译外语。在内部，该项目名为Camerabuds，将摄像头和电池放入微型设备中可能会使耳机体积庞大，并有使其过热的风险。将隐蔽的摄像头安装到可穿戴设备上也可能引发隐私问题。</p>
  <p><strong>5、AI智能手表：</strong>早在2021年，The Verge就报道过Meta正在开发一款智能手表。据说该设备有两个摄像头：一个在前面用于视频通话，一个在后面用作运动摄像头，因为手表的主体可以很容易地从框架上拆卸下来。古尔曼认为这款手表可能想要与苹果产品竞争，可以与Hypernova配合使用，并显示用眼镜拍摄的照片。</p>
  <p>结合此前的消息，目前只猜测出了5款AI可穿戴设备，剩下的一种会是什么呢?或许只有5款，因为我们注意到备忘录中Bosworth所写的 “half a dozen” ，鉴于这句话取自泄露的内部备忘录而非官方声明，所以多方猜测所谓的6款可能只是粗略计算，而非确切的六种。</p>
  <p>这个名为《2025：伟大之年》的备忘录无疑彰显了Meta的野心以及2025年的来势汹汹。那么国内厂商又会如何应对呢?</p>
  <h2><strong>超越Meta的同时，与眼镜品牌合作</strong></h2>
  <p>事实上，尽管有的国内厂商在宣传上称自己早已有AI眼镜的相关计划，但这句话在Meta Ray-Ban 智能眼镜爆火后再说出来已经难以令人信服。</p>
  <p>但从竞争的角度看，无论是先于Meta还是跟注Meta，想要在百镜大战中存活下来，需要做的只有靠产品力说话。其中，将这一点看得最清楚的或许是雷鸟V3 AI拍摄眼镜。</p>
  <p>在雷鸟V3&nbsp;AI拍摄眼镜的发布会上，雷鸟将自身产品与Meta Ray-Ban进行了近乎全方位的对比。从第一人称拍摄、音质、AI等硬实力到充电速度、重量、乃至价格，都完成了对Meta Ray-Ban的超越。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7ab0f88a24104232aaa6a9a1f164c60d@813924438_oswg78848oswg715oswg346_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Meta在2025年将推出的多款AI可穿戴设备必然是优于曾经的明星产品Meta Ray-Ban，而想要在众多厂商押注AI眼镜以及曾经的明星产品续作下占据市场，超越与创新是为数不多的道路。</p>
  <p>而除了产品本身足够能打外，渠道也是国内厂商能够依靠的一大优势。AR厂商Rokid的AI+AR 眼镜——Rokid Glasses，选择与依视路旗下知名时尚眼镜品牌暴龙眼镜进行联名。</p>
  <p>雷鸟则更加“激进”，选择与博士眼镜成立合资公司，共同开发新一代 AI 眼镜。除此之外，星纪魅族、 XREAL、界环，李未可等AR眼镜厂商也都在不同程度上与博士眼镜有着紧密合作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_11647c5f18f74e8b9b2e2ba18ba9085b@813924438_oswg145670oswg659oswg396_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种合作意味着厂商们更加重视作为一副眼镜的基础体验，比如外观设计、佩戴体验以及验光配镜服务等。然后再是智能体验的融入，并借助传统眼镜品牌的渠道和品牌优势，让智能眼镜渗透到更广泛的消费者群体中。</p>
  <p>随着百镜大战的日益到来，各家厂商都试图通过增强硬实力的同时完善视光、设计、渠道的做法，力争在众多竞争者中脱颖而出。</p>
  <h2><strong>写在最后</strong></h2>
  <p>Meta的内部备忘录让我们看到了其野心之大，而国内厂商对此似乎早已准备好了应对办法，这场百镜大战中究竟是Meta守擂成功继续扩大优势，还是其它品牌异军突起抢占市场，科技旋涡也会持续关注相关动态。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/6YjO8LaYB7qeupOvkY-MUA" rel="noopener noreferrer nofollow" target="_blank">“科技旋涡”</a>，作者：科技旋涡，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156400790526725</id>
            <title>DeepSeek爆火后，美国科技巨头面临灵魂拷问</title>
            <link>https://www.36kr.com/p/3156400790526725</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156400790526725</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:27:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI投资, DeepSeek, 科技巨头, 资本支出  
<br><br>  
总结: 本文讨论了美股科技巨头在AI领域的大规模投资与中国初创公司DeepSeek推出的低成本AI模型之间的对比。DeepSeek以不到600万美元的成本推出的R1模型在某些方面表现出色，引发了对科技巨头们数百亿美元投资必要性的质疑。尽管高管们认为继续投资是满足AI需求的战略优势，但投资者对其回报的担忧日益加剧。DeepSeek的崛起被视为对全球AI竞争格局的影响，促使市场重新审视科技巨头的投资策略。 </div>
                        <hr>
                    
                    <blockquote>
   <p>在本次财报季，美股科技巨头们正面临一场严峻的拷问：在中国AI初创公司DeepSeek以不到600万美元成本推出可媲美OpenAI的R1模型后，大笔砸钱还有意义吗？</p>
  </blockquote>
  <p>在本轮财报季上，美股科技巨头们正面临一场严峻的拷问。</p>
  <p>一边，是Meta、谷歌、亚马逊等科技巨头继续着他们每家动辄<strong>数百亿美元规模</strong>的大手笔AI投资计划；另一边，是大洋彼岸的中国AI初创公司DeepSeek以<strong>不到600万美元</strong>的开发成本推出开源的R1模型，而在某些方面的表现甚至媲美OpenAI的o1模型。</p>
  <p>差距悬殊的资金规模对比，让华尔街和硅谷开始质疑，原本的假设：科技巨头们必须投入巨资在芯片和数据中心上才能构建尖端人工智能模型，真的还成立吗？</p>
  <h2><strong>大规模砸钱还有必要吗？</strong></h2>
  <p>今年初的财报季上，各大科技公司一如既往地宣布在AI领域投入巨资。而华尔街开始拿起放大镜，格外严肃地审视这些巨额资本支出计划，光四大科技巨头总计今年将投入约3200亿美元：</p>
  <blockquote>
   <p>Meta计划2025年资本投入600-650亿美元，用于推动人工智能战略。</p>
   <p>微软承诺今年投入800亿美元用于AI基础设施，以扩大其全球高性能数据中心网络，满足训练和运行AI模型所需的专用芯片需求。</p>
   <p>谷歌预计2025年将在资本支出方面投入750亿美元，较去年激增逾42.7%，比分析师预期高将近30%。</p>
   <p>亚马逊计划将今年的资本支出从去年的约830亿美元提高到1000亿美元。公司CFO表示，支出的增长“主要与AWS有关，包括支持对我们人工智能服务的需求，以及支持我们北美和国际部门的技术基础设施。”</p>
  </blockquote>
  <p>如果换在几个月前，这样数以百亿美元计的投资规模可能并不会引起华尔街太多的质疑，因为当时几乎所有人都信奉着一个假设：只有依靠大笔投资，才能在当前最重要的AI竞赛中拨得头筹。</p>
  <p>然而，在DeepSeek的AI模型的横空出世之后，这样的假设出现了裂痕。</p>
  <p>根据DeepSeek公开的数据，DeepSeek-V3这个参数量高达671B的大模型<strong>，在预训练阶段仅使用2048块GPU训练了2个月，且只花费557.6万美元。</strong>与此同时，该模型相比其他前沿大模型，性能却足以比肩乃至更优。</p>
  <p>在这样的背景下，很多投资者开始质疑：科技巨头们的大笔砸钱还有意义吗？</p>
  <h2><strong>质疑声已经响起</strong></h2>
  <p>上周，在DeepSeek-R1模型引发的震惊声中，美国科技股已经大跌。而本周，随着美股科技巨头们公布“大规模砸钱”计划，Meta、谷歌、亚马逊的股价几乎无一例外地立即遭到砸盘。在这背后，很显然能看出华尔街投资者们对于科技巨头们砸钱策略的质疑。</p>
  <p>Futurum Group 分析师丹尼尔·纽曼表示：“考虑到这些巨额开支，他们（美股科技巨头们）急需提高AI的收入回报，但目前发生的事情（DeepSeek）对美国来说是一个警钟……<strong>就目前而言，人工智能的资本支出实在太多，但消费却不足。”</strong></p>
  <p>Direxion资本市场主管Jake Behan表示：“资本支出开始让人感觉像是房间里的一只800磅重的大猩猩。现在的问题几乎不在于人工智能支出何时能够盈利，而在于它是否能够合理化。”</p>
  <p>在微软财报公布后，Valoir分析师 Rebecca Wettemann表示，DeepSeek 的崛起让一些投资者担心，微软可能因全力支持 OpenAI 及其基础设施而押错了宝：</p>
  <blockquote>
   <p>"我们不认为所有公司都会立即转向DeepSeek，但<strong>DeepSeek发布的低成本、低资源消耗的AI模型表明，AI在未来将变得更加商品化。</strong>真正的差异化在于支持更高准确性、安全性和满足特定需求定制化的平台功能，这也是微软需要投资的方向。"</p>
  </blockquote>
  <p>持有微软股份的 Zacks Investment Management 投资组合经理 Brian Mulberry 表示，在看到微软的大规模投资计划后，他确实感到担忧：</p>
  <blockquote>
   <p>“我们确实希望开始看到一个更清晰的发展路线图，了解所有已投资资本的盈利模式是什么样的。”</p>
  </blockquote>
  <h2><strong>公司高管：大笔砸钱才能建立战略优势</strong></h2>
  <p>尽管质疑声四起，但科技巨头公司的高管们仍然普遍认为表示，继续大规模投入对于满足日益增长的AI需求是必要的。</p>
  <p>META CEO扎克伯格表示，他仍然相信大力投资公司的人工智能基础设施会成为战略优势。</p>
  <blockquote>
   <p>“现在就对基础设施和资本支出的走势做出判断可能还为时过早，”扎克伯格说。“这里同时出现了一系列趋势。”</p>
  </blockquote>
  <p>他坚信：“长期来看，大力投资资本支出和基础设施将成为一种战略优势。”</p>
  <p>扎克伯格似乎淡化了DeepSeek带来的威胁。他表示，这个行业在不断变化，DeepSeek的出现只是这种潮起潮落的一部分：</p>
  <blockquote>
   <p>“我认为他们（DeepSeek）做了许多新颖的事情，我想我们仍在消化这些事情，他们还有很多东西......我们希望在我们的系统中实现。”</p>
  </blockquote>
  <p>微软CEO萨蒂亚·纳德拉则认为，增加AI支出将有助于缓解限制公司充分利用人工智能的能力的产能问题。他补充说，随着人工智能变得更加高效和广泛可用，“我们将看到需求呈指数级增长。”</p>
  <p>Meta 首席人工智能科学家Yann LeCun还特意解释了人们对于AI投资成本的质疑。<strong>他解释称，在DeepSeek崛起后，投资者对美国科技巨头股票的抛售，其实是源于对AI基础设施投资的“重大误解”。</strong></p>
  <p>他强调，广为流传的DeepSeek的600万美元成本额，是单次训练成本，而不包括前期的投入成本。尽管这一训练成本的确很低，但不能以此来单独与科技公司们的全部投资额来作对比。</p>
  <p>LeCun 表示：<strong>“这些数十亿美元的资金中，很大一部分都投入到了推理基础设施中，而不是训练基础设施中。</strong>为数十亿人运行人工智能助手服务需要大量的计算。一旦你将视频理解、推理、大规模内存和其他功能纳入人工智能系统，推理成本就会增加。”</p>
  <p>无论科技巨头们的决策如何，不可否认的是，DeepSeek的出现已经如同一个搅局者，影响了全球AI赛道的竞争格局。</p>
  <p>据研究公司 SimilarWeb估计，在短短一周内，DeepSeek网站的用户数量就已经超过了谷歌的 Gemini 聊天AI（后者已经存在了近两年）。而未来，这场AI赛跑的格局变化，还值得进一步关注。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/4vekiYti7z6N8NmVRyRVJQ" rel="noopener noreferrer nofollow" target="_blank">“财联社AI daily”</a>，作者：刘蕊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156402166553348</id>
            <title>国产 DeepSeek V3 被秒成"前浪"？谷歌开放最强 Gemini 2.0 全家桶：速度快60倍，上下文还长16倍</title>
            <link>https://www.36kr.com/p/3156402166553348</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156402166553348</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:26:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <谷歌, Gemini 2.0, 人工智能, 模型>
<br>
<br>
总结: 谷歌发布了功能强大的人工智能模型套件Gemini 2.0，包含多个版本如2.0 Flash和2.0 Pro，旨在提升开发者的创作和协作能力。Gemini 2.0 Flash以其低延迟和高性能受到欢迎，支持多模态输入，并在基准测试中表现优异。2.0 Pro则专注于编码性能，能够处理复杂提示词。尽管用户对模型的性能给予积极反馈，但也对其使用限制和复杂性表示不满。谷歌的目标是让AI的能力接近人类水平，未来将推出更多功能。 </div>
                        <hr>
                    
                    <p>昨日夜里，谷歌向所有人发布了 Gemini 2.0——迄今为止谷歌“功能最强大”的人工智能模型套件。</p>
  <h2>谷歌 Gemini 2.0 向所有人开放</h2>
  <p>去年 12 月，谷歌发布 Gemini 2.0 Flash 的实验版本，正式开启了代理型 AI 的新时代。Gemini 2.0 Flash 是谷歌为开发者群体打造的高效主力模型，具有低延迟、高性能等优势。今年早些时候，谷歌在 Google AI Studio 中更新了 2.0 Flash Thinking Experimental，通过将 Flash 模型的惊人速度与复杂问题的推理能力相结合，进一步提高了性能表现。</p>
  <p>上周，谷歌面向桌面及移动设备端的全体 Gemini 应用用户发布了 2.0 Flash 更新版本，希望帮助更多人以全新方式使用 Gemini 进行创作、互动和协作。</p>
  <p>如今，谷歌将通过 Google AI Studio 和 Vertex AI 中的 Gemini API 向公众发布更新之后的 Gemini 2.0 Flash。开发人员现已可以使用 2.0 Flash 模型构建生产级应用程序。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7561c1c3bc69479fbaeb91069784edbe@5888275_oswg75784oswg972oswg786_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>谷歌还发布了 Gemini 2.0 Pro 的实验版本，这是谷歌旗下迄今为止编码性能最强、最善于处理复杂提示词的大模型</strong>。除了在 Google AI Studio 和 Vertex AI 当中使用之外，Gemini 2.0 Pro 也将在 Gemini 应用中面向 Gemini Advanced 用户开放。</p>
  <p>此外，谷歌将在 Google AI Studio 和 Vertex AI 中公开预览迄今为止最具成本效益的模型方案 Gemini 2.0 Flash-Lite。</p>
  <p>最后，2.0 Flash Thinking Experimental 将被添加在桌面和移动设备端的模型下拉菜单中，以供 Gemini 应用用户随时使用。以上提到的所有发布模型都将支持带有文本输出的多模态输入，且在未来几个月的通用版本中还将支持更多模态。</p>
  <h3>2.0 Flash：面向全体用户带来更新</h3>
  <p>Flash 系列模型首度亮相于 I/O 2024 大会，作为一种强大的主力模型广受开发者欢迎。Gemini 2.0 Flash 提供全面的功能，包括原生工具使用、100 万个 token 上下文窗口和多模式输入。它目前支持文本输出，具有图像和音频输出功能，并且计划在未来几个月内全面推出 Multimodal Live API。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e9b4901d878d4e8aba54cfbda63b7d88@5888275_oswg120758oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2.0 Flash 现已在谷歌 AI 产品中面向更多用户正式发布，同时在关键基准测试上的性能也得到了提升。图像生成与文生语音等功能将在不久之后推出。</p>
  <p>感兴趣的用户可以通过 Gemini 应用 或者 Google AI Studio 及 Vertex AI 中的 Gemini API 立即体验 Gemini 2.0。</p>
  <h3>2.0 Pro Experimental：谷歌编码性能最好的模型</h3>
  <p>在分享 Gemini 2.0 早期实验版本（例如 Gemini-Exp-1206）的过程中，谷歌收到了开发人员对其优势及最佳用例（例如编码场景）的极佳反馈。</p>
  <p>作为对这些反馈的回应，谷歌已经发布 Gemini 2.0 Pro 的实验版本。与之前已经发布的各类大模型相比，Gemini 2.0 Pro Experimental 拥有最强大的编码性能与复杂提示词处理能力，而且可以更好地理解并推理世界知识。该模型配备有谷歌旗下最大的上下文窗口，可容纳 200 万 token，这使其能够全面分析并理解大量信息，并可调用谷歌搜索及代码执行等其他工具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_90714f4e44ae4fb09b1e67f75d3b8b0f@5888275_oswg162943oswg640oswg988_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Gemini 2.0 Pro 现在以实验模型的形式向 Google AI Studio 和 Vertex AI 中的开发者，以及 Gemini Advanced 用户开放。这部分用户可通过桌面及移动设备端的模型下拉菜单立即体验。</p>
  <h3>2.0 Flash-Lite：谷歌最具性价比的模型</h3>
  <p>谷歌方面称，此前收到了大量关于 1.5 Flash 模型价格和运行速度的积极反馈，公司一直在保持成本和速度水平的同时不断努力提高模型质量。此次推出的 2.0 Flash-Lite 是一款质量优于 1.5 Flash 的新模型，且继续保持后者的速度和成本优势。2.0 版本在大多数基准测试中均优于 1.5 Flash。</p>
  <p>与 2.0 Flash 一样，2.0 Flash-Lite 版模型的上下文窗口可容纳 100 万 token 并支持多模态输入。例如，它可以一次性为大约 4 万张不同照片生成单行标题，且此项操作在 Google AI Studio 付费套餐中的成本不到 1 美元。</p>
  <p>Gemini 2.0 Flash-Lite 已经在 Google Ai Studio 和 Vertex AI 中提供公开预览版。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0f84fb6f42e54705a926581abee960f2@5888275_oswg160210oswg1080oswg681_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2>用户反馈怎么样？</h2>
  <p>谷歌首席科学家、AI 大佬 Jeff Dean 盛赞了 Gemini 2.0 Pro 的编程能力。他在 X 上发贴称对于 Gemini 2.0 Pro 编程能力感到惊讶。他表示：“我喜欢 Boggle 游戏（一种填字游戏）。这个演示展示了我们的 Gemini 2.0 Pro 模型在 AI Studio 中的编码能力。令人难以置信的是，它可以通过一个相对简单的提示，编写出完整的代码，包括所有正确的数据结构和搜索算法，以在 Boggle 游戏板上找到所有有效的单词。作为一名计算机科学家，我也很高兴它第一次就正确地完成了数据结构。” 他还幽默地用了 “Discombobulating!” （令人困惑 / 震惊）来形容。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4213cf5ef0e440ca9f4cdb780bd2dc0b@5888275_oswg217113oswg960oswg420_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Gemini 2.0 的全面发布引起了网友的广泛关注。InfoQ 旗下极客时间专栏作者林健（键盘） 得知 Gemini 2.0 Flash 上线后立即接入 API 试用，他在 X发贴称，Gemini 2.0 Flash 在长文本、成本和吞吐量等方面的表现优于 DeepSeek V3 和 GPT 4o-mini。</p>
  <p>尤其是与 DeepSeek V3 对比时优势明显（按后台的数据粗算，不计缓存 token）。Gemini 2.0 Flash 的成本比 DeepSeek V3 低 6 倍、输出速度快 60 倍、上下文长 16 倍，更重要的是还原生支持所有模态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_11cea4b69c2441a58c05ce17fbb5e769@5888275_oswg203580oswg1080oswg766_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b57a6fa895ae460aab21019d5a42fcde@5888275_oswg263644oswg1080oswg932_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也有 X 用户将 o3-mini-high、Gemini 2.0 Flash 和 Gemini 2.0 Pro 放在一起跑了几个基准测试进行性能比较。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4021ac5eabeb4e479e3a93dfa32e82ed@5888275_oswg107000oswg1080oswg456_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在综合性能表现中，Gemini 全家桶中的 2.0 Pro 在所有类别中排名第一，2.0 Flash 排名第三位，2.0 Flash Lite 则以更低的成本挤进了前十名。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0506e5b0352d4df199a237cd50fe127f@5888275_oswg466535oswg1080oswg890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>尽管在很多基准测试中 Gemini 系列模型都打败了同类模型，但基于 Gemini 衍生出来的产品还是被用户疯狂吐槽。</p>
  <blockquote>
   <p>我不使用 Google Gemini 的首要原因是它们会截断输入文本。因此我无法简单地将长文档或其他类型的内容作为原始文本粘贴到提示框中。</p>
  </blockquote>
  <p>甚至无法在 Gemini 中上传文档，只能上传图片。在 Hacker News 上，ID 名为 heavyarms 的用户表示：</p>
  <blockquote>
   <p>“我上次（也就是几天前）再次使用 Gemini 时，还是发现它只有一个‘上传图片’选项... 而我断断续续玩了几个月的 Gemini，却从来没有真正上传过图片。这基本上就是我对目前大多数 Google 产品的看法：不成熟、有缺陷、令人困惑、不直观。”</p>
  </blockquote>
  <p>而且谷歌这些模型的各种版本使用时的限制条件也让人摸不着头脑。有用户吐槽：</p>
  <p>“简单来说，我今天花了一个小时想弄清楚怎么用‘深度研究’这个功能，结果还是没搞明白。我买了 Gemini Advance 的商业办公标准版，但不确定是不是还需要 VPN、额外付费买 AI 产品，或者升级到更高级的办公套餐。谷歌的产品线太复杂了，各种功能互相交织，搞得人一头雾水。我都开始怀疑，谷歌作为 AI 提供商到底靠不靠谱了。”</p>
  <p>谷歌的 API 也饱受用户诟病。</p>
  <blockquote>
   <p>使用 Google API 通常会让人感到沮丧。事实上，我喜欢他们提供的最佳基础云服务，但他们的附加 API 却杂乱无章。在这些与 AI 相关的 API 中，谷歌的 API 是最糟糕的。</p>
  </blockquote>
  <h2>大模型下一步：各方面能力无限接近人类水平</h2>
  <p>无论从大模型的部署和使用成本，还是性能上来讲，大模型的下一步目标很明确：让 AI 的能力无限接近人类水平。听起来很科幻，但其实已经在路上了。</p>
  <p>谷歌在 12 月份的一篇博客文章中写道：“在过去的一年里，我们一直在投资开发更多的代理模型，这意味着它们可以更多地了解你周围的世界，提前思考多个步骤，并在你的监督下代表你采取行动。”并补充说，Gemini 2.0 在“多模态性方面取得了新进展——比如原生图像和音频输出——以及原生工具的使用”，并且该模型系列“将使我们能够构建新的人工智能代理，让我们更接近通用助手的愿景。”</p>
  <p>Anthropic 是一家 由亚马逊支持的人工智能初创公司，由前 OpenAI 研究主管创立，是开发 AI Agent 竞赛中的关键参与者。10 月，Anthropic 表示其 AI Agent 能够像人类一样使用计算机来完成复杂的任务。这家初创公司表示，Anthropic 的计算机使用能力使其技术能够解释计算机屏幕上的内容、选择按钮、输入文本、浏览网站并通过任何软件和实时互联网浏览执行任务。</p>
  <p>Anthropic 首席科学官贾里德·卡普兰 (Jared Kaplan) 当时在接受 CNBC 采访时表示，该工具“基本上可以像我们一样使用计算机”。他说，它可以完成“数十甚至数百步”的任务。</p>
  <p>OpenAI 最近发布了一项类似的功能，名为 Operator，它可以自动执行诸如计划假期、填写表格、预订餐厅和订购杂货等任务。OpenAI 将 Operator 描述为“可以上网为您执行任务的 Agent”。</p>
  <p>本周早些时候，OpenAI 推出了 Deep Research，它允许 AI Agent 编写复杂的研究报告并分析用户选择的问题和主题。谷歌去年 12 月推出了一款同名的类似工具——Deep Research，它充当“研究助手，探索复杂主题并代表你编写报告”。</p>
  <p>CNBC 于 12 月首次报道称，谷歌将在 2025 年初推出多项人工智能功能。</p>
  <p>“从历史上看，你并不一定总是第一，但你必须执行力强，真正成为同类产品中最好的，”首席执行官 Sundar Pichai 在当时的战略会议上表示。“我认为这就是 2025 年的意义所在。”</p>
  <p><strong>参考链接：</strong></p>
  <p>https://blog.google/technology/google-deepmind/gemini-model-updates-february-2025/</p>
  <p>https://x.com/lmarena_ai/status/1887180371219132898</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Wmt7VRG0blp4sTC9p4Brcw" rel="noopener noreferrer nofollow" target="_blank">“AI前线”</a>，作者：冬梅、核子可乐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156404365728264</id>
            <title>微软官宣All in智能体，SWE Agent首曝光，奥特曼预警2025编程巨变</title>
            <link>https://www.36kr.com/p/3156404365728264</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156404365728264</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 软件工程, AI智能体, GitHub Copilot, 2025年变革
<br>
<br>
总结: 2025年，软件工程将经历重大变革，AI智能体的引入将显著提升开发效率。微软的GitHub Copilot将全面拥抱智能体，具备自主改bug、提交PR等能力，成为开发者的得力助手。AI将与人类工程师紧密协作，自动化测试、代码优化和漏洞检测等任务将不再依赖单一人力。尽管AI的普及可能带来新的安全威胁，但其在提高生产力和解决开发者长期困扰的问题方面的潜力不可忽视。Altman强调，未来的编程环境将更加智能，AI将在解决复杂问题中发挥重要作用。 </div>
                        <hr>
                    
                    <blockquote>
   <p>2025年，软件工程要彻底变天了。先有奥特曼预言，后有微软下场All in智能体。刚刚，首个自主SWE智能体面世，不仅会主动改bug修复错误，还能自主提交PR评论。</p>
  </blockquote>
  <p>奥特曼预言，2025年软件工程将迎来巨变。</p>
  <p>开年智能体大爆发，AI自动化软件工程已成为不争的事实。</p>
  <p>就在今天，纳德拉官宣，GitHub Copilot将all-in智能体，微软自主的SWE智能体首次亮相。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5fc4f8fa1eec42f7961e4000cac8df7c@5888275_oswg52975oswg873oswg263_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>GitHub现任CEO Thomas Dohmke表示，自主SWE智能体（项目代号Padawan）也将融入GitHub用户体验，不过要等到今年晚些时候发布。</p>
  <p>「它可以将GitHub Copilot体验从搭档提升到人类程序员水平」。</p>
  <p>不论是改Bug还是开发新模块，不需要去特别说明相关的代码，SWE智能体会主动找到合适的代码，并解决问题，就像你雇了一个工程师。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_096a346c351e457cb49314864b68dafc@5888275_oswg128190oswg1080oswg1109_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有网友对此表示，基本上，每一个repo都会有一个AI贡献者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_031282f315124f88ae7e434ff2448263@5888275_oswg145392oswg1080oswg333_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>软件工程AI智能体苏醒</strong></h2>
  <p>2021年，GitHub Copilot一经推出成为了开发者们的得力助手。</p>
  <p>时隔4年，Copilot终于迎来了重大升级。</p>
  <p>如前所述，此次更新的最大亮点推出了Agent模式（预览版）。在这个模式下，Copilot展现出惊人的自主能力。</p>
  <ul>
   <li>自主迭代代码，识别错误并自动修复</li>
   <li>主动建议终端命令，并请求执行</li>
   <li>识别运行时错误，主动修复</li>
  </ul>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5f4833b054114e69a089e594c7c744f4@5888275_oswg462995oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在智能体模式下，Copilot不仅会对自己的输出进行迭代，还会对输出结果进行持续改进，直至完成所有子任务，满足开发者的请求。</p>
  <p>更强大的是，它不再仅仅执行要求的任务，还能去推断额外的必要任务，确保请求完整运行。</p>
  <p>在Copilot自我纠错过程中，比较省事的是，开发者不必从终端手动复制粘贴内容回到聊天窗口。</p>
  <p>在调用模型方面，开发者有Anthropic、OpenAI系列的模型可选。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4a2df066b9ee4d3f9a85cb65973e880b@5888275_oswg97979oswg620oswg298_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在全新VS Code智能体模式中，Copilot会对自身代码进行迭代，提出并指导终端命令，分析和解决问题。</p>
  <p>举个栗子，用GitHub Copilot构建一个Web应用程序来跟踪马拉松训练。</p>
  <p>这里有一个Runner Tracks网站，展示了一些比赛的结果。现在若是想要改进这张表的分页，添加更多参赛者数据，直接在Copilot Chat中输入要求即可。</p>
  <p>——更新分页按钮，让其看起来更加美观。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3f5df9c65648472ea4dcc5045b8ff816@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然后选用o3-mini模型，Copilot直接开始输出代码，再返回Runner Tracks网站，可以看到「按钮」变成了蓝色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d479ca835bdf4e6fab5fcf6b4059a043@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接下来，继续迭代这个网站——让用户可以选择每页显示的行数。</p>
  <p>这时，涉及到了不止一个文件的更改。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_629e8f64a2984a1dbe5272176be3ab5c@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>再上升一个难度的任务，Runner Tracks网站中有一个列出比赛的页面，若是想要按名称去搜索比赛，这将需要对项目服务器端代码UI和测试中许多文件进行修改。</p>
  <p>这个场合，就轮到Agent模式出场了。</p>
  <p>它最擅长的是推理和迭代整个项目，并且执行重复的操作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7eee1435581f45c8ad7e23e0f3e0eba1@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>可以看出，Copilot Agent自主更新了服务器后端、UI，主动修复错误。</p>
  <p>在这些基本项完成后，它又转向服务单元测试、页面测试、以及端到端的测试。</p>
  <p>直至测试更新后，系统会主动提示开发者去运行单元测试。</p>
  <p><strong>GitHub Copilot Edits</strong></p>
  <p>这次，同时上线的还有多文件编辑工具GitHub Copilot Edits。</p>
  <p>Copilot Edits可以一次性处理工作空间中的多个文件，并给出代码的更改意见。</p>
  <p>所有这些处理都可以在编辑器中直接完成，非常便于快速审查代码，同时了解周围代码的完整上下文。</p>
  <p>在操作过程中，用户还可以对每一次编辑选择接受或者放弃，从而拥有更加灵活的控制。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5ec851530f5a47ec9fa5e922d4f0cc2f@5888275_oswg286033oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一个新变化是，当切换到并排视图时，用于编辑的控制选项依然可见。</p>
  <p>由此可以帮助用户了解大范围的改动。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c48a85a3d1ab452a82b97e9361dca6de@5888275_oswg192373oswg1080oswg386_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后，Copilot Edits增加了一个新的设置，用于在超时后自动接受编辑器的建议。</p>
  <p>这个新设置的名称为「chat.editing.autoAcceptDelay」，它可以指定Copilot Edits的建议被接受之前需要等待的秒数。当用户点击接受按钮或开始审阅更改时，倒计时停止。</p>
  <p>这个设置对于那些喜欢在周末疯狂追剧的人来说应该很熟悉。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1bbd9ac262ae4f758d7f681b4d2e17d7@5888275_oswg36088oswg1080oswg581_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Project Padawan</strong></p>
  <p>而「Project Padawan」，则可以进一步将SWE智能体融入GitHub的用户体验中。</p>
  <p>一起来看个例子，GitHub cli库每天被使用数百万次，尽管有数百个贡献者，但积压了许多问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_deab31516c3a466eb7abba615530e787@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中的一个错误报告，展示了GH报告重命名的命令中缺少了验证，若是人力完成，会耗费大量的精力。</p>
  <p>要知道，这个代码库中有700个文件，大约20万行代码。</p>
  <p>而现在，有了「自主SWE智能体」，完全就可以放心交给这个AI助手。</p>
  <p>我们可以将问题分配给Copilot，它便开始立即处理。几秒钟后，它便从draft PR直接链接到开发者创建的问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e93bd5327dac4c87924f3ccab45d4167@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接下来，Copilot会不断更新PR描述，并自主提交，在共享实时计划同时，可以让开发者清晰看到更改进度。</p>
  <p>在PR完成后，它还会推送最终更改的提交，自主请求代码审查，并将PR标记为「准备审查」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4d23b3eda6a24b1882ae8f942a529b9b@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>开发者在此还提交了自己的审查请求，Copilot立即收到任务后开始了更改。并且，它还主动回复评论开发者的更改内容，并将最新进展推送到PR。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4f5f2319047c427cb37a1879a1a79c25@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以上所有流程，展示了Copilot成为一个真正的「AI工程师」，能与开发者合作完成编码任务。</p>
  <p>对此，网友表示，「过去一个月我一直在使用智能体，感觉和Karpathy的编码风格类似。一旦建立了构建、测试、迭代的反馈循环，你和智能体就能立刻进入状态。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_99f6e428fcd649529c35d2eb86f26367@5888275_oswg123404oswg1080oswg244_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>开发者领导SWE智能体，和项目经理一起编写详细的工单，审查工作、必要时接入。</p>
  <p>这，就是编码的未来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_294c938ecee9434bbbc4d7b2413ac6f2@5888275_oswg130568oswg1080oswg274_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>如何用？</strong></h3>
  <p>想要用上Copilot agent新功能，需要下载VS Code Insiders，然后启用GitHub Copilot Chat智能体模式设置。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_80cf6b8710f14c75a600da89bbaa2b60@5888275_oswg210392oswg1080oswg592_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然后，在「Copilot编辑」面板中，从模型选取器旁边的「编辑」切换到「智能体」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_14c845eb91e54afb9c36707fef94fb17@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>智能体模式的引入，将改变开发者在编辑器中的工作方式。</p>
  <p>为了无缝衔接，微软同时将其植入到所有支持Copilot的集成开发环境（IDE）中。</p>
  <h2><strong>2025年底，软件工程迎来巨变</strong></h2>
  <p>2月5日，OpenAI首席执行官Sam Altman与印度联邦信息技术部长Ashwini Vaishnaw进行了一场对谈。</p>
  <p>在此次访谈中，奥特曼也强调了智能体以及软件工程如何在未来变革中扮演的至关重要的角色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1f9929a65bcb4273bad20d365657eb68@5888275_oswg130387oswg1080oswg966_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在谈及AI如何改变软件工程时，Altman给出了令人期待的前景。</p>
  <p>他表示：「到2025年底，软件工程将发生翻天覆地的变化。这不仅意味着开发效率的大幅提升，还可能对网络安全产生深远的影响。」</p>
  <p>AI将成为软件工程中的得力助手，自动化测试、代码优化和漏洞检测等任务将不再是人类工程师的单打独斗，而是与AI紧密协作的成果。</p>
  <p>AI在软件工程中的应用，不仅能提高开发效率，还能帮助解决一些长期以来困扰开发者们的问题。</p>
  <p>例如，AI能够快速发现代码中的潜在问题并提出解决方案，极大地缩短开发周期。同时，AI还将在网络安全领域发挥重要作用，尽管这一过程需要谨慎对待，因为AI的普及也可能带来新的安全威胁。</p>
  <p>Altman谈到：「到2025年底，AI将变得更加智能，尤其是在软件工程领域。我们将看到一个更加智能的编程环境，AI将在解决复杂问题时扮演重要角色。」</p>
  <p>x上有网友已经开始期待软件智能体时代的到来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_307c7073c248422d84ca25acb6f30f2a@5888275_oswg78785oswg1080oswg714_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>甚至有网友开始幻想使用AI智能体来建立价值百万美元的公司了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f28aee1d7fe04c31a2db1dc476035b6c@5888275_oswg366105oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>智能化的AI软件工程不仅可以提高生产力，还能够更高效地进行系统开发和优化，甚至可能在未来改变整个软件开发行业的格局。</p>
  <p>这种变革类似于工业革命中的自动化生产线，AI将帮助软件开发者摆脱繁琐的细节工作，使他们能将精力集中于更高层次的创新和设计上。</p>
  <p>但同时，如何确保AI技术在应用中的安全性，避免其被滥用，将是未来需要解决的重要问题。</p>
  <p>关于这些问题，Altman指出：「我们必须在技术发展的同时，也要确保安全的可控性。AI的影响是深远的，我们要确保它能为全球带来积极的变革。」</p>
  <h3><strong>Deep Research助力研究</strong></h3>
  <p>访谈中主持人向奥特曼提出了一个关键问题：「在当前的深度研究环境中，AI是否已经足够成熟，能在一些关键领域发挥作用？」</p>
  <p>对此，Altman作出了充满信心的回应：「底层技术已经达到了一个门槛，尤其是在诊断疾病和教育领域，我们已经看到了惊人的成果。未来几个月内，我们将发布能够解决现实问题的模型。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e02fa7b6dd7b41279713e90e6e146b05@5888275_oswg53910oswg1080oswg649_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他特别提到，AI的进步不仅仅是在研究领域，更多的应用场景已经悄然出现，从医疗诊断到教育辅导，AI的潜力逐渐展现。</p>
  <p>例如，在医学领域，AI的研究助手不仅能够协助科学家高效回顾现有文献，还能在庞大的数据中找到潜在的联系，为科学发现提供有力支持。</p>
  <p>然而，尽管AI可以帮助提高效率，但它并非万能，Altman强调：「Deep Research可以帮助我们提高效率，例如在文献回顾、数据整理等繁重的低层次工作中。但它不可能独立完成一项复杂的任务。就像在癌症研究中，AI并不会直接治愈疾病，但它能帮助研究人员更快地找到解决方案。」</p>
  <p>这种高效的支持能够大大加速科学研究的进程，助力科研人员从繁琐的任务中解脱出来，将更多精力投入到创新和突破之中。</p>
  <h2><strong>结语‍</strong></h2>
  <p>无论是微软CEO纳德拉宣布GitHub Copilot全面拥抱智能体，还是OpenAI CEO Altman对未来软件工程的展望，都清晰地表明：AI智能体正引领软件工程领域进入一个全新的时代。</p>
  <p>AI智能体不仅将成为开发者的得力助手，更可能成为推动整个行业变革的核心力量。</p>
  <p>从代码编写、错误修复到项目开发，再到深度科学研究，AI的应用潜力正在被迅速释放。</p>
  <p>这场变革也带来了一系列值得思考的问题：开发者如何适应与AI协同工作的新模式？&nbsp;如何确保AI在网络安全领域的应用既能提升防御能力，又能避免新的风险？&nbsp;如何平衡AI带来的效率提升与潜在的就业影响？</p>
  <p>虽然AI并非万能，但无论如何，在2025年底，我们有望见证一个更加智能、高效的软件工程未来。</p>
  <p><strong>参考资料：</strong></p>
  <p>https://x.com/sama/status/1887177808394252777</p>
  <p>https://x.com/ashtom/status/1887548091404046359</p>
  <p>https://x.com/satyanadella/status/1887587703665139765‍</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/aKLnb2jOMUJ3QIV9r6R25Q" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156387000867586</id>
            <title>德银：不只是DeepSeek，2025年将是中国企业在全球崛起的一年，中国股票“估值折价”将消失</title>
            <link>https://www.36kr.com/p/3156387000867586</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156387000867586</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:11:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <中国资产, DeepSeek, 制造业, 估值折价>
<br>
<br>
总结: 德意志银行在最新报告中指出，2025年将是中国在全球竞争中领先的一年，预计中国股票的“估值折价”将消失，A股和港股的牛市将持续并超过之前高点。中国在多个制造和服务业领域展现出高性价比和优质产品，尤其在电动汽车和高科技领域的崛起。报告还强调，中国的制造业优势日益凸显，出口规模和专利申请数量均处于全球领先地位。中美贸易问题可能带来正面影响，投资者需迅速调整策略，增加对中国市场的配置。 </div>
                        <hr>
                    
                    <p>Deepseek爆火之后，要重估的或是整个中国资产。</p>
  <p>在2月5日的最新报告中，德意志银行唱多称，2025年是中国超越其他国家的一年，预计中国股票“估值折价”将消失，A股/港股牛市将继续并超过此前高点。</p>
  <p>德银表示：</p>
  <blockquote>
   <p>2025年被视为投资界意识到中国在全球竞争中领先的一年。越来越难以不承认，中国企业在多个制造和服务业领域提供高性价比和优质产品。</p>
   <p><strong>我们预计中国股票的“估值折价”将消失</strong>，盈利能力可能因政策支持消费和金融自由化而超出预期。<strong>港股/A股的牛市始于2024年，预计会在中期内超过之前的高点。</strong></p>
  </blockquote>
  <p>具体来看，德银表示，<strong>中国制造业和服务业在全球占据领先地位</strong>，而<strong>DeepSeek的崛起更像是中国的“斯普特尼克”时刻</strong>（指迎来变革和进步的重要契机）：</p>
  <blockquote>
   <p>中国在服装、纺织品、玩具、基础电子、钢铁、造船等领域，以及电信设备、核能、国防和高速铁路等复杂行业中也占据领导地位。而在2025年，中国在一周内推出了世界上第一架第六代战斗机和其低成本的人工智能系统DeepSeek。</p>
   <p>马克·安德森将DeepSeek的推出称为“人工智能的斯普特尼克时刻” ，但这更像是中国的斯普特尼克时刻，中国知识产权得到了认可。中国在高附加值领域表现出色并主导供应链列表，正在以前所未有的速度扩展。</p>
  </blockquote>
  <p>此外，德银乐观地指出，中美贸易问题可能会带来正面惊喜，而且贸易和市场并非那么紧密相关：</p>
  <blockquote>
   <p>随着中国企业在全球范围内的主导地位不断巩固，<strong>估值折扣似乎最终应该转变为溢价</strong>。我们相信<strong>投资者将不得不在中期内迅速转向中国，并且在不推高股价的情况下很难获得中国股票。</strong></p>
  </blockquote>
  <h2><strong>中国制造业优势日益凸显</strong></h2>
  <p>近年来，中国制造业在全球范围内的优势日益凸显。</p>
  <p>德银表示：</p>
  <blockquote>
   <p>从最初在服装、纺织品和玩具领域的崛起，到如今在基础电子、钢铁、造船等领域占据主导地位，中国制造业的发展轨迹令人瞩目。特别是在白色家电、太阳能等领域，中国企业的表现更是异军突起。</p>
   <p>值得注意的是，中国在电信设备、核电、国防和高速铁路等复杂行业中的崛起，展现了其强大的技术实力。2024年底，中国在汽车出口领域的快速崛起引起全球关注，其高性能、外观吸引人且价格具有竞争力的电动汽车（EV）成功打入国际市场。2025年，中国更是在短短一周内推出了世界上第一架第六代战斗机和低成本人工智能系统DeepSeek，这被视为中国知识产权得到认可的重要标志。</p>
   <figure class="image">
    <img src="https://img.36krcdn.com/hsossms/20250207/v2_f5499cb73fbf43ed8d53519dea8fc7f8@5888275_oswg210851oswg1080oswg440_img_000?x-oss-process=image/format,jpg/interlace,1" />
   </figure>
  </blockquote>
  <p>中国制造业的实力可以从以下几个方面得到印证：</p>
  <blockquote>
   <p>出口规模：<strong>中国的商品出口额是美国的两倍</strong>，<strong>贡献了全球制造业增加值的30%。</strong></p>
   <p>专利申请：2023年<strong>，中国占全球专利申请的近一半</strong>。在电动汽车领域，中国拥有约70%的专利，5G和6G电信设备领域也有类似优势。</p>
   <p>人才储备：除印度外，中国拥有比世界其他国家更多的STEM（科学、技术、工程和数学）毕业生。</p>
   <p>产业集群：中国为关键行业创造了类似硅谷的本地专业集群，并与大学在研究方面紧密合作。</p>
  </blockquote>
  <p>德银还表示：</p>
  <blockquote>
   <p>自由化金融体系对促进消费是有帮助的，通过正常化利率，从而结束从存款人到企业的资金转移。这将减少过度投资和过度竞争，因为资本得到了配给，这将有利于提高国有企业回报率。我们预计，<strong>随着国有企业提高回报率，将要求缓解过度竞争以提高股票价值。我们预计这将在2025年成为一个关键话题，该因素将成为推动牛市的关键因素。</strong></p>
  </blockquote>
  <h2><strong>中国经济和出口仍保持较快增长</strong></h2>
  <p>2024年，中国出口增长7%，对巴西、阿联 酋和沙特阿拉伯的出口分别增长23%、19%和18%，对"一带一路"中的东盟国家增长13%。<strong>中国对东盟和金砖国家的出口现已相当于对美国和欧盟的出口总和，</strong>且过去五年中，对这些目的地的出口市场份额<strong>每年增长两个百分点</strong>。</p>
  <p>中国经济增长的动力来自几个方面：</p>
  <blockquote>
   <p>制造业优势：<strong>在几乎所有行业中，中国都拥有世界领先的公司，</strong>并不断抢占市场份额。</p>
   <p>"一带一路"倡议：该倡议打开了中亚、西亚、中东和北非等地区，扩大了中国的潜在市场。</p>
   <p>自动化领先：<strong>约70%的工业机器人安装在中国，推动了生产力优势</strong>。</p>
   <p>内需潜力：家庭存款增长放缓至名义GDP增长率的两倍，但自2020年以来，<strong>储蓄增加了10万亿美元，预计这些储蓄将在中期内流入消费和股票市场。</strong></p>
  </blockquote>
  <h2><strong>中美贸易问题可能带来正面惊喜，贸易和市场并非那么紧密相关</strong></h2>
  <p>据央视新闻此前报道，美国总统特朗普2月1日签署行政令，对进口自中国的商品加征10%的关税。但德银认为，实际情况可能比预期更为有利。特朗普政府似乎更看重战术上的胜利，而非坚持难以获得支持的意识形态立场。</p>
  <p><strong>DeepSeek的推出动摇了世界对中国可以被遏制的信念。</strong>更好的做法可能是通过降低监管、提供廉价能源和相对较低的进口中间产品壁垒来刺激商业。预计在中期选举前，更倾向于贸易的立场最终将成为发展中的"美国优先"议程的一部分。</p>
  <p>德银分析认为，<strong>一个快速达成的中美贸易协议可能涉及有限的关税、撤销一些当前的限制，以及美国和中国公司之间的一些大型合同。如果这种情况发生，预计中国股市将会上涨。</strong></p>
  <blockquote>
   <p>出口下降可能在一段时间内反而推动股市上涨。中国在各行业的主导地位是通过在许多领域的过度投资实现的。如果能够限制供应，可能对股票有利，并释放一些资本用于国内消费。</p>
  </blockquote>
  <p>整体来看，德银认为，<strong>随着中国企业在全球范围内的主导地位不断巩固，投资者可能需要迅速调整策略，增加对中国市场的配置</strong>。<strong>预计香港/中国股市将在中期内继续领先全球市场，延续2024年的强劲表现。</strong></p>
  <blockquote>
   <p>我们认为全球投资者往往严重低配中国，就像他们几年前回避化石燃料一样，直到市场惩罚了那些做出非市场决策的人。我们看到今天基金对中国的持仓与此相似。喜欢领先公司、拥有护城河的投资者不能忽视，<strong>如今是中国公司拥有宽广和深厚的护城河，而不是西方公司</strong>。</p>
   <p><strong>随着中国企业在全球范围内的主导地位不断巩固，中国估值折价似乎最终应该转变为溢价。我们相信投资者将不得不在中期内迅速转向中国，并且在不推高股价的情况下很难获得中国股票。</strong>我们之前一直看好，但对于找到什么因素会促使世界觉醒并购买感到困扰，<strong>我们相信中国的“斯普特尼克时刻”（或电动汽车领域的主导地位）就是这个因素</strong>。</p>
  </blockquote>
  <p>本文不构成个人投资建议，不代表平台观点，市场有风险，投资需谨慎，请独立判断和决策。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/c9kN42djbTQyI3-VeJbq1Q" rel="noopener noreferrer nofollow" target="_blank">“华尔街见闻”</a>，作者：赵颖，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156361918044679</id>
            <title>“DeepSeek风暴”席卷全球资本市场，产业链企业谁是输家？谁是赢家？</title>
            <link>https://www.36kr.com/p/3156361918044679</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156361918044679</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:07:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, 生成式AI, 产业链, 云服务  
<br><br>  
总结: 春节假期，DeepSeek因其低成本、高性能和开源特性成为科技圈的焦点，吸引了多家云服务巨头接入。随着投资者对中国互联网和半导体公司的看涨情绪，相关科技股在资本市场表现强劲。DeepSeek的崛起可能会影响整个产业链，尤其是生成式AI的应用和基础模型的提供商。最终用户和GenAI应用提供商将从中受益，而专有模型提供商可能面临竞争压力。DeepSeek的开源策略和低成本API将重塑市场格局，未来的赢家和输家尚未最终确定。 </div>
                        <hr>
                    
                    <p>春节假期，全球掀起一股 “DeepSeek 风暴”。凭借“低成本、高性能、开源”等优势，DeepSeek 以屠龙者之相一跃成为整个科技圈关注的焦点。</p>
  <p>2月初，天翼云、华为云、腾讯云、阿里云、百度智能云等相继接入DeepSeek ，以云服务巨头们为首，从芯片厂商到软件厂商再到垂直应用领域的多家企业争先恐后加入这位“新贵”的朋友圈。</p>
  <p>这股风暴的效应也非常明显地反映到了资本市场——随着全球投资者对中国互联网公司以及对于中国半导体与软件领军者的狂热看涨情绪，恒生科技指数步入“技术性牛市”；而在 A 股市场，涵盖众多科技股的创业板截至周五上午收盘暴涨超 3%，周涨幅已接近 7%。</p>
  <p><strong>无数人在询问，以 DeepSeek 为代表的新一代生成式 AI 到底将如何影响整条产业链？谁将被颠覆？谁又能成为这股热潮中的受益者？</strong>趁着这股热度，不少研究机构和券商也纷纷发布了相关报告，因此本文将综合 IoT Analytics、 TrendForce 集邦咨询、IBM 以及多家券商的报告，对产业链受到的影响进行解析。</p>
  <p>注：本文仅进行产业链分析，不构成任何投资建议</p>
  <h2><strong>一图搞懂生成式 AI 价值链</strong></h2>
  <p>一个显而易见的结论是，此前，对于生成式 AI（GenAI）的支出正在使广泛的价值链受益，下图基于 IoT Analytics 发布的《2025-2030 年生成式 AI 市场报告》，描绘了整个价值链中 GenAI 支出的主要受益者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_34ff31f2050a460ba9f6aa4e7118979f@000000_oswg263108oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>价值链上的受益者包括：</p>
  <h3><strong>Tier-0</strong></h3>
  <p><strong>最终用户——包括使用生成式 AI 应用的消费者和企业。</strong></p>
  <p>截至 2 月 5 日，DeepSeek 的全球下载量已接近 4000 万。据 AI 产品榜数据，DeepSeek 应用(仅包含 APP，不包括 Web 端) 2025年1月11日上线，至2025年1月31 日，DAU 2215 万。彼时 ChatGPT 日活 5323 万，豆包日活 1695 万，这意味着 DeepSeek 达到 ChatGPT 日活用户的 41.6%，已超过豆包。</p>
  <p>由 IBM 委托开展的一项新研究发现，在接受调研的企业级（规模超过 1000 名员工）组织当中，约有 42% 已经在其业务中积极使用人工智能。</p>
  <p><strong>GenAI 应用——在其产品中包含 GenAI 功能或提供独立 GenAI 软件的软件供应商，包括专注于 Agentic AI 的企业软件公司（如 Salesforce）以及专注于 GenAI 应用程序的初创公司（如 Perplexity 或 Lovable）。</strong></p>
  <p>2023 年 3 月 7 日，Salesforce 宣布推出 Einstein GPT，这是全球第一个 CRM 生成式 AI，用例包括 Slack、Sales、Service、Marketing、Commerce 以及 App Builder，以助力提高员工效率，改进客户体验。</p>
  <p>Perplexity 成立于 2022 年 8 月，专注于搜索领域，目标是取代谷歌，甚至被称为“谷歌杀手”。据悉，Perplexity AI 是建立在大模型之上的 AI 搜索应用。有别于传统罗列网页式搜索，而是通过利用 AI 工具，提供经过提炼总结后的答案，并附上出处。</p>
  <h3><strong>Tier-1</strong></h3>
  <p><strong>一级受益者——基础模型提供商（如 OpenAI 或 Anthropic）、模型管理平台（如 AWS Sagemaker、Google Vertex 或 Microsoft Azure AI）、数据管理工具（如 MongoDB 或 Snowflake）、云计算和数据中心运营商（如 Azure、AWS、Equinix 或 Digital Realty）、AI 咨询和集成服务商（如 Accenture 或 Capgemini）、边缘计算公司（如 Advantech 或 HPE）。</strong></p>
  <h3><strong>Tier-2</strong></h3>
  <p><strong>二级受益者——为一级受益者提供产品和服务支持的企业，包括芯片供应商（如 NVIDIA 或 AMD）、网络与服务器设备供应商（如 Arista Networks、华为或 Belden）、服务器散热技术供应商（如 Vertiv 或 Schneider Electric）。</strong></p>
  <p>华为全联接大会 2024 期间，在以“星河AI网络，共赢行业智能化”为主题的峰会上，华为数据通信产品线总裁王雷面向全球升级星河 AI 网络发布 20 余款新品，包括业界首款 100T 数据中心盒式以太交换机、业界首款 51.2T 数据中心盒式液冷交换机，业界首款 AI 路由器、高品质万兆园区新款交换机和 Wi-Fi 7 AP、智能 SASE 分支安全解决方案和业界首个 IP 自动驾驶网络等领先解决方案，帮助客户创造更大商业价值。</p>
  <h3><strong>Tier-3</strong></h3>
  <p><strong>三级受益者——为二级受益者提供产品和服务支持的企业，包括芯片设计电子自动化软件供应商（如 Cadence 或 Synopsys）、半导体制造商（如台积电 TSMC）、用于散热技术的热交换器供应商、电网技术供应商（如西门子能源或 ABB）。</strong></p>
  <h3><strong>Tier-4</strong></h3>
  <p><strong>四级及更远层级的受益者——继续为上游环节提供支持的公司，如半导体制造设备所需的光刻系统供应商（如 ASML），以及光刻系统供应链上的光学元件供应商（如蔡司）。</strong></p>
  <h2><strong>DeepSeek 浪潮中的赢家和输家</strong></h2>
  <p>DeepSeek R1 等模型的崛起预示着生成式人工智能价值链的潜在转变，其颠覆性主要体现在：</p>
  <p><strong>①最大的 DeepSeek R1 模型 （具有 6850 亿个参数）性能与美国基础模型提供商的一些领先模型相当甚至更好。</strong>基准测试表明，DeepSeek 的 R1 模型的性能与 OpenAI 的 o1 和 Anthropic 的 Claude 3.5 Sonnet 等领先、更知名的模型相当或更好。</p>
  <p><strong>②DeepSeek 的训练成本要低得多，但并没有最初新闻所说的那么高。</strong>早期的报道显示，该模型的训练成本超过 550 万美元，但自发布以来，不仅训练，而且开发整个模型的真正价值一直存在争议。据半导体研究和咨询公司 SemiAnalysis 称，550 万美元只是成本的一部分，不包括硬件支出、研发团队的工资和其他因素。</p>
  <p><strong>③DeepSeek 的 API 定价比 OpenAI 便宜 90% 以上。</strong>无论开发模型的实际成本如何，DeepSeek 都提供了使用其 API 的更便宜的方案：DeepSeek R1 的输入和输出令牌成本分别为每百万 0.55 美元和每百万 2.19 美元，而 OpenAI 的 o1 模型成本为每百万 15 美元和每百万 60 美元。</p>
  <p><strong>④DeepSeek R1 是一个创新模型， DeepSeek 发布的论文展示了在 V3 基础上开发 R1 的方法</strong>：利用混合专家 (MoE)架构、强化学习和极具创意的硬件优化，创建需要更少资源来训练和执行 AI 推理的模型，从而实现更低的 API 使用成本。</p>
  <p><strong>⑤DeepSeek 比多数竞争对手更加开放。</strong>DeepSeek R1 可在HuggingFace或GitHub等平台上免费获取。</p>
  <p><strong>⑥DeepSeek 在 R1 主版本发布的同时发布了功能强大的小型模型。</strong>DeepSeek不仅发布了具有超过 6800 亿个参数的主要大型模型，而且还发布了多个DeepSeek R1 精简模型。这些模型的大小从 700 亿到 15 亿不等，后者可适用于许多消费级硬件。</p>
  <p>这些优势将挑战现有的市场格局并重塑对盈利能力和竞争优势的期望。<strong>如果出现更多具有类似功能的模型，某些参与者可能会受益，而其他参与者则面临越来越大的压力。</strong>在此背景下，IoT Analytics 根据 DeepSeek R1 引入的创新以及开放、经济高效的模型的广泛趋势，评估了主要的赢家和可能的输家。值得一提的是，该评估考虑了此类模型对价值链的潜在长期影响，而不仅仅是 R1 的直接影响。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_626c69aa80e64e86b86505a72236b40a@000000_oswg295532oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>谁是明显的赢家？</strong></h3>
  <p><strong>首先，最终用户肯定会获得更多的受益，</strong>更多更便宜大模型的出现最终将降低终端用户的成本，并使人工智能更加普及。日常生活中，已经有越来越多的人正通过提供初步构想、自动完成重复性任务、快速生成报告和文档等手段显著提升工作效率。</p>
  <p><strong>GenAI 应用提供商也是赢家之一，</strong>随着更多基础模型的上线，构建在其上的初创公司将拥有更多选择。如上所述，DeepSeek R1 比 OpenAI 的 o1 模型便宜得多，尽管推理模型在应用场景中使用较少，但持续的突破使得模型更强大且更便宜。可以预见，更多、更廉价的模型将降低 GenAI 功能在应用中的集成成本。</p>
  <h3><strong>谁是可能的赢家？</strong></h3>
  <p><strong>边缘 AI/边缘计算公司是可能的潜在赢家。</strong>在微软最近的财报电话会议上，萨蒂亚·纳德拉指出，“人工智能将更加无处不在”，因为更多的工作负载将在本地运行。DeepSeek 与强大的 R1 模型一起发布的精简小型模型足够小，可以在许多边缘设备上运行。虽然规模较小，但 1.5B、7B 和 14B 模型也是同样强大的推理模型。它们可以安装在笔记本电脑和其他功能较弱的设备上，例如 IPC 和工业网关。这些精简模型已从 Hugging Face 平台上被下载了数十万次。拥有边缘 AI 解决方案的边缘计算制造商（如意大利的 Eurotech 和台湾的研华科技）将从中获利；专门从事边缘计算芯片的芯片公司（如 AMD、ARM、高通甚至英特尔）也可能受益；Nvidia也在这个细分市场运营。</p>
  <p><strong>数据管理服务提供商是另一大潜在赢家。</strong>显而易见，没有数据就没有人工智能，要使用开放模型开发应用程序，采用者需要大量数据进行训练和部署，这需要适当的数据管理。因此，随着不同 AI 模型数量的增加，数据管理将变得越来越重要。MongoDB 、Databricks 和 Snowflake 等数据管理公司以及超大规模企业提供的相关产品都将从中获利。</p>
  <p><strong>GenAI 服务提供商同样受到明显的积极影响。</strong>DeepSeek 的崛起表明 GenAI 的复杂性仍在增长，不同模型的可用性增加了复杂性，从而推动企业对 GenAI 服务的需求。不过，如果领先的 GenAI 模型（如 DeepSeek R1）免费提供，企业可自行试验和部署，可能会减少对 AI 集成服务的需求。综合而言，随着新技术不断涌现，企业将寻求最佳方式利用开源模型，这将推动 GenAI 服务需求增长。</p>
  <h3><strong>带来的影响尚不确定</strong></h3>
  <p><strong>云计算提供商受到的影响是中性的。</strong>一方面来看优势，DeepSeek R1 已被微软 Azure AI Foundry、AWS Bedrock 和 Amazon Sagemaker 集成，云服务商虽然投资 OpenAI 和 Anthropic，但仍保持开放模式，支持多种模型的托管、训练和微调，更高效的模型降低了资本支出，有助于提高云计算利润率；另一方面来看劣势，随着边缘计算能力增强，模型推理可能更多地转移到本地设备，减少云端推理需求，此外，更高效的训练方法可能进一步降低训练成本。总结来看，更小、更高效的模型减少了对云计算的依赖，但整体 AI 需求的增长和 CAPEX 下降可能抵消影响。</p>
  <p><strong>EDA 软件提供受到的影响也是同样的道理。</strong>有利的方面来看，AI 计算负载日益专业化将带来对新型 AI 芯片的需求的增加，而 EDA 工具在 AI 专用芯片设计中至关重要；不利的方面来看，如果 AI 模型趋向y小型化、低资源消耗，那么高性能数据中心 GPU 和 ASIC 设计的需求可能减少，从而降低 EDA 工具在高端 AI 芯片领域的授权收入。Synopsys 和 Cadence 等 EDA 供应商可能受益于 AI 硬件多样化，但行业需适应新趋势，更多关注边缘、消费级和低成本 AI 计算芯片设计，而非大型数据中心 GPU。</p>
  <h3><strong>谁是可能的输家？</strong></h3>
  <p><strong>AI 芯片相关企业可能会成为输家。</strong>固然，AI 训练成本的降低可能会推动整体 AI 芯片需求上升，即“杰夫森悖论”（即效率提升反而增加需求）。ASML 首席执行官也有类似的想法：“AI 成本降低可能意味着更多的应用，更多的应用意味着随着时间的推移需求会更多。我们认为这是增加芯片需求的机会。”但劣势也相当明显——DeepSeek R1 训练成本下降主要由于减少对高端 GPU 的依赖，这可能影响高性能 AI 芯片的投资回报，并影响大规模 AI 芯片采购计划（如最近宣布的星际之门项目）。IoT Analytics 研究显示，NVIDIA 在数据中心 GPU 市场占比高达 92%，但如果 AI 模型所需硬件减少，可能会削弱 NVIDIA 的增长前景。</p>
  <p><strong>数据中心相关行业（网络设备、电力基础设施、冷却系统）可能也会受到冲击。</strong>如果 AI 训练和推理变得更高效，对高端数据中心 GPU 的需求下降，数据中心扩张的必要性也会减少。这可能影响网络设备、电力基础设施（如电网技术）、服务器冷却解决方案的市场需求。</p>
  <p><strong>不过，笔者也看到过一些相反的观点。比如 TrendForce 集邦咨询近日发布的研报指出，DeepSeek 模型虽降低 AI 训练成本，但 AI 模型的低成本化有望扩大应用场景，进而增加全球数据中心建置量。</strong></p>
  <h3><strong>谁是明显的输家？</strong></h3>
  <p><strong>专有模型提供商将受到比较大的负面影响。</strong>那些已经在 GenAI 领域投入巨资的专有模型公司（如 OpenAI、Anthropic）正在或即将蒙受损失。DeepSeek R1 的开源策略削弱了专有模型的竞争优势。即便这些公司推出更多开源模型，也会影响其当前的盈利模式。此外，DeepSeek 证明了顶级 AI 模型可以免费开放，未来专有模型的“护城河”变得不确定。当 DeepSeek 以免费（用于本地部署）或非常便宜（其 API 比同类模型便宜一个数量级）的方式发布强大的模型，OpenAI 、Anthropic 和 Cohere 等公司可能面临激烈竞争。</p>
  <h2><strong>写在最后</strong></h2>
  <p>DeepSeek 的发布只是产业链变革的一个起点，未来还将有更多意想不到的变化发生。赢家和输家的界限或许尚未最终划定，而真正决定企业命运的，仍然是它们在未来几年内的战略选择。在这场智能化的竞赛中，谁能笑到最后？或许，我们很快就会见分晓。</p>
  <p><strong>参考资料：</strong></p>
  <p>DeepSeek R1’s implications: Winners and losers in the generative AI value chain，iot-analytics</p>
  <p>芯报丨AI搜索公司Perplexity完成5亿美元融资，AI芯天下</p>
  <p>DeepSeek超ChatGPT成全球增长最快AI应用！下载破4000万，日活超豆包登顶中国No.1,量子位</p>
  <p>DeepSeek 的低成本 AI 模型将催生光通信需求，TrendForce</p>
  <p>华为云、ZStack、腾讯云、阿里云、百度云：首批上线 DeepSeek，大江网</p>
  <p>DeepSeek引爆中国AI投资狂潮 港A股这是要复刻2023年“美股疯牛”?，智通财经</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MTM5ODQyMA==&amp;mid=2651322079&amp;idx=1&amp;sn=103f775d3b6b96e6b5ec8c2adaa486d6&amp;chksm=bc2742413eb043ab184d628e76e3cce966ecf47cf32791997d36edcff187b797150d93cbf65b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“物联网智库”（ID：iot101）</a>，作者：Sophia，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156346391976456</id>
            <title>钱塘征信正式成立，蚂蚁集团持股29.9%</title>
            <link>https://www.36kr.com/p/3156346391976456</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156346391976456</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:06:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 钱塘征信, 个人征信, 股东结构, 市场化原则  
<br><br>  
总结: 钱塘征信有限公司于2025年正式成立，成为国内第三家个人征信公司，注册资本为10亿元。其股东结构多元，包含国有资本和民营企业，主要股东包括浙江省旅游投资集团和蚂蚁集团。钱塘征信将按照市场化原则设立股东会、董事会等管理机构，未来致力于提供多样化的个人征信产品，支持普惠金融发展。分析师认为其多元股东结构有助于行业竞争和长远发展。 </div>
                        <hr>
                    
                    <blockquote>
   <p>钱塘征信称，后续将按照市场化原则设立股东会、董事会、监事会和高级管理层</p>
  </blockquote>
  <p>继百行征信、朴道征信之后，国内第三家个人征信公司正式成立。</p>
  <p>国家企业信用信息公示系统显示，2025年2月5日，钱塘征信有限公司（下称“钱塘征信”）完成工商登记，经营范围包括个人征信业务等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0e9ab8872c5a41f99fcc087eae90f0aa@000000_oswg221255oswg865oswg595_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2024年11月11日，中国人民银行（下称“央行”）公告称，钱塘征信获准设立经营个人征信业务，并对其董事、监事、高级管理人员予以公示。</p>
  <p>工商登记信息显示，钱塘征信注册资本10亿元，由六名股东共同出资。其中，浙江省旅游投资集团有限公司（下称“浙江旅投”）持股40.1%，为第一大股东；浙江融信网络技术有限公司持股（下称“浙江融信”）29.9%，为第二大股东，该公司是蚂蚁集团全资子公司；杭州溪树企业管理合伙企业（有限合伙）（下称“杭州溪树”）持股10%，为第三大股东；传化集团有限公司持股7%，为第四大股东；浙江电子口岸有限公司和杭州市金融投资集团有限公司分别持股6.5%。</p>
  <p>根据央行此前公示的牌照申请信息，浙江旅投和蚂蚁集团拟各自持股35%。正式成立后，浙江旅投持股比例为40.1%，蚂蚁集团通过浙江融信间接持股29.9%，其余股东持股比例不变。</p>
  <p>据了解，各股东持股比例由股东按市场化原则平等协商确定。钱塘征信方面表示，未来将践行征信为民理念，秉持“信用为本、平等普惠”的发展原则，为金融机构提供更加多样、更加丰富的个人征信产品，支持普惠金融发展。</p>
  <p>这一股权结构与其余两家个人征信公司类似，既包括国有资本，也包括民营企业。</p>
  <p>天眼查显示，百行征信第一大股东为中国互联网金融协会，持股比例36%；芝麻信用、考拉征信、中诚信征信、腾讯征信、深圳前海征信等八家企业分别持股8%。</p>
  <p>朴道征信第一大股东为北京金融控股集团有限公司，持股比例35%；京东科技、旷视科技、小米、北京聚信优享企业管理中心（有限合伙）分别持股25%、17.5%、17.5%和5%。</p>
  <p>博通咨询金融业资深分析师王蓬博认为，<strong>在风险可控的前提下，征信信息建设一直坚持“政府+市场”双轮驱动，钱塘征信股东结构多元，能够在信息安全、数据、场景及技术方面形成优势并互补，有利于行业形成良性竞争和长远发展，提振市场信心。</strong></p>
  <p>除了前两大股东，市场也颇为关注钱塘征信第三大股东杭州溪树企业管理合伙企业（有限合伙）。</p>
  <p>工商信息显示，杭州溪树成立于2021年9月3日，同年11月26日，央行公示受理了钱塘征信的个人征信业务申请。</p>
  <p>杭州溪树工商登记的营业场所为浙江省杭州市西湖区西溪路543号-569号（单号连续）1幢2号楼5层515室，而蚂蚁集团登记地址为浙江省杭州市西湖区西溪路543号-569号（单号连续）1幢2号楼5层517室，二者相邻。</p>
  <p>杭州溪树共有两名合伙人，分别是孔令仁和李臻，后者同时担任执行事务合伙人。</p>
  <p>公开信息显示，孔令仁曾担任蚂蚁集团企业融资部总监。在2021年钱塘征信牌照申请的董监高拟任名单中，孔令仁拟任财务负责人。李臻曾任芝麻信用联席总经理。2024年7月，芝麻信用发生工商变更，李臻卸任经理一职。</p>
  <p>目前，李臻同时担任钱塘征信董监高成员和法定代表人。</p>
  <p>央行2024年审批通过后公示的钱塘征信董监高名单中，2021年公示的拟任总裁和股东董事董占斌、股东董事余泉、独立董事胡少先、财务负责人孔令仁均未出现，同时新增了李臻、聂正军、陈亮，三人均在蚂蚁集团任职多年。</p>
  <p><strong>截至目前，央行与钱塘征信尚未公布钱塘征信董监高人员具体任职信息，第三家个人征信机构高管格局有待进一步明确。</strong></p>
  <p>钱塘征信称，后续将按照市场化原则设立股东会、董事会、监事会和高级管理层，聘请具备专业性、良好声誉的独立董事，提升公司治理水平和社会责任担当。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkyMjY5MTQ1Nw==&amp;mid=2247628348&amp;idx=2&amp;sn=66db5ad24142a0a2fab1d949e1ffb579&amp;chksm=c074b15a0da143f793b520d1718089b46af0b1f9f884aef850a2fb6204b5b61c4128fd8909b5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“财经五月花”（ID：Caijing-MayFlower）</a>，作者：唐郡，编辑：张威，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156054213483010</id>
            <title>小米市值突破 1 万亿，造小米 SU7 成了雷军最好的决策</title>
            <link>https://www.36kr.com/p/3156054213483010</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156054213483010</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:03:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米集团, 股价, SU7, 市值  
<br><br>  
总结: 小米集团在2024年股价表现突出，涨幅121%，市值突破万亿港元。小米SU7的成功推出是股价上涨的重要驱动力，交付量不断攀升，市场反响超出预期。尽管小米在造车初期面临质疑，但凭借精准的市场定位和高效的营销策略，成功打破行业壁垒。小米汽车的产能提升和新车型YU7的推出，将进一步影响市场格局和小米的股价表现。 </div>
                        <hr>
                    
                    <p>2 月 6 日，小米集团的港股迎来了强劲上涨，股价突破到 40.55 港币，涨幅为 2.27%，<strong>市值突破万亿港元大关，达到了 1.02 万亿港元，创下历史新高</strong>。</p>
  <p>回顾 2024 年，小米集团的股价表现尤为亮眼，其涨幅高达 121%，远超同期恒生科技指数的 18.7%。进入 2025 年，小米集团股价继续上涨，增幅为 17.54%。</p>
  <p>插入短视频「小米市值破万亿」</p>
  <p>相比之下，其他科技巨头的表现则较为温和。2024 年，阿里巴巴上涨 11%、京东上涨 24%、腾讯上涨 44%、美团上涨 85%、网易上涨 1%，这些公司都未能达到小米的增长水平。</p>
  <p>从 2018 年 7 月 9 日上市港股，到很快破发，市值始终徘徊在低谷；再到凭借 SU 7 和小米汽车的成功，小米的「万亿市值」路走的并不平坦，而小米汽车，对于雷军的意义，显然非同寻常。</p>
  <h2><strong>01 小米 SU7，平等撞飞所有对手</strong></h2>
  <p>2024 年，小米迎来了厚积薄发的一年，尤其在汽车领域的布局。<strong>小米 SU7 的推出，成为股价大幅上涨的重要驱动力</strong>。</p>
  <p>雷军曾透露，小米 SU7 的市场反响远超预期，成功程度是最初预想的 3 到 5 倍。这一出乎意料的成功，促使小米汽车一次次调整年初设定的目标，逐步从 7 万辆、10 万辆、12 万辆，最终突破至 13.5 万辆的交付成绩。</p>
  <p>回顾小米在汽车领域的开局，可以说是在怀疑和质疑中起步的。作为 2021 年才宣布进军造车行业的企业，小米在新造车势力中入局最晚，第一辆量产车小米 SU7，直到 2024 年 3 月才正式交付。</p>
  <p>当时的局面对小米来说，压力山大。</p>
  <p>在手机领域，小米曾肩负起推动智能手机普及的重任，时代也给予了它丰厚的回报。然而，到 2023 年底，新能源汽车的渗透率已接近 40%。面对如此竞争激烈的市场，小米要做的，不是以低价推动普惠，而是要探索智能汽车的边界，将产品推向更高品质。这并不是小米特别擅长的节奏。</p>
  <p>外界对小米造车的怀疑声音，在长时间内始终未曾消退。2023 年 12 月 28 日，小米举行了第一个汽车技术发布会，初期的热度非常高，但很快，质疑与批评声接踵而至。有一句友商的话广为流传：「军儿，收手吧，外面都是 XX。」</p>
  <p>雷军曾回忆道，在那段艰难的时刻，他让市场部邀请了 20 多位媒体朋友，为小米汽车的未来出谋划策。出乎意料的是，绝大多数人并不看好小米的造车之路。他们普遍认为：</p>
  <p><strong>每个月能卖出 3000 辆车，就已经是难得的成功了</strong>。</p>
  <p>在这种不被看好的氛围中，小米汽车艰难前行。2024 年 3 月 28 日，小米 SU7 发布会一结束，短短时间内大定量突破了 5 万台，首销期中有 60% 的「天使单」，即消费者未曾试驾便直接下单。尽管这一火爆的订单量令业界瞩目，但外界对能否持续热销以及小米的交付能力，仍然存在疑问。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a7c1f84226b5412a8b7136a7a7c417bf@000000_oswg168734oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">小米集团过去一年的股价表现 | 图片来源：雪球</p>
  <p>随着交付期的开启，小米股价也开始稳步上涨。</p>
  <p>2024 年 4 月和 5 月的交付量分别为 7000 辆和 8600 辆，资本市场保持观望态度。然而，从 6 月到 9 月，小米 SU7 的交付量连续保持在 1.3 万辆以上，小米集团股价也突破 20 港元大关。从 10 月到 2025 年 1 月，小米连续四个月交付量超过 2 万辆，股价更是节节攀升。</p>
  <p>在 2024 年年底的跨年直播中，雷军提出了第一个新年 flag：「2025 年将加速交付，交付目标为 30 万辆。」</p>
  <p><strong>这一目标彻底激发了资本市场的热情，小米市值也最终突破了 1 万亿港元大关</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_02418685ac994fc6b464131136c4ac54@000000_oswg111610oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>小米 SU7 Ultra 的价格高达 81 万元，第一次敲开了超级电动轿跑市场的大门 | 图片来源：小米</p>
  <p>对于小米汽车取得成功的原因，主要有三个方面：</p>
  <p>1 小米对造车这件事的复杂度，有足够认知，投入也足够大。据了解，<strong>小米在汽车研发上的投入超过了 130 亿元，累计投入已接近 300 亿元</strong>，这还不包括小米集团其他相关资源的投入。显然，足够的资金和对市场的深刻理解是小米能够快速在汽车行业立足的基础。</p>
  <p>2 精准的市场定位。当时，SUV 市场的竞争已然非常激烈，小米想要在这个领域击败对手，难度可想而知。因此，小米巧妙地绕过了消费者偏爱的 SUV，转而在相对「冷门」的轿车市场发力，成功塑造了品牌认知。这一策略类似于选择了一个细分市场（即「利基市场」），并从 0 到 1 地进行拓展。尽管这种选择在当时被认为是「小众」，但实际上，小米抓住了市场中的潜在需求。</p>
  <p>3 小米被认为是国内最会做营销的车企。360 集团创始人周鸿祎在自己的 AI 课程中提到的，雷军不仅在产品上精益求精，更在营销策略上展现了大师级的智慧。他表示：</p>
  <p><strong>小米 SU7 的发布，堪称汽车行业的一堂免费的营销课</strong>。</p>
  <p>周鸿祎认为，传统车企的老板虽然也有不少业内影响力，但他们普遍采用的是 ToB 的思维模式，即主要通过经销商与用户间接接触。而雷军则大胆采用了 ToC 的互联网思维，直接与用户打交道。这种方式在短视频时代尤其有效，使得小米能够快速吸引消费者的注意并与其建立情感连接。</p>
  <p>小米 SU7 的成功，可以视为小米模式和小米方法论的成功体现。早年间，雷军就提出了「顺势而为」的商业理念，并总结出了「小米方法论」的七字诀：专注、极致、口碑、快。这个理念贯穿了小米的所有产品和战略，从手机到智能硬件，再到如今的汽车，都有着鲜明的印记。</p>
  <h2><strong>02 下一个目标，Model Y</strong></h2>
  <p>自上市以来，产能一直是制约小米汽车销量的主要瓶颈。2024 年，小米汽车交付量超过 13.5 万辆，但由于产能不足，小米 SU7 仍面临大量未交付订单。</p>
  <p>根据第三方统计，<strong>截至 2024 年 12 月底，小米汽车累计收获订单已超过 26 万份，其中已完成交付的订单约为 13.5 万份</strong>。这意味着，即便考虑到因超长交付时间而流失的部分用户，小米汽车内部仍积压着超过 10 万份的订单。</p>
  <p>小米汽车的生产能力也在不断提升。据了解，小米一期工厂的额定年产能为 15 万辆，月产能为 1.25 万辆。通过双班生产和产线优化，小米成功将月产能提升至 2.4 万辆，然而，仍未能完全满足市场的强烈需求。因此，小米正在建设二期工厂，预计将在 6 月竣工，进一步应对需求增长。</p>
  <p>然而，除了产能问题外，另一关键因素是小米汽车的第二款车型——小米 YU7。雷军曾透露，小米的产品计划中，小米 SU7 Ultra 将于 3 月上市，而小米 YU7 预计将在 6 月至 7 月间推出。作为小米未来的重要战略车型，YU7 被寄予厚望，尤其是在与特斯拉 Model Y 的竞争中，备受瞩目。</p>
  <p>作为 20-30 万元新能源市场的标杆车型，特斯拉 Model Y 吸引了大量竞争对手的「围攻」。2024 年 9 月到 10 月之间，包括乐道、极氪、智界、智己、阿维塔、岚图在内的六家车企陆续发布了新产品，这些车型几乎都将 Model Y 作为竞争对标对象。这一现象被外界戏称为「六大门派围剿特斯拉 Model Y」。</p>
  <p>尽管这些新兴品牌的车型在订单量和产品力上有所提升，但从实际销量来看，它们仍未能真正挑战 Model Y 在纯电 SUV 领域的领导地位。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_decfd34f97084dd7a76c2f44fc29460c@000000_oswg652228oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">备受关注的小米 YU7，即将在 6 月份上市 | 图片来源：小米</p>
  <p><strong>小米 YU7，被认为是最有机会把特斯拉 Model Y 拉下神坛的玩家</strong>。</p>
  <p>毕竟，小米已经有过成功的经验。2024 年 7 月，乘联会数据显示，小米 SU7 的单月交付量首次超过特斯拉 Model 3，成功成为 20 万元以上纯电轿车的销售冠军。同年 12 月，小米 SU7 继续表现强劲，以 2.58 万辆的销量位居第五，而特斯拉 Model 3 则以 2.1 万辆的销量位居第六。</p>
  <p>小米的造车之路，从初期的质疑到如今的成功，不仅展示了其在智能硬件领域的优势，还通过精准的市场定位和高效的营销策略，成功打破了行业壁垒。随着产能的逐步提升与新车型的陆续推出，小米正在为未来的发展奠定坚实基础，尤其是在与特斯拉 Model Y 的竞争中，YU7 的推出有望成为改变市场格局的重要一环。</p>
  <p>2025 年汽车市场的竞争烈度，相比去年会再上一个台阶。而小米 YU7 的成绩，会和小米 SU7 一样，对小米集团的股价有着巨大影响。毕竟，你现在已经很难再把小米看成是一家单纯的消费电子公司了。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653073410&amp;idx=1&amp;sn=86acbc0ecd07453414ccd454d0273800&amp;chksm=7fb52ab0a66aa09b52e78dd7bfa42c7d1d1f9be2cae555a0ef6e3caa55efa974c69cfb7d7e73&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：周永亮，编辑：靖宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156369267694336</id>
            <title>第一批DeepSeek“受害者”出现了，公司最高裁员95%，员工想转行做保洁</title>
            <link>https://www.36kr.com/p/3156369267694336</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156369267694336</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:03:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <DeepSeek, 裁员, AI, 上美股份>
<br>
<br>
总结: 上美股份董事长吕义雄宣布大规模裁员，裁员比例最高达95%，主要依据是员工是否能使用AI。裁员涉及多个部门，法务部、客服部和内容创新部门的裁员比例尤为显著。尽管吕义雄在新年贺信中提到要提升员工的工作幸福感，但实际行动却与此相悖，引发员工的不满和焦虑。网友对此反应强烈，有人认为AI只是裁员的借口，强调会用AI的人在未来不会失业。AI的应用正在改变工作方式，成为提高工作效率的重要工具。 </div>
                        <hr>
                    
                    <p>第一批 DeepSeek “受害者”已经出现了！</p>
  <p>有的老板开年发红包，有的老板财源广进。</p>
  <p>2月6日，网上流传出一张<strong>上美</strong>的内部群聊天图，截图显示<strong>董事长兼 CEO 吕义雄</strong>对各部门下达裁员指示，称<strong>只留下能用AI的人，部门最高裁员比例达到95%</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1bcd39398f0b4fe1af660d54d45f9d00@000000_oswg1222381oswg1080oswg2341_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中，</p>
  <p>法务部裁员50%，只留20%能用AI的人；</p>
  <p>客服部裁员95%，只留5%能用AI的人；</p>
  <p>新品创新中心裁员70%，只留30%能用AI的人及工艺把控的人；</p>
  <p>内容创新部门裁员80%，只留20%能用AI的人，并且一个团队要做出20个团队的活。</p>
  <p>吕义雄还提到要训练<strong>通过鼠标+语言与AI对话，取消键盘</strong>。</p>
  <p>没有键盘，想象一下整个大楼的员工都在不停说话，应该会有点吵。</p>
  <p>上美股份是一家本土化妆品公司，旗下产品包括<strong>护肤品牌韩束、一叶子，母婴品牌红色小象、newpage一页</strong>等，于2023年在香港联交所主板挂牌上市。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f7740c3a46cc4067bbade34b52ce021e@000000_oswg896648oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>近期上美股份股价表现积极，今日股价继续上涨，收盘时股价37.50港元，总市值149.26亿元，表现出市场对其AI转型的认可。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fa4e79809e2e4ed494b1df6822c26ecf@000000_oswg79494oswg665oswg691_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>春节期间，吕义雄发布的新年贺信中，还写着要“提升上美人的工作幸福感，一起分享劳动果实”，结果年还没过完，吕总已经想把“家人们”开了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1e1118a8d1804d0099c86f73daec29ec@000000_oswg461684oswg673oswg661_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>AI成裁员主因</strong></h2>
  <p>消息一出，网友也是炸开了锅。</p>
  <p>小红书上，有上美员工心态挺好，已经打算去干保洁了，名字也改成了“上美保洁”，毕竟保洁不会被AI替代。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ba572f89b1c146d690c4f33e3278fa5a@000000_oswg372115oswg1009oswg757_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>针对裁员重灾区客服部门，有网友明确表示讨厌AI客服，担心之后可能会加大人工客服的工作量。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c55fe4704b904069b77832ef48763aa5@000000_oswg22562oswg391oswg259_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>擅长数学的网友则热心指出了裁员的漏网之鱼，裁员50%，留下20%，剩下30%去哪了？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_64607ad541b44e8288a5c076fe65048d@000000_oswg12317oswg382oswg131_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>顺便再向AI请教下，裁这么多人要赔多少钱。这个可能得以万计算了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5bea5fb96bdb4dae9e7847d4639837ea@000000_oswg8008oswg373oswg112_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过，也有聪明的网友扶了扶柯南的眼镜框，指出AI不过是裁员的借口。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_28205eaa9cc148489502dd51aee0b8c8@000000_oswg21690oswg387oswg247_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>就在几天前，化妆品巨头雅诗兰黛发布2025年第二季度（2024年10月-12月）财报时，因业绩亏损，宣布了近10年来最大规模的裁员计划，裁员5800-7000人。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1a7f5044f09f423eaf44e078f265b969@000000_oswg1136951oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>事件发酵后，吕义雄在朋友圈回应，称不是要裁员，有的地方加人，有的地方减人。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2efb9f37fec14d7fa357907224add1c4@000000_oswg216908oswg700oswg506_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有昵称是“上美保洁”的网友表示，不是真裁员，只是给员工制造焦虑，老板强调的是AI的重要性，要学会用AI来提高工作效率，并称上美本身就有淘汰制。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0166d3e7f3d04ca5a66c151b6639558c@000000_oswg31766oswg385oswg362_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>拥抱DeepSeek成大趋势</strong></h2>
  <p>不可否认的是，AI正逐渐改变着人们的工作方式。</p>
  <p>在小红书上，博主“英语老师Jannie”直接把DeepSeek叫做“AI时代的魔法奇迹”。</p>
  <p>称自己以往出一套试卷题要花两三天的时间，现在用DeepSeek出题，省时省力，而且还有针对性。</p>
  <p>AI时代，学生不用担心考试卷子不够多了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_843acb25b7ca4e4eae4d9ca0f7034f57@000000_oswg477945oswg862oswg815_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>山东大学第二医院髋痛专业殷医生在与DeepSeek交谈时发现，它就像一个青年专家一样。</p>
  <p>对于疾病的关键点，比如诱发因素、原理都呈现得十分清楚，甚至包含了不同专家观点的争论，专业能力让他刮目相看。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_18b77910c2b3459d8ad2e29f31810504@000000_oswg1050751oswg1077oswg1077_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在小红书上热衷科普法律案例的“若飞律师”，在使用DeepSeek后感叹“真是小瞧它了”，表示之前只把AI看做是辅助工具，现在把它当做团队的成员。</p>
  <p>以往做案例检索的初筛要花将近2个小时，DeepSeek只需要2到3分钟，大大节省了时间。</p>
  <p>内容中的错别字、语句语意的纠正更是不在话下。遇到陌生领域的问题，DeepSeek还可以快速帮助检索和学习。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a64e52ebd4f84b98bc6b9c7626ce1ae7@000000_oswg517647oswg857oswg820_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>会用AI的人不会失业</strong></h2>
  <p>过去，人们总担忧AI第一个淘汰的职业会是程序员。</p>
  <p>现实却是AI辅助编程工具Cursor成为历史上最快突破一亿美金收入的 AI 应用，成为了数百万程序员的首选编辑器。</p>
  <p>程序员这个职业没有被淘汰，但确实会让很多不用AI的程序员失业。</p>
  <p>大浪潮下，会用AI的人不会失业，他们只会让别人失业。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5NzAwNzMyMA==&amp;mid=2660165496&amp;idx=1&amp;sn=060f143a1e3cdfd921f079b07812ad50&amp;chksm=bc7cea2f2b31d2090da6691d5999e0e3d508e5c542520c7fd9fc92429135824f850e8d904497&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“科技每日推送”（ID：apptoday）</a>，作者：赵芷姗，编辑：汤安迪，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156368678476551</id>
            <title>头部VC大洗牌：合伙人离职内幕</title>
            <link>https://www.36kr.com/p/3156368678476551</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156368678476551</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:03:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 风投, 合伙人, 人工智能, 新兴基金  
<br><br>  
总结: 近年来，风投行业经历了合伙人结构的重大变化，许多合伙人选择离开老牌公司，转投新兴基金或自立门户。前Facebook产品负责人迈克·弗纳尔提出，成功的风险投资公司应专注于未来十年内具有重大影响力的趋势。随着生成式人工智能的崛起，Conviction公司的创始人郭睿迅速崭露头角，成功筹集了规模达1.15亿美元的基金，并投资了多家初创公司。合伙人离职的原因主要包括财务激励不足和合伙人结构臃肿。新兴基金在募资方面表现良好，尤其是在人工智能领域，显示出强大的市场潜力。 </div>
                        <hr>
                    
                    <blockquote>
   <p>一群合伙人正纷纷离开老牌风投公司，转投新兴基金或自立门户。来认识一下风投界的新势力吧。</p>
  </blockquote>
  <p>2023年，前Facebook产品负责人迈克·弗纳尔（Mike Vernal）离开红杉资本后，花了很多时间思考什么样的策略对一家新的风险投资公司来说才算理想，能帮助它赢得交易并迅速站稳脚跟。</p>
  <p>他的方案是：<strong>“挑选一个将会产生重大影响力的趋势，一个在未来十年具有决定性意义的趋势，然后成为该领域的顶级管理者。”</strong></p>
  <p>过去十年，Ribbit在金融科技领域做到了这一点，它投资了Coinbase、Nubank和Robinhood等明星公司，让米奇·马尔卡（Micky Malka）在《福布斯》全球最佳创投人榜（Midas List）上名列前茅。Paradigm在加密货币领域取得了成功，对比特币和以太坊，以及初创公司Chainalysis和Uniswap都作出了明智的投资决策。</p>
  <p>随着生成式人工智能的兴起，弗纳尔坚信他找到了在下一轮风投变革中崭露头角的赢家：Conviction公司的创始人郭睿（Sarah Guo）。</p>
  <p>不久前，郭睿还只是个初现锋芒的新人，是老牌“蓝血”风投公司Greylock新一代的年轻合伙人，之后单飞创业。在OpenAI发布ChatGPT并引发投机热潮的几周前，她宣布成立自己的首只基金，规模达1.15亿美元，专注于人工智能。此后，她早早投资了一些人工智能初创公司，这些公司的估值如今已飙升至数十亿美元，其中包括Cognition、Harvey、Mistral和Sierra，她还与技术专家埃拉德·吉尔（Elad Gil）共同推出了一档广受欢迎的人工智能主题播客《No Priors》。弗纳尔说：“显然，她已成为人工智能领域最睿智、人脉最广的投资者之一。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c50b0633b468466aabc48e8a70887c5c@000000_oswg99078oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Conviction的郭睿和迈克·弗纳尔此前分别就职于老牌风投公司Greylock和红杉资本。图片来源：Ellian Raffoul Photography</p>
  <p>迈克·弗纳尔投资过Clay、Notion、Rippling和Verkada等估值达数十亿美元初创公司。郭睿先是与他共事数月，以观察彼此是否合作默契无间，随后她正式邀请弗纳尔担任Conviction的第二位普通合伙人。</p>
  <p>二人向《福布斯》独家透露，他们现已筹集到第二只基金，规模为2.3亿美元。郭睿表示，这只基金的规模是Conviction首只基金的两倍，而且筹集过程比首只基金还要顺利。她说：“两只基金的筹集过程都很顺利。但第一次筹资时，有人质疑我们的投资渠道和能力是不是在一定程度上得益于我们之前背靠的大平台。”而第二次，这种质疑就少多了。</p>
  <h2>01</h2>
  <p>Conviction增加合伙人以及扩大第二只基金规模（The Information去年11月率先报道了相关早期消息）都是近期一个趋势的最新体现。近几个月来，这一趋势一直是董事会会议、行业假日派对和群聊的热门话题：<strong>风投行业的合伙人结构发生了巨大变化，其规模之大，业内多年未见。</strong></p>
  <p>几个月来，尤其是在刚刚过去的假日季，那些成立数十年的老牌公司以及新崛起的行业巨头的合伙人纷纷在领英（LinkedIn）和X平台上宣布他们即将开启新征程。</p>
  <p>这份名单很长，在此仅列举其中几位：光速创投（Lightspeed）的亚历克斯·陶西格（Alex Taussig）和妮可·奎因（Nicole Quinn）；红杉资本的马特·米勒（Matt Miller）；安德森·霍洛维茨（a16z）的斯里拉姆·克里希南（Sriram Krishnan）和米歇尔·沃尔兹（Michelle Volz）；Lux Capital的比拉尔·祖贝里（Bilal Zuberi）。</p>
  <p>奎因仍在光速创投兼任部分工作，克里希南最近则被任命为特朗普政府白宫人工智能政策顾问，像他们这样的人目前可能还不打算自立门户，不过其他很多人都有此打算。一位了解米歇尔·沃尔兹计划的消息人士称，她正在筹备一只由个人担任合伙人的种子前和种子阶段基金，专注“美国活力”（American Dynamism）领域。</p>
  <p>这一概念由她的前雇主提出，广义上涵盖与国家利益相关的领域，如航空航天、国防和制造业。沃尔兹未回应置评请求。尚未正式离开Lux的祖贝里表示，他计划成立一家公司，专注于人工智能与物理世界交叉领域的种子轮和A轮交易。祖贝里告诉《福布斯》：“我认为一些资深普通合伙人意识到，他们的热情和专长都在专注于早期阶段的纯粹风投上，这与许多多阶段投资公司所做的事情有些不一样。”</p>
  <p>还有更多人准备行动起来。</p>
  <p>Forerunner Ventures的网站显示，合伙人布莱恩·奥马利（Brian O’Malley）最近转任董事合伙人；两位消息人士称，最近他一直在与各方会面，探讨筹集自己基金的可能性。另有三位消息人士称，Index Ventures的合伙人达米尔·贝西罗维奇（Damir Becirovic）最近离职，着手创立一家新公司。他在领英上更新了自己的头衔，显示为Relentless公司的联合创始人，这家新的风投公司“只为最具雄心壮志之人服务”。奥马利和贝西罗维奇未回应置评请求。此前也未有关于他们离职的报道。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4a079e0cadc046788d86004ecf97a851@000000_oswg29423oswg1080oswg528_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>去年10月，Chemistry公司联合创始人Kristina Shen与联合创始人马克·戈德堡（Mark Goldberg）和伊桑·库尔兹韦尔（Ethan Kurzweil）宣布成立规模达3.5亿美元的首只基金，他们三人分别来自安德森·霍洛维茨、Index Ventures和柏尚投资（Bessemer Venture Partners）。她接着说道，“如果2025年的离职人数超过去年，我也不会感到惊讶。”</p>
  <p><strong>在风投行业的每一个兴衰周期，都不乏传奇人物退休、新秀离巢与老东家竞争，也会有不少表现不佳的人悄然离开竞争激烈的公司。</strong></p>
  <h2>02</h2>
  <p>即便如此，多位来自知名机构（如捐赠基金）的资金配置者在接受《福布斯》采访时（多数人因未获授权接受媒体采访而要求匿名）表示，与以往常见的人员变动相比，他们在过去一年左右的时间里注意到了一个重大转变。其中一位表示：“很难确切指出原因所在，因为数据显示新成立的基金总数并没有那么多。但所涉人员的资质让人感觉情况确实不太一样了。”</p>
  <p><strong>具体到个人层面，合伙人离开风投公司的原因往往难以确切界定。</strong>每段合作关系都有其独特的内部政治、经济纠葛和背后隐情。就像恋人分手一样，不同的人对于某次离职的说法也可能不尽相同，全看你询问的对象是谁：公司可能会淡化人才流失的影响，而合伙人可能会迫于压力夸大自己此前在公司的地位。</p>
  <p>但无论他们是主动离开老牌公司，还是被迫离开，合伙人离职通常可归因于2025年风投行业面临的两个共同问题：财务激励措施形同虚设以及臃肿的合伙人结构。</p>
  <p><strong>薪酬问题正在那些业绩出色、履历亮眼的合伙人当中引发普遍的焦躁情绪。</strong></p>
  <p>随着许多公司的基金规模不断扩大，参与预期利润分成对合伙人的激励作用可能越来越小。通常情况下，要等提供了大部分资金的有限合伙人收回本金后，才开始发放合伙人的附带权益（也就是carry）。对于一只规模达数十亿美元的基金来说，收回本金并非轻而易举之事。2020年和2021年零利率、快节奏的投资环境将初创公司的估值推至离谱的高度，这使得实现盈利的挑战更加艰巨。</p>
  <p>“当一只基金的回报率达到3倍、4倍甚至5倍时，你其实并不想离开，”&nbsp;经常协助合伙人谈判退出协议的律师事务所Lowenstein Sandler合伙人埃德·齐默尔曼（Ed Zimmerman）表示。但一些规模庞大的基金若能实现资金翻倍甚至回本，就已属幸运。齐默尔曼补充道：“过去一两年，我们确实听到客户说，他们不太有把握能从自己的上一只基金获得收益分成了。”</p>
  <p>“人们逐渐意识到，有些基金甚至可能根本无法回本，” Category Ventures创始人维利·伊尔切夫（Villi Iltchev）说。他于去年12月离开Two Sigma的风投部门，成立了规模达1.6亿美元的首只基金。“在大公司里，你的付出与回报之间可能几乎没有关联。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9b40e293792241d1af344bca2b97aa04@000000_oswg39691oswg1080oswg559_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2>03</h2>
  <p>风投公司也做不到始终忠诚。随着大型基金和多策略公司兴起，安德森·霍洛维茨、General Catalyst、恩颐投资（NEA）、红杉资本和Thrive Capital等公司管理的资产膨胀至数百亿美元，这些公司的运营模式变得越发像华尔街及其私募巨头。“有些人在由首席执行官领导的大型组织中如鱼得水，而有些人则像独行侠，” Conviction公司的弗纳尔说。</p>
  <p>近来，由于首次公开募股（IPO）数量不足以及大规模收购活动减少，风投公司及其投资者从投资中获得的现金回报受到了限制。一些基金因此感受到了压力，不得不筹集规模较小的基金，并暂停后期投资项目。结果，一些合伙人在公司的规划中就显得有些格格不入，尤其是新入职的员工以及那些从事不太热门领域投资的人，比如（非人工智能领域的）消费类投资或成长期投资项目。对人工智能关注度的增加也促使风投公司更加倚重那些具备相关技术知识的专业人士。</p>
  <p>因此，包括Conviction和Category在内的一些新兴基金在募资过程中没经历太多波折，也就不足为奇了。这些基金的重点很明确，就是要将深厚的技术知识应用于人工智能和科技初创企业。《福布斯》在去年12月报道了另一家这样的新兴管理机构Laude Ventures的成立，该基金专注于研究，规模为1.5亿美元。</p>
  <p>“从历史上看，大部分回报都被少数风投公司占据，但如果你此前没有机会接触到这些公司，现在想挤进去就很难，”&nbsp;基金中的基金（FoF）TrueBridge Capital Partners的联合创始人埃德温·波斯顿（Edwin Poston）说（TrueBridge是《福布斯》全球最佳创投人榜和美国未来独角兽公司榜单的数据合作伙伴）。“如果你有机会投资可能成为下一个Benchmark或Thrive的公司，那么可以想见，你可能会通过一只规模较小的早期基金收获非常可观的回报。”</p>
  <p>对于像Conviction这样的专业基金以及那些可能效仿它的基金来说，这是个好兆头。《福布斯》全球最佳创投人榜的资深上榜者、Index Ventures的退休合伙人迈克·沃尔皮（Mike Volpi）最近为一只新基金Hanabi Capital招募投资者，据说他个人以及一些朋友将为该基金提供资本支持。他表示，资金来源的增加和多元化应该会给新兴基金提供一个证明自己的机会。“我刚进入这个行业时，绝对想不到有人首次募资就能筹集到1亿或2亿美元，”&nbsp;沃尔皮说。“新一代的风投机构能否成功还需要时间来检验。不过，优秀的基金至少在募资方面很在行。”</p>
  <p>Conviction的郭睿表示，传统风投公司还在犹豫不决，不知在快速变化的人工智能领域采取何种投资策略之时，她的小公司可以抢占有潜力的投资机会。她希望今后能为Conviction招募更多合伙人，但她和弗纳尔并不着急。“我认为，要闯出一番名堂，并不需要人多势众。”&nbsp;她说。</p>
  <p>本文译自：</p>
  <p>https://www.forbes.com/sites/alexkonrad/2025/01/31/inside-venture-capital-great-reshuffling/</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzIwODU2NjQ5Mw==&amp;mid=2247616666&amp;idx=1&amp;sn=4fcd67616a6ea7daafb9799ac8e7790d&amp;chksm=9674b89872fb30032c4b18c7afe49279b08f72a5ebe829861425e783694dc3d8ab9ebcdafe9d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“福布斯”（ID：forbes_china）</a>，作者：Alex Konrad，翻译：Lemin，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156350110177792</id>
            <title>打造“机器人通用大脑”，40亿美元估值的Skild AI如何创造具身智能的“GPT-3”时刻</title>
            <link>https://www.36kr.com/p/3156350110177792</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156350110177792</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:03:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI基础模型, 具身智能, Skild AI, 机器人通用模型  
<br><br>  
总结: 在AI时代，Skild AI致力于打造具身智能的机器人通用基础模型，提升机器人的感知、决策和控制能力，以应对复杂任务。该公司获得了多轮融资，联合创始人Deepak Pathak和Abhinav Gupta在机器人领域有着深厚的背景和技术积累。Skild AI的目标是通过海量数据训练出具有泛化能力的机器人模型，解决劳动力短缺问题，并推动机器人在各个领域的应用。该模型的开发将使机器人能够在多种环境中执行任务，标志着机器人技术的重大进步。 </div>
                        <hr>
                    
                    <p>AI时代，AI基础模型的能力越强，AI应用就能解锁更多的功能，解决更复杂的问题。具身智能的出现，则解锁了机器人的通用智能，不仅提高机器人的感知能力，决策能力，控制能力，而且让机器人可以跨平台，跨环境完成各种不同的复杂任务。这种通用能力，由机器人通用基础模型提供。</p>
  <p>一家叫Skild AI的公司，致力于打造机器人通用基础模型，试图创造具身智能领域的“GPT-3”时刻。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b19077566ec946f8bf1a354d8ed6be1a@000000_oswg404525oswg1080oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Skild AI于2023年获得Lightspeed Venture Partners和Sequoia Capital投资的1450万美元种子轮融资，2024年7月获得Lightspeed Venture Partners、Coatue、软银和Bezos Expeditions领投的3亿美元A轮融资，最近，据彭博社和金融时报报道，软银正计划向Skild AI投资5亿美元，使它的估值从A轮的15亿美元提升到40亿美元。</p>
  <p>在Skild AI的投资人名单上，还有Felicis Ventures、Menlo Ventures、General Catalyst、CRV、SV Angel、卡内基梅隆大学等知名机构和大学。</p>
  <p>Skild AI联合创始人兼CEO Deepak Pathak表示：“我们正在构建的大规模机器人基础模型展现出跨机器人硬件和任务的泛化能力，为现实环境中的自动化应用开辟了巨大潜力。我们相信Skild AI标志着机器人规模化应用的技术跃迁，或将彻底改变实体经济的运行方式。”</p>
  <h2><strong>具身智能先锋，离开CMU投身“机器人基础模型”创业</strong></h2>
  <p>过去十年，机器人开始能够完成极限跑酷，用双手操控物体，以自然流畅的姿态移动。这些重大突破，多数与Skild AI的两位创始人Deepak Pathak（CEO）和Abhinav Gupta（总裁）有关，他们共同拥有超过90000次论文引用。</p>
  <p>Deepak Pathak在伯克利攻读AI博士期间加入FAIR，之后成为CMU机器人研究所助理教授（AP），他还是MIT科技评论的35 U 35科技创新者；Abhinav Gupta是CMU机器人研究所终身教授，FAIR Robotics创始成员与研究负责人。他们相识十年后，于2023年双双离开CMU，投身具身智能创业，并组建了由Meta、Tesla、NVIDIA、Amazon、Google以及CMU、斯坦福大学和加州大学伯克利分校等高校的机器人和人工智能专家组成的顶尖团队。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f3051273873843f1897c3508dbc6df67@000000_oswg936252oswg1080oswg557_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Deepak Pathak和Abhinav Gupta出身计算机视觉与深度学习领域，他们不拘泥于机器人的传统路径。当业界仍执着于采集特定数据来训练单一场景下的专用机器人时，他们已通过自适应架构与Transformer模型，利用海量数据构建机器人基础模型。这一开创性方法解锁了物理世界的具身智能，创造出通用性强、鲁棒性高且能自主进化的模型。</p>
  <p>在追求机器人通用智能的征途中，核心挑战始终是：如何在缺乏规模化数据的情况下构建训练模型，与大语言模型不同，机器人领域没有现成的“数据互联网”。为此，Deepak Pathak和Abhinav Gupta探索在线视频、远程操控、现实数据、模拟训练等多元路径。</p>
  <p>2015年，他们首次实现机器人数据规模千倍突破；随后，率先尝试人类远程操控与低成本机器人操作平台；2017年提出著名的“好奇心驱动”自主学习算法；2021至2022年，凭借大规模自适应SIM2REAL（虚拟到现实训练）技术再度突破，斩获机器人学习大会最佳系统奖。</p>
  <p>而这些技术基石，导向了Skild AI的技术愿景，打造可适应任意任务与环境的机器人通用基础模型。这些技术思想也在重塑人们对AGI的认知——仅靠数字知识无法构建真正的AGI，机器智能体通过“实践”学习：在新环境中尝试新任务，将即时反馈与既有知识融合，从而理解世界运行规律。</p>
  <p>“机器人领域的GPT-3时刻即将到来，这将引发一场巨大的转变，将我们在数字智能领域看到的进步带到物理世界。”红杉资本合伙人Stephanie Zhan表示。</p>
  <h3><strong>具有通用性和泛化能力的机器人基础模型</strong></h3>
  <p>当前美国劳动力市场缺口达170万（数据来源：美国商会），医疗、建筑、仓储与制造业尤为严峻——专家预测至2030年制造业岗位缺口将达210万（数据来源：全美制造商协会）。</p>
  <p>而根据《福布斯》预测，到2030年全球人才缺口可能达到8520万人，造成8.5万亿美元经济损失。</p>
  <p>Skild AI的技术可让机器人代替人类执行危险任务，或与人类协同应对新挑战。</p>
  <p>“通过打造能够安全执行任何自动化任务、在任何环境中运行并具有任何类型实体的通用机器人，我们既能扩展机器人能力边界，又能降低其成本门槛，缓解劳动力短缺危机。”Skild AI联合创始人Abhinav Gupta指出。</p>
  <p>与为特定应用设计或仅在孤立或受限环境中部署的传统垂类机器人不同，Skild AI打造的是机器人通用基础模型，相当于“机器人大脑”，将成为各种机器人形态、场景和任务的共享通用大脑，包括操作、运动和导航。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_cc0c4e229c204011a619cdeb4ee8e68c@000000_oswg796063oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这个模型通过接触海量真实世界的数据进行训练，训练数据点比竞争模型多至少1000倍，包括文本、图像和视频。Skild AI的“大脑”还接受了机器人控制任务的训练，其中包括人类远程操作员控制机器人完成简单任务的过程。这一过程教会了AI如何处理物理动作，同时还在随机任务中通过试错学习，进一步提升了其能力。</p>
  <p>这种对不同类型数据的综合处理使得Skild AI的模型展现出了“涌现行为”的迹象。这意味着它能够执行一些并未出现在其训练数据中的动作和技巧。这些行为非常微妙，例如接住滑落的物体，或将正在操作的物体旋转到正确的方向。</p>
  <p>尽管这些细微的“修正”几乎是人类下意识完成的动作，但正是这些能力让人类工人在通用型任务中表现得如此出色。一个能够整合这些更精细运动技能的机器人，将比传统汽车工厂中那些高速、高精度但依赖工具和对象精确位置的工业机器人更加灵活。</p>
  <p>在产品方面，Skild AI首先开发的是安防/巡检机器人平台，适用于工业场景的机器人，执行检测、监控与精细操作等任务。</p>
  <p>还有Skild AI移动操作平台，在机器人通用模型的支持下，这个移动操作平台让机器人开发变得像调用API一样简单。</p>
  <p>而且，Skild AI可以兼容市售机械组件，使其在工业领域获得显著竞争力，并为进军消费级市场奠定基础。从能够掌握恶劣物理条件的弹性四足机器人，到执行复杂家庭和工业任务中灵巧物体操作的人形机器人，Skild AI 的终极目标是让智能机器人像智能手机般普及。</p>
  <p>商业模式方面，目前Skild AI将效仿OpenAI，通过开放其机器人AI大脑接口供客户定制开发。</p>
  <h2><strong>解锁机器人的智能后，创业者要钻到场景中去</strong></h2>
  <p>最近一年，具身智能这个机器人和人工智能的交叉领域吸引了大量投资。</p>
  <p>去年11月，打造“机器人大脑”的Physical Intelligence获得了杰夫·贝索斯、Lux Capital和Thrive Capital领投的4亿美元融资，估值20亿美元；去年2月，Figure AI获得了微软、OpenAI创业基金、英伟达、亚马逊工业创新基金和杰夫·贝索斯投资的6.75亿美元融资，估值26亿美元。</p>
  <p>还有Sanctuary AI（人形机器人）、Robust AI（智能机器人系统）和 Brightpick AI（仓储机器人）等公司，也都获得了金额不小的融资。</p>
  <p>有趣的是，Figure AI原本使用的是OpenAI的定制模型来打造人形机器人，但是最近它宣布停用OpenAI模型，而自己打造端到端机器人AI模型，并将在近期公布其新模型，这表明具身智能的基础模型（机器人大脑）和大语言模型之间并不完全通用，其内在原因，是具身智能基础模型需要的训练数据与大语言模型有本质差异。</p>
  <p>对于中国的具身智能行业，机器人基础模型确实重要，目前也有一些创业公司在这个方向耕耘。但具身智能行业想要发展，其内在逻辑与AI行业类似，需要打造更聪明，更能解决具体场景中实际问题的垂类机器人。</p>
  <p>有了机器人基础模型，可以让机器人更聪明，做到很多之前无法做到的复杂动作，但是只有进入到垂类场景，机器人才能更好地落地和商业化，产生更多价值。</p>
  <p>对于具身智能创业，中国创业者具有独特优势，一方面，中国的机器人制造产业链更完整也更集中，另一方面，中国不仅拥有丰富的机器人使用场景，而且每一个使用场景都具有足够大的市场空间。作为天使投资机构，阿尔法公社希望发现具身智能领域的非凡创业者，希望帮助下一个世界级的机器人公司发展壮大。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA4NDE1MjQ3NQ==&amp;mid=2651857412&amp;idx=1&amp;sn=3fee9b292fbcfee3891fe49aae955c48&amp;chksm=85996bfb50c6e7adf4a0fddef608b340224ca68f7b6c7ce5d4fe5c4b3d007695131b266e1794&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“阿尔法公社”（ID：alphastartups）</a>，作者：发现非凡创业者的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>