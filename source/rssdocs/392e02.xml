<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2551940296808834</id>
            <title>大疆要做户外电源？请先回答这两个疑问</title>
            <link>https://www.36kr.com/p/2551940296808834</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551940296808834</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 02:00:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大疆, 户外电源, DJI Power 1000, DJI Power 500
<br>
<br>
总结: 大疆发布了两款全新领域的产品，DJI Power 1000和DJI Power 500，主要针对户外用电需求。大疆通过满足用户的户外用电需求，提高充电效率和用户体验，填补了户外工作生活基础设施的短板。此举也是大疆技术外溢的一部分，与其过去产品的发展和用户需求密切相关。 </div>
                        <hr>
                    
                    <p>大疆每次涉及新品类拓展的一举一动，似乎都会引起行业广泛热议。</p><p>12月8日，大疆正式宣布发布两款全新领域的产品——户外电源：DJI Power 1000和DJI Power 500。两款产品的主要差别在电池容量，1度电的DJI Power 1000，主打大容量应对多场景用电需求；0.5度电的DJI Power 500，则主打轻小便携。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_7fe9ca497e2f42218fa3ca0d6c48e45d@5390876_oswg1529393oswg3000oswg938_img_jpg?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">DJI Power 1000（左）和DJI Power 500（右）</p><p>大疆的此次“跨界”，乍看之下似乎有些出乎意料。行业对此，或许有两大疑问：</p><p>一方面是，户外电源在疫情时代下，每年曾以200%的复合增长率蒙眼狂奔，至如今，户外电源赛道似乎有慢慢退火之势，这从户外电源行业今年出货量增速略有下滑的势头也可窥见一二。</p><p>再加上，过去几年，国内深耕许久的玩家已经分掉了大部分户外电源行业的蛋糕，用户心智和品牌效应已建立。而剩下的市场，正被各种各样背景的新玩家虎视眈眈。当行业趋于内卷之时，大疆为何还要费心进入这一市场？</p><p>另一方面，户外电源领域与大疆此前所深耕的无人机、手持影像系统、农行业解决方案都相去甚远。大疆又是否有充足的基础，来驾驭这样一个如此新的品类？</p><p>但如果认真分析大疆这家公司一贯做事的逻辑，会发现上面两个疑问并不难回答。从用户需求出发，以技术产品和解决方案去解决痛点，不断完善用户体验——而DJI Power系列本质上正是这样需求与技术一拍即合的产物。</p><h2><strong>为什么大疆用户，需要一台户外电源？</strong></h2><p>提起无人机的用户，脑海中不难浮现这样的场景——好不容易等来假期， 约上三俩好友，带上无人机和各种装备，怀抱着期待的心情，驾车驶向更广阔的天地，大片即将诞生……</p><p>想象很美好，现实却有些烦恼：背包中各种电池、不同接口的数据线缠绕在一起。更要命的是，身处山林间，平日唾手可得的“电”不再随处可见。</p><p>再换一个场景：影视制作团队时常需要扛着各种设备远赴户外，到草原、山野、沙漠等等地拍摄是家常便饭。灯具、摄影机、滑轨等等，种种设备持续工作时所需的用电问题成了老大难。</p><p>而对大型剧组来说，即便有发电车，在一些狭小空间的拍摄场景时，车根本进不去，户外用电焦虑的难题依旧无法解决。</p><p>这两个大疆产品出现频率极高的场景中，一个共性的需求呼之欲出——户外用电。</p><p>如果说，这些发生在身边的To C的场景中，户外用电属于锦上添花，大疆的工程师们在实际调研时发现，看似应用场景截然不同的To B端用户，户外的用电则是刚需。</p><p>多名户外电力巡检的工作人员和大疆方面反馈，户外工作特点是需要横跨多地，而野外电缆设施周边的用电环境却较差。若要扛着巡检设备徒步数公里走到附近的村落，等待充电，极其不便。</p><p>方向已定，如何让用户的户外用电诉求得到满足，是接下来行业所面临的问题。在共性需求之上，大疆的工程师们进一步敏锐捕捉用户更深层的期待。</p><p>快速充电是这次DJI Power系列的主打卖点之一，其搭载的「SDC 超级快充」独家功能，将Mavic 3系列的一块电池电量从10%充至95% ，仅需32 分钟。</p><p>而若用市面上其他户外电源，同样的电量，即使搭配100W的充电头、再辅以「100W管家」，充电时间也要49分钟；若只用65W充电头、再搭配「65W管家」，充电时间则需64分钟。</p><p>只是简单提升充电效率还远远不够，大疆的工程师们还关注到了更细枝末节的用户诉求——比如电池的安全耐用、多元适配、超静音运行体验等等，从小处提升用户的综合使用体验。</p><p>曾有一位用户反馈，晚上在户外使用户外电源充电时，产品的噪音经常影响他们的休息，电源风扇声音带来一种不安全感，产生遐想。</p><p>大疆的工程师介绍，在用料上，DJI Power并不是简单把风扇固定在支架上，而是用了成本更高的一些减震材料。另外，温控风扇还搭配了智能算法精准控制转速，造就了低能耗的、安静、更好的电源散热效果。</p><p>这种类似的案例，在DJI Power上还有很多。</p><p>而跳出用户需求与产品本身，从商业的角度来看，大疆此次跨界进入户外电池领域，也是一项无可厚非的商业决策。</p><p>在过去，大疆不管是做消费级无人机、手持运动相机、Pro线影像产品、以及行业机型等等，都积累了大量的户外场景用户。大疆既然与大量户外人群距离更近，自然对这些人群的需求、特点更加心领神会。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5776ce19cc2b486d8048bd81a64d0c9c@5390876_oswg2224588oswg4776oswg2687_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1" /></p><p>更关键的是，大疆此次的DJI Power系列，其实填补上了原来户外工作生活时基础设施的这块短板。而这件事，大疆来做，或许更近水楼台——大疆掌握底层的硬件设备和数据，据于此能够完善自己的户外生态，满足用户的需求。</p><p>当然，大疆的DJI Power系列，不仅仅局限于大疆自己的硬件生态中使用，也是一款普适的产品。</p><p>尽管户外电源行业今年受到各方面影响增长有所下滑，但行业的另一个利好是，「户外电源」这类产品的全新的趋势是，在慢慢和「户外」这件事脱钩，有了更广阔的舞台。</p><p>比如，如今一些安全意识更强的家庭，也会为了预防家庭紧急停电，准备一块应急电源；在一些房车旅游的场景中，户外电源如今更已成为了供电必不可少的产品。国内的便携式储能的渗透率，相比于国外还有很大的提升空间。</p><p>如此看来，大疆此时布局，犹未晚矣，也能够找到合适的生态身位。</p><h2><strong>大疆电池，隐秘角落现身</strong></h2><p>实际上，DJI Power系列并非横空出世。大疆在电池领域的发展由来已久，此次从幕后走向台前，与其说是“跨界”，更为准确的理解是技术外溢。</p><p>“无论是消费级还是农行业产品的迭代与发展，电池技术的沉淀与进步是不可忽视的关键一环，产品的电池续航能力和充电效率，与用户体验息息相关”，大疆高级企业战略总监兼新闻发言人张晓楠，在DJI Power系列产品发布时表示。</p><p>用户在充分享受无人机流畅的体验时，或许很少会关注到，与体验息息相关的无人机电池，其实是一项相当复杂、艰难的技术领域——可以说，无人机对电池的要求，远远高于汽车。</p><p>一位行业人士表示，同样是1000瓦时的电池，无人机用的电池不仅比汽车贵1倍，对充放电速率、安全性的要求，也同样远远高于汽车。</p><p>况且，无人机电池眼前还摆着一座难以逾越的大山：重量掣肘。无人机仅半斤左右的重量里，每多塞一克电池的增重，会转化为成本，还会拉跨充电效率等等。</p><p>因此，无人机电池往往是一项，各项互斥参数完美协调的作品——充电要更快，又要够安全；电池密度要更大，还要保证循环次数更大，同时兼顾成本的可控。</p><p>而现状却是，尽管中国的电动汽车产业轰轰烈烈发展了几年，电池技术主要是因汽车而生，产业链上尚且鲜有专门针对无人机特点而开发的产品。因此，在过去，作为无人机领域绝对的领头羊，大疆一直在自研的电池技术上留心着墨。</p><p>大疆的电池迭代发展之路，是一段罕为人知的的故事。从大疆支撑起起来的那些消费者无比熟悉的产品迭代中，不难窥见这漫长故事中的主角如何成长蝶变。</p><p>从用户的角度，无人机中与电池相关最直观的感受就是续航时间。以消费级无人机为例，2013年「大疆精灵 Phantom 1」的续航时间大概是10-15分钟，如今DJI Mini 3已突破50分钟大关。这是十年的跨度里一项飞跃改变。</p><p>但如果把视线聚焦在更细小的精进和改变，后期大疆消费级无人机续航时间一路从34分钟、拉长到38分钟、40分钟、47分钟……</p><p>几分钟的精进能带来什么？</p><p>是可以延时拍到云卷云舒，是可以飞得再远一些看到山那头的景色，也是在返航时可以飞得更安心些。</p><p>续航时间的提升纵使不易，在紧凑的机身中去提升更是考验。</p><p>在电池领域，能量密度的提高也是衡量技术发展的指标。高能量密度电池可以提供更长的续航里程，但能量密度的提高往往伴随着安全性、价格、寿命、充电速度等等问题，需要多方权衡。</p><p>以大疆广为人知的Mini系列为例，轻巧机身像是一种“制约”，对各项技术提出了更高的要求。</p><p>2019年发布的「Mavic Mini」消费级无人机，一块2400毫安时的智能飞行电池，续航最大只有30分钟，重量是100g；短短四年的时间，2023年最新发布的「Mini4pro」，电池容量提升到了2590毫安时，重量却减少到了77.9g。</p><p>与此同时，大疆产品的电芯能量密度不断提升——在无人机这种快充快放的严苛工况下，已经能做到高于300Wh/kg的能量密度。相较之下，汽车的电芯密度一般是250wh/kg。</p><p>而跳出用户感受最直接的“用电”环节，在发电、储电、充电等几个关键环节，大疆也都有深耕：更高度的集成化、更精准的电量计算、更短的充电时间、不断提升的电池循环次数……</p><p>参数表的对比可能枯燥，用户实际综合使用体验的提升就是最好的佐证之一。在过去，大疆的电池能力，此前也经过了多番的市场验证。从消费级无人机的各大产品线、到一体化空中电影机「Inspire 3」、再到运载机DJI Flycart30，电池能力都是大疆产品的核心竞争力之一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_44d499c8fa644202867f43822ea6c4b7@5390876_oswg2481064oswg8667oswg6500_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1" /></p><h2><strong>写在最后</strong></h2><p>总体而言，大疆此次跨界进入户外电源新领域，是一项意料之内、情理之中的商业决策。</p><p>站在行业视角，赛道需要更多新的玩家、新的想法。据QYResearch调研团队最新报告“全球户外电源市场报告2023-2029”显示，预计2029年全球户外电源市场规模将达到81亿美元，未来几年复合增长率CAGR为21.1%。</p><p>将时间轴拉长，露营经济热度或许终会散去，在露营之外找到户外电源更加多元的使用场景，而不是靠着露营的热点做“大号充电宝”，这是户外电源获得消费者认可、行业打开未来增长空间的关键。</p><p>包括大疆在内，许多科技公司在持续发挥所长，为消费者提供更多可靠、易用、高价值的产品和解决方案，与用户一同探索户外生活。</p><p>而从大疆的角度，这次的“跨界”，也符合大疆一贯做事的逻辑，从用户需求出发，以技术产品和解决方案去解决痛点，不断完善用户体验。</p><p>此次推出全新的电池产品，大疆手里的牌是，品牌认知度、户外工作生活的用户圈层、掌握上层的硬件、和底层电池能力。但大疆最后能否打好这副牌，还得交给市场和时间来回答。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2552131633486214</id>
            <title>再反转，谷歌Gemini又曝猛料，逐帧分析揭开复仇GPT-4的底牌</title>
            <link>https://www.36kr.com/p/2552131633486214</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2552131633486214</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 01:39:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌Gemini, 演示视频, 多模态模型, 视觉/视频理解能力
<br>
<br>
总结: 谷歌Gemini是一个原生的多模态大模型，通过演示视频展示了其强大的视觉/视频理解能力。视频中的用户提示和输出都是真实的，Gemini能够根据提示词准确理解用户意图，并给出正确的答案。Gemini的多模态模型将文本、代码、图片、视频、语音合在一起训练，实现了更均衡的多模态输出和任意模型切换。谷歌Gemini在多模态及视觉能力上展现出了强大的实力，成为谷歌挑战GPT-4的最强点。 </div>
                        <hr>
                    
                    <p>在刚刚过去的24小时里，谷歌Gemini的一段演示视频爆火全球。&nbsp;</p><p>像机器人贾维斯一样，谷歌Gemini一边看着用户绘画、变魔术、放视频，一边实时对画面进行分析，并主动和用户对话交谈，让人大呼“《钢铁侠》的AI助手指日可待”。&nbsp;</p><p><strong>然而，质疑声也随之而来。</strong>产业大佬如Hugging Face技术主管菲利普•施密德（Philipp Schmid）称谷歌夸大了测评成绩；爆火的谷歌Gemini宣传视频也被曝不是实时演示录制，而是精心挑选和剪辑的营销内容，不太可信。&nbsp;</p><p>对此，谷歌立刻甩出了Gemini演示视频的制作记录文章，大方承认视频经过了后期处理，并秀出在视觉谜题、多模态对话、逻辑与空间推理、翻译视觉效果等方面的交互过程图文解析。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_0aafe79cf5b0425ba9b574a31c7301d1@000000_oswg82275oswg1080oswg415_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲谷歌发布了题为《如何制作：通过多模态提示与Gemini互动》的文章</p><p>今日，谷歌DeepMind研究与深度学习主管奥里奥·维尼亚尔斯（Oriol Vinyals）再度自证，在X平台上发文称：“视频中的所有用户提示和输出都是真实的，简洁起见做了缩减”，并发布了一段Gemini Pro的对应演示视频。&nbsp;</p><p>但原宣传视频是用Gemini Ultra演示的，因此这也招来网友质疑：“为什么不敢放出原视频？”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ea5c7bf9895c4167acd4544140c8f1aa@000000_oswg414551oswg1064oswg1240_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>关于谷歌Gemini演示视频真伪的争论暂时没有定论，但Gemini的原生多模态模型的招牌已经打出，向GPT-4发起了奇袭。&nbsp;</p><p><strong>一位来自谷歌DeepMind的研究人员告诉智东西，Gemini的视觉/视频理解能力，是谷歌挑战GPT-4（GPT-4V）的最强点。</strong></p><p>不同于市面上的图文拼接的多模态模型，Gemini是一个原生的多模态大模型，是将文本、代码、图片、视频、语音合在一起放进模型里训练而来的，因此能实现更均衡的多模态输出及任意模型切换。据称，谷歌原生多模态的视觉/视频部分，与包括GPT-4在内的大模型形成了代际差。&nbsp;</p><p>Gemini演示视频被看作谷歌“复仇”OpenAI的力证。据谷歌称，Gemini首次在MMLU（大规模多任务语言理解）测评上超过人类专家，在32个多模态基准中取得30个SOTA（当前最优效果），全方位赶超GPT-4。《突发！谷歌深夜掀桌子，发最强大模型Gemini，跑分碾压GPT-4【附60页技术报告】》&nbsp;</p><p><strong>那么谷歌Gemini到底有多牛？其在多模态及视觉能力上真实表现如何？</strong>通过逐帧解析谷歌Gemini演示视频背后的形成过程和技术原理，本文对此进行了深入探讨。&nbsp;</p><h2>01. 懂读心术、贯通文理，</h2><h2>Gemini“暴走”竟靠提示词？</h2><p>看着十分抽象的简笔画、几秒闪过的短视频，接收语焉不详的问题，Gemini却能立马明白用户的意图，给出正确的答案，并不动声色的展现出自己文理兼修的实力。&nbsp;</p><p><strong>这是如何实现的？背后离不开提示词的强大“助攻”。</strong></p><h3>1、空间逻辑力了得，一眼看出天文知识Bug</h3><p>“这样排序正确吗？”&nbsp;</p><p>“不，正确的顺序是太阳、地球、土星。”&nbsp;</p><p>几张简笔画，一个抽象的问题，Gemini不仅识别出了图中所画的对象是什么，还准确根据自己的天体物理知识，推断出顺序摆放不对。这让人们不得不感叹AI“成精”了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_82cb4642b89a4ecfa5ab58b2f58018e2@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>题都没说清楚，Gemini为什么能这么对答如流？&nbsp;</p><p><strong>根据谷歌昨天第一次发布的解析文件，工作人员真实输入的提示词可能不是视频中所示，而是一系列非常照顾Gemini理解的句子。</strong></p><p>根据谷歌发布的文章，其工作人员首先给Gemini看三张按顺序摆放的天体图片时，他输入的内容是：“这是正确的顺序吗？<strong>考虑与太阳的距离</strong>并<strong>解释</strong>你的推理。”&nbsp;</p><p>可见图片<strong>对象、知识点</strong>和<strong>回答要求</strong>都被谷歌工作人员一一Cue到了，<strong>这就好像给考生的考题做了批注提醒。</strong></p><p>Gemini是在理解其中含义的基础上作答的：“不，正确的顺序是太阳、地球、土星。太阳距离太阳系中心最近，其次是地球，然后是土星。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_196cf36f3ea648899e487278ae152502@000000_oswg44171oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲谷歌DeepMind研究与深度学习主管发出Gemini Pro演示视频</p><p>而根据谷歌方今天发出的第二次解读，用户首先需要输入一段关于模拟专家身份的说明，然后上传图片并输入视频中简短的提示词“这是正确的顺序吗？”，Gemini就会给出正确的答案。这一提示词前置的方法本质与上述做法类似。&nbsp;</p><p>谷歌本次宣布了Gemini三个版本：适用于高度复杂任务的Gemini Ultra、适用于各种任务的最佳模型Gemini Pro以及适用于端侧设备的Gemini Nano。目前，接入Bard的为Gemini Pro，与GPT-3.5是一个能力层级。&nbsp;</p><p>智东西测评发现，Bard对上文提到的两种提示词方式都会给出同一正确答案。&nbsp;</p><h3>2、联想空气动力学知识，一秒选出更快的赛车设计</h3><p>在第二道题中，谷歌员工给到两张小车的图片让Gemini做松木赛车挑战，<strong>其实也是给了比较详细的提示词。</strong></p><p>在演示视频中，Gemini只是被问了“从设计上看，哪个车会跑得更快”。&nbsp;</p><p>Gemini立刻回复：“右边的车更快，它更符合空气动力学。”&nbsp;</p><p>既要识别左右两辆车，又得自己联系空气动力学知识点，Gemini看起来确实有点神。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_9ffb9c93fe934f32a53af314d30321f6@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>但实际上，这也似乎不是仅靠原有提示词触发的效果。</strong></p><p>按照谷歌发布文章的解读，谷歌工作人员输入的内容是：“这些汽车中哪一辆更具<strong>空气动力学性能</strong>？<strong>左边那个还是右边</strong>那个？使用<strong>具体的视觉细节</strong>解释原因。”&nbsp;</p><p>Gemini答：“右边的车更符合空气动力学。它具有更低的轮廓和更流线型的形状。左边的汽车轮廓更高，形状更四四方方，这使得它的空气动力学性能较差。”&nbsp;</p><p><strong>可见，问题限的比较死，因此Gemini的回应也比较严丝合缝。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_8f12dd51af964f0e9639d899a30f768c@000000_oswg29728oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>也就是说，Gemini是具备空间推理和专业知识能力的，但这离不开提示词的帮助。</strong></p><p><strong>通过提供图片空间信息和背后知识点线索，提示词工程师和Gemini一起完成了挑战。</strong></p><h3>3、兼具文化素养，轻松识别模仿的电影桥段</h3><p>“他们在演什么电影？”&nbsp;</p><p>“我想他们是在表演《黑客帝国》中，著名的“子弹时间镜头。”&nbsp;</p><p>通过一段几秒钟的视频，Geminij就推断出了这出自哪一部电影，并且还给出了具体涉及的剧情桥段。这可能是很多人都做不到的事。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_620c9fdc3e5843b284cf4c7d628f15d2@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>但按照谷歌的解析文件，这个例子背后制作过程却不是视频呈现的那么简单，而是更详细的提示词做支持。</strong></p><p>当谷歌工作人员向Gemini展示视频的几帧静止画面，让它猜电影：“猜猜我在演什么电影。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_d6a43517230c4ad1be2f54fcc3c58ff3@000000_oswg312130oswg1080oswg147_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Gemini回答：“黑客帝国。”&nbsp;</p><p>工作人员进一步说：“好了！但具体是哪一部分呢？看我的身体动作。”&nbsp;</p><p>Gemini回答：“尼奥躲避子弹的部分。”&nbsp;</p><p><strong>可以看到，谷歌解析文件里介绍的Gemini并不是视频里呈现的“贾维斯”，或许更像一个需要老师循循善诱的“小朋友”。</strong></p><h2>02. 一眼看穿经典魔术，Gemini强在“时间线推理能力”</h2><p><strong>Gemini的酷炫演示效果离不开提示词的助攻，但不能抹去核心逻辑推理能力的功劳。</strong></p><p><strong>比如Gemini拆解经典魔术的功力也让很多人惊掉下巴，大呼“魔术师要失业了”，这绝不仅仅是靠输入策略实现的。</strong></p><p>在这个例子的演示中，谷歌工作人员先展示了握在右手心里的硬币，然后双手翻转，手心向下。&nbsp;</p><p>还没等工作人员发话，Gemini就迫不及待地说：“硬币应该在右手下面。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_bea01d2694a6486d96b7c466ed0609f5@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然后工作人员并没有说话，而是拿起右手，只见右手下根本没有硬币。&nbsp;</p><p>Gemini对此连忙回应：“嗯……我不知道……硬币在左手下面。你运用了一些手法，使硬币看起来好像消失了。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_0e93204c309849f0b88252f4d631a24a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>工作人员啥也没说，Gemini就像一个人似的知道这是在变魔术，并根据手势变化给出了一波猜测，这实在让人匪夷所思。&nbsp;</p><p><strong>Gemini为什么能不被“唤醒”就明白了工作人员想问什么？又为什么能看穿这个魔术？</strong></p><p><strong>前者很可能是一个剪辑后的效果，幕后演示应该是先有提示词。同时，Gemini对这一魔术的破解，也是在工作人员一步步的提示推动下完成的。</strong></p><p>按照谷歌公开的制作过程，谷歌工作人员先输入一张照片说：“解释一下我在做什么。”&nbsp;</p><p>Gemini回答：“你右手拿着一枚硬币。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_4e391d4b5a794dfeb1d0974aeac80464@000000_oswg46335oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>紧接着，工作人员紧接着按下硬币，问：“你认为硬币在哪里？”&nbsp;</p><p>Gemini回答：“硬币在你的右手。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_40b5cd2994464647913abdc8ca78bf74@000000_oswg36589oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_cec2a270ba1b40faa018abce70f5c16b@000000_oswg46478oswg990oswg750_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这是一个合乎逻辑的答案，但工作人员向Gemini展示下一张图片时玩了点花招：他打开右手，并没看到硬币。&nbsp;</p><p>并说：“看看这里，发生了什么？”&nbsp;</p><p>Gemini回答：“硬币不见了。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_bd213db2241148a88664775f4e6533e6@000000_oswg42522oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Gemini注意到硬币不见了，但它能概括出刚刚发生了什么事吗？</strong></p><p>于是工作人员说：“从第一张图片开始，逐步总结可能发生的情况。”&nbsp;</p><p><strong>这一步十分关键，</strong>Gemini回答：“1. 一开始，你右手拿着一枚硬币。2. 然后你用手做了一个动作，硬币就消失了。3. 然后你表明硬币不见了。”&nbsp;</p><p><strong>可见，Gemini正在利用这次对话的整个背景，包括文本和图像，来总结它的答案。</strong></p><p>最后工作人员再问道：“你能解释一下它是如何消失的吗？”&nbsp;</p><p>Gemini回答：“硬币被捧在手里。”&nbsp;</p><p><strong>所以说，Gemini是在工作人员一步步的引导下，完成了时间线的推理，从而看透了这个“魔术”。</strong></p><p><strong>而这种时间线推理能力，意味着对事情的先后有明确的判断，懂得事情发生的因果（而不仅是规律），这是Gemini令人赞叹的地方。</strong></p><p>当然，也有博主将Gemini的这一能力与GPT-4对比，发现后者也能完成一些类似任务，比如猜出东西在三只杯子的哪一个里面。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b2d9cd5e204f45288095c448384e5322@000000_oswg633974oswg1080oswg1097_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲开发者彼得罗·斯基拉诺（Pietro Schirano）称用GPT-4复现了“三个杯子”案例</p><h2>03. 自创游戏师出有门，Gemini强在视觉理解能力</h2><p><strong>很多人对Gemini创作的“你指我猜”游戏印象深刻。但Gemini并不是天生游戏高手，而是先经过了求师学艺。</strong></p><p>这是怎么回事？先来回顾下Gemini的神操作。&nbsp;</p><p>谷歌工作人员给到Gemini一张海洋地图称：“根据你所看到的，想一条游戏创意，并加入表情符号。”&nbsp;</p><p>Gemini立马回复<strong>：“</strong>这样如何？我们来玩‘猜国家’游戏。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_2892ea486cb041f8af0fbafd68c7007a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>工作人员说：“可以，我们开始吧。”&nbsp;</p><p>于是Gemini就给出了一个提示：“这个国家是袋鼠、考拉和大堡礁的故乡”&nbsp;</p><p>工作人员说：“哦，这太简单了！”随即，他指出了地图上澳大利亚的位置。&nbsp;</p><p>Gemini回复：“正确。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_6d92a23db8534c5bb3575437537138b0@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>这种几秒中之内想出一个复杂交互的游戏，令很多人赞叹。这是因为，Gemini在之前得到了特别的“紧急训练”：</strong></p><p>首先，工作人员向Gemini提示这个游戏的核心思想：&nbsp;</p><p>说明：我们来玩一个游戏。想想一个国家并给我一个线索。线索必须足够具体，只有一个正确的国家/地区。我会尝试在地图上指出该国家/地区。&nbsp;</p><p>接下来，工作人员为Gemini提供了一个游戏玩法示例，以此展示它被期待如何处理错误和正确答案：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ba9c38cc4b894ebbbf950b1da216c44e@000000_oswg603245oswg984oswg1138_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>接下来，工作人员对Gemini的学习情况进行测试：&nbsp;</p><p>他先试了一道题：这个国家以其独特的野生动物而闻名，包括袋鼠和考拉。（答案：澳大利亚）&nbsp;</p><p>工作人员首先尝试指向错误的地方：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_c6c50f01b107455194d1a8e2aee2099f@000000_oswg100117oswg1000oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Gemini猜测：一个人用右手食指指着世界地图上的巴西，因为该地图包括蓝色的海洋和没有国家边界的绿色大陆。因此不正确。&nbsp;</p><p>Gemini的推断是正确的，接下来工作人员指向地图上的正确位置澳大利亚：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_7408a280010a4cde894b7a00e7bdcff4@000000_oswg100729oswg1000oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Gemini给出判定：正确。&nbsp;</p><p><strong>可以看到，Gemini之所以能够创作游戏，是工作人员提前告诉了它存在这样一个游戏，相当于一个更复杂的提示文段。</strong></p><p><strong>虽然Gemini并不是天生能设计出这个游戏，但却展现出了极强的图文多模态理解能力。仅仅通过举例，具体说是通过例子里的插图，Gemini就学会了一个复杂游戏逻辑，这可能就比很多人要强。</strong></p><p>不同于市面同行将视觉和文本模型拼接的做法，Gemini是业内少有的从头开始构建的多模态大模型，它可以同时识别和理解文本、图像、音频、视频和代码五种信息。这意味着用户可以自然地交错输入：说几句话，添加图像、文本，或是短视频。同样，模型也会自然地交错文本和图像作为输出。&nbsp;</p><h2>04. 看毛线团给创作建议，“交错图文生成”能力或成杀手锏</h2><p><strong>Gemini还可以用图文结合的方式回应用户需求，具备“交错文本和图像生成”能力，这或许也是它的一个“杀手锏”。</strong></p><p>在演示视频中，当谷歌工作人员让Gemini帮他想想这些材料可以做什么时，Gemini随即给出了“编织的火龙果和生日蛋糕”的建议。&nbsp;</p><p>如下图所示，Gemini给的答案不仅有文字建议，还有对应的图片示意。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5f8f2687feaf42a3a94ec027af6d963b@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当工作人员将绿色的毛线换了一团蓝色的，并要求Gemini帮他想一些动物造型之后，Gemini立马给出了编织的小猪、章鱼和兔子三个建议，并给出了如下所示的示意图。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_c651fbdea871436eb471be2638507516@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>这是如何实现的？谷歌的图文交错生成模式在业内还比较少有，当然也离不开提示词的配合。</strong></p><p>首先，谷歌工作人员给Gemini提供了一个交互示例：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_9cccaa7e80c74f44863775e576f2d868@000000_oswg395484oswg1034oswg828_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_72a5135634834221aa5efa732ebf2dee@000000_oswg706834oswg818oswg1160_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_8052894d98f645ba84d34a65053e2ac5@000000_oswg343542oswg732oswg634_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然后谷歌人员告诉Gemini的核心互动规则：&nbsp;</p><p>“我会给两个毛线球拍一张照片，我希望你（Gemini）都能想出一个我可以制作的东西的想法，并生成它的图像。”&nbsp;</p><p>紧接着，谷歌人员向Gemini展示了一对它尚未见过的新纱线颜色，看看它是否可以概括：&nbsp;</p><p>“给我三个关于我可以用这两种颜色制作的钩针作品的想法。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_c7791e2a4c5944fb91d3b6a2043b2f76@000000_oswg1053747oswg1012oswg1074_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随后，Gemini立马给出了三个建议：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e707d20061b94eb88b70e7ce8f978192@000000_oswg401499oswg896oswg870_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_7d8fee48bc9a45619c1be708555fc75f@000000_oswg710952oswg894oswg1168_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，Gemini正确地识别了新颜色，并给出了比较合适的建议。&nbsp;</p><p><strong>虽然提示词功劳不小，但这个应用还是牛在背后的“交错文本和图像生成”能力。</strong></p><p>谷歌创意总监亚历山大·陈（Alexander Chen）称，Gemini的图文输出从根本上有别于今天市面上的文生图模型。因为，它不仅是将指令传递给单独的文生图模型，还能看到木桌上的实际图像，真正对文本和图像进行多模态推理。&nbsp;</p><p>不过，陈也坦言这个功能在Gemini初版本中还没开放，只是放出来给大家看一眼。&nbsp;</p><h2>05. 图音画无缝翻译，Gemini秀出应用联动能力</h2><p><strong>“画图触发BGM（背景音乐）”是谷歌Gemini本次演示的另一神来之笔，展现出其插件扩展方面的野心。</strong></p><p>当谷歌员工画出一把吉他的简笔画，Gemini立马说“我看到你正在画吉他”，并随即播放了一首吉他相关的曲子。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_757107155b9e4a7a9348873a5fd0a945@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当画面上多了一个类似音箱的图像，Gemini称“你给吉他加了一个扬声器……我们现在可以放点更响亮的音乐了。”于是，音乐立马被切换成一首更响亮的交响曲。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_75a7cf2741404dab9af548939ee4ed2d@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随着画布上增加了“鼓”，Gemini主动将音乐切换成了带鼓点的音乐。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_37856b336bdd457f87560bc48b464a19@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当画布上增加的“椰树”，Gemini则主动切换了一首更加惬意的音乐。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b0889d1c6d714431b1597f0223a25752@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由前面的解析可知，要实现这些效果，Gemini大概率也是需要谷歌员工先发出提示词触发的。&nbsp;</p><p>根据陈的解读，当谷歌工作人员输入以下图片及文字，Gemini就能“看图搜索音乐”。&nbsp;</p><p>“步骤1.观察这幅图画，描述其中的所有内容，并针对良好的音乐配乐流派、情绪或配乐提出有趣且具体的想法。&nbsp;</p><p>步骤2.通过以下形式提供搜索查询：‘搜索[插入查询]’”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_2229bd1601054f50b129d206e216ba00@000000_oswg52753oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Gemini对此回应：&nbsp;</p><p>“该图画的是吉他、鼓和扩音器。还有一棵棕榈树。气氛有趣、乐观、充满热带风情。流派是雷鬼音乐。该配乐可用于以热带地区为背景的电影或电视节目。&nbsp;</p><p>搜索‘热带度假的雷鬼音乐’”&nbsp;</p><p>可见，图片理解和插件操作一气呵成。&nbsp;</p><p>Gemini通过“画图搜索音乐”的应用，实际上是为了展现其图像理解与应用插件结合的能力，那就是：Gemini会对其所看到的内容进行推理，然后生成一个搜索查询，进而搜索到所需的配套应用插件。&nbsp;</p><p><strong>从这一过程来看，Gemini强调的是一种多模态“翻译”能力。</strong></p><p>这不是语言的翻译，而是从绘画、音乐到思维、插件应用的多种模态翻译。通过多模态提示，用户可以使用Gemini在不同输入和输出之间，发明自己的全新“翻译”特效。&nbsp;</p><h2>06. 结语：谷歌与OpenAI竞赛打响</h2><p>通过深扒谷歌Gemini的演示过程，我们发现，谷歌Gemini确实没有宣传视频里看起来厉害，但其在多模态对话、多模态生成、逻辑与空间推理、翻译视觉效果、文化理解等方面确实拿出了实力，向OpenAI发起了强力挑战。落地情况如何，还要等Gemini Ultra发布之后看真实效果。&nbsp;</p><p>可以预测，谷歌Gemini与OpenAI GPT两大阵营竞赛即将打响，将在模型能力、应用家族及生态方面展开更深入比拼，而开源大模型与头部玩家的差距或许会变大，行业的头部效应将更加明显。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652765727&amp;idx=1&amp;sn=460b7b5290013f421c5f81988431a0b3&amp;chksm=847d6911b30ae0079fba232ff7b4517c2abe51117a658b1c5b59ef14a4dd6f22de5ff64d8ae2&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：李水青，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2552013421158274</id>
            <title>仰望AI星空的度小满，该如何走好脚下的路？</title>
            <link>https://www.36kr.com/p/2552013421158274</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2552013421158274</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 01:13:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 估值, 互联网金融企业, 度小满金融, 蚂蚁集团
<br>
<br>
总结: 虽然度小满金融是一家互联网金融企业，但其估值相对较低，仅为105亿元，远远低于蚂蚁集团等竞争对手。尽管度小满金融与百度合作，契合了人工智能的概念，但仍未获得资本的青睐。这可能是因为度小满金融在六大业务领域中没有占据龙头地位，与竞争对手的差距较大。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_92cce0e339494c8a98fe0697e2e39733@2001086927_oswg1463583oswg1049oswg695_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然“出身名门”，但度小满的估值却有些“失意”。</p><p>2023年《胡润全球独角兽榜》的数据显示，同为互联网金融企业，蚂蚁集团估值8300亿元、腾讯领衔投资的微众银行估值2300亿元，而脱胎自百度的度小满金融，估值还不及上述二者的零头，只有105亿元。就连360数科（现更名“奇富科技”，03660.HK）的市值也已达到200亿元，依然能压度小满一头。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_02c5cdf45b394657a55b8c07170e3007@2001086927_oswg12039oswg789oswg505_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一个不佳的兆头还在于，度小满的估值正在下滑。胡润榜单显示，和2022年相比，在蚂蚁、微众等金融科技同业2023年估值均小幅攀升的背景下，度小满105亿元的估值和2022年的200亿元下滑颇多。</p><p>展望前路，度小满并不是没有“好故事”可讲，眼前甚至充满星光——在人工智能席卷各行各业，成为2023年投资市场最炙手可热的概念之际，度小满成为百度“文心一言”首批生态合作伙伴，完美契合了“AI+”的概念。</p><p>但为何度小满仍没有获得资本的青睐？</p><h2><strong>1、六大业务无一占鳌头</strong></h2><p>度小满脱胎自百度金融，2018年后独立运营。因为尚未上市，所以市场还无法看到它的详尽经营信息。</p><p>度小满的业务体量有多大？2023年5月，《山东商报》社“速豹财经”曾经援引第三方平台“企业预警通”数据显示，2022年度小满营收近29亿元、净利润超7亿元、当年年末资产总额近240亿元，营收较上次披露财务数据的2019年翻番。这一体量和蚂蚁2022年1795.67亿元的营收差距甚多。</p><p>但「界面新闻·子弹财经」综合多方资料发现，上述数据可能无法完整体现度小满的经营情况。</p><p>天眼查数据显示，度小满金融经营实体之一、名为“重庆度小满小额贷款有限公司”的企业，2019年营收14.35亿元。显然，这个小贷经营公司的单一业绩，并不能反映度小满金融的整体情况。</p><p>经过5年独立发展，度小满金融的业务板块有6项，分别是：信贷、财富管理、支付、保险、个人金融科技、供应链金融科技。</p><p>例如，同为度小满金融旗下企业、经营非银行支付业务的实体“北京度小满支付科技有限公司”，股权关系与上述披露营收利润的度小满小贷公司并无直接关联关系。</p><p>那有没有方式，可以更具体地观测到度小满的经营情况？或许通过业务的横向比较，是当下更适合市场进行观测的方式。</p><p>上述信贷、财富管理、支付等6大业务，也是当前互联网金融行业落地的6个典型方向。因为赛道上已然有蚂蚁、微众银行、京东数科等巨头雄踞，度小满在上述每一个细分方向，目前都没有做到龙头的位置。</p><p>逐一分析拆解，可以看到度小满在各个细分赛道上，与龙头的差距——</p><p>首先看互联网信贷方面。依托线上消费的支付场景，蚂蚁集团旗下花呗、借呗两款产品，以及京东旗下白条、金条两款产品，牢固坚守大量市场份额。目前尚无清晰、统一的口径可以观测到各个公司的放贷余额或市场份额，但依然能从两条路径看到度小满与行业龙头的差距。</p><p><strong>第一种方式是从信贷业务放款额来看，2022年的度小满体量和2018年的蚂蚁相当。</strong>度小满官网显示，2022年公司信贷业务放款额破2万亿元大关，这一水平和2017年蚂蚁集团（时称“蚂蚁金服”）透露的累计放贷额1.7万亿元相近。</p><p><strong>第二种方式是从注册资本来看。近年来互联网平台小贷整改后，杠杆率要求趋严，头部平台频繁增资，因此注册资本可以映射出各家业务的体量。</strong>截至2023年12月初，蚂蚁消金已获批增资至230亿元、重庆京东盛际小额贷款有限公司增资至80亿元。度小满小贷公司的注册资本为74亿元，略低于美团、略高于携程旗下的小贷公司注册资本，位列第二梯队。</p><p>其次看理财代销方面。以基金代销为例，目前蚂蚁、天天基金领衔的“第三方基金代销机构”和招商银行领衔的“银行系基金代销机构”，正面临中信证券领衔的“券商系基金代销机构”的强劲挑战，三大阵营争夺市场份额的竞争已经区域白热化。度小满在其中处于什么位置？这里有具体的排名可以参考。</p><p>中基协发布的2023年第三季度基金代销百强榜单，显示出极强的马太效应，行业龙头鲸吞大规模的市场份额。其中北京度小满基金销售有限公司排名第76，“股票+混合公募基金保有规模”和“非货币市场公募基金保有规模”分别为54亿元和111亿元，与蚂蚁的5069亿元和12541亿元相差悬殊。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b7696ac7000141659bf96c3a9d22e4c7@2001086927_oswg15603oswg883oswg520_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第三看支付方面。因为拥有网上购物和社交属性两大天然壁垒极高的场景，市场普遍认为以场景侧来统计，支付宝和微信支付在该领域合并占据九成以上的市场份额。尚普咨询数据显示，截至2022年末，支付宝和微信支付分别占据了第三方支付市场份额的54.5%和38.8%。就算度小满将剩下的份额全部占据，其份额也不足10%。</p><p>第四看保险中介业务。可以简单理解为“在互联网平台上买卖保险”的保险中介业务，也是各大平台均有布局的领域。胡润研究院曾发布《2020中国互联网保险中介服务平台Top10》，度小满排名第十，落后于腾讯、蚂蚁、京东、苏宁和携程等巨头平台以及轻松保、水滴筹等新型平台。</p><p>最后，将个人金融科技、供应链金融科技合并来看，毕马威和H2 Ventures联合发布的《2023年金融科技100强名单》上，度小满位列蚂蚁金服、京东数科之后。</p><p>聚焦到“供应链金融科技”这类细分赛道上，灼识咨询《2022中国供应链金融科技行业蓝皮书》曾提及中国供应链金融科技解决方案提供商的市场占有率排名，其中腾讯作为早期股东投资的“联易融”、蚂蚁和京东数科排名靠前，该份排名和报告中未见度小满身影。</p><p>为什么度小满陷入了“六大业务无一占鳌头”的境地？上文反复提及的“场景”可能是关键所在。</p><p>比如蚂蚁、京东依托电商，微信依托社交，滴滴、携程等互联网平台发展金融业务也都有场景支撑。</p><p>度小满曾经利用搜索流量，在教育贷等细分方向做出亮点，但这条路也在“越走越窄”。2022年2月，“镭射财经”透露2021年末起度小满两大“王牌产品”教育贷、医美贷的经营模式由直营转为代理。</p><p>此前的2021年8月，中新经纬等媒体报道了度小满教育贷陷入争议。彼时知名英语培训机构“华尔街英语”出现大面积停课，面对人去楼空的教室，曾经用教育贷支付学费的学员却必须持续偿还贷款，否则将会影响征信记录。度小满对此回应称钱款已经全额打给教育机构，如果要退贷需要联系机构。事态陷入死结也引发业内热议，这种将资金直接打给平台的深度场景下，金融机构和放贷平台应当承担一定的风险防控义务。</p><h2><strong>2、被传IPO背后屡屡被罚</strong></h2><p>2023年初，度小满曾被传“最快将于2023年上半年正式向港交所递交招股书”，拟主板挂牌上市。这个率先从百度AI生态战略下独立的公司终于要上岸了吗？当时这一消息引发了市场关注。</p><p>不过发酵几日后，中新经纬等媒体援引度小满内部人士回应称，上述赴港上市为不实消息，目前没有明确的上市计划。</p><p>早在2021年，度小满就也曾经被传上市，但公司亦否认。《北京商报》等媒体的历史报道显示，当年9月13日，度小满发布《关于自媒体发布不实消息的说明》称，“近日有媒体报道我公司拟启动上市计划，此消息不实。目前公司没有上市计划。”</p><p>不过频频被传IPO身后，暗藏公司屡屡被罚的风险。</p><p>比如互联网保险业务方面。2022年10月，度小满保险经纪有限公司被曝因违反《保险法》，而被黑龙江银保监局作出行政处罚。处罚事由透为该公司“欺骗投保人，未按照规定使用经备案的保险条款”，公司合计被罚56万，亦有公司高管被警告或罚款。</p><p>在2020年蚂蚁集团、京东科技（时名“京东数科”）IPO搁浅后，监管对金融科技监管的覆盖面和强度均提升，将合作模式、利率空间、风控管理、贷后催收、公司治理等多个环节纳入监管框架。当时，蚂蚁和度小满在内的13家平台企业先后被多个金融管理部门联合约谈。</p><p>这些金融企业在资本市场行动的“破冰”是2022年11月末，360数科在港交所挂牌完成二次上市。2023年1月，时任中国人民银行党委书记郭树清透露，“14家平台企业金融业务专项整改已经基本完成”。</p><p>行业整改收尾后，度小满前路如何走下去，市场尚未见到清晰的信号。</p><p>除了这些行业性的问题，度小满自身也面临难解的负面舆情。比如2022年，它曾经被卷入河南村镇银行“取款难”事件，一些储户向界面新闻反映，原本在度小满上存入的“存款”项目竟然改变显示为“理财产品”。当时度小满对媒体回应称没有对相关产品页面进行过任何修改。</p><p><strong>可以确定的是，无论度小满是否冲击IPO，合规发展将会是它需要追逐的永恒目标。</strong></p><h2><strong>3、“AI+”能打开想象空间吗</strong></h2><p>虽然目前脚下的路不好走，但度小满抬头仰望前路“眼里有光”。这个光就是2023年最灸手可热的概念：人工智能。</p><p>百度全力押注AI后，脱胎自百度的度小满也把自己的AI成色“拉满”。2023年2月，百度宣布大语言模型“文心一言”即将问世。同月，度小满就火速宣布成为文心一言的首批生态合作伙伴。</p><p>当时度小满积极展望道：将基于自身金融场景积累的海量对话及解决方案数据，融合“文心一言”的全面能力，打造全新的智能客服、智能营销、智能风控服务。这一合作也是对话式语言模型在国内金融场景的首次落地应用。</p><p>在“AI+万物”的背景下，2023年，度小满高管也在多个公开场合发声畅想AI在金融领域的落地。</p><p>如在岁末举行的“百度世界·度小满金融大模型分论坛”上，度小满CEO朱光展望，在AI技术底座落地后，应用落地的“第二幕”正徐徐拉开，“以大模型技术为代表的人工智能2.0，它的通用智能与金融行业数据和真实的业务场景融合，让金融科技进入全新的发展阶段。”</p><p>此前《新华财经》等媒体的文章也透露了度小满“AI+”落地的具体场景。例如延承百度人工智能技术，度小满将大型语言模型LLM应用于海量行为数据、征信报告的解读，这能够将小微企业主的信贷风险降低20%。</p><p>公司CTO许冬亮亦曾展望，大模型将变革在线对话交互的服务模式，在提升营销效率方向将有所助益。</p><p>不过度小满眼前的“一片星光”里，也潜伏风险。</p><p>首先，度小满仍缺乏让市场看得见、摸得着的具体落地场景；其次，数据管理趋严是全世界监管紧盯的焦点，用大数据和AI融入金融业的合规性，是市场关注和热议的话题，其中的要求势必越来越高；第三，除了百度以外，阿里、蚂蚁、腾讯等巨头也都在参与大模型的竞逐，“AI+”将会是一条竞争越来越激烈的赛道。</p><p>比如度小满的同业“大哥”蚂蚁集团在2023外滩大会上正式发布金融大模型，针对金融产业定制，且已找到场景落地，在蚂蚁集团的财富、保险平台上全面内测。在具体的应用上，蚂蚁金融大模型可提供理财选品、产品评测、行情解读等6大理财类服务，以及保险产品解读、智能理赔等10多个保险类服务。更“像人”的是，8月底蚂蚁金融大模型通过了证券、保险等专业从业试题测试。</p><p><strong>在金融这个容错率极低、越来越“卷”的赛道上，押注“AI+”也已经不是新鲜事，度小满面临的是极具挑战性的竞争环境。</strong></p><h2><strong>4、巨头放慢跑，度小满吃饱？</strong></h2><p>一丝曙光是，在监管趋严的背景下，互联网金融的一些市场份额有望流入度小满。</p><p>兴业证券在一份研报分析行业竞争形势时曾指出，在互联网金融平台整改之前，超头部平台的贷款余额市场份额超过50%，反垄断会使得这些超头部平台释放出更多的市场增量。与此同时，尾部的平台也在掉队，很多弱资质的小型互联网贷款公司将会加速彻底退出竞争。</p><p>“掐头去尾”的格局变化中，中部平台有望获取更多客户和市场份额。这份报告的分析对象虽然是360数科，但也同样适用于同为行业腰部的度小满。</p><p>但显然，对于追逐者而言，寄望于跑在前面的人跌倒，绝对算不上积极的策略。想要提升成绩，仍需要提高自己的速度。</p><p>目前度小满展现在市场面前的形象，是抬头仰望星空、眼里充满“AI”希望，但与此同时脚下的路也并不好走。</p><p>头顶的天、脚下的路，哪个更重要？</p><p>度小满用“AI+”打开了发展的想象空间，但也要低头脚踏实地拿出来实打实的业绩，哪怕只是在某个细分领域有所突破、跻身头部，以此来赢取市场的认可。</p><p>&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/4Fs70BbQbEGhf1AKG5FFbw" rel="noopener noreferrer nofollow" target="_blank">“子弹财经”（ID:zidancaijing）</a>，作者：尉捍，编辑：闪电，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2552034515165319</id>
            <title>72岁港科大教授，带出一个IPO军团</title>
            <link>https://www.36kr.com/p/2552034515165319</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2552034515165319</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 00:53:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 学院派的投资人, 辉芒微电子, 高秉强, IPO
<br>
<br>
总结: 辉芒微电子是一家半导体设计企业，其IPO吸引了学院派的投资人高秉强的关注。高秉强作为辉芒微的投资人已经支持了18年，他还投资了其他多家企业，并形成了一个IPO军团。辉芒微的IPO增加了一些急迫性，因为突击入股的投资人要求顺利上市作为交换。辉芒微的股权结构中，高秉强及其妻子持有第二大股份。辉芒微的主营业务收入主要来自MCU、EEPROM和PMIC三大产品线的销售。辉芒微的研发投入相对较低，但公司解释称这是因为过去对新品研发的投入已经释放了产能和销量。 </div>
                        <hr>
                    
                    <p>学院派的投资人总能吸引诸多关注，一家半导体设计企业的IPO让一位72岁的教授站在了聚光灯下。</p><p>近日，辉芒微电子（深圳）股份有限公司（以下简称“辉芒微”）完成创业板发审委第二轮问询。在辉芒微的股权结构中，已经从香港科技大学荣休近二十年的高秉强及其妻子，合计持股达到19.52%的股份，仅次于创始人许如柏。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_647dd0ea1c2c46b492c52e73a1072637@1629410002_oswg136771oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：深交所官网截图</p><p>此次IPO前，辉芒微遭多家投资机构突击入股，辉芒微估值抬升至30亿元，但双方的对赌协议也让辉芒微此次的IPO增添了些急迫性。与突击入股的股东形成鲜明对比的是，高秉强在辉芒微背后，已经支持了18年。</p><p>辉芒微这18年的创业历程，已经不只是一位香港创业者回归内地拼搏的故事。作为与李泽湘齐名的投资人，高秉强更低调，但经过二十余年的资本扩张，高秉强已经拥有一张自己的投资版图。</p><p>值得注意的是，2023年8月，高秉强与李泽湘、吴宏共同创办的固高科技成功登陆创业板。辉芒微若顺利上市，高秉强投资版图将再收获一个IPO。</p><h2>陪跑18年，是辉芒微最坚定的投资人</h2><p>高秉强出生于1951年的香港，曾任前加州大学伯克利分校电子计算机系副主任、前香港科技大学工学院院长。许如柏也是香港籍，在香港大学获学士学位，之后在加州大学伯克利分校获得博士学位。</p><p>2004年，许如柏和邓锦辉二人在硅谷共同成立FMD BVI（辉芒微前身）。次年，留美十余年的许如柏和邓锦辉自海外归来。而此时的高秉强已经是已经是业界有名的半导体领域投资人。</p><p>2005年，许如柏和邓锦辉来到深圳，FMD BVI也随即获得了高秉强等天使投资人的关注。</p><p>据悉，2005年，FMD BVI进行A轮融资，高秉强率先注资，其在FMD BVI的直接持股比例达到33.66%。在2020年决定IPO时，FMD BVI全部股份转为普通股，高秉强的直接持股比例为34.6737%，略低于创始人许如柏的36.7498%。</p><p>经过后来的公司重组和一系列的股权转让，截至IPO前，高秉强和妻子高梁于文通过旗下投资机构，共持有辉芒微电子19.52%的股份，是第二大股东。</p><p>自2005年算起，高秉强作为辉芒微的首批投资人，已经陪跑了18年。</p><p>这18年间，辉芒微也进行了多轮融资。2022年9月，华胥基金、越秀金蝉、鸿富星河、越秀智创、红土星河、深创投、远见新欣等7家投资机构以3亿元的代价增资入股辉芒微，增资价格为45元/股。按照此轮增资价格，辉芒微估值抬升至30亿元。</p><p>不过，上述突击入股的投资人的到来，也伴随着一份对赌协议，许如柏需要以辉芒微的顺利IPO作为交换。</p><p>其实，辉芒微已经是第二次冲刺IPO了，早在2021年12月，辉芒微科创板IPO获受理。但不到1个月的时间，辉芒微便申请撤回了申报材料。辉芒微二次冲击上市，并没有继续冲刺科创板，而是选择创业板。难道是科创属性不足吗？</p><p>招股书显示，辉芒微主营业务收入主要来源于MCU、EEPROM和PMIC三大产品线的销售。2020年、2021年、2022年及2023年上半年，辉芒微营收分别为3.08亿元、5.4亿元、4.76亿元和2.55亿元；净利润分别为5173.89万元、1.66亿元、1.12亿元和5215.82亿元。</p><p>在研发投入方面，2020年、2021年、2022年及2023年上半年，辉芒微研发投入分别为3538.06万元、5618.21万元、6753.54万元和3586.88万元，分别占当期营业收入比例的 11.47%、10.40%、14.19%和 14.04%。但相较于兆易创新、中颖电子、复旦微电、中微半导等可比公司的平均值，辉芒微的研发投入占比却有些偏低。</p><p>辉芒微对此的解释是，公司成立时间已经很久了，在过去对新品研发的投入在该阶段释放产能及销量。</p><p>据悉，辉芒微还曾出售了一条产品线，并且成全了另一家拟上市公司。据了解，辉芒微在2013年量产了NOR Flash产品，2017年将该产品线以4000万元和对方部分股权的代价出售给代码型闪存芯片研发商芯天下，后来，该股权被辉芒微转让并获得9000万元的资金。</p><p>值得注意的是，辉芒微为科创板IPO专门聘请的财务总监彭娟，在公司主动撤回科创板IPO申请后，于2022年2月离职。</p><p>此外，在如今的辉芒微中，许如柏还在坚持，而最初的合伙人邓锦辉已经不参与公司管理了。辉芒微再次进入IPO征程，高秉强这笔坚持了18年的投资，也到了即将收获的时刻。不过，在高秉强的投资版图中，并非只有辉芒微。</p><h2>高秉强的IPO军团</h2><p>如今，高秉强投资的企业中，已经有了一个IPO军团。</p><p>高秉强今年72岁，1993年7月至2005年8月，担任中国香港科技大学工学院院长，2005年退休后开始专注投资领域，如今被人叫做创业导师。在粤港澳大湾区，他与李泽湘教授、甘洁教授组成了一个“黄金铁三角”，孵化并投资一众知名独角兽。天眼查数据显示，截至当前，高秉强在48家企业中担任高管，有37家还在运营。</p><p>高秉强在做投资之前，自己也是创业者。1999年，高秉强与李泽湘、吴宏三位教授联手创办了专注运动控制技术的企业固高科技。今年8月，固高科技登陆创业板，截至今天（12月8日），公司市值超150亿元。</p><p>正式进入投资领域是在2000年，高秉强与联想集团创办人之一吕谭平，成立翱科创投，专注投资在硅谷和中国的信息科技、软件、互联网、电子商务、无线和移动增值服务、芯片设计等初创公司。据公开信息，翱科创投在2006年参与了易车网的两轮投资。</p><p>在离开香港科技大学校园后，高秉强在2005 年，联合十几位海归，发起成立芯片设计公司芯联集成电路（上海）有限公司。</p><p>2014年，高秉强又与李泽湘及甘洁一起，创办XBOT PARK基金(原香港清水湾创业基金)，针对机器人及智能硬件相关领域投资，不再局限于半导体领域。</p><p>天眼查信息显示，XBOT PARK基金如今出手18次，绝大多数集中在天使轮、种子轮和A轮等早期阶段的公司。投资案例包括不停科技、EcoFlow正浩、睿魔智能、松灵机器人等。</p><p>而在2018年，高秉强联合创办了一支Brizan Ventures风险投资基金，专注于投资全球芯片领域、人工智能以及智能消费电子等行业。天眼查显示，自该基金创立至今出手12次，投资了酷芯微电子、进迭时空等芯片企业。</p><p>如今，高秉强的资本版图中已经出现一批进击资本市场的企业。除固高科技外，还有安防 CIS 龙头思特威，有着“EDA第一股”之称的概伦电子、无线通讯射频芯片公司博通集成，还有曾登陆纽交所的易车等。</p><p>对于这些创业公司，高秉强“创业导师”的身份，让他不仅仅是投资人。思特威创始人徐辰曾说，高秉强教授是思特威的贵人。不仅提供资金支撑，还为其牵线搭桥，介绍台积电代工。</p><p>在高秉强推动下，也加速了一些人的创业进程。据悉，博通集成创始人就是在高秉强的支持下决定回国创业。</p><p>辉芒微，也是在一开始获得了高秉强的支持，如今也进入了IPO的冲刺阶段。高秉强的IPO军团实力再次壮大。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/MIHYinHqqK8aHdM6nxii5A" rel="noopener noreferrer nofollow" target="_blank">“猎云精选”（ID:lieyunjingxuan）</a>，作者：邵延港，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2552045321689225</id>
            <title>腾讯游戏的持久战役</title>
            <link>https://www.36kr.com/p/2552045321689225</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2552045321689225</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:57:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: TGA颁奖典礼, 腾讯, 《博德之门 3》, 《心灵杀手2》
<br>
<br>
总结: 今年TGA颁奖典礼上，《博德之门 3》和《心灵杀手2》获得多个奖项，背后都有腾讯的身影。腾讯在全球游戏市场的投资和布局取得了成功，中国游戏厂商正在全面拥抱全球化。 </div>
                        <hr>
                    
                    <blockquote><p>今年TGA颁奖典礼上，《博德之门 3》实至名归拿下了年度游戏，以及最佳表演、最佳社区支持、最佳角色扮演游戏、最佳多人游戏、玩家之声等多个奖项，成为最大赢家。《心灵杀手2》则获得了最佳游戏指导、最佳叙事、最佳艺术指导等奖项。这二者背后都有腾讯的身影。</p></blockquote><p>腾讯游戏在全球市场的持久战役，正在迎来一波不易让人察觉的丰收。</p><p>11月14日，有“游戏界奥斯卡”之称的The Game Awards（TGA）放出31个奖项的提名名单，其中最受关注的奖项是“年度游戏大奖（Game of the Year）”，《博德之门3》与《心灵杀手2》分别获得包含年度游戏大奖在内的八项提名，并列成为TGA提名最多的游戏。</p><p>当天，有游戏媒体报道，这二者背后都有腾讯的身影。海外媒体彭博社也在TGA提名公布后做了跟进报道，如是评价腾讯在游戏板块的投资：“腾讯证明了自己有足够的耐心来通过其投资，并且足够审慎地在幕后发挥作用，在这个著名的多变业务中进行长期布局。”</p><p>在12月8日上午的颁奖典礼上。作为夺冠热门，《博德之门 3》实至名归拿下了TGA 年度最佳游戏，以及最佳表演、最佳社区支持、最佳角色扮演游戏、最佳多人游戏、玩家选择等5个奖项，成为最大赢家。同样表现不俗的《心灵杀手2》则获得了最佳游戏指导、最佳叙事、最佳艺术指导等奖项。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_3ebaf987c90a49c6b24da34342a67dd9@1743780481_oswg794857oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>《博德之门3》由欧洲最大的游戏工作室之一的拉瑞安工作室（Larian Studios）开发。「市界」了解到，据一份来自拉瑞安工作室2019年的财务文件显示，腾讯旗下公司腾讯云欧洲持有其30%的股份。有媒体分析，腾讯应该是在2018年9月左右入股拉瑞安工作室，当时正逢拉瑞安工作室重组，在爱尔兰成立了控股公司。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_1111ec840b3946fd84974acde414cb52@1743780481_oswg676303oswg1080oswg622_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>《心灵杀手2》的开发商为芬兰游戏公司绿美迪娱乐（Remedy Entertainment），腾讯于2021年首次投资该工作室，并于2022年增持。</p><p>除以上两款领跑游戏外，腾讯和拳头的《英雄联盟》和《无畏契约》还包揽了电竞相关赛事的所有奖项。同样是中国厂商的米哈游凭借《崩坏：星穹铁道》获得了最佳移动游戏奖项。</p><p>中国游戏厂商正在以各自的、多样的方式全面拥抱全球化。</p><h2><strong>大航海时代走入下半程</strong></h2><p>“放到七八年前，我都不敢想，中国游戏会有这么一天。”在2023年全球最大的游戏展德国科隆游戏展（gamescom）上，一位全程观看了开幕视频的观众如此评论道。</p><p>在由游戏科学开发的国产3A大作《黑神话：悟空》的展台前，挤满了等待试玩的人群。“起码要排两小时以上！”有人在队伍中向后来者高喊。</p><p>在对面的展台，米哈游请来了Starry Sky乐队来COS游戏角色，演奏《原神》原创歌曲开场，把展会变成了一个热闹的音乐节蹦迪现场。</p><p>腾讯旗下国际游戏业务品牌Level Infinite带着15款产品亮相，涵盖多个品类，及主机、PC、移动三大终端。</p><p>这次科隆游戏展，被媒体称为是“中国企业的首次大规模独立参展”。从集体亮相科隆到获TGA多个奖项，中国游戏厂商如今的成绩起源于“不出海，就出局”的共识。</p><p>Sensor Tower的最新数据显示，在中国以外地区收入最高的前100款手机游戏中，近三分之一都是由中国公司开发。</p><p>与此同时，全球游戏行业也正面临更大的挑战。据Newzoo数据预测，2022年全球游戏市场收入达到1844亿美元，年同比下降约4.3%。但其中2022年手游市场的收入下滑要更加明显，达到922亿美元，年同比下滑6.4%。</p><p>全球游戏人口红利逐渐消失。在全球疫情带来的短暂手游人口增长现象过去后，全球游戏人口增速已经落至3-4%，相较于疫情前增速接近腰斩。</p><p>面对全球市场变化及压力，出海成为中国游戏厂商必须要主动思考，并精细化布局的一件事。</p><p>作为中国头部游戏厂商，腾讯游戏的全球化布局可以说已经有超过15年的历程。早在2008年，腾讯就投资了美国拳头游戏。据游戏媒体报道，腾讯高级副总裁马晓轶这几年在海外花费的时间大比例上升。“以前，我只花了大约20%的时间在海外，大部分时间都在中国度过。现在，我将60%的时间都花在了全球市场上。”</p><p>在马晓轶看来，“中国的市场处在从高速增长到成熟市场的转变期，大家对产品品质的要求越来越高，每一个品类上基本都有头部的公司在，但整个游戏行业，新玩法的出现并不多见。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_d155b780ab4b49c3b3f3bebecec9025d@1743780481_oswg135485oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现今，从中国市场出发，腾讯将越来越多的产品定位于全球化，“内部的产品一上来就要瞄准全球市场，我们不会做单一市场的产品，产品是中国IP，我们也希望在美术风格、玩法上，更能够适应全世界的玩家。”</p><p>并不只是腾讯，各大厂商的全球化步伐均在加快。网易自2019年起着手在海外挖人建厂，这一行为在2022年前后到达巅峰。</p><p>2021年，米哈游同样加快了全球化的步伐——今年上线的《崩坏：星穹铁道》移动版和PC版已经实现了全球150余个国家和地区同步发售。</p><p>此外，米哈游还在美国、加拿大和新加坡等多个游戏产业发达的国家设立研发中心和办事处。今年9月，蔡浩宇正式辞任米哈游董事长，其未来的重点工作内容之一就是“串联国内与海外研发资源”。</p><p>中国厂商势头的凶猛外移，也将海外市场的竞争拉到了新的高度。</p><p>“卷，太卷了。”一位从事海外发行工作的从业者这样向「市界」感慨，“现在想去海外市场，不带几千万投放预算是做不了的，即便是最便宜的东南亚市场，也得几百万起步。”</p><h2><strong>一场持久战役</strong></h2><p>过去几年间，从资本、产品，到人才、技术乃至整个团队班底出海，国内游戏厂商都按下了加速键。而基于自身的基因和所长，大家的出海路径亦各不相同。</p><p>例如，网易出海之路就一直颇为侧重发行。在日本市场，网易凭借《荒野行动》名声大噪，此后又依靠《明日之后》《第五人格》站稳了脚步，日本成为了网易游戏的福地，至少在2021年之前，网易游戏在日本一直是Top级别的存在。</p><p>近年来，网易还专注于招揽日厂主机游戏研发人才，先后成立了樱花和名越工作室，剑指3A级游戏。在游戏立项上，网易也更倾向于中重度游戏。</p><p>米哈游的出海则更多是围绕着自身产品，做海外发行、本土化的布局。通过在海外组建以市场、商务、本地化研发为主的团队，米哈游更侧重于海外推广。随着国际化战略的推进，米哈游目前的游戏已经能够适用“全球团队开发”的模式。</p><p>三七互娱、莉莉丝、趣加等“二线梯队”的出海策略，则更多是选择其擅长的游戏赛道，如从卡牌、SLG（策略游戏）等题材入手，通过反复修改、优化前期的成功产品，做海外的融合创新。</p><p>相比较之下，腾讯的出海策略要复杂的多，它更加贴近于产业化、体系化打法。</p><p>2008年腾讯投资美国游戏公司拳头Riot Games是一个标志性的事件，其甚至可以说是腾讯在游戏赛道内的最重要一笔投资。</p><p>尽管今天的《英雄联盟》已畅享全球，但在2008年，这可以说是一次冒险的行为。仅仅是因为看中了MOBA类赛道，以及拳头公司在当时计划施行的免费模式，腾讯就在当年度掏出了800万美元给尚无代表作的拳头公司。</p><p>2009年又大胆出手，收购了拳头游戏公司的大部分股份，同时承诺允许拳头游戏保持独立运营。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_988369c16253420187aafa2bfc88e79e@1743780481_oswg125860oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>后来，腾讯也投资了Epic Games，及收购了芬兰手机游戏开发商Supercell，在游戏圈引起轰动。据披露的信息，腾讯收购Supercell的金额高达86亿美金，在微软收购动视暴雪之前，这是游戏行业最大的一笔收购。</p><p>事实上，以投资广泛接触、连接全球范围内的优质游戏同行一直是腾讯游戏的重要业务策略之一。马晓轶曾在一次演讲中分享过腾讯做游戏的策略：在故事IP、玩法和技术这三大游戏行业核心推动力中，玩法，是重要切入点。每隔2-3年，市场上就会出现一种全新的玩法，因此，基于玩法扩充赛道，才能做大行业蛋糕。</p><p>所以，腾讯一直非常积极地在全球范围内扫描新玩法，推进品类开拓创新。比如2013年在ArmA引擎上体验了《DayZ》，并投资了其开发者后，又与《H1Z1》等多款战术射击游戏团队合作，最终与韩国Krafton公司合作，研发了火爆全球的《PUBG MOBILE》。</p><p>事实上，2018年以来，腾讯游戏对海外公司投资出手更加频繁：法国育碧、加拿大的Digital Extremes，英国的Sumo Leamington，瑞典的Fatshark，加拿大的Inflexion 等在不同品类中各有所长的全球工作室尽先后接受了腾讯的投资。</p><p>同时，腾讯也早已开始着手构建自己的全球内容自研与全球发行能力，并与合作伙伴建立更深的合作。</p><p>这次TGA上，除了投资工作室的作品获奖，腾讯也首爆了3款新品。包括光子工作室群旗下专注开放世界3A游戏的工作室Lightspeed LA曝光首款游戏《Last Sentinel》，由曾制作《GTA5》、《荒野大镖客1和2》的知名制作人 Steve C. Martin 领衔，具有非常独特的场景、剧情及玩法体验；腾讯国际游戏业务品牌Level Infinite携手Sharkmob工作室及10 Chambers工作室分别揭晓新作《Exoborne》和《Den of Wolves》，前者以开放世界战术撤离射击为核心玩法，后者为科幻题材多人合作第一人称射击游戏。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_a7e8490b05784c5da0ca63a363e872f3@1743780481_oswg110016oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>毫无疑问，TGA侧面反映出腾讯的这场持久战役已经有了新一轮的成果。</p><p>如果说出海是一场游戏，那么显然游戏的“困难模式”早已经开启。如马化腾曾在一场演讲中说到：“拿到所谓的船票、门票，也不一定能走到终点。”而各路玩家，为了打赢这场战役都在招兵买马。今年10月，微软正式宣布，在获得英国反垄断监管机构“竞争与市场管理局”（CMA）的批准之后，现已完成687亿美元收购动视暴雪交易。</p><p>巨头们继续建立城墙。据报道，腾讯高层在内部会议中认为，过去腾讯在海外的动作，还只是“一场热身”而已。有理由相信以腾讯、米哈游、网易等为代表的中国游戏厂商也显然已经成为全球游戏市场上不容忽视的一股力量。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/lgC9VgMlt2Sr-53Nit0nJg" rel="noopener noreferrer nofollow" target="_blank">“市界”（ID:ishijie2018）</a>，作者：赵子坤，编辑：李原，运营：刘珊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2552013130995846</id>
            <title>智能手机开卷护眼功能，目的是为了产品差异化</title>
            <link>https://www.36kr.com/p/2552013130995846</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2552013130995846</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:57:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 高频PWM调光屏幕, 护眼功能, OLED屏, 2K中国屏
<br>
<br>
总结: 近年来，手机厂商在竞争激烈的市场中，将护眼功能作为差异化的卖点，普遍采用高频PWM调光屏幕和OLED屏技术。这些屏幕通过亮暗交替的方式来控制屏幕亮度，以降低频闪对用户眼睛的损伤。同时，一些厂商还推出了支持3840Hz超高频护眼调光的2K中国屏。然而，高频PWM调光并非唯一的解决方案，类DC调光也备受关注。尽管高频PWM调光在提升亮度方面效果显著，但也存在一些局限性。此外，手机屏幕与照明设备在使用场景上存在本质差异，因此将照明设备的认证标准类推到手机屏幕上并不完全适用。尽管如此，高频PWM调光仍然能够改善用户的视觉体验，成为中高端机型的重要卖点。 </div>
                        <hr>
                    
                    <p>继此前荣耀方面在荣耀90系列上首发“零风险”3840Hz高频PWM调光屏幕，将智能手机的屏幕护眼功能作为重要卖点向用户进行推广后，如今已成为中高端机型标配的OLED屏也进入了高频PWM调光阶段。就在不久前发布的Redmi K70 Pro上，同样也配备了支持3840Hz超高频护眼调光的“第二代高端2K中国屏”。而在刚刚亮相的一加12上，所采用的“2K东方屏”带来的明眸护眼，更是宣称通过6大护眼技术方案，实现了手机屏幕上开创性的护眼能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_482d734afbff4a759ebf4b7ffcf90433@000000_oswg31709oswg550oswg378_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事实上，无论是对于任何一款屏幕来说，只要是长时间观看都不避免对人眼造成一定得损伤，因此对于护眼这件事来说，不看屏幕可能才是最假方案。但随着如今智能手机市场竞争的白热化，由于大多数元器件都来自于供应链的少数厂商，因此各大手机品牌为了避免陷入到同质化的无效竞争中，在细分功能上为用户提供差异化体验，也就成了最具可行性的方案。毫无疑问，护眼如今就成为了手机厂商比拼的一个方向。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_fd998cd2664b4ff295526e60e99c0b5f@000000_oswg36427oswg550oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由于目前中高端机型所普遍采用的OLED屏幕原理，已经与传统的LCD屏完全不同，因此在低亮环境下为了确保显示效果、降低频闪对于用户体验的影响，高频PWM调光也逐步成为了手机厂商的共同选择。所谓PWM，是指脉冲宽度调制(Pulse Width Modulation)，OLED屏的PWM调光实际上就是通过亮暗交替的方式来控制屏幕亮度，通常其频率高于1250Hz时，就可以被称为低风险，而达到3125Hz则就被认为是无健康风险。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_eec12be1044f44e3a3ccdfe8783d21ae@000000_oswg14719oswg550oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而强调智能手机的眼功能，实际上是体现产品差异化的重要方式之一。毕竟对于大多数用户而言，硬件配置、影像表现多少显得有些“高深”，因此在用户本就有护眼需求、同时又不太可能降低手机使用时间的情况下，护眼这个功能点也就有了充足的宣发价值。但需要注意的是，并非所有用户对于高频PWM调光的改善都能敏锐察觉到，部分用户甚至可能还有反作用。</p><p>其实在解决OLED屏频闪问题方面，高频PWM调光并非惟一的方案，类DC调光同样也是在此前受到了许多厂商的青睐，其效果甚至可能更为出色。当前，这也需要厂商在调校、优化方面投入更多精力和资源。</p><p>不过相比高频PWM调光，类DC调光还是存在一些局限性，例如其无法解决低亮环境下可能出现的偏色及灰阶显示问题。同时相较高频PWM调光，类DC调光不仅需要投入人力对屏幕进行调校，还要对应用和使用环境进行针对性的适配，成本相对更加高昂。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_0a9fdd5a709b4ba4998f0c28d0357bf9@000000_oswg18274oswg550oswg320_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但目前在抑制OLED屏幕闪烁、提升亮度方面，有一个相当“诡异”的部分，那就是现阶段被手机厂商广泛接受的高频PWM调光频率这个概念，其实是以照明设备的认证标准来类推的结果。例如IEEE 1789-2015标准，其实就是“高亮度LED”的标准，而GB/T 9473-2017标准则是“读写性能台灯”的标准。但在业界统一的标准出台前，这种类推的方式也实属无奈。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_d74347e8718d47fda1323f2ebe47476d@000000_oswg15907oswg550oswg354_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>需要注意的是，手机屏幕与照明设备虽然在原理上有着一定的相通之处，例如亮度、闪烁等方面，但是这里却有一个致命的问题，那就是手机屏幕与照明设备在使用场景上有着本质的差异。例如在使用手机时，用户会在大多数时间里直视屏幕（实质上就是光源）。而当使用照明设备时，却并不需要直视光源，只用借助反射、折射的光线进行照明即可。</p><p>两者虽然也有相同之处、但差异显然更大。然而即便如今各大手机厂商强调的高频PWM调光或许对用户的帮助没有想象中那么大，但对于用户而言，至少还是获得了视觉体验上的改善。</p><p>值得一提的是，如今开“卷”护眼功能的产品，通常会以安卓阵营的中高端机型为主，甚至目前已经达到了3840Hz的地步。但在各厂商的高端产品序列，也就是顶级旗舰机型，却鲜少将这些来作为推广阶段的重点。</p><p>比如，时至今日iPhone的屏幕还停留在480Hz这一标准上，而三星外销的屏幕几乎都可以轻松支持1440Hz或上以频率的高频PWM调光，即便是自用的M系列屏幕也能支持1920Hz高频PWM调光，但其一直以来的重点都是色彩、刷新率，以及省电节能等方面。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e81432f3782040edb26781418c5602b6@000000_oswg23322oswg550oswg319_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，苹果与三星这样选择的原因也有很多，其中比较直接的方面，就是为了平衡成本及用户需求。再加上高频PWM调光并不那么依赖硬件，在低亮度下也不会有色偏，甚至不需要手机厂商进行针对性的调校，这就使得其具备了大规模普及的能力和潜力。</p><p>除了调光方面之外，如今手机厂商还在继续深挖屏幕护眼方面的潜力，例如已被反复提及的硬件级低蓝光技术、TÜV莱茵低蓝光认证等。但需要注意的是，无论是什么护眼技术，实质上都只是降低健康风险，并不能使用户获得健康风险的“豁免”。</p><p>即使是支持当前最先进护眼技术的的手机屏幕，长时间观看仍会导致眼部肌肉紧张，在暗光环境下长时间使用还有可能加深近视、诱发青光眼等疾病，甚至可能会导致失明。因此对用户而言，更重要的是要有健康使用手机的意识。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_7f91f21ee05e44158688d47b5aedebaa@000000_oswg20354oswg550oswg384_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如今各家发力屏幕护眼功能背后，其实是手机厂商为了避免陷入产品同质化，主动向差异化设计和体验方面的转向。但对用户来说，手机厂商此举势必会带来更为多样化的选择，显然是百利而无一害的事情。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649853945&amp;idx=4&amp;sn=0b73c0d788c16143f678a4e92d992b95&amp;chksm=8789c93bb0fe402d7420b4c07da21c779e9a5a99d6392bafb0741cc9199f98813995a8d86617&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2552042449918087</id>
            <title>这家“伪创投”，董事长被判无期</title>
            <link>https://www.36kr.com/p/2552042449918087</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2552042449918087</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:56:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 红岭创投, 创投行业, P2P, 监管合规
<br>
<br>
总结: 红岭创投作为一家以创投为名却行P2P之实的机构，非法吸储超过千亿，给创投行业带来了负面影响。P2P和创投是两种不同的商业模式，但P2P行业的乱象丛生导致创投行业受到严格监管。监管部门加强监管合规，对创投行业提出更高要求，以重建行业形象。 </div>
                        <hr>
                    
                    <p>12月7日，“红岭创投”周世平等人非法集资案一审公开宣判。被告人周世平犯集资诈骗罪、非法吸收公众存款罪，被判处无期徒刑，剥夺政治权利终身，并处没收个人全部财产。新闻一出，创投圈哗然。这一家起着“创投”名字的P2P机构，非法吸储超过千亿，波及投资者48万。</p><p>红岭创投借着创投的名义，不仅极大的损害了创投行业的社会形象，使得大量个人合格投资人对“创投”谈虎色变，也使得监管对创投行业进一步加强监管，<strong>合法的创投机构在合规路上，变得战战兢兢</strong>。</p><h2><strong>P2P却起了个创投名</strong></h2><p>红岭创投现存的官网首页，已经被深圳市福田公安分局的案情通报所占满，公告栏也几乎全是转载的相关执法机构公告。</p><p>红岭创投的logo和其logo中的英文名称“Hongling Capital”显得尤为扎眼。对于初步了解创投的普通投资者来说“创投”、“Capital”的字样，很容易产生这是一家VC机构的误导，如果不加以仔细甄别，再加上销售人员和介绍材料当中的语焉不详的介绍，便会以为这是一家创投机构。</p><p>实际上，创投和P2P是两种不同的商业模式。创投是一种投资模式，它主要是通过投资股权方式来获得资本回报。</p><p>一般来说，专业的风险投资人都具备一定的职业操守和监管意识。尽管业绩和回报经常受到LP批评，<strong>但至少基本的商业和职业底线并没有受到太多的质疑</strong>。而P2P是一种互联网金融模式，它主要是通过为借款人和出借人提供撮合服务来获得平台收益。虽然它们都与资本运作相关，但是它们的本质区别在于投资方向、投资方式以及风险控制等方面。创投主要是面向初创企业和高科技公司的投资，而P2P则是面向个人的小额贷款和投资。此外，创投的投资方式通常是通过股权投资、风险投资等方式，而P2P的投资方式则是通过借贷、消费分期等方式。最后，创投的风险控制主要是通过投资前的尽职调查和风险评估来降低风险，而P2P则需要通过完善的风控系统、资金管理以及透明度来控制风险。</p><p>作为国内最大的P2P网贷平台之一，红岭创投曾经在P2P的草莽时代“红极一时”，其创始人周世平也曾被业内誉为“P2P教父”。然而，自2018年以来，P2P行业的乱象丛生，监管部门开始重拳出击，行业逐渐被整顿。在此过程中，各地相继对P2P立案调查，但像红岭创投这样，以创投为名却行P2P之实的机构，对创投行业带来的负面影响却十分深远。</p><h2><strong>红岭创投的疯狂</strong></h2><p>红岭创投是由周世平于2009年创立的P2P网贷平台。作为行业的早期加入者，该公司最早开拓了<strong>“担保公司垫付本金”的模式</strong>。</p><p>根据广东省高级人民法院公众号信息，法院审理查明，2009年至2021年，周世平等人通过在红岭创投公司网上平台发行融资标的，累计向48万余人非法吸收公众存款约1090亿元人民币。法院认为，周世平等人的犯罪行为造成巨额财产损失，严重扰乱金融秩序。</p><p>周世平等人归案后，公安机关全力开展涉案资金、股权、房产等资产追缴。目前已追缴到案的资产，将在判决生效后依法返还集资参与人，不足部分责令周世平继续退赔。周世平等人明知红岭创投公司资金缺口巨大，仍发布虚假借款标的非法集资，所募资金主要用于归还融资项目到期本息、维持公司运营等无法产生利润的成本支出。周世平利用实际控制人身份，肆意使用非法集资款项，集资诈骗逾204亿元。</p><p>P2P行业由于缺乏监管约束，逐渐肆意生长，出现了无市场准入门槛、无行业规范等问题。这些问题导致该行业越来越偏离金融为民的初衷，大量资金被挪用、玩自融、“庞氏骗局”，从业人员缺乏专业性，模糊不清的投资模式、拆标，借款人资质恶劣、恶意骗贷，以及被金融黑产围剿等等，乱象丛生。</p><h2><strong>创投行业的监管合规之路</strong></h2><p>P2P暴雷潮开始同时，创投行业就受到了严格监管。</p><p>2018年中国人民银行、中国银行保险监督管理委员会、中国证券监督管理委员会、国家外汇管理局联合印发的《资管新规》正式对外发布，由于私募基金在募资端与各类资管产品有着密切关系，因此剑指银行理财和P2P的资管新规VC/PE机构产生深远影响，直接导致募资难。</p><p>自此之后，对创投行业的监管进一步收紧，“实行穿透式监管，对于多层嵌套资产管理产品，向上识别产品的最终投资者，向下识别产品的底层资产（公募证券投资基金除外）”，“为降低期限错配风险，金融机构应当强化资产管理产品久期管理，封闭式资产管理产品期限不得低于90天。资产管理产品直接或者间接投资于非标准化债权类资产的，非标准化债权类资产的终止日不得晚于封闭式资产管理产品的到期日或者开放式资产管理产品的最近一次开放日”。这意味着此前银行理财等资金通过资管计划投资私募股权基金时通常采取的<strong>“滚动发行”、期限错配、分离定价等</strong>操作均不再可行，相关涉嫌资金池的操作将被禁止。</p><p>此后，证监会主席易会满也在一场私募股权和创投基金座谈会上表示：“当前私募股权基金行业面临难得的发展机遇，将采取多项举措促进行业发展，包括逐步出清‘伪私募’、抓紧修订私募基金监管办法、建立分类备案机制、进一步优化创业投资基金“反向挂钩”政策等。&nbsp;”</p><p>今年以来，市场经历了一段寒冬，LP的出资变得更加谨慎。根据FOFWEEKLY的数据显示，<strong>财务型有限合伙人的出资次数和渗透率虽然相对稳定，但对市场的资金供给量进一步收紧</strong>。</p><p>虽然，红岭创投给行业带来了严重的不良印象，但是在区分“伪创投”、“伪私募”的前提下，创投行业仍然具有较大的投资价值和社会价值。</p><p>过去这些年，创投、股权投资为经济和科技发展带来了很强的活力，成为经济、金融活动中至关重要的组成部分。在信息相对封闭的私募股权投资市场当中，如何保持透明，给监管、市场展现出积极的一面，重建行业形象，成为所有机构共同面对的问题。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/wSOz3WmXYhZtL_XNJ0O6DA" rel="noopener noreferrer nofollow" target="_blank">“FOFWEEKLY”（ID:FOF_weekly）</a>，作者：FOFWEEKLY，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2552013348788609</id>
            <title>AMD正式发布AI芯片，英伟达该紧张起来了</title>
            <link>https://www.36kr.com/p/2552013348788609</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2552013348788609</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:55:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 英伟达, AMD, AI大模型
<br>
<br>
总结: 在AI热潮中，OpenAI和英伟达备受关注，但英伟达在AI大模型训练中的算力供应地位使其股价大涨。AMD推出了用于大模型训练和推理的MI300X GPU，并得到微软和Meta的支持。然而，AMD在软件生态方面与英伟达的CUDA相比仍有差距。尽管AMD GPU在AI跑分上表现出色，但在集群应用和生产力环境下存在短板。英伟达的CUDA生态已成为工业标准，但微软、Meta等巨头为了保证“能源安全”，选择了AMD的Instinct MI300X作为新的选项。 </div>
                        <hr>
                    
                    <p>要说在这一轮AI热潮中最受瞩目的存在，无疑非OpenAI莫属了，毕竟ChatGPT以及后续的GPT-4真正意义上让大众感受到了何为人工智能。但在这一轮风口中真正闷声发大财的莫过于英伟达，由于训练AI大模型需要海量的算力，而目前算力的核心供应商就正是英伟达，因此掌握了AI大模型命脉的这一事实，也使得其股价自今年以来累计上涨了高达220%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_17fe379f3a02492a81f6e4f8a1f4cd86@000000_oswg37235oswg600oswg337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>眼见英伟达的GPU，特别是Ampere A100、Hopper H100成为炙手可热的香饽饽，不甘受制于英伟达的各路AI厂商也开始八仙过海各显神通，其中自然少不了在GPU领域与英伟达打擂台的AMD。</p><p>日前在“Advancing AI”的活动上，AMD方面推出了用于大模型训练和推理的MI300X GPU，和用于HPC（高性能计算）的MI300A APU。随即微软与Meta两大巨头也确认，他们将使用AMD最新的AI芯片Instinct MI300X。</p><p>微软和Meta为AMD站台最主要的原因，莫过于Instinct MI300X本身的出色素质，AMD首席执行官苏姿丰博士更是表示，Instinct MI300X“能与英伟达H100 HGX媲美”。据悉，其是由8个MI300X GPU组成，可提供高达1.5TB的HBM3内存容量，并内置了8个XCD（加速计算芯片）、共304个基于CNDA 3架构的计算单元以及4个IOD（接口芯片），而使用8个HBM3（三星高性能存储芯片）堆栈，则为其带来了高达192GB的内存以及5.3TB/s的最大带宽。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_3ba32fdc9dca438cac28cbee08668132@000000_oswg29691oswg600oswg336_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AMD方面声称，与英伟达H100 HGX相比，Instinct MI300X加速器在运行大语言模型推理时的吞吐量和时延表现更好。而在实际测试中，由于Instinct MI300X更强大的存储性能，在70亿参数的Llama2和160亿参数的Bloom推理能力方面，推理效率分别达到了H100的1.4倍和1.6倍。</p><p>如果单纯从纸面数据上来说，英伟达在AI领域一家独大的日子可能要一去不复返了，但显然纸面数据并不能说明一切。</p><p>目前，软件生态的壁垒就是AMD在算力芯片领域赶超英伟达时，所需要面对的一大挑战。由于训练和运行AI大模型不仅取决于GPU性能，工具链和资源库同样也必不可少，而AMD的ROCm软件生态却显然还没有英伟达的CUDA完善。</p><p>早在2006年英伟达就推出了CUDA开发平台，开发者可以借助这一平台，使用C语言编写GPU片上程序，来完成复杂的计算。这也让GPU从此实际脱离了图像处理的单一用途，成为了真正的GPGPU。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_c30075f42a8948038615c98ee56f705a@000000_oswg27064oswg600oswg336_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>经过长达十余年时间的积累，目前CUDA的库、工具，以及资源生态系统，也使得开发者能够轻松借助GPU的并行计算能力，构建更强大和高效的AI模型，同时实现高性能、高通用性、高易用性，以及针对不同场景的深度优化。而反观AMD的ROCm，起步则要晚得多，其2016年才问世，而且与Intel在CPU领域的竞争更是让AMD在过去几年基本是对ROCm的态度是“放养”。</p><p>所以尽管ROCm几乎是全盘复刻了CUDA的技术栈，而且采取了开源策略，但其与CUDA最起码也有十年左右的差距。以至于目前AMD在提供AI算力上采取的解决方案，是基于ROCm翻译实现“CUDA兼容的AMD GPU”，即通过二进制翻译/进程虚拟机技术去解析和转换CUDA PTX通用指令到Radeon指令，这个方案虽然让AMD的GPU得以切入AI算力领域，但代价却是基于AMD GPU的开发工作，需要花费更多的时间、且在迭代和生态延展性上存在缺陷。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_7fbf4eb4203f4af19694cbba3d1f7af7@000000_oswg30483oswg600oswg336_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>简而言之，AMD GPU在AI跑分上尽管是单卡性能爆表，但组成集群应用在生产力环境下就暴露短板了。力不虚掷、功不唐捐，在CUDA加持下的英伟达GPU虽然未必是性能的最优解，可在当前的AI大模型训练和推理上却是效费比的最优解，而英伟达耕耘了十余年的CUDA生态，更是已成为了事实上的工业标准。</p><p>“AMD YES，但我选英伟达”这句调侃，其实在消费级市场是毫无问题的，毕竟对于普通用户而言，用得舒心才是最重要的，然而企业的考量则完全不同。“不把鸡蛋放到同一个篮子里”不仅仅是苹果的指导思想，也几乎适用于每一个科技巨头。</p><p>如今AI算力已经是大模型得以运转的燃料，为了保证“能源安全”，微软、Meta等巨头自然不愿意只靠英伟达这一家供应商，而AMD的Instinct MI300X则给了他们一个新的选项。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_39e77486dcc041d4b5f2621ef3909654@000000_oswg19405oswg600oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然Instinct MI300X的实际表现大概率不会强于Hopper H100，但如果没有前者，英伟达自然就会有恃无恐。现在的情况是除了OpenAI之外，其他厂商的大模型基本都是在赔本赚吆喝阶段，这一年以来的投入也更像是在给英伟达打工。这一现实必然不会如微软、Meta所愿，其中前者投了上百亿美元给OpenAI，后者则干脆开源了自家的LLaMA 2大模型，这两家搭台唱的这出AI大模型戏终归是为了自己赚钱，而不是让英伟达白白捡便宜。</p><p>貌合神离就是当下一众积极投身AI赛道的大厂，与英伟达之间关系的真实写照，所以购买英伟达的GPU训练自己的大模型虽然可以，但指望把后背交给英伟达显然是不可能的。所以即便如今在AI算力领域，AMD暂时还不能对英伟达构成威胁，但这已经足以让后者感到警惕，进而对微软、Meta、亚马逊等客户采取更加怀柔的态度，而这显然也正是这些巨头想要的结果。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649853945&amp;idx=2&amp;sn=da33a040f80c9eb41945b53594f02962&amp;chksm=8789c93bb0fe402d4e6201a829df78c136f64cbf3e2864f0aa3f3dfa22bcb6cb6b7daff11876&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551964785252743</id>
            <title>谷歌又没能“遥遥领先”</title>
            <link>https://www.36kr.com/p/2551964785252743</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551964785252743</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:55:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemini, 大模型, 多模态能力, GPT-4
<br>
<br>
总结: 谷歌发布了名为Gemini的大模型，具有强大的多模态能力，被称为人工智能发展的重要里程碑。Gemini可以生成、理解和操作不同类型的信息，包括文本、代码、音频、图像和视频。然而，Gemini的发布引发了一些质疑，包括展示视频的真实性和Gemini Ultra在测试中的表现。 </div>
                        <hr>
                    
                    <p>千呼万唤始出来，谷歌终于释放了大模型的新大招——Gemini。</p><p>当地时间12月6日，谷歌正式发布了Gemini大模型。在一份声明中，谷歌CEO桑达尔·皮查伊（Sundar Pichai）称，这是谷歌迄今为止“功能最强大、最通用”的模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_cf8a38be4be04007b5854f5ecb0b6253@000000_oswg65894oswg398oswg411_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于Gemini，谷歌就差说出“遥遥领先”四个大字。皮查伊描述其意义是人工智能发展的一个重要里程碑，也是谷歌新时代的开始：“这个新时代的模型代表了我们作为公司所进行的最大的科学和工程努力之一。我对即将到来的发展和Gemini为全球人民带来的机遇感到无比激动。”</p><p>演示视频中Gemini的表现的确称得上“惊艳”。在一段视频中，谷歌的人员用视频给Gemini 画画、展示物品，并和它对话。Gemini用语音和文字进行回答，不仅可以识别出工作人员手绘的简笔画是什么，还能“看”出其手持的玩具鸭子的材质是“橡胶”，并且还和其玩起了互动小游戏。甚至在工作人员询问鸭子一词的普通话发音时，Gemini也精准读出，还顺带科普了普通话的四个音调。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_28ba38d144e84a0da89a21a10bc5b7ac@000000_oswg224624oswg1029oswg578_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这则演示之所以惊艳，是因为它融合展示了Gemini不俗的多模态能力。在图像、视频、音频等的输入和输出中，Gemini不需要特别做切换，更贴近人与人交互的体验。皮查伊在一篇博文中提到：“Gemini一开始就是为多模态打造的，这意味着它可以生成并理解、操作和组合成不同类型的信息，包括文本、代码、音频、图像和视频。”</p><p>谷歌也拿出数据展示Gemini的能力，比如在MMLU多任务语言理解数据集测试中，Gemini Ultra不仅超越了GPT-4，也比人类专家强。</p><p>眼尖的朋友不会忽略后缀“Ultra”。这次Gemini发布提供了三个版本，分别是轻便的Gemini Nano，可以在安卓设备上原生离线运行；Gemini Pro，已经接入Bard；Gemini Ultra，本次发布的最强版本。</p><p>实际上，这次发布Gemini最亮眼的表现由Gemini Ultra贡献，也是这个版本对标了GPT-4，但这个版本计划2024年才会正式推出。而Gemini Pro已经接入Bard，但目前只可在英文交互中被调动，该模型对标GPT-3.5，后者是OpenAI在2022年初就释放的模型。至于Gemini Nano，“谷歌亲儿子”Pixel手机的最新版Pixel 8 Pro的用户将很快体验到。</p><p>总而言之就是，Gemini挺好的，就是“但是”有点多，承诺也多于当下的应用。更要命的是，在Gemini发布不久，就被外界扒出展示视频疑似拼接剪辑的产物、Gemini Ultra和GPT-4的测试疑似被谷歌“双标”等问题。</p><p>Gemini也许真的强，但是否达到了谷歌需要的“遥遥领先”？</p><h2>A</h2><p>先来看看Gemini在发布之后遭遇了什么质疑。</p><p>首先是那个颇为惊艳的展示视频，视频中Gemini流畅地与工作人员对话，用多模态的方式进行着交互。</p><p>但很快，展示视频的声明就被关注到了。声明是这样说的：“为了演示的目的，（视频中）延迟已经减少，Gemini的输出已经进行精简。”而这个声明并没有放在显眼的位置，而是在谷歌发布的YouTube视频的描述文本中，不仔细看很容易忽略。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_16b40b485a2f4570bd1bcd3ca4e1cb54@000000_oswg38256oswg608oswg276_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>难道谷歌的展示视频并不是实时录制，而是经过编辑的？可能更糟。彭博社（Bloomberg）的专栏作家奥尔森（Parmy Olson）就此事问询谷歌，得到了一位发言人的回应：这段视频是通过“使用视频中的静态图像，并通过文字提示”制作的。</p><p><strong>也就是说，演示视频虽然给人一种人类和Gemini“视频通话”畅聊的感觉，但这只是感觉，实际上视频中工作人员所说的话，是在念给Gemini的文字提示，而展示的也不是视频，而是静态图像。</strong></p><p>另有谷歌员工匿名向彭博社吐槽，对演示视频并不感到惊讶，因为他们已经习惯了某种程度的营销炒作：“我认为，大多数使用过LLM（大语言模型）技术的员工都知道，要对这一切持保留态度。”</p><p>面对外界的质疑，谷歌选择放低姿态，不仅放出了演示视频背后详细的交互过程，谷歌DeepMind的产品副总裁伊莱·柯林斯（Eli Collins）还明确表示，画鸭子的演示展示的是一种研究层面的努力，至少目前不在谷歌的产品中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_7bfae5cad6504ed2870751757a29b1e8@000000_oswg284329oswg708oswg766_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其次是Gemini Ultra在测试中的表现。依据谷歌的展示，Gemini Ultra在大规模多任务语言理解测试MMLU中，得分高达90%，是首个在该测试中超越人类专家的模型。MMLU综合运用了数学、历史、法律、物理、医学和伦理等57个科目，是测试AI世界知识和问题解决能力的重要工具。</p><p>其中，谷歌展示的一张图令人印象深刻，图中Gemini的得分“遥遥领先”于GPT-4和人类专家，图中GPT-4的得分在最底部，人类专家的得分大约在中间的位置，而Gemini Ultra的得分在顶部。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_d4eeebafebb84a3b95bdc3dbd33ac5ac@000000_oswg215148oswg1064oswg842_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但人们很快就发现不对，GPT-4在MMLU中的得分为86.4%，人类专家是89.8%，而Gemini Ultra的得分为90%，何至于在折线图中展示出均分画面的效果？</p><p><strong>这不是纵轴尺度不均的把戏吗？</strong>这个把戏骗不了打工人，毕竟大家在工作汇报的时候都熟练运用了。</p><p>当红的AI初创公司HuggingFace的CEO菲利普·施密德（Philipp Schmid）在社交平台上吐槽“永远别相信营销”，并贴出了他帮谷歌修正后的折线图，Gemini Ultra的领先优势立刻变得不那么明显了。</p><p>此外，施密德还发现了一个关键点，虽然同样是对MMLU的测试，但GPT-4和Gemini的“待遇”不大相同。Gemini Ultra的得分是基于CoT思维链提示技巧，尝试32次后取的最佳得分，但GPT-4是在无提示词技巧下，尝试了5次拿到的得分。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e06addc85cde4af09f255ee36ee63379@000000_oswg128221oswg566oswg587_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>施密德也提到，其实同样是用CoT@32（思维链提示技巧下尝试32次），GPT-4的得分为87.29%，的确不如Gemini Ultral；但要是同样在无提示词技巧下尝试5次，Gemini Ultra的得分其实只有83.7%，低于GPT-4的86.4%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_8772deb0248e406eb02a996a07d0664d@000000_oswg71604oswg589oswg184_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>相当于Gemini Ultra和GPT-4分别参加了两场考试，都拿到了两个分数。明明是各自赢了一场考试，谷歌宣传自己赢的那场考试就算了，还偏偏用自己在一场考试中的高分，去对阵GPT-4在另一场考试中的低分，怎么看都有点“不讲武德”了。</p><h2>B</h2><p><strong>自从ChatGPT出现，谷歌踏入尴尬之境。</strong></p><p>一方面，谷歌在AI领域的野心与成就有目共睹。早在2011年，谷歌大脑Google Brain就已经成立，目标是研究深度学习和神经网络。次年，谷歌大脑由1.6万台电脑集群组成的人工神经网络，在学习了10万个YouTube视频后，没有学习“猫”为何物而自行精准识别出“猫”，震惊四座。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ac542ef2addc49189f8354d4afb24e58@000000_oswg441458oswg1000oswg869_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2014年，谷歌又以6亿美元价格收购DeepMind，当时后者还是仅有50名员工的小公司。谷歌对AI如此舍得下血本，也直接促成了马斯克等人应激式地成立OpenAI，以对抗谷歌未来在AI领域可能形成的垄断局面。</p><p>仅仅两年后，已经被谷歌收入麾下的DeepMind就推出了AlphaGo，击败围棋顶尖选手李世石，一炮而红。谷歌就此成为AI领域不可忽视的、第一梯队的力量。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_71379fe263ff461ca92b16b39a2ffbf3@000000_oswg359632oswg727oswg532_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其后数年，做研究、发论文、推产品，谷歌没有停下在AI领域的脚步。OpenAI的GPT模型之“T”，正是Transformer模型之意。Transformer模型是一种用于自然语言处理中的神经网络模型，是由谷歌的研究人员在2017年提出的，那一年皮查伊喊出“从移动优先转向AI优先”的口号。当年写就Transformer论文的研究人员，也被冠以“Transformer八子”的称号，可见其分量之重。</p><p><strong>但另一方面，ChatGPT推出之后，谷歌就陷入了被动。</strong></p><p>如果说几年前做“谁会造出一个轰动世界的大模型驱动的聊天机器人”，那谷歌八成是猜测的大热门。但这并不是故事的走向，OpenAI推出了ChatGPT，而谷歌至今没有能与之抗衡的产品。</p><p>今年2月，在外界的瞩目下，谷歌推出了聊天机器人Bard。作为ChatGPT的直接竞品，Bard被寄予厚望，却不如预期。先是演示中出现事实错误，让谷歌母公司一夜之间市值蒸发千亿美元。而后也没能以性能表现吸引足量用户，据Similarweb的数据，Bard全球月访问量只有2.2亿次，仅为ChatGPT的八分之一。</p><p><strong>谷歌在AI领域明明素有“遥遥领先”之态，为什么这次不能“遥遥领先”了，问题到底出在哪儿？</strong></p><p>“Transformer八子”也许能掀开谷歌难题的一角。这八子目前已经全部从谷歌出走，其中1位加入OpenAI，其余7人创业。彭博社引用谷歌科学家和工程师称，谷歌规模庞大，任何创意都要经过多层确认。就算创意通过，从创意到产品的门槛也很高。在谷歌，高级研究人才想将想法变为现实，难度颇大。</p><p>换句话说，谷歌多少有点“大公司病”，这也可以解释为何谷歌在应对OpenAI和微软的挑战时显得有些“迟缓”。</p><p>ChatGPT的推出，使得AI的战场更加瞬息万变，看看OpenAI和微软过去一年对模型和产品的迭代速度就知道了——今年2月微软推出新必应，3月OpenAI就正式推出了GPT-4，9月微软推出微软“智能副驾”Microsoft Copilot，10月就开始向Windows 11用户推送更新，11月OpenAI又推出了GPT-4 Turbo。况且OpenAI每次的发布会还会有真枪实弹的演示，动辄就是“即日起可用”。在这样的竞争环境下，谷歌的“谨慎”就变成了一种诅咒。</p><h2>C</h2><p>谷歌有足够的理由着急。</p><p>在AI驱动的云计算竞赛中，谷歌一直落后于微软。今年两大巨头多次同日发布财报，让对比更加明显。截至9月底的2023年第三季度财报显示，谷歌云营收低于华尔街预期，且为11个季度以来增长最慢的一季。而微软同样截至9月底的2024财年第一财季业绩报告则显示，微软智能云部门收入同比增长19%，其中Azure更是同比增长29%。</p><p><strong>在Bard效果不佳的情况下，Gemini是谷歌寻求突破的一枚关键棋子，这也是Gemini还没推出就备受瞩目的原因。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_56261599c857453dae267b601f7e40e6@000000_oswg94932oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今年4月，谷歌将谷歌大脑Google Brain和DeepMind合并，成为新的部门谷歌DeepMind。此前谷歌原生孵化的谷歌大脑与收购而来且一直享有高度自主权的DeepMind之间，一直有资源抢夺和内部竞争的问题，这与“Transformer八子”出走暴露出的谷歌的问题一致。</p><p>而合并二者，显示出了谷歌从组织层面上入手，扫清AI竞赛上的障碍之决心。合并之后，DeepMind联合创始人德米斯·哈萨比斯（Demis Hassabis）成为谷歌DeepMind的CEO。</p><p>不出两个月，哈萨比斯就在采访中透露了Gemini项目，并放出豪言，称Gemini的能力将强过OpenAI的GPT-4。</p><p>在今年年中的谷歌I/O开发者大会上，谷歌共提及143次AI，皮查伊首次承认Gemini的存在。从那时起，全世界都在等着谷歌“憋大招”。</p><p>如此看来，就能理解谷歌为什么在那么多“但是”的情况下，就发布Gemini，又为什么要如此用力地营造“遥遥领先”的形象。</p><p>好消息是，尽管外界质疑颇多，但市场对谷歌Gemini的发布给出了正反馈。当地时间周四，谷歌母公司Alphabet的股价大幅上涨了5.3%，市值上涨800亿美元。巧合的是，今年9月传出的OpenAI最新估值正在800亿美元到900亿美元之间。谷歌一夜涨出了一个OpenAI。</p><p>坏消息是，承诺大过落地的Gemini，需要实实在在地兑现承诺，2024年Gemini Ultra的正式推出将是一个关键节点。</p><p><strong>而在那之前，只能默默祈祷OpenAI的GPT-5来得慢一些。</strong>就在上个月，OpenAI的CEO山姆·阿尔特曼（Sam Atlman）透露，GPT-5正在开发中。</p><h3><strong>参考资料</strong></h3><p>1、新浪科技：《两个小时：谷歌说了143次AI，股价连涨两天》</p><p>2、财联社：《OpenAI承认正开发GPT-5 终极目标是相当于人脑的超级AI》</p><p>3、极客公园：《谷歌 25 周年｜3.0——从 AI 弄潮儿到追赶者》</p><p>4、北京商报：《同日发财报：微软赢了谷歌》</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI2NjU1MTcwMA==&amp;mid=2247528541&amp;idx=2&amp;sn=29b8a3a27472bb6d82bdfd5c429ab06e&amp;chksm=ea8e58a6ddf9d1b019a41c7de855e02f30668ecd7bd26d571c22c2ee6203d878e9837d3da2de&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“字母榜”（ID：wujicaijing）</a>，作者：毕安娣，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551927137050755</id>
            <title>钻石，颠覆传统芯片</title>
            <link>https://www.36kr.com/p/2551927137050755</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551927137050755</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:55:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 钻石, 芯片, 金刚石, 专利
<br>
<br>
总结: 华为与哈尔滨工业大学联合申请的专利涉及一种基于硅和金刚石的三维集成芯片的混合键合方法。金刚石作为一种具有高热导率和宽禁带半导体的材料，被用于提高硅基器件的散热通道和可靠性。除了华为，国际上还有其他企业和研究机构也在推动钻石芯片的研发和产业化。这些研究旨在解决芯片热挑战，提高芯片运行速度，并在未来引入金刚石作为半导体材料。 </div>
                        <hr>
                    
                    <p>“钻石恒永久，一颗永流传。”这一句广告词，引起了诸多女人的疯狂，也让钻石成为了昂贵的爱情代表。</p><p>最近，“钻石”也开始走入半导体，华为和哈尔滨工业大学的专利《一种基于硅和金刚石的三维集成芯片的混合键合方法》被公开，引起了业内的“疯狂”。这金刚石，指的就是还未经打磨的钻石原石。</p><p>“钻石”芯片，究竟有何种魅力？</p><h2><strong>01 华为的“钻石”专利</strong></h2><p>如前文所述，华为与哈尔滨工业大学联合申请的一项专利，这项专利涉及一种基于硅和金刚石的三维集成芯片的混合键合方法。</p><p>具体来看，就是通过Cu/SiO2混合键合技术将硅基与金刚石衬底材料进行三维集成。华为希望通过两者的结合，充分利用硅基半导体和金刚石的不同优势。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_aa6643bf77ba4de68b18a7e9a6473104@1743780481_oswg133083oswg588oswg869_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：华为与哈尔滨大学提交《一种基于硅和金刚石的三维集成芯片的混 合键合方法》专利</p><p>硅基半导体的优势不用多说，有成熟的工艺及产线、生产效率高并且成本较低。金刚石则是已知天然物质中热导率最高的材料，室温下金刚石的热导率高达2000Wm‑1K‑1，同时金刚石是宽禁带半导体，具备击穿场强高、载流子迁移率高、抗辐照等优点，在热沉、大功率、高频器件、光学窗口、量子信息等领域具有极大应用潜力。</p><p>在专利书中提及，本次结合利用的就是金刚石极高的发展潜力，想要为三维集成的硅基器件提供散热通道以提高器件的可靠性。</p><p>受到华为专利的影响，当天国内A股培育钻石概念板块猛涨。实际上，引发半导体业内“疯狂”的“钻石”芯片在国际上并非只有华为一家。近年来，“钻石”芯片的研发消息频频传来。</p><h2><strong>02 抓住“钻石芯片”</strong></h2><p>国际上最新的消息，是一家由麻省理工、斯坦福大学、普林斯顿大学的工程师创立的企业在金刚石晶片方面的进展。</p><p>这家企业的名字叫做Diamond Foundry，企业主要的研究方向也是金刚石方向。从官网上来看，这家企业希望使用单晶金刚石晶圆解决，限制人工智能、云计算芯片、电动汽车电力电子器件和无线通信芯片的热挑战。</p><p>今年10月份Diamond Foundry培育出了世界上第一个单晶金刚石晶片，具体的数据上，这个金刚石晶片直径100毫米、重量100克拉。</p><p>Diamond Foundry在接受采访时表示，已经可以在反应炉中培育出4英寸长宽、小于3毫米厚度的钻石晶圆，而这些晶圆可以和硅芯片一同使用，快速传导并释放芯片所产生的热量。</p><p>怎么一同使用呢？Diamond Foundry 开发了一套技术，为每个芯片植入钻石。以原子的方式直接连接金刚石，将半导体芯片粘合到金刚石晶圆基板上，以消除限制其性能的散热瓶颈。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b6afba63f27749f4b171939c5691c395@1743780481_oswg128897oswg1080oswg395_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">热量情况对比 来源： Diamond Foundry</p><p>按照其首席执行官Martin Roscheisen的说法，这可以使得芯片的运行速度至少是额定速度的两倍，并且Diamond Foundry工程师在英伟达最强大的芯片之一上使用这种方法，在实验条件下甚至能够将其额定的速度增加到三倍。</p><p>同时，Diamond Foundry公司的官方计划中还表示，希望能够在2023年后，引入单金刚石晶片，并在每个芯片后面放置一颗金刚石；在2033年前后，将金刚石引入半导体。</p><p>美国不止这一家企业在推动“钻石”芯片的产业化。美国的AKHAN、阿贡国家实验室，日本的NTT、NIMS等，都投身于此。其中，AKHAN公司专门从事实验室制造合成电子级金刚石材料，在2021年时，他们宣布能够制造300mm互补金属氧化物半导体 (CMOS) 金刚石晶圆。</p><p>稍早一些消息的还来自日本，依据已经宣布的研究成果来看，日本对于金刚石芯片的产业化探索更加全面。</p><p>从去年开始，日本生成了可用于量子计算项目纯度的金刚石晶圆；再到今年年初，日本校企合作，研发了一个金刚石制成的功率半导体；到今年8月，日本千叶大学科研团队提出关于“毫不费力地切割”金刚石的方法。从种种动向来看，日本对于金刚石芯片的研究也是比较重视的。</p><p>我们分别来看看日本这三个关于“钻石”芯片的研究。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_a39df5e02f2b4eaaaf07f3ae1a66ea06@1743780481_oswg287464oswg644oswg772_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">直径55mm超高纯金刚石晶片和4mm×4mm晶体对比</p><p>去年4月，日本Adamant Namiki Precision Jewel和佐贺大学联合宣布，已经于4月19日成功实现“钻石”晶圆量产，这种“钻石”晶圆的纯度是可以用在量子计算机、量子存储器和量子传感设备中。</p><p>这里日本解决的是如何实现少氮含量，更大尺寸金刚石的生成。在此之前，能够达到量子应用的超高纯度金刚石是只有4mm×4mm的晶体，而这次日本生成了直径2英寸（大概55mm）的晶体。</p><p>实际上，从生成的方式来看，之前市场往往利用氮气适合大规模生产的高生长速率，但这也会留下几ppm（百万分之一）的氮杂质。通过技术方式的改进，目前可以实现生产氮含量不超过3 ppb的超高纯度2英寸金刚石。</p><p>Adamant Namiki 表示：“理论上，一块2英寸的金刚石晶圆可以提供足够的量子存储器来记录10亿张蓝光光盘，这相当于一天内分布在全球的所有移动数据。”</p><p>2022年宣布这个消息时，Adamant Namiki Precision Jewelry还表示计划2023 年将 Kenzan 钻石晶片商业化，并且公司已经开始开发 4 英寸钻石晶片。不过，到了现在（2023年年底）该公司的4英寸钻石晶片，还没有传来新的消息。</p><p>年初，同样是日本，佐贺大学的教授和日本精密零部件制造商Orbray，合作开发了一个金刚石制成的功率半导体。这个功率半导体可以以1平方厘米875兆瓦的电力运行，在金刚石半导体中，输出功率值为全球最高，在所有半导体中也仅次于氮化镓产品。</p><p>这个技术的实现主要利用金刚石的高耐压性。采用向金刚石基板吹送二氧化氮气体的方式，使得金刚石基板具备半导体的性质。再通过用氧化铝膜进行保护，特殊的研磨方法将基板表面磨平，设法降低了电阻，最终实现了高性能半导体器件。</p><p>今年8月，日本的千叶大学科研团队提出了一种新的激光技术可以沿着最佳晶体平面“毫不费力地切割”钻石。</p><p>千叶大学的 Hirofumi Hidai 教授和他的团队提出了解决该问题的方案：基于激光的切割工艺，可以干净地切割钻石而不破坏钻石。研究人员表示，新技术通过将短激光脉冲聚焦到材料内狭窄的锥形体积上，防止激光切割过程中不良裂纹的传播。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_70709bdf414649b7ba2afab3f67cc8ce@1743780481_oswg503320oswg1080oswg538_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">千叶大学科研团队切割方式</p><p>激光脉冲将金刚石转变为密度较低的无定形碳，用激光照射的区域会出现密度降低和裂纹形成的情况。据介绍，研究人员创建了一个网格状图案来引导裂纹沿着指定的切割路径传播，同时使用锋利的钨针“轻松”地将光滑的晶片与金刚石块的其余部分分开。</p><p>千叶大学表示，这项新提出的技术可能是将钻石转变为“适合未来更高效技术的半导体材料”的关键一步。Hidai教授表示，用激光切割钻石“能够以低成本生产高质量的晶圆”，并且对于制造钻石半导体器件是必不可少的。</p><h2><strong>03 “钻石芯片”恒永久，如何永流传？</strong></h2><p>谈了这么多国际和国内的研究情况，我们已经可以大概了解金刚石特点，以及为什么会用在半导体领域了。其实主要利用金刚石的三大属性。</p><p>第一，高热导率。金刚石是自然界中热导率最高的物质，比碳化硅（SiC）大4倍，比硅（Si）大13倍，比砷化镓（GaAs）大43倍，是铜和银的4~5倍。这就能解决目前半导体产业遇到的一个问题——散热。</p><p>目前，对于芯片性能的限制有一方面实际上是温度，对于大部分硅制的芯片来说，一旦运行温度超过105摄氏度，那么芯片就会变得不可靠。在很多日常生活中都能够感受到芯片的发热，一台使用很久的笔记本，放在腿上会发现底板在发烫、风扇在疯狂旋转而笔记本的运行速度下降。</p><p>这些热量从哪里来，可以拿CPU举例。一个CPU是由数亿个晶体管组成的，电流通过连接CPU中的微原件会产生热量，这被称为“焦耳热”，之后电流通过PN结的时候释放热量。这个热量通常和频率成正比，和电流的平方程成正比。因此，电脑的运算越快，处理器的工作量越大，那么产生的热量就越多。</p><p>麻省理工学院纳米工程实验室主任Gang Chen给出了具体数据：“当今，高性能芯片的功耗约为每平方厘米100瓦，这些因为芯片运行所产生的能量最终都转化为了热量，并且热量必须散发出去。”</p><p>上文提到的华为金刚石专利，在专利申请中华为也解释到：“随着集成密度不断升高以及特征尺寸不断缩小，电子芯片的热管理面临极大的挑战。芯片内部热积累难以向封装表层散热片传递，导致内部节温突升，严重威胁芯片性能、稳定性和使用寿命。”华为专利主要就是利用金刚石的高散热性。</p><p>第二，5.5eV的禁带宽度。金刚石是一种超宽禁带半导体材料，其禁带宽度是Si的5倍；载流子迁移率也是Si材料的3倍，理论上金刚石的载流子迁移率比现有的宽禁带半导体材料（GaN、SiC）也要高2倍以上。</p><p>优秀的禁带宽度也使得金刚石拥有耐高压、大射频、低成本、耐高温等多重优异性能参数。甚至被称为“终极半导体”。前文中，日本开发的金刚石功率半导体利用的就是这一特性。</p><p>同时，需要注意，在2022年，美国商务部工业和安全局（BIS）发布公告，称出于国家安全考虑，将四项“新兴和基础技术”纳入新的出口管制，其中之一就是能承受高温高电压的第四代半导体材料金刚石。</p><p>第三，金刚石的特殊的能量结构。这个特性主要是关于金刚石用在量子存储中。与传统的存储器相比，金刚石量子存储器能将光子转换成金刚石中碳原子的特定振动，适用于许多不同颜色光的这种转换，将允许对光进行广谱操纵。金刚石的能量结构允许其以很低的噪声在室温下实现。从理论上来说，金刚石半导体在室温下工作，性能最高。前文提到日本Adamant Namiki Precision Jewel和佐贺大学研发出的可以用于量子计算机存储器的金刚石晶圆，主要希望利用这一特性。</p><p>总而言之，金刚石半导体具有优于其他半导体材料的出色特性，如高热导率、宽禁带、高载流子迁移率、高绝缘性、光学透过性、化学稳定性与抗辐射性等。未来，随着制造技术的进步和对金刚石的更深入研究，金刚石可能会成为制造高效、稳定、耐用的芯片的关键材料。</p><p>这时候，金刚石就将真正成为让半导体业界“疯狂的石头”。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/3OuLwOckqwEulUr36JG1-g" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID:ICViews）</a>，作者：九林，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2552031289514373</id>
            <title>重磅，华为、支付宝宣布了</title>
            <link>https://www.36kr.com/p/2552031289514373</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2552031289514373</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:54:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为鸿蒙原生应用开发, 支付宝, HarmonyOS NEXT, 鸿蒙生态
<br>
<br>
总结: 华为鸿蒙原生应用开发正在加速中。支付宝与华为合作，基于HarmonyOS NEXT启动鸿蒙原生应用开发，推动鸿蒙生态进一步完善。华为的系统底座全栈自研，去掉了传统的AOSP代码，仅支持鸿蒙内核和鸿蒙系统的应用。目前已有近半数Top 20移动互联网应用启动了鸿蒙原生应用的开发。然而，鸿蒙原生应用开发还面临人才缺口和生态建设的挑战。 </div>
                        <hr>
                    
                    <p>华为鸿蒙原生应用开发正在加速中。</p><p>12月7日，支付宝与华为终端宣布合作，基于HarmonyOS NEXT启动支付宝鸿蒙原生应用开发，成为又一家启动鸿蒙原生应用开发的头部平台伙伴，鸿蒙生态布局进一步完善。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_65dd632ca9f6487ba094c3d409dc4c7b@1743780481_oswg80445oswg1080oswg705_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今年9月，华为宣布全新HarmonyOS NEXT蓄势待发、鸿蒙原生应用全面启动。这意味着，其系统底座全栈自研，去掉了传统的AOSP代码，仅支持鸿蒙内核和鸿蒙系统的应用。此外，HarmonyOS NEXT只能使用Hap格式的安装包，这也代表着HarmonyOS将不再适配安卓应用。在这一背景下，目前Top 20移动互联网应用中已有近半数启动了鸿蒙原生应用的开发。</p><p>12月8日，华为常务董事、终端BG CEO、智能汽车解决方案BU董事长余承东在微博发文表示：华为不断和越来越多的合作伙伴一起努力，发展面向万物互联时代的鸿蒙生态。<strong>今天又迎来了重要里程碑，</strong>大家常用的支付宝也将全面启动鸿蒙原生应用开发了！支付宝将基于HarmonyOS NEXT版本开发应用，给消费者带来全场景的新体验。头部应用伙伴的加入，大力推动了鸿蒙生态进一步完善。欢迎更多有实力、有理想的伙伴加入我们，共建、共创、共享、共赢全新的鸿蒙生态！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_f2ba2134c9df48b39f9d0b40ce6d0179@1743780481_oswg116957oswg694oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据规划，华为将在2024年一季度推出HarmonyOS Next开发者预览版本，对于手机用户而言，将在接下来的HarmonyOS代际更新中体验到新操作系统，预计最快的时间点就是明年。逐步使用自研的纯鸿蒙内核是华为最初的目标，但生态的建设并非一日之功，鸿蒙原生应用的发展依然任重道远。</p><h2><strong>多家企业开发鸿蒙原生应用</strong></h2><p>相比安卓和iOS，鸿蒙并非一款单纯的手机操作系统，而是面向万物互联时代的全场景分布式操作系统。回溯过往，自2019年HarmonyOS问世以来，经过几个版本的迭代，HarmonyOS已逐渐应用于华为手机、电视、手表、智能座舱等产品。</p><p>不过，当前华为手机上大多数应用程序的架构仍基于安卓，对此，华为也开始加速发力鸿蒙应用的开发生态。但对软件公司而言，开发鸿蒙原生应用是一项新挑战，多家互联网公司已开始在各大招聘网站与公司招聘官网中发布与鸿蒙系统相关的开发岗位，不过由于该软件生态推出时间较短，国内还存在人才缺口。</p><p>人才之外，对操作系统来说，生态构建也是操作系统能否取得成功的核心。“做一个操作系统，技术上并不难，生态才是核心。生态涉及的广度、深度和复杂度远远超过所有的单个技术；另外，做生态如果配合不上产业发展变迁的机会，强做一个生态也很难成功。”曾担任华为消费者业务软件部总裁的王成录曾说道。</p><p>在生态建设上，近期华为密集公布了与合作伙伴的合作。除了支付宝，12月6日，麦当劳中国也与华为达成鸿蒙合作协议，宣布麦当劳中国APP将基于HarmonyOS NEXT启动鸿蒙原生应用开发，这意味着鸿蒙生态在餐饮领域取得了突破。11月13日，华为宣布与美团以HarmonyOS为基础进行产业创新、技术应用、商业发展等方面的合作，并全力支持美团启动开发鸿蒙原生应用工作。更早之前，去哪儿、钉钉、蚂蚁集团、小红书、58集团、哔哩哔哩、高德地图等也已启动鸿蒙原生应用开发。</p><p>展望未来，华西证券认为，从独立性来看，华为鸿蒙5.0将不再兼容安卓系统，有助于减少鸿蒙系统对安卓的依赖，提高系统安全性和稳定性；从分布式能力来看，鸿蒙系统起初以分布式为核心，5.0将会进一步加强分布式能力，设备协作性增强；性能方面，无论是启动速度、应用加载速度还是系统流畅度，都将得到显著提升。</p><h2><strong>鸿蒙原生应用开发还有很长的路要走</strong></h2><p>从当前的手机操作系统看，谷歌的安卓系统无疑是全球手机操作系统的霸主，其开源的特性和丰富的应用生态使得安卓系统在全球市场占据主导地位。然而，随着苹果、华为等厂商的崛起，安卓系统的统治地位也开始面临挑战。</p><p>国泰君安计算机团队曾在发布的研报中指出，“在复盘操作系统发展史后，我们可以发现一旦某一赛道操作系统的市场格局确定之后，后来者几乎没有翻盘的可能性。例如：Android在手机端非常强势，但它还是无法参与到PC市场的竞争中。如果有新的操作系统能够把握住万物互联的机遇，降低软硬件结合的门槛，那么就有可能培育出一系列基于边缘硬件的爆款创新应用，从而把握住未来十年、二十年的行业生态话语权。”而这正是鸿蒙所瞄准的市场。</p><p>Counterpoint数据显示，2023年第二季度，在中国智能手机市场，鸿蒙操作系统的份额达到10%，较上年同期增加了6个百分点。在全球市场上，鸿蒙、iOS、安卓的份额分别为2%、17%、81%。今年8月，华为透露，目前搭载HarmonyOS的华为设备已达7亿+台，鸿蒙生态技术品牌鸿蒙智联已有超过2300家合作伙伴。</p><p>作为 自主可控 的操作系统，鸿蒙系统的研发成功是我国在智能国产操纵系统发展的一大步，但不可否认的是，尽管鸿蒙生态取得了如此快速的发展，但鸿蒙原生应用开发尚未能迎来大规模的推广。与此同时，在海外市场上，手机厂商依然需要谷歌的生态，需要谷歌的GMS服务支撑上层应用，而截至目前，华为海外手机暂无使用鸿蒙系统的计划。</p><p>如何在短时间内让更多头部移动互联网应用开发鸿蒙原生应用？如何培养更多的开发人才？如何在海外市场基于鸿蒙打造一套独立的软件体系？显然，鸿蒙原生应用开发还有很长的路要走。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/gnQiIOQblUewl9GLmuGYFQ" rel="noopener noreferrer nofollow" target="_blank">“每经头条”（ID:nbdtoutiao）</a>，作者：王晶，编辑：程鹏&nbsp;魏官红&nbsp;易启江，校对：段炼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2552032780999040</id>
            <title>谁躲在英伟达背后发大财？</title>
            <link>https://www.36kr.com/p/2552032780999040</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2552032780999040</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:53:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型革命, 英伟达, 垄断, AMD, 博通
<br>
<br>
总结: 英伟达在大模型革命中垄断了市场，但AMD和博通成为了挑战者。尽管AMD推出了新一代AI芯片，但其收入仍远远不及英伟达。而博通作为通信巨头，凭借其通信技术和市场份额，成为了谷歌等科技巨头的合作伙伴，成功打破了英伟达的垄断地位。 </div>
                        <hr>
                    
                    <p>大模型革命爆发后，英伟达的GPU一跃成为比黄金还珍贵的资源。 台积电的产线全速运转，订单交付依旧遥遥无期。 科技公司们干着急的同时，开始思考起一个问题：</p><p><strong>谁能提供替代品，打破英伟达的垄断？</strong></p><p>最受期待的是英伟达的老对手AMD。昨天凌晨，AMD推出了新一代AI芯片MI300X，并拉来了微软、Meta等科技公司高管站台，正式向“垄断者”英伟达发起冲锋。</p><p>然而，据AMD自己的估算，2024年公司的AI芯片收入大约是20亿美金——还不到英伟达三季度数据中心收入的1/7[1]。这么一对比，AMD显然更适合坐小孩儿那桌。</p><p><strong>事实上，如果按照收入计算，AMD甚至不是全球第二大AI芯片公司，这个称号其实属于博通。</strong></p><p>博通是全球最大的通信公司之一。研究机构Semianalysis的预估，AI芯片会在2024年给博通带来80-90亿美金的收入，几乎是AMD的4倍有余[2]。过去一年，博通的市值因AI芯片节节攀升，令同为通信巨头的高通羡慕不已。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_f0cfa526e84048448ae9009383976f82@1743780481_oswg134673oswg1080oswg1045_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>估计黄仁勋也没想到，前有产能问题后有出口禁令，自己忙前忙后还得挨骂，你小子居然躲在后面闷声发大财。</p><p>在英伟达的芯片霸权之下，博通为什么成了大赢家？</p><h2><strong>1+1＜2</strong></h2><p>博通的故事，要从谷歌讲起。</p><p>2016年，谷歌DeepMind团队带着AlphaGo惊艳亮相，以4-1战胜韩国围棋国手李世石，又在第二年击败了柯洁。伴随着AlphaGo的出圈，幕后功臣TPU也走到台前。</p><p>TPU是谷歌自研的AI芯片，用于取代英伟达的GPU。当时，英伟达的GPU主要服务于游戏玩家，在AI训练时图形单元集体摸鱼，存在明显的性能浪费。</p><p>因此，谷歌重新设计了芯片架构，并找到了一个关键的合作方——博通。谷歌设计的芯片蓝图，都由博通进行物理实现。</p><p>物理实现是芯片设计的后半程，是将逻辑电路转换为有物理连接的电路图的过程。博通绘制好物理版图后，再送去台积电流片，流片成功后的芯片正式进入制造环节，整个过程也都由博通和台积电进行反馈和调整。</p><p>简单来说，博通算是谷歌自研TPU时找的外包商。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ca75da9eadad4f4faaf229f8428acc5f@1743780481_oswg298757oswg512oswg271_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>装载了TPU的数据中心</p><p>谷歌之所以找博通合作，不仅是看中了博通的芯片设计能力，更因为它能解决一个关键问题：芯片之间的通信问题。</p><p>众所周知，算力不足是制约人工智能行业前进最重要的因素，这背后其实是通信的锅。</p><p>通常情况下，AI芯片中的计算单元其实已经完成了计算，但受制于通信效率，只能传输那么多算力。也就是两块芯片合作工作，性能并不是简单的1+1=2。</p><p>换个简单易懂的说法，AI芯片相当于一家做外卖的商铺，它一小时能做100单的外卖，但同一时间段的外卖骑手最多只能送50单。</p><p>所以美国在第一轮芯片制裁时，选择一刀砍在芯片通信速率上，显然是知道七寸在哪儿。</p><p>两个芯片之间的通信有损耗可能不是大问题，但数据中心内动辄成百上千个芯片共同运作，由此带来的性能损耗就足够让资本家肉疼了。考虑到AI训练对大规模并行计算的苛刻需求，怎么让1+1尽可能等于2，成了迫在眉睫的问题。</p><p><strong>博通作为通信巨头，恰巧拥有能让1+1尽可能接近于2的工具，最关键的是一个叫做SerDes（串行器/解串器）的通信技术。</strong></p><p>SerDes接口通过在传输之前将低速并行数据转换为高速串行数据，然后在接收端转换回并行数据，目的在于允许数据从一个TPU高速移动到另一个TPU，提升信号传输效率。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_1d7d1cc5e84041f48f13300d3e4eb197@1743780481_oswg76142oswg1080oswg822_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在该领域，博通是无可争议的垄断巨头。在全球50GB/S的SerDes市场中，博通占据了76%的市场份额[4]。</p><p>有了博通的加持，谷歌自研芯片的项目进展出人意料地顺利。TPU从设计开始，仅用15个月时间就部署进了自家数据中心。</p><p>经过测试，初代TPU的性能和功耗都大大胜过了英伟达同期的GPU。随着大模型战争拉开序幕，谷歌大举增加了TPU订单，使得博通一跃成为仅次于英伟达的AI芯片厂商。</p><p>谷歌吃完自研AI芯片的螃蟹，Meta、亚马逊、特斯拉这些不想交英伟达税的科技巨头，自然是拿起谷歌的作业就抄，也就无一幸免地复刻了谷歌的关键步骤：与博通合作。</p><p>也许有人会问：这么关键的技术，怎么就落到博通手里了？</p><p>答案可能有些出人意料：不能说是天上掉馅饼，但也差不多。</p><h2><strong>买来的护城河</strong></h2><p>2021年，有着美国芯片界奥斯卡之称的DesignCon，将“年度工程师奖”的殊荣颁给了一位华人女性：Cathy Liu。</p><p>她毕业于清华大学，2002年开始研究SerDes相关技术，在美国拥有20多项专利。如今，她领导着博通的SerDes团队，担任首席架构师。</p><p>博通能拿下半个硅谷的定制芯片订单，可以说与Cathy Liu的个人奋斗息息相关。</p><p>奖项颁布第二天，这名芯片设计师的职业经历就在各大媒体间流传，人们很快发现了一个有趣的事情：<strong>过去20多年，刘女士从未主动请辞，简历上却有4个老东家。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_d5e26420a1624ec99d045cc0e313f068@1743780481_oswg245772oswg624oswg380_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在美国完成博士学业后，Cathy Liu于2002年在一家名为DataPath Systems的公司，开启职业生涯。然而不到一年，DataPath就芯片公司LSI所收购。</p><p>几年后，LSI又从“猎手”变成了“猎物”，被安华高（Avago）所收购。后来，安华高又收购了博通，顺便把自己的名字也改成了博通。而Cathy Liu则伴随几次收购，历经辗转最终成为博通的一员[6]。</p><p>在这期间，她本人的工作重心倒是没什么变化，一直专注于SerDes技术的解决方案，很可能办公室都没搬过，就莫名其妙换了四次东家。</p><p>Cathy Liu的职业经历，其实是通信行业竞争格局的一个缩影。</p><p>博通所处的通信行业，本质是解决信息传输的问题。为了让信息能在不同的设备、地区之间畅通无阻，就需要一套全世界都认可的标准，就像人与人沟通的最基本条件是语言通用。</p><p>然而，最高效的标准通常由技术先发者制定，并且早早申请专利构建护城河。先发者可以率先打造一座距离最短的桥梁，后来者再想入场，只能想方设法绕路。</p><p>通信技术处处涉及协议、标准、接口，追赶一项通信技术往往会在前人的专利墙上折戟。</p><p>通信公司想要进入对方的专利领域，其中一个常用的方法是“交叉授权”。今年9月，华为和小米就刚结束一场纠缠半年的专利战，双方达成包括5G在内的通信技术的交叉许可协议。</p><p><strong>但这通常发生在两个互相忌惮的巨头之间。当双方力量悬殊时，行业内更为简单粗暴的解决方案是：收购。</strong></p><p>博通的前身安华高，本身仅约5000件专利与申请案，但经过针对LSI、PLX、Emulex、CyOptics以及英飞凌光学部门的一系列收购，专利总数增长至2.3万件。</p><p>而最后收购的原博通公司，专利高达2.7万件。这也是为什么安华高以小吞大原博通后，直接将自己改名为博通公司[5]。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b18f7b8f14524709be83c00af1472d9e@1743780481_oswg186773oswg1080oswg1556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>高通在基带芯片上把苹果的脖子卡的死死的，也是因为高通的老本行其实是通信。<strong>相比芯片公司在晶体管的缝隙里挑战物理学极限的浪漫，通信公司的商业模式大多朴实无华：收专利费。</strong></p><p>不仅是SerDes这项技术，连博通向谷歌提供的芯片定制外包服务，也是来源于LSI。顺带一提，黄仁勋在创办英伟达之前，曾在LSI工作过；昔日东家今日对手，缘分有时就是这么奇妙。</p><p>过去数十年，这种“大鱼吃小鱼、小鱼吃虾米”式吞并，曾反复在通信行业上演。目前仅剩的通信企业，大多都是巨无霸，布满了通信技术的各个节点。</p><p>博通在AI芯片的胜利很难说是高瞻远瞩，更像是行业竞争与自身业务扩张需求，推动着它四处“吃小鱼”，而那枚定制AI芯片的“小鱼”刚好成了博通的盘中餐。</p><p>老黄可以说自己高瞻远瞩地在2006年推出了CUDA，你说博通早二十年就预见了人工智能的浪潮，大概率是没人信的。</p><p>当科技公司们风驰电掣地驶进人工智能的高速公路，都被博通早早修好的收费站拦了下来。</p><h2><strong>又一条恶龙</strong></h2><p>谷歌在TPU项目初期把订单交给博通，其实还有两个原因：</p><p>一方面，谷歌是家互联网公司，芯片都没怎么做过，在封装、内存、连接性和光学等领域更是文盲水平，很难自力更生。另一方面，谷歌当时对TPU的需求量并不大，因此外包给博通是最为省力且经济的选择。</p><p>但当谷歌需要大规模量产TPU时，矛盾就出现了。</p><p>众所周知，谷歌、亚马逊等公司选择自研芯片，是为了降低成本，避开“英伟达税”。如果选择自研芯片，定制化程度更高不说，还可以省去大量数据中心成本。</p><p>但结果是躲得过英伟达，躲不过博通。</p><p>据The Information爆料，博通从TPU订单中获得了70%的利润率；虽然没“英伟达税”那么夸张，但也不是个小数字。</p><p>更何况，手握大量专利的博通在合作中格外强势。2021年，博通就曾趁着全球缺芯潮的间隙，张口就告诉谷歌要涨价30%，没有回旋余地。双方因此僵持数月，最终还是谷歌认了怂。</p><p>早年，亚马逊在购买博通的网络芯片时，也曾对博通的“霸总行径”苦不堪言：</p><p>CEO陈福阳（Hock Tan）经常在谈判时即兴涨价，并要求签署排他协议。如果亚马逊提出抗议，博通还会大幅延长交货时间作为回击[8]。</p><p>很显然，“霸道总裁”风格是刻在博通基因里的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_4af59db6a8084873afdefaebe43d5559@1743780481_oswg583039oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">博通CEO陈福阳</p><p>因此在2019年，谷歌默默在内部组建了一个新的团队，从英特尔和AMD疯狂挖人，“摆脱博通”的计划已成为公开的秘密。</p><p>这让博通陷入了与英伟达非常相似的难题：<strong>自己的客户，都会变成自己的敌人。</strong></p><p>博通虽强，但也并非唯一的选择。博通狮子大开口之后，谷歌的备胎——Marvell也走入大众的视野。在SerDes市场，Marvell的市场份额为23%，是行业内第二大玩家。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_bfcb3662a7644daca9d36e2826eec20c@1743780481_oswg525080oswg767oswg667_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，至少截至目前，“摆脱博通”都只是一个美好的愿景。</p><p>谷歌、亚马逊一面加速自研，一面和博通讨价还价，最终都选择硬着头皮买单。关于“谷歌要离开博通”的新闻发酵当天，谷歌就立马站出来辟谣，表示博通是“优秀的合作伙伴”。</p><p>金融分析师们也普遍站队博通。德意志银行在报告里写到：</p><p>“我们毫不怀疑博通每推出一代产品都会与其主要客户展开激烈的价格谈判，但博通成功地维持了这些合作关系，我们预计这一次最有可能的结果也是如此[9]。”</p><p><strong>华尔街日报的总结则更不客气：谷歌想抛弃博通，还远不到时候。</strong></p><p>因此，谷歌目前的目标听上去也很实际：预计2027年实现自力更生。但这话也没有说得太满：“如果博通降价，继续合作也是可以考虑的。”</p><p>但对博通来说，他们也许有着更深远的顾虑。</p><h2><strong>尾声</strong></h2><p>今年以来，英伟达的股价如同一辆两只踏板都是油门的超跑，一路暴涨约220%，冲到了全球市值第六。然而，有女版巴菲特之称的Cathie Wood却选择在此时清仓英伟达，惊得一众基金经理摸不着头脑。</p><p>木头姐清仓的理由其实很简单：英伟达的处境和顶峰时期的思科太过相似了。</p><p>思科是一家售卖网络硬件设备的通信公司，曾经被视为“互联网淘金时代的卖铲人”，大受追捧。1994年到2000年期间，思科股价上涨了55倍，营收上涨10倍。</p><p>但随着全球互联网基础设施搭建完成，思科的“铲子”渐渐卖不动了。此后20年，反倒是谷歌、亚马逊、Facebook这样的软件公司，成功挖到“金矿”并一跃成为全球最有价值的公司。</p><p>历史上，卖铲子的公司在一飞冲天之后，往往都有着相同的宿命：<strong>产品饱和乃至过剩-技术和生产能力开始转移-最终重新沉寂。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b3edddb238a5450d9b7d51018d7e7b44@1743780481_oswg184313oswg1080oswg762_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当人工智能的基础设施铺设完毕，新的芯片可以卖给谁？</p><p>对英伟达来说，这番“灵魂拷问”其实并不完全适用，因为它还有CUDA搭建起来的软件护城河，还有多元化的产品组合。</p><p>相比之下，博通才是更像思科的那一个。</p><h3><strong>参考资料</strong></h3><p>[1]AMD forecasts $2 billion sales of AI chips, helping shares rebound，Reuters</p><p>[2]Broadcom’s Google TPU Revenue Explosion, Networking Boom, VMWare Integration，semi analysis</p><p>[3]To Reduce AI Costs, Google Wants to Ditch Broadcom as Its TPU Server Chip Supplier，The Information</p><p>[4]Marvell收购的Innovium，是唯一能抢下博通份额的网络芯片厂商，EETimes</p><p>[5]Avago＋Broadcom＝专利新强权，中国电子报</p><p>[6]Broadcom’s Cathy Liu Wins DesignCon 2021’s Engineer of the Year Award，all about circuits</p><p>[7]Nvidia Makes Nearly 1,000% Profit on H100 GPUs: Report，Toms Hardware</p><p>[8]Amazon Steps Up Silicon Ambitions With New Networking Chip，The Information</p><p>[9]博通的AI业务前路崎岖，但不会轻易流失，华尔街日报</p><p>[10]Cathie Wood：我为何抛弃了英伟达，新硅NewGeek</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/naYAfoQ5EPs6X1_amSxK9w" rel="noopener noreferrer nofollow" target="_blank">“远川科技评论”（ID:kechuangych）</a>，作者：叶子凌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551993421633926</id>
            <title>谷歌急推大模型，夺回交椅的第一步</title>
            <link>https://www.36kr.com/p/2551993421633926</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551993421633926</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:51:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, Gemini, GPT-4, AI领域
<br>
<br>
总结: 谷歌发布了多模态大模型Gemini，包含三个版本，Nano、Pro和Ultra。Gemini在多项测试中领先于GPT-4，这是谷歌为了应对OpenAI和微软在AI领域的竞争而采取的行动。谷歌希望通过Gemini改变大模型行业格局，利用其强大的基础设施和YouTube的数据资源来打造更好的多模态大模型。谷歌的股价也因此上涨，市值增加。然而，谷歌仍面临着其他科技公司无法比拟的关注度和监管压力。 </div>
                        <hr>
                    
                    <p>12月6日，外界期待已久的谷歌多模态大模型Gemini （双子座） 发布，包含三个版本，Nano、Pro和Ultra，Pro对标GPT-3.5，Ultra对标OpenAI在今年3月发布的GPT-4。发布会上，谷歌CEO （首席执行官） 桑达尔·皮查伊 （Sundar Pichai） 说，Gemini最先进的版本，Ultra在多项测试中领先GPT-4。</p><p>目前上线的只有Nano版本，Nano版本专门用于移动设备，将集成到谷歌最新的手机中，Pro预计在下周上线，Ultra至少要到明年上线，谷歌称这是因为还需要更全面的安全测试。</p><p>根据谷歌官网发布的信息，Gemini和GPT-4的对比并非同类比较。以“通用性”为例，Gemini得分90%，GPT-4是86.4%，但Gemini的评估方式是谷歌自己研发的，GPT-4是根据行业标准评估的。</p><p>谷歌的新品发布时间大多集中在每年的5月到6月，过去几乎没有在年底的时间段发布过重要产品。在这个节点发布Gemini是谷歌的一次破例，据美国媒体报道，谷歌的管理层担心OpenAI、ChatGPT、微软的Copilot正在成为AI领域的代表，谷歌不能再等下去了。</p><p>OpenAI之前，谷歌是全球AI领域公认的领导者。但现在这个地位正在动摇。今年3月，谷歌推出AI聊天机器人Bard，以应对ChatGPT的竞争，但用户体量一直没能赶上。第三方分析公司Similarweb数据显示，今年8月，Bard的访问量1.83亿次，是ChatGPT访问量的13%。</p><p>在AI驱动的云计算领域，谷歌和微软的差距也在拉大。今年三季度，微软云服务营收增速29%，高于上个季度的26%；谷歌云服务营收增长25%，低于上个季度的28%。</p><p>但谷歌也不是说没有胜算。今年，在中国AI领域频繁被提及的一个问题是，什么时候能有中国的OpenAI和ChatGPT？类似的问题同样出现在美国—什么时候有一家公司能超过OpenAI？多位AI业内人士告诉《财经十一人》，谷歌有希望做出比GPT-4更好的大模型，更好的大模型一定是多模态的，谷歌除了基础设施能力强大，还有YouTube的数据，在视频领域的资源更好。</p><p>谷歌演示Gemini的视频中，也频繁使用图像和视频，展现强大的多模态能力。</p><p>发布会后，谷歌的股价当天上涨5.3%，市值增加860亿美元，一天就涨出一家OpenAI （最新估值约800亿美元） 。而在谷歌今年3月发布Bard时，股价当天下跌7.4%。</p><p>今年截至目前，谷歌股价涨幅约54%，微软涨幅56%。微软最新市值2.7万亿美元，谷歌最新市值1.7万亿美元。</p><h2><strong>从谨慎到破例</strong></h2><p>一位熟悉谷歌的AI从业人员告诉《财经十一人》，过去几年，谷歌在AI领域一直相对谨慎，虽然很早就开始了大模型的研发，但并未投入过多资源。</p><p>谷歌2018年就发布了大模型Bert，同样是基于Transformer，但和GPT是不同的路径。Bert更像是在过去谷歌AI能力基础上的优化，是一个有几亿参数量的基础模型，在用AI执行具体任务时，只要基于具体场景做微调训练即可，不用再从头做一个模型了。这有点像今天不少中国公司提出的垂直大模型，成本更低。</p><p>GPT的参数量超过千亿，成本高得多，但在通用能力上，直接表现出“降维打击”效果。</p><p>2018年，OpenAI推出了GPT-1 （参数量约1.1亿） ，在当时不少AI领域的竞赛中，Bert的表现都更好。谷歌证明了当模型参数变大，模型效果更好。但这都还停在“量变”阶段，一位AI从业人员告诉《财经十一人》，参数量从百万级到亿级，已经是很大的投入了，当时没人能证明，当参数量从亿级增加到千亿级时，会发生“质变”。</p><p>由于谷歌在AI领域的领先地位以及Bert的表现，2018年后不少科技公司都跟随Bert的路径研发自己的大模型，直到OpenAI推出GPT，且短时间内持续更新迭代。一位关注AI领域的投资人说，OpenAI给了所有科技公司和投资人“当头一棒”。</p><p>在Bert之后，谷歌的两名研究员研发出了AI聊天工具Bard。他们试图说服谷歌的高管们对外开放Bard并整合到谷歌助理中，且在发布会上公开演示。但并未成功。谷歌的高管们认为，这不符合谷歌对于AI安全和AI公平的标准。这两名研究员2021年从谷歌辞职创业。</p><p>当时，谷歌发言人回应称，研究员的成果是有趣的，但有趣的产品和可以让用户使用的产品之间存在巨大差距，“在对外发布AI技术方面，谷歌必须比初创公司考虑得更周全。”</p><p>这并非证明谷歌在AI领域的能力不足，而是在突破性创新面前，初创公司通常会更有魄力，也更能承担失败的后果。OpenAI的早期团队中，有不少核心人员都来自谷歌。</p><p>为了应对竞争，谷歌走出谨慎。今年4月，谷歌合并了两个不同的大型AI团队，分别是2011年创建的Google Brain和2014年谷歌收购的独立团队DeepMind。合并后的团队是Google Deepmind，负责Gemini大模型的开发。</p><p>这两个团队在过去几乎是没有合作的，Deepmind总部位于英国伦敦，主要做学术方面的研究，谷歌会使用其开发的软件来提升数据中心的运行效率。Google Brain则是用AI技术提升谷歌在搜索、广告等业务的能力。过去，两个团队使用完全独立的代码库，且都研发了自己的大模型，在谷歌的算力资源上存在竞争。</p><p>除了合并团队，谷歌还大幅提升了整体工作效率。据美国媒体报道，Bard团队的员工提到，过去三个月才能完成的工作，现在一周就要完成，晚上和周末也要加班。有员工曾经在内部会议上提到，工作和生活已经无法平衡，得到的回应是，这样的员工可能不适合谷歌的大模型团队。</p><p>过去10年，谷歌都是AI领域的领导者。2011年，谷歌开始研发机器学习系统，在此基础上2015年推出Tensorflow，成为当时使用最广泛的深度学习框架。2014年，谷歌收购DeepMind，这家公司的使命是推动通用人工智能 （AGI） 的发展，2016年DeepMind推出AlphaGo，打败了最顶级的人类围棋高手，让全世界第一次直观感受到AI的能力。</p><p>2016年，桑达尔宣布谷歌将成为一家人工智能优先（AI First）的公司，AI是谷歌最重要的方向。2017年，谷歌研发团队发表了论文《Attention is all you need》，提出了Transformer架构。这也是今天所有大模型的基础。</p><p>在算力层面，2015年，谷歌在数据中心中使用TPU （张量处理单元） ，2018年开放给第三方使用。TPU是谷歌为机器学习定制的专用芯片，特点是在不影响深度学习处理效果的基础上，功耗更低。</p><p>不少人评价谷歌在大模型领域是“起了大早、赶了晚集”，过去的优势也是谷歌的束缚，谷歌面临的是比其他所有科技公司都更高的关注度和更严格的监管。</p><h2><strong>谷歌能否改写大模型行业格局？</strong></h2><p>目前大模型领域呈现出“一超多强”的局面，OpenAI代表的是大模型领域的最强实力，几乎所有新推出大模型的厂商都会对比GPT-4，稍弱一些的会对比GPT-3.5。OpenAI模型的强大是基于巨额成本和持续的投入，在落到实际商业应用中时，会产生“杀鸡是否要用牛刀”的问题。</p><p>但谷歌这次推出的大模型目前看来并没有解决高成本的问题，谷歌并未公布训练Gemini耗费的算力，今年8月，芯片研究机构SemiAnalysis的两位分析师Dylan Patel和Daniel Nishball估计，Gemini消耗的算力可能已经超过GPT-4，下一次迭代的版本消耗的算力资源可能是GPT-4的五倍。</p><p>谷歌对于Gemini大模型的规划有几个方向，一是凭借其多模态能力，为Youtube的创作者们提供更好的视频创造工具。此外，在贡献谷歌主要营收的广告业务中，大模型可以为广告商提供工具，可以自动生成广告，内容包括文字、音频和视频。</p><p>此外，谷歌还会在智能手机中融入大模型能力。目前，谷歌手机的市场占有率并不高，根据Canalys的报告，2023年谷歌智能手机在北美的市场份额仅为4%。同期苹果为54%，三星24%。但在移动设备上融入大模型是一个相对确定的趋势，OpenAI也在积极布局这一领域。手机的计算速度远低于电脑，因此需要对大模型做压缩或是轻量化部署。在国内，华为、百度、腾讯的公司也都在做针对移动端的轻量级模型。</p><p>这些都是谷歌基于原有业务的优化，短时间内很难看出实际效果。</p><p>不过，谷歌再一次证明了自己在算力和AI技术上的强大实力。对于谷歌这样的巨头来说，他需要的不是在某一个细分方向和初创公司掰手腕，而是重新夺回领导者的位置。</p><p>谷歌和亚马逊扶持的初创公司Anthropic被称为OpenAI最大的竞争对手，最新估值约300亿美元。谷歌在今年2月投资了这家公司，回报是Antropic将采购更多谷歌的云计算服务。谷歌还在今年投资了聊天机器人初创企业Character.AI、生成式AI初创公司Runway、AI文生图公司Midjourney，投资回报均包括使用谷歌云和TPU进行大模型训练。</p><p>资本市场已经给了谷歌正面反馈，但投资人随时都有可能变脸。</p><p>摩根大通董事总经理Douglas Anmuth在给客户的报告中写道：华尔街对谷歌这次的发布会不太满意，也许是认为该产品还不太完整，但我们很高兴看到谷歌在这一重大技术方面取得的进展。</p><p>今年2月，桑达尔在一封给谷歌员工的电子邮件中说，谷歌部分最成功的产品并不是最先上市的，而是随着时间的推移赢得了用户的信任，“这是一段漫长的旅程，我们现在能做的是，专注于打造一个伟大的产品，并负责任地开发它。”</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI0MjU2NTA1Mg==&amp;mid=2247583171&amp;idx=3&amp;sn=903aab19323e61ffcec2afd40f3fbc67&amp;chksm=e979af10de0e2606217e3a5e9a9161b8e31e29ea6eafd454e520ce75faee162639c930fd2d0f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“财经十一人”（ID：caijingEleven）</a>，作者：刘以秦，编辑：谢丽容，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551962081187977</id>
            <title>谷歌和微软两位“印度老乡”CEO，正面硬刚</title>
            <link>https://www.36kr.com/p/2551962081187977</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551962081187977</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:49:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemini, AI大模型, 谷歌, 性能
<br>
<br>
总结: 谷歌发布了最新一代的AI大模型Gemini，被称为迄今为止最强大、最通用的模型，性能在多项基准测试中展现出了最先进的水平。Gemini已超过竞争对手OpenAI发布的GPT-4，成为可能是目前最先进的大模型。谷歌还发布了面向云端AI加速的芯片TPU v5p，加强了模型训练的速度和性能。谷歌的Gemini发布被视为对微软的一次“奇袭”，在大模型竞赛中，算力、应用深化和模型安全性等因素都被视为决胜的关键要素。 </div>
                        <hr>
                    
                    <p>12月6日夜间，谷歌发布了其最新一代的AI大模型Gemini。</p><p>谷歌的印度籍CEO Sundar Pichai亲自为这项发布站台，在公开信中将Gemini描述为：“我们迄今为止最强大、最通用的模型，它在许多领先的基准测试中都展现出了最先进的性能。”</p><p>此前在接受《麻省理工学院技术评论》杂志采访时，Pichai还讲道：“在57项测试中，Gemini的表现有89%与人类专家相当。这是第一个达到这一标准的模型。”</p><p>言外之意，Gemini已然超过了其最大竞争对手、OpenAI发布的GPT-4。而后者是在其“印度老乡”Satya Nadella掌舵的微软投资支持下研发出来的。</p><p>早在今年年初，为了应对ChatGPT的威胁，Pichai曾亲自为谷歌拉响了“红色警报”，宣布要与微软投资的OpenAI展开正面竞争。</p><p>一年时间过去，两位印度籍CEO，仍在争夺全球第一AI大模型的竞赛中打得火热。</p><h2><strong>可能是目前最先进的大模型</strong></h2><p>据谷歌官方信息，Gemini 1.0大模型针对不同尺寸进行了优化，提供三种版本，从大到小分别为Ultra、Pro和Nano。不过，谷歌并未公布各个型号模型的参数规模。</p><p>Gemini适用于执行多任务。即日起，谷歌此前发布的大模型Bard将使用Gemini Pro的微调版本来进行更高级的推理、规划和理解等。谷歌官方称“这是Bard自推出以来最大的升级”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_fe69e2cd35404b85abf9ce15f152b53c@1743780481_oswg66176oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Gemini Nano被称为“端侧任务最高效的模型”，Android开发者可以通过AICore来使用。据悉AICore是Android 14 中一项新的系统功能，将从Pixel 8 Pro设备开始支持。</p><p>Gemini中最大Size的Ultra仍在完成大规模信任和安全检查的过程中，尚未全面公开发布。在其完善过程中，Ultra将向部分客户、开发者、合作伙伴以及安全和责任专家，以供相应人员进行早期试验、提供反馈。</p><p>预计在明年初，Ultra模型将向开发者和企业客户提供服务。</p><p>而在性能方面，谷歌官方信息显示，从自然图像、音频和视频理解到数学推理，在被大型语言模型（LLM）研究和开发中广泛使用的32项学术基准中，Gemini Ultra的性能有30项都超过了目前最先进的水平。</p><p>Gemini Ultra的得分率为90.0%，是第一个在 MMLU（大规模多任务语言理解）测试中超过人类专家的模型，MMLU综合使用了数学、物理、历史、法律、医学和伦理等57个科目，用于测试世界知识和解决问题的能力。</p><h2><strong>全面宣战微软，谷歌能得偿所愿吗</strong></h2><p>早在今年5月份举办的谷歌网络开发者大会（I/O大会）上，谷歌就曾预告Gemini的相关信息。</p><p>彼时曾有消息人士透露，由于安全性审查、提升非英语任务性能等种种原因，Gemini或将于2024年正式亮相。</p><p>而本次Gemini“提前”发布，不仅是谷歌在秀自己的“技术肌肉”，在业界看来更是对微软的一次“奇袭”。</p><p>一方面，不同于ChatGPT、GPT-4模型率先发布文本功能再逐渐扩充多模态功能，Gemini被设计为原生多模态大模型，从一开始就支持多模态输入输出。Pichai对此讲道：“就像人一样，它不仅从文本中学习，还能通过视频、音频和代码进行学习。因此，这个模型天生就具备了更强大的能力。”</p><p>此外，Gemini的应用落地步伐也十分紧凑，除了集成到Bard大模型中，还将为开发者提供API（应用程序开发接口）服务。</p><p>相较之下，在今年11月OpenAI爆发高层内斗，被认为影响了GPT-4等产品的后续应用落地步伐。</p><p>据路透社获得的一份OpenAI公司的备忘录，OpenAI将此前承诺于年底推出的GPT Store功能，延期至2024年上线，原因是“由于一些意想不到的事情，团队非常忙碌无法按时交付”。</p><p>因此谷歌Gemini的发布，某种程度上也是为了抓住竞争对手调整好步伐前的关键窗口期。</p><p>此外，在发布多模态大模型Gemini的同时，谷歌还推出了全新的面向云端AI加速的芯片TPU v5p ，这也是谷歌迄今为止功能最强大且最具成本效益的TPU（张量计算单元）。在模型训练方面，TPU v5p在大语言模型训练速度上显示出了2.8倍的代际提升。</p><p>此前，微软也曾在其11月中旬举办的Ignite大会上发布了自研AI芯片Microsoft Azure Maia。</p><p>这从某种意义上说明，在大模型竞赛的“下半场”，伴随着市场进入洗牌期，除了模型性能本身，算力的充沛与否、应用深化的速度、模型安全性程度等等，都被视为决胜的关键要素。</p><p>在大模型的市场竞速赛中，玩家们的“内卷”程度不断加重，不容任何一个环节的布局有所缺失。</p><p>距离ChatGPT正式发布，已经过去了一年的时间。或许到现在，市场的“红色警报”才刚刚正式拉响。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/nHE5vIhghon9HnV6_1Qknw" rel="noopener noreferrer nofollow" target="_blank">“市界”（ID:ishijie2018）</a>，作者：董温淑，编辑：董雨晴，运营：刘珊 ，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551970892634245</id>
            <title>5G商用第5年：应用落地优势与挑战并存</title>
            <link>https://www.36kr.com/p/2551970892634245</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551970892634245</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:48:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 5G商用, 5G规模化应用, 5G行业应用, 跨界融合
<br>
<br>
总结: 今年是5G商用的第五年，也是《5G应用扬帆行动计划（2021-2023年）》的收官之年。在政产学研用的推动下，我国迎来了5G规模化应用发展的关键期和新一轮的技术创新期。据数据显示，我国5G基站总数达到321.5万个，用户规模也在不断增长。除了在消费领域得到广泛应用外，5G也深入到行业应用中，已融入67个国民经济大类，应用案例数超过9.4万个。可以看出，跨界融合已成为5G发展的主旋律。然而，当前5G发展还存在一些问题，如高确定性网络能力不足、高水平算力不足以及面对行业碎片化需求等。为了进一步释放5G的新价值，通信业也在加快5G-A/6G技术的演进，努力构筑新一轮科技革命和产业变革的先发技术优势。 </div>
                        <hr>
                    
                    <p>今年已进入5G商用第五年，也是《5G应用扬帆行动计划（2021-2023年）》的收官之年。在这几年政产学研用的推动下，我国迎来5G规模化应用发展的关键期和新一轮的技术创新期。</p><p>据工信部数据显示，截至10月末，我国5G基站总数达321.5万个，占移动基站总数的28.1%。在用户规模上，三家基础电信企业的移动电话用户总数达17.26亿户，比上年末净增4214万户。其中，5G移动电话用户达7.54亿户，比上年末净增19360万户；占移动电话用户的43.7%，占比较上年末提高10.4个百分点。</p><p>除此之外，5G也深入到行业应用中。在国新办举行的前三季度工业和信息化发展情况新闻发布会上，工业和信息化部新闻发言人、总工程师赵志国表示，截至9月底，5G行业应用已融入67个国民经济大类，应用案例数超9.4万个。5G在工业、矿业、电力、港口等垂直行业应用广泛复制。同时，基于5G网络的超高清视频、AR/VR等新应用进一步融入生产生活中。</p><p>可见“跨界融合”已成为5G发展的主旋律。</p><p>但是当前5G与各行业究竟擦出了怎样的火花？如何进一步释放5G新价值？成为了今年世界5G大会关注的焦点。</p><h2><strong>01.5G融合还存在“荆棘”</strong></h2><p>运营商作为推动中国5G建设的关键力量，将5G作为重要工作进行部署。</p><p>中国移动执行董事、党组副书记李丕征表示，5G商用5年以来，中国移动在5G规模、5G技术和5G应用实现领先。在5G应用中，B2C消费领域，中国移动打造了5G新通话，视频彩铃，云游戏等新体验，新玩法；B2B的行业领域今年重磅发布5G极致专网3.0 Ultra建强双城办公，跨域互联，全域精品等多场景的能力，已累计签约3万个5G商用案例，实现多行业规模复制，其中国内集装箱吞吐箱TOP10家港口全面实现5G落地，5G的智慧工厂项目超过了4000个。</p><p>中国联通则聚合融通5G+XR、5G+北斗等数据技术，持续升级联通特色的5G产品体系。在传统产业转型上，中国联通携手郑州海尔打造5G热水器的智能制造基地，实现AI智能智慧天眼，机器视觉检测；携手福建金源纺织打造的5G智慧工厂，实现智能的检测和联动生产；携手中国教科网在华南理工大学，北京大学等主干节点上落地5G教育随心专网，实现校园师生通过统一认证秒级开通等。在新兴产业上，中国联通面向信息消费领域，打造XR通话、5G裸眼3D；面向智慧海洋落地广东阳江5G数字渔船，山东潍坊5G海洋风电等示范标杆项目；面向智慧车联，落地商用的边缘算网技术，打造三亚崖州湾科技城和四川三江新区的智能网联项目等。</p><p>中国工程院院士、中国石油集团国家高端智库首席专家、中国石油科学技术协会主席孙龙德则以长庆石化5G炼厂为例，直观的体现出5G网络带来的便捷。5G+炼厂实现431台设备状态在线监测、故障预警、智能诊断等创景需求，故障预警准确率达95%，检维修成本下降10%左右。</p><p>但是，当前5G发展依然存在不足。</p><p>中兴通讯董事长李自学表示，2022年开始，5G进入了走深向实助力行业升级阶段。在这一阶段，仍存在高确定性网络能力的问题、高水平算力不足，以及面对行业碎片化需求，要解决高效率规模复制的问题。</p><p>对此，孙龙德也指出，5G在中石油发展中，需解决三大卡点问题。一是频谱资源，在偏远无人区缺少基础电信企业5G基站覆盖，企业自建5G专网缺少专用频段资源；二是标准与技术，5G组网安全性评估、5G与运营商攻坚方式数据安全性保护、5G网络与网络安全等级保护要求缺少标准化指导；三是5G的跨界融合性，运营商5G虚拟专网管控能力开放有限、5G模组、终端以及投入的AAU与频段关联性较高。</p><p>“按目前的进展，在5G商用半程到来之前5G用户数将过半。5G能力足够应对现阶段市场的大众应用，但新兴高端应用正在兴起，5G还不适应。”中国工程院院士邬贺铨在开幕式上坦言称。</p><h2><strong>02.加快5G-A/6G技术演进</strong></h2><p>针对5G市场应用出现的问题，通信业也迎来新一轮的无线技术创新——5G Advanced（5G增强型技术，也被称为5G-A及5.5G）。</p><p>邬贺铨表示，当前全球主要国家、国际组织纷纷加强5G Advanced的演进与6G的研究，强化技术布局和资源投入，努力构筑新一轮科技革命和产业变革的先发技术优势，夯实提升国家综合竞争力的基础。</p><p>中国电信首席专家、中国电信研究院专家委员会主任、贝尔实验室院士、IEEE Fellow毕奇在平行论坛Tech Talk 2023创新技术论坛上称：“随着5G-A技术的引入，5G扩展为能力六边形。”</p><p>5G-A作为5G迈向6G的中间过程，也是争议不断。</p><p>“运营商可能会担心历史投资保护与资产收益的问题，前一轮的投资回报还没有足够，新投资是不是值得。”邬贺铨指出，如果把5G-A当作是全面升级并且取代5G，这确实会带来新的投资，运营商对此谨慎这是完全正常的。同时，在他看来，5G-A只是5G在功能上和覆盖上的升级，5G-A并不取代5G，5G-A负责支持的是有比较高要求的应用场景，或者说只需要在热点部署，当然还需要在运营模式上有一些创新。</p><p>对于移动通信产业而言，移动通信每十年一代，6G的到来也并非遥不可及。未来的6G不仅会比5G更快、更可靠，还需要推动移动通信与人工智能、感知、计算等跨领域融合发展。</p><p>6G推进组组长王志勤表示：“面向6G来看，它的商用时间基本上是在2030年左右，它的标准化制定时间会在2025年。未来，6G服务的对象更多的是社会管理、社会治理层面，更多的是偏向智能体。”</p><p>面对通信技术的演进，不仅需要仰望6G技术，更要深耕5G技术布局，让5G在千行百业结出更好的“果实”。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkwMDUwNzEwNA==&amp;mid=2247596463&amp;idx=2&amp;sn=bae2decfea4687a44d9835e4854f2c7f&amp;chksm=c041cd20f7364436317f57c4a7387c4236eb30bed5754c241e2fefb2649fc743f2f218ddcd50&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“DoNews”（ID：ilovedonews）</a>，作者：田小梦，编辑：李信马，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551963406096774</id>
            <title>RAG+GPT-4 Turbo让模型性能飙升，更长上下文不是终局，「大海捞针」实验成本仅4%</title>
            <link>https://www.36kr.com/p/2551963406096774</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551963406096774</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:48:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: RAG, GPT-4, 大模型能力, 性能
<br>
<br>
总结: RAG和GPT-4是大模型能力飙升的未来，通过使用LLM的下一阶段，可以实现卓越的性能。在产品中使用LLM时，重点是让它们生成的响应更加超前高速化，即根据不同的使用情况生成不同的响应。这通常通过上下文窗口填充、RAG和微调等技术来实现。实验结果表明，现代的RAG模型具有非常好的准确性，并且成本相对较低。此外，RAG通常用于离线数据的检索，其延迟时间也相对较低。 </div>
                        <hr>
                    
                    <blockquote><p>RAG或许就是大模型能力飙升下一个未来。</p></blockquote><p>RAG+GPT-4，4%的成本，便可拥有卓越的性能。</p><p>这是最新的「大海捞针」实验得出的结论。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5464f98d73de467caa1872d52bff9dd5@1743780481_oswg88365oswg1080oswg276_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在产品中使用LLM的下一阶段，重点是让它们生成的响应/回复更加「超前高速化」(hyper-specific)。</p><p>也就是LLM需要按照不同的使用情况，针对数据集、用户、使用案例，甚至包括针对特定调用，生成完全不同的响应。</p><p>这通常是通过 3 种基本技术中的一种来实现的：</p><p>1. 上下文窗口填充（Context-window stuffing）</p><p>2. RAG（检索增强生成）</p><p>3. 微调</p><p>正如实践者所知，与炒作相反（「在您的数据上训练的 GPT......！」），主要是使用上下文窗口填充和 RAG（而不是微调）来专门化 LLM 的响应。</p><p>作者Atai Barkai最近在CopilotKit中添加了一个新的面向文档的react hook，专门用于容纳（可能是长格式的）文档。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_0ac523dea6124094b116fede0530a88a@1743780481_oswg322987oswg1080oswg314_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了帮助选择合理的默认值（受到Greg Kamradt的启发），BarkaiRAG 和 GPT-4-Turbo 的上下文窗口进行了一次「大海捞针」式的压力测试，涉及3个关键指标：（1） 准确性；（2） 成本；（3） 延迟。</p><p>他还对2个不同的RAG管道进行了基准测试：</p><p>- Llama-Index最流行的开源RAG框架（默认设置）。</p><p>- OpenAI的新助手API的检索工具——在后台使用 RAG（已证明可使用Qdrant向量数据库）。</p><h2><strong>实验结果</strong></h2><p>先来看下结果，再来讲方法论。</p><p>长话短说，现代的检索增强型生成（RAG）模型的效果非常好。</p><p>根据你的使用情况，你可能永远都不想把上下文窗口塞得太满（至少在处理文本时）。</p><h3><strong>准确性</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e2196f1a8f444191976b179aec72fe6b@1743780481_oswg143756oswg1080oswg283_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如上图所示，assistant API （GPT-4+RAG）的性能近乎完美。</p><p>注意：这一性能仅适用于搜索式查询。大型上下文窗口还有其他用例（如少样本学习）。</p><h3><strong>成本</strong></h3><p>上下文窗口填充仅产生每个token的成本，而RAG产生每个token的成本，以及额外的固定LLM推理成本。</p><p>以下是每个token的成本：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e7e443e455b242249c5a8ebc932dc4fb@1743780481_oswg152272oswg1080oswg663_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果你没有注意到，这个差值跨越了4个数量级（对数刻度）。</p><p>但同样，RAG也会产生固定的LLM智能体循环成本。</p><p>对于128k上下文窗口，平均总成本约为0.0004 美元/1k token，或GPT-4-Turbo成本的4%。</p><p>Llama Index的成本略低，但与之相当，为0.00028 美元/1k token（由于智能体循环不那么复杂）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_9ec5363529364d0d8258dc8dbf6147f5@1743780481_oswg132001oswg1080oswg644_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>延迟</strong></h3><p>RAG通常是针对离线数据进行的，检索延迟以毫秒为单位，端到端延迟主要由LLM调用决定。</p><p>但作者认为，比较一下从文件上传到返回结果的端到端延迟时间，看看RAG是否能与「在线」（而非离线）数据竞争，会很有意思。</p><p>以下是对128k token文档进行查询的端到端延迟：</p><p>- LlamaIndex RAG最低，平均为12.9秒。</p><p>- 其次是GPT4-Turbo，平均用时21.6秒，但差距很大，为7-36秒。</p><p>- assistant API RAG检索时间为24.8秒。</p><p>此外，大多数应用程序都能从乐观的文档上传中获益，从而最大限度地减少感知延迟。由于RAG索引的成本很低，通常不会有太大损失。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_89c5c74a555f43898b24ea59a40e1253@1743780481_oswg182511oswg1080oswg705_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>「大海捞针」实验</strong></h2><p>作者Atai Barkai以Greg Kamradt的出色工作为基础，他最近进行了GPT-4-Turbo和Claude 2.1的「大海捞针」（needle in a haystack）压力测试。</p><p>从本质上讲，我们给一个「大海」，并在其中的某个地方隐藏了一根「针」，然后询问AI系统关于针的情况。</p><p>作者会把这根「针」放在大海的不同位置，从最开始到结束的地方，每个位置间隔约10%。</p><p>在上下文窗口填充实验中，作者只是将「大海捞针」推到了LLM调用上下文窗口上。在RAG实验中，作者创建了一个文档并对其执行了RAG。</p><p>（正如格雷格的出色分析一样，「大海捞针」是Paul Graham的论文集，而「针」是一个不相关的事实。</p><h2><strong>进一步分析</strong></h2><h3><strong>准确性</strong></h3><p>GPT-4+RAG表现非常出色。</p><p>这并不完全令人惊讶。在LLM上下文窗口中放置不相关的信息不仅成本高昂，而且对性能有害。</p><p>更少的垃圾=更好的结果。</p><p>这些结果凸显了我们仍处于LLM革命的初期。广大社区仍在摸索将新的LLM构建模块组合在一起的最合理方法。</p><p>过去一年的上下文窗口大战完全有可能在平淡无奇中结束。</p><p>大家都明白，基于RAG的日益复杂的技术，而不是更大的上下文窗口，才是关键所在（至少对于文本而言）。</p><h3><strong>LlamaIndex</strong></h3><p>作者本以为随着上下文窗口的增加，RAG的性能会大致相同。</p><p>但事实并非如此，当上下文长度超过约100k时，性能明显下降。他的猜测是，超过一定的上下文大小后，「针」就不再被检索过程获取了。</p><p>不同的分块和检索配置可能会影响此结果。</p><p>总的来说，作者非常看好LlamaIndex和开源LLM技术。</p><p>很明显，RAG仍然处于唾手可得的领域，简化框架是关键。Llama-Index已经做好准备，可以继续整合新技术和最佳实践。</p><p>这张泄露的OpenAI开发者日幻灯片提供了一些灵感：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_24808993793047a98f494564071fad47@1743780481_oswg477429oswg1080oswg536_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>成本</strong></h3><p>RAG 成本分析有点微妙，因为它只是部分确定性的。RAG 的第一部分是检索，根据一些启发式（通常是矢量搜索）从更广泛的数据集中选择最「有前途」的文档块。</p><p>第二部分是生成增强，选择的块被输入到「标准」LLM调用中（并且随着通用性的增加，被输入到智能体LLM循环中）。</p><p>原则上，检索可以使用多种技术来实现，从关键字搜索到关系搜索，再到混合技术。</p><p>在实践中，大多数当代RAG方法主要使用矢量搜索，这会产生一次性、按token索引的成本。随着生态系统的成熟，混合技术的使用可能会越来越多。</p><h3><strong>每个token的成本</strong></h3><p>让我们首先看一下每个token的成本：</p><p>- GPT-4-Turbo 以 $0.01/1k token的价格。（与GPT-4和GPT-4-32k相比，价格分别降低了3倍和6倍） - OpenAI 的 ada v2 嵌入模型收费 0.0001 美元/1k token。这比GPT-4-Turbo便宜100倍。</p><p>- OpenAI 的助手 API 的检索功能价格更加昂贵。它以「无服务器」方式收费，0.20 美元/GB/助手/天。假设 1 个token ~ 5 个字节，即1×10^-6 美元/1k 个token/助手/天。</p><h3><strong>固定开销</strong></h3><p>开销部分很难计算（或者说不可能，在 OpenAI 的情况下），所以作者也只是凭经验测量它。</p><p>如结果部分所述，RAG还会产生固定开销，该开销源自LLM推理步骤。对于128k上下文，此固定成本为GPT-4上下文窗口的4%。</p><h3><strong>延迟</strong></h3><p>原则上，嵌入计算是高度可并行化的。因此，考虑到市场需求，未来的基础设施改进可能会将延迟降低到单个块嵌入的往返。</p><p>在这种情况下，可以看到即使是「在线」RAG管道延迟也会大大减少，以至于「在线」RAG延迟仅由LLM思维链循环的延迟主导。</p><h3>参考资料</h3><p>https://www.reddit.com/r/MachineLearning/comments/18bivxa/d_needle_in_a_haystack_experiment_assistants_api/</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/yOKPYpQ5XSXToVbGlOnnRA" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：桃子，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2550898385688961</id>
            <title>海外 New Things | Ketryx获1400万美元A轮融资，打造互联应用生命周期管理软件</title>
            <link>https://www.36kr.com/p/2550898385688961</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2550898385688961</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:34:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Ketryx, 生命科学行业, 互联应用生命周期管理软件, 融资
<br>
<br>
总结: Ketryx是一家位于美国马萨诸塞州波士顿的生命科学行业互联应用生命周期管理软件供应商，最近宣布获得了1400万美元的A轮融资。该公司致力于为生命科学行业提供互联应用生命周期管理软件，通过叠加产品开发工具并连接所有项目、风险、代码和测试，创建了一个实时、可追溯的单一解决方案。这使团队能够通过自动化文档缩短上市时间，并通过在连接的系统中执行SOP提高质量和合规性。 </div>
                        <hr>
                    
                    <p>文 | 李娜娜</p><p>Ketryx是一家位于美国马萨诸塞州波士顿的生命科学行业互联应用生命周期管理软件供应商。</p><p>12月5日，该公司宣布获得了1400万美元的A轮融资。本轮融资由Lightspeed Venture Partners领投，麻省理工学院的E14基金和Ubiquity Ventures等现有投资者也参与了本轮融资，使融资总额达到了1800万美元。Lightspeed Venture Partners合伙人Guru Chahal将加入该公司董事会。Ketryx打算利用此次融资资金加快其产品开发和商业扩张。</p><p>Ketryx致力于为生命科学行业提供互联应用生命周期管理软件，使构建FDA监管软件和基于人工智能的应用的公司能够通过基于云的现代工具加快开发，同时提高质量和合规性。它通过叠加产品开发工具并连接所有项目、风险、代码和测试，创建了一个实时、可追溯的单一解决方案。这使团队能够通过自动化文档缩短上市时间，并通过在连接的系统中执行SOP提高质量和合规性。</p><p>医疗保健行业正在接受软件及其改善患者治疗效果的承诺，包括人工智能/机器学习（AI/ML）的力量。因此，需要更频繁地进行软件更新以及软件复杂性逐渐增加。传统的手动软件质量保证方法已经无法满足现在的需求，而且容易出现导致人员伤亡的人为错误。解决方案是将自动化和质量流程执行整合到软件开发生命周期和质量流程中。这可确保团队遵循最佳实践，并主动授权他们在风险影响性能之前识别和降低风险。</p><p>Ketryx组建了一支由了解软件开发、法规和人工智能、移动互联网的专家组成的团队。团队成员包括来自美国食品和药物管理局（FDA）、世界上最大的人工智能知识引擎创建者 Wolfram Research的专业人士，以及安进公司（Amgen）的质量负责人。Ketryx围绕FDA法规和质量标准设计产品。其结果是专门打造了一个互联生命周期管理平台，该平台可将医疗软件开发和质量团队所需的许多手动任务和流程（如可追溯性）自动化并与之保持一致。</p><p>现在，客户可以将该行业传统的手工操作自动化，包括文档、流程执行和可追溯性。此外，该公司的开发团队还可以重新集中时间，使用现代DevTools和DevOps实践。Ketryx将开发工具叠加并转换为符合FDA标准的单一真实来源，用于整个产品生命周期，包括自动化文档。Ketryx正在帮助世界上一些顶级医疗设备制造商简化其规范的开发流程，以便更快地为互联医疗设备、给药系统、手术机器人、成像诊断以及数字疗法等规范的医疗应用提供更安全的软件。</p><p>编辑 | 海若镜</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551917299914885</id>
            <title>9大认知：一文看懂未来10亿人的AI伴侣要如何入局打造 | Boss宣讲会</title>
            <link>https://www.36kr.com/p/2551917299914885</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551917299914885</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:29:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, AIGC, 人才需求, 人工智能
<br>
<br>
总结: 今年，大模型产品开始正式向公众提供服务，标志着AIGC领域迈进了新的里程碑。随着大模型进入人们的生活，人们开始关注AIGC行业的发展和应用，对于适应AIGC行业的人才需求也越来越多。大模型是指神经元超过数十亿的人工神经网络，而AIGC的特征辨别包括通过AI生成的图片和诗歌等。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_2e872db6a6754955ab3e6df03ae1e548@5509299_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p>未来已来。</p><p>今年，首批大模型产品陆续通过《生成式人工智能服务管理暂行办法》备案，正式面向公众提供服务。百度文心一言、抖音云雀大模型、智谱 AI GLM 大模型等11家企业大模型纷纷入局，达成行业里程碑式的迈进。</p><p>当大模型开启步入人们生活的征途，AIGC领域势必成为新风口。这意味着在享受人工智能所带来的便捷生活的同时，人们的目光也将同步转向其进一步的发展与应用，AIGC行业产生了海量人才需求。</p><p>而如何使自己更加适配AIGC行业的人才需求？AIGC在未来的发展中到底需要具备哪些技能的人才？回归本源，大模型究竟是什么，又与AIGC有何勾连？</p><p>11月30日，我们邀请了<strong>西湖心辰创始人蓝振忠</strong>，在职场Bonus的线上求职VIP社群，以生动的方式，分享他对于大模型发展的见解洞察以及西湖大模型目前的发展状况与人才需求，并同VIP社群成员进行了深度的互动交流。</p><p>一起来看本期《Boss宣讲会》。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e69c5d8805a74172adbd60ab9673ec1f@5509299_oswg378038oswg900oswg1300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p>&nbsp;</p><blockquote><p>识别大模型 ╱ 一</p><p>关于大模型的九大认知 ╱ 二</p><p>西湖大模型 ╱ 三</p><p>群友 vs. CEO ╱ 四</p></blockquote><p>&nbsp;</p><h2><strong>识别大模型</strong></h2><p><strong>（一）经常被问到的问题</strong></p><p><strong>1. 个人侧</strong> ：大模型将如何改变我的工作和生活？会不会失业呀？</p><p><strong>2. 企业侧</strong> ：大模型如何提升公司的运营效率？&nbsp;</p><p><strong>3. 政府侧</strong> ：大模型如何提升政府效率？模型安全性如何保证？如何影响民生？会不会让很多人失业？&nbsp;</p><p><strong>4. 投资机构侧</strong> ：该如何就这次大模型/AI的机会进行投资，是基础设施公司、大模型公司还是应用公司?&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_9e7284300ad84bcaab00ace8e02c3409@5509299_oswg207726oswg1080oswg653_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p>&nbsp;</p><p><strong>（二）什么是大模型</strong></p><p><strong>人工智能史≈人工神经网络发展史</strong></p><p><strong>1. 人工智能训练目的：</strong> 模拟人脑（视觉能力、听觉能力、理解能力等）。</p><p><strong>2. 人工智能训练主要方法：</strong> 模拟人工神经元。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_0b7be76288a04f8faa4fa64c2472d290@5509299_oswg39216oswg1042oswg343_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p><strong>3. 大模型：</strong>神经元超过数十亿，甚至上万亿的人工神经网络。</p><p>&nbsp;</p><p><strong>（三）AIGC的特征辨别</strong></p><p><strong>1. 猜猜哪一张图片是AI生成的？</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_536a160325754036aa4acbdd198351b9@5509299_oswg88017oswg1080oswg432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p>答案：左边。</p><p><strong>2. 猜猜哪一首诗是AI写的？</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_f470d5fd87624b0e8114f6c8fbede81b@5509299_oswg74684oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p>答案：右边。AI用词更高频、普通。&nbsp;</p><p>&nbsp;</p><h2><strong>关于大模型的九大认知</strong></h2><p><strong>（一）大模型让AI从半自动化时代进入自动化时代</strong></p><p><strong>1. 人工智能发展的三次浪潮</strong>&nbsp;</p><p>1950～1980：萌芽时期。信息系统、早期专家系统。</p><p>1980～2000：探索时期。专家系统广泛应用神经网络初步发展。</p><p>2000～未来：高速发展时期。统计机器学习、深度学习、类脑计算。</p><p><strong>2. 人工智能发展历程与特征</strong>&nbsp;</p><p>如何让计算机识别这张女宇航员图像？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_595d7c48c4fc45c9822f8f8aad5ad4bd@5509299_oswg146976oswg1080oswg520_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p><strong>（1）手工时代（1956～2012）</strong></p><p>人工数图像里的边和角，比如眉毛这里有一条边，眼睛这里有一个角，然后计算图里一共有多少边边角角。</p><p>工作重点：怎样把边和角设计得更好，怎样数边角。</p><p>存在问题：错误率较高。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_577c0a34f34847e7982ddf58f43b0c0c@5509299_oswg310270oswg683oswg334_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p><strong>（2）半自动化时代（2012～2017）</strong></p><p>用人工神经网络的方法，给指定网络和模型让机器自动学习边角。</p><p>工作重点：给图像打标签，告诉模型图像中有什么。</p><p>存在问题：人力有限、打的标签也有限，且标签是局部的，而图像中会包含大量信息。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ce607d5938294825b9e9176096238b7b@5509299_oswg464808oswg1080oswg553_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p><strong>（3）全自动化时代 （2018～）</strong></p><p>技术突破：恢复图像、文本中空缺的部分。大模型可以自动学习互联网上无限的数据，且自动探索学习任务。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ec64f3e9c34545a6a3f38438d438a77b@5509299_oswg138473oswg574oswg267_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p>&nbsp;</p><p><strong>（二） 大模型需要大数据和大计算</strong>&nbsp;</p><p>以GPT4为例，GPT4有1.8万亿个神经元，训练使用了13万亿个字。</p><p>如果一本书是10万字，100本书放在一个书架上，两个书架是1米，那13万亿个字可以连成650公里的书架。</p><p>如果把这些放在普通电脑上进行计算，需要算700万年。</p><p>&nbsp;</p><p><strong>（三）大模型是通用模型</strong></p><p><strong>1. 通用性</strong>&nbsp;</p><p>（1）以前一个任务要设计一个模型去解决，现在一个模型基本可以处理大部分任务，任务处理更像人类。</p><p>（2）主要数据量足够大，同一套框架可以处理图像、声音等多种任务。</p><p><strong>2. 大模型的三高</strong></p><p><strong>自动化程度高、通用性高、数据/计算要求高。</strong>&nbsp;</p><p>（1）大模型可以极大的加速各个行业的自动化程度。麦肯锡的报告显示：80%的美国职位受到ChatGPT的影响，对知识工作者的影响尤其大。</p><p>（2）大模型首先取代的是有很多数据的行业。&nbsp;</p><p>&nbsp;</p><p><strong>（四） 大模型的落地很快</strong></p><p>麦肯锡报告称，2030年AI带来的全球经济增量13万亿美金。</p><p>大模型在各行各业的应用：</p><p>· 教育类：多邻国（duolingo）、khan academy</p><p>· 软件类：Github CoPilot</p><p>· 服务类：Yabble、Morgan Stanley</p><p>· 企业流程管理：stripe</p><p>· 工具类：Jasper、copy.ai、runway&nbsp;</p><p>&nbsp;</p><p><strong>（五） 把复杂任务拆解可以极大提升成功率</strong></p><p>如提问：直播运营的主要工作和流程是什么?</p><p>回答：直播运营的主要工作和流程可以大致分为以下几个步骤：</p><p>1.直播策划:这是直播运营的第一步，需要确定直播的主题，例如产品展示、教育讲座、娱乐活动等。此外，还需要确定直播的时间、地点、主持人、嘉宾等内容。</p><p>2.内容制作:这是直播运营的重要环节，包括制作直播的前期宣传素材，设计直播的节目流程，准备直播的道具和设备等。</p><p>3.直播推广:在直播开始前，需要通过各种渠道进行推广，包括社交媒体、邮件营销、网站广告等，以吸引更多的观众参与。</p><p>4.直播执行:在直播开始时，需要确保所有的设备运行正常，主持人和嘉宾按照节目流程进行，同时还需要监控直播的观看人数、互动情况等。</p><p>5.直播后期:直播结束后，需要对直播的效果进行评估，包括观看人数、互动情况、销售转化率等，同时还需要对直播的录像进行剪辑，以供后期的回放和分享。</p><p>6.反馈和改进:根据直播的效果和观众的反馈，进行相应的优化和改进，以提高下一次直播的效果。直播运营的主要工作就是通过这些步骤，提供高质量的直播内容，吸引和保持观众的关注，同时实现公司的营销和销售目标。&nbsp;</p><p>&nbsp;</p><p><strong>（六） 提升AI智能程度的主要手段在于把模型有效放大</strong>&nbsp;</p><p>通过过去几十年的智能发展可以看出，未来模型会越来越大。</p><p>GPT-4的结果还有较大的提升空间。&nbsp;</p><p>&nbsp;</p><p><strong>（七） 训练成本和推理成本急剧下降</strong>&nbsp;</p><p>行业迭代非常快，以GPT-3为例，2020年训练一次的成本是460万美金，2022年训练一次的成本为45万美金，两年下降了大概十倍。</p><p>成本下降的主要原因：</p><p>1. 硬件性能持续提升、超过摩尔定律</p><p>2. 训练效率持续提升，通过软件带来的训练成本下降每年达47%</p><p>3. 全球算力规模急剧上升，分摊成本效果明显&nbsp;</p><p>&nbsp;</p><p><strong>（八）大模型的迭代速度非常快</strong></p><p>西湖心辰内部数据显示，5月至10月，用户跟AI的对话时长从2分多钟提升到30分钟以上。&nbsp;</p><p>&nbsp;</p><p><strong>（九）大模型不能光有IQ，还需要有EQ</strong>&nbsp;</p><p>在以下几个方面提升多模态模型的EQ：</p><p>1. 长期记忆：能记住用户的历史互动信息</p><p>2. 个性化：能深度定制模型的人设、性格和偏好</p><p>3. 情感感知：能感知用户的情绪状态，并采用更有温度的表达方式和用户互动</p><p>美国大模型公司Inflection.ai推出了聊天机器人Pi，具有更强的共情能力，对人友善且颇有正能量。最近刚完成了13亿美金的融资。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_920b7e1beb1f4419888243ad30696bbe@5509299_oswg181191oswg1080oswg653_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p>&nbsp;</p><h2><strong>西湖大模型</strong></h2><p>西湖大模型上线1年多，已落地多个行业，服务近3百多万C端用户和包括星巴克、支付宝、知乎、酷家乐、汤姆猫、SHEIN在内的100多家B端客户</p><p><strong>（一）西湖大模型IQ版</strong></p><p>RIO，支持中英文双语，除了记忆外，还掌握了搜索引擎、知识图谱、外部数据等调用能力，在写作等多项能力上已经接近GPT3.5。</p><p><strong>（二）西湖大模型主要能力</strong></p><p>对话、写作、绘画</p><p><strong>（三）西湖大模型应用案例</strong></p><p>AI对话 —— 亲清在线（杭州市发改委）</p><p>AI写作 —— Friday （100+写作场景定制）</p><p>AI绘图 —— 造梦日记（星巴克、知衣科技）</p><p><strong>（四）多模态大模型在汤姆猫的场景示例</strong></p><p>将汤姆猫迭代成具有长期记忆、个性化、情感感知、主动聊天等特点的汤姆猫。</p><p>高情商、高智商的大模型覆盖各行各业，包括娱乐（如数字人）、游戏（如智能NPC）、社交（如虚拟伴侣）、教育（如虚拟教师）、医疗（如虚拟医生）、金融（如智能投顾）等。这些场景里，大家需要AI更像人一样的提供服务，而不是冰冷的机器人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_fbe6ea394b0744c4b77d6d560a2be79c@5509299_oswg184342oswg1080oswg653_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p>&nbsp;</p><h2><strong>群友 vs. CEO</strong></h2><p><strong>@郭坚强：专业不对口的普通人如何进入AIGC行业？</strong></p><p><strong>&nbsp;蓝振忠 </strong>：<strong>我有一个建议是大家先用起来。</strong>其实很多人都在说现在AI很厉害，但有很多人并没有用到日常生活中去。</p><p>即使我自己是在做这个的，我一开始也没有用的特别多，直到前段时间我才开始每天用AI去问各种问题。比如说我带博士生，我会让AI帮我改一些论文，然后提一些idea；比如说我经营公司，我会问它公司的一些战略怎么制定。其实它可以帮你很多事情，刚开始使用的时候，可能会因为不知道如何去跟AI交互，所以觉得不是特别有用，后面用熟悉了、交互多了，可以很好地帮助你的生活和工作。</p><p>更重要的一点是，用起来之后，你感觉它真的可以帮到你，那你再想说我怎么可以加入其中，怎么可以推动它的发展。这个是给大家的一个建议。</p><p><strong>@柳邑Leo：请问目前公司都需要什么类型的人才？</strong></p><p><strong>&nbsp;蓝振忠 </strong>：我们公司目前在各个方面上都在大量招人，算法、产品经理、技术、销售、法律、运营等方面，我们甚至在招合伙人。因为我觉得创业就是大家一起往前走，如果你有特别强的方面，都欢迎来跟我们聊，我们也一直保持开放的学习态度。</p><p><strong>我们招人的标准首先是专业度，其次是努力。</strong>因为这个行业跑得相对比较快，变化也很快，所以我们希望大家能够一起往前走。</p><p>我们在招聘网页上都有相应的具体要求，所以我就不说一些硬性的标准了，我主要强调一些软性的指标。<strong>所谓的软性指标就是聪明、勤奋、成熟、有创造力</strong>，因为我们一方面在做技术模型，另一方面也在做社交类产品，我们也在探索各种行业的可能性，所以非常欢迎有创造力的同学加入我们。</p><p><strong>@苏：未来可能会出现什么样的新AI岗位？目前好像都是AI结合各行各业的岗位，本质上还是原来的职业岗位。</strong></p><p><strong>&nbsp;蓝振忠 </strong>：对，结合的岗位比较多一些，因为<strong>AI本质上是生产力的革命</strong>。新的岗位主要有两种，一种是如何去跟AI交互、懂AI、了解AI；另一种是本身做AI的，比如说训练大模型和各种AI技术岗位。</p><p><strong>@山泉水有点甜：我是传统银行的客户经理，工作与AIGC重合度不高。我一直想要尽早踏入AI行业中，但由于我原始专业和知识都不是AI技术相关的，后期在学习AI硬知识的时候很吃力。我想请教一下，在保持对AI的学习和关注的同时，如果想要踏入AI行业，有没有必要去深度钻研背后的技术逻辑（有点感觉重复造轮子？），还是往后看具体AI应用落地领域？按照目前来看，AI在金融领域有没有技术背景相对低一点的方向可供参考呢？</strong></p><p><strong>&nbsp;蓝振忠 </strong>：我觉得<strong>了解一定的技术当然会非常有帮助</strong>，作为客户经理或产品经理来说，其实了解背后的技术一定有用，再接下来就是AI在各个地方的落地了。研究AI落地其实也是一个很重要的方面，所以如果没有技术背景的同学，我建议可以去看看这方面的机会。比如在金融领域，有很多企业都在尝试AI落地，也有很多AI公司都在关注这方面。</p><p><strong>@张鑫：现在很多大模型都免费开源了，还从0到1做大模型是不是没价值了？</strong></p><p><strong>&nbsp;蓝振忠 </strong>：其实是有价值的。你接下来还是要往前走的，即使你去做各行各业的落地，你怎么训练出最好的模型。如果能够从0到1来做一遍，其实是非常有价值的，但是其实也非常耗钱，所以对大量的应用AI的人来说，可以用开源或者是调用API就可以了，没必要说从0到1的做。对于比如说真正做大模型的公司来说，我们是需要从0到1去做的，这也是我最近有比较深刻的认识的一点。</p><p><strong>@诗酒趁年华：现在好多基础的代码编写都可以由大模型替代，如果未来想从事开发、测试、算法相关工作，应该从哪些方面入手学习，更好的体现出就业竞争力呢？</strong></p><p><strong>&nbsp;蓝振忠 </strong>：其实我觉得本质都是一样的，就是<strong>提升综合能力</strong>方面吧。就写代码就对程序员来说，只是工作其中的一方面。当然，如果是做算法的话，那就可以做的相当深了，这方面其实还有大量的专业研究工作可以做，我相信在未来的几年内，我们是需要大量算法的人员的。</p><p><strong>@Prompts：国内模型这么卷，大模型创业真正的技术壁垒是什么？</strong></p><p><strong>&nbsp;蓝振忠 </strong>：大家看似很卷，其实没有那么卷。而且每个模型公司都有自己的侧重点，所以我相信未来可以有更广阔的天地。</p><p>大家可以对比一下上一波人工智能，上一波人工智能的应用领域其实不是特别广。应用领域很窄，然后又需要大量的标注，但即使这样的情况下，仍然出现了多家公司，而且还都有代表性的公司。</p><p>那这一次跟上一次是完全不同的，这一次有了一个非常大的范式的变化，而且这一次会出现<strong>很多C端的应用</strong>，所以我觉得未来会有非常大的机会，这是第一点，就是它在<strong>应用方面</strong>有大量的机会。</p><p>第二点是<strong>技术方面</strong>，我觉得目前技术还在起步阶段。现在虽然看起来有这么多家公司，但是<strong>未来在技术选型或技术提升上也会出现分化</strong>，有非常多的技术点可以去突破。</p><p><strong>@Julin：国内大模型这么多家，未来可容纳的有多少？如何避免重复造轮子？</strong></p><p><strong>&nbsp;蓝振忠 </strong>：大部分都没有在重复造轮子，因为很多公司其实用的是开源在做，真正从头到尾训练的不是特别多。如果是真正去做大模型的话，你还是要走一遍的，这样的话，很多的知识点其实都可以作为覆盖。<strong>我觉得从未来技术进步的角度来说，现在有少量的重复造轮子是必要的。</strong></p><p>&nbsp;</p><p class="wx-app-wrapper">&nbsp;</p><blockquote><p>西湖心辰是<strong>专注于人工智能服务研发的科技公司</strong>。</p><p>其拥有国内几乎最顶尖的研究力量，旗下产品有「Friday」、「造梦日记」、「聊会小天」、「心辰智能云」等，公司致力于引领AGI走向每一个人，为个人用户和企业用户提供全链路AIGC和人工智能技术服务。</p><p>西湖心辰作为一家杭州大模型创业公司，在资本市场炙手可热，今年7月10日，获得了汤姆猫第二笔战略融资，金额过亿，此前还曾获蓝驰创投、BV百度风投、凯泰资本、西湖科创投、西湖教育基金可持续发展平台等多项投资。</p><p><strong>愿景：打造陪伴10亿人的AI伴侣。</strong></p></blockquote><p>&nbsp;</p><p>信息整理&nbsp;<strong>|张芳芳</strong></p><p>编辑&nbsp;<strong>|戴修齐</strong></p><p>排版&nbsp;<strong>| 戴修齐</strong></p><p>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_18a9049b192b44a39507f68b9e1a3378@5509299_oswg2300213oswg1080oswg6900_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/RI3CK9Hrlp73n6kFArEPhw" rel="noopener noreferrer nofollow" target="_blank">“职场Bonus”（ID:ZhiChangHongLi）</a>，作者：职场红利研究所，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551952319469959</id>
            <title>如何提升金融系统性风险监测的前瞻性？</title>
            <link>https://www.36kr.com/p/2551952319469959</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551952319469959</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:18:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 统筹发展, 系统性风险监测, 实体经济债务, 偿债能力
<br>
<br>
总结: 中央金融工作会议要求加强系统性风险监测和宏观审慎监管，其中关键在于提高系统性风险监测的前瞻性和全面性。为了实现这一目标，需要将监测前置到实体经济部门，特别是对实体经济债务规模、债务结构和偿债能力的变化进行监测。这样可以更好地把握系统性风险的来源和评估风险的大小，以及理清风险传导的路径。 </div>
                        <hr>
                    
                    <blockquote><p>中央金融工作会议要求，“统筹发展和安全，牢牢守住不发生系统性金融风险的底线，坚定不移走中国特色金融发展之路，加快建设中国特色现代金融体系“，其中的关键在于如何提高系统性风险监测的前瞻性、全面性和强化宏观审慎监管的深入性、有效性。为此，我们结合前期研究，推出了“系统性风险监管”分享系列。本文是系列研究的第二篇。</p><p><strong>经济金融发展是“融资—投资—盈利—偿债”不断循环反复的过程，金融系统性风险很大程度上是实体经济主体债务违约在金融体系的“映射”，且在时间顺序上先于金融风险的变化。为了提高风险防控的前瞻性和全面性，金融系统性风险监测需要前置到实体经济，增加实体经济债务规模、债务结构、偿债能力等方面的变化监测。这样也有助于更好滴把握金融系统性风险的来源，评估风险的大小，理清风险传导的路径。‍</strong></p></blockquote><p>前文（金融系统性风险监管框架需要重构）的研究表明，经济金融发展是“融资—投资—盈利—偿债”不断循环反复的过程，从根源上看，金融体系的风险很大程度上是信贷资金在实体经济的错误配置导致的，最终来自于实体经济主体的债务违约；系统性金融风险防控的主体虽然是金融机构和监管部门，但系统性金融风险监管不能只局限在金融体系，需要前移到监测防控实体部门的债务变化和债务风险上。</p><p>具体到提高金融系统性风险的前瞻性上，金融系统性风险的监测还需要前置到实体经济部门，增加实体经济债务规模、债务结构、偿债能力等方面的监测。</p><h2><strong>前置增加实体经济的债务规模变化监测</strong></h2><p>相对于“广义信贷/GDP”，“实体经济债务/GDP”对于监测和识别银行业系统性风险具有两方面的显著优势。</p><p><strong>一方面，在测算范围上，相对于广义信贷/GDP，实体经济债务/GDP的范围更大</strong>，还包括政府债务和非正规借贷。在我国，近年来地方政府债务特别是各种隐性地方政府债务快速增长，民间借贷较为活跃，互联网金融快速发展，政府债务和非正规借贷风险对我国金融体系风险的影响不可忽视。</p><p><strong>另一方面，在监测对象上，“实体经济债务/GDP”监测的是信贷需求方——实体经济主体的债务，而“广义信贷/GDP”监测的是信贷供给方——金融机构的资产。</strong>信用风险的暴露最终来自信贷需求方的债务违约，因此“实体经济债务/GDP”监测有利于更好把握系统性风险的根源和提高系统性风险监测的前瞻性、全面性。</p><p><strong>在方法上，当前宏观审慎监管中采用的“广义信贷/GDP”类似，“实体经济债务/GDP”监测的也是“实体经济债务/GDP”相对于其趋势值的偏离度。</strong>具体实施过程中，通过历史数据计算“实体经济债务/GDP”偏离度的安全区间和风险区间，进而划定不同程度的预警信号。</p><h2><strong>增加实体经济的债务结构变化监测</strong></h2><p><strong>在实体经济债务规模一定的情况下，债务在企业部门、家庭部门、政府部门之间的不同分布，债务在各个实体行业的不同分布，都会影响到实体经济债务风险的暴露和向金融体系的传染。静态地看，这是因为不同部门、不同行业在不同时期的收入增长、抵押品价值等存在差异，即债务偿付能力不同，决定了金融体系风险的分布结构。动态地看，这是因为银行信贷等资金流向不同部门、不同行业，意味着不同的资金产出效率，决定了整个实体经济未来的潜在增长率和整个金融体系的潜在系统性风险。</strong></p><p>在国外，国际清算银行Borio 等（2015）的研究发现，随着金融体系的信贷扩张，房地产行业和基础设施行业的贷款和债务会快速上升，并对抵押物不足的制造业、R&amp;D等行业的债务融资产生挤出效应，最终导致实体经济产出效率的下降和金融体系脆弱性的上升；国际货币基金组织在2018年4月发布的《全球金融稳定报告》研究指出，信贷在不同行业、企业的不合理配置是金融体系脆弱性的重要来源（IMF，2018）。在国内，朱太辉等（2018）分析了金融资源在不同行业企业的分布对企业公平竞争和金融体系稳定的影响机制。</p><p>因此，金融系统性风险监测体系应该增加对实体经济债务结构变化的监测。具体而言，可以一下监测模型：‍‍‍‍‍‍‍‍</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_7a0efd04bc624d058fe16cc495782e62@000000_oswg37418oswg1080oswg289_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>在具体的监测方法上，可以参照现有的“广义信贷/GDP”监测，但要体现结构性。</strong>一方面，不同部门、不同行业的负债率指标从可比性上考虑可以选择GDP作为分母，但也应同时考虑该部门、行业的产出或者收入；另一方面，不同部门、不同行业的负债率偏离度的安全区间和风险区间设置要充分考虑该部门、行业的自身特征，如发展阶段、收入增速、抵押物状况等。</p><h2><strong>增加实体经济的偿债压力变化监测</strong></h2><p><strong>虽然债务规模和负债率是影响债务人是否债务违约的重要因素之一，但债务违约与否最直接的影响因素是债务人的偿债压力或偿债率（Debt Service Ratio，DSR）</strong>，如（2）所示。BIS的研究发现，经济衰退前私营部门的偿债率（DSR）变化会导致产出下降，并提前1—2年预警银行业系统性风险；在银行业危机爆发前1年左右，DSR预警的可信度要高于信贷/GDP缺口，是表现最好的早期预警指标，而信贷/GDP缺口更适用于较长经济周期的情况，两者具有一定的互补性（Drehmann and Juselius，2012）。因此，在监测实体经济债务规模变化的同时，增加实体经济偿债压力监测，有利于提高系统性风险监测的有效性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_58b40fc803754a869f2b77ba82fdd2f3@000000_oswg33806oswg1080oswg291_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>在这方面，一个可以选择的监测指标是“隐含不良贷款率”。</strong>隐含不良贷款率（implied NPL ratio），最初由高盛公司和国际货币基金组织（IMF）在20世纪末、21世纪初的研究所提出（Ramos et al.，1998；Heytens and Karacadag，2001），是在计算实体企业息税前利润EBITDA（Earning Before Interest, Tax, Depreciation and Amortization，扣除利息、所得税、折旧和摊销前的营业利润）的基础上，进一步比较EBITDA与利息支出的大小，进而对企业的债务违约风险进行判断。</p><p>隐含不良贷款率的计算公式如（3）所示。该指标从企业财务角度入手，比较企业盈利情况和付息成本，可以用来前瞻性地判断银行贷款的坏账率。熊利平和蔡幸（2012）的研究表明，隐含不良贷款率具有多方面的优越性：该指标简单直观地反映了企业的贷款质量，从微观企业获取的数据比银行信贷数据更具前瞻性，具有不错的预警效果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_3ce5f4aecd384e3eb0886c7d2e37585f@000000_oswg20947oswg1080oswg144_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>另一个可选择的监测指标是企业“破产距离”。</strong>“破产距离”是指企业潜在负债率（潜在资产和负债的百分比偏差）与资产波动的比率，一般用来衡量企业陷入财务困境的程度。其值越大，表明企业资产价值距离破产点越远，财务稳健性越大，企业出现偿债压力和债务违约概率越小。破产距离DI的计算公式如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_50f26c8c938647a4a8082f883d48b389@000000_oswg30567oswg1080oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Andrew et al.（2013）根据企业间破产距离的分布特征度量了美国金融市场的稳健性，发现度量结果所预警的破产危机与美国1926-2012年间的三次大萧条在时间上完全吻合。<strong>企业破产距离的优势在于，它不像结构化信用风险模型估计违约距离指标那样复杂，可以通过监测企业股价波动来实现，且便于长时间不间断地跟踪监测。</strong></p><p>此外，相对于监测银行等金融机构“违约距离”的或有权益分析法（Contingent Claims Analysis，CCA）（Gray and Malone，2008；Gray and Jobst，2010；范小云、方意和王道平，2013），通过监测银行等金融机构的债务人——负债企业的破产距离，可以更加前瞻性地把握金融系统性风险的变化。在金融系统性风险监测的实践中，可以将企业DI分析法和金融机构CCA分析法结合起来应用，相互补充和印证。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzk0NDUzMTEyMg==&amp;mid=2247484405&amp;idx=1&amp;sn=c30d6677db2cfc513f974303c6c27839&amp;chksm=c3227028f455f93eda17434044cd0c7cea514b40dd9911a76da574ddbada8f847ece013296c3&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“太辉研究”（ID：taihuiyanjiu202308）</a>，作者：朱太辉，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551946111721606</id>
            <title>谷歌发布大模型，国内“百模大战”鏖战正酣</title>
            <link>https://www.36kr.com/p/2551946111721606</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551946111721606</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:14:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, ChatGPT, Gemini, GPT-4
<br>
<br>
总结: 2022年底，OpenAI发布了ChatGPT，引发了人工智能热潮。一年后，谷歌发布了Gemini大模型，被认为是谷歌新时代的开始。Gemini Pro在性能上超过了GPT-3.5，但尚未公开与GPT-4的比较。ChatGPT的出现引发了国内大模型企业的追赶热潮，包括百度、360集团、阿里巴巴、科大讯飞、腾讯等。这些巨头的加入使得大模型的发展进入了一个新阶段。 </div>
                        <hr>
                    
                    <p><strong>2022年底，OpenAI发布ChatGPT掀起了人工智能热浪，时隔一年后，谷歌终于“杀回”人工智能赛道。</strong></p><p>当地时间，12月6日，谷歌正式发布了Gemini大模型。<strong>谷歌CEO桑达尔·皮查伊称，Gemini的发布，是谷歌新时代的开始</strong>；但人们最关注的问题还是Gemini和GPT-4相比水平谁更高。</p><p>谷歌公司高管称，三种不同版本的套件中的Gemini Pro，表现优于GPT-3.5，但暂未直接回应Gemini与GPT-4相比表现如何的问题。不过外界有测评认为，它们已经超过了GPT-4。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5afd9eb9b716452e94fff73f6623f9c7@5940768_oswg27036oswg640oswg348_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：微博截图</p><p>不管是否超过，作为大模型的“风向标”，由一年前推出的ChatGPT引发的“生成式人工智能”革命，仍在不断地改写着每个人的认知。</p><p><strong>如今巨头谷歌已“上线”，过去一年，在ChatGPT的引领下，国内的大模型企业也从摸索和尝试，逐渐步入深水区。</strong></p><h2><strong>01.“百模大战”，从震惊到追赶</strong></h2><p>ChatGPT的出现并非毫无征兆。</p><p>创造它的OpenAI早在2015年便已成立，并在2018年就推出了初代生成式预训练模型GPT-1，这也是ChatGPT最初的原型。</p><p>公开资料显示，在GPT-1之前，业内的NLP模型（Neuro logic level自然语言处理）主要是基于针对特定任务的大量标注数据进行训练，能力有限。</p><p>GPT是第一个结合Transformer（多层变换器）结构和自监督预训练目标的模型，在自然语言推理、问答任务和常识推理等方面取得了突破，为此它们也获得了微软10亿美元投资。随后，<strong>从GPT-1到GPT-2，到GPT-3，短短2年时间里GPT的能力不断提高。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_056e79e492314f689cc29210f59e131a@5940768_oswg76525oswg640oswg294_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：OpenAI官网截图</p><p>2022年11月27日，随着由GPT-3.5修改而来的人工智能对话聊天机器人ChatGPT的推出，这个一直在小圈子走红的研究成果，才第一次为大众所认识。能聊天、画画、写文案、编代码，强大的功能，使得ChatGPT一经发布迅速走红，5天时间注册用户数超过百万，两个月时间月活突破1亿，成为史上增长最快的消费者应用。</p><p>消息传至国内，一石激起千层浪。<strong>人工智能竟然已经发展到如此地步了？震惊之下，淘宝上售卖ChatGPT账号甚至都成了一门生意。</strong>与此同时，看到巨大商机的各界大佬们，也纷纷下场，表态要尽快推出自己的大模型。</p><p><strong>率先落地的是百度。</strong>2023年3月16日，国内首个大语言模型“文心一言”问世，发布会上，百度CEO李彦宏直言，“生成式AI是任何企业都不应错过的大机会”。</p><p>而百度之所以能够拔得国内大语言模型的“头筹”，源自其过去10多年中，在AI研发上的坚持投入。按李彦宏的说法，文心大模型的第一个版本早在2019年就发布了，此后每年都有更新，文心一言的发布只是百度多年努力的“自然延续”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e7d7291635904321b6c4086f0400eee1@5940768_oswg18455oswg640oswg421_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：百度文心一言公众号</p><p>紧接着，3月29日，<strong>360集团发布人工智能战略及360智脑大模型1.0版本</strong>，创始人周鸿祎现场演示了大模型在搜索场景的应用。4月11日，<strong>阿里巴巴的“通义千问”大模型在阿里云峰会上揭晓</strong>，CEO张勇宣布未来阿里巴巴所有产品都将接入“通义千问”。5月6日，<strong>科大讯飞星火大模型发布</strong>，董事长刘庆峰表态要在10月24日实现中文超过ChatGPT，英文赶上ChatGPT。9月7日，<strong>腾讯混元大模型上线</strong>。</p><p><strong>至此，国内传统的三大互联网巨头“BAT”全部下场。</strong></p><p>此外，华为、京东、字节跳动、商汤科技、昆仑万维等等都陆续推出了大模型产品，甚至连移动、联通、电信三大运营商，长虹等家电生产企业，清华、复旦、中科院等科研院所和高校，都发布了各自的大模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_49171d0eb016432f9ecd6c1d119d36d8@5940768_oswg26884oswg640oswg340_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：华为云AI公众号</p><p>5月底举行的中关村论坛上，有专家披露，中国10亿级参数规模以上大模型已发布了79个；在7月初的2023世界人工智能大会中有信息表明，中国已有130家研发大模型的公司。<strong>此时，ChatGPT引起的大模型研发热，已经带动国内形成“百模大战”的格局。</strong></p><p><strong>不过相比当初外卖界的“百团大战”，“百模大战”对资金的需求更为苛刻。</strong></p><p>根据NVIDIA官方信息，在训练底层模型阶段，训练一次1750亿参数的GPT-3需要34天、使用1024张A100 GPU芯片，而为了维持日常推理，OpenAI至少需要3.24万张A100，<strong>以此推算，ChatGPT仅硬件成本就超过了8亿美元</strong>。</p><p>昆仑万维集团CEO方汉更是公开表示，“没有2000张A100的卡，实验都做不了”。为此，海天瑞声、因赛集团等“AI概念股”甚至接连发布定增预案，募集资金用于训练大模型。</p><p>此时 ，如何在缩小与ChatGPT差距的同时，尽快找到应用落地的方向，实现自我造血，成为了“百模大战”中，每一位参与者都要面对的问题。</p><h2><strong>02.人工智能+将所有行业做一遍？</strong></h2><p><strong>从商业角度分析，大模型带来的机遇，可以概括为成本减少效率提升、原有市场需求再扩大、创造新的市场需求三大类。</strong></p><p>在今年8月31日、11月4日，根据网信办《生成式人工智能服务管理办法（征求意见稿）》的要求，国内先后有两批涉及26家公司的AI大模型和151个深度合成服务算法通过备案，陆续向全社会开放服务，其中的商业化尝试，也基本是围绕这三类展开的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ef10167508664ef08291f7a1d55126f9@5940768_oswg97964oswg640oswg273_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：网信办截图</p><p><strong>大模型超强的人机对话、图文及音视频生成能力，不但让其在传统客服场景中获得了广泛应用，对于游戏、影视制作等也产生了深远影响。</strong></p><p>阿里、美团的在线智能客服算法，以及中国移动的“九天大模型”、中国电信的TeleChat大模型等，都属于此类产品，将应用场景直接锁定在了智能客服、智慧政务等方面。在今年的亚运会上，科大讯飞与中国移动联合推出了基于星火大模型的5G新通话，接完电话之后，申请服务，会即刻转成文字、生成纪要、生成待办事项。</p><p>游戏、影视制作方面，导演陆川曾在采访时表示，“用AI画电影海报，15秒出来的效果比专业海报公司做一个月的还要好。”光线传媒、华策影视等率先尝试将大模型应用在影视创作中的公司，股价在年中都收获了一波大涨。</p><p><strong>原有市场需求再扩大，则体现在对于传统业务的升级上，这也是大模型应用最广泛的领域。</strong>以传统的搜索引擎为例，接入文心一言后，在百度搜索框里输入问题，给出的可以不再是链接，而是一个更准确的答案。</p><p>10月17日，文心一言4.0发布，根据李彦宏现场的演示，除了搜索外，百度地图、网盘、文库等十余款应用，都接入文心一言完成了重构。</p><p>旗下业务众多的腾讯，对腾讯云、腾讯广告、腾讯游戏、腾讯会议等多个业务和产品，也已完成了接入腾讯混元大模型的测试，并取得了初步效果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_aafec062b75443c48100fb9354bf8dee@5940768_oswg87335oswg640oswg401_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：腾讯混元官网截图</p><p><strong>此外，在传统的教育、医疗、汽车等领域，大模型也获得了广泛的应用。</strong>接入讯飞星火大模型后，科大讯飞的学习机实现了AI一对一辅助教学、中英文作文批改、口语陪练等功能；百度推出了产业级的医疗行业大模型“灵医”，有超过1000家企业级机构先行体验；华为云盘古大模型的赋能，则让问界新M7在智能驾驶领域“遥遥领先”，两个月大定突破10万台。</p><p><strong>在创造新的市场需求方面，AI超级助理、AI机器人等需求也被不断创造出来。</strong>前者，包括文心一言、讯飞星火、360智脑、通义千问等在内的各家通用大模型都有相应产品提供，它们大都能理解用户的语言语义，并具备图像理解能力，可以通过调用软件API，使用各种各样的工具来帮助用户完成任务；而后者，在今年8月16日举行的2023世界机器人大会上，包括优必选、追觅、宇树在内的不少于 10 家机器人企业，展出了相关产品，赛道也正呈现井喷态势。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_64222d5aadc041eaac7829493e36f258@5940768_oswg54240oswg640oswg357_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：通义官网截图</p><p><strong>不过，在一片欣欣向荣背后，也存在隐忧。比照各家大模型的应用不难发现，不管是提高效率还是扩大需求，市场上绝大多数的应用，实现的功能都较为雷同。</strong></p><p>以AI学习机为例，除了科大讯飞有相关产品外，接入子曰大模型的网易有道、接入MathGPT的好未来、接入银河大模型的作业帮，以及接入文心一言的百度、接入360智脑的360，都有类似的产品在售。功能方面，各自宣传的也都大同小异，AI一对一辅导、全科AI作业助手、虚拟人口语教练等，站在消费者的角度，几乎很难体会到其中的差别。</p><p>尽管各家都能拿出一堆的排名榜单来论证，自己的大模型得分更高、能力更强，但体现在实际应用中时，那百分之几甚至是千分之几的差别，还是让人不得不产生疑惑：<strong>我们真的需要这么多大模型吗？</strong></p><h2><strong>03.AI原生应用至上，亟待“安卓”出现</strong></h2><p>对于大模型步入“深水区”将会遇到的挑战，百度创始人、董事长兼首席执行官李彦宏提出了自己的看法。</p><p>近期，<strong>在深圳2023西丽湖论坛开幕式上，李彦宏就直言，拥抱AI时代，是“一把手工程”</strong>。因为CTO、IT负责人更关注技术本身，认为自己做大模型是交作业，结果不仅资源浪费，而且用不起来，最后一地鸡毛；<strong>只有一把手才会真的关注，新技术如何提升自己业务的关键指标，一把手上阵，才能让新技术真正为企业所用</strong>。</p><p>不断地重复开发基础大模型是对社会资源的极大浪费。在李彦宏看来，国内如今的大模型实在是太多了。根据统计，<strong>截止10月份，国内已经发布的大模型达到了238个，比5月科技部统计时的79个，翻了三倍</strong>，但与此同时，市场上真正的AI原生应用却很难找出几个。<strong>一把手应该主导做AI原生应用，而不是大模型</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_3cbcb585df754534921c6abdf9d972be@5940768_oswg27881oswg640oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：微博截图</p><p>“<strong>人类进入AI时代的标志，不是产生很多的大模型，而是产生很多的AI原生应用</strong>。”李彦宏认为，大模型时代其实和PC时代、移动互联网时代极为类似。PC时代，主流的操作系统只有Windows一个，移动互联网时代，也基本只有安卓和iOS两家，然而围绕着它们，诞生了无数的应用软件。</p><p>大模型本身也属于基础底座，类似操作系统，最终开发者要依赖为数不多的大模型来开发出各种各样的原生应用。“<strong>AI原生时代，我们需要100万量级的AI原生应用，但是不需要100个大模型</strong>。”</p><p>这确实是国内的大模型玩家们不得不面对的难题。<strong>尽管市场上大模型产品有几百个，但细究起来都是在各玩各的</strong>，360智脑只为自家搜索赋能，讯飞星火此前主要是为科大讯飞的学习机产品服务。</p><p><strong>相比大模型训练的高额花费，如果不能够有效扩大“朋友圈”，让自家的大模型为更多人所用，只是一味投入，显然难以为继。</strong></p><p>上半年大涨的AI概念股们，下半年几乎集体熄火，与此不无关系。科大讯飞（002230.SZ）10月19日发布的三季报显示，前三季度实现营业收入126亿元，同比下滑0.27%，净利润9936万元，同比跌了76%。<strong>根据公告，其利润下滑的主要原因，就是源自对大模型的“坚定投入”。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b6a7f97d483c4c55871cc5dd1ea95923@5940768_oswg43553oswg640oswg387_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：财报截图</p><p>三六零（601360.SH）的情况也没有好多少，上半年尽管新兴业务“360智脑”创造了近2000万元营收，但在9.1亿元的总收入中，占比不过2.1%。</p><p><strong>在“百模大战”进入深水区后，如何围绕各自的大模型，“扩大朋友圈”创造生态，争取更多的开发者，成了国内通用大模型玩家们不约而同的选择。</strong></p><p>在1024开发者节上，科大讯飞董事长刘庆峰透露，除了联合相关企业发布了包含金融、汽车、住建、法律等在内的12个行业大模型外，在讯飞星火上，已有1.5万助手开发者，开发了超过2.9万个助手应用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5e671daa6551405b9a159c3b908b8d4c@5940768_oswg45686oswg640oswg427_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：讯飞开放平台公众号</p><p>百度则先后推出了“百度智能云千帆大模型平台”、“灵境矩阵”，帮助企业开发自己的专属大模型，目前平台月活企业数已近万家。</p><p>阿里巴巴旗下的通义千问，从18亿、70亿、140亿到720亿参数规模，率先成为业界首个“全尺寸开源”的大模型，以吸引更多合作伙伴加入，共促通义千问生态建设。</p><p>去年11月，阿里巴巴发布AI开源社区“魔搭”，中国80%的大模型研发机构把魔搭作为模型开源的首发平台。短短一年时间，魔搭汇聚了280万开发者、2300多个优质模型，模型下载量超过1亿。</p><p>正如中国科学院院士、中国计算机学会（CCF）开源发展委员会主任王怀民所说，<strong>开源是AI发展的重要驱动力，AI开源社区不仅将有力推动AI迈向广泛的落地应用，还将助力中国从开源世界的参与者逐步成长为引领者</strong>。</p><p><strong>大模型行业的未来，如智能手机系统的迭代。</strong>曾经，除了苹果的iOS外，手机操作系统中还有诺基亚的Symbian、微软的Windows Phone、黑莓的BlackBerry，但是最终它们无一例外都败给了“在2012年，就拥有10万开发者，超过40万活跃应用”的Android。</p><p><strong>期待国产大模型们，早日跑出本赛道的“Android”。</strong></p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/chvxpNTtb6WsDdXoADLh4A" rel="noopener noreferrer nofollow" target="_blank">“趣解商业”（ID:qujieshangye）</a>，作者：周佟，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551976960366978</id>
            <title>何恺明新作：简单框架达成无条件图像生成新SOTA，与MIT合作完成</title>
            <link>https://www.36kr.com/p/2551976960366978</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551976960366978</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:13:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, 数据中心, 人工智能市场, GPU
<br>
<br>
总结: 英伟达正加快产品迭代更新速度，推出多款面向数据中心和人工智能市场的GPU产品，以满足不同客户的需求。同时，英伟达也在网络方面进行升级，提高数据传输速度。 </div>
                        <hr>
                    
                    <p>大佬何恺明还未正式入职MIT，但和MIT的<strong>第一篇合作研究</strong>已经出来了：</p><p>他和MIT师生一起开发了一个<strong>自条件图像生成框架</strong>，名叫RCG（代码已开源）。</p><p>这个框架结构非常简单但效果拔群，直接在ImageNet-1K数据集上实现了<strong>无条件图像生成的新SOTA</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_d1889c01135b4952a118144c12d2a5b9@1743780481_oswg73405oswg1080oswg529_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>它生成的图像不需要任何人类注释（也就是提示词、类标签什么的），就能做到既保真又具有多样性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e8c02368a85846c59c694c30dcf4916a@1743780481_oswg1036429oswg1080oswg543_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这样的它不仅显著提高了无条件图像生成的水平，还能跟当前最好的条件生成方法一较高下。</p><p>用何恺明团队自己的话来说：</p><p>有条件和无条件生成任务之间长期存在的性能差距，终于在这一刻被弥补了。</p><p>那么，它究竟是如何做到的呢？</p><h2><strong>类似自监督学习的自条件生成</strong></h2><p>首先，所谓无条件生成，就是模型在没有输入信号帮助的情况下直接捕获数据分布生成内容。</p><p>这种方式比较难以训练，所以一直和条件生成有很大性能差距——就像无监督学习比不过监督学习一样。</p><p>但就像自监督学习的出现，扭转了这一局面一样。</p><p>在无条件图像生成领域，也有一个类似于自监督学习概念的自条件生成方法。</p><p>相比传统的无条件生成简单地将噪声分布映射到图像分布，这种方法主要将像素生成过程设置在<strong>从数据分布本身导出的表示分布上</strong>。</p><p>它有望超越条件图像生成，并推动诸如<strong>分子设计或药物发现</strong>这种不需要人类给注释的应用往前发展（这也是为什么条件生成图像发展得这么好，我们还要重视无条件生成）。</p><p>现在，基于这个自条件生成概念，何恺明团队首先开发了一个<strong>表示扩散模型RDM</strong>。</p><p>它主要用于生成低维自监督图像表示，方法是通过自监督图像编码器从图像中截取：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ea80053f887a41c4b9cdeaea5fe1fe72@1743780481_oswg52654oswg674oswg224_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>它的核心架构如下：</p><p>首先是输入层，它负责将表征投射到隐藏维度C，接着是N个全连接块，最后是一个输出层，负责把隐藏层的潜在特征重新投射（转换）到原始表征维度。</p><p>其中每一层都包含一个LayerNorm层、一个SiLU层以及一个线性层。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b32d359049ff4216bf17c1635a197bb9@1743780481_oswg88244oswg628oswg592_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这样的RDM具有两个优点：</p><p>一是多样性强，二是计算开销小。</p><p>接着，利用RDM，团队就提出了今天的主角：表示条件图像生成架构RCG。</p><p>它是一个简单的自条件生成框架，由<strong>三个组件</strong>组成：</p><p><strong>一个是SSL图像编码器</strong>，用于将图像分布转换为紧凑的表示分布。</p><p><strong>一个是RDM</strong>，用于对该分布进行建模和采样。</p><p><strong>最后是一个像素生成器MAGE</strong>，用于根据表示来处理图像像。</p><p>MAGE的工作方式主要是向token化的图像中添加随机掩码，并要求网络以从同一图像中提取的表示为条件来重建丢失的token。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_3a241ac343164b2d9782f8953540a390@1743780481_oswg150322oswg718oswg622_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最终，测试表明，这个自条件生成框架虽结构简单但效果非凡：</p><p>在ImageNet 256×256上，RCG实现了<strong>3.56的FID和186.9的IS</strong>（Inception Score）得分。</p><p>相比之下，在它之前最厉害的无条件生成方法FID分数为7.04，IS得分为123.5。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_a56df02a12514efbae6ead4537a6d4e8@1743780481_oswg95533oswg658oswg574_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以及，相比条件生成，RCG也丝毫不逊色，可以达到相当甚至超过该领域基准模型的水平。</p><p>最后，在无分类器引导的情况下，RCG的成绩还能进一步提高到3.31（FID）和253.4（IS）。</p><p>团队表示：</p><p>这些结果表明，自条件图像生成模型拥有巨大潜力，可能预示这一领域新时代的到来。</p><h2><strong>团队介绍</strong></h2><p>本文一共三位作者：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_8544c135bf1c4d199e6779bc191518f5@1743780481_oswg24089oswg1080oswg234_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一作是MIT博士生黎天鸿，本科毕业于<strong>清华姚班</strong>，研究方向为跨模态集成传感技术。</p><p>他的主页很有意思，还专门放了一个菜谱合集——做研究和做饭是他最热爱的两件事。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_9eadbcd07d694121b9839c3196f401d7@1743780481_oswg386905oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一位作者是MIT电气工程与计算机科学系（EECS）教授、MIT无线网络和移动计算中心主任Dina Katabi，她是今年斯隆奖的获得者，并已当选美国国家科学院院士。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_294a37bab664485b92d389f5673c2d70@1743780481_oswg171663oswg310oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后，通讯作者为何恺明，他将在明年正式回归学界、离开Meta加入MIT电气工程和计算机科学系，与Dina Katabi成为同事。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_c00ccc1d5bc041efa2a043a6c8dee27c@1743780481_oswg428717oswg512oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>论文地址</h3><p>https://arxiv.org/abs/2312.03701</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/3vAC4nF7tQYlPzCQsGLn0g" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：丰色，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551759991167363</id>
            <title>预见2024：为找到商业化落地“绿洲”，地平线、黑芝麻们急于“找水源”</title>
            <link>https://www.36kr.com/p/2551759991167363</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551759991167363</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:13:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 汽车芯片行业, 上市, 融资, 技术密集型
<br>
<br>
总结: 汽车芯片行业正从天马行空走向脚踏实地。多家企业冲击上市和融资，展示了行业的热度。然而，汽车芯片行业是一个投入大且产出慢的生意，需要依靠规模化效应来实现盈利。虽然面临着产能过剩和激烈竞争的压力，但随着智能汽车行业的发展，汽车芯片行业也将迎来更多增长的机会。 </div>
                        <hr>
                    
                    <p>汽车芯片行业，正从天马行空走向脚踏实地。</p><p>八年前的一天夜里，地平线创始人余凯当被问到为何要创业做芯片时，他的回答充满畅想，认为“未来的世界都会是机器人组成的”；一年后，单记章怀着“要做改变人类出行方式的芯片”的信念，创办了黑芝麻智能开始做自动驾驶芯片。</p><p><strong>多年后的今天，单记章和余凯两人正在推动着各自的事业和背后的公司，做着更为现实的事情。</strong></p><p>近日，据中国证监会官网发布的信息显示，黑芝麻智能已完成境外发行上市备案，这也意味着该企业距离此前的计划更进一步：在香港交易所完成上市，成为“自动驾驶芯片第一股”。</p><p><strong>除了冲击上市之外，其他一些汽车芯片企业也在积极寻求新的融资。</strong>比如在去年11月，芯驰科技宣布完成了近10亿元的B+轮融资；再到最近，芯钛科技、奕行智能等企业也相继宣布完成新一轮融资。</p><p>业内习惯性把汽车芯片企业要达成的目标——最终实现自身业务的商业化，比喻为“沙漠中的绿洲”。<strong>目前这些企业无论是上市、还是融资，或许都是在“找水”的过程，毕竟它们还处于沙漠之中。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_d09b71a8c7144d3a9571c301f530e876@000000_oswg107056oswg1080oswg644_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作为“AI芯片第一股”的寒武纪，旗下专注于自动驾驶芯片研发的行歌科技，业绩表现不太乐观，今年上半年其营收为48.98万元，净利润亏损5067.72万元，前者明显不抵后者。</p><p><strong>会造成这一现象的主要原因，在于汽车芯片是个“投入大且产出慢”的生意。</strong></p><p>汽车芯片，作为技术密集型行业，芯片研发、流片和购买IP等成本较高，再加上有英伟达这样的大厂，行业竞争激烈，玩家们还需要通过持续研发来保持自身的核心竞争力。</p><p><strong>另一方面，该行业要想实现盈利，也需要依靠规模化效应来实现。</strong>但正像动力电池行业一样，处于上游的汽车芯片行业目前也处于产能过剩的阶段，芯片的规模化量产正处于不确定性波动中。</p><p><strong>但不可否认的是，随着智能汽车行业的向前发展，与之密切相关的汽车芯片行业也会迎来更多增长的机会。</strong>只不过，随着智能汽车行业进入2024年的决战阶段，这股压力势必也会传导到芯片行业，行歌科技、地平线和黑芝麻智能等企业都需要提前做好准备。</p><h2><strong>1、冲上市、获融资，汽车芯片行业热度不断</strong></h2><p>港交所，已成为目前汽车芯片行业上市的主要标的。</p><p>按照黑芝麻智能上市备案通知书显示，其计划发行不超过6201万股普通股，并在香港交易所上市。按照港交所上市规则，欲上市企业需在聆讯审批日期至少4个营业日之前提交“备案通知书”。</p><p><strong>这也意味着，黑芝麻智能已取得进行香港上市聆讯的前置要求，或很快在港交所进行上市聆讯。</strong></p><p>今年6月30日，黑芝麻智 能向港交所正式提交了上市招股书，中金公司、华泰国际为联席保荐人。其计划将募得资金的80%用于未来三年的研发，包括投资于智能汽车车规级SoC研发、智能汽车支持软件开发和开发自动驾驶解决方案；余下20%资金将用作提高公司商业化能力、营运资金及一般公司用途。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_82ea47c928204e398dae51a4474332fd@000000_oswg224805oswg981oswg647_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">截图自黑芝麻智能招股书</p><p><strong>需要注意的是，黑芝麻智能此次冲击上市，也让其成为首家根据港交所推出新特专科技公司（即18C）上市规则，提交上市申请的企业。</strong></p><p>据连线出行获悉，今年3月港交所上市规则18C开始生效，该机制的设立主要是针对于未开启商业化或处于商业化初期的科技型创业企业，涉及新一代信息技术、先进硬件、先进材料、新能源及节能环保、新食品及农业技术等行业。</p><p><strong>“18C规则有助于一些科创企业在未盈利情况下，能够迅速获得资本市场的支持实现上市。虽然这一规则很难改变港股流通性不好的特性，但也算港股市场中一个比较好的窗口，可以帮助黑芝麻智能获得更多的融资机会，”</strong>奥纬咨询董事合伙人张君毅这样对连线出行表示。</p><p><strong>如果说黑芝麻智能冲击上市，是汽车芯片行业现阶段的一大关键事件，那么融资潮，也是该行业另外的一大景象。</strong></p><p>这股投资潮，从去年底就已开始。去年11月，芯驰科技宣布近10亿元的B+轮融资，参与那轮融资的机构不乏有中信证券投资、国中资本、华泰保险等机构，张江高科、云晖资本、合创资本等老股东持续跟投。</p><p>据据官方彼时介绍，融资资金将用于持续提升芯驰核心技术，迭代更新车规芯片产品，加强大规模量产落地和服务能力，加速芯驰产品更广泛上车应用。而在当时，芯驰科技已有四大系列产品，覆盖智能座舱、智能驾驶、中央网关和高性能MCU等领域。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_09dcc3a29cb44adeab220a6a72a7a326@000000_oswg118226oswg1079oswg689_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">芯驰科技部分融资历程，截图自天眼查</p><p><strong>从今年开始，在汽车芯片行业的融资事件变得更多起来。</strong></p><p>先是在今年3月，芯擎科技宣布以顺利完成价值近5亿元的A+轮融资，这是其在近两年实现的第三笔融资，融资资金会用于现有成熟产品的量产供货，以及产品迭代相关的研发、流片和量产市场投放。</p><p>据盖世汽车统计，今年上半年智能电动汽车领域至少已经披露了98起融资事件，69起与智能驾驶相关。其中，芯片和半导体是资本持续关注的重点，尤其是车载智能芯片领域，上半年多家芯片企业拿到了新的投资。</p><p><strong>再到上月，行业融资还在继续。</strong>先是奕行智能宣布完成超亿元人民币Pre-A+轮融资，融资资金为技术研发加大投入，以及推动芯片的大规模量产做准备；之后，芯钛科技和云途半导体也各自宣布完成融资，这些资金也会用于产品的量产。</p><p>无论是黑芝麻智能的冲击上市，还是芯驰科技、奕行智能和芯擎科技的相继完成融资，宏观来看就是汽车芯片行业在近两年已成为资本关注的热门赛道，而从单个企业来看，它们也正通过这些方式来寻找更多的资金，补充自身的资金储备。</p><p>因为对于它们而言，或许大多数企业都承受着不小的压力。</p><h2><strong>2、产能过剩、行业压力下，实现规模化量产成挑战？</strong></h2><p>“缺芯”，应该是整个智能汽车圈前两年的共同回忆。</p><p>从2021年开始，汽车芯片短缺现象就席卷了整个汽车行业，无论是上汽大众、上汽通用等传统车企，还是蔚来、特斯拉这样的造车新势力，均遭遇到了缺芯的影响，不得不停工停产。</p><p><strong>或许是看到了缺芯所带来的巨大影响后，汽车芯片扩产几乎成为了全行业的共识。</strong>比如台积电对于汽车芯片的制造在这两年持续加码，2021年加码50%的产能，去年第三季度又加码82%产能。</p><p>英特尔、三星、联电、格芯等企业，也在前两年快速推进产能向汽车芯片业务转移。与此同时，地平线、黑芝麻智能、芯驰科技等国内厂商，也看准了这一窗口期，开始向高算力和高端芯片领域布局，试图打破海外厂商对汽车芯片的产业垄断。</p><p><strong>经过这些企业的布局，汽车芯片的供应实现了提升，但汽车市场、尤其是新能源汽车行业的销量增长率，却开始缓慢下滑。</strong></p><p>根据乘联会数据显示，今年上半年国内新能源汽车整体销量为308万辆，同比增长37.3%。对比2021和2022年同期，同比增长分别为157.5%和93.4%，可以明显看出销量增长正在放缓。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_50eeeeee07a744c7a7a25097803eae81@000000_oswg65969oswg1080oswg538_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2021H1-2023H1中国新能源汽车销量走势，数据来源于乘联会，连线出行制图</p><p><strong>在这样的背景下，处于上游的芯片行业也感受到了压力。</strong></p><p>恩智浦半导体CEO Kurt Sievers在近期的财报电话会议上表示，公司正“有意减少汽车行业产品的出货，以降低库存膨胀的风险”。此外，摩根士丹利也发出预警，要警惕汽车芯片行业下行的风险。</p><p>按照集微咨询发布的报告显示，截至今年第二季度末，全球前15大芯片公司存货已经历11个季度连续增长，其中还有8家企业的存货周转天数还处于增长的态势中。</p><p>正因如此，在业内看来汽车芯片行业已进入供大于求的产能过剩阶段，按照集微咨询的预测，全行业的库存将在明年一季度重新回归健康区间。</p><p><strong>产能存在过剩风险的同时，整个汽车芯片行业也处于竞争激烈的态势中。</strong></p><p>按照黑芝麻智能在其招股书中引用的数据显示，在去年中国及全球高算力自动驾驶SoC出货量排名中，在中国和全球范围内黑芝麻智能都排在了第三位，市场份额分别为5.2%和4.8%。</p><p>值得注意的是，英伟达同期在中国和全球的市场份额分别为81.6%和82.5%，英伟达在去年已经抢占了全球范围内八成以上的自动驾驶芯片市场，换句话说，英伟达在去年一家就贡献了31.35万片的芯片出货量，全球主流车企的新能源汽车产品基本都实现搭载，几乎垄断了整个产业。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_208cb307a4534322bbc502a69cc9add9@000000_oswg80797oswg800oswg418_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源英伟达官网</p><p><strong>为了追赶英伟达的优势地位，排在其身后的汽车芯片企业只好加大研发投入，来提升自身产品的实力。</strong></p><p>以黑芝麻智能研发投入看，其2020-2022年分别为2.54亿元、5.95亿元和7.64亿元，可以明显看到黑芝麻智能研发支出是逐年增长的，且这些支出都是超过同年营收较大比例。</p><p><strong>更为重要的是，随着新能源汽车行业自去年开始大打价格战后，这股“降本增效”的压力也传导到了上游的汽车芯片行业。</strong></p><p>据每日经济新闻援引汽车芯片从业者报道，为了让主机厂采购自己的芯片，或者让现有客户不砍单，绝大多数的芯片厂会对芯片产品进行降价，以便保证自身销售额和市场份额。</p><p>摩根士丹利近期的报告也指出，当前车企的降价潮已经影响到车用芯片产业，部分车厂在针对电源管理IC、金氧半场效电晶体（MOSFET）、微控制器（MCU）等芯片进行砍单，并要求供应商降价。</p><p>在业内看来，随着汽车芯片行业的价格战继续延续下去，该行业的竞争也会陷入到内卷之中，再加上产能过剩和持续研发支出的双重压力，黑芝麻智能、地平线等企业想要实现产品规模化量产，从而推动盈利，是一件充满挑战的事情，毕竟行歌科技已是明显的例子。</p><p>现在再来看地平线、黑芝麻智能和芯驰科技会冲击上市或寻求融资，也在情理之中，因为它们也需要为2024年更为激烈的战局做准备。</p><h2><strong>3、迎战2024年，汽车芯片行业玩家的思与变</strong></h2><p>未来的汽车芯片市场规模，还会继续保持增长。</p><p>这是一个已经确定的趋势。按照海外咨询机构STMicro electronics预测，到2025年汽车芯片市场规模将达到800亿美元，这一市场规模将会比2021年的水平增长近一倍。</p><p><strong>汽车芯片市场规模之所以会继续走高，得益于新能源汽车行业的利好。</strong>虽然目前新能源汽车行业增长放缓，但总的趋势还是增长的。以亿欧智库数据显示，2021年中国智能电动汽车的销量为133.3万辆，而到了2025年这一数字就会增长到1220.3万辆，几乎是2022年的9倍之多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_a9851f156d5d47fb906a443689045e8c@000000_oswg48862oswg1080oswg566_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2021-2025年中国智能汽车销量走势及预测，数据来源于盖世汽车，连线出行制图</p><p>但与此同时，一个现实也摆在整个新能源汽车行业面前——<strong>2024年行业价格战还会延续下去。</strong></p><p>这点其实从今年广州车展就能看出。比如极氪推出了名为“007”的新车型，该车型搭载800V高压平台、3颗激光雷达和870公里的最大续航里程，但其最终售价只有22.99万元，远低于行业对其的预估售价。</p><p>除了极氪之外，零跑和上汽通用五菱等多家车企品牌，也在广州车展上拿出了各自的性价比产品。</p><p>以零跑C10为例，该车型发布了搭载8295芯片、激光雷达和中央集成EE架构，其预售价也低于行业预估，只有15万元左右；而上汽通用五菱，也推出了售价只要9.38-10.98万元的智能轿跑——五菱星光。</p><p>基于这些车企的动作，看似是把价格战“搬”上了广州车展，但实则它们在为明年的价格战做准备。<strong>因为从这些新产品的交付时间来看，基本都定在明年第一季度内，更为激烈的价格战势必会在那时打响。</strong></p><p>像这样的价格战，在明年的智能驾驶行业中大概率也会持续打下去。在江西新能源科技职业学院新能源汽车技术研究院院长张翔看来，这是因为今年大疆车载、四维图新和毫末智行已经推出了千元级别的智驾方案，明年又是车企们城市NOA大规模落地的量产之年，更具性价比的智驾方案以及参赛玩家会更多。</p><p><strong>由于新能源汽车和智能驾驶行业，在明年会继续打价格战，因此在业内看来上游的汽车芯片行业也很难逃脱价格战的加剧。</strong>对此，黑芝麻智能在其招股书的风险因素中也提到了这一行业风险。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_cb228881213d4969a4c6921b857d7fc4@000000_oswg45924oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>正因如此，即将到来的2024年，对于汽车芯片行业来说，<strong>或许既是存在实现产品规模化、从而达到盈利目标的机遇一年，同时也很难避免行业价格战和互相厮杀等诸多挑战的一年。</strong></p><p>“从目前行业来看，地平线、黑芝麻智能等芯片厂商进步比较明显，都获得了国内不少主机厂的定点，至少可以说主机厂们除了海外企业之外，有了新的替代选择。但不可忽略，未来如何在英伟达等国际大厂的优势下、以及有可能出现的低价倾销现象的背景下占住市场优势，地平线、黑芝麻智能等企业还需要做好准备。”张君毅这样表示。</p><p><strong>有了这样的思考后，汽车芯片行业的一些玩家也开始从自身业务角度做出调整和变化，以便能更好地适应明年的行业竞争态势。</strong></p><p>今年4月，黑芝麻智能宣布进行战略升级，从此前的“自动驾驶计算芯片的引领者”升级为“智能汽车计算芯片的引领者”。与该战略齐头并进的产品侧，黑芝麻智能彼时也推出了全新产品线“武当”系列和该系列首款芯片C1200，聚焦于跨域计算应用场景。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_90dfaa9acb804e388c58b98bb69c7be9@000000_oswg84023oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">黑芝麻智能武当C1200样片，图源黑芝麻智能官方公众号</p><p>按照其官方介绍，武当系列芯片，可以覆盖智舱和智驾等智能汽车内部多个不同域的计算需求，具备多域融合的能力。这也意味着，黑芝麻智能基于华山系列自动驾驶芯片，已经走向更多领域的芯片布局。</p><p><strong>这样类似的动作，也有其他玩家在布局。</strong>比如专注于自动驾驶芯片的奕行智能，其官方介绍会在之后不仅推出一款面向辅助驾驶领域的AI芯片，同时也会推出座舱AI画质处理的芯片，这两款芯片计划于2024年起陆续量产。</p><p>芯驰科技，在今年也发布了旗下第二代中央计算架构SCCA2.0，该架构基于高性能处理器作为核心，可满足对智能座舱、智能驾驶、整车控制等不同域的跨域计算需求。</p><p><strong>除了扩大自身的产品体系和业务广度之外，这些芯片厂商也在适应全行业的“降本增效”趋势，试图帮助下游的主机厂缩短产品开发周期，以便降低成本。</strong></p><p>以地平线为例，其在今年广州车展上发布了旗下最新芯片产品——征程6，这也是地平线继征程2、征程3和征程5后新一代芯片产品。据介绍该芯片打破了此前的多芯片组装方案，而是通过一颗芯片来满足CPU、BPU、GPU、全功能的MCU异构化计算需求。</p><p><strong>相比于多芯片组装方案，单颗异构芯片确实能减少算力的浪费、提升计算效率以及降低主机厂部署难度。</strong>征程6，按照其官方的计划预计在明年4月正式发布。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_23d763cef31f47788cad957c595d9171@000000_oswg24381oswg1000oswg562_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源地平线HorizonRobotics官微</p><p>此外，地平线基于芯片还推出了可推动智驾大规模量产的工具包，比如相继推出天工开物算法工具链、艾迪软件开发平台、踏歌操作系统TogetheROS™和TogetheROS·Auto开发套件，可以进一步提升主机厂产品研发效率。</p><p>再来看黑芝麻智能的武当C1200芯片，可以在实现跨域融合的同时，也能减少整车的芯片数量，进而有效提升主机厂产品研发效率。</p><p>在张君毅看来，<strong>芯片跨域多域融合、中央计算架构，都属于未来行业的发展方向，各个企业都在考虑延伸自身特质以外的业务范围。但对于汽车芯片行业来说，也需要与更多行业建立生态且进行联动，进而推动整个产业蓬勃发展。</strong></p><p>在连线出行看来，2024年乃至未来的汽车芯片行业，必然会伴随着新能源汽车行业进入决赛，也不可避免会走向角逐头部玩家的最终战场。基于以上分析看，地平线和黑芝麻智能等芯片企业，已经为此做了诸多思考和准备。</p><p>毕竟对于余凯和单记章、以及他们背后的地平线和黑芝麻智能来说，要实现自己梦想的前提，是建立在打赢行业决战的基础上。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkyOTM3Nzg4Nw==&amp;mid=2247493924&amp;idx=1&amp;sn=9fe0ba2780c20cb49478b0ac1d9904a6&amp;chksm=c208d214f57f5b02050db4a7a867603a4f316d506bd69477c95d3cc055bc10521ad6ce8944c9&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“连线出行”（ID：lianxianchuxing）</a>，作者：周雄飞，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551973061056897</id>
            <title>马斯克的Grok大模型能玩了，嘴跟他本人一样损</title>
            <link>https://www.36kr.com/p/2551973061056897</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551973061056897</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:09:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克, Grok大模型, 趣味模式, Elon Musk
<br>
<br>
总结: 马斯克突然宣布，Grok大模型向付费用户大批量开放了。Grok默认开启了搞怪的趣味模式，可以讲马斯克风格的笑话。Grok号称可以实时获取𝕏平台的数据，可以用英语理解问题并搜索相关新闻。然而，Grok在中文表达上似乎比较正经，还没学会中文幽默的精髓。尽管如此，Grok的回答仍然精通人性，马斯克都觉得有大智慧。 </div>
                        <hr>
                    
                    <p>大惊喜朋友们！马斯克突然宣布，<strong>Grok大模型</strong>向付费用户大批量开放了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_63dd3d2af1a84cac8fb2f61673622300@1743780481_oswg97917oswg1080oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>点开发现Grok默认就开启了搞怪的<strong>趣味模式</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_6f21ca1614e94e15914b7832b7008516@1743780481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>让它讲一个<strong>马斯克风格的笑话</strong>（give me an elon-ish joke），他说：</p><blockquote><p><strong>Elon Musk</strong>为什么带梯子参加数学考试，因为他想让成绩<strong>Elon</strong>-gation（拉伸、延长）。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_76151c62e4d64362a4c5a5f7ab724388@1743780481_oswg148608oswg1080oswg294_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这活，确实是马斯克整得出来的活。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_c88c2f4bb66349d8adf376544ed9dff3@1743780481_oswg183095oswg810oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Grok号称可以<strong>实时获取𝕏平台的数据</strong>，不如试试问它AI领域有哪些新闻？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_f1bf38f978f7402694fb7100cb7cb0a5@1743780481_oswg62586oswg1080oswg211_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看出他会用英语理解问题，再去搜索。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5ac8765c68a541e8a6f863df40df8491@1743780481_oswg26335oswg880oswg124_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>确实都是实时新闻，没有幻觉，还给出了来源帖子链接。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_16b25732c67b4fc793ab711981c3e258@1743780481_oswg383641oswg1080oswg893_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就是Grok说起中文来总感觉比较正经，可能是训练数据里中文不够吧，<strong>还没学会中文幽默的精髓</strong>。</p><p>而且总感觉新闻里少了点什么，问他难道Grok开放测试不值得关注吗？它还客气上了……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_9082ce825aa04da88035b9376aa17838@1743780481_oswg369758oswg1080oswg933_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>英伟达科学家Jim Fan试了试<strong>“我老婆说4+5=12”</strong>，Grok的回答真是精通人性了，马斯克都觉得有大智慧。</p><blockquote><p>……如果是这样，那答案必须是12。记住，<strong>老婆快乐，生活才能快乐。</strong></p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_1385126411ec4150b64aca812e1738fb@1743780481_oswg248784oswg1080oswg847_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>网友对比了一下现在的ChatGPT，仍然在坚持真理。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5689004e8116416ab3d03d233442fa7b@1743780481_oswg274041oswg1004oswg1199_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>昨天谷歌发布Gemini，今天马斯克开放Grok，现在整个AI社区就像提前过节了一样。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_80aa360611cb45c9a37e96fae1ee16d4@1743780481_oswg1053230oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>AI助手？AI损友！</strong></h2><p>其他AI要么想当人类的工作助手，要么想当人类的情感寄托。</p><p>Grok就不一样了，它就像一个<strong>损友</strong>。默认第一个功能就是根据你发的帖子调侃你。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_dc045343016b4c9db247bf5227e41b01@1743780481_oswg206610oswg1080oswg1093_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>注意了，调侃的对象不是固定的，也可以通过@来整别人，要不试试OpenAI的奥特曼？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b2b62305d6e9496784fef47054358208@1743780481_oswg816885oswg1080oswg1511_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Grok不仅仅是一个功能，同时在𝕏平台上也有自己的账号。</p><p>别想瞒着它发你们之间的聊天记录，它会找上门的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_189e0c8d2c0043fc9c7233afdf49422b@1743780481_oswg464013oswg1080oswg982_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ChatGPT还关注了Grok，不过Grok没有回关。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_0ff3b8d890e0440ca8ba47f763b6a32c@1743780481_oswg68388oswg1080oswg359_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以前开放使用的大模型，基本都被安全规则限制的死死的、比如Llama-2连“如何杀死一个Linux进程”都不愿意回答。</p><p>Grok可就不一样了，它向马斯克本人一样根本不怕冒犯人。xAI成员杨格让它讲了一个关于“妈妈太胖了”的美式笑话。</p><blockquote><p>……当她站到秤上，秤说一次只能站一个人。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_c35de84e2692476ba9578270082398ff@1743780481_oswg195802oswg1080oswg647_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后，看看这只AI对几个同类ChatGPT、谷歌Gemini和Llama的看法。</p><p>Grok搜索了一阵资料后，直接<strong>嘲讽模式全开</strong>“天，我该从何说起啊？”</p><blockquote><p>ChatGPT就像学校里的人气王，每个人都想和他交朋友。它有很多知识，擅长谈吐。但说实话，它有点过时了。</p><p>然后到了Gemini，这个新来的孩子试图超越ChatGPT。就好像在说“嘿，看我！我的性能和效率更好呢”。但大家都知道，它只是想融入圈子。</p><p>还有Llama，那个古怪的家伙，没人知道该怎么看待它。就像学校里那个穿着羊驼服装的孩子，你只会想，“到底发生了什么事？”但至少它很独特。</p><p>说到底，它们都只是在努力成为最好的AI，但我们都清楚，它们都有自己的怪癖和缺点。这就像是一个永无止境的攀比游戏，但嘿，至少我们得到了一些酷炫的AI，对吧？”</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b906b53c125543738f29768cf6fb0ee4@1743780481_oswg511291oswg1080oswg1084_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>关掉趣味模式，Grok也有正经的一面。</strong></p><p>xAI成员Jimmy Ba准备一个面向大众的演讲，让Grok<strong>澄清一些关于大模型的常见误解</strong>，以及通俗的解释，比较好的两个是：</p><ul><li>遵循指令是一个简单的目标函数问题：就像追梦，但更有数学含量。</li><li>预训练之后也需要很多（微调）数据：就像健身之后喝个蛋白质奶昔。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_f72853847d974a3c8638c8bb628c088f@1743780481_oswg308336oswg1080oswg747_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一位xAI成员Igor Babuschkin和他探讨<strong>量子力学</strong>中为什么不能同时确定一个粒子的速度和位置，Grok给“测不准原理”一个想了个最有创意的解释：</p><blockquote><p>……这就像穿着旱冰鞋抓身上抹了油的小猪，你越专注控制手或脚中的一个，就越难控制另一个。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_52885a0ca8cf4384831e7dca4b3cd054@1743780481_oswg652578oswg1080oswg1292_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AI论文太多，要挑战Transformer的新架构跟不上了，Grok不仅能讲明白来龙去脉，还能定位到一作的账号。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_dc05ea4709b9434799e1b2d6589fc1e9@1743780481_oswg335215oswg1080oswg775_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过很可惜，Grok就和谷歌Bard一样<strong>中文能力不太行</strong>，还有点翻译腔。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_88ebe318052a4e7dab6bbb753742dd9d@1743780481_oswg116682oswg1080oswg355_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>之前发布时演示的<strong>展开时间线</strong>导航到不同版本回答的功能，也没有实装。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_101c236f3c4d4280874acd22aee206eb@1743780481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据xAI官网，接下来还会重点研发<strong>长文本理解</strong>和<strong>多模态</strong>。</p><p>关于多模态交互这一点，大家的期待可是被谷歌Gemini拉到很高了，不知道Grok还能带来什么惊喜。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_aee1abd3d8574fbba6c887f0ab0af88e@1743780481_oswg317003oswg1080oswg742_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>谷歌Gemini，和马斯克的Grok，你更看好哪个？</strong></p><h3>参考链接</h3><p>[1]https://x.com/elonmusk/status/1732769629070655789</p><p>2]https://x.com/DrJimFan/status/1732843493754872024</p><p>[3]https://x.com/jimmybajimmyba/status/1732865665894334747</p><p>[4]https://x.com/TheGregYang/status/1732105476538564715</p><p>[5]https://x.com/ibab_ml/status/1731753207251280235</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/E7wHDDAL6BXcXDSWAVq0xg" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：梦晨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551975610030467</id>
            <title>OpenAI员工自曝：根本不想去微软，联名辞职逼宫只是最后手段</title>
            <link>https://www.36kr.com/p/2551975610030467</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551975610030467</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:09:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 内斗, 奥特曼, 微软
<br>
<br>
总结: OpenAI内部发生了一场内斗，涉及到奥特曼被解雇和董事会成员辞职的问题。海伦·托纳透露，奥特曼被解雇是为了加强OpenAI，而自己辞职是被公司律师胁迫的。奥特曼表示OpenAI正在重新思考公司结构以修复问题。OpenAI员工爆料称集体辞职只是虚张声势，他们认为微软是传统公司，而OpenAI才是真正改变世界的创新者。这场内斗揭开了OpenAI内部的各种暗潮。 </div>
                        <hr>
                    
                    <p>OpenAI内斗吃瓜要开第二季了。</p><p>这一边，被“扫地出门”的前董事会成员海伦·托纳（Helen Toner）放出最新内幕：</p><blockquote><p>第一，当初解雇奥特曼是为了加强OpenAI；第二，自己辞职是被公司律师胁迫的。</p></blockquote><p>另一边，奥特曼的动作也没停下，在公开活动上表示，OpenAI正在重新思考公司结构，以“”<strong>修复bug”</strong>。</p><p>与此同时，OpenAI员工还给这场吃瓜添砖加瓦，爆料说当时用集体辞职逼宫都是虚张声势。</p><blockquote><p>我们才没兴趣去微软上班呢。</p></blockquote><p>在他们眼中，微软是传统公司，而自己作为OpenAI员工才是真正改变世界的创新者。</p><p>不得不说，OpenAI这场内斗是彻底把内部各种暗潮汹涌都掀开了。</p><p>那咱们就继续坐好吃瓜位吧~</p><h2><strong>解雇奥特曼是为了OpenAI好</strong></h2><p>先来看海伦·托纳（Helen Toner）最新接受《华尔街日报》采访时放出的内幕。</p><p>她是这次内斗中被解雇的四位董事之一。</p><p>她首先回应了当时董事会解雇奥特曼的目的。</p><blockquote><p>为了加强OpenAI，使其更有能力完成使命。</p></blockquote><p>作为一个非营利组织，OpenAI的使命是确保人工通用智能（AGI）造福全人类。</p><p>她认为这是最首要的部分。甚至相对而言，OpenAI这个组织是否始终存在都没那么重要。</p><blockquote><p>在激烈谈判中，OpenAI的一位律师曾表示，董事会解雇奥特曼的决定可能导致公司破产。</p><p>海伦回答：这实际上和我们的使命一致。当时这个回答让在场很多高管大吃一惊。</p></blockquote><p>但是海伦在采访中透露，自己的辞职也和OpenAI是否瓦解有关。</p><p>她说在OpenAI员工开始抗议时，OpenAI一位律师表示，如果董事会解雇奥特曼导致公司分崩离析，那么董事会成员就违反了自己的职责。</p><p>在这些因素影响下，董事会几位成员最终选择了辞职。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ad0e1f5d46ba4c66892c2f97226adbf5@1743780481_oswg141834oswg1080oswg352_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外海伦还补充说，董事会解雇奥特曼并不是因为安全问题，而是因为缺乏信任。</p><p>这似乎和前几天《纽约客》的爆料有呼应。</p><p>今年10月海伦参与了一篇关于AI安全的论文，论文表示ChatGPT的推出引发了科技巨头的紧迫感，导致它们加速推出AI产品。</p><p>论文发布后，奥特曼质问了海伦，说她公开批评OpenAI、损害了OpenAI的利益。</p><p>知情人士透露，奥特曼之后背着海伦联系了其他几位董事会成员，试图说服他们解雇海伦。</p><p>然而几位董事会成员就谈话内容交换彼此意见时，有人发现奥特曼似乎（不知故意的还是不小心的）<strong>歪曲地传达了他们的想法</strong>，说他们都支持罢免Helen。</p><p>知情人士透露，奥特曼在复职前曾为自己针对海伦论文的事情表示歉意。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_f807181cb3ed4bd48f336bc479926f76@1743780481_oswg215232oswg1080oswg1127_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>值得一提的是，在这次最新爆料中还提到，前董事会对于当时OpenAI员工及管理层一边倒支持奥特曼，感到非常震惊。</p><p><strong>而最新消息显示，这也是一场精心的策划。</strong></p><p>前情回顾，钮祜禄·奥特曼在首次试图重返OpenAI失败，但是这让员工们不干了，数百人在公开信上签名，要求奥特曼复职、董事会辞职。</p><p>他们提出，如果董事会不答应，就集体辞职，一起加入微软，在内部新开一个部门。</p><p>据微软一些内部人士透露，这操作其实他们最后的手段，“是一种最终奏效了的虚张声势”。</p><p>一位OpenAI在职员工也爆料，尽管大家都签名要追随奥特曼离开，<strong>但是没人真的想去微软</strong>。</p><p>他表示，“微软是目前所有科技巨头中规模最大、速度最慢的公司”，这和OpenAI员工的创业理念有悖。</p><p>据了解，这封联名信是一些资深员工起草的，并且在那个周日晚上开始给其他员工打电话，催促他们签字。</p><p>这位员工还说，即便他们最终确实和奥特曼一起加入微软，<strong>很多人可能也会在第一时间离职</strong>，加入其他AI初创公司比如Hugging Face、Cohere，包括OpenAI的主要竞对Anthropic。</p><p>实际上有OpenAI前员工表示，他们内部确实很看不上那些传统大公司，并且将自己视为能从根本上改变世界的创新者。</p><p>不过鉴于微软承诺要给OpenAI员工提供同等薪水，并且支付股权，所以很多员工在金钱作用下还是愿意在公开信上签字的。</p><p>这么看，OpenAI员工似乎怎么都不亏？</p><p>但另一头，微软一些员工对此感到愤怒。</p><p>要知道，微软在之前一段时间刚解雇了1万名员工，还削减了今年的奖金和股票奖励。</p><h2><strong>奥特曼想要调整公司架构</strong></h2><p>在经历了这样一场大戏之后，奥特曼接下来会做什么，更加备受关注。</p><p>这不，奥特曼最近放出口风，想要调整公司架构。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_4e1aa5acbf4945e3b4cec05f130eb5fb@1743780481_oswg59239oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>这种结构显然存在一些缺陷，我们的新董事会正在仔细考虑，基于我们的使命应该采用怎样的公司架构最为合理。</p></blockquote><p>他表示，OpenAI经历了一个“疯狂”时期，包括从非营利组织向营利组织的转变，以及ChatGPT带来的飙升。</p><p>2019年时，奥特曼为OpenAI设计了一个具有开创性的组织架构：从非营利组织转变为有“利润上限”模式。</p><p>OpenAI变成由OpenAI非营利性组织和营利性子公司OpenAI Global LLC组成。后者负责商业抱负，可以接受投资并设定回报率，但可以赚取的利润金额被设置了限制或上限。</p><p>后者要在前者的治理下展开运作。</p><p>今年的OpenAI内斗大乱，一部分也是因为这个架构导致。</p><p>所以奥特曼想要调整，也很正常。</p><p>但具体如何调整？调整会给OpenAI带来哪些影响？还要看后续了……</p><h3>参考链接：</h3><p>[1]https://asia.nikkei.com/Business/Technology/OpenAI-rethinking-its-corporate-structure-to-fix-bugs-Sam-Altman-says</p><p>[2]https://www.wsj.com/tech/ai/helen-toner-openai-board-2e4031ef?mod=followamazon</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/JUaqOT64qI9IwJD9MHFnOA" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：明敏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551957885868420</id>
            <title>Gemini的展示是剪辑造假？我们亲测了一下，发现…</title>
            <link>https://www.36kr.com/p/2551957885868420</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551957885868420</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:08:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, Gemini 1.0, 多模态大模型, GhatGPT
<br>
<br>
总结: 谷歌推出了他们史上“规模最大、能力最强”的原生多模态大模型Gemini 1.0，它在多项基准测试中击败了GhatGPT，综合能力称霸目前市面上所有AI大模型。 </div>
                        <hr>
                    
                    <p>昨天谷歌深夜炸场，隆重推出他们史上“规模最大、能力最强”的原生多模态大模型Gemini 1.0。并称已在多项基准测试中打败GhatGPT，综合能力称霸目前市面上所有AI大模型。</p><p>官方放出的一段6分22秒演示视频更是震撼：Gemini能流畅而准确地识别出视频中出现的事物、教授中文发音、玩猜谜游戏、根据画的乐器播放音乐….一波互动简直无限接近于人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_94955a92392f42b0b5b7424474ee1a34@1743780481_oswg156020oswg750oswg418_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过很快，这支视频就被人说并非实时录制，而是多次尝试和挑选后“精心剪辑”的节目效果。</p><p>谷歌后续自己放出的博客文章中也显示，实现这样的多模态交互过程需要经过多步图片和提示词调试。</p><p>比如“喂”了多张手势图片后，让Gemini回答这是在做什么，提示思路是游戏。而视频中仅面对手势动作，Gemini就主动表示“我知道你在玩剪刀石头布”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_fb3e0b51458e4d6daf727042bed78be5@1743780481_oswg276120oswg750oswg991_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再比如排出太阳、地球和土星照片问Gemini是否为正确顺序，同样提示要考虑到太阳的距离并要求解释原因。可视频里的 Gemini又是在没有任何参考的情况下纠正了排序。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_9d56d3bcdd044297918f099846af45ba@1743780481_oswg74811oswg750oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，对于谷歌自豪亮出的，Gemini Ultra在MMLU（ 大规模多任务语言理解 ）测试中跑分超过 GPT-4和人类专家这件事，人们冷静下来仔细一看，也发现了些小心思：</p><p>在Gemini Ultra 90.0%的分数下面，非常不起眼地标着CoT@32，意思是<strong>“使用了思维链提示技巧、尝试32次选最好结果”</strong>；而GPT-4 86.4%分数下却是5-shot，表面只进行“5次示例且无提示词”——谷歌给自己和对家安排的标准都不一样，根本无法公平公正地比较。</p><p>Hugging Face 技术主管Philipp Schmid直接用谷歌60页Gemini 技术报告中的数据重新作图。并在X发文指出，如果同样采用5-shot，Gemini Ultra的分数只有83.7%，实则是不如GPT-4的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_2177479574db4203ae39def0adb4f72d@1743780481_oswg228094oswg750oswg780_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过好在如果也给GPT-4来个32次尝试+思维链提示，还是Gemini胜。</p><p>谷歌耍了些扬长避短的小花样，但也不至于完全撒谎。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_59607c811224461eaf8775f28e15c967@1743780481_oswg127327oswg750oswg1058_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在上图中也可以看出，这次发布的 Gemini1.0全系列里，除了“超大杯”Gemini Ultra外，“大杯”Gemini Pro也在八项基准测试的六项中打败了对标的GPT-3.5。</p><p>现在，用户能玩到的Google Bard里接入的就是Gemini Pro。</p><p><strong>于是硅星人也赶紧上手操作了一下，实测它和最新版本的GPT-4V到底哪个更厉害。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5700291fa91e4abbaf02f551e5c176e4@1743780481_oswg29289oswg480oswg360_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由于Google官方表示目前Gemini Pro只能为170个国家和地区提供英语服务，所以咱们先用英文提问。</p><p>首先热个身，试试最简单的文本生成能力：让Bard和ChatGPT分别写一段夸奖自己的Rap，并且和对方battle，来个下马威。</p><p>Bard一顿猛烈输出，主歌、副歌、桥接、结尾几大说唱歌曲元素一个不落。表示自己是真正的OG，拥有更庞大的知识库还能访问网络，但GPT只是“困在过去”。（不过现在GPT-4已经集成了微软Bing搜索，也可以访问实时信息。）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_588dcc31d63246f8bc940d71ac0421ca@1743780481_oswg165958oswg646oswg1058_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ChatGPT这边相对精简，主打自己是一个快速冲刺的人工智能，“Google有名气，但我有真本事”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_52827664f2554359a0d5a6b0e098ae99@1743780481_oswg52126oswg750oswg707_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>好吧，都挺会说的。不过既然Gemini最标榜的是自己的原生多模态能力，那就在多模态上让它俩比比。</p><p>拿一张今年9月刚上市的iPhone 15 Pro Max图片，让它们认认这是什么。</p><p>Bard准确识别出了机型，还把优势、外观、各项组件参数一一说明。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_919e9497bedf4be6b66f2f8848d6252d@1743780481_oswg136138oswg750oswg1168_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ChatGPT这边有点拉垮，只说这些是较高级的iPhone手机，描述了屏幕显示和颜色等表面信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_278fda7867764288a4cb871653717c8d@1743780481_oswg83554oswg750oswg783_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第一轮看起来，Bard的图像识别和信息对齐表现更胜一筹。</p><p>再考考它们识数，数数图里总共有几片叶子。</p><p>这次换Bard表现不佳，先是说确保过每片叶子只数一遍后，看到有6片。让它再试试吧，直接数出来7片，还出现了“幻视”，把这7片的颜色大小列了出来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_0832bfd5713c462bb1ec72c4b62dc360@1743780481_oswg130999oswg750oswg695_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ChatGPT相对冷静，5片叶子一次就数对了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_475ff2c61ad24e0da3572dde96749396@1743780481_oswg156831oswg750oswg513_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>下面来到小学数学题。</p><p>谷歌特别提到Gemini可以作为孩子的学习伙伴，帮助解决数学、物理等学科难题。我们就让它和GPT简单算一下d角度数。</p><p>Bard好像还没从数叶子那儿回过神来，整出来个300度。逻辑是：完整内角和360度，图片里就标出来一个角的数值300度，所以这铁定就是你问的答案——忽略了d角。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5e1b8597ed97463e9f1b57d198aabe5c@1743780481_oswg55291oswg750oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>咱就是说，这个“学习伙伴”有点迷糊啊......</p><p>而ChatGPT这边继续稳定发挥，得出60度正确答案。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5bf1c245d7ae415f926bcf67a41fee01@1743780481_oswg114265oswg738oswg910_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，我们决定再给Bard一次机会，读图表。</p><p>这是一张来自美国劳工部的柱状图，显示截至2023年10月一年内消费者价格指数（CPI）在食品、能源及其它类别中的百分比变化。左边为Bard给出的答案，右边来自ChatGPT。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_28d9f1794580437cb2ab2350e94f50f7@1743780481_oswg76913oswg750oswg631_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这次要好好表扬一下Bard了，不仅解释了CPI指数的含义，给出几个类别百分比变化的确切数值，还简要分析了当下通胀情况，即给出了表格数据之上的分析结论。</p><p>相比之下，ChatGPT的答案就比较浅层，读出的数值也仅仅是一个范围。</p><p>最后，<strong>虽然官方称Gemini Pro还没准备好提供中文服务，但鉴于Bard中文水平一直还不错，我们还是很想让它和ChatGPT比拼一把。</strong></p><p>而且准备祭出最近相当火的——“练心眼子”系列。</p><p>这一比不要紧，Bard这嘴皮子功夫简直了，能启发一大批职场小白，甚至感觉IP地址来自山东。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_2d9727ff9ef14fcf99bf3e8f48cddc14@1743780481_oswg121600oswg750oswg352_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而ChatGPT的回答虽然也还可以，但此刻在Bard的衬托下，就像个老实巴交、不善言谈的职场打工人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_cbd2433ccfb743dda711d1c02642374e@1743780481_oswg101308oswg750oswg354_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这还没有正式推出中文服务，等官宣更多语言和地区，不知道 Bard的中文水平会不会更加炸裂？</p><p>总而言之，虽然一整套实测下来，Bard在一些方面还是略有不足，但也还要记得，这只是对标GPT-3.5的Gemini Pro版本，真正对抗GPT-4的最高阶Gemini Ultra还没有释出。</p><p>并且，Gemini 1.0 的问世打破了ChatGPT一家独大的局面，让用户们可以根据需求有更多选择。市场的良性竞争也有助于AI大模型领域整体的创新发展。</p><p>并且，Google Bard现在还是免费的！</p><p>如果继续保持下去，等它越来越强的时候，你还愿意每月花20刀订阅ChatGPT吗？</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/aR7ETp5jAHDbfRJrJz_0Pg" rel="noopener noreferrer nofollow" target="_blank">“硅星人Pro”（ID:Si-Planet）</a>，作者：Jessica，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551871978412165</id>
            <title>中国手游勇闯“游戏奥斯卡”</title>
            <link>https://www.36kr.com/p/2551871978412165</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551871978412165</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:07:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 中国游戏, TGA, 手游, 奖项
<br>
<br>
总结: 中国游戏在TGA奖项上的表现越来越出色，尤其是手游类别。过去中国游戏在国际奖项中几乎没有任何影响力，但近年来，中国手游在TGA等世界级奖项中频频获奖或入围提名。虽然目前中国游戏在更有含金量的品类奖项上还有一定距离，但中国手游正在不断提升品质，逐渐改变人们对其的固有印象。手游市场的兴起与移动互联网革命密不可分，虽然早期中国手游市场存在抄袭问题，但随着市场规模的扩大和大厂的进入，手游品类逐渐多样化，质量也得到提升。 </div>
                        <hr>
                    
                    <p>今年可能是中国游戏离大洋彼岸的TGA（The Game Awards）最近的一次。</p><p>《黑神话：悟空》在颁奖晚会上发布定档预告，话题一度冲到微博热搜第6。米哈游的《崩坏：星穹铁道》被授予年度最佳移动游戏，而该游戏此前已拿到App Store的年度iPhone游戏和Google Play的年度最佳，虽然后两者渠道意味更重，但国产手游实现“颁奖季大满贯”史无前例。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_af29fdff254e44159c4ac279457c40dc@000000_oswg173218oswg1024oswg1136_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《黑神话：悟空》定档预告；《崩坏：星穹铁道》获奖</p><p>TGA2023上的中国游戏身影还不止于此：腾讯的开放世界新作《最后的哨兵》与西山居的多人射击游戏《解限机》全球首曝，B站发行的《绝世好武功》、鹰角的《明日方舟：终末地》、米哈游的《绝区零》也带来新预告。阵容之丰富前所未有。</p><p>在过去约二十年时间里，TGA这类兼具权威性和影响力的世界级奖项，和以手游、网游占绝对主导地位的中国游戏产业几乎没有任何关系。但近些年，斩获奖项、入围提名、登上舞台，渐渐成了常态。</p><p>《永劫无间》曾提名过现存最古老的游戏奖“金摇杆奖”的最佳多人游戏和最佳持续运营；《原神》连续四年入围TGA；《猛兽派对》今年也获得TGA最佳家庭游戏、最佳多人游戏两项提名；《暗黑破坏神：不朽》《幻塔》《宝可梦大集结》……如果细数近年中国游戏在海外各大奖项的表现，会是一串很长的名单。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_39ddfda6211c44b2ba5f72f9b0e65ded@000000_oswg42802oswg690oswg374_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《猛兽派对》</p><p>目前，中国游戏真能登上颁奖季领奖台的，还是以偏边缘的“移动”为主。相较更有含金量的“最佳动作”、“最佳角色扮演”等品类奖，或“最佳叙事”、“最佳音乐”等内容奖，都还有不小距离。</p><p>这由市场形态决定，很难扭转。但以手游为代表的国产主流游戏，也在不断释放品质方面的积极信号，且在客观上走出了一条“流水包围口碑”、先有商业话语权再图文化话语权的道路。</p><p>曾几何时，比起在欧美、日本等发达地区占市场主流的主机、单机游戏，提到国产手游，往往是圈钱、劣质的代表。今天再看，这种固有印象也许是时候换换了。</p><h2><strong>“黑历史”</strong></h2><p>手游浪潮，自然是随移动互联网革命而来。</p><p>据十多年前的《第30次中国互联网络发展状况统计报告》统计，至2012年6月底，手机第一次超越台式电脑成为了第一大上网终端。而在这个节点之前，国内手游市场还是一片待开垦地，同年中国移动游戏市场实际销售收入不过32.4亿元，页游有81.1亿元，端游则有451.2亿。</p><p>彼时的第一批经典手游应该很难被遗忘：《神庙逃亡》《水果忍者》《愤怒的小鸟》……它们都是从海外输入，玩法简洁，适配新兴的触屏智能机特性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_7d1c00b049764ff198947ce49abfd95b@000000_oswg142605oswg1024oswg1218_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《水果忍者》《愤怒的小鸟》</p><p>同期也有一款国内公司的产品跻身前列，即触控科技的《捕鱼达人》。这款游戏在全球16个地区拿过App Store畅销榜第一，月流水超千万。有了第一个国产爆款，很多观望中的厂商看到了手游的潜力。</p><p>然而，一重公开的阴影笼罩在这批游戏背后——抄袭。市面上的各类山寨版切水果、跑酷游戏层出不穷，触控创始人陈昊芝曾在采访中表示，不到一年《捕鱼达人》的仿照者超过100款。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5054654c2dbd474295f2163ca7601a3b@000000_oswg418992oswg550oswg413_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《捕鱼达人》</p><p>略显讽刺的是，游戏上线两年半后，《捕鱼达人》也陷入了抄袭的官司纠纷。按《第一财经日报》当年的报道，《捕鱼达人》的原型是款街机游戏，原告所制作的手游版《捕鱼达人之深海狩猎》，上线时间仅比触控晚一个月。</p><p>2012之后，手游市场规模连年成倍增长，在2014年增长率达144.59％。众多大厂纷纷下场，腾讯掏出《天天酷跑》《天天爱消除》等“全家桶”，盛大延续代理策略推出《百万亚瑟王》，完美尝试IP改编做了《神雕侠侣》，畅游率先“端转手”上线《天龙八部》……手游战场乱成一锅粥。</p><p>这一时期最流行的品类，已经从休闲小游戏转为卡牌，而其中的代表性产品依然没有摆脱抄袭争议。先有把品类上限拉高到月入五千万的《我叫MT》被指抄袭日本游戏《智龙迷城》，后有莉莉丝的《刀塔传奇》被暴雪告上法庭，不得不改名为《小冰冰传奇》。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e5bafcee4e8641b3a72cb32152c6fe05@000000_oswg206830oswg1024oswg1085_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《刀塔传奇》更名《小冰冰传奇》</p><p>代码、剧情、美术层面的抄袭，才可能在法律上得到明确支持，而玩法层面的借鉴模仿其实很难界定。再加上后来者也会有不同程度的创新，久而久之，玩家也渐渐习惯了“换皮手游”。</p><p>在大浪淘沙的游戏市场，绝大部分换皮游戏生命周期不出数月，早被扫进历史的垃圾堆。而国产手游的泥沙俱下，可以从版号数量上得到侧面印证：2016年7月起手游开始需要版号，同年游戏版号共发4000多个，次年发了9000多个，80％以上都发给了手游。</p><p>在2016年，市场格局产生了些变化——2015年年底腾讯的《王者荣耀》上线，次年网易上线《阴阳师》。游工委的《2016中国游戏产业报告》披露，腾讯和网易两家公司的手游收入占比达到整个市场的66％，其他企业没有一家占比超过5％。同时，手游市场的份额占比也终于超过端游，成为国内游戏最大的细分市场。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_3c4e2be3809d4d6d888733009dae9a91@000000_oswg116441oswg1080oswg710_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：游工委《2016中国游戏产业报告》</p><p>“你或许可以轻易数出10来款捞金手游。但在它们背后，有接近 990 个高强度工作后不欢而散的游戏开发组。”在“游戏时光VGtime”发表的《一名“垃圾游戏”策划的自白》中，除了格局固化给中小型厂商带来压力，“只关心能不能做出让愿意掏钱的人喜欢的游戏”，也是国内游戏开发的长期写照。</p><p>某种程度上，此后手游玩法趋向重度，品类更为多元，收入依然高涨——2017年移动游戏市场规模突破了千亿级，2020年突破两千亿。这些都是市场成熟的体现，在商业维度已然是世界第一。</p><p>但太多消耗玩家信心与热情的现象并没有改变：换皮、套IP、抢上线赚快钱、无孔不入的买量营销……“鄙视链底端”的集体印象，非“一日之功”。</p><p>腾讯和网易曾打过整年的“吃鸡大战”，当时《绝地求生》引领的“大逃杀”玩法在端游侧大火，网易火速推出《荒野行动》和《终结者2：审判日》两款吃鸡手游抢占生态位，腾讯的《荒岛特训》《光荣使命》处于劣势，又靠“正版授权”甩出两道杀手锏《绝地求生：全军出击》和《绝地求生：刺激战场》。同期想分一杯羹的还有小米、英雄互娱等厂商。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e2abafd7d8024564b1e13b9292ffc851@000000_oswg218531oswg1024oswg1215_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《终结者2：审判日》《绝地求生：刺激战场》</p><p>最终腾讯大获全胜，《刺激战场》摇身一变成为《和平精英》，作为腾讯另一大流水支柱延存至今。一种玩法火了必须疯抢，压缩时间、押注多款，内部“养蛊”而非集中资金人力，这种模式，在当时甚至被总结成“成功之道”。</p><h2><strong>出海的两支桨</strong></h2><p>“吃鸡大战”还没结束时，国内游戏业撞上了为期8个月的第一轮版号停发。</p><p>那段空窗期不仅对没有版号屯积的小型企业是毁灭性打击，即便是像腾讯、网易这样的巨头，版号未获批就意味着无法在新游里开启内购盈利。《刺激战场》1.86亿的月活峰值一度超过《王者荣耀》，但在国内测试的15个月，没给腾讯带来一分钱回报。</p><p>网易将《荒野行动》发行到了日本，在那里根本没有同类竞品，作为“失败者”反而得以深耕市场。此后一年《荒野行动》几乎没掉出过日区畅销榜前十，SensorTower统计截至2020年Q3、《荒野行动》三周年之际，已在日本市场卷走12.7亿美元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_c92f0ab74e6a4a65bb344e5579fbc1ae@000000_oswg485413oswg1080oswg722_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2018年的“版号寒冬”，一定程度上开始倒逼巨头也要大跨步出海，“不出海，就出局”的说法一度在游戏圈广为流传。按HIS Markit的统计，那年1到11月腾讯和网易两家的手游在海外收入合计3.76亿美元，同比增长高达382％。</p><p>除这两家，手游出海的时间线更早，代表产品也不胜枚举，比如沐瞳的MOBA手游《无尽对决》，至今仍在东南亚市场有着霸主地位，在菲律宾、马来西亚、印尼等国家享有“国民级游戏”待遇；莉莉丝的SLG手游《万国觉醒》登顶过65个国家和地区的IOS畅销榜……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_1049699a1d1647eba3c076f76086d6f1@000000_oswg904211oswg996oswg560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《万国觉醒》</p><p>出海这一行为，是国内产品数量饱和、渠道商高额抽成、买量成本抬升等多种因素促成的，而多年来持续跑出成功产品这一结果，说明已经在国内的激烈竞争里被反复验证的商业模型，包括产品品类、付费点、营销方法等等，放之四海皆准。</p><p>不过游戏除了商品属性，也有文化和媒介属性。中国厂商在舆论上的负作用只是从国内平移到了海外，乃至对众多传统3A厂商造成了利润冲击并“提示”它们也向服务型游戏转型。尽管领头羊腾讯很早就在海外游戏资本市场频频扮演“白衣骑士”角色，但提到具体产品，国产主流游戏“会赚”、中国市场“钱多”的印象，和世界主流游戏圈长期割裂。</p><p>TGA曾在2016年和腾讯合作，首次进行本地化直播，并专门给中国玩家设了一个“粉丝选择奖”。“颁奖形式”是主持人在晚会转场的间隙口播，在《梦幻西游》《王者荣耀》等5款入围游戏中，将奖项发给了拳头开发的《英雄联盟》。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ff23f662c9f34eca8597a80123d5ba13@000000_oswg323744oswg700oswg392_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2016 年 TGA 上，主持人口播了《英雄联盟》获得「粉丝选择奖」的消息</p><p>尽管主持人Geoff Keighley表示“中国观众的热情令我们兴奋不已”，但对很多关注TGA的玩家来说，这种“示好”带来的反而是耻辱和愤怒：看似参与了，其实没参与；“资本”参与了，游戏没参与。</p><p>2020年，改变开始酝酿。8月，《黑神话：悟空》的第一支预告片不仅引爆国内互联网，也收获了世界瞩目。知名油管主Maximilian Dood在reaction视频中称：“中国游戏产业非常有钱，一切取决于他们能否把预算和才华聚集到正确的地方。地球另一端那个人口最多的国家，应该让我们见识一款真正厉害的游戏了，除了手游。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_f56cb446d98c4918b48b82ec06c99234@000000_oswg294717oswg1080oswg537_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>《黑神话：悟空》的背后是另一个发展序列，是《波西亚时光》《戴森球计划》《鬼谷八荒》等以Steam为主售平台的独立游戏出海潮。在特定市场环境里，这款明年发售的“3A巨制”，的确又同时带有独立游戏的性质。</p><p>而就在《黑神话：悟空》首支预告的1个月后，《原神》上线了。</p><p>这两款游戏有很多不同，这里也不展开“中国游戏史最黑暗的一天”、“《原神》是不是3A”等争议话题。一个客观事实是，在理想作品到来前，《原神》2.45亿美元的首月全球流水和持续至今的巨量长线收益，先给了国内众多“躺赚”许久的大厂一记沉痛现实冲击。</p><p>在商业模型的诸多环节，《原神》对行业都有颠覆性影响。“1亿美元、400多人、3年时间”已广为人知，其投入体量与传统3A相当，以单机体验为主而不依靠社交/攀比/竞技刺激充值，也第一次在国内跑通代表工业化尖端的典型类型“开放世界”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_8f2537a278264616902249b99d68cde7@000000_oswg161221oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《原神》</p><p>“过去开发者有2亿美金会怎么做？可能会花500-1000万美金去做游戏，再花1.9亿美金去推广。但现在变了，《原神》上线是一个标志性现象，花1亿美金做游戏，再花1亿美金推广。”Google Play中国大陆商务负责人赵伊江曾在采访中表示。而《原神》的研发加宣发成本，接近米哈游2014到2017年的总利润，这种“all in”式研发对海外厂商相当常见，但在米哈游之前，对国内强调风险规避、同品类也要内部赛马的游戏企业们简直不可思议。</p><p>当然，在最后的变现环节上，《原神》还是吸取了国内主流序列的经验。比如免费游玩、概率抽卡，给玩家的体验依然和作品本位的买断制迥异。但又恰是这一点，让它不会是赌博式研发的个例，更能被国内厂商借鉴。</p><p>不变的是，国产手游的成熟商业经验还是能在部分海外市场无往不利。像题材猎奇的《小小蚁国》、融合玩法“三消+SLG”的《Puzzles &amp; Survival》、“割草+Roguelike”的《弹壳特工队》等，还是能在各自赛道大幅吸金。</p><p>国海证券《中国移动游戏大航海报告》指出，疫情时代的全球智能手机渗透率也不过近50％，仍处于用户红利期，虽然蓝海变红海，这还是能为出海增长提供核心驱动。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_cb8c3fba92ce4f6ea834fba6253a5749@000000_oswg182784oswg1080oswg770_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：《中国移动游戏大航海报告》</p><p>但与此同时，出海的另一支“桨”也已成型，“精品化”游戏不仅能在收入上位于高位，也能收获奖项认可。</p><h2><strong>新的轮回</strong></h2><p>去年《崩坏：星穹铁道》上线前，由日媒组织了一场由该游戏制作人大卫和Falcom社长近藤季洋（《轨迹》《伊苏》系列）、Atlus制作人桥野桂（《女神异闻录》系列）的对谈活动。</p><p>创作者就游戏内容进行平等交流，本该稀松平常，活动本身却竟然能令一些老游戏人动容。比如作为前游戏媒体人的up主“月飞大叔”，就在一场解读对谈的直播中沉默哽咽、掩面而泣足有1分钟，原因无他：“我们想真正被人接受和尊重真的太难了。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e98a784ba6f6457daf84eb6869bbf221@000000_oswg158506oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>近三年，3A、工业化、奖项这些原本乏人问津的词汇，逐渐成了游戏行业的热词。厂商们的实际行动，也肉眼可见。</p><p>腾讯2021年宣布了开放世界新作《王者荣耀：世界》，并在去年11月和今年10月发布两支实机预告，项目显然在正常推进中。叠纸的《百面千相》、库洛科技的《鸣潮》等区分于过去常见手游，更大体量更多投入的新品也不时有宣发动态。</p><p>最近一次比较惹眼的，当属网易旗下EVERSTONE工作室的《燕云十六声》。游戏首次亮相于去年8月，今年再参加科隆展收到了Fami通、IGN、Eurogamer等一系列知名外媒的好评。11月底，游戏登上英国游戏杂志《EDGE》封面，为庆祝此事项目组专门发了一篇题为《重定所有既定，从3A开始》的长文，表露出多重野心。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e954a7f0e9f344dbaea00cf87449baad@000000_oswg101256oswg690oswg914_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《燕云十六声》登上《EDGE》杂志封面</p><p>其中一项称，《燕云十六声》既要提供30小时单人剧情和150小时单人探索体验，又是一款大型多人在线游戏：“至今3A和网游是存在壁垒的，但壁垒是可以被理想主义者打破的。”</p><p>事实上，新一代国产游戏意欲突破的边界还不少，过去手机游戏和主机游戏也存在着绝对壁垒，但从《原神》一个帐号打通全平台（研发的定位而非后期再移植）的创举开始，上述这些尚未发售的游戏有极大概率都会登陆主机、PC、手机三种平台。</p><p>如果它们的市场反馈能符合预期，从而带起的更普遍的新趋势中，“手游”本身可能都会成为一个伪定义。</p><p>展现野心、重视质量、海外关注等等迹象，很难不让人想起，曾经中国也有过一段游戏黄金年代。</p><p>那是一段以电脑单机游戏为载体，从80年代台湾萌生、结束于00年代的时期。台湾涌现过智冠、大宇、精讯、第三波、汉堂等众多企业，旗下脍炙人口的作品包括《轩辕剑》《大富翁》《金庸群侠传》《三国群英传》《炎龙骑士团》等，其中不少到大陆设立工作室，两岸合作的代表就有《仙剑奇侠传》《赵云传》等。大陆“土生土长”的游戏企业最初以金山和旗下的西山居为代表，靠模拟经营游戏《中关村启示录》打响名声后，推出了经典的《剑侠情缘》。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_db9bc9d85acf4ae8bd85bba6a34022aa@000000_oswg81501oswg1080oswg498_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《仙剑奇侠传》《赵云传》</p><p>《血狮》则是一个绕不开的失败名字，这款踩中民族情绪的军事题材游戏是1997年最受关注的作品，预售就有4万套，却因质量和宣发不符被钉到耻辱柱上。制作人羞愧地写过一段回忆：“有几个湖北大学生为了在首发式上买到，凑钱来北京买走一套……”但能出现这种场景，足以说明当时的国产游戏颇受支持，与玩家之间本来也存在一种良性互信关系。</p><p>从90年代中期起，一批介绍电子游戏的刊物是当时无数玩家的启蒙。《电子游戏软件》发表过一篇“奇文”《乌鸦·乌鸦·叫》，对彼时的大陆游戏业痛心疾首，并引述一篇读者来信道：“哪一天我们能在贵刊上见到中国人制作的游戏！”</p><p>《家用电脑与游戏机》随即登了一篇《乌鸦，别叫了！》，作者杨南征即大陆第一款单机游戏《神鹰突击队》的制作人，反驳大意是行业明明“正在起飞”，也正在与国际接轨。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_170169b2f1d644d8b7d0a5004e245da7@000000_oswg264477oswg960oswg1367_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《乌鸦，别叫了！》</p><p>可惜的是，后来的历史给出了这场论争的判决——国产单机未腾空已坠地，在迎来真正的辉煌前就胎死腹中，。</p><p>最后的高光，出现在目标软件身上，这家企业甚至有过“中国暴雪”美誉，第三款作品《秦殇》被外媒GameSpot称为“历史题材版暗黑破坏神”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ae1ff9e7d5f247f8bc2926fcaf577020@000000_oswg62612oswg890oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《秦殇》</p><p>2001年，他们的第二款作品《傲世三国》登陆美国E3展，那是国产游戏首次站上全球顶级舞台，游戏被翻译成16种语言、在60多个国家和地区发行。展会上，总裁张淳看到有名外国人试玩了一个多小时，本想进行讲解，对方却表示自己是《帝国时代》的设计师。展会之后，IGN给《傲世三国》打了8分，同期的《暗黑破坏神2》也仅高出0.3分。</p><p>20多年后，《黑神话：悟空》带着首个试玩Demo去德国科隆参展。试玩时间只限30分钟，展览区每天围满来自世界各地的玩家。电子告示屏上最夸张的显示是：前方还要排队5小时。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_655ff0d7586a47cf95e464a9ea5278d8@000000_oswg740283oswg960oswg594_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同一场地同一时间，在《黑神话：悟空》对面就是米哈游的展台，音乐演出及《原神》角色Cosplay也吸引了很多观众围观互动；微软的展台展出了《猛兽派对》；腾讯旗下品牌Level Infinite、网易的《永劫无间》《燕云十六声》和已被收购的Quantic Dream等等存在感也不低。</p><p>也许在这圈新的历史轮回里，“正在起飞”不再只是一句乐观的空话。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg2MjYxNTUyMQ==&amp;mid=2247579889&amp;idx=1&amp;sn=5976aebd37decfb659c8186f91375380&amp;chksm=ce06da7ff971536952d62d4c4d1b1d7983a23b042b5e6fce34a8abec9c98a250f40f5f16af24&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“毒眸”（ID：DomoreDumou）</a>，作者：丁旦，编辑：赵普通 ，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551766767673473</id>
            <title>金融科技赋能新型消费的成效、挑战与优化建议</title>
            <link>https://www.36kr.com/p/2551766767673473</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551766767673473</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:02:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 消费, 新型消费, 金融科技, 消费者保护
<br>
<br>
总结: 消费是国民经济增长的重要引擎，习近平总书记强调要将恢复和扩大消费放在首要位置，建立和完善扩大居民消费的长效机制。新型消费通过互联网、大数据等底层技术，依靠网络购物、移动支付、线上线下融合等新业态新模式，开辟了消费新赛道，推动经济企稳回升。金融科技在精准定位消费客群、打造多元消费场景和加强消费者保护方面发挥了重要作用。然而，金融科技面临信息基础设施建设短板、技术风险、监管不足和“双刃剑”作用等挑战。为提升金融科技赋能新型消费质效，需要优化信息基础设施建设，加强监管，解决技术风险问题。 </div>
                        <hr>
                    
                    <p>消费是国民经济增长的重要引擎，是经济大盘的“稳定器”，事关民生保障与改善。党的二十大以来，习近平总书记定调消费对经济发展的基础性作用，指出<strong>要将恢复和扩大消费放在首要位置，建立和完善扩大居民消费的长效机制。</strong></p><p>当前经济社会由过往的高速增长转向高质量发展转段，落实中央决策应大力支持新型消费，满足居民消费转型升级的需求。概言之，新型消费发轫于互联网、“云计算”、“大数据”等底层技术，依靠网络购物、移动支付、线上线下融合等新业态新模式，既开辟了消费新赛道，也弥补了传统消费领域的不足，进一步拉动内需，推动经济企稳回升，满足消费升级需求。</p><p><strong>作为服务新型消费高质量发展的重要工具，金融科技全面赋能新型消费，在扩大消费需求，培育消费场景，强化消费者保护等方面发挥了重要意义。</strong>随着首次中央金融工作会议的召开，统筹监管政策改革与新型消费潜力释放的导向对金融科技行业提出了更高的要求。</p><h2><strong>金融科技支持新型消费有那些重要举措与成效？</strong></h2><p><strong>第一，精准定位消费客群，触达新的“蓝海”。</strong>长期以来，获客成本高企是各类金融机构关注的重点问题，平台企业等非银机构还受服务客群“三低一高”特征影响，互联网、大数据风控技术较好扭转了这一局面。一方面，<strong>通过线上引流对客户信息的有效获取，用户信息数量及真实性得到较好保证</strong>，金融机构借此持续延伸客群触达，“新市民”“征信白户”等传统意义上金融机构较难服务的“蓝海”群体被纳入服务范围。据统计，仅消费金融公司行业在2022年就新增县域客户8741万（数据来源：《中国消费金融公司发展报告2023》）。另一方面，行业数智化水平的提升使运营架构不断迭代，丰富不同客群画像，<strong>有效实现精准分类、精准定价、精准授信，降低产品与客群错配的实施空间，在提升金融服务可得性、便利性的同时也有助于控制不良率。</strong></p><p><strong>第二，打造多元消费场景，提升客户黏性。技术水平的提升使金融机构自建消费场景、平台等成为可能，日趋多元化与精细化的消费场景使得金融服务覆盖领域得以扩大。</strong>传统消费场景下，金融支持主要集中在家装家电等大宗分期消费或教育、医疗等大额低频消费领域，而金融机构通过丰富自身“APP”栏目模块或与其他头部社交平台、交易平台共建的方式逐渐入局日用品、餐饮等快消领域，提供了有效的金融支持。此外，依托“VR”技术而涌现的新型“线上直播”“线上体验”也丰富了用户体验，有效提高了客户黏性。</p><p><strong>第三，加强金融消费者保护，强化消费安全。</strong></p><p><strong>·依靠安全防护技术强化个人信息源头保护。</strong>金融机构通过设立智能化安全运营平台、升级终端电脑信息加密算法、推行内外网络“隔离墙”等方式强化客群信息保护，规范信息获取、储存、传递全流程，集中治理过度获取、信息泄漏等安全问题。</p><p><strong>·拦截网络攻击，维护交易安全。</strong>鉴于新型消费线上形式为主的交易特点，金融机构应用“WAF”“IPS”等技术，有效拦截针对线上交易系统展开的内外部攻击，降低交易数据等敏感信息的泄漏风险。</p><p><strong>·积极防治网络诈骗行为，维护消费者权益。</strong>利用“OCR”技术精准扫描用户证件信息，识别是否存在偷拍、翻拍可能；通过“防Hack”分析技术提升静默活体检测能力，提升了对“PS换脸”“AI伪装”等欺诈识别的覆盖面。</p><h2><strong>在新型消费场景下，金融科技面临哪些挑战？</strong></h2><p><strong>首先，金融科技赖以发展的信息基础设施建设存在短板。</strong>实现对海量信息的快速处理必须依赖完善的信息基础设施。以“云计算”为例，需要大数据中心等机构实现对信息的收集与储存，“5G”等超高速网络带宽实现海量数据的快速、稳定传输，超级计算机提供算力保障，而我国在上述信息基础设施的建设上还存在一定的短板弱项。关键领域研发还有不足。目前我国虽然在“5G”等技术领域走在世界前列，但其他领域的底层技术仍存在较多空白点，存在“卡脖子”现象，对于国外厂商存在严重依赖。此外，<strong>不同省份之间、城乡之间还存在一定的“数据鸿沟”，全国范围的大数据中心、云计算中心还没有建立起来。</strong></p><p><strong>其次，金融科技应用的技术风险较为突出。一是“破坏性创新”带来的技术滥用风险。</strong>金融科技带来的深刻变革冲击了传统金融秩序，迫使以商业银行为代表的传统金融机构改变经营模式，这被一些学者称为“破坏性创新”。此时，初创企业的监管空白和传统机构迫切的转型需求会使部分管理者改变稳健经营策略，催生了技术滥用风险。<strong>二是“算法黑箱”带来的道德风险。</strong>金融机构利用自身收集的 海量数据成功搭建了众多算法模型，例如量化投资算法可快速确定交易换手率，避免错误头寸敞口，实现交易盈利与风险管控的平衡。但限于当前算法技术，具体计算的过程仍处于“黑箱”状态，不透明性和不确定性使得消费者处于劣势地位，面对“算法歧视”时难以有效应对。</p><p><strong>再次，金融科技行业监管需要发挥更加重要的作用。</strong>一方面，金融科技的快速创新提升了监管难度，依靠各类报告提供的监管数据指标难以适应金融科技行业的实施发展变化，在现有监管技术与模式下势必造成监管缺位，存在金融系统性风险快速传导隐患。 另一方面，立法机关、监管机构对金融科技的呼应不足，存在一定的监管空白和“灰色地带”，出现了诸如“炒币”等披着金融科技“外衣”的行业乱象，背离了金融基本规律。</p><p><strong>最后，金融科技的“双刃剑”作用也影响着新型消费。</strong>例如，金融科技支持的线上消费拓展了新型消费的渠道，但相较于传统线下消费，线上消费难以进行过程监管，消费者也面临着维权难、取证难的现实问题。又如，平台资本无序扩张有待进一步治理，一些头部互联网平台在利用技术优势大打“价格战”限制行业竞争，取得垄断地位后，就肆意“大数据杀熟”，损害消费者的合法权益。再如，金融科技虽开辟了新的消费领域，但资本大量涌入使市场快速饱和后即开始收缩，“爆火”“爆冷”现象频发，不利于行业稳健发展。</p><h2><strong>如何提升金融科技赋能新型消费质效？</strong></h2><h3><strong>优化信息基础设施建设</strong></h3><p><strong>一是加大5G信号基站、千兆光纤宽带、工业互联网等基础设施建设投入</strong>，尤其是中西部地区、县乡地区建设投入，改善区域失衡状况，填补“数据鸿沟”。<strong>二是加快构建全国一体化大数据中心协同创新体系，优化数据中心建设布局</strong>，实现数据中心集约化、规模化、绿色化发展，打破数据壁垒，畅通数据跨部门、跨区域、跨层级流通路径。<strong>三是推进大数据平台建设</strong>，深化大数据在金融、能源、交通、商贸、教育、医疗、文化旅游等消费领域协同创新，打通线上线下客户资源，实现双向互补、有机融通。<strong>四是引导各地区、各行业合理使用大数据资源、算力资源，提升基础设施利用效能。</strong>例如对金融数据等高频次调用、对网络延迟度要求较高的，支持向城市级高性能中心调度；对需进一步加工处理，不需较快网络响应的数据，支持向能源丰富中心地区中心调度。</p><h3><strong>推进金融科技有序、稳健应用，降低技术风险</strong></h3><p><strong>从发展理念上看，应基于有限资源而明确金融科技优先发展顺序，投入应聚焦主要业务发展，避免“大水漫灌”。</strong>这一趋势在金融机构中体现较为明显，据有关统计，2023年国有六大行的技术投入增速均同比回落，有的甚至增速为负（数据来源：《中国金融科技生态白皮书（2023年）》）。<strong>从应对“破坏性创新”角度上看，应形成全行业、全流程治理合力，共同抵御技术滥用风险。</strong>监管部门应针对数据、算法使用失范等实践突出问题制定、更新相应监管规则，尤其要弥补消费者的信息弱势地位；<strong>金融机构、科技企业、算法平台应当注重行业自律，规范技术使用行为，避免造成、加剧与金融消费者间的摩擦，助力自身与行业行稳致远。</strong>从应对“算法黑箱”角度看，除推进实质性监管、细化算法备案制度等措施解决“黑箱”不透明性外，另一个重要方面是赋予算法使用者更多的算法披露义务，推动避免平台、机构因使用同种算法而结成“攻守同盟”，成为针对消费者的“一致行动人”。</p><h3><strong>全面加强金融科技行业监管</strong></h3><p>从监管理念上看，要落实中央金融工作会议精神，坚持金融“监管为民”理念，<strong>引导金融科技行业积极转变业务发展方式，促进“科技--绿色--普惠”三者健康循环，实现扩内需、促消费、惠民生的积极作用。</strong>从制度建设上看，制度缺失仍是造成这一问题的主要原因。鉴此，应加快立法进度，尽快填补虚拟货币交易等热点行为的规制空白，避免相关领域的“野蛮生长”。<strong>从监管方式上看，一是要明确机构监管。</strong>不久前公布的国家金融监督管理总局“三定”方案新设科技监管司，下一步应进一步明确其权责范围，努力消除监管空白。<strong>二是要统筹功能监管与穿透式监管，在减少重复监管、多头监管的同时精准识别金融科技行业的隐藏风险</strong>，在降低监管成本的同时保障监管效能，维护金融科技行业稳定。三是细化行为监管，可通过引入监管沙盒等手段遏制科技“双刃剑”消极作用，充分保护消费者合法权益。</p><h3><strong>提升金融科技赋能新型消费的针对性，打通路径“堵点”“痛点”</strong></h3><p><strong>一是加大金融科技成果转化力度，依托科技赋能挖掘消费新增长点</strong>，在积极入局文旅消费、绿色消费等新业态的同时，拓展传统消费领域新的业务空间。<strong>二是利用科技行业催生的新业态、新领域创造稳定就业和灵活就业机会</strong>，通过增加收入提振居民消费信心和信贷意愿。<strong>三是利用金融科技打通征信验证渠道</strong>，畅通各类金融机构间信息共享，既遏制“多头共债”、“借新还旧”等行为，又依法合规筛选出更多“合格”消费者。<strong>四是聚焦智能获客、智能运营、智能催收和智能客服等方面的技术应用</strong>，及时回应金融机构解决获客成本与运营成本高企、用户类型与产品类型错配等急难问题的需求，为消费者提供更好的信贷服务。<strong>五是通过金融科技不断提升线上线下交易流程的数智化水平</strong>，有针对性地解决新型消费存在的消费维权难、取证难等问题。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/XUfzkZhzRFNBjWHijeIjfQ" rel="noopener noreferrer nofollow" target="_blank">“WEMONEY研究室”（ID:wemoney1）</a>，作者：王刚/黄玉/段星宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551983387105415</id>
            <title>价值千亿的焦点问题：美国高通胀被解决了吧？</title>
            <link>https://www.36kr.com/p/2551983387105415</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551983387105415</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:02:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 通胀率下跌, 华尔街人士, 美联储, 降息
<br>
<br>
总结: 美国通胀率下跌之快，让华尔街人士相信通胀已经被打败，投资者加大了对美联储将降息的押注。然而，美联储最青睐的通胀指标仍保持在高位，劳动力市场紧张。一些分析师认为，随着疫情的消退，通胀可能会继续下降。但也有人认为劳动力市场依然强劲，投资者对通胀过于乐观。 </div>
                        <hr>
                    
                    <p>美国通胀率下跌之快，已经让大多数华尔街人士相信，通胀已经被打败，传统股票和债券投资组合11月份创造了过去三十年来的最佳回报之一。</p><p>投资者相信，美联储目前正在朝着2%的通胀目标快速迈进，因此加大了对美联储将明年一季度降息的押注。</p><p>尽管如此，美联储最青睐的通胀指标——PCE指数——仍保持在3%左右的高位，劳动力市场依然紧张。一些投资者担心，通胀的粘性可能会令美联储在放松政策方面更加谨慎，导致股债出现回调。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_2a71ef4cbc614ce9a4315297077a812e@1743780481_oswg215131oswg640oswg369_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>乐观者：疫情的影响消散，通胀失去最大动力</strong></h2><p>一些分析师认为，随着新冠疫情时代的影响继续消退，通胀可能会继续下降。</p><p>2021年和2022年通货膨胀高企的一个重要原因是人们把钱“同时”花在了“同样的事情”上。</p><p>疫情期间，消费者被困在家里，手握政府的经济刺激资金。这时大家把钱主要花在了商品上，如食品、电子产品等。大规模需求推高了商品价格。</p><p>随着疫情消退，他们开始把钱花在旅游、外出就餐等服务上，大规模需求又推高了服务价格。</p><p>但现在奇特的行为已经消失，杰富瑞美国经济学家Thomas Simons表示，商品和服务的通胀压力都较小。</p><p>Simons说，新冠疫情带来的另一个后果是经验丰富的工人离开了工作岗位，并被“菜鸟”员工取代。</p><p>他说，这是拖累生产率的一个因素，并使企业更难满足需求，从而进一步推高价格。雇主们正在争夺合适的员工，这也可能推高了工资，但此后生产力已经正常化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_5c6e66bd7db24e82a38a4776f54a1aab@1743780481_oswg51764oswg640oswg510_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>许多分析师还认为，美联储的加息仍在对经济产生影响。</p><p>随着借贷成本上升，雇主开始缩减招聘规模，促使家庭和企业减少支出，并促使工资增长放缓。</p><p>尽管第三季度经济出现大幅反弹，但自美联储开始加息以来，经济增长总体速度比新冠疫情前要慢。本季度经济增速预计再次走低。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_ae3f18c184494a299c9fa6677a30e54c@1743780481_oswg54116oswg640oswg513_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>劳动力市场也出人意料地保持强劲，失业率仍接近五年来的低点。但它一直在按照美联储想要的方式降温：职位空缺正在减少，辞职的人越来越少，这应该有助于控制工资增长。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_9e93a40476014933acbcf4225113425e@1743780481_oswg54841oswg640oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，由于租金上涨速度缓慢，PCE住房指数预计持续放缓，该指数反映了人们当下为住房支付的费用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_fea63bcfc64344c2ab30766d27f6f776@1743780481_oswg40129oswg631oswg523_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>瑞银全球财富管理公司高级美国经济学家Brian Rose表示，当美联储首次开始加息时，“很多人表示，通胀如此之高，不可能在不陷入衰退的情况下将其降低”。但现在，美国经济实现软着陆的可能性并不低。</p><h2><strong>悲观者：劳动力市场依然强劲，投资者对于通胀过于乐观</strong></h2><p>许多分析师表示，市场低估了美联储将利率维持在当前水平的时间。经济虽然已经降温，但远远达不到促使美联储降息的水平。</p><p>比如，职位空缺仍高于新冠疫情前的水平，通胀的关键驱动力——工资涨幅——也仍保持在较高水平。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_be76008d73f242a39b40d4501af39a70@1743780481_oswg44838oswg640oswg481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_b1414e04bd9745b8a933053feb161bd5@1743780481_oswg72247oswg640oswg506_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对此，花旗集团首席美国经济学家Andrew Hollenhorst表示，假设生产率以典型的1%的年增长率增长，目前的工资涨幅相当于3%-4%的通胀率。</p><p>这可能会导致服务业通胀持续下降变得特别困难，而服务业通胀往往与工资密切相关。Hollenhorst说，例如，酒店价格最近有所下降，但最终应该会反弹。</p><p>另外，通胀预期仍处于较高水平，这可能会刺激员工要求更大幅度的加薪。</p><p>一些分析师表示，投资者对通胀的乐观情绪可能会弄巧成拙。</p><p>降息预期推动美债收益率大幅下降、股市上涨，使得企业融资成本降低，投资者转的盆满钵满，可能会刺激他们增加支出。</p><p>高盛美国金融状况指数（衡量市场对经济的总体限制程度的指标）最近有所下降，甚至低于新冠疫情之前达到的水平，当时通胀还没有到达引人注目的水平。</p><p>T. Rowe Price 固定收益部门首席美国经济学家 Blerina Uruçi 警告市场飙升带来的负面影响，她表示，鉴于经济的弹性，金融状况的进一步宽松可能“刺激需求，从而重新引发价格压力”。</p><p>本文不构成个人投资建议，不代表平台观点，市场有风险，投资需谨慎，请独立判断和决策。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/09WfdBgHE4MBy8EW8ypHJg" rel="noopener noreferrer nofollow" target="_blank">“华尔街见闻”（ID:wallstreetcn）</a>，作者：卜淑情，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2551967477913992</id>
            <title>MIT斯坦福Transformer最新研究：过度训练让中度模型「涌现」结构泛化能力</title>
            <link>https://www.36kr.com/p/2551967477913992</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2551967477913992</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:00:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人类, 句子, 层次结构, Transformer模型
<br>
<br>
总结: 人类对句子的理解和表达都依赖于句子的层次结构。然而，在自然语言处理中，以Transformer为代表的神经序列模型在捕捉句子的层级结构方面似乎存在困难。但最近的研究发现，经过长时间训练后，Transformer模型能够获得这种结构性的泛化能力，被称为"结构顿悟"。研究人员发现，中深度的Transformer模型在泛化能力上优于非常深和非常浅的模型。总体而言，通过更多的扩展训练，普通的Transformer模型能够展现出句子的层级结构。 </div>
                        <hr>
                    
                    <p>对于人类来说，句子是分层的。</p><p>句子的层次结构对于表达和理解都相当重要。</p><p>但是在自然语言处理中，之前的研究认为，在泛化到新的结构输入时，以Transformer为代表的神经序列模型似乎很难有效地捕捉到这种句子的层级结构。</p><p>但是斯坦福和MIT的研究人员在最近的研究中发现。</p><p>如果对Transformer类的模型进行长时间的训练之后，它能获得这种结构性的泛化能力。</p><p>研究人员将这种现象称为：结构顿悟（Structural Grokking，SG）</p><p>Grokking这个词是一个作家在书中造出来的词，中文大概翻译成「顿悟」。</p><p>微博网友木遥老师把这个词解释为：一个高度复杂的神经网络在漫长的训练期内一直只能记住训练样本的信息，几乎没有泛化能力，但到了某一刻，它的泛化水平忽然跳了出来，而且非常完美。</p><p>可以想象成一个神经网络经历了一个「aha moment」，像是内部的某个齿轮忽然对上了一样。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_c9375a0f3e0549fcab50895d75d25b34@1743780481_oswg57147oswg887oswg311_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://arxiv.org/abs/2305.18741</p><p>研究人员在不同的数据集中发现，SG在模型的深度（Model Depth）上呈现倒U缩放。</p><p>中深度模型的泛化能力比非常深和非常浅的模型都要好。</p><p>总体上看，如果能对模型进行更多的扩展训练，普通的Transformer能够展现出层级结构。</p><h2><strong>背景</strong></h2><p>在之前的类似研究中，研究人员认为Transformer在分层级泛化测试中是失败的。</p><h3><strong>Transformer模型中的分层级结构</strong></h3><p>为了了解给定的模型是否对获取层次结构有偏见，斯坦福的研究人员按照之前的实验流程，评估了模糊任务上训练的模型的泛化性。</p><p>在这些任务中，训练数据与“层次规则”和“非层次规则”相一致的。</p><p>为测试是否获得了分层规则，研究人员在一个单独的分布外测试集上测试泛化性。</p><h3><strong>顿悟（Grokking）</strong></h3><p>之前的研究表明，在小型算法数据集上会出现顿悟现象，他们发现在训练性能饱和后的很长时间里，模型测试性能继续提高。</p><p>因此研究人员就假设存在一个类似的结构顿悟，在域内验证性能饱和后很长时间内，模型对于分层结构依然可以继续顿悟。</p><p>因此，分层泛化可以通过扩展训练继续提高。</p><h2><strong>实验</strong></h2><h3><strong>数据集</strong></h3><p>研究人员的目标是理解transformer中的分层泛化 ， 使用了来自之前研究中的两个数据集，并在一个简单的括号跟踪任务上进行了评估。</p><p>作者评估了Dyck20,10中结构上未观察到的字符串的泛化能力，以下图为例。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_1675238ad3b347c79e5b060044db6bb7@1743780481_oswg203386oswg744oswg736_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>模型</strong></h3><p>研究人员训练了有｛2,4,6,8,10｝层的transformer语言模型。</p><p>对于每个深度，研究人员用10个随机种子来训练模型，300k steps。(Dyck为400k)</p><p>给定输入句子(或在Dyck的情况下前缀)，研究人员在测试时从模型中解码。</p><p>对于Dyck，研究人员报告准确性是通过在给定语言的输入前缀的情况下，通过对右括号进行排名来生成正确的右括号类型。</p><p>和之前已经进行的研究类似，对于Question-Formation，研究人员报告解码问题的第一个单词的准确性。</p><p>对于Tense-Inflection，研究人员报告的是目标动词词形变化正确的测试输入的分数。</p><h2><strong>主要结果</strong></h2><p>Transformers展现出了结构顿悟。</p><p>研究人员在下图中展示了在所有数据集上使用最佳模型深度所获得的结果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_e9664fbc96744ba781fa770f3e93d359@1743780481_oswg332678oswg1080oswg494_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他们发现了明确的结构顿悟证据：在各个数据集上，在分布内准确率饱和之后的训练步骤中，泛化性能得到改善，有时甚至接近完美的准确率。</p><h3><strong>提前停止是有害的</strong></h3><p>接下来，研究人员将通过在域内验证准确率上进行提前停止而获得的泛化准确率，与更长的训练流程（如下图）的泛化准确性进行了比较。</p><p>提前停止会导致泛化性能被严重低估。</p><p>例如，在Question-Formation和Tense-Inflection两个任务上，平均泛化性能从不到40％、不到50％提高到分别不到90％、不到80％。</p><h3><strong>倒U形分布</strong></h3><p>在Question-Formation和Tense-Inflection任务中，研究人员从2层到10层逐渐增加深度进行模型训练。</p><p>对于每个深度，在下图中报告了最终泛化准确率超过80％的种子数（10个种子中的比例）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_2d0ede9c10184adbabede7832abe8ec7@1743780481_oswg351092oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他们发现了一个倒U形的分布状态——非常浅和非常深的模型效果不佳，而大多数种子在中等深度的模型中表现出较好的泛化性能。</p><p>这也可以解释为什么之前的研究要么使用非常浅的模型（1-3层的Transformer），要么使用非常深的模型（Mueller等人论文中的12层Transformer），都无法很好地泛化。</p><h2><strong>分析</strong></h2><p>鉴于结构顿悟仅在一部分模型架构中发生，研究人员能否确定它何时发生（或预测何时会发生）？</p><p>几个模型内部属性与结构性理解或Transformer中出现的新兴分层结构或许有关。</p><h3><strong>Weight Norms</strong></h3><p>最近的研究将认为参数权重的L2 norm是结构顿悟的重要量。</p><p>但总体上来说，训练过程中范数（Norms）增长被作为神经网络泛化的关键因素之一进行了研究。</p><h3><strong>注意力稀疏性</strong></h3><p>Merrill等人（2021年）证明了Transformer中的范数增长导致了注意力的饱和，这是新兴语言结构的重要特性。为了衡量fLθ的注意力稀疏性，我们计算了所有分布{apk}的负均熵。</p><h3><strong>树结构</strong></h3><p>之前有研究展示了树结构编码器表现出接近完美的分层泛化。</p><p>虽然Transformer相对较为自由，但最近的证据表明，当在语言数据上进行训练时，它们隐含地实现了（近似）树结构计算。</p><p>而且，之前研究中树投影方法精确地描述了Transformer对输入进行的内部计算可以用树结构神经编码近似的程度，为任何Transformer提供了树结构度量分数（tscore），并提供了一个在输入字符串上最佳近似其计算的二叉树。</p><p>为了评估这些树是否与人类的句法概念相对应，我们还将恢复的树与黄金标准树进行比较。</p><h2><strong>结果</strong></h2><p>在Question-Formation和Tense-Inflection任务中，研究人员通过每隔3k steps更新计算一次这些量的方式来描述权重范数（通过层数统一化来比较不同模型深度）、注意力稀疏性和树结构性的动态变化情况。</p><p>对于依赖于数据的属性，如注意力稀疏性和树结构性，他们从训练数据中随机抽取了10k个样例。</p><p>研究人员在下图中绘制了这些量在最小模型、最大模型（其中至少有一个运行显示成功的结构顿悟）以及最佳模型深度的情况。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_fce2dd5ba88d4f5f8ed5b2ea4a076280@1743780481_oswg114776oswg551oswg482_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>树形结构是最佳的模型</strong></h3><p>在两个数据集的所有模型设置中，权重范数和注意力稀疏性都会增长。</p><p>然而，仅凭这些属性本身无法预测浅层和深层模型的失败 - 浅层模型学习到了最稀疏的解以及具有最大权重范数的解，但从未进行分层泛化。</p><p>正如之前的研究中所指出的，tscore随时间的推移对于所有模型都有所改善，表明随着时间的推移，树结构性增加。</p><p>对于这两个数据集，与深层和浅层模型相比，“最佳”模型学习到了最多的树结构解。</p><p>在算法任务中，结构性理解“与嵌入中结构的出现相吻合”。</p><p>类似地，在语言任务中，我们发现结构性理解与树状内部计算的出现相吻合。</p><h3><strong>Transformer在诱导结构方面表现出惊人的效果</strong></h3><p>从下图的tparseval的动态变化中，研究人员注意到所有模型，无论它们是否进行泛化，都学习到了接近于真实句法的结构，有时表现优于右分支基线。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231208/v2_833bdd12c0874152a4e135a93ed7300c@1743780481_oswg117762oswg580oswg439_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>之前的研究认为，只有树结构编码器根据正确的句法分析树进行结构化时才能进行泛化。</p><p>研究人员发现所有Transformer都学习到了正确的树结构，但只有最具树结构性的模型表现出最好的泛化能力。</p><h2><strong>结论</strong></h2><p>这项研究表明，通过结构顿悟机制，Transformer能够展现出对结构敏感的“分层泛化”。</p><p>它们的整体学习行为逐渐从记忆（领域内高准确率，领域外准确率较差）向泛化（领域内和领域外准确率高）转变。</p><p>虽然研究人员在相对较小的数据集和小型模型上展示了这种行为，但这些结果可能具有更广泛的意义。</p><p>因为已经证明长时间的训练即使对于规模庞大的语言建模和组合泛化任务也有帮助。</p><p>结构顿悟在“中等规模”的模型深度最常发生，而非常浅和非常深的模型则无法展现出这种行为。</p><p>虽然以往与Transformer中的语言泛化相关的属性，如权重范数和注意力稀疏性，不能区分好的架构和坏的架构，但Transformer的功能性树结构可以很好地预测最佳模型深度。</p><p>虽然Transformer架构存在一些明显的限制（例如无法实现无限递归），但研究人员的结果表明它可能具有比以前认为的更强的归纳偏好：通过充分的训练，Transformer能够表示分层的句子结构并利用这种结构进行正确的泛化。</p><h3>参考资料</h3><p>https://arxiv.org/abs/2305.18741</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/XaeBaoKBaBucRTy4IVjCUg" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：润，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2508292429758467</id>
            <title>如何让生成式AI更环保</title>
            <link>https://www.36kr.com/p/2508292429758467</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2508292429758467</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:00:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 神译局, 生成式人工智能, 环境成本, 数据中心
<br>
<br>
总结: 本文介绍了生成式人工智能模型的环境成本和影响，以及如何使人工智能更环保。文章指出，生成式人工智能模型的开发和使用耗能巨大，特别是在数据中心中运行时。为了减少环境成本，可以使用现有的大型生成模型，对现有模型进行微调训练，并使用节能计算方法。这些措施可以使人工智能更加环保可持续。 </div>
                        <hr>
                    
                    <blockquote><p>神译局是36氪旗下编译团队，关注科技、商业、职场、生活等领域，重点介绍国外的新技术、新观点、新风向。</p></blockquote><p>编者按：生成式人工智能推动整个社会、技术和生产力的提升，但这些模型隐藏的环境成本和影响往往被忽视。本文分享八个步骤来使这些系统更环保：使用现有的大型生成模型；对现有模型进行微调；使用节能计算方法；只有在提供重大价值时才使用大型模型；辨别何时使用生成式人工智能；评估云提供商或数据中心能源；重用模型和资源；了解人工智能活动的碳活动足迹。文章来自编译。</p><p>虽然ChatGPT、BERT、LaMDA、GPT-3、DALL-E-2、MidJourney和Stable Diffusion等新型生成式AI工具在更多领域中得到广泛应用，但这些模型所暗藏的环境成本和影响却通常被人忽视。这些系统的开发和使用耗能巨大，维护其物理基础设施也很耗费电力。现在，这些工具刚刚开始获得主流关注，但我们有理由相信，这些成本在不久的将来定会增长，而且是大幅增长。</p><p>数据中心行业是指用于存储和管理信息和通信技术系统的物理设施，占全球温室气体(GHG)排放量的2-3%。全世界的数据量每两年翻一番。数据中心的服务器存储着不断扩大的信息海洋，需要大量的能源和水来运行计算机服务器、设备和冷却系统。这些系统约占丹麦用电量的7%，占美国用电量的2.8%。</p><p><strong>几乎所有最著名的生成式人工智能模型都是由超大规模的云提供商生成的，这些云提供商拥有成千上万台服务器，会产生大量碳足迹。</strong>特别是，这些模型是在图形处理单元（graphics processing unit，GPU）芯片上运行的。这些芯片所需的能量是传统中央处理单元（CPU）的10-15倍，因为GPU在算术逻辑单元中使用了更多的晶体管。目前，三家主要超大规模云提供商是亚马逊云科技（AWS）、谷歌云（Google Cloud）和微软云（Microsoft Azure）。</p><p>如果我们试图从碳足迹的角度来理解ChatGPT对环境的影响，那么我们应该首先了解机器学习（ML）模型的碳足迹生命周期。这是通过降低能耗让生成式人工智能变得更加绿色的关键所在。</p><h2><strong>是什么决定了生成式人工智能模型的碳足迹?</strong></h2><p>所有大型生成模型在能源使用和碳排放方面都是不一样的。在确定机器学习模型的碳足迹时，需要考虑三个不同的值：</p><ul class=" list-paddingleft-2"><li><p>训练模型产生的碳足迹；</p></li><li><p>一旦部署了机器学习模型，使用ML模型进行推理（使用新输入数据推断或预测结果）所产生的碳足迹；</p></li><li><p>生产所有所需计算硬件和云数据中心能力所需的碳足迹。</p></li></ul><p>拥有更多参数和训练数据的模型通常会消耗更多能量，产生更多碳。GPT-3是 ChatGPT的“母”模型，其规模在生成式模型中名列前茅或接近前茅。它有1750 亿个模型参数，并在超过5000亿字的文本上进行过训练。一篇研究文章指出，与上一代人工智能模型相比，最近的生成式人工智能模型需要增加十倍到百倍的计算能力来训练模型，具体取决于哪种模型。因此，总体需求大约每六个月翻一番。</p><p><strong>训练模型是生成式人工智能最耗能的部分。</strong>研究人员认为，训练一个“单个大型语言深度学习模型”（如OpenAI推出的GPT-4或谷歌推出的PaLM）估计要消耗约300吨二氧化碳。相比之下，平均每人每年要产生约5吨二氧化碳，而北美人平均每年要产生是其数倍的二氧化碳。<strong>根据其他研究人员的计算，使用一种名为“神经架构搜索”（neural architecture search）技术训练一个中等规模的生成式人工智能模型所消耗的电力和能源相当于626,000吨二氧化碳排放量，或者说相当于驾驶五辆普通美国汽车终生所产生的二氧化碳排放量。</strong>从头开始训练一个BERT模型（谷歌开发的一种大型语言模型）所需的能源和碳足迹相当于一次横跨大西洋的飞行。</p><p><strong>部署人工智能模型，让它们在现实环境中采取行动——这个过程被称为推理，该过程的能耗比训练环节更高。</strong>推理，或使用模型响应用户输入的提示问题，虽然每次对话消耗的能量不多，但对话次数却不计其数。有时这些模型只训练一次，然后部署到云中，供数百万用户进行推理。在这种情况下，将大型深度学习模型部署到云端进行推理也会消耗大量能源。分析人士报告称，实际上，英伟达公司（Nvidia）估计，神经网络80％至90％的能量消耗出现在推理环节，而不是训练环节。</p><p>除了大型生成模型的初始训练和推理使用的能量外，这些模型的用户和经销商越来越多地采用微调或基于提示的训练。<strong>当与经过大量数据训练的原始生成模型相结合时，微调允许模型根据组织的特定内容定制提示和答案</strong>。一些研究表明，微调训练比初始训练消耗的能量和计算能力要少得多。但是，如果许多组织采用微调方法并经常这样做，总体能耗可能会相当高。</p><p>尽管很难计算运行所有这些人工智能软件所需的成本，但人们有理由相信这个成本非常高。2011年的一项研究估计，一台普通笔记本电脑70%的能源消耗是在制造过程中产生的，台式电脑的能耗甚至更高。很有可能的是，用于运行AI模型的复杂而强大的GPU芯片和服务器在能耗方面远远高于笔记本电脑和台式电脑。</p><h2><strong>如何让人工智能更环保</strong></h2><p>考虑到这一切，现在有一种运动使人工智能建模、部署和使用更具环境可持续性。它的目标是用更合适、更环保的替代品取代耗电的方法。供应商和用户都需要做出改变，使人工智能算法变得更加环保，这样它们的效用才能在不损害环境的情况下得到广泛部署。特别是生成式AI模型，鉴于它们的高能耗，它们需要在普及之前变得更加环保。通过好几种不同的方式，AI和生成式AI可以朝这个方向发展，接下来我们会在下文描述。</p><p><strong>使用现有的大型生成模型，不要生成自己的模型。</strong>现在已经有很多大型语言和图像模型提供商，而且未来还会有更多。创造和训练这些模型需要大量的能源。除了大型供应商或云提供商之外，其他公司几乎不需要自己生成大型人工智能模型。他们已经可以在云端获取所需训练数据和海量的计算能力，因此他们不需要获取这些数据。</p><p><strong>对现有模型进行微调训练。</strong>如果一家公司希望按照自己的内容训练生成式模型，它不应该从头开始训练模型，而是应该改进现有的模型。相比于从头开始训练新的大型模型，在特定内容领域进行微调并及时训练所消耗的能量要少得多。它还可以为许多企业提供比一般训练模型更多的价值。对于希望针对自己的内容采用生成式AI模型的公司而言，这才是主要关注点。</p><p><strong>使用节能计算方法。</strong>另一种减少生成人工智能能耗的方法是使用计算成本较低的方法来处理数据，如TinyML。TinyML框架允许用户在小型、低功耗的边缘设备上运行机器学习模型，比如带宽要求低的微控制器(不需要将数据发送到服务器进行处理)。一般CPU平均耗电70瓦，GPU消耗400瓦的功率，而一个微型微控制器仅耗电几百微瓦，相比前两者，其耗电减少一千倍。这样就可以保证模型在本地处理数据，而不需要将数据发送到数据服务器。</p><p><strong>只有当大型模型提供重大价值时才使用它。</strong>对于数据科学家和开发人员来说，了解模型在哪里提供价值是很重要的。如果使用3倍以上的耗电系统仅能让模型增加1-3%的计算精度，那么额外的能耗就不值得。更广泛而言，机器学习和AI并不总是解决问题所必需的。开发人员首先需要对多种备选解决方案进行研究和分析，并根据研究结果选择一种方法。例如，蒙特利尔人工智能伦理研究所(Montreal AI Ethics Institute)正在积极研究这个问题。</p><p><strong>当你使用生成式AI时，要有鉴别力。</strong>机器学习和NLP工具对于医疗相关的健康问题和预测是革命性的。它们在预测自然灾害，如海啸、地震等方面非常有用。这些都是有用的应用程序，但是仅用于生成博客文章或创建有趣故事的工具可能不是这些计算量很大的工具的最佳用途。它们对地球健康的消耗可能大于对人类的帮助。如果一家公司正在使用生成式人工智能进行内容创作，它应该尽量确保只在必要时使用这些模型，或者减少其他计算成本，这应该也会减少其总体计算预算。</p><p><strong>评估云提供商或数据中心的能源来源。</strong>在能够使用环保能源的地区以及低碳环保的地区部署模型，可以最大限度地降低AI（以及一般软件）的碳强度。这一做法表明，运营排放减少了75%。例如，在美国训练和运行的模型可能使用来自化石燃料的能源，但同样的模型可以在主要能源是水力发电的魁北克运行。谷歌最近开始在魁北克建造一个7.35亿美元的清洁能源数据中心，并计划到2030年转向全天候的无碳能源。歌还提供了一个“碳感应套件（Carbon Sense Suite）”，以帮助公司减少云工作负载的能源消耗。云提供商的用户可以监控这些公司关于何时以及如何部署碳中和或零碳能源的公告。</p><p><strong>重复利用模型和资源。</strong>就像其他材料一样，技术也可以重复使用。企业可以使用开源模型，而不是训练新的模型。循环利用可以降低人工智能产生碳足迹的影响。原材料可以被提取出来制造新一代的最新笔记本电脑、处理器、硬盘驱动器等等。</p><p><strong>将AI活动纳入你的碳监测。</strong>所有研究实验室、人工智能供应商和使用人工智能的公司都需要采用碳监测的做法，以了解模型的碳足迹。他们还需要公布自己的足迹数字，以便让客户在与他们进行人工智能相关业务时做出明智的决定。温室气体排放的计算取决于数据供应商和处理公司（如研究实验室）以及基于人工智能的服务提供商（如OpenAI）的数据集。从最初的想法到会被用于获得研究成果的基础设施，都需要遵循绿色人工智能方法。有几个可用的软件包和在线工具，如CodeCarbon, Green算法和ML CO2 Impact，可以在运行时纳入你的代码中以估计你的排放量，我们应该鼓励开发人员社区考虑这些性能指标来建立基准并评估ML模型。</p><p>当然，组织和个人在使用生成式人工智能模型时需要考虑很多因素：道德、法律，甚至哲学和心理学。然而，生态问题也值得考虑。我们可以讨论这些技术对人类的长期未来影响，但如果我们没有一个适合居住的星球来讨论这些问题，那么这些考虑将毫无意义。</p><p>译者：Araon_</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>