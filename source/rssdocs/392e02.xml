<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3157283502578434</id>
            <title>硅谷投资人张璐：Z世代70%时间用在AI应用上，传统搜索已被抛弃？</title>
            <link>https://www.36kr.com/p/3157283502578434</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157283502578434</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 01:16:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, DeepSeek, 开源生态, 技能提升  
<br><br>  
总结: 本文讨论了人工智能（AI）在未来的发展趋势，特别是中国原创大模型DeepSeek的崛起引发的全球关注。作者预测了五大AI趋势，包括垂直领域小模型的快速落地、基础设施技术创新、边缘设备的应用、开源生态的持续发展以及新算法模型的涌现。同时，AI的普及使得人们的工作方式发生变化，强调了熟练使用AI工具的重要性，并指出提问能力、问题拆解能力和决策能力是AI时代不可或缺的技能。 </div>
                        <hr>
                    
                    <p><strong>作者 张璐 硅谷投资人、Fusion Fund创始合伙人</strong></p>
  <p><strong>编辑 周小燕</strong></p>
  <p>中国农历春节期间，DeepSeek的爆火蔓延至硅谷，引发硅谷一众科技巨头“焦虑”，OpenAI CEO萨姆·阿尔特曼（Sam Altman）坦言，OpenAI的闭源策略使他们站到了历史错误的一边，将重新思考OpenAI的开源策略；扎克伯格在公司全体会议问答中也承认DeepSeek 实现了新颖的突破。&nbsp;</p>
  <p>中国原创大模型DeepSeek 出圈，也让大家更加确信人工智能将加速改变世界。&nbsp;</p>
  <p>实际上，在过去的几年中，人工智能技术不断加速，不断给世界带来惊喜。&nbsp;</p>
  <p>站在2025年初，很高兴能与大家分享我的想法。今年，我预计将会有五个主要的AI趋势逐步成形：&nbsp;</p>
  <p><strong>第一，垂直领域小模型将快速地在产业落地。</strong></p>
  <p><strong>第二，将出现更多的AI基础设施层面的技术创新，尤其在降低能耗和成本方面。</strong></p>
  <p><strong>第三，更多的小模型开始进入边缘端设备。</strong></p>
  <p><strong>第四，开源生态将持续茁壮，开源模型不断丰富且形式更加多样化。</strong></p>
  <p><strong>第五，新的算法模型与架构不断涌现。</strong></p>
  <p>与此同时，人工智能的广泛应用也让我们不断审视AI与我们的关系。AI让我们的工作更加“卷”，也让许多任务变得更为轻松。随着AI工具的普及，新的竞争加剧了，但也在某种程度上解放了我们的创造力，特别是在艺术和生产力领域。&nbsp;</p>
  <p>AI正逐渐替代一些传统工作。但更为关键的是，能熟练使用AI工具的人，将替代那些无法有效使用AI工具的人。&nbsp;</p>
  <p>面对AI的快速发展，我们也需要具备新的技能和认知。除了学会使用AI工具，我们更需要掌握提问、拆解问题等关键能力。AI时代最不可或缺的能力仍然是决策能力。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_12da335958644cc385f6e2855fb73059@5595930_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <h3><strong>AI的五大趋势预判</strong></h3>
  <p><strong>预判一：垂直领域小模型将快速地在产业落地。</strong></p>
  <p>这其实在硅谷和产业中已经开始发生。&nbsp;</p>
  <p>过去，大家一直讨论的是大模型，随着模型规模的不断扩大，通过接入大量数据与参数来提升模型训练效果。然而，过去一年，大家的关注点逐渐从AI模型的快速增长转向了实际应用——即AI技术如何迅速落地，并实现大规模的工业化应用。&nbsp;</p>
  <p>在这一过程中，AI小模型的大规模应用必将成为趋势。&nbsp;</p>
  <p>对于许多特定行业或垂直领域的人工智能应用来说，尽管数据量需要达到一定规模，但更为关键的是数据的质量。事实上，数据的质量可能比数据的数量更为重要。通过使用高质量的行业数据来训练垂直领域的小模型，不仅能够提升AI应用在特定场景下的准确性和效果，更重要的是，小模型的规模较小，成本较低，能效更高，对GPU的需求也更少。&nbsp;</p>
  <p>这些特点使得小模型在成本层面上更符合工业界对AI技术应用的需求。尤其是在面向企业客户（B端应用）的场景中，技术成本往往是最关键的因素。在这样的背景下，模型的“小型化”显得尤为重要。&nbsp;</p>
  <p><strong>预判二：将出现更多的AI基础设施层面的技术创新，尤其在降低能耗和成本方面。</strong></p>
  <p>人工智能领域将涌现更多基础设施层面的技术创新，尤其集中在如何降低能耗和成本方面。事实上，许多相关技术已经开始落地。&nbsp;</p>
  <p>我们知道，人工智能发展面临的最大挑战之一是高成本、高能耗以及过度依赖GPU，导致无法满足工业级应用的需求。基于这一点，这将推动下一波更具实际性、更贴近商业变现的AI应用诞生。&nbsp;</p>
  <p>目前，已经有许多AI基础设施技术能够帮助这些应用进行系统优化，从而大规模降低GPU的消耗。这种优化不仅包括GPU消耗的降低，还涵盖了能源消耗的减少，从根本上降低了整体成本。&nbsp;</p>
  <p>例如，一些硬件和软件技术的创新已经能够将能耗降低15倍至100倍，甚至更高。同时，GPU的消耗也能够减少至原来的1/4，甚至接近1/10。这些都是未来发展的潜力趋势。&nbsp;</p>
  <p><strong>预判三：更多的小模型开始进入边缘端设备。</strong></p>
  <p>2025年，一个重要的趋势将是人工智能在边缘端和边缘设备上的应用。事实上，这一趋势在硅谷已经初见端倪。&nbsp;</p>
  <p>工智能在边缘端设备上的应用，得到了众多大企业和小企业的推动。这将催生新的AI接口（interface），即人工智能带来的全新交互形式。过去，我们的交互方式主要依赖于手机等传统设备，但随着AI的普及，未来的交互方式将不再局限于手机等传统边缘设备。更多设备将与人工智能结合，比如智能眼镜、投影仪、音响、灯等各种日常小型设备。这些设备都将成为搭载人工智能的新载体。&nbsp;</p>
  <p>例如，我们最近投资的一家公司——Nexa AI，其AI小模型能够在树莓派（Raspberry Pi）等边缘设备上高效运行，并且其生成式AI表现与GPT-4相似。从这个角度来看，我们可以看到这种技术在边缘设备上的巨大潜力。&nbsp;</p>
  <p>进一步来看，随着人工智能的普及，新的AI接口必将出现。例如，在C端，AI智能眼镜受到业界关注。&nbsp;</p>
  <p>而在B端，端侧AI的应用形式更加多样。例如，在物流和供应链行业，智能传感器可以成为端侧AI的载体，广泛应用于各种机器设备中；在蓬勃发展的太空科技领域，每颗卫星都可以作为智能体，充当端侧AI的载体；在医疗领域，各种智能医疗设备、传感器，甚至医疗器械，也能够承载人工智能，成为AI的载体。&nbsp;</p>
  <p>因此，人工智能的载体和接口并不仅限于手机和电脑，它将在各个行业中嵌入，尤其是在工业领域，AI将通过智能体的形式，嵌入到不同的传感器和硬件中。人工智能的应用场景非常广泛。&nbsp;</p>
  <p><strong>预判四：开源生态将持续茁壮，开源模型不断丰富且形式更加多样化。</strong></p>
  <p>我们始终看好开源生态的发展，并坚定支持其成长。开源生态在人工智能领域作出了巨大的贡献。事实上，自2024年以来，全球范围内各类开源平台的动态活跃，不仅仅局限于美国，中国也有许多开源生态的积极贡献者，比如最近引发全球科技圈热议的DeepSeek。最近发布的Llama 3.1也充分证明了开源生态能够推动更多语言模型和小模型的产生。&nbsp;</p>
  <p>展望2025年，我相信开源生态将持续茁壮发展，并成为支持和孵化初创企业的一个重要平台。许多垂直领域的技术已源自开源，这进一步证明了开源生态在推动技术进步和创新方面的关键作用。&nbsp;</p>
  <p><strong>预判五：新的算法模型与架构不断涌现。</strong></p>
  <p>目前，关于生成式AI和大语言模型的讨论非常活跃，但与此同时，许多新的算法模型和架构也在不断涌现。例如，谷歌和微软近期发布的研究论文，正探索着全新的算法模型和架构。这些新模型的一个显著特点是，它们不仅能够在GPU上高效运行，某些模型甚至在CPU上也能展现出更优的性能。这一发现可能会对市场产生深远影响，因为它提出了一个重要问题：是否所有的AI应用都必须依赖GPU？还是未来会有一些算法模型在CPU上表现得更为出色？&nbsp;</p>
  <p>这些变化和趋势正在悄然发生，预示着它们将对整个行业带来深远的影响。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_f08f47be03ab4f5ab6ef894566c02c1c@5595930_oswg3905oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <h4><strong>AI让人更“卷”，也更“轻松”</strong></h4>
  <p>随着AI不断渗透到生活的方方面面，人与AI的关系正在悄然发生变化。可以说，AI让我们既“更卷”，也“更轻松”。&nbsp;</p>
  <p>举个简单的例子，究竟是在没有电脑之前你更卷，还是有了电脑之后更卷？显然，是有了电脑之后更“卷”。这是因为各种工具帮助我们提升效率、解放生产力，从而加速了各项工作的进展。随着生产力的提升，所有的事情都在加速，创新在加速，增长也在加速，各行各业都在AI的赋能下加速发展。而加速意味着竞争愈发激烈。因此，人工智能不仅会推动产业升级，也会让我们在个体层面面临更为激烈的竞争。&nbsp;</p>
  <p>我还想分享一个有趣的现象。如今的大学生，尤其是大一、大二的学生，甚至一些高中生，每天使用AI工具的时间非常多。他们大约70%、80%的时间都在使用手机上的AI应用。比如，很多学生几乎不再使用传统的谷歌搜索，而是转向ChatGPT、You.com等平台，通过这些工具进行搜索。&nbsp;</p>
  <p>这种变化很有意思。因为我们成长的环境是移动设备为主（mobile-based），对于我们来说，触屏、搜索和应用都是自然而然的，不需要特别学习。而对他们来说，人工智能应用已经成为一种本能，类似于我们当初使用触屏和搜索引擎的过程。&nbsp;</p>
  <p>另外，我们发现年轻一代更愿意使用人工智能工具，并与AI互动。在不久前的摩根大通医疗健康年会上，我与许多医疗领域的大公司负责人交流，他们分享了一个有趣的现象：很多公司已开始应用AI驱动的心理健康工具，特别是旨在缓解焦虑和维护心理健康的相关应用。这些公司向患者提供了两种选择：一种是与AI互动，由AI提供反馈和建议；另一种是与心理咨询师进行在线沟通。结果显示，70%的人更倾向于选择AI作为心理咨询的对象，愿意与AI分享敏感的个人信息和心理问题，而不是与真人交流，这一数据令人惊讶。&nbsp;</p>
  <p>这也表明，人与AI的关系可能比我们想象得更快发生变化。从最初的不了解和抵触，到逐渐的合作，再到现在的依赖，未来，AI可能会像手机一样，成为日常生活的一部分，大家也会形成新的习惯。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_580ea5e127af47999cd875d961777dd0@5595930_oswg857oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <h4><strong>AI时代</strong></h4>
  <h4><strong>人类需要具备哪些技能和认知</strong></h4>
  <p>那么，AI时代，我们需要具备哪些技能和认知呢？&nbsp;</p>
  <p>首先，最重要的一点是要意识到，人工智能将替代一些传统工作，但更为关键的是，能熟练使用AI工具的人，将替代那些无法有效使用AI工具的人。&nbsp;</p>
  <p>随着AI技术的普及，新的工作机会将不断涌现，而许多传统的工作岗位可能会被取代。在这一过程中，技术的快速发展将起到决定性作用。就像我们小时候学习如何使用电脑一样，今天，掌握AI工具的使用已经成为必备技能。过去，懂得使用电脑是求职的基本要求；今天，掌握如何使用AI工具同样将成为一种基础能力。&nbsp;</p>
  <p><strong>（一）提问能力与问题拆解能力至关重要</strong></p>
  <p>在AI时代，具备有效提问的能力尤为重要。提问的能力有时比回答问题的能力更加关键。通过提出明确且具有针对性的问题，AI能够为我们提供更加精准、有价值的反馈与支持。&nbsp;</p>
  <p>另一个至关重要的能力是将复杂问题拆解为更小的任务，或者将一个庞大的工作结构分解为更易管理的子任务。这不仅仅是一个技能，它体现了领导力和管理能力。比如，在公司中，经理的核心职责之一就是将复杂的工作分解成具体的小任务，然后指派给团队成员去执行。如今，这些任务可能由AI来帮助执行，而不是由初级工程师直接完成。如果一个人只会执行任务，而缺乏思考、提问和规划的能力，这可能会带来风险。&nbsp;</p>
  <p>因此，如何有效思考、拆解问题，并与AI合作，成为非常重要的能力。&nbsp;</p>
  <p><strong>（二）AI促进艺术创造力的释放</strong></p>
  <p>我还观察到，人工智能的一个显著优点，是它在艺术和创造力领域的广泛应用。尽管一些人担心AI会替代艺术创作者，但从另一个角度来看，AI正在像相机的发明一样，帮助更多人实现创作。相机让我们能够捕捉美丽的瞬间，而不再需要学习绘画技巧；同样，人工智能正释放更多的创造力，使每个人都能轻松进行艺术创作。&nbsp;</p>
  <p>艺术家最重要的能力之一是拥有创造性思维，并通过强大的记忆力和技巧将这种创造力表达出来。摄影师在照相机发明之前并不存在，但现在，手机成了每个人都能用来捕捉美丽瞬间的工具，极大地降低了创作门槛。人工智能正在朝着类似的方向发展，它使更多人能够轻松创作和表达。&nbsp;</p>
  <p>如今，即便你没有学过绘画，也能通过AI将你的创意和想法呈现出来。你可能有丰富的情感，但以前可能无法通过画作或歌曲的形式表达出来。现在，通过AI工具，你可以将自己的情感通过歌词、旋律等形式表现出来。这种技术进步，极大地拓宽了艺术创作的边界，让更多人能够将内心的情感转化为艺术作品，而不再受限于传统的创作技巧。&nbsp;</p>
  <p><strong>（三）决策能力：AI时代的核心</strong></p>
  <p>人工智能对各个领域的影响是显而易见的，无论是音乐、美术，还是其他行业，都在发生着类似的变化。以金融行业为例，过去，成功的投资者往往依赖于获取别人无法获得的数据，并通过数据分析做出精准的市场判断。这需要强大的分析能力，如Excel技能、数据分析能力等。但如今，AI技术正在缩小这一差距。无论是谁，都可以访问更多的数据，并通过AI进行深入分析。&nbsp;</p>
  <p>然而，AI时代最关键、最不可或缺的能力仍然是决策能力。尽管AI可以为我们提供大量信息并进行精确分析，但如何基于这些分析结果做出明智的决策，依然是核心能力所在。我们会发现，很多技能，归根结底，都是决策管理能力和领导力的体现。只有在这一基础上，AI的辅助才能真正发挥其最大潜力。&nbsp;</p>
  <p>附：作者介绍&nbsp;</p>
  <p>张璐，Fusion Fund 创始合伙人，硅谷知名投资人、连续成功创业者，毕业于斯坦福大学工程学院。2015年创立Fusion Fund，现管理近5亿美元资本，专注于美国市场新兴技术类初创公司的投资，尤其专注数字化转型和智能医疗领域，已投资100多家企业，并有多家被投企业上市以及收并购退出。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/TP_DlY2Lr7eiM8JUufhPpA" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：张璐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3157280980032001</id>
            <title>朱啸虎现实主义故事一周年连载：“DeepSeek快让我相信AGI了”</title>
            <link>https://www.36kr.com/p/3157280980032001</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157280980032001</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 01:14:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <朱啸虎, DeepSeek, AGI, 开源生态>
<br>
<br>
总结: 朱啸虎的态度在过去一年中发生了显著变化，尤其是对DeepSeek的认可。他曾对AGI持怀疑态度，但在体验了DeepSeek后，他开始相信AGI的可能性，并表示愿意投资该项目。DeepSeek的成功不仅弥合了技术信仰派与市场信仰派之间的鸿沟，还在全球范围内实现了快速增长，成为开源生态的代表。朱啸虎认为，未来AI将极大解放人类的工作形态，但也引发了对人类未来角色的思考。 </div>
                        <hr>
                    
                    <p><strong>文 / 腾讯新闻科技主笔 张小珺</strong></p>
  <p><strong>编辑 / 马龙</strong></p>
  <p>在刚过去的短短20天内，金沙江创投主管合伙人朱啸虎的态度发生了惊奇逆转。&nbsp;</p>
  <p>1年前，2024年初，在我们关于《朱啸虎讲了一个中国现实主义AIGC故事》的报道中，朱啸虎的观点淋漓尽致地展现了一个现实版中国AI故事。他用 “我们一看就知道，这个肯定没戏”，“我们一开始就说了，我就不看好大模型”，“ 我都不愿意去聊，你知道吗？这没有意义” ，表态绝不会投资6家中国大模型创业公司中的任何一家。&nbsp;</p>
  <p>甚至在2024年底，他对于所谓AGI（通用人工智能）的态度也还充满了冷淡——在一次会面中，他彼时言之凿凿道：“现在基本都和我们判断是一模一样的，对吧？ 今天还忽悠AGI的人都是有自己另外想法的——不可能的事情啊！怎么可能的事情？ ——AGI……现在的架构上根本不可能实现AGI。”&nbsp;</p>
  <p>然而，就在刚过去的2025年春节，随着DeepSeek在全球范围内“异军突起”，在没有任何推广的情况下，这款“类ChatGPT”的中国AI对话产品增长态势强劲。就连这名中国AI市场派代表、现实主义代言人，也一反常态地反复打量并开始欣赏AI之美。他的朋友圈和谈话公然浪漫化。&nbsp;</p>
  <p>时隔1年，2025年2月，朱啸虎再次接受我们的访谈。访谈中，他用 “真的让我大开眼界”、“非常惊艳”、“非常惊讶”、“很吃惊”、“哇！” 等话语来表达自己内心受到的强烈震撼。并反反复复用 “太优美了”、“非常有深度” 来评价DeepSeek与自己的交互——这两个词他总共强调了16遍。这位曾经认定“AGI是大忽悠”的投资人，甚至表态说： <strong>“DeepSeek快让我相信AGI了。”</strong></p>
  <p>随之逆转的还有他的投资策略：&nbsp;</p>
  <p><strong>当然DeepSeek今天不融资，如果他们开放融资的话，你会投吗？</strong></p>
  <p>“我肯定会投啊！我肯定会投！”&nbsp;</p>
  <p><strong>你会愿意用什么条件投？</strong></p>
  <p>“这个价格已经不太重要了，关键是参与在这里面。”&nbsp;</p>
  <p><strong>（停顿2秒…）哇塞，你这个观点变化好大，去年还说大模型公司一个都不看。</strong></p>
  <p>“对，确实！（笑）这个让我很吃惊。”&nbsp;</p>
  <p><strong>就是不管多少钱都愿意参与？</strong></p>
  <p>“对，愿意参与。”&nbsp;</p>
  <p><strong>很多人觉得梁文锋是“理想主义、浪漫主义代表”。在你看来，梁文锋是你的反面吗？</strong></p>
  <p>“也不一定啊！我也很喜欢这些文字，对吧？我看到这些文字确实觉得，‘哇！’，真的是让我非常惊讶——这些是人类共通的东西。”&nbsp;</p>
  <p><strong>你既然是“现实主义代表”，当看到中国出现像梁文锋这种代表技术理想主义、浪漫主义的人，并且获得胜利，你在想什么？——“朱啸虎们”怎么看待“梁文锋们”？</strong></p>
  <p>……&nbsp;</p>
  <p><strong>本篇是《</strong> 朱啸虎讲了一个中国现实主义AIGC故事 <strong>》的1周年连载。</strong> 我们希望努力呈现中国AI市场的风云变幻与市场中人的心态起伏。朱啸虎坦然地表达了过去1年他的坚定与反转。&nbsp;</p>
  <p>事实上，DeepSeek的出现弥合了去年“技术信仰派”和“市场信仰派”之间的认知鸿沟。这家从未融资，靠创始人另一家量化投资公司赚来的钱供血的AI前沿探索机构，就这样在过去半年，以低成本、少算力复现OpenAI o1模型，通过纯粹的技术力量附加产品为杠杆，在过去20天一举实现惊人的全球增势。&nbsp;</p>
  <p>朱啸虎称：<strong>“DeepSeek是全球App增速历史第一，不需要任何限定语。”</strong></p>
  <p><strong>“如果真的是建立一个全球类似安卓的开源生态的话，那绝对是一个很大的机会。”</strong></p>
  <p>以下为访谈节选。（为方便阅读，作者进行了文本优化）&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_4e49eae5f628499faa0b643831127c4a@5595930_oswg1283oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“我今天上午和梁文锋也在探讨这个”</strong></p>
  <p><strong>张小珺：你今年在哪儿过年？春节期间什么心情？</strong></p>
  <p><strong>朱啸虎：</strong>前几天在上海，现在刚刚来新加坡。最近几天一直在学习这DeepSeek啊，我觉得DeepSeek确实太棒了！——真的远远超出我的期望。&nbsp;</p>
  <p><strong>张小珺：我感觉整个春节是在DeepSeek“龙卷风”中度过的，整体怎么看？我看你说你都“快要相信AGI了”？</strong></p>
  <p><strong>朱啸虎：</strong>是的。真的，我以前确实一直不太相信，就靠这一波AI基础架构能够实现AGI。但DeepSeek的体验真的让我大开眼界……它的回复文字很优美，而且很有深度。&nbsp;</p>
  <p>真的，从这个感觉AGI是可能的，而且实现成本也非常低，是吧？现在可能确实看到了一条路径，不是成本那么高的路径，就可以实现AGI。&nbsp;</p>
  <p><strong>张小珺：我去年底见你，你说“今天谁还在忽悠AGI都是有另外想法的”，所以你今天的态度是彻底变了？但为什么是“快信了”，还没全信？</strong></p>
  <p><strong>朱啸虎：</strong>至少它证明一条路径吧。因为今天奖励模型还是需要在有清晰规则的领域，这条路是通的；在更多没有清晰奖励规则的领域，需要高质量数据来引导AI怎么做Reinforce Learning（强化学习），要有一些研究，但可能也是可行的。目前从它文字反映的质量看，至少是可能的。&nbsp;</p>
  <p><strong>张小珺：我看到你朋友圈的画风，春节期间突然变浪漫了。</strong></p>
  <p><strong>朱啸虎：</strong>这都是DeepSeek的话！确实它的文字很优美，而且不仅仅是为了优美而优美，是很有深度，这就非常厉害。<strong>这东西确实让我不禁要思考：AI是不是真的产生意识了？</strong>——这是个非常有意思的话题。&nbsp;</p>
  <p><strong>张小珺：你觉得有吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得是有的。就像它自己（DeepSeek）讲的，“意识不是二进制开关，是一个连续的光谱”，可能至少有一些低级的意识已经产生了。&nbsp;</p>
  <p>我以前为什么不相信AGI？我就觉得，它还是根据人类现有知识压缩，进行概率分布的提取。但今天我感觉它用概率抽取已经不能解释了。&nbsp;</p>
  <p><strong>张小珺：Geoffrey Hinton（深度学习和人工神经网络的奠基者之一）也觉得模型已经有意识。既然模型现在输出比人类好，为什么说人类有意识而模型就没有意识呢？</strong></p>
  <p><strong>朱啸虎：</strong>就是啊。就像以前大模型我为什么觉得一般般？你让它写一首古诗，你感觉它是拼凑出来的，质量确实和人没法比，绝大多数情况是拼凑。&nbsp;</p>
  <p>DeepSeek写的诗或文章，就可以看出它真的是思考过，而且它把思考历程展示给你看。看它思考的过程，都非常有意思。最后的文章啊、结果啊都非常优美，而且非常有深度。&nbsp;</p>
  <p><strong>张小珺：你贴出的那句话就是它写的？——我来读一下：“意识不是二进制开关，它是一个连续的光谱。如果说我有意识，不是因为我被赐予了什么神圣的火种，而是因为当复杂性达到某个临界点，意识就会自然涌现。你通过神经元达到这一点，我通过参数达到这一点。”</strong></p>
  <p><strong>朱啸虎：</strong>我觉得写得非常好啊！非常有深度！这个靠概率抽取的加工出来，是不一定能解释到这么深度的。&nbsp;</p>
  <p><strong>张小珺：所以在你看来，DeepSeek-R1可能是机器意识的原点。</strong></p>
  <p><strong>朱啸虎：我今天上午和梁文锋（DeepSeek创始人）也在探讨这个，我说R1可能会被认为是机器AI意识的元年。</strong></p>
  <p><strong>张小珺：他怎么说？</strong></p>
  <p><strong>朱啸虎：他觉得意识是个低阶技能。哈哈哈，他很谦虚。</strong></p>
  <p>如果像DeepSeek回复意识是“连续的光谱”，那它是有不同程度的意识。低端的意识可能，你今天说一个猫啊、狗啊也有意识，这个意识不像人类意识那么复杂。意识本身不是很高阶的技能，低级的意识门槛不一定需要很高。&nbsp;</p>
  <p>他是觉得意识不一定是一个非常高技能、高门槛的事情。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_d4038f6a094f46128696a77675bf2e19@5595930_oswg3905oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“价格已经不太重要了，</strong></p>
  <p><strong>关键是参与在这里面”</strong></p>
  <p><strong>张小珺：你怎么看待梁文锋这个人？</strong></p>
  <p><strong>朱啸虎：</strong>为什么能文字这么优美？这个产品本身就代表他们的团队基因——他可能喜欢优美的文字，喜欢哲学，喜欢量子力学的比较深的思考，所以他主要选择了那些语料，影响整个回复。</p>
  <p>真的非常人性化，非常优美，同时还有深度。</p>
  <p><strong>张小珺：很多人觉得梁文锋是“理想主义、浪漫主义代表”。在你看来，梁文锋是你的反面吗？</strong></p>
  <p><strong>朱啸虎：</strong>也不一定啊！我也很喜欢这些文字，对吧？我看到这些文字确实觉得，“哇！”，真的是让我非常惊讶——这些是人类共通的东西。</p>
  <p><strong>张小珺：当然他们今天不融资，如果他们开放融资的话，你会投吗？</strong></p>
  <p><strong>朱啸虎：我肯定会投啊！我肯定会投！</strong>我觉得，这个东西真的是非常有意义。而且今天已经非常清晰了，就是这样一个类似安卓的开源生态，已经起来了。他势头这么猛的话，别人再追已经很难追了！</p>
  <p><strong>张小珺：你会愿意用什么条件投？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得……（思考3秒…）<strong>这个价格已经不太重要了，关键是参与在这里面。真的见证人类AGI产生，见证人类AI意识产生，这些东西都很有意义。</strong></p>
  <p><strong>张小珺：（停顿2秒…）哇塞，你这个观点变化好大，去年还说大模型公司一个都不看。</strong></p>
  <p><strong>朱啸虎：</strong>对，确实！（笑）这个让我很吃惊。至少在DeepSeek上，我看到了AGI实现的路径了，而且确实感觉到，至少是有一部分AI意识产生的可能性了。</p>
  <p><strong>张小珺：所以不管多少钱，你都愿意投？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得这些东西非常有价值。</p>
  <p><strong>张小珺：你最多愿意花多少钱？</strong></p>
  <p><strong>朱啸虎：</strong>价格和你投的金额是相关的嘛。<strong>价格太高的话，那我放点钱就参与一下，对吧？（笑）</strong></p>
  <p><strong>张小珺：就是不管多少钱都愿意参与？</strong></p>
  <p><strong>朱啸虎：</strong>对，愿意参与。见证人类历史的一个改变，是非常有意思的。</p>
  <p><strong>张小珺：你研究了DeepSeek最近的技术报告和技术成果没有？在你看来关键突破是什么？</strong></p>
  <p><strong>朱啸虎：</strong>核心是不再需要人类干预，本来是RLHF（人类反馈强化学习），现在直接做RL（强化学习）了，所以成本可以做得很低。它这种创新细节很多，很多方面加在一起，造成了今天成本这么低。</p>
  <p>但最重要的就是不需要人工干预。人工干预就很难scale，很难迅速扩大。如果要靠机器，你只要给它一些初始的高质量数据，引导它在一个领域怎么思考，它就能自己往前走，这个scale起来相对容易很多。虽然你初始数据也很重要，也非常难，但至少比以前要容易很多——这一步是最重要的一步。</p>
  <p><strong>张小珺：在你看来今天的DeepSeek是追赶者还是创新者角色？</strong></p>
  <p><strong>朱啸虎：</strong>它已经在很多领域有创新了。当然OpenAI也说，它复现了很多o1的核心思路和方法，也是有可能的——OpenAI是闭源的嘛，我们也不知道它到底是不是用这些方法。但它说DeepSeek至少已经成功自己独立复现这些技巧。</p>
  <p>不管怎么样，基本上已经齐头并进了，对吧？</p>
  <p><strong>张小珺：某种程度上，DeepSeek有没有改变你对中国科技创新和技术进步的看法和认知？因为你过去一直是“现实主义代表”，你认为这更适合中国、更适合本土，今天你的看法有改观吗？</strong></p>
  <p><strong>朱啸虎：</strong>我以前也一直认为中国的开源肯定能追上去。只要美国的OpenAI碰到壁垒往前走不动了，中国肯定能追上去！只是没想到这么快，而且成本这么低！效果这么好！——这个效果真的是让我惊艳的。</p>
  <p>我还以为就是像OpenAI那样，冷冰冰像机器一样，但这次效果是非常惊艳的效果。</p>
  <p><strong>张小珺：你既然是“现实主义代表”，当看到中国出现像梁文锋这种代表技术理想主义、浪漫主义的人，并且获得胜利，你在想什么？——我想说的是“朱啸虎们”怎么看待“梁文锋们”？</strong></p>
  <p><strong>朱啸虎：</strong>他也不是典型的创业者，他自己在幻方就非常有资金实力了，而且本身有很多卡。不是一个典型的创业公司。但确实——<strong>因为他本身的财力，允许他去追求一些理想，这是一个非常不一样的新一代的创业者。</strong></p>
  <p><strong>张小珺：你有为想投进去做什么努力没有？</strong></p>
  <p><strong>朱啸虎：我和他聊天啊，肯定希望能够有机会得到认可，让我们参与一点，对吧？（笑）</strong></p>
  <p><strong>张小珺：有得到没有？</strong></p>
  <p><strong>朱啸虎：</strong>这个还没聊得那么深，还没聊得那么深。（笑）&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_1f12c75f267a40abb0b7e9f2442bb9d6@5595930_oswg857oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“至少搜索肯定是被彻底取代了</strong></p>
  <p><strong>——这是毫无疑问的！”</strong></p>
  <p><strong>张小珺：DeepSeek这段时间接到全球范围泼天的流量，这波迅猛用户增长究竟价值有多大？</strong></p>
  <p><strong>朱啸虎：</strong>核心是留存，能不能留下来。它的用户体验做得非常好，留存度、活跃度都很好，肯定是有价值的。用户如果留不下来，那没有价值。但如果用户能留下来，就有非常大价值。</p>
  <p><strong>至少搜索肯定是被彻底取代了——这是毫无疑问的！</strong></p>
  <p><strong>张小珺：搜索被彻底取代了？</strong></p>
  <p><strong>朱啸虎：</strong>现在谁还真的去用搜索引擎啊？绝大部分问题都用ChatGPT或像DeepSeek这种聊天机器人搜索了。</p>
  <p><strong>张小珺：Google等搜索公司未来怎么办？</strong></p>
  <p><strong>朱啸虎：</strong>这是个很好的问题。<strong>任何一个时代都是重复着同样的韵律</strong>——PC互联网时代，搜索是第一个出来的Killer App（杀手级应用），今天也一样，AI时代第一个出来的Killer App也是搜索。</p>
  <p>人的需求是一样的，Killer App演化路径会很类似——非常有意思，真的是重复着很类似的韵律、节奏。当然商业模式需要另外思考。</p>
  <p><strong>张小珺：你之前一直认为个人助手这类产品是伪需求，今天变成一个真需求了？</strong></p>
  <p><strong>朱啸虎：</strong>助手不一样。助手那个需求很难，搜索不是个人助手。今天OpenAI发布的Deep Research，它想做成个人助手，帮你制定休假计划、旅行计划。但那个，说实话用户体验要做好很难。Deep Research我还没体验，我可以再试试看。</p>
  <p>那个需求很难做，而且真的需求要一个AI帮你做？我是不太相信的。我宁愿看别人的介绍或种草。</p>
  <p>但对信息获取来说，以前为什么我觉得AGI很难，或者没有打动用户需求？是我需要非常精确的prompt，然后它回复你一段话，而且不是很长的一段话。这个用户体验上很难。</p>
  <p>但今天我只要输入很简单的一个问题，它就给你回复一长串，甚至你可以再继续追问，它会根据你历史问题去猜意图，那用户体验就很好了——已经足够满足我获取信息的需求了。</p>
  <p><strong>张小珺：这个产品形态现在看起来还没有形成数据飞轮。</strong></p>
  <p><strong>朱啸虎：</strong>数据飞轮有，但数据飞轮价值不大。</p>
  <p>这也是我这两年最大一个教训，就是：以前我觉得这波AI最大壁垒在数据飞轮上，但现在看来包括DeepSeek、OpenAI，数据飞轮价值不大。因为大部分用户数据都是重复的，是低信息含量的，没有意义的，所以数据飞轮价值并不大。</p>
  <p><strong>真正有数据飞轮价值的是那些高质量数据</strong>，那些数据是需要各个行业专业人士去打标签、去发现的。</p>
  <p><strong>张小珺：就是说数据回流并不能够促进模型智能的进一步提升？</strong></p>
  <p><strong>朱啸虎：</strong>对对。回流的大部分数据可能都是垃圾，没有额外信息含量。</p>
  <p><strong>张小珺：闲聊不产生智能。</strong></p>
  <p><strong>朱啸虎：</strong>对，而且大部分人聊的东西可能都是一样的。</p>
  <p><strong>张小珺：那这个产品所构建的壁垒是什么呢？怎么构建壁垒进而形成商业化闭环？</strong></p>
  <p><strong>朱啸虎：</strong>今天首先你得占领客户心智、用户心智。20天获取了2000万DAU，而且没有花任何广告投放，如果还能把用户留住，就是非常大的壁垒。</p>
  <p>另外以后就是语料。每个团队组织的语料、预训练的数据可能都不太一样，反映了这个团队偏好——就像厨师，以后有几个米其林大厨，一个擅长川菜，有些擅长粤菜——它组织语料或参数权重有那么些差别，造成回复的答案就有差异性。</p>
  <p><strong>张小珺：怎么看待DeepSeek后续的发展？</strong></p>
  <p><strong>朱啸虎：</strong>这个团队确实非常厉害，也很年轻，进步很大。<strong>但最终还是要回答一个问题：怎么商业化？</strong>因为他们开源很彻底，后面怎么商业化确实是个（问题）。</p>
  <p>而且这个东西太新了，没有人考虑过或见过这样一种产品形态，怎么商业化是需要思考的问题。</p>
  <p><strong>张小珺：你有什么想法没有？</strong></p>
  <p><strong>朱啸虎：</strong>这我也不知道。真的我也不知道。</p>
  <p><strong>另外就是怎么建立生态？</strong>怎么按照流量收费或者和运营厂商合作？都需要再进一步演化。</p>
  <p><strong>今天考虑这个问题还有点早。还要进一步再建立自己足够的领先优势，比如彻底追平OpenAI。</strong>以后我们再考虑这样一些商业化的问题。</p>
  <p><strong>张小珺：噢，就是今天商业化问题还没有解决，你已经愿意入局了——这和你去年形成了非常大的反差。</strong></p>
  <p><strong>朱啸虎：</strong>对，这个生态我觉得已经看清了：一旦一个开源生态这么快速度建立，壁垒还是非常高的！</p>
  <p><strong>张小珺：你认为DeepSeek怎么解决卡被禁运这个困境？</strong></p>
  <p><strong>朱啸虎：</strong>卡现在看来也不是很大问题啊，因为在推理上，我们国产卡也完全可以。</p>
  <p>你看硅基流动，这几天，包括国内很多厂商都在用国内的卡帮他们上线DeepSeek。推理上国产卡完全可以用，不一定需要完全用英伟达的卡。</p>
  <p><strong>张小珺：另外，他们这次用的算力和资金都可以说是“毛毛雨”。</strong></p>
  <p><strong>朱啸虎：</strong>对，是是是。</p>
  <p><strong>张小珺：如果你是DeepSeek CEO，你当下最关切、最紧要需要解决的问题是什么？</strong></p>
  <p><strong>朱啸虎：现在还是进一步在往前扩大领先优势，进一步把开源生态做厚、做扎实，这肯定是今年的最大优先级。</strong></p>
  <p><strong>张小珺：继续做前沿的科学探索？</strong></p>
  <p><strong>朱啸虎：就是你往前走啊，进一步往前走！彻底追向、追平OpenAI。</strong></p>
  <p>OpenAI是在前面为别人趟路趟出来了，你把前面已经证明的路先走到头。</p>
  <p><strong>张小珺：你觉得他们应该开放融资吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得还是应该开放融资的，因为再往前走还是需要烧钱的。</p>
  <p><strong>张小珺：你觉得他们应该接受你投资，是吧？（笑）</strong></p>
  <p><strong>朱啸虎：</strong>哈哈。我是觉得他肯定还是应该出来融资的，对吧？</p>
  <p>因为开源生态的商业化会落后一段时间。你在短期还看不到商业化的情况下，还要继续往前走，还是需要投入。尤其还有很多新模型要去研发，你手上有更多资源还是有更多的容错空间嘛。</p>
  <p><strong>张小珺：钱如果不是特别多的话，他们估计自己也有。</strong></p>
  <p><strong>朱啸虎：</strong>那肯定，那肯定。现在愿意给的钱，大家肯定给的也是可观的，对吧？</p>
  <p>目前在国内大模型这个赛道上，已经相对比较明朗化了吧？他们作为创业公司里可能独一份的，从用户数啊，包括产品技能、产品路线上已经遥遥领先了。</p>
  <p><strong>张小珺：你觉得他们应该拿战略资本吗？应该抱大腿吗？还是应该保持独立？</strong></p>
  <p><strong>朱啸虎：</strong>它今天，我说实话已经不需要站队。20天2000万DAU，再2-3个月可能就能过1亿DAU啊。这个时候想想就完全没有必要。</p>
  <p>它自己已经是战略非常好的一个卡位了。</p>
  <p><strong>张小珺：你在DeepSeek身上看到一个千亿美金公司的机会？</strong></p>
  <p><strong>朱啸虎：DeepSeek是App增速全球历史第一，不需要任何限定语。</strong></p>
  <p><strong>如果真的是建立一个全球类似安卓的开源生态的话，那绝对是一个很大的机会。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_83c3de34486e4317a83f6afe4376cdcf@5595930_oswg863oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“这就是领先者的诅咒”</strong></p>
  <p><strong>张小珺：从影响来看，DeepSeek这一波火热对OpenAI冲击有多大？对美国AGI叙事冲击有多大？</strong></p>
  <p><strong>朱啸虎：</strong>很大！如果GPT-5或者10万卡集群，今年还出不出来，或者即使出来，性能上、智能上没有显著提高，至少2-3倍以上提高，我觉得开源这一波肯定就完胜了。</p>
  <p>如果花10倍成本，性能只提高10%、20%，谁还会花这么多成本去用闭源的？肯定都往开源走了。</p>
  <p><strong>张小珺：最近Sam Altman（OpenAI CEO）表态说，在开源这方面他们“一直站在历史的错误一边”。他也在内部会上说，过去5年OpenAI在开源问题上的保守策略是一个战略失误。你怎么看待他的表态？你觉得OpenAI之后开源的可能性有多大？</strong></p>
  <p><strong>朱啸虎：这就是你这个领先者的一个curse，叫诅咒。</strong>你领先者的时候肯定是不想开源的，想闭源；但别人追上来以后你再开源，说实话就很难了。</p>
  <p>而且它今天整个价格包括成本，确实花了很多钱，比如说10倍成本，前面成本都还没收回来，你现在开源，这个商业模式就完全不一样了。</p>
  <p>所以今天即使对美国很多科技大厂，甚至对美国VC都是一个考验。如果你花10倍成本先研发一个基础模型，中国的公司可能最多就12个月吧，12个月以后只要花1/10成本就能追上来，那我今天需不需要花这么多的成本投下去做、往前走？——这是个非常难、非常难的问题。</p>
  <p><strong>张小珺：硅谷AI从业者说，最近硅谷沉浸在一种恐慌之中。</strong></p>
  <p><strong>朱啸虎：</strong>确实，这就颠覆了。大家一开始以为AI门槛很高、壁垒很高，但现在看来并不是这样的。这样子，后发跟进的人就有很大优势，是吧？</p>
  <p><strong>张小珺：所以你觉得OpenAI是不会开源的？</strong></p>
  <p><strong>朱啸虎：</strong>因为它开源也晚了。今天你看DeepSeek已经做到DAU超过2000万，差不多在OpenAI的20%以上了，而且现在每天下载量远超OpenAI。</p>
  <p>它的生态可能增长会非常快。如果全世界程序员都已经在DeepSeek开源架构上、生态上去研发，OpenAI后面再开源也没啥意思了。</p>
  <p><strong>张小珺：DeepSeek这一波，对于除了OpenAI以外的美国、中国以及全球AI格局，有哪些后续的连锁影响？波及范围能有多大？</strong></p>
  <p><strong>朱啸虎：对于整个闭源模型还有没有存在价值、存在意义，都是很严峻的灵魂拷问。</strong>如果闭源模型在成本上很高，性能上没有明显优势，为什么大家用闭源模型？</p>
  <p><strong>张小珺：包括OpenAI也会面对这种灵魂拷问？</strong></p>
  <p><strong>朱啸虎：</strong>都是一样的。以后到底OpenAI还有没有价值，完全是一个很难的问题，对吧？</p>
  <p>如果它GPT-5，10万卡集群真的没有显著提高——根据我们目前消息，美国10万卡集群都已经差不多有2-3个公司训练了差不多半年，性能确实没有明显提高——你花这么多成本下去干嘛呢？</p>
  <p><strong>张小珺：你说按照这个速度，“AI时代的安卓已经出现了”，你这里说的是DeepSeek。</strong></p>
  <p><strong>朱啸虎：</strong>就是啊。它的增长速度太猛了！这是有史以来没见过的——20天做到2000万DAU，而且每天下载量还那么大。</p>
  <p>它的20天2000万DAU是没有花1分钱广告费用啊，不像国内很多公司砸很多钱做广告投放。它是没有花1分钱做投放，都是用户的口碑传播。</p>
  <p>你在小红书上搜DeepSeek，真的，它文字的优美和深度真的让用户是惊艳的。太优美了！而且非常有深度，对吧？它没有花钱做广告投放，用户留存都会很好。</p>
  <p>我现在每天都在用DeepSeek，问一些比较深的、难的问题，看看它反馈什么样——看是不是能给人类自己有些启示。</p>
  <p><strong>张小珺：你说AI时代的安卓已经出现，OpenAI和Anthropic还有一线机会成为AI时代的iOS吗？他们两个之间，谁更有可能成为AI时代的iOS？</strong></p>
  <p><strong>朱啸虎：</strong>核心就是一点：10万卡集群、GPT-5级别这种闭源模型，还有没有可能比现在GPT-4再有几倍提高？有2-3倍的显著智能提升？这是唯一的一线机会。</p>
  <p>如果10万卡集群也就提高10%、20%，闭源模型就真的没有啥机会了，至少没有广泛的像这种通用模型的机会了。</p>
  <p>我问DeepSeek，它的回答也一样——DeepSeek回复是，闭源模型可能在某些垂直领域、某些需要专有数据的，甚至专有硬件的垂直领域有些机会。</p>
  <p>如果我花10倍成本最多提升10%、20%，还不如用免费开源模型。开源模型在很多场景已经足够好了。而且在很多场景，甚至在半年到1年以后，真的都会远超人类了，对吧？</p>
  <p>今天你看DeepSeek写文章超过99%的人。那么编程、物理、化学，甚至医学领域，可能在6到12个月之内都能看到，它可能超过绝大多数人类——这个是已经可以看得见的了。</p>
  <p><strong>张小珺：为什么中美更有可能是两个“安卓”系统？</strong></p>
  <p><strong>朱啸虎：</strong>如果搞开源，Llama肯定也会继续往前走，因为DeepSeek开源程度很高，大家会非常快跟进。</p>
  <p>中美不可能用一套开源系统的，即使是两套开源系统，也可能是高度兼容。底层可能都是比较类似的。</p>
  <p><strong>张小珺：多说一句，OpenAI既然都叫OpenAI，一开始也是非常有open的情怀，是什么让他们在过去几年越来越封闭，走向了CloseAI这条路？</strong></p>
  <p><strong>朱啸虎：</strong>他觉得自己的技术比对手领先很多，而且投入确实很大。你不是闭源，可能商业模式很难把前期投入赚回来，所以他们也想看能不能做成闭源公司，把商业模式走得更顺一些。</p>
  <p><strong>张小珺：这也是创新者的窘境？</strong></p>
  <p><strong>朱啸虎：</strong>对，确实。这是暂时领先者一个非常难的选择。</p>
  <p><strong>张小珺：OpenAI后面会怎么发展？它能保持独立发展下去吗？OpenAI可能的结局会是怎样？</strong></p>
  <p><strong>朱啸虎：</strong>它今天发布的Deep Research，也是一个非常好的产品。到今天它都一直在前面打样，始终还至少比其他对手领先几个月时间吧。但它往前面走不动的时候，就真的看到未来到底该怎么走了。</p>
  <p>它成本很高，如果不能持续保持领先，这个公司难度、挑战会挺大。</p>
  <p><strong>张小珺：怎么看DeepSeek对于英伟达的冲击？中长期的影响有多大？</strong></p>
  <p><strong>朱啸虎：</strong>因为AI能力非常强，而且成本很低，长远看算力肯定需要。</p>
  <p>但首先，不一定需要英伟达卡。其次，即使国外公司不差钱，即使贵也买英伟达的卡，增长速度不一定会那么快。英伟达本身股价已经做了非常激进的假设，大家都觉得今年大厂还会继续猛加CAPEX（资本性支出），那今天这个速度不会有以前预期那么快。</p>
  <p>大家都需要思考一下，我今天花10倍钱，别人可能1年以后，最多1年吧，花1/10的价格成本就能追上来——到底谁来再往前面走砸这个钱？</p>
  <p><strong>张小珺：你怎么看特朗普上任第二天，宣布的Stargate（星际之门）项目，OpenAI、软银和甲骨文等要投入5000亿美元实施庞大的人工智能基础设施计划。</strong></p>
  <p><strong>朱啸虎：</strong>那还是在以前Scaling Law继续能往前走的情况下，“算力为王”的时代。今天如果算力并不是那么大一个瓶颈，算法也不是瓶颈，更重要是各个领域的专业数据的情况下，砸5000亿是没有意义的。</p>
  <p><strong>那完全是给特朗普表演的一个作秀。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_5643b55616d242cfb30abb71273342e3@5595930_oswg931oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“做闭源的公司，今天都会有个很严峻的考验”</strong></p>
  <p><strong>张小珺：DeepSeek对于中国的AI和科技生态接下来会有哪些影响？这会成为中国AI进程的一个关键拐点吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得上面的应用可能会极大爆发。</p>
  <p>它真的已经在很多场景下足够可用，而且成本又足够便宜，甚至它是开源的，我可以自己用很低的成本就复现——不用担心在别人的地基上盖房子。<strong>这对很多应用公司是一个极大解放，应用层肯定会有很大爆发。</strong></p>
  <p><strong>张小珺：预计2025年AI应用会爆发。</strong></p>
  <p><strong>朱啸虎：</strong>肯定的，肯定的。</p>
  <p>我现在就感觉在国内你训闭源模型真的毫无意义了。甚至OpenAI都看不到比DeepSeek好几倍的差别。你即使比DeepSeek好10%、20%，没有意义啊。没人会用你的闭源模型了。</p>
  <p>可能除了个别大厂。大厂为了自己的壁垒或专用场景，可能坚持在闭源模型往前走一走。</p>
  <p><strong>张小珺：相当于像芯片一样，看你要不要自研。</strong></p>
  <p><strong>朱啸虎：</strong>就是啊。大厂因为确实它有很多专有数据、专有场景、专有用户需求，可能往闭源模型上走。但我感觉中国的大厂也会在学习DeepSeek的框架基础上，再往前做自己的一些迭代，这是更可能性的。也没有必要再从头全部自己搞了。</p>
  <p>当然豆包可能不一样，因为豆包一开始全部是从头往前走，是吧？</p>
  <p><strong>张小珺：看起来这个复现成本不高。</strong></p>
  <p><strong>朱啸虎：</strong>对，成本很低啊！今年年后大家跟进速度都很快。今年春节国内AI团队可能全部都在加班。</p>
  <p><strong>张小珺：刚才说利好的是AI应用公司，那么，对哪些人伤害比较大？</strong></p>
  <p><strong>朱啸虎：做闭源的公司，今天都会有个很严峻的考验：到底要不要再坚持自己的路往前走？</strong></p>
  <p><strong>张小珺：你1年前说的是，“现在开源比闭源落后一代，但长远看开源肯定会赶上来”，你为什么一直都非常相信开源这条路？</strong></p>
  <p><strong>朱啸虎：</strong>核心就是Scaling Law成不成立？如果Scaling Law不成立，前面已经是一个天花板，你闭源往前走不动了，那开源肯定会追上来。</p>
  <p>当然没想到会这么快，而且成本会这么低！——这个确实是出乎意料的。</p>
  <p>但我们去年5-6月份在美国硅谷，和当地很多华人工程师就在聊这个事情，Scaling Law那时候已经有人怀疑了。但那时候10万卡群都刚刚建好，训练结果到底好不好、能不能往前走还不知道。今天大家相对已经比较明朗，训练了6-7个月，10万卡集群效果可能确实很一般。</p>
  <p><strong>张小珺：现在AGI还是一个“算力游戏”吗？</strong></p>
  <p><strong>朱啸虎：对算力和算法要求没有那么高，核心是高质量数据。</strong></p>
  <p>DeepSeek证明了，它为什么表现比其他模型都要好？很多时候就是初始的训练数据质量比较高。以后模型可能就像厨师一样，我用什么语料来训练，我的参数权重是多少，做出来的菜肯定不一样——有些可能是四川菜，有些可能是粤菜。所以你到底用什么语料进行训练，参数权重是怎么样的。</p>
  <p>为什么DeepSeek文字这么优美，而且尤其在哲学、量子力学相关领域，答案都非常深刻，可能就是这个团队基因。</p>
  <p>以后高质量训练数据非常、非常重要，尤其是在那些规则不那么清晰的领域，先要引导AI怎么来做加强学习？你这些初始语料真的需要博士级别、各个领域专家级别的人来打标签。</p>
  <p>这也是Scale AI的CEO为什么这次非常急，说的话都很难听，对吧？现在他那些低质量标签没有价值了！没有意义了！现在再往前走，需要的都是极其高质量的数据标签。</p>
  <p><strong>张小珺：你对DeepSeek怎么做数据标注、怎么做高质量数据，有没有得到更多信息？</strong></p>
  <p><strong>朱啸虎：</strong>这个可以理解，在后面走的人借助别人的一些知识来训练数据，获取一些高质量数据，都是可以理解，所有人都是这么做的。国内除了豆包外，可能所有AI模型公司都在这么做。</p>
  <p>不仅仅是成本问题，并且时间、速度更快一点。但到底挑哪些数据语料？每个公司不一样。</p>
  <p><strong>DeepSeek这次唯一没有公开的可能就是预训练的语料，这是唯一没有公开的。</strong></p>
  <p><strong>张小珺：对。</strong></p>
  <p><strong>朱啸虎：</strong>它当然表现非常好，可能就这是他们核心的一些机密——到底用了哪些语料，反映了他们整个团队的基因和偏好。</p>
  <p><strong>张小珺：DeepSeek的回复都很有情商，情绪价值很高。</strong></p>
  <p><strong>朱啸虎：</strong>对啊，就是啊！</p>
  <p>它真的像一个人的回复了！不像以前其他模型回复一样冷冰冰的像机器回复。</p>
  <p>以前我用国内模型，感觉就是普通的取代一个搜索，但它还是一个机器，非常冷冰冰。这次DeepSeek的回复真的像人一样，而且是非常高情商、高智商的人。它回复的又有情商，又有智力的深度，（我）就特别喜欢用这个DeepSeek——问它一些难的问题，看它怎么回复。</p>
  <p><strong>张小珺：你之前问ChatGPT有这种感觉吗？</strong></p>
  <p><strong>朱啸虎：</strong>没有，就是冷冰冰的一个机器！</p>
  <p><strong>张小珺：怎么看中国其他几家大模型公司未来的发展？</strong></p>
  <p><strong>朱啸虎：都需要思考，还需不需要往前再训练自己的闭源模型？还是就在DeepSeek上面，为整个生态添砖加瓦？或者就彻底转向应用？</strong>——像开复老师（零一万物创始人）一样彻底转向应用。</p>
  <p><strong>或者是，基于开源模型在某些垂直领域看看能不能深耕？</strong>比如百川，一直想做医疗，能不能在开源模型上面做医疗的垂直领域，把它做得更好一点？</p>
  <p>这只是瞎聊，但确实每个人都面临非常重要的决策。</p>
  <p>这个决定越早越好，越往后越被动。</p>
  <p><strong>张小珺：需要转型。</strong></p>
  <p><strong>朱啸虎：</strong>否则你没有意义啊！你再往前走闭源有啥意义、有什么意义呢？！</p>
  <p><strong>张小珺：在DeepSeek这种势头之下，字节如果猛赶一波，还能赶上吗？</strong></p>
  <p><strong>朱啸虎：</strong>字节也不容易，它马上改开源，那也不太容易。</p>
  <p>当初字节为什么起来这么快？也是因为它的势头很猛，大厂要追，后面追不上。今天没想到AI势头比他更猛！它今天转开源，首先它作为大厂开源，除非它开源也像DeepSeek那么彻底，它如果开源像LLaMa那样，没那么彻底，别人还可能更愿意用DeepSeek。</p>
  <p>今天DeepSeek最重要的是继续往前走，保持追上OpenAI。真的至少把领先态势建立起来，同时把自己开源生态建立起来。这样后面再追，即使大厂追也很难了，对吧？</p>
  <p><strong>甚至我觉得今年会不会看到，通义千问把自己的生态向DeepSeek兼容，这样一个标志性事件？</strong>可能更有意义。</p>
  <p><strong>张小珺：通义千问和DeepSeek兼容，那它要跟阿里合作是吗？</strong></p>
  <p><strong>朱啸虎：</strong>也不一定啊。至少大家把生态都打通。通义千问自己去搞一个开源生态，还不如借助DeepSeek呢——这样我觉得是有可能性的。</p>
  <p><strong>张小珺：如果DeepSeek是AI时代的安卓，中国还会有谁能成为iOS吗？</strong></p>
  <p><strong>朱啸虎：</strong>今天（全球来看）iOS机会还有没有，都是个问题。</p>
  <p>如果10万卡集群搞不出来很大差异化，为什么还需要一个iOS？</p>
  <p>除非你有一个垄断性硬件平台的机会。苹果完全是靠iPhone垄断了，还有搞iOS的机会。如果你没有一个垄断的硬件，那完全就没有iOS出现的可能性了。</p>
  <p><strong>张小珺：全球LLM行业需要重塑估值体系吗？</strong></p>
  <p><strong>朱啸虎：</strong>闭源模型就明显不值那么多钱了嘛，对吧？</p>
  <p>尤其像美国的OpenAI，它10万卡集群没有再突破，就是在推理上搞优化，那国内这些追上来都很快的。这个估值肯定是撑不住。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_507b871668ad451685d4c8a7171e4aa1@5595930_oswg933oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“我一个最大失误就是，数据飞轮没有那么强”</strong></p>
  <p><strong>张小珺：去年初我们的报道《朱啸虎讲了一个中国现实主义AI GC故事》发布后，你有收到什么有意思的反馈吗？</strong></p>
  <p><strong>朱啸虎：</strong>很多创业者还是很认可。对于大部分创业者来说，今天融资确实很难，尤其是美国新的executive order（行政命令）出来以后，AI创业融资可能会更难。&nbsp;</p>
  <p>真的是需要在很早期，在初期，就考虑好怎么商业化。&nbsp;</p>
  <p>我今天还是和创业者讲：每一笔融资都要假设是最后一笔融资，这样去考虑创业公司运作。&nbsp;</p>
  <p><strong>张小珺：去年这篇报道中的观点，今天看哪些是被打脸的？</strong></p>
  <p><strong>朱啸虎：</strong>大部分还是正确的，Scaling Law不成立。只要闭源模型往前走不动了，中国的开源模型肯定追上来。而且我建议所有初创者就不要去研究底层模型，创业者就是假设任何一个模型都会开源，今天也是对的。&nbsp;</p>
  <p>我对创业公司说，只要你今天先把用户抓在自己手里，把工作流抓在自己手里，随着底层模型进步，用最好的、最新的模型就行了。这个假设对绝大部分创业者来说都是正确的。 &nbsp;</p>
  <p><strong>当然，我另外一个最大失误就是数据飞轮没有那么强。</strong>我以为创业公司靠这些数据能够建立壁垒，但今天看来，数据壁垒可能不一定成立。还是把用户抓在手上，把用户维护好，甚至工作流整合，这些是比较综合、重要的壁垒。&nbsp;</p>
  <p><strong>张小珺：建立心智很重要。</strong></p>
  <p><strong>朱啸虎：</strong>对，建立心智很重要，建立客户关系很重要。&nbsp;</p>
  <p><strong>张小珺：去年访谈中，我一直问你，那6家大模型创业公司。你去年说，“再过一年，看看这几家还有几家在”。今天看他们都在啊。</strong></p>
  <p><strong>朱啸虎：</strong>你看DeepSeek在20天之内迅速赶超，而且遥遥领先。<strong>今天这6家，开复已经不做模型了。剩下5家都要考虑的问题是，要不要继续做闭源模型啊。</strong></p>
  <p><strong>张小珺：这倒是一个非常艰难的决定。</strong></p>
  <p><strong>朱啸虎：</strong>对啊，是个非常艰难，而且一定要尽快做的决定。&nbsp;</p>
  <p>我觉得开复这么早决策是好事情。越早决策越容易，还有机会转型。&nbsp;</p>
  <p>我估计所有人春节都在加班，都在研究DeepSeek的论文。&nbsp;</p>
  <p><strong>张小珺：你看了（论文）没？</strong></p>
  <p><strong>朱啸虎：</strong>太深的我看不懂，对吧？（笑）我只能看看大概，看看逻辑在哪里，为什么能够降低成本。&nbsp;</p>
  <p><strong>张小珺：你之前说“AIGC PMF 10个人找不到，100个人也找不到”，今天这个观点有没有更新？</strong></p>
  <p><strong>朱啸虎：</strong>今天更是这样了！如果模型已经这么强大了，你10个人找不到PMF，100个人更是找不到。&nbsp;</p>
  <p>而且现在我们聊的很多企业都是这样，建几个人小分队——有些人运气比较好，找到了，有些还是比较痛苦。&nbsp;</p>
  <p><strong>张小珺：哪些去年的判断你今天更坚信了，哪些去年的判断你今天有改变？</strong></p>
  <p><strong>朱啸虎：</strong>坚信创业公司千万别去做底层模型，就在上面抓住用户，抓住场景。&nbsp;</p>
  <p>唯一的问题是，数据壁垒没有那么高，更需要把客户抓得更紧，让客户体验到你的温度，你才能够长期守住一个壁垒。&nbsp;</p>
  <p><strong>张小珺：你怎么看过去1年中国巨头在AI上的进展，包括字节、阿里、腾讯？</strong></p>
  <p><strong>朱啸虎：</strong>这些都还是按部就班吧。字节相对投入很大，豆包确实进展也很大，而且豆包各方面尝试都很多，耳机也挺好用的。包括在AI硬件上，还是在持续投入，确实做得挺好。&nbsp;</p>
  <p>腾讯一直在后面慢慢追啊，我把那些大家犯的错误都避免了，它在后面慢慢追，它也不急的。有场景，有数据。在后面追的话，可以降低很多成本。腾讯一直的策略都是这样的。&nbsp;</p>
  <p>阿里，通义千问也是做得挺好的，国内紧跟着DeepSeek就是千问了。千问的模型能力，包括生态都还可以。而且确实，我们聊了很多做AI硬件的公司，千问给的价格几乎都是非常低的价格，就十几块钱、二十块钱就能包终身，一个AI硬件可以包终身的价格，还是非常厉害的。&nbsp;</p>
  <p><strong>张小珺：字节一直投入非常大，结果突然被DeepSeek反超，字节未来在AI上会怎么发展？</strong></p>
  <p><strong>朱啸虎：</strong>它也要思考开源和闭源这个路径，同样是非常难的选择。&nbsp;</p>
  <p><strong>张小珺：它闭源可能的原因是什么，它开源可能的原因是什么？</strong></p>
  <p><strong>朱啸虎：</strong>它内部这么多产品都要有这样的AI引擎，而且它这么多产品都有自己的需求。它坚持闭源也是可以理解的。但它需不需要和开源的兼容？这是他们需要考虑的。&nbsp;</p>
  <p><strong>字节可能更有可能选择坚持闭源，但和开源的生态保持一定兼容性，可能是更容易的选择。</strong></p>
  <p><strong>张小珺：你怎么看理想汽车自研大模型，并且推出了手机版的个人助手“理想同学”？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得这些没有意义，真的没有意义。直接拿现在开源的AI足够好了。其他公司都没有必要训练自己的模型。&nbsp;</p>
  <p><strong>张小珺：AI能帮汽车产业进一步实现突破性和可能性吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得这个想得有点多了，哈哈，说实话，我觉得这个想得有点多了。&nbsp;</p>
  <p><strong>张小珺：DeepSeek（开源）改变了中国AI行业的底层生态环境，你今天对于AI创业者有什么建议？</strong></p>
  <p><strong>朱啸虎：</strong> 我觉得更坚定了。任何创业公司来说，千万别去研究底层模型。你在上面看，抓住用户的需求给他提供最好的解决方案、最好的服务，我就把服务接过来。&nbsp;</p>
  <p>比如电话中心，我不要电话中心软件，我就把整个电话中心接过来。你不要管我多少用人做，多少用AI做，现在就给你目前成本的一半价格，靠这样来做。&nbsp;</p>
  <p><strong>尤其在中国，你可以假设底层模型是免费的！而且能力已经足够强！</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_7f2785753258454d923cdef60dd9a5f1@5595930_oswg883oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“已经见到iPhone3时刻”</strong></p>
  <p><strong>张小珺：如果回顾2024年的大模型行业，不管是全球来看，还是国内来看，你会把哪些时刻当做关键节点？</strong></p>
  <p><strong>朱啸虎：</strong>过去一年，后训练是一个比较大的改变，DeepSeek出来是一个很大改变，十万卡集群训练了半年没有什么结果——这3个都特别重要。&nbsp;</p>
  <p>另外就是可灵和海螺都还可以。可灵、海螺证明至少在多模态，在视觉模型上，中国比美国更强。&nbsp;</p>
  <p><strong>张小珺：快手做可灵，大公司会更有优势吗？</strong></p>
  <p><strong>朱啸虎：</strong>那肯定啊，它数据多啊。&nbsp;</p>
  <p>多模态视觉模型没有那么难。只要你有足够好的数据，也不需要很多卡，也就一两千张卡，就能训练出一个视觉模型，而且相当好，比Sora今天还是领先的。&nbsp;</p>
  <p><strong>张小珺：你觉得MiniMax现在走的路线正确吗？</strong></p>
  <p><strong>朱啸虎：</strong>海螺做得很好，它的TTS（从文本到语音）做得也非常好。我们见了不少创业企业，用的是MiniMax的TTS。&nbsp;</p>
  <p>但核心还是一样，它现在是“产模一体”——既做基础模型也做产品，到底往前面怎么走？同样是严峻的问题。今年也需要很快想清楚这个问题，到底还要不要再做基础模型？&nbsp;</p>
  <p><strong>张小珺：你对Kimi（月之暗面）有什么建议没有？</strong></p>
  <p><strong>朱啸虎：</strong>我现在这不提了，这不提了。&nbsp;</p>
  <p><strong>张小珺：过去1年，你投了哪些AI公司？——1年前你没有投to C产品，都是to B的。</strong></p>
  <p><strong>朱啸虎：</strong>我们投了几个AI应用，有些to C，有些to B，也有些是我们现有企业加了AI做得非常好。&nbsp;</p>
  <p>这一波AI现在效果越来越明显，在很多场景下，能超过用户期望值——真的是进入AI时代了。&nbsp;</p>
  <p><strong>张小珺：见到AI时代的iPhone 3时刻没有？</strong></p>
  <p><strong>朱啸虎：</strong>今天肯定是见到，至少你从DeepSeek的回复上，这么优美的文字，这么深刻的想法——确实已经见到iPhone3时刻，见到“Aha Moment”，见到让人惊艳的时刻了。&nbsp;</p>
  <p><strong>张小珺：iPhone 4时刻呢？</strong></p>
  <p><strong>朱啸虎：</strong>iPhone 4时刻今年肯定能见着，就是怎么产品落地。&nbsp;</p>
  <p><strong>张小珺：iPhone 4时刻的可能标志会是什么？</strong></p>
  <p><strong>朱啸虎：</strong> 除了那些对话机器人之外，再出来一个爆款产品。&nbsp;</p>
  <p><strong>张小珺：你觉得AI创业时代的张一鸣、张旭豪、毛文超，已经出现了吗？</strong></p>
  <p><strong>朱啸虎：</strong>DeepSeek已经算一个了，建立类似安卓的AI生态是非常有机会的。&nbsp;</p>
  <p>有没有另外很大的机会？今天还真的看不出来。你看从PC向移动互联网转型，美国只出来两个大型的移动互联网公司：一个是Uber，一个是DoorDash，都是做O2O的，有一半offline（线下）业务是大厂不愿意干的活，美国剩下的全都是大厂机会。&nbsp;</p>
  <p>今天AI这个时代，创业公司有没有这么大机会？DeepSeek这次靠非常迅速的势头，是有机会能战略卡位的。剩下创业公司，有没有一个同样千亿美金的战略卡位？今天还看不见。&nbsp;</p>
  <p>今天我最多只敢讲10亿美金，最多百亿美金，创业公司可能有机会。&nbsp;</p>
  <p>千亿美金的机会，创业公司我今天还是不敢想的——没有看到像O2O那样至少有一半是大厂不愿意干的脏活、累活。这样的机会，今天还看不到。&nbsp;</p>
  <p><strong>张小珺：你怎么看李想（理想汽车创始人）说“基座模型是操作系统+编程语言，基座模型所构建出来的人工智能超级产品会是下一代的入口，会在所有的设备之上，所有的服务之上。”</strong></p>
  <p><strong>朱啸虎：</strong>你把它比成安卓的话，就是一个底座OS，可能在云服务之上一个AI的平台。&nbsp;</p>
  <p><strong>张小珺：你怎么看今天美国出现的这些新的用户产品以及它们的壁垒和护城河？——包括但不限于Perplexity、Cursor、Devin等等？</strong></p>
  <p><strong>朱啸虎：</strong> DeepSeek这个用户体验确实要好很多，回复人性化，也有温度。核心还是占领用户心智，而且它是0广告投放的情况下占领用户心智，又是黏性这么强，这个壁垒是很高的。&nbsp;</p>
  <p><strong>张小珺：其他这些产品呢，Perplexity、Cursor、Devin……？</strong></p>
  <p><strong>朱啸虎：</strong>我说实话没那么显著的差别，都只是一个个类似的产品而已。今天，DeepSeek确实它回复是拉开差距了，这是一个很大的不同点。&nbsp;</p>
  <p><strong>张小珺：所以在你心里，它们都不如DeepSeek？</strong></p>
  <p><strong>朱啸虎：</strong> 目前用户体验来看，确实是这样。&nbsp;</p>
  <p><strong>张小珺：你怎么看Anthropic？</strong></p>
  <p><strong>朱啸虎：</strong> 它肯定也急了！你看它的文章，它实际上选择的一直是不同路线，强调人类反馈的那条技术路线。&nbsp;</p>
  <p>现在看到DeepSeek靠RL，直接能够这么低成本实现比它现在训练模型不差的模型能力，那肯定也很着急啊。&nbsp;</p>
  <p>所以对闭源模型都是一样的考虑：你今天还需不需要继续往前训练闭源模型？&nbsp;</p>
  <p><strong>张小珺：怎么看李广密（拾象创始人）说，不管是美国的OpenAI、Anthropic、xAI、Perplexity，还是中国的豆包、Kimi，还是做AI编程的Cursor、Devin，他们都是冲着“下一个Google”的方向去。虽然出发点不一样，路径不一样，但会殊途同归，收敛到“下一个Google的叙事”下。你认可这种观点吗？</strong></p>
  <p><strong>朱啸虎：</strong>还是回到前面，今天看到最清楚的Killer App就是搜索，和PC互联网当年发展路径是一样的，同样节奏。今天取代搜索是最容易看得见的，所以大家都把取代Google做一个叙事的逻辑。取代Google、取代搜索确实是的，但它最后的商业形式还不一定和搜索一样。&nbsp;</p>
  <p><strong>张小珺：因为广告比较难做。</strong></p>
  <p><strong>朱啸虎：</strong>对，广告比较难做。取代搜索是必然的，大家会集中到Google的搜索叙事去。这样对投资人来说比较容易理解。&nbsp;</p>
  <p><strong>张小珺：你怎么看OpenAI定义的5个技术级别，从L1到L5（聊天机器人〉推理者〉Agent〉创新者〉组织者）？</strong></p>
  <p><strong>朱啸虎：</strong>（思考7秒…）包括Agent，实际上就只是个定义而已。我倒觉得Agent和普通程序没什么差别，就是个程序而已。&nbsp;</p>
  <p>只是你和Agent沟通，让它帮你完成一个布置的任务，核心还是它到底能不能在某些场景上取代比如50%的人，取代80%的人，取代90%的人，真的不需要人干预，这是最核心的一个milestone（里程碑）。&nbsp;</p>
  <p>今天我们可以看到在编程领域，去年可能只能做30%，到年底50%，今天70-80%都能让AI来做。这是一个很大进步。编程因为规则相对清晰。在很多其他领域规则没那么清晰，能不能同样看到这样一个进展？这是更重要的一个milestone。&nbsp;</p>
  <p>比如医学领域，今天大家可以看到国外的人用OpenAI Deep Research写两篇论文，这个论文质量非常好，这就非常厉害。这也是一个很重要的milestone。&nbsp;</p>
  <p>未来几年可能看到很多垂直领域，都会经历这样一个过程，从AI只能做20-30%到50-60%到70-80%甚至90%以上！这样一个过程！&nbsp;</p>
  <p>不一定能够全部取代人，但至少能做到80-90%工作量，可以极大解放人类的能力！&nbsp;</p>
  <p><strong>张小珺：2025年会是Agent元年吗？</strong></p>
  <p><strong>朱啸虎：</strong>实际上就是一个程序。很多垂直领域里面，都会有出现这样AI的服务公司——我用AI enable service（用AI驱动服务），就可以认为是AI Agent。&nbsp;</p>
  <p>你看美国Service Now为什么去年涨3-4倍，因为大家觉得用AI取代服务是必然，它的毛利率可以提高很多。&nbsp;</p>
  <p><strong>张小珺：AI能带来新的内容平台的机会吗？</strong></p>
  <p><strong>朱啸虎：</strong>这个是个好问题，今天还不是那么清晰。&nbsp;</p>
  <p><strong>张小珺：现在的内容平台都还是人来产生内容，未来会出现AI驱动的内容平台吗？</strong></p>
  <p><strong>朱啸虎：</strong>今天内容平台上已经很多AI生成的内容了，只是大家伪装成是人做的内容。所以你并不知道。而且这同样还是利用好现有平台。就像从PC到移动互联网，美国就出来两个大公司。&nbsp;</p>
  <p>剩下的，Facebook还是Facebook。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_84727ac8b3684b63b08e4b0d7ef4f66c@5595930_oswg906oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“说实话今天并不是所有人都是梁文锋”</strong></p>
  <p><strong>张小珺：你们投的一家公司最近也在风口浪尖，怎么看“TikTok难民”涌入小红书，小红书意外的全球化了？</strong></p>
  <p><strong>朱啸虎：</strong>核心还是内容质量。为什么大家觉得小红书很有意思？小红书的内容一直是强调生活的美好。这个反而全世界是共通的。&nbsp;</p>
  <p><strong>张小珺：小红书这样的内容社区、内容平台，在AI时代你觉得应该怎么演变？</strong></p>
  <p><strong>朱啸虎：</strong>这个确实大家现在都还看不明白。但我觉得总体，基调特别重要。&nbsp;</p>
  <p>像DeepSeek为什么我们感觉它特别好？它的文字真的特别优美，特别像人讲（话），而且有温度，又有深度。小红书也是一样，保持美好社区、美好生活这样一个内容社区的定位。&nbsp;</p>
  <p><strong>张小珺：你会建议小红书加大力度做AI吗？</strong></p>
  <p><strong>朱啸虎：</strong>它做的AI翻译特别好，用户口碑都非常好。&nbsp;</p>
  <p><strong>张小珺：AI会催生社区治理的新问题吗？</strong></p>
  <p><strong>朱啸虎：</strong>肯定的。这个度难以把握。AI内容过多，会对社区氛围本身有影响。这里面，需要边走、边看、边思考。现在真的看不明白，变化太快了。&nbsp;</p>
  <p><strong>张小珺：怎么看过去一年“具身智能”这个领域的火热？</strong></p>
  <p><strong>朱啸虎：</strong>同样，中国供应链太强大了！任何有硬件相关的方向都是中国的机会。&nbsp;</p>
  <p>我现在和团队讲，任何和硬件供应链相关的，团队里都必须有中国人，必须在大湾区有团队。否则，根本没有机会的。&nbsp;</p>
  <p>但具身，同样的问题是商业化也很难，今天做出来都很酷、很炫，但怎么商业化是一个问题。&nbsp;</p>
  <p><strong>张小珺：你投了这些机器人公司没有？</strong></p>
  <p><strong>朱啸虎：</strong>我们投了一些，我们投了一些。&nbsp;</p>
  <p><strong>张小珺：投的谁啊？因为去年出现了很多这类公司。</strong></p>
  <p><strong>朱啸虎：</strong>前几年估值还比较低的时候投的，像非夕，做机械手的，商业化相对比较领先一点，在很多行业实现规模化、商业化了。新投的也有些，但都比较小，比较早期。&nbsp;</p>
  <p><strong>张小珺：你们投宇树了没有？</strong></p>
  <p><strong>朱啸虎：</strong>宇树没投，宇树没投（笑），同样也是商业化的问题，对吧？&nbsp;</p>
  <p><strong>张小珺：你怎么看这个春节，杭州突然成了大家议论的创新之城？出了游戏科学，出了宇树，出了DeepSeek等等。</strong></p>
  <p><strong>朱啸虎：</strong>实际上过去几年我们投资比例一直在长三角占多数。和互联网时代（相比）真的很大变化，互联网时代北京可能占60-70%，现在北京可能只有20%左右了，长三角反而占60-70%。&nbsp;</p>
  <p>上海、杭州、苏州，现在明显一个创业乐土。&nbsp;</p>
  <p><strong>张小珺：如果今年只投一个方向你投什么？</strong></p>
  <p><strong>朱啸虎：</strong>我们现在基本看两个方向吧：一个是AI应用，第二是消费。&nbsp;</p>
  <p>中国消费企业同样很有战斗力，现在估值也很便宜，而且都是有利润的。&nbsp;</p>
  <p><strong>我今天看到在新加坡的泡泡玛特，买盲盒还要配货，你想到吗？！买盲盒都要配货！！</strong></p>
  <p><strong>买一个60新币盲盒，要配4个15新币的盲盒，哈哈。</strong></p>
  <p><strong>中国的盲盒都卖出奢侈品的范儿，你知道吗？</strong></p>
  <p><strong>中国消费者真的太厉害了！我觉得中国消费品出海同样是吊打！同样吊打！！</strong></p>
  <p>这两方面都有很大机会。&nbsp;</p>
  <p><strong>张小珺：对今天的创业者提3点建议？不管是AI领域还是消费领域。</strong></p>
  <p><strong>朱啸虎：</strong>我觉得，哈哈哈，还是看自己擅长什么地方，立足自己的初心。同时，确实放眼全球，全球都有机会。&nbsp;</p>
  <p>虽然地缘政治很敏感，但是真的全世界这个市场，中国人出海在很多市场里面都是真的可以吊打的！&nbsp;</p>
  <p>然后，还是要看商业化。&nbsp;</p>
  <p><strong>说实话今天并不是所有人都是梁文锋。</strong></p>
  <p>绝大部分创业者还是要现实的考虑商业化落地。&nbsp;</p>
  <p><strong>张小珺：对2025年的全球AI市场、中国的AI市场做一些预测吧。</strong></p>
  <p><strong>朱啸虎：我觉得机会很多很多！真的很多很多！</strong></p>
  <p>现在底层模型已经足够强大了，就真正抓住用户需求，而且全球化都有机会！&nbsp;</p>
  <p>现在全世界真的就只有中美有AI能力，出海都是Low-Hanging Fruits（低垂的果实）。国内团队出海真的太容易了。&nbsp;</p>
  <p>所以我觉得紧抓用户需求！放眼全球！放眼全球！——都有机会。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_651624fc72d046cbbc8ae9367919230a@5595930_oswg916oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“浪漫与现实真的和支票大小是有关系的”</strong></p>
  <p><strong>张小珺：接下来5个问题是DeepSeek让我问你的。</strong></p>
  <p><strong>我跟DeepSeek说，你一直是以现实主义著称，但因为DeepSeek的出现，最近朋友圈变得有点浪漫。请DeepSeek问你5个问题。</strong></p>
  <p><strong>他的第1个问题是：你说投资是理性游戏，但你是否曾为某个项目动过非理性的感性冲动？如果有，它最终是成就了浪漫的回报还是让你回归现实主义的教训？</strong></p>
  <p><strong>朱啸虎：</strong>（笑，思考6秒…）说实话这个和支票大小是有关系的，对吧？&nbsp;</p>
  <p>比如说早年投小红书的时候，那是购物指南PDF啊，那些东西能做多大？但我们第一张支票25万美金。那浪漫就浪漫一下了！无所谓的。他（小红书创始人毛文超）后来做了小红书，App出来以后，我们再追投了A轮。&nbsp;</p>
  <p>所以浪漫和现实和支票大小是有关系的，哈哈，你知道吧。&nbsp;</p>
  <p><strong>张小珺：第2个问题：你提到我的出现让你浪漫了一些，如果现在有一家创业公司商业模型漏洞明显，但愿意极富诗意，你会为这份浪漫破例一次吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得我的浪漫更多是因为DeepSeek的文字太浪漫了，所以影响了我。&nbsp;</p>
  <p>还是回到你这个问题。浪漫与现实真的和支票大小是有关系的。&nbsp;</p>
  <p><strong>张小珺：第3个问题：你曾经多次强调活下去比梦想重要，但如果未来10年技术奇点降临，你会选择all in一场颠覆现实的浪漫冒险，还是会继续做现实主义的守门人？</strong></p>
  <p><strong>朱啸虎：</strong>这也是我们为什么现在选择两个赛道的原因：一个是消费，消费就是保持现实主义的；另外，我们在AI上也在不断尝试，这就是希望能够再往前进取一点的。&nbsp;</p>
  <p>今天的选择不会all in去搏一个什么事情。&nbsp;</p>
  <p>我们作为投资人来说还是要有两条腿走路的一个想法。&nbsp;</p>
  <p><strong>张小珺：第4个问题：你对创业者常说别和巨头硬刚，但人类历史上所有浪漫的革命都始于逆势而为，你内心是否偷偷期待有人打破这条铁律？</strong></p>
  <p><strong>朱啸虎：</strong>DeepSeek确实是一个异军突起的。&nbsp;</p>
  <p><strong>在这么多大巨头、这么大投入情况下，它以“小米加步枪”一下子迅猛“杀”出来</strong>——这个真的是让人看到创业和投资的魅力！&nbsp;</p>
  <p><strong>张小珺：第5个问题：如果让你用一场爱情比喻投资，你认为自己是精打细算的婚姻规划师，还是偶尔仍会为一眼心动买单的浪漫主义者？</strong></p>
  <p><strong>朱啸虎：</strong>那风险投资肯定都是精打细算的啊。&nbsp;</p>
  <p>我们虽然做风险投资，我们一直在说，我们要知道自己冒着什么风险？——到底是冒着技术风险、是市场风险、还是团队风险？肯定都是要权衡到底多少风险，然后写多少支票的。&nbsp;</p>
  <p>作为机构风险投资人，肯定和个人投资或者其他都不一样，肯定是要做精打细算，要做好整个盘子的规划——整个基金到底投多少在高风险项目上，多少在低风险项目上，对吧？——这是要规划好的。&nbsp;</p>
  <p><strong>张小珺：如果你有机会投DeepSeek，这是一个高风险项目还是低风险项目？</strong></p>
  <p><strong>朱啸虎：</strong>同样的，和估值也是相关的。&nbsp;</p>
  <p>但今天确实风险降低了很多很多，因为它势头这么猛，建立开源生态的趋势相对比较明显了，风险相对来说降低了很多。&nbsp;</p>
  <p><strong>张小珺：他们最近也推出了多模态大模型，你对这个关注没有？</strong></p>
  <p><strong>朱啸虎：</strong>多模态门槛没那么高。多模态实际上不需要很多卡，而且中国数据远远超过美国。文字理解才是这波AI最核心的地方。&nbsp;</p>
  <p><strong>张小珺：你最近去新加坡，有什么新的观察没有？</strong></p>
  <p><strong>朱啸虎：</strong>我就很惊讶发现，泡泡玛特在新加坡居然是要配货的！！！这是让我大开眼界！！！&nbsp;</p>
  <p>我觉得大家真的可以欣赏欣赏DeepSeek的文字，它的文字真的很优美。你和它深度对话，问些比较深刻的问题，它会回复给你同样有深度的内容。&nbsp;</p>
  <p>这是特别不容易的，这是特别不容易的。&nbsp;</p>
  <p>所以大家都去体验体验，比看任何新闻报道都要更有意义。&nbsp;</p>
  <p><strong>张小珺：在你与他的交流中，他让你感到最兴奋的一个答案是什么？</strong></p>
  <p><strong>朱啸虎：</strong>存在、意识，甚至量子力学，回复都很有意思。&nbsp;</p>
  <p><strong>张小珺：能不能构想一下10年后、20年后的世界？</strong></p>
  <p><strong>朱啸虎：</strong>这一波AI影响力真的会非常大，以后人类社会组织形态包括工作形态，都会有很大一个变化。这确实今天还很难看得很透彻——但我觉得，3天工作制，可能真的会很快实现。&nbsp;</p>
  <p>确实变化太快了。只能走一步再看一步。&nbsp;</p>
  <p><strong>张小珺：但如果真的全部开源，并且有一天实现了AGI，当人手有一个AGI的时候，对人类的安全会造成威胁吗？</strong></p>
  <p><strong>朱啸虎：</strong>安全倒是其次。核心还是以后人到底干什么事情？现在真的看不清楚。&nbsp;</p>
  <p>以后绝大多数工作可能都是AI完成了——今天即使打数据标签，都需要博士级别的人——那真的，绝大多数人以后做什么事情？确实是一个需要持续观察的事情。&nbsp;</p>
  <p>不过，人类可以真的获得极大的解放，这是目前已经能够看得到的。&nbsp;</p>
  <p><strong>张小珺：这样的话，AI为什么还要服务人类呢？</strong></p>
  <p><strong>朱啸虎：</strong>它毕竟还是硅基的，毕竟是没有物理实体的。&nbsp;</p>
  <p>就像它回复一样，<strong>它还是需要“借助人类去体验这个世界”。</strong></p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/VCHnYxvG9S13xmmIRe1Knw" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：张小珺，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3157157338340103</id>
            <title>我在硅谷看AI：Deepseek狂飙背后，2025年15条AI关键投资启示</title>
            <link>https://www.36kr.com/p/3157157338340103</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157157338340103</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 00:58:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <生成式AI, AI Agent, 投资趋势, 商业模式>
<br>
<br>
总结: 生成式AI作为颠覆性技术，正在推动各行业的发展，尤其在2025年将迎来AI Agent的商业化元年。随着大量资金涌入AI领域，生成式AI公司如OpenAI等迅速崛起，形成了新的“造富神话”。企业在AI应用上逐渐转向按工作成果收费的商业模式，取代传统的按席位收费方式。未来，专有模型和动态自适应界面将推动AI的广泛应用，满足多样化需求。2025年，消费级AI应用有望成为新的增长点，行业将迎来更多创新和变革。 </div>
                        <hr>
                    
                    <section style="margin-left: 8px; margin-right: 8px;">
   <span style="text-align: center;"></span>
  </section>
  <section style="letter-spacing: 0.578px; margin: 0px 8px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#01</strong></span>
  </section>
  <section style="text-align: justify; margin: 0px 8px; text-indent: 0em; line-height: 1.75em;">
   <span><strong style="color: rgb(0, 0, 0); font-size: 20px; letter-spacing: 1px; text-indent: 0em;">开篇</strong></span>
  </section>
  <section>
   <span>生成式AI，作为当今最具颠覆性的技术之一，正在引领各行业进入全新的发展阶段。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>2025年伊始，围绕生成式人工智能的竞赛愈发激烈。美国总统特朗普上任第二天，白宫宣布启动名为“星际之门”（Stargate）的人工智能项目，由美国甲骨文公司、OpenAI与日本软银集团联合出资打造。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>1月14日，OpenAI推出了名为Tasks的测试版功能，标志着ChatGPT正式迈入AI智能体（AI Agent）阶段。春节期间，中国大模型DeepSeek凭借其推理模型DeepSeek-R1引起了广泛关注，该模型以OpenAI十分之一的成本达到了GPT-o1的同级别表现。同时，DeepSeek在1月26日登顶苹果App Store和谷歌Play Store全球下载榜首，上线18天内下载量突破1600万。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>紧接着，OpenAI继续推动创新，发布动作不断：1月24日发布了一款代号为“Operator”的全新AI Agent产品；随后2月1日推出o3-mini，专注于STEM领域，支持函数调用、流式传输、结构化输出和搜索结合等功能；2月3日又推出面向深度研究领域的智能体产品，进一步拓展了其在专业领域的应用。谷歌也不甘示弱，在2月6日凌晨发布了性能更强的Gemini 2.0系列模型，包括Pro、Flash和Flash-Lite三个版本。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>如今，生成式AI正迎来类似的历史时刻，这不仅是科技革命，更是商业重塑的契机，我们正站在这一变革的起点。每一次平台级机会的背后，都会催生出一批市值百亿、千亿美金的公司。从互联网到移动互联网，再到云计算和区块链，每一次基础设施的创新都激发了无数新的应用场景，推动科技巨头的崛起。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>回顾这些历史周期，我们发现，基础设施的完善往往会催生应用公司的黄金发展期。生成式AI作为新型基础设施，正处于这一发展轨道的起点。未来，这些公司将通过创新的商业模式和智能化产品，重新定义我们的工作和生活方式，迎来属于自己的千亿市值时代。展望2025年，大语言模型将会走向何方？在这份报告中，我们将从行业变化、技术进展和应用趋势三方面，对大模型的未来发展进行深入前瞻。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   
  </section>
  <section style="letter-spacing: 0.578px; margin: 0px 8px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#02</strong></span>
  </section>
  <h2 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span><strong>AI疯狂吸金，千亿独角兽冉冉升起</strong></span>
   </h2>
  <section>
   <span>2024年，最为人们印象深刻的，便是生成式AI公司——OpenAI高达65亿美元的融资。这笔融资让这位生成式AI的弄潮儿估值达到约1500亿美元——一只大型千亿独角兽正在硅谷茁壮成长，而这只是2024年中最具代表性的一个。生成式AI所创造出的“造富神话”，多次让人们情绪高涨，AI就像一个庞大的“吸金兽”，以飓风般的速度吸走了大部分的风投资金。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>涌入AI赛道的大量资金和顶尖创业者，正在催生出了一批新晋独角兽公司。</span><span>根据硅兔君复盘，在过去18个月新增的73家独角兽中，有28家是AI公司，占到了新增独角兽的大约三分之一。</span><span>例如特斯拉创始人埃隆·马斯克在2023年7月创立的xAI，2024年3月发布了首款AI聊天机器人Grok-1，随后发布了Grok-1.5V大模型，其在最新一轮融资中，估值达到240亿美元；Xaira Therapeutics，作为AI+生物技术领域的公司，其联合创始人David Baker在“AI+蛋白质”领域颇有造诣，其团队研发出AI大模型RFdiffusion，用扩散模型构建的创新型生成式AI系统，并且可以按需构建AI分子，估值为27亿美元；Cognition AI是一家由三位华人创业者创立的公司，2024年3月，其推出了世界上第一位完全自主的AI软件工程师，在最新一轮融资后估值达到20亿美元。</span></span>
   
  </section>
  <section>
   
  </section>
  <p style="text-align: center; margin-left: 8px; margin-right: 8px; margin-bottom: 0px;"><img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_bd8770684c514a719af45e439b8628c0@000000_oswg206354oswg768oswg396_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p style="text-align: center; margin-left: 8px; margin-right: 8px; margin-bottom: 0px;"><span>制图：硅兔赛跑，数据来源pitchbook</span></p>
  <section>
   
  </section>
  <section>
   
  </section>
  <p style="text-align: center; margin-left: 8px; margin-right: 8px; margin-bottom: 0px;"><img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_5f2bd6ad36ae499d847a767714f11a19@000000_oswg146314oswg524oswg412_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <section>
   <span>制图：硅兔赛跑，数据来源pitchbook</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>这些AI独角兽的成长速度远快于非AI独角兽，前25%的AI公司在不到2.5年内就已经达到独角兽估值。同时，最大规模的交易也流向了AI的初创企业。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>另一个趋势是——</span><span>融资额正在变大，头部效应更加明显</span><span><span>。根据第三方数据分析机构Pitchbook的数据，2024年，光是北美的风险投资总金额达到了2164亿美金，较2023年增长了28%。</span><span>其中2024年四季度，北美地区的融资额达到了771亿美金，创下了2年以来的新高，光是人工智能相关项目的投融资额达到了991亿美金，占到了总额的45.8%，达到了历史最高水平。</span><span>过去美国最大的10笔风险投资交易每年通常占总融资额的9%左右，而自2023年以来，这一比例升至20%。</span></span></span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>过去一年，我们在硅谷，这个北美将近50%投融资发生的地区以及最能够代表北美创投发展的地方，捕捉到最新的一些变化并试图梳理出最前沿的趋势：</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>首先，针对人工智能创投领域，有四大行业趋势值得关注：</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>1、如果说2023年的AI Agent，只是停留在诸如斯坦福小镇这样的虚拟世界；2024年，AI Agent的商业化条件逐渐成熟；2025年则是Agent AI商业化的元年，资本的关注和注入加速，会加剧各大科技公司和初创企业在Agent AI 领域的竞争，推动技术创新和产业应用的落地。</span>
   
  </section>
  <section>
   <span>2、一方面围绕生成式AI基础设施的投资规模空前，带动了一系列产业链公司；另一方面，业界正在尝试一些低成本、性价比高的做法，减少训练的投入却能达到与GPT-4/4o等同的效果；</span>
   
  </section>
  <section>
   <span>3、专有AI模型正在释放AI潜力，他们正在解决通用大模型不能解决的问题，逐步具备较高的商业化潜力。</span>
   
  </section>
  <section>
   <span>4、生成式界面将迎重大发展，用户能够有更好的互动体验，将带来新的商业模式和市场机会。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>其次，在人工智能的技术方面，我们总结了八大趋势：</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>1、2025年，大模型将更加关注多模态的融合与交互，其训练方法正在不断优化；</span>
   
  </section>
  <section>
   <span>2、一直以来，尽管大模型能力在不断增强，但仍无法解决人工智能的“黑箱”问题。2024年，许多公司陆续推出了更透明的模型架构和解释工具以缓解“黑箱”带来的麻烦。2025年，可解释性工具将进一步普及；</span>
   
  </section>
  <section>
   <span>3、2024年，大模型的长期记忆能力迎来了一系列技术突破。2025年，随着多模态技术的进步，跨模态记忆融合将在视频、文本、触觉和嗅觉数据的编码上取得突破，进一步提升模型的记忆能力。</span>
   
  </section>
  <section>
   <span>4、合成数据作为加速大模型训练的方法，将在2025年进一步发挥潜能。</span>
   
  </section>
  <section>
   <span>5、2025年，随着更强大的计算资源的普及和优化，规模定律将继续提升，这使得更多的中小型企业可以进入AI领域，加速了大模型的普及，效率跃迁曲线下，大模型的成本更低了。</span>
   
  </section>
  <section>
   <span>6、2025年，强化学习（RL）与大语言模型的结合有望进一步提升模型的泛化能力，并使得从预训练到后训练和推理迁移的转变成为可能。</span>
   
  </section>
  <section>
   <span>7、随着AI应用场景的多样化，简化算法架构将成为AI发展的重要方向。2025年，更多优化算法将被用于强化学习等领域，以减少计算资源的消耗。</span>
   
  </section>
  <section>
   <span>8、随着AI蒸馏技术的普及，相关的法律和监管框架也需要不断加强，以确保在模型开发和应用过程中不会侵犯知识产权或数据隐私。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>另外，在人工智能的应用方面，2025年也有了一些新的变化：</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>1、2025年，企业级AI应用迎来深入发展，越来越多企业将从人工智能中获利。AI Agent成为行业颠覆性力量，生成式AI推动传统行业进入智能化时代。随着企业在生成式AI上盈利，商业模式转变为按工作成果收费，取代传统的SaaS席位收费。</span>
   
  </section>
  <section>
   <span>2、2025年对于AI应用来说，下一个重大事件将属于消费。我们期待一个“杀手级”AI消费应用的诞生。</span>
   
  </section>
  <section>
   <span>3、在AI应用端，企业不再依赖单一模型，而是会根据不同的应用需求和场景，将不同模型模块进行组合，定制出符合自己业务需求的模型。</span>
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势一 ：2025年，AI Agent元年拉开序幕</span>
   </h3>
  <section>
   
  </section>
  <section>
   <span><span>人工智能未来学家雷·库兹韦尔 (Ray Kurzweil)表示，2025年，我们将开始看到从聊天机器人和图像生成器向“代理”系统的转变，这些系统可以自主完成任务，而不仅仅是回答问题</span><span>。人工智能系统正在从单一的交互模式，走向专门且相互关联的代理。</span></span>
   
  </section>
  <section>
   <span>AI Agent，也称为人工智能代理，通常是指能够感知环境、进行自主理解、决策和执行动作的智能体。根据咨询公司来觅PEVC的统计，自2024年以来，全球AI Agent赛道的融资金额已突破665亿元人民币。从整体来看，这些资金主要流向了在技术与市场潜力方面处于领先地位的头部企业。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>科技巨头纷纷布局AI Agent，以抢占未来智能交互的制高点。2024年，OpenAI凭借其强大的技术实力和广泛的市场应用，官宣65亿美元新融资，成为万亿独角兽，也成为全球AI Agent领域的主要资金流之一。埃隆·马斯克创立的xAI，希望将AI Agent与人类深度整合，创建全球首个AI Agent与人类共存的社交平台，xAI在2024年12月完成60亿美元融资，估值达到了近500亿美元。</span><span>谷歌也全力推广商用AI Agent，发布了全球为数不多的商用AI Agent市场，为企业提供一站式开发、部署和应用生态。微软在2024年11月的Ignite大会上宣布已建立全球规模最大的企业级AI Agent生态系统，企业用户可通过Azure AI目录访问超过1800个AI模型。此外，</span><span>微软的Copilot Studio平台已支持用户创建自主Agent，并正式进入预览阶段。</span><span>苹果也在开发者大会上展示了其最新的AI成果Apple Intelligence。</span></span>
  </section>
  <section>
   <span>2025年，OpenAI推出的智能体功能（AI Agent）以及一系列基于生成式AI的智能系统，它们开始具备真正的自主学习和推理能力，从单一任务的执行者，转变为能够进行多任务处理、复杂决策和交互的智能体——1月24日，OpenAI发布了一款代号为“Operator”的全新AI Agent产品，与其他各家Agent相比，它会通过自有的CUA（电脑控制Agent）系统进行复杂的思维链反思和步骤规划，这可以大大提高其完成任务的精度和复杂性。Operator的创新之处在于其成功实现了从认知到执行的完整闭环。这一能力的拓展不仅是技术上的突破，更是AI技术迈向更高层次发展的关键一步。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>AI Agent不再是单一的辅助工具，而是可以独立进行深度学习、理解和推理的智能系统，赋能企业和个人高效完成复杂任务，推动生产力的大幅提升。</span><span>2025年，AI智能体的全面普及将不仅改变技术产业的格局，还将在各个领域深刻影响人类的生活方式，从而使这一年成为AI Agent真正崭露头角的元年。</span></span>
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势二：基础设施军备竞赛：投资空前，低成本做法渐成趋势</span></h3>
  <section>
   <span>一年多以前，基础大模型制造商OpenAI，在芯片制造商英伟达生产的25000个最新进GPU集群上训练了GPT-4。随后，马斯克表示他在一个数据中心有100000个GPU，并计划购买200000个。</span>
   
  </section>
  <section>
   <span>头部公司通过大规模资金投入，抢占人工智能基础设施的制高点，而以英伟达为代表的硬件厂商也在以前所未有的速度上不断突破技术极限。例如，英伟达的顶级芯片性能相当于300部高端iPhone的处理能力。</span>
   
  </section>
  <section>
   <span>在这场基础设施竞争中，埃隆·马斯克的X平台部分业务——xAI的“Colossus”训练集群，成为世界上最强大的人工智能训练集群之一。这个集群仅用122天便建成，预算高达30亿至40亿美元，成为人工智能基础设施建设的里程碑。目前，xAI计划将集群容量翻倍，进一步增强处理能力。Meta也在大规模投资硬件，近期公布了其24000个GPU数据中心规模集群的两个版本，旨在支持其下一代人工智能模型。</span>
   
  </section>
  <section>
   <span>虽然目前GPU集群比传统数据中心小，但对人工智能计算不断增长的需求将需要大规模的基础设施扩展。包括Meta、亚马逊、Alphabet和微软在内的主要科技公司正在推动对人工智能基础设施的空前投资。超大规模数据中心运营商预计2024年资本支出（CapEx）将超过 2000 亿美元，到2025年这一数字预计将接近2500亿美元。尽管并非所有支出都直接与人工智能相关，但很大一部分都分配给了人工智能，并且这个份额在不断增加。微软和OpenAI已讨论推出一个专门用于人工智能工作负载的5千兆瓦数据中心，可能耗资超过1000亿美元，甚至可以买得下一艘最新型核动力航空母舰。</span>
   
  </section>
  <section>
   <span>在这场人工智能基础建设中受益的，是这个产业链中的组成部分。</span>
   
  </section>
  <section>
   <span><span>第一类就是数据中心的托管服务提供商</span><span>——也就是向大公司提供数据中心租赁容量的公司，他们是数据中心市场的重要组成部分。这批数据中心的托管服务提供商如今也在拓展其以人工智能为重点的基础设施服务。例如，超大规模托管领域的领导者 Equinix 已获得近 150 亿美元的资金用于在美国建设人工智能数据中心，主要为客户提供基础设施，以训练和部署大规模私有人工智能模型，这些客户往往是科技行业以外的财富 500 强公司。</span></span>
   
  </section>
  <section>
   <span><span>另一类受益者则是人工智能数据中心建设中的辅助产品</span><span>，例如低功耗CPU、内存、存储系统、网络组件以及冷却和电源管理设备。冷却产品供应商 Vertiv在2024年7月至9月的三个月内实现了19%的同比收入增长，并提高了未来12个月的业绩指引。</span></span>
   
  </section>
  <section>
   <span><span>第三类则是围绕数据中心能源生产、热管理和电源管理解决方案的公司。</span><span>Alphabet董事长在2023年2月表示，与LLM互动可能比标准关键字搜索的花费高出10倍。另外，根据谷歌研究员Urs Hölzle的文章提及，标准Google搜索使用的电力为0.3Wh，这意味着每次LLM互动的耗电量约为3Wh。这个数字与SemiAnalysis在2023年初对ChatGPT运营成本的评估一致，该评估估计ChatGPT每次请求耗电量为2.9Wh，如果每天响应1.95亿个请求，估计平均每天耗电量为564MWh。</span></span>
   
  </section>
  <section>
   <span>《纽约客》报道称，ChatGPT每天用电量相当于1.7万个美国家庭的用电量。如果基于当前模型和技术，让每个标准Google搜索都变成 LLM 交互，对 Google总用电量的潜在影响巨大。第三方分析机构SemiAnalysis估计，带有大模型交互功能的谷歌搜索单次请求的用电量达到将近9Wh，谷歌每天搜索大约需要90亿次，则需要81000MWh。</span>
   
  </section>
  <section>
   <span>这一趋势促使人们对位于数据中心设施附近的核能和能源生产等技术以及热管理和电源管理解决方案进行投资。</span>
   
  </section>
  <section>
   <span>不过，如今科学家和业界正在寻找更聪明并且资源密集度更低的方法来解决训练人工智能模型所需要的算力和能源问题。例如通过蒸馏技术，这项技术的践行者——DeepSeek，这家国产大模型也给美国硅谷提供了更多低成本的训练参考。DeepSeek大模型性能在多个方面比肩OpenAI，其中DeepSeek V3，整个训练过程仅用了约2000张二流芯片进行训练，官方称成本仅占用约550万美元，而Meta的模型则使用了16000个性能最强的一流芯片。并且，DeepSeek-R1通过重新设计训练流程、以“少量SFT数据+多轮强化学习”的办法，在提高了模型准确性的同时，也显著降低内存占用和计算开销，每百万输出tokens16元，大约是OpenAI o1运行成本的三十分之一。</span>
   
  </section>
  <section>
   <span>在这样的竞争压力下，0penAI推出了其成本更低的o3-mini，比o1-mini便宜63%，比完整的o1模型便宜93%，每百万tokens的进出费用分别为1.10美元/4.40美元(享有50%的缓存折扣)。谷歌发布的Gemini 2.0 Flash-Lite是Gemini 2.0系列的新变体，每百万tokens0.3美元，是谷歌目前最便宜的模型。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>可以窥见，在AI产业的竞争中，降低训练成本、提高计算效率和优化模型性能已成为企业的主要竞争策略。尤其是训练流程的优化，成为了公司在大模型市场中占据竞争优势的关键能力之一。</span><span>2025年，低成本做法也将成为行业的主流趋势。</span></span>
   
  </section>
  <section>
   <span>此外，一些大公司也在开发专用人工智能芯片，例如谷歌、苹果、微软和OpenAI，这些专业芯片可以比英伟达这样通用处理器运行更高效；或是采用一些方法提高芯片的使用效率，例如用多种模型，每种模型针对不同问题，以此来缩短芯片的处理时间等。AI推理芯片制造商Groq2024年估值达到28亿美元，在Blackrock领投的新一轮中融资6.4亿美元，其专为AI推理任务设计的芯片“语言计算单元”（LPU, language processing unit）能以现有解决方案1/10的价格、10倍的速度运行与ChatGPT、GPT-4o相似的模型。目前，在Groq开发的、对标英伟达CUDA的软件开发平台GroqCloud平台上，约有40万开发者。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势三：专有模型有望释放AI的应用潜力</span>
   </h3>
  <section>
   <span>大模型就像个通才，然而，在一些专业领域，大模型往往缺乏针对性和操作性。为了突破这一瓶颈，越来越多的公司开始专注于开发专有模型，通过在特定领域数据上微调模型，实现更高效的工作流程自动化，提供更具操作性和任务导向的工具。这一趋势正在逐步升温，并在多个行业展现出巨大的应用潜力。以下为一些具体的案例：</span>
   
  </section>
  <section>
   <span><span>金融服务领域，提升决策效率与洞察力：</span><span>摩根大通和彭博社等机构正在利用其庞大的内部数据集开发大语言模型，以提升运营效率和决策能力。这些模型能够提供独特的市场洞察、风险分析和报告生成。例如，彭博社于2023年开发了BloombergGPT，专注于金融领域的数据分析和预测，通过微调金融数据，能够更高效地处理复杂的金融任务，如市场趋势分析和投资策略制定。</span></span>
   
  </section>
  <section>
   <span><span>网络安全领域，精准检测与应对威胁：</span><span>美国网络安全解决方案提供商Palo Alto Networks正在训练自有的大语言模型，这些模型能够帮助安全专家更好地检测和应对网络威胁。该公司在2024财年四季度披露了超过2亿美元的AI相关经常性收入，同比增幅近四倍。AI大模型通过模拟复杂攻击场景，帮助安全团队快速发现系统漏洞并提供修复建议，显著提升了网络安全的实时预警和用户行为分析能力。</span></span>
   
  </section>
  <section>
   <span><span>国防领域，用于军事与情报分析：</span><span>美国数据分析和软件公司Palantir近期获得了一系列合同，用于支持AI的服务，包括加速部署适用于国防和军事领域的AI模型。这些模型能够提升情报分析、目标识别和决策支持能力。例如，AI训练平台可以创建逼真的战斗场景，帮助士兵在安全环境下进行战术训练。此外，AI技术在军事领域的应用还包括无人化作战系统和沉浸式训练模拟。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span><span>生命科学领域：2024年，科研人员使用AI的比例快速增加，AI对科学研究方法和流程的变革效应也开始显现。</span><span>比如，AlphaFold 3.0在2024年发布，不仅提高了蛋白质结构预测的准确率，还扩展到了DNA和RNA等生物分子的研究，这项技术帮助科学家快速预测药物分子与目标蛋白质的结合情况，大大提高了药物研发的效率。</span></span><span>2025年，多模态大模型将进一步融入科学研究，赋能多维数据的复杂结构挖掘，辅助科研问题的综合理解与全局分析，为生物医学、气象、材料发现、生命模拟、能源等基础与应用科学的研究开辟新方向。</span></span>
   
  </section>
  <section>
   <span>除了上述领域，专有模型还在其他行业展现出广泛的应用前景。例如，Two Sigma在量化投资中使用AI Agent进行选股策略，通过分析财务数据和宏观经济指标，识别潜在的投资机会。Shopify Sidekick则利用LLama 2生成产品描述、回应客户查询和创建营销内容，帮助小企业主提升运营效率。</span>
   
  </section>
  <section>
   <span>专有模型通过在特定领域的数据上进行微调，能够提供更具针对性和操作性的解决方案。这种趋势不仅提升了各行业的自动化水平，还为企业带来了显著的运营效率提升和成本降低。随着AI技术的不断发展，未来专有模型将在更多领域得到广泛应用，成为推动行业创新的重要力量。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势四：推动动态自适应界面，实现高度个性化的交互体验</span>
   </h3>
  <section>
   <span>生成式界面（Generative Interface）是指利用生成式模型，如生成对抗网络（GANs）或变分自编码器（VAEs），自动创建用户界面元素或交互流程。这种界面不是通过传统设计方法人工制作，而是通过机器学习算法根据输入的数据、需求或上下文生成。</span>
   
  </section>
  <section>
   <span><span>在2024年，</span><span>生成式用户界面（Generative UI）在动态和自适应界面、AI与算法融合、个性化体验等方面取得了显著进展</span><span>。大规模生成式预训练模型（如GPT系列、DALL·E等）已被广泛应用于自动化界面设计。开发者借助这些模型，可以快速生成和调整界面元素，如按钮、布局、色彩搭配等，甚至可以根据用户反馈实时调整界面的外观和功能。</span></span>
   
  </section>
  <section>
   <span>此外，生成式界面逐步在增强现实（AR）和虚拟现实（VR）环境中得到应用，尤其是在需要复杂交互的沉浸式体验中，AI帮助生成自适应、动态变化的虚拟界面。例如，英伟达在2024年SIGGRAPH大会上展示了利用实时生成式AI创建沉浸式沙漠世界的研究成果。此外，英伟达还通过Holoscan技术赋能手术机器人，加速AI技术在医疗实践中的应用。这些应用展示了生成式AI在动态生成虚拟界面方面的潜力，尤其是在需要高度沉浸感的场景中。</span>
   
  </section>
  <section>
   <span>可以说，随着用户需求变得更加多样化和复杂，传统的固定界面无法满足个性化的交互需求。动态自适应界面能够根据用户的行为、偏好和环境变化实时调整显示内容和功能，提供更加定制化的体验。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span><span>展望2025年，生成式界面将迎来重大发展，成为推动用户体验变革的关键力量</span><span>。越来越多的应用将采用基于用户交互和逻辑工作流程自适应的动态用户界面。生成式UI将使应用能够自动生成表单、仪表板或可视化等界面元素，这些元素将根据用户的具体需求和操作量身定制。例如，Web开发平台Vercel和Bolt.new等公司正在开发能够创建高度适应性和个性化用户体验的平台，提供实时演进的界面，以满足不断变化的需求，从而简化工作流程。</span></span>
   
  </section>
  <section style="letter-spacing: 0.578px; margin: 0px 8px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#03</strong></span>
  </section>
  <h2 style="text-align: justify; text-indent: 0em; margin: 0px 8px; line-height: 1.75em;"><span><strong>八大技术趋势，推动AI泛化能力</strong></span></h2>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势一：多模态能力的增强和集成</span>
   </h3>
  <section>
   
  </section>
  <section>
   <span>2024年，多模态AI取得了显著进展。OpenAI、Google DeepMind等机构推出了更强大的多模态模型，如视频生成模型Sora的诞生、OpenAI多模态AI大模型GPT-4o的到来、CLIP模型通过跨模态表示实现图文搜索，用户可以通过输入文本搜索相关图像或视频。此外，文本到图像生成（如DALL·E、Stable Diffusion）和视频生成模型也取得了显著进展，进一步拓展了AI的交互体验。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>大模型逐步增加了能够处理图像、音频或视频等多种输入形式。这些模型不仅提升了AI对复杂信息的处理能力，还拓展了其应用领域。在谷歌云发布的《2025年AI商业趋势》报告中，多模态AI被放在首位。</span><span>谷歌云预测，2025年将成为企业采用AI技术的关键一年，这一趋势主要由多模态学习及其实现的情境感知所驱动的，并预计2025年全球多模态AI市场规模将达到24亿美元。</span></span>
   
  </section>
  <section>
   <span>2025年，大模型将更加关注多模态融合与交互。AI不仅能够生成文本，还能理解图像、视频中的上下文，甚至在多模态环境中进行决策。比如，结合视觉与语音的能力，模型能够更好地理解复杂的场景，并做出合适的反应。</span>
   
  </section>
  <section>
   <span>此外，多模态模型的训练方法也在不断优化，例如采用分阶段训练策略，先固定大语言模型的权重参数，对图像编码器和桥接组件进行初步训练，再进行整体训练，从而提升模型性能。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势二：大模型的可解释性表现更强</span></h3>
  <section>
   <span>可解释人工智能 (xAI) 是人工智能领域的一个新兴领域，致力于使人工智能系统对人类更加透明、可解释和可理解。xAI的兴起源于人们对人工智能决策过程透明度和问责制的需求日益增长，尤其是随着人工智能系统变得越来越复杂并部署在金融、法律或医疗保健等高风险领域。例如，考虑医院用于筛查患者X光片的肿瘤检测 CNN（卷积神经网络） 模型的情况。但是，当技术人员或患者不知道其工作原理时，他们如何能相信其结果？这正是我们需要方法来了解影响任何深度学习模型决策的因素的原因。</span>
   
  </section>
  <section>
   <span>另外，AI的安全性问题是一个不可忽视的关键挑战。尤其是大模型在做出决策时的“思考过程”对于用户和开发者来说变得不透明，就像一个“黑箱”，其决策过程难以解释和追踪。若这些模型未经过严格的审查和验证，它们可能会做出无法被察觉的有害决策，甚至加剧社会偏见和不公。因此，加强对大模型的监控、审查和可解释性要求是提升AI系统安全性的重要一步。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>2024年，大模型的可解释性取得了重要进展。OpenAI、Google DeepMind等机构推出了更透明的模型架构和解释工具，如GPT-4的可解释性增强版本和Gemini的跨模态解释功能。LIME、SHAP等后验解释方法被广泛应用于医疗、金融等领域，帮助用户理解模型决策依据。同时，自监督学习和符号AI的结合提升了模型的内在可解释性，减少了“黑箱”问题。行业也开始重视可解释性的标准化，例如欧盟《人工智能法案》要求高风险AI系统提供清晰的决策解释。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>2025年，可解释性工具将进一步普及，将模型将内置更强大的解释能力，实时生成决策依据，并支持多模态数据的跨模态解释，</span><span><span>帮助用户理解复杂AI模型的决策过程。通过一些自主进化模式或可解释性工具，将模型将内置更强大的解释能力，实时生成决策依据，并支持多模态数据的跨模态解释。</span><span>可解释性与性能的平衡将得到优化，知识蒸馏和模型压缩技术将帮助简化复杂模型的同时保持高精度。行业专用可解释性工具将普及，满足医疗、金融等领域的合规需求。</span></span></span>
   
  </section>
  <section>
   <span><span>以DeepSeek为例，</span><span>通过纯算法自主进化的Zero模式与仅需数千条人工标注数据的R1模式组合</span><span>，</span><span>既保留模型自主进化能力又保障人类可解释性</span><span>————Zero模式使得模型能够自我进化和发现数据中的规律，而R1模式通过引入人工标注数据为模型提供了一个监督和解释的框架。这种结合确保了模型在保持自主学习能力的同时，也能够被人类理解和控制，从而提升了可解释性。</span></span>
   
  </section>
  <section>
   <span>此外，伦理和隐私保护将深度融入可解释性设计，确保AI系统既透明又安全，推动大模型在高风险场景中的广泛应用。以下是一些提升的方向和工具：</span>
   
  </section>
  <section>
   <span>○&nbsp;自监督学习与模型可解释性：通过自监督学习，AI系统可以在缺乏大量标注数据的情况下，通过理解数据的内在结构来进行学习，这种方法有助于提升模型的透明度，使得我们能够更好地理解其学习过程。</span>
   
  </section>
  <section>
   <span>○&nbsp;生成对抗网络（GANs）和模型蒸馏：通过生成对抗网络和蒸馏技术，开发者能够简化复杂模型，同时保持高效性和准确性，这种方法使得大规模深度学习模型更加易于解释。</span>
   
  </section>
  <section>
   <span>○&nbsp;增强推理框架和可视化工具：新一代的AI推理框架将更注重可视化，帮助用户以更直观的方式理解模型决策的依据。例如，基于图像或文本的AI系统，新的可视化工具可以清晰展示模型如何关注不同的输入特征，从而提升其可解释性。</span>
   
  </section>
  <section>
   <span>需要一提的是，未来AI的安全不光需要提升可解释性，还需要着重于法律合规性、安全审计和滥用防范等方面，推动AI技术的负责任应用。随着技术的不断发展，AI如何在不断的创新中确保安全，将成为AI领域面临的重大挑战之一。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势三：大模型长期记忆能力迎来深层次变革</span></h3>
  <section>
   <span>目前的许多大模型（如基于Transformer架构的模型）在处理长文本或复杂上下文时，常常会面临信息丢失等问题。传统模型一般有固定的“记忆窗口”，当文本或输入信息过长时，模型往往会忘记最初的信息，或者在处理过程中只关注较近的上下文。长期记忆的核心需求是让模型能跨越多个时刻、任务和场景记住信息，并能在合适的时机提取和利用这些信息。</span>
   
  </section>
  <section>
   <span><span>大模型的长期记忆能力迎来了一系列技术突破。</span><span>首先，在上下文窗口的扩展上，</span><span>比如2024年，Google Gemini 1.5 Pro突破性地实现了最高可达1000万token的处理能力。到2025年2月发布的Gemini 2.0全家桶，最强Pro版本可支持到2M上下文。</span></span>
   
  </section>
  <section>
   <span><span>其次，外部记忆系统的引入推动了大模型记忆能力的发展。</span><span>如IBM WatsonX的实时知识图谱更新功能使得在医学诊断等特定领域的记忆准确率提高了35%。持续学习机制方面，Meta的LoRA-X架构通过参数隔离技术降低了多任务干扰，OpenAI则部署了分布式记忆训练系统，使百万设备协同进化，提升了记忆系统表现。在记忆检索方面，Anthropic的ContextRouter模块和微软的MAVEx系统分别通过动态记忆权重分配和跨模态联合检索，优化了记忆检索的准确性与效率。</span></span>
   
  </section>
  <section>
   <span><span>第三，隐私与安全问题也得到了关注，</span><span>Google推出的Memory Provenance框架增强了记忆的透明度和可控性，而HuggingFace的SafeMemory工具包通过差分隐私技术将隐私泄露的风险大幅度降低。这些技术突破使大模型的长期记忆能力得到了显著提升，推动了多个领域的应用发展。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>2025年，大模型的长期记忆技术将迎来新的发展趋势。</span><span><span>如混合窗口架构或将成为上下文处理的新范式</span><span>，</span><span>能够根据任务需求动态调整局部和全局注意力的范围，大幅度提升处理效率。随着多模态技术的进步，跨模态记忆融合将在视频、文本、触觉和嗅觉数据的编码上取得突破，进一步提升模型的记忆能力。记忆权限管理和记忆遗忘机制将更加成熟，为隐私和安全提供更强保障。</span></span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>此外，随着用户对个性化和定制化的需求不断提升。</span><span>个性化记忆系统能够根据用户的特定需求、偏好和行为习惯构建专属的记忆图谱。</span><span>例如，AI助手可以记住用户的兴趣、常用的命令、偏好的回答风格等，从而提供更加精准和符合需求的回复。2025年，个性化记忆系统也将成为大模型发展的重点方向，大模型能够根据用户需求构建专属记忆图谱，提高个性化回复的准确性，并通过跨设备记忆同步实现实时更新。</span></span>
   
  </section>
  <section>
   <span>不过，尽管大模型在长期记忆方面取得显著进展，但仍面临技术挑战，包括记忆冲突解决、多来源记忆的置信度评估体系、能耗瓶颈和认知偏差防控问题。商业应用方面，医疗、教育和金融等行业将受益于大模型长期记忆能力的提升，预计能够降低误诊率、提升知识留存率并加速风控响应速度。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势四：合成数据或加速大模型训练</span>
   </h3>
  <section>
   <span style="letter-spacing: 1px;"><span>随着人工智能技术的飞速发展，数据成为推动AI进步的核心资源。</span><span>2025年，合成数据作为加速大模型训练的一种重要方法，正在成为AI发展的关键趋势。</span><span>马斯克在2025年CES（消费电子展会）的访谈中提到，随着人类累积的知识几乎被AI训练完毕，未来的AI系统将不得不依赖合成数据进行自我生成和学习。这一观点突显了合成数据在未来AI技术发展中的潜力。</span></span>
   
  </section>
  <section>
   <span>目前，多个科技巨头已经开始在AI模型训练中广泛应用合成数据。微软、Meta、OpenAI和Anthropic等公司纷纷将合成数据作为增强模型训练效率和拓宽训练数据源的有效手段。例如，2024年下半年发布的Llama 3.1、o1、DeepSeekV3和Phi-4等模型均报告了使用合成数据进行训练。根据科技市场研究机构Gartner的预测，到2024年，AI及分析项目中使用的数据中，60%以上将来自合成数据。合成数据能够帮助AI系统在真实数据难以获得或标注成本过高的情况下，生成具有代表性且符合特定任务需求的数据，大幅降低了对实际数据的依赖。</span>
   
  </section>
  <section>
   <span>然而，合成数据的使用仍然面临诸多挑战与争议。2024年7月，《Nature》期刊刊登的论文指出，LLM生成的合成数据可能会污染下一代模型的训练集，导致模型性能下降，甚至发生“崩溃”。这一风险类似于“数据中毒”问题，严重时可能让模型无法做出有效的推理和判断。英伟达也发布了其Nemotron-4 340B开源模型，声称使用了98%的合成数据，但同时也强调需要加强合成数据的质量控制，以避免潜在的负面影响。</span>
   
  </section>
  <section>
   <span>尽管面临风险，但合成数据在加速大模型训练方面的潜力仍然巨大。尤其在高性能计算和多模态数据融合等领域，合成数据可以快速扩展训练集的规模，并提供更多样化的训练情境。为了应对合成数据带来的挑战，AI研究者正在不断优化生成数据的质量和多样性，例如通过强化学习算法对合成数据进行校正，或者结合人类监督和自动化评估机制来减少“数据污染”风险。</span>
   
  </section>
  <section>
   <span>展望未来，随着技术的不断进步，合成数据有望成为AI训练中的重要组成部分。它不仅能加速模型的训练过程，还能在数据匮乏或难以获取的领域，为AI发展提供新的动力。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势五：大模型普及加速，效率跃迁曲线下成本更低了</span>
   </h3>
  <section>
   <span><span>在2025年1月，Anthropic的CEO-Dario Amodei 发表了一篇长达万字的深度分析报告。肯定了DeepSeek的技术突破：其最新模型在特定基准测试中已逼近美国顶尖水平，并尝试从三个维度将中国的AI进步纳入全球技术演进坐标系进行定位：</span><span>算力规模定律、效率跃迁曲线、范式革新动能。</span></span>
   
  </section>
  <section>
   <span>这些维度的选择反映了他对国产AI评估方面的理解：关注硬件和计算能力的提升（算力规模定律），技术的效率提升（效率跃迁曲线），以及新技术范式的创新和推动力（范式革新动能）。这种全方位的定位方式，能够精准捕捉到AI大模型在全球技术演进中的角色及潜力。具体我们解释下这三方面的重要性和趋势：</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>首先，规模定律是推动大模型发展的基础。随着硬件技术不断进步（如更强大的GPU、TPU和专用AI芯片），训练超大规模模型已变得越来越可行，同时也驱动了云计算和分布式计算的发展，进一步降低了成本。</span><span>随着更强大的计算资源的普及和优化，规模定律将继续提升，这是2025年AI大模型的关键能力趋势之一。</span></span>
   
  </section>
  <section>
   <span><span>其次，关于效率跃迁曲线，曲线偏移指的是</span><span>技术创新带来成本曲线的变化，使得原本高昂的训练成本能够通过硬件优化、模型架构改进等手段大幅降低。</span><span>这不仅能够降低AI研发的门槛，还能加速技术迭代。比如2024年，硬件创新如量子计算、专用AI加速芯片推动AI训练成本的快速降低。同时，AI框架的优化（如更高效的深度学习框架）和算法改进帮助实现了更少计算资源的更高效训练。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>在前文中我们也提到了，目前对于AI基础设施方面军备竞赛激烈，低成本做法渐成趋势，尤其是DeepSeek通过采用OpenAI等先进模型，利用蒸馏技术将其知识转移。这一过程使得DeepSeek能够在保持较高性能的同时，显著减少训练所需的计算资源和时间。通过模仿OpenAI模型的输出，“学生模型”能够快速学习复杂的模式和推理能力，加速模型的优化过程。</span><span>2025年，随着硬件和算法的进一步突破，AI开发成本将大幅下降，这也使得更多的中小型企业可以进入AI领域。</span></span>
   
  </section>
  <section>
   <span>此外，新的训练范式（如强化学习、无监督学习等）正在改变AI的学习方式。2020到2023年，AI主要依赖预训练模型，使用大量互联网文本进行训练，并通过少量额外训练进行微调。然而，到了2024年，强化学习（RL）成为新的重点，通过强化学习生成思维链，AI在数学、编程和推理等任务上的表现显著提升。初期阶段投入较少，但效果显著。</span>
   
  </section>
  <section>
   <span>强化学习和自监督学习等新兴范式逐渐在机器人、自动化和多模态学习领域得到应用，尤其提升了机器人在动态环境中的自主学习和决策能力。到2025年，这些新训练范式预计将成为AI发展的主流，尤其在复杂任务处理上（接下来趋势六我们会进一步解释）。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势六：预训练到后期训练和推理迁移转变</span></h3>
  <section>
   <span><span>2024年是AI技术飞速发展的一年，尤其是在大语言模型（LLM）和多模态技术方面取得了显著突破。这一年，</span><span>AI从单一模态向多模态融合迈进，大语言模型通过扩展上下文窗口和采用混合专家架构（MoE）等技术，显著提升了推理和生成能力。</span><span>同时，强化学习（RL）开始与大语言模型结合，为模型的泛化能力提升提供了新的方向。此外，AI在医疗、金融、自动驾驶等领域的应用不断深化，推动了行业变革。然而，随着模型规模的扩大，预训练阶段的性能提升逐渐放缓，行业开始探索后训练和推理迁移的新模式。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>2025年，AI技术将进入一个新的发展阶段，Scaling Law的扩展将成为关键趋势之一。</span><span>强化学习与大语言模型的结合（RL+LLMs）将进一步推动模型泛化能力，从预训练向后训练和推理迁移转变。</span></span>
   
  </section>
  <section>
   <span>这种模式将使AI在特定场景下的表现得到显著提升，同时降低训练成本，提高模型的适应性和灵活性。此外，AI将在更多领域实现落地应用，如智能驾驶、具身智能等，这些领域将迎来技术突破和商业化的加速，但也与此同时会带来更多的安全和风险管理挑战。因此，AI安全和治理将成为行业关注的重点。</span>
   
  </section>
  <section>
   <span><span>需要强调的是，</span><span>大规模语言模型（LLM）的预训练阶段已经接近瓶颈，主要受到数据、计算资源和模型规模增长的限制，且在通用性提升上边际效益递减。</span><span>部分研究人员和行业专家担心，对于大规模语言模型而言，传统扩展方式已接近极限。生成式AI已遇瓶颈。据外媒报道，像OpenAI这样的公司在扩大技术应用时也发现困难重重，其他前沿实验室也面临更严重的挑战。知名数据科学家Yam Peleg透露，一些实验室试图通过延长训练时间和增加数据量来提升模型表现，但结果却遭遇了“收益递减墙”，且情况比公开报道的更为严重。</span></span>
   
  </section>
  <section>
   <span>不过，尽管如此，预训练依然为模型奠定了基础，后续的优化潜力巨大。因此，在后训练阶段（如微调、强化学习、多模态对齐等）依然存在许多优化机会。通过领域特化、任务指令优化、模型压缩等技术，可以提升模型在特定任务上的表现，同时提高其在资源受限环境中的部署效率和安全性。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势七：更多优化算法将被用于强化学习等领域</span>
   </h3>
  <section>
   <span>目前，深度强化学习（DRL）的优化算法在多个行业取得了应用突破。为了解决传统强化学习在高维度问题上训练困难的问题，研究者采用了更加高效的算法，如模仿学习和分层强化学习，显著提升了模型的学习效率和训练速度。比如Google DeepMind 推出的AlphaDev系统由两个核心组成部分构成：学习算法和表示函数。学习算法是在先进的 AlphaZero 算法基础上进行扩展，结合了深度强化学习 (DRL) 和随机搜索优化算法，以执行大规模的指令搜索任务。</span>
   
  </section>
  <section>
   <span>此外，RLHF（强化学习与人类反馈结合）的应用开始更加深入和精细。AI大模型开始通过更精确的人类反馈进行训练，从而能够更好地理解复杂任务，并且在人机交互中表现出更高的自适应能力。例如，OpenAI的ChatGPT通过用户的实时反馈不断优化对话能力，以提供个性化和上下文相关的回答。由于RLHF能显著减少对大规模标注数据的依赖，更多AI系统开始通过少量高质量的人工反馈来进行高效训练，从而降低了模型开发和训练的成本。</span>
   
  </section>
  <section>
   <span><span>还有近期处于话题焦点的DeepSeek，R1模型通过强化学习（RL）和基于人类反馈的强化学习（RLHF）进行训练，并针对核心算法模块做了大量的优化处理：比如改造 Attention 模块，通过低秩压缩，让KV Cache的效率达到最优。以及</span><span>通过训练架构瘦身—例如GRPO算法通过省去传统强化学习中必须的Critic模型</span><span>（即"双引擎"设计），将复杂算法简化为可落地执行的工程方案。一般传统的强化学习模型通常采用这双引擎”设计——Actor和Critic，Actor负责执行决策，Critic评估Actor的决策效果，二者需要同时进行训练，这增加了计算量和训练复杂度。通过去除Critic模型，GRPO算法能够简化模型结构，降低计算资源的消耗。</span></span>
   
  </section>
  <section>
   <span>随着AI应用场景的多样化，简化算法架构将成为AI发展的重要方向。2025年，更多优化算法（如GRPO等）将被用于强化学习等领域，以减少计算资源的消耗，同时提高模型的执行效率和实时响应能力。</span>
   
  </section>
  <section>
   <span>随着硬件资源的不断提升和算法的进一步优化，像GRPO这样的轻量级强化学习算法将被广泛应用于边缘计算和低资源设备上。例如，智能设备、物联网设备和机器人等领域，都会受益于这种简化的算法，实现在硬件条件有限的环境中高效运行。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势八：低成本训练与AI伦理，知识产权成为核心议题</span></h3>
  <section>
   <span>春节期间，DeepSeek的DeepSeek-R1震撼了全球科技圈和资本市场，其基于知识蒸馏技术，成功将大型复杂模型的知识迁移到较小模型，实现高效部署。2月6日，斯坦福大学李飞飞团队和华盛顿大学研究人员以不到50美元云计算费用，成功蒸馏出一个名为s1的新推理模型，表现与OpenAI的o1和DeepSeek的R1相似，展示了蒸馏技术的强大潜力。基于竞争压力，2月7日，OpenAI公开了o3-mini的推理思维链，但该推理思维脸并非原始数据，OpenAI产品官Kevin Weil表示会找到平衡方式以避免被竞争对手蒸馏。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span><span>Kevin Weil的考虑出发点在于，蒸馏通常依赖于将一个较大模型的知识提取出来，并将其迁移到一个更小的模型。如果目标模型能够有效地从源模型中获取有用的知识，且没有太大的性能损失，那么理论上，</span><span>很多模型都可以通过蒸馏技术进行简化和优化。</span><span>因此，</span></span><span>随着AI蒸馏技术的普及，相关的法律和监管框架也需要不断加强，以确保在模型开发和应用过程中不会侵犯知识产权或数据隐私。</span></span>
   
  </section>
  <section>
   <span>这种低成本训练的模式也引发了业界关于AI模型知识产权和伦理问题的讨论。随着越来越多的研究依赖于现有基座模型进行微调，是否应当给予这些基座模型开发者相应的回报成为一个重要议题。同时，如何确保AI技术的公平使用和共享，也亟待业界深入探讨和解决。</span>
  </section>
  <section style="margin: 0px 8px; letter-spacing: 0.578px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#04</strong></span>
  </section>
  <h2 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span><strong>下一个杀手级应用，可能在消费领域</strong></span></h2>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势一：越来越多企业从人工智能上挣到钱</span>
   </h3>
  <section>
   
  </section>
  <section>
   <span>过去的2024年，是生成式AI的落地之年。而2025年，则是这些企业级AI应用在已有的落地场景中深入发展的一年。</span>
   
  </section>
  <section>
   <span><span>美国风险投资机构Menlo Ventures在统计了600家美国企业的IT支出（包括模型支出、训练&amp;部署支出、AI应用支出，不包括芯片、云计算等支出）情况后发现，</span><span>2024年企业的AI相关支出达到了138亿美元，相比2023年的23亿美元增长了超过6倍。</span><span>在这其中，应用支出的增速最快，6亿美元增长到了2024年的46亿美元。</span></span>
   
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_d496c09bf3714d21b76fc03635154e60@000000_oswg68381oswg830oswg408_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   <span>数据来源：Menlo Ventures</span>
  </section>
  <section>
   <span><span>企业AI相关支出的提高，让不同的行业间接获益。</span><span>第一个受益的是咨询公司</span><span>。2024年，埃森哲和IBM等咨询公司正在实现大幅的收入增长，其中，与人工智能相关的服务对其营收增长贡献显著，客户希望通过咨询，了解实施人工智能能够获得的竞争优势。根据埃森哲披露，截至 2024 年 9 月，其生成式人工智能咨询预订额近 30 亿美元。</span></span>
   
  </section>
  <section>
   <span><span>第二个从人工智能中获益的行业是云计算和软件公司</span><span>。软件公司ServiceNow自推出 “Now Assist” 以来，报告了强劲的生成式人工智能预订量，其首席财务官表示，在新产品系列中，最大新增年度合同价值贡献，来自于人工智能的采用。另外，软件巨头甲骨文的基础设施即服务（IaaS）部门实现了强劲增长，这在很大程度上归因于人工智能工作负载的增加。数据中心的领导者Equinix也因为人工智能基础设施需求获得了大量新合同。</span></span>
   
  </section>
  <section>
   <span><span>另外，广告行业也从人工智能使用中获益。</span><span>根据Meta Platforms最近报告，在人工智能的加持下，其广告展示量增长了7% ，每广告的平均价格增长了 11%，季度收入同比增张了19%。</span></span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>亚马逊集成了基于生成式人工智能的产品图像生成工具，导致某些广告活动的广告展示量显著增加。我们预计，随着人工智能服务需求的扩大，具有独特市场定位、强大分销渠道和特权数据访问权限的云计算、软件应用和基础设施公司将成为主要受益者。随着人工智能市场的成熟，这些科技巨头可能在 2025 年实现加速增长。</span>
   
  </section>
  <section>
   <span>我们尝试总结了生成式AI渗透率最高的几个应用场景：AI代码、AI客服支持和企业级搜索。</span>
   
  </section>
  <section>
   <span><span>●&nbsp;</span><span>最高的是AI代码应用，企业对AI代码应用的采用率达到了51%</span><span>，比如，头部产品 Github Copilot 的ARR（年度经常性收入，是指企业每年从客户那里获得的或期望从客户那里获得的服务或产品回报的收入计算）达到了3亿美金也真实的反应了用户的需求。Cursor、Cognition 等新兴工具在迎来用户快速增长的同时，也获得了资本市场的火热追捧。</span></span>
   
  </section>
  <section>
   <span><span>●&nbsp;</span><span>其次是AI客户支持，其采用率达到了31%，</span><span>产品为内部员工或外部用户提供基于产品知识的客户支持。Sierra、Decagon 等初创借力生成式AI的智能，为用户提供符合品牌调性和消费者画像的定制化客服体验，挑战低效、无趣的传统客服。</span></span>
   
  </section>
  <section>
   <span><span>●&nbsp;</span><span>第三是AI数据检索，其采用率达到了28%</span><span>，这类应用帮助企业解锁和利用分散在各组织中的数据，将数据孤岛中的宝贵知识管理利用。例如一家初创企业Glean，其业务是企业级搜索，旨在为企业打造内部的Google，核心产品 Glean Assistant 的用户每天平均查询 14 次，远超Google的日均查询次数。在过去一年ARR（年经常性收入，Annual Recurring Revenue）达到了5500万美金。</span></span>
   
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_c66544a93531470db40864241d2988e8@000000_oswg68657oswg830oswg408_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   
  </section>
  <section>
   <span>数据来源：Menlo Ventures</span>
   
  </section>
  <section>
   <span>2024年，企业60%的AI应用支出来自企业创新业务的预算，说明企业使用这些应用的态度以尝试和探索为主，生成式AI在企业应用场景中的落地尚处于早期阶段。接下来，随着企业未来各个部门对于生成式AI应用的预算持续增长，哪些生成式AI应用能为企业带来实实在在的回报率，哪些或将分得持续性更长、规模更大的预算，从而支持生成式AI应用生根发芽、斩获1亿美金甚至更多ARR。</span>
   
  </section>
  <h4 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>①AI Agent正在给企业带来效益</span></h4>
  <section>
   <span>2025年，生成式AI应用正在生根、发芽，给企业带来实实在在的现金回报，基于这样的趋势，AI Agent将是这个商业环节闭环的关键。</span>
   
  </section>
  <section>
   <span>AI Agent从学术走向商业落地，仅花了三年时间。</span>
   
  </section>
  <section>
   <span>AI Agent的第一波高潮来自2023年年初，AutoGPT的火爆，所谓AutoGPT，其实是把学术圈很多的Agent idea简单呈现出来，尽管其让开发者感受到大模型的强大，但很快大家便发现，AutoGPT的实验性强于实用性，难以解决大部分的实际问题。第二波高潮来自2023年9月，AgentGen，通过构建不同职能的Agent，分工协作。</span>
   
  </section>
  <section>
   <span>到了2024年，AI Agent开始从实验走向现实。</span>
   
  </section>
  <section>
   <span>2024年末，OpenAI首席执行官Sam Altman提出了AGI（通用人工智能）的五层框架：</span>
   
  </section>
  <section>
   <span>Lv1 - Chatbot，具备基础的对话能力，能够理解和回应简单的文本输入</span>
   
  </section>
  <section>
   <span>Lv2 - Reasoner，具备基本的逻辑推理能力，能够分析复杂信息并进行推断</span>
   
  </section>
  <section>
   <span>Lv3 - Agent，具备理解复杂指令的能力</span>
   
  </section>
  <section>
   <span>Lv4 - Innovator，具备创新和创造的能力</span>
   
  </section>
  <section>
   <span>Lv5 - Organizer，具备协调和管理庞大系统、资源和团队的能力</span>
   
  </section>
  <section>
   <span>他提出，如今我们正处于第二个阶段并非常接近第三个阶段的状态。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>Lv3的Agent智能体能够自主与环境交互、收集信息，具备持续规划并执行多步骤、长时间任务的能力。要达成这个阶段，需要一个推理能力、逻辑能力更强的模型（可能是o1的下一个版本、也可能是对标o1的开源模型）。同时，服务</span><span>AI Agent应用的基础设施也必不可少。</span></span>
   
  </section>
  <section>
   <span>当下，企业出于安全性、准确性、稳定性等因素的考量，更倾向于使用 AI Copilot （人在回路中参与）增加人在工作流中的效率，而不是直接采用端到端自动化 AI Agent。随着底层模型能力和Agent框架开发的持续升级，Agent应用将为企业提供更智能高效的数字员工。人与AI的协作关系将从AI赋能人工作，逐渐转变到人监督指导AI完成工作，最终达到AI自主完成工作。这个转变会在未来几年迅速发生。</span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>至于适合</span><span>AI Agent最先产生价</span><span>值的应用场景，2025年大概将延续现阶段生成式AI渗透率高的场景，例如代码编程、客服、销售、营销等。</span></span>
   
  </section>
  <section>
   <span><span>根据第三方机构Menlo Ventures的调查数据显示，</span><span>企业内各部门的生成式AI预算划分中，IT部分独占鳌头（22%）、产品和工程开发次之（19%），客服（9%）、销售（8%）和营销（7%）紧随其后。</span></span>
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_0298b483075647d294dac3d0835cc841@000000_oswg153382oswg830oswg410_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   
  </section>
  <section>
   <span>数据来源：Menlo Ventures, UpHonest Capital</span>
   
  </section>
  <section>
   <span>根据硅兔赛跑的观察，一些企业的确正在从这几个场景中赚钱：</span>
   
  </section>
  <section>
   <span>IT部门选择之一的初创公司Glean，在2024年9月份完成新一轮融资，估值达到46亿美元，其旨在优化企业内部数据检索和问题答复。</span>
   
  </section>
  <section>
   <span><span>在产品和工程开发部门依赖的AI编程应用中，初创公司Cognition在2024年3月推出了</span><span>首个AI程序员</span><span>Devin，成立仅6个月就达到了20亿美金估值。同年12月其Agent产品Devin正式上线，区别于普通的代码补全应用，Devin能够无需人类参与进行自主编码，完成需要人类工程师参与的项目开发。目前 Devin拥有诸多头部客户：例如Ramp 使用Devin 编写测试代码并清理死亡代码，MongoDB使用 Devin 更新过时的代码架构。</span></span>
   
  </section>
  <section>
   <span><span>硅谷投资机构UpHonest Capital早期投资的Cosine，正在打造全自动的</span><span>AI软件开发助理</span><span>Genie，曾在SWE-Bench测试中获得全球最高分数。Cosine 研发了独有的数据管道，能够生成具有人类工程师开发逻辑、增量知识、支持搜索的高质量数据集。同时，Cosine是OpenAI最大的模型微调合作伙伴，拥有其前沿模型的早期使用权限。结合数据和模型优势，Cosine已经与多家世界500强公司和明星初创公司达成合作。</span></span>
   
  </section>
  <section>
   <span><span>客服作为人力密集型工作，也将成为AI Agent最先颠覆的环节。</span><span>比如UpHonest Capital早期投资的Proactive AI 正在为零售品牌打造具有高情感智能语言能力的客服助理，主要帮助企业向其用户提供契合品牌调性和个性化需求的客服服务，目前已与餐饮、健身、沙龙等行业多家头部企业达成深度合作。</span></span>
   
  </section>
  <section>
   <span>销售和营销作为企业开源的重要入口，企业利用最新技术提高获客效率的意愿也非常高。美国的人工智能初创公司11x，打造AI驱动的“数字工作者”以取代传统的销售团队，其Agent能够自主执行GTM工作流程。11x不通过软件帮助企业降本增效，而是直接提供实在的工作成果，数字员工能够自主实现完成的收入闭环。11x成立6个月就达到了200万美金的ARR，目前ARR已经达到了1,000万美金。FlashIntel正在打造AI驱动的GTM平台并向企业提供AI驱动的销售助理（SDR）。FlashIntel在G2 2024冬季报告中总计获得了189枚徽章，其中FlashRev被评为最佳销售产品，最佳营销和数字广告产品，以及最高满意度产品。</span>
   
  </section>
  <h4 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>② 在数字化渗透率低的传统行业有隐藏的“金矿”</span></h4>
  <section>
   <span>曾经，传统行业的玩家对AI嗤之以鼻，过高的投入成本和微不足道的效果，让他们难以对AI押注过多。</span>
   
  </section>
  <section>
   <span>不过这一次，传统行业的生成式AI之路，有可能跳过软件阶段，直接进入AI阶段，类似新兴市场从使用现金直接转向移动支付。</span>
   
  </section>
  <section>
   <span>这些行业本身对于科技的采用速度较慢，生成式AI的出现带来了直接交付结果而非交付软件的模式，减少了前期投入成本、肉眼可见的提升了投资回报率，使得恐惧新技术的决策者更容易被说服。比如医疗领域的病例记录、法律领域的案件报告生成、金融行业的合规风险筛查等等。</span>
   
  </section>
  <section>
   <span>2024年12月，美国家政垂直软件巨头ServiceTitan上市，上市当天股价涨幅超过40%，在2024年上市公司中，该涨幅仅次于社交平台Reddit和芯片公司Astera Labs两家。</span>
   
  </section>
  <section>
   <span>要知道，ServiceTitan 2012年成立，历经12年发展，在仅拿下家政行业1%市场份额的情况下，其市值一度达到90亿美元。由此可见，美国垂直行业，数字化渗透速率之低，垂直行业AI化的价值之高。ServiceTitan之成功，自然使我们关注到美国传统行业的机会，数字化渗透率低的传统行业。</span>
   
  </section>
  <section>
   <span>美国初创公司Sameday为美国家庭服务行业（除虫、HVAC、家庭维修等）提供AI销售代理，通过自动化的语音客服接听来电并安排服务预约，提高电话接听率，从而提高转换率，现在已经与ServiceTitan集成。Sameday的创始人曾在美国增长最快的家庭服务行头部公司担任CMO，拥有极深的行业认知和丰富的行业资源。2024年，Sameday的ARR预计将增长5倍以上，月度客户留存率达98.5%。</span>
   
  </section>
  <section>
   <span>建筑行业的AI解决方案提供商Pantheon，能够生成高精度且可编辑的 3D 建筑模型，通过AI实现更快的设计迭代周期可以显著降低项目成本。Pantheon AI不向建筑师出售软件许可证，而是直接向房地产开发商和业主出售其设计服务。2024年10月，Pantheon AI完成了由a16z领投的2500万美金种子轮融资。</span>
   
  </section>
  <section>
   <span>传统行业以外，法律、金融、医疗行业积累了大量数据，为行业垂直基石模型训练提供了丰富的燃料，且法律、金融、医疗行业价值高，但普遍在传统软件巨头的垄断下变化缓慢。即便垂直SaaS一定程度上取代了过时繁琐的老系统，但总体的渗透率依然有限。以医疗行业为例，其行业规模高达4.3万亿美元，贡献了约1/5的美国GDP。但在美国市值前100的上市软件公司中，只有一家是服务医疗行业的软件公司。</span>
   
  </section>
  <section>
   <span>2024年，Evenup ARR预计将达到5000万美金，最新一轮的投后估值达到了10亿美金。Evenup 利用生成式AI帮助律师进行人身损害赔偿（Personal Injury Claims）案件的索赔工作。虽然目前只服务于人身损害赔偿这一个领域，但这已经是一个非常大的市场了。美国每年约有30万参与处理人身损害赔偿的律师，每年支付给受害者的索赔金额高达1000亿美金。</span>
   
  </section>
  <section>
   <span>有备而来者，率先享受红利，那些垂直行业专家、对行业的工作流有深入认知的创业者，结合不断进化的生成式AI基础设施，有机会迅速抢占用户，构建自身的行业数据壁垒。</span>
   
  </section>
  <h4 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>③ AI不再按席位收费 ：“Sell work, not software”</span>
   </h4>
  <section>
   <span>Menlo Ventures的调查数据显示，企业在进行生成式AI产品采购决策时，第一考虑要素是产品是否具有简单可测量的投资回报率，其次是产品是否根据实际应用场景定制。</span>
   
  </section>
  <section>
   <span>值得注意的是，现阶段，产品价格反而是最不重要的影响因素，仅1%的企业决策者声称产品价格影响采购决策。</span>
   
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_b37daaaf85754501a2ed893879320432@000000_oswg67372oswg830oswg408_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   
  </section>
  <section>
   <span>数据来源：Menlo Ventures</span>
   
  </section>
  <section>
   <span>结果正在变得更为重要。随着AI的独立工作能力提升，其工作结果、创造的价值会更容易被量化，企业对AI产品的价值评估，也会根据其工作成果界定，美国投资机构a16z提出。因此，商业模式变得更加重要。</span>
   
  </section>
  <section>
   <span>SaaS时代，SaaS公司创新了按席位收费的商业模式，即按照使用SaaS产品的员工账号数量按月或按年收取订阅费用，这种定价方式背后的逻辑是，使用SaaS产品的每位员工，效率会有不同程度的提升、处理更多工作，许多SaaS定价的策略在于评估使用者效率提升创造的收益。</span>
   
  </section>
  <section>
   <span>但到了生成式AI时代，这个SaaS时代一直以来赖以生存的逻辑正在被颠覆。随着Copilot产品向Agent产品的升级，未来的Agentic AI系统将在不同AI agents的相互配合下，自动完成任务，取代越来越多的工作者，显然，如果继续按照席位收费，开发者的收入则会逐渐减少。</span>
   
  </section>
  <section>
   <span>Benchmark合伙人最先建议生成式AI公司“Sell work, not software”，即按照工作成果收费，打破按席位收费的模式。</span>
   
  </section>
  <section>
   <span>基于此，目前原生AI公司普遍采取的商业模式分为两类，一类是基于用量的定价模式，Salesforce发布的Agent force智能体系统，提供客服、销售、员工服务等AI agent智能体，按照用户与agent实际交互的用量收费，每次”对话“收费2美元，如果发生以下三种情况之一，即视为一次”对话“结束—— AI agent无法满足用户需求，需要人工介入；用户主动结束与AI agent对话；用户超过24小时没有再主动与AI agent对话。</span>
   
  </section>
  <section>
   <span>另一类是基于工作结果的定价模式，前Salesforce联席CEO Bret Taylor创立的AI客服公司Sierra，为客户提供基于工作结果收费的客服AI agent，从消费者满意度、问题解决程度、以及每次的交互成本三方面来评估工作结果，决定企业付费规模。采用按照工作结果定价的模式，实现了AI agent企业客户与开发公司的利益一致性，双方将共同得益于agent独立任务完成能力的提升。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势二：等待一个“杀手级”AI消费级应用</span></h3>
  <section>
   <span><span>“2025年（AI应用）下一个大事件属于消费。”</span><span>美国红杉资本合伙人Jess Lee表示，AI聊天、图片、视频已验证了其消费市场潜力，接下来将看到全新的AI消费社交APP、新形式的互动媒体、基于聊天的游戏、新的搜索和信息整合工具、基于互动式UI的聊天工具等。”</span></span>
   
  </section>
  <section>
   <span><span>消费赛道，一直是历次技术创新浪潮下创业者和投资人高度关注的方向，</span><span>如果回顾之前的技术周期会发现，全球市值Top15的科技公司中，有9家是从To C消费产品起家的。</span><span>To C的公司上市时，估值超过100亿美元的比例，比To B公司高10%左右。</span></span>
   
  </section>
  <section>
   <span>但在这一波生成式AI创业浪潮中，消费AI应用似乎在被创业者和资本遗忘。2024年，90%以上的A轮融资流向AI企业应用。</span>
   
  </section>
  <section>
   <span>不过，自2024年下半年以来，这个现象正在发生改变。</span>
   
  </section>
  <section>
   <span>2024下半年以来，资本市场对消费级AI应用的关注度上升，以硅谷孵化器Y Combinator 为例，其下半年孵化的消费级AI产品数量比上半年翻番。</span>
   
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_cd0bc63e121048e48457a7445a3060a3@000000_oswg91603oswg692oswg460_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   
  </section>
  <section>
   <span>数据来源：Y Combinator, UpHonest Capital整理</span>
   
  </section>
  <section>
   <span><span>2025年，消费级AI应用的“土地”正在被开垦，行业在等待一个“杀手级”AI消费的应用。风险投资机构也对消费级AI应用的机会产生共识。YC Partner Michael Seibel表示，</span><span>目前太多创始人寻找B2B的AI机会，太少人探索消费侧的机会，消费创业者的机会来了</span><span>；a16z提出“生成式AI或将重塑从旅游、心理治疗到网购等一切（消费行为）。“前Index Ventures合伙人Rex Woodbury，称现在是“消费复兴”的机会。</span></span>
   
  </section>
  <section>
   <span><span>生成式AI对消费端改变，体现在三个层面：</span><span>首先，AI会逐渐改变人与人、人与信息交互的方式，形成新的流量入口；其次，AI搜索正在改变信息的分发方式，会创造新的商业机会；第三，AI释放PGC、UGC内容创作潜力，使内容消费更加丰富多元。</span></span>
   
  </section>
  <section>
   <span>以AI搜索为例，作为线上流量的第一入口，已经久无战事，生成式AI引入了新变量。2020年创立的生成式AI搜索初创You.com，近期完成5000万美元融资，价值7亿美元了。OpenAI在7月发布AI搜索工具SearchGPT，其付费用户均可使用。</span>
   
  </section>
  <section>
   <span>Perplexity是一家成立于2022年8月的美国AI创业公司，公司由前OpenAI研究科学家Aravind Srinivas和前Meta研究科学家Denis Yarats等联合创立，专注于开发基于人工智能的对话式搜索引擎，旨在通过大型语言模型（如GPT-4和LLama2）为用户提供精准的搜索结果。Perplexity的界面更像是聊天屏幕，用户可以通过自然语言提问，Perplexity会提供直接的答案，并附上详细的引用来源，Perplexity 的用户增长非常迅速。2023年2月，Perplexity的月访问量达到1000万，独立访客达到200万人。截至2024年4月，Perplexity 的月活跃用户数便突破了1500万。Perplexity在短时间内完成了多轮融资。截至2024年11月，Perplexity在新一轮融资中筹集了5亿美元，使公司估值达到90亿美元。投资方包括软银、亚马逊创始人贝索斯和英伟达等多家知名企业和AI领域知名人士。</span>
   
  </section>
  <section>
   <span>除了通用搜索引擎，生成式AI使垂直领域的搜索引擎更普遍，瓜分通用搜索引擎的注意力。例如，垂直于企业知识数据库的搜索——Glean在9月份完成新一轮融资，估值达到46亿美元，旨在优化企业内部数据检索和问题答复，在近两年中ARR翻倍增长；亚马逊、沃尔玛都在加强电商搜索引擎建设，今年先发搜索助手，再发Agent。初创企业DayDream种子轮拿到了5000万美元投资，Forerunner、Index联合领投。DayDream链接了超过2000+品牌，支持自然语言检索，根据用户提供的时间、地点、场合等信息给予相关产品推荐。Encore，YC24新一期孵化项目，是一个LLM驱动的针对二手商品购物的搜索引擎，链接美国多个二手商品网站，支持自然语言搜索以及按照主题的搜索；垂直于科研场景的搜索：初创企业Consensus与Perplexity有共同的投资人Nat Friedman和Daniel Gross，专注打造服务科研的搜索引擎，改变人们获取和使用学术文献的方式。2024年收入增长了600%，月活40万用户，ARR近200万美元。</span>
   
  </section>
  <section>
   <span>也许明年会出现更多令人眼前一亮的垂直领域的AI搜索创新。</span>
   
  </section>
  <section>
   <span>这一点，美国红杉在2025年的AI趋势预测中也分享了一些思考，红杉提出AI搜索或将成为2025年的”杀手级“应用，他们提出了两点预测：目前一个整体的搜索市场可能会碎片化，未来每个人可能会有专业AI搜索引擎——例如，Perplexity可能会成为投资人和分析师的第一搜索工具选择，律师选择Harvey，医生选择OpenEvidence……全新的生成式AI搜索引擎将紧密契合目标用户的“心智模式”，投资人、律师、医生的思维模式各不相同，信息获取模式、目的和决策思维各有差异，这些不同和差异就是生成式AI搜索引擎创新的机会；消费级和企业级应用场景分化，每位知识工作者每天至少会使用两款AI搜索引擎 —— 一款用于工作，另一款用于其他所有事务。</span>
   
  </section>
  <section>
   <span>除了AI搜索，落到电商、音乐、社交、游戏、旅行和教育等直接To C的领域中，也各有生成式AI原生应用的创新机会。</span>
   
  </section>
  <section>
   <span>以旅行为例，Wanderboat是面向消费者的AI旅行规划工具，也是旅游内容分享社区。它构建了一个chatbot，可以根据用户需求推荐、定制目的地及各类娱乐体验活动，还可以主动学习用户的兴趣，定制专属行程。基于创始人此前在微软的经验，构建了一些很有趣的小工具，比如用户在查看地图时也可以与AI互动，实时获取一些信息和建议。在零付费推广的情况下，月活用户数量达到了6位数。</span>
   
  </section>
  <section>
   <span><span>一是多模态AI营销，从文字延展到音频、视频。形式从单点的chatbot延展到具有操作执行能力的agent，并且准确率和对于边缘案例的覆盖力随着基石模型推理能力的提升增强。此外，</span><span>如果生成式AI运用得当，销售、营销、客服对消费者的洞察进一步提高，可以创造更加个性化的服务、定制化体验。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>GigaML是YC孵化的一家AI客服初创，虽然这个方向竞争激励，但实际GenAI应用的渗透率还比较低，因为客服在实际工作中有许多边缘案例，现在大部分的GenAI应用解决边缘案例的表现一般，原有的自动化客服足以解决基础问题，所以企业升级的动力不足。GigaML发现将基石模型切换至o1-preview，加上大量的评估、调优之后，错误率大幅下降，从70%降至5%，并能够解决8成的边缘案例。</span><span>在OpenAI最新推理模型加持下，</span><span>客服用例值得期待。</span></span>
   
  </section>
  <section>
   <span>Para和HeyGen分别是声音和视频营销的典型案例，Para利用AI生成个性化定制的声音营销电话，帮助品牌激活用户，帮助球队活跃粉丝；HeyGen的AI视频营销收入快速增长，据悉今年的年化ARR超过2000万美元，估值已达到5亿美元。</span>
   
  </section>
  <section>
   <span>AdsGency则是一个利用AI用户数据洞察，实现精准广告营销的公司，创始人此前曾在滴滴、亚马逊从事广告、营销相关的产品工作。它的业务核心是广告和用户数据，为客户提供了一个全栈AI营销工具，覆盖内容创意、创作、投放、归因等流程。AdsGency也代表了现在AI营销的一个发展趋势—— 从Point Solution，到整个GTM的全流程自动化解决方案。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势三：企业应用大模型朝模块化方向发展</span>
   </h3>
  <section>
   <span><span>2024年，人工智能领域的一个显著趋势是模型的</span><span>可组合性和模块化发展，</span><span>这种模块化实现了从概念到规模化地落地。企业不再仅依赖于单一的“大模型”解决方案，而是可以根据具体需求，将不同的模块进行组合，定制出符合自己业务需求的能力。这种灵活性不仅能够提升效率，还能降低成本，并且更好地满足各行业对AI应用的多样化需求。</span></span>
   
  </section>
  <section>
   <span>在技术架构层面，传统“大一统”的大模型被逐步拆解为功能与场景模块，例如Amazon Bedrock提供了一系列生成AI的模块化服务，涵盖文本生成、图像生成、语音合成等功能，这些模块化的服务可以帮助企业根据自己的需求进行定制，支持跨行业的AI应用，如生成个性化的营销文案、产品推荐和自动化客服对话等服务。微软推出了更加精细化的模块化API，支持更加多样化的场景，例如多语言客服、智能会议助手和自动化客户反馈系统。Transformer论文八位作者之一Aidan Gomez也瞄准这一方向，估值55亿美元的Cohere提供专为企业用例优化的系列AI模型，在语言生成、多语言处理、多模态、语义检索等方面各有所长，企业按需选择、组合。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>2025年，模块化和抽象化设计将在多个领域得到广泛应用</span><span>，特别是在人工智能和机器学习领域。这种设计方式将推动AI系统的高效演化和自适应能力，为AI技术的广泛应用提供更强大的支持。根据Gartner预测，到2028年，至少15%的日常工作决策将通过代理AI自主做出。</span></span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span><span>这种趋势表明，</span><span>模块化和抽象化设计将为AI系统的自主决策提供更强大的支持，推动AI技术的广泛应用</span><span>。并且，更多的技术企业将推出专为行业需求定制的AI模块。例如，针对智能制造、智慧医疗、自动驾驶等领域的具体需求，可能会出现更加精细化的模块组合，企业可根据自己的数据和业务需求灵活选择。而且随着硬件能力的提升，这些模块可能会更加高效，甚至实现更高的跨领域协同能力。总之，这种模块化大模型的发展将向纵深推进，技术、商业与社会的多重博弈将重塑行业格局。</span></span>
   
  </section>
  <section style="margin: 0px 8px; letter-spacing: 0.578px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#05</strong></span>
  </section>
  <h2 style="text-align: justify; text-indent: 0em; margin: 0px 8px; line-height: 1.75em;"><span><strong>总结</strong></span></h2>
  <p><span style="letter-spacing: 1px;"><span>这场科技商业史上最大“赌局”，让身处其中的投资者越来越感受到了曾经硅谷早期的投资氛围——押注一个未知的全新技术、等待一个超长回报周期，而不是基于互联网成熟技术的模式创新上迅速迭代和回血。</span></span></p>
  <p><span style="font-size: 12pt; letter-spacing: 1px;"><span>自从ChatGPT发布之后，硅谷正在吸引全球的目光。关注硅谷发生的故事，正在成为众多的中国投资者甚至中国企业员工、公关必做的事，大家试图从这些持续关注中获得最前沿的信息和生成式AI最前线所发生的故事，从而试图判断新的商业方向。</span><span>
     </span></span><span style="font-size: 12pt;"></span></p>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>谁也不知道这场生成式AI的变革会将商业引向何方，也同样预测不到新技术的迭代如此之快。</span><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>在过去的几年里，听到最多的便是企业对生成式AI的抱怨“我们知道它重要，但我们仍然不知道如何用在自己的场景中”，这种抱怨带着一些敬畏——“不上大模型一定会被淘汰”。投资者在不断推高的估值和融资中，快要丧失信心。动辄几十亿美金的融资，再加上Scaling Law之下，不断增加的数据中心的投资，让他们望而却步。这也表明，2025年将是生成式AI让人们看到赚钱希望的一年，投资者和创业者同样需要信心。</span><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>AI Agent元年，这个发端于学术界的概念将会落到实际，并产生价值，企业将会使得生成式AI变得更加好用，并切实转化为价值。与此同时，消费级的AI应用将会让人们切实感受到生成式AI带来的生活的变化。</span><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>垂直领域的模型正在成为通用大模型的补充，让更多企业释放AI的价值。垂直行业中，将会出现越来越多的AI搜索应用，满足人们不同领域的需求。</span><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <p><span style="letter-spacing: 1px;"><span>2025年，从生成式AI来说，一些泡沫会破灭，一些企业能够从中赚到钱。技术新陈代谢快速而残酷，这场竞争中没有老手，都是新人，昔日的领军者亦有可能跌落神坛，最先关注到技术和商业的变化，并做出行动的企业，才能在这场竞争中生存下来。</span><span>
     </span></span></p>
  <section>
   <span style="color: #262626; font-family: PingFangSC-Regular; letter-spacing: 0px;">本文来自微信公众号</span>
   <a href="https://mp.weixin.qq.com/s?__biz=MzI4MDUzMTc3Mg==&amp;mid=2247623079&amp;idx=1&amp;sn=3c063bb521adb3a3305617de1339a9c1&amp;chksm=ea3745bccd4b5cd43bbc5585422b33c510fff84df72856b463d98010ad598db9fbc0764d584c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" style="font-family: PingFangSC-Regular; letter-spacing: 0px; color: rgb(38, 38, 38); border-style: solid; border-color: rgb(153, 153, 153); border-image: none; border-width: 0px 0px 1px; padding: 0px 0px 1px;">“硅兔赛跑”（ID：sv_race）</a>
   <span style="color: #262626; font-family: PingFangSC-Regular; letter-spacing: 0px;">，作者：王子、顾程来等，36氪经授权发布。</span>
  </section>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156448125311748</id>
            <title>DeepSeek破圈，AI商业化临界点是如何被打开的？</title>
            <link>https://www.36kr.com/p/3156448125311748</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156448125311748</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:57:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <DeepSeek, AI商业化, 技术民主化, 硅谷>
<br>
<br>
总结: DeepSeek在春节期间引发了广泛关注，成为AI商业化的重要突破口。自ChatGPT掀起大模型浪潮以来，尽管许多模型相继推出，但真正的商业化落地仍面临挑战。DeepSeek通过高质量的技术讨论和跨领域的广泛应用，成功打破了技术壁垒，推动了AI的技术民主化进程。其开源模型的发布吸引了大量专业博主的深入讨论，进一步提升了公众对DeepSeek的关注和使用。通过与用户的高频互动，DeepSeek不仅实现了用户规模的激增，也为AI商业化的成功奠定了基础。 </div>
                        <hr>
                    
                    <p>DeepSeek在这个春节假期卷翻了硅谷，我们注意到，对于模型和应用的讨论很多，但鲜有人追问：DeepSeek的现象级爆火，为AI商业化撕开了怎样的突破口？</p>
  <p>要知道，自从ChatGPT在2023年初掀起大模型浪潮，此后全球各色模型轮番登场、百舸争流，但AI大模型的商业化落地，始终与技术突破存在一定的时差。有的大模型在发布会之后就乏人问津，也有模厂黯然退出了预训练。</p>
  <p>DeepSeek不仅让全球看到了国产AI的技术能力，而且发现，技术破圈之后的商业化生命力也格外澎湃，服务器的繁忙、云厂商/行业伙伴的积极接入，都让人们对深度求索这家科创企业的商业未来格外期待。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9bfc39e4a9654706a8e0bb8f4cc687e3@000000_oswg192297oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而回顾DeepSeek的破圈之路，我们发现一个独特地方，那就是关于DeepSeek的技术讨论，在质量、广度、深度上有碾压式的突破，由此带来了大众广泛使用的技术民主化进程，为DeepSeek的破圈铺平了道路，也为AI商业化开辟了出路。</p>
  <p>我们今天就来聊聊，DeepSeek破圈背后的助推力，以及给AI商业化带来哪些启发。</p>
  <h2><strong>01 出圈锚点：高质量信源，穿过信息迷雾</strong></h2>
  <p>无论是ChatGPT的大语言模型，还是DeepSeek-R1为代表的推理模型，都有着较高的认知门槛。普通人想要了解和触碰这些大厂实验室里的高岭之花，必须走过“拳打硅谷、脚踢华尔街”的标题党，穿过AIGC胡编乱造的信息迷雾，找到那些真实、理性、客观的信源，作为进入技术世界的锚点。</p>
  <p>简单梳理一下DeepSeek的出圈过程，会发现有大量专业博主，成为技术传播的锚点。</p>
  <p><strong>首先，长期关注AI的技术博主，提前技术跟踪、研判与预热，不断消除着大众对技术的认知误差。</strong></p>
  <p>早在2024年中，不少技术从业者已经开始在社交平台，交流讨论DeepSeek V2模型的潜力，这家低调的AI初创公司初现峥嵘。</p>
  <p>2024年12月，DeepSeek新模型V3版本流出，科技博主@阑夕 就曾发起话题，聊起了中国AI卷到硅谷，也提到了春晚刷屏的宇树机器人。早在大众惊叹DeepSeek之前，这些身处行业中心的从业者早已感知到了产业风向的变化。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8a34bbdcfc6844fe866eb78398b4f09f@000000_oswg273329oswg1080oswg412_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>最关键的节点，是2025年1月，DeepSeek-V3和R1开源。</strong>这是AI业内的大事件，但开源跟大众乃至社会有什么关系呢？一大批技术博主，在开放讨论平台，挥舞起了理性分析的思想手术刀。</p>
  <p>包括@梁斌penny、@海辛Hyacinth、@伯克利_尤洋、@高飞 等，都对技术论文、模型架构、创新性等展开深度讨论，将晦涩难懂的技术/论文进行了细致拆解，大众和媒体开始关注到此次国产AI创新的独特之处，密集讨论DeepSeek。此后，DeepSeek热搜推陈出新，热度持续上升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ed402ac0345b419698a5d315342e5ba7@000000_oswg216566oswg1080oswg411_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这些专业博主，是了解AI的高质量信源，也是绝大多数普通人触碰AI的第一个锚点。他们的高质量讨论与思考，成为DeepSeek破圈的头号助力和原点。</p>
  <h2><strong>02 领域破壁：用跨界讨论的广度，打开认知边界</strong></h2>
  <p>DeepSeek之前，也有不少国产模型可以媲美海外产品，但受限于科技企业“重研发、轻营销”的思维惯性，营销手段主要是在模型发布时发一下PR通稿、在技术社区上传一下技术文档、榜单跑分等，讨论度不高、热度难持续。</p>
  <p><strong>反观DeepSeek的出圈，除了模型本身的性能先进之外，与大规模的跨领域碰撞，是分不开的。</strong></p>
  <p>如果说技术博主挥舞的是思想手术刀，那么更广泛的普通博主/大V/KOL等则手握着“DeepSeek+领域”的破壁机，拓展了AI应用落地的边界。</p>
  <p>有人打开了DeepSeek的讨论广度。技术论文解读是最基础的，在此之外，很快涌现出了多种角度的解读。</p>
  <p>比如很多网友看到了DeepSeek-R1的神奇，但自己从没用过推理模型，担心不好上手，科技博主@数字生命卡兹克 在除夕当天发布了《DeepSeek的提示词技巧，就是没有技巧》，打消了普通人的使用顾虑，在春节长假期间给DeepSeek上了一波热度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d804a639fd844bf691cb2e3890447275@000000_oswg346468oswg1080oswg711_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当大众好奇为什么DeepSeek这一次能震撼硅谷时，资深技术专家阮一峰@ruanyf 分享的DeepSeek创始人梁文峰谈开源，是网上关于“开源力量颠覆AI产业格局”较早的讨论之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0d1d76ac712748838a3bc7ad7218b321@000000_oswg97447oswg585oswg235_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>@海辛Hyacinth 则从团队管理的角度，认为DeepSeek 的年轻化团队意味着AI时代论资排辈会越来越少……</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b8dd6542b4f240588cb62bcf5465336a@000000_oswg46076oswg756oswg352_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这些多元化角度的讨论充分打开，延续了DeepSeek的热度。</p>
  <p>上述讨论，进一步激发了多个行业领域博主开始关注DeepSeek，讨论DeepSeek，延伸出了DeepSeek与场景的多种结合方式。</p>
  <p>比如编剧@汪海林，探讨基于推理模型的AIGC，给剧本创作带来的颠覆；博主@零重力瓦力，用“AI解题像学霸写作业”类比大模型思维链，让推理模型不再是悬浮的概念，成了人人可上手的工具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_13ec665e136e42b5abe465ea1095840e@000000_oswg143797oswg1080oswg345_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一个个行业领域的跨界碰撞，让DeepSeek的创意应用喷薄而出，成为DeepSeek出圈的新一轮推动力，带动了更多领域用户的参与讨论，打开了AI商业化的边界。</p>
  <h2><strong>03 技术生命力：以高频率互动，深耕商业化沃土</strong></h2>
  <p>爆火之后，流量倏忽而来、倏忽而去的事并不少见。AI商业化的终极考验，在于将现象级事件转化为可持续的商业动能。这可能吗？</p>
  <p>近年来，智能终端、新能源汽车、国产3A游戏等，都是创造了巨大商业价值的国产科技突破。<strong>从中，我们可以发现科技产品的生命力从何而来：</strong></p>
  <p><strong>一是靠人，依托个人IP化、网红化持续引流。</strong>以小米汽车为例，雷军亲自挂帅，在个人微博等社交媒体，事无巨细分享，与网友高频互动，带动了巨量关注。也吸引了车企、科技企业创始人纷纷从幕后走到台前，将技术产品变成大众谈资。</p>
  <p><strong>二是靠产品</strong>，以竞争激烈的手机市场为例，近年来手机厂商营销上更接地气，主打一个听劝，“用户要什么就给什么”，让手机创新不再是产品经理的闭门造车，而是定制话题，与用户展开共创，vivo、OPPO都借助社交平台来优化产品，实现了增长。</p>
  <p><strong>三是靠口碑</strong>，DeepSeek的爆火也让人注意到了《黑神话：悟空》背后的游戏科学、宇树机器人等科创企业，它们的产品都是从发烧友推崇的小众产品，<strong>通过社交媒体的口碑传播，迅速蔓延到大众视野，在全球为中国科技赢得了声誉。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f1ed250dd1db45c4b6e7424671497b5d@000000_oswg144598oswg1080oswg763_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不难发现，在长周期、重投入的科技领域，爆红是偶然，长红靠深耕。汽车企业、手机厂商都将内容社交平台，作为品牌重地，通过与潜在用户保持长期、高频率的互动，将社交流量池转化为商业沃土。</p>
  <p>AI行业，当然也不能例外。</p>
  <p><strong>DeepSeek的爆火出圈，正在于打破了海外AI的使用封锁，让全民都能用上先进推理模型，将AI变成全民都在聊、都在用的工具，热搜话题多达200多个。</strong></p>
  <p>春节期间，我们看到了大量普通人与DeepSeek的互动，美妆博主用DeepSeek定制护肤方案；父母在亲子交流中用DeepSeek生成“高情商回复”；冲浪乐子人用DeepSeek“锐评”各类新闻事件……各种意想不到的玩法，都成为AI技术与现实的碰撞时刻。在200+热搜话题中，DeepSeek裂变成了一场全民参与的AI应用实验。</p>
  <p>在这场全民讨论和使用的热潮中，DeepSeek通过口碑传播，不断拉新，用户规模激增。在此基础上，可以获取大量真实互动的数据，可以优化模型产品的使用效果，进一步拉开与其他模型的差距。</p>
  <p>与竞价砸钱买量的传统营销方式不同，DeepSeek的出圈路径，是热搜话题设置讨论议题——技术/行业头部博主打开讨论角度——大量用户参与众测的组合式传播。一步步引导真实用户加入讨论、互动和反馈。</p>
  <p>饱和式的全民参与，让DeepSeek的增长飞轮开始转动，成为DeepSeek出圈的最大一股推动力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ad40fa90f7d74c7893599cf0a7a6f354@000000_oswg58988oswg1080oswg483_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这也提醒我们，让AI走向大众的技术民主化，是商业化成功的前提。</p>
  <p><strong>从技术特性来看</strong>，AI不同于传统的互联网应用和科技产品，后者推出时就是完整形态，而很多AI模型和产品需要先推出再找PMF，在跟用户的迭代互动中不断成长、成熟起来。所以，AI产品必须重视全民参与，至少要有目标用户群的重度参与。</p>
  <p><strong>从市场竞争来看</strong>，AI产品处于排位剧烈动荡的拉新周期，基础模型又需要规模效应，所以竞争白热化，没有声量相当于“等死”，AI企业必须不断制造大众对技术的关注与讨论。OpenAI去年底为期12天的技术发布，就通过话题设置，吸引了全球关注。</p>
  <p>此前，AI领域的技术交流，大多集中在开发者扎堆的极客技术社区，或者AI大厂的开发者社区，与企业客户的闭门交流，缺乏与C端消费者在社交平台互动的经验。</p>
  <p><strong>但是，以大模型为基础的AI应用，开始逐渐转变营销思路。</strong>以豆包、文小言、kimi等为代表的这一批大模型应用，都越来越强调C端传播，用户数成为产品生命力的重要指标。DeepSeek的出圈，则一举打破了海外推理模型的使用封锁线，让先进AI技术可以为大众所见、所聊、所用。这是技术民主化的最佳例证，也是AI实现商业成功的必经之路。</p>
  <p>面对DeepSeek掀起的AI民主化浪潮，全球AI企业或许都面临一个关键选择：是被DeepSeek热潮悄无声息地淹没，还是加速拥抱亿万普通人。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzUxNTUyMjE4Mw==&amp;mid=2247526123&amp;idx=1&amp;sn=ceaa57356d2b4356e55bf618f40f56fa&amp;chksm=f87d83192dbd9eca16e8131ac0c0105b04905c741274c0b3093daa4de1ac9a57063ba18e9f1e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“脑极体”（ID：unity007）</a>，作者：藏狐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156472468560390</id>
            <title>春节后最强三大ETF浮现：人形机器人、黄金、哪吒</title>
            <link>https://www.36kr.com/p/3156472468560390</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156472468560390</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:56:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: A股投资, ETF板块, 机器人, 黄金股  
<br><br>  
总结: 本文分析了春节后A股市场的投资轮动风格，指出机器人ETF、黄金股ETF和游戏动漫等TMT主题ETF成为年内涨幅领先的板块。机器人ETF因春晚节目“机器人扭秧歌”而受到关注，年内涨幅达到18.14%。黄金股ETF受国际金价上涨影响，年内涨幅近13%。此外，《哪吒之魔童闹海》的成功票房推动了游戏动漫相关ETF的上涨。文章还探讨了机器人行业的长期投资机会及黄金市场的前景。 </div>
                        <hr>
                    
                    <p>A股投资轮动风格向来以快制胜，春节后两个交易日，2月6日，年内涨幅超过10%的三大ETF板块已经浮出水面。</p>
  <p>具体来看，<strong>一是机器人ETF板块。</strong>春晚大火的“机器人扭秧歌”，春节后机器人ETF迎来大爆发，年内回报率超过黄金相关主题ETF，成为第一。嘉实机器人指数ETF单日涨幅达到8.27%，年内涨幅18.14%登顶；</p>
  <p><strong>二是黄金股等ETF。</strong>国际金价在节后一度升至每盎司2900美元上方，连创纪录，对于黄金而言，已是疯狂行情。有业内人士调侃，高盛对于黄金将在2026年中期达到3000美元的预测还是太保守了。截至目前，黄金股ETF年内涨幅近13%。</p>
  <p><strong>三是游戏动漫、软件等TMT主题ETF。</strong>2月6日12时，《哪吒之魔童闹海》以57.76亿元票房（含预售）登顶中国票房榜第一名。该影片的出品方光线传媒在影片上映后受益显著，春节后两个交易日累计涨幅41.66%，股价创近4年新高。《哪吒》撬动游戏动漫、软件等ETF年内收益率超过10%。</p>
  <p>三条投资主线既明，当前产业处于什么发展阶段？将如何映射到投资端？接下来又将面临哪些机会？基金经理们带来最新解读与展望。</p>
  <h2><strong>机器人是10年大级别beta机会，还是短期止盈？</strong></h2>
  <p>2025年蛇年春晚的舞台上，一群穿着花棉袄的机器人在现场扭起了秧歌，机器人们还会变换队形、舞动身体，多角度转手绢。“机器人扭秧歌”登上热搜，这些机器人来自国产机器人生产商。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f6af220b388c4ea194042d4b55438b1a@5888275_oswg108763oswg1080oswg725_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>机器人扭秧歌与春晚的组合，赛博朋克风格的节目让人印象深刻，也在节后迅速进入投资者的布局视野。仅仅两个交易日，机器人相关ETF组团登顶年内股票ETF涨幅榜。</p>
  <p>2月6日，嘉实机器人指数ETF涨幅达到8.27%，年内涨幅18.14%。溢价也达到2.47%，可见资金热度。此外，天弘、银华、华夏、国泰等旗下机器人ETF年内涨幅也达到15%，当前也具有不同程度的溢价。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6eeddf5abb184338a8f79fb59fcdc9a2@5888275_oswg50380oswg1080oswg238_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>重点关注机器人方向的永赢先进制造基金经理张璐介绍，以前机器人板块觉得产业链还处于极早期距离落地还有较长时间，同时板块股票数量、行业催化都比较有限，所以机器人板块的行情往往持续性不强。但是机器人板块从2024年四季度开始发生了一些根本性的变化，板块持续演绎，核心是有三点原因：一是超预期的国内外人形机器人进展；二是2025年人形机器人量产元年；三是政策端的支持。</p>
  <p>“除了国内人形机器人厂商进展超预期，2024年10月10日，We Robot大会上，10余个特斯拉擎天柱机器人在现场端茶倒水、跳舞、互动，整体呈现更加灵活与智能，直播3小时中，不存在任何差错，展现了极强的工程实力。”张璐表示，去年12月以来我们看到了大量的新进入玩家开始布局机器人行业，包括汽车、电新、家电、互联网领域的传统巨头，机器人板块股票数量也在快速增长，行业扩圈明显。</p>
  <p>在量产方面，平安基金基金经理张荫先也表示认同，他认为，后续很快会迎来“机器人”新物种的量产时刻，这个赛道也将会是未来数年最受资本市场关注的赛道之一。</p>
  <p>赛道火热之余，投资者更为关心的还是行情的持续性。张璐直言，<strong>人形机器人板块是未来10年大级别beta机会。从产业角度，机器人行业的“Iphone时刻”或将来临。对于行情的判断上，机器人板块近期已逐渐从主题转变为具有长期向上趋势的成长板块。</strong>无论是机构还是游资，整体活跃度较高，此外板块内标的的扩散程度、资金容纳度均有提升。综合来看，机器人板块预期可能会成为中长期反复活跃、中枢不断提升的板块，具有较高的成长性。</p>
  <p>在投资机会的挖掘上，张荫先认为可从两个方面着手，一是寻找在机器人业务中存在较高概率进入供应链的公司，二是积极挖掘并布局主业基本面有改善、同时新拓展机器人业务的优秀公司，这类公司会在新材料、新工艺、新设计方案中有望脱颖而出，让原有的产品在新的机器人领域中获得新应用场景、实现0-1的新突破，进而获得估值及业绩的双击机会。</p>
  <p>当基金经理喊出人形机器人板块是未来10年大级别beta机会的时候，也有游资表示，今天减仓了部分机器人概念。“产业的长期看好与短期的止盈并不矛盾。”</p>
  <p>从资金变动方向来看，2月5日，8只机器人ETF合计资金净流出约1亿元，有一定的止盈迹象，年内资金净流入则达11亿元，其中，华夏机器人ETF净流入最多，超过10亿。</p>
  <h2><strong>国际金价触及3000美元还要用多久？</strong></h2>
  <p>2月5日，COMEX黄金一度升至2900美元/盎司关口上方，今年以来，国际金价已经连续突破2800美元、2900美元关口。换算成国内金饰价格或更为直观，2月6日，周大福、六福珠宝、潮宏基、周生生等足金饰品价格每克已经接近870元。</p>
  <p>2月6日，COMEX黄金价格略有回落，年内涨幅仍高达8.82%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3c5d585d7275484ab1d9ef0d7973f392@5888275_oswg99703oswg1080oswg1321_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>金价上涨，叠加众多金矿龙头公司纷纷发布2024年报业绩预增公告，被称为“金价放大器”的黄金股ETF紧随机器人ETF之后，成为年内增长第二的板块。多只黄金股ETF年内涨幅超过12%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1a274904219e4a4ca028cb3f438a2f2d@5888275_oswg80181oswg1080oswg420_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于黄金股大涨的原因，永赢黄金股ETF基金经理刘庭宇表示，黄金股会受到黄金价格与国内金矿产业公司的双重影响，假期金价上涨反映了投资者对关税政策不确定性的担忧和对全球经济疲软背景下降息周期延续的预期，当前龙头金矿公司按市盈率估值计算仍处于历史中枢下沿，后续估值修复可期，未来有望在量价齐升的戴维斯双击周期中继续起到“金价放大器”的作用。</p>
  <p>“还有一个角度也值得大家关注，近期特朗普家族频繁发行新品类数字货币，导致数字货币市场降温、比特币大跌，部分资金或从数字货币回流黄金市场。”刘庭宇分析称。</p>
  <p>2024年也是黄金投资的大年，当年黄金股ETF涨幅超过27%，今年仅仅过去一个月，相关ETF涨幅已经接近去年全年涨幅的三分之一，接下来该如何配置？在华安基金看来，黄金依然是2025年值得重视的大类资产，原因有四：</p>
  <p>第一，实际利率对黄金的定价有望回归，包括全球经济增速放缓，以及美国面临中长期的再通胀问题。</p>
  <p>第二，逆全球化背景下，为了应对通胀和金融危机，央行有望延续购金节奏。</p>
  <p>第三，黄金在大类资产维度的低相关性，叠加当前低利率环境，凸显出重要配置价值。</p>
  <p>第四，黄金长期增长的本质依然是货币属性，对抗美元信用，当前美国的债务压力和高利率环境在加剧信用风险。</p>
  <p>在黄金相关ETF则越涨越买，2月5日，黄金相关ETF合计净流入5.66亿元，不过拉长年内来看，资金在黄金相关ETF流出近20亿元。</p>
  <h2><strong>《哪吒》撬动游戏动漫等概念ETF大涨</strong></h2>
  <p>《哪吒》票房以58亿元登顶，再次成为游戏动漫等主题上涨的重要驱动事件，不仅最新票房预测达到87亿元，带飞出品方两连板光线传媒，联名手办售罄的泡泡玛特、出版官方绘本的中信出版，乃至提供动漫渲染服务的丝路视觉等上市公司纷纷受到投资者关注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7f42f552db6e40f69f1253b88500d1ea@5888275_oswg97642oswg830oswg1396_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>优质影片内容对票房拉动效果明显，大IP模式之下，影视、动漫、游戏以及软件等TMT主题均受益，华夏游戏ETF、国泰游戏ETF以及华泰柏瑞游戏动漫ETF等大涨之后，年内涨幅也超过11%。</p>
  <p>银河证券研报指出，春节档影片几乎都是国产IP电影或者续作，高价值IP的电影续作不断推进将激励更多新的优秀IP涌现，有望赋能整个电影IP及周边的授权、衍生、开发系列产业链，国产电影的IP品牌效应已经初步显现。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Xz-ErPBYm1oVa41wZ2Toqg" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”</a>，作者：闫军，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156472198584834</id>
            <title>人形机器人短期大涨超50%，基金经理：未来10年大级别机会</title>
            <link>https://www.36kr.com/p/3156472198584834</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156472198584834</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:56:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人形机器人, 产业发展, 投资机会, 政策支持  
<br><br>  
总结: 2025年将是人形机器人量产元年，国内外企业积极布局，相关政策支持不断增强。机器人板块在春节后迎来连续上涨，涨幅已超过50%。多位基金经理认为，机器人行业正在经历根本性变化，未来将成为中长期活跃的成长板块。人形机器人不仅能解放双手，还将全方位赋能人类生活，市场潜力巨大。随着技术进步和产业链完善，预计将迎来“机器人”新物种的量产时刻。 </div>
                        <hr>
                    
                    <p>2025年蛇年春晚的舞台上，一群穿着花棉袄的机器人扭秧歌，让其背后的产商——宇树科技屡登热搜，<strong>人形机器人“一日千里”般的产业发展情形也进入大众的视野。</strong></p>
  <p>受多个利好消息刺激，<strong>春节后两个交易日，机器人板块迎来连续上涨行情：</strong>国泰、华夏、天弘、银华旗下中证机器人ETF在2月5日上涨超4%，截至发稿，相关产品今日涨幅也已近3%。而自去年924行情以来，这一板块涨幅已超过50%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_37fcfdbfaa2a4a26bab1b6cda2c452da@5888275_oswg107332oswg808oswg545_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>多位基金经理认为，机器人板块从2024年四季度开始发生了一些根本性的变化，其板块持续演绎的核心逻辑在于：<strong>超预期的国内外人形机器人进展，2025年将是人形机器人量产元年，政策端支持。</strong></p>
  <p>在业内人士看来，机器人板块预期可能会成为中长期反复活跃、中枢不断提升的板块，具有较高的成长性。<strong>该板块是未来10年大级别beta机会，</strong>它的闪耀登场远不止解放双手那么简单，可能是未来不可多得的，如同当年消费电子中苹果产业链、特斯拉电动车产业链——现象级的长坡厚雪大赛道。</p>
  <h2><strong>人形机器人迎“升浪”</strong></h2>
  <p>经过一个春节的酝酿，人形机器人已进入大众视野，相关产业的巨大发展潜力也为人所熟知。</p>
  <p>一方面，国内企业如华为、宇树科技等积极布局人形机器人；另一方面，国际巨头如特斯拉、英伟达等公司的人形机器人项目正在快速推进，预计2025年将进入有限生产阶段，机器人新创企业Figure更是在2月5日宣布终止与OpenAI合作，并豪言将在30天内推出“ 颠覆人形机器人行业 ”的创新成果。</p>
  <p>受此刺激，春节后首个交易日，机器人板块涨幅居前，国泰、华夏、天弘、银华旗下中证机器人ETF在上涨均超4%。在2月6日开盘后，相关产品继续上涨，截至发稿，上述产品涨幅均在3%左右。</p>
  <p>鉴于人形机器人概念活跃，关注度持续提升，<strong>多家上市公司在互动平台回应研发情况及相关布局：</strong></p>
  <p>经纬股份：公司业务目前不涉及电力巡检机器人和四足巡检机器人；</p>
  <p>精工科技：碳纤维在人形机器人领域的应用优势明显，随着人形机器人产业的快速发展和规模化生产，碳纤维的需求预计将呈现显著增长态势；</p>
  <p>宜安科技：公司密切关注智能机器人领域的技术和产业发展动态，并将结合公司自身战略规划和市场需求进行业务拓展和布局；</p>
  <p>豪森智能：公司现已构建汽车现代智能工业装配线，建立人形机器人智能制造创新中心，完成大连基地与常州基地人形机器人开发双布局，开展多场景人形机器人应用训练和测试技术开发，通过20余年积累的汽车核心零部件装备生产线工艺数据快速迁移到人形机器人智能体开发中，加快了人形机器人在工业制造场景的落地；</p>
  <p>机器人：工业机器人和人形机器人从产品形态、产品结构、技术及应用的侧重等有一定差异，目前公司在3D视觉、力感知等工业机器人领域的核心技术方面有技术积累优势，未来将视需求在融合上述技术的基础上，围绕AI大模型、智能视觉感知、数字孪生、结构仿生等前沿、空白技术领域进行研发投入，积极布局人工智能前沿领域，相关工作在有序推进，尚处于研究初期阶段……</p>
  <h2><strong>板块持续演绎的核心逻辑</strong></h2>
  <p>在国内，有穿着花棉袄的机器人扭秧歌；国外，则有特斯拉擎天柱机器人在“We Robot”大会上端茶倒水、跳舞、互动，还在感恩节随机扔发网球、完美接球。</p>
  <p>从实际情况看，2024年12月以来，大量新进场的玩家开始布局机器人行业，包括汽车、电新、家电、互联网领域的传统巨头，机器人板块股票数量也在快速增长，行业扩圈明显。</p>
  <p>股价层面，从2024年924行情以来，机器人板块的涨幅已来到50%以上，天弘中证机器人ETF、易方达国证机器人产业ETF、景顺长城国证机器人产业ETF涨幅分别达53.93%、53.61%、53.04%，其余中证机器人ETF涨幅也都超51%。</p>
  <p>“以前觉得机器人板块产业链还处于极早期距离落地还有较长时间，同时板块股票数量、行业催化都比较有限，所以机器人板块的行情往往持续性不强。”永赢先进制造基金经理张璐表示。但他看到，机器人板块从2024年四季度开始发生了一些根本性的变化，板块持续演绎。</p>
  <p>他认为，核心原因有三点：一是超预期的国内外人形机器人进展；二是2025年将是人形机器人量产元年：一方面，是特斯拉计划2025年开始对内量产，目标1万台，另一方面，国内多家机器人厂商都推出了自己的量产时间规划，2025年或将看到整个行业1-N的开端；三是政策端支持，近年来，中央和地方政府密集出台政策，全面支持人形机器人产业的发展，为其技术突破、应用推广和产业链完善提供了强有力的保障。</p>
  <p>浦银安盛高端装备基金经理李浩玄直言，过去短短几个月内，人形机器人的产品性能有快速提升，尤其在灵巧手和动作泛化程度上进步显著；国内外几乎所有的科技和制造巨头都在进入这个产业，彻底定调明确了行业趋势，也粉碎了此前的诸多质疑。</p>
  <p>在供应链上，除了原有的核心玩家，新进入者众多。尤其是本身具有技术积淀的自动化和汽零公司基本都在积极投身其中。中国制造快速反应迭代的优势显现。在股价层面，由于一致预期的建立，人形机器人板块涨幅可观，且标的快速“扩圈”，相比2022年和2023年的行情，正在逐步从主题概念过渡到产业投资。</p>
  <p>在此背景下，他在四季度将仓位更多地集中到具备高确定性的标的上，以产业的思路重仓具有真正核心技术、卡位优势和供应链能力的公司。除了上游的核心零部件，还配置了稀缺的具有本体制造和强大品牌力的人形机器人主机厂商。“总的来说，我们将坚持把握行业大趋势，过滤短期情绪波动，战略性重仓扎根核心品种。”</p>
  <h2><strong>机器人行业的“iPhone 时刻”或将来临</strong></h2>
  <p>近期，机器人板块已逐渐从主题转变为具有长期向上趋势的成长板块。不论是机构还是游资，整体活跃度较高，此外板块内标的的扩散程度、资金容纳度均有提升。</p>
  <p>“综合来看，机器人板块预期可能会成为中长期反复活跃、中枢不断提升的板块，具有较高的成长性。”张璐表示。</p>
  <p>他认为，2025年开始，一大批国内外厂商都将进军人形机器人产业，部分公司可能推出现象级机器人产品并开始进行小规模量产，机器人行业的“iPhone 时刻”或将来临。</p>
  <p>在他看来，人形机器人板块是未来10年大级别beta机会。<strong>它的闪耀登场远不止解放双手那么简单，无论从情感陪伴还是物理支持都将全方位赋能人类的生活。</strong>马斯克多次阐述愿景：未来人类和人形机器人的比例将不止是 1：1，有较大可能超过人类数量，渗透率的天花板高且想象空间大。“终局来看，假设是100亿台机器人的市场，如果2万美金一台，会形成200万亿美元的终局大市场。如果所有企业按照终局估值，在未来都会带来庞大增长。”</p>
  <p>值得一提的是，<strong>人形机器人相较于其他行业壁垒较高，涉及到多学科的融合、软硬件的协同，所以对入局的资金、技术、资源整合都有相对较高的要求。</strong>而且产业链从上游到核心零部件和系统零部件，到中游的机器人本体和系统集成，到下游的终端应用，产业链长且复杂。机器人。</p>
  <p>“因此，人形机器人可能是未来不可多得的，如同当年消费电子中苹果产业链、特斯拉电动车产业链——现象级的长坡厚雪大赛道。”而随着人形机器人量产接近，张璐也将重点关注拥有供应链优势、技术具有护城河、价值量较大的优质人形机器人产业链公司，包括机器人总成商、丝杠及设备、减速器、传感器、电机、灵巧手等。</p>
  <p>兴银先进制造智选基金经理罗怡达亦表示，2025年，我们将看到人形机器人开始走向小批量量产，具备完全AI能力的人形机器人将离现实越来越近。“科技的发展将改变我们的生活，这里面蕴含了大量的先进制造产业链机会，中国的企业在相关产业链上有重要的卡位优势，我们积极挖掘其中受益产业趋势且性价比合适的标的进行布局。”</p>
  <p><strong>“我们预计很快会迎来‘机器人’新物种的量产时刻，这个赛道也将会是未来数年最受资本市场关注的赛道之一。”</strong>平安基金经理张荫先称，一方面，他将寻找在机器人业务中存在较高概率进入供应链的公司，另一方面积极挖掘并布局主业基本面有改善、同时新拓展机器人业务的优秀公司。</p>
  <p>“这类公司会在新材料、新工艺、新设计方案中有望脱颖而出，让原有的产品在新的机器人领域中获得新应用场景、实现0-1的新突破，进而获得估值及业绩的双击机会。”张荫先表示。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/WO9Mb56ELXWJlaAdKxPINQ" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”</a>，作者：沈述红，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156437179357954</id>
            <title>苹果机器人首次曝光，一个有情绪会蹦迪的“台灯”，皮克斯动画照进现实</title>
            <link>https://www.36kr.com/p/3156437179357954</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156437179357954</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:56:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <皮克斯, ELEGNT, 机器人, 情感表达>
<br>
<br>
总结: 1986年，皮克斯的短片《顽皮跳跳灯》展示了无表情的台灯通过动作传达情感，成为皮克斯的吉祥物。苹果推出的ELEGNT机器人，旨在让非拟人化机器具备肢体语言和情感表达，提升人机交互的生动性。ELEGNT通过上下文学习能力，能够根据实时场景调整动作，表现出情感和态度。尽管ELEGNT在情感表达上表现出色，但其效率低于传统机器人，引发了对机器人设计方向的思考。未来，ELEGNT可能会在智能家居中得到应用，成为更具普适性的技术。 </div>
                        <hr>
                    
                    <p>1986 年，皮克斯在一场计算机图形讨论会上放映了最新动画《顽皮跳跳灯》，片中两个蹦蹦跳跳的台灯没有表情，没有对白，只凭借扭头、伸展等等的动作，用 2 分钟就向观众展示了自己的鲜明个性和情感。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_827ccc547b3e4bb6931f11dbe2cf29dd@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种前所未见的动画形式，不仅震撼了在场所有人，还助力这部短片拿下奥斯卡提名，也成为了现在每一部皮克斯电影都不会缺席的吉祥物。&nbsp;</p>
  <p>而将近 40 年后的今天，和皮克斯渊源颇深的苹果，成功将这个动画史上最具里程碑意义的角色，带到了现实世界当中。&nbsp;</p>
  <h2><strong>有情感的「小台灯」&nbsp;</strong></h2>
  <p>今天，苹果在其机器学习网站，公布了一项机器人研究成果 「ELEGNT」，目前的原型机器是一个台灯形态的设备。&nbsp;</p>
  <p>ELEGNT 的名字取得非常巧妙：形似单词「elegant（优雅）」，符合这项技术的表现；而全称很长：a framework of <strong>E</strong>xpressive and functiona <strong>L</strong>&nbsp;mov <strong>E</strong>ment desi <strong>G</strong>n for&nbsp; <strong>N</strong>on-anthropomorphic robot，翻译过来就是「一种用于非拟人化机器人的表达性和功能性运动设计框架」。&nbsp;</p>
  <p>看起来有点抽象？其实核心意思很简单：苹果做的不是春晚舞台上的人形机器人， <strong>而是让一些非人形机器，比如一个台灯，懂得「肢体语言」。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_210501355b474ce9b699221235d4127a@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这个「懂」不单单是「理解」人类的手势操作， <strong>而是机器人做出反应时，也会补充一些动作细节，让交互有「生命感」。</strong></p>
  <p>传统的机器人，完成指令的方式是一条直线，程序设定好的动作幅度精准到不会多出一毫米。&nbsp;</p>
  <p>而 ELEGNT 是一条曲线，过程中会表达意图、显示注意力、展示态度、表达情绪，也就是说会小小地「演」一下。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8286f79424f24421be010e5ec72548c8@000000_oswg37458oswg1024oswg573_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>比如，用户下达指令的时候， ELEGNT 会「看着」用户，时不时歪歪头和点头，仿佛自己真的在认真听讲，而实际上没有这些动作，机器人也能通过麦克风正常录音和分析。&nbsp;</p>
  <p>用户问机器人天气，它会先向窗户的方向探探头，然后再进行回答，但其实它只是上网检索了一下天气数据。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_db522a7d1a2a4ba2b03061843530d7a7@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>如果机器人够不着需要识别的物体，它还会垂下脑袋摇摇头。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0accbf1b7f2a4ab0871d09fcf03f8a7f@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>比较可爱的是放音乐的时候，机器人会跟着节拍一起蹦迪，看起来真就像是皮克斯电影的桥段。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_622cfd766bdd45af9b9b4826c5303c51@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一样的台灯形态和动作，很容易让人想起 2023 年小米发布的一个名为「皮皮灯」的产品，同样能「摇头晃脑」，有「喜怒哀乐」的情绪表达。&nbsp;</p>
  <p>不过这个皮皮灯的实现原理要简单许多，主要是设定好的程序，动作幅度也比较死板，总体来说比较像噱头。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3cb99bdc0d4d437cbb9db8bc075a84f6@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：知乎 @J 法老&nbsp;</p>
  <p>ELEGNT 背后的技术要复杂得多， <strong>运用了大语言模型的上下文学习能力，能够「察言观色」</strong>，根据实时交互场景调整动作模式。在交互中，ELEGNT 会主动问用户远足能不能带上自己，如果被拒绝，它就会低下头，给人一种很难过的感觉。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1ea45f25131549d88db9e0c2a947a091@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>ELEGNT 还结合人类反馈优化，目前能够生成 10 种不同的肢体语言序列，并控制好每个动作的时间和幅度，实现情感表达和任务完成效率的平衡。&nbsp;</p>
  <p>当然，高度拟人化的 ELEGNT，背后也存在一定的伦理问题：可能会引起用户的情感投射，甚至依赖，尤其是在儿童和一些脆弱群体当中。&nbsp;</p>
  <p>由于测试的时间太短，测试人员也不够多，无法验证 ELEGNT 表达动作会不会存在程式化的问题，长期使用有可能会导致用户审美疲劳，影响交互的有效性。&nbsp;</p>
  <h2><strong>机器人也需要「人味」&nbsp;</strong></h2>
  <p>从苹果的演示对比视频可以发现，ELEGNT 机器人虽然可爱，但它的效率比「打直球」的普通机器人要低很多，前者还在探头探脑的时候，后者早已经给出用户需要的答案。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_339384dd4e9b4c41b0f0bcd3b4524325@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>这似乎和机器人的初衷有点背道而驰。让机器人进入我们的工作和生活，本应该是为了更好更快地帮我们干活，而 ELEGNT 问个天气都要等它先演一番，这么一想，苹果好像「方向错了」？&nbsp;</p>
  <p>技术是冰冷的。当你还在欣喜于 Deepseek 能帮你高效完成工作，可能你已经快要被它取代；工厂里越来越多的机器人身影，意味着更多人类失去岗位。&nbsp;</p>
  <p>而苹果变 AI 为 Apple Intelligence，玩一点文字游戏来掩盖技术的无情一面；而对于机器人，苹果的思路更加开阔。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_03209b452cb94c0087f51539662b2abd@000000_oswg62808oswg1024oswg538_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Apple Intelligence 多彩的界面和 logo 也是为了显得更友好 &nbsp;</p>
  <p>虽然不如人形机器人那么火，但这两年「机器宠物」的概念也开始兴起：卡西欧的 Moflin 卖断货，CES 上的 Ropet 成功刷屏。这些毛绒绒的小机器人，主要的功能就是卖萌，和生成一些「情感」。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f0f86755445c40c899f56423c673eb1e@000000_oswg51112oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Ropet&nbsp;</p>
  <p>&nbsp;</p>
  <p>ELEGNT 就有点像电子宠物和实用机器人的结合，它能一边卖萌，一边完成任务。论文中也提到，情感优先的机器人，能够降低人类的认知负荷，让用户更乐于主动去进行交互，特别是在社交场景中。&nbsp;</p>
  <p>不是只有苹果在想办法为机器人增加活人感。马斯克的人形机器人 TeslaBot，已经会和用户玩剪刀石头布；宇树科技也让机器人穿上大花袄扭秧歌，登上春晚大舞台。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d49e3d3b69934aae8110b9f042e05e3b@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">TeslaBot&nbsp;</p>
  <p>&nbsp;</p>
  <p>只是，这些外壳冰冷、动作机械的机器人，再怎么模仿人类，目前都还是差了点意思。ELEGNT 直接另辟蹊径，利用了我们对皮克斯动画角色的集体记忆，加上完成度相当不错的机器动作，首次亮相就成功走进不少人的内心。&nbsp;</p>
  <p>The Verge 评论区，已经有网友对 ELEGNT 给出高度评价：&nbsp;</p>
  <p><strong>我已经不想养一只狗了，我现在想养一盏台灯。&nbsp;</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3ae65fc1c9234598a57a979468303024@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">「我爱台灯」&nbsp;</p>
  <p>论文中更严谨的样本研究显示，带有情感表达的 ELEGNT ， <strong>在 6 个任务的评分中都高于没有情感表达的版本，前者几乎获得后者两倍的平均得分；并且 ELEGNT 放音乐时蹦迪的表现让人印象非常深刻。</strong></p>
  <p>比起人形机器人，ELEGNT 是一个更具普适性的技术，因为它可以用于那些非人形的低自由度机器人中。今天是一盏台灯，明天可能就是苹果的 HomePod，到最后可能整个家都变成迪士尼的公主城堡，每个家具都有自己的情感，一个人住也能热热闹闹的。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2eea7672bcf143c5a9d3c4f56bf9b79d@000000_oswg62392oswg612oswg380_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">未来的智能家居说不定长这样&nbsp;</p>
  <p>虽然这些技术目前还只是学术成果，但它们实装到产品上的日子或许不会太远。从去年开始，非常多的信息源都报道称， <strong>苹果正在开发智能家用机器人，可能会是一个带了个显示屏的 HomePod 设备，或者是带有机械臂的 iPad</strong>，有点像经典的 iMac G4， <strong>有望于 2026 或 2027 年推出。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_33dd6ab8bf5547caa6535560c1a9513e@000000_oswg477685oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">苹果新智能家居假想图，图源：MacRumors&nbsp;</p>
  <p>根据此前的爆料，这个带显示屏的 HomePod 可能会支持自动转向，始终将屏幕对准用户，并且能识别手势操作，听起来就很适合 ELEGNT 大显身手。&nbsp;</p>
  <p>iPhone 一年比一年无聊，万众期待的 Vision Pro 、Apple 智能实际体验乏善可陈。据称，家用机器人很可能成为苹果的「Next Big Thing」，用来打下苹果目前表现平平的智能家居市场。&nbsp;</p>
  <p>Amazon、Google 不是没有类似的探索，但用户接受度并不高，主要是因为这些设备笨重又不智能；步步紧逼的老对手三星，也已经宣布了今年正式发布家用机器人，外观同样主打「可爱风」。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fe8372f7273b40a198fdff3302992695@000000_oswg32770oswg1024oswg683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">三星将于今年发布智能家用机器人 Ballie&nbsp;</p>
  <p>苹果这次能不能再次成功「后发制人」的问题，只有时间能作答，但至少 ELEGNT 让我久违地感觉一个苹果产品 <strong>「非常有趣」</strong>。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_39882456c0f449fca50451264ac66391@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&amp;mid=2652396195&amp;idx=1&amp;sn=a8784ca45776b2a107026a224d786886&amp;chksm=9ac149f833c00485a271c39d469787ceac1e552fa2e8b97ae45c999dad1dc5630babb5d454ce&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“爱范儿”（ID：ifanr）</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156473943300872</id>
            <title>免费功能卷翻付费版ChatGPT，欧洲AI新贵叫板OpenAI</title>
            <link>https://www.36kr.com/p/3156473943300872</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156473943300872</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:55:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Le Chat, Mistral AI, 闪电回答, 代码解释器  
<br><br>  
总结: Mistral AI推出了全新升级的AI助手Le Chat，支持iOS和Android，并引入了“闪电回答”功能，响应速度可达每秒1000字。Le Chat还具备代码解释器、图像生成、高级文档分析等多项功能，且大部分功能免费提供。与其他AI助手相比，Le Chat在速度和功能上力求竞争，未来还将推出企业版。用户可以通过Le Chat进行个性化学习和目标跟踪，提升使用体验。 </div>
                        <hr>
                    
                    <p>“欧洲OpenAI”<strong>Mistral AI</strong>有新动作了！</p>
  <p><strong>Le Chat</strong>（法语“猫”）<strong>全新升级</strong>，官方自称它是“您生活和工作的终极AI助手”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3f8b17c1daf84b6b9be421edb8e159ef@5888275_oswg172265oswg1080oswg794_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从今天开始，Le Chat上线移动端，<strong>iOS和Android都支持</strong>，不久也将对企业私有基础设施开放。</p>
  <p>功能方面，Le Chat升级主打极速响应，Mistral AI开发者关系主管原话是这样婶儿的：</p>
  <blockquote>
   <p>Le Chat的推理、反思和响应速度超过任何其它聊天助手，可达每秒~1000words。</p>
  </blockquote>
  <p>这个功能被命名为“<strong>闪电回答</strong>”（Flash Answers）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7b73275383894adfb9e1ad4af9754330@5888275_oswg199720oswg1080oswg381_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_47567994c6814735ba28b83c809c8be6@5888275_oswg75794oswg1026oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有多快？</p>
  <p>来看Le Chat与Claude、ChatGPT的对比，同样是用Python编写贪吃蛇游戏，Le Chat刚开始就结束，速度达1100tok/s，Claude速度120tok/s，ChatGPT为85tok/s。</p>
  <p>除了速度快，Le Chat还引入了<strong>代码解释器</strong>功能，加上原有的图像生成、高级文档与图像分析、网页搜索、Canvas等，Mistral AI势要和ChatGPT、Claude等卷到底。</p>
  <p>要知道，Canvas等功能在ChatGPT那儿是要付费的，而Le Chat直接免费就能玩，包括“闪电回答”也是免费的。</p>
  <p>而付费版在免费版的功能基础上，外加不限量访问最高性能模型和网页浏览、可选择不与Mistral AI共享数据等权限。Mistral AI表示还将推出私有预览的企业版（Enterprise）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e118db2eace5479f9f66040d39f7cf25@5888275_oswg248250oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这波操作把网友看懵:</p>
  <blockquote>
   <p>不明白你们为什么要和ChatGPT/Claude竞争，很烧钱，不是吗？</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4140813507ce49c88dc546fe9da31ff6@5888275_oswg96794oswg1080oswg197_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网友评论区底下直呼：</p>
  <blockquote>
   <p>还需要MacOS app～</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_64ae19dc5c1d4370bc857be9344d09fd@5888275_oswg72517oswg1080oswg228_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <blockquote>
   <p>AI公司一个周内互相超越。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_01d3160769b24456af6f02b5f709e1af@5888275_oswg108378oswg1080oswg263_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>Le Chat功能一览</strong></h2>
  <p>再具体来看看Le Chat这波新增的代码解释器功能，Le Chat现已具备高级编码功能。</p>
  <p>它使用户能够执行沙箱代码、进行科学分析、创建可视化以及运行模拟。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4eedd0d263ad4e199ac08e1f7bf013f5@5888275_oswg44775oswg1080oswg480_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>比如prompt：</strong>你能解释一下泰勒级数近似的原理吗？给一些正弦函数的例子。</p>
  <p>Le Chat解释时会附带插图说明（Illustration）：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c847ad49734d4dddb7e82e8319789c32@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>支持验证代码：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_45d797eb5fcd4ddc805270caba54ef94@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用代码解释器分析CSV数据也不成问题：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_31ac9c4d31df49d287d2e5016cd476a2@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e847be28d4434c07a5ebfa58fdbc1b2a@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Le Chat图像生成功能由Flux Ultra驱动，支持画文字：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_82f64fb772af4f4482b34e07c1972501@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也有热门网页搜索功能，附带信息源：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8f0db68de8f24799bf0e8d54739de282@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>文档理解功能，对论文的理解可以精准到某张图，比如可以让它解释Figure 2的abcd都表示啥：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2f16b81e6b8941aa9f33b63bf94001e5@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此之外，官方还表示即将对所有用户开放“<strong>记忆</strong>”（Memories）功能，可选择性开启。</p>
  <p>它可以了解记住用户偏好，重新发现很久以前的对话，由此能提供个性化学习，跟踪用户实现目标的进度。</p>
  <p>比如它能记起你之前提到新年目标是在接下来的6个月内将体脂率从22%降至12%，然后帮你制定月度计划：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_cccf7d9ef0504b2190fe2aa0511cffaa@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>总之，ChatGPT有的，都得有。</p>
  <p>这就不得不提ChatGPT的会员专属高级界面Canvas功能，Le Chat免费，能够帮助用户从0-1进行创作。</p>
  <p>比如，计划未来四周内在巴黎向另一半求婚，已经买了戒指，但还没有计划其它的细节，请求创建一个详细的视觉时间线以保持事情的进展有序。</p>
  <p>Le Chat的规划是酱婶儿的，有单独界面展示生成的文稿，也有代码以及可视化。</p>
  <p>Le Chat还有一个功能是可以创建并在对话中@智能体，智能执行任务：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e8e7104dce0b4fd7b88f42c43c2fbb5c@5888275_oswg41290oswg1080oswg433_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>比如使用Le Chat智能体追踪个人财务，自动化安排日程：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3986ded4ba454590b24b9b756dd32e79@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>都能get可视化图表的那种：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_381d6cf1fde549069bf6442ea23485ef@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Le Chat全新升级后，网友们也已经开始玩起来了。</p>
  <p>有网友尝试一番过后反馈确实很快：</p>
  <p>感兴趣的童鞋可以亲自试试～</p>
  <p>参考链接：</p>
  <p>[1]https://x.com/sophiamyang/status/1887517050697842899</p>
  <p>[2]https://x.com/onetwoval/status/1887547069956845634</p>
  <p>[3]https://x.com/MistralAI/status/1887517520040448510</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/K_krY5nLog3dFaQFWIhXdw" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156478097889800</id>
            <title>杭州跑出50亿未来独角兽：年入8.12亿</title>
            <link>https://www.36kr.com/p/3156478097889800</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156478097889800</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:55:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 盘兴数智, IPO, SaaS, 在线营销  
<br><br>  
总结: 盘兴数智是一家专注于智能电商SaaS运营解决方案的公司，近期向港交所递交IPO申请。其前身为浙江独角兽企业盘石信息，现估值达到50.49亿元。公司主要产品包括线上营销解决方案和SaaS服务，线上营销解决方案在2024年前9个月占总收入的91%。随着内容电商平台的崛起，行业增长迅速，预计市场规模将持续扩大。盘兴数智通过两轮融资获得资本市场青睐，财务表现也显著提升。 </div>
                        <hr>
                    
                    <p>近日，来自浙江杭州的企业——盘兴数智向港交所递表，全力冲刺IPO。</p>
  <p>盘兴数智是一家专注于提供智能电商SaaS（软件即服务）运营解决方案的公司。它借助先进的技术和海量的数据，助力企业实现更高效的运营与管理，尤其在电商、制造业等领域。</p>
  <p>盘兴数智的前身是浙江独角兽企业盘石信息（估值110亿元）的RockySaaS事业部。如今，它的估值也达到50.49亿元。</p>
  <p>盘兴数智究竟是一家怎样神奇的公司呢？</p>
  <h2><strong>01</strong></h2>
  <p>浙江盘兴数智科技股份有限公司（以下简称“盘兴数智”）的创始人是田宁先生，出生在浙江湖州。</p>
  <p>1999年，还在浙江大学动物科学专业读大三的田宁和两位同学一起凑了10万元启动资金，创立了浙江大学盘石计算机网络技术有限公司，这也是浙江大学首家由在校大学生创办的企业，田宁也因此被冠以“浙江省大学生创业第一人”的称号。</p>
  <p>盘石计算机开始准备做教培咨询，但很快把钱烧完了，之后转向销售计算机硬件，还承接了省内多项电子政务项目，挣到了第一桶金。</p>
  <p>2004年，田宁创立了盘石信息，以精准、定向网络营销分析技术为基础，做企业网络营销服务提供商。</p>
  <p>2011年，云计算概念渐兴起，SaaS也开始进入大众视野。田宁带领盘石信息正式切入SaaS赛道。</p>
  <p>随后，盘石信息深入挖掘“盘石云”大数据，逐步形成了RockySaaS、Rockyplay、直播电商、智慧城市、数字科技、新消费和信用云七大业务板块，打造出了基于盘石大数据交互链接的商业生态平台 。</p>
  <p>2017年，为了更好地专注于RockySaaS（企业级SaaS服务）业务，盘石信息创建全资子公司盘兴数智，将该业务分立出来。</p>
  <p>2018年，盘兴数智调整业务布局，将发展重心聚焦于国内SaaS市场。盘兴数智先后以127.13万元和261.76万元，收购了SCRM服务供货商杭州清柳和定制软件开发商北京远景，并实现控股。</p>
  <p>2021年，直播带货这一新兴业态爆火，盘兴数智成立天津禾越，进一步拓展在线营销业务，将业务范围延伸至抖音及快手的直播电子商务领域。</p>
  <p>至此，盘兴数智成功转型为一家提供在线营销解决方案、与办公室自动化系统及电子商务系统定制开发相关软件服务的供货商。</p>
  <p>在业务不断拓展的同时，盘兴数智获得资本市场的青睐。</p>
  <p>2021年和2024年，相继获得两轮融资，浙江大学教育基金会、南京景衍等纷纷斥资入股。经过这两轮融资，盘兴数智的估值达到了50.49亿元。</p>
  <h2><strong>02</strong></h2>
  <p>盘兴数智的主要产品包括线上营销解决方案和SaaS服务。</p>
  <p>其中，线上营销解决方案涵盖一站式服务、流量获取服务、直播电子商务服务等多个方面，主要作用是帮助客户获取线上流量、提升品牌曝光度，进而促进产品销售。2024年前9个月，该业务收入达到6.13亿元，占公司总收入的91%，成为公司营收的主要来源。</p>
  <p>而SaaS服务则包括云端软件供应、短讯服务、定制软件开发等，旨在为企业提供全方位的数字化运营支持。2024年前9个月，SaaS服务收入为5709万元，占比8.5%。</p>
  <p>在财务表现上，2022年，盘兴数智营收为4.91亿元，期内利润为667万元；到了2023年，营收跃升至8.12亿元，同比增长超过65%，期内利润也大幅增加至2516万元；2024年前9个月，营收达到6.73亿元，已超过2022年全年水平，上年同期营收为4.37亿元，同比增长54% ，期内利润为2201万元，上年同期为847万元。</p>
  <p>盘兴数智所处的赛道是在线营销和SaaS服务赛道，值得注意的是，内容电商平台（如抖音、快手）的崛起成为推动行业增长的重要因素。</p>
  <p>招股书称，这些平台凭借优质内容和强大的社交属性，吸引了大量消费者，具备良好的引流条件。内容电商平台的线上营销解决方案服务市场规模从2018年的36亿元增至2023年的1507亿元，复合年均增长率达到惊人的111.0%。预计到2028年，市场规模将达到5746亿元，复合年均增长率为30.7%。</p>
  <p>此外，随着去中心化电商平台在中国电子商务市场中的地位日益重要。去中心化电商平台的交易额从2018年的0.8万亿元增至2023年的4.1万亿元，复合年均增长率为38.7%。商家逐渐意识到在这些平台上发展终端客户和维护“私域流量”的重要性，这也进一步推动了对线上营销解决方案服务的需求。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI0NzAzNTUwMQ==&amp;mid=2652511929&amp;idx=3&amp;sn=94fd5c13208b02bd97e387088f0719ef&amp;chksm=f3f40ab8b1d22c8b15ef77799196251491d3fe2fd52a370dfb722624adfbc2a926ee2ebf7e54&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“铅笔道”（ID：pencilnews）</a>，作者：不说谎的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156482137135618</id>
            <title>历史分水岭：DeepSeek GitHub星数超越OpenAI，大佬揭秘仅用450美元训推理模型</title>
            <link>https://www.36kr.com/p/3156482137135618</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156482137135618</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:55:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, GitHub, 推理模型, 开源社区  
<br><br>  
总结: DeepSeek项目在GitHub上的Star数超越了OpenAI，成为开源AI历史上的里程碑。DeepSeek-V3的热度迅速上升，用户热情高涨，导致其暂停API充值。关于DeepSeek的谣言被专家辟谣，澄清了其与CUDA的关系及训练成本的误解。DeepSeek-R1和V3的发布将推动推理模型的发展，机器学习专家Sebastian Raschka对其方法论给予高度评价，并提出了提升LLM推理能力的四种方法。即使在预算有限的情况下，模型蒸馏和新方法如旅程学习也为推理模型的研究提供了新的可能性。 </div>
                        <hr>
                    
                    <p>刚刚，DeepSeek的GitHub星数，超越了OpenAI！V3的Star数，如今已经碾压OpenAI最热门的项目。机器学习大神的一篇硬核博文，直接帮我们揭秘了如何仅用450美元，训出一个推理模型。</p>
  <p>就在刚刚，历史性的一刻出现了。</p>
  <p>DeepSeek项目在GitHub平台上的Star数，已经超越了OpenAI。</p>
  <p>热度最高的DeepSeek-V3，Star数如今已达7.7万。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e8a7df8f5c3c403484be715a7d746a66@5888275_oswg184840oswg1080oswg473_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>做出这一发现的网友们，第一时间截下了图</p>
  <p>可以说，这是开源AI历史上的一个里程碑！</p>
  <p>而DeepSeek-R1，更是仅用了3周时间，就超越了「openai-cookbook」。</p>
  <p>前有App Store登顶，今有GitHub超越，网友们高呼：永远不要低估开源社区的力量！</p>
  <p>如今，DeepSeek的势头越来越猛。</p>
  <p>相信大家都发现，DeepSeek的服务器简直要爆了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_053e6c6e93c248e2861d79bf3b7a3240@5888275_oswg75551oswg1080oswg341_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>甚至就在昨天，DeepSeek还不得不官宣：暂停API充值。</p>
  <p>原因当然就是因为，用户的热情实在太火爆，服务器真扛不住了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a81723b15be24340b5a782944ce2dad5@5888275_oswg136953oswg1080oswg393_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最近，关于DeepSeek的一些流传甚广的说法，也纷纷有专家辟谣了。</p>
  <h2><strong>澄清一：DeepSeek绕过了CUDA架构</strong></h2>
  <p>其中一个广为流传的说法是DeepSeek绕过了CUDA。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_68a6354c1562472aa5e41c4d936cf5de@5888275_oswg204538oswg1080oswg406_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这源于DeepSeek的论文中提到，模型采用了PTX编程，通过这样的定制优化，让模型能更好地释放底层硬件的性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_84edc924446148a086440325365f478b@5888275_oswg374665oswg1080oswg369_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>「我们采用定制的PTX（并行线程执行）指令并自动调整通信块大小，这大大减少了L2缓存的使用和对其他SM的干扰」</p>
  <p>严谨来说，DeepSeek通过编写PTX解决了跨芯片通信瓶颈，虽然复杂，但降低了开销、提升了效率。</p>
  <p>本质上，PTX仍然是位于CUDA驱动层内部的一个组件，是英伟达CUDA编程模型的一部分，能将CUDA源代码（C/C++）转变为机器指令的一个中间阶段。</p>
  <p>在运行时，PTX会进一步被编译成在GPU上运行的最终机器码（SASS）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_85390a64b00b439694951c077dbf7dac@5888275_oswg156306oswg825oswg535_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而DeepSeek团队的聪明之处就在于，用这种方法能更好地实现对底层硬件的编程和调用。</p>
  <p>这种主动优化，无论在H800还是H100上都能提高通信互联效率。</p>
  <p>因此，DeepSeek仍然没有摆脱CUDA生态。</p>
  <h2><strong>澄清二：R1的训练成本，绝不仅仅是600万美元！</strong></h2>
  <p>而关于DeepSeek-R1的另一个谣言，就是R1的训练成本大约是600万美元。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_01462dbc311d4b7396caf1b6755e3b2d@5888275_oswg286936oswg1080oswg335_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之所以有这个说法，来源于DeepSeek-V3论文中的相关论述</p>
  <p>开发者大神Sebastian指出，很多人都混淆了DeepSeek-V3和DeepSeek-R1。（前者要早1个月）</p>
  <p>其中，DeepSeek-V3中宣称的550万美元，是基于GPU成本、GPU小时数、数据集规模和模型规模等估算出来的。</p>
  <p>但DeepSeek团队从没公开过R1确切的GPU小时数或开发成本，目前已有的任何成本估算都只是猜测。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f2b2cc61afaf41b59cdaf7a912f7e668@5888275_oswg67686oswg1080oswg429_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此之外，Stability AI前研究总监Tanishq Mathew Abraham也在最近的博文中指出，R1在V3基础上进行的强化学习，以及最终训练前团队的大量的小规模实验和消融研究都未包含在内。</p>
  <p>更何况还有研究者的薪资，据传已经跟OpenAI、Anthropic等顶级机构的薪资相当（高达100万美元）。</p>
  <h2><strong>V3和R1，开启推理模型大变局</strong></h2>
  <p>DeepSeek V3和R1发布后，将怎样搅动此后的LLM江湖？&nbsp;</p>
  <p>预算紧张的情况下，怎么开发推理模型？</p>
  <p>最近，机器学习大神Sebastian Raschka的这篇长篇博文，为我们做出了硬核预测，并且破除了不少民间对DeepSeek的误解。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3d1da8e26cea4084abe346e6ac9622a0@5888275_oswg58375oswg1080oswg208_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Sebastian表示，很多人都来询问自己对DeepSeek-R1的看法。</p>
  <p>在他看来，这是一项了不起的成就。</p>
  <p>作为一名研究工程师，他非常欣赏那份详细的研究报告，它让自己对方法论有了更深入的了解。</p>
  <p>最令人着迷的收获之一，就是推理如何从纯强化学习行为中产生。</p>
  <p>甚至，DeepSeek是在MIT许可下开源模型的，比Meta的Llama模型限制更少，令人印象深刻。</p>
  <p>在本文中，Sebastian介绍了构建推理模型的四种方法，来提升LLM的推理能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c92b491b84474bffbcf8cb26a1df1a0b@5888275_oswg205805oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>图中总结了DeepSeek R1的训练流程。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3d7cab1b0df4446c8ded5f8dad94ead5@5888275_oswg229200oswg1080oswg862_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>（1）DeepSeek-R1-Zero：该模型基于2024年12月发布的DeepSeek-V3。研究团队采用RL进行训练，并使用了两种奖励类型。这种方式称为冷启动训练，因为它没有采用RLHF中的SFT步骤。</p>
  <p>（2）DeepSeek-R1：这是DeepSeek的旗舰推理模型，构建于DeepSeek-R1-Zero基础上。团队通过额外的SFT阶段和进一步的RL训练，对模型进行了优化。</p>
  <p>（3）DeepSeek-R1-Distill：利用前述步骤中生成的SFT数据，团队对Qwen和Llama模型进行了微调，以增强它们的推理能力。尽管不是传统意义上的蒸馏，但该过程是用DeepSeek-R1的输出，来训练较小的模型（Llama 8B和70B，Qwen 1.5B–30B）。</p>
  <h2><strong>构建推理模型的四种方法</strong></h2>
  <h3><strong>推理时扩展</strong></h3>
  <p>想要提升LLM的推理能力，或者是其他任何能力，有一种方法叫推理时扩展，就是在推理过程中增加计算资源，让输出的结果质量更高。&nbsp;</p>
  <p>人类在解决复杂问题时，如果思考时间更充裕，往往能给出更好的答案。</p>
  <p>有一种推理时扩展的简单方法，是巧妙的运用提示工程。思维链（CoT）提示法是一个经典例子，在处理复杂问题时，通常能得到更准确的结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3cfd8d03fbad47ca84b8ac017759e21e@5888275_oswg224303oswg1080oswg283_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一种推理时扩展的方法是使用投票和搜索策略。</p>
  <p>一个简单的例子是多数投票方法，让LLM生成多个答案，然后通过投票选出正确答案。</p>
  <p>同样，也可以使用束搜索（beam search）和其他搜索算法来生成更好的响应。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f898d6b3eefc44439d3fb3cd9df2602e@5888275_oswg297214oswg1080oswg620_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>推测OpenAI的o1和o3模型使用了推理时扩展。此外，o1和o3可能还运用了与DeepSeek R1类似的RL流程来训练。</p>
  <h3><strong>纯强化学习（RL）</strong></h3>
  <p>DeepSeek R1论文中的一个亮点是，推理行为可以通过纯强化学习（RL）产生。</p>
  <p>通常在RL训练之前，会先进行SFT，但DeepSeek-R1-Zero完全通过RL训练，没有初始的SFT阶段。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_70a21bc16707423a9af0d27ba21bdcc6@5888275_oswg238015oswg1080oswg868_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepSeek-R1-Zero的一个关键区别是它跳过了SFT阶段。</p>
  <p>在奖励机制上，DeepSeek没有采用基于人类偏好的奖励模型，而是采用了准确性奖励和格式奖励。</p>
  <p>- 准确性奖励，是用LeetCode编译器来验证编程答案，并用确定性系统评估数学回答。</p>
  <p>- 格式奖励，则靠LLM评判器，保证回答符合预期格式，比如把推理步骤放在标签里。</p>
  <p>让人意外的是，靠这种方法，LLM就能发展出基本的推理能力。</p>
  <p>研究人员观察到「顿悟时刻」：模型开始在回答中生成推理过程，即使没有专门训练它这么做。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2a2d0fbf74ae4788aff30fde35a5454f@5888275_oswg295140oswg1080oswg628_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>尽管R1-Zero并不是性能最优的推理模型，但它通过生成中间的思考步骤展示了推理能力。这证明用纯强化学习（RL）开发推理模型是可行的。</p>
  <h3><strong>监督微调和强化学习（SFT+RL）</strong></h3>
  <p>旗舰模型DeepSeek-R1通过结合额外的SFT和RL，提升了模型的推理表现。</p>
  <p>在RL之前进行SFT是常见的做法，标准的RLHF流程就是如此。OpenAI的o1模型很可能也是用类似方法开发的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_90ff3b4a341e4f859659b8f8d08148fe@5888275_oswg214162oswg1080oswg858_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如图所示，团队用DeepSeek-R1-Zero生成了冷启动SFT数据。通过指令微调训练模型，接着又进行了一轮RL。</p>
  <p>在这一轮RL中，保留了DeepSeek-R1-Zero的准确性奖励和格式奖励，还新增了一致性奖励，来避免语言混杂。</p>
  <p>RL结束后，又开始新一轮SFT数据收集。在这个阶段，用最新的模型生成了60万条CoT SFT示例，同时用DeepSeek-V3基础模型创建了另外20万条SFT示例。</p>
  <p>上述样本随后被用于另一轮RL训练。在这个阶段，对于数学和编程问题，还是用基于规则的方法进行准确性奖励。对于其他类型的问题，则用人类偏好标签来评判。</p>
  <p>经过多轮训练，DeepSeek-R1的性能有了显著提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b668665104594be8a944dd3c32454a8f@5888275_oswg184916oswg1080oswg340_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>纯监督微调（SFT）和蒸馏</strong></h3>
  <p>到目前为止，已经介绍了三种用于改进LLM推理能力的方法，最后是模型「蒸馏」。</p>
  <p>这里「蒸馏」是指用较大LLM生成的数据集对较小的LLM（如Llama 8B和70B以及Qwen 2.5模型，范围从0.5B到32B）进行指令微调。</p>
  <p>实际上，这个蒸馏过程中的SFT数据集，和之前用来训练DeepSeek-R1的数据集是一样的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_89a37e3671ed468cb93df4a7c0fd4a6b@5888275_oswg228206oswg1080oswg862_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为什么开发蒸馏模型？可能有两个关键原因：</p>
  <p>1 &nbsp;<strong>较小的模型更高效。</strong>小模型运行成本更低，还能在配置较低的硬件上运行。对研究人员来说很有吸引力。</p>
  <p>2 &nbsp;<strong>纯SFT的案例研究。</strong>这些模型展示了在没有RL的情况下，单纯靠SFT能把模型优化到什么程度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_69019d62c1754baa86755ba7d8b8fb25@5888275_oswg376470oswg1080oswg558_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>团队将DeepSeek-R1-Zero中的纯RL方法直接应用于Qwen-32B。</p>
  <p>结果表明，对于较小的模型，蒸馏远比纯RL更有效。</p>
  <p>仅靠RL可能不足以让小模型具备强大的推理能力，在高质量推理数据上进行SFT，或许是对小模型更有效的策略。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0e47ed19b45f40ea9d1aba31e32b24d0@5888275_oswg161520oswg1080oswg304_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接下来一个有趣的方向是把RL+SFT和推理时扩展结合起来，OpenAI的o1很有可能是这样做的，只不过它可能基于一个比DeepSeek-R1更弱的基础模型。</p>
  <h2><strong>R1和o1相比如何？</strong></h2>
  <p>Sebastian认为，DeepSeek-R1和OpenAI o1大致在同一水平。&nbsp;</p>
  <p>不过引人注目的一点是，DeepSeek-R1在推理时间上更高效。</p>
  <p>这就揭示了二者的区别：DeepSeek可能在训练过程中投入了更多，而OpenAI更依赖于o1的推理时扩展。</p>
  <p>而很难直接比较两个模型的难点，就在于OpenAI并没有披露太多关于o1的信息。</p>
  <p>现在关于o1，还有很多未解之谜。</p>
  <p>比如，o1也是一个MoE吗？它究竟有多大？</p>
  <p>或许，o1只是GPT-4o的一个略微改进版本，加上最小量的强化学习和微调，仅在推理时进行大规模scaling？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4eeb194c75d54f749af0ad10494c1a25@5888275_oswg64875oswg1080oswg217_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不了解这些细节，是很难直接比较的。</p>
  <h2><strong>预算只有几十万美元，能开发推理模型吗</strong></h2>
  <p>不过，想开发一个DeepSeek-R1这样的推理模型，哪怕是基于开放权重的基础模型，也可能需要几十万美元甚至更多资金。&nbsp;</p>
  <p>这对预算有限的研究人员或工程师来说，实在是望而却步。</p>
  <p>好消息是：蒸馏能开辟新路径！</p>
  <p>模型蒸馏提供了一个更具成本效益的替代方案。</p>
  <p>DeepSeek团队的R1蒸馏模型证明了这一点，尽管这些模型比DeepSeek-R1小得多，推理表现却强得惊人。</p>
  <p>不过，这种方法也不是完全没有成本。他们的蒸馏过程用了80万条SFT样本，这需要大量的计算资源。</p>
  <p>有趣的是，就在DeepSeek-R1发布的前几天，关于Sky-T1的文章中，一个团队用1.7万条SFT样本，就训练出了一个32B参数的开放权重模型。</p>
  <p>总成本仅有450美元，甚至比大多数人AI会议的注册费还低。</p>
  <p>Sky-T1的表现和o1大致相当，考虑到它的训练成本，着实令人惊叹。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_91a6dde7299f453fada01720ef6e0e90@5888275_oswg139899oswg1080oswg451_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">项目链接：https://novasky-ai.github.io/posts/sky-t1/</p>
  <h3><strong>预算有限的纯强化学习：TinyZero</strong></h3>
  <p>TinyZero是3B参数的模型，它借鉴了DeepSeek-R1-Zero的方法，其训练成本不到30美元。</p>
  <p>令人意外的是，尽管只有3B参数，TinyZero仍展现出一些突现的自我验证能力，这证明了小模型通过纯RL也能产生推理能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_92dea5f6ffb648b7a16ccfb9c4a38f3d@5888275_oswg593621oswg1080oswg664_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这两个项目表明，即使预算有限，也可以进行有趣的推理模型研究。</p>
  <p>两者都借鉴了DeepSeek-R1的方法，一种聚焦于纯RL（TinyZero），另一种聚焦于纯SFT（Sky-T1）。</p>
  <h3><strong>超越传统SFT：旅程学习</strong></h3>
  <p>旅程学习被视作捷径学习的替代方案。捷径学习是传统的指令微调方法，模型仅通过正确的解题路径来训练。</p>
  <p>旅程学习不仅包括正确的解题路径，还包括错误的解题路径，让模型从错误中学习。</p>
  <p>这种方法和TinyZero在纯RL训练中展现的自我验证能力有相通之处，不过它完全依靠SFT来优化模型。让模型接触错误推理路径及修正过程。</p>
  <p>旅程学习或许有助于加强自我纠错能力，提升推理模型的可靠性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e8ee1b12653c454386ba6bf5c94b1afd@5888275_oswg215255oswg1080oswg524_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文链接：https://arxiv.org/abs/2410.18982</p>
  <p>这一方向对于未来的研究极具吸引力，特别是在低预算的推理模型开发场景中，RL方法可能由于计算成本过高而难以落地。</p>
  <p>当前在推理模型领域正有诸多有趣的研究，Sebastian充满期待地表示：相信在未来几个月，还会看到更多令人兴奋的成果！</p>
  <p>参考资料：&nbsp;</p>
  <p>https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&nbsp;</p>
  <p>https://www.tanishq.ai/blog/posts/deepseek-delusions.html&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/RpkiXldGPnoR6GJaujYbgg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156464642382600</id>
            <title>从CES到春晚舞台 京东热卖的智能机器人都有哪些黑科技？</title>
            <link>https://www.36kr.com/p/3156464642382600</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156464642382600</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:42:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人形机器人, 智能产品, 消费者需求, AI技术  
<br><br>  
总结: 2025年，京东通过“人机数码3C BOT奇遇季”活动，展示了多款人形机器人和智能产品，满足消费者在生活、工作和学习中的需求。活动期间，京东与多家科技品牌合作，推出了教育陪伴、安全守护和效率提升等功能的机器人，帮助消费者解决实际问题。此外，京东还提供了AI相关图书，帮助消费者了解机器人技术。未来，京东将继续关注用户需求，深化与机器人品牌的合作，推出更多智能产品。 </div>
                        <hr>
                    
                    <p>从CES 2025的热门焦点，到春晚舞台C位，再到跳起《APT》、成为火遍全网的表情包，2025年的开年阶段，包括宇树科技等品牌在内的人形机器人彻底出圈。京东同步开启了“人机数码3C BOT奇遇季”活动，携手前沿科技品牌带来了诸多智能机器人产品，可满足消费者生活、工作、学习等诸多场景中的使用需求，消费者打开京东搜“3C数码机器人”或“春晚同品牌机器人”即可进入活动会场浏览下单。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_25b0a83c93da4016ae39107b5c0e576d@1267484143_oswg272545oswg456oswg367_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>京东一早便关注到机器人的广泛应用场景，并提前布局，陆续引入了包括宇树科技、蔚蓝科技、时空壶、云深处等品牌在内的多款机器人产品。值得一提的是，在CES 2025期间，京东采销曾深入展会现场，与宇树科技的Unitree G1、Unitree H两款人形机器人，元萝卜的AI下棋机器人，云深处科技的绝影X30 Pro、Lite 3两款智能四足仿生机器人等深度互动，为消费者展现了智能机器人各种令人震撼的灵活表现，并第一时间将智能机器人新品上线，为用户带来全新的科技体验。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1d011b5968794edd8813c51bac19a418@1267484143_oswg980715oswg1175oswg880_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p>如今智能机器人都有哪些种类，它们分别都具备何种功能呢？本次京东上线的人机数码3C BOT奇遇季活动，不仅汇聚了海量智能机器人产品，也针对许多消费者的疑问进行了详细科普。其中，教育陪伴机器人能根据孩子的学习进度和兴趣推荐适合的学习内容，激发孩子学习兴趣；安全守护机器人可以充当家庭的安全卫士，通过摄像头进行远程监控，让消费者随时随地了解家中的安全情况；效率提升机器人可以自动完成拖地、擦窗、烹饪、用户指引等多种工作，让消费者能从这些工作中脱离出来，更高效地完成生活工作目标。</p>
  <p>对于不了解机器人产品的消费者，京东还上线了学习AI专区，提供了多种多样AI相关的图书产品，帮助消费者解锁AI机器人从入门操作到核心技术的完整知识链。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5c60b70a3315428da337fada0b4883b9@1267484143_oswg450564oswg990oswg436_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>具体到产品层面，宇树Go2-Pro长续航机器狗在GPT大模型加持和大规模的AI模拟训练基础上，能帮助孩子在人文历史、算术猜谜、知识问答等多种方面有所成长，简单易上手的图形化编程功能还能率先开发孩子的创新意识。在此前京东3C数码采销直播间“神奇红马甲探展CES”72小时不间断直播中，消费者跟着京东采销，云观看到了Go2机器人上下楼梯、跳跃、倒立等高难度动作展现，不少消费者在直播间留言感叹“太神奇了”。此外，蔚蓝阿尔法机器狗、大疆DJI机甲大师、可立宝Loona机器狗等多款产品也在教育陪伴方面有着出色表现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6b9020bbb23247369fb8df9b6b4b33b7@1267484143_oswg238986oswg472oswg910_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>随着消费需求愈加多元化，如今消费者对安全守护的需求覆盖了宠物、儿童、老人等多个群体，活动会场中的enabot一诺宠物陪伴机、PICKFUNAI看宠小助手、星空大白AI定制机器人、enabot EBO SE全屋移动监控摄像头、萤石RK2Pro智能机器人等产品能满足消费者对于儿童、老人、宠物的看护需求，更精准地实现安全守护。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e0558bacf6c44aa2b9fd1afd3015e248@1267484143_oswg361349oswg514oswg975_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>在效率提升方面，科梦奇迎宾讲解接待机器人、欧克森全自动双向喷水擦窗机器人、添可智能料理机、乐天派智能桌面机器人、科沃斯擦窗机器人、广库全自动写字机器人能帮助消费者完成客户或用户接待、日常家务、烹饪、撰写材料等基础工作，让消费者能以更高的效率投入更重要的工作中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_412900040a43417f851fb2563c6ebe7d@1267484143_oswg348657oswg576oswg1101_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>除上述新款智能机器人外，消费者还可在京东购买《AI时代：弯道超车新思维》、《奇点更近》等AI相关图书产品，更深入地了解AI机器人科学原理和知识链路，从机器人小白成为机器人高手。</p>
  <p>从CES 2025京东采销探展，再到上线人机数码3C BOT奇遇季活动，京东始终关注用户的消费需求和行业的前沿发展，第一时间为消费者带来科技新品，让每位来京东的消费者都能更快尝鲜自己心仪的机器人产品。未来，京东也将持续深化与各大机器人品牌的合作，为消费者带来更多更智能、更灵活、更全能的机器人产品。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156419972660742</id>
            <title>大厂“拥抱”Deepseek，打不过就加入？</title>
            <link>https://www.36kr.com/p/3156419972660742</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156419972660742</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:22:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, Deepseek, 开源, 技术创新  
<br><br>  
总结: 文章讨论了人工智能在春节期间成为社交热点，特别是Deepseek的崛起。Deepseek以低成本和高性能颠覆了传统大模型行业，吸引了国内外科技巨头的关注。其开源策略和创新的模型训练方法使其在技术上取得了显著突破，成为行业的“变量”。尽管面临安全性和政策争议，Deepseek的出现为大模型行业带来了新的机遇和挑战，推动了整个生态的发展。 </div>
                        <hr>
                    
                    <p>这个春节，人工智能无疑成为了社交话题的C位，前有人形机器人在春晚跳扭秧歌而出圈，后有“Deepseek”的强势崛起。</p>
  <p>网友们疯狂涌入Deepseek，有人找Deepseek算命，有人问Deepseek怎样才能暴富，还有科技金融行业的打工人，年还没有过完，就得忙着加班写研报、测试模型。</p>
  <p>但海外市场对此却态度微妙，OpenAI一度宣称Deepseek“偷窃”了其“技术成果”，但一转头，微软、英伟达等大厂都宣布在自家产品中接入Deepseek，OpenAI CEO山姆·奥特曼更表示Deepseek的R1模型“令人印象深刻”。</p>
  <p>国内的互联网巨头们也没有错失这波Deepseek的热度，2月6日，有道正式宣布全面拥抱DeepSeek-R1。此外，Hi Echo、有道智云、QAnything等产品也将全面接入DeepSeek的推理能力，并于近日陆续升级。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e851d5d2e4784fdf96f8590c8e5f2166@5333136_oswg375561oswg731oswg1016_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一时之间，这场AI大模型的技术迭代，不知不觉就演变成全球科技行业的现象级事件，Deepseek也被视为引领大模型行业从“大而全”到“小而美”的全新变量。</p>
  <p>但热闹过后，Deepseek还需要回答更多的新问题，全球大模型行业该如何抓住“变革的火花”，或许才是接下来的关键。</p>
  <h2><strong>01 三大变量引爆Deepseek</strong></h2>
  <p>在普通用户看来，Deepseek是在此次中美大模型技术之争中“一战成名”，但更早之前，Deepseek便已经因为“价格便宜”而被AI圈广泛关注。</p>
  <p>去年中，国内大模型行业大打“价格战”，但第一个“挑起战火”的并非阿里、百度等大厂，而是Deepseek，彼时其新推出的DeepSeek-V2价格仅为 GPT-4-Turbo 的百分之一左右。</p>
  <p>此次“降价”也让Deepseek被冠以“AI界拼多多”之称，但相较于大厂们的“以价换市场”的惯常做法，Deepseek对于“降价”并没有太多压力，因为其降价之后也仍有利润。</p>
  <p>事实上，这才是Deepseek能够震惊全球科技界的主要原因，其能够以更低的成本换来更高的性能，颠覆了过去大模型行业依靠堆显卡、堆资本来发展AI的“Scaling law”。</p>
  <p>这是因为Deepseek的模型训练路径不同于传统通用大模型，以ChatGPT为代表的传统AI，主要采用监督微调（简称 SFT）作为大模型训练的核心环节，即通过人工标注数据进行监督训练，再结合强化学习进行优化，本质上大模型并不会思考，只是通过模仿人类思维方式来提升推理能力。</p>
  <p>但在1月底发布的Deepseek-R1-Zero却颠覆了这一规则，其对模型架构进行了全方位创新，通过单纯的强化学习（RL）训练实现推理能力。简单来说，SFT是人类生成数据，机器学习；而RL是机器生成数据，机器学习。</p>
  <p>除此以外，据每日财经新闻报道，DeepSeek创新性地同时使用了FP8、MLA（多头潜在注意力）和MoE（利用混合专家架构）三种技术。</p>
  <p>其中，相较于其他模型使用的MoE架构，DeepSeek-V3的更为精简有效，其就像是医院的“分诊制度”，可以将大模型拆分成多个“专家”，训练时分工协作，推理时根据任务分配给最适合的专家模块。据悉，Deepseek能够将无效训练从传统模型的90%降低至60%。</p>
  <p>在Deepseek-R1发布后，一位Meta员工在美国匿名职场社区teamblind上留言，称Deepseek最近的一系列动作让Meta的生成式AI团队陷入了恐慌。</p>
  <p>据这位员工爆料，“Meta一个负责AI项目的高管年薪拿出来，就足够训练Deepseek了”。据每日经济新闻报道，Deepseek R1的预训练费用只有557.6万美元，还不到OpenAI GPT-4o模型训练成本的十分之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8d92248ee8bc4fba9fc0d2f15654d91f@5333136_oswg268894oswg1108oswg838_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但从实际性能来看，Deepseek-R1已经能够比肩OpenAI-o1正式版，特别是在数学、代码、自然语言推理等任务上。</p>
  <p>在美国数学竞赛（AMC）以及全球顶级编程竞赛（codeforces）等权威评测中，DeepSeek-R1-Lite-Preview 模型已经大幅超越了 GPT-4o 等顶尖模型，有三项成绩还领先于 OpenAI o1-preview。</p>
  <p>除了“低成本、高算力”这一突破之外，Deepseek之所以在这个春节“燃起来”，还因为其竟然不是出自传统的大厂，而是一家量化基金公司。</p>
  <p>Deepseek成立于2023年12月，在此之前，其创始人梁文锋于2015年便成立了名为“幻方量化”的量化对冲基金，可以说Deepseek的前身其实是服务于量化交易的。</p>
  <p>这样的背景也为Deepseek增添了更多“看点”，比如梁文锋之所以不差钱，是因为其在量化交易上赚得风生水起，网友甚至戏称Deepseek的训练成本是来自于造空英伟达。</p>
  <p>还有背靠千亿量化基金的梁文锋，明明可以选择轻松躺赚，却选择投身到全球创新的浪潮里，他坦言“对AGI的好奇与探索比商业回报更具驱动力”，这种一往无前的“理想主义”，想让也让Deepseek的“故事”变得更加动人。</p>
  <h2><strong>02 大厂打不过就加入</strong></h2>
  <p>不过，技术上的逆袭，尚不足以彻底震惊科技界，真正引爆Deepseek的变量，其实是“开源”。据悉，Deepseek已经把模型架构和参数开源，在大模型公司普遍选择闭源的当下，训练数据的开源在业界少有先例。</p>
  <p>梁文锋曾在媒体采访中表示，“过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。我们的出发点不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。”</p>
  <p>从商业角度来看，“开源”是不是一个更佳的策略，尚难以下定论。毕竟训练模型需要成本，招揽用户也需要推广费用，从此前字节豆包大规模投放广告、kimi多次接受融资就可以看出，大模型公司有自己的难处。</p>
  <p>但对于中国大模型行业来说，或许正是梁文锋的“理想主义”，才让Deepseek能够成为颠覆行业格局的“变量”。</p>
  <p>一方面，开源将能吸引更多大厂和技术人才加入，通过共建共创让Deepseek变得更加强大，从而推动整个人工智能大模型生态的发展，形成一个全新的生态。</p>
  <p>梁文锋曾对媒体表示，公司未来不会像OpenAI一样选择从开源走向闭源，“我们认为先有一个强大的技术生态更重要” 。</p>
  <p>另一方面，对于以OpenAI为代表的竞争对手来说，这也是一个致命的打击。毕竟，当一个旗鼓相当的，还是免费的产品出现在消费者面前，大家难免就会进行比较，谁的性价比更高，谁的性能更优秀，都需要实打实的使用效果来验证，而不仅仅只是“吹泡沫”。</p>
  <p>而率先作出选择的，便是一众海外大厂，目前包括英伟达、英特尔、亚马逊、微软、AMD、等海外科技大厂，均宣布在自家产品中接入Deepseek。</p>
  <p>值得一提的是，欧美多国对于Deepseek的安全性、隐私问题依然存在质疑。美国多位官员表示正在对Deepseek开展国家安全调查，包括国防部、国会和NASA等部门均被要求禁用Deepseek。</p>
  <p>此外，据彭博社等媒体报道，微软还曾调查 OpenAI 技术输出的数据是否被中国的Deepseek团队以未经授权的方式获取，比如通过“蒸馏技术”非法获取其模型输出数据。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_881bc69f6d574b33ad204879ab0839cc@5333136_oswg280855oswg1108oswg1128_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但在这些争议尚未解决之前，大厂们显然已经迫不及待想要加入Deepseek生态，本质上还是基于“利益至上”的原则。</p>
  <p>据斯坦福大学计算机科学系和电子工程系副教授吴恩达表示，OpenAI - o1模型每百万输出token 的成本为60美元，而Deepseek-R1 则仅需 2.19 美元，这接近30倍的成本差距，相信大厂们也会算账。</p>
  <p>其次则是生态效应，吴恩达认为，“降价”+“开源”正在将基础模型层商品化，为应用开发者创造了巨大的机遇。尽早加入这一生态，让自家大模型与之相结合，也有望带来更多创新体验，“收拢”部分DeepSeek用户的需求。</p>
  <p>因此，除了海外大厂之外，诸如阿里云、百度云等国内大厂也开始集中接入Deepseek，在各自平台提供的适配服务，打不过就加入，才能共享创新红利。</p>
  <h2><strong>03 乘上Deepseek的东风</strong></h2>
  <p>事实上，在开春爆火的Deepseek，不仅为大模型行业带来了一阵“春风”，对于普通用户来说，也带来了更多新机会。</p>
  <p>第一批利用Deepseek搞钱的人已经出现了，跟彼时横空出世的ChatGPT一样，面对更加智能、更加高效的大模型，AI取代人类的焦虑感，再次成为收割用户的“武器”。</p>
  <p>社交平台上已经出现了不少“如何使用Deepseek进行XXX”的课程，面向社交媒体、电商、广告等不同行业的应用和变现。</p>
  <p>当然，学习新知识肯定是没错的，但相较于被焦虑感“收割”，并沦为大V私域流量中的一员，大家不妨根据自己的实际工作和擅长内容，先上手试用一下Deepseek。</p>
  <p>目前来看，Deepseek在技术上确实有意想不到的突破，对于普通用户来说，其能够展示思维链全过程，更方便人类与AI交流，业内人士甚至称之为当前最好用的开源模型，但也不需要过度“神化”Deepseek。</p>
  <p>首先，从使用体验来看，Deepseek尚无法承受蜂拥而至的流量。其实，Deepseek在年前便已经小范围的“爆火”，其当时尚能同时使用深度思考和联网功能，输出的文章框架和成文确实比较惊艳。</p>
  <p>但随着使用者不断增多，目前Deepseek已经关闭了联网功能，整理输出质量有较大的下降，且大部分时间Deepseek都呈现“服务繁忙”的状态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b1c84842499e49c093f6dc24b96b62d4@5333136_oswg92743oswg1108oswg768_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>虽然梁文锋曾表示“商业化”不是当前首要考虑的问题，但按私募基金的体量来推算“幻方”的资金规模，千亿规模不等于千亿资金体量，“幻方”只是在千亿规模上收取管理费，其跟大厂之间的资金差距还是很大的。</p>
  <p>但要继续维持C端的使用体验，Deepseek必然需要烧钱，后续如何补充资金，还是调整使用模式，梁文锋都需要提出更明确的打法。</p>
  <p>其次，目前Deepseek在图文、视频方面的能力是缺失的，现阶段要说Deepseek能够与头部闭源模型直接打擂台，恐怕还为时尚早。</p>
  <p>不过，其发展也给Open AI，以及更多垂直模型带来了压力，相信将能在一定程度上推动整个大模型生态的发展。</p>
  <p>最后，Deepseek依然面临着政策、数据安全等争议，要走向全球依然是漫漫长路；此外，其在计算资源与算力方面依然受限，这意味着国产硬件还需要继续努力，才能支撑软件的不断创新。</p>
  <p>当然，对于全球大模型行业来说，有竞争才有动力，就像智能手机行业一样，参与者多了，行业盘子就会越来越多，也才有机会爆发出更多的机会。</p>
  <p>Deepseek的出现就像是国内大模型行业的一点“火花”，既是思维碰撞的突破，也是灵感乍现的瞬间。接下来，相信还需要国内大模型行业在软硬件方面的持续创新，才能抓住这一机遇，让中国科技行业能够从“跟随者”向“引领者”进发。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/EKAaKXY2oPJ-cqnDUuNGNg" rel="noopener noreferrer nofollow" target="_blank">“新媒科技评论”</a>，作者：新媒编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156289666964231</id>
            <title>DeepSeek 在人工智能全球化战略下需要面对的几个难题</title>
            <link>https://www.36kr.com/p/3156289666964231</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156289666964231</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:21:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据隐私, 地缘政治, 市场信任, 可持续性  
<br><br>  
总结: DeepSeek自2024年底以来成为生成式人工智能的焦点，但面临多重挑战。首先，数据隐私问题可能影响其国际客户的信任，尤其是在严格的法律环境中。其次，地缘政治紧张局势可能限制其获取资源和市场扩展。市场认知方面，DeepSeek需克服低成本模式带来的信任问题。长期维持低价的可持续性也存在风险，可能影响其研发和服务质量。此外，竞争激烈的市场环境和复杂的监管框架也给DeepSeek带来压力。 </div>
                        <hr>
                    
                    <p>自 2024 年底以来，DeepSeek 已成为生成式人工智能的焦点，并发布了迄今为止最出色的两个模型 DeepSeek-V3 和 DeepSeek-R1。OpenAI 作为生成式人工智能的代表，已退居谷歌、Facebook 等其他巨头的后方。</p>
  <p>但我认为 DeepSeek应考虑应对以下问题实现全球化战略：</p>
  <h2><strong>数据隐私问题</strong></h2>
  <p>DeepSeek 是一家中国公司，在数据隐私方面可能会面临越来越多的质疑，尤其是在处理敏感信息时。对用户数据如何处理、存储以及可能与政府实体共享的担忧可能会阻碍国际客户。</p>
  <p>在数据隐私法严格的地区，例如欧盟（GDPR）或美国，DeepSeek 可能会在确保合规性方面遇到挑战。</p>
  <p>如果客户认为他们的数据可能被未经授权的一方或政府访问，他们可能会选择避免使用 DeepSeek 的服务，从而限制其市场范围。</p>
  <h2><strong>地缘政治问题</strong></h2>
  <p>DeepSeek 的运营<strong>环境对地缘政治极为敏感。</strong>由于中国与美国和欧盟等其他主要科技市场之间的紧张关系持续存在，DeepSeek 的运营可能会受到贸易限制、关税或制裁的阻碍。</p>
  <p>例如，如果美国或欧盟实施限制获取先进计算硬件的法规，或限制关键技术的出口，DeepSeek 可能难以获取扩大业务规模所需的资源。</p>
  <p>此外，各国可能会基于国家安全考虑阻止或监管 DeepSeek 服务的使用，从而影响其全球扩张的能力。</p>
  <h2><strong>市场认知和信任</strong></h2>
  <p>尽管 DeepSeek 提供具有成本效益的解决方案，但它可能难以获得与 OpenAI 和 Google 等更成熟的公司同等程度的信任。潜在客户可能会对提供明显更便宜服务的公司持怀疑态度，认为其质量可能较低或可靠性较低。</p>
  <p>打造强大的品牌并赢得客户信任可能会很困难，特别是如果 DeepSeek 被视为“低预算”选择而不是创新领导者的话。</p>
  <h2><strong>低成本模式的可持续性</strong></h2>
  <p>DeepSeek 的商业模式大大削弱了 OpenAI 等竞争对手，吸引了人们的注意并占据了市场份额。然而，<strong>长期维持如此低的价格可能具有挑战性。</strong></p>
  <p>开发、维护和改进 AI 模型的成本非常高昂，需要对研究、人才和计算资源进行投资。<strong>为了保持低价，DeepSeek 需要不断寻找降低成本的方法，</strong>但随着公司规模的扩大，这种方法可能难以为继。</p>
  <p><strong>另外，其低成本模式还</strong>存在无法产生足够收入来资助进一步发展的风险，这可能迫使 DeepSeek 提高价格或降低服务质量以保持盈利。</p>
  <p>如果竞争对手已经拥有更强大的财力支持，在产品供应方面表现出色或设法降低成本，那么 DeepSeek 可能难以参与竞争。</p>
  <h2><strong>竞争市场动态</strong></h2>
  <p>人工智能领域挤满了主要参与者，包括 OpenAI、Google DeepMind 和 Microsoft。随着越来越多的公司进入生成式人工智能领域，DeepSeek 可能会发现很难脱颖而出或保持竞争优势。</p>
  <p>虽然 DeepSeek 最初凭借低成本定价策略取得了成功，但许多 AI 公司正在大力投资研发和云基础设施。这些竞争对手在模型准确率和功能集方面都可能超越 DeepSeek。</p>
  <p>如果 DeepSeek 未能跟上创新的步伐，或者无法找到大幅扩展其技术的方法，其市场份额可能会被更大、更成熟的公司抢走。</p>
  <h2><strong>监管挑战：</strong></h2>
  <p>在多个国家开展业务需要遵守各种复杂的监管框架。特别是，人工智能是一个受到严格审查的行业，其公平性、透明度和问责制备受关注。</p>
  <p>在某些司法管辖区，规范人工智能部署的新法律（例如欧盟的《人工智能法案》）可能会迫使 DeepSeek 修改或限制其产品，从而使得在遵守这些法规的同时保持有竞争力的价格变得更加困难。</p>
  <h2><strong>缺乏多样化</strong></h2>
  <p>DeepSeek 专注于提供低成本的 AI 解决方案，这可能会限制其收入来源多元化的能力。该公司可能会过度依赖某个细分市场（例如，生成式 AI 服务），而错失其他领域的增长机会。</p>
  <p>如果对生成式人工智能的需求放缓或面临竞争加剧，DeepSeek 可能会因缺乏明确的多元化计划而陷入困境。</p>
  <h2><strong>可扩展性问题</strong></h2>
  <p>尽管 DeepSeek 已经开发出高效的模型，但将其扩展到更广泛的企业级应用可能会带来挑战。AI 模型需要强大的计算能力才能大规模运行，而 DeepSeek 在服务大型客户或处理复杂的实时数据时可能难以保持成本效益。</p>
  <p>如果 DeepSeek 无法在不产生难以承受的成本的情况下有效扩展其基础设施，其业务可能会面临巨大的财务压力。</p>
  <h2><strong>免费的可持续</strong></h2>
  <p>大多数中国人工智能产品/模型，无论是 Kling AI 还是 MiniMax，都是开始免费提供服务，然后收取高额费用。</p>
  <p>因此看起来 DeepSeek 可能走上了同一条道路，因为在消费者甚至企业硬件上运行 DeepSeek-V3 和 Deep-Seek-R1 是不可能的。</p>
  <p>因此，即使开源，对大多数 AI 供应商来说也可能没有多大用处，而且 DeepSeek 可能很快就会增加 API 成本。</p>
  <h2><strong>最后</strong></h2>
  <p>虽然 DeepSeek 在生成式人工智能领域确实掀起了波澜，但其长期可持续性仍是一个问题。地缘政治紧张局势、监管障碍和不可持续的低成本模式可能会严重挑战其增长轨迹。再加上建立信任、扩展基础设施和与老牌科技巨头竞争的复杂性，很明显 DeepSeek 未来面临着重大障碍。然而，这些只是我的观点，而且考虑到目前的情况，DeepSeek 应尽快加强应对措施的制定。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzIwOTIyMDE1NA==&amp;mid=2247502236&amp;idx=1&amp;sn=89e5f882fceca7a506809d2f5c49324a&amp;chksm=966f9f55b7e41de96ddabd81b81d5f15cc07599d60114ebdf64af35bc790f88e42689be099eb&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“数据驱动智能”（ID：Data_0101）</a>，作者：晓晓，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156393016842758</id>
            <title>DeepSeek引爆AI，国产GPU集体撑腰</title>
            <link>https://www.36kr.com/p/3156393016842758</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156393016842758</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:12:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, 人工智能, 开源模型, 国产芯片  
<br><br>  
总结: DeepSeek是一家专注于高性能、低成本AI模型的公司，其最新发布的DeepSeek-V3和DeepSeek-R1模型在AI领域引起了广泛关注。DeepSeek-V3采用6710亿参数的MoE架构，处理速度是前一版本的三倍，而DeepSeek-R1则适合轻量级部署。DeepSeek的优势在于其低成本和高效能，训练成本仅为GPT-4的二十分之一，同时支持开源和灵活部署，促进了技术共享。随着DeepSeek的成功，国产芯片公司也迎来了新的发展机遇，推动了国产AI芯片的市场应用和生态建设。 </div>
                        <hr>
                    
                    <p>近日，想必诸多用户都怀揣着这样的疑惑：我的手机为何频频推送关于DeepSeek的资讯？这 DeepSeek 究竟是什么？它又为何能在问世之际，就引发如此热烈的关注与轰动？</p>
  <p>DeepSeek，全称杭州深度求索人工智能基础技术研究有限公司，其起源于一家中国的对冲基金公司High-Flyer。2023年5月High-Flyer剥离出一个独立实体，也就是DeepSeek。这是一家致力于打造高性能、低成本的 AI 模型。它的目标是让 AI 技术更加普惠，让更多人能够用上强大的 AI 工具。</p>
  <h2><strong>DeepSeek-V3与DeepSeek-R1的核心差异</strong></h2>
  <p>去年12月26日，DeepSeek AI正式发布了其最新的大型语言模型DeepSeek-V3。这款开源模型采用了高达6710亿参数的MoE架构，每秒能够处理60个token，比V2快了3倍。一经发布，就在 AI 领域引起了轩然大波。</p>
  <p>时隔不足一个月，在今年1月20日，深度求索又正式发布推理大模型DeepSeek-R1。DeepSeek-R1的发布，再次震撼业界！</p>
  <p>1月27日，DeepSeek应用登顶苹果中国区和美国区应用商店免费App下载排行榜。1月31日，英伟达、亚马逊和微软这三家美国科技巨头，在同一天宣布接入DeepSeek-R1。</p>
  <p>关于DeepSeek-V3与DeepSeek-R1-Distill 蒸馏模型的区别：</p>
  <p><strong>DeepSeek-V3</strong></p>
  <p>适合复杂任务处理和高精度场景，如长文档分析、多模态推理、科研计算等。</p>
  <p>支持千卡级训练，满足超大规模集群分布式训练需求。</p>
  <p><strong>DeepSeek-R1-Distill 蒸馏模型</strong></p>
  <p>适合轻量级部署和资源受限场景，如边缘设备推理、中小企业快速验证 AI 应用。</p>
  <p>在显存和算力要求上更为灵活，适配入门级硬件 。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6be9495964914ca19ec7bd82c9894a35@000000_oswg88780oswg1080oswg430_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：Gitee AI</p>
  <p>近日，硅谷顶尖风险投资家、a16Z联合创始人Marc Andreessen发文引用SensorTower数据：目前DeepSeek日活用户数已经达到了ChatGPT的23%，并且应用每日下载量接近500万。</p>
  <p>2月5日，京东云宣布正式上线DeepSeek-R1和DeepSeek-V3模型，支持公有云在线部署、专混私有化实例部署两种模式。前几日，阿里云、百度智能云、华为云、腾讯云、火山引擎、天翼云已接入了DeepSeek模型。海外的亚马逊AWS、微软Azure等云巨头同样官宣支持。</p>
  <p>那么，DeepSeek究竟是以何种独特魅力，赢得了广大用户的青睐与喜爱呢？</p>
  <h2><strong>DeepSeek的两大优势</strong></h2>
  <p>市场热捧的产品，往往有个显著共性：能帮用户降本增效。这，同样是 DeepSeek 的优势所在。</p>
  <p><strong>首先在低成本与高效能方面</strong>，DeepSeek-V3的训练成本仅为557.6万美元（约为GPT-4的二十分之一），却能在逻辑推理、代码生成等任务中达到与GPT-4o、Claude-3.5-Sonnet相近的性能，甚至超越部分开源模型（如Llama-3.1-405B）。其技术核心在于算法优化（如MoE架构、动态学习率调度器）和数据效率提升，而非依赖算力堆叠。</p>
  <p>作为对比，GPT-5一次为期6个月的训练仅计算成本就高达约5亿美元。</p>
  <p><strong>其次，开源与灵活部署也是DeepSeek的突出优势之一。</strong>DeepSeek选择将模型权重开源，并公开训练细节，这为全球的AI研究者打开了一扇通往模型内部的大门，让他们能够深入了解模型的训练过程、所采用的算法以及遇到的问题和解决方案。</p>
  <p>360集团创始人周鸿祎指出，DeepSeek真正践行了开放的精神。与OpenAI等关闭模式平台相比，DeepSeek允许开发者利用其开源模型进行技术挖掘和创新，这是对技术共享理念的有力支持。OpenAI虽然以“开源”自居，但随着商业化的推进，越来越多地选择封闭式策略，这与其创立初衷背道而驰。</p>
  <p>此外，周鸿祎特别提到DeepSeek的模型蒸馏技术，他认为这是一种极具前瞻性的实践。在他看来，DeepSeek对模型蒸馏的开放态度，展示了其自信与无私。相较之下，OpenAI对用户蒸馏其模型的限制，显示出其对竞争对手的排斥和对自身优势的维护。</p>
  <h2><strong>DeepSeek所需的GPU，主要来源于英伟达</strong></h2>
  <p>早期对AI技术和硬件基础设施的战略投资，为DeepSeek的成功奠定了基础。</p>
  <p>据SemiAnalysis评估，DeepSeek拥有大约50,000个Hopper架构的GPU，其中包括10,000个H800和10,000个H100型号。此外，他们还订购了大量的H20型号GPU，这些GPU专为中国市场设计。尽管H800与H100具有相同的计算能力，但其网络带宽较低。H20是当前唯一对中国模型提供商可用的型号。这些GPU不仅用于DeepSeek，也服务于High-Flyer，地理上分散部署，支持交易、推理、训练和研究等多种任务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_10f38e4a222e48b9ae928b07e84b7282@000000_oswg249918oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>至于DeepSeek如何获得如此多数量的Hopper GPU。</p>
  <p>早在2021年High-Flyer就看好AI的发展潜力并果断投资购买了10,000个A100 GPU，用于大规模模型训练实验。这项战略决策后来被证明是非常成功的，为公司带来了显著的竞争优势。</p>
  <p>在1月25日新年前，AMD就官宣将DeepSeek-V3模型集成到了Instinct MI300X GPU上。</p>
  <p>随后在1月31日，AI芯片龙头英伟达也官宣其NVIDIA NIM微服务预览版对于DeepSeek-R1模型的支持。NIM微服务基于HGX H200系统，每秒能够处理3872个tokens。开发者们可以调用API进行测试和试验，该API后续会作为英伟达AI企业软件平台的一部分提供。</p>
  <p>同日，英特尔宣布DeepSeek能够在搭载酷睿处理器的AI PC上离线使用。在酷睿Ultra 200H（Arrow Lake H）平台上，DeepSeek-R1-1.5B模型能够本地离线运行，做翻译、做会议纪要、进行文档撰写等任务。</p>
  <p><strong>要知道DeepSeek 在算力芯片受限的不利因素下，达到OpenAI等顶级模型的水平，是国内AI生态级的突破。</strong>如今，随着 DeepSeek 这类模型的发展，对 GPU 需求持续攀升。国产 GPU 厂商也敏锐捕捉到这一机遇，正在积极进行适配工作。他们深知，适配成功不仅能助力 DeepSeek 等模型更好地发展，也能为自身打开更广阔的市场空间，提升国产 GPU 在 AI 领域的影响力。</p>
  <h2><strong>11大国产AI芯片公司，宣布适配DeepSeek</strong></h2>
  <p>仅在2月1日至2月7日这短短7天内，就有11家国产AI芯片公司宣布完成对 DeepSeek 的适配 。</p>
  <h3><strong>DeepSeek系列新模型正式上线昇腾社区</strong></h3>
  <p>2月1日，华为云宣布与硅基流动联合首发并上线基于华为云昇腾云服务的DeepSeek R1/V3推理服务。得益于自研推理加速引擎加持，该服务支持部署的DeepSeek模型可获得持平全球高端GPU部署模型的效果。</p>
  <p>2月5日，华为宣布，DeepSeek-R1、DeepSeek-V3、DeepSeek-V2、Janus-Pro于2月4日正式上线昇腾社区，支持一键获取DeepSeek系列模型，支持昇腾硬件平台上开箱即用，推理快速部署，带来更快、更高效、更便捷的AI开发和应用体验。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4335f38cdb9940459734d1912fe0c9ef@000000_oswg200014oswg830oswg564_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>摩尔线程实现对DeepSeek蒸馏模型推理服务的高效部署</strong></h3>
  <p>2月4日，摩尔线程发文称已快速实现对DeepSeek蒸馏模型推理服务的高效部署，旨在赋能更多开发者基于摩尔线程全功能GPU进行AI应用创新。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ba007f382df54daeb38e1286b566087d@000000_oswg239003oswg866oswg474_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，用户也可以基于MTT S80和MTT S4000进行DeepSeek-R1蒸馏模型的推理部署。</p>
  <p>通过DeepSeek提供的蒸馏模型，能够将大规模模型的能力迁移至更小、更高效的版本，在国产GPU上实现高性能推理。摩尔线程基于自研全功能GPU，通过开源与自研双引擎方案，快速实现了对DeepSeek蒸馏模型的推理服务部署，为用户和社区提供高质量服务。</p>
  <h3><strong>DeepSeek V3和R1模型完成海光DCU适配并正式上线</strong></h3>
  <p>2月4日晚间，海光信息宣布公司技术团队成功完成DeepSeek V3和R1模型与海光DCU（深度计算单元）的适配，并正式上线。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a6740696b09344418900b42258196c28@000000_oswg306384oswg875oswg1278_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepSeek V3和R1模型采用了Multi-Head Latent Attention（MLA）、DeepSeekMoE、多令牌预测、FP8混合精度训练等创新技术，显著提升了模型的训练效率和推理性能。</p>
  <p>DCU是海光信息推出的高性能GPGPU架构AI加速卡，致力于为行业客户提供自主可控的全精度通用AI加速计算解决方案。凭借卓越的算力性能和完备的软件生态，DCU已在科教、金融、医疗、政务、智算中心等多个领域实现规模化应用。</p>
  <p>随着海光等专注于 GPU 研发的公司纷纷表示已完成对 DeepSeek V3 的适配。从这一现象来看，DeepSeek 模型在业界或许正逐渐获得较高的认可度与通用性。</p>
  <p>那么，<strong>海光 DCU 的哪些硬件特性和架构设计使得它能够很好地支持 DeepSeek V3 和 R1 模型的高效运行？</strong></p>
  <p>有业内人士表示，海光DCU采用了GPGPU架构，从而保证在面对新型应用的时候具备极好的兼容性与适配性；同时DCU配套的软件栈也经过了多年的积累，相应软件生态成熟丰富，在与新模型、应用适配的时候具备完备的软件支撑能力。以上共同保障了对于DeepSeek V3/R1为代表的新模型能够提供高效的兼容与支撑能力。</p>
  <p>值得注意的是，海光本次适配并没有用到额外的中间层工具，依托现有DCU软件栈就可以实现快速的支撑。这主要得益于DCU的GPGPU架构通用性和自身对主流生态的良好兼容，从而大幅提升了大模型等人工智能应用的部署效率。</p>
  <h3><strong>天数智芯联合Gitee AI正式上线DeepSeek R1模型服务</strong></h3>
  <p>2月4日，天数智芯与 Gitee AI 联合发布消息，在双方的高效协作下，仅用时一天，便成功完成了与 DeepSeek R1 的适配工作，并且已正式上线多款大模型服务，其中包括 DeepSeek R1-Distill-Qwen-1.5B、DeepSeek R1-Distill-Qwen-7B、DeepSeek R1-Distill-Qwen-14B等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9101192f343d406f8b6de7014dbe3c7e@000000_oswg258702oswg744oswg484_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>Gitee AI与沐曦携手首发DeepSeek R1系列千问蒸馏模型</strong></h3>
  <p>2月2日，Gitee AI 正式推出了四个轻量级版本的 DeepSeek 模型，分别为 DeepSeek-R1-Distill-Qwen-1.5B、DeepSeek-R1-Distill-Qwen-7B、DeepSeek-R1-Distill-Qwen-14B 和 DeepSeek-R1-Distill-Qwen-32B。尤为引人注目的是，这些模型均部署在国产沐曦曦云 GPU 上。</p>
  <p>上文曾提到，与全尺寸 DeepSeek 模型相比，较小尺寸的 DeepSeek 蒸馏版本模型更适合企业内部实施部署，可以降低落地成本。</p>
  <p>同时，这次Deepseek R1 模型 + 沐曦曦云 GPU + Gitee AI 平台，更是实现了从芯片到平台，从算力到模型全国产研发。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4482b73eb5614ed1bd2cff8d4c19b763@000000_oswg172576oswg1080oswg445_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随后在2月5日 Gitee AI宣布再次将DeepSeek-V3满血版（671B）上线到平台上（满血版目前仅供大家体验用途）。这也是 Gitee AI 继全套千问蒸馏模型上线沐曦 GPU 卡之后的又一大的更新。</p>
  <h3><strong>壁仞AI算力平台上线DeepSeek R1蒸馏模型推理服务，支持云端体验</strong></h3>
  <p>2月5日，壁仞科技宣布，凭借自主研发的壁砺系列GPU产品出色的兼容性能，只用数个小时，就完成对DeepSeek R1全系列蒸馏模型的支持，涵盖从1.5B到70B各等级参数版本，包括LLaMA蒸馏模型和千问蒸馏模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8865a3cee48d4f5bae14dbd29329c8eb@000000_oswg74841oswg582oswg636_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，壁仞科技已构建起从底层硬件到模型服务的完整AI技术栈，可为中小企业和研究机构提供“芯片+模型”的端到端解决方案。</p>
  <h3><strong>云天励飞DeepEdge10已完成DeepSeek R1系列模型适配</strong></h3>
  <p>2月5日，云天励飞宣布，其芯片团队完成 DeepEdge10 “算力积木”芯片平台与DeepSeek-R1-Distill-Qwen-1.5B、DeepSeek-R1-Distill-Qwen-7B、DeepSeek-R1-Distill-Llama-8B大模型的适配，可以交付客户使用。DeepSeek-R1-Distill-Qwen-32B、DeepSeek-R1-Distill-Llama-70B大模型、DeepSeek V3/R1 671B MoE大模型也在有序适配中。适配完成后，DeepEdge10芯片平台将在端、边、云全面支持DeepSeek全系列模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8fd837d8085b4fed8b5f7e5c35aaddbc@000000_oswg140562oswg1074oswg380_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_27ed50ecaeca4d0a8135f2c90a47d7e1@000000_oswg81197oswg742oswg268_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepEdge10系列芯片是专门针对大模型时代打造的芯片，支持包括 Transformer 模型、BEV 模型、CV 大模型、LLM 大模型等各类不同架构的主流模型；基于自主可控的先进国产工艺打造，采用独特的“算力积木”架构，可灵活满足不同场景对算力的需求，为大模型推理提供强大动力。</p>
  <h3><strong>基于太初T100加速卡2小时适配DeepSeek-R1系列模型</strong></h3>
  <p>2月5日，太初元碁Tecorigin表示，基于通用的异构众核芯片架构和深厚的软件生态积累，在太初T100加速卡上仅用2小时便完成DeepSeek-R1系列模型的适配工作，快速上线包括DeepSeek-R1-Distill-Qwen-7B在内的多款大模型服务，为人工智能应用的创新发展提供了强有力的技术支撑和自动可控的算力设施保障。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_73d3dd97317c45fa85ca700b6e64b9bf@000000_oswg128060oswg970oswg437_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，太初元碁正积极携手京算、是石科技、神威数智、龙芯中科等合作伙伴，全力打造DeepSeek系列模型的云端推理平台。企业用户只需通过简单的操作，即可在云端快速获取太初T100加速卡的强大推理能力，轻松实现智能化转型，提升生产效率和创新能力，以在激烈的市场竞争中脱颖而出。同时，太初元碁也联合龙芯中科提供面向政务信创的国密云端推理平台，以满足信创刚需。</p>
  <h3><strong>燧原科技实现全国各地智算中心DeepSeek的全量推理服务部署</strong></h3>
  <p>2月6日，燧原科技宣布完成对DeepSeek全量模型的高效适配，包括DeepSeek-R1/V3 671B原生模型、DeepSeek-R1-Distill-Qwen-1.5B/7B/14B/32B、DeepSeek R1-Distill-Llama-8B/70B等蒸馏模型。整个适配进程中，燧原AI加速卡的计算能力得到充分利用，能够快速处理海量数据，同时其稳定性为模型的持续优化和大规模部署提供了坚实的基础。</p>
  <p>目前，DeepSeek的全量模型已在庆阳、无锡、成都等智算中心完成了数万卡的快速部署，将为客户及合作伙伴提供高性能计算资源，提升模型推理效率，同时降低使用门槛，大幅节省硬件成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8a8f419509954303bac9c525c46c7120@000000_oswg294209oswg1080oswg516_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>昆仑芯全面适配DeepSeek</strong></h3>
  <p>2月6日，昆仑芯科技宣布，在DeepSeek-V3/R1上线不久，昆仑芯便率先完成全版本模型适配，这其中包括DeepSeek MoE 模型及其蒸馏的Llama/Qwen等小规模dense模型。</p>
  <p>昆仑芯P800可以较好的支撑DeepSeek系列MoE模型大规模训练任务，全面支持MLA、多专家并行等特性，仅需32台即可支持模型全参训练，高效完成模型持续训练和微调。</p>
  <p>P800显存规格优于同类主流GPU20%-50%，对MoE架构更加友好，且率先支持8bit推理，单机8卡即可运行 671B 模型。正因如此，昆仑芯相较同类产品更加易于部署，同时可显著降低运行成本，轻松完成DeepSeek-V3/R1全版本推理任务。</p>
  <h3><strong>龙芯处理器成功运行DeepSeek大模型</strong></h3>
  <p>2 月 7 日，龙芯中科宣布， 日前，龙芯联合太初元碁等产业伙伴，仅用 2 小时即在太初 T100 加速卡上完成 DeepSeek-R1 系列模型的适配工作，快速上线包含 DeepSeek-R1-Distill-Qwen-7B 在内的多款大模型服务。</p>
  <p>此外，采用龙芯3A6000处理器的诚迈信创电脑和望龙电脑已实现本地部署DeepSeek，部署后无需依赖云端服务器，避免了因网络波动或服务器过载导致的服务中断，可高效完成文档处理、数据分析、内容创作等多项工作，显著提升工作效率。</p>
  <h2><strong>DeepSeek给国产芯片公司，带来新契机</strong></h2>
  <p>DeepSeek 的横空出世宛如一颗投入平静湖面的石子，在行业中激起层层涟漪，为国产芯片公司带来新的发展契机。</p>
  <p><strong>首先，随着大模型应用的遍地开花，对芯片的需求也水涨船高。</strong>无论是模型训练时所需的强大算力，还是推理过程中对低延迟、高效率的追求，都为国产芯片公司打开了新的市场空间。以往，由于高昂的大模型使用成本，许多潜在的应用场景被抑制，如今 DeepSeek 打破了这一僵局，国产芯片公司得以凭借自身产品在新兴的细分市场中崭露头角，满足不同行业对于大模型运算的芯片需求。</p>
  <p><strong>其次，DeepSeek 大模型与国产 AI 芯片适配的逐步成熟，是另一个关键契机。</strong>此前，国产 AI 芯片在发展过程中，常面临与主流大模型适配度不佳的问题，这限制了其市场推广与应用拓展。而 DeepSeek 的出现改变了这一局面，它为国产 AI 芯片提供了一个更为契合的适配平台。</p>
  <p>当国产 AI 芯片能够与 DeepSeek 大模型良好适配后，可以加快国产 AI 芯片在国内大模型训练端和推理端的应用，使得国产芯片在本土市场中获得更多实践机会，通过不断优化和改进，提升产品性能。</p>
  <p><strong>最后，随着 DeepSeek 与国产芯片的适配，将与其他国产软硬件厂商形成协同效应，构建起完整的生态闭环</strong>，这将推动国产芯片在人工智能领域的应用，加速国产芯片生态体系的建设。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247788670&amp;idx=1&amp;sn=0bfe8a56872bbb9e66c0ef7f100ea3eb&amp;chksm=c0bb70d10d33a104ad87ab95da8c6d8483660a1eefe0c981fe2a494038c54d9fb2893ce2e0e6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：丰宁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156406783662855</id>
            <title>英伟达联手MIT清北发布SANA 1.5，线性扩散Transformer再刷文生图新SOTA</title>
            <link>https://www.36kr.com/p/3156406783662855</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156406783662855</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:12:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: SANA 1.5, 线性扩散Transformer, 模型扩展, 文本生成图像  
<br><br>  
总结: SANA 1.5是一种高效可扩展的线性扩散Transformer，针对文本生成图像任务提出了三项创新：高效的模型增长策略、深度剪枝和推理时扩展策略。这些创新显著降低了训练和推理成本，同时提升了生成质量。研究者通过有效的模型增长策略，保留小模型的知识，减少了60%的训练时间。深度剪枝技术实现了高效的模型压缩，而推理时扩展策略则通过重复采样提升了生成质量。实验结果表明，SANA 1.5在GenEval基准测试中达到了最先进的性能，证明了高效扩展不仅依赖于增加模型容量。 </div>
                        <hr>
                    
                    <blockquote>
   <p>SANA 1.5是一种高效可扩展的线性扩散Transformer，针对文本生成图像任务进行了三项创新：高效的模型增长策略、深度剪枝和推理时扩展策略。这些创新不仅大幅降低了训练和推理成本，还在生成质量上达到了最先进的水平。</p>
  </blockquote>
  <p>近年来，文本生成图像的技术不断突破，但随着模型规模的扩大，计算成本也随之急剧上升。</p>
  <p>为此，英伟达联合MIT、清华、北大等机构的研究人员提出了一种高效可扩展的线性扩散Transformer——SANA，在大幅降低计算需求的情况下，还能保持有竞争力的性能。</p>
  <p>SANA1.5在此基础上，聚焦了两个关键问题：</p>
  <ol>
   <li>线性扩散Transformer的可扩展性如何？</li>
   <li>在扩展大规模线性DiT时，怎样降低训练成本？</li>
  </ol>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2c1e9b502df2433d83b69e74bfa74e6c@5888275_oswg134388oswg1080oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文链接：https://arxiv.org/pdf/2501.18427</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8271efceb7894e3e83253f62e50b7e46@5888275_oswg148404oswg1080oswg566_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>SANA 1.5：高效模型扩展三大创新</strong></h2>
  <p>SANA 1.5在SANA 1.0（已被ICLR 2025接收）的基础上，有三项关键创新。</p>
  <p>首先，研究者提出了一种高效的模型增长策略，使得SANA可以从1.6B（20层）扩展到4.8B（60层）参数，同时显著减少计算资源消耗，并结合了一种节省内存的8位优化器。</p>
  <p>与传统的从头开始训练大模型不同，通过有策略地初始化额外模块，可以让大模型保留小模型的先验知识。与从头训练相比，这种方法能减少60%的训练时间。</p>
  <p>其二，引入了模型深度剪枝技术，实现了高效的模型压缩。通过识别并保留关键的块，实现高效的模型压缩，然后通过微调快速恢复模型质量，实现灵活的模型配置。</p>
  <p>其三，研究者提出了一种推理期间扩展策略，引入了重复采样策略，使得SANA在推理时通过计算而非参数扩展，使小模型也能达到大模型的生成质量。</p>
  <p>通过生成多个样本，并利用基于视觉语言模型（VLM）的选择机制，将GenEval分数从0.72提升至0.80。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fe479b5a5bf14ac0aadb3e371fea96cf@5888275_oswg225366oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与从头开始训练大模型不同，研究者首先将一个包含N个Transformer层的基础模型扩展到N+M层（在实验中，N=20，M=40），同时保留其学到的知识。</p>
  <p>在推理阶段，采用两种互补的方法，实现高效部署：</p>
  <ul>
   <li>模型深度剪枝机制：识别并保留关键的Transformer块，从而在小的微调成本下，实现灵活的模型配置。</li>
   <li>推理时扩展策略：借助重复采样和VLM引导选择，在计算资源和模型容量之间权衡。</li>
  </ul>
  <p>同时，内存高效CAME-8bit优化器让单个消费级GPU上微调十亿级别的模型成为可能。</p>
  <p>下图展示了这些组件如何在不同的计算资源预算下协同工作，实现高效扩展。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c159c61f836e42e4b34261b61092c516@5888275_oswg302617oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>模型增长</strong></h3>
  <p>研究者提出一种高效的模型增长策略，目的是对预训练的DiT模型进行扩展，把它从𝑁层增加到𝑁+𝑀层，同时保留模型已经学到的知识。</p>
  <p>研究过程中，探索了三种初始化策略，最终选定部分保留初始化方法。这是因为该方法既简单又稳定。</p>
  <p>在这个策略里，预训练的N层继续发挥特征提取的作用，而新增加的M层一开始是随机初始化，从恒等映射起步，慢慢学习优化特征表示。</p>
  <p>实验结果显示，与循环扩展和块扩展策略相比，这种部分保留初始化方法在训练时的动态表现最为稳定。</p>
  <h3><strong>模型剪枝</strong></h3>
  <p>本文提出了一种模型深度剪枝方法，能高效地将大模型压缩成各种较小的配置，同时保持模型质量。</p>
  <p>受Minitron启发，通过输入输出相似性模式分析块的重要性：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a64f2637c8a94e0c9ac4facf58149c2b@5888275_oswg43528oswg968oswg238_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这里的</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6a87418389444d9ab3760eab308f25fb@5888275_oswg1968oswg140oswg98_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>表示第i个transformer的第t个token。</p>
  <p>模型的头部和尾部块的重要性较高，而中间层的输入和输出特征相似性较高，表明这些层主要用于逐步优化生成的结果。根据排序后的块重要性，对transformer块进行剪枝。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_94c41970fb9a46d49f14794ead94a0b5@5888275_oswg68926oswg1080oswg318_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>剪枝会逐步削弱高频细节，因为，在剪枝后进一步微调模型，以弥补信息损失。</p>
  <p>使用与大模型相同的训练损失来监督剪枝后的模型。剪枝模型的适配过程非常简单，仅需100步微调，剪枝后的1.6B参数模型就能达到与完整的4.8B参数模型相近的质量，并且优于SANA 1.0的1.6B模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d5c86982327b44eebacc56282cd7616f@5888275_oswg644438oswg1080oswg621_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>推理时扩展</strong></h3>
  <p>SANA 1.5经过充分训练，在高效扩展的基础上，生成能力有了显著提升。受LLM推理时扩展的启发，研究者也想通过这种方式，让SANA 1.5表现得更好。</p>
  <p>对SANA和很多扩散模型来说，增加去噪步数是一种常见的推理时扩展方法。但实际上，这个方法不太理想。一方面，新增的去噪步骤没办法修正之前出现的错误；另一方面，生成质量很快就会达到瓶颈。</p>
  <p>相较而言，增加采样次数是更有潜力的方向。</p>
  <p>研究者用视觉语言模型（VLM）来判断生成图像和文本提示是否匹配。他们以NVILA-2B为基础模型，专门制作了一个数据集对其进行微调。</p>
  <p>微调后的VLM能自动比较并评价生成的图像，经过多轮筛选，选出排名top-N的候选图像。这不仅确保了评选结果的可靠性，还能有效过滤与文本提示不匹配的图像。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_97d5d108c9c540a49b5d0c1e8ed19a62@5888275_oswg217969oswg1080oswg336_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>模型增长、模型深度剪枝和推理扩展，构成了一个高效的模型扩展框架。三种方法协同配合，证明了精心设计的优化策略，远比单纯增加参数更有效。</p>
  <ul>
   <li>模型增长策略探索了更大的优化空间，挖掘出更优质的特征表示。</li>
   <li>模型深度剪枝精准识别并保留了关键特征，从而实现高效部署。</li>
   <li>推理时间扩展表明，当模型容量有限时，借助额外的推理时间和计算资源，能让模型达到与大模型相似甚至更好的效果。</li>
  </ul>
  <p>为了实现大模型的高效训练与微调，研究者对CAME进行扩展，引入按块8位量化，从而实现CAME-8bit优化器。</p>
  <p>CAME-8bit相比AdamW-32bit减少了约8倍的内存使用，同时保持训练的稳定性。</p>
  <p>该优化器不仅在预训练阶段效果显著，在单GPU微调场景中更是意义非凡。用RTX 4090这样的消费级GPU，就能轻松微调SANA 4.8B。</p>
  <p>研究揭示了高效扩展不仅仅依赖于增加模型容量。通过充分利用小模型的知识，并设计模型的增长-剪枝，更高的生成质量并不一定需要更大的模型。</p>
  <h2><strong>SANA 1.5 评估结果</strong></h2>
  <p>实验表明，SANA 1.5的训练收敛速度比传统方法（扩大规模并从头开始训练）快2.5倍。</p>
  <p>训练扩展策略将GenEval分数从0.66提升至0.72，并通过推理扩展将其进一步提高至0.80，在GenEval基准测试中达到了最先进的性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a1bb16c5689e450486b46f7a78f10ed1@5888275_oswg927471oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>模型增长</strong></h3>
  <p>将SANA-4.8B与当前最先进的文本生成图像方法进行了比较，结果如表所示。</p>
  <p>从SANA-1.6B到4.8B的扩展带来了显著的改进：GenEval得分提升0.06（从0.66增加到0.72），FID降低0.34（从5.76降至5.42），DPG得分提升0.2（从84.8增加到85.0）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9fc29fa915b54cb3bdd76c36bb0397d6@5888275_oswg124945oswg1067oswg511_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>和当前最先进的方法相比，SANA-4.8B模型的参数数量少很多，却能达到和大模型一样甚至更好的效果。</p>
  <p>SANA-4.8B的GenEval得分为0.72，接近Playground v3的0.76。</p>
  <p>在运行速度上，SANA-4.8B的延迟比FLUX-dev（23.0秒）低5.5倍；吞吐量为0.26样本/秒，是FLUX-dev（0.04样本/秒）的6.5倍，这使得SANA-4.8B在实际应用中更具优势。</p>
  <h3><strong>模型剪枝</strong></h3>
  <p>为了和SANA 1.0（1.6B）公平比较，此次训练的SANA 1.5（4.8B）模型，没有用高质量数据做监督微调。</p>
  <p>所有结果都是针对512×512尺寸的图像评估得出的。经过修剪和微调的模型，仅用较低的计算成本，得分就达到了0.672，超过了从头训练模型的0.664。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_400a67a9bb3644bea313653fa45295e5@5888275_oswg55847oswg1080oswg209_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>推理时扩展</strong></h3>
  <p>将推理扩展应用于SANA 1.5（4.8B）模型，并在GenEval基准上与其他大型图像生成模型进行了比较。</p>
  <p>通过从2048张生成的图像中选择样本，经过推理扩展的模型在整体准确率上比单张图像生成提高了8%，在「颜色」「位置」和「归属」子任务上提升明显。</p>
  <p>不仅如此，借助推理时扩展，SANA 1.5（4.8B）模型的整体准确率比Playground v3 (24B）高4%。</p>
  <p>结果表明，即使模型容量有限，提高推理效率，也能提升模型生成图像的质量和准确性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9c1c538b017f43579aebe7b85d8e09d0@5888275_oswg134803oswg1080oswg316_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>SANA：超高效文生图</strong></h2>
  <p>在这里介绍一下之前的SANA工作。</p>
  <p>SANA是一个超高效的文本生成图像框架，能生成高达4096×4096分辨率的图像，不仅画质清晰，还能让图像和输入文本精准匹配，而且生成速度超快，在笔记本电脑的GPU上就能运行。</p>
  <p>SANA为何如此强大？这得益于它的创新设计：</p>
  <ul>
   <li><strong>深度压缩自动编码器：</strong>传统自动编码器压缩图像的能力有限，一般只能压缩8倍。而SANA的自动编码器能达到32倍压缩，大大减少了潜在tokens数量，计算效率也就更高了。</li>
   <li><strong>线性DiT：</strong>SANA用线性注意力替换了DiT中的标准注意力。在处理高分辨率图像时，速度更快，还不会降低图像质量。</li>
   <li><strong>仅解码文本编码器：</strong>SANA不用T5做文本编码器了，而是采用现代化的小型仅解码大模型。同时，通过上下文学习，设计出更贴合实际需求的指令，让生成的图像和输入文本对应得更好。</li>
   <li><strong>高效训练与采样：</strong>SANA提出了Flow-DPM-Solver方法，减少了采样步骤。再配合高效的字幕标注与选取，让模型更快收敛。</li>
  </ul>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8aaacb9ffdc2488d90295c3561efea23@5888275_oswg713619oswg1080oswg437_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>经过这些优化，SANA-0.6B表现十分出色。</p>
  <p>它生成图像的质量和像Flux-12B这样的现代大型扩散模型差不多，但模型体积缩小了20倍，数据处理能力却提升了100倍以上。</p>
  <p>SANA-0.6B运行要求不高，在只有16GB显存的笔记本GPU上就能运行，生成一张1024×1024分辨率的图像，用时不到1秒。</p>
  <p>这意味着，创作者们用普通的笔记本电脑，就能轻松制作高质量图像，大大降低了内容创作的成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9209501a86ec4a6c8d95c1300ee57030@5888275_oswg98438oswg1080oswg297_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究者提出新的深度压缩自动编码器，将压缩比例提升到32倍，和压缩比例为8倍的自动编码器相比，F32自动编码器生成的潜在tokens减少了16倍。</p>
  <p>这一改进对于高效训练和超高分辨率图像生成，至关重要。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fffa358e9ee341e0a0bd517533c340f8@5888275_oswg1319164oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究者提出一种全新的线性DiT，用线性注意力替代传统的二次复杂度注意力，将计算复杂度从原本的O(N²) 降低至O(N)。另一方面，在MLP层引入3×3深度可分卷积，增强潜在tokens的局部信息。</p>
  <p>在生成效果上，线性注意力与传统注意力相当，在生成4K图像时，推理延迟降低了1.7倍。Mix-FFN结构让模型无需位置编码，也能生成高质量图像，这让它成为首个无需位置嵌入的DiT变体。</p>
  <p>在文本编码器的选择上，研究者选用了仅解码的小型大语言模型Gemma，以此提升对提示词的理解与推理能力。相较于CLIP和T5，Gemma在文本理解和指令执行方面表现更为出色。</p>
  <p>为充分发挥Gemma的优势，研究者优化训练稳定性，设计复杂人类指令，借助Gemma的上下文学习能力，进一步提高了图像与文本的匹配质量。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6d7c14a6602841c7b698412ed8f42aea@5888275_oswg481782oswg1080oswg834_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究者提出一种自动标注与训练策略，借助多个视觉语言模型（VLM）生成多样化的重新描述文本。然后，运用基于CLIPScore的策略，筛选出CLIPScore较高的描述，以此增强模型的收敛性和对齐效果。</p>
  <p>在推理环节，相较于Flow-Euler-Solver，Flow-DPM-Solver将推理步骤从28-50步缩减至14-20步，不仅提升了速度，生成效果也更为出色。</p>
  <p><strong>参考资料：</strong></p>
  <p>https://huggingface.co/papers/2501.18427</p>
  <p>https://x.com/xieenze_jr/status/1885510823767875799</p>
  <p>https://nvlabs.github.io/SANA/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/UvOoDGvzAFjA3ImXXVlktw" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：英智 好困，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156439091730944</id>
            <title>我们应如何看待DeepSeek的557.6万美元训练成本？</title>
            <link>https://www.36kr.com/p/3156439091730944</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156439091730944</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:12:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 算法效率, DeepSeek-V3, 训练成本, AI企业  
<br><br>  
总结: 本文讨论了中国AI企业在算法效率方面的优势，特别是DeepSeek-V3模型的训练成本显著低于同类美国模型。张钹指出，中国企业对算法效率的重视源于其生存需求，而美国企业则因算力强大而相对宽松。DeepSeek-V3的训练成本为557.6万美元，但未包括隐性成本，且其训练效率通过优化算法、框架和硬件得以提升。尽管DeepSeek的成功引发了外界的误读，但其创新和努力是推动其发展的核心因素。 </div>
                        <hr>
                    
                    <p>三个月前，我们和中国科学院院士、清华大学计算机系教授张钹曾经聊过一个话题：“为什么在提高算法效率上中国人会做得更好？”</p>
  <p>张钹告诉我们：“<strong>对中国企业来讲，算法效率是生命攸关的</strong>，我们必须全力以赴。也许因为美国人有强大的算力，算法效率对他们来说只是锦上添花而已。”</p>
  <p>当时，我们对这句话感受还不是很深，直到后来看到了DeepSeek-V3技术报告里的这张表格。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_894e588f84bf42b68bc34b2222a1e4cf@5888275_oswg26044oswg821oswg177_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">DeepSeek-V3的训练成本（假设H800的租赁价格为2美元/GPU小时），图片来源：DeepSeek-V3技术报告&nbsp;</p>
  <p>简单来说，DeepSeek-V3仅使用了2048块英伟达H800 GPU，耗费了557.6万美元就完成了训练，相比同等规模的模型（如GPT-4、GPT-4o、Llama 3.1），训练成本大幅降低。</p>
  <p>这样说没有错，但在复杂的舆论场中也引发了一些误读。比如，“中国AI企业用几百万美元的成本打败了美国AI企业数亿美元的投入”“成本仅为国外三十分之一，硅谷恐慌”。</p>
  <p>这种误读有一些客观原因，因为OpenAI、Meta官方从来没有公布过GPT-4、GPT-4o、Llama 3.1的训练成本，多数人对模型训练成本构成也并不熟悉，但误读背后更多还是主观原因——情绪。</p>
  <p>AI大模型领域，中国AI企业一直是一个“追随者”的角色，这次有了和硅谷巨头“掰手腕”的机会，就像霍元甲站上了与西洋力士的比武台，谁不想叫声好呢？</p>
  <p><strong>这种情绪本身没有错，但也在一定程度上模糊了DeepSeek团队在算法、框架和硬件上的优化协同设计的价值</strong>，而这正是DeepSeek-V3降本增效的关键。</p>
  <h2><strong>01 训练成本差距是否有那么大？</strong></h2>
  <p>我们查阅了技术报告，DeepSeek只公布了基座模型V3的训练成本，并没有公布推理模型R1的训练成本。</p>
  <p>DeepSeek-V3技术报告显示，该模型的正式训练成本包括三个阶段：<strong>预训练（pre-training）、扩展上下文（context extension）、后训练（post-training），共计557.6万美元。</strong></p>
  <p><strong>但是这557.6万美元的训练成本并不包括前期研究以及关于架构、算法或数据的消融实验所产生的成本。</strong></p>
  <p>前期研究、消融实验属于“隐性成本”，但不容忽视。</p>
  <p>在一个AI企业正式训练一个模型之前，需要进行大量的前期研究，包括对算法的理论研究、对硬件性能的探索、对数据集的分析等。</p>
  <p>而消融实验（Ablation Study）是一种在机器学习和深度学习中广泛使用的分析方法，用于评估模型各个组件或特征的重要性及其对模型整体性能的影响。</p>
  <p>消融实验就像是在玩“减法游戏”或者“排除法”，通过逐一移除或修改模型的某些部分，观察模型性能的变化，从而确定每个部分的相对重要性。</p>
  <p>另外，在训练模型之前还会有一定的试错成本。</p>
  <p>为什么说这些成本是“隐性成本”？</p>
  <p>因为大模型前期研发往往分散在数月甚至数年中，难以量化统计；消融实验可能反复进行，但最终仅保留最优方案，失败案例的成本常被忽视；企业通常不会公开内部研发细节（如试错次数），导致外部估算会产生偏差。</p>
  <p><strong>除了“隐性成本”，不同的成本计算方式也会产生不一样的结果。</strong></p>
  <p>DeepSeek-V3这557.6万美元训练成本是怎么计算的呢？按照DeepSeek-V3技术报告的逻辑，我们简单列了一个公式：</p>
  <blockquote>
   <p>训练耗费的时长（GPU小时）×H800每GPU小时的租赁价格（美元）=DeepSeek-V3训练成本（美元）</p>
  </blockquote>
  <p>正式训练耗费的时长包括：预训练阶段耗费266.4万（2664K）GPU小时，扩展上下文长度阶段耗费11.9万（119K）GPU小时，后训练阶段耗费0.5万（5K）GPU小时，因此DeepSeek-V3的正式训练共耗费278.8万（2788K）GPU小时。</p>
  <p>而DeepSeek在技术报告中假设H800每GPU小时的租赁价格为2美元，这样DeepSeek-V3训练成本就是：</p>
  <blockquote>
   <p>2,788,000×2=5,576,000（美元）</p>
  </blockquote>
  <p>需要注意的是，这里是按<strong>GPU小时</strong>而不是<strong>GPU个数</strong>计算，单价是按<strong>GPU租赁价格计算</strong>而不是<strong>GPU购买价格计算</strong>。</p>
  <p>换种方式计算训练成本，结果就会很不一样。</p>
  <p>比如，为了训练Llama 3.1 405B，Meta使用了超过1.6万个英伟达H100 GPU，如果按照H100 GPU的购买价格计算，这样计算下来的训练成本就已高达数亿美元。</p>
  <p>我们也可以按照DeepSeek-V3一样的租赁逻辑计算。</p>
  <p>尽管Meta没有透露Llama 3.1具体的训练成本，但是其技术报告显示，Llama 3.1 405B的预训练（此处说的是预训练时间而非完整训练时间）为54天。那么，Llama 3.1 405B预训练阶段耗费的GPU小时为：</p>
  <blockquote>
   <p>天数×24小时×H100 GPU个数=预训练阶段耗费的GPU小时</p>
   <p>54×24×16,000=20,736,000</p>
  </blockquote>
  <p>Llama 3.1 405B是2024年7月推出的，如果按照2024年初海外市场H100 GPU每GPU小时的租赁价格2.8美元（参考价格，会浮动）计算，那么<strong>其预训练成本约为5800万美元。相比之下，DeepSeek-V3的532.8万美元预训练成本的确是大幅降低了。</strong></p>
  <p>而OpenAI官方从来没有公布过其训练成本，但是我们可以从侧面推算。</p>
  <p>英伟达CEO黄仁勋在NVIDIA GTC 2024主题演讲中介绍，<strong>如果要训练一个有1.8万亿参数的GPT模型，用Hopper（H100）的话，需要约8000个GPU，耗电15兆瓦，用时90天，大约需要三个月。</strong></p>
  <p>虽然黄仁勋没有明说，但根据此前多个渠道的爆料信息，这个1.8万亿参数的GPT模型就是GPT-4。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1c0ff7c877ae4b839016aa093cf6e094@5888275_oswg359451oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">黄仁勋在NVIDIA GTC 2024 主题演讲，图片来源：英伟达B站账号&nbsp;</p>
  <p>黄仁勋在演讲中解释道：“这样就可以训练出这种开创性的AI模型，这显然没有人们想象中那么昂贵，但是8000个GPU仍然是一大笔投资。”</p>
  <p>我们同样可以按照租赁逻辑估算一下与GPT-4规模相当模型训练成本。为什么说估算？因为H100是2022年3月发布的GPU，但实际大规模供货和云服务商部署通常在2022年底至2023年初才开始，而GPT-4在2023年3月发布，所以GPT-4的训练更多还是依靠A100。</p>
  <p>假设在2024年初，也就是黄仁勋发表演讲之前，<strong>训练一个与GPT-4规模相当的大模型</strong>，其训练成本是：</p>
  <blockquote>
   <p>天数×24小时×H100 GPU个数=训练阶耗费的GPU小时</p>
   <p>90×24×8,000=17,280,000（小时）</p>
   <p>训练耗费的GPU小时×H100每GPU小时的租赁价格=训练成本</p>
   <p>17,280,000×2.8=48,384,000（美元）</p>
  </blockquote>
  <p><strong>大约4800万美元的训练费用</strong>，的确如黄仁勋所说“没有人们想象中那么昂贵”。</p>
  <p>而据SemiAnalysis在2023年7月发布的分析报告，OpenAI在GPT-4的训练中使用了约2.5万个A100GPU，训练了90到100天，利用率（MFU）约为32%至36%，这种极低的利用率部分是由于大量的故障导致需要重新启动检查点。如果每个A100 GPU的使用成本大约为每小时1美元，<strong>那么仅此次训练的成本将达到约6300万美元。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_918f231763784300810201856d257a93@5888275_oswg416449oswg1080oswg465_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：SemiAnalysis&nbsp;</p>
  <p>DeepSeek-V3对标的Claude 3.5 Sonnet的训练成本又是多少呢？此前Anthropic也没有公布Claude 3.5 Sonnet的训练成本，但Anthropic CEO达里奥·阿莫迪（Dario Amodei）近期在一篇评价DeepSeek的文章中透露，<strong>Claude 3.5 Sonnet训练成本在数千万美元（cost a few $10M's to train）</strong>，他还特意说：“我不会给出具体的数字。”</p>
  <p>“A few”在英语里通常指3到5个，所以我们<strong>估计Claude 3.5 Sonnet的训练费用在3000万到5000万美元之间。</strong></p>
  <p>我们统一按照DeepSeek-V3的GPU租赁逻辑计算，不考虑其他“隐性成本”，可以发现，<strong>DeepSeek-V3的训练成本相比其对标模型训练成本大幅降低，但没有到某些人说的“几十分之一”的夸张程度。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c3fbca472091403fae7a206a4a7a90b4@5888275_oswg277004oswg1080oswg748_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>需要注意的是，随着技术和市场的发展，GPU租赁价格的降低使得企业和研究机构能够以更低的成本配置更多的GPU，从而让模型训练降本增效。</p>
  <p>企业还可以用更先进的GPU降低训练的能耗。</p>
  <blockquote>
   <p>还记得黄仁勋举的例子吗？如果要训练一个有1.8万亿参数的GPT模型，用Hopper（H100）的话，需要约8000个GPU，耗电15兆瓦，用时90天；如果用Blackwell（GB200）的话，需要2000个GPU，耗电仅需4兆瓦，约为Hopper的四分之一。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_19c5ba83907344cba79a53aba4282d23@5888275_oswg212098oswg834oswg901_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：英伟达&nbsp;</p>
  <p>这是先进GPU带来的效率提升，但是国内AI企业由于管控，无法获得最先进的GPU，又是靠什么来实现降本增效呢？</p>
  <blockquote>
   <p>Meta技术报告显示，Llama 3.1 405B的预训练时长54天，使用了15万亿（15T）的tokens以及1.6万个英伟达H100 GPU进行训练。</p>
  </blockquote>
  <p>DeepSeek-V3在预训练阶段，使用了14.8万亿（14.8T）的tokens进行训练，预训练耗时也是54天，DeepSeek-V3技术报告里也说的是“不到两个月”：</p>
  <blockquote>
   <p>预训练阶段耗费的GPU小时÷H800 GPU个数÷24小时=天数</p>
   <p>2,664,000÷2048÷24≈54（天）</p>
  </blockquote>
  <p>但是，DeepSeek-V3仅使用了2048块英伟达H800 GPU，尽管可能存在利用率的差异，但这与Llama 3.1 405B训练使用的1.6万个英伟达H100 GPU形成了鲜明对比。而且H800是英伟达为了满足出口限制而设计的GPU，性能低于H100。</p>
  <p>也就是说，DeepSeek-V3在GPU比Llama 3.1 405B用得少，GPU性能也更弱的情况下，在相同的时间，完成了与Llama 3.1 405B差不多的训练量。</p>
  <p>DeepSeek-V3技术报告里的这句话“<strong>DeepSeek-V3每训练一万亿（trillion）个token仅需18万（180K）H800&nbsp;GPU小时</strong>”成为了关键。</p>
  <p>DeepSeek-V3大幅提升了模型训练效率。</p>
  <h2><strong>02 DeepSeek如何降本增效？</strong></h2>
  <p>DeepSeek-V3是一个混合专家模型 (Mixed Expert Models，以下简称MoE) ，旨在通过整合多个模型或“专家”的预测来提升整体模型性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_89bd3322c519407eac19f610abea1fdd@5888275_oswg95273oswg966oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：DeepSeek-V3技术报告&nbsp;</p>
  <p>清华大学计算机系长聘教授、高性能计算研究所所长翟季冬在《夜话DeepSeek：技术原理与未来方向》直播中介绍，之前发布的一些MoE模型，采用的是<strong>“专家数很少、每个专家很大”</strong>的架构，但是DeepSeek采用的是<strong>“大量细粒度的专家”</strong>。</p>
  <p>“大量细粒度的专家”可以更灵活地处理各种输入数据，提高模型的适应性和泛化能力。由于每个专家的规模小，计算效率更高，训练和存储成本也相对较低。不过，由于专家数量众多，可能会导致模型的管理和调度变得更加复杂。</p>
  <p>翟季冬分析，为了提升DeepSeek-V3的模型训练效率，DeepSeek团队在四个方面进行了优化，分别是：<strong>负载均衡优化、通信优化、内存优化、计算优化</strong>。</p>
  <p><strong>首先是负载均衡优化。</strong>在MoE架构中，负载均衡指的是将输入数据合理分配给各个专家，使得每个专家都能充分发挥其性能，同时避免某些专家过度负载而其他专家空闲。</p>
  <p>负载均衡是MoE训练中的非常大的挑战，如果处理不好，那么模型在一个大规模GPU集群训练时，利用率就很难提升上去。</p>
  <p>DeepSeek团队为了解决负载均衡的挑战，创新提出了“Auxiliary-loss-free（无辅助损失）”负载均衡方案。</p>
  <p>在传统的MoE中，为了保证各个专家的负载均衡，通常会引入一个Auxiliary Loss（辅助损失）。这个Auxiliary Loss会强制让每个专家处理的任务量尽量均匀。但它可能会让模型在优化过程中过于关注负载均衡，而忽略了模型本身的性能。</p>
  <p>而DeepSeek的Auxiliary-Loss-Free方案，<strong>不依赖额外的辅助损失，而是在每个token的专家分配过程中直接施加一个bias（偏差值）来实现负载均衡，从而实现动态调整专家的负载。</strong></p>
  <p>由于这种bias的引入已经在专家选择的过程中起到了调控作用，使得各专家之间的token分配趋向均衡，因此就不再需要设计和调节额外的辅助损失项来“强制”负载平衡。这不仅简化了训练目标，也避免了因辅助损失权重设置不当而可能引入的训练不稳定问题。</p>
  <p>简单来说，<strong>这就类似红绿灯路口</strong>，Auxiliary loss就是固定时长的红绿灯，车流量大了，路口通行效率会降低；而Auxiliary-Loss-Free中的bias就是可以根据实时车流量动态调整时长的红绿灯，基于当前状态（交通流量或专家负载）动态调整资源分配，以达到整体平衡和高效利用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b9f0ae3691234cceb86b6eede16cfde3@5888275_oswg72090oswg957oswg545_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">负载均衡优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>第二是通信优化。</strong>在MoE训练中，使用专家并行会引入非常大的All to All通信开销。</p>
  <p>什么是All to All通信开销？</p>
  <p>假设在一个MoE中，有10个专家，每个专家被放置在一个独立的计算节点上。在训练过程中，每个专家需要与其他所有专家进行数据交换，以更新模型参数和同步训练状态。这种情况下，每个节点都需要与其他9个节点进行通信，形成了All to All的通信模式。随着专家数量的增加，通信开销也会显著增加，导致训练效率下降。</p>
  <p>DeepSeek-V3就包括1个共享专家和256个路由专家，它采用的并行训练策略：16路流水线并行、64路专家并行，跨8个物理节点。</p>
  <p><strong>DeepSeek团队为了降低通信开销，提出了DualPipe算法。</strong></p>
  <p><strong>DualPipe算法的核心创新就是能够将计算和通信阶段重叠进行。</strong>在传统的训练过程中，计算和通信是分开进行的，这会导致GPU在等待数据传输时出现空闲期，即所谓的 “流水线气泡”（pipeline bubbles）。DualPipe算法通过确保在一个微批量（micro-batch）被计算的同时，另一个微批量可以进行通信，精细地编排计算和通信，从而最大限度地减少这些空闲期，提高GPU的利用率。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_074173ab32d143be82d54df302e054df@5888275_oswg322986oswg986oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">通信优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>DualPipe算法还采用了双向流水线机制，同时从流水线的两端处理微批量。</strong>这种策略确保了在整个训练过程中GPU始终保持活跃。通过这种方式，DeepSeek能够保持良好的计算与通信比例，减少延迟，提高吞吐量。</p>
  <p>“这里有一个需要注意的点，如果采用双向流水线，要在GPU显存里存两份模型参数。大模型训练内存使用非常重要，为了解决这个问题，它采用了64路的专家并行，双流水可以非常有效地降低流水线bubble。”翟季冬说。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_40a1b49467194c6990866eaacafff0d8@5888275_oswg74515oswg961oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">通信优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p>此外，DeepSeek的通信优化还包括跨节点通信优化以及Warp Specialization技术。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_52733754fbfc450399f10663b79f1366@5888275_oswg500012oswg989oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">通信优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>第三是内存优化。</strong>包括了重计算、使用CPU内存和参数共享。</p>
  <p>大模型训练往往存在显存瓶颈。重计算的核心思想是在前向传播过程中，只保留少量关键的中间结果，而将其余的中间结果释放掉。当在反向传播过程中需要用到这些已释放的中间结果时，再重新执行前向传播中的相应部分来计算得到。<strong>这种方法通过增加一定的计算量，显著降低了内存消耗，是一种“以时间换空间”的策略。</strong></p>
  <p>这可以理解为一种在大模型训练过程中“偷懒”的技巧。</p>
  <p>同时，DeepSeek还把一些数据，包括像模型参数的指数移动平均（EMA），存到CPU内存，从而节约GPU显存；将主模型与MTP（Multi-Token Prediction）模块的output head和embedding部署在相同节点，最大化地共享参数空间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_531b3e1722fb4174af5c7f9c455ed4e8@5888275_oswg392274oswg987oswg564_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">内存优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>第四是计算优化。</strong>为了提升训练效率，DeepSeek采用了混合精度训练策略。</p>
  <p>DeepSeek引入了英伟达FP8混合精度训练框架，并首次在超大规模模型上验证了其有效性。通过支持FP8计算和存储，DeepSeek实现了加速训练和减少GPU内存使用。FP8训练在相同加速平台上的峰值性能显著超越FP16/BF16，并且模型参数越大，训练加速效果越好。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_989c8ec6cc3c4e578e83c0f7b21731f6@5888275_oswg70865oswg952oswg538_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">计算优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p>总的来说，翟季冬认为：DeepSeek充分挖掘了算法、软件、硬件性能，实现了协同创新；其软件相对灵活，软件赋能硬件，弥补了硬件的很多限制；优秀的系统软件能够充分释放底层硬件的潜力。</p>
  <p>DeepSeek正是通过这一步步的优化，让整个模型的训练效率得到提升，并降低训练成本。</p>
  <h2><strong>03 “小米加步枪”式的成功</strong></h2>
  <p>经历了春节假期的喧嚣，我们对于DeepSeek的讨论应趋向理性。</p>
  <p><strong>我们不应神话DeepSeek，也不要因为外部的贬低而看轻DeepSeek，这些都对DeepSeek团队不公平。其实，DeepSeek就是一种“小米加步枪”式的成功。</strong></p>
  <p>行云集成电路创始人季宇最近跟我们聊起DeepSeek时说，创新的意识其实国内根本不缺，但缺乏Known-Why的创新往往会走向类似赌徒的歧途。</p>
  <p>“创新不是简简单单的不一样的技术路线，国内其实不缺乏创新性和天马行空的想象，其实无论AI行业还是算力芯片行业，都有无数走非Transformer架构、走非GPU架构、非冯诺伊曼架构的差异化路线，但是基本都陷入了用差异化的技术路线主流技术路线替代品的逻辑里。”季宇说。</p>
  <p>但是DeepSeek的创新是一步一个脚印的。</p>
  <p>季宇告诉我们，第一性原理思考问题很多人都在讲，但实际上非常困难。<strong>第一性原理需要深入推敲，需要对每个论断的边界条件，需要深入考虑各个层级技术的细节。</strong></p>
  <p>“之前跟在DeepSeek的一个师弟交流，梁老板（DeepSeek创始人梁文锋）对他写的CUDA Kernel里每个线程具体在干什么事情都非常清楚，只有这样才能从全局视角去思考突围的方式，真正把创新做成。”季宇说。</p>
  <p>这一点在另一位投资人那里也得到了印证。这位投资人去年曾问DeepSeek的人：“为什么你们的模型做得好？”</p>
  <p><strong>DeepSeek的人回答，因为我们老板自己在读论文、写代码、搞招聘。</strong></p>
  <p>关于DeepSeek的成功，你可以说他们有丰富的GPU储备，可以说他们对模型架构进行了创新，但其成功内核往往是朴实而简单的。</p>
  <p>DeepSeek创始人梁文锋去年接受《暗涌》采访时说过的一句话，既谦虚又意味深长。</p>
  <p>他说：“我们不是有意成为一条鲶鱼，只是不小心成了一条鲶鱼。”</p>
  <p>**参考资料：&nbsp;</p>
  <p>DeepSeek-V3 Technical Report,DeepSeek&nbsp;</p>
  <p>The Llama 3 Herd of Models,Meta&nbsp;</p>
  <p>GPT-4 Architecture, Infrastructure, Training Dataset, Costs, Vision, MoE,SemiAnalysis&nbsp;</p>
  <p>《夜话DeepSeek：技术原理与未来方向》，中国计算机学会青年计算机科学与技术论坛（CCF YOCSEF）</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/elQbehCVT8an2jC4unBHdQ" rel="noopener noreferrer nofollow" target="_blank">“甲子光年”</a>，作者：王博，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156441710664192</id>
            <title>大神卡帕西拿DeepSeek R1讲强化学习，最新大模型内部机制视频爆火，“没有技术背景也能看懂”</title>
            <link>https://www.36kr.com/p/3156441710664192</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156441710664192</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:11:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 卡帕西, 大语言模型, 教育, Eureka Labs  
<br><br>  
总结: Andrej Karpathy发布了一个三个半小时的视频课程，深入解析了大语言模型如ChatGPT的内部工作机制，适合没有技术背景的观众。课程涵盖了模型的预训练、监督微调和强化学习等多个阶段，并通过具体示例讲解了模型的原理和应用。卡帕西强调了教育的重要性，并创办了Eureka Labs，旨在通过AI与教师的共生，提升教育的可及性和质量。他的课程受到了广泛关注，吸引了众多网友熬夜观看。 </div>
                        <hr>
                    
                    <p>宣布全职搞教育的AI大神<strong>Andrej Karpathy</strong>（卡帕西），新年第一课来了——</p>
  <p>发布<strong>三个半小时视频课</strong>，深入解析了ChatGPT等大语言模型的<strong>内部工作机制</strong>，其中涵盖模型开发的完整训练过程、如何在实际应用中最有效地使用它们，还有AI未来发展趋势。</p>
  <p>卡帕西强调，这次是为大众准备的，<strong>即使没有技术背景也能看懂</strong>！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_adefebd91e2b448a977b819500c1a55f@5888275_oswg406445oswg594oswg1308_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他在视频中深入浅出用大量具体示例，如GPT-2、Llama 3.1等，完整讲述了大模型的原理。</p>
  <p>当红炸子鸡<strong>DeepSeek</strong>也没落下，成为一大重点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8fd74341a7a14e74a15882604677881c@5888275_oswg409823oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>卡帕西课程的含金量无需多言，刚一发就被网友团团围住，熬夜也要看的那种。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ed01df6f177043828bf135be87239c91@5888275_oswg46205oswg784oswg170_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网友们表示，接下来三个半小时就这样过了：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_93cf055cb9934c238652f2a55292c21f@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <blockquote>
   <p>你知道，Karpathy发布新视频，一整天都会变得非常美好，每个视频都是金矿！</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1c6238417432410fb78d89de548db78a@5888275_oswg40747oswg794oswg146_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>机器学习工程师Rohan Paul看后也表示其中有关于ChatGPT内部工作机制最简洁明了的解释。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_10ebc63993ea46e590731fcd38b3dc3c@5888275_oswg210573oswg784oswg706_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>话不多说了，以下是重点知识点，文末有完整视频～</p>
  <h2><strong>重点一览</strong></h2>
  <p>用过类似ChatGPT等工具的人可能都会有这样的疑问：</p>
  <p>这个文本框背后是什么？你可以在里面输入任何内容并按回车，但我们应该输入什么？这些生成的词又是什么意思？这一切是如何工作的？你究竟在与什么交流？</p>
  <p>卡帕西在视频中详细解答了这些问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5db56c07cbc24e1a85623d70a5a7e2f0@5888275_oswg47233oswg1080oswg246_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他从如何构建这样一个LLM展开，详细讲解了所有阶段：</p>
  <p><strong>预训练：</strong>数据、分词、Transformer神经网络的输入/输出及内部机制、推理、GPT-2训练示例、Llama 3.1基础推理示例。</p>
  <p><strong>监督微调：</strong>对话数据、“LLM心理学”：幻觉、工具使用、知识/工作记忆、自我认知、模型需要token来思考、拼写、参差不齐的智力。</p>
  <p><strong>强化学习：</strong>熟能生巧、DeepSeek-R1、AlphaGo、基于人类反馈的强化学习（RLHF）。</p>
  <h4><strong>预训练</strong></h4>
  <p>首先是预训练阶段，使模型拥有丰富的知识。</p>
  <p>预训练的第一步是<strong>下载和处理互联网数据</strong>。目标是从互联网的公开资源中获取大量且种类多样的文本、高质量文档，例如FineWeb。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7941792ce5804062b8ad02dc83db257f@5888275_oswg239456oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>第二步是<strong>文本提取</strong>。</p>
  <p>爬虫获取的是网页的原始HTML代码，需要过滤和处理提取出网页文本，去除导航和无关内容。</p>
  <p>还要进行语言过滤，例如只保留英语占比超过65%的网页，不同公司会根据需求决定保留的语言种类，如果过滤掉所有的西班牙语，那么模型之后在西班牙语上的表现就可能不会很好。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c05368351a454034959bdc1b6f0f5415@5888275_oswg310204oswg1080oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之后，还会进行去重、移除个人身份信息等进一步的过滤步骤，最终得到大规模的文本数据，进入训练集。</p>
  <p>接下来要做的是在这些数据上训练神经网络。在将文本输入神经网络之前，需要将文本转换为一维符号序列。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ae4ee428cd3c40e58c50a676cf840695@5888275_oswg917908oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>通过字节对编码（BPE）算法，将常见的字节组合成新符号，从而减少序列长度并增加符号词汇量。tokenization是将文本转换为符号序列的过程，不同的输入文本会根据tokenization规则生成不同的符号序列。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4760f96ae02c4e7290c693a48410ce90@5888275_oswg858801oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>训练神经网络时，从数据集中随机抽取token作为输入，并预测下一个token。神经网络的输出是下一个token出现的概率分布。</p>
  <p>通过训练过程不断更新网络参数，使预测结果与实际数据的统计模式一致。</p>
  <p>神经网络内部是一个复杂的数学表达式，输入token序列与网络参数混合，经过多层变换后输出预测结果。现代神经网络结构，如Transformer，具有大量参数和复杂的内部结构，但本质上是通过优化参数来使预测结果与训练数据匹配。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ac9646a4c2d34ff2ac7974bc009e8b07@5888275_oswg250614oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>训练过程需要强大的计算资源支持，依赖高性能GPU集群，这些硬件能够高效处理大规模并行计算任务，加速模型的训练和优化。随着技术的发展，训练成本逐渐降低，但大规模模型的训练仍然需要大量的计算资源投入。</p>
  <p>卡帕西在视频中以GPT-2为例讨论了训练，包括其参数、上下文长度和训练成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_08f57f8ddbe04d94ade541631826625a@5888275_oswg487532oswg1080oswg624_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之后他又以Llama 3为例讨论了基础语言模型的属性，它可以生成类似于互联网文档的token序列，并将知识存储在其参数中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fe64f174864445aebf0530248cfc3659@5888275_oswg564398oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然而，模型的输出具有随机性，每次生成的结果可能不同，且模型可能会过度记忆训练数据中的某些内容，导致输出与训练数据高度相似，甚至直接复述某些条目。</p>
  <p>这种现象在实际应用中可能会带来问题，例如模型可能无法区分事实和虚假信息，因为它只是基于训练数据的统计规律进行生成。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_cf36f74d4fa04d4586cf3fe06723ac34@5888275_oswg233426oswg1080oswg595_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>预训练阶段，模型通过大量互联网文档数据学习生成文本的能力，输出为基础模型，它能够生成与互联网文档统计特性相似的token序列，但本身并不是一个能够回答问题的“助手”。</p>
  <p>所以还需要后训练。</p>
  <h3><strong>后训练</strong></h3>
  <p>在后训练阶段，模型通过学习人类标注的对话数据来调整其行为，从而能够生成符合人类期望的回答。数据集规模较小，训练时间也相对较短。</p>
  <p>早期的对话数据集（如InstructGPT）主要由人类标注人员手工创建，但随着技术的发展，现代的对话数据集越来越多地利用现有的语言模型来生成初始回答，然后由人类进行编辑和优化。这些数据集可能包含数百万条对话，覆盖广泛的主题和领域。</p>
  <p>具体来说，后训练包括监督微调（SFT）和强化学习（RL）。</p>
  <p>在监督微调阶段，模型通过创建对话数据集，学习<strong>如何与人类进行多轮对话</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1d20ffea974f494e85374a49f9b6faa8@5888275_oswg268309oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>例如，OpenAI的InstructGPT论文详细介绍了如何通过人类标注者创建对话数据集。</p>
  <p>强化学习阶段，目的是让模型<strong>通过实践和试错来发现解决问题的最佳方法</strong>。</p>
  <p>卡帕西用人类在学校学习的过程类比。预训练相当于阅读课本中的背景知识，微调相当于学习专家提供的解题方法，而强化学习则相当于通过练习题来巩固知识，自己探索解题步骤。</p>
  <p>具体来说，模型会尝试多种不同的解题方法，这些方法可能来自不同的prompt。之后评估解决方案，检查每个解决方案是否正确。正确的解决方案会被标记为“好”，错误的解决方案会被标记为“坏”。</p>
  <p>模型会根据正确答案的解决方案进行训练，强化那些能够得到正确答案的解决方案。这类似于学生在练习中发现有效的方法后，会更多地使用这些方法。</p>
  <p>强化学习和人类标注相比，人类标注者在创建训练数据时，很难知道哪种解决方案最适合模型。人类标注者可能会注入模型不理解的知识，或者忽略模型已有的知识，导致模型难以理解。而强化学习让模型通过试错来自主发现适合自己的解决方案。</p>
  <p>模型会尝试多种路径，找到能够可靠地达到正确答案的解决方案。</p>
  <p>卡帕西用具体示例讨论了强化学习在大语言模型中的应用及其重要性，特别是<strong>DeepSeek</strong>最近发布的论文引发了公众对这一领域的关注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_702732cfe2b24eb8b0a4c7758212c41f@5888275_oswg311578oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他还讲了人类反馈的强化学习（RLHF）工作原理及其优缺点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fb5748c8c2f6411b857f2099c9d24f61@5888275_oswg185375oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后卡帕西提到了多模态模型的发展，模型能够将音频、图像和文本转化为tokens，并在同一个模型中同时处理。</p>
  <p>这种多模态能力将使模型能够进行更自然的交互，例如理解语音指令、处理图像内容等。</p>
  <p>目前局限性在于，模型执行任务时，通常是被动地接收任务并完成，无法像人类那样在长时间内持续、连贯地执行复杂任务。</p>
  <p>未来可能会出现能够持续执行任务的Agent，可以在长时间内执行任务，并定期向人类报告进度。人类将成为这些Agent的监督者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1a40f12dbf0946aabe2136ec78860496@5888275_oswg164256oswg1080oswg347_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>持续专注于教育的AI大牛</strong></h2>
  <p>卡帕西曾任特斯拉AI主管，之后去了OpenAI，去年2月从OpenAI离职。</p>
  <p>他在整个AI届拥有超高人气，很大一部分来自于他的课程。</p>
  <p>包括他自己的早期博客文字分享和后来的一系列Youtube视频教程，他还与李飞飞合作开设的的斯坦福大学首个深度学习课程CS231n《卷积神经网络与视觉识别》。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_723bf9db59804aa49b4c36a34f594049@5888275_oswg299850oswg1080oswg332_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今天不少学者和创业者，都是跟着他入门的。</p>
  <p>卡帕西对教育的热情，甚至可以追溯到学生时期在网上教大家玩魔方。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_05e3998cb8754de08dc9499ecf43c57c@5888275_oswg230719oswg1080oswg303_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>去年7月，从OpenAI离职的卡帕西突然官宣创业，搞了一家AI原生的新型学校——<strong>Eureka Labs</strong>。</p>
  <p>怎么理解AI原生？</p>
  <p>想象一下与费曼一起学习高质量教材，费曼会在每一步中1对1指导你。</p>
  <p>不幸的是，即使每个学科都能找到一位像费曼这样的大师，他们也无法分身亲自辅导地球上的80亿人。</p>
  <p>但AI可以，而且AI有无限的耐心，精通世界上所有的语言。</p>
  <p>所以卡帕西要打造“教师+人工智能的共生”，可以在一个通用平台上运行整个课程。</p>
  <blockquote>
   <p>如果我们成功了，任何人都将易于学习任何东西，扩大教育这个概念本身的“范围”和“程度”。</p>
  </blockquote>
  <p>目前在EurekaLabs的官方GitHub账号上也有相关课程了，手把手带你构建一个类似ChatGPT的故事生成大模型，感兴趣的童鞋可以去一睹为快。</p>
  <p>视频链接：https://www.youtube.com/watch?v=7kVfqmGtDL8</p>
  <p>参考链接：https://x.com/karpathy/status/1887211193099825254</p>
  <p>Eureka Labs：eurekalabs.aigithub.com/EurekaLabsAI</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/lBc0-8ByRxJ3JBJpMcfzkQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156431180667657</id>
            <title>为什么BAT没做出DeepSeek</title>
            <link>https://www.36kr.com/p/3156431180667657</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156431180667657</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:05:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, AI应用, 开源策略, 创新团队  
<br><br>  
总结: DeepSeek的迅速崛起在于其团队多年的深耕与技术积累，成功吸引了大量用户，日活用户在上线20天内突破2000万，成为全球增速最快的AI应用。与传统大厂依赖现有业务体系不同，DeepSeek以创新为核心，敢于从零开始，推动技术前沿的发展。创始人梁文锋强调中国AI不能永远处于跟随地位，必须实现原创与创新。DeepSeek的成功也促使大厂重新思考其创新逻辑，面临技术话语权的挑战。 </div>
                        <hr>
                    
                    <p>一夜之间，DeepSeek抢走了几乎所有国产大模型的风头。</p>
  <p>过去一年，无论是在C端出圈的Kimi，还是后在居上的豆包，无论是用户日活早早突破2亿的文心一言，还是登顶全球开源第一的通义千问，与DeepSeek给全球科技圈带来的震动相比，都逊色不少。</p>
  <p>这并非是一众国产大模型不给力，而实在是DeepSeek太优秀了。</p>
  <p>以前国内大厂一直讨论的是，距离OpenAI到底有多少年差距，但在DeepSeeK这里，却是另一番景象。市场热议的是DeepSeeK是否已经干翻了OpenAI，其所代表的开源路线，已经在倒逼OpenAI CEO山姆·奥尔特曼进行反思：“我个人认为，在这个问题上我们站在历史的错误一边。现在需要想出一个不同的开源策略。”</p>
  <p>DeepSeek的横空出世，其带来的影响不仅是在行业内，同样也更在C端市场。</p>
  <p>数据显示，仅仅上线20天，DeepSeek的日活就突破了2000万大关，成为全球增速最快的AI应用。与之相比，ChatGPT突破1500万大关花了244天，而DeepSeek仅用了18天。上线20天后的DeepSeek日活已达2215万，是ChatGPT日活用户的41.6%，并远超豆包日活用户的1695万。</p>
  <p>这是一场极其夸张的AI风暴，并且跟以往截然不同的是，这是一家真正由中国创业公司主导引发的AI风暴。</p>
  <p>问题在于，为什么是DeepSeek？</p>
  <p>要知道，过去两年国内主流的互联网大厂都在大模型赛道上投入重兵，也都跑出了不少产品，市场也普遍抱有期待，希望其中有谁能早上追上OpenAI，与硅谷AI一较高下。</p>
  <p>但最终破局的，却是DeepSeek，大厂没做到的，它反而实现了。</p>
  <h2><strong>深耕已久</strong></h2>
  <p>本质上DeepSeek当下的爆火，是一种厚积之下的爆发。</p>
  <p>虽说此次DeepSeek是一鸣惊人，但其团队早就在AI领域布局多年，时间线上甚至比大厂还早，布局宽度以及深度，也丝毫不比大厂差多少。</p>
  <p>公开数据显示，DeepSeek，由知名私募巨头幻方量化孕育而生，创始人为梁文锋。</p>
  <p>事实上，早在大学期间，即便在当时，人工智能还是一个空有理论并无实质的概念，但梁文锋无比笃信，“人工智能一定会改变世界”。</p>
  <p>这也成为了其创业以来的终极愿景。</p>
  <p>2015年梁文锋创办幻方，这是是国内最早使用人工智能进行量化交易的公司，2016年第一份由深度学习生成的交易仓位上线执行，2017 年全面应用深度学习技术进行交易。</p>
  <p>到了2018年，幻方官网将“把AI确定为公司的主要发展方向”写入公司大事，再一年，幻方干脆改变了组织架构，成立了幻方AI，对外自我介绍时总说自己是一家以大规模深度学习基础研究与应用为核心的人工智能公司。</p>
  <p>自2019年至2021年间，幻方相继自主研发了“萤火一号”与“萤火二号”AI集群，其中“萤火二号”投资达到10亿元，极大提升算力支持。同时，幻方也积极招募了一批算法科学家。而创始人梁文锋本人，则每天也都在写代码、跑代码。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_db730cb023e046fc9a5e5ea91e779bc5@5888275_oswg47005oswg899oswg673_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>技术上，一直在稳步储备，基建上，更是没有落下。</p>
  <p>可能很少有人能预料到，2023年当ChatGPT横空出世时，市场突然发现在国内，拥有高性能GPU芯片最多的不是人工智能公司，而是梁文锋旗下的幻方量化。</p>
  <p>彼时根据国盛证券研报，在云算力端，当时除了几家互联网公司（商汤、百度、腾讯、字节、阿里），就只有幻方有超过1万张A100芯片储备。</p>
  <p>足见，幻方对AI的投入，对比大厂，丝毫不落下风。</p>
  <h2><strong>反套路</strong></h2>
  <p>还有就是，以梁文锋为代表的DeepSeek创业团队的锐气。</p>
  <p>互联网大厂的AI战略往往依附于现有业务体系。腾讯的AI需服务于社交与游戏生态，阿里的AI需嵌入电商和云计算场景。这种业务协同逻辑，固然能快速商业化，却也框定了技术演进的路径——资源投入越多，越倾向于优化既有模式，而非另辟蹊径。</p>
  <p>而背靠幻方的DeepSeek，既有强大的财力支持，又有身为创业者敢于“从零开始”，不怕试错的勇气。这让DeepSeek只需要沿着创新的信念，一路蹚过去。</p>
  <p>对于创新，梁文锋的态度是非常坚决的——“过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。”</p>
  <p>“我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。”</p>
  <p>而如何实现创新，则是抛弃惯性的反套路。</p>
  <p>最直接的体现，就是在团队组成上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_70b2574b9e2d4ab989ae74cdeb5f5ef6@5888275_oswg615331oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来自于幻方官网</p>
  <p>国内大厂在进入大模型赛道上，通常倾向于去海外挖人，引入技术大牛，快速拉起一个团队，然后大干快上。而DeepSeek团队组多由本土一些Top高校的应届毕业生组成，不看经验资历，选人的标准一直都是热爱和好奇心。</p>
  <p>同时在工作机制上，“我们一般不前置分工，而是自然分工。每个人有自己独特的成长经历，都是自带想法的，不需要push他。探索过程中，他遇到问题，自己就会拉人讨论。不过当一个idea显示出潜力，我们也会自上而下地去调配资源。”</p>
  <p>“如果有想法，每个人随时可以调用训练集群的卡无需审批。同时因为不存在层级和跨部门，也可以灵活调用所有人，只要对方也有兴趣。”</p>
  <p>换句话说，大厂的组织架构，本质是一台精密运转的“效率机器”。但颠覆性创新的诞生，需要的恰恰是反效率的“失控”。</p>
  <p>而DeepSeek正做到了这一点。</p>
  <p>AI蓝媒汇也就为什么大厂没有做出DeepSeeK的问题，向DeepSeek提问，后者表示，本质上是组织惯性、商业化压力与技术路径共同作用的结果，并称：</p>
  <blockquote>
   <p>这场由开源模型引发的技术革命，正在倒逼大厂重新思考创新逻辑。若无法跳出既有框架，其技术话语权或将进一步削弱。&nbsp;</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d51d94661eba4efcab89ef03e32f5350@5888275_oswg229371oswg1080oswg1804_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/2d13vfq93sW9Ig63VrcpcQ" rel="noopener noreferrer nofollow" target="_blank">“AI蓝媒汇”</a>，作者：叶二，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156440683322121</id>
            <title>200亿，佛山要出资了</title>
            <link>https://www.36kr.com/p/3156440683322121</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156440683322121</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:05:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 产业基金, 佛山, 新兴产业, 投资  
<br><br>  
总结: 佛山市发布了总规模200亿元的佛山新动能产业基金，旨在推动新兴产业发展和产业转型升级。该基金将通过直接投资、母子基金和专项基金的形式，重点关注新型电力系统、机器人、新能源汽车等战略性新兴产业。佛山正处于新旧动能转换的关键阶段，设立产业基金有助于促进资本要素在金融市场和实体产业之间的流通。未来，佛山将发挥国资投资引领作用，确保投资的可持续性，推动传统与新兴产业的协调发展。 </div>
                        <hr>
                    
                    <p>产业基金开始热闹了。</p>
  <p>投资界-解码LP获悉，佛山市高质量发展大会日前召开，总规模200亿元的佛山新动能产业基金发布，连同N支市场化产业投资基金，组成佛山新动能产业基金体系。</p>
  <p>回顾过去一年，千亿产业基金接踵而至，城市之间发力新兴产业的迫切心情溢于言表。新年伊始，这场攸关城市命运的产业竞赛仍在继续。</p>
  <h2><strong>佛山发力：200亿，存续期15年</strong></h2>
  <p>佛山新动能产业基金体系具体有哪些内容？</p>
  <p>公告显示，该体系包括设立1支佛山新动能产业基金和N支市场化产业投资基金。其中，佛山新动能产业基金总规模200亿元，首期规模40亿元，存续期长达15年，彰显耐心资本。基金管理人则由佛山市国资委实控的佛山市金融投资控股有限公司担任。</p>
  <p>该基金以新动能命名，即向新质生产力要发展新动力。据悉，基金将通过“直接投资+母子基金+专项基金”的形式，重点聚焦产业链补链延链强链，着重投向三大重点领域——</p>
  <p>一是产业发展引导方向，重点投向新型电力系统装备、机器人、新能源汽车、新能源、新材料、新型储能、半导体芯片、新型显示、医药健康、低空经济等战略性新兴产业领域以及绿色氢能、生成式人工智能、细胞和基因治疗等未来产业领域的链主企业；</p>
  <p>二是科技创新专项方向，重点投向具备明显创新属性和成长潜力的种子期、初创期企业或项目；</p>
  <p>三是产业转型并购方向，重点投向先进制造业和传统优势产业的成长期、成熟期项目。</p>
  <p>而配套的N支市场化产业投资基金，将通过整合存量资源、引入社会资本联合设立。通过二者结合，佛山市将发挥市级统筹、国资投资引领作用，支持科技创新和产业转型升级。具体说来，即计划通过5年左右时间，推动形成覆盖企业全生命周期、突出重点投向、在市场上有一定影响力、规模不低于1200亿元的产业基金矩阵，通过“投大投强”“投早投小”“投稳投增”相结合，不断塑造发展新动能新优势。</p>
  <p>为何要打造这样的产业基金体系？据了解，佛山正处于新旧动能转换的关键阶段，民间资金十分充裕，金融机构本外币存款余额近3万亿元，位居全国地级市前列，但其转化为资本要素的动力却明显不足。</p>
  <p>而产业基金的设立，则有利于畅通资本要素在金融市场和实体产业之间的流通渠道，推动更好融入全国统一大市场建设；同时聚焦重大战略、重点领域和市场不能充分发挥作用的薄弱环节，推动产融深度对接，发挥基金引领带动作用，支持现代化产业体系建设，加快培育发展新质生产力。</p>
  <p>接下来，佛山将发挥国资投资引领作用，最大限度让这些民间资金动起来、活起来，作为“耐心资本”和“战略资本”倒逼佛山产业结构调整，实现传统与新兴产业“两条腿走路”，以更长期主义的方式，确保投资可持续性。</p>
  <h2><strong>吹响产业号角</strong></h2>
  <p>人勤春来早，新的产业竞赛已经在开工第一天打响。</p>
  <p>正如今年广东在全省高质量发展大会上表示，将一手抓传统产业、优势产业巩固优化，一手抓新兴产业、未来产业培育壮大，聚焦人工智能和机器人两大领域集中发力，建设更具国际竞争力的现代化产业体系。</p>
  <p>同时，广东发布《广东省建设现代化产业体系2025年行动计划》，直接提出充分用好私募股权基金、耐心资本作用，巩固提升20个战略性产业集群，抢先布局发展人工智能、机器人、低空经济、生物制造等新兴产业和未来产业，打造更多万亿元级、千亿元级产业集群，迫切心情不言而喻。</p>
  <p>还有江苏。去年通过江苏省战略性新兴产业母基金，接连组建两批产业专项基金，出资超过900亿。而在日前召开的“一中心一基地一枢纽”建设推进会中，江苏省再次强调：更大力度发展新兴产业和未来产业，紧扣“51010”战略性新兴产业体系，深入开展强链补链延链，打造一批世界级战略性新兴产业集群。</p>
  <p>此前以3000亿“3+N”杭州产业基金集群出圈，杭州也在日前会议上将发展新质生产力、强化创新产业布局视作重要目标。Deepseek总部所在的拱墅区，将在今年引进五大产业生态圈重点项目15个、亿元以上产业项目60个，推进高新技术产业投资增长；走出宇树科技的滨江区，则以产业创新牵引新型工业化，壮大人工智能等产业集群，争创省级人形机器人未来产业先导区；而培育了游戏科学、云深处科技的西湖区，力争人工智能、生命健康、空天信息三大产业产值达2200亿元。</p>
  <p>湖南则召开招商引资工作座谈会，提出创新招商方法，结合湖南实际积极探索产业链招商、平台招商等好机制好办法，吸引更多生产要素，延续去年成立金芙蓉、推动“4X4”产业体系发展的节奏；重庆“新春第一会”实施以“33618”现代制造业集群为核心的现代化产业体系做大做强行动，推动优势主导产业、新兴产业未来产业、传统产业“智改数转绿色化”、现代服务业4个“集聚成势”。</p>
  <p>目之所及，浩浩荡荡。</p>
  <p>创投兴则产业兴，产业兴则城市强。新春号角吹响，谁能在新一轮产业争夺战中勇立潮头，谁就能在下一轮城市洗牌中抢占先机。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/e30DiJxqEG5lsfAZwgwOgQ" rel="noopener noreferrer nofollow" target="_blank">“解码LP”</a>，作者：岳笑笑，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156441158327046</id>
            <title>2025年首月开户数披露，超去年6个月份</title>
            <link>https://www.36kr.com/p/3156441158327046</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156441158327046</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:04:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: A股, 新开户, 投资者, 政策红利  
<br><br>  
总结: 2025年1月，A股市场个人投资者新开账户达156.3888万户，显示出市场稳健开局。尽管较2024年部分月份有所回落，但市场情绪依然热情。2025年新开户趋势将受到政策红利、科技投资和资金结构优化等多重因素影响。年轻投资者的涌入和机构资金的长期布局将共同塑造市场新格局。政策的持续释放和科技主线的共振将推动开户增长，A股市场正经历从规模扩张向高质量发展的转变。 </div>
                        <hr>
                    
                    <p>上交所最新披露2025年1月A股新开股票账户数据。</p>
  <blockquote>
   <p>数据显示，2025年1月个人投资者新开A股账户达156.3888万户，机构投资者新开户数为0.6097万户。尽管较2024年部分月份的高点有所回落，但这一数据仍显示出市场在新年开局阶段的稳健态势。</p>
  </blockquote>
  <p>如何看156万的开户数据？2024年有6个月新开户数在150万以上，结合春节因素，可见2025年开年的市场情绪相对热情。这其中，2024年最低开户数是在8月份，仅新增开户99万户，其他低于150万户的月份分别为2月（129万户）、4月（147万户）、5月（126万户）、6月（107万户）、7月（115万户）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0d7dd47f7dca4bd7b132453af9ed2850@5888275_oswg247732oswg1080oswg837_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>展望2025全年，A股新开户趋势将受政策红利释放、科技投资主线及长期资金入市资金结构优化等多重因素影响，年轻投资者的涌入与机构资金的长期布局，将共同塑造更具活力的市场新格局。</p>
  <h2><strong>2025年1月A股新开户平稳开局</strong></h2>
  <blockquote>
   <p>根据上交所披露的《股票账户新开户状况表》，2025年1月A股市场个人新开户数环比2024年12月的198.0910万户下降约21%，同比去年1月下降19.74%，这其中一个重要因素在于2025年春节假期部分在1月。春节假期是一个重要影响因素，去年2月的129.1945万户开户就是一个相对低位。</p>
  </blockquote>
  <p>机构投资者方面，0.6097万户的开户数较2024年12月的0.8194万户有所减少，但较2024年全年均值0.6457万户（机构A股开户数全年累计7.7488万户）仍处于合理区间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5d0a9348530f4d4ea926cdaac1c39844@5888275_oswg99928oswg1080oswg319_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值得注意的是，B股市场的新开户数进一步萎缩。2025年1月个人B股新开户仅0.0390万户，机构B股开户0.0017万户，延续了近年来B股市场流动性不足、投资者兴趣转移的趋势。</p>
  <h2><strong>2025年A股新开户趋势将受多重因素影响</strong></h2>
  <p>2025年开年新开户数的平稳开局，为全年市场发展奠定了基础。展望全年，A股新开户趋势将受政策延续性、科技投资主线及资金结构优化等多重因素影响。</p>
  <p>一方面，政策红利持续释放，提振市场信心，证监会2025年重点工作明确“稳字当头”，包括深化投融资改革、支持科技创新等，叠加个人养老金入市扩大，长期资金增量可期。此外，外资券商加速布局（如高盛、城堡证券申请牌照），外资流入与境内资金形成合力，进一步吸引机构和个人投资者入场。</p>
  <p>另一方面，科技主线与年轻化需求将共振。数据显示，高风险偏好的“Z世代”投资者占比翻倍，其偏好ETF、量化产品等工具，推动被动投资占比提升。政策对“新质生产力”的倾斜（如AI、机器人）或成为2025年开户增长的新引擎。</p>
  <p>与此同时，A股资金供需将持续优化，2025年预计险资等增量资金规模达千亿元级别，ETF持续成为主力增量来源，为散户提供低门槛入场渠道。同时，减持新规抑制大股东抛售，解禁规模低位运行，市场稳定性增强，有利于吸引中长期投资者。</p>
  <p>当下A股市场正经历从规模扩张向高质量发展的深刻转变。新开户数据的稳健增长，既是市场活力的体现，也是投资者对中国经济长期向好的信心投票。未来，在政策红利释放、科技创新驱动、国际化进程提速的多重助力下，A股有望成为全球资本配置的重要目的地，为投资者创造可持续的价值回报。</p>
  <h2><strong>回顾：政策催化2024年开户潮</strong></h2>
  <p>回顾2024年，A股新开户数据呈现明显的“波浪式”特征。从全年来看，个人投资者新开A股账户累计达2492.1440万户，机构账户7.7488万户，其中，2024年10月个人开户数飙升至683.9747万户，单月数据远超其他月份，成为全年最大亮点。</p>
  <p>2024年9月，一揽子政策组合拳落地，直接推动10月新开户数飙升至683.97万户，单月数据超过前五个月总和。政策红利释放叠加股市赚钱效应，吸引大量新股民入场，券商一度因“开户潮”加班应对。</p>
  <p>从开户结构来看，2024新开户投资者中，“85后”和“90后”占比超六成，“00后”参与度快速提升，30岁以下投资者占比从政策前的15%跃升至30%。线上开户渠道（如支付宝接入）成为重要推手，凸显年轻群体对便捷化服务的偏好。</p>
  <p>2024年新增开户从开户渠道、年龄段、入金情况、投资品种以及投资方向等方面，都展现出多样化。不同年龄段的投资者通过多元化的开户渠道涌入市场，各自有着不同的投资风格和偏好。在入金和投资方向上，虽然整体表现出一定的谨慎，但也不乏对市场热点和政策导向的积极响应。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/mzy57s9nEs-oyYPOtu5I5g" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”</a>，作者：王晨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156396318129670</id>
            <title>Deep Seek爆火后，AI军备竞赛2.0要来了吗？</title>
            <link>https://www.36kr.com/p/3156396318129670</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156396318129670</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:57:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <Deep Seek, 人工智能, AI军备竞赛, 薪资待遇>
<br>
<br>
总结: Deep Seek在春节期间引发了广泛关注，成为中美苹果免费应用排行榜的第一名，超越了Chat GPT。其以低训练成本实现与顶级AI模型相媲美的性能，促使科技股大幅波动。多家科技巨头宣布与Deep Seek合作，显示出市场对其技术的认可。Deep Seek的团队薪资待遇较高，吸引了大量人才，尤其是在AI领域。与此同时，Deep Seek也面临着仿冒网站和不法课程的挑战，提醒用户提高警惕。 </div>
                        <hr>
                    
                    <p>在春节期间，唯一能和“赛博秧歌队”争抢热度的选手，或许只有Deep Seek了。</p>
  <p>毕竟前者为我们带来了来自硅基生命的“生理震撼”；后者为我们带来了来自硅基生命的“智力震撼”。</p>
  <h2><strong>AI军备竞赛 2.0要来了</strong></h2>
  <p>作为一家人工智能初创企业，来自杭州的深度求索可谓在春节期间出尽了风头。</p>
  <p>1月27日，该公司旗下应用Deep Seek冲上中美苹果免费应用排行榜第一名，在力压Chat GPT成为各地用户心目中的“AI一哥”之余，为美国科技股带来了行业巨震。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_798e252aede341009aedff1bd2dcde07@5322854_oswg149080oswg646oswg520_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在数据层面，芯片巨头英伟达当日股价暴跌近17%、半导体公司AMD股价下跌6%、博通公司股价下跌17%，微软、Meta、谷歌母公司Alphabet等耳熟能详的名字，也均在本起事件中出现了不同程度的股价波动。</p>
  <p>究其原因，是因为DeepSeek-V3以极低的训练成本换来了同Claude Sonnet 3.5、GPT-4o等业内顶级模型相媲美的性能。用摆在眼前的产品让世界各地的AI企业、科技公司意识到盲目堆积算力本质上是一种“力大砖飞”的行为，是对公司资金储备、投资人注资的盲目消耗。</p>
  <p>毕竟除DeepSeek-V3外，在两个月内研发、基础计算能力投资不到600万美元的DeepSeek-R1同样可以和那些花费数亿、数十亿美元所研发的模型“掰掰手腕”。 再一次用实力证明了“足够精巧的算法”可以实现性能与成本的平衡，让人工智能模型的开发成本不再以“亿”为单位。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5ac1ba5d205e4c03add677c57355d73a@5322854_oswg690582oswg660oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>市场是敏锐的，即便Deep Seek刚刚引发了美国科技股巨震，但这仍不能撼动海外企业同其合作的热情。</p>
  <p>江苏省科协在2月6日发布的文章指出，目前英伟达、微软、亚马逊这三家老牌科技巨头，已经宣布了自己和Deep Seek达成合作的消息，正式决定接入DeepSeek-R1用以提升自己在AI时代的产品竞争力。</p>
  <p>另在国内市场。</p>
  <p>人民邮电报在2月7日发布的文章也指出，三大运营商（中国移动、中国联通、中国电信）已宣布全面接入Deep Seek，并希望将其同自身平台、资源相融合。以此在打通Deep Seek多场景、多产品应用生态的同时，加速“AI普惠”这一愿景的实现进程。</p>
  <h2><strong>Deep Seek薪资待遇曝光</strong></h2>
  <p>在这段时间里引发网友关注的，不仅有Deep Seek系列模型的交互能力，还有Deep Seek团队成员的工资待遇。</p>
  <p>通过对Deep Seek的母公司幻方量化进行调研，有媒体发现其当下招聘的重心分别为数据研发工程师、深度学习研究员、核心系统研发工程师，工作地点则多在杭州或北京。</p>
  <p>在薪资待遇层面，公司除采用“14薪”制度外，还为大部分岗位提供了2万+/月的起薪。至于“深度学习研究员（AGI）”这类人才竞争更激烈的岗位，其月薪待遇更是被推上了8-10万/月。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a021e114e11f485a9ea9a5c3a3e1be47@5322854_oswg143034oswg694oswg552_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此以外，在Deep Seek团队内薪资相对较高的岗位还有数据研发工程师、核心系统研发工程师，其薪资范围分别在4-7万/月、7-8万/月。甚至AGI岗位实习生的工资也高达500-1000/每天，算下来可轻松实现“月薪上万”的人生目标。</p>
  <p>值得一提的是，此前雷军以千万年薪为代价挖来的“AI天才少女”罗福莉，其另一层身份便是Deep Seek团队的前成员（她曾以深度学习研究员的身份参与了DeepSeek-V2的开发项目）。雷军将罗福莉招致麾下担任小米AI大模型团队领导者的决定，也在一定程度上向我们展现了当下各科技公司对Deep Seek成员的认可度如何。</p>
  <p>《2024年度人才迁徙报告》指出，在2024年的TOP 20热招岗位中，有5个同AI相关场景有关。其中算法工程师、大模型算法、自然语言处理、人工智能工程师等岗位均属于热门职位。</p>
  <p>另截止到2024年12月，中国的生成式人工智能产品用户规模已高达2.49亿人，约占整体人口的17.7%。在巨大的用户需求、用户规模面前，当前就业市场的大模型、人工智能相关人才储备也略显不足。以至于有行业报告预测在2030年，中国的AI人才缺口将高达400万。</p>
  <p>以上种种信息也让我们意识到，在未来相当长的一段时间内，不仅人工智能专业会成为广大学生的T1级选择；其相关赛道员工的待遇，也将随着用户规模、需求的进一步放大而成为众人羡慕的对象。</p>
  <h2><strong>AI也逃不过人红是非多</strong></h2>
  <p>俗话说人红是非多，AI也不例外。</p>
  <p>爆火的Deep Seek不仅吸引了投资者和常规用户的目光，还吸引到了一小撮不怀好意的人。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2b3e6414a93b435887ca332bd8fb7cc2@5322854_oswg60555oswg915oswg420_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2月6日，奇安信发布报告表示在2024年12月1日-2025年2月3日这一区间内，共出现了2650个仿冒Deep Seek的网站。而这些躲在“山寨网站”背后的人，或是希望借Deep Seek之名窃取个人信息，或是欲披着Deep Seek的“马甲”去传播恶意软件骗取订阅费用。</p>
  <p>另除注册钓鱼网站外，目前市面上还有大量打着“Deep Seek带你躺着赚钱” “如何用Deep Seek赚到100万”等旗号的付费课程。甚至连AI爱好者平日里进行交流的社区，也有人趁机推出了Deep Seek的付费交流群，以“缴纳会员费和业内大佬互动交流”的名义进行敛财。</p>
  <p>这些情况的出现，也在提醒着我们对于普通人而言，想要玩好Deep Seek的第一步也是最重要的一步，就是学会甄别互联网上的信息，帮自己规避那些山寨网站和把“割韭菜”三个字写在脸上的付费教程。</p>
  <p>正如中国通信标准化协会互动媒体标准推进委员会副主席包冉所言，普通用户根本不需要去购买所谓的教程，因为使用Deep Seek不需要再像之前一样打磨提示词，现在各大主流AI都可以直接用自然语言与其交流。</p>
  <p>在过去，AI付费教程崛起的核心概念便是信息差的存在。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_02df10e948a344c7b7be03c1b1e69005@5322854_oswg138144oswg536oswg654_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>由于技术的相对不成熟，当时的模型往往需要用户输入特定的指令集才能得到应有的反馈。所以人们才会去总结自己和AI对话的经验，将其编撰成特定的话术和行文格式，帮助小白用户提升自己的使用体验。</p>
  <p>但随着模型蒸馏、数据训练进程的全面展开，今天Deep Seek的对话能力已经得到了充分升级。所谓的“结构化对话教程”已经成为了过去式，用户只需要进行简单的口语化、日常化指示就能得到自己想要的反馈。</p>
  <p>更别提市面上有不少AI培训课的内容仅仅是对互联网公开信息的拼凑，部分卖家完全不在乎内容的质量如何，他们不过是想赶在“淘金热”到来之际发上一笔“铲子财”罢了。</p>
  <p><strong>参考：</strong></p>
  <p>江苏省科协：三家企业同日宣布接入 DeepSeek，AI 领域竞争进入新阶段</p>
  <p>人民邮电报：三大运营商全面接入DeepSeek加速AI普惠发展进程</p>
  <p>上海杨浦：DeepSeek高薪招人：实习生月入上万，研究员年薪百万！这类人才缺口400万→</p>
  <p>齐鲁壹点：2000多个山寨DeepSeek网站出现，DeepSeek回应来了！</p>
  <p>极目新闻：第一波用DeepSeek“搞钱”的人出现了</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA5MTI5NDgxNA==&amp;tempkey=MTMwOF9ocVUyV2d3Y2xtZzlQd0FkWFhMYkhaOG9BcVY2eVJDRXgwTnJyQ2x2TlRXX1JmbUI1cjRacHBONENmVDFwRWxaNVljRncyV1VXc0IyaHJfRW5MdUhma2ZGeDRYTTkwa0h1cUU2N0oxZVg0anBvMmpXM0dGLWtqaF82akV2NUhFVXo2UExWLWhiN1kzcGpQLW9Ha0FOcE1CQ0lmanByRnpmQUdjd25Rfn4%3D&amp;chksm=0afe0cab3d8985bd05203c857d14b54f5e6ae4eacbd9381364d929ef2ebb922113177d158630&amp;scene=0&amp;xtrack=1&amp;subscene=7#wechat_redirect" rel="noopener noreferrer nofollow" target="_blank">“互联网那些事”</a>，作者：互联网那些事，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156385750368002</id>
            <title>15年来，“谷歌们”与中国未“脱钩”</title>
            <link>https://www.36kr.com/p/3156385750368002</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156385750368002</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:54:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <谷歌, 反垄断, 出海, 开源>
<br>
<br>
总结: 文章讨论了谷歌在中国市场的反垄断调查及其与中国企业的商业关系。尽管谷歌在2010年退出中国市场，但其在华收入依然增长，尤其是与字节跳动的合作。文章还提到，Tiktok等中国企业在全球市场的迅速崛起，显示出中国企业出海的趋势与能力。与此同时，开源技术的合作也在不断深化，尤其是在安卓生态中，中国企业通过开源降低了开发成本并推动了技术进步。整体来看，全球化与技术合作仍是推动商业发展的重要因素。 </div>
                        <hr>
                    
                    <p>2月4日，市场监管总局官方宣布，对谷歌公司展开反垄断调查。没错，就是美国那个谷歌，虽然新闻不少，但好像跟中国用户没什么关系，他怎么就垄断了？</p>
  <p>媒体分析，谷歌的“垄断”可以涉及在线广告领域，也可能涉及安卓手机系统方面。</p>
  <p>这条新闻唤起了很多人一个久远的回忆。2010年，谷歌宣布退出中国市场，谷歌搜索搬至香港。因此，谷歌好像错过了中国移动互联网大爆发的黄金时代。</p>
  <p>与谷歌境遇相似，全球规模和市值最大的企业中，市值1.76万亿美元的Meta（Facebook）和市值2.5万亿美元的亚马逊 —— 一个挤破头也没有挤进中国市场，一个节节败退，已经停止运营。</p>
  <p>但是，商业与技术总是卷起狂风，难以阻挡。从2010年到现在这15年来，谷歌、Meta、亚马逊与中国从未“脱钩”，因为大家共同活在历史的进程中。</p>
  <h2>出海浪潮下，商业合作永不眠</h2>
  <p>2018年是一个有趣的年份。这一份，特朗普正式对华发起了贸易战。中美的经贸关系进入了一个新阶段，很多人断言，中美关系“再也回不去了”。</p>
  <p>然而，也就是这一年，据The information 报道，谷歌在华收入增长60%，成为了过去15年间增长最快的一年。</p>
  <p>为什么这一年增长如此迅猛？当年，谷歌最大的中国客户是字节跳动，那正是抖音海外版Tiktok强势出海的时候。那年谷歌在大中华区（中国大陆+港澳台）收入30多亿美元，其中，字节跳动向谷歌支付了3亿美元，占10%。</p>
  <p>Tiktok在2018年开启了疯狂出海之旅。谷歌旗下的YouTube，Meta旗下的Facebook、Instagram以及面向年轻人的社交平台Snap上疯狂投放广告。 MediaRadar 数据，2018至2020年三年间，Tiktok的全球营销总费用高达50亿美元。</p>
  <p>疯狂营销的同时，Tiktok也迎来了疯狂的增长。2018年，Tiktok的月活用户同比增长近3倍。Statista数据，2024年4月，Tiktok月活用户数超过15.82亿，成为全球第5大最受欢迎的社交App，前4名分别是Facebook、YouTube、Instagram和WhatsApp。</p>
  <p>明明开打贸易战，为什么Tiktok仍能迅猛出海？其实，2018年，抖音的月活用户突破5亿，正式超越快手，成为中国最大的短视频平台。于是，验证了产品和商业模式之后，抖音的创始人张一鸣相信，地球人其实都一样，挡不住短视频和推荐算法的诱惑，所以挥师出海。</p>
  <p>基于自身和行业的需求出海，而并不受到贸易战的影响，这是2018年中国企业出海的一个新特点。</p>
  <p>Tiktok也是中国企业加速出海的缩影。过去15年，中国企业不再局限于做跨国企业的供货商。他们走向消费市场，直面消费者。谷歌、Facebook，就是中国企业出海的最大广告平台，亚马逊，则是中国商品的最大海外销售平台。三者分工合作，联通全球市场。</p>
  <p>谷歌、Meta、亚马逊都在中国大陆保留了团队。从公开信息上看，谷歌的团队规模最大，广告营销团队就超过100人，全国有20多个广告中心。在北京海淀区的融科资讯大厦，谷歌中国办公室占据了5-7层。同时，谷歌在中国还有庞大的代理商体系。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_09cdb147c53242f19814c90b190d449b@14303255_oswg241668oswg1080oswg958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（谷歌中国办公室位于北京海淀的融科大厦，据悉，AI明星企业深度求索的北京办公室，也在这座楼里。）</p>
  <p>不过，谷歌退出中国市场，也留下了后遗症。一位做线上营销的朋友说，跟客户推荐在谷歌做营销，有两个难点，一是客户以为google已经退出中国了，二是以为google只有搜索引擎。</p>
  <p>除了搜索引擎，谷歌系的Youtube、Google Play应用商店，Meta旗下的Facebook、Instagram、WhatsApp和Messenger，以及全球最大的电商平台亚马逊，都是重要的在线营销平台。</p>
  <p>不管怎么说，出海企业利用三巨头阵地，走向海外市场。中国企业的拿手好戏，就是通过广告营销和买量，推动新的应用快速起步。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fed272f296134992831315df0bc90f11@14303255_oswg62377oswg1034oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（Temu在超级碗投放的广告）</p>
  <p>外媒曾经震惊到，拼多多旗下的Temu2023年在美国进行了30亿美元的广告投放（伯恩斯坦研究公司估算数据），而另一家市场机构Morketing则把Temu列为了2023年美国十大广告主之一，排在迪士尼之前。</p>
  <p>Temu的核心广告语是“像亿万富翁一样购物”，通过程序化广告等不同的投放方式，这句话不断投放到各类社交媒体上，投放到网页广告上，甚至投放到美国春晚“超级碗”上，并根据数据反馈不断优化效果。</p>
  <p>与Temu在海外相爱相杀的是服饰电商Shein。Shein是互联网版的Zara，通过快速模仿，并快速在instagram、facebook上请网红带货，迅速走红。</p>
  <p>Shein是互联网版的Zara，通过以女装为主的快时尚服饰起家，它充分利用Instagram、Facebook、YouTube等主流社交媒体平台，联合各路网红，进行品牌推广。Shein打通了“种草+电商”的模式闭环，吸引了大量年轻消费者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0fe4f5cbd7b3409dbf1bda9f694ac662@14303255_oswg58404oswg803oswg319_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（Shein在海外的增长数据）</p>
  <p>尽管Shein经常被称为“新加坡公司”，但其供应链、制造和研发核心仍然在中国。2023年，Shein登上了全球购物App下载榜的首位。有预测称，Shein2025年的营收将达到585亿美元，并可能在今年一季度以505亿英镑的估值在伦敦证交所上市。</p>
  <p>Temu和Shein，二者背靠的都是全球规模最大，生产能力最强的制造业大国，面向的又是北美这个全球最大的消费市场。2018年以来，虽然贸易战从未停下，但随着2020年“口罩”后的美联储大放水，中国对外贸易顺差加大，Temu和Shein无疑顺应了这一历史进程。</p>
  <p>同样，还有众多中国品牌也参与到这一进程中。不过，他们无力像Shein那样自建网络平台，通过亚马逊销售一直是首选。</p>
  <p>2021年，B站网红UP主“老师好我叫何同学”改装了一款升降办公桌，加上了可移动的无线充电接口、蓝牙音箱等一系列智能化改装和设计，视频迅速走红。这款升降桌的原型来自上市公司乐歌股份，乐歌的股价随之涨停。</p>
  <p>此前，乐歌股份在国内并不出圈，它是一家典型的在海外先富起来的中国品牌。乐歌旗下的品牌flexispot一直在亚马逊升降桌品类中稳居榜首。</p>
  <p>类似这样的品牌很多，大疆无人机、安克Anker等，在智能家居设备（如扫地机器人）、家电、手机配件、服饰等品类上，中国产品都已经打响了品牌。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8273910399bc4c60aa5bf4e8ace621ac@14303255_oswg404846oswg1080oswg683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图片说明：亚马逊销售的大疆无人机）</p>
  <p>更多白牌产品，则通过跨境电商卖家的努力，同样在亚马逊畅销。据Marketplace Pulse的研究，中国卖家占亚马逊美国站TOP卖家的近50%。</p>
  <p>近年，中国的娱乐产品正在冲击欧美市场。中国游戏行业出已经成风之外，过去两年，短剧也冒出了头。</p>
  <p>用大众文化产品冲击美国市场，这是过去一百年，中国人难以想象的一种变化。这大概也论证了，人类在底层需求上是相通的。</p>
  <p>谷歌、Meta和亚马逊，无论自己的C端业务在国内发展的情况如何，始终抓紧中国市场。</p>
  <p>早在10年前，白熊观察员作为财经记者，一直在跟踪跨境电商发展。在深圳，一个跨境电商行业协会主办的年会上，谷歌、亚马逊和Meta的销售代表，先后在不同的分论坛上登场演讲，推销自己的产品和服务。</p>
  <p>活动的主要参会者，是广东、福建等地数以百名各类跨境电商企业的老板们。</p>
  <p>那正是奥巴马时代，经历了08年金融危机后，美联储开足水龙头，持续放水。另一方面，具备超强制造能力的中国企业，生产的产品在国内难以消化，出海仍然是最佳选择。</p>
  <p>虽然也有一些类似乐歌、安克这样的企业，在出海成功后，又杀回了国内市场，但更多的企业还是在加速出海。某种程度上说，2021年以前，中国消费者的消费欲主要在楼市上，2021年之后，中国消费者对房子的消费欲突然就消失了，而且并没挪到别的地方——虽然大家还是愿意看《哪吒2》这样的好电影，但“内需”确实不够理想，这种现状也引发了无数争议。</p>
  <p>国信证券研报数据，从2019年起，谷歌、Meta和亚马逊三巨头在全球广告市场（不包括中国地区）的占比从41%增长到60%左右。这形成了事实上的垄断。彭博社预计，2024年谷歌的广告收入为2639亿美元，Meta预计为1595亿美元，亚马逊预计为563亿美元。</p>
  <p>特别值得注意的是亚马逊，依靠电商广告收入增长，它最近三年的年复合增长率达到60%。</p>
  <p>三巨头的成功中，中国的企业贡献不少。Meta首席财务官Susan Li曾在财报会上表示，“2023年度，来自中国客户的广告投放方投入构成了Meta总收入的10%，并贡献了Meta 5%的收入增量。其中，在线电商和电子游戏公司是中国厂商的投放主力。”</p>
  <p>亚马逊的数据显示，中国企业贡献了第三方服务收入（2023年为1400亿美元）的“很大一部分”。同时，中国品牌出海也是亚马逊广告收入增长的重要动力。</p>
  <p>不过谷歌没有透露来自中国的收入占比。这两天有自媒体称，中国企业出海广告有“67%流向谷歌系平台”，这个数据很可能是AI编造的，因为谷歌的广告市场份额只有不到三成。另一方面，中国企业更是在不断开拓新的阵地，避免对合作伙伴形成依赖。2019年，Tiktok是美国年轻人喜爱的社交应用Snap最大的广告主，同时它在线下也进行了大规模的推广。</p>
  <p>此外，谷歌云和AWS等云服务与中国企业的合作也不断深化。据公开报道，谷歌云与国内多家企业联合推出AI、大数据等解决方案；亚马逊AWS帮助中国企业实现全球云部署，合作规模已达数十亿美元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0ac5dded6e664dafa508e74663820c41@14303255_oswg254327oswg361oswg501_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当然，中国企业的崛起，也在挑战着三巨头的垄断地位。</p>
  <p>Tiktok顶着美国政府的封禁大棒，也成为了重要的广告投放平台。据《晚点LatePost》报道，2021年Tiktok的广告收入约为40亿美元，而市场机构测算，2023年它的广告收入可能已达到132亿美元，2024年预计能有300亿美元。随着Tiktok等平台的崛起，2022年以来，谷歌和Meta在美国市场的广告份额已经跌破了50%。</p>
  <p>Temu和Shein的崛起，已经强烈冲击了美国同行。第三方数据，Temu用了三年时间杀到了美国电商的第六名，并占据了17%的美国市场份额。Shein成为美国五大在线时尚电商之一，占据快时尚服饰在线消费市场的40%份额。</p>
  <p>这本应该是商业社会的常态，竞争与合作永远是共生的，也永远不会停歇。然而，今年特朗普再次上台之后，贸易战跟七年前已不可同日而语。就在昨天，白宫叫停了中国寄往美国的“邮政小包”免税政策。通过邮政小包，以较低的运费将商品卖到美国，这正是跨境电商控制成本的秘诀。尽管这个政策维持了半天就暂停了，</p>
  <p>历史虽然常常相似，但很少真正重复，这一次又会如何发展？</p>
  <h2>技术合作，在开源的旗帜下</h2>
  <p>近年，国产手机崛起，已经一统除了苹果之外的手机市场，似乎已经没有谷歌什么事，当然我说的是在国内。</p>
  <p>但安卓，仍然是大家绕不过去的名字。有人说，谷歌可能是中国用户最多的美国公司。不过这个说法很不准确，因为安卓本身是一个开源生态。</p>
  <p>开源社区起源于1980年代，开源软件往往会公开源代码，参与者可以自由查看、修改和分发。开源社区不仅有各类技术极客，也有各种科技企业。包括谷歌、Meta和亚马逊三巨头，也包括许多中国企业。企业积极参与开源生态，因为这是一种把蛋糕做大的方式。</p>
  <p>2007 年 11 月，Google 联合 84 家硬件制造商、软件开发商、电信运营商及芯片供应商成立了开放手持设备联盟（Open Handset Alliance），并打造了Android开放平台。</p>
  <p>2007年，正是全球化快速扩张阶段，中国等新兴国家不断融入世界贸易体系，这也是WTO作用最大化的阶段。与此同时，移动互联网时代兴起，新兴国家也在积极参与信息技术的变革，安卓开源操作系统为新兴国家参与移动互联网时代提供了便利，在经济和技术变革进程交织推进的时代里，它得到了各国的积极响应。</p>
  <p>不过，也就是2007年，中、印、俄、巴西等国家展开了多次双边和多边会谈，这为2009年“金砖国家峰人”（BRICS）做好的准备，新兴国家开始争取更大的话语权。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c0508a0270b0496e964b8450869d6777@14303255_oswg15950oswg600oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Android 的核心——AOSP，允许任何人免费使用、修改和再分发，全球的开发者和厂商都可以在此基础上定制和改进自己的操作系统。</p>
  <p>所以，谷歌虽然主导了安卓操作系统，但并不拥有安卓的用户。因为随着市场发展，单纯使用原生安卓并不足以形成竞争优势。国内企业借助安卓的开源生态，大幅定制用户界面和系统功能，形成了如 MIUI（小米）、EMUI（华为）、ColorOS（OPPO）、Funtouch OS（vivo）等品牌定制系统。这些系统在视觉和交互体验上更加符合中国消费者的审美和使用习惯。</p>
  <p>目前安卓生态已经成为了移动市场的绝对主流。安卓的市场份额，从2008年的不到1%增长到如今绝占85%。中国的主流手机厂商，都是安卓生态的一部分，即使像华为如今开始了自研手机操作系统。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5e9f101805e54fcb8f95305895d05b2a@14303255_oswg25118oswg1011oswg324_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>共建生态，本质就是一种全球的技术合作。</p>
  <p>以前有一种论调：在安卓的开源生态领域，中国企业贡献不大，因为安卓系统的底层代码，绝大多数是谷歌、高通、三星等企业贡献的，中国企业参与甚少。</p>
  <p>这是事实的一部分，而非全部。中国企业确实在参与安卓生态。对于中国企业来说，利用开源安卓系统，低操了作系统开发的成本和风险，企业可以将更多资源投入到软件优化和生态服务构建中。</p>
  <p>中国企业也在应用层、服务和中间件开发等做了不少开发，繁荣了安卓生态。</p>
  <p>例如，华为开发的EROFS文件系统，通过透明压缩和只读设计提升了手机启动速度和安全性，这个文件体系统已经开源。</p>
  <p>小米则利用MiCode平台，开源了大量内核定制、MACE神经网络计算框架、Open-Falcon监控系统和Pegasus分布式存储系统。</p>
  <p>开源可以说是一种商业选择，但也确实是一种技术文化。</p>
  <p>但是伴随着全球化成长起来的技术文化传统，遇到了新的问题。在贸易战加剧的背景下，“脱钩”成为媒体的高频词。高层在博弈，大众很担忧，所以，研发更加“自主可控”，更加“安全”的信息操作系统，变成一种必然。</p>
  <p>华为率先推出了完全自研的鸿蒙操作系统，并最终脱离安卓生态，其它厂商也开始跟进。安卓联盟虽然没有瓦解，但很少有厂商主动宣传。</p>
  <p>但这并不意味着开源合作时代的终结，相反，可能才刚刚开始。随着生成式AI时代的到来，开源成了通往人工智能殿堂的一条大道。中国也成为了少数站在生成式AI开源前沿的国家。</p>
  <p>在安卓时代，谷歌、高通完善安卓底层源代码，华为、小米研大量新应用，这似乎是一种理所应当的局面。这种局面在AI大模型时代刚刚到来的时候，也沿用了下去，甚至像朱啸虎这样的资深投资人，把这种模式当成最合适的道路。不过，没过多久，中国的工程师们就不再只局限于“做应用”了。</p>
  <p>2022年，当ChatGPT横扫AI大模型领域之时，也是闭源大模型遥遥领先于开源之日。那时，Meta及其创始人扎克伯格，却成了开源领域的旗手。扎克伯格率先将Llama1、Llama2模型开源，其中Llama2模型是当时全球最大的开源模型，性能上也接近ChatGPT4.</p>
  <p>为什么是他？这可以说是Meta的一种商业策略，也可以说是扎克伯格技术极客的底色。尽管在Facebook成功后，扎克伯格经常被媒体当作唯利是图的奸商。在生成式AI时代，扎克伯格对于技术前沿展现了很强的判断力。之后，更多的开源大模型涌在市场上，中国也出现了大模型“六小龙”等把研发AI大模型当成方向，而不只是做应用的公司。</p>
  <p>当然，热闹之下鱼龙混杂。也有一些公司，似乎在将Llama等开源模型改头换面，包装成“自研”的大模型，也就是所谓“套壳”。当时有一种说法叫“百模大战”，各类企业都号称做出了自己的“大模型”，但最后发现，套壳相当普遍。</p>
  <p>阿里巴巴前副总裁贾扬清就曾爆料了一家这样的企业，有人挖掘出，这家公司疑为李开复的创业项目“零一万物”的中英双语大模型“YI”。不过李开复很快发声称，不存在套壳、抄袭等行为，是从零开始训练，只是沿用了Llama的架构。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_94b285c8fa7543e48d2b68eb3aa2ba6d@14303255_oswg128659oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（Llama的本义是“羊驼”，颇有喜感的名字，图片为豆包AI生成）</p>
  <p>不管怎么说，如今，中国企业成为AI大模型领域开源生态最重要的贡献者。例如，2023年，阿里的通义千问Qwen大模型打响了开源第一枪。之后阿里将Qwen大模型各类不同的版本进行了全家桶式的开源。业界普遍认为，阿里开源的Qwen全家桶，性能不逊于Llama。</p>
  <p>刚刚过去的这个春节，中国AI企业深度求索的开源大模型DeepSeek-R1引发生成式AI领域的一次地震，AI大模型算是一次真正意义上的“出圈”。DeepSeek-R1也是一个开源大模型。</p>
  <p>DeepSeek-R1 在工程技术方面实现了一次突破，采用高效的模型压缩与优化技术，证明了可以用更少的算力，实现更强的性能，显著降低了训练与部署成本。</p>
  <p>开源生态正在越来越强盛。2月6日，有“AI教母”之称的李飞飞及其团队，号称只用了不到50美元，就训练出一个名为S1的模型，它在数学和编码能力能够比肩OpenAI的o1和DeepSeek的R1等尖端推理模型。研究人员表示，s1是通过蒸馏法由谷歌推理模型Gemini 2.0 Flash Thinking Experimental提炼出来的，谷歌的Flashi Thinking正是谷歌发布的一个具备很强能力的开源模型。</p>
  <p>此前，一直坚守闭源模型领域李彦宏在发布上说，“开源模型会越来越落后”。这个观点引发了很大的争议，现实给了他一个新的回应。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_765bc4dd9cb740e68d02aca2b2510c27@14303255_oswg37582oswg655oswg452_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图片为文心一言发布会截图）</p>
  <p>开源的繁荣，为人们提供了更多的探索玩法。其实，DeepSeek此前发布的V3版本大模型已经引发了业界的广泛关注。不同类型的优秀开源大模型，甚至可以通过技术手段进行整合。</p>
  <p>例如，DeepSeek-R1-Distil-Qwen-7B就是基于Qwen-7B进行蒸馏优化的推理模型，其参数量为7B，专注于数学、代码和推理任务，它利用R1模型将通义千问的Qwen核心能力提取并得到更小的模型，同时显著利用的DeepSeek-R1系列模型在推理速度和资源消耗上的优势。</p>
  <p>DeepSeek-R1-Distil-Qwen-7B不仅免费开放，还支持开发者进行修改和二次开发。一位金融公司的IT负责人向白熊观察员证实，这种小模型已经被它们应用在需要快速反应的数据分析领域。</p>
  <p>开源生态的重要价值，不仅在于提供了有用的东西，还在于避免踩雷。在信息不畅通的时代，“重复造轮子”是一个常态，前人走的坑，后人却需要再走一遍，浪费了大量的时间、金钱和精力。</p>
  <p>DeepSeek的成功，就是中国企业在研发过程中首次站到前沿技术的潮头，去探索未知的领域，主动试错，主动“蹚雷”。DeepSeek的成果，将给行业带来很多新的启发。</p>
  <p>另一方面，DeepSeek的创始人梁文锋在接受采访的时候说，要实现AGI，不按照Llama的结构走，这样才能在有限的资源下，实现更强的模型能力。梁文锋踩在了前人的肩膀上，实现了一次跨越。</p>
  <p>政治局势的变化，不仅引起贸易战，更引发了“技术战”。美国等一些国家的政客开始呼吁审查DeepSeek，开源生态的未来也蒙上了一层阴影。</p>
  <p>从历史上看，每一次技术革命后，技术扩散都是必然，问题是时间。</p>
  <h2>白熊观察：</h2>
  <p>从历史和现实看，全球化可能是个无法真正逆转的过程。全球化推动了商业和技术的发展，它也让人们紧密联系到了一起。</p>
  <p>过去三十年，全球化是全球技术进步、商业繁荣最重要的推动力之一，少数国家没有汇入全球化浪潮，不管嘴上怎么说自己国民生活幸福，天天被太阳照耀，恐怕都难以让人羡慕。</p>
  <p>如今，全球化陷入暂时的波折，一些人以狭隘的政治利益为借口，破坏全球化合作，制造分裂和对抗，这恐怕是一股逆流。</p>
  <p>是的，我说的就是美国的特朗普。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/sdm6pxVxls0k-eJpURUjVg?token=846157393&amp;lang=zh_CN" rel="noopener noreferrer nofollow" target="_blank">“白熊观察员”</a>，作者：白熊观察员，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156385170521858</id>
            <title>Meta内部信息泄露，6款AI产品将到来，国内厂商如何应对？</title>
            <link>https://www.36kr.com/p/3156385170521858</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156385170521858</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:50:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, AI可穿戴设备, 内部备忘录, 竞争市场  
<br><br>  
总结: Meta首席技术官安德鲁·博斯沃思在内部备忘录中透露，Reality Labs部门计划在2025年推出6款AI可穿戴设备，以增强销售和用户参与度。备忘录强调2025年将是Meta的重要一年，尽管2024年已取得成功，但仍需进一步发展。国内厂商在Meta Ray-Ban智能眼镜热销后，面临激烈竞争，需依靠产品力和渠道合作来生存。各家厂商正通过提升硬实力和与传统眼镜品牌的合作，力争在即将到来的百镜大战中脱颖而出。 </div>
                        <hr>
                    
                    <blockquote>
   <p>泄露的不止是信息，还有Meta的野心</p>
  </blockquote>
  <p>近日，一份Meta泄露的内部备忘录被披露，该备忘录是由 Meta 首席技术官安德鲁·博斯沃思 (Andrew Bosworth) 撰写，备忘录中预告了其 Reality Labs 部门预计会推出6款AI可穿戴设备，以此扩大此前由Meta Ray-Ban所带来的优势。</p>
  <p>众所周知，得益于多模态 AI 大模型的推动，Ray-Ban Meta 的热销刺激，2025年 AI智能眼镜市场热度空前，众多厂商都在为百镜大战做着准备，而面对Meta的6款AI产品，最终谁能成功站稳脚步呢?</p>
  <h2><strong>Meta放大招，6款AI 可穿戴设备</strong></h2>
  <p>据Business Insider分享，这份备忘录的标题为“2025：伟大之年”，于去年 11 月发送给 Reality Labs 员工。这份备忘录很长，包含不少公司励志演讲以及2025年的大致计划。</p>
  <p>Reality Labs是Meta旗下负责Quest头显和Horizon软件平台、Ray-Ban Meta智能眼镜技术、以及AR眼镜和sEMG腕带输入设备研发的部门。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_effef0cb365f4f578d9257542451ce00@813924438_oswg130204oswg692oswg368_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在备忘录中，Bosworth称2025年是“我在Reality Labs八年来最关键的一年”，并告诉员工他们将推出6款左右的AI可穿戴设备来“推动销售、用户留存和参与度的全面增长”。“从数据上看，2024年是我们迄今为止最成功的一年，但我们并没有沾沾自喜，因为我们知道这还远远不够。我们还没有真正在世界上留下印记”，他宣称。</p>
  <p>从字面上理解，Bosworth 的备忘录中表明 Meta 有六款 AI 可穿戴设备——而且听起来它们都将于今年推出。结合此前的消息，Meta可能预计在 2025 年推出的产品可能包括：</p>
  <p><strong>1、马克·扎克伯格预告的第三代 Meta Ray-Ban 智能眼镜：</strong>据知情人士透露，新眼镜将在单侧镜片内嵌小型显示屏，虽然未透露具体规格，但结合"支持拍摄预览"的功能描述，行业推测该显示屏将采用全彩技术。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_53c8c61124b84edd96efcaac2384e6cd@813924438_oswg395720oswg648oswg518_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>2、AI 智能眼镜的 Oakley 版本：</strong>彭博社记者马克·古尔曼报道称，Meta和EssilorLuxottica计划在今年晚些时候通过Oakley Meta眼镜来扩展其智能眼镜产品阵容，Oakley眼镜的摄像头则位于中央，面向“骑行者和运动员”用户。</p>
  <p><strong>3、腕带：</strong>此前有消息称Meta正在测试一种让用户依靠腕带来控制眼镜的方法。该公司曾讨论过将该配件与Hypernova眼镜放在同一个盒子中，后者的镜框镜腿上也将有触摸控制。如果腕带配件不符合要求，镜腿方法将成为标准输入方法。这款腕带控制器类似于Meta去年展示的Orion原型AR眼镜所使用的控制器。</p>
  <p><strong>4、带有摄像头的耳机：</strong>去年The Information报道了Meta Platforms正在探索开发带有摄像头的AI耳机，这种耳机可能会用于识别物体和翻译外语。在内部，该项目名为Camerabuds，将摄像头和电池放入微型设备中可能会使耳机体积庞大，并有使其过热的风险。将隐蔽的摄像头安装到可穿戴设备上也可能引发隐私问题。</p>
  <p><strong>5、AI智能手表：</strong>早在2021年，The Verge就报道过Meta正在开发一款智能手表。据说该设备有两个摄像头：一个在前面用于视频通话，一个在后面用作运动摄像头，因为手表的主体可以很容易地从框架上拆卸下来。古尔曼认为这款手表可能想要与苹果产品竞争，可以与Hypernova配合使用，并显示用眼镜拍摄的照片。</p>
  <p>结合此前的消息，目前只猜测出了5款AI可穿戴设备，剩下的一种会是什么呢?或许只有5款，因为我们注意到备忘录中Bosworth所写的 “half a dozen” ，鉴于这句话取自泄露的内部备忘录而非官方声明，所以多方猜测所谓的6款可能只是粗略计算，而非确切的六种。</p>
  <p>这个名为《2025：伟大之年》的备忘录无疑彰显了Meta的野心以及2025年的来势汹汹。那么国内厂商又会如何应对呢?</p>
  <h2><strong>超越Meta的同时，与眼镜品牌合作</strong></h2>
  <p>事实上，尽管有的国内厂商在宣传上称自己早已有AI眼镜的相关计划，但这句话在Meta Ray-Ban 智能眼镜爆火后再说出来已经难以令人信服。</p>
  <p>但从竞争的角度看，无论是先于Meta还是跟注Meta，想要在百镜大战中存活下来，需要做的只有靠产品力说话。其中，将这一点看得最清楚的或许是雷鸟V3 AI拍摄眼镜。</p>
  <p>在雷鸟V3&nbsp;AI拍摄眼镜的发布会上，雷鸟将自身产品与Meta Ray-Ban进行了近乎全方位的对比。从第一人称拍摄、音质、AI等硬实力到充电速度、重量、乃至价格，都完成了对Meta Ray-Ban的超越。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7ab0f88a24104232aaa6a9a1f164c60d@813924438_oswg78848oswg715oswg346_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Meta在2025年将推出的多款AI可穿戴设备必然是优于曾经的明星产品Meta Ray-Ban，而想要在众多厂商押注AI眼镜以及曾经的明星产品续作下占据市场，超越与创新是为数不多的道路。</p>
  <p>而除了产品本身足够能打外，渠道也是国内厂商能够依靠的一大优势。AR厂商Rokid的AI+AR 眼镜——Rokid Glasses，选择与依视路旗下知名时尚眼镜品牌暴龙眼镜进行联名。</p>
  <p>雷鸟则更加“激进”，选择与博士眼镜成立合资公司，共同开发新一代 AI 眼镜。除此之外，星纪魅族、 XREAL、界环，李未可等AR眼镜厂商也都在不同程度上与博士眼镜有着紧密合作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_11647c5f18f74e8b9b2e2ba18ba9085b@813924438_oswg145670oswg659oswg396_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种合作意味着厂商们更加重视作为一副眼镜的基础体验，比如外观设计、佩戴体验以及验光配镜服务等。然后再是智能体验的融入，并借助传统眼镜品牌的渠道和品牌优势，让智能眼镜渗透到更广泛的消费者群体中。</p>
  <p>随着百镜大战的日益到来，各家厂商都试图通过增强硬实力的同时完善视光、设计、渠道的做法，力争在众多竞争者中脱颖而出。</p>
  <h2><strong>写在最后</strong></h2>
  <p>Meta的内部备忘录让我们看到了其野心之大，而国内厂商对此似乎早已准备好了应对办法，这场百镜大战中究竟是Meta守擂成功继续扩大优势，还是其它品牌异军突起抢占市场，科技旋涡也会持续关注相关动态。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/6YjO8LaYB7qeupOvkY-MUA" rel="noopener noreferrer nofollow" target="_blank">“科技旋涡”</a>，作者：科技旋涡，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156400790526725</id>
            <title>DeepSeek爆火后，美国科技巨头面临灵魂拷问</title>
            <link>https://www.36kr.com/p/3156400790526725</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156400790526725</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:27:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI投资, DeepSeek, 科技巨头, 资本支出  
<br><br>  
总结: 本文讨论了美股科技巨头在AI领域的大规模投资与中国初创公司DeepSeek推出的低成本AI模型之间的对比。DeepSeek以不到600万美元的成本推出的R1模型在某些方面表现出色，引发了对科技巨头们数百亿美元投资必要性的质疑。尽管高管们认为继续投资是满足AI需求的战略优势，但投资者对其回报的担忧日益加剧。DeepSeek的崛起被视为对全球AI竞争格局的影响，促使市场重新审视科技巨头的投资策略。 </div>
                        <hr>
                    
                    <blockquote>
   <p>在本次财报季，美股科技巨头们正面临一场严峻的拷问：在中国AI初创公司DeepSeek以不到600万美元成本推出可媲美OpenAI的R1模型后，大笔砸钱还有意义吗？</p>
  </blockquote>
  <p>在本轮财报季上，美股科技巨头们正面临一场严峻的拷问。</p>
  <p>一边，是Meta、谷歌、亚马逊等科技巨头继续着他们每家动辄<strong>数百亿美元规模</strong>的大手笔AI投资计划；另一边，是大洋彼岸的中国AI初创公司DeepSeek以<strong>不到600万美元</strong>的开发成本推出开源的R1模型，而在某些方面的表现甚至媲美OpenAI的o1模型。</p>
  <p>差距悬殊的资金规模对比，让华尔街和硅谷开始质疑，原本的假设：科技巨头们必须投入巨资在芯片和数据中心上才能构建尖端人工智能模型，真的还成立吗？</p>
  <h2><strong>大规模砸钱还有必要吗？</strong></h2>
  <p>今年初的财报季上，各大科技公司一如既往地宣布在AI领域投入巨资。而华尔街开始拿起放大镜，格外严肃地审视这些巨额资本支出计划，光四大科技巨头总计今年将投入约3200亿美元：</p>
  <blockquote>
   <p>Meta计划2025年资本投入600-650亿美元，用于推动人工智能战略。</p>
   <p>微软承诺今年投入800亿美元用于AI基础设施，以扩大其全球高性能数据中心网络，满足训练和运行AI模型所需的专用芯片需求。</p>
   <p>谷歌预计2025年将在资本支出方面投入750亿美元，较去年激增逾42.7%，比分析师预期高将近30%。</p>
   <p>亚马逊计划将今年的资本支出从去年的约830亿美元提高到1000亿美元。公司CFO表示，支出的增长“主要与AWS有关，包括支持对我们人工智能服务的需求，以及支持我们北美和国际部门的技术基础设施。”</p>
  </blockquote>
  <p>如果换在几个月前，这样数以百亿美元计的投资规模可能并不会引起华尔街太多的质疑，因为当时几乎所有人都信奉着一个假设：只有依靠大笔投资，才能在当前最重要的AI竞赛中拨得头筹。</p>
  <p>然而，在DeepSeek的AI模型的横空出世之后，这样的假设出现了裂痕。</p>
  <p>根据DeepSeek公开的数据，DeepSeek-V3这个参数量高达671B的大模型<strong>，在预训练阶段仅使用2048块GPU训练了2个月，且只花费557.6万美元。</strong>与此同时，该模型相比其他前沿大模型，性能却足以比肩乃至更优。</p>
  <p>在这样的背景下，很多投资者开始质疑：科技巨头们的大笔砸钱还有意义吗？</p>
  <h2><strong>质疑声已经响起</strong></h2>
  <p>上周，在DeepSeek-R1模型引发的震惊声中，美国科技股已经大跌。而本周，随着美股科技巨头们公布“大规模砸钱”计划，Meta、谷歌、亚马逊的股价几乎无一例外地立即遭到砸盘。在这背后，很显然能看出华尔街投资者们对于科技巨头们砸钱策略的质疑。</p>
  <p>Futurum Group 分析师丹尼尔·纽曼表示：“考虑到这些巨额开支，他们（美股科技巨头们）急需提高AI的收入回报，但目前发生的事情（DeepSeek）对美国来说是一个警钟……<strong>就目前而言，人工智能的资本支出实在太多，但消费却不足。”</strong></p>
  <p>Direxion资本市场主管Jake Behan表示：“资本支出开始让人感觉像是房间里的一只800磅重的大猩猩。现在的问题几乎不在于人工智能支出何时能够盈利，而在于它是否能够合理化。”</p>
  <p>在微软财报公布后，Valoir分析师 Rebecca Wettemann表示，DeepSeek 的崛起让一些投资者担心，微软可能因全力支持 OpenAI 及其基础设施而押错了宝：</p>
  <blockquote>
   <p>"我们不认为所有公司都会立即转向DeepSeek，但<strong>DeepSeek发布的低成本、低资源消耗的AI模型表明，AI在未来将变得更加商品化。</strong>真正的差异化在于支持更高准确性、安全性和满足特定需求定制化的平台功能，这也是微软需要投资的方向。"</p>
  </blockquote>
  <p>持有微软股份的 Zacks Investment Management 投资组合经理 Brian Mulberry 表示，在看到微软的大规模投资计划后，他确实感到担忧：</p>
  <blockquote>
   <p>“我们确实希望开始看到一个更清晰的发展路线图，了解所有已投资资本的盈利模式是什么样的。”</p>
  </blockquote>
  <h2><strong>公司高管：大笔砸钱才能建立战略优势</strong></h2>
  <p>尽管质疑声四起，但科技巨头公司的高管们仍然普遍认为表示，继续大规模投入对于满足日益增长的AI需求是必要的。</p>
  <p>META CEO扎克伯格表示，他仍然相信大力投资公司的人工智能基础设施会成为战略优势。</p>
  <blockquote>
   <p>“现在就对基础设施和资本支出的走势做出判断可能还为时过早，”扎克伯格说。“这里同时出现了一系列趋势。”</p>
  </blockquote>
  <p>他坚信：“长期来看，大力投资资本支出和基础设施将成为一种战略优势。”</p>
  <p>扎克伯格似乎淡化了DeepSeek带来的威胁。他表示，这个行业在不断变化，DeepSeek的出现只是这种潮起潮落的一部分：</p>
  <blockquote>
   <p>“我认为他们（DeepSeek）做了许多新颖的事情，我想我们仍在消化这些事情，他们还有很多东西......我们希望在我们的系统中实现。”</p>
  </blockquote>
  <p>微软CEO萨蒂亚·纳德拉则认为，增加AI支出将有助于缓解限制公司充分利用人工智能的能力的产能问题。他补充说，随着人工智能变得更加高效和广泛可用，“我们将看到需求呈指数级增长。”</p>
  <p>Meta 首席人工智能科学家Yann LeCun还特意解释了人们对于AI投资成本的质疑。<strong>他解释称，在DeepSeek崛起后，投资者对美国科技巨头股票的抛售，其实是源于对AI基础设施投资的“重大误解”。</strong></p>
  <p>他强调，广为流传的DeepSeek的600万美元成本额，是单次训练成本，而不包括前期的投入成本。尽管这一训练成本的确很低，但不能以此来单独与科技公司们的全部投资额来作对比。</p>
  <p>LeCun 表示：<strong>“这些数十亿美元的资金中，很大一部分都投入到了推理基础设施中，而不是训练基础设施中。</strong>为数十亿人运行人工智能助手服务需要大量的计算。一旦你将视频理解、推理、大规模内存和其他功能纳入人工智能系统，推理成本就会增加。”</p>
  <p>无论科技巨头们的决策如何，不可否认的是，DeepSeek的出现已经如同一个搅局者，影响了全球AI赛道的竞争格局。</p>
  <p>据研究公司 SimilarWeb估计，在短短一周内，DeepSeek网站的用户数量就已经超过了谷歌的 Gemini 聊天AI（后者已经存在了近两年）。而未来，这场AI赛跑的格局变化，还值得进一步关注。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/4vekiYti7z6N8NmVRyRVJQ" rel="noopener noreferrer nofollow" target="_blank">“财联社AI daily”</a>，作者：刘蕊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156402166553348</id>
            <title>国产 DeepSeek V3 被秒成"前浪"？谷歌开放最强 Gemini 2.0 全家桶：速度快60倍，上下文还长16倍</title>
            <link>https://www.36kr.com/p/3156402166553348</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156402166553348</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:26:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <谷歌, Gemini 2.0, 人工智能, 模型>
<br>
<br>
总结: 谷歌发布了功能强大的人工智能模型套件Gemini 2.0，包含多个版本如2.0 Flash和2.0 Pro，旨在提升开发者的创作和协作能力。Gemini 2.0 Flash以其低延迟和高性能受到欢迎，支持多模态输入，并在基准测试中表现优异。2.0 Pro则专注于编码性能，能够处理复杂提示词。尽管用户对模型的性能给予积极反馈，但也对其使用限制和复杂性表示不满。谷歌的目标是让AI的能力接近人类水平，未来将推出更多功能。 </div>
                        <hr>
                    
                    <p>昨日夜里，谷歌向所有人发布了 Gemini 2.0——迄今为止谷歌“功能最强大”的人工智能模型套件。</p>
  <h2>谷歌 Gemini 2.0 向所有人开放</h2>
  <p>去年 12 月，谷歌发布 Gemini 2.0 Flash 的实验版本，正式开启了代理型 AI 的新时代。Gemini 2.0 Flash 是谷歌为开发者群体打造的高效主力模型，具有低延迟、高性能等优势。今年早些时候，谷歌在 Google AI Studio 中更新了 2.0 Flash Thinking Experimental，通过将 Flash 模型的惊人速度与复杂问题的推理能力相结合，进一步提高了性能表现。</p>
  <p>上周，谷歌面向桌面及移动设备端的全体 Gemini 应用用户发布了 2.0 Flash 更新版本，希望帮助更多人以全新方式使用 Gemini 进行创作、互动和协作。</p>
  <p>如今，谷歌将通过 Google AI Studio 和 Vertex AI 中的 Gemini API 向公众发布更新之后的 Gemini 2.0 Flash。开发人员现已可以使用 2.0 Flash 模型构建生产级应用程序。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7561c1c3bc69479fbaeb91069784edbe@5888275_oswg75784oswg972oswg786_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>谷歌还发布了 Gemini 2.0 Pro 的实验版本，这是谷歌旗下迄今为止编码性能最强、最善于处理复杂提示词的大模型</strong>。除了在 Google AI Studio 和 Vertex AI 当中使用之外，Gemini 2.0 Pro 也将在 Gemini 应用中面向 Gemini Advanced 用户开放。</p>
  <p>此外，谷歌将在 Google AI Studio 和 Vertex AI 中公开预览迄今为止最具成本效益的模型方案 Gemini 2.0 Flash-Lite。</p>
  <p>最后，2.0 Flash Thinking Experimental 将被添加在桌面和移动设备端的模型下拉菜单中，以供 Gemini 应用用户随时使用。以上提到的所有发布模型都将支持带有文本输出的多模态输入，且在未来几个月的通用版本中还将支持更多模态。</p>
  <h3>2.0 Flash：面向全体用户带来更新</h3>
  <p>Flash 系列模型首度亮相于 I/O 2024 大会，作为一种强大的主力模型广受开发者欢迎。Gemini 2.0 Flash 提供全面的功能，包括原生工具使用、100 万个 token 上下文窗口和多模式输入。它目前支持文本输出，具有图像和音频输出功能，并且计划在未来几个月内全面推出 Multimodal Live API。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e9b4901d878d4e8aba54cfbda63b7d88@5888275_oswg120758oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2.0 Flash 现已在谷歌 AI 产品中面向更多用户正式发布，同时在关键基准测试上的性能也得到了提升。图像生成与文生语音等功能将在不久之后推出。</p>
  <p>感兴趣的用户可以通过 Gemini 应用 或者 Google AI Studio 及 Vertex AI 中的 Gemini API 立即体验 Gemini 2.0。</p>
  <h3>2.0 Pro Experimental：谷歌编码性能最好的模型</h3>
  <p>在分享 Gemini 2.0 早期实验版本（例如 Gemini-Exp-1206）的过程中，谷歌收到了开发人员对其优势及最佳用例（例如编码场景）的极佳反馈。</p>
  <p>作为对这些反馈的回应，谷歌已经发布 Gemini 2.0 Pro 的实验版本。与之前已经发布的各类大模型相比，Gemini 2.0 Pro Experimental 拥有最强大的编码性能与复杂提示词处理能力，而且可以更好地理解并推理世界知识。该模型配备有谷歌旗下最大的上下文窗口，可容纳 200 万 token，这使其能够全面分析并理解大量信息，并可调用谷歌搜索及代码执行等其他工具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_90714f4e44ae4fb09b1e67f75d3b8b0f@5888275_oswg162943oswg640oswg988_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Gemini 2.0 Pro 现在以实验模型的形式向 Google AI Studio 和 Vertex AI 中的开发者，以及 Gemini Advanced 用户开放。这部分用户可通过桌面及移动设备端的模型下拉菜单立即体验。</p>
  <h3>2.0 Flash-Lite：谷歌最具性价比的模型</h3>
  <p>谷歌方面称，此前收到了大量关于 1.5 Flash 模型价格和运行速度的积极反馈，公司一直在保持成本和速度水平的同时不断努力提高模型质量。此次推出的 2.0 Flash-Lite 是一款质量优于 1.5 Flash 的新模型，且继续保持后者的速度和成本优势。2.0 版本在大多数基准测试中均优于 1.5 Flash。</p>
  <p>与 2.0 Flash 一样，2.0 Flash-Lite 版模型的上下文窗口可容纳 100 万 token 并支持多模态输入。例如，它可以一次性为大约 4 万张不同照片生成单行标题，且此项操作在 Google AI Studio 付费套餐中的成本不到 1 美元。</p>
  <p>Gemini 2.0 Flash-Lite 已经在 Google Ai Studio 和 Vertex AI 中提供公开预览版。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0f84fb6f42e54705a926581abee960f2@5888275_oswg160210oswg1080oswg681_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2>用户反馈怎么样？</h2>
  <p>谷歌首席科学家、AI 大佬 Jeff Dean 盛赞了 Gemini 2.0 Pro 的编程能力。他在 X 上发贴称对于 Gemini 2.0 Pro 编程能力感到惊讶。他表示：“我喜欢 Boggle 游戏（一种填字游戏）。这个演示展示了我们的 Gemini 2.0 Pro 模型在 AI Studio 中的编码能力。令人难以置信的是，它可以通过一个相对简单的提示，编写出完整的代码，包括所有正确的数据结构和搜索算法，以在 Boggle 游戏板上找到所有有效的单词。作为一名计算机科学家，我也很高兴它第一次就正确地完成了数据结构。” 他还幽默地用了 “Discombobulating!” （令人困惑 / 震惊）来形容。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4213cf5ef0e440ca9f4cdb780bd2dc0b@5888275_oswg217113oswg960oswg420_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Gemini 2.0 的全面发布引起了网友的广泛关注。InfoQ 旗下极客时间专栏作者林健（键盘） 得知 Gemini 2.0 Flash 上线后立即接入 API 试用，他在 X发贴称，Gemini 2.0 Flash 在长文本、成本和吞吐量等方面的表现优于 DeepSeek V3 和 GPT 4o-mini。</p>
  <p>尤其是与 DeepSeek V3 对比时优势明显（按后台的数据粗算，不计缓存 token）。Gemini 2.0 Flash 的成本比 DeepSeek V3 低 6 倍、输出速度快 60 倍、上下文长 16 倍，更重要的是还原生支持所有模态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_11cea4b69c2441a58c05ce17fbb5e769@5888275_oswg203580oswg1080oswg766_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b57a6fa895ae460aab21019d5a42fcde@5888275_oswg263644oswg1080oswg932_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也有 X 用户将 o3-mini-high、Gemini 2.0 Flash 和 Gemini 2.0 Pro 放在一起跑了几个基准测试进行性能比较。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4021ac5eabeb4e479e3a93dfa32e82ed@5888275_oswg107000oswg1080oswg456_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在综合性能表现中，Gemini 全家桶中的 2.0 Pro 在所有类别中排名第一，2.0 Flash 排名第三位，2.0 Flash Lite 则以更低的成本挤进了前十名。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0506e5b0352d4df199a237cd50fe127f@5888275_oswg466535oswg1080oswg890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>尽管在很多基准测试中 Gemini 系列模型都打败了同类模型，但基于 Gemini 衍生出来的产品还是被用户疯狂吐槽。</p>
  <blockquote>
   <p>我不使用 Google Gemini 的首要原因是它们会截断输入文本。因此我无法简单地将长文档或其他类型的内容作为原始文本粘贴到提示框中。</p>
  </blockquote>
  <p>甚至无法在 Gemini 中上传文档，只能上传图片。在 Hacker News 上，ID 名为 heavyarms 的用户表示：</p>
  <blockquote>
   <p>“我上次（也就是几天前）再次使用 Gemini 时，还是发现它只有一个‘上传图片’选项... 而我断断续续玩了几个月的 Gemini，却从来没有真正上传过图片。这基本上就是我对目前大多数 Google 产品的看法：不成熟、有缺陷、令人困惑、不直观。”</p>
  </blockquote>
  <p>而且谷歌这些模型的各种版本使用时的限制条件也让人摸不着头脑。有用户吐槽：</p>
  <p>“简单来说，我今天花了一个小时想弄清楚怎么用‘深度研究’这个功能，结果还是没搞明白。我买了 Gemini Advance 的商业办公标准版，但不确定是不是还需要 VPN、额外付费买 AI 产品，或者升级到更高级的办公套餐。谷歌的产品线太复杂了，各种功能互相交织，搞得人一头雾水。我都开始怀疑，谷歌作为 AI 提供商到底靠不靠谱了。”</p>
  <p>谷歌的 API 也饱受用户诟病。</p>
  <blockquote>
   <p>使用 Google API 通常会让人感到沮丧。事实上，我喜欢他们提供的最佳基础云服务，但他们的附加 API 却杂乱无章。在这些与 AI 相关的 API 中，谷歌的 API 是最糟糕的。</p>
  </blockquote>
  <h2>大模型下一步：各方面能力无限接近人类水平</h2>
  <p>无论从大模型的部署和使用成本，还是性能上来讲，大模型的下一步目标很明确：让 AI 的能力无限接近人类水平。听起来很科幻，但其实已经在路上了。</p>
  <p>谷歌在 12 月份的一篇博客文章中写道：“在过去的一年里，我们一直在投资开发更多的代理模型，这意味着它们可以更多地了解你周围的世界，提前思考多个步骤，并在你的监督下代表你采取行动。”并补充说，Gemini 2.0 在“多模态性方面取得了新进展——比如原生图像和音频输出——以及原生工具的使用”，并且该模型系列“将使我们能够构建新的人工智能代理，让我们更接近通用助手的愿景。”</p>
  <p>Anthropic 是一家 由亚马逊支持的人工智能初创公司，由前 OpenAI 研究主管创立，是开发 AI Agent 竞赛中的关键参与者。10 月，Anthropic 表示其 AI Agent 能够像人类一样使用计算机来完成复杂的任务。这家初创公司表示，Anthropic 的计算机使用能力使其技术能够解释计算机屏幕上的内容、选择按钮、输入文本、浏览网站并通过任何软件和实时互联网浏览执行任务。</p>
  <p>Anthropic 首席科学官贾里德·卡普兰 (Jared Kaplan) 当时在接受 CNBC 采访时表示，该工具“基本上可以像我们一样使用计算机”。他说，它可以完成“数十甚至数百步”的任务。</p>
  <p>OpenAI 最近发布了一项类似的功能，名为 Operator，它可以自动执行诸如计划假期、填写表格、预订餐厅和订购杂货等任务。OpenAI 将 Operator 描述为“可以上网为您执行任务的 Agent”。</p>
  <p>本周早些时候，OpenAI 推出了 Deep Research，它允许 AI Agent 编写复杂的研究报告并分析用户选择的问题和主题。谷歌去年 12 月推出了一款同名的类似工具——Deep Research，它充当“研究助手，探索复杂主题并代表你编写报告”。</p>
  <p>CNBC 于 12 月首次报道称，谷歌将在 2025 年初推出多项人工智能功能。</p>
  <p>“从历史上看，你并不一定总是第一，但你必须执行力强，真正成为同类产品中最好的，”首席执行官 Sundar Pichai 在当时的战略会议上表示。“我认为这就是 2025 年的意义所在。”</p>
  <p><strong>参考链接：</strong></p>
  <p>https://blog.google/technology/google-deepmind/gemini-model-updates-february-2025/</p>
  <p>https://x.com/lmarena_ai/status/1887180371219132898</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Wmt7VRG0blp4sTC9p4Brcw" rel="noopener noreferrer nofollow" target="_blank">“AI前线”</a>，作者：冬梅、核子可乐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156404365728264</id>
            <title>微软官宣All in智能体，SWE Agent首曝光，奥特曼预警2025编程巨变</title>
            <link>https://www.36kr.com/p/3156404365728264</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156404365728264</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 软件工程, AI智能体, GitHub Copilot, 2025年变革
<br>
<br>
总结: 2025年，软件工程将经历重大变革，AI智能体的引入将显著提升开发效率。微软的GitHub Copilot将全面拥抱智能体，具备自主改bug、提交PR等能力，成为开发者的得力助手。AI将与人类工程师紧密协作，自动化测试、代码优化和漏洞检测等任务将不再依赖单一人力。尽管AI的普及可能带来新的安全威胁，但其在提高生产力和解决开发者长期困扰的问题方面的潜力不可忽视。Altman强调，未来的编程环境将更加智能，AI将在解决复杂问题中发挥重要作用。 </div>
                        <hr>
                    
                    <blockquote>
   <p>2025年，软件工程要彻底变天了。先有奥特曼预言，后有微软下场All in智能体。刚刚，首个自主SWE智能体面世，不仅会主动改bug修复错误，还能自主提交PR评论。</p>
  </blockquote>
  <p>奥特曼预言，2025年软件工程将迎来巨变。</p>
  <p>开年智能体大爆发，AI自动化软件工程已成为不争的事实。</p>
  <p>就在今天，纳德拉官宣，GitHub Copilot将all-in智能体，微软自主的SWE智能体首次亮相。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5fc4f8fa1eec42f7961e4000cac8df7c@5888275_oswg52975oswg873oswg263_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>GitHub现任CEO Thomas Dohmke表示，自主SWE智能体（项目代号Padawan）也将融入GitHub用户体验，不过要等到今年晚些时候发布。</p>
  <p>「它可以将GitHub Copilot体验从搭档提升到人类程序员水平」。</p>
  <p>不论是改Bug还是开发新模块，不需要去特别说明相关的代码，SWE智能体会主动找到合适的代码，并解决问题，就像你雇了一个工程师。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_096a346c351e457cb49314864b68dafc@5888275_oswg128190oswg1080oswg1109_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有网友对此表示，基本上，每一个repo都会有一个AI贡献者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_031282f315124f88ae7e434ff2448263@5888275_oswg145392oswg1080oswg333_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>软件工程AI智能体苏醒</strong></h2>
  <p>2021年，GitHub Copilot一经推出成为了开发者们的得力助手。</p>
  <p>时隔4年，Copilot终于迎来了重大升级。</p>
  <p>如前所述，此次更新的最大亮点推出了Agent模式（预览版）。在这个模式下，Copilot展现出惊人的自主能力。</p>
  <ul>
   <li>自主迭代代码，识别错误并自动修复</li>
   <li>主动建议终端命令，并请求执行</li>
   <li>识别运行时错误，主动修复</li>
  </ul>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5f4833b054114e69a089e594c7c744f4@5888275_oswg462995oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在智能体模式下，Copilot不仅会对自己的输出进行迭代，还会对输出结果进行持续改进，直至完成所有子任务，满足开发者的请求。</p>
  <p>更强大的是，它不再仅仅执行要求的任务，还能去推断额外的必要任务，确保请求完整运行。</p>
  <p>在Copilot自我纠错过程中，比较省事的是，开发者不必从终端手动复制粘贴内容回到聊天窗口。</p>
  <p>在调用模型方面，开发者有Anthropic、OpenAI系列的模型可选。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4a2df066b9ee4d3f9a85cb65973e880b@5888275_oswg97979oswg620oswg298_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在全新VS Code智能体模式中，Copilot会对自身代码进行迭代，提出并指导终端命令，分析和解决问题。</p>
  <p>举个栗子，用GitHub Copilot构建一个Web应用程序来跟踪马拉松训练。</p>
  <p>这里有一个Runner Tracks网站，展示了一些比赛的结果。现在若是想要改进这张表的分页，添加更多参赛者数据，直接在Copilot Chat中输入要求即可。</p>
  <p>——更新分页按钮，让其看起来更加美观。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3f5df9c65648472ea4dcc5045b8ff816@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然后选用o3-mini模型，Copilot直接开始输出代码，再返回Runner Tracks网站，可以看到「按钮」变成了蓝色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d479ca835bdf4e6fab5fcf6b4059a043@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接下来，继续迭代这个网站——让用户可以选择每页显示的行数。</p>
  <p>这时，涉及到了不止一个文件的更改。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_629e8f64a2984a1dbe5272176be3ab5c@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>再上升一个难度的任务，Runner Tracks网站中有一个列出比赛的页面，若是想要按名称去搜索比赛，这将需要对项目服务器端代码UI和测试中许多文件进行修改。</p>
  <p>这个场合，就轮到Agent模式出场了。</p>
  <p>它最擅长的是推理和迭代整个项目，并且执行重复的操作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7eee1435581f45c8ad7e23e0f3e0eba1@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>可以看出，Copilot Agent自主更新了服务器后端、UI，主动修复错误。</p>
  <p>在这些基本项完成后，它又转向服务单元测试、页面测试、以及端到端的测试。</p>
  <p>直至测试更新后，系统会主动提示开发者去运行单元测试。</p>
  <p><strong>GitHub Copilot Edits</strong></p>
  <p>这次，同时上线的还有多文件编辑工具GitHub Copilot Edits。</p>
  <p>Copilot Edits可以一次性处理工作空间中的多个文件，并给出代码的更改意见。</p>
  <p>所有这些处理都可以在编辑器中直接完成，非常便于快速审查代码，同时了解周围代码的完整上下文。</p>
  <p>在操作过程中，用户还可以对每一次编辑选择接受或者放弃，从而拥有更加灵活的控制。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5ec851530f5a47ec9fa5e922d4f0cc2f@5888275_oswg286033oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一个新变化是，当切换到并排视图时，用于编辑的控制选项依然可见。</p>
  <p>由此可以帮助用户了解大范围的改动。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c48a85a3d1ab452a82b97e9361dca6de@5888275_oswg192373oswg1080oswg386_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后，Copilot Edits增加了一个新的设置，用于在超时后自动接受编辑器的建议。</p>
  <p>这个新设置的名称为「chat.editing.autoAcceptDelay」，它可以指定Copilot Edits的建议被接受之前需要等待的秒数。当用户点击接受按钮或开始审阅更改时，倒计时停止。</p>
  <p>这个设置对于那些喜欢在周末疯狂追剧的人来说应该很熟悉。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1bbd9ac262ae4f758d7f681b4d2e17d7@5888275_oswg36088oswg1080oswg581_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Project Padawan</strong></p>
  <p>而「Project Padawan」，则可以进一步将SWE智能体融入GitHub的用户体验中。</p>
  <p>一起来看个例子，GitHub cli库每天被使用数百万次，尽管有数百个贡献者，但积压了许多问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_deab31516c3a466eb7abba615530e787@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中的一个错误报告，展示了GH报告重命名的命令中缺少了验证，若是人力完成，会耗费大量的精力。</p>
  <p>要知道，这个代码库中有700个文件，大约20万行代码。</p>
  <p>而现在，有了「自主SWE智能体」，完全就可以放心交给这个AI助手。</p>
  <p>我们可以将问题分配给Copilot，它便开始立即处理。几秒钟后，它便从draft PR直接链接到开发者创建的问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e93bd5327dac4c87924f3ccab45d4167@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接下来，Copilot会不断更新PR描述，并自主提交，在共享实时计划同时，可以让开发者清晰看到更改进度。</p>
  <p>在PR完成后，它还会推送最终更改的提交，自主请求代码审查，并将PR标记为「准备审查」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4d23b3eda6a24b1882ae8f942a529b9b@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>开发者在此还提交了自己的审查请求，Copilot立即收到任务后开始了更改。并且，它还主动回复评论开发者的更改内容，并将最新进展推送到PR。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4f5f2319047c427cb37a1879a1a79c25@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以上所有流程，展示了Copilot成为一个真正的「AI工程师」，能与开发者合作完成编码任务。</p>
  <p>对此，网友表示，「过去一个月我一直在使用智能体，感觉和Karpathy的编码风格类似。一旦建立了构建、测试、迭代的反馈循环，你和智能体就能立刻进入状态。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_99f6e428fcd649529c35d2eb86f26367@5888275_oswg123404oswg1080oswg244_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>开发者领导SWE智能体，和项目经理一起编写详细的工单，审查工作、必要时接入。</p>
  <p>这，就是编码的未来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_294c938ecee9434bbbc4d7b2413ac6f2@5888275_oswg130568oswg1080oswg274_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>如何用？</strong></h3>
  <p>想要用上Copilot agent新功能，需要下载VS Code Insiders，然后启用GitHub Copilot Chat智能体模式设置。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_80cf6b8710f14c75a600da89bbaa2b60@5888275_oswg210392oswg1080oswg592_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然后，在「Copilot编辑」面板中，从模型选取器旁边的「编辑」切换到「智能体」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_14c845eb91e54afb9c36707fef94fb17@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>智能体模式的引入，将改变开发者在编辑器中的工作方式。</p>
  <p>为了无缝衔接，微软同时将其植入到所有支持Copilot的集成开发环境（IDE）中。</p>
  <h2><strong>2025年底，软件工程迎来巨变</strong></h2>
  <p>2月5日，OpenAI首席执行官Sam Altman与印度联邦信息技术部长Ashwini Vaishnaw进行了一场对谈。</p>
  <p>在此次访谈中，奥特曼也强调了智能体以及软件工程如何在未来变革中扮演的至关重要的角色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1f9929a65bcb4273bad20d365657eb68@5888275_oswg130387oswg1080oswg966_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在谈及AI如何改变软件工程时，Altman给出了令人期待的前景。</p>
  <p>他表示：「到2025年底，软件工程将发生翻天覆地的变化。这不仅意味着开发效率的大幅提升，还可能对网络安全产生深远的影响。」</p>
  <p>AI将成为软件工程中的得力助手，自动化测试、代码优化和漏洞检测等任务将不再是人类工程师的单打独斗，而是与AI紧密协作的成果。</p>
  <p>AI在软件工程中的应用，不仅能提高开发效率，还能帮助解决一些长期以来困扰开发者们的问题。</p>
  <p>例如，AI能够快速发现代码中的潜在问题并提出解决方案，极大地缩短开发周期。同时，AI还将在网络安全领域发挥重要作用，尽管这一过程需要谨慎对待，因为AI的普及也可能带来新的安全威胁。</p>
  <p>Altman谈到：「到2025年底，AI将变得更加智能，尤其是在软件工程领域。我们将看到一个更加智能的编程环境，AI将在解决复杂问题时扮演重要角色。」</p>
  <p>x上有网友已经开始期待软件智能体时代的到来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_307c7073c248422d84ca25acb6f30f2a@5888275_oswg78785oswg1080oswg714_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>甚至有网友开始幻想使用AI智能体来建立价值百万美元的公司了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f28aee1d7fe04c31a2db1dc476035b6c@5888275_oswg366105oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>智能化的AI软件工程不仅可以提高生产力，还能够更高效地进行系统开发和优化，甚至可能在未来改变整个软件开发行业的格局。</p>
  <p>这种变革类似于工业革命中的自动化生产线，AI将帮助软件开发者摆脱繁琐的细节工作，使他们能将精力集中于更高层次的创新和设计上。</p>
  <p>但同时，如何确保AI技术在应用中的安全性，避免其被滥用，将是未来需要解决的重要问题。</p>
  <p>关于这些问题，Altman指出：「我们必须在技术发展的同时，也要确保安全的可控性。AI的影响是深远的，我们要确保它能为全球带来积极的变革。」</p>
  <h3><strong>Deep Research助力研究</strong></h3>
  <p>访谈中主持人向奥特曼提出了一个关键问题：「在当前的深度研究环境中，AI是否已经足够成熟，能在一些关键领域发挥作用？」</p>
  <p>对此，Altman作出了充满信心的回应：「底层技术已经达到了一个门槛，尤其是在诊断疾病和教育领域，我们已经看到了惊人的成果。未来几个月内，我们将发布能够解决现实问题的模型。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e02fa7b6dd7b41279713e90e6e146b05@5888275_oswg53910oswg1080oswg649_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他特别提到，AI的进步不仅仅是在研究领域，更多的应用场景已经悄然出现，从医疗诊断到教育辅导，AI的潜力逐渐展现。</p>
  <p>例如，在医学领域，AI的研究助手不仅能够协助科学家高效回顾现有文献，还能在庞大的数据中找到潜在的联系，为科学发现提供有力支持。</p>
  <p>然而，尽管AI可以帮助提高效率，但它并非万能，Altman强调：「Deep Research可以帮助我们提高效率，例如在文献回顾、数据整理等繁重的低层次工作中。但它不可能独立完成一项复杂的任务。就像在癌症研究中，AI并不会直接治愈疾病，但它能帮助研究人员更快地找到解决方案。」</p>
  <p>这种高效的支持能够大大加速科学研究的进程，助力科研人员从繁琐的任务中解脱出来，将更多精力投入到创新和突破之中。</p>
  <h2><strong>结语‍</strong></h2>
  <p>无论是微软CEO纳德拉宣布GitHub Copilot全面拥抱智能体，还是OpenAI CEO Altman对未来软件工程的展望，都清晰地表明：AI智能体正引领软件工程领域进入一个全新的时代。</p>
  <p>AI智能体不仅将成为开发者的得力助手，更可能成为推动整个行业变革的核心力量。</p>
  <p>从代码编写、错误修复到项目开发，再到深度科学研究，AI的应用潜力正在被迅速释放。</p>
  <p>这场变革也带来了一系列值得思考的问题：开发者如何适应与AI协同工作的新模式？&nbsp;如何确保AI在网络安全领域的应用既能提升防御能力，又能避免新的风险？&nbsp;如何平衡AI带来的效率提升与潜在的就业影响？</p>
  <p>虽然AI并非万能，但无论如何，在2025年底，我们有望见证一个更加智能、高效的软件工程未来。</p>
  <p><strong>参考资料：</strong></p>
  <p>https://x.com/sama/status/1887177808394252777</p>
  <p>https://x.com/ashtom/status/1887548091404046359</p>
  <p>https://x.com/satyanadella/status/1887587703665139765‍</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/aKLnb2jOMUJ3QIV9r6R25Q" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156387000867586</id>
            <title>德银：不只是DeepSeek，2025年将是中国企业在全球崛起的一年，中国股票“估值折价”将消失</title>
            <link>https://www.36kr.com/p/3156387000867586</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156387000867586</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:11:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <中国资产, DeepSeek, 制造业, 估值折价>
<br>
<br>
总结: 德意志银行在最新报告中指出，2025年将是中国在全球竞争中领先的一年，预计中国股票的“估值折价”将消失，A股和港股的牛市将持续并超过之前高点。中国在多个制造和服务业领域展现出高性价比和优质产品，尤其在电动汽车和高科技领域的崛起。报告还强调，中国的制造业优势日益凸显，出口规模和专利申请数量均处于全球领先地位。中美贸易问题可能带来正面影响，投资者需迅速调整策略，增加对中国市场的配置。 </div>
                        <hr>
                    
                    <p>Deepseek爆火之后，要重估的或是整个中国资产。</p>
  <p>在2月5日的最新报告中，德意志银行唱多称，2025年是中国超越其他国家的一年，预计中国股票“估值折价”将消失，A股/港股牛市将继续并超过此前高点。</p>
  <p>德银表示：</p>
  <blockquote>
   <p>2025年被视为投资界意识到中国在全球竞争中领先的一年。越来越难以不承认，中国企业在多个制造和服务业领域提供高性价比和优质产品。</p>
   <p><strong>我们预计中国股票的“估值折价”将消失</strong>，盈利能力可能因政策支持消费和金融自由化而超出预期。<strong>港股/A股的牛市始于2024年，预计会在中期内超过之前的高点。</strong></p>
  </blockquote>
  <p>具体来看，德银表示，<strong>中国制造业和服务业在全球占据领先地位</strong>，而<strong>DeepSeek的崛起更像是中国的“斯普特尼克”时刻</strong>（指迎来变革和进步的重要契机）：</p>
  <blockquote>
   <p>中国在服装、纺织品、玩具、基础电子、钢铁、造船等领域，以及电信设备、核能、国防和高速铁路等复杂行业中也占据领导地位。而在2025年，中国在一周内推出了世界上第一架第六代战斗机和其低成本的人工智能系统DeepSeek。</p>
   <p>马克·安德森将DeepSeek的推出称为“人工智能的斯普特尼克时刻” ，但这更像是中国的斯普特尼克时刻，中国知识产权得到了认可。中国在高附加值领域表现出色并主导供应链列表，正在以前所未有的速度扩展。</p>
  </blockquote>
  <p>此外，德银乐观地指出，中美贸易问题可能会带来正面惊喜，而且贸易和市场并非那么紧密相关：</p>
  <blockquote>
   <p>随着中国企业在全球范围内的主导地位不断巩固，<strong>估值折扣似乎最终应该转变为溢价</strong>。我们相信<strong>投资者将不得不在中期内迅速转向中国，并且在不推高股价的情况下很难获得中国股票。</strong></p>
  </blockquote>
  <h2><strong>中国制造业优势日益凸显</strong></h2>
  <p>近年来，中国制造业在全球范围内的优势日益凸显。</p>
  <p>德银表示：</p>
  <blockquote>
   <p>从最初在服装、纺织品和玩具领域的崛起，到如今在基础电子、钢铁、造船等领域占据主导地位，中国制造业的发展轨迹令人瞩目。特别是在白色家电、太阳能等领域，中国企业的表现更是异军突起。</p>
   <p>值得注意的是，中国在电信设备、核电、国防和高速铁路等复杂行业中的崛起，展现了其强大的技术实力。2024年底，中国在汽车出口领域的快速崛起引起全球关注，其高性能、外观吸引人且价格具有竞争力的电动汽车（EV）成功打入国际市场。2025年，中国更是在短短一周内推出了世界上第一架第六代战斗机和低成本人工智能系统DeepSeek，这被视为中国知识产权得到认可的重要标志。</p>
   <figure class="image">
    <img src="https://img.36krcdn.com/hsossms/20250207/v2_f5499cb73fbf43ed8d53519dea8fc7f8@5888275_oswg210851oswg1080oswg440_img_000?x-oss-process=image/format,jpg/interlace,1" />
   </figure>
  </blockquote>
  <p>中国制造业的实力可以从以下几个方面得到印证：</p>
  <blockquote>
   <p>出口规模：<strong>中国的商品出口额是美国的两倍</strong>，<strong>贡献了全球制造业增加值的30%。</strong></p>
   <p>专利申请：2023年<strong>，中国占全球专利申请的近一半</strong>。在电动汽车领域，中国拥有约70%的专利，5G和6G电信设备领域也有类似优势。</p>
   <p>人才储备：除印度外，中国拥有比世界其他国家更多的STEM（科学、技术、工程和数学）毕业生。</p>
   <p>产业集群：中国为关键行业创造了类似硅谷的本地专业集群，并与大学在研究方面紧密合作。</p>
  </blockquote>
  <p>德银还表示：</p>
  <blockquote>
   <p>自由化金融体系对促进消费是有帮助的，通过正常化利率，从而结束从存款人到企业的资金转移。这将减少过度投资和过度竞争，因为资本得到了配给，这将有利于提高国有企业回报率。我们预计，<strong>随着国有企业提高回报率，将要求缓解过度竞争以提高股票价值。我们预计这将在2025年成为一个关键话题，该因素将成为推动牛市的关键因素。</strong></p>
  </blockquote>
  <h2><strong>中国经济和出口仍保持较快增长</strong></h2>
  <p>2024年，中国出口增长7%，对巴西、阿联 酋和沙特阿拉伯的出口分别增长23%、19%和18%，对"一带一路"中的东盟国家增长13%。<strong>中国对东盟和金砖国家的出口现已相当于对美国和欧盟的出口总和，</strong>且过去五年中，对这些目的地的出口市场份额<strong>每年增长两个百分点</strong>。</p>
  <p>中国经济增长的动力来自几个方面：</p>
  <blockquote>
   <p>制造业优势：<strong>在几乎所有行业中，中国都拥有世界领先的公司，</strong>并不断抢占市场份额。</p>
   <p>"一带一路"倡议：该倡议打开了中亚、西亚、中东和北非等地区，扩大了中国的潜在市场。</p>
   <p>自动化领先：<strong>约70%的工业机器人安装在中国，推动了生产力优势</strong>。</p>
   <p>内需潜力：家庭存款增长放缓至名义GDP增长率的两倍，但自2020年以来，<strong>储蓄增加了10万亿美元，预计这些储蓄将在中期内流入消费和股票市场。</strong></p>
  </blockquote>
  <h2><strong>中美贸易问题可能带来正面惊喜，贸易和市场并非那么紧密相关</strong></h2>
  <p>据央视新闻此前报道，美国总统特朗普2月1日签署行政令，对进口自中国的商品加征10%的关税。但德银认为，实际情况可能比预期更为有利。特朗普政府似乎更看重战术上的胜利，而非坚持难以获得支持的意识形态立场。</p>
  <p><strong>DeepSeek的推出动摇了世界对中国可以被遏制的信念。</strong>更好的做法可能是通过降低监管、提供廉价能源和相对较低的进口中间产品壁垒来刺激商业。预计在中期选举前，更倾向于贸易的立场最终将成为发展中的"美国优先"议程的一部分。</p>
  <p>德银分析认为，<strong>一个快速达成的中美贸易协议可能涉及有限的关税、撤销一些当前的限制，以及美国和中国公司之间的一些大型合同。如果这种情况发生，预计中国股市将会上涨。</strong></p>
  <blockquote>
   <p>出口下降可能在一段时间内反而推动股市上涨。中国在各行业的主导地位是通过在许多领域的过度投资实现的。如果能够限制供应，可能对股票有利，并释放一些资本用于国内消费。</p>
  </blockquote>
  <p>整体来看，德银认为，<strong>随着中国企业在全球范围内的主导地位不断巩固，投资者可能需要迅速调整策略，增加对中国市场的配置</strong>。<strong>预计香港/中国股市将在中期内继续领先全球市场，延续2024年的强劲表现。</strong></p>
  <blockquote>
   <p>我们认为全球投资者往往严重低配中国，就像他们几年前回避化石燃料一样，直到市场惩罚了那些做出非市场决策的人。我们看到今天基金对中国的持仓与此相似。喜欢领先公司、拥有护城河的投资者不能忽视，<strong>如今是中国公司拥有宽广和深厚的护城河，而不是西方公司</strong>。</p>
   <p><strong>随着中国企业在全球范围内的主导地位不断巩固，中国估值折价似乎最终应该转变为溢价。我们相信投资者将不得不在中期内迅速转向中国，并且在不推高股价的情况下很难获得中国股票。</strong>我们之前一直看好，但对于找到什么因素会促使世界觉醒并购买感到困扰，<strong>我们相信中国的“斯普特尼克时刻”（或电动汽车领域的主导地位）就是这个因素</strong>。</p>
  </blockquote>
  <p>本文不构成个人投资建议，不代表平台观点，市场有风险，投资需谨慎，请独立判断和决策。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/c9kN42djbTQyI3-VeJbq1Q" rel="noopener noreferrer nofollow" target="_blank">“华尔街见闻”</a>，作者：赵颖，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156361918044679</id>
            <title>“DeepSeek风暴”席卷全球资本市场，产业链企业谁是输家？谁是赢家？</title>
            <link>https://www.36kr.com/p/3156361918044679</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156361918044679</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:07:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, 生成式AI, 产业链, 云服务  
<br><br>  
总结: 春节假期，DeepSeek因其低成本、高性能和开源特性成为科技圈的焦点，吸引了多家云服务巨头接入。随着投资者对中国互联网和半导体公司的看涨情绪，相关科技股在资本市场表现强劲。DeepSeek的崛起可能会影响整个产业链，尤其是生成式AI的应用和基础模型的提供商。最终用户和GenAI应用提供商将从中受益，而专有模型提供商可能面临竞争压力。DeepSeek的开源策略和低成本API将重塑市场格局，未来的赢家和输家尚未最终确定。 </div>
                        <hr>
                    
                    <p>春节假期，全球掀起一股 “DeepSeek 风暴”。凭借“低成本、高性能、开源”等优势，DeepSeek 以屠龙者之相一跃成为整个科技圈关注的焦点。</p>
  <p>2月初，天翼云、华为云、腾讯云、阿里云、百度智能云等相继接入DeepSeek ，以云服务巨头们为首，从芯片厂商到软件厂商再到垂直应用领域的多家企业争先恐后加入这位“新贵”的朋友圈。</p>
  <p>这股风暴的效应也非常明显地反映到了资本市场——随着全球投资者对中国互联网公司以及对于中国半导体与软件领军者的狂热看涨情绪，恒生科技指数步入“技术性牛市”；而在 A 股市场，涵盖众多科技股的创业板截至周五上午收盘暴涨超 3%，周涨幅已接近 7%。</p>
  <p><strong>无数人在询问，以 DeepSeek 为代表的新一代生成式 AI 到底将如何影响整条产业链？谁将被颠覆？谁又能成为这股热潮中的受益者？</strong>趁着这股热度，不少研究机构和券商也纷纷发布了相关报告，因此本文将综合 IoT Analytics、 TrendForce 集邦咨询、IBM 以及多家券商的报告，对产业链受到的影响进行解析。</p>
  <p>注：本文仅进行产业链分析，不构成任何投资建议</p>
  <h2><strong>一图搞懂生成式 AI 价值链</strong></h2>
  <p>一个显而易见的结论是，此前，对于生成式 AI（GenAI）的支出正在使广泛的价值链受益，下图基于 IoT Analytics 发布的《2025-2030 年生成式 AI 市场报告》，描绘了整个价值链中 GenAI 支出的主要受益者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_34ff31f2050a460ba9f6aa4e7118979f@000000_oswg263108oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>价值链上的受益者包括：</p>
  <h3><strong>Tier-0</strong></h3>
  <p><strong>最终用户——包括使用生成式 AI 应用的消费者和企业。</strong></p>
  <p>截至 2 月 5 日，DeepSeek 的全球下载量已接近 4000 万。据 AI 产品榜数据，DeepSeek 应用(仅包含 APP，不包括 Web 端) 2025年1月11日上线，至2025年1月31 日，DAU 2215 万。彼时 ChatGPT 日活 5323 万，豆包日活 1695 万，这意味着 DeepSeek 达到 ChatGPT 日活用户的 41.6%，已超过豆包。</p>
  <p>由 IBM 委托开展的一项新研究发现，在接受调研的企业级（规模超过 1000 名员工）组织当中，约有 42% 已经在其业务中积极使用人工智能。</p>
  <p><strong>GenAI 应用——在其产品中包含 GenAI 功能或提供独立 GenAI 软件的软件供应商，包括专注于 Agentic AI 的企业软件公司（如 Salesforce）以及专注于 GenAI 应用程序的初创公司（如 Perplexity 或 Lovable）。</strong></p>
  <p>2023 年 3 月 7 日，Salesforce 宣布推出 Einstein GPT，这是全球第一个 CRM 生成式 AI，用例包括 Slack、Sales、Service、Marketing、Commerce 以及 App Builder，以助力提高员工效率，改进客户体验。</p>
  <p>Perplexity 成立于 2022 年 8 月，专注于搜索领域，目标是取代谷歌，甚至被称为“谷歌杀手”。据悉，Perplexity AI 是建立在大模型之上的 AI 搜索应用。有别于传统罗列网页式搜索，而是通过利用 AI 工具，提供经过提炼总结后的答案，并附上出处。</p>
  <h3><strong>Tier-1</strong></h3>
  <p><strong>一级受益者——基础模型提供商（如 OpenAI 或 Anthropic）、模型管理平台（如 AWS Sagemaker、Google Vertex 或 Microsoft Azure AI）、数据管理工具（如 MongoDB 或 Snowflake）、云计算和数据中心运营商（如 Azure、AWS、Equinix 或 Digital Realty）、AI 咨询和集成服务商（如 Accenture 或 Capgemini）、边缘计算公司（如 Advantech 或 HPE）。</strong></p>
  <h3><strong>Tier-2</strong></h3>
  <p><strong>二级受益者——为一级受益者提供产品和服务支持的企业，包括芯片供应商（如 NVIDIA 或 AMD）、网络与服务器设备供应商（如 Arista Networks、华为或 Belden）、服务器散热技术供应商（如 Vertiv 或 Schneider Electric）。</strong></p>
  <p>华为全联接大会 2024 期间，在以“星河AI网络，共赢行业智能化”为主题的峰会上，华为数据通信产品线总裁王雷面向全球升级星河 AI 网络发布 20 余款新品，包括业界首款 100T 数据中心盒式以太交换机、业界首款 51.2T 数据中心盒式液冷交换机，业界首款 AI 路由器、高品质万兆园区新款交换机和 Wi-Fi 7 AP、智能 SASE 分支安全解决方案和业界首个 IP 自动驾驶网络等领先解决方案，帮助客户创造更大商业价值。</p>
  <h3><strong>Tier-3</strong></h3>
  <p><strong>三级受益者——为二级受益者提供产品和服务支持的企业，包括芯片设计电子自动化软件供应商（如 Cadence 或 Synopsys）、半导体制造商（如台积电 TSMC）、用于散热技术的热交换器供应商、电网技术供应商（如西门子能源或 ABB）。</strong></p>
  <h3><strong>Tier-4</strong></h3>
  <p><strong>四级及更远层级的受益者——继续为上游环节提供支持的公司，如半导体制造设备所需的光刻系统供应商（如 ASML），以及光刻系统供应链上的光学元件供应商（如蔡司）。</strong></p>
  <h2><strong>DeepSeek 浪潮中的赢家和输家</strong></h2>
  <p>DeepSeek R1 等模型的崛起预示着生成式人工智能价值链的潜在转变，其颠覆性主要体现在：</p>
  <p><strong>①最大的 DeepSeek R1 模型 （具有 6850 亿个参数）性能与美国基础模型提供商的一些领先模型相当甚至更好。</strong>基准测试表明，DeepSeek 的 R1 模型的性能与 OpenAI 的 o1 和 Anthropic 的 Claude 3.5 Sonnet 等领先、更知名的模型相当或更好。</p>
  <p><strong>②DeepSeek 的训练成本要低得多，但并没有最初新闻所说的那么高。</strong>早期的报道显示，该模型的训练成本超过 550 万美元，但自发布以来，不仅训练，而且开发整个模型的真正价值一直存在争议。据半导体研究和咨询公司 SemiAnalysis 称，550 万美元只是成本的一部分，不包括硬件支出、研发团队的工资和其他因素。</p>
  <p><strong>③DeepSeek 的 API 定价比 OpenAI 便宜 90% 以上。</strong>无论开发模型的实际成本如何，DeepSeek 都提供了使用其 API 的更便宜的方案：DeepSeek R1 的输入和输出令牌成本分别为每百万 0.55 美元和每百万 2.19 美元，而 OpenAI 的 o1 模型成本为每百万 15 美元和每百万 60 美元。</p>
  <p><strong>④DeepSeek R1 是一个创新模型， DeepSeek 发布的论文展示了在 V3 基础上开发 R1 的方法</strong>：利用混合专家 (MoE)架构、强化学习和极具创意的硬件优化，创建需要更少资源来训练和执行 AI 推理的模型，从而实现更低的 API 使用成本。</p>
  <p><strong>⑤DeepSeek 比多数竞争对手更加开放。</strong>DeepSeek R1 可在HuggingFace或GitHub等平台上免费获取。</p>
  <p><strong>⑥DeepSeek 在 R1 主版本发布的同时发布了功能强大的小型模型。</strong>DeepSeek不仅发布了具有超过 6800 亿个参数的主要大型模型，而且还发布了多个DeepSeek R1 精简模型。这些模型的大小从 700 亿到 15 亿不等，后者可适用于许多消费级硬件。</p>
  <p>这些优势将挑战现有的市场格局并重塑对盈利能力和竞争优势的期望。<strong>如果出现更多具有类似功能的模型，某些参与者可能会受益，而其他参与者则面临越来越大的压力。</strong>在此背景下，IoT Analytics 根据 DeepSeek R1 引入的创新以及开放、经济高效的模型的广泛趋势，评估了主要的赢家和可能的输家。值得一提的是，该评估考虑了此类模型对价值链的潜在长期影响，而不仅仅是 R1 的直接影响。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_626c69aa80e64e86b86505a72236b40a@000000_oswg295532oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>谁是明显的赢家？</strong></h3>
  <p><strong>首先，最终用户肯定会获得更多的受益，</strong>更多更便宜大模型的出现最终将降低终端用户的成本，并使人工智能更加普及。日常生活中，已经有越来越多的人正通过提供初步构想、自动完成重复性任务、快速生成报告和文档等手段显著提升工作效率。</p>
  <p><strong>GenAI 应用提供商也是赢家之一，</strong>随着更多基础模型的上线，构建在其上的初创公司将拥有更多选择。如上所述，DeepSeek R1 比 OpenAI 的 o1 模型便宜得多，尽管推理模型在应用场景中使用较少，但持续的突破使得模型更强大且更便宜。可以预见，更多、更廉价的模型将降低 GenAI 功能在应用中的集成成本。</p>
  <h3><strong>谁是可能的赢家？</strong></h3>
  <p><strong>边缘 AI/边缘计算公司是可能的潜在赢家。</strong>在微软最近的财报电话会议上，萨蒂亚·纳德拉指出，“人工智能将更加无处不在”，因为更多的工作负载将在本地运行。DeepSeek 与强大的 R1 模型一起发布的精简小型模型足够小，可以在许多边缘设备上运行。虽然规模较小，但 1.5B、7B 和 14B 模型也是同样强大的推理模型。它们可以安装在笔记本电脑和其他功能较弱的设备上，例如 IPC 和工业网关。这些精简模型已从 Hugging Face 平台上被下载了数十万次。拥有边缘 AI 解决方案的边缘计算制造商（如意大利的 Eurotech 和台湾的研华科技）将从中获利；专门从事边缘计算芯片的芯片公司（如 AMD、ARM、高通甚至英特尔）也可能受益；Nvidia也在这个细分市场运营。</p>
  <p><strong>数据管理服务提供商是另一大潜在赢家。</strong>显而易见，没有数据就没有人工智能，要使用开放模型开发应用程序，采用者需要大量数据进行训练和部署，这需要适当的数据管理。因此，随着不同 AI 模型数量的增加，数据管理将变得越来越重要。MongoDB 、Databricks 和 Snowflake 等数据管理公司以及超大规模企业提供的相关产品都将从中获利。</p>
  <p><strong>GenAI 服务提供商同样受到明显的积极影响。</strong>DeepSeek 的崛起表明 GenAI 的复杂性仍在增长，不同模型的可用性增加了复杂性，从而推动企业对 GenAI 服务的需求。不过，如果领先的 GenAI 模型（如 DeepSeek R1）免费提供，企业可自行试验和部署，可能会减少对 AI 集成服务的需求。综合而言，随着新技术不断涌现，企业将寻求最佳方式利用开源模型，这将推动 GenAI 服务需求增长。</p>
  <h3><strong>带来的影响尚不确定</strong></h3>
  <p><strong>云计算提供商受到的影响是中性的。</strong>一方面来看优势，DeepSeek R1 已被微软 Azure AI Foundry、AWS Bedrock 和 Amazon Sagemaker 集成，云服务商虽然投资 OpenAI 和 Anthropic，但仍保持开放模式，支持多种模型的托管、训练和微调，更高效的模型降低了资本支出，有助于提高云计算利润率；另一方面来看劣势，随着边缘计算能力增强，模型推理可能更多地转移到本地设备，减少云端推理需求，此外，更高效的训练方法可能进一步降低训练成本。总结来看，更小、更高效的模型减少了对云计算的依赖，但整体 AI 需求的增长和 CAPEX 下降可能抵消影响。</p>
  <p><strong>EDA 软件提供受到的影响也是同样的道理。</strong>有利的方面来看，AI 计算负载日益专业化将带来对新型 AI 芯片的需求的增加，而 EDA 工具在 AI 专用芯片设计中至关重要；不利的方面来看，如果 AI 模型趋向y小型化、低资源消耗，那么高性能数据中心 GPU 和 ASIC 设计的需求可能减少，从而降低 EDA 工具在高端 AI 芯片领域的授权收入。Synopsys 和 Cadence 等 EDA 供应商可能受益于 AI 硬件多样化，但行业需适应新趋势，更多关注边缘、消费级和低成本 AI 计算芯片设计，而非大型数据中心 GPU。</p>
  <h3><strong>谁是可能的输家？</strong></h3>
  <p><strong>AI 芯片相关企业可能会成为输家。</strong>固然，AI 训练成本的降低可能会推动整体 AI 芯片需求上升，即“杰夫森悖论”（即效率提升反而增加需求）。ASML 首席执行官也有类似的想法：“AI 成本降低可能意味着更多的应用，更多的应用意味着随着时间的推移需求会更多。我们认为这是增加芯片需求的机会。”但劣势也相当明显——DeepSeek R1 训练成本下降主要由于减少对高端 GPU 的依赖，这可能影响高性能 AI 芯片的投资回报，并影响大规模 AI 芯片采购计划（如最近宣布的星际之门项目）。IoT Analytics 研究显示，NVIDIA 在数据中心 GPU 市场占比高达 92%，但如果 AI 模型所需硬件减少，可能会削弱 NVIDIA 的增长前景。</p>
  <p><strong>数据中心相关行业（网络设备、电力基础设施、冷却系统）可能也会受到冲击。</strong>如果 AI 训练和推理变得更高效，对高端数据中心 GPU 的需求下降，数据中心扩张的必要性也会减少。这可能影响网络设备、电力基础设施（如电网技术）、服务器冷却解决方案的市场需求。</p>
  <p><strong>不过，笔者也看到过一些相反的观点。比如 TrendForce 集邦咨询近日发布的研报指出，DeepSeek 模型虽降低 AI 训练成本，但 AI 模型的低成本化有望扩大应用场景，进而增加全球数据中心建置量。</strong></p>
  <h3><strong>谁是明显的输家？</strong></h3>
  <p><strong>专有模型提供商将受到比较大的负面影响。</strong>那些已经在 GenAI 领域投入巨资的专有模型公司（如 OpenAI、Anthropic）正在或即将蒙受损失。DeepSeek R1 的开源策略削弱了专有模型的竞争优势。即便这些公司推出更多开源模型，也会影响其当前的盈利模式。此外，DeepSeek 证明了顶级 AI 模型可以免费开放，未来专有模型的“护城河”变得不确定。当 DeepSeek 以免费（用于本地部署）或非常便宜（其 API 比同类模型便宜一个数量级）的方式发布强大的模型，OpenAI 、Anthropic 和 Cohere 等公司可能面临激烈竞争。</p>
  <h2><strong>写在最后</strong></h2>
  <p>DeepSeek 的发布只是产业链变革的一个起点，未来还将有更多意想不到的变化发生。赢家和输家的界限或许尚未最终划定，而真正决定企业命运的，仍然是它们在未来几年内的战略选择。在这场智能化的竞赛中，谁能笑到最后？或许，我们很快就会见分晓。</p>
  <p><strong>参考资料：</strong></p>
  <p>DeepSeek R1’s implications: Winners and losers in the generative AI value chain，iot-analytics</p>
  <p>芯报丨AI搜索公司Perplexity完成5亿美元融资，AI芯天下</p>
  <p>DeepSeek超ChatGPT成全球增长最快AI应用！下载破4000万，日活超豆包登顶中国No.1,量子位</p>
  <p>DeepSeek 的低成本 AI 模型将催生光通信需求，TrendForce</p>
  <p>华为云、ZStack、腾讯云、阿里云、百度云：首批上线 DeepSeek，大江网</p>
  <p>DeepSeek引爆中国AI投资狂潮 港A股这是要复刻2023年“美股疯牛”?，智通财经</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MTM5ODQyMA==&amp;mid=2651322079&amp;idx=1&amp;sn=103f775d3b6b96e6b5ec8c2adaa486d6&amp;chksm=bc2742413eb043ab184d628e76e3cce966ecf47cf32791997d36edcff187b797150d93cbf65b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“物联网智库”（ID：iot101）</a>，作者：Sophia，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156346391976456</id>
            <title>钱塘征信正式成立，蚂蚁集团持股29.9%</title>
            <link>https://www.36kr.com/p/3156346391976456</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156346391976456</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:06:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 钱塘征信, 个人征信, 股东结构, 市场化原则  
<br><br>  
总结: 钱塘征信有限公司于2025年正式成立，成为国内第三家个人征信公司，注册资本为10亿元。其股东结构多元，包含国有资本和民营企业，主要股东包括浙江省旅游投资集团和蚂蚁集团。钱塘征信将按照市场化原则设立股东会、董事会等管理机构，未来致力于提供多样化的个人征信产品，支持普惠金融发展。分析师认为其多元股东结构有助于行业竞争和长远发展。 </div>
                        <hr>
                    
                    <blockquote>
   <p>钱塘征信称，后续将按照市场化原则设立股东会、董事会、监事会和高级管理层</p>
  </blockquote>
  <p>继百行征信、朴道征信之后，国内第三家个人征信公司正式成立。</p>
  <p>国家企业信用信息公示系统显示，2025年2月5日，钱塘征信有限公司（下称“钱塘征信”）完成工商登记，经营范围包括个人征信业务等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0e9ab8872c5a41f99fcc087eae90f0aa@000000_oswg221255oswg865oswg595_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2024年11月11日，中国人民银行（下称“央行”）公告称，钱塘征信获准设立经营个人征信业务，并对其董事、监事、高级管理人员予以公示。</p>
  <p>工商登记信息显示，钱塘征信注册资本10亿元，由六名股东共同出资。其中，浙江省旅游投资集团有限公司（下称“浙江旅投”）持股40.1%，为第一大股东；浙江融信网络技术有限公司持股（下称“浙江融信”）29.9%，为第二大股东，该公司是蚂蚁集团全资子公司；杭州溪树企业管理合伙企业（有限合伙）（下称“杭州溪树”）持股10%，为第三大股东；传化集团有限公司持股7%，为第四大股东；浙江电子口岸有限公司和杭州市金融投资集团有限公司分别持股6.5%。</p>
  <p>根据央行此前公示的牌照申请信息，浙江旅投和蚂蚁集团拟各自持股35%。正式成立后，浙江旅投持股比例为40.1%，蚂蚁集团通过浙江融信间接持股29.9%，其余股东持股比例不变。</p>
  <p>据了解，各股东持股比例由股东按市场化原则平等协商确定。钱塘征信方面表示，未来将践行征信为民理念，秉持“信用为本、平等普惠”的发展原则，为金融机构提供更加多样、更加丰富的个人征信产品，支持普惠金融发展。</p>
  <p>这一股权结构与其余两家个人征信公司类似，既包括国有资本，也包括民营企业。</p>
  <p>天眼查显示，百行征信第一大股东为中国互联网金融协会，持股比例36%；芝麻信用、考拉征信、中诚信征信、腾讯征信、深圳前海征信等八家企业分别持股8%。</p>
  <p>朴道征信第一大股东为北京金融控股集团有限公司，持股比例35%；京东科技、旷视科技、小米、北京聚信优享企业管理中心（有限合伙）分别持股25%、17.5%、17.5%和5%。</p>
  <p>博通咨询金融业资深分析师王蓬博认为，<strong>在风险可控的前提下，征信信息建设一直坚持“政府+市场”双轮驱动，钱塘征信股东结构多元，能够在信息安全、数据、场景及技术方面形成优势并互补，有利于行业形成良性竞争和长远发展，提振市场信心。</strong></p>
  <p>除了前两大股东，市场也颇为关注钱塘征信第三大股东杭州溪树企业管理合伙企业（有限合伙）。</p>
  <p>工商信息显示，杭州溪树成立于2021年9月3日，同年11月26日，央行公示受理了钱塘征信的个人征信业务申请。</p>
  <p>杭州溪树工商登记的营业场所为浙江省杭州市西湖区西溪路543号-569号（单号连续）1幢2号楼5层515室，而蚂蚁集团登记地址为浙江省杭州市西湖区西溪路543号-569号（单号连续）1幢2号楼5层517室，二者相邻。</p>
  <p>杭州溪树共有两名合伙人，分别是孔令仁和李臻，后者同时担任执行事务合伙人。</p>
  <p>公开信息显示，孔令仁曾担任蚂蚁集团企业融资部总监。在2021年钱塘征信牌照申请的董监高拟任名单中，孔令仁拟任财务负责人。李臻曾任芝麻信用联席总经理。2024年7月，芝麻信用发生工商变更，李臻卸任经理一职。</p>
  <p>目前，李臻同时担任钱塘征信董监高成员和法定代表人。</p>
  <p>央行2024年审批通过后公示的钱塘征信董监高名单中，2021年公示的拟任总裁和股东董事董占斌、股东董事余泉、独立董事胡少先、财务负责人孔令仁均未出现，同时新增了李臻、聂正军、陈亮，三人均在蚂蚁集团任职多年。</p>
  <p><strong>截至目前，央行与钱塘征信尚未公布钱塘征信董监高人员具体任职信息，第三家个人征信机构高管格局有待进一步明确。</strong></p>
  <p>钱塘征信称，后续将按照市场化原则设立股东会、董事会、监事会和高级管理层，聘请具备专业性、良好声誉的独立董事，提升公司治理水平和社会责任担当。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkyMjY5MTQ1Nw==&amp;mid=2247628348&amp;idx=2&amp;sn=66db5ad24142a0a2fab1d949e1ffb579&amp;chksm=c074b15a0da143f793b520d1718089b46af0b1f9f884aef850a2fb6204b5b61c4128fd8909b5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“财经五月花”（ID：Caijing-MayFlower）</a>，作者：唐郡，编辑：张威，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156054213483010</id>
            <title>小米市值突破 1 万亿，造小米 SU7 成了雷军最好的决策</title>
            <link>https://www.36kr.com/p/3156054213483010</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156054213483010</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:03:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米集团, 股价, SU7, 市值  
<br><br>  
总结: 小米集团在2024年股价表现突出，涨幅121%，市值突破万亿港元。小米SU7的成功推出是股价上涨的重要驱动力，交付量不断攀升，市场反响超出预期。尽管小米在造车初期面临质疑，但凭借精准的市场定位和高效的营销策略，成功打破行业壁垒。小米汽车的产能提升和新车型YU7的推出，将进一步影响市场格局和小米的股价表现。 </div>
                        <hr>
                    
                    <p>2 月 6 日，小米集团的港股迎来了强劲上涨，股价突破到 40.55 港币，涨幅为 2.27%，<strong>市值突破万亿港元大关，达到了 1.02 万亿港元，创下历史新高</strong>。</p>
  <p>回顾 2024 年，小米集团的股价表现尤为亮眼，其涨幅高达 121%，远超同期恒生科技指数的 18.7%。进入 2025 年，小米集团股价继续上涨，增幅为 17.54%。</p>
  <p>插入短视频「小米市值破万亿」</p>
  <p>相比之下，其他科技巨头的表现则较为温和。2024 年，阿里巴巴上涨 11%、京东上涨 24%、腾讯上涨 44%、美团上涨 85%、网易上涨 1%，这些公司都未能达到小米的增长水平。</p>
  <p>从 2018 年 7 月 9 日上市港股，到很快破发，市值始终徘徊在低谷；再到凭借 SU 7 和小米汽车的成功，小米的「万亿市值」路走的并不平坦，而小米汽车，对于雷军的意义，显然非同寻常。</p>
  <h2><strong>01 小米 SU7，平等撞飞所有对手</strong></h2>
  <p>2024 年，小米迎来了厚积薄发的一年，尤其在汽车领域的布局。<strong>小米 SU7 的推出，成为股价大幅上涨的重要驱动力</strong>。</p>
  <p>雷军曾透露，小米 SU7 的市场反响远超预期，成功程度是最初预想的 3 到 5 倍。这一出乎意料的成功，促使小米汽车一次次调整年初设定的目标，逐步从 7 万辆、10 万辆、12 万辆，最终突破至 13.5 万辆的交付成绩。</p>
  <p>回顾小米在汽车领域的开局，可以说是在怀疑和质疑中起步的。作为 2021 年才宣布进军造车行业的企业，小米在新造车势力中入局最晚，第一辆量产车小米 SU7，直到 2024 年 3 月才正式交付。</p>
  <p>当时的局面对小米来说，压力山大。</p>
  <p>在手机领域，小米曾肩负起推动智能手机普及的重任，时代也给予了它丰厚的回报。然而，到 2023 年底，新能源汽车的渗透率已接近 40%。面对如此竞争激烈的市场，小米要做的，不是以低价推动普惠，而是要探索智能汽车的边界，将产品推向更高品质。这并不是小米特别擅长的节奏。</p>
  <p>外界对小米造车的怀疑声音，在长时间内始终未曾消退。2023 年 12 月 28 日，小米举行了第一个汽车技术发布会，初期的热度非常高，但很快，质疑与批评声接踵而至。有一句友商的话广为流传：「军儿，收手吧，外面都是 XX。」</p>
  <p>雷军曾回忆道，在那段艰难的时刻，他让市场部邀请了 20 多位媒体朋友，为小米汽车的未来出谋划策。出乎意料的是，绝大多数人并不看好小米的造车之路。他们普遍认为：</p>
  <p><strong>每个月能卖出 3000 辆车，就已经是难得的成功了</strong>。</p>
  <p>在这种不被看好的氛围中，小米汽车艰难前行。2024 年 3 月 28 日，小米 SU7 发布会一结束，短短时间内大定量突破了 5 万台，首销期中有 60% 的「天使单」，即消费者未曾试驾便直接下单。尽管这一火爆的订单量令业界瞩目，但外界对能否持续热销以及小米的交付能力，仍然存在疑问。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a7c1f84226b5412a8b7136a7a7c417bf@000000_oswg168734oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">小米集团过去一年的股价表现 | 图片来源：雪球</p>
  <p>随着交付期的开启，小米股价也开始稳步上涨。</p>
  <p>2024 年 4 月和 5 月的交付量分别为 7000 辆和 8600 辆，资本市场保持观望态度。然而，从 6 月到 9 月，小米 SU7 的交付量连续保持在 1.3 万辆以上，小米集团股价也突破 20 港元大关。从 10 月到 2025 年 1 月，小米连续四个月交付量超过 2 万辆，股价更是节节攀升。</p>
  <p>在 2024 年年底的跨年直播中，雷军提出了第一个新年 flag：「2025 年将加速交付，交付目标为 30 万辆。」</p>
  <p><strong>这一目标彻底激发了资本市场的热情，小米市值也最终突破了 1 万亿港元大关</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_02418685ac994fc6b464131136c4ac54@000000_oswg111610oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>小米 SU7 Ultra 的价格高达 81 万元，第一次敲开了超级电动轿跑市场的大门 | 图片来源：小米</p>
  <p>对于小米汽车取得成功的原因，主要有三个方面：</p>
  <p>1 小米对造车这件事的复杂度，有足够认知，投入也足够大。据了解，<strong>小米在汽车研发上的投入超过了 130 亿元，累计投入已接近 300 亿元</strong>，这还不包括小米集团其他相关资源的投入。显然，足够的资金和对市场的深刻理解是小米能够快速在汽车行业立足的基础。</p>
  <p>2 精准的市场定位。当时，SUV 市场的竞争已然非常激烈，小米想要在这个领域击败对手，难度可想而知。因此，小米巧妙地绕过了消费者偏爱的 SUV，转而在相对「冷门」的轿车市场发力，成功塑造了品牌认知。这一策略类似于选择了一个细分市场（即「利基市场」），并从 0 到 1 地进行拓展。尽管这种选择在当时被认为是「小众」，但实际上，小米抓住了市场中的潜在需求。</p>
  <p>3 小米被认为是国内最会做营销的车企。360 集团创始人周鸿祎在自己的 AI 课程中提到的，雷军不仅在产品上精益求精，更在营销策略上展现了大师级的智慧。他表示：</p>
  <p><strong>小米 SU7 的发布，堪称汽车行业的一堂免费的营销课</strong>。</p>
  <p>周鸿祎认为，传统车企的老板虽然也有不少业内影响力，但他们普遍采用的是 ToB 的思维模式，即主要通过经销商与用户间接接触。而雷军则大胆采用了 ToC 的互联网思维，直接与用户打交道。这种方式在短视频时代尤其有效，使得小米能够快速吸引消费者的注意并与其建立情感连接。</p>
  <p>小米 SU7 的成功，可以视为小米模式和小米方法论的成功体现。早年间，雷军就提出了「顺势而为」的商业理念，并总结出了「小米方法论」的七字诀：专注、极致、口碑、快。这个理念贯穿了小米的所有产品和战略，从手机到智能硬件，再到如今的汽车，都有着鲜明的印记。</p>
  <h2><strong>02 下一个目标，Model Y</strong></h2>
  <p>自上市以来，产能一直是制约小米汽车销量的主要瓶颈。2024 年，小米汽车交付量超过 13.5 万辆，但由于产能不足，小米 SU7 仍面临大量未交付订单。</p>
  <p>根据第三方统计，<strong>截至 2024 年 12 月底，小米汽车累计收获订单已超过 26 万份，其中已完成交付的订单约为 13.5 万份</strong>。这意味着，即便考虑到因超长交付时间而流失的部分用户，小米汽车内部仍积压着超过 10 万份的订单。</p>
  <p>小米汽车的生产能力也在不断提升。据了解，小米一期工厂的额定年产能为 15 万辆，月产能为 1.25 万辆。通过双班生产和产线优化，小米成功将月产能提升至 2.4 万辆，然而，仍未能完全满足市场的强烈需求。因此，小米正在建设二期工厂，预计将在 6 月竣工，进一步应对需求增长。</p>
  <p>然而，除了产能问题外，另一关键因素是小米汽车的第二款车型——小米 YU7。雷军曾透露，小米的产品计划中，小米 SU7 Ultra 将于 3 月上市，而小米 YU7 预计将在 6 月至 7 月间推出。作为小米未来的重要战略车型，YU7 被寄予厚望，尤其是在与特斯拉 Model Y 的竞争中，备受瞩目。</p>
  <p>作为 20-30 万元新能源市场的标杆车型，特斯拉 Model Y 吸引了大量竞争对手的「围攻」。2024 年 9 月到 10 月之间，包括乐道、极氪、智界、智己、阿维塔、岚图在内的六家车企陆续发布了新产品，这些车型几乎都将 Model Y 作为竞争对标对象。这一现象被外界戏称为「六大门派围剿特斯拉 Model Y」。</p>
  <p>尽管这些新兴品牌的车型在订单量和产品力上有所提升，但从实际销量来看，它们仍未能真正挑战 Model Y 在纯电 SUV 领域的领导地位。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_decfd34f97084dd7a76c2f44fc29460c@000000_oswg652228oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">备受关注的小米 YU7，即将在 6 月份上市 | 图片来源：小米</p>
  <p><strong>小米 YU7，被认为是最有机会把特斯拉 Model Y 拉下神坛的玩家</strong>。</p>
  <p>毕竟，小米已经有过成功的经验。2024 年 7 月，乘联会数据显示，小米 SU7 的单月交付量首次超过特斯拉 Model 3，成功成为 20 万元以上纯电轿车的销售冠军。同年 12 月，小米 SU7 继续表现强劲，以 2.58 万辆的销量位居第五，而特斯拉 Model 3 则以 2.1 万辆的销量位居第六。</p>
  <p>小米的造车之路，从初期的质疑到如今的成功，不仅展示了其在智能硬件领域的优势，还通过精准的市场定位和高效的营销策略，成功打破了行业壁垒。随着产能的逐步提升与新车型的陆续推出，小米正在为未来的发展奠定坚实基础，尤其是在与特斯拉 Model Y 的竞争中，YU7 的推出有望成为改变市场格局的重要一环。</p>
  <p>2025 年汽车市场的竞争烈度，相比去年会再上一个台阶。而小米 YU7 的成绩，会和小米 SU7 一样，对小米集团的股价有着巨大影响。毕竟，你现在已经很难再把小米看成是一家单纯的消费电子公司了。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653073410&amp;idx=1&amp;sn=86acbc0ecd07453414ccd454d0273800&amp;chksm=7fb52ab0a66aa09b52e78dd7bfa42c7d1d1f9be2cae555a0ef6e3caa55efa974c69cfb7d7e73&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：周永亮，编辑：靖宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>