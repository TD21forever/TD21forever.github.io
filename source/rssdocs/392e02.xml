<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2653793386417413</id>
            <title>B站无法“放弃”年轻人</title>
            <link>https://www.36kr.com/p/2653793386417413</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653793386417413</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 12:05:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_140b430ae7da40829c448de61a3f21be@18980759_oswg136308oswg1080oswg720_img_jpg?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这段时间以来，B站对年轻群体的追捧越来越热情。</p><p>1月10日，B站举办2024 AD TALK营销伙伴大会，直言年轻人是新消费力量和新消费增量。接着，在1月24日，B站又宣布与全球最大规模的手办模型展Wonder Festiva主办方、日本玩具制造商海洋堂达成合作，看上去是要把年轻人的生意进行到底。</p><p>坦白来讲，B站的底色一直是年轻化。这几年来，B站也的确吃到了一些年轻群体的红利，数据显示，B站保持了超过十年的健康成长：2009年注册B站的用户，有68%依然活跃在社区；新增用户平均年龄在22岁。</p><p>这其中，老用户的广告价值增长了4倍，生态方面，有74%的90后贡献过商业价值。如果在新消费如日中天的时代，手握大量年轻用户的B站可谓是前途一片光明，可随着新消费势力偃旗息鼓，年轻人的消费能力严重降级。</p><p>B站握紧年轻人还有意义吗？这是个值得深思的问题。</p><h2><strong>急需年轻化的国货成了B站“金主”？</strong></h2><p>在2023年Q3的财报中， B站的游戏收入较2022年同期减少33%，当游戏业务大幅度缩水后，B站对广告与电商的期望值急剧飙升，尤其试水电商，是B站紧跟互联网节奏，不得不发力的一条路。</p><p>毕竟其他视频社交平台，如抖音、快手、小红书……早已开始在这个领域奋力掘金。从目前来看，大量活跃的年轻用户成了B站电商化为数不多的优势之一，也正是凭借这一点，B站顺利吸引到了第一批“金主”品牌：</p><p>那些急需更新消费画像，苦追年轻人的传统国货品牌显然在B站这里找到了舒适区。东阿阿胶、乌江榨菜、白象方便面、鸿星尔克……至少从品牌传播效果与市场调动力的角度来看，年轻的B站功不可没。</p><p>数据显示，2022年底，东阿阿胶首次与B站跨年晚会合作，晚会播出后的第一个1月，旗下主推产品“桃花姬阿胶糕”销量增长了一倍，此前此品类已连续8年无销量增长，2022年的销量甚至低于8年前。</p><p>同类型的还有乌江榨菜，2023年10月份，B站以“电子榨菜”聚集地的名义，和乌江榨菜联名推出两款包装焕新的产品。这一波联名，着实让一直苦于难以年轻化的老品牌尝到了甜头。</p><p>在乌江榨菜的用户调查中，品牌消费主力以30岁以上的人群为主，30岁以下的占比不足一半。联名新品发售24小时，天猫乌江官方旗舰店销量排名进入前五名，抖音联名专场累计成交金额突破63万。</p><p>更关键的是，流入的新客大部分是年轻人。以乌江榨菜在天猫的旗舰店为例，与B站联名让品牌平均年龄较店铺成交人群平均年龄年轻10岁，其中，18岁-25岁和26-30岁的人群分别占比41.51%和20.55%，换句话说，30岁以下人群超过了6成。</p><p>此外，白象方便面也在B站上靠着老牌国货的情怀狠狠刷了一把好感。细数B站上出现的最多的品牌，基本是一些经典国货，它们往往是被新消费浪潮残忍碾压过，需要一次新鲜的市场大换血，遍布年轻人的B站成了不错的选择。</p><p>而B站也恰好需要它们。</p><p>2022年，B站净亏损75.08亿元，同比扩大10.26%，创历史新高。2023年的情况也不容乐观，财报显示，2023年三季度，B站营收58亿元，经调整净亏损8.6亿元。一直以来，B站的投入成本都居高不下。</p><p>自研游戏投入，收益分成成本，营销推广成本……每一项都催动B站赶紧实现商业化，以销售支出为例，去年前三季度B站就花了27.91亿元，而2022年同期为36.55亿元。品牌的青睐对缺钱的B站极为重要。</p><p>这也是B站绝不放弃年轻群体的关键所在。然而，作为视频平台，天生“佛系”的B站远不及抖音、快手的快速转化。抖快的刺激性消费早已在无形中锻炼了整个电商市场，B站从内容到商品之间的触达路径、时间都过于漫长。</p><p>数据显示，B站视频带货中，价格在100元至300元之间的商品，通过一条6-8分钟左右的视频，只能有50%的即时转化率；而价格超过300元的商品，则要通过约10至15天的种草期。</p><p>时至今日，视频平台搅局电商消费，讲究的就是“速度”，这一点正是B站的软肋，所以B站清楚地明白，年轻才是自己面对消费市场的唯一优势。特别是对于国货来说，数据显示，国货销售火爆的背后，90后及00后国货消费金额占比达到62%，成为了国货消费的绝对主力。</p><p>哪怕是为了留住金主，B站也会一直年轻下去。</p><h2><strong>B站只剩年轻人？</strong></h2><p>B站现在不得不面临一个问题：虽然年轻群体尚有一定的商业价值，可消费能力却大不如前。新消费旺盛的年代，年轻人的消费活力能轻而易举供养一个新品牌，时至今日，网红餐厅茶饮、点心铺……纷纷倒在了寒风里。</p><p>年轻人曾经封神的商业价值就此大打折扣。</p><p>事实也是如此，“精细化”成为2023年的消费关键词，超过92%的年轻人表示，自己需要更精细地规划或减少消费。 具体来看，年轻人在各大领域的消费习惯也发生了一定变化：有数据统计，仅2022年一个季度，某宝某猫的零食边角料销售就比前一年增长了17倍；CIC的用户调研数据显示，90%以上的用户愿意考虑有质量保证的二手电子产品。</p><p>值得注意的是，消费市场上此消彼长。年轻群体开始节衣缩食，有一定积蓄的中老年群体的消费热情接着显露出来。这两年，银发一族被商业世界频频关注，《2022“银发族”消费趋势报告》显示，2022年前八个月“银发族”的成交单量、购物用户数、人均单量分别达2018年的3倍、1.8倍、1.7倍。</p><p>2023年继续承接了上一年的趋势：从消费上看，2023年9月，银发人群线上消费在1000-1999元区间的占比为32.5%，同比增长0.6%，线上消费在2000-2999元区间的占比为8.4%，同比增长0.8%。</p><p>在这种背景下，迟迟破不了圈层的B站不可能不焦虑。即使忽略消费能力，中老年群体也是互联网中仅存的增长动力，2023年9-10月第六次短视频用户年度调查显示，短视频在各年龄段用户中均衡渗透，其中占比最高的是30-39岁，为21.8%，40-49岁和50-59岁的年龄段用户占比加起来为34.7%，20-29岁的年轻用户占比仅为15.5%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d9fc75b06330499dabd47576e7ef8a55@18980759_oswg23148oswg544oswg231_img_jpg?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此前，B站就曾公开招聘银发一族，试图进一步寻找增量市场，内容上也有意扶持银发文化与站内中老年UP主，济公游本昌还入驻了B站。显而易见，在消费寒冬里，B站仅靠年轻人实现商业化的可能性越来越渺茫。</p><p>对比B站缺失中老年用户的“沮丧”，快手、抖音已经能熟练应用银发生态。数据显示，抖音一直位列中老年用户APP使用频率TOP3。快手上中老年用户也是平台的主力人群之一，51+人群占比23.7%，51+女性占所有女性用户26.4%，超过四分之一。</p><p>当庞大的用户消费力释放出来，效果斐然。以抖音为例，2020年6月，抖音电商正式成立，一年之后的抖音618好物节期间，50岁以上人群成交额累计高达50亿元，其中仅丝巾一项订单总量就达到84万条。</p><p>B站用户生态的不完善在很大程度上限制了平台的商业化进程，年轻群体固然深受一些品牌追捧，可不得不承认一点，B站所促成的消费行为往往与情怀、玩梗挂钩，国货品牌就是典型的例子，年轻用户敬佩白象、鸿星尔克的义行，从而疯狂下单。</p><p>东阿阿胶在B站的成功少不了年轻人盘了无数遍的《甄嬛传》加持；乌江榨菜则与B站的电子榨菜相呼应……可一旦脱离情绪价值，年轻人未必会长久支持名不见经传的“老牌国货”，《2022人民美好生活洞察报告》显示，60后才是国货产品的消费主力，占比超过一半。</p><p>B站也颇为无奈，谁能想到自己会一直“年轻”。</p><h2><strong>2024年，B站“赌”对了吗？</strong></h2><p>年轻人的钱远不如从前那么好赚了，这似乎已经是经过消费市场盖章认证的共识。可B站显然还在继续挖掘年轻人的经济价值，如果这是一场孤注一掷的豪赌，身后挤满年轻人的B站又有几分胜算呢？</p><p>在过去一年里，置身在复苏浪潮里的消费市场明显有几处增长点：诸如男性消费、个性消费、情绪消费……以情绪消费为例，年轻人一向乐于为情绪价值买单，美团消费数据显示，仅在元旦期间，轰趴、围炉煮茶、Livehouse等休闲玩乐订单量同比增长225%。</p><p>《2023青年消费调研》显示，年轻人在汽车之类的耐用品，家用电器、家居日用品、书籍文具上的消费开支变化不大，美妆个护和服饰鞋子包包出现了明显下滑，最明显的是，在旅游、演出、医美体验等服务类产品上，开支变多。</p><p>尽管“理性”取代冲动逐渐成了年轻人现阶段消费不得不提的关键词，但往深层来看，社交、悦己等象征情感属性的消费行为在这届年轻人的日常生活中，仍然占比重要，调研显示，七成以上消费者的主要消费诉求为兴趣消费，平均月支出占比为27.6%。</p><p>露营、citywalk、特种兵旅游这些消费方式从年轻人中快速传播开来，最终成为全网追逐的年轻文化现象。由此可见，虽然年轻人失去了曾经强悍的消费能力，可他们依旧拥有强大的消费号召力。</p><p>整个电商市场，开始围绕情感、兴趣搭建消费场景的平台也不少，抖音持续发力“兴趣电商”恰好印证了这一点。在互联网领域，B站相比于快手、抖音，最大的优势就是兴趣聚集，尤其年轻用户粘性不是抖音们能够比拟的。</p><p>数据显示，B站新用户平均年龄不到22岁，老用户留存率高达80%，付费增长率也不是问题，截至2022年第四季度B站的日活用户达到了9280万，同比增长29%，月付费用户数为2810万，同比增长15%。</p><p>《2023青年消费调研》中，有四成人的收入有所上涨，六成人花的比去年花的多，他们辗转四处，造就了一个又一个城市消费盛宴，能省的都省去了，该花的一分没落下。这或许是B站能否利用年轻群体突围的重中之重。</p><p>就目前来看，B站也试图在搭建一条情绪触发消费的电商链路。例如年轻人爱上旅游，B站就跟华侨城文化旅游节建立合作；Z时代热衷二次元，B站就创建以手办、各类玩偶、耳机、键盘为主的“魔力赏”，其中，“蔬菜精灵”系列盲盒仅用28天就卖出了25万只“菜狗”，众筹到了1390万。</p><p>此外，B站在节点营销上也刻意与整个电商市场区分开，相比其他平台的618、双十一，B站反而更重视高考、毕业季、七夕等特色节点。飞瓜数据显示，2023年高考期间，近7天内“高考”的标签热度明显上升，排名仅次于搞笑、手机游戏等B站高频热词。</p><p>“高考”在B站的热度值一度达到1542.3，相关视频投稿1.2万，播放数高达2.73亿次。一朝解放的学子们消费潜力瞬间爆发，出行游玩、时尚穿搭、美妆护肤……都是目标消费市场，B站不少up主凭借高考内容接到了游戏、手机等品牌推广。</p><p>从某种角度来看，手握大量年轻用户的B站在消费市场的确该有一席之地。但是调研数据显示，2023年消费者更频繁使用的购物软件TOP5为：拼多多（45.8%）、淘宝（40.3%）、抖音（29.9%）、京东（28.1%）和小红书（17.5%）。</p><p>电商之路，漫漫其修远兮，有人的地方不一定有“江湖”，B站与年轻人都要共勉。</p><p class="editor-note">本文来自微信公众号“消费最前线”（ID:xiaofeizqx），作者：江心白，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653857442237697</id>
            <title>魅族停止传统智能手机新项目，2024年手机厂商狂“卷”AI？</title>
            <link>https://www.36kr.com/p/2653857442237697</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653857442237697</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 12:05:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>龙年开工第一天，魅族就宣布了一个重大决定，<strong> All in AI并停止传统智能手机新项目</strong>，在此之前，已经有多家手机厂商争相布局AI大模型，这意味着，又有一家手机厂商决定死磕AI。</p><h2><strong>1.魅族宣布：All in AI</strong></h2><p><strong>2024年2月18日，魅族宣布 All in AI，同时停止传统智能手机新项目，全力投入明日设备 AI For New Generations。</strong>魅族计划，今年将发布首款 AI Device 硬件产品，并更新面向AI时代打造的手机端操作系统，与全球顶尖的 AI Device 厂商展开正面竞争。除了AI Device 产品，魅族还将重构Flyme 系统、建设 AI 生态。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_22d3891b8c954d37a1fb9a00cd100909@5940768_oswg200820oswg932oswg511_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：魅族科技公众号</p><p>另外，<strong>爱企查App显示，魅族已经申请注册了“孔明 AI”、“孔明AI大脑”、“KONGMING AI”商标，</strong>足见魅族的决心。而魅族的底气，来自于完善的研发和供应链等硬件团队以及体系化开发、设计、交互的软件团队。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_7253af69637e4576b8e818158e7b0f61@5940768_oswg128459oswg1200oswg878_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：爱企查</p><p>不过，虽然决定停止传统智能手机新项目，但是有星纪魅族人士告诉“界面新闻”，<strong>这并不意味着之后魅族不再推出手机形态的产品，</strong>而是将会在产品中融入AI方案，打造与传统智能手机不同的产品。</p><p>同时，为了不影响老用户的使用，<strong>“在魅族 All In AI 过渡期内，原魅族 Flyme、Flyme Auto、Flyme AR、MYVU、PANDAER 以及无界智行业务的用户体验及服务将不会受到影响。”</strong>另外，魅族还将对在售手机的用户提供原有的售后及相关服务保障。</p><h2><strong>2.手机厂商开“卷”AI</strong></h2><p>新年开工第一天，除了魅族，OPPO创始人、首席执行官陈明永通过内部信，表明了OPPO未来几年的发展方向也是AI。<strong>陈明永认为，“从发展阶段来看，AI手机将成为继功能机、智能手机之后，手机行业的第三阶段。”</strong>而在此之前，OPPO已经通过语音助手小布、安第斯大模型等布局AI手机。除此以外，OPPO还专门成立了AI中心，未来资源将向AI集中。可见，OPPO也致力于成为AI手机时代的引领者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1262d539410347a5875cd7135fb84e7e@5940768_oswg187735oswg492oswg839_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：微博截图</p><p><strong>其实，2023年开始，各大手机厂商就已经开“卷”AI大模型，</strong>7月，华为发布盘古大模型3.0；10月，小米宣布将AI 大模型植入系统；11月，vivo发布了自研的AI“蓝心”大模型；今年1月，荣耀揭晓了自研的“魔法大模型”。</p><p>到目前为止，国内几大手机厂商不仅都有了自己的AI大模型，还都公布了在AI方面的规划，不夸张地说，AI已经成为了手机行业的新方向。不过，手机厂商开“卷”AI，背后的原因是什么呢？</p><h2><strong>3.AI“救场”智能手机？</strong></h2><p>市场调研机构Techlnsights发布的一份预测报告显示，全球智能手机行业正面临“寒冬”。<strong>2023年，全球智能手机换机率为23.5%，创历史新低。同时，消费者平均换机周期也长达4年多，可见，消费者的换机意愿正在减弱。</strong>而之所以导致这个情况，一是因为智能手机的价格越来越高，二则是因为如今的智能手机同质化严重。</p><p>智能手机行业创新力不足，手机厂商们纷纷开始“卷”内存、续航、折叠屏等，却还是无法满足消费者多样化的使用需求，因此智能手机行业急需新的发展方向。而AI与智能手机的结合，不仅可以提升用户的使用体验，还可以刺激消费者的换机需求。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_0c19c90cf6284483810d236648d92877@5940768_oswg249296oswg2048oswg1152_img_jpg?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：罐头图库</p><p>只是，想要靠AI给智能手机赋能并不是一件容易的事。目前AI的应用场景比较有限，这也导致如今AI的应用效果不如手机厂商的宣传效果。想要让AI更加智能，需要反复训练，而这会涉及到用户的隐私问题，<strong>此前国外社交新闻站点Reddit和WPS就曾陷入用户隐私信息的舆论中</strong>，因此如何在合法且不引发用户反感的情况下训练AI，让AI越来越智能，成为不少企业需要解决的问题。</p><p>对各大手机厂商来说，AI或许是一个新方向，但是由于如今AI的发展仍旧面临一些问题，AI能给手机行业带来多大的改变，还需要时间给出答案。</p><p class="editor-note">本文来自微信公众号“趣解商业”（ID:qujieshangye），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653966202764416</id>
            <title>OpenAI为什么总是领先一个版本</title>
            <link>https://www.36kr.com/p/2653966202764416</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653966202764416</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 12:02:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_7c562287fc7146969c19a46dd4c139d7@46958_oswg163044oswg742oswg489_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Sora视频模型的发布，几乎复刻了一年半之前GPT-3初登场时的AI圈盛况：&nbsp;</p><p><strong>突然出现，引起热议，广为震惊。</strong></p><p>北京时间2月16日，在没有任何消息外泄、事先预告的情况下，OpenAI在社交平台X（原推特）发帖，首次对外公布了名为Sora的文生视频AI模型。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a6168d0b22ae4a72a4bddfbccc6bf79f@46958_oswg835031oswg917oswg1209_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一句“Introducing Sora, our text-to-video model（介绍一下Sora，我们的文本转视频模型）”，切入正题之简短，比起宣发，更像是一则告知：<strong>是的，我们又掏出大的来了。</strong></p><p>之后，便是对Sora模型的能力介绍：Sora可以创建长达60秒的视频，其中包含高度详细的场景、复杂的摄像机运动以及充满活力、情感的多个角色。&nbsp;</p><p>还附上了演示案例的对应Prompt（提示词）：美丽、白雪皑皑的东京城很繁华。镜头穿过熙熙攘攘的城市街道，跟随几个人享受美丽的雪天并在附近的摊位购物。美丽的樱花花瓣随着雪花在风中飞舞。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a2de27cfeb0344e988ec5b93bf3f4ecd@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于Sora，业界评价并不统一：&nbsp;</p><p><strong>有人100%认可，也有人120%、200%认可。</strong></p><p>360创始人周鸿祎发文称，Sora意味着实现通用人工智能可能从10年缩短至1年，该模型展现的不仅是视频制作的能力，还展现了大模型对真实世界有了理解和模拟之后，会带来新的成果和突破。&nbsp;</p><p>英伟达人工智能研究院首席研究科学家Jim Fan将Sora称作是视频生成领域的GPT-3时刻：Sora是一个“数据驱动的物理引擎”，一个可学习的模拟器或“世界模型”。&nbsp;</p><p>高强度网上冲浪且一向心直口快的马斯克则直接打出gg&nbsp;human（人类输了） 。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_859269d1c10a4fb5b50ce4bc8287a88d@46958_oswg759628oswg905oswg1092_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>暂且不去深究后续影响到底是积极还是消极，能给AI、影视、社媒等一众行业同步带来颠覆性王炸、划时代之感的，又是OpenAI，总是OpenAI。&nbsp;</p><p>像是一群工程师还在讨论如何进一步完善登月计划，OpenAI的团队已经从火星传回来一组自拍——他们总是领先一个版本，为什么？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3b448392ef5b40aabcdae16838fd6f93@46958_oswg797239oswg923oswg1135_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>前文英伟达AI研究院科学家Jim Fan对于Sora的评价，从技术层面来看很有参考性：他将Sora定义为物理引擎和世界模型。传统意义上的视频画面是二维，而人们身处的物理世界是三维的。&nbsp;</p><p>这成为了AI视频模型设计之初的理念区别：在生成视频的过程中，AI的作用到底应该是将多段视频片段拆分组合，还是应该作为一个主体，构建并记录一个虚拟的AI空间。&nbsp;</p><p>OpenAI的选择是后者。&nbsp;</p><p>其官网发布的Sora技术报告中，有一句话值得注意：“我们的结果表明，发展能够模拟物理世界动态的通用模拟器是一条充满希望的途径，具有前所未有的准确度和现实感。”&nbsp;</p><p>做一个粗浅的理解就是，Sora不是编辑视频，而是在生成视频之前先建模一个空间，然后变成一个镜头记录这个三维立体的虚拟空间。&nbsp;</p><p>立体建模能展现信息量远远多于平面图，<strong>从设计思路上OpenAI就领先了一个维度，或者说提前了一个版本。</strong></p><p>当然，更多的信息量意味着更庞大的数据流，在有限算力内跑出更好效果、在保证效果的前提下尽量节约算力，本质上是同一个问题：AI计算效率。&nbsp;</p><p>但对于OpenAI来说，这些问题都有经验可循——<strong>从ChatGPT到GPT-4等等项目的技术积累，成为OpenAI构建Sora模型的良好地基。</strong></p><p>受大语言模型成功案例启发，OpenAI在探索视频模型时就在思考“如何获得类似的好处”：大模型运转期间，token（词汇单元）作为自然语言处理任务中的最小文本单位，承载着输入信息的作用，帮助模型对文本进行处理和理解。ChatGPT将代码、数学以及各种不同的自然语言一并拆分为token，再交由模型对token进行处理和理解，并能够通过学习token之间的关系来获取更多的语义信息。&nbsp;</p><p>同理，在视频生成模型中，OpenAI也创造了与token对应的数据单位“Patch”（图像单元），将图形语言转化为对应格式的Patch进行计算，在保证模型扩展性的同时，大幅提升单位算力内的运算效率。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_38265689e8e345c68f4d3db82b141c04@46958_oswg213146oswg1080oswg201_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在模型的前端，OpenAI同样用上了自己在GPT系列模型的成果：&nbsp;</p><p>和文本对话类似，训练文生视频的过程中，除了需要视频素材案例之外，同样需要大量对应的文字说明。OpenAI采用了最初在DALL·E 3中提出的“重新加标题”模式，用具备高度描述性的标题生成器为训练集中的视频素材生成文字说明。生成结果也证明了，在制作期间为素材添加额外的说明，可以提高包括准确性在内的整体视频质量。&nbsp;</p><p>此外，仿照DALL·E 3的做法，OpenAI还另外使用GPT对用户输入的简短提示词进行了更便于AI理解的扩写，把用户输入的文字扩充成更长、更详尽的说明，再交由视频生成模型进行处理。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_358996e42ee6428082fad6003e154d5b@46958_oswg393563oswg1080oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于OpenAI这类技术驱动型公司来说，经验和技术的积累都是加速度，有迹可循的成功经验叠加团队自身对AI概念领先理解，让OpenAI总是能踩在自己的肩膀向上，或是推着自己加速向前。&nbsp;</p><p>比技术领先更可怕或者说更值得友商在意的，是这种领先往往会成为惯性，一步快步步快。指望靠加速追赶和对标与OpenAI看齐，在配套设施愈发成熟的阶段，难度恐怕只会不降反增。真正的增量，仍在顶层设计的创新之中。&nbsp;</p><p>所以，与其说是AI挤占了人的创新空间，倒不如说是AI拉高了有效创新的门槛：设计AI，或者能超越AI创意的设计，才是大模型时代的有效增量。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/3tW9UTKVWp2m1kYiGXcyfg" rel="noopener noreferrer nofollow" target="_blank">“AI蓝媒汇”（ID:lanmeih001）</a>，作者：陶然，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653950714318084</id>
            <title>XR乱战2024：VisionPro引爆的下一代计算平台之争</title>
            <link>https://www.36kr.com/p/2653950714318084</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653950714318084</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:58:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2024 年才过去一个多月，XR（扩展现实，AR、VR、MR 的统称）领域又重新「热」了起来。</p><p>苹果 Vision Pro 当居首功。春节前，苹果在美国正式发售了旗下首款 MR 混合现实设备 Vision Pro ——苹果称其为「空间计算设备」。在此之前，MacRumors 援引知情人士报道称，Vision Pro 在预售阶段就卖出了超过 20 万台，收入近 7 亿美元。</p><p>不过首批媒体评测解禁后的结果让人大跌眼镜：<strong>几乎没有一个评测人认为 Vision Pro 能够像初代 iPhone 一样，在大众市场「一炮而红」。</strong>不是说 Vision Pro 不好，恰恰相反，Vision Pro 在核心体验—— MR 混合现实——方面做到了一个极致，问题是在佩戴、暗光表现、续航等方面都有待改进，更关键的当然还是价格：</p><p><strong>2.5 万元（3500 美元）起，是真的很贵！</strong></p><p><strong>第一代 Vision Pro 更像是一款面向开发者、果粉和 XR 爱好者的产品，苹果可能希望借此验证市场、打好 visionOS 生态的基础，再通过成本的降低谋求第二代平价款空间计算设备的爆发。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_494b85ffdfcb41d19a0a3ec43505e8ff@1547419282_oswg52802oswg992oswg558_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图/苹果</p><h2>Vision Pro引爆了新一轮XR热潮</h2><p><strong>但今年让 XR「热」的又不只是苹果。</strong>作为国内前三大 AR 眼镜厂商，Rokid、XREAL 和雷鸟创新从去年就开始了新一轮的密集融资，同时也在陆续迈出从「头戴显示器」到「真 AR 眼镜」关键一步。</p><p>耐人寻味也让人期待的是，他们选择的光学透视（OST）路线与苹果 Vision 选择的视频透视（VST）路线有根本上的区别。与此同时，还有全球更多厂商或准备或正在加入这场路线之争。</p><p><strong>作为 XR 行业绕不开的全球巨头，Meta 选择了「通吃」</strong>：在欧美文娱圈火了的 Meta x 雷朋智能眼镜，下一代将加入显示屏幕和生成式 AI，走轻便的光学透视路线；Quest 3 继续走在视频透视（VST）路线上，试图凭借「还可以的」MR 体验，争取成为全球消费者的 Vision Pro「平替」。</p><p>还有 XR 芯片公司万有引力，也计划在 2024 年量产首款 XR 芯片；联发科在继索尼 PSVR 2 后，也开始牵手 Meta 联合研发 AR 眼镜专用芯片。</p><p><strong>2024 年，我们将看到与此前迥异的 XR 行业，将成为新主流的头戴式 MR ，将与眼镜式 AR 互相争夺下一代个人计算平台的主导权。</strong></p><h2>XR项目密集融资，巨头跑步入场</h2><p>春节前，小雷（ID：leitech）到合肥参加了 Rokid 举办的 AR 生态大会，这也是 Rokid 第二届 AR 应用开发大赛的决赛。应用开发大赛不少见，每一家致力于生态的平台公司，都会举办类似的活动，意图都是吸引更多开发者进入生态，Rokid 也不例外。（关于这场大会，雷科技有现场深度报道《<a href="https://mp.weixin.qq.com/s/WIbXcS5Fc2UpzIj2-dDNfw" rel="noopener noreferrer nofollow" target="_blank">从一场比赛，到Rokid的AR生态梦</a>》，戳链接看详情。）</p><p>2023 年初，Rokid 就在杭州举办了首届 AR 应用开发大赛，年中又发布了第一款真 AR 平台—— Rokid AR Studio，由 Rokid Max Pro（眼镜）和 Rokid Station Pro（主机）组成，同时支持 SLAM 定位、6DoF 和手势追踪。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_c89e7dee346943c291cba5931b580595@1547419282_oswg309550oswg1600oswg1066_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">面向开发者的一代，图/ Rokid</p><p><strong>至此，Rokid 之心「路人皆知」，他们已经跨出了转向真 AR 平台的关键一步。</strong></p><p>一家扎根杭州的 AR 平台公司为何要将第二届应用开发大赛决赛迁移到合肥？答案在于：融资。2024 新年伊始就有消息传出，Rokid 完成了由合肥市政府整体牵头的新一轮战略性融资，规模近 5 亿元。就在两个月前，Rokid 才完成了一轮 1.12 亿美元（近 8 亿人民币）的融资，估值也顺势突破 10 亿美元，跻身「独角兽」之列。合肥让蔚来再上新台阶的事情在业界被传为美谈，拥抱高科技产业的合肥自然也想要在XR赛道“掐尖儿”。</p><p><strong>就在 Rokid 完成新一轮融资的几周后，另一个TOP玩家XREAL 也宣布完成又一轮 6000 万美元规模（约合人民币 4.3 亿元）的战略融资，估值同样突破 10 亿美元，算是成功地跻身独角兽行列。</strong></p><p>而在去年，中国 AR「御三家」的剩下一家，背靠华星光电（TCL）的雷鸟创新也火速完成了两轮融资，一轮过亿，一轮数千万。此外，INMO 影目科技、致敬未来等 AR「新秀」也都完成了一轮融资。除了XR硬件厂商，产业链上下游也在走热，XR 芯片厂商万有引力已完成 A 轮数亿元的融资，米哈游、红杉继续跟投。</p><p>在全球范围，大量XR初创公司在寻求更多的融资，更多大公司在进入这个尚显拥挤的赛道，纷纷打造或者说猎取可与苹果就Vision Pro一战的公司。上个月的 CES 2024 前夕，三星就联合高通、谷歌宣布共同开发一个 MR 平台，媒体报道称将在 2024 年末发售。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_bd389a5e1226477baeb8d4de3ebf392e@1547419282_oswg178678oswg1920oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图/三星</p><p>密集的融资、巨头的涌入，既代表了资本的热情，也代表了 XR 公司对于「弹药」「粮食」的迫切需求。<strong>兵马未动，粮草先行。</strong></p><h2>不甘沦为“显示器”，XR想做新一代计算平台&nbsp;&nbsp;</h2><p>过去两三年，AR 眼镜领域发生了根本的变化，新涌现的 AR 眼镜品牌不再谋求十年前谷歌眼镜的「一锤定音」，而是多选择从眼镜式「显示器」做起，主打观影和游戏场景。</p><p>因为这是相对更好做的：</p><p>不存在内容生态的困难，现成的所有 2D 内容，包括电视剧、电影、游戏，都能直接从实体屏幕轻松迁移到空间中的虚拟屏幕；</p><p>教育市场难度较小，消费者不需要思考 AR 的用途，因为一切都没变，只是显示画面的载体从一台显示器变成一副眼镜；</p><p>不用挑战性能、功耗和发热的「不可能三角」，以及与眼镜厚度、重量之间的平衡。</p><p><strong>但从另一个角度来看，AR 眼镜的发展也受限于「显示器」的定位，消费者对于显示器和计算设备也不会一概而论，尤其是在Vision Pro横空出世之后。</strong></p><p><strong>做新一代计算平台，成为XR设备们的新目标。</strong></p><p>在春节前举办的那场 AR 生态大会上，Rokid 创始人兼 CEO 朱铭明透露，他们将在今年 Open Day（开放日）发布一款重要新品。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a32e35637d3748a8a0a0478120b66c91@1547419282_oswg1618110oswg1383oswg921_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">祝铭明，图/ Rokid</p><p>根据雷科技（ID：leitech）从 Rokid 了解到的信息，<strong>他们将于今年上半年发布这款定位「普惠版空间计算套装」的产品，包括一款 AR 眼镜和一款 Station 2 主机。</strong></p><p>考虑到去年 Rokid AR Studio 套装 8998 元的定价，「普惠版空间计算套装」应该要比这个价格便宜不少，不过暂不知晓配置上会有哪些调整。但如果不出意外，普惠版至少会继续同时支持 SLAM 定位、6DoF、手势识别等关键技术。</p><p><strong>XREAL 也终于迈出那一步了。</strong>今年 CES 前夕，<a href="https://www.leikeji.com/article/60346" rel="noopener noreferrer nofollow" target="_blank">XREAL 面向开发者推出了 Air 2 Ultra</a>，首次提供了完整的 6DoF 支持，通过两侧增加的双目鱼眼摄像头，也支持了手部追踪等功能。此外，眼镜售价达 699 美元（近 5000 元人民币），本体的重量控制在 80g。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_f8f4b3e82cc14eccb48ebb473aae0ba2@1547419282_oswg52870oswg1024oswg749_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Ultra 两侧的鱼眼摄像头（3D 传感器），图/ XREAL</p><p>XREAL 没有透露 Air 2 Ultra 的算力来源，预计还是要通过外接手机或主机的方式提供算力，主机搭载的处理器和售价都暂且未知。</p><p>作为「配套」，XREAL 这次还专门提供了开发套件，包括 XREAL AR 环境启动器 Nebula（Android、Mac、Windows）、最新版 XREAL SDK。这样一看，XREAL 大概要在今年复制 Rokid 走过的路。</p><p>中国AR“御三家”剩下的雷鸟创新尚未开始面对开发者群体。他们在去年底和今年初分别发布雷鸟 X2 以及 X2 Lite：前者搭载高通骁龙 XR2（第一代），搭载一颗支持拍摄的 1600 万摄像头，不支持手势追踪，交互主要依赖触摸、点击镜腿，或者是「配件」雷鸟 Ring 智能戒指；Lite 主要降低了配置和重量，处理器换成了骁龙 AR1，重量也从 119g 降至约 60g。</p><p>但 2024 年，雷鸟创新终归还是面对生态的问题。<strong>就像朱铭明说的，初创公司不能等待生态成熟才做，等到生态成熟的时候，就没有初创公司的事了。</strong></p><p>别忘了苹果 Vision Pro。就在 Vision Pro 发售前一天，苹果在<a href="https://www.apple.com/newsroom/2024/02/apple-announces-more-than-600-new-apps-built-for-apple-vision-pro/" rel="noopener noreferrer nofollow" target="_blank">新闻稿</a>中宣布，<strong>visionOS 上已经有了 600 多款专为 Vision Pro 打造的新应用，还有超过 100 万个兼容的 iPadOS 应用。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_0d086f6cffee4fc49ef8f6780f705f79@1547419282_oswg214816oswg1280oswg853_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图/苹果</p><p><strong>生态包括应用生态，也包含内容生态，后者可能更重要，这样看，iPhone 15 Pro 系列支持空间视频拍摄的重要性也被低估了。</strong>按照 iPhone 14 Pro 系列 2023 年上半年 4750 万台的出货量，至少可以判断 iPhone 15 Pro 系列未来半年内的出货量，也会是数千万台级别的，而这意味着在 3D 视频内容拍摄上将迎来供给端的巨大变化。</p><p>事实上，iPhone 15 Pro 系列发售后，Rokid 和 XREAL 也先后宣布了各自平台对苹果空间视频的观看支持。而 Vision Pro 的发售也势必牵引更多开发者进入空间计算应用的开发生态，2024 年，能不能吸引开发者为平台开发和迁移应用，这对于每一家 XR 厂商都将是一次关键的挑战和机遇。</p><p>虽然截胡Vision Pro发新品，但Meta 对 Vision Pro 的到来，其实是“乐见其成”。</p><p>一是 Meta 创始人兼 CEO 扎克伯格一直认为，如果能有至少一个强大的竞争对手，可能会极大地推动这个市场的发展。这里既包括消费者的认知层面，当然也包括市场规模的扩大。</p><p>二是 Quest 3 的起售价是 500 美元——只有 Vision Pro 的七分之一，考虑到功能性上两者大体相同，区别更多在体验的完善上，<strong>Meta 认为那些对 Vision Pro 感兴趣又被价格吓退的消费者，会转而在 2024 年更多地考虑 Quest 3。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_beabf0c3b7514b1d8ccfb442ae204e6a@1547419282_oswg614213oswg1920oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Quest 3，图/ Meta</p><p>Meta 也不是「干等」。和过去头戴式 VR 的定位不同，Quest 3 选择和 Vision Pro 一样以头戴式 MR「出道」，并且受益于更好的硬件配置和算法，Quest 3 也能通过视频透视（VST）技术实现不错的 VR 与 AR 体验切换，还有眼球追踪、手势交互设计以及更广的视场角等。同时 Meta 还在推动 Quest 上的 VR 应用适配新的 MR 平台，让 Quest 3 用户在 VR、AR 模式下都能体验。</p><p>当然，尽管我们说 Vision Pro 很贵，更像是面向开发者、极客群体的一代产品，但在 2024 年，还没有一家厂商、一个从业者能忽略它。</p><p>目前，Vision Pro 还只在美国市场发售，但苹果方面一再指出，今年晚些时候将在全球更多国家和地区推出。<strong>至于国内市场的发售日期，有国内网友跑到纽约问到了苹果大 Boss，库克对此回应道：</strong></p><p><strong>很快了。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_7fcab414fd064eee8feeda107850b21b@1547419282_oswg697982oswg1960oswg1306_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">发售日当天，库克到 Apple Store，图/苹果</p><p><strong>根据最新的供应链消息，苹果 Vision Pro 最早将于 4 月份在中国市场发售，「最晚时间不晚于5月。」</strong>按照知情人士的说法，「工信部注册流程已接近于完成。首批在华销售货源会比较紧张。」</p><h2>群雄大乱斗，XR迎来至关重要的一年</h2><p>正如前文所说，2024 年我们会看到更多大公司、创业公司涌入到 XR 领域，可以想见，他们将在资金、产品、市场份额等不同层面掀起一场全球大乱斗。但无论从哪个方面来看，这场乱斗都不会是决定性的。</p><p>如果XR 的终局是下一代通用计算平台，而不是下一代游戏主机或者私人电影院，那实际上到目前为止，可能只有 Vision Pro 勉强接近这个目标，另外，三星联合谷歌、高通计划今年推出的 MR 设备（搭载骁龙 XR2+ Gen 2）也有希望。</p><p>但不管是有计算性能却不轻便的 Vision Pro，还是轻便却性能一般的一众 OST 眼镜，他们都面临一些共同的问题。</p><p>大概一个世纪前，鲁迅先生在那篇《记念刘和珍君》中写道：真的猛士，敢于直面惨淡的人生，敢于正视淋漓的鲜血。XR面临的“淋漓的鲜血”是什么？</p><p>首当其冲的问题就是 XR 产品至今也没让消费者明白，把应用和内容从手机、电脑屏幕移到空间（不管是虚拟还是真实）中到底有什么价值？——<strong>目前厂商们谈得较多的是私密性，隐私性，比如可以带着XR设备在家观影不打扰家人，在公共场所观影不打扰旁人抑或被旁人窥见，但这样的场景还不够通用。</strong></p><p>VR 也好，AR、MR 也罢，我们最常听到的一种说法就是刚戴上很新奇，甚至很惊艳，但接着就会觉得平淡。就算是 Vision Pro 也没能绕开这个问题，作为首批提前拿到的媒体，The Verge 那篇 Vision Pro&nbsp;<a href="https://www.theverge.com/24054862/apple-vision-pro-review-vr-ar-headset-features-price" rel="noopener noreferrer nofollow" target="_blank">评测</a>的标题就是：</p><p><strong>「magic，until it's not」（乍见惊艳，后觉平淡）。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1977339e75d64a8cb7f748723f29e148@1547419282_oswg3556230oswg3354oswg2274_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图/ The Verge</p><p>这既有空间内容、应用生态贫瘠的缘故，也是因为所有人——操作系统厂商、开发者和用户，都还没有准备好从 2D 界面交互转向 3D 界面交互。从 2D 到 3D 界面，我们看似增加了一个维度，有了更多的自由度，但实际在交互「秩序」没有确立之前，一切都是混乱的。</p><p>在 Vision Pro 中，2D 界面仍然是最主要的交互形态，这延续了手机、电脑的交互模式。就算是苹果，也只是在逐步引导用户尝试 3D 模型、空间视频等形式，或许在从 2D 交互完全升级到 3D 交互之前，我们都需要一段从 2D 到 3D 的过渡阶段。可以理解真实世界并建模的大模型AGI技术，则让XR设备以及空间计算的3D交互看到了新的曙光，但原生3D交互的实现，依然需要时间。</p><p>在那之前，XR 这场关乎下一代计算平台的战事还是乾坤未定。但尽管这么说，2024 年对于 XR 行业来说依然会是极其关键的时刻，就如 IDC 不久前在一份报告开篇写道：</p><blockquote><p>2024 年将是 AR/VR 产业发展漫长画卷中至关重要的一年。</p></blockquote><p>题图来自苹果。</p><p>本文来自微信公众号“雷科技”（ID:leitech），作者：雷科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653927341703425</id>
            <title>MWC24前瞻：更“混搭”的展会，也更值得关注</title>
            <link>https://www.36kr.com/p/2653927341703425</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653927341703425</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:55:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还有不到一周时间，2024年度的MWC（世界移动通信大会）就要在西班牙巴塞罗那正式拉开帷幕。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_47253a6dc36740508836e1f6c24a3ccd@000000_oswg22057oswg750oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>众所周知，由于各种各样的原因，前几年的MWC要么曾被一度取消，要么便是在规模上明显有所缩水。</p><p>正因如此，当目前整个消费电子行业普遍都认为市场开始呈现出“回暖”迹象时，今年MWC无论参展厂商的阵容、还是在目前已知的展出内容上，都得到了显著的加强。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_879146f963e546c2bf09f263180a25dc@000000_oswg43909oswg750oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且对于我们三易生活来说，这也将是我们继2019年之后，久违地再次前往巴塞罗那、为大家第一时间带来相关报道的一届MWC。因此在我们尚未动身的此时此刻，将首先为大家带来本届MWC的前瞻，也相当于是变相“预告”我们接下来的一部分报道内容。</p><h2><strong>首先，这是一届没有明确“主题”的MWC</strong></h2><p>如果大家此前就有关注MWC展会、或者是关注过其“国内副本”MWCS（即MWC上海展），可能就知道，他们通常每一届都会有一个提纲挈领的“副标题”。</p><p>实际上，这个“副标题”未必会限制现场的展出内容，但它确实会在一定程度上概括此次展会的主要方向，并且可能会对之后一年的整个移动通信和消费电子产品潮流产生潜在的影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ff22e1be25764fc4a43f855b2cf97814@000000_oswg39244oswg750oswg340_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而，在本届MWC的官网上取消了显眼的、统一的“副标题”，也就是没有一个主要的展会主题。取而代之的是一个意义（指代）并不明确，而且也没有放在官网显眼位置的“Future First（未来优先）”作为口号。</p><p>为什么会这样？其中一种解释，是今年MWC在展出的内容上相比往年可能更加多元化，以至于官方并不能找到一个占“主导地位”的方向。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_bfc64deafd554ffc857a2df19e3b1f62@000000_oswg82041oswg750oswg421_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">往年的MWC现场</p><p>从行业技术换代的角度来说，这其实很好理解。比如，不管是5G、WiFi7、AI，还是工业4.0，它们现在都方兴未艾，远没有到被下一代新标准取代的时候。所以对于整个通信和消费电子行业而言，现在确实找不到一个具有“划时代”意义、适合作为本届MWC主题的方向。当然，这并不见得是坏事。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3e539ca069f7498bb85c1210253b08b3@000000_oswg44086oswg750oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，从另外一个“俗”一点的角度来说，这也可能是因为本届MWC找到了更多的“金主（赞助商）”。所以可以看到在它的官网上关于会议主题的内容，被明确地列为了至少六个方面，而且每一个都有显眼的赞助商Logo。</p><p>显然也没有什么不好的，因为正如我们前面讲到的那样，当各大厂商变得更愿意为MWC上的宣传而掏钱时，这本身就代表他们对于今年（以及之后的）市场有了更高的期待，并且也会更愿意拿出更高端、技术创新更多的产品带给消费者。</p><h2><strong>其次，即将亮相的新品可能会相当惊艳</strong></h2><p>既然我们前面已经讲到，厂商们对于2024年的信心。那么很显然，这必然就意味着在今年的MWC现场，我们将有望看到一些比过去更富创新魄力，定位也可能会更高的产品发布和展示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ef79f0b937c54d7b9f15c5df77757782@000000_oswg30192oswg750oswg478_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">小米14 Ultra已经公布的部分外观</p><p>比如一个典型的例子，就是已经宣布将在2月22日召开新品发布会的小米14 Ultra。作为小米旗下的第五世代影像超旗舰，在如今这个其他品牌已经普遍赶上了“1英寸”、“多主摄”、“大底潜望”配置的背景下，小米要怎么做出产品的差异花，如何再一次立住本身的定位，显然就是很值得关注的一件事。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_db79dd70b2214b22bf5eb1d2c768f277@000000_oswg61745oswg750oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且从目前的消息来看，小米方面似乎还有意将小米SU7也带到MWC进行展示。而这很可能会是这款新车正式发布前首次在海外市场亮相。相比于此前的“预发布”，这次在MWC的展出显然意义会更加重大一些。</p><p>当然，除了小米，今年在MWC现场也大概率会有更多的新机、特别是顶级旗舰亮相。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_60a899729b124c2ebed6c00786f04028@000000_oswg27676oswg750oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如，荣耀可能会在MWC上公布他们的影像旗舰Magic6 RSR。这款产品实际上在此前的发布会上就已经有所暗示，而且它也大概率会成为国产1英寸旗舰CMOS（OV50K）的首发机型。因此它的影像表现到底如何，能否抗衡LYT900、HP2X等顶级CMOS，以及为何会延迟发布，自然就成为了此次MWC相当值得探究的重点。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3b58198f0a9e4d3abdf5de288cd07be4@000000_oswg39015oswg750oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>又比如说，根据此前官网上的“明示”，HMD也大概率会在本届MWC期间发布新机。而且有可能会是不止一款“不用诺基亚商标、但却复刻经典诺基亚手机造型”的新品。颇为值得玩味的是，HMD旗下的上一代旗舰手机诺基亚9 Pureview，也正是在4年前的MWC期间发布，而且当时我们就在现场。如今恰逢新机亮相，颇有种“时光回溯”的既视感了。</p><p><strong>MWC不再局限于通讯技术，但这显然没什么不好</strong></p><p>当然，会在此次MWC期间亮相的不只是那些即将上市的机型，还会包括很多大胆的、带有技术前瞻意味的概念产品。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_77abbb15a8664849b9571bba44a2c85b@000000_oswg38785oswg750oswg493_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如目前已有传言称，三星会在今年推出量产的三折叠形态手机/平板。从以往的经验来看，这很可能就意味着三折叠结构的各种“概念机”，会成为一系列屏厂今年在MWC上展出的一大亮点。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_68d3c2d1cb154aea97661b7cb6983585@000000_oswg75533oswg750oswg817_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>又比如说，此前就有消息称，联想有可能会在本届MWC期间展出他们的“透明屏”笔记本电脑，以及配备多款AI CPU的新款旗舰产品。从以往的经验来看，这很有可能会成为其国内春季新品阵容的一次大规模“前瞻”。</p><p>不仅如此，根据现有的公开信息显示，诸如高通、AMD、Intel等芯片厂商，以及微软、Meta、谷歌等互联网企业，还有华擎、仁宝、光宝、广达等上游代工厂，今年都会参与MWC。所以我们甚至有可能会在此次展会期间，看到诸如骁龙X Elite PC，甚至是Intel“箭湖”和AMD Zen5的一些技术展示或预览。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_278d49ca7115422795df870e701fcef0@000000_oswg45240oswg750oswg348_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这似乎也就意味着，今年的MWC不仅仅会是手机、移动设备的一次大规模“嘉年华”，还很有可能会成为比年初CES更引人关注的一次消费电子大展。</p><p>从这个角度来说，如今的MWC其实早已不再局限于移动设备、通信产品的展示和交流，更像是变成了一个广义上的消费电子技术和产品的展览。虽然它不再那么“纯粹”，但也会更容易被厂商和消费者所接受与关注。而这无论是对于MWC自身、还是对于整个消费电子行业来说，显然都会是一件好事。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649858259&amp;idx=1&amp;sn=ee6834f534c8a0f2187f829dbc8fd76b&amp;chksm=86c5637420a8677ea12e4c9d7d9117ecb92310656f5409e5a475724ed103e33b59ab1df03f05&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653927493452035</id>
            <title>阿里云盘对超容量存储下手，只为让深度用户付费</title>
            <link>https://www.36kr.com/p/2653927493452035</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653927493452035</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:46:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如今来看，网盘似乎并不是一门好生意，并且几乎每一个试图改变网盘行业游戏规则的“勇者”，最终都会长出鳞片、化身新的“恶龙”。就在上线短短两年半之后，阿里云盘也开始像曾经誓要拉下马的竞争对手学习了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_78338632eb444492a8e0f2f796e77832@000000_oswg15772oswg600oswg222_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>日前有用户反馈，阿里云盘方面宣布将从2024年3月1日起对容量超出使用限制的账户执行新的政策，这类用户的在线播放功能、上传、转存、下载、分享、快传等功能可能会受一定影响。用户只有通过开通SVIP会员、购买大容量套餐，或是主动清理超限文件，才能确保正常使用。</p><p>此前在2021年春季公测时，阿里云盘为用户准备了100GB的基础容量，以及300GB的可提升容量。去年8月，阿里云盘又进行了一次按注册时间赠送存储容量的活动，注册越久领取的容量越多。但问题在于，由此所获得的存储空间是有时限的，有效期往往是半年到一年。</p><p>所谓超容量存储、容量溢出账户，基本都是由于用户在阿里云盘各种存储容量赠送活动中领取了大量免费容量，或是所购买的会员服务过期产生。通常来说，对于存储空间超出免费配额，网盘行业的通行做法是限制用户的上传、转存，相当于不再允许用户继续向网盘里存放新的数据，但对于已有数据的使用不会进行限制。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_edf9c54c052842809fad50d1f49b8d4e@000000_oswg27597oswg487oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>要知道对于一切提供云计算服务的厂商而言，个人云的成本其实从来不在存储方面，真正花钱的地方在于海量的带宽消耗，以及对于用户存储在网盘上的数据进行内容审核所带来的成本。阿里云这次限制存储空间超出免费配额的用户正常使用，核心目的其实只有一个，那就是促使用户付费。</p><p>在当年的“网盘大战”时，360率先打响了网盘补贴的关键一枪。免费网盘空间很快就成为了彼时各大网盘争夺用户的法宝，从GB级送到TB级，再到最后的无限空间、永久免费。但这个战略确实也劝退了一批参与者，比如说雷军就曾在金山云的上市发布会上回忆了金山退出网盘行业的原因，“看了自己的账户后发现实在跟不起。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_38f0f0fd6e9b49768d48ed0b7ce45f05@000000_oswg59545oswg600oswg577_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由于网盘厂商赠送了太多的免费空间，以至于当硝烟散去之后，大家赫然发现网盘行业鼻祖Dropbox开拓的卖空间变现行不通了。为了提高用户的付费意愿，限速就成为了网盘行业幸存者商业化的唯一选择。只可惜，这一切也随着工信部在2021年11月明确要求网盘对于非会员的下载速度进行保障而告终。</p><p>遗憾的是，网盘低频且非刚需的属性还决定了它并不适合承载广告，因此在兜兜转转一圈，向用户兜售更大的存储空间就几乎成为了唯一解。在阿里云盘之前，腾讯微云也曾对超容量存储下狠手，要求用户限期清理超量部分，否则账号就将被冻结。那么，为什么阿里云盘会突然对用户翻脸无情呢？其实原因很简单，因为市场环境变了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_6ea61c7024524f288d601ab7ccf43888@000000_oswg27079oswg496oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>诚然，最初阿里云盘是阿里在稳定了toB的企业级业务后，为了补齐阿里云生态圈的空白与短板打造。这也是为什么在2021年春季，百度网盘几乎“统一”了国内网盘市场的情况下，阿里云盘还会喊出“无论免费收费、未来都不限速”，来向用户送福利。但时移世易，三年后的市场环境，乃至阿里本身的小气候都发生了巨大的改变。</p><p>阿里在去年迎来了1+6+n组织变革，也就是阿里集团不再“托底”，各业务开始走向自主决策、自负盈亏、适者生存。再加上，聚焦主业是如今阿里的核心战略，电商又重新成为了头等大事。在这样的剧烈变化之下，甚至当年的“新零售”都在被边缘化，更遑论是阿里云盘。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_b4f7f5a3641043fb982206bf6a007c4c@000000_oswg16810oswg600oswg423_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>原先，阿里云盘是阿里云在自研智能存储和全球加速云网络技术12年后，首次推出个人云产品，它的存在也彰显了阿里云尝试在公有云市场完成业务闭环的决心。而阿里云盘的用户友好型战略，确实也取得了亮眼的表现，仅用不到3年时间就收获了超过2亿的注册用户。</p><p>但空有用户却无法顺利变现，这就是网盘行业不被认为是一个性感生意的关键，如今盈利已然变成了摆在阿里云盘面前不得不考虑的问题。在这样的情况下，继续执行用户友好型的策略，显然就是对于阿里云盘自己的不友好。自然而然的，原先存在于阿里云盘的各个“灰色地带”就会被逐步消除。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_bf86a779f1024818b977624b99f4f10f@000000_oswg19511oswg600oswg405_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>效仿隔壁百度网盘、通过明显区分会员和非会员下载速度显然会行之有效，但阿里云盘毕竟有过“不限速”的承诺，以至于其SVIP用户也就只有一个“优享极速通道”。而清理超容量账号这招既没有将收费摆在台面上，又能真正促使一大批用户付费，毕竟会把阿里云盘存储容量用超的，往往是深度用户。</p><p>阿里云盘这一策略直指的就是借助此前赠送的大量存储空间，在其中存储了诸多数据的用户。在被限制了在线播放、上传、转存、下载、分享、快传等功能之后，这类用户超限存储的数据无异于是被封禁了。而用户想要“赎回”自己的数据，最简单、最直接的方式就是付费。</p><p>前期先大量向用户赠送限时免费存储空间，待到用户将其填满后，再出台容量超出使用限制的措施，阿里云盘这一手阳谋堪称是无懈可击。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649858259&amp;idx=2&amp;sn=1f9c9f9e686720b9f1dbe92af63face6&amp;chksm=865f1a1fd3ab335f5ec247e1f1dc7abb1589537e495775f166076cb8d5ceb6e5f344ec78cd8a&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653923978202630</id>
            <title>激光雷达开年大战，让智驾的2024更有火药味</title>
            <link>https://www.36kr.com/p/2653923978202630</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653923978202630</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:44:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>​1月1日，何小鹏宣布XNGP已覆盖全国243座城市，2月2日，鸿蒙智行宣布，问界车型智驾系统升级，高阶智驾实现覆盖全国99%路段，大城市到小乡村都能用。</p><p>春节期间，我体验了小鹏G6的智驾功能，可用路段几乎不用接管，车道线、红绿灯等均能正确识别。能够大幅提升出行体验的智能驾驶，成长速度比我们想象中快得多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ec5abdbc77f24dbaa02dda33e600ad51@5687509_oswg872913oswg4096oswg2304_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>高速路况简单，问界、小鹏等车企已实现基本覆盖，下一步车企竞争的重点，将是城区领航辅助驾驶。车企准备如何应对接下来的竞争，行业已传出了不少风声。</p><h2><strong>硬件「两极分化」</strong></h2><p>均衡智驾级别与成本，是车企与自动驾驶企业需要谨慎对待的问题，如小鹏出于成本考虑，计划未来持续减少激光雷达。不过现阶段而言，高阶智驾依然难以离开激光雷达。</p><p>去年12月26日发布的问界M9，搭载行业首颗量产的192线激光雷达，拥有长达250米识别距离、184万点/秒成像能力、垂直分辨率达0.1°、雷达扫描频率达20Hz，相较于目前市场上主流的96线~156线激光雷达，堪称「遥遥领先」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_867b8d7674c440e9a53b230b19c618c7@5687509_oswg624958oswg3840oswg2160_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而华为192线激光雷达官宣后不久，北醒光子就官宣旗下256线激光雷达投产，CES2024大会上，激光雷达巨头禾赛科技更是推出了512线激光雷达——AT512，这款雷达探测距离可达300米，最远测距可达400米，成像能力则达到了1288.8万点/秒。</p><p>激光雷达线束越多，捕捉到的物体细节越丰富，建模轮廓越完整，形成的点云图也会更加清晰，而且拥有更高的冗余度和抗干扰能力，能够提升智驾安全性。不过线束太高随之而来的便是成本上升与功耗提高，恐怕只有问界M9这种50万元左右的豪车，才能用得上192线及以上线束的激光雷达。考虑到车载激光雷达的功耗一般在50W以内，对于续航的影响不会很明显。</p><p><strong>卷硬件方面，中国企业经验丰富，按照这个发展速度，相信用不了几年，上千线束的激光雷达就会面世。</strong></p><p>智驾对于芯片也有一定要求，国内地平线公司将于4月发布征程6芯片，算力高达560TOPS，之前NVIDIA发布的Thor芯片算力在达到了2000TOPS。不过相较于雷达等其他硬件的参数提升，算力提高并不困难，单颗算力不足，那就多来几颗芯片就是了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_33c0598743fc4644ad7c17237b3a8808@5687509_oswg218461oswg1280oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>激光雷达+高算力芯片无疑可以提高智驾安全性，但高昂的成本并非每家车企都愿意接受，以特斯拉为首的部分车企，选择了廉价的纯视觉方案。当然，即便是特斯拉，也需要以高算力芯片作为基础，国内部分企业则选择更加极致的路线，低算力芯片+摄像头+少量雷达，即可实现L2+级自动驾驶。</p><p>代表企业有商汤绝影、大疆车载等企业，商汤绝影与哪吒汽车联合推出的智驾方案，仅需16TOPS算力芯片和5R11V（5颗毫米波雷达、11颗摄像头）传感器，就实现了高速、城市路段领航辅助驾驶。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_f113cecd8c774df3847f20063843cf2b@5687509_oswg1709547oswg1920oswg1000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大疆车载推出的方案，最低仅需32TOPS算力芯片，搭配7~9颗摄像头，无需任何雷达，即可实现区域记忆行车。若想实现L2+级领航辅助驾驶，将芯片升级至80TOPS即可，这一套硬件成本还比不上一颗激光雷达。</p><p><strong>汽车智驾硬件已呈现出两大方向，高端车型追求硬件性能提升，成本次要考虑，激光雷达线束数量与芯片算力为主要竞争点。中低端车型则追求极致压榨硬件潜能与低成本，以便于惠及购车预算较低的消费者，如此一来难免对于软件算法提出更高要求。</strong></p><h2><strong>软件「大模型当先」</strong></h2><p>2023年下半年至今，不少车企宣布将AI大模型、生成式AI搬到汽车上，以求将汽车与智能助手、生产力挂钩。如比亚迪的「璇玑架构」，分为云端AI与车端AI两部分，车端AI大模型无需数据上传，拥有更好的保密性，没有网络的情况下，也能执行用户发出的指令。</p><p>相较于AI大模型与生成式AI，大模型在智驾领域的前景肉眼可见，去年毫末智行就发布了自动驾驶生成式预训练Transformer大模型DriveGPT雪湖·海若，以DriveGPT作为云端测评模型，评测车端小模型的行驶表现。毫末智行将场景离散化处理，分割成数十万个小场景，与实际驾驶环境进行匹配，系统可以根据相似的场景，作出智驾推导与判断。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1be9746abfc04158aea481d04d0d7fda@5687509_oswg795166oswg1920oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>自动驾驶企业与车企正在尝试车端部署智驾大模型，但上千亿参数的智驾大模型，哪怕裁减到百亿级参数，由于车载芯片算力问题，暂时反应速度也比不上云端大模型。堆芯片可以解决算力问题，取而代之的则是成本问题。</p><p>大模型的主要优势之一，就在于可以降低智驾生态建设成本。截至2023年11月国内公路里程已达535万公里，而且还在不断变动，全部高精度绘制所需要的成本无法想象。当前虽然摆脱了对高精度地图的依赖，但依然需要「轻量级地图」或「去高精度地图」。</p><p>华为已打破了这一传统，不是一城一城的开通，而是直接全国覆盖。华为所采用的方案与毫末智行相似，<strong>智驾大模型收集到了足够的数据，并离散化处理，成为道路拓扑推理的依据，结合普通导航地图便可实现领航辅助驾驶。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_f940766a711e46438f309860e9e19e9a@5687509_oswg684349oswg3200oswg1600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>车企都在摆脱高精度地图的依赖，但依然需要轻量级地图，这就导致领航辅助驾驶覆盖速度不够快。况且国内公路一直在变化，部分地区可能需要反复绘制，小乡镇等落后地区，恐怕2030年都等不到车企的地图绘制团队。</p><p><strong>通过大模型、离散场景与道路推理，实现领航辅助驾驶乃至自动驾驶，对于算力和数据量的要求更高，整体成本低一些，拥有大量数据后，效率提升较为明显。</strong>有了华为作为先例，2024年或许我们就能看到其他车企采用相同方案实现全国智驾。</p><h2><strong>自动驾驶脚步渐快</strong></h2><p>从近年来各类智驾法律法规的制定、路测牌照的发放，我们能看到相关部门正有条不紊推动自动驾驶商用。</p><p>2024年2月8日，全国首个智能汽车智驾表现数据开放平台亮相苏州。该平台由车控CHEK打造，目的是解决智能汽车信息不对称问题，国内问界、小鹏、蔚来等众多车企已加入该平台，将通过该平台披露智驾接管次数、避障能力等数据。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d0f85c9a3dce4d13a29c9cdb30393920@5687509_oswg2106275oswg1500oswg1875_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>该平台的建立，一方面能够反映出车企的不足之处，为车企指明技术优化方向，另一方面则可以作为消费者买车时的参考，智驾好不好不能只看车企宣传，数据才能说明真实情况。</strong></p><p>软硬件的持续研发与升级，成本的不断降低，都令15万元以内车型看到了普及高阶智驾的曙光。高端车与低价车型的可靠性，我们都能在车控CHEK的平台看到数据，若是高端车型的接管频率高于低价车，恐怕会对车企名声产生一定影响。不过目前智驾硬件成本偏高，短时间内我们无法看到太多成果，也难以做出对比。</p><p>高速NOA较为成熟，今年有可能实现全面覆盖，城区NOA则是今年车企竞争的重点。更高线束激光雷达、更高算力智驾芯片的应用，能够强化汽车的智驾能力。极氪001改款被曝或将成为首款正式搭载NVIDIA Thor芯片的车型，北醒光子256线激光雷达已投产，相信首款搭载该产品的汽车距离上市也不远了。</p><p>大模型的加入则可以大幅提升智驾训练效率，加速智驾算法完善，并且令智驾系统驾驶逻辑更像老司机。</p><p>何小鹏曾表示，2024年是自动驾驶元年。从车企、自动驾驶企业、供应链企业的动作来看，这个元年的火药味格外足。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5ODc5NjcwMA==&amp;mid=2247593339&amp;idx=2&amp;sn=71a95a4a0a76928fcccb70ffe9a91f1e&amp;chksm=a7b68a236673ed0a710d00a9b647b48ae8679d6fbe4185b9d33e9e4c71059b56db5f231d03c4&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“电车通”（ID：dianchetong233）</a>，作者：失魂引，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653877819817091</id>
            <title>中国大模型产业的五个真问题</title>
            <link>https://www.36kr.com/p/2653877819817091</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653877819817091</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:44:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2023年科技领域最热的话题就是AI大模型。这股热潮由美国创业公司OpenAI引领，ChatGPT发布后几个月，中国公司密集发布自己的大模型，整个2023年，中国公司发布的大模型数量已经超过130个。&nbsp;</p><p>OpenAI能够实现技术突破，和许多科技创新领域公司的特点类似。有足够优秀的人才，海量资金支持，多年持续投入，以及对目标坚定。在ChatGPT发布之前的很长一段时间里，产业界和投资界大多不看好OpenAI，但并未动摇该公司的方向。2023年，几乎所有人都认可了大模型的方向，大家认为，OpenAI已经把结果摆出来了，其他公司要做的就是尽快跟进，不断优化，确保能参与未来。&nbsp;</p><p>一些人把过去没有大规模投入大模型的原因归咎于不确定结果。现在已经确定了，算力、数据、人才都可以加大投入，中国公司擅长工程优化，做出能实际应用的大模型产品指日可待。&nbsp;</p><p>但事实真的如此吗？对于OpenAI来说，大模型从来都是确定的方向，OpenAI的大部分资金都花在了算力上，当时英伟达的A100 （AI专用芯片） 价格比今天低很多。据第三方数据机构SemiAnalysis估计，OpenAI使用了约3617台HGX A100服务器，包含近3万块英伟达GPU。光有GPU还不够，投资方微软帮助OpenAI搭建了大模型定制化的算力集群，能够进一步提升这些GPU的效率。在数据方面，OpenAI从数据收集、数据标注、数据清洗、数据整理、数据优化等每个环节都有持续投入。OpenAI团队中大部分人，都来自顶尖的科研机构或科技巨头。&nbsp; &nbsp;&nbsp;</p><p>也就是说，在这种实力和投入力度下，OpenAI依然用了超过八年的时间，才打造出突破性产品GPT4，且存在“幻觉” （也就是答非所问、胡说八道等情况） 。&nbsp;</p><p><strong>为什么中国公司在几个月的时间里，就能做出号称匹敌GPT4的大模型？这是谁的幻觉？</strong></p><p>2023年下半年，陆续有部分大模型被指出是“套壳”，直接套用了国外的开源大模型，在一些检验大模型能力的榜单上排名靠前，不少指标都接近GPT4。多位业内人士告诉《财经》记者，榜单表现越好，套壳比例越高，略有调整表现就会变差。&nbsp;</p><p><strong>“套壳”只是中国大模型产业现状的冰山一角，这背后折射出产业发展的五个问题，它们之间互为因果，每个问题都无法独立解决。</strong>到今天，大模型的大众热度已经明显下滑，2024年，中国大模型产业的问题会进一步暴露。但在热闹、问题之下，大模型已经在产业中发挥价值。</p><h2><strong>模型：原创、拼装还是套壳？</strong></h2><p>2023年11月，阿里巴巴前技术副总裁、AI科学家贾扬清发文称，某国内大厂做的大模型用的是Meta的开源模型LLaMA，只是修改了几个变量名。贾扬清表示，因为改名导致他们需要做很多工作来适配。&nbsp;</p><p>此前，就有国外开发者称，李开复创办的“零一万物”使用的就是LLaMA，只是重命名了两个张量，因此，业内质疑零一万物就是“套壳”。随后，李开复和零一万物均有回应，称在训练过程中沿用了开源架构，出发点是充分测试模型，执行对比实验，这样能快速起步，但其发布的Yi-34B和Yi-6B模型都是从0开始训练，并做了大量原创性优化和突破工作。&nbsp;</p><p>2023年12月，媒体报道称，字节跳动秘密研发的大模型项目中，调用了OpenAI的API （应用程序接口） ，并使用ChatGPT输出的数据进行模型训练。而这是OpenAI的使用协议中明确禁止的行为。&nbsp;</p><p>随后，OpenAI暂停了字节的账号，表示会进一步调查，如果属实将要求更改或终止账户。&nbsp;</p><p>字节对此的回应是，2023年初，技术团队在大模型探索初期，有部分工程师将GPT的API服务应用于较小模型的实验性项目研究中。该模型仅为测试，没有计划上线，也从未对外使用。在2023年4月公司引入GPT API调用规范检查后，这种做法已经停止。且字节大模型团队已经提出了明确的内部要求，不得将GPT模型生成的数据添加到字节大模型的训练数据集，并培训工程师团队在使用GPT时遵守服务条款。&nbsp;</p><p><strong>目前国产大模型中，主要分为三类：</strong> 一是原创大模型；二是套壳国外的开源大模型；三是拼装大模型，也就是把过去的小模型们拼在一起，变成参数量看起来很大的“大模型”。&nbsp;</p><p>其中，原创大模型数量最少，做原创大模型需要有很强的技术积累，且要有持续的高投入，风险很大，因为一旦模型没有足够强的竞争力，这些大规模投入就打了水漂。大模型的价值需要商业化来证明，当市场上已经出现足够好的基础大模型，其他公司应该去挖掘新的价值点，比如大模型在不同领域的应用，或是中间层，比如帮大模型训练、数据处理、算力服务等。&nbsp;</p><p><strong>但现状是，大部分参与者都在“卷”所谓的“原创大模型”，又担心风险太高，于是有了大量套壳、拼装的大模型。</strong> 无论是直接使用开源模型或是拼装模型，只要符合相关规范，都没有问题。到商业化落地阶段，客户也不太会在意是否原创，有用就行，甚至不少客户会因为成本更低，更愿意选择非原创的技术。&nbsp;</p><p>问题在于，即使是拼装和套壳，大家也要不断强调“原创”，为了证明“原创”，就需要调整修改，而这又会影响大模型的迭代能力，陷入内耗。</p><h2><strong>算力：卡脖子还是不想买？</strong></h2><p>大模型的基础之一是海量算力，且是先进算力，因此大模型也被称为暴力美学。英伟达的A100此前被认为是最适合训练大模型的，近期英伟达又推出了更先进的算力芯片H100，但还未在中国市场开售。&nbsp;</p><p>一位英伟达的长期合作伙伴告诉《财经》记者，2023年，A100的售价涨了约1倍，据他了解，2023年密集购买A100的中国公司主要是自身有业务需求的大厂，包括阿里巴巴、腾讯、字节跳动、百度等，创业公司很少。有一些知名大模型创业公司会主动要求和他建立战略合作关系，以此来对外证明自己在投入算力，“不给钱的那种”。&nbsp;</p><p>尽管有美国政府的“出口管制规则”，中国公司想要获得英伟达的算力，并非不可能，目前有很多方式可以选择。除了直接购买，还可以通过英伟达在中国的合作伙伴们购买。GPU本身很贵，买来之后的部署、运营、调试、使用，都是成本。此前业内流传的一句话是，中国不少科研机构连A100的电费都付不起。&nbsp;</p><p>由八张A100组成的DGX服务器最大功率是6.5kW，也就是运行一小时需要6.5度电，同时要搭配大约同等电量的散热设备。按照平均工业用电每度0.63元计算，一台服务器开一天 （24小时） 的电费约200元。 <strong>如果是1000台服务器，一天的电费就是约20万元。</strong></p><p>因此，除了大厂，创业公司很难大规模购买、部署GPU。&nbsp;</p><p>GPU资源还可以租用，在阿里云、腾讯云或是亚马逊AWS等云服务平台上，都可以直接租用A100算力服务。租金同样在过去一年涨了不少。&nbsp;</p><p>但实际情况是，不少大模型公司并不想在算力上做大规模投入。多位关注AI的投资人告诉《财经》记者，一旦创业公司开始部署算力，会出现两个“问题”，一是这个投入没有上限，没有终点，谁也不知道要烧到什么程度。OpenAI到今天还会因为算力跟不上而出现宕机。二是公司会因此变成重资产公司，这对于公司未来的估值有不利影响，会直接影响到投资人的收益。&nbsp;</p><p>2023年，中国不少投资人会直接告诉大模型创业者，先招一些名校背景的人，抓紧开发布会，发布大模型产品，然后做下一轮融资，不要去买算力。&nbsp;</p><p>创业公司们在风口期拿到大量融资，高薪招人，高调发布产品，推高估值。一旦风口过去，继续融资或是上市就需要收入，到时候再通过此前融到的钱，去低价甚至亏本竞标项目，或是直接对外投资来并表收入。&nbsp;</p><p><strong>这就有可能陷入一个恶性循环：不愿意承担算力高投入的风险，就很难在大模型领域有突破性发展，也就难以和那些真正在这个方向上大规模投入的巨头们竞争。</strong></p><h2><strong>数据：低质数据怎么解决？</strong></h2><p>数据和算力都是大模型的基础，在数据方面，中国大模型产业面临和算力同样的问题：是否值得大规模投入？&nbsp;</p><p>在中国，一般的数据获取门槛很低，过去主要是用爬虫工具来收集数据，现在可以直接用开源的数据集。中国大模型以中文数据为主，业内普遍认为中文互联网数据的质量较低。&nbsp;</p><p>一位AI公司创始人形容，当他需要在互联网上搜索专业信息时，他会用谷歌搜索，或是上YouTube。国内的网站或App上，并非缺少专业信息，而是广告内容太多，找到专业内容需要的时间更久。&nbsp; &nbsp;&nbsp;</p><p>OpenAI用于训练大模型的中文数据同样来源于中国互联网平台，但它额外做了很多工作来提升数据质量，这不是普通的数据标注工作能完成的，需要专业团队对数据进行清洗、整理。&nbsp;</p><p><strong>此前就有AI创业者表示，在中国很难找到相对标准化的数据服务商，大多是定制化服务，定制服务又很贵。</strong></p><p>这和是否要大规模投资算力的逻辑有些类似，这笔投入对于很多公司，尤其是创业公司来说，看起来并不划算。如果大规模投入，一旦最后的模型效果不理想，同样是“打水漂”，还不如用开源数据训练，直接开发布会。&nbsp;</p><p><strong>此外，中国市场缺乏有效的数据保护手段，</strong> 一位大厂AI负责人说，“在中国，你能拿到的数据，别人也能拿到”，“如果你花很多钱去做高质量数据，别人可以用很低的成本拿到，反过来也一样。”&nbsp;</p><p>包括数据处理在内的大模型中间环节，在2024年会是一个相对明确的新发展方向。无论是哪种模型，在落地到具体应用场景中时，必须要用专业数据做优化调试，这对于数据处理的要求更高，此外还需要有模型调试、工程优化等环节参与。&nbsp;</p><p>但如果其中的环节又变成了投资人眼里的“新风口”，那又是另一个故事了。</p><h2><strong>资本：只有资本短视吗？</strong></h2><p>以上的三个问题，背后都指向一个共同的方向：资本短视。&nbsp;</p><p>尽管OpenAI已经蹚出一条明确的道路，对于绝大部分公司来说，想从零开始做出成熟的大模型，需要耗费的成本和时间并不会短很多。&nbsp;</p><p><strong>对于大部分投资人来说，每笔投资的目的很明确：退出、赚钱。</strong> OpenAI火了，估值一路攀升，未来还会继续增长。2023年4月，该公司估值约280亿美元，到2023年12月，据美国媒体报道，OpenAI最新一轮估值或将超过1000亿美元。这在投资人眼里是一个非常确定的信号，如果以合适的价格投资中国大模型创业公司，也能在很短时间内做到估值成倍增长。&nbsp;</p><p><strong>中国投资人的耐心只有三五年，这是资本运作模式决定的。</strong> 投资人从LP手里募资，需要在一定年限内退出并拿到可观的收益。投资人退出的渠道包括项目并购、上市，或是在后续融资中把自己手里的股份卖给新投资方。&nbsp;</p><p>早期融资可以靠风口和讲故事，但走到中后期甚至上市，就必须有一定规模的商业化能力。投资人们发现，拖得越久，项目上市或被并购的难度就越高，因为AI领域主要的商业模式是做B端的定制化项目，这条路径就决定了创业公司很难做出高增长的收入。投资人只能趁风口还在，迅速推动公司完成多轮融资，抬高估值，之后哪怕打折出售手里的股份，也是划算的。&nbsp;</p><p>这也是为什么2023年大模型相关的发布会层出不穷，各种大模型榜单百花齐放且排名各不相同，这些都是有助于融资的“故事”。类似的路径在几年前的AI产业已经出现过一次，那个阶段的代表公司是AI四小龙。2023年的大模型创业只是把过去三年走完的路在一年时间里加速完成。&nbsp;</p><p>但短视绝不是投资人单方面的问题。在今天的商业环境下，大部分人都追求短期的、确定性的结果，十年，甚至五年后的未来都似乎难以把握。</p><h2><strong>商业化：谁是合适的买单人</strong></h2><p>2023年，中国大模型产业迅速从比拼大模型参数进入到比拼商业化的阶段。2024年1月的CES （消费电子展） 上，两位著名的AI科学家李飞飞和吴恩达均表示，接下来AI商业化会有明显发展，会深入到更多行业。&nbsp;</p><p><strong>目前看来，大模型的主要应用方向有两个：</strong> 一是通过大模型技术为C端用户提供新的工具，比如付费版GPT4、百度用文心大模型重构的百度文库、新的AI视频剪辑工具、文生图工具等。但C端付费短期内很难有大规模增长，对于大模型工具有刚需的人群相对较少。&nbsp;</p><p><strong>更有希望的商业化方向是B端服务。</strong> 在中国市场，做B端软件服务一直是一个“老大难”的生意。多位投资人和业内人士都提到，中国市场最大的B端客户是政府和国企，大模型做为先进的生产力工具，会有一个直接影响是减少人力。而在政府和国企，减少人力在很多时候反而会变成阻力。&nbsp;</p><p>如果退而求其次，选择中小B客户，在2024年恐怕也很难。一位AI大模型创业者说，他近期询问了不少企业客户，得到的回应是：“大模型能做什么？能帮我裁员还是能帮我赚钱？”&nbsp;</p><p>到今天，即使是最先进的大模型也依然存在“幻觉”问题，这在C端应用上还可以忍受，但在一些专业的B端场景中，有“幻觉”就意味着难以真正落地。过去比对式AI，例如人脸识别，如果识别错误，人工辅助、调整的成本很低，但大模型擅长“一本正经地胡说八道”，具有一定迷惑性。&nbsp;</p><p>但大模型已经切实在实际应用了。多位业内人士都提到，因为大模型的出现，很多过去无法解决的问题都有了新方法可以解决，且效率有明显提升。例如前文提到的拼接大模型，在过去很少有人尝试，现在不少AI公司都开始把多个不同场景的小模型拼在一起，在解决大部分同类问题时，不需要再单独训练模型，可以直接调取使用。&nbsp;</p><p>此外，在一些有庞大业务的公司里，大模型也已经落地使用。类似于上一轮AI视觉技术带动AI算法的发展，这些AI算法迅速在内容推荐、电商、打车、外卖等领域发挥重要价值。现在，腾讯的游戏业务、阿里的电商业务、字节的内容业务等，都已经用上了大模型。&nbsp;</p><p><strong>2024年，AI大模型的发展会有几个相对确定的趋势：</strong> 一是融资热度下滑，2023年出现的一家公司完成多轮数亿美元融资的情况会明显减少，大模型创业公司需要寻找新的出路。目前看来，大厂们更有实力做大模型基础设施的工作，创业公司可以考虑调整方向，填补基础大模型到应用之间的空白。&nbsp;</p><p>二是大模型的应用会持续深入，但这主要会集中在数字化程度很高且业务体量非常大的领域。在C端，大模型也会进一步普及，不过对于中国公司来说，不能只依赖C端用户付费，C端应用场景中会加入其他变现模式，主要是广告。&nbsp;</p><p>三是国产算力会进一步得到重视，得到重视并不意味着短期内会有明显进步，这是一个漫长的过程。国产算力能力提升的同时，会有更多趁机炒作、造势、圈钱的现象。&nbsp;</p><p>风口会刺激产业迅速扩张，泡沫随之而生，机会越大，泡沫就越大。只有撇开泡沫，才能看清产业发展的新机会。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI0MjU2NTA1Mg==&amp;mid=2247588880&amp;idx=1&amp;sn=305a16c80e76b67041cfbb04bdd63e74&amp;chksm=e8506b7fe598f6d8f067191f1dd667adc3a64975781b4ae11641204b31f2973763807d8ca74c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“财经十一人”（ID：caijingEleven）</a>，作者：刘以秦，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653858365799557</id>
            <title>EDA行业营收，逆风创历史</title>
            <link>https://www.36kr.com/p/2653858365799557</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653858365799557</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:43:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_e7d7106e08e34df18c946c907ecc86a7@46958_oswg344265oswg888oswg513_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>SEMI 电子设计市场数据报告显示，2023 年第 3 季度全球EDA收入增长创纪录。 这是自 1998 年第四季度以来最高的总体增长。EDA是如何从半导体行业的“边缘人物”变成当红炸子鸡的呢？&nbsp;</p><h2><strong>不容小觑的市场潜力</strong></h2><p>EDA软件是半导体产业链中的重要环节之一，在多个领域中都发挥着至关重要的作用，近年来行业发展速度不断加快。目前我国EDA软件行业主要由国内和国外厂商所组成，以Synopsys、Cadence、Siemens EDA等为代表的国外大型厂商排在第一市场梯队，其凭借着技术和资金等方面积累的优势占据市场主导地位；之后为华大九天、国微集团和概伦电子等国内领先厂商位于第二市场梯队，相比其他本土企业，这类厂商在个别细分领域的市场份额占比较高，在整体市场中有着一定的话语权；此外其他本土EDA软件厂商排在第三市场梯队，整体市场竞争力比较弱。&nbsp;</p><p>担任中国台湾大学电机资讯学院院长的张耀文教授以实际应用说明半导体产业的重要性：人工智能、5G 物联网、云端服务、高性能计算、大数据分析、智慧医疗、自驾车和机器人等新科技创造当今人类的新文明，这些新科技的实现，都必须仰赖半导体技术的发展，而且相辅相成地成为技术发展的主要驱动力。&nbsp;</p><p>在了解各国半导体领域版图前，必须先了解半导体是怎么来的。从半导体原料到指尖上一块小小的芯片，涵盖了数百道加工步骤和长长的全球价值链（Global Value Chain），由各国企业分工不同阶段的制程。阳明交通大学副校长、电子研究所的李镇宜教授表示，半导体整体产业的发展与板块移动，属于跨国、跨企业在多年的良性竞争与互补合作下，诞生的共创机制。&nbsp;</p><p>半导体价值链可分为设计与制造两大部分，后者又可分为前端的晶圆制造生产与后端的封装测试。设计端包含开发基本电路模组、电子设计自动化（Electronic Design Automation, EDA）软件，以及提供指令集架构的公司。&nbsp;</p><p>半导体产业的全球价值链，可分为设计与制造两大部分，由各国企业分工协作。&nbsp;</p><p>进行电路设计的公司，大部分都没有自行生产芯片的工厂（无厂半导体企业），因此需要委托晶圆代工厂来制造芯片，全球市占率6 成的的台积电即为国际晶圆代工龙头。前端工程的晶圆代工厂，会将电路设计图转印到晶圆上，而后端的企业则负责裁切晶圆，制成芯片后进行封装测试。&nbsp;</p><p>根据半导体产业协会（SIA）与波士顿顾问集团（BCG）于2021 年4 月合作发表的分析报告，可见美国在最上游的芯片设计与半导体制造设备（如掺杂技术〔Doping〕 与制程控管所需机具），都扮演极具分量的角色，而这些主要技术，也成为美国在地缘政治中的关键施力点。&nbsp;</p><p>美国针对半导体产业链各重点环节对中国展开的芯片制裁，一方面，英伟达与AMD被美国限制向中国出口现成的高阶芯片，以拦截尖端科技发展。高阶芯片在进行大数据分析的高效能运算（high performance computing）系统中必不可缺，势必影响阿里巴巴、腾讯与百度的云端服务的布局，以及未来AI 发展。&nbsp;</p><p>另一方面，中国被禁止取得美国的半导体设备，阻绝高阶芯片的制造。巧妇难为无米之炊，尤其半导体机具设备并非一次性购入即可，还需厂商提供长期维修保养、排除故障问题等服务。美国的禁令旨在使中国半导体大厂的芯片制程大幅落后。不只是现成的芯片与制造设备，美国还对半导体制造设备的必要元件下禁令，意图让中国无法发展本土的半导体制造设备。&nbsp;</p><p>如果中国国内无法制造，难道不能委托其他晶圆代工厂协助？事情没那么简单，别忘了美国也管制国产EDA 软件出口到中国，相当于扼杀中国自行设计高阶芯片的能力。因为拥有约八成市占率的EDA 软件三大巨头——新思科技（Synopsys）、Cadenc与西门子（Siemens），其总部都在美国，而中国国内的EDA 企业均未具备设计先进电路制程的能力。&nbsp;</p><p>工研院产科国际所杨瑞临研究总监分析，美国从产业链的设计与制造端紧抓要害，全方位围堵中国的半导体产业发展。&nbsp;</p><h2><strong>半导体产业中不可或缺的芯片之母——EDA</strong></h2><p>虽然EDA 软件的市场价值在2021 年约100 亿美元，与半导体市场将近6000 亿美元的规模相比不到十分之一，但它可是半导体价值链中至关重要的芯片之母。&nbsp;</p><p>不像1970 年代时，IC 上只有数以千计的晶体管，如今迈入超大型集成电路（Very Large Scale Integration，VLSI）世代，一块IC 上就有上亿个晶体管。（以iPhone 14 所用的A16 仿生芯片为例，其一平方公分的晶圆面积上就布满约160 亿颗晶体管！）IC 上的各个区块肩负不同功能，每个区块都需由一组团队设计，光是一块IC，背后就需要上千人的团队才能开发成功。巨量的元件大大提升后期整合的难度， 设计工程师绝不可能将一个个晶体管手动排列上去，一定得仰赖EDA 的辅助。EDA 让工程师可以利用程式规划芯片功能，再交由EDA 将程式码转换成电路设计图，达成高效率设计。&nbsp;</p><p>EDA 之所以强大，是因为它不只能优化设计，还可以提供模拟和验证的功能。规划IC 架构后，工程师能在投入实体制作前，先行在不同条件参数与运作方式下模拟电路的表现，知道IC 布局是否能起作用。工程师可以针对效能最强、面积最小或发热最低等不同目标来模拟，进行调整除错，找出最佳化的设计。&nbsp;</p><p>除了设计端，制造端与EDA 同样密不可分。EDA 的验证功能可以协助检验芯片的设计是否正确连接，有无遵循晶圆代工厂的生产规格，确保制作良率可以符合量产的效益。建置EDA 软体与设计环境的公司，和负责研发先进制程的晶圆代工厂商，两者之间需紧密沟通往来，才可以让设计跟上最新制程资料，不停向前推进半导体纳米微缩的技术节点。&nbsp;</p><p>EDA 就像是建筑师的蓝图，可以预先在一定的施工条件下，构想好空间配置，确保每个工班做出来的东西可以流畅地衔接在一起。&nbsp;</p><h2><strong>EDA新趋势</strong></h2><p>2024年1月16日，EDA及半导体IP大厂新思科技和工业软件大厂Ansys正式宣布，双方已经就新思科技收购Ansys事宜达成了最终协议。&nbsp;</p><p>根据该收购协议条款，Ansys股东将以每股Ansys股票换取197.00美元现金和0.3450股新思科技普通股，按2023年12月21日新思科技普通股的收盘价（559.96美元/股）计算，该收购总价值约为350亿美元，是2024年开年最大的并购案，同时从成交金额350亿美元（约2500亿人民币）来看，此次收购是近年来科技行业宣布的最大交易之一。从新思科技（Synopsys）并购史来看，自其创立之初到2023年，并购次数次数高达42起，其中仅2023一年就有四起。相对于Ansys于2023年12月21日的收盘价溢价约29%，比Ansys截至同日的60天成交量加权平均价格溢价约35%。根据协议条款，预计Ansys股东将拥有合并后公司约16.5%的预估股权。&nbsp;</p><p>为了完成这笔巨额收购，新思科技计划通过现金和债务融资相结合的方式为190亿美元的现金对价提供资金。新思科技已获得160亿美元的全额承诺债务融资。该交易预计将于2025年上半年完成，但需获得Ansys股东的批准、获得必要的监管部门批准以及其他惯例成交条件。&nbsp;</p><p>值得注意的是，此次新思科技对于Ansys的收购正值新思科技的权利交接之际，现任董事长兼CEO Aart de Geus 于2024年1月1日转任新思科技董事会执行主席，Sassine Ghazi 正式出任公司全球总裁兼首席执行官。行业人士猜测，这笔重大收购可能将是Sassine Ghazi谋求推动新思科技进一步改变和壮大的关键举措。&nbsp;</p><p>公开资料显示，Ansys成立于1970年，总部位于宾夕法尼亚州的Canonsburg，是一家专门从事工程仿真软件开发和销售的公司，同时也是全球最大的CAE(Computer Aided Engineering，工程设计中的计算机辅助工程）软件大厂之一，同时也是全球EDA软件大厂。&nbsp;</p><p>随着RISC-V技术深入各领域，它以开源、简洁和高度可扩展的特性正逐步塑造未来。尽管RISC-V潜力巨大，其生态系统仍存在待完善之处。特别是其独立、灵活和弹性的设计理念让系统碎片化的问题剧增。&nbsp;</p><p>EDA的任务就是倾听客户需求，来满足他们在不同应用对产品设计或生态系统的支持。&nbsp;</p><p>为了应对这些挑战，国内思尔芯为RISC-V提供了涵盖微架构分析、系统整合、规范符合性测试以及软件性能评估的一系列优化解决方案。通过思尔芯的“芯神匠”的系统&amp;应用性能分析、“芯神瞳”的评估架构配置/软件性能分析、“芯神鼎”的规范符合性测试等策略，构建一个更高效和稳定的RISC-V平台。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247698191&amp;idx=1&amp;sn=2db85387decff9c2b4a0dd87a79d8d84&amp;chksm=c09d779c4368e01a078ec3769b7ecfbd192dee49e60c5bd1eeaa2581fa249e2b8e473517710d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：米乐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653865345154184</id>
            <title>AI Phone的起点：大厂会如何摸着陈明永过河</title>
            <link>https://www.36kr.com/p/2653865345154184</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653865345154184</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:43:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>形如隐士一般的段永平系的公司老板们，是真的不知道，外界对他们一言一行见观瞻的真实反应，尤其是那三位千亿富豪。他们不理解外界对他们的真实观感，就像外界不知道他们真正的财富水平，以及赚取财富的方式一样。</p><p>每年例行的《致OPPO伙伴们一封信》当中，OPPO公司创始人陈明永只讲述了一个关键词：AI。他认为，AI手机将会是功能机、智能手机之后，手机行业的第三个阶段。</p><p>“这轮由大模型支撑的AI技术，正在重构手机行业的未来。”在这封非常简短的公开信当中，陈明永没有提到所谓AI手机的定义，与当前的智能手机的区别，以及OPPO的具体计划。</p><p>他只是说，OPPO已经做好充分准备，并专门成立了AI中心，将资源向AI集中。</p><p>一个月前，OPPO高级副总裁刘作虎就曾经在一款新产品的发布会上，预先提到AI 手机时代的观点，他认为，手机大厂再不布局大模型就没戏了。</p><p>但是，他也没有明言，他认为的AI手机究竟是何物，究竟和刚刚上市的OPPO智能手机有什么区别，OPPO的AI手机时代何时到来？</p><h2><strong>陈明永的新机</strong></h2><p>陈明永和刘作虎肯定不会告诉OPPO的消费者，先按下购机需求，等待一两年，等待OPPO的AI手机时代到来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d1bbb5b9ad0d482ebb628c4f1db2feb9@000000_oswg149385oswg640oswg397_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">陈明永确实是喜欢直截了当的表态</p><p>刘作虎的访谈信息当中笼统提到了一个方向：将用户需求和大模型训练、芯片的底层能力进行结合。</p><p>在当下流行的通话摘要、翻译、影像效果提升之外，他拒绝透露更多的OPPO的特色AI应用。</p><p>大模型为底色的这一波AI技术潮流，究竟能为用户体验带来什么样的变化，不同于之前的智能手机时代，成为新的智慧手机特征？</p><p>2016年11月，《智物》的联合创始人在《第一财经周刊》的专栏上写过一篇短文，冒昧引用了前华为人士的一段话，用来形容smartphone和Intelligent Phone的区别，iPhone为代表的智能手机其智能在于记住用户信息和链接，而“智慧手机”或者说人工智能是手机的意义在于，借助记忆用户的信息，更主动为用户服务。</p><p>2个月之后，华为CBG负责人余承东在美国CES展会上接受新华社的采访，他第一次提到了具备AI能力的智能手机，可以称为是Intelligent Phone。这些设备将是没有胳膊和腿的机器人，成为用户数字世界和物理世界之间的连接，是一个更智能的智能助理。</p><p>他在CES的主题演讲当中阐述了这个命题，他认为手机可以胜任计算机视觉，可以做本地的决策，可以做有触觉和味觉等等。他的演讲以及新华社的访谈当中，都没有提到，华为是否做出来了所谓的Intelligent Phone，以及会不会，以及何时做Intelligent Phone的计划。</p><p>他也没有提到，华为将会如何去做。</p><p>新华社当时的报道中提到，这是第二次有中国企业家受邀作主旨发言。在这一篇文章当中，余承东还提到了华为当时已经年销售1.4亿台，他的目标是很快可以年销售到2亿台。</p><p>余承东不需要到Intelligent Phone时代，就实现了这个目标。后来，余承东也很少再提到这个主题，就像他不曾发表过那个重要的演讲一样。对余承东这样的市场英豪来说，实际的销售目标，远比文人之间争夺文字发明权重要的多。</p><p>陈明永和刘作虎一定和余承东有类似的秉性和气质。OPPO的关于AI手机时代的高论，其本意和余承东在8年前的讲述没有区别，只不过是为了当下能够有更好的手机销量。</p><p>陈明永、刘作虎的这番表态，和OPPO关于像素级模仿华为的战略，以及陈明永提到的IoT战略规划一样，都是为了当下OPPO智能手机的销量有更好的表现。希望让外界看到，OPPO是一个有长期战略，技术实力的科技公司。从而有助于用户在市场的购买。</p><p>这与数月前，vivo高级副总裁胡柏山讲述，未来vivo的技术战略是在XR以及人型机器人一样。vivo会做一款真正的混合现实眼镜吗？vivo会去做所谓的人形机器人吗？</p><p>胡柏山意图所向的，也不过是能让外界意识到，vivo有这样的眼光，有这样的能力去做类似苹果、特斯拉的技术布局一样。重点是在帮助vivo手机当下的销量，而不是有多少人记得vivo是否真正有能力，是否最终会去做所谓的眼镜和机器人。</p><p>这一策略是否能最终得售？</p><h2><strong>AI Phone的金手铐</strong></h2><p>陈明永这一次关于，OPPO集中资源投入，成为AI手机时代的引领者的普及者表态，是否经得起检验。会不会像之前Zheku芯片一样，浅尝辄止，所谓像素级模仿华为，最终只是羡慕华为的成功，而经受不起华为的苦难。</p><p>AI手机战略，不会是又一场叶公好龙？</p><p>虽然刘作虎没有明言OPPO关于AI手机的定义，但是，在一个月前的那场访谈当中，刘作虎提到了关于潘塔纳尔系统的细节，其中提到，OPPO所努力的生态当中，未来的手机将会变成一个智慧化的系统，所有的服务会被“原子化”，“不一定通过某一个APP提供一种服务，而是在你需要的时候就给你提供这个服务。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_7ccab446aa1f444f8b00bcac36c21346@000000_oswg284722oswg640oswg536_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">刘作虎们最大的束缚也是当今最大的利润来源</p><p>当7年前，余承东做关于Intelligent Phone的演讲时，华为内部就有过一场这样的试验，巧合的是，当时华为也把这些服务形式叫做原子化服务。</p><p>陈明永和余承东所指的，难道是同样的一种AI手机？在FT中文网，以及《智物》的平台上，我们曾经多次回顾，华为当时的那场试验，并试图讨论过这个所谓的“智慧手机”的可能性，以及可能的路径和影响力。</p><p>《智物》现在倾向于，最大的可能性是一个新的创业团队去引领，去推动“智慧手机”的普及，而不是OPPO、vivo等大厂，这与这些大佬们的战略眼光，公司自身的技术实力关系不大，而是这些大佬们目前所处的阶段和模式。</p><p>刘作虎没有明言所谓美团“原子化服务”的细节。事实上，当前百度、美团、滴滴、微信这些Killer APP们贡献了OPPO所有的利润，手机销售的硬件利润基本上已经被归零。这些形式各异的APP们，背后有着一个共同的商业模式——搜索广告、竞价排名。</p><p>淘宝最大的利润来自于广告，而不是卖货的表现，这就是过去20年互联网商业的核心。</p><p>陈明永、刘作虎靠着这样的商业模式，赚到每年至少200亿元人民币以上的净利润，哪怕不再新增手机销量。如今，大模型、多模态为代表的AI技术，真实潜力现在无法准确估量。但是有一点，已经是人所共知，就是对搜索商业模式的挑战和替代。</p><p>当谷歌、百度的Page Rank，开始变成Chat GPT时代的Content Rank、Service Rank，智能搜索突然变成了智慧服务。</p><p>陈明永、刘作虎所说的AI手机时代，美团APP预装，突然变成了刘作虎提到的“原子化服务”，用户不再需要美团APP，美团不再需要向OPPO缴纳预付安装广告费，商家不再需要向美团支付推广费。</p><p>OPPO们每年200亿元人民币的净利润，何以为继？商家如何向OPPO支付推广费用，获得消费者？华为验证过这个试验，只是基数不多。</p><p>旧的商业链路、循环面临挑战，新的商业闭环尚未确立。陈明永、刘作虎愿意做这样的开拓者和普及者，还未找到新的AI商业模式之前，就去放弃旧的移动互联网的利润？OPPO、vivo一直讲求四个利益方和谐共处，但实际上，在OV体系当中真正有话语权的，只有OV的股东。</p><p>也不只是OV，苹果、小米也是同样尴尬的角色。在真正的AI手机开拓者，像乔布斯那样的产品经理成功做出有市场说服力的AI Phone之前，这些大厂不会真正开始所谓的AI Phone——以智能服务代替竞价排名广告。</p><p>一个最简单的验证是：2024年，AI手机元年，OPPO的新手机开机时，还有没有美团、滴滴、携程这些预装软件。</p><p>《智物》本以为余承东有一个其他大厂不具备的优势，特殊的供应链制裁，让余承东可以从零起步，让新鸿蒙直接进入到AI智慧服务的时代，放弃广告模式，放弃APP Store。余承东继2017年的演讲之后，成为AI手机时代的乔布斯，真正做一款AI Phone。</p><p>似乎没那么简单，从AI Pin和Rabbit R1的产品表现来看，突破Multi touch传统产品形态，难度2007年的乔布斯iPhone时刻要难——芯片没有成熟到支持本地模型的阶段，也可能是产品路径不对，导致原来为智能手机时代设计的芯片架构，根本没法大规模应用在智慧手机时代。</p><p>vivo副总裁周围对这一细节，有非常精辟的表述，AI模型应用在手机侧，挑战在于存储，而不只是算力。真正的AI Phone芯片未来，何谈AI Phone？</p><p>另一方面，也更为重要的是，华为看起来也想“先立后破”。通过过去几个月一路战略合作协议，华为的新鸿蒙与腾讯、京东的绝大多数APP签署了合作，这些APP目前已经全部被“翻译”到鸿蒙生态当中，余承东重新为华为捡回来一个年赚百亿的业态。</p><p>在苹果，或者其他的美国公司做出来所谓的AI Phone之前，多赚一点智能手机时代的利润，也是一个不错的方案。但是挑战在于，如果是一家苹果这样技术、品牌俱佳的对手，率先做出AI Phone，中国大厂需要多久，多大的代价去追赶。最终的结果，会不会也像今天一样，苹果赚走智能手机领域几乎所有的硬件利润，以及越来越多的互联网利润。</p><p>陈明永可以接受那样的场景，他本人以及他的股东们，也都是苹果公司最重要的股东。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI2ODYwNzQ0Nw==&amp;mid=2247487947&amp;idx=1&amp;sn=d3e771df2214140781b2c062c9d22e35&amp;chksm=ebb29b2d2146072d3472366c9fb244462daf42393f1130fefe26a50d6c73db0edb4e66be6294&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智物科技评论”（ID：IntellegentThings）</a>，作者：文/智物，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653920857784578</id>
            <title>下一代智能版 Windows 要来了？微软推出首个 Windows Agent，命名为 UFO</title>
            <link>https://www.36kr.com/p/2653920857784578</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653920857784578</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:42:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着 AI 技术的进步，那边在&nbsp;OpenAI 大杀四方、用 Sora 彻底革了视频的命之际，这边的微软悄然对传统用户界面“出招”，最新带来一款用于构建用户界面（UI）交互智能体的 Agent 框架——UFO，能够快速理解和执行用户的自然语言请求，它的发布也向外界展示了未来与 Windows 交互是多么的容易。</p><p>UFO 可以在 Windows 内自主回答用户查询，也能够在单个或者跨多个 App 中无缝导航和操作来满足 Windows 操作系统上用户请求。它可以更加智能地理解用户的意图，不用人工干预，自动执行相应的操作。</p><p>简单来看，当你想要从一份&nbsp;Word 文档中提取文本、对照片应用程序中的图像进行观察、以及总结 PowerPoint 中的内容，然后利用所有这些信息撰写一封深度的电子邮件内容并完全自主发送时，你只需要借助一个 UFO 框架就可以完成。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_5fd26ac5bc27446c9d053304c330f8cb@46958_oswg151670oswg919oswg511_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>正所谓，以前需要大量手动工作的跨应用程序工作流程，现在可以直接简化为针对 UFO 的简单自然语言指令。基于此，很多人也将 UFO 视为是下一代 Windows 系统的核心。</p><h2><strong>微软推出首个专为 Windows 定制的 Agent——UFO</strong></h2><p>值得注意的是，这里的 UFO 并不是指“不明飞行物”，它的全称为 UI-Focused Agent，是一种以用户界面（UI）为中心的代理，主要基于 OpenAI 的 GPT-4V 图像识别模型开发而成，为 Windows 操作系统上的应用程序量身定制。</p><p>UFO 采用双代理框架，对图形用户界面（GUI）和 Windows 应用程序的控制信息进行细致的观察和分析，这使得代理能够在单个应用程序内和跨应用程序之间无缝导航和操作，以满足用户的请求。</p><p>利用 AI 技术，UFO 可以让用户“说说话”——用自然语言命令就能完成繁琐的 Windows 任务。根据研究团队透露，UFO 是第一个专为 Windows 操作系统环境下完成任务而定制的用户界面代理。在他们看来，这一开创性的 Agent 将改变人们与 Windows 设备的交互方式。</p><p>目前 UFO 面向所有用户开源，代码地址详见：https://github.com/microsoft/UFO。</p><p>与此同时，微软研究团队还针对 UFO 项目发布了一份 30 页的技术报告：https://arxiv.org/pdf/2402.07939.pdf。</p><p>话不多说，让我们先来看看 UFO 到底能用来干些什么？</p><p><strong>一、一条指令即可删除 PowerPoint&nbsp;演示文稿上的所有注释</strong></p><p>我们在日常工作中制作 PPT 时，通常会遇到要准备两个不同版本的情况，一版要添加备注，方便自己捋清楚 PPT 内容逻辑；另一版往往更加简洁明了，方便对外。</p><p>过去，在用户想要一个没有附带任何说明的干净版本的幻灯片时，传统的方法可能是手动一页一页地去删除备注内容。当然如果 PPT 页数少还要好操作一些，一旦遇到页数超多的 PPT 内容，这无疑是一个繁琐又耗时的工作。</p><p>UFO 的到来，可以帮我们有效减少工作量，你只需要对它发出以下请求——“帮助我快速删除测试幻灯片中的所有备注。“</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_2f244fd00f3e46f9948d26e5059eac23@46958_oswg44426oswg680oswg135_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>它就可以自动提供解决方案给你。</p><p>在实际测试过程中，UFO 直接建议使用“删除所有演示文稿笔记”功能，这是一个经常被 PowerPoint 用户忽视的功能，由于这个功能按钮隐藏的位置较深，没有什么办公软件使用经验的人或许根本找不到。</p><p>当 UFO 提供建议之后，它会直接自动导航到“文件”选项，并提供对后台视图的访问。随后，它顺利地过渡到“信息”菜单，单击”检查问题“按钮，并选择“检查文档”，开始检查文档中的注释。</p><p>鉴于可能存在误删的情况，UFO 还提供了一层保护功能，即征得用户同意之后才会删除所有注释内容。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_10af6f73df854d99bb1fd68d92b51f66@46958_oswg434414oswg665oswg820_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>二、总结会议纪要，并发送邮件</strong></p><p>当向 UFO 发出请求：“我叫扎克。请阅读会议记录以确定所有行动项目，并理解 LLM-training·png 中包含 LLM 培训工作流程，最终撰写一封包含这些内容的新邮件。通过电子邮件地址，发送完整的电子邮件给我们的领导 Hidan ，请他来审查”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ed9accaabb264f248d6625962f17ec54@46958_oswg95468oswg1054oswg207_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作为回应，UFO 为这项任务制定了一个动态计划：</p><p>它在 Word 中激活所需的文档文件，利用 GetTextAPI 从主窗口中提取文本；</p><p>紧接着，UFO 切换到照片中的 LLM-training·png&nbsp;图像文件，观察并生成一个详细的描述；</p><p>收集所有必要的信息后，UFO 打开 outlook 应用程序，访问“新建电子邮件”按钮启动”编辑“功能，然后自主输入电子邮件收件人、起草主题和撰写电子邮件正文，包括所有必需的信息。</p><p>在发送之前，由于动作的敏感性，安全保护功能会提示用户确认。一旦确认，电子邮件发送。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d958c627c9d94ce7b41d1886542f0ca9@46958_oswg493818oswg1080oswg593_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_441a183be3024ddd983d43a0e992c462@46958_oswg407474oswg1040oswg795_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>整个过程如视频所示：&nbsp;</p><p><strong>三、联网查找以及下载相关内容</strong></p><p>它还能直接帮助阅读 PPT 内容，帮助用户在网上搜索到并打开论文，以及对论文进行总结和下载。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_112cd8f854d745d0b33f02e5c007abaa@46958_oswg371529oswg1047oswg944_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>四、一键换 PPT 模板</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d68d78c5caa7447f87f0679d3173291c@46958_oswg235245oswg883oswg665_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>五、直接在 VS Code 中下载&nbsp;Docker 扩展</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_651e16c8ffb34fd5a2cc8bb905f2f70d@46958_oswg82361oswg891oswg330_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>UFO 是如何实现调动多 App 自动化工作的？</strong></h2><p>毋庸置疑，UFO 可以接受自然语言指令，具有理解用户用自然语言表达的请求的能力，将其分解成一系列逐步的子任务。然后，通过分析屏幕截图和控件信息自动完成 Windows 下各个 App 的操作和请求，极大地提升了工作效率。</p><p>那么，它究竟是如何做到的？</p><p>对此，在论文中，研究人员解释道，UFO 结合了两个 Agent，它们决定选择哪些应用程序和控件来处理用户请求，其中：</p><p><strong>应用程序选择代理(AppAgent)</strong>的任务是选择一个正确的应用程序来满足用户的请求。当一个请求跨越多个应用程序，并且任务已在前一个应用程序中部分完成时，此代理还可以切换到另一个应用程序。</p><p><strong>动作选择代理(ActAgent)</strong>，其负责在所选应用程序上反复执行动作，直到在特定应用程序内成功地结束任务。</p><p>这两个 Agent 利用 GPT-Vision 的多模态功能来理解应用程序 UI 并满足用户的请求。他们利用一个控制交互模块来确定他们的行动，从而对系统产生切实的影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_780add309d8a488e87e1ea363e199ca5@46958_oswg121247oswg846oswg424_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>详细来看，UFO 为 AppAgent 提供了完整的桌面截图和一系列可供参考的应用程序，方便了 AppAgent 的决策过程。随后，AppAgent 选择一个适当的应用程序，并制定一个全面的计划来完成请求。然后将该计划转交给 ActAgent。</p><p>一旦确定了一个合适的应用程序，它就会在桌面上显示。然后，ActAgent 启动操作来完成用户请求。在每个动作选择步骤之前，UFO 捕获当前应用程序的 UI 窗口的屏幕截图，所有可用的控件都被标注。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_330b4eeb161d4c99bc9b98154e267d68@46958_oswg112143oswg714oswg437_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，UFO 记录每个控件的信息，以供 ActAgent 观察。ActAgent 的任务是选择要操作的控件，然后通过控件交互模块选择要在所选控件上执行的特定操作。这个决定是基于 ActAgent 的观察，它的事先计划，和它的操作记忆。</p><p>在执行之后，UFO 为未来的步骤构建一个本地计划，并进行到下一个行动选择步骤。这个递归过程会一直持续到用户请求在选定的应用程序中成功完成为止。这就结束了用户请求的一个阶段。</p><p>在用户请求跨越多个应用程序的场景中，ActAgent 会将任务委托给 AppAgent，以便在 ActAgent 完成当前应用程序上的任务后切换到另一个应用程序，从而启动请求的第二阶段。</p><p>这个迭代过程将持续到用户请求的所有方面完全完成。用户可以选择交互式地引入新的请求，提示 UFO 通过重复上述过程来处理新的请求。在成功完成所有用户请求后，UFO 结束其操作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_be263a59e7614f90923a8fa8ec8bb407@46958_oswg120323oswg875oswg443_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>UFO 完成了 86% 的任务，明显高于&nbsp;GPT-3.5 和 GPT-4&nbsp;</strong></h2><p>为了评估 UFO 的性能，由于现有的 Windows Agent 存在局限性，该研究团队选择了 GPT-3.5 和 GPT-4 作为基线模型，同时因为这些模型缺乏直接与应用程序交互的能力，所以由研究人员指示它们并提供分步说明来完成用户请求。然后一个人类作为他们的代理人来执行这些操作。</p><p>另外，该研究团队使用 WindowsBench 数据集对各种框架进行了全面的定量比较：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_59b4951ee4004a289e3cb7c32dde6a0d@46958_oswg35475oswg916oswg198_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据上图不难看出，UFO 在基准测试中成功率高达 86%，是 GPT-4 的两倍多。另外，根据研究显示，UFO 完成任务的步骤最少，且从安全的角度来看，UFO 达到最高的保障率为 85.7%，这证明它可以准确地分类敏感请求，确认其可以作为一个安全的代理。</p><p>与此同时，微软研究团队还对框架进行了 50 项任务的测试，涉及 9 个广泛使用的 Windows 应用程序，包括 Outlook、Photos、PowerPoint、Word、AdobeAcrobat、文件资源管理器、Visual Studio Code、微信和 Edge 浏览器。</p><p>最终测试结果如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_5ea8d18b404e454cbc6d179423924cb1@46958_oswg30925oswg902oswg357_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>局限性</strong></h2><p>不过，研究人员也在论文中承认目前的 UFO 还有很大的局限性。</p><p>比如，UFO 只能执行 Python 软件包 pywinauto 和 Windows UI 自动化所支持的控件和操作。他们还注意到当 UFO 遇到不常见的应用程序 GUI 时，会出 Bug。</p><p>当然，微软计划通过支持其他后端和集成专用图形用户界面模型进行视觉识别来改进 UFO。此外，连接到在线搜索引擎作为外部知识库也可以提高 Agent 适应未知 GUI 的能力。&nbsp;</p><p>整体来看，这款 Windows Agent 还不是很灵活，它们也需要支付额外费用。尽管你可以通过 GitHub（https://github.com/microsoft/UFO）在计算机上免费安装 UFO，但它需要 OpenAI 的 API 密钥才能使用 GPT-4V 进行推理，每次请求都会产生费用。它也只能通过命令行访问。</p><p>对此，外媒 The Decoder 也评价道，“要让 UFO 这样的概念发挥作用，就需要将其更紧密地集成到操作系统中。理想的情况是，它们在本地运行，以较低的成本提供较快的性能。这也有可能消除对隐私的担忧。</p><p>尽管如此，UFO 仍是从根本上改变计算机操作方式的重要一步。与强大的语音识别模式（如 Whisper）相结合，它可以消除对传统界面的需求，尽管这似乎还很遥远。”</p><h2><strong>UFO 背后的团队</strong></h2><p>最后同样值得关注的是，这款由微软官方团队推出的 Agent，不少华人工程师参与其中：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_4ccc37a71b5a4d439f231243f635d23b@46958_oswg45202oswg947oswg209_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Chaoyun Zhang，是微软亚洲研究院 DKI（Data、Knowledge、Intelligence）小组的高级研究员，研究兴趣包括时间序列建模、时空数据挖掘、因果推理以及云服务和 AIOps 的可解释机器学习。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a0c8eccb3acf4b9881e19e6601e309d4@46958_oswg69099oswg771oswg358_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Liqun Li，2012 年于中国科学院软件研究所获博士学位，2006 年于清华大学计算机科学与技术系获学士学位，现任微软亚洲研究院 DKI 组首席研究员，目前专注于构建基于 LLM 的自主代理，用于数据分析和工作流程自动化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_de8e03d410a4436c8af4a537488c6d22@46958_oswg12631oswg249oswg215_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Shilin He，是微软亚洲研究院 DKI 小组的高级研究员。于 2020&nbsp;年在香港中文大学获得博士学位。在此之前，于 2016 年获得华南理工大学菁英计划学士学位。目前从事云智能/AIOps 方面的研究，旨在将 ML/DL 技术整合到云系统的管理和维护中。</p><p>Xu Zhang，微软高级研究员。</p><p>Bo Qiao，微软亚洲研究院&nbsp;DKI 小组的研究 SDE。</p><p>Si Qin，现任微软亚洲研究院 DKI 的首席研究员和研究经理。</p><p>Minghua Ma，微软亚洲研究院 DKI 小组研究员。他的研究兴趣包括云智能/AIOps。在加入微软研究院之前，他在清华大学计算机科学与技术系获得博士学位。</p><p>Yu Kang，是微软亚洲研究院&nbsp;DKI（数据、知识、智能）小组的首席研究员和研究经理。他还是复旦大学计算机学院兼职教授。此外，他还是香港中文大学的名誉研究员。专注于智能云服务的数据驱动技术。</p><p>Qingwei Lin，DKI 研究领域的合伙人研究经理。在云智能/AIOps领域，他在 AAAI、IJCAI、SigKDD、WWW、ICSE、FSE、ASE、OSDI、NSDI、USENIX ATC 等顶级会议上发表约 100 篇论文，并获得 2017 年最佳研究论文奖 ESEC/FSE 的 ISSRE 和 SIGSOFT 杰出论文奖。</p><p>Saravan Rajmohan，M365 AI 和应用研究合作伙伴总监。领导应用研究团队与各个 Microsoft 研究小组进行深度协作和合作，推动系统创新以及隐私保护机器学习创新。</p><p>Dongmei Zhang，是微软亚洲研究院杰出科学家、副院长，领导数据、知识和智能领域的研究，研究方向包括数据智能、知识计算、信息可视化和软件工程。</p><p>Qi Zhang ，微软全球资深副总裁、微软亚太研发集团首席技术官，微软（亚洲）互联网工程院 常务副院长。于 2002 年加入微软，拥有超过 20 年机器学习、大数据、人工智能算法、平台、商业化的从业经历，在产品研发、战略决策、组织构建、人才培养方面积累了丰富的经验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_0696bb8e517a4a12ab0b2bb3e2e5a847@46958_oswg169097oswg1080oswg401_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>参考：&nbsp;</p><p>https://arxiv.org/pdf/2402.07939.pdf</p><p>https://github.com/microsoft/UFO</p><p>https://the-decoder.com/microsofts-ufo-abducts-traditional-user-interfaces-for-a-smarter-windows-experience/</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/bW75KUG6TSP4RJYP68Bpcg" rel="noopener noreferrer nofollow" target="_blank">“CSDN”（ID:CSDNnews）</a>，整理：屠敏&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653880027053189</id>
            <title>“今天，所有VC的会上都在谈Sora”</title>
            <link>https://www.36kr.com/p/2653880027053189</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653880027053189</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:42:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_2768f4af8d434f60aacd68d6786417cd@000000_oswg48614oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>仿佛梦回2023。去年年初，ChatGPT引发了普通人澎湃的讨论热情，此后海内外在AI大模型投资上展开了军备竞赛。</p><p>龙年刚一开年，OpenAI又打开了新局面。这次火的是文生视频。2月16日凌晨，OpenAI发布了文生视频大模型Sora。Sora能够根据文本提示创建详细的视频、扩展现有视频中的叙述以及从静态图像生成场景。</p><p>这类应用早就有了，但Sora的呈现仍然惊艳，视频中的主体稳定可控，可实现多角度切换，时长方面也突破，最长能生成60秒视频。</p><p>不愧是OpenAI。尽管Sora仍处于开发早期阶段，但它的推出已经标志着生成式AI迎来一个里程碑。</p><p>资本端同时传来新消息。在完成最新交易后，OpenAI的估值已飙升至800亿美元以上。这笔交易来自于Thrive Capital精心策划的要约收购。</p><p>尽管OpenAI和Thrive Capital对此皆不予置评，但小红书博主“Shannon”昨天发的帖子很有情绪的代表性，“明天所有fund开会的议题都有OpenAI的Sora”。</p><p>只不过，和去年相比，投资人的心态变了。不是人人都有机会投中OpenAI，但OpenAI的能力边界却实实在在影响着一批创业公司和背后的投资人。</p><h2><strong>“水到渠成”和“令人发指”</strong></h2><p>首先需要明确，“文生视频大模型”并不是一条全新的赛道。在OpenAI登场之前，头部大模型研发商几乎都拥有自己的文生视频大模型，例如Google的Lumiere以及Stability AI的SVD（Stable Video Diffusion），甚至已经诞生了垂直于多媒体内容创作大模型的独角兽，例如视频生成大模型Gen-2的开发商Runway，在2023年6月底完成由Google、Nvidia、Salesforce参与的C轮融资后，估值超过15亿美元。</p><p>更重要的是，上述已有的“视频大模型”，隐隐有了生产力工具的影子。</p><p>以Runway为例，与许多“拿着锤子找钉子”式的“技术驱动型”大模型创业团队不同，Runway的三名创始人Valenzuela、Alejandro Matamala和Anastasis Germanidis来自于纽约大学艺术学院，他们共同看到了“人工智能在创造性方面的潜力”，于是决定共商大计，开发一套服务于电影制作人、摄影师的工具。</p><p>这层基因打底，相比科技公司的“车库文化”，Runway的发展轨迹更像“横店影视城奋斗史”：先开发了一系列细分到不能再细分的专业创作者辅助工具，针对性地满足视频帧插值、背景去除、模糊效果、运动追踪、音频整理等需求；随后参与到图像生成大模型Stable Diffusion的开发过程中，积累AIGC在静态图像生成方面的技能点，并获得了参与《瞬息全宇宙》等大片制作的机会——这些影片在宣发中曾经有过详细描述，出品人们感叹他们的加入让后期团队“保持了一个超乎常规的小规模”状态，影视同行们惊叹很多许多复杂的特效制作（比如《瞬息全宇宙》里那两块对话的石头），工期已经从“好几天”缩短到了“几分钟”。</p><p>等到2023年2月，Runway发布第一代产品Gen-1，普通用户已经能通过iOS设备进行免费体验，范围除了“真实图像转黏土”“真实图像转素描”这些滤镜式的功能，还包含了“文本转视频”，从而使得Gen-1成为了首批投入商用的文生视频大模型；2023年6月，他们发布了第二代产品Gen-2，训练量上升到了2.4亿张图像和640万段视频剪辑。</p><p>2023年8月，爆火B站、全网播放量超过千万、获得郭帆点赞的AIGC作品《流浪地球3预告片》正是基于Gen-2制作。根据作者@数字生命卡兹克 在个人社媒上的分享，整段视频的制作大体分为两部分——由MidJourney生成分镜图，由Gen-2扩散为4秒的视频片段——最终获得素材图693张、备用剪辑片段185条，耗时5天。半年之后，@数字生命卡兹克 再次通过“MJ V6画分镜-Runway跑视频”制作了一段3分钟的故事短片《The Last Goodbye》，投稿参赛Runway Studios（Runway专门为企业级客户提供定制化服务的部门）所组织的第二届AI电影节Gen48。</p><p>换句话说，<strong>实际上至少在一年以前，“文生视频大模型”就已经拥有足够的关注度，其目前用户规模也被远远低估。</strong></p><p>Runway的联合创始人Valenzuela在C轮融资后透露，除了像New Balance这样的世界500强客户，他们还拥有“数百万个人创作者”。</p><p>除此而外，Sora所展现出来的“精准的物理世界还原能力”，也并不是OpenAI独自探索的AI领域。马斯克就在Sora发布的两天半后，也就是2月18日，在科技播客栏目“DrKnowItAll”里留言，“这种精准还原现实世界物理规律的虚拟世界生成能力，特斯拉已经差不多快掌握一年了……只不过因为素材来自车载摄像头，所以视频看上去没那么有趣”。</p><p>OpenAI在同期发布的技术论文《Video generation models as world simulators》也明确Sora更像是“数据驱动的物理引擎”，通过大模型的持续扩散来“高性能地模拟物理世界或者数字世界中的人、动物、其他物体”，因此仍然拥有“同行们都会面临”的局限性，例如“很难准确模拟复杂场景的物理原理，并且无法理解因果关系，比如Sora生产一段人咬饼干的片段，饼干可能不会出现咬痕”。</p><p><strong>真正带来压迫感的，或许是Sora不可思议的进化速度。</strong></p><p>从技术层面看，无论是“拥有精准物理规则的真实世界”“支持60秒视频生成”还是“单视频多机位”都可以被形容为水到渠成，然而正如上面所提到的——如今看起来傻傻的、只支持生成“4秒视频生成”并且“掉帧明显到像幻灯片”的Gen-2其实是2023年6月发布的产品，距离Sora的发布日不过8个月。</p><p>2023年11月，Meta发布的视频生成大模型Emu Video看起来在Gen-2上更进一步，能够支持512×512、每秒16帧的“精细化创作”，但3个月之后的Sora已经能够做到生成任意分辨率和长宽比的视频，并且根据上面提到的开发者技术论文，Sora还能够执行一系列图像和视频编辑任务，从创建循环视频到即时向前或向后延伸视频，再到更改现有视频背景等。</p><p><strong>而如果要死磕这种不可思议的进化速度，除了“神秘的外星文明”，最现实的解释恐怕只有“海量烧钱”。</strong></p><p>作为Runway半个领路人的Stability AI近两年周期性地遭遇“现金流压力”，一会儿传闻高层正在积极探索出售公司，一会儿又流传着早期投资者Coatue Management的内部信，直指“Stability AI的财务状况令人担忧”，建议CEO Emad Mostaque原地辞职。最揪心的传闻是，为了让亚马逊相信自己不会拖欠高达7500万的云服务费用，身为前对冲基金经理的Emad Mostaque选择以个人财产作为担保。</p><p>然而从融资的角度看，Stability AI做到了赛道的天花板，其在2022年10月完成超过1亿美元的融资后，估值早早来到了独角兽级别。Emad Mostaque在去年7月的一次采访中忍不住直发狂暴言论，他说：“Bard AI只是因为在宣传片中提供了不准确的信息，就造成了每天超过1000亿美元的损失……<strong>人工智能作为基础设施所需的投资总额可能为1万亿美元，这会是人类有史以来最大的泡沫”。</strong></p><p>知乎上，一位叫做“像素炼金师”的创业者坦承了他在目睹Sora发布后的心路历程：<strong>“我有些害怕科技巨头的产品像隆隆火车一样驶过，而我做的东西如同路边的野草一样，在这个技术进步就像跑马灯一样的时代里，留不下一丝痕迹。”</strong></p><h2><strong>估值800亿和领头羊的边界</strong></h2><p>无论怎样，OpenAI再次印证了AI“巨无霸”的地位。看似无远弗届的能力，支撑其估值在不到10个月的时间里增长了两倍。CB Insights的数据显示，OpenAI目前是世界上最有价值的科技初创企业之一，仅次于字节跳动和SpaceX。</p><p>拓展模型能力的同时，OpenAI还在推进多元化的战略。尤其是在半导体领域，奥特曼正与潜在投资者、半导体制造商和能源供应商等各种利益相关者接触。他甚至在考虑成立一家独立于OpenAI的新公司，进入AI芯片行业。</p><p>这笔交易也揭示了，奥特曼之于OpenAI，仍然是不可或缺的角色。原本在去年11月，OpenAI便将敲定最新的融资交易，但当时奥特曼遭遇了解雇风波。交易有没有受到影响不知道，总之结果是，770名员工中的700多人最终签署了请愿书，要求他复职。</p><p>细看这轮融资，不是发行新股，而是准许OpenAI员工对外出售所持股份。这对于OpenAI来说并不新鲜。2023年，Thrive Capital、红杉资本、Andreessen Horowitz和K2 Global等风险投资巨头也采取了类似的做法，参与OpenAI的要约收购，当时该公司的估值已经达到290亿美元。</p><h2><strong>那么，OpenAI的边界在哪里？</strong></h2><p>这个问题不仅事关OpenAI的估值，也关乎大大小小生成式AI创业公司的前景。</p><p>原本在视频生成这个赛道上，海外已经有几家创业公司卡位。最知名的莫过于前文所述的Runway。另一个领头羊是Pika，创立于去年4月，11月宣布完成了总计5500万美金的A轮及天使轮融资，估值达2.5亿美元。Pika由郭文景和孟晨琳共同创立，两人都曾是斯坦福大学人工智能实验室的博士生，履历亮眼。郭文景还被誉为“华裔天才少女”。</p><p>OpenAI会冲击这些公司吗？别急，Sora 公开后，有海外博主已经对几家公司的产品做了对比。他给Sora、Pika、Runway和Stable Video四个模型输入了相同的prompt。结论是，Sora 在生成时长、连贯性等方面都有显著的优势。</p><p>必须要说，这几家做文生视频的公司都开发了自己的大模型，而非纯粹的基于别人的大模型来开发应用场景的那类公司。但即使有技术护城河，要抵挡OpenAI的冲击也没那么容易。</p><p>当然，这并不是说，纯做应用的公司完全没有前途了，背后也许涉及到一个发展阶段的问题。</p><p>去年，红杉资本的两位合伙人再次发表文章，复盘一年前自己对市场的看法。他们指出，其中一个预测错误是，垂直分离尚未发生。“我们仍然相信应用层公司和基础模型提供商之间会有分离，模型公司专注于规模和研究，应用层公司专注于产品和UI。但在实际上，这种分离还没有干净利落地发生。最初面向用户的应用中，最成功的那些都是垂直整合的公司。”</p><p><strong>国内也是类似的局面。</strong></p><p>有投资人告诉我，他们关注的一家AIGC公司也在开发基于特定产业数据的独有的模型，而不是仅仅调用别人的API。“不然很难指望他们在应用层面做出真正差异化的东西。”</p><p>回头看，过去一年，OpenAI的每一次技术突破，都会拓展资本对它的想象空间，但同时也堵上一部分创业公司的前进之路。</p><p><strong>“AGI去年已经把软件行业毒死了。现在公众只是在目睹毒发的过程。”</strong>有创业者在转发一则Sora的消息时，在朋友圈评论道。</p><p>所以，AI投资难，尤其是应用层。“重点还是界定清楚，什么东西能在大模型的演进过程中受益，什么东西又在大模型演进过程中被瓦解。”一位AI投资人曾模糊地告诉我。但OpenAI的超能力使得这个关键问题没那么容易预判。</p><p>再看大模型。《北京最火独角兽翻6倍了》一文写过，智谱AI去年一年的估值翻了已经翻了6倍多，已经有投资人给出200亿估值。我最近也听说，百川智能和MiniMAX，最近都传出新一轮融资已到位的消息。OpenAI出新招，这些公司不可能不焦虑。好在弹药尚且充足。Sora的诞生，无疑又将引发新一轮追赶。</p><p>借着Sora火热，AI的相关概念必将再炒一波，尤其是英伟达这类充当卖水人，又可以大赚一笔了。但对于一级市场的创业者和投资人而言，我只能说，暂时，继续卷罢。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkwMjUxNTkwNQ==&amp;mid=2247593731&amp;idx=1&amp;sn=064ab8f48efe884713ba778b93480254&amp;chksm=c1a3a34c9630d0e68a2b9a4566697fe42612ca93ff344530b6c2dfd0e02fe529eff5f9f34464&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投中网”（ID：China-Venture）</a>，作者：刘燕秋 蒲凡，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653920888650886</id>
            <title>走起，大航天时代</title>
            <link>https://www.36kr.com/p/2653920888650886</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653920888650886</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:41:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3f6f13848136472d8f7b74c488ce43e7@46958_oswg271100oswg847oswg1095_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>想象如下场景：在戈壁遭遇险情，只要轻触按键，车辆坐标和信息就可发送，剩下的则是静待救援；即便没有手机信号，还能远程通话；远洋货轮的水手和游轮上的旅客，不用在出发前抓紧拷贝影像资源，路上可以即时追剧；山区的居民、护林员、科考队员也能够实时联网。&nbsp;</p><p>上述这一切正在由商业航天技术加速实现。&nbsp;</p><p>2023年，当手机和汽车都能与穹顶的卫星相连，越来越多的公众产生了相似的感慨，“原来航天离我这么近”。&nbsp;</p><p>在这一年里，中国商业航天再一次刷新了自己的发射纪录，轨道级航天发射总量达67发，占全球发射总量的三成，仅次于美国的116发 （占全球总量52%） ，位居全球第二。&nbsp;</p><p>商业航天以市场需求为导向，欢迎新技术和新理念，决策、研发、生产流程以效率为先，目标就是降低航天工业的制造成本，促进航天技术普及。&nbsp;</p><p><strong>整个产业链分别是：上游的卫星制造，中游的卫星发射、地面设备制造，下游的卫星应用与运营；</strong> 用卫星在空中组网来提供信号，“让天下没有连不上的网络”，这就叫卫星互联网，是目前商业航天最清晰可见的盈利场景。&nbsp;</p><p>2023年，SpaceX首席执行官马斯克公开表示，借助卫星网络为全球用户提供高速互联网的星链 （starlink） 业务，已实现了现金流平衡。星链赚钱了，加上在俄乌冲突中体现出来的强大的应急能力，国内的企业正在加速摸着SpaceX过河。&nbsp;</p><p>速度必须加快。太空轨道是稀缺资源，好的点位有限，奉行先占先得。建立中国的卫星网络需要大量的投入，迫在眉睫。&nbsp;</p><p>高效率、规模化、低成本，这恰恰是商业航天的特质和优势，可堪大用。&nbsp;</p><p>中国工程院院士、现任国家卫星定位系统工程技术研究中心主任刘经南向《财经》记者透露，中国要推进商业航天发展，只有充分利用民间的资源，如资金、技术、场所等，群策群力，才有希望推出具有市场竞争力的创新产品，从而进一步推动中国航天事业的发展。&nbsp;</p><p>在产业的顶层制度设计上，国家相关部门已经有所考虑和布局。2023年12月，中央经济工作会议将“以科技创新引领现代化产业体系建设”放在2024年经济工作的首位；“商业航天”首次被中央经济工作会议“点名”。&nbsp;</p><p>党的二十大报告强调，要坚持把发展经济的着力点放在实体经济上，推进新型工业化，加快建设制造强国、质量强国、航天强国、交通强国、网络强国、数字中国。&nbsp;</p><p>为了织密中国的卫星互联网，未来几年的火箭订单需要排队预约，旺盛的市场需求让业内信心满满；经过几年的技术积累，业内已经涌现出了一批占据头部地位的企业。更重要的是，航天技术离消费者越来越近，让整个商业故事逐渐走向闭环。&nbsp;</p><p>“人类的征途是星辰大海”——600年前，大航海时代，高桅重帆远涉大洋；今天，大航天时代，火箭飞船遨游寰宇。两者颇有相似之处，科学在借助商业化力量开拓新边疆，新技术不断涌现，并走入民用领域；同时，航天创造出前人无法企及的财富机遇，商机无限。&nbsp;</p><p>这是一场真正走向星辰大海的史诗征途，正如中科创星创始合伙人米磊所说，错过“大航海时代”的中国人，决不能再错过即将到来的“大航天时代”了。</p><h2><strong>商业航天，无限商机</strong></h2><p>一条航天产业链由许多环节构成，从上游研制、发射，到下游运营、应用，几乎每一个环节都能创造千亿级别的市场。&nbsp;</p><p>根据美国卫星产业协会 （SIA） 的统计数据， <strong>2022年全球航天产业的总收入是3840亿美元。</strong> 其中卫星产业总收入为2810亿美元，占全球航天产业收入的73%，主要包括卫星制造业收入、发射服务业收入 （约70亿美元） 、卫星服务业收入和地面设备制造业收入等。&nbsp;</p><p>商业航天已经成为世界大国战略竞争和博弈的主要领域和主战场。泰伯智库认为，2023年至2028年，商业航天产业开始迎来发展黄金期。到2025年仅中国市场规模就将达到2.8万亿元。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_104f775ac6554877b3f522a8cecaed19@46958_oswg80831oswg558oswg656_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>位于产业链上游的制造环节可分为卫星总体制造和卫星配套制造，发射环节可分为火箭总体制造、火箭配套制造、卫星发射服务等，而产业链下游则可细分为通信、导航、遥感应用等领域。&nbsp;</p><p>卫星制造包括卫星平台和卫星载荷，卫星发射包括火箭制造和发射服务，管控包括平台和业务管控等方面。卫星运营及服务涵盖了卫星移动通信服务、宽带广播服务和卫星固定服务等多个领域。地面设备包括地面运维系统、应用网络以及终端设备。卫星的下游应用广泛，涵盖了政府、行业和个人等多个领域。&nbsp;</p><p>自人类开始向太空进军以来，在长达半个多世纪的时间里，航天事业长期是国家力量独步的舞台。谈及航天，传统观念里总有些关键词，比如高精尖、大国重器、国防安全、神秘。这种观念曾一度成为商业航天发展的最大桎梏。&nbsp;</p><p>长久以来，中国航天事业以重大科研为主的模式，稍有真正意义上的工业化产品，形成了以保障航天重大工程为核心的航天工业体系。 <strong>商业航天模式与传统航天模式相比，更加包容新技术和新理念，决策、研发和生产的流程也更加高效。</strong></p><p>“工业化造星是民营卫星制造商的愿景。”时空道宇前瞻实验室负责人侯冰告诉《财经》记者，2021年9月，位于台州的卫星超级工厂制造基地建成，并完成首颗试产星下线，目前通过创新量产AIT （卫星的总装、集成和测试） 模式，工厂研制周期大幅缩短，已经实现日产一颗卫星，而且生产成本下降45%左右，“商业航天研制能力大幅迭代，我们正像造车一样造卫星”。&nbsp;</p><p>商业航天以市场需求为导向，采用更灵活、更高效的资源配置模式，肩负着更多的使命。探索航天产业融合社会化工业体系共同发展，旨在降低航天工业的制造成本，促进航天技术的普及。&nbsp;</p><p>不只是火箭和卫星，载人航天的商业化包括近地轨道载人和货物运输服务，以及太空旅游；深空探测和空间站的商业化开发处于摸索阶段，目前围绕深空探测的商业活动有太空采矿及行星探测器的制造，也逐渐有民营企业参与到国际空间站的商业化开发中，未来或将实现太空居住、太空城市等。&nbsp;</p><p>目前，星际荣耀正在研发价格低廉、性能优异的商业可重复使用运载火箭，公司火箭总指挥谢红军向《财经》记者透露，公司的目标是在2025年将发射价格降低到现有运载工具的一半以内。随着可重复使用火箭的商业化，他坚信普通人进入太空将像如今乘坐航班一样简单。&nbsp;</p><p>商业航天的发展还将带来更多的工作岗位，促进航天技术在更多领域的融合和扩散。&nbsp;</p><p><strong>美国蔡斯经济计量学会的研究显示，NASA在航天科技每投入1美元，就对美国民生产总值产生14美元或更多的经济效益，这是其他产业难以达到的高度。</strong></p><p>据《人民日报》报道，中国载人航天工程发展30年以来，已经有4000余项技术成果被广泛应用于国民经济的各个行业。&nbsp;</p><p>从先进材料到信息通信、光电传感、智能制造、数据处理，如今提升人类社会智能化信息化水平的大批先进技术创新可以追溯到航天科技：清晨醒来，不愿从柔软被窝起身时，所躺着的记忆海绵，最早就是为了在发射和着陆时保护航天员；出门前，询问天气是否要带伞，实时更新的天气预报正源于气象卫星；轻便超薄的笔记本电脑也最早是为了节省太空空间和飞行燃料；泡面里的蔬菜包也同样源于载人航天计划，是为了给航天员补充维生素，还有净水器、纸尿裤，不胜枚举。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_81f31e93ca044f8f923f15584126f132@46958_oswg91540oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2024年1月19日，蓝箭航天自主研发的可重复使用垂直起降回收验证火箭在中国酒泉卫星发射中心点火升空，验证朱雀三号大型液氧甲烷可重复使用火箭的一子级垂直返回关键技术。图/中新&nbsp;</p><h2><strong>群雄逐鹿卫星互联网</strong></h2><p>太平洋上风高浪急，船员遇险采用仅有的一格信号的手机呼救成功。20年前，这则通讯运营商的广告曾深入人心，让人们意识到永不失联的重要。&nbsp;</p><p>当5G逐渐普及，在网约车上给自己家里叫上一份外卖，回家路上看着在线视频，已经成为一些人心中的常态。但联合国数据显示，全球近30亿人从未使用网络；全球七成地区，难以覆盖移动网络和光纤宽带。&nbsp;</p><p>人们将卫星作为移动基站发射到太空，利用卫星通信技术连接互联网，这就是所谓的卫星互联网。卫星互联网不仅具有军事、航空等传统功能，还是推动产业互联网发展6G网络、实现全球网络海陆空360°覆盖的先锋之一。&nbsp;</p><p>中国电信副总经理夏冰在2023中国无线电大会上表示，6G下一步将结合卫星通信和卫星互联网，构建天地一体化的融合网络。&nbsp;</p><p>接入互联网的卫星中，既有高轨道卫星，也有低轨道卫星，夜晚眺望星空，有时隐约会看到天空中，挂着一条反光的项链，那就是低轨卫星连成的星链。低地球轨道卫星凭借绕行周期短、近地面等特点，能够实现数据的快速获取和传输。&nbsp;</p><p>在2023年，这一技术进入中国大众的视野。2023年7月，中国成功将卫星互联网技术试验卫星发射升空，卫星顺利进入预定轨道。同年8月，华为发布新款手机，可支持卫星通话。同年10月，SpaceX星链官方网站全新推出星链直连手机业务。&nbsp;</p><p>不仅仅是手机，2023年9月，时空道宇与极氪联合发布了首款量产卫星互联网乘用车，该车型将在极氪001FR上实现车载卫星通信功能，提供双向卫星消息和卫星通话服务。接下来，时空道宇自主研发了车规级高精度融合定位终端。&nbsp;</p><p>辰韬资本投资总监杨季超向《财经》记者透露，华为和苹果等行业头部企业通过宣传，提前为商业航天应用布局教育用户，让用户对卫星应用产生感知和好奇，从而促进商业航天卫星应用在消费级产品中的规模化应用落地。&nbsp;</p><p>遥感和导航是商业航天此前最常见的用途，在北京微纳星空科技有限公司董事长兼总经理高恩宇告诉《财经》记者，即时遥感星座将突破传统观测限制，通过建立星座，实现分钟级快速重访全球任意目标，实现即时、高效的遥感监测。不过卫星互联网是最容易被公众理解、并愿意付费的技术场景。&nbsp;</p><p>特斯拉创始人马斯克领导的太空探索技术公司 （SpaceX） 的星链计划，是全球最大的卫星运营商。截至2023年5月，该公司已有逾150万用户。同年11月，马斯克公开表示，星链业务已经实现了现金流平衡。&nbsp;</p><p><strong>“在没有网络覆盖的地方，卫星会成为刚需。”</strong> 北京千域空天咨询有限公司创始人蓝天翼对《财经》记者表示，卫星在东部地区高速路、城市是提升服务体验，而在更广袤的地方，将成为提供相应服务的必需品。&nbsp;</p><p>基于卫星互联网，可以广泛应用于老百姓日常使用的手机、对讲机、腕表、充电宝、汽车、应急包，甚至穿戴设备等日用品结合，通过增加卫星通信功能，为消费者提供通信服务，弥补数字鸿沟。&nbsp;</p><p>低轨卫星的低时延和高精度，还将直接助力高级别自动驾驶的落地。此前，业内将自动驾驶的实现逻辑倚重于车辆自身的雷达、摄像头的精度提升，以及道路与车之间的即时通信上，但其均面临投入成本高、全面普及难、特定场景下低效等问题。&nbsp;</p><p>当然，高级别自动驾驶下的高精度的定位服务，不但需要卫星，一般还需要地面基准站修正误差。&nbsp;</p><p>不只是民用领域，原米切尔航空航天研究所部门主任、美国空军退役少将劳伦斯·斯图兹里姆直言道，当前美军卫星通讯面临带宽不足以承载高清图像，以及延迟过高、互操作性不强等三大弊端。他认为大量发射低轨道小型卫星，不但能改变如上困局，还能借助发射效率高、成本低的优势，以应对来自太空的攻击。目前，SpaceX接受了美国国防部价值7000万美元的合同，定制了一款“星盾”的服务产品，提供专属的加密网络通讯服务。&nbsp;</p><p><strong>太空轨道是一种稀缺资源，自然成为各国发射卫星的必争之地。</strong></p><p>根据国际电信联盟 （ITU） 的规定，卫星的频率及轨道使用权采用“先登先占”的竞争方式来获取。卫星制造和发射越快，在卫星互联网这一块就越有话语权，获得的利益也就越可观。&nbsp;</p><p>如果卫星公司想让自己的网络覆盖全球，往往需要对每颗卫星的位置都进行精巧地设计，平衡成本和性能。最经济的方案，需要24颗就能覆盖全球。但如果是后来者，没占上最理想的位置，可能就需要部署更多卫星，用更复杂的排布方式，这当然会增加成本。&nbsp;</p><p>人类从实现第一颗卫星在轨到1000颗卫星在轨，经历了逾半个世纪的时间；自2010年开始，全球在轨卫星数量呈现出阶梯加速式的增长态势，从1000颗增至5000颗，只用了约十年的时间；最近三年，全球在轨卫星数量已从5000颗增长至8000颗。&nbsp;</p><p>SpaceX计划到2027年前将4.2万颗卫星送入轨道，星链已经布局了5144颗互联网卫星，在全球低轨卫星总量中占比超过了55%，组成了目前人类有史以来规模最大的卫星星座。&nbsp;</p><p>商业航天不仅是一种商业行为，而是通过商业化运作来推动国家战略的实施。建立中国的卫星网络，需要大量的投入，包括制造卫星、发射卫星以及终端应用等各大环节。在接受《财经》记者采访时，业内人士普遍认为，从2024年开始，大量的卫星将会被送入太空，此事迫在眉睫。</p><h2><strong>破冰十年，政策春风不断</strong></h2><p>破冰之旅始于十年前。此前，商业航天缺乏明显的政策鼓励，审批程序复杂冗长、存在行业准入资质和配套资源受限等诸多掣肘。&nbsp;</p><p>2014年，国务院出台《关于创新重点领域投融资机制鼓励社会投资的指导意见》，打破了商业航天政策门槛。上述文件首次提出鼓励民间资本参与国家民用空间基础设施建设。由此，国内商业航天事业正式起步，商业航天全产业链逐渐发展。&nbsp;</p><p>自此，一众商业航天公司如雨后春笋般成立，并在短短几年间成功实现了多次商业航天发射。 <strong>从2019年开始进入快速发展阶段，基本形成了国营为主、民营补充的完整产业链。</strong></p><p>“党中央明确把商业航天列为战略性新兴产业之一，我们迎来了中国商业航天发展极好的机遇。”在国际宇航科学院院士、中国遥感委员会主席顾行发看来，商业航天目前在中国的发展势头非常迅猛。&nbsp;</p><p>2020年4月，国家发改委公布的新基建类别中，卫星互联网首次纳入其中，成为通信网络基础设施的范畴。&nbsp;</p><p>2020年9月，中国以“GW”公司的名义向U提交了星座频谱申请，计划发射12992颗卫星，并将它们逐渐构建成一张星网。中国计划发射的卫星数量仅次于美国，居世界第二位。&nbsp;</p><p>2021年，星际探测、重型火箭等写入“十四五”规划和2035年远景目标纲要，在上述文件中明确提及要发展空间基础设施体系、星际探测、新一代重型运载火箭和重复使用航天运输系统、探月工程四期、北斗产业化应用等重大航天工程或航天科技发展应用方向。&nbsp;</p><p>2021年4月26日，中国卫星网络集团有限公司 （简称“中国星网”） 正式成立，负责统筹规划中国卫星互联网领域发展，被誉为中国版“星链”。&nbsp;</p><p>北京、上海、天津、深圳等各地政府出台针对航空航天产业的支持政策。北京市人民政府办公厅印发《北京市促进未来产业创新发展实施方案》，其中在未来空间领域提出面向未来太空探索需求，重点发展商业航天、卫星网络等细分产业。&nbsp;</p><p>2023年10月，上海市人民政府发布《上海市进一步推进新型基础设施建设行动方案（2023-2026年）》，根据该计划，到2025年，将形成年产50发商业火箭、600颗商业卫星的批量化制造能力，以打造“上海星”“上海箭”为目标。&nbsp;</p><p>目前，上海松江正在致力于打造低轨宽频多媒体卫星“G60星链”。该实验卫星已经完成发射并成功组网，一期将发射1296颗，未来将实现1.2万多颗卫星的组网。上海联合长三角九大城市共同打造全国首个卫星互联网产业集群。&nbsp;</p><p>2023年12月，G60卫星互联网首颗商业卫星在格思航天G60卫星数字工厂下线。上海联和投资有限公司党委书记、董事长秦健介绍称，2024年，通过格思航天卫星工厂数字化生产线生产，并由垣信卫星完成至少108颗卫星发射并组网运营，G60卫星互联网产业基地将形成初步商业服务能力。&nbsp;</p><p>还有的城市利用原有产业优势，试图吸引链主入驻，打造生态圈。无锡凭借材料和先进制造，在航空领域积累了丰富的生产经验。目前，无锡正在积极加码打造航天产业，希望借助航材方面的成熟优势，帮助航天产业加速成熟发展。&nbsp;</p><p>现在，蓝箭航天在惠山区投资建设火箭高端智能制造基地，旨在与无锡携手打造一个新的产业生态，蓝箭航天空间科技股份有限公司创始人兼CEO （首席执行官） 张昌武对《财经》记者如是称。&nbsp;</p><p>有的地区依托自身区位优势，打造对商业航天更友好的发射基地，并由此延伸开发航天资源。&nbsp;</p><p>2024年1月，在山东海阳附近海域，“引力一号”圆满完成首飞，刷新全球最大固体运载火箭、国内运力最大民商火箭纪录，“引力一号”的诞生地和发射地均在烟台海阳。&nbsp;</p><p>海阳东方航天港是中国第五处火箭发射场，也是中国首个海上发射母港。海阳总投资263.7亿元，涵盖了星箭研发制造、空天信息应用、航天文旅产业等多个领域。&nbsp;</p><p>目前，各地政府纷纷加码，充分发挥自己的比较优势和绝对优势，为产业的发展构建良好的物质基础，这将有助于商业航天这一长周期的产业健康发展，也有助于地方产业的升级，实现双方的良性互补。&nbsp;</p><p>政策春风拂面之下，中国商业航天产业的发展逐渐提速。 <strong>企查查数据显示，中国现存航天、卫星相关企业共21.47万家；2023年新增5.14万家，同比增长42.84%。</strong></p><p>中国商业航天发展提速很快，市场需求十分旺盛。&nbsp;</p><p>2023年，中国一共将270颗卫星送入太空，其中有137颗是商业卫星，占比65%。这270颗卫星的发射任务中13次是由商业火箭完成的。据专家分析，2024年，中国的商业航天发展还将持续加速，未来五年至十年，将迎来快速发展期。预计五年内，中国在轨运行的商业卫星将超过1200颗。&nbsp;</p><p>在业内看来，未来五年，随着国家大的遥感星座、低轨通信星座的建设，商业火箭端明显是供不应求的卖方市场。&nbsp;</p><p>“以星链为标杆的卫星互联网应用证明了，火箭市场是一个在迅速打开的市场，厂商之间基本上不存在直接竞争。”东方空间联合创始人、联席CEO姚颂告诉《财经》记者，至少在2030年以前，各家公司只要能造出一个运载能力足够可靠、价格足够便宜的火箭，基本上就不会缺卫星互联网发射的订单。</p><h2><strong>技术追赶，任重道远</strong></h2><p>2023年12月初，中国航天科技集团有限公司明确将要对标SpaceX，并表示：在发展观念、科研生产模式、关键核心技术、质量效率等方面，跟马斯克创立的SpaceX火箭发射公司都有着明显的差距和不足，公司整体“大而不强”！&nbsp;</p><p>作为中国航天技术代表的国家队企业主动表态对标美国民营商业航天企业，并且诚恳直言存在明显差距，承认“这与我们在航天领域率先实现强国目标还相去甚远，每个航天人对此要怀有深深的危机感”，颇为罕见。&nbsp;</p><p>对此，多位航天界人士对《财经》记者表示，与SpaceX相比，国内企业在部分关键技术上，存在十年左右技术代差。&nbsp;</p><p>从发射次数上来看，2023年，SpaceX以96次发射独占鳌头，相比之下，中国以67次发射排行第二；发射载荷质量统计上，SpaceX全年发射质量达到1286吨，占全球发射质量的80%左右。这一数字已经远远超过了除SpaceX外的其他所有国家和地区全年发射载荷质量的总和。&nbsp;</p><p><strong>目前，商业航天面临着几大关键性的挑战，包括降低卫星制造成本、拓展卫星商业应用场景、降低发射成本、提高火箭运力等。</strong></p><p>中国传统卫星为保证发射成功高可靠，使得成本过高、周期过长、功能单一。制造流程往往都是非标准化的，开放度低、难以批量生产，一颗卫星制造周期平均需要36个月，难以支撑商业航天快速发展需求，影响商业卫星星座组网。传统卫星发射后，无法按需迭代升级，功能单一导致利用率低。&nbsp;</p><p>在这方面，像上海的格思航天、台州的时空道宇都在探索用数字工厂制造卫星，从而降低制造成本、提升制造效率。不过，这背后更需要整个卫星产业链条的梳理与重塑，探索卫星产品的标准化，实非易事。&nbsp;</p><p><strong>目前商业航天发展的阻碍，恰恰就是高昂的发射成本。</strong></p><p>鼎晖百孚合伙人刘尚告诉《财经》记者，和所有的运载工具一样，火箭必须降本，降低让卫星上天的成本，进而降低卫星运营商的成本，加快卫星组网的速度，让消费者能够更快更省地用上卫星互联网，最终让整个商业航天的商业逻辑早日闭环并运转起来。&nbsp;</p><p><strong>目前国内市场的太空运输价格，从地面到500公里高空，大约需要12万元人民币。</strong> 然而，由于技术创新和成本降低，SpaceX已经将类似服务的价格降低了5000美元。这表明各家公司仍然具有巨大的潜在价格优势，并且通过不断努力和技术创新，有望在未来使太空运输服务变得更加实惠。&nbsp;</p><p>商业航天时代，航天活动遵循以盈利为主要目的、遵循市场机制，因此运载火箭的低成本、大运力是未来的趋势。固体火箭结构简单，易于实现小型化，同时方便存储，可以实现快速响应的发射。&nbsp;</p><p>东方空间的“引力一号”是迄今全球运力最大固体运载火箭、迄今国内运力最大民商火箭等亮眼纪录。其运载能力处于目前中低轨卫星星座组网发射运力需求主流区间，不仅可以支持百公斤级卫星的“一箭30星”，实现“一箭一轨”或“一箭半轨”发射，助力星座组网工作的高效推进，还可以发射3吨至4吨重量的小型货运飞船、超大型卫星等。&nbsp;</p><p>垂直起落是当前重点发展的回收手段，目前主要由美国的SpaceX引领该技术。液体火箭有更高的性能，同时可以多次启动和推力可调，进而实现火箭的垂直回收，对于降低发射成本至关重要。&nbsp;</p><p>2023年12月，星际荣耀的双曲线二号验证火箭在中国酒泉卫星发射中心完成了第二次飞行试验，成功完成了一个高度达340多米的“蚱蜢跳”。&nbsp;</p><p>“我们计划在2025年底，发射能够成功入轨并可回收的火箭双曲线三号，如果我们能够成功，那就相当于达到了SpaceX在2015年时的水平。”双曲线二号验证火箭型号总师季海波告诉《财经》记者，只有攻破这一难关、达到这一目标，再往后，我们和SpaceX的差距才会逐步减少。&nbsp;</p><p>商业航天企业中人，对于SpaceX的发展经历如数家珍，在接受《财经》记者采访时，他们普遍感慨马斯克的敢想敢干，以及NASA长期以来通过订单持续“投喂”，让SpaceX走出了早期技术验证的荒漠阶段；同时也羡慕SpaceX所处的资本市场对于前瞻科技受挫失败的较高容忍度。&nbsp;</p><p>此外，还有一些软性实力的差异，比如航天文化。中国科技新闻学会太空文化传播青少年工作委员会委员王君毅告诉《财经》记者，每次对外宣讲，他都会从“航天和航空的区别在哪里”开篇，在他看来，国内航天科普尚处萌芽期，任重道远。&nbsp;</p><p>在这方面，美国国家航空航天局 （NASA） 形成了相当发达的航天文化产业：定期开放公众参观，航天员、工程师亲临现场做科普；另外，还会在影视节目中植入自身角色。如此种种，帮助年轻人内心种草，从小向往航天事业；依托肯尼迪航天中心等航天资源打造航天文化、航天科普基地。&nbsp;</p><p>这对招引人才具有重大的意义。业内曾有个传言，谷歌创始人Larry Page将NASA视作竞争对手。自己用期权、高工资能从苹果抢来的人才，面对NASA的“降薪”入职邀请，依然甘之若饴。因为后者的事业更大、更好玩。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_f0a40a80e87f483da51f80a8b0261a2c@46958_oswg357835oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2023年12月29日，海南文昌，中国首个开工建设的商业航天发射场——海南国际商业航天发射中心一号发射工位竣工。图/中新&nbsp;</p><h2><strong>资本加持，期盼国民共进</strong></h2><p>商业航天领域刚刚起步，技术还处于迭代阶段，市场处于培育期，因此需要更多政策性支持和更充裕的资金支持。&nbsp;</p><p>航天产业投资的高峰期发生在2019年至2021年，直到2021年至2022年，由于多家企业遭遇发射失败，商业航天经历了一个低潮。&nbsp;</p><p>不过，从2023年开始，因为国家政策层面开始加大扶持力度，资本市场对商业航天的热度显著升温，不少政府引导基金和对政策比较敏锐的基金重点关注航天产业。&nbsp;</p><p>企查查数据显示，融资方面，2023年，我国商业航天领域有133个品牌产品合计完成170起融资，合计披露融资金额超185亿元。&nbsp;</p><p>从融资轮次上看，2022年-2023年，近五成融资事件处于股权融资，有160起；A轮23起，占比6.91%；早期融资，如种子轮及天使轮共计42起，占比12.61%。&nbsp;</p><p>2022年12月，长光卫星技术股份有限公司向上交所提交了科创板IPO （首次公开募股） 申请，有望成为国内首个IPO的商业航天公司。&nbsp;</p><p>2024年1月，东方空间宣布完成近6亿元人民币B轮融资，此次融资将用于“原力-85”百吨级液氧煤油发动机研发与生产工作，加速“引力二号”中大型可回收液体运载火箭研制。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_64ce264bf2514a4dae4d8be02597e0a6@46958_oswg321469oswg1013oswg791_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2024年1月，在山东海阳附近海域，引力一号（遥一）海澜之家号运载火箭，将搭载卫星顺利送入预定轨道。图/东方空间</p><p>不过，航天事业实在太烧钱。重资产运营之下，前期资金需求量巨大，依赖对外融资。航天十二院战略规划推进部测算，巨型的互联网星座建设如OneWeb、StarLink等建设规模达千颗卫星，其资金需求在百十亿美元左右。建设规模在百颗卫星级别的星座，资金需求也在30亿美元左右。&nbsp;</p><p><strong>因此，商业航天想要越过“死亡谷”（创业企业在获得正向现金流之前的一段盈亏曲线），需要不小的资金储备。</strong> 另据卫星与航天市场研究与咨询公司Northern Sky Research的预测，全球只有18%的星座能走到发射阶段，少数公司具备卫星发射能力。&nbsp;</p><p>从市场规模看，中国商业航天产业已经初具规模，并且迈入产业发展的快车道；从应用场景看，虽然商业航天仍处于产业发展的初级阶段，但发展空间及潜力极大，这种发展潜能吸引了资本市场的持续投入。但是，随着资本逐步向优秀企业集中，商业航天企业需要加速商业化应用落地，形成先发优势。&nbsp;</p><p>商业航天领域投资仍然存在高投入、长周期、高门槛等特点，尚未出现成熟的商业化路径。从投资端看，受准入门槛限制，人民币基金在商业航天领域的投资具有本土优势。&nbsp;</p><p><strong>“投资商业航天的黄金窗口还有两年。”</strong> 新鼎资本董事长张驰认为，商业航天即将迎来大规模发展，头部玩家的先发优势会很明显。而且整个产业链条并不像汽车、芯片那么长，如果看上好项目，出手要趁早。&nbsp;</p><p>谈及商业航天和国家航天之间的关系，业内也是众说纷纭。&nbsp;</p><p>“如果实现‘国家队’和民企的紧密合作，让这些技术下沉到民企开展的航天项目中去，就能极大节省民企在技术研发的巨大投入，进一步降低风险。”在北京大学地球与空间科学学院教授焦维新看来，来自体制内的力量也能为民营航天企业的成长提供不可或缺的帮助。&nbsp;</p><p>对此，张驰认为中国产业链条完备，善于实现规模化、产业化的大规模推广。就像当初Tesla跑通了锂电池造车的商业逻辑和产品雏形，最终中国成为全球最大新能源汽车消费、制造全链条市场一样，商业航天更合适借助成熟技术，不断探索和拓展盈利模式。&nbsp;</p><p>事实上，两者之间的互动往往是双向的、共赢的，尤其是创新性商业模式上，商业航天能够让大众体会到航天技术的实惠，加速完成航天领域的国家战略，让国家力量将资源聚焦于更具挑战，更需要长期探索的前瞻和基础研究上。&nbsp;</p><p><strong>跳出体制机制的天生差异，或许商业航天还可以换一个思路来理解——“从商业属性上，能够自我造血，谋求可持续高质量发展的航天事业。”</strong> 这不但要求完善现有航天领域的基础设施，比如上文所述的火箭发射、卫星制造的高效、低价、规模化，更在于整个产业链条的创新，以及创新业务的探索及商业运作。&nbsp;</p><p>在基础设施的巨大投入后，如果没有商业化运营、市场化拓展，整个产业的价值便难以得到充分体现，甚至无从体现。万物生华工程技术研究院常务副院长刘雨菲认为，商业航天不应该仅仅是传统航天的补充，还是航天业发展的一个重要方向与转型路径。&nbsp;</p><p>前苏联火箭先驱康斯坦丁·齐奥尔科夫斯基曾说过：“地球是人类的摇篮，但人类不可能永远被束缚在摇篮里，而会不断探索新的天体和空间，先小心翼翼地穿出大气层，再去征服太阳系。”&nbsp;</p><p>600年前，从大江大河内陆海到大洋，今天从地球到太空的星辰大海。正所谓能力越大责任越大，中国应该在人类文明探索航天的征途上向前一步，商业航天正是一支不可忽视的庞大舰队。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ktouZgPU8WxD9oaxVRxqVA" rel="noopener noreferrer nofollow" target="_blank">“财经十一人”（ID:caijingEleven）</a>，作者：李皙寅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653885167647875</id>
            <title>电商“变法”，AI维新</title>
            <link>https://www.36kr.com/p/2653885167647875</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653885167647875</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:31:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>度过了一个春节假期后，开工的第一天，想必很多朋友都想不起来自己以前是干什么工作的了——电商人除外。</p><p>大过年仍旧坚守岗位的电商从业者不少。今年，京东、小红书都作为2024央视春晚的唯二大厂，在全国观众面前刷了一把存在感。其中，京东是大家熟悉的传统电商巨头，努力通过春晚红包活动，激活新的增长。小红书则在“大家的春晚”直播中同步上架“春晚同款”，向电商领域大步进攻。</p><p><strong>这种“新旧混战”的局面，是电商行业这一年多来的“主旋律”，并将在2024年变得愈发激烈。</strong></p><p>其实早在节前的一月份，各个平台促销正酣之时，就爆发过一场关于“新旧电商”的大讨论。</p><p>一些消费者、互联网产品经理、行业分析师等，认为阿里系（淘宝、天猫、一淘等）、京东这类传统电商，有严重的“路径依赖”，延续着以前惯用的营销手法——“年货节”。只有拼多多显示“正常发货”，狠狠拿捏住了春节商家歇业快递停运的用户痛点。</p><p>反方则认为，这波对拼多多是“过誉”“尬吹”，只是宣传文案有差异，京东、淘宝也都有“春节不打烊”活动，没人会彻底躺平。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_cf9118cd34b14fb2b06fd8be4f5afb51@000000_oswg169980oswg367oswg388_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（引发讨论的截图之一）</p><p>吵得激烈，说明多个电商平台“卷起来”，谁都别想躺赚，消费者是乐意见到的。同时，大众也对传统电商的创新不足，积怨已久，“恨铁不成钢”。</p><p>这不禁让我想起了去年底，拼多多市值超过阿里时，马云在内网罕见发声，“AI电商时代刚刚开始，对谁都是机会，也是挑战”。</p><p>言犹在耳，但问题是，AI或许对很多人来说是一个陌生的概念，但对“数字原生”的电商企业来说，却不是什么新事物，早在2013年，淘宝就提出了“千人千面”的算法。拼多多几年前的招股书中，就提到“拼多多是由分布式智能代理网络（分布式AI）驱动的”。</p><p>维新变法之后，李鸿章说过一句话：“若旧法能富强，则中国之强久矣，何待今日？”同样的逻辑，若靠AI就能保持领先，那传统电商其实在技术上一直并不弱，又为什么会被后起之秀迎头赶上呢？</p><p>从 “电商+AI”到“AI电商”，残酷的存量时代，电商行业需要的，不只是从机器学习到大模型的技术升级，而是一场更彻底的“变法”。</p><h2><strong>电商求变，AI革命肇始</strong></h2><p>目前，头部电商平台和AI科技公司，都纷纷在“AI电商”领域集结重兵。</p><p><strong>“守成”赛道：</strong>阿里系、京东系，要守住自己在电商领域的头部身位。淘天集团刚刚建立了完整的AI团队，把原本负责AI业务的20多个团队收拢为4个团队，分别负责阿里妈妈、C 端消费者、B 端商家，以及行业特色应用。京东基于言犀产业大模型，上线了京东云AIGC内容营销平台，言犀数字人平台，以及一系列AI工具，为京东零售及外部客户所用。</p><p><strong>“进取”赛道：</strong>拼多多、字节跳动、快手、小红书等，拥有自己的电商业务，也都相继推出了AI工具。</p><p><strong>“跨界”赛道：</strong>百度、腾讯等基础模型厂商，也都带着AI挤进电商战局，推出了针对性的技术解决方案。</p><p>总体来说，和此前将机器学习、小模型应用于业务的“电商+AI”不同，这一轮由大模型掀起的AI热潮，对电商行业的冲击是前所未有的，竞争也格外激烈。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_f661be102cc1471eb9ad5cbbcab87a50@000000_oswg508126oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>究其原因，一是外部危机。</strong>电商行业整体增速放缓，进入到存量市场竞争阶段，传统电商和新晋平台的矛盾也一步步加深，同时消费者的行为决策习惯也出现了很大的变化，追求更高的性价比、直播/内容种草等新形式，电商企业到了不得不升级的时候。</p><p><strong>二是内部基础。</strong>电商企业一开始就建立在互联网、移动互联网之上，是数字化最早、最成熟的行业之一，大量业务是由数据驱动的，为引入AI提供了很好的基础，也有通过AI降本增效的现实条件和迫切诉求，非常适合大模型、AIGC、数字人等新一代AI技术的落地。</p><p>内外驱动之下，电商行业迎来了一场轰轰烈烈的AI革命。</p><h2><strong>AI“维新”，重塑电商产业链</strong></h2><p>大模型强大的理解、泛化能力，使其在创造、生成、决策等任务上，比此前的机器学习更具颠覆性，可以改造电商产业链的每一个环节。</p><p>我们通过交易的四个核心步骤来看看，AI给电商带来的新意：</p><h3><strong>1.建店经营。</strong></h3><p>网商的前提是要有货物的展示平台，流量的承载渠道，“线上店铺”就是一个必要的入口。对一个商家来说，开店、拍摄、美工、文案、上新等日常经营活动，周期长，琐事多，成本高，有大量重复性操作，让员工苦不堪言。大模型的生成能力和AIGC工具，可以帮助商家极速开店，自动生成商品素材图片，节省模特、拍摄、后期等成本，写好详情页文案，优化标题等。</p><p>线上店铺的经营门槛大幅降低，对于青年创业者、农林牧副渔等运营能力不高的传统行业企业，AI可以让他们快速进入电商行列。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_5772000fb22b4009a79e7e346642b7fc@000000_oswg709483oswg957oswg690_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>2.创意营销。</strong></h3><p>有了店铺，流量从哪里来？随着消费者年龄的年轻化，购物习惯也发生了很大的变化，主要转化率较高的两种增长方式：一是基于内容营销种草，兴趣决定购买；二是基于主播互动的消费，决策链路更短。</p><p>对商家来说，内容营销涉及选品、文案制作、短视频制作、内容投放，每一步都精准，才能打造“爆款”，实现生意爆发。阿里妈妈将直通车、引力魔方、万相台等多个营销工具聚合升级为“万相台无界版”，根据目标用户，智能生成广告内容，再进行智能投放。一个营销活动结束后，通过AI智能分析进行复盘、总结，为新手小白商家提供决策帮助。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_bac1e8b615824085aafbd3b106613d36@000000_oswg292482oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>直播带货的流量凶猛、增长强劲，然而一个真人主播团队，包括主播、运营、中控等专业人才，是很多中小微商家所承受不起的。数字人直播就成为一个比较好的替代，可以24小时不间断直播，随时与用户互动，不错过成交机会。而且只需要虚拟数字人和一个运营，成本大大降低。目前数字人是各个电商平台和AI大模型厂商都在重点升级的能力之一。据京东战报，2023年618期间，言犀数字人开播商家较去年双十一增幅超5倍。百度电商的慧播星7*24h日不落计划，部分优质直播间的单场直播GMV高达300万。</p><h3><strong>3.交互服务。</strong></h3><p>通过内容种草和数字直播，吸引到新用户，还需要接待、咨询和导购等一系列服务。目前，很多电商平台都对客服的响应时间做了规定，以提升消费者体验，这也给平台商家和人工客服带来了很大的压力。基于大模型，AI客服、AI导购可以理解用户的提问，提供问答服务。这也是AI电商的重点，包括京东AI智能客服“京小智”、淘宝的“淘宝问问”、百度电商推出的优选智能助手“小优”、小红书的AI智能笔记助手等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_03d856e79e5e49a1a0a6aa811724577c@000000_oswg88230oswg595oswg420_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>4.物流履约。</strong></h3><p>物流履约环节，是电商服务链条中相对较重，也直接影响到用户体验的关键部分。收发货快不快、好不好，用户体感会决定品牌美誉度、复购率。</p><p>一些拥有物流体系的电商平台来说，通过AI技术优化供应链管理，提升履约效率和质量，可以形成差异化的竞争优势。</p><p>比如言犀大模型的AI赋能京东的数智供应链，提高商品流转效率；菜鸟官网也显示，落地应用了大量阿里的AI技术，包括智能调度算法、智能地址识别、切箱算法等，提高物流运营效率。</p><p>总而言之，从开店上新到履约完成，AI在电商上下游产业链遍地开花，展现出全盘改造的生命力。</p><h2><strong>革命尚未成功，AI仍需努力</strong></h2><p>总而言之，AI电商充满了想象力。但正如历史上所有新事物的成长一样，都要经历一个漫长的成熟期，面临来自保守力量的阻截，AI电商也不例外。</p><p>从AI自身来看，技术成熟度还有待打磨。</p><p>面向电商的AI内容生成，在细分行业理解、内容合规、生图效果上都有待改进。一味追求AI降本增效，内容效果不佳而仓促上线，很容易引发消费者的反感，得不偿失。</p><p>目前，社交网络上已经出现了“第一批AI电商受害者”。有商家利用AI生成的模特图，与实物差别巨大，没有真实地反映产品信息，反而增加了消费者的决策难度，伤害了用户体验与信任。</p><p>低质、失真的AI内容，恐怕会加速用户流失与口碑下滑，因此电商平台必须慎之又慎，并制定相应的反馈和规范机制，来进行约束。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3cc4a8a82e364b56a9456d0c3ae52403@000000_oswg241681oswg364oswg537_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智能客服与导购也存在类似的问题。消费者做消费决策需要的是认真负责地介绍和建议，而大模型的“幻觉”问题带来了不可控。京东集团技术委员会主席、京东云事业部总裁曹鹏此前曾对媒体表示，“当文心一言、星火产生一个错误回答时用户会一笑了之，但是在严肃的商业实践中，一个错误意味着不可估量的损失”。</p><p>数字人主播也存在技术规模化应用不成熟的问题。必须承认，现在的数字人主播，交互能力有限，大多只能进行单纯的讲解和商品优惠介绍，无法跟用户深入沟通，消费者难以跟数字人主播建立情感连接，看几次就审美疲劳了。</p><p>归根结底，AI之于电商还是“花拳绣腿”，有待技术的更新迭代优化，以及更多AI-native应用的开发。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_7d2cf8802e67411fbf868138a9900cf4@000000_oswg773430oswg858oswg509_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而相比技术本身，来自组织的惯性力量，或许才是电商变革的最大阻碍，也是更难触动的。</p><p>就拿春节大促来说，AI通过数据和竞对分析，未必写不出“正常发货”的文案，但比起“年货节”这样做过多次、员工操作熟练、执行效果也不错的方案，一个效果未知、履约难度大、风险成本高的新方案，在内部能够顺利推动吗？多个部门之间能配合吗？商家和物流体系呢？</p><p>AI的船舵，最终还是把握在人的手里。一切触动根本的改革，一定都是“一把手工程”，自上而下推动的。</p><p>我们曾走访过很多数字化转型的零售企业，比如某500强国产羽绒服品牌，专门成立了“数字化专班”，由从生产到营销的负责人组成，去协调各方利益与积极性，才推动了数字化、智能化技术在内部的全面落地。</p><p>AI电商也是如此，不仅要技术升级，也要在组织管理、产业开放度、渠道关系等多方面，进行全面深入的改造。</p><p>举个例子，AI工具要对商家带来生产力增长，必须根据行业特性、专属数据进行精调，做好产品化打磨，让小白商家也能轻松上手，AI生成内容质量可控、成本可控。这种AI工具和开发工作，会非常多、非常琐碎，靠电商平台自己是无法全部干完的，这就需要一群AI开发者。</p><p>那么，电商平台是否有开放心态来扶持AI开发者生态和第三方服务商，是否能守住不碰用户数据、不做用户业务的边界感？</p><p>如果AI工具和产品全都自己研发，内部是否有充足的开发力量，团队之间的配合是否高效？技术研发是否与落地紧密结合，解决商家经营中的实际问题？AI产品推出后，是否给商家提供了平台环境、易用工具链、存算网资源等充分的支持？</p><p>毫不怀疑，电商是AI技术最好的练兵场，AI是电商行业必不可少的利器。二者结合，AI电商将会是2024最值得期待的革新之一。</p><p>但最终，新技术会将哪一些企业，送上时代的浪潮之巅，取决于它们是否被彻底地信仰、有力地执行。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzUxNTUyMjE4Mw==&amp;mid=2247519743&amp;idx=1&amp;sn=573fd2d5cdaf751422541f48a9e0eef2&amp;chksm=f86f24fd023d249f0faea23fb2c67290605f62e4038d6d76149dbaeee456f7ad5537a499b37c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“脑极体”（ID：unity007）</a>，作者：藏狐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653933193940228</id>
            <title>夫妻奶茶店跑出一个IPO，估值50亿</title>
            <link>https://www.36kr.com/p/2653933193940228</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653933193940228</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:30:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_048036c9b1914444b6e03f8bd6bdb7a8@5807375_oswg1282303oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>继成都、郑州、台州后，这回奶茶IPO轮到了上海。&nbsp;</p><p>2月14日，沪上阿姨（上海）实业股份有限公司（简称：沪上阿姨）以向港交所递交上市申请，正式宣告加入奶茶上市潮，成为了继茶百道、古茗、蜜雪冰城之后，又一家向港股发起冲刺的新茶饮品牌。&nbsp;</p><p>据灼识咨询报告，截至2023年9月30日，以全系统门店数目计算，沪上阿姨是中国北方最大的中价现制茶饮店品牌、中国第三大中价现制茶饮店品牌，为中国第四大的现制茶饮店网络。&nbsp;</p><p>值得一提的是，与前三年赴港IPO的奶茶店不同，正如沪上阿姨选择于情人节提交招股书一般，这家上海奶茶店颇具罗曼蒂克色彩，掌舵人为一对夫妻。&nbsp;</p><p>他们于2013年离职500强企业后，以上海老弄堂的沪式茶饮为奶茶灵感，将门店取名为“沪上阿姨”，由售卖“五谷奶茶”起家，后又在鲜果茶需求不断增长下，于2019年开始提供鲜果茶，得以在全国快速扩张，截至2023年9月30日，其门店数量达到7297家。&nbsp;</p><p>而现在，随着开出7000家奶茶店，这对夫妻也踏上了IPO征途。&nbsp;</p><h2><strong>“山东女婿”奔沪创业，嘉御资本连投三轮</strong></h2><p>沪上阿姨的故事，始于单卫钧和周蓉蓉这对夫妻。&nbsp;</p><p>上个世纪90年代末，单卫钧与妻子周蓉蓉在山东知名外资企业工作，均做到了高级经理。2011年，单卫钧想去更广阔的天地“折腾”一下，便卖掉山东的房产和车辆，举家搬到了上海。&nbsp;</p><p>一次偶然，两人在旅途中接触到奶茶，在看到了中国茶发展的新机遇和大市场后，2013年，夫妻俩便在上海人民广场开出了第一家沪上阿姨。&nbsp;</p><p>从这个25平米的店铺开始，他们做的第一杯五谷血糯米，将五谷和奶茶进行跨界搭配，首月销售额破40万。在上海连开几店后，沪上阿姨率先开始拓展山东市场，并把首店开在周蓉蓉的老家烟台。此后沪上阿姨又逐步开拓东北、河北、天津等地市场。&nbsp;</p><p>但随后，当单卫钧试图拓展南方市场时，却发现能在北方市场引起热烈反响的五谷茶不如凉爽的水果茶更受欢迎，尤其体现在下沉市场。&nbsp;</p><p>故而2019年，沪上阿姨迈出了向新鲜水果茶进发的第一步，并于2021年起，由“五谷茶”向“鲜果茶”转型，此举也让沪上阿姨得以在全国各地快速扩张，并扩展至南方地区。&nbsp;</p><p>据招股书，2021年、2022年至2023年9月30日，沪上阿姨全系统门店数目分别为3776家、5307家、7297家，其GMV由2021年的41.61亿元增加45.8%至2022年60.68亿元，并由截至2022年9月30日止九个月的45.54亿元增加57.7%至截至2023年9月30日止九个月的71.83亿元。&nbsp;</p><p>根据灼识咨询，于2022年及截至2023年9月30日止九个月，以全系统门店数目及GMV增长率计算，沪上阿姨是以全系统门店数目计算的前五大现制茶饮店品牌中增长最快的现制茶饮店品牌。&nbsp;</p><p>市场上的优异表现，自然也引来了一众资本驻足。&nbsp;</p><p>就在2020年，沪上阿姨以加盟跑出“逆势扩张”之势时，2020年11月及2021年10月，A轮及A+轮融资也相继完成，苏州宜仲两次分别以对价7500万和5300万元投入。&nbsp;</p><p>2023年7月，金镒资本、苏州祥仲、知壹投资、德赛创新、市北高新、南京祥仲、颐玉谘询这7家VC又跑来“团购”B轮；甚至在今年2月提交招股书之前，瀚率投资、金鴞投资、上海一僕及银麟投资又“突击”C轮入股。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_75284eeb87c5417f9052636f42fee01c@5807375_oswg33428oswg954oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：沪上阿姨招股书截图&nbsp;</p><p>据招股书，2020年至2024年，沪上阿姨分别在A轮、A+轮、B轮和C轮融资7500万元、5300万元、2.3亿元和1.215亿元，每股对价从11.96元到50元，意味着这四年来估值翻了3.2倍。&nbsp;</p><p>按照最后一轮融资，银麟投资以对价800万元认购新增注册资本，持股为0.16%计算，沪上阿姨C轮融资估值为50亿元。&nbsp;</p><p>值得注意的是，苏州宜仲、苏州祥仲、南京祥仲均由苏州维特力新创业投资管理有限公司(简称：苏州维特力新) 管理，由嘉御资本创始合伙人兼董事长卫哲最终控制。这意味着嘉御基金对沪上阿姨连投了3轮，共计投资了1.78亿元。&nbsp;</p><p>IPO前，单卫钧和周蓉蓉合计持股80.63%，嘉御资本通过苏州宜仲、苏州祥仲、南京祥仲合计持股8.15%，为第一大机构股东。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_6e2a3c190be441d187b6af21d614ab4f@5807375_oswg30107oswg1080oswg475_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：沪上阿姨招股书截图&nbsp;</p><h2><strong>聚下沉、抢加盟，2024奶茶店IPO提速</strong></h2><p>随着奶茶店头号玩家们集体亮相港交所，不免要被横向比较，这其中，沪上阿姨自然算不上“遥遥领先”。&nbsp;</p><p>据招股书，蜜雪冰城国内外超36000家门店，截至2023年9月30日，公司拥有超过16000个加盟商伙伴。&nbsp;</p><p>同天递表的古茗，截至2023年12月31日，其门店网络共有9001家门店。再看茶百道招股书，截至2023年8月8日，其门店达7117家。&nbsp;</p><p>简单来看，沪上阿姨的门店网络跟茶百道旗鼓相当，但跟古茗仍有差距，更是被行业老大蜜雪冰城甩在了后面。&nbsp;</p><p>在财务数据方面，沪上阿姨的成绩虽然不错，但同比第二梯队其他玩家却略微逊色。&nbsp;</p><p>2021、2022全年以及2023年前9个月，沪上阿姨营业收入分别为16.40亿元、21.99亿元、25.35亿元，对应净利润分别为0.83亿元、1.49亿元、3.24亿元。&nbsp;</p><p>而古茗在2023年前9个月门店数量为8578家时，实现了55.71亿元营收，净利润10.45亿元，在门店规模相差1281家的情况下，其营收规模跟净利润分别为沪上阿姨的2倍及3倍。&nbsp;</p><p>与此同时，提交招股书的奶茶们更是在加盟及下沉上有着相同的偏好。&nbsp;</p><p>数据显示，截至2023年3月末，茶百道在三线及以下城市的门店数量占比为39.4%。截至2023年9月末，沪上阿姨网络中约49.0%的门店位于三线及以下城市。截至2023年末，古茗三线及以下城市门店数量占比为49%。&nbsp;</p><p>下沉意味着这些茶饮顶流们都走的是“蜜雪冰城”路线，而能实现狂奔就得归因于加盟。&nbsp;</p><p>招股书显示，截至2023年9月，3.6万家蜜雪冰城中，99.8%是加盟店；8578家古茗里，除了6家直营店，剩下的都是加盟店。截至2023年8月8日，茶百道门店已达7117家，其中99%都为加盟门店。到沪上阿姨这边，加盟店比例也从2021年的98.3%进一步提升到2023年9月30日的99.3%。&nbsp;</p><p>加盟不仅为各家跑马圈地打下基础，更是让奶茶店们赚得盆满钵满。&nbsp;</p><p>据招股书，以2023年前9个月为例来看，蜜雪冰城“销售商品（向加盟商卖商品）”收入是145亿，占比94%，古茗销售商品的收入是42亿，占比四分之三；茶百道向加盟店下销售货品及设备是茶百道最核心的收入来源，在其报告期内，这一收入占总收入比例均在93%至95%之间，2022年其来自货品的收入占比90.1%。&nbsp;</p><p>截至2023年9月30日止九个月， 沪上阿姨7245间加盟店收入占总收入的96.1%。其中，向加盟商销售货物占其加盟业务收入的绝大部分，向加盟商销售货物的收入占加盟业务收入的79.7%。&nbsp;</p><p>可见，加盟商及加盟店的数量对各家经营业绩的影响之大。&nbsp;</p><p>而随着头部玩家们规模效应显现，在下沉抢加盟的情况也愈发激烈，奔赴二级市场，或成为奶茶内卷之中增强竞争力的一大途径。&nbsp;</p><p>（首图来源：企业供图）</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/4Igco-C-qAu92PWhJcrkBg" rel="noopener noreferrer nofollow" target="_blank">“直通IPO”（ID:zhitongIPO）</a>，作者：孙媛，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653863154745607</id>
            <title>先捧后“杀”？Vision Pro难救苹果</title>
            <link>https://www.36kr.com/p/2653863154745607</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653863154745607</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:30:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>被苹果 CEO蒂姆·库克赞美为“将开启空间计算时代”的Vision Pro，正在遭遇一场退货潮。&nbsp;</p><p>2月16日，话题#果粉们开始大批退货Vision Pro#突然登上微博热搜榜，在话题下面，不少用户纷纷发表了自己的观点：“这玩意儿现在发展得确实还没那么成熟，建议租赁”“苹果有一个14天全额退款的退货计划，随着这个时间的接近，出现一股退货潮在所难免”“一斤多的重量都堆到眼前，舒适度为零，退货也是情理之中”“不实用，一般人用不上”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_f8bf0cd59c9141dca2511bf61774de04@000000_oswg183326oswg1080oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：微博</p><p>事实上，自Vision Pro于2月2日上市之后，用户就已在各类社交平台上吐槽Vision Pro的实际使用感受，综合而言，其槽点主要集中在：佩戴体验不舒适、实际体验与想象存在偏差、眼睛疲劳、使用场景有限、内容生态尚未构建完整等等。</p><p>Vision Pro曾一机难求。1月19日上午8点，Vision Pro准时开启预售，然而开售不到5分钟，服务器就被挤爆了，很多订单无法处理，仅仅开售半小时后后，便已显示全部售罄。因为订单较多，导致Vision Pro发货时间大幅延后，苹果官网显示，发货日期已经延至3月份，部分订单甚至已经排到了4月份。</p><p>短短一个多月的时间之后，用户对待Vision Pro的态度却发生了天壤之别的转变，对于股价接连受挫、iPhone销售情况不及预期的苹果而言，Vision Pro似乎还是难以成为苹果的第二增长曲线，Vision Pro能否力挽狂澜并帮助苹果创造新的消费电子时代，目前仍是一个未知数。</p><h2><strong>01.大批用户退货Vision Pro</strong></h2><p>东海证券研报显示，预售开启后的首个周末，苹果即售出16万台至18万台Vision Pro，预购不到10天，苹果已售出超20万台Vision Pro，但在近半个月的体验过后，不少曾经抢购Vision Pro的用户的兴奋劲已经过去了，并且发现了Vision Pro存在的诸多缺陷。</p><p>Meta CEO马克·扎克伯格在体验完Vision Pro后，在Instagram上发布了一段视频开怼Vision Pro，并将其与自家产品Quest 3进行了对比。</p><p>马克·扎克伯格在视频中表示，在使用了Vision Pro后，“我不仅认为Quest 3更具性价比，我还认为它是更好的产品，不接受反驳”。此外，他在视频中重点强调了苹果所做的妥协，认为Quest 3的重量轻了120克，更便于舒适地长时间佩戴。他还表示，由于没有有线电池组，Quest 3的运动范围更大，而且视野也比Vision Pro更宽。</p><p>特斯拉CEO埃隆·马斯克也对Vision Pro进行了吐槽。2月7日，马斯克在X平台上回应了一位用户对Vision Pro的评论，埃隆·马斯克称，“我试过Vision了，但它并没有让我震惊”。同时其还表示，“iPhone 1在我看来也不怎么样。考虑到所有因素，它的实用性比其他替代品要低，但到了iPhone 3，无疑是最好的智能手机”。</p><p>众多用户也直言Vision Pro的实际体验与想象中存在较大的偏差，而偏差主要集中在以下两个方面。</p><p>佩戴不适感是引发Vision Pro退货潮的主要原因之一。不少用户反映，Vision Pro容易导致视觉疲劳，并出现眼睛红肿现象。亦有用户表示，佩戴Vision Pro会导致头痛和晕动病。一名科技博主在YouTube发视频称，Vision Pro的重量明显是一种负担，感觉不舒服，如果用头显做在iPhone或Mac上做的事情，比如打开Safari浏览器或搜索二手车，还需要额外的步骤。</p><p>此外，Vision Pro还存在着视觉效果不佳的情况。有不少用户在社交平台上抱怨称，Vision Pro将虚拟应用覆盖在用户视线之上的能力“还不够好”，当观察真实物体时，视线在大多数照明条件下都是模糊的，比如查看电脑或iPhone时，图像质量不够清晰，无法看清屏幕上的内容，阅读小字体的论文也是如此。还有用户指出，佩戴Vision Pro时只有转动头部才能看到屏幕上的不同元素，因为屏幕周边有巨大的黑边，模糊并扭曲了20%左右的视线。</p><p>不过，也有用户站在中立的角度上，对Vision Pro遭遇退货潮进行了分析。一位科技博主在社交平台上发文称，“目前除了少数数码、科技领域等人士有幸体验过，估计国内99.99%的人都没有机会体验。到底成色如何，应该等到国内大规模上市，更多人体验过才有说服力。另外，任何产品的一代，要想达到出色、让人惊艳的程度都比较困难。经过不断迭代，后面不断改进优化，会逐渐赢得未来。”</p><p>截至目前，尽管苹果并没有对Vision Pro遭遇退货潮进行回应，但无法忽视的是，Vision Pro在上市初期就遭遇了退货潮，侧面反映出Vision Pro的市场接受度仍存在不确定性。</p><h2><strong>02.Vision Pro难成救命稻草</strong></h2><p>Vision Pro预售火爆，并被苹果视为第二增长曲线，但目前而言，Vision Pro很难成为苹果的救命稻草。</p><p>一方面，要想让用户持续使用并购买Vision Pro ，就需要建立一个丰富的内容生态，包括游戏、电影、音乐、社交等各个方面，而Vision Pro运行的是visionOS系统，此前有报道称，visionOS主要面向的目标用户是iOS开发者，但他们对空间开发环境还不熟悉，而且当前visionOS版本App的应用都还停留在2D交互层面，无法发挥Vision Pro硬件能力。</p><p>苹果确实也在努力改进Vision Pro的内容生态。2月14日，苹果全球营销高级副总裁 Greg Joswiak称，目前有1000+ App专为Vision Pro设计，远远超过产品刚发布几天上线的150多个应用程序。</p><p>尽管苹果已经构建了上千个应用程序，但仍然有用户认为，“现在没有足够多的多样化体验和多样化内容，来保证每周使用它大约两个小时”。值得注意的是，内容生态要由来自各行各业的合作伙伴共同建设，并不是短期内能迅速解决的事情。</p><p>另一方面，Vision Pro的价格对于大部分用户而言是一个重要的考虑因素，与国产AR眼镜厂商相比，动辄超过两万元的价格并不具备性价比。</p><p>2月2日，Vision Pro正式发售，起售价为3499美元，由于在中国市场未发售，导致国内价格被炒到10万元。天风国际分析师郭明錤表示，苹果Vision Pro头显的初期备货约为6万至8万台，由于备货数量并不多，在上市初期会出现脱销现象。</p><p>此外，有市场机构曾预估，Vision Pro首年销售预期约为30万至40万部，即便顺利实现这一预估目标，也只能为苹果带来14亿美元的收入，不足苹果总收入的1%。可见，现阶段Vision Pro还难以成为苹果的救命稻草。</p><h2><strong>03.Vision Pro困于小众</strong></h2><p>虽然Vision Pro在WWDC2023上发布之后变得声名大噪，但仍然是一款十分小众的产品。市场研究机构Counterpoint认为，3499美元的定价表明，Vision Pro并非针对普通消费者，而是瞄准专业用户和内容开发者。</p><p>郭明錤在最新发布的报告中指出，根据预购前的备货水准，以及出货时间，预估苹果在开放Vision Pro预购后，首周末卖出16万至18万部Vision Pro，在今年的出货量达到50万部应不难。但在预购销售一空后需求却快速下滑。郭明錤还表示，早期迹象可能意味着，市场对Vision Pro的需求正在减弱。预订开放后48小时内，那些延长的发货时间并未发生变化，这引发了一个重大担忧：即在核心粉丝和重度用户下单后，需求可能会迅速减弱。</p><p>华泰证券也在研报中指出，假设Vision Pro一代产品出货量为50万台至100万台，乐观计算第一代产品对供应链一年的拉动约为30亿美元，而iPhone对供应链的拉动约为600亿美元，明显相差较大。</p><p>不过，不少机构也对Vision Pro的发展潜力寄予厚望。1月31日，市场调查机构Statista发布报告称，彼时苹果Vision Pro销量已逼近20 万台大关。预估Vision Pro上市首年出货量为35万台，第二年将达到148万台。根据售价和预测销量简单计算，Vision Pro今年预计为苹果带来12亿美元的收入，2025年则预计带来近52亿美元的收入。</p><p>摩根士丹利预测，苹果可以在发布后的四年内将Vision Pro带来的收入提高到40亿美元，这一增速将超过AirPods刚发布的前四年，仅次于Apple Watch。</p><p>Vision Pro能否迎来爆发时刻还有待时间验证，Vision Pro虽然只是硬件，但其背后是个巨大的生态产业链，涉及到创新性技术、创新性材料、创新性内容生态等等，现阶段Vision Pro仍难撕小众标签，要想实现真正的爆发更是任重而道远。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkwMDUwNzEwNA==&amp;mid=2247601825&amp;idx=1&amp;sn=aa07a8e5983e58677921d4f2f9867654&amp;chksm=c1a103736379e81ee6cdcef7ad76eec14ce90985fe5d6bd80b2c53abdad901a89a743d0fda8a&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“DoNews”（ID：ilovedonews）</a>，作者：张宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653661270671619</id>
            <title>一个Sora，着什么急？</title>
            <link>https://www.36kr.com/p/2653661270671619</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653661270671619</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>嗯，这两天被技术刷屏了。</strong></p><p>你看到了吗？&nbsp;</p><p>Open AI和去年一样，大过年出来炸街， <strong>推出一门“文生视频”（Text-to-Video Generation）的技术，还给它起个名字，叫Sora</strong> ；我英文不好，索性叫它「索拉」。&nbsp;</p><p>它的能力，相信你也一目共睹，有关内容网络上也有不少，我也比较好奇，打开自己ChatGPT账号看了下，还没有体验权限。&nbsp;</p><p>然后，我的朋友圈也有不少垂直领域专家、学者、创始人出来浅谈；有的说：厉害了，只要一段咒语就可以生成你想要的东西，如果不会写，交给AI让它帮你写。&nbsp;</p><p>不能体验视频，索性体验下指令魔法吧。我想制作一段品牌15秒的TVC，描述一个女人拿着某品牌牛奶的创意广告。&nbsp;</p><p><strong>找GPT试了下，它给的答案是：</strong></p><blockquote><p>在昏黄的晨光下，一位穿着轻盈夏装的女士，踏着柔软的草地，手中轻握一瓶光泽璀璨的品牌牛奶。她优雅地行走于一片盛开的野花之中，微风轻拂，牛奶瓶随着她的步伐轻轻摇曳，捕捉着阳光的每一次闪烁。&nbsp;</p><p>女士停下脚步，轻轻打开牛奶，将这纯净的液体倾倒入一个透明的高脚杯中，牛奶与晨光相遇，仿佛融入了大自然的清新之中。&nbsp;</p><p>画面缓缓推进，只见她轻抿一口牛奶，闭眼享受这份来自大自然的赠礼。画面定格在她满足的微笑上，随后是品牌标志缓缓显现，背景淡入一句温暖的标语：“从大自然到您的桌上。”&nbsp;</p><p>此刻，一切都显得如此纯净、宁静，仿佛时间在这一刻静止，留下的只有与自然的和谐共鸣。&nbsp;</p></blockquote><p>GPT-4的咒语，我用国产大模型KIMIChat试了下，也可以；用智谱AI，和其他大模型给出的答案，可能差点意思。&nbsp;</p><p>至于文案能生成什么样的创意视频，我不知道。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_aeb7d3ee088b437abede8c54ae44b1d2@000000_oswg844300oswg1080oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">●Pic©Open AI /sora官网‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍</p><p>当面对一项新技术、新软件出现时，我遵循一个简单的评估准则： <strong>是什么？有什么作用？怎么利用它？相较于宏观层面讨论，我更关注于个体、中小企业的应用。</strong></p><p>所以，遇到事情不要慌。&nbsp;</p><p>梳理一下，大家评价主要围绕7个维度扩散开来，分别是： <strong>技术创新、技术优势、技术细节、行业影响、伦理和安全担忧、市场反应、以及用户体验。</strong></p><p>这些东西真可以很快给中小企业（个体）带来革命吗？&nbsp;</p><p>我认为不会。为什么？&nbsp;</p><p><strong>首先，周期问题。</strong></p><p>技术存在上下游关系，一个新技术在国外已经开源、或者底层原理被公开供国内参考，那国内头部公司也要一定时间去适应。&nbsp;</p><p>等到头部公司将产品开发出来并推出市场后，无论中小公司商用、还是类似复刻GPT-4这样的收费模式，都存在周期，半年、一年，甚至更长，待考究。&nbsp;</p><p>想象一下：&nbsp;</p><p>京东、淘宝、抖音开发一套短视频生成技术，目的是帮商家弄出更拉风的广告视频，提高获客效率。&nbsp;</p><p>听起来很美好，理论上这玩意能让中小公司广告吸引力、卖货能力直线上升。但说实话，中小公司可能一开始对这事儿不怎么上心。&nbsp;</p><p>最先尝试并广泛应用这项技术的，是提供软件即服务（SaaS）的B端公司，尤其是专注于市场营销技术（MarTech）的企业。&nbsp;</p><p>因为，这些公司可以用这门技术，为客户提供定制化广告，而且营销领域，投入产出比（ROI）是每个人都极为关注的指标。&nbsp;</p><p><strong>所以，只有当技术被证明能够制作出更逼真的虚拟内容，提高获客效率，并且仿真技术足够强大时，中小公司可能才真正开始广泛采用。</strong></p><p>换句话说，技术一开始得经历一番磨合期，证明自己真能给生意带来实在好处，才能被更多人接受和用上，它可以瞬间爆发，但并非快速普世。&nbsp;</p><p><strong>其次，技术实用性。</strong></p><p>文生视频，目前还是帮大家创造一些虚拟世界的东西，如同前几年被吹爆的元宇宙。&nbsp;</p><p>人们衣食住行终归要回到实体中来，现在能源、食物生产，气候调节、光合作用、生物节律、环境系统大部分还依赖于太阳，除非哪天能造出人造太阳，否则生活方式不会有太大变化。&nbsp;</p><p>从根本上说，人类最终目标是生存、繁衍，这些刻在基因中，Sora目前无法推进到治疗疾病、提高粮食生产，带动经济等重要问题上。&nbsp;</p><p>那么，文生视频就具有想象空间，就目前来说，还停留在提供娱乐工具、增加点流量、广告点击层面，属于互联网吸引力再分配。&nbsp;</p><p><strong>再者，虚拟离不开现实。</strong></p><p>Sora能造出个假的世界，可以做到增强现实，甚至未来带上苹果眼罩Apple Vision Pro看的更仿真，但假世界，始终按照我们对真世界的理解来造，它和真正世界是有区别。&nbsp;</p><p>比如说：&nbsp;</p><p>真实世界有些科学现象，有量子力学定律，牛顿运动定律、热力学定律、进化论、板块构造论....假的世界是造不出来的。&nbsp;</p><p>所以，假世界，是简化版真世界，顶多在娱乐方面让我们放松下，对了解真实世界没太大帮助，时间长了，还会让你活在幻想中。&nbsp;</p><p>昨天看到一个段子，朋友说：&nbsp;</p><p>如果将来90%用户，在抖音上浏览的90%内容是AI生成的，他们还浑然不觉，这会是个怎样的世界呢？还听到个笑话：现在视频创作者用AI出视频大纲，拍完视频后，观众又用AI来总结视频的精华点。&nbsp;</p><p><strong>嗯，很有意思，耐人寻味。</strong></p><p>不得不说，大小模型的确提高了生产效率，也代替了不少简单的工作，但对一个社会运行、35岁再就业，似乎没那么被需要。&nbsp;</p><p>企业用AI来替代人干活，看起来效率提高了，如果他们不给员工培训新技能，就相当于把人从社会里踢出去了， <strong>省下的点钱，最后可能因为社会问题又得花出去。</strong></p><p>想想看：&nbsp;</p><p>有个员工，每天在仓库盘点货品，活很简单，自己很有存在感；突然有一天，老板说，我要用技术迭代你们，弄一个库存工具，一切自动化。&nbsp;</p><p>于是，这位员工没了工作。他试图找新工作，但发现自己技能已经跟不上时代了，慢慢地开始感到沮丧和无力。&nbsp;</p><p>最后，情绪不仅影响到本人，也会影响到同事、家庭，造成一个连锁反应，最终，公司会发现，为了提高效率而节省下来的成本，实际转化成社会成本，增加了更多负面影响。&nbsp;</p><p><strong>因此：Sora很好，但替代不了人。它是一个工具，工具离不开与人共处，不必焦虑，还有很长的路......。‍</strong></p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzU5ODMyNDEyNw==&amp;mid=2247498304&amp;idx=1&amp;sn=3f8afbe553f420c86a4016eaef1a0365&amp;chksm=ffff47b6bed279a02cbb2a6bfed47c5d658ebd3c16a901292ae276e8939ec2869f7f2c846b34&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“王智远”（ID：Z201440）</a>，作者：王智远，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653630408081670</id>
            <title>只修改一个关键参数，就会毁了整个百亿参数大模型？</title>
            <link>https://www.36kr.com/p/2653630408081670</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653630408081670</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:23:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>【导读】在当今人工智能领域，AI&nbsp;模型以卓越的语言理解和生成能力重塑了我们对智能交互的认知。然而，在其卓越表现的背后，隐藏着诸多尚未充分挖掘的关键因素。本文将分享大语言模型训练过程中产生的多种独特现象，推导在二阶段预训练时如何巧妙平衡数据量与背景知识的注入，从理论与实践的角度揭示其内在运作机制，深入剖析语言核心区与维度依赖理论的作用及其带来的深刻影响。</p><p>本文精选自《新程序员&nbsp;007：大模型时代的开发者》，《新程序员 007》聚焦开发者成长，其间既有图灵奖得主 Joseph Sifakis、前 OpenAI 科学家 Joel Lehman 等高瞻远瞩，又有对于开发者们至关重要的成长路径、工程实践及趟坑经验等，欢迎大家点击订阅年卡。</p><p>自然语言处理领域存在着一个非常有趣的现象：在多语言模型中，不同的语言之间似乎存在着一种隐含的对齐关系。复旦&nbsp;NLP&nbsp;团队在早期便开始做了一些相关的工作，于&nbsp;2022&nbsp;年发布了一篇关于&nbsp;Multilingual BERT&nbsp;的分析[1]，随后团队持续进行对大语言模型内语言对齐机制、语言与知识结构之间内在联系的深入研究，并在&nbsp;AAAI 2024&nbsp;提交了一份研究报告，提出了关于大语言模型中语言对齐部分的若干猜想。基于这些研究成果，本文将分享一些大语言模型中语言和知识分离的现象。</p><h2><strong>现象 1：mBERT 模型的跨语言迁移</strong></h2><p>2022 年开始，我们发现 Multilingual BERT 是一个经过大规模跨语言训练验证的模型实例，其展示出了优异的跨语言迁移能力。具体表现为，<strong>该模型能够在某单一语言环境下训练完成一个部分后，可以非常容易地成功迁移到其他语言环境中执行任务。</strong>这一现象不禁令人思考：模型中是否存在某种特定的部分？为了探索这种多语言对齐的现象，研究采用了 Prompt 搜索方法对模型逐层分析（见图 1），针对每种语言的每一层网络及各个&nbsp;head（全称&nbsp;attention-head，BERT&nbsp;的基本组成模块）单元进行了细致研究，旨在考察它们对语法分类任务的执行能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_6082caaad8ac4a23a8fd90599e312afa@000000_oswg295317oswg1080oswg683_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 1&nbsp;mBERT 不同层恢复各类语言语法关系的准确性</p><p>在针对多语言样本的测试中，我们选取了每种语言不同层次的部分 head 进行测试，评估它们在语法关系预测任务上的表现。实验结果显示了一个较为显著的现象：<strong>在大规模预训练过程中，即使未注入任何显式的语法先验知识，模型依然能够在语法结构层面展现出良好的对齐特性，并能在不同层次间保持一定的精度一致性。</strong>这一趋势在大多数语言中尤为突出，但在某些特殊或较少使用的语言中则不甚明显。&nbsp;</p><p>通过对多种不同语法现象的预测比较，研究着重对比了英语与西班牙语、英语与日语之间的差异。在第 7 层网络的语法关系可视化中，数据显示亲缘性较高的语言，其预测位置更为接近且分布趋于均匀。而像英语与日语这样差异较大的语言，部分语法成分的预测位置相对集中（见图 2），未能有效区分开来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_0b3a62f54a0f444e8a373f6627b0b0d1@000000_oswg405307oswg1080oswg474_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 2&nbsp;mBERT 第 7 层的不同语法关系表示的可视化</p><p>接下来我们发现了更为不寻常的现象：当针对特定任务对模型进行微调（Fine-tune）时，比如运用 Multilingual BERT 进行任务倾向性分析或命名实体识别等任务的微调后，模型在处理语法成分的对齐关系及区分边界的表现会得到显著提升（见图 3）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3797c198e32442c09e4fb928bb9b520a@000000_oswg449183oswg1080oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 3 在进行任务 Fine-Tune 之后，聚合对齐更加明显</p><p>在未经微调的原始模型中，其内部蕴含了大量的语法预测信息，这些预测主要聚集在模型的中间层级，混合度比较高。但在执行相应的任务预测微调之后，这些预测分布会变得更为清晰、更具独立性。基于这一现象，可以合理推测 Multilingual BERT 模型上<strong>用单一语言微调特定任务后，其学习到的能力能够快速迁移到其他语言</strong>的原因。</p><h2><strong>现象 2：大语言模型同样存在显著的语言对齐</strong></h2><p>鉴于我们已经在上述 2022 年的研究中做了相关工作，并揭示了 Multilingual BERT 中的语言对齐现象，那么在大语言模型上面，除了 decoder-only 结构的设计改进外，剩下的就是模型的宽度和深度拓展。此现象在 Multilingual BERT 中的存在，自然引起了我们<strong>对大语言模型内部语言对齐和语法-语义对齐特性的探究。</strong></p><p>为了更深入地解释这一问题，我们首先在&nbsp;2023&nbsp;年&nbsp;EMNLP&nbsp;发表了一篇论文[2]，不仅在原始 Multilingual BERT 上进行了相应的分析工作，还在 LLaMa 模型上复现了这一现象。研究采用了一系列额外的语言评价指标，诸如 RSA 等，以期望获得更全面和准确的结论。研究结果表明，该现象在大语言模型上面与 Multilingual BERT 非常类似（见图&nbsp;4）。若按照先前提出的分层逻辑，模型在语法层面展现出明显的对齐性，这与我们早期的研究结果高度一致。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3a26eb9fad79442bab2e96d52a433e5d@000000_oswg156886oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 4&nbsp;语言直接在句法关系上具有很强的对齐性</p><p>其次，我们探索了将 Multilingual BERT 上的迁移工作应用到更大规模的语言模型上。具体来说，我们在词性标注任务（POS tag, Parts-of-speech tagging）上设计了一种特殊的方法（见图 5）。在面对单个语言的小规模数据集时，我们选取了若干位置，无须任何标注数据，直接使用 Multilingual BERT 的迁移方式，从而在多语言环境中获得了优秀的标注效果。举例来说，即使缺乏阿拉伯语的标注数据集，仅拥有英语和法语的数据集，也能成功地迁移到其他语言环境。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d4f77af220a04d5da3467f4b91f6bacf@000000_oswg145654oswg1080oswg456_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;5&nbsp;词性标注任务，可以通过跨语言训练得到非常高的结果</p><p>所以，<strong>在大语言模型当中也依然存在这种语言对齐现象</strong>。模型已成功实现了词形（单词形式，word form）与中间层语义表示、语法表示之间的转换，脱离了原有的词形，这一转换使得模型能够去处理别的任务。</p><p>通过前面的分析和工作，我们得出结论，大语言模型在多语言预训练阶段确实有效地实现了不同语言间语义层面上的对齐。我们认为，相较于可能不太重要的形式层面，语义层面的一致性可能是关键所在。一旦语义层面实现统一，理论上可以直接应对多种相关的下游任务。为了验证这一猜想，我们进一步开展了一系列研究工作。</p><h2><strong>现象 3：知识与语言分离</strong></h2><p>以下是我们投稿至&nbsp;AAAI 2024&nbsp;的论文[3]。假设语义层面已经实现了很好的对齐，那么词汇形式的具体表达的重要性便会相应大幅削弱。为此，我们深入探究了如何从&nbsp;LLaMa&nbsp;模型出发，将其语言能力迁移至其他小型语种的过程中，即便面对词形的变化，模型内部已经具备一层进行语义转换的能力。</p><p>从以英语为主的训练语言转向中文或任何其他语言时，实际上的转换需求就仅限于形式上的改变。通常，将 LLaMA 扩展为小语言需要经历三步（见图&nbsp;6）：<strong>第一步是词表扩展</strong>（Vocabulary Extension）；<strong>第二步是继续预训练</strong>（Further Pre-training）；<strong>第三步是任务添加，所以需要使用 SFT</strong>（Supervised Fine-Tuning）<strong>数据</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1010661847044f3cb06471204133c7fa@000000_oswg220056oswg1080oswg650_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;6&nbsp;将英文 LLaMA 扩展为其他语言</p><p>为了更清晰地理解这一过程，我们将其分解为三种形式进行观察。第一种形式是完全不改动词表，直接进行继续预训练和指令微调。第二种形式只进行词表扩展，而不进行其他操作。第三种形式则完全省略前两步，直接使用大量的 SFT 数据进行训练。</p><p>基于这些设定，我们进行了对比实验。首先，直接使用 LLaMA 或 LLaMA 2 进行 SFT 训练，观察使用经过词料扩展和大规模负责培训后的效果，例如 Chinese LLaMA、Chinese LLaMA 2 和我们实验室开源的 Open Chinese LLaMA（经过 200b 数据训练）。此外，我们还测试了不进行词表扩展，直接使用 100k 和 1m 数据对中文语料进行 SFT 训练的情况。</p><p>由于评测的目的是模型生成能力，所以我们使用了能提供生成式问答题目的 LLMEVAL 评测方式，基于模型生成数据的正确性、信息量、流畅性、逻辑性等部分，分别用 GPT-4 进行打分，结果如下（见图 7）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_560e9c43d0f7473a925c348a80a11a02@000000_oswg447715oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;7&nbsp;Token 扩展会导致原始信息丢失，需要大量训练才能恢复</p><p>因此，以 Chinese LLaMA 为例，恢复信息需要达到 200 倍以上的二次预训练数据，这会大幅增加训练成本。如果使用需求是让 token 的生成速度变快，我们认为依旧可以扩展词表。反之，若对生成速度没有特别大的需求，如 LLaMA 根据 UTF-8 编码生成可能需要 2 ~ 3 个 token 才能产生一个汉字，在只追求生成质量的情况下，直接进行大量中文的 SFT 数据训练，就已经可以实现非常好的处理效果。也就是说，<strong>词形和语义在语言层面已经进行了分离，提供其中文能力并不需要特别大量的数据训练</strong>。在 SFT 非常少量时，大规模的二次预训练可以加快模型对于指令的响应学习，但当 SFT 数据量扩展到 950k 之后，再去增加中文的二次预训练数据其实并没有什么特别的意义，例如在 950k SFT 的情况下，LLaMA 对比经过 1M 中文二次预训练的 LLaMA 模型，效果并没有大幅度的变化。</p><p>这也是我们之后在语言解释工作上的基础：<strong>语言的词形消失，知识和语言被分离，加入少量的中文数据无法在知识层面提升模型能力</strong>。基于这种思考，我们开始了新的评测（见图 8），其中蓝色的部分是 LLaMA-7b 模型，粉红色的部分是 LLaMA-2-7B 模型，绿色的部分是 LLaMA-13B 模型。我们希望借此看看，在经过大量的训练之后，模型的知识层面会产生哪些变化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_c12d04b6db054c95915403e0d44e5cb2@000000_oswg58081oswg1080oswg481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;8&nbsp;使用中文进行二次预训练并不能在知识层面提升模型能力</p><p>在经过 C-Eval、GAOKAO-Bench、MMLU 和 AGIEval 等基准评测之后，观察到大量未经针对性优化的预训练模型并未显著提升其内在的知识掌握程度，反而在某些情况下相较于原始 LLaMA 模型有所下滑。这主要是由于目前普遍采用的中文语料库训练数据规模有限，进而制约了模型在语言理解和生成方面的性能表现，导致了此类评测结果的出现。因此，如何有效地开展针对中文环境的第二阶段预训练亟需更多思考。单纯依赖现有方法，并不能充分反映出模型在特定中文领域知识的进步。值得注意的是，<strong>仅在现有的通用模型中融入少量涵盖世界知识或是物理、化学、数学等领域专业知识的中文数据，是没有太大意义的</strong>。</p><p>在其他语言中，我们也做了类似的工作（见图 9）。研究选了十几种语言，每种语言都用相应的 SFT 数据进行训练和测试，观察发现数据达到一定量级，如 65k SFT 之后，都处于相对可用的版本。但因为这些 SFT 数据有一部分是机器翻译的，不如中文直接使用的效果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_e17f503052c146889c525fa49c4ab432@000000_oswg365128oswg1080oswg493_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;9&nbsp;在其他低资源语言中表现类似</p><h2><strong>现象 4：语义和词形对齐</strong></h2><p>训练过程中，我们发现了一些有趣的现象，也可以从一定程度上说明这种语义和词形对齐的关系。例如，用 95k 的 SFT 对某些进行训练，并将早前的一些 checkpoint（在训练过程中不同时间点保存的模型版本）打印出来，并询问以下问题（见图&nbsp;10）：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_c840aa333ce74e15a62663111f0f60bf@000000_oswg141936oswg1080oswg214_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;10&nbsp;训练过程中非常明显的 Coding-Switch（语码转换）现象</p><p>模型在响应查询时，输出的部分内容以红色和蓝色标示。我们观察到，模型能够在保持语义连贯正确的前提下，自动插入其他语言的词汇，而且这些词汇与前面的内容衔接自然流畅，仿佛原本就应该属于同一句话。这就从某种程度上表明，<strong>模型在内部实现了语义与词形的解耦，即模型有能力在维持语义完整性的同时，灵活处理不同语言的词形表达</strong>，引证了我们前文中的一些猜想。我们做了十几种语言，每种语言都出现了一定比例的 Coding-Switch 现象，所以这并不仅仅是中文特有的个例。</p><h2><strong>现象 5：少量的数据就能影响整个大模型</strong></h2><p>基于上述发现，我们开始深入思考。除了之前观察到的这些现象之外，其实在大语言模型的训练过程当中还有很多别的现象，比如“毛刺”（见图&nbsp;11），即“噪音”（Noise）。在进行大规模预训练时，我们自身也进行了 30b 和 50b 参数级别的模型预训练，同样发现了类似情况。每当遇到这些噪音数据，我们的解决办法通常是回溯，回滚到出现问题的预训练阶段，检查那一阶段的数据。多数情况下，我们发现是由预训练数据所引起的，这部分有问题的数据会导致模型的 PPL（perplexity）值急剧升高。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_b3a05b394c0349988cf3b6a1d4d574c6@000000_oswg182564oswg1080oswg757_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;11&nbsp;“毛刺”</p><p>为何少量的数据会对如此大规模的模型造成如此严重的影响呢？OpenAI 和 Anthropic 在他们的论文[4][5]中均对此有所涉及，他们在研究 SFT 和预训练相关课题时，大多得出类似的结论：<strong>模型进行两三轮的微调通常就已经接近最优状态，过多的训练轮次往往会导致模型性能下降</strong>。这一结论在我们自身的实验中均得到了印证。</p><p>在传统训练流程中，我们可能对某部分数据训练 30 轮或 50 轮，即便数据质量不高，也只是导致这部分训练效果不佳。然而，在大语言模型上，当我们引入少量 SFT 数据并进行六轮甚至十轮微调时，整个模型的能力却可能会急剧下降，且在 SFT 数据上的表现也并未改善。这究竟是什么原因呢？这一系列疑问驱使我们去探寻深层次的答案，促使我们开始想要打开黑盒，去对它做更进一步的解释和分析。</p><p>以前，想对人脑的认知功能进行深入分析是很难的，因为直接观测和测量人脑各区域的功能是不可行，同时现代伦理准则也严格约束了对动物（如猴子）进行复杂神经科学实验的可能性。例如，我看过一则关于剥夺猴子视觉社交刺激的研究引发争议，因其可能对动物造成不可逆的影响。</p><p>在人工智能领域，BERT 模型的出现虽然为语言处理带来了重大突破，但其智能程度相对有限，且结构和动态行为相对易于分析。随着大语言模型的发展，尤其是参数量庞大的预训练模型，它们展现了更高水平的智能表现，同时也带来了新的挑战——<strong>模型的内部工作机理更加复杂且难以直观理解</strong>。那怎么办呢？我觉得不能像电视剧里刘华强说的那样，“给你机会还不中用”。既然有了机会，我们还是得把握住。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_2a2a04de61ea4240b49a50398c8e80e2@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>大语言模型参数中记录了知识有明显的语言核心区</strong></h2><p>经过先前的一系列分析，我们旨在探究这些现象如何具体表现在大型语言模型的参数结构中，并从参数当中研究出一些解释和情况。过去半年以来，我们不停地实验就是围绕这一目标展开。在某种程度上，这与人脑的功能分区原理相似——人脑中有专门的语言区及核心区，而在大语言模型中也可能存在着负责语言理解与知识表达的部分结构。现在有相当一部分共识，认为一部分知识存储和处理功能可能对应于模型中的<strong>前馈神经网络</strong>（Feedforward Neural Network, FFN）部分，尤其是其中的<strong>多层感知器</strong>（Multi-Layer Perceptron, MLP）组件。然而，目前我们的研究结果其实还比较初步，有些实验结论其实并不一定十分可靠。</p><p>研究中，<strong>我们认为大模型中明显存在着承载语言能力的核心区域</strong>。为什么会这么说？这一判断基于如下实验设计：首先，我们选取了六种语言，针对每种语言收集了约十万条未曾出现在 LLaMA 原始训练集中的文本数据，这些数据源自书籍并经由转换获取，出现重叠的概率较低。接下来，我们利用这些数据对 LLaMA 模型进行了二次预训练。</p><p>预训练完成后，我们对比了模型训练前后参数的变化情况，针对每种语言独立进行。首先对韩语进行预训练并记录参数变化，随后依次对俄语、越南语等其余语言进行相同操作。实验中，我们特别关注了权重变化最大的 1% 至 5% 的参数部分，因为直觉上人们通常认为权重变化较大的区域更为重要。经过四个月的研究，我们发现并非权重变化大的区域才最关键，相反，那些经过大规模预训练后变化很小的参数区域才是模型的核心稳定部分。</p><p>为验证这一点，我们进一步做了若干实验。我们发现<strong>有非常少数的参数在所有语言二次预训练中变化都很小</strong>（见图 12），无论在哪一层、哪个矩阵，都有一个显著的集中区域，其参数变化极其微小，在不同语言上的变化都非常有限。因此，我们将六种语言训练前后参数变化幅度累计起来，考察各个位置变化的综合程度，并挑选出变化最小的&nbsp;1%&nbsp;至 5%&nbsp;的参数。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_df640b4425684e00884ca83c8da5e025@000000_oswg167310oswg1080oswg557_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;12&nbsp;有非常少数的参数在所有语言二次预训练中变化都很小</p><p>把这部分参数拿出来之后，我们将这些变化极小的参数区域进行扰动实验。通过 7b 参数规模的模型，我们选取底层变化最小的 3%&nbsp;参数进行随机化处理，然后观察模型的 PPL 指标（见图&nbsp;13）。实验结果显示，当扰动这最小变化的 3% 参数时，PPL 值会显著上升；而如果我们从模型中随意选取 3% 的参数进行同样的扰动，PPL 虽会下降，但下降幅度并不明显。反之，如果我们对权重变化最大的那部分参数（同样取 3%）进行扰动，虽然 PPL 会比随机扰动稍高，但只要扰动那些变化最小的核心区域，PPL 值就会剧烈上升。同样，我们还尝试了仅扰动 1% 参数的情况，尽管变化幅度略有减小，但总体影响仍然较大，表现为几千到几万的增量。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_f861ff1c837947c385d1d2280bb88d58@000000_oswg137992oswg1080oswg407_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;13&nbsp;扰动核心区域在 130 种语言上 PPL 全都呈现爆炸趋势</p><p>如果用 13b 参数的模型重复上述工作，得到的结论是完全一致的（见图 14）。<strong>只要是变动这个区域 3% 的部分，整个模型语言能力基本上就会完全丧失掉了</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ddaeb91b0f4a452587d887d2f6ecae56@000000_oswg136068oswg1080oswg407_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;14&nbsp;LLaMA2-7B 和 13B 现象完全一样</p><p>语言能力区域非常重要，所以我们通过冻结它做了另一个实验（见图 15）。实验中，我们首先锁定了模型的语言核心区参数，并用中文知乎数据对该模型进行再训练。另一组对照实验则是不解冻核心区参数。通过在中文微信公众号和英文 Falcon 数据集各选取 1 万条样本计算 PPL，我们发现：若冻结语言核心区并用 5 万条中文知乎数据进行训练，模型的中文 PPL 可以恢复至约 7 左右，表明<strong>模型通过其他区域的参数补偿了语言能力；但英文能力在这种条件下无法恢复到先前的爆炸趋势中</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d99e4ee556cb44e79dc846645bae7c7d@000000_oswg128458oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;15 模型具备一定的“代偿”能力，可以使用中文数据训练以恢复中文能力</p><p>然而，如果仅扰乱而不冻结语言核心区参数，仅通过中文知乎数据训练，无论是中文&nbsp;PPL&nbsp;还是英文&nbsp;PPL&nbsp;都能恢复至接近原始模型的良好状态（见图 16）。<strong>因此，语言核心区的参数至关重要，且对模型能力的影响呈现出平滑而敏感的特点，只需几千条数据即可相对容易地恢复其原有功能</strong>。然而，一旦该区域被锁定，模型能力的恢复将变得困难，性能指标会出现显著变化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_0a3c19bf6a4a4ae0a918646bfe7a62f2@000000_oswg128849oswg1080oswg510_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;16 在语言区不锁定的情况下，仅训练中文，英文也能恢复一定能力</p><p>观察打印出的区域（见图 17），可以发现 QKVO 矩阵在维度上具有明显的集中现象，即主要集中在一小部分维度上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_8c8ee5dc392f48ea925939ff9df1dfd4@000000_oswg396970oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;17 QKVO矩阵都呈现维度集中现象</p><p>虽然&nbsp;MLP&nbsp;层没有那么明显的集中性，但在进一步放大查看后，发现在某些列上也存在显著的现象（见图&nbsp;18）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a52ea7989e0c407fa3076c4e20a4ced5@000000_oswg333156oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;18 FFN-UP &amp; Down某些维度上具有明显的列聚集现象</p><p>例如，在最后一层的&nbsp;mlp.down&nbsp;这个区域里面，少量维度尤其集中（见图&nbsp;19）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_dcdb0ea06b794ac694a615e5e09fde98@000000_oswg1108831oswg1080oswg1083_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;19 维度集中现象明显</p><p>基于此，我们进一步分析，这种维度集中性与 Layer Norm（层归一化，Layer normalization）中的单个维度扰动在计算上等效，于是我们尝试直接扰动 Layer Norm 中的单个维度。</p><p>实验结果显示，在 LLaMA 2-13B 模型中，如果仅扰动第一层的 input Layer Norm 2100 维度，将其随机化，模型的 PPL 值会由 5.877 突升至 21.42；若将该值乘以 10，PPL 值则更剧烈地增加到为 3 亿多（见图 20）。这表明尽管其他 Layer Norm 参数在理论上同样重要，但扰动它们并不会导致如此严重的性能崩溃。然而，<strong>对于这些特定维度，即便是微小的改动也会带来显著的性能变化</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ae483c672cd9468fa6eda339aecfa524@000000_oswg360654oswg1080oswg571_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;20 扰动实验</p><p>为了直观展示这种变化，我们用扰动后的模型进行句子补全任务，输入为“Fudan University is located in”（复旦大学位于……）。在正常状态下，LLaMA2-13B 模型能够输出高质量的结果，甚至可以处理中英混合，例如直接给出复旦大学官网的链接。然而，如果将 2100 维度的 Layer Norm 随机化，模型便开始出现知识错误和语言错误，生成的文本不再正确（见图 21）。但同等程度地扰动其他维度，模型的语言输出却不会出现较大变化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1c13cf217dde46b899bccd7e592e0ac4@000000_oswg421709oswg1080oswg578_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图&nbsp;21&nbsp;仅修改 130 亿参数中的 1 个就会使模型混乱</p><p>再回来看图 20，若将 2100 的维度乘以 10，模型的 PPL 值急剧增大，输出变得杂乱无章。可见，如果在这个特定位置（2100 维度）改动参数，整个语言模型的功能就会严重受损。当然，如果我们对其他位置的参数乘以 10，也会导致一些错误，比如模型可能会错误地将济南等地识别为复旦大学的校区。通过 PPL 指标，我们可以明显看出这些扰动对模型性能的具体影响，更何况未经扰动的 LLaMA2-13B 模型上本身也经不起多次尝试导致的错误。也就是说，<strong>130 亿参数的大模型只改一个参数，整个模型的语言能力就能完全归零</strong>。</p><h2><strong>大模型语言核心区与维度依赖理论</strong></h2><p>这些现象和理论能带来什么？其实我觉得它能在构建大模型时提供诸多有益的解释。以往我们的部分工作采用了一些技巧性的方法，尽管成效显著，但却难以阐明其内在机制。</p><p>首先，在进行二阶段预训练时，若目标是增强模型在特定领域（如医学或强化中文知识）的表现，而原始训练数据对该领域覆盖不足，传统的经验告诉我们，必须辅以大量相关背景知识的混合数据。例如，在开发 Open Chinese LLaMA 时，我们发现仅添加纯中文数据会导致模型性能大幅下降，而现在我们明白参数各个区域负责部分其实已经确定，如果大量增加某类在预训练时没有的知识，会造成参数的大幅度变化，造成整个语言模型能力损失。</p><p><strong>若要对特定分区进行调整，就必须引入与之相关的背景知识，添加 5 ~ 10 倍原始预训练中的数据，并打混后一起训练，这样才能让模型逐步适应变化</strong>。否则，一旦触及核心区域，模型将丧失几乎所有能力。</p><p>其次，大模型语言关键区域参数极为敏感，尤其是那些对模型性能至关重要的小区域。在 SFT 阶段，若训练周期过长，针对少量数据进行多个 EPOCH 的训练，会造成语言关键区域变化，导致 PPL 飙升，甚至整个模型失效。<strong>因此，与小模型不同，不能针对少量训练数据进行过度拟合</strong>。</p><p>第三，模型对于噪音数据的敏感性是众所周知的，但其背后的原因值得深挖。比如，预训练数据中如果出现大量连续的噪音数据，比如连续重复单词、非单词序列等，都可能造成特定维度的调整，从而使得模型整体&nbsp;PPL&nbsp;大幅度波动。</p><p>另外，有监督微调指令中如果有大量与原有大语言模型不匹配的指令片段，也可能造成模型调整特定维度，从而使得模型整体性能大幅度下降。我们可通过语言核心区和维度依赖理论来解释这一现象，这意味着<strong>在未来训练和&nbsp;SFT&nbsp;阶段，我们需要采取相应的策略进行精细化调整</strong>。</p><p>相关资料：</p><p>[1] Xu et al. Cross-Linguistic Syntactic Difference in Multilingual BERT: How Good is It and How Does It Affect Transfer? EMNLP 2022</p><p>[2] Xu et al. Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization, EMNLP 2023</p><p>[3] Zhao et al. LLaMA Beyond English: An Empirical Study on Language Capability Transfer. AAAI 2024 submitted</p><p>[4] Training language models to follow instructions with human feedback, OpenAI, 2022</p><p>[5] Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback, Anthropic, 2023</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2651004769&amp;idx=1&amp;sn=07167a1b9ab56a02d1a95be908ac0f69&amp;chksm=bc256fddb3fa9ee4f2dd081033c0bb247ea0866719367ed1530e1dfed1aa20ea22c5aa06f093&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“CSDN”（ID：CSDNnews）</a>，作者：张奇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653921166819593</id>
            <title>这些手机指纹识别技术，你正在用哪个？</title>
            <link>https://www.36kr.com/p/2653921166819593</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653921166819593</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:22:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>基于安全考量，每个人都会对手机设上一个专属于自己的密码。拿起手机，解锁，进入桌面，一气呵成。从输入密码到滑动图案，密码解锁的过程随技术迭代不断优化，体验也在不断升级。&nbsp;</p><p>时至今日，指纹解锁已经广泛普及到不同价位段的手机，而各家厂商宣传的超薄屏下指纹识别、屏幕超声波指纹、超声波3D广域指纹解锁等等听起来很厉害的技术，它们之间有什么区别？有没有哪一个是最好用的？我们接着往下看。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_5290e7734a7d4aa884b89249aecae09b@46958_oswg25052oswg690oswg596_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源微博@一加手机</p><p>从原理上来说，指纹识别技术本质上属于<strong>生物识别技术</strong>（biometrics）的一种，因其独特性、稳定性及便捷性等特点，被广泛应用于手机解锁、移动支付等多种场景，并随着技术的迭代而产生不同的类型。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1fd25ceba0a742d8b25a1245b7f814b3@46958_oswg53998oswg1080oswg662_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而手机实现指纹识别功能需要搭载指纹识别模块，指纹识别的工作过程通常分为三步：<strong>采集、处理和匹配</strong>。根据采集原理的不同，划分出了电容式、光学式和超声波式三种不同的指纹识别方式，目前各大手机厂商搭载的指纹识别技术均可归属于这三大类当中，我们逐一来解析。&nbsp;</p><h2><strong>电容式指纹识别</strong></h2><p>电容式指纹识别技术根据采集的方式可以进一步细分为刮擦式和按压式。&nbsp;</p><p>刮擦式类似于相机拍照，当手指在传感器表面滑动时，传感器对指纹进行“拍照”从而采集信息进行识别。就像拍照对手机防抖、光线和角度有要求一样，刮擦式指纹识别对手指滑动的速度和方向也都有较高要求，导致识别速度和精度较低，日常使用不便，因此已经被更先进易用的按压式指纹识别技术取代。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_c649f17d5fb8440dbf069a62f381ba11@46958_oswg67056oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Moto ME860：搭载刮擦式电容指纹识别模块</p><p><strong>按压式电容指纹识别</strong> 作为前者的优化方案，手指只需按压在传感器上，就能快速识别指纹，更易于操作。2013年，iPhone 5s问世，将正面按压式电容指纹识别和Touch ID结合，让大众消费者体验到了更好用更便捷的指纹识别，从而极大的推动了按压式指纹识别技术的普及和推广。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_4aaebb9a5c3a47c296bc194c0df70f16@46958_oswg79339oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">iPhone 5s：首款搭载正面按压式指纹识别手机</p><p>而随着手机屏幕占比越来越大，手机正面没有多余空间去容纳实体按键，按压式指纹识别逐渐由手机正面转向背面和侧面，从而逐渐出现使用后置指纹识别以及侧边指纹识别的手机。&nbsp;</p><p>而近些年来，厂商和消费者对于手机影像能力的追逐，让手机后置摄像头的尺寸不断扩张，后置指纹识别也逐渐消失，目前使用按压式指纹识别的手机<strong>主要以侧边识别为主</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_06d71cefef064400a743bbdad64bd662@46958_oswg36287oswg800oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">华为Mate7：首款支持后置指纹识别的Android手机</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ac63da7ac467453b9801d120b91b2419@46958_oswg28886oswg799oswg473_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">努比亚Z9尊享版：首款支持侧边指纹识别手机</p><h2><strong>光学式指纹识别</strong></h2><p>随着市场需求的演变，手机的发展趋势愈发明显：全面大屏、机身轻薄、外形美观。同时，手机屏幕也在经历一场由LCD向OLED的革新。在这变革之中，基于OLED屏幕的屏下指纹识别技术应运而生，为行业带来新的机遇。&nbsp;</p><p>该技术主要利用光反射原理，将指纹传感器巧妙地嵌入屏幕下方，手指按住对应屏幕识别区域即可解锁。相较于按压式指纹识别，用户不仅能享受到更强烈的科技体验，也进一步提升了手机的安全性与便捷性，让手机整体设计更加完整美观。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_73386672e5984ae6b1a8251a90e6eb70@46958_oswg29286oswg798oswg461_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">vivo X20 Plus屏幕指纹版：首款支持光学屏下指纹识别的量产手机</p><h2><strong>超声波式指纹识别</strong></h2><p>在2015世界移动通信大会（MWC 2015）上，高通正式推出移动行业首个基于超声波技术的3D指纹认证解决方案——<strong>Qualcomm Snapdragon Sense ID 3D指纹技术</strong>。&nbsp;</p><p>超声波指纹识别的工作原理是当手指按压屏幕，屏幕下的传感器就会向手指按压区域发射超声波，接触到指纹凹凸不平的沟壑时，超声波被吸收、穿透、反射的程度有差异，会产生不同能量的回波并被传感器接收，从而构建出3D指纹图像。&nbsp;</p><p>相较于光学指纹识别，超声波式指纹识别技术的优点包括穿透性更强，抗水渍、污渍干扰能力强，识别率高，支持活体检测，安全性较高。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_550c6912fe224ab4baa4d66d96b8fb93@46958_oswg57811oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">三星S10：首款屏下超声波指纹识别的手机</p><h2><strong>三种指纹识别种类区别</strong></h2><p>以上的三种指纹识别技术，区别还是挺大的，但都各有其优缺点。&nbsp;</p><p>电容式指纹发展时间更长，技术成熟完善，成本相对较低，目前主要为集成在电源键上的侧边指纹识别，因此被广泛应用于中低端和性价比机型，机型选择相对较少，同时集成式的设计可能会容易导致误触，湿手解锁体验不佳。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a404695878f4496388bc42e283805801@46958_oswg32046oswg809oswg544_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Redmi K40 Pro：搭载侧边指纹识别</p><p>而对于更加追求科技感和解锁体验的用户来说，光学指纹识别更加合适，得益于正面指纹识别的位置，在解锁时体验会更加舒适流畅，符合握持手机的姿态。&nbsp;</p><p>由于光学式指纹识别需要通过手指按压屏幕，屏幕发光照亮手指按压区域，从而识别出指纹，因此无法识别屏幕特定区域需要长期发亮，增加功耗，可能影响屏幕寿命，尤其是夜间解锁体验并不友好。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_2a45336e46284a67a6c9b26ac2305511@46958_oswg17506oswg537oswg474_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">一加12：超薄光学屏幕指纹</p><p>超声波指纹识别更适合需要高精度识别或者湿手触控的小伙伴，超声波式指纹识别速度快，抗水渍、污渍干扰能力强，识别率高，支持活体检测，安全性较高。&nbsp;</p><p>但是目前超声波指纹识别的技术并不成熟，造价高，因此通常搭载在旗舰机型上。基于超声波的特性，对于喜欢手机贴膜，尤其是钢化膜的用户来说，不得不放弃考虑，因为传统的钢化膜会极大影响超声波识别的速度和精度。&nbsp;</p><p>据爆料消息称，国产供应链目前已经实现超声波指纹识别技术突破，<strong>预计今年将会有搭载国产超声波式指纹识别技术的新机上市</strong>，对超声波式指纹识别感兴趣的小伙伴可以再等等。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3155a9658dda4a07960fea40ec465f6b@46958_oswg53584oswg895oswg654_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">iQOO8Pro：超声波3D广域指纹</p><h2><strong>写在最后</strong></h2><p>指纹识别技术相较于人脸识别和密码识别具有一定的优势。首先，指纹识别具有更高的唯一性和稳定性，因此安全性更高；其次，指纹识别不需要复杂的硬件设备，成本更低；最后，指纹识别更加便捷快速，用户无需输入密码或进行人脸对准等操作。&nbsp;</p><p>当然，文中介绍到的三种指纹识别技术都有其适用的场景和局限性，用户具体选择哪种类型，还需要考虑成本、耐久性、易用性等多个因素。所以，笔者也无法简单地说哪种指纹识别技术最好用，只能说<strong>根据不同的使用场景和需求选择最适合自己的更为重要</strong>。&nbsp;</p><p>相信在未来的发展中，随着技术的不断进步和应用场景的不断拓展，指纹识别技术也将会不断更新迭代，出现更加好用和便捷识别方式，让我们一起期待这一刻的到来！&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/TecysIEqskN0owCccHI00Q" rel="noopener noreferrer nofollow" target="_blank">“PConline太平洋科技”（ID:pconline_cn）</a>，作者：PC，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653748155108869</id>
            <title>跨越失望低谷，空间计算点燃元宇宙重生之火</title>
            <link>https://www.36kr.com/p/2653748155108869</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653748155108869</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:18:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>导读</strong></p><p>元宇宙经历“失望低谷期”，行业巨头正通过创新应用案例跨越理论与实用之间的鸿沟。</p><p>空间计算作为关键技术，构建三维沉浸式环境，打破现实与虚拟世界的界限。</p><p>苹果Vision Pro等设备展示了空间计算如何实现无缝混合现实体验，加速元宇宙从概念到实际应用的进程。</p><p>商业领域中，空间计算结合元宇宙理念被广泛采纳，如数字孪生和沉浸式购物，预示着Web 3.0时代的到来。</p><p>自2022年11月以来，生成式AI虽然占据新闻头条，但2024年将标志着空间计算崭露头角的时刻。</p><p>备受期待的苹果Vision Pro本月初已开始发货，其预售库存仅在18分钟内售罄，这预示着市场对新型数字体验的强烈需求。Meta、Magic Leap、索尼等硬件领军企业也在为新一代增强现实和虚拟现实应用设定发展路线图。这些企业不仅推动扩展现实与空间计算的发展，还从根本上改变我们连接、互动、消费和创造的方式，并为未来计算和工作场景奠定了新的舞台。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_163ae666b1f3486c92884bf972e824bd@813924438_oswg790199oswg1080oswg713_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随着空间计算新篇章的展开，人们不禁发问：这是“Web3D”的新纪元吗?它是否会取代元宇宙?</p><h2><strong>元宇宙转型期：穿越“失望低谷”，迎接创新应用</strong></h2><p>关于元宇宙，尽管该术语几乎在一夜之间从公众视野中消失，甚至有专家怀疑其概念或趋势是否已经消亡。然而，对于元宇宙终结的传言可能被过分夸大了。</p><p>Meta元宇宙部门副总裁Vishal Shah，作为下一代计算领域的关键领导者之一，认为是围绕元宇宙的炒作而非理念本身已经熄灭。他在接受国外《财富》杂志采访时提及Gartner的技术成熟度曲线，表示：“我们并非为了追求一时热度而投资，而是多年来一直在这一领域持续深耕。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_45ce3979fd054012bd507dc90603156b@813924438_oswg158496oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（GARTNER在2022年8月发布的区块链和 Web3 技术成熟度曲线）</p><p>当前，元宇宙似乎正处在技术成熟度曲线中的“失望低谷期”，这个阶段位于“过高期望峰值”和“启蒙上升期”之间，是任何新兴技术演进过程中必须经历的关键节点，意味着相关领导者需要超越初期的热情，开发实用且创新的应用实例来证明其实用性和驱动广泛采用。</p><h2><strong>空间计算：构建沉浸式体验的新基石</strong></h2><p>空间计算的兴起并不替代元宇宙的理念，反而可能是实现元宇宙承诺的关键途径。据苹果公司描述，其新款visionOS平台是一个无限的应用画布，突破传统显示器界限，引入全三维用户界面，通过最自然直观的输入方式——包括眼睛、手部动作和语音控制。在此背景下，我们可以将空间计算视为一座桥梁，引导我们走向三维沉浸式网络世界，由各种增强及虚拟现实应用和环境相互连接。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_5b3f379e3099405bb7d13de475e8ec3a@813924438_oswg865153oswg1060oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>苹果CEO蒂姆·库克曾指出：“增强现实是一项深远影响的技术。”通往沉浸式数字未来的起点在于混合型体验。在产品发布会上，苹果将Vision Pro定义为“一款开创性的空间计算机，能够无缝融合数字内容与物理世界”。</p><p>在苹果看来，其进化过程的一个逻辑步骤就是将实体世界和数字世界更紧密地结合在一起，最终摆脱对电脑、传统娱乐设备以及手机的依赖，创造出与周围世界全新的交互维度和层次。苹果Vision Pro正是加速并转变我们步入全新互联网时代的例证之一。最终，一个真正的元宇宙意味着彻底摆脱所有设备的束缚，无论它们是电脑、手机还是头戴式设备。</p><h2><strong>从概念到实践：元宇宙与空间计算交汇的未来形态</strong></h2><p>探讨空间计算与元宇宙之间的交汇之处，实际上没有人能确切预测元宇宙将如何演变，但我们将会见证向着某种真正跨越现实与虚拟边界的形态发展的进程。比如，在2023年末，马克·扎克伯格以逼真的化身形式出现在播客主持人兼计算机科学家Lex Fridman的节目中，展示了由Meta自家技术驱动的实时互动功能。当时，两位嘉宾仿佛置身同一房间般交流互动，Meta的逼真化身利用空间音频技术传达情感，成功跨越了“恐怖谷效应”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a1e271e22b2b46b9844b4c64f0696af1@813924438_oswg301931oswg1080oswg545_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>值得注意的是，节目开场时，Fridman提到这次对话是在元宇宙内部进行的。或许元宇宙的起源故事及其早期定义已不再准确反映当下对“元宇宙”一词的理解。在某些圈子中，元宇宙的概念已演化为“虚拟世界”。扎克伯格本人将元宇宙描绘成一个不同于手机或电脑的空间，在那里人们可以与他人在一个共享环境中共同完成事情。</p><p>扎克伯格解释说：“我认为我们将朝着拥有类似普通眼镜的设备的方向前进，这种设备不仅可以让我们看到物理世界，还能展示全息影像。在不远的将来，也许到本世纪末，当你步入一个房间时，那里的全息影像数量可能会与实物对象一样多。”</p><p>空间计算正在铺就通向增强现实的道路。Nike公司元宇宙工程总监Andrew Schwartz在X平台上发表的一篇文章中分享了他的观点，将空间计算视为连接元宇宙的一种桥梁。</p><p>他提出：“如果说互联网的组织原则是信息希望被分享，而元宇宙的组织原则是信息希望被体验，那么空间计算就提供了创建这些体验所需的各种工具。”</p><h2><strong>商业领域的空间计算探索与实践</strong></h2><p>企业高管面临的挑战是超越表面炒作，携手创新者共同勾勒出计算和互联网本身的下一章。富有远见的领导者已经在积极投资，确保不失去与社群建立联系的机会，提升相关知识与经验，并了解培育品牌、服务和商业机会的新方法。最近，Ralph Lauren首席执行官Patrice Louvet将元宇宙和可持续性列为吸引Z世代群体的两大核心投资领域。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ab66862f1aaf40cd8a9b3ab2a60b7d83@813924438_oswg103766oswg382oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（路易威登展示了由 Threekit 创建的 3D 数字资产）</p><p>在接受彭博社采访时，Louvet表示：“我们在投资元宇宙，因为我们需要到达消费者所在的地方。‘那就是他们希望与我们这样的品牌互动的地方。’”</p><p>目前已有多个追随Ralph Lauren脚步的成功案例，致力于开发具有潜力的虚拟世界和体验项目。例如，Threekit帮助品牌制作3D和增强现实资产，解锁名为“视觉商务”的沉浸式购物体验。Obsess则帮助企业将传统的二维电子商务网站转型为完全沉浸式的3D商店，让顾客能够虚拟漫游购物环境。家具零售商Serendipity在美国佛罗里达州海滩上创建了一个虚拟入口，让消费者可以在虚拟快闪展厅中漫步后随时返回海滩。同时，德勤也预见了企业级应用在这一领域的新机遇。</p><p>数字孪生技术已经可以模拟真实世界资产的表现，测试新特性和场景，识别故障率以及评估与其他智能设备的交互性能。运用AI和私有的大型语言模型，数字孪生还可以模拟客户和买家角色以及市场反馈情况。空间模拟技术使得企业能够在实际建设之前复制现有设施或设计新模式，从而评估和优化性能、瓶颈、故障率，并针对不同的流程和条件进行验证试验。</p><p>NVIDIA AI和Omniverse借助生成式AI创建协同运作的元宇宙环境，在其中，车辆原型、内饰、道路、高速公路和自动驾驶的实际驾驶场景的虚拟再现有助于团队加快设计进度、提高安全性并缩短上市时间。此外，NVIDIA和Omniverse利用AI技术打造制造工厂和配送中心的数字孪生体，以便全天候设计和优化工作流程，无需购买设备或建造实体设施。随后，合成数据可用于部署新设计、工作流程并在现实世界中更新训练AI模型。</p><p>德勤的一项研究显示，92%的制造商已经开始尝试或实施至少一种与元宇宙相关的应用场景，平均每个厂商运行超过6种此类应用。正如德勤所描述的那样，“与全尺寸数字孪生体进行最佳交互的方式是通过AR技术，它可以在物理世界之上叠加一层数字内容，形成一个共享的三维沉浸式互联网环境。”</p><h2><strong>元宇宙新声观点</strong></h2><p>空间计算已正式进入我们的生活。类似于元宇宙的世界已经开始为消费者、企业和商业应用打开新的大门，引领我们迈向Web 3.0或Web 3D时代。不论如何称呼，下一代网络将是空间化和沉浸式的，连接起数字与实体空间，并已在如火如荼地建设之中。</p><p>空间计算、扩展现实技术以及(按照无限可扩展互操作世界的定义)元宇宙将在根本上重塑运营、研发、客户和员工体验，乃至整个市场的格局。在个人层面，智能手机模糊了我们对数字与物理世界边界的感知。然而，多数人尚未体验过沉浸式3D网络所带来的变革。不过，这一变革即将到来。无论是怎样的未来景象，都不会凭空出现，而是因像您一样的人们构想、创造和接纳，才得以逐渐成形。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ubU_ZJEOWILUQo9odgrUzw" rel="noopener noreferrer nofollow" target="_blank">“元宇宙新声”（ID:NFTMall）</a>，作者：王秦州，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653735656799366</id>
            <title>后Sora时代，CV从业者如何选择模型？卷积还是ViT，监督学习还是CLIP范式</title>
            <link>https://www.36kr.com/p/2653735656799366</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653735656799366</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:17:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote><p>如何衡量一个视觉模型？又如何选择适合自己需求的视觉模型？MBZUAI和Meta的研究者给出了答案。&nbsp;</p></blockquote><p>一直以来，ImageNet 准确率是评估模型性能的主要指标，也是它最初点燃了深度学习革命的火种。但对于今天的计算视觉领域来说，这一指标正变得越来越不「够用」。&nbsp;</p><p>因为计算机视觉模型已变得越来越复杂，从早期的 ConvNets 到 Vision Transformers，可用模型的种类已大幅增加。同样，训练范式也从 ImageNet 上的监督训练发展到自监督学习和像 CLIP 这样的图像 - 文本对训练。&nbsp;</p><p>ImageNet 并不能捕捉到不同架构、训练范式和数据所产生的细微差别。如果仅根据 ImageNet 准确率来判断，具有不同属性的模型可能看起来很相似。当模型开始过度拟合 ImageNet 的特异性并使准确率达到饱和时，这种局限性就会变得更加明显。&nbsp;</p><p>CLIP 就是个值得一提的例子：尽管 CLIP 的 ImageNet 准确率与 ResNet 相似，但其视觉编码器的稳健性和可迁移性要好得多。这引发了对 CLIP 独特优势的探索和研究，如果当时仅从 ImageNet 指标来看，这些优势并不明显。这表明，分析其他属性有助于发现有用的模型。&nbsp;</p><p>此外，传统的基准并不能完全反映模型处理真实世界视觉挑战的能力，例如不同的相机姿势、光照条件或遮挡物。例如，在 ImageNet 等数据集上训练的模型往往很难将其性能应用到现实世界的应用中，因为现实世界的条件和场景更加多样化。&nbsp;</p><p>这些问题，为领域内的从业者带来了新的困惑：如何衡量一个视觉模型？又如何选择适合自己需求的视觉模型？&nbsp;</p><p>在最近的一篇论文中，MBZUAI 和 Meta 的研究者对这一问题开展了深入讨论。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_b5c82ac78c4a46af8cde2cf993af66e9@46958_oswg23884oswg1080oswg210_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文标题：ConvNet vs Transformer, Supervised vs CLIP:Beyond ImageNet Accuracy</p><p>论文链接：https://arxiv.org/pdf/2311.09215.pdf</p><p>论文聚焦 ImageNet 准确性之外的模型行为，分析了计算机视觉领域的四个主要模型：分别在监督和 CLIP 训练范式下的 ConvNeXt（作为 ConvNet 的代表）和 Vision Transformer (ViT) 。&nbsp;</p><p>所选模型的参数数量相似，且在每种训练范式下对 ImageNet-1K 的准确率几乎相同，确保了比较的公平性。研究者深入探讨了一系列模型特性，如预测误差类型、泛化能力、习得表征的不变性、校准等，重点关注了模型在没有额外训练或微调的情况下表现出的特性，为希望直接使用预训练模型的从业人员提供了参考。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_918c14060be04fff890e060865550553@46958_oswg409897oswg1080oswg791_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在分析中，研究者发现不同架构和训练范式的模型行为存在很大差异。例如，模型在 CLIP 范式下训练的分类错误少于在 ImageNet 上训练。不过，监督模型的校准效果更好，在 ImageNet 稳健性基准测试中普遍更胜一筹。ConvNeXt 在合成数据上有优势，但比 ViT 更偏重纹理。同时，有监督的 ConvNeXt 在许多基准测试中表现出色，其可迁移性表现与 CLIP 模型相当。&nbsp;</p><p>可以看出，各种模型以独特的方式展现了自己的优势，而这些优势是单一指标无法捕捉到的。研究者强调，需要更详细的评估指标来准确选择特定情境下的模型，并创建与 ImageNet 无关的新基准。&nbsp;</p><p>基于这些观察，Meta AI 首席科学家 Yann LeCun 转发了这项研究并点赞：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1ccc5111cf5840bc95bc979677c14254@46958_oswg164732oswg1080oswg392_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>模型选择</strong></h2><p>对于监督模型，研究者使用了 ViT 的预训练 DeiT3- Base/16，它与 ViT-Base/16 架构相同，但训练方法有所改进；此外还使用了 ConvNeXt-Base。对于 CLIP 模型，研究者使用了 OpenCLIP 中 ViT-Base/16 和 ConvNeXt-Base 的视觉编码器。&nbsp;</p><p>请注意，这些模型的性能与最初的 OpenAI 模型略有不同。所有模型检查点都可以在 GitHub 项目主页中找到。详细的模型比较见表 1：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_f0eb61f538674485a6e84bff7bf3fa38@46958_oswg45262oswg1080oswg213_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于模型的选择过程，研究者做出了详细解释：&nbsp;</p><p>1、由于研究者使用的是预训练模型，因此无法控制训练期间所见数据样本的数量和质量。</p><p>2、为了分析 ConvNets 和 Transformers，之前的许多研究都对 ResNet 和 ViT 进行了比较。这种比较通常对 ConvNet 不利，因为 ViT 通常采用更先进的配方进行训练，能达到更高的 ImageNet 准确率。ViT 还有一些架构设计元素，例如 LayerNorm，这些元素在多年前 ResNet 被发明时并没有纳入其中。因此，为了进行更平衡的评估，研究者将 ViT 与 ConvNeXt 进行了比较，后者是 ConvNet 的现代代表，其性能与 Transformers 相当，并共享了许多设计。</p><p>3、在训练模式方面，研究者对比了监督模式和 CLIP 模式。监督模型在计算机视觉领域一直保持着最先进的性能。另一方面，CLIP 模型在泛化和可迁移性方面表现出色，并提供了连接视觉和语言表征的特性。</p><p>4、由于自监督模型在初步测试中表现出与监督模型类似的行为，因此未被纳入结果中。这可能是由于它们最终在 ImageNet-1K 上进行了有监督的微调，而这会影响到许多特性的研究。</p><p>接下来，我们看下研究者如何对不同的属性进行了分析。&nbsp;</p><h2><strong>分析</strong></h2><p><strong>模型错误</strong></p><p>ImageNet-X 是一个对 ImageNet-1K 进行扩展的数据集，其中包含对 16 个变化因素的详细人工注释，可对图像分类中的模型错误进行深入分析。它采用错误比例度量（越低越好）来量化模型在特定因素上相对于整体准确性的表现，从而对模型错误进行细致入微的分析。ImageNet-X 的结果表明：&nbsp;</p><p>1. 相对于监督模型，CLIP 模型在 ImageNet 准确性方面犯的错误更少。</p><p>2. 所有模型都主要受到遮挡等复杂因素的影响。</p><p>3. 纹理是所有模型中最具挑战性的因素。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_c682799a794345acae6bde5746b44c15@46958_oswg163174oswg1080oswg591_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>形状 / 纹理偏差</strong></p><p>形状 - 纹理偏差会检测模型是否依赖于脆弱的纹理捷径，而不是高级形状线索。这种偏差可以通过结合不同类别的形状和纹理的线索冲突图像来研究。这种方法有助于了解，与纹理相比，模型的决策在多大程度上是基于形状的。研究者对线索冲突数据集上的形状 - 纹理偏差进行了评估，发现 CLIP 模型的纹理偏差小于监督模型，而 ViT 模型的形状偏差高于 ConvNets。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_b05a7910a172400fa86e697f9921f02b@46958_oswg292414oswg1080oswg683_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>模型校准</strong></p><p>校准可量化模型的预测置信度与其实际准确度是否一致，可以通过预期校准误差 (ECE) 等指标以及可靠性图和置信度直方图等可视化工具进行评估。研究者在 ImageNet-1K 和 ImageNet-R 上对校准进行了评估，将预测分为 15 个等级。在实验中，研究者观察到以下几点：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_c9cd7d669712404291a8cec73e86ef75@46958_oswg321127oswg1080oswg804_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>1. CLIP 模型过于自信，而监督模型则略显不足。</p><p>2. 有监督的 ConvNeXt 比有监督的 ViT 校准效果更好。</p><p><strong>稳健性和可迁移性</strong></p><p>模型的稳健性和可迁移性对于适应数据分布变化和新任务至关重要。研究者使用各种 ImageNet 变体对稳健性进行了评估，结果发现，虽然 ViT 和 ConvNeXt 模型的平均性能相当，但除 ImageNet-R 和 ImageNet-Sketch 外，有监督模型在稳健性方面普遍优于 CLIP。在可迁移性方面，通过使用 19 个数据集的 VTAB 基准进行评估，有监督的 ConvNeXt 优于 ViT，几乎与 CLIP 模型的性能相当。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d3c868cf483c4efb9563c7f7244fcba7@46958_oswg292245oswg1080oswg681_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>合成数据</strong></p><p>PUG-ImageNet 等合成数据集可以精确控制摄像机角度和纹理等因素，是一种很有前景的研究路径，因此研究者分析了模型在合成数据上的性能。PUG-ImageNet 包含逼真的 ImageNet 图像，姿态和光照等因素存在系统性变化，性能以绝对 top-1 准确率为衡量标准。研究者提供了 PUG-ImageNet 中不同因素的结果，发现 ConvNeXt 在几乎所有因素上都优于 ViT。这表明 ConvNeXt 在合成数据上优于 ViT，而 CLIP 模型的差距较小，因为 CLIP 模型的准确率低于监督模型，这可能与原始 ImageNet 的准确率较低有关。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_9859c4f87a284d248306cf80d0256ad1@46958_oswg110896oswg1080oswg431_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>变换不变性</strong></p><p>变换不变性是指模型能够产生一致的表征，不受输入变换的影响从而保留语义，如缩放或移动。这一特性使模型能够在不同但语义相似的输入中很好地泛化。研究者使用的方法包括调整图像大小以实现比例不变性，移动 crops 以实现位置不变性，以及使用插值位置嵌入调整 ViT 模型的分辨率。&nbsp;</p><p>他们在 ImageNet-1K 上通过改变 crop 比例 / 位置和图像分辨率来评估比例、移动和分辨率的不变性。在有监督的训练中，ConvNeXt 的表现优于 ViT。总体而言，模型对规模 / 分辨率变换的稳健性高于对移动的稳健性。对于需要对缩放、位移和分辨率具有较高稳健性的应用，结果表明有监督的 ConvNeXt 可能是最佳选择。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_313a029cad534e878fcd50336c00b043@46958_oswg207426oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>总结</strong></h2><p>总体来说，每种模型都有自己独特的优势。这表明模型的选择应取决于目标用例，因为标准性能指标可能会忽略特定任务的关键细微差别。此外，许多现有的基准都来自于 ImageNet，这也会使评估产生偏差。开发具有不同数据分布的新基准对于在更具现实世界代表性的环境中评估模型至关重要。&nbsp;</p><p>以下是本文结论的概括：&nbsp;</p><p><strong>ConvNet 与 Transformer</strong></p><p>1. 在许多基准上，有监督 ConvNeXt 的性能都优于有监督 ViT：它的校准效果更好，对数据转换的不变性更高，并表现出更好的可迁移性和稳健性。</p><p>2. ConvNeXt 在合成数据上的表现优于 ViT。</p><p>3. ViT 的形状偏差更大。</p><p><strong>监督与 CLIP</strong></p><p>1. 尽管 CLIP 模型在可转移性方面更胜一筹，但有监督的 ConvNeXt 在这项任务中表现出了竞争力。这展示了有监督模型的潜力。&nbsp;</p><p>2. 有监督模型在稳健性基准方面表现更好，这可能是因为这些模型都是 ImageNet 变体。&nbsp;</p><p>3. CLIP 模型的形状偏差更大，与 ImageNet 的准确性相比，分类错误更少。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_EmdQhrfkBBfeanSmXALsw" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID:almosthuman2014）</a>，编辑：蛋酱，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653760774963460</id>
            <title>乐视收购失败的电视品牌Vizio，要被沃尔玛20亿买下了</title>
            <link>https://www.36kr.com/p/2653760774963460</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653760774963460</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:13:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d8d4940fa488439ba70f0d7e99b3c661@46958_oswg91608oswg700oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：unsplash</p><p>据《华尔街日报》报道，零售巨头沃尔玛正在洽谈收购美国电视制造商Vizio，知情人士称这项交易将超过20亿美元，此举将为沃尔玛提供更多销售广告和向消费者推销商品的渠道。</p><p>20亿美元的价格，与2016年乐视收购Vizio时的金额一致。2016年，由华人企业家王蔚创办的Vizio已成为美国销量第一的液晶电视品牌，还推出了PC和平板电脑产品。</p><p>乐视在当年7月宣布，将以20亿美元收购Vizio并借此打入美国市场。但到2017年4月，乐视突然宣布放弃此次收购，Vizio则将其告上法庭，起诉称“乐视希望通过收购Vizio制造财务健康、积极扩张业务的假象”，并且试图诱导Vizio提供机密的客户信息。此外，双方合同曾约定1亿美元的合约终止费用，而收购失败后，Vizio仅收到4000万美元。该诉讼后来由两家公司于2018年11月以未公开的条款达成和解。</p><p>如今的Vizio已停止生产电脑及平板产品，主要产品是智能电视与条形音箱。2021年，公司登陆纽交所，股票代码VZIO。</p><p>消息发布后，Vizio股价在近五天上涨了25%，由7.42美元/股涨至目前的9.53美元/股，公司总市值18.79亿元。</p><p>沃尔玛，包括其山姆会员连锁店，一直以来是Vizio的最大客户，而Vizio历来也是沃尔玛销售量最大的电视品牌。</p><p>Vizio财报显示，公司主营业务分为设备与平台+，后者指其智能电视平台SmartCast。截至2023年9月30日的九个月，公司营业收入为11.77亿美元，同比下滑11.43%；净利润1500万美元，同比扭亏，上年同期为净亏损670万美元；公司拥有的现金及现金等价物为2.16亿美元。用户数据方面，当期SmartCast平台活跃账户1790万，每用户平均收入为31.55美元，同比增长14%。</p><p>市场份额方面，来自数据机构statista的数据显示，2022年，Vizio在北美智能电视市场份额为5%，排名第六，第1-3名是三星、索尼与LG。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_2cb7a3f37bb7469fbeb2f4c25b4c3ff5@46958_oswg246039oswg700oswg475_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2022年北美电视市场份额，来源：statista</p><p>此外，开源证券今年1月末发布的美国彩电市场实探报告显示，在沃尔玛、山姆会员店等零售渠道，Vizio属于中小尺寸、低价电视畅销品牌。在线上的亚马逊渠道，近两年里，Vizio的份额徘徊在5%-10%左右，排名第四。</p><p>目前这项收购尚不确定。尽管沃尔玛可以借助Vizio获得新的广告渠道，但沃尔玛已有一个定位相似的自有品牌ONN——ONN同样主打性价比，旗下有电视、音箱、平板等大量消费电子产品。若收购完成，Vizio与ONN的关系也将成为沃尔玛需解决的问题。</p><p>本文来自<a href="https://www.jiemian.com/article/10805744.html" rel="noopener noreferrer nofollow" target="_blank">“界面新闻”</a>，记者：徐诗琪，编辑：徐诗琪，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653770472586376</id>
            <title>vivo“登顶”印度，一步之遥？</title>
            <link>https://www.36kr.com/p/2653770472586376</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653770472586376</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:11:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_2b477384310b49289c736be78e78413d@000000_oswg308684oswg987oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>印度，一直是中国手机品牌的必争之地。</p><p>日前，Counterpoint Research发布的最新数据显示，2023年印度智能手机出货量为1.52亿部，与2022年持平，其中vivo成为增长最快的头部玩家，市场份额从15.8%涨至17%，与排名第一的三星仅有1%的差距。</p><p>这意味着，vivo向“印度一哥”之位发起冲击。</p><p>入“印”十年，vivo的日子过得到底怎么样？挑战三星，vivo胜算几何？问鼎“印度一哥”之路，vivo还将面临哪些挑战？</p><h2><strong>印度，vivo出海的“第一站”</strong></h2><p>据“人民网”报道，早在2014年，vivo创始人、总裁兼首席执行官沈炜亲自带队考察印度，考察团里除了vivo的高管外，还有与vivo合作的国内代理商，代理商们每到一处便和自己所负责代理的国内片区进行比照，凡是相似点较多的，就划为在印度拓展业务的区域。</p><p><strong>之所以如此，与印度举足轻重的市场地位息息相关。</strong></p><p>2023年4月，印度人口达到14.26亿人，一举成为世界人口第一大国，高基数之下顺势晋升为全球第二大智能手机市场。</p><p>更为重要的是，印度的潜力不可估量。</p><p>作为重要的新兴市场，印度的经济增长强劲，其财政部预计到2027年有望超过日本和德国成为世界第三大经济体，届时其GDP将达到5万亿美元，从而释放更大的消费潜力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_989b714fe17340d69eed7d3857f9953d@000000_oswg39734oswg1027oswg459_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：中经数据</p><p>一名互联网观察人士告诉锌刻度：“中国企业早就预判了商机，不管是之前的‘中华酷联’，还是之后的‘华米OV’都纷纷涌向印度，谁也不愿意错过这块‘肥肉’。”</p><p>此背景下，三星首当其冲。</p><p>虽然，三星多年称霸印度智能手机市场，可市场份额却逐年缩水，2015年尚有30%的市场份额，2023年已降至18%，颓势肉眼可见。</p><p>与之对应的是，中国手机品牌崛起。</p><p>这其中，<strong>vivo并不是走得最快的一个，却稳打稳扎前行，不声不响逼近三星，大有取而代之的势头。</strong></p><p>关于此，从其业绩也可见一斑。</p><blockquote><p>据公开数据显示，vivo印度公司2023财年的销售收入为2987.49亿卢比，同比增长了9%，而净利润为21.1亿卢比，成功扭亏为盈；2016年4月1日至2023年3月31日，销售收入累计为1.4万亿卢比，净利润累计为38.7亿卢比。&nbsp;</p></blockquote><p>需要注意的是，印度之外，vivo也在东南亚扎根站稳脚跟，成为马来西亚、印度尼西亚等国家智能手机市场排名前三的常客。</p><h2><strong>生根，比落地更难</strong></h2><p>vivo之所以起势，与本土化息息相关。</p><p>众所周知，出海容易落地难，比落地更难的是生根，这意味着要付出更多的智慧和心血，这是出海企业必须解决的棘手问题。</p><p>对此，vivo给出的解题思路是“More Local,More Global”。</p><p><strong>入印之初，vivo的打法就与主流有所不同，没有采取门槛更低的合作方式，而是独自建厂、带领经销商铺设门店、从上至下聘用本土人才，以求更好地服务本土消费者。</strong></p><blockquote><p>据印度相关媒体报道，vivo的“印度制造”拟投入750亿卢比，按照计划2023年完成第一阶段350亿卢比投资，而当第二阶段投资完成之后，智能手机生产规模将接近其在中国的规模，并成为在印度投资最多的手机品牌之一，与韩国三星电子不相上下。</p></blockquote><p>如此一来，vivo的竞争力也有了差异化。</p><p>对手们更侧重于线上，而vivo则更侧重于线下，其在印度拥有约7万家门店，90%销售通过线下渠道完成。</p><p>换而言之，其触角已深入印度的“神经末梢”。</p><p>更为关键的是，vivo精准迎合本土消费者，成功抢占经济型高端市场，才有了2023年的逆势增长。</p><p>Counterpoint Research的高级分析师瓦伦・米什拉：“智能手机市场的消费者购买模式发生了转变，消费者愿意花更多钱购买高质量的设备，以便延长使用寿命。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_db1feaaa569245f6a5a14004730fa8fd@000000_oswg111381oswg742oswg432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">高端手机逆势增长</p><p>通俗易懂地说，<strong>印度中产阶级的不断壮大，中高端消费市场也愈发兴旺，成为智能手机品牌的必争之地。</strong></p><p>问题在于，中印两国的国情不同。</p><p>以2023年第三季度为例，中国手机市场智能手机均价为3480元，而印度市场为195美元，约1400元上下，即便如此也创了印度智能手机均价的历史新高。</p><p>一名业内人士告诉锌刻度：“高端化与经济性往往是对立的，可越来越多的印度消费者既渴望性能优异，又对价格敏感，vivo抓住了这个矛盾点，进而获得更多用户的青睐。”</p><p>譬如，在拓展高端客群方面，vivo没有盲目押注最新的旗舰机，而是抓住印度中产阶级的实际需求差异，围绕设计、影像、系统与性能，重点在线上推出T系列、在线下推出V29机型，双双成为销售的关键增长点。</p><p>vivo中央研究院院长胡柏山曾表示：“经营本质要求就是要跟踪用户需求变化，所以用户导向是企业一切的根本出发点，而创新也必然从用户导向出，只有这样企业才有生命力。”</p><p>不难看出，<strong>高端化成为智能手机行业的共识，但在不同国家不同地区高端化的内涵是不一样的，不能盲目套用“药方”。</strong></p><p>从这个角度来看，2024年向三星发起挑战，vivo是有底气的。</p><h2><strong>竞争，又微妙起来</strong></h2><p>三星之外，vivo问鼎“印度一哥”之路还有其他挑战。</p><p><strong>一方面，小米重新起势。</strong></p><p>印度也是小米出海的“第一站”，好巧不巧同样是2014年起意的，可谓英雄所见略同，不过小米走得更快一些，早在2016年营业收入就超过10亿美元，一举成为印度最快创造该纪录的公司。</p><p>而三星，也曾是小米的“手下败将”。</p><p>2018年至2021年，小米一直是印度智能手机行业的“一哥”，如若不是2022年遭遇“黑天鹅”，也轮不到三星称王。</p><p>事实上，近年来印度频频“刁难”，外企无不噤如寒蝉。</p><p>为了破局，小米印度选择加码投资，并雇佣更多店员以增加就业机会，计划2024年底较2023年初增加两倍达到1.2万人，“经过多年对在线电商的大力押注后，小米将专注于提高印度零售店等线下渠道的销售额，以寻求重振智能手机销售。”</p><p>战略调整之后，小米显露了王者归来的迹象。</p><p>2023年第四季度，在印度智能手机市场，小米、vivo、三星的市场占有率分别为18.3%、17.3%、16.8%，竞争格局又微妙了起来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_206de329b4f24c32b25c20710c5bb9b8@000000_oswg39251oswg730oswg411_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Counterpoint Research</p><p><strong>另外一方面，荣耀重返印度市场。</strong></p><p>随着荣耀元气复苏，扩张成为其关键词，遂进入更多海外市场：2023年上半年荣耀欧洲地区部出货量增长超过130%，中东非地区部出货量增长超130%，拉美地区部出货量增长超230%；其中，2023年前5个月的海外销量已经超过2022年全年的海外销量，预计2023年海外销量增长130%以上。</p><p>印度，自然也在荣耀的考虑之中。</p><p>有外媒报道，其计划2024年第一季度至第三季度在印度本土生产手机，并占据印度智能手机市场5%的销量份额。</p><p>随着新玩家的入局，印度智能手机市场更卷了，也存在分流的压力。</p><p>总而言之，<strong>印度市场既充满机遇也有不少挑战，2024年vivo全年反超三星悬念或不大，但小米等对手不容小觑，未来鹿死谁手尚犹未可知。</strong></p><p>但可以确定的是，打铁唯有自身硬。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg3MDEwODYzMg==&amp;mid=2247512503&amp;idx=1&amp;sn=8618928a941d4001fa93920087e1c397&amp;chksm=cf61ece210e8fa2e5481161a9353d8aa92c24bfe5f565a32e9558cb2443e0db30bbccd8ac08d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“锌刻度”（ID：znkedu）</a>，作者：陈邓新，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653771456400904</id>
            <title>Sam Altman新布局：AI生活助手Shelpful获2100万元投资，将如何改变日常生活？</title>
            <link>https://www.36kr.com/p/2653771456400904</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653771456400904</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 11:07:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>“元宇宙的开拓者”</strong>是我们针对元宇宙的发展而设立的专栏，主要面向那些深挖元宇宙产业或者在元宇宙进行“淘金”的从业者，分享这些企业或者创业者们的故事，以独特的视角窥见那些引领全球元宇宙发展的企业或个人，我们深信元宇宙的大幕已经拉开，引领未来20年的科技互联网已经走上了时代浪潮。<strong>Sam Altman又投资人工智能公司了，这次是哪个方向的？以下是我们的第63期内容，以下Enjoy。</strong></p><p><strong>Sam Altman又双叒投资了一家人工智能（AI）初创企业</strong>！</p><p>不过，这回他投的既不是能源项目也不是人工智能芯片等硬件产品，而是与我们日常生活息息相关的AI生活助手Shelpful。</p><p>据悉，<strong>Shelpful拿到了Apollo Projects风险投资基金的300万美元（约2100万人民币）种子轮投资</strong>，而该风投基金由Sam Altman和他的兄弟共同创立。</p><p>按照科技初创公司的标准，这笔投资并不是很大，但Sam Altman的参与显然提升了这家公司的知名度，<strong>那么它是如何赢得OpenAI首席执行官的青睐的呢</strong>？</p><h2><strong>01.Shelpful=Super+Helpful</strong></h2><p>这家总部位于美国波特兰的公司由CEO Sharon Pope、联创Lydia Swift以及曾在亚马逊的Alexa工作过的Chris Morse于2021年创立，<strong>旨在利用人工智能技术帮助人们管理自己的生活并追求自我提升项目</strong>。根据官网介绍，Shelpful的诞生源于CEO Sharon Pope的个人经历。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_bf51f214d2b04c33a7b8c4e5e2ed7754@5629480_oswg232541oswg600oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在疫情期间，Sharon Pope作为忙碌的职场母亲，需要完成多项日程，经常感到来自时间管理方面的调整，于是便萌生了设计一个私人助手来帮助自己安排日程的想法——Shelpful由此问世，而公司名称“Shelpful”的由来也很有深意。</p><p>当创始人之一（Sharon）第一次有了这项服务的想法时，她觉得自己需要立即创建这款生活助手。由于时间紧迫，她把自己名字的第一个字母（S）和这项服务的缩写（helpful）结合在了一起。</p><p>后来，<strong>“Shelpful”逐渐演变成了“Super+Helpful”的含义</strong>，这恰好也符合产品设计的初衷，即提供给用户一个Super（超级的）+Helpful（有帮助的）的“生活助理”。</p><p>如今，Shelpful的应用范围也更加广泛，可以完成提醒用户缴纳账单、按时服药、进行规律的体育锻炼等工作，帮助用户进行计划好的日程。</p><p>不过，令人疑惑的是，<strong>投资了众多行业大牛的Sam Altman是如何发现这家初创企业的</strong>？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ee24f9ca77e545c3a4a70604c6ee02d0@5629480_oswg595445oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>原来，在Shelpful成立两年后，创始人Pope在社交媒体上发布了关于它的信息，而这些信息恰好传到了曾与Pope一同在YC工作过的Altman那里。</p><p>Sam Altman一直致力于利用人工智能技术增强人类能力、推动创新，而Shelpful的设计理念与Sam Altman的人工智能愿景不谋而合，合作就此达成。不过，除了行业大佬的加持，Shelpful公司的产品本身也极具价值。</p><h2><strong>02.科技与情感的完美融合</strong></h2><p>在科技高速发展的今天，人工智能已经渗透到我们生活的方方面面。然而，单纯的科技驱动并不能满足我们对于产品体验的所有需求。</p><p>Shelpful深谙此道，<strong>致力于将人工智能与人性化的服务相结合</strong>，为用户带来全新的产品体验。其核心产品集合了三种类型的服务，正是这一理念的完美体现。</p><h3><strong>HabitGPT</strong></h3><p><strong>HabitGPT是一款贴心的人性化智能助手</strong>。通过深度学习用户的习惯和需求，能够为用户提供个性化的改善建议。无论是健身、饮食还是睡眠，HabitGPT都能根据用户的实际情况提供科学、合理的指导。</p><p>当你因为工作繁忙而忽略健康饮食的时候，HabitGPT会根据你日常的饮食习惯，为你量身定制一个健康的食谱。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_876fa69cc7414c438bbc8f0f0a1ef5ca@5629480_oswg115586oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>它也会根据天气、季节等因素，为你推荐合适的运动方式。当你坚持一段时间后，HabitGPT还会为你分析数据，让你看到自己的进步和需要改进的地方。</p><h3><strong>Shelper</strong></h3><p><strong>Shelper则是一款集成了人工智能和人情味的专家</strong>。用户可以通过语音或文字与Shelper交流，获取各种生活服务信息。</p><p>除了安排日程、查询信息，Shelper能在用户需要时给予情感支持，提供难能可贵的“情绪价值”，成为用户生活中不可或缺的伙伴。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_fa97e34f80c5439e84c10260fbb32194@5629480_oswg578680oswg1080oswg531_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当你情绪不佳时，它能为你推荐合适的音乐、电影或者书籍，让你在烦躁的生活中找到片刻的宁静。</p><p>而当你需要倾诉时，Shelper会耐心倾听你的心声，给予你温暖的回应和建议。它就像一个知心朋友，时刻陪伴在你身边。</p><h3><strong>HabitGPT＋Shelper</strong></h3><p>如果你觉得HabitGPT与Shelper的单独使用体验难以满足你的需求，<strong>不妨将两者搭配起来使用</strong>。</p><p>比如，你可以在Shelper应用中设置自己的生活习惯目标，并同时获取到HabitGPT提供的个性化建议。</p><p>这样的组合使得用户不仅能够获得科学的指导，还能感受到温暖的人文关怀。</p><p>又或者，你在Shelper中设置了一个减肥目标，HabitGPT会为你同步提供个性化的饮食和运动建议。</p><p>你还可以在Shelper中设置其他的生活目标，比如学习一门新的语言，阅读更多的书籍，或者培养一项新的兴趣，HabitGPT会根据你的目标和喜好为你推荐合适的学习资源。</p><p>HabitGPT和Shelper的结合不仅可以帮助你养成良好的生活习惯，还可以帮你拓展视野，提升生活品质和幸福感。它们是私人教练，也是生活顾问，随时为你提供专业和贴心的服务和建议。</p><h2><strong>03.更注重培养和保持习惯</strong></h2><p>除了将科技与情感完美融合起来，<strong>Shelpful还藏着一个杀手锏——更加注重培养用户习惯，使其更好地生活。</strong></p><p><strong>生活习惯是一种看不见的力量，潜移默化地影响着每一个人</strong>。从长远来看，习惯甚至能够决定一个人的命运。一个人成功与否，往往取决于他的习惯是否良好，是否能够持之以恒地追求目标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_aff0f89f95884c03a742527f6136ed47@5629480_oswg166428oswg760oswg440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>而Shelpful的目标用户正是那些需要外部激励和组织帮助的人</strong>，以帮助他们养成和保持良好习惯。Shelpful总结发现，在他们的服务帮助下，早期成员通常可以一次成功养成3-4个习惯。</p><p>例如在改善健康方面，可以督促用户进行身体活动、正念饮食、按时服药等；在心态方面，会耐心指导用户积极获取自我肯定或学习励志名言；另外，在家庭护理方面，Shelpful也给用户提供了类似管家般的体验，从提醒清洁、关注电器安全，到照顾宠物等方方面面都为用户省去了大量规划时间。</p><p>因此，为更好地促进用户养成个人习惯，Shelpful还开设了两大特色板块——在官网提供了习惯生活指南和创建关于习惯的研讨会。</p><h3><strong>抢占现场研讨会</strong></h3><p>如今，无论是职场打工人还是需要照顾家庭的中老年人，多少对于时间安排和规划感到焦虑，毕竟并非人人都是“时间管理大师”。大多数人甚至每天过着两点一线的生活，想要改变什么，但内心却对于自己的生活习惯感到矛盾和不自在。</p><p>举个例子，有的人认为每天下班后做运动会有助于身体健康，但就算下定决心开始，最终却连30分钟都坚持不到；还有的人想利用碎片化时间多读书，但真正将其融入到日常生活中时，又会发现不能专注，并且生活的琐事会让读书这件事情变得更加混乱。</p><p>因此，<strong>Shelpful就这些困惑创建了一个现场研讨会</strong>，来告诉用户那些烦恼只是暂时的，养成好习惯也需要好的方法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_93b3c0b4ead54e3789eeb1783a2de5e5@5629480_oswg537941oswg1080oswg707_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了确保研讨会的专业性，<strong>Shelpful邀请了经过平台认证的习惯教练Sharon和Lydia进行指导</strong>。认证教练们在人类的行为、感知、思考方式等方面具备专业的知识，为参加研讨会的用户带来独家和定制化的习惯养成方法。</p><p>在研讨会的实时互动会话中，参与者大概会经历三个活动板块。</p><p>首先会根据BJ Fogg博士（世界知名行为科学家）的研究，学习习惯养成的基本工具。再与经过认证的习惯教练一起动手设计3个习惯，可以立即将制定的习惯付诸实践。最后，Shelpful将与用户保持深度联系，包括后续跟进方法反馈和提供个人指导资源，帮助用户持之以恒。</p><h3><strong>日常习惯小指南</strong></h3><p>不仅如此，<strong>Shelpful还在官网上提供许多培养小习惯的生活指南</strong>，帮助用户改善他们的日常生活并养成有益的习惯。习惯指南涉及到健康、学习、工作效率、时间管理等方面。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_39989348ed2247a5ae40b82547ad1418@5629480_oswg259134oswg539oswg701_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>官网持续更新指南，提供资源链接或建议读物</strong>，比如提供免费瑜伽和冥想视频的链接，提供专业健康知识文章，以帮助用户学习更多关于习惯养成和行为改变的知识。</p><p>鼓励用户从小步骤开始，例如，想要养成锻炼习惯的人可以从每天步行10分钟开始，想要做到保持房间整洁可以从养成每天整理的24个小习惯开始。</p><p>此外，以这种更新小指南的形式让用户进入官网后可以随时浏览，并且让用户能增加一些自主学习的潜意识，在潜移默化中学习更有利于生活习惯的培养和保持。</p><h2><strong>04.AI生活助手的未来期望</strong></h2><p>在这个忙碌且“内卷”的时代，Shelpful无疑被赋予了更多的使命，即支持每个人去追求、并坚持为自己的健康、幸福和自我保健培养重要的习惯。在遇到生活琐事的烦恼时，不少用户真真切切得到了帮助，培养并保持了有利于生活的好习惯。</p><p>谈到后续发展时，<strong>Shelpful的创始人表示将继续增强产品的AI功能</strong>，使其服务更智能、更快、更直观，同时与专业教练建立合作伙伴关系，以补充现有的教练服务。</p><p>尽管生成式人工智能的兴起以及一系列聊天机器人的出现正在改变数字助理的游戏规则，但是人类的习惯依然需要人类来创造和维持，Shelpful也将在未来继续保留真人团队，<strong>努力将人工智能与人情味融为一体</strong>。</p><p>本文来自微信公众号“元宇宙之心MetaverseHub”（ID:MetaverseHub），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653745507679363</id>
            <title>Sora背后团队：应届博士带队，00后入列，还专门招了艺术生</title>
            <link>https://www.36kr.com/p/2653745507679363</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653745507679363</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 10:34:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在世界上最受关注的技术团队是哪一支？</p><p><strong>Sora团队</strong>，已经来到聚光灯中心。</p><p>不仅项目负责人评论区被挤爆，成了𝕏最火“景点”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_05036d2e5d964c75b337f0a485d541d4@46958_oswg792747oswg956oswg728_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>天才成员们的履历，也正在持续引爆关注。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a1c84623baaf47e6a6506452ead9e2ab@46958_oswg92126oswg1080oswg369_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>大家伙发现，这支团队挺年轻：两位负责人都是在去年（2023年）刚刚博士毕业，团队里甚至还有00后选手……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_f7af4c10a8464afca6b590189b87c3b2@46958_oswg65776oswg1080oswg258_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但牛也是真的牛：</p><p><strong>Tim Brooks</strong>，DALL-E 3作者之一，GitHub 5.7k️项目InstructPix2Pix作者，2021-2022年在英伟达实习时，就是视频生成研究的项目负责人。</p><p><strong>William (Bill) Peebles</strong>，和谢赛宁合作，搞出了Sora的技术基础之一DiT（扩散Transformer）。论文还曾入围CVPR 2022最佳论文候选。</p><p>……</p><p>这支团队到底什么来头，咱们今天一起仔细聊聊。</p><h2><strong>应届博士带队</strong></h2><p>包括Tim和Bill在内，Sora的主要负责人一共有三名（以下排名不分先后）。</p><p><strong>Tim Brooks</strong>，也是DALL-E 3的作者，去年1月刚从加州大学伯克利分校博士毕业。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_9dd98d07e1364e9fa28ff815dcaf41c7@46958_oswg1481693oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Tim本科就读于卡内基梅隆大学，主修逻辑与计算，辅修计算机科学，其间在Facebook软件工程部门实习了四个月。</p><p>2017年，本科毕业的Tim先到Google工作了近两年，在Pixel手机部门中研究AI相机，之后到了伯克利AI实验室攻读博士。</p><p>在伯克利读博期间，Tim的主要研究方向就是图片与视频生成，他还在英伟达实习并主导了一项关于视频生成的研究。</p><p>回到校园后，Tim与导师Alexei Efros教授和同组博士后Aleksander Holynski（现在谷歌）一起研制了AI图片编辑工具InstructPix2Pix，并入选CVPR 2023 Highlight。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_41c5b016b9bf497aac5f8c4e9588fed5@46958_oswg80749oswg1080oswg389_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>去年一月，Tim顺利毕业并取得了博士学位，转而加入OpenAI，并相继参与了DALL-E 3和Sora的工作。</p><p>值得一提的是，Tim不仅在专业领域拥有高超的技术水平，还是个多才多艺的人。</p><p>据Tim自己介绍，他还喜欢摄影和音乐，高中时他拍摄的照片获得过National Geographic颁发的奖项，本人到过百老汇演出，还获得过B-box国际奖项……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_05fa4fa18d744bd9b0c0a7d74b28e0cb@46958_oswg52274oswg1080oswg194_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而与Tim师出同门、晚毕业4个月的<strong>William Peebles</strong>，也是Sora的另一名负责人。</p><p>（Peebles在𝕏上用昵称Bill，在Linkedin上及论文署名时用大名William，下文一律用Bill指代。）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3ff3c99144df498990a0ada8710fd993@46958_oswg1469524oswg1058oswg1199_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Bill本科就读于MIT，主修计算机科学，参加了GAN和text2video的研究，还在英伟达深度学习与自动驾驶团队实习，研究计算机视觉。</p><p>毕业后正式开始读博之前，他还参加了Adobe的暑期实习，研究的依然是GAN，该项目和（时任）卡内基梅隆大学华人学者朱俊彦（也是Efros教授学生，现在在MIT）组有合作，并成为CVPR 2022最佳论文候选。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_64e83b2977cf4d58ab7d916f9288bbfc@46958_oswg802813oswg1080oswg687_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>之后，学期开始，Bill到了伯克利Efros教授课题组攻读博士，研究成果多次入选SIGGRAPH、ICCV、CVPR等学术会议。</p><p>2022年5月，Bill到Meta进行了为期半年的实习，和谢赛宁（Bill开始实习时还未离开Meta）合作发表了DiT模型，首次将Transformer与扩散模型结合到了一起。</p><p>该成果被ICCV 2023录用为Oral论文。值得一提的是，OpenAI此次发布的Sora，被认为正是基于DiT构建的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_51a0dda3052d4bf6a1c4bbe8bbd8b090@46958_oswg1389287oswg1080oswg973_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>去年5月，Bill也从伯克利毕业，并入职OpenAI。</p><p>除了这两位去年加入的研究者，Sora团队的另一位负责人<strong>Aditya Ramesh</strong>则是OpenAI的“老人”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1e3e863e477c4427951893b305781df3@46958_oswg286723oswg750oswg501_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Aditya是DALL-E的创造者，主导了三代DALL-E的研究，三个版本的论文当中他都是共同一作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_8c73c48229bb431d938cb0dd4d1a4afc@46958_oswg128428oswg1080oswg1369_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而这样一位主导三代DALL-E，如今又领导Sora团队的大神，却只有本科学历。</p><p>据LeCun介绍，Aditya本科就读于纽约大学，并在他的实验室参与过一些项目。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_c253034298fe4308b82ab9df031f7970@46958_oswg162113oswg1080oswg442_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其间，Aditya就已经在研究生成式模型，并和LeCun共同发表论文。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_35460e98e4e7472abbd791958bacfe66@46958_oswg292791oswg1080oswg579_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>毕业之后，Aditya本想继续深造，但在OpenAI的暑期实习中被留了下来，成为了正式研究人员。</p><h2><strong>00后已加入</strong></h2><p>Sora团队的本科生，还不止Aditya Ramesh一位。</p><p>前文提到，这支团队中有一位“00后”<strong>Will DePue</strong>，就是2022年才刚从密西根大学计算机系本科毕业的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d11db98272f44703afb6d0761d76a5ab@46958_oswg394360oswg480oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这位小哥大四的时候创业搞了个市场咨询公司DeepResearch，这家公司后来被Commsor收购。</p><p>2023年7月，小哥加入OpenAI。根据他的领英信息，他是在今年1月才刚刚加入Sora项目组的。</p><p>另外，David Schnurr和Joe Taylor也都没有博士学位。前者毕业于加州大学圣塔芭芭拉分校，后者毕业于美国旧金山艺术大学。</p><p>而正如Aditya Ramesh自己所说，Sora团队的不少成员都是DALL-E 3的作者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_5b87eb5f360c43468c56070c2ee492b1@46958_oswg86536oswg936oswg324_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>包括两位华人Li Jing和Yufei Guo。</p><p>Li Jing是DALL-E 3的共同一作，2014年本科毕业于北京大学物理系，2019年获得MIT物理学博士学位。在Meta做了2年多博士后之后，Li Jing于2022年加入OpenAI。</p><p>华人作者中还有Ricky Wang，今年一月刚刚从Meta/Instagram跳槽到OpenAI，另外两位Yufei Guo、Clarence Ng没有太多公开资料。</p><p>新跳槽来的还有Conner Holmes，他在微软工作时以外援形式参与了DALL·E 3的推理优化工作，后来干脆加入OpenAI了。</p><p>最后，来看一眼完整作者名单：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_54008902d5c441528902be792ad66084@46958_oswg17659oswg650oswg538_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从团队的组建情况和研究基础来看，Sora应该是OpenAI近半年来的最新成果，而非网传“早已有之但憋着不发”。</p><p>不过，Sora炸场，顶级人才又持续星聚，还是惊得众人开始重新考量OpenAI的技术领先性。</p><p>就在今天，作者释出的Sora新作，连“同一场景”下的多机位视频都整出来了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_74df207304314077b1be4f0f19ebfd37@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>网友们的心情be like：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_07d3fc9315534c5eab9491249afa3573@46958_oswg602705oswg675oswg900_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在，是视频生成，下一个又会是什么？</p><p>参考链接：</p><p>[1]https://www.wpeebles.com/</p><p>[2]https://www.timothybrooks.com/about/</p><p>[3]http://adityaramesh.com/about.html</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ggST2FiiUN8AgCApKWIh4Q" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：克雷西 鱼羊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653735906296070</id>
            <title>让视觉语言模型搞空间推理，谷歌又整新活了</title>
            <link>https://www.36kr.com/p/2653735906296070</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653735906296070</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 10:33:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote><p>视觉语言模型虽然强大，但缺乏空间推理能力，最近 Google 的新论文说它的 SpatialVLM 可以做，看看他们是怎么做的。&nbsp;</p></blockquote><p>视觉语言模型 (VLM) 已经在广泛的任务上取得了显著进展，包括图像描述、视觉问答 (VQA)、具身规划、动作识别等等。然而大多数视觉语言模型在空间推理方面仍然存在一些困难，比如需要理解目标在三维空间中的位置或空间关系的任务。</p><p>关于这一问题，研究者们常常从「人类」身上获得启发：通过具身体验和进化发展，人类拥有固有的空间推理技能，可以毫不费力地确定空间关系，比如目标相对位置或估算距离和大小，而无需复杂的思维链或心理计算。</p><p>这种对直接空间推理任务的熟练，与当前视觉语言模型能力的局限形成鲜明对比，并引发了一个引人注目的研究问题：是否能够赋予视觉语言模型类似于人类的空间推理能力？</p><p>最近，谷歌提出了一种具备空间推理能力的视觉语言模型：SpatialVLM。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d8a97b8820204b3c9115b7cb0c52484f@46958_oswg121164oswg1080oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文标题：SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities</p><p>论文地址：https://arxiv.org/pdf/2401.12168.pdf</p><p>项目主页：https://spatial-vlm.github.io/</p><p>值得注意的是，研究者假设当前视觉语言模型在空间推理能力方面的限制并非源于其架构的局限，而更可能是由于在大规模训练时所使用的常见数据集的限制。例如，许多视觉语言模型是在以图像 - 描述对为特征的互联网规模数据集上进行训练的，这些数据集中包含的空间信息有限。存在限制的原因是获取富含空间信息的具身数据或 3D 感知查询的高质量人工注释比较困难，自动数据生成和增强技术是解决该问题的一种方法，然而很多之前的数据生成研究侧重于生成具有真实语义标注的照片逼真图像，忽略了对象和 3D 关系的丰富性。</p><p>与之相反，本文研究者专注于直接从现实世界数据中提取空间信息，以捕捉真实 3D 世界的多样性和复杂性。这一创新源自近期视觉模型方面在自动从 2D 图像中生成 3D 空间注释方面的进展。</p><p>SpatialVLM 系统可以实现数据生成和对视觉语言模型进行训练，以增强它们的空间推理能力。具体而言，研究者结合面向开放词汇的目标检测（open-vocabulary detection）、度量深度估计、语义分割和以目标为中心的描述模型，实现了在大规模地密集注释真实世界数据。SpatialVLM 将由视觉模型生成的数据转换成一种可用于描述、VQA 和空间推理数据的混合体上训练视觉语言模型的格式。</p><p>实验证明，本文训练的视觉语言模型表现出许多令人满意的能力。首先，它在回答定性空间问题方面的能力得到显著提升。其次，即使在有噪声的训练数据下，它也能可靠地进行定量估计。这种能力不仅使其具备关于目标大小的常识知识，还使其在重新排列任务的开放词汇奖励标注方面非常有用。第三，本文的空间视觉语言模型在自然语言界面的基础上，结合强大的大型语言模型，能够进行空间推理链以解决复杂的空间推理任务。</p><h2><strong>方法概览</strong></h2><p>为了使视觉语言模型具备定性和定量的空间推理能力，研究者提出生成一个大规模的空间 VQA 数据集用于训练视觉语言模型。具体而言，就是设计一个全面的数据生成框架，首先利用现成的计算机视觉模型，包括开放词汇检测、度量深度估计、语义分割和以目标为中心的描述模型，提取以目标为中心的背景信息，然后采用基于模板的方法生成质量合理的大规模空间 VQA 数据。本文中，研究者使用了生成的数据集训练 SpatialVLM，以学习直接的空间推理能力，然后将其与 LLMs 嵌入的高层常识推理相结合，解锁链式思维的空间推理。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_31e8fa8785a44cd1a82e018a3866dbe8@46958_oswg385663oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>2D 图像的空间基准</strong></p><p>研究者设计了一个生成包含空间推理问题的 VQA 数据的流程，具体流程如图 2 中所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d386a4fd45464fa7b11a84053e70b891@46958_oswg506135oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>1、语义过滤：在本文的数据合成流程中，第一步是采用基于 CLIP 的开放词汇分类模型对所有图像进行分类，排除不适合的图像。</p><p>2、2D 图像提取以目标为中心的背景：这一步获得由像素簇和开放词汇描述组成的以目标为中心的实体。</p><p>3、2D 背景信息到 3D 背景信息：经过深度估计，将单眼的 2D 像素提升到度量尺度的 3D 点云。本文是第一个将互联网规模的图像提升至以目标为中心的 3D 点云，并用其合成带有 3D 空间推理监督的 VQA 数据。</p><p>4、消除歧义：有时一张图像中可能有多个相似类别的目标，导致它们的描述标签存在歧义。因此，在询问关于这些目标的问题之前，需要确保参考表达不含有歧义。</p><p><strong>大规模空间推理 VQA 数据集</strong></p><p>研究者通过使用合成数据进行预训练，将「直观」的空间推理能力融入 VLM。因此，合成涉及图像中不超过两个目标（表示为 A 和 B）的空间推理问答对。这里主要考虑以下两类问题：</p><p>1、定性问题：询问某些空间关系的判断。例如「给定两个对象 A 和 B，哪个更靠左？」</p><p>2、定量问题：询问更精细的答案，包括数字和单位。例如「相对于对象 B，对象 A 向左多少？」、「对象 A 距离 B 有多远？」</p><p>此处，研究者指定了 38 种不同类型的定性和定量空间推理问题，每种问题包含大约 20 个问题模板和 10 个答案模板。</p><p>图 3 展示了本文获取的合成问答对的示例。研究者创建了一个包括 1000 万张图像和 20 亿个直接空间推理问答对 (50% 是定性问题，50% 是定量问题) 的庞大数据集。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3adc7a3ed39a4561add3c0face570430@46958_oswg436553oswg1080oswg635_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>学习空间推理</strong></p><p>直接空间推理：视觉语言模型接收图像 I 和关于空间任务的查询 Q 作为输入，并输出一个答案 A，并且以文本的格式呈现，无需使用外部工具或与其他大型模型进行交互。本文采用与 PaLM-E 相同的架构和训练流程，只是将 PaLM 的骨干替换为 PaLM 2-S。然后，使用原始 PaLM-E 数据集和作者的数据集的混合进行模型训练，其中有 5% 的 token 用于空间推理任务。</p><p>链式思维空间推理：SpatialVLM 提供了自然语言接口，可用于查询具有基础概念的问题，当与强大的 LLM 结合使用时，可以执行复杂的空间推理。</p><p>与 Socratic Models 和 LLM 协调器中的方法类似，本文利用 LLM (text-davinci-003) 来协调与 SpatialVLM 进行通信，以链式思维提示的方式解决复杂问题，如图 4 所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_9d52f99642734df0801830b67257563a@46958_oswg339593oswg1080oswg454_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>实验及结果</strong></h2><p>研究者通过实验证明并回答了如下的问题：</p><p>问题 1：本文设计的空间 VQA 数据生成和训练流程，是否提高了 VLM 的一般空间推理能力？以及它的表现如何？</p><p>问题 2：充满噪音数据的合成空间 VQA 数据和不同的训练策略，对学习性能有何影响？</p><p>问题 3：装备了「直接」空间推理能力的 VLM，是否能够解锁诸如链式思维推理和具身规划等新能力？</p><p>研究者通过使用 PaLM-E 训练集和本文设计的空间 VQA 数据集的混合来训练模型。为了验证 VLM 在空间推理上的局限是否是数据问题，他们选择了当前最先进的视觉语言模型作为基线。这些模型的训练过程中语义描述任务占据了相当的比重，而不是使用本文的空间 VQA 数据集进行训练。</p><p><strong>空间 VQA 表现</strong></p><p>定性空间 VQA。对于这一问题，人工注释的答案和 VLM 输出均为自由形式的自然语言。因此，为了评估 VLM 的性能，研究者使用人工评定员确定答案是否正确，表 1 中展示了各个 VLM 的成功率。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d6c8ff43c89c46fca619eb5b80a756ee@46958_oswg33505oswg1080oswg227_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>定量空间 VQA。如表 2 所示，本文的模型在两个指标上都比基线表现更好且遥遥领先。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_db3065b22b9843ba9cc4f88464ac73f9@46958_oswg50812oswg1080oswg269_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>空间 VQA 数据对通用 VQA 的影响</strong></p><p>第二个问题是，由于与大量的空间 VQA 数据共同训练，VLM 在其他任务上的表现是否会因此而降低。通过将本文模型与在通用 VQA 基准上没有使用空间 VQA 数据进行训练的基本 PaLM 2-E 进行了比较，如表 3 所总结的，本文的模型在 OKVQA 基准上达到了与 PaLM 2-E 相当的性能，其中包括了有限的空间推理问题，并且在 VQA-v2 test-dev 基准上表现略好，该基准包含了空间推理问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_bd18ddb28dc34facab5cd8ad6310ade2@46958_oswg124562oswg1080oswg272_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>ViT 编码器在空间推理中的影响</strong></p><p>Frozen ViT (在对比目标上进行训练) 是否编码了足够的信息来进行空间推理？为了探索这一点，研究者的实验从第 110,000 步的训练开始，分成两个训练运行，一个 Frozen ViT，另一个 Unfrozen ViT。通过对这两个模型进行了 70,000 步的训练，评估结果如表 4 所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_0c70f3d4443a4a77a33cfbac98cfdca8@46958_oswg69211oswg1080oswg213_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>含噪声的定量空间答案的影响</strong></p><p>研究者者使用机器人操作数据集训练视觉语言模型，发现模型能够在操作领域进行精细的距离估计 (图 5)，进一步证明了数据的准确性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d92dfa9e08da4f9daefb30fbbfc97fdb@46958_oswg351336oswg1080oswg404_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表 5 比较了不同的高斯噪声标准差对定量空间 VQA 中整体 VLM 性能的影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_09bca8e4bd3f403a9c8e6e146af0e0ff@46958_oswg27763oswg1080oswg202_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>空间推理启发新应用</strong></h2><p><strong>1、视觉语言模型作为密集奖励注释器</strong></p><p>视觉语言模型在机器人学领域有一个重要的应用。最近的研究表明，视觉语言模型和大型语言模型可以作为机器人任务的通用开放词汇奖励注释器和成功检测器，可用于制定有效的控制策略。然而，VLM 的奖励标注能力通常受到空间意识不足的限制。由于 SpatialVLM 能够从图像中定量估计距离或尺寸，因此它独特地适用作为密集的奖励注释器。作者进行一项真实的机器人实验，用自然语言指定了一个任务，并要求 SpatialVLM 为轨迹中的每一帧注释奖励。</p><p>图 6 中每个点表示一个目标的位置，它们的颜色表示注释的奖励。随着机器人朝着指定目标的进展，可以看到奖励是单调增加的，表明 SpatialVLM 作为密集奖励注释器的能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_756aa1f3068f4d159f53bfa85c438ae4@46958_oswg383070oswg1080oswg436_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>2、链式思维空间推理</strong></p><p>研究者还研究了 SpatialVLM 是否能够用于执行需要多步推理的任务，考虑到它对基本空间问题的增强回答能力。作者在图 1 和图 4 中展示了一些例子。当大语言模型 (GPT-4) 装备有 SpatialVLM 作为空间推理子模块时，可以执行复杂的空间推理任务，比如回答环境中的 3 个对象是否能够形成「等腰三角形」。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/gj43Bf_BNNfTNWziAfx5Gg" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID:almosthuman2014）</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653744595878152</id>
            <title>“中科院金属所，带飞了太仓航空航天”</title>
            <link>https://www.36kr.com/p/2653744595878152</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653744595878152</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 10:19:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>落地研究所，能否地方政府另辟蹊径的“灵药”呢？</p><p>2023年5月， 生产航空发动机涡轮叶片的公司“华钛瑞翔”落户江苏太仓。这家只拿到了种子轮融资的公司，却着实不简单。</p><p>发动机一直是我国航空产业的短板，而其中的高、低压涡轮叶片的材料又是个中难题，采用镍基合金，耐高温高压性能好，但成本高，良品率也较低，这种情况下民用、商用明显受限。</p><p>华钛瑞翔是中科院金属所的技转项目，去年成功产出第一片合格的钛铝合金低压涡轮叶片，与镍基涡轮叶片相比，不仅更轻，产业化成本更比欧美产品降低了近50%。可以说，华钛瑞翔，是研究所的技转项目产业化落地太仓的一个缩影。</p><p>这样的例子还有不少，除了项目，也帮助太仓吸引了源源不断的人才和资源，最重要的还是产业注意力，一位熟悉国内空天产业的朋友告诉我，近期他和团队提到、听到最多的城市名字，就是太仓。</p><p>自从2019年发布《太仓航空产业发展规划》以来，先后出台了《太仓市航空航天产业创新集群发展专项政策（二十条）》、《太仓市低空经济三年行动计划》等多个产业政策，数据显示，目前太仓市已集聚航空产业链配套企业超100家，2022年产值达120亿元。按照规划，到2025年，太仓整体那航空航天产业集群规模将达到500亿元。</p><p>怎么解读这个数字呢？就拿航空航天的大市、四川省会成都来说吧，2022年成都市111户航空航天规上企业完成营业收入1142亿元，刨除包括成飞在内的航空航天产业10户重点企业营收981.3亿元，差值在150亿元左右。</p><p>虽说“产值”和“营收”不能直接对比，但从数量级上总归能看出来，太仓作为苏州代管一个县级市，对发展航空航天产业的“胃口”着实不小。</p><p>那么问题来了。仅仅不到5年时间，太仓是如何从无到有，培养出一个产值上百亿元的产业集群？这其中，包括中科院金属所在内的科研单位，又起到了什么作用？太仓对空天产业的招商引资，是可以复制的吗？</p><h2><strong>谈航空航天，绕不过去太仓</strong></h2><p>无疑，航空航天成了投资行业的热门主题，今年一月中旬，引力一号火箭首飞成功后，不少投资人、创业者、媒体人朋友都成了“自来水”，纷纷转发朋友圈，仿佛规模化商业航天新纪元就要到来。国产919大飞机更是国之重器，备受万千瞩目。</p><p>近期陆续有航空航天相关船业公司拿到融资，地方也都将航空航天当作重点招引和投资产业之一，不仅密集成立专项基金，还陆续出台相当优惠的招引政策，企业落地的新闻也不断出现：</p><p>文昌航天城的首支航天产业基金落地，规模10亿元；</p><p>陕西成立了10亿人民币规模的秦创原空天交汇科技产业基金，其中组建方之一就是陕西空天动力研究院；</p><p>天回航天完成超亿元的人民币A轮融资，用于公司液氧煤油火箭发动机的产业化基地建设，这轮投资方包括四川绵阳科发基金、西安市人才基金等；</p><p>在四川，资阳重产投了星河动力并且在当地落了一个生产线；德阳什邡落了星际荣耀的生产线……</p><p>以江浙沪的空天产业来说，太仓是个绕不过去的城市。</p><p>由于毗邻上海，太仓持续在接收上海溢出的产业，在上海汽车产业多年的带动下，太仓发展出了高端装备制造和先进材料两个千亿级产业。强大的工业基础，加以转型升级，就让太仓顺利切入了航空航天领域。</p><p>另外，太仓和德企打交道已有30年，最近也迎来了第500家德企落地，其中舍弗勒、卓能电子、巨浪凯龙等企业凭借先进技术基础，已涉足航空航天产业。所以，太仓虽然作为江苏代管的县级市，但当地高端精密制造产业链相当完整，与国际企业开展合作经验丰富，发展劲头不容小觑。</p><p>另外，有熟悉太仓的朋友告诉我，空天产业之所以在太仓生根，离不开中科院金属所的加持，他的原话是，“一个金属所，就把太仓的航空航天产业带的飞起来了”，而我深入了解后才知道，太仓为了吸引包括金属所在内的研究所落地，也是做了十足的准备，并且花了相当大的力气。</p><h2><strong>金属所，怎么就带飞了太仓航空航天？</strong></h2><p>追溯起来，太仓真正着力布局空天产业，可以从2019年发布《太仓航空产业发展规划》算起，和老牌的成都、海南空天产业城市相比，起步不算早，但这几年的发展却势头很猛。</p><p>熟悉太仓招商的朋友告诉我，所谓“金属所带飞了太仓航空航天”，并不单指金属所，而是指研究所在太仓航空航天的产业发展中，起了重要作用，这些研究所包括中科院下属计算所、硅酸盐所、光机所，西工大长三角研究院、吉太航空研究院等多个科研院所，都帮助太仓完善了航空航天的相关产业布局。</p><p>2020年，太仓政府与以“三航”（航空、航天、航海）著称的西北工业大学合作，其太仓校区正式开工建设，奠定了产业发展所需的科研人才基础。除了西工大，太仓同步推动着与西交利物浦大学太仓校区、上海交大空天技术创新中心等大学大院大所分支机构的合作。</p><p>以中科院金属所为例，文首提到的华钛瑞翔，在研究团队验证了技术可行性后，随即将项目落户在太仓，把突破性的工艺从实验室搬进工厂，只用了一年半时间，这种全新材料突破，开启了低压涡轮叶片的国产化进程，产业化以后其成本比欧美降低近50%。</p><p>华钛瑞翔总经理刘荣华就表示，落户太仓综合成本是最低的，并且发展产业的决心大，配套服务相当到位。</p><p>“刚开始入驻这里，厂房没有高压电，政府直接投入了2000多万元帮他们解决问题，为企业节省了大量资金。”</p><p>除了这种从实验室到工厂的模式，太仓也花了大成本招引龙头企业。星河动力在2020年成功发射谷神星一号运载火箭后，标志着中国民营商业火箭首次进入500km太阳同步轨道，星河动力也就奠定了业内的地位。</p><p>我查阅资料后发现，太仓与星河动力的合作始于2022年，星河动力液体火箭项目在太仓港区开工，这次开工建设的新一代可重复使用液体燃料运载火箭产业化基地项目，总投资额15亿元，项目占地100亩。</p><p>在星河动力的牵引下，相继有航天驭星、太昌宇图、曙光航空发动机、金江铜业等项目签约入驻，也带来了高博航空、开运联合、爱上飞行、泰克南航空等项目与当地洽谈。</p><p>另外，太仓和中国商飞也有些浅层合作。2021年，太仓与商飞签约拟定双方携手推动民机数字技术支持产业化发展。2022年，中国商飞上海飞机设计研究院与位于太仓的吉太航空，宣布联合组建民机航电设备联合工程中心。</p><p>随着不同细分空天产业的头部公司都落子太仓以后，当地政府同步规划出土地资源，并投入大量配套，建设了大飞机苏州（太仓）航空产业园、航空零部件产业园、航空新材料产业园、临港航空航天产业园等，作为产业发展的平台载体。</p><p>逐渐地，太仓“产学研一体化”发展模式成型，航空零部件智能制造、航空新材料、航空机载系统、航空服务业、航空配套装备成为太仓的重点发展方向。像点石航空动力自主研发生产出了小型航空发动机，西工大研究院团队的新型高温结构材料，也被高晶新材料送上了生产线。</p><p>航空航天产业在当地形成集聚效应后，太仓并未止步，不仅颁布了航空航天20条政策，包括产业引导基金、人才项目补贴等，还要力争到2025年太仓航空航天产业整个产值和规模达到500亿元。</p><p>这么看来，太仓既发挥了苏州模式的优势，也借鉴了合肥模式的优点。苏州模式被认为是根据产业方向来做产业集群的培育；合肥模式是指找到链主和链长企业，沿着这些企业的上下游打造产业集群。太仓在确定往空天领域发力的背景下，结合落地的研究所，引来链主企业集聚上下游产业链，似乎证明了苏州模式和合肥模式并不冲突，而是可以取长补短。</p><h2><strong>靠谱项目哪里来？</strong></h2><p>从上述例子来看，不难发现，太仓落地研究所和龙头产业，都拉动了当地招引航空航天企业的节奏。那么在全国都在卷招商引资的今天，落地研究所，能否地方政府另辟蹊径的“灵药”呢？</p><p>要回答这个问题，得看看与此前相比，现在地方招商到底卷在哪，难在哪。</p><p>有地方招商的朋友和我谈到，在“钱越来越贵”的背景下，如果有好项目，政府、国资一般跟着基金走，基金手里有什么好项目，招商团队就跟着服务：当地政府跟投，然后给空间给政策。</p><p>但现在情况又发生了进一步变化，优质资产也开始荒了（我的同事蒲凡已经撰写相关稿件，待刊发），双方不一定互相都有资源共享。市场上好项目不多，基金风险控制也很严格，GP不仅自己找不到好项目，还会反过来找政府推荐靠谱项目。</p><p>靠谱项目哪里来？比如靠比赛筛选，科技局、招商局会举办比赛来筛选优质的小项目，但有些比赛跑出来的项目，落地后成长并不强劲，也有些参赛者就想拿补贴，还有些老师本身就在学校担任教职，拿创业补贴本身就有一定的风险。</p><p>小项目靠谱的不多，靠谱项目又很难引进。比如就算有好项目来和政府洽谈落地，有些项目资金需求量太大，地方一时半会也很难满足。</p><p>因此，“找不到好项目、招不来好项目、小项目缺乏强劲成长性”，这些都是地方在招商中遇到的实际困难，这种情况下，吸引研究所落地可能是破局的解法之一。</p><p>太金属所、硅酸盐所、光机所、西工大太仓分校等，都带动了太仓相关产业领域教授、学生的集聚，无论他们创业还是就业，有实打实的人才集聚效应，也给地方的招商打下了相关基础。</p><p>熟悉太仓招商的朋友表示，大部分太仓接触的科技企业，整体上跟产业紧密程度很高。产业链匹配是企业要在太仓落地的第一道门槛，在带动上下游企业合作伙伴来落地、吸引行业内突破关键技术早期项目落地上，研究所的确作用不小。</p><h2><strong>落地研究所，能解决招商难吗？</strong></h2><p>那么，太仓通过研究所带飞了自己的航空航天产业，是个例吗？</p><p>除了太仓，常州物理所和苏州纳米所，也成功带动了当地的相关产业发展。从这些城市的案例看，拉研究所来落地，似乎是个不错的“前置”招商方案。</p><p>2023年常州迈入GDP万亿之城，产业集聚度全国前3，投资热度全国第1，新能源产业产值达7500亿元左右。这离不开常州在新能源行业强势发展下找准了定位，该市动力电池全国出货量排名第一，且动力电池产业链完整度达97%。</p><p>同时，常州的新能源产业发展，也离不开多年前中科院物理研究所在溧阳成立的研究院，不仅拉来前沿项目，也凝聚了产业，其中早期孵化的代表项目就有中科海纳和卫蓝新能源。</p><p>苏州工业园更是早在2006年就创建了中科院苏州纳米所，至今苏州纳米城入驻企业超500家，上市企业5家；每平方公里就入驻近10家大院大所。</p><p>从常州和苏州工业园的例子来看，这事不仅能助推产业爆发式增长，其长尾效应也不容小觑。</p><p>“这些研究所表面上只是一个创新平台、研究机构，但不是落地就可以躺着拿钱、拿资源，其实它们承载了孵化和产业职能。”熟悉太仓招商的朋友告诉我，政府给土地、资金，每年产业公司肯定是要落人才项目的，有项目研究出来了，大概率不会放在其他地方。</p><p>另外，研究所一落地，也会吸引很多项目过来，“因为大家还是追着产业走，太仓就有与中科院渊源比较深的项目过来，很多老师的课题、项目也都会放到太仓。”</p><p>这位朋友继续以中科院硅盐酸所太仓园区为例，硅盐酸属于无机材料，这跟太仓的材料和工业传统优势高度相关，“已经在太仓了落地了包括院士项目在内的十几个重点项目”。</p><p>从数据上来看，硅酸盐所太仓园区自2015年成立以来，已累计孵化高新技术企业19家，获评各级创业领军人才20项，引进孵化的中科赛诺新能源、芯合半导体、莒纳新材料等企业估值合计超60亿元。</p><p>总的说来，落子高校院所研究所，有助于早期孵化，也有利于为产业输送人才。像西工大就在太仓孵化出了华易航动力科技、域圆科技等企业，这样的例子不胜枚举。此外，像西工大民航学院、材料学院毕业的学生，也可以进入当地空天企业实习就业，为太仓提供人才储备。</p><p>但这有个前提，除了需要地方政府的前期投入，在政府招引研究所的同时，也要承担很重的职能。并且，政府前期花大成本落子这些研究院所后，其中的风险是投入和产出不一定成正比，很多实验室成果不一定能明确转化为产业化企业，并且也许会面临转化周期长的问题。</p><p>换言之，如果当地招引要立竿见影，这不见得是个保险的方式。毕竟像太仓航空航天这样具备“天时”（空天产业发展正当其时），“地利”（地处长三角中心，承接上海产业外溢），再加上“校企地”全面合作的“人和”，其实也挺难得，其他城市到底是否具备这些条件，就得各自掂量一下了。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI4MjYxMTYyNA==&amp;mid=2247509633&amp;idx=1&amp;sn=8a700f193a046e98ae7e373ec5bb7790&amp;chksm=ea6a7f12dcf7bbc5f8022c8b0e17d5024dcaf66c302823ed7b6cb2bd418f7cd45711dd8e4c9d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“东四十条资本”（ID：DsstCapital）</a>，作者：竺晶莹、张楠，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653745392189703</id>
            <title>Sora发布后，我开始担心失业了</title>
            <link>https://www.36kr.com/p/2653745392189703</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653745392189703</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 10:19:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_6bc5bc3b94414c29a141d567649eefbd@46958_oswg28128oswg550oswg506_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：麦肯锡报告</p><p>最近看了一个麦肯锡的报告，说到2030年，AI会替代1亿多中国人的岗位。</p><p><strong>且不说这个预测是否准确，但看看如今生成式AI的发展速度，连我都开始考虑一个问题：产品经理会不会有一天也被AI替代？</strong></p><p>你可能会说：产品经理不是创意型的工作吗？不是需要人际沟通的工作吗？</p><p>连OpenAI创始人奥特曼都说了：创意型工作、人际沟通型工作是AI替代不了的。</p><p>实话说，我以前也是这么想的，但是Sora发布以后，我开始怀疑起这个结论了。</p><p>我们可以梳理一下，一个优秀的B端产品经理到底需要哪些核心能力？</p><p>其实也就3点：</p><p>1、对B端系统的学习能力</p><p>2、对业务知识的学习能力</p><p>3、与客户、研发沟通的能力</p><p>先说第1点和第2点。</p><p>在我们从前的认知里面，虽然都公认AI学习能力很强，但是AI更善于机械的存储和检索知识，无法进行逻辑推导，更没有决策能力。</p><p>就算是去年大火的ChatGPT，其本质也只是“根据上一个单词生成下一个单词”，和人类的认知能力有着天壤之别。</p><p>但是看看刚推出的Sora，它的核心能力已经不是简单的视频生成了。</p><p><strong>在足以“以假乱真”的视频背后，是AI通过大量学习，掌握了真实世界的物理规则！</strong></p><p>比如，街道上的水面动态反射出人的倒影，不懂光学原理是很难如此精准的生成视频的。</p><p><strong>你可能会说：AI只是简单的模仿，但是它并没有人类的思考能力啊。</strong></p><p><strong>其实，婴儿学习世界法则的过程，不就是模仿的过程吗？</strong></p><p><strong>AI的学习过程，和人类的学习过程，并没有本质的区别！</strong></p><p>还有人说，Sora只是掌握了一些简单的物理规则。</p><p><strong>但是对于AI这种“怪物”来说，只要突破了从0到1，它就能以人类难以企及的速度完成进化。</strong></p><p>同时，B端业务的壁垒并没有想象中那么高。</p><p>不但有规律可循，逻辑也不复杂——相信我——只要有足够的数据喂给AI，它就能在短时间内超越大多数产品经理！</p><p>再说第3点，与客户、研发沟通的能力。</p><p>短时间内，线下沟通工作恐怕很难被AI替代，毕竟AI还无法像人类一样，主动去客户现场去完成调研工作。</p><p><strong>但是问题在于：只要AI足够强大，客户自己就能够完成产品的设计工作！根本就不需要产品经理在中间做沟通工作！</strong></p><p>也就是说，AI会重塑产品设计的链路，去掉中间非必需的产品研发环节，直接辅助客户生成想要的产品！</p><p><strong>如果你觉得这个不可能实现，那么可以想一想如今的无代码产品，很多用户已经能够自助搭建APP了。</strong></p><p>所以，只要AI足够强大，客户摆脱对产品经理的依赖是完全有可能的。</p><p>当然了，如果AI真的进化到那一步，不只是产品经理，人类大部分岗位恐怕都要失业了。</p><p>所以“好消息”是，AI的发展还需要时间。</p><p>而且不同行业、不同岗位被AI颠覆的时间点，也会有很大的差异。</p><p>比如，虽然AI的学习能力很强，但是前提是有大量优质的线上数据。</p><p>而B端领域的主要数据都在线下。</p><p>即便未来B端业务的线上化程度越来越高，但是仍然会长时间面临“垂直领域数据量不够大”的问题！</p><p><strong>毕竟AI学习非常依赖高质量、大量的数据，面对“小数据”，还是人类的认知能力更强一些（至少目前来看是这样）。</strong></p><p><strong>再加上相对于C端业务，B端业务环节错综复杂，对决策的准确性要求很高，至少在一定时间内，AI仍然只能起到辅助产品经理的作用。</strong></p><p>所以，在AI时代，B端产品经理的生命周期还是相对长的。</p><p>不过，看看Sora现在的表现，我也不敢预测或者说低估AI的进步速度。</p><p>所以我还是相信，迟早有一天，AI会替代掉产品经理的工作。</p><p>当然，即便这件事最终发生了，首先被AI替代的，还是“原型仔”。</p><p><strong>即既不需要和客户沟通，又不需要深入掌握垂类行业知识（特别是线下知识），而只是负责执行的“功能设计师”。</strong></p><p>其实，不用等AI替代，那些没有行业壁垒、不能洞察客户需求的产品经理，也很容易被淘汰出局。</p><p>这一类产品经理其实有很多。</p><p>比如很多G端产品经理，做的项目都是面子工程，本身就不存在行业壁垒。</p><p>还有很多外包产品经理，每个行业、每个领域都浅尝辄止，也形成不了自己的核心竞争力。</p><p>甚至包括很多企业的内部产品经理，名义上是产品经理，实际上做的都是运营工作。</p><p>他们其实是最容易被AI替代的。</p><p><strong>所以，即便是在AI时代，大家也会发现：</strong></p><p><strong>那些缺乏核心竞争力的产品经理，会最先被淘汰。</strong></p><p><strong>而优秀的产品经理，即便最终岗位被AI替代了，凭借着自己深厚的行业积累以及客户沟通能力，华丽转身的机会还是很大的。</strong></p><p>毕竟，AI在替换掉“老岗位”的同时，也会创造出“新岗位”。</p><p>这些新岗位在AI的加持下不但更加轻松和体面，收入还会更高。</p><p>其实，每一次技术的进步，人类的整体福祉都是不断增加的。</p><p><strong>所以，我们真正要做的，不是害怕AI，更不是抵制AI，而是争取成为AI时代的赢家。</strong></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/3bF56WqnVyddc-XY7oknGw" rel="noopener noreferrer nofollow" target="_blank">“ToB老人家”（ID:ToBlaorenjia）</a>，作者：王戴明，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653745439129857</id>
            <title>数学天才孙崧回国任教，中科大少年班出身，27岁破解“丘成桐猜想”，官宣加盟浙大</title>
            <link>https://www.36kr.com/p/2653745439129857</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653745439129857</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 09:54:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>陈秀雄高徒、中科大少年班02级校友<strong>孙崧</strong>，官宣加入浙大数学高等研究院！</p><p>根据浙江大学官方消息，加州大学伯克利分校数学系正教授孙崧，现已<strong>全职加入浙大，担任杜建英讲席教授</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_37be6572807d4fe6b817c145a3957021@46958_oswg455642oswg768oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>孙崧长期深耕<strong>微分几何、复几何和几何分析</strong>领域。</p><p>27岁，孙崧就与导师一起破解了困扰数学界近40年的难题，后获国际几何学领域最高荣誉之一——<strong>维布伦几何学奖</strong>。</p><p>同时获奖的还有菲尔兹奖得主Simon Donaldson。</p><p>他还曾获有着“诺奖风向标”之称的斯隆研究奖、科学突破奖–数学新视野奖等，受邀在国际数学家大会上作了45分钟的报告。</p><p>加入浙大数学高等研究院后，出生于1987年的他就是该院<strong>第五位永久成员</strong>，也是最年轻的一位。</p><p>而其他四位成员，也都是赫赫有名的顶尖数学家，分别是：创始院长、中科院院士<strong>励建书</strong>，中科院院士<strong>阮勇斌</strong>，中科院院士<strong>孙斌勇</strong>，北大数学“黄金一代”、前耶鲁大学数学系教授<strong>刘一峰</strong>。</p><h2><strong>为卡拉比猜想画上句点</strong></h2><p>孙崧的主要研究成果之一，就是在2014年，与导师陈秀雄和1986年菲尔兹奖得主Simon Donaldson一起，证明了<strong>第一陈</strong>（省身）<strong>类为正时的卡拉比猜想</strong>。</p><p>此时孙崧只有27岁，距离丘成桐给出“前一半”卡拉比猜想的证明，已经过去了近四十年。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_c93b995e072e4d67bc2e3d760a9deed2@46958_oswg445244oswg1000oswg295_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>△</strong>左起：陈秀雄，Simon Donaldson，孙崧，图源美国数学学会官网</p><p>1954年，国际数学大会在阿姆斯特丹举行，卡拉比在会议的邀请报告中用一页纸写下了他的著名猜想：</p><blockquote><p>令M为紧致的卡勒（Kahler）流形，那么对其第一陈类中的任何一个（1，1）形式R，都存在唯一的一个<strong>卡勒-爱因斯坦度量</strong>，其Ricci形式恰好是R。</p></blockquote><p>用物理语言来描述，就是在封闭的空间，有无可能存在<strong>没有物质分布的引力场</strong>？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1664d97317534722a30bc719d02fa878@46958_oswg123720oswg703oswg469_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>1976年，丘成桐利用卡勒几何中的曲率的概念成功证明了第一陈类为负或零时的卡拉比猜想。</p><p>值得一提的是，当年的丘成桐，也是27岁。</p><p>而针对第一陈类为正的情况，丘成桐提出了一个证明思路，即将空间的卡勒-爱因斯坦度量的存在性问题转化为代数几何的稳定性问题，被学界称为“丘成桐猜想”。</p><p>但丘成桐本人也未能给出具体的证明过程。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ad567a96b8b14c09b21b9ff840e575e3@46958_oswg322867oswg766oswg688_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最终，通过不断构造逼近的方式，三人给出了这一猜想的最终证明，三篇系列论文发表在国际数学顶刊《美国数学会杂志》上。</p><p>审稿人评价道：</p><blockquote><p>证明是突破性的，它不仅解决了一个基本性的问题，同时还发展了许多新颖有力的工具，以揭示卡勒几何、代数几何和偏微分方程之间的深刻联系。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_c2cb220477644c899233986a01014cd4@46958_oswg42567oswg1080oswg397_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>至此，历经师徒三代人（陈秀雄是卡拉比教授的“关门弟子”）和历代数学家们60年的努力，卡拉比猜想终于画上了完美的句点。</p><p>2014年当年，孙崧获得了有“诺奖风向标”之称的斯隆研究奖，获奖原因正是“卡勒几何方面的工作”。</p><p>斯隆研究奖旨在支持和奖励“处于职业早期阶段的杰出学者”，目前为止，斯隆研究奖获得者中已诞生50余位诺奖得主。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_5f91f30ecc27481d930e3b6d44905251@46958_oswg46820oswg1080oswg419_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2018年，因为丘成桐猜想的证明，32岁的孙崧与导师陈秀雄，还有Simon Donaldson一起，获得维布伦奖。</p><p>值得注意的是，Simon是1986年的菲尔兹奖得主，彼时已年近花甲。</p><p>该奖项由美国数学会颁发，面向的对象是在几何或拓扑学领域取得重大成果的学者，1981年丘成桐也获得了这一奖项。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_1cc660b8c1474586b5d2484f3ce33885@46958_oswg732383oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同年，孙崧受邀在国际数学家大会上作45分钟报告。</p><p>而后，科学突破奖评审委员会授予孙崧2021年数学新视野奖，“以表彰他在复几何领域的一系列开创性贡献。”</p><p>科学突破奖被誉为“科学界的奥斯卡”，旨在表彰全世界最顶尖的科学家。</p><p>其中每年颁奖不超过3人的数学新视野奖，专门面向年轻科研人员，以表彰他们在各自领域的优异成就。</p><h2><strong>浙大数高院最年轻的永久成员</strong></h2><p>回顾孙崧的数学生涯，他常说没有捷径可走，兴趣是求索的前提。</p><p>据他在浙大官微上的自述：</p><blockquote><p>我觉得需要有发自内心的渴望去理解数学。研究需要专注，更需要坚持走自己的路，研究自己觉得有意思的问题。</p></blockquote><p>兴趣驱动下，孙崧数学生涯可谓一路“高开高走”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_decbf38f06f24e59ad2682e52d949615@46958_oswg755405oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>△</strong>图源：“浙江大学”微信公众号</p><p>2000年，孙崧以中考全县第一的成绩考入安徽省怀宁中学。</p><p>高二，参加全国高中学生化学竞赛，获二等奖；同年参加高考，被中科大少年班录取。孙崧由此也成为了怀宁县考进科大少年班的第一人。</p><p>2006年，孙崧拿到全额奖学金前往美国威斯康星大学数学系学习，并在四年后获博士学位。</p><p>正是在读博期间，师从知名几何学专家<strong>陈秀雄</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_14f806f635264d6fbfe7e6446cf8b662@46958_oswg1341464oswg800oswg1200_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>陈秀雄是美国威斯康星大学终身教授，美国纽约州立大学石溪分校教授。</p><p>此外，他还是中科大几何与物理研究中心创始主任、“吴文俊讲席教授”，上海科技大学数学科学研究所创始所长、特聘教授。</p><p>除维布伦奖，他还是2019年西蒙斯学者奖获得者，是继陶哲轩和姚鸿泽后第三位获得西蒙斯学者奖的华人数学家。</p><p>碰巧的是，陈秀雄教授是中科大1982级校友，师徒两人入校时间正好相隔二十年。</p><p>毕业后，孙崧曾任纽约州立大学石溪分校助理教授；2018年任加州大学伯克利分校副教授、数学系正教授。</p><p>这次加盟浙大数高院，孙崧将成为浙大数高院第五位永久成员，且1987年出生的他，也是其中最年轻的一位。</p><p>据浙江大学官方微信公众号消息，孙崧具体职位是<strong>杜建英讲席教授</strong>，他本人表示：</p><blockquote><p>加盟浙大后，我将做好自己的学术研究，指导有志于从事数学的学生，并尽我所能将自己的专业传承给更年轻的一代。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_141b380ca01a4063b34d8062f56ba6b3@46958_oswg318940oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>浙大数高院于2017年成立，中科院院士励建书，是该研究院的创始院长。</p><p>2019年，密歇根大学讲席教授阮勇斌加盟。阮勇斌教授长期致力于辛几何、数学物理等领域的研究，2021年当选为中科院院士。</p><p>一年后，当时最年轻的中科院院士孙斌勇也入职数高院，并继续在李群表示论等领域深耕。</p><p>同样间隔一年，北大数学“黄金一代”刘一峰加盟，之前他在耶鲁大学任正教授。加入数高院后，又在数学四大顶刊发表论文三篇。</p><p>参考链接：[1]https://www.ustcif.org.cn/default.php/content/4053/[2]https://www.ams.org/news?news_id=4705[3]https://news.stonybrook.edu/newsroom/press-release/general/2182014songsun/[4]https://mp.weixin.qq.com/s/QZjDCye_KemNq55SjwllAA</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Jekm92yMmAxyExFFHegc4w" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：克雷西 西风&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2653745805376648</id>
            <title>24 小时随时随地高效沉浸式编程：我用 Vision Pro 做到了，老板高兴坏了</title>
            <link>https://www.36kr.com/p/2653745805376648</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2653745805376648</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 09:53:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Vision Pro 能否成为编程助手？</p><p>想象一下，你不再被格子间或堆满生活用品的房间束缚，取而代之的是：你置身于风景如画的湖畔，眼前是郁郁葱葱的绿色山区，耳边是婉转悠扬的鸟鸣声，湖面上波光粼粼，薄雾轻盈地升腾，一切都是那么静谧美好。在这种环境下，你还能像以前一样写代码吗？或许灵感会像泉水般涌现，思绪也会像清风般飘逸，指尖跃动的代码，仿佛也能化作这湖光山色的一部分，充满了灵动与活力？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_d7f2142d5f6d4d7f874076552e9c861e@46958_oswg110229oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>苹果公司在推出 Vision Pro 时，介绍的应用场景不是很多，包括提供更具有沉浸感的影视和游戏体验、运行 App Store 中已有的 App、多屏办公等。一些人已经使用它来玩游戏、观看影视，那么除此之外，头显设备能提高程序员们的生产力吗？</p><p>实际上，在苹果 Vision Pro 发布两周后，不少开发人员已经尝试了使用该设备来编写代码，并纷纷通过录制视频或写博客文章的方式给出了评价。</p><p>一位名为“Your Average Tech Bro”的 YouTuber，决定从早上 7:40 起床开始，尝试佩戴这款头戴设备，以便在接下来的 24 小时里一直戴着它来编程。一天体验下来，他的感受还挺不错，并且讽刺那些嫌这款头显太重的兄弟，认为他们“该锻练身体了”。他也提出了一个使用这款头显进行编程的一个缺点：无法捕捉到某些网站上的小按钮，细节做得不够精细。但他认为 Vision Pro 在未来将是一个成功的设备，只是需要再等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_ce20c8f113f94fb5bfab050c60b63f2c@46958_oswg49252oswg1080oswg681_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作为一名软件工程师，视频博主 Utsav 也好奇是否能使用 Vision Pro 帮助自己完成编程工作，于是自费买了台设备，并花了足足一周的时间进行体验。对他而言，是将他原来的 MacBook Pro 屏幕无缝地转变为了一个非常大的、令人难以置信的清晰虚拟屏幕。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_456ad21d944e4569916afd2620d29833@46958_oswg62626oswg987oswg636_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一方面，虽然写代码是工作中的重要组成部分，但还有一部分工作是需要协作的，因此他也认为需要在场景上做一些有意义的增强。</p><p>总之，Utsav 得出的结论是，尽管这项技术尚未完全成熟，且其价格合理性难以证明，但它仍然可以成为偶尔需要集中编码体验的理想助手。因此，总的来说，尽管这样的完美设备“尚未出现”，但苹果头显在当前使用案例中仍然是最佳选择。</p><p>软件开发人员、IT 企业家 Willem 也做了同样的尝试，他坐在自家阁楼里，房间里几乎没有家具，而是堆满了两个孩子的用品和玩具，但他将头显背景设置成了面向山川湖泊。他感觉这样能快速进入状态，过滤掉现实世界中的种种视觉干扰因素。</p><p>其他网友对 Willem 的看法表示非常赞同：“我很容易分心，尤其是在家工作时，我常常四处走动。对我来说，拥有一个轻便的工作空间，可以随身携带，进行轻松工作（例如聊天、电子邮件等），这一点非常吸引人。虽然佩戴 Vision Pro 或许看起来有些愚蠢，但 Willem 的分享确实帮助我看到了使用 Vision Pro 的潜力，比苹果广告描述得更好。”</p><p>但这也意味着，Vision Pro 可以被携带到任何地方，并让你快速进入到工作模式。这有点像手机，虽然我们不喜欢为别人 7*24 小时地提供服务，但手机使这成为了可能。 Vision Pro 的到来，也可能让我们面临类似的问题——不必携带 MacBook 或者大屏幕也能随时随地提供服务，还能始终保持高效工作状态。</p><p>以下是 Willem 的感受：</p><h2><strong>体验苹果 Vision Pro： 主打一个无干扰的编程环境&nbsp;</strong></h2><p>不少音乐发烧友都喜欢选择高端耳机，享受由此带来的高品质音乐播放体验。苹果 Vision Pro 也差不多，只是这次服务我们的眼睛、而非耳朵。它的佩戴感受类似于护目镜，透过镜片看到的则是一个与现实融为一体的数字世界。我们可以选择将外部真实场景透传进来，也可以将背景过滤掉，类似于降噪耳机屏蔽实际环境音。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_5ef06c4b48554a7ea75264d87d5080d7@46958_oswg180769oswg554oswg417_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">苹果 Vision Pro，为挑剔的眼睛而生。</p><p>苹果 Vision Pro 头显搭载一系列先进芯片、传感器与摄像头，能够将虚拟物体投射进我们的现实世界、实现数字界面的稳定悬停，并实时接受用户的交互和操作。我们可以借此实现很多功能，比如在眼前搞出一块巨大的影院屏幕，或者让家人相簿环绕在我们周围。当然，也可以使用 Vision Pro 处理工作，面对湖泊编程。</p><p>事实证明，Vision Pro 不只是一台精美的可穿戴投影仪，更有着良好的交互体验！它的内侧摄像头能够跟踪用户的虹膜位置，实现眼动与视线落点定位。这些信息可进一步用于同数字世界的互动。另有一组摄像头会记录下用户指尖的细微运作，而且所有一切都被无缝整合成统一的体验，让操作者能够“查看和点击”，整个过程与传统电脑上的指向加点击和移动设备上的触摸加滑动一样既顺畅、又自然。</p><p>整个基础交互模型的效果非常好，短短几分钟后我就感觉完全适应了。而且在此之后，我甚至开始怀疑，为什么当初 iPhone 和 iPad 不提供类似的响应模式。这就是经典的苹果魔法，他们解决了所有复杂、艰深的底层难题，只留给用户丝滑的操作体验。Vision Pro 干得非常漂亮，点赞！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a6c2da48265f465e8653ac4ea17e78f6@46958_oswg143152oswg554oswg318_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">接入 Vision Pro 的蓝牙键盘和触控板。</p><p>为了完成日常工作，我得把标准蓝牙键盘和触控板接入 Vision Pro，再通过触摸的方式进行输入——好在整个感受非常自然。Vision Pro 不需要再连接计算机，因为它本身就是一部强劲的计算设备，搭载有性能超群的苹果自研芯片和充足的内置存储空间（我的是 1 TB 版本）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_6616d3d7c5ee4955b5cb5954d09f3026@46958_oswg330039oswg554oswg417_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">键盘、触控板、Vision Pro 再加一杯咖啡，我的工作台就搭起来了。</p><p>我本人特别喜欢平板电脑，爱的就是它们的便携性和强大的功能。Vision Pro 无疑朝着这个方向又迈进了一步：它更加便携，而且能在眼前为我们呈现一整个虚拟的世界。这就像是把巨大的多显示器组合装进了自己的口袋——简直疯狂！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_10f2a38f059e48608c51f6d06a699c8b@46958_oswg183615oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">绝非幻想：显示屏、键盘、触控板（请注意实体键盘上方悬停的，其实是 Vision Pro 的 UI 屏幕）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_14211f7c2d744e64b5501badeac9e83b@46958_oswg151276oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">我们可以像这样轻松摆放多块虚拟显示屏。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_fce8e3e9ee274cd89a02b22a858a0c2c@46958_oswg178726oswg554oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">通过这张 2D 图像可能感觉不出来，但 Vision Pro 提供的多屏效果是有景深的，如同真有两块屏幕竖在桌上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_04f8ec9e4a914fe089bf7df1883a268f@46958_oswg208459oswg554oswg497_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">大家可以围着屏幕看、贴近屏幕看，甚至把它们在背景空间里拖来拖去、任意摆放。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_5ef8796ebbdf4392a82582946b2d5360@46958_oswg202349oswg554oswg364_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">画面看起来非常自然，我的大脑甚至总觉得自己一伸手就会碰到。</p><p>在把数字世界跟现实世界混合起来这件事上，苹果的确完成得不错，也让用户有了一边操作、一边对实际环境保持关注的能力。我个人也很喜欢，因为它不会让人感觉“被封闭在了电脑里”。整个体验非常适合某些工作流程，例如发送电子邮件、检索内容或者拨打电话。当然，大家也可以选择完全沉浸在 Vision Pro 提供的虚拟环境中、关闭真实背景的透传显示，整个体验将有所不同。</p><p>有些朋友称之为“深度工作”模式，更适合那些需要集中注意力的任务。我也发现 Vision Pro 特别强大，能够让我面对繁重的工作时快速进入心流状态。我可以让自己彻底沉浸在上下文（图像、日志、代码、模型）当中，过滤掉现实世界中的种种视觉干扰因素。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_96018f03097d418c96b2b4b9ef42afd3@46958_oswg176249oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">这些窗口就是同一项目中的各相关界面——它们尺寸都很大，中间的长条型窗口看起来有 3 米高！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_0cd57d4ba02f4834b1d3eaa63eab6992@46958_oswg177466oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">哪怕是上图里“最小”的窗口，实际上也尺寸惊人；为了直观对照，我去掉了虚拟月球背景，现在窗口就跟我女儿的鞋形成了鲜明对比。</p><p>这就相当于把一个个窗口弄到像钢铁侠战衣的展柜那么大，这也是我喜爱 Vision Pro 的原因之一。显示内容几乎能跟环境融为一体，用户可以在其中随意排布和处理自己手头的工作。我自己还特别喜欢在窗口之间走来走去，这边看看代码、那边看看服务器输出，感觉自己如同置身一处宽敞的机房、面对一台“庞大且运转迅速的机器”。这种感受跟以往任何传统桌面体验都完全不同。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_7890acb94c324e50800b781995739e36@46958_oswg218381oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">再次强调，2D 的照片体现不出实际观感，总之能在数字环境中走来走去真的太神奇了！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_4c17c3204e80413187c50bf04a82af8f@46958_oswg204647oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">这些窗口非常巨大，甚至让普普通通的状态数据有了种庄严、肃穆的感觉。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_797af5e4953b4f9b95f345d0d6bdd345@46958_oswg126504oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">如果转为纯虚拟环境，Vision Pro 还会在我们即将撞上物体时发出警告——最大的风险，当然就是跑来跑去的小孩子喽！</p><p>我将继续探索、学习和体验 Vision Pro，而且就目前来讲，我已经被它那强大的数字 3D 空间展示能力所折服。整个使用感受非常自然，不禁让我想起自己刚刚拥有初代 iPhone 时，每次滑动解锁都会憨憨笑出声来，但 Vision Pro 更复杂也更强大，其中还有更多要素可以解锁。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_4ea032bfd1fc4d888dcf1bb0e61af7e7@46958_oswg239469oswg554oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">说到缺点……戴着 Vision Pro 喝咖啡真的很费劲，苹果最好考虑改进一下：-）</p><p><strong>参考链接：</strong></p><p>https://www.youtube.com/watch?v=12qdf3NAJmo</p><p>https://www.youtube.com/watch?v=8LLbtNswsn0</p><p>https://www.youtube.com/watch?v=clRj-4dsRPw</p><p>https://willem.com/blog/2024-02-16_vision-pro/</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/afbE4yT3qkb_fUyBJF_p1A" rel="noopener noreferrer nofollow" target="_blank">“InfoQ”（ID:infoqchina）</a>，编译：核子可乐、Tina&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>