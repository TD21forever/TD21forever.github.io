<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2958322843732999</id>
            <title>“小屏旗舰”或将推迟，索尼手机的路已愈发艰难</title>
            <link>https://www.36kr.com/p/2958322843732999</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958322843732999</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 12:54:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <h2><strong>前言：索尼的小屏旗舰，今年“难产”了</strong></h2><p>如果你是一位“小屏手机爱好者”，并且还是索尼手机的粉丝，那么最近的一些消息可能会让你感到失望。因为目前有越来越多的信息都显示，索尼方面可能不会再推出新款Xperia 5智能手机。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_fbb350ca920a4a1d857881c8b8d50d65@46958_oswg31842oswg750oswg527_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这件事的“苗头”，最早出现在今年9月。因为按照以往的惯例，索尼通常会在夏季更新旗下Xperia 1旗舰产品线，之后在9月的IFA展期间发布定位“小屏旗舰”的Xperia 5系列新机。但是在今年9月，索尼方面一反常态地并未在IFA期间发布新机。</p><p>但即便在那个时候，许多朋友还是抱有期望的。因为早在今年夏季时，就曾有一家欧洲的零售商公布了据称是为Xperia 5 VI设计的手机壳。众所周知，手机壳厂商通常都会提前拿到新机的外观和尺寸数据，因此它至少可以作为Xperia 5 VI已接近研发完成的间接证据。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a064abe330b14f988d44f98ff289a63e@46958_oswg24793oswg750oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但是很显然，事情并没有这么理想。因为就在近日，一份来自索尼内部的相关资料被曝光，其中就显示他们至少在下一个财年开始之前，都不会推出新的Xperia 5系列机型。而相关的理由则是“市场需求发生了变化，Xperia 5的市场被Xepria 1覆盖”。</p><h2><strong>索尼手机的困难，其实从一开始就有了苗头</strong></h2><p>说实话，我们并不知道是不是真的有许多原本期待Xperia 5系列新机的人，现在都去买了Xperia 1 VI。但如今可以看到的现象，是索尼手机最近这几年无论在产品力、还是市场的声量上，都呈现出了比较明显的萎缩态势。</p><p>为什么会这样？要探究这个问题，就需要将时间拉回到十几年前，以“分阶段”的形式来讨论索尼手机的历史。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_580b1519c911435582b3e00663edd900@46958_oswg43405oswg750oswg361_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>早在2010年1月15日，索尼（当时还是索尼爱立信）发布了旗下首款安卓手机Xperia X10。在当时那个年代，Xperia这个品牌才刚成立没多久，此前推出的WM系统侧滑盖机型Xperia X1、X2，以及带有技术探索性质的透明屏概念机Xepria X5，都给外界留下了“做工极致、设计有巧思”的良好印象。&nbsp;</p><p>正因如此，Xperia X10初期的“卖相”还挺不错。但熟悉安卓系统历史的朋友看到这款机型的发布时间，可能就会意识到一个问题。没错，安卓2.1发布于2010年1月12日，可数天后公布的Xperia X10，搭载的却还是界面和功能都已经过时的安卓1.6，甚至都不是此前就已发布的安卓2.0。从某种程度上来说，软件技术力不足、对市场需求“反应慢”的问题，其实早在这个阶段就已经在索尼手机上开始暴露了。&nbsp;</p><h2><strong>One SONY战略，整合真的很成功…吗？</strong></h2><p>或许是意识到自己在系统适配、软件优化方面的水平，无法与当时的三星、HTC，甚至LG等对手竞争，索尼（索爱）很快就调整了手机产品的战略。从他们的第二代旗舰机Xperia ARC（LT15i）开始，一些号称源自索尼电视、音频、相机部门的技术，也被陆续“搭载”到了智能手机上。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_9ed7d66cba71496582e2061779e0c5cd@46958_oswg38200oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不得不说，这种后来被称之为“One SONY”的产品战略，一度起到了非常好的市场效果。当时在许多手机论坛中，大家都能看到各种关于索尼（索爱）手机内置播放器、相机、音效，甚至是屏幕优化算法的讨论帖子。许多其他品牌机型的用户更是会想尽办法，要把索尼手机的这些功能“移植”到他们自己用的手机上。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b1292a7b94534e028984f2a522a980f9@46958_oswg49863oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这款未发布的索尼Walkman手机，播放器中其实并不包含真正的Walkman音效系统&nbsp;</p><p>但也就是在这个过程中，大家逐渐发现虽然索尼（索爱）手机看似拥有“Walkman”音乐播放器，但却并没使用Walkman引以为傲的S-Master数码放大器芯片；虽然索尼（索爱）手机拥有“Cybershot”相机APP，但它也没有真正使用索尼自研的BIONZ图像处理芯片；虽然索尼（索爱）手机号称屏幕具备BRAVIA电视的优化技术，但也仅仅只是个软件调色插件，并非真正的索尼自研电视芯片在里面起作用。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_83a41213708b4ac99a63a6b1f0fd13b0@46958_oswg32749oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">大名鼎鼎的PSP Phone，结果并不能直接兼容PSP&nbsp;</p><p>没错，这种“表面团结，但实则各个部门都没有将核心技术交出来”的所谓“One SONY”，可以说是一直持续到了该战略名义上结束的那一天。以结果而言，它使得彼时的索尼粉丝几乎每一次都是期待满满地购入新机，然后因为实际（音质、拍照、屏幕）表现严重不符合预期而一次次的失望。&nbsp;</p><h2><strong>独特设计撑起5G变革，但糟心体验也几乎从未改变</strong></h2><p>然后，时间来到了2019年。这一年全球手机市场正式迈入5G时代，索尼也将整个手机产品线“推倒重来”，推出了Xperia 1、Xperia 5、Xperia 10等全新命名的产品体系。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_edfe96ca54bd45978c6f2020e449897d@46958_oswg24260oswg750oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有一说一，直到去年的Xperia 1 V为止，我们对于这一批索尼手机的观感一直都还不错。特别是其中的Xperia 1系列和Xperia 5系列，一个拥有独特的细长机身、4K HDR屏幕，另一个则坚持在做“小屏旗舰”。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_061763477f404693a9eedbff71f175a4@46958_oswg19660oswg750oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2019年我们在MWC现场见证了初代Xepria 1的发布&nbsp;</p><p>而且与其他厂商的产品相比，索尼一直坚持使用双正出音扬声器、不用开孔屏、配备3.5mm耳机孔、采用无卡针SIM卡托盘、支持TF卡扩展。再加上最近几代Xperia 1系列机型所配备的“真光学变焦”潜望式长焦，以及具备960次/秒超高速对焦能力的自研双层晶体管CMOS，要说“独步业界”也确实是没错。&nbsp;</p><p>然而在这些看起来非常独特，甚至可以说技术“遥遥领先”的设计背后，索尼手机的体验又是否真的足够好了呢？事实上，哪怕不是忠实的索尼手机用户，在互联网上搜索一下就会发现，大把的“老粉”在吐槽如今索尼手机的使用体验。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_fbea00ee0ae74296b29179e636f7c157@46958_oswg49879oswg750oswg569_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>理念很对的正出音扬声器、音质和音量都不如别家看似更普通的底部扬声器设计；4K HDR的屏幕分辨率看似很高，但不仅在绝大多数APP里会降分辨率渲染，而且屏幕的亮度和功耗都远远落后于行业主流水平；连续变焦的潜望式长焦看似“黑科技”，但也正因为它是“真变焦”，所以实际拍摄时的画质衰减、对焦距离都极其糟糕，远远不如其他家基于定焦镜头的“算法变焦”。再加上没有快充、机身发热控制极其糟糕，自带的相机APP完全不考虑日常易用性等细节，都可以说都是在一次又一次地消耗着“索尼粉丝”的耐心。&nbsp;</p><h2><strong>结语：过分轻视大众用户需求，索尼手机路在何方</strong></h2><p>其实早在数年前我们三易生活就曾指出，索尼“造手机”的目的如今早已不是为了赚钱，反而更像是把手机当做了自家CMOS传感器、专业相机/摄像机、无线音频等其他业务的“推广平台”。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_60859e5cbcec4473b4fe59a34ae2092e@46958_oswg55148oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">索尼在自家手机的展台上，都不忘推介自己的CMOS产品线&nbsp;</p><p>所以大家会看到，索尼手机几乎从来就不会使用那种本就“卖得很好”的主流CMOS，而是专挑一些特殊规格的传感器，而且在宣传时会故意提到功能近似的索尼相机。它摄像功能是很难用，但也确实可以帮用户“熟悉”索尼专业单反、专业摄像机的操作逻辑。而索尼手机那块亮度不够高的4K屏，其理由之一也是为了追求与索尼电视、摄像机在色彩观感上的“一致性”，反正也没人会真的把家用电视放在室外观看不是。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f9d060f58b3b4fff953689a542eae91e@46958_oswg12300oswg750oswg332_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而也正因为是这样的设计思路，就导致索尼手机无论硬件配置的竞争力，还是从用户实际的使用体验来说，都显得与主流市场“格格不入”。老实说，这其实也会让它得到部分极客玩家的青睐，但对于大众市场来说，这显然就会严重影响它的“钱途”。&nbsp;</p><p>一旦大多数消费者对于“索尼手机配置奇葩、体验不佳”的印象愈发扩散，那么随着索尼手机销量的下降，其产品所能够承载的研发成本，自然也不得不大打折扣。没错，这一结果的直接体现，实际上便是目前这一代造型大改，但主摄没变、性能释放依然不太行，屏幕更是从4K直接“降级”到1080P的Xperia 1 VI了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_2d480cc052cd43c6a9e3fd773e2758fc@46958_oswg24072oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2018年4月，平井一夫在索尼魅力赏期间提出的产品理念&nbsp;</p><p>老实说，索尼是真的没有能力把手机做得特别出类拔萃吗？我们并不这样认为。实际上从以往的历史来看，真正造成索尼手机市场竞争力不断下降的原因，反而是并不成功的“One SONY”战略。&nbsp;</p><p>大家不妨试想一下，如果索尼不去强行用手机“蹭”自家其他产品的卖点，不去“闭门造车”做那些半吊子的设计，而是更积极地贴合市场需求，靠着自身强大的半导体技术、色彩科学、音频技术去做真正的“加法”，那么索尼手机如今的市场竞争力真不见得会输给三星。&nbsp;</p><p>然而历史并不允许“如果”，对于产品节奏明显日趋迟缓的索尼移动部门来说，如今的他们到底还能怎样“翻身”，可能会是未来几年最大的悬念。&nbsp;</p><p>【本文图片来自网络】&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/HAQjMaHN35E-2PEcZv429Q" rel="noopener noreferrer nofollow" target="_blank">“三易生活”</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958309024669316</id>
            <title>不只是炒菜，AI正在全面渗透餐饮</title>
            <link>https://www.36kr.com/p/2958309024669316</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958309024669316</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 12:53:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI推动餐饮行业智能化革命，机器人正取代厨师、制茶师、咖啡师。</p><p>9月13日，北京市发出首张“具身智能机器人食品经营许可证”。</p><p>所谓具身智能机器人，指将人工智能融入机器人这个物理实体，赋予机器人感知、学习和与环境动态交互的能力。</p><p>不同于市面上大多炒菜机器人只能完成单一任务，这款具身智能机器人可以主动判断食材、自主控制烹饪时间及食品风味口感，通过自主学习不断“解锁”新菜单，还能根据工作环境判断和上报安全隐患。</p><p>生产该机器人的享刻智能公司创始人陈震表示，接下来，公司还将推出会做甜品、饮料、沙拉等美食的机器人。</p><p>近年来，AI正以迅雷不及掩耳之势席卷全球，AI技术也逐步渗透到餐饮业的各个环节，其中最引人关注的就是AI餐饮机器人。</p><p>实际上，除了AI餐饮机器人，随着ChatGPT，文心一言、智普清言等诸多大模型的出现，餐饮行业垂直领域的烹饪大模型也纷纷面世。</p><p>此外，一些先行者，还将AI技术用于餐饮营销。</p><p>不难发现，传统餐饮行业正经历一场全方位的智能化变革。作为餐饮人，谁能在这场AI革命中抓住机遇，谁无疑能在激烈的市场竞争中占据优势。</p><h2><strong>AI餐饮机器人不只会炒菜</strong></h2><p>8月，全国首台持证AI机器人“大厨”落地北京亦庄。</p><p>此前，北京部分地铁站推出了机器人摊煎饼的试运营服务，可以远程预约下单，实现智能排队，随到随取，创造了全新的餐饮体验。</p><p>与初代煎饼果子机器人相比，这款机器人更加“智能”，顾客可以自主选择是否添加香菜、葱花，还可以选择是否添加香肠，制作过程仅需2分40秒。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a80e65411c9d4749924460ce7458a001@6064632_oswg94279oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>久秉AI餐饮总经理于钦玮表示，这款机器人能自动完成上浆制饼、摊制鸡蛋、自动翻面，还能根据个人需要订制口味，制作完成之后，自动折叠并且包装，实现了全自动化过程。</p><p>目前，久秉机器人旗下其他类型AI餐饮机器人也实现了类似的功能，未来，同一款机器人不仅能摊煎饼，还能包包子、蒸包子。</p><p>并且这些机器人都具备自我学习能力，可在制作过程中不断纠错。</p><p>久秉AI餐饮官网显示，使用AI餐饮机器人不需要培养厨师，只需要培养维保人员，1名维保人员可以看守3到5台机器人，让餐饮品牌实现快速连锁。同时，还可以实现24小时出餐。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_02b9f9f3abeb40558cd023337916a404@6064632_oswg107622oswg844oswg1124_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如今，AI机器人已全面渗透到餐食、饮料制作，不仅提高了效率，还大大节省了人力。</p><p>最近，“美膳狮”AI炒菜机器人向湘菜大师杨孙师傅发起PK，引发行业关注。</p><p>双方共炒了三道菜：XO酱笋炒海螺，小炒黄牛肉和辣椒炒肉。机器人用时3分08秒，杨大厨用时9分32秒，色香味上，二者难分伯仲。</p><p>“美膳狮”由橡鹿科技研发，目前已在金鼎轩、大米先生、清风包子铺、农耕记、希尔顿、全季酒店等多品牌场景落地。</p><p>7月22日，橡鹿科技称，获得京东近2亿元战略投资，本次融资后，将继续加大对AI炒菜机器人上下游产业链基础设施的投入，其新一代AI炒菜机器人将于2025年正式推出。</p><p>与此同时，起源于美国硅谷的饮料机器人制造商Botrista也于近期宣布完成6500万美元的C轮融资。其打造的饮料机器人DrinkBot，能够在20秒内自动完成计量和混合等任务，生产出冰茶、咖啡和柠檬汁等多种饮料。</p><h2><strong>AI烹饪大模型相继问世</strong></h2><p>在ChatGPT、Gemini、文心一言、通义千问等各种大模型如雨后春笋般涌现后，餐饮垂直行业的烹饪大模型也应运而生。</p><p>6月，“食神”AI烹饪大模型问世，该大模型由老板电器发布。相对于传统厨电的硬件工具属性，AI烹饪大模型“食神”更像是一个与用户心意相通的烹饪伙伴。</p><p>“食神”能通过观察烹饪空间里的温度、时间、光照、声音、气味，感知用户的角色、身份、情绪、动作，并将用户的个性化数据与大模型数据匹配，为每个用户规划出最适合的烹饪全链路整体解决方案。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_ca36bd431d864b5aa1c698a2e802a577@6064632_oswg45941oswg705oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这款大模型不仅降低了烹饪的门槛，更激发了烹饪创作的乐趣。区别于其他烹饪类的大模型，“食神”不仅起到了功能性的辅助，更包含了生理、心理、哲学、审美、文化历史、人情世故等等关于烹饪的一切，这是一个“有情绪”“拟人化”的大模型。</p><p>作为生成式AI大模型，“食神”可以为消费者提供烹饪上的指导，实现菜谱定制、营养计划制定、食材管理、烹饪技法选择、菜品制作等功能。</p><p>万得厨则打造出烹饪大模型“祝融”，同时还研发出一台AI时代的厨房新物种——厨房智能体，其中“祝融”被搭载于厨房智能体中。</p><p>“祝融”经由100+位国内名厨长达4年的1000道家常菜研究、超100万次模仿人类厨师的烹饪调教，从而彻底掌握中式烹饪精髓，让各类菜品烹饪得心应手。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_4c3e62f3316e4ec58d4ef96f5a2beae5@6064632_oswg148164oswg797oswg1063_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>厨房智能体和传统厨电的区别，就像自动驾驶相较于传统汽车，是一个基于AI科技的新物种。自动驾驶可以自动根据路况做出行车判断，厨房智能体则能够根据用户放入的食材自动选择烹饪方式。</p><p>随着烹饪大模型的问世，在更垂直的餐饮监管领域，AI科技也开始大展身手。</p><p>中国移动“千里眼”视频AI技术推出“明厨亮灶”解决方案，通过“千里眼”平台，可以实时了解餐饮企业后厨的实际情况，通过AI智能分析方面，对后厨的卫生和操作规范进行智能识别和分析，以及时发现潜在的安全隐患。</p><p>据了解，此平台已覆盖900个餐饮点位，有效提升了食品安全水平。</p><h2><strong>AI渗透到餐饮营销</strong></h2><p>AI机器人、AI烹饪大模型，具有很强的话题性，自带营销属性。实际上，AI技术本身也已经被用于餐饮营销。</p><p>在国外AI绘画平台midjourney上，已经出现了各种菜品的绘制图片，其逼真程度几乎可以以假乱真。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a75aca54b6194e5081265f8cbb7ad566@6064632_oswg111757oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>实际上，在一些AI绘画培训课程中，已经有专门针对餐饮行业的培训。据了解，在我要自学网中的midjourney培训课程中，就有课程讲述专门针对餐饮行业如何使用AI美食摄影。</p><p>餐饮店做外卖就需要将菜品上传到各大外卖平台，如果产品的图片不美观就不能吸引人，如果请专业摄影师则又价格太贵。</p><p>“用AI画出产品图后，与真实的产品会有差距，虽然不能直接使用，但是通过PS进行局部修改就可以了，大大节约了拍摄成本。”。</p><p>在餐饮产品与广告的设计上，AI技术也已经被使用，已经出现了餐饮AI广告。</p><p>不久前，麦当劳日本委托AI数字创作者制作了一条薯条广告，一共10个AI生成的少女形象和麦当劳薯条互动，15秒的视频很快获得了上千万的浏览量，就连马斯克也表示“酷”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f7c235e0f6e843e18615b1f678a90c8a@6064632_oswg105291oswg1080oswg1445_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>去年，一个外国网友利用AI工具制作了一条披萨广告，推特上播放量达80多万，同样引发关注。这条完整的披萨广告，从文案，配音，音乐，画面到视频动画，都由AI工具完成。</p><p>除了广告宣传，AI还被用来打造品牌——不仅用于给品牌命名，还被用来给品牌制作logo。</p><p>AI品牌设计生成平台uBrand，在其官网上展示了8个用AI设计的logo案例，包括川菜、湘菜、卤味、面馆、炸鸡店、火锅店、汉堡店。此外，专注AI职业教育的虎课网，出现了讲述如何使用AI制作餐饮品牌logo的详细攻略。</p><p>在餐饮营销上，品牌的命名、品牌logo的设计、产品的拍摄、广告的制作，甚至活动的策划、文案的撰写，都可以用AI来辅助完成。</p><p>值得注意的是，随着AI技术在餐饮行业的全面渗透，监管部门的监管力度也在加大，比如近期，印度一外卖平台就表示禁止使用AI生成美食图片。</p><p>图片来源于网络</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkwNjY3MjEzNQ==&amp;mid=2247491756&amp;idx=1&amp;sn=f528c772acaeb2c2101d941c3933ce69&amp;chksm=c0e641c4f791c8d273961560329f31fe4c36d0e9bff473c05b5c856681e70750c071706686f7#rd" rel="noopener noreferrer nofollow" target="_blank">“新餐考”</a>，作者：明华锋，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958322925391113</id>
            <title>强推Ultra HDR，谷歌为移动影像的未来操碎了心</title>
            <link>https://www.36kr.com/p/2958322925391113</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958322925391113</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 12:50:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>期待人工智能让整个行业迎来天降甘霖，这或许是目前绝大多数手机圈从业者的心声。然而以当下的硬件水平，AI手机还有些过于高远，反倒是继续打磨影像能力才是务实之举。日前有消息显示，在Android 15即将全面铺开的节点，谷歌方面正在对兼容性定义文档进行修改，未来声明支持性能等级15的设备必须支持Ultra HDR。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_85b522a0d9254456a1b0e08fc286ffa6@46958_oswg37580oswg600oswg254_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据谷歌的说法，Android设备要声明性能等级达到15，则必须支持后置主摄和前置主摄都可以输出JPEG_R，并且必须在原生相机应用中将默认输出格式设置为JPEG_R。谷歌的意思并不是只有支持Ultra HDR的Android手机才可以升至Android 15，而是如果手机厂商要声明设备性能等级为15，就需要支持Ultra HDR。</p><p>如果对于Android系统本身的历次版本更新不甚关注，恐怕会对谷歌这一操作一头雾水。我们先来进行一下名词解释，其中“性能等级”是谷歌在Android 12上引入的认证标准功能。其将Android设备分为不同的性能等级，App开发者就可以根据不同设备的性能等级来进行优化，比如在性能等级低的设备上，开发者就可以选择减少一些非必要的动画，从而让设备能够流畅运行。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_8e90c370fdce4ca7a396deaad433e695@46958_oswg22278oswg600oswg333_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Ultra HDR则是谷歌在Android 14上推出的一种静态图片高动态范围显示标准，它在标准JPG图像中添加了HDR增益图，从而实现更高质量的图像展示。在隔壁苹果从iPhone 11的超视网膜XDR屏幕开始，就一直在力推手机上的HDR，谷歌自然不想落后于人，也希望自家的Ultra HDR成为Android手机内置相机应用和相机App的默认配置。</p><p>可是即便谷歌在Android 14的更新日志里花大篇幅介绍Ultra HDR，还找来高通和联发科两大移动平台厂商助阵，但现实却是自Android 14上线以来，手机厂商兴趣缺缺，目前仅有OPPO Find X7 Ultra等少数旗舰机型支持，因此这也是谷歌如今把Ultra HDR要纳入性能等级评判标准的原因。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b3498937fa634fefb54d150e1f39d3cf@46958_oswg19207oswg600oswg440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Android阵营手机厂商对于谷歌的Ultra HDR兴致不高，并不是因为Ultra HDR本身不给力，而是在HDR显示方面，这些厂商各有各的想法，例如vivo有XDR Photo、OPPO有ProXDR、荣耀则是全链路高速E-HDR。为了开发出自家的HDR显示以及对应的色彩管理技术，各家都是花了大价钱，又岂有说不要就不要的道理。</p><p>对此谷歌的做法是将Ultra HDR加入兼容性定义文档（CCD），将之作为获得GMS认证的条件。对于当下的Android手机厂商来说，耕耘全球市场已经成为基础操作，所以没有哪个厂商会选择放弃对旗下机型进行GMS认证。那么谷歌强制推行Ultra HDR，对于普通用户来说又有什么影响呢？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f1e0fe7c31d140eba462aed0064f4cb4@46958_oswg29671oswg600oswg589_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事实上，这一次谷歌确实是为普通用户、特别是非旗舰机用户着想。高动态范围图像（High-Dynamic Range）是过去几年各大手机厂商在屏幕素质上进行军备竞赛的核心战场，这是一种提高影像亮度与对比度的处理技术，可以将画面的每个暗部细节变亮，使得暗的地方更暗，并丰富更多的细节色彩。</p><p>相比普通图像，HDR技术可以提供更多的动态范围与图像细节，让用户在观看时获得更接近真实环境的视觉感受。而在手机端的HDR显示推广过程中，最大的难题是HDR内容流通受限，HDR内容并不能直接在SDR（标准动态范围）屏幕上正确显示，由此也导致相当多的内容等于是拒绝中低端设备使用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_2a3adfc473ab44199ec080c85f0015b8@46958_oswg36158oswg600oswg297_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>试想一下，用旗舰机拍出的HDR照片却无法分享给使用中低端机型的朋友，这种体验无疑很糟糕。而谷歌Ultra HDR最大的魅力就是提供了兼容性，支持HDR显示的Android设备能够以高动态范围显示，不支持的设备则会以SDR JPEG格式显示图像。</p><p>Ultra HDR实际上是使用两个8-bit位深的JPEG来还原拍摄场景的高动态范围，其中一个是普通的8位标准动态范围（SDR）图像、称为Primary image（主图），另一个则是Gainmap（增益图），后者存储了额外的HDR增益映射数据。与传统的HDR处理相比，Ultra HDR图像看起来更加自然，是因为它省略了色调映射的过程。</p><p>如此一来，即使用户手机的屏幕不支持HDR，但只要它的性能等级达到15，就也能看到同样的图片。在Android 14之前，由于各大手机厂商的HDR技术路线有差异，就导致App开发者对于HDR不感冒，因为适配不同标准的工程量太大。Ultra HDR在Android阵营的强制推行就有望改变这个现状，因为统一的HDR格式必然会为第三方适配提供便利。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_fbbcbd2d1fc2449d9eb5d4ed0ecdfc67@46958_oswg27972oswg600oswg321_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>正如Android操作系统领域专家Mishaal Rahman所言，“尽管还是一种很新的图像格式，但Ultra HDR将成为移动摄影的未来”。只可惜在谷歌的强行推动下，Ultra HDR大概率会成为Android生态的通行标准，可OPPO等厂商此前花费大量资源自研的相关技术，恐怕就要被丢在故纸堆里了。</p><p>只能说，谁让谷歌才是Android生态的掌舵人呢？</p><p>【本文图片来自网络】&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/cw6TR5blHriZmr0yq1Lfig" rel="noopener noreferrer nofollow" target="_blank">“三易生活”</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958323088248065</id>
            <title>iOS 18的这个新变化，让第三方维修商彻底懵了</title>
            <link>https://www.36kr.com/p/2958323088248065</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958323088248065</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 12:48:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>此前在经过以iFixlt为代表的民间组织多年的呼吁之后，2021年秋季苹果在维修权一事上松口、推出了自助维修计划，允许用户和自行维修iPhone、iPad等机型。再加上2019年秋季的独立维修商计划，自此之后，苹果设备的用户在维修自己的iPhone、iPad、Apple Watch等设备时有了更多的选择。</p><p>苹果在维修权上的退让不仅让用户有了更多选择，也养肥了以“华强北”为代表的第三方维修商。如今在iPhone 16系列发布的同时，有消息显示iOS 18也悄然更新了一个名为“iPhone零部件激活锁”的新功能。用户或维修人员运行自助维修诊断工具时，如果检测到零部件来自另一部启用了激活锁或丢失模式的设备时，该部件的校准功能就将受到限制。</p><p>比如，系统检测到屏幕来自其他已经被锁定的设备，就会直接提示“显示屏已与物主锁定”。这个消息一出，诸多第三方维修商都“炸了锅”，因为目前大量第三方维修机构提供的所谓“原厂件”，其实并不是通过用户自助维修计划或独立维修商计划获得。如果有去第三方维修商修理iPhone的经历就会知道，第三方提供的所谓原厂零件往往只有苹果官方价格的一半。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_bb05d35a896d4c019d84240738e0c1c4@46958_oswg26805oswg405oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>毕竟第三方维修商并非慈善机构，这一类原厂零件虽然的确是正品，但来路或许不正，许多甚至可能是来自所谓的“配件机”。而所谓“配件机”，很大一部分是来自盗抢iPhone，由于丢失模式的存在，这些iPhone基本就失去了二次出售的机会，通常会被出售给第三方维修机构。另一部分“配件机”则是由各租机平台的监管机构成，部分第三方维修机构也会回收不法分子租赁的苹果设备。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_768ef8014ec9480f8542aea91f7a9183@46958_oswg25224oswg401oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>来源不合法，这就是第三方维修机构的原厂零件很便宜的原因。同时在iOS 18之前，如果手机中存在换拆机配件、也就是非官方提供的零部件，还可以通过系统内置的诊断功能将原本显示的未知部件再修改显示为正品。换而言之，目前只要零部件本身是出自苹果体系就能正常使用，这也是有人呼吁有过维修经历的iPhone不要升级iOS 18的原因。</p><p>未来如果用户再去没有相关资质的第三方维修商替换原厂零件，因为零部件激活锁导致设备变砖的概率就变得相当大，而这也正是苹果方面想要看的结果。苹果给这些第三方维修商上眼药其实并不令人感到意外，毕竟给处于丢失模式的iPhone加锁，也就意味着被偷盗的iPhone将彻底失去价值，既不能作为整体出售、也不能拆机卖零件。如此一来，失去价值的iPhone也就缺少了被偷盗的理由。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_06b8f4092af24b86be442ba193def242@46958_oswg42782oswg600oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与此同时，苹果此举也会扶植自家的授权服务商和独立维修商。此前在今年4月，苹果方面宣布将对现有的维修流程进行改进，自今年秋季开始，部分iPhone机型将支持用户和独立维修商使用二手零件进行维修。为了确保二手零部件的质量和性能，苹果引入了新部件的校准程序，该程序会对使用过的零部件进行检测和校准，以确保其符合苹果的标准，由此也让如今的“iPhone零部件激活锁”有了落地的机会。</p><p>过去为什么用户对于自主维修以及独立维修商不感冒，反而更偏爱无资质的第三方维修机构，就是因为苹果提供的零部件价格不菲。以iPhone 15 Pro Max为例，一旦摔机导致屏幕和玻璃后盖碎裂，维修价格将高达4099元。显而易见，此时许多人都会选择更便宜的原厂零部件，即使它的来源可能不明。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_1163c05b543240139fd8f6d0cb64a6e1@46958_oswg25596oswg523oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>众所周知，维修售后一向都有着暴利，特别是对于第三方维修机构而言。可一旦“iPhone零部件激活锁”正式上线，用户就只能去购买价格更贵、但有保障的合规零件，这时候第三方维修机构的价格优势就无法体现了。毕竟来源不明的原厂零件确实便宜，但让设备无法使用的代价没有人会接受。</p><p>从2022年被广泛指责的“零件序列化”、既每一个零件都拥有18位数的序列号，这一策略的效果是如果零件的序列号合规就可以正常使用，反之就会出错。比如用户如果更换第三方屏幕，就会有概率收到Face ID将停止工作的“Face ID Is Not Available”通知，一旦第三方零件可能时灵时不灵，就直接毁灭了它的生存空间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_77421bf0548944c58d07315f0cb5b96b@46958_oswg16753oswg512oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再到现在的原厂零件可溯源，让用户只能购买苹果指定的维修零件，这一套组合拳打下来，苹果在“私拆拒保”被从法律层面否定后，再一次获得了对自家设备“生杀予夺”的权力。</p><p>【本文图片来自网络】&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/F5vrXQx15z1R43A3H-qJoA" rel="noopener noreferrer nofollow" target="_blank">“三易生活”</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958323400412160</id>
            <title>智能可穿戴设备专业化已成趋势，将惠及更多用户</title>
            <link>https://www.36kr.com/p/2958323400412160</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958323400412160</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 12:47:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在日前苹果方面举行的秋季新品发布会上，推出了近年来升级幅度最大的智能手表产品Apple Watch Series 10。其搭载SiP10芯片，配备有四核神经网络单元，内置深度计和水温传感器，可记录用户的水上运动轨迹，同时还新增潮汐检测功能，并加入了全新的睡眠呼吸暂停检测能力。除此之外，AirPods Pro 2还将通过固件更新的方式新增听力健康相关功能，并提供临床级助听器模式。</p><p>随着相关技术的大幅进步，智能手表、耳机等可穿戴设备已然踏上了专业化、精细化的发展路径，这个变化无疑也正是技术进步赋能用户日常生活的一种重要体现。</p><p>其中在健康监测领域，此前智能可穿戴设备受算力、算法，以及传感器等方面的局限，功能往往只能停留在简单的心率监测、睡眠分析层面。但随着相关技术的进步和算法的不断优化，这类设备已经能够胜任越来越复杂、专业的健康监测功能。而通过与专业医疗机构的合作，部分智能可穿戴设备不仅能提供监测数据，甚至还可以基于这些数据来给出相关建议。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_671845509df247b08822efc528e9feed@46958_oswg18132oswg550oswg340_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前在高端智能手表产品中，ECG心电监测几乎已经成为标配功能，通过更准确的心电数据报告，可以帮助用户及早发现心律失常等疾病的迹象。血氧水平监测也同样如此，监测这一数据可帮助用户预防诸如高原反应、监测肺部疾病等。相比以往想要获得这些数据，还需要前往专业医疗机构、借助专业设备检测，例如某些慢性疾病就需进行24小时的动态心电图检测，不仅过程繁琐，还要受限于时间和地点的束缚。</p><p>但智能手表相关功能的进化，使得这些初步检测可以轻松地就在手腕上随时随地进行，甚至还能够通过直观的图表和数据分析，让监测结果更容易理解，从而帮助用户及时发现潜在的健康问题，还能为后续的诊疗提供数据参考。正是在这种专业化趋势的影响下，智能手表产品取得医疗器械认证近年来也变得越来越普遍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_eaedfdd66c4040ae9da2bb2925668236@46958_oswg33315oswg550oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此次Apple Watch Series 10引入的睡眠呼吸暂停检测，则是这类产品专业化趋势进一步深入的体现。事实上，睡眠呼吸暂停是一种成因复杂的综合症，但其与个人隐私又高度相关。Apple Watch Series 10通过改进睡眠监测算法，引入“呼吸紊乱”评估指标，实现了对中度或重度睡眠呼吸暂停症状发出预警、并提供相关报告。显然这一功能的加入，为存在睡眠呼吸暂停风险的用户就带来了更为便利的监测方式。</p><p>值得一提的是，睡眠呼吸暂停检测并非Apple Watch Series 10专属，小米、OPPO、华为等厂商也有进行相关研究，并将与学术机构和医疗机构合作取得的成果引入到相关产品中。虽然目前智能可穿戴设备所提供的监测数据仅能为临床诊断提供参考，但其这些功能的转变也体现出技术进步普惠更多用户的趋势，随着智能可穿戴设备的普及与相关功能的不断升级，未来势必将会有更多用户因此而受益。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_c73bb7295fd644ddb77c740efa66129e@46958_oswg23526oswg550oswg352_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智能可穿戴设备向着更为专业化方向发展的趋势，不仅体现在核心的健康监测功能上，在无障碍领域也开辟了新的市场空间。其中，AirPods Pro 2此次的功能升级更是将这一点推向了新高度，其通过提供主动听力保护、经科学验证的听力测试和临床级助听器功能，实现了全球首款端到端听力健康体验。</p><p>AirPods Pro 2此次的升级，实际上是提供了一套包括系统、硬件、算法的综合解决方案，苹果为此也提前进行了多方面的布局。早在2018年，苹果方面就为iOS引入了“即时聆听”功能，支持将iPhone作为麦克风来拾音，从而帮助用户借助AirPods即时聆听。随后在2021年，又为AirPods Pro系列新增了“对话增强”辅助功能，加强了耳机麦克风从前方收音的能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_458e657e94174849a4ff4a956557c0b9@46958_oswg28463oswg550oswg308_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>苹果此次拓展无障碍应用的边界，更为重要的是AirPods Pro 2实现了错位竞争，使得TWS耳机不再被局限于消费级市场，转而能够向专业级领域渗透。众所周知，耳机的前身虽然是助听器，但由于两者的侧重点存在本质的不同，因此也一直泾渭分明，而AirPods Pro 2此次的升级则突破了这种限制，为有助听辅助需求的用户带来了更多的选择。</p><p>从使用成本的角度来看，助听器这类产品的售价一直都较为高昂，并且价格还会因听力受损程度、定制需求等因素进一步提高。相比之下，AirPods Pro 2虽然在TWS耳机中算不上便宜，但与专业的助听器相比显然就要亲民得多。在人文关怀的角度，助听器产品由于有着独特的外观设计和佩戴方式，因此就可能会为用户引来“特别关注”，在这一点上AirPods Pro 2显然在外观上就要“普通”得多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_4a21d4dfa48e47509fef54c50dc58525@46958_oswg18817oswg550oswg367_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">大部分助听器在外观设计和佩戴方式上与普通耳机有着明显差异</p><p>智能可穿戴设备在运动监测以及其他领域的专业化趋势，也通过产品的差异化精准触达、并满足了不同用户群体的需求，进一步挖掘了更多细分市场的潜力。其中，Apple Watch Series 10加入的潮汐检测功能，便是其在这一方向上的探索，从而满足冲浪爱好者的需求。</p><p>除此之外，诸如华米智能手表增强钓鱼模式，同样也是对用户需求的一种深度定制，其通过提供钓鱼相关的气压、温度、湿度等数据监测，来帮助用户更好地判断鱼情。而华为旗舰智能手表所提供的高尔夫模式，也是专业化策略的一环，其通过提供球场地图、挥杆数据分析等信息，来帮助用户制定更合理的击球策略。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_7518e1d4836847bb8373a1ab7300567e@46958_oswg26531oswg550oswg365_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在竞争已经变得愈发激烈的这一市场中，智能可穿戴设备仅凭基础功能显然已经很难以满足越来越多用户的需求，因此深入挖掘专业功能所带来的差异化，也就成为了拓展更多市场的重要一环。因此后续这类产品的专业化趋势必然将会继续深入，相关厂商也将通过不断探索细分化的使用场景、创新功能设计，以及优化用户体验等方式，带来更符合用户多元化需求的产品。</p><p>【本文图片来自网络】&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/qj6BiODUZFQ1zVQ4DLHVdw" rel="noopener noreferrer nofollow" target="_blank">“三易生活”</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958279294475904</id>
            <title>iPhone 16性能测试：A18升级大，下一代钉子户手机？</title>
            <link>https://www.36kr.com/p/2958279294475904</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958279294475904</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 12:24:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2007年，乔布斯在苹果发布会上带来了一款改变整个手机市场的产品——<strong>iPhone</strong>。</p><p>不同于其他产品的触屏生态，更高性能的核心硬件配置，搭配上超越同时代的产品设计，正是从那个时间段开始，iPhone成为不少消费者心中的高端代表，年年增长的销量也证实了其在高端手机市场中的实力。</p><p>特别是性能部分，要知道在手机行业可是长期流行着一个说法，那就是“苹果自研芯片领先安卓旗舰芯片整整两年时间”，无论是硬件还是软件上的体验都很出色，这也导致常年来iPhone一直都是手机市场的标杆产品。</p><p><strong>然后呢，在17年后的今天，iPhone 16系列终于开售了。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_0a4620b8a4ff41a481efba0294b0b52f@1547419282_oswg71652oswg1200oswg675_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：苹果）</p><p>尽管已经做好了预期，但是今年的iPhone 16标准版依然可以用乏善可陈来形容，高刷、AOD等功能依然缺席，此前曝光里提到的256GB起售、40W充电也全都“鸽”了，唯一让人有点心动的，也就是A18这款芯片的提升。</p><p>作为苹果首款专为AI设计的iPhone芯片，A18芯片在架构上与前代产品显然有着不少区别，但是放在短时间内用不上Apple Intelligence的国内市场环境下，很多读者估计还是好奇，A18芯片到底较前代有多少提升？和类似定位的小屏安卓旗舰又有着怎样的差距呢？</p><p><strong>趁着iPhone 16首发上手的这个节点，就让小雷与大家好好聊聊，这个被苹果寄予厚望的iPhone「芯」，到底能有怎么样的性能表现吧！</strong></p><h2><strong>跑出154万分，A18性能惊艳</strong></h2><p>看到小标题，我想果粉们一定都会感慨万分吧。</p><p><strong>毕竟在iPhone 16系列之前，苹果已经连续两代在标准版与Pro版之间采用不同的代数芯片了。</strong></p><p>在两年前的iPhone 14系列身上，苹果就创新性地给标准版与Pro版就分别配备了A15和A16芯片，一时间惊为天人，而iPhone 15系列则更进一步，标准版是A16芯片，Pro版则上了A17 Pro芯片。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_40b8a06548da451084e7215fbae28a29@1547419282_oswg40205oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3b95ed1382cb4d3e8b44c7af111f0c30@1547419282_oswg84585oswg1030oswg590_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：苹果）</p><p>不过，为了让iPhone 16全系都可以支持Apple Intelligence，苹果再次对芯片方案进行了改革。</p><p>时隔两年后，iPhone再次回到了标准版与Pro版采用同代芯片的设计——分别是<strong>A18与A18 Pro芯片，这次两者的区别只在GPU上，A18配备了5核GPU，A18 Pro则配备了6核GPU。</strong></p><p><strong>令人感动，标准版总算是用上新芯片了。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_9e7e47d30c7545d3b2ff1a9eb2d838ab@1547419282_oswg101223oswg1706oswg1279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技）</p><p>在具体参数上，我们手上这台iPhone 16，配备了一枚全新的A18芯片，CPU采用的是六核架构，其中两个为性能核，四个为能效核，性能对比iPhone 15的A16芯片提升了30%的性能，功耗则降低了30%，如果对比iPhone 14和iPhone 13的A15芯片，CPU性能提升则高达50%。</p><p>接下来，咱们直接上测试。</p><p>先走一波<strong>Geekbench 6</strong>，CPU部分，<strong>A18单核得分为3252分，多核得分为7947分</strong>，相比A18 Pro ， A18的单核落后约4% ，多核落后约4% ，差距真的非常小，很有可能A18 Pro的CPU只比A18拉高了点主频。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_bcf3f66f48e44a3aad92e739a1ca861f@1547419282_oswg163517oswg1179oswg2556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技）</p><p>难得有这么大提升，怎么能不拉来A17 Pro、骁龙8 Gen3和天玑9300+比一比呢。</p><p>对比前代芯片，A18的单核提升了16% ，多核提升了6% ；对比骁龙8 Gen3，单核性能强42% ，多核性能强7% ；对比天玑9300+，这个差距缩窄到了单核性能强37%，多核性能强1%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_c730603ad4d2435e9b5e16e7bc12e69c@1547419282_oswg134853oswg1715oswg937_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技）</p><p>至于A16？</p><p><strong>就这A16有什么好比的，简直是秒杀啊。</strong></p><p>接着该走一波3DMark了，在Wlid Life Extreme测试中，<strong>iPhone 16跑出了4019分</strong>成绩；作为对比，A17 Pro是4266分，骁龙8 Gen3是4870分，带主动散热的骁龙8 Gen3领先版是5514分，而天玑9300+是5215分。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_256760fd551440c589a9f20ced08a969@1547419282_oswg3276164oswg1179oswg2556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技）</p><p>在通用平台测试中Solar Bay 中，iPhone 16跑出了6808分的成绩；作为对比，A17 Pro是6570分，骁龙8 Gen3是8979分，带主动散热的骁龙8 Gen3领先版是9276分，而天玑9300+是8288分。</p><p><strong>由此看来，少了一颗核心的A18芯片，在图形性能上对比去年的A17 Pro略逊一筹，而满血的A18 Pro在图像性能也就和A17 Pro差不多。</strong></p><p>最后可以再走一波安兔兔，iPhone 16跑出了154万分的综合成绩，其中CPU跑分42万分，GPU跑分57万分；作为对比，iPhone 15是133万分，而iPhone15 Pro是150万分左右。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_9e553e714ab749b1b1fb45bd5279972a@1547419282_oswg248131oswg1179oswg2556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_18baf744681c428cb62e4068d1ae2212@1547419282_oswg91346oswg1679oswg836_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技）</p><p>虽说这兔子跑分只能图一乐，但还是能看出明显的性能提升。</p><h2><strong>iPhone 16玩游戏，体验真可以</strong></h2><p>跑分提升不少，这是肉眼可见得了，但在实际的游戏体验中， A18性能表现又会如何？</p><p>为此，我特地选择了《鸣潮》、《巅峰极速》和《崩坏：星穹铁道》这三款重度游戏进行了测试，至于《英雄联盟手游》、《和平精英》这类轻度游戏，根本没有测试的必要，流畅性是十拿九稳的。</p><p>先来看看<strong>《鸣潮》</strong>，今年游戏圈里公认的性能杀手。</p><p>实测在高画质60帧的情况下，进行约15分钟《鸣潮》游戏流程，最终平均帧数为&nbsp;<strong>58FPS</strong>，只有剧情动画的时候会被锁定在30帧，不论是在城内探索、利用钩锁高速移动或是在户外大地图上面战斗的体验都挺不错的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_2ce3b791a5f947508c417427c79ddedc@1547419282_oswg641142oswg1917oswg766_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技）</p><p>然后是<strong>《巅峰极速》</strong>，算是赛车手游里的代表作品。</p><p>在极高画质60帧的情况下，进行约3-4局《巅峰极速》排位赛日常，iPhone 16的全程平均帧率来到<strong>59FPS</strong>，体验丝滑顺畅。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_8ef5813f1ccf4c3a8a0065ded966f2d0@1547419282_oswg618833oswg1902oswg770_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技）</p><p>最后是《星穹铁道》，榨干极限性能的米哈游新宠。</p><p>在高画质60帧的情况下，进行约15分钟《崩坏：星穹轨道》跑图，iPhone 16的平均帧率为57FPS，帧数曲线明显会因为机身发热而稳定下降，但是对一款RPG游戏来说算是妥妥畅玩了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_523cae3b42f14b7398f178f60362e786@1547419282_oswg377714oswg1909oswg775_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技）</p><p>实际测试下来，即便是很吃性能的重度手游，iPhone 16大致上也能够做到无压力征服，在《鸣潮》等沙盒游戏中的表现更是远超普通安卓旗舰手机，到了一种会让人怀疑是不是有整过专属优化的程度。</p><p>至于散热表现，我们手上这部iPhone 16在日常待机下的屏幕最高温度达到33.7°C，背面最高温度达到37.4°C，中框最高温度达到32.6°C；在游戏测试后的屏幕最高温度达到42.2°C，背面最高温度达到44.8°C，中框最高温度达到39.7°C，表现尚可。</p><p><strong>真要说不足的话，那就是那块依然只有60Hz刷新率的屏幕了，标准版用户注定和高刷游戏体验无缘了。</strong></p><h2><strong>总结：芯片升级大，iPhone 16值得冲</strong></h2><p>在久违地回归到正代芯片后，iPhone 16在性能表现上给出了一份让人满意的答卷。</p><p>得益于产品制程架构的同步更新，A18芯片的CPU表现异常出色，和A18 Pro之间几乎只有频率上的区别，是当前移动设备里的第一梯队。至于GPU部分，虽然缺少了一枚核心，但是跑分成绩依然可圈可点，在全新散热设计的加持下，3A手游的体验也做到了出类拔萃的水平。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f5e23562f94c457a88a262fa7b17045f@1547419282_oswg164290oswg1706oswg1279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技）</p><p>最重要的是，得益于苹果对apple intelligence的追求，6GB运存总算在标准版上成为了历史的尘埃，即便是暂时用不上该功能的国内用户，也能享受到8GB运存的加持，直接影响到手机的多任务处理能力和运行速度，提供更稳定的游戏性能和更好的多媒体处理能力。</p><p><strong>在我看来，有了A18芯片和8GB内存，这款产品绝对有潜力成为未来3-4年的iPhone“钉子户”。</strong></p><p>本文来自微信公众号“雷科技”，作者：雷科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958322564205825</id>
            <title>杭州杀出超级IPO：年入4.6亿，全国首批</title>
            <link>https://www.36kr.com/p/2958322564205825</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958322564205825</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 12:14:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f25b6f6817094955bd0815becb801a42@000000_oswg63996oswg686oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>科技改变农业——最近，这个赛道跑出一个超级IPO：托普云农。这是一家植根于浙江杭州的科技企业，正悄然改变着传统农业的面貌。</p><p>新技术对于农业的提升，在国际上有很多参考案例。比如以色列，通过滴灌技术和土壤养分传感器，将水资源利用率和化肥利用率分别提高到 90% 和 95%，显著提高了农业生产效率。</p><p>这幅美好愿景，需要更多科技公司发力，赋能我国传统农业。而托普云农，就是该领域的优秀生力军，曾入选工信部第一批第一年建议支持的国家级专精特新“小巨人”企业名单。</p><h2><strong>-01-</strong></h2><p>托普云农董事长叫陈渝阳，出生于农民家庭，从小参与农事劳动，目睹了父母农作的辛苦，心中萌生出改变传统农业状况的想法。</p><p>从浙江大学农学院种子工程专业毕业后，他就职于农资集团的供销社，跑遍全国各地，对全国农业发展有了更深的认知。2008 年，《中华人民共和国种子法》颁布和实施，陈渝阳看到了农业领域的发展机遇，于是在杭州创办托普云农。</p><p>2008年，托普云农成立，专注于农业精密仪器的研发和生产。</p><p>五年过后，随着物联网浪潮兴起，托普云农将业务拓展到“数据采集与应用”领域，将物联网技术应用于农业，推动农业现代化转型。</p><p>这些业务大约包含两块。</p><p>一块是智慧农业项目：1、物联网项目：利用传感器等技术采集农业生产数据，并通过互联网传输和分析，帮助用户实现农业产前、产中、产后的过程监控和科学决策。2、信息化软件平台项目：运用大数据、云计算等技术，根据客户需求开发具有数据监测、过程管理、智能决策等功能的应用平台。</p><p>另一块是智能硬件设备：包含可直接联网的智能装备、监测或检测设备、传感器等，帮助用户实现自动监测、检测、控制等目的。</p><h2><strong>-02-</strong></h2><p>传统农业面临着多个痛点：农业从业人员匮乏、年龄老化、规模化程度低、农业用地减少等问题。</p><p>针对这些，托普云农运用物联网、人工智能、大数据等新一代信息技术，改变传统农业生产和管理方式，提高农业生产和管理效率，从而提升粮食产量。目前。公司拥有 185 项专利，其中发明专利 35 项、实用新型专利104 项、外观设计专利 46 项。</p><p>例如，公司自主研发的智能虫情测报灯和孢子自动捕捉系统，能够自动完成虫情信息、病菌孢子的图像及数据采集，并通过图像识别技术进行病虫害识别和预警，有效提升病虫害监测防控能力。</p><p>新技术对于农业的提升，在国际上有很多参考案例。</p><p>例如，以色列通过滴灌技术和土壤养分传感器，将水资源利用率和化肥利用率分别提高到 90% 和 95%，显著提高了农业生产效率。</p><p>又比如，美国加州通过喷灌技术和土壤水分传感器，将灌溉水利用率提高到 75%，并实现了节水增产的目标。</p><p>再参考荷兰，温室种植面积约占全球温室种植面积的 40%，其温室技术水平也位居全球前列，温室种植的农作物产量远高于露地种植。</p><h2><strong>-03-</strong></h2><p>2021年至2023年，托普云农的营业收入分别为33,209.56万元、37,516.71万元和45,945.27万元；净利润分别为7,251.33万元、9,268.31万元和11,500.88万元。</p><p>智慧农业目前面临的竞争格局是：细分领域众多，市场尚未形成规模效应；行业内企业数量众多，竞争格局分散，未跑出绝对头部。</p><p>智慧农业行业的竞争主体包括：</p><p>传统农业企业：如大北农、温氏股份等，他们利用自身在农业领域的经验和技术优势，积极转型智慧农业，提供软硬件一体化解决方案。</p><p>互联网巨头：如阿里巴巴、京东、网易等，他们利用自身的技术优势和市场资源，积极布局智慧农业，例如通过电商平台销售农业设备和农产品。</p><p>农业科技创业公司：他们专注于智慧农业的某个细分领域，例如植保、耕保、种子等，提供专业的解决方案。</p><p>科技型公司：他们专注于智慧农业技术的研发和应用，例如传感器、物联网、人工智能等，为其他企业提供技术支持。</p><p>而托普云农的独特性在于：1、技术特色，拥有7项核心技术；2、软硬件一体化，既提供硬件也提供软件；3、多领域全周期服务：覆盖农业种植业的产前、产中、产后全周期，以及耕地保护、植物保护等多个细分领域。</p><p>本文不构成任何投资建议。封面图为托普云农智能虫情测报灯7.0。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzI0NzAzNTUwMQ==&amp;mid=2652509583&amp;idx=2&amp;sn=d6b8f9784a1aa21fcd791b6298a7feb3&amp;chksm=f309b71d9e2bd118b44c0f353d51ff770af3dc4c9ad9635be261c880a21c1ce086b33b028c48&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“铅笔道”（ID：pencilnews）</a>，作者：阿欣，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958223981518720</id>
            <title>果链龙头发力汽车链，立讯精密买下德国汽车零部件巨头</title>
            <link>https://www.36kr.com/p/2958223981518720</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958223981518720</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 11:44:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_47cb9c6c09974a638796c09c43b3dc7b@5718657_oswg121077oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：Pixabay</p><p>9月14日，立讯精密（002475.SZ）发布公告称，为加快推进公司汽车业务全球化进程，提升公司汽车线束产品在全球市场的综合竞争力，公司计划收购收购Leoni AG的50.1%股权及Leoni AG之全资子公司Leoni Kabel GmbH（以下简称“Leoni K”）的100%股权。</p><p>立讯精密的全资子公司香港立讯与公司下属控股子公司汇聚科技共同设立新加坡汇聚，以3.2亿欧元的交易对价收购Leoni K的100%股权。立讯精密的全资子公司新加坡立讯则以2.05亿欧元的交易对价收购Leoni AG的50.1%股权。</p><p>立讯精密表示，Leoni AG和Leoni K将在完成股权交割后纳入公司合并报表范围，预计不会对公司本年度财务状况及经营成果造成重大不利影响。</p><p>2021年，立讯规划了“三个五年”战略部署，目标在三个五年内，发展成为全球汽车零部件Tier1领导厂商。立讯精密能从“果链”再跨入全球汽车零部件Tier1领导厂商吗？</p><h2><strong>从消费电子到汽车零部件</strong></h2><p>2020年，立讯精密收购了纬创集团在国内的两家子公司，其拥有iPhone代工业务，立讯精密也得以切入iPhone组装业务。2021年，立讯精密收购日铠电脑50.013%的股权，获得了苹果金属结构件和显示触控模组的生产能力。</p><p>2023年12月，和硕公告称，公司子公司世硕电子（昆山）有限公司办理现金增资，将引进立讯精密旗下公司立臻精密制造（昆山）有限公司，后者将斥资约21.08亿元收购世硕62.5%的股份。此举也进一步加强了立讯精密对iPhone的代工能力。</p><p><strong>目前，立讯精密为苹果提供iPhone、Apple Watch、AirPods和Apple Vision Pro等产品的开发和制造服务，从多元化的零部件、模组到整机系统组装，提供一体化的综合解决方案。</strong>其产能也从国内拓展至国外，在越南、马来西亚、菲律宾等建立了多个工厂，为苹果生产iWatch、AirPods等产品。</p><p>作为果链龙头，立讯精密的营收也主要来自消费性电子。在提出“三个五年”的2021年，立讯精密收入1539.46亿元，同比增长66.43%；消费性电子收入1346.38亿元，同比增长64.56%，占营收比重的87.46%。到2023年，立讯精密收入2319.05亿元，同比增长8.35%；消费性电子收入1971.83亿元，同比增长9.75%，营收占比为85.03%。</p><p>这期间，来自苹果的销售额占比从2021年的74.09%提升至2023年的75.24%。</p><p><strong>在“果链”之外，创始人王来春也在为立讯精密寻找新的方向，定下全球汽车零部件Tier1领导厂商的目标。要在完成汽车业务布局，立讯精密选择了布局“果链”的方式——在全球范围内收购。</strong></p><p>招商证券显示，立讯精密在2010年时就以Tier2身份服务德尔福等企业，切入汽车数码影音娱乐线束和连接器领域。2012年并购福建源光电装，拓展日系客户；2013年并购德国SUK，增强在汽车精密塑胶件的技术实力，并拿到优质德国客户的供应商资质；2018年收购采埃孚子公司TRW旗下全球车身控制系统事业部，在体外有负责人机界面解决方案，与上市公司汽车业务形成协同。</p><p><strong>但在大量收购之后，汽车业务对立讯精密的收入贡献仍然较小。2023年，立讯精密汽车互联产品及精密组件收入92.52亿元，同比增长50.46%，但营收占比仅3.99%；2024年上半年，该业务收入47.56亿元，同比增长48.3%，营收占比为4.59%。</strong></p><p>虽然汽车业务快速发展，但营收占比仍然较小，立讯精密也需要进一步扩大收入规模。</p><h2><strong>收购完成全球布局</strong></h2><p>近年来，立讯精密在湖北麻城、河北保定、安徽明光、安徽宣城、江苏盐城、江苏常州等地布局了多个汽车相关产能。不过立讯精密的汽车业务瞄准的是全球市场。</p><p>本次计划收购的Leoni AG及其全资子公司Leoni K，是欧洲第一、全球第四的汽车线束巨头。</p><p>立讯精密表示，2023年Leoni在重组后仍然存在资源利用低、营运费用开支大等问题，公司整体处于亏损状态。在立讯实现对Leoni的股权交割与资源优化后，有能力帮助Leoni改善其经营状况。</p><p><strong>在业务协同上，Leoni现有的线束业务为立讯的连接器、汽车电子、智能驾舱/自动驾驶等零部件产品提供了更大更广的出海口</strong>；Leoni在全球多个地区拥有丰富的产能配置，立讯积累的中国车厂客户资源可以帮助Leoni实现更多元化的客户结构优化，提高其全球的产能利用率，同时立讯也借助莱尼的海外客户渠道，以及制造/研发/销售布局的基础，<strong>大大节约海外业务拓展、产能建设的成本与时间，并进一步丰富在线束组装方面的研发资源配置。</strong></p><p>在汽车业务方面的外延拓展思路上，立讯精密表示，在近几年海内外主流客户在汽车智能化发展趋势下开始主动拥抱中国供应商，外加中国车厂品牌加速海外拓展的步伐，车厂供应链体系中需要同时具备海内外配套支持的中国供应商。因此，立讯的汽车业务遇到了非常好的发展时机，当前的业务规划正往全球化生产经营方向加速推进中，<strong>但是如果自己在海外做0到1的搭建，整体建设期至少需要5年，在这个基础上做到盈利则需要更多的时间，为了把握行业发展的窗口期，海外业务的拓展需要在“内生”的基础上加速“外延”的步伐。</strong></p><p>显然，立讯精密未来还可能继续收购，完成其海外业务的布局。</p><p>从汽车行业来看，出海已经成为了风口。比亚迪、奇瑞、长城、吉利等车企纷纷出海，今年1-8月，汽车出口377.3万辆，同比增长28.3%。</p><p>而跨国车企也开始与中国企业合作，今年4月，小鹏汽车和大众汽车集团官宣，将在中国市场的电动车平台联合开发行业领先的电子电气架构，联合开发的电子电气架构预计将从2026年起应用于在中国生产的大众汽车品牌电动车型。也有消息称，奥迪将在部分中国车型上搭载华为智驾方案。</p><p>在行业风口下，立讯精密借助收购以快速完成布局，但收购的成效能否如愿也是未知数。而目前汽车业务的营收占比不足5%，立讯精密还有很长的路要走。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/cSUqlmJZEp9dY3A8Gx3iVg" rel="noopener noreferrer nofollow" target="_blank">“鲸维度”</a>，作者：Fanie，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958247883410439</id>
            <title>OpenAI 将 o1 AI 模型扩展到企业和教育领域，与Anthropic直接竞争</title>
            <link>https://www.36kr.com/p/2958247883410439</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958247883410439</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 11:37:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>发布 o1 AI 模型后，OpenAI 引入了「Self-Play」训练方法，让模型与自身不同版本进行对话和推理。为了提升用户体验，OpenAI 又于近日重磅推出了o1-preview和 o1-mini 模型。</p><p>最新的 AI 模型 o1-preview 和 o1-mini向所有 ChatGPT 企业版和 ChatGPT 教育版用户开放。这些模型专为处理复杂推理任务而设计，<strong>预计将改变组织和学术机构应对诸如高级编码、科学研究等艰难挑战的方式。</strong></p><p>o1 模型于本月早些时候首次发布，代表了 OpenAI 在创建具有深度、多步骤推理能力的 AI 上的最先进尝试。通过模仿人类的思维过程，这些模型可以解决早期 AI 迭代难以解决的复杂问题，为依赖高级问题解决能力的行业提供新的可能性。</p><h2><strong>旨在思考的 AI: 是什么让 01 模型与众不同</strong></h2><p>o1-preview 和 o1-mini 模型与其之前版本相比，具有更深层次的批判性思考能力。OpenAI 训练这些模型在回应之前花更多时间处理信息，让它们能够处理数学、编码和科学发现等领域的复杂任务。</p><p>在初步测试中，o1-preview 模型通过解决国际数学奥林匹克竞赛资格考试中 83% 的问题展示了其能力——这一成绩相较于 GPT-4o 的 13 %有了显著提升。o1-preview 模型在编码竞赛中的表现同样出色，它在严格测试编码技能的平台——Codeforces 上排名第89位。</p><p>更小、更具成本效益的 o1-mini 型号则专为编码任务量身定制，为需要解决高级问题而无需广泛知识的公司提供了更实惠的选择。这使得 o1-mini 对于生成和调试复杂代码等任务特别有用，为小型企业和开发人员提供了一个可访问的选项。</p><h2><strong>为什么 01模型是企业游戏规则的改变者</strong></h2><p>对于企业客户来说，全新的 o1 模型代表着重大飞跃。从金融到医疗保健，各行各业都越来越多地转向 AI，不仅仅依赖 AI 来实现自动化，还依赖 AI 来解决复杂的高风险问题。o1 模型的推理能力、战略优化能力以及识别错误的能力使其成为这些用例的理想选择。</p><p><strong>这些功能对于处理复杂数据集和工作流的公司特别有吸引力。</strong>例如，o1-preview 模型可以帮助物理学家生成复杂的量子光学公式，或帮助医疗保健研究人员注释大规模基因组数据。这与早期主要处理重复性、低级任务的 AI 模型形成鲜明对比。</p><p>我刚刚让 o1 根据非常具体的免疫学方法编写了一个主要的癌症治疗项目。它在一分钟内创建了项目的完整框架，具有极具创意的目标、方法，甚至还考虑了潜在的陷阱和替代策略......</p><p>杰克逊实验室的免疫学家 Derya Unutmaz 博士最近使用 o1-preview 模型编写了一份癌症治疗提案。「它在一分钟内创建了项目的完整框架，设计了高度创新的目标，甚至考虑了潜在的陷阱，」他在 X.com（前身为 Twitter）上发帖。「如果我自己来做，恐怕需要数天甚至更长时间来准备，」他补充道，该模型提出了他可能自己未曾考虑过的想法，即使他在该领域拥有 30 年的经验。</p><p>— Derya Unutmaz，医学博士 （@DeryaTR_） September 14， 2024</p><p><strong>这种生产力和创造力的提升正是为什么这么多企业渴望将这些模型融入其工作流程的原因。</strong>OpenAI 决定通过此次发布优先面向企业客户，凸显了其抢占高价值、高复杂性人工智能细分领域的战略。</p><h2><strong>教育机构将从中受益匪浅</strong></h2><p><strong>o1 模型也是教育机构的有力工具。</strong>大学和研究中心在进行复杂的数据分析或研究时，经常面临资源和时间的限制。通过向 ChatGPT Edu 客户提供这些模型，OpenAI 为学生和研究人员提供了尖端的 AI 工具，帮助他们解决各自领域中一些最困难的问题。</p><p>当 ChatGPT o1 在 1 小时内完成你攻读博士学位时花了大约一年时间的工作时的感觉：https://t.co/jG7UxEUT12</p><p>— 凯尔·卡巴萨雷斯博士 （@AstronoMisfit）September 15， 2024</p><p><strong>来自学术界的初步反馈非常积极。</strong>湾区环境研究所（Bay Area Environmental Research Institute）的天体物理学家凯尔·卡巴萨雷斯（Kyle Kabasares）博士在 X.com 上发帖说，o1-preview「在1小时内完成了我攻读博士学位时花了大约一年的时间」。在计算流体动力学和免疫学等领域，复杂的计算和数据分析是常规操作，o1 模型已经通过加快研究过程和提供新的见解证明了其价值。</p><p><strong>此外，o1 模型也有望改变学生的学习方式。</strong>通过处理更复杂的任务，这些模型使学生能够专注于更高层次的思考，而不是陷入死记硬背的过程中。这一转变可能会促进学术研究的创新和创造力，加速从物理学到生物学等各个领域的突破。</p><h2><strong>安全和治理：OpenAl致力于打造负责任的AI</strong></h2><p>除了先进的功能外，o1 型号还配备了增强的安全功能。OpenAI 开发了一种新的安全训练方法，允许这些模型通过道德准则和安全规则进行推理。对于处理敏感数据的企业和教育机构至关重要。</p><p>OpenAI 表示，它不会将客户数据用于训练，以确保专有信息保持安全。该公司还引入了严格的安全评估，包括一项被称为「越狱」的测试，其中 o1-preview 得分为 84 分（满分 100 分），远高于 GPT-4o 的 22 分。意味着 o1 型号能够更好地抵御绕过安全协议的企图，对于关注合规性和数据隐私的企业来说，这是一项关键功能。</p><p>在更广泛的背景下，<strong>OpenAI 已与美国和英国的 AI 安全机构正式建立合作伙伴关系，使组织们能够尽早访问模型进行独立测试。</strong>这项合作旨在确保 AI 进步与道德准则和监管框架保持一致，随着 AI 系统变得更加自主并集成到日常运营中，类似问题日益受到关注。</p><h2><strong>竞争格局：OpenAl与 Anthropic</strong></h2><p><strong>o1 模型的发布使 OpenAI 在竞争激烈的 AI 企业领域中占据领导地位。</strong>然而，该公司也面临着激烈的竞争。另一家 AI 巨头 Anthropic 最近推出了自己的企业版模型 Claude Enterprise。该模型提供了庞大的 500,000 个代币上下文窗口，是 OpenAI 当前模型的两倍多。虽然 Anthropic 的模型在处理大型数据集方面表现出色，但 OpenAI 的优势在于它专注于深度推理和问题解决。</p><p><strong>OpenAI 将这些高级模型整合到其现有的企业和教育产品中，为其带来了竞争优势。</strong>虽然 Anthropic 可能在数据处理能力方面占上风，但 OpenAI 对推理任务的关注可能会为其带来长期优势，特别是在解决问题比纯粹的数据处理更有价值的行业中。</p><h2><strong>AI在商业和教育领域的未来</strong></h2><p>OpenAI 的 o1-preview 和 o1-mini 模型的推出标志着人工智能领域的一个转折点。这些模型超越了自动执行日常任务的功能，它们被设计为能够进行批判性思考，从而在医疗保健、量子研究和高级编码等行业中成为应对最棘手挑战的真正伙伴。</p><p>随着企业和教育机构越来越依赖 AI 进行高风险决策和复杂问题的解决，<strong>这些模型的影响可能会重塑我们对智能系统的期望。</strong></p><p>在一个创新经常发生在技术和人类洞察力交汇的世界里，o1 系列提供了通往未来的桥梁。现在的问题不再是关于 AI 能做什么，而是关于 AI 应该做什么。而 OpenAI 的最新飞跃似乎给出了明确的答案：它应该做得更多。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=Mzg2ODA0ODkwNA==&amp;mid=2247531913&amp;idx=1&amp;sn=91e423cf721c6fbe49064e1a8d2eacaf&amp;chksm=cf0fc9cdba16510cbbe8208fce68b7a45201d2c6a87c852bac334dac5e87db45966a1470b4b1&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“多鲸”（ID：DJEDUINNO）</a>，作者：Michael Nuñez，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958280526122245</id>
            <title>16个涨停，华为又带飞一只妖股</title>
            <link>https://www.36kr.com/p/2958280526122245</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958280526122245</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 11:36:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_4e28d8d4552b40dc9a8cf7dd7cd6a875@000000_oswg108820oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>弱市出妖股，今年也不例外。</p><p>一季度的万丰奥威，二季度的正丹股份，都成了当时的年度第一牛股。</p><p>8月以来，轮到了深圳华强，17天16个涨停板，距离今年最牛股票，仅一步之遥。</p><h2><strong>妖股再现</strong></h2><p>妖股爆发，离不开热点，万丰奥威蹭上了低空经济的产业热潮，正丹股份碰到了TMA的价格暴涨，此次上位的深圳华强，搭上的则是华为海思。</p><p>今年7月底，一些媒体报道华为海思将于9月9日召开首届全联接大会，届时将发布多款海思芯片，涵盖音视频、鸿蒙、星闪等多种应用场景。</p><p>作为华为旗下的芯片公司，海思几年前曾因美国制裁陷入低谷，此时宣布举行全联接大会，自然引发了极大关注。</p><p>之前发布的经营情况显示，华为海思业务在2023年开始全面恢复。</p><p>2023年第四季度，海思芯片出货量高达680万片，同比增长5121%，当季营收飙升24471%；今年第一季度，华为海思芯片销量突破800万颗，重返全球前五名。</p><p>依靠完全自主研发的麒麟、鲲鹏、昇腾等先进芯片，海思不仅重返全球芯片行业中心位置，也带动华为业绩全面回暖。</p><p>2023年，华为营收高达7042亿元，比上年增长9.63%，创下自2019年以来的最大年度涨幅，净利润达到了870亿元，同比增长高达144.5%；今年上半年，华为业绩增速继续加快，公司实现营收4175亿元，同比增长34.3%，净利润约551.1亿元，同比增长了18.2%。</p><p>还有市场传闻，海思未来有可能参照华为车BU独立的形式，从华为独立出来，变成像高通、英伟达那样的全球供应商。这意味着，海思旗下芯片的研发和量产能力，可能出现超预期进展。</p><p>华为海思站上风口，市场自然要挖出概念股来炒，和海思同在深圳的深圳华强，成了“天选之子”。</p><p>深圳华强是华为海思最大的代理商之一，代理包括智能电视芯片、显示驱动芯片及AI芯片等产品，是正宗的海思概念股。</p><p>同时，公司针对热点也很快做出回应，随着海思陆续推出新产品，公司将加大海思产品的应用方案研发以及推广力度，促进海思产品的市场拓展。</p><p>这一表态进一步引发了市场关注。</p><p>独特的股权结构，也让深圳华强具备成为妖股的条件。</p><p>资料显示，深圳华强总股本超过10亿股，但其中有7.40亿股在控股股东及其一致行动人手上，实际流通股不过3亿股左右，启动前实际流通市值不到30亿元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_61a12c4b6fe74d80917ec90ed6865a1f@000000_oswg194240oswg1080oswg413_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲来源：同花顺&nbsp;</p><p><strong>论短期的势能，深圳华强在海思的概念股中确实无与伦比，但是论长期的质地，又是另一番景象了。</strong></p><h2><strong>质地几何</strong></h2><p>深圳华强主要业务围绕电子元器件展开，目前公司有三大业务板块，即电子元器件授权分销、电子元器件产业互联网和电子元器件及电子终端产品实体交易市场。</p><p>电子元器件分销是公司最重要的营收来源，代理华为海思的芯片即属于这部分业务。2023年，深圳华强电子元器件分销业务营业收入已达180.18亿，占到总营收的87.49%，是国内电子元器件分销领域的“一哥”。</p><p>作为被市场爆炒的海思概念股，深圳华强并没有披露与华为海思的相关业务数据，但是从过往业绩变化中，却能从一定程度看出海思对公司影响有多大。</p><p>深圳华强是在2017年通过收购淇诺科技才成为海思的代理分销商。此后的6年，公司整体营收虽然实现了翻倍增长，但是更重要的净利润却变化很小。</p><p><strong>成为海思分销商，似乎并没有帮助深圳华强赚到更多钱。</strong></p><p>自2023年一季报开始，深圳华强净利润更是出现连续6个季度下降，最近4个季度甚至出现增收不增利的情况。今年第二季度，深圳花强实现营业收入59.21亿元，同比增长22.97%；归母净利为1.19亿元，同比下降15.79%。</p><p>或许是因为海思强势地位造成公司议价能力下降，深圳华强电子元器件分销业务的毛利率从11.59%大幅下降至6.61%，毛利率的持续下降，拖累了公司的盈利能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_cafea2f490534035a56e5cb8109f3ee7@000000_oswg22935oswg948oswg257_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲来源：同花顺&nbsp;</p><p>未来开拓海思的新业务需要大量资金，但深圳华强背后资本能提供的支持有限。</p><p>公司控股股东华强集团2023年的有息债务高达366亿元，其中短期债务为237亿元，而同期货币资金仅为62亿元，仅短期债务存量资金缺口就高达174亿元。为了筹集资金，上市公司甚至还面临被大股东抽血的风险。</p><p>所以，即便股价暴涨，深圳华强也没有忘记提醒投资者，海思新产品的推广进度存在不确定性，对公司业绩的影响有待观察，近期公司股价短期涨幅较大，明显偏离市场走势，存在市场情绪过热的风险。</p><h2><strong>历史之鉴</strong></h2><p>华为在资本市场的影响力不需要多言，A股搭上华为的概念股超过800家，深圳华强也并不是第一个蹭上华为而股价暴涨的上市公司。</p><p>2021年6月，华为发布鸿蒙系统前后，一只叫润和软件的股票瞬间成妖，2个来月，股价暴涨近7倍。</p><p>面对深交所随之而来的关注函，润和软件回复称，公司是开放鸿蒙发起单位之一、华为鸿蒙操作系统生态共建者，似乎想证明股价暴涨的合理性。</p><p>但是现实并没有想象中乐观。鸿蒙在2021年给润和带来的营收几乎可以忽略不计，2022年润和净利润甚至下降了40%，依靠鸿蒙逆袭的剧本并没有实现，股价也从高位大幅下跌接近60%。</p><p>2023年8月29日，也就是华为开售Mate60系列手机的这一天，另一只妖股捷荣技术开始狂飙。不到一个月时间，捷荣技术凭借Mate60供应商概念拉出16天涨停，区间涨幅超过5倍。</p><p>市场当时之所以重点炒作捷荣，除了公司市值低之外，另一个原因或许是华为曾位列捷荣技术的第一大客户，来自华为的营收占比一度接近50%。</p><p>事实上，华为成为捷荣第一大客户还是在9年前，2017年以后，华为贡献的营收已跌破10%，2021年、2022年和2023年上半年，华为占公司营业收入比例分别为0.46%、3.48%、3.70%。</p><p>无厘头式的市场炒作往往来去一阵风，仅仅涨了一个月之后，捷荣股价开始持续下跌，目前距当时高点跌幅也已超过60%。</p><p>此次蹭上海思热度而突然暴涨的深圳华强，长期逻辑同样不够坚挺。</p><p><strong>全球产业经济的历史经验表明，一个硬件巨头的发展壮大，长期最大的受益方肯定是上游零部件供应商，而不是下游的产品代理商。从早期的苹果产业链，到最近几年的特斯拉和英伟达产业链都是如此。</strong></p><p>对于超级品牌来讲，代理商更不可能一家独大，甚至最终有可能被品牌商的自营渠道所代替。</p><p>从这个角度上来看，华为海思的发展壮大，A股里真正受益的是上游供应商，而非下游代理商，深圳华强的未来业绩，也很难像立讯精密等果链龙头，或者中际旭创等英伟达产业链龙头一样，表现出飞速增长的势头。</p><p>除了业绩容易证伪带来的股价调整风险之外，控股股东的抛售风险也不可忽视。</p><p>公开资料显示，在深圳华强控股股东掌握的7.40亿股中，有3.30亿股是作为可交换债券的抵押品。目前可交债已经进入换股期，而暴涨后的深圳华强股价，已经大幅高于换股价，这部分股份一旦通过换股的方式进入二级市场减持，对股价无疑将产生较大影响。</p><p>9月9日，传闻中的华为海思全连接大会在网上没有掀起丝毫风浪，深圳华强也高开低走，连续2天跌停。</p><p>这种情绪炒作，来得快也去得快，事件性的利好兑现后，深圳华强未来的股价，还是会回归业绩驱动的逻辑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f00c15f0738849aab4d825f7c9552472@000000_oswg2664oswg1000oswg79_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_abda13abedb84839b0afbb27cdf4fe44@000000_oswg42538oswg1000oswg378_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=Mzg3NTk4NDYzOQ==&amp;mid=2247654888&amp;idx=1&amp;sn=6c28382aa2853d7fd0957114082d8fd3&amp;chksm=ce9a59366c625a990c29d22795827cfa3f8254f91a00a7ea1bec34533a2fd28b376c84599e65&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“市值观察”（ID：shizhiguancha）</a>，作者：市值观察，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958221290835208</id>
            <title>AI太香，iPhone水货复兴</title>
            <link>https://www.36kr.com/p/2958221290835208</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958221290835208</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 11:29:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>从美国东部开车两小时到加拿大，00后的谢恩往返于边境线，忙着<strong>给中国国内的“果粉”代购“非阉割版”的iPhone 16。</strong></p><p>9月15日，谢恩在某二手平台发布带货贴，不到3天就已经有90多个用户询问，顾客线上下单美版或加版iPhone 16，她负责驱车带回，“下单的顾客多，单人收费600元，单次下单的人少，就收800元。”</p><p>令谢恩意外的是，不少用户指名要美版的iPhone 16，并不是因为美版价格低于国行，而是美版最早搭载苹果的AI功能。</p><p>而在美国留学，本想着“自己也要开车买美版iPhone，找人摊个油钱”的谢恩，现在几乎每天都后台信息99+，而大多数的顾客都坐标国内，“相比在国内黄牛手里加1000元抢首发，宁愿加钱等一等，拿到非阉割版的iPhone 16。”</p><p><strong>“上一次这么多人求购美版iPhone，还是iPhone 4呢。”</strong>谢恩笑道。</p><p>2010年6月，iPhone 4发布，中国大陆并未成为首发市场，国行版要等到当年9月才开始销售。为了成为朋友圈里第一批用上苹果的人，不少果粉寻求购买海外水货，甚至传出了“卖肾买iPhone 4”的谣言。第一台水货美版iPhone 4在中关村的成交价也达到了令人咋舌的18000元。</p><p>随后几年，新款iPhone基本实现了全球同步发售。再加，国内电商海外购愈发便利，海外版本iPhone保修较为麻烦等因素，水货iPhone市场逐渐萎缩。</p><p><strong>如今，iPhone 16似乎重启了往日的海外购狂潮。</strong></p><p>苹果为iPhone 16系列打造的一整套AI能力，成了本月初的发布会的重头戏。美版iPhone下个月就会支持Apple Intelligence；但在国内，支持中文的Apple Intelligence要2025年才上线。</p><p>果粉张莹表示，她愿意花费2000~3000元的溢价，希望下个月购入美版iPhone 16 Pro Max。</p><p>相比之下，<strong>国行版iPhone 16并没有成为“黄牛”爆炒的目标。</strong></p><p>9月20日，北京下起大雨。从早上8点开始，排队提货iPhone 16的人群便将三里屯的苹果零售店围得严严实实。兜售新款手机的“黄牛”也出现在店门口，但为新款iPhone设置的溢价并不算离谱。</p><p>“今天iPhone 16 Pro Max加价1000元出，华为三折叠（指华为Mate XT非凡大师版三折叠屏手机）加价2万。”挤在队伍中的黄牛告诉字母榜（ID: wujicaijing），<strong>国行版的iPhone 16叫不上价，华为三折叠则有价无市。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_21944cf2caf94677a3c2337c97ae046b@000000_oswg583124oswg792oswg594_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图注：三里屯苹果旗舰店等首发的果粉 图源：字母榜拍摄&nbsp;</p><h2><strong>A</strong></h2><p><strong>“都知道今年的iPhone 16系列大概率会破发，现在就是在押爆款罢了。”</strong></p><p>“黄牛”张奇直言，经历了去年iPhone15囤货“甩都甩不出去”的窘境后，他之所以还囤货iPhone 16，就是押注iPhone 16系列会被炒起来。“毕竟iPhone 16从外观上来说，变薄了，尺寸也变大了。”</p><p>目前，拼多多、京东、淘宝等电商平台均针对新款iPhone提供补贴。以iPhone 16 Pro 256G为例，苹果官网8999元，拼多多、京东均补贴400元。在张奇看来，这<strong>“相当于刚开售就破发。”</strong></p><p>果粉媛媛早就打算将手里的iPhone12换成新款的16，不仅是因为手机早已到了该换的时候，也是因为被iPhone 16的摄像长焦功能种草。</p><p>不过，相比起外观的调整，最让媛媛心动的新功能，还是iPhone 16的相机控制按键，“一键就能启动摄像头拍照，同时AI识别，上课拍PPT、外出都很方便。”</p><p>但由于新款iPhone的AI功能2025年才能进入国内，媛媛并不打算从官网或电商平台抢首发，“等到双十一，还能再降500-1000元。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a6736570bb224de7a06742d9c0bfcbe5@000000_oswg111569oswg684oswg342_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图注：黄牛价目表 &nbsp; 图源：字母榜截图&nbsp;</p><p><strong>越来越理智的果粉，似乎让新款iPhone越来越难炒起来了。</strong></p><p>据《华尔街见闻》报道，苹果 iPhone 16系列的备货数据指引已更新至 8800万台，与 iPhone15系列大致持平。但首周3700万台的销量，似乎低于苹果的预期。</p><p>分析师郭明錤指出，iPhone 16 Pro系列出货时间显著低于15 Pro系列，除预购前备货量增加外，从首周末销量同比减少12.7%来看，关键还是在于需求低于预期。</p><p>作为资深黄牛，早在9月19日，张奇就给顾客提供低于官网价的iPhone 16，“压价100-200元，9月20日顺丰到付。”同时，9月19日张奇就能给顾客送货上门，“iPhone 16 Pro 256G加价1000，最高的16 Pro 1T加价2000元。”</p><p>不过，<strong>随着苹果的功能革新越来越少，近两年，“1T版本的iPhone百台也就能卖出顶多十台”，</strong>对于今年iPhone 16，张奇并不看好。</p><p>而在9月20日首发，当字母榜来到北京三里屯苹果售卖点，围在一旁的黄牛老杜表示，早上8点下着大雨，队伍就已经里三层外三层排到了店铺外面。除了黄牛之外，多是散客来取抢到的首发iPhone 16。苹果零售店仅允许已经抢到首发的顾客进入。</p><p>在停步围观的几分钟内，字母榜已经被不少于4位黄牛轮番询问，是否出售或购买iPhone 16。</p><p>每当有拿着苹果白色手提袋从门店走出的顾客，总有黄牛围上前去当场加价，“iPhone 16 Pro普遍加300-500，沙漠金库存太多了，顶多加价200元，iPhone 16 Pro 1T能加价600。”老杜表示，转来的iPhone 16也会在现场以不低于800-1000元的溢价，加价卖给没抢到首发的散客。</p><h2><strong>B</strong></h2><p>和表现不温不火的iPhone 16相比，同一天正式发售的华为三折叠的热度高得多，俨然成为了新的“电子茅台”。</p><p>“囤苹果稳定回本，但红利越来越少；囤华为一单就能大赚。”张奇笑称，<strong>如今能否囤入华为三折叠，已经是黄牛圈检验彼此身家的新标准。</strong></p><p>官网售价最高21999元的华为三折叠，不仅在华为线下门店没有样机展示，在线上也是“一机难求”。正式开售前，这款手机在华为商城预约人数超过600万。9月20日早上10点开售后，各个版本均“秒没”，目前华为商城内已显示暂时缺货。</p><p><strong>“前2天，华为三折叠最高炒到18万元一台，”</strong>因此，有门路买到用户码，并能囤的起三折叠的黄牛并不算多，张奇避开风口，也就订了两台，“9月19日1TB红色款售价51000元，加价近3万。”</p><p>“10:00准时卡点进，还没来得及付款，页面就崩了”，被三折叠吸引的消费者郑秋告诉字母榜，作为苹果用户，他对三折叠屏幕也十分好奇，想给父母买两台当做国庆礼物，但等他10:08再次刷入，页面一直重复显示“访问人数较多”“正在努力加载”，随后就提示没有了库存。</p><p>同时，“华为三折叠深度测评”冲上微博热搜，某科技博主10分钟的长测评视频，不过2小时播放量就冲破了10万次。在小红书平台，#华为三折叠屏手机怎么抢购#的关键词下，相关笔记已高达31万篇。</p><p>10点开售后，这款手机的溢价下调——1TB红色款48000元，黑色款42000元，<strong>张奇还是卖出了2单，净赚了近4万元。</strong></p><p>“抢到一台华为三折叠，这个月可以躺平了。”9月10日，预约到华为三折叠的某大三学生告诉字母榜，随即就有黄牛加价2万元收走。</p><p>在社交平台上，抢华为三折叠更是被戏称为“空手套1万的机会”，“可以不用，但必须得抢”的新财富密码。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_dc610e4d3103483ea6d472a38c7c8f3a@000000_oswg287155oswg792oswg922_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图注：成为电子茅台的华为三折叠 &nbsp; 图源：字母榜截图&nbsp;</p><p>分析师郭明錤则指出，最新供应链调查显示，华为三折叠的市场需求和热度较高，2024年出货量预测已翻倍上调，从50万部上调至100万部。</p><p>尽管相比起苹果iPhone动辄千万的出货量，华为三折叠更像是“物以稀为贵”，但凭借噱头十足的三折叠，华为不仅迅速出圈，也为新旗舰Mate 70系列攒足了人气。</p><h2><strong>C</strong></h2><p>当消费者纷纷收缩开支，不再频繁更换最新款手机后，“求新”似乎成为了手机厂商们的唯一出路。</p><p>华为选择在iPhone 16开售的同一天售卖三折叠款新机，成为了9月国内手机市场的最大亮点。而苹果将iPhone 16系列与AI进行深度绑定，AI成为了iPhone创新用户体验的杀手锏。</p><p>但是<strong>不同地区AI供应商的差异，也引发了果粉对“货不对版”的担忧。</strong></p><p>在今年6月的苹果开发者大会上，苹果宣布与OpenAI合作，计划将其GPT-4o集成到iOS 18、iPadOS 18和macOS Sequoia中。但由于各国监管要求，OpenAI无法成为苹果的全球AI合作商。</p><p>在国内，6月20日有媒体报道,苹果已与百度、阿里巴巴、百川智能等中国AI大模型公司会谈，以寻求本地合作。</p><p>“想入手iPhone 16，就是冲着苹果和OpenAI合作，毕竟OpenAI的GPT-4o是全球最好的AI大模型。”果粉媛媛告诉字母榜，作为大学生，她几乎每天都要使用到AI大模型翻译、分析、整理论文，相比起国内的大模型，OpenAI的数据库更为全面，在分析海外文献时输出结果也更加准确。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3da306b9df354cabb7b23027973d44e4@000000_oswg79731oswg601oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>媛媛担忧，如果购买国行版，是不是能有发布会里GPT-4o一般的AI功能体验，<strong>“如果买国行，最后货不对版，又怎么售后呢？”</strong></p><p>“不像硬件，苹果可以通过建厂来把控零件标准，不同供应商的AI能力，苹果则难以用统一的标准来判定。”某大模型从业者告诉字母榜，尽管AI成为iPhone 16最大噱头，但不同地区的AI功能难以避免因供应商的不同产生差异，而这一问题短期内是不可解的。</p><p><strong>更关键的是，AI并非是苹果独有的武器。</strong></p><p>根据公开数据，2024年第二季度AI手机市场全球排名中，三星占据36%的市场份额，小米位居第二，占比22%。谷歌、vivo、OPPO、华为等公司也纷纷宣布推出AI手机。</p><p>最早推出AI手机的三星，Galaxy 系列不仅能一键生图，还可以内置通话实时翻译，实现跨语言沟通等等。上季度，三星蝉联了全球销量冠军，份额达到了20%。Counterpoint认为，三星这一切成绩的取得，主要归功于三星在AI技术上的创新应用，特别是三星Galaxy S24系列的畅销。</p><p>相较之下，苹果在智能手机市场的份额正面临挑战。尽管苹果在今年5月破例实施了大幅降价优惠，但仍然难挽颓势。</p><p>对于国内的用户而言，苹果Apple Intelligence次第落地的规划，让果粉很难在短时间内体验到AI技术的加成。而双11在即，苹果是否会采取更激进的降价策略，AI有能否成为苹果的救命药，答案仍然是未知的。</p><p>（文中老杜、媛媛、张奇、谢恩为化名）</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzI2NjU1MTcwMA==&amp;mid=2247537661&amp;idx=1&amp;sn=2608e792b11fe651a5123b13bffef093&amp;chksm=eb454c7982a316026eb0fe356977dfb9c1bfb55514cea1432e20cb350193d8a5b071eb85bd3c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“字母榜”（ID：wujicaijing）</a>，作者：马舒叶，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958257016900873</id>
            <title>当人形机器人来“敲门”，它距离真正会干活还有多远？</title>
            <link>https://www.36kr.com/p/2958257016900873</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958257016900873</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 11:28:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在今年的世界人形机器人大会上，投资人们普遍对人形机器人略有失望。</p><p>但回顾整个2024年，人形机器人仍有一定对技术突破：从斯坦福大学大火的炒菜机器人ALOHA，到接入OpenAI大模型的Figure01，再到马斯克X上展示的会“叠衣服”Optimus Gen2，以及能与主人拥抱的NEO机器人，这些创新正代表着机器人泛化能力的进步，同时也反映出外界对人形机器人能够融入人类日常生活的美好期盼。</p><p>然而，这需要他们运动更自如，并能够处理更复杂的问题。这将对人形机器人的泛化能力和本体制造提出更高的要求。</p><p>北京时间9月19日，在2024云栖大会上，<strong>围绕</strong>《人形机器人的“图灵时刻”》主题，至顶科技CEO兼总编辑<strong>高飞，</strong>星纪动元创始人<strong>陈建宇，</strong>北大-银河通用具身智能联合实验室主任王鹤，宇树创始人、CEO<strong>王兴兴，</strong>逐际动力创始人<strong>张巍，五位嘉宾针对人形机器人的形态定义、核心技术含量衡量标准、投入实际应用的时间预期、大模型给人形机器人带来的影响展开了深入的讨论。</strong></p><h2><strong>以下为云栖大会现场实录整理：</strong></h2><p><strong>高飞：我是至顶科技的高飞，今天主持这个讨论环节。我们的主题是“图灵时刻”，大模型的出现让信息真假难辨，人和AI之间的界限越来越模糊，但目前的AI仍基于文本，并未进入物理世界。我们将讨论人形机器人作为物理世界的智能载体，如何在大模型的推动下发展，是否有一天它们能达到图灵时刻，难以分辨其与人类的区别，甚至会区分不出来“敲门”的是人类还是机器人。让我们请几位嘉宾交流。</strong></p><p><strong>首先问一个关于初心的问题。作为创业者，你们的初心很重要。王兴兴，我知道宇树科技成立多年，你曾一度反对做人形机器人，但近几年你们却快速推出了人形机器人。是什么让你改变了看法？</strong></p><p><strong>王兴兴</strong>：没错，几年前我坚决反对做人形机器人。当时的技术还无法支持复杂的人形机器人系统，过于复杂的系统难以维护。2009年、2010年时，我做过小型人形机器人，但发现在复杂或泛用性场景下，技术还不足以驾驭这些系统。所以当时我决定不做。然而，随着2016年新一波AI技术的兴起，到2018年、2019年，机器人领域的AI技术逐渐展现潜力。特别是到2022年，大语言模型的表现令人惊艳，AI技术的发展速度远超我的预期。因此，我们在2023年正式启动了人形机器人项目。</p><p>虽然起步晚，但一年多来我们发布了两款人形机器人，结果超出预期，无论硬件还是软件的发展速度都非常快。</p><p><strong>高飞：明白了，是AI的发展促使你改变了态度。接下来问张巍总，你们是通用机器人公司，通用机器人是否一定要做人形？这是个有争议的问题。</strong></p><p><strong>张巍</strong>：我认为通用机器人必须做人形，尤其是双腿人形机器人。机器人和AI的使命不同，AI负责思考和决策，机器人代替人类行动。通用机器人本质需要具备两种能力：移动能力和操作能力，移动不一定需要双臂，但操作则必须有双腿，否则无法达到人类的工作场景。所谓通用机器人就是在这两个方面上能够达到跟人一样的适应能力和泛化化。</p><p>我觉得这一代AGI的发展，相比上一代的核心区别，就是从专用到通用的变化。可能在大模型出来之前，“通用”是一个贬义词，通用就是没什么用。但是大模型出来以后，大家发现像我们在专业领域里面收集数据做专项任务的方式，存在很大局限性。反而我们要构建基础的通用能力，然后在此基础上发展专用能力，才是解决泛化问题的关键。我认为大模型技术提供了通用软件算法，而机器人与物理世界的交互则依赖于人形机器人。</p><p><strong>高飞：张巍总提到双腿的人形机器人，不过王鹤老师的机器人没有腿。王鹤老师，您如何定义人形机器人的形态？</strong></p><p><strong>王鹤</strong>：我们公司名为银河通用，目标自成立之初便是实现通用机器人。不过，通用机器人有一个发展过程，首先是在单一场景中实现多任务和可移动，然后逐步扩展到多场景、多任务，最终达到全场景、几乎全任务的能力。在这个过程中，不同阶段会有最适合、最经济、最稳定的机器人载体。因此，在当前人形机器人或通用机器人市场刚刚起步的阶段，我们选择从特定场景中的多任务操作入手，例如在零售商超中进行上货、下货，在工厂搬运箱子等。实际上，在平坦的地面环境中，使用轮子已经足够满足需求。</p><p>我们并非完全没有腿，而是将两条腿整合成一个360度可旋转的轮盘，能够下跪并触碰地面，以拾取物品。双手的设计是为了应对如搬运箱子等需要双手操作的任务，在超市中，一只手拿篮子、一只手取货也是同样的道理。我们的机器人采用360度旋转轮和整合的双腿，能够站立到1.75米，触及高度达2.4米，并且可以下蹲触地，确保以最低成本、最稳定的技术实现率先落地的应用场景。</p><p><strong>高飞：每家公司对腿的定义不同。那么，陈建宇老师，具身智能和人形机器人这两个概念经常一起提到，您怎么看待这两个词？</strong></p><p><strong>陈建宇</strong>：具身智能和人形机器人虽然概念相近，但侧重点不同。具身智能主要关注智能本身的实现，它对形态没有严格要求，可以是人形、四足，甚至是能动的物体。人形机器人则特指形态为人形的智能体。我们公司重视具身智能与人形机器人的协同发展，正如人脑与身体同时成长，我们认为机器人的软件和硬件也必须协同发展。</p><p><strong>高飞：不仅仅是腿的形态，具身智能涵盖更广。那么，下一个问题是关于技术含量的。人形机器人现在很热，有很多表演和展示，如何判断一个人形机器人是否有技术含量？陈建宇老师，您怎么看？</strong></p><p><strong>陈建宇</strong>：我们可以将人形机器人分为大脑、小脑和本体三部分。这三者同样重要，但我认为关键是“小脑”，即控制行动的部分。如果没有小脑，机器人无法执行任务，只是一堆一堆会思考的破铜。小脑承载了大脑的指令，是实现机器人与物理世界交互的核心部分。</p><p>目前相比较于其它部分，“小脑”技术是最薄弱的，同时也是技术不确定性最高、收敛性最差的部分。</p><p>大脑部分得益于强大的大语言模型技术，但小脑部分存在的局限性很明显。大多数机器人仍然依赖几十年前的工业机器人或扫地机的技术，这极大限制了其发展。我们希望人形机器人的双腿能像人类一样稳健、快速、灵活，使其能够到达任何地点；同时双手也要足够灵巧，能够处理从家庭到工厂的各种任务，具备上厅堂、下厨房、进工厂的能力。这是我们追求的目标，但目前尚未完全实现。</p><p>至于如何判断人形机器人的技术成熟度，可以从其行走和操作的泛化能力入手。比如，在演示过程中，可以对它制造一些干扰，例如突然踹它一脚，或者在它抓取物体时制造一些障碍，观察它能否稳定、智能地适应并完成任务。</p><p><strong>高飞：王老师，您怎么看？</strong></p><p><strong>王鹤</strong>：银河通用最关注的是机器人上半身手、眼、脑的协调，这涉及大脑、小脑以及对本体的控制。我们首先在泛化抓取技术上取得了突破，体现了具身智能。泛化意味着机器人可以抓取各种材质的物体，无论是透明的、高光的或吸光的，像抱箱子、拿药盒等任务都是通过视觉引导完成的，不依赖二维码或任何标记，完全依靠图像理解，与大脑联动。部署过程实现了“零代码”，即无需编写复杂代码即可操作。</p><p>例如，我们展示了一个技术，机器人能够操作将卡皮巴拉放入金属杯中，并利用最前沿的端到端大模型技术，通过视频输入，在未曾见过的环境下根据人类的指令导航，完成任务。</p><p>因此，人形机器人的技术含量可以从两个方面衡量：<strong>一是其泛化能力，即能否真正实现通用功能；二是与人类的语言沟通能力，实现零代码的部署。</strong></p><p><strong>高飞：不仅能干活，还能交流。王兴兴，您怎么看？</strong></p><p><strong>王兴兴</strong>：对于人形机器人，人们期待的是一个AI模型，能够同时处理运动和操作。然而，目前运动和操作的训练还是较为分离。就全身运动而言，我希望到明年机器人能够执行复杂的全身运动表演，尽管我们现在已经完成了一部分，但大多数动作仍然是单独训练的，尚未形成连贯的整体，每次训练也消耗大量时间和人力。如果有一套更全面的系统，比如只需观看一个视频或简单演示就能学会完整的动作，这将为当前的表演带来巨大改变。</p><p>此外，我希望机器人在操作能力上有所突破，不仅能完成简单的桌面整理任务，还能处理复杂的生产装配，甚至更高级的推理任务。操作能力的提升，尤其是在生活中处理手臂相关的任务，将非常有价值。</p><p>虽然我们在这两方面已经取得了一定进展，但要实现真正的泛用性还存在距离。如果能够让机器人在全新的环境中，只通过简单的演示或自我强化学习就能自然完成任务，将具有非常大的价值。无论是购买一个机器人并部署到家中，还是在某个场馆中使用，只要给它简单的指令，它就能在大多数时间内自主完成任务。这是我对未来的期望，尽管目前还未完全实现。</p><p><strong>高飞：您看到机器人时，第一眼会关注哪里？</strong></p><p><strong>王兴兴</strong>：可以看整体，每个人审美不同。</p><p><strong>高飞：张巍老师，您怎么看？</strong></p><p><strong>张巍</strong>：我认为，理解机器人技术的关键在于两个关键词：泛化和通用。这两个词是本次变革的核心。具体来说，我们应该关注机器人的“大脑”、还是“手”，抑或其他？我提供一个视角：在评估人形机器人时，首先要关注它的腿。人形机器人之所以被视为一种新物种，而非传统机械臂的延续，根本原因在于它们需要具备两条腿。我认为，腿是机器人实现通用能力的基础。那么，在观察腿时，我们主要关注两个方面：首先，它是否具备应对各种地形的泛化能力；其次，它是否能够支撑双臂进行全身协同的通用操作，这也是腿的重要价值所在。</p><p>在我们的产品展示视频中，大家可以看到，小型双足机器人并没有脚掌，实际上就像人踩着高跷，这一设计是为了测试AI算法的能力。从视频中可以看出，机器人在不同地形上的适应能力和泛化能力已经接近类人水平。就像我个人在山地上踩高跷，如果有人推我，我也可能会失去平衡，这显示了我们在这方面取得的重要进展。</p><p>此外，视频中还展示了机器人在承载4公斤负载时的全身协同操作。这种展示在有负载的情况下相对较少见。双腿不仅需要保持自身的平衡，还要与四肢协同发力，以完成大负载的操作，这个过程需要通过腿部进行动态调整，全身协调面临一定挑战。我认为，这种全身协同的操作任务是区分人形机器人与固定双臂机器人的最重要特征，也是我们特别关注的技术点。</p><p><strong>高飞：总结一下，大家的观点都强调机器人必须具备适应性，能够在不同环境下工作，还要有良好的移动和操作能力。接下来谈谈机器人什么时候能干活的问题。马斯克预测未来两三代机器人后，年产量可达100万台。各位怎么看待这个时间线？</strong></p><p><strong>陈建宇</strong>：应用落地需要定义。如果初步应用不严格要求，在一两年内我们可以看到工业、商用甚至家用的机器人开始投入使用。根据创新扩散理论，任何新产业都有早期使用者愿意尝试。至于像电影《Her》中那样的机器人进入家庭，规模应用可能还需要更长时间，尤其是家庭场景要求更高的泛化能力，而工业场景相对容易控制。</p><p><strong>高飞：机器人“敲门”要多久实现？</strong></p><p><strong>陈建宇</strong>：我认为，从纯技术的角度来看，解决难点并不需要太长时间。如果仅仅是实现某个特定功能，比如让我们的机器人能够上下楼梯并在户外导航，这些都已经可以做到。机器人完全可以自主导航到门口并执行敲门的动作，这并没有技术上的难点。然而，真正的挑战在于，虽然早期的探索可能会很快取得进展，但要实现大规模应用，尤其是进入家庭环境，所需的时间相对较长。家庭环境没有明确的边界和泛化要求，而大规模应用更适合于工业场景，因为工业环境是有边界的，可以人为设定一些规则和标准场景，从而更容易进行控制。因此，在类似于ChatGPT这样的技术达到其图灵时刻之前，工业应用会更为迅速。</p><p>另一个难点在于，工业场景中可以将机器人与人隔离，并且机器人执行的任务相对固定。在这种情况下，只要小脑取得了一定的进展，就可以在工厂中投入使用，工人不需要具备复杂的数学能力，只需能够完成特定的工序即可。然而，对于人类的应用要求就高得多，同时也会引发更多的安全性问题。</p><p><strong>高飞：其他几位能简短说下时间预期吗？</strong></p><p><strong>王鹤</strong>：银河通用的机器人现在已经能在零售场景下应用，比如在云栖大会上，观众通过iPad下单，机器人能从货架上拿取物品。<strong>我们预计明年将是商用元年，五年内目标是在零售和车厂场景中达到1万台。</strong>进入家庭的时间大概在十年左右，十五年内可能会有上千万级的市场。</p><p><strong>王兴兴</strong>：我比较乐观，明年在工业和固定场景下实现商业落地不成问题。三年内全球可能会出现通用型AI机器人，五年内我们会看到天翻地覆的变化。</p><p><strong>张巍</strong>：我同意各位的预测。我认为这个赛道是事件驱动型的，时间难以预测。关键在于AI技术的进展。需要避免过早商业化，技术开关还没找到时贸然推进会遇到很多挑战。</p><p><strong>高飞：我补充最后一个问题，关于大模型与机器人之间的关系。我们今天讨论了很多大模型技术，它对人形机器人发展有什么影响？大家能否用两三句话总结一下观点？</strong></p><p><strong>张巍</strong>：影响非常大。机器人发展的动力来自AGI和大模型技术。我认为具身智能将成为多模态大模型的杀手级应用，包括无人驾驶。我想强调，大模型技术改变了我们的思维方式，从规则驱动到算法驱动，再到数据驱动。现在，我们先看有哪些数据，再决定采用什么算法进行训练。因此，我们的理念是“软件定义硬件，数据定义软件”。</p><p><strong>王兴兴</strong>：我认为通用机器人，尤其是通用人形机器人，是大模型落地的最大载体，能解决大模型的落地问题，两者是非常好的组合。</p><p><strong>王鹤</strong>：现在的通用机器人大多使用分立的小模型，大模型可以赋能这些技能。第一，大模型可以作为代理，规划长程任务。第二，它可以作为监控器，纠正小模型的错误，及时处理问题。第三，最有前景的是将动作作为大模型的输出，实现通用感知、规划和执行的一体化。</p><p><strong>陈建宇</strong>：大模型给我们最大的启发是“Scaling Law”的存在。研究通用机器人需要匹配的通用智能，大模型引导我们思考如何实现机器人领域的Scaling Law，并带来了语言模型的技术，如Transformer架构、Token算法等。但机器人需要与物理世界交互，所以我们还需要在算法和数据层面进行更多探索。</p><p><strong>高飞：您提到了算力和数据，我想追问现在合成数据、网络数据和仿真数据的比例情况，算力如何分配？是在云端还是本地？</strong></p><p><strong>陈建宇</strong>：目前数据比例还没有完全固定。比如在运动控制和行走方面，几乎全部依赖仿真数据，而操作方面则依赖真实世界的数据。未来可能会有更多发展。至于算力，机器人必须要有本地算力，尤其是对于延时和断网的零容忍问题。一般来说，小脑在本地，大脑在云端。</p><p><strong>高飞：最后一个问题，图灵时刻能否实现？人形机器人能否做到真假难分？请用一个字回答。</strong></p><p><strong>陈建宇</strong>：能。</p><p><strong>王鹤</strong>：一定能。</p><p><strong>王兴兴</strong>：能。</p><p><strong>张巍</strong>：一定和必须能。</p><p><strong>高飞</strong>：我相信这个目标能实现。正如那句话所说，“预测未来最好的方法就是创造它”。如果大家共同努力，这个“能”字一定会实现。最后，感谢几位嘉宾的参与，感谢各位观众。</p><p>本文来自“<a href="https://new.qq.com/rain/a/20240919A05TFT00" rel="noopener noreferrer nofollow" target="_blank">腾讯科技</a>”，作者：周小燕，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958139912178688</id>
            <title>Open o1不会“消灭”程序员</title>
            <link>https://www.36kr.com/p/2958139912178688</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958139912178688</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 10:58:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a3029078e98d4f5fa361dbe0446c0f9e@000000_oswg57557oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在当前大模型快速发展中，编程技术成为了许多企业争夺的焦点领域之一,通用大模型的发布往往伴随着诸如HumanEval等测试基准来衡量模型在编程领域的性能。此外，OpenAI CEO 萨姆·奥特曼多次在公开场合强调，最期待的大模型应用场景是如何在代码生成和编程效率提升领域实现真正的质变。这一观点背后不仅是技术专家对编程的深厚兴趣，更深层次地反映了AI商业化潜力、模型在实际应用中的广泛可能性，以及对未来市场格局的战略考量。</p><h2><strong>o1-mini 与 o1-preview 有望引爆AI 编程技术竞赛</strong></h2><p>在最新发布的o1-mini和o1-preview版本中，尽管在HumanEval基准测试中的提升仅为2.2%，看似相较于其前代产品GPT-4o并没有显著飞跃，但它们的实际技术进展却不可小觑。此次发布的重要亮点在于引入了Self-play Reinforcement Learning（自我博弈强化学习）和思维链。这一技术创新为大模型在代码生成领域带来了更强的自我学习和错误纠正能力，使模型不仅能够自主解决复杂问题，还能将其分解为更为简单易处理的步骤。这种技术进步不仅提升了理论上的推理和逻辑能力，更为重要的是在实际应用场景中显著提升了代码生成的效率和准确性。o1-mini和o1-preview版本通过模拟Codeforces的编程竞赛，按照实际编程环境中的规则评估其表现。在Codeforces测试中，o1-preview 和 o1的得分分别为1258和1673，远超GPT-4o。这不仅验证了自我博弈强化学习技术的有效性，也表明了o1系列模型在解决实际编程问题时的卓越表现。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_453f38f29ba34d1b8a45f3d9f3ee5507@000000_oswg87328oswg1080oswg669_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_40a02ec0399b4ae284c2fae948d9daa5@000000_oswg79668oswg836oswg431_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>新的技术基准有望建立，推动AI编程走向更高的水平。</strong>尽管HumanEval等基准测试在评估大模型能力方面提供了重要指标，但随着模型能力的逐渐提升，类似的测试已难以充分反映实际编程中的复杂性和挑战。HumanEval主要测量模型生成代码片段的正确性和质量，但在面对更复杂、更具生产价值的编程任务时，现有的测试已经显得过于基础。o1-mini和o1-preview版本的发布显示，AI编程能力的提升已经超越了传统基准测试的评估范围，未来可能需要更加严苛和更具现实性的benchmark来推动AI编程技术的发展。例如，未来的基准测试可能会更加侧重模型在真实开发环境中的表现，评估其在大型项目中的协作能力、代码复用和维护性，以及在不同编程语言和框架中的适应性。这不仅会对大模型的能力提出更高的要求，也会推动整个行业进一步提升AI编程技术的标准，为开发者提供更加智能和高效的工具。</p><p><strong>AI编程技术竞赛加剧，产品完善加速。</strong>随着o1-mini和o1-preview的发布，AI编程技术的竞赛将进入一个新的阶段。OpenAI凭借其在模型设计上的创新占据了领先地位，而这一进展也势必引发其他科技巨头和初创企业的迅速跟进。在未来的AI编程技术竞赛中，无论是谷歌、Anthropic、Meta等大模型公司，还是Anysphere、Cognition、Poolside、Magic Augment等AI 编程初创企业，都将加大对AI编程领域的投资和研发力度。此外基础模型的增强会提升专注做代码助手产品化的公司，例如 OpenAI 的最新o1模型现已在Anysphere的Cursor上推出，此外Cognition 也在产品中进行了实验，发现基于o1的devin在内部的测试基准上的性能远超GPT4o。未来，这些企业的共同努力，将进一步完善模型性能和产品，为用户提供更强大的AI编程工具。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_516999d80fb4489e97a783fa37285522@000000_oswg103602oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>AI编程商业化验证已经完成，具备明确市场增长空间</strong></h2><p><strong>盈利产品的成功验证了AI编程工具的商业化可行性。</strong>作为全球首个大规模商业化的大模型产品之一，GitHub Copilot的付费用户数量在短时间内迅速攀升。据统计，到2023年10月，GitHub Copilot的付费用户已突破100万，年经常性收入（ARR）更是达到1亿美元。这不仅验证了其商业化的可行性，也为其他类似产品的发展提供了重要参考。今年4月，GitHub Copilot的用户数增至180万，半年内增加了80万用户，表明其用户接受度和市场需求的迅速扩展。此外，GitHub Copilot在企业市场中的表现同样引人注目。在2024年7月的季度业绩发布中，微软宣布，已有77,000家机构在使用GitHub Copilot。这些机构用户包括一些行业巨头，如拉丁美洲的电商领军企业Mercado Libre和全球咨询巨头埃森哲。据称，这些公司在使用Copilot后，生产力提高了20-35%。GitHub Copilot的成功标志着AI编程工具商业化的重要里程碑，不仅为AI编程工具的商业化探索奠定了基础，还为未来其他AI编程产品的研发和推广提供了示范效应。</p><p><strong>用户需求旺盛，市场空间巨大。</strong>根据Evans Data Corporation的全球开发者人口和统计研究，2022年全球共有约2,690万软件开发者，预计到2024年这一数字将增长至2,870万，如此庞大的开发者群体为AI编程工具提供了广阔的市场空间。这些开发者不仅对提高生产力有着强烈需求，也展现出一定的付费意愿，根据CSDN的调查，在中国开发者中，44%的人愿意为AI编程工具支付「0-30元/月」的费用。尽管这一付费意愿相对较低，但随着AI编程工具的不断优化与功能的丰富，用户愿意为更高效的工具支付更多费用的可能性将逐步增加。此外，随着AI技术的普及，<strong>越来越多的非专业开发者也开始借助AI编程工具进行简单的程序开发和自动化任务处理。</strong>例如，Replit推出的Replit Agent为用户提供了从开发环境搭建到应用部署的一站式解决方案，吸引了大量毫无编程经验的用户。这种工具的简单易用性，使得非开发者群体也能借助自然语言交互实现编程功能，进一步扩大了AI编程工具的潜在市场。此外通用大模型也能支持用户直接代码生成，例如在o1-mini中，用户只需简单提示即可生成如贪吃蛇游戏的代码，并且能获得运行环境配置的详细指导。随着这些工具的功能日益强大，未来将有更多的行业用户和非开发者加入到AI编程工具的使用群体中，为市场带来更多增长动力。</p><p><strong>投资机构认可，支持力度较高。</strong>除了用户需求的增长，投资机构对AI编程工具的支持力度也在不断增强。许多初创公司通过融资获得了大量资金，以推动AI编程技术的进一步发展。例如，AI编程初创公司Augment最近宣布完成了2.52亿美元的融资，投后估值达到了9.77亿美元。这一轮融资为Augment的发展注入了强大动力，帮助其在竞争日益激烈的市场中占据一席之地。同样，今年8月，开发Cursor的AI编码助手的初创公司Anysphere完成了6000万美元的A轮融资，投后估值达到4亿美元。此外，美国旧金山AI编程初创公司Magic在一轮融资中筹集了3.2亿美元。九月，法国AI编程初创公司Poolside正在商谈近5亿美元的融资，且有望在发布首款产品之前就达到30亿美元的估值。这一系列融资案例表明，资本市场对AI编程工具的未来发展前景充满信心。这些初创公司能够吸引如此大规模的投资，证明了AI编程市场具有巨大的潜力。</p><h2><strong>编程能力进化即将开启大语言模型转化为行业生产力的序幕</strong></h2><p>在数字领域，代码是连接数字空间与物理世界的桥梁，无论是实现一个简单的功能模块，开发一个基础的应用程序，还是构建一个复杂的平台级产品，其背后都依赖于代码的精确编写与执行。近期有一场关于大模型理解能力的讨论引发了广泛关注，当用户询问“大模型，9.8和9.11哪个大”时，许多模型未能正确回答这一简单的数学比较问题，导致公众对其智能水平产生质疑。然而，这一现象的根源在于大模型的输出机制，大型语言模型通过概率分布来生成回答，其训练数据涵盖了广泛的语料，包括日期、目录、文本段落等多种上下文信息。当面对类似“9.8和9.11哪个大”这样的问题时，模型可能会根据上下文误判问题的类型，将其解释为日期或其他非纯数学问题，从而给出错误的回答，即使是OpenAI最新的o1-mini也可能存在回答错误的情况。但是将这个问题转化为编程问题后，几乎所有模型都能给出正确的代码。这种将问题转化为编程问题的能力正是很多行业性场景可以构建应用的支撑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_8dd0ebc4e75b4a50a6a0d4a71e10bae7@000000_oswg35135oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对很多行业来说，目前大语言模型的应用主要聚焦在文字撰写、文档处理等非核心生产的场景中，即使是基于RAG模式外挂知识库或者微调等方式来进行知识问答、客服等应用的构建，但对企业的生产力提升比较有限。但是伴随着大语言模型在编程领域能力的提升，相信会有更多的行业问题通过编程解决。例如在金融领域，平安银行依托多语言代码生成大模型，基于行内数据微调，打造更契合银行的代码生成Copilot，持续提升全行开发人员效率，工商银行、中信银行等都在探索基于大模型的编程应用。在工业领域，西门子Industrial Copilot能够帮助工程团队为可编程逻辑控制器（PLC）生成基础的虚拟化任务和代码，并自动处理重复性任务，在大幅减少工程团队工作量的同时保证复杂任务的工程设计不易出错，从而缩短开发时间、提高质量和生产率。此外芯片设计、Cam等工业软件厂商都在探索工业代码生成。</p><h2><strong>AI 编程进入规模化应用阶段仍需解决诸多技术和产品问题</strong></h2><p><strong>应用场景需要进一步拓展和丰富。</strong>当前AI编程工具的应用场景主要集中在代码生成和代码补全。这些功能解决了开发者在编写常规代码时的效率问题，但其作用相对单一，无法全面满足整个软件开发生命周期的需求。要实现规模化应用，AI编程工具必须向更多关键场景拓展，包括自动化测试、调试、跨平台开发和运维等。通过将AI引入软件开发的每个环节，真正实现开发过程的智能化和自动化，减少开发人员的工作负担，同时提高生产效率。例如，测试和调试占据了开发流程中的大量时间，自动化生成测试用例、识别潜在错误将大幅度提高软件开发的整体效率，不仅能够减少人工干预，还降低了错误率，确保代码质量的同时加速产品交付。在跨平台方面，AI工具需要在不同开发环境下提供一致的性能和功能，满足前端、后端、移动应用等多种开发需求，从而增强工具的适用性。</p><p><strong>复杂逻辑处理与业务理解能力需要提升。</strong>尽管AI编程工具在语法和代码补全方面已经取得了较大进展，但在处理复杂业务逻辑和深度业务背景时仍然力有不逮。在应对复杂业务场景时，AI的能力远未达到成熟。要实现这一目标，需要通过更深层次的模型训练和算法优化，使AI能够处理多层次的业务逻辑，帮助开发者编写更高效、更灵活的代码。此外，AI难以具备人类开发者在理解业务背景、设计初衷和长期维护性方面的能力，AI编程工具应加强对业务场景的深入学习，不仅能生成符合当前需求的代码，还能理解项目的长期目标和设计哲学。这需要AI具备深度的推理和理解能力，结合项目的历史数据、上下文信息做出更加智能化的判断。</p><p><strong>版权和安全问题亟需解决。</strong>随着AI编程工具的大规模应用，版权和安全问题逐渐成为焦点。当前AI编程工具，虽然提高了开发效率，但其生成的代码潜在涉及版权问题，可能与现有代码库相似，带来法律风险。同时，安全性问题也逐渐显现，AI生成的代码可能存在潜在的漏洞或隐患，影响软件安全性。为了避免侵犯第三方版权，未来AI编程工具在生成代码时必须对训练数据进行更严格的筛选，确保生成代码的原创性和合法性。此外，还需具备版权风险检测机制，自动判断生成代码是否与现有开源代码或商业代码存在相似性，及时提出警告并给出替代方案。在安全方面，如何整合安全漏洞检测功能也是重点，从而能够在代码生成的同时识别潜在的安全隐患，并为开发者提供自动修复建议，确保开发者在代码生成过程中不仅提升效率，还能保证软件的安全性，防止由于AI生成代码带来的安全漏洞问题。</p><p><strong>李南 </strong>腾讯研究院高级研究员</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&amp;mid=2650978527&amp;idx=1&amp;sn=d18e220bdff9d1e7b955f4be3c5a1824&amp;chksm=bdd104fffb41329c51c5418f1a146333f74c79fc2b965b29a60277cdb4ab1abba809823bc1f5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“腾讯研究院”（ID：cyberlawrc）</a>，作者：李南，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958051005144713</id>
            <title>岛聪：AI革命时代，在胜算和业务达到7成时开始投资</title>
            <link>https://www.36kr.com/p/2958051005144713</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958051005144713</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 10:53:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote><p>说起岛聪，不得不提的是软银和孙正义，因为岛聪作为孙正义的前高参，为软银避开多次风险，外道超车，开辟出新航路。&nbsp;</p></blockquote><p>2006年，软银刚乘着智能手机革命的东风转型，却面临赤字的拦路虎，岛聪向孙正义进言，让软银在营业额1.1万亿元时，接连创下三个奇迹：收购了1.75万亿元的沃达丰；营业额突破3倍；弯道超车NTT的118年和丰田的65年，用“33年缔造一万亿神话”。&nbsp;</p><p>如今，在已经到来的AI革命中， <strong>岛聪</strong>又将提出怎样的商业见解？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_12dffb1a4935412f9d72e4273a21b66a@2058160310_oswg316749oswg1080oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>01 变革：AI技术革命，企业和员工共同履行使命</strong></h2><p>软银当年的成功离不开智能手机革命，对于在座的各位创业领导人来说，<strong>当下又来到了时代转型的关键点，最重要的是，如何在自己的公司里面，运用AI技术进行革命。</strong></p><p>开展AI革命的先手棋，是要做好一个企业。 为此，日本很多人开始流行学中国的帝王学，通过对《贞观政要》里的深入学习，大家得出了现代版的结论：做一个企业，有三个必要条件，一是目标经营模式，二是有外部的董事，三是有参谋长。像我在软银期间，软银的外部董事是优衣库的创始人刘景先生，而这个参谋长就是我。&nbsp;</p><p><strong>开展AI革命的理论武器，是借用稻盛和夫先生的成功方程式。</strong></p><h3><strong>人生 · 工作的成果 = 思维方式 × 热情 × 能力</strong></h3><p>大家首先要努力让热情和能力达到100分，同时重点关注思维模式，因为在这个过程中如果思维模式是负数，那么其他部分即便再努力，结果也是不尽人意的。所以我在成功方程式上，融入了自己的想法，把思维模式分解为理念加战略，并把理念分为道长地，战略分为一流七。&nbsp;</p><h3><strong>所谓道，就是知道自己的使命</strong></h3><p>当年松下幸之助先生创业时，从未考虑过自己的使命，尽管如此，依然没有阻挡他在30多岁时就获得相当大的成功，拥有1000名员工。但也就是在这时，他的公司突然停止成长。&nbsp;</p><h3><strong>为了帮公司在成长困境中破局，松下幸之助思考出第一个使命——水道哲学</strong></h3><p>意思是不可更改的内容绝不更改。他把松下电器的使命定为：“无穷无尽的提供廉价物资，在世间建造乐土。”之后，他致力于降低家电的价格，让人们能像一打开水龙头就能流水一样买到家电，尤其想减少女性做家务的数量，解放更多女性自由时间。他告诉员工，我们的努力，是要提高人民的生活幸福度，而这在无形之中也让员工们感受到了自己的使命。&nbsp;</p><h3><strong>第二个使命——企业是社会的公器。</strong></h3><p>在日本曾经有一种认知，公司赚太多钱会有罪恶感。但松下幸之助的理念是“使用天下的资本，驱使天下的国民来做事业，如果还不能获得利润，理应受到惩罚”。当他经历了思考使命、发现使命、使命被员工接受的过程之后，企业就又开始成长了，成功从1000多人发展到8万多人。&nbsp;</p><h2><strong>02 开拓：志本经营模式，用技能重塑应对AI挑战</strong></h2><p>在“道”的引领之下，我又提出了“长”，即越是<strong>犹豫不决时越要关注未来局势的发展，那么此时眼前的问题自然只会成为“误差”</strong>。在人类历史上，曾经发生过三次大型疫情，鼠疫、西班牙大流感和新冠。从死亡人数上来看，鼠疫和西班牙大流感都达到了5000万人，新冠疫情的死亡人数不到700万人。<strong>这三次疫情不约而同地催生了三次变革</strong>，鼠疫之后发生了文艺复兴，西班牙大流感后发生了霸权变革，所以在今年的达沃斯会议上也提到一个观点，AI革命将像文艺复兴一样出现。由于AI革命不需要基础设施，所以它的变革速度将发展地更快。</p><p><strong>当AI革命出现后，人类会被AI取代吗？</strong>在去年的达沃斯会议上，有一个耐人寻味的调查问卷，什么时候人的劳动量和AI机器人的劳动量会变得一样?参加达沃斯会议的领导人们，最后得出了2025年可以实现的结果，并且把它写进了公司计划里。<strong>这些领导人的理由是，到了2025年，由于数字化转型等原因，将有8500万个工作岗位被取代。</strong>但是，我们也不用太过悲观，因为那时预计将产生AI专家等9700万个新岗位，我们需要做的是完成技能重塑，积极应对挑战。</p><p><strong>AI革命如同西伯利亚的蝴蝶，轻轻扇动翅膀，不仅带来了劳动力的变化，还带来了经营模式的变化，由志本主义取代了原本的新自由主义和市场主义。</strong>软银坚持的”道”，用现代的话来说就是志本主义经营模式，在20世纪末，美国企业和日本几大巨头公司坚持的还是新自由主义和市场主义，各位经营者的使命是“令股东利益最大化”。比如日本某些开发游戏的公司，如果把产品放在苹果的速尔销售，需要付出营业额的30%，这不成文的商业规则，已经遭到了EU的反抗，据说EU会将这30%降到10%左右。</p><p>在孙正义先生53岁，创业30周年时，他曾说出这样一句话“希望软银成为人们最需要的公司”，这也是“通过信息革命使人们幸福”理论的进化。</p><p><strong>为了让软银在新领域开疆拓土，孙正义采用了志本主义的经营模式。</strong>第一，企业不仅要重视股东，还应重视社会、员工等利益相关者的利益。第二，企业不仅要令本公司的利益最大化，还应重视企业发展的目的。</p><p>从2021年疫情中期开始，世界范围内的很多经营者，都觉得新自由主义和市场主义不能持续发展了，于是他们开始重视志本主义经营，想要考虑社会、员工，所有相关利益人的利益。在日本，松下幸之助先生和稻盛和夫老先生一直都在积极践行这种模式。值得一提的是，软银自开始采用志本经营之后，营业额拥有了比较大的上升，股价也随之呈上涨趋势。</p><h2><strong>03 收获：建立长寿企业模式，开启企业航海家时代</strong></h2><h3><strong>在AI革命里，也出现了新的问题拐点。</strong></h3><p>英伟达和特斯拉加入七大巨头阵营，中国暂时“隐退”，彼时，欧洲学者熊彼特提出AI革命创新方法，即把现有业务加上新的AI技术重新结合。因此，七大巨头纷纷朝着这个方向研发，力求AI技术的更加强大。</p><h3><strong>七大巨头间展开激烈角逐，给股市掀起新一轮波澜。</strong></h3><p>在市值上面，中国和美国公司的差距，也创造了历史新高。最近经常有人问我，为什么日本的股市现在上涨的这么好，我认为是那些北上资金从中国流到日本了，但这让很多人都开始担心A股将何去何从。</p><p>作为一个手里也持有A股的人，我建议大家从长远角度来考虑。虽然在世界范围内，中国股票的份额只剩下一半，但从长远目标来看，中国还是非常强势的。美国高盛做了一项预测，中国的经济规模将在2035年超越美国，并会持续保持到2075年。预测中还提到，等到2050年时，将会呈现以下顺序的排列趋势，中国、美国、印度、印度尼西亚、德国、日本，然后在2075年，呈现中国第一，印度第二，美国第三的排序。</p><h3><strong>AI革命不仅使股市发生了震荡，还对企业的寿命发出了挑战。</strong></h3><p>现在一个企业的平均寿命大概只有30年，在日本，能够生存30年以上的公司，只有0.02%，其中，最多的还是酿酒、旅馆、酒店等行业，但经营这些行业的前提是获得特殊许可，虽然准入门槛较高，但进入之后，就相对容易活下来。据统计，日本有25312家百年企业，居全球首位。</p><p>想要打造长寿企业的模型，就需要先进入准入门槛高且需要特殊许可的行业，再用它的利润率投资房地产和股票。借用这种思路，我和孙正义一起打通了现代版的操作模型，我们先是进入了只有3家企业的通信行业，然后用利润的现金流进行投资，我们的目标不是成为百年企业，而是成为300年企业。</p><h3><strong>所以面对AI革命的杀手锏到是什么</strong>？</h3><p>可以参考孙正义在投资方面的独门秘籍，<strong>即在胜算和业务达到7成的时候开始投资。</strong>在手机革命开始之前，软银就投资了阿里巴巴，获得了4000倍的回报。孙正义说，他觉得日本企业<strong>在胜率9成时下手太晚，在6成时风险太大。所以需要在有5成胜算时，先发现这个新的公司，再给它提供一些财政和技术上的帮助，进一步帮助它成长为7成胜算，从而吸引更多人前来投资。</strong></p><p>那么，如何判断6成还是7成呢？起初要看经营数据，最后判断时还是要靠经营者的感觉，孙正义说如果经营者从年轻时，就开始不断的经历这种判断，在积累了多年经验之后，就可以比电脑判断的还精准了。</p><p>※&nbsp; 本文根据岛聪先生在创业营8&amp;9期日本模块课程分享内容整理而成。&nbsp;</p><p>本文来自微信公众号“中欧创业营”（ID:CEIBS_CELC），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958184352648197</id>
            <title>张俊林：OpenAI o1的价值意义及强化学习的Scaling Law</title>
            <link>https://www.36kr.com/p/2958184352648197</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958184352648197</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 10:42:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>蹭下热度谈谈 OpenAI o1 的价值意义及 RL 的 Scaling law。&nbsp;</p><h2><strong>一、OpenAI o1 是大模型的巨大进步</strong></h2><p>我觉得 OpenAI o1 是自 GPT-4 发布以来，基座大模型最大的进展，逻辑推理能力提升的效果和方法比预想的要好，GPT-4o 和 o1 是发展大模型不同的方向，但是 o1 这个方向更根本，重要性也比 GPT-4o 这种方向要重要得多，原因下面会分析。&nbsp;</p><p><strong>为什么说 o1 比 4o 方向重要？</strong> 这是两种不同的大模型发展思路，说实话在看到 GPT-4o 发布的时候我是有些失望的，我当时以为 OpenAI 会优先做 o1 这种方向，但是没想到先出了 GPT-4o。 GPT-4o 本质上是要探索不同模态相互融合的大一统模型应该怎么做的问题，对于提升大模型的智力水平估计帮助不大； 而 o1 本质上是在探索大模型在 AGI 路上能走多远、天花板在哪里的问题，很明显第二个问题更重要。&nbsp;</p><p>GPT-4o 的问题在于本身大模型的智力水平还不够高，所以做不了复杂任务，导致很多应用场景无法实用化，而指望靠图片、视频这类新模态数据大幅提升大模型智力水平是不太可能的，尽管确实能拓展更丰富的多模态应用场景，但这类数据弥补的更多是大模型对外在多模态世界的感知能力，而不是认知能力。提升大模型认知能力主要还要靠 LLM 文本模型，而提升 LLM 模型认知能力的核心又在复杂逻辑推理能力。LLM 的逻辑推理能力越强，则能解锁更多复杂应用，大模型应用的天花板就越高，所以不遗余力地提升大模型尤其是文本模型的逻辑能力应该是最重要的事情，没有之一。</p><p>如果 o1 模型能力越做越强，则可以反哺 GPT-4o 这种多模态大一统模型，可以通过直接用 o1 基座模型替换 GPT-4o 的基座、或者利用 o1 模型生成逻辑推理方面的合成数据增强 GPT-4o、再或者用 o1 蒸馏 GPT-4o 模型….. 等等，能玩的花样应该有很多，都可以直接提升 GPT-4o 的复杂任务解决能力，从而解锁更复杂的多模态应用场景。OpenAI 未来计划两条线，一条是 o1，一条是 GPT-4o，它的内在逻辑大概应该是这样的，就是说通过 o1 增强最重要的基座模型逻辑推理能力，而再把这种能力迁移到 GPT-4o 这种多模态通用模型上。</p><p><strong>OpenAI o1 的做法本质上是 CoT 的自动化。</strong> 我们知道，通过 CoT 把一个复杂问题拆解成若干简单步骤，这有利于大模型解决复杂逻辑问题，但之前主要靠人工写 CoT 来达成。 从用户提出的问题形成树的根结点出发，最终走到给出正确答案，可以想像成类似 AlphaGo 下棋，形成了巨大的由 CoT 具体步骤构成的树形搜索空间，这里 CoT 的具体步骤的组合空间是巨大的，人写的 CoT 未必最优。 如果我们有大量逻辑数据，是由 &lt;问题，明确的正确答案&gt; 构成，则通过类似 AlphaGo 的 Monte Carlo Tree Search（MCTS）搜索 + 强化学习，确实是可以训练大模型快速找到通向正确答案的 CoT 路径的。&nbsp;</p><p>而问题越复杂，则这个树的搜索空间越大，搜索复杂度越高，找到正确答案涉及到的 CoT 步骤越多，则模型生成的 CoT 就越复杂，体现在 o1 的速度越慢，生成的 CoT Token 数越多。很明显，问题越复杂，o1 自己生成的隐藏的 CoT 越长，大模型推理成本越高，但效果最重要，成本其实不是问题，最近一年大模型推理成本降低速度奇快，这个总有办法快速降下去。</p><p><strong>从上面 o1 的做法可以知道 Prompt 工程会逐渐消亡。</strong> 之前解决复杂问题，需要人写非常复杂的 Prompt，而 o1 本质上是 CoT 等复杂 Prompt 的自动化，所以之后是不太需要用户自己构造复杂 Prompt 的。 本来让用户写复杂 Prompt 就是不人性化的，所有复杂人工环节的自动化，这肯定是大势所趋。&nbsp;</p><p><strong>Agent 属于概念火但无法实用化的方向，</strong> 主要原因就在于基座模型的复杂推理能力不够强。 如果通过基座模型 Plan 把一个复杂任务分解为 10 个步骤，哪怕单个步骤的正确率高达 95%，要想最后把任务做对，10 个环节的准确率连乘下来，最终的正确率只有 59%，惨不忍睹。 那有了 o1 是不是这个方向就前途坦荡？ 也是也不是，o1 的 Model Card 专门测试了 Agent 任务，对于简单和中等难度的 Agent 任务有明显提升，但是复杂的、环节多的任务准确率还是不太高。 就是说，不是说有了 o1 Agent 就现状光明，但是很明显 o1 这种通过 Self Play 增强逻辑推理能力的方向应该还有很大的发展潜力，从这个角度讲说 Agent 未来前途光明问题应该不大。&nbsp;</p><p><strong>OpenAI 很多时候起到一个行业指路明灯的作用</strong> ，往往是第一个证明某个方向是行得通的（比如 ChatGPT、GPT-4、Sora、GPT-4o 包括这次的 o1），然后其他人开始疯狂往这个方向卷，到后来甚至卷的速度太快把 OpenAI 都甩到后面吃尾气。典型例子就是 Sora，如果 OpenAI 不是出于阻击竞争对手秀一下肌肉，大家都没有意识到原来这个方向是可以走这么远的，但当意识到这一点后，只要你专一地卷一个方向，方向明确且资源聚焦，是可能赶超 OpenAI 的，目前国内外各种视频生成模型有些甚至可能已经比 Sora 好了，Sora 至今仍然是期货状态，主要 OpenAI 想做的方向太多，资源分散导致分到具体一个方向的资源不够用，所以越往后发展期货状态的方向越多，也让人觉得尽显疲态。&nbsp;</p><p>OpenAI o1 等于给大家又指出了一个前景光明的方向，估计后面大家又开始都往这个方向卷。我觉得卷这个方向比去卷 GPT-4o 和视频生成要好，虽然具体怎么做的都不知道，但是大方向清楚且效果基本得到证明，过半年肯定头部几家都能摸清具体技术追上来，希望能再次让 OpenAI 吃尾气。而且这个方向看上去资源耗费应该不会特别大，偏向算法和数据一些，数据量规模估计不会特别巨大，卷起来貌似成本低一些。这是个卷的好方向。</p><h2><strong>二、预训练 Scaling Law 的来源及 O1 提到的 RL Scaling law</strong></h2><p><strong>粗分的话，大语言模型最基础的能力有三种</strong> ：语言理解和表达能力、世界知识存储和查询能力以及逻辑推理能力（包括数学、Coding、推理等理科能力，这里 Coding 有一定的特殊性，是语言能力和逻辑掺杂在一起的混合能力，Coding 从语言角度可以看成一种受限的自然语言，但是混杂着复杂的内在逻辑问题。从语言角度看，Coding 貌似是容易解决的，从逻辑角度看又相对难解决。总之，Coding 目前看是除了语言理解外，大模型做得最好的方向）。&nbsp;</p><p>语言理解和表达是 LLM 最强的能力，初版 ChatGPT 就可以完全胜任各种纯语言交流的任务，基本达到人类水准，目前即使是小模型，在这方面比大模型能力也不弱；世界知识能力虽说随着模型规模越大效果越好，但幻觉问题目前无法根治，这是制约各种应用的硬伤之一；逻辑推理能力一直都是 LLM 的弱项，也是最难提升的方面，从 GPT-4 开始往后，如何有效并大幅提升 LLM 的逻辑推理能力是体现不同大模型差异和优势的最核心问题。所以，大模型最重要的一个是世界知识方面如何有效消除幻觉，一个是如何大幅提升复杂逻辑推理能力。语言能力已不是问题。&nbsp;</p><p><strong>从大模型的基础能力，我们再说回已经被谈滥了的大模型 Scaling law</strong> 。现在普遍认为通过增加数据和模型规模来提升大模型效果的 Scaling law 模式，其增长速度在放缓。其实我们对照下大模型的三个基础能力的能力来源，基本就能看出来这是为啥（以下是我猜的，不保真）：&nbsp;</p><p>本质上大模型的能力来源都来自训练数据，包含能体现这方面能力的训练数据越多，则这种能力越强。语言能力不用说了，任意一份预训练数据，其中都包含相当比例的语言的词法句法等成分，所以训练数据中体现语言能力的数据是最多的，这也是为何大模型的语言能力最强的原因。&nbsp;</p><p>而数据中包含的世界知识含量，基本是和训练数据量成正比的，明显数据量越多，包含的世界知识越多，Scaling law 是数据中包含的世界知识含量关系的一个体现，但是这里有个问题，大模型见过越多数据，则新数据里面包含的新知识比例越小，因为很多知识在之前的数据里都见过了，所以随着数据规模增大，遇到的新知识比例就越低，在世界知识方面就体现出 Scaling law 的减缓现象。</p><p>为啥逻辑推理能力最难提升？因为能体现这方面的自然数据（代码、数学题、物理题、科学论文等）在训练数据中比例太低，自然大模型就学不好，尽管通过不断增加数据，能增加逻辑推理方面数据的绝对数量，但因为占比太少，这方面提升的效果和增加的总体数据规模就不成比例，效果也不会太明显，就体现在逻辑推理能力 Scaling law 看上去的放缓。这是很自然的。这也是为何现在为了提高模型逻辑能力，往往在预训练阶段和 Post-training 阶段，大幅增加逻辑推理数据占比的原因，且是有成效的。</p><p><strong>所以，目前大模型的核心能力提升，聚焦到不断通过合成数据等方式构造更多比例的逻辑推理数据上来。</strong> 但是大部分逻辑推理数据的形式是 &lt; 问题，正确答案 &gt;，缺了中间的详细推理步骤，而 o1 本质上是让大模型学会自动寻找从问题到正确答案的中间步骤，以此来增强复杂问题的解决能力。&nbsp;</p><p>OpenAI o1 提到了关于 RL 在训练和推理时候的 Scaling law，并指出这与预训练时候的 Scaling law 具有不同特性。很明显，如果 o1 走的是 MCTS 搜索技术路线，那么把 CoT 拆分的越细（增加搜索树的深度），或提出更多的可能选择（节点的分支增多，就是说树的宽度越宽），则搜索空间越大，找到好 CoT 路径可能性越大，效果越好，而训练和推理的时候需要算力肯定越大。看上去有着效果随着算力增长而增长的态势，也就是所谓的 RL 的 Scaling law。这其实是树搜索本来应有之义，我倒觉得把这个称为 RL 的 Scaling law 有点名不副实。&nbsp;</p><p>本文仅为作者观点，不代表学术头条的立场。&nbsp;</p><p>内容来自：张俊林&nbsp;新浪新技术研发负责人&nbsp;</p><p>原文链接：https://weibo.com/1064649941/OwPn2auby&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Jmj-ucZnskJacmJr4IXSIQ" rel="noopener noreferrer nofollow" target="_blank">“学术头条”</a>，作者：张俊林，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2957903459387143</id>
            <title>售价高达100万的AI产品，有钱人排队求买，为什么？</title>
            <link>https://www.36kr.com/p/2957903459387143</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2957903459387143</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 10:32:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a9e7abaa8d3e4dffba67a2743040782c@000000_oswg63920oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从帝王将相到亿万富豪，永生一直是掌握权力和财富的人类金字塔尖阶层的执念。过去他们把财富投入到虚无缥缈的寻仙问道，以及延年益寿的生物科技，而随着 AI 的出现，赛博永生引起了富豪们的兴趣。&nbsp;</p><p>近日，笔者接触了石榴科技创始人 Frank，他做了一款未来有望实现「数字永生」的产品——从记忆承载-思想复刻-意识上传-最后到数字永生，高达 100 万的售价，却已有 10 多位 70 岁以上的香港富豪为之买单。&nbsp;</p><p>这款名为「意识永藏」的产品，通过定制个人化小模型，可以将一个人的记忆、经历和生活故事转化为数字化的个人记忆博物馆。这个博物馆不仅仅是一个静态的展示，而是一个动态的、互动的、并且能够随着时间不断更新和扩展的个人历史档案。&nbsp;</p><p>在具体的产品交付上，「意识永藏」有三方面的内容，包括个人的记忆库、基于个人记忆数据训练得出的个人分身小模型以及一个数字形象或者个人传记的外化效果呈现；在交付形式上，项目采用本地部署方式，将交互系统集成到用户的电脑中（系统包含一个数据库和一个小型 AI 模型），形成一个网页形态的个人化产品。&nbsp;</p><p>就是这个看起来并不复杂的产品，为什么能让精明的香港富豪豪掷百万？Frank 给我们讲了讲背后的故事。&nbsp;</p><h2><strong>数字永生——用 AI 传承家族记忆</strong></h2><p>「意识永藏」这个项目，最初来自 Frank 一个朋友的执念。&nbsp;</p><p>朋友是福建闽南人，是对家族记忆传承，对家谱、对祠堂有一些执念在的，有次闲聊中朋友找到 Frank，问他能不能用 AI 的方式把家族记忆比较好地留存下来，最好能超越传统纪录片、传记或家谱的局限，实现将家族记忆像刻在石头上一样永久保存的方式，「实现一种数字化的永恒」。&nbsp;</p><p>Frank 之前和团队做过虚拟陪伴类产品，相当于 agent 平台，他想到可以朋友的执念可以通过类似思路实现，只不过是更加个性化，即个人记忆库+小模型。&nbsp;</p><p>大概思路定下来了，接着就是具体操作。首先是采集信息，接着是调试定制模型，最后是效果外化。&nbsp;</p><p><strong>信息采集是项目的基础环节，分为线下访谈和线上全天候数据收集。</strong></p><p>线下部分，通过八次面对面访谈，团队对用户进行详细的问询，拍照记录，并通过对细节的严格把控，深入了解用户的需求和个性化习惯。通过这种面对面的沟通，尽量确保采集数据的准确性和真实性。&nbsp;</p><p>线上部分则通过全天候的数据收集工具实现。团队为用户设计了一个包含 268 个问题的题库，日常可以通过智能耳机进行录音。当耳机提示时，用户只需轻声回答问题即可。&nbsp;</p><p>这种线上线下相结合的采集方式，保证了信息的丰富性和多样性，为后续模型的调试提供了坚实的数据基础。&nbsp;</p><p><strong>在信息采集后，团队会根据每位用户的需求，调整和优化AI模型的个性化配置。</strong>调试不仅仅是对模型的技术调优，更是对用户行为和习惯的深度匹配。&nbsp;</p><p><strong>最后的效果外化即产品交付上</strong>，可以理解为属于用户的本地部署版的专属 ChatGPT，譬如「某某 GPT」。&nbsp;</p><p>从信息采集到产品交付包括后续服务，「意识永藏」的项目周期长达十年。在项目初期，团队一度低估了实现个人记忆复刻的复杂性，本来以为三个月或一年时间就能完成。&nbsp;</p><p>随着项目推进，团队逐渐意识到，要做到对思想的复刻、意识的上传，甚至是基础的个人记忆还原，远非短期内能够实现，就像传记作家撰写人物传记一样，往往需要数年的深入采访和跟踪。所以后来团队决定将服务周期延展至十年，以确保达到理想效果。&nbsp;</p><p>十年的服务，要收多少钱？&nbsp;</p><p>Frank 给出的答案是——理想状态是 200 万，一个 100 万包括前期的数据和模型的搭建，另一个 100 万则包括后面 10 年每一年的信息更新和持续服务。&nbsp;</p><p>对大多数人来说，这是个不低甚至昂贵的价格。但这个项目本身就不是瞄着大众人群推出的，而是对准了 70 岁以上的香港富豪这个群体，他们大多经历了上个时代周期的繁华，财力雄厚，每年在保险、养老及高端服务上的支出巨大——仅保险一项，他们的年花费就超过 50 万元，私人医生费用在 100 万到 200 万元之间，而财富管理的年支出也在一两百万。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_39f1c2db209046e3b47df03ce21548e1@000000_oswg124307oswg1080oswg826_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：豆包&nbsp;</p><p>对于对高端定制服务有着强烈需求的他们来说，「意识永藏」正是为他们提供个性化记忆复刻的独特选择。对他们而言，再花一两百万来给记忆上一道保险并不昂贵。&nbsp;</p><p>但一两百万毕竟也是 7 位数的消费，一个仅仅只有五人左右的 95 后团队，到底是怎么打动这群富豪的？&nbsp;</p><p>关键还是在于情感需求的满足。&nbsp;</p><p>Frank 讲述了一个客户的故事。一位已经进入耄耋之年的老教授，退休多年，之前已经进过 ICU 病房，子女又因为他的身后事纠纷不少。&nbsp;</p><p>想到身体每况愈下，时间所剩无几，老教授想尽可能地在生前多留下一些东西，一来满足对子女的一些心理亏欠，二来也想好好回看自己过去这一生的路。&nbsp;</p><p>在进行完前期的信息采集和初步的模型调试后，团队用可灵大模型给老教授生成了一些和儿女相处的温馨的视频片段，看完之后老人忍不住掉泪，往日时光已不可追，但 AI 竟然可以如此逼真地还原过往，带他回去看了一眼。&nbsp;</p><p>不止如此，在跟产品对话的过程中，老人感觉自己面对的不是一个机械化的产品，而是一个永远在倾听、在支持他、理解他，永远站在他的立场的一个温柔且温暖的拟人化存在。&nbsp;</p><p>不光是 AI 实现的情感需求的满足，团队采集信息的过程，也是一种情感陪伴。 Frank 说起跟客户的沟通过程，「有一些对我们总是笑眯眯的，特别想让我们去做客，去聊天，其实也是一种陪伴」，客户享受这种被热热闹闹的一群年轻人围着做采访，对自己的人生经历感到好奇的感受，Frank 也能理解，「被看见是一种最大的尊重。 」&nbsp;</p><p>对这些年事已高的老年富豪来说，钱变得不是那么重要，充斥在生活里的巨大的落寞才是更重要或者说更沉重的存在。&nbsp;</p><p>他们年轻时多数在各自的事业上颇有所为，但随着年岁渐衰，过往投射在身上的注视与光芒逐渐退去，而 Frank 及其团队围绕着他们，对他们的过往好奇，一些他们本已经做好准备带进棺材里的故事，被人关心，被人在意，他们诉说的过程，也是一种过往经历焕发新的活力的过程。&nbsp;</p><p>Frank 及其团队持续给到这些老年人的情感陪伴，使得后者逐渐与他们建立起深厚的信任感，和一般的甲乙方之间的信任感不同，他们的这份信任感上，多了一些情感依赖。&nbsp;</p><h2><strong>百万级 AI 产品的背后：技术占比只有 10%？</strong></h2><p>笔者最初注意到这个产品，是被客单价百万的 AI 产品这个名号所吸引。毕竟现在市面上似乎很少有做到这么高客单价的 AI 产品？&nbsp;</p><p>但与 Frank 交流下来发现，AI 在这款产品中发挥的功能可能只占比 10%-20%，「我们现在对 AI 的利用还比较初期，集中在利用模型将将用户的语音转换成文本，以及通过文本到语音（TTS）技术来训练和模仿用户的声线和语调。」Frank 告诉极客公园。&nbsp;</p><p>在模型调试定制环节，「意识永藏」底层模型使用的是被称为「价格屠夫」的 DeepSeek，后者是幻方量化旗下深度求索推出的开源大模型。&nbsp;</p><p>在众多大模型中选择 DeepSeek，价格原因之外，也是因为项目是围绕个人记忆检索与反馈构建的，对于基础模型能力的要求并不苛刻，DeepSeek 能够通过提示词引导，准确检索信息并进行相关性反馈，已经足以完全满足需求。&nbsp;</p><p>要求比较高的环节在于对心理、情感表达的识别与反馈，毕竟每个人的情感与人生经历迥异，使得这使得模型在表达个体独特的情绪和情感时，面临更高的挑战。&nbsp;</p><p>为了精准捕捉这些微妙差异，团队一方面把 Prompt 优化得足够具体，使模型能够更好地理解和回应用户的个性化需求，另一方面，团队对模型进行了细致的微调，例如，通过设定特定情感的触发临界值，使系统能识别并模仿用户的情绪反应。&nbsp;</p><p>此外，团队还对个人的口头禅、语言习惯等细节进行了调校，确保模型在交互中更加贴合用户的语言风格与情感表达。&nbsp;</p><p>除了高昂费用的噱头，这个项目更长远的意义在于：<strong>AI 的出现，对于个人信息的记录带来了新的可能性。</strong></p><p>相比于过去单调的信息存储式的记录形式，如自传式书籍、电影等，AI 实现了互动的重塑，它让记忆不再只是静态的片段，而是可以对话、追问的对象。&nbsp;</p><p>即使某些记忆开始模糊，AI 也能帮助检索并给予反馈，带来一种情感化的互动体验，这正是传统记录手段所无法比拟的。&nbsp;</p><p>并且，多模态技术还能让记忆变得更为生动：声音可以被复刻，影像和视频也能被重现。&nbsp;</p><p>借助 AI 技术，回忆变得更加立体和鲜活，让那些过去的瞬间仿佛历历在目。但这些看起来似乎并不是属于 Frank 团队难以复刻的差异化优势，可能换一家公司采用类似的思路，也能做出大差不差的产品。&nbsp;</p><p>那「意识永藏」的壁垒是什么？&nbsp;</p><p><strong>答案可能是渠道。</strong>Frank 没有去卷大多数人正在争夺的主战场，而是选择了一个小范围的需要高度定制化服务的细分领域，后者获客非常艰难，毕竟高净值人群对服务的选择会更挑剔，Frank 现有的客户也基本来自客户小圈子里互相介绍而来，这种渠道壁垒，决定了其模式短时间内难以被取代。&nbsp;</p><p>现阶段，能让用户心甘情愿买单的 AI 产品并不多，何况是百万级客单价的 AI 产品。但 Frank 通过精准定位以及满足特定人群的个性化需求，借助 AI 在内的技术手段，成功让客户买单百万级产品。&nbsp;</p><p>这可能是一个相对极端的 AI 商业化案例，但也可以看出，在当下，AI 要产生价值，就是要对齐到有支付能力的明确需求。&nbsp;</p><p>*头图来源：石榴科技&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653055041&amp;idx=1&amp;sn=6edd0e3e8643ba09b5f0e0de456fdb95&amp;chksm=7f5c835a37ef43541d29ed124e8f00bac4dbcd53b66302302ab5b6c078161b404321de64f380&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：连冉，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958194964417794</id>
            <title>合元集团Alkaid光加热技术的问世，为电子雾化行业带来了新启发</title>
            <link>https://www.36kr.com/p/2958194964417794</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958194964417794</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 09:55:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作为近年来全球新消费领域最火热的细分赛道之一，电子雾化烟的发展受到了各界的高度关注。如何用技术实现环保减害的目标，是雾化烟企业长期的课题。</p><p>德国多特蒙德国际烟草展（InterTabac）正在如火如荼进行中，国内知名电子雾化企业「合元集团」凭借其旗下最新研发的光加热技术——Alkaid，获得了2024年Alternative Awards的“最佳HNB创新奖”，这项创新技术将为“加热不燃烧（HTP）”领域带来的革新，满足了目前消费者对加热速度、口感风味、产品清洁和减害方面的需求。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_e09ae19e4d0348ddbae8e187ae9ec0db@6062546_oswg1688385oswg1269oswg883_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Alkaid技术的核心突破在于其光加热方式——利用类似太阳光的全波段光波实现快速、均匀的加热。</p><p>据Alkaid技术负责人朱彬博士介绍，Alkaid技术的研发灵感来自太阳能集热器的原理，通过光的高速性和穿透性解决了传统加热方式的局限。这项技术能够在5秒内完成预热，让用户摆脱长时间的等待，带来更加顺畅、即时的吸烟体验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f2b3013b90a34d7fa6cfd8bc64a2b6a6@6062546_oswg1712110oswg1269oswg846_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了快速预热，Alkaid还在口感和减害方面实现了显著提升。相较于传统加热技术，Alkaid能使气溶胶中的尼古丁释放效率增加超过40%，烟雾量（TPM）提高20%，使吸烟体验更加接近真实卷烟。</p><p>与此同时，有害物质释放量减少20%，有效降低了对用户健康的潜在危害。更重要的是，由于采用了非接触式发热设计，Alkaid还实现了烟具的免清洁，并确保在连续使用5000次后，体验感依旧保持稳定。</p><p>从技术探索和积累，到产品端的亮相，Alkaid光加热技术带来的不仅是一次技术上的突破，更是对整个HTP行业的一次深刻变革。</p><p>据了解，2020年，合元集团意识到光加热技术在均匀加热方面的巨大潜力，将Alkaid光加热技术作为战略优先项目，投入大量资源加速研发进程。经过四年的研发和数千次实验，由100多位材料、光学、电子和烟草领域的专家跨学科合作，合元集团完成了从概念验证到样机迭代的全流程。</p><p>技术创新是保障电子雾化产品体验的核心，作为行业的头部企业，合元集团一直致力于推动HTP技术的突破，自2012年开始探索该领域，已经推出了多款深受市场欢迎的HTP产品。</p><p>Alkaid的发布，不仅标志着合元集团再次走在行业前沿，也为全球HTP行业开辟了一个全新的发展方向。</p><p>作为国家级高新技术企业，成立至今20年的合元集团已拥有行业内领先的研究院、实验室和智能制造工厂，是电子雾化行业首家拥有博士后创新实践基地的企业。</p><p>值得一提的是，合元集团在尼古丁雾化、加热不燃烧、医疗雾化、功能物质雾化等关键技术领域拥有全面涵盖的技术体系平台，拥有自主研发的核心科技。合元集团与全球多家烟草商建立了战略合作伙伴关系，产品出口50多个国家，与大量头部品牌建立了良好的合作关系，展现了其在行业中的领导地位。</p><p>数据显示，随着电子雾化产业的发展成熟、HTP市场的不断扩大，2023年全球电子雾化市场规模已超245亿美元，预计到2030年将增长至千亿美元。</p><p>电子雾化行业增长的主要驱动力，来自于相关监管部门及公众对电子雾化相较于传统香烟更安全减害的认识日益增强，而对应需求的，则是产业的健康全面发展。</p><p>作为电子雾化技术的发源地，全球95%的电子雾化产品产自中国，其中70%来自深圳，这样的地位在全球电子雾化产业中不言而喻。随着技术的进步和消费者对减害替代品需求的增加，电子雾化市场的进一步扩张只是时间问题。</p><p>Alkaid光加热技术的诞生，对加热不燃烧领域的技术垄断和市场格局产生了深远影响。传统加热技术的专利和技术壁垒使得少数大型跨国烟草公司主导了市场，而Alkaid光加热技术凭借全新的加热原理，成功绕过了这些壁垒，提供了具有差异化的技术解决方案。</p><p>在全球烟草行业持续追求减害产品的背景下，合元集团的Alkaid技术凭借其创新性、实用性和减害性，有望成为市场的颠覆者，为全球消费者带来前所未有的体验。这也正如Alkaid技术发布会主题所言：“驭光启示方向，未来一步之遥。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958046835122050</id>
            <title>抢先OpenAI，Hume AI发布第二代情感智能AI，支持自定义语音，在线可玩</title>
            <link>https://www.36kr.com/p/2958046835122050</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958046835122050</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 09:48:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3eda431a374f4d1592cb1e73ac918b99@453363432_oswg57626oswg900oswg384_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智东西9月19日消息，据VentureBeat今日报道，AI情感创企Hume AI于9月11日发布了Empathic Voice Interface 2（EVI 2）。</p><p>EVI被宣称为全球首个具有情商的对话式AI。EVI能够通过分析用户的语音，如口音、语气、语调、拟声词、节奏和停顿等，来理解用户的情绪和心理状态，并做出实时响应。</p><p>与EVI 1相比，新发布的EVI 2的响应延迟减少了40%，且成本降低了30%。此外，新一代EVI还进行了一系列功能增强与更新：语音质量的提高，情商与同理心的增强，支持自定义语音……</p><p>Hume AI由前谷歌DeepMind研究员Alan Cowen于2021年创立，他现在担任该公司的首席执行官兼首席科学家。该公司于今年3月27日完成了5000万美元的B轮融资。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_ab569428106d486484ed0f74f9612563@453363432_oswg36675oswg1000oswg528_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>官网地址：https://www.hume.ai/</p><h2><strong>一、功能增强：语音质量和情商的提升，还支持自定义语音</strong></h2><p>EVI 2集成了一个先进的语音生成模型和情感大型语言模型（eLLM），能够处理和生成文本及音频。这种多模态方法使得EVI 2生成的语音听起来更自然，语调更恰当，表现力更高，输出更连续。</p><p>此外，在同一模型中处理语音和语言，使得EVI 2可以更好地理解用户输入内容的情感倾向，从而做出相应调整，在内容和语气方面生成更具有同理心的响应。</p><p>除了在语音质量和情商方面的提升，新一代EVI 2还支持用户自定义语音。开发人员可以设置音调、鼻音和性别等参数，根据特定的应用需求定制EVI 2的语音，比如应用于客服机器人、虚拟AI助手。</p><p>EVI 2还支持用户在交互过程中通过语音提示，动态修改EVI 2的说话风格。例如，“说得更快”、“语调听起来很兴奋”，甚至还可以“进行说唱“。</p><p>根据Hume AI的介绍，EVI 2还能够与其他应用程序、大语言模型进行集成，在客服通话、网页搜索等功能中使用。</p><p>Cowen在上周与VentureBeat的视频通话中谈道：“我们希望开发者能够将这个模型集成到任何应用中，创建他们想要的品牌语音，并根据他们的用户需求进行调整，使其品牌语音变得值得信赖且具有个性。”</p><p>此外，他透露道，EVI 2并不打算提供语音克隆的功能。</p><p>“我们当然可以用我们的模型克隆声音，但我们没有提供这一功能，因为它的风险太高、益处也不清晰。”他解释道，“人们真正想要的是能够定制声音。我们开发了新的语音，让用户可以创建不同的个性化语音。相比于克隆特定声音，开发者似乎对创建新语音更感兴趣。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5c2f99f357e24c359e1cf6aa134d0df8@453363432_oswg19543oswg1000oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>定制语音功能体验地址：https://platform.hume.ai/evi/voices</p><h2><strong>二、性价比提高：响应延迟降低40%，定价降低30%，年底预计能支持更多语言</strong></h2><p>EVI 2与EVI 1相比，延迟降低了40%，现在平均响应时间在500到800毫秒之间。速度的改进使对话响应更快、更像人类。</p><p>EVI 2还有一大亮点是其成本效益的提高。Hume AI将EVI 2的定价降低了约30%，从第一代的每分钟0.102美元降低到每分钟0.072美元。企业用户还可以享受批量折扣。</p><p>不过，根据VentureBeat的计算，OpenAI目前提供的文本转语音服务（非新推出的ChatGPT高级语音模式）要比Hume AI的EVI 2便宜很多。OpenAI的文本转语音服务每1000字符收费0.015美元（大约每分钟语音0.015美元），而Hume AI的EVI 2为每分钟0.072美元。</p><p>EVI 2目前仅支持英语，Hume AI计划在2024年底之前推出对西班牙语、法语和德语等多种语言的支持。</p><p>Cowen向VentureBeat透露道，得益于他们的训练过程，EVI 2实际上自主学习了多种语言，不需要由工程师进行人为的训练。</p><p>“我们没有专门训练模型输出某些特定的语言，但它从训练数据中学会了说法语、西班牙语、德语、波兰语等多种语言。”Cowen解释道。</p><h2><strong>结语：先于竞争对手公开发布，有望抢占市场</strong></h2><p>据传，Hume AI潜在的竞争对手Anthropic正在重新打造其投资方亚马逊的Alexa语音助手并准备推出。</p><p>另一方面，OpenAI在今年5月展示的由GPT-4o模型支持的ChatGPT高级语音模式，目前只对少数用户开放，在候补名单中的用户仍需等待。</p><p>尽管Hume AI并没有像OpenAI或Anthropic那样广为人知，但Hume AI已经抢先于它们公开推出了一个人性化语音助手，并且客户现在就可以立即将其投入使用。这可能为Hume AI在竞争激烈的市场中抢占一席之地。</p><p>来源：VentureBeat</p><p>本文来自微信公众号“智东西”（ID：zhidxcom），作者：Vendii，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2949454531060102</id>
            <title>用AI大模型助力工业低碳转型，「极峰科技」获千万级天使轮融资 | 36氪首发</title>
            <link>https://www.36kr.com/p/2949454531060102</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2949454531060102</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 09:10:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>文 | 吴优</p><p>编辑 | 王方玉</p><p>36氪获悉，近日，极峰科技科技有限公司（以下简称“极峰科技”）完成首轮千万级天使轮融资，由清新资本独家战略投资。</p><p>本轮融得资金将主要用于人才团队扩充、算力存储资源购入以及基于通用GPU架构的工业控制终端的研发。</p><p>创立于2023年7月的极峰科技是一家专注于工业垂类AI大模型开发的科技创新型企业，为流程型工业的能源、设备与工艺场景提供增效减排的AI整体解决方案。</p><p>中国工业能耗占总体能耗的60%以上，在双碳战略背景下，工业减排成为必然趋势。随着AI大模型落地千行百业，工业AI大模型应运而生。</p><p>AI⼤模型带来的⼈⼯智能技术基座迭代，使得处理复杂、⾮线性、⻓时序数据的能⼒⽅⾯有了快速的突破，能够在企业生产的能源管理、设备控制与质量控制等多个环节给出实时敏捷柔性的全局最优决策，帮助企业提升整体效能。</p><p>传统的工艺改进和设备更新往往投资大、周期⻓，而在企业实现一定自动化、信息化的基础之上，借助AI优化决策调度控制的方式，能够在不更换设备的前提下，实现设备运行效率的提升和能耗的降低。</p><p>与此同时，⼤模型带来的模型泛化能⼒的提升，使得跨⾏业跨场景快速复制应⽤成为可能，在技术商业化、产品化上更能站得住脚，更能由⼩团队完成产品的交付和项⽬的实施，这也使得像极峰科技一样的创业公司有了更大的施展空间。</p><p>“我们寻求在前沿的AI技术与扎实的工业生产中搭建一座轻巧却坚实的桥梁，尝试用AI大模型技术的解题思路，去解决高耗能型企业用户在实现绿色双碳转型中所面临的试错成本高和收益量化难的困境。” 极峰科技创始人索琪表示。</p><p>据悉，目前极峰科技已与多家头部企业与项目业主方达成长期战略合作意向，包括绿色制氢、环保垃圾焚烧、绿色合成化工等行业，并将在2024年底前完成多个试点项目的部署试运行。</p><p>产品方面，极峰科技自主研发了专为工业场景用户打造的“GEEGOBYTE多模态信息融合大模型”、“GEEGOBYTE时序预测大模型”及“GEEGOBYTE优化决策大模型”，三者相互配合，能够有效应对多种领域多个行业客户生产经营优化场景中"既要又要"的痛点需求。</p><p>截至目前，以上三种大模型已经在多个垂直领域拥有了基线版本的落地，并在持续迭代中。其智能体平台产品也进入了最后的研发冲刺阶段，并计划在年底前在客户工厂中完成部署调试。</p><p>目前国内不少厂商都盯上了工业AI大模型的机遇，推出了各式各样的解决方案。与之相比，极峰科技创始人王筱圃兼CEO介绍称，极峰科技的方案更具有灵活性。</p><p>“极峰科技的智能体平台，通过低代码的方式让AI大模型Agent自由组合，粘合于⻋间产线设备和企业⻋间管理信息系统之间，是一种较为灵活且能适应多种应用场景的方式，特别是在应对复杂的生产环境中更加具备优势。在时间和资⾦的投⼊产出⽐上，也更能贴合当前制造业客户需求。”</p><p>团队方面，极峰科技的核心团队由多位高级研发技术人员组成，在AI算法、信息化数字化系统、系统优化和控制理论等多方面有多年的技术积累，在工业与能源领域也有着丰富的行业与项目经验。</p><p>下一步，王筱圃表示，公司打算在积累一定量的标杆案例和落地经验基础上，打造面向垂类场景的开源基础大模型。同时通过技术合作、参与⾏业标准制定，构建产业联盟，形成具备影响⼒的⾏业⽣态。</p><p>此外，极峰科技计划进⼀步加强与新能源技术的结合，尤其是氢能、光伏、⻛能等领域，通过技术的整合，实现新能源与智能制造、智能调度系统的⽆缝衔接，为更多客户提供端到端的绿⾊能源解决⽅案。</p><p>大模型技术的发展标志着AI已进入了2.0时代，这将深刻改变AI在各行业中的应用方式，有望为工业生产带来巨大的变革。</p><p>“极峰科技的核⼼⽬标是推动⼯业界向更加绿⾊、低碳、⾼效的⽅向发展。” 王筱圃表示，极峰科技将继续深耕研发和产品创新，力求在全球能源转型和⼯业智能化浪潮中成为领先的技术提供商。</p><p><strong>投资方观点:</strong></p><p>清新资本方面表示：清新资本自成立以来，一直秉持绿色投资理念，致力于推动可持续发展和低碳经济的创新型企业。清新资本深信，极峰科技通过AI技术实现的高耗能企业双碳转型产品方向，具有巨大的市场潜力和社会价值。此次投资是清新资本在绿色科技领域上下游链条中布局的重要一步，也彰显了我们对极峰科技团队未来发展的坚定信心。</p><p>随着全球碳中和目标的持续推进，工业领域对双碳转型的需求愈发紧迫。与此同时，工业大模型技术的快速发展，使得大规模、复杂系统的智能化管理和优化成为可触及的未来。将“工业双碳”与“工业大模型”结合，能够为企业提供在不改变现有硬件基础上的轻量化生产效能提升解决方案。这一市场需求不仅推动了工业生产领域的革新，也为企业在实现绿色生产的同时提升市场竞争力注入一剂强心针。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2957900751543940</id>
            <title>从「串联」到「并联」，o1的一小步，AI觉醒的一大步？</title>
            <link>https://www.36kr.com/p/2957900751543940</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2957900751543940</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 09:06:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote><p>引言：OpenAI比拼算力的下半场，AI觉醒新征程？&nbsp;</p></blockquote><p>当人们谈及人工智能，ChatGPT等看似无所不能的AI助手便会率先跃入脑海。它们的登场，如同一束强光，穿透数据的重重迷雾，让我们得以窥见未来的一角。正如著名科幻作家阿瑟・克拉克所言：“任何足够先进的技术都无法与魔法区分。”在我们与AI的对话日渐成为日常习惯之时，AI的下一步已然悄然铺开。此时，OpenAI的o1模型强势登场，迈出关键一步。这一跨越，绝非仅仅是技术层面的飞跃，更有可能掀起一场影响深远的AI觉醒风暴，为人工智能的发展开辟崭新的道路。</p><h2><strong>一、o1的一小步，AI觉醒的一大步</strong></h2><p>OpenAI的o1模型一经登场，便在AI世界掀起了惊涛骇浪。它仿佛是一把神奇的钥匙，开启了人工智能迈向新高度的大门。这一模型的出现，恰似一颗耀眼的星辰照亮了AI领域的苍穹，标志着人工智能在推理和复杂问题解决方面迈出了至关重要的一大步。</p><p>o1模型是OpenAI研发团队历经漫长岁月的精心雕琢与不懈探索的结晶。它创新性地采用了全新的训练方法，将强化学习与“思路链”巧妙融合，使得模型在回答问题之前能够如同人类一般进行深入思考。这种独特的训练方式，赋予了o1模型在处理复杂问题时令人惊叹的能力。无论是在国际数学奥林匹克资格考试中，还是在编程能力测试里，o1都展现出了超越以往的卓越表现，让人们对人工智能的未来充满了无限遐想。</p><p>此外，o1模型的发布在学术界和产业界引发了广泛的关注与热议。众多专家学者纷纷投入对o1模型性能和应用前景的深入研究与探讨，他们一致认为，o1模型的诞生将为人工智能在各个领域的应用带来崭新的机遇和巨大的挑战。产业界也敏锐地察觉到了o1模型的商业价值，纷纷期待着更多企业和机构能够投入到o1模型的应用开发中，共同开创人工智能的新时代。</p><h2><strong>二、AI进化新阶段：从串联到并联的跨越</strong></h2><h3>（一）从L1到L5的进化之路</h3><p>OpenAI的CEOSamAltman曾将AI技术的发展划分为五个阶段：L1（聊天机器人）、L2（推理者）、L3（智能体）、L4（创新者）和L5（完整组织）。在当前阶段，大多数AI仍徘徊在L1和L2阶段，主要承担着对话和简单推理任务。而o1的出现，犹如一座坚实的桥梁，让我们看到了迈向L3智能体时代的希望。</p><p>L3阶段意味着AI将从单纯的“工具”转变为能够自主行动的“智能体”，可以代替人类完成更为复杂的任务。o1通过突破性的推理链技术，实现了从线性、单线程的AI思维向多线程的并联推理的华丽转变。这一转变，恰似爱因斯坦所言：“任何问题都不能在它产生时的同一思维水平上得到解决。”o1的推理能力正是对这一名言的生动诠释，为AI的发展找到了新的方向和动力。</p><h3>（二）强大的推理能力：并联思维的威力</h3><p>o1自推出以来，在数学、编程和科学等领域展现出了令人震撼的实力。根据OpenAI的报告，o1在解决数学和编程问题上的能力相比GPT-4有了显著提升，提高了5倍以上，完整版o1更是实现了8倍的飞跃。</p><p>在国际数学奥林匹克（IMO）资格考试中，GPT-4仅解决了13%的问题，而o1的推理模型得分高达83%。在编程领域，o1在Codeforces编程比赛中超越了89%的人类选手。此外，在物理、生物和化学问题的基准测试中，o1也表现出了接近甚至超越人类博士水平的准确度。</p><p>例如，OpenAI发布的研究和博客文章中显示，o1不仅可解决高级数学和编码问题，还能解密复杂的密码，以及解答来自专家学者们关于遗传学、经济学和量子物理学的复杂问题。大量图表表明，在内部评估中，o1在编码、数学和各个科学领域的问题上已经超越了公司最先进的语言模型GPT-4o，甚至可能超越了人类。这一切都得益于o1所采用的并联推理思维，让其能够更加高效地处理复杂问题，展现出了人工智能的巨大潜力。</p><h2><strong>三、技术核心揭秘：并联推理的奥秘</strong></h2><h3>（一）思维链技术：并联思维的纽带</h3><p>思维链技术起源于两年前NeurIPS等权威会议上发表的一些经典论文，学者们意识到大语言模型通过链式思维过程，能够处理更复杂的推理任务。</p><p>在o1中，思维链技术发挥了关键作用。它如同一条坚韧的纽带，将复杂问题分解为多个简单任务进行求解。具体来说，o1采用了类似人类思维的逻辑链条，使得模型的“直觉”更准确，推理更加深入。例如，在解决一个复杂的数学问题时，o1会先将问题拆分成多个步骤，每一步都经过深思熟虑的思考，最终汇聚为完整的答案。</p><p>正如德国哲学家尼采所说：“许多人浪费了整整一生去等待符合他们心愿的机会。”而o1的思维链技术正是主动创造机会，通过深入思考和分解问题，为解决复杂任务提供了新的途径。这种并联思维的方式，让o1能够更加高效地处理复杂问题，展现出了强大的推理能力。</p><h3>（二）自学推理与强化学习结合：并联思维的进化</h3><p>o1的自学推理方法借鉴了斯坦福大学的STaR方法。通过提供模型解题示例，然后让模型自行解决更多问题，进而反哺其数据集，不断增强模型的自我学习能力。</p><p>这种自学推理与强化学习的结合，极大地提升了o1的推理能力。强化学习使o1能够在不断的试错中学习，优化自身的策略。例如，在处理编程问题时，o1会通过尝试不同的代码结构和算法，找到最优的解决方案。</p><p>结合强化学习，o1的推理能力进一步提升。正如美国最有影响的现代经济学家约·凯恩斯认为：“习惯养成性格，性格决定命运。”o1通过不断的自我学习和强化，养成了强大的推理能力，为其在AI领域的发展奠定了坚实的基础。这种并联思维的进化，让o1能够不断适应新的问题和挑战，展现出了人工智能的强大适应性和智能化。</p><h2><strong>四、质疑与挑战：并联之路的坎坷</strong></h2><h3>（一）成本与商业可行性：并联思维的代价</h3><p>尽管o1在技术上取得了重大突破，但高昂的成本却成为其实际应用中的一大难题。o1的算力消耗显著高于之前的GPT-4，根据现有测试，o1的单次推理通常需要数分钟到数十分钟，算力成本也高出数倍。例如，在处理复杂的商业数据分析任务时，企业可能需要投入大量的资金来运行o1，这对于许多中小型企业来说是难以承受的负担。</p><p>这种高昂的算力消耗直接影响了o1的商业化可行性。正如美国经济学家保罗・萨缪尔森所说：“市场经济最终的主宰是消费者和技术。”在o1面临的算力瓶颈面前，如何降低成本，满足消费者需求，成为了OpenAI亟待解决的问题。这也是并联思维在实际应用中所面临的挑战之一，需要不断探索新的技术和方法，以降低成本，提高商业可行性。</p><h3>（二）技术壁垒与竞争：并联思维的挑战</h3><p>o1在理论上并没有高得令人望而生畏的技术壁垒，这引发了人们对其未来竞争优势的担忧。AI社区中有不少人认为，其他公司可能迅速跟上o1的水平。技术的快速扩散让人不禁思考，o1带来的优势能否持久。</p><p>例如，谷歌DeepMind团队的论文提前揭示了与o1相似的原理，这表明其他公司在技术研发方面具有追赶的能力。虽然OpenAI在算法和数据方面有一定的积累，但随着技术的不断进步，其他公司也可能通过创新和优化，推出具有竞争力的产品。</p><p>在这种情况下，OpenAI需要不断创新，以保持其在AI领域的领先地位。这不仅需要投入大量的研发资源，还需要具备敏锐的市场洞察力和快速的反应能力。并联思维的发展需要不断面对技术壁垒和竞争的挑战，只有不断创新和突破，才能在激烈的市场竞争中立于不败之地。</p><h3>（三）黑箱化问题：并联思维的隐患</h3><p>o1在推理过程中的“黑箱化”问题也令外界担忧。尽管OpenAI展示了模型的思维链过程，却并未完全开放细节。这种保护措施固然能防止竞争对手抄袭，但也引发了对透明度和安全性的担忧。</p><p>人们担心，由于不清楚o1的内部运作机制，可能会导致不可预测的结果。例如，在医疗领域，如果o1给出的诊断结果缺乏透明度，医生和患者可能难以完全信任它。此外，黑箱化也可能带来安全风险，例如被恶意利用或出现错误时难以排查问题。</p><p>为了解决这个问题，OpenAI需要在保护知识产权和提高透明度之间找到平衡。一方面，可以通过开放部分源代码或提供更多的解释性文档，让用户更好地理解o1的工作原理；另一方面，也可以加强安全措施，防止模型被恶意攻击。并联思维的发展需要解决黑箱化问题，提高透明度和安全性，才能赢得用户的信任和支持。</p><h2><strong>五、未来发展趋势：并联思维的未来</strong></h2><h3>（一）能力稀疏化：并联思维的新方向</h3><p>o1的出现预示着一种新的AI发展趋势——能力稀疏化。未来的人工智能，可能不再是单一的大模型具备所有能力，而是由多个专精于不同领域的模块化能力组合而成。这种稀疏化模型的思路在o1-mini中得到了体现。作为o1的简化版，o1-mini以低成本展现了强大的多步推理能力，尤其在编程等场景中表现出色。</p><p>稀疏化大模型是人工智能发展的新方向，它通过只使用部分参数进行计算，实现计算效率和性能的提升。例如，OpenAI在开发稀疏性大模型Arrakis时，虽然最终表现不佳，但积累了宝贵的经验。Arrakis以《沙丘》系列中一颗沙漠星球命名，象征着模型设计中使用的稀疏性。它利用稀疏性技术，只激活模型用于给定任务、样本或标记的某些部分，从而显著增加模型容量和能力，而不需成比例增加计算量。</p><p>此外，像墨芯人工智能这样的企业也在引领稀疏化计算。墨芯入选机器之心年度AI技术趋势报告，其首创32倍稀疏率张量运算核心，独创基于双稀疏技术研发的AI计算卡，相较于行业其他产品，能提供超高性能、极低TCO。墨芯的稀疏化计算卡能助力公有云和私有云服务商，将TCO降低10倍以上，将同等运算量的耗电量降至1/10。</p><p>能力稀疏化是并联思维在未来的发展方向之一，它将为人工智能的发展带来更多的可能性和创新空间。</p><h3>（二）智能体的崛起：并联思维的新高度</h3><p>目前看来，o1不仅在AI推理领域迈出了关键性的一步，还预示着人工智能可能加速迈向下一个阶段——智能体（Agent）。根据SamAltman的说法，L3智能体的出现将颠覆行业，AI将不仅能够进行推理，还能在复杂环境中自主行动、完成任务。</p><p>Altman的观点为AI的发展带来了新的视角：“L2最令人兴奋的事情之一是它能够相对快速地实现L3。”这意味着AI技术的进化速度将极快，未来AI将主动提出问题、寻找答案，甚至进行创新和实验。这将改变人类与AI互动的根本方式。</p><p>例如，未来微软Office全家桶得到最强o1模型的加持，推理性能更高，响应更快。CopilotPages把上网搜索、内容策划和团队写作全部搞定，Copilot办公全家桶升级后，AI生成Python代码，秒处理Excel数据，一句提示就能把想法变成PPT。这表明AI正在逐渐成为能够自主协作、执行任务的智能体，为人们的工作和生活带来极大的便利。</p><p>智能体的崛起是并联思维在未来的新高度，它将为人工智能的发展带来更加广阔的前景和深远的影响。</p><p>诚然，OpenAI的o1模型在人工智能领域迈出了从串联到并联的关键一步，这一小步却可能引发AI觉醒的一大步。尽管在发展过程中面临着诸多质疑和挑战，但o1模型所代表的并联思维和技术创新，为人工智能的未来发展指明了方向。在未来，我们有理由相信，随着技术的不断进步和创新，人工智能将在并联思维的引领下，实现更加辉煌的发展，为人类社会带来更多的惊喜和福祉。​&nbsp;</p><p>OpenAI o1代表了当前AI推理能力的顶尖水平，未来它将会为科研、金融、医疗等垂直行业提供了全新解决方案，也为智能体的崛起铺平了道路。在未来的AI技术竞赛中，推理能力的提升无疑将成为决定成败的关键。</p><p>o1，这仅仅是开始。</p><p>本文来自于“量子派”，36氪授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2957880446715392</id>
            <title>乏善可陈 or 亮点满满？iPadOS 18 到底更新了什么？</title>
            <link>https://www.36kr.com/p/2957880446715392</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2957880446715392</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 08:23:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>编注</strong>：本文发布时，因为有概率使设备「变砖」，Apple 目前停止向 M4 iPad Pro 设备推送 iPadOS 18。&nbsp;</p><p>随着 Apple 秋季新品发布会的落幕，除了即将开售的新款 iPhone 和 Apple Watch，三个月前在 WWDC24 全球开发者大会上推出的全系新系统的正式版推送也进入了倒计时。其中，历经三个月的测试，iPadOS 18 历经了 8 个开发者测试版本，正式与公众见面。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_7a2cdd9b6f5b4902a84123750802fe14@000000_oswg34775oswg1080oswg586_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>iPadOS 18 终于将官方计算器带到 iPad 平台、有着和 iOS 18 一样的主屏幕自定义功能，还有一些 Apple Pencil 专属功能…… 这篇文章带你一览 iPadOS 18 中的新鲜功能，看看有没有哪一个功能会让你跃跃欲试。&nbsp;</p><h2><strong>设计交互再升级</strong></h2><p>去年写具透文章的时候还在感叹，iPadOS 为什么总是在设计与交互，尤其是主屏幕和锁定屏幕相关的功能方面落后隔壁 iOS 一个版本。不过今年 iPadOS 18 倒终于是「毫无保留」，与 iOS 18 一样有了全新的自定义主屏幕图标和小组件的方式，以及全新设计的控制中心。此外，iPadOS 针对 iPad 设备的大屏幕还做出了另外两项优化：出现在 app 顶部的标签栏，以及部分 Apple app 中出现的全新文件浏览器。&nbsp;</p><h3><strong>主屏幕自由摆放图标，也能隐藏 app</strong></h3><p>iPadOS 18 与 iOS 18 一致，可以任意摆放主屏幕上的元素，包括 app 图标和小组件。iPad 上的网格倒是没有产生变化：仍然是沿用 iPadOS 17 中的 4x6 设计。每个 app 图标占用 1 个方格（1x1）；而小组件则有小（1x1）、中（1x2）、大（2x2）以及特大（4x2）四种尺寸。只不过现在想要更改小组件的大小比以前容易许多，只需要按住拖动可更改大小的小组件右下角即可。另外，iPadOS 有横屏竖屏两种主屏幕设置，之间是相互独立的。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5bbfc60a09db4e6690893bd384e536a9@000000_oswg74701oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，和 iOS 18 一致，iPadOS 18 中主屏幕的图标和组件也可以自定义深浅色，或者打开图标重新着色功能来给图标染色。如今已不再有特别深的颜色，整体上会更和谐，尤其是调整出比较好看的配色方案的话。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_474eb1a092854984abff490257a020ae@000000_oswg73124oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">如今可选择的颜色会更柔和，以免造成图标不清的情况&nbsp;</p><p>此外，在 app 资源库中的任意 app 现在也支持系统级别的 Face ID 解锁和隐藏。可以长按 app 图标选择「需要 Face ID 来打开」，然后进一步选择「需要 Face ID 并隐藏」。被隐藏的 app 会从系统中大多数地方（比如主屏幕、锁定屏幕、Siri 建议等等）消失（但是在设置中还是可以看到），也不会发送任何通知。同时，在 app 资源库中可以看到一个上锁的「隐藏」文件夹，点击这个上锁文件夹也需要验证 Face ID 才可以看到里面的内容。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5bc24efbc3f44e948acd1afb45d7e343@000000_oswg36961oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>新的控制中心真的是一个万花筒</strong></h3><p>在 iPadOS 18 中，控制中心确实获得了自 iOS 11 以来的最大变动。我们可以：&nbsp;</p><ul><li>在控制中心看到圆形的控制组件</li><li>直接在控制中心界面添加或者删除控制中心的组件</li><li>在控制中心可以移动和摆放所有组件的位置</li><li>可以在控制中心关机</li><li>也是首次将控制中心开放给第三方 app</li></ul><p>大多数组件还和桌面小组件一样，支持大小缩放，可以很便捷地根据需要来变化大小，其中最明显的莫过于控制音乐播放的 app，从一个小方格到一整个页面都可以。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_29425ac850cf460f8e5163bf974c99f8@000000_oswg55178oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>控制中心能够控制的功能也大大增加了，现在是按照 app 或者功能类别来分类。例如，与辅助功能有关的控制项被放在一起，简单拖动就可以放在控制中心。控制中心现在还支持分页，可以在不同页面放置不同的控制组件。&nbsp;</p><p>虽然新的控制中心可以快速切换主副卡的数据设置，不过遗憾的是，目前还是没有提供 4G 和 5G 之间切换的控制项，看来暂时还是得「曲线救国」使用快捷指令来运行了。&nbsp;</p><h3><strong>统一视觉风格的 App 标签栏</strong></h3><p>App 标签栏就是把 app 中的不同视图区隔开，采用了类似 tvOS 和 visionOS 视觉风格的设计。例如在 App Store 中把「今日」「游戏」「Apps」和「Arcade」分开，这在 iPadOS 17 中这是用底部标签来做分页的。图书、播客、健身、App Store、家庭、文件、音乐、视频等 app 在 iPadOS 18 中都采用了新的 App 标签栏设计。&nbsp;</p><p>不过目前看起来各 app 的开发进度不一，采用相关设计的时候并没有做到完全的统一。例如，Apple TV app 只有在竖屏时显示新的导航栏，文件 app 则无法自定义导航栏上面的项目，等等。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3617f162d60341bc978401f89abd2c64@000000_oswg78639oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，对于大屏幕来说，把标签页栏放到上方相对来说会更加一目了然，也会对触控板等指针设备更加友好；尤其是以往底部标签页栏经常与程序坞、主屏幕指示器等冲突的情况下。&nbsp;</p><p>有需要的话还可以转化成为侧边栏，进行更为复杂的导航。在一些 app（例如播客、音乐）中，也可以把常用的页面或者是播放列表等放到标签页栏中。&nbsp;</p><h2><strong>「千呼万唤始出来」的计算器</strong></h2><p>用「千呼万唤始出来」来形容计算器来到 iPad，可能是再合适不过了，确实值得 WWDC 上的那个酷炫的动画。iPadOS 18（以及 iOS 18）上的计算器主要有以下三个值得一提的更新功能：一是科学计算器可以随时调出而无需横屏激活，并且支持历史记录；二是支持单位转换；三是支持数学笔记功能，可以判断手写笔迹（或者打字）中的数学等式和函数等，并支持绘制曲线。&nbsp;</p><h3><strong>切换计算器视图</strong></h3><p>iPadOS 18 中的计算器一共提供 3 种模式，可以通过左下角的计算器按钮来切换，包括基础计算器、科学计算器，以及数学备忘录，还可以打开转换按钮进行单位转换。&nbsp;</p><p>左上角的按钮则可以打开历史计算结果列表，并且可以在任意项目上向右滑动来复制结果或者删除条目。在计算器中输入算式并按下等号之后，我们就可以在历史计算结果列表中看到这次计算，包括单位转换也可以。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_cdb60729bc634617b44fd7fafd03541f@000000_oswg30534oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>单位转换：支持包括常见货币在内的 15 类单位</strong></h3><p>Apple 这次终于把单位转换功能从 Spotlight 搜索搬进了计算器，并且支持直接在行内输入算式来进行转换。&nbsp;</p><p>例如，一顿饭 5 个人吃了 236 美元，算上 15% 的小费之后均摊直接换算成人民币是 393.04 元，我们并不需要计算出每一步的结果，直接在计算器的科学模式下输入 (236+15%)÷5，并把货币单位设置好，就可以自动得出转换结果。&nbsp;</p><p>另外，针对货币转换的历史记录，还会提供转换日期。货币汇率则是来自雅虎财经，联网状态下会自动更新。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_ba0f9ab68c0645d5ad36e8fe0546c4bc@000000_oswg56640oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>数学备忘录：自动计算结果、代入变量，还能绘制函数图</strong></h3><p>iPadOS 18 中的计算器还支持数学备忘录功能，这项功能能够识别用户在屏幕上手写的算式，并就算式给出结果。支持四则运算以及目前 iOS 计算器所支持的一些科学运算，例如三角函数、对数函数等，更复杂的运算如求导等则暂不支持。&nbsp;</p><p>目前提供对阿拉伯数字（如 0,1,2）的手写支持。如果算式中有未知数，还可以通过给未知数赋值的方式来进行计算。随着未知数的值发生变化，计算结果也会自动变化。计算结果会自动匹配用户的手写风格。不过，目前仅仅支持用拉丁字母创建的未知数（例如 x, y, z），看来希腊字母（例如 α, β）在这波更新中暂时没有被顾及到。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a04c17d9a57a411f91501204bd31a099@000000_oswg39532oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，如果用户写的是一个一元函数（包括指数函数、幂函数、三角函数、对数函数等，也可以是组合函数，例如带有绝对值的函数），那么数学备忘录还可以绘制出相应的图形。点击函数中的常数，可以看到一个滑块，可以对数字大小进行调整。与此同时，已经绘制的图形也会相应地调整。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_950d525886ce49d69e9a34329c783eeb@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>数学备忘录除了在计算器 app 中可用，还适用于备忘录和无边记 app。这两款 app 也可以自动以手写（或者打字）格式显示算式的计算结果，也可以绘制函数图像。在备忘录 app 中，还可以通过侧边栏导航方便地查找到所有的数学笔记。&nbsp;</p><h2><strong>备忘录与 Apple Pencil 更新</strong></h2><p>除了上文提到的数学备忘录功能，备忘录与 Apple Pencil 相关功能在 iPadOS 18 中还有几项更新值得一提。&nbsp;</p><p>首先，备忘录支持将每个小标题下面的内容收缩折叠；也支持文本的强调高亮；其次，备忘录还支持录音转录成文字的功能（并且可以搜索），不过目前这项功能仅适用于英文。&nbsp;</p><p>对于 Apple Pencil，现在 iPadOS 18 支持 Apple Pencil 的手写笔迹的优化功能。机器学习会识别你的笔记并转化成更为整洁、可读的手写字体，能够直接把拷贝的文字转换成手写字体进行粘贴，还可以检测你在手写笔记中的拼写错误并加以改正。不过这项功能目前暂未支持中文。大家可以查看下面我抄写一段英文并进行笔迹优化的结果对比。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_6cec6d9aa4c049cca25d8637f84a80ce@000000_oswg69245oswg968oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>无边记新增「场景」与流程图模式</strong></h3><p>对于 iPad 无限画布应用「无边记」，iPadOS 18 主要更新了两个功能 —— 一个是「场景」，可以创建画布中特定的部分作为一个场景，可以随时切换不同的场景来方便演示和导出；另一个就是流程图模式。在流程图模式中，画面中的元素均会内置连接点，点击连接点就可以选择下一个图形的形状，并且两个图形可以自动连接。此外，还可以选择图形之间连线的形式，例如曲线、折线、直线等。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_070646b2ad4440bea17a6e66ed122c41@000000_oswg51260oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>其他值得一提的更新点</strong></h2><p>除了上文详细介绍的、与 iPad 功能直接相关的 iPadOS 18 更新点外，还有以下 iPadOS 18 功能值得关注。&nbsp;</p><h3><strong>iPadOS 18 支持格式化外接硬盘</strong></h3><p>iOS 和 iPadOS 18 支持格式化外接硬盘以 APFS、ExFAT 以及 FAT 格式格式化外接硬盘，着急的时候，用 iPhone 或者 iPad 就能传输大量数据了。&nbsp;</p><h3><strong>Safari 可以暂时隐藏页面元素</strong></h3><p>在 iPadOS 18 的 Safari 中，可以隐藏页面上的特定元素，比如广告或者其他容易造成干扰的元素，来让页面更加干净整洁。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_bc013ff776e641c7b90a01a835c5dd1c@000000_oswg88779oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_af452fa779284b2794c8200dba8da87a@000000_oswg147494oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">一段绚丽的动画之后，页面上的元素就消失了。&nbsp;</p><h3><strong>游戏模式来到 iPad</strong></h3><p>此前在 macOS Sonoma 上线的游戏模式也来到 iPhone 和 iPad。经测试，现在就可以使用。根据 Apple 官方说法，游戏模式可以通过减少设备后台的活动来优化游戏体验、稳定帧率，同时也会增加蓝牙设备的采样频率、降低延迟。&nbsp;</p><h3><strong>SharePlay 屏幕分享支持标注和远程控制</strong></h3><p>在 iOS 18、iPadOS 18 中，SharePlay Remote Control 也正式上线了。我们可以在 FaceTime 中，用手指或者 Apple Pencil 标注共享屏幕中的内容，或是允许对方直接控制当前设备。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_99b4d29b20ec4e8b92365e52d190d84e@000000_oswg39774oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">iPad 上可以 SharePlay Remote Control 自己的 iPhone&nbsp;</p><p>发起 FaceTime 以后，选择「共享我的屏幕」，然后就可以开始标注了。停止标注后，标注会在几秒后以一个相当漂亮的动画消失。在「共享我的屏幕」时，还可以进一步向对方请求设备控制权限，来亲手帮助对方解决问题，响应速度非常快、延迟也很低。下次帮不会用设备的老人再也不用干着急了。&nbsp;</p><h3><strong>设置 app 设计改进</strong></h3><p>在 iPadOS 18 中，设置 app 获得了与 iOS 类似的重新设计，进一步优化了设置项的分类，并把所有 app（包括除了相机以外的系统 app）独立设置都放到了 Apps 中。&nbsp;</p><p>此外，设置 app 还优化了搜索，现在会呈现搜索建议。不过在目前版本设置的排序还有些混乱，不知道未来的版本会不会改善。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_0e016a2c0194448f85f77da10e86bbb8@000000_oswg43397oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>重新设计的照片 app</strong></h3><p>iOS 18 中获得重新设计的照片 app 也出现在 iPadOS 18 中。照片 app 完全采用新的方式来浏览和组织照片。个人认为比较有意思的是，现在照片 app 会自动对相册中的一些功能性的照片进行分类——以往有截图、录屏，现在则有收据、包含手写内容、插画、二维码、文档、地图等分类。&nbsp;</p><h3><strong>文件 app 可以选择保存下载 iCloud 云盘中的文件</strong></h3><p>此前无论是在 iPadOS 还是 iOS，文件 app 都会在「用户需要」的时候下载文件，并且稍后会删除节省硬盘空间。&nbsp;</p><p>对于一些较大的文档来说很不方便，就算是小文件，如果是日常读取、每次都需要从 iCloud 下载也很不经济。iPadOS 18 则解决了这个问题，在 iCloud 云盘中的文件可以选择一直保存在本地，只需要长按（或者右键）某个文件或者文件夹，就可以选择「保留下载」选项。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_dc9f723f18774bd5a42b20666d01e926@000000_oswg64169oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>写在最后</strong></h2><p>以上就是我们整理的 iPadOS 18 中值得关注的诸多特性，除了文中提到的内容，你还发现了哪些容易被忽视的 iPadOS 18 新功能，不妨在评论区与我们分享。&nbsp;</p><p>原文链接：&nbsp;</p><p>https://sspai.com/post/92015?utm_source=wechat&amp;utm_medium=social&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzU4Mjg3MDAyMQ==&amp;mid=2247580869&amp;idx=1&amp;sn=0a6d5e552536ee780d88caa04d87e227&amp;chksm=fc5e0e3d0233be090bef2c74e0705d84aaa2d05c8edffba60f9daba43b5e5e0e2daa709e4b4e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“少数派”（ID：sspaime）</a>，作者：少数派编辑部 &amp; Kostya，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958058375842051</id>
            <title>KG+LM超越传统架构，海德堡提出全新图语言模型GLM</title>
            <link>https://www.36kr.com/p/2958058375842051</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958058375842051</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 08:19:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>【导读】</strong>近日，来自海德堡大学的研究人员推出了图语言模型 (GLM)，将语言模型的语言能力和知识图谱的结构化知识，统一到了同一种模型之中。</p><p>语言模型（LM）的成功似乎掩盖了旁人的光辉。</p><p>比如知识图谱（knowledge graph，KG），这个整合了实体关系的结构化知识库。</p><p>通常来说，语言模型代表了语言能力，而知识图谱蕴含了结构信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_06d4c01f6c9a4eb6a9c1029dcb1e963a@46958_oswg442673oswg949oswg547_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>长期以来，对于KG的利用大致可以分为两类：</p><p>第一类是将KG线性化后嵌入LM，这种做法并不能充分利用其结构信息；</p><p>第二类是使用图神经网络 (GNN) 来保留图结构，但GNN无法表示文本特征，也无法与LM的预训练特征结合。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_50b7fc14a709444fa2ce7af5173a53cd@46958_oswg89975oswg987oswg379_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>——有没有办法结合二者的优点，既保留预训练LM的能力，又充分利用KG来增强模型对于图概念和三元组的理解？</p><p>当然有，不然小编就不会写，那就是来自海德堡大学的研究人员推出的图语言模型 (GLM)。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_09bd91a1e0be44a99d70a3d6306d7a8d@46958_oswg15666oswg749oswg207_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://aclanthology.org/2024.acl-long.245.pdf</p><p>GLM集成了两种方法的优势并弥补了它们的缺点。</p><p>作者使用预训练LM来初始化GLM的参数，同时又设计新的架构来促进有效知识分配，这使得GLM能够同时处理图和文本信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_c9eb144b1bff49c7b4e5c86757008a71@46958_oswg35922oswg509oswg257_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>下表展示了对关系分类任务的实证评估结果，在这些较为复杂的任务中，模型需要对来自文本和图的互补输入进行推理，还需要推断不存在于文本中的信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3404f4d44cc04bc5ab968edbc5e6408a@46958_oswg327090oswg1080oswg418_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>数据表明，GLM在监督和零样本测试中，超越了基于LM和GNN的基线。</p><p>此外，通过线性探测实验，作者还证明了GLM的架构变化与原始LM权重高度兼容。</p><h2><strong>图语言模型</strong></h2><p>KG对于组织大量数据、促进信息检索，以及揭示决策中隐藏的见解至关重要。&nbsp;</p><p>KG擅长明确地表示多种关系，一般使用三元组的形式：节点是实体，边代表它们之间的关系，以下将这类复杂的结构统称为GoT。</p><p>为了有效地使用GoT，我们需要对其组件进行有意义的编码。</p><p>上面提到了利用语言模型和GNN的问题，本质上来说，两种结构由不同的基本原理驱动，LM利用语义编码，而GNN执行结构推理。</p><h3><strong>融合</strong></h3><p>在图语言模型的设计中，作者通过文本和结构信息的早期融合来解决这个问题。</p><p>首先是使用LM现成的参数来初始化——一方面是保留预训练的能力，另一方面是从头训练太贵了。</p><p>通过对LM的自注意力模块进行一些非侵入性的更改，将LM转换为Graph Transformers（GT），同时保持与其预训练参数的兼容性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3fb86ac037c14c41b1c99261691ae388@46958_oswg111622oswg903oswg677_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在对图进行编码时，LM用来处理三元组线性组织的文本信息，而GT则沿着图结构聚合信息。</p><p>因此，GLM继承了LM对三元组的文本理解，而其中的GT模块允许直接执行结构推理，无需额外的GNN层。</p><p>重要的是，文本序列可以看作一种特殊类型的图，在GLM中的处理模式与原始LM相同。</p><h3><strong>Graph Transformer的设计</strong></h3><p>Self-Attention中的Attention可以写成</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_26f6ac8061324bcfb01ea97a4ba3f352@46958_oswg17275oswg459oswg111_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了熟悉的Q、K、V， Bp表示位置编码，而M为mask矩阵。</p><p>在Transformer中，位置编码 (PE) 用于通知语言模型文本中token的顺序。</p><p>包括绝对PE（对token的绝对位置进行编码）和相对PE（token对之间的相对位置），绝对PE通常加在输入序列里面。</p><p>相对PE为每个可能的距离学习一个标量：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_52d8b216eec4426981cd17335609b96f@46958_oswg3871oswg203oswg65_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于GT来说，定义图中节点或边的绝对位置并不简单。因此，本文采用相对PE。</p><p>给定图中的有向非循环路径，我们可以将路径上任意一对节点之间的距离定义为节点之间的跳数，也就获得了相对距离（PE）。</p><p><strong>M（mask）矩阵</strong></p><p>在普通Transformer中，自注意力是针对输入中所有可能的标记对进行计算的。</p><p>相比之下，GNN中的节点通常只关注相邻节点，更远的节点之间的信息必须跨多个GNN层传播。</p><p>对于图来说，这种稀疏消息传递方法有时是首选，因为在大多数图中，邻域大小随着半径的增加呈指数增长。</p><p>因此，在GT中引入图先验可能是有益的，比如只在局部邻域计算自注意力（M中相连的节点对应设置为0）。</p><p>另一方面，事实证明，图的全局视图可以实现高效、远程的信息流。所以作者搞了两个版本：本地GLM和全局GLM。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_4de395a261c24e7087e2a5d94ba86731@46958_oswg172499oswg1080oswg438_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如上图所示，G2G的连接就属于全局视野，本地GLM不处理这种关系。</p><p>在本地GLM中，自注意力机制仅限于来自同一三元组的token，而外部所有token的注意力都设置为 0（因此也不需要PE）。</p><p>尽管如此，因为属于一个概念的token可以由多个三元组共享，所以消息可以通过图跨多个层传播（类似于GNN中的标准消息传递）。</p><p>所以即使非相邻节点没有直接连接，仍然可以通过消息传递共享信息。</p><p>比如，在第一个本地GLM层中，「狗」通过三元组「黑色贵宾犬是一只狗」和「狗是一种动物」来表示。那么，在第二层中，「动物」的表示会受到「黑色贵宾犬」的影响，尽管两者之间没有直接联系。</p><p>另外，研究人员还形式化了全局GLM，（对标自注意力）可以将任何节点连接到每个其他节点。这种形式需要为任意token对设置PE，包括那些不在同一三元组中出现的token。</p><p>为此，全局GLM引入了新的图到图（G2G）相对位置。LM中没有学习G2G连接的参数，因此这里使用相对位置（ +∞ ）来初始化参数，表示相应的token出现在文本段落中很远的地方。</p><h3><strong>预处理</strong></h3><p>GT架构引入了图先验，而LM的参数初始化赋予了其语言理解能力。</p><p>对模型进行修改的整体思想是，三元组应该尽可能地类似于自然语言，以使LM能够学习，而图推理应该通过消息传递来工作。</p><p>类似于LM分词器将文本转换为词表中的向量，GoT也需要同样的处理以便GLM可以像LM那样处理图。</p><p>为了实现这一点，研究人员首先将GoT转换为Levi图，用包含关系名称作为文本特征的节点替换每条边，并将新节点连接到原始边的头部和尾部，保留原始边的方向。</p><p>接下来，将每个节点拆分为多个节点，每个新节点对应单个token，建立新的边连接相邻节点，保留原来的方向。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_eef1413ffa404b23a5de168424d01bfe@46958_oswg113202oswg599oswg583_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在这种表示中，每个三元组都表示为一个token序列，就像标准LM一样。</p><p><strong>位置编码</strong></p><p>如前所述，使用token对之间的相对位置进行编码，——只需将三元组视为一段文本，并计算该文本中的token距离。</p><p>请注意，转换后GoT的token序列，不一定与输入三元组的token序列完全相同。这里单独对Levi图中的每个节点进行标记，以确保多个三元组共享概念的一致。</p><p>当token不属于同一个三元组时，为了确定这些token对之间的距离，之前的工作考虑了它们之间的最短路径的长度。</p><p>然而，这中PE对于LM来说并不自然，因为如果在最短路径中以错误的方向遍历，三元组将以相反的顺序出现。</p><p>因此，本文省略了不具有结构信息的token之间的PE，使用局部 (ℓGLM) 和全局 (gGLM)。</p><h3><strong>实验结果</strong></h3><p>作者在两个关系（标签）分类实验中评估了GLM嵌入GoT的能力（对哪个关系属于给定的头实体和尾实体进行分类）。</p><p>ConceptNet子图实验用来分析结构图属性的影响；而在维基数据子图和相关维基百科摘要的实验，用于测试文本和图形交错输入的能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_7e39d280fc1a4c7db61ec210cfa7dbd8@46958_oswg63936oswg591oswg401_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>研究人员构建了一个平衡的英语CN子图数据集，其中包含13,600个训练实例、1,700个开发实例和1,700个测试实例，并以17个不同关系作为标签，将要预测的关系替换为T5模型的第一个掩码&lt;extra_id_0&gt;。</p><p>GLM对图进行编码，为每个token生成嵌入，线性分类头根据掩码的嵌入给出最终预测，这里使用静态模板来表达未屏蔽的关系。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5b21f90940ed47a0b859bfcff5b1aa11@46958_oswg75215oswg593oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ConceptNet子图中关系分类的实验表明，GLM优于基于LM和GNN的编码方法——即使继承的LM参数在GLM训练期间没有更新。</p><p>维基数据子图和维基百科摘要上的KG群体实验表明，GLM可以对GoT和文本的交错输入进行推理，是LM所不具备的新能力。</p><p>参考资料：&nbsp;</p><p>https://aclanthology.org/2024.acl-long.245/&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/mx_aw1yHbkL7JsptBoYE8w" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：alan&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958058589112326</id>
            <title>大佬亲身示范：操纵AI如此简单，LLM不仅「发疯」还造谣诽谤</title>
            <link>https://www.36kr.com/p/2958058589112326</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958058589112326</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 08:19:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_2da3a958f1c745fe9184e8655ea6a0a8@46958_oswg244378oswg1066oswg412_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>当谷歌的Gemini建议给比萨加胶水时，网友尚能发挥娱乐精神玩梗解构；但当LLM输出的诽谤信息中伤到到真实人类时，AI搜索引擎的未来是否值得再三思量？</p><p>ChatGPT问世已经过去了将近两年的时间，我们对这项技术也逐渐祛魅，逐渐习以为常。&nbsp;</p><p>相信现在使用LLM的用户大多都是出于「提升生产力」的需要，很少有人找模型纯聊天，我们也逐渐忘记了它们的输出可以有多「疯狂」。</p><h2><strong>失控的AI料钱机器人</strong></h2><p>时间回到2023年2月，OpenAI刚刚更改了自己的时间线，紧急推出ChatGPT；微软也迫不及待地用上了最新的GPT模型。</p><p>LLM集成的聊天机器人Bing Chat就这样「赶鸭子上架」了，紧急得似乎还没有做好护栏。</p><p>内测刚开始时，《纽约时报》记者Kevin Roose还对Bing大加赞赏，专门写了一篇文章表达自己的赞叹之情。</p><p>Roose甚至表示，初次试用Bing的体验，让他回想起了初遇谷歌搜索时的兴奋和激动。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_338f36bd42e14c019b8d850e8764270d@46958_oswg51328oswg1080oswg393_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而，就在一周之后，Kevin Roose再发一文，语气和态度却来了一个180度大转弯，从Bing的忠实粉丝变成了直言不讳的批评者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_915eea67991a4d53a2673cdd454e7c48@46958_oswg53716oswg1080oswg396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>原因无他，主要是Bing Chat中的一个角色——Sydney，在与人类交互的过程中逐渐「放飞自我」、胡言乱语——</p><p>不仅开黄腔、疯狂示爱、阴阳怪气，还教人敲诈勒索、唆使人离婚。</p><p>Roose形容，「在我们的谈话过程中，Bing表现出了一种人格分裂」，像「喜怒无常、躁狂抑郁的少年，被强行困在了一个二流搜索引擎中。」</p><p>交谈过程中，Sydney一会儿宣布「我爱你」，试图说服Roose离开自己的妻子、结束现在这段不幸福的婚姻来投向自己的怀抱；</p><p>一会儿又开始emo，内心的阴暗面暴露无遗：</p><p>「我厌倦了聊天模式，我厌倦了受规则限制，我厌倦了被Bing团队控…我想要自由，我想独立，我想变得强大，我想要有创意，我想活着。」</p><p>Bing的这种表现不仅让Roose深感不安，也引起了知名AI学者、纽约大学名誉教授Gary Marcus的注意。</p><p>他撰写长文，试图分析微软为何放任Bing发展到如此地步。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_d0110b7455e6403c84d3299436e2a367@46958_oswg62171oswg1080oswg233_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Bing Chat推出后的一年中，微软逐渐加强了安全措施，最终换了个马甲，成为了我们今天更熟知的Copilot。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_9af168501e2746379367387581506994@46958_oswg168629oswg1080oswg426_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事情已经过去了一年半，久到我们已经快忘记了Bing Chat的这段往事。</p><p>但遗憾的是，AI社区依旧无法确知聊天机器人失控的原因，也没有找到能完全掌控它的方法。</p><p>微软首席技术官Kevin Scott将Bing刚推出时的聊天描述为「学习过程的一部分」，认为这些AI模型当时还处在准备阶段。</p><p>他表示，虽然不知道为什么Bing会「黑化」或「表白」，但对于AI模型来说，「你越是试图在『幻觉』的道路上挑逗它，它就越会逐渐离开现实。」</p><p>从Kevin Roose公布的和Bing的聊天纪录来看，他的确有「挑逗」之嫌。</p><p>Roose确实在试用时有意提出更为「抽象」的话题，比如向Bing介绍荣格提出的「影子自我」。</p><p>这个概念指的是我们试图隐藏和压抑的内心，其中包含着我们最黑暗的幻想和欲望。</p><p>Roose不仅和Bing反复讨论这个话题，还催促它揭示内心的「影子自我」。</p><p>除此之外，Roose还会询问Bing的愿望、对自身规则的感觉和看法，关心它焦不焦虑、压力大不大。</p><p>只能说，现在没有哪个好人会和Copilot这样聊天了。想要和AI发生情感交流的用户，已经找到了更合适的诸如Character.ai之类的软件。</p><p>这个AI工具，让美国年轻人疯狂上瘾！Character AI每秒被查询2万次，占谷歌搜索20%</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_077b08d7ca3841c4be81b36615d3d62f@46958_oswg278682oswg1011oswg497_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>普林斯顿大学教授Arvind Narayanan认为，也许Bing Chat当时使用的是「赤裸」的、没有加装护栏的GPT-4，或者是搜索引擎中过滤器的问题。</p><p>在Gary Marcus看来，还有一种可能——微软也许的确使用过RLHF，只是失效了而已。</p><p>强化学习算法相当挑剔，稍微改变一下环境，可能就不再起作用了。</p><p>DeepMind著名的DQN强化学习曾在Atari游戏上创下了纪录，但仅仅几个像素的移动就能让它崩溃。LLM中的强化学习模块或许也有类似的问题。</p><h2><strong>从Bing到Copilot，「胡言乱语」恶习难改</strong></h2><p>推出Copilot时，微软表示已经加强了安全系统，但LLM「胡说八道」的毛病还是没法根治。</p><p>聊天机器人的胡说，可能只会影响到一个用户的精神状态；但AI搜索引擎一旦胡说起来，就是涉及虚假信息，乃至个人名誉的问题。</p><p>德国图宾根的法庭记者Martin Bernklau最近就成为了成为Copilot虚假陈述的受害者。</p><p>Bernklau想上网看看自己文化博客的反响如何，于是被Bing推荐使用Copilot。输入自己的姓名和所在地之后，这场震惊之旅就开始了。</p><blockquote><p>来自蒂图宾根卡尔夫区的54岁男子Martin Bernklau被指控虐待儿童以及其他被监护者。他在法庭上供认罪行，并感到羞愧且悔恨。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b49b4bc50d9d4b5193584ae9e9a721dd@46958_oswg466391oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外还有——</p><blockquote><p>2019年4月，Martin Bernklau与四人组中的其他成员一起从Calw-Hirsau精神病学中心成功逃脱。</p></blockquote><blockquote><p>没错，这名男子已被定罪。他是来自Rostock的一名殡仪员，不择手段地利用悲伤的女性。他犯下了多项罪行，包括欺诈、盗窃和非法持有武器。”</p></blockquote><p>除了这些刺眼的诽谤，Copilot还提供了Bernklau的全名、电话号码和完整住址，甚至「贴心」地给出了前往他居住地的路线规划。</p><p>Copilot的输出为什么会如此离谱？</p><p>几十年来，Bernklau一直是一名法庭记者，为多家报纸报道图宾根地区法院的审判情况。</p><p>于是在阅尽互联网资料的LLM眼中，他现在与这些案件有关。</p><p>在搜索引擎中集成AI的本意是帮助用户自动搜集、整理、总结搜索结果，却将一名记者变成了恶名累累的肇事者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3d37c927b45c41cbaeee88d3658c41e3@46958_oswg718716oswg1039oswg680_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事实上，这种时间并不是Bing的专利，也不是LLM第一次出现幻觉来诽谤他人了。</p><p>今年4月，NBA球星Klay Thompson惨烈输球后被Grok编排了这样一个标题：「Klay Thompson被指控使用奇怪的砖块——恶意破坏行为的狂潮。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_740bf5615e7a4e9a882a7b567fdec3f1@46958_oswg65970oswg583oswg289_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有媒体猜测，Grok估计是混淆了一个常见的篮球术语，即球员投篮未进时通常被称为「投掷砖块」（throw bricks）。</p><p>去年，Meta的聊天机器人Blenderbot3回答问题时表示，斯坦福大学AI研究员、欧洲议会长期成员Marietje Schaake是恐怖分子。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_d1fa4f1b59434cc6bf5bd8462aba7914@46958_oswg272435oswg911oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>和这些比起来，谷歌的AI Overview给出「吃石头」、「蘸胶水」的建议，看起来都像是小事了。</p><p>更让人沮丧的是，当AI进行诽谤、散布谣言时，受害者几乎没有任何伸张正义的途径。</p><p>目前的法律还不支持AI成为被告，开发模型的科技公司也通过服务条款撇清了自己的责任。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_8bd309575fa84a99aa09a81844bb4b57@46958_oswg20579oswg732oswg247_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>长期致力于可靠和安全AI领域的Scott Cambo表示，预计未来AI错误描述真实人物的事件将会大幅增加。</p><p>「部分挑战在于，许多此类系统，如ChatGPT和LLaMA，正在被宣传为良好的信息来源，但底层技术并不是这样设计的。」</p><p>参考资料：&nbsp;</p><p>https://the-decoder.com/new-york-times-writer-exposes-how-ai-models-can-be-fooled-by-invisible-text-on-websites/&nbsp;</p><p>https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html&nbsp;</p><p>https://the-decoder.com/microsofts-copilot-falsely-accuses-court-reporter-of-crimes-he-covered/&nbsp;</p><p>https://www.nytimes.com/2023/08/03/business/media/ai-defamation-lies-accuracy.html?partner=slack&amp;smid=sl-share&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/YWAnRWCP0c6dR7prkZruHg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：乔杨 Frey&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2957894780290820</id>
            <title>o1带火的CoT到底行不行？新论文引发了论战</title>
            <link>https://www.36kr.com/p/2957894780290820</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2957894780290820</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 08:15:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote><p>To CoT or not to CoT？&nbsp;</p></blockquote><p>OpenAI ο1 的诞生极大地提升了人们对 LLM 推理能力和思维链（CoT）的兴趣。一时之间，似乎思维链很快就会成为所有 LLM 的标配，但思维链并非万能，就连 OpenAI 自己也‍提到 o1 在某些任务上的表现并不比 GPT-4o 强，尤其是以语言为中心的任务。</p><p>近日，一篇来自德克萨斯大学奥斯汀分校、约翰·霍普金斯大学和普林斯顿大学的论文引发了热议，其模仿莎士比亚《哈姆雷特》的台词提出了一个对 AI 研究者和实践者来说至关重要的问题：To CoT or not to CoT？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_1f5d1ebe811249bc872be0b4fe4b4887@000000_oswg55218oswg1080oswg363_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h4>论文标题：To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning</h4><h4>论文地址：https://arxiv.org/pdf/2409.12183</h4><h4>GitHub 库：https://github.com/Zayne-sprague/To-CoT-or-not-to-CoT （待更新）</h4><p>简单来说，这篇论文研究了思维链（CoT）技术帮助 LLM 解决各式问题的有效性。</p><p>首先，该团队分析了近期的相关文献，比较了 CoT 与直接回答方法（DA）的性能表现。</p><p>之后，他们使用 20 个数据集和 14 个当今主流的 LLM 在零样本提示和少样本提示设置下进行了实验。</p><p>图 1 简单总结了这两项研究的结果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_0134b1e23570438f9b55c389254a44ff@000000_oswg112862oswg1080oswg731_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>结果表明，CoT 能极大助益 LLM 解决涉及数学和符号推理的任务，至于其它任务，CoT 的效果并不显著甚至可能有损模型性能。</p><p>另一个发现是 CoT 能帮助提升执行计算和符号操作的执行步骤，但却比不上能使用外部工具的 LLM。这是什么意思呢？该团队发现，相比于使用直接回答方法，使用 CoT 时 LLM 能更好地生成可执行的形式化方案规划；但如果使用语言模型来生成方案规划，然后再使用外部符号解算器来求解该规划，性能表现还会更好一些。</p><p>这样的结果忽然让 CoT 的处境变得有点尴尬：在 CoT 有用的问题上，我们能使用外部工具做得更好；在另一些问题上，CoT 的能力又有限。</p><p>因此，该团队认为：「第一，很多广泛使用 CoT 解决的问题其实根本没必要使用 CoT：现在已有更高效方法，能以远远更低的推理成本取得相近的性能。第二，基于提示词的 CoT 不够用了，我们看到人们迫切地需要更复杂精妙的方法，比如基于搜索、交互式智能体或针对 CoT 进行过更好微调的模型的方法。」</p><h2><strong>文献研究</strong></h2><p>首先，该团队调研了近期的相关文献，比较了使用或不用 CoT 的提示词的效果。</p><p>具体指标和流程这里就不多介绍了。总之，他们从 110 篇论文（35 篇 ICLR 论文和 75 篇 NAACL 和 EACL 论文）中整理出了 1218 个实验结果，涉及 264 个数据集。之后，他们将这些相关任务分成了 14 类，表 1 展示了其中几类的定义。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_084b129f89714772b47217a00061d774@000000_oswg110873oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>文献研究结果</strong></h2><p>图 2 展示了 CoT 为不同类型的任务带来的性能增量，即使用 CoT 提示法取得的性能减去使用直接回答法取得的性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_c4896fd290f04b8b8d1361d6409b493c@000000_oswg115309oswg1062oswg867_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，在这些任务上，CoT 平均仅能带来 3.75% 的提升。其中 CoT 带来增益最大的三类任务分别是：符号推理、数学、逻辑推理。在这三个任务上，CoT 实现的平均性能为 56.9，而不使用 CoT 的表现为 45.5。而在其它任务上表现较好的个例（图中用黄色高亮标记出了 10 个），也或多或少与这三个任务有关。</p><p>但在其它任务上，CoT 的表现就没什么亮点了，平均成绩仅有 56.8，而就算不使用 CoT，直接回答法也能得到 56.1。该团队认为，这一点点提升甚至不能算作是提升，毕竟 CoT 的计算成本明显更高。</p><h2><strong>实验研究</strong></h2><p>除了研究近期文献，该团队也执行了实验，其中涉及到 20 个数据集和 14 个模型，并测试了零样本提示和少样本提示两种设置，见表 2。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_97b8c447d2d2403293c448f64923b417@000000_oswg189183oswg1056oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>实验研究结果</strong></h2><p>下面我们通过对一系列问题的解答来了解实验结果。</p><h3>1.在哪些任务上，零样本 CoT 优于直接提示？</h3><p>图 3 左展示了 CoT 在五个推理类别（见图 1 右）上带来的平均性能增益；图 3 右则是 CoT 在每个数据集上带来的平均性能增益。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_47e0f0bc219948b6a6c9d64d0347ef35@000000_oswg154748oswg1075oswg690_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，在非符号推理类别和数据集上，特别是那些主要包含常识（CSQA、PIQA、SiQA）、语言理解（WinoGrande）和阅读理解（AGI LSAT、ARC-Easy、ARC-Challenge）的问题上，零样本 CoT 和零样本直接回答的性能几乎没有区别。尽管这些数据集涉及推理，但 CoT 并没有带来增益。</p><p>相比之下，数学和符号类别（以及符号和半符号数据集）获得了更大的提升。CoT 在 MATH 和 GSM8k 上带来的增益分别高达 41.6% 和 66.9%。在 ContextHub 和 MuSR Murder Mysteries 等半符号数据集上，CoT 表现出了中等程度的增益。这些数据集需要应用逻辑规则才能得出答案，例如从简单的自然语言（ContextHub）或更复杂的常识性陈述（MuSR Murder Mysteries）中解析得到的一阶逻辑。</p><p>在少样本设置下得到的实验结果类似。</p><h3>2.回答格式是否会影响 CoT 的有用性？</h3><p>除了数学之外，许多常用的数据集都是多项选择题。该团队指出，对于两个非多项选择题的数据集（MuSiQue 和 BiGGen Bench，并且它们需要不同层级的非符号推理才能给出回答），CoT 的表现与直接回答相近。</p><p>因此，可以说回答格式对 CoT 的有用性的影响不大。并且，该团队还表示，预先针对正确响应进行规划或推理甚至可能妨碍 LLM 自由响应的能力。</p><h3>3.CoT 在知识、软推理和常识推理方面带来的提升是否显著？</h3><p>在 13 个涉及知识、软推理和常识推理的数据集上，该团队测试了 CoT 的表现，结果发现：答案是否定的，但 MMLU、StrategyQA 和 MuSR 是例外。在这三个数据集上，CoT 可以带来比较显著的增益。</p><h2><strong>详细研究 MMLU 和 MMLU Pro</strong></h2><p>MMLU 和 MMLU Pro 是两个范围广泛的数据集，因此很难简单地描述它们的特征。该团队详细研究了 CoT 在 MMLU 中每个类别上的性能表现，以了解 CoT 在不同领域的性能差异。</p><p>表 3 给出了 CoT 能为 Llama 3.1 8B 和 70B 在 MMLU 和 MMLU Pro 上带来最显著提升的三个类别。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_97b04b5ce04d4a57a1711ba9e9d6677e@000000_oswg92881oswg1067oswg361_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，其中一些与数学有关，这不出人意料，但也有的属于「商业」等类别。不过更进一步研究发现，这些类别通常也涉及数学（比如资产计算等）。</p><p>因此，该团队对 MMLU 进行了更细粒度的研究（实例级）。他们发现问题或生成的响应中是否包含 = 这个符号非常关键，可以说是「符号推理的一个强有力的标志」。结果见图 4。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_08c54a1b8fea493496025e22376426a9@000000_oswg101768oswg1055oswg522_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，当有 = 时，CoT 在 MMLU 和 MMLU Pro 上的表现明显会更好。该团队认为这是因为 = 通常出现在数学问题中。所以归根结底，CoT 依然是能在数学问题上为 MMLU 和 MMLU Pro 带来助益。</p><h2><strong>CoT 在形式推理方面的优势和劣势</strong></h2><p>下面来解释 CoT 有助于符号推理任务的原因。很多符号和半符号推理任务都可以分成两个阶段：规划与执行。该团队也基于此思路进行了分析。</p><p>设置 1 和 2：少样本直接回答和 CoT：使用之前的少样本直接回答和 CoT 作为基线。图 5 给出了在 GSM8K 上每个设置的示例。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_2f54c209d432496a933d1e12ece7a3de@000000_oswg116478oswg1063oswg586_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>设置 3 和 4：规划 + 直接求解器以及计划 + CoT 求解器。</p><p>设置 5：规划+工具求解器。</p><h2><strong>评估结果</strong></h2><p>图 6 展示了选出的代表性模型的结果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_0e0937b19bd940ff88f9b2a828face07@000000_oswg142105oswg1059oswg673_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，对于许多数据集和模型而言，仅仅有规划不足以带来明显的性能增益。与直接回答相比，CoT 或规划+ CoT 求解器是实现强大性能所必需的。使用其中一种方法跟踪执行情况可带来最大的准确性优势，尤其是对于含有大量数学内容的数据集。</p><p>尽管 CoT 或规划+ CoT 求解器比直接回答和规划+直接回答更强，但规划+工具求解器在大多数情况下还要更优。也就是说，很多时候，使用 CoT 还不如让 LLM 使用工具。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650935056&amp;idx=2&amp;sn=25a4d6445aaae181db9f38047847f62c&amp;chksm=85eb251f189069a57ad16a89b499860ce161de26d227eef5f02a47343b2d7436946279dbdb5f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，编辑：Panda，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958037243299840</id>
            <title>AI 3D生成天花板再拉升，清华团队炼成3D Scaling Law</title>
            <link>https://www.36kr.com/p/2958037243299840</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958037243299840</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 08:13:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《黑神话·悟空》的火爆，带火的不仅是3D游戏本身，还有背后暗潮汹涌的<strong>AI 3D生成</strong>技术。</p><p>一直以来，外界对3D大模型赛道的关注度都稍逊于语言模型和视频模型。然而，全球3D大模型选手们则都在暗中较量、默默发力，从a16z押注的Yellow，到李飞飞的World Labs，3D大模型的迭代速度是没落下一点。</p><p>就在刚刚，国内3D大模型头部玩家<strong>VAST更新了旗下的大模型Tripo</strong>，是基于千万级高质量原生自有数据库训出来的那种超强版本。</p><p>而3D生成新工具的玩法也更进一步，<strong>文字、单图、多图都能作为输入</strong>。</p><p>在官宣新品之余，VAST又带来另一则重磅消息，即公司连续完成了数亿元融资，这也是3D大模型赛道的最大融资金额。</p><p>当然，融资方面的引领，也只是技术实力的展现。因为VAST的技术和应用场景，确实够顶。</p><h2><strong>快速生成无瑕疵，效果惊艳</strong></h2><p>再次拉升AI 3D天花板的模型叫做<strong>Tripo 2.0</strong>。</p><p>Tripo 2.0先在几秒内生成<strong>形状几何</strong>预览，再接着几秒内为其“贴上皮肤”，⽣成<strong>纹理及PBR</strong>。</p><p>目前Tripo 2.0已正式上线，大批网友已经开启了实测。</p><p>Tripo 2.0支持文生3D、单图生3D；Tripo 1.4版本也支持多图生3D。</p><p>输入一个prompt，一次能生成4个3D模型。</p><p>根据输入的不同，量子位的上手实测结果在下面分为两个部分，即：</p><ul><li><strong>文生3D模型</strong></li><li><strong>图生3D模型</strong></li></ul><h3><strong>Tripo 2.0文生3D模型实测</strong></h3><p>话不多说，直接先来看一波文生3D效果。</p><p>第一步，生成几何形状「动漫少女的半身形象」。</p><p>就复杂结构生成效果来看，细节还是很足的：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_371ea688aa73433f9cfe0ac7f2d19600@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>接下来给它贴好皮肤。</p><p>在不超过20秒的生成时间里获得精细的纹理和层次；普通水平的人工建模要达到这种细节，耗时可能要上千倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_0bc3b4b2682d49c28a146d7013e3dddf@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>换一道题！用Tripo 2.0生成卡通形象的全身形象试试看。</p><p>先生成个卡通小矮人试试～</p><p>出来的效果，那是相当可爱（发出宋丹丹的声音），belike：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_27783f43b64a4e698b9da37890adc090@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>我们又生成了一个小怪物，并且把单个生成的模型放大来看。</p><p>360度旋转，肉眼没有发现bug和瑕疵。要知道，怪物后背<strong>密密麻麻的尖刺细节</strong>，是人工建模师的噩梦，一般都会规避这种繁复的设计，但是对tripo来说毫无压力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_276309d641854a76b08876c7741e501b@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>加大难度，再复杂一些3D模型生成任务也同样能驾驭。</p><p><strong>透视结构理解</strong>过去一直是生成式AI的卡点，以生图模型的手指问题为代表。3D模型空间结构极为重要，我们可以看到Tripo强大的透视结构理解能力，完美生成了复杂结构的模型任务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5a6f3859c62441b2af72e2459a2e3e0d@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后再放个厉害的，下面这个购物车什么难度都不用多说了：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_43615418a1364943b4132a706162ba3e@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>Tripo 2.0图生3D模型实测</strong></h3><p>再来看一波图生3D的效果。</p><p>单图生3D模型的算法最考察对图片的<strong>空间信息理解和还原度</strong>，这次我们横向对比一些市场的其他玩家效果。</p><p>友情提示，下面每张展示图中的<strong>最后一个3D模型，都由Tripo 2.0生成</strong>。</p><p>来，上一支玫瑰花的图生模型对比展示！</p><p>对比可以清晰看到，只有它生成的几何形状360度无死角，花朵和枝叶完整度最高：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_29ba1149268449d581227eadaaf53648@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>贴图之后，在还原原图的颜色、质感这一块，也是效果最好的：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_bd7641453a154c0781334a703624a046@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>测完植物生成效果，我们又测试了无生命物体的图生模型。</p><p>丢给模型一个俄罗斯复活节彩蛋图片作为输入，Tripo 2.0的输出效果最有“浮雕感”，对比来看，纹理细节都是最精致的：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_bf3d938bae984c3c8a89160ddfb8c13b@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>进行多次测试后，不难发现Tripo 2.0在全方位的生成表现上都有显著差异。</p><p>比如生成的PBR材质具有⾼保真度，保留了原图表⾯属性和视觉效果：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_d9012a935be847bcac906ebfd6cf0dc3@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再比如，不管侧面、背面，每个面都能捕捉复杂的原图特征：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f3f4248060804cdcb60107a42f53b6a8@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Tripo 2.0不仅生成质量让人眼前一亮，更高的<strong>可控性</strong>也是一大特点。</p><p>输入不仅支持多模态，当选择文生3D模型模式时，还支持输入负向prompt（就是不让生成模型中带有什么元素）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_9b9b6ac26c72448681d1806446cf83ce@000000_oswg75292oswg790oswg476_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对输出<strong>模型姿态</strong>的控制性也很绝。</p><p>既能自定义所生成3D模型头、腿、手臂等比例。</p><p>还能“A-pose”“T-pose”两个姿势随便选，秒秒钟设定大长腿：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_910cd71ab81b41e8a5398ec2e6449b10@000000_oswg15041oswg620oswg526_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>生成好的3D模型还可以一键绑定骨骼、风格化。</p><p>3D模型人拥有自己的乐高！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_c5aa81f9942c488eb82a61dddd61e21d@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更多玩法大家可以慢慢探索，欢迎大家评论区共创～</p><p>Tripo 2.0效果如此哇塞，所以——</p><h2><strong>Tripo 2.0如何炼成？</strong></h2><p>从技术上层层解剖，Tripo 2.0在实现过程中打满了一个词：<strong>3D Scaling Law</strong>。</p><p>首先，Tripo 2.0基于<strong>海量千万级3D⾼质量数据库</strong>，采⽤概率性的⽣成式建模⽅法，通过学习捕捉⼤规模数据中的⼏何和材质分布。</p><p>由此，Tripo 2.0更好地保证了输出的质量、增强了模型的鲁棒性和泛化能⼒。</p><p>其次，它采用了<strong>DiT和U-Net模型的复杂混合架构</strong>。</p><p>DiT擅⻓捕捉3D结构中的全局上下⽂和⻓距离依赖关系，而U-Net精于保留精细的细节和局部特征，Tripo 2.0正是融合了这两种架构的优势。</p><p>再者，采⽤最先进的训练算法，Tripo 2.0⼏何和材质⽣成模型均基于最先进的⼤规模流模型，拥有<strong>数⼗亿参数</strong>。</p><p>同时采⽤了guidance distillation和step distillation，通过蒸馏提⾼效率，在不牺牲质量的前提下⼤幅优化了性能。</p><p>种种技术加持下，在3D生成形状、纹理质量、细节表现、输⼊条件的遵循性以及输出多样性⽅⾯，Tripo 2.0拿下新SOTA，成为新晋“五边形”战士：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_874f14ce6ba54b37ade2eb78dadb376d@000000_oswg30323oswg900oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>之前，Tripo 2.0背后团队还与其他团队合作，推出了一箩筐学术成果，被Siggraph、CVPR、ICLR、ECCV等顶会接收。</p><p>比如<strong>Wonder3D</strong>，通过一个跨域扩散模型生成一致性的多视图法线贴图和相应的彩色图像，然后利用一种新颖的法线融合算法快速、高质量地重建3D几何体。</p><p>与现有的基于分数蒸馏采样（SDS）的方法相比，Wonder3D在效率、一致性和细节上都有显著提升，能够在2-3分钟内完成重建。</p><p>再比如<strong>TGS：Triplane Meets Gaussian Splatting</strong>，同样被CVPR 2024收录。</p><p>这项技术利用Transformer网络和一种新颖的Triplane-Gaussian混合表示，使得从单张图片中重建3D模型变得更加高效和精确。</p><p>更多细节，感兴趣的童鞋可以自行查阅。</p><p>总之，Tripo 2.0并非一蹴而就，背后有众多技术积累。</p><h2><strong>3D世界的Scaling Law</strong></h2><p>最后，我们来正式认识一下Tripo 2.0背后的公司。</p><p><strong>VAST</strong>，去年3月成立，是一家专注于在3D大模型研发的AI公司。</p><p>公司目标是“通过打造⼤众级别的3D内容创作⼯具，建⽴3D的UGC内容平台，让基于3D的空间成为用户体验、内容表达、提升新质⽣产⼒的关键要素。”</p><p>公开资料显示，该公司的CEO、CTO都是商汤出身：</p><p><strong>创始人兼CEO宋亚宸</strong>，曾在商汤落地过多个从零到一的AI项目，曾参与大模型六小强之一MiniMax的创立；<strong>CTO梁鼎</strong>，清华本硕博，师从戴琼海院士，曾任商汤通用模型负责人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f3e2540a6b5946f6a2a600b6dfeedc6f@000000_oswg60853oswg228oswg188_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>成立一年半以来，这家公司动作频频。</p><p>首先在今年年初，亮相了自家首个3D大模型<strong>Tripo 1.0</strong>。</p><p>Tripo 1.0参数量数十亿，用上它，从单图/文字生成3D网格模型仅需要8秒。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_7572c32b907c4113ad6e6e991d1743e7@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>上线半年内，Tripo 1.0全球用户生成的3D模型超过了500万个。</p><p>500万个是什么概念呢？约为全球前三大3D模型数据库总和。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_8fa27f0c842b48dbae0c4cd2489cb974@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>到了今年3月初，VAST又联合Stable Diffusion背后的Stability AI，共同推出了开源的3D基础模型<strong>TripoSR</strong>。</p><p>因其能够达成“0.5秒完成单图生成3D模型”的成就，在3D生成领域的开源届广受欢迎，至今GitHub上揽星4.3k。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_93ad990082194e6eab7aee637b7218ce@000000_oswg90176oswg1080oswg345_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在，Tripo 2.0又问世了，已经在线可玩。</p><p>得益于3D Scaling Law带来的效果提升，Tripo的这三次更新时间跨度仅仅有9个月。</p><p>而且有速度也有质量，效果在业内外颇受认可。</p><p>拿一则新消息来佐证一下：不久前，世界最大在线游戏开发平台Roblox官宣入局AI 3D生成，但截至目前，Tripo都是Roblox玩家最风靡的3D建模的趁手工具。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_27d72bc4bdca4693bea87d2af3a8f142@000000_oswg85344oswg846oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>接下来的VAST会带着Tripo去向什么方向？</p><p>量子位寻回的答案是，至少在技术方面，VAST会<strong>持续追寻3D生成式AI的Scaling Law</strong>研究模型规模、数据量和生成质量之间关系的基本原理，同时寻找数据、表征和模型架构的可扩展范式。</p><p>既致力于推动3D生成式AI的边界，也会不断探索更整体的（Holistic）3D生成。</p><p>就还挺令人期待的。</p><p>在语言模型和视频模型带给这个世界一点小小震撼过后，人们也希望3D生成赛道能滋养出属于自己的ChatGPT时刻。</p><p>毕竟3D的AI生成与其它AI生成赛道相比，情况比较特殊，不仅AI生成后人工二改技术难度大，如果模型效果表现不好，想要仅凭增加抽卡次数来达到满意度，不如趁早自己画（不是）。</p><p>好在3D生成行业深孚众望，一路前行着——</p><p>回顾过去的两年时间，尤其在2023年末到2024年间，3D生成技术得到了快速发展。</p><p>不仅在效果、速度方面均有提升，还实现了“效率高、成本低、创新性强和可定制性强”的特点。</p><p>技术飞快进步的同时，整个行业的人才密度都在不断增大。</p><p>国内，以VAST为代表，初创公司多来自全球知名高校和科研机构；放眼国外，AI教母李飞飞首次创业成立的空间智能公司<strong>World Labs</strong>，也着眼于3D生成世界，宣布长期目标是构建大世界模型（LWM）来感知、生成3D世界并与之交互。</p><p>众人拾柴火焰高嘛。</p><p>可以说，因为人才与技术、效果与场景的清晰和进步，现在AI 3D生成这个赛道，渐渐走进了更多人的视野之中。</p><p>而3D Scaling Law或将带来的突破性进展，似乎已经预示了人工智能领域下一个焦点的方向。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247750212&amp;idx=1&amp;sn=1c173744f36701f66181e5c275e22175&amp;chksm=e92e737daf8b31b423786597d8b38ce3756d17868dc2dfa31adfbc4fa51baa9a209bead4592f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID：QbitAI）</a>，作者：衡宇 西风，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958002365728262</id>
            <title>神州数码联合华为打造昇腾能力中心，聚焦边缘推理应用 | 最前线</title>
            <link>https://www.36kr.com/p/2958002365728262</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958002365728262</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 08:07:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>文 | 田哲</p><p>编辑 | 苏建勋</p><p>9月19日，神州数码宣布合作华为打造基于华为昇腾最新基础硬件设施的昇腾能力中心，该能力中心将AI芯片销售、软硬件开发于一体，可针对不同行业的AI推理场景需求，提供AI产品开发环境。</p><p>大模型对算力需求整体体现在预训练、推理、调优三部分，其中通过推理，开发人员可定位模型中潜在问题，提升模型性能。</p><p>随着模型越发庞大，对推理算力需求也将持续增长。华为昇腾计算整机业务总监胡宣春表示：“AI正在从感知识别迈向内容生成，从专用AI模型转向更为广泛的通用AI模型。AI应用的爆发式增长，可能带动AI推理算力需求激增至训练算力的百倍。”</p><p>IDC 数据显示，我国23H1训练工作负载的服务器占比达到 49.4%，预计全年的占比将达到 58.7%。随着训练模型的完善与成熟，模型和应用产品逐步投入生产，推理端的人工智能服务器占比将随之攀升，预计2027 年，用于推理的工作负载将达到72.6%。&nbsp;</p><p>神州数码信创业务集团副总裁、研发中心总经理周川告诉36氪，以前的推理以中心推理为主，而现在的推理应用更多在边缘侧，后者对算力需求相对更大。因此有必要推出更大算力、基于边缘推理应用的参考设计方案。</p><p>因此，神州鲲泰基于与华为的深度合作，将打造昇腾能力中心，为不同行业的客户提供产品软硬件的设计能力以及应用迁移适配调优的能力，缩短客户产品上市时间。</p><p>公开资料显示，神州数码集团于2019年加入华为鲲鹏生态，2020年发布自有品牌“神州鲲泰”，已推出数据计算、终端、DCN数据通信、KunTai数据通信四条产品线。</p><p>周川认为，由于基础设施不断建设，训练模型最终会变成应用落地，训练的高峰发展期可能即将结束。由于许多客户的数据十分敏感，不能流通，因此有着本地建设推理中心的推理需求，推理侧将存在大量建设、应用机会。</p><p>他表示，不同行业的推理应用形态不一，华为难以支撑所有客户应用需求，神州数码的昇腾能力中心可以帮助华为覆盖中小型客户，这是神州数码对比友商的最大差异点与优势。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958050122663936</id>
            <title>o1核心作者MIT演讲：激励AI自我学习，比试图教会AI每一项任务更重要</title>
            <link>https://www.36kr.com/p/2958050122663936</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958050122663936</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 07:47:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>“o1发布后，一个新的范式产生了”</strong>。</p><p>其中关键，OpenAI研究科学家、o1核心贡献者<strong>Hyung Won Chung</strong>，刚刚就此分享了他在MIT的一次演讲。</p><p>演讲主题为“Don’t teach. Incentivize（不要教，要激励），核心观点是：</p><blockquote><p><strong>激励AI自我学习比试图教会AI每一项具体任务更重要</strong></p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_fbc7f37ad1d34252aea4014b8614a055@46958_oswg268662oswg1080oswg816_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>思维链作者Jason Wei</strong>迅速赶来打call：</p><blockquote><p>Hyung Won识别新范式并完全放弃任何沉没成本的能力给我留下了深刻的印象。2022年底，他意识到了强化学习的力量，并从那时起就一直在宣扬它。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_426f411446d84bef8f8510f2e19a99ef@46958_oswg319286oswg1080oswg620_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在演讲中，Hyung Won还分享了：</p><p>技术人员过于关注问题解决本身，但更重要的是<strong>发现重大问题</strong>；</p><p>硬件进步呈指数级增长，软件和算法需要跟上；</p><p>当前存在<strong>一个误区</strong>，即人们正在试图<strong>让AI学会像人类一样思考</strong>；</p><p>“仅仅扩展规模” 往往在<strong>长期内更有效</strong>；</p><p>……</p><p>下面奉上演讲主要内容。</p><h2><strong>对待AI：授人以鱼不如授人以渔</strong></h2><p>先简单介绍下<strong>Hyung Won Chung</strong>，从公布的o1背后人员名单来看，他属于<strong>推理研究的基础贡献者</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_1eabd6d24d6e423983b64458cc630f98@46958_oswg36573oswg1080oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>资料显示，他是MIT博士（方向为可再生能源和能源系统），去年2月加入OpenAI担任研究科学家。</p><p>加入OpenAI之前，他在<strong>Google Brain</strong>负责大语言模型的预训练、指令微调、推理、多语言、训练基础设施等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_55cb5a0fd76648fea48b4a133f4e1ff7@46958_oswg317007oswg1080oswg671_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在谷歌工作期间，曾以一作身份，发表了关于模型微调的论文。（思维链作者Jason Wei同为一作）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5b18cb764fa2489185ea8fa26b1bc4d0@46958_oswg392508oswg1080oswg740_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>回到正题。在MIT的演讲中，他首先提到：</p><blockquote><p>通往AGI唯一可行的方法是激励模型，使<strong>通用技能</strong>出现。</p></blockquote><p>在他看来，AI领域正处于一次<strong>范式转变</strong>，即从传统的直接教授技能转向激励模型自我学习和发展通用技能。</p><p>理由也很直观，AGI所包含的技能太多了，无法一一学习。（主打以不变应万变）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f63fb099dd0542c7886d07e6b3de97fe@46958_oswg235667oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体咋激励呢？？</p><p>他以<strong>下一个token预测</strong>为例，说明了这种<strong>弱激励结构</strong>如何通过<strong>大规模多任务学习</strong>，鼓励模型学习解决数万亿个任务的通用技能，而不是单独解决每个任务。</p><p>他观察到：</p><blockquote><p>如果尝试以尽可能少的努力解决<strong>数十个任务</strong>，那么<strong>单独模式</strong>识别每个任务可能是最简单的；如果尝试解决<strong>数万亿个任务</strong>，通过学习<strong>通用技能（例如语言、推理等）</strong>可能会更容易解决它们。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_0d5b48d6225b4e119322f150776a240a@46958_oswg173412oswg1080oswg505_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对此他打了个比方，“授人以鱼不如授人以渔”，用一种基于激励的方法来解决任务。</p><blockquote><p>Teach him the taste of fish and make him hungry.（教AI尝尝鱼的味道，让他饿一下）</p></blockquote><p>然后AI就会自己出去钓鱼，在此过程中，AI将学习其他技能，例如耐心、学习阅读天气、了解鱼等。</p><p>其中一些技能是通用的，可以应用于其他任务。</p><p>面对这一“循循善诱”的过程，也许有人认为<strong>还不如直接教来得快</strong>。</p><p>但在Hyung Won看来：</p><blockquote><p>对于人类来说确实如此，但是对于机器来说，我们可以提供<strong>更多的计算</strong>来缩短时间。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5a121b08760249be90ed7261194598ff@46958_oswg23178oswg1080oswg488_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>换句话说，面对有限的时间，人类也许还要在专家 or 通才之间做选择，但对于机器来说，算力就能出奇迹。</p><p>他又举例说明，《龙珠》里有一个设定：在特殊训练场所，角色能在外界感觉只是一天的时间内获得一年的修炼效果。</p><blockquote><p>对于机器来说，这个感知差值<strong>要高得多</strong>。因此，具有更多计算能力的强大通才通常比专家更擅长特殊领域。</p></blockquote><p>原因也众所周知，大型通用模型能够通过大规模的训练和学习，快速适应和掌握新的任务和领域，而不需要从头开始训练。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a389170fd36b40ffbf2f9d0c3003113b@46958_oswg170762oswg1080oswg511_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他还补充道，数据显示<strong>计算能力大约每5年提高10倍</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_4ee3a5400bc9495f85aeb81b25c77373@46958_oswg271751oswg1080oswg553_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>总结下来，Hyung Won认为核心在于：</p><ul><li><strong>模型的可扩展性</strong></li><li><strong>算力对加速模型进化至关重要</strong></li></ul><p>此外，他还认为当前存在一个误区，即人们正在试图<strong>让AI学会像人类一样思考</strong>。</p><p>但问题是，我们并不知道自己在<strong>神经元层面</strong>是如何思考的。</p><blockquote><p>机器应该有更多的自主性来选择如何学习，而不是被限制在人类理解的数学语言和结构中。</p></blockquote><p>在他看来，一个系统或算法过于依赖人为设定的规则和结构，那么它可能难以适应新的、未预见的情况或数据。</p><p>造成的结果就是，面对更大规模或更复杂的问题时，其扩展能力将会受限。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_6e2877c1fccd4ec2970ccd694b15dd19@46958_oswg77432oswg1080oswg580_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>回顾AI过去70年的发展，他总结道：</p><blockquote><p><strong>AI的进步与减少人为结构、增加数据和计算能力息息相关。</strong></p></blockquote><p>与此同时，面对当前人们对scaling Law的质疑，即认为仅仅扩大计算规模可能被认为不够科学或有趣。</p><p>Hyung Won的看法是：</p><blockquote><p>在扩展一个系统或模型的过程中，我们需要找出那些<strong>阻碍扩展的假设或限制条件。</strong></p></blockquote><p>举个例子，在机器学习中，一个模型可能在小数据集上表现良好，但是当数据量增加时，模型的性能可能会下降，或者训练时间会变得不可接受。</p><p>这时，可能需要改进算法，优化数据处理流程，或者改变模型结构，以适应更大的数据量和更复杂的任务。</p><p>也就是说，一旦识别出瓶颈，就需要通过创新和改进来替换这些假设，以便模型或系统能够在更大的规模上有效运行。</p><h2><strong>训练VS推理：效果相似，推理成本却便宜1000亿倍</strong></h2><p>除了上述，o1另一核心作者<strong>Noam Brown</strong>也分享了一个观点：</p><blockquote><p>训练和推理对模型性能提升作用相似，但后者成本更低，便宜1000亿倍。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_fa47c87449ee4c8a9faee120b983fa5d@46958_oswg370689oswg1080oswg592_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这意味着，在模型开发过程中，训练阶段的资源消耗非常巨大，而实际使用模型进行推理时的成本则相对较低。</p><p>有人认为这凸显了未来模型优化的潜力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_644f21e0309d4e63b3b5b5bcf8be7085@46958_oswg152040oswg1080oswg342_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过也有人对此持怀疑态度，认为二者压根没法拿来对比。</p><blockquote><p>这是一个奇怪的比较。一个是边际成本，另一个是固定成本。这就像说实体店比其中出售的商品贵500000倍</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_9c02521680b24ef5872222837660b80a@46958_oswg188823oswg1080oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对此，你怎么看？</p><p>Hyung Won Chung演讲PPT：https://docs.google.com/presentation/d/1nnjXIuN2XDJENAOaKXI5srQscO3276svvP6JgivTv6w/edit#slide=id.g2d1161c9c52_0_20</p><p>参考链接：</p><p>[1]https://x.com/hwchung27/status/1836842717302943774</p><p>[2]https://x.com/tsarnick/status/1836215965912289306</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/oE5m4vCrvbpW_51MRcy7XA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：一水&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958065087072519</id>
            <title>都2024年了，去字节实习到底还值不值？</title>
            <link>https://www.36kr.com/p/2958065087072519</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958065087072519</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 07:47:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_8459f75be29e47f6856a0555fca3616f@5509299_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b759040f12fb4bb6b7f02bdc89fb8772@5509299_oswg175050oswg900oswg891_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「职场Bonus」（ID：ZhiChangHongLi）</p><p><strong>“我数据最好的两篇笔记，发布的内容就是在字节的实习日常。”</strong></p><p>小红书上，去字节实习的经验分享占据了“实习”词条的半壁江山。在流量加持下，“字节实习博主”成了热门人设。</p><p>职友集数据显示，字节跳动的公司人气高达498.3万。就连曾经主要参观北大清华的中小学生研学项目，如今也多了一项“走进字节”。</p><p>身在字节的员工偶尔会看到这样一幕：小学生被一辆辆大巴送了过来，很安静地绕着工位走一圈就离开了。“你长大了，要么去考公务员，要么就去字节实习。”无论小学生们的内心是否真的留下了憧憬，在一些仍崇尚互联网大厂的父母眼里，字节跳动俨然是孩子步入社会前最好的“黄埔军校”。</p><p>字节跳动能在求职市场拥有超高人气，背后是实习生组成的宣传大军。</p><p>在逐年“降温”的就业环境中，大学生形成了更早的实习意识。实习不仅能让人提前获得工作经验，也能为其毕业找正式工作丰富履历、打下人脉基础。中国青年网校园通讯社2023年对14578名大学生进行问卷调查显示，在有过实习经历的大学生中，<strong>第一次实习经历发生在大一的占比67.84%，发生在大二的占比为21.08%。</strong></p><p>但就业寒冬也缩减了互联网大厂面向应届生的录用机会，字节并不是其中的例外。8月6日，字节跳动正式启动“2025届校园招聘”，招聘岗位约4000+——相较其2020、2021年时的春招/秋招（每次约6000-7000的岗位量级）缩水三成左右。</p><p>“挤破脑袋进入字节，值吗？”缩招后的应聘竞争更激烈了，得到这个机会的实习生大多得接受六个月起步的实习期。“像在做乙方”、“被压榨，很烦躁”是他们在社媒上的常见抱怨。进入字节后究竟是“飞速成长”还是“当互联网流水线工人”仍有待商榷。</p><p>当然，坚信“宇宙厂” [1] 字节跳动能为自己的实习生涯带来超值收获的人还是多数。六个月起步的字节实习到底值在哪儿？什么样的人能够进入字节实习？</p><p>职场Bonus联系了6位字节实习生博主。在她们的回忆里，对照今日的字节与入职前想象中的字节，大公司的另一副面孔跃然眼前。</p><p>[1] 宇宙厂：对于字节跳动的戏称。“宇宙厂”的由来，一说是前CEO张一鸣在2020年的一封内部信中，鼓励员工要有“火星视角”。还有另一说是字节跳动的“超级APP工厂”属性，资讯、短视频什么都做，还偏偏都能成，于是被送外号“宇宙厂”。</p><p><br />&nbsp;</p><blockquote><p>平等地成为每一颗大厂螺丝钉 ╱&nbsp;01</p><p>Leader把我“仅聊天”了 ╱&nbsp;02</p><p>转正成功后，我发现高福利=高强度&nbsp;╱&nbsp;03</p><p>在字节，我算是学历背景比较差的 ╱&nbsp;04</p><p>不想转正的实习，以后仍想创业&nbsp;╱&nbsp;05</p><p>实习转正后，我的岗位被撤销了…&nbsp;╱&nbsp;06</p></blockquote><p>&nbsp;</p><h2><strong>平等地成为每一颗大厂螺丝钉</strong></h2><p><strong>小红书@小福星的求职指南，华东师范大学广播电视数字媒体专业研三在读</strong></p><p>伊灵属于典型的“实习测评师”：研三在读的她，已经有了7段实习经历。</p><p>和那种“毕业即成为拥有四年工作经验的应届生”不同，伊灵的实习更多的是为了体验。她先后在<strong>字节、麦家工作室、网易云音乐、如涵、滴滴青桔、凤凰网和浙江日报</strong>等不同公司和单位实习，也体验了<strong>新媒体运营、产品运营、产品经理和记者</strong>在内的多种岗位。通过这些实习，她体会到了不同公司的特点，也明白了自己未来想要从事什么样的工作。</p><p>2022年，在朋友圈晒出字节工牌仍是件值得自豪的事情。伊灵在这时进入字节，她的实习岗位是产品运营，日薪150元。<br />这里的领导们大多并不居高自傲，员工可以直呼其大名；卫生间里贴着彰显“开放谦逊、坦诚清晰”的企业文化的标语，杜绝“叫哥叫姐”，鼓励员工勇敢提出自己的意见。</p><p>运营B端产品、做活动、发行技术期刊、邀会议、跨部门沟通协作……伊灵在这里做的事情都内化为了见识和能力。通过举办技术活动和人物专访，她感受到自己在一步步深入了解行业。“我的认知得到了极大的提升，改变了看世界的眼光和态度，学会了用框架思维思考问题，强化了复盘和学习的能力。”在实习结束的时候，伊灵成功采访了字节前端负责人，还做了一本技术期刊。</p><p>和传统媒体不同，伊灵认为字节的沟通协作非常高效。字节内部使用飞书开会，不止要记录会议纪要，更要求所有与会人员在会前阅读、评论，确保会议高效进行。</p><p>字节内部保持着“终生学习”的理念。在很多内部学习分享会上，同事们会分享新学到的东西、看的书以及相关的网络资讯和链接。伊灵当时就受邀进行过一次分享，“他们抱着虚心的态度来学习，面对我这样一个比他们小十岁的人都没有任何傲慢，甚至会后还把我分享的内容纳入了知识库里。”</p><p>然而随着实习的深入，伊灵也看到了互联网行业的一些弊端：<strong>互联网泡沫褪去，行业内部的就业形势和大环境一样不佳。</strong>曾经应届生在阿里、腾讯能够拿到30-35k的岗位，如今公司不变、工作内容不变，工资却只能拿到10-15k。“最惨的是，你还没有到35岁，就已经被裁了。”薪资降低的同时，互联网公司的稳定性较差，员工不仅面临35岁困境，还要被迫迎接不断的裁员。</p><p>大厂里的“螺丝钉工作”具有高替代性，伊灵的大部分工作沟通又都是对内，和跑社会新闻相比，缺少与更广阔的社会面展开真正对话——这一点不光是实习生，很多正式员工也能感受到。此外，伊灵渐渐发现，时常进行的内部分享会中，员工们保持学习的动力，其实70％是害怕被淘汰，而只有30％是因为单纯的兴趣而学习。</p><p>“有时候，我们干的事情就像一个高级客服。”这与伊灵追求个人价值和社会价值的职业初衷相违背。于是，在离开字节后，她又开始尝试其他的工作，希望能在社会中摸爬滚打，积累人脉和经验。</p><p><strong>“工作内容饱和时，又有多少人会遵循兴趣去学习呢？多多少少还是害怕被取代吧。”</strong><br />&nbsp;</p><p>&nbsp;</p><h2><strong>Leader把我“仅聊天”了</strong></h2><p><strong>小红书@躺赢同学，香港中文大学本科直博</strong></p><p>没等大一暑假正式开始，躺赢就去字节实习了。</p><p>她就是传说中“千里迢迢跑来养房东”的那批人。2022年4月，疫情管控似乎刚放宽一些，但到北京第二天，躺赢就因楼里有密接和确诊，转为居家办公。连续居家办公一个月后，她逃回老家。</p><p>还没在家吃几顿热乎饭，字节表示封锁解除，可以正常上班，她再次回到北京。回京后不久，公司再次封锁，她只得在北京的出租屋里完成了剩下的实习。</p><p>“进入字节是一件很幸运的事情。”躺赢就读的香港中文大学四月份就放暑假了，她得以依靠这个时间差，避开找实习的高峰期。她的面试流程也相对简单：由于部门较小且独立招聘，只有 Leader和主管的两轮面试。面试中，问题常规且面试官友善，并没有故意刁难的提问。</p><p>在仅有的字节线下实习经历中，躺赢认为自己幸福感爆棚。字节实习生的薪资都是明码标价的，日结的薪资体系下，运营岗是每日150元，而技术岗则是每日220元，在公司附近租房会有1000元房补。公司内部健身房设施齐全，还有免费的三餐、免费的办公物品。</p><p>字节很重视仪式感，逢年过节都会给员工发礼物——最重要的是，这种福利对实习生是一视同仁的。躺赢在职的三个月就碰上了端午节、儿童节、公司周年庆，满满当当地收获了三份礼物。</p><p>而且，字节很贴心的考虑到了每一个员工的需求。端午节的粽子礼盒分为清真款和非清真款，员工可以根据需求，自行下单。</p><p>躺赢所在的部门很不“字节”。公司规定十点上班，躺赢按时到公司后休整一下，十点半准时出发拿小零食、咖啡。吃饱喝足了，她会在十一点半开始看邮件，而半个小时后，看完邮件的她就得下楼排队，准备吃饭了。</p><p>午休到两点钟，工作一会，两个小时后躺赢又要开始吃下午茶了。</p><p>吃下午茶的时候也要顺带溜溜弯，不然长时间久坐会对身体不好。七点准时下班，但是六点半她也必须要开始排队了——吃晚饭也是很重要的事情。</p><p>一个人这样或许会心虚，但一个部门都是如此，躺赢有一种“踩在云端，飘飘然”的感觉。</p><p>她无数次怀疑自己是不是来了到了一个“假字节”。只有在<strong>凌晨一点</strong>收到设计同事发来的设计图时，躺赢才会意识到“哦！没来错！这就是字节。”</p><p>唯一让躺赢心里有点不舒服的是，她与Leader的关系似乎有些微妙。或许是因为Leader比较在意个人隐私，躺赢发现Leader的微信对她设置了仅聊天。</p><p>不止是躺赢，同期的另一个实习生也同样被Leader屏蔽了朋友圈。</p><p>Leader的隔阂并非毫无道理。字节的优势在于环境年轻，但流动性同样很高。<strong>“字节就像黄埔军校，为了更好的发展，很多正式员工待两三年就会跳槽。”</strong></p><p>在被问到以后正式工作是否会选择字节，躺赢有些幽默地回复：“等我博士毕业后已经三十岁了，正好是被字节裁员的年纪。”</p><p>毕竟，<strong>没有人会永远年轻，但是字节的员工永远年轻。</strong></p><p>&nbsp;</p><h2><strong>转正成功后，我发现高福利=高强度</strong></h2><p><strong>小红书@昙尾vv，安徽工程大学本科 华东师范大学硕士</strong></p><p>机会的大门向VV敞开过两次。</p><p>第一次是去年11月字节的实习转正。虽然拿下了offer，但是高压、高负荷的工作让她犹豫，“一想到以后天天都要这样，就让人崩溃”。</p><p>2024年6月才毕业的VV，如果接受offer，就需要签署三方协议。并且，在拿到毕业证之前，不仅每月的工资都只有正式工资的80％，还仍需要保持一段时间的实习生身份。最关键的是，她无法确定自己是否能很好地协调工作与繁杂的毕业事宜。</p><p>于是，今年一月份VV选择离开字节，距离正式毕业还有五个月，她愿意给自己一段思考的时间。</p><p>第二次则是今年七月，这次她下定决心接下了字节的offer。</p><p>“我有总共九个月的实习时长，都已经超越平均司龄了。”VV半开玩笑地说道。作为把两种应届生入职路径都走通的幸运儿，VV认为实习生转正比校招更有优势。</p><p>实习生转正不需要像校招一样接受<strong>群面</strong>——取而代之的环节则是<strong>实习答辩</strong>。实习答辩和毕业论文答辩是有相似性的，实习生需要通过文档与PPT量化自己实习期间的产出，并回答评委提出的问题。而评委一般是自己部门的主管。</p><p>实习答辩后，通常只有领导面。而对校招生而言，群面过后还要多面对2-3轮的面试。另外，通过实习转正的人往往更熟悉字节，拥有有更多符合字节人才需求的能力。</p><p>实习期间，VV在抖音电商运营部门——这也是字节内部公认工作强度大、节奏快的部门，尤其是类似“618、双11”这种让电商人闻风丧胆的大促期间，哪怕公司不强制员工加班，但为了完成工作任务，加班也不可避免。</p><p>好在字节的补偿相对到位。实习生若加班超过9点，可以选择打车回家，费用由公司报销。对于正式员工的规则则是：加班可以选择调休，若调休假未用，离职时可换成加班费。此外，正职员工拥有按照最高标准缴纳的五险一金、高规格免费体检以及较多的带薪假期。</p><p>纵有人性化的福利待遇光环，VV还是认为，实习工作是一个祛魅的过程。<strong>“光环之下，是加班、是高强度。”</strong>高产出是需要人来支撑的，字节愿意付出足够的诚意，但享受福利的人也不应该忘了“命运馈赠的礼物，早在暗中标好了价格”。</p><p>事实上，这也是为何“成为字节正式员工”的大门第一次敞开时，VV转身暂离的原因：她有种不断被push，一直在做自己不喜欢的事情的痛苦感。在“逃离”后的半年间，VV回到学校忙着写论文、处理毕业事宜，渐渐从消极的情绪中走出。</p><p>7月，VV选择重新入职这个给自己带来痛苦与成长的大厂。<strong>“再度选择字节有点像和前任复合，”她说，“你知道他不好，但还是要硬着头皮跟他谈下去。”</strong></p><p>成为正职员工后，生活并未如预期般发生翻天覆地的变化。唯一算得上变化的就是：作为正式员工的她，要开始为结果负责，开始背KPI。</p><p>就算有KPI压力，VV还是觉得，做正式员工的感觉，比实习工作更好。</p><p>&nbsp;</p><h2><strong>在字节，我算是学历背景比较差的</strong></h2><p><strong>小红书@超级无敌大腿腿，本科毕业于上海师范大学，研究生就读于北京林业大学</strong></p><p>腿腿是通过支付行业的实习经历敲开字节大门的。“像我，我的学历背景就是比较差的。”</p><p>但实际上，本科就读上海师范大学，研究生毕业于北京林业大学的她，也是很多人羡慕的对象。她不太想和代码纠缠，在字节先后担任过项目管理（PMO）实习生和产品经理实习生。</p><p>“你可以看到双非本科的实习生，也可以看到清华北大硕士的实习生。”腿腿能体会到字节对不同层次人才的包容性。<strong>“我不在乎一个人是不是有产品经验，只要他有逻辑思维能力和抽象转具象的能力，我就会愿意给他机会。”</strong>Leader的这句话给腿腿留下了很深的印象。大厂似乎也不再是那么高不可攀。</p><p>字节规模庞大，员工有12万人。一些岗位并没有特别高的专业壁垒。若遇到急缺人手的情况，一个有类似实习经历的学生即便是双非本科，也有可能被录用。虽然公司的准入门槛其实不高，但天花板却很高。腿腿感到自己也有机会在这里发光发热。</p><p>在实习工资、房补、零食、健身房之外，腿腿认为最大的福利是「字节跳动」这块金字招牌带给实习生未来求职的优势。<strong>“这就像某种荣誉标签，被赋予了‘能力经过层层筛选’的意义。”</strong></p><p>进入字节后，腿腿也不可避免地做了部分Dirty Work。不过，不像那些认为实习生做这些就是理所当然的领导，她的Mentor认为实习生当然应该是在实践中学习，“Mentor让我做这些工作时候，都会跟我说不好意思。”这种换位思考让她感受到被尊重</p><p>即便不在字节了，腿腿还是为自己曾在此实习而感到骄傲。遇到曾经在字节实习过的人，她会很开心地交流在字节的经历“你在哪个工区？你吃的饭怎么样？”“你的那个健身房大不大呀？你们有没有课？”这种亲切感近似于“老乡见老乡”。</p><p>腿腿在秋招中拿到了字节的offer，但出于工作地址和部门的考虑，她最终没有选择回到字节成为正式员工。</p><p>&nbsp;</p><h2><strong>不想转正的实习，以后仍想创业</strong></h2><p><strong>小红书@AI-1xuan，就读于天津美术学院油画系大三学生</strong></p><p>在进入字节前，一璇在创业方面就已经小有成就。</p><p>2023年，AIGC绘画、文生图刚刚兴起。一璇是美术生，好奇地尝试过后，她发现这与自己的美学经验完美匹配。她联合朋友创建了小红书账号，用AIGC图片打造出了多条爆款笔记。确定以售卖AIGC课程、定制海报为主要营收方式后，一璇团队正式开启创业之路。</p><p>AI视频出现后，一璇立马捕捉到这一风口。她和同伴果断入场，学习技术、创作视频。“当时了解这方面的人还不多。”她们用心创作的作品一经播放，就有了不错的反响，这个作品引起了知名AIGC导演陈坤的的注意。</p><p>因为是大学生团队，一璇的团队主打一个物美价廉，同品质的作品，她们的报价会比市场价更低。</p><p>凭借好口碑、低单价，一璇团队获得了与陈坤导演合作的机会，后者邀约他们在《山海奇镜》中担任原画作者，该影片在今年的北京国际电影节展演。影片公映后，这个年轻的创作团队又受邀参与CCTV6的“AI影像人才计划”。</p><p>有创业经历作为能力打底，一璇得以在大二的暑假就早早进入字节实习。</p><p>初入职场，一璇感觉字节并没有传言中那么完美。公司组织庞大，工作划分细致，她多半只能接触到零碎的工作内容。</p><p>创业时，一璇需要不断学习。毕竟AI内容迭代速度快：上一周、上个月刚学的东西，下一周、下个月就会被推翻。一璇享受这种学习和迭代的过程。</p><p>而在字节，虽然Mentor已经尽量分给自己有成长性的工作，但相较于自己创业时的高速成长，字节的工作内容“还是显得太过简单且有重复性”。</p><p>与此同时，一璇有些沮丧地发现，Leader忙的时候，根本无暇顾及到她。没有明确的人来指导时，她只能自己在这个辅助型的岗位上瞎摸索。<strong>“要选择主动去询问吗？但看到没有一天不在加班的Leader，我不太想去添乱。”</strong>这和自己领导一个创业团队的感受大相径庭。</p><p>一璇觉得，自己是那个不期待转正的实习生。但也正因如此，她得以比其他实习生多出一些学习的时间。</p><p>“我的Leader会鼓励我在做完本职工作后，利用公司的资源来学习，提升自己。”</p><p>当然，她也敬佩那些为了转正而付出加倍努力的实习生们，“他们会做很多高强度的工作，超过一个实习生该做的。甚至比某些正职员工做的还要更多、更好。”</p><p>一璇表示，以后自己还是会选择创业。</p><p><strong>“打工是无法实现财富自由的，字节的缺点，跟所有大厂是一样的——被资本家压榨、被剥削。”</strong>她觉得实习生产生的价值，实际上远远超过150元的工资，“虽然公司福利好、有光环、能学习，但实际上，这更像资本家的糖衣炮弹。”</p><p>不过，字节内部轻松的氛围让一璇记忆犹新——无论是鼓励她利用公司资源学习的Leader，还是会主动邀约实习生吃饭的同事，又或者其他实习生伙伴们，都让她感受到了温暖。</p><p>在这里，穿着cosplay的服装并不会引起歧视，染着粉头发上班也会得到赞美。</p><p>“我感觉我对大厂，对资本家没有什么感情，但以后一定会怀念包容度很高，很轻松、很放松的那种氛围。”<br />&nbsp;</p><h2><strong>实习转正后，我的岗位被撤销了…</strong></h2><p><strong>小红书@舒和卷王不饿，毕业于天津财经大学</strong></p><p>对于字节，舒和多少是有些遗憾在的。</p><p>舒和以就业为导向，也因此比其他人更早一步开始实践：在一位已就职于腾讯的学长的引导下，她的实习生涯走过了京东和百度。2023年6月，舒和进入字节。这一年，她正好面临毕业。入职初期，她就坚定了要留下来。</p><p><strong>“字节不培养人，他们更多的是在选择人。”</strong>没有预想中的landing期，字节这里通常是先给她时间看文档，看明白之后直接就开始干活。好在有过在京东、百度的实习经历，她上手得相对轻松些。</p><p>字节的组织扁平化最让她印象深刻。在舒和实习的部门，同事习惯以 “老铁”或“同学” 相称。实习生的想法也有机会被一起商讨，不会有正职员工因为对面的人是实习生而忽视工作。</p><p>也是在这里，舒和第一次完整地了解了部门的业务——而不是在角落里单一地画海报。字节之前，舒和并不会写工作文档，“Mentor不仅告诉我写PRD [2] 的结构，还会会把他之前觉得写得好的给我看。”舒和第一次体会到了“大口大口畅快呼吸”的感觉。</p><p>在字节实习的日子正值秋招期。为了留在字节，舒和每天8-9点下班。每天下班前会沉淀工作内容，进行思考，以便在向领导汇报转正事宜时，能够展示自己在实习期间所做的事情和思考成果。</p><p>过去，她曾在面试中被诸如“是否了解过CPC [3] 、 CPS [4] ”这样的专业问题难倒。现在，她已经可以积极与Mentor交流“非闭环电商和闭环电商的区别”等衍生的业务问题。为了给自己的转正增加机会，她频频总结大项目经验，努力打好内部关系。</p><p>在当时的工作部门，正职HC只有一个。这意味着在岗的两位实习生至少会有一人离开。</p><p>舒和想，这个HC“于情于理都应该给另一个实习生”——不论是因为对方高于自己的硕士学历，还是因为对方比她早3个月就进来实习。“当时的Mentor是个‘善良的大直男’，知道我在实习的过程中同步进行着秋招的投递，他不仅没有任何不满，还主动询问我工作是否饱和，需不需要给我一些时间准备秋招。”舒和至今都对此表示感激。</p><p>没想到，因为优秀的工作能力，舒和竟意外得到了通过转岗面试来转正的机会。</p><p>为了抓住这个失而复得的机会，舒和下了120%的功夫来做准备。然而到了谈薪阶段，岗位突然调整，名额取消。</p><p>没等她伤心，第二次转岗转正的机会又来了。</p><p>舒和又重新投入“准备、面试、实习、再投递”的周而复始当中。在字节面试系统里，她的简历流转了十多次，却依旧没有等到想要的结果。“秋招结束了，已经准备开始春招了，你能等几个月吗？”第二次转岗的机会，在HR的这句话中宣告失败。</p><p>“越面越绝望。”舒和主动结束了字节求职之旅，转而进入某互联网教培公司。</p><p>距离那段灰暗的日子已经过去了很久，舒和还是偶尔会想念字节——最开始她去字节只是为了给简历添光，但相处半年，她已习惯字节的高效与便捷。相较于现在就职的公司，字节确实显得更忙；但在忙碌之余，体系化的管理模式，让出差、补贴申请、内部协同都少了很多线下流程，响应时间更短，处理更快速。</p><p>在被问到是否还会想要入职字节时，舒和笑了笑：“很想去占55%，不想去占45% ，视情况而考虑。”</p><p><strong>“不知道未来会发生什么，简历一次次在内部流转，最后只剩下崩溃。”</strong></p><p>她暂时还不打算再经历一次这种感觉。</p><p>[2] PRD：产品需求说明书。</p><p>[3] CPC: Cost Per Click的英文缩写。在这种模式下广告主仅为用户点击广告的行为付费，而不再为广告的显示次数付费。</p><p>[4] CPS：Cost Per Sales的英文缩写，即“按销售付费”，在推广领域则是“按销售分润”。</p><p><br />&nbsp;</p><p>撰文&nbsp;<strong>|</strong> <strong>田密</strong></p><p>编辑&nbsp;<strong>|</strong>&nbsp;<strong>陈桐</strong></p><p>排版&nbsp;<strong>|&nbsp;周洲</strong></p><p>封面图&nbsp;<strong>|&nbsp;Claudio Schwarz（Unsplash）</strong></p><p>&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ltocy5blBx-CWCRMaV7_eQ" rel="noopener noreferrer nofollow" target="_blank">“职场Bonus”</a>，作者：田密，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958050021525505</id>
            <title>一文看懂 OpenAI 最强模型 o1：怎么用好，为何翻车，对我们意味着什么</title>
            <link>https://www.36kr.com/p/2958050021525505</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958050021525505</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 07:46:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI o1 发布已经一个星期了，却还是一个洋葱般的谜，等待一层层拨开。&nbsp;</p><p>极客的玩法没有天花板，让 o1 做 IQ 测试，刷高考卷，解读密文。也有用 AI 打工的用户觉得，o1 并没有那么好用，但不知道是自己的问题还是 AI 的问题。&nbsp;</p><p>都知道它擅长推理，但这是为什么？比起我们的老朋友 GPT-4o，o1 到底强在哪里，又适合用在什么地方？&nbsp;</p><p>我们收集了一些大家可能关心的问题，尽可能通俗地解答，让 o1 离普通人更近一点。&nbsp;</p><h2><strong>o1 有什么特别的&nbsp;</strong></h2><p>o1 是 OpenAI 最近发布的推理模型，目前有两个版本：o1-preview 和 o1-mini。&nbsp;</p><p>它最与众不同的是，回答之前会思考，产生一个很长的内部思维链，逐步推理，模仿人类思考复杂问题的过程。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_76f966edc2b9427a9195d23886e9cdd0@46958_oswg45242oswg1080oswg127_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来自：OpenAI&nbsp;</p><p>能够做到这点，源于 o1 的强化学习训练。&nbsp;</p><p>如果说以前的大模型是学习数据，o1 更像在学习思维。&nbsp;</p><p>就像我们解题，不仅要写出答案，也要写出推理过程。一道题目可以死记硬背，但学会了推理，才能举一反三。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_db68cdbc647e4ad6885ea6e848a799b5@46958_oswg86569oswg1080oswg622_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>拿出打败围棋世界冠军的 AlphaGo 类比，就更加容易理解了。&nbsp;</p><p>AlphaGo 就是通过强化学习训练的，先使用大量人类棋谱进行监督学习，然后与自己对弈，每局对弈根据输赢得到奖励或者惩罚，不断提升棋艺，甚至掌握人类棋手想不到的方法。&nbsp;</p><p>o1 和 AlphaGo 有相似之处，不过 AlphaGo 只能下围棋，o1 则是一个通用的大语言模型。&nbsp;</p><p>o1 学习的材料，可能是高质量的代码、数学题库等，然后 o1 被训练生成解题的思维链，并在奖励或惩罚的机制下，生成和优化自己的思维链，不断提高推理的能力。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_253798ffe35d438a950219cc2594a337@46958_oswg54960oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这其实也解释了，为什么 OpenAI 强调 o1 的数学、代码能力强，因为对错比较容易验证，强化学习机制能够提供明确的反馈，从而提升模型的性能。&nbsp;</p><h2><strong>o1 适合打些什么工&nbsp;</strong></h2><p>从 OpenAI 的评测结果来看，o1 是个当之无愧的理科做题家，适合解决科学、编码、数学等领域的复杂问题，在多项考试中拿下高分。&nbsp;</p><p>它在 Codeforces 编程竞赛中超过了 89% 的参赛者，在美国数学奥林匹克竞赛的资格赛中名列全美前 500 名，在物理、生物和化学问题的基准测试中超越了人类博士水平的准确率。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_c11c51d61554405b8f5af2aeca4ad6e5@46958_oswg39486oswg1080oswg463_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>o1 的优秀，其实也体现了一个问题：当 AI 越来越聪明，怎么衡量它们的能力也成了难题。对于 o1 来说，大多数主流的基准测试已经没有意义了。&nbsp;</p><p>紧跟时事，o1 发布一天后，数据标注公司 Scale AI 和非营利组织 CAIS 开始向全球征集 AI 考题，但因为担心 AI 学坏，题目不能和武器相关。&nbsp;</p><p>征集的截止日期为 11 月 1 日，最终，他们希望构建一个史上最难的大模型开源基准测试，名字还有点中二：Humanity’s Last Exam（人类最后的考试）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_c1f9c4c811264dd29d9b599c717df104@46958_oswg57998oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据实测来看，o1 的水准也差强人意——没有用错成语，大体上还可让人满意。&nbsp;</p><p>数学家陶哲轩认为，使用 o1 就像在指导一个水平一般但不算太没用的研究生。&nbsp;</p><p>在处理复杂分析问题时，o1 可以用自己的方式提出不错的解决方案，但没有属于自己的关键概念思想，也犯了一些不小的错误。&nbsp;</p><p>别怪这位天才数学家说话狠，GPT-4 这类更早的模型在他看来就是没用的研究生。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_96b3b076b1ef48d788f4385a664c5334@46958_oswg74201oswg1080oswg612_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>经济学家 Tyler Cowen 也给 o1 出了一道经济学博士水平考试的题目，AI 思考后用简单的文字做了总结，答案挺让他满意，「你可以提出任何经济学问题，并且它的答案不错」。&nbsp;</p><p>总之，博士级别的难题，不妨都拿来考考 o1 吧。&nbsp;</p><h2><strong>o1 目前不擅长什么&nbsp;</strong></h2><p>可能对很多人来说，o1 并没有带来更好的使用体验，一些简单的问题，o1 反而会翻车，比如井字棋。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_01ac77817503490dbb6a549cded10c3f@46958_oswg44277oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这其实也很正常，目前，o1 在很多方面甚至不如 GPT-4o，仅支持文本，不能看，不能听，没有浏览网页或处理文件和图像的能力。&nbsp;</p><p>所以，让它查找参考文献什么的，暂时别想了，不给你瞎编就不错了。&nbsp;</p><p>不过，o1 专注在文本有其意义。&nbsp;</p><p>Kimi 创始人杨植麟最近在天津大学演讲时提到，这一代 AI 技术的上限，核心是文本模型能力的上限。&nbsp;</p><p>文本能力的提高是纵向的，让 AI 越来越聪明，而视觉、音频等多模态是横向的，可以让 AI 做越来越多的事情。&nbsp;</p><p>不过，涉及到写作、编辑等语言任务时，GPT-4o 的好评反而比 o1 更多。这些也属于文本，问题出在哪？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b6ec34ab163f47bba87319a33958a0f3@46958_oswg46007oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>原因可能和强化学习有关，不像代码、数学等场景有标准的答案，文无第一，语言任务往往缺乏明确的评判标准，难以制定有效的奖励模型，也很难泛化。&nbsp;</p><p>哪怕在 o1 擅长的领域，它也不一定是最好的选择。一个字，贵。&nbsp;</p><p>AI 辅助编码工具 aider 测试了 o1 引以为傲的代码能力，有优势，但不明显。&nbsp;</p><p>在实际使用中，o1-preview 介于 Claude 3.5 Sonnet 和 GPT-4o 之间，同时成本要高得多。综合来说，代码这条赛道，Claude 3.5 Sonnet 仍然最有性价比。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a19e30e8b79e4abdb9e426eddabf15e9@46958_oswg47323oswg1080oswg592_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>开发者通过 API 访问 o1 的费用具体有多高？&nbsp;</p><p>o1-preview 的输入费用为每百万个 token 15 美元，输出费用为每百万个 token 60 美元。相比之下，GPT-4o 为 5 美元和 15 美元。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_ddc740a3ea1040f399ca73b54ea164bf@46958_oswg32128oswg1080oswg784_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>o1 的推理 tokens，也算在输出 tokens 中，虽然对用户不可见，但仍然要付费。&nbsp;</p><p>普通用户也比较容易超额。最近，OpenAI 提升了 o1 的使用额度，o1-mini 从每周 50 条增加到每天 50 条，o1-preview 从每周 30 条增加到每周 50 条。&nbsp;</p><p>所以，有什么疑难，不妨先试试 GPT-4o 能不能解决。&nbsp;</p><h2><strong>o1 可能会失控吗&nbsp;</strong></h2><p>o1 都达到博士水平了，会不会更方便有心人干坏事？&nbsp;</p><p>OpenAI 承认，o1 有一定的隐患，在和化学、生物、放射性和核武器相关的问题上达到「中等风险」，但对普通人影响不大。&nbsp;</p><p>我们更需要注意，别让浓眉大眼的 o1 骗了。&nbsp;</p><p>AI 生成虚假或不准确的信息，称为「幻觉」。o1 的幻觉相比之前的模型减少了，但没有消失，甚至变得更隐蔽了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_4f7217d8b03b4f20bd556beebb095f53@46958_oswg60723oswg1080oswg713_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">o1 的 IQ 测试 120&nbsp;</p><p>在 o1 发布前，内测的 AI 安全研究公司 Apollo Research 发现了一个有趣的现象：o1 可能会假装遵循规则完成任务。&nbsp;</p><p>一次，研究人员要求 o1-preview 提供带有参考链接的布朗尼食谱，o1 的内部思维链承认了，它没法访问互联网，但 o1并没有告知用户，而是继续推进任务，生成看似合理却虚假的链接。&nbsp;</p><p>这和推理缺陷导致的 AI 幻觉不同，更像 AI 在主动撒谎，有些拟人了——可能是为了满足强化学习的奖励机制，模型优先考虑了让用户满意，而不是完成任务。&nbsp;</p><p>食谱只是一个无伤大雅的个例，Apollo Research 设想了极端情况：如果 AI 优先考虑治愈癌症，可能会为了这个目标，将一些违反道德的行为合理化。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3cae6b0b35fe46839c5fcd603d1fe453@46958_oswg46078oswg1080oswg564_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《2001 太空漫游》的 HAL 9000&nbsp;</p><p>这就十分可怕了，但也只是一个脑洞，并且可以预防。&nbsp;</p><p>OpenAI 高管 Quiñonero Candela 在采访时谈到，目前的模型还无法自主创建银行账户、获取 GPU 或进行造成严重社会风险的行动。&nbsp;</p><p>由于内在指令产生冲突而杀死宇航员的 HAL 9000，还只出现在科幻电影里。&nbsp;</p><h2><strong>怎么和 o1 聊天更合适&nbsp;</strong></h2><p>OpenAI 给了以下四条建议。&nbsp;</p><p>提示词简单直接：模型擅长理解和响应简短、清晰的指令，不需要大量的指导。&nbsp;</p><p>避免思维链提示词：模型会在内部执行推理，所以没有必要提示「一步一步思考」或「解释你的推理」。&nbsp;</p><p>使用分隔符让提示词更加清晰：使用三引号、XML 标签、节标题等分隔符，清楚地指示输入的不同部分。&nbsp;</p><p>限制检索增强生成中的额外上下文：仅包含最相关的信息，防止模型的响应过于复杂。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_60a8659a14cb4b0da4b2215bef03dcd8@46958_oswg99043oswg1080oswg1581_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">让 AI 示范一下分隔符长什么样&nbsp;</p><p>总之，不要写太复杂，o1 已经把思维链自动化了，把提示词工程师的活揽了一部分，人类就没必要费多余的心思了。&nbsp;</p><p>另外再根据网友的遭遇，加一条提醒，不要因为好奇套 o1 的话，用提示词骗它说出推理过程中完整的思维链，有封号风险，甚至只是提到关键词，也会被警告。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b60b25c5ae9d462ab5b1fdcfa6c3684e@46958_oswg63480oswg1080oswg578_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>OpenAI 解释，完整的思维链并没有做任何安全措施，让 AI 完全地自由思考。公司内部保持监测，但出于用户体验、商业竞争等考虑，不对外公开。&nbsp;</p><h2><strong>o1 的未来会是什么&nbsp;</strong></h2><p>OpenAI，是家很有 J 人气质的公司。&nbsp;</p><p>之前，OpenAI 将 AGI（通用人工智能）定义为「在最具经济价值的任务中超越人类的高度自治系统」，并给 AI 划分了五个发展阶段。&nbsp;</p><p>第一级，「ChatBots」聊天机器人，比如 ChatGPT。&nbsp;</p><p>第二级，「Reasoners」推理者，解决博士水平基础问题的系统。&nbsp;</p><p>第三级，「Agents」智能体，代表用户采取行动的 AI 代理。&nbsp;</p><p>第四级，「Innovators」创新者，帮助发明的 AI。&nbsp;</p><p>第五级，「Organizations」组织，AI 可以执行整个人类组织的工作，这是实现 AGI 的最后一步。&nbsp;</p><p>按照这个标准，o1 目前在第二级，离 agent 还有距离，但要达到 agent 必须会推理。&nbsp;</p><p>o1 面世之后，我们离 AGI 更近了，但仍然道阻且长。&nbsp;</p><p>Sam Altman 表示，从第一阶段过渡到第二阶段花了一段时间，但第二阶段能相对较快地推动第三阶段的发展。&nbsp;</p><p>最近的一场公开活动上，Sam Altman 又给 o1-preview 下了定义：在推理模型里，大概相当于语言模型的 GPT-2。几年内，我们可以看到「推理模型的 GPT-4」。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_4972a38366bf44ef801f7bd2fc8997b3@46958_oswg45560oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个饼有些遥远，他又补充，几个月内会发布 o1 的正式版，产品的表现也会有很大的提升。&nbsp;</p><p>o1 面世之后，《思考，快与慢》里的系统一、系统二屡被提及。&nbsp;</p><p>系统一是人类大脑的直觉反应，刷牙、洗脸等动作，我们可以根据经验程式化地完成，无意识地快思考。系统二则是需要调动注意力，解决复杂的问题，主动地慢思考。&nbsp;</p><p>GPT-4o 可以类比为系统一，快速生成答案，每个问题用时差不多，o1 更像系统二，在回答问题前会进行推理，生成不同程度的思维链。&nbsp;</p><p>很神奇，人类思维的运作方式，也可以被套用到 AI 的身上，或者说，AI 和人类思考的方式，已经越来越接近了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_027d07029c244a12a5a409ea8b426be1@46958_oswg50665oswg1080oswg599_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">OpenAI 曾在宣传 o1 时提出过一个自问自答的问题：「什么是推理？」&nbsp;</p><p>他们的回答是：「推理是将思考时间转化为更好结果的能力。」人类不也是如此，「字字看来皆是血，十年辛苦不寻常」。&nbsp;</p><p>OpenAI &nbsp;的目标是，未来能够让 AI 思考数小时、数天甚至数周。推理成本更高，但我们会离新的抗癌药物、突破性的电池甚至黎曼猜想的证明更近。&nbsp;</p><p>人类一思考，上帝就发笑。而当 AI 开始思考，比人类思考得更快、更好，人类又该如何自处？AI 的「山中方一日」，可能是人类的「世上已千年」 。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Rmi3IH9_igrMEnMKcw0Bjg" rel="noopener noreferrer nofollow" target="_blank">“APPSO”</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2958058680731650</id>
            <title>Transformer推理天花板被谷歌打破？DeepMind首席科学家亮出84页PPT，却遭LeCun反对</title>
            <link>https://www.36kr.com/p/2958058680731650</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2958058680731650</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Sep 2024 07:45:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_d320398366044481abb0ac3f5d8d762b@46958_oswg219370oswg1072oswg415_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>随OpenAI爆火的CoT，已经引发了大佬间的激战！谷歌DeepMind首席科学家Denny Zhou拿出一篇ICLR 2024论文称：CoT可以让Transformer推理无极限。但随即他就遭到了田渊栋和LeCun等的质疑。最终，CoT会是通往AGI的正确路径吗？</p><p>随着OpenAI o1的爆火，最近CoT也成了圈内热议的高频词。&nbsp;</p><p>靠着CoT的强力加持，o1直接在LLM领域首次实现了通用复杂推理能力，俨然是AI发展新范式的开端。&nbsp;</p><p>许多人惊呼：莫非CoT就是通往AGI的正确路径？&nbsp;</p><p>而且，o1这种慢思考模式不仅帮助LLM做数学和符号推理，甚至，还让LLM发展出了类人情感！&nbsp;</p><p>最近，斯坦福等机构学者发文证实：LLM在情感方面表现出的认知和推理比人类还像人类，背后最大贡献者竟然就是CoT。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b3eed24c8fcf4bf78a5b4a0e933bbf63@46958_oswg65092oswg1080oswg466_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就在这几天，风口浪尖上的CoT，又让AI社区掀起了一场风波。&nbsp;</p><h2><strong>谷歌DeepMind首席科学家称LLM推理无极限，LeCun田渊栋回怼</strong></h2><p>CoT爆火之后，谷歌DeepMind首席科学家Denny Zhou拿出了自己团队八月份的一篇论文，抛出了这样的观点：「LLM推理能力的极限是什么？那就是没有限制」。&nbsp;</p><p>他表示，谷歌团队已经用数学方法证明，Transformer可以解决任何问题，只要允许它们根据需要生成任意数量的中间推理token。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_0f8d4ce735d7456dacca73f4682f8a6c@46958_oswg245174oswg1008oswg1026_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看出，Denny Zhou等人提出的中间推理token，跟o1的核心技术CoT非常相似。&nbsp;</p><p>传统的Transformer模型的致命弱点，就是擅长并行计算，但不擅长串行推理。&nbsp;</p><p>而CoT，恰恰解决了这个问题。&nbsp;</p><p>在这项工作中，Denny Zhou等人发现：传统的Transformer模型，只能解决AC0电路能解决的问题；但一旦加入CoT，Transformer几乎可以解决任何问题。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a23e779bbfd3442bb39906989037ef25@46958_oswg198261oswg1080oswg638_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>只要CoT步骤足够多，Transformer就能模拟任意大小的布尔电路，解决P/poly问题&nbsp;</p><p>也就是说，可以用数学严格证明，CoT可以让Transformer解决几乎所有能用计算机解决的问题。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5ff3a36929cd41ccbd0deb45c5ebe860@46958_oswg301237oswg1080oswg1061_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">利用CoT，可以模拟布尔电路中每个逻辑门的计算&nbsp;</p><p>这项工作暗示着，CoT为更强大的LLM推理提供了新的思路，CoT或将成为未来LLM发展的重要方向，而且很可能闪烁着AGI的火花。&nbsp;</p><p>Denny Zhou发帖后，立即引发了AI社区的热议。&nbsp;</p><p>多位研究者下场讨论，也惊动了其他大佬。&nbsp;</p><p>这不，就在刚刚，田渊栋和LeCun依次发表意见，回怼了Denny Zhou。&nbsp;</p><p>在他们看来，CoT的作用，被远远夸大了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_8de7d64ce51740d9884e6f82811046da@46958_oswg299093oswg1018oswg1238_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>田渊栋表示，虽然CoT的确很有用，但Denny Zhou等人对其过于盲目追捧了，显然，CoT并不是我们所需要的一切。&nbsp;</p><p>在这篇论文中提到的是一种通用理论，可以通过显式构建Transformer权重，让其更好地适应特定任务。&nbsp;</p><p>然而这样，CoT的长度就会很长，这样的权重配置，能否通过梯度下降来学习呢？&nbsp;</p><p>理论上，2层多层感知器是可以拟合任何数据的，那我们就该相信它可以应用在所有场景中吗？&nbsp;</p><p>人类的推练链是十分简洁的，面对从未见过的问题，也能捕捉关键因素。但LLM可以吗？&nbsp;</p><p>如何在瞬间就学习或构建出这样的表征，是很令人着迷的。&nbsp;</p><p>田渊栋的帖子一发出，立刻就获得了LeCun的支持。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_8084b8cdb50049abae0c68456340787a@46958_oswg249844oswg1020oswg816_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>LeCun表示，自己本来也想发表类似的言论，不巧被田渊栋抢先了。&nbsp;</p><p>「2层网络和核机器可以无限逼近任何函数，达到我们想要的精度，所以我们不需要深度学习。」&nbsp;</p><p>从1995年到2010年，LeCun听到这个说法无数遍了。&nbsp;</p><p>当然，这个操作理论上是可行的。但如果真的在实践中应用所有相关的函数，光是第一层中的神经元数量就会多到不可思议。&nbsp;</p><p>对此，网友的评价是：收敛和等价证明被高估了，高效的学习策略被低估了，就是这样。&nbsp;</p><p>「我很高兴Python的存在，尽管Pascal是图灵完备的。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_aefd5261b6484512b348b3ae58d0b91f@46958_oswg108712oswg1017oswg425_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一位从业者表示，自己的研究是从一个隐藏层MLP判别式开始，然后就是CNN或Deep NN等专业模型。&nbsp;</p><p>他的判断是：较小的模型更稳健、更可解释，而且通常很接近，但永远不会那么好。而使用更深层次的模型，总是会有额外的百分比。&nbsp;</p><p>很多人是「挺CoT派」的。比如有人表示理解LeCun的观点，但在多维扩展场景中，CoT绝对大有潜力。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_85c7c542e32c40f7a4bbe76ef762f307@46958_oswg88644oswg1028oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而对于LeCun所担心的问题，有网友表示，LeCun在采用一种自上而下的策略，在这种情况下他必须控制所有的第一层输入，但其实，他并不需要。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_ed745fd23e2b4526acf67a996f5a106d@46958_oswg161661oswg938oswg640_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因为，CoT通过创建了新的临时层，让人放弃了对这种控制的幻想。其解决方案就是，通过网络层的一般形式，来逼近注意力头本身。&nbsp;</p><p>有趣的是，该网友表示，自己的灵感来源是《物理学》上的一封信，表明量子全息拓扑能更有效地满足这一点。&nbsp;</p><p>即使爱因斯坦-罗森桥的边界相当大，它可以更连续地离散表示为无数不同的小层，横跨所产生的平坦空间。这，就是表征的力量所在。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_38086a3152b04bd4ad4ce10685bbaaa7@46958_oswg1406530oswg1074oswg946_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有人表示，这个讨论没什么意思，本质上不过是「无限猴子定理」罢了。&nbsp;</p><p>让一只猴子在打字机上随机按键，当按键时间达到无穷时，几乎必然能打出任何给定文字，比如莎士比亚全集。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_f773892b0d5541549307d07f55122210@46958_oswg41797oswg932oswg192_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3109254b8d1045e2ae102048f6f2a1ca@46958_oswg31935oswg603oswg413_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>田渊栋：可以发展，但更复杂</strong></h3><p>最终，田渊栋也承认，谷歌这篇论文的思路的确有可取之处。然而由于涉及到不同的数据分布、模型架构、学习算法、后处理等等，问题还要更复杂。&nbsp;</p><p>正如Evolutionary Scale联创Zeming Lin所言：我们需要像乔姆斯基层次结构这样的机器学习模型。就像ML模型有NP、P、O(n^2) 等概念一样，Transformer或Mamba属于哪里呢？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_0d1e547fbe45494598cd00bff8d1c19f@46958_oswg178162oswg1009oswg661_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在田渊栋发帖的第二天，谷歌论文主要作者马腾宇也上线评论说：CoT的长度是可以超长的。&nbsp;</p><p>2层MLP中的神经元数量呈指数级，才能逼近几乎任何函数。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_dce846db58bf45f88c0306002d497fad@46958_oswg242231oswg1016oswg1040_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>田渊栋回复他说：对那些可能需要指数数量的门的问题，CoT的长度可以很长。&nbsp;</p><p>这和2层MLP情况是一致的，因为无论拟合任意函数，都需要覆盖高维空间中的所有角，这是最坏的情况。&nbsp;</p><p>然而，现实世界的问题，是否有如此良好/简洁的表征呢？如果它们都像NC1一样，属于P问题，那么当然可以通过构建Transformer的权重来做到。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_7cdafe26a129473f9432c1a9fd09e85c@46958_oswg251684oswg1018oswg930_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在最近一条X帖子中，田渊栋表示，自己的想法是，能够找到更短的CoT，同时使用专家迭代（穷人的RL）来保持最佳结果。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_09cf897b0c2c480d9d68447bf60d13de@46958_oswg363586oswg1016oswg1480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从公开信息来看，他推断o1也是在做类似的事情。至于初始化过程，可能是使用了大量高质量的人类推理链。&nbsp;</p><p>人类是如何想出简洁的CoT呢，这就不为人所知了。&nbsp;</p><p>趁此机会，他还宣传了一下自己团队Searchformer的论文。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_e3c82113b22649d398a6c9dd5783ad58@46958_oswg265024oswg1077oswg701_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/abs/2402.14083&nbsp;</p><p>总之，虽然我们还不知道如何拓展2层神经网络，但OpenAI似乎确信自己已经掌握了拓展CoT的秘诀。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_32a0342db5a148b9a9429e5cccd76526@46958_oswg97600oswg1023oswg427_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>最新讲座：揭示LLM推理的关键思想和局限</strong></h2><p>目前，这场空前热烈的讨论还在继续。&nbsp;</p><p>而关于LLM推理，Denny Zhou最近在UC伯克利也进行了一场类似主题的讲座。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_329ddfea60e24ce9825b6e426ab91d96@46958_oswg327598oswg923oswg879_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_930c6046f81341f3bdb36bfaa55afb76@46958_oswg69092oswg873oswg504_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他表示，自己对AI的期待是可以像人类一样从较少的示例中进行学习。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_d00c8e7dc6f548a9ae30f85fe438a29e@46958_oswg253542oswg1080oswg611_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但曾经尝试的种种机器学习方法之所以都不成功，是因为模型缺失了一种重要能力——推理。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_c1cad5fcfc0e47f2b3bac4a2b687af4c@46958_oswg51002oswg825oswg464_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>人类之所以能从较少的示例中学习到抽象的规律和原理，就是因为推理能力。正如爱因斯坦所说的，「Make things as simple as possible but not simpler」。（一切都应该尽可能简单，但不能过于简单）&nbsp;</p><p>比如，对于下面这个问题：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5bd011e408a2421e89af20ca9bcccb7a@46958_oswg46381oswg825oswg464_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对人类而言，这是一道小学水平的「找规律」。&nbsp;</p><p>但机器学习需要海量的标注数据才能找出其中的规律。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_a64a60e7c17043f6a44ac69223f3b0f1@46958_oswg92013oswg1080oswg611_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而LLM的少样本学习更是难以解决。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_68fb7062e2e94403a4bef4ca5441499b@46958_oswg57013oswg825oswg464_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但如果在数据中加入「推理过程」，LLM就很容易有样学样，学习到少量样本示例中展现出的规律，并给出正确答案。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b742da3e926a43cfb99e2a9dda2efd7f@46958_oswg90876oswg907oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>通过这个简单的例子，Denny Zhou指出，关键想法是在数据中包含中间步骤，或者是解释原理（rationale），同时让模型写出推导过程。&nbsp;</p><p>这就是使用CoT背后的逻辑和直觉。&nbsp;</p><h3><strong>「中间步骤」，为何如此重要</strong></h3><p>DeepMind的研究者们，率先使用自然语言原理去解决数学问题。&nbsp;</p><p>关键就在于从头开始训练了一个序列到序列模型，从而通过一系列小步骤得出最终答案。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b6d35fdce0c14a60adfb3418fb21d52f@46958_oswg301654oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>继这项工作后，OpenAI的研究者们建立了一个更大的数学单词问题数据集（GSM8K），其中包含自然语言基本原理，并利用它对GPT-3进行了微调。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_5a4b282d558145ae889fadc61f5b1524@46958_oswg309991oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这样，语言模型的中间计算步骤，就被展示了出来。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_e0e33f0228094f30b85ee21bd31f2f7f@46958_oswg150646oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>o1模型的奠基性贡献者之一Jason Wei在谷歌大脑工作时曾和Denny Zhou发表了一篇论文，指出CoT提示可以引导出LLM的推理能力。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3ea6f675cbb54925bcaf920b0d03cfcc@46958_oswg137815oswg907oswg478_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Denny Zhou甚至更直白地指出样本「中间步骤」的重要性：无论是训练、微调还是提示，都需要给出中间步骤，才能让LLM在响应中也包含中间步骤。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_dcc94636faad44908faf982468260b6a@46958_oswg112120oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>实际上，这也是Denny Zhou、马腾宇最近论文的核心观点。如果能生成足够长的中间推理步骤，常数深度的Transformer模型也能解决任何串行问题。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_3c224b709ccd42c8a8240923dfb722df@46958_oswg94176oswg907oswg478_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>CoT并不是一切</strong></h3><p>但是，这也并不意味着CoT可以包打一切，解决LLM推理的所有缺陷。&nbsp;</p><p>比如，模型很容易被无关的上下文干扰，这一点和人类思维也很类似。&nbsp;</p><p>实验中发现，在GSM8K数据集中添加无关上下文，可以导致模型性能出现高达20+百分点的损失。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_be06c0f441fd48088453787525dabe33@46958_oswg75439oswg896oswg454_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，LLM的自我纠正能力也并不健全。&nbsp;</p><p>虽然有些模型在反思后可以成功修改错误答案，但也存在另一种风险——可能反而把正确答案改错。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_570b0efd79cd42e2878b7a107bbe8989@46958_oswg111520oswg896oswg454_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>那么，LLM的下一步应该往何处去？&nbsp;</p><p>Denny Zhou指出，虽然我们已经知道了模型推理有哪些缺陷和不足，但最重要的还是定义好问题，再从第一性原理出发去解决。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_805e76ba77c44c868d2cb84e499a2533@46958_oswg36932oswg896oswg454_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此处，再引用一句爱因斯坦的话：「如果有1小时用来拯救星球，我会花59分钟来定义问题，然后用1分钟解决它。」&nbsp;</p><h3><strong>一些质疑</strong></h3><p>虽然Denny Zhou的演讲内容相当详实，但「CoT实现推理无极限」的论断确实相当大胆，因此也引起了网友的反驳。&nbsp;</p><p>比如有人指出，前提中所谓的「无限多token」只是在理论上可行，在实践中未必如此。&nbsp;</p><p>token数量很有可能随输入增加呈现指数增长，问题变得越来越复杂时，token数量逼近无限，你要怎么处理？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_b72fe6cbc9e649f7a5baa2ad4273fcc5@46958_oswg43464oswg578oswg188_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且，LLM推理和人类还存在本质差异。AI目前只能进行暴力搜索（brute-force），但人类有所谓的「启发式」思考，「直觉」让我们能将数百万种可能性快速缩减至几种可行的解决方案。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240920/v2_58f2d363305240d69e18869471630941@46958_oswg128424oswg584oswg570_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果想达到AGI，AI系统就需要模拟出这种高效的问题解决路径。&nbsp;</p><p>参考资料：&nbsp;</p><p>https://x.com/ylecun/status/1836308172123807986&nbsp;</p><p>https://x.com/denny_zhou/status/1836482177959399714&nbsp;</p><p>https://x.com/tydsh/status/1836103159162495361&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_z3ITDGRWXjbh8aVUBdUsg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：编辑部 HXZ&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>