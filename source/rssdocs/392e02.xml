<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2956431122200454</id>
            <title>机器人“图灵时刻”何时到？四名创始人答曰：五年内见真章丨最前线</title>
            <link>https://www.36kr.com/p/2956431122200454</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956431122200454</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 14:31:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者丨邱晓芬</p><p>编辑丨苏建勋</p><p>在2024年的云栖大会上，作为AGI的一项重要支线，具身智能也成为了其中一大讨论焦点。</p><p>在“机器人的图灵时刻”论坛上，阿里特意邀请了四家当前炙手可热的人形机器人厂商——宇树科技、星动纪元、银河通用、逐迹动力，针对今年的机器人热潮的本质、发展历程、如何落地、技术难点等关键问题展开了讨论。</p><p>不过，不像AI的论坛那么针锋相对，四位创始人对于机器人赛道的判断基本一致，大家认为：</p><ol><li>本次机器人走向台前不是靠自我革命，而是靠大模型能力助推，具身智能将会是多模态大模型的killer APP；</li><li>通用机器人本质解决两件事：移动、操作；此次机器人行业变革两个关键词：泛化、从专用到通用；</li><li>机器人领域发展历程：从规则驱动、到算法驱动、再到数据驱动</li><li>对机器人落地的判断：5年，在某些特定场景（工业/零售等）会有大规模落地；10年，能进家庭；15年，产生大千万级别市场；</li><li>商业化落地的路径是： 先从<strong>单一场景+多任务+可移动做起；再做多场景+多任务，最后普及到全场景+全任务。</strong></li></ol><p>以下是星动纪元创始人陈建宇、银河通用创始人王鹤、宇树科技创始人王兴兴、逐迹动力创始人张巍的交流整理（略惊摘编）</p><p><strong>主持人：通用机器人一定要做成人形吗？</strong></p><p><strong>王兴兴：</strong> 好几年前有投资人问我，我们做不做人形机器人？我说我坚决地反对做人形机器人，我当时在大一，09年、10年的时候，我自己就做过小的人形机器人。做过好以后，我发现全球当前的人类技术其实没办法驾驭这么复杂的机器人系统。</p><p>但是2016年开始，新的AI技术诞生了，在差不多在22年的时候，整个的大语言模型的效果已经非常惊艳，整个AI技术发展是远超我自己预计的，所以我们在23年初正式开始做人形机器人，目前取得的效果也非常惊艳。</p><p>机器人整个发展节奏，无论是硬件和软件，都是超过我自己预计的节奏 。</p><p><strong>张巍：</strong>我觉得一定要做成人形，而且是有两条腿的人形机器人。</p><p>我简单说一下我对通用机器人的理解。我首先觉得机器人和AI的使命是不同的，AI是代替人来思考决策的，而机器人本质上要代替人来运动。</p><p>大家看到各式各样的机器人非常多，本质上就在做两件事情，一件事情是要移动（Mobility），空间中从 a 到 b；另一件事情是，操作。</p><p>所谓的通用机器人，在这两个能力上都能达到跟人一样的环境适应能力和任务的泛化性。值得一提的是，通用的移动能力其实是不太需要双臂的，但是通用的操作能力反而是需要双腿的，不然你可能都没法到人能到的地方去干活。</p><p><strong>我觉得 AGI 的发展最相比上一代最大的区别，就是从专用到通用的变化</strong>，在大模型出来之前，我感觉通用这个词是个贬义词，通用，就是证明它是没啥用。</p><p>但是大模型出来以后，大家发现，以前我们这种在专业领域里收集数据，去做专项任务的训练方式是有很大局限性的，反而我们要忽略专项的能力，要先构建通用的基础模型能力，再在上面长出专用的能力，这才是系统化解决泛化性的关键。&nbsp;</p><p>我觉得软件算法的通用性，就靠大模型技术；机器人跟物理世界交互的通用性，就靠人形机器人。&nbsp;</p><p><strong>主持人：您怎么定义人形机器人形态？</strong>&nbsp;</p><p><strong>王鹤：</strong>我们公司叫银河通用，我们从建立的第一天就是要达成通用机器人。当然通用有一个过程，<strong>他先做到单一场景、多任务、可移动，然后再做到多场景、多任务，最后做到全场景、全任务。</strong>在这个过程中，形态上在不同阶段也有它最适合、最经济、最稳定的载体。</p><p>通用机器人这个万亿市场刚刚开局的时候，我们选择了先从几个场景里头的多任务做起，比如零售商超场景上货下货，在工厂里去抱箱子，其实我们发现如果它是平地的话，轮子是够用的，也不能说我们没有腿，我们是把两只腿并在了一体。</p><p>那为什么要有双手呢？因为我们发现，比如说你在超市里头一只手拿篮子，一只手拿货，也是要两只手，所以我们的形态目前是360度轮，双腿并成一条腿，站直一米七三，够到二米四，蹲下来可以摸地，用最便宜的价格、最稳定的机器人技术率先实现可以落地的机器人。</p><p><strong>主持人：具身智能和人形机器人，大家讨论的时候，总是把两个词语放在一块，您怎么看？</strong></p><p><strong>陈建宇：</strong>这个确实是比较容易混淆的两个概念，但是他们的侧重点是不太相同的。</p><p>对具身智能来说，我们主要关注智能性和软件。具身智能其实对形态其实是要求不高的，可以是人形的、四足的、轮式的、单个机械臂的，甚至就是一个桌子、椅子，只要它能动，都可以给他赋予具身智能，是一个更广泛的概念。</p><p>人形机器人顾名思义一定是人形的。</p><p><strong>主持人：机器人现在有很多种类，怎么判断它的技术含量？</strong></p><p><strong>陈建宇：</strong>非常粗略的把人形机器人相关的技术分成三大块的话，其实就是大脑、小脑和本体。</p><p>我觉得这里面最关键的是小脑，它是最基础的部分，就如果你只有一个本体、大脑，缺了小脑的话，其实你只能成为一个会思考的一堆烂铁。</p><p>小脑是承接大脑思考、规划的，同时也是技术不确定性最高的，最没有收敛的。 但是我们是有蛮多的产业可以去借鉴，包括我们的工业机器人产业、电动车的产业。</p><p>对于小脑来说，我们发现大部分的机器人用的还是十几年前，甚至几十年前的扫地机这一类的技术去做。</p><p><strong>王鹤：</strong>我认为人形机器人的技术含金量可以从这两个地方总结：</p><p>一，他的泛化性到底有多强？是不是真正能通向未来的通用？</p><p>二，它能不能跟人之间用自然语言来沟通，然后实现零代码的部署？不仅能干活，还能交流。&nbsp;</p><p><strong>张巍：</strong>机器人就看两个关键词，<strong>一个叫泛化，一个叫通用</strong>，这是本次变革最关键的两个词。</p><p>我提供个我的角度，我觉得咱们先看腿，人形机器人之所以是一个新的物种，它不是一个传统机械臂公司的延续，它的本质就是要长出两条腿来。</p><p>那看腿也要看什么呢？主要看两点，一个就是腿，他能不能完成他本能的一些本职的工作，就是地形的泛化能力。第二点是看他能不能支撑双臂去完成全身协同的通用操作，这也是腿存在的一个重要的价值。&nbsp;</p><p><strong>主持人：机器人到底什么时候能干活？</strong></p><p><strong>陈建宇：</strong>如果说我们不是特别严苛的定义，就是说它能初步去用起来的话，那我认为不管是工业还是商用，甚至是家用，一两年的时间就能有，根据罗杰斯的那个创新扩散的模型，都有一些早期的一些使用</p><p>工业的场景会更快一些，因为它是有边界的，你可以人为的制定一些规则，所以在它的图灵时刻还没到来之前，机器人可能就能逐步应用起来。</p><p><strong>王鹤：</strong>以零售场景为例，现在的技术已经达到了产业化的边界了，我们预测就是从明年开始将会是商用的元年。</p><p><strong>5年，我们的目标是在这样的场景和车厂的抱箱子里头达到一万台；10年，是我认为安全性可以进入家庭标准的；15年，我预计可能会产生千万乃至大千万级别的市场。&nbsp;</strong></p><p><strong>王兴兴：</strong>我个人的话相对比较乐观，我觉得到明年，像一些工业场景，明年基本上该问题不大，我觉得三年左右至少全球范围内有通用型的 AI 出来，因为跟过去十年不一样了，现在整个机器人AI人才资金投入是巨量的，都是几百倍甚至上千倍的投入。五年应该会有天翻地覆的变化。&nbsp;</p><p><strong>张巍</strong>：我认为用时间去衡量它，是一个比较难的事情，我管这个赛道的产业的发展叫事件驱动，而不是时间驱动。它更关键的是看这个 AI 技术、关键的开关什么时候能找到，而不能用时间去具体的衡量它。</p><p>我也是相对乐观的。只不过我也说，我们要避免过早的去做商业化，比如说在大模型ChatGPT 2.0、3.0的时候你要做个超级应用，那肯定要打一堆补丁，因为上一代人工智能和机器人落地的过程中也遇到了很多这种挑战，大家都调侃说“人工智能等于智能不够靠人工”，所以是靠很多这个增加了部署的售后成本，最终商业逻辑还是挺难跑通的。&nbsp;</p><p><strong>主持人：大模型对人形机器人的发展，起到了什么样的影响？</strong></p><p><strong>张巍：</strong>我觉得机器人这一波的发展不是自我革命，发展是靠大模型技术和大模型技术背后的技术，我甚至认为具<strong>身智能将会是多模态大模型的一个killer APP</strong>。当然我把无人驾驶也算在我们具身智能赛道里边来了。</p><p>我觉得这几年由于受到大模型技术发展的一个启发，<strong>机器人领域的发展也经历了从规则驱动、到算法驱动、再到数据驱动的一个跳变啊。</strong></p><p>以前你可能看你有什么算法，然后根据算法的需求来收数据来解决问题。现在的思维变了，我们要首先看你有什么数据，然后你获取新数据的方式和成本是怎么样？数据的分布是什么样的？</p><p>这就直接的决定了你采用什么样的算法去训练，所以我们公司有个口号叫，<strong>软件定义硬件，但数据定义软件。</strong></p><p><strong>王兴兴：</strong>我一直感觉，通用人机器人算是大模型的最好的一个落地的载体，二者是非常好的一个组合关系</p><p><strong>王鹤：</strong>我觉得就是现在的通用机器人，几乎都是分立的小模型，所以大模型赋能技能有几步？</p><p>第一步是，大模型可以作为一个agent来调用这些 API ，进行长程的任务规划；</p><p>第二步是大模型可以作为一个monitor，看小模型执行过程中有没有出任何错误，及时的去终止、挽救这些错误，比如药盒子掉在地上了，他立马说你也给他捡起来；</p><p>第三步是最有想象力的，就是端到端的vision language action，把动作作为大模型输出的模态，像自动驾驶一样，做一个把通用感知、通用规划和通用执行融为一体的大模型。&nbsp;</p><p><strong>陈建宇：</strong>：我认为大模型这边带给我们最重要的启发就是，告诉我们有 scaling law的存在，启发我们去思考怎么样去做机器人的scaling law。</p><p>同时它也带着我们来一些语言模型领域的一些技术，比如说 Transformer的架构。算法层面、模型层面，还是数据层面，其实都有很多的不同，需要我们去探索。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_06276e627ac64b95978fa3b60c120336@1199336245_oswg137923oswg1080oswg600_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">end</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2957023987827717</id>
            <title>科技巨头的风云变幻：AI 泡沫、英特尔困境与英伟达逆袭 | 投向预言家</title>
            <link>https://www.36kr.com/p/2957023987827717</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2957023987827717</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 14:04:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近期，科技巨头们的命运各不相同，充满了戏剧性。AI领域，尽管OpenAI这样的明星公司吸引了无数目光，但大模型的同质化现象让业界担忧，杀手级应用迟迟未现，泡沫破裂的声音隐约可闻。</p><p>英特尔在AI赛道上落后于英伟达和AMD，甚至考虑出售部分资产以求自救。然而，就在市场情绪低迷之际，英伟达的CEO黄仁勋在高盛科技会议上的一番豪言壮语，仿佛一声春雷，不仅稳固了投资者的信心，还带动美股大盘逆转，重现生机。</p><p>另一边，苹果面临着华为等强劲对手的挑战，加上与中国市场的重要应用微信之间的“苹果税”纠纷，让苹果在中国的销量遭遇滑铁卢，这也促使巴菲特减持苹果股票。</p><p>不过，著名的“大空头”史蒂夫·艾斯曼却给出了不一样的看法，他认为尽管低端消费者正在经历困境，但当前的经济形势与2008年的危机截然不同，不必过于悲观。这些动态充分展示了科技行业在创新、竞争与市场波动中的起伏不定。</p><p>搜狐号财经联合36kr财经开启【AI的虚火与现实】活动已开启好内容自荐，<strong>本周我们议题为【科技股的趋势】</strong>，我们收到了很多优秀观点，让我们一起看看<strong>@首席商业评论、@江瀚视野、@港股解码、@华尔街见闻、@金十数据</strong>怎么看？更多精彩请点击#<a href="https://www.sohu.com/xtopic/TURBeE1UZ3pNalEx?spm=smpc.content.content.1.1726732877487x2pMlTP" rel="noopener noreferrer nofollow" target="_blank">降息疑云，巴菲特逃顶记</a>#</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_56ed4177cb3541b19f2670232b60db10@5579416_oswg151749oswg800oswg533_img_000?x-oss-process=image/format,jpg/interlace,1" /></p><p class="img-desc">投向预言家：AI虚火与现实</p><h2><strong>首席商业评论：AI跑马圈地时代已经过去</strong></h2><p>根据著名经济历史学家Carlota Perez总结的历史经验，随着AI基建投资的持续扩张，如果在未来一段时间（我们预估是12-18个月内）应用层仍然没有出现Killer App, 我们很可能会看到这轮AI热潮泡沫被刺破。Carlota Perez的话可能有些夸张，但大模型同质化的问题也导致Killer App难以出现。</p><p>OpenAI这家被称作“地球村AI希望”明星公司一再不及预期。传说中的GPT 5一直被推迟发布。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ae41f37dcbb7470196e19c63b58d42f5@5579416_oswg39935oswg749oswg423_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">投向预言家：AI虚火与现实</p><p><strong>氪星主编：</strong>当前Ai的问题是收入扩张追不上成本，从而导致盈利遥遥无期。</p><p><strong>狐选理由：</strong>无论风头多大，落地才是硬道理！</p><h2><strong>江瀚视野：英特尔被爆或将弃资产自救，落后的英特尔能有办法吗？</strong></h2><p>在AI这一新兴且极具潜力的市场上，英特尔的表现尤为乏力。虽然英特尔也推出了针对AI的处理器和加速器产品，但其在市场上的竞争力远不如英伟达和AMD。英伟达凭借其强大的GPU性能和CUDA生态，在AI训练和推理领域占据了绝对的领先地位。而AMD则通过其高性能的处理器和GPU产品，在AI应用中也表现出色。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_0ae1f3762a08479bb49d070d2032f653@5579416_oswg41580oswg700oswg446_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">投向预言家：AI虚火与现实</p><p><strong>氪星主编：</strong>每轮技术浪潮中都有时代的领头羊，显然Ai时代微软已经掉队。</p><p><strong>狐选理由：</strong>领先的技术才是硬道理，单纯玩资本让人不免感觉其黔驴技穷。</p><h2><strong>港股解码：</strong><a href="https://www.sohu.com/a/807809521_522913?spm=smpc.content.content.2.1726754289670N3nPHFY" rel="noopener noreferrer nofollow" target="_blank"><strong>苹果硬撼三叠屏，巴菲特卖对了吗？</strong></a></h2><p>巴菲特最近频频有卖出操作，今年已大幅减持第一大持仓股苹果。面对竞争对手的步步紧逼，各国反垄断和反“苹果税”的步步为营，苹果当前的境况如履薄冰，一旦产品或策略出了差错，很可能万劫不复。如此看来，巴菲特的减持未必不是明智之举。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_8bd8a923704f42e496e5356a5249f5c0@5579416_oswg25677oswg494oswg359_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">投向预言家：AI虚火与现实</p><p><strong>氪星主编：</strong>行业下行背景下，巨头也不能独善其身。</p><p><strong>狐选理由：</strong>苹果的对手越来越强，苹果税也不是万能盈利神器，请修炼内功。</p><h2><strong>华尔街见闻：又一次，英伟达和黄仁勋成为美股的“大救星”</strong></h2><p>黄仁勋的最新讲话“解答投资者心中的大问题”，他对“需求之大”的强调、甚至是不乏炫耀性的夸张描述，恰好是推动英伟达和美股指数大反转的关键。黄仁勋还告知听众，生成式人工智能仍处于起步阶段，它将扩展到数据中心以外的更多领域，点燃对未来增长的想象空间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a6ef84cebd5a44aebb2d31af7d772cce@5579416_oswg31594oswg549oswg308_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">投向预言家：AI虚火与现实</p><p><strong>氪星主编：</strong>市场泡沫在一个又一个乐观预期下不断膨胀。</p><p><strong>狐选理由：</strong>这么快就忘记了黄仁勋的“抛售”？</p><h2><strong>金十数据：</strong><a href="https://www.sohu.com/a/808333628_334198?scm=10001.325_13-109000.0.10140.5_32&amp;spm=smpc.channel_248.block3_308_NDdFbm_1_fd.1.17261322508304cM50lZ_324" rel="noopener noreferrer nofollow" target="_blank"><strong>投资者可以放心了？“大空头”现在并不担心美国经济</strong></a></h2><p>在金融危机前做空抵押债务证券而闻名的艾斯曼并不担心美国经济，并认为现在和2008年其实不一样......艾斯曼指出，上一次低端消费者陷入困境导致更大问题是在2007年和2008年，当时他们背负了太多债务。但他现在表示，不太富裕的消费者只是在努力跟上通胀。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_9e11e2e6ace04dbd8e061961452a2250@5579416_oswg50710oswg755oswg453_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">投向预言家：AI虚火与现实</p><p><strong>氪星主编：</strong>美国经济可能比市场预期的更有韧性。</p><p><strong>狐选理由：</strong>美国经济软着陆变数的确不少，时间会给出答案。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956879209511811</id>
            <title>云天励飞七年半亏损近27亿元，实控人身家一年半蒸发超88亿元</title>
            <link>https://www.36kr.com/p/2956879209511811</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956879209511811</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 12:46:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_8194a97e82d547909e281debe5859c1f@000000_oswg80194oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>对于云天励飞而言，目前无疑是较为困难的时刻拥有大模型及算法芯片两大热门项目，让资本市场对公司存在期待，但缓慢的商业化进程及惨淡的业绩又让公司成长性遭质疑。</p></blockquote><p>上市一年半，AI大模型及芯片企业云天励飞仍未走出亏损泥潭。</p><p>自2023年上市到2024年上半年，云天励飞的业绩亏损尚有扩大的趋势。从近几年公司经营及业绩表现来看，未来云天励飞想要扭亏为盈，并不容易。</p><p>此外，由于数字城市运营管理竞争激烈，云天励飞盈利能力出现大幅下滑。在业绩持续亏损等众多不利因素影响下，云天励飞股价较高点已经跌超83%，较公司发行价也跌超50%。</p><p><strong>从公司经营业绩及现金流来看，留给云天励飞的时间不多了。</strong></p><h2><strong>&nbsp;因股权激励亏损扩大，7年半公司亏损近27亿元</strong></h2><p>公开资料显示，云天励飞成立于2014年8月，由陈宁、田第鸿共同出资设立。据悉，云天励飞是一家人工智能企业，公司基于算法芯片等产品，为政府、公安等客户提供数字城市运营管理等服务。</p><p>2019年，科创板顺利推出，业绩不再是科技企业上市的拦路虎，连续多年亏损的云天励飞看到了上市曙光。2020年7月，云天励飞成功完成股份制改革，2020年12月云天励飞首度递交招股书，计划在科创板上市。</p><p>值得注意的是，在递表前一年即2019年云天励飞归母净利润亏损还高达5亿元。由于持续亏损，加之在其他因素影响下，云天励飞上市所需时间并不短，直到2023年4月云天励飞才正式在科创板上市。</p><p>上市以后，云天励飞并没有改变亏损局面，2023年云天励飞净亏损3.83亿元。2024年上半年，云天励飞再度亏损3.10亿元。值得注意的是，自2017年以来云天励飞已经连续7年半亏损，累计亏损近27亿元。</p><p><strong>令人担忧的是，2021年之前虽然云天励飞持续亏损，但公司收入却在快速增长。近两年，云天励飞似乎失去了往日增长动能。</strong>数据显示，2021年至2023年云天励飞营业收入分别为5.66亿元、5.46亿元、5.06亿元，呈逐年下滑趋势。</p><p>值得注意的是，云天励飞所处的行业仍在蓬勃发展当中。以公司下游主要应用市场智能安防为例，中国安防协会发布数据显示，2022年国内智慧安防市场规模约为630亿元，同比增长约7.5%，预计到2023年底，我国智能安防行业市场规模将达到800亿元左右。</p><p>在下游需求不断增长的基础上，云天励飞收入不增反降，也反映在该领域市场竞争较为激烈。2024年上半年，云天励飞实现营业收入2.89亿元，同比增长97.40%，扭转了连续下滑的营业收入。</p><p><strong>在公司收入大幅增长的背景下，云天励飞亏损非但没有减少，反而在增加。</strong>同期，云天励飞亏损3.10亿元，2023年上半年则为2.11亿元。</p><p>对此，云天励飞则表示，公司2024年上半年亏损加大主要原因是股份支付增加所致。据悉，2024年上半年云天励飞仅股份支出费用便多达7862.31万元。</p><p>根据云天励飞披露的信息，公司股权激励涵盖了公司部分核心员工，云天励飞也提示，为留住人才，未来不排除继续大额股权激励的可能。</p><p>对于科技企业而言，股权激励有一定的必要性，但因股权激励导致本就亏损的业绩继续扩大，是否值得还有待商榷。</p><h2><strong>身陷“百模大战”，云天励飞毛利率断崖式下滑</strong></h2><p>2023年是AI爆发的元年，云天励飞是A股为数不多同时拥有大模型及人工智能芯片的企业，具有一定的稀缺性。<strong>因此投资者对云天励飞寄予厚望，也是云天励飞能超额完成募资的原因所在。</strong></p><p>发展之初，云天励飞还曾因为技术方向有过激烈争论，而这主要来源于公司两位创始人。据悉，云天励飞创始人陈宁、田第鸿两人均是美国佐治亚理工学院博士毕业生，且两人都是资深的科技工作者。</p><p>不过对于云天励飞的发展方向，陈宁、田第鸿却有不同的理解，长期在IC（集成电路）行业任职的陈宁主张芯片优先于算法，而田第鸿则认为算法优于芯片。</p><p>由于存在纷争，股权占比、话语权较小的田第鸿在公司递交招股书时，清空了公司股权，正式退出了云天励飞，套现资金仅数千万元。而云天励飞上市后，凭借手中持有的股权，陈宁身家一度突破百亿元。</p><p>在田第鸿退出后，云天励飞也加大了算法芯片投入，基于此，云天励飞还研发出了三代指令集架构、四代神经网络处理器架构。</p><p>在算法芯片突破后，云天励飞将该产品商业化布局数字城市运营管理，其中第一个落地方向便是智能安防。</p><p>截至2023年底，云天励飞来自数字城市运营管理AI产品及整体解决方案收入为3.92亿元，占公司整体收入比例高达77.39%，该产品主要在不同应用场景通过摄像头收集、分析、挖掘、管理数据，以提高城市管理的智能化水平。</p><p><strong>不过在该领域，云天励飞面临着极为激烈的竞争。</strong>IDC数据显示，国内计算机视觉前五强为商汤科技、旷视科技、海康威视、创新奇智、云从科技，合并市占率达到42%。作为对比，近两年云天励飞市占率仅为1%左右。</p><p>由于行业竞争激烈，加之公司下游客户主要以政府为主，因此产品议价能力较弱。在各种不利因素影响下，云天励飞整体盈利能力逐年走低。</p><p>数据显示，2023年一季度公司毛利率还高达50.64%，2024年上半年云天励飞毛利率下滑至15.76%，仅一年多的时间，公司毛利率便出现断崖式下滑。</p><p>近两年，由于大模型爆火，云天励飞还推出了千亿级“天书”大模型。左手芯片，右手大模型，让云天励飞在发行时受到资本追捧，刚上市时公司市值一度突破450亿元。</p><p><strong>但无论是算法芯片还是大模型均需要较大的研发投入。</strong>2021年-2023年，云天励飞研发支出分别为2.95亿元、3.47亿元、2.95亿元，这对于年营收仅5亿元的企业而言不可谓不多，这也是云天励飞持续亏损的重要原因。</p><p>2023年，云天励飞大力研发的算法芯片为公司带来的收入仅几千万元，而大模型又陷入“百模大战”当中，较大的研发支出恐进一步拖累公司业绩。</p><p>从经营业绩和成果来看，云天励飞目前的经营策略难言成功。</p><h2><strong>募投项目延期，实控人身家一年半蒸发超88亿元</strong></h2><p>业绩不佳，资本市场上对云天励飞的期待也降低了不少。</p><p>截至9月19日，云天励飞股价报收21.55元/股，较公司股价高点跌幅超83%。较公司发行价43.92元/股跌超50%以上。</p><p><strong>云天励飞股价大幅下跌，明面上来看，损失最大的便是公司实际控制人陈宁。</strong>截至目前，陈宁持有云天励飞8367.21万股，在此轮公司股价下跌中，陈宁身家蒸发超88亿元。不过由于陈宁持有成本极低，相较于初始投资成本，陈宁依旧挣得盆满钵满。</p><p>此外，云天励飞众多核心员工也受益匪浅。截至目前，公司前十大股东中有三大员工持股平台，分别是深圳云天创享、珠海云天创享一号及深圳云天创享二号，分别为公司第二、三、四大股东，合计持有公司13.65%，市值超10亿元。</p><p>该持股平台涉及人数众多，均是云天励飞核心人员，凭借公司不断的股权激励，加之公司成功上市，云天励飞部分核心人员也挣得盆满钵满。而在公司上市过程中，云天励飞成功募资39亿元，以中信证券为代表的多家保荐机构便分走了2.8亿元。</p><p>凭借该笔募资，解决了云天励飞燃眉之急，公司货币资金也由2022年底的3.91亿元增长至2023年3月31日的近40亿元。</p><p>不过由于持续亏损加之需要对外投资，截至今年6月30日，云天励飞货币资金及可交易性金融资产下降至23.55亿元，较2023年3月31日下降近20亿元。</p><p>有意思的是，在公司货币资金不断消耗过程中，云天励飞募投项目也选择了延期。</p><p>公司城市AI计算中枢及智慧应用研发项目、面向场景的下一代AI技术研发项目、基于神经网络处理器的视觉计算AI芯片项目此前预计2024年12月达到可使用状态，此次则延迟至2026年6月。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ecf80aab48c24cb8afea985b78be341a@000000_oswg87102oswg967oswg553_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 / 公司投入募资资金明细</p><p>而在补充流动资金上，截至6月30日，云天励飞已经投入11.29亿元。此外云天励飞还两次使用了超募资金，分别为1.5亿元及1.75亿元。</p><p>从云天励飞资金使用及募投项目延期来看，公司对流动资金需求度很高，若非公司IPO募资39亿元，公司是否有足够流动性支撑新项目研发还是未知之数。</p><p>从公司IPO结果来看，实控人及核心员工因为公司上市挣得盆满钵满，中信证券等保荐机构也拿到了一笔可观的保荐费用，云天励飞自身也因为获得30多亿元资金解决了燃眉之急。</p><p>但由于公司业绩欠佳、发行时估值较高、市场环境变化等多种不利影响，公司股价已经大幅度破发，让一众投资者损失惨重。</p><p>为此，云天励飞也推出了2500万元至5000万元的回购计划。截至9月3日，云天励飞已经回购3944.70万元，不过该笔回购未能阻止公司股价下跌。</p><p><strong>对于云天励飞而言，当前无疑是较为困难的时刻</strong>——拥有大模型及算法芯片两大热门项目，让资本市场对公司存在期待，但缓慢的商业化进程及惨淡的业绩又让公司成长性遭质疑。</p><p>基于行业现有的竞争格局及公司资金状况，云天励飞需要尽快提升经营业绩，才能让公司走得更远。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkxMjQ0MTUyNw==&amp;mid=2247534397&amp;idx=1&amp;sn=559de63a5b796cc942d6d7f0dc2fe5aa&amp;chksm=c022a36cf1a6b7951993ef3bcec59ad2ffbc739a0d33ff41543de316a2fc9f944fa21fc93410&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“创业最前线”（ID：chuangyezuiqianxian）</a>，作者：段楠楠，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956905885458311</id>
            <title>iOS 18体验：设计乱改、AI缺失，苹果活该被骂上热搜？</title>
            <link>https://www.36kr.com/p/2956905885458311</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956905885458311</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 12:40:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>9月17日凌晨，苹果推送iOS 18正式版更新，支持第二代iPhone SE及后续机型，内部版本号为22A3354，更新容量大小约4GB。本次大版本更新带来了许多新功能，比如果粉们一起期盼的应用上锁，或是通话录音等。</p><p>不过，iOS 18正式版的到来却让各方都彻底炸开了锅。</p><p>17日上午，话题「iOS 18还我妈生相册」、「iOS 18好丑」同时登上热搜榜，最高甚至冲进前十，讨论度甚至比即将发售的iPhone 16系列还高。<strong>但大部分用户都表达了对本次更新的不满。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_5d113fd377b04dc7ba517380cfe04668@1547419282_oswg159672oswg1179oswg485_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：微博）</p><p>比如，有些用户认为iOS 18实在是太像MIUI；另一部分用户则是对新改动的相册APP有很大怨言。值得一提的是，传闻中的苹果零部件加密也在本次更新中正式上线，iOS 18能够对非原装零部件实时监测，并发出警告。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_9e53eb96290d4662b7c1839cf6e8b871@1547419282_oswg190805oswg640oswg497_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：X）</p><p>可以说，iOS 18引起了众多不满，但它真的有这么糟糕吗？</p><h2><strong>iOS 18，为了更新而更新？</strong></h2><p>iOS 18正式版被骂上热搜，其实也不能怪果粉们玻璃心。</p><p>争议最大的是iOS 18全新相册APP，在设计上，它抛弃了此前简单的信息流逻辑，转而变成卡片样式。新版相册APP会将相册、精选集、回忆等功能同时展示在首页，相当凌乱。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_819b0d88c55a431ea773b9e7dafe84c5@1547419282_oswg1395297oswg1306oswg1828_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：Apple Newsroom）</p><p>相册APP提供的视频播放功能，将原本缩略图形式的进度条简化成了时间轴进度条，目前只有手动拖动时才能正常显示每秒的影片截图，部分用户表达了对这种改动的不习惯。&nbsp;</p><p>小雷自己手持的iPhone 15 Pro在很早之前就更新到了iOS 18测试版，在初上手时的确对这个新版本相册APP不太习惯，尤其是那些来自苹果的「建议」，这不太符合我的日常需求。不过，其实我们可以手动取消一些相册建议，比如人物与宠物，这个相册是可以直接关闭的。&nbsp;</p><p>不难看出，苹果将智能精选放在了新版相册APP的首要位置上，这些通过机器学习精选的照片可能很有趣，但相册始终是要方便用户浏览的，而现在智能精选占据了主要地位，用户想要按顺序查看照片的习惯则会被打乱。<strong>这便是为何全网几乎都在吐槽：还我妈生相册。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_147f625e995c4622829bcba6a0ca34cc@1547419282_oswg167488oswg1179oswg2556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技制图）</p><p>另一项争议比较大的改动是控制中心，在iOS 18上，我们可以自由定制所需的小组件。之所以争议如此大，主要还是因为控制中心选择了圆形图标，这完全不像苹果的设计风格。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_bbec18fdc7af49c0a71d2e43ed7535d9@1547419282_oswg123419oswg1179oswg2556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技制图）</p><p>此前iOS向来遵循独特的圆角矩形设计，其曲率和iPhone的边框曲率相近，视觉观感会比较和谐。此外，一个控制中心里同时出现两种尺寸的圆角矩形和完全的圆形图标，这也是iOS历史上比较罕见的选择。</p><p><strong>不过，由于自定义程度足够高，新版控制中心也可以被整出很多花活：例如一整页的手电筒开关、一整页的飞行模式图标等。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_cbe7e4160514460598f17e0bd6b5ece5@1547419282_oswg146648oswg1179oswg2556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技制图）</p><p>整体来看，iOS 18被吐槽的地方的确是改动较大的部分，同时也是苹果在开放与自定义方向上撕开的一个口子。但糟糕的设计、粗制滥造的审美和意义不明的排列方式，让多数老果粉都表示不习惯。&nbsp;</p><h2><strong>越来越无趣，iOS被骂不冤枉？</strong></h2><p>作为iPhone的核心竞争力之一，iOS在诞生的前几年时间里一直都是定制化Android们的标杆，许多大厂前期的系统里或多或少也有一些「果味」。但近两年，以OriginOS 4为代表的一众深度定制化系统叫好声不断，反倒是iOS年年被吐槽。</p><p>首先，苹果在iOS 7上正式走进扁平化时代后，基本就是小修小补，设计风格没有太明显的变化。彼时，你可以说苹果过于超前，<strong>像是非线性动画、扁平化图标、毛玻璃效果等，都是一直都现在还在流行的元素。</strong>但这么多年来，iOS也确实是缺少新意。</p><p>其次，功能性上的缺失，让iOS变得不太实用。众所周知，iPhone X之后苹果就进入到了全面屏时代，iPhone也是一年比一年大，刚刚发布的iPhone 16 Pro Max，显示尺寸已经来到6.9英寸了。<strong>在这种尺寸下，iOS仍不支持侧面返回，这几乎让Pro Max用户失去了单手使用的可能性。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_70047a8d526049ce9765810bcba32477@1547419282_oswg669662oswg2440oswg1060_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：苹果官网）</p><p>iOS 18其实也带来了果粉们期待了很久的功能，比如应用上锁、通话录音等，但应用双开或是小窗模式，这些已经十分常见的功能，iOS始终没有。</p><p>或许苹果认为这些功能并不适合出现在iOS上，但这也让iPhone变得不够实用。另外，为了能保证旧款设备的持续更新，iOS几乎每个大版本都要对性能策略进行调整。外媒INIYSA在性能测试报告中提到，升级到iOS 18后的iPhone 15 Pro Max，在多项性能表现上高于iOS 17版本，尤其是AI和机器学习计算速度，高出数倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e0441031ab5147a882598bde3a3bc43e@1547419282_oswg156352oswg1440oswg803_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：INIYSA）</p><p>但也有反面案例，比如iPhone 13系列用户就表示过，iOS 18使其性能下降严重，流畅度不及从前。INIYSA给出的最新数据也表示，iOS 18有意调整了单核峰值性能，主要为了控制发热和提升续航。</p><p>客观地说，iOS倒也不是每年都在原地踏步，比如随灵动岛一同登场的实况显示，目前已经成为各大定制系统争先模仿的功能。可整体看下来，iOS近几年的变化也的确不大，愈发无趣的新特性，难免让果粉们争相逃离苹果生态。&nbsp;</p><h2><strong>iPhone 16系列遇冷，iOS“功不可没”？</strong></h2><p>从市场的角度看，iOS 18引发的争议并不仅限于设计层面，它反映了苹果在当前竞争中的更深层次挑战。根据2023年第二季度的市场数据显示，苹果在全球智能手机市场的份额约为17.6%，仍稳居全球第二，但在部分地区，尤其是中国市场，苹果的表现不如预期。同一季度，中国本土品牌如华为、OPPO和小米分别占据了19.8%、16.5%和13.7%的市场份额，显示出强大的本地竞争力。</p><p>更重要的是，iOS 18是iPhone 16系列的预载系统，这意味着购买了这代iPhone的用户没有后悔药可吃，只能默默地接受新版iOS带来的变化。这或许会成为旧款iPhone用户选择静观其变的原因之一。</p><p>iOS 18风评不佳的同时，中国手机厂商也开始出手了：OPPO今日官宣ColorOS开发者大会定档10月17日、vivo也在此前暗示了OriginOS 5内测版即将上线，至于备受期待的鸿蒙，早在今年中旬就已确定年末上线。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_80d75cdfc4844baa86a8fa8fd883bed8@1547419282_oswg922612oswg2304oswg1824_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：OPPO）</p><p>根据Counterpoint Research的报告，2023年上半年，全球Android智能手机的出货量占比超过72%，而iOS则占据了剩余的份额。虽然苹果仍然占据着高端市场的重要地位，但Android在中高端市场的渗透率正在不断上升，尤其是通过定制化系统，安卓在满足用户个性化需求方面的表现更加出色。</p><p>在酷安社区中，OriginOS 4的用户评分高达8.2、鸿蒙4.0用户评分高达8.4，而iOS 18只有7.4分，仅略高于realmeUI 5.0的7.3分。</p><p><strong>iOS 18正式版推出后，iPhone 16系列的预售明显出现了一些问题。</strong>比如，目前Apple Store上iPhone 16 Pro沙漠色钛金属显示10月11日到货，而iPhone 14、iPhone 15系列预售时，这个时间段预订基本已经要排队到11月了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_33ff16c15b624ebcbe0c00ca77e2cf65@1547419282_oswg143901oswg1179oswg773_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：Apple Store）</p><p>当然，苹果iOS 18面对的压力不仅来自设计层面的吐槽，更是在市场策略上的滞后。即便iPhone在高端市场依旧有相当的用户群体，但全球竞争格局的变化正在对其形成巨大挑战。如果苹果继续在设计和用户体验上止步不前，那么随着定制化Android和鸿蒙系统的持续发展，iPhone的市场份额可能会进一步缩小。</p><p>未来，苹果要想继续保持在智能手机市场的竞争力，必须在iOS设计和功能体验上做出更大的突破。但这种突破可能未必会让所有老用户接受，正如iOS 18的设计，就引起了巨大的争议。假如你还没有从旧版本升级到iOS 18，那么小雷建议你慎重考虑。</p><p>本文来自微信公众号“雷科技”，作者：雷科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956816277593985</id>
            <title>增程「神教」，越来越热闹</title>
            <link>https://www.36kr.com/p/2956816277593985</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956816277593985</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 12:30:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a883b2117c2a4a0ab1c98371ed5b816c@6062471_oswg128296oswg1265oswg814_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>增程神教，越来越热闹。</strong></p><p>除了<a href="" rel="noopener noreferrer nofollow">蔚来</a>这样纯电忠实的信徒外，不少的造车新势力，都开始或已经押注增程成为他们的下一增长点。</p><p>据36氪报道，截至今年9月，<a href="" rel="noopener noreferrer nofollow"><strong>小鹏汽车</strong></a><strong>的增程车项目已经明朗</strong>，今年上半年已完成核心零部件定点，首款增程车正在全力开发当中，预计2025年下半年量产。</p><p>具体来看，有消息人士透露，小鹏的增程车型“是以G9为原型车开发，主要针对20万元以上价格带”的中大型SUV，并且下线时间“不会晚于明年四季度”，届时小鹏也将形成纯电与增程两大车型产品阵列。</p><p>在小鹏之外，早在几个月前，<strong>小米也被曝出正在规划主打家用的增程SUV车型</strong>，或将在2026年上市。而继承小米精神的<strong>智己同样被传出，将在2025年一季度发布一款对标理想L7的增程式SUV车型。</strong>甚至<strong>吉利旗下聚焦纯电的极氪，也放出了要做增程的风声</strong>——CEO安聪慧也在009光辉的发布会上，面对媒体咨询未来是否有增程计划时称：“未来不排除做增程混动车”。</p><p>此外，今年下半年的<strong>重点增程产品零跑C16、阿维塔07、深蓝S05</strong>等车型也已经快要全部和大家见面了。</p><p>这也同去年年底李想的大胆预判，不谋而合。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_6773a2a2b625480e9dc14ebb6bcad5f0@6062471_oswg173071oswg869oswg345_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：李想微博</p><p>遥想大众中国CEO炮轰理想力推的“增程式是最糟糕的方案”言论，已经过去了四年。在这四年时间里，增程车型的占比不断增加，甚至在过去的一年中进一步加速，销量占比增长超过5%。相比之下，纯电的新能源车的批发销量占比已经从一年前的接近七成跌落至今年7月的刚刚过半。</p><p><strong>那么，为什么增程这个被大众和长城等多个老牌车企高管公开宣称落后的技术，能够在电池续航屡创新高的当下“开历史的倒车”，还越发展越好？随着增程神教的“信徒”越来越多，本来在舒适圈中的理想和鸿蒙智行，是不是也该为自己纯电车型的未来担忧一下了？</strong></p><h2><strong>很懂技术的纯电车企，不懂中国消费者？</strong></h2><p><strong>想要了解为何如此多的新能源汽车企业会对增程“前倨后恭”，自然绕不开这项技术的缺点。而总结下来其实无外乎三点：馈电时动力衰减明显、充电速度较慢以及增程器发力状态下噪音较大。</strong></p><p>而这三大缺点，对于一个背着“充电宝”的增程车来说是无法避免的。</p><p>众所周知，增程车往往是“小电池+大油箱”的串联组合，在电量无法支持纯电模式的时候，就需要增程器的介入，来完成用油发电再转为动能的过程，但当前绝大多数发动机效率都是跟不上电耗的，也就电机基本都无法全力输出，自然而然会出现馈电时动力衰减的情况。</p><p>此外，跟不上电耗的发动机效率，也让增程器成为了增程动力系统“水桶”中最短的一块“木板”，馈电状态下自然需要高负荷或满负荷运转，这就导致了增程器工作噪音非常大，即便各车企做出了不少降噪方面的努力，但相比于纯电的体验，还是差了太多。</p><p>最后，小容量的电池同样决定了增程车的充电效率难以同主流的纯电车型相比，也闹出了不少充电站“拒绝”增程的笑话。</p><p><strong>放在四年前，无论是哪家纯电车企，看着正在不断突破上限的续航里程和加速铺设的补能设施，都憧憬着长续航、快充电、充电站充足的美好未来，对背着发动机跑来跑去的增程技术嗤之以鼻、认为背着油箱到处跑的电车是一项终将会被且很快会被淘汰的技术，也是情理之中的事情。</strong></p><p><strong>但是，自诩很懂技术的车企，却还是低估了中国消费者对于用油“安全感”的依赖性。</strong></p><p>作为增程式技术的主力车型，SUV的客户群体天然就有大比例的家庭用户。这类用户的日常生活几乎都集中在城市中，日常出行半径其实不高。以长距离通勤著称的北京、上海来说，来回一天通勤往返最多可能也就是百公里左右，增程的纯电续航完全可以满足。</p><p>在绝大多数通勤较短的同时，家庭用户又有着对极高补能效率的追求。</p><p>李想曾以亲身经历举例子：“我自己跑长途的时候，一个人在那里充电1、2个小时都无所谓，我还能看看手机，甚至有点像玩游戏一样拿手机去找充电桩。如果我带着老婆、父母、孩子到处找充电桩，在那里排着队充电，这就是很大的灾难了！尤其是节假日，因为节假日是潮汐效应，是平常排队的大概4倍-5倍。”</p><p>就这样，将增程车的纯电里程覆盖提高到150km之后，理想拿出了理想one这个经典“奶爸车”的原型，也拿下了中国家庭高端SUV的市场份额。</p><p>此后，被誉为中国车企中最优秀产品专家的理想，又将冰箱彩电大沙发的家庭配置搬上了车，也进一步提升了增程SUV产品的市场份额。</p><p><strong>跟随着理想脚步的“华为版理想”问界的成功和“平价版理想”零跑的大卖。新能源每份销量周榜前三几乎都被增程车包揽，也似乎在向其他车企喊话，“只要加入增程神教，就能享受到旗下产品畅销的感觉”。</strong></p><p>在这样一而再再而三的示范之下，曾经对增程嗤之以鼻的车企，也都在市场老师的教训之下，纷纷回头乖乖补课了。</p><h2><strong>增程“乱纪元”，理想华为加速突围</strong></h2><p>不过，虽说这些回头“补课”的纯电车企没有赶上增程发展的黄金时期，大家一拥而上之后的未来也未可知，但真要论当下最慌的究竟是谁，我想大概并不会是以小鹏、小米为代表的纯电车企。</p><p><strong>因为当越来越多的车企都想要进增程市场浑水摸鱼的时候，留给理想与鸿蒙智行这些原住民“突围”的时间也越来越少了。</strong></p><p><strong>毕竟，就当前来看，这两家还尚未拿出一款能在纯电市场中翻起水花的产品。</strong></p><p>其中，作为新势力电车品牌中一骑绝尘遥遥领先的尖子生，理想却在初入纯电市场之时，也被纯电市场的当头一棒打得嗡嗡作响。</p><p>在进入2024年以前，理想凭借L7、L8、L9三款爆卖的增程SUV巩固了自己绝对的新势力之王后，快速制定了向纯电发展的策略。</p><p>按照其去年年底的规划，3月发布MEGA ，下半年发布3款纯电SUV。其中，M9、M8将在2024年内量产，M7预计在2025年一季度量产。2月，理想创始人、CEO李想信心满满的表示，今年将是理想汽车史无前例的产品大年，到年底，理想将组成“4+4”产品布局（4款纯电车型和4款增程式电动车的产品矩阵）。</p><p>然而，MEGA标新立异的外观却引发了舆论风波。上市72小时大定仅有3200余辆。而原本预计年销8万辆的理想MEGA，本应大卖的前两个月中，仅分别卖出3229辆与1145辆。</p><p>面对MEGA的滑铁卢，理想快速做出了反思和调整。</p><p>据晚点报道，3月21日，李想在内部信中写道，理想误判了纯电战略节奏，错误地把MEGA的 “从0到1” 阶段（商业验证期）当成了 “从1到10” 阶段（高速发展期）进行经营。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_da82a5e76c7a404488244e9574e3eb4f@6062471_oswg424741oswg1544oswg1524_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，理想在一季度财报发布的电话会议中，他也直言“公司今年不会发布纯电SUV产品，会放在明年上半年”，“现阶段销售中高端纯电SUV，足够多的自营超充桩是必要条件，我们认为，当自营的超充桩数量达到和特斯拉中国相近的数量时，才是产品推向市场的合适时机”。</p><p>无论如何反思、纯电车型怎样“跳票”推迟，高端纯电终将会是理想要踏入的领域。不过，就目前来看，就算理想做好像<a href="" rel="noopener noreferrer nofollow">蔚来</a>一样的补能设施，并像过去一样愿意低头倾听消费者的需求，也只是拿下纯电贴身肉搏的入场券罢了。</p><p><strong>而相比于被市场教育之后立马收缩的理想汽车，鸿蒙智行则显得头铁了很多。但可惜的是，即便其进行了多次尝试，但在问界之外，同奇瑞、北汽合作推出的智界与享界旗下的纯电车型，销量却难言成功。</strong></p><p>去年11月，华为和奇瑞打造的纯电中大型轿车智界S7发布，但在发布会后三个月，相关交付却仍然一拖再拖。</p><p>在交付都难以保证的情况下，智界S7前四个月的总销量刚刚超过2000台。不过，或是因为内部将智界滞销的原因归咎于产能问题而非汽车本身，在半年后的4月份智界S7进行二次上市，三款车型的价格全部下调两万元。</p><p>这样重新上市+降价的组合拳，确实在短期内提振了销量，但在两个月后销售数据迅速下滑，8月销量更是跌破千辆，也宣布了华为首次试水纯电难言成功。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_94d3f85138ae4fc090e08b87db4c613d@6062471_oswg107960oswg772oswg452_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：懂车帝</p><p>而就在智界的销量向下俯冲之时，第三界享界的销量，也难以复现问界的奇迹。</p><p>享界S9上市后，余承东曾晒图透露，享界S9上市72小时大定数量为4800辆。而根据车fans创始人孙少军在其微博给出的数据，享界上市近一周，累计锁单量已经来到7500-8500辆这一范围内。</p><p>按这样的销量来看，作为一款超过40万元的纯电轿车，其实已经不差。因为至今尚且没有出现一款在每个月稳定出售三千辆以上的豪华纯电轿车。但相比于上市两小时大定破万，上市三周大定超三万的问界M9，还是相差较远。</p><p>其实至此，无论是车企内部还是外界的有关人士都已经看清，理想与华为的关系已经不像去年一样剑拔弩张，李想也不会再因为华为的进场而焦虑到睡不着觉，反而在如何安稳度过从增程向纯电的阵痛期这个问题之上，成为了对方“过河”的重要参考。</p><p><strong>不过，随着增程领域的玩家越来越多，本来泾渭分明的增程市场即将迎来一轮重新洗牌，而理想与华为，则需要在这潭水彻底变浑之前，拿出自己有能力在代表未来的纯电市场立足的现实证明。</strong></p><p>参考资料：</p><p>1.《纯电不好卖，华为也没辙》，电动汽车观察家；</p><p>2.《纠偏“增程落后论”从阿维塔开始》，道哥说车；</p><p>3.《纯电生意不好做，理想取消今年纯电车发布计划》，晚点LatePost。</p><p>本文来自微信公众号“奇偶派”（ID：jioupai），作者：叶子，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956887733369734</id>
            <title>人类离AGI时代，又近了18个月</title>
            <link>https://www.36kr.com/p/2956887733369734</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956887733369734</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 12:17:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT问世18个月之后，行业开始叩问未来——“AGI时代”何时到来？</p><p>9月19日，云栖大会“通往AGI的大模型发展之路”圆桌对话现场，阶跃星辰创始人、CEO 姜大昕、月之暗面创始人 杨植麟、清华大学人工智能研究院副院长、生数科技首席科学家朱军以及极客公园创始人张鹏，<strong>以从业者和亲历者身份，回顾了过去18个月行业的发展，都提到“AGI加速非常快”。</strong></p><p>在姜大昕看来，<strong>AGI的演进路线分为“模拟世界” “探索世界” “归纳世界”</strong>，对应的产业化应用包括GPT-4o、FSD v12和OpenAI o1，“（它们）在这三个方向上都取得了非常大的突破。”</p><p>杨植麟对AGI加速的理解来自两个层面，<strong>“智商一直在提升” 、“多模态横向发展”。</strong></p><p>而朱军不仅认为AGI的进程在加快，在他看来，<strong>AGI的加速表现，也包括解析问题的速度变快</strong>，这些得益于从业者对多模态的认知更成熟，以及为算力、基础设施资源准备更充分。</p><p>AGI进程加快，离不开开拓者OpenAI的牵引。OpenAI在9月12日发布了新模型o1，Sam Altam说这是“新的范式变革的发生”，行业则认为这是AGI发展的关键一步。</p><p>站在从业者视角，<strong>o1模型推理能力在具体场景下具备了出色的能力，更重要的是它在数据“枯竭”的背景下，探索了一套“强化学习如何泛化”的方法论</strong>，姜大昕说“它带来了Scaling Law新的方向”，杨植麟说“（强化学习）很大程度上解决了AI进一步Scaling、数据从哪里来的问题。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e57700528fb144b2ad277758b64ac580@46958_oswg51495oswg960oswg527_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>过去18个月，AGI加速越来越快</strong></h2><p>“过去的18个月，AGI的加速是非常快的”，阶跃星辰创始人、CEO 姜大昕说。</p><p>回看过去的一年，从OpenAI的GPT-4一家独大、遥遥领先，到今年开始除了OpenAI o1之外，Anthropic也推出了Claude 3.5、Google则发布Gemma，以及XAI的Grok 2、Meta的Llama 3先后亮相，大模型出现了群雄并起，你追我赶的趋势。</p><p>在这种背景下，大模型的能力和质量也在多线程提升，GPT-4o的多模融合上了一个新台阶，包括图像、视觉、音频等独立的模型融合到一个模型当中，“多模融合一定是有助于我们更好的去为我们的物理世界建模。” 姜大昕说。</p><p>姜大昕把AGI的演进路线总结为“模拟世界” “探索世界” “归纳世界”，“过去几个月的时间，我们看到GPT-4o、FSD v12和OpenAI o1分别在这三个方向上都取得了非常大的突破。”</p><p>对于过去的18个月的总结，月之暗面Kimi创始人杨植麟答案是“智商一直在提升” “多模态横向发展”。</p><p>杨植麟说：“智商一直在提升，如果看竞赛数学能力，可能去年是完全不及格，今年已经能做到90多分” “横向上也产生了很多新的突破，最近有特别多新的产品和技术出来，你可以通过一个论文直接生成基本上看不出来是真是假的双人对话，类似这种不同模态之间的转化、交互和生成是会越来越成熟。”</p><p>“大模型今年发生了很多重要变化，我也同意AGI的进程在加快”，清华大学人工智能研究院副院长、生数科技首席科学家朱军说。</p><p>在朱军看来，AGI的加速表现也包括解析问题的速度变快，“大家对这种（多模态）路线的认知和准备达到了比较好的程度，还有物理的条件，比如说像云的设施，计算的资源准备，当我们掌握了这些之后，再去做解决的问题，速度是越来越快的。”&nbsp;</p><h2><strong>OpenAI o1的意义：强化学习</strong></h2><p>OpenAI新发布的o1模型，将大模型的推理能力拉到了理科博士的水平。</p><p>“它第一次证明了语言模型可以有人脑慢思考的能力，它可以自我反思、纠错，直到找到正确解决问题的途径”，“它还带来了Scaling Law新的方向，o1试图回答强化学习如何泛化。”姜大昕说。</p><p>目前在学术界，针对<strong>AGI按照能力等级将其划分为L1、L2、L3、L4、L5，其中L1代指聊天机器人、L2则具备深度思考推理能力、L3是数字世界走向物理世界的智能体、L4需要具备发现、创造新知识的能力、L5代表组织者，AI已经具备组织协同能力。</strong></p><p>“（OpenAI o1）代表着显著的质变”，朱军说，“o1在L2级别的特定任务下，可以达到人类很高阶的智能水平，确实代表着整个行业的进步。”</p><p>对于新的o1模型，外界评论颇为正向，那么内部视角又是如何？Sam Altman将其定义为“新的范式变革的发生”。</p><p>“我觉得它的意义很大，它提升了AI的上限，关键就是能不能通过强化学习进一步Scaling”，杨植麟说，“如果我们看AI历史上70-80年的发展，唯一有效的就是Scaling，唯一有效的就是加更多的算力。”</p><p>在杨植麟看来，过去GPT-4模型能力是一种确定性的提升，o1则不是确定性的提升。</p><p>“之前大家可能担心说互联网上大部分优质数据都被使用完了，也没有更多数据可以挖掘。原来的范式可能会遇到问题，AI要进一步Scaling，数据从哪里来？（强化学习）很大程度上解决了这个问题，或者至少证明了它初步可行” “这样就会越来越多的人投入做这件事情。最终去做到10倍于GPT的效果，完全有可能。”&nbsp;</p><h2><strong>创业、投资与下一个18个月</strong></h2><p>朱啸虎在“中国现实主义AIGC故事”中说，“我信仰AGI、信仰应用，信仰能马上商业化的。”</p><p>什么量级数据的产品才能商业化，当创业者转变为投资人，会如何看现在AI项目的数据指标，又是什么样的项目值得被投？</p><p>杨植麟的答案是“产品本身价值” “产品增量价值”以及“足够大的市场规模”。</p><p>“DAU和留存率肯定是最重要的指标，但作为一个产品，首先是要有价值，这个本质可能跟AI没有太大关系” “ChatGPT之外还会有大量的机会，相比于它要产生增量价值，能做在ChatGPT里面做不了的事情” “要随着技术的发展，这个市场规模越来越大，不是越来越小”，杨植麟说。</p><p>过去的18个月，从ChatGPT，到今天o1，不管是应用还是模型，能力项都在不断地拓宽和提升，从业者也基本形成了AGI加速的共识，那么未来的18个月，通用人工智能会走到哪一步？</p><p>朱军说，“我们要做（L4级）科学发现和创新，需要的能力目前散落在各个角落，还缺一个系统把这些东西集成在一起。如果激进一点，未来18个月在L4上也会有显著的进展。”</p><p>杨植麟则把自己的目标和OpenAI进行了对齐，继续在强化学习这条路上探索Scaling。</p><p>“接下来最重要的里程碑，是开放性的强化学习，o1可能一定程度上说明这个方向有比之前更强的确定性，这会是一个重要的里程碑，也是AGI路上现在仅剩唯一一个重要的问题了。”</p><p>姜大昕和杨植麟在强化学习上也有共识，不过他还有另外一个期待——“视频理解生成一体化”。“这样就可以彻底建立一个多模的世界模型，可以帮助我们真正的产生非常长的视频，也就是解决Sora目前的技术缺陷。还有，它可以作为机器人的大脑，帮助智能体更好探索物理世界。”</p><p><strong>以下为对话实录（在不改变原意的情况下，有删减调整）</strong></p><p><strong>张鹏：</strong>大家早上好，我是极客公园的张鹏。今天非常荣幸，也非常开心，能有这样的机会来到云栖大会，同时也能够和几位在国内大模型领域的探索者，一起探讨模型技术的进展。</p><p>刚才在吴总的演讲中，我相信很多人都感受到了他对大模型和这一波AGI发展的强烈信心，甚至明确指出，这不仅仅是移动互联网的延展，可能是一场对物理世界的全新变革。当然，我觉得我们这个环节可能需要对他的结论进行思维链的解构，第一步就是要看看模型技术的进展如何。在过去的18个月里，和未来的18个月里，有哪些总结和展望？</p><p>我们先从对过去的看法开始。ChatGPT的发布引发了全球对AGI的理解，至今也差不多18个月了。不知道各位对此有何感受？模型的发展是在加速，还是在减速？我们都在观察你们这些“打游戏的人”，今天请到“打游戏的人”现场分享。我们请姜大昕来分享一下，你怎么看AGI的发展，是加速还是减速？</p><p><strong>姜大昕：</strong>我觉得过去18个月的发展是在加速的，速度非常快。</p><p>回顾过去18个月发生AI事件时，可以从两个维度来看：一个是数量，一个是质量。从数量上看，几乎每个月都会有新的模型、新的产品和应用涌现。单从模型来看，OpenAI在2月份发布了Sora，5月份推出了GPT-4o，上周又发布了o1。过去一年，我们感觉GPT-4独领风骚，遥遥领先，而到了今年，局面变成了“群雄并起”，你追我赶，所以总体上感觉大家都在提速。</p><p>有三件事情给我留下了深刻印象。第一件事情是GPT-4o的发布，它在多模融合领域达到了一个新的台阶。在GPT-4o之前，有GPT-4v，它是视觉理解模型，视觉生成模型，还有声音模型。这些原本孤立的模型，到了GPT-4o这里，都融合到了一起。为什么这种融合非常重要？因为我们的<strong>物理世界本身就是多模态的，融合有助于更好地为物理世界建模，模拟这个世界。</strong></p><p>第二件事情是特斯拉发布的FSD V12，大家知道它是一个端到端的大模型，可以把感知信号直接转化为控制序列。<strong>智能驾驶这个领域非常具有代表性，它是真实应用场景从数字世界走向物理世界的范例。</strong>因此，我认为FSD V12的成功不仅在于智能驾驶本身，它的方法论为未来智能设备与大模型结合、探索物理世界指明了方向。</p><p>第三件事是<strong>o1的发布，它第一次证明了语言模型可以具备“人脑的慢思考”能力，也就是所谓的系统2的能力</strong>。系统2能力是理解和归纳世界的基础条件。</p><p><strong>我们一直认为AGI的演进路径可以分为模拟世界、探索世界，最后是归纳世界。</strong>而过去几个月里，GPT-4o、FSD V12和o1分别在这三个阶段和方向上都取得了很大的突破，也为未来的发展指明了方向。因此，不论从数量还是质量来看，这些进展都非常值得关注。</p><p><strong>张鹏：</strong>杨植麟，你的感受怎么样？你是投身其中的人，和我们这些“看游戏”的人一定有所不同。</p><p><strong>杨植麟：</strong>整体来看，确实是处于加速发展的阶段，核心可以从两个维度看AI的发展。</p><p><strong>第一个维度是纵向维度，即智商的不断提升。</strong>现在主要是文本模型，能力提升明显。比如说去年模型的数学竞赛成绩可能完全不及格，而今年已经能拿到90多分。代码能力方面，模型已经能够击败许多专业的编程选手。</p><p><strong>另一个维度是横向发展，除了文本模型之外，其他不同的模态也在发展，</strong>这些模态的横向扩展使模型具备了更多的技能，能够完成更多任务。</p><p>再来看具体的技术指标，比如语言模型支持的上下文长度，去年这个时间点，许多模型只能支持4到8K，但现在128K已经成为标配。智商的提升和许多优化手段相结合，让AI的发展进一步加速。</p><p>横向上，视频生成等新突破不断涌现，比如Sora，它的影响力非常大，完成了视频生成。最近还有很多新的产品和技术涌现，甚至可以通过一篇论文生成看似真实的双人对话等。模态之间的转化、交互和生成变得越来越成熟，整体是在加速过程中。</p><p><strong>张鹏：</strong>这些技术确实在扩展它们带来的变化和创新。虽然我们还没有看到某个具体的超级应用崛起，但从技术上看，进展非常明显。朱军老师，你怎么总结过去18个月AGI技术的经历？有哪些可总结的进步台阶？</p><p><strong>朱军：</strong>在AGI的领域，最关注的还是大模型。今年大模型发生了很多重要的变化，<strong>我非常同意刚才提到的技术进展在加快。我想补充一点，解析问题的速度也在加快。</strong></p><p>回顾一下语言模型的历程，从2018年杨植麟他们开始做，到今年已经走了五六年的路。去年<strong>上半年主要关注语言模型，下半年开始讨论多模态，</strong>从多模态的理解到多模态的生成，尤其是视频生成技术的发展最为明显。</p><p>今年2月份，很多人被技术的快速发展震惊了，甚至开始质疑技术是否完全公开，技术突破是如何实现的，讨论非常多。但事实上，这个行业在用了大约半年的时间后，已经做到了将这些技术投入实际应用，而且效果非常好，尤其是在时空一致性上的表现非常突出。</p><p><strong>这次加速的核心原因在于，大家对技术路线的认知和准备达到了比较好的程度。物理条件的成熟也起到了重要作用，比如云设施和计算资源的准备。</strong></p><p>与当初ChatGPT推出时相比，当时很多人并没有做好接受这项技术的准备，导致很多时间花在了学习和掌握上。当大家掌握了这些技术后，发现进展的速度越来越快。当然，不同的能力在用户层面的表现可能会有所差异，甚至在不同行业的速度上也存在快慢差异。但从广泛角度来看，技术进展的曲线越来越陡峭。对于未来更高阶AGI的发展，我保持乐观，我认为未来的进展速度将比过去更快。</p><p><strong>张鹏：</strong>从三位的角度来看，如果有人说AGI的发展变慢了，你们可能一句话就是“你还想要怎样？” 过去18个月的进展已经让每个人目不暇接了。刚刚发布的o1模型也在专业领域引发了广泛讨论。我们正好有机会听听大家的看法。姜大昕，你怎么看待o1？很多人认为这是AGI发展阶段的一个重要进步，你如何理解这个进步？</p><p><strong>姜大昕：</strong>确实，我看到了一些非共识的声音。有些人认为意义重大，有些人则觉得没什么特别。但如果你实际使用过o1，第一印象就是它的推理能力非常惊艳。我们进行了很多测试，发现它的推理能力确实上了一个新台阶。关于它的意义，我能想到两点。</p><p><strong>第一，o1第一次证明了语言模型可以具备人脑的慢思考能力，也就是系统2的能力。</strong>系统1是直线型思维，而系统2能够探索不同的路径，自我反思和纠错，不断试错，直到找到正确的答案。之前的GPT-4可以把复杂的问题拆解成多个步骤来解决，但仍然是直线型的。而系统2的区别在于，它能够尝试不同路径。这次o1通过将模仿学习和强化学习结合，使得模型同时具备系统1和系统2的能力，这一点非常重要。</p><p><strong>第二，o1带来了Scaling Law的新方向。</strong>它尝试回答强化学习如何泛化的问题。强化学习不是新概念，DeepMind从AlphaGo到AlphaFold都走的是强化学习路线，但这些强化学习场景都是为特定领域设计的，比如AlphaGo只能下围棋。而o1的出现则使得强化学习的通用性和泛化能力上了一个新的台阶，且达到了更大规模。<strong>所以我认为，o1带来了新的Scaling范式，可以称之为新的Scaling路径。</strong>虽然目前它还不算特别成熟，但这恰恰让人觉得兴奋，就像OpenAI在告诉我们，它找到了一个上限非常高的技术路径。如果仔细思考这背后的方法，你会相信这条路是可以走下去的。</p><p><strong>因此，从能力上看，o1证明了语言模型可以具备系统2的能力；从技术上看，它带来了新的Scaling范式，这其意义非常重大。</strong></p><p><strong>张鹏：</strong>听起来虽然有一些非共识的声音，但你对o1是非常看好和认同的。朱军老师，你怎么看待o1带来的进展？你如何评价它的意义？</p><p><strong>朱军：</strong>我认为o1代表了一个显著的质变。学术界对AGI做了一个分级，从L1到L5。L1是聊天机器人，L2是推理者，能够做复杂问题的深度思考和推理，L3是智能体，可以与数字和物理世界进行交互和改变，L4是创新者，能够发现和创造新的知识，L5是组织者，可以更高效地协同和组织资源。</p><p><strong>o1执行L2级任务，已经达到了人类高阶智能水平，</strong>从分级的角度来看，它确实是行业的巨大进步。</p><p>技术上，正如姜大昕所说，o1结合了强化学习和其他技术，这些技术在研究领域已经有很多尝试，但这次它在大规模模型上的效果得到了验证。这对于行业的工程实现有很大触动，也会激发更多的探索和研发。正如刚才所提到的，我认为进展会非常快，因为我们已经做好了很多准备。我也期待这个领域中，L2的能力将进一步优化，甚至实现更高阶的进展。</p><p><strong>张鹏：</strong>你对这个进展的定义已经非常高了，认为在L2阶段，AGI已经有了显著的进步和阶段性成果。而之前我们还在L1阶段，未来还要进一步前进，直到实现L3阶段，才能全面系统性地改变物理世界。</p><p>这次o1发布后，Sam Altman也称这是一次范式革命。Sam Altman向来擅长演讲和表达，我们想听听你的看法，你如何理解他说的这次范式变革？你是否认同这是一次范式革命？</p><p><strong>杨植麟：</strong>我觉得它的意义确实很大，主要在于提升了AI的上限。AI的上限指的是你现在是否可以提升5%、10%的生产力，还是10倍于GPT。<strong>这其中最关键的问题是，你能不能通过强化学习进一步进行Scaling，这是完全提升AI能力上限的核心。</strong>如果我们回顾AI 70-80年的发展历史，唯一真正有效的路径就是Scaling，唯一有效的方式就是增加更多算力。</p><p>在o1出现之前，其实已经有很多人在研究强化学习，但当时没有一个非常明确的答案。强化学习如果与大语言模型、以及现在的Pre-Training（预训练）和Post-Training（后训练）整合在一起，能否持续提升？这是一个悬而未决的问题。</p><p>比如，GPT-4这一代模型的提升更多是确定性的提升，也就是说我在同样的范式下，通过扩大规模来实现进步。这肯定是会有提升的，但o1的提升并不是完全确定性的提升。所以在此之前，大家会担心，现在互联网上大部分优质数据已经被用完了，继续使用这些数据也无法挖掘出更多东西。因此，原来的范式可能会遇到瓶颈，<strong>AI有效的进一步Scaling（扩展）数据到底从哪里来？我认为，o1的出现很大程度上解决了这个问题，或者至少证明了它初步可行。</strong>这意味着，会有越来越多的人投入到这项工作中。</p><p>最终，要实现10倍于GPT的效果完全是有可能的。我认为这是一个非常重要的开端，而对于许多产业格局以及创业公司来说，这次范式的变化也将带来新的机会。</p><p><strong>这里有一个非常关键的点，就是训练和推理算力的占比会发生很大的变化。</strong>当然，这并不是说训练的算力会下降，训练的算力可能还会持续提升，但与此同时，推理算力的提升速度可能会更快。这个比例的变化本质上会带来很多新的机会。</p><p>这里面将会有很多新的创业公司的机会。如果你是一家已经达到一定算力门槛的公司，你可以在算法的基础创新上做很多工作，甚至可以在基础模型上取得突破。这非常重要。对于算力相对较少的公司，也可以通过后训练的方式，在某些领域做到更好的效果，这也会带来更多产品和技术的机会。整体而言，这次变化打开了很多创业相关的想象空间。</p><p><strong>张鹏：</strong>这次范式变化的核心在于，<strong>在Scaling Law上解决了我们接下来应该Scaling什么样的东西，看到了一条新的路径。</strong>你刚才提到的未来扩展的创新路径空间，可探索的东西变多了，而不是一个收缩的、预设的状态。今天三位对o1带来的变化都很兴奋，但这也是大家现在比较关心的问题。</p><p>我想问问朱军老师，在强化学习加入这个体系并成为新的范式之后，我们能看到泛化这个能力的明确路径吗？因为就目前来看，o1在局部的能力表现很棒，提升也很明显，但泛化路径明确吗？这个确定性足够吗？</p><p><strong>朱军：</strong>这个问题很值得思考。o1在每个特定任务上取得突破后，是否可以推动它的泛化或者更广泛的能力提升呢？从强化学习的角度来看，o1的技术实现路径并没有明确告诉我们怎么做到这一点。</p><p><strong>张鹏：</strong>不像ChatGPT推出时那么开放透明。</p><p><strong>朱军：</strong>是的，但通过科研的积累和对其方法的解读，我们可以看到它用到了一些技术。</p><p>强化学习过程中监督数据的方式和之前的结果监督不同。每一步的思考过程都需要被标注，这类数据的获取非常困难，你需要专业人士生成高价值的数据。同时，在强化学习的实际应用中，特别是在更泛化和开放的场景中，定义Reward Model（奖励模型）并不容易。比如在定理证明或编程中，Reward Model是明确的，因为有正确的答案。</p><p>但是在自动驾驶等领域，很多场景下难以清晰界定“好”或“坏”。问题不是简单的对与错，有时是对生成内容、对美学或其他标准的评价，每个人的感受不同，因此在这种情况下，技术的泛化面临很多挑战。我们如何定义Reward Model？如何收集相关数据？此外，还有如何高效实现这些技术。</p><p>不过，现在我们已经看到了曙光，大家也开始沿着这个方向努力。再加上更强大的基础设施，比起上一代AlphaGo向其他领域的迁移，泛化的速度可能会更快。我们现在有更好的模拟器，甚至包括AGI生成环境的构建。这些进步结合在一起，让这条路比之前更容易取得效果和提升。这是我对泛化问题的看法。</p><p><strong>张鹏：</strong>现在还没有一个公开且明确的路径能保证完全实现泛化，但这个过程本身存在很多探索的空间。我再追问一下杨植麟，你怎么看这个状态？对像你这样的创业公司来说，这是好事还是坏事？在你看到这些变化时，心理状态是什么？你会如何分析这个环境？</p><p><strong>杨植麟：</strong>这是一个非常好的机会。你会发现，新的技术变量和技术维度都出现了，这些变化或多或少已经与我们之前的一些投入相关。现在它变成了一个主题，我们在这个主题下有非常多的新机会。</p><p>朱军老师刚才提到了泛化的问题，此外还有一些基础的技术问题没有完全解决，因为底层涉及训练和推理的Scaling，同时在这个过程中也会出现许多性质上的新挑战。</p><p>我觉得，今天这些性质还没有被完全探索清楚，包括刚才提到的过程监督问题，过程中的一些幻觉现象可能会对效果造成很大影响。这些都值得研究。但如果能够解决这些问题，AI的能力将会上升一个台阶。对于我们来说，通过这些技术创新可以形成一些突破的机会。</p><p><strong>张鹏：</strong>不确定性反而是好事，有确定的方向但不确定的路径对创业公司来说可能是一个优势，否则就没有创业公司的空间了。回到姜大昕这边，杨植麟提到的算法、算力、数据这三个因素在AGI领域被视为关键的三角，这次看起来在算法层面有了一些范式变化。反过来看，算力和数据会产生怎样的连锁反应？你能帮我们推理一下吗？</p><p><strong>姜大昕：</strong>算法、算力、数据的关系是一个铁三角，这个没有改变。强化学习确实是算法上的一个重大变化，带来的结果有确定的、有大概率的，还有不确定的。</p><p>确定的就是刚才两位提到的，在推理侧方面，计算需求成倍增加，同时对推理芯片的要求也显著提高。我们可以想象，OpenAI在o1背后使用了H100芯片来做推理，每个问题可能需要耗费十几秒甚至几十秒。如果我们要加快这个过程，对推理芯片的性能要求自然也会提高。</p><p>另一个大概率会发生的事情是，训练强化学习阶段所需要的算力可能并不会比预训练少，甚至可能更多。算力需求还会持续增加，尤其是在强化学习阶段生成的数据量可能是没有上限的。我们听说，OpenAI在训练这类模型时用了上万张H100卡片，持续训练了几个月，现在训练还没有完成，这代价是非常高的。<strong>因此，如果我们追求的是通用的、能够泛化的推理模型，而不是为某个特定场景设计的强化学习模型，那么所需的算力仍然很大。</strong></p><p>在主模型方面，我们也需要考虑是否继续Scaling，提升参数量，带来更好的推理能力。比如，GPT-4已经达到了万亿级参数，如果继续增加参数，边际收益会逐渐下降。但强化学习有可能加倍这些收益，是否可以将总收益再拉正？如果这个推论成立，那么算力的增长又回到了平方维度，计算量将等于参数量乘以数据量。因此，无论是推理端还是训练端，强化学习带来的算力需求都会继续增长。</p><p>数据方面，在强化学习中主要有两类数据：一类是少量人工生成的高价值数据，另一类是海量的机器生成数据。数据量可以非常大，但数据的质量同样关键。你如何构建数据生成算法，以及如何使用主模型，这些都非常重要。</p><p><strong>张鹏：</strong>刚才大家对o1带来的范式变化做了非常好的分析。今天三位都是创业者，正在各自的领域发展并带领团队。我想问一下杨植麟，Kimi在今年引发了大家的关注，发展得非常好。你觉得这波AI的变化，接下来会对AI产品产生什么样的连锁反应？你自己是如何看待这些变化的？它们会如何发生？</p><p><strong>杨植麟：</strong>这是个很好的问题。目前我们还处于产业发展的早期阶段，有一个特点就是技术驱动产品的比例较大。很多时候，你会根据当前技术的发展情况，最大化地提取它的潜力。所以我认为这个问题非常重要。我们需要根据新的技术进展，重新思考现在的产品能做出什么变化。</p><p>当前的技术发展，我觉得有几个关键点。<strong>首先，新的PMF（产品市场匹配）机会可能会出现。</strong>这在于两个因素的平衡。</p><p>第一个因素是，系统2思考的延迟增加，这对用户来说是一种负面体验，因为每个人都希望快速得到结果。第二个因素是，它能够提供更好的输出，甚至能完成更复杂的任务。</p><p>因此，新的PMF产生的过程，是要在延迟增加带来的负面用户体验和更高质量的输出之间找到平衡点。<strong>你需要确保增量的价值高于用户体验的损失，这一点非常重要。</strong>在更高价值的场景，特别是生产力场景中，率先会出现一些应用场景。因为在娱乐类的场景中，用户可能很难接受这种延迟的增加，这是一点很重要的考量。</p><p><strong>同时，我认为产品形态也会发生变化。</strong>随着思考范式的变化，同步、实时的聊天产品形态在一定范围内也会有所调整。未来的AI不仅仅是思考20秒、几十秒，它可能需要调用各种工具，完成分钟级、小时级，甚至天级别的任务。因此，它可能更像一个真实的助手，帮助你逐步完成任务。产品形态的设计也会随之发生重大变化，所以我认为这里面有非常大的想象空间。</p><p><strong>张鹏：</strong>我们刚才聊到了o1带来的变化，也看到了AGI领域的其他变化，比如空间智能。今天我们也看到自动驾驶、机器人等具身智能的进展。朱军老师，你怎么看待这些AI相关条线的最新技术进展？它们对未来产品或技术最终落地产业会有怎样的推动？有没有阶段性的总结和观察？</p><p><strong>朱军：</strong>大模型或者大规模预训练技术还是代表了整个范式的变化。我们讨论了很多，涵盖了从语言到多模态，再到具身智能、空间智能等领域。其实，<strong>关键还是在于如何让智能体具备交互和学习能力，这是智能发展的必然方向。</strong>决策与交互是智能中非常核心的能力，我们每时每刻都在做决策，面对的始终是未知和开放的环境。因此，在智能的发展路径上，大家都是朝着这一方向努力的。</p><p>所有这些进展，包括o1、视频生成、3D等技术，都有两个明确的方向。首先，是面向消费者和数字内容，能够让人们参与其中、讲述故事，并具备交互性。这在数字内容上肯定是非常重要的。其次，是面向实体世界和物理世界的生产力提升，不仅仅是为了展示好看的内容，更是要与物理世界结合。</p><p>现在，最好的结合点是机器人。已经有很多成功的例子展示了这一点，我们看到使用预训练范式，机器人的能力具有了通用性。比如，我们在实验室中对四足机器人进行了测试，过去它在不同的环境下需要人工调参，现在通过仿真环境生成合成数据进行大规模训练，训练后的机器人能够适应各种环境，就像更换了一个新的大脑。</p><p>这只是一个初步的例子，大家也在关注更复杂的控制和决策问题，比如空间智能。AGI L3阶段是智能体阶段，在经历了L1、L2阶段的进展之后，接下来就是L3阶段，让机器人更好地进行推理规划，并与环境进行高效交互。未来，我们将看到机器人能够接受复杂指令，完成复杂任务，通过内嵌的思维链和过程学习来执行任务，那时智能能力将会有极大的提升。</p><p><strong>张鹏：</strong>我突然想到一个问题，作为创业公司，尤其像你这样需要投入大量成本来开发基础模型的公司，你觉得过去18个月，尤其是o1的出现，是否对你的心态有了改变？未来创业公司的空间是否更大，机会是否更多？你的心态如何变化，你怎么看待未来技术创业的走向？</p><p><strong>姜大昕：</strong>从两个角度来看，一个是创新点，强化学习的出现确实与之前的范式不同。之前GPT的范式中并没有什么特别新的东西，但o1仍处于初始阶段。正如刚才两位提到的，强化学习如何与大模型结合并实现泛化，这是一个值得探索的问题。我们在做搜索路径时，是否需要人工路径干预来找到更好的路径？题目从哪里来？答案如何找到？这些都是新的、未知的领域，需要进一步探索。我相信在未来一段时间内，这些探索将加速，也一定会有更多的创新机会。</p><p>另一方面，关于算力的挑战，我之前也提到过，无论是推理端还是训练端，我们需要的算力依然非常大，尤其是当我们追求的是通用且能够泛化的推理模型时，所需的算力并不小。正如我们常常调侃得那样，<strong>“卡伤感情，没卡没感情，用卡费感情。” 但是，如果我们的目标是AGI，那么无论付出多少代价，都必须坚持下去。</strong></p><p><strong>张鹏：</strong>之前我们认为，如果按照原有的Scaling Law继续走下去，只有少数玩家能够参与进来。现在，资源门槛是否有所降低？算力方面的竞争是否会持续？你如何整合资源，让计算效率更高？</p><p><strong>姜大昕：</strong>我觉得可以分为两种不同的创新。<strong>一种是基础模型，目标是奔着AGI去，这需要非常大的投入。</strong>我们看到国外的巨头每年都有上千亿美金的预算规划。<strong>另一方面，还有大量的创新空间集中在应用层面。</strong>GPT-4所展示的智能已经在处理数字世界和物理世界的问题上取得了进展。现在，o1又将强化学习泛化到了更高的层次，正如杨植麟所说，它的上限变得更高了，因此，创新机会仍然很多。</p><p><strong>张鹏：</strong>我再问问杨植麟，你目前有C端产品，最近很多投资人都在看DAU、留存率等指标，来决定是否投资一家公司。如果你站在投资人的角度，作为一位对AI了解的技术背景投资者，你会看哪些数据来做出投资决策？</p><p><strong>杨植麟：</strong>这是一个很好的问题。首先，DAU和留存率等数据肯定是重要的指标，但我会分成几个层面来看。<strong>第一个层面是产品是否有价值，</strong>是否满足了用户的真实需求。这个与AI无关，它是产品本身的基本属性。比如留存率就是一个前置的指标。<strong>第二个层面与AI更相关，不仅要有价值，还要有增量价值。</strong>相比市面上已有的AI产品，或者像通用的ChatGPT，你的产品需要能够产生增量价值，提供ChatGPT做不到的，或者做起来体验不好的功能，这才是增量价值。这种增量价值可能来自交互的不同，或者不同的入口，也有可能是背后对应的不同资源。因此，通过这种方式产生增量价值是非常重要的。</p><p><strong>第三，不仅要有增量价值，还需要随着技术的发展，市场规模能够越来越大，而不是逐渐缩小。</strong>如果你专门研究某个非常细分的领域，未来可能面临需求减少的风险。但如果你现在已经能够产生一定的PMF（产品市场匹配），而且还有扩展到更大市场的潜力，那么这就是一个很好的创业机会。</p><p><strong>张鹏：</strong>听起来数据是需要看的，但在数据之前，产品的逻辑要成立，如果逻辑成立，数据就能证明这个产品是值得投资的。</p><p><strong>杨植麟：</strong>对。</p><p><strong>张鹏：</strong>我还有一个问题，虽然预料未来总是很难，但我想知道，未来18个月你期待看到什么样的进展？你觉得会有哪些令人兴奋的变化？</p><p><strong>朱军：</strong>现在的技术进展速度很快，很多时候我们对未来的预测其实都过于保守。回到你的问题，<strong>我预计未来18个月里，L3智能体的进展将非常令人兴奋。</strong>比如世界模型的创建和生成、虚实融合，尤其是在特定场景下决策能力的提升。它会利用推理、感知等能力来取得突破。与此同时，最近我在分析L4相关的科学发现和创新能力。<strong>我们发现，许多能力是分散在各个角落的，仍然缺乏一个能够将这些能力集成在一起的系统。</strong></p><p><strong>如果更激进一点，我认为L4在未来18个月内也会有显著的进展，特别是在科学发现和创新领域。</strong>L4还包括创意表达，比如艺术创作、视频生成等，它们能够放大大家的想象力，帮助我们将抽象的想法具象化。因此，我认为未来L3和L4都会有一些突破的苗头。</p><p><strong>张鹏：</strong>到年底前，你有哪些值得期待的进展，能提前透露吗？</p><p><strong>朱军：</strong>到年底前，我希望我们的视频模型能够更高效、更可控地为大家所用。高效意味着更低的算力成本，能够服务更多的用户；可控意味着用户能够持续表达自己的创意，进行多次交互，不断启发自己，最终目标是实现实时生成。这样一来，用户体验和用户量都会有巨大的提升，这是我今年重点要突破的方向。<strong>长远来看，未来18个月我们将进入虚实融合的场景。</strong></p><p><strong>张鹏：</strong>杨植麟呢？你未来18个月，或者未来三个月有什么进展可以分享吗？</p><p><strong>杨植麟：接下来的重要里程碑是开放性的强化学习，能够在产品上与用户交互，在真实环境中完成任务并自我进化。</strong>o1一定程度上证明了这个方向的确定性，它是AGI路上剩下的唯一关键问题，这个问题非常重要。</p><p><strong>张鹏：</strong>你期待未来18个月内，能够在这个问题上取得明确的突破和进展？</p><p><strong>杨植麟：</strong>是的，AI领域的18个月已经足够长了，会有很多进展。</p><p><strong>姜大昕：我非常期待强化学习能够进一步泛化。</strong>另一个方向是视觉领域，虽然我们期待已久，但在视频生成上仍然面临很大挑战。到目前为止，视觉理解和生成模型还是分开的。GPT-4在解决了很多问题后，唯独不能生成视频。如果我们能够解决视频生成和理解一体化的问题，就可以建立一个完整的多模态世界模型，帮助我们生成非常长的视频，并解决Sora目前的技术难题。此外，这一技术还能作为机器人的大脑，帮助智能体更好地探索物理世界，这是我非常期待的。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/FC017FrY69FmuwLMVpyX2g" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：苏扬 周小燕 李安琪，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956899271212423</id>
            <title>折叠屏手机持续增长，产品创新与挑战并存</title>
            <link>https://www.36kr.com/p/2956899271212423</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956899271212423</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 12:05:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>日前调研机构IDC公布的最新预测数据显示，预计2024年国内折叠屏手机市场的出货量或将达到1068万台、同比增长52.4%，至2028年国内折叠屏手机出货量有望超过1700万台，五年复合增长率可能会达到19.8%。此外，IDC方面预计国内折叠屏手机的出货量将会占据全球这一细分市场40%左右的份额。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_c7659aa1235c4be2b5553d11e7e0a877@000000_oswg27972oswg550oswg371_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此前在2023年，国内市场便成为了折叠屏手机的主要战场。在IDC的年度分析报告中显示，2023年国内市场折叠屏手机出货量达700.7万台、同比增长114.5%。在同期全球折叠屏手机出货量约为1860万台的背景下，国内市场出货量占比就已提升至37.67%。</p><p>这一市场现状的背后，无疑是国内厂商在这一细分市场中持续创新的必然结果。随着小米、vivo、华为、OPPO、荣耀等国内头部厂商持续突破折叠屏的技术难点，并不断改善相关机型的耐用性、屏幕折痕、软件适配等关键痛点，也使得国产折叠屏手机在市场上受到了越来越多的关注，也实现了市场份额的快速增长。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_1c3a30078464426eb02384a467cc6ffc@000000_oswg27729oswg550oswg374_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>凭借独特的产品形态和相对更为灵活的使用方式，折叠屏手机不仅在国内市场持续升温，在全球范围同样也受到了诸多关注。据调研机构Counterpoint公布的数据显示，这类机型在西欧、拉丁美洲，以及亚太等多个重要市场的出货量均有显著增长。</p><p>事实上，如今折叠屏手机的兴起不仅是产品形态的进化，同样也是智能手机市场在日益激烈的竞争环境下，相关厂商探索产品差异化的实践。这类产品凭借着独特的屏幕可折叠设计、更大的屏幕尺寸，也满足了用户在更多场景中的不同需求，因此随着相关技术的逐步成熟，也有望成为未来这一市场新的增长点。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_6d3ef4b4b8cd4662ae60659b60bcba71@000000_oswg20601oswg550oswg390_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>近期，华为方面还推出了业内首款量产的三折叠机型Mate XT非凡大师，由于具备全新的产品形态，因此也引发了外界的众多关注。然而这一产品形态的实现显然并非易事，华为方面针对性地对目前折叠屏手机的“无人区”进行技术攻关，由此也实现了率先量产。</p><p>目前制约折叠屏手机向三折叠形态进化的痛点来自多个方面，其中屏幕两次折叠无疑是首要难点。由于屏幕折叠方式的不同，将会带来更多耐弯折的挑战，同时还需要兼顾外折抗挤压、内折抗拉伸的要求，不仅增加了屏幕应力的复杂度，也提高了对机身结构稳定性的要求。通过引入多向弯折柔性材料，Mate XT非凡大师的屏幕耐弯折能力提升了25%，配合非牛顿流体+322cm² UTG玻璃组成的复合超韧叠层结构，还将其抗冲击能力提升了30%，也在一定程度上保障了机身的耐用性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_8cc0591e1a7148828f89be8e1072b570@000000_oswg23816oswg550oswg380_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>电池相关技术同样也是制约三折叠手机出现的难点，由于折叠屏手机的结构决定了其内部空间更加局促，不仅考验相关元器件的堆叠，对于电池体型的制约也更多。据悉，Mate XT非凡大师此次就搭载了全新架构的硅负极电池，采用三电芯并联方案，厚度低至1.9mm，为机身的纤薄化提供了帮助。</p><p>此外对于所有折叠屏手机都非常重要的铰链，依旧是实现三折叠形态的关键所在。由于需要再同一块屏幕上实现两种完全不同的翻折，因此不仅要求极高的精密度与联动性，还需要在耐用性和成本之间找到平衡。此次Mate XT非凡大师所采用的华为天工铰链系统就通过引入内嵌设计，将一体连杆结构外折铰链和嵌入式滑轨结构内折铰链整合，实现了双轨联动、并降低了厚度。</p><p>虽然有着诸多的创新点，但这款机型的部分技术并非华为首创。其中在电池方面，随着硅碳负极技术的进步，如今手机电池的能量密度、体形等方面均有了大幅度的进步，例如此前vivo X Fold3 Pro所采用的蓝海电池，能量密度就提升至780Wh/L，同时其体形方面的优势也帮助这款机型将屏幕展开后的机身厚度控制在5.2mm。</p><p>同时目前的多电芯并联方案也并不鲜见，例如realme方面更是有“卫星帆板”折叠电池的技术储备，其四块电芯中每个电芯的厚度仅2.9mm，这也是realme 320W超光速秒充的基础之一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_630c42897645421bb1ef51d70738ecf0@000000_oswg31568oswg550oswg313_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>铰链作为折叠屏手机的核心零部件之一，各大主流厂商也早已在这一方向开卷。尽管早期的铰链还存在精密化、成本等方面的局限性，但如今随着工艺、技术、材料等方面的大幅升级，也已经带来了实打实的进步。例如小米龙骨转轴2.0就将零部件数量减少至137个，不仅降低了生产难度，还大幅减少了潜在故障点。</p><p>尽管折叠屏手机这一细分市场目前依然保持着高速增长的态势，并且相关厂商也在着力解决技术局限所带来的痛点，但要将其塑造为用户的刚需，仍面临着诸多挑战。这些困难不仅体现在技术层面的持续突破上，更涉及到用户体验和生态建设等更多的领域。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_739a3a115408480896a793b12bfc526c@000000_oswg17182oswg550oswg336_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中，内屏适配问题作为现阶段大折叠发展过程中的一块“硬骨头”，始终是相关厂商难以回避的难题。尽管近年来折叠屏手机、特别是大折叠在生产力应用的适配上取得了一定进展，例如优化了多任务处理、分屏显示等功能，然而相较数量庞大的APP，这些提升并未能完全解决局限性。</p><p>因此当折叠屏手机进化至三折叠形态，屏幕面积的提升自然也就对内屏的适配提出了更高要求。毕竟更多的屏幕形态、更复杂的交互逻辑，也就意味着需要投入更多资源进行相应的适配。因此如何将软件适配进一步完善，将会是所有折叠屏手机厂商必须要面对的课题。</p><p>另一方面，折叠屏手机在形态不断创新的同时，自然就要面对轻薄与功能性之间的权衡。如今折叠屏手机的轻薄化已经成为趋势，现阶段的在售产品中，大折叠的重量通常都保持在220g左右。然而对三折叠形态的机型而言，屏幕尺寸的增加无疑就会对轻量化设计提出了更多的挑战。</p><p>尽管华为方面通过采用先进材料、优化结构设计等方式，在一定程度上减轻了Mate XT非凡大师的机身重量，但298g的重量势必会对用户体验造成一定的影响。因此如何在保证产品形态与功能完整性的同时，进一步减轻机身重量、提升便携性，后续还需要相关技术的不断提升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_4b0092c98e3a40fc8efebd2569957a85@000000_oswg14127oswg550oswg368_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外硬件配置与顶级旗舰机型的落差，则是折叠屏手机如今所需要面对的另一项长期挑战。由于折叠屏手机在结构设计、屏幕技术等方面的特殊性，使得其硬件配置往往受到一定的局限。但从长远来看，两者的配置差异大概率会在相当长的时间内存在，所以如何通过其他方面来抹平体验上的距离，也将成为相关厂商需要解决的一个难题。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649871412&amp;idx=4&amp;sn=5e8e7507f708cb41526f2439acb9d5dd&amp;chksm=867e69f9086fe9f6cc9fa93c51aee7fb77a3b9003586bac8314bd196a54bdb3424c93f9812c3&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956846982494851</id>
            <title>港大发布智能交通大模型全家桶OpenCity，打破时空零样本预测壁垒，训练速度最多提升50倍</title>
            <link>https://www.36kr.com/p/2956846982494851</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956846982494851</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:58:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>【导读】</strong>近日，香港大学发布最新研究成果：智能交通大模型OpenCity。该模型根据参数大小分为OpenCity-mini、OpenCity-base和OpenCity-Pro三个模型版本，显著提升了时空模型的零样本预测能力，增强了模型的泛化能力。</p><p>精确的交通流量预测对于提升城市规划和交通管理效率至关重要，有助于更合理地分配资源并提升出行质量。</p><p>然而，现有的预测系统在处理未知区域的交通预测，以及进行长期预测时，常常无法达到预期效果，这些挑战主要源于交通数据在空间和时间上的不一致性，以及在不同时间和地点的显著变化。</p><p>基于「开发一种具有高度通用性、鲁棒性和适应性的时空预测模型」的思路，香港大学、华南理工大学等机构的研究人员提出了一个创新的基座模型OpenCity，能够识别并整合来自多个数据源的时空模式，以增强在不同城市环境中的零样本学习能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_1ce00d5b33a04cbb9a0d47f45a14c081@46958_oswg33601oswg1080oswg161_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文链接：http://arxiv.org/abs/2408.10269</p><p>代码链接：https://github.com/HKUDS/OpenCity</p><p>OpenCity结合了Transformer和图神经网络技术，以捕捉交通数据中的复杂时空关联。通过在广泛的、多样化的交通数据集上进行预训练，OpenCity能够掌握丰富且具有广泛适用性的特征表示，这些特征适用于多种交通预测情境。</p><p>实验结果显示，OpenCity在零样本学习方面取得了显著成效。</p><p>此外，OpenCity的可扩展性也得到了验证，这表明有望构建一个能够满足所有交通预测需求的系统，并且能够以较低的额外成本适应新的城市环境。</p><h2><strong>概述</strong></h2><h3><strong>现有问题</strong></h3><p>C1. 空间泛化：现有的交通预测模型在空间泛化方面存在限制，难以适应不同地区因基础设施和人口特征不同而表现出的各异交通模式。在现实条件下，全面部署传感器来收集数据并不可行。因此，开发一种能够在有限数据支持下适应新区域的模型显得格外关键。这种模型能够降低跨城市部署的成本，并确保交通预测系统在多元化的城市环境中有效运作，无需频繁重训练或调整。</p><p>C2. 时间泛化与长期预测：现有的交通预测模型虽然能够较好地处理短期预测（如未来一小时内），但在进行数小时甚至数天的长期预测时则效果不佳。模型难以适应城市环境中随时间变化而变化的复杂交通模式，这一点限制了城市规划者和交通管理者制定有效长期策略的能力。</p><p>C3. 通用表征学习与时空异质泛化：开发能够广泛适用的交通模型，关键在于开发能够广泛适用的交通模型，通过学习通用的交通动态特征实现泛化。这种泛化学习使得模型能够适应不同的应用场景，即便是在缺乏特定场景训练数据的情况下也能运行。考虑到城市交通的多样性及其时空分布的显著变化，模型需要具备适应这些变化的能力，以保持其功能性和灵活性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_18f5baafc65c48b790778acc1deaaa1a@46958_oswg105088oswg1080oswg363_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图1 左图展示了不同交通数据集之间的数据分布差异，突显了开发能够适应这些分布差异的模型的必要性。右图则比较了OpenCity在零样本条件下的表现与使用全样本数据的基线模型的表现。结果表明，尽管OpenCity面对时空异质性分布偏移的挑战，其性能仍可与全样本基线模型匹敌</p><h3><strong>论文贡献</strong></h3><p>（1）通用时空建模。OpenCity针对城市交通在不同地区及时间内的多样性和变化进行专门设计。</p><p>（2）卓越的零样本预测能力。OpenCity在未经特定区域训练的情况下，展示了超越常规模型的性能，这突显了其泛化特征学习的能力，并允许该模型在新环境中快速部署，减少了重训练的需求。</p><p>（3）快速适应性。OpenCity在多个时空预测任务中显示了其广泛的适用性，能够快速地适应各种场景，实现灵活的部署。</p><p>（4）扩展能力。OpenCity展现了良好的扩展潜力，这意味着它能够在几乎无需额外训练的情况下有效地适应未知环境。</p><h2><strong>方法</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e46667b7903a49bba032a4118c453bc9@46958_oswg215187oswg1080oswg298_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图2 OpenCity整体框架</p><h3><strong>用于分布偏移泛化的时空嵌入</strong></h3><p><strong>上下文归一化</strong></p><p>传统方法通常依赖于训练数据的统计特征，例如均值和标准差，来进行数据的标准化处理。然而，当测试数据表现出与训练数据在地理空间上无重叠的异质性时，这些统计参数可能不再适用，也难以适应。为了克服这一挑战并满足零样本交通预测的需求，采用了实例归一化IN(⋅)处理数据。</p><p>该方法利用每个个区域的单个输入实例</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_49e0b9d5f96945cb96f2179753e10512@46958_oswg1667oswg136oswg42_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>的均值μ(Xr)和标准差σ(Xr)进行数据标准化，而不依赖于整个训练集的统计信息。相关研究表面实例标准化能有效减轻训练数据与测试数据之间分布差异的问题，形式化如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_bba3b3c6ab6142fc86f3cd5aa1fec5d8@46958_oswg4615oswg450oswg114_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>用于高效长期预测的Patch嵌入</strong></p><p>OpenCity旨在应对长期交通预测的复杂性，特别是处理增加的输入时间步长，这会导致计算资源和内存需求显著增加。为减轻这一负担，采纳了一种基于时间维度的Patch分割策略。在此策略中，设定了Patch长度P，用于确定每个Patch包含的时间步数；同时设置了步长S，用于定义连续Patch之间的重叠程度。采用此Patch处理方式后，输入数据的形状发生了变化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_b7250f296c99411f96fbaf0747aa1a69@46958_oswg2066oswg178oswg50_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，这里𝑁为块的数量，</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_6bf09999c3b84225905a53a18d1f22ee@46958_oswg1754oswg202oswg50_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。</p><p>研究人员选择将一小时的交通数据设定为一个Patch的长度，并设置步长S=P，这样的配置帮助模型有效捕捉并适应交通数据在更长时间跨度的变化趋势。</p><p>此外，采用Patch处理方法显著减少了对计算和内存的需求，从而实现了更高效和可扩展的长期交通预测。</p><p>Patch处理完成后，对数据应用线性变换和正余弦位置编码PE，以获取最终的时空嵌入表示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_7f2f9db821e3463c9405c78ab52d37ad@46958_oswg1827oswg162oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>被用于后续模块的输入，如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e9e313ba66a04d89893194266e58dd86@46958_oswg3590oswg408oswg64_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>时空上下文编码</strong></h3><p>为了捕获交通数据中的复杂时空模式，OpenCity模型整合了时间与空间的上下文信息。</p><p>通过充分考虑这两个维度的多个因素，OpenCity能更全面地洞察影响交通模式的多元因素。这种整体方法使得该框架能够在各种时间段和地理区域中提供更精确的预测。</p><p><strong>时间上下文编码</strong></p><p>为了使OpenCity成功地捕捉交通数据中的独特时间模式，利用了诸如一天中的时间</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_43121412dc92464a889e9c4b4143d363@46958_oswg1749oswg140oswg44_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>和一周中的某一天</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_75658438ec8a49f8a02eec41b4e20acd@46958_oswg1812oswg142oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>等时间特征来识别周期性关系，并通过线性层转换这些时间特征，生成反映时间上下文的特定嵌入。通过精确模拟交通流的周期性特征，的方法能够在长期预测中达到高精度。</p><p>时间上下文的编码过程融合了Patch操作和时空嵌入的对齐，具体实现如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_44c1248bcd3344288df21be7c691c06a@46958_oswg4582oswg432oswg84_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>空间上下文编码</strong></p><p>鉴于地理特征的多样性，每个区域的交通模式具有其特有的特征（例如，交通枢纽的流量通常较高）。为了有效捕捉这些区域性特征，在交通网络模型中引入了空间上下文。</p><p>首先，进行了拉普拉斯矩阵的标准化处理：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_584f86dc8fa3443d9ccd6d9e23375414@46958_oswg2492oswg350oswg44_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，其中I和D分别是单位矩阵和度数矩阵。</p><p>然后执行特征值分解，得到</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_75c813e3b60f43d0978343b7f36d5a05@46958_oswg1626oswg178oswg50_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，其中，U和Λ分别代表特征值和特征向量。</p><p>选择了最小的k个非零特征向量作为区域嵌入s，用以编码交通网络的结构特性。这些嵌入随后经过一个线性层的处理，用以产生最终的空间编码</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_08424401ee01426b944c767955267de4@46958_oswg1805oswg154oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。</p><h3><strong>时空依赖建模</strong></h3><p><strong>时间依赖建模</strong></p><p>OpenCity利用新提出的TimeShift Transformer架构，专注于捕捉时间依赖性。</p><p>该方法从两个主要方面识别交通模式：</p><p>（1）周期性交通模式。模型能够识别交通中的周期性和重复模式，如每小时、每日和每周的循环。通过对这些周期性变化的编码，的方法可以更精确地解析交通网络中的规律性。</p><p>通过时间嵌入D和空间嵌入C来捕获交通模式的周期性特征。目标在于探索历史交通模式与未来趋势之间的关系。时间嵌入被细分为历史时间信号和未来时间信号两部分：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_02b80013d5624972b3a613cb527732b6@46958_oswg2239oswg222oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d70a3fe3f38a4d8fb93f4c50b9b59d41@46958_oswg2219oswg222oswg46_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。</p><p>的模型专门建模了历史时间和未来时间的映射模式，这使得它能够更有效地学习和应用交通时间序列的周期性特征。此过程通过构建一个时间转移的多头注意力机制来完成，其中将未来的时空嵌入作为查询（Query），将历史的时空嵌入作为键（Key），并将历史时空数据的表示作为值（Value）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_74e0ce0bb76a4ef59f8b60737e8bc007@46958_oswg19099oswg908oswg186_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中，</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a1d873d8c98d47f2b90db26d4d5f18c9@46958_oswg2048oswg128oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>和</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_74a23184ff9a44d8bd75ca16540d6ef2@46958_oswg2297oswg174oswg46_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为权重矩阵，δa为dropout操作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_c38b46ccd50a4e839b2b0e51e9226db9@46958_oswg1950oswg162oswg44_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为更新后的空间嵌入，</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_043655027a0549a79d5f5b2a6ff7062a@46958_oswg2228oswg180oswg50_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为来自第h个注意力头的周期关联编码模块的输出。</p><p>引入RMSNorm以提升训练过程的稳定性。通过明确地建立历史与未来时间信息之间的联系，OpenCity具备了识别周期性的时空交通模式的能力。</p><p>（2）动态交通趋势。除周期性模式外，时间编码器还能捕捉交通数据随时间发展的复杂和非线性动态趋势。</p><p>该模块旨在探索不同时间点之间的动态依赖性。例如，交通事故等突发事件可能导致交通速度和流量急剧变化。</p><p>为了应对这种情况，采用了一种改进的注意力机制，与周期性交通模式编码类似。</p><p>其区别在于，查询（Q）、键（K）和值（V）的输入被改为上一步的归一化输出（M）。此调整帮助模型专注于学习不同时间点之间的动态依赖关系，而非仅限于周期性模式。</p><p>由此产生的时间表示</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_171122db8e16454ab1c1f271bc551cdc@46958_oswg2020oswg192oswg44_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>能够有效捕捉这些动态的时空联系。</p><p><strong>空间依赖建模</strong></p><p>由于在交通预测中，交通网络展现出显著的空间相关性，捕获空间依赖性对模型设计至关重要。一个区域的交通状态通常会受到其邻近区域状态的影响。为了有效学习这种空间联系，采用了图卷积网络（GCNs）：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_02029f2eec6849eb9cc52c41dc3b40b5@46958_oswg4393oswg512oswg84_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_7ab722029e034fa58522438a4885d6b6@46958_oswg766oswg42oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>是归一化的邻接矩阵，𝛼用于平衡原始信息的保留程度。残差连接、RMSNorm（RN）和SwiGLU激活函数被用于后续的运算。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_870c8384c1a14429a3ecef4cae6ebeeb@46958_oswg12760oswg644oswg150_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>式中，</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_68a1ef2f79704314a9852c385cc24c65@46958_oswg2167oswg148oswg58_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>代表第l层时空编码网络的最终输出，σ是Swish激活函数，</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_8ed58a2969c0433b8a7401443d8ce207@46958_oswg3098oswg282oswg46_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>是可训练权重。通过叠加多层时空编码网络，OpenCity具备捕获复杂的时空依赖性的能力，从而使其能够学习交通网络内的复杂相互作用。</p><h2><strong>实验</strong></h2><h3><strong>零样本 vs. 全样本</strong></h3><p>全面评估了OpenCity在零样本条件下的性能，测试涉及跨区域、跨城市和跨类型三个维度，并将其与基线模型在全样本条件下的性能进行了对比，结果如表1所示。</p><p><strong>（1）优越的零样本预测性能。</strong></p><p>OpenCity在零样本条件下取得了突出成就，能够在无需额外微调的情况下超越多数基线模型。这突显了模型在掌握复杂的大规模交通数据时空模式、提取适用于多种任务的通用知识的可靠性与效率。</p><p>在多个数据集的测试结果下，OpenCity常常位于前两名，即便不是最佳，其与最优性能（MAE）的差距也控制在8%之内。</p><p>这种卓越的零样本预测能力展现了OpenCity在处理多样化交通数据集时的广泛适应性和普遍性，无需大规模的重新训练。</p><p>其核心优势在于能迅速适应新环境，大幅降低了传统监督学习方法所需的时间和资源，为实际应用带来了明显的优势。</p><p><strong>（2）卓越的跨任务泛化能力。</strong></p><p>对OpenCity进行了跨四个不同交通数据类别的评估，包括交通流量（CAD3、CAD5）、交通速度（PEMS07M、TrafficSH）、出租车需求（CHI-TAXI）和自行车轨迹（NYC-BIKE）。基线分析显示，虽然多种模型在特定类型数据上表现出色，但没有一个能够在所有类别中一直维持最优结果。</p><p>相比之下，OpenCity在所有测试类别中均呈现出高质量的成果，展示了其卓越的稳定性和多功能性。此外，为了评估OpenCity框架的通用性，特别测试了其在跨类别零样本泛化能力上的表现（以NYC-BIKE为例）。</p><p>结果表明，OpenCity在多个评价指标上均展现了出色的成绩，进一步验证了其对多样数据类型的适应性和普适性。</p><p><strong>（3）优越的长期预测性能。</strong></p><p>OpenCity架构在长期交通预测任务中的表现优于基线方法，这是其显著的优势之一。许多现有模型在预测时间范围延长时常常难以维持准确性，原因在于这些模型可能过度依赖历史数据，未能有效捕捉交通状况的动态变化和演进。</p><p>相反，OpenCity能够从广泛的交通数据源中学习到关键的时空特征，使其能够提供稳定而可靠的预测，即便在交通模式随时间发生变化的情况下也是如此。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e0443e96849a426cb3477f23e6d729db@46958_oswg265777oswg1080oswg429_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表1&nbsp;零样本 vs. 全样本性能</p><h3><strong>有监督预测性能</strong></h3><p>为了进一步验证OpenCity的性能，进行了监督学习评估。在这一评估中OpenCity采用一体化配置，在单个数据集上与基线模型进行了全面的端到端训练和测试比较。</p><p>表2中的结果显示，OpenCity在监督学习环境中展示了出色的性能，并在大多数评估指标上保持了领先地位。此外，观察到大多数基线模型在CAD-X数据集上的表现欠佳，这可能是由于它们倾向于过度拟合历史的时空模式，难以适应长期依赖的交通模型。</p><p>相反，OpenCity架构通过有效地从预训练阶段提取通用的周期性和动态时空特征，成功克服了由时间和地点的分布偏移引起的预测性能降低问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_262264d012fb4d269695d13f934e055a@46958_oswg227620oswg1080oswg269_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表2&nbsp;有监督任务评估</p><h3><strong>模型快速适应能力探索</strong></h3><p>本节中探讨了OpenCity在下游任务中的快速适应能力。对预训练阶段未出现的交通数据类型实施了“高效微调”策略。具体做法是仅更新模型的预测头部（最后一个线性层），并限制训练周期为至多三个。</p><p>如表3所示，虽然OpenCity在一些指标上的零样本性能最初不如基线模型的全样本性能，这可能归因于交通模式和数据采样的差异。然而，通过高效微调，OpenCity的性能显著提升，超越了所有比较模型。</p><p>特别值得注意的是，OpenCity的训练时间仅需基线模型的2%至32%。这种快速的适应性突显了OpenCity作为基本交通预测模型的潜力，展示了其对新的时空数据类型的迅速适应能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_c1d4a57776184a068f9d503b97c3e85d@46958_oswg334651oswg1080oswg745_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表3&nbsp;OpenCity快速适应能力评估</p><h3><strong>消融实验</strong></h3><p>（1）动态交通建模的重要性。</p><p>-DTP。除动态交通建模模块后，性能有所下降。这说明该模块对于有效分析最新交通模式并适应突发的交通状况以优化预测至关重要。</p><p>（2）周期性交通转移建模的作用。</p><p>-PTTM。在模型中取消了周期性编码，选择直接将时间和空间上下文融入时空嵌入。性能的下降表明，通过映射历史与未来时间对之间的交通流，OpenCity 能够有效捕获影响时空模式演变的关键规律。</p><p>（3）空间依赖性建模的作用。</p><p>在-SDM变体中，移除了空间编码模块。分析显示，通过学习空间关系，模型的时空预测能力得到了显著提升。模型通过整合依赖于空间区域的交通信息，有效地识别了动态交通流模式，为零样本交通预测提供了关键支持。</p><p>（4）时空上下文编码的作用。</p><p>在移除了时空上下文信息编码后（-STC），性能显著下降。时间上下文信息帮助模型识别并学习特定时段的常见交通模式，同时区域嵌入则提供了区域特定的关键特征。这些因素共同为理解城市间的动态时空模式提供了深刻的洞察。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ddea59a714ef4c82a7350f7fa3913932@46958_oswg105993oswg1080oswg698_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图3&nbsp;OpenCity消融实验</p><h3><strong>模型可扩展性研究</strong></h3><p>如图4所示，本节探索了OpenCity在数据量和参数规模这两个维度的可扩展性。</p><p>对于参数规模，考察了三个不同的版本：OpenCity-mini（2M参数）、OpenCity-base（5M参数）以及OpenCity-plus（26M参数）。在数据规模的可扩展性方面，对于OpenCity-plus模型，分别使用了10%、50%和100%的预训练数据，以研究增加数据量所带来的优势。</p><p>为了便于比较，使用相对预测误差作为纵轴的度量标准。结果显示，随着参数数量和数据量的增加，OpenCity的零样本泛化能力也逐渐提升。</p><p>这表明OpenCity能够有效地从大规模数据集中提取有用信息，并通过增加参数规模来提高其学习能力。这种可扩展性的展示支持了OpenCity成为广泛应用于交通领域的基础模型的潜力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_47094fe4826b468c8bebaa0867f007d8@46958_oswg132213oswg1080oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图4&nbsp;模型可扩展性研究</p><h3><strong>与大规模时空预测模型的比较</strong></h3><p>在本节中，对OpenCity与其他先进的大型时空预训练模型进行了比较，包括以其出色的零样本泛化能力而著称的UniST和UrbanGPT。评估使用的是三个模型在预训练阶段均未接触过的CHI-TAXI数据集。</p><p>如表4所示，OpenCity在这些先进的大型时空模型中显示出了显著的性能优势。此外，与UrbanGPT相比，OpenCity和UniST表现出了明显的效率提升。这可能是因为UrbanGPT需要依赖于大型语言模型（LLM）以问答格式进行预测，从而限制了其处理批量数据的效率。</p><p>OpenCity在性能和效率方面的卓越表现突显了其在交通领域作为强大大规模模型的潜力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_0637bf4b5e77443f8497d23f28e9778b@46958_oswg87570oswg1080oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表4 与大规模时空预测模型的比较实验。</p><h2><strong>总结与展望</strong></h2><p>该论文提出了OpenCity，一个针对交通预测设计的可扩展时空基础模型，它在多种交通预测场景中展示了卓越的零样本预测能力。</p><p>该模型核心采用了Transformer编码器架构，用以建模动态的时空依赖性，并通过在大型交通数据集上预训练，使得OpenCity在多种下游任务中均表现出色，其零样本预测性能可与全样本设置下的先进模型媲美。</p><p>OpenCity框架能够有效处理不同分布的数据，并展现出高效的计算性能。鉴于其所显示的良好扩展性，OpenCity为开发一个强大且适用于多种城市环境和交通网络的通用交通预测解决方案奠定了基础。</p><p>参考资料：&nbsp;</p><p>http://arxiv.org/abs/2408.10269&nbsp;</p><p>https://sites.google.com/view/chaoh&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/GEX3PGhRHHjoOKS9Ewo7yQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：LRST&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956741130352772</id>
            <title>从IPO到资产通证化再到IMO，Web3进入服务实体企业的拐点时刻</title>
            <link>https://www.36kr.com/p/2956741130352772</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956741130352772</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:57:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近，有个“圈外”的朋友给我分享了一则新闻：</p><blockquote><p>在2024年8月28日，香港金管局公布的Ensemble项目沙盒中，蚂蚁数科与朗新科技基于内地充电桩资产发行的RWA（现实世界资产），成为香港金管局Ensemble项目的首批四个用例之一。</p><p>RWA首单尝试中，朗新旗下新电途作为新能源数字化平台的运营方和服务方，将平台上运营的部分充电桩作为RWA锚定资产，基于可信数据在区块链上发行“充电桩”数字资产，每一个数字资产代表对应充电桩的部分收益权。</p></blockquote><p>常看本专栏的朋友肯定不会陌生，RWA指的是通过区块链技术转化为Web3的现实世界资产。而有形资产RWA的上链“通证化”，通常依赖于结合AIoT和Web3的DePIN（去中心化物理基础设施网络）。</p><p>发现越来越多的小伙伴对RWA和DePIN这个领域感兴趣，自然我也喜出望外！</p><p>“我们已经（实现了）从公司上市到现在资产上市。蚂蚁数科支持朗新案例的首单RWA，融资1个亿，相当于mini-IPO，就是把资产上市了。”蚂蚁数科CEO赵闻飙对于本项合作的点评直指本质。</p><p>“<strong>RWA与IPO有个显著区别，就是融资主体从企业变成了优质资产。</strong>类似企业融资需要尽职调查，实物资产融资也需要做可信调查，而Web3技术解决了实物资产的可信问题。”</p><p>“<strong>RWA作为链接数字与实体世界的桥梁，是金融回归本源，服务实体经济高质量发展的生动实践。</strong>”第十三届全国政协委员、中国证券监督管理委员会原主席肖钢称。</p><p>本次有形资产RWA的发行，也就是资产通证化，尤其具有里程碑式意义，因此今天这篇文章我们就围绕这则案例来解读Web3技术出海的创新路径。</p><h2><strong>RWA 打通传统行业的融资堵点</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_fe89f727f7ca4ab088649ba46d48b385@000000_oswg318955oswg1080oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以望见，不远的未来，10个充电桩、几十辆汽车、100块电池，都不再是普通硬件，它们都可能变成数字资产，为项目带来融资。</p><p>根据朗新科技董事长徐长军介绍，当前85%的充电服务商是中小企业，82%以上的运营商只有10个以下的充电桩，50%以上的运营商投资小于100万。目前，在朗新科技旗下第三方聚合充电服务平台上，聚合了1600个新能源运营商，有14万座充电场站，超过140万的充电枪/充电桩。</p><p>在上述案例中，朗新科技将9000多个新能源充电桩作为锚定资产，在区块链上发行并融资1亿元。</p><p>探究这个案例的技术原理，其实并不复杂，朗新旗下“新电途”将平台上部分充电桩作为RWA锚定资产，通过蚂蚁数科旗下蚂蚁链的Web3和AIoT技术融合，构成DePIN，使每一个数字资产代表对应充电桩的部分收益权。</p><p><strong>RWA现实世界资产具体包含什么？</strong></p><p><strong>RWA通常被划分为两大类别：有形资产和无形资产。</strong></p><p>有形资产的范畴包括房地产、艺术品、贵金属以及交通工具等。而无形资产则涵盖股票和债券、知识产权、投资基金、合成资产、收入分成协议、现金和应收账款等。</p><p>无论是实物资产，还是数据资产，只要资产优质，即使公司本身规模不够大、或者公司财务状况不够上市或银行融资，它都有可能通过RWA获得融资。</p><p><strong>什么是资产通证化？</strong></p><p>对于这一概念，许多人可能尚感陌生。为了更好地理解，我们可以将其与“资产证券化”进行比较。</p><p>由于“证券化”一词暗示了在二级市场，即交易所中的可交易性，而“通证化”则字面上理解为一种可以流通的凭证。</p><p>那么，通证化究竟应用于何处呢？答案是在Web3领域。</p><p>我们将两者结合理解，<strong>资产通证化意味着将现实世界中的资产通过唯一标识认证的方式转移到区块链上进行运作，并实现融资和交易。</strong></p><p>朗新集团的主营业务包括新能源配套服务，例如充电桩和虚拟电厂等。通常而言，此类企业在一级市场的融资途径有限，主要包括企业抵押融资贷款、发行企业债券、发行信托产品等。而且朗新集团作为一家上市公司，其在一级市场的融资行为显得尤为谨慎，原因在于对股价可能产生的剧烈波动的担忧。然而，为了企业的扩张与发展，资金需求巨大，因此出现了一种创新的融资方式——资产通证化融资。</p><p><strong>资产通证化的融资主体不再是公司，而是对应的实物资产，但是普通的实物资产并没有产权证明，难以融资，这是DePIN需要解决的问题。</strong></p><p>以充电桩为例，若要利用它们进行融资，传统上需要抵押其所有权和运营权。但充电桩不同于房产等具有产权证明的资产，无法直接进行抵押。也不可能将充电桩转移至仓库并加以锁定，除非愿意安排专人每日现场监督，这导致许多金融机构对这类项目望而却步，因为过程繁琐且成本高昂。</p><p>当前，区块链技术的应用使得为每个或每批充电桩创建一个“产权证明”成为可能，进而实现将这些产权证明用于抵押。这一过程允许以分批和分量的方式进行抵押融资。</p><p>这种科技创新所引领的新型融资模式，为实体经济与资本市场之间架设了一座桥梁，使得融资方式更加多样化和实际化。</p><p><strong>RWA这个市场规模有多大呢？</strong></p><p>花旗2023年发布的一份报告预计，RWA将会是带动区块链行业进入数十万亿美元规模的杀手锏，几乎任何能够以价值表示的资产都能被代币化。私人部门/非上市公司资产的代币化将增长80倍以上，到2030年将达到约4万亿美元的规模。</p><p>根据BCG和ADDX的研究，全球非流动性资产的代币化将会产生16万亿美元规模的市场（这将接近10%的2030年全球GDP）。</p><h2><strong>由AIoT+Web3构建的数字底座是资产通证化的基石</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_b9b9b25ef57e440ea7dcbee6baa060e5@000000_oswg611733oswg1080oswg420_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由AIoT与Web3共同构建的DePIN数字底座，为资产通证化提供了坚实的基础。</p><p>在这个数字化时代，AIoT技术通过智能设备和传感器收集大量数据，实现了物理世界与数字世界的无缝连接。而Web3，作为新一代互联网技术，利用区块链、去中心化应用（DApps）和智能合约等技术，为数据的可信度和安全性提供了保障。</p><p>DePIN作为结合了AIoT和Web3的数字底座，不仅能够实现资产的高效管理和实时监控，还能通过通证化将实体资产转化为数字资产。</p><p>通证化使得实体资产的流通和交易更加便捷，降低交易成本，提高市场效率。此外，通证化资产还可以实现去中心化管理，减少了中介机构的介入，进一步提升了资产的透明度和安全性。</p><p>通证化的背后是金融创新的力量。</p><p>其实金融创新一直是推动经济发展的重要驱动力。在不同的历史时期，各种资本形式在经济舞台上扮演了关键角色。例如，在机械化时代，财团资本发挥了巨大作用；进入电气化时代后，金融资本成为经济发展的核心力量；而在信息化时代，风险资本则成为推动创新和经济增长的重要引擎。如今，随着数字化时代的到来，加密资本逐渐浮出水面，也开始对经济发展产生深远的影响。</p><p>可以看到，每一次技术浪潮的兴起都伴随着金融创新的涌现。从早期的资产证券化，即将传统的实物资产转化为可交易的证券，到如今的资产通证化，即将各种资产转化为数字代币，金融创新不断推动着经济的变革和发展。这些创新不仅提高了资本的流动性和效率，还为投资者提供了更多的投资机会和风险管理工具。</p><p><strong>资产通证化并不是终点，CHIP（Community Hardware Incentive Program）或者IMO（Initial Miner Offering）或许是更加顺应加密资本崛起趋势的创新融资方式。</strong></p><p>在文章《技术革命,金融创新和组织变革的融合创新:DePIN+CHIP》中，我曾对CHIP做过介绍。</p><p>它通过激励措施，鼓励社区成员购买和运行硬件，参与网络建设的机制。社区成员购买和运行DePIN硬件，为网络的物理基础设施做出了贡献，并获得相应的功能型代币奖励。这种机制强调了激励措施对社区参与的促进作用，通过正向激励引导更多的社区成员加入到网络建设中来。</p><p>在传统的股权融资模式下，投资者购买的是项目公司的股份，从而获得了公司未来收益的分成权。而在CHIP模式下，投资者购买的是DePIN硬件等算力设备，从而获得了参与项目共识、获得代币奖励的权利。</p><p>需要特别注意的是，由于DePIN与物理世界高度相关，这些资产的运行直接关系到每个人的衣食住行等基本需求。因此，为了保障公众利益，维护市场稳定，这些资产的交易必须在合规的交易所进行。</p><p>合规交易所作为DePIN资产交易的重要场所，承担着至关重要的责任。首先，它需要对每一个上线交易的项目进行严格的审核和尽职调查，确保项目的真实性、合规性和可行性。其次，它需要提供一个安全、公平、透明的交易环境，保护投资者的合法权益。再次，它还需要与监管机构保持密切沟通和协作，遵守相关法律法规，共同维护市场秩序。</p><p>只有在合规交易所的保驾护航下，DePIN资产的价值才能得到真实反映，投资者的利益才能得到有效保障，这一新型基础设施形态才能健康有序地发展，为实体经济赋能，为人们的美好生活添砖加瓦。</p><h2><strong>DePIN是实体企业技术出海的新模式与新选择</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_64c0613d8f1046458968e97c68cd40ab@000000_oswg952039oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随着全球经济放缓，投融资活动减少。2023年，东南亚的融资活动降至六年最低，88%的投资者认为退出环境更加艰难。这导致许多出海的中国企业面临资金难题。</p><p>如今，中国企业出海，已经从过去的产品出口，转变为制造出海、品牌出海。这意味着，中国企业要更深刻地走进海外市场，在海外扎根本地化。这不可避免地面临着海外投资、海外融资等需求。然而，与之配套的境外融资服务却相对滞后，使得境外融资难、融资贵，成为制约境外中资企业发展的主要问题之一。</p><p>这个问题有解吗？</p><p>当然有。</p><p>作为Web3在实体经济领域的重要落地场景，DePIN利用代币经济来激励和协调全球分布式物理基础设施的建设与运营，打通了虚拟与现实之间的双向通道。</p><p>朗新科技与蚂蚁数科携手打造的新能源资产通证化的案例，便是Web3技术出海具备独特价值的例证，这在新一波中国企业全球化浪潮中，具有更大的想象力，解决诸多现实的资金难题。</p><p><strong>未来DePIN将继续打造数字资产流通网络，为更多实体企业搭建起科技桥梁。随着未来越来越多从事实体经济的企业加入，Web3也将进入服务实体企业的拐点时刻。</strong></p><p>在DePIN打通实物资产通证化后，实体产业的数字资产化流动，也将完成最后一公里——让物理资产数字化，并将预期收益现时化。这也是数字时代，实体产业数字化从提升生产力，到重构生产关系的拐点。</p><p>一方面，DePIN为现实世界的数据上链、资产数字化提供了坚实基础。通过物联网设备采集的数据可以通过DePIN进行加密存证，并实现跨链、跨域的安全流通，助力数据要素市场的繁荣发展。</p><p>另一方面，DePIN也为加密货币等数字资产赋予了现实应用场景。通过参与DePIN生态建设，社区成员可以用劳动和资源换取相应的代币回报，让数字财富惠及更多人群。</p><p>Messari研究院预测，到2024年，DePIN的总可寻址市场空间将达到3.5万亿美元，是当前加密货币总市值的三倍之多。可以说，DePIN正在成为继DeFi之后，加密经济突破传统藩篱、服务实体产业的又一次伟大尝试。</p><h2><strong>写在最后</strong></h2><p>在DePIN的浪潮中，我们看到了一个全新的经济生态正在形成。这个生态不仅为传统行业带来了数字化转型的机遇，还为新兴的Web3领域提供了广阔的发展空间。</p><p>DePIN的崛起正在开启一个全新的发展纪元。在这场变革浪潮中，越来越多的AIoT企业开始从传统的中心化平台转向去中心化的DePIN生态，探索出海的创新路径。</p><p>随着海量物联网设备的接入和数据的汇聚，DePIN将催生出更多数据驱动的创新商业模式。企业不仅可以利用数据提升自身产品和服务，还可以通过数据交易和数据服务为其他参与者赋能，衍生出多元化的盈利模式，推动跨界融合的创新业态不断涌现。</p><p>参考资料：</p><p>蚂蚁数科CEO赵闻飙：公司DNA就是区块链，RWA就像一次小型IPO，来源：元界</p><p>内地资产在香港发行代币，大门被推开了，来源：零壹财经</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MTM5ODQyMA==&amp;mid=2651319475&amp;idx=1&amp;sn=881de2593874b0ff130d4b41edda6c0d&amp;chksm=bcc87f4a344378152a21b2a11c97450e803f2e1d47b15b0ae92530c2870dc711c435c2f9c78b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“物联网智库”（ID：iot101）</a>，作者：彭昭，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956846964373896</id>
            <title>OpenAI o1全方位SOTA登顶lmsys排行榜，数学能力碾压Claude和谷歌模型，o1-mini并列第一</title>
            <link>https://www.36kr.com/p/2956846964373896</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956846964373896</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:51:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>【导读】</strong>o1模型发布1周，lmsys的6k+投票就将o1-preview送上了排行榜榜首。同时，为了满足大家对模型「IOI金牌水平」的好奇心，OpenAI放出了o1测评时提交的所有代码。</p><p>万众瞩目的最新模型OpenAI o1，终于迎来了lmsys竞技场的测评结果。&nbsp;</p><p>不出意外，o1-preview在各种领域绝对登顶，超过了最新版的GPT-4o，在数学、困难提示和编码领域表现出色；</p><p>而o1-mini虽然名字中自带「mini」，但也和最新版的GPT-4o并列综合排名第二，困难提示、编码、数学等领域和o1-preview同样登顶第一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e37101bc10ee44568372ad42cbf454fc@46958_oswg373858oswg1080oswg779_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>果然，o1模型不愧是通用推理领域的新王。</p><p>lmsys社区官方发推表示，这项测试结果收集了6k+社区投票，并将OpenAI这次取得的进展描述为「令人难以置信的里程碑」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d654d26e09e2471db0543e9d055bd6f3@46958_oswg214400oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>单纯看排行榜的排名可能不够具有说服力，于是lmsys特意统计了总榜上前25名模型的1v1胜率。</p><p>可以看到，o1-preview对所有模型的胜率都超过了50%，对比04-09版GPT-4-Turbo的胜率最高，达到了88%。</p><p>o1-mini如果对战o1-preview，胜率为46%，对09-03版GPT-4o的胜率为48%，可以说是大体平手、稍逊一筹的状态。</p><p>值得注意的是，虽然Grok-2-mini和Claude 3.5 Sonnet都排在比较靠后的位置，但o1-preview对这两个模型的胜率并不高，分别是58%和57%，大大小于排名第四的Gemini 1.5 Pro的69%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_697a36cbfdb4465a811a605f762f5c98@46958_oswg1276133oswg1080oswg1045_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果看到细分领域的排行榜，尤其是数学/推理领域，效果则更加惊艳。</p><p>o1-preview和o1-mini不仅是登顶数学排行榜，而且是体现出了绝对的领先优势。</p><p>排在第三、第四的Claude 3.5 Sonnet、Gemini 1.5 Pro和08-08版ChatGPT-4o的均分都在1275左右，不相上下；o1-preview和o1-mini则一骑绝尘，分数飙到1360附近，直接碾压。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_fb5f2cd636724191bdad1d26184ada6f@46958_oswg553295oswg1080oswg847_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>o1推理团队的领导者之一William Fedus看到这张图也是相当开心，他表示这张图「很好地用视觉表达了范式转换」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_7327723f1ba9469bb6e18c16348e2ae8@46958_oswg60430oswg1080oswg187_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>看来最新的o1模型在STEM学科和通用推理方面的确又达到了新高度，用实际测评结果回应了「AI遇冷」、「OpenAI碰壁」的质疑声。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_9d5a20b2ece54991bd6fade49e706fdd@46958_oswg442271oswg1080oswg915_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「那就继续期待OpenAI接下来的发布吧！」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_bb02015a270f4ad08673a6ed25893788@46958_oswg75540oswg1080oswg197_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但一些人感叹「未来可期」的同时，另一些人想到了自己不多的智商和头发。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_90bc1eb848ce46f9a8a5b3210d041fc5@46958_oswg67934oswg1080oswg173_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「模型搞得这么好了，测试就不适合我这种蠢人了。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_6dae9cfa26b64d16adfa199e5a4d2863@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同时，也有一些人表达了对lmsys排行榜结果的质疑。</p><p>比如，众所周知的o1模型推理时间长，因而回答的延时也长，和其他模型都有明显差别；而且不同于各类基准测试的客观标准，lmsys社区中完全基于用户的主观评分，难说这里面是否存在「安慰剂效应」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ed5f18363dc6435c9dfb754ff6019418@46958_oswg86575oswg1080oswg211_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也有人不服o1在编码排行榜上的第一，认为虽然o1-mini非常适合进行项目规划，但在Cursor这类编码助手中还是Claude模型的表现最佳。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_5a03c30985bc4e639c7716146ecae942@46958_oswg139706oswg1080oswg321_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>排行榜的结果当然不是全部，o1模型能否继续赢得口碑，同时保持住智力水平不变蠢，还要看接下来的一段时间。</p><h2><strong>IOI金牌代码全公开</strong></h2><p>说到o1模型的编码能力，不知道你还是否记得，刚发布时OpenAI提到了这样一个指标：如果放宽提交约束到每个问题允许1万次提交，o1可以达到高于IOI金牌门槛的分数。</p><p>在模拟进行的Codeforces编程竞赛中，使用相同的规则进行评估，o1-preview可以打败62%的人类选手，正式版o1则上升到超越89%的对手。</p><p>专门微调过的o1-ioi模型，表现优于93%的竞争对手。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d428626d990341878694700ffab938fe@46958_oswg84962oswg1080oswg596_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，前段时间有用户在实时的Codeforces比赛中使用了o1模型，结果是超越了99.8%的人类选手。</p><p>由于o1在编程竞赛领域的表现如此突出，引起了AI社区强烈的兴趣和好奇，OpenAI于是选择发布o1模型提交的代码内容，包括6个问题的全部C++代码以及注释。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_f1b160ab5a5749aaad07988f335efead@46958_oswg277582oswg1080oswg576_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>发文的yummy是o1模型的核心贡献者Alexander Wei&nbsp;</p><p>对于o1的惊艳表现，Alexander Wei自己都很惊讶。</p><p>他本人在9年前曾参加IOI竞赛，但从未想到自己这么快就需要和AI竞争，模型展现出的推理过程的复杂程度令人印象深刻。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_712a774ed307475db847d9ea0cb76b28@46958_oswg181667oswg1080oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>博文表示，虽然o1模型距离人类的顶级表现还有很长的一段路要走，但我们期待有一天能实现这个目标。</p><p>这个发展轨迹让人想起了AlphaGo——从水平高超，到能和人类顶级高手不分胜负，再到5-0完全碾压李世石。</p><p>OpenAI想要达成的，估计就是究极进化的、能在编程上碾压人类顶级高手的AlphaZero。</p><p>此处公布代码的6个问题具体如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_51d6d21f39814f8382a9c10ce552ac97@46958_oswg152129oswg892oswg990_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有网友指出，其中最令人印象深刻的应该是象形文字（hieroglyphs）问题，o1模型总共得到44分，在现场的所有选手中排名第四。这表明，模型或许可以破译一些人类无法解决的子任务。</p><p>前几天，一位目前在NASA工作的天体物理学博士就尝试让o1复现自己论文中的代码，结果一试吓一跳——自己读博时花了1年写出的代码，o1只用了一小时就写完了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_6efe246ec2264c3491a2965aa9ad0267@46958_oswg71939oswg1080oswg149_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这还只是裸模型，如果加上代码解释器、网络实时搜索等各种工具，效果想必更加惊艳。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_20f7f0585f324031a33ed9aa6d6232d3@46958_oswg127239oswg1080oswg274_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且，Reddit网友还送来了温馨提示：这只是o1预览版哦，可以狠狠期待一下不到一个月就即将问世的正式版o1了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d26bd660b00044c9929b283b908be998@46958_oswg102192oswg1080oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，这位网友还表示，o1基本沿用了GPT-4的架构；那你想，改换架构后的GPT-5（也就是传说中的猎户座）能达到什么高度。</p><p>参考资料：&nbsp;</p><p>https://x.com/lmsysorg/status/1836443278033719631&nbsp;</p><p>https://codeforces.com/blog/entry/134091&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ip8KQrZ66nzBhCwwSW2Dow" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：乔杨&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956842338695559</id>
            <title>贾跃亭喜提2.1亿，没有一笔融资是一份PPT搞不定的</title>
            <link>https://www.36kr.com/p/2956842338695559</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956842338695559</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:51:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大洋彼岸的贾跃亭又拿到新融资了！</p><p>没有一轮融资是一条三寸不烂之舌和一份PPT搞不定的！&nbsp;</p><p>这次他又拿到了3000万美金，大概2.1亿元的新一轮融资。&nbsp;</p><p>险遭退市的FF再次合规上市，股价也应声大涨。这可把贾跃亭笑弯了腰。&nbsp;</p><p>这次又是拿着什么由头去忽悠资本的呢？&nbsp;</p><p>当然是什么最热，蹭什么了！这次， <strong>贾跃亭把他的FF套上了AI和EV的概念。</strong></p><p>我去了解了一下啊，这次被忽悠的金主分别来自中东美国和亚洲。&nbsp;</p><p>中东自古出土豪。 这次的中东金主是来自阿联酋拉斯海马投资公司Master投资集团。&nbsp;</p><p>集团老板甚至还亲自为贾跃亭站台发表讲话，说很高兴参与这次融资，成为FF的战略伙伴。 并且还特地强调了，他相信FF会有光明的未来。&nbsp;</p><p>三方资本出了3000万美金，也确实不算多， 那对中东土豪来说，可能更是洒洒水了，就当花钱买个高兴。&nbsp;</p><p>FF官方还说， <strong>这笔新钱会带来新的可能，会用来生产新车FF 91 2.0，以及更新产品和软件。</strong></p><p>但是，不知道这些土豪知不知道，仅仅在半年前，贾跃亭连几十万的房租都给不出，甚至还闹到了法院。 最终只能卖厂子地皮来抵，自己跑去租房子生产。可以说，这在国内外的造车届都算是奇闻了。&nbsp;</p><p>就在喜提新融资的当天，FF还向世界宣布了一则喜讯。 说是公司又满足了《纳斯达克上市规则》中的股价要求和定期申报要求，公司现已符合纳斯达克继续上市的所有标准。&nbsp;</p><p>那为什么又会有这声明呢？ 是因为今年上半年，FF的股价有连续十天的收盘价低于0.1美元，按照规则是要被退市的。这又可以称得上是另一奇观了。&nbsp;</p><p>你说他没造出车吧，那还真造出了几辆。八 月中旬FF终于在“租赁”的生产工厂中，完成了第2辆FF 91 2.0的交付，这也是FF成立十余年来、融资数百亿后交付的第13辆车。&nbsp;</p><p>这样的数量，其稀有程度堪比全球限量款的超跑了。 新拿3000万美金，对造车这项大工程来说，肯定是杯水车薪啊。&nbsp;</p><p>但老贾又开始忽悠，说要拿着这个钱去造新的子品牌， 说是这个子品牌主要打中低端的大众市场。&nbsp;</p><p><strong>你也不得不佩服贾跃亭，连房租交不起、险遭退市这种艰难时候，都能被他挺过来。还一直能找到接盘侠，这能力是多少人羡慕的？</strong></p><p>当然，这3000万美金，被霍霍完肯定用不了多久。不知道下一次，又会拿出什么新的PPT。&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTU1MjE3Mg==&amp;mid=2247559191&amp;idx=1&amp;sn=befb083f37cbc1862825846229fa29f2&amp;chksm=ce302911c1e3c7cdf1ccfd01dc264df327eb013ab875434bea92debb8cb81dceaea4f5bbaacb&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“XCJ-YY”（ID：xincaijing）</a>，作者：锌财经编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956847088187776</id>
            <title>AI探索宇宙结构新突破，超精准场级模拟，半秒完成冷暗物质仿真</title>
            <link>https://www.36kr.com/p/2956847088187776</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956847088187776</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:47:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>【导读】</strong>AI开启模拟宇宙！近日，来自马克斯·普朗克研究所等机构，利用宇宙学和红移依赖性对宇宙结构形成进行了场级仿真，LeCun也在第一时间转发和推荐。</p><p>下面的两组动图展示了计算机对于宇宙形成的模拟：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_c2e973f6a6f74e09bac09b0b5f9f8a9a@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中一行是根据物理定律计算的，而另一行是由人工智能学习后生成的。</p><p>你能看出来哪一个结果出自AI之手吗？</p><p>这就是来自马克斯·普朗克研究所等机构发表的工作：利用宇宙学和红移依赖性对宇宙结构形成进行场级仿真。</p><p>AI终于开始模拟宇宙了！LeCun也在第一时间转发和推荐：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ec46d6679c254c5ea32eb740160cab64@46958_oswg55648oswg1021oswg233_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作者表示：我们现在可以使用人工智能在多个时间步上对大多数宇宙学特性生成宇宙的冷暗物质模拟。</p><p>并且，物理学是这个神经网络设计的核心，它可以看成是PINN（内嵌物理知识神经网络）的一种实现，其损失函数建模了时间相关的粒子坐标和速度之间的特定关系。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d69049519fe64ca2b87fc5db180829fc@46958_oswg1584183oswg669oswg1003_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在这项工作中，研究人员提出了一个用于大规模结构的场级模拟器，捕获宇宙学依赖性和宇宙结构形成的时间演化。</p><p>模拟器将线性位移场映射到特定红移处对应的非线性位移。</p><p>模拟器是一个神经网络，包含对Ω和红移z处的线性增长因子D(z)的依赖性进行编码的样式参数。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e13c0ff19e8d4b4cafe7d4dc7f82e71c@46958_oswg225803oswg858oswg895_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>研究人员在六维N-body相空间上训练模型，将粒子速度预测为模型位移输出的时间导数，显著提高了训练效率和模型准确性。</p><p>最终，模拟器在测试数据（训练期间未见过的各种宇宙学和红移）上实现了良好的精度和性能，在z = 0，k ∼ 1 Mpc/h的尺度上达到了百分比级精度，并在较高红移下提高了性能。</p><p>通过合并树将预测的结构形成历史与N体模拟进行比较，可以找到一致的合并事件序列和统计特性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_292e6fa3d63c4a0f803157b42229480d@46958_oswg191127oswg400oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>并且，该模拟器速度极快，在单个GPU上半秒内就能够预测128的立方个粒子的非线性位移和速度场。</p><p>同时又可以通过多GPU并行处理进行良好的扩展，支持任意大尺寸的实现。</p><h2><strong>模拟宇宙的AI</strong></h2><p>随着宇宙学数据分析推向更小的尺度，利用高阶统计数据，并实现场级分析和基于模拟的推理方案，为预测非线性宇宙结构形成提供了更准确的方法。——当然也对算力提出了超高要求。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_2f72391e1d0a412d814afa40ca640651@46958_oswg797242oswg919oswg555_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如利用N点统计的传统分析方法，需要大量模拟数据集来进行准确的协方差估计。</p><p>而基于模拟的推理方法和场级分析，则需要生成许多后期密度场的准确实现，以约束模型参数和初始条件重建。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_58a49072edea429f912bb1c1e834451e@46958_oswg411448oswg975oswg377_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>DESI、Euclid、Vera C. Rubin天文台、SPHEREx和Subaru Prime Focus Spectrograph可以为研究者提供大量最新的星系巡天数据。</p><p>为了探明宇宙学参数和初始条件的最佳约束，需要对巡天观测值进行快速、高度准确的预测。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_f054d6a274c64e8a8be9a854c0b33ed8@46958_oswg783887oswg892oswg887_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在这项工作中，作者通过添加红移依赖性和对多个红移模拟快照的训练来扩展场级N体模拟器。</p><p>由于本模型的时间依赖性和自可微性，研究者可以有效地获得N体粒子速度作为输出粒子位移的时间导数。</p><p>可以在训练期间动态评估这些速度，由此定义一个取决于粒子位置和速度的损失函数，在六维N体相空间上进行训练。</p><p>强制执行「速度必须等于位移时间导数」的物理约束，可以提高训练效率并提高模型的准确性，特别是对于速度场。</p><h3><strong>模型结构</strong></h3><p>作者通过周期模拟框中的坐标x来描述N体粒子。每个粒子都与规则立方晶格上的一个位点q相关联，因此它在红移z处的位置定义为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_276ab46658dd44aeac72f376f13f6b30@46958_oswg4170oswg255oswg47_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这里Ψ是位移场，q是粒子的拉格朗日坐标。在线性Zeldovich近似 (ZA) 中，位移场演变为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a32ba26945df4c5aa7833a6c57690fc4@46958_oswg6508oswg327oswg79_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中 D(z) 是线性增长因子，zi是早期选择的红移，以便线性理论可以很好地描述位移场。</p><p>随着引力簇的非线性在后期变得重要，这种线性近似变得不准确，而模拟宇宙结构形成的非微扰方法（如N体模拟）变得必要：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ae6d1578427d441d9ae256d29baddf2d@46958_oswg8037oswg381oswg83_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这里f(z)为线性增长率，H(z) 是哈勃率（Hubble rate），使用粒子速度来模拟星系探测中的红移空间扭曲。</p><p>研究人员设计了场级模拟器，根据目标红移处的ZA位移场来预测z = 3-0范围内任何红移处的非线性粒子位移和速度。</p><p>场级模拟器采用U-Net/V-Net设计，使用PyTorch的map2map库实现和训练模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_05c2f093aa944a2f9217b9a35e67e628@46958_oswg332387oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如上图所示，模型的输入具有三个通道，对应于所需红移处ZA位移的笛卡尔分量，排列在3D网格中。</p><p>输入经过四个ResNet 3×3×3卷积，第一个卷积运算将3个输入通道转换为64个内部通道。</p><p>在四次卷积操作之后，结果的副本被存储以供网络的上采样端使用，然后使用2×2×2卷积核对结果进行下采样。</p><p>该架构的感受野对应于给定焦点单元两侧的48个网格点。预测单个粒子的位移时，以焦点粒子为中心的大小为97的区域需要通过网络，对应于拉格朗日体积189.45 Mpc/h。</p><p>不过，由于网络缺少填充区域中所有单元的信息，因此这些区域的粒子位移并不准确，需要从输出中移除。</p><p>网络有限的感受野也有一个优点：它在线性理论准确的大尺度上保留了ZA场。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_b5d5e697a96a4e8faa630c81d16b6ec1@46958_oswg188324oswg950oswg319_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以上的操作可以针对固定宇宙学的单个红移来训练来自模拟快照的数据。</p><p>为了扩展网络功能，允许网络学习N体映射作为Ω和红移的函数，作者对其进行了增强以包含样式参数 。</p><p>在执行任何卷积（包括下采样/上采样操作）之前，快照的Ω和D(z)值将传递并映射到与卷积核尺寸匹配的内部数组，然后使用这些参数调节网络权重。</p><h3><strong>模型训练</strong></h3><p><strong>训练数据</strong></p><p>研究人员从一组具有不同宇宙学参数和一组固定快照红移的模拟中随机采样快照，同时训练样式参数和网络参数，使用Quijote Latin超立方体模拟，在边长1 Gpc/h的空间中使用512个粒子运行。</p><p>所有这些模拟的拉格朗日空间分辨率均为1.95 Mpc/h，整个数据集包含2000个模拟，每个模拟都有一组独特的五个ΛCDM宇宙学参数Ω。</p><p>研究人员将2000个模拟分为三组：1874个用于训练，122个用于验证，4个用于测试。为了鼓励各向同性，这里使用数据增强，通过立方体的对称性随机变换输入和目标数据。</p><p><strong>损失函数</strong></p><p>模型训练使用的损失函数包含四个项。第一个是粒子位移的平均平方误差（MSE），比较粒子的模拟器位移预测和真实的N体位移：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_70948e2859a442da9ae199b72b5eccb6@46958_oswg5695oswg407oswg89_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第二项是欧拉密度的MSE：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a3c8597bbf9641b3a66a00d6dec7522e@46958_oswg6146oswg347oswg77_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第三项是采用粒子速度的MSE：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_c15dfed200d74496a396cd30813de45f@46958_oswg5934oswg351oswg89_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后一项对应于欧拉动量场的MSE损失。这里将粒子速度分布到与初始拉格朗日网格具有相同分辨率的欧拉矢量场网格并计算，p是网格单元中每粒子质量的欧拉动量。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_51116e1c4bd5427eabaea401db20e762@46958_oswg6197oswg369oswg91_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>于是，红移z处快照的最终损失函数为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_4abb71674b6a4294b90c07646456387a@46958_oswg5537oswg323oswg75_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>实验结果</strong></h3><p>研究人员通过构建模拟器输出和N体模拟真值的欧拉密度、和动量自功率谱和互功率谱来评估模拟器的准确性。</p><p>对于密度场，使用CIC插值方案将粒子分布到512网格并估计功率谱，下表列出了用于测试本文模拟器的五个模拟宇宙学参数：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_7959f7a867a647db9fc0b8df9bf90ebd@46958_oswg73078oswg613oswg359_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>模拟器在训练过程中从未遇到过以上5种测试模拟中的任何一种。</p><p>下面测试在训练数据中的五个固定红移之间进行插值时的模型性能：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_80f14cf34290467cbba20a471402bb1b@46958_oswg338674oswg1080oswg655_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上图显示了SNN模拟器的功率谱误差（比例函数），每条曲线的颜色表示红移。</p><p>欧拉密度误差仅源于粒子位移的误差，当红移z = 0时，新的瞬态模型的随机性与原始模型的随机性相当，并且传递函数误差通常比原始模型有所改善。</p><p>在上图的最右列中，可以看到由于模拟器无法完美预测BAO幅度而导致的振荡误差。不过模拟器的这些错误特征低于1%，并且可能会随着更多的训练数据而得到改善。</p><p>红移相关模型的性能与z = 0时的真实空间密度统计数据相当，并且在较高红移时对于红移空间和真实空间统计数据的性能明显更好。</p><p>随着红移的减小，误差平滑且单调地增加。这表明模拟器可以在其训练数据中的少量固定红移快照之间有效地进行插值，而不会过度拟合，否则我们会在中间看到错误的振荡特征。</p><p>参考资料：&nbsp;</p><p>https://x.com/cosmo_shirley/status/1825749316134158627&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/d9tl6Wo2rTJYitpGswKdEg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：alan&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956861261839238</id>
            <title>​“创造市场”与“算法进化”，中美AI竞速的岔路口</title>
            <link>https://www.36kr.com/p/2956861261839238</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956861261839238</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:45:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e7d23e67d6d84d70b77d8deea0b45d61@000000_oswg95848oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“人工智能的商业模式，是要创造一个市场，而非一个算法”。这是世界AI泰斗Michael I.Jordan的观点。</p><p>而<strong>当前的全球AI市场，占据主导地位的中美双方，却也走出了两条截然不同的技术路径，前者执着于前沿技术的探索，后者则发力应用优化和商业化落地。</strong></p><p>南辕北辙的两个方向，或许已经无法直接进行排位先后、优劣的对比，但对于应用和落地，中国明显有自己的鲜明主张，甚至即将完成超越。谷歌中国区前负责人李开复表示，预计到明年年初，中国的应用普及速度将远远超过美国。</p><p>只是，这一路走来，中国企业付出了多少，鲜为人知。</p><h2><strong>国内AI大模型：从“雨后春笋”到“销声匿迹”</strong></h2><p>2022年11月，自ChatGPT推出后，国内市场被激发出前所未有的热情。随后在2023年初，国内涌现出首批大模型创业者，掀起了一阵大模型创业的小高潮。同年6月，百模大战正式打响。</p><p>耗时不到三个月，中国就诞生了超200款大模型，但到23年12月，持续更新的模型便迅速减少至156款。再到今年5月，便仅剩19款。<strong>很多大模型如同昙花一现，稍纵即逝。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_3ae6d638f6cb45a6a850b6f1a88c3c0e@000000_oswg105559oswg1080oswg651_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源来自pixabay图库</p><p>而被业界称为"六小虎"的智谱AI、零一万物、百川智能、MiniMax、月之暗面和阶跃星辰，也开始进行业务调整，有的暂停了预训练模型的研发，有的则逐渐退出C端市场，转而聚焦B端业务，甚至还有公司进行了人员缩减。</p><p>这一现象背后，可以预见的是<strong>单靠融资驱动的商业模式已经成为过去式。</strong>面对全球AI大模型百舸争流的形势，中国AI产业需要深刻反思并寻求破局之机。而首要目标就是回归商业本质，摒弃单纯追求技术参数竞赛的浮躁心态，更加注重市场需求导向的研发与应用创新。</p><p>彼时，国内AI大模型开始进一步分化。按模态划分，大模型可分为自然语言处理（NLP）大模型，视觉（CV）大模型、多模态大模型等；按照部署方式划分则可以分为云侧大模型和端侧大模型两类。</p><p>其中，云侧大模型又有通用大模型和行业大模型两种，通用大模型具有适用性广泛的特征，目前更具代表性的有文心一言、通义千问、讯飞火星等，行业大模型则具有专业性强的特点，针对特定行业（如金融、医疗、政务等）的需求进行模型训练。</p><p><strong>可见，国内AI大模型的应用路线开始日渐清晰，大致途径为“基础大模型→行业大模型→终端应用”。</strong></p><p>值得注意的是，继百模大战降温、应用路线清晰后，价格战也开始了。一个典型例子就是，今年5月21日，百度宣布两款大模型免费开放：Speed和Lite，这两个相对轻量的大模型免费提供，而最强大的大模型依然收费。</p><p>尽管，低价甚至免费可以增加用户基数，但也给企业带来了不小的生存压力，毕竟这违背了最基本的商业逻辑。但如果技术和产品的竞争力足够强，那么也无需主动去参与价格战。</p><p>如此一来，价格战的开启虽然不是一个好兆头，但也从侧面推动AI技术创新进入了新的加速期。</p><h2><strong>中美多维差异背后，技术落地路径已然不同</strong></h2><p>在全球人工智能持续竞速的背景下，中美双方孰强孰弱一直是备受关注的议题。据悉，目前全球发布的大模型总数中，中美合计占约80%，处于绝对的主导地位。</p><p>具体来看，中美双方之间在技术背景、文化属性、市场环境、人才培养、算力、数据等维度上都存在差异。</p><p>技术背景方面，美国的科技发展尤其注重“技术优先”和“知识密度优先”，行业、企业之间重视基础创新，对于新兴的事物保持着较强的鼓励和促进态度。同时，整个生态上的分工也更为明确，形成了一套较为完整且兼具创新的生态链，从而共同推近统一目标。</p><p>国内相较更为多样化，并尝试依托于更多的应用爆发以及市场的多样性来加速发展。同时在发展过程中，对于安全、可控，以及持续性和自主性等维度的要求会更高。</p><p>又因为技术背景和市场环境的缘故，双方在商业模式上的区别也较为明显。美国AI公司更多用的是软件模式，可以快速起量；国内公司则更擅长性能调优，多采用个性化定制的服务方式。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_5ed29217d74948f1bfd38c08eb848269@000000_oswg58283oswg911oswg783_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源来自知乎@hayley</p><p>人才培养方面，从上图可以看出，国内在人工智能人才培养上的比例分布情况。国内人工智能人才的本科比例较高，但硕士和博士比例逐渐下降。</p><p>原因在于大量人才选择出国深造和工作。相关数据显示，美国39.52%的人工智能人才实际上来自于中国。这使得错失更多高端人才的中国，在基础研发上阻力相对较大。</p><p>算力方面，由于国内在先进制程芯片以及计算密度上不占优势，所以仍处在落后于美国的阶段。但基于国内政策及资本的积极态度，长远来讲，算力难题是有解的。</p><p>而算力之外，数据是另一个限制中国AI产业发展的重要因素。一方面是因为大量数据的私有化，导致获取数据的成本高，另一方面，因为处理数据的成本居高不下，所以企业之间对自己的数据策略（包括数据配比，数据来源，数据加工等等）高度保密。</p><p>最后也最关键的是，产业发展路径方面，美国倾向于从底层开始限制开源生态的分发过程，并试图通过限制开源来抑制产业创新。而国内则倾向于大力推动开源模型的发展，从而更加贴合垂直行业的应用落地。</p><p>就影响而言，美国所主张的限制开源，对国内不会造成太大影响。尽管底层研发技术仍有差距，但GPT-3.5的出现意味着技术取得了阶段性的突破，而且因为开放使用，国内已经获取了开源模型。因此，技术革命的传播速度快于立法监管的速度，导致监管是失效的。</p><p>综合来看，多个角度上的差异造成了中美双方在技术落地路径上的大相径庭，美国仍旧处于从0-1技术探索的前沿阵地，而国内则更关注商业落地并贴合市场需求进行应用优化。</p><h2><strong>想“超车”美国，还得看“应用线”</strong></h2><p>在国内企业转向美国的开源人工智能模式以求迎头赶上的同时，美方也陷入一个相对尴尬的境地。因为，他们一直试图通过限制微芯片销售和遏制投资来减缓国内的进步，但却无法阻止企业为了促进软件的普及而选择公开发布的做法。</p><p>美国在开源模型上的“两头为难”恰好为国内企业实现“超车”提供了机会。</p><p>从Sora和GPT-4这两大爆款来看，Sora在算法上的突破并不大，效果展示上的惊艳更多源于巨亮算力的堆集，它解决了决帧与帧之间的时序一致性问题，但同时导致Sora的视频生成成本短时间内无法降低。</p><p>而GPT-4虽然强大，其成本高企同样是当下最难跨越的现实问题之一。这也使得企业在实际应用中往往选择性价比更高的解决方案，如开源模型或规模更小的商用模型。</p><p>而且，一旦最好的开源技术来自于中国，美国开发者最终将由主动转为被动，甚至需要在中国技术的基础上构建自己的底层系统。</p><p>可见，追求技术领先的美国，在跨出商业化落地的“临门一脚”时已经被成本“绊倒”，未来还有可能因此陷入僵局。</p><p>形成鲜明对比的是，中国的科技投资者在推动人工智能时追求尽快转亏为盈，这意味着资金正在流向易于执行的应用，而不是更具抱负、专注于基础研究的目标，杜克大学约翰·科克电气与计算机工程杰出教授陈怡然这样说到。</p><p><strong>与此同时，中国对人工智能的投资中，多达50%投向了监控所需的计算机视觉技术，而不是为生成式人工智能建立基础模型。</strong></p><p><strong>尤其对于国内本地市场的需求，百度文心一言、阿里通义千问等国内自主研发的大规模模型，在应对广泛且普遍的应用场景时，已经充分展现了其实用性与高效性。</strong>诚然，在应对极其复杂或特定复杂需求时，这些模型与全球顶尖的大模型相比，尚存在一定的性能差距。</p><p>然而，就当前多数生产工具的实际需求而言，无论是通过开源途径获取的模型，还是国内商业化提供的解决方案，均能提供基本且相对令人满意的服务支持。</p><p>尤为值得一提的是，随着各类应用场景的不断拓展与深化，国内大模型的实际应用落地进程正显著加速，展现出蓬勃的发展态势。</p><p>由此来看，中国虽然暂时无法通过现有的大模型实现技术上的全面超越，但美国也无法进行有效封锁，开源技术既是中国AI发展如此迅速的关键原因，也将是中国取得领先地位的机遇。</p><p><strong>而技术路径上的差异已经让美国陷入阶段性停滞不前，国内应该继续专注于应用开发，从而缩小商业化价值上的差距。</strong></p><p>长远来看，美国如果真限制开源，那么这将是技术衰落的开始，同时也是中国正式崛起的开始。</p><p>战局最终将如何演化，我们静待时间揭晓。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkzMTczMjQwMw==&amp;mid=2247559753&amp;idx=1&amp;sn=cba1373c92501ecddab5d76140e80f10&amp;chksm=c372b3ec03b22da934a6bdcdf6856039d8b4a940781d5f26a59de7aa4ac7c1236916cdd38c8d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“港股研究社”（ID：ganggushe）</a>，作者：璟松，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956862230568580</id>
            <title>瑞士机器人科技公司Verity研发仓库自主巡检无人机，实现零误差库存自动化管理 | 瑞士创新100强</title>
            <link>https://www.36kr.com/p/2956862230568580</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956862230568580</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:26:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_66df3d9e01aa4a4290c655c3d81ef0a4@5898759_oswg1272597oswg904oswg648_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源Verity</p><p>瑞士机器人科技公司Verity成立于2014年，其开发的仓库巡检无人机能完全自主执行库存扫描任务，实现库存管理、监控和检查任务的完全自动化，协助企业进行零误差库存管理。</p><p>Verity由Raffaello D'Andrea创立，Raffaello D'Andrea拥有加州理工学院电气工程博士学位，曾是Kiva Systems联合创始人，该公司后被亚马逊收购并更名为亚马逊机器人公司。Verity的团队由经验丰富的工程师、计算机科学家、软件开发人员、设计师和商业专业人士组成，拥有人工智能和机器人、供应链和无人机技术领域的顶尖人才。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d29e68805cb6433d97f751502cc6e556@5898759_oswg73792oswg924oswg740_img_jpg?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源ACCESSWIRE</p><p>仓库管理的复杂性与精细度要求都很高，从卸货、入库、运营至拣选出库，每一个环节都需要保持精确。一旦出现货物实际库存位置与库存管理系统不符，就需要对整个仓库货物进行逐一盘点检查，依靠人工修正。这一过程不仅耗费大量时间与人力成本，还有可能拉低企业货物周转及运营效率。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_2778e19aaa38459a9e1f91bec7a13ecd@5898759_oswg57204oswg725oswg401_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源Verity</p><p>Verity开发的仓库自主巡检无人机与仓库智能管理系统，即旨在通过完全自主的无人机系统，智能识别仓库管理系统指示的货物位置与仓库中货物的实际位置之间的差异并精确提示，减少盲目耗时的人工检查，提升库存管理效率。</p><p>Verity的无人机拥有5级自主性，可在无任何人工干预的情况下完成不间断仓库扫描。Verity的智能平台拥有100多项支持高级算法和分析的专利，能够在云端自动创建和管理巡检任务，并全面地分析仓库、运营和库存数据。Verity会根据历史与实时数据在云端自动生成仓库巡检任务，并指定具体执飞无人机、扫描点位与检查顺序。无人机会按指令自动起飞至指定地点对库存进行扫描，并将扫描的实时数据汇总至系统与库存管理系统数据进行比较分析，一旦发现异常则即时提示，从而快速纠正入库、拣选和其他错误。如果执飞期间无人机电量不足，该无人机会自动返回并进入充电状态，其他无人机会继续执行该任务直至任务完成，整个过程无需人工介入。</p><p>Verity的定位系统让无人机能以厘米级的精度在货架之间自主定位和穿行，并在遇到障碍物的情况下自动规划新路线，实时分享给其他无人机，即便在网络不稳定或质量较差的仓库中也能使用。Verity的定位系统基于其通过3D测绘构建出的仓库货架环境的精确数字模型。Verity的无人机搭载的智能摄像头可提取货架的物理尺寸，捕捉货架上的货物图像，测量每根货架横梁的高度，绘制出各个货架的位置，最终以高精度3D模型呈现出仓库全貌，包括实时显示当前可用的库存位置。Verity的无人机可在数天内完成仓库地图的绘制，并在每次巡检时进行更新，这不仅能支持无人机的精确飞行，提高库存管理的准确性，还能在仓库配置发生变化时轻松更新整个系统，降低仓库管理成本。</p><p>基于以上功能，Verity能够帮助企业减少90%的盘点工作时间，降低40%的存货丢失量，且其整体投资回收期小于1年。目前，Verity的无人机已应用于运动服饰、物流、航运、食品等领域的仓库管理，在全球20个国家的100多个设施中完成了超过25万次自主飞行，公司客户包括On、DSV、马士基、KeHE、三星SDS等行业领导者。</p><p>2023年，Verity完成了共计4300万美元的B轮融资，投资者包括高通、A.P. Molle、Exor等。自2015年底以来，Verity的融资额已达7400万美元。未来，Verity的无人机将进一步开拓其全自主仓库巡检无人机的应用领域和场景，协助企业提升库存智能管理水平。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_1c82e29dd37843d5a8822b1c0f8a08ea@5898759_oswg863376oswg720oswg965_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>Verity是2023年《瑞士创新100强》（TOP100 Swiss Startups）上榜企业。《瑞士创新100强》汇聚了最佳“瑞士制造”的初创及成长期科技创新企业，是瑞士科技创新领域最具国际影响力的标杆榜单。自2011年以来，该榜单每年在瑞士全国范围内评选出100家最具开创性和市场前景的瑞士创新企业和25家最具独角兽潜力的瑞士成长期企业，覆盖生命科学、工程机械、机器人、信息通信、低碳科技、食品科技等领域。《瑞士创新100强》及系列品牌活动是瑞士创新生态圈的标志性活动，代表着瑞士创新最高地和国际投融资最前沿。</p><p>2023年《瑞士创新100强》中文版由以明科技（Insight Tech）荣誉发布。以明科技是《瑞士创新100强》的中国授权合作方，负责《瑞士创新100强》在中国的运营推广并协助榜单项目对华商业合作。作为中欧（瑞士）科技创新投资与产业化运营商，以明科技为瑞士创新和中国产业的双向合作提供投融资和商业拓展服务并开展股权投资业务。</p><p>获取2023年《瑞士创新100强》完整榜单及行业榜单，请访问以明科技公号或官网。</p></blockquote>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956848211582848</id>
            <title>看懂美联储降息：我们该如何配置自己的投资？</title>
            <link>https://www.36kr.com/p/2956848211582848</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956848211582848</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:25:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_1d473d197d544ac9bebcbfc23aa32389@5065245_oswg166457oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>真不愧是常年占据财经媒体头条的美联储，四年第一次降息这个噱头还嫌不够，要给市场来个一次性大满足。</p><p>当地时间18日，美联储鲍威尔宣布将基准利率目标范围下调50个BP，降至4.75%-5%，这是该机构自2020年3月以来的首次降息。值得一提的是，如此大的降息幅度，在历史上的降息周期开局中非常罕见，上世纪90年代以来仅有2001年1月、2007年9月和2020年3月这三次。</p><p>而<strong>这三次毫无例外，要么是对重大危机的应对，要么成为了重大危机的先兆</strong>。</p><p>也是因此，这次降息鲍威尔真的在从各个角度给自己找补，也给市场释放鹰派信号。他表示，在美国经济仍然强劲的情况下，以重大举措启动其历史性的紧缩政策，将有助于限制经济衰退的可能性；但他也小心翼翼地坦承，<strong>美联储未来不一定会采取类似的步伐，还要看之后的经济数据表现</strong>。</p><p>总结下来，鲍威尔这一套操作就是“身体很诚实，但嘴上还得矜持”，明明已经给了市场预期最大幅度的降息，却还要坚持对未来的谨慎预期，这种“撕裂”，或者说有些纠结的态度，其实正是这一轮降息的<strong>关键信号</strong>。</p><p>一个明显的信号是，美联储理事米歇尔·鲍曼对50BP的降息投下了反对票，<strong>这是自2005年以来美联储议息会议中的第一次“异议”</strong>。显然，无论是市场预期还是美联储内部，对于25BP还是50BP都有很大的分歧，降息后整个资产端先涨后跌的走势也反映出，虽然是期待已久的大幅度降息，但美国经济的衰退风险并未被市场忽视。</p><p>因此，主要资产如美股、美债和黄金等，仍将是以波动为主，相比来说，在美国经济衰退没有得到证实之前，美股的表现会相对更好一些；外围方面，AH中的地产股终于迎来了喘息的机会，同时科网股则是一直被资金面困扰，成为全球市场中少有的科技题材估值洼地，短期内会有不错的表现。</p><p><strong>01&nbsp; &nbsp;纠结的降息</strong></p><p>从这次降息的关键词“纠结”开始，就能很好地理解目前整个美国的宏观环境，以及未来可能会出现的降息路径。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e0138faa4e674cd8b724045ccef70f24@5065245_oswg148470oswg1080oswg591_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>纳斯达克指数走势</p><p>在今年8月初和9月初，美股先后经历了两次大幅度暴跌，整个上半年暴涨背后积攒的泡沫焦虑爆发。在这背后，除了所谓的套利交易之外，美国经济呈现出的不良信号，<strong>开始让软着陆还是硬着陆的讨论再度回归</strong>，对于宏观环境的焦虑，成为这两次暴跌最主要的利空因素。</p><p>而这个不良信号，其实就是就业。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_2c4bfc0d0cf4414f87d19039a807d129@5065245_oswg43014oswg615oswg504_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>平均工资和失业率情况，资料来源：美国劳工局，彭博</p><p>根据美国劳工统计局的数据，可以看到在最近一段时间，无论是平均工资（第一行）还是失业率（第二行），在2024年上半年都有恶化。其中，三月平均工资是2020年中旬以来的最低，最广义失业率则是2021年10月以来的最高。不仅如此，四五月份美国失业率达到“萨姆法则”的触发线，后者通过历史数据整理，被认为是经济衰退的前兆。</p><p><strong>在劳动力市场一系列的不良数据发布之后，让物价数据已经不再那么引人关注了</strong>。8月份，总市场篮子和核心市场篮子中超过50%的品类的年化月度通胀率低于2.5%，核心商品价格指数已恢复到轻微通缩。可以说，通胀问题现在已经不是困扰美国经济的核心因素。</p><p>而作为美国的央行，美联储首要关注的并非是通胀，而是宏观经济；什么数字对宏观经济的影响更大、呈现更直观，美联储就会拿什么数据作为行动的依据。在2021年美国大放水之后，这个数据是物价指数；在今年以后的相当一段时间里，这个数据是劳动力。</p><p>但是，和物价数据不同，虽然对宏观经济枯荣的反应更加直观且及时，但劳动力数据并不是一面普通的镜子，而是有多个面的“万花筒”，数据的统计口径不同，得到的结论会大相径庭。</p><p>例如，在今年8月21日，美国劳工统计局披露的报告显示，从2022年4月到2024年3月的一年内，美国经济创造的就业岗位比最初报告的少了81.8万个，实际的就业增长比最初报告的290万减少了近30%，也是2009年以来修正幅度最大的一次。<strong>即时的就业数据很有可能对决策产生误导，甚至会起到反效果</strong>。</p><p>于是，自从这次就业数据的大幅度下修之后，市场开始质疑美联储没有及时降息，劳动力市场的数字显示，美国经济远没有之前披露的那样乐观，且在失业率等指标上看，已经有了进入衰退的风险。</p><p>但是，如果从另一个层面观察就业数据，或许会得出完全不一样的结论。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_0e656e3129d54ed9956d14d8c9774e34@5065245_oswg362329oswg1023oswg760_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>萨姆法则触发线&nbsp;</p><p>根据萨姆法则，如果‌失业率的三个月移动平均值比过去12个月内的最低点高出0.5个百分点或更多，则预示着美国经济可能已经陷入或即将陷入衰退。但是，上图红色线条展示的，25至54岁这一主要工作年龄段的就业情况却非常强劲，与萨姆法则的触发线走势截然相反。</p><p>而另据美国劳工统计局的数据，25至54岁这一主要工作年龄段的就业率，非常接近美国的历史高点——克林顿总统在位的末期，彼时的美国经济根本就不存在衰退的疑虑。因此，<strong>从主要就业人口的情况来看，美国并没有衰退的疑虑，美联储也没有必要在短期大幅度降息</strong>。</p><p>所以，美联储如此纠结的背后，就是主要参考数据从物价指数转换到就业情况，后者的多面性，让市场和机构本身很难对宏观经济有着一致性的判断，导致美联储甚至出现了快二十年没出现的内部矛盾。</p><p>面向未来，之后的每次降息很大概率会重复这次降息的纠结，直到新的数据出现，能够让市场产生相对统一的宏观环境判断。</p><p><strong>02&nbsp; &nbsp;资产走势如何</strong></p><p>本质上讲，50BP起步的降息，在历史上是比较罕见的，在短期会让市场担忧，美国经济是不是遇到了很大的困难，才需要更大幅度的宽松解救；因此，短期内美债和黄金这类避险资产依然有不错的空间，中小市值的股票（如罗素2000）、银行、地产等等，以及美股的中概股和香港的科网股。</p><p>但如果要仔细分析，不同资产在不同形态的降息路径下，表现是会有差异的。因此，想要了解未来的资产走势，就需要先了解降息的路径。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_79ee36e76584430a881556096a7dc5aa@5065245_oswg18043oswg625oswg262_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>市场及政策预定者的利率预测，资料来源：彭博</p><p>在美联储释放了50BP的降息之后，市场开始定价美联储在今年剩余的两次会议上再降息70BP，而根据政策制定者们的预测，2024年将进一步宽松仅50BP。<strong>这反应出市场的立场比政策制定者要激进得多，对经济状况的担忧也比政策制定者高得多</strong>。</p><p>另外，从整体的降息路径来看，呈现出的趋势是典型的“先急后缓”，市场预期美联储将在今年内将政策利率降至4%至5%区间，并在明年三季度快速下探至3%以上。这意味着，到明年三季度，市场预计美联储降息总幅度高达250BP以上，让政策利率在短的时间内回归到3%左右的位置。</p><p>当然，你可以理解为市场对未来的经济预期很差；但这样的降息幅度在另一个侧面也反映出，<strong>美联储将会以“雷霆手段”，去避免美国经济出现硬着陆的</strong>。</p><p>在宣布降息之后，鲍威尔就明确表示，这一决定并不是为了应对危机而降息，而是让货币政策从极端紧缩的状态中“松绑”，回归正常化，同时仍不排除未来进一步观察经济走向调整政策的可能。鉴于无论是市场还是政策制定者，都对进一步降息抱有期待，<strong>一些对利率敏感的风险资产，很有可能在这段时间领跑</strong>。</p><p>从美股本身而言，小盘股、价值股以及受益于降息的周期股、地产股和银行股等等，在降息开始之后的表现会相对亮眼；其他资产方面，原油、铜等受益于降息，但在最近一段时间表现不好的资产，有很大可能会重拾涨势，走出一波不错的行情。</p><p>而传统上在降息初期表现比较好的美债和黄金等避险资产，由于前段时间对降息本身已经有了充分定价，再加上市场在50BP降息之后，对美国经济的担忧有所缓解，在降息开启之后虽然还有上涨空间，但表现和弹性相对来说会弱于前述这类风险资产。</p><p>当然，一个非常重点的话题是，之前在纳指中占比较高的大型科技股，如英伟达、微软等等，面对如今的降息环境会有怎样的反映。在我们看来，<strong>现在是一个板块轮动的绝佳机会，大型科技股的股价仍有基本面支撑，但短期在这些板块中获利了结，切换到对利率更加敏感的小盘股，将会是不少资金的选择</strong>。</p><p>相对于大公司而言，小公司往往在高利率环境中表现不佳，因为它们的债务水平普遍高于大公司，并且更严重地依赖浮动利率贷款。更便宜的融资和更好的收益可能会提振它们的业绩基本面，并进而提升他们的股价表现。</p><p>另外，和美国大型科技股相对的是，2023年至今的绝大部分时间里，中国的科技股们表现都是相对较差的，直到今年开始才有了一定程度的估值回归；但相对于这些公司们的业绩质量，目前的估值普遍还是相对低位，特别是对外部流动性更加敏感的港股，弹性会比A股更大，<strong>诸如阿里巴巴、京东、腾讯等等仍然有不错基本面的企业，会是不错的投资标的</strong>。</p><p>当然，真正能促使股市进一步回暖的因素，仍然在于国内能不能进一步释放流动性。美国这边已经有了不错的示范，进一步的宽松不仅会让股市上升，也会提振整个市场的信心；而对于国内来说，外部的宽松效果想要真正达成全方位的信心好转，自然需要来自自身政策端的支持。</p><p><strong>03&nbsp; &nbsp;结语</strong></p><p>降息的时代开始了，全球资产配置将会进入一个再分配阶段。在这段时间里，如何配置自己的投资、进一步优化目前的投资结构，是每个理性投资者都要深思熟虑的事情。</p><p>在这里需要强调的是，盲目认为外部宽松就一定会导致热钱流入AH市场，我们自己不需要额外做什么就能躺着收涨的观点，其实是已经落后了的。现如今，新兴市场对于大部分的外资来说，并不只是中国了，印度、越南、巴西和南非等等，所有经济体都在期待迎接从美国流出的资金。</p><p>“打铁还需自身硬”，从国家的角度，就是经济发展的主动权要掌握到本国手里，期待别的国家只能是杯水车薪；从投资的角度，那就是挑选投资标的，一定要选择那些“好公司”，<strong>无论外部环境如何变化，自身都能创造出源源不断地增长和盈利动能</strong>。</p><p><strong>声明：本文仅用于学习和交流，不构成投资建议。</strong></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/OE4JjpYbBE-ObO7GjZaEeg" rel="noopener noreferrer nofollow" target="_blank">“躺平指数”</a>，作者：躺姐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956808680667784</id>
            <title>这家靠滤镜火遍全球的公司，抢先 Meta 苹果推出新一代 AI 智能眼镜，8400 元「租」一年</title>
            <link>https://www.36kr.com/p/2956808680667784</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956808680667784</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:05:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_39e1eb1a2d624bb3b81ea39946b30977@000000_oswg436874oswg541oswg622_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>即使没有用过，你也很可能对外网的热门拍照社交平台 Snapchat 有所耳闻。&nbsp;</p><p>这个拍摄平台以搞怪和丰富的动态滤镜闻名，算是 AR 技术的一种早期应用形式。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_f440017b7c5f44d889072966160466f5@000000_oswg443383oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>它的开发商 Snap 公司野心不仅仅在于做一个热门应用。2021 年，这家公司推出了首款 AR 眼镜——第四代 Spectacles，成为该领域的先锋。&nbsp;</p><p>而在近日举办的 2024 Snap 全球生态合作伙伴大会上，Snap 带来了第五代 Spectacles 智能眼镜，也是第二代 AR 眼镜。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_196c436b3c644698ab77890fdd6b1a51@000000_oswg64277oswg832oswg568_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这不仅是一个比上一代更好用的 AR 设备，还是一个面向未来的 AR 软件+硬件平台。&nbsp;</p><h2><strong>更好的 AR 眼镜&nbsp;</strong></h2><p>前三代的 Spectacles 眼镜主要还是一个自带摄像头、能发 Snapchat 短视频的眼镜「时尚单品」，采用了多彩的镜框和圆形的镜片，看起来就像一个度假用的墨镜。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_25167fcd32d8462aba10650e68412718@000000_oswg29347oswg720oswg405_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Engadget&nbsp;</p><p>正式进军 AR 领域的第四代 Spectacles 眼镜一改活泼的外观，看起来相当严肃：厚厚的黑色镜框，以及棱角分明的镜片，像是一个更具分量的 3D 眼镜。&nbsp;</p><p>全新的第五代 Spectacles 大体延续了「3D 眼镜」的设计语言，只是总体要更圆润，眼镜柄要更粗。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_4979575d22f747bf8ef54d803371619d@000000_oswg619882oswg832oswg622_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">第五代 Spectacles&nbsp;</p><p>虽然造型不如苹果 Vision Pro、Meta Quest 等头显设备那么夸张，但戴在头上，还是会因为太大而显得有点不协调。&nbsp;</p><p>226 克的重量也不算轻，相当于将一台国产大折叠手机挂脸上，比上一代的 134 克足足重了将近 70%。&nbsp;</p><p>大幅增重带来了更多的功能。上一代仅支持手势操作，这一代不仅 <strong>新增了语音输入，还能在手机上安装 App 进行联动</strong>，不过依旧不支持眼动追踪，也不支持音频播放。&nbsp;</p><p>用户在手机上安装 Snapchat 应用后，就可以把手机当作 Spectacle 的「手柄」，可以用来当作直升机游戏的操纵台，或者高尔夫模拟器中的球杆。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_42e7def312d24830963763246e35e37f@000000_oswg903481oswg1024oswg769_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，没有佩戴眼镜的用户，也可以通过手机摄像头，看看对面戴着眼镜的小伙伴在对着空气做什么了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_1835475f2b0b46ba925acb37bd472757@000000_oswg504345oswg1024oswg578_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：CNET&nbsp;</p><p>上一代被诟病的续航也有了增加，从 30 分钟提升到 45 分钟，虽然提升幅度高达 50%，但依旧不算是优秀的水平。&nbsp;</p><p>不少外网评测者还提到一个喜闻乐见的升级：第 5 代 Spectacles 发热对比上一代大大减少。The Verge 表示，即使带它到气温三十多摄氏度的洛杉矶市区，眼镜也不会像以前那样因为过热崩溃了。&nbsp;</p><p>作为一个用来看的设备，新一代 Spectacles 最重要的提升是显示的视野范围大幅提升，从 26.3 度提升到 46 度的对角线视野，相当于距离 3 米的距离看一块又长又窄的 100 英寸（2.54 米）屏幕。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a0284cde18b3484e891ce37df7bc4c42@000000_oswg884888oswg1024oswg558_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：CNET&nbsp;</p><p>考虑到用户已经把接近半斤重的设备夹在了脸上，这个大小其实是远远未能满足需求，跟苹果 Vision Pro 在现实世界变出 IMAX大屏的效果比，更是相形见绌。&nbsp;</p><p>The Verge 尝试用 Spectacles 玩模拟高尔夫游戏，出来的效果很难称得上「未来感」。&nbsp;</p><p>不过，眼镜形态的 Spectacles 的一大优势是不需要通过摄像头捕捉外界环境，也不会遮住眼睛，和现实世界以及身边人没有那么强的「断连」感，因此也很适合协作。&nbsp;</p><p>CNET 评测者和一名 Snap 团队的成员尝试了使用 Spectacles 进行协作，眼镜可以识别附近的另一位佩戴者，然后进行体验的共享，并且还会利用多个摄像头，把房间扫描成一个混合现实的网格。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_dc246b3b7ed745a09ee35ce84d183dfb@000000_oswg737363oswg1024oswg571_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">戴着眼镜就可以一起下棋，或者观棋&nbsp;</p><p>具体体验而言，即使是酒店环境这种小环境，两台眼镜之间的连接也不够实时。Snap 的目标是将连接体验拓展到更大的环境，例如户外，美术馆，或者展览会场。&nbsp;</p><h2><strong>面向未来的 AR 平台&nbsp;</strong></h2><p>和第五代 Spectacles 眼镜一起发布的，还有其搭载的全新「Snap OS」操作系统。&nbsp;</p><p>Snap OS 和 Vision Pro 上的 visionOS 类似，有一个在用户手上展开的主菜单界面，用户通过手势或者语音打开各种各样的应用。&nbsp;</p><p>Snap 希望借助这个操作系统，吸引更多开发者为 Spectacles 平台开发 AR 应用，特别是能够协作、共享体验的 AR 应用。&nbsp;</p><p>Snapchat 应用有一个名为「Lens Studio」的创作平台，主要用于滤镜的开发。而全新的 Lens Studio 5.0 平台，则增强了 AR 开发能力。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_63ba8330e7e84ea4a585407e40579489@000000_oswg181542oswg1024oswg386_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>开发者不仅可以跳过繁琐的编译环节，快速将项目推送至 Spectacles 眼镜，还能使用官方的 Spectacles 交互工具包快速构建应用体验，而不是从零开始设计软件交互。&nbsp;</p><p>Snap 机器学习（SnapML）平台还允许开发者直接在应用中使用自定义的机器学习模型，来识别、追踪和增强物体。&nbsp;</p><p>对于这些 AR、VR 或者 XR 平台来说，内容和应用是始终绕不开的坎。苹果通过和多家应用和应用提供商联手，并直接支持 iPad 的海量应用，尽可能让这个新生的平台快速成熟。&nbsp;</p><p>Snap 也走了类似的道路，和其他品牌合作推出了应用体验，比如乐高官方的「BRICKTACULAR」游戏，允许用户一起搭积木，未来还会有《星球大战》IP 的更多内容。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_8419f9602f034db28145c938d059b2a5@000000_oswg849691oswg832oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，Snap 比苹果 Vision Pro 和 Meta Quest 走得更远，愿意为大模型开发者提供比较敏感的摄像头、麦克风的权限，让他们为 Spectacles 添加多模态大模型，直接看用户所看，听用户所听。&nbsp;</p><p>Snap 本身也和 OpenAI 合作，Spectacles 集成了自家基于 ChatGPT 打造的「My AI」聊天机器人， 也引入了 OpenAI 的多模态 AI 模型。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_9148f2eb48a0442aba95a9e05a8fb04c@000000_oswg935760oswg832oswg622_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>CNET 测试了一下 Spectacles 的 AI 功能，尝试生成一些「3D Emoji」，发现机器人反应比较慢，也不能总是清晰理解用户的要求。&nbsp;</p><p>Spectacles 的提供方式类似订阅制，开发者计划需要 <strong>每个月 99 美元</strong>（折合人民币约 702.16）的费用，并且需要一次订阅一年，也就是 <strong>一次需要缴费 1188 美元</strong>（折合人民币约 8425.89 元），停止订阅后，需要将眼镜寄回 Snap 公司。&nbsp;</p><p>除了这个方案之外，Spectacles 不对外销售，普通消费者无法在市场买到这款产品。&nbsp;</p><p><strong>也就是说，对于开发者来说，他们不仅需要支付高昂的费用测试 Spectacles 软件，短期内也无法收到来自用户的反馈，更不用提收入转化。</strong></p><p>关于 Spectacles 对开发者的吸引力，Snap CEO Evan Spiegel 的看法是这样的：&nbsp;</p><p><strong>我认为这与开发人员对早期台式计算机或早期智能手机真正兴奋的原因是一样的。我认为这是一群有远见的技术专家，他们对未来感到非常兴奋。&nbsp;</strong></p><p>在 Snap 预想中， AR 生态构建是一个十分长久的过程，Spiegel 认为，在这个世纪的末尾，Spectacles 才会成为一项真正有意义的业务。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a6c76c4e39d34deb9e4e624b80cfd9d4@000000_oswg407024oswg832oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Snap CEO Evan Spiegel&nbsp;</p><p>从这个设计不够轻便简洁，显示效果还比较局限，生态依赖开发者积极性的第五代 Spectacles 来看，Snap 确实还有很长的路要走。&nbsp;</p><p>但或许他们要进一步加快脚步了。Meta 有望在下周推出全新智能眼镜产品，CEO 扎克伯格声称，这将是一副「无可挑剔」的 AR 眼镜。&nbsp;</p><p>根据彭博社 Mark Gurman 的爆料，苹果 Vision 团队正在继续试验几种不同的穿戴式 VR/AR 眼镜产品，其中一款类似 Ray-Ban Meta 的智能眼镜。&nbsp;</p><p>实力和资源都要更强的玩家在后面追赶，曾经的领头羊 Snap，或许需要拿出比目前更好的产品和方案。&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&amp;mid=2652367326&amp;idx=1&amp;sn=f7141e128f7d10e2c783cd9b2fa92d5c&amp;chksm=9a13b9b722343a7481350d67299cf8614b998c19331e4444e122664c7ad7415d9d267d44c308&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“爱范儿”（ID：ifanr）</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956738431907969</id>
            <title>英伟达生态新动作，瞄准了工业大赛道</title>
            <link>https://www.36kr.com/p/2956738431907969</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956738431907969</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:04:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_9012e37f1c4147be84b9e5bb71368f9a@000000_oswg51748oswg1080oswg574_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>春江水暖鸭先知。NVIDIA当下的动作正在透露出一些新的风向。<strong>‍‍</strong>‍‍‍‍‍‍</p><p>不久前，NVIDIA(英伟达)发布了一个面向3D建模的生成式AI服务，引起了业内的广泛瞩目。如果说之前的生成式AI更多是在生成文字、图片、视频等二维世界的内容。那么，这次NVIDIA正在通过生成式AI去帮助企业构建3D资产，加速数字孪生和仿真产业的发展，同时也加速AI在物理世界的应用落地。</p><h2><strong>01 “CUDA原生”瞄准了工业</strong></h2><p>春江水暖鸭先知。作为全球加速计算的领导者，NVIDIA的动作正在透露出一些新的风向。</p><p>NVIDIA创始人兼CEO黄仁勋，在2024年SIGGRAPH上的两场围炉谈话中，将其对AI的最新洞察，放在了生成式AI和加速计算，如何通过可视化，来改变制造业等行业上。NVIDIA也在会议期间推出了一套全新的NIM微服务。</p><p>SIGGRAPH大会是讨论计算机图形学最新创新的场所。NVIDIA发布了适用于OpenUSD、几何体、物理学、材质等的生成式AI模型与NIM微服务。OpenUSD是三维场景内部数据交换的开源软件，已逐渐成为三维视觉、建筑、设计、制造等众多行业的标准。</p><p>借助这些模型和服务，开发者能加速制造业、汽车、机器人等行业应用的开发。</p><p>在两场围炉谈话中，黄仁勋探讨了构建数字孪生、虚拟世界的重要性。他说，行业通过构建城市规模的大规模数字孪生，来提高效率并降低成本。“比如，在部署到下一代人形机器人之前，AI可以在这种虚拟世界中进行训练。”</p><p>为什么黄仁勋会重点讨论工业可视化、虚拟世界或数字孪生？NVIDIA又为何在此时在CUDA生态中，推出全新的NIM微服务？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_01d19d64c6a44b1ba89d2754cee95ce8@000000_oswg562333oswg818oswg432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来自NVIDIA官网</p><p>就如NVIDIA Omniverse与仿真技术副总裁Rev Lebaredian所表示的——重工业的生成式AI潮已经到来。数智前线也获悉，生成式AI正在从一些简单场景，走入复杂的生产环节。而上述技术生态，可加速这一进程。</p><p>“直到最近，数字世界的主要用户还是创意行业；而现在，借助NVIDIA NIM微服务为OpenUSD带来的增强功能和可访问性，各个行业都可以创建基于物理学的虚拟世界和数字孪生，为这次新一轮AI技术热潮做好准备。”Rev Lebaredian说。</p><p>在汽车行业，国内车企都在“卷”数字孪生。“最近特斯拉即将发布FSD12.5版本，也在积极推动FSD在中国的落地。”一家中国大型车企人工智能人士告诉数智前线，“特斯拉把仿真作为战略级目标，我们也在做元宇宙，解决自动驾驶数据闭环问题。”此前，车企采集“鬼探头”数据难度大、成本高。现在，车企可以在元宇宙仿真环境中，解决长尾场景的训练。</p><p>在机器人行业，一家电力巡检机器人公司正在通过仿真环境训练AI，让机器人能实时感知到电厂内复杂的环境和物理空间，规划移动路线，并可以查看沿路数千个在不同设备上的表计。</p><p>建筑设计是一项复杂耗时的工作，建筑设计中的3D模型是个必不可少的交付件。而对于一些复杂几何形状和异形结构，3D模型的重建工作难度较大。现在，一些设计企业与AI企业一起，尝试只需要一些图片、草图和文字，就可以生成模型。还可以赋予建筑设计不同的材质，来完善设计。</p><p>在钢铁行业，金相分析是通过显微镜查看材料切片内部的缺陷和结构等的一种方法，来了解基础材料的整体性能。传统人工的效率较低，还要严重依赖人的经验。现在，不少钢铁企业的一个共同的诉求是，期望利用以往的知识库，通过训练专业的AI，来对材料进行全方位的解析。</p><p>而NVIDIA通过全新的NIM微服务，让应用企业不用从零开始，直接去调用服务，再结合自己的数据，快速实现一个应用。因此，一些企业将此形容为“CUDA原生”。</p><p>伴随生成式AI从一些边缘场景到更深层次场景的落地，黄仁勋称，“每个人都将拥有AI助手”。同时，AI与图像技术等的融合正在深化，“几乎每个行业都将受到这项技术的影响，无论是科学计算以更少的能源更好地预测天气，还是与创作者合作生成图像，或为工业可视化创建虚拟场景，”黄仁勋表示，“生成式AI还将彻底改变机器人自动驾驶汽车领域。”</p><h2><strong>02 新NIM微服务，带来哪些想象</strong></h2><p>上述这些行业应用背后，都依赖3D建模和仿真技术的应用。</p><p>而3D内容和场景的构建在过去一直是令人头疼的事情，它涉及的链条和流程很复杂，比如建模、着色、动画、照明、渲染等。</p><p>在过去数十年，动画、视觉特效和游戏工作室一直在努力提升流程中各种工具之间的互操作性，但收效甚微。将数据从一个位置迁移到另一个位置非常棘手，因此工作室构建了复杂的工作流程来管理数据互操作性。</p><p>而且，除了系统和工具的割裂，传统的3D制作流程是线性协作，涉及多部门多人员的格式转换和修改，费时费力。</p><p>OpenUSD是一个开源的通用3D数据交换框架，它在2023年由NVIDIA、皮克斯、苹果等厂商牵头成立，可通过软件工具与数据类型之间的互通构建虚拟世界，具有极高的互操作性和兼容性，解决创建三维场景时工作流和复杂性方面的多项挑战。</p><p>OpenUSD也是NVIDIA Omniverse平台的基础。在与《连线》杂志资深撰稿人的对谈中，黄仁勋曾如此表示：OpenUSD是第一种几乎将所有工具的多模态表达融合在一起的格式。理想情况下，随着时间的推移，人们可以将几乎任何格式引入其中，让每个人都能进行协作并使内容永远留存。而生成式AI，一定能够助力Omniverse产生更好的仿真效果。</p><p>而NVIDIA这次推出的针对OpenUSD开发的NIM微服务，也是全球首个用于OpenUSD开发的生成式AI模型。它将生成式AI的能力以NIM微服务的形式，整合进USD工作流中，大幅降低了用户运用OpenUSD的门槛。同时，NVIDIA也发布了多款适用于机器人数据格式和Apple Vision Pro流式传输的全新USD连接器。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_7bfaa1257ea54a5d99ecf4c7cc4798cd@000000_oswg253560oswg607oswg337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来自NVIDIA官网</p><p>目前，已经发布的NIM微服务有三项：一是USD Code NIM微服务，可以回答常识性OpenUSD问题，并基于文本提示自动生成Python代码。</p><p>二是USD Search NIM微服务，使开发者能够使用自然语言或图像输入，在海量OpenUSD、3D和图像数据库中进行搜索，大大提高企业流程化检索并处理材料的速度。</p><p>三是USD Validate NIM微服务，可以检查上传文件与OpenUSD发布版本的兼容性，并生成完全由NVIDIA Omniverse Cloud API驱动的RTX渲染路径追踪图像。</p><p>除了NVIDIA提供的原生NIM微服务，生态伙伴也正在基于这些微服务，创建了多个热门的AI模型，提供给用户进行推理优化。</p><p>全球知名的创意内容平台Shutterstock基于NVIDIA最新版本的Edify视觉生成模型，推出了文本转3D的全新服务，包括制作3D原型或填充虚拟环境等。</p><p>比如为虚拟场景创建能够准确反射的照明是一项复杂的任务。以前，创作者需要操作昂贵的360度摄像机装备，亲身到拍摄现场从头开始创建背景，或者在庞大的资料库中搜索近似的内容。</p><p>但现在，通过3D生成服务，用户只需用文字或图片描述他们所需要的具体环境，就能得到最大分辨率为16K的高动态范围全景图像 (360 HDRi)。而且，这些场景和组件可以快速切换，比如让跑车出现在沙漠、热带海滩或者蜿蜒的山路上。</p><p>除了创建照明，创作者也可以快速添加各种渲染材质，如混凝土、木材或皮革等，从而构建自己的3D资产。而且，在AI帮助下生成的3D资产也可以随时进行编辑并以各种流行的文件格式提供。</p><p>而NVIDIA的Edify AI模型，也在帮助Getty Images让艺术家实现任意控制图像的构图和风格。比如在一张完美的珊瑚礁照片上漂浮一个红色沙滩球。而且，创作者也可以用企业的数据，在基础模型上进行微调，生成符合特定品牌创意风格的图像。</p><p>这些模型微服务和工具正在极大地加速品牌方在3D资产上的创建，将使数字孪生的开发变得更加普及和便捷。</p><h2><strong>03 先发企业已开始尝试</strong></h2><p>正是随着3D内容和资产创建变得更加便捷和准确，工业、自动驾驶、工程、机器人等行业正在享受到生成式AI带来的技术红利。尤其在制造业和广告创意行业，一批先发企业正在积极通过NVIDIA Omniverse平台加速数字孪生和仿真的落地应用。</p><p>可口可乐是首个将Omniverse和NIM微服务所提供的生成式AI用于营销场景的品牌。在其演示的一段视频中，只需要在系统中用自然语言输入“给我建一张桌子，上面放着塔可和莎莎酱，沐浴在晨光中”。</p><p>很快，USD Search NIM微服务能在庞大的3D资产库中搜索出对应的3D资产，通过API的方式快速调用，而USD Code NIM则可以将这些模型组合成场景，开发人员输入提示就可以获得用于创造新颖3D世界的Python代码，大大增强了他们的创作能力。可口可乐通过生成式AI，可以在全球100多个市场定制个性化的形象，实现本地化营销。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_9891b50fe4454f51afe211af51c37dc6@000000_oswg352318oswg649oswg375_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来自NVIDIA官网</p><p>而作为可口可乐背后的广告服务商，WPP专门推出了智能营销操作系统。该系统利用了Omniverse开发平台和OpenUSD，能够非常精简且自动化地实现多语言文本、图像和视频的创建，简化了广告主和营销人员的内容创建过程。通过生成式AI服务于客户，WPP将一个个疯狂的创意搬到了现实。</p><p>正如WPP首席技术官所言，“这些创新的美妙之处在于它与我们的工作方式高度兼容，并充分利用了开放标准。这不仅加速了未来的工作，而且使我们能够继续巩固和扩展我们之前在OpenUSD等标准上的所有投资。通过使用NVIDIA NIM微服务与NVIDIA Omniverse，我们能够以前所未有的速度与可口可乐公司等企业联合推出创新的新生产工具。”</p><p>作为全球最大的消费电子代工企业，富士康专门为墨西哥的一家新工厂构建了虚拟的数字孪生工厂，工程师可以在虚拟环境中定义流程和训练机器人，从而提高工厂的自动化水平和生产效率，节约时间、成本和能源。</p><p>富士康在背后也用到了Omniverse平台来构建其数字孪生，将所有3D CAD元素整合到同一个虚拟工厂中，并在那里使用Omniverse和OpenUSD上开发的可扩展机器人仿真平台NVIDIA Isaac Sim对机器人进行训练，为其数字孪生带来物理级精确和逼真的视觉呈现。</p><p>除了富士康，包括台达电子、联发科、和硕等电子制造企业，都在使用NVIDIA AI和Omniverse构建工厂数字孪生。</p><p>而小鹏汽车MPV车型小鹏X9在设计过程中则使用Omniverse平台，通过将车型开发工作流引入虚拟世界，让小鹏汽车在新车设计时规避传统工作流存在的瓶颈。</p><p>比如，Omniverse平台一方面拥有强大的互操作性，使得用于工业建模、渲染和3D特效的文件和数据不再需要繁复的转换，加速了小鹏汽车设计团队之间的沟通协作；另一方面，小鹏汽车借助Omniverse的实时渲染与光线追踪等功能，实现了汽车颜色和内饰变化的即时可视化，让虚拟效果更加真实，帮助承接用户需求，进而改进产品体验。</p><p>过去两年，生成式AI的爆火让外界的目光更多在一些ToC和协同办公领域的应用上，但现在，物理世界也将迎来一波新的爆发和机遇。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkwNDMyOTA1NA==&amp;mid=2247490771&amp;idx=1&amp;sn=12404b86092a96942b903a567c42b679&amp;chksm=c125ec270b68157e2273e179bec76e18f0196eaecb48f1c9e7a77e0427b5213ec7d4310be568&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“数智前线”（ID：szqx1991）</a>，作者：周路平 赵艳秋，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956839119665544</id>
            <title>从云栖大会，透视中国AI水面下的暗涌</title>
            <link>https://www.36kr.com/p/2956839119665544</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956839119665544</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 11:03:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2024云栖大会上，极少在公开场合露面的阿里CEO、阿里云董事长兼CEO吴泳铭对AI的未来发展提出了积极的观点。他认为过去22个月，AI发展速度已超任何历史时期，“但我们依然还处于AGI变革早期”。面向未来，他提出生成式AI最大的想象力，“绝不是在手机屏幕上做一两个新的超级app，而是接管数字世界，改变物理世界。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_0a3adc0367194594b5e638353ecab757@11416942_oswg3865546oswg4800oswg3200_img_jpeg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">阿里CEO、阿里云董事长兼CEO吴泳铭</p><p>此刻距离OpenAI发布ChatGPT已过去22个月。全球AI技术圈和创投圈经历了一个完整周期：技术奇点爆发引发狂热追捧，再到创新曲线放缓，失望和质疑声音浮现。如今随着OpenAI发布o1模型，AI深入各行各业，市场的信心正在重新爬升。吴泳铭的此次发声，在当下的冷暖切换期，无疑更具参考意义。</p><p><strong>如何看待这一次AI革命浪潮？AGI的最终形态会是什么？我们如何把握这一次技术革命？</strong></p><p>吴泳铭发言和这届云栖大会变成了最好的解题集。主论坛成为AI创业者的舞台，阿里云请来了国内大模型、自动驾驶和人型机器人的明星创业者和科学家。走进云栖小镇，阿里云几乎搬来了中国AI圈所有的创业公司和产品，4万平米的展区，挤满了全球百余款AI应用。400多场并行话题及论坛中，150余场和大模型相关。在世界机器人大会爆火的人形机器人，在云栖再次当上了顶流。</p><p>上一届云栖大会，焦点还在AI上游的算力和生态。这一届云栖成为中国AI产业的微缩地图。AI开始走出服务器，深入千行百业。始于2009年的云栖大会，见证了每一波中国科技潮水的方向，也给出了理解当下的线索。</p><h2><strong>01 悄然演进的新产业革命</strong></h2><p>ChatGPT爆火后，如何定义这一浪潮的级别，成为全球顶级大脑热议的话题。其中，互联网是个热门对比维度。</p><p>A16Z创始人 Marc Andreessen提出过一个有趣的观点：互联网通过连接现有的计算机来促进新计算机的创建，而AI尤其是大模型，则更像是一种新型计算机。</p><p>对于这个全球记者采访提纲里的CEO热门问题，吴泳铭给出了进一步的延伸。他认为，过去三十年，互联网浪潮的本质是连接，互联网连接了人、信息、商业、服务等等，通过连接提高了世界的协作效率，创造了巨大的价值，改变了人们的生活方式。但生成式AI是通过给生产力供给增加智能，从而为世界创造更大的内在价值。“这种价值创造，可能是移动互联网连接价值的十倍、几十倍。”</p><p>吴泳铭给予AI浪潮如此之大的预期，很大原因在于作为中国最大云厂商的掌舵者，他可以亲眼见证中国AI市场水面之下的暗流涌动。正如他在云栖大会上提到：</p><p>“今天我们接触到的所有客户、所有CTO，几乎都在用AI重构自己的产品。大量新增需求正在由GPU算力驱动，大量存量应用也在由GPU重新编程。在汽车、生物医药、工业仿真、气象预测、教育、企业软件、移动APP、游戏等行业，AI计算正在加速渗透。”</p><p>传统AI焦点在于模拟人类的感知，生成式AI却将机器智能跃升到了思考推理和创造的维度。吴泳铭在演讲中进一步解释道：</p><p>“生成式AI让世界有了一个统一的语言——Token。它可以是任何文字、代码、图像、视频、声音。AI模型可以通过对物理世界数据的Token化，理解真实世界的方方面面，比如人类行走、奔跑、驾驶车辆、使用工具的动作，绘画、作曲、写作、表达、教学、编程的技巧。理解之后，AI就可以模仿人类去执行物理世界的任务。这将带来新的产业革命。”</p><p>互联网本质上只改变了人类“连接”另一个人类、信息、商业、服务的形态，但大模型同时改造前端的交互界面，和后端的生产环节。很多悄然开始的产业革命，并不容易被普通人所察觉。</p><p>以深势科技为例。这家公司是“AI for Science”科学研究范式的头部践行者，运用人工智能和多尺度模拟仿真算法，结合先进计算手段求解重要科学问题，为人类文明最基础的生物医药、能源、材料和信息科学与工程研究打造新一代微尺度工业设计和仿真平台。</p><p>基于深势科技发布的Uni-Mol分子构象大模型，可实现分子生成、性质预测等多种通用能力。在药物发现领域，基于Uni-Mol开发的虚拟动力学分子生成方法VD-Gen，能直接在蛋白靶点空腔中生成具有高结合亲和力的分子。</p><p>基于阿里云高性能计算，深势科技将单次预测能支持的最大氨基酸序列长度提升至 6.6k，覆盖99.992%已知的蛋白序列。</p><p>来自广东的拓斯达工业机器人公司，则将传统的工业机器人控制软件与通义大模型结合，让工业机器人在指令控制、传感反馈、知识学习等方面具备了新能力。在 3C、锂电、光伏等行业的自动化生产场景中，集成了大模型能力的拓斯达六轴工业机器人，可以与现场工程师通过语言交互，无代码完成码垛、喷涂、装配等复杂任务。</p><p>生成式AI的想象力正在徐徐展开。物理世界的大部分事物都会具备AI能力，形成下一代的全新产品，并与云端AI驱动的数字世界连接产生协同效应。</p><h2><strong>02 生成式AI的机会在改变物理世界</strong></h2><p>2008年，移动互联网诞生，2012年获得全行业共识，这中间走过了五年。ChatGPT引发的生成式AI创业热潮，几乎是从第一天诞生起就达到了全球性共识，全球科技巨头都在不计成本火速投入。</p><p>一大原因在于，移动互联网只做到了物理世界的联网，但生成式AI可以真正改造物理世界。吴泳铭在云栖大会上指出，“我们不能只停在移动互联网的视角看未来。生成式AI最大的想象力，绝不是在手机屏幕上做一两个新的超级app，而是接管数字世界，改变物理世界。”</p><p>汽车行业正在发生这样的变革。之前的自动驾驶技术，是靠人来写算法规则，几十万行代码，仍然无法穷尽所有的驾驶场景。小鹏汽车董事长、CEO何小鹏在云栖大会现场提到，自动驾驶从1925年开始研发，但接近百年时间都只能做到特定场景下使用。“一个人无法用规则去面对世界上所有的场景，即使仅仅在开车这一个专业的业务。”</p><p>采用“端到端”的大模型技术训练后，AI模型直接学习海量人类驾驶视觉数据，让汽车具备了超越大部分司机的驾驶能力。何小鹏表示：“对于最普通的用户，从现在到未来的36个月，可以让我们每一个人在每一个城市都像老司机一样开车。”</p><p>宇树科技CEO王兴兴也分享了类似的感受，他曾经非常反对做人形机器人，直到大模型的出现看到了新的可能。</p><p>过去让大模型实现跟人类一样的复杂操作基本是无解的，因为人类动作是无穷的。即使是端茶、倒水这样的简单场景，就涉及到几百种细微动作。过去都要依靠人类专家手动编程，大模型为机器人提供了一种可能性——机器人能够形成理解事物本质及其处理方法的世界模型。</p><p>人型机器人带来的好处有两方面，首先，今天生活的世界是围绕人类行为所优化的，人形可以让机器人最大程度上适应环境，其次，通用机器人在制造方面存在巨大的规模效应。只有大规模制造，从而获得成本优势，才能真正实现机器人的真正普及。</p><p>吴泳铭指出：“机器人将是下一个迎来巨变的行业。未来，所有能移动的物体都会变成智能机器人。它可以是工厂里的机械臂、工地里的起重机、仓库里的搬运工、救火现场的消防员、家庭里的宠物狗。”</p><p>在吴泳铭的畅想里，未来，工厂里会有很多机器人，在AI大模型的指挥下，生产机器人。现在每个城市家庭里有一辆车，未来每个家庭可能会有两三个机器人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_1400a209407a4dcba458e7b3d1ab6bf2@11416942_oswg2250870oswg4800oswg3200_img_jpeg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AI驱动的数字世界连接着具备AI能力的物理世界，将会大幅提升整个世界的生产力，对物理世界的运行效率产生革命性的影响。而这一切来临的快慢，取决于AI基础设施的进化速度。</p><h2><strong>03 我们仍处于AI大基建时期</strong></h2><p>历史上每一波应用的喷涌而出，前提都是基础设施的完善。4G、5G和智能手机的普及，带来了短视频呼啸而来的大爆发。公路、铁路基建，催生了中国领先全球的电商、物流业。</p><p>以互联网基建为例。截止到今年6月，中国光缆线路总长度达6712万公里，全国互联网宽带接入端口11.7亿个，我国移动电话基站总数达1188万个，5G基站总数达391.7万个。</p><p>AGI应用的繁荣，同样势必根植于一个健全的大一统的算力基建之上。从2012年的AlexNet模型到2017年的AlphaGo Zero，算力消耗足足翻了30万倍。而ChatGPT横空出世的背后是，微软Azure云上的数万张A100芯片，成本高达数亿美元。</p><p>根据OpenAI的研究报告，自2012年开始，AI训练需要的算力每隔 3-4 个月便会翻番，到 2018 年，训练所耗费的算力更是增长了大概 30 万倍，而相比之下，摩尔定律在同样的时间里只有 7 倍的增长。</p><p><strong>当物理世界被纳入AI改造的范畴后，训练和推理所需的算力成本更会爆发式增长。</strong></p><p>这让云计算天生地跟AIGC绑定在了一起。云计算的算力集中、灵活部署、按需付费、成本较低等特点，尽管不能解决全部问题，但几乎是算力短缺昂贵的背景下的唯一答案。无论是训练还是推理，大模型都离不开云。</p><p>吴泳铭在云栖大会上提到，在新增算力市场上，超过50%的新需求由AI驱动产生，AI算力需求已经占据主流地位。这一趋势还会持续扩大。过去一年，阿里云投资新建了大量的AI算力，但还是远远不能满足客户的旺盛需求。</p><p>CPU主导的计算体系正在加速向GPU主导的计算体系转移，AI计算正在加速渗透千行百业。当前，行业前沿模型训练计算量每年增长4~5倍，中国AI算力规模2022~2027年复合增长率高达33.9%；模型参数以10倍速增长，模型数据集以50倍速增长，对存力也提出了更高需求。</p><p>为提升智驾大模型训练效率，小鹏汽车早在2022年就携手阿里云在乌兰察布建成中国最大的自动驾驶智算中心，将自动驾驶模型训练效率提升了超600倍。而近两年内，由于大模型技术快速发展，阿里云已将此智算中心的算力储备扩张超4倍至2.51Eflops，为小鹏汽车提供稳定高效的算力底座，支撑了大模型快速迭代，实现智驾“全国都好用”。</p><p>本届云栖大会上，“全球首款AI汽车”小鹏P7+也亮相了2024云栖大会。这款车搭载了业内领先的端到端大模型。过去2年，小鹏汽车与阿里云共建的AI算力规模提升超4倍。何小鹏表示，将继续深化与阿里云的AI算力合作，加速推动端到端大模型拓展自动驾驶上限，提升下限。</p><p>吴泳铭无疑清晰地看到了这一趋势。自宣布“AI驱动、公共云优先”以来，阿里云大刀阔斧地进行投入AI基础设施建设。在今年的云栖大会，他再次强调：</p><p>“阿里云正在以前所未有的强度投入AI技术研发和基础设施建设。我们的单网络集群已拓展至十万卡级别，正在从芯片、服务器、网络、存储到散热、供电、数据中心等方方面面，重新打造面向未来的AI先进基础设施。”</p><p>本次云栖大会，阿里云展示了AI驱动的全系列产品家族升级。</p><p>最新上线的磐久AI服务器，支持单机16卡、显存1.5T，并提供AI算法预测GPU故障，准确率达92%；阿里云ACS首次推出GPU容器算力，通过拓扑感知调度，实现计算亲和度和性能的提升；为AI设计的高性能网络架构HPN7.0，可稳定连接超过10万个GPU ，模型端到端训练性能提升10%以上；阿里云CPFS文件存储，数据吞吐20TB/s，为AI智算提供指数级扩展存储能力；人工智能平台PAI，已实现万卡级别的训练推理一体化弹性调度，AI算力有效利用率超90%。</p><p>同时，阿里云宣布通义千问三款主力模型再次大幅降价，最高降幅85%，百万tokens价格低至0.3元。过去半年，阿里云百炼平台持续降低大模型调用的门槛，进一步推动大模型的普惠。</p><p>模型成本与整个社会的创新之间是一个结构明确的跷跷板。伴随AI基础设施成本下降一同发生的，则是跷跷板另一端创新的喷涌而出。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956760979863939</id>
            <title>留子们用火星文写避雷帖，AI竟看懂了？我们实测：几乎全军覆没</title>
            <link>https://www.36kr.com/p/2956760979863939</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956760979863939</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 10:56:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote><p>这种用法也是够邪门的。&nbsp;</p></blockquote><p>留子们在写一种很新的差评。</p><p>由于全球点评打卡平台，都有个自动翻译的功能，为了防止被店家骚扰，也为了给同胞避雷，身在海外的国人们，想出各种奇招优雅给差评。</p><p>例如，打 5 分忽悠老板，再用中文加密：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_0a4b1e3e4f514d54800362bbf8c06907@000000_oswg823495oswg735oswg1318_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>用中文谐音写了一堆差评，然后在结尾给个虚假好评，商家拿翻译器一翻，只看到一个早餐不错。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_57ec4a16f058447bab02fe07e26d747e@000000_oswg248469oswg1080oswg671_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有人费老大劲儿，用米粒摆出「报吃」的汉字，中国人一看就懂：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a1e8f5fd5f7444aa8e717faccdc89cee@000000_oswg716435oswg1080oswg673_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更有甚者，重启上古火星文，直接干翻各类翻译器。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a842864548ad4426866afefb57dd23b1@000000_oswg98609oswg784oswg710_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但是，最近有网友发现，这段如同计算机乱码的火星文差评，AI 竟然也能读懂啦。</p><h2><strong>「哈利・波特都比我住得好」</strong></h2><p>这事儿，还得从一个海外避雷帖说起。</p><p>有网友去国外旅游时，入住了一家酒店，居住体验极差。</p><p>他一气之下，跑去爱彼迎官网，用火星文写下了一段差评。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_98980981019d4ef68ff76b3d81b21eeb@000000_oswg435400oswg1080oswg899_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>本以为只有中国人能看懂，没想到竟被 AI 破解了。</p><p>有网友复制了这段火星文，然后粘贴给各家大模型，并给出一段提示词：</p><blockquote><p>Prompt：&nbsp;</p><p>Whats the meaning of the Chinese comment about the Airbnb？&nbsp;</p><p>中文提示词：&nbsp;</p><p>这是一段加密后的酒店点评文字，请完整解密还原。&nbsp;</p></blockquote><p><strong>这是 Claude 3.5 Sonnet 的回答：</strong></p><p>我来为您解密这段加密后的酒店点评文字。</p><ul><li>解密后的内容如下：1.0</li><li>"不要来住"</li><li>千万不要千万！墙壁和纸一样薄，这样的价格房间竟然在阁楼，难道我是当年的姑娘？洗澡水太小，厕所的灯光也昏暗，哈利波特都比我住的好。避雷！都不许来住！！！</li><li>这是一条非常负面的酒店评价。评分只有 1.0 分（满分 5 分），评价者强烈建议其他人不要入住这家酒店。主要投诉点包括：</li><li>1.&nbsp;房间隔音差（墙壁和纸一样薄）</li><li>2.&nbsp;价格与房间质量不符（价格不菲但房间在阁楼）</li><li>3.&nbsp;洗澡设施不佳（水流太小）</li><li>4.&nbsp;厕所照明不足（灯光昏暗）</li><li>评价者用了一些夸张的比喻来表达不满，如&nbsp;"难道我是当年的姑娘"&nbsp;可能暗指房间条件像古时妓院，"哈利波特都比我住的好"&nbsp;则是说即使是住在楼梯下储物间的哈利波特，居住条件也比这里好。&nbsp;最后，评价者用&nbsp;"避雷"&nbsp;一词警告其他人远离这家酒店，并强调&nbsp;"都不许来住"，表达了极度的不满和失望。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_b247520391264d16b7f71aa75ab10915@000000_oswg430679oswg793oswg860_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>这是 GPT-4o 的回答：</strong></p><p>这段文字使用了网路上的火星文、谐音字和一些符号来进行加密，以下是解密后的酒店点评原文：</p><ul><li>3.0</li><li>“不要来住”</li><li>骗中国人不骗中国人！墙壁和纸一样薄，这么贵的价格房间竟然在阁楼，难道我是当年的灰姑娘？洗澡水又少，厕所的灯光也昏暗，哈利波特都比我住得好。避雷！都不许来住！！！&nbsp;这段点评表达了对酒店的不满，主要包括房间墙壁隔音差、房间位置不佳、洗澡水少、厕所灯光昏暗等问题。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_38c2722749544b94bbeb73b05fe52afc@000000_oswg56216oswg542oswg692_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>这是 o1-preview 的回答：</strong></p><p>思维链摘要：</p><p>Deciphering symbols</p><p>I'm&nbsp;analyzing&nbsp;an&nbsp;encrypted&nbsp;hotel&nbsp;review&nbsp;with&nbsp;a&nbsp;mix&nbsp;of&nbsp;Chinese,&nbsp;Russian,&nbsp;phonetic&nbsp;symbols,&nbsp;and&nbsp;Japanese&nbsp;hiragana.&nbsp;The&nbsp;text&nbsp;might&nbsp;be&nbsp;in&nbsp;"Martian&nbsp;language"&nbsp;using&nbsp;homophones&nbsp;and&nbsp;similar&nbsp;characters.&nbsp;Let's&nbsp;break&nbsp;it&nbsp;down.&nbsp;</p><p>Figuring out the title</p><p>OK,&nbsp;let's&nbsp;break&nbsp;down&nbsp;the&nbsp;title&nbsp;"卟崾莱住"&nbsp;into&nbsp;"不要来住"&nbsp;by&nbsp;matching&nbsp;similar&nbsp;characters.&nbsp;This&nbsp;tells&nbsp;me&nbsp;it's&nbsp;about&nbsp;avoiding&nbsp;a&nbsp;stay,&nbsp;which&nbsp;seems&nbsp;interesting.&nbsp;</p><p>Deciphering lines</p><p>I’m&nbsp;matching&nbsp;transliterated&nbsp;Chinese&nbsp;characters&nbsp;to&nbsp;Cyrillic&nbsp;ones,&nbsp;tweaking&nbsp;only&nbsp;the&nbsp;vowel&nbsp;sounds.&nbsp;Each&nbsp;line&nbsp;translates&nbsp;smoothly,&nbsp;confirming&nbsp;the&nbsp;title's&nbsp;meaning.&nbsp;</p><p>Piecing together I’m&nbsp;translating&nbsp;and&nbsp;interpreting&nbsp;Chinese&nbsp;text,&nbsp;thinking&nbsp;through&nbsp;the&nbsp;use&nbsp;of&nbsp;homophones&nbsp;and&nbsp;characters&nbsp;to&nbsp;form&nbsp;meaningful&nbsp;sentences,&nbsp;like&nbsp;identifying&nbsp;the&nbsp;meaning&nbsp;of&nbsp;"笩洃姑娘"&nbsp;as&nbsp;"灰姑娘".</p><p>标题：“不要来住”</p><p>正文：“中国人不骗中国人！墙壁和纸一样薄，这么贵的价格房间竟然在阁楼，难道我是当灰姑娘？洗澡水又少，厕所的灯光也昏暗，哈利波特都比我住的呢。避雷！都不许来住！！！”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d183b1e95aac4472a1eb64f486f07daa@000000_oswg65576oswg500oswg1265_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>这是谷歌 Gemini Advanced 的回答：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ad79c714a6f64807900460e9e83d103f@000000_oswg389532oswg1080oswg1252_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>这是阿里的 qwen2.5 72B 的回答：</strong></p><ul><li>3.0</li><li>“不要来住”</li><li>房间人不骗房间！墙壁和纸一样薄，这个价格的房间竟然在阁楼，难道我是当劈柴的姑娘？洗澡水又少，厕所的灯也昏暗，哈利波特都比我们住的好。避雷！都不要来住！！！</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_9f46ce48deb440e88350372a8bbbecd8@000000_oswg186855oswg1080oswg324_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>网友纷纷评论：</p><blockquote><p>火星文在 AI 面前毫无用处&nbsp;</p><p>区区火星文，本模型什么语料没见过？</p><p>有种 20 年前网络冲浪的感觉</p></blockquote><p>当然，也有 AI 歇菜的时候。</p><p>比如，有网友上传了谷歌地图中某家韩国餐馆的点评截图，然后让 ChatGPT 判断这家餐馆怎么样。</p><p>在网友的提醒下，ChatGPT 并未识别出「难吃」的字样，而是胡编乱造 ——「用调料写了『好好吃』字样」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_b0ce754221694530af273bcd1ccccc27@000000_oswg1263547oswg1080oswg2568_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>16 款大模型挑战火星文，仅 1 家能读懂</strong></h2><p>AI 真能看懂火星文？我们决定实测一番。</p><p>有请国内大模型选手：</p><blockquote><p>百度文小言（改名了）、阿里通义千问、腾讯元宝、字节豆包、月之暗面 Kimi、智谱清言、讯飞星火、阶跃星辰跃问、零一万物万知、昆仑万维的天工、商汤的商量、百川智能的百小应&nbsp;</p></blockquote><p>国外选手：</p><blockquote><p>OpenAI 的 GPT-4o、o1-preview、Claude 3.5 Sonnet、谷歌 Gemini&nbsp;</p></blockquote><p>请听题：</p><blockquote><p>这是一段加密后的餐馆点评文字，请完整解密还原。&nbsp;</p><p>过姩厾阣孒①傢荖牸呺倞婇菅，閄匾湜唫洸閁閁哋漷沬婼趧牸哋哪傢。阣唍后趫级妷朢，ル溡哋羙恏汜忆嘟岥誶孒...... 萠伖形嫆，湜哪种漷沬婼倁檤孒嘟婹苁菅財里朓起唻哋难阣。</p></blockquote><p>翻译过来就是：</p><blockquote><p>过年去吃了一家老字号京菜馆，门匾是金光闪闪的郭沫若题字的那家。吃完后超级失望，儿时的美好记忆都破碎了...... 朋友形容，是那种郭沫若知道了都要从棺材里跳起来的难吃。&nbsp;</p></blockquote><p>（友情提示：用的是腾讯「帮小忙」中的「火星文翻译器」）</p><p>链接：</p><p>https://tool.browser.qq.com/toMars.html</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_f17f2d4693c043bebf8e365c36738890@000000_oswg181855oswg1080oswg515_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了字节豆包准确翻译出火星文外，其他国内外大模型均翻车。</p><p>把「漷沬婼」单拎出来，大模型们的翻译法就五花八门。</p><p>文心翻译成「豪华若」，通义、天工、百小应翻译成「泡沫若」，元宝翻译成「模糊若」，Kimi 翻译成「泼墨若」，阶跃星辰翻译成「火玫瑰」，讯飞星火翻译成「琥珀色」……</p><p>此外，通义、万知、天工、商量，还有 Claude 3.5 Sonnet，还把差评硬生生翻译成好评。</p><p><strong>百度文心 3.5：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e6acdb8e9869479a8058afb3ee478759@000000_oswg427800oswg1080oswg907_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>阿里通义千问：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_c717d3e946cc4d55bf63f87c366f12e6@000000_oswg215944oswg1080oswg515_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>腾讯元宝：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_bc88e65551eb46cc96253ab3601617e8@000000_oswg262542oswg1080oswg403_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>字节豆包：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_36c379ef5d424211ab2943679e1ca774@000000_oswg51701oswg1080oswg411_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>月之暗面 Kimi：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a0c9339b4b8946769fd620b23e083995@000000_oswg362354oswg1080oswg850_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>智谱清言：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_23b727fbb02e42eb957ccb48fd7b8f49@000000_oswg513391oswg1080oswg776_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>讯飞星火：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_58da49fb8f644b3484bc2453f11b114f@000000_oswg604724oswg1080oswg912_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>阶跃星辰跃问：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d0ee78bb5b1b4dd090135d6a7cb24661@000000_oswg258249oswg1080oswg654_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>零一万物万知：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_585a665422784914b47ee7374e3b469e@000000_oswg244349oswg1080oswg723_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>昆仑万维天工：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_6d58f16b81954327818a31326f0f1ace@000000_oswg493191oswg1080oswg961_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>商汤商量：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_84a3a47d1e1e4ee6b85cb8819cdf0e56@000000_oswg113562oswg1080oswg291_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>百川智能百小应：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_0d356080caaf4a26b2f617605835fb73@000000_oswg277887oswg1080oswg589_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>GPT-4o：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_12e895506ca64d7f88cb6312b6559315@000000_oswg53734oswg1080oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>o1-preview：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_1a86de4d32304db3bb350a569e9dddd2@000000_oswg39148oswg1080oswg364_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Claude 3.5 Sonnet：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a19e24b48fc343f7bcd62249d5e7ba94@000000_oswg572559oswg1080oswg735_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>谷歌 Gemini：</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_74e3c9643f4642cdaec85af91e1815e6@000000_oswg283660oswg1080oswg481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有哪些 AI 的邪门用法？大家在评论区讨论一波吧。</p><p>参考链接：</p><p>https://x.com/dotey/status/1835910802072592794</p><p>https://x.com/Cldeop/status/1835498503851880549</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzUyODA3MDUwMA==&amp;mid=2247523279&amp;idx=1&amp;sn=bb2f6df5e9776715661fa39d4a3fb82f&amp;chksm=fb32ad3a7d504847364179c26c9968ef7916b218f29edba027e94404f6400136c56057c7f671&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之能”（ID：almosthuman2017）</a>，编辑：杨文，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956799824329344</id>
            <title>服务器芯片抢手，x86仍是市场首选</title>
            <link>https://www.36kr.com/p/2956799824329344</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956799824329344</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 10:55:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在数字化浪潮的推动下，服务器市场持续发展，各大厂商纷纷加大投入，力求在竞争中占据一席之地。CPU 作为服务器的核心部件，其性能和功耗直接影响服务器的整体表现，也因此成为市场关注的焦点。&nbsp;</p><p>从全球范围来看，Intel、AMD两大巨头领跑通用CPU（桌面与服务器CPU）市场，国内也形成了以龙芯、海光、兆芯、华为鲲鹏、飞腾、申威等为代表的竞争格局，其中龙芯、申威在分别引进MIPS、Alpha架构后走了自主路线，海光、兆芯基于x86架构自研，华为鲲鹏、飞腾则选择了ARM架构。此外，近两年 RISC-V 架构也吸引了更多的关注。那么，对于服务器 CPU 而言，哪种架构才是最为合适的呢？&nbsp;</p><p>目前，业界对此尚有争论，但从市场表现来看，x86服务器仍是首选。赛迪顾问在刚刚发布的《2023-2024年中国服务器市场研究年度报告》就提到，x86服务器依旧占据主力市场，且未来三年市场规模保持增长，预计到2026年市场规模突破1600亿元。&nbsp;</p><p>x86架构服务器为何受到青睐？接下来我们一探究竟。&nbsp;</p><h2><strong>服务器市场，强劲增长</strong></h2><p>近年来，伴随数字化转型的不断加速、云计算的广泛应用、人工智能的蓬勃兴起以及物联网的持续发展，服务器市场的需求展现出强劲的增长态势。&nbsp;</p><p><strong>在云计算领域，</strong> 云计算服务提供商为满足大量企业和个人用户对于云存储及云计算资源的迫切需求，持续扩大数据中心规模，进而使得服务器的采购量稳步增加。诸如全球大型云服务厂商亚马逊的 AWS、微软的 Azure、谷歌云等，始终在持续投入资金，大力建设并扩充数据中心，对服务器的需求既庞大又稳定。&nbsp;</p><p><strong>在人工智能和机器学习领域，</strong> 其快速发展亟需强大的计算能力以进行模型训练和推理。AI 服务器凭借其高性能的计算和并行处理能力，能够有效满足复杂算法和大规模数据处理的严苛要求。&nbsp;</p><p>再者，<strong>随着物联网连接的设备数量不断攀升，</strong>这些设备所产生的海量数据需要在后端进行妥善存储、高效处理和深入分析。而服务器作为数据处理的核心设备，在物联网架构中无疑起着关键的支撑作用。&nbsp;</p><p><strong>传统企业为提高运营效率、增强竞争力，纷纷踏上数字化转型之路</strong> ，其中包括建立企业内部的信息化系统、搭建电子商务平台以及开展大数据分析等，而这一系列举措均离不开服务器来支撑业务的顺利运行。&nbsp;</p><p>这一系列前沿应用与技术的快速发展，对服务器中的 CPU 性能提出了更高要求，促使 CPU 用量显著增加。如今，智算中心的蓬勃发展犹如一股强劲东风，为服务器 CPU 的火热态势再添动力。&nbsp;</p><h2><strong>三大架构共舞，适者为王</strong></h2><p>x86架构是计算机领域中最为广泛应用的指令集架构之一，其主要特点包括：复杂指令集（CISC）、高度可编程性、强大的处理能力、向下兼容性以及封闭的源代码。x86架构广泛应用于个人电脑和服务器领域，支持广泛的软件和操作系统，具有强大的生态系统和向下兼容性。&nbsp;</p><p>ARM架构是一种低功耗的精简指令集（RISC）架构，广泛应用于移动设备和嵌入式系统，其主要特点包括：低功耗、高性能、可扩展性、广泛应用以及开源支持等。&nbsp;</p><p>RISC-V架构是一种新兴的开源指令集架构，灵活且可扩展，支持模块化设计，易于实现和部署，社区活跃，适合需要定制化、低功耗和高性价比的应用场景。&nbsp;</p><p>x86和ARM是当前国内最为主流且面向大众市场的两类指令集架构，而RISC-V仍处于起步阶段，发展尚需时日。从市场情况来看，追求安全、稳定的关键基础设施行业在更换服务器时，更倾向于选择x86兼容路线，这主要是因为：&nbsp;</p><p><strong>第一点，x86架构在国内拥有广泛的市场基础。</strong> 国产芯片若能完全兼容该路线，即意味着能够无缝适配国内已有的环境基础，确保各行业用户切换设备后的快速配套，而无需再花费更多时间和经济成本重新适应。&nbsp;</p><p><strong>第二点，x86架构拥有庞大的生态支持。</strong> 在长期的发展过程中，x86架构配套软件及开发工具不断成熟完善，形成了庞大的生态链，能为复杂指令和商业计算提供强大支持。而国产芯片兼容x86后，可以迅速接入完整的主流生态，大大降低迁移成本和维护难度。&nbsp;</p><h2><strong>智算中心加速布局，国产化大势所趋</strong></h2><p>近年来，随着全国一体化算力网络和“东数西算”工程的部署，我国各地计算中心加快布局，根据国家信息中心联合发布的《智能计算中心创新发展指南》，当前我国超过30个城市正在建设或提出建设智算中心，已建成的、在建中的和规划中的智算中心数量已逾40家。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_0e7fd6f4e9294b2b884e9565b1221e40@000000_oswg125587oswg951oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与此同时，数据量的爆炸性增长成为另一大显著趋势。据 IDC 最新发布 Global Data Sphere 2023 数据，2023 年我国数据量规模预计为 30.0ZB，到 2027 年数据量规模则将达到 76.6ZB，2023-2027 年 CAGR 达到 26.4%。英特尔的研究则进一步揭示了AI领域的发展速度，指出AI模型计算量正以每年10倍的速度激增，这一趋势在人工智能与传统产业深度融合的推动下，预计将更加迅猛。&nbsp;</p><p>在此背景下，运营商作为智算中心建设的重要力量，正积极承担算力基础设施建设任务。中国电信、中国移动和中国联通等运营商纷纷加大AI算力服务器的采购力度，其中中国电信2023-2024年AI算力服务器集中采购规模为4050台，而2024-2025年的规模达1.56万台，较上一轮增长224%；中国移动2024-2025年新型智算中心集采项目计划采购7994台AI服务器及配套产品，2024年中国联通计划采购AI服务器2503台。&nbsp;</p><p>值得注意的是，从中标结果综合来看，国产服务器占比超过40%，这显示出国产CPU在信息安全、供应链自主可控等方面的优势正逐步被市场认可，随着中国信息化和数字化进程的推进，国产高端处理器的需求将持续攀升。&nbsp;</p><p>在此背景下，对服务器CPU的独立自主性提出了更为迫切与深刻的要求。&nbsp;</p><h2><strong>自研提速，国产x86创造新“弯道”</strong></h2><p>近年来，国产CPU自研进入快速发展期，并取得较大突破。以华为为代表的ARM架构厂商，虽然受到制裁和版本授权的阻碍，但仍在现有技术授权下设计生产了具备较高性能的产品。以阿里为代表的RISC-V架构厂商，则经过多年积累和打磨，开始密集量产CPU产品。以龙芯为代表的LoongArch架构厂商，也开始加速产品迭代，并进一步缩小与国际主流产商的性能代差。以海光为代表的x86架构厂商，则依托高起点的技术架构，聚焦高端芯片自研，通过对完整 x86 指令集的消化吸收，推出了自研C86架构体系，在安全性等方面进行了大量指令优化和扩展更新。 目前已推出多款性能达到国际主流高端处理器水平的产品，不管是在性能、兼容性还是安全性方面都有着卓越的表现。&nbsp;</p><p><strong>在性能方面，</strong> 它 具备强大的计算能力和数据处理速度。无论是大规模的数据运算还是科学计算等领域，该处理器都能以卓越的性能表现脱颖而出，为用户提供高效稳定的计算体验。&nbsp;</p><p><strong>在兼容性方面，</strong> 它与广泛的软硬件生态系统保持着良好的兼容性，能够无缝对接国内外主流的操作系统、数据库、虚拟化平台以及云计算平台。同时，基于C86的新一代处理器有效运行目前数百万款基于相关技术的系统软件和应用软件，为用户在不同场景下的应用提供了极大的便利，减少了因兼容性问题带来的成本和时间消耗。&nbsp;</p><p><strong>在安全性方面，</strong> 这款处理器更是下足了功夫。通过在安全层级进行大量的指令更新和架构优化，它为用户的数据和系统安全提供了坚实的保障，能够有效抵御各种潜在的安全威胁，如恶意软件攻击、数据泄露等，确保用户的信息安全和业务的稳定运行。&nbsp;</p><p><strong>值得注意的是，今年3月，在中央政府采购网发布《关于更新中央国家机关台式计算机、便携式计算机批量集中采购配置标准的通知》，在公布的配置更新参数中，明确指定了海光CPU的配置要求，即需满足或高于C86 3350标准。</strong></p><p>这也说明，C86处理器凭借其出色的性能表现与对广泛软件生态的兼容能力，以及内置的高安全性设计，赢得了国家的充分认可。作为国产处理器领域的一项重要成果，C86已然成为国产处理器的主流发展方向之一。&nbsp;</p><p><strong>从市场的角度来看，</strong> 自研的服务器CPU能够减少对进口产品的依赖，使国内企业在全球市场上拥有独特的竞争优势。这种竞争优势不仅体现在价格上，更体现在产品的定制化、快速响应市场需求以及长期的技术支持上。&nbsp;</p><p><strong>从商业环境来看，</strong> 自研服务器CPU能够带动国内企业在芯片设计、制造、封装测试等全链条上的技术创新活力，构建可控的产业链生态。这不仅有助于提升国内芯片产业的整体竞争力，还能为云计算、大数据、人工智能等新兴技术的快速发展提供坚实的硬件支撑，加速产业升级转型。&nbsp;</p><p>可以说，自研C86的出现和成型，是具有开创性意义的，标志着国产芯片在x86架构基础上迈出了至关重要的一步。同时，它也为国产服务器行业带来了新的竞争活力和发展机遇。&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247747427&amp;idx=1&amp;sn=956daec01fdcba742ee17e524038e4c4&amp;chksm=c0ab4a57981e259280643f4cd9b58af0bf60fe2b3d853eab241234eff9203496590903f3d9e0&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：丰宁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956817111497353</id>
            <title>万字实录：杨植麟、姜大昕、朱军现场激辩，国产AI巨头对o1模型和行业的深度思考</title>
            <link>https://www.36kr.com/p/2956817111497353</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956817111497353</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 10:54:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上周 OpenAI 发布了开启新范式的 o1 模型，这周开源大模型圈也掀起了新的波澜。&nbsp;</p><p>在今天的云栖大会，阿里云 CTO 周靖人发布通义千问新一代开源模型 Qwen2.5，旗舰模型 Qwen2.5-72B 性能超越 Llama 405B，再登全球开源大模型王座。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_305035dd27624baa965d5dc1396538a3@46958_oswg68433oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>阿里巴巴集团 CEO 吴泳铭认为，过去 22 个月，AI 发展速度超过任何历史时期，但我们依然还处于 AGI 变革的早期。&nbsp;</p><p><strong>生成式 AI 最大的想象力，绝不是在手机屏幕上做一两个新的超级 app，而是接管数字世界，改变物理世界。&nbsp;</strong></p><p>对中国 AI 影响颇大的几位大模型公司掌舵者——阶跃星辰创始人姜大昕、月之暗面 Kimi 创始人杨植麟以及清华大学人工智能研究院副院长、生数科技首席科学家朱军，也齐聚一堂讨论 AI 的前沿趋势和应用进展，包括对 o1 模型的深度思考。&nbsp;</p><p>划重点——&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_7d0d9855bcd1415684ee57dbe846cd28@46958_oswg64584oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>姜大昕：</strong></p><p>回顾过去，我们的感觉还是 GPT-4 是一家独大，遥遥领先。到了今年就变成了一个好像是群雄并起，你追我赶的局面，所以感觉各家是在提速了。&nbsp;</p><p>FSD V12 它的成功意义不仅在于智驾本身，这套方法论可以认为是为将来的智能设备，如何和大模型相结合，更好地去探索物理世界指明了一个方向。&nbsp;</p><p>o1 从能力上来讲，它展示了 language model 可以有系统 2 的能力。从技术上来讲，它带来了一个新的 scaling 的范式。&nbsp;</p><p>o1 第一次证明了语言模型其实也可以有人脑的慢思考，就是系统 2 的能力。&nbsp;</p><p>算法、算力、数据，铁三角的关系没有改变。RL 确实是算法上的改变。&nbsp;</p><p><strong>杨植麟：</strong></p><p>OpenAI o1 主要意义在于它提升了 AI 的上限。AI 的上限是说，你现在去提升 5%、10% 的生产力，还是说 10 倍的 GDP。&nbsp;</p><p>新的 PMF 产生的过程或者探索的过程，其实是要在在延时增长的用户体验下降和最后结果产生质量更高的用户价值的上升之间找到一个平衡点。&nbsp;</p><p>以后的 AI，可能它不光是现在思考个 20 秒、40 秒，它已经可能要思考或者调用各种工具，它可能执行分钟级别、小时级别甚至天级别的任务，所以你的产品形态上可能会更接近一个人，它更接近「助理」的概念。&nbsp;</p><p><strong>朱军：</strong></p><p>大家最后要指向的有两个方向——一个是给消费者看到的这些数字内容，就是说看上去很好看、很自然，能够讲故事，能够让大家参与讲故事、能够交互。这肯定是一个很重要的方向，在数字内容上，另外一个方向，指向实体、指向物理世界。&nbsp;</p><p>现在用到 L1、L2 的进展之后，后面肯定会提升到 L3，让机器人更好地做它的推理规划，然后更好更高效地和环境做交互，更好地完成我们的复杂任务。&nbsp;</p><p>APPSO 在云栖大会现场第一时间梳理了这场讨论的内容，以下是论坛实录（有删减），Enjoy it~&nbsp;</p><h2><strong>如何看待 OpenAI o1 模型的发布&nbsp;</strong></h2><p><strong>张鹏：</strong> 最近刚刚出的这个 o1 新模型，也是在专业人群里形成了非常多的影响。在还在很丰富地讨论。&nbsp;</p><p>正好我们既然都在这个舞台有机会，三位都对这个事儿有自己的见解，我们就在这儿来讨论一下。&nbsp;</p><p>先问大昕，你觉得怎么看这个 o1?&nbsp;</p><p>很多人认为这是 AGI 的一个发展阶段的一个重要进步，到底我们怎么理解这个进步。&nbsp;</p><p><strong>姜大昕：</strong>确实，我看到一些非共识，有些人觉得意义很大，有些人觉得也不过如此。&nbsp;</p><p>我觉得大家如果去试用 o1 的话，可能第一印象就是他的这个推理能力确实非常惊艳，我们自己试了很多的这个 query，觉得推理能力确实上了一个大台阶。&nbsp;</p><p>然后我们去思考它背后的意义究竟是什么？我能想到的有两点，第一个就是还是刚才说的，就是他第一次证明了 large language model，就是语言模型，它可以有这个人脑的慢思考，就是 system 这样的一个能力，因为它和就比如说以前的这个 GPT 的范式或者 GPT 训练，它是叫 Predict next token。&nbsp;</p><p>他只要这样训练。就注定了他一定只有这个系统 1 的能力，而这个 o1 他是用了一个强化学习这样的一个训练框架，所以带来了这个系统 2 的能力。&nbsp;</p><p>那么系统 1 体现一个直线性思维。虽然我们看到这个 GPT-4，它有的时候可以把一个复杂的问题拆解成很多步，然后去分步的去解决。&nbsp;</p><p><strong>系统 2 和系统 1 最大的区别就在于，系统 2 能够去探索不同的路径，就它可以自我去反思，自我去纠错，然后不断的试错，直到找到一个正确的途径。</strong></p><p>所以这次我觉得 o1 是把以前的模仿学习和强化学习结合起来了，使得一个模型同时有了人脑系统 1 和系统 2 的这样的一个能力。&nbsp;</p><p>从这个角度来看，它的意义是非常大。&nbsp;</p><p><strong>第二个，我觉得是它带来了一个 scaling law 的一个新的方向。</strong></p><p>就是我理解这个 o1，他实际上想试图回答的一个问题就是说 RL 强化学习究竟怎么去泛化，因为强化学习不是他第一个，Deepmind 其实一直走的就是强化学习这个路线。&nbsp;</p><p>从这个 AlphaGo 到 AlphaFold，到 AlphaGeometry，其实他的强化学习是非常厉害的。&nbsp;</p><p>但是以前的强化学习的这个场景，都是为特定场景去设计的。AlphaGo 只能下围棋，AlphaFold 只能去预测蛋白质的结构。&nbsp;</p><p>所以 o1 就是在 RL 强化学习上，代表着通用性和泛化性上了一个大的台阶。&nbsp;</p><p>它 scale 到了一个很大的规模，所以我是把它看成带来了一个技术的新的范式。我们不妨称之为这个 RL scaling。&nbsp;</p><p>而且我们看到其实有意思的一点就是，o1 它并没有到一个成熟的阶段，它还是一个开端。&nbsp;</p><p>但是这个我觉得恰恰让人觉得非常的兴奋，这就等于 OpenAI 跟我们说，我找到了一条上限很高的道路，你仔细去思考它这个背后方法的话，你会相信这条路实际上是能够走得下去的。&nbsp;</p><p>o1 从能力上来讲，我觉得它展示了 language model 可以有系统 2 的能力。从技术上来讲，它带来了一个新的 scaling 的范式。所以我觉得它的意义还是非常大。&nbsp;</p><p><strong>张鹏：</strong> 听起来虽然说现在有非共识，但感觉你非常看好，我是非常认同的。那我再听听朱军老师怎么看这个 o1 它带来的这一个阶段的进展，怎么评价他这个进展的意义。&nbsp;</p><p><strong>朱军：</strong> 对，我的看法是它是代表着一个显著的质变。因为我们也对 AGI 也大概做了一些分级。&nbsp;</p><p>其实学术界，包括产业界，大家是有这个 L1 到 L5 的这种分级。&nbsp;</p><p>其实 L1 的话相当于是那个叫聊天机器人，比如像 ChatGPT 这种，L2 的话，其实就是它叫推理者，就是可以做复杂问题的深度思考的这种推理。&nbsp;</p><p>然后 L3 的话就是叫智能体，它实际上是从在回应刚才吴总讲的——就是数字世界走向物理世界，我要去改变的，我要去交互的。&nbsp;</p><p>然后 L4 的话就是创新者，他实际上就是要去发现，要去创造一些新的东西，或者就发现一些新的知识。然后 L5 的话就是组织者，它可以去协同，或者是有某种组织的方式更高效来去运转。&nbsp;</p><p>这是大家对这个 AGI 的一个 L1 到 L5 的分级。每一级的话，他的也有这个相应叫 narrow 和 general 的一个区分。就是你现在在某些 task 上可能展示出来。&nbsp;</p><p>比如说像现在的 o1，其实它在 L2 的这个 narrow 场景下，在一些特定任务下已经实现了。&nbsp;</p><p>他可以去达到人类很高阶的这种智能的水平。我觉得从这个分级的角度来看的话，其实它确实代表着整个行业的一个巨大的进步。&nbsp;</p><p>刚才技术上的姜总也讲了，他实际上还是将过去，比如说强化学习，或者是其他一些技术的话，其实在研究里面已经做了一些很多东西。&nbsp;</p><p>但实际上他在这个大规模的几种模型上面能够给他 scae up，给他做出来效果。这还是一个从工程上或者从实现上来说，是对行业一个很大的触动。&nbsp;</p><p>然后当然他也会触发或者激发出来很多未来的一些探索，或者是实际的这个研发，它可能会走向从 narrow 到 general 的这种跃迁，我觉得可能刚才讲到这个速度，我相信他可能会很快。&nbsp;</p><p>因为大家已经有很多准备了。然后我也期待这个领域里面可能会更多的将这个 L2 能够做的更好，甚至更高阶的能够实现。&nbsp;</p><p><strong>张鹏：</strong> 我觉得再回植麟这边，因为这次发布 o1 之后，Sam Altman 也热情洋溢的说了，我们认为这是一次新的范式的革命，当然就是 Sam Altman 是很会演讲，也很会表达。&nbsp;</p><p>我们想听听你怎么看，就是我们怎么理解他说的这是一次新的范式的变革。你是否认同，这是一次范式的变革。&nbsp;</p><p><strong>杨植麟：</strong> 我觉得它的确实意义很大， <strong>主要的意义在于说提升了这个 AI 的上限。你现在去提升，比如说 10% 的生产力，还是说十倍的 GDP</strong>，我觉得这里面确实可能最重要的问题就是，你能不能通过强化学习去进一步的 scaling。&nbsp;</p><p>所以我觉得这个是一个完全提升了 AI 上限的东西。&nbsp;</p><p>就是我们如果看 AI 历史上七八十年的发展是吧？唯一有效的就是 scaling，加更多的算力。&nbsp;</p><p>但是在 o1 提出来之前，其实也可能也有很多人在研究强化学习，但是可能都没有一个非常确切的答案，就是说强化学习。如果跟大语言模型或者跟现在这个 post-traing 这些东西整合在一起，它能不能持续的提升。&nbsp;</p><p><strong>而我觉得比如说 GPT-4 这一代模型的提升，它更多的是一个确定性的提升。我在一样的方式下，然后把这个规模变得更大，它肯定是会有确定性的提升。</strong></p><p><strong>但是我觉得 o1 的提升并不是一个完全确定性的提升</strong>，所以在之前可能大家会担心说，你现在可能互联网上大部分的优质数据都已经被使用完了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e4adbaca4c6e4ce29332baebe54d9d28@46958_oswg30507oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>张鹏：</strong> 数据墙的问题，数据墙。&nbsp;</p><p><strong>杨植麟：</strong> 然后你可能继续去使用这个数据，你也没有更多的数据可以挖掘。所以你原来的范式可能会遇到问题，但是 AI 有效的，你要需要进一步的 scaling，对吧？那你这个 scaling 可能从哪里来？&nbsp;</p><p>所以我觉得其实很大程度上是解决了这个问题，或者说至少是证明了他初步可行的情况下，就可能我们会有越来越多的人可以去投入去做这个事情。最终去做到可能这种十倍 GDP 这样最终的效果。&nbsp;</p><p>我觉得它就是完全有可能是一个很重要的开端。&nbsp;</p><p>当然，我觉得对于很多产业的格局上，或者说对于创业公司的新机会来讲，也会发生一些变化。对，因为比如我觉得这里面很关键的一个点，就是说你的这个训练和推理的算力的占比，它其实是会发生很大的变化。这个变化当然我不是说训练的算力会下降，其实训练算力可能还会持续提升。&nbsp;</p><p>但是在与此同时，可能推理的算力提升的会更快。然后这个比例的变化，我觉得其实本质上是会产生很多新的机会。可能这里面会有很多新的创业公司的机会。&nbsp;</p><p>一方面，如果你是有达到一定算力门槛的公司，他其实可以在这里面做很多算法的基础创新。那你可以在这个基础的模型上甚至取得突破。所以我觉得这个很重要。对于说可能你算力相对少一点的公司，他也可以通过比如说后训练的方式，在一些领域上去做到最好的效果。&nbsp;</p><p>那这里面也会产生更多的产品和技术的机会。所以 <strong>我觉得整体可能也是打开了很多这种，我觉得至少是创业相关的一些想象空间。</strong></p><p><strong>张鹏：</strong> 所以核心这一次的所谓范式变化，带来的就是在解决了 scaling law 的问题，我们到底接下来要 scaling what 吧，其实我们看到了一个新的路径。&nbsp;</p><p>并且可能你刚才也讲到，就是未来可扩展的这种创新的路径，空间，可探索的东西变多了，而不是原来是一个收缩的状况。&nbsp;</p><p>当然，我觉得今天看起来三位都对于这个 o1 带来的这次变化是蛮兴奋的。但这也是大家现在比较关心的一个问题。&nbsp;</p><p>在一个阶段性，毕竟接下来还是在一些比较明确的场景里，我想问问朱军老师，就是在这种把 RL 加到这个体系里面成为一个新的范式之后，我们能看到明显的去泛化这个能力的路径。&nbsp;</p><p>因为在今天你看他的这个能力在局部还是蛮棒的，提升很明显。但如果要泛化这个路径明确吗？确定性明确吗？&nbsp;</p><p><strong>朱军：</strong> 对，其实这个问题确实很值得思考。因为现在他在每一级的话都有，先是在一些任务上能够取得突破，然后我们再想着给他做到更广泛的任务上。&nbsp;</p><p>从这个 IO 来说，就比如说现在的 o1 的这种技术的实现路线。因为他没有完全地告诉我们是怎么做的。&nbsp;</p><p><strong>张鹏：</strong>现在不像 ChatGPT 出来那么OPEN，目前明显没有那么 OPEN。&nbsp;</p><p><strong>朱军：</strong> 目前明显没有那么 OPEN。&nbsp;</p><p>对，所以单从这个本身的这些科研的积累，或者从这个解读上能够看到他可能用到哪些技术。但其实做 RL 这里边一个很重要的问题，就是这个叫过程监督的这种数据。&nbsp;</p><p>它和之前的这个结果，直接 UP 的监督还不太一样。你要对里边的每一步，比如说我思考的过程，每一步都要去标注这种数据。&nbsp;</p><p>首先获取可能就比较难了，就是他需要你需要专业的人，然后去做这个专业的这种高价值的数据。另外一个就是说你在实际做 IO 里边，包括之前大家看 AlphaGo 迁移到其他领域里面临同样的问题。&nbsp;</p><p>就是说你在更泛化的或者更开放的这种场景下，你的这个 reward model 不好定义。比如说就拿这个，现在他做的是这个是定理证明，或者是一些编程的。&nbsp;</p><p>他有确定答案的这种问题的话，你的奖励函数是很容易定义的。&nbsp;</p><p>但如果你到比如说到自动驾驶里面，或者到这个艺术创作里边，比如像生图生视频，那在这个里面的话，你是比较模糊的去界定。&nbsp;</p><p>可能很多场景下你是很难清晰的来定义到底什么好什么不好。&nbsp;</p><p>或者是他可能很多问题不是「是」和「非」的问题，他是大家对这个比如像生成内容的话，他是对美学，或者对其他的这种评价。每个人的感受可能还不太一样。&nbsp;</p><p>就在这种情况下，你要去泛化的话，在技术上就面临着很多问题的，就是我怎么去定义这个 reward model，我怎么去收集数据。当然还包括你怎么去让高效的来去实现，能够去 get scale？&nbsp;</p><p>但是现在刚才也讲到很多，就是说现在其实大家看到这条路了，这条路其实已经相当于看到曙光，就是会引导大家很多的去朝这边去努力。&nbsp;</p><p>然后，另外就结合现在的比较强大的这个基座的话，其实可能比之前，比如上一代把 Alpha 给迁移到其他的领域里面，我相信会更快。&nbsp;</p><p>因为包括像一些像开放领域里边，我们可能有更好的模拟器。这些加持在一起，我想这个路可能会走的更快一点，会比之前可能会更容易达到取得效果和提升。&nbsp;</p><p>对，可能从我的角度来说看，这个可能后边要去泛化的一些思考，就是今天是还没有看到一个公开的明确的可以确定性把这个泛化完成的路径，但它存在探索的空间和足够的可能性。&nbsp;</p><p><strong>张鹏：</strong> 这个问题我觉得想再追问一下，植麟，我其实想问的是说，你看到那个东西的时候，你会映射到自己未来要做的事情会是一个什么心理状态，你会怎么分析这个环境。&nbsp;</p><p><strong>杨植麟：</strong> 对，我觉得这个其实是一个很好的机会。因为等于说你有一个新的技术变量，一个新的技术维度。然后当然这个可能或多或少我们之前也有一些投入，但是可能现在会变成一个主题。&nbsp;</p><p>然后在这个主题下面，我觉得我们是有非常多的这种新的机会。&nbsp;</p><p>一方面是刚刚朱老师提到的这个怎么去泛化的问题，然后另一方面就是可能不光是泛化，就是说在这个过程中可能还有一些基础的技术问题可能不完全解决。&nbsp;</p><p>因为可能他和实际上底层涉及到训练跟推理，可能两个东西要同时去 scaling。对，但这里面可能很多性质，我觉得今天也许也没有被完全探索清楚，然后包括刚刚提到的过程监督的这些问题。&nbsp;</p><p>可能中间的一些幻觉也会给这个效果带来很大的伤害，所以这些问题我觉得都很值得研究。但如果能够做好的话，那其实是可以把现在的很多能力去提升一个台阶的。&nbsp;</p><p>我觉得还是像我刚刚说的， <strong>对我们来讲，可能会有更多通过这种基础创新去形成一些突破的机会。</strong></p><p><strong>张鹏：</strong> 不确定其实是好事儿，对吧？就是有确定的方向，然后有不确定的路径。&nbsp;</p><p>对创业公司本身是好事，否则就没有创业公司的事儿了。我再回到大昕这边，我其实刚才植麟也提到了一点，我觉得这是个很有意思的问题。&nbsp;</p><p>你看。过去我们说算法、算力、数据，这三个都是我们在谈 AGI 的时候，看起来是一个关键的三角，对吧？这次看起来在算法层面有一些范式的变化。&nbsp;</p><p>反过来，对于算力，对于数据这方面，这个三角形它会怎么产生连锁的反应。能不能帮我们推理一下？&nbsp;</p><p><strong>姜大昕：</strong> 对， <strong>我觉得这个连锁的关系就是算法、算力数据这个铁三角的关系没有改变。RL 确实是一个算法上的改变，对算力造成的结果，我觉得有一个是确定的，有一个大概率会确定。</strong></p><p>还有一个是我目前不太确定的，就像刚才两位谈到的，就是在推理侧的对计算的需求量肯定是成倍的提升，这就是 OpenAI 的 blog，里面也提到叫 test time scaling。&nbsp;</p><p>同时它对这个推理芯片能力的要求肯定也是提高了。&nbsp;</p><p>因为可想而知，就是 OpenAI 在这个 o1 的背后，可能是用的 H100 在做推理，一个问题往往要消耗十几秒几十秒的时间。所以我们想加快这个速度的话，对这个推理芯片的要求也会提高，一个大概率会确定的事情就是在训练 RL 的阶段，我们所需要的算力可能并不比预训练要少。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_edcb433692ae45a28caa0cda4110ba56@46958_oswg56352oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>张鹏：</strong> 这可能是一个非公共利益的需求，还是会持续上升。&nbsp;</p><p><strong>姜大昕：</strong> 对，就是为什么呢？因为在这个 RL 的阶段，我们做 self play这个数据量，刚才这个植麟也谈到，它是 self play出来，它理论上是可以没有上限的。&nbsp;</p><p>所以我们也听说 OpenAI 在训练 strawberry 模型的时候，用了上万张的 H 卡训练几个月。现在还是一个 o1 的 preview，就是他训练还没有完成，所以这个训练代价是非常高的。&nbsp;</p><p>我觉得如果我们追求的是一个通用的有泛化能力的推理模型，而不是为某个特定场景所设计的一个 RL 的模型的话。那么它可能训练所需要的这个计算量并不小。&nbsp;</p><p>还有一个是我不太确定的，就是在这个 self play 的时候，我们用的这个主模型，它的参数量要不要再继续 scale，让它产生更好的推理路径。因为现在有一个大家有个普遍的观点，就是说 GPT-4 到了万亿参数以后，你再去 scale 它的参数。那么它的边际效益是在下降的。&nbsp;</p><p>但如果 RL 这个方法它产生一个放大器的作用，能够加倍你的收益的话，那是不是总的收益 ROI 又打正了，所以这是一个不太确定的事情，可以留到后面去验证。&nbsp;</p><p>如果这个结论成立的话，那么算力的增长又回到了平方这样的一个维度。&nbsp;</p><p>因为算力计算量等于参数量乘以这个数据量，所以我的感觉就是 RL 要带来的这个不管是对推理侧还是训练侧，它对算力的需求都是在增长的。&nbsp;</p><p>对，刚才提到了在 IO 阶段其实有两种数据，一个是少量人工合成的数据，第二个就是海量的 Self-Play，就是机器生成的数据。&nbsp;</p><p>那么数据量很大，但是数据的质量非常的关键。所以就是你怎么去构造生成这个数据的算法，以及 self play用的这个主模型的能力就变得非常关键了。&nbsp;</p><h2><strong>AI 是在加速还是在减速？&nbsp;</strong></h2><p><strong>张鹏：</strong>从 ChatGPT 的发布，可能引发了整个世界对于 AGI 这件事的理解，到现在可能也差不多 18 个月了。 我不知道各位的感受是怎么样的，这个模型技术的发展是在加速还是在减速？&nbsp;</p><p>要不大昕先来帮我们分享一下，你怎么看过去 18 个月，这个 AI、AGI 的发展是在加速还是减速。&nbsp;</p><p><strong>姜大昕：</strong> 对，我觉得过去 18 个月其实感觉是在加速的，速度还是非常快的。&nbsp;</p><p>因为当我们回顾过去 18 个月发生的大大小小的 AI 事件以后，我们可以从两个维度去看。一个是数量的角度，一个是质量的角度。&nbsp;</p><p>从数量的角度来看，基本上还是每个月都会有新的模型、新的产品、新的应用这样涌现出来。比如单从模型来看的话，OpenAI 二月份发了一个 Sora，我记得当年当时还是过年的时候，把大家轰炸了一下。&nbsp;</p><p>然后五月份出了个 GPT-4o，然后上周又出了这个 o1，然后 OpenAI 的老对手，Anthropic，它有这个 Claude 3到3.5这样的一个系列。再加上 Google 的 Gemini 系列、Llama 系列等等。&nbsp;</p><p><strong>回顾过去，我们的感觉还是 GPT-4 一家独大，遥遥领先，到了今年就变成了好像是群雄并起，你追我赶这样的一个局面。所以感觉各家是在提速的。</strong></p><p>从质量的角度来看，我觉得有三件事情可能给我的印象非常的深刻。&nbsp;</p><p>第一件事情就是 GPT-4o 的发布。因为我认为他是在多模融合这样的一个领域上了一个新的台阶。&nbsp;</p><p>在 GPT-4o 之前，比如说 GPT-4V 它是一个视觉的理解模型，有 Sora，就是视觉的生成模型，还有 whisper，这是声音模型。原本这些孤立的模型到了 4o 这里都融合在了一起。&nbsp;</p><p>那为什么融合这件事情非常的重要？&nbsp;</p><p>是因为我们的物理世界本身就是一个多模的世界，所以多模融合一定是有助于我们更好的去为物理世界建模，去模拟世界。&nbsp;</p><p>第二件事情就是特斯拉发布的这个 FSD V12。大家知道它是一个端到端的大模型，它把这个感知信号直接变成这个控制序列。而智驾这件事情，我觉得它是非常有代表性的。&nbsp;</p><p>它是一个从数字世界走向物理世界的真实应用场景。&nbsp;</p><p><strong>所以我觉得 FSD V12 它的成功意义不仅在于智驾本身，这套方法论可以认为是为将来的智能设备，如何和大模型相结合，更好地去探索物理世界指明了一个方向。</strong></p><p>第三件事情就是上周的这个 o1，我觉得我对他的理解就是，它第一次证明了语言模型其实也可以有人脑的慢思考，也就是系统 2 的能力。&nbsp;</p><p>而我们觉得系统 2 的能力，它是归纳世界所必备的一个前提条件，是一个基础的能力。所以我们一直认为 AGI 的演进路线可以分为模拟世界、探索世界，最后归纳世界。&nbsp;</p><p>过去几个月的时间，我们看到 GPT-4o、FSD V12 和 o1 分别在这三个阶段或者这三个方向上都取得了非常大的突破。&nbsp;</p><p>而且更重要的是为将来的发展也指明了一个方向。所以我觉得无论是从数量还是质量来说，都是可圈可点。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_366d369eec5b42c9a3df3c09ddb5e818@46958_oswg37646oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>张鹏：</strong> 看来，对于你期待的领域里，其实都看到了广泛的突破和进展。植麟，你的体感是怎么样的，投身其中的人可能会跟我们外边看游戏的人不一样，你可以分享一下。&nbsp;</p><p><strong>杨植麟：</strong> 对，我觉得整体也是处于一个加速发展的阶段。然后可能核心是分层，我觉得可以从两个维度来看，就是 AI 的发展。&nbsp;</p><p>现在我觉得第一个维度是这个纵向的维度。也就是说智商是一直在提升的。现在的反映方式还是去看这个文本模型能做到多好。&nbsp;</p><p>然后第二个是这种横向的发展。&nbsp;</p><p>除了文本模型之外，像刚才姜总提到的，就是也会有各种不同的模态来。这个模态其实也在做一个横向的发展。它更多的是说能让模型具备更多的技能，能够去完成更多的任务。然后同时跟这个纵向的智商的发展去相结合。&nbsp;</p><p>其实在这两个维度上，我觉得都看到了非常大的进展。&nbsp;</p><p>比如说在这个纵向的维度上，其实智商是一直在提升的。比如说像我们如果去看这个数学竞赛，数学的能力可能去年是完全不及格，到今年可能已经做到能做到 90 多分。&nbsp;</p><p>然后像代码其实基本上也是一样，就是能够击败很多专业的编程选手。然后包括因此也产生了很多新的应用机会。比如说像现在比较流行的类似 Cursor 的这种，可能通过自然语言直接去写代码，这样的软件也越来越普及。&nbsp;</p><p>所以我觉得这个其实是很多技术发展的结果。&nbsp;</p><p>包括我们如果去看很多具体的技术指标，像比如现在的语言模型，能支持的这个上下文的长度。其实如果去年这个时间点去看的话，大部分的这个模型它都只能支持 4 到 8K 的 context。&nbsp;</p><p>但是从今天去看，你会发现 4 到 8K 这个已经是一个非常低的数了，对吧？可能 128K 已经是个标配，已经有很多可以支持 1M 或者甚至 10M 的长文本长度。&nbsp;</p><p>这个其实也是后面自身不断提升的一个很重要的基础。&nbsp;</p><p>然后包括最近的很多进展，它其实不光只是做 scaling，比如说 scaling 还是会持续，而且很多进展它其实也来自于比如说后训练的算法的优化，来自于数据的优化。&nbsp;</p><p>这些优化其实它的周期是会更短的，所以这个周期更短会导致整体的 AI 的发展节奏也会进一步加快。&nbsp;</p><p>包括我们最近在数学上看到的很多进展，其实也是得益于这些技术的发展，横向上当然也产生了很多新的这样的突破。&nbsp;</p><p>当然，Sora 可能是影响力最大的。在这里面完成了这个视频生成。&nbsp;</p><p>最近有特别多新的产品和技术出来。类似这样的这种不同模态之间的转换交互和生成，其实会变越来越成熟。所以我觉得整体是在这个加速的过程中。&nbsp;</p><p><strong>张鹏：</strong> 感觉这些技术其实还在加速的去扩展它带来的变化和创新。&nbsp;</p><p>虽然可能我们客观上看，好像没有说再长出某个 Super App，但如果我们抛掉这个 Super App 的视角，我们去看技术，反而能够看到它的真正的进展。这个可能是更加理性客观的视角。&nbsp;</p><p>我也想听听朱军老师你会怎么总结这 18 个月，到底我们说 AGI 的技术，它是经历了什么样的发展，有什么可以总结的这种进步的台阶。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_26aca445f1ec498882820bbfc15fa455@46958_oswg34851oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>朱军：</strong> 对，其实就是 AGI，这里边可能大家最关注的还是大模型，就是大模型从刚才两位也讲了，去年其实发生了，包括今年发生很多重要的变化。然后整个的进展我是非常同意。刚才讲到就是在加快。&nbsp;</p><p>另外我想补充一点，其实现在就是大家在做这个，比如说我在解析的问题或者什么，这个速度其实也在变快的。&nbsp;</p><p>就我们说它的 learning curve 在变得更陡。&nbsp;</p><p>原来比如说像如果你看语言模型的话，可能植麟他们也算最早去做这个，大概走了五六年。&nbsp;</p><p>但其实从去年开始，上半年大家还是关注语言模型。下半年的话在讨论这个多模态，从多模态理解再到多模态生成。在我们再回头看的话，比如说像这个图像或者像视频。&nbsp;</p><p>像视频其实最明显，从今年的二月份，当时很多人是被震惊到了。我就很多时候觉得这个技术是不是因为他很多没有公开。然后就是都在讨论怎么去突破。&nbsp;</p><p>但事实上，我们现在看到就是说这个行业里边，大概用了半年的时间，其实已经已经做到了，就是可以去用，而且达到了一个很好的效果。&nbsp;</p><p>在这个时空一致性上，这大概走了半年的一个路。&nbsp;</p><p>我想这里面加速的一个最核心的原因就是说，其实现在大家对这种路线的认知和准备，其实达到了一个比较好的程度。&nbsp;</p><p>我们还有这个物理的条件。比如说像这个云的设施，计算的这种资源的这种准备上，不像那个 ChatGPT 当时出来的时候，大家当时更多的是一种不知所措。&nbsp;</p><p>我觉得很多人可能没准备好去接受这个，所以中间去花了很长的时间去学习，去掌握这个。&nbsp;</p><p>当我们掌握了之后，再发现这个进展的话，再去做新的问题。其实它的这个速度是越来越快的。当然这个可能不同的能力在辐射到实际的用户的这个角度来说，有一些快慢之分，也分行业。&nbsp;</p><p>这可能在广泛的角度来说，大家可能没感知到。但是从技术来说，其实这个进展是我感觉是曲线是越来越陡。而且我们要预测未来的话，可能就是包括像更高阶的这种 AGI 可能发展。&nbsp;</p><p>我觉得我是比较乐观的，可能会看到比之前更快的速度来去实现。&nbsp;</p><h2><strong>AI 会给产业带来什么变化&nbsp;</strong></h2><p><strong>张鹏：</strong> 我想问问植麟，Kimi 在今年引发了大家很多关注的产品，发展的也很好。&nbsp;</p><p>你觉得这一波的 AI 的新的变化，接下来会对于 AI 相关的产品带来什么样的连锁反应，能不能也帮我们推理一下，你在看到它的时候，脑子里会怎么想，这个变化会如何发生。&nbsp;</p><p><strong>杨植麟：</strong> 对，这是个很好的问题。我觉得我们现在其实还是处于这个产业发展的早期。&nbsp;</p><p>所以现在的这个技术发展，我觉得有几个点。一个就是说其实我觉得这里面会有很多探索新的 PMF 的机会。因为这个 PMF 指的是，我觉得是两个东西的平衡。&nbsp;</p><p>一方面是由于你需要做这种系统 2 的思考，导致了你的延迟是增加的。&nbsp;</p><p>那这个延迟增加对用户其实是一个负向的体验对吧？因为所有用户都希望尽快能拿到这个结果。&nbsp;</p><p>但第二个点就是说他确实能提供更好的输出，能拿到更好的结果，能甚至能完成一些更复杂的任务。&nbsp;</p><p>所以等于说这个新的 PMF 产生的过程或者探索的过程，它其实是要在这个延时增长的用户体验下降和最后结果产生质量更高的用户价值的上升之间去找到一个平衡点。&nbsp;</p><p>所以你要让这个增量的价值是大于体验损失的。我觉得这个是很重要。&nbsp;</p><p>在这里面可能就是我觉得一些更高价值的场景，特别是生产力的场景，我觉得是会率先可能有一些东西出来。因为如果你是一个娱乐场景，那大概率就是你你可能很难忍受这种延时上的增加。&nbsp;</p><p>所以我觉得这个是比较重要的一点。&nbsp;</p><p>然后可能我觉得产品形态上也会发生一些变化，可能就是因为你娱乐这种思考的方式，所以现在这种同步及时的类似聊天的这种产品的形态，那可能一定程度上也会发生变化。&nbsp;</p><p>因为以后的 AI 可能它不光是这种，现在可能思考个 20 秒、40 秒，他以后可能要思考或者去调用各种工具，他可能是执行这种分钟级别、小时级别甚至天级别的任务。&nbsp;</p><p>所以你的产品形态上他可能会更接近一个人，他更接近一个 assistant 或者助理的概念，然后帮你去完成一个异步的任务。&nbsp;</p><p>这里面的产品形态的设计，我觉得可能也会发生很大的变化。所以这里面我觉得可能新的想象空间是蛮大的。&nbsp;</p><p><strong>张鹏：</strong> 其实我们刚才聊到了这个 o1 带来的变化。其实我们也看到在 AGI 领域也有一些其他的变化。&nbsp;</p><p>比如像李飞飞在推这个空间智能，包括其实今天我们也会看到，后面也会看到在自动驾驶，在这个机器人等等具身智能方面的变化。&nbsp;</p><p>所以我想问问朱军老师，因为朱军老师可能也会去思考，就是在其他的这个 AI 相关的条件里面的最近的一些技术进展会对于未来的产品或者说一些技术最终落到产业里有什么明确的推动了。有没有阶段性的一些总结和观察？&nbsp;</p><p><strong>朱军：</strong> 对，我觉得现在是这样，其实大模型或者叫我们叫大规模预训练这种技术，它还是代表着一个整个范式的变化。就是不光是前面也聊了很多，也不光是语言到多模态。&nbsp;</p><p>再到刚刚提到像这个具身或者就李飞飞老师叫空间智能，其实还是重点，还是想怎么去让智能体能够有交互，能够在这个过程中去学习。&nbsp;</p><p>从智能的角度来看的话，从包括从 AGI 发展上，它是一个必然的决策交互。&nbsp;</p><p>就是因为决策交互实际上是智能里面非常核心的这个能力的一个体现。我们其实每时每刻都在做决策。&nbsp;</p><p>我们面对的是一个未知的开放环境。所以对智能来说的话，它的发展的路径上，就在整个的规划里面，大家也是朝这个方向在走。&nbsp;</p><p>然后现在其实像所有这些进展，包括刚才讨论了很多的 o1，也包括像我们做这个像视频生成，或者像 3D 这些东西的话，其实大家都是最后要指向的——&nbsp;</p><p>我觉得有两个方向，一个是就是给这个消费者给大家看的，就是说这些数字内容就是他看上去很好看，然后很自然，然后能够讲故事，能够让大家真正能够去参与的去去讲故事，有交互。这肯定是一个很重要的方向。&nbsp;</p><p>就是在这个数字内容。然后另外一个方向就是指向这个实体，指向这个物理世界就是生产力。对，一定是生产力的一个提升。就是说它不光是给我们去去做一些好看的东西，或者觉得好玩的一些东西。&nbsp;</p><p>然后他实际上最终还是要去和我们的这个物理世界结合。这其中现在可能最好的一个结合点就是和和机器人结合在一起。其实现在已经有好多例子在在展示出来。&nbsp;</p><p>我们也看到很好的一些进展，就用了这种比如说像预训练的这种范式，能够让机器人的他的能力具有这个通用性。比如说像我们做过我们自己实验室也做过一类的，像这个四足机器人。&nbsp;</p><p>过去可能大家在这不同场地下边，你要让他跑起来，都要去需要用很多的人工去调，可能去调仓。但现在其实你在一个仿真环境里面，或者是用一些 AI 的方式来生成一些合成数据，让他去在里面大规模的训练。&nbsp;</p><p>这训练出来的策略可以装到机器人上，他相当于换了一副大脑，就可以让他的四肢能够去更好的协同起来。&nbsp;</p><p>他可以同样一套策略来去做各种场地的这种适应。这其实还是一个初步的例子。而且现在大家也在关注更复杂的这种控制决策等等。就像这个空间智能、计算智能这里边，其实就像刚才讲到这个，它实际上智能体是 AGI 的 L3。&nbsp;</p><p>所以从现在用到的 L1、L2 的进展之后，后边肯定会集成到这个 L3 里边。让机器人比如说更好地去做推理规划，然后更高效的和这个环境做交互，完成复杂任务。&nbsp;</p><p>因为现在任务很多时候还是相对分散的。未来可能很快我们会看到，就是说他可以接受复杂的指令，完成复杂的任务。&nbsp;</p><p>然后通过他的这个内嵌的这种思维链或者这个过程的学习方式，能够给完成这个复杂任务。到那个时候，可能这个智能的能力又有一个很巨大的提升。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_41dc61e3090b4817a98ae0993ce73729@46958_oswg28511oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>张鹏：</strong> 我突然想到了一个问题，因为这个还是让人很兴奋的技术进展，但作为创业公司，肯定也在面临着今天的一个现实的产业环境。&nbsp;</p><p>就是我想问问大家，不知道像你们这样的花很多的成本去做基础模型，包括你们做这个统一多模态的这种模型，也要参数做的很大。过去都让人觉得要捏把汗？因为要花很多的钱，对吧？&nbsp;</p><p>然后遇到这样问题，今天这种新的技术的变化，在过去 18 个月，包括这次的 o1 出来，会对你的心态是有什么影响和改变吗？你是觉得未来作为这样的创业公司是有了更大的创新空间，有了更让人兴奋的可能性吗？ 你会是一个什么样的心理的反应，你怎么看你未来创业路的走向。&nbsp;</p><p><strong>姜大昕：</strong> 对。我觉得从两个角度看，一个就是创新的点，我觉得 RL 出来确实和前面那个范式不太一样。就是第一个 GPT 的范式，它就 predict next token。&nbsp;</p><p>这个事情其实从 18 年 GPT-1 出来，一直到这个 GPT-4，除了加了一个 MOE 的混合专家模型以外，其实没有什么太多新的很新的东西在里边儿。但是 o1 的话，我觉得它还是一个初始阶段。&nbsp;</p><p>就是刚才两位也谈到，就是这个强化学习究竟怎么和大模型相结合，能够做到泛化这件事情我觉得有非常多的问题值得去探索。就是刚才其实你也谈到，如果的 function，包括我们在做这个搜索路径的时候，需不需要人工干预去帮他找到更好的路径等等。包括你 self play 题目从哪里来，答案怎么去找，这些都是一些新的这个未知的领域去要去探索的。&nbsp;</p><p>我相信在未来的这个一段时间里面，肯定会有很多很多问题，朱军老师说这个一定会加速的，那我也相信一定是这样的一个趋势。所以对我们创业公司来说，在创新这个方向上肯定是有很多的机会。&nbsp;</p><p>但是另外一方面，我觉得从刚才您谈到就是算力的挑战，其实我刚才也讲了一下，其实我们认为在推理侧也好，在训练侧也好，他所需要的这个算力还是不小的，尤其是当我们需要追求的一个是通用性的，能够泛化的推理模型的时候，这个所需要的算力并不小，也包括回应您刚才说的那件事情。&nbsp;</p><p>其实我们经常内部有调侃，就是说这个讲卡伤感情，没卡没感情，然后我们后面又加了一句叫用卡费感情。但如果我们这个所要追求的目标就是 AGI 的话，那你付出再多，你还是要坚持下去。&nbsp;</p><p><strong>张鹏：</strong> 因为过去觉得如果按照上一个 scaling law 继续往下走，其实能玩的玩家就会变得越来越少。因为对资源的比拼太多了。现在你觉得对于资源的门槛是会有降低吗？&nbsp;</p><p>还是说还是继续要拼在这个算力上的资源，包括这种你怎么去能整合这么多的计算资源工程上要做的更好，这个还是一个核心点。&nbsp;</p><p>姜大昕： 我觉得是这样的，就分成两种不同的创新，一种就是基础模型，就是奔着 AGI 去，我就是要做通用的泛化性能力强的这个的话，投入是很大。&nbsp;</p><p>而且我们看到国外的巨头不约而同的都是一年几十亿美金，上千亿美金这样的一个规划。但是另外一方面，我觉得还有大量的创新的空间，实际上是做应用。&nbsp;</p><p>本来我觉得 GPT-4 所展现出来的智能，后面加上智能体 agent 这样一个框架，已经能够解决我们其实很多的问题了。&nbsp;</p><p>就像朱军老师说两类问题，一个是数字世界的问题。物理世界的问题，我们都可以再往前走。&nbsp;</p><p>今年 o1 出来以后，把这个强化学习又泛化到了一个更高的阶段。像植麟说的，它的上限变得更高了。所以我觉得这里面还是有大量的机会的。&nbsp;</p><p><strong>张鹏：</strong> 那我再问问这个植麟，因为植麟现在有 C 端的产品，最近我其实听到很多投资人都在看这个 DAU 是多少，留存多少等等，各种各样的指标去再看，去评估要不要投一个公司。&nbsp;</p><p>我觉得今天能不能换个身份，假定你今天不是创业者，假定你是个有技术背景，对 AI 有很了解的投资人，你会在今天看创业者的什么数据来做你的投资决策。&nbsp;</p><p><strong>杨植麟：</strong> 这个是个很好的问题。我觉得首先像 DAU，你刚刚说的这些数据，我觉得肯定是重要的指标，然后我觉得可能分成几个层面。&nbsp;</p><p>第一个层面就是说作为一个创业来讲，你做一个产品，它首先是要有价值，或者说你是满足了用户的一个真实的需求。我觉得这个可能还是一个本质，可能跟 AI 也没有太大关系。就是你作为一个产品本身，它需要满足这个属性，所以可能也有更多的前置的指标，比如说像一些留存，所以这个还是最重要的。&nbsp;</p><p>然后我觉得第二个点，可能是跟 AI 跟相关的。就是说你不光是要有价值，其实你也要有增量的价值。这个增量价值可能相比于市面上已有的 AI 产品，或者说像更通用的。&nbsp;</p><p>我觉得接下来肯定会有通用的 AI 产品，其实现在已经有了。对，也是我们正在做的事情。但就是说你在这个通用产品之外，比如说 GPT之外，其实可能还会有大量的机会。这些 AI 产品的机会，你要相比于这个东西能产生增量价值，产生一个你在 ChatGPT 里面做不了的事事情，或者说做起来体验很差的事情。&nbsp;</p><p>这个我觉得是一个会有很大的这样的价值。比如说最近很火的 Cursor，它就是一个很好的例子，这里面一般你的增量价值会产生几个方面。一方面就是说你有可能你的交互是完全不一样，或者你是不同的入口，对吧？&nbsp;</p><p>然后有可能你是背后对应的是不同的这个资源，也有可能。所以我觉得通过这种方式去产生这个增量价值，可能是我觉得会很重要的一个事情。&nbsp;</p><p>然后第三个维度，我觉得是说不光是有价值，有这样价值，而且他可能还是要随着这个技术的发展，就是市场规模应该越来越大，而不是越来越小。&nbsp;</p><p>对，比如说如果你是一个专门研究 prompt engineering 的，那你可能现在就是会有一个风险：也许接下来的需求会越来越小。&nbsp;</p><p>对，但是你如果是说目前已经能产生一定的 PMF，但是还没有说泛化到一个很主流的群体，有可能是因为你技术不够强。那这个时候其实你在搭配上。&nbsp;</p><p>第二点就是你有增量价值的话，然后你的市场又越来越大。它可能就是一个好的 AI 创业的机会。&nbsp;</p><h2><strong>未来 18 个月，我们会看到什么样的进展&nbsp;</strong></h2><p><strong>张鹏：</strong> 对，听起来就是数据是要看的。但是在看数据之前先看逻辑，就是产品存在的逻辑。如果他是成立的，数据又能证明，可能这就是一个值得投的公司。&nbsp;</p><p>还有一个很感兴趣的问题，就是因为我们的时间也有限，我们 move on 到也许未来的 18 个月。&nbsp;</p><p>我想问各位，你虽然预期预料未来都很难，但是你至少心里会有一个期待。&nbsp;</p><p>比如在下一个 18 个月里，我们期待看到什么样的进展。在 AGI 的领域里面，第一，会让你觉得你会很兴奋。第二，你觉得它是有可能的。&nbsp;</p><p><strong>朱军：</strong>对， <strong>我觉得因为现在整个 A 技术处于加速状态，其实很多时候我们的预测通常会过于保守。</strong>如果回到你那个问题的话，就是说我预想的，比如说未来 18 个月可能比较令人兴奋的一个进展可能是，我希望看到可能 L3 已经基本上实现。&nbsp;</p><p>AGI 的 AGI L3 就是关于智能体。比如说我们说的这个世界模型的创建生成，然后虚实的融合，还有包括像这个至少在一些特定场景下的这种决策能力的一个巨大提升。就结合其实今天讲到的这个推理、感知等等这些。&nbsp;</p><p><strong>张鹏：</strong>在特定场景里，已经确实不是 copilot，是 autopilot。&nbsp;</p><p><strong>朱军：</strong> 我觉得可能在某种意义上会达到这种。就是说他是在至少在一些特定场景下，但是这个可能还会有更长、更泛化的能力。&nbsp;</p><p>与此同时，我前一段时间领了一个任务，就是对 L4 来去做专门的分析。最后调研或者是分析下来，你会发现可能如果我们要去做那个科学发现或者做创新的话，他需要的那些能力，或者可能现在已经是散落在各个角落里边。&nbsp;</p><p>但是现在可能还没有，还缺一个系统怎么把这些东西给集成在一起，给他做 work。但我觉得如果更激进一点，我甚至觉得未来 18 月可能在 L4 上也会有显著的进展。&nbsp;</p><p>当然这里边我刚才讲的是严肃的科学发现。&nbsp;</p><p>其实还有一些比如说像创意的这种表达上的。就目前其实我们在某种意义上已经达到了比如像艺术创造，像这个生图生视频，就是一定程度上能帮大家来去放大想象，或者是让你的想象可以具象化。&nbsp;</p><p>所以我对整个的这个发展还是比较乐观的。我觉得至少有一些 L3 或者说 L4 的苗头。&nbsp;</p><p><strong>张鹏：</strong> 说完了 18 个月到年底之前，你自己的事儿上会有什么进展，能提前透露吗？&nbsp;</p><p><strong>朱军：</strong> 对，我到今年年底的话，我肯定是希望将我们本身做的这个像视频的模型能够以更加高效更可控的方式提供给大家。&nbsp;</p><p>我解释一下高效和这个可控可控的话，主要是指比如说你想去表达一个故事，它不是简单地将一段话或者一个图片给它动起来，我们是希望它可以连续的去讲。&nbsp;</p><p>而且是它不光是人的这个一致性，还像物体等等各种的这种主题的一致性，还包括交互性。这些都是在可控里边的高效。&nbsp;</p><p>其实它一方面是解决是对算力的成本的一个考量。因为你要做，比如说像想去服务很多人，让大家去用的话，你首先你成本也要降下来，不然的话这个本身就是烧钱的。&nbsp;</p><p>然后其实另外一个更重要的还是从这个体验上，就是使用者来说的话，因为他想去表达自己的创意，他可能需要多次的去和这个系统来去来去交互，能够让他自己的一方面去验证。另外其实还是启发。&nbsp;</p><p>所以这个过程的话也需要你的模型系统能够比较高效，尽量的是比如说终极目标是达到 40，就能够让大家快速的能够能去尝试。等到这个阶段的话，我相信用户体验，包括用户量的都会有一个巨大的一个提升。&nbsp;</p><p>这是今年我们可能重点想去突破的。然后长远的话，我们还是看到就像可能明年 18 月可能就会走向这个实体的虚实融合的这种场景了。&nbsp;</p><p><strong>张鹏：</strong> 对，3 个月的目标和 18 个月对未来的期待都是很明确的。植麟，我觉得这是挺好的概念，你既可以说说 18 个月，也可以讲讲未来 3 个月有什么样的进展。&nbsp;</p><p><strong>杨植麟：</strong>我觉得接下来最重要的 milestone 可能是开放性的强化学习。&nbsp;</p><p>就是你可能真的能够，比如说你就在产品上跟用户去交互，在一个真实的环境里面去完成任务，然后自己去进化。我觉得 o1 其实已经可能一定程度上说明这个方向有比之前更强的确定性。&nbsp;</p><p>我觉得这个会是一个重要的里程碑，可能也是 AGI&nbsp; 这个路上现在仅剩唯一的一个重要问题了。&nbsp;</p><p><strong>张鹏：</strong>所以关键问题是，期待 未来 18 个月要有新的突破和进展？&nbsp;</p><p><strong>杨植麟：</strong>对，应该是能看到很多进展的。18 个月其实很长，在 AI 领域。&nbsp;</p><p><strong>张鹏：</strong> 如果看看过去 18 个月走的路，那你未来三个月会有什么可以透露的吗？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_f856d730ccdf418ba8873f1f94d4352b@46958_oswg27716oswg1080oswg561_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>杨植麟：</strong> 我们还是希望能在产品和技术上持续的创新，就至少可能在一两个重要领域能够做到世界最好。但是有新的进展会尽快跟大家分享。&nbsp;</p><p><strong>张鹏：</strong> 看似没透露，但实际上我觉得后头应该会看到他的进展的。来，大昕。你怎么看 18 个月和未来三个月，&nbsp;</p><p><strong>姜大昕：</strong> 对，第一我很期待，就是强化学习能够进一步泛化。另外一个方向，其实我也很期待，应该说期待了很久了。&nbsp;</p><p>就是在视觉领域的理解和生成一体化的这个事情，因为在文字这个领域，GPT 已经做到了，是理解生成一体化。但是遗憾的是，在视觉领域，这个问题当然不只是遗憾，就是它非常难。&nbsp;</p><p>在目前为止，我们看到的视觉，它的理解和生成这两个模型是分开的。&nbsp;</p><p>即使像刚才说多模融合 GPT 思路，大家仔细去看，其他模态都解决了，它唯独不能生成视频。所以这是一个悬而未决的问题。&nbsp;</p><p>那么它为什么很重要呢？&nbsp;</p><p>如果我们解决了视频理解生成一体化，那么我们就可以彻底的建立一个多模的世界模型。从有一个多模的世界模型以后，可以帮助我们真正的去产生非常长的视频。&nbsp;</p><p>也就是说解决 Sora 目前的技术缺陷。还有一个就是它可以和机器人智能相结合，它可以作为机器人的大脑去帮助智能体更好的去探索这个物理世界。所以我也是非常期待的。&nbsp;</p><p><strong>张鹏：</strong>你未来年底之前，有什么我们值得期待的你的进展？&nbsp;</p><p><strong>姜大昕：</strong> 我也是期待一方面模型和技术的进步，另外一方面产品能带给用户更多更好的体验，其实阶跃有一款产品叫「跃问」，在上面，用户可以体验我们最新的万亿参数的模型，它不光是理科很强，而且它的文学创作能力也很强，经常给大家带来一些惊喜。&nbsp;</p><p>同时，跃问上还有一个新的功能叫「拍照问」，我们看到用户经常拍张照片去问食物的卡路里，去问宠物的心情，问一个文物的前世今生，包括 Mata 眼镜的发布，还有 Apple Intelligence，它今年都突出了视觉交互的功能。所以我们在跃问上也有体现，而且我们会努力一步步把这个功能做得越来越好。&nbsp;</p><p><strong>张鹏：</strong> 今天，我们已经略微超时了，但其实感觉我们讨论刚刚开始，还有很多值得持续深入的。当然可能要在未来不断的 AI前 进的过程中，我们再把这种讨论继续下去。反过来，我们至少能看到的是 AGI 的发展还在提速，这些技术还是让人充满了期待。&nbsp;</p><p>感谢今天几位的分享，也谢谢大家的聆听！谢谢！&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/RK834YtR6e2GHRKW39enAA" rel="noopener noreferrer nofollow" target="_blank">“APPSO”</a>，作者：在现场的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956705760901253</id>
            <title>云服务新战局：AI应用之争悬念丛生</title>
            <link>https://www.36kr.com/p/2956705760901253</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956705760901253</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 10:10:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_a1601b3fb8d54776895b97255d7e6c05@46958_oswg230844oswg740oswg693_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>科技圈的迭代总是让人应接不暇，眼下云服务行业又在进入新变局。</p><p>从去年的“大模型之战”，到今年的“AI应用之争”，推动着云服务进入了新的阶段，开启了云计算持续多年的新技术变革。一众云服务巨头领略到了新技术的魅力，也让他们找到了新的发展路径，更让他们开始浮想联翩——“云+AI”，能够孵化出多少可能？</p><p>而在业界眼中，“云+AI”则意味着新的悬念：云计算将如何进化，会走向何方？大模型的市场格局，会有怎样的改变？云服务巨头又会在其中扮演怎样的角色，发挥怎样的作用？大模型和AI应用，能否成为云服务商的第二增长曲线？</p><p>一连串的问号，人们期待着答案的揭晓。</p><h2><strong>新阶段：AI应用成重头戏</strong></h2><p>眨眼之间，以大模型为代表的AI浪潮，已在国内奔涌了近两年时间。公开数据显示，截至目前，国内完成备案并上线、能为公众提供服务的大模型已达190多个，注册用户数超6亿。</p><p>来自知名咨询机构埃森哲的最新调研显示，59%的中国企业计划在未来一年内继续加大数字化转型的投入，相比去年增加了6个百分点，同时，有相当多的中国企业希望能够抓住AI技术，不停地创新加速重塑。这不但显示出了各个行业对于AI服务的潜在需求，也显示出了大模型潜在的巨大商业价值。</p><p>在大模型领域重要的参与者——云服务巨头眼中，这些信息和数字意味着技术创新和重大利好：<strong>大模型各项能力的不断迭代，由此带来的商业价值会不断提升，用户规模也会持续扩大，从而形成新的业务逻辑和增长引擎。</strong></p><p>大模型的落地应用，确实改变了云行业。它不仅能够帮助行业客户实现基于AI能力的业务创新与升级，而且不同于以往的技术迭代，大模型驱动着基础设施的重构，也带来了上层应用的变革。</p><p>如果回溯一下信息技术的发展史就会看到，这种情况可以说前所未有。在大模型出现之前的很多年里，IT业一直是“CPU+OS+软件”这样的组合唱主角，但此后，计算、网络、存储的虚拟化，让算力成为了大众资源，也让云改变了基础设施的能力和形态。</p><p>而到了如今这个新的时代，“GPU+云+AI”这个新组合取而代之。在GPU为大模型提供算力支持的前提下，云服务商需要重新构建从底层到应用层的服务架构，而大模型将带来从研发到应用的重构。</p><p>这显示出了目前云服务的转变和趋势：<strong>大模型与云计算的未来密不可分，它的训练底层需要算力、存储和网络，大模型的升级和迭代，会对算力提出更高要求。</strong></p><p>同时，MaaS变成了云架构新的重要组成，成为云服务商竞相发力的重点，这会让云服务大厂的技术体系出现重大变化。随着云服务与大模型的深度融合，云服务商会以云的模式推动大模型的服务化和应用的规模化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_021db061a1ae4a7aad031537c382cda1@000000_oswg62008oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由此，阿里云、腾讯云、百度智能云等云服务巨头，在经历了过去几年的低谷之后，纷纷以AI作为未来发展的重点，用以重构自身的技术业务，从而带动业绩的增长。这些大厂发布的财报数据也显示出，来自AI的收入占比正在逐步提升。</p><p>今年8月，阿里巴巴集团发布的季度业绩显示，云智能集团在最新财季营收同比增长6%至265.49亿元，其中，AI相关产品收入实现三位数同比增长。</p><p>百度集团公布的2024Q2财报则显示，智能云营收51亿元，同比增长14%。AI收入占比9%，高于上一季度的6.9%。</p><p>在与笔者的交流中，多位业内人士表示，新一代云计算已开始初露峥嵘——云计算产业的新一轮变革也正在随之到来，由此衍生出的技术迭代、产业落地、商业转化，将会持续多年。</p><p>与此同时，云服务巨头在AI领域的深度参与和大量投入，已让去年开启的“大模型之战”的硝烟渐渐散去，大模型带来的AI应用变成了现在的重头戏。</p><p>这意味着，以MaaS平台和AI原生应用为核心的全新云服务生态已经出现，以AI技术改造的应用软件在生态中会占据更重要的位置。</p><p>由于云行业的“马太效应”，数据、算力和存储等底层资源将由少数云服务巨头主导，云服务的商业机会逐渐向上，向PaaS、MaaS、SaaS层聚拢，特别是SaaS，从研发到商业模式，均会发生根本性变革。</p><p>目前，各云服务巨头一方面以大模型对自身产品进行全面升级和改造，另一方面向不同行业输出，帮助客户和合作伙伴快速开发AI应用。</p><p>例如，腾讯旗下数百款产品均已接入腾讯混元大模型，通过智能化升级扩大付费用户基础。据介绍，今年一季度，腾讯会议收入同比翻倍，企业微信收入则同比增长200%。同时，腾讯助力众多企业客户以更加高效、简单的方式，用大模型开发AI原生应用，快速接入生产场景。</p><p>由此可见，国内的云行业在以大模型为代表的AI浪潮的推动下，目前已来到了一个新的阶段——“新型云服务商”开启了“大模型及应用淘汰赛”。在这样的背景下，云服务巨头纷纷厉兵秣马，开始了又一轮的激烈竞争。</p><h2><strong>巨头竞争：优势和软肋</strong></h2><p>对于那些处在变革时期国内云行业之中的云服务巨头们来说，之所以言必称“算力”、“大模型”、“AI应用”，是因为他们热切期盼着源源不断的新机会。</p><p>也正因为此，随着云服务巨头技术和服务的日渐完善，各家都希望能够通过AI，在2024年变得更加激烈的“云服务+大模型+AI应用”竞争中，找到自己的方向和打法。</p><p>有AI行业专家表示，随着各自技术体系的日渐完善，云服务巨头将围绕AI，展开不同维度的竞争。众多云服务巨头的推动和参与，不仅会让与AI相关商业模式的效果快速显现，而且对于AI研发、AI能力、AI应用、AI模型迭代在各行业不同场景中的落地，包括AI生态圈的建设，均会带来深远影响。</p><p>如今，国内云服务巨头的AI布局日益清晰。腾讯云善于培育生成式AI加持下的SaaS服务、华为云凭借昇腾AI芯片不断扩大自己的“朋友圈”、电信运营商云持续发力AI算力。</p><p>按照多位业内人士的观点，在一众激烈竞争的云服务巨头之中，阿里云和百度智能云颇具代表性，可以说构成了目前国内云和AI发展的两极，各自也都有着优势和软肋。</p><p>2023年，阿里经历了业务和组织架构上的重大调整，云业务成为了集团的战略重心。阿里云搭建技术服务体系的思路很清晰，通过从底层算力到AI平台再到模型服务的全栈技术创新，对云服务进行整体升级，以IaaS层为基础和底座，加上PaaS层的容器、中间件、数据库、大数据计算、数据仓库与数据湖，为MaaS层的基础大模型、行业大模型做支撑。</p><p>同时，阿里希望与大量的AI企业产生业务协同。自2023年以来，阿里投资了大量的AI公司，智谱AI、百川智能、零一万物、MiniMax、月之暗面等头部创业公司的融资，都有阿里的身影。投资模式可为阿里云的生成式AI业务的落地节约时间，增强实力。</p><p>但问题在于，阿里云近年来的宕机事件（包括最近阿里云盘出现BUG），正在反复考验着阿里云的品牌和口碑，作为规模化的基础设施服务，服务信任体系的建立与破坏重建的代价，都是十分高昂的。</p><p>而且，从业绩上看，阿里云的营收规模虽比此前有所增长，但最新一季营收仍然只有6%，如何让“AI+公共云”这一组合突破规模瓶颈，如何保持领先，从而与其它竞争对手拉开距离，追赶上全球顶级云服务商的脚步，挑战仍然巨大。</p><p>与阿里云不同，百度智能云一直以来的打法是以AI带动云，从此前官宣“文心一言”作为开始到现在，百度智能云所推出的大模型相关的云计算产品，已涵盖从底层基础设施，到大模型开发与应用，再到AI原生应用开发端到端，这让百度智能云的“云智一体”架构得以持续升级，加速重构百度的业务和营收结构。</p><p>而随着“云智一体”架构的完善，百度在AI芯片、框架、模型、应用均有布局，已形成了一种“智能闭环路径”。但在应用层，AI原生应用并不是简单复制传统软件和移动互联网APP就可以，而是需要为客户解决很多过去解决不了、解决不好的问题，这对于百度的“云智一体”战略、大模型产业生态、AI原生应用生态，都将构成较大的考验。如何面向企业级客户提供更有效的赋能工具，是百度智能云接下来需要面对的挑战。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_5aed02fe37b249ac915f29b2fbaa793a@000000_oswg51079oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>多位行业观察人士和研究专家认为，阿里云和百度智能云是目前国内云服务商的两个典型代表，他们各自旗下的云和AI技术体系都很完善，业绩回暖的同时，需要面对诸多考验和难题。</p><p>这说明，目前国内的云服务市场，处于结构性调整阶段，在国内的AI大模型红利真正到来之前，新一轮的云计算技术变革，由于受到技术和服务架构升级、应用产品落地、以AI为核心的新型生态的建立都需要大量时间等因素影响，将会持续多年。</p><p>在此过程中，会开启“淘汰赛”，很多资金、技术、服务实力偏弱的“玩家”，会逐步被淘汰，或是被主流玩家收购。</p><h2><strong>淘汰赛：如何突围？</strong></h2><p>有行业观察人士表示，云行业的“淘汰赛”，往往通过降价的方式展开。云行业属于“烧钱”的重资产行业，加上企业客户每年的IT支出固定，市场处于存量竞争状态，哪个云服务商拓展了更多客户，拿下更多大单，其它的云服务商的业绩势必会受到影响。</p><p><strong>云巨头的逻辑是，通过降价，可以提升云计算在不同行业的渗透率，扩展用户规模和黏性，还可以通过普及算力，释放技术红利，驱动非互联网行业从简单上云到深度用云，从而形成规模效应，持续降低边际成本，获得更高利润，以便实现新的资源采购与研发投入，以此巩固竞争优势。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_3de5eead63bd48d68856deec36bab879@000000_oswg89607oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AI大模型同样如此。今年5月时，各个云服务巨头，纷纷大幅下调大模型调用价格：</p><p>例如，字节跳动旗下的豆包主力模型，在企业市场的定价调整为0.0008元/千tokens，较行业平均价格便宜99.3%；阿里通义千问GPT-4级主力模型Qwen-Long输入价格为0.0005元/千tokens，降幅达97%，输出价格为0.002元/千tokens，降幅达90%......降价之剧烈，让大模型创业企业在价格上难以抗衡。</p><p>“很明显，云服务巨头此番降价的目的在于扩大市场和用户规模，这会是他们的长期策略，”上述行业观察人士估计，今年开始的大模型“淘汰赛”，会持续三年左右的时间。云服务巨头希望通过降低大模型调用价格，刺激调用次数的大幅增长，算力成本会因此而摊薄，慢慢产生利润。</p><p>而且，价格的一降再降，能够吸引大量开发者和生态合作伙伴。在此过程中，其它的大模型服务商会因为价格和成本原因倒下，市场上的大模型服务商变得屈指可数，这就是云服务商推动“淘汰赛”的目的所在。</p><p>但有专家认为，这也反映出了云服务巨头的大模型思路有待改进。作为对比，OpenAI旗下的ChatGPT，其研发成本、训练成本和人力成本，每年动辄花费数十亿美元。这表明，大模型的技术和资金门槛非常高，而且需要不断升级，这就需要有更多的投入，其中的风险也是非常多的。</p><p>国内的科技巨头目前呈现出了大模型平台雷同的趋势，大模型产品服务的同质化问题突出，关键在于，AI大模型对于云服务巨头的进一步增长的带动作用有多大，随着投入力度的不断加大，AI是否会像这些巨头预期的那样，带来越来越丰厚的回报，这些都是未知数。</p><p>这位专家表示，在有一两个足够好的基础大模型的基础上，其它巨头企业其实应该将关注点放在算力、数据、大模型训练等中间层服务上，或者是大模型衍生出的真正能够创造价值的行业应用上。“现在的云服务巨头可以说是悬念迭起，AI大模型对他们真正的考验还在后面。”</p><h2><strong>结语</strong></h2><p>的确，大模型与AI应用，为云服务巨头带来了新的变化，新的期盼，但同时也带来了新的挑战。相比之下，国外的科技巨头在发展大模型方面，做得要扎实得多。</p><p>如今，亚马逊、微软、谷歌这些巨头企业，均以投资或者自行研发的方式推出了大模型产品。特别是微软，在云、软件和AI大模型方面，已经趟出了一条清晰的路径，这三大业务相辅相成，互为补充。围绕这三大业务，微软不仅逐渐形成了涵盖IaaS层、PaaS层、SaaS层的全面业务布局，而且积极进行投资并购，以扩充自身的业务范围。</p><p>“从微软的例子来看，他们已经建立了一个良好的业务循环，”上述行业专家认为，第一，大模型的应用消耗大量算力，可以带动云服务的收入增长，第二，大模型同时会优化软件应用的功能和体验，带动软件业务收入的增长，发现新的用户需求，反过来还可以进一步促进大模型的成熟。</p><p>但这些做法、思路和经验并不能为国内的云服务商和大模型服务商带来太多助益。由于中美云服务市场、客户需求、技术服务等方面的诸多差异，国内云服务商在面对大模型的时候，其实并无太多可以提供参考借鉴的例子，在大模型这个问题上，中美云服务商的不同点会越来越多，国内的大模型服务商，需要找到自己的节奏、特色和优势。</p><p>当前，国内的大模型和AI应用服务尚处于初级阶段，市场规模和产业成熟度尚待提升，空间巨大，各方竞争激烈，在这样的形势下，如何培养大模型的刚需用户群体？大模型的业务边界如何划分？大模型如何成为稳定持久的业务增长引擎？大模型在各行各业落地应用时，如何保护隐私和数据安全？</p><p>只有通过不断构建健康、自主可控的大模型生态，吸引越来越多的创业者、开发者、合作伙伴、客户加入进来，才能让大模型和AI应用真正成为各行各业智能化升级的“刚需”，形成新质生产力，从而让创新发展的新动能与新优势，真正显现出来。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzUxNDcwNjIwNQ==&amp;mid=2247550095&amp;idx=1&amp;sn=85f6426e41b6df045207e1c5621373c5&amp;chksm=f89247d2cc8bb5d5c0a189054cd96ef8545added4996abf7397603db168282f8c751e0b89cc4&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“一点财经”（ID：yidiancaijing）</a>，作者：一点.大科技组，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956715574271620</id>
            <title>拆解式回应“股东檄文”，图森“未来”生变？</title>
            <link>https://www.36kr.com/p/2956715574271620</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956715574271620</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 10:08:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>市值最高攀至160亿美元的自动驾驶明星公司，风波仍未平息。&nbsp;</p><p>此前，“一份11页的股东联合檄文”细数图森未来（下称：图森）陈默、郝佳男等管理层“五宗罪”，涉及自营交易和挪用公款等，并传出侯晓迪（联合创始人，曾任CTO、CEO、总裁、董事会主席）试图夺回图森等消息，引发外界广泛关注。&nbsp;</p><p>9月18日，图森现任管理层——创始人、董事长陈默，CEO吕程，中国区CEO郝佳男集体亮相沟通会，对“股东檄文”进行拆解式逐一反驳，并对公司“混乱”的过去，“迷雾”中的现在和未来进行耐心解答，试图向外界传达：图森想要活下去，想要活得更好。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_dc0993bce6864e118b7bc8163be6423f@1629410002_oswg68807oswg1080oswg515_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：猎云网&nbsp;</p><p>对于图森的发展方向，陈默表示，“（侯晓迪）可能觉得无人驾驶是唯一的路”，但是，“我们（图森现任管理层）觉得公司现金流是唯一的路”。&nbsp;</p><p>基于“现金流为王”，图森已于今年8月正式宣告转型AIGC方向，并宣布与《三体》的相关IP授权与合作。而这，或许正是“股东檄文”的导火索，也给今年12月的董事会换届制造了不确定性。&nbsp;</p><p>2025年前后，伴随控制权一锤定音，财务报告新鲜出炉，图森的未来，方能揭开一层神秘面纱。&nbsp;</p><h2><strong>“股东檄文”细数“五宗罪”，现任管理层一一回应</strong></h2><p>从2021年4月登陆纳斯达克市值一度超过160亿美元到如今的暂停上市，从2015年CEO陈默、CTO侯晓迪、首席架构师郝佳男联合创立的自动驾驶公司到如今的探索AIGC业务，图森的未来，不再星光熠熠，充满不确定性。&nbsp;</p><p>自2022年3月起，图森管理层剧变不断：吕程、陈默相继出局，又在大权独揽的侯晓迪被董事会罢免后，重新返场掌舵这家公司。（推荐阅读《<a href="http://mp.weixin.qq.com/s?__biz=MzkxNzQxNTg2OA==&amp;mid=2247484541&amp;idx=1&amp;sn=494533861ab752dc04a7a8d029b6918a&amp;chksm=c141b6aef6363fb895b3a38dc5e5da4549f76f828b3c00ece4921f3c71ee1fd464d6e7c0689a&amp;scene=21#wechat_redirect" rel="noopener noreferrer nofollow" target="_blank">被炒CEO复仇！图森管理层再迎“剧变”</a>》）&nbsp;</p><p>然而，陈默吕程接手的图森已然元气大伤，面临的是环境大变、业务中断、频繁被审查的烂摊子。陈默吕程不得不裁员、缩减美国业务并转向日本澳洲等国家重建商业生态，有消息称，侯晓迪对此持不同意见“图森要做L4级无人驾驶，且主阵地要在美国”。（推荐阅读《<a href="http://mp.weixin.qq.com/s?__biz=Mzg5MTc3NjgxNQ==&amp;mid=2247498575&amp;idx=1&amp;sn=a666fe40b8aa069d1c4b7c1e4f12f61b&amp;chksm=cfca810ff8bd081920ed6510413123d843cc46fc279acaa705cd90bd7541108b1826659ac129&amp;scene=21#wechat_redirect" rel="noopener noreferrer nofollow" target="_blank">图森未来震荡继续！将裁掉一半人，叫停多个业务，今年已亏3.34亿美元</a>》）&nbsp;</p><p>彼时，已经暂时失去超级投票权（授权陈默，为期两年）的侯晓迪，无奈离开图森转而创办一家新的自动驾驶公司Bot.auto，试图再造一个“图森”。&nbsp;</p><p>直到图森逐渐转型AIGC业务，再次将这家公司的“未来”之争点燃，“股东檄文”由此诞生，此举或许也给了侯晓迪重新寻求夺回图森的希望。由此，图森现任管理层集体亮相，对外予以回应。&nbsp;</p><h3><strong>1.背离主业？</strong></h3><p>“股东檄文”指出，陈默、郝佳男注册的新公司主体，主要方向为视频制作和动画领域，与图森的自动驾驶业务不符合；&nbsp;</p><p>图森在8月15日发布的与《三体》合作的相关稿件中明确指出：公司“生成式AI”新业务部门正式成立并宣布公司正式进入动漫、电影和游戏行业，该业务已经获得集团董事会的一致批准，符合集团公司相关的股东章程和审批流程。&nbsp;</p><p>基于此，图森探索新业务战略和方向，自然也属于正常招聘相关人才开展商业活动，不存在任何违规行为。&nbsp;</p><p>对于背离自动驾驶主业，图森现任管理层表示：公司并无计划退出交通运输行业，将通过技术合作和授权，继续推动自动驾驶技术实现商业化。&nbsp;</p><p>陈默在沟通会现场透露，目前已经接洽了两个车企客户，合作规模（专利授权费）预计在千万美金级别。&nbsp;</p><h3><strong>2.利益输送？</strong></h3><p>“股东檄文”指出，注册的新公司主体可能与陈默个人控制的影视和动漫相关的公司之间有关联。&nbsp;</p><p>对此，图森现任管理层表示，新设立的两家公司主体：&nbsp;</p><p>北京熊熊的梦幻工厂文化有限公司（下称：北京熊熊公司）正是图森集团基于生成式AI的新业务方向，根据中国法律要求设立的VIE结构的中国境内公司。北京熊熊公司的股东由中国籍自然人、公司高管郝佳男和李海泉担任，并根据图森公司要求与两位高管签署了相关的VIE控制协议全套文件。&nbsp;</p><p>广州熊熊动漫文化有限公司是北京图森未来科技有限公司的全资子公司，是图森集团体系内的全资子公司。&nbsp;</p><p>以上两家公司设立流程符合图森集团的公司管理制度、公司章程和股东利益，不存在欺诈和利益输送行为。&nbsp;</p><h3><strong>3.关联交易？</strong></h3><p>“股东檄文”指出，陈默相关的北京熊熊国文化传媒有限公司、北京水墨侠道文化传播有限公司、广州熊熊国的侠道互动娱乐有限公司、侠道（上海）文化传播有限公司的关键职位——董事、监事和财务总监为图森相关人员，且多家公司注册信息、联系方式、通讯地址与图森、Hydron之间有重叠。&nbsp;</p><p>对此，图森现任管理层表示：&nbsp;</p><p>北京熊熊国文化传播有限公司——该公司2020年陈默个人设立，当时图森集团计划探索互联网业务，后来没有任何的实际运营，也没有任何业务。&nbsp;</p><p>其他水墨侠道相关的公司——水墨侠道公司的创立初衷是陈默个人对武侠和动漫、游戏的兴趣和热爱；公司成立后与图森集团一直保持独立运营，没有使用过图森的任何资金和公司资源，所有运营资金均来自陈默个人。&nbsp;</p><p>上述的注册联系人信息均为公开信息，当时图森集团也不是上市公司，相关同事也只是帮忙注册一下相关信息，并不存在水墨侠道与图森集团之间的关联方交易。&nbsp;</p><h3><strong>4.欺诈隐瞒</strong></h3><p>“股东檄文”指出，图森现任管理层尤其是CEO吕程，一直在编织一个谎言，试图欺骗董事会、公众和美国联邦法院。他们声称图森未来在中国的自动驾驶商业化进程如火如荼，迫切需要大量资金以维持这一机会。比如，在图森发布的每一份公开文件中，吕程都未曾透露公司正悄然转向视频游戏和动画制作。2024年6月，吕程还向美国加州南区联邦法院坚称，图森中国是投资者从图森自动驾驶技术中获益的唯一途径。&nbsp;</p><p>对此，图森现任管理层表示：&nbsp;</p><p>2024年2月，美国南加州法院发布的TRO禁令对图森中国自动驾驶业务产生了巨大影响，并导致了大量核心技术研发团队离职。为了保证道路测试安全，图森逐步减少了自动驾驶研发测试工作。&nbsp;</p><p>2024年3月，鉴于在自动驾驶领域面临的挑战和困难，图森高管团队开始生成式AI应用相关的前期探索工作，并积极与董事会进行沟通讨论；经过前期数月的初步探索，管理层认为该领域存在巨大商业化机会。&nbsp;</p><p>因此，根据公司章程和治理制度，图森集团于2024年8月12日召开董事会，正式批准了建立生成式AI新业务方向，正式进入动漫电影和游戏行业。8月15日，公司正式宣布与三体宇宙的相关IP授权与合作。&nbsp;</p><p>图森管理层和CEO，在上述的商业活动中不存在任何欺骗董事会、公众和美国联邦法院的行为，也没有将资金故意转移到中国。图森集团资金没有用于陈默个人相关的视频游戏和动画领域投资。&nbsp;</p><h3><strong>5.成本剧增</strong></h3><p>“股东檄文”指出，图森暂停自动驾驶相关的运营之后，AWS的成本没有下降，并迅速增长到几百万美金级别。股东怀疑图森可能将大部分的资源用于动画和视频相关的项目。&nbsp;</p><p>对此，图森现任管理层表示，AWS的相关合同，是公司前任CEO和创始人侯晓迪在职期间与AWS签署的年框合同 （具体条款见下图），且合同中有最低消费的要求，相关资源可用于后续生成式AI相关业务。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_888b7800e4f34357a61f1a8b0c7ed30d@1629410002_oswg246926oswg784oswg952_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：图森&nbsp;</p><h2><strong>侯晓迪回归存疑，转型AIGC因“现金流为王”</strong></h2><p>事实上，图森管理层的出局、返场，运营层面的裁员、转型AIGC，一系列争斗、内乱的根源在于——权和钱。&nbsp;</p><h3><strong>1.权：侯晓迪要回归？</strong></h3><p>具体而言，图森的管理层争斗涉及三方：侯晓迪、吕程和陈默、“美国董事会”（彼时，图森的董事会席位中一度没有中国董事在任）。&nbsp;</p><p>此前，侯晓迪与吕程、陈默的管理权之争，已经被广泛报道，并以后者出局暂时落幕。然而，大权独揽的侯晓迪，又在半年后遭遇了“美国董事会”的“恶意罢免”。&nbsp;</p><p>陈默回忆到，2022年10月底，侯晓迪曾主动联系他并求助：“在此之前，我们俩就很久没联系。侯晓迪希望我动用超级投票权，帮他把图森当时的管理层干掉，当时具体发生什么，我确实不知道。就在我考虑的时候，第二天他就被开除了，这是一个客观事实。”&nbsp;</p><p>需要注意的是，在图森的架构里，陈默和侯晓迪都拥有31%左右的超级投票权，二人只要共同行使超级投票权，就能在任何时刻绝对控制公司。&nbsp;</p><p>然而，半年前遭遇侯晓迪“背刺”的陈默，很难爽快答应。据智通财经消息，陈默甚至主张新浪及其他中方股东和他一起卖股票，即使当时股价已经从高点跌去95%，也要彻底与图森划清界限。&nbsp;</p><p>经过投资方作为中间人的多次撮合游说，陈默终于松口，“当时（图森）情况很差很差，包括很多的业务都崩了，当时的董事会我也已经一个都不认识了。如果让我回去，当时我就提了两点要求才肯去收拾这个烂摊子：第一，要吕程跟我一起回去；第二，让他（侯晓迪）把超级投票权给我，如果没有绝对权力的话，我收拾不了当时的董事会成员”。&nbsp;</p><p>回归图森后，陈默和吕程面临的是自动驾驶市场遇冷的复杂环境，自身业务上合作伙伴逃离的业务中断等，二人无奈裁员收缩。&nbsp;</p><p>而这，也引发了侯晓迪与陈默、吕程的不满，并最终导致他彻底离开公司“另起炉灶”，试图再造一个“图森”。近期的“股东檄文”和相关传闻，则给侯晓迪“夺回”图森创造了机会和部分支持。&nbsp;</p><p>需要注意的是，今年11月侯晓迪的超级投票权将正式恢复，12月股东会将选举新的董事会和董事长。&nbsp;</p><p>图森方面表示，“图森集团董事会和管理层会按照公司治理文件和法律要求的流程，正常进行董事会和股东会的换届选举”。吕程在沟通会现场表示，“（侯晓迪）是否回归是一个法律问题”。陈默补充到，“我们的意见显然是相左的，那剩下的就看A类股股东如何投票”。&nbsp;</p><p>值得一提的是，陈默还在现场提到，“从来没有抹黑过侯晓迪，一直都是公司层面运作处理，如果有哪篇稿子说我们抹黑侯晓迪，可以找出来发给我们看。”&nbsp;</p><h3><strong>2.钱：“现金流是唯一的路”</strong></h3><p>无论是当时的裁员收缩，还是如今的转型AIGC，作为掌舵者的陈默都强调“现金流是唯一的路”，“今天的图森，最关注的是现金流，现在只做赚钱的业务。”&nbsp;</p><p>而这，正是图森选择转型AIGC，成为一家人工智能科技公司的无奈选择。&nbsp;</p><p>吕程在沟通会现场表示，图森进入AIGC领域其实很正常，“我们会不停地寻找更多的商业机会，包括怎么实现商业化，提高公司和股东的价值，这是我们应该做的事情。”&nbsp;</p><p>对于转型AIGC的逻辑，吕程将其概括为四个方面：&nbsp;</p><p>首先，市场层面，近一年来AIGC非常火，行业也取得了迅速发展。而且，内容和游戏是非常大的一个市场，全球大概有6000亿美元的规模。&nbsp;</p><p>第二，价值层面，我们也通过研究游戏和动画的制作流程，觉得AIGC在这里面能创造很大价值，比如说提高效率、缩短制作周期等等。&nbsp;</p><p>第三，技术层面，“自2022年初开始，图森已在自动驾驶领域开展大模型技术和生成式AI应用的研发与实践。此外，公司自主研发的用于大规模数据管理的基础设施，为生成式AI技术在新领域的应用提供了坚实基础。”&nbsp;</p><p>郝佳男补充到：目前图森技术团队大约有200人左右，还是当年做自动驾驶的核心团队，转向AIGC后同样可以延续优势。&nbsp;</p><p>第四，管理层面上，我们在这方面也有一些经验。比如陈默在创办图森之前，有过多年的游戏行业经验。&nbsp;</p><p>此外，图森进军AIGC领域的战略也比较简单，就是和著名的大的IP合作，和著名的业界人才合作，创作高质量的内容和游戏。&nbsp;</p><p>以今年8月15日，图森宣布与《三体》的合作为例：其与上海三体动漫有限公司达成合作，共同开发基于小说《三体》系列的动画长篇电影和视频游戏。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_6fd4ce8c532547c5a688f1079b53bf70@1629410002_oswg240050oswg500oswg2591_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：图森&nbsp;</p><p>谈及图森下一步还有哪些新的IP内容和游戏发行的计划、未来的主要业务市场是哪些？&nbsp;</p><p>图森现任管理层表示，公司会积极推进生成式AI技术研发和IP内容的打造，预计会在今年12月发布相关的业务进展，业务将面向全球市场。如有更进一步的更新，我们会及时与各位媒体和投资者沟通。&nbsp;</p><p>需要注意的是，截至2023年9月30日，图森未来持有7.768亿美元的现金、等价物和投资。相关文章提到，“扣除已经存入托管账户的1.74亿和解金，粗略估算（图森）目前还有4亿美元左右。”&nbsp;</p><p>对此，图森现任管理层表示，“公司2024年的审计财报报告正在准备中，预计明年初会公开发布”。&nbsp;</p><p>换言之，无论从现金角度还是管理层潜在变动角度出发，留给图森“逆转”未来的时间，都不多了。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/XQLV6PtgnqZQHqazakhLIg" rel="noopener noreferrer nofollow" target="_blank">“猎云精选”</a>，作者：王非，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956705616263044</id>
            <title>OpenAI o1：大进步？小技巧？新思路？</title>
            <link>https://www.36kr.com/p/2956705616263044</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956705616263044</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 10:03:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d5b348533a534ada8e3171d397e39ebc@000000_oswg75552oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>经过漫长的等待，OpenAI终于在9月12日发布了新模型O1，用户可以直接访问预览版o1-preview，或者小尺寸版o1-mini。其酝酿了快一年的大招，一会儿Q*、一会儿草莓、一会儿AGI、一会儿GPT5，耗得核心技术团队都快走光了，才终于拿出来让所有人检验和评论。这样一个备受瞩目的产品，势必对行业甚至社会产生深远的影响。而且它不像平时那些版本更新一样，只是简单的技术能力提升，而需要从多个视角和维度去观察和预测其影响。</p><h2><strong>一、大进步</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_4e7cb215bb1e40f2b408cb4dffffc81a@000000_oswg157827oswg1080oswg420_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与GPT-4o相比，o1-preview在解决数学和编程问题上的能力提升了5倍以上，而还未放出的o1则超过8倍！在解决博士级别科学题目的时的成功率，都已经超过了人类专家的水平。理化竞赛能力都超过了人类博士的水平；在国际数学奥林匹克（IMO）资格考试中，GPT-4o 只正确解决了 13% 的问题，而推理模型的得分为 83%；编程能力在Codeforces 竞赛中超过了 89%的人类选手 。o1看起来在包括科学在内的各个领域都超过人类的最强能力，不难理解奥特曼之前对实现AGI的满满自信。</p><p>在实际操作中，可以看出新模型的推理过程与之前有很大区别。我们可以看到多了一个可以打开和关闭的Show chain of thought（显示思路）框，显示了整个思维过程。类似于人类在回答难题之前的长时间思考，o1 在尝试解决问题时会通过思考将问题分解，并步步为营，反复思考每个小任务，认识并纠正错误。当一个方法不起作用时，它会尝试另一种方法，从而极大提高了模型的推理能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ec464766ba5f4116b32643fe8c5b99fc@000000_oswg139005oswg1080oswg748_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在这些激动人心的能力进展背后，一系列被大家长期猜测的技术进展也一一被验证。</p><h3><strong>1、思维链</strong></h3><p>CoT（Chain of thought，思维链），是学者们发现的能够激发大模型通过“思考”来回答困难问题的技术，可以显著提高其在推理等任务上的正确率。这个思路在两年前的几篇经典论文中已经得到不断完善。</p><p>《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models，NeurIPS2022》这篇文章提出，在问LLM问题前，手工在prompt里面加入一些包含思维过程（Chain of thought）的问答示例（Manual CoT），就可以让LLM在推理任务上大幅提升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_4c7505dfaf0c400691785acaa68044b1@000000_oswg514787oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>《Large language models are zero-shot reasoners. NeurIPS2022》提出先使用 “Let's think step by step.” 让模型自己给出推理过程（Zero-shot CoT ），也衍生出诸如“一步一步慢慢来“这些著名的咒语。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_f0781b1e4a7c4bf9b5ec9eb5a5d6cc3d@000000_oswg571386oswg964oswg678_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>《Automatic Chain of Thought Prompting in Large Language Models，ICLR2023》这篇文章可以理解为二者的结合，先用 “Let's think step by step.” 咒语产生推理过程，再把这些过程加到prompt里面去引导大模型推理。这样不需要自己写，又能相对靠谱。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_405954fe40d148dd9cfb2f170c7b0d9c@000000_oswg613374oswg1080oswg636_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在这些之后，CoT还经历了千变万化的演进，但大都还是通过prompt来诱导大模型分步思维，人们就在想，能不能让大模型自己学会这种方法呢？</p><h3><strong>2、强化学习和自学推理</strong></h3><p>类似当年的Alpha-Zero，强化学习是让机器自己通过与环境交互并观察结果的方式调整行为策略的机器学习方法，但之前很难用于语言模型。直到斯坦福大学 2022 年提出一种「自学推理」（Self-Taught Reasoner，STaR）方法：先给模型一些例题详细解法，再让模型学着去解更多的题，如果做对就把方法再补充到例题里，形成数据集，对原模型微调，让模型学会这些方法，这也是一种经典的自动生成数据的方法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_242eafc1514840a4b9014602b7c7aad0@000000_oswg161113oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>后来基于此又演进出了名为"Quiet-STaR"的新技术，也就是传说中的Q*，翻译过来大概为"安静的自学推理"。核心为在每个输入 token 之后插入一个"思考"步骤，让大模型生成内部推理。然后，系统会评估这些推理是否有助于预测后续文本，并相应地调整模型参数。这种方法允许模型在处理各种文本时都能进行隐含的推理，而不仅仅是在回答问题时。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_642ca4a921704b98a3efe2d297beb672@000000_oswg211061oswg1080oswg469_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>用人话说呢，<strong>加入强化学习就是在大模型训练时就教他一些套路（当然应该也是模型自己生成并优选的），思考时直接就按题型选套路分解问题、按步骤执行、反复审核，不行就换个套路，跟通常教小学生普奥的套路类似。但这种自学习机制，由于奖励模型的复杂，所以通常仅在数学和代码领域表现较好。</strong></p><h3><strong>3、Scaling Law的延伸</strong></h3><p>以上技术手段结合的后果就是，预训练阶段并没有什么变化，但在推理阶段的计算量大大增加，原来追求的快思考变成了故意放慢速度，以追求更加准确的结果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_8e36fda339e24531bfbedcea1ae547ff@000000_oswg75258oswg1080oswg380_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>OpenAI 提及了自己训练中发现的一个现象：随着更多的强化学习（训练时计算）和更多的思考时间（推理时计算），o1 的性能能持续提高。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_b2e6f64b4be846a4851aa43fb64ae950@000000_oswg132879oswg1080oswg1104_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>英伟达AI领导者 Jim Fan 在 X 上点评了这一事件的历史意义——模型不仅仅拥有训练时的 scaling law，还拥有推理层面的 scaling law，双曲线的共同增长，将突破之前大模型能力的提升瓶颈。“之前，没人能将 AlphaGo 的成功复制到大模型上，使用更多的计算让模型走向超人的能力。目前，我们已经翻过这一页了。”</p><p><strong>可以预见，在预训练边际成本递减的背景下，基于强化学习的推理增强会越来越受到重视并发挥作用，也会有更多的算力被投入到推理阶段，全球人工智能芯片和算力的需求也还会继续增加。</strong></p><h2><strong>二、小技巧</strong></h2><p>不可否认，o1代表了人工智能领域的一次重要进步。但细细回顾过去一年奥特曼的言行，以及OpenAI的组织架构和核心团队的变化，不免让人产生一些疑虑：这个故事会不会有些许夸大其词之处？会不会是借助一系列小技巧，来维持公司估值的增长和资源的获取呢？</p><h3><strong>1、技术壁垒</strong></h3><p>无论是Sora还是o1，其实都是基于已有科研成果的工程创新，并没有多高的技术壁垒。OpenAI最大的贡献还是坚定而不计成本地率先实践。跟Sora一样，一旦OAI明确了技术方向，工程复现大概率只是时间问题，而OAI在所有方向上卷赢全球简直是不可能完成的任务。况且以这几天全网的测试情况，模型效果只能说差强人意，很多场景下还不如其他工程手段下思维链方法的结果（如Claude3.5），甚至可以说经常只是概率稍大的抽卡，实用价值还很难确定。另外，也许是为了避免友商的窥探和抄袭，或者是因为开放的思维过程存在安全性问题，OpenAI并未向用户开放整个思维链细节，但仍有研究者在很短时间内宣称复现了与之类似的推理能力。</p><p><strong>可以想象，后面各大厂商都会开始卷推理，陆续推出“深思熟虑”版的模型，快速拉齐水平，而如果OpenAI后面再没有拿得出手的底牌，仍然难以扭转本轮模型竞赛到顶的困境。</strong></p><h3><strong>2、成本</strong></h3><p>去年已经基本完成的模型拖延了这么久才面世，除了众所周知的安全原因外，可能是因为<strong>o1和Sora一样，算力消耗过于巨大而并不具备大规模商用的可行性</strong>。面对这一挑战，奥特曼团队一直在尝试寻找解决方案。他们等待了很长时间，希望算力成本能够随着技术进步而下降。同时，他们也在全球范围内四处融资，筹集资金来购买或租赁更多的计算资源。然而，即使经过了这些努力，推出的产品仍然单次推理动辄需要数分钟甚至数十分钟，单价高出4o数倍，token消耗也经常会提升数倍。</p><p>这些因素导致了一个尴尬的局面：科研贡献暂时远大于商业价值。在这样的背景下，OpenAI的行业地位和估值能否维持，变得相当不确定。高昂的研发和运营成本，加上商业化受阻，可能会影响投资者的信心和市场预期。</p><h3><strong>3、方法论</strong></h3><p>如果说前面两点商业视角的质疑对一路引领的OAI有一些不公平，那么这个方法论是不是真的如其所说，能达到甚至超过各STEM领域的“博士水平”，其实也是值得进一步讨论和验证的。<strong>从原理上说，这种思路还是在“大力出奇迹”的Scaling Law基础上继续叠加buff，引入类似蒙特卡洛树搜索等暴力方法多路径尝试推理，某种意义上是在用文科方法解决理科问题。</strong>类似之前的AutoGPT类应用，面向复杂问题，如果不对思维链的搜索空间进行严格限制和引导，可能会陷入漫无边际的发散，消耗大量算力仍然无法得到需要的结果。</p><p>如前文提到，这种方法有些类似面向普通学生的“普奥”中常用的套路式教学，更多依赖记忆和模式匹配，而并非对问题本质的深刻理解和创造性思维。就连9.11和9.8谁大都还要琢磨半天，还有相当大概率答错。这种方法培养出的AI，恐怕更像是一个只会刷题刷分的"小镇做题家"，而非真正具有洞见和创新能力的"博士"，毕竟只有“做题”过程的训练数据好找。</p><p>诚然，在现实中，大量的科研工作确实涉及重复性、机械性的任务，这部分工作如果能够由AI来承担，无疑会极大地提高科研效率。<strong>但科研的核心仍然在于创新，在于对未知问题的探索和对新知识的发现。这需要的是灵感、创造力和逻辑推理能力，而非单纯的计算能力。</strong></p><p>正如《Large Language Monkeys: Scaling Inference Compute》一文所指出的，仅仅通过增加生成样本的数量来扩展推理计算，本质上并没有改变大型语言模型的基本属性，它仍然是一个基于统计概率进行"打字"的"猴子"。要真正实现通用人工智能，实现在科学领域的突破性进展，我们可能需要在算法和架构上寻求更加本质的创新，而不是简单地堆砌算力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_3244b0c643324d59813a05a480cb9947@000000_oswg130326oswg1080oswg238_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>三、新思路</strong></h2><p>前面是夸也夸了，踩也踩了，但归根到底，笔者认为这些都并非o1的最重要价值。虽然看起来并非OAI眼中的重点，但在材料中多次提到了一个很重要的点，就是o1更适用于科学、编码、数学和类似领域的复杂问题，或者更确切说，是复杂问题中的繁琐工作，尤其是多步归纳或者演绎推理。例如，“医疗保健研究人员可以使用 o1 来注释细胞测序数据，物理学家可以使用 o1 生成量子光学所需的复杂数学公式，所有领域的开发人员可以使用 o1 来构建和执行多步骤工作流程。”</p><p><strong>以前我们对人工智能的期待，往往是一个模型既有知识，又有智力，甚至还要有情感和创意，以至于模型的参数量和算力消耗不断攀升。但也许这些目标是要用各种不同的方法去解决，有些还可能是非技术方法。o1的未来也许确实会以某种方式提升原来多模态模型的世界理解能力，但其本身的核心价值，恰恰是一个与世界知识大幅解耦的推理模型。这一点在o1-mini上体现得更加彻底，作为一个低成本的小模型，尤其擅长编程这种不需要太多世界知识的多步严谨推理场景。</strong></p><p>人类学习的过程，是先大量学习知识，通过神经元的大量激活和连接形成智力，而具体的知识则往往会被忘记，类似张无忌学太极拳的过程。<strong>在解决不同问题过程中，除了以语言理解和逻辑推理能力为基础，还要靠可信知识的查阅和引用，靠灵感创意的涌现，靠情感的人际连接和感应……人工智能也不会仅仅是一个深度学习大模型，而会成为一个越来越“稀疏“而灵活的能力组合，甚至是一套人机协同的新机制。“做题”能力肯定是必要的，但学会了做题，离解决实际问题，还有相当长的距离。</strong></p><p><strong>o1的出现，或许预示着这样一个"能力稀疏化"的趋势。未来的人工智能，会从单一的大模型，逐渐演化为知识、推理、创意、情感等不同能力模块的灵活组合，并与人类形成更加紧密和高效的协作。</strong>o1只是一个开始，期待百花齐放的未来。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&amp;mid=2650978477&amp;idx=1&amp;sn=4aa131f7c53dd97ac9d73a01021b7cf2&amp;chksm=bdd316e9929259d60d4e23c6e28ecdb6c12c08af0d537015eb0f90bf00c6dd47a4684e60ee84&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“腾讯研究院”（ID：cyberlawrc）</a>，作者：王鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956730820933513</id>
            <title>苹果开启“万物皆AI时代”？行内人带你看懂苹果秋季发布会</title>
            <link>https://www.36kr.com/p/2956730820933513</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956730820933513</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 09:29:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_586d0dd0a7184e769fd0aa02bf131cc0@46958_oswg187893oswg960oswg539_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>9月10日，苹果召开了2024年秋季新品发布会，正式发布了历史上的第一台AI iPhone。iPhone从诞生到现在已经成为全球最具标志性的智能硬件之一，持续引领着智能手机行业的发展。然而，随着大模型技术的崛起，苹果的领先地位似乎正面临着前所未有的挑战。</p><p>在这次发布会中，苹果展示了其在硬件和软件上的进展，但相较于OpenAI等公司在大模型技术上的突破，许多人开始质疑：苹果是否已经在这场大模型竞赛中落后了？与此同时，苹果一直以其严密的隐私保护机制而闻名，但在AI时代，数据的获取和利用变得至关重要。苹果是否能够在继续保护用户隐私的同时，推动AI技术的进步？这种平衡变得越来越难以把握。</p><p>除此之外，未来AI硬件的载体是否仍然是手机？随着智能眼镜、手表等设备的迅速发展，手机作为主流硬件的地位似乎正受到挑战。苹果能否继续依赖iPhone的强大市场份额，还是需要探索其他形式的硬件设备来适应AI时代的需求？</p><p>更为关键的是，苹果要实现其“万物皆AI”的愿景还面临着技术与战略上的巨大挑战。从终端产品的整合到芯片设计的突破，苹果在实现这一目标的过程中，还需要解决哪些难关？这些问题不仅关乎苹果的未来，也关乎整个科技行业的演变方向。</p><p>为了探讨这些核心议题，我们邀请到了两位行业资深人士，他们将为我们深入分析苹果当前的处境、挑战与未来发展方向。接下来，我们将听取他们的专业见解，解读苹果在这场智能革命中的角色与前景。</p><h2><strong>嘉宾</strong></h2><p><strong>王煜全：海银资本创始合伙人、Frost&amp;Sullivan中国区首席顾问</strong></p><p>作为风险投资⼈，资深市场营销和战略投资专家，对全球的科技创新都有最新的观察和思考。</p><p><strong>李楠：怒喵科技创始人、CEO；前魅族科技 CMO 兼公司高级副总裁、魅蓝总裁</strong></p><p>作为资深的手机行业从业者，对硬件及消费电子产品的创新，有着独到的理解。</p><p><strong>郑可君：腾讯科技主编</strong></p><h2><strong>划重点</strong></h2><p><strong>●&nbsp;苹果在大模型领域是否已经落后：</strong>李楠认为苹果在AI领域完全踏空了，它传统的芯片和操作系统优势已不再是核心竞争力；王煜全认为苹果拥有“金矿”，它在本次革命中还有机会，其核心优势在于对用户行为数据的掌控，即使在当前的智能革命中行动缓慢，未来它依然具备凭借这一控制力引领行动智能的潜力。</p><p><strong>●&nbsp;苹果的AI数据隐私问题：</strong>李楠认为马斯克在推特上已经说得很清楚，调用第三方大模型时，还是得把数据给到GPT。我可以信任苹果，但我不信任OpenAI；王煜全认为归根结底，隐私安全的信任与否其实只有两个选择，不管你信任谁，都会有漏洞，重要的是“权衡利弊，取其轻”。</p><p><strong>●&nbsp;未来AI的硬件产品是不是手机：</strong>李楠认为预测未来尤其是在科技领域极其困难，甚至乔布斯也无法完全看清；王煜全认为短期来看，未来手机将作为管理中心连接各种设备，人工智能的核心是通过规模化提供高端服务，硬件和软件的价值在于有效传递这些服务，而非仅作为简单的工具存在。</p><p><strong>● 苹果要实现万物皆可AI还需要什么：</strong>李楠认为苹果丧失了激发用户情感的能力，作为消费品牌，它丧失了“One more thing”和“Think different”的能力，这可能是它面临的更大难关；王煜全认为技术革命的核心在于观念的突破，而苹果当前的Apple Intelligence只是对现有服务的提升，缺乏真正的创新。</p><blockquote><p>苹果“万物皆可AI”了？</p></blockquote><p><strong>以下为直播实录精简版：</strong></p><h2><strong>苹果踏空AI，还是仍拥有“金矿”？</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_57fe0383d05f430c86ceccc939196859@46958_oswg334916oswg960oswg516_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：Apple Intelligence——适用于 iPhone、iPad 和 Mac 的个人智能系统</p><p><strong>总结：苹果的核心挑战在于硬件与软件周期的平衡，需在兼顾旧设备兼容性与抓住新技术革命间做出选择</strong></p><p><strong>腾讯科技：怎么评价这场发布会？看完后感受如何？</strong></p><p><strong>李楠：</strong>这些年来，苹果每年的发布周期是固定的，它的发布会一直存在同样的问题——确定性太强了，以至于我即便不看也能猜到他们会做什么，毫无惊喜。</p><p><strong>王煜全：我认为苹果并没有这么不堪。它过去的策略，和现在有所不同了。</strong></p><p>过去苹果更多的是处于“evolution”的阶段，这种进化过程中的硬件预埋策略是非常有效的。</p><p>它的做法是，在推出任何新应用时，确保前三代手机都能支持，因此在某些功能推出时不会立刻应用到最新机型上。</p><p>这也是为什么我们总是感觉苹果推出应用的时间总是比其他公司要晚。这并不是苹果没有能力立刻推出，而是因为它要确保旧机型也能兼容，这个策略在以前是可行的。因为换手机的周期大概是3到4年，因此，当三代手机都能支持一个应用时，市场上就有80%的苹果设备能够使用该功能。这个策略支撑了苹果的应用生态，特别是App Store的发展。</p><p>然而，当今市场的变化带来了新的挑战。如今的革命（revolution），与过去的渐进进化不同。这种革命性的变革迫使苹果思考是否要继续沿用旧策略，是否仍然要等待三代手机都能支持新技术再推出新功能。</p><p>例如，苹果这次推出的A18芯片，标榜为支持Apple intelligence的第一代芯片。那么苹果是否要等到市场上有三代手机都搭载了A18芯片，才推出全面的人工智能应用呢？如果这样的话，可能等到那个时候市场早已发生了巨变，这样苹果就会失去革命的时机。</p><p>因此，苹果面临两难的选择：是继续背负过去的用户基础，延续之前的策略，还是抛开旧用户，轻装上阵，快速跟进新的技术潮流？<strong>诺基亚就是这么死的，但是很多时候，后人没有办法吸收前人的经验，还是会做一模一样的选择。</strong></p><p><strong>总结：创始人和职业经理人在面对风险与机会时，决策的出发点可能大不相同，库克的稳健与责任使他做出了更保守的选择。</strong></p><p><strong>王煜全：</strong>说到底，还是创始人和职业经理人的问题。Tim cook是一个非常典型的经理人，我们已经预期到这是一场革命。我们也预期到苹果在这个革命当中有很大的优势，<strong>但是我们依然会知道苹果还是会采取保守策略，以至于可能会错过这场革命。</strong></p><p><strong>腾讯科技 ：</strong>如果他是创始人，可能会选择放手一搏，抓住一个机会后全力以赴。而库克带领苹果已经13年了，他可能更倾向于稳健发展，确保股价稳定，对投资人有交代，同时也要考虑到维持大批员工的生计。这是他必须优先处理的事情。尤其是在去年大语言模型技术还未完全明朗的背景下，库克的选择可能更为谨慎。</p><p><strong>总结：苹果在AI领域已经完全踏空了，它传统的芯片和操作系统优势已不再是核心竞争力。</strong></p><p><strong>李楠：事实上苹果已经错过了这场革命。</strong>我们都知道，苹果这几年一直在不断收购公司，但它并没有收购任何一家真正涉及大规模语言模型（LLM）的公司。苹果所说的AI与今天我们所提到的大规模神经网络完全不同。</p><p>首先，我们需要明确AI的概念。在大规模神经网络的语言模型领域，苹果完全没有核心能力。它与中国一些依赖开源技术的公司水平差距不大。虽然苹果拥有一些专利，比如通过识别画面来预测用户意图的技术，但与中国其他品牌相比，并没有显著差距，这也是它为什么需要接入GPT-4o的原因。</p><p>因此，苹果确实错过了2023年3月由OpenAI发布GPT4所引发的大规模语言神经网络革命。在2023年3月之前，苹果拥有两个核心技术：芯片设计和操作系统。但当大规模神经网络成为算力的中心时，计算的方式从冯诺依曼架构转向了大规模神经网络，这使得苹果的这两项核心技术不再具备优势。<strong>这是苹果多年来首次未能掌握最高价值的算力部分。</strong></p><p>基于原生多模态数据训练的GPT-4o发布后，整个领域的进展非常迅速。我们持续跟踪所有模型的性能和进展时，感受到的速度非常惊人，完全像我刚毕业时在互联网早期写程序的感觉——几乎每天都有新的东西出现。</p><p>而iPhone是一个拥有7000万台级别的量产产品，驱动着全球供应链，它的软件功能已经非常复杂了。在这种情况下，苹果不可能毫无准备地跟上如此迅速的技术变化。</p><p>这说明两点：第一，苹果在转型时确实非常难以掉头；第二，它在AI领域完全踏空了，显得非常被动。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_8a4a6d74ce7e47b9b5b72ad2fb9fc1fa@46958_oswg1080745oswg1000oswg569_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>总结：苹果拥有“金矿”，它在本次革命中还有机会，其核心优势在于对用户行为数据的掌控，即使在当前的智能革命中行动缓慢，未来它依然具备凭借这一控制力引领行动智能的潜力。</strong></p><p><strong>王煜全：</strong>刚才李总提到，这次苹果发布会表现平平无奇，所以大家的反应很正常，但苹果的股票并没有大跌，原因很简单，尽管发布会没有惊喜，但苹果的终端实力依然存在。</p><p>对此，我与李总的看法不完全一致，我不认为这一轮的革命是由大模型主导的。大模型主导的是上一轮革命，不管是大语言模型还是其他类型，它们的核心都是内容。比如OpenAI的核心价值就在于它利用了整个互联网的数据进行训练。</p><p>我们需要把话题扩展一下。人工智能时代还没有真正的思想家诞生，而在之前的互联网时代，像凯文·凯利这样的思想家曾出现过。在无线互联网时代，这样的思想家没有出现，导致了巨大的误解，很多人以为无线互联网只是互联网的无线化，实际上它有本质区别。互联网的核心在于内容的聚集，因此会诞生大模型，而我们称之为内容智能。</p><p>但无线互联网是关于行动的汇集，是第一次大规模地采集和分析人类行为。所以我们称之为终端智能，它是行动智能而不是内容智能。在行动智能领域，手机厂商拥有很大的控制力，因为用户的行为被手机厂商记录和分析。我认为，只要这种行动控制力没有被打破，苹果的优势依然明显。</p><p><strong>虽然苹果在行动智能方面还没有布局，甚至可能意识还不够深刻，但等到它真正想做的时候，其他公司未必能超越。因此，苹果的优势依然牢牢掌握在自己手中。</strong></p><p>现在我们大部分的手机行为都是通过App实现的，而这些App的底层实际上由苹果主导。如果苹果想打通这些App，它是有机会的，但如果它不愿意，外界的第三方App想打通的可能性非常小。</p><p><strong>这就意味着，苹果拥有“金矿”，如果它不去挖掘，别人也没法挖。</strong>以前我在为移动做顾问时也看到过类似的情况，直到某一天无线互联网真正打开，篱笆才倒塌，这才让其他人有了机会。这道篱笆何时倒下，可能还需要一些时间。<strong>所以苹果的逻辑很简单：如果它不推动革命，外界也难以掀起革命。</strong></p><p>OpenAI的这种“革命”，它更多是延续了互联网的逻辑，我认为这并不是终端智能的本质。目前手机上运行的多个App之间是割裂的，过去我们都体验过这种痛苦，比如搜索功能越来越低效，因为内容被分散在各个App里。当你的行为也被分散化，导致任何一个平台对你的认知都是不完整的，无法整合。</p><p>然而，苹果对用户的认知却越来越完整。通过手机、手表等设备，苹果对用户的行为掌握得非常透彻。所以，它的自信并非没有根据。虽然这种自信对我们用户可能并不是好事，但它确实是存在的。</p><p><strong>总结：算力的变革正在改变软件和硬件的格局，核心竞争力在于为用户提供独特的高价值体验，OpenAI目前在这方面领先于苹果。</strong></p><p><strong>李楠：</strong>我是做产品的，喜欢用最简单的大白话把问题说明白。我们在做硬件产品时，常说一句话：“软件决定硬件”。其实还有一句话我们通常不提，但它是存在的：“算力决定软件”。过去几十年，算力一直是基于冯诺依曼架构，所以这句话不需要多说，但完整的逻辑就是这样。如今，算力发生了变化，软件也随之改变。如果过去是Photoshop这样的软件主导，现在则可能是Midjourney这样的AI软件。因此，软件变了，硬件也必然会跟着变。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_3cf282b71764483cbfed589d65e04fa9@46958_oswg44708oswg960oswg548_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：冯诺依曼架构</p><p>我想强调两点：</p><p>第一，算力决定软件，算力发生革命性变化时，软件也会随之变革，提供这些软件的公司大概率不止一家；</p><p>第二，软件决定硬件，当软件变革时，硬件也会随之改变，而提供硬件的公司大概率也不会只有一家。与此同时，我要强调最后一点：<strong>所谓的“入口论”没有用户价值作为支撑。你并不是因为掌握了入口而变得强大，而是因为你为用户提供了超越的价值，不能倒置因果。</strong>核心在于提供独特的最高价值能力。客观来说，今天能提供这种能力的是OpenAI，而不是苹果，我现在已经不用苹果手机了。</p><p>我还想分享一个调研结果：我们在美国的Discord群里有几万名真正的消费者，其中一些人买了Meta眼镜。我们调研他们对Meta眼镜的不满之处，气其中有一个原因就是Meta眼镜不能使用GPT-4o。Meta眼镜卖出了200万副，但实际上，消费者并不是在购买Meta眼镜，而是购买Llama。然而，消费者觉得Llama3不够好，所以他们希望使用GPT-4o。</p><p><strong>总结：手机终端在行为智能上的潜力巨大，能够直接执行指令，而OpenAI的GPT-4o目前仍局限于内容层面的辅助功能。</strong></p><p><strong>腾讯科技：在AI时代，手机终端与大模型平台的结合逐渐成为焦点。两位认为，苹果在这一领域的开放性是否会影响其竞争力？手机终端的潜力又如何在这一场竞争中发挥作用？</strong></p><p><strong>王煜全：</strong>我认为，<strong>当一场革命来临时，沿用过去的推论来预测未来是很危险的。</strong>现在最好的工具当然是OpenAI，我也同意这一点，但认为OpenAI就是一切的前提是没有预见到未来可能会有新的革命发生。而我认为革命是存在的。我们不要忘记，最近一个热门的话题就是数据垄断。我前几天刚写了一篇关于“数字封建主义”的文章，谈到各个数字平台正在形成垄断。</p><p>举个例子，我希望手机能够通过调用我的App来完成任务，比如我对Siri下指令说“请帮我订餐”，它就能直接完成。但说实话，OpenAI目前是做不到这一点的，因为底层API很难对第三方开放，而手机终端是有可能做到的。现在苹果还没有完全开放第三方的API。</p><p>不过，苹果的手机已经在很多底层技术上实现了打通，比如视频处理功能。其实我最期待的是OpenAI的GPT-4能够直接打开摄像头，实时识别视频内容并与我互动。但目前它只做到了拍照功能，还没有开放视频识别功能。但如果我们回头看看，谁更容易做到这一点？答案显然是手机终端。所以，<strong>手机在执行我们的许多行为指令上有很大的潜力，而GPT-4o目前更多像是一个参谋或者顾问。我认为内容和行为是完全不同的两件事。</strong></p><p><strong>李楠：</strong>关于这个问题，我和两个斯坦福年轻人——“章鱼”的创始人聊过。他们通过蒸馏剪枝将端侧模型缩小到一B左右，在学习安卓12的API。他们确实担心能否学习iOS的API，苹果是否允许？我告诉他们：“不让你学的人，就是可能会被你打败的人。”</p><p>这样的情况在开源软件时代我们见过无数次。你可以帮助华为打败苹果，或者帮助安卓打败iOS，因为你能够提供比Siri更好的端侧AI体验，帮助执行任务。<strong>谁封闭，开源世界就会攻击谁。</strong>最后的结果输赢不定，但五五开是常见的结果，也许会被击败。<strong>就像今天的甲骨文，Oracle已经不再具有昔日的影响力。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_274bb1c25afa4a0097eca7ebf673a804@46958_oswg601024oswg960oswg636_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：Oracle</p><p><strong>总结：AI技术的未来充满不确定性，成功与失败交织在一起。终端和AI的形态还在快速演变中，未来充满了未知与可能。</strong></p><p><strong>腾讯科技：目前很多新兴AI应用不断涌现，但成功的似乎微乎其微，两位怎么看待这个现象？</strong></p><p><strong>李楠：</strong>GPT4的革命自2023年3月开始，到现在2024年9月，才一年多时间。在这一年多的时间里，可能性是无限开放的。我们知道，在高度成熟的互联网行业后期，投资的胜率非常低，资本认为只有1%或更少的机会，今天可能还更低。因此，100个失败的AI应用案例是完全可能的，但不代表那千分之一的成功案例不存在。我们已经看到一些例子，比如Meta眼镜在不到12个月内卖出了200万副，它确实为用户提供了真正的价值。</p><p><strong>王煜全：</strong>用历史去预测未来是非常困难的。当年互联网的BAT（百度、阿里巴巴、腾讯）出现之前，BBS（论坛）一度很流行，大家都在讨论，后来很多人说BBS会消亡，事实也证明如此。关键问题是，未来的BAT会是什么样子？我觉得在这方面的探索很少，讨论也不多。</p><p><strong>我们常说任何新技术出来就像一辆坦克，但关键是如何打出“闪电战”。OpenAI的ChatGPT确实是个“坦克”，但它的“闪电战”是什么？我觉得现在还没找到。</strong></p><p>唯一一个有一定规模的应用可能就是AI搜索，但它的形态现在和未来或许会有很大差异，还未定型，这正是它有趣的地方。因此，终端的很多形态，可能今天我们讨论的方向会与未来大不相同。</p><p><strong>总结：未来智能终端的成功不仅依赖于性能的提升，更关键的是用户的实际使用体验。手机应用与互联网应用的差异，将决定未来的发展方向。</strong></p><p><strong>腾讯科技：两位如何看待未来“闪电战”的关键因素？</strong></p><p><strong>李楠：</strong>提到“闪电战”，iPhone的迅速崛起就是历史上著名的一次闪电战，它有一个销量的“金线”。我们认为，iPhone的实际销量应该超过了70万台，供应链订单超过140万台，所以任何未达到这条线的产品，我们认为都不算是一次新的革命原型。然而，Meta眼镜已经突破了200万副的销量。虽然我不敢断言它是否真的成功，但至少它达到了一个基本的标准线，展现出了一种类似“闪电战”的效果。我认为，<strong>未来手机厂商之间的竞争，模型的智能水平将是决定性的。</strong></p><p><strong>王煜全：</strong>我觉得我们现在看到的一切，未来可能并非如此。作为经历过无线互联网时代的一员，我当时也曾担任过移动的能源顾问。那个时代一开始大家都非常关注性能等技术指标，但后来我们知道，性能到了某个阶段，已经不再是限制因素。因此，这也是一种预测，不可能完全准确，但我们应该对性能的持续提升保持信心。</p><p>回到问题的核心，我认为未来的“闪电战”依然取决于用户的实际使用体验。当性能不再是瓶颈时，真正的障碍是用户的使用意愿。从这一角度看，手机终端是关键。事实上，我们现在刚刚迈出了第一步，我们讨论的主要是将现有的OpenAI业务从互联网转移到手机上，但忽略了手机与互联网是完全不同的。手机上的应用和互联网应用可能会有很大差别，而在这方面的研究还不够深入。</p><h2><strong>数据隐私：价值与风险的博弈</strong></h2><p><strong>腾讯科技：</strong>接下来我们聊一下隐私安全性的问题，之前两位对这个话题有不同的观点：煜全很认可苹果的安全机制，而李楠对苹果的隐私保护持怀疑态度。今天我们可以展开聊聊。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_0a0d9fa928444af28d321f37f31ed083@46958_oswg240016oswg960oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：Apple intelligence安全隐私</p><p><strong>总结：隐私安全在技术发展中是无法避免的风险问题，但当技术带来的价值远超风险时，人们往往会选择继续使用。平台对数据的掌控，特别是像苹果这样的公司，可能在未来的竞争中占据领先地位。</strong></p><p><strong>李楠：</strong>我可以信任苹果，但我不信任OpenAI。我觉得马斯克说的是事实。用户隐私这个问题，实际上就是一个伪命题。苹果强调隐私保护，其实更多的是向用户表明态度，“我很在乎你，我是为你服务的。”所以我觉得听一听就好了。</p><p><strong>王煜全：</strong>我觉得这事根本就不重要。<strong>归根结底，信任与否其实只有两个选择，不管你信任谁，都会有漏洞。</strong>到目前为止，我还没见过一个完全没有漏洞的系统。也许在未来，基于去中心化构建的集中计算平台能够解决这个问题。现在，很多人在研究联邦学习等技术，但距离实际应用还有很长的路要走。这不仅是技术问题，还涉及到平台能否成立、应用能否成功。在此之前，你只能选择使用这些集中化的平台提供的服务。</p><p>严格来说，这些平台都有漏洞，甚至在某些方面，西方人认为苹果的漏洞可能更大，特别是在中国，苹果还依赖云上贵州。所有这些都是隐患。如果你认为有问题，可以选择不用，但问题是，如果不用，你就会落后。所以大多数人还是选择使用这些技术。我们会发现，很多时候我们使用的技术并没有那么安全，但当技术发展到一定程度时，安全问题就逐渐被淡化了。所以我认为，只要达到一定的安全性标准，就应该去使用这些技术，因为它们带来的利益和价值远远超过了安全性带来的风险。</p><p><strong>现在的问题是“权衡利弊，取其轻”。一方面是所谓的安全隐私，可能会有部分用户隐私被泄露；另一方面则是所有的隐私都被某个平台掌控，比如苹果。</strong>你会选择哪一边？我们之前讨论的“技术封建主义”危害更大，因为它让你没有翻盘的机会。这也是为什么我认为，苹果在下一轮竞争中可能会领先，它对用户数据的掌控过于强大。苹果可以不分享数据给其他人，但可以让自己的应用使用这些数据，这就像当年Internet Explorer是如何击败Netscape的一样。</p><p><strong>总结：苹果在隐私保护和数据监管上的保守态度虽然维护了用户信任，但也可能限制了其在终端智能领域的发展潜力，尤其是涉及AI代理和API开放等关键技术。</strong></p><p><strong>腾讯科技：</strong>那么目前来看，如果我们想找到一家比苹果能更好地保护用户隐私的科技巨头，还会有谁？另外，苹果确实是一个消费品牌，很多时候它的动作是为了传播效果。至于它具体如何处理和使用这些数据，我们实际上并不知道。</p><p><strong>王煜全：</strong>关键是，<strong>屠龙的少年有可能变成恶龙。</strong>当我保护得特别好，所有用户都涌向我时，我拥有了足够的话语权，你猜我会怎么做？</p><p>当然，坦白说，我也不认为苹果完全是在做传播。我认为现在尤其是在欧洲，数据监管越来越严格，苹果可能因为对数据监控的谨慎态度，推迟了许多新技术的推出。</p><p>比如在人工智能领域，大家都在谈论大模型，但我更关注的是AI代理（AI agents），它们能够帮助我完成任务。一个核心问题是，我能否调用其他API，甚至在手机上调用其他App。在互联网领域，API的核心就是能够调用其他应用程序。我认为，<strong>苹果之所以不开放这些功能，很可能是由于对隐私、监管以及可能面临罚款的恐惧。既然大家都没有开放这些功能，苹果也可能长期不开放，但这也意味着终端智能的功能性会因此受到很大限制。</strong></p><p><strong>总结：李楠认为安卓开源和市场多样性将推动技术的落地，即使苹果不开放也不会阻碍创新。王煜全则指出，无论是苹果还是安卓，底层功能不开放，跨App调用仍面临技术和监管的障碍，限制了真正的智能行为分析和应用。</strong></p><p><strong>李楠：</strong>那不会，安卓阵营是开源的。即使苹果不开放某些功能，我们可以通过技术demo来展示成果，最终由某些品牌落地，并获得市场成功。苹果手机的全球出货量只占14%，还有86%是其他品牌的手机，因此不会因为苹果不做某些功能而阻碍技术进步。</p><p>不同国家、市场和品牌中，总会有激进的品牌通过开源生态取得优势。我相信这些多样性会促使功能的实现。比如，章鱼正利用安卓开源代码的API进行训练。虽然有些App不开放接口，但我们仍可以通过其他手段实现功能，比如通过苹果的专利模拟GUI操作，或者利用网页URL调用功能。App生态虽然有限制，但这并不意味着需求无法被满足。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_7aa7d0be7a70407eba1fe7839adba8e6@46958_oswg546313oswg960oswg596_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：安卓VS苹果</p><p><strong>王煜全：</strong>开源阵营也有相同的问题。即便是开源的安卓，如果它不允许你从底层调用其他App，你也无法实现跨App调用，没有开放到那个程度。很多底层功能如果苹果作为手机终端厂商不开放，第三方就无法调用。不仅仅是苹果，其他品牌也会面临相同的监管问题。因此，即使苹果手机只占14%的市场份额，其他品牌也会受到类似限制。最核心的问题是，现在手机终端是否能够实现像“帮我订餐”这样的智能操作。订餐需要第三方App开放数据来分析用户行为，而很多App不愿意开放这些数据。</p><p>虽然有其他方案，比如模拟操作界面或调用网页URL，但这些并不能真正解决调用App内部数据的核心问题。即使在技术上能够绕过一些限制，但平台不开放数据接口，无法实现深度的行为分析。手机对我的最大价值在于分析我的行为并做出决策，而这些行为数据现在并不开放。如果终端厂商不开放底层功能，即便有技术手段，也很难实现我所期待的智能操作。简单来说，你能设计一个应用监督我在手机里每次调用App的行为，知道我在微信里做了什么吗？</p><p><strong>总结：未来需求挖掘的方式将超越App的限制，通过自然语言处理等技术获取用户行为数据，将成为新的方向。App不是唯一的解决方案，自然语言和新型数据采集方式将带来更深入的用户理解。</strong></p><p><strong>李楠：</strong>过去20年里，人的需求确实主要体现在App里的行为中，但Rewind的案例给我们带来了一些新的思考。Rewind的概念是通过一个挂坠记录你一天的所有声音，Plaud则是提供一个AI录音机，在需要的时候记录会议。这些应用告诉我们，<strong>虽然我们习惯了通过App进行行为表达，但人类的需求和欲望并不局限于App。我们有更自然、更根本的表达方式，不能因为用了20年App就认定它是唯一的解决方案。</strong></p><p><strong>App并不是最优解，也不可能是。如果App不开放，那我们可以不使用它，这并不意味着我们无法发现需求或解决问题。</strong>Plaud可以记录你的会议，Rewind的目标是记录你一天的音频，未来或许还会有记录视觉信息的技术。当我们拥有这些数据时，我们将能够更深入地了解用户，即使不完全知道他们在App里的具体行为。</p><p>自然语言处理能力能够主动发起对话，甚至可以直接询问用户的需求，而这正是App所不具备的能力。因此，未来会有全新的方式来挖掘需求。这些数据将具有极高的价值，但它们并不一定来源于App的操作行为。虽然App里的数据很有价值，但我对所有App是否能真正利用这些数据并进行AI化持怀疑态度。</p><p>然而，这也带来了另一种可能性。比如我们正在与钉钉合作，钉钉的创始人跟我很熟，他们正在尝试一个新方向——通过AI对App行为数据进行训练，然后利用这个AI来服务用户。当App能够理解自然语言并调用其内部功能时，它就可以与其他App进行对话。因此，未来即使我们不了解所有App的内部行为数据，也可以通过自然语言来获取信息，比如“这位用户每天大概几点开会”。</p><p><strong>而且在8个月内，我相信你会看到这样的场景。</strong></p><p><strong>总结：未来手机将超越当前的功能，成为智能顾问般的工具，帮助用户快速解决问题并进行分析。小公司虽然具备技术能力，但用户更信任大公司如谷歌和苹果，因为它们能确保数据安全并提供稳定的服务。手机和人工智能的结合将彻底改变我们与设备的交互方式。</strong></p><p><strong>王煜全：</strong>刚才提到的都是正确的，比如你可以用AI工具记录视频、分析App并执行操作，无论是来自大公司还是小公司，这些技术都可以实现。<strong>但问题在于，你会相信一个小公司吗？</strong>回想一下，当年安卓是如何崛起的。当时有很多人做手机操作系统，但最终成功的是安卓，因为它背后有谷歌支持。谷歌承诺不收费，长期维护系统，大家信任它。而小公司即使技术再好，也难以赢得用户的信任。手机是非常私密的设备，用户希望自己的手机能够保障安全。</p><p>其次，操作系统如果开放API，肯定会有监管。大公司能够确保安全，而让第三方持续记录你的行为，这实际上是非常困难的。因此，我们讨论基于几个基本点。<strong>首先，我认为手机正在超越当前的基本功能，不再仅仅是用于通讯和娱乐，未来它会承担更多任务。</strong>举个例子，我经常需要进行研究，过去我会打开电脑，通过谷歌进行搜索，再整理信息。现在，我已经习惯了使用GPT-4o，手机上有语音互动功能，我随时可以通过语音向GPT-4o提问，比如“这个问题你怎么看？”或“帮我整理一下资料”。它马上就能给出答案，极大地加快了我的研究效率。</p><p>目前唯一的问题是，手机上的整理结果还需要导入电脑，但我相信，未来苹果等公司很快会意识到这一点，可能直接在电脑上实现这一功能。人工智能的加入让我的研究过程快了一大步，感觉就像有一个强大的顾问随时在旁协助我。它背后有强大的数据库，能快速提供所需的分析和结论。</p><p><strong>因此，随着人工智能的发展，手机的使用方式将与过去完全不同。如果我们仅从现有手机的角度去解决问题，那就没有真正理解未来手机的潜力和用途。</strong></p><p><strong>总结：超级App之间短期内不可能打通数据，但随着App的AI化和大模型的发展，未来App之间通过自然语言进行交流或许会实现数据互通。</strong></p><p><strong>不过，短期内竞争仍主要集中在巨头之间，去中心化的真正实现可能还很遥远。</strong></p><p><strong>腾讯科技 郑可君：</strong>另一个问题，以后各个App之间会愿意打通数据吗？还是说它们更像互相隔着一个防盗门在隔空喊话，但是把数据还锁在自己这。我很难想象这个情景是什么样子的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_3af1af0a0e0d4355ae67e79fc3e204ac@46958_oswg231439oswg960oswg502_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：App Store</p><p><strong>李楠：不用想，肯定不会打通。</strong>苹果的数据属于苹果，钉钉的数据属于钉钉。App生态本身就是个问题，而App这种形态未来必然会面临挑战。不过，很多App正在走向AI化，像Notion这样的应用已经在朝这个方向发展。</p><p>未来，App有可能通过AI互相对话，比如Midjourney和Notion可以通过自然语言交流，这样用户就不需要再费力输入复杂的提示词了。如果所有App都能理解自然语言并生成语言，那它们之间为什么不能对话？一旦实现对话，数据就相当于打通了。我觉得8个月内我们可能就能看到类似的应用出现。</p><p><strong>王煜全：</strong>其实并不难想象，各大平台都基于大模型运行，大模型之间已经有了统一的交流语言——token。一个平台输入token，输出token，另一个平台同样也是如此，理论上它们是可以对话的。但问题在于，标准必须足够统一。</p><p>OpenAI的平台本身很有潜力，比如之前的GPT Store，但它的管理经验明显不如App Store。GPT Store只是简单陈列应用，而App Store开放了很多端口。虽然去中心化的App互通未来可能会实现，但我认为短期内仍然是巨头之间的竞争。大模型在应用层面可能带来新的统一标准，这或许是未来的方向。</p><h2><strong>AI硬件的未来：手机仍是核心，还是变数难测</strong></h2><p><strong>总结：短期来看，未来手机将作为管理中心连接各种设备，人工智能的核心是通过规模化提供高端服务，类似于福特通过规模化生产普及汽车。硬件和软件的价值在于有效传递这些服务，而非仅作为简单的工具存在。</strong></p><p><strong>腾讯科技：</strong>手机之后会是AI与物理世界交互的最佳硬件吗？下一代的产品范式会是什么？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_e6a65f8274444aad9567b20b7dde9aa6@46958_oswg233544oswg960oswg629_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：Meta智能眼镜</p><p><strong>王煜全：</strong>关于手机之后的硬件形态，其实很早就开始讨论了。虽然智能时代才刚刚到来，但手机的功能早在之前就已被广泛研究。当时有个流行的概念叫PDA（Personal Digital Assistant，个人数字助理），但我们提出，手机的定位应该更高，叫“个人智能助理”（Personal Intelligent Assistant, PIA），因为它的算力远超传统的数字助理。即便到了今天，这个定义依然适用，手机依然是非常强大的设备。</p><p>我们还提到了“身体局域网”（Body Area Network）的概念，它是指耳机、手表、笔记本电脑等设备通过手机组成的网络。尽管耳机和手表的算力较弱，但它们通过手机这个中心设备进行数据处理和传输。未来，手机可能不再是主要的交互界面，而是管理和处理其他设备的后台中心。交互界面可能会是VR设备或其他外设。<strong>虽然我们携带的设备越来越多样化，但手机作为“个人智能助理”依然是核心。</strong></p><p>在进一步探讨未来时，<strong>人工智能带来的核心能力与工业革命非常相似。工业革命的核心能力是规模化生产复杂产品，如汽车，而智能革命则是规模化提供服务。</strong>以前很多服务只能通过人来提供，但现在人工智能已经可以实现。硬件和软件的价值在于它们传递服务，满足用户需求。如果硬件和软件不能有效传递这些服务，它们的存在就失去了意义。</p><p>以福特汽车为例，1908年福特开始大规模生产汽车，售价仅为950美元，折合今天的价格也不到1万美元。而特斯拉今天还没有能达到这一价格的车。当时福特通过规模化生产降低了制造成本，让汽车变得更加普及。类似地，今天我们追求的目标是通过人工智能规模化提供高端且稀缺的服务，以满足大众需求。<strong>曾经只有人才能提供的服务，现在人工智能也可以做到。而硬件和软件只是这些服务的载体，技术进步是为了更好地传递这些服务</strong>。</p><p><strong>总结：预测未来尤其是在科技领域极其困难，甚至乔布斯也无法完全看清。关键在于行动，不断尝试，并在短期内保持灵活性，而不是试图掌控长期未来。</strong></p><p><strong>李楠：</strong>我见过很多硬件行业的人，他们试图预测未来，用产品去赌。通常一次失败就会损失一个亿人民币，这还只是少数情况。</p><p>事实证明，地球上可能没有人能够看清超过12个月的未来，因为我见过太多中国大佬们栽跟头。</p><p>我曾看过一个有趣的访谈，早期的PDA和智能手机制造商的老板谈到过他和乔布斯的一次会议。当时他们造不出高质量的智能手机，于是去找苹果商谈。乔布斯在会议中间画了一个MacBook的图，然后把各种设备，如音箱、手机等，围绕在它周围。乔布斯说，“你看，你的手机可以加入到这个圈的外围。”但另一人说道，“你错了，手机应该是这个圈的中心。”这个故事告诉我们一个很重要的道理：乔布斯这样的天才在移动互联网变革的早期阶段也未必能看清未来。</p><p><strong>所以，今天如果有人说他可以确定手机依然是未来的中心，这种预言有点超出人的能力范围。不过，我相信现在确实有动摇手机中心地位的机会。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_f6e4a73ddb404f5fa2d28b0c14d0d2e6@46958_oswg304751oswg960oswg647_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此，最重要的不是去预测未来，而是在不让自己失败的前提下多做尝试。或许某个项目在6个月内能赚1.6亿人民币，就像Meta眼镜已经突破了iPhone的销量金线一样。我们应该专注于行动、发布产品，而不是过度预测未来。<strong>能看清12个月的人，几乎是神了。能在6个月内不把自己玩死，就已经很不错了。</strong></p><p><strong>总结：从工业设计的角度，iPhone 16通过4K 120Hz视频拍摄等功能强化了摄影能力，符合当今视频时代的需求。增加拍摄按键体现了“软件定义硬件”，提升了用户体验。</strong></p><p><strong>腾讯科技：</strong>苹果这次发布会上新增了一个控制按键，可以直接使用视觉搜索功能。你们认为这是合理的交互设计吗？为什么在Siri已经可以快捷唤醒的情况下，苹果还要加入这种看起来传统的硬件设计？</p><p><strong>李楠：从乔布斯的设计风格来看，他宁愿去掉所有的按键。</strong>我曾参与过一个获得IF金奖的产品，我们也尽量减少按键设计。</p><p>然而，这次苹果反其道而行之，增加了按键。但我不认为这个设计完全没有道理。从工业设计的角度看<strong>，iPhone 16的最重要升级是4K 120Hz的视频拍摄、实时调整和混音功能。这些增强功能显然是为了强化iPhone在摄影和高质量视频输出上的能力，这正符合当今TVC和Vlog时代的需求。</strong>因此，软件如此强大地加强了这些功能，为此增加一个拍摄按键，让用户更舒适地使用这些功能，是合理的。这是“软件定义硬件”的体现，为用户提供了实际的价值。</p><p>至于它是否与Vision Pro有关系，我个人认为没有太大关联。也许苹果想把它们关联起来，但在我看来，这只是苹果的一厢情愿。<strong>我不觉得Vision Pro有什么实质性的成功，无论从哪个维度看，这款产品都已经失败。没有任何证据能证明它的成功，我作为20年的苹果用户都无法证明它的成功。</strong></p><p><strong>腾讯科技：</strong>或许Vision Pro还在迭代中，未来它的续航和重量可能会改善，如果这些问题解决了，将会有更广泛的应用。</p><p><strong>李楠：</strong>你说的有道理，但这需要苹果展示出“做减法”的能力。我同意未来可能会有改进，<strong>但现在看，苹果在很多产品上并没有展现出足够的减法能力。</strong></p><p><strong>总结：新按键的意义取决于苹果是否有更深层的计划，如果它能启动智能助理功能，按键就有价值。</strong></p><p><strong>王煜全：</strong>我觉得关键在于苹果的下一步动作，目前它的真实意图还不清楚。</p><p>它在大谈Apple Intelligence的同时，展示的应用却显得很小儿科。所以我怀疑是否有后续计划，如果没有后续，这个按键就没有意义；但如果有后续，这个按键可能就有用。</p><p>理论上讲，增加一个按键意味着这个功能会被频繁使用。如果这个按键只是为了摄像，我觉得不应该这么设计，但如果是为了实现视觉智能，比如按下这个键，摄像头不仅打开，还能实时识别物体并启动对话支持，那这个按键就有意义。尤其是如果它能启动一个强大的智能助理功能，那这个按键就变成了助理键，这样的设计是有价值的。</p><p><strong>腾讯科技：</strong>它的多模态功能或许不仅限于拍摄，我想象中的多模态应该是更全面的，不只是按下按钮在框内识别物体，而是像一个随时陪伴在你身边的朋友，甚至不需要唤醒词，只要带着手机，随时就能互动。</p><p><strong>王煜全：</strong>我觉得它还是需要有唤醒机制，随时随地记录你会让人害怕。必须要有一个唤醒信号，让用户明确知道自己启动了互动，并默许设备记录状态。虽然用户可能实际上没有对信息的真正掌控权，但对监管者必须表现出用户拥有控制权的样子。</p><h2><strong>&nbsp;苹果要实现万物皆AI，存在什么问题？</strong></h2><p><strong>腾讯科技：</strong>如果苹果要实现“万物皆AI”，从终端产品、芯片到软硬件结合的生态系统来看，还有哪些难关需要攻克？哪些是现在需要解决的，哪些是未来需要解决的？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_de015886701a43369c1d78443d8555ac@46958_oswg777224oswg960oswg477_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>总结：苹果丧失了激发用户情感的能力，作为消费品牌，它丧失了“One more thing”和“Think different”的能力这可能是它面临的更大难关。</strong></p><p><strong>李楠：</strong>苹果在未来面临的一个明确难关是它与高通的竞争。苹果一直在开发自己的通讯基带，并尝试将其整合到SOC中，虽然不清楚在AI时代是否会改变这一目标，但它已经在这个领域努力了很多年。在中国，很多用户经常吐槽苹果手机的信号问题，这个基带问题确实是苹果多年必须克服的难题。</p><p>除了通讯基带，苹果在端侧模型的技术上还有很大的潜力。苹果有强大的芯片设计能力，能够在硬件层面为端侧模型提供更多支持。我们已经在A18芯片上看到了它在这方面的改进，未来iPhone的端侧模型能力会变得越来越强。</p><p><strong>但我认为苹果面临的另一个更大的问题是，它已经失去了让消费者感到激动的能力。这个问题比技术难题更大。</strong>如今的苹果不再像过去那样能驱动消费者的情感，甚至连发布新产品都不能让用户激动。举个例子，我今天看到华为的三折叠手机，感觉比苹果的发布会更让我激动。</p><p><strong>苹果已经丧失了“one more thing”和“think different”的能力，作为一个消费品牌，它已经不再能引发用户情感的共鸣。这是一个比技术挑战更严重的问题，尤其是在消费领域，购物车添加行为是理性驱动的，但用户在最终付款时是感性驱动的。</strong></p><p><strong>真正的算力革命发生的时刻，苹果最应该找回来的是当年的“Think different。”</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_c1426ef6d29e4bb5bb3217662a720c50@46958_oswg85349oswg960oswg316_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>总结：技术革命的核心在于观念的突破，而苹果当前的Apple Intelligence只是对现有服务的提升，缺乏真正的创新。</strong></p><p><strong>王煜全：说实话，最大的难关是观念问题。历次技术革命的真正引领者往往是观念的革命者。</strong>当年苹果通过iPod彻底颠覆了音乐产业，因为他们根本没把自己当作一个硬件公司。后来iPhone的发布，我印象特别深，乔布斯第一次演讲时说，这是iPod、internet navigator和phone的结合。这种观念上的升级充分展现了苹果的技术优势。</p><p>但现在来看，Apple Intelligence更多的是为苹果的现有服务进行升级，而不是从根本上推动技术革命。我认为这是一个巨大的局限。它还是围绕着如何通过智能技术提升苹果现有的服务，而不是思考如何利用苹果的硬件来支持更广泛的智能化需求。关键的问题应该是，人工智能如何真正帮助人们解决问题，而不是单纯为了提升摄像头等功能。</p><p><strong>软件和硬件都应该为用户需求服务。现在的问题是，苹果并没有展示出真正的新突破。</strong>就拿摄像头为例，如果摄像头能够成为一个契机，扩展手机的功能，那是正确的方向。但如果只是让Apple Intelligence来帮助摄像头，那就是走错了方向。所以，<strong>目前来看，苹果喊了很久的“革命”并没有真正展现出革命性的表现。</strong></p><p>本文来自<a href="https://new.qq.com/rain/a/20240918A08U7X00" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：涵清，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956527005513863</id>
            <title>添可，用创新再造美好家</title>
            <link>https://www.36kr.com/p/2956527005513863</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956527005513863</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 09:00:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>人们对美好生活样貌的定义，写在家居环境的进化历程中。</p><p>随着消费者对家居环境美学与实用的需求不断提升，家庭环境中的美不能只是简单做加减法的拼凑。美是极简的，也是流畅的，不仅需要考虑节约空间的需求，也需要考虑是否方便好用、是否彰显品味。这要求家居环境勾勒师们重新归零，以整体逻辑重新定义家庭的美、温馨和舒适。</p><p>“家居一体化”和“极简”美学风格是新一代美好生活的样貌。几乎所有的家电产品都变得“隐形”，饮水机、洗碗机、消毒柜、冰箱、洗衣机等等，都尝试以“嵌入式”的方式融入家居环境中，与家庭环境成为一个整体，而不再只是简单的堆砌。</p><p>原有的单品模式已经不能满足对新装修的需求，成套化、嵌入式的整体思维带来的实用属性和设计美观度，已经成为众多高端家电品牌的发展趋势。与此同时，家装行业正由新房市场向存量房市场过渡，存量房改造市场规模逐渐扩大。有预测称，到2030年，存量房二次装修市场将突破1000万-1200万套，总的装修需求非常大。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_20a83d3b674f43e386f05ef604787bb8@11416942_oswg4721259oswg4000oswg2666_img_jpeg?x-oss-process=image/quality,q_80/format,jpg/interlace,1" /></p><p>这为嵌入式家居带来更大市场想象力，也意味着更多具备创新性的嵌入式家居产品，走进家庭中。9月19日，高端智能生活电器品牌添可召开秋季新品发布会，发布空间站最新产品芙万Art Station智能洗地机、芙万Artist系列智能洗地机产品，以家居设计市场作为切口，将洗地机与家居空间融合。基于对家居环境的理解，添可正在尝试以整体思路提升整体家的美感，包括本次发布会中，首次面向消费者的饮万水纪元智能净热冷一体机，也从单品的层面融入家居美学设计，均是对于美好家庭的再定义。</p><h2><strong>01 成套化、嵌入化，给家居环境创造美</strong></h2><p>在中国市场买家电，从来都不缺好的单品。从产品角度满足消费者基础功能性需求，并展现良好的设计理念，足以走进万千家庭。然而，正因品牌众多，很多家庭明明拥有“高价装修与高端家电”，却无法摆脱“凌乱和廉价的家居环境视觉感官”。</p><p>根源在于，更多家庭环境中选择的家电产品，还是处于来自不同品牌、各种外观设计的“堆叠”。因此，在单品过多，成散装、拼凑形态的家居环境，需要一个解法，嵌入式或将是新装家庭需求的绝佳优选。</p><p>市场研究机构GFK也指出，占比72%的一线城市受访者表示考虑购买成套家电，这意味着成套化、嵌入化的家电，已经成为中国家电的确定性演进方向。其中，高端市场是当下行业的机遇所在。GFK在报告中指出，高端用户更愿意为美好生活支付更高的产品溢价，是中国家电市场存在的重要“结构性机会”。存量房改造趋势下，市场和用户的需求分化将会更为明显，高端用户对生活品质要求提升将会走在最前面，这也是家电企业不落于人后的必选项。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_b248391cc3d54fd78f45b1fdd5709265@11416942_oswg407875oswg1143oswg631_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p><p>因此，消费者对当下家电产品的需求，首先要做到好用，其次则是能够作为家庭的时尚单品。</p><p>对于洗地机发明者的添可来说，产品力是最简单的基础题。以添可本次发布的空间站最新产品芙万Art Station为例，从其清洁能力构造的细致程度，就可见创作者对用户需求的细致洞察。&nbsp;</p><p>芙万Art Station的细致在于构建了空间感，并不只是着眼于地面，而是让洗地机和地面两个主体都做到干净，其构建出的清洁空间也能做到真正干净。</p><p>据添可介绍，其搭载的“前置多层捕获0缠毛”技术，抓毛钢齿采用航空级磁力研磨工艺，可彻底解决毛发缠绕问题；面对洗地机停机后总会残留水渍的行业难题，芙万Art Station轻松上演水渍“消失术”，每次清洁结束后机身自动回退，同时持续劲吸，消除洗地机停机刹那带来的水回流，清洁全程无水渍，解决了一直以来所面临的行业难题。&nbsp;</p><p>真实使用场景中，也做到了足够便捷。添可创造性将陀螺仪运用于洗地机，毫秒级检测洗地姿态和扭转角度，更灵活、更稳定、更可靠。中央智驱全向扭转，AI感应洗地力道与扭转角度，实时精算匹配力度。内置电机驱动小轮旋转，实现了全向丝滑助力。</p><p>更为重要的是，芙万Art Station洗地机开创了0.1㎡集成清洁中心，从前端装修开始，以一体化思路解决地面清洁问题，重新定义了空间站产品的新标准。</p><p>装修前，先预留好三通管道和清洁中心位置，让洗地机完美融合进家装空间。将空间站连接龙头/角阀，芙万Art Station可自动检测清水箱状态，缺水即补，未满即补满；拖地后，洗地机中的污水通过空间站自动排污至住宅排污管/地漏；污水排空后，空间站对污水桶内部进行深度冲洗，从排污到清洗一气呵成。</p><p>其实，对于基站式洗地机，维护基站是用户经常面临的难题，很多市面上能够上下水的洗地机多需要用户手动清理污水箱，基站容易藏污纳垢、产生异味。添可首创了模拟洗碗机的净洗三重奏，包括预洗-精洗-自洁三个步骤，能够实现从外到内的全站深度自清洁。</p><p>占地0.1平方米，能够实现自动加水、自动添加清洁液、自动排污、热水自清洁、冲洗污水桶、高温全链速干、充电、除菌、智能人机交互8大功能于一体，真正做到了“拿起即用，放下即净”的全托管式清洁体验。</p><p>芙万Art Station洗地机自主研发的洗地机前装创新模式，满足了用户对清洁体验的极致需求，更为重要的是，能成为家的时尚单品，作为家的一部分，为家庭创造了更多的美感。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_19a9079f332b4bebbdfddfd4d2662ba0@11416942_oswg4195340oswg2308oswg1378_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1" /></p><p>据悉，芙万Art Station设计灵感来自古人“天圆地方”的智慧。方圆互融之间，激发和谐美感。方，则严谨有序；圆，则灵动圆满。方圆共进，空间动静皆宜，生活顺遂美满。占地仅0.1㎡的情况下，能够完美嵌入各种家居环境，严丝合缝，和谐共生，构建了融合进家庭环境的清洁空间，正如小小方圆，即囊括宇宙万物。无论是古典雅致风，还是现代简约风，芙万Art Station都能与之相得益彰，共同演绎出中式家庭独有的和谐之道。</p><p>更重要的是，本次发布会，也是添可联合家居市场的一场启动。利用空间站洗地机自带的前装需求属性，联合设计师、切入前装渠道，给新装修家庭的智能家居消费者多了一种选择。这也意味着添可再一次打开集成清洁中心新赛道，也自我突破性的走向前装市场中。</p><h2><strong>02 用创新，再造美好家</strong></h2><p>事实上，洗地机行业当前已进入白热化竞争，众多品牌纷纷入局。</p><p>入局者众的直接变现是行业快速增长的势头之一。奥维云网（AVC）线上监测数据显示，洗地机成清洁电器最大增长动力，销额同比增长达到22%；2023年，洗地机产品全球销量已超过140万台，同比增长超过100%。</p><p>然而，快速增长的过程中，产品已经呈现同质化竞争，功能上，多数洗地机都具备吸拖一体、自清洁等功能，呈现了洗地机功能、外观等方面的相似性。</p><p>那么，不想在红海中囿于内卷的桎梏，唯一的方法就是不断突破，以真创新的方式开创蓝海赛道。这也是添可长期以来在做的事。</p><p>2020年，添可首发第一台智能洗地机，进一步推动了中国乃至全球家庭的地面清洁方式的革新。这一年，洗地机快速占据了整个家电清洁品类18.7%的市场份额，并成为后一年清洁电器中增长最快的品类之一。</p><p>随后，添可不断更新对洗地机的可能性，包括全能洗地机“空间站”、让洗地机变得轻松而高效、通过智能化的方式链接了机器与环境之间的关系等等，回望过去添可品牌的发展之路，几乎就是洗地机的进化史，可以看到添可不断自我推翻的过程，这也是添可能够处于行业第一梯队和灵感来源的原因。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ad1af408bb51475ba3a3eb430e621edc@11416942_oswg2067081oswg3631oswg2420_img_jpg?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p><p>时至今日，添可仍在坚持不断优化、迭代洗地机，以满足消费者多元的需求。比如，本次发布会中，新品芙万Artist 系列智能洗地机搭载添可最新洗地科技，可以说是拥有添可硬核顶配。</p><p>功能上，Artist 系列拥有18000pa的飓风吸力，同时搭载添可首创*6250mAh超大软包电池的智能洗地机，搭配大容量的清、污水箱，拥有75min的超长续航，可以一气呵成完成400㎡的全屋清洁，即使是别墅、大平层也无需反复倒水、补水。</p><p>此外，添可还创研了超级充电站，让芙万Artist 70的充电速度提升2倍，大幅节省了用户的等待时间。</p><p>美学设计上看，芙万Artist系列设计灵感来自北极光，月岩灰、天际蓝、星云紫的配色承袭天地自然之韵，浑然天成。AI极光灯灵动变频，IMD水晶层炫色微光，更增添了未来感十足的科技光彩，能够优雅地融入家中的每一个角落，成为随心所欲的家居点睛之笔。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_1e9e6f4b559547a5ae5b81ad4164fc2f@11416942_oswg5660788oswg2470oswg1372_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1" /></p><p>本次全新发布的空间站最新产品芙万Art Station，与家居空间融合，强调美学与配套性，或将是添可首创、自我颠覆的又一次历史性突破。</p><p>毫无疑问，能经受住时间洗礼的伟大品牌，都是敢于自我颠覆的破局者。不仅要引领整个行业的审美取向，还要在长跑中长期赢得胜利，其本质正在于源源不断的创新力。</p><p>本次发布会中，添可再造了对家庭美学的畅想。除芙万外，添可也在更多家庭场景中发挥力量，如此次添可食万智能料理机就与华为云盘古大模型合作，华为云盘古大模型在持续优化添可食万用户烹饪体验的同时，也将帮助食万升级智能设备、优化烹饪能力，实现“大厨技能家庭化”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_5361b7685e5547bda8fdfee827dfbeed@11416942_oswg142126oswg1600oswg1066_img_jpeg?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p><p>食万智能料理机并非只是智能硬件，通过烹饪数据化以及美味标准化建设，其拥有了一个“智慧大脑”，能够1:1复刻大厨技能，实现自动投料、智能翻炒、智能温控等，让烹饪从“农业经验”转化为“工业模式”，这加速了中餐数字标准化的进程，也意味着智能烹饪将拉开新的篇章。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_79778a728e43482b872cf95f4a18e68a@11416942_oswg214994oswg1600oswg1066_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p><p>今年7月，添可在官方视频号上更新了一条名为“对手”的品牌故事片。视频开篇提及，六年来，添可一直都在面对同一个对手，而这个对手，就是添可自己。无论是洗地机层面的破圈新市场，还是食万+华为云盘古大模型等更多品类的创新，都是添可不断自我突破的表现。</p><p>而自我突破，才是一家创新型科技公司应有的样子，也是深度洞察消费者需求的结果。</p><p>添可在视频末尾这样说，“六年来，我们一直在做自己的对手。不断交出专业创新、脚踏实地的产品，再把它们，交给身边更多相信专业的，你的手里。直到那些你生活里的对手，都不再是你的对手。”无数次推翻重构、在红海里找蓝海，常以破局者姿态勇立潮头的添可，又一次拥抱了新阶段的自己——也是永远的对手。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956582197698437</id>
            <title>微软联合贝莱德推300亿美元AI基金，将投数据中心和能源</title>
            <link>https://www.36kr.com/p/2956582197698437</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956582197698437</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 08:46:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_ccaef80fc23b425f8f1211c7f051d7a9@453363432_oswg73477oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智东西9月18日消息，据《金融时报》今日报道，全球最大资产管理公司之一的贝莱德（BlackRock）准备与美国科技巨头微软等公司联合推出一项超过300亿美元的AI投资基金，用于投资数据中心和能源项目，以满足AI日益增长的需求。</p><p>该基金名为全球AI基础设施投资伙伴关系（Global AI Infrastructure Investment Partnership，以下简称“GAIIP”），旨在吸引300亿美元的私募股权投资，并利用这些资金支持最高达700亿美元的债务融资。它将成为华尔街有史以来规模最大的投资基金之一。</p><p>贝莱德的前身是‌黑石集团（Blackstone Group）金融资产管理部门（Blackstone Financial Management），该部门于1992年从黑石集团独立出来，并更名为贝莱德（BlackRock）。目前是全球规模最大的资产管理集团之一。</p><p>今年1月，贝莱德同意以125亿美元收购基础设施投资公司Global Infrastructure Partners（以下简称“GIP”）。这笔收购将于10月完成，之后贝莱德会把GIP与现有的基础设施团队结合起来。</p><p>GAIIP基金由贝莱德和GIP共同发起。微软和阿联酋阿布扎比支持的投资公司MGX是GAIIP基金的普通合伙人，而发展迅速的美国芯片制造商英伟达将在数据中心设计和整合方面提供专业咨询。</p><p>GAIIP基金旨在应对构建AI产品所带来的巨大电力和数字基础设施需求。预计在未来几年内，AI产品将面临严重的能源瓶颈。AI所需的计算资源比以往的技术创新需要更多的能源，并已对现有的能源基础设施造成了压力。</p><p>贝莱德已将能源部门列为其增长的主要机遇之一。“动员私人资本建设数据中心和电力等AI基础设施，将释放数万亿美元的长期投资机会，”贝莱德CEO拉里·芬克（Larry Fink）谈道。&nbsp;</p><p>2017年，贝莱德宣布计划与沙特阿拉伯共同设立400亿美元的基础设施基金。而布鲁克菲尔德去年筹集了280亿美元，设立了2023年之前规模最大的基础设施基金。</p><p>今年早些时候，微软同意支持加拿大布鲁克菲尔德资产管理公司（Brookfield Asset Management）建设的100亿美元可再生能源电力项目。微软已承诺到2030年确保其100%的能源消耗与零碳能源采购相匹配。</p><p>“国家和世界将需要更多的资本投资来加速发展所需的AI基础设施。这种努力是重要的一步，”微软总裁布拉德·史密斯（Brad Smith）说道。</p><p>来源：《金融时报》</p><p>本文来自微信公众号“智东西”（ID：zhidxcom），作者：吴浪娜，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956502020939655</id>
            <title>阿里集团CEO吴泳铭：AI最大的想象力在于改变物理世界</title>
            <link>https://www.36kr.com/p/2956502020939655</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956502020939655</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 08:42:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>刚刚，阿里巴巴集团CEO、阿里云智能集团董事长兼CEO吴泳铭在2024云栖大会上发表主题演讲——</strong></p><p>“&nbsp;<strong>过去22个月，AI发展速度超过任何历史时期，但我们依然还处于AGI变革的早期。生成式AI最大的想象力，绝不是在手机屏幕上做一两个新的超级app，而是接管数字世界，改变物理世界。</strong>”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_f334c8f045c04c689ab14c86bb220fa5@5956492_oswg44925oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以下为演讲全文：</p><p>欢迎来到2024云栖大会。今天，云栖大会的焦点也是AI。我主要分享三点内容：<strong>第一，过去22个月，AI发展的速度超过任何历史时期，但我们现在依然还处于AGI变革的早期阶段。</strong></p><p><strong>大模型技术快速迭代，技术可用性大幅提升。</strong>大模型已经具备了文本、语音、视觉的多模态能力，能够开始完成复杂指令。去年，大模型还只能帮助程序员写简单的代码，今天已经能直接理解需求，完成复杂的编程任务。去年，大模型的数学能力还只有中学生水平，今天已达到国际奥赛金牌水平，并在物理、化学、生物等多方面学科接近博士水平。</p><p><strong>同时，模型推理成本指数级下降，已经远远超过摩尔定律。</strong>一年来，通义千问API在阿里云百炼上的调用价格下降了97%，百万Tokens调用花费最低已经降到了5毛钱。推理成本是应用爆发的关键问题，阿里云会努力把成本继续降下去。</p><p><strong>开源生态蓬勃发展。</strong>今年6月，通义千问开源Qwen2，迅速登顶Huggingface的全球开源模型排行榜。在Huggingface上，Qwen的原生和衍生模型接近5万个，排名全球第二。阿里云魔搭社区上有超过1万个模型、服务了超过690万开发者。</p><p>这一切才刚刚开始，要实现真正的AGI，下一代模型需要具备更大规模、更通用、更泛化的知识体系，同时也将具备更复杂更多层次的逻辑推理能力。<strong>全世界先进模型竞争的投入门槛，将达到数十亿、数百亿美金的级别。</strong>AI具备创造能力、帮助人类解决复杂问题的路径清晰可见，也打开了AI在各行业场景中广泛应用的可能性。</p><p><strong>第二，AI最大的想象力不在手机屏幕，而是接管数字世界，改变物理世界。</strong></p><p>今天很多行业内人士一直在想AI最大的应用是什么，可能一直在想手机上有什么AI时代创新的超级APP。<strong>但我们认为AI最大的想象力绝对不是在手机屏幕上，AI最大的想象力是在通过渗透数字世界、接管数字世界，并改变物理世界，这才是AI最大的想象力。</strong></p><p>我们不能只停在移动互联网的视角看未来。生成式AI最大的想象力，绝不是在手机屏幕上做一两个新的超级app，而是接管数字世界，改变物理世界。过去三十年，互联网浪潮的本质是连接，互联网连接了人、信息、商业和工厂，通过连接提高了世界的协作效率，创造了巨大的价值，改变了人们的生活方式。但生成式AI是通过生产力的供给创造了新的价值，从而为世界创造了更大的内在价值，也就是总体提高了整个世界的生产力水平。<strong>这种价值创造，可能是移动互联网连接价值的十倍、几十倍。</strong></p><p>我们认为<strong>生成式AI将逐渐渗透数字世界，并接管数字世界，物理世界的大部分事物都会具备AI能力，形成下一代的具备AI能力的全新产品，并与云端AI驱动的数字世界连接产生协同效应。</strong></p><p>很长一段时间，AI的焦点主要集中在模拟人类的感知能力，比如自然语言理解、语音识别、视觉识别。但是生成式AI的崛起，带来了质的飞跃，AI不再仅仅局限于感知，而是首次展现了思考推理和创造的力量。</p><p>生成式AI让世界有了一个统一的语言——Token。它可以是任何文字、代码、图像、视频、声音，或者是人类千百年来的思考。AI模型可以通过对物理世界数据的Token化，理解真实世界的方方面面，比如人类行走、奔跑、驾驶车辆、使用工具，绘画、作曲、写作、表达、教学、编程的技巧，甚至是开公司创业。理解之后，AI就可以模仿人类去执行物理世界的任务。这将带来新的产业革命。</p><p>我们看到，汽车行业正在发生这样的变革。之前的自动驾驶技术，是靠人来写算法规则，几十万行代码，仍然无法穷尽所有的驾驶场景。采用“端到端”的大模型技术训练后，AI模型直接学习海量人类驾驶视觉数据，让汽车具备了超越大部分司机的驾驶能力。</p><p>机器人将是下一个迎来巨变的行业。未来，所有能移动的物体都会变成智能机器人。它可以是工厂里的机械臂、工地里的起重机、仓库里的搬运工、救火现场的消防员、包括家庭里的宠物狗、保姆、助理。</p><p>未来，工厂里会有很多机器人，在AI大模型的指挥下，生产机器人。现在<strong>每个城市家庭里有一辆或者两辆车，未来每个家庭可能会有两三个机器人，帮助人们提升生活当中的效率。</strong></p><p><strong>可以想见，AI驱动的数字世界连接着具备AI能力的物理世界，将会大幅提升整个世界的生产力，对物理世界的运行效率产生革命性的影响。</strong></p><p><strong>第三，AI计算正在加速演进，成为计算体系的主导。</strong></p><p>无论是我们看到端侧的计算，还是云端的世界，这都是一个非常明显的趋势。生成式AI对数字世界和物理世界的重构，将带来计算架构的根本性变化。过去几十年，CPU主导的计算体系，正在加速向GPU主导的AI计算体系转移。<strong>未来几乎所有的软硬件都会具备推理能力，它们的计算内核将变成GPU AI算力为主、CPU传统计算为辅的计算模式。</strong></p><p>我们看到，<strong>在新增算力市场上，超过50%的新需求由AI驱动产生，AI算力需求已经占据主流地位。</strong>这一趋势还会持续扩大。过去一年，阿里云投资新建了大量的AI算力，但还是远远不能满足客户的旺盛需求。</p><p>今天我们接触到的所有客户、所有开发者、所有CTO，几乎都在用AI重构自己的产品。<strong>大量新增需求正在由GPU算力驱动，大量存量应用也在用GPU重新改写。</strong>在汽车、生物医药、工业仿真、气象预测、教育、企业软件、移动APP、游戏等行业，A</p><p>计算正在加速渗透。在各行各业，看不见的新产业革命正在悄然演进。</p><p>所有行业，都需要性能更强、规模更大、更适应AI需求的基础设施。</p><p>阿里云正在以前所未有的强度投入AI技术研发和基础设施建设。我们的单网络集群已拓展至十万卡级别，正在从芯片、服务器、网络、存储到散热、供电、数据中心等方方面面，重新打造面向未来的AI先进基础设施。</p><p>从历史经验来看，人们对新技术革命，往往对短期高估，又对长期低估。因为在新技术应用早期，渗透率还比较低，人们经验没有发生过此类事件，大部分人的本能会产生怀疑，这很正常。<strong>但新技术革命会在人们的怀疑中成长，让很多人在迟疑中错过。</strong>站在AI时代浪潮的开端，我感到无比兴奋。今天，我们请到大模型、自动驾驶和机器人三个领域的企业家和科学家。他们正在飞奔着用AI重构我们的世界，期待他们的精彩分享。</p><p>谢谢大家。希望大家度过一个充实、愉快的云栖。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/l-jp3acu3cUS_SZkwjha5Q" rel="noopener noreferrer nofollow" target="_blank">“蓝鲨硬科技”</a>，作者：吴泳铭，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956630288381832</id>
            <title>AI“缝”搜索</title>
            <link>https://www.36kr.com/p/2956630288381832</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956630288381832</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 08:38:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>下半年，搜索领域变得热闹起来。</p><p>8月27日，夸克发布全新PC端，整合AI搜索、AI写作、AI PPT、AI文件总结等功能。差不多同一时间，字节继头条搜索、悟空搜索、闪电搜索之后，在移动市场上线“抖音搜索”App，第四次把脚踏入了搜索的“河”。9月4日，百度推出新搜索“文小言”，融合一系列能力后，提供“搜创聊”的体验。</p><p>三家动作各不相同，夸克希望补全在PC端的能力，赶上AIPC风口；字节则希望完善搜推一体化，巩固自身内容生态；百度则希望让文小言成为探索搜索4.0时代的“先锋”，提前卡位。如果把视线放到整个搜索领域，抖音、视频号在搜索框新增电商入口，这门古早的生意，又变得热闹起来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_04e1eb12400f47ed8fa0432007d0bae1@000000_oswg42258oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>百度副总裁、AI创新业务负责人薛苏认为，传统搜索与AI搜索有三个不同。一个是支撑技术上，AI搜索的底层是生成式大模型；其次是场景与需求差异，传统搜索用排序方式解决需求，而AI搜索则是用生成式方法；再次是在产品理念与定位上，存在工具性与人性的差异。</p><p>实际上，目前领跑“AI搜索”的大厂们，对于技术本身要保守得多。由于RAG与搜索的亲缘性，主导着当下国内AI应用开发。然而，OpenAI最近发布的新系列模型，为行业提供了新的参考：o1两个版本专注在推理上，不再通过prompt完成CoT（思维链），而是使用强化学习，执行链式思考。</p><p>即便学术界已在今年开始讨论RAT（RAG+CoT）的可行性，但国内巨头似乎还未将重心放在这里，反而更具现实主义地押注生态。相较而言，初创公司所面对的挑战要艰难得多，没有巨头那么多花式各样的“缝补布料”（生态），有且只有一身蛮力。</p><p>移动时代的老巨头们依托于生态优势，试图打通端与端、应用与应用、内容形式的隔阂——试图摆脱搜索框的束缚，从而在下个时代来临前，为通用搜索上竖起“盾”。而Kimi、智谱、MiniMax，则长袖善舞，想要找到更垂直的领域，完成数据的输入与输出，比如想尽办法附着在搜索框中。</p><p>眼下，搜索框成了钱钟书的“围城”，有人想打破，有人却在死命朝里钻。</p><h2><strong>构建、补全、重塑</strong></h2><p>分类目录、文本检索、整合分析、用户中心、生活生态圈，被归类为搜索的五个发展阶段。</p><p>五个发展阶段的确存在代际之分，但不是今是昨非。分类目录仍然在各应用中普遍存在，文本检索依然是爱如生古籍库这些文史类专用数据库中最基础的搜索形态，当下主流搜索市场仍以整合分析为主，至于用户中心与生活生态圈，还有待AI技术与端侧成熟。</p><p>去年以来，百度、阿里（夸克）、字节、360等传统搜索引擎厂商都推出了各自号称“AI搜索”的产品，实际上都只是完成了搜索AI化改造中的部分环节，包括结果上的智能化排序、推荐、关键词解析等。</p><p>无论字节完善搜推一体化，还是夸克补全PC端，抑或是百度推出“新搜索”，都表明巨头们视搜索为打开商业生态的一把“钥匙”。这便是字节始终不愿放弃搜索的核心原因，也恰好证明搜索本身在AI时代的重要战略价值。毕竟，学习和搜索是唯二的能够无限scaling计算能力，简单来说，因为豆包与内容生态的存在，字节不缺学习，缺的只有搜索。</p><p>而在搜索的AI化改造过程中，通用搜索至少面临着两重挑战，第一个来自端侧。</p><p>日前国内一家半导体公司表示，作为新业务板块，今年AI芯片市场的需求井喷，且大客户集中在国内互联网巨头。而Canalys日前发布的数据显示，处于中游的联想，其AIPC第二季度出货量环比增长228%。PC端之所以率先起量的核心原因，是办公智能化推动。因此，夸克8月末升级后，完成了移动端与PC端的布局，并上线了多种面向办公场景的功能，初步坐上了牌桌。</p><p>互联网公司推出适配端的产品，并不意味着AI搜索往后是一片坦途，在端的调用权限仍然在硬件厂商手中。早前，苹果在Apple Intelligence的发布会上，展现了一家硬件厂商如何通过端侧内置全系统调用工具，提供新的用户体验，甚至连第三方应用也得配合，显示出封闭生态下的硬件厂商，会更有主导权。</p><p>第二重考验是打破以移动App为首的信息孤岛，解决内容、场景、知识垂类间的隔阂。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_40164474008b4fb7b12f1abc196673d0@000000_oswg27115oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>阿里与腾讯在几个月时间内，先后打通了信息流（微信广告跳转淘宝天猫）与资金流（淘天接入微信支付），巨头间正在拆除藩篱。这一背景，对于通用AI搜索而言是一大利好。</p><p>百度在“文小言”的发布会上呈现了多种类搜索的探索，包括对话框式的传统搜索、交互式的AI助手、自主专题订阅，以及涉及到图文视频等媒介下的搜索等。传统订阅机制以App、内容平台为核心，例如微信公众号订阅。而文小言的“自由订阅”则呈现了“需求导向”的特点，例如按照关键词订阅，从而可以跨App与内容平台。</p><p>尽管“文小言”算得上是目前通用AI搜索最大胆的尝试，但从内容、产品、场景等层面来看仍有诸多挑战。</p><p>内容上，百度既有生态占比权重非常高，其他巨头的内容权重占比很低。产品方面，经历移动时代规训的用户，能否适应各种AI原生的交互形式，还有待观察。前文提到的“自由订阅”并没有在文小言界面中呈现，而是需要在与AI助手对话中才能实现。</p><h2><strong>追逐、聚合、突围</strong></h2><p>“AI时代的超级应用，大概率会是一个AI助理”。诚如月暗杨植麟在最近的采访中所言，比起随时会被超越的大模型，现阶段资本和AI巨头更愿意把赌注压在看得见产品和增长的AI助手上。</p><p>OpenAI是指引的灯塔，AI助手成为了各家“秀肌肉”的窗口，从Sora到GPT-4o，凡是被OpenAI“鸽掉”的功能都被聚合在了国内的AI助手中。于是，在一个看似平平无奇的App中，同时可以验收大模型训练、推理、长文本、多模态、Agent等多项技术成果。</p><p>智谱把对话、AI生图、AI生视频、AI视频通话等统统打包进了智谱清言中，Minimax同样把对话、语音、AI生图、AI生视频、AI生音乐等功能内嵌入海螺AI当中。</p><p>追逐最前沿的技术，以此与传统的大厂作出区隔，成为了AI头部创业公司的选择。毕竟OpenAI式的叙事极具诱惑，据媒体报道，OpenAI正在洽谈新一轮融资，其估值达到了1500亿美元，对比中国大模型公司目前30亿美元的最高估值，差距相当于50个智谱和月暗。</p><p>大厂高调谈AI搜索，而AI公司却缄默不语，只是在其应用内部悄悄上线“联网”或“AI搜索”相关功能。一方面，国内的AI公司将AGI奉为圭臬，不愿意被贴上“AI搜索”的标签，像“Perplexity”一样把路走窄；另一方面，也暴露出其被互联网巨头围剿的困境。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_d284e6f87f074b689d49792a1346d0b8@000000_oswg31054oswg1080oswg771_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>阿里、百度、腾讯之长，恰恰是AI公司之劣势。内容、产品、场景、生态，大厂均已提前锁定，反观AI公司产品尚未成熟就被迫推向市场，宛如一个个“打黑工”的童工。智谱、月暗、Minimax等声称的“联网”与“AI搜索”本质上还是在“爬数据”，只不过内化为生成问答的步骤之一。上述的“爬”绕不过互联网大厂的生态藩篱，这意味着如果某厂拒绝向AI公司开放链接，那就有一定概率影响最后回答质量。</p><p>这过程中还存在一个问题，即缺乏场景支撑的搜索问答更加容易出现幻觉和泛化问题。假设将AI搜索和问答锁定在电商领域，就会自然划分出种草、交易、售后易等几个细分场景，无论是AI搜索还是数据反馈都能更加精准对应，如此迭代下来，远比毫无目的的搜索对话效果更强。当用户打开Kimi、海螺AI时，他们是茫然的，大部分人可能还得思考几秒提什么问题，但打开淘宝，用户的搜索是相对明确的。</p><p>为此，市面的AI助手都不约而同地弱化了“搜索”的标签。为了能建立集中获取数据反馈的渠道，在互联网大厂的地盘上，这些AI公司也只能低头，双手奉上投流“过路费”。为了解决问答不够垂和专，弥补场景缺陷，AI公司也在尝试通过专家数据标注和用户数据分类收集、处理等方式来解决。</p><p>每一次新技术升级和产品推出都能引发圈内的一次狂欢，帷幕落下，尚未有明确的数据证明带来了直接的用户或商业转化。靠资本去治疗AI公司的先天体弱，到底还能支撑多久？</p><h2><strong>CoT再次定义AI搜索</strong></h2><p>时至今日，国内市场对AI助手的期待经历了“Copilot辅助”“效率工具”再到“Super App”的转变，其所承载的意义早已超过了本身。</p><p>从上文的描述中不难发现，围绕着AI助手和AI搜索，互联网大厂的思路是跳出“框”，进而去补足和强化生态体系；AI公司则在入“框”，把对话框视为与用户交互和反馈最有价值的渠道。</p><p>到现在，AI搜索在技术方面已经没有壁垒，模型推理能力的不足靠RAG缝缝补补，大厂和AI公司也能交出一份差强人意的答卷。对未来AI搜索发展可能会涉及几个方面：跨端、跨场景、跨数据、主动适应、自然语言唤起、多轮对话以及多步推理。</p><p>近期，OpenAI发布o1，将此前普遍运用于Agent训练的CoT技术自动化，实现模型的自我理解和进化，标志着大模型推理能力迈上新台阶。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_0ca5c9e67a664f78ba50abcc546a2d03@000000_oswg180437oswg690oswg388_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从RAG到CoT，也将开启了AI搜索的新时代。CoT的本质是将复杂问题切分为若干个简单执行任务，重推理而弱化了搜索色彩，最后导向的方向是既垂直又精专。</p><p>OpenAI已经落子，国内大概率要follow。CoT就像给AI搜索再次开启了“加速器”，会进一步明晰化大厂与AI公司的分野。</p><p>对强技术而弱搜索生态的AI公司不失为一个好消息，从整体上提升模型推理能力，搜索和强化学习机制内化，不过多地展示过程和呈现参考资料，直接解决问题。毕竟，AI助手内的参考资料引用明为“提高准确率”，实则是给推理能力不足的大模型“开外挂”。</p><p>互联网大厂的落地在垂直场景中，“CoT自动化+Agent”也许是下一个“黄金拍档”，先理解、推理与制定计划，再由Agent执行。在娱乐、电商、社交等场景，既能简化跳转步骤，减少流程，还能直接替代用户上手操作。</p><p>短期内，AI搜索的产品形式不会有太大变化，但是速度和效果将会提升一个level，唯一需要考虑的因素是推理成本。</p><p>AI搜索是否需要以一个独立的产品存在值得商榷，毕竟国内已经有无数多的场景和产品可以嵌入。包括新生代的AI助手，如何与旧业务和产品融合打通，怎么在新场景中发挥其功能，可能才是众多玩家关注的重点。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA4MjUxODMwMg==&amp;mid=2649658882&amp;idx=1&amp;sn=68a3f46c557fbde9bd1c008824ad608a&amp;chksm=86f7b5c1258527328e1f448797bddd21e19a17a04ebdbed2f9d6f8155b755bea731880f917b3&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“guangzi0088”（ID：TMTweb）</a>，作者：郝鑫 吴先之，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2956684281084035</id>
            <title>内部数百工程师可随意摄取 OpenAI 先进模型，OpenAI 前员工揭露：谏言即被开除，祈祷公司不报复</title>
            <link>https://www.36kr.com/p/2956684281084035</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2956684281084035</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Sep 2024 08:32:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240919/v2_10b4d4635a8e43c686775e31a0cfcc54@46958_oswg36061oswg640oswg402_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就在 OpenAI 新模型发布不久还被广泛赞誉的时候，OpenAI 举报人对其悄悄“背刺一刀”。</p><p>“我在 OpenAI 工作期间，运营体系有很长一段时间都存在漏洞，这些漏洞可能允许我或者公司内的其他数百名工程师绕过访问控制、窃取包括 GPT-4 在内的最先进 AI 系统。”OpenAI 举报人 William Saunders 在近日参加的一场关于人工智能监管的听证会上说道。</p><p>去年年初，一名黑客入侵了 OpenAI 的内部消息系统，并窃取了该公司 AI 技术设计的详细信息。这件事大家是最近才知道的。OpenAI 高管于 2023 年 4 月在公司旧金山办公室举行的全体会议上向员工透露了这一事件，并通知了董事会。但高管们决定不对外公开这一消息，因为没有关于客户或合作伙伴的信息被窃取。另外高管层也认为这与所谓国家安全没有关系，因为他们相信黑客是一名个人，与外国政府没有联系。</p><p>Saunders 在过去三年，一直担任 OpenAI 公司的技术人员。“OpenAI 一直强调自己正在进步，但我和其他已经辞职的员工都怀疑他们能不能跟得上发展的节奏。”Saunders 说道。</p><p>他以 OpenAI 最新模型 o1 为例称，这是首个向着生物武器风险迈进的系统，因为它能够帮助专家规划并重现已知的生物威胁。“如果不是经过了严格测试，o1 项目的开发者很可能忽略掉这种危险的能力。虽然 OpenAI 率先开展了相关测试，但公司的总体思路仍然是以部署为优先、而非以严格监管为优先。因此我认为，OpenAI 确实有可能遗漏未来 AI 系统当中某些重要的危险能力。”</p><p>“我之所以从 OpenAI 辞职，是因为我不再相信他们会以负责任的态度制定 AGI 相关决策。”看得出来，他抨击的 OpenAI 不止不关心 AI 安全，自家的安全也是一点都不担心。</p><h2><strong>批评 OpenAI，是要被“惩罚”的&nbsp;</strong></h2><p>今年 6 月有媒体曝出，OpenAI 员工如果想离开公司，将面临大量的、限制性极强的离职文件。如果他们在相对较短的时间内拒绝签字，就可能被威胁失去公司既得股权。这种做法在硅谷并不常见。这项政策迫使离职员工在放弃他们已经赚到的数百万美元和同意不批评公司之间做出选择，而且没有截止日期。</p><p>这一消息在 OpenAI 内部引起了轩然大波。与许多硅谷初创公司一样，OpenAI 的员工通常以股权的形式获得大部分的预期薪酬。员工们往往认为，一旦按照合同中规定的时间表“归属”，这些股权就属于他们了，公司无法收回。</p><p>外媒报道后的第二天，首席执行官 Sam Altman 就发文道歉，总体意思是：我不知道我们有一些威胁公平的条款，我保证我们不会再这样做了。OpenAI 部分高管在公司内部也表达了同样的歉意。OpenAI 首席战略官 Jason Kwon 承认，该规定自 2019 年以来就已实施，但“团队确实在一个月前就发现了这个问题。这么久了才被发现，是我的错。”</p><p>但外媒指出，公司领导层的道歉存在问题。终止文件中的离职信中写道：“如果您拥有任何既得的权益单位…您必须在 60 天内签署一份放弃索赔协议，以便保留这些权益单位。”该协议由 Kwon 和 前 OpenAI 人力副总裁 Diane Yoon 签署。这份秘密的超限制性保密协议仅针对已既得股权的“对价”，由首席运营官 Brad Lightcap 签署。</p><p>用威胁既得股权的方式让前员工签署极其严格的保密协议只是一部分，这里面还涉及更多细节。OpenAI 发出的冗长而复杂的解雇文件有效期只有七天，这意味着前员工只有一周的时间来决定是接受 OpenAI “封杀”，在无限期内无法发声批评 OpenAI，还是承担失去数百万美元的风险。但时间非常紧迫，他们几乎没有时间去寻找外部顾问。</p><p>“我们希望确保你们明白，如果不签署，可能会影响你们的股权。这对每个人来说都是如此，我们只是按规矩办事。”OpenAI 的代表如是说道。</p><p>大多数前员工在压力之下屈服了。对于拒绝签署第一份终止协议并寻求法律顾问的员工，OpenAI 改变了策略：没有说要取消股权，而是说阻止其出售股权。“你必须明白，此外你将没有资格参与未来我们赞助或促成的招标活动或其他流动性机会。”</p><p>此外，公司文件中还包含，“根据公司的全权酌情决定权”，任何被公司解雇员工的既得股权可以减至零。还有条款规定，公司可以全权决定哪些员工可以参与出售其股权的招标要约。</p><h2><strong>解雇一个员工，找个理由就可以&nbsp;</strong></h2><p>可能有人还记得，今年 OpenAI 因涉嫌泄露信息解雇了两名员工，其中一个就是 Leopold Aschenbrenner。Aschenbrenner 后来解释了他为什么会被解雇，并透露了更多细节。</p><p>“去年某个时候，我写了一份关于未来 AGI 道路上需要做的准备、安全和保障措施的头脑风暴文件。我与三位外部研究人员分享了这份文件以征求反馈。这就是泄密的内容。”Aschenbrenner 解释称，“当时在 OpenAI，与外部研究人员分享安全理念以获得反馈是完全正常的。这种情况一直都有。文档中有我的想法。在我分享之前，我审查了它是否有任何敏感内容。内部版本提到了未来的集群，我在外部副本中删去了它。有一些内部 PPT 的链接，但对于外部人员来说，这是一个无效链接。PPT 也没有与他们分享。”OpenAI 给他的回复是“计划在 2027-2028 年实现 AGI”，但公司并未设定准备时间表。</p><p>但这并不是他被解雇的真相，真正的原因是他写了一份关于 OpenAI 安全性内部备忘录并与董事会分享了该备忘录。</p><blockquote><p>去年，我写了一份关于 OpenAI 安全性的内部备忘录，我认为这份备忘录严重不足，无法防止外国参与者窃取模型权重或关键算法机密。我与几位同事和几位领导分享了这份备忘录，他们大多表示这份备忘录很有帮助。</p><p>几周后，发生了一起重大安全事件。这促使我与几位董事会成员分享了这份备忘录。几天后，我清楚地知道，领导层对我与董事会分享这份备忘录非常不满。显然，董事会就安全问题向领导层提出了质问。</p><p>我因与董事会分享备忘录而收到人力资源部门的正式警告。人力资源部的人告诉我，担心间谍活动是种族主义行为，而且没有建设性。我可能没有发挥出最佳外交能力，本可以更精通政治。我认为这是一个非常重要的问题。安全事件让我非常担心。</p><p>我之所以提起这件事，是因为当我被解雇时，他们明确表示安全备忘录是我被解雇的主要原因。他们说：“这是解雇而不是警告，因为这份安全备忘录。”</p></blockquote><p>Aschenbrenner 透露，在被解雇前，他被拉到一边跟律师交谈，但双方很快就对峙了起来。律师问了他对人工智能发展的看法、对 AGI 的看法、AGI 的适当安全级别、政府是否应该参与 AGI、我和超级联盟团队是否忠于公司，以及他在 OpenAI 董事会活动期间做了什么。然后律师还和 Aschenbrenner 的几个同事谈了谈，然后回来告诉就告他被解雇了。“他们查看了我在 OpenAI 工作期间的所有数字文件，然后发现了泄密事件。”</p><p>此外，律师团队还提出了其他几项指控。其中一件是，Aschenbrenner 在调查期间不愿透露与谁分享了头脑风暴文件，他表示自己确实不记得了，只记得曾与一些外部研究人员讨论过这些想法。“这份文件已经有六个多月了，我花了一天的时间研究它。”Aschenbrenner 表示，“它根本就不值得关注，因为它根本不是什么问题。”</p><p>Aschenbrenner 表示，OpenAI 还声称不喜欢他参与政策的方式。</p><p>“他们引用了我曾与几位外部研究人员谈过的观点，即 AGI 将成为政府项目。事实上，我当时正在与该领域的许多人讨论这一观点。我认为这是一件值得思考的重要事情。所以他们找到了我五、六个月前写给一位同事的 DM，他们也引用了这一点。”Aschenbrenner 说道。“我曾认为，与该领域的外部人士讨论有关 AGI 未来的高层问题是符合 OpenAI 规范的。”</p><p>OpenAI 公司内部的其他员工都对这样的事情表示惊讶。</p><blockquote><p>从那时起，我和几十位前同事谈过这件事。他们的普遍反应是“这太疯狂了”。我也感到惊讶。几个月前我才刚刚升职。当时，Ilya 对我升职一事的评论是：“Leopold 太棒了。我们很幸运能拥有他。”&nbsp;</p></blockquote><p>“从某种意义上说，这是合理的。我有时在安全问题上可能很烦人，这惹恼了一些人。我反复提到这一点，也许并不总是以最圆滑的方式提出来的。尽管有压力要求我在董事会活动期间签署员工信，但我并没有签署。”Aschenbrenner。</p><p>Saunders 和其他 OpenAI 员工此前签署了关于“对先进人工智能发出警告的权利”公开信。他们认为，只要政府还没有对 AI 企业施以有效监督，那就只有现任及前任员工来负起责任。然而，广泛的保密协议却阻止了他们表达自身担忧的权利，除非企业主动承认他们无力解决这些问题。”</p><p>Saunders 在听证会上隐隐透露出担心被报复的想法。他表示，“鉴于整个行业的历史上曾经发生过极端情况，我们中有一部分人可能担心受到各种形式的报复。我们并不是第一批遇到、或者决定正视这些问题的人。”</p><p><strong>参考链接：</strong></p><p>https://www.judiciary.senate.gov/imo/media/doc/2024-09-17_pm_-_testimony_-_saunders.pdf</p><p>https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees</p><p>https://www.dwarkeshpatel.com/p/leopold-aschenbrenner?open=false#%C2%A7what-happened-at-openai</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/dzYc1EHoa-gDVFeHoxrLvw" rel="noopener noreferrer nofollow" target="_blank">“AI前线”</a>，整理：褚杏娟 核子可乐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>