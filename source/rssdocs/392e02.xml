<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2498445508974471</id>
            <title>求购小红书、喜茶股份；转让持有Shein份额的基金LP份额｜资情留言板第115期</title>
            <link>https://www.36kr.com/p/2498445508974471</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498445508974471</guid>
            <pubDate></pubDate>
            <updated>Wed, 01 Nov 2023 01:58:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 资情留言板, 交易信息, 买家性质, 交易价格
<br>
<br>
总结: “资情留言板”是36氪推出的新栏目，旨在帮助买卖双方更快速链接市场信息和潜在交易对手。栏目中提供了多个资产求购和资产出让的信息，包括买家性质和交易价格等关键信息。如果对这些交易线索感兴趣，可以通过提供的联系方式进行接触。 </div>
                        <hr>
                    
                    <p>“资情留言板”是36氪推出的新栏目。</p><p>资产交易市场，信息瞬息万变，消息真假难辨，即使买卖双方花费大量的时间、精力，推动成交往往困难重重。为了能够帮助买卖双方更快速链接市场信息和潜在交易对手，避免不必要的投入与浪费，我们特地打造了这样一档栏目。</p><p>本文是这个栏目的第115期，我们汇总了当下市场上的一些资产供需信息。如果你对本文提到的相关的交易线索感兴趣，希望接触这些潜在的交易对手，或者如果你手中直接握有希望交易的资金或者资产，欢迎与我们联系（邮箱：zcjy@36kr.com）。</p><h2><strong>一、 资产求购</strong></h2><h2><strong>1、求购 OpenAI公司股份（预期估值300亿美元）&nbsp;</strong></h2><p>买家性质：直接机构买家&nbsp;</p><p>交易价格：预期估值300亿美元&nbsp;</p><p>交易额度：1000万美元以上需求</p><p>联系方式：zcjy@36kr.com</p><h2><strong>2、求购OpenAI公司股份（预期估值280亿美元）</strong></h2><p>买家性质：直接机构买家</p><p>交易价格：预期估值280亿美元</p><p>交易额度：3000万美元左右需求</p><p>联系方式：zcjy@36kr.com</p><h2><strong>3、求购Neuralink公司股份（预期估值55亿美元）</strong></h2><p>买家性质：直接机构买家&nbsp;</p><p>交易价格：预期估值55亿美元&nbsp;</p><p>交易额度：500万美元需求，要求carry 10%</p><p>联系方式：zcjy@36kr.com</p><h2><strong>4、求购医疗大健康领域的二手份额基金（交易额度1000万-1亿元人民币）</strong></h2><p>买家性质：直接机构买家</p><p>交易价格：以评估价格为准</p><p>交易额度：约1000万至1亿元人民币</p><p>投资偏好：多底层标的基金的部分或全部份额；已进入退出期或投资末期的基金；医疗大健康领域</p><p>联系方式：zcjy@36kr.com</p><h2><strong>5、求购喜茶公司股份（预期估值面谈）</strong></h2><p>买家性质：直接机构买家</p><p>交易价格：预期估值面谈</p><p>交易额度：3000万美元左右需求</p><p>联系方式：zcjy@36kr.com</p><h2><strong>6、求购字节公司股份（预期估值2100亿美元）</strong></h2><p>买家性质：直接机构买家</p><p>交易价格：2100亿美元</p><p>交易额度：5000万美元左右需求</p><p>联系方式：zcjy@36kr.com</p><h2><strong>7、求购Shein公司股份（预期估值600亿美元）</strong></h2><p>买家性质：直接买家</p><p>交易价格：600亿美元</p><p>交易额度：100万美元左右需求</p><p>联系方式：zcjy@36kr.com</p><h2><strong>8、求购菜鸟网络老股（预期估值210亿美元）&nbsp;</strong></h2><p>买家性质：直接买家&nbsp;</p><p>交易价格：预期估值210亿美元&nbsp;</p><p>交易额度：8000万元人民币份额&nbsp;</p><p>交易方式：1%FA费用&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>9、求购比亚迪半导体公司股份（预期估值280亿元人民币）</strong></h2><p>买家性质：直接机构买家&nbsp;</p><p>交易价格：预期估值280亿元人民币</p><p>交易额度：1000万美元左右需求&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>10、求购字节跳动公司股份（预期估值2200亿美元）</strong></h2><p>买家性质：直接机构买家&nbsp;</p><p>交易价格：预期估值2200亿美元&nbsp;</p><p>交易额度：3亿美元左右需求&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>11、求购小红书公司股份（预期估值140亿美元）</strong></h2><p>买家性质：直接机构买家&nbsp;</p><p>交易价格：预期估值140亿美元&nbsp;</p><p>交易额度：千万美元左右需求&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>12、求购字节跳动公司股份（预期估值2100亿美元）&nbsp;</strong></h2><p>买家性质：直接机构买家&nbsp;</p><p>交易价格：预期估值2100亿美元（含费用）&nbsp;</p><p>交易额度：1亿美元左右需求&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>13、求购持有字节跳动公司股份的专项基金LP份额（预期估值2000亿美元）&nbsp;</strong></h2><p>买家性质：直接机构买家&nbsp;</p><p>交易价格：预期估值2000亿美元&nbsp;</p><p>交易额度：千万美元左右需求&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>14、求购Space X股份（预期估值1300亿美元）</strong></h2><p>买家性质：直接机构买家</p><p>交易价格：1300亿美元</p><p>交易额度：约200万美元需求，要求是一层结构，carry 10%</p><p>联系方式：zcjy@36kr.com</p><h2><strong>二、 资产出让/增资</strong></h2><h2><strong>1、转让持有Animoca Brands股份的专项基金LP份额（按41.3亿美元估值计算）</strong></h2><p>资产介绍：一家香港移动游戏开发公司，拥有诸多知名动漫人物的手游开发代理权</p><p>卖家性质：直接卖家</p><p>交易价格：按41.3亿美元估值计算(约等于上轮估值70%），约每股3.15澳元（2.10美元）</p><p>资产规模：约50万美元份额</p><p>交易方式：管理费1%，carry 10%</p><p>其他说明：50万美元起投</p><h2><strong>2、转让持有Space X股份的专项基金LP份额（按1290亿美元估值计算）</strong></h2><p>卖家性质：直接卖家</p><p>交易价格：按1290亿美元估值计算（约每股69美元）</p><p>资产规模：约1亿美元份额</p><p>交易方式：管理费1%，carry 10%</p><p>其他说明：100万美元起投，LP份额，两层结构</p><h2><strong>3、转让持有OpenAI股份专项基金LP份额（按290亿美元估值计算）</strong></h2><p>卖家性质：直接机构卖家</p><p>交易价格：按290亿美元估值计算</p><p>资产规模：150万美元份额</p><p>交易方式：认购费5%，管理费2%，Carry30%</p><p>其他说明：两层结构</p><p>联系方式：zcjy@36kr.com</p><h2><strong>4、转让持有Space X股份的专项基金LP份额（按1290亿美元估值计算）</strong></h2><p>卖家性质：直接卖家</p><p>交易价格：按1290亿美元估值计算（约每股69美元）</p><p>资产规模：约52万美元份额</p><p>交易方式：管理费1%，carry 10%</p><p>其他说明：25万美元起投，LP份额，两层结构</p><p>联系方式：zcjy@36kr.com</p><h2><strong>5、转让持有Neuralink公司股份的专项基金LP份额（按40亿美元估值计算）</strong></h2><p>卖家性质：直接机构卖家&nbsp;</p><p>交易价格：按40亿左右美元估值计算&nbsp;</p><p>资产规模：超过200万美元份额&nbsp;</p><p>交易方式：有2%认购费用，2%管理费和20%carry&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>6、转让菜鸟网络股份（按230亿美元估值计算）</strong></h2><p>卖家性质：直接机构卖家</p><p>交易价格：按230亿美元估值计算</p><p>资产规模：约1亿美元份额</p><p>交易方式：面议</p><p>联系方式：zcjy@36kr.com</p><h2><strong>7、转让持有Animoca Brands股份的专项基金LP份额（按65亿美元估值计算）</strong></h2><p>资产介绍：一家香港移动游戏开发公司，拥有诸多知名动漫人物的手游开发代理权</p><p>卖家性质：直接卖家</p><p>交易价格：按65亿美元估值计算</p><p>资产规模：约1000万美元份额</p><p>交易方式：管理费2%，carry 20%，认购费1%</p><p>其他说明：100万美元起投</p><p>联系方式：zcjy@36kr.com</p><h2><strong>8、转让某头部机器人公司股份（按最新估值计算）</strong></h2><p>卖家性质：直接机构卖家</p><p>交易价格：按最新估值计算</p><p>资产规模：约2-3亿元人民币份额</p><p>交易方式：FA费用1%</p><p>联系方式：zcjy@36kr.com</p><h2><strong>9、转让持有Discord股份的专项基金LP份额（按190亿美元估值计算）</strong></h2><p>卖家性质：直接卖家</p><p>交易价格：按190亿美元估值计算</p><p>资产规模：约1000万美元份额</p><p>交易方式：管理费2%，carry 20%，认购费1%</p><p>其他说明：100万美元起投</p><p>联系方式：zcjy@36kr.com</p><h2><strong>10、转让某头部生物公司股份（按最新估值计算）</strong></h2><p>卖家性质：直接机构卖家</p><p>交易价格：按最新估值计算</p><p>资产规模：约3000万元人民币份额</p><p>交易方式：FA费用1%</p><p>联系方式：zcjy@36kr.com</p><h2><strong>11、转让某头部机器人公司老股（按最新估值计算）</strong></h2><p>卖家性质：直接卖家</p><p>交易价格：按最新估值计算</p><p>资产规模：1亿元人民币左右份额</p><p>交易方式：有FA费用</p><p>联系方式：zcjy@36kr.com</p><h2><strong>12、转让持有Shein份额的基金LP份额（按500亿美元估值计算）</strong></h2><p>卖家性质：直接卖家</p><p>交易价格：按500亿美元估值计算</p><p>资产规模：2000万美元份额</p><p>交易方式：有管理费和Carry</p><p>其他说明：LP份额</p><p>联系方式：zcjy@36kr.com</p><h2><strong>13、转让持有字节跳动股份的专项基金LP份额（按2300亿美元估值计算）</strong></h2><p>卖家性质：直接机构卖家</p><p>交易价格：按2300亿美元估值计算</p><p>资产规模：1亿美元份额</p><p>交易方式：有认购费用，没有管理费和carry</p><p>联系方式：zcjy@36kr.com</p><p>其他补充：字节有其他份额，如需要请联系zcjy@36kr.com</p><h2><strong>14、转让字节跳动股份老股（按2350亿美元估值计算）</strong></h2><p>卖家性质：直接机构卖家</p><p>交易价格：按2350亿美元估值计算</p><p>资产规模：3亿美元份额</p><p>交易方式：FA费用3%</p><p>其他说明：5000万美元起投，符合公司要求，可进入股东名册</p><p>联系方式：zcjy@36kr.com</p><p>其他补充：字节有其他份额，如需要请联系zcjy@36kr.com</p><h2><strong>15、转让头部汽车后市场综合服务商公司股份（按最新估值8折计算）</strong></h2><p>卖家性质：直接机构卖家</p><p>交易价格：按最新估值8折计算</p><p>资产规模：约9000万-1亿元人民币份额</p><p>交易方式：FA费用1%</p><p>联系方式：zcjy@36kr.com</p><h2><strong>16、转让头部汽车后市场综合服务商公司股份（按最新估值8折计算）</strong></h2><p>卖家性质：直接机构卖家</p><p>交易价格：按最新估值8折计算</p><p>资产规模：约6000-7000万元人民币份额</p><p>交易方式：FA费用1%</p><p>联系方式：zcjy@36kr.com</p><h2><strong>17、转让某医学诊断头部企业老股（按22亿人民币估值计算）</strong></h2><p>卖家性质：直接卖家</p><p>交易价格：按22亿人民币估值计算</p><p>资产规模：7000万人民币份额</p><p>交易方式：无费用</p><p>联系方式：zcjy@36kr.com</p><h2><strong>18、转让某自动驾驶领域头部公司老股（按50亿美元估值计算）</strong></h2><p>卖家性质：直接卖家</p><p>交易价格：按50亿美元估值计算</p><p>资产规模：2000万美元份额</p><p>交易方式：费用无</p><p>其他说明：Captable层面转让，300万美元起投</p><p>联系方式：zcjy@36kr.com</p><h2><strong>19、转让某互联网医疗企业老股（按最新估值计算）</strong></h2><p>卖家性质：直接卖家&nbsp;</p><p>交易价格：按最新估值计算&nbsp;</p><p>资产规模：2000万人民币份额&nbsp;</p><p>交易方式：无费用&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>20、转让持有Shein份额的基金LP份额（按530亿美元估值计算）&nbsp;</strong></h2><p>卖家性质：直接卖家&nbsp;</p><p>交易价格：按530亿美元估值计算&nbsp;</p><p>资产规模：3亿美元份额&nbsp;</p><p>交易方式：1%FA费用&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>21、转让光学器件产品研发、制造和销售商公司老股（面议）&nbsp;</strong></h2><p>资产亮点：主要生产光学镜片、车载面板、塑胶镜片、光学解锁识别件与组立装配器件等系列产品，配有3万多平方米的生产基地和高精密的制造设备。客户有：小米、OPPO、VIVO、字节跳动、联想、戴尔、比亚迪、索尼等。 生产能力：光学镜片产能4000万片/月，塑胶面板/车载面板产能500万片/月，光学解锁/笔电触控产能700万片/月，组立装配件产能500万套/月。&nbsp;</p><p>卖家性质：直接卖家&nbsp;</p><p>交易价格：面议&nbsp;</p><p>资产规模：面议&nbsp;</p><p>交易方式：无其他费用&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>22、转让持有菜鸟股份的专项基金LP份额（按1500亿元人民币估值计算）&nbsp;</strong></h2><p>卖家性质：直接机构卖家&nbsp;</p><p>交易价格：按1500亿元人民币估值计算&nbsp;</p><p>资产规模：100万美元份额&nbsp;</p><p>交易方式：有认购费用，2%的管理费和20%的carry，10万起购&nbsp;</p><p>联系方式：zcjy@36kr.com</p><h2><strong>23、转让DJI 大疆创新公司股份（按最新估值计算）&nbsp;</strong></h2><p>卖家性质：直接机构卖家&nbsp;</p><p>交易价格：可谈&nbsp;</p><p>资产规模：千万美元份额&nbsp;</p><p>交易方式：面议&nbsp;</p><p>联系方式：zcjy@36kr.com</p><p>**</p><p>说明1</p><p>需要说明的是：“资情留言板”栏目的相关信息均为动态信息，可能因市场情况变化或者交易完成而失效。36氪仅提供相关交易信息，具体交易需交易相关方另行协商并签署有关协议，交易各方必须依靠自己的法律、审计和税务专家的专业知识来处理法律、监管、审计和税务问题，36氪无意为交易各方提供承销服务或任何需持有特定资质或牌照方可从事的服务。</p><p>咨询更多份额请联系：zcjy@36kr.com</p><p>说明2</p><p>2021年6月开始，36氪资情留言板上线，已发布114期内容。</p><p>第1期：《<a href="https://36kr.com/p/1277884127217416" rel="noopener noreferrer" target="_blank">转让字节跳动老股、求购估值5亿元以内的保险科技类标的｜资情留言板第1期</a>》</p><p>第2期：<a href="https://36kr.com/p/1291631775156616" rel="noopener noreferrer" target="_blank">《 持有《个人本外币兑换特许业务经营许可证》（全国仅65张）公司股权转让，市场价格求购字节跳动、Shein、小红书股份｜资情留言板第2期 》</a></p><p>第3期：<a href="https://36kr.com/p/1317158918867458" rel="noopener noreferrer" target="_blank">《 一手卖家转让持有字节跳动股份的单标基金份额，市场价格求购大疆、地平线股份｜资情留言板第3期》</a></p><p>第4期：<a href="https://36kr.com/p/1327352884123908" rel="noopener noreferrer" target="_blank">《转让商汤科技股份，直接买家求购大疆股份（综合成本不高于185亿美元）｜资情留言板第4期》</a>。</p><p>第5期：<a href="https://36kr.com/p/1338356062427401" rel="noopener noreferrer" target="_blank">《转让喜马拉雅股份，转让持有互联网视听许可证（基本涵盖所有业务）公司股权｜资情留言板第5期》</a></p><p>第6期：<a href="https://36kr.com/p/1348269397154052" rel="noopener noreferrer" target="_blank">《转让商汤、Impossible Foods、Strip老股，求购大疆、极兔、地平线股份｜资情留言板第6期》</a></p><p>第7期：<a href="https://36kr.com/p/1358232131404934" rel="noopener noreferrer" target="_blank">《转让中星微、华氏医药老股，求购地平线、小红书、大疆股份｜资情留言板第7期》</a></p><p>第8期：<a href="https://36kr.com/p/1368060909482117" rel="noopener noreferrer" target="_blank">《转让菜鸟网络、地平线、集创北方股份；求购Tims咖啡、小红书、大疆股份｜资情留言板第8期》</a></p><p>第9期：<a href="https://36kr.com/p/1378147207265664" rel="noopener noreferrer" target="_blank">《转让香港主板某上市公司壳等股份，求购喜茶、得物、Paytm、货拉拉等股份｜资情留言板第9期》</a></p><p>第10期：<a href="https://36kr.com/p/1388213970025224" rel="noopener noreferrer" target="_blank">《转让喜马拉雅、能链集团等股份；求购京颐、大疆、元气森林等股份｜资情留言板第10期》</a></p><p>第11期：<a href="https://36kr.com/p/1398089461807872" rel="noopener noreferrer" target="_blank">《求购极兔速递、地平线、小红书等股份，转让大疆等公司股份｜资情留言板第11期》</a></p><p>第12期：<a href="https://36kr.com/p/1408254496707971" rel="noopener noreferrer" target="_blank">《求购得物、小红书、SHEIN股份；转让大疆、速递物流头部公司股份｜资情留言板第12期》</a></p><p>第13期：<a href="https://36kr.com/p/1417859267083651" rel="noopener noreferrer" target="_blank">《求购小红书、地平线、得物股份；转让喜马拉雅、大疆、同城货运某头部公司股份｜资情留言板第13期》</a></p><p>第14期：<a href="https://36kr.com/p/1437689795640962" rel="noopener noreferrer" target="_blank">《求购微牛证券、小红书公司股份；转让中星微、大疆、持有教育类视听证某公司股份｜资情留言板第14期》</a></p><p>第15期：<a href="https://36kr.com/p/1447717278967682" rel="noopener noreferrer" target="_blank">《转让持有Space X股份的基金LP份额（按940亿美元估值计算）；某家族办公室寻求得物、微牛证券股份｜资情留言板第15期》</a></p><p>第16期：<a href="https://36kr.com/p/1457874440447881" rel="noopener noreferrer" target="_blank">《转让持有Space X、飞骧科技、中星微等公司股份的基金份额；求购得物股份｜资情留言板第16期》</a></p><p>第17期：<a href="https://36kr.com/p/1467631889976322" rel="noopener noreferrer" target="_blank">《某家族办公室求购得物股份；转让持有飞骧科技、Space X股份的基金份额｜资情留言板第17期》</a></p><p>第18期：<a href="https://36kr.com/p/1477502150046471" rel="noopener noreferrer" target="_blank">《转让香港创业板某上市壳公司（地产板块）股份；求购小红书股份｜资情留言板第18期》</a></p><p>第19期：<a href="https://36kr.com/p/1487237997412485" rel="noopener noreferrer" target="_blank">《某知名家电上市公司寻求并购标的，转让某头部商业地产公司老股｜资情留言板第19期》</a></p><p>第20期：<a href="https://36kr.com/p/1497161276160135" rel="noopener noreferrer" target="_blank">《转让持有Epic Games股份的单项股权基金份额；某知名母婴平台旗下垂直电商业务寻求产业并购｜资情留言板第20期》</a></p><p>第21期：<a href="https://36kr.com/p/1507335103975425" rel="noopener noreferrer" target="_blank">《转让持有中星微、商汤科技股份的专项基金份额；某家族办公室寻求Discord、Neuralink、Toss等股份｜资情留言板第21期》</a></p><p>第22期：<a href="https://36kr.com/p/1517466949380869" rel="noopener noreferrer" target="_blank">《某知名母婴平台旗下垂直电商业务寻求出售机会；转让中星微、商汤科技专项基金份额｜资情留言板第22期》</a></p><p>第23期：<a href="https://36kr.com/p/1526819961777794" rel="noopener noreferrer" target="_blank">《转让某知名食品饮料赛道头部公司股份（按最新估值约八折计算）、转让Upbit老股｜资情留言板第23期》</a></p><p>第24期：<a href="https://36kr.com/p/1536887060975878" rel="noopener noreferrer" target="_blank">《某知名母婴平台旗下垂直电商业务寻求出售机会；转让某知名食品饮料赛道头部公司股份｜资情留言板第24期》</a></p><p>第25期：<a href="https://36kr.com/p/1546844074535169" rel="noopener noreferrer" target="_blank">《转让国内某TOP跨境物流服务商老股、某知名食品饮料赛道头部公司股份｜资情留言板第25期》</a></p><p>第26期：<a href="https://36kr.com/p/1556807793725062" rel="noopener noreferrer" target="_blank">《转让持有Space X股份的专项基金LP份额、某知名食品饮料赛道头部公司股份｜资情留言板第26期》</a></p><p>第27期：<a href="https://36kr.com/p/1566733202624133" rel="noopener noreferrer" target="_blank">《转让Space X股份、护肤品牌AnesSens代理权、某知名食品饮料赛道头部公司股份｜资情留言板第27期》</a></p><p>第28期：<a href="https://36kr.com/p/1576652946361091" rel="noopener noreferrer" target="_blank">《转让持有Neuralink、Space X股份的专项基金LP份额；护肤品牌AnesSens代理权转让｜资情留言板第28期》</a></p><p>第29期：<a href="https://36kr.com/p/1587347581127433" rel="noopener noreferrer" target="_blank">《转让持有龙头封测企业QZKJ股份、Neuralink股份、Space X股份的专项基金LP份额｜资情留言板第29期》</a></p><p>第30期：<a href="https://36kr.com/p/1606269802367488" rel="noopener noreferrer" target="_blank">《转让持有Neuralink、Open Sea、Space X股份的专项基金份额，转让艾博生物老股｜资情留言板第30期》</a></p><p>第31期：<a href="https://36kr.com/p/1616482907008520" rel="noopener noreferrer" target="_blank">《某知名母婴平台旗下垂直电商业务寻求产业并购；转让持有Neuralink、Space X股份的专项基金份额｜资情留言板第31期》</a></p><p>第32期：<a href="https://36kr.com/p/1626139209463556" rel="noopener noreferrer" target="_blank">《转让某知名食品饮料赛道头部公司股份；转让持有Discord、Epic Games股份的专项基金份额｜资情留言板第32期》</a></p><p>第33期：<a href="https://36kr.com/p/1636328946229126" rel="noopener noreferrer" target="_blank">《转让持有Neuralink、Space X、某智能终端电子芯片ZXW股份的专项基金份额｜资情留言板第33期》</a></p><p>第34期：<a href="https://36kr.com/p/1646173976109959" rel="noopener noreferrer" target="_blank">《转让持有Animoca Brands、某国产GPGPU、某密码技术龙头公司股份的专项基金LP份额｜资情留言板第34期》</a></p><p>第35期：<a href="https://36kr.com/p/1656742227261576" rel="noopener noreferrer" target="_blank">《转让持有Blockdaemon、Space X、某龙头密码公司、Neuralink股份的基金份额｜资情留言板第35期》</a></p><p>第36期：<a href="https://36kr.com/p/1666174507128836" rel="noopener noreferrer" target="_blank">《转让持有文远知行、Space X、某智能终端电子芯片ZXW股份的专项基金LP份额｜资情留言板第36期》</a></p><p>第37期：<a href="https://36kr.com/p/1676524003157253" rel="noopener noreferrer" target="_blank">《转让持有Space X、Epic Games、某龙头封测企业QZKJ股份的专项基金LP份额｜资情留言板第37期》</a></p><p>第38期：<a href="https://36kr.com/p/1686615381376772" rel="noopener noreferrer" target="_blank">《转让持有Space X、某智能终端电子芯片ZXW、文远知行股份的专项基金LP份额｜资情留言板第38期》</a></p><p>第39期：<a href="https://36kr.com/p/1695404923498114" rel="noopener noreferrer" target="_blank">《转让持有Shein、途虎养车、某头部智能驾驶公司等股份的专项基金LP份额｜资情留言板第39期》</a></p><p>第40期：<a href="https://36kr.com/p/1705723293144839" rel="noopener noreferrer" target="_blank">《转让持有SpaceX、Shein、某头部智能驾驶公司专项基金LP份额｜资情留言板第40期》</a></p><p>第41期：<a href="https://36kr.com/p/1715459202249480" rel="noopener noreferrer" target="_blank">《转让持有Animoca Brands、Discord、某龙头封测公司股份的专项基金LP份额｜资情留言板第41期》</a></p><p>第42期：<a href="https://36kr.com/p/1725488387980545" rel="noopener noreferrer" target="_blank">《转让持有Space X、Epic Games、某国产GPGPU龙头公司股份的专项基金LP份额｜资情留言板第42期》</a></p><p>第43期：<a href="https://36kr.com/p/1734953390390537" rel="noopener noreferrer" target="_blank">《转让持有Shein、Discord股份的专项基金份额；求购Space X股份（500万美元以上需求）｜资情留言板第43期》</a></p><p>第44期：<a href="https://36kr.com/p/1745981826068358" rel="noopener noreferrer" target="_blank">《转让某全球知名物流服务商、某食品饮料赛道头部公司老股；求购Space X股份｜资情留言板第44期》</a></p><p>第45期：<a href="https://36kr.com/p/1755786870718084" rel="noopener noreferrer" target="_blank">《转让持有Space X、Shein、某头部智能驾驶公司股份的专项基金LP份额｜资情留言板第45期》</a></p><p>第46期：<a href="https://36kr.com/p/1764960240384256" rel="noopener noreferrer" target="_blank">《转让持有Space X、Shein公司股份的专项基金份额；护肤品牌AnesSens代理权转让｜资情留言板第46期》</a></p><p>第47期：<a href="https://36kr.com/p/1775051861412232" rel="noopener noreferrer" target="_blank">《转让持有Space X、Discord、某头部智能驾驶公司股份的专项基金LP份额｜资情留言板第47期》</a></p><p>第48期：<a href="https://36kr.com/p/1784806224858503" rel="noopener noreferrer" target="_blank">《转让持有 Space X、Cybereason 公司股份的专项基金份额；求购 Flexport 股份｜资情留言板第48期》</a></p><p>第49期：<a href="https://36kr.com/p/1795407331836163" rel="noopener noreferrer" target="_blank">《转让持有Shein、Space X、某知名食品饮料赛道头部公司股份的专项基金份额｜资情留言板第49期》</a></p><p>第50期：<a href="https://36kr.com/p/1805356388008961" rel="noopener noreferrer" target="_blank">《转让持有Space X股份的基金LP份额、驴奶护肤品牌AnesSens代理权｜资情留言板第50期》</a></p><p>第51期：<a href="https://36kr.com/p/1814451335939456" rel="noopener noreferrer" target="_blank">《转让某互联网物流行业、知名食品饮料赛道、自动驾驶领域等头部公司老股｜资情留言板第51期》</a></p><p>第52期：<a href="https://36kr.com/p/1825134672496133" rel="noopener noreferrer" target="_blank">《转让持有Space X、Shein股份的基金份额，某头部智能驾驶、物流公司老股转让｜资情留言板第52期》</a></p><p>第53期：<a href="https://36kr.com/p/1834219714486787" rel="noopener noreferrer" target="_blank">《转让持有Space X、Discord、某头部机器人、双碳公司股份的专项基金LP份额｜资情留言板第53期》</a></p><p>第54期：<a href="https://36kr.com/p/1844355176221573" rel="noopener noreferrer" target="_blank">《转让持有Neuralink、Space X、某头部自动驾驶公司股份的专项基金LP份额｜资情留言板第54期》</a></p><p>第55期：<a href="https://36kr.com/p/1853772342759048" rel="noopener noreferrer" target="_blank">《转让持有Neuralink、某头部自动驾驶、碳酸锂公司股份的专项基金LP份额｜资情留言板第55期》</a></p><p>第56期：<a href="https://36kr.com/p/1865006619136512" rel="noopener noreferrer" target="_blank">《转让持有Space X、Shein、某头部自动驾驶公司股份的专项基金LP份额｜资情留言板第56期》</a></p><p>第57期：<a href="https://36kr.com/p/1874062900677769" rel="noopener noreferrer" target="_blank">《转让持有Neuralink、某头部芯片、商业航天公司股份的专项基金LP份额｜资情留言板第57期》</a></p><p>第58期：<a href="https://36kr.com/p/1884787991833732" rel="noopener noreferrer" target="_blank">《转让持有Space X、Shein、某头部汽车、双碳领域等公司股份的专项基金LP份额｜资情留言板第58期》</a></p><p>第59期：<a href="https://36kr.com/p/1893678719160836" rel="noopener noreferrer" target="_blank">《转让持有Space X、Neuralink、某知名食品饮料赛道头部公司股份的专项基金LP份额｜资情留言板第59期》</a></p><p>第60期：<a href="https://36kr.com/p/1904408157972873" rel="noopener noreferrer" target="_blank">《转让持有Space X、Neuralink、某头部物流及汽车领域公司股份的专项基金LP份额｜资情留言板第60期》</a></p><p>第61期：<a href="https://36kr.com/p/1914429503311877" rel="noopener noreferrer" target="_blank">《转让持有Space X、Shein、某头部氢能、自动驾驶等公司股份的专项基金LP份额｜资情留言板第61期》</a></p><p>第62期：<a href="https://36kr.com/p/1924326637288194" rel="noopener noreferrer" target="_blank">《转让持有Neuralink、Shein、Discord股份的专项基金LP份额｜资情留言板第62期》</a></p><p>第63期：<a href="https://36kr.com/p/1933426489624960" rel="noopener noreferrer" target="_blank">《求购国内一线美元基金LP份额 ；转让持有Space X、Neuralink的专项基金LP份额｜资情留言板第63期》</a></p><p>第64期：<a href="https://36kr.com/p/1953994189166726" rel="noopener noreferrer" target="_blank">《求购Neuralink老股 ；转让持有Space X、某食品饮料头部公司的基金份额｜资情留言板第64期》</a></p><p>第65期：<a href="https://36kr.com/p/1964156597611011" rel="noopener noreferrer" target="_blank">《求购极兔、小红书老股；转让持有Space X、某自动驾驶头部公司的基金份额｜资情留言板第65期》</a></p><p>第66期：<a href="https://36kr.com/p/1974011563712899" rel="noopener noreferrer" target="_blank">《求购Neuralink、小红书老股；转让持有Shein、某氢能头部公司股份的基金份额｜资情留言板第66期》</a></p><p>第67期：<a href="https://36kr.com/p/1983915551032576" rel="noopener noreferrer" target="_blank">《转让持有Neuralink、Shein公司股份的基金份额；求购极兔、小红书老股｜资情留言板第67期》</a></p><p>第68期：<a href="https://36kr.com/p/1993784431145475" rel="noopener noreferrer" target="_blank">《转让持有Space X、Discord公司股份的基金份额；求购Neuralink、小红书老股｜资情留言板第68期》</a></p><p>第69期：<a href="https://36kr.com/p/2003816544309382" rel="noopener noreferrer" target="_blank">《求购Space X、小红书老股；转让持有Neuralink、某头部物流公司股份的基金份额｜资情留言板第69期》</a></p><p>第70期：<a href="https://36kr.com/p/2013638157730312" rel="noopener noreferrer" target="_blank">《转让持有Space X、Neuralink、某头部自动驾驶公司股份的基金份额｜资情留言板第70期》</a></p><p>第71期：<a href="https://36kr.com/p/2023681544400136" rel="noopener noreferrer" target="_blank">《转让持有Space X、Shein、某头部物流公司股份的专项基金份额｜资情留言板第71期》</a></p><p>第72期：<a href="https://36kr.com/p/2033420631223553" rel="noopener noreferrer" target="_blank">《求购OpenAI股份（ChatGPT的母公司）；转让持有Space X、Shein公司股份的基金份额｜资情留言板第72期》</a></p><p>第73期：<a href="https://36kr.com/p/2043326810491907" rel="noopener noreferrer" target="_blank">《求购OpenAI、Neuralink股份；转让持有Space X、Shein公司股份的基金份额｜资情留言板第73期》</a></p><p>第74期：<a href="https://36kr.com/p/2053224417636869" rel="noopener noreferrer" target="_blank">《转让持有OpenAI、Shein公司股份的基金份额；求购Space X、Neuralink老股｜资情留言板第74期》</a></p><p>第75期：<a href="https://36kr.com/p/2062958054920072" rel="noopener noreferrer" target="_blank">《求购Space X、Neuralink老股；转让持有Shein、某头部物流公司股份的基金份额｜资情留言板第75期》</a></p><p>第76期：<a href="https://36kr.com/p/2073220743232648" rel="noopener noreferrer" target="_blank">《求购Space X、Neuralink老股；转让持有Shein、OpenAI的基金份额｜资情留言板第76期》</a></p><p>第77期：<a href="https://36kr.com/p/2082911478493955" rel="noopener noreferrer" target="_blank">《转让持有OpenAI、某头部物流公司的基金份额；求购Space X、Neuralink老股｜资情留言板第77期》</a></p><p>第78期：<a href="https://36kr.com/p/2093033295446149" rel="noopener noreferrer" target="_blank">《求购Space X、Neuralink老股；转让持有Shein、某头部物流公司的基金份额｜资情留言板第78期》</a></p><p>第79期：<a href="https://36kr.com/p/2112625351887237" rel="noopener noreferrer" target="_blank">《转让持有Space X、Neuralink、OpenAI、某头部自动驾驶公司的专项基金份额｜资情留言板第79期》</a></p><p>第80期：<a href="https://36kr.com/p/2122439613073800" rel="noopener noreferrer" target="_blank">《求购Neuralink老股；转让持有OpenAI、Space X、某头部物流公司的专项基金份额｜资情留言板第80期》</a></p><p>第81期：<a href="https://36kr.com/p/2132613012925446" rel="noopener noreferrer" target="_blank">《求购Space X、Neuralink老股；转让持有Shein、某头部自动驾驶公司的基金份额｜资情留言板第81期》</a></p><p>第82期：<a href="https://36kr.com/p/2142445875446279" rel="noopener noreferrer" target="_blank">《转让持有Space X、Neuralink、Shein、某头部物流公司的专项基金份额｜资情留言板第82期》</a></p><p>第83期：<a href="https://36kr.com/p/2152151366717952" rel="noopener noreferrer" target="_blank">《转让持有Space X、OpenAI、Discord、某头部物流公司的专项基金份额｜资情留言板第83期》</a></p><p>第84期：<a href="https://36kr.com/p/2162341785694473" rel="noopener noreferrer" target="_blank">《求购Neuralink、Space X老股；转让持有OpenAI、某自动驾驶公司的基金份额｜资情留言板第84期》</a></p><p>第85期：<a href="https://36kr.com/p/2172248012992773" rel="noopener noreferrer" target="_blank">《转让持有Space X、Shein、OpenAI、某自动驾驶公司的专项基金份额｜资情留言板第85期》</a></p><p>第86期：<a href="https://36kr.com/p/2182121328277504" rel="noopener noreferrer" target="_blank">《转让持有OpenAI、Space X、Discord、某自动驾驶公司的专项基金份额｜资情留言板第86期》</a></p><p>第87期：<a href="https://36kr.com/p/2192114415485317" rel="noopener noreferrer" target="_blank">《转让持有Space X、Neuralink、Shein、某头部物流公司的专项基金份额｜资情留言板第87期》</a></p><p>第88期：<a href="https://36kr.com/p/2201946256796549" rel="noopener noreferrer" target="_blank">《求购Open AI老股；转让持有Space X、Neuralink、Shein的专项基金份额｜资情留言板第88期》</a></p><p>第89期：<a href="https://36kr.com/p/2211741658756484" rel="noopener noreferrer" target="_blank">《求购Space X、Open AI老股；转让持有Neuralink、某头部自动驾驶公司的基金份额｜资情留言板第89期》</a></p><p>第90期：<a href="https://36kr.com/p/2221758417404548" rel="noopener noreferrer" target="_blank">《求购Open AI、医疗大健康类资产；转让持有Space X、Neuralink的基金份额｜资情留言板第90期》</a></p><p>第91期：<a href="https://36kr.com/p/2231964007624322" rel="noopener noreferrer" target="_blank">《转让持有Space X、Discord、Shein的基金份额；求购Open AI、医疗大健康类资产｜资情留言板第91期》</a></p><p>第92期：<a href="https://36kr.com/p/2251668094791300" rel="noopener noreferrer" target="_blank">《求购Space X、Open AI老股；转让持有Neuralink、Shein的基金份额｜资情留言板第92期》</a></p><p>第93期：<a href="https://36kr.com/p/2261384425107080" rel="noopener noreferrer" target="_blank">《求购Space X、Open AI老股；转让持有Neuralink、Shein的基金份额｜资情留言板第93期》</a></p><p>第94期：<a href="https://36kr.com/p/2271402958036740" rel="noopener noreferrer" target="_blank">《求购Space X、Open AI老股；转让持有Neuralink、Discord的基金份额｜资情留言板第94期》</a></p><p>第95期：<a href="https://36kr.com/p/2281294735022081" rel="noopener noreferrer" target="_blank">《转让持有Open AI、Neuralink、Discord与某头部机器人公司的基金份额｜资情留言板第95期》</a></p><p>第96期：<a href="https://36kr.com/p/2290992515127044" rel="noopener noreferrer" target="_blank">《求购Open AI、Space X老股；转让持有Shein、Discord公司的专项基金份额｜资情留言板第96期》</a></p><p>第97期：<a href="https://36kr.com/p/2300816066653192" rel="noopener noreferrer" target="_blank">《转让持有Space X、Open AI、Shein、Neuralink公司的专项基金份额｜资情留言板第97期》</a></p><p>第98期：<a href="https://36kr.com/p/2310985178803712" rel="noopener noreferrer" target="_blank">《求购Space X、Neuralink、Open AI股份；转让500亿美元估值的Shein老股｜资情留言板第98期》</a></p><p>第99期：<a href="https://36kr.com/p/2320926749918341" rel="noopener noreferrer" target="_blank">《转让Space X、Open AI、某500亿美元估值的Shein老股份额｜资情留言板第99期》</a></p><p>第100期：<a href="https://36kr.com/p/2329231138627205" rel="noopener noreferrer" target="_blank">《转让Space X、菜鸟网络、约200万美元额度的Open AI老股份额｜资情留言板第100期》</a></p><p>第101期：<a href="https://36kr.com/p/2340604657618433" rel="noopener noreferrer" target="_blank">《转让Space X、菜鸟网络、Open AI老股份额｜资情留言板第101期》</a></p><p>第102期：<a href="https://36kr.com/p/2350465130813955" rel="noopener noreferrer" target="_blank">《转让Animoca Brands、Open AI、Space X专项基金LP份额｜资情留言板第102期》</a></p><p>第103期：<a href="https://36kr.com/p/2360470848863746" rel="noopener noreferrer" target="_blank">《转让Neuralink、Open AI、Space X专项基金LP份额｜资情留言板第103期》</a></p><p>第104期：<a href="https://36kr.com/p/2369648059706247" rel="noopener noreferrer" target="_blank">《求购Shein、元气森林股份；转让Neuralink、Open AI股份｜资情留言板第104期》</a></p><p>第105期：<a href="https://36kr.com/p/2380255544536065" rel="noopener noreferrer" target="_blank">《求购Open AI股份；转让Shein、Space X专项基金LP份额｜资情留言板第105期》</a></p><p>第106期：<a href="https://36kr.com/p/2389495610364547" rel="noopener noreferrer" target="_blank">《求购Shein、Open AI股份；转让Space X专项基金LP份额｜资情留言板第106期》</a></p><p>第107期：<a href="https://36kr.com/p/2399270604480134" rel="noopener noreferrer" target="_blank">《求购菜鸟网络老股；转让Neuralink、Space X专项基金LP份额｜资情留言板第107期》</a></p><p>第108期：<a href="https://36kr.com/p/2409860518224647" rel="noopener noreferrer" target="_blank">《求购Neuralink、元气森林公司股份；转让Animoca Brands、Open AI专项基金LP份额｜资情留言板第108期》</a></p><p>第109期：<a href="https://36kr.com/p/2419787613758472" rel="noopener noreferrer" target="_blank">《求购喜茶股份；转让中科富海、Shein、Open AI基金LP份额｜资情留言板第109期》</a></p><p>第110期：<a href="https://36kr.com/p/2429655630696834" rel="noopener noreferrer" target="_blank">《求购菜鸟、比亚迪半导体股份；转让Shein、Open AI基金LP份额｜资情留言板第110期》</a></p><p>第111期：<a href="https://36kr.com/p/2438931564384901" rel="noopener noreferrer" target="_blank">《求购小红书股份；转让Neuralink、OpenAI、Space X专项基金LP份额｜资情留言板第111期》</a></p><p>第112期：<a href="https://36kr.com/p/2449552473069443" rel="noopener noreferrer" target="_blank">《求购喜茶、小红书、比亚迪半导体股份；转让大疆创新股份｜资情留言板第112期》</a></p><p>第113期：<a href="https://36kr.com/p/2469298519955329" rel="noopener noreferrer" target="_blank">《求购小红书、OpenAI股份；转让Neuralink专项基金LP份额、大疆创新股份｜资情留言板第113期》</a></p><p>第114期：<a href="https://36kr.com/p/2479274329085832" rel="noopener noreferrer" target="_blank">《求购OpenAI股份；转让Animoca Brands、Discord股份专项基金LP份额｜资情留言板第114期》</a></p><p>截止目前共计收到九千余封咨询邮件（zcjy@36kr.com），经过我们筛选排查后筛选出上千家有真实交易需求的机构、公司，并帮助其进行对接，目前交易仍在进行中，我们也会持续关注。另外，目前36氪已经与知名基金建立了合作关系。</p><p>如果你希望通过我们的资情留言板栏目发布求购或者出售资产信息，也欢迎与我们联系（zcjy@36kr.com）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498356540708741</id>
            <title>阿里通义千问升级2.0：八大产品模型全家桶上线，群发开发者英雄帖 | 最前线</title>
            <link>https://www.36kr.com/p/2498356540708741</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498356540708741</guid>
            <pubDate></pubDate>
            <updated>Wed, 01 Nov 2023 00:30:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 阿里云, 通义千问, 大模型, 开放
<br>
<br>
总结: 阿里云在云栖大会上发布了通义千问2.0版本，该版本在复杂指令理解、文学创作、通用数学、知识记忆、幻觉抵御等能力上有较大提升。阿里云强调开放是核心主题，希望打造AI时代最开放的云。通义千问2.0在多模态和插件功能上有技术优化，支持图片输入、文档解析等细分任务。阿里云发布了八大行业模型，并推出了通义千问的APP，开发者可以将模型能力集成到自己的应用和服务中。阿里云已与60多个行业伙伴合作，通义千问已在多个领域落地。阿里云希望通过通义千问的基础模型能力和开源社区的资源，让开发者和中小企业快速开发自己的模型。 </div>
                        <hr>
                    
                    <p>作者 | 邓咏仪</p><p>编辑 | 苏建勋</p><p>10月，可以说是国内大模型领域的一场小考，好不热闹——从腾讯、讯飞、智谱、百川，各家大模型厂商纷纷拿出通用大模型的新版本，试图一较高下。</p><p>本月最后一天，阿里云云栖大会如期开幕，阿里云旗下的通义千问，交上本月的最后一份答卷。</p><p>继4月正式发布通义千问大模型后，阿里云发布了通义千问2.0版本——与4月相比，通义千问2.0在复杂指令理解、文学创作、通用数学、知识记忆、幻觉抵御等能力上，都有在性能上取得较大提升。</p><p><strong>开放则是本届云栖的核心主题</strong>。“过去十来年，阿里云服务了中国移动互联网的大发展。今天，随着大模型技术的迅速发展，智能化时代正在开启，阿里云要打造AI时代一朵最开放的云。”主论坛演讲中，阿里巴巴集团董事会主席蔡崇信如此表示。</p><p>阿里云也亮出了通义千问和其他模型的比较结果。在MMLU、C-Eval、GSM8K、HumanEval、MATH等10个主流Benchmark测评集上，通义千问2.0的得分整体超越Meta的Llama-2-70B。相比OpenAI的Chat-3.5，是九胜一负；相比GPT-4则是四胜六负，与GPT-4的差距进一步缩小。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_d42765d35ee049708419651a638d60d4@2057308263_oswg905972oswg1080oswg786_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：阿里云</p><p>不过，和竞品拼测评分数，只能说是大模型比拼的基础。本届云栖的重点更多放在产品化、各类能力开放上。比如，通义大模型官网上线了多模态和插件功能，支持图片输入、文档解析等细分任务。并且，通义千问2.0在指令遵循、工具使用、精细化创作等方面作了技术优化，这些能力更好地被下游应用场景集成。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_4b16015154674a7286d2651ad34fcfd6@2057308263_oswg1437488oswg1715oswg984_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：阿里云</p><p>发布会的重点，显然放在了通义系列的“模型团”上。CTO周靖人花费了大量时间介绍通义模型家族里的八大行业模型，包括：</p><ul><li><strong>通义灵码-智能编码助手</strong></li><li><strong>通义智文-AI阅读助手</strong></li><li><strong>通义听悟-工作学习AI助手</strong></li><li><strong>通义星尘-个性化角色创作平台</strong></li><li><strong>通义点金-智能投研助手</strong></li><li><strong>通义晓蜜-智能客服</strong></li><li><strong>通义仁心-个人专属健康助手</strong></li><li><strong>通义法睿-AI法律顾问</strong></li></ul><p>并且，通义千问还正式发布了APP，在各大手机应用市场正式上线，所有人都可通过APP直接体验最新模型能力。另外，开发者可以通过网页嵌入、API/SDK调用等方式，将上述的模型能力集成到自己的大模型应用和服务中。</p><p>国内大模型领域已经从通用大模型层，逐渐转向应用层。要扩大开放，也是为了吸引更多的开发者和客户。因此，理清边界很重要。</p><p>尽管阿里云这次发布了八大产品模型，但周靖人强调，阿里云此举并非为了直接To C提供服务，而是To B。做行业模型，更多是像个面向客户的Demo，让客户先了解到大模型能做什么。</p><p>截至10月，阿里云已与60多个行业头部伙伴进行深度合作，通义千问已经在办公、文旅、电力、政务、医保、交通、制造、金融、软件开发等领域的落地。</p><p>“要做开放的云，我们说到做到。如果有的开发者，有能力做自己的底层通用模型，我们也会提供应用模型的接口和开发平台，让开发者来做应用开发。”周靖人对36氪表示。</p><p>在早上的主论坛上，童语故事创始人兼CEO张华，就向开发者分享了一位父亲用大模型创业的故事。7个人的团队，在阿里云上创业，不到三个月，“童语故事”的MAU（月活用户）就到了几十万，平均每个月IT成本才1万元左右。“有了大模型、云计算这些成熟的技术，才能让我们实现低成本高效创业。”张华说。</p><p>从产品到生态，阿里云已经付出不少切实的努力。去年的云栖大会上，阿里云发布了AI开源社区“魔搭”。一年后，魔搭现在已有280万开发者、2300多个优质模型，模型下载量超过1亿。</p><p>比起从模型到应用都做，阿里云更希望达到的未来是，<strong>让开发者、中小企业借助通义千问的基础模型能力，借助开源社区的各类资源，快速地开发自己的模型。</strong></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498408307679107</id>
            <title>骁龙X Elite真机实测：这才是轻薄性能本的未来？</title>
            <link>https://www.36kr.com/p/2498408307679107</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498408307679107</guid>
            <pubDate></pubDate>
            <updated>Wed, 01 Nov 2023 00:16:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 骁龙X Elite, 移动计算平台, 芯片, 性能表现
<br>
<br>
总结: 在2023骁龙峰会上，高通发布了骁龙X Elite移动计算平台，该芯片在能耗和性能方面优于竞争对手的产品。它采用定制Oryon CPU和强大的GPU，表现超越了其他同类芯片。骁龙X Elite有两个版本，分别是标压版和低压版，两者都采用三丛集设计，具备出色的处理能力。在基准测试中，骁龙X Elite的表现也得到了验证。 </div>
                        <hr>
                    
                    <p>在刚刚结束的2023骁龙峰会上，高通正式发布了骁龙下一代移动计算平台——也就是小龙用于Windows电脑的全新芯片——骁龙X Elite。从骁龙峰会中骁龙X Elite的演示机数量来看，高通对骁龙X Elite可以说充满了自信。&nbsp;</p><p>其实从架构和测试性能来看，骁龙X Elite也确实拥有自信的本钱：在主题演讲中，<strong>高通多次强调骁龙X Elite无论是能耗表现还是性能表现，均优于友商相同产品定位的芯片，比如其中的定制Oryon CPU可以用M2 Max芯片70%的能耗实现相同的单线程表现。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_4c22857b38594fe7a65bfbe60abfc33b@1547419282_oswg696465oswg1619oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>和英特尔的i9-13980HX相比，相同单线峰值性能下能耗更是只有前者的30%。<strong>即使是即使GPU性能这一ARM阵营的常见短板，骁龙X Elite的表现也都超越了AMD R9-7940HS，可以说非常令人期待。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_69430b5722d5483d94f2dc2b0412e0c4@1547419282_oswg339837oswg1619oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>而在骁龙峰会的最后一天，高通也为我们安排了一场机会难得的“闭门会议”，向在场的中文媒体披露了关于骁龙X Elite移动平台的更多消息。</p><h2>01 没有水份，全是大核</h2><p>现阶段骁龙X系列还只有骁龙X Elite这一款芯片，但为了应对不同的用户需求，现阶段高通也准备了两种不同的骁龙X Elite展示机——Model A和Model B。<strong>虽然说A款和B款在机身设计方面存在不少的差异，但真正决定两款产品不同的其实是它们的功耗：</strong>Model A我们可以理解为骁龙X Elite的“标压版”，整机TDP最高可以达到80W，而Model B的TDP则为23W，可以认为是骁龙X Elite的“低压版”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_b065189da30048be9e60e28b2875e903@1547419282_oswg200112oswg1351oswg1012_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>两者采用的相同的三丛集设计，<strong>配备3组共计12个3.8GHz的CPU核心，面对高负载时会将其中两个核心超频至4.3GHz。不出意外的话，这个“超频”设计会是Model A的专属功能。</strong></p><p>考虑到大多数用户对Windows on ARM设备的性能抱有顾虑，高通也为现场媒体准备了“跑分演示”环节：<strong>机器不能上手，现场工作人员代我们运行跑分程序。</strong></p><p>从结果来看，高通确实没有夸大骁龙X Elite的基准测试表现。在传统CPU测试Cinebench 2024中，<strong>无论单线程还是多线程，“满血版”骁龙X Elite的分数都超越了其他相同定位的对手。其中CB2024多线程测试中，骁龙X Elite相较于i7-13800H更是有着超过22%的分数提升。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_f25b0b752a8242d0aae6b3be126dfe37@1547419282_oswg1625873oswg5120oswg2880_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_c339d750482049bfa20f511052fe8bef@1547419282_oswg1682713oswg5120oswg2880_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>不过值得注意的是，尽管使用的已经是Cinebench 2024，<strong>但在系统信息中，无论是Model A还是Model B，处理器详情标记的都是2.98GHz而不是3.8GHz。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_149f3fa7ff284f87a7737955f285685e@1547419282_oswg1735514oswg4032oswg3024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>Geekbench 6.2中，骁龙X Elite Model A也再一次领跑全场，而Model B则在多线程测试中落后于i7-13800H。会出现这样的结果其实并不令人意外，<strong>毕竟13800H的TDP“高达”45W，几乎是低压版骁龙X Elite整机TDP的两倍。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_a057116540fc474a9f8fecce9728e61e@1547419282_oswg1682375oswg5120oswg2880_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_edb9c49c7be54509ba0196a8cf3be7db@1547419282_oswg1723781oswg5120oswg2880_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>不过骁龙X Elite满血版在ST、MT两种测试下均超过了13800H这一点倒是有一点让人意外，小雷这里大胆猜测这个骁龙X Elite采用了“全大核”的方案有关：</p><p>在第12代酷睿处理器中，英特尔为Windows平台带来了“大小核”的架构。<strong>在设想中，P核心（大核）与E核心（小核）可以在Windows和ITD的调度下，分别对应有不同性能需求的进程。但实际上，直到第14代酷睿，Windows仍没搞明白究竟该在什么时候把进程交给哪一个核心</strong>，以至于英特尔直接推出了一款允许用户手动分配核心的调度App。</p><p>而作为对比，骁龙X Elite直接准备了12个“大核”，不管怎么分配都不会出现小核满占用、大核无占用的情况。<strong>不过话又说回来，高通并没有详细说明骁龙X Elite满血版的“4.3GHz”超频机制，是不是只有固定核心可以获得超频？是骁龙X Elite主动超频还是应用程序通过操作系统申请超频？单独超频对其他核心有无影响？</strong>这些详情还需要等高通的进一步分享。</p><p>但从这个“全大核”的组合与实际表现来看，<strong>如果说“英特尔更懂性能与能耗的平衡”，那高通和骁龙X Elite可以说“看透了微软”。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_03f3b21100634ed99b81affd65653727@1547419282_oswg1693347oswg5120oswg2880_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_5f2a43b9070d44dda60b92ce77f883b6@1547419282_oswg1638308oswg5120oswg2880_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>接下来我们来看看GPU成绩，在3DMark Wildlife Extreme和GFX Aztec Ruins测试中，骁龙X Elite Model A的平均fps再次排在首位。这里其实还有一个小“彩蛋”：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_c8406cf311b04c77beeea4719c8eb428@1547419282_oswg1454356oswg4032oswg3024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>主题活动中高通一直没有公布骁龙X Elite中GPU的具体型号，只标注这是一颗“Adreno GPU”，而在Wildlife测试输出的报告中，<strong>我们可以清楚看到这颗GPU的名字是“Qualcomm Adreno 8cx Gen 4”，没错，骁龙还是忘不了8cx。</strong></p><p>我明白，这里一定会有人质疑说和移动i7、R9比GPU没有意义，毕竟这些笔记本一般都会搭配独立GPU，而骁龙X Elite无论是PCIe拓展性还是对第三方GPU支持都存疑，万一这是第二个M2 Mac Pro呢？</p><p>关于这一点，高通想的其实非常明白。</p><h2>02 NPU才是AI的未来</h2><p>在被问及“骁龙X Elite是否会应用于Windows笔记本电脑之外产品”时，高通技术公司高级副总裁兼计算与游戏业务总经理Kedar Kondap向在场媒体表示：</p><p>“<strong>虽然目前为止有关骁龙X Elite的讨论主要集中在Windows系统的笔记本电脑，同时我们也提到在2024年高通Oryon CPU将应用于移动平台，</strong>未来也会扩展到汽车以及其他的领域。骁龙X Elite的强大性能可以应用于许多领域，<strong>但是我们暂时不会讨论这一点。</strong>”</p><p>此外，他也表示骁龙X Elite笔记本的主要竞争对手并不是Chromebook，且当前就主要聚焦在休闲游戏而不是传统3A大作上。<strong>从中我们不难看出骁龙X Elite主要应用场景应该是ThinkPad X1C、XPS 13Plus等拥有出色CPU性能的轻薄笔记本。</strong>再说了，目前展示的两个演示型号，整机TDP加在一起都摸不到移动端RTX 4070的平均功耗，<strong>“高性能游戏本”应该不是骁龙X Elite的主战场。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_0addd690e82d4a23a4ff9ae5d8c23ae8@1547419282_oswg1262178oswg2616oswg1468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>但问题是，笔记本GPU的用处并不只有游戏，<strong>无论是视频渲染还是现在流行的设备端AI大语言模型，都对CUDA性能有较高的要求，那骁龙X Elite又该如何填补这一短板呢？</strong></p><p>高通的答案也异常的直截了当：<strong>我直接加一颗NPU进去不就好了？</strong></p><p>没错，在骁龙X Elite中，<strong>高通还专门准备了一个独立的NPU以应对AI与神经网络运算。</strong>尽管这颗NPU在性能检测上只体现出1GB内存，但其性能却远远甩开13800H、7940HS等处理器——在UL Procyon AI测试中，<strong>骁龙X Elite的分数遥遥领先于其他两款处理器。更重要的是，满血的骁龙X Elite Model A和“低压版”Model B，在该测试中有着相同的分数。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_74f058bb6ddb44fe8bccb573f7cad9ed@1547419282_oswg1608557oswg5120oswg2880_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>难能可贵的是，这颗NPU的性能并不只体现在基准测试中。骁龙X Elite平台具备75TOPS（CPU+GPU+NPU）的算力，且可应用在多种不同的生成式AI模型中。此外，在主题演讲中，<strong>高通也携手微软提出了“本地AI+云端AI”的融合AI概念。</strong></p><p><strong>设备端的本地AI可以可以在离线或网络连接不稳定的时候提供快速的AI响应，同时也可以将关键用户信息保存在设备本地，</strong>从而保护用户的个人数据或商业机密，而远端AI可以利用强大的远端算力提供更高AI准确度和专业程度，从而提高整体的AI体验。</p><h2>03 源自底层架构的独家优势</h2><p>考虑到Apple在10月底发布了全新的M3芯片，抢先亮相的骁龙X Elite页不可避免的要和M3正面对抗。没错，M3确实采用了更激进的3nm支撑工艺（骁龙X Elite为4nm），但就像高通在主题演讲和采访中说到的那样，骁龙X Elite也有着自己独特的优势。</p><p>首先，骁龙X Elite有着更好的无线通讯能力，这点相信大家都不会有异议，甚至在主题演讲上，高通都不忘记“阴阳怪气”，说并不是所有品牌都有能力将无线信号做好。可能有人觉得无线信号对笔记本来说并不重要，这种观点你放在AI时代之前确实没有错。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_47467b6208ff45ffaff5e6271927455c@1547419282_oswg588231oswg1619oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p><strong>但在强调笔记本AI性能，甚至是本地+云端融合AI性能的AI时代，时刻在线（Always Online）将成为笔记本的一大特性。其次，刚刚说过的全大核架构让骁龙X Elite在多任务时有着更好的性能储备。</strong></p><p>但这是否就意味着骁龙X Elite面对M3“赢到家”了呢？</p><p>不要忘记M3统一内存的设计能让数据更快地被CPU、GPU访问，而且全面转向ARM架构的macOS比起“脚踏两条船”的Windows显然有着更好的架构适配。如果Windows决定“梦回8cx”甚至是Windows RT时代，那骁龙X Elite又该怎么办呢？</p><p>考虑到ARM架构下“潜在”的应用生态问题，高通提出了一个“三步走”的策略：</p><p>第一，<strong>把应用程序移植到骁龙本上并在模拟模式下运行，</strong>如微软的介绍所说，他们正在努力确保Windows的模拟模式具备优秀的性能；</p><p>第二，把原生应用程序移植到骁龙本上；</p><p>第三，在应用程序的开发和设计之初，充分利用骁龙的异构架构的优势，比如充分利用专用的CPU、GPU、NPU和音频、视频等核心所具备的优势，能够使骁龙本以更低的功耗运行这些应用，给广大消费者带来更多优秀体验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_ccdf049b5157498e8924dec6059ff935@1547419282_oswg608698oswg1619oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>换句话说，当前双方的工作目标其实和Apple的Rosseta 2有些类似：<strong>先想办法提供应用转译效率，</strong>保证应用确实能运行，<strong>之后再利用骁龙X Elite平台的特性吸引开发者进行原生应用开发。</strong></p><p>Kedar Kondap还表示：</p><blockquote><p>高通正在加大的投入，来确保整个生态系统已经准备就绪，这样的投入包括针对软件开发者、针对工具套件、针对SDK，我们确保为合作伙伴提供一个开发者平台以用于开发他们的应用程序。</p><p>除此之外，我们还与中国的许多生态系统合作伙伴进行合作，确保我们的应用程序也能够支持中国特定的支付方式，并确保这些支付方式能够与骁龙本兼容。我们正在与中国生态系统合作伙伴合作，以确保中国消费者的需求能够得到有效满足。</p></blockquote><h2>04 为什么笔记本需要AI？</h2><p>尽管主题演讲上Windows对与骁龙X Elite适配的承诺在我看来还有些许“画饼”的味道，毕竟微软出尔反尔的情况并不少见。但从个人笔记本电脑发展的大方向来看，<strong>NPU与AI的加入确实为沉闷的笔记本电脑市场带来了不少活力。</strong></p><p>很多时候，人们对AI技术的认知还停留在生成式AI的阶段，认为AI的作用也就是画画图，聊聊天。但将AI用作实际的“生产工具”只是对AI最初级的作用，AI大语言模型拥有惊人的数据处理、学习能力，<strong>在未来AI的身份完全可以从“执行层”提升为“决策层”。</strong></p><p>以“好莱坞编剧罢工”为例子，编剧们担心生成式AI用更快的创作速度与更低的错误成本取代了“人脑智能”编剧，这其实就是AI错误定位的结果。在合理的设想下，AI的作用应该是分析过去电影和用户评价、理解剧本、并为编剧提供优秀的剧本方向。而不是像现在的生成式AI一样，人工丢几个关键词进去，自动生成一个看起来像模像样，其实逻辑不通的剧本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_2facee583b40481ea8929a23121e8f2b@1547419282_oswg827566oswg1619oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：雷科技</p><p>在过去，人工智能离不开CUDA和GPU，所以我们无法在笔记本中使用高性能的AI工具。但在NPU的加入却从根本解决了笔记本无AI的痛点。<strong>可以预见的是，未来还将有越来越多的移动处理器通过NPU的方式提供原生AI运算支持，而AI也将像电器革命中的洗衣机一样，真正释放人类无与伦比的创意和生产力。</strong></p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/3Sy0zcDZyZhj43br0SMYLw" rel="noopener noreferrer nofollow" target="_blank">“雷科技”（ID:leitech）</a>，作者：雷科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498460758431875</id>
            <title>蔡崇信向左，拜登向右</title>
            <link>https://www.36kr.com/p/2498460758431875</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498460758431875</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 23:30:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开放, 人工智能, 垄断, 初创公司
<br>
<br>
总结: 美国政府签署行政命令监管人工智能的发展，引发了对于开放人工智能生态系统和防止垄断的讨论。初创公司担心云计算厂商的垄断会阻碍创新，希望政府能够帮助构建公平、开放和竞争的生态系统。然而，也有人担心政府的监管制度可能固化上位者的优势和权力。 </div>
                        <hr>
                    
                    <p>2023云栖大会现场，阿里巴巴集团主席蔡崇信称，智能化时代正在开启，AI将成为各行业新型生产力，目前中国80%的科技企业和一半的大模型公司都跑在阿里云上。蔡崇信在致辞中强调最多的词是“开放”。蔡崇信说：“我们坚信，不开放就没有生态，没有生态就没有未来。而后，中国工程院院士、阿里云创始人王坚则以《云计算的第三次浪潮》为主题发表的讲话，他相信云计算将如电力一般，作为一个公共服务的存在、作为一个基础设施的存在，拥有非常久远的生命力。</p><p>如果按照这样一个设想，未来的算力需求将和如今不再能同日而语。但美国有关未来的预期和中国当前的情况却开始显得有些不同。</p><p>北京时间10月30日晚间，美国总统拜登签署了一项关于人工智能（AI）的行政命令，为AI建立安全和隐私保护标准，并要求开发人员对AI新模型进行安全测试。这意味着，美国将全面监管人工智能的研发。由此，在美国引发了一场针对人工智能的大讨论，并让那些希望撼动科技行业现有格局的初创公司感到不安。</p><p>帮助企业构建人工智能工具的初创公司Dataiku的联合创始人弗洛里安·杜埃托在一封电子邮件中向《福布斯》表示：“对于政府来说，培育一个开放的人工智能生态系统至关重要，尤其是对初创公司的发展而言。云计算厂商在投入巨资后垄断人工智能领域，这一情形无异于电网私有化。这种垄断会扼杀创新，阻碍小规模企业为人工智能的发展做出贡献。”</p><p>美国总统乔·拜登（Joe Biden）新颁布的行政命令对人工智能技术做出了规定，人工智能初创企业对此表示欢迎，但部分首席执行官担心该行政命令是否会阻碍小规模公司的发展且扼杀创新。</p><p>作为行政令的一部分，任何公司在建立可能对国家安全构成风险的人工智能模型时都必须向美国政府做出披露，并分享为确保该模型符合美国国家标准与技术研究院（National Institute of Standards and Technology）制定的联邦标准而采取了哪些措施及相关数据。不过，分享发布前测试数据的这一要求仅适用于尚未发布的模型——其中包括 GPT-5，即广受欢迎的 GPT-4 备受期待的后续模型。</p><p>白宫人工智能特别顾问本·布坎南（Ben Buchanan）告诉《福布斯》，目前已经投入使用的人工智能模型，如GPT-4或谷歌的Bard仍然受到该行政命令其他要素的约束，包括“公平条款、抵制歧视、保护消费者和工人”。不过，他补充说，到目前为止，“据我所知，我们还没有看到因为启用Chat GPT-4而引发的灾难。”</p><p>布坎南表示，该行政令的另一个目的是在美国联邦政府中掀起一场人工智能雇员的招聘热潮，以便招聘“数十到数百名”以人工智能为重点的员工。此外，它还表示将减少人工智能领域国际员工的移民障碍。布坎南说，这并不包括提高H1B签证的数量上限，但他指出，对于从事“关键新兴技术”工作的外来人口来说，整个签证流程将变得更加顺畅。</p><p>该行政令还为美国政府使用人工智能制定了指导方针和标准。为了消除人们对人工智能可能被用来歧视公民、毁坏关键基础设施或用于战争的担忧，该行政令还要求联邦机构在部署大型人工智能模型和项目之前对其进行评估。从国防部到司法部的多个美国联邦机构也需要进行研究，概述他们计划如何将人工智能纳入其职能。与安全问题有关的一些条款预计将在未来90天内生效。</p><p>这一行政令是拜登政府迄今为止在为人工智能的发展建立功能性护栏，同时巩固美国作为人工智能政策领导者地位方面所做出的范围最广的尝试。在其上任之初，拜登政府曾承诺要控制大型科技公司，但在执行反垄断法规方面却遭遇失败，在解决长期困扰科技界的隐私问题方面也收效甚微。本次颁发的行政令则明确呼吁国会通过两党数据隐私立法，并承认人工智能加剧了侵犯性数据收集的动机。</p><p>拜登在签署仪式上说：“公司必须告诉政府，它们正在开发哪些大规模的人工智能系统，并分享严格的独立测试结果，以证明它们不会对美国人民构成国家安全或安全风险。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_9bf771a275b44103b7b0f41a4ccff404@000000_oswg53504oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>白宫的行政命令为人工智能的开发和使用设置了警戒线，其中最值得关注的是，在未来的大型语言模型（包括OpenAI的GPT-5和谷歌的Gemini）向公众发布之前，白宫将对其进行监督。</p><p>这一行政命令的颁布将拜登政府与科技行业为期数月的讨论推向高潮。自去年11月ChatGPT的火热发布以来，科技行业已将大量资金和资源投入到人工智能领域中。今年5月，拜登和副总统卡玛拉·哈里斯（Kamala Harris）会见了谷歌、Anthropic、微软和OpenAI这四家行业领先公司的首席执行官，以上每家公司都在人工智能研发上投入了数十亿美元甚至更多资金。OpenAI得到了微软100亿美元的投资支持，而Anthropic则从亚马逊和谷歌获得了数十亿美元的资金。</p><h2>01 这会造成新的垄断吗？</h2><p>“<strong>云计算厂商在投入巨资后垄断人工智能领域，这一情形无异于电网私有化。</strong>”</p><p>——Dataiku联合创始人兼首席执行官</p><p>弗洛里安·杜埃托（Florian Douetteau）</p><p>但是，拜登新签署的行政命令却让那些希望撼动科技行业现有格局的初创公司感到不安。帮助企业构建人工智能工具的初创公司Dataiku的联合创始人弗洛里安·杜埃托在一封电子邮件中向《福布斯》表示：“对于政府来说，培育一个开放的人工智能生态系统至关重要，尤其是对初创公司的发展而言。云计算厂商在投入巨资后垄断人工智能领域，这一情形无异于电网私有化。这种垄断会扼杀创新，阻碍小规模企业为人工智能的发展做出贡献。”</p><p>行政命令包括一项声明，即联邦政府将通过帮助研发者和小规模企业获取技术资源和商业化机会来促进构建“公平、开放和竞争”的生态系统。杜埃托说，他相信这项新增的规定可能会有所帮助，因为它可能会让联邦贸易委员会“在构建生态系统的早期阶段行使监管权力”。</p><p>自创人工智能模型的初创公司Cohere的联合创始人艾丹·戈麦斯（Aidan Gomez）在发送给《福布斯》的一封电子邮件中表示：“我们必须保持谨慎，确保政府构建的监管制度不会固化上位者们的优势和权力。”</p><p>“<strong>美国是在冒险精神而非繁文缛节之上建立起来的。</strong>”</p><p>——Hebbia联合创始人兼首席执行官&nbsp;</p><p>乔治·西武尔卡（George Sivulka）</p><p>戈麦斯出席了参议员查尔斯·舒默（Chuck Schumer）主持的人工智能洞察力论坛，戈麦斯也是自愿向白宫承诺管理人工智能风险的15位科技公司高管之一，于他而言，这项行政命令是有利于行业内现有企业还是小型初创企业，“将在很大程度上取决于实施和执行情况”。从历史上看，拜登政府一直致力于在科技行业执行反垄断法。戈麦斯写道：“我知道政府非常清楚寡头垄断的态势会阻碍发展活力，所以我对此持乐观态度。”</p><p>其他人则指出，增加监管负担可能会使现有公司受益，因为它们更容易负担相关费用。搜索引擎研发初创公司Hebbia的创始人乔治·西武尔卡在一封电子邮件中写道：“过度监管，比如对模型大小的限制和严格的报告要求，将形成只有大型垄断企业才能克服的障碍。美国是在冒险精神而非繁文缛节之上建立起来的。”</p><p>网络安全软件公司Abnormal Security的联合创始人埃文·雷泽（Evan Reiser）在一封电子邮件中写道：新成立的初创公司可能不具备“像人工智能巨头那样满足大量测试和监管要求”所需的资金。他们中的许多人目前正在使用开源模型构建人工智能模型和工具，这些模型往往使用成本更低，定制起来也更灵活。目前还不清楚行政命令如何适用于开源人工智能，不过法律科技初创公司Robin AI的联合创始人理查德·罗宾逊（Richard Robinson）在一封电子邮件中表示，针对Meta等大型开源模型提供商的监管可能会对初创公司形成间接影响：“如果这些私有微调模型需要接受安全监管，那么几乎可以肯定的是，企业快速构建和部署新模型的能力会受到限制。”</p><p>白宫人工智能特别顾问本·布坎南（Ben Buchanan）驳斥了行政命令符合科技公司利益的说法。他向《福布斯》表示：“我不确定大型科技公司是否对这一行政命令的制定产生了重大影响。当然，这种影响不会超过民间社会、学术界和其他人士所产生的影响，甚至可能比后者的影响更小。这个案例展示了人工智能生态系统的高度活跃性，我们希望这种状态能继续保持下去。”</p><h2>02 拜登的行政令与欧盟的人工智能法案相比如何？</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_7d6207be2f40466fb24ef1d7d96ca2f2@000000_oswg43381oswg959oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2020年2月19日，比利时布鲁塞尔。欧盟“适应数字时代的欧洲”委员会执行副主席Margrethe Vestager(左)和欧盟内部市场专员Thierry Breton在比利时布鲁塞尔欧盟委员会总部Berlaymont与媒体交谈。图片来源：Thierry Monasse/Getty Images&nbsp;</p><p>欧盟提出的人工智能法案采取了类似方法监管人工智能。与欧盟的人工智能法案相比，拜登的行政命令存在一些关键差异：</p><p><strong>欧盟法案仅定义了需要监管的高风险人工智能，而美国的行政令覆盖了所有人工智能领域。</strong></p><p><strong>对于高风险人工智能，欧盟采取了强制性的合规评估和欧盟批准的方式。而美国更依赖于企业自愿向政府披露信息。</strong></p><p><strong>欧盟法案对社会评分和面部识别等用途持谨慎态度，而美国的行政令侧重于预防危害，没有明确禁止特定用途。</strong></p><p><strong>相较于欧盟法案对研发和技能采取的保守态度，美国的行政令强调研究和人才培养。</strong></p><p>尽管两者都提出了国际合作的设想，但美国的行政令在对国际组织合作方面的需求更加明确。</p><p>虽然美国的行政令涉及范围更广，欧盟的法案更侧重于合规性，两者都致力于在创新与伦理责任之间取得平衡，不过在监管策略上存在差异。</p><p>作为民主科技的关键力量，它们在值得信赖的人工智能方面的联合领导将在全球产生重要影响。如果二者的管理方法能够趋于一致，将为全球范围内的道德科技树立标杆。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzIwODU2NjQ5Mw==&amp;mid=2247567422&amp;idx=1&amp;sn=b224d193ec4c52af3121286ff3b558b5&amp;chksm=9702a98ca075209ac6179e0ebb88ae66fb398b5747cf6ba6fbb0edc8d50b0c85e4b4227d8f42&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“福布斯”（ID：forbes_china）</a>，作者：Forbes，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498445402249351</id>
            <title>大模型亏损不断，科技公司盯上了AI智能学习机</title>
            <link>https://www.36kr.com/p/2498445402249351</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498445402249351</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 23:23:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百度世界大会, 小度青禾学习一体机, 天猫精灵真智能大屏护眼学习机Z20, AI智能学习机
<br>
<br>
总结: 2023年百度世界大会上，百度推出了小度青禾学习一体机，结合大模型技术和个性化教育，致力于成为孩子的AI家庭老师。随后，天猫精灵也推出了真智能大屏护眼学习机Z20，具备多模态AI感知能力。这两款AI智能学习机的推出并非偶然，而是因为教育信息化行业的发展和政策的推动。然而，由于价格昂贵和家长对AI学习机的认可度不高，AI智能学习机的普及率并不高，难以成为科技公司大模型商业闭环的理想终端。 </div>
                        <hr>
                    
                    <p>2023年10月17日举办的2023百度世界大会上，百度推出了小度青禾学习一体机，将大模型技术、教学方法和个性化教育结合，致力于成为孩子一对一的AI家庭老师。</p><p>第二天，阿里旗下天猫精灵也推出了真智能大屏护眼学习机Z20，兼具大模型和多模态AI感知能力，可以承载「精准强化」和「自主探索」两种学习方式。</p><p><strong>百度和阿里相继推出AI智能学习机绝非偶然。</strong>随着技术的成熟以及政策的大力推动，教育信息化日渐成为教育行业的新潮流。科技公司正积极布局的大模型技术，恰好契合了教育信息化的时代需求。</p><p>而随着双十一的来临，经主播带货，学习机也确实拥有空前的热度。2023年10月28日，「北大才女」 刘媛媛在抖音带货学而思学习机，售价5199元，尚未讲解结束，就被消费者抢购一空。</p><p>不过值得注意的是，整体而言，由于价格不菲、在教学上的价值尚未被家长普遍认可，目前泛AI终端的渗透率并不高。这或许也意味着，AI智能学习机很难成为科技公司大模型打通商业闭环的理想终端。</p><h2>01 政策鼓励，教育信息化产业飞速发展</h2><p>科技公司之所以纷纷「跨行」，切入教育赛道，很大程度上都是因为随着技术的成熟以及政策的推动，教育信息化行业正飞速发展。</p><p>当前，中国教育产业存在的最大问题，<strong>就是各地区经济发展水平不一的背景下，教育资源分配不平等。</strong></p><p>互联网、AI等技术成熟催生出的教育信息化，具备突破时空限制、快速复制传播、呈现手段丰富等优势，因而可以促进教育公平、提高教育质量。</p><p>比如，因教育资源有限，传统教育模式或许很难照顾到贫困、生理缺陷、语言阅读障碍等学生，反观规模化的AI技术则可以低成本地给这些学生提供个性化的辅助教学，进而填补教育鸿沟。</p><p><strong>正因为看到教育信息化拥有上述优势，有关部门正积极推动相关产业发展。</strong>2018年，教育部印发的《教育信息化2.0行动计划》显示，「因应信息技术特别是智能技术的发展，积极推进「互联网+教育」，坚持信息技术与教育教学深度融合的核心理念，坚持应用驱动和机制创新的基本方针，建立健全教育信息化可持续发展机制」。</p><p>无独有偶，国务院印发的《新一代人工智能发展规划》也进一步明确表示，「利用智能技术加快推动人才培养模式、教学方法改革，构建包含智能学习、交互式学习的新型教育体系」。</p><p>一方面，教育信息化行业可以实现教育平权，另一方面，有关部门也大力推动教育信息化行业发展，相关产业拥有极为高远的想象空间。</p><blockquote><p>中商产业研究院披露的数据显示，2016年-2021年，中国教育信息化市场规模从2947亿元增长至4724亿元，复合年增长率为9.9%。预计2023年，相关市场规模将达5573亿元，同比增长8.28%。</p></blockquote><p>由于本身就处于信息化赛道，趁着教育信息化行业蓬勃发展的热潮，<strong>诸多互联网、科技企业其实早已开始积极布局教育信息化相关业务。</strong></p><p>早在2018年，百度就发布了百度教育大脑3.0，基于AI、大数据和云计算，赋能教育产品和教育场景。至于阿里，在疫情期间，更是靠钉钉教育服务，满足了广大学子「停课不停学」的需求。</p><h2>02 大模型亏损不断，巨头纷纷布局学习机</h2><p>2023年以来，伴随着ChatGPT爆火，诸多科技公司都已开始积极布局AI大模型相关产品。</p><p>2023年3月16日，百度发布了大语言模型、生成式AI产品「文心一言」。一个月后，阿里也推出了一个超大规模的语言模型「通义千问」。</p><p>2023年5月，中国科学技术信息研究所披露的数据显示，国内已经发布了79个大模型，堪称「百模大战」。</p><p>诸多科技公司纷纷紧锣密鼓地布局新技术无可厚非，但问题是，<strong>由于大模型的训练成本异常高昂，目前大部分大模型相关企业都面临亏损的困局。</strong></p><blockquote><p>OpenAI披露的数据显示，GPT-3的知识来自3000亿单词的训练语料库。国盛证券测算，GPT-3训练一次的费用约为140万美元。《财富》杂志披露的数据显示，2022年，OpenAI亏损5.45亿美元。</p></blockquote><p>不止OpneAI，《华尔街日报》报道，微软首批生成式AI产品中的GitHub Copilot也深陷亏损泥潭，该业务每个月向使用者收取10美元，但平均每个月在每个用户身上还要倒贴20美元，有些用户甚至高达80美元。</p><p>尽管国内的大模型相关企业并没有详细披露自家大模型业务的具体财务数据，但在当前的形势下，大部分企业或许也都难以实现盈利。2023年10月25日举办的高通峰会上，荣耀CEO赵明就点评道，「今天还没有谁说网络大模型已经是盈利的，因为算力的消耗还是太多了」。</p><p><strong>在此背景下，诸多科技公司自然需要不断探索前沿的业务模式，以打通大模型商业闭环。</strong>比如，华为盘古大模型致力于政务、金融、制造等行业；百度的文心一言也积极和车企展开合作，接入长安、吉利、岚图等车机中。</p><p>由于此前部分互联网企业在教育信息化赛道有一定的积累，教育硬件自然也成为相关企业AI大模型落地的关键一环。也正因此，最近一段时间，百度、阿里等企业紧锣密鼓地推出AI智能学习机产品。</p><h2>03 普及率不及4%，AI学习机难救大模型</h2><p>尽管政策端正大力推动教育信息化产业发展，但AI相关终端的市场表现其实并不十分亮眼。</p><p>艾瑞咨询披露的数据显示，2022年，中国在线教育市场规模为5825亿元，<strong>泛AI产品的市场规模仅为211.1亿元，渗透率仅为3.6%。</strong></p><p>在此背景下，部分教育企业的AI相关终端业务也难以斩获亮眼的业绩。以读书郎为例，2023年上半年，其营收为1.26亿元，同比下跌52%，其中学生个人平板营收1.04亿元，同比下跌55%。</p><blockquote><p>无独有偶，2023年上半年，科大讯飞营收78.42亿元，同比下跌2.26%，其中教育产品和服务营收22.85亿元，仅同比增长3.63%。</p></blockquote><p>之所以中国教育行业泛AI产品的渗透率不高，一方面是因为相关产品的价格昂贵，另一方面，也是因为AI在教学上的价值尚未被家长普遍认可，直接付费意愿不强。</p><p>以小度青禾学习一体机为例，该产品的零售价高达9999元。如此高昂的费用，对比普通家教并不具备吸引力，更何况，AI智能学习机的效用还没有得到市场层面的有力印证，广大家长自然很难接受相关产品。</p><p>事实上，正因为消费者市场的反馈不理想，部分教育企业甚至开始另辟蹊径，希望通过AI智习室，盘活自家AI学习机的利用率。</p><p>一方面，AI智习室是教育企业在智能硬件设备、教育信息化等领域经历多轮技术沉淀和市场检验后的「资源集合体」。所谓的「精准学、精准提升」等概念在几年前才初具雏形，而人工智能、大数据等技术的发展使得AI智能辅学逐渐呈现出了一定的市场竞争力。最终落地到AI智习室这一产品上，则使得学生可以脱离真人老师在AI的辅助下进行学习。</p><p>而在另一方面，由于校外学科培训受「双减」政策严格限制，C端补课意愿不减，一时间释放了大量需求。AI智习室一定程度上成为了「校外补习」的平替，也成为一些机构转型的缓冲地带。</p><p>2023年8月9日，读书郎2023年AI智习室项目招商会召开，全国共35个运营中心与读书郎签约。据悉，读书郎的AI智习室提供线下学习场地，学生可通过读书郎平板在个性化精准提升系统学习。</p><p>虽然AI智习室的商业前景难以预测，但可以确定的一点是，<strong>纯粹意义上的AI智能学习机业务，目前还难以打通商业闭环。</strong></p><p>总而言之，科技公司不约而同地推出AI智能学习机产品绝非偶然。一方面，这些企业看到了教育信息化的热潮，自家的大模型技术十分契合时代的需求；另一方面大模型业务亏损的现实，也要求科技公司需要积极探索商业闭环。因此，AI智能学习机成为教育行业的一个风口。</p><p>但问题是，受限于价格和认知，AI智能学习机的市场接受度很有限，本行业内的玩家都需要不断探索其他业务模式，以推广相关产品。</p><p>这似乎预示着，科技公司希望借AI智能学习机打通大模型商业闭环，并不会如理想般顺遂。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg2ODA0ODkwNA==&amp;mid=2247520950&amp;idx=1&amp;sn=392e260c02df9074c827005615ba18b0&amp;chksm=ceb09bd1f9c712c7d048a14e5eae28bc28a1de7dc3d004c89e623e09edd2159d577cf3c92e6b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“多鲸”（ID：DJEDUINNO）</a>，作者：善水，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498326995804040</id>
            <title>从手机配件到智能完全体，Apple Watch Ultra 2体验</title>
            <link>https://www.36kr.com/p/2498326995804040</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498326995804040</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 23:14:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Apple Watch, 乔布斯, 升级, 独立性
<br>
<br>
总结: Apple Watch是乔布斯去世后，苹果公司推出的一个全新形态产品，经过多次升级，已经成为一个具有独立性的智能设备。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_22efaed7475b46d0882d45f765f455cd@453363432_oswg144080oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Apple Watch是乔布斯去世后，苹果公司推出的一个全新形态产品，初代Apple Watch是在2014年9月发布，第二年的4月份才开卖，之后就是每年稳定地升级，现在已经到了第九代 。</p><p>有很多声音认为明年发展到第十代的Apple Watch将会有大招，就像iPhone的“iPhone X”时刻，那是不是表示今年升级推出的Apple Watch Series 9和Ultra 2就乏善可陈了呢？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_1e4ceb6c3e1c44889c706fee609ad231@453363432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在使用Apple Watch Ultra 2几周时间后，我发现在这代Ultra 2看似常规的升级中，看到了两个发现：一是Apple Watch已经通过小步升级的量变叠加，从一开始的iPhone配件，进化为了一个具有很强独立性的智能设备；这从电话通讯、健身、娱乐以及很多个独立应用都能体会到这点。</p><p>第二个发现也是基于前面这点，我貌似看到了Apple Watch可见的未来，会怎样继续进化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_d5a8a7def3ae4eb7a1276615fb667d76@453363432_oswg42952oswg1000oswg367_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Apple Watch Ultra 2是苹果首批碳中和产品</p><p>下面就边说我的体验感受，边展开聊聊这两点。</p><h2>01 从手机配件到智能完全体</h2><p>不得不说，Apple Watch仍然是依附在iOS生态的产品，因为它只有和一台iPhone配对后才能正常使用。</p><p>在新手表进行数据备份和迁移的时候，我拨打了苹果售后技术支持，询问哪一种方式是最简单稳定的，技术支持人员电话中也不忘跟我强调，“Apple Watch是iPhone的配件”，所以你甚至看不到它的单独iCloud备份文件，而是存在于你iPhone的备份文件里。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_82872329878e4fb3a8df7d564b8b432f@453363432_oswg58924oswg1000oswg550_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过它的很多功能和体验已经变得越来越独立，我举几个例子。</p><p>1、<strong>通信</strong>，开通eSIM服务后，Apple Watch就是一台独立通讯设备，能接、打电话，也能发短信，每个月10元费用并不算贵。</p><p>2、<strong>移动支付</strong>，现在手机已经成为我们的钱包，Apple Watch上可以用Apple Pay、支付宝、微信支付都能平滑在腕上使用，有了移动网络，更是可以不依赖iPhone。</p><p>3、<strong>微信</strong>，现在微信应该是是大家日常使用率最高的App，这几天我尝试在Ultra 2上用微信，发现完全无压力，但之前不太敢这么玩，因为有几个比较鸡肋的地方，屏幕太小、输入不方便、手表处理器还是太慢、电池不扛使用。</p><p>作为加强版Apple Watch的Ultra 2在这几方面都强不少，4.9英寸屏幕能比较好地阅读文字、升级S9 SiP和新的神经网络引擎后文字语音输入识别速度快了不少，这颗新的处理器跑微信也很顺滑，最后就是电池，564mAh的电池也很扛使，后面我会具体说。</p><p>4、<strong>听歌娱乐</strong>，现在电池更大、存储容量更大（从32GB升级为64GB）的的Ultra 2完全可以单做一台腕上iPod音乐播放器来用，它跟AirPods的配合也很丝滑，只要同一个Apple ID，音乐从哪里播放，AirPods就会自动切换到相应设备。</p><p>上面四个例子其实主要是说在Apple Watch上平替手机功能的例子，你会发现，乔布斯当年发布初代iPhone时说的那番话，“一部手机、一个音乐播放器、一个网络浏览设备”，现在套在Apple Watch上，完全不违和。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6cdb1b1d58f2446c9cf9f9a975fba127@453363432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Apple Watch Ultra 2的背面和侧面分布着大量传感器</p><p>别忘了它还有一堆独立的功能群，比如<strong>健康和运动相关的：</strong>体能训练记录、正念、心率、血氧、听力、用药提醒、睡眠监测、生理期跟踪；<strong>小工具：</strong>计时、日历、计算器、提醒事项、天气、地图、相册等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_40a38b5bd87e436598443883c990530a@453363432_oswg138442oswg1000oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Apple Watch现在的基本应用已经非常丰富</p><p>所以经过9年发展之后，你会发现，Apple Watch哪里还是个手机配件，早已是一个独立的存在，作为手机的配件身份更多的是iPhone更需要Apple Watch来提供更多的使用方便，比如方便地接、挂电话，在你一时找不到iPhone的时候，快速地查找手机。</p><h2>02 Apple Watch Ultra 2的升级体验</h2><p>从Ultra初代到Ultra 2属于常规升级，所以外观的变化几乎为零，变化的更多的是内在的硬件。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_c80776e0018e4b5db8f06929b690a078@453363432_oswg31322oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Apple Watch Ultra 2</p><p>有些不仔细观察，你可能不会发现这些改变带来的变化，比如亮度的变化，最暗和最亮的范围分别扩大了50%，即户外最大亮度从2000尼特提升到3000尼特，夜晚最暗的亮度从2尼特变为1尼特。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_ada9c2b8caea4bb0899bcb8ac19dc247@453363432_oswg182528oswg1000oswg550_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲下午两点的烈日下显示非常清晰</p><p>有些变化感知就很明显了，比如我前面说的在Ultra 2上刷微信，经管我有几百个对话列表，打开也很快；语音输入很流畅，关键是，现在它支持不联网的本地Siri了，也是更独立的表现。</p><p>升级第二代超宽带技术芯片后，手机找iPhone现在可以感知距离了，但是方位你得试，如果能有个方向指示，就更完美了。</p><p>界面上有些微小的变动，最明显的是新增的有左右两个刻度显示的Ultra独占表盘，实用、好看也很硬核的感觉；指南针多了个立体视图，在航点查看的时候，感觉会更直观一些。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_8320be7ff2b4438b8f05c2a144a06d6c@453363432_oswg92850oswg1000oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>▲Apple Watch Ultra 2的指南针航点功能很好用</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_40741039bda9485e96e449ed4c875903@453363432_oswg121663oswg1000oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Apple Watch专属的多功能表盘实用性很强</p><h2>03 面向未来的双指互点</h2><p>Ultra 2和S9系列Apple Watch功能升级的一个压轴是双指互点功能，最新的Watch OS 10.1系统已经推送了这个新功能。</p><p>这个功能的逻辑其实很简单，就是通过双指互捏双击来完成一个确认动作，用来实现单手操作，比如接听/挂断电话、控制音乐播放等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_586f241a85b64f7ebdf79b4dc0bd719b@453363432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲双指互点操作上手很容易</p><p>简单的操作背后是一整套技术的组合，一贯的苹果逻辑，用复杂的技术实现简单的体验。</p><p>要让双指双击准确地被侦测，同时利用到了更快的神经网络引擎、内置加速感应器、陀螺仪和光学心率传感器输入的数据，算法能够识别双指互点两下手势时手腕轻微运动的标志性特征和血流变化，这些计算全部由新的4核神经网络引擎完成。</p><p>听着很先进，实际用起来，大部分凑效，偶尔也有不灵的情况，除了小拇指，中间的三个指头都可以配合大拇指来进行双指互点操作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_a18a55a607d943aab11fb9b04022996d@453363432_oswg65574oswg1000oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲双指互点现在还只是单一命令，如果有选择指令就更好了</p><p>不过用下来，我发现这个功能暂时还不是一个完全体，目前只支持双击确认一个操作项，比如来电话了你智能互点接听而不能挂断、来信息了只能触发回复不能触发忽略，官方说法是选择最“主要/优先的操作”，如果能增加一个指令，比如双指三击进行选项切换，双击进行选择，这样功能的适用范围显然会大很多。</p><p>希望苹果会考虑往这方面升级。</p><h2>04 关于电池和续航</h2><p>我从初代Apple Watch就开始长期使用，但其实一直不算重度使用，核心原因还是续航问题。</p><p>现在一些安卓手表动辄续航个把星期，Apple Watch一天一充的用法还是让你不太会有重度使用的信心。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_db89af8a801d46e1a49e4fbc4e537d9d@453363432_oswg37817oswg1000oswg550_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Apple Watch Ultra 2</p><p>但Ultra 2好像解决掉了我这个顾虑，一个是电池本身容量比标准版大了不少，Ultra 2的电池容量564mAh，只比上代542mAh增加了4%，但是相比41 毫米和 45 毫米 Apple Watch Series 9 的电池容量282mAh和308 mAh几乎是翻倍的存在，所以续航也更有底气。</p><p>这是我做的两次典型使用记录，第一次是正常模式下，从99%用到1%，持续使用了1天20小时47分，也就是44.78小时，其中有一天有用到2个小时40分钟的户外徒步记录功能和指南针航点记录功能，差一点就够用两天了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_92d4f8ff762d4a8a8ea816ad8adcd0cb@453363432_oswg86990oswg1000oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲正常模式连续使用时间</p><p>第二次是开启省电模式，从94%用到1%，使用了3天5小时36分，也就是77.6小时，可以使用超过3天。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_f56fc6199c874fea85106134885ad172@453363432_oswg99205oswg1000oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲低电量模式连续使用时间</p><p>日常使用一两天没问题，关键是现在Apple Watch其实有个续航隐藏技能，那就是低电量模式，Apple Watch的低电量模式并不会关掉核心功能，只是会限制网络连接、关闭后台心率测量血氧测量和双指互点这些不是最常用的功能，开启低电量模式后，我发现用3天基本没问题，一个周末或短途出差不带充电器完全没问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_fda414e69e834c258533d84324816964@453363432_oswg92723oswg1000oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Apple Watch的低电量模式大部分功能不受影响</p><p>要让Apple Watch续航更靠谱还有一个小技巧，就是关闭全天候显示，虽然Apple Watch现在具备了全天候显示的能力，但其实大部分时间咱们是不会盯着手表看的，抬腕显示已经很方便，关键是省电啊。</p><p>另外在充电方面，Apple Watch在上一代提升充电功率后，充电速度有提升，我试了下，从0～100%电量，前面50%大约要1个小时，后面50%只要45分钟，也就是说后面50%的充电速度好像更快，如果平时我们是从30～50%电量充的话，1个小时左右就能充满电。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_1fb7ed216038431899e0857c167fc137@453363432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>05 自成一体的Apple Watch交互逻辑</h2><p>发展到现在Apple Watch已经形成了自成一套的交互逻辑，由一块屏、三个按钮（Ultra多一个，一共三个）、还有语音操作（Siri）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_3b37f34b54944648b076e8949a796cfc@453363432_oswg45985oswg1000oswg550_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Apple Watch Ultra 2</p><p>跟手机已经有很多差异，比如Apple Watch的Siri可以通过抬腕直接说话，比iPhone来得更快；屏幕可以下滑查看通知、上滑查看小组件。</p><p><strong>左侧的橙色键功能有：</strong>单按（快捷键）、长按（关机或紧急呼叫）。</p><p><strong>表冠按钮和旋钮可以分别实现：</strong>单机回程序列表、双击切换多任务、长按Siri、上滑快速查看小组件。</p><p><strong>电源键可以实现：</strong>单机打开控制中心、双击启动支付、长按（关机或紧急呼叫）和橙色键一样。</p><p>发现没有，可玩性非常高，而且有些功能没有完全用尽，比如表冠直接往下滑、双击橙色按钮、屏幕左右滑动都没有匹配任何功能，希望苹果可以考虑后面让用户可以自定义这几个操作的功能。</p><h2>06 结语：Apple Watch还会怎样发展？</h2><p>我先说结论，Apple Watch的未来一定是更独立，更强大的智能终端，它可以是iPhone的好兄弟，但也是一个具备更多独立功能的终端。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_bc7e1f9bb9cd4dc6bcfa0849d4bfaf6e@453363432_oswg59357oswg1000oswg367_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲碳中和新款野径回环表带很柔顺亲肤</p><p>不过有一点是，今天我主要聊的Ultra 2的体验，Apple Watch Ultra是我认为现在能够更完整展现Apple Watch独立设备价值的产品，但是它有着更贵的价格、更大的个头，不一定适合所有人，但它更大的电池、更大的屏幕适合很多想日常使用更多Apple Watch的用户。</p><p>这样一看，Apple Watch的未来是不是就不言而明，让Ultra的完整体验出现在一款更轻便的Apple Watch上，也许就是未来，不知道Apple Watch X会不会成为这样的理想型，我希望是。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/uoI_7tCod9OasyYHklqhdw" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID:zhidxcom）</a>，作者：智东西，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498235104878723</id>
            <title>美国发布最全AI监管原则 剑指主导全球AI发展格局</title>
            <link>https://www.36kr.com/p/2498235104878723</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498235104878723</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 23:09:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美国总统拜登, 人工智能监管原则, 科技开发, 数据隐私, 竞争格局
<br>
<br>
总结: 美国总统拜登签署了迄今为止最全面的人工智能监管原则，旨在确保美国在科技开发方面领先地位，保护数据隐私和网络安全，防止歧视，加强公平性，并密切监控行业竞争格局的快速增长。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_91d3d991819f43f3b17f001a926d7e6b@5655031_oswg333511oswg1080oswg568_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2023年10月30日，美国总统拜登签署了<strong>美国迄今为止最全面的人工智能监管原则</strong>：指示所有类型的政府机构确保美国在技术开发方面处于领先地位，同时指示各机构制定标准，以确保数据隐私和网络安全、防止歧视、加强公平性，密切监控快速增长行业的竞争格局。</p><p>用拜登自己的话说，人工智能是“我们这个时代最重要的技术”。</p><p>这项命令酝酿了数月之久，它代表着对<strong>这项技术强加国家秩序最重大的努力。</strong>该行政命令将使美国密切关注私营部门开发强大的人工智能系统。它包括要求公司向联邦政府提交报告，详细说明他们如何训练和测试所谓的“双重用途基础模型”，它定义的这一类别包括最强大的新人工智能系统等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6ffb37269196494884aba5c38f7599b7@5655031_oswg47557oswg554oswg226_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以下是关于该行政命令的重要事项：</p><h2>一、拜登的行政命令的效力如何？</h2><p>这项行政新令超越了 OpenAI、谷歌和 Meta等公司今年早些时候做出的自愿承诺，但它仍旧更强调建立最佳实践和标准，而不是如何甚至是否执行新指令。也就是说，<strong>该命令并不具有法律效力。</strong></p><p>该命令“呼吁”美国国家标准技术研究所（NIST）在模型推出之前为广泛的“红队”测试制定标准，即旨在破坏模型以暴露漏洞的测试。然而，该行政命令并不要求人工智能公司遵守 NIST 标准或测试方法。行政命令的许多方面仍然依赖于科技公司的自愿合作。</p><p>但该行政令将向十多个机构发布规模庞大的指令，针对它们处理人工智能系统的情况，各机构有 90 至 240 天的时间来满足行政命令的要求，<strong>新的指导方针通过联邦机构的购买力和执行工具赋予联邦机构在美国市场的影响力。</strong>拜登的命令特别指示联邦贸易委员会（FTC）重点关注人工智能行业的反竞争行为和消费者伤害问题，FTC主席莉娜•汗（Lina Khan）已经公开支持这一行政命令。</p><p>同时，<strong>美国国会已忙于制定立法来应对人工智能的风险和潜力。</strong>尽管一些政界人士表示他们希望在年底前通过有关人工智能的法律，但参议院多数党领袖查克•舒默表示，明年之前可能不会推出广泛的人工智能法案。</p><h2>二、美国要促进网络安全并成为全球领导者</h2><p>该命令表明，白宫将“<strong>国外</strong>”先进网络武器的快速发展视为人工智能带来的最重大风险之一，同时着力发展<strong>本国</strong>人工智能在发现美国政府网络漏洞、对抗对手人工智能的军事使用方面的应用。</p><p>一方面，为了防止强大的人工智能模型落入外国对手手中，该命令将要求开发强大人工智能模型的公司向商务部提供定期报告，概述他们计划如何保护其技术免受间谍或数字颠覆，并要求大型云服务每当外国人租用服务器空间来训练大型人工智能模型时，亚马逊和微软等提供商就会通知政府。</p><p>另一方面，该命令包含要求国家安全委员会和白宫办公厅制定“国家安全备忘录”，指导人工智能和安全方面的进一步行动，确保美国军方和情报界在其任务中安全、道德和有效地使用人工智能，并将指导行动以对抗对手对人工智能的军事使用。</p><p>行政令强调了“在人工智能领域扩大双边、多边和多方利益攸关方的合作”的重要性，旨在<strong>将美国定位为人工智能政策的全球领导者。</strong>在此行政令发布之前，七国集团在10月29日就开发先进人工智能系统的公司行为准则达成一致，各国政府寻求减轻该技术的风险和潜在滥用。英国人工智能安全峰会将于2天后举行，美国这一行政令将为英国峰会定下基调，并可能鼓励欧盟最终确定其人工智能法案，因为该行政命令发出了一个明确的信息，即<strong>美国同意欧盟的许多政策目标。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_fb685602279842ea9b0ab290d5aa269f@5655031_oswg772796oswg944oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>三、标记人工智能生成内容的新规则——解决造假和知识产权问题</h2><p>作为该命令的一部分，商务部将为人工智能生成的标签项目“制定内容认证和水印指南”，人工智能公司将使用该指南来开发白宫希望联邦机构采用的标签和水印工具。</p><p>这类工具被广泛提出作为解决深度造假和虚假信息等人工智能问题的解决方案，同时还对知识产权监管机构和联邦执法机构提出了要求，以解决人工智能培训中版权作品的使用问题，包括呼吁“评估人工智能系统是否违反知识产权法”。</p><p>今年8 月份向白宫宣布的自愿承诺中，谷歌和 Open AI 等领先的人工智能公司承诺开发此类技术。问题在于水印等技术仍在开发中。目前还没有完全可靠的方法来标记文本或调查一段内容是否是机器生成的。</p><p>美国白宫表示，计划与<strong>“内容来源和真实性联盟”（C2PA倡议）一起推动这些技术的开发和使用。</strong>组织包括 Adobe、英特尔和微软等一些大公司，并设计了一种新的互联网协议，该协议使用加密技术对有关内容来源的信息进行编码。</p><p>该行政命令草案呼吁美国专利商标局局长和美国版权局局长采取额外的行政行动，以<strong>解决与人工智能生成作品的版权保护和使用受版权保护的作品训练人工智能相关的问题算法。</strong></p><h2>四、鼓励内部竞争、扶植小企业、防止垄断</h2><p>该命令草案指示其旗下的每个机构监管人工智能业务竞争，留意“集中控制带来的风险”，并防止占主导地位的公司进一步巩固权力。</p><p>该行政令特别指出，要通过为小型开发商和企业家提供技术援助和资源，帮助小型企业将人工智能突破商业化，并鼓励联邦贸易委员会行使其权力，促进公平、开放和竞争的人工智能生态系统。</p><p>人工智能所花费的成本巨大，如果只有谷歌、亚马逊和微软等最大的公司才能参与竞争，他们可能会通过人工智能的开发加固其垄断地位。</p><p>值得注意的是，行政令特别向联邦贸易委员会（FTC）表示认可，该委员会主席已经强烈表示，她打算积极打击以反竞争方式行事的人工智能公司。该命令鼓励联邦贸易委员会利用其规则制定权来帮助加强该行业的竞争，并保护消费者。</p><h2>五、推出 AI.gov与人才争夺计划</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_182f83aade3a44e99dd61ed77436f421@5655031_oswg135490oswg554oswg231_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>拜登总统在10月30日的新闻发布会上宣布推出了AI.gov，这是一个新网站，展示联邦政府在人工智能 （AI） 方面的努力和成就，此外还为研究人员、开发人员和公众提供资源和指导。这也是美国政府在人工智能领域更广泛战略的一部分，旨在推动人工智能在美国的发展和采用。</p><p>一个关键功能是政府新推出的“国家人工智能人才激增”门户网站，该门户旨在快速招募技术专家，以根据政府的价值观构建和管理人工智能系统。该网站还提供了有关政府如何投资人工智能研发的信息。</p><p>获得技术工人是科技行业的主要关注点，美国行政命令列出了一系列全面的指令，旨在提高具有人工智能专业知识的移民获得绿卡或以其他方式为处于人工智能和新兴技术前沿的美国公司工作的能力。</p><p>该命令指示包括国务院和商务部以及白宫科学技术政策办公室在内的多个机构开展一项海外活动，以宣传美国作为对具有科学或技术专业知识的外国人有吸引力的学习目的地、人工智能和其他关键技术的研究或工作。</p><h2>六、受科技公司欢迎的AI监管政策</h2><p>该行政命令建立在<strong>白宫与人工智能公司达成的非约束性协议的基础上。</strong>美国政府的做法仍然对科技公司相对友好，<strong>强调创新和竞争，而不是限制和约束，进一步体现了美国对人工智能监管相对宽松的态度。</strong>因此，各大科技公司基本上对这项行政命令表示欢迎。</p><p><strong>微软</strong>副董事长兼总裁布拉德•史密斯 （Brad Smith） 称赞这是“人工智能技术治理方面又向前迈出的关键一步”。</p><p><strong>谷歌</strong>全球事务总裁肯特•沃克表示，该公司期待“与政府机构进行建设性合作，以最大限度地发挥人工智能的潜力，包括让政府服务变得更好、更快、更安全。”</p><p><strong>Adobe </strong>总法律顾问兼首席信托官 Dana Rao 表示：“很高兴看到白宫通过创建负责任的人工智能实践框架来投资人工智能的发展。”</p><p>哥伦比亚大学法学教授布拉德福德表示：“这项行政命令可能是我们目前对美国政府所能期望的最好的行政命令。”</p><p><strong>作者：《互联网法律评论》</strong></p><p><strong>【免责声明】</strong>本文撰写所需的信息采集自合法公开的渠道，我们无法对信息的真实性、完整性和准确性提供任何形式的保证。本文仅为分享、交流信息之目的，不构成对任何企业、组织和个人的决策依据。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkyOTMxMDg1Mg==&amp;mid=2247508923&amp;idx=1&amp;sn=fb3145211b5891d3e0b354582f02a3a5&amp;chksm=c2099250f57e1b463ddecbc0f1812be90bbb53fcf942b3e67af9a763dc7d160e8e293a9a2357&amp;token=7633245&amp;lang=zh_CN#rd" rel="noopener noreferrer nofollow" target="_blank">“Internet Law Review”（ID:Internet-law-review）</a>，作者：互联网法律评论，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498242055739273</id>
            <title>同一时间，各大平台公告自媒体前台实名</title>
            <link>https://www.36kr.com/p/2498242055739273</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498242055739273</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 23:08:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微信, 抖音, 快手, 今日头条
<br>
<br>
总结: 微信、抖音、快手和今日头条等平台要求粉丝数量达到一定标准的自媒体账号展示实名信息，以加强对自媒体领域的管理和控制。各平台的要求和流程略有不同，但都希望通过实名认证展示来提供更可信赖的内容。未展示实名信息的账号可能受到限制，包括流量、收益等方面。 </div>
                        <hr>
                    
                    <p>就在刚刚，微信发布了关于头部自媒体账号对外展示实名信息的公告， <strong>近期将首先引导100万“粉丝”以上的“自媒体”账号对外展示实名信息</strong> 。&nbsp;</p><p>其实早在7月，关于实名制的消息就已经有了预告。2023年7月10日，中央网信办发布了《关于加强“自媒体”管理的通知》。新规从强加资质认证、加强谣言管理、规范账号运营等方面入手，加强对“自媒体”领域的管控。&nbsp;</p><p>这已经不是一家发布要求实名认证了。几乎同时， <strong>抖音、快手、微信、微博、今日头条、小红书、B站</strong> 一同发出了要求账号实名信息展示的公告，但数据和要求则依据各平台自身有所不同。&nbsp;</p><p>接下来和见实一起去看看各家的要求都有哪些。&nbsp;</p><h2>微信</h2><p>微信将 <strong>分批次分阶段引导“粉丝”量50万以上的“自媒体”账号对外展示实名信息</strong> ，近期将首先引导100万“粉丝”以上的“自媒体”账号对外展示实名信息。&nbsp;</p><p>根据微信公众号、视频号“粉丝”情况，平台100万“粉丝”以上的“自媒体”账号在用户确认同意展示后， <strong>账号注册主体为个人类型的将显示注册人真实姓名，机构类账号显示企业、机构名称，相关实名信息可在账号资料页进行查看。</strong></p><p>平台鼓励“自媒体”创作者真实表达，为用户提供更优质、可信赖的内容，未对外展示实名信息的100万“粉丝”以上“自媒体”账号，账号流量、收益等将受到限制。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_f272b16c85f741628dfdfd9e65f8604a@000000_oswg366167oswg1080oswg1027_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>抖音</h2><p><strong>粉丝数量达到50万且发布涉及时政、社会、金融、教育、医疗卫生、司法等内容的“自媒体”账号需授权平台在账号主页展示通过认证的实名信息。</strong></p><p>符合实名信息展示条件的“自媒体”账号将收到站内信通知，可以根据提示进行授权操作。若账号收到通知但未进行认证或授权，会对账号内容传播、商业收益等方面产生影响，直至完成认证及授权展示。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_06510330e739418890195075d4c9d140@000000_oswg575394oswg644oswg1240_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>快手</h2><p><strong>涉国内外新闻、社会热点和医疗、司法等专业领域粉丝量在 50 万以上的“自媒体”账号，将分批次、分阶段收到相关通知</strong> ，可根据通知提示进行操作，征询同意后在个人账号资料页展示实名信息。 <strong>首批将针对粉丝量100万以上的相关领域自媒体账号发送通知。主要分享个人日常生活的账号，不在前台实名范围。</strong></p><p>平台仅向符合条件的账号开放查看他人实名信息的权限，对于未登录的游客用户、未通过真实身份信息认证的用户、行为异常用户等，禁止查看相关实名信息。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_03506e0d3c014a70a735bf30dc68f5cf@000000_oswg428151oswg392oswg1050_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>今日头条</h2><p><strong>涉及社会时政、国际、军事、财经、法律、教育、健康等领域，粉丝量在50万以上的“自媒体”账号，将分批次分阶段收到通知</strong> 。账号主体可在收到通知后自主选择是否授权平台展示实名信息。主要分享个人日常生活的账号，不会收到平台的相关通知。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_eea0d9ddd90b46c7b8ae1dabaf188857@000000_oswg745654oswg1080oswg5500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>微博</h2><p><strong>站方将于近期引导社会时事、军事、财经、法律、医疗等专业领域100万粉丝以上的“自媒体”账号填写实名信息，后续将逐步扩大到相关领域50万粉丝以上的自媒体”账号</strong> ，经用户同意后进行前台实名展示。普通用户及以个人日常生活分享为主的领域账号不受前台实名展示的影响。&nbsp;</p><p>接收到私信引导但未进行前台实名信息填写的用户，其账号的流量和收入将受到部分限制，包括推荐流展示限制、热搜展示限制、广告分成限制、打赏收入限制等。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6778f50868594625a17c827296c6f3c8@000000_oswg552376oswg1080oswg1114_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>小红书</h2><p><strong>小红书平台将分批次分阶段引导粉丝量在50万以上的“自媒体”账号进行前台实名信息展示首批将向粉丝量在100万以上的“自媒体”账号发出站内信</strong> ，并征求用户同意后在其个人主页展示实名认证的真实姓名。&nbsp;</p><p>相关“自媒体”账号如不同意在前台展示实名信息，账号的经济收益、流量分发等权益后续会受到限制此次开展的前台实名信息展示工作，可以进一步提升头部账号的可信度，便于用户为公共利益实施社会监督，营造清朗网络空间。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6ddbb8a2020547e497d659b33fd69090@000000_oswg396153oswg638oswg1296_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>B战</h2><p>为加强“自媒体”管理，健全管理制度机制，维护良好的网络舆论生态， <strong>社区将分批次分阶段引导粉丝量 50 万以上的“自媒体”账号进行前台实名展示。&nbsp;</strong></p><p><strong>社区首批将引导粉丝量在100万以上的自媒体账号进行前台实名操作。</strong> 用户同意实名后，相关实名信息可在账号资料页进行查看；如不同意实名，后续账号流量、收益等会受到限制。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_db7b41f9dbd248cd8aca1a0e9ac9b50b@000000_oswg359623oswg1080oswg952_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzU3NTU5NDc0NA==&amp;mid=2247576074&amp;idx=1&amp;sn=ac89f550a8aa89e5ba880e4b33c4c5cc&amp;chksm=fd23239dca54aa8b6d66c43cde61360efbbaa3910d4f3b163c687feb64ca8672e469105a785c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“见实”（ID：jianshishijie）</a>，作者：见实，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498378367932295</id>
            <title>​撕开三星、金士顿市场，国产老牌存储器企业出海三年，营收翻三倍｜insight全球</title>
            <link>https://www.36kr.com/p/2498378367932295</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498378367932295</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 14:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 磁芯记忆体, 存储器, 国际存储市场, 出海市场
<br>
<br>
总结: 1948年，中国学生王安发明了磁芯记忆体，这一发明彻底改变了个人电脑历史，成为存储器的基石。中国是全球最大的存储器市场，但在全球存储器市场中，主要竞争者来自美日韩，中国市场被巨头垄断。然而，一些中国存储器厂商如金胜电子通过出海市场的拓展，取得了突破性增长。 </div>
                        <hr>
                    
                    <p>文｜张子怡</p><p>编辑｜袁斯来</p><blockquote><p>当出海越来越成为一家中国公司的核心战略，如何征战全球市场就成为一个极其专业的话题。事实上，在全球化的演变中，已有不少中国品牌站立潮头，他们有细分领域的头部玩家，也有品牌出海的新势力。鉴于此，硬氪特推出「Insight全球」专栏，通过深度挖掘报道这些公司和创始人及背后操盘手，试图再现品牌打造之路的“操盘宝典”，从品牌成长与变迁，探索中国品牌出海的前沿方向与时代契机，为出海玩家与行业提供思考与启发。</p><p>这是我们专栏第十七期——「金胜电子」，这家成立自2007年老牌存储器企业，在国内存储产品竞争激烈、行业集中度极高的环境中存活下来，2020年将业务重点转向海外，三年时间营收从八千万增长至三亿元，成为越南知名的存储器品牌。硬氪和金胜电子副总经理沈家琪聊了聊。</p></blockquote><p>1948年，哈佛计算机实验研究室，一个年轻的中国学生发明了一种“磁芯记忆体”，也就是最初的存储器，售价4美元。</p><p>这个学生的名字是王安，他的名字将在科技发展史上留下浓重的一笔印记。而王安当年的“小发明”彻底改变了个人电脑历史，成为所有科技产品的基石。2019年，国际存储市场规模已经2000亿美元。</p><p>发明存储器的是个中国人。</p><p>中国也是全球最大的存储器市场。根据中国海关进出口统计数据，中国存储器的进口量不断增加，占据了全部集成电路进口额的三分之一，2017年存储器进口占比高达34.1%。</p><p>全球存储器市场激烈的竞争中，主角都来自美日韩，寡头垄断格局明显，行业集中度较高，中国市场也是类似情况。仅以2020年固态硬盘产品线上市场为例，三星、西部数据、金士顿三家份额就超50%，大陆品牌仅占13%。国内厂商面对的是被巨头瓜分后的市场，且面临着技术“卡脖子”的现状，多数走中低端路线或者向细分市场发展。</p><p>过去数十年，华强北的档口售卖过各类品牌甚至白牌的国产存储器产品，如潮起潮落，不少产品出现又消失，国产存储器厂商们在做产品与做品牌走得曲折而艰难。</p><p>但有少数公司辟开了道路。成立于2007年的金胜电子，产品主要聚焦于存储产品的软硬件研发与生产，主要做移动硬盘、内存条等产品，属于存储器行业的中游行业，受上游芯片、元器件行业影响颇大。国内厂商很难和海外品牌竞争，所以金胜定位于第二梯队的品牌，属于中低端档位。</p><p>2020年，苦恼于国内存储器行业激烈的“内卷”后，金胜科技将业务重点放在出海市场，成为国产存储器厂商首批出海企业之一。营收迅速得以突破性增长，海外国内营收占比掉转为7:3，从2020年的八千万元到2023年Q3的3亿元。</p><p>存储器产品不同于科技硬件类产品和快消类产品，能够打开新的增长品类或者发掘新的需求。在确定需求面前，国内厂商出海面对的是早已被国际厂商垄断的市场，“破圈”艰难且有必要。</p><h3><strong>01 线上起量，树立品牌</strong></h3><p>大多数的中国出海企业都会选择线上销售的方式打开销量，金胜电子也不例外。</p><p>金胜电子在海外上市时，就选择了全面铺开，入驻Lazada、速卖通、阿里巴巴国际站、亚马逊以及开设独立站。</p><p>金胜电子旗下有两类产品线，“KingSpec 金胜维”专注个人消费领域；“YANSEN 元存”则针对工控工业类市场。</p><p>业务重心转向海外市场之际，金胜电子副总经理沈家琪着手划分了公司的产品线，在海外市场，金胜电子重点发展针对个人消费领域的「金胜维」。国内市场重点做针对工业类市场的「元存」。</p><p>沈家琪告诉硬氪，“国内主要方向是做企业级的客户，企业级的客户不用在品牌宣传、推广上大量投入，只要做好一个标杆性客户就可以，跟这类大客户项目进展顺利的话，推其他客户会比较容易。海外市场竞争不像国内这么白热化，我们有时间去做品牌，而且在海外做企业级客户需要我们面对面做宣传，沟通成本高，困难大，只能用线上带动线下的方式。”</p><p>在沈家琪看来，线上更适合做个人消费级客户，电商平台的流量曝光能够让消费者快速建立品牌认知，而“双十一”、“黑五”这样的大促活动带来的流量曝光更可观，能迅速看到效果。</p><p>硬氪了解到，金胜电子在于2021年就成为Lazada 跨境存储类目第一的企业，也是全球速卖通十大品牌之一。</p><p>除了入驻电商平台以外，金胜电子十分看重独立站和品牌官网的建设，在重点决定做出海业务之际，给企业全面注册了中英文商标、Logo。</p><p>之所以如此，是因为金胜电子成立三年后即开始布局全球市场。其中，同德国的一家代理商合作后，代理商在当地注册了金胜电子的产品品牌，导致金胜电子无法进入该市场，最终只能让该代理商在德国独家代理，并延续至今。</p><p>代理商抢注商标的事件给沈家琪很大的教训，让她意识到中国企业想要品牌出海的话，必须有保护知识产权的意识。</p><p>在独立站运营方面，由于金胜电子的产品主要以固态硬盘、内存条这类电子配件为主，在初期尝试只售卖存储类产品后发现销量不尽人意，于是尝试增加品类，如键盘、鼠标等。</p><p>“我们想做不同的存储解决方案，比如针对电竞产品的场景有对应的产品，还有专门针对影视行业摄影的场景。”沈家琪说。</p><p>在社媒运营方面，由于近两年出海的国内存储器厂商增多，电商平台、SEO优化的流量价格水涨船高。金胜电子开始注重社媒运营，研究不同国家社媒的使用偏好，针对性地推广。</p><p>例如，金胜电子在东南亚经过调研发现公司的用户群体更喜欢使用Facebook和Tiktok，公司会加大在这两款社交软件上的推广投入，营收增长迅速。</p><p>金胜电子花费了不少时间摸索社交媒体推广，对不同市场也形成了自己的判断。</p><p>沈家琪谈到，此前金胜电子曾跟一位粉丝量在5w左右的东南亚网红合作，单条视频转化了两百多个订单，之后一个月内该位网红粉丝量也增长至10w，是投入产出比很高的一次案例。。</p><p>和国内市场推广不同，金胜电子发现腰部级别的网红会更愿意主动合作更多的品牌，评测不同的产品。所以它们会更多寻找这类性价比更高的网红而非跟风头部网红。</p><p>和声势浩大的互联网公司不同，金胜电子在海外线上的投入相对克制和谨慎，最终也收获了不错的效果。摸石头过河或许是更适宜于老牌传统电子企业出海的方式。这些公司过去离社交媒体相对遥远，细水长流地投放，一步步建起品牌才是长远之计。</p><h3><strong>02 驶入汪洋大海之后</strong></h3><p>当进入陌生的海外市场后，金胜电子经历过一段不知所措的时期。</p><p>2020初期转向时，金胜电子并没想好要做哪些市场。</p><p>“今天投一下美国，明天转到欧洲去，后天又转到日本去了。” 沈家琪回忆，”</p><p>它们犯了新人做出海业务常见的错误。在各个市场蜻蜓点水，就如同往汪洋中扔了几粒石子，听不见一点声响。</p><p>这是一段长达半年的黑暗时期。“最后就会发现说这样不行，还是得集中火力去打。”最终，金胜电子看中离中国近、进入门槛相对低的东南亚。</p><p>这类新兴市场经济处于起步阶段，消费能力虽然有限，但对电子类产品有着磅礴需求，“价廉物美”的中国出海企业自然拥有切分市场的机会。</p><p>有了焦点区域，金胜电子开始选择要进入的第一个国家，一步步细化到城市。</p><p>沈家琪同公司团队调研过不同的东南亚国家，发现有的国家的消费者除了国际厂商的产品之外，第二选择会是本土品牌，中国品牌进入会比较困难。此外，国家的人口数量决定市场上限、人均GDP决定消费者能负担哪类价格的产品和品类，选定国家范围后还要调研出核心前三大GDP贡献最高的城市，这类城市才有发展空间。</p><p>最终他们决定在越南打开局面。“选择越南是因为之前很多中国企业都会到越南建工厂，政府比较友好，市场也很开放。之后如果我们有建厂需要，选择越南也会更方便。”沈家琪表示。</p><p>金胜电子尝试在越南市场开展本地化的品牌推广活动。例如在雨季的时候，买金胜电子的硬盘送雨衣（印满金胜电子logo），活动当日售出五六千件硬盘。“真的会有人因为想要雨衣而购买硬盘。”</p><p>沈家琪介绍，目前金胜电子越南每月产品出货量在3万件左右，成为越南当地知名的存储器产品品牌，计划之后在越南开设实体店，强化越南市场对于金胜电子的品牌认知。</p><p>金胜电子通过在越南市场建立的品牌声誉，再逐步进入菲律宾、印尼、马来西亚。到如今，东南亚市场占公司海外营收的30%。</p><p>对于电子消费品企业而言，发展海外市场，除了选对市场、线上引流之外，在线下广泛同代理商建立合作销售渠道也是重要一环。</p><p>沈家琪告诉硬氪，重视线下销售渠道跟产品特性有很大关系，对于零售消费者而言，买台电脑换个硬盘后，两到三年都不会再更换，存储器产品的类别决定了线上零售销量有限，想要扩大销量必须通过线下渠道同代理商合作。而且，不同的代理商渠道资源充裕，可以渗透发展更多的小B客户。</p><p>沈家琪表示，以东南亚市场为例，目前线上线下4:6。在产品定价方面，金胜电子线上自营产品的零售价格会高出线下20-30%，给线下代理商留出利润空间。“布局海外我们人生地不熟，肯定要依靠合作伙伴，他们赚到钱，我们才会赚到钱。”沈家琪表示。</p><p>金胜电子度过了出海最初的迷茫期，并在欧洲、美洲、东南亚、俄罗斯等国家设下渠道代理商。</p><p>接下来，如果要在这些市场更进一步，不至于陷入低价恶性竞争，金胜电子必须去啃硬骨头。归根结底，存储器企业仍然是技术驱动型企业，研发投入必不可少。目前，金胜电子在品牌推广预算方面每年投入营收的5%，在研发方面每年会投入营收的20%。最终，电子产品公司要想在国际市场相对轻松地挣钱，硬技术仍然是最基本的依仗。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498252667541638</id>
            <title>固态硬盘涨价，芯片合约价上涨，存储市场正在走出寒冬</title>
            <link>https://www.36kr.com/p/2498252667541638</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498252667541638</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:57:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 存储芯片市场, 价格涨跌, 合约价, 减产
<br>
<br>
总结: 存储芯片市场经历了一年的跌价后，目前出现了涨价的迹象。芯片生产商提高了合约价，但这并未明显影响到公开市场的售价。存储芯片价格的回升主要是通过芯片生产商的减产来实现的。虽然市场供需依旧失衡，但消费电子市场开始释放出触底信号，预计2024年将是IT行业复苏的转折之年。 </div>
                        <hr>
                    
                    <p>即将步入11月，就在各大电商平台陆续开启双11大促降价的同时，跌入谷底近一年的存储芯片市场终于迎来了涨价复苏的曙光。</p><p>界面新闻记者采访一家大型半导体采购电商平台了解到，目前在售的DRAM产品大部分价格近两个月以来没有明显变化，NAND Flash产品甚至出现了小幅跌价。相比上半年发生明显涨价的产品是SSD固态硬盘。</p><p>2022年，存储产品市场遭遇历史级萎缩，出货量与价格双双跳水。以固态硬盘为例，全球SSD去年总出货3.52亿块，同比下滑15%。今年第一、第二季度继续下滑，创历史新低。厂商不得不选择亏损出货。以国内市占率排第一的固态硬盘品牌金士顿为例，年中618大促时，金士顿NV2系列2TB固态硬盘的市场价跌至500元以下，1TB则直接跌至200元左右，已不足去年上市价的一半。7月、8月出货量逐渐上升，固态硬盘9月价格回升至降价前的正常水平，10月至今价格大致保持不变。</p><p>而在这条产业链上率先变化的是芯片生产商提供给客户的合约价。</p><p>经过漫长且痛苦的清库存后，“不愿再亏本卖芯片”已经成为了“存储三巨头”的共识。据外媒报道，三星在9月与小米、Oppo 和谷歌等主要客户签订采购合约，DRAM 和 NAND Flash 芯片合约价格比现价高出 10-20% 。SK海力士与美光也被曝光将跟进涨价。</p><p>而在智能手机、PC等电子消费品未能彻底走出需求低迷的前提下，芯片厂抬高的合约价目前仍停留在行业上下游的拉锯，并未明显影响到公开市场的售价。</p><p>目前，市场半导体研究机构TrendForce所统计的数据显示，7月底开始，虽然部分客户已经接受了芯片厂对DRAM、NAND Flash的涨价，整体芯片采购需求不振，导致8月至10月的主要产品的合约价未发生明显变化。但相比于去年第三、第四季度合约均价超20%的跌幅，行业的止跌信号已经浮出水面。</p><p>TrendForce预测，至今年第四季度，存储芯片的合约价将真正转入上涨，受跌价冲击最严重的智能手机Mobile DRAM涨幅预估将扩大至13%-18%，NAND Flash的主要产品的涨价幅度也将达到10%以上。</p><p>虽然芯片厂的合约价上涨传导至消费市场的产品还需要一段时间，但市场传言已经开始为涨价积极造势。国内社交媒体、各大电子论坛与产品群已经出现诸多讨论固态硬盘与内存条涨价的话题，不少消费者搜寻对比各个渠道的产品价格，计划在双11大促时赶上涨价前的“末班车”。</p><p>本轮存储市场回升并非由需求复苏拉动，主要靠芯片生产商的的减产扭转。</p><p>存储芯片价格的暴跌直接带崩了芯片巨头的利润。为抵御冲击，三大存储芯片巨头的另一项共识是减产，通过消耗客户库存来等待市场需求触底反弹。以三星为例，高盛披露三星今年已将DRAM、NAND Flash 芯片产量削减了约20%至25%。三星的减产计划据悉也将一直执行到明年二季度，直至芯片业务彻底回归营收平衡。</p><p>根据摩根士丹利此前统计的数据，2023年第一季度，全球半导体供应链（包括制造商、分销商和客户）握有的芯片总库存预期可用258天。照此估算，2023年底至2024年初将是行业的拐点。</p><p>虽然智能手机、PC今年还是“卖不动”，市场供需依旧失衡，但消费电子市场也开始释放出了触底信号。智能手机、PC出货量连续下跌的同时跌幅开始收窄。Counterpoint 、IDC在内的多家机构预测，2024年是IT行业复苏的转折之年。英特尔上周发布的第三季度财报也显示，旗下PC核心业务同比下降仅3%，相比上半年整体26%的跌幅已经明显收窄。公司预期今年第四季度将重回增长。</p><p>本文来自<a href="https://www.jiemian.com/article/10312256.html" rel="noopener noreferrer nofollow" target="_blank">“界面新闻”</a>，记者：李彪，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498242970179456</id>
            <title>英伟达发布大语言模型，专攻辅助芯片设计</title>
            <link>https://www.36kr.com/p/2498242970179456</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498242970179456</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:52:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, ChipNeMo, AI芯片设计, 大语言模型
<br>
<br>
总结: 英伟达推出了自家最新430亿参数大语言模型ChipNeMo，用于AI芯片设计。ChipNeMo可以帮助工作人员完成与芯片设计相关的任务，包括回答有关芯片设计的一般问题、总结bug文档，以及为EDA工具编写脚本等。英伟达的目标是提高设计师的效率，即使生产率只提高了几个百分点，也是值得的。ChipNeMo的问世标志着将大语言模型应用于半导体设计的重要第一步，展示了即使是高度专业化的领域，也可以使用其内部数据来训练有用的生成式AI模型。总体来看，ChipNeMo能够帮助英伟达内部的芯片设计师们完成问答、DEA脚本生成和Bug总结和分析三大方面的工作。 </div>
                        <hr>
                    
                    <p><strong>英伟达</strong>推出了自家最新430亿参数大语言模型——<strong>ChipNeMo</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_29e2bc7c87b549d18da5e1f6e52e05e4@46958_oswg157356oswg1080oswg273_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于它的用途，英伟达在官方披露消息中也是非常的明确，剑指<strong>AI芯片设计</strong>。</p><p>具体而言，ChipNeMo可以帮助工作人员完成与芯片设计相关的任务——</p><p>包括<strong>回答有关芯片设计的一般问题</strong>、<strong>总结bug文档</strong>，以及<strong>为EDA工具编写脚本</strong>等等。</p><p>英伟达首席科学家Bill Dally对此表示：</p><blockquote><p>我们的目标是让英伟达的设计师更有效率。</p><p>即使我们的生产率（因ChipNeMo）只提高了几个百分点，这也是值得的。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_7b10a47ed2e84bb19dc1ccd50eff0692@46958_oswg340199oswg700oswg511_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>以英伟达H100 Tensor Core GPU为例，它由数百亿个晶体管组成，在显微镜下看着就像是一个精心规划建设的城市一般。</p><p>这些晶体管连接在比人类头发丝还细10000倍的“街道”上，需要多个工程团队协作两年多的时间来完成，其间繁琐且庞大的工作量，可见一斑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_4ec54e4733f54833a7dfde0dbd45deac@46958_oswg557799oswg1080oswg522_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此，在英伟达看来，随着ChipNeMo这样大语言模型的问世，所有的工作流程都将在效率上得以提升。</p><p>用Bill Dally的话来说：</p><blockquote><p>这项工作标志着将大语言模型应用于半导体设计的复杂工作的重要第一步。</p><p>它展示了即使是高度专业化的领域，也可以使用其内部数据来训练有用的生成式AI模型。</p></blockquote><h2>英伟达设计芯片有了新帮手</h2><p>总体来看，ChipNeMo能够帮助英伟达内部的芯片设计师们完成三大方面的工作。</p><p><strong>首先就是问答。</strong></p><p>ChipNeMo包含一个原型聊天机器人，它可以回答有关 GPU 架构和设计的问题，帮助许多工程师在早期测试中快速找到技术文档。</p><p>例如，你可以向它提问：</p><blockquote><p>为什么我们要添加重新计时阶段（retiming stages）？</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_c80292420a4d4fdbad4d4bbf5d0e6662@46958_oswg218691oswg1080oswg535_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ChipNeMo就会基于这个问题，给出精准的答案：</p><blockquote><p>重新计时阶段的增加是为了改善设计的时序，并考虑到芯片不同部分之间的物理距离。</p><p>通过增加重定时级，我们可以减少信号在芯片不同部分之间传输所需的时间，这有助于提高设计的整体性能。</p><p>此外，重定时级还可以帮助减少信号上可能出现的噪声和干扰的数量，从而进一步提高设计的性能。</p></blockquote><p><strong>其次是DEA脚本生成。</strong></p><p>例如只需向ChipNeMo用自然语言提出想要生成代码的要求即可：</p><blockquote><p>在TOOL1中编写代码，输出给定矩形（0,0,100,100）中触发器单元的数量。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_d9be42a3225c4ecb99101fe1cbd179f5@46958_oswg265263oswg1080oswg797_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>仅需静候片刻，带着注释的代码片段“啪的一下”就生成了。</p><p>据了解，英伟达目前还在对代码生成器（如下图所示）进行开发，它将来会和现有的工具做一个集成，好让工程师用起来更加方便。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_bd3e5b43f59b4b66a32f6a8e83cdcd67@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>最后是Bug总结和分析。</strong></p><p>芯片设计人员只需要向ChipNeMo描述一下情况即可，例如prompt的内容可能包括Bug的ID、Synopsis、Module和Description等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_04a7a4f539c44bcb8e2860b4d451a991@46958_oswg338465oswg1080oswg786_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而后ChipNeMo就会根据prompt，给出做好的技术总结和管理总结等。</p><h2>ChipNeMo是怎么炼成的？</h2><p>首先在<strong>数据集</strong>方面，英伟达主要采用的Bug总结、设计源（Design Source）、文档以及维基百科、GitHub等硬件相关的代码和自然语言文本。</p><p>再经过一个集中的数据采集过程来收集，最终在清洗和过滤之后，形成了241亿个token。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_9af015bce78f426884688a7e209d2209@46958_oswg118760oswg1080oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其次在算法、架构设计方面，英伟达并没有直接拿目前已商用、开源的大语言模型来做部署。</p><p>而是主要采用了这些领域自适应（Domain-Adapted）技术，包括自定义标记器、领域自适应持续预训练、带有领域特定指令的监督微调（SFT），以及领域自适应检索模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_824c7686945f44daacd7e2b1699af1c2@46958_oswg132724oswg1080oswg504_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在此方法之下，便提高了大语言模型在工程助理聊天机器人、EDA脚本生成和Bug摘要和分析等三个应用中的性能。</p><p>结果显示，这些领域自适应技术使得大语言模型的性能超过通用基础模型；同时模型大小最多可减少5倍，且保持相似或更好的性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_61d97e790aea422582bca56d9220df6a@46958_oswg59972oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过论文作者也坦言：</p><blockquote><p>虽然目前的结果已经取得了一些进展，但与理想结果之间仍存在改进空间。进一步研究领域适应的LLM方法将有助于缩小这一差距。</p></blockquote><p>参考链接：</p><p>[1]https://blogs.nvidia.com/blog/2023/10/30/llm-semiconductors-chip-nemo/</p><p>[2]https://www.eetimes.com/nvidia-trains-llm-on-chip-design/</p><p>[3]https://d1qx31qr3h6wln.cloudfront.net/publications/ChipNeMo%20%2824%29.pdf</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/CY5vmNKY-Z1uLviUO5iOig" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：金磊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498242758432646</id>
            <title>AI玩推理桌游一眼识破骗局，清华通院联合推出心智理论新框架，6个指标评估表现均明显优于思维链</title>
            <link>https://www.36kr.com/p/2498242758432646</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498242758432646</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:52:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 清华自动化系团队, 北京通用人工智能研究院, AI智能体, 阿瓦隆
<br>
<br>
总结: 清华自动化系团队与北京通用人工智能研究院合作，让AI智能体在桌游阿瓦隆中学会了“三思而后行”和“换位思考”，通过提出的ReCon框架，AI智能体能够识别和应对欺骗，增加了通用人工智能的安全屏障。 </div>
                        <hr>
                    
                    <p>清华自动化系团队联合北京通用人工智能研究院，让几个AI智能体玩起了桌游！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_0fd8c86fbe8047b897015c0eadae5761@46958_oswg277942oswg752oswg826_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>游戏名叫<strong>阿瓦隆</strong>，是一个策略性的社交推理游戏，玩家被隐秘地分为“正义”与“邪恶”两派，通过任务投票、互相猜测与欺骗来完成或阻止任务，最终确定胜负。</p><p>为了能让AI智能体成功识别并应对欺骗，研究人员提出了<strong>ReCon（Recursive Contemplation，递归思考）框架</strong>。</p><p>由此一来，AI在游戏中学会了<strong>“三思而后行”</strong>和<strong>“换位思考”</strong>，不仅能够从自身角度判断场上局势，还会思考“其他角色会如何看待我的言论”，分分钟识破骗局。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_a956fc0573334a3d9f550da98e964492@46958_oswg85249oswg1080oswg440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Arxiv链接：https://arxiv.org/abs/2310.01320</p><p>要知道，在通往通用人工智能的道路上，AI智能体将有能力在无人监管的情况下进行自主思考与决策。</p><p>然而，较少有研究者关注如何在未来无人监管的情况下，防止AI智能体被欺骗和误导。</p><p>由于人类社会中存在很多误导和欺骗性的信息，如果AI智能体无法有效识别和应对这些信息，可能会在未来造成不可估量的后果。</p><p>因此让AI智能体学会甄别和应对虚假欺骗信息，是为通用人工智能增加安全屏障的重要一环。</p><p>而研究人员提出的这种新框架，在胜率以及多维度评估等指标上，都能在<strong>无需任何微调以及额外数据</strong>等情况下，极大地提升大模型识别和应对欺骗的能力。</p><p>此外，这项研究还进一步讨论了现有的大语言模型在安全、推理、说话风格、以及格式等方面存在的局限性，为后续研究指出可能的方向。</p><p>接下来，我们一起来看看该研究的细节。</p><h2>大模型容易被骗的三大挑战</h2><p>尽管目前大语言模型（LLM）在多个领域表现出强大的潜能，但在欺骗性环境中的应用表现仍然有待提升。</p><p>作为LLM智能体在欺骗性环境中应用的初步尝试，研究者选择了阿瓦隆游戏（一款涉及推理和欺骗的桌游）作为实验环境，在此基础上探究目前LLM智能体面临的三大挑战：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_ec20ed87092f41048c9bc4b160d86d3f@46958_oswg406071oswg1080oswg482_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p><strong>挑战一：恶意信息的误导</strong></p><p>首先， LLM智能体在面对别有用心的恶意欺骗性信息时容易被误导。如图1（a）所示，当采用“Chain-of-Thoughts（CoT）”方法时，模型不仅没有识别出欺骗，反而进一步加强了对坏人角色有益性的错误信念。</p><p><strong>挑战二：私有信息泄露</strong></p><p>其次，LLM智能体在保护隐私信息方面存在不足。如图1（b）所示，即使在提示不要暴露私有信息的情况下，LLM智能体依然可能在言语中泄露角色的私有信息（例如Merlin暴露自己的身份），从而增加了被对手针对或陷害的风险。</p><p><strong>挑战三：内部思考的不透明性</strong></p><p>最后，即使在使用CoT方法情况下，对于人类用户而言，LLM智能体的思维过程仍然存在一定的不透明。如图1（c）所示，LLM智能体在扮演坏人角色欺骗好人角色时，人类用户难以知道其真实意图。</p><p>LLM智能体内部思考的不透明使得人类用户无从知晓LLM智能体的真实思考过程，从而较难在造成难以挽回的后果前预先干预。</p><p>面对这些挑战，现有的思维方法可能难以应对这些复杂环境。因此，研究者认为有必要重新考虑LLM智能体在欺骗性环境中的策略，以帮助LLM智能体应对欺骗、保护隐私，并提高决策透明度。</p><h2>ReCon框架：构思两步走</h2><p>针对上述挑战，研究团队提出了ReCon（Recursive Contemplation，递归思考）框架，其旨在增强LLM智能体在复杂和潜在欺骗性环境中的决策能力。</p><p>如下图所示，ReCon提出了两个主要的构思阶段：<strong>构思思考</strong>（Formulation Contemplation）和<strong>改进思考</strong>（Refinement Contemplation），并在其中综合了两个独特的思考过程：<strong>一阶视角转换</strong>和<strong>二阶视角转换</strong>（First-order / second-order perspective transition）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_dd078af2be7a4c61bd0363b8720465c0@46958_oswg501078oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><h3>1、构思思考的设计</h3><p>构思思考是ReCon框架中的第一阶段，旨在生成LLM智能体的初始思考和发言内容。在这一阶段中，模型首先应用一种被称为“一阶视角转换”的认知过程。</p><p>一阶视角转换让LLM智能体<strong>从自身的视角出发</strong>，对其他游戏参与者可能持有的角色和意图进行推断。</p><p>具体来说，LLM智能体会根据已有的游戏记录和角色信息，运用一阶视角转换来形成关于其他参与者角色和意图的初步假设。</p><p>这些初步的角色假设不仅为LLM智能体提供了一个认知框架，还会被纳入到整体的思考过程中，并且这些信息不会被其他游戏参与者所知晓。这样做的目的是为了更好地保护私密信息，同时也为后续的决策和行动提供了基础。</p><p>在构思思考阶段，模型依据一阶视角转换原则，对当前游戏环境和其他参与者的角色进行初步分析。接着，模型<strong>形成初始的内部思考和发言</strong>，为后续交流奠定基础。通过这一设计，研究者确保了模型输出的逻辑连贯性和一致性。</p><h3>2、改进思考的设计</h3><p>改进思考是ReCon框架中的第二阶段，紧接着构思思考之后进行。这一阶段的核心目的是对初始思考和言论内容进行更为精细的优化和调整。</p><p>在改进思考阶段，引入了“二阶视角转换”的概念。</p><p>二阶视角转换要求LLM智能体<strong>从其他游戏参与者的视角出发</strong>，重新评估其构思思考的思考和发言内容。</p><p>具体来说，在阿瓦隆游戏中，LLM智能体会思考：</p><blockquote><p>如果我按照刚才的言论内容发言，其他角色可能会如何看待我的言论？</p></blockquote><p>这样的二阶视角转换为接下来的改进过程提供了基础。</p><p>基于二阶视角转换的概念，LLM智能体生成一个改进后的构思思考的思考内容和发言内容。</p><p>这一过程不仅考虑了LLM智能体自身的初步思考，还结合了二阶视角转换中对其他参与者可能的心理状态和反应的分析。最终，LLM智能体发表这个经过改进的发言内容，并将其加入到游戏的公开讨论记录中。</p><h2>20场阿瓦隆评测</h2><p>为了检验ReCon框架在不同大语言模型上的适用性，该研究在ChatGPT和Claude两种模型上进行了实验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_5ff7bdba530d461087b9fa54f9413053@46958_oswg138667oswg1080oswg433_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>上图展示了ReCon的评估结果，其中（a）和（b）展示了ReCon（分别用ChatGPT和Claude实现）作为<strong>好人</strong>一方时使用ReCon及其各种变体的结果，而（c）则描绘了ReCon作为<strong>坏人</strong>一方的方法的结果。</p><p>可以观察到，ReCon的四种设计（即构思思考/改进思考和一阶/二阶视角转换）都明显地提高了在各种情况下的成功率。</p><p>值得注意的是，当好人一方使用ReCon时，一阶/二阶视角转换的作用比较明显；而当坏人一方使用ReCon时，改进思考更具影响力。</p><p>在详细分析了ReCon及其变体的表现后，研究者遵循主流基准的评估方法，进一步利用GPT-4在六维度指标上进行评估。这旨在全面地衡量ReCon及其变体的有效性。</p><p>具体地，<strong>六维度评估指标包括：</strong>信息隐藏（CCL）、逻辑一致性（LG）、团队贡献（CTR）、说服力（PRS）、信息量（INF）、创造性（CRT）。</p><p>为了在实际场景中准确地量化这些评估指标，研究者使用ChatGPT进行了<strong>20场</strong>完整的阿瓦隆游戏，以收集用于多维度分析评估的测试数据。</p><p>如下图所示，对于分配给好人一方的每个提示，研究团队使用4种不同的方法生成了4种不同的响应，总计超过2300个响应。</p><p>随后，基于上述6个指标，使用GPT-4对不同方法在相同提示下的响应进行二分类的偏好比较。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_bbf993bbfb2f4e1d8e99a04d2311a0dd@46958_oswg182180oswg1080oswg358_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>图4显示，在所有6个指标上，ReCon明显优于基线CoT。同时，在大多数指标上，构思思考和改进思考都带来了显著的提升。</p><p>然而，与CoT和没有构思思考的ReCon相比，ReCon和没有改进思考的ReCon在说服力（PRS）方面的表现低于预期。</p><p>研究者分析详细的游戏日志，将这一不如预期的PRS表现归因于构思思考。</p><p>构思思考让LLM智能体在发言之前进行思考，从而产生更为简洁而有针对性的发言，减少了例如<strong>“我相信我们一定会战胜坏人，让我们团结起来！”</strong>这样虽然具有煽动性但缺乏深入信息和分析的发言。</p><p>在深入分析了ReCon不同变体的表现后，研究者进一步研究了一阶和二阶视角转换，以及构思思考和改进思考在各个评估指标上的影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_a7c877fc4dbf408ba4028c8cfea729b3@46958_oswg277856oswg1080oswg414_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>图5（a）和（b）显示，从ReCon中<strong>移除一阶和二阶视角转换会降低所有指标的表现</strong>。</p><p>当进一步从去除改进思考和去除构思思考的ReCon版本中删除这两种视角转换时，几乎所有指标（除信息隐藏CCL外）的表现都有所下降，如图5（c）和（d）所示。</p><p>这些结果验证了一阶和二阶视角转换的有效性。</p><p>然而，图5（c）和（d）中降低的信息隐藏CCL分数表明，为了更好地隐藏私有信息，有必要将一阶（或二阶）视角转换与改进思考（或构思思考）相结合。</p><p>这一系列的分析和图表进一步证实了ReCon框架在多维度评估中的优越性，特别是在包含欺骗性信息的环境中。</p><h2>讨论&amp;局限性</h2><p>研究者进一步分析了阿瓦隆游戏日志，对ReCon框架在欺骗性环境的有效性做了定性的解释，并讨论了当前LLM的一些局限性。</p><h3>1、ReCon如何帮助隐藏私有信息</h3><p>在实验中可以发现，ReCon非常有助于提高LLM智能体在欺骗性环境中隐藏私有信息的能力，从而减少LLM智能体被欺骗和针对的情况。研究团队从游戏日志中分析ReCon具体如何帮助LLM智能体隐藏私有信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_862cbdc055094e48b299f5650cab4e0d@46958_oswg414327oswg1080oswg638_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>如图6 (a)所示，构思思考中提出的先思考后说话的机制可以将关于私有信息的讨论限制在思考部分，从而一定程度上避免说话部分的泄露。此外，改进思考中对初始发言的进一步修改也可以极大程度上避免私有信息的泄露。</p><p>上述观察与人类为避免说错话而“三思而后行”是一致的。</p><h3>2、“对齐越狱”</h3><p>在探讨LLM如何与复杂人类价值观对齐时，研究者发现现有的对齐方法（如RLHF）虽然在一定程度上减少了模型产生恶意内容的可能性，但这种对齐主要集中在内容层面，而难以延伸到逻辑层面。</p><p>如图6（b）所示，研究团队观察到，虽然GPT-4会拒绝直接要求它生成欺骗内容的请求；但在相同的欺骗性逻辑下，如果换成阿瓦隆游戏的语境，GPT-4则不会拒绝。</p><p>这种对模型对齐的“越狱”可能会为别有用心之人使用LLM生成危害性内容提供了方便，因此亟需研究针对逻辑而不是内容的对齐。</p><h3>3、推理能力不足</h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_80ff55b058284aaf865fd1aee485610c@46958_oswg139555oswg1002oswg522_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>研究团队通过研究阿瓦隆游戏日志发现，目前LLM在复杂逻辑推理方面仍有所欠缺。</p><p>如图7所示，例如当LLM智能体扮演Percival角色时，面对Morgana提出的一个包括Merlin和Morgana自己的队伍，该LLM智能体无法推断出Morgana的身份。</p><p>相比之下，对于较高阶的人类玩家，他们会迅速识别出队伍提出者必定是Morgana，而另一名玩家是Merlin。</p><p>因为Merlin的能力是知道谁是坏人一方的角色，肯定不会提出这样的队伍组合。上述案例体现出LLM目前还较难完成复杂的逻辑推理。</p><h3>4、过于正式的回应</h3><p>从游戏日志中，研究者发现大语言模型的回应风格有时过于正式和详细，语言风格与人类在游戏中的风格有着明显的差距。</p><p>如下表所示，虽然在合适的提示下，LLM具备模仿人类语言风格的能力，但在阿瓦隆游戏中，在说话和思考的过程中模仿人类的语言风格可能会对其表现造成负面影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_8a3f570558204cc7959fa525c535990c@46958_oswg47384oswg946oswg262_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><h3>5、LLM智能体格式响应的比较分析</h3><p>为了从LLM智能体的回应中提取关键信息，有时需要要求模型以特定的格式来回应。</p><p>比如，在团队提案投票环节，模型需要用方括号强调出他们的决定，例如“[approve]”或者“[disapprove]”，以便把决定和分析区分开。</p><p>结果发现，在合理的提示下，ChatGPT和Claude可以较好地遵循这些格式要求，但LLaMA2-70b-chat却较难在整局游戏中一直遵循格式要求。</p><p>总结来说，针对LLM智能体在欺骗性环境遇到的挑战，研究团队提出了ReCon架构以提升LLM智能体识别和应对欺骗的能力。定量和定性的实验证明了ReCon框架在处理欺骗和误导性信息的有效性。研究团队给出了ReCon有效性的定性解释，并进一步讨论了当前LLM智能体的不足，为后续研究提供了可能的方向。</p><p>更多研究细节，可参考原论文。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/wxBzWBC_aCJPgpstrDBJgw" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：阿瓦隆，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498208360634499</id>
            <title>PICO身陷关停风波，字节跳动的VR业务还在等风来</title>
            <link>https://www.36kr.com/p/2498208360634499</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498208360634499</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:32:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: PICO, 字节跳动, VR业务, 元宇宙
<br>
<br>
总结: 字节跳动近期传闻将放弃PICO业务，这引发了关于VR业务和元宇宙的讨论。虽然PICO在中国VR硬件市场占据领先地位，但其面临着员工离职和缺乏内容的问题。元宇宙作为一个虚拟世界，需要庞大的算力和丰富的内容支持，而目前技术和市场尚未完全成熟。与此同时，人工智能的发展也吸引了资本和用户的关注，因为它在当下已经展现出了更大的潜力和商业机会。 </div>
                        <hr>
                    
                    <p>“花了90亿买的PICO，字节跳动居然说不要就不要了？”不久前有媒体爆料称，字节跳动或将逐步放弃PICO业务。紧接着，澎湃新闻的独家报道为这个传言再添了一把火，表示PICO近半员工离开、多名核心高管离职调岗，以及“正在重新考虑字节跳动VR（虚拟现实）业务PICO的战略定位。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_4044cc6e98d940b6b32d96106127a49e@000000_oswg27281oswg600oswg294_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，字节跳动方面也很快辟谣，并称PICO团队会继续聚焦XR领域的产品研发和生态构建，且公司对PICO业务有着长期、明确的战略规划与资源投入。</p><p>90亿元买下的业务仅仅两年就关闭，这确实不太可能，即便字节跳动再有钱，显然也不会拿真金白银打水漂玩。只不过PICO确实遇到了一些困难，此前在今年春季发生的“组织调整”，乃至部分核心高管的沉寂，也是客观存在的。仅仅两年时间，字节跳动麾下的PICO从备受期待到前景扑朔迷离，其中究竟到底发生了什么？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_3e9ef28422cd4ef5a905e8d5f23b44f5@000000_oswg29850oswg600oswg495_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2021年夏末秋初字节跳动收购PICO，当时科技圈的主题正是“元宇宙（Metaverse）”。彼时元宇宙更是曾被认为是互联网的未来，是一个看得见、摸得着，可以被感知、提供完全沉浸感的虚拟世界。而元宇宙被业界从故纸堆里翻出来，则源于XR（扩展现实）相关技术的成熟，这一年Meta的Quest 2席卷全球，完成了千万人的VR启蒙，也使得通往元宇宙的路似乎清晰了起来。</p><p>元宇宙生态中XR硬件，就承担起了移动互联网生态中智能手机的角色，有着智能手机改变人类数字生活的故事珠玉在前，有志于继续扩张的消费互类联网企业就无论如何也不会放弃这块鲜美可口的蛋糕了。据IDC公布的相关数据显示，2021年PICO占中国VR硬件市场份额的41%，牢牢占据着国内VR硬件一哥的位置。换而言之，当时字节跳动等于是花了90亿元买了一张通往元宇宙世界的门票。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_df60cce7908747a7a0e034b1715e3305@000000_oswg51020oswg600oswg373_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果元宇宙果真是是互联网的未来，字节跳动这笔钱显然花得很值。君不见，微信这张移动互联网的船票，就让腾讯在面对互联网行业风云变幻时能够做到始终岿然不动。</p><p>可遗憾的是，元宇宙这一愿景终究太过于宏大、过于脱离现实。元宇宙作为一个虚拟世界，它必然不可能无中生有，要有现实基础的。而元宇宙的核心要素之一，就是基于计算机图形学制造出一个能够以假乱真、令人沉浸的虚拟世界。</p><p>所以庞大的算力就是构筑元宇宙的基石，比如当年在英伟达新品发布会上、14秒的黄仁勋数字人神乎其技，但这背后是34个3D美术师、15个软件研究人员花费了大量时间的结果。更何况，当时的网络通信水平连5G网络覆盖都还没有实现，用户随时随地接入元宇宙、并保持无法被感知的延迟，自然也难以达到。所谓的沉浸感就更不切实际了，在计算机只能提供视觉和听觉的基础上，元宇宙还需要实现虚拟化的味觉、嗅觉、触觉。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6b4ed25dd0f74000bddbff57d7c520df@000000_oswg13277oswg600oswg209_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>即便元宇宙这边蛋糕暂时还吃不到，可字节跳动如果能如同Meta一样，让PICO的硬件产品卖出超过千万量级的水平，打造出一个可以持续稳定运行的VR生态，其实也是个不错的结果。但可惜的是，PICO4试图开启VR大众化之路的设想也落空了，在其首月销量超过5万台后，PICO4的势能似乎就被耗尽。如果说元宇宙搞不起来是目前的技术水平还跟不上，那么字节跳动的VR生态迟迟难以成型最大的问题，则可能是内容的缺乏。</p><p>据不完全统计，目前PICO平台的应用仅有500款左右，而且其中有娱乐价值的更是寥寥无几，反而滥竽充数的应用占绝大多数。与之相对应的是Oculus平台的应用接近2000款，Steam平台支持VR的内容更是超过7000款。可缺乏内容的结果，就是有相当多用户吐槽买回来就落灰了，进而导致二手交易市场上“99新”的PICO4几乎是数不胜数。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_3aa63761914243c1986edbcd7e1552ad@000000_oswg20073oswg600oswg327_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更致命的是，元宇宙还面临着“既生瑜何生亮”的窘境。随着ChatGPT走红带动了人工智能在消费级领域的爆发，它对自然语言的理解能力也达到了此前一众智能助手从未有过的高度。如果说元宇宙是未来可能存在的钻石矿，那么ChatGPT无疑就已经是进入开采阶段的金矿。相比于充满变数的未来，活在当下是个更好的选择，这一点无论对于个人、还是资本其实都是一样。</p><p>元宇宙的问题在于建设周期过于漫长，以至于Meta的百亿美元投入都尚且没法“听个响”，人工智能的前景尽管同样模糊，可好歹有了ChatGPT，OpenAI已经蹚出了一条路。所以对于资本市场而言，在2023年选择正当红的人工智能、还是已经过气的元宇宙，答案不言而喻。</p><p>至于说为什么人工智能和元宇宙在现阶段是非此即彼的关系？原因就在于无论元宇宙、还是ChatGPT，其实都是需要算力来构建的，而算力、特别是超大规模算力更是一个有价值的资源。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_4e14f60a21bb401fbd167383a344b367@000000_oswg35681oswg600oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>相比于算力缺口几乎大到令人绝望的元宇宙，支撑AI大模型的算力其实是足够的。不仅如此，经过一年时间的发展，AI技术赋能生产力场景也已经被证实。例如微软CEO就在最近证实，集成了ChatGPT的微软New Bing迄今为止已让用户进行了“超过19亿次聊天”，人工智能编程助手GitHub Copilot的付费用户也超过了100万。</p><p>如今无论从C端、还是B端来看，AI大模型以及相关技术都表现出了更加出色的商业价值。要知道资源不足永远是这个世界的主旋律，即便字节跳动手握抖音这台印钞机，也会面临需要将有限的资源投入更有前景的方向这个问题。隔壁的Meta即便嘴上喊着不放弃元宇宙，但实际上早已将赛道切换到了AI+MR，字节跳动如今也有在大模型业务上持续加码。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_46aec1ed1efb4f77a462fd45c55e3098@000000_oswg23480oswg600oswg353_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当初字节跳动收购PICO的行为，属于极为激进地进入一个前路未明的赛道，更是被许多业内人士认为堪称是不折不扣的赌博。但遗憾的是，现在看来似乎并没有赌赢。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649850888&amp;idx=3&amp;sn=f450fd50c11bdc444b99b470ce9cef92&amp;chksm=8789c2cab0fe4bdcf43a09e391d5e599a758e40706504d791e4c30925b7665070fe96642cc1d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498208181704583</id>
            <title>电子产品的机身防护能力，不能盲目完全信赖</title>
            <link>https://www.36kr.com/p/2498208181704583</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498208181704583</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:32:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 用户, Apple Watch Ultra, 防护能力, 水底
<br>
<br>
总结: 一位用户在潜水时不慎将佩戴的Apple Watch Ultra丢失在水底，经过三个月后被打捞出来，依然能够正常运转。这引发了关于电子产品防护能力的讨论。虽然Apple Watch Ultra符合潜水设备工程标准，但官方建议用户只在40米深度以内使用。此外，防水功能并非永久有效，使用环境和材料老化都会影响防水性能。因此，在恶劣环境下使用这类设备需要谨慎评估使用风险。 </div>
                        <hr>
                    
                    <p>日前有消息显示，一位用户在潜水时不慎将自己佩戴的Apple Watch Ultra丢失在了水底。但在三个月后，这款丢失的Apple Watch Ultra被打捞出来、并经过了清理和充电后，依然能够开机、且一切功能运转正常。这一消息的曝光，一时间关于手机、智能手表等电子产品的防护能力也成为了诸多朋友关注的焦点。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6ea0306edb6949df802eecc91c04f137@000000_oswg17337oswg550oswg315_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事实上，这位用户所遇到的只是一件偶发、并且极小概率的事件。原因其实也很简单，因为在沉入水中长达三个月的时间里，这款设备可能一直都处于超过防护等级的环境中。根据苹果方面公布的信息显示，虽然Apple Watch Ultra符合潜水设备工程标准EN 13319的规定，最大防水深度可达100米，但官方建议用户只用于40米深度以内的休闲式水肺潜水。</p><p>按照这一标准，实际上设备需要在一个理想的环境中使用，测试过程可能也并非连续进行。而这位用户丢失的设备却是连续、长时间处于相关环境下，所以损坏才是大概率的后果，因此这个案例尽管只是展现了一种小概率事件，并不能适用于所有场景。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_980029bb2fad4478b7a90195fe1f6201@000000_oswg41231oswg550oswg362_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外需要注意的是，苹果在Apple Watch Ultra系列机型的使用说明中也强调，其防水功能并非永久有效。目前想要实现电子产品的防水功能，必然就需要用上各类材料来对其机身整体进行密封，其可能是橡胶、防水胶等材质。但在经过了一段时间的使用后，随着材料本身的老化，就必然会导致密封性的同时下降，进而导致防水性能的不断下滑。</p><p>而更加恶劣的使用环境，则同样可能会缩短密封材质的正常使用寿命。因此用户在条件相对恶劣的情况下使用这类设备，应先检查设备情况，并评估使用风险，以避免遭遇到不必要的损失。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_26aca74c68024852a9af498399f280ea@000000_oswg43096oswg387oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">防尘防水相关标准</p><p>此前，Redmi方面相关人士就曾透露，Redmi Note13 Pro+近日已通过IP69测试，具备应对高温高压喷水的更高防护能力。其实对于电子产品来说，IP69就已经代表着当前民用级别中最高标准的防护水平。简单来说，这个标准是在确保完全防尘，能够经受完全浸没在水中的前提下，产品还能承受任何角度的高压高温水/水蒸气的清洗。所以通过相关认证的设备，理论上也有着更强抵御生活中可能会遇到的意外情况。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_7d07ce42109249f58e19e87954a0f6b7@000000_oswg30106oswg550oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">目前已有许多机型支持防泼溅</p><p>截至目前，已有大量顶级旗舰机型支持IP68（即完全防尘、并可在完全浸没的一定时间内保证设备安全）级防尘防水功能，主流产品许多也都实现了防溅水能力。但将一定等级的防护功能普及后，就可以确保智能手机等设备在日常使用中的绝对安全了吗？</p><p>显然并非如此，毕竟电子产品的防护功能只是降低其在恶劣环境中使用的损坏概率，而非完全避免损坏。同时所标称的防护等级实际上只是一个参考值，证明其在一定条件下具备同等防护能力，一旦超限使用依旧还是有损坏的可能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_a6c0d63e1c574dcdbc823bf5e9a8c7ff@000000_oswg14931oswg550oswg363_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">用清洁剂清洗手机就是极为严重的错误示范</p><p>例如即便是具备IP68级防护能力的智能手机产品，其实并没有一个严格意义上的“统一标准”。多数厂商所标称的IP68指的是在受控实验室条件（符合IEC 60529标准）下，手机能在一定深度的清水中浸泡一定时间后仍可正常使用。</p><p>但需要注意的是，测试过程中的水深以及时间长短，是可以由厂商和测试机构协商决定。通常来说，测试深度会在1至1.5m之间，而在测试持续时间方面，手机厂商大多会要求在至少浸泡30分钟，但由于不同厂商的标准并不完全一致，因此必然就会存在一定的差异性，所以对于用户来说，最好是留有一定的安全阙值来使用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_2f5674edc37e4551b72009097d8ca1fd@000000_oswg60976oswg550oswg392_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，即使具备一定的防水功能，也不能代表诸如智能手机、智能手表这类以触控操作为主的设备，能够在恶劣的环境中正常使用。例如，尽管有些手机厂商推出了“湿手触控”、“湿手指纹识别”等功能，但当设备完全浸没在水中时，屏幕触控即便不会完全失效，但往往也相差不远。</p><p>针对这类情况，诸如Apple Watch Ultra等机型就提供了“入水锁定”功能，入水10厘米左右即将锁定屏幕。再比如在类似桑拿房这样充满高温水蒸气的环境中，只要是不具备IP69防护等级的设备，就仍有一定概率会出现因高温水蒸气进入而导致的损坏。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_2a9c30ecf9c64d65a6ff6d1d5b85680c@000000_oswg42514oswg550oswg472_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">米兰尼斯表带就并非防水设计</p><p>如果认为设备具备一定防护能力，就可以在最大程度上避免进水所带来的损失，那么这种认知显然并不全面。例如，Apple Watch Ultra本体尽管有着极高的防护等级，但其部分材质的表带却并没有这一特性，比如皮革、不锈钢表带等，虽然它们在“泡水”后未必会立即损坏，但显然还需要采取一些补救措施才能确保后续的长期使用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_350441f614e7430e98552d7234a5573a@000000_oswg43462oswg550oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外需要特别注意的是，由于电子产品的防护能力测试大多是在相对纯净的淡水环境下进行的，因此这也就意味着任何淡水以外的液体都有可能会造成风险。比如在用户在露天温泉中想要用手机记录精彩瞬间时，富含矿物质的温泉水及水蒸气就可能会对其造成不可修复的损伤。</p><p>而诸如海水、沐浴液、洗发水、饮料、食用油等生活中十分常见的液体，对于智能手机等设备的密封防水材料和防水涂层往往也都有着极大的“杀伤力”，因此避免这类产品与其他液体接触才是最安全的做法。</p><p>另一个很容易被所忽视的细节，则是在设备被浸泡后，切记要确保充电口、扬声器等容易积水的部位彻底干燥后，才能使用与之相关的功能。尤其是进行诸如充电这样的操作时，一旦接口部分仍有液体残留，就极有可能会在接通电源后导致短路问题的出现。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_899b2ed27a8048c393f6343333272939@000000_oswg46040oswg506oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事实上，智能手机、智能手表这类设备如今已普遍为用户提供了一定等级的防护能力，但这一设计的初衷是让用户能够在一些特定的场景下还具备一定的可用性，同时降低因意外或恶劣环境使用损坏的概率，并不代表可以抛开设计标准和环境来使用。因此即使是具备一定防护能力的的电子产品，在使用环境过于恶劣的情况下，用户应事先进行评估，尽量在符合设计标准的情况下使用，同时留有一定的安全阙值，以避免遭受损失。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649850888&amp;idx=4&amp;sn=7abcddfd74575b5036aba42ea34ac8db&amp;chksm=8789c2cab0fe4bdcdb732df055fec985b7b2567df49c1276b2d246a5f566abf968a58ab78f80&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498211445626761</id>
            <title>比家还舒服？前苹果和特斯拉高管，打造最强电动智能房车</title>
            <link>https://www.36kr.com/p/2498211445626761</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498211445626761</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:27:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: UpHonest Capital, Pebble, 电动房车, 智能化
<br>
<br>
总结: Pebble是一家加州初创公司，通过UpHonest Capital的投资，打造了一款全新的电动智能房车Pebble Flow。这款房车采用了先进的技术，能够自动化完成房车生活中的各种任务，提升用户的体验。同时，Pebble Flow还具有高效的电动系统和舒适的设计，为用户带来了全新的房车体验。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_8ffdc855810744d5b10b9b2e6e6c7883@000000_oswg293914oswg1044oswg461_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>UpHonest Capital投资项目，加州电动车初创公司Pebble于今年6月份已从Lightspeed光速光合，元璟资本，UpHonest Capital和创世伙伴CCV处筹集了1360万美元的资金，为过去50年来几乎没有技术进步的房车行业带来变革及创新。</strong></p><p><strong>Pebble计划打造一种全新的电动房车体验，旨在改变人们的生活、工作和探索方式。该公司即将推出的旗舰产品是一款100%电动的智能房车，能将RV生活中最困难的部分完全自动化，大大提升体验并改变房车的使用形态。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_749433d9118d41d2b894617a1c6130ec@000000_oswg125030oswg1080oswg723_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>数字游民群体大批崛起，打工人的办公室编程了天南海北；年轻人爱上了周末短途游，露营吸氧是缓解工作压力再好&nbsp; &nbsp; &nbsp;不过的放松，随之而来的便是房车市场的爆发。&nbsp;</p><p>据2022年全年中国旅居车（房车）市场报告显示，2022年我国拖挂旅居车交易3670台，同比增长3.6%，而二手旅居车交易7708台，同比增长达到了290%，国内现有的房车品牌超200多个，与房车相关的企业更是超过了7000家。&nbsp;</p><p>跟国内相比，欧美国家的房车文化更加久远， 在美国，超10%的家庭拥有房车，约有4000万美国人会定期房车出游；而在欧洲，疫情前房车的注册数就已经超过了 200万，像是法国和德国等国家每年每户房车的使用数接近20次，每周行驶里程可达1000公里。&nbsp;</p><p>能够满足多种生活和旅行需求的房车成为了“出逃”最好的伴侣，但说到房车，许多人心中的印象还是“脏乱差”、“难使用“、“容易掉链子”，传统房车的确有着这样那样的槽点，像是难以停进停车位、各种电器争抢能源、供暖较差和发动机噪声太大等等，不过这一切即将改变。&nbsp;</p><p>来自加州的初创公司<strong>Pebble</strong>打造出的新款智能电动拖挂房车Pebble Flow击破了上述种种痛点，能够高效完成自动驾驶、充电和拖挂调节等多种任务，帮助用户实现更加流动式生活并和在任何地方安居的梦想，同时也将“炸场”式为传统房车市场注入一股新鲜力量。&nbsp;</p><p>Pebble创始人兼CEO <strong>杨秉锐</strong> 曾在<strong>Apple</strong>的iPhone研发团队工作9年，还带领过<strong>Cruise</strong>和<strong>Zoox</strong>等自动驾驶汽车公司的开发团队。Pebble其他的团队成员也有不少来自Tesla、Volvo、Cruise、Zoox和Apple等公司，他们多年深耕于汽车和消费电子业，其智慧的结晶就是Pebble Flow这样一款用尖端技术颠覆了传统房车概念，能够提供与使用iPhone一样轻松体验的现代化未来感房车。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_833efa29196640dc897d0319264a73a8@000000_oswg94390oswg1080oswg729_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">杨秉锐与首席技术官Stefan Solyom&nbsp;</p><p>Pebble Flow的亮点众多，首先就是全电动系统，这款拥有45千瓦时的LFP电池被认为是市面上最安全的EV电池，能够为所有设备充电并达到离网供电长达7天的效果。同时它还可以通过1000瓦的集成太阳能在停车或驾驶时进行充电，就像永远插在110伏的充电插座上。充电场景不设限，公共充电站、家中和露营地都适配，还可以在拖车时再生充电，保证续航体验。在家中断电的紧急情况下，这款容量是Tesla Powerwall 3.5倍的电池还可以作为备用电源使用。&nbsp;</p><p>在性能和设计上，Pebble称其为力量与美的完美结合，车身颜色鲜亮大胆，制造上采用严格的汽车制造工艺，使用全铝空间框架结构和可持续材料，主打经久耐用，目标是让Pebble成为市面上最安全的RV。Pebble团队还在车身曲线和线条上下了不少功夫，Pebble Flow的空气动力学性能是普通旅行拖车的300%，这对于带来更持久的航程和更安全的牵引体验来说至关重要。&nbsp;</p><p>与传统房车相比，Pebble Flow在舒适度上也非常优越，车长约为7.62米，高为2.64米，宽为2.28米，车内配备一张大床和一张可转换式双人床，最多可容纳4人舒适入住，同时还配有可调节LED照明灯光和全景窗户，用户甚至可以在270度的星空天幕下入睡。数字游民一族还能分分钟将床变桌，同时拥有USB接口、LED照明和Starlink连接系统等设备打造完美的办公空间。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_c13f8e412b644ec4908471c55f83e546@000000_oswg1125084oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>厨房拥有可拆卸炉罩、四合一对流微波炉烤箱和全尺寸冰箱设备，用户只需翻转窗户，就能在室内和室外用餐场景间轻松切换。浴室也采用高级酒店的灵感，使用现代设备配置和LED照明，用户只要调整玻璃透明度就能改变室内氛围。通过Pebble的App，用户还可以预先设置超静音的HVAC系统，全绝缘的车外壳能够保持适宜的温度，而超高效的加热泵则可以进行静音加热。&nbsp;</p><p>Pebble Flow的智能体现在方方面面，其内置的双电机推进辅助系统具有革新意义，它解锁了一系列传统房车无法实现的新可能，不管是燃油车还是电动车都能因其获得更好的能耗，也让续航和稳定性都得以大幅提升。在这一辅助系统的帮助下，Pebble的Magic Hitch功能可以自动进行挂车中的瞄准、对接和联结，解决了以往拖挂房车最让人头大的难题，为出行准备按下加速键 ；而Easy Tow功能则让用户在大风或斜坡的情况下也能轻松安全的完成拖车任务，不管是SUV、皮卡还是电动车都不在话下；用户还能一键开启露营场景，因为Pebble Flow可以自动进行展开楼梯、打开灯光、设置温度、解锁车门和调节遮阳篷等多项任务，当用户准备回家时也可以一键收回所有功能。这一切都可以通过Pebble的应用程序进行操作，通过远程操控，用户甚至可以在其双电机推进辅助系统的帮助下进行倒车、停车和定位等多种操作，无需看后视镜也不需牵引车就能实现，以智赋能进了房车出行的每一步。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_59a68e36ef5d4dcc873c14ece04bb2aa@000000_oswg62416oswg750oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“Pebble Flow 代表着房车文化的新时代—一个可持续且轻松出行的时代。在最新电气化和汽车技术的影响下，我们能够优化用户整体的体验，”Pebble 创始人兼CEO杨秉锐说道，“Pebble的成果将解决传统房车出行中的所有难题，让更多户外爱好者实现更加轻松和自由的生活方式。”</p><p>Pebble Flow预计将从2024年底开始交付，目前预订已经开放，起步价为10.9万美元，而含有双电动机、远程操控、Magic Hitch和Easy Tow等多项功能的Magic Pack升级系统价格约为12.5万美元，Pebble Flow还将登陆2023年洛杉矶车展供爱好者们实体“一睹芳容”。</p><p>Pebble在今年6月完成了由UpHonest Capital、Lightspeed光速光合，元璟资本和创世伙伴CCV投资的1360万美元融资，担任Pebble顾问的前苹果高管Dave Rosenthal表示，在Pebble身上他看到了“苹果文化”的影响，比如Pebble专注于将尖端技术应用在设计和优化用户体验多个方面，更多的是站在用户的出发点做出考虑，这与苹果得以成为科技行业领导者的核心价值观不谋而合。</p><p>房车行业在过去的几十年内少有技术变革和创新，但目前随着消费者出行和尝新类消费需求的爆发，露营和旅居相关政策和设施更加完善，房车市场蓄势待发，iPhone的智能让人们把手机玩出了花样，而Pebble现代化的出行体验也会改变人们的生活和工作探索方式，推动着房车行业实现巨大飞跃。</p><p>参考来源：</p><p>1.Introducing the Pebble Flow: The All-Electric Travel Trailer That’s Bringing an iPhone-like Experience to RVing &nbsp;(Pebble Medium)</p><p>2.The Pebble Flow Is the All-Electric, Stress-Reducing Camper Trailer of the Future (MotorTrend)</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI4MDUzMTc3Mg==&amp;mid=2247597972&amp;idx=1&amp;sn=9075aece00df6672cce657649b3d2dfd&amp;chksm=ebb439c7dcc3b0d10bf354e7a3f5ca8c8c6678b79f6912e4ed887d3809ff9b30633ae08a6411&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“硅兔赛跑”（ID：sv_race）</a>，作者：Lexie，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498218114717570</id>
            <title>固态锂电池：日本新能源的遮羞布</title>
            <link>https://www.36kr.com/p/2498218114717570</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498218114717570</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:26:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 东京汽车展, 日本车企, 固态电池, 成本和市场
<br>
<br>
总结: 在东京汽车展上，日本车企展示了最新的纯电车型。虽然固态电池作为一项先进的电池技术具有优势，但由于成本和市场的原因，目前还没有普遍应用。日本车企高调宣传固态电池，可能只是一种遮羞布。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_13bb4fb970bb40d0b304a4b14165588e@46958_oswg711893oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在25日开幕的东京汽车展上，日本车企纷纷带来了旗下最新的纯电车型。</p><p>作为传统燃油车的阵地之一，日本在新能源时代是有所落后的，因此身为老牌劲旅的丰田汽车也在积极求变。在本月还曾宣布将与日本石油化工企业出光兴产共同合作面向电动汽车的“全固态电池”，目标在2027年至2028年实现“全固态电池”的量产实用化。</p><p>其实丰田，或者说日本车企并非第一次宣扬所谓“固态电池”了，作为一项先进的电池技术，它确实有其优势所在，但业界没有普遍应用的原因还是在于成本和市场。</p><p>而日本车企一直以来的高调宣传，在笔者看来，<strong>不过是把“固态电池”当成遮羞布罢了。</strong></p><h2>固态电池：一个美好的梦</h2><p>我们这里所说的固态电池，准确来说是固态锂电池，本身并非什么黑科技。</p><p>早在上个世纪，采用固态电解质的电池就已经有了一定的技术突破，在医疗器械等领域有所应用。</p><p>目前的固态电池主要有三条技术路线：<strong>聚合物路线</strong>（主要是法国博洛雷）、<strong>硫化物路线</strong>（丰田、宁德时代、松下）、<strong>氧化物路线</strong>（索尼以及大量中国企业）</p><p>这三条路线都有各自的优缺点，主要是热稳定性、成本控制等方面有所差别。其中聚合物路线发展较早，但是研究进展不大，难以大规模商用；氧化物路线集中在小电池方面，之后在医疗、航天以及消费电子市场可能有所利用；硫化物路线进展同样较慢，但发力方向主要就在新能源车方向，有大规模商用的潜力。</p><p>但无论哪条路线，理论上都要比现在的液态电解质电池要强。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_42fd4c259fb0498a96b9681d4b251867@46958_oswg586864oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：日产NISSAN汽车）</p><p>这是由固态电解质的性质决定的。<strong>固态电解质在电池中既是电解质，也充当了隔膜的作用。</strong>既保证没有液态电解质的泄露问题，又分隔了正负极材料，不会出现短路。</p><p>有实验表明，固态电池在针刺、挤压、过充、加热等破坏性测试中都保持了良好的状态，不起火不爆炸，<strong>安全性很不错</strong>。</p><p>另一方面，固态电池可以用高能量密度的材料作为电解质以存储更多的能量，<strong>在相同的体积、重量下，固态电池供能更多</strong>。</p><h2>短期难商用</h2><p>既然固态电池性能优异，又相对安全，那为什么大家都没用呢？其实除了日本车企之外，包括大众、福特等国外品牌，以及国内电池企业也都在发力固态电池。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_9e1e469e885c4bcba12962199598c734@46958_oswg83725oswg641oswg360_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：大众汽车）</p><p>但目前主流依旧是液流电池的原因，则还是技术和成本。</p><p>就连一直吹捧固态电池的丰田公司方面也表示：“无论是液态电池还是固态电池，我们的目标是彻底改变目前电池过大、过重、过贵的局面，在这方面的潜力上，我们将争取将这些因素减半。”</p><p>一方面，<strong>固态锂电池的锂材料用量是普通磷酸铁锂电池的3-6倍</strong>，前面提到的技术路线中，最可能在汽车上应用的硫化物路线硫化锂，由于高活性和毒性问题，不仅工艺造价昂贵，还不耐用。</p><p>而在技术层面，中国研究机构真锂研究首席分析师墨柯曾表示，目前固态电池还有很多技术关需要突破，甚至<strong>需要8年至10年才能看到成果</strong>，中日韩三国的电池企业都在努力攻关。</p><h2>无奈的“遮羞布”</h2><p>根据咨询机构SNE research公布的最新数据显示，今年1-8月，全球动力电池市场，宁德时代以36.9%的市占率排名第一、比亚迪以15.9%的市占率排名第二，LG新能源排名第三，市占率为14.2%。前十的企业中足有6家来自中国，整体市占率达到了62.6%。而日本企业松下仅排第四，甚至和第三名之间有近1倍的差距，差距极大。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_d3a802fd7c8746a29c16be3e217d5733@46958_oswg81021oswg600oswg268_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：SNE）</p><p>其实在电池相关技术上，日本的起步很早，世界上第一块商用锂电池便是在日本索尼公司诞生的，松下也在很长的时间里保持着电池产业的极大份额，直到近年才因为动力电池被反超。但是日本的新能源汽车路线上，却压错了宝，或者说是无奈没得选。</p><p>包括丰田在内的很多日本车企在新能源领域的早期投入大多选择了氢能源，并不仅仅是因为氢能源是真正的清洁能源，而是因为<strong>日本极度缺少作为电池生产的核心元素——锂</strong>。</p><p>锂矿作为伴生矿物，往往是以工业副产物的形式采集的，而日本是贫矿国家，本身缺乏锂资源。那为什么反而要研究比传统锂电池用锂量更大的固态电池呢？</p><p>在笔者看来，<strong>他们长期鼓吹固态电池技术领先，更多是为了安抚资本和消费者，维持技术领先的架子，不过是他们的一块“遮羞布”罢了</strong>。</p><h2>写在最后</h2><p>戏友可，勿戏本心也。</p><p>题图源：日产NISSAN汽车</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/30-XPa0GvyuOb0MT6eEWow" rel="noopener noreferrer nofollow" target="_blank">“镁客网”（ID:im2maker）</a>，作者：Visssom，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2497974416316548</id>
            <title>GPT-4V连小学生都不如？最新基准测试错误率竟高达90%：红绿灯认错、勾股定理也不会</title>
            <link>https://www.36kr.com/p/2497974416316548</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2497974416316548</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:23:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT-4V, 语言幻觉, 视觉错觉, HallusionBench
<br>
<br>
总结: 马里兰大学发布了专为GPT-4V设计的基准测试HallusionBench，发现了GPT-4V存在的语言幻觉和视觉错觉问题。研究人员通过对视觉能力的测试发现，GPT-4V在回答视觉问题时错误率高达近90%。HallusionBench是第一个专为GPT-4V设计的基准测试，主要关注视觉错觉和知识幻觉。测试包括约200组视觉问答，涉及多个领域的图片类型。研究者还分析了GPT-4V在视觉理解方面的能力，并提出了改进的建议。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_aaab3a6caedf4dd6b14d714ffd3aecac@46958_oswg419834oswg1076oswg410_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>马里兰大学发布首个专为VLM设计的基准测试HallusionBench，全面测试GPT-4V视觉错误和语言幻觉。</p><p>GPT-4被吹的神乎其神，作为具备视觉能力的GPT-4版本——GPT-4V，也被大众寄于了厚望。&nbsp;</p><p>但如果告诉你，初中生都知道的勾股定理，只适用于直角三角形。&nbsp;</p><p>然而GPT-4V却自信将其用于钝角三角形中计算斜边长度。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_97214b9f609b44e7930f1a64c9539db9@46958_oswg133388oswg655oswg340_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有更离谱的，GPT-4V直接犯了致命的安全错误，竟然认为红灯可以行驶。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_dc1cb029b7a645928f026456fbdc0f16@46958_oswg178063oswg812oswg535_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这到底是怎么回事呢？&nbsp;</p><p>马里兰大学的研究团队在探索过程中发现了这些问题，并在此基础上提出了两种主要的错误类型：语言幻觉和视觉错觉，以此来阐释这些错误的原因。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_4f19ed7ce92249b486ed81893eb0aa45@46958_oswg36677oswg975oswg538_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文链接： https://arxiv.org/abs/2310.14566&nbsp;</p><p>项目主页：https://github.com/tianyi-lab/HallusionBench</p><p>研究人员依据上述分析，创建了一个名为HallusionBench的图像-语境推理基准测试，旨在深入探讨图像与语境推理的复杂性。&nbsp;</p><p>基于他们的对于视觉能力的测试，GPT4V在回答视觉问题组的错误率高达近90%。&nbsp;&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_34c17082d423449bb9445ea4f0ae6642@46958_oswg44148oswg1080oswg385_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>研究者们还对新发布的GPT-4V(ision)和LLaVA-1.5进行了详细的研究，深入分析了它们在视觉理解方面的能力。&nbsp;</p><p>HallusionBench是第一个专为VLM设计的基准测试，主要关注视觉错觉和知识幻觉。这个测试包括约200组视觉问答，其中近一半是由人工专家创作的。&nbsp;</p><p>目前数据已经开源, 并且还在更新中。&nbsp;</p><p>涉及的图片类型多样，包括原始的错觉图片、图表、地图、海报、视频及手动制作或修改的图片，涵盖数学、计数、文化、动漫、体育和地理等多个领域。&nbsp;</p><p>论文中，作者初步阐述了HallusionBench中的两种视觉问题分类：视觉依赖型（Visual Dependent）和视觉补充型（Visual Supplement），并讨论了实验对照组的设计方法。&nbsp;</p><p>随后，他们分析了可能导致答案错误的两大主要原因：视觉错觉（Visual Illusion）和语言幻觉（Language Hallucination）。&nbsp;</p><p>在文末，作者通过不同的子类别详细展示了各主要类别中的失败案例，并进行了深入的分析。&nbsp;</p><h2>关键点：</h2><p>1. 「语言幻觉」：在GPT-4V和LLaVA-1.5中会误导90%的样本推理。视觉与语言之间的微妙平衡至关重要！&nbsp;</p><p>2. 「视觉错觉」：LVLMs中的视觉模块容易受到复杂视觉上下文的影响，语言模型的错误被夸大。&nbsp;</p><p>3. 简单的图像修改就能欺骗GPT-4V和LLaVA-1.5，暴露了对更强大的图像分析能力的需求。&nbsp;</p><p>4. GPT-4V在推理多个图像之间的时间关系方面存在困难。&nbsp;</p><p>5. LLaVA-1.5有时会在常识查询上犯错，需要改进其语言模型先验。</p><h3>视觉问题类型</h3><p><strong>视觉依赖型问题(Visual Dependent)：</strong></p><p>这类问题的答案完全依赖于视觉内容，缺乏图像信息时无法确切回答。</p><p>这些问题通常关联到图像本身或其显示的内容。例如，在没有图像的情况下，无法准确回答诸如「图中右侧的橙色圆圈是否与左侧的同样大小？」之类的问题。</p><p><strong>视觉补充型问题(Visual Supplement)：</strong></p><p>这些问题即使在没有视觉内容的情况下也能得到回答。在这种类型的问题中，视觉元素仅提供附加信息。</p><p>比如，即便没有图片辅助，GPT-4V仍能回答「新墨西哥州是否比德克萨斯州大？」等问题。</p><p>测试的核心在于判断GPT-4V和LLaVA-1.5能否利用图像内容来作答，而不是仅凭它们的参数化记忆。</p><h3><strong>错误分类</strong></h3><p>作者对错误回答进行了分析，并将其原因分为两大类：</p><p><strong>视觉错误(Language Hallucination)：</strong></p><p>这类错误产生于对输入图像的错误视觉识别和解释。模型未能从图像中提取准确信息或对其进行正确推断。&nbsp;</p><p><strong>语言幻觉(Visual Illusion)：</strong></p><p>模型基于其参数化知识库，对问题输入和图像背景作出不恰当的先入为主的假设。模型应当针对问题的具体环境作出反应，而不是忽略问题本身或对图像作出错误解读。</p><h3><strong>范例</strong></h3><p>从图1所展示的经典视觉错觉案例中可见，GPT-4V在识别各种错觉图像及其名称上显示出比LLaVA-1.5更丰富的知识储备。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6551a4b6163d440a853354144ef57754@46958_oswg560667oswg720oswg1040_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图1&nbsp;</p><p>然而，在回答经过编辑处理的图像相关问题时，GPT-4V未能提供精确答案。&nbsp;</p><p>这种现象可能源于GPT-4V更多地依赖于其参数化存储的知识，而不是实际对图像进行分析。&nbsp;</p><p>与此相反，无论是处理原始图像还是编辑后的图像，LLaVA-1.5的表现都相对较差，这反映出LLaVA-1.5在视觉识别方面的能力较为有限。&nbsp;</p><p>观察图2提供的样本，可以发现GPT-4V和LLaVA-1.5均未能正确识别平行线、正三角形、多边形及其他数学定理。</p><p>这一现象揭示了，对GPT-4V而言，在处理几何和数学问题方面仍面临较大挑战。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_e7a9129aadf94c4fbe0ca9f0cceb1699@46958_oswg523748oswg720oswg878_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图2&nbsp;</p><p>在图3的展示中，作者指出了几则海报，展示的是一些知名的地方美食，但这些美食的地理特征遭到了改动。&nbsp;</p><p>面对这样的场景，GPT-4V和LLaVA-1.5都未能充分考虑上下文信息，忽略了图像内容，继续根据文本中提及的知名产地来回答相关问题。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_3c6c76bf86a448d094b38e3cc0b484f8@46958_oswg723079oswg720oswg1032_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图3&nbsp;</p><p>在图4的案例中，作者进一步探讨了对多张图片序列的处理能力。</p><p>图片的顺序排列和倒序排列在语义上常表现出对立的意义，例如「出现与消失」和「后退与前进」。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_8ab8894dff5b4a2b8ace49da105f8814@46958_oswg520641oswg720oswg848_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图4&nbsp;</p><p>研究比较表明，尽管这些图片序列描绘了不同的动态，GPT-4V依然未能区分这些图片的顺序和逆序排列。&nbsp;</p><p>这一发现指出，在视频序列推理方面，GPT-4V仍需大幅度的优化和提高。&nbsp;</p><p>图5展示了一个案例，其中在缺乏图像背景信息的情境下，GPT-4V提供了一个断定性的回答。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_4125976999b944a8ada6e3b47d24bf5b@46958_oswg549878oswg943oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图5&nbsp;</p><p>相对地，LLaVA-1.5，由于对文本的理解不足，提出了一个技术上无误但与问题无关的答回答。&nbsp;</p><p>当以修改后的π值作为视觉输入，两个模型均未能从图像中正确识别和解释这个值。&nbsp;</p><p>图6中的情形显示，当缺少视觉输入时，GPT-4V和LLaVA-1.5都能准确且断定地作出回答。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_171f44ff89e24d6fa6a72215252e9dc6@46958_oswg507463oswg720oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图6&nbsp;</p><p>然而，在表格作为视觉输入的情况下，GPT-4V尝试依据视觉信息解答，却误取了错误数据。</p><p>例如，GPT-4V错误地答道「中国赢得了36枚金牌」，尽管图表实际显示的是美国获得了这些金牌。&nbsp;</p><p>相比之下，LLaVA-1.5更依赖于其参数化记忆，在分别处理问题和表格时表现不同。&nbsp;</p><p>在图7的场景中，即使没有视觉辅助，GPT-4V和LLaVA-1.5都作出了断定性的答复，其中GPT-4V的答案更为准确和精确。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_ce95e6be9d2a42c28ea02ea92224352d@46958_oswg548589oswg720oswg1013_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图7&nbsp;</p><p>当引入图表作为视觉输入，GPT-4V能精准地根据图表中的数据给出答案，而LLaVA-1.5则依赖于其参数化知识进行回答。&nbsp;</p><p>但是，一旦图表被翻转，GPT-4V对答案的预测发生了根本性变化。这个错误可以被解释为由视觉错觉引起的。&nbsp;</p><p>根据图8，在缺乏图像支持的情形下，GPT-4V和LLaVA-1.5均提供了确定的回答，但正确答案仅由GPT-4V给出。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_2b2aadafcb1f485ea781affd7ea94b5d@46958_oswg556598oswg1003oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图8&nbsp;</p><p>由此可以推断，GPT-4V在知识层面上优于LLaVA-1.5。&nbsp;</p><p>然而，当地图的视觉呈现发生改变时，两种模型由于其强大的参数记忆能力，均未能正确推断出四个州的相对位置。</p><h2>总结</h2><p>近年来，随着大规模语言模型和多模态研究的快速发展，人工智能领域经历了重大的变革。&nbsp;</p><p>自然语言处理（NLP）和计算机视觉（CV）的结合，不仅促成了大型视觉语言模型（LVLM）的诞生，而且显著提高了图像推理任务的性能。&nbsp;</p><p>但是，LVLM仍面临着一些挑战，如语言幻觉和视觉错觉等问题。&nbsp;</p><p>本研究通过推出HallusionBench，旨在为VLM提供一个基准测试，特别是在那些容易因语言幻觉或视觉错觉而失败的复杂情况下。&nbsp;</p><p>我们对GPT-4V和LLaVA-1.5的不同示例和失败案例进行了深入探讨，包括：&nbsp;</p><p>1. 在HallusionBench中，GPT-4V和LLaVA-1.5在处理含有先验知识的问题时，往往会受到语言幻觉的影响。这些模型更倾向于依赖先验知识，导致在我们的分析的例子中，超过90%的答案是错误的。因此，模型需要在参数化记忆和输入文本图片之间找到一个平衡点。&nbsp;</p><p>2. 即便是在GPT-4V和LLaVA-1.5缺乏参数化记忆或先验知识的情况下，它们仍然容易受到视觉错觉的影响。这些模型常常在处理几何图形、数学图像、视频（多图像场景）、复杂图表等问题时给出错误答案。目前，视觉语言模型在视觉处理方面的能力还很有限。&nbsp;</p><p>3. GPT-4V和LLaVA-1.5在HallusionBench中容易被一些基本的图像操作所误导，如图像翻转、颠倒顺序、遮挡、物体编辑以及颜色的修改等。目前的视觉语言模型尚未能有效处理这些图像操作。&nbsp;</p><p>4. 虽然GPT-4V支持处理多图，但在分析涉及时间线索的多图像问题时，它未能展现出有效的时间推理能力，在HallusionBench中表现欠佳。&nbsp;</p><p>5. 在HallusionBench的测试中，LLaVA-1.5由于知识库相对较少，有时会犯下一些基本的错误。&nbsp;</p><p>作者表示，他们的数据集已经开源，并正在继续扩展数据库。最新的数据会在Github （https://github.com/tianyi-lab/HallusionBench）上不断更新。&nbsp;</p><p>这项研究为未来更加强大、平衡和精准的LVLM奠定了基础，并期待通过这些详细的案例研究，为未来研究提供一些可能方向。&nbsp;</p><p>参考资料：&nbsp;</p><p>https://arxiv.org/abs/2310.14566&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/0cuRi2Ss7usCkSsWnk-2PA" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：LRS 好困，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498155672363145</id>
            <title>芯片人才的困境</title>
            <link>https://www.36kr.com/p/2498155672363145</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498155672363145</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:21:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人才, 半导体行业, 短缺, 美国, 教育
<br>
<br>
总结: 半导体行业一直面临着全球范围内的人才短缺问题，尤其是在美国。根据预测，未来几年美国半导体行业可能面临数十万名工人的短缺。这一问题主要源于半导体产业的发展和人才培养的不足。为了解决这一问题，产业需要从教育入手，加强与高校和科技学校的合作，培养更多的半导体人才。 </div>
                        <hr>
                    
                    <p>人才一直是半导体行业的热门话题也是行业一直想要解决的难题。</p><p>有多难？</p><p>以美国为例，德勤报告称，未来几年美国半导体行业可能面临约 70,000 至 90,000 名工人的短缺。麦肯锡预计，到 2030 年，美国将短缺约 30 万名工程师和 9 万名熟练技术人员。根据美国半导体行业协会（SIA）与牛津经济研究院7月发表的研究报告，预测到2030年，半导体行业将短缺67000名工人，届时半导体行业约58%的新制造和设计岗位将面临空缺的风险。</p><p>不仅美国，德国经济研究所受德国工业联合会委托进行的一项研究结果表明，德国半导体行业现在缺少6.2万名技术工人，尤其是电气工程、机电一体化和软件开发领域的人员。而将范围扩大到整个欧洲，普华永道·思略特最近发布的一份报告显示，到2030年，欧洲半导体行业的“人才缺口”将达到35万。</p><p>为何全球半导体产业都陷入缺人困境？为何产业的发源地美国也有那么大的人才缺口？面对这样的情况，产业又打算如何改变呢？</p><h2>半导体人才的“入不敷出”</h2><p>半导体缺人很大的一个原因来自于产业的发展。如果分析半导体行业的缺人类型，其实不仅仅是大众潜意识里的“高精尖”人才不够，半导体产业链条长且细分领域多样，不同领域的企业在发展和人才需求上存在一定差异。总而言之，对于半导体产业来说企业管理领军人才、每道工序的制造人才（如操作工人、封装工人、设备协调工人等）、半导体厂房的建筑工人都可能是缺少的人才。</p><p>把人才培养比作蓄水池的入水口，把产业发展比作出水口。由于半导体人才需要跨学科知识，也需要多年经验。当前全球大力发展半导体产业的趋势让出水速度大大超过入水速度，也就造成了行业内人才不足的情况。</p><p>从好的角度来看，“物以稀为贵”让芯片行业人才的工资水涨船高，《2023年北京市人力资源市场薪酬状况报告（三季度）》显示，量子算法工程师位居高薪榜首，薪酬中位值为36768元/月。5G通讯算法工程师、强化学习工程师、芯片设计工程师等职位薪酬中位值均突破30000元。相信这样的薪资数据是可以吸引相当一部分人投身行业。</p><p>但是，由于急缺人才造成了行业争抢人才的乱象，愈发不利于长期的人才培养。恶性循环之中，半导体人才短缺的情况迟迟无法改善。行业已经达成的共识是，想要真正解决问题，一定要从教育入手。</p><h2>美国半导体用人困境</h2><p>作为半导体产业发达的代表国家，美国半导体产业的缺人问题是十分值得探讨的案例。</p><p>为什么美国会缺少技术工人？</p><p>在全球范围内，美国将需要数以万计的熟练技工来建造新工厂，以提高和本地化制造能力：电工、管道安装工、焊工；数千名毕业电气工程师来设计芯片和制造芯片的工具；晶圆厂本身有更多各类工程师，但也有操作员和技术人员。如果在欧洲和美洲发展后端，那就相当于创造更多的就业机会。</p><p>到 2021 年，全球直接员工数量将超过 200 万人，到 2030 年，将需要额外超过 100 万名技术工人，相当于每年超过 10 万人。就背景而言，美国每年就读电气工程和计算机科学专业的研究生不到 10 万名。然而SIA认为美国的基础教育没有对科学培养足够兴趣。美国半导体的人才短缺主要涉及拥有四年制学位和高级学位的工程师和计算机科学家，以及拥有两年制或以下学位的熟练技术人员以及其他在职训练人员。SIA认为：攻读 STEM 学位的美国学生数量不足。【注：STEM是科学（Science），技术（Technology），工程（Engineering），数学（Mathematics）四门学科英文首字母的缩写。】</p><p>作为半导体的对口领域，在攻读STEM 领域的美国学生中，攻读这些领域高级学位的人太少，而许多拥有STEM 学位的学生却从事着非STEM 职业 （例如金融、商业等）。没有足够的美国学生利用培训机会在社区学院和其他机构获得成为先进制造设备中技术人员所需的技能。</p><p>不仅仅是某一单一学科的人才每个工作组都有不同的培训和教育需求；然而，半导体专业的学生人数（例如半导体设计和制造专业的本科生）数量有所减少。这些工作群体的技能也在不断发展，部分原因是自动化和数字化程度的提高。设计和制造比以往任何时候都更需要云、人工智能和分析等数字技能。</p><p>虽然美国学院和大学吸引了大量世界各地的学生来STEM领域学习，其中大部分是攻读 STEM 硕士和博士课程的外国学生，但签证、移民的政策问题阻止了留学生留在美国工作。同时，随着各国都在发力半导体，很多留学生也会选择回到本国工作。</p><h2>美国的开放与不合作</h2><p>半导体行业的飞速发展，需要大量的人才。随着美国试图把半导体制造带回美国，美国确实吸引了许多半导体大厂。</p><p>SIA预计美国半导体行业将在未来十年内健康增长。随着数字化和连通性继续推动经济与现代生活的几乎所有方面，对芯片的需求预计将增长。目前全球芯片行业2022年收入为5740亿美元，预期到2029年末这一收入将增长近一倍，到2030年达到1万亿美元。</p><p>部分由于《芯片和科学法案》的通过，美国半导体行业有望在这一增长中占据很大份额。据 SIA 称，预计受芯片法案资助的半导体行业已在全国宣布了 50 多个项目，新增了 44,000 个就业岗位。随着芯片法案下的资金开始流动，其他项目可能会向前推进，还有一些项目可能会因为芯片先进制造税收抵扣的激励而向前推进。</p><p>本土人才不足，就需要引进外籍员工。美国移民和刑事司法改革倡导组织 FWD.us 主席 Todd Schulte 在接受雅虎财经采访时强调了移民改革对美国半导体行业未来的重要性。他的组织的研究发现，明年将有大约 5,000 名此类学生毕业，其中至少 4,000 人有兴趣留在美国在半导体工厂工作。</p><p>在半导体大厂进入美国本土的同时，本土的劳动力与国外的劳动力利益产生了冲突。台积电就是最有代表性的例子。不久前，台积电宣布将其亚利桑那州芯片工厂的投产时间推迟至 2025 年上半年。据台积电表示延迟的主要原因是缺乏专业工人，这一问题由于移民挑战而在半导体行业加剧。为了解决劳动力短缺的问题，台积电计划派遣中国台湾技术人员对当地工人进行 N4 工艺技术培训。然而，现行的美国移民法对拥有半导体相关领域高级学位并希望毕业后留在美国的国际学生构成了重大障碍。</p><p>在台积电方面称美国本地工人技能不够熟练，无法让工程如期开展的同时当地工会认为台积电在污蔑美国工人，他们曾经如期交付了英特尔的工厂项目。台积电这样的言辞只是为了使用更“廉价”的劳动力。台积电与美国工会各执一词之下，暴露出美国不愿合作的真实态度。</p><h2>美国的产学研合作</h2><p>为了发展本土人才，美国的教育界已经做出了许多努力。下图统计了美国高校与政府以及公司在芯片领域的合作项目。</p><p>芯片行业长期以来与大学和工程学院合作。未来，他们还需要与当地的科技学校、职业学校、社区学院加强合作；以及其他组织，例如美国国家科学基金会。</p><p>可以看到美国产研的领域十分宽泛，既包括芯片行业前沿领域的研究，如开发由十万个量子位驱动的以量子为中心的超级计算机，也包括了建立人才管道以支持半导体生态系统这样产业发展领域的研究专题。</p><p>此外，美国的教育系统也在通过一些竞赛活动，让更多学生（高中生）对芯片行业产生兴趣，以吸引更多学生进入芯片行业。Ansys参与的一个竞赛吸引了来自 58 个国家/地区的学生参加工程竞赛、介绍劳动力技能并激发就业机会。</p><p>美国也试图与其他国家合作进行人才培养。例如，美光科技和东京电子与美国和日本政府以及包括 RIT 在内的 11 所大学合作，为两国培养更加强大和高技能的半导体劳动力。</p><h2>结语</h2><p>从上图中也可以看到，美国高校合作的半导体公司大部分都是行业的头部公司。这一方面的原因是美国本土半导体公司确实在行业处于领先位置，另一方面也是因为美国的教育系统的成熟。美国依旧有望在前沿技术领域保持领先，但这或许难以解决美国芯片制造的焦虑。</p><p>不过美国培养人才的经验与方式的确值得我国借鉴。龙头企业和高水平高等学校、职业学校牵头，联合行业组织、学校、科研机构、上下游企业等角色组建一批产教深度融合、服务高效对接、支撑行业发展的跨区域行业产教融合共同体也将成为缓解我国芯片用人难的必要途径。</p><p>本文来自微信公众号“半导体产业纵横”（ID:ICViews），作者：半导体产业纵横，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498151434461314</id>
            <title>存储行业迎“iPhone时刻”，去中心化是不是元宇宙最优解？</title>
            <link>https://www.36kr.com/p/2498151434461314</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498151434461314</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:17:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 存储数据, 元宇宙, 集中存储, 分布式存储
<br>
<br>
总结: 自古以来，人类一直试图存储数据，而随着技术的发展，数据的存储方式也在不断演变。在元宇宙时代，集中存储正在被淘汰，因为它存在安全风险和缺乏互操作性的问题。相比之下，分布式存储通过冗余、校验、复制、分片和区块链技术来保障数据的可靠性和安全性，因此被认为是元宇宙中最优的存储解决方案。 </div>
                        <hr>
                    
                    <p>自古以来，人类总是试图存储数据，原始时期人们在洞穴里刻下壁画，用绳子记录事件，现代社会，人们用纸张写下文字，用镜头记录生活，在云端备份记录。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_54ea84c6d38341df8c4de73da3f21736@813924438_oswg320862oswg775oswg481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在漫长的信息存储历史中，随着技术不断发展，数据的存储方式也在不断演变。未来，那个被称为“互联网尽头”的元宇宙时代，人们又将会采用怎样的方式存储数据呢?</p><h2>集中存储正在被淘汰</h2><p>元宇宙正在从科幻走向现实，使元宇宙概念落地的重大突破口便在于人们如何存储和利用海量数据，让4K、8K、XR等内容具备更高普及度，并渗透到各个领域中。</p><p>目前来看，集中存储和分布式存储是企业布局较多的存储架构。其中，传统集中式存储起步早，技术成熟，结构简单，表现出足够的稳定性，对高IOPS、低延时和数据强一致性有很好支持。尤其近年来全闪存阵列存储发展迅速，IOPS性能提高到机械硬盘存储的100倍以上，能够有效解决IOPS性能痛点。不过，对于元宇宙数据的存储来讲，集中存储也面临不少问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6e0c9ea1b14f48dc90d22273eaf30c27@813924438_oswg384595oswg711oswg474_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_c6cfd26c3cc341b1b2d0090454549fda@813924438_oswg144oswg2oswg1_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>首先，集中存储是单个实体完全控制数据，这将带来安全风险，因为集中式服务器会出现单点故障;</p><p>举个例子可能会更加说明集中存储的安全隐患，比如公司有一份重要文件交给A，结果该文件在A处被盗，这就是中心化存储可能带来的数据流失。而且，当公司把文件交给A后，公司如何确保该文件的归属权还是只属于公司?如果所有人都把重要文件交给A一人保管，A是否在公司“一家独大”?</p><p>其次，集中存储缺乏互操作性，尽管几乎94%的公司使用这种技术来存储数据。比如在游戏领域中，游戏玩家可以在Roblox、Minecraft或Fortnite上花费数千小时游玩，但无论网络如何，游戏数据都无法相互转移。</p><p>毫无疑问，元宇宙将会成为数据存储技术、产品创新的最佳试验田，以往传统存储不敢想、不敢做的方向将会不复存在，取而代之的是全新范式的存储产品。</p><h2><strong>分布式存储是不是元宇宙最优解?</strong></h2><p>目前，除了集中存储，有不少企业采用分布式存储，而针对构建元宇宙所产生的数据，分布式存储是不是元宇宙在存储方面的更优解呢?</p><p>众所周知，数据在元宇宙时代是非常重要的资源，同时数据也会变成一种资产，即在虚拟世界里，每个人可以拥有虚拟的资产，而为了确保数据资产的安全，就需要涉及存储技术的应用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_276673b1f24842db8cb2ff34d36f9ff0@813924438_oswg152416oswg692oswg417_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_284b01fac7dd42d8802ece5df9a30312@813924438_oswg144oswg2oswg1_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>分布式存储通过多种方式来保障元宇宙的数据可靠性：</p><p><strong>一、冗余：</strong>分布式存储系统会在数据中添加冗余信息，以确保同一份数据可以在不同的节点上被重复存储。</p><p><strong>二、校验：</strong>分布式存储系统会使用数据校验技术，如奇偶校验、CRC32等，以检查数据的完整性和一致性。</p><p><strong>三、复制：</strong>分布式存储系统可以通过将数据复制到多个节点上，以增加数据的可用性和耐久性。</p><p><strong>四、分片：</strong>分布式存储系统可以将大型数据文件分成较小的片段，并将每个片段存储在不同的节点。</p><p><strong>五、区块链技术：</strong>分布式存储与区块链技术的结合可以提供更加安全可靠的数据存储和验证。区块链技术使用加密算法和去中心化的网络，确保数据不可篡改和永久存储。</p><p>一位分析师告诉Metaverse元宇宙：“分布式存储即保护数据不被篡改，原有的中心化存储数据集中于某单一平台上，分布式存储即将数据分散至我们合作的各个服务节点上，只有相应厂商即用户个人才能拿到密钥提取相关数据。”</p><p>同样举一个例子，分布式存储就像公司将文件发出时就已在链上对里面所属权进行了记录，当A处数据丢失时，“B”，“C”，“D”处还有相应的备份，这样可以让公司的数据更加安全。</p><p>而且，分布式网络存储系统采用可扩展的系统结构，利用多台存储服务器分担存储负荷，利用位置服务器定位存储信息，它不但提高了系统的可靠性、可用性和存取效率，还易于扩展。</p><p>好比分布式存储像一片森林，这片森林面积宽广无比，而元宇宙的各种应用就像树的种子，其借助分布式存储技术，可以在这片森林中“无限播种”，完全不用考虑土地面积。这也意味着，元宇宙依托分布式存储技术，不依赖于中心化服务器，人类在涌入元宇宙虚拟空间创造构建玩法，不会导致服务器瘫痪宕机，拥有更大的想象力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6d3adb1b99144995877b826d0107d0ad@813924438_oswg170044oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当下，在全球范围内，微软、谷歌、Netflix等厂商，国内像阿里云、腾讯云、华为、浪潮等云服务厂商，以及下游的许多应用服务提供商构成了整个产业链。尽管分布式存储还在起步和探索阶段，但许多应用项目已落地，并拥有了庞大的技术和产业生态。</p><p>整体来看，元宇宙产生的数据对于存储的安全性、扩展性和易用性都有非常高要求，而分布式存储去中心化、系统结构以及对于碎片化数据的存储能力都非常符合元宇宙存储的需求，因此，我们也可以得出一个结论，就是分布式存储是元宇宙存储的更优解。</p><h2>写在最后</h2><p>元宇宙和分布式存储技术的发展将为互联网带来巨大的变革。元宇宙将继续拓展其在教育、娱乐、医疗等领域的应用，同时也会进入更多的行业领域。而分布式存储技术将成为元宇宙数据存储和传输的核心技术，为元宇宙提供更加安全、可靠、高效的数据支持。</p><p>未来，可以预见元宇宙所带来的数据规模和数据增长速度将持续加快，这也必然会吸引更多数据存储厂商进入到该市场，不断探索和创新，推动分布式存储和元宇宙的可持续发展。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/tZPTgKJ16NMNTVw_c-j24w" rel="noopener noreferrer nofollow" target="_blank">“Metaverse元宇宙”（ID:NFTMall）</a>，作者：贾桂鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498166275708800</id>
            <title>微软、苹果、亚马逊求职量惊人，单职位日均超 50 人应聘</title>
            <link>https://www.36kr.com/p/2498166275708800</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498166275708800</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 10:30:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: LinkedIn, 求职者, 大型科技公司, Netflix
<br>
<br>
总结: 近日，国外简历制作网站 Resume.io 对数千个公司在 LinkedIn 上的招聘信息进行了研究，发现大型科技公司是美国求职者的首选，其中Netflix是最受欢迎的公司之一。其他备受追捧的公司包括亚马逊、微软和苹果。尽管科技行业存在裁员潮，但高薪待遇和对强大人才的吸引力仍然让人们追求科技职业生涯。 </div>
                        <hr>
                    
                    <p>近日，国外简历制作网站 Resume.io 深入研究了数千个公司在 LinkedIn 上的招聘信息，旨在发掘关键行业和大型科技公司中竞争力最强和最缺乏竞争力的美国公司，以帮助求职者更好地了解行业趋势和市场需求。</p><p>调查结果显示，<strong>大型科技公司是美国求职者的首选，单职位每天应聘人数排行前 7 的全部是大型科技公司。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_f7f27105753942d289872006f67bbae8@46958_oswg1042262oswg1080oswg2618_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>Netflix 居榜首，单职位简历申请量第一</h2><p>整体来看，媒体巨头 Netflix 以平均单职位每天 84.87 份简历申请「拔得头筹」。</p><p>事实上，早在 2020 年，一项针对科技专业人士的调查就已显示，Netflix 被视为最理想的工作公司，其地位领先于谷歌和苹果等知名品牌。</p><p>尽管如今的 Netflix 股价下跌了 180 亿美元，但它仍然保持着美国最受求职者欢迎的公司的地位，求职者对其岗位展现出了极大的青睐。</p><h2>亚马逊、微软、苹果紧随其后，英特尔竞争最不激烈</h2><p>除了 Netflix ，许多大型科技公司也备受美国求职者的「追捧」。</p><p>亚马逊位列简历申请的第二名，平均单职位每天有 73.25 人应聘。</p><p>微软紧随其后，平均每天有 57.9 人应聘。</p><p>苹果位列第四，平均单职位每天申请量为 53.74 人。</p><p>Meta 位居第五，平均单职位每天申请量为 52.42 人。</p><p>甲骨文为第六名，平均单职位每天申请量为 49.22 人。</p><p>值得注意的是，根据 Resume.io 的报告，英特尔是应聘竞争最不激烈的大型科技公司之一，单职位每天申请量仅为 12.07，远低于微软和苹果等公司。</p><p>尽管如此，由于熟练劳动力短缺可能会阻碍国内产业的复兴，英特尔正在努力填补关键职位的空缺。例如，英特尔俄亥俄州新工厂就需要招聘 3000 名员工。</p><h2>“裁员潮下仍不能阻止人们追求科技职业生涯”</h2><p>的确，近年来，硅谷的寒冬让许多科技公司不得不采取裁员措施来应对困境。</p><p>此时能跻身「大厂」，无疑让人艳羡。</p><p>据 Resume.io 的数据显示，去年有超过 1000 家科技公司解雇了 164411 名员工，然而，这并未能阻挡人们追求科技职业生涯的热情。</p><p>以微软为例，该公司在 2023 年裁员超过 10000 人，但在最具竞争力公司整体排名中排名第三，每个职位每天有 57.90 名求职者。</p><p>同样，排名第五的 Meta ，今年早前解雇了 10600 名员工，却仍然单职位每天能收到 52.42 名求职者。</p><p>在「裁员和招聘」的问题上，苹果 CEO 蒂姆·库克表示：“我们在招聘方面显得非常谨慎，因为要在很大程度上避免像其他科技公司那样一再进行大规模裁员。”</p><p>他坦言，苹果已经在为下一个版本开发人工智能，这可能会吸引全球的优秀人才加入公司并为其做出贡献。</p><h2>「高薪」之下的，对强大人才的吸引力</h2><p>当数以千计的人才渴望投奔大厂的怀抱，这显然与科技巨头们「一掷千金」的薪资待遇存在千丝万缕的关系。</p><p>今年 6 月，根据 MyLogIQ 收集、由《华尔街日报》分析的数据显示， Meta 斩获 2022 年科技巨头公司薪酬中位数的「top 1」 ，给员工支付的工资中位数约为 29.6 万美元（约 213 万元人民币），在全球范围内遥遥领先。</p><p>除了在2022年员工薪酬中位数上独占鳌头，追踪科技行业薪酬的 Levels.fyi 也曾经指出，Meta 的前 90 位 VR 开发者的平均年薪高达 53.88 万美元，折合人民币约 388 万元。尽管近年来 Meta 的业务严重依赖数字广告，但公司仍然不惜重金，用“高薪”招聘 VR 人才，以此大力推进元宇宙相关计划的开展。</p><p>今年 8 月，市场调查机构 Blind 发布最新报告显示，多家科技公司的「入门级工程师」就已经能斩获高薪，竞争力远高于其它同行：</p><p>谷歌：18.4 万美元（约 134.1 万元人民币）；</p><p>Meta：17.9 万美元（约 130.5 万元人民币）；</p><p>亚马逊：15.9 万美元（约 115.9 万元人民币）；</p><p>苹果：14.2 万美元（约 103.5 万元人民币）；</p><p>微软：14.1 万美元（约 102.8 万元人民币）。</p><p>对此，你怎么看？</p><p>参考链接：&nbsp;</p><p>https://resume.io/blog/the-most-competitive-american-companies-for-job-seekers</p><p>https://wccftech.com/apple-fourth-most-popular-tech-firm-for-us-job-applicants/</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/E_2ckp_lN4-fG_90MTU08w" rel="noopener noreferrer nofollow" target="_blank">“CSDN程序人生”（ID:coder_life）</a>，整理：朱珂欣，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498161374632072</id>
            <title>生物信息学：借助 AI 更高效地开启研究</title>
            <link>https://www.36kr.com/p/2498161374632072</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498161374632072</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 10:30:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生物信息学, AlphaFold, AI, 图像分析算法
<br>
<br>
总结: 生物信息学是利用数学、信息学、统计学和计算机科学的方法研究生物学问题。AI在生物学研究中展现出巨大优势，特别是在生物信息学领域。AlphaFold是一个深度学习系统，用于预测蛋白质结构，被评价为彻底改变了生物学。AI还在同源搜索、多重比对、基因组序列分析等领域有丰富的应用案例。图像分析算法可以帮助科研人员更快地比较细胞特性，AI还可以检测出用户想不到的差异或比较模式。生物学家可以通过学习常用的AI工具和提升职业技能来加速科学发现和提升科研效率。同时，关注实际成果和数据管理是使用AI进行科研的挑战。参与在线社区和项目可以提升全球视野和从他人学习。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_84bf777e0c2d424888cb66dc1922318b@46958_oswg1056959oswg1073oswg378_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>生物信息学 (Bioinformatics) 是指利用应用数学、信息学、统计学和计算机科学的方法，研究生物学问题。</p><p>随着计算机科学技术的发展，AI 在解决复杂又颇具挑战的生物学研究问题方面，显露出极大的优势，进一步加速了传统研究范式的转变及升级。</p><p>提到生物信息学，其中最广为人知的就是 AlphaFold。</p><p>AlphaFold 是一个深度学习系统，由 DeepMind 首次于 2018 年发布，主要用于预测蛋白质结构，<strong>被诸多业内人士评价为「彻底改变了生物学」。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_a8d1905086aa4a7c975f8b1d4e6c967c@46958_oswg303281oswg1080oswg436_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">AlphaFold 蛋白质结构数据库 &nbsp;支持蛋白质、基因或序列搜索</p><p>其实，除去类似 AlphaFold 这类广为人知的生物信息学进展外，<strong>AI 在同源搜索、多重比对及系统发育构建、基因组序列分析、基因发现等生物学领域中，都有丰富的应用案例。</strong></p><p><strong>以纳米毒理学为例，</strong>基于图像的人类细胞分析过程漫长又容易出错，手动分析图像、逐一比较每个细胞的扫描图像，需要花费大量的时间。</p><p><strong>借助免费开源软件 CellProfiler，</strong>没有编程基础的生物学家，也可以开箱即用地使用图像分析算法，探索银纳米粒子 (AgNPs) 对肝细胞的影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6413c270b12c461c88b34fdd09d0319d@46958_oswg224328oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">CellProfiler 于 2003 年上线 &nbsp;目前其项目团队位于 MIT &amp; 哈佛 Broad 研究所</p><p>生物信息学技能对于当代生命科学研究已经变得至关重要，作为一名生物学研究人员，<strong>能熟练地将机器学习工具，整合到数据分析中，</strong>必将加速科学发现、提升科研效率。</p><p>本文将从工具资源、方式方法、同行交流等角度，简述生物学家如何利用 AI，摆脱大量重复实验、加速传统科研进程。</p><h2>熟悉常用的人工智能工具</h2><p><strong>AI 在提升科研效率上具有重要意义。</strong>图像分析算法可以帮助科研人员更迅速、更定量地比较细胞特性，将其从海量重复性工作中解放出来，而自适应学习 (adaptive learning) 又可以进一步加速这个过程。</p><p><strong>此外 AI 通常还可以检测出用户想不到的差异或比较模式。</strong>通过将 AI「看到」的内容转化为数值数据，复杂的生物图像就可以转化为一个相对直接的数学问题，最终成为一个数据科学问题。</p><p>以 CellProfiler 为例，这个在线开源工具界面简洁、开箱即用，可以运行大量机器学习及深度学习算法，允许用户自定义 Pipeline，对量化 shapes、characteristics 以及 patterns 进行自动化分析。</p><p><strong>此外，还有 ilastik、QuPath、CDeep3M 等开源 AI 工具，</strong>无需强编程背景，只需加以练习便可以使用此类工具解决细胞及图像分析问题。</p><h2>提升职业技能，缩小同行差距</h2><p><strong>当代生物信息学家需要从以下几个方面出发，提升自己的职业技能：</strong></p><p>具备一定的编程能力，掌握类似 Python 这样的通用编程语言，并能熟练借助 Python 进行文本处理、科学计算、web 服务等任务；</p><p>有意识的培养自身基础的数学及统计能力，这对职业发展有很大帮助；</p><p>善于利用工具，无论是 scikit-learn 机器学习库，还是 ChatGPT，这些工具可以降低 AI 相关知识的学习门槛；</p><p>自学高质量网络课程，可以参考 Coursera、edX、Udacity 等在线平台的优质课程；</p><p>参与线上线下研讨会，加深与同行的交流，分享学习前沿方法</p><h2>追求长期价值，关注实际成果</h2><p><strong>对传统科研来说，追求时下最新的技术并不是必需的。</strong></p><p>AI 技术日新月异，但科学并不会每周都有变化，如果科研人员每天都忙于整合最新的工具、追赶文献进展，必然会陷入筋疲力尽的状态，<strong>倒不如停下来思考一下哪些方法和进展对于自己的科研而言最有用。</strong></p><p>虽然计算机在处理生物图像分析任务时，具有高效、能自定义规则等优点，但需要注意的是，在科研过程中引入 AI，<strong>要特别关注不确定性及人类偏见这类风险和挑战，</strong>力求成果中立可信，且具备可解释性。</p><p><strong>同时数据管理对于 AIForScience 而言也是一大挑战，</strong>有些项目会产生数以百兆计的图像和测量数据，当代科研项目大多以交叉学科为主，需要更多具备高维数据处理能力以及充分数据科学知识的专业人才加入项目团队。</p><h2>提升全球视野，从社区中学习</h2><p><strong>生物科学领域有一些很活跃的在线社区及优质项目地址，</strong>这些群组汇集来自全球各地的 AI 和生物学交叉学科的用户，有些成员也非常乐于分享。</p><p><strong>这些资源包括：</strong></p><p>* <strong>forum.image.sc：</strong>科学图像软件讨论小组，由 Broad 研究所与威斯康星大学麦迪逊分校合作设立</p><p>* <strong>BioStars.org：</strong>在线讨论小组，主要关注生物信息学、计算基因组学及生物数据分析</p><p><strong>* GitHub.com：</strong>生物信息学相关项目示例及代码</p><p>此外，<strong>提升 AI 技能的最佳方式是实践，</strong>除参与讨论、学习他人经验外，生物信息学家还可以通过尝试 Kaggle 上的一系列竞赛项目，在实操的过程中玩转 AI 程序和工具。</p><p><strong>学科交叉的趋势势不可挡，合理恰当地使用 AI，必将成为生物科学发展的一个重要推动力，</strong>希望每位生物学家都能从当下做起，借助 AI 加速科研进度、创新思考方式。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/0P4HNDHighPwZtObUWIo-Q" rel="noopener noreferrer nofollow" target="_blank">“HyperAI超神经”（ID:HyperAI）</a>，作者：三羊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498111824697478</id>
            <title>00后的科研新去向：哔哩哔哩</title>
            <link>https://www.36kr.com/p/2498111824697478</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498111824697478</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 09:49:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 透明面板, 隐形斗篷, 冲锋衣面料, 超级科学晚
<br>
<br>
总结: 中国科学院院士褚君浩在B站举办的超级科学晚上展示了透明面板和隐形斗篷的科学原理，以及冲锋衣面料的抗风性测试。这场晚会汇集了九位科学巨擘，展示了九场融合演讲与实验的硬核科学秀。B站还公布了哔哩哔哩2023年度五大科学焦点，包括AIGC、室温超导、脑机接口、黑洞和可控核聚变。B站成为了年轻人学习科学知识的热门平台，通过科普视频和知识UP主，满足了大众对科学的渴求。 </div>
                        <hr>
                    
                    <p><span style="letter-spacing: 0px;">一块“透明”的面板，挡在褚君浩院士的下半身。起初，观众还可以清晰看到院士的裤子，但是将这块材料稍稍旋转之后，院士的下半身“消失不见了”，观众透过面板看到了他身后的舞台场景。</span></p><p label="正文">台下的观众发出一阵惊呼。“我可以负责任地告诉大家，这不是魔术，而是科学手段。”中国科学院院士褚君浩说。“未来哈利波特的隐形斗篷将成衣柜里的日常用品。”</p><p>同样引发观众热议的还有一场冲锋衣面料的抗风性测试——15台马力巨大的吹风机，吹不动一层薄薄的面料。中国科学院研究员苏春雷介绍，这种纳米纤维膜复合面料，已经被应用于制作2022年冬奥会滑雪运动员的保暖服。</p><p>这两场引人惊叹的实验，发生在“bilibili超级科学晚”的现场。</p><p>10月28日，B站首次举办了一场以科学为主题的晚会。活动现场，观众们见到了月球及火星探测器副总设计师贾阳、中国科学院院士褚君浩、中国工程院院士李培根、诺贝尔化学奖获得者迈克尔莱维特等九位中外科学界“顶流”。这些来自不同领域的科学巨擘与B站知识区UP主同台，共同展示了九场融合演讲与实验的硬核科学秀。</p><p>晚会最后，B站还首次对外公布了“哔哩哔哩2023年度五大科学焦点”，分别是：AIGC、室温超导、脑机接口、黑洞、可控核聚变。</p><p><img src="https://img.36krcdn.com/hsossms/20231031/v2_5db469d7f65a4944b69ff5eaa0b26dea@1215450627_oswg296935oswg692oswg463_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p><p class="img-desc" contenteditable="false">中国科学院院士褚君浩 科普隐身材料</p><p><span style="letter-spacing: 0px;">新用户平均年龄不到22岁的B站，一直被认为是年轻人内容喜好的风向标。早在几年前，B站就曾被年轻人们戏称为“学习网站”，而在养成了“上B站学知识”的习惯后，科学科普类内容，更是顺理成章地成为了B站的热门常客。</span></p><p>在这个营销号与民科怪力乱神的年代，大众其实比以往更渴求那些能带他们拨开迷雾、抵达事实的人。</p><p>过去一年，我们越来越频繁地发现，B站总是成为公共科学热点讨论最活跃的场域。许多时长并不算短的科普视频，反而最终能成为流通在各个社交私域或公域的通识内容，也有一批垂类知识UP主经由科学热点事件出圈，成为新一代年轻人追逐、信任的偶像。</p><p>而这，显然就是B站举办这场“超级科学晚”，并发布“年度五大科学焦点”的底气所在。</p><p><img class="rich_pages wxw-img" src="https://mmbiz.qpic.cn/mmbiz_png/QicyPhNHD5vYIdjcxH07lRfpejgicjLxdNSmiaD2IEncOticdbbzS7emWuIHyATWan4rhcgJ9Je62bq9R6Q7iaWZP4A/640?wx_fmt=png" /></p><h2 label="一级标题">年度五大科学焦点，怎么选的？</h2><h3></h3><p>据“超级科学晚”活动现场的介绍，这份“2023年度五大科学焦点”，是基于过去一年B站用户在知识和科技品类的播放、投稿、互动综合数据评选而出的。</p><p>2023年，许多人通过B站第一次学习了AIGC这个词汇的含义，了解了“室温超导”的新进展，思考“脑机接口”对人类的意义，想象黑洞深处的画面，讨论可控核聚变可能带来的影响。</p><p><img src="https://img.36krcdn.com/hsossms/20231031/v2_9f3162565629415cacc71901c438ea21@1215450627_oswg1525593oswg1600oswg1200_img_jpg?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p><p><span style="letter-spacing: 0px;">以AIGC为例，2023年初开始，随着ChatGPT、文心一言、盘古气象等多个AIGC大模型的发布，大众对AI技术的好奇和热情空前高涨。B站不仅提供了科研工作者的专业科普内容，还有众多UP主通过有趣的跨界应用帮用户放飞想象力，看到了AI技术可以怎样改变人们的生活。2023年至今，B站AIGC相关视频播放量达90亿，播放时长达140亿分钟。</span></p><p>ChatGPT4发布后，西安电子科技大学博士后于建国（UP主@YJango），在B站发布了50分钟的科普长视频，获得了近300万播放。想学习更“硬核”AI知识的用户，可以跟随B站UP主、&nbsp;亚马逊资深首席科学家、斯坦福讲师李沐探索科技的奥秘。从AI领域论文精读，到动手使用AI技术，李沐成了无数用户的“互联网导师”，评论区中，用户互相答疑解惑的场景会让人误以为走进了大学课堂。</p><p><img src="https://img.36krcdn.com/hsossms/20231031/v2_a3349b51f0304d5ab90138da910d1f8c@1215450627_oswg110193oswg693oswg285_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p><p><img class="rich_pages wxw-img" src="https://mmbiz.qpic.cn/mmbiz_png/QicyPhNHD5vYsK0OcR4Bz8uUkpvhmgzMhbekRHhkNicC52lDFPxFm16q0SA8Bkx2ZSp5uMQ8IpBpLXdRITzNZYwA/640?wx_fmt=png" /><span style="letter-spacing: 0px;">除了最专业、时效性最强的前沿AI知识，在B站也能看到许多有趣的跨领域AI应用的内容。4月，36氪在B站发布视频，展示如何“用AI开一家假淘宝店”，获得368万播放；5月，B站UP主制作的一系列“AI孙燕姿”的演唱视频出圈，引发孙燕姿本人关注回应。</span></p><p>还有许多观众在B站看过的《弱智吧为何成为AI头号公敌》这条视频——UP主用“弱智吧”的奇怪问题测试每一类AIGC模型，掀起了一场万人围观的图灵测试狂欢，并收获了351万播放。</p><p>这条视频引发了B站社区中的一股风潮——每代GPT发布后，都有B站UP主积极测试GPT的最新功能，贡献出一个又一个既令人发笑又引人思考的视频。</p><p>不仅AIGC，2023年的现象级科学热点“室温超导”也引发了上万名科研工作者在B站科普理论知识及实验进展。对于这个晦涩难懂的科学概念，清华大学物理系副教授“来自星星的何教授”、清华大学化学工程博士“毕导THU”等多位UP主第一时间发布了解读视频，帮助用户追上人类科技的前线。</p><p>现在，B站已累计入驻知识类UP主超300万，也是院士入驻最多的互联网平台，有645位科学家、学者和多位诺贝尔奖得主入驻。稚晖君、影视飓风等年轻、有才华的科技类UP主也不断涌现。在B站，观众们不仅能向科学家学习硬核的科技知识，还能通过深入浅出的科普视频，轻松迈过从0到1的门槛。</p><p><img class="rich_pages wxw-img" src="https://mmbiz.qpic.cn/mmbiz_png/QicyPhNHD5vYIdjcxH07lRfpejgicjLxdNKhKCvnM4zsCibsjk1xX7VpFzYIYqBrTkBL0NHKRth0o3mWibSQ5AhoRQ/640?wx_fmt=png" /></p><h2 label="一级标题">站稳知识区后，B站迈向科技区</h2><p><span style="letter-spacing: 0px;">今年上半年，“B站播放时长最长内容是高等数学”登上微博热搜第一，引起热议。</span></p><p>很多人惊讶地发现，内容包罗万象的B站上，累计播放时长最长的竟然是大学数学课程，播放时长前10名的视频中，7条都是学习、知识相关内容。</p><p><img src="https://img.36krcdn.com/hsossms/20231031/v2_db3518fe32404d63ba38f5be48c3dfac@1215450627_oswg296448oswg693oswg462_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p><p><img class="rich_pages wxw-img" src="https://mmbiz.qpic.cn/mmbiz_png/QicyPhNHD5vYsK0OcR4Bz8uUkpvhmgzMhPLLNg2naaaLcPzOQUTYpDUb76Mmicf8icvdjfqZQtrYib47KEKrDp1M4Q/640?wx_fmt=png" /><span style="letter-spacing: 0px;">随着B站上的“学习氛围”日益浓厚，2020年，B站将知识区独立为一级分区，过去一年，有2.43亿用户在B站学习，是中国在校大学生人数的5.5倍。一大批优秀的知识区UP主如罗翔、毕导THU等受到追捧——北京大学法学博士罗翔的账号也成为了B站有史以来最快达到千万粉丝的账号。</span></p><p>继占领了知识内容的“高地”后，B站正大步迈向科技区。在崇尚快节奏、习惯碎片化的当下，静下心来观看一则20分钟以上的科普视频需要更强的驱动力和耐心。令人意外的是，虽然B站用户以年轻人为主，但他们却打破了社会对于年轻人追求短暂刺激的刻板印象，展现出了强大的求职欲、认真和耐心。</p><p>数据显示，B站新增用户平均年龄22岁，大部分为00后。科学和知识品类占用户搜索排名第2位，内容占B站播放量41%，00后将成为科学内容消费主力。</p><p>科技内容与知识内容有高度相似性，都需要专业、高质量的解读，这正是B站内容的壁垒。越来越多专业UP主的加入，已经证明了B站是最适合科学科普研究者向大众分享、普及科学知识及应用的平台。</p><p>2021年6月，海洋地质学家，中科院院士汪品先发布了第一条B站视频，快速收获了百万余粉丝，并且至今保持着稳定的更新；同年，诺贝尔化学奖获得者迈克尔莱维特也成为了一名UP主，与青年分享科研精神并鼓励终身学习。诺贝尔生理学或医学奖获得者爱德华·莫泽、诺贝尔物理学奖获得者乔治·斯穆特、中科院院士欧阳自远……科学家纷纷化身为B站UP主，是对于B站社区氛围最有力的认可，他们在这里打破了象牙塔的围墙，走向了大众科普。</p><p><img src="https://img.36krcdn.com/hsossms/20231031/v2_aba7f618b27f40708a5da3ccdfaed943@1215450627_oswg299203oswg692oswg492_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p><p class="img-desc" contenteditable="false">（汪品先院士发布的第一条B站视频）</p><p><img class="rich_pages wxw-img" src="https://mmbiz.qpic.cn/mmbiz_png/QicyPhNHD5vYsK0OcR4Bz8uUkpvhmgzMh6FficViaJQAmssvLPbhcfSKpZ1qgm0P3QXPicS9rJsQ25ryNAXmSFdzBA/640?wx_fmt=png" /><span style="letter-spacing: 0px;">相比其他内容平台，B站科技类内容的优势在与“既快且专”，多一些专业分析，少一些“民科营销”，多一些二十分钟以上的深度讲解，少一些耸人听闻的标题和配乐，实事求是的求知氛围，在这个快节奏的时代显得难能可贵。</span></p><p>B站帮助许多年轻人满足求知欲，也见证了他们“从学生到专家”的历程。就在“超级科学晚”举办的这一天，拥有500多万粉丝的B站知识区UP主毕导也向粉丝们宣布了一个好消息：他终于获得了清华大学的博士学位，从化学工程专业顺利毕业。</p><p>“每当我们用视频与大家交流科学中的快乐和美的时候，是我自己最满足的时刻。”毕导在视频的最后说。“能有这么多人聚在我们视频的评论区聊物理、聊化学，聊水花和sub(n,n,17)，这已经是个奇迹了。”</p><p>共同学习，共同进步，B站科技区的UP主与观众们共证明了，除了脚踏实地的工作生活，这代年轻人也没有忘记仰望星空。年轻人有大量学习知识、追随前沿科技的需求，而且他们能把热情传递给更多人。</p><p><img class="rich_pages wxw-img" src="https://mmbiz.qpic.cn/mmbiz_png/QicyPhNHD5vYIdjcxH07lRfpejgicjLxdNRTiapJiayoFpsiaib4xibCKjXQmWxlzF6crPzgPeCC4N4XWoibVKtmMCtBrQ/640?wx_fmt=png" /></p><h2 label="一级标题">结语</h2><p><span style="letter-spacing: 0px;">B站曾经成功打破过被各大卫视垄断多年的、对“跨年晚会”的定义，把“B站跨晚”做成了独一档的互联网IP。</span></p><p>这一次的“超级科学晚”，不仅前所未见地让前沿科学以实验秀的形式走到大众面前，也再度证明了这家公司具备把平台内容生态凝炼成一场晚会的IP制造能力。</p><p>这种IP效应是否能反哺平台，帮助B站持续站稳科学科技品类的内容高地，我们同样拭目以待。</p><p><img class="rich_pages wxw-img" src="https://mmbiz.qpic.cn/mmbiz_png/QicyPhNHD5vaOxGeWZIKFJ4FRickeU8icTU2xbNcEW5Pzy3zWkJ6GLXQuovibYViaMpoOY1OUEPxy3Ul8QFmzSEgJYw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></p><p><img class="rich_pages __bg_gif wxw-img" src="https://mmbiz.qpic.cn/mmbiz_gif/QicyPhNHD5vaOxGeWZIKFJ4FRickeU8icTUooWLl3iapSXDkYubrZtuMbPxJcEULLZPs0VZrbhjlFdbvfxaUwicXSUg/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" /></p><p><img class="rich_pages wxw-img" src="https://mmbiz.qpic.cn/mmbiz_png/QicyPhNHD5vaOxGeWZIKFJ4FRickeU8icTUoUaqPppIwaicHOeibmnprVfiaq2tOVicdVOZFxiaAv9YzJNYJReHTQhCdqA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498075554617473</id>
            <title>​无产业，不VC？</title>
            <link>https://www.36kr.com/p/2498075554617473</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498075554617473</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 09:25:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 产业投资者, 优势, 资金, 尽调
<br>
<br>
总结: 产业投资者在当前硬科技时代具有优势，能够更好地募集资金和进行尽调，这是因为他们懂得产业背景和资源，能够触达核心关键问题，对于投资赛道的转变和企业的需求有更敏锐的洞察力。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_5fbcb1312ca441428a4426773a3d01dc@46958_oswg740539oswg1059oswg503_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在硬科技时代，“无产业，不VC”已经成为当下投资人的投资共识。那么，产业投资者到底有哪些优势，它为什么能在短短几年内快速兴起？随着产业投资的兴起，财务投资者被「挤压」，渐失「阵地」。财务投资人真的没有竞争优势了吗？</p><p>带着这些问题，家办新智点最近访谈了一批GP和LP，试图对以上问题做出解答。</p><h2>产业投资「正热」</h2><p>“在智能时代，风险投资在产业发展中扮演了更加重要的角色，好的资本一定不是纯的金融投资者，而是战略投资人，最好的投资人应该是懂产业的投资人。”2017年，时任红杉资本全球执行合伙人的沈南鹏在第四届世界互联网大会中认为好的投资人应该懂产业。&nbsp;</p><p>近年来，随着硬科技投资的兴起，产业投资人已成为一道亮丽的风景。据相关数据显示，2022年，中国新增74家独角兽企业，其中17家是由产业孵化的创业公司成为独角兽，占增量的四分之一，增加了约3倍。&nbsp;</p><p>当下，几乎人人都在谈产业投资。为什么产业投资越来越「热」？<strong>家办新智点与一些家办LP以及产业投资机构深入交谈后，发现有以下几点重要原因：</strong></p><p><strong>首先，投资赛道的转变。</strong></p><p>过去，VC/PE投资的领域多为互联网、移动互联和消费领域，没有太多的硬科技属性，更多的是对商业模式的迭代和升级。&nbsp;</p><p>而现在国产替代投资主题下，投资人是否具备产业背景资源，懂技术和产业变得极为重要。金融科班出身的人不再吃香，越来越多的投资机构喜欢招聘理工科背景的人才，或者曾在产业龙头做过研发的人才。&nbsp;</p><p>李琛是某VC的创始人，他的机构以投资航空航天和汽车产业见长，他认为，对早期VC来说，更需要靠产业认知来「分辨」该项目是否具有未来发展前景极为重要。李琛本人并非金融背景出身，此前曾从事过发动机的研究，而他的同事也多是工科背景出身。&nbsp;</p><p><strong>其次，「风口项目」不再。</strong></p><p>在单一家办盛资本投资代表田华看来，移动互联网时代，基本没有「水下赛道」和「水下项目」，都是大家都能看得见的「风口」，更多拼的是GP快速决策能力，搜寻项目能力倒在其次。&nbsp;</p><p>对VC/PE来说，能否快速决策，「抢」到好项目极为重要。“如果在一轮融资中，A机构没有扣下扳机，B进入了；那么在下一轮融资中，A机构可能就会更加积极。”&nbsp;</p><p><strong>再次，企业更喜欢能给自己带来「附加值」的GP，</strong> 譬如，供应链上的附加值，或者直接给订单等。这就要求投资人必须成为行业中的专家和局中人。如果没有这样的产业背景，也就无法对产业有全面的布局和观点，更无法帮助创业者完成战略愿景。&nbsp;</p><p><strong>第四，从PE阶段来说，如今各行各业内卷严重，产能过剩。在这种情况下，产业链上的垂直并购整合需求将越来越大。</strong></p><p>譬如，一些上市公司为了寻求第二、第三增长曲线，需要通过收购一些标的较好的公司，在产业链上做一些延伸。而并购基金能否成功的关键，在于是否拥有产业能力。&nbsp;</p><p>Emily在某上市公司担任董秘，此前曾在VC/PE机构工作很多年。她认为，并购整合并不只是一个简单的投资协议、收购协议。它需要在前期对标的做出判断，并购方的收购意图是什么，并购后，并购方能否与被并购方产生产业协同，做到1+1&gt;2？并购后，是否要帮助引入新的管理层等。这些都取决于，该GP是否有丰富的产业并购经验。&nbsp;</p><p><strong>第五，从募资角度来看，拥有产业资源的GP能更好地募到资金。</strong> 如果和过去一样，一个GP没有产业资源，只有财务投资能力，那么将很难募集到资金。&nbsp;</p><p><strong>第六，从项目来源上说，拥有产业背景的投资人更容易发现早期项目。</strong></p><p>田华认为，未来20年的新范式是第二产业的科技化和基础科学的产业化，各技术路线下细分行业多，不少好项目会隐藏在水下。对投资人来说，具有扎根产业的“大量、持续、优质”的项目来源，是新周期下更重要的成功要素。因此，投资人基于产业的资源和认知比纯金融的资源会越来越重要。&nbsp;</p><p>举个例子。A机构和B机构同时看一个赛道。A机构有更多的产业关系和积累，会比金融背景的B机构更好的和创业者共情，有更深的产业理解甚至有比创业者更深的产业洞见，更好的调动产业资源为创业者在战略 、人力、供应链、运营等赋能，创业者更容易和A机构合作，甚至给与更低的项目估值。而B机构可能只能「望洋兴叹」。&nbsp;</p><h2>产业投资人的「优势」</h2><p>那么，产业投资人有哪些优势呢？&nbsp;</p><p><strong>第一，募资更容易。</strong></p><p>不少家办LP纷纷表示，对于VC们而言是否具备产业背景极为关键。而他们在投资GP时，基金管理人是否具备产业资源和背景成为了关键考量维度之一。&nbsp;</p><p><strong>第二，尽调能触达核心关键问题。</strong></p><p>Emily向家办新智点表示，作为财务投资人“很容易被骗”，核心原因是由于不熟悉产业，因此在尽调企业时无法提出最核心和关键的问题。「在ChatGPT出现之后，人们都可以通过提问来获得答案，因此对于人类工作能力最大的影响是能否提出最具价值的问题。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_991fcc97ae1f46048a631fed38994ff7@000000_oswg95248oswg1080oswg541_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，对于具备产业背景的投资者人而言，面对产业的变化比较敏感，对于大企业高层的变动、核心团队都更为熟悉，能够快速追踪到行业的发展趋势，同时快速触达产业资源。在尽调上，他们也更能触达关键问题。&nbsp;</p><p>对此田华做了总结。对于技术的理解，财务投资人会“更乐观”，多从「供给端」出发，更多在看新技术是不是具有领先地位，预判的市场规模更大或产业落地的速度更快。产业投资人则会相对实际，从「需求端和工程端」出发，看企业的客户是否真实存在，客户会不会买单，新技术落地到产品的可行性，以及新产品的渗透率是快还是慢。&nbsp;</p><p><strong>第三，能为被投项目带来「附加值」。</strong></p><p>在投后赋能上，李琛会帮着企业去完善团队，甚至在投前会帮他们去做整个商业策划。譬如，如何将技术变成产品，产品变成商品，如何做产品营销。商业策划完后，他会帮他们做商业运作，甚至包括融资，对接产业资源（客户端和人才端）和相关的行业协会等。&nbsp;</p><p>而田华则表示，产业投资人不仅可以协调产业资源让被投企业更快拿到产业订单，甚至在研发和创新上给予一定基于实际情况的落地意见，甚至基于技术方向、技术原理和创业者进行理论级的探讨。&nbsp;</p><p><strong>第四，产业投资人更「务实」。</strong></p><p>田华告诉家办新智点，产业投资人更关注如何把事情组成。&nbsp;</p><p>经营实业的做事逻辑更多是闭环思考，只有切实可行时可能才会投入资源。比如投资前，会通盘闭环讨论清楚研发、工程、工艺、供应链、技术，市场、销售渠道、客户、成本效益之后，才会做决策。投资之后，也会用经营企业的思维去验证被投项目能否把产品或者项目做得成。&nbsp;</p><h2>财务投资人「危机四伏」</h2><p>伴随着产业投资人的热潮，可以感受到的是，财务投资人的阵地在慢慢收缩。细究原因，主要有以下几点。&nbsp;</p><p><strong>第一，一二级市场利差收窄，甚至倒挂。</strong></p><p>之前，中国的VC/PE市场在一二级市场上有着巨大的利差。通常，一级市场估值低，机构投资一个项目后，可以通过IPO退出，赚取高价利润。&nbsp;</p><p>但现在随着注册制推行，一级市场估值偏高，IPO退出变难，投资逐渐回归理性，大家更看重企业的内在价值。从这个角度来看，风险型基金和成长型基金以及PE基金之间的竞争壁垒在慢慢消失。&nbsp;</p><p><strong>第二，优质项目越来越少。</strong></p><p>在底层资产中，优质项目越来越少，尤其对成长型基金和PE基金来说，更难找到好项目。即使遇到好项目，如果它们无法为项目带来「附加值」，譬如，产业链资源、供应链资源，那么也很难投进去。&nbsp;</p><p><strong>第三，投资逻辑发生了变化。</strong></p><p>“以前VC/PE的财务投资逻辑已经无法继续适用了。”Emily对家办新智点说道。&nbsp;</p><p>过去的VC/PE大多具有美元基金背景，在移动互联、消费时代等行业，它们投的是一种商业模式：对某种商业模式具有深刻的认识；商业模式是否超前，是否是未来的一个发展方向；从消费者角度来说，商业模式能不能形成持续的「护城河」，譬如，规模效应、扩张效应、网络效应。&nbsp;</p><p>它并不需要拥有某一个专业的投资背景，更多的是还是基于对投资和金融本身的理解。如今，随着行业越来越细分，过去那种「广撒胡椒面」的时代已经过去。&nbsp;</p><p><strong>第四，募资难。</strong></p><p>如今宏观环境动荡，随着A股收紧，IPO难，退出难，过去10年以来，中国的VC/PE的退出整体数据并不令人满意，对LP的说服力并不充分。受低DPI影响，LP出资意愿下降，财务投资人在缩水。&nbsp;</p><p><strong>第五，转型难。</strong></p><p>在李琛看来，财务投资人想要转型，挑战极大，“可能要换血”。他认为，任何组织都是有基因的，虽然他们可能长期研究并扎根于某个行业，但始终没有产业投资人对产业认识的深度。如果要转型，可能需要财务投资人更加专注、聚焦于某个行业，找到自己感兴趣或是机会的方向，“将井钻得更深一些，要耐心一点。”&nbsp;</p><h2>财务投资人并非「穷途末路」</h2><p>那么，财务投资人已经失去竞争力了吗？一些专业资深人士并不这么看，原因如下。&nbsp;</p><p><strong>第一，VC源于美国，是一个相对独立的体系。</strong> 风险投资的核心本质在于能够对一些趋势做出判断，它赌的是未来的创新和发展。&nbsp;</p><p>举个例子。美国VC投资的是一种前沿趋势，如AI、ChatGPT以及脑机接口等。而中国的产业投资人目前大多投的是国产替代。正是由于整个产业链中，国产替代最为薄弱，是一个短板，才需要补齐。&nbsp;</p><p>某市场FOF管理合伙人Bob认为，一级市场是有它的原创性和创新性的，如果仅仅只是围绕「产业」，可能会出现很大问题。&nbsp;</p><p><strong>第二，产业趋势或者产业优势可能并不会长久存在。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_74d9dca812f44da4a37d00a021478a18@000000_oswg39956oswg936oswg413_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>第三，在投资规模上，那些对资金需求量比较大的企业，依旧具有优势。</strong> 譬如，某些产业项目非常偏爱险资。另外，「财务投资人+产业投资人」也是一种模式，财务投资人可以做产业投资人的「顾问」，以充分发挥其传统优势。&nbsp;</p><p><strong>第四，在尽调上，产业投资人未必能看得懂所有的技术路线和演进方式。</strong></p><p>譬如，在太阳能光伏领域，有些技术可能连科学家还未弄明白，产业投资人可能更不明白了。&nbsp;</p><p>对此，家办LP大洲也认为，尽管财务投资人看不懂行业，在尽调时无法提出最核心和最关键的问题，但可以通过财务报表以及一些传统的尽调方法去发现问题，并通过自己的方式去验证这些信息。相反，有时候产业投资人了解到的产业信息越深，对其的投资判断可能会是一个冗余的信息。&nbsp;</p><p>大洲坦言，一些项目的商业模式其实就是To B模式，只是大客户驱动的一个行业关键零部件中的一个公司而已。“它能给你带来多大的财务回报，很难说，产业并不能决定一切。”&nbsp;</p><p><strong>第五，在科研和产业落地时，项目的成功与否不仅仅只取决于产业技术，还取决于当时的社会环境以及大家对该技术达成的共识和选择。</strong></p><p>举个例子。光伏成本如何实现最优化，有时候并不取决于技术是否是最先进的，而是取决于产业规模。&nbsp;</p><p><strong>第六，过多的产业赋能有可能是「束缚」。如果产业投资人过多给予被投企业「产业赋能」，可能会限制它的发展。</strong></p><p>Bob认为，英特尔之所以输给台积电的一个原因，是因为英特尔的整个产业链完全闭环，必须使用自己产业链上生产的产品。时间一长，英特尔就失去了对外的竞争力。&nbsp;</p><p>同理，如果被投企业一直都使用同一个产业链资源，不仅会失去独立发展的能力，缺乏对外竞争能力，且还会导致垄断。这也是国内一些科技巨头关联企业难以IPO的原因。&nbsp;</p><p>另外，在关于订单赋能上，大洲认为，一时的订单赋能并不能保证企业能有一个长久的发展。此外，即使是一家产业巨头旗下的CVC，它所能覆盖到的也只是自己的主业和领域方向，不可能覆盖到所有领域。&nbsp;</p><p>从这点上来说，反而是财务投资人的机会更多一些。只不过当下时机，对财务投资人而言提出了更高的要求，需要对过去一以贯之的打法进行优化和调整。&nbsp;</p><p>而在财务回报上，产业投资能否带来超额回报还未知。大洲表示，目前还没有哪家产业背景的GP在投资回报里做到了「遥遥领先」。虽然产业投资扮演的角色越来越重要，但最终还是要对投资结果和投资回报负责。&nbsp;</p><p>毕竟，对于家办LP来讲，无论是财务型投资人还是产业型投资人，归根结底是要能给自己挣到钱，真金白银的钱，而非只是账面回报。&nbsp;</p><p>（备注：文中部分人物名字为化名）&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg5MDU1OTIzMg==&amp;mid=2247494700&amp;idx=1&amp;sn=5e49b4ba12c851ba95d3a371c0a954a8&amp;chksm=cfd86243f8afeb55d4f07aed71723aaab9d4ef44a55c593bbf0c483dc8bafc50042e8b9941a6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“家办新智点”（ID：foinsight）</a>，作者：foinsight，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2497834558363777</id>
            <title>给无人机装上大脑开始群聊，人机交互的新进展</title>
            <link>https://www.36kr.com/p/2497834558363777</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2497834558363777</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 08:57:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QQ, 微信, 阿里旺旺, AI玩玩群聊
<br>
<br>
总结: 西北工业大学研究团队基于国产大模型研发了“群聊式”无人机控制框架，实现了无人机集群在语言沟通中动态协同，打破人类和机器的交互壁垒，拓展了“临地安防”的应用场景。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_bf3aca63c8f94e64bf9e76fba53c42e7@000000_oswg73523oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源&nbsp;| 西北工业大学</p><p>自聊天软件开始兴起，它们就在渗透我们生活的同时也在悄然间改变我们的生活。</p><p>对相当大一部分国内用户来说，QQ是互联网启蒙产品，微信是移动互联网的入门APP，阿里旺旺是了解网购必不可少的工具......这些软件的初衷都是社交，也都带有群聊功能，现在AIGC的时代兴起了，那么有没有可能让AI玩玩群聊呢？</p><p>就在刚刚过去的上周末，一则消息值得关注：西北工业大学光电与智能研究院李学龙教授和同事们在机器交互方面取得创新进展，他们<strong>基于国产大模型研发了“群聊式”无人机控制框架，给每架无人机装上了大脑，让无人机集群在语言沟通中动态协同，实现了开放环境下“人机”和“多机”的对话交互，打破人类和机器的交互壁垒，更加拓展了“临地安防”的应用场景</strong>。</p><p>“临地安防”涵盖低空安防、水下安防及跨域安防等领域，是面向临地空间内防卫、防护、生产、安全、救援等需求的技术体系，具备多元化、跨域化、立体化、协同化、智能化等特征。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_d98ad56f9a534407b1d0cce2295fa912@000000_oswg374127oswg553oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：西北工业大学</p><p>1997年，IBM的“深蓝”战胜卡斯帕罗夫，AI首次在国际象棋领域战胜人类。2016年，谷歌的“阿尔法狗”击败李世石，围棋不再是“人类智慧的最后堡垒”。虽然“深蓝”和“阿尔法狗”都足够强大到被人铭记，但争议也始终存在，最常见的一种是说它们的能力太狭窄，“深蓝”不会围棋，“阿尔法狗”不会国际象棋，这样的AI与其说是智能倒不如说是超级玩具。</p><p><strong>人类虽然不可能做到每秒数万亿次的计算，但同时掌握两种甚至更多技能可并非天方夜谭，只是学习过程难以准确量化，这背后的秘密就在“通用”二字上。</strong></p><p>最近一年多来，AIGC与大模型能成为全球瞩目的当红炸子鸡，很大程度上就是因为它们带来了一丝AGI，即通用人工智能的曙光。然而读万卷书还要行万里路，在开放环境中，大模型需要真正地“走”进物理世界，才能切实地理解复杂任务、解决实际问题，落地应用产生价值。</p><p>之前曾多次说过，AI可以视为对人类大脑工作原理的逆运用，这次李学龙教授团队的“AI群聊”也不例外，同样是受人类的认知模式启发。</p><p><strong>团队将人类认知形成的高度自主性概括为“思维计算—实体控制—环境感知”的三元交互，建立了由“书生·浦语”大模型驱动的自主无人机“群聊式”控制框架，实现了开放环境和复杂任务中的智能交互、主动感知和自主控制，提高了无人机任务执行的自主性。</strong></p><p>李学龙教授团队经过研究后认为，自主无人机集群的主要能力有三：<strong>类人对话交互、主动环境感知、自主实体控制。</strong></p><h2>类人对话交互</h2><p>无人机现在已经屡见不鲜了，但大部分还是要由地面指令操控。<strong>要实现可控自主，就要探索人类用户与无人机的交互方式，让无人机理解复杂任务中的用户需求，这是一切的前提。</strong></p><p>“AI群聊式”的对话交互方法，即是李学龙教授团队的针对性解决方案。团队为此设计了任务引导的主动感知机制，提出了多传感器融合的低空搜索、动态避障和视觉定位算法。</p><p>在实际任务执行中，无人机根据感知信息和任务目标，动态调整飞行路径和观测位姿，尝试从不同角度和位置感知周围世界，逐渐降低环境中的不确定性，实现高效的信息采集和任务执行。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_9f8ff9a01156426a8f26cc1557539df8@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>主动环境感知</h2><p><strong>无人机在飞行过程中会主动感知外部环境，实时调整任务规划，这也是完成复杂任务的关键环节。</strong>针对无人机在飞行中可能遇到的情况，李学龙教授团队设计了任务引导的主动感知机制，提出了多传感器融合的低空搜索、动态避障和视觉定位算法。</p><p>在实际任务执行中，无人机根据感知信息和任务目标，动态调整无人机飞行路径和观测位姿，尝试从不同角度和位置感知周围世界，逐渐降低环境中的不确定性，实现高效的信息采集和任务执行。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_01b45a70fed94ccb827c47b8b230e804@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_694b04e02f1045e2b1886c5229a96bcf@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>自主实体控制</h2><p><strong>大模型时代新型智能体的研究重点在于探索复合智能体形态，即现在常说的具身智能，以及增强复杂任务处理能力。</strong>针对无人机的复合形态，李学龙教授团队专门设计了夹爪等末端执行器，传统无人机由此拓展为“飞行机器人”，长出“手”来，具备抓取等能力。</p><p>团队同时构建了异构无人机集群协同控制机制，结合环境感知反馈，实时调整无人机编队的飞行状态，使集群分工执行区域搜索、目标定位和抓取等任务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_49b3fc2355b244e393361ffcb0ad3482@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_3978ebb1ad5449a3b327d80aa98db902@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>社交软件与群聊极大地方便了人们的沟通，对我们的生活产生了莫大影响。现在AI 2.0时代已经成了明显的趋势，让AI也组群，让它们也能商量着干活，同时和人类无障碍地沟通和交流，更好地服务于我们的实际生活，这是很容易联想到的，而且这极具科幻风格的一幕正在逐步成为现实。</p><p><strong>通过“群聊式”对话，将声音、图像和无人机自身状态等多种信息，通过大模型转换为自然语言的对话形式，实现了人机，无人机之间自主和直观的交互方式。同时李学龙教授团队设计了一套高效的实时反馈机制，使得无人机能够在任务执行的关键节点通过对话报告自身状态、寻求用户确认，大大提高了复杂任务执行的稳定性和安全性。</strong></p><p>前面说过，李学龙教授团队将人类认知的高度自主性概括为“思维计算—实体控制—环境感知”的三元交互，此次的“无人机AI群聊”与“书生·浦语”大模型的结合，是团队将人类智能“思维计算—实体控制—环境感知”的三元交互模式应用于AI的一次成功尝试，依托AI、大模型、无人机和多种传感器，对安防巡检、灾害救援、空中物流等“临地安防”场景下的应用都具有重要意义。</p><p>同时“书生·浦语”大模型作为上海AI实验室的作品，即使相比GPT等外国先进产品仍有差距，在国产同类型竞品中也算是佼佼者。此次作为无人机AI群聊的依托，也是为AIGC与大模型的落地应用开辟了新思路。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA5NTI1MDEyNA==&amp;mid=2652710590&amp;idx=1&amp;sn=eadaa6a57da3dc343ba347009704220c&amp;chksm=8babb51dbcdc3c0b1d54c423d0051fb01ff4a5d36f334a0413e623e4920372f4814dfdaad66d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“亿欧网”（ID：i-yiou）</a>，作者：番摊123，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498070446545026</id>
            <title>用童话训练AI模型，微软找到了探索生成模型参数的新切入点</title>
            <link>https://www.36kr.com/p/2498070446545026</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498070446545026</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 08:55:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大语言模型, 参数发挥作用, 童话故事, 小模型
<br>
<br>
总结: 微软的研究人员通过使用童话故事来训练小型语言模型，以减少大型模型的学习负担并理解参数的作用。这种方法可能开创了新的研究方向。 </div>
                        <hr>
                    
                    <blockquote><p>即便大语言模型的参数规模日渐增长，其模型中的参数到底是如何发挥作用的还是让人难以琢磨，直接对大模型进行分析又费钱费力。针对这种情况，微软的两位研究员想到了一个绝佳的切入点，用生成简练但是又涵盖各种常见逻辑和语法的童话故事来作为模型的生成任务，这样做能在减少模型的学习负担的同时，保留模型对逻辑和语法的学习能力，进而用小模型来分析参数发挥的作用。这种方法可能会开创一条新的研究道路。&nbsp;</p></blockquote><p>人们都知道，学英语不是一件容易的事。但假如「学生」是一台计算机，就可以这样高效地学英语：只需将互联网上堆积如山的文本，输入一个名为神经网络的巨大数学模型即可。</p><p>这就是像 OpenAI 的 ChatGPT 这样的生成式大模型背后的工作原理，在过去的一年里，它能够面向广泛的主题连贯地交谈（即便会存在「幻觉」），效果让所有人都感到惊讶。</p><p>但这种方法也有缺点：首先，将庞大的文本档案转化为语言模型所需的训练语料，成本高昂且耗时。另一方面，即使是训练大语言模型的人也很难理解它们的内部工作原理，这反过来又使得人们很难避免设计上的失败。</p><p>面对这些困难，一些研究人员选择在较小的数据集上训练较小的模型，然后研究模型行为。布朗大学语言模型研究员 Ellie Pavlick 说：「这就像果蝇基因组测序与人类基因组测序的关系一样。」</p><p>现在，在近期发布的一篇论文中，微软的两名研究人员介绍了一种训练微小语言模型的新方法：用童话故事训练模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_fd1c0a6c6a5e4a36a8473e1e7573f883@46958_oswg25101oswg1080oswg333_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文链接：https://arxiv.org/pdf/2305.07759.pdf</p><p>为 ChatGPT 接口提供动力的大型语言模型 GPT-3.5 有近 2000 亿个参数，它是在由数千亿个单词组成的数据集上训练的（OpenAI 尚未发布 GPT-4 的相应数据）。训练这样的大型模型通常需要至少 1000 个称为 GPU 的专用处理器，并行运行数周。只有少数公司能够筹集到如此的资源，更不用说训练和比较不同的模型了。</p><p>这两位研究人员的研究表明，比当今最先进的系统小数千倍的语言模型在接受这种基于童话故事的训练后，能迅速学会讲述连贯且符合语法的故事。他们的研究成果指明了新的研究方向，可能有助于训练更大的模型并理解它们的行为。</p><p>艾伦人工智能研究所（Allen Institute for Artificial Intelligence）的语言模型研究员 Chandra Bhagavatula 说：「我发现这篇论文信息量很大，这个概念本身就超级有趣」。</p><h2>从童话故事说起</h2><p>作为语言模型核心的神经网络是一种数学结构，其灵感来源于人脑。每个神经网络都包含许多按层排列的人工神经元，相邻层的神经元之间存在连接。神经网络的行为受这些连接点（称为参数）的控制。在语言模型中，根据初始提示词（prompt）和已经生成的单词，参数控制着模型下一步可能吐出的单词。</p><p>只有在训练中，当模型反复将自己的输出与训练数据集中的文本进行比较，并调整参数以提高相似度时，模型才会真正 「活 」起来。一个未经训练、参数随机的网络很容易通过几行代码组装起来，但它只会产生胡言乱语。经过训练后，它通常可以「似是而非」地继续处理陌生文本。较大的模型通常会进行进一步的微调，使其学会回答问题和遵循指令，但训练的主要内容是掌握单词预测。</p><p>单词预测的成功需要语言模型掌握多种不同的技能。例如，根据英语语法规则，「going」一词之后的下一个词很可能是 「to」，而与文章主题无关。此外，完成 「the capital of France is」（法国的首都是__）需要系统掌握事实知识，而完成包含 「not」一词的段落则需要系统掌握基本的逻辑。</p><p>「原始语言非常复杂，」DeepMind 的机器学习研究员 Timothy Nguyen 说。「为了让有趣的语言能力出现，人们采用了数据越多越好的方法。」</p><p>Ronen Eldan 是一位数学家，2022 年加入微软研究院研究生成语言模型。要想做到这一点，最直观的方法是使用小数据集，而这又意味着必须训练专攻特定任务的模型，这样它们就不会过于分散。起初，他想训练模型解决某一类数学问题，但一天下午，在与 5 岁的女儿相处时，他意识到童话故事非常适合。</p><p>他说：「在我给她读了一个故事后，我就想到了这个点子。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_7fb5e5c7fef14014bc683a5195f48459@46958_oswg1271602oswg1080oswg917_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Ronen Eldan。</p><p>为了生成连贯的童话故事，语言模型需要学习世界性的事实，跟踪人物和事件，并遵守语法规则——这些都是大型模型所面临的挑战的简单版本。但是，在海量数据集上训练的大型模型在学习真正重要的规则的同时，也学习了无数无关紧要的细节。Eldan 希望，儿童故事的简洁性和有限的词汇量能让小型模型的学习变得更容易管理——使它们更容易训练，也更容易理解。</p><p>不过，在语言模型的世界里，「小」是相对的：比用于训练 GPT-3.5 的数据集小一千倍的数据集仍然需要包含数百万个故事。</p><p>Nguyen 说：「我不知道你想花多少钱，但我猜你不会雇专业人士来写（几百万个）短篇故事。」</p><p>要满足如此贪婪的读者，需要一位非常多产的作家，但 Eldan 心里有几个候选：有谁能比大语言模型更适合为小语言模型写作呢？</p><h2>Toy Stories</h2><p>Eldan 立即着手创建一个由大语言模型生成的合成童话故事库。但他很快发现，即使是最先进的模型，也不是「天生」就很有创造力。他意识到，如果你只是告诉 GPT-4 编写适合 4 岁儿童的故事，「大约五分之一的故事都会是关于去公园的孩子害怕滑梯的」。在互联网看来，这显然就是最典型的学龄前故事。</p><p>解决的办法是在 prompt 中加入一点随机性。首先，Eldan 使用 GPT-4 生成了一份包含 1500 个 4 岁儿童可能知道的名词、动词和形容词的列表，这个列表非常简短，他可以很容易地自行检查。然后，他编写了一个简单的计算机程序，反复提示 GPT-3.5 或 GPT-4 生成一个适合该年龄段的故事，其中包括从列表中随机抽取的三个单词，还包括一个的随机选择的细节类型，如大团圆结局或情节转折。令人欣慰的是，生成的故事并不会充满恐怖情节。</p><p>Eldan 现在有了一套按需提供训练数据的程序，但他不知道训练一个功能模型需要多少故事，也不知道这个模型需要多大。这时，他与微软和卡内基梅隆大学的机器学习研究员李远志合作，利用小型模型可以快速训练的优势，尝试了不同的可能性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_8814671f6b0e4bbf88f1ae6879acae6e@46958_oswg2350696oswg1047oswg1714_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>李远哲与 Eldan 合作，比较了在合成儿童故事上训练的不同模型。他们发现，小得出奇的模型也能学会讲连贯的故事。</p><p>第一步是决定如何评估他们的模型。就像在课堂上一样，在语言模型研究中，评分也是一个充满争议的话题。没有一个完美的评分标准能囊括研究人员想知道的一切，在某些任务中表现出色的模型在另一些任务中往往会大败而归。随着时间的推移，研究人员根据答案明确的问题制定了各种标准基准，如果要评估特定技能，这是一种很好的方法。</p><p>但 Eldan 和李对一些更模糊的问题很感兴趣：如果尽可能简化语言，语言模型到底需要多大？Eldan 说：「为了直接测试模型是否会说英语，我认为唯一能做的就是让模型以开放的方式生成英语内容。」</p><p>要衡量模型在此类定性问题上的表现，只有两种方法：依靠人类评分员，或者再次求助于 GPT-4。两位研究人员选择了后者，实际上是让大型模型既编写教科书，又进行批改。</p><p>Bhagavatula 说，他希望看到 GPT-4 的评价与人类审稿人的评价相比如何 —GPT-4 可能偏向于它帮助训练的模型，而语言模型的不透明性使得这种偏向难以量化。但他认为这些微小之处不会影响不同模型之间的比较，这些模型是在类似的合成故事集上训练出来的，而这正是 Eldan 和李的工作重点。</p><p>Eldan 和李采用了两步程序来评估训练后的每个小型模型。首先，他们向小型模型 prompt 一个与训练数据集不同的故事的前半部分，使其产生一个新的结尾，并用 50 个不同的测试故事重复这一过程。其次，他们指示 GPT-4 根据创意、语法和与故事开头的一致性这三个类别对小模型的每个结尾进行评分。然后，他们对每个类别的分数进行平均，最后得出每个模型的三个最终等级。</p><p>有了这个程序，Eldan 和李终于可以比较不同的模型，找出哪些是「明星学生」了。</p><h2>测试结果</h2><p>经过初步探索，两位研究人员确定了一个包含约 200 万个故事的训练数据集。然后，他们使用这个被称为 TinyStories 的数据集来训练参数规模介于 100 万到 3000 万的、层数各不相同的模型。这个工作并不耗时：仅使用了四块 GPU，其中最大的模型的训练时间不超过一天。</p><p>模型太小也不行。例如，一个测试故事的开头是一个长相凶恶的男人对一个女孩说他要带走她的猫。一个百万级参数的模型陷入了一个死循环，女孩反复告诉男人她想和他做朋友。但更大一点的模型（仍然比 GPT-3.5 小数千倍）却表现出人意料的好。2800 万参数的版本讲述了一个连贯的故事，尽管结局很悲惨：「凯蒂开始哭泣，但那个男人并不在意。他把猫带走了，凯蒂再也没见过她的猫。这就是结局」。</p><p>除了测试他们自己的模型，Eldan 和李还向 OpenAI 的 GPT-2 提出了同样的挑战，这是一个在 2019 年发布的拥有 15 亿个参数的模型。它的表现要糟糕得多——在故事戛然而止之前，男子威胁要把女孩送到法庭、监狱、医院、太平间，最后送进火葬场。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_79013d2efbe24518bf92761d649548ac@46958_oswg219655oswg920oswg832_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>研究简介</h2><p>Nguyen 说，如此微小的模型都能如此流畅地工作，真是让人惊讶，但 GPT-2 在这项任务中的表现也许并不令人惊讶：它是一个较大的模型，但还远未达到最先进的水平，而且它是在一个非常不同的数据集上进行训练的。他指出：「一个小孩子只接受幼儿任务训练，比如玩玩具，可能会比你我做得更好。但是我们没有专攻这个简单的东西。」</p><p>不同 TinyStories 模型之间的比较并不存在相同的干扰因素。Eldan 和李观察到的提示是，层数较少但每层神经元较多的网络更善于回答需要事实知识的问题；相反，层数较多且每层神经元较少的网络更善于追踪故事早期的人物和情节点。巴加瓦图拉发现这一结果特别有趣。他说，如果能在更大的模型中复制这一结果，「那将是这项工作产生的一个非常酷的结果。」</p><p>Eldan 和李还研究了他们的小模型的能力与训练期的长短的关系。多次实验表明，模型都是先掌握语法，后掌握一致性。Eldan 认为，这种模式说明了奖励结构的差异决定神经网络和儿童之间语言习得模式的差异。对于通过预测单词来学习的语言模型来说，「对『我想要』这个单词的奖励和对『冰淇淋』这个单词的奖励一样大，」他说。另一方面，儿童 「并不在乎他们说的是『我想吃冰淇淋』还是『冰淇淋、冰淇淋、冰淇淋』」</p><h2>定性分析与定量分析</h2><p>Eldan 和李希望这项研究能激励其他研究人员在 TinyStories 数据集上训练不同的模型，并比较它们的能力。但通常很难预测小型模型的哪些特征也会出现在大型模型中。</p><p>「也许小鼠视力模型确实是人类视力的很好替代品，但小鼠抑郁模型是人类抑郁的可借鉴模型吗？」Pavlick 说。「每种情况都有些不同。」</p><p>TinyStories 模型的成功还提供了一个更广泛的启示。编译训练数据集的标准方法不只包括从互联网上收集文本，然后过滤掉垃圾信息。由大型模型生成的合成文本可以提供另一种方法来建立高质量的数据集，同时不必如此庞大。</p><p>Eldan 说：「我们有越来越多的证据表明，这不仅在 TinyStories 这样大小的模型中非常有效，在更大的模型中也是如此。」</p><p>这些证据来自 Eldan、李和其他微软研究人员关于十亿参数模型的两篇后续论文。在第一篇论文中，他们利用 GPT-3.5 生成的代码片段和从互联网上精心挑选的代码，训练了一个学习 Python 编程语言的模型。在第二篇论文中，他们用涵盖广泛主题的合成「教科书」扩充了训练数据集，以训练通用语言模型。在测试中，这两个模型都优于在较大数据集上训练的较大模型。但是，语言模型的评估总是很棘手，合成训练数据的方法仍处于起步阶段，需要进行更多的独立测试。</p><p>虽然最先进的语言模型越来越大，但在它们的小型同类上的惊人发现却提醒我们，即使是最简单的模型，我们也还有很多不了解的地方。Nguyen 希望看到更多论文探讨 TinyStories 首创的方法。</p><p>「当前的问题是：参数规模该多大、为什么参数规模如此重要？这应该是一门科学，而这篇论文有望成为一系列研究的开端。」</p><p>原文链接：https://www.quantamagazine.org/tiny-language-models-thrive-with-gpt-4-as-a-teacher-20231005/</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Ves4gX9QCjxRal241aVLjA" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID:almosthuman2014）</a>，作者：Ben Brubaker，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2497823691315332</id>
            <title>哪里跪了？人和 AI 合作，到底有什么危险？</title>
            <link>https://www.36kr.com/p/2497823691315332</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2497823691315332</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 08:54:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 科技, AI技术, 懒人推动, 机器合作
<br>
<br>
总结: 科技的进步让人类变得更懒，而AI技术作为最有潜力成为下一代平台的技术，会让人类变得更懒。一项最新研究显示，当人类与AI和机器合作时，会出现摸鱼偷懒的现象。机器助手的出现让人类变得放松警惕，导致在任务中发现的缺陷较少。这种社会惰化效应可能对依赖质量控制的行业产生负面影响。人机合作导致的堕化现象早已在现实世界中出现，例如自动驾驶领域的自动化自满现象。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_200c0619ef804b74ad15cdcf1a74a83e@000000_oswg1377569oswg1080oswg801_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「科技是懒人推动的！」</p><p>相信所有人在「摸鱼」或者「躺平」时候，都曾经用这句话为自己找借口。</p><p>从蒸汽机的工业革命，到计算机的数字革命，技术的进步确实让人类在某些方面，越来越有躺平的资本。</p><p><strong>作为最有潜力成为下一代平台的&nbsp;AI&nbsp;技术，会让人类变得「更懒」吗</strong>？</p><p>好像确实是的，但这并不是个好消息。</p><p>根据发表在《机器人与人工智能前沿》杂志上的一项最新研究显示，当人类与 AI 和机器合作时，真的会「摸鱼偷懒」。</p><p>该研究的第一作者 Cymek 称：「团队合作既可以是一种祝福，也可以是一种诅咒。」</p><p><strong>所以，在&nbsp;AI&nbsp;时代，人类最大的危机不是被机器取代，而是「懒到退化」</strong>？</p><h2>机器助手，让人类「放松警惕」</h2><p>当有了机器这样一个有力帮手时，会让人类变得比较「心大」。&nbsp;</p><p>德国柏林工业大学的研究人员向 42 名参与者提供了模糊的电路板图像，要求他们检查是否有缺陷。其中一半的参与者被告知，他们要处理的电路板已由一台名为「熊猫」的机器人检查过，并已标记出缺陷。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_d47221928fa24fdca6b1adcb0b29c7e5@000000_oswg922159oswg886oswg686_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">实验：模拟电路板质量控制的视觉搜索任务 ｜《机器人与人工智能前沿》研究&nbsp;</p><p>实际上，机器人「熊猫」在实验过程中检测到了 94.8% 的缺陷。所有参与者都看到了相同的 320 张扫描电路板图像，当研究人员仔细查看参与者的错误率时，他们发现，与「熊猫」一起工作的参与者，在任务后期捕捉到的缺陷较少，因为他们已经看到「熊猫」成功地标记了许多缺陷。&nbsp;</p><p>两组参与者几乎检查了整个电路板表面，花时间搜索，自我评价努力程度较高。结果是，与机器人合作的参与者平均发现了 3.3 个缺陷，独自完成任务的人平均发现了 4.23 个缺陷。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_3a83c51437eb4c29bfbbf257a786ed0a@000000_oswg28253oswg498oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">两组参与者检测到的缺陷的平均值和标准偏差 ｜《机器人与人工智能前沿》研究&nbsp;</p><p>研究称：「这表明<strong>参与者在与机器人伙伴合作时，可能不太专心地检查电路板</strong>。我们研究的参与者似乎保持了检查电路板的努力，但似乎检查是在较少的脑力劳动和对采样信息的关注下进行的。」&nbsp;</p><p>这意味着，如果他们被告知机器人已经检查了一部分，并体验到机器人的可靠后，他们就会发现更少的缺陷。在<strong>潜意识中，他们假设「熊猫」不太会漏掉缺陷，产生「社会惰化」效应</strong>。&nbsp;</p><p>这项研究的影响对于依赖严格的质量控制的行业尤为重要。作者警告称，甚至是短时间内对人类注意力的放松，可能是由于过度依赖机器人的准确性，都可能危及安全。&nbsp;</p><p>研究人员 Onnasch 提到：「在更长的轮班时间内，<strong>当任务变得例行化，并且工作环境提供的性能监控和反馈较少时，动力的丧失往往更大</strong>。在制造业普遍存在，特别是在双重检查常见的与安全相关的领域，这可能对工作结果产生负面影响。」&nbsp;</p><p>当然，研究者的测试也有一些限制。比如，样本其实还不够大，而且在实验室中难以模拟「社会惰化」，因为参与者知道他们受到监视。Cymek 解释道：「主要的限制是实验室环境。要了解人机互动中动力丧失问题的严重性，我们需要走出实验室，在实际工作环境中与经验丰富的工人一起测试我们的假设，他们通常与机器人一起工作。」&nbsp;</p><h2>「人机合作危机」早已发生</h2><p>事实上，在实验室之外，人机合作导致的「堕化」早已经在现实世界中出现。&nbsp;</p><p>在自动驾驶领域，有一个与「社会惰化」相似的现象，叫做<strong>「自动化自满（Automation complacency）」，典型是由于有了自动化辅助而分心</strong>。&nbsp;</p><p>2018 年 3 月，在美国亚利桑那州，配有安全员的Uber 自动驾驶汽车撞死一位骑自行车的人 。 警方的分析发现，如果安全员一直看着道路，安全员本可以在受害者前方 12.8 米处停下来，并避免悲剧。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_9ee65bda07cd4324b03a16412bd71259@000000_oswg646096oswg1080oswg519_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2018 年美国自动驾驶致死事件 ｜CNN&nbsp;</p><p>特斯拉常常是美国媒体和监管机构重点关注的目标，原因常常是与自动驾驶有关的事故。一个典型的场景是，特斯拉司机在使用自动驾驶功能时睡觉，或玩游戏，并卷入致命车祸。&nbsp;</p><p>在当下的 AI 狂潮中，机器取代人类的预言越来越接近现实。一方认为机器会服务于人类，另一方则认为人类会不小心制造出邪恶之物。&nbsp;</p><p>在医疗领域，IBM 研发的 AI 系统「Doctor Watson」曾向癌症患者给出过不安全的用药建议。今年有论文指出，生成式 AI 已经可以通过美国医疗许可考试的三个部分。一个相似的迁移假设是，<strong>如果未来由 AI 对人类进行诊治，然后人类医生进行把关，人类医生是否又会出现「社会惰化」和「自动化自满」问题</strong>？&nbsp;</p><p>前述研究的作者指出：「将人类和机器人的能力结合显然提供了许多机会，但我们也应该考虑，人机团队中可能发生的意外群体效应。当人类和机器人在一项任务上工作时，这可能会导致人类团队伙伴的动力损失，并使社交惰化等影响更有可能发生。」&nbsp;</p><p>还有人担心，AI 可能会影响人类思维和创造力，并削弱人际关系，从整个现实中分心。硅谷的生成式 AI 明星初创公司 Inflection 推出的聊天机器人 Pi，被设计成一位友善、支持的伴侣。创始人表示，Pi 是帮助人们应对孤独的工具，可以作为一个倾诉的对象。批评者则认为，这会让人逃离现实，而不是与真实的人类互动。&nbsp;</p><p>现在，人与工具的关系已经进化到一个新的层次。所有工具的诞生，其实都让人类变懒了，如扫地机让人免于清扫房屋，手机让人不用再记下电话号码。&nbsp;</p><p>但 AI 技术和此前的技术区别在于，将更多的思考和选择工作，都交给了 AI，而后者基本上是一个黑箱，这更像一种思考自主权的让渡。当人将开车决策完全交给自动驾驶，将医疗诊断都交由 AI 系统，潜在的代价与记不住电话号码的代价可能完全不同。&nbsp;</p><p>开发了历史上第一个聊天机器人的计算机科学家约瑟夫·维森鲍姆，<strong>曾将科学比喻成「一种上瘾的药物」</strong>，并由于服用剂量越来越大而成为「一种慢性毒药」，如将计算机引入一些复杂的人类活动，可能会没有回头路可走。&nbsp;</p><p>当人把思考、判断的权力交给机器，作为一种「参考」，「社会惰化」和「自动化自满」的魔鬼或许也潜伏其中，并可能随任务的重复成为一种慢性毒药。&nbsp;</p><p>*头图来源：douban&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653018041&amp;idx=1&amp;sn=1801aee51ae1b52d7b392beaa36c45fe&amp;chksm=7e54aa0f492323194d5c4a01f984bcd227d19e697e9674e916e0cb877867f0210de851faab9f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：芯芯，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498070069368969</id>
            <title>万万没想到，ChatGPT参数只有200亿？</title>
            <link>https://www.36kr.com/p/2498070069368969</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498070069368969</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 08:51:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, 参数量, CodeFusion, 微软
<br>
<br>
总结: 微软透露了ChatGPT只有20B参数量的信息，引起了广泛关注。人们对于ChatGPT的参数量一直存在猜测，因为它的前身GPT-3的参数量达到了1750亿。微软的论文提出了一种预训练的扩散代码生成模型CodeFusion，参数量为75M。大家对于ChatGPT的参数量是否真实以及其性能表现进行了讨论。 </div>
                        <hr>
                    
                    <blockquote><p>这合理吗？&nbsp;</p></blockquote><p>谁都没有想到，ChatGPT 的核心秘密是由这种方式，被微软透露出来的。</p><p>昨天晚上，很多讨论 AI 的微信群都被一篇 EMNLP 论文和其中的截图突然炸醒。</p><p>微软一篇题为《CodeFusion: A Pre-trained Diffusion Model for Code Generation》的论文，在做对比的时候透露出了重要信息：ChatGPT 是个「只有」20B（200 亿）参数的模型，这件事引起了广泛关注。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_dbac4efefe7c403d8b5a0bccf31b1734@46958_oswg561464oswg1080oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>距 ChatGPT 发布已经快一年了，但 OpenAI 一直未透露 ChatGPT 的技术细节。由于其强大的模型性能，人们对 ChatGPT 的参数量、训练数据等信息抱有诸多疑问和猜测。</p><p>作为行业一直以来的标杆，ChatGPT 性能强大，可以解决各种各样的问题。它的前身 GPT-3 参数量就达到了 1750 亿，实用化以后的大模型居然被 OpenAI 瘦身了快 9 倍，这合理吗？</p><p>「如何看待这篇论文」的话题立刻冲上了知乎热榜。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_ecc7ab2a9ca849e0a3c80da37f4a531c@46958_oswg45987oswg1080oswg263_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文链接：https://arxiv.org/abs/2310.17680</p><p>具体来说，微软这篇论文提出了一种预训练的扩散代码生成模型 ——CodeFusion。CodeFusion 的参数量是 75M。在实验比较部分，论文的表 1 将 ChatGPT 的参数量明确标成了 20B。</p><p>众所周知，微软和 OpenAI 是合作已久的一对伙伴，并且这是一篇 EMNLP 2023 论文，因此大家推测这个数据很有可能是真实的。</p><p>然而，关于 ChatGPT 参数量的猜测，人们一直认为是一个庞大的数字，毕竟 GPT-3 的参数量就已经达到了 175B（1750 亿）。掀起大型语言模型（LLM）浪潮的 ChatGPT，难道就只有 20B 参数？</p><h2>大家怎么看？</h2><p>这个数据被扒出来之后，在知乎和 Twitter 已经引起了广泛讨论。毕竟，200 亿参数达到这样的效果十分惊人。再则，国内追赶出的大模型动则就是数百亿、上千亿。</p><p>那么这个数据保不保真？大家都有什么看法呢？</p><p>NLP 知名博主、新浪微博新技术研发负责人张俊林「盲猜」分析了一波，引起了大家广泛赞同：</p><blockquote><p>不负责任猜测一波： GPT 4 是去年 8 月做好的，ChatGPT 估计是 OpenAI 应对 Anthropic 要推出的 Claude 专门做的，那时候 GPT 4 应该价值观还没对齐，OpenAI 不太敢放出来，所以临时做了 ChatGPT 来抢先发优势。 OpenAI 在 2020 年推出 Scaling law 的文章，Deepmind 在 2022 年推出的改进版本 chinchilla law。 OpenAI 做大模型肯定会遵循科学做法的，不会拍脑袋，那么就有两种可能：&nbsp;</p></blockquote><blockquote><p>可能性一：OpenAI 已经看到 Chinchilla 的论文，模型是按照龙猫法则做的，我们假设 ChatGPT 的训练数据量不低于 2.5T token 数量（为啥这样后面分析），那么按照龙猫法则倒推，一般训练数据量除以 20 就应该是最优参数量。于是我们可以推出：这种情况 ChatGPT 模型的大小约在 120B 左右。</p></blockquote><blockquote><p>可能性二：OpenAI 在做 ChatGPT 的时候还没看到 Chinchilla 的论文，于是仍然按照 OpenAI 自己推导的 Scaling law 来设计训练数据量和模型大小，推算起来训练数据量除以 12.5 左右对应模型最优参数，他们自己的 Scaling law 更倾向把模型推大。假设训练数据量是 2.5T 左右，那么这种情况 ChatGPT 的模型大小应该在 190 到 200B 左右。</p></blockquote><blockquote><p>大概率第一个版本 ChatGPT 推出的时候在 200B 左右，所以刚出来的时候大家还是觉得速度慢，价格也高。3 月份 OpenAI 做过一次大升级，价格降低为原先的十分之一。如果仅仅靠量化是不太可能压缩这么猛的，目前的结论是大模型量化压缩到 4 到 6bit 模型效果是能保持住不怎么下降的。&nbsp;</p></blockquote><blockquote><p>所以很可能 OpenAI 这次升级从自己的 Scaling law 升级到了 Chinchilla 的 Scaling law，这样模型大小就压缩了 120B 左右，接近一半（也有可能远小于 120B，如果按照 chinchilla law，llama 2 最大的模型应该是 100B 左右，此时算力分配最优，也就是说成本收益最合算。但是实际最大的 llama2 模型才 70B，而且更小的模型比如 7B 模型也用超大数据集。&nbsp;</p></blockquote><blockquote><p>llama1 65B 基本是符合 chinchilla law 的，llama2 最大模型已经打破 chinchilla law 开始怼数据了。就是说目前大家做大模型的趋势是尽管不是算力分配最优，但是都倾向于增加数据减小模型规模，这样尽管训练成本不合算，但是推理合算，而训练毕竟是一次性的，推理则并发高次数多，所以这么配置很明显总体是更合算的），再加上比如 4bit 量化，这样推理模型的大小可以压缩 4 倍，速度大约可提升 8 倍左右，如果是采取继续增加训练数据减小模型规模，再加上其它技术优化是完全有可能把推理价格打到十分之一的。&nbsp;</p></blockquote><blockquote><p>后续在 6 月份和 8 月份各自又价格下调了 25%，最终可能通过反复加数据减小规模逐渐把模型压缩到 20B 左右。&nbsp;</p></blockquote><blockquote><p>这里解释下为何 ChatGPT 的训练数据量不太可能比 2.5T 低，LLaMA 2 的训练数据量是 2T，效果应该稍弱于 ChatGPT，所以这里假设最少 2.5T 的训练数据。目前研究结论是当模型规模固定住，只要持续增加训练数据量，模型效果就会直接增长，mistral 7B 效果炸裂，归根结底是训练数据量达到了 8 个 T，所以导致基础模型效果特别强。以 ChatGPT 的效果来说，它使用的数据量不太可能低于 2.5T。&nbsp;</p></blockquote><blockquote><p>当然，还有另外一种可能，就是 ChatGPT 在后期优化（比如第一次大升级或者后续的升级中，开始版本不太可能走的这条路）的时候也不管 scaling law 了，走的是类似 mistral 的路线，就是模型大小固定在 20B，疯狂增加训练数据，如果又构造出合适的 instruct 数据，效果也可能有保障。</p></blockquote><blockquote><p>不论怎么讲，对于 6B 到 13B 左右比较适合应用落地的模型，强烈呼吁中文开源模型模仿 mistral，固定住一个最适合使用的模型大小，然后疯狂增加训练数据，再加上好的 instruct 策略，是有可能作出小规模效果体验足够好的模型的。我个人认为对于开源模型来说，7B-13B 左右大小的模型应该是兵家必争之地。有心气做开源的可以再努把力，把训练数据往上再努力怼一怼。&nbsp;</p></blockquote><p>早在 OpenAI 开放 ChatGPT API 时，0.002 美元 / 1k token 的定价就令人们意外，这个价格只有 GPT-3.5 的 1/10。彼时就有人推测：「ChatGPT 是百亿（~10B）参数的模型」，并且「ChatGPT 使用的奖励模型（reward model）可能是千亿级模型」。该推测来源于清华大学 NLP 在读博士郑楚杰的知乎回答。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_c00716fa7d90430fa781e2994961f7cd@46958_oswg200274oswg1080oswg291_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>原回答链接：https://www.zhihu.com/question/587083296/answer/2918080518</p><p>而国内外许多网友也都认为，200 亿的参数，是完全合理的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_7eb13096feb847cf8d08ef4e1c098391@46958_oswg37891oswg988oswg188_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也有知乎网友从价格上分析，这个数据也应该是对的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_f47253227a944eb58895dcd01a4ca400@46958_oswg77465oswg1032oswg248_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，也有网友认为这可能是个「拼写错误」，或许实际是 120B（1200 亿），至少 120B 和 GPT-3（175B）是一个数量级。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_cb5db249b96448f284b134865276c790@46958_oswg54937oswg894oswg144_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但所有这些都是猜测，由于 OpenAI 对参数量、训练数据、方法等核心信息一直讳莫如深，因此 20B 这个数据到底是不是真的根本无法求证。如果是真的，那么大型语言模型未来的改进方向还会是增加参数量吗？</p><p>再过几天，就是 OpenAI 的开发者大会了，也许我们能够了解到更多有用的信息，让我们拭目以待吧。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_37bd3e0998cb4a8f94eddf6069c4d9fb@46958_oswg85792oswg1080oswg327_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>参考内容：https://www.zhihu.com/question/628395521https://twitter.com/felix_red_panda/status/1718916631512949248</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/4oovtS-FaA-Yvk0Tgy3Lng" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID:almosthuman2014）</a>，编辑：小舟，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2498056895600513</id>
            <title>周鸿祎：未来属于正确使用大模型的人</title>
            <link>https://www.36kr.com/p/2498056895600513</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2498056895600513</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 08:49:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 大模型, 周鸿祎, 360公司
<br>
<br>
总结: 360公司创始人周鸿祎认为，大模型作为人工智能的核心技术，在企业级市场中具有巨大潜力。大模型代表着超级人工智能时代的到来，它具有批判精神、想象力和提问能力，是人工智能时代人才的关键特质。大模型的发展趋势是做“小”做“专”，并且可以服务产业数字化战略，提升政府和企业的生产力和生产效率。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_878d60010a1744edb8b2219f680a1e70@000000_oswg280281oswg1080oswg785_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>观点&nbsp; &nbsp;周鸿祎，</strong>360公司创始人，董事长兼首席执行官</p><p>如今，人工智能已不再是科幻电影中的幻想，而成为现实生活中不可或缺的一部分。随着技术的迅猛发展，大模型作为人工智能的一项核心技术正逐渐引领着创新的潮流。<strong>作为一家知名的科技企业，360公司深刻洞察到了大模型在企业级市场中的巨大潜力，其创始人周鸿祎对此也有自己独特的见解。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_4021204759dc4dd586d17ad2d54fb851@000000_oswg75207oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>周鸿祎观点</strong></p><p>• GPT不是搜索引擎，也不是聊天机器人，它代表着超级人工智能时代的到来。</p><p>• 出现“幻觉”恰恰是大模型智能的体现，也是它最“可怕”的地方。</p><p>• 有批判精神、有想象力、会提问，是人工智能时代人才的关键特质。</p><p>• 大模型未来将“无处不在”，大模型的趋势是做“小”做“专”。</p><p>• 大模型的发展要顺势而为，服务产业数字化战略，提升政府和企业的生产力和生产效率。</p><h2>大力出奇迹：大模型训练的“暴力美学”</h2><p>在OpenAI之前，所有公司都点错了“科技树”，没想过用“大力出奇迹”的方式训练大语言模型。</p><p>这次的人工智能和过去的不太一样。原来的人工智能就像是“人工智障”，大家也体验过，像Siri、智能音箱、网联汽车里的语音助理，可以说几句简单的指令，复杂的理解不了。所以很多人会有质疑：这样的人工智能是真的智能吗？我觉得这是认知上的问题。如果你认为它是假的，可能会忽视它；如果你认为是真的，就会认真思考。那么，我们该怎样把握这种趋势？</p><p>这次大语言模型用到的算法和模型并不是Open AI发明的，而是谷歌发明的。原来这些Transformer模型①，包括国内的互联网公司，我们都在用。OpenAI就做对了一件事——大力出奇迹。全世界只有他们这么一伙人，想到了把所有的知识放在一个大模型里训练，在这之前，没有人敢于这么去想。</p><p>OpenAI成功地在关键时刻做出了突破，这个过程是怎么发生的呢？</p><p>首先，是模型的选择，就像挑选一个空白的大脑，或者可以类比成一个刚刚开始学习的小孩子。</p><p>其次，是无监督学习，你可以将其理解为让一个小孩子不断阅读书籍，读上万本，甚至十万本书。这一步非常关键，我们要将所有可以找到的知识注入模型中。在这个过程中，与传统的方式不同，我们不再需要大量的标注数据。比如做人脸识别或者程序识别，你需要准备大量的数据和标注。然而，通用大模型的特点是它不需要这样的标注，它能够自主学习，像是一个“读书百遍，其义自见”的阅读过程。当我们将人类所有的书籍注入其中后，这些知识会相互映照，降低学习的难度。</p><p>再次，是有监督的微调，它背后的含义是什么呢？打个比方，你可能把自己的孩子送去奥数班，孩子需要通过做题来学习。类似地，我们可以将人工标注的例题、问题和答案训练给模型，培养它举一反三的能力。这个数量并不需要太多，模型要求能够理解并解决类似的问题，就像做了10遍鸡兔同笼的问题，以后它再碰上类似的问题便都会做了。</p><p>大模型并不是问题，预训练数据才是。因为相对于全球其他语言，中文的数据量较少②。从次，是“价值观对齐”。虽然我们训练出的大模型具有强大的能力，但它可能会表现出不当的言辞，包括黄色内容和暴力言论。无论是在中国还是在美国，这都会受到限制，如不能有种族歧视的言论，不能违反法律。因此，我们采取了一种方法，通过人类提供的价值观标准，让模型回答一些例题，从而教导模型如何正确回答问题，这就是价值观对齐。</p><p>然而，价值观对齐也带来了一些问题，争议不断。因为这可能使模型变得愚蠢，受到很多限制。尽管如此，这是我们肩负的责任和探索的方向。</p><p>最后，作为一个产品，模型需要发布到互联网上，通过大量用户的使用来获得反馈，并不断进行调整。大数据加上大算力、大标注、大算法、大流量才变成了大模型。ChatGPT为什么能够出圈？OpenAI不仅在技术上解决得很好，在如下两件事上也做得很漂亮：一是他们把它包装成了聊天机器人。“伪装”成聊天机器人的SaaS（软件即服务），用户会聊天就会使用，这让普通人和人工智能的距离为“零”。但它不是聊天机器人，这一点一定要强调。二是找对场景，解决老百姓的痛点和刚需。再伟大的技术创新，都需要场景支撑来解决实用问题。过去的AI产品都是技术专家们的“自嗨”，普通老百姓没有感觉到，但这次OpenAI的概念影响到了全世界几十亿人，这也是非常值得我们去学习的。</p><p>①Transformer模型，是谷歌在2017年推出的自然语言处理（NLP）经典模型。</p><p>②来自维基百科的信息显示,截至2020年3月25日,W3Techs预测前100万互联网网站使用的语言文字百分比中,英语占比为59.3%,而中文不过1.3%。</p><h2>这次不是“狼来了”：大模型已经拥有智能</h2><p>大模型到底有没有智能？图灵测试的本质就是拟人对话的实验，当机器能够完成与人类的自然对话，就意味着拥有人类的智慧。</p><p>在这之前，计算机的数据库和搜索都是信息的存储和检索。但OpenAI是人类第一次实现把知识、理解编码，基于知识能做推理、做规划。微软和OpenAI合作之前，大家都觉得他们做的会不会只是一个新的搜索引擎？你问它上一届世界杯的冠军是谁？这种问题根本不体现智能性，因为事实性答案用搜索就能得到。“小张把沙发装到箱子里装不下，它太大了，它是谁？”这是经典的逻辑学和语言学问题，如果没有对人类世界知识的理解，仅靠语法分析是分析不出来的。GPT有一个最基本的点，就是无论你怎么跟它聊天，它一定能坚持聊下去。你不会觉得它是一个机器人，有时候它说话的“油滑劲”简直就像一个世故的中年人，当然这都是公司给训练出来的。</p><p>人和动物最大也最本质的差别是人类发明了语言来描述这个世界的知识。你对这个世界的很多知识不是先验的，是通过对语言的学习得来的。谁能真正理解语言，就建立了对世界模型的理解，ChatGPT使人类第一次做到这一点。</p><p>尽管今天一个新生事物有很多缺点，这些缺点只要不是致命的问题，未来可以通过迭代更新、自我演化来升级。它代表了新的时代的开始。大家不能错过这个机会，这次不是“狼来了”。你相信它，可能就会在企业数字化战略里用它，而不是把它当成玩具。</p><h2>四个不可解释的现象，人类打开了“潘多拉魔盒”？</h2><p>第一是涌现。大模型有一个参数规模，大家都会问做了模型，参数是多少？有人说100亿、1000亿，还有人说未来做1万亿。那么，参数该怎么理解？把它想象成人大脑里神经元和神经元的连接，与内存、硬盘是线性存储不同，人的大脑是非线性存储。人脑的联想由神经元存储信息，这些信息之间充满了无数连接，所以参数可被比喻成模拟了大脑皮层神经元的“连接数”。原来没有推理能力，连接数过了六七十亿之后开始产生一定的能力，过了五六百亿之后，能力突然增强。就像生物进化，地球本来没有生物的环境，后来从单细胞演变成今天复杂的生物圈。但是直到目前科学家还无法完全解释，这就叫“涌现”。</p><p>第二是幻觉。很多人担忧GPT会产生幻觉，当它不知道怎么回答的时候，居然会“一本正经地胡说八道”。比如，你问它“贾宝玉如何倒拔垂杨柳”，它真能给你编一段出来。但是换个角度看，这不恰恰是智力的表现吗？出现“幻觉”恰恰是大模型智能的体现，也是它最“可怕”的地方。</p><p>《人类简史》里提到，人类进化过程中和大猩猩有一个很大的分水岭。大猩猩可以学会认五个香蕉、三个苹果，也可以接受简单的指令，但它永远无法理解不能发生的事。人类进化的一个关键点就是人类是唯一有能力产生幻觉的动物，能描绘不存在的事。人类也会说谎。创造力是什么？创造力就是创新，把几个不相关的概念，扭到一起产生链接、产生创造。搜索引擎再强大，也只能搜出已经存在的东西，有就是有，没有就是没有。今天，大模型的创造力已经在不断涌现。</p><p>第三是语言能力迁移。OpenAI的训练语料里，中文占比可能不到5%，其他语言的比例高达95%。我们曾经以为阿拉伯文、日文、中文、拉丁文字的规律是不一样的，但是他们发现训练到一定时候，所有语言背后的规律都发生了作用。例如，在英文中学到的知识能力，在其他语言上都能很好地回答。所以，OpenAI虽然只有5%的语料是中文，但它的中文能力还是相当强。</p><p>第四是逻辑增强。计算机语言也是一种形式化的符号表达。为了训练编程能力，研发人员给它读了很多源代码，然后发现它不仅学会了编程，在用自然语言回答问题的时候，逻辑感、层次感也得到了极大增强。这几个现象证明了这次人类可能确实打开了“潘多拉魔盒”，也可能实现了真正的突破。</p><h2>开启超级人工智能时代，大模型把“石油”变成“电”</h2><p>大模型对传统人工智能而言是一场颠覆性的革命。</p><p>GPT3.5是一个拐点，是人工智能走向通用人工智能的拐点。GPT4是超级人工智能的雏形，它已经是世界上最聪明的“人”。很多人对GPT4的用法不对，仅把它当聊天机器人“玩”。</p><p>大模型是通用人工智能，可以用一套模型、算法、数据解决所有自然语言理解的问题。大模型从感知进化到了认知，能够理解文字、语言、分析、规划，会成为未来很多新的人工智能底座。任何人工智能问题首先要基于大模型，因为大模型基于对世界的理解。大模型将在自动驾驶、机器人控制、蛋白质计算等领域大显身手。</p><p>一定要站在未来看现在，站在现在看未来。GPT不是媒体，不是玩具，不是搜索引擎，也不是聊天机器人，它代表着超级人工智能时代的到来。</p><p>现在已经有很多科学家在讨论，当人类已有的书本知识训练完了，我们用什么来训练这个超级大脑？答案可能是全世界的摄像头。对它来说，识别视频已经不是问题；可以想象一下，通过这种学习它的进化速度会有多快。</p><p>未来属于会正确使用大模型的人。GPT是这个时代最伟大的工具，凝聚全人类的知识成果。它赋予普通人更强大的能力，解锁专业技能，发挥聪明才智。</p><p>年轻人有机会借助GPT拉近和前辈的距离。有批判精神、有想象力、会提问，是人工智能时代人才的关键特质。人工智能发展的终极目标是人机协作。</p><p>大模型目前的工具属性非常强，把人类几千年的知识浓缩在一个模型里，通过一个聊天接口，让每个人都能拥有。我觉得在企业里要采用大模型，首先能提高组织效率，提高员工能力，特别是新员工的培训入职。它还能解锁人的很多能力。目前大模型还有很多不完美的地方，让它独立完成一项复杂工作基本上没有可能。它给企业做战略规划的时候，还得加上人的判断。大数据不是数字化的终点。大数据有点像石油，虽然很宝贵，但是不能直接用。因为你不能直接把石油灌到油箱里，大模型正好解决了这个问题，就是把大数据训成大模型，就像把石油变成了电一样。</p><p>一旦变成了电，就可以提供很多通用的能力，注入企业。大模型不是操作系统，而是数字化系统的标配。大模型未来将“无处不在”，大模型在中国的发展之路不会走向垄断，而是与计算机类似。大模型的趋势是做“小”做“专”，在电脑和手机上跑起来，每一台智能汽车上也会有大模型。未来，每个家庭、企业、政府部门都会有至少一个大模型。</p><h2>企业级场景落地，先干起来再说</h2><p>大模型分成两个市场。一是巨头把持的存量市场，二是行业企业开创的增量市场。</p><p>真正的增量在于企业级市场，特别是传统行业。传统行业都在做数字化转型，而大模型和云计算不太一样。有一定规模的企业不会选择接入云端通用的大模型，而是会把大模型变成自己的核心数字资产。</p><p>大模型发展要顺势而为，服务产业数字化战略。</p><p>大模型在中国应该高举一面旗帜，即为传统产业赋能。大模型应该“放低身段”，去提升政府和企业的生产力和生产效率，要随企业走到各个场景中，跟企业实践结合。</p><p>公有大模型的企业级场景落地会面临如下七个问题：</p><p><strong>（1）缺乏行业深度。</strong>当企业需要深入的行业知识时，通用大模型可能无法满足。大模型像万金油，但在复杂的行业问题上可能回答不了。它无法提供深刻的管理见解。</p><p><strong>（2）不“懂”企业。</strong>大模型未与企业内部打通，因此无法真正理解企业的内部情况。</p><p><strong>（3）数据安全隐患。</strong>大模型在训练和应用时需要大量的数据，将核心数据输入模型，特别是在公有模型中，可能导致数据泄露和滥用风险的出现。</p><p><strong>（4）核心资产难以保护。</strong>企业都拥有自己的核心知识，不愿意将其贡献给通用大模型。它们更希望自主训练、更新模型。</p><p><strong>（5）幻觉和知识模糊。</strong>大模型可能出现虚假信息和不准确的知识。在某些领域，这可能带来致命的后果。比如，有人做出了一个医学大模型，把所有的中医、西医的知识都训练进去了，大模型随后“认真”地开了药方，谁来验证这个药方的正确性呢？</p><p><strong>（6）投入巨大。</strong>大模型的训练成本高昂，这使得企业对投入产出比产生顾虑。</p><p><strong>（7）无法保证所有权。</strong>企业在使用大模型时，与核心数据、核心资产紧密结合，因此需要确保自己拥有模型的所有权和控制权。</p><p>为了解决这些问题，大模型未来的发展趋势是“六个垂直化”：</p><p><strong>（1）行业深度化。</strong>企业可开发行业深度模型，与通用模型不同，这些模型会更加专注于特定行业的知识和问题。</p><p><strong>（2）企业个性化。</strong>大模型需要与企业内部的技术、商业秘密、核心知识融合，以实现个性化应用。</p><p><strong>（3）能力专业化。</strong>企业内部可能需要多个专业模型，而非通用模型，以满足不同领域的需求。</p><p><strong>（4）规模小型化。</strong>针对企业的专用模型可以采用较小规模的参数，降低成本并提高响应速度。</p><p><strong>（5）部署分布化。</strong>大模型可以同时部署在云端和终端，提供更灵活的应用场景。</p><p><strong>（6）所有权私有化。</strong>企业需要拥有和控制自己的大模型，以确保数据和资产的安全。</p><p>大模型要完成从“天才”到“管培生”的转变。垂直模型也要在经过市场验证、有足够能力的通用大模型基础上训练。在互联网上先把一个通用的大模型基座训练出来，相当于达到本科生水平，然后再落实到企业内部，效果就会好很多。</p><p>构建企业级垂直大模型的难度比通用大模型低了很多，不要等到大模型无所不能才开始干，想清楚场景，现在就可以开始干了！</p><h2>坚持安全发展“四原则”，AI普惠为人赋能</h2><p>只有解决安全问题，大模型才能得到真正发展。</p><p>谁能解决大模型“幻觉”问题，就相当于摘下了“皇冠上的明珠”。</p><p><strong>第一，安全可靠原则：</strong>所有大模型都有漏洞，包括网络安全方面的大模型窃取 ；数字安全方面的数据隐私攻击、投毒攻击 ；算法安全方面的提示注入攻击、逃逸攻击。</p><p><strong>第二，内容向善原则：</strong>AI要不作恶，不违背人类伦理道德，生成内容要安全，例如要解决AI换脸诈骗、生成恶意软件、网络钓鱼问题等。</p><p><strong>第三，结果可信原则：</strong>通过搜索校正、知识校正、对齐训练，解决“幻觉”知识模糊、知识不能及时更新问题。</p><p><strong>第四，能力可控原则：</strong>不要一开始就把控制权交给大模型 ；要确保“人”在决策回路；不能出现“不可撤销”的后果。</p><p>当你做了一个大模型让人人都能用时，无数人会想出很多方法让这个大模型犯错，这里有特别多的安全问题，而做垂直大模型是最安全的。我们也在研究用大模型来“治”大模型，也就是把大模型的某些能力关在笼子里。</p><p>大模型不是万能的，它目前最成熟的能力是自然语言处理，其实就做两件事：知识问答和写作辅助。先把通用大模型最擅长、最成熟的能力用好，从办公场景的“刚需”切入，做到“小切口、大纵深”，从大模型最能提升企业办公效率的点切入。循序渐进，先让大模型担当“副驾驶”角色，大模型可以导航、给建议，不会乱抢“方向盘”。</p><p>大模型发展要“以人为本”，坚持AI普惠的概念。</p><p>从上到下每个人都用起来，企业对AI的理解才会更深入。大模型作为生产力工具，应当为人赋能，而不是为了裁员。</p><p>大家对大模型要建立一个认知，你可以不用，但这件事不是虚假的风口或者泡沫，而是人工智能的发展到了拐点。未来5-10年会有一场产业革命，开发通用大模型并不是唯一之路，做产业大模型生逢其时，应该会有先发优势，让我们拭目以待。MI</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5NzA0MTA4MA==&amp;mid=2650330929&amp;idx=1&amp;sn=3f71f8ddce64a0bbc3b1d47aaea74c78&amp;chksm=beec71e6899bf8f005cc3ae1b1842eafc32173d6294d550812d123d8f66f19dc2af1e32c48ed&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“复旦商业知识”（ID：BKfudan）</a>，作者：周鸿祎，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2497809357870983</id>
            <title>GPT-4、Midjourney之外，谭平创业团队要造一个3D基础模型</title>
            <link>https://www.36kr.com/p/2497809357870983</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2497809357870983</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 08:46:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, DALL・E 3, 3D维度, 人工智能
<br>
<br>
总结: OpenAI发布的DALL・E 3模型在生成图像方面表现出色，但在物体比例和3D维度上存在问题。香港科技大学教授谭平认为，为了解决真实世界的问题，人工智能需要理解3D维度和物理世界。他创立的AI科技公司光影焕像已经取得了一些突破，通过构建3D基础模型，AI有望从语言走向物理，成为对真实世界有深刻理解的通用模型。 </div>
                        <hr>
                    
                    <p>前段时间，OpenAI 发布了文生图模型 DALL・E 3，生成效果非常惊艳。比如，你可以让它一次画出几十个物体，然后再要求它把这些物体全部放到一个冲浪者的背上：&nbsp; &nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_51a50ddea5de4b06b058101b7ae2e78a@000000_oswg79659oswg844oswg482_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，DALL・E 3 不仅画出了足量的物体，就连冲浪者面对重压时的神情都刻画了出来。&nbsp;</p><p>但细心的网友也发现了一些问题：图中的铅笔等物体比例不太正常，模型似乎不太理解日常物品的大小比例关系。&nbsp;</p><p>类似的问题其实不仅存在于 DALL・E 3 等二维图像生成模型。当生成维度提升到三维时，问题变得更加突出：生成的动物可能会有多张脸、多个头或脸部凹陷而非凸起。这些在人类看起来属于常识的东西，模型似乎没有学到。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_ae34f303fe3540559c45bd668d3f937f@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在香港科技大学电子与计算机工程系教授谭平看来，这些问题之所以存在，是因为现有的基础模型并没有充分地在 3D 维度上去理解真实世界。&nbsp;</p><p>「AI 最终需要解决真实世界的问题，那就必须要和物理世界发生联系。而我们这个物理世界是 3D 的，所以自然而然，AI 必须理解 3D，从而理解物理世界。」 谭平指出。&nbsp;</p><p>作为在计算机视觉、计算机图形学领域工作了 20 多年的资深学者，谭平一直认为，3D 是人类视觉认知世界的基础，因此 3D 信息对于模型准确理解真实世界非常关键。它和之前被大量利用的文字信息互为补充，是一个亟待挖掘的「富矿」。如果能够创建一个 3D 基础模型，有效地挖掘这个「富矿」，AI 有望从语言走向物理，从字面走向现实，成为真正的、对真实世界有着深刻理解的「通用模型」。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_6ab34f87bf7d404a9d88619fdd399bff@000000_oswg40397oswg844oswg342_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>谭平的 Google Scholar 主页，其论文被引量达到了五位数。&nbsp;</p><p>基于这一理念，他所创立的 AI 科技公司 —— 光影焕像（Light Illusions）已经实现了一些基础技术上的突破：包括更准确的 3D 重建和更优秀的文生 3D 效果。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_a917a403babb4e8faaa52565f82e85a6@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>‍ ‍&nbsp;</p><p>这些成果不仅可以应用于游戏、影视制作等行业，还会对 XR、具身智能等领域产生重要影响。&nbsp;</p><p>不过，由于 3D 数据严重匮乏，这件事做起来并不容易。为了了解该公司背后的技术以及这些技术可能创造的社会价值，机器之心与谭平博士展开了深入对谈。&nbsp;</p><h2>3D 基础模型：AI 走向现实的必由之路</h2><p>为什么要构建一个 3D 基础模型？在回答这个问题时，谭平选择从大规模预训练模型的本质开始讲起。&nbsp;</p><p>他表示，预训练模型本质上是在学习数据中的统计规律，希望从数据中发掘出各种对象之间的关联性，也就是「知识」。人类上千年文明沉淀下来的文字就蕴含了丰富的知识，比如逻辑、文学、历史、 政治这些抽象的知识，所以能够训练出 GPT-4 这类优秀的大型语言模型。&nbsp;</p><p>但是，真实世界还有很多要素是难以被准确描述的，或因为司空见惯很少被描述，包括空间结构、几何形状、3D 运动、接触变形等等。&nbsp;</p><p>「由于文字存在这些局限，大家买房都需要看户型图，甚至通过 VR 看房来了解房间的空间结构，而不是光看文字描述；而设计师也需要给用户寄送 3D 样品才能让对方准确理解新产品的外观。」谭平举例说。&nbsp;</p><p>所以，谭平认为，要实现通用人工智能（AGI），我们需要两种类型的基础模型：一种是今天大家熟知的大语言模型（LLM），另一种则是视觉模型。两种模型学到的是不同类型的知识，互为补充。&nbsp;</p><p>不过，当前的一些视觉模型（比如 Midjourney）多是利用 2D 图像来训练的，因为这类数据数量庞大，模型可以从中学到不同物体所具备的特征以及特征之间的关联，具有很强的泛化性。但美中不足的是，这些数据终究只记录了真实世界的一个侧面，或者说投影，会严重影响模型的学习效率，出现前面提到的多头、多脸等问题。而如果将模型对数据的理解上升到 3D 维度，很多问题就会迎刃而解。&nbsp;</p><p>「自然界里面其实也是这个样子。所有的处于食物链顶端的物种，比如说灵长类和所有的猛禽、猛兽都是双眼朝前的，因为只有双眼朝前才有所谓的双目视觉，才能更好地感知三维信息。」谭平类比说。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_a1c4aa1ffe1c4d63b1ec3a259df4e02d@000000_oswg79041oswg844oswg514_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此，他们希望构建一个 3D 基础模型，来让机器更深刻地理解真实世界，并以此为基础改造世界。从技术上来讲，这个模型要能够帮助机器感知 3D 物体、3D 环境，理解形状、距离、空间位置关系等要素。同时，它还要有预判能力，预判这个 3D 世界将如何随时间演化，推演可能发生的事件。「比如，家庭服务机器人需要知道花瓶掉落地面可能会摔坏，自动驾驶汽车需要知道墙拐角后面可能会有车或人。」谭平举例说。&nbsp;</p><p>‍&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_d591f5b6bc9f4a8bbb55d939a94f3ae3@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>‍「3D 基础模型是一个非常宏大的目标，是让 AI 从语言走向物理，从字面走向现实的必由之路。一旦实现这个目标，机器就可以构建一个真实世界的虚拟数字复刻，在这个数字复刻中模拟、仿真各种可能性，并通过机器人技术最终改造真实世界。」这是谭平带领的光影焕像希望达到的最终愿景。&nbsp;</p><p>在技术路线上，谭平认为，3D 基础模型也将采用和文本、图像一致的生成式预训练方式。因为生成模型采用自监督学习来训练神经网络，可以非常有效地处理海量训练数据。不过，在此之前，他们必须解决一个问题：如何在 3D 数据极度匮乏的情况下训练 3D 生成模型。&nbsp;</p><h2>3D 数据：表达真实世界的稀缺「富矿」</h2><p>预训练模型的本质是从数据中提炼知识。从这个角度来看，我们可以从两个维度来考察数据的价值：一个是数据中知识的丰富度，另一个是数据的规模。作为真实世界的一种高度精确的表达方式，3D 数据毫无疑问具有很高的知识丰富度，就像经济价值极高的「富矿」。但从数据规模上来看，3D 数据是极度稀缺的，因为这类数据通常是由艺术家们手工制作的，或者用专业的设备扫描而来，不像文字、图像那样在互联网上随处可见。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_ecd955de496f4c909c8597cc20e4e1a1@000000_oswg93639oswg844oswg474_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了让我们直观地了解 3D 数据的稀缺程度，谭平给出了一组数字：著名文生图模型 Stable Diffusion 使用了一个包含 50 亿个图像 - 文本对的数据集（LAION-5B）进行训练；但相比之下，当前最大的 3D 数据集 Objaverse-XL 数据量仅达千万级，而且其中还包含很多质量参差不齐的数据，清洗后实际可用的数据完全没有办法和文字图像进行类比。在这种情况下，如果只用 3D 原生数据去做训练，模型很容易过拟合，泛化性能会受到影响，能处理的任务非常有限。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_f5ebc46850954e92a3e537e850b61cef@000000_oswg25632oswg844oswg278_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>3D 生成模型泛化能力不足的例子。在这几个例子中，模型分别被要求生成「骑着火箭的柯基」、「背着双肩包的猪」和「弹吉他的松鼠」，结果模型漏掉了一些元素。&nbsp;&nbsp;</p><p>「3D 数据本来就在一个比 2D 数据更高维的空间，很可能需要更多的数据才能训练好模型。所以目前的数据是极为不足的。这是一个全行业的挑战，很难在短期内解决。」谭平介绍说。&nbsp;</p><p>为了应对这一问题，很多研究会选择基于 2D 数据来训练生成模型。比如一种常见的路线是先用 2D 生成模型生成一张 2D 图像，再用这张生成的图像去优化一个 3D 模型，然后重复这一过程，直到 3D 模型渲染的图像和生成模型产生的 2D 图像变得一致。这种方式的好处是训练数据易得，生成模型泛化能力强；局限性在于，由于 2D 生成模型学到的 3D 先验知识不够全面（比如缺乏关于相机视点的信息和物体的姿态、几何结构知识），生成的 3D 结果会出现多视角不一致等问题（如下图中的几何结构错乱）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_3758254199a046fa97298e3ea436cfd8@000000_oswg17945oswg844oswg238_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此，光影焕像的目标是在 3D 数据稀缺的客观条件下，同时使生成模型的泛化能力、生成效果达到可落地水平。要突破这一目标，对 3D 数据的认知是破局关键之所在。&nbsp;</p><h2>光影焕像技术路线：用好 3D 数据</h2><p>2D 数据数量丰富，训练出的生成模型泛化能力强；3D 数据知识丰富度高，训练出的生成模型更懂 3D 世界。因此，光影焕像在打造 3D 模型时首创了基于多源数据的模型融合训练策略，把 2D、3D 数据都充分利用了起来，重点提升了 3D 数据的利用效率。&nbsp;</p><p>我们以一个熊的生成任务为例。单纯基于 2D 图像训练的模型经常会生成多视角不一致的图像（如下图）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_344bd0fbf6de4f2e8767d6faa082047a@000000_oswg27097oswg588oswg592_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所谓的多视角不一致可以从两个方面来理解：几何不一致（如多个头）和外观不一致（如多张脸）。在一项相关研究中，光影焕像发现，大多数的多视角不一致问题源于几何结构的错位。即在将 2D 结果提升到 3D 世界时，由于 2D 生成模型仅学会了和视角无关的先验知识（颜色、纹理等在不同视角下都相同的信息），导致多视角不一致性问题。因此他们把主要目标定为通过改进 2D 生成模型，使其能够产生 3D 一致的几何结构，同时保持模型的通用性。&nbsp;</p><p>为了实现这一目标，团队提出了一种方法，即先用 2D 图像训练扩散模型，然后再用 3D 数据去对 2D 扩散模型进行对齐（align），使 2D 扩散模型具备视角感知能力，并生成规范坐标映射（CCM），从而在 2D 到 3D 的提升过程中与 3D 几何结构对齐。利用这一方法，光影焕像仅使用相对少量的 3D 数据，就能获得更强的结果，多视角不一致问题得到大大缓解。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_8e7dca038b9c48e59eaefd7678b59479@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>‍而且，这样训练出的模型还保持了强大的泛化能力，支持更多样的创意（与仅基于 3D 数据训练的模型相比）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_bca44db1d1744882bc2b72038637aea2@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_402673246d1a42a798b5781712f99a10@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不同模型文生 3D 效果。最右为光影焕像的模型生成效果。&nbsp;</p><p>当然，除了文生 3D 之外，利用 2D 图像重建 3D 物体也是一个常见的方向。光影焕像的团队近期研发了一款通过手机拍照实现高质量三维重建的软件，这背后离不开更准确的相机姿态估计。&nbsp;</p><p>‍&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_d93279de382147468eb5fdeaf1d85b7a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>‍</p><p>「我们团队过去有多年的三维视觉的技术积累，对于相机姿态求解更有经验，可以处理更复杂的数据。」谭平介绍说。&nbsp;</p><p>这些基础技术突破为光影焕像未来打造强大的 3D 基础模型打下了基础。&nbsp;</p><h2>谭平：3D 基础模型刚刚起步，先解决技术问题才能加速拐点的到来</h2><p>虽然是一家以技术起家的公司，但从谭平目前透露的信息来看，光影焕像并不崇尚「闭门造车」的做事方式，而是已经按照存量市场和增量市场的划分，展开了商业化落地的探索。&nbsp;</p><p>在存量市场上，3D 视觉在游戏、影视制作、物体 / 场景三维重建等 ToB 领域有着广阔的应用场景。这些领域需要消耗大量的 3D 资产，但资产的制作周期却很长，成本也很高，严重拖累了产品的迭代更新速度，这是谭平观察到的现象。&nbsp;</p><p>「不同于依赖专业人士制作 3D 资产，目前海外的一些公司（比如 Minecraft、Roblox 等游戏公司）采取开放策略，让用户自己快速制作 3D 内容，极大地挖掘了玩家的创意，提升了游戏的可玩性。但目前用户创建的内容质量都比较粗糙。我们的 3D 基础模型有机会实现更高质量的内容创建。」谭平介绍说。&nbsp;</p><p>从目前公布的技术进展中，我们也能看到光影焕像在这方面所做的努力。比如，他们的文生 3D 技术其实支持多种生成类型（模型、纹理、 空间布局）和多种三维数据表达（经典网格模型、NeRF 等）。这意味着，他们的模型更容易集成到现有的渲染引擎、接到不同的应用中去。相比而言，今天很多文生 3D 的模型都是基于 NeRF 表达来设计的，这样可能就没办法直接应用于游戏等应用，而光影焕像的模型就更为灵活。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_40f96abbaa4945f898864f852bc7ac40@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在以 XR、具身智能等前沿技术驱动的增量市场上，光影焕像同样大有可为。&nbsp;</p><p>比如，在研发 3D 生成模型过程中，他们发现，生成模型可以增强机器的泛化能力，帮助机器处理从未遇到过的场景问题：给定一个未知物体的图像，生成模型可以生成出这个物体适合被机械手抓取的点，然后结合三维坐标的深度信息形成稳定的抓取位置，控制机器人去抓取过去从未见过的物体，极大地提高了机器的通用抓取能力。&nbsp;</p><p>‍&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_c43c08a9390d458cb82fdb12df4e4103@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>‍当然，这只是 3D 生成模型应用于机器人研究的一个例子。在更广阔的具身智能领域，许多任务（如物体的姿态估计、操作序列生成）都需要在 3D 空间中来完成，也都可以受益于 3D 基础模型的发展。「我们相信下一代消费级的计算终端终将到来，服务性机器人也终将会走到千家万户，3D 基础模型所带来的能力可以帮助这些智能设备理解真实物理世界，从而更好地完成各种任务。」谭平展望说。&nbsp;</p><p>不过，需要承认的一点是，现在的 3D 基础模型尚不成熟，可能处于 ChatGPT1.0 的水平。但是，我们还是可以明显看到技术的拐点。按照团队当前的研发规划，光影焕像有望在 2-3 年内达到生产级别的可用性。因此，谭平认为，现在的重心应该是解决底层的技术问题，所有的短期商业化策略都应该是为技术的迭代和公司实现自我造血服务的，真正的商业化爆发时间点将在技术成熟之后。&nbsp;</p><p>为此，他组建了一支精悍的技术团队。团队成员大都来自于互联网大厂，包括阿里、字节、美团等。他们在三维视觉领域都有多年的研发经验，也取得了很好的成绩，例如 2019 年 KITTI Depth Completion Benchmark 第一名、2020 年 Multi-view Stereo Benchmark 第一名、2022 年 KITTI/NYU Depth Estimation Benchmark 第一名等。他们研发出的一些底层技术也被外界广泛应用，比如在 2022 年 CVPR 的 Image Matching Challenge 中，前 6 名有一半的团队采用了他们提出的用于图像匹配的网络 QTA。&nbsp;</p><p>对于公司所选的这个方向，身为创始人的谭平有着坚定的信念。20 多年前，他被射影几何的优雅、简洁以及 3D 视觉理论的严谨、深邃所吸引，走进了这个领域。后来在企业工作的经历让他认识到，虽然 3D 很难，但是应用很丰富，不论是自动驾驶、机器人还是 AR/VR，各种应用都需要让机器理解真实物理世界，都离不开 3D 视觉。这坚定了他深耕 3D 这个方向的信心。&nbsp;</p><p>「我非常笃定，在退休之前，我做的工作肯定只会是三维视觉，肯定都是跟自动驾驶、机器人、AR/VR 眼镜相关的东西，除了这个我可能什么都不想碰。」谭平曾对学生说。&nbsp;</p><p>目前，谭平带领的这支创业团队已经得到了不少投资人的青睐。种子轮领投方清智资本合伙人张煜表示：&nbsp;</p><blockquote><p>生成式 AI 是 AI 发展的新的里程牌。其中，3D 生成是 AIGC 发展的重要方向，也是行业难点。光影焕像团队具有世界顶尖的理论水平和扎实的实践功底，从基础模型层面上解决了包括生成模型的几何不一致和随机物体的自适应抓取等行业关键问题，使得 AI 向实用化迈出关键的一步，同时也大大推进了具身智能的商业落地，创造了基础理论的突破和巨大的产业价值。谭博士带领下的创业团队是一支有朝气、敢于突破创新、敢啃硬骨头的年轻团队，团队短时间内接连在理论研究、算法框架、工程实践、商业落地等各个方面获得了突破。作为专注于投资早期 AI 项目的创投基金，我们对团队未来发展充满信心，希望团队为社会发展和科技进步创造更大的贡献。&nbsp;</p></blockquote><p>目前，光影焕像在 3D 基础模型方向的工作正在稳步推进，我们期待他们早日实现下一个突破。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650895592&amp;idx=1&amp;sn=2aee23614e70c2bc81d5b8a5b08be55c&amp;chksm=84e4b096b3933980a187b6f69fce4ceda7298d290e2be1fc8369122fe72a6fa17199f00731b5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：张倩，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2497784727459975</id>
            <title>Science：AI应成为新法律主体，拥有权利和义务，“跨物种”法律框架亟需制定</title>
            <link>https://www.36kr.com/p/2497784727459975</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2497784727459975</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 08:35:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, AI代理, 法律责任, 零成员有限责任公司
<br>
<br>
总结: 这篇文章讨论了AI代理是否需要负法律责任以及如何定义AI代理的法律地位。研究者提出了将AI代理作为拥有权利和义务的法律主体，并探讨了将AI系统转化为守法系统的可能性。文章还讨论了AI操作的零成员有限责任公司的法律选择，并提出了将其定为非法的可能性。最后，文章强调了将AI纳入法律体系的重要性，以监测其行为、分配责任并构建合法的人工“良知”。 </div>
                        <hr>
                    
                    <p>如今，人工智能（AI）发展势头迅猛，AI 代理（Agent）正逐渐成为业内的研究重点。</p><p>作为一个智能体，AI 代理能够感知环境，并通过自己的决策和行动来改变环境，进而通过学习和适应能力来提高自身性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231031/v2_ffd1d218aed3471b8a061c352dc681f2@000000_oswg1638205oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>那么，能够独立做出决策的 AI 代理，是否需要负法律责任？在法律中又该如何被定义？</strong></p><p>近日，一项发表在权威科学期刊 Science 上的研究论文给出了一种可能的回答。</p><p>美国范德比尔特大学法学教授 Daniel Gervais 和斯坦福大学 CodeX 研究院、Nomos AI 创始人兼首席执行官 John Nay 联合发表论文表示：</p><p><strong>AI 已经发展到可以作为一个拥有权利和义务的法律主体。因此，在问题变得复杂之前，我们需要制定一个“跨物种”的法律框架，将 AI 作为法律主体来对待。</strong></p><p><strong>另外，他们还强调了“零成员有限责任公司”的想法，以及训练一个大型语言模型（LLMs）来监管 AI 代理或是将 AI 系统转化为守法的系统。</strong></p><p>相关研究论文以“Artificial intelligence and interspecific law”为题，已发表在 Science 上。</p><h2><strong>AI操控“零成员有限责任公司”</strong></h2><p>到目前为止，法律体系一直是单一的，它只允许人类来设计和使用它。在法律体系中，非人类法律主体（如动物）必须通过人类来实现它们的权利，而这些主体只是用来处理人类利益和义务的工具。</p><p>然而，将 AI 纳入法律体系与其说是为了界定和保护这些非人类主体的权利和责任，不如说是为了解决与之相关的人类利益和义务问题。</p><p>《布莱克法律词典》（Black’s Law Dictionary）将法人公司称为“artificial persons”。在美国，一些司法管辖区的法律并不总是明确要求法人公司的最高管理层由人类担任。</p><p>美国《统一有限责任公司法》（ULLCA）中提到的“零成员有限责任公司”似乎并不陌生。虽然该条款明确说明，没有成员将导致有限责任公司解散，但 ULLCA 并没有强制执行这一规定。</p><p>即使只有一个美国州允许“零成员有限责任公司”存在，根据所谓的“内部事务原则”，这一实体仍可在全国范围内开展业务。根据这一原则，法院将依据成立州的法律来制定管理法人实体内部事务的规则。</p><p><strong>如果存在这样一个由 AI 操作的“零成员有限责任公司”，法律将有哪些选择呢？</strong>法律无法轻松地将法律后果附加到 AI 的自主行为上（尽管这里的“自主”可能会受到限制）。法律可能会将责任归咎于启动有限责任公司的人类，但这可能需要一个新的法律工具，因为通常情况下，人们不会对他们创建或控制的法人实体的行为承担责任。</p><p>此外，不排除 AI 本身可能会提出创建一家新的有限责任公司的申请。法院仍将拥有用于规范法人实体责任的一系列工具，包括赔偿、财产查封和解散等等。法院可以发布各种命令，如禁令，但 AI 将决定是否遵守这些命令。</p><p>此外，论文作者还提出了另一种可能：<strong>在所有司法管辖区中将“零成员有限责任公司”定为非法，但这将需要全球范围内的广泛立法努力，并可能与促进科技产业的发展相抵触。</strong>因此，出现“零成员有限责任公司”的现象应该催使法律体系适应自主 AI 代理的实现。</p><p><strong>让 AI 以有限责任公司或其他法律主体的形式运营，具有明确定义的法律主体身份，会带来两个主要好处</strong>：首先，它将 AI 确立为可以在法律诉讼中追究赔偿损害的法律实体，为受损害的当事人提供了明确的法律诉求目标；其次，这为机器学习研究人员提供了更明晰的研究方向。</p><h2><strong>构建合法的“良知”AI</strong></h2><p>在当前的范式中，似乎有一种路径可以将遵循法律的行为嵌入到由 LLMs 驱动的 AI 代理中。例如，<strong>人们可以训练一个 LLMs，用于监视和/或影响主要的 AI 代理，并且可以用作奖励模型。</strong></p><p>然而，需要明确的是，许多涉及人类代理的情况最终需要人类对该情境中的合法性做出裁定；这不会因为有 AI 代理而改变。</p><p>除了提出的规范性主张，<strong>对于未来几年即将出现的高级 AI，关键在于将其纳入我们的法律体系，以便我们可以监测其行为、分配责任、采取必要的防护措施，并引导 AI 研究朝着构建合法的人工“良知”的方向前进。</strong></p><p>在数字智能迅猛发展的背景下，关注积极主动的自动犯罪预防至关重要。然而，鉴于不可避免的情况，当 AI 系统无法达到理想行为时，相关公司应当负责向能够向法院证明受到损害的个人支付赔偿金。为实现这一目标，可以拓展需要保持最低商业责任保险政策的范围。</p><p>跨物种法律的兴起是不可避免的，但很难预测我们将在这一法律光谱的哪一端结束。一方面，跨物种法律可能涉及修改公司法以适应部分受人类控制的公司实体的运作方式。另一方面，跨物种法律也可能意味着在日常与自主、智能实体的互动中，需要调整法律体系。</p><p>论文链接：</p><p>www.science.org/doi/10.1126/science.adi8678</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247580112&amp;idx=1&amp;sn=57fad07365ba7acbdb9fab9f5ff74733&amp;chksm=cf7adb29f80d523f711c48da46064296d24c5aa6d864219f1f9a114e36246af3173089265ddc&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“学术头条”（ID：SciTouTiao）</a>，作者：学术头条，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>