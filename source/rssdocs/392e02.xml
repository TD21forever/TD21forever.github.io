<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3112594571398659</id>
            <title>上海张江杀出超级独角兽：一把融资近10亿，四年融资近40亿</title>
            <link>https://www.36kr.com/p/3112594571398659</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112594571398659</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 12:24:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 合见工软, EDA, 融资, 国产软件  
<br><br>  
总结: 合见工业软件集团有限公司（合见工软）于2020年成立，专注于国产高性能工业软件及解决方案的研发，特别是在电子设计自动化（EDA）领域。公司在短时间内完成了多轮巨额融资，吸引了多家知名投资机构和企业的参与。合见工软推出了多款自主知识产权的产品，包括数字验证仿真器和FPGA原型验证系统，致力于提升国产EDA技术的竞争力。预计到2025年，中国EDA市场规模将达到184.9亿元，目前市场主要被外资巨头占据。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_08de3728685240c39003c50f177e3025@000000_oswg1555961oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>近日，上海合见工业软件集团有限公司（下称合见工软）完成近10亿元A轮投资，由浦东创投集团旗下浦东引领区基金参与。&nbsp;</p>
  <p>合见工软的上两轮融资数额同样巨大：&nbsp;</p>
  <p>2022年6月，合见工软宣布完成Pre-A轮超11亿元的融资。投资者包括上汽集团旗下尚颀资本、IDG资本、国科投资、中国汽车芯片联盟、斐翔资本、广汽资本等，老股东武岳峰科创、木澜投资等跟进。&nbsp;</p>
  <p>合见工软发起轮融资于2021年完成，由国家级产业基金国家集成电路产业投资基金二期（国家大基金二期）、中国互联网投资基金；科技及半导体产业专业投资机构武岳峰科创、红杉中国、韦豪创芯、深创投；多家知名集成电路行业领军企业及其关联基金闻泰科技、韦尔股份、木澜投资、卓胜微电子、上海瀚迈、华勤技术以及全球知名集成电路设计公司等共同发起，融资金额超17亿人民币。&nbsp;</p>
  <p>起步就是巨额融资，这是一家怎样的公司？&nbsp;</p>
  <p>合见工软于2020年成立，总部位于上海 ，主要从事国产高性能工业软件及解决方案研发，以EDA（Electronic design automation，电子设计自动化）领域为突破方向。&nbsp;</p>
  <p>EDA是指利用计算机辅助设计（CAD）软件，来完成超大规模集成电路芯片的功能设计、综合、验证、物理设计（包括布局、布线、版图、设计规则检查等）等流程的设计方式。它应用于芯片的设计、制造、封测、封装等多个环节，承担着电路设计、电路验证和性能分析等多项芯片开发过程中的核心工作。&nbsp;</p>
  <p>合见工软董事长潘建岳是常州武进人，生于1967年，1985年毕业于江苏名校前黄高中，并考入了清华大学精密仪器系。之后保送本校硕士。1992年7月，潘建岳硕士毕业，进入中国科学院空间技术研究中心。&nbsp;</p>
  <p>1993年，潘建岳加入当时全球电子设计自动化领域的领导企业美国明导资讯，正式进入电子半导体专业领域。1995年，潘建岳加入EDA巨头新思科技，担任中国区总经理。2008年，潘建岳担任新思科技全球副总裁兼亚太区总裁。&nbsp;</p>
  <p>2011年，潘建岳与清华校友武平、李峰创建了武岳峰资本，专注于高科技产业的投资。武平1984年毕业于清华大学电子工程系，是展讯通信创始人。李峰1990年毕业于清华大学力学系，是中国列车上唯一的电子传媒的运营商“亿品传媒集团”的创始人。&nbsp;</p>
  <p>2020年，潘建岳找来在新思科技研发副总裁郭立阜，以及EDA巨头楷登电子中国区负责人徐昀，共同创办合见工软。&nbsp;</p>
  <p>之所以创办合见工软，有一个小故事。2020年5月份，有一位专家在与潘建岳沟通时表示，未来中国芯片产业的发展，最重要的三个环节是装备、材料、EDA。专家接着对他说，你对EDA这么熟悉，你们就应该把这个责任承担起来。潘建岳萌生了打造国产EDA的决心。&nbsp;</p>
  <p>2021年10月，合见工软推出国内第一款拥有自主知识产权的商用级数字验证仿真器UniVista Simulator。&nbsp;</p>
  <p>之后，合见工软又发布了先进FPGA原型验证系统UniVista Advanced Prototyping System（简称UV APS）。合见工软的UV APS不但能够为高性能计算、汽车电子、人工智能、通信网路、GPU等多垂直应用领域提供快速、专业、高质量的物理板卡快速定制化服务。&nbsp;</p>
  <p>合见工软还在短时间内完成对几家技术领先EDA初创公司的投资和合并，已收购全资子公司：上海华桑电子，云枢创新软件，北京诺芮集成电路；同时对上海孤波科技进行战略投资，组合更完整的测试产品工具链。&nbsp;</p>
  <p>2024年9月，合见工软发布了多个创新产品，包括算力主芯片方案、存储方案、互联方案和系统方案。&nbsp;</p>
  <p>尤其值得一提的是数据中心级全场景超大容量硬件仿真加速验证平台UniVistaHyperscale Emulator，为国产自研硬件仿真器中首台可扩展至460亿逻辑门设计的产品，并支持多系统进一步扩展，可大幅提升仿真验证效率，缩短超大规模芯片的仿真验证周期，达成了国产自研硬件仿真加速平台的能效和容量新高度，为芯片系统级软硬件协同设计及验证提供了强大的算力支撑。&nbsp;</p>
  <p>资料显示，2025年中国EDA市场规模将达到184.9亿元。而目前EDA市场被新思科技、楷登电子和西门子三大外资巨头主导。&nbsp;</p>
  <p>本文不构成任何投资建议。本文还参考了浦东创投、半导体行业观察、投资界、武进新闻网等内容 ，一并致谢。封面图来自AI生成。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI0NzAzNTUwMQ==&amp;mid=2652511467&amp;idx=1&amp;sn=04f09264a372a4668b45b5e2444499ba&amp;chksm=f34ce5fa36626cc0e8367c728f1eb4b7d40807d30ee076dbdb71236532f9515e2b284031408d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“铅笔道”（ID：pencilnews）</a>，作者：黄小贵，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112594652466697</id>
            <title>苏州跑出超级隐形冠军：年入5.16亿，全国第一</title>
            <link>https://www.36kr.com/p/3112594652466697</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112594652466697</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 12:22:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <新广益, 特殊薄膜材料, 抗溢胶特种膜, FPC>
<br>
<br>
总结: 新广益是一家专注于高性能特种功能材料的公司，核心产品为特殊薄膜材料，尤其是抗溢胶特种膜和强耐受性特种膜。该公司在柔性线路板生产中扮演重要角色，抗溢胶特种膜的市场占有率连续四年位居全国第一。新广益的创始人夏超华于2004年创立公司，随着消费电子市场的快速发展，产品需求不断增加。该行业尚未形成大规模竞争，存在许多蓝海机会。新广益的主要客户包括全球柔性线路板生产厂商，且在技术上打破了国际垄断。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_cf17db2b51f9411d82c5cb4d6c9f052d@000000_oswg71886oswg940oswg627_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>近日，苏州吴中区跑出一家超级隐形冠军：新广益，向深交所发起IPO冲刺。&nbsp;</p>
  <p>它的核心产品是：特殊薄膜材料。在电子产品制造过程中，它的角色颇为关键。&nbsp;</p>
  <p>例如，新广益有类产品叫“特种膜”，主要应用于柔性线路板的生产。柔性线路板用于连接电子产品的各个组件，而特种膜能确保线路板的制造不出现问题。&nbsp;</p>
  <p>根据江苏省新材料产业协会数据，2020至2023年，其生产的抗溢胶特种膜连续四年全国市占率第一，2023年市占率达30%。&nbsp;</p>
  <h2><strong>-01-</strong></h2>
  <p>新广益坐落于苏州市吴中区，由退伍军人夏超华先生创立。&nbsp;</p>
  <p>2004年，正值消费电子迅猛发展，FPC产品（柔性印制电路板）市场需求增长。凭借对高性能特种材料的熟悉，夏超华与另外两位合伙人创立了新广益电子，专注于高性能特种功能材料。&nbsp;</p>
  <p>随着时间的推移，最初的三位创始人变成了一位，仅有夏超华留了下来。&nbsp;</p>
  <p>目前，新广益的核心产品是特殊薄膜材料，比如抗溢胶特种膜、强耐受性特种膜等。&nbsp;</p>
  <p>其中，收入占比最高的是抗溢胶特种膜，2024年上半年，其收入占比约为53.58%；其次是强耐受性特种膜，收入占比约为21.68%。&nbsp;</p>
  <p>抗溢胶特种膜用于FPC生产，能够有效解决压合溢胶等问题，其耐高温、抗溢胶等性能优于传统产品。&nbsp;</p>
  <p>而强耐受性特种膜应用于FPC自动化生产，可在极端环境下发挥保护、牵引等作用，性能较传统产品更为优良。&nbsp;</p>
  <p>FPC是什么？中文名称为柔性印制电路板，是一种采用柔性基材制成的印刷电路板，与传统的刚性印刷电路板相比，它更轻薄、可弯曲、体积小，可以自由折叠、卷曲并进行三维布线。在需要节省空间及重量的场景下，它备受客户欢迎。&nbsp;</p>
  <p>这些产品广泛应用于手机、平板、笔记本电脑等，尤其用于显示模组、无线充电模组、柔性线路板的加工环节。&nbsp;</p>
  <p>根据江苏省新材料产业协会数据，2020年至2023年，公司抗溢胶特种膜产品连续四年全国市占率第一，2023年市场占有率达到30%。&nbsp;</p>
  <h2><strong>-02-</strong></h2>
  <p>新广益所处的赛道是：高性能特种功能材料。该赛道尚未形成大规模竞争格局，是消费电子产业链不可或缺的部分。&nbsp;</p>
  <p>近年来，随着全球范围内对环保节能型产品重视程度的不断提升，以及新能源汽车行业的快速发展，提升了高质量特种材料的需求。&nbsp;</p>
  <p>然而，由于该领域的进入门槛较高，涉及多项专利技术和严格的生产工艺要求，行业还有很多蓝海机会。&nbsp;</p>
  <p>从客户层面来看，新广益的主要客户包括鹏鼎控股、维信电子等全球柔性线路板生产厂商。&nbsp;</p>
  <p>在市场竞争方面，新广益的竞品包括住友化学、积水化学、索尼、凡纳克（PANAC）等日本企业，以及三井化学、3M、索马龙、德莎等国际企业。&nbsp;</p>
  <p>与竞品相比，在业务定位上，新广益的最大区别体现在以下几点。&nbsp;</p>
  <p>1、产品更聚焦，尤其是聚焦于高性能特种功能材料，包括抗溢胶特种膜和强耐受性特种膜等。&nbsp;</p>
  <p>2、在这个细分赛道，拥有自主研发技术（如抗溢胶特种膜），打破了国际垄断。&nbsp;</p>
  <h2><strong>-03-</strong></h2>
  <p>2021年至2024年上半年，其营业收入分别为49,610.28万元、45,526.27万元、51,614.17万元、28,428.59万元，净利润分别为8,350.04万元、8,151.34万元、8,328.25万元、5,062.55万元。&nbsp;</p>
  <p>该赛道目前呈现出几个最新趋势。&nbsp;</p>
  <p>1、出现一些新材料研发技术，比如高分子材料的改性、纳米材料的应用、绿色材料技术等。&nbsp;</p>
  <p>2、出现了新的应用场景。除了传统的消费电子、汽车电子等领域外，还逐渐渗透到新能源、生物医疗、航空航天等新兴领域。例如，在新能源电池中，高性能隔膜材料的需求正增强。&nbsp;</p>
  <p>3、数字化与智能化，比如生产过程的自动化、智能化等。&nbsp;</p>
  <p>据相关数据显示，2021年中国功能性膜材料市场规模达1,140亿元，同比增长17.0%，预计2024年可达到1,690.5亿元，年复合增长率14.0%。&nbsp;</p>
  <p>本文不构成任何投资建议。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI0NzAzNTUwMQ==&amp;mid=2652511467&amp;idx=3&amp;sn=632e76d629110f24686da46754def943&amp;chksm=f3a1eba8ca703c3fb76b9687afaf3d9b34bee408b2527e66365a5787541301890b490e001664&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“铅笔道”（ID：pencilnews）</a>，作者：华泰诗，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112600394567429</id>
            <title>被唱衰的L4自动驾驶，为什么复活了？</title>
            <link>https://www.36kr.com/p/3112600394567429</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112600394567429</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 12:20:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 自动驾驶, L4级, 融资, 商业化  
<br><br>  
总结: 2024年，Waymo获得56亿美元融资，成为美国第二大出行公司，而小马智行在美国上市并获得超额认购。小马智行的目标是到2025年底实现L4级自动驾驶的商业落地，尽管市场对L4级的信心不足。行业内对L2级和L4级的技术路径存在分歧，许多公司因缺乏资金转向L2级。Waymo选择直接走L4级路线，认为渐进式迭代可能导致虚假的安全感。小马智行强调技术、政策和规模化量产是实现Robotaxi商业模式的关键。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_c6ed24a7a3064caa840e648007510809@46958_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>2024年10月，Alphabet（Google母公司）旗下自动驾驶公司Waymo收获了有史以来规模最大的一笔融资，金额高达56亿美元（约合410.2亿元人民币）。</p>
  <p>一个月后，来自中国的自动驾驶公司小马智行登陆美国纳斯达克。因市场把Waymo作为其标的对象，在IPO路演过程中，小马智行获得了超额认购，募得资金近4.52亿美元（约合33.1亿元人民币）。</p>
  <p>小马智行联合创始人兼 CTO 楼天城在创立该公司之前，曾在 Google X从事无人车技术研发。该项目是Waymo的前身，这也在一定程度上影响了小马智行的后市。</p>
  <p>2024年以来，Waymo进入了降本和扩量的周期。其在旧金山的日均单量超过当地出租车，付费出行服务更是从年初的周均5万单提升至目前的17.5万单，市场份额一举超越Lyft，成为仅次于Uber的美国第二大出行公司。</p>
  <p>在大洋彼岸的中国，萝卜快跑在武汉率先出圈，累计提供超过 800 万单的自动驾驶出行服务，其中在 2024 年第三季度提供了 98.8 万订单，同比增长 20%。</p>
  <p>同样以Robotaxi为核心业务的小马智行，正以“千台车毛利转正和规模化运营”为关键里程碑，力争在2025年底打造出“样板间”，向政府和合作伙伴展示L4大规模商业落地可行性，进而争取在业务拓展方面获得助力。</p>
  <p>过去两年，自动驾驶在中国发生了剧烈的技术变革，以高阶芯片、AI大模型为代表的技术迭代，以及“端到端”“NOA”（自动辅助导航驾驶）等从概念变为现实，高阶智驾成为各路玩家竞逐的焦点。</p>
  <p>在前不久的“2024理想 AI Talk”上，理想汽车董事长兼CEO李想表示，其“端到端+VLM”的双系统解决方案有望在2025年实现L3有监督智能驾驶，目标是在三年后迭代到无监督的L4级自动驾驶。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_a0df75c4a22c46f0b4291dd2ada81056@46958_oswg50908oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但随着企业之间的竞争从L2级（即车辆实现部分的自动化，主要功能有acc自动巡航、自动跟车、自动泊车等）向L3级（即车辆在特定条件下可以自主完成驾驶任务，但驾驶员需要保持警惕并准备随时接管车辆控制权‌）甚至L4级（指高度自动驾驶，车辆在特定环境和条件下能够完全自主地完成驾驶任务，无需人类驾驶员的干预‌）发起进击，其背后是难以弥合的路径分歧和更为艰巨的任务挑战。</p>
  <h2><strong>01&nbsp;&nbsp; 虚假的安全感</strong></h2>
  <p>2023年6月15日，小马智行在广州南沙进行了一场业内首个Robotaxi全无人10小时的直播。团队希望通过这场直播向业界证明，L4级自动驾驶是可以做到的，而且还在一步一步向前迈进。</p>
  <p>在自动驾驶行业术语中，L4级是一个分水岭，区别于有监督的L3级，L4级彻底摆脱了对驾驶员的依赖，但因技术实现难度过高，市场对于L4级自动驾驶不仅缺乏信心，而且质疑和唱衰的声音始终存在。</p>
  <p>一些L4级自动驾驶厂商由于缺乏资本输血财竭力尽，不得不转向L2级赛道才得以求存。</p>
  <p>元戎启行是最典型的例子。这家公司在2019年创办时，瞄准的就是L4级自动驾驶赛道，而L3级及以上在自动驾驶公司曾一度受到资本市场宠爱。彼时，业内普遍认为，无人驾驶汽车将从2020年之后开始普及。元戎启行2021年9月完成B轮3亿美元融资官宣后，以超过10亿美元的估值，跻身自动驾驶“独角兽”企业的阵营。</p>
  <p>但很快，由于技术突破不再迅速，头部选手商业落地受阻。“对Robotaxi这样的L4技术，大规模商业化部署不仅需要法律法规允许，也需要商业上实现闭环，短期内很难实现。”在不少投资人认清现实后，自动驾驶在资本领域的热度持续消退。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_788be0476f0a4709bab7b78e2839e0c4@46958_oswg32573oswg800oswg533_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而当元戎启行CEO周光再次亮相时，L4级已经是其“唾弃”的伪概念。在2024中国电动汽车百人会论坛上，他公开表示，“在2022年就决定不搞L4了，没有任何商业模式”。即便是做Robotaxi业务，也是以“端到端”的架构来支持运营。</p>
  <p>尽管周光言辞犀利、语出惊人，但面对信心跌落和商业化拷问，先从L2级商用做起，拥抱端到端、无图方案确实是行业风向。</p>
  <p>多年来，中国自动驾驶产业一直遵循渐进式的发展思路，也就是先搞L2级，再搞L3级，然后升级到L4级……但L2级 和 L4级 本质上是两套技术栈。也就是说，二者不是递进关系，而是并行关系。</p>
  <p>持这派观点的不在少数，例如百度创始人李彦宏认为，L2级之后率先进入商用的很可能是L4级，而不是L3级。</p>
  <p>“如果说你一直想种的是L2的种子，却希望它结出L4的果子，这是一个过于理想化的事情。”小马智行对于L2级进化到L4级同样持否定态度。该公司是行业唯一走Waymo路线，并坚持把L4级走到底的公司。公司决策层认为，虽然L4级无人驾驶和L2级辅助驾驶在技术特点上有很强的共通性，可以被复用，但二者指向了两种不同落地场景，对应着不同的产品逻辑。</p>
  <p>无论是L2+还是L2++，辅助驾驶日常只在80%的情况下运转，司机都是责任主体；而L4级的Robotaxi 提供的是完整的无人出行服务，系统需要对驾驶行为的结果负责，追求的是99.999%的万无一失。</p>
  <p>在不同安全等级的约束之下，L2级和L4级的成本空间完全不同。小马智行副总裁、北京研发中心负责人、Robotaxi业务负责人张宁指出：“L2是以性价比为纲的选择，更适合去卷极致性价比；L4是以安全为首位，需要对结果负责，‘责任’二字极其重要。”</p>
  <p>早年间，Waymo也曾构想从L2级辅助驾驶跃迁到L4级无人驾驶，推出渐进式的L3级，但通过团队通过社会试验发现，在渐进式迭代的过程中，当监管次数越降越低，越容易让人产生“虚假的安全感”。</p>
  <p>要知道，每个系统版本之间都有不同程度的差异。也许上一个版本在这个路口能顺利通过，下一个版本就回退了。司机在开小差的过程当中，可能就会酿成交通事故。最终会牵扯车辆失控后复杂的责任认定问题。</p>
  <p>这也是为什么，Waymo选择单刀直入L4级的原因。</p>
  <h2><strong>02&nbsp;&nbsp; 如何抵达真正的无人驾驶</strong></h2>
  <p>当然，Waymo坚定走L4级技术路线的背后，是以吞噬巨量资金为代价的。</p>
  <p>前不久，美国第二大Robotaxi公司Cruise，在烧光通用汽车（GM）100亿美元之后，面对安全监管、市场竞争和财务压力等现实挑战，最终沦为了弃子。昔日与Waymo齐名的硅谷双子星陨落，让赛道上不少公司再次认识到资金的重要性。</p>
  <p>作为对比，特斯拉很早就通过向量产车推送FSD（特斯拉研发的完全自动驾驶系统）实现了盈利。FSD是为进化成完全无人驾驶而生，马斯克的构想是在其成熟后，推出 Robotaxi 服务。而这件事情，在2024年10月特斯拉“We,Robot”发布会上得以尽显，首款Robotaxi车型Cybercab，取消了方向盘、踏板和后视镜，高度依赖于特斯拉的FSD完全自动驾驶能力。</p>
  <p>由于特斯拉的这套“渐进式”发展模式，在现金流和数据流上更为占优，特别是特斯拉FSD V12在2024年1月大规模推送后，“端到端”智驾方案受到了行业追捧。参赛者包括小鹏、理想、智己、商汤等主机厂和智驾解决方案供应商。</p>
  <p>此前，智驾算法多半是规则式的，而“端到端”是一种模仿学习思路，通过学习 “传感器数据” 与 “人类驾驶轨迹” 的海量对比，让车端模型能做到输入传感器数据后，输出合理的驾驶轨迹，不需要人为干预中间步骤。</p>
  <p>在2024广州车展上，理想汽车发布了端到端+VLM（视觉语言模型架构）双系统。基于这套智能驾驶技术架构，该公司的目标是在2024年年底或2025年年初推出L3级自动驾驶。借助这一体系，力争在三年内实现无监督的L4级自动驾驶。</p>
  <p>当前，各家对于L4级自动驾驶的探索才刚刚开始。“现有的端到端只能解决L3，还解决不了L4。”李想认为，在技术上真正实现L4级，第一需要拥有500万辆以上车型的数据；第二要掌握 VLA（视觉语言行动模型）基础模型能力；第三要有足够多的资金招募最顶级的人才和足够多的算力。</p>
  <p>楼天城则认为，“端到端”属于Learning by Watching（通过观察进行学习）的范畴，即通过观察人类驾驶行为然后进行模仿学习，比拼的是数据量和算力，但“像人永远无法做到 L4”，真正有希望抵达L4级的是Learning by Practicing（通过实践进行学习），通过搭建训练模型的虚拟环境，也就是 “世界模型”来实现，最终确保车辆不再发生由系统错误产生的问题和事故。</p>
  <p>所谓“世界模型”的构建包含了四大要素：数据生成器生成的场景数据，驾驶行为好坏的评估体系，高真实性的仿真，以及数据挖掘工具和引擎。楼天城坦言，小马智行从零开始追了近两年，整个过程非常痛苦：“这两年别说对外，对内都很难展示进展。但我不断告诉他们，这是正确的，我们应该这么做。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_2a01798953bb44fcb03f521ef479f721@46958_oswg53476oswg800oswg533_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>消除了技术屏障外，李想强调，决定L4级能否商业化落地还需要技术到位、产品到位、环境和政策到位，同时还需要消费者对于人工智能的信任到位。</p>
  <p>为了验证无人驾驶Robotaxi商业模式可行性，小马智行认为，技术、政策、规模化量产、生态共建缺一不可。目前，小马智行每天有超过百台的Robotaxi在北上广深四座城市进行运营。</p>
  <p>按照小马智行的测算，1000台车将是Robotaxi大规模商业落地的分水岭。在千台车的规模之下，供应链议价权相比于现在的百台车显著提升。在成本控制方面，第七代车型较上一代有60%-70%以上的降本空间，这将有助于小马智行在2025年下半年到2026年年初实现毛利转正的业绩目标。</p>
  <p>目前，小马智行一方面与主机厂达成了战略合作，另一方面利用IPO带来的现金流支撑团队打造“样板间”。张宁表示，千台车还不是特别大的投入，更重要的是把模式打通，做成样板间，向合作伙伴、政府、公众证明Robotaxi完整的商业闭环。“就像今天Waymo给全世界看到，L4 Robotaxi如何去成功一样，我们也可以走出中国自己的一条路线图来。这是我们集全公司之力在做的一件事情。”</p>
  <p>对于新势力玩家来说，生死存亡是一两年内可以预见的事情。在绝大多数玩家都拿到了电动化的门票后，智能化成为了竞逐焦点。“我们今天在做的所有事情，都是为了拿到L4的门票，因为L4所需要花的钱，所需要拥有的能力，所需要的数据量，是大家今天所不具备的。”李想认为，L4将会分出真正的胜负。如果不能实现L4，理想肯定无法迈入“万亿俱乐部”。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/84vJeQI3buzYLvVAOslX7w" rel="noopener noreferrer nofollow" target="_blank">“财经汽车”</a>，作者：包校千，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112615064325632</id>
            <title>十年后，跨年演讲输给十二颗葡萄</title>
            <link>https://www.36kr.com/p/3112615064325632</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112615064325632</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 12:06:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 跨年演讲, 罗振宇, 观众反响, 情感需求  
<br><br>  
总结: 跨年演讲在过去十年中经历了从火热到冷却的过程，观众对其热情逐渐减退，尤其是年轻人更倾向于传统的跨年庆祝方式。尽管罗振宇和吴晓波等商业大咖仍在继续演讲，但观众对内容的期待和满意度下降，演讲被批评为内容空洞和广告过多。社交媒体的变化也影响了人们对跨年演讲的关注，情感需求逐渐取代了对知识的渴求。如今，观众更希望通过轻松的方式与他人共享情感，而非沉重的知识灌输。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_8c3d8674f7004e9181f461f921d1f53e@46958_oswg876614oswg1080oswg722_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今天，距离新一年的开始仅仅过去了4个工作日。但在互联网上，跨年演讲的话题却已几乎失去痕迹。人们对它的记忆，已经模糊了。</p>
  <p>今年的跨年其实很热闹。2025，是罗振宇进行跨年演讲的第十年。在网上，还能看到首次演讲的张朝阳、围炉直播的雷军、大谈饮食的马未都，和即将告别聚光灯的吴晓波。</p>
  <p>人们期待着这些商业大咖们以年为单位，将发生的大事件浓缩成一粒粒知识胶囊，然后在短短几个小时之内吞咽，快速滋补自己的认知。</p>
  <p>但在今年演讲结束后，社媒上反响平淡，吐槽频出。罗振宇内场高价票一度骨折出售，吴晓波演讲更是被评为“贵价鸡汤”。</p>
  <p>对于年轻人们来说，跨年演讲更已成为过时的仪式。比起端坐在电脑前，他们更喜欢在灯火阑珊处为倒计时欢呼，或者遵守某个古老习俗，在跨年钟声中吞下十二颗葡萄。</p>
  <p>跨年演讲进入寒冬已不是新事，当下吴晓波已告别战场，罗振宇却还有另一个十年要守。降低姿态、回归初心，或许是他们在光鲜的现场后，更应沉淀的事。</p>
  <h2><strong>&nbsp;跨年演讲正在冷却</strong></h2>
  <p>“下定决心过好每一天！”在年终秀现场的巨大屏幕上，吴晓波戴着墨镜和头戴耳机。他正乘坐着陆空一体式飞行汽车前往演讲现场。车体厚重，像是在吴晓波周围筑了一个堡垒。&nbsp;</p>
  <p>今年是他演讲的第十年，也是最后一次年终秀。现场灯光湛蓝，光线如水波般流动。吴晓波身穿米色西装，舞台宽阔，他步伐轻巧，跑向聚光灯下。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_53790a8108644cb69b3d9b0b6b00bc6e@46958_oswg656765oswg1080oswg675_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这是2024年12月30日的景象，再往后一天，便是跨年当天。那晚，网络上更是大咖云集，演讲活动层出不穷。若打开日程表细数，就能看见很多熟悉的面孔。&nbsp;</p>
  <p>罗振宇已是台上的熟人，他依旧眯着眼睛，笑容和善；雷军一身白衣，仪态松弛，身后是宏伟的小米汽车工厂；张朝阳更是直接站在了教室里，实打实地为观众上了三个小时物理课。&nbsp;</p>
  <p>但如果聚焦于商业大佬们的跨年仪式，便会发现这几年，人们越来越不爱看跨年演讲了。&nbsp;</p>
  <p>单看抖音的数据，截至1月4日，罗振宇2024年跨年演讲抖音观看量为1209.4万，而相较于2023年的3386.4万和2021年的6005.2万人，观看人次明显大量减少。&nbsp;</p>
  <p>“行于可行，止于当止”是这一年吴晓波的演讲主题。但对于看客们来说，这更像是在跨年演讲彻底冷却前的一个明智决定。&nbsp;</p>
  <p>在2023年演讲结束后，人们已开始讨论跨年演讲的遇冷现象。那时有微博大V直言“罗振宇今年的跨年演讲现场上座率不到1/3”。其热度甚至超过演讲本身，挂在热搜榜良久。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_8fd03701892943a78dabc188e5d1b104@46958_oswg69163oswg633oswg200_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>虽然此事在后期被罗振宇亲自下场辟谣，但二手市场的标价骗不了人。当年的2980元门票最低仅售1300元。即使是黄牛，也是亏本在卖：价值980元的票，只需800元就可以拿下。&nbsp;</p>
  <p>而在今年，门票的价格仍一路下跌。临近演讲前，门票的价格更是低得令人膛舌：有的内场门票定价4680元，转卖的价格在1300-1800元左右，开场前仅需900元。&nbsp;</p>
  <p>大家对跨年演讲的不满除了表现在价格上以外，也表现在社交媒体上更尖锐的评论上。回溯到2018年，罗振宇作为跨年演讲这一形式的发起者，便已开始受到质疑。&nbsp;</p>
  <p>在演讲中，他把“小趋势”一词定义为“影响趋势的趋势””，被观众诟病为“永不出错的车轱辘话”。罗振宇还引用了巴菲特的名句，但随后也被扒出是错误信息。&nbsp;</p>
  <p>两天后，罗振宇发了一条微博，写着“我们是伞兵，伞兵天生就是被包围的”。不难看出，相较于自我反省，他似乎怨气更大一些。&nbsp;</p>
  <p>一位观众在下方留言，“仿佛收获了很多，又好像什么都没有”。这句话似乎如影随形，在此后的跨年演讲，“内容空洞”“鸡汤浓度过高”等类似的评论已成为常客。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_2001452ffc714ebfa47e45cb1ffa6dd4@46958_oswg37508oswg832oswg509_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有博主评论罗振宇今年的演讲中广告量过高：他像爆单的网红，而跨年演讲则是他的商单交付报告。&nbsp;</p>
  <p>据不完全统计，罗振宇在演讲中提及了8个广告主、3本新书和1个APP产品。甚至内场观众收到的大礼包里，也全部是广告产品。例如名创优品的玩偶、1688的定制毛毯、运满满的帆布包等。&nbsp;</p>
  <p>罗振宇的聪明之处在于，他巧妙地把自己的观点糅合到品牌创立或发展的故事里，用奋斗和成长的故事引得观众共鸣，又借此去除了一部分商业的锈味。&nbsp;</p>
  <p>但广告还是太多了。话题“跨年花千元听罗振宇演讲结果都是广告”在结束后再次登上微博热搜。观众们说，在商业价值外，剩下的都是怀旧情绪在堆砌，情感单薄。&nbsp;</p>
  <p>十年前的这一天，无数互联网创业者挤在狭小的出租屋里。他们准时蹲守在电脑前收听演讲，手里握着黑色签字笔，一点点记录着金句。&nbsp;</p>
  <p>相较于那时，现在的罗振宇已经达不到人们的期望值了。&nbsp;</p>
  <h2><strong>&nbsp;跨年演讲见证了互联网的这十年&nbsp;</strong></h2>
  <p>跨年演讲的现象级爆火，是因为乘上了互联网和社交媒体的蓬勃发展。例如，截止到2016年第二季度，微信覆盖了中国94%以上的智能手机，月活跃用户达到8.06亿。它和QQ都成为主流社交媒体之一。&nbsp;</p>
  <p>那时的人们对互联网上的社交感到新奇，把微信朋友圈视为塑造个人形象的工具。而现在，微信好友圈变了味，人们对认识的人反而防备心更甚，不愿轻易表达自己。&nbsp;</p>
  <p>发朋友圈的人也变少了。人们在现实的社交圈中带着面具，他们更愿意披上马甲在别的社交软件发表真实想法。因此，原本刷屏的跨年演讲金句，也消失在用于打造人设的社媒中。&nbsp;</p>
  <p>互联网发展最快速的时期，正处于罗振宇决定进行第一次演讲的前夕。那时，半数中国人已接入互联网。而数字创业也因不同的信息差而充满各种未知的契机。&nbsp;</p>
  <p>以互联网产业著称的中关村创业大街挤满着想品尝“总理咖啡”的年轻创业者，而在偏远地区，还有人从未听说过互联网。认知差异因网络而变成鸿沟，也为商业人士们的创业尚留有空白。&nbsp;</p>
  <p>2015年12月31日，还没减肥的罗振宇一身黑衣，走上北京水立方中的舞台。背景的大屏上，文字单薄。他认真地和观众讲：“要会观察、结缘，也要学会做PPT”。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_856659a37bbb493ca5737aae6e9fd92c@46958_oswg38452oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>同一时期，网络正在人们带来无限量的信息。创业者们也逐渐认识到，认知差异不仅是单纯的“会不会用电脑”，而是在互联网真正普及前，是否能抢先起跑。&nbsp;</p>
  <p>那时的吴晓波刚试运用自媒体“吴晓波频道”。日本购物风流行，他在出差回来的飞机上写了《去日本买只马桶盖》；因不解“小鲜肉”一词，他吃力钻研追星圈，写出了《知道鹿晗的请举手》。&nbsp;</p>
  <p>十年后的今天，智能马桶已成为过时的产物，网络上的流量小生一波接一波的火了又去。网络的普及让每个人信息获取渠道平等，曾经的差异一去不返。&nbsp;</p>
  <p>也是那年，罗振宇和吴晓波一起吃了个饭，跨年演讲的念头也孕育于此。只不过二人的想法差别巨大。罗振宇想把观众定位于具有热情和求知欲的年轻人，而此前提出“反屌丝文化”的吴晓波则把目光转向中产阶级。&nbsp;</p>
  <p>如今，这两种人群都不再相信认知的不同会带来新的机会。时间用蛮力挤压着创业的入口，人与人的认知差异夹缝狭隘，新的机会愈加罕见。&nbsp;</p>
  <p>机会流失的背后，经济正在下行，人们的消费观更加理性。若想加入跨年演讲现场，门票加上交通费和酒店费，这对于大部分人来说的确有些昂贵。&nbsp;</p>
  <p>而年轻人们相较于长叙事则更熟悉短视频。他们觉得，四个小时的演讲比两个小时的电影，“坐定难度”还大一些，信息量也显得有些沉重。&nbsp;</p>
  <p>于是在2025年跨年钟声响起时，年轻人们争相效仿西班牙的跨年习俗，忙乱掐点吞下12颗葡萄。&nbsp;</p>
  <p>毕竟，葡萄随手便能买到，也没有更深奥的命题，只要咽得够快就行。 &nbsp;</p>
  <h2><strong>&nbsp;有的人还是喜欢看跨年演讲&nbsp;</strong></h2>
  <p>跨年演讲虽一年不如一年，但还是有人愿意年年准时观看。他们不为汲取新知，而是更多出于一种情怀：想在一年结束之际，会一会台上的老朋友。&nbsp;</p>
  <p>有观众看完演讲眼圈发红。她说因为价格问题，所以这是自己十年来第一次，也是最后一次坐在跨年演讲的现场。&nbsp;</p>
  <p>座位很远，舞台很大，罗胖很小。她坐在看台的远处欢呼，前方人山人海，莫名有种不可跨越的距离感。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3a967fca374440359f5ba809e3202f39@46958_oswg101146oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>她看演讲的理由也很简单，只是想用罗振宇的鸡汤安慰过去一年的疲惫，也为新的一年输入更大的期待。&nbsp;</p>
  <p>老观众们的共识便成为了：比起学习，跨年演讲的作用更像是一种心灵抚慰和洽谈。情怀似乎是支持演讲的主要驱动力。&nbsp;</p>
  <p>作为中国知识付费的头部博主，罗振宇和吴晓波常年暴露在镜头下，言论和形象影响力仍是巨大的。但也无法从根本拯救他们正在直转而下的演讲口碑。&nbsp;</p>
  <p>在今年的跨年赛道，新进场的选手们反而收到了更好的评价。这表明，现在的观众们更想看亲民一些、轻松一些的晚会。毕竟，生活压力已经很大了。&nbsp;</p>
  <p>雷军便是其中一位新人。从“Are you OK”开始爆火的他，一直走的是接地气赛道。连第一次跨年活动，主题也是温馨的“围炉直播”。他特意说明，这是一次无主题闲聊、主打陪伴。&nbsp;</p>
  <p>在直播中，他还现场接入了玩梗出名的B站晚会，亲自发送“OK”梗的弹幕。数据说明了观众们的喜欢，观看人次为3788.4万，点赞数超过1.2亿，几乎和演讲第十年的“老人”们齐平。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_9f8588bb21574787b06ccf64a561f834@46958_oswg690862oswg1053oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>董宇辉更是脱离了发言这一形式，回到了自己的老家西安举办了一场音乐会。&nbsp;</p>
  <p>当晚音乐会开播后大受欢迎，甚至导致同时间的其他卫视晚会收视率直线下跌。直播时间只有两个半小时，观看人次却从头到尾稳定在1900万左右，波动极小。&nbsp;</p>
  <p>除了郎朗和方锦龙以外，董宇辉请的均是咖位不大的演奏者。虽没有名气，舞台也略显拥挤，但内容扎实，观众反馈出乎意料的好。&nbsp;</p>
  <p>若从深度方面讨论，没有晚会能比的过张朝阳的跨年量子力学课。他延续了《张朝阳的物理课》风格，将量子力学的宏大分解成早上的一缕阳光、电动牙刷的振动，&nbsp;</p>
  <p>好玩的是，张朝阳将晦涩的物理知识化成了生活小贴士。比如，他根据量子运动提醒大家要早点洗衣服，因为“油点和污渍通过扩散效应渗入布料”。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ee2ff1f1cf2f4941b000a3bfe3528d2d@46958_oswg295938oswg599oswg399_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>虽命题深奥，但张老师的教学通俗易懂，几乎没有什么高深的专业词汇。人们总是喜欢听得懂的东西，因此首次开播观看人次也破千万。&nbsp;</p>
  <p>这些现象表明，跨年演讲这一形式正在退场，IP和网红形象的建立正成为这些商业人士扭转舆论的主要命题。&nbsp;</p>
  <p>跨年的价值，不再取决于知识的浓度。在信息和认知方面趋近的今天，人们正在回归初始的情感需求。&nbsp;</p>
  <p>跨年是一个晚上，或在12月31日分钟与时针重合的那一秒。人们更希望与演讲者或身边的人一起，共享情绪，留下一段钟声中的限定记忆。&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/0L9Mi5L8cmANuPwXOcO8Hg" rel="noopener noreferrer nofollow" target="_blank">“未来商业观察”</a>，作者：肖珂，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3111858592042498</id>
            <title>流于形式的AI工具学习并不能解决企业应用场景的痛</title>
            <link>https://www.36kr.com/p/3111858592042498</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3111858592042498</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 11:59:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI技术, 企业应用, 挑战, 培训体系  
<br><br>  
总结: 文章探讨了AI技术在企业应用中的现状与挑战，指出AI的广泛应用与技术创新并存，但企业在实施过程中面临战略规划不明确、内部摩擦、投入与回报不成比例、技术与人才短缺以及数据质量与安全等问题。同时，企业在AI应用上存在对效果期望不切实际、流于表面的工具学习和过于依赖技术而忽视业务需求的误区。为此，企业需建立系统化的培训体系、开放包容的企业文化和鼓励创新的机制，以提升员工的AI应用能力，实现技术与业务的有效结合。 </div>
                        <hr>
                    
                    <p>在不同的使用者眼中AI有可能是人工智能也有可能是人工智障！&nbsp;</p>
  <p>这就与企业做数字化转型在于转而非数字化本身的道理一样。&nbsp;</p>
  <p>当前AI技术的应用已经渗透到社会经济的多个领域，其发展现状呈现出以下特点：&nbsp;</p>
  <p><strong>第一，广泛应用与深入融合性，</strong> 可以说AI目前已经渗透至我们生活的各个方面，在不断颠覆与改变着我们的工作与生活方式；&nbsp;</p>
  <p><strong>第二，技术创新与不断突破，</strong> 且创新与突破的速度在不断的加快；生成式AI的普及不仅提高了工作效率，还激发了新的创意和应用。&nbsp;</p>
  <p>虽然AI技术在我们的生活中大放异彩，但相对于工作场景的普及与应用老杨认为还有很长的路要走，<strong>当前企业应用AI技术还面临着诸多难点，</strong>比如：&nbsp;</p>
  <p><strong>1.战略规划与实施路径不明确</strong>&nbsp;</p>
  <p>企业在应用AI技术时，往往缺乏明确的战略规划和实施路径。这可能导致企业在一些不必要的项目上投入大量时间和资金，而忽视了那些更具潜力的应用场景。缺乏长远规划也会使得AI项目难以持续推进，无法实现预期的商业价值。&nbsp;</p>
  <p><strong>2.内部摩擦与信任问题</strong>&nbsp;</p>
  <p>企业内部员工对AI技术的理解和接受程度不一，许多员工将AI视为取代自己工作的工具，而不是提升工作效率的手段，这种误解导致了对AI的抵触情绪；同时员工对AI的工作原理和应用场景缺乏足够的了解，导致无法有效利用AI技术来提升自身的工作表现，这种情况不解决、不改善，可能会导致技术与人之间的脱节，特别是当前一些企业中基层管理者由于对AI的信任度较低，担心AI应用过程中数据的安全和隐私问题，从而对AI技术产生不信任感。推动AI应用的障碍。&nbsp;</p>
  <p><strong>3.投入与回报的问题</strong>&nbsp;</p>
  <p>AI项目的开发和部署需要大量的资金投入，包括数据获取、模型训练、硬件采购等，对于大部分传统企业而言，投入产出比可能较低，难以承担高昂的成本。&nbsp;</p>
  <p><strong>4.技术与人才短缺</strong>&nbsp;</p>
  <p>AI技术的实施需要专业的人才支持，包括数据科学家、机器学习工程师等。然而，目前市场上对这类高端人才的需求远远超过供给，导致企业在招聘时面临较大压力。同时，现有员工技能不足、对新技术上手慢也是企业应用AI技术的一大障碍。此外，AI技术的快速发展使得企业在技术更新和迭代方面也需要不断投入和跟进。&nbsp;</p>
  <p><strong>5.数据质量与安全</strong>&nbsp;</p>
  <p>高质量的数据是AI应用的基础，但对于大部分传统企业而言却面临着数据不完整、不准确、格式不统一等问题。此外，数据隐私和安全也是重要考虑因素，尤其是在涉及敏感信息的行业，当前需要面临的现实情况是企业内部的业务数据往往涉及商业机密，不愿意外泄，这使得外部AI公司难以获取到足够的行业数据来训练模型。&nbsp;</p>
  <p>从以上不难看出，企业应用AI技术面临诸多难点和挑战。企业需要加强技术研发投入、培养专业人才、制定明确的战略规划和实施路径、建立合规体系并寻求外部资金支持等。通过这些措施，企业才可以更加顺利地实现AI技术与工作场景的融合发展，更好的用AI技术赋能企业经营管理。&nbsp;</p>
  <p><strong>那么当前企业在AI技术的应用上存在哪些误区呢？</strong> 老杨总结如下：&nbsp;</p>
  <p><strong>第一，对AI效果的期望不切实际</strong>&nbsp;</p>
  <p>当前一些企业存在盲目跟随其他企业的AI应用模式，而没有根据自身的业务需求和技术能力进行合理规划。部分企业在实施AI项目时，对技术的期望过高，希望它能够立即带来显著的效益。然而，AI技术的价值不仅在于初期投资，更在于其长期带来的业务变革与提升，更重要的是AI技术是不是与企业经营管理融合发展，因此企业应关注AI的长期战略投资，确保整体项目的可持续性，而非如同做数字化一样是一阵风。&nbsp;</p>
  <p><strong>第二，流于表面的工具学习</strong>&nbsp;</p>
  <p>当前很多企业要求员工拥抱AI、学习AI，但其学习形式都过于依赖于网上一些“快餐式”的课程，这些课程主要教授使用AI工具或生成内容的提示词，对于企业来说，尤其是管理流程复杂、生产工艺多样的大型企业，这种工具化的学习几乎无法带来实际效益。所以企业应构建系统化的AI解决方案，涵盖从数据处理、预测分析到业务流程优化的全链条应用场景。&nbsp;</p>
  <p><strong>第三，过于依赖技术而忽视业务需求</strong>&nbsp;</p>
  <p>企业在应用AI技术时，往往偏向于关注技术的先进性和创新性，而对业务需求的理解和洞察相对薄弱。这导致了不少AI项目的失败，因为技术本身不是目的，而是为了解决特定的业务问题。技术与业务的结合至关重要，企业应明确业务需求，确保AI技术的应用能够真正提升业务效率。所以企业应以掌握AI的能力和AI思维为目标，将AI转化为可以在具体业务场景中发挥作用的工具，而不是纠结于技术层面。&nbsp;</p>
  <p>所以从以上我们不难看出企业应保持理性和客观的态度，正确认识AI技术的局限性和潜力，制定合理的战略规划，加强技术与业务的结合，提升应用能力，以实现AI技术的真正价值。&nbsp;</p>
  <p>那么企<strong>业该如何培养员工从接受到应用AI的能力，赋能企业管理？</strong>&nbsp;</p>
  <p>老杨认为：&nbsp;</p>
  <p><strong>1.一个系统化的培训学习体系很重要：</strong>&nbsp;</p>
  <p>企业应根据员工的不同层次和岗位需求，制定全面的培训计划，制定针对性的培训课程，例如在课程设计上要涵盖AI基础知识、应用案例、操作技能等；在培训形式上除了传统的课堂培训，还可以采用在线课程、研讨会等形式，让员工在轻松的氛围中学习；最关键的是学习的持续性，定期更新培训课程，确保员工的知识和技能不落伍；&nbsp;</p>
  <p><strong>2.一个开放包容的企业文化很重要：</strong>&nbsp;</p>
  <p>企业需打造开放包容的企业文化，对AI技术的应用问题，需营造开放的交流环境，使员工对新技术产生兴趣和好奇心。在员工尝试使用AI技术时，及时提供必要的技术支持，包括引导、培训和解答问题，确保在遇到困难和挫折时，员工能够获得所需的帮助。&nbsp;</p>
  <p><strong>3.一个鼓励创新的机制</strong>&nbsp;</p>
  <p>企业应鼓励员工培养创新思维和解决问题的能力，利用AI技术作为解决问题的新工具。通过引导员工思考如何将AI技术应用于实际工作中，激发他们的创造力和想象力。同时，建立奖励机制，对在AI应用方面取得突出成果的员工给予表彰和奖励。&nbsp;</p>
  <p>综上所述，AI技术无论多先进如果应用不当，都无法解决企业管理场景的痛，流于形式的学习只是徒增浪费，不在认知上提升、不在管理机制上进行变革、不在应用场景上做深度融合，最终AI技术也只能是花架子。&nbsp;</p>
  <p><strong>--END--</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg2NTY3NjU1OA==&amp;mid=2247497552&amp;idx=1&amp;sn=0b9adcfdcfa31c8b8a7fe7df193db10c&amp;chksm=cfabbfb9931153fb97fa6b0d4b5ccbc4e7a86b5ede17cd2a31ae4f74b7a8c842ca2f82580c3b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“湘江数评”（ID：benpaoshuzi）</a>，作者：老杨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112563631853058</id>
            <title>上海四小龙，集体求变</title>
            <link>https://www.36kr.com/p/3112563631853058</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112563631853058</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 11:45:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <叠纸, 二次元, 女性向市场, 游戏变革>
<br>
<br>
总结: 2024年，叠纸的《恋与深空》在女性向市场表现优于其他三家上海四小龙，显示出女性玩家的活跃和市场潜力。二次元游戏市场面临供大于求的困境，低质量游戏被淘汰，头部游戏仍在挣扎。米哈游的《原神》收入大幅下滑，迫使其采取降价和买量策略以维持市场地位。女性玩家的崛起推动了游戏内容的多样化，开发者需在题材和风格上进行差异化竞争。整体来看，四小龙在变革中遇到阻力，亟需创新以应对市场挑战。 </div>
                        <hr>
                    
                    <p>2025新年伊始，叠纸《恋与深空》又一次冲到了畅销榜首，引发了媒体的报道，这也是短期内第4次冲到第一的表现。</p>
  <p>过去外界将米哈游、莉莉丝、鹰角、叠纸一起命名为「上海四小龙」，四者发展的方向并不相同。之前莉莉丝更偏向买量和数值，更偏向华南公司的打法，而其他三者则是内容向的新势力。</p>
  <p><strong>从2024年的发展来看，叠纸所代表的女性向市场力量发展表现优于米哈游、鹰角所属的二次元、也优于莉莉丝主打的卡牌和SLG。</strong></p>
  <p>但四小龙的基调是一致的，都在过去一年积极求变，同时也都遇到了变革中的阻力。</p>
  <h2><strong>二次元的困顿与希望</strong></h2>
  <p>当一个集聚效应非常强的垂直赛道出现下滑，执牛耳的存在必然好不到哪里去，自带热搜体制的米哈游这一年依然腥风血雨。</p>
  <p>2024年的最后一篇分享中游戏价值论提到，年底二次元游戏市场呈现两级趋势。一方面大量二游停运，另一方面新品消息铺天盖地。</p>
  <p>市场供大于求，低质量二游将被淘汰，头部二游仍在强撑。2024年，二次元游戏市场遭遇了前所未有的挑战。据中国游戏产业报告，2024年，我国二次元移动游戏市场实际销售收入293.48亿元，同比下降7.44%。</p>
  <p>其实这个情况今年早期就有了苗头。</p>
  <p>年中的时候我们提到，新品是赛道健康持续发展的必需品，但<strong>新鲜血液带来的是额外增收还是存量竞争是两码事。</strong>这个赛道不仅仅是整体上头部通吃，细分赛道有了头部之后，目前基本看不到能够冒头的第二个直接竞品。</p>
  <p>作为攫取最大蛋糕的老大，以米哈游为例，其实从星铁到zzz，内部吸血影响的说法并不罕见。根据 Sensor Tower 等平台的数据，2020 年《原神》收入高达 15.6 亿美元，2023 年仅为 9.4 亿美元，下滑 40%。</p>
  <p><strong>市场缩水意味着左手倒右手并没有把蛋糕做得更大，星铁上位，原神下滑，ZZZ新高，前两位也开始震荡，这是客观存在的现象。</strong></p>
  <p>如此状况下，今年米哈游最大看点也是求变。</p>
  <p>最典型的《原神》四年开始放下身段选择降价。这其实传达了一个明确的信号，<strong>二游老大也要用新的手段才能维持发展、维持地位了。</strong>当时也提到，对于米哈游自身品牌而言，降价的行为可能不仅仅是对用户示好，而是一种祛魅。</p>
  <p>自此，疯狂买量的消息传出，DataEye-ADX数据显示，<strong>今年暑期档投放中重度APP游戏中，‍米家两款跻身前6。</strong>同样引用媒体报道的爆量助手数据，米家三款最近30天都位居TOP 5。从趋势图来看，投放素材分别达到3-5倍的程度。</p>
  <p>买量本身是正常的商业策略，其实在原神之前，阴阳师爆火的时代，二次元赛道与买量的距离并没有那么远。作为卡牌玩法，本身也会采用正常的买量营销策略。</p>
  <p>2020年原神横空出世后，市场对于二次元产品的商业框架的认知，集中在以内容驱动，配合氪金潜力巨大的抽卡玩法，与用户建立紧密情感连接的同时可以获得非常高的回报率。相比市场主流的买量产品，节省巨额的营销推广费用。同时情绪驱动也可以加速品牌的建立。</p>
  <p>新兴的细分赛道、更高的回报更具粘性的用户群体，吸引一大波产品进场跟风。</p>
  <p><strong>随着内容化不再是二次元游戏的专属，米哈游的疯狂买量更是一记重炮，从泾渭分明的新方向拉回到与买量产品同一起跑线。</strong></p>
  <p>假设现在想要立项，且不论是否有精妙的剧本和角色设计，卷到挑剔的品相成本、社区维护和管理投入、行业老大已有巨额的宣发投入，面对高风险低回报率，如何说服决策者或者投资人。</p>
  <p><strong>二游赛道底层商业逻辑的改变，才是巨额买量之下真正的冲击。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_99fb2f300e6f4f0fb91e1dec31694c68@000000_oswg891082oswg1080oswg496_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>同时这一系列的高成本投入动作也没能让原神和星铁重回过去高度，反倒是买量相对最少，经过大改和强力角色卡池的《绝区零》冲了一次榜首，超越开服的表现。</p>
  <p><strong>米哈游的一系列求变是两条主线，内容向的代表能不能突破用户审美疲劳以及在全新的赛道证明自己一次。</strong></p>
  <p>2024年9月，米哈游发布了一张包含多个新项目的招聘广告。这张招聘广告中包含五个全新项目，关键词分别是现代都市、写实奇幻、动物拟人、崩坏IP新作以及一款欧美卡通画风产品。</p>
  <p>同样赛道的鹰角过去一年异常低调，除了自我表达强烈的单机游戏《来自星尘》外，到了年末《明日方舟：终末地》宣布二测才激起了浪花。</p>
  <p>大环境决定鹰角吃老本的现状并没有改变，被寄予厚望的终末地也明确表达了鹰角在二游赛道的理解。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ab0bb41c208a48c5a6bc3bb970949d9a@000000_oswg873499oswg955oswg526_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>保持美术竞争力，提高产品表现力，技术里的加持下从玩法和平台突破，这其实也是行业明确的解题思路之一。</p>
  <p><strong>对于鹰角自身而言，继续践行从小成本到大制作的迈步，这样的求变必然会遇到产品开发商一系列的新问题。</strong></p>
  <p>包括年中有报道陈腾讯NExT Studios 前副总经理顾煜加入鹰角网络，并在其中担任技术高管，定位接近CTO。</p>
  <p>从过去拼内容，到现在品牌、IP、内容、技术，都要一把抓，终末地也是鹰角求变阶段性的成果。</p>
  <h2><strong>女性市场的风和新的挑战</strong></h2>
  <p>2024的叠纸可以用春风得意来形容，《恋与深空》蓄势后的爆发，多次登顶就是最好的证明。</p>
  <p>然而行业最关注的焦点还是赛道的发展，一个比较有意思的点是，今年惨淡的电影市场也在大谈特谈女性观影。</p>
  <p>值得注意的是，<strong>眼下「她力量」的风到底能不能成为市场增量而不是过去的存量换血本身需要打个问号。</strong></p>
  <p>因为过去几年大家不提「她经济」并不代表女性玩家的示弱。相反，几乎所有大DAU类型(派对、MOBA、FPS)，细分赛道自走棋、二次元、小游戏都可以看到女性玩家活跃的身影，甚至SLG这种都会拿女玩家出来做宣发。</p>
  <p>在过去的认知中，相比于男性玩家对于游戏玩法带来的乐趣，女性玩家更容易被游戏美术、音乐、剧情人设、营销等层面的内容所吸引。在这种理念的驱使下，<strong>女性向市场的新品更注重在题材和风格上进行差异化竞争，同时加大在美术音乐、市场营销等包装层面的投入。</strong></p>
  <p>这也导致玩法的同质化或者说整体弱化，其主要的作用是为故事剧本的展开提供互动的手段以及养成体系的数值体现，这一点有点类似二次元市场过去的理念。</p>
  <p>而女性玩家活跃于各个类型玩法实际情况其实也表明，她们是真正热爱游戏的玩家，并不会被固有的题材和玩法所限制，或者说，通过习惯培育女性玩家对于玩本身的乐趣接受度不断提高。</p>
  <p>换句话说，<strong>女性玩家正在从泛用户走向核心，这才是这一轮「她经济」浮出水面的最关键支撑。</strong></p>
  <p>面对这样的趋势，玩法变革同样成为关键，灵犀《如鸢》是一例，叠纸《无限暖暖》是另一例。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_611ee823f3904f95a8d8efbf34e102b5@000000_oswg986703oswg1080oswg687_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>产品上线后，叠纸创始人姚润昊第二天发布内部信称，「无限暖暖的首日流水大大提高了公司游戏首日流水记录。我们原本以为很难在我们不擅长的PC和PS平台上取得突破，事实上，从首日收入来看，国内PC收入超过50%，海外的PS+PC的收入占比更是高达80%。其中，笔记本占到了很大的份额。」</p>
  <p>跨端固然是一种转变，但需要注意的是，变革同样也有新的问题。《无限暖暖》在移动端的表现似乎并不尽如人意，而PC主机端则显得更为出色。这背后折射出手游公司跨端转平台必然面对的新的技术考验，而不仅仅是产品思路的挑战。</p>
  <p>「PC、主机和移动版本是两个游戏」，这种论调在接下来的跨平台浪潮中会被反复验证，进而继续把高企业技术积累带来的竞争优势，叠纸也好、鹰角也罢，从小到大寻求转变的过程中都必须克服技术壁垒的困难，才能保护移动端的基本盘。</p>
  <h2><strong>直面最激烈战场的野心和挑战</strong></h2>
  <p><strong>在上海四小龙中，莉莉丝都是最特殊的那个，是被包裹上了华东公司皮的华南公司，它的业务形态和华南系的公司更为贴近，无论是产品的形态，还是运营的方式，都是如此。</strong></p>
  <p>其擅长的卡牌和SLG，包括出海的打法，都与其他三人完全不同。</p>
  <p>然而从《剑与远征：启程》开始，莉莉丝有意识向内容向靠拢，保持放置卡牌基本盘的同时，向剧情、世界探索、赛季制等长线内容的形态涉足。</p>
  <p>这款产品拿下谷歌游戏2024年度最佳游戏和年度iPhone游戏是最好的实力证明。</p>
  <p>然而即便如此，启程本身的稳定性却不如AFK一代和莉莉丝其它的SLG产品，这与放置卡牌当下激烈的市场环境也有关系。</p>
  <p>「不想只做买量式的氪金游戏」是莉莉丝明确的战略转型，这两年新推出的《生活派对》以及《远光84(Farlight 84)》毫不掩饰自己向往内容和大DAU的转型之心。</p>
  <p>当然从现实发展的角度，无论主打内容牌的游戏团队还是传统买量领头羊，都渴求大DAU的出现，能够给企业的整体发展提供助力。</p>
  <p>然而《生活派对》愈挫是今年转型路上的重大打击。</p>
  <p>上个月传出「莉莉丝游戏旗下的《生活派对》项目组，在开启不删档测试之后的4个月后，迎来较大幅度的裁员。原制作人下课，当下项目一把手的位置虚位以待。」的消息。</p>
  <p>就在一年前的11月，这款原本被寄予厚望的《生活派对》开启首次测试。当时游戏价值论聊过，这款产品的社交的比重甚至高于《蛋仔派对》、《元梦之星》，用莉莉丝发行负责人张子龙当初的说法「《生活派对》比较特殊，我们把它定义为「依托于游戏的社交产品」。」</p>
  <p>莉莉丝当然是很有野心的，挑战的派对游戏以及射击赛道都是令人咋舌的巨头战场。</p>
  <p>不过相比其他竞品，《生活派对》的发展过程相对来说比较低调，莉莉丝有意识避免重走买量营销的路子。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0054cfd7bfb54ff2a3d018e00fc2124b@000000_oswg534130oswg1080oswg547_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一款英雄射击《远光84》海外上线之初，也没有投入什么资金买量，据官方所说曾靠着自然增长达到了百万DAU。</p>
  <p>当《生活派对》冲锋失利，这一款FPS赛道产品谋求大DAU之路就更具看点。<strong>未来的国内运营策略上，莉莉丝到底是继续保持克制走内容传播、口碑推广的转型策略，还是会重回买量模式。</strong></p>
  <p>最近这款游戏也开始在朋友圈等渠道投放预约广告，预示今年加入国服战场的时机即将到来。</p>
  <p><strong>回顾上海四小龙的2024年，无一例外都遇到了变革上的阻力，基本盘的维稳和突破、跨赛道的开拓、跨平台的全新挑战，就和我们之前全年盘点中的总结一样，这是游戏行业新一轮大变革的起点，过去功成名就的方法论迫切需要革新。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_d4d7a1e3c67c48388f5dfd55045f33a6@000000_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTU0MTcyMg==&amp;mid=2247505262&amp;idx=1&amp;sn=522172350319698aa21c074d80bb0be3&amp;chksm=cf3c808857e0005f2279bebfa6a021a9b94941d1bceff79f2b0ff1b1bd551ef7643c359b45c2&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“游戏价值论”（ID：gamewower）</a>，作者：李亚捷，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112477146287624</id>
            <title>李开复独家回应：盲目坚持负担不起的东西，并不是健康的选择 | 智涌独家</title>
            <link>https://www.36kr.com/p/3112477146287624</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112477146287624</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 11:30:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 商业化, 大模型, 拆分, 李开复  
<br><br>  
总结: 李开复在与《智能涌现》的对谈中强调，零一万物将专注于商业化而非技术实验，计划调整业务优先级，放弃超大模型的预训练，转向小参数行业模型。与阿里云合作成立“产业大模型联合实验室”，以便利用大厂资源进行大模型训练。公司还将拆分部分业务，独立运营以提高专注度和效率。李开复指出，创业公司需灵活调整战略，确保技术能够落地应用并带来收入。 </div>
                        <hr>
                    
                    <p>“我们做的是商业公司，不是‘零一万物技术实验室’。”</p>
  <p>放弃模型？被阿里全盘收购？2025年的第一周，大模型六小虎之一的“零一万物”深陷舆论漩涡。</p>
  <p>2025年1月7日，《智能涌现》与漩涡中心的零一万物创始人李开复，进行了一场对谈。这位“最资深的AI创业者”，回应了近日零一万物的人员变动和业务拆分：</p>
  <p>“创业公司第一年打法未必合适第二年，调整和转型是创业之必然。今年是商业化的决胜之年，零一万物的业务优先级也要做出相应的调整。”李开复对《智能涌现》表示。</p>
  <p>就在一天前，流传在网上的一则消息，直指零一万物“将卡和预训练团队卖给了阿里”。当日晚，李开复亲自在朋友圈辟谣。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_e207944553954ac3900c9e7cabbcaccd@5783683_oswg81865oswg1080oswg711_img_jpeg?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p class="img-desc">李开复在朋友圈的回应。</p>
  <p>这次变动的关键，在于零一万物预训练和Infra团队的去向。</p>
  <p>李开复告诉《智能涌现》，<strong>愿意继续训练超大参数模型的成员，加入了零一万物和阿里云成立的“产业大模型联合实验室”</strong>。</p>
  <p>《智能涌现》了解到，2024年12月中旬，两个团队陆续收到调整通知，而后在12月底，预训练团队收到阿里“通义”的offer，Infra团队则收到了阿里智能云团队的offer。</p>
  <p>“阿里收编”的背景，源自零一万物的一个判断：初创公司投入超大模型预训练的性价比，太低了。</p>
  <p>“大家都看得很清楚，只有大厂能够烧超大模型。”李开复告诉《智能涌现》，零一万物2024年以来的目标，是做小参数、适中的行业模型，“超大模型的用处在于可以教较小的模型，所以我们就需要一个训得起大模型的大厂合作。”</p>
  <p>李开复口中的“大厂”，就成了零一万物的老股东阿里。“零一万物中还有不少成员有AGI的梦想，这部分成员就可以选择加入实验室。”李开复提到。</p>
  <p>而至于“卡被收购”的传言，李开复直言，零一万物是通过云服务的模式训练模型：“我们自己也不拥有卡，我们怎么去卖？”</p>
  <p>如何赚钱，成了这家独角兽2025年最重要的命题。除了模型训练策略的调整，零一万物还将游戏、金融等AI业务考虑拆分，进行独立运营和融资。</p>
  <p>拆分的逻辑，来源于创新工场时期孵化项目的经验。李开复告诉《智能涌现》，当团队非常聚焦在一个垂类，他们更能做深做透。</p>
  <p>当然，零一万物拆分业务的逻辑也相当现实，“<strong>先去找投资人聊，看有没有人愿意投</strong>”。</p>
  <p>“创业公司的生存之道是要考虑怎么样去善用每一块钱，而不是弄更多GPU来烧。”李开复总结。</p>
  <p>以下是《智能涌现》与李开复的对话，略经编辑：</p>
  <h3><strong>超大模型，交给阿里训</strong></h3>
  <p><strong>《智能涌现》</strong>：围绕事件的焦点，零一万物的预训练团队和Infra团队，到底发生了什么？</p>
  <p><strong>李开复</strong>：我们跟最大的投资者阿里一直在沟通，也成立了一个联合实验室（产业大模型联合实验室）。联合实验室会是做更有Scaling Law方向性的工作，这个是阿里来主导。</p>
  <p><strong>那我们有一些成员擅长和愿意投入Scaling Law ，所以部分团队会通过联合实验室和阿里深度整合。</strong></p>
  <p><strong>《智能涌现》</strong>：意味着预训练团队和Infra团队可以自行选择去阿里，或者留在零一万物？</p>
  <p><strong>李开复</strong>：这些细节就先不多说了。</p>
  <p>能透露的是，现在有一个做超级大模型的巨大机会，阿里决定要往前冲，我们也为阿里鼓掌。在过去的一年半里，我们确实有一些优秀的成员还对这件事情抱有很大热情。那双向选择是很自然的。</p>
  <p><strong>《智能涌现》</strong>：预训练和Infra团队加入阿里，是不是意味着零一万物正式放弃预训练了？</p>
  <p><strong>李开复</strong>：我们理想化的“预训练”是做务实的、小而快的，然后以商业性价比来评估的模型。</p>
  <p>之前OpenAI 前联合创始人Ilya说，Scaling Law已经到了尽头。意味着巨大的模型要花很多的钱，得到的效率也不会像以前那样递增。所以必然只有大厂能烧超大的模型。</p>
  <p>随着Yi-Lightning（零一万物的20B模型）获得了比较好的市场反馈，我们也看到以后零一的角色应该是做相对快而小，而且便宜的模型。以后训练的模型不会比Lightning更大了。</p>
  <p><strong>《智能涌现》</strong>：1月初零一万物和阿里云成立实验室训练大模型，两方的角色定义是什么？</p>
  <p><strong>李开复</strong>：超大模型的用处在于它可以教较小的模型，我们叫做“teacher model”，大模型用数据蒸馏、数据合成等方法，教小模型能力，是训练模型的一种策略。</p>
  <p>虽然大模型可能很贵，也比较慢，但是它是中国大模型在应对科技封锁时，必须要占据和坚守的创新生态位和安全底线。</p>
  <p>所以我们觉得要和一个烧得起大模型的大厂合作，以后超大的模型由阿里训练，我们就可以用小而精的团队来做小而便宜的模型，拥抱应用的爆发。</p>
  <p>很多人还是抱着超大模型的梦的，那么这些人就非常适合加入阿里主导的联合实验室。</p>
  <p><strong>《智能涌现》</strong>：传闻中零一万物的卡（指GPU）卖给了阿里，是怎么回事？</p>
  <p><strong>李开复</strong>：卡的事情我不知道是哪里出来的。我们自己也不拥有卡，怎么去卖啊？所以卡的事情无法回应。</p>
  <p><strong>《智能涌现》</strong>：不自己买卡建集群，购买云服务，是AI初创公司的常态吗？</p>
  <p><strong>李开复</strong>：大家认为小公司不适合超大模型，所以那些有上万张卡的小公司，可能要重新考虑，不烧大模型的话，卡要不要减少。</p>
  <p>我觉得这是一个行业通用的思考。<strong>我们不再做这件事情不是说不相信Scaling Law，而是说我们把用更多卡烧超大模型这件事情，交给能够做 Scaling Law的大公司，比如说阿里，然后我们跟它合作，这才是生存之道</strong>。</p>
  <h3><strong>七成收入来自B端</strong></h3>
  <p><strong>《智能涌现》</strong>：您的辟谣朋友圈提到，2024年零一万物的确认收入已经有一个多亿了。这主要来源于哪些业务？</p>
  <p><strong>李开复</strong>：实际上我们一开始以To C为主，而且To C我们一开始就做出海。我们有明确的认知，2024年在国内做To C比较难商业化变现，所以国内我们基本上坚决不烧钱获客，去做To C产品。</p>
  <p>在C端，<strong>我们去年达成的业绩，大概有2-3成来自出海的付费产品</strong>，比如PopAi，它是一个生产力工具。</p>
  <p><strong>《智能涌现》</strong>：那意味着也有七成的收入来自B端？</p>
  <p><strong>李开复</strong>：To B是在2024年下半年，我们经历了半年的战略转型。因为我们先打磨了大模型技术，过程就像是通过技术在找场景。</p>
  <p>所以To B我们也做了多种尝试，其中一个就是游戏产业，下半年整体也有比较好的增长。我们在金融和能源行业也有不错的增长。</p>
  <p><strong>《智能涌现》</strong>：从上半年的To C转到下半年的To B，业务形态的变化是相当大的。</p>
  <p><strong>李开复</strong>：可能外界会感觉2025年1月初开始变动比较大，实际上我们已经规划了数月时间。我们整体的组织、资源的配置、项目优先级的排序，哪些做和不做，其实经过了系统性的整体梳理，在年末开始有了一些里程碑的体现。</p>
  <p>比如我们和阿里谈联合实验室，也谈了一段时间，近期才官宣。</p>
  <p><strong>《智能涌现》</strong>：近一年来，零一万物整体的组织、资源的配置，有哪些变动？</p>
  <p><strong>李开复</strong>：我们的组织架构调整主要在于增加To B的功能，能够带来更多行业大模型的合作。</p>
  <p>所以我们内部团队也做了相应的调整。比如落地要有非常强的售前，以及聆听客户需求、跟进策划产品和商业模式的团队。我们还要有强的工程研发，因为这些应用需要标准化、平台化。我们坚持不做接一单赔一单的To B生意。</p>
  <p><strong>《智能涌现》</strong>：零一万物专注训练小模型，怎么做商业化？</p>
  <p><strong>李开复</strong>：我们认为极速的、高性价比的模型特别适合做产业模型。这不是说我们要做3B、4B的模型，这些过小的模型在很多场景是不work的。</p>
  <p>同时我们也不会继续做超大参数的模型，因为这些超大模型在车企、金融、游戏等很多领域也不适用。我们要做的是和Yi-Lightning相似规模，或者更小一点的模型，能够适用于更多行业场景。</p>
  <p><strong>《智能涌现》</strong>：零一万物在行业To B起步是比较晚的，怎么弥补后发劣势？</p>
  <p><strong>李开复</strong>：我们会主打几个业务。我们不像有些AI公司，能够雇300个销售。我们会用我个人的人脉去切入一些非常好的领域和公司，然后去找到可以做标配解决方案的领域。</p>
  <p>同时，我们可以跟创新工场联动，创新工场孵化的很多领域的公司，跟我们都是非常互补的，可以合作。</p>
  <p>以及我们觉得行业模型还不够细分，比如我不认为金融是一个赛道。我们会在行业的基础上再向下细分赛道。这里我就不能讲细节了，因为讲了别人就知道你在做什么了。</p>
  <h3><strong>我们是商业初创公司，不是技术实验室</strong></h3>
  <p><strong>《智能涌现》</strong>：我们了解到，2025年1月初的一次内部会上，你提到零一万物要“全面向应用看齐”。</p>
  <p><strong>李开复</strong>：一开始我们肯定带着追求AGI的理想，吸引了非常多有强大技术魂的同事，验证了我们能够做出世界级的技术。</p>
  <p>但某种程度上，<strong>今年会是大模型公司商业化的淘汰年</strong>。如果大家不能走过这个坎，不能去验证技术能够真正落地到应用，就会面临淘汰的可能性。</p>
  <p><strong>《智能涌现》</strong>：“真正落地到应用”的评判标准是什么？用户数？营收？还是利润？</p>
  <p><strong>李开复</strong>：我们觉得的核心就是<strong>这个应用必须要能够赚钱，要能够带来收入，而不是盲目的做这个增量，盲目的做用户数。</strong></p>
  <p>所以要“全面向应用看齐”，是指：<strong>当你真的有技术，没有应用的时候，这基本上只是一个实验室。</strong></p>
  <p>我们做的是商业公司，不是“零一万物技术实验室”。</p>
  <p><strong>《智能涌现》</strong>：听说公司对部分业务做了拆分，成立子公司独立运营和对外融资。</p>
  <p><strong>李开复</strong>：这其实很像创新工场run了很久的孵化模式。比如前阵子被报道的“零一绿洲”（零一万物AI游戏子公司）的拆分，这个业务我们也run了几个月，觉得它能够跑起来。</p>
  <p><strong>《智能涌现》</strong>：为什么拆分？</p>
  <p><strong>李开复</strong>：当你的团队非常聚焦在一个垂类，而且这个垂类是你预测是可以做大垂类的时候，他们会更专注，更可能把这个行业做得更深、更透。</p>
  <p>所以相比于在一个想做多行业的团队里面，独立之后能够更专注，也能够接触专有的资源。</p>
  <p><strong>《智能涌现》</strong>：评判业务要不要拆分的标准是什么？</p>
  <p><strong>李开复</strong>：先去找投资人聊，看有没有人愿意投。</p>
  <p>如果盲目地拆分，万一团队自己没办法充分的造血，实际上是没有必要的。</p>
  <p><strong>《智能涌现》</strong>：很少有初创企业一下子同时做这么多业务方向，会分散精力吗？</p>
  <p><strong>李开复</strong>：我们还是希望未来能够实现一个To B的平台。其中有不少中央研发的成本，是由业务线来共同分担的，可能20%花在这条，30%花在另一条，50%做大家通用的工具链等。</p>
  <p>同时，业务跑出来，有时候是因为风口，有时候是因为概念，很难去规划，不同方向得边做边看。当然希望我们今年可以做出几条明星产品线。</p>
  <p><strong>《智能涌现》</strong>：经历这一年半，你对AI创业有怎样的新理解？</p>
  <p><strong>李开复</strong>：要勇于主动调整，看清什么是对的战略路线。创业公司<strong>第一年的打法未必适用于第二年，此时如果盲目坚持一些负担不起的东西，对初创公司来说并不是正确和健康的选择</strong>。</p>
  <p>我们希望我们的未来是有更强的确定性，这样我们也更有信心去达成目标。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_f3ddcf54de0a4d378d21472048da4e3a@5783683_oswg649725oswg1389oswg517_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">欢迎交流！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_8bac857851e6473c87a16c837c9000a3@5783683_oswg141209oswg900oswg296_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p class="img-desc">欢迎关注！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112451739946504</id>
            <title>AI采购代理+设备钱包：万物经济的实现路径</title>
            <link>https://www.36kr.com/p/3112451739946504</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112451739946504</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 11:23:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI采购代理, 数字钱包, 万物经济, AIoT  
<br><br>  
总结: AI采购代理是一种由人工智能驱动的软件系统，能够自主完成在线购买的全流程，并与用户的数字钱包相连，深入理解用户需求。它通过学习用户的偏好和历史记录，搜索并比较可用选项，最终达成交易并处理售后事宜。AI采购代理的崛起与数字钱包的融合，将重塑电子商务体验，推动在线消费的变革。未来，AIoT技术的发展将使得智能设备能够自主参与数据交易，进一步提升采购的智能化和自主化水平。设备钱包在这一过程中扮演着关键角色，促进价值的捕获与交换。 </div>
                        <hr>
                    
                    <p>在前文《2025 AI Agents百家争鸣，2026智能代理+Web3触发万物经济》中，我曾提及智能代理是2025年备受瞩目的热点。其中，AI采购代理是一类值得重点关注的智能代理应用。</p>
  <p><strong>简言之，AI采购代理是一种由人工智能技术驱动的软件系统，能够自主完成在线购买商品或服务的全流程：</strong></p>
  <p>AI采购代理与用户的数字钱包相连，可获取购买所需资金。同时，它通过学习用户的偏好、历史购买记录、预算等数据，深入理解用户需求。</p>
  <p>当用户提出购买特定产品或服务的需求时，AI采购代理会在互联网上全面搜索可用选项，并运用机器学习算法比较不同选项的性价比。</p>
  <p>锁定最优选项后，AI代理会像人类助理一样与卖家进行沟通，讨价还价，力争最优惠的交易条件。</p>
  <p>达成交易后，AI代理从用户的数字钱包中自动完成支付，并持续跟踪物流状态直至用户收货，同时处理售后相关事宜。</p>
  <p>随着时间推移，AI采购代理不断学习，日益精准地把握用户偏好和需求，代替用户做出更加明智的购买决策。</p>
  <p>综上，AI采购代理可视为一种智能化的“自主经济代理人”，专注于以最优性价比满足用户购物需求，提升用户体验。</p>
  <p>相比其他五花八门的AI代理，采购代理的特色是与钱相依相伴。</p>
  <p>同时，我们还需关注到，人工智能的真正风口未来可能并非软件行业，而是硬件行业。</p>
  <p><strong>当AIoT进入2.0“通感智值一体化”阶段，AIoT需要为用户创造更大价值，而这一价值可通过“AI采购代理+设备钱包”的组合，实现多方价值的创造与交换，形成正向循环，进而催生更多设备联网需求。</strong></p>
  <p>对于AI采购代理，迷之相信“颠覆性创新”的木头姐Cathie Wood带着她的团队方舟资本（ARK Invest）率先做出了解读。因此本文将深入剖析方舟资本对AI采购代理的前沿洞察，探讨AIoT与AI采购代理结合将擦出怎样的火花。</p>
  <h2><strong>AI采购代理与数字钱包的融合之道</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_26ec690e7f5749e991c035127b457ccc@000000_oswg138375oswg1080oswg727_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>方舟资本认为，如果将大模型融合到数字钱包中，或许可以孕育“AI采购代理”这一创新方式，重塑电子商务行业。</p>
  <p><strong>AI采购代理作为嵌入数字钱包的智能代理，将产品发现和支付流程无缝融合，使得采购过程从一次点击简化为一次查询。其潜力不仅局限于电子商务领域，更有望扩展至整个在线经济版图。</strong></p>
  <p>方舟资本的研究显示，到2030年，AI代理有望推动全球近9万亿美元的在线支出。这一愿景包括应用层面的AI集成和操作系统层面的AI集成。</p>
  <p>数字钱包整合基于LLM大模型的搜索功能，将从根本上重塑潜在客户开发和电子商务行业。</p>
  <p><strong>采购代理通过整合在线购物流程（搜索、聚合和结账），打造无缝的“一键购买”体验。直观而强大的搜索工具让消费者更快、更准确地找到相关产品，帮助企业提升转化率。</strong></p>
  <p>如上图所示，根据方舟资本对美国用户的调查，现有的数字化工具虽然提高了客户满意度，推动了在线零售平台的增长，但仍有28%的用户对不相关的搜索结果和复杂的结账流程感到不满，18%的购物者因此中途放弃了“购物车”中的商品，创建账户的复杂流程更是劝退了26%的用户。</p>
  <p>随着LLM的不断发展和完善，AI采购代理将越来越擅长个性化产品推荐、价格比较和支付选择，消费者对数字钱包和AI代理的依赖也将与日俱增。</p>
  <p>通过“一次查询即可购买”的革命性体验，购物者只需发出一个指令，即可实现商品的寻找、比较、选择和购买，整个过程高效、无摩擦。</p>
  <p>方舟资本认为，AI采购代理有望将一键购买打造成新的行业标准。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_2e65245c0248464fa28164abc2110ee0@000000_oswg102733oswg1080oswg727_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>注：2018-2023年的数据（紫色实线）是全球支付报告中记录的历史数据；2024-2030年的数据（紫色虚线）是方舟资本对数字钱包支付方式的预测</p>
  <p>总的来说，方舟资本对AI采购代理的洞察令人激动不已。数字钱包整合LLM驱动的搜索功能，将重新定义在线消费体验和价值链。消费者有望摆脱对单一市场的依赖，更多地依靠AI汇总信息、跨多个供应商进行购买。</p>
  <p>未来，LLM支持的采购代理与数字钱包的融合，将为消费者带来将大部分购物体验（从产品发现到结账）托付给AI采购代理的机会。</p>
  <h2><strong>AIoT赋能AI采购代理：开启采购智能化与自主化</strong></h2>
  <p>随着AI采购代理在电子商务领域的崛起，它们与万物经济的融合之路也渐次展开。</p>
  <p><strong>在万物经济时代，智能设备不再仅仅扮演数据的生产者角色，而是能够根据自身需求和目标，自主地参与数据交易。</strong>这种交易可以是设备之间的点对点交易，也可以是设备与其他经济主体之间的交互。而AI智能代理正是实现这一愿景的关键所在。</p>
  <p><strong>事实上，无论是B2C还是B2B场景中的采购，AIoT技术的发展都将为AI采购代理的应用提供更加广阔的舞台。</strong></p>
  <p>通过物联网设备，AI采购代理可以实时掌握库存水平，甚至可以在库存水平较低时自动触发采购订单。这有助于缩短交货时间，降低物资短缺的风险。</p>
  <p>此外，物联网设备还可以监测设备的性能，预测何时需要维护或更换零部件。AI采购代理可以利用这些数据，优化采购目录，管理支出，做出更明智、更迅速的决策。</p>
  <p>AIoT技术不仅可以帮助AI采购代理自动化许多任务，释放出宝贵的时间，让采购专业人员能够专注于更重要的项目；同时，AI采购代理还可以利用物联网数据，提供准确的交付更新和跟踪信息，改善客户服务，提升用户体验。</p>
  <p>然而，要真正实现AI采购代理与万物经济的无缝融合，仍有一些挑战需要克服。为了使智能代理能够自主执行任务，我们需要赋予它们独立的“身份”和自主权。在Web3的世界中，为智能代理注册一个链上身份和链上钱包，是顺理成章的选择。这将使智能代理成为真正的独立个体，拥有自己的财务账户，能够自主地参与经济活动。</p>
  <p><strong>通过赋予智能代理自主交易的能力，我们可以构建一个高度自动化、高效运转的经济系统。</strong></p>
  <p>在这个系统中，智能代理可以根据自身的任务和目标，自主选择交易对象，谈判交易条件，并完成交易过程。这不仅可以大大提高经济活动的效率，还可以促进资源的优化配置，推动商业模式的创新。</p>
  <p>举个例子，假设一台由智能代理控制的智能冰箱检测到鸡蛋、牛奶等日常食品的库存量较低，它可以自主连接到线上超市，比较不同商家的价格和质量，选择最优的供应商，并完成下单和支付的全部流程。这整个过程无需人工干预，完全由智能代理自主完成。类似的场景在万物智联的未来将司空见惯。</p>
  <h2><strong>设备钱包：AI采购代理与万物经济的连接纽带</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_b0e61bc582084b5c807e30d19dee64d9@000000_oswg291115oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随着AIoT技术的不断发展，各种硬件设备中的数字钱包也日益丰富。这些设备钱包不仅承载着物联网的多方价值实现与交换，更是创造设备联网需求的重要驱动力。</p>
  <p>在AI采购代理与万物经济融合的过程中，设备钱包无疑扮演着至关重要的角色。</p>
  <p><strong>在智能时代的企业生态中，垂直市场的物联网设备厂商和应用服务商正在逐步演变为“万物运营商”这一新兴角色。</strong></p>
  <p>当一个物联网企业不再满足于简单地将产品销售给用户，而是在此基础上持续提供多样化的附加服务，不断创造新的服务内容和收入模式时，它就具备了成为“万物运营商”的基本条件。</p>
  <p><strong>随着创新浪潮和数字化转型的深入推进，越来越多的企业意识到，商业模式需要从单纯的商品销售转向提供多元化的服务，即打造XaaS（X as a Service）模式。</strong>这里的“X”可以代表任何形态，如运输即服务、医疗即服务、空间即服务、出行即服务等。服务的定价和收费方式也呈现出多样化的特点，包括按使用量收费、成果报酬、定额制、会员制、动态定价等。</p>
  <p><strong>更进一步，XaaS模式还有可能升级为VNaaS（Value Network as a Service，价值网络即服务）模式。在这种模式下，提供服务的主体从单一企业演变为紧密合作的企业集群。</strong></p>
  <p>与计算机时代线性的企业生态不同，智能时代的企业生态呈现出复杂的网状结构，每个企业都拥有与最终客户互动的触点，有机会提供端到端的服务。</p>
  <p>以制造业为例，从零部件供应商、仓储提供商、运输服务商，到设备制造商、销售渠道方、金融服务企业、设备服务运营商等，各个角色通力协作，为最终客户提供端到端的价值流动网络。</p>
  <p>在这个过程中，AI采购代理和数字钱包的应用，有利于跟踪和计算联网设备提供的价值，促成各方实现收益的合理分配。这种基于价值网络的服务，具有高度的敏捷性和灵活性，构建了一种新型的动态平衡。</p>
  <p>更值得关注的是，尽管单个物联网设备有其控制者或所有者，但当联网设备的数量不断增长，它们作为一个超大规模的协作网络，呈现出显著的公共产品属性。</p>
  <p>当我们在这个由联网设备构成的网络中引入市场机制时，就有可能实现一个去中心化的、以价值交换为基础的设备间大规模协作体系。通过设备钱包，我们可以有效地从设备网络中捕获和交换经济活动的价值，从而为机器经济创造内生的增长动力。</p>
  <p>总而言之，AI采购代理与万物经济的共生演进，离不开设备钱包这一关键纽带。<strong>随着AIoT技术的不断进步，设备钱包将在价值捕获、价值交换和需求创造等方面发挥越来越重要的作用。</strong></p>
  <h2><strong>写在最后</strong></h2>
  <p>AI采购代理作为人工智能技术在电子商务领域的创新应用，正在重塑我们的购物体验和商业模式。它与数字钱包的融合，不仅提升了购物的便捷性和智能化水平，更为万物经济时代的到来奠定了基础。</p>
  <p>随着AIoT技术的不断进步，AI采购代理将与智能设备形成更加紧密的联动，通过设备钱包实现多方价值的捕获和交换。这种共生演进的趋势，将加速企业生态的变革，推动XaaS和VNaaS模式的崛起，最终实现基于价值交换的大规模协作经济。</p>
  <p>参考资料：</p>
  <p>1. Armed With Purchasing Agents， Digital Wallets Could Turn One-Click Checkout Into One-Query Purchases，来源：ARK Invest</p>
  <p>2. 如何构建智能时代的新安迪比尔定律？【物女心经】，来源：物联网智库</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MTM5ODQyMA==&amp;mid=2651321748&amp;idx=1&amp;sn=6c081552ddf2e317af7000eabff52836&amp;chksm=bc77055cdbe540352c3fadffa534b7c4ba61c40a7c9fab4a768aa9ee1cd9b04fbb3ba315d235&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“物联网智库”（ID：iot101）</a>，作者：彭昭，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112496219590407</id>
            <title>炸裂：CES成芯片巨头 “斗秀场”，新品巅峰对决</title>
            <link>https://www.36kr.com/p/3112496219590407</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112496219590407</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 11:13:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: CES 2025, 英伟达, 高通, 英特尔, AMD  
<br><br>  
总结: CES 2025将在拉斯维加斯举行，科技公司如英伟达、高通、英特尔和AMD将展示新技术和产品。英伟达推出了RTX 50系列显卡，强调其强大的算力和硬件升级。高通发布了Snapdragon X AI芯片，旨在以低成本为PC提供AI运算能力。英特尔则推出了首款18A制程芯片，计划继续发展显卡业务。AMD展示了多款新处理器和显卡，进一步巩固其在市场中的地位。 </div>
                        <hr>
                    
                    <p>CES一直被誉为“科技春晚”，是全球科技创新和消费电子行业的风向标。今年的国际消费类电子产品展览会（CES 2025）将在美国拉斯维加斯拉开帷幕。&nbsp;</p>
  <p>整个科技圈都在翘首以盼。&nbsp;</p>
  <p>AMD 磨刀霍霍，传闻中的新技术、新显卡惊艳全场；英伟达也毫不示弱，准备凭借新一代 GPU 在光影渲染与智能计算领域再攀高峰；英特尔则聚焦于 CPU 升级，力求让酷睿 Ultra 200H 处理器成为移动端新宠。这场盛会究竟会碰撞出怎样的科技火花？让我们抢先一探究竟。&nbsp;</p>
  <h2><strong>&nbsp;01 英伟达：RTX Blackwell 系列正式推出</strong></h2>
  <p>在CES开幕前夕，美国银行将英伟达继续列为该行的“首选”，将其评级为“买入”，目标价为190美元。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3203860e4b8a4b408663353b02c07dc6@000000_oswg132030oswg831oswg384_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今天，老黄穿着皮衣再次登场。</p>
  <p>首先带来的是RTX 50系列Blackwell显卡。规格方面，RTX 5090 显卡，拥有 920 亿个晶体管，可提供超 3,352 TOPS 算力，支持 DLSS 4。</p>
  <p>RTX 5090搭载GB202 GPU，内建21,760个CUDA核心，<strong>是第一款超过20,000个内核的 GeForce GPU。</strong>搭配512bit位宽的32GB GDDR7显存，TDP功耗575W。3个DP 2.1a接口，1个HDMI 2.1接口。</p>
  <p>这一代RTX 50系列带来了重大的硬件升级，包括 PCle 5.0接口、GDDR7内存、DisplayPort 2.1a接口，全系采用16 针电源接口。</p>
  <p><strong>次旗舰RTX 5080则拥有10752个CUDA核心，</strong>搭载256bit位宽的16GB GDDR7显存（速率比5090更快，达到了30Gbps），TDP功耗360W。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ec88b5d8552d423f98e060a236d884ab@000000_oswg45953oswg830oswg629_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>价格分别为：<strong>RTX 5090售价1999美元、RTX 5080 售价999美元、RTX 5070 Ti售价749美元，RTX 5070售价549美元。</strong>其中，RTX 5080将于1月21日率先上市<strong>。RTX 5090D（国内特供版）售价16499元起，RTX 5080售价8299元起。</strong></p>
  <p>并且黄仁勋还特意提到了RTX 4090，去年的首发价格为1599美元，而如今RTX 5070用549美元，就可以提供和4090相媲美的性能。（以RTX 5090售价1999美元的价格来看，折合人民币是1.46万元左右）&nbsp;</p>
  <p>黄仁勋透露，Blackwell系统的奇迹在于其前所未有的规模，Blackwell芯片是人类历史上最大的单芯片；该系统的最终目标是增强我们在技术和创新方面的能力和体验。&nbsp;</p>
  <p>创建NVLink的根本目的是围绕主动型人工智能（Agentic AI），它展现了延长测试时间和提升客户互动的完美模型。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_1ca44e933a724f789ae8ebdd87b49cf0@000000_oswg248024oswg831oswg384_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>英伟达的目标是创建一个巨型芯片，该芯片将使用72个Blackwell GPU或144个芯片，超越世界上最快的超级计算机的能力</strong>。&nbsp;</p>
  <p>黄仁勋透露，英伟达拥有多种（计算）系统，如NBLink 36x2和NBLink 72x1，能够满足全球几乎所有数据中心的需求，<strong>目前在约45家工厂生产。</strong></p>
  <p>据现场消息，<strong>Blackwell目前已全面投入生产，</strong>所有主要云服务提供商均已建立系统，提供约200种不同型号和配置，来自约15家硬件制造商。Blackwell相比于前一代在性能上实现了四倍的提升。&nbsp;</p>
  <p>值得注意的是，在今日英伟达公布的人形机器人领域开展合作的厂商中，包括<strong>国内厂商宇树科技、小鹏。</strong></p>
  <h2><strong>&nbsp;02 高通：新款AI芯片，搭载PC售价低至600美元</strong></h2>
  <p>智能手机是高通最主要的收入来源，尤其是在高端手机市场中，高通的Snapdragon系列芯片占据了主导地位。然而，随着智能手机市场逐渐饱和，高通面临增长放缓的挑战。&nbsp;</p>
  <p>此前，高通展示了骁龙X系列持续的发展势头，目前已有超过60款PC设计量产或在开发中，预计到2026年将超过100款。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_840a0edaacfd4b3f8b06ede154513e41@000000_oswg101535oswg830oswg462_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_13972c71e57742ecb7c1583315ea6c87@000000_oswg295701oswg829oswg464_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在CES上，高通宣布推出新的人工智能（AI）芯片Snapdragon X，旨在为个人电脑（PC）提供强大的运算能力，使其能够运行最新的AI软件，让更多用户能够以较低的成本享受到AI赋能的PC体验。&nbsp;</p>
  <p>据介绍，Snapdragon X采用4纳米制程工艺制造，配备高通的Oryon CPU，拥有8个核心，最高主频可达3GHz，为下一代PC提供了强大的计算性能。&nbsp;</p>
  <p>高通表示，Snapdragon X将支持微软Copilot+软件。Copilot+是微软基于生成式人工智能开发的AI助手，能够帮助用户完成复杂任务。&nbsp;</p>
  <p>此外，包括<strong>宏碁、华硕、戴尔科技和联想集团在内的PC制造商将采用这款AI芯片，且搭载Snapdragon X的PC的售价预计将低至600美元，产品预计在2025年初上市</strong>，这意味着用户将很快能够体验到。&nbsp;</p>
  <p>除了新的笔记本电脑，高通的客户还将提供基于Snapdragon X的新型小型台式电脑。此外，高通还将通过Snapdragon X Elite和Snapdragon X Plus等高端芯片，进一步满足高性能设备的需求。&nbsp;</p>
  <p>高通强调其芯片在提供长时间电池续航的同时，也能保持较高的性能水平，特别是在移动设备领域的优势。&nbsp;</p>
  <h2><strong>&nbsp;03 英特尔：发布首款Intel 18A制程芯片、不会放弃显卡业务</strong></h2>
  <p>英特尔刚刚经历了自 1971 年上市以来最糟糕的一年，所以在2025 年国际消费电子展 （CES）上发布新芯片，希望能够扭转公司的命运。&nbsp;</p>
  <p>这场发布会是自英特尔CEO帕特·基辛格离任后最大的产品发布会。在1月6日的英特尔CES 2025演讲中，英特尔临时联席CEO Michelle Johnston宣布，<strong>首款Intel 18A制程芯片——英特尔Panther Lake处理器将于2025年下半年发布。</strong></p>
  <p>Johnston还展示了PantherLake芯片的样品，并表示芯片已经在测试中，她对18A非常满意。Johnston宣布，Intel 18A制程将于“今年晚些时候发布”。她表示，“英特尔会在2025年及以后继续增强AIPC产品组合，向客户提供领先的英特尔18A产品样品，并在2025年下半年量产”。&nbsp;</p>
  <p>以下是本次发布的新芯片的完整列表（英特尔去年年底发布了其中一些芯片）：&nbsp;</p>
  <p>Core Ultra 200V系列处理器（原代号Lunar Lake）</p>
  <p>Core Ultra 200H系列处理器（原代号Arrow Lake H）</p>
  <p>Core Ultra 200HX系列处理器（原代号Arrow Lake HX）</p>
  <p>Core Ultra 200S系列处理器（原代号Arrow Lake S）</p>
  <p>Core Ultra 200U系列处理器（原代号Arrow Lake U）</p>
  <p>Core 200S系列处理器（原代号Bartlett Lake S）</p>
  <p>Core 200H系列处理器（原代号Raptor Lake H Refresh）</p>
  <p>酷睿100U系列处理器（原代号Raptor Lake U Refresh）</p>
  <p>Core 3 处理器和英特尔处理器（原代号 Twin Lake）</p>
  <p>英特尔借CES 2025之机推出了备受期待的用于<strong>笔记本电脑的“Arrow Lake”Core Ultra 200U、200H 和 200HX 芯片系列</strong>，加入了“ Lunar Lake ”Core Ultra 200V 系列。&nbsp;</p>
  <p><strong>200U 系列 Core Ultra 芯片将驱动比 200V 更高效的系统，而 200H 和 200HX 分别适用于更高性能和最大功率的笔记本电脑。</strong>所有这些新推出的芯片，无论是注重性能的H系列和HX系列，还是注重效率的U系列，均未将人工智能输出作为主要考量因素。而V系列则凭借其每秒48万亿次运算（TOPS）的性能指标，在此特定性能领域占据领先地位。&nbsp;</p>
  <p>同时英特尔也推出了用于<strong>商务笔记本电脑的 Arrow Lake 处理器。</strong></p>
  <p><strong>Lunar Lake 将顶级 AI 带入办公室</strong></p>
  <p>Lunar Lake 处理器拥有英特尔第二代 AI 优化神经处理单元 (NPU)，可以更高效地执行 AI 软件任务。这些 vPro 芯片配备了与消费级系统相同的重新设计内核、下一代英特尔 Arc 显卡和集成英特尔Wi-Fi 7 (5 Gig)。&nbsp;</p>
  <p>新 Wi-Fi 比 Wi-Fi 6 快五倍（高达 5.8Gbps），延迟降低 60%，可实现更好的视频会议。这款 Wi-Fi 芯片使用基于 AI 的网络优化软件，在 2.4GHz、5GHz 和 6GHz 频率下工作时保持正常运行时间。&nbsp;</p>
  <p>此外，该芯片还支持 40Gbps Thunderbolt 4，比 USB 3.2（10Gbps）快四倍。这使英特尔 Thunderbolt Share 能够实现 PC 到 PC 的无缝数据共享，并连接双 4K 显示器或单个 8K 显示器。英特尔还通过蓝牙添加了带有 Microsoft Teams 认证的蓝牙 5.4，以增强安全性。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_f8b04c96feb849d69c9c4b5f52ad63b0@000000_oswg405999oswg831oswg468_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英特尔的 Core Ultra 200 系列处理器允许第三方安全软件使用 NPU，使其能够更有效地检测勒索软件和加密劫持等威胁。Core Ultra 200V 还支持 Microsoft Pluton 安全处理器，为安全提供坚实的基础，旨在帮助企业更加自信地开展网络安全措施。&nbsp;</p>
  <p>英特尔还推动了由 200 多家独立软件供应商组成的庞大生态系统，这些供应商开发针对其平台量身定制的商业应用程序和服务。知名公司包括 Adobe、Citrix、Power BI、Webex 和 Microsoft。其他供应商利用 AI 实现各种业务应用，从数据可视化和分析到视频编辑和媒体创作。&nbsp;</p>
  <p>目前英特尔为其 2025 系列中的多款处理器提供 vPro 安全措施，从 200V 系列芯片到适用于通用工作机器和高功率移动工作站的 U、H 和 HX 系列选项。Arrow Lake Core Ultra 200 系列芯片也配备了集成于主板的 NPU 硬件，尽管其性能不及 Lunar Lake 200V 处理器中的相应硬件。&nbsp;</p>
  <p><strong>2025年推出其余的Core Ultra 200系列芯片。</strong>随着英特尔将 Lunar Lake vPro 引入办公室，该公司的 Lunar Lake 和新的 Arrow Lake Core Ultra 200 系列处理器将适合消费者笔记本电脑。&nbsp;</p>
  <p><strong>轻薄笔记本电脑：Core Ultra 200U 系列</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_5431fe6a89504075bdc0fa2228573e2d@000000_oswg231009oswg831oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此类笔记本电脑专为忙碌的工作者和主流消费者而设计。&nbsp;</p>
  <p>一般来说，OEM 选择英特尔时，他们通常会采用新的英特尔酷睿Ultra 200U 芯片。这些 U 系列芯片可改善日常任务的处理能力并增强英特尔显卡，同时通过低功耗高效 (LPE) 内核以及英特尔标准的高性能 (P) 和高效 (E) 内核来提高效率。&nbsp;</p>
  <p>整个产品线共有 12 个核心，包括两个 P 核心（最高 5.3GHz）、八个 E 核心和两个 LPE 核心。这些将是该处理器系列的四个 CPU 选项（从 Core Ultra 5 到 Core Ultra 7）的共同特征。&nbsp;</p>
  <p><strong>英特尔的目标是通过 Core Ultra 200U 系列芯片，让 PC 制造商能够实现真正的全天电池续航。</strong>根据英特尔使用 UL Procyon 电池寿命基准测试和 3x3 Microsoft Teams 会议场景进行的测试，新配备的笔记本电脑在基本生产力模式下可使用长达 20 小时，在 Microsoft Teams 会议模式下可使用长达 10 小时。&nbsp;</p>
  <p>虽然你可以在这些芯片上完成一些 AI 工作，但它们的<strong>&nbsp;13-TOPS NPU </strong>并不完全达到Copilot+ PC所需要 45 NPU TOPS 等级。&nbsp;</p>
  <p><strong>高级超便携式电脑：原装 Core Ultra 200V 系列</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_677c5b1c797f41239d509d922109c4d0@000000_oswg338923oswg831oswg863_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此类笔记本电脑适合知识工作者和专业消费者；有些笔记本电脑自 2024 年底开始发售，内置 Lunar Lake 200V 系列芯片。在这类笔记本电脑上，可以获得能够实现高达 5.1GHz 涡轮频率的 P 核和达到 3.7GHz 的 LPE 核。&nbsp;</p>
  <p>英特尔还将其最新的英特尔 Arc 集成显卡升级到了 200V。这款集成图形处理器 (IGP) 包含八个 Xe 核心（最高 2.05GHz），带有 64 个矢量引擎、8MB 缓存，并且能够利用片上系统内存模块作为额外的视频内存资源。它还具有 AI 升级和光线追踪引擎，以提高保真度。（许多这些图形功能也继续通过英特尔的 H 系列和 HX 系列 Arrow Lake 芯片发挥作用和发展）&nbsp;</p>
  <p>这些是英特尔 2025 年堆栈中用于本地 AI 工作的最先进芯片，<strong>起始 NPU TOPS 为 48。</strong>这使得 OEM 能够基于这些芯片指定兼容 Copilot+ PC 的笔记本电脑。&nbsp;</p>
  <p><strong>高性能笔记本电脑：Core Ultra 200H 系列</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_8cb103f9ae0540139d77895235349a75@000000_oswg263308oswg831oswg823_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此类笔记本电脑专为办公室内外的高级用户而设计。&nbsp;</p>
  <p>处理器具有更多重新设计的内核（从 14 到 16 个不等）、更高电压的 Intel Arc 显卡和可选的Thunderbolt 5连接，速度是上一代的两倍。它们提供卓越的性能、增强的图形处理能力和更快的连接能力，可完成要求苛刻的任务。然而，与 U 系列一样，它们不太注重 AI 性能<strong>，NPU 速度仅为 11 TOPS</strong>，因此配备 H 系列芯片的笔记本电脑将不包含在 Copilot+ PC 计划中。&nbsp;</p>
  <p>对于这些高速笔记本电脑，英特尔酷睿超 200H 系列是游戏的代名词。该系列从酷睿超 5 225H 处理器开始，该处理器包含四个 P 核（最高 4.9GHz）、八个 E 核、两个 LPE 核和八个 Xe 图形核心（最高 2.2GHz）。最后是功能强大的酷睿超 9 285H，该处理器包含六个 P 核（最高 5.4GHz）、八个 E 核、两个 LPE 核和八个 Xe 核（最高 2.35GHz），可用于高强度工作或游戏。&nbsp;</p>
  <p><strong>这些芯片特别具有耐力游戏模式，该模式使用英特尔的动态调节技术根据系统温度调整性能和功耗，以最大限度地延长游戏电池寿命。</strong></p>
  <p><strong>内容创作者、游戏本、工作站：Core Ultra 200HX 系列</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_dfbd7a33dc864246adfe88d0822812a8@000000_oswg273363oswg831oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此类笔记本电脑不仅适合计算需求最高的技术创作者，也适合顶级 PC 游戏体验。具有更多重新设计的 CPU 核心（完全放弃 LPE 核心）、对绝对最佳独立显卡的支持以及 Thunderbolt 5，可为要求苛刻的工作负载和游戏提供顶级性能和图形功能。&nbsp;</p>
  <p>额定功率高达 55 瓦，它们不适用于轻薄便携机器，而适用于工程和 3D 渲染所需的强大数字计算器，为了获得峰值处理和图形处理能力，较厚的设计和更高的价格是可以接受的权衡。&nbsp;</p>
  <p>这正是英特尔 Core Ultra 200HX 系列的用武之地。它包括更基本的 Core Ultra 5 235HX具有六个 P 核（最高 5.1GHz）、八个 E 核（最高 2.9GHz）和三个 Xe 核（最高 1.8GHz），以及 Core Ultra 9 285HX具有八个 P 核（最高 5.5GHz）、16 个 E 核（最高 2.8GHz）和四个 Xe 核（最高 2GHz）。&nbsp;</p>
  <p><strong>这些芯片可提供高达 13 个 NPU TOPS</strong>，比英特尔大多数 Arrow Lake 产品线都要多，但这还不足以被视为 Copilot+ PC。英特尔的重点是其他性能领域。&nbsp;</p>
  <p>从本月开始，Arrow Lake 处理器将应用于各大品牌各种型号的商务级和主流笔记本电脑，并将持续发布到 2025 年第一季度。&nbsp;</p>
  <p><strong>不会放弃显卡业务</strong></p>
  <p><strong>英特尔已经明确表示，不会关闭其独立显卡业务，</strong>即便英伟达在这个领域近乎垄断的存在。&nbsp;</p>
  <p>英特尔新CEO Michelle Johnston Holthaus在CES 2025主题演讲中向听众表示：“我们非常重视独立显卡市场，并将继续朝这个方向进行战略投资。”关于独立显卡业务会不会被关闭，这是她经常遇到的问题。&nbsp;</p>
  <p>此外，这位新CEO还对Lunar Lake芯片大加赞赏，并称2024年“英特尔真正重新确立自己在人工智能PC市场领导者地位的一年，因为它在性能和电池续航时间方面具有优势。”&nbsp;</p>
  <p><strong>英特尔未来的“战略投资”也可能是在人工智能领域，而</strong>不是游戏领域，这与AMD和NVIDIA最近将工作重点重新放在人工智能的巨大商机上的做法类似。&nbsp;</p>
  <p>不过，至少还有一款游戏显卡即将推出。Holthaus表示，英特尔将在下周推出其下一款已经宣布的B570 GPU，这款显卡比B580更经济实惠。&nbsp;</p>
  <h2><strong>&nbsp;04 AMD：多款锐龙新品炸场，怪兽级CPU诞生</strong></h2>
  <p>AMD 在今年的CES上势头强劲。&nbsp;</p>
  <p>2024 年第三季度，AMD占据了台式机 CPU 领域的 28.7% 份额，比去年同期增长了 9.6 个百分点。在移动领域，截至去年第三季度，AMD 占据了 22.3% 的芯片市场份额，比上一财年增长了 2.8 个百分点。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_1b7eb89bb9eb484bb2c53a644fc0fca4@000000_oswg186847oswg831oswg469_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在CES 2025正式到来之前举办新品发布会，AMD向消费者推出海量的终端产品，包括旗舰级别的锐龙9 9950X3D，锐龙AI Max、Radeon RX 9000系显卡等产品，此外AMD也发布了其余不同定位的锐龙AI处理器，进一步丰富了家族的产品。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_09ccd68583e04999873fa037c1653bca@000000_oswg113820oswg830oswg414_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>AMD的 2025 战略积极进取且多管齐下，从 Ryzen 9 9950X3D 开始。9950X3D 面向“游戏玩家和创作者”，拥有 16 个基于 AMD Zen 5 架构的内核，主频高达 5.7GHz。根据该公司的基准测试，与 AMD 的 7950X3D 相比，9950X3D 在《霍格沃茨遗产》和《星际争霸》等热门游戏中的平均速度提高了 8%。&nbsp;</p>
  <p><strong>9950X3D 和 Ryzen 9 9900X3D将于 2025 年第一季度左右出货。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_9870f72d553f47b189db50d16558e876@000000_oswg82229oswg831oswg305_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为了补充 Ryzen 9 9950X3D 和 9900X3D，AMD 还宣布推出<strong>针对中端笔记本电脑和超便携电脑的全新“Fire Range”系列芯片。</strong>该系列芯片将于 2025 年上半年推出，包括 Ryzen 9 9850HX、9955HX 和 9955HX3D，提供 12 到 16 个内核，最高主频在 5.2GHz 到 5.4GHz 之间。&nbsp;</p>
  <p>值得注意的是，Fire Range 芯片的功耗约为 54 W，不到 9950X3D（170 W）功率要求的一半。&nbsp;</p>
  <p>除了上述这些处理器之外，对于游戏玩家来说还有一款处理器值得特别关注，那就是代号为<strong>“Strix Halo”的处理器</strong>，这款处理器拥有超乎寻常的GPU规格，在内置集显性能上已经能够达到主流移动显卡的水平，在CES 2025上，AMD也正式推出了这款处理器，也即锐龙AI MAX和锐龙AI MAX Pro系列处理器。&nbsp;</p>
  <p><strong>AI PC芯片</strong></p>
  <p>为了支持下一代Copilot+ PC（具有 AI 加速 Windows 11 功能的笔记本电脑和紧凑型台式机），AMD 推出了全新和升级的处理器系列：<strong>Ryzen AI 300 系列和 Ryzen AI Max 系列。</strong></p>
  <p>该系列的所有芯片都配有专用的神经处理单元 (NPU)，以加速某些 AI 工作负载，例如运行文本摘要语言模型或 Windows 11 的 AI 图像编辑器。&nbsp;</p>
  <p>Ryzen 300 系列芯片将于 2025 年第一季度或者第二季度上市，包含 6 到 8 个内核，主频高达 5GHz，在最佳情况下可提供24 小时以上的电池续航时间。有四个 SKU：Ryzen AI 7 350、Ryzen AI 5 340、Ryzen AI 7 Pro 350 和 Ryzen AI 5 Pro 340。&nbsp;</p>
  <p><strong>Ryzen AI Max是 AMD 为 Copilot+ PC 提供的旗舰产品。</strong>AMD锐龙AI MAX处理器最高拥有16个Zen 5架构CPU核心，最高40个单元的RDNA 3.5 GPU核心，50TOPS的AI算力，此外带宽也将达到256GB/s，可以说是目前性能最为出色的APU。&nbsp;</p>
  <p>得益于极其强悍的GPU，旗舰AMD锐龙AI Max+395处理器与酷睿Ultra 9 288V相比，CPU性能领先了2.6倍，而GPU性能领先了140%，即使面对苹果的M4 Pro处理器也是丝毫不怵，在AI性能上，55W的AMD锐龙AI Max+395处理器甚至可以跟台式机中450W的RTX 4090掰手腕，功耗最多低了87%，同时也<strong>是世界上首款能够运行70B参数大模型的AI PC处理器。</strong></p>
  <p><strong>惠普和华硕都将推出搭载AMD锐龙AI MAX处理器的产品</strong>，包括mini工作站和ROG Flow Z13等，都能带来极致的性能。&nbsp;</p>
  <p>为了瞄准更经济实惠的“主流”设备，<strong>AMD 还推出了新款 Ryzen 200 系列芯片</strong>。这些处理器（大多数都配备 NPU）拥有 6 到 8 个内核，主频高达 5.2GHz，计划于 2025 年第二季度推出。&nbsp;</p>
  <p><strong>掌机市场</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_56d57f0961f146199862c82b03b0d746@000000_oswg153148oswg831oswg470_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Valve 的 Steam Deck 等手持式 PC 仍然是 AMD 的主要增长领域。为此，该芯片制造商宣布推出 Ryzen Z2 系列的新处理器，该系列适用于轻量级和以游戏为中心的外形。&nbsp;</p>
  <p>有四核 Ryzen Z2 Go（最高主频 4.3GHz）和 12 个显卡核心，还有八核 Ryzen Z2 Extreme（最高主频 5Ghz）和 16 个显卡核心。它们加入了八核 Ryzen Z2，后者最高主频 5.1GHz，并配备 12 个显卡核心。<strong>所有三款 Ryzen Z2 SKU 将于 2025 年第一季度上市。</strong></p>
  <p><strong>显卡</strong></p>
  <p>最后，AMD 发布了其下一组独立的桌面 GPU：Radeon RX 9070 XT 和 Radeon RX 9070。它们基于该公司的 RDNA 4 架构，基于4nm工艺打造。AMD表示该架构具有改进的光线追踪性能、更好的媒体编码质量和改进的 AI 加速。<strong>RX 9070 XT 和 RX 9070 显卡将于 2025 年第一季度由宏碁、华硕、技嘉和讯景等制造商上市。</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247785350&amp;idx=1&amp;sn=c04537fb051d791da81b6b6bfc75609f&amp;chksm=c084c687b9b308fcda4e028ad5303920137c8447ba0b61733d29d5772f235271c66b3d1b00d8&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：九林，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112442008325893</id>
            <title>投资造火箭，丰田也想上天</title>
            <link>https://www.36kr.com/p/3112442008325893</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112442008325893</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 11:01:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 丰田, 火箭, 投资, 太空  
<br><br>  
总结: 丰田在CES上宣布将投资开发轨道火箭，并通过其子公司“Woven by Toyota”向日本初创公司Interstellar Technologies Inc投资70亿日元。丰田章男表示，未来出行不应仅限于地球，反映出车企对太空探索的兴趣。Interstellar Technologies成立于2013年，已成功发射多次小型火箭，但仍在开发更大规模的液体轨道火箭。丰田希望利用其汽车生产经验与该公司合作，降低发射成本并推动火箭量产。此外，丰田还在进行“Woven City”项目，计划在未来城市中测试新技术。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_11b38c57dde34615993e1ced75f88b28@000000_oswg928332oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <blockquote>
   <p><strong>不让马斯克吃独食‍‍‍‍‍‍‍</strong></p>
  </blockquote>
  <p>丰田也要投资造火箭了。&nbsp;</p>
  <p>在拉斯维加斯消费电子展CES上，丰田举办了一场新闻发布会，丰田章男亲自站台，释放出了一个重要信号—— <strong>丰田正在探索轨道火箭的开发和生产</strong>。&nbsp;</p>
  <p>同时还通过其移动技术子公司“Woven by Toyota”，准备花 <strong>70亿日元</strong>（折合人民币3.2亿），投资一家开发卫星运载火箭的日本太空初创公司 <strong>Interstellar Technologies Inc</strong>。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0cb893b7afb946d39a102865306cce4f@000000_oswg724261oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用丰田章男的话说， <strong>未来出行不应只局限于地球，或只局限于一家汽车公司</strong>。&nbsp;</p>
  <p>这个说法，和马斯克的“多行星物种”不谋而合，毕竟马斯克的终极梦想就是将人类送去火星，在马斯克的商业帝国中，SpaceX的地位仅次于特斯拉，SpaceX更是在今年垄断了90%的发射载荷。&nbsp;</p>
  <p>其实不止丰田，随着智能化网联战场的白热化，不少车企都把钱投向了太空， 看来地球已经满足不了这些车企了。&nbsp;</p>
  <h2><strong>日本版SpaceX？</strong></h2>
  <p>丰田章男不是随便说说，这70亿日元将在Interstellar Technologies F轮融资首阶段投入。&nbsp;</p>
  <p>不过，丰田投资的这家Interstellar Technologies（星际技术）公司说起来有点意思。&nbsp;</p>
  <p>这是一家正儿八经的日本火箭初创企业，创立于 <strong>2013年</strong>，日本全国的航天爱好者和科技工作者募捐资金组建，然后由日本知名互联网公司Livedoor创始人堀江贵文成立，不过其核心研发团队最早可以追溯到1997年成立的一个火箭爱好者组织。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_c97423f660ff4e8ca9a8a4d0762a865d@000000_oswg72155oswg1080oswg674_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2019年，这家公司就成功发射了 <strong>日本首枚飞跃100公里卡门线</strong>（航天界定义的太空界线）的民营火箭 <strong>“MOMO”3号机</strong>，但当时并没有有效载荷，只搭载了20kg的实验设备，用于测定重力等数据。&nbsp;</p>
  <p>从2017年的首次发射到现在，Interstellar Technologies一共进行了7次小型亚轨道MOMO火箭的发射，但其中 <strong>成功的只有三次</strong>，而且尚未在轨道上部署任何卫星。&nbsp;</p>
  <p>由于 “MOMO” 为小型火箭，可进行的实验十分有限。因此Interstellar Technologies还在开发一款小型液体轨道火箭Zero，设计用于将100公斤重的物体发射到至500至700千米外的太阳同步轨道，比如运载航天器。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_5e74627d8a774feb886c01215121da26@000000_oswg306154oswg753oswg425_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>本来打算在2020年首射，2023年实现商用化的计划，如今也已经拖到了2025年。&nbsp;</p>
  <p>一句话总结—— <strong>有实力，但不多</strong>。&nbsp;</p>
  <p>不过丰田投资这家公司并不是病急乱投医，在日本，自研火箭发射还仍是一片巨大的蓝海，2023年，世界卫星发射次数为2901次，比10年前增加约14倍，而同年日本火箭发射成功次数仅为2次。&nbsp;</p>
  <p>最关键的是，这家公司还有相当突出的一点，发射成本极低，根据此前星际技术公司透露，每次发射费用不到5000万日元，仅相当于44万美元，这个金额在火箭发射方面可以说是相当低了。&nbsp;</p>
  <p>而且丰田表示，希望利用能其在大规模生产汽车方面的经验，与星际技术公司合作生产火箭，不过，丰田章男没有透露任何细节，只是展示了火箭的效果图。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_968288bf9f554d3791377ca4c0a7b53a@000000_oswg471132oswg1080oswg599_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其实这不是丰田第一次投资火箭类的太空事业。&nbsp;</p>
  <p>早在2019年，丰田就宣布发展太空计划，建造可回收火箭和实现月球计划，帮助人类探索月球开发新能源。&nbsp;</p>
  <p>到了2021年，丰田联合3家日本大型银行三菱日联银行、三井住友银行、瑞穗银行将共同向一支由东京一家投资咨询公司Sparx设立的基金出资 <strong>82亿日元</strong>。&nbsp;</p>
  <p>这个基金主要为太空产业相关的人力和技术发展领域提供资金支持，还打算吸引其他投资者，将资金规模推升至150亿日元，在选择具体对象时，还会接受日本宇宙航空研究开发机构（JAXA）的建议。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_e65bc36f686b495e921e415fd2e82e8a@000000_oswg421807oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除了火箭，丰田还与日本宇宙航空研究开发机构（JAXA）合作，共同打造一款可在月球表面行驶的月球车，为此，丰田还成立了一个名为“月球勘探机动工作组”(Lunar Exploration Mobility Works)的新部门。&nbsp;</p>
  <p>这款车被称为“ <strong>月球巡航者</strong>”，预计将于2032年由SpaceX运送到月球，长约两辆小型巴士并排的大小，可容纳两名宇航员在加压环境中工作，紧急情况下能够容纳四人。计划采用氢动力系统，续航里程高达6200英里（约10000公里），届时NASA和JAXA的宇航员都将能够驾驶这款车。&nbsp;</p>
  <h2><strong>&nbsp;把钱花在天上</strong></h2>
  <p>车企造火箭，听起来有点天方夜谭，但实际上在商用火箭圈不算是什么新鲜事。&nbsp;</p>
  <p>上世纪60年代的“阿波罗”登月计划中， <strong>克莱斯勒汽车</strong>公司就曾制造过土星IB一级及其8台液氧煤油主发动机，后来的土星5登月火箭的很多技术，就是来源于土星IB运载火箭。&nbsp;</p>
  <p>通用也早早地参与了NASA的阿波罗月球计划，开发、测试、集成和生产了阿波罗系列的惯性制导和导航系统。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_71e6e7c658d646839b0e9ce7654ba62c@000000_oswg992219oswg1080oswg735_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>特别是近几年来，很多车企都已不再满足在地球上玩儿，想和太空沾沾边。据不完全统计，本田、通用、奥迪、吉利等车企或品牌也先后在不同的技术领域发力太空竞争。&nbsp;</p>
  <p>比如同为日本车企的 <strong>本田</strong>，早在2019年就已经成立了火箭等太空专业开发团队，进行发动机的试制、敲定商业化的详细计划。&nbsp;</p>
  <p>2021年，本田正式宣布它正在开发一种可部分重复使用的火箭，以发射小型卫星，并于今后6年内向研发投入5万亿日元，在2030年之前完成试飞发射。&nbsp;</p>
  <p>国内，吉利更是继 <strong>特斯拉之后，全球第二家造汽车加卫星的企业</strong>，建设运营“吉利未来出行星座”，截至2024年10月，吉利在轨卫星已经达到30颗，完成3个轨道面部署，可实现24小时覆盖全球90%区域。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_4d618b2e1a9c423eb0439181469b2a17@000000_oswg515384oswg768oswg512_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>车企将目光瞄向太空，除了马斯克造火箭的催熟外，更主要的还是因为航天技术与汽车技术在某些方面还是互通的。&nbsp;</p>
  <p>现在很多汽车技术都是源自航空航天，譬如航空座舱、轻量化技术，汽车上普遍采用的铝材以及碳纤维等材料，早先就是用于降低飞船重量，而HUD抬头显示系统，也是为了不分散宇航员注意力而发明，还有空气动力学等等。&nbsp;</p>
  <p>另外，在如今智能网联化的浪潮下，未来出行势必会成为卫星互联网的应用场景之一，而且有不少车企这么干了，比如吉利还有比亚迪。&nbsp;</p>
  <p>海外知名研究公司Strategy Analytics的汽车互联出行主管罗杰·兰考特（Roger Lanctot）曾说过：“ <strong>汽车制造商正在向太空发出汽车互联方面的求助信号</strong>。”&nbsp;</p>
  <p>不过，丰田打算投资火箭发射还有别的心思，为了其打造的未来城市 <strong>“Woven City”的电信网络</strong>做铺垫。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_d54ed3a47d5a4fd386c59f9e692c8709@000000_oswg1535977oswg1080oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>根据Interstellar Technologies的声明，作为这次资本与业务合作的一部分，Woven将派遣一名董事加入公司董事会。同时，Woven还将在供应链优化和公司治理方面提供支持，为确保火箭的顺利量产。&nbsp;</p>
  <p>丰田的Woven City（编织城市）项目，最早是在2020年的CES上首次提出这一概念，该项目位于日本富士山脚下一块175英亩的土地上， <strong>耗资100亿美元</strong>。&nbsp;</p>
  <p>之所以叫这个名字，是指丰田将三种不同类型的街道或小路编织在一起，每种街道或小路供特定类型的用户使用。其中一条仅供速度较快的车辆通行。第二条街道则混合了自行车、滑板车等低速个人代步工具和行人，第三条道路将是一条类似公园的长廊，仅供行人使用。&nbsp;</p>
  <p>按照丰田的说法，这将是一个“未来城市的原型”，在这里，丰田可以对 <strong>自动驾驶汽车、创新的街道设计、智能家居技术、机器人技术和新的移动产品</strong>进行测试，测试的对象是居住在这里的真实人群，丰田将其称之为“Weavers”。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_7b08460bd91e4d21b7737a2900ed19e2@000000_oswg998496oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如今4年过去了，丰田章男也透露了“Woven City”实验项目最新进展，目前已完成"第一阶段"建设，计划于 2025 年正式启动。&nbsp;</p>
  <p>今年秋天，Woven City将迎来的 <strong>首批100名居民</strong>，他们都是丰田或其子公司Woven by Toyota的员工，第一阶段将最终容纳360名居民。&nbsp;</p>
  <p>而第二阶段和后续阶段的目标是建造足够多的住房和设施，供多达2000人常年居住，并由该公司的氢燃料电池技术提供动力。&nbsp;</p>
  <p>造完汽车，还造城市和火箭，丰田玩得是越来越花了。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTc3NjgxNQ==&amp;mid=2247540891&amp;idx=1&amp;sn=929bf761bb92b3d835d77808b9e81eb6&amp;chksm=ce9437ae69e9a45c832b7a5535e1a738e3d236ed6b20e1b2185b2eab34e5a35d01fc21afac96&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“超电实验室”（ID：SuperEV-Lab）</a>，作者：王磊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112436158697224</id>
            <title>每8天就有一个新并购，2024半导体行业“大洗牌”，谁会是下一个巨头？</title>
            <link>https://www.36kr.com/p/3112436158697224</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112436158697224</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 11:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 半导体, 并购, 政策支持, 市场复苏  
<br><br>  
总结: 半导体行业的并购浪潮从2024年延续至2025年，受到政策支持、行业回暖及AI需求爆发等因素的推动。2024年，A股市场上首次披露了43起半导体并购事件，产业链整合成为并购的重头戏。并购不仅帮助企业快速获取核心技术和市场份额，还提升了竞争力。跨界收购的公司面临整合风险，但也寻求转型机会。整体来看，此轮并购反映了行业对技术创新的渴求和市场复苏的结果。 </div>
                        <hr>
                    
                    <p>半导体行业的并购浪潮从2024年一直延续到2025年。</p>
  <p>2024年的最后两个交易日，深康佳A（000016.SZ）、捷捷微电（300623.SZ）、利扬芯片（688135.SH）相继公告半导体资产并购事项；2025年开年以来，艾森股份（688720.SH）、双成药业（002693.SZ）等多家公司按规定披露并购事项最新进展公告。</p>
  <p>在政策支持下，叠加行业回暖及AI需求爆发等因素影响，半导体行业并购成为资本市场的年度热词。2024年全年A股有逾40家上市公司首次披露半导体资产并购事项，几乎每8天就有一个新的并购。不仅有兆易创新（603986.SH）、长电科技（600584.SH）、通富微电（002156.SZ）等产业链内上市公司通过横、纵向并购，拓宽产品线及整合供应链；也有奥康国际（603001.SH）、友阿股份（002277.SZ）、至正股份（603991.SH）等欲跨界收购半导体资产，谋求转型。</p>
  <p>风口之下，多只半导体并购概念股成为年度“大牛股”，例如双成药业筹划收购奥拉股份复牌后连收14个涨停板，友阿股份、光智科技（300489.SZ）复牌后双双收获8连板，富乐德（301297.SZ）公告收购富乐华预案复牌后走出6连板……</p>
  <p>近日，友阿股份、光智科技等多家公司还在投资平台上回应了投资者关心的并购进展。</p>
  <p>“此轮半导体行业并购力度较大，覆盖度也较广，意味着行业集中度正在提高，开始大洗牌。”深度科技研究院院长张孝荣向时代周报记者表示，“对于产业链内的头部公司而言，此轮并购是一个重要机遇，公司能够通过并购迅速扩大市场份额、掌握核心技术、降低成本，增强自身竞争力；同时，政策扶持为并购活动创造了有利条件。对于跨界收购的公司而言，由于不同行业间存在经营模式、企业文化和技术壁垒的差异，并购后的整合难度较大。”</p>
  <h2><strong>产业链并购整合</strong></h2>
  <p>此轮半导体行业的并购浪潮与政策支持密不可分。</p>
  <p>2024年4月以来，新“国九条”“科技十六条”“科创板八条”“并购六条”等政策相继出台，之后，11月和12月，深圳和上海相继公布了2025-2027年支持并购重组的行动方案，为上市公司并购重组的创造新机遇。</p>
  <p>而作为政策重点支持的半导体行业，也缓缓拉开了一场并购重组的大幕。根据Wind数据库及时代周报记者不完全统计，2024年全年，A股市场上共首次披露了43起半导体并购事件，其中有25起事件首次发布于“9.24”新政公布之后。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_7fccd5b759ce49a586b065b09a612081@000000_oswg208107oswg974oswg1127_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△数据来源：时代周报记者据wind、上市公司公告整理</p>
  <p>据时代周报记者观察梳理，产业链整合是此轮并购的重头戏，在这43起并购案例中，有34起为半导体产业链之间的资产合并（其中，半导体材料和模拟芯片上市公司尤为活跃，分别发起7宗、8宗并购事件）；此外，有9宗并购由非半导体行业上市公司跨界发起。</p>
  <p>具体来看，此轮并购覆盖面较广，从上游的半导体材料、设备、分立器件，到中游的芯片设计、晶圆制造、封装测试，各细分领域均有上市公司参与其中，其中更是不乏头部公司的身影，比如上游的高端半导体设备制造商华海清科（688120.SH）、半导体分立器件制造商捷捷微电、半导体溅射靶材制造商江丰电子（300666.SZ）；中游的国产存储芯片龙头兆易创新、指纹识别芯片龙头汇顶科技（603160.SH）、智能安防芯片设计公司星宸科技（301536.SZ）等等。</p>
  <p>从并购类型来看，既有横向并购扩大规模、丰富产品线；也有纵向并购拓宽业务范围、打通供应链。</p>
  <p>华海清科就表示为丰富公司半导体设备品类，拟斥资10.05亿元收购芯嵛半导体（上海）有限公司82%股权。据华海清科2024年12月25日公告，芯嵛公司是国内少数能实现大束流离子注入设备生产的供应商。离子注入机是集成电路制造前道工序中的关键设备之一。</p>
  <p>华海清科认为，公司能够通过本次收购较快实现对离子注入核心技术的吸收和转化，跨越式地完成产品和业务板块布局，提升公司核心竞争力。</p>
  <p>再如利扬芯片，拟收购国芯微(重庆) 科技有限公司100%股权，以弥补公司在集成电路测试特种芯片相关领域的空白；兆易创新收购苏州赛芯电子科技股份有限公司70%股份，扩展公司模拟产品品类……&nbsp;</p>
  <p>众多并购案例中，去年已披露的最大一笔并购交易来自富乐德，也被外界视为一笔“蛇吞象式”交易。富乐德以发行股份及可转换公司债券的方式，作价65.50亿元购买控股股东下属半导体资产——江苏富乐华半导体科技股份有限公司（简称“富乐华”）100%股权，后者是功率半导体关键材料之一的覆铜陶瓷载板生产商。</p>
  <p>作为一家泛半导体领域设备精密洗净服务提供商，富乐德认为，本次收购有助于整合集团内优质半导体产业资源，推动优质半导体零部件制造业务的导入，更好地为客户提供高附加值的综合性一站式服务。</p>
  <p>最新数据显示，富乐华的盈利能力高于富乐德。2024年1月-9月，富乐华实现营业收入13.73亿元，归母净利润1.91亿元，同期，富乐德实现营业收入5.60亿元，归母净利润7942.29万元。</p>
  <p>此外，并购金额超10亿元的还有芯联集成-U（688469.SH）、长电科技、通富微电和纳芯微（688052.SH ）。芯联集成-U欲斥资58.97亿元收购芯联越州72.33%股权，长电科技以6.68亿美元（折合人民币约48亿元）收购晟碟半导体80%股权，通富微电以13.78 亿元收购京隆科技26%股权，纳芯微以10亿元收购麦歌恩68.28%股份。</p>
  <p>在并购标的选择上，大多数企业进行外延式并购，仅长川科技（300604.SZ）、立昂微（605358.SH）、赛微电子（300456.SZ）、江丰电子等少数几家公司通过收购控股或参股子公司的剩余股权，提升对子公司的控制力，深化协同效应。</p>
  <p>时代周报记者注意到，境外半导体资产也成为国内企业此轮并购的焦点，标的公司业务主要涉及半导体材料、分立器件、设计领域。如有研硅拟收购株式会社DG Technologies（DGT）70%股权，该公司主营产品为刻蚀设备用部件；艾森股份收购马来西亚INOFINE公司80%股权；希荻微收购韩国集成电路设计上市公司Zinitix Co.,Ltd.合计30.91%的股权；中巨芯-U收购半导体高纯石英材料制造商Heraeus Conamic UK Limited 100%股权等。</p>
  <p>“此轮并购对于半导体行业来说是一个发展契机。我国的半导体行业仍然处于向国外追赶的发展阶段。目前的中下游的集成电路制造环节有望突破技术壁垒，上游的材料、设备制造等环节相对薄弱，研发时间较长，并且需要大量的从业人员。从国外半导体巨头的并购经验来看，国内一些大型半导体企业也可以通过并购国内外一些具有核心行业技术的中小企业，缩短自己的研发时间，减少重复开发技术投资，整合技术力量，增强国际竞争力。”宁波财经学院校学术委员会副主任、科创投资人禹久泓教授向时代周报记者表示。</p>
  <p>“并购是半导体行业发展的重要手段之一。并购有助于企业快速获取核心技术、拓展市场份额、提升竞争力。国外半导体巨头企业也是通过并购实现了技术整合、市场拓展和产业链优化。国内企业可以从中汲取并购经验，包括选择合适的并购对象、制定合理的并购策略、加强并购后的整合与管理等。”张孝荣表示。</p>
  <h2><strong>跨界收购谋转型</strong></h2>
  <p>除了原半导体产业链公司通过并购填补业务版图空缺或完善产业链布局之外，随着半导体热度升高，去年也有不少公司跨界将目光投向半导体领域。</p>
  <p>2024年12月，先有“温州鞋王”奥康国际跨界收购存储芯片公司，后有深康佳A筹划收购宏晶微电子；在此之前的11月，友阿股份拟收购半导体功率器件公司尚阳通；10月，百傲化学（603360.SH）增资芯慧联、至正股份拟收购半导体引线框架公司先进封装；9月，光智科技拟并购半导体材料公司先导电科；8月，双成药业拟收购模拟芯片公司奥拉股份……&nbsp;</p>
  <p>据时代周报记者梳理，截至目前，这9起跨界并购有6起尚在进行中。这些公司能否成功跨界尚且存疑，但这些跨界公司在首次发布并购预案后几乎无一例外地在二级市场激起层层热浪，表现最强势的如14连板双成药业、8连板友阿股份以及6连板至正股份。</p>
  <p>2024年12月30日，深康佳A发布公告称，筹划发行股份购买宏晶微电子科技股份有限公司（简称“宏晶微电子”）控股权并募集配套资金。目前公司正与宏晶微电子的实际控制人刘伟接洽，预计在2025年1月14日前披露本次交易方案。值得一提的是，公告当日，深康佳A股票正式停牌，在停牌前的最后一个交易日即12月27日，公司股价一度涨停，最新市值为133亿元。</p>
  <p>作为家电行业巨头之一，深康佳A近年业绩持续萎靡，公司在2023年确立了“一轴两轮三驱动”的集团战略，将发展重心聚焦到消费电子和半导体两大主业。此次交易标的宏晶微电子主营业务为芯片研发、设计和销售，其曾于2015年在新三板挂牌，后于2019年终止挂牌。2024年8月，宏晶微电子完成了新的IPO辅导备案，拟于科创板上市，但此后IPO进入了停滞状态。</p>
  <p>曾经的鞋业翘楚——奥康国际也试图通过战略转型寻求出路。公司正在筹划以发行股份及或支付现金的方式购买联和存储科技（江苏）有限公司（简称“联和存储”）股权，进入半导体行业。具体交易方案目前仍在商讨论证中。公司股票已于2024年12月24日开市起停牌，停牌前的最后一个交易日股价报收于7.08元/股，总市值28.4亿元。</p>
  <p>官网显示，标的公司联和存储是一家提供存储芯片和解决方案的供应商，总部位于江苏省无锡市，在首尔、上海、深圳设有研发中心。此次跨界并购被看作是业绩压力之下奥康国际为了寻找新的增长点所做的重要尝试。</p>
  <p>值得一提的是，跨界转型是机遇但也充满挑战。由于半导体行业专业壁垒较高，且不同行业上市公司在业务和管理模式等方面存在一定差异，多家公司均在公告中提到并购整合风险。</p>
  <p>例如百傲化学在公告中表示，本次股权并购属于跨行业并购，由于公司本身缺少标的公司所在行业人才和管理经验，存在一定的并购整合风险，包括企业文化融合、管理体系对接、人员安置与激励等方面。标的公司作为被并购方，如何将其与公司的现有管理体系有效整合，是此次并购成功的关键因素之一。</p>
  <p>零售业巨头友阿股份也公告表示，本次交易完成后，公司主营业务将拓展至高性能半导体功率器件研发、设计和销售，公司的主营业务、经营规模、资产和人员等都较重组前有较大的变化，对公司的内部管控能力提出了更高的要求。上市公司将结合标的公司的业务特点，进一步加强管理能力、完善管控制度以适应重组后的业务变动及规模扩张。</p>
  <p>“上市公司跨界并购半导体资产事项不断发生，很大程度源自于目前整个半导体市场的巨大的上升趋势。由于半导体行业存在门槛较高、工艺复杂、链条较长等特点，上市公司在并购过程中不仅需要加强对半导体技术的理解，还要把控管理模式及财务风险，即半导体投入产出周期性对于财务数据的影响，另外要特别关注知识产权和法律风险。总体上，上市公司要进行尽职调查，重视双方业务的协同性和互补性，建立有效的整合计划和节点，增加有效的沟通，以减少相关整合风险。”艾媒咨询首席分析师张毅向时代周报记者表示。</p>
  <p>半导体产业的并购浩浩荡荡向前，这不仅是反映了行业对技术创新的渴求，也展现了政策支持、市场复苏共振的结果，但在轰轰烈烈的历史进程中，大浪淘沙，谁能成为下一个巨头还要拭目以待。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjEyODE4MA==&amp;mid=2653322447&amp;idx=2&amp;sn=daf88354f6ed1cbd28a20fcbba32c457&amp;chksm=bcafc444aa0d81f14646faa18d5a2c2abc08e49289eb11676a1c46ab55100cc32cf4a7d5b416&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“时代周报”（ID：timeweekly）</a>，作者：庞宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112513770573315</id>
            <title>今年的CES，汽车领域有哪些热点？</title>
            <link>https://www.36kr.com/p/3112513770573315</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112513770573315</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 10:44:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <CES, 人工智能, 汽车技术, 中国企业>
<br>
<br>
总结: 本届CES展会吸引了约1440家中国企业参展，AI依然是核心主题，强调其在家居、汽车、机器人等领域的深度应用。展会设有多个消费技术产品类别，特别关注AI、数字健康和汽车出行技术。英伟达、高通等科技巨头展示了最新的AI产品和技术，汽车行业成为新主角，智能化技术推动了汽车的全面升级。未来出行形态的探索也在加速，包括人形机器人和飞行汽车等创新概念。 </div>
                        <hr>
                    
                    <p>在今年CES开幕之前，一些中国参展企业员工遭遇拒签的消息陆续传出来，虽然大家心情复杂，但也并没有阻止中国企业奔向CES的热情。&nbsp;</p>
  <p>本届CES参展企业数突破4000家，中国企业大概为1440家左右，高于去年，整体数量仍然占全部展商数量近三分之一。&nbsp;</p>
  <p>和去年一样，AI依旧是本届CES的核心，不过今年的主题"DIVE IN" ，可以理解为深入探索和体验AI如何深度应用在家居、汽车、机器人技术、健康等多领域。&nbsp;</p>
  <p>2024年CES设置了二十多个消费技术产品类别，涵盖5G、AI、数字健康、机器人、虚拟现实、汽车技术、元宇宙等前沿科技领域。&nbsp;</p>
  <p>2025年同样也有二十三个消费技术产品类别，与去年的差别不大。不过今年主办方特意列出了三个重点类别：AI、数字健康以及汽车出行技术，足可以看出这三大类对人类生活的影响和重大意义。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_7004907630cc43b09abc8a01c279f98b@000000_oswg412189oswg1080oswg442_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于其中作为科技趋势风向标的CES创新奖，今年参赛产品增加了49.5%，这显示了人工智能如何通过增强用户体验、提高生产力、提供健康解决方案等方式，逐步融入人们的日常生活。&nbsp;</p>
  <p>在参展商方面，包括英伟达、英特尔、AMD、高通、微软、谷歌和亚马逊等国际知名科技品牌的悉数到场，也让CES含金量保持高水准。&nbsp;</p>
  <p>值得注意的是，本届有250多家汽车技术相关公司参展，为历年之最，云集了全球知名车企和供应商。其中包括宝马、本田、现代汽车、奔驰等老牌车企，来自中国的车企有极氪、长城、小鹏汇天等。&nbsp;</p>
  <p>虽然特朗普的关税政策影响了市场信心，但在CES开幕之前，受CES释放的一系列利好推动，美国科技股开始反弹提振股市，尤其是以英伟达为代表的芯片股，成为其中最大的赢家，这也让英伟达成为CES最值得期待的参展商之一。&nbsp;</p>
  <h2><strong>科技巨头们的新动向</strong></h2>
  <p>和往年一样，在连续多日的高热度预热后，英伟达的演讲率先开幕。黄仁勋在特别演讲中首先推出了备受期待的最新GPU——RTX 5090，并公布了50系列GPU的价格，从549美元到1999美元。同时，Blackwell架构关键的互联技术也上了新的NVLink72。&nbsp;</p>
  <p>作为今日特别重磅，黄仁勋还发布全球最小的个人AI超级计算机Project Digits，搭载全新Grace Blackwell超级芯片。&nbsp;</p>
  <p>虽然此前黄仁勋有发过该产品的信息，但实物细节还是很震撼的。每个Project DIGITS配备了128GB统一、相干内存和高达4TB的NVMe存储，仅需标准电源插座即可运行，在家就可以跑大模型，而价格只需要3000美元起。&nbsp;</p>
  <p>黄仁勋说，AI将成为每个行业、每个应用的主流。每位数据科学家、AI研究人员和学生的办公桌上都可以放置像Project DIGITS一样的个人AI超级计算机，让他们能够参与并塑造人工智能时代。&nbsp;</p>
  <p>Thor也是此次演讲的一大看点，它专为处理海量传感器数据而生。包括比亚迪、理想、极氪等很多中国车企在内，此前都宣布过与Thor的合作。&nbsp;</p>
  <p>英伟达借助Omniverse平台，对驾驶场景进行深度测试，并生成合成数据，加速人工智能模型的研发进程。目前，丰田、AURORA和大陆集团已经加入英伟达的合作阵营，它们将共同致力于下一代高度自动化和自动驾驶车队的推出。&nbsp;</p>
  <p>黄仁勋表示英伟达汽车业务将在 2026 财年实现 50 亿美元的收入规模。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_4dacf65fe5974e98a44673deadb65596@000000_oswg300727oswg1080oswg643_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一巨头高通，也展示了一系列行业领先的AI创新产品，骁龙X系列中的第四款平台，家电中的全新AI聊天机器人、先进的智能电视、人形机器人等终端。&nbsp;</p>
  <p>高通技术公司将2025年视为“智能家居2.0”元年，随着生成式AI与边缘侧产品的融合，智能家居行业即将迎来重大发展。&nbsp;</p>
  <p>在汽车领域，高通宣布基于骁龙®数字底盘™解决方案的多项最新合作进展，覆盖数字座舱、智驾和两轮车。合作客户包括零跑汽车、阿尔卑斯阿尔派、亚马逊、、Mahindra、现代摩比斯和皇家恩菲尔德等。&nbsp;</p>
  <p>高通还宣布了其骁龙汽车平台至尊版持续发展的势头，重点展示了与德赛西威、Garmin佳明和松下汽车基于骁龙座舱平台至尊版的合作。&nbsp;</p>
  <p>AMD向消费者推出了海量的终端产品，包括包括RDNA 4显卡、新一代锐龙X3D处理器、锐龙Z2处理器、锐龙AI MAX/AI MAX PRO处理器在内的全线新品。&nbsp;</p>
  <p>英特尔带来第二代酷睿Ultra处理器系列，为移动AI与图形技术树立全新标杆。同时英特尔还表示，2025 年将推动AI PC产品组合持续演进，下半年还将实现采用前沿英特尔18A 制程工艺产品的批量生产。&nbsp;</p>
  <p>在高端内存和生成式人工智能等领域已然落后的三星电子，依旧将重点放在了AI家电领域，押注于AI技术与其智能手机、电视、冰箱等各种电子产品的结合，以帮助自己在人工智能领域占据一席之地。&nbsp;</p>
  <p>三星与现代汽车集团建立了新的合作关系，通过在现代电动汽车搭载SmartThings平台，实现SmartThings平台与汽车的联动。&nbsp;</p>
  <h2><strong>汽车成为新主角</strong></h2>
  <p>过去一年，AI大模型在语音、车控、娱乐乃至自动驾驶领域实现全面应用，智能化技术给汽车使用场景带来颠覆式变化，也让汽车成为人类生活的新主角。&nbsp;</p>
  <p>在AI技术推动下，车企重点发力的智能座舱、操作系统、智能驾驶等，都获得长足进步，这在2025年CES上有很好的体现。&nbsp;</p>
  <p>宝马首发新世代超感智能座舱——宝马首创全景iDrive，最大特点就是涵盖了视平线全景显示、3D抬头显示、超感智控方向盘、向心中控4项新技术，强调“以驾驶者为中心”，开创全新的座舱人机交互模式。这款智能座舱将随首款新世代SAV车型在2025年内推出，中国市场版本将融入本土技术和服务，满足中国消费者几乎所有场景的交互需求。&nbsp;</p>
  <p>随全新座舱发布的还有宝马新世代操作系统X，也是座舱的底层软件架构。这款操作系统是宝马与中国科技公司合作，作为BMW首创全景iDrive的底层软件架构，其能最大程度发挥4个界面的硬件能力，确保交互体验更加流畅和专注。将搭载首款新世代量产车型，在2026年与中国消费者见面。&nbsp;</p>
  <p>宝马则计划展示其最新的i Vision Dee概念车，主打增强现实与车内交互的结合，福特则会展示其全新AI驾驶助手系统，该系统集成了实时路径规划、语音识别和智能泊车功能。&nbsp;</p>
  <p>定位纯电动中型SUV的smart精灵#5车型，重点聚焦于智能驾驶系统以及座舱技术的最新研发成果。这款车首搭字节跳动的“豆包AI大模型”，还搭载了AMD高算力芯片及智能座舱。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_c04024a9782c4739960f909a657c0364@000000_oswg35939oswg866oswg577_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>本田将带来全新全球化“Honda 0”系列的两款电动车型。新车已在去年CES展上亮相，并计划在2026年正式上市。同时本田将利用这些概念车展示其即将推出的专有车辆操作系统，该系统将应用于这些车辆的量产版。作为本田智能化战略的一部分，这也是本田自研的全新操作系统。&nbsp;</p>
  <p>同时，索尼本田的电动车品牌AFEELA今年总算不再是概念了，其首款车型AFEELA 1在CES正式发布，预计将于今年在美国加州率先上市，并计划于明年中期开始交付。&nbsp;</p>
  <p>现代将展示世界上第一个全挡风玻璃全息显示屏。这一创新技术将彻底改变驾驶者的视觉体验，使信息展示更加直观、生动。大众ID. CODE概念车也搭载了类似的Wide-R曲面屏。&nbsp;</p>
  <p>至于中国车企，长城将魏牌全新蓝山带到了CES。作为长城汽车智能化战略的集大成者，全新蓝山在智能驾驶、智能座舱等方面均展现出了卓越的实力。在智能驾驶方面，全新蓝山搭载了长城汽车自主研发的Coffee Pilot Ultra智能驾驶系统。在智能座舱方面，其搭载的Coffee OS 3.1系统通过AI赋能重新定义了智能座舱体验。&nbsp;</p>
  <p>与全新蓝山一道出征的，还有长城灵魂S2000——全球唯一水平对置8缸8档摩托。该车还开创性地搭载了高通骁龙8155芯片，并配备了12.3英寸LCD可触控液晶仪表，为摩托车骑行带来了颠覆性的智能交互体验。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_08eef91b4a3c47d493823e8aa06b7b22@000000_oswg685229oswg1080oswg639_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>极氪则带来了战略、技术及产品“四项最新发布”，包括与高通携手合作布局智能座舱；全球首家OEM量产自研英伟达NVIDIA DRIVE AGX Thor智驾域控制器平台；极氪能源首发海外800V超快充补能规划；与Waymo联合开发的首款量产原生自动驾驶汽车极氪RT，将于2025年开启大规模交付。&nbsp;</p>
  <p>除此之外，极氪还带来了多款明星车型亮相CES。包括全场景超级座舱极氪MIX、四座超豪华旗舰极氪009光辉以及纯电猎装超跑极氪001FR等车型。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3f6fde51b5884eb7822220cdb509e2ae@000000_oswg72811oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>机器人和未来出行形态</strong></h2>
  <p>在AI技术进步以及汽车成熟的产业链下，全球范围内很多车企或供应链企业，开始将目光放在未来的竞争，尤其是与汽车有高度通用性的领域，比如作为具身智能最佳载体的人形机器人、飞行汽车等等。&nbsp;</p>
  <p>以人形机器人为例，中国国内已有包括小鹏、比亚迪、广汽等在内的十多家汽车及供应链企业，已经开始了相关布局。&nbsp;</p>
  <p>此次CES的演讲中，黄仁勋也提到了英伟达的人形机器人战略，他说，人形机器人的时代即将到来，这标志着通用机器人技术的重大进步。&nbsp;</p>
  <p>他还公布了英伟达在人形机器人领域开展合作的伙伴名单，其中国内厂商包括宇树科技人形机器人H1和小鹏汽车人形机器人老铁。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_700947575e3a4b2a89930ba612546408@000000_oswg229030oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有不少国内汽车产业链企业也在此次CES率先亮剑。&nbsp;</p>
  <p>在去CES之前，速腾聚创发布机器人技术平台战略，并推出一系列机器人增量零部件及解决方案新品，包括三款应用于车载和机器人场景的数字化激光雷达、机器人视觉全新品类Active Camera解决方案、端到端架构的智能化方案Robo FSD和第二代灵巧手Papert 2.0等。这些新品被悉数带到了CES。&nbsp;</p>
  <p>禾赛也将展示其全新迷你型高性能 3D 激光雷达，这款新品专为机器人及工业市场而设计，用于AGV/AMR、无人配送车、割草机器人、清扫机器人、农业机器人等。&nbsp;</p>
  <p>除了展示这款新产品外，禾赛还将在现场展示面向前装量产市场的激光雷达产品，包括超高清远距激光雷达AT系列、舱内远距激光雷达ET系列、补盲激光雷达FT系列等。&nbsp;</p>
  <p>另外，车企将一部分重点放在探索未来出行的形态，其中包括飞行汽车、出行系统等。&nbsp;</p>
  <p>继去年CES首次登台后，今年小鹏汇天展出其创新型飞行汽车“陆地航母”，这款飞行汽车采用分体式设计，兼具道路驾驶和飞行能力，预计2026年第一季度实现首批交付，单台售价不超过200万元人民币。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_d139ba7d521248d7b6c7c31f35a2ca31@000000_oswg497771oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>丰田汽车在五年后重返CES，丰田章男在演讲中提到一项宏大的未来愿景，不仅将业务扩展至地球上的移动出行，还在积极探索火箭技术，试图开辟人类未来出行的新纪元。&nbsp;</p>
  <p>丰田将与Interstellar Technologies的合作，建立合适的电信网络，以支持即将推出的Woven City的需求。&nbsp;</p>
  <p>Woven City是一个围绕未来出行和智慧生活理念构建的实验性城市。作为连接人、车与城市的新型生态体系，Woven City在设计上融入了智能交通、可再生能源与自动驾驶等前沿科技，致力于探索如何提升居民的生活品质和出行效率。&nbsp;</p>
  <p>今年首次参展的铃木也带来Glydways城市交通系统，含有多款多功能微型电动汽车平台概念。与传统公共交通相比，这款小型乘客舱需要在专用车道行驶，并具有可扩展设计，若成功应用将大大降低城市交通基础设施建设成本，同时提供了公平的可持续出行机会。&nbsp;</p>
  <h2><strong>车云小结</strong></h2>
  <p>过去CES更多的是天马行空式的“炫技”，展示的是未来5到10年内将上市的新技术。但最近这两年，随着AI的飞速发展和AI赋能产业的更多可能，都极大地缩短了新技术和产品的开发和部署周期，让竞争变得更有悬念。&nbsp;</p>
  <p>以汽车行业为例，这两年在CES展出的很多产品，很多能在当年落地，甚至有不少已经同步上市。&nbsp;</p>
  <p>这一点可以从在今年的CES创新奖窥见一斑，虽然此前中国车企在智舱、智驾等一些赛道上领先，但国外车企也没有放弃追赶，今年他们所展现的一些新技术，或许值得中国车企认真对待。&nbsp;</p>
  <p>具体获奖名单可以关注我们明天的推送。&nbsp;</p>
  <p>车云团队将在CES现场，为观众带来全球展商尤其是中国科技和汽车企业的最新动态，敬请关注我们的后续报道。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5ODY2MzIyMQ==&amp;mid=2652553473&amp;idx=1&amp;sn=8552cf849f7e9506db1e32fdae4905ce&amp;chksm=bc2eca1dc363dbfabaa6e766e49d0679c26eb6c2ce38bf5aa943c55d711361e2d4bfe1b2057f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“车云”（ID：cheyunwang）</a>，作者：Jaden，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112311327149825</id>
            <title>Tokenization，再见，Meta提出大概念模型LCM，1B模型干翻70B？</title>
            <link>https://www.36kr.com/p/3112311327149825</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112311327149825</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 10:30:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大概念模型, 语言建模, 推理, 语义表示  
<br><br>  
总结: Meta提出的大概念模型（LCM）通过抛弃token，采用高层级的概念在句子嵌入空间进行建模，旨在解耦语言表示与推理。该模型模拟人类的推理过程，强调在多级别抽象上显式的推理和规划，提升了对长文输出的可读性和处理长上下文的能力。LCM在推理效率上优于传统的语言模型，且具备零样本泛化能力，能够支持多种语言和模态。整体而言，LCM代表了对当前大规模语言建模技术的超越，尽管仍需进一步提升性能。 </div>
                        <hr>
                    
                    <p><strong>【导读】</strong>Meta提出大概念模型，抛弃token，采用更高级别的「概念」在句子嵌入空间上建模，彻底摆脱语言和模态对模型的制约。</p>
  <p>最近，受人类构思交流的高层级思路启发，Meta AI研究员提出全新语言建模新范式「大概念模型」，解耦语言表示与推理。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_97a5eb7fc3d5447ebdd6a0493d4a6ec9@46958_oswg345256oswg1080oswg784_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网友Chuby兴奋地表示：「如果Meta的大概念模型真的有用，那么同等或更高效率的模型，其规模将更小。比如说1B模型将堪比70B的Llama 4。进步如此之大！」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_20639e64a2ce4658b6c7ab9a0e322fb6@46958_oswg118240oswg1080oswg285_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而在最近的访谈中，Meta的首席科学家Yann LeCun表示下一代AI系统LCM（大概念模型）。新系统将不再单纯基于下一个token预测，而是像婴儿和小动物那样通过观察和互动来理解世界。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_93f164b0e9ae45ab810c8c8d534e18e5@46958_oswg603208oswg1080oswg688_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>华盛顿大学计算机科学与工程博士Yuchen Jin，非常认同Meta的新论文，认为新模型增强了其对「tokenization将一去不复返」这一看法的信心，而大语言模型要实现AGI则需要更像人类一样思考。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_487035ff71734fe9b6bcd00f3a897506@46958_oswg234959oswg1080oswg582_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>甚至有人因此猜测Meta是这次AI竞赛的黑马，他们会用模型给带来惊喜。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ece882af0fa641178526b3c5535f6e61@46958_oswg73717oswg1080oswg208_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>简而言之，「大概念模型」（LCM）是在「句子表示空间」对推理（reasoning）建模，抛弃token，直接操作高层级显式语义表示信息，彻底让推理摆脱语言和模态制约。</p>
  <p>具体而言，只需要固定长度的句子嵌入空间的编码器和解码器，就可以构造LCM，处理流程非常简单：&nbsp;</p>
  <p>首先将输入内容分割成句子，然后用编码器对每个句子进行编码，以获得概念序列，即句子嵌入。</p>
  <p>然后，大概念模型（LCM）对概念序列进行处理，在输出端生成新的概念序列。</p>
  <p>最后，解码器将生成的概念解码为子词（subword）序列。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ba76f60e5bc34088be24c7d4bd8c5428@46958_oswg753311oswg1080oswg1195_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文链接：https://arxiv.org/pdf/2412.08821&nbsp;</p>
  <p>代码链接：https://github.com/facebookresearch/large_concept_model&nbsp;</p>
  <p>文中对推理（inference）效率的分析颇具看点：在大约1000个token数左右，新模型理论上需要的计算资源就比LLama2-7b具备优势，且之后随着下上文中token数越大，新模型优势越大。具体结果见论文中的图15，其中的蓝色表示LLama2-7b模型，红色和绿色分别代表新模型；红色的参数规模为7b，而绿色为1.6b；右图是左图在0-3000的token数下的局部放大图。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_be909624353b4f149904140a7e6febf1@46958_oswg160366oswg1080oswg515_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>新模型的其他亮点如下：</p>
  <p>在抽象的语言和模态无关的层面上进行推理，超越token：（1）新方法模拟的是底层推理过程，而不是推理在特定语言中的实例。（2）LCM可同时对所有语言和模态进行训练，即获取相关知识，从而有望以无偏见的方式实现可扩展性。目前支持200种语言文本。</p>
  <p>明确的层次结构:（1）提高长文输出的可读性。（2）方便用户进行本地交互式编辑。</p>
  <p>处理长上下文和长格式输出：原始的Transformer模型的复杂性随序列长度的增加而呈二次方增长，而LCM需要处理的序列至少要短一个数量级。</p>
  <p>无与伦比的零样本（zero-shot）泛化能力：LCM可在任何语言或模态下进行预训练和微调。</p>
  <p>模块化和可扩展性：（1）多模态LLM可能会受到模态竞争的影响，而概念编码器和解码器则不同，它们可以独立开发和优化，不存在任何竞争或干扰。（2）可轻松向现有系统添加新的语言或模态。</p>
  <h2><strong>为什么需要「概念」？</strong></h2>
  <p>虽然大语言模型取得了无可置疑的成功和持续不断的进步，但现有的LLM都缺少人类智能的一个重要的特点：<strong>在多级别抽象上显式的推理和规划。</strong></p>
  <p><strong>人脑并不在单词层面运作。</strong></p>
  <p>比如在解决一项复杂的任务或撰写一份长篇文档时，人类通常采用自上而下的流程：首先在较高的层次上规划整体结构，然后逐步在较低的抽象层次上添加细节。</p>
  <p>有人可能会说，LLM是在隐式地学习分层表示，但具有显式的分层结构模型更适合创建长篇输出。&nbsp;</p>
  <p>新方法将与token级别的处理大大不同，更靠近在抽象空间的（分层）推理。&nbsp;</p>
  <p>上下文在LCM所设计的抽象空间内表达，但抽象空间与语言或模态无关。&nbsp;</p>
  <p>也就是说在纯粹的语义层面对基本推理过程进行建模，而不是对推理在特定语言中的实例建模。&nbsp;</p>
  <p>为了验证新方法，文中将抽象层次限制为2种：子词token（subword token）和概念。&nbsp;</p>
  <p>而所谓的「概念」被定义为整体的不可分的「抽象原子见解」。&nbsp;</p>
  <p>在现实中，一个概念往往对应于文本文档中的一个句子，或者等效的语音片段。&nbsp;</p>
  <p>作者认为，与单词相比，句子才是实现语言独立性的恰当的单元。&nbsp;</p>
  <p>这与当前基于token的LLMs技术形成了鲜明对比。&nbsp;</p>
  <h2><strong>大概念模型总体架构</strong></h2>
  <p>训练大概念模型需要句子嵌入空间的解码器和编码器。而且可以训练一个新的嵌入空间，针对推理架构进行优化。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_f6466626707e45b2a8495e3df1a2615f@46958_oswg145710oswg1080oswg536_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在此研究使用其开源的SONAR作为句子嵌入的解码器和编码器。</p>
  <p>SONAR解码器和编码器（图中蓝色部分）是固定的，不用训练。</p>
  <p>更重要的是，LCM（图中绿色部分）输出的概念可以解码为其他语言或模态，而不必从头执行整个推理过程。</p>
  <p>同样， 某个特定的推理操作，如归纳总结，可以在任何语言或模态的输入上以零样本（zero-shot）模式进行。</p>
  <p>因为推理只需操作概念。</p>
  <p>总之，LCM既不掌握输入语言或模态的信息，也不以特定语言或模态生成输出。</p>
  <p>在某种程度上，LCM架构类似于Jepa方法（见下文），后者也旨在预测下一个观测点在嵌入空间中的表示。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_2bfc87a4d0f8433c8d43bb371bbe5229@46958_oswg32979oswg1080oswg360_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文链接：https://openreview.net/pdf?id=BZ5a1r-kVsf&nbsp;</p>
  <p>不过，Jepa更强调以自监督的方式学习表示空间，而LCM则不同，它侧重于在现有的嵌入空间中进行准确预测。&nbsp;</p>
  <h2><strong>模型架构设计原理</strong></h2>
  <p><strong>SONAR嵌入空间</strong></p>
  <p>SONAR文本嵌入空间使用编码器/解码器架构进行训练，以固定大小的瓶颈代替交叉注意力，如下图2。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ef0b2786cb9141a8af88c4880850e410@46958_oswg151812oswg1080oswg568_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>SONAR广泛用于机器翻译任务，支持200种语言的文本输入输出，76种语言的语音输入和英文输出。&nbsp;</p>
  <p>因为LCM直接在SONAR概念嵌入上运行，因此可对其支持的全部语言和模态进行推理。&nbsp;</p>
  <p><strong>数据准备</strong></p>
  <p>为了训练和评估LCM需要将原始文本数据集转换为SONAR嵌入序列，每个句子对应嵌入空间的一个点。&nbsp;</p>
  <p>然而处理大型文本数据集有几个实际限制。包括精准的分割句子很难，此外一些句子很长很复杂，这些都会给SONAR嵌入空间的质量带来负面影响。&nbsp;</p>
  <p>文中使用SpaCy分割器（记为SpaCy）和Segment any Text （记为SaT）。&nbsp;</p>
  <p>其中SpaCy是基于规则的句子分割器，SaT在token级别预测句子的边界进行句子分割。&nbsp;</p>
  <p>通过限制句子的长度的长度还定制了新的分割器SpaCy Capped和SaT Capped。&nbsp;</p>
  <p>好的分割器产生的片段，经过编码后再解码而不会丢失信号，可以获得更高的AutoBLEU分值。&nbsp;</p>
  <p>为了分析分割器器的质量，从预训练数据集中抽取了10k份文件，代表了大约500k个句子。&nbsp;</p>
  <p>测试中，使用每个分割器处理文档，然后对句子进行编码和解码，并计算AutoBLEU分数。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_b314e13ce4a54ff6ab000cf097d4d91d@46958_oswg132272oswg1080oswg437_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如图3所示，如果字符上限为200个，与SpaCy Capped相比，SaT Capped方法总是略胜一筹。&nbsp;</p>
  <p>然而，随着句子长度增加，两种分割器都表现出明显的性能不足。&nbsp;</p>
  <p>当句子长度超过250个字符时，这种性能低下的情况尤为明显，这突出表明了在不设置上限的情况下使用分段器的局限性。&nbsp;</p>
  <p><strong>Base-LCM</strong></p>
  <p>下个概念预测（next concept prediction）的基线架构是一个标准的只含解码器的Transformer，它将一系列先行概念（即句子嵌入）转换为一系列将来的概念。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_b58ebf198fdc4347bff44dad43d75c3d@46958_oswg102335oswg1080oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如图4所示，Base-LCM配备了「PostNet」和「PreNet」。PreNet对输入的SONAR嵌入进行归一化处理，并将它们映射到模型的隐藏维度。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_1513bd19cac840d596fa2900cc84aa0a@46958_oswg25504oswg1080oswg179_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Base-LCM在半监督任务上学习， 模型会预测下一个概念，通过优化预测的下一个概念与真实的下一个概念的距离来优化参数，也就是通过MSE回归来优化参数。&nbsp;</p>
  <h2><strong>基于扩散的LCM（Diffusion-based LCM）</strong></h2>
  <p>基于扩散的LCM是一种生成式潜变量模型，它能学习一个模型分布pθ ，用于逼近数据分布q。&nbsp;</p>
  <p>与基础LCM相似，将扩散LCM建模被视为自动回归模型，每次在文档中生成一个概念。&nbsp;</p>
  <p>大概念模型「Large Concept Model」并不是单纯的「next token prediction」， 而是某种「next &nbsp;concept predition」,也就是说下一个概念的生成是以之前的语境为条件的。&nbsp;</p>
  <p><strong>具体而言， 在序列的位置n上，模型以之前全部的概念为条件预测在此处某概念的概率， 学习的是连续嵌入的条件概率。</strong></p>
  <p>学习连续数据的条件概率，可以借鉴计算机视觉中的扩散模型用于生成句子嵌入。&nbsp;</p>
  <p>在文中讨论了如何设计不同扩展模型用于生成句子嵌入， 包括不同类型的正向加噪过程和反向去噪过程。&nbsp;</p>
  <p>根据不同的方差进度（variance schedule）， 生成不同的噪音进度（noise schedule），从而产生对应的前向过程；通过不同的权重策略，反映不同的初始状态对模型的影响。&nbsp;</p>
  <p>文中提出了3类噪音进度：余弦Cosine，二次函数Quadratic以及Sigmoid。&nbsp;</p>
  <p>并提出了重建损失加权策略：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_81634481d12a4328b26b5760dbeca2e9@46958_oswg18085oswg1080oswg81_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文详细讨论了不同噪音进度和加权策略策略的影响，结果如下：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_bfe5bd7de70a4a5a92e0329ab08f20de@46958_oswg119933oswg1056oswg966_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>单塔扩散LCM（One-Tower Diffusion LCM）</strong></p>
  <h4>使用图像领域的扩散加速技巧，也可以加速LCM的推理。</h4>
  <p>如图6左图，单塔扩散LCM由一个Transformer主干组成，其任务是在给定句子嵌入和噪音输入的条件下预测干净的下一个句子嵌入 。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_48ee3881a8134b0292e886651fbac605@46958_oswg132120oswg1080oswg428_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>双塔扩散LCM（Two-Tower Diffusion-LCM）</strong></p>
  <p>如图6右侧，双塔扩散LCM模型将前一语境的编码与下一嵌入的扩散分开。&nbsp;</p>
  <p>第一个模型，即上下文标注模型，将上下文向量作为输入，并对其进行因果编码。&nbsp;</p>
  <p>也就是说，应用一个带有因果自关注的纯解码器Transformer。&nbsp;</p>
  <p>然后，上下文分析器的输出结果会被输入第二个模型，即去噪器（denoiser）。&nbsp;</p>
  <p>它通过迭代去噪潜高斯隐变量来预测干净的下一个句子嵌入 。&nbsp;</p>
  <p>去噪器由一系列Transformer和交叉注意力块组成，交叉注意力块用于关注编码上下文。&nbsp;</p>
  <p>去噪器和上下文转换器共享同一个Transformer隐藏维度。&nbsp;</p>
  <p>去噪器中每个Transformer层（包括交叉注意力层）的每个区块都使用自适应层规范（AdaLN）。&nbsp;</p>
  <p>在训练时，Two-Tower的参数会针对无监督嵌入序列的下一句预测任务进行优化。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_fd9e0356d13a44918b3824be9e1f765f@46958_oswg75340oswg1080oswg511_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>因果嵌入在去噪器中移动一个位置，并在交叉注意力层中使用因果掩码。在上下文向量中预置一个零向量，以便预测序列中的第一个位置（见图8）。为了有条件和无条件地训练模型，为无分类器引导缩放推理做准备，以一定的比率从交叉注意力掩码中删除随机行，并仅以零向量作为上下文对相应位置进行去噪处理。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_7ad91837fdb549738b1be6bccf937ba5@46958_oswg63574oswg1080oswg488_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>量化LCM</strong></p>
  <h4>在图像或语音生成领域，目前有两种处理连续数据生成的主要方法：一种是扩散建模，另一种是先对数据进行学习量化，然后再在这些离散单元的基础上建模。</h4>
  <p>此外，文本模态仍然是离散的，尽管处理的是SONAR空间中的连续表示，但全部可能的文本句子（少于给定字符数）都是SONAR空间中的点云，而不是真正的连续分布。&nbsp;</p>
  <p>这些考虑因素促使作者探索对SONAR表示进行量化，然后在这些离散单元上建模，以解决下一个句子预测任务。&nbsp;</p>
  <p>最后，采用这种方法可以自然地使用温度、top-p或top-k采样，以控制下一句话表示采样的随机性和多样性水平。&nbsp;</p>
  <p>可以使用残差矢量量化作为从粗到细的量化技术来离散SONAR表示。&nbsp;</p>
  <p>矢量量化将连续输入嵌入映射到所学编码本中最近的元素。&nbsp;</p>
  <p>RVQ每次迭代都会使用额外的码本，对之前量化的残余误差进行迭代量化。&nbsp;</p>
  <p>在试验中从Common Crawl提取的1500万个英语句子上训练了RVQ编码本，使用64个量化器，每个编码本使用8192个单元。&nbsp;</p>
  <p>RVQ的一个特性是，第一个码本的中心点嵌入累积和是输入SONAR向量的中等粗略近似。&nbsp;</p>
  <p>这样，在使用SONAR文本解码器解码量化嵌入之前，可以先探索码本数量SONAR嵌入自动编码BLEU分数的影响<strong>。</strong></p>
  <p>正如图9中所示， 随着编码本数量的增加，自动编码BLEU不断提高。&nbsp;</p>
  <p>当使用全部64个码本时，自动编码BLEU分数约为连续SONAR内嵌时自动编码BLEU分数的70%。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_5a1e4048cf7f46dea2fbb71ae8ce6f4e@46958_oswg79711oswg1080oswg370_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>模型分析&nbsp;</strong></h2>
  <p><strong>推理效率</strong></p>
  <p>作者直接比较了双塔扩散LCM和LLM的推理计算成本，也就是在不同prompt和输出总长度（以词组为单位）的情况下的计算成本。</p>
  <p>具体而言，论文中的图13，作者分析了理论上大概念模型（LCM）和大语言模型的推理需要的每秒浮点运算次数(flops)。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_2d5bea06f58c47f2aaf9b553873fa17e@46958_oswg160366oswg1080oswg515_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如左图所示，只有在非常短的句子（小于等于10个token）， LLM才有优势。</p>
  <p>在上下文超过10000个token左右时，不论是Two-tower LCM（1.6B）还是Two-tower LCM（7B），token数几乎不再影响推理需要的计算量。</p>
  <p><strong>SONAR 空间的脆弱性</strong></p>
  <p>在潜在空间中建模时，主要依靠诱导几何（L2-距离）。</p>
  <p>然而，任何潜在表示的同质欧几里得几何都不会完全符合底层文本语义。</p>
  <p>嵌入空间中的微小扰动都可能导致解码后语义信息的急剧丢失，这就是明证。</p>
  <p>这种性质被叫做嵌入为「脆弱性」。</p>
  <p>因此，需要量化语义嵌入（即SONAR代码）的脆弱性，以便于了解LCM训练数据的质量以及这种脆弱性如何阻碍LCM的训练动态。</p>
  <p>给定一个文本片段w及其SONAR代码x=encode(w)，将w的脆弱性定义为</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_049499ec6bba4c7489afb5cd50f9c416@46958_oswg19495oswg1080oswg175_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随机抽取了5000万个文本片段，并为每个样本生成了9 个不同噪音水平的扰动。且在实验中，对于外部余弦相似度(CosSim)指标，使用mGTE作为外部编码器。</p>
  <p>具体的脆弱性得分结果在图14中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_637b2b9bd09f41a18b70b92086ae9b01@46958_oswg159590oswg1080oswg459_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>图14中左图和右图分别描绘了BLUE和CosSIM得分随文本长度和噪声水平变化的曲线。&nbsp;</p>
  <p>可以观察到，BLEU分数的下降速度比余弦相似度更快。&nbsp;</p>
  <p>最重要的是，脆性得分对解码器的选择很敏感。具体而言，随着噪声量的增加，微调解码器的自动编码 BLEU 和余弦相似度得分的下降速度明显低于基本解码器。&nbsp;</p>
  <p>还注意到，在平均扰动水平下，总体得分分布如图15所示，在SONAR样本中，脆弱性得分差距很大。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_6086d025457548149f819599f684aae3@46958_oswg99964oswg1080oswg583_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种差异的原因可能是句子长度。与自动编码BLEU指标相比（该指标在长句子中仅下降1-2%），脆弱性对句子长度更为敏感，在两种相似性指标中都下降得更快。&nbsp;</p>
  <p>这表明，使用最大句子长度超过250的SONAR和LCM模型会面临极大的挑战。另一方面，虽然短句的平均鲁棒性更高，但在错误的位置拆分长句可能会导致更短但更脆弱的子句。&nbsp;</p>
  <p><strong>不同任务的测评</strong></p>
  <p>表10列出了不同基线和LCM在摘要任务上的结果，分别包括CNN DailyMail 和 XSum数据集。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_02edcbe67bd247c7aee5aad72b5058cc@46958_oswg91288oswg1080oswg647_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与经过专门调整的LLM（T5-3B）相比，LCM的Rouge-L（表中的R-L列）分数也具有竞争力。&nbsp;</p>
  <p>而较低的OVL-3分数则表示，新模型倾向于生成更抽象的摘要，而不是提取性摘要。LCM产生的重复次数比LLM更少，更重要的是，其重复率更接近真实的重复率。&nbsp;</p>
  <p>根据CoLA分类器得分，LCM生成的摘要总体上不太流畅。&nbsp;</p>
  <p>不过，在该得分上，即使是人工生成摘要的得分也比LLM低。&nbsp;</p>
  <p>在来源归属（SH-4）和语义覆盖（SH-5）上也有类似的现象。&nbsp;</p>
  <p>这可能是由于基于模型的指标更偏向于LLM生成的内容。&nbsp;</p>
  <p>表11列出长文档总结总结（LCFO.5%、LCFO.10%和LCFO.20%）的结果。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_fefd49046fb943959d04ad56d7d06392@46958_oswg107853oswg1080oswg668_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在预训练和微调数据中，LCM只看到了有限数量的长文档。&nbsp;</p>
  <p>不过，它在这项任务中表现良好。&nbsp;</p>
  <p>在5%和10%的条件下，它在Rouge-L指标上优于Mistral-7B-v0.3-IT和Gemma-7B-IT。&nbsp;</p>
  <p>在5%和10%条件下的度量Rouge-L优于Mistral-7B-v0.3-IT和Gemma-7B-IT，在 20%条件下接近Gemma-7B-IT 。&nbsp;</p>
  <p>还观察到，LCM在所有条件下都能获得较高的SH-5分数，也就是说，摘要可以归因于来源。&nbsp;</p>
  <p><strong>LCM的扩写</strong></p>
  <h4>摘要扩展是说在给定摘要的情况下，创建更长的文本，其目标并不是重新创建初始文档的事实信息，而是评估模型以有意义和流畅的方式扩展输入文本的能力。</h4>
  <p>当考虑到简明扼要的文件具有摘要类似的属性（即主要是从细节中抽象出来的独立文件）时， 摘要扩展任务可以被描述为生成一个更长的文档的行为，该文档保留了相应短文档中的基本要素以及连接这些要素的逻辑结构。&nbsp;</p>
  <p>由于这是一项更加自由的生成任务，因此还需要考虑到连贯性要求（例如，生成的一个句子中包含的详细信息不应与另一个句子中包含的信息相矛盾）。&nbsp;</p>
  <p>这里介绍的摘要扩展任务包括将来自CNN DailyMail和XSum的摘要作为输入，并生成一份长文档。&nbsp;</p>
  <p>表12显示了CNN DailyMail和XSum的摘要扩展结果。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_8f36d64292c249c8be0049c0959ec9d5@46958_oswg75862oswg1080oswg664_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>图中，加黑加粗的表示最佳的结果。&nbsp;</p>
  <p><strong>零样本（zero-shot）泛化能力</strong></p>
  <h4>使用XLSum语料库测试新模型的泛化能力。</h4>
  <p>XLSum语料库是涵盖45种语言的大规模多语言抽象新闻摘要基准。&nbsp;</p>
  <p>文中将LCM的性能与支持八种语言的Llama-3.1-8B-IT进行了比较：英语、德语、法语、意大利语、葡萄牙语、印地语、西班牙语和泰语。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ef7a3081318943b0939667b792ef66ab@46958_oswg119327oswg1080oswg475_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作者在图 16 中报告了42种语言的Rouge-L分数。排除了SONAR目前不支持的三种语言：Pidgin、拉丁字母塞尔维亚语和西里尔字母乌兹别克语。&nbsp;</p>
  <p>在英语方面，LCM大大优于Llama-3.1-8B-IT。&nbsp;</p>
  <p>LCM可以很好地推广到许多其他语言，特别是像南普什图语、缅甸语、豪萨语或韦尔什语这样的低资源语言，它们的Rouge-L分数都大于20。&nbsp;</p>
  <p>其他表现良好的低资源语言还有索马里语、伊博语或基隆迪语。&nbsp;</p>
  <p>最后，LCM的越南语Rouge-L得分为30.4。&nbsp;</p>
  <p>总之，这些结果凸显了LCM对其从未见过的语言的令人印象深刻的零样本（zero-shot）泛化性能。&nbsp;</p>
  <h2><strong>总结</strong></h2>
  <p>此外，文章也描述了显式规划、方法论、相关方法以及模型限制等。</p>
  <p>文章讨论的模型和结果是朝着提高科学多样性迈出的一步，也是对当前大规模语言建模最佳实践的一种超越。</p>
  <p>作者也承认，要达到当前最强的LLM的性能，还有很长的路要走。</p>
  <p>参考资料：</p>
  <p>https://x.com/Yuchenj_UW/status/1871274230383591749</p>
  <p>https://x.com/kimmonismus/status/1871291589672550865</p>
  <p>https://www.youtube.com/watch?v=UmxlgLEscBs</p>
  <p>https://x.com/AIatMeta/status/1871263650935365759</p>
  <p>https://arxiv.org/pdf/2412.08821</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/TpfRePjwzHdSIXJYCDCIJw" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：KingHZ&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112311277375241</id>
            <title>1/10训练数据超越GPT-4o，清华等提出隐式过程奖励模型PRIME，在线刷SOTA</title>
            <link>https://www.36kr.com/p/3112311277375241</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112311277375241</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 10:00:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 过程强化, 隐式奖励, 推理能力, 语言模型  
<br><br>  
总结: 本文介绍了清华研究者提出的PRIME算法，通过隐式奖励进行过程强化，显著提高了语言模型的推理能力，超越了传统的监督微调(SFT)和蒸馏方法。PRIME在多个基准测试中表现出色，平均提升了16.7%，在某些测试中甚至超过了20%。该算法利用了较少的数据资源，仅使用了1/10的数据量。研究者还分享了PRIME的开源解决方案和相关模型，旨在推动语言模型的进一步发展。 </div>
                        <hr>
                    
                    <p><strong>【导读】</strong>1/10训练数据激发高级推理能力！近日，来自清华的研究者提出了PRIME，通过隐式奖励来进行过程强化，提高了语言模型的推理能力，超越了SFT以及蒸馏等方法。</p>
  <blockquote>
   <p>Tell me and I forget, teach me and I remember, involve me and I learn.</p>
   <p>告诉我，我会忘记，教我，我会记住，让我参与，我就能学会。&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
   <p>——本杰明·富兰克林&nbsp;&nbsp;</p>
  </blockquote>
  <p>打破数据墙，我们还能做些什么？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_7f75bbf8f8ab4731b94a821ebe56dea4@46958_oswg489509oswg997oswg359_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>近日，来自清华UIUC等机构的研究者提出了PRIME（Process Reinforcement through IMplicit REwards）：通过隐式奖励来进行过程强化。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_c4d14a55afe74909bb9be28b8ff0987d@46958_oswg134053oswg973oswg315_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>GitHub地址：https://github.com/PRIME-RL/PRIME</p>
  <p>这是一种带有过程奖励的在线RL开源解决方案，可以提高语言模型的推理能力，超越了SFT（监督微调）或者蒸馏等方法。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_f98d463db015483ab80c349518076cde@46958_oswg115082oswg1080oswg463_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对比SFT，PRIME让模型在重要基准测试上实现了巨大提升：平均提高了16.7%，在AMC和AIME中都提高了20%以上。</p>
  <p>Eurus-2-7B-PRIME与Qwen2.5-Math-7B-Instruct，使用了相同的base model（Qwen-2.5-Math-7B），但在上表的6项测试中，5项都超越了instruct版本，同时也超越了GPT-4o。</p>
  <p>而这个成绩只用了Qwen Math 1/10的数据资源（230K SFT + 150K RL）！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_e11b22ed4f384d9aaf2c4f2294fe9539@46958_oswg80329oswg1079oswg375_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作者发布了本研究中使用的所有模型和数据，感兴趣的读者请见文后链接。</p>
  <h2><strong>过程奖励模型</strong></h2>
  <h3><strong>热身阶段（SFT）</strong></h3>
  <p>如前所述，选择Qwen2.5-Math-7B-Base作为起点，然后上点难度，采用竞赛级别的数学和编程基准，包括AIME 2024、AMC、MATH-500、Minerva Math、OlympiadBench、LeetCode和LiveCodeBench（v2）。</p>
  <p>首先对基础模型进行监督微调，以获得RL的入门模型（教模型学习某些推理模式）。</p>
  <p>为此，研究人员设计了一个以动作为中心的链式推理框架，策略模型在每个步骤中选择7个动作中的一个，并在执行每个动作后停止。</p>
  <p>为了构建SFT数据集，研究者从几个开源数据集中收集了推理指令。</p>
  <p>值得注意的是，对于许多具有真实答案的数据集，作者选择将其保留用于之后的RL训练，目的是让SFT和RL使用不同的数据集，以使RL中的探索多样化，并且作者认为在PL中真实标签更加重要。</p>
  <p>作者用LLaMA-3.1-70B-Instruct来回答指令，并使用系统提示要求模型执行以动作为中心的思维链。</p>
  <h3><strong>隐式PRM</strong></h3>
  <p>下面接入过程奖励模型（PRM），这里采用隐式PRM，只需要在响应级别标签上训练ORM。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_18431d5cd39347ec9fc5533c74ecc5c7@46958_oswg281750oswg973oswg523_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>过程奖励模型简单理解就是对每个推理步骤进行评分，举个例子：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_351898c3a64e4f568a42132a26c03bc5@46958_oswg917259oswg1080oswg779_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>PRM是以这种粒度来评价响应的。</p>
  <p>在本文的隐式PRM中，可以使用以下方式免费获得过程奖励：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_5cf29e0b2d2c4d3f9099fbf9fecf7554@46958_oswg23370oswg625oswg119_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>通过简单地收集响应水平数据和训练ORM来获得PRM，而无需注释步骤标签。</p>
  <p>这与ORM训练目标的具体选择无关，比如使用交叉熵损失来实例化隐式PRM，就可以替换成：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_388c33a663ee49569dae4d07a35dfb7a@46958_oswg42314oswg753oswg219_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>强化学习</strong></h3>
  <p>本文的目标是广泛利用强化学习（RL）来提高推理能力。针对这种资源有限的情况，作者总结了一些最佳实践：</p>
  <blockquote>
   <p>从Ground Truth验证器和高质量数据开始：作者进行了严格的数据收集和清理，以获得可验证的RL数据，并发现仅使用结果验证器足以构建强大的基线。</p>
   <p>作者比较了不同的RL算法得出结论，无价值模型的REINFORCE类方法足够有效。</p>
   <p>使用「mid-difficulty」问题进行稳定训练：作者提出了一种名为在线提示过滤器的机制，通过过滤掉困难和简单的问题，在很大程度上稳定了RL训练。</p>
  </blockquote>
  <h3><strong>使用PRM进行强化学习</strong></h3>
  <p>将PRM集成到在线强化学习中并非易事，这里有几个需要解决的关键挑战。</p>
  <p><strong>如何为强化学习提供密集奖励？</strong></p>
  <p>奖励稀疏性一直是强化学习中长期存在的问题。到目前为止，我们仍然没有特别好的解决方案来为LLM的在线强化学习构建密集奖励。</p>
  <p>以前的方法主要是为密集奖励建立一个额外的价值模型，众所周知，这样的模型很难训练，而且性能提升不大。</p>
  <p>根据前文对隐式PRM的介绍，使用</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_7469e6fae98242b7af2b0bbd48e766f0@46958_oswg4501oswg351oswg71_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>可以免费从隐式PRM中获得token级别的过程奖励。</p>
  <p>这种方式可以直接取代PPO中的价值模型，非常容易与任何优势估计函数和结果奖励相结合。在实践中，作者将过程奖励与REINFORCE、RLOO、GRPO、ReMax和PPO集成在一起，并进行了细微的修改。</p>
  <h2><strong>如何设置一个好的PRM来启动RL？</strong></h2>
  <p>即使我们找到了在RL中使用过程奖励的途径，训练好的PRM也并非易事：需要收集大规模（过程）奖励数据（很贵），并且模型应该在泛化和分布偏移之间取得良好的平衡。</p>
  <p>隐式PRM本质上是一种语言模型。因此从理论上讲，可以使用任何语言模型作为PRM。在实践中，作者发现最初的策略模型本身就是的一个很好的选择。</p>
  <p><strong>如何在线更新PRM以防止奖励黑客攻击？</strong></p>
  <p>在线RL中，避免RM被过度优化或被黑客入侵至关重要，这需要RM与策略模型一起不断更新。然而，鉴于步骤标签的成本很高，在RL训练期间很难更新PRM，——可扩展性和泛化问题。</p>
  <p>但是，本文的隐式PRM仅要求更新结果标签。也就是说，使用结果验证器即可在训练期间轻松更新PRM。</p>
  <p>此外，还可以进行双重转发：首先使用策略部署更新PRM，然后使用更新的PRM重新计算过程奖励，从而提供更准确的奖励估算。</p>
  <h3><strong>PRIME算法</strong></h3>
  <p>下图表示PRIME算法的整个循环：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_cdd82748b7784578945b664c049f8008@46958_oswg59754oswg593oswg413_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>策略模型和PRM都使用SFT模型进行初始化。对于每个RL迭代，策略模型首先生成输出。然后，隐式PRM和结果验证器对输出进行评分，隐式PRM在输出时通过结果奖励进行更新。最后，将结果奖励ro和过程奖励rp组合在一起，用于更新策略模型。</p>
  <p>以下是算法的伪代码：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_d6fcbdf459f7496fa1dd9a3b98360191@46958_oswg695748oswg859oswg1089_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>实验</strong></h3>
  <p>默认情况下，使用SFT模型初始化隐式PRM，并保留SFT模型作为参考对数探测器。超参数方面，策略模型的学习率固定为5e-7，PRM学习率为1e-6，使用AdamW优化器，mini batchsize大小为256，micro batchsize为8。</p>
  <p>rollout阶段收集256个提示，每个提示采样4个响应。PRM训练时β=0.05，所有实验中将KL系数设置为0。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_779b7ee4e789483c9cabd10d764eedb0@46958_oswg205676oswg847oswg555_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>将PRIME与仅带有结果验证器（OV）的RLOO进行比较，与稀疏奖励相比，PRIME将RL训练加速了2.5倍，并将最终奖励提高了6.9%，且方差更低。在下游任务上，PRIME的性能也始终优于OV。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_90532a4256044ad997e77355c50104ec@46958_oswg120524oswg851oswg401_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>下面展示PRM在线更新的重要性。比较两种设置：在线PRM使用Eurus-2-7B-SFT初始化，离线PRM使用EurusPRM-Stage1初始化。</p>
  <p>从下图中可以看出，在线PRM在训练集和测试集上的性能都大大优于离线PRM。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_d5e13dee9c83481485df97443f91ee65@46958_oswg213197oswg789oswg549_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_2fa8a9b1e5bb491c9771e61d79d7831b@46958_oswg162456oswg867oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>参考资料：&nbsp;</p>
  <p>https://curvy-check-498.notion.site/Process-Reinforcement-through-Implicit-Rewards-15f4fcb9c42180f1b498cc9b2eaf896f&nbsp;</p>
  <p>https://the-decoder.com/ai-learns-math-better-with-new-approach-that-uses-a-fraction-of-the-data/&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/bogt5zl7rytcz-FhNECTNg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：alan&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112154098322944</id>
            <title>2024年度智能车十大技术方案/产品</title>
            <link>https://www.36kr.com/p/3112154098322944</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112154098322944</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:48:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <智能车, 核心技术, 自主研发, 智驾方案>
<br>
<br>
总结: 本文介绍了中国智能车领域的十大核心技术方案和产品，强调这些技术对智能车市场的重要性。技术来源包括自主研发和供应商提供，构成了智能车的基础。各大车企如小鹏、比亚迪、华为等展示了各自的创新方案，推动智能化与电动化的融合。文章还提到特斯拉的FSD V13作为特殊存在，代表了全球智能驾驶的竞争态势。整体上，这些技术方案展现了中国智能车行业的快速发展和未来潜力。 </div>
                        <hr>
                    
                    <p>中国智能车群星闪耀，其中有这样一批核心技术，它们往往在聚光灯前一闪而过，但却对智能车的大卖起到了重要作用。</p>
  <p>它们有的来自主机厂自研，是车企赖以生存的护城河。</p>
  <p>有的来自供应商提供，是智能车时代的关键底座。</p>
  <p>它们不是繁荣璀璨的中国智能车江湖的全部，但在广泛征集、专业推荐、以及智能车参考垂直社群的万人票选后，实力所至、魅力所向、民心所属。</p>
  <p>2024年<strong>十大技术方案/产品</strong>是：</p>
  <p>（按品牌笔画排序）</p>
  <h2><strong>小鹏汽车·AI鹰眼智驾方案</strong></h2>
  <p>小鹏十年AI坚守，智驾大成之作。</p>
  <p>果断<strong>拿掉Lidar</strong>，引爆两大轿车爆款。</p>
  <p>新势力智驾标杆，率先推动<strong>智驾平权</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0525819fdb72472ea794df5ca1e68fae@000000_oswg854661oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>比亚迪·天神之眼</strong></h2>
  <p>这是新能源领头羊的全新探索，将智能化与电动化优势融合，实现<strong>「整车智驾」</strong>。</p>
  <p>自研计算平台打底，超海量数据加持，巨大潜力准备释放。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_67136ef9eecc474d9af1362f90017e38@000000_oswg865713oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>文远知行·WePilot高阶智能辅助驾驶解决方案</strong></h2>
  <p>「Robotaxi第一股」七年技术沉淀，携手全球第一Tier 1共同打造。</p>
  <p><strong>深耕国内，服务全球，中国出海冠军率先量产</strong>。</p>
  <p>告别高精度地图，环岛Corner Case也能开。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_f7ff7e413d9b42a4a00d1d452928d74e@000000_oswg872002oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>禾赛·激光雷达ATX</strong></h2>
  <p>更轻更小更清晰，最远探测<strong>300米</strong>，<strong>智能车时代的“安全气囊”</strong>。</p>
  <p>在成本侧捍卫了冗余感知，推动激光雷达迈向<strong>「千元机时代」</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_bf087107d3b8474dbde2842a0d310407@000000_oswg846852oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>华为·ADS 3.0</strong></h2>
  <p><strong>「全国都能开」</strong>只是起点，<strong>「车位到车位」</strong>率先开卷。</p>
  <p>三年沉淀，贯通行泊两域，将用户体验拉至新高。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_b29b4557071042bb942e4be1795a5534@000000_oswg903074oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>地平线·征程6系列</strong></h2>
  <p><strong>10TOPS到560TOPS</strong>，高中低阶智驾全面覆盖。</p>
  <p><strong>「征程与共」</strong>的新起点，<strong>定点超百款中高阶智驾车型</strong>。</p>
  <p>地平线的最新护城河，国产智驾普及的算力底座。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_c133dea058b149ea9591ea6918ca3771@000000_oswg893944oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>英特尔·第一代英特尔锐炫™车载独立显卡</strong></h2>
  <p>史无前例的车载独立显卡，<strong>229TOPS</strong>智舱算力天花板。</p>
  <p><strong>200亿参数</strong>大模型车端也能跑，为打造「生活第三空间」创造条件。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_7209e0ee0dbb424a83640160bec82cde@000000_oswg858086oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>商汤绝影·座舱多模态大模型</strong></h2>
  <p>千亿级参数，百万级装车。</p>
  <p>AI融合OS，携手两大芯片巨头，专为汽车场景定制。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0dd09a837e2b4902a1463ca430bee720@000000_oswg896182oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>理想汽车·端到端+VLM双系统架构</strong></h2>
  <p>对端到端的笃信，快慢思考的结合。</p>
  <p>全新范式让理想智驾飞升，<strong>跻身第一梯队</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_a2c5cd068b9744cc8d596c30214190c1@000000_oswg858579oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>蔚来汽车·SkyRide天行智能底盘</strong></h2>
  <p>集线控转向、后轮转向和主动悬架于一体，160km/h超高速爆胎，CEO极限亲测。</p>
  <p>大众名宿见证香槟塔挑战，让传统豪华黯然失色。</p>
  <p>这一刻，打破百年巨头垄断，再一次宣誓，<strong>先进的底盘在中国</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_315e692f32044c63b57f5ff232c90143@000000_oswg853334oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>特殊存在：特斯拉 FSD V13</strong></h2>
  <p>马斯克的智驾王牌，特斯拉的转型基石。</p>
  <p>大洋彼岸的独孤求败，东方群雄的最终宿敌。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_340323fa11d94fd887478f4710250194@000000_oswg862839oswg1063oswg1890_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkzOTE3Nzc5MA==&amp;mid=2247538486&amp;idx=2&amp;sn=86ada6f3bd2a72eadcd6c3e50f50dc13&amp;chksm=c3c461f9590254ee93407085f7d39eea11b8e9b4cbf61ee3f13269289791e13d58dd0dc218dd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智能车参考”（ID：AI4Auto）</a>，作者 ：有据无车，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112459092070153</id>
            <title>无锡，诞生今年首个超级独角兽</title>
            <link>https://www.36kr.com/p/3112459092070153</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112459092070153</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:40:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 超级融资, 盛合晶微, 半导体, IPO  
<br><br>  
总结: 盛合晶微半导体有限公司近日成功完成7亿美元的定向融资，主要投资方为无锡和上海的国资机构。该公司是中国大陆首家专注于12英寸中段凸块和硅片级先进封装的企业，已成为无锡的独角兽。此次融资将助力其超高密度三维多芯片互联集成加工项目，并加速其IPO进程。无锡因其完善的集成电路产业链和丰富的人才资源，成为半导体行业的重要基地。 </div>
                        <hr>
                    
                    <p>2025年第一笔超级融资出现了。</p>
  <p>投资界获悉，近日盛合晶微半导体有限公司（简称“盛合晶微”）宣布，面向耐心资本的7亿美元（约合50亿人民币）定向融资已高效交割。投资方阵容浮现——</p>
  <p>包括无锡产发科创基金、江阴滨江澄源投资集团、上海国投孚腾资本、上海国际集团、上海临港新片区管委会新芯基金及临港集团数科基金，以及社保基金中关村自主创新基金、国寿股权投资、Golden Link等。</p>
  <p>半导体圈对盛合晶微并不陌生——早年由中芯国际和长电科技两大巨头联合成立，是中国大陆第一家致力于12英寸中段凸块和硅片级先进封装的企业。2021年开始独立发展，一级市场融资份额抢手，成为无锡又一现象级独角兽。</p>
  <h2><strong>刚刚宣布融资50亿，加速IPO</strong></h2>
  <p>正如盛合晶微披露，本次投资方主要为无锡和上海两地国资。其中，无锡产发科创基金，由江阴新国联创业投资有限公司、无锡产业发展集团有限公司共同出资；江阴滨江澄源投资集团，穿透下来背后则是江阴市国资委。</p>
  <p>还有一众上海国资。上海国际集团是上海重要的国有资本投资运营平台，累计管理资产规模超1400亿元；上海国投孚腾资本是由上海国投公司作为主要发起人，联合上汽集团、宁德时代、哔哩哔哩等产业集团和投资机构共同设立的股权管理机构；上海临港新片区管委会新芯基金是由临港新片区基金管理的政府专项基金；临港集团数科基金，成立于2022年底，旨在助力上海城市数字化转型。</p>
  <p>地方国资出资，大多承载着当地产业发展的目标。追溯下来，盛合晶微与无锡、上海两地关系密切。官网显示，公司总部位于无锡市辖内的江阴高新技术产业开发区，同时在上海和美国硅谷也设有分支机构。</p>
  <p>谈到这次融资，盛合晶微董事长兼首席执行官崔东表示，“引入无锡市和上海市两地国资投资，为公司长期发展注入新动能，也有利于公司与产业链生态的紧密协作。”</p>
  <p>当然，其他投资方同样来头不小。比如，社保基金中关村自主创新基金成立于2023年，由社保基金出资，首期规模50亿元，君联资本担任管理人；国寿股权投资是中国人寿旗下的专业化私募股权投资平台，投向医疗健康、科技创新产业的关键领域和重点环节。</p>
  <p>此外还出现知名产业资本的身影。投资方Golden Link外界可能并不熟悉，但资料显示，这正是比亚迪旗下全资持股基金，此前已出现在美的、地平线等知名项目股东阵营中。</p>
  <p>这一次，盛合晶微一举融资超50亿，将助力公司正在推进的超高密度三维多芯片互联集成加工项目建设。据悉，该项目于2024年5月在无锡市江阴高新区正式开工。</p>
  <p>此前，盛合晶微曾传出IPO消息。早在2023年6月，证监会披露盛合晶微首次公开发行股票并上市辅导备案报告。报告显示，中金公司与盛合晶微签署了上市辅导协议，计划在科创板上市。</p>
  <p>本次官方通稿中，也罕见提及IPO进程，“本次增资是在公司推进上市过程中快速完成的，有针对性地引入坚定看好和愿意长期支持公司发展的耐心资本和产业资本，藉以改善和优化公司股权治理结构。”这也意味着，中国半导体将要迎来一个IPO。</p>
  <h2><strong>无锡超级独角兽成长史</strong></h2>
  <p>那是2014年，为了填补当时中国大陆在12英寸中段硅片制造领域的空白，晶圆制造龙头中芯国际和封装龙头长电科技联合宣布，双方正式签署合同，建立具有12英寸凸块加工及配套测试能力的合资公司。</p>
  <p>其中，长电科技前身为江阴晶体管厂，正是成长于江阴的代表性企业，这也为合资公司选址埋下伏笔。</p>
  <p>对于选择江阴的原因，彼时任中芯国际首席执行官兼执行董事邱慈云博士表示：“长三角是中国集成电路产业实力较强、规模较大、生态环境健全的地区。江阴地处苏锡常‘金三角’的几何中心， 距离上海中芯国际只有180公里，交通便利。同时，我们的战略合作伙伴长电科技立足江阴，合资公司可以依托长电已有的制造基地和健全的配套设施，使中段和后段实现紧邻建设，从而占据地缘优势、缩短物流时间，为客户提供一站式服务。”</p>
  <p>自起步起来，中芯长电便确定将中段硅片制造和三维芯片系统集成作为产业定位和技术方向。从一个仅有6人的小团队出发，仅一年时间中芯长电就完成了生产工艺的调试和产品认证加工。</p>
  <p>很快，中芯长电就获得中芯国际、国家集成电路产业基金和美国高通公司2.8亿美元融资。2016年，公司开始提供与28纳米及14纳米智能手机AP芯片配套的高密度凸块加工和测试服务。</p>
  <p>随着公司独立发展，盛合晶微迅速成为一级市场被争抢的项目。据当时投资人回忆，盛合晶微作为中国大陆第一家致力于12英寸中段凸块和硅片级先进封装的企业，市场认可度高，项目异常抢手，头部机构和“国家队”虎视眈眈。</p>
  <p>2022年3月，盛合晶微宣布C轮3亿美元融资已全部顺利交割完成。参与增资的投资人包括光控华登、建信股权、建信信托、国方资本、碧桂园创投、华泰国际、金浦国调等，既有投资人元禾厚望、中金资本、元禾璞华也参与了本次增资。增资完成后，公司的总融资额将达到6.3亿美元，投后估值超过10亿美元。</p>
  <p>时隔一年，盛合晶微再次完成3.4亿美元C+轮融资首批签约，包括君联资本、金石投资、渶策资本、兰璞创投、尚颀资本、立丰投资、TCL创投、中芯熙诚、普建基金等投资人，以及元禾厚望、元禾璞华等既有股东。估值跃升至近20亿美元。</p>
  <p>官网显示，盛合晶微目前已推出3倍光罩尺寸TSV硅通孔载板技术，标志着其芯片互联先进封装技术迈入亚微米时代。随着新一轮50亿融资交割，盛合晶微正成为无锡乃至中国半导体行业的一张名片。</p>
  <h2><strong>半导体“全国第二”，为何是无锡？</strong></h2>
  <p>盛合晶微成长于无锡，并非偶然。</p>
  <p>位于江苏省南部，太湖之畔，无锡具备得天独厚的地理优势，有着“小上海”之称。从鱼米之乡的物流和交易中心，到民族工商业和乡镇工业的发源地之一，无锡自古以来都是产业发达的地区。</p>
  <p>早在上世纪60年代，彼时国内半导体工业薄弱，无锡江南无线电器材厂就已经开始探索集成电路产业的步伐，并催生出了日后无锡集成电路领军企业华晶和华润微，见证了中国集成电路产业筚路蓝缕。中国第一块6英寸集成电路，也诞生在无锡。</p>
  <p>几十年来，中国集成电路产业发展迅猛。而放眼中国的集成电路产业发展早期，不少人才都来自无锡，这里也被称为中国集成电路产业人才的“黄埔军校”。据悉，目前仍有不少“华晶”人奋斗在我国集成电路产业链重要岗位，包括中芯国际、华虹宏力、长电科技等。</p>
  <p>时至今日，无锡是全国少有的拥有集成电路全产业链的地级市，拥有以卓胜微、中科芯、长电科技、盛合晶微等为代表的一批“航母级”企业。数据显示，2023年，无锡集成电路规上产业产值达2400亿元，全国城市排名第二。</p>
  <p>一枚小小的芯片，从原料到成品，包含上千道工序。放眼无锡超600家集成电路产业链企业中，覆盖了设计、制造、封测、装备、材料等各环节。</p>
  <p>此前一家射频芯片公司创始人选择回国创业，先后考察了北京、上海、苏州多个地方，最终选择了无锡。“无锡的封测产业比较有优势，其他配套产业相对完善，可以省去很多物流成本，这对初创企业而言比较重要。”</p>
  <p>越来越多企业聚集，无锡也成了半导体投资人定期的出差打卡地。据《无锡日报》</p>
  <p>，2021年至2024年11月，无锡新增在中基协备案的股权投资基金已超3500亿元；全市私募基金管理人140家，注册基金总规模约6000亿元。不仅有锡创投等本土创投机构，还有红杉中国、高瓴、毅达资本、中车基金、前海基金、一村资本、彬复资本等知名VC/PE被吸引而来。</p>
  <p>犹记得去年6月，总规模500亿元的江苏省战略性新兴产业母基金启动运行。其中，江苏省集成电路（无锡）产业专项母基金、江苏省生物医药（无锡）产业专项母基金以及无锡未来产业天使基金三只基金落地无锡。上周，锡创投公布集成电路战新产业母基金将出资首批子基金。</p>
  <p>当中一个细节是，该产业专项母基金存续期15年，以耐心资本支持江苏省“1650”产业体系、“51010”战略性新兴产业集群及《打造具有全球影响力的产业科技创新中心行动方案》明确的13个新兴产业领域中的集成电路产业，坚持“投早、投小、投科技”，推动产业链强链补链延链。</p>
  <p>回顾这些年各地产业变迁史，每一个千亿、万亿产业集群崛起，背后往往都经历了十年乃至数十年的耐心培育。正如我们所见，眼下全国掀起一场场产业逆袭战，皆为序章。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/NPwtlViYZ-LyxpWGrgy_FA" rel="noopener noreferrer nofollow" target="_blank">“投资界”</a>，作者：吴琼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112465497984516</id>
            <title>Uber与美团，会在何处梦幻对决?</title>
            <link>https://www.36kr.com/p/3112465497984516</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112465497984516</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:39:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <美团, Uber, 市场竞争, 本地生活服务>
<br>
<br>
总结: 美团与Uber是全球科技与服务领域的两大互联网公司，尽管分别来自中国和美国，但在市场规模和影响力上相当。两者的竞争可能在本地生活服务领域展开，尤其是在国际市场。Uber的核心业务是网约车，而美团则从外卖业务扩展到多种本地服务。两者的国际化策略不同，美团更注重中国市场的城市下沉，而Uber则优先进行国际扩展。未来，双方在中东市场的碰撞可能性较大，尤其是美团已在沙特挑战Uber的子公司Careem。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ae96fe0426224b66aa05b4f3a255a280@46958_oswg47844oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>美团与Uber，是当今全球科技与服务领域中规模相当、影响深远的两家互联网公司。虽然它们分别来自美国和中国，但其产品型态、收入规模到市值量级，都足以媲美彼此。</p>
  <p>如果两者产生市场竞争，从商战角度，将其视为中美新型代理人战争的一部分，或许也不算夸张。这场梦幻对决会出现吗？如果出现，又将以什么型态，在哪个地域出现？</p>
  <h2><strong>01 业务对撞，最可能发生在本地生活服务</strong></h2>
  <p>根据Uber的投资者报告，其潜在市场产值(Total Addressable Market, TAM)约为12万亿至16万亿美元，该产值反映了以网约车为主（全球潜在市场约5万亿至10万亿美元）三项事业（另有配送与货运）的全球市场。</p>
  <p>而根据美团在IPO时所估算，中国生活服务行业在2023年的潜在市场产值超过4.5万亿美元（33万亿人民币），其中在线产值超过1.1万亿美金（8万亿人民币）；当时预估在线总产值50%来自于食品消费，30%来自酒旅服务。</p>
  <p>Uber与美团都构筑了超级APP生态系统。双方的核心差异是，Uber虽拥有网约车与外卖双主线事业，但网约车事业更为核心，将基于算法的共享用车模型，按照使用的频次、价格、场景三条线延伸成生态系统；至于外卖服务，在将配送延伸到生活杂货后，近期才开始初步尝试与到店服务结合。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_88c8c91f8a504b9d8cd056c44ad4dc90@46958_oswg10919oswg727oswg282_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>美团自“千团大战”崛起，但成为千亿美金量级公司，主要还是从外卖主线事业延伸到“核心本地商业”，涵盖从餐饮外卖、到店餐饮、食品零售、酒旅预订等数十种从高频到长尾的产品/服务。特别餐饮的部分，既往供应链上游延伸，也不断裂变出对外卖和到店服务的补充（比如“秒提”），并以小象超市与美团优选增加品类广度。</p>
  <p>不过，美团在网约车领域不如Uber成功，网约车品牌“滴滴出行”、用车整合平台“高德”，在中国市场影响力都高于美团。</p>
  <p>因此，如果美团和Uber发生激烈业务对撞，不会在出行领域，最可能在以外卖为主线的本地生活服务，特别是在国际市场。</p>
  <h2><strong>02 按需响应，服务公司的顶流规模</strong></h2>
  <p>那么，作为当前全球顶流的按需服务（on-demand）类公司，核心运营指标能到达什么量级？比较2024Q3季报可以发现，双方都已证明所涉入的商业需求足够高频、盈利空间足够大，在境外也仍有足够的复制圈地机会。</p>
  <p>Uber在Q3的收入达112亿美元，增速仍有20%，单季净利超过26亿美元；美团同期收入约128亿美元（936亿人民币），增速仍有22%，单季期内溢利超18亿美元（129亿人民币）。</p>
  <p>从使用频次更能证明其影响力。Uber在Q3的订单数为28.7亿单，除以月支付活跃用户数1.6亿，每活跃用户单月约使用5.9次；美团同期订单数70.8亿单，虽然未公告月支付活跃数据，但依Q1公告年活跃用户5亿推断，同口径数据应优于Uber。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_03ce0ef841b347f68e835e9813901727@46958_oswg15807oswg743oswg363_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>03 先国际化还是先城市下沉？</strong></h2>
  <p>拥有如此高的消费频次与收入增速，投资人求着它们国际化也不意外，毕竟时间就是金钱，各国得到资本挹注的copycat不少。不过，双方不同的策略引导出迥异的国际化时程：美团选择先深化中国的城市下沉市场，因此国际化布局更晚；Uber则选择先行国际化，在2024Q3才开始关注城市行政核心区以外的郊区与二、三线城市，认为在饱和前还能额外再增长150%-240%的产值。</p>
  <p>具体来说，Uber在2009年由Travis Kalanick和Garrett Camp在美国加州旧金山创立后，于2011年首次进行国际化，进入美国以外的市场，第一个国际市场选择巴黎（法国），迄今美国以外收入约占总收入的60%。与美国旅游公司的国际化相比，Uber的国际化步伐更快，比如与Airbnb相比，Airbnb有75%的收入来自美加澳法英5大核心客源市场，说来有趣，除法国外，恰恰是地缘政治上的五眼联盟地域；而Uber除了这五大市场，在拉美也很有影响力，在巴西的人口渗透率接近20%，在墨西哥则超过10%。</p>
  <p>美团由王兴在2010年创立，如果不计入对印尼Go-Jek和对印度Swiggy的转投资，国际化应视2024Q3以Keeta品牌投入利雅得（沙特）为首次出海。考虑到中国市场足堪挖掘，美团国际化的时间较晚可以理解，因为，即便我们用广义的地域定义（涵盖北非），来计算中东在网约车和外卖领域的潜在市场，总产值仅百亿美元量级，也不到中国的1%。</p>
  <p>相较来看，中国旅游公司的国际化，一般先东亚再泛亚，亦即先从邻近中国的日韩泰开始做起，携程与同程都不例外。美团的国际化相对较为特殊，在香港之后直接跳级中东。</p>
  <p>东南亚与中东的差异在于，中东的人数较少，但客单价较高，更有可能快速盈利；但缺点也很明显，如果将东南亚与中东各国按GDP排序，2023年东南亚榜首印尼接近1.4万亿美元，排名第六的马来西亚已达4,000亿美元；但中东落差明显，土耳其与沙特虽都破有万亿美元的GDP，但排名第五（埃及）之后已不足4,000亿美元，而且与什叶派及逊尼派国家交好，恐怕也不容易做（排名第三）以色列的生意，真正能经营的国家数/人口数大概率都不如东南亚。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0a37dfb1f285450081555552bb9c52fd@46958_oswg19300oswg776oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>04 旅游布局增添碰撞可能性</strong></h2>
  <p>虽然两者的本业都不是旅游，但显然双方都很容易触及旅游场景，因为ROI迟早会算起来合理，值得加力投入。</p>
  <p>Uber曾在多个地域试点与旅游相关服务，比如火车票、船运、接送机和礼宾服务，目前大致可从”代驾”与”自驾”理解其布局。代驾部分自网约车本业添加适合旅游场景的功能，让乘客了解目的地城市的平均叫车等待时间和乘车费用，并能基于航班信息获取机场接送建议时间；自驾部分则与共享用车公司Turo合作，细节我们在环球旅讯与海择观点都谈过。</p>
  <p>至于美团，就我们所理解，此前并没有系统性的本地生活角度运营酒旅产品，导致看来更像是价格敏感版的携程。2024年起，美团外卖与美团酒旅开始有较深入的交叉营销，低星酒店与生活服务有更多融合。有趣的是，Airbnb也在2024Q3说明会更多的将本地生活产品融入旅游场景，可以说所见略同。</p>
  <p>值得注意的是，Uber和美团双方在旅游的布局都没有想象中快，影响力也没有想象中大，我们认为部分是因为本地生活的频次红利太丰厚，本业的ROI既然仍高，何必多做投入？另一方面，确实也没找到更好的本地服务/异地旅游间的融合方式。近期本地服务”旅游化”开始被重视，具体作法值得观察。</p>
  <h2><strong>05 首战将在中东</strong></h2>
  <p>如果双方在国际市场发生”本地生活服务”领域的业务碰撞，最可能发生在国际的哪个地域？</p>
  <p>我们从国际化先行的Uber切入。Uber在投资人报告提及六个高成长的潜在市场，分别是西班牙、德国、意大利、阿根廷、日本、韩国，除去美团当前还不太可能直接覆盖的欧洲与南美，剩下日本和韩国。不过，日韩Uber的市场份额较小，面临当地强大竞争对手Kakao与JapanTaxi的挑战，其中Kakao在韩国网约车市场的占有率甚至超过90%，并不具备两强对撞的土壤，我们还是分得清Uber投资者报告中的幻想与真实。</p>
  <p>Uber与美团在各自的扩展路径上面临着不同的挑战，这使得梦幻对决更加难以实现。不过，若把被收购的子公司也涵盖在内，中东将是双方最早掀起战火之处。</p>
  <p>Uber本身虽然在中东影响力不大，但Uber在2019年以31亿美金收购的Careem，则是当地的强大玩家。Careem与Uber很像，都从网约车应用，成为集用车、送餐（Careem NOW）、支付（Careem Pay）、配送于一身的超级APP。迄2023年，共覆盖中东、北非和南亚3个地区、14个国家共100多个城市。2022年收入超过3.5亿美元；截至2023年，用户总数超过4,800万。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_4b5f86a3011c4f0b91205593da695fcf@46958_oswg26602oswg894oswg614_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>确实如同王兴所说，中东不是空白市场与绿地市场（We understand that it's not an empty market, it's not a greenfield market）。美团已在沙特挑战了Careem，未来还可能在中东其他城市正式对战Uber。</p>
  <p>好吧，这不是代理人战争，而是代理人跟代理人之代理人的战争，听起来有点绕口，但也会让投资人有点兴奋，不是吗？</p>
  <p>【本文为评论员个人观点表达，不代表环球旅讯立场】</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/wZer9vt_OFN1ANSuEe_YNw" rel="noopener noreferrer nofollow" target="_blank">“环球旅讯”</a>，作者：海择资本&nbsp;罗海资，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112465596976896</id>
            <title>人工智能会取代浏览器吗？</title>
            <link>https://www.36kr.com/p/3112465596976896</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112465596976896</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:35:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <Vision Pro, 浏览器, 人工智能, 未来技术>
<br>
<br>
总结: 文章探讨了苹果的 Vision Pro 设备对传统互联网浏览器的影响，指出在沉浸式体验日益普及的背景下，浏览器的局限性愈发明显。随着人工智能的发展，浏览器需要适应新的信息获取和交互方式，否则将面临消亡的风险。回顾互联网浏览器的历史，作者认为其设计初衷是围绕文档展开，但未来的技术将推动其向个性化和对话式体验转变。文章强调，浏览器的演变将是渐进的，未来将与多种设备和新兴技术紧密结合。 </div>
                        <hr>
                    
                    <p>我对苹果的 Vision Pro 上瘾了。它是一款近乎完美的娱乐设备，是我理想的电视。当然，我希望它能更轻一些，也非常希望它的电池续航时间能更长。我希望它的 Siri 能更好用，这样当我问它我正在看什么时（比如，胡安·索托在道奇体育场打了多少个本垒打？），它应该能和洋基队比赛的视频源一起显示答案。单独去 Safari 查找这些信息真的很麻烦。</p>
  <p>如果 Vision Pro 教会了我什么，那就是在专为沉浸式体验而设计的设备上，Safari 浏览器感觉格格不入。在 AR、VR 和语音控制系统越来越多地融入日常生活的世界里，浏览器的局限性变得非常明显。目前，Vision Pro 不可能离开我的生活，但如果浏览器离开了，我一点也不会介意。</p>
  <p>对我们大多数人来说，很难想象没有互联网浏览器的生活。但随着人工智能将信息从文本、视频和音乐分解并组合成一条条人工智能聊天机器人的答案，我很清楚，在未来十年，浏览器将需要适应新的世界，否则就会消亡。</p>
  <p>我用的第一个真正的互联网浏览器是 Lynx。我早在 1993 年就用它了，当时我刚刚注册了纽约的服务提供商 The Pipeline。它先于 Mosaic 推出，后者最终将浏览器的概念推广给了大众，并成为了互联网的垫脚石。从那时起，各种浏览器——Netscape、微软的 Internet Explorer、谷歌的 Chrome 和苹果的 Safari——都曾一度成为我生活的一部分。它们是互联网的主要门户，是访问和与开放互联网上的信息交互的通用工具。它们帮助塑造了我们消费信息的方式，并改变了多个行业。</p>
  <p>回顾过去我们会发现，无论是 1994 年的 Mosaic 还是 2024 年的 Chrome，这些互联网浏览器的界面基本是一样的，几十年来大体保持不变，这多少有些不可思议。你可以输入网址（或快速搜索）来调出网页。你可以保存书签。你可以前进和后退。但正如“人工智能”的到来迫使技术栈中的一切（设备、操作系统、应用程序、云平台、网络甚至芯片）快速适应和发展一样，浏览器也必须重塑自我。它必须蜕皮、脱去旧皮，并为这个新世界脱胎换骨。</p>
  <p>要了解浏览器为何正处于一个巨大转变的门槛上，就必须回到互联网的起源。如果你了解浏览器是为什么创建出来的，那么你就能理解它的发展轨迹和变革的必要性。1989 年，Time Berners-Lee 爵士在欧洲核子研究中心工作期间创建了万维网（WWW），以满足科学家、大学和其他机构之间对共享信息的简单平台的需求。互联网浏览器应运而生，让这一过程变得更加容易。因此，互联网浏览器最初是围绕文档设计的，这一前提至今未变。</p>
  <p>大多数美国人第一次了解浏览器是从 John Markoff 的一篇文章中了解到的，当时他是《纽约时报》的一名技术作家。他的文章反映了一种对互联网力量充满希望、乐观和乌托邦式的想法，鼓励读者将浏览器视为“信息时代的宝藏地图”。</p>
  <p>“我写这篇文章是因为 DEC 的 Brian Reid 告诉我，互联网的重要性在于，处于职业中期的计算机科学家将从中受益匪浅，因为他们可以快速与同事分享学术论文，”Markoff 在一封电子邮件中说道。“它与最初的想法相比并没有太大变化，尽管如今这些页面不再那么学术化，有了图片，并且经常用于流式传输视频。”</p>
  <p>自从我看到 Humane 的 AIPin 的早期版本、Snap 的 AR 眼镜，以及听到苹果的 Vision Pro 的消息后，我就一直在怀疑浏览器的未来。就在两年多前，随着对用户友好的 ChatGPT 的问世，一切都水到渠成了。</p>
  <p>我并不指望这些设备明年或后年就能称霸世界，但旅程已经开始了。而且已经很明显，许多新兴设备和我们迄今为止使用的这些计算机并不相像。首先，其中一些甚至没有屏幕或键盘。</p>
  <p>其次，随着生成式人工智能的兴起，我们开始看到网页本身的原子化。这本身就破坏了互联网的原始前提以及迄今为止互联网的构建方式。如果没有文档可以连接，浏览器如何完成目前它做的那些工作？（比尔·格罗斯在今年早些时候与弗雷德的对话中也表达了类似的观点。）</p>
  <p>更重要的是，在“AI”和“AGI”的炒作中被掩盖的一个事实是，这些创新带来的真正突破是大型语言模型和相关技术能够获取数据并创建逻辑流，生成文本、视频或音频内容。这是从“信息”角度来看的根本进步。即使是早期（和最近开发的）工具，如 NotebookLM（可以从文本创建音频），也为我们提供了未来的方向性视角。</p>
  <p>例如，十年后（或更早），AppleNews 的客户可以要求它创建一个精选的早间新闻节目，其中包含来自预选来源和主题的信息，并让 AI 生成的播报员读给他们听，或者让他们在未来版本的 Vision Pro 或类似版本上观看内容。</p>
  <p>这些都不是科幻小说——你现在就可以做几乎所有这些事情，尽管做得没那么好。随着时间的推移，这样的未来不仅会是一种可能性，它将成为我们的第二天性。因此，这将是互联网上信息生态系统迄今为止的运作方式会遭遇的重大变化。这些新技术使我们有机会对信息进行更加个性化、以对话为中心的控制。</p>
  <p>当前的应用程序需要频繁的用户参与。我们必须有意识地跟踪一切。我们总是在拍照、记录信息和手动追踪卡路里、检查配料表，还有在购物时研究营养成分。未来的技术挑战不止是建立一个更好的食品数据库。新的技术应该做到无缝监控和干预，而无需用户不断输入。</p>
  <p>在不久的将来，你可以想象一个非人类实体——我们称之为 DietBot——充当你的私人营养师和膳食计划员，而你几乎不需要付出任何努力。这个流行的 DietBot 可以实时分析你的饮食模式、健康目标和饮食限制，从而匹配餐馆或杂货店。它可以根据你的特定需求预先筛选选项，自动标记过敏原，建议更健康的替代品，并根据你当天的活动调整份量建议。</p>
  <p>虽然浏览器无处不在，大家现在很难想象没有浏览器的生活，但事实是，我们人类过去不得不适应以文档为中心的互联网体验。我们被迫适应各种技术局限，而不是技术真正适应人类的需求。</p>
  <p>整个互联网生态系统都是为了被大型平台货币化而存在的，而且——正如 Flipboard 创始人兼首席执行官 Mike McCue（曾在 Netscape 鼎盛时期工作）等人所说，它很好地实现了这一目的。</p>
  <p>“自 90 年代中期以来，互联网和互联网浏览器一直专注于使用 HTML 和 HTTP 等开放标准连接和呈现内容，”他说。“几十年来，这种做法一直行之有效，并推动了亚马逊、Airbnb 等有着超级价值的互联网企业的崛起。”</p>
  <p>McCue 认为，通过 ActivityPub 等协议与人工智能相结合，我们可以创造更加个性化、中介化的信息体验。虽然他认为 Claude 和 ChatGPT 等 AI 界面是一次重大转变，但他认为“你总是需要一些技术载体”。改变的是载体的使用方式。正如浏览器将自身委身为应用程序来适应移动优先的世界一样，个性化、交互式、以对话为中心的 AI 系统将迫使浏览器再次进化。</p>
  <p>那么，这种进化会是什么样子呢？</p>
  <p>The Browser Company 联合创始人 Josh Miller 正在开发“Arc”，这是一款面向 AI 优先时代的浏览器。他认为，过去浏览器的用户界面已经不再那么必要，但浏览器的内部结构将对我们的未来至关重要。“虽然大多数人认为我们正在构建的是浏览器，”Miller 在一次谈话中说，“但我们正在构建的是一个基于浏览器的系统。”</p>
  <p>他希望将浏览器从单纯的查看器转变为类似操作系统的实体，在系统级别维护个人偏好和行为，让我们可以在不同设备中使用“AI”，而无需在应用程序级别重复我们的选择。他的新浏览器操作系统将从根本上理解用户的背景和偏好，从而更轻松地创建个性化体验。我们的使用模式和偏好将决定信息和服务呈现给我们的方式，而不是让应用程序来决定我们如何与信息交互。</p>
  <p>Miller 认为，互联网浏览器的核心技术，尤其是那些开放且被广泛采用的标准技术，使浏览器能够快速发展，并适应未来我们将与多种设备交互的现实——不仅仅是台式机、笔记本电脑或手机。毕竟，可穿戴设备和无屏幕设备都需要浏览、检索和与信息交互，用的肯定不是我们熟悉的那种浏览器。</p>
  <p>Miller 说，正如 iPhone 将自己定位为手机的再造一样，浏览器也将经历类似的转变。然而，转变“将是渐进的”，而浏览器的当前形式“实际上将成为这一转变的重要组成部分”，“几乎是将人们与未来联系起来并‘放松警惕’的一种方式”。</p>
  <p>Miller 的乐观源于浏览器能够为手机变身的事实。我们的移动应用本质上都是带有包装器的浏览器，用于执行特定任务，使互联网更容易管理和个性化。下一次演进可能需要更多的扭曲。</p>
  <p>随着 VR、AR、音频界面和聊天越来越成为我们——不仅仅是像我这样的 Vision Pro 爱好者，而是所有人——日常生活的核心，互联网浏览器的局限性会变得越来越明显。我毫不怀疑，浏览器的功能和工作方式的这种巨大变化将产生深远的影响。</p>
  <p><strong>原文链接：</strong></p>
  <p>https://crazystupidtech.com/archive/will-ai-eat-the-browser</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/RByw8k3ofYLkgaWFM9CbQQ" rel="noopener noreferrer nofollow" target="_blank">“InfoQ”</a>，作者：Om&nbsp;Malik，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112302501215749</id>
            <title>CES 2025上的机械手，是扫地机的具身路径？</title>
            <link>https://www.36kr.com/p/3112302501215749</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112302501215749</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:32:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 机器人, 扫地机, 机械臂, 具身智能  
<br><br>  
总结: 2024年，机器人领域迎来了重要的发展，特别是在扫地机的设计上，加入了“机械臂”以提升清洁能力。中国厂商在CES 2025上展示了配备机械手的扫地机，能够识别并处理障碍物，重构了清洁逻辑。机械手的设计灵感源于用户在狭窄空间清洁和整理杂物的需求。具身智能的兴起为扫地机的技术创新提供了新方向，尽管面临结构重构的挑战，但也为未来的3D清洁应用打开了可能性。 </div>
                        <hr>
                    
                    <p>在刚刚过去的2024年，机器人迎来了一次空前的历史高光时刻。</p>
  <p>一位在机器人领域做研究做了半辈子的老教授就曾感慨：</p>
  <p>“这样频繁地收到会议邀请、又有这么多钱投到我这个研究领域，放在我刚入行的时候是不敢想象的。”</p>
  <p>也是在机器人有了一个更性感的名字——具身智能后，产品设计已经相当成熟的扫地机器人也有了新设计路径。</p>
  <p>就在这几天在美国举办的CES 2025上，中国机器人厂商为扫地机加上了“机械臂”，开始试水具身智能。</p>
  <p><strong>这一次，扫地机用上了真正的“机械臂”，可以“手动”清理路障的“机械臂”。</strong></p>
  <h2><strong>01「扫地机+机械手」的设计逻辑</strong></h2>
  <p>在CES 2025上，我们看到有两家中国机器人厂商为扫地机加装了“机械臂”这一结构设计，他们就是同为拥有“米系”基因的石头和追觅。&nbsp;</p>
  <p>这不是两家厂商第一次推出“机械臂”设计方案。</p>
  <p>上一次应用“机械臂”，是通过为扫地机用于拖地的抹布或用于扫地的边刷增加自由度，让其拥有了伸缩外扩功能，这一功能最终被用于<strong>改善扫地机边角清洁能力</strong>。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_da01783b78f84e2b949d29507f6ea91c@5540194_oswg430512oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>彼时这样的“机械臂”方案在国内得到了广泛普及，成了2023年几大主流扫地机产品旗舰机型的标配。&nbsp;</p>
  <p>与上一次能够将抹布外扩几厘米的“机械臂”不同的是，这一次，中国机器人厂商直接为扫地机增加了一个配备夹爪的机械臂，因而官方也称之为“机械手”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_b3393e80026c42d3b2fc1848158c8c30@5540194_oswg273971oswg802oswg528_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以追觅配备机械手的扫地机为例，其工作流程如下：</p>
  <p>首先，扫地机上舱盖打开，双折叠机械手从舱内伸出，机械手和机身双目系统绑定，识别地面上的障碍物；</p>
  <p>其次，夹爪上还配备了一个RGBD摄像头，配合机身双目系统，进行障碍物的点云重建，从而得到机械手的抓取点；</p>
  <p>最后，<strong>机械手感知到障碍物，选择物体的抓取点，执行抓取动作，将障碍物放到指定位置</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_b2f00cca7403406ca5b3ccaff87a6a72@5540194_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>通过这样一套工作流程，扫地机在家庭中进行地面清洁的逻辑被重构。</p>
  <p>以往扫地机遵循的是先扫后拖、边扫边拖、脏污复拖的逻辑，在加入机械手后，现在的清扫逻辑变成了：</p>
  <p>第一步，先基于以往清洁逻辑进行一次完整的清洁，在第一次建图过程中遇到障碍物依然采用避障方式绕行并识别出障碍物，判断障碍物是否可以被抓取；</p>
  <p>第二步，完成整体清洁后，再对（能抓起的）物品/障碍物进行抓取、整理，将能够抓取的障碍物放到指定位置，例如将拖鞋放到玄关、将玩具放到玩具房等；</p>
  <p>第三步，对因障碍物堆放漏扫的区域进行一次补充清洁。</p>
  <p>至于为什么会做这样的设计，追觅官方给出的解释是，在进行场景调研时，追觅发现用户在使用扫地机时存在两个痛点：</p>
  <p>其一是<strong>狭窄空间的地面清洁</strong>，其二是<strong>需要人为归整地面上的杂物</strong>。</p>
  <p>这也就成了扫地机机械手的设计灵感来源。</p>
  <p>据悉，追觅在CES 2025上展示的扫地机上的机械手，可以夹起机身附近30cm范围内的400g的物体，此外，官方还为这只机械手设计了单独的清洁工具配件仓，用于为机械手提供顺手的工具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_234c2a7ece6a4cb68e140a106f8aa438@5540194_oswg102793oswg1080oswg658_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>&nbsp;当然，这样的设计思路，多少也与当下具身智能热有一定关系。</p>
  <p>具身智能不仅让人形机器人有了空前热度，其背后所仰仗的大模型技术，也让扫地机这一已经成熟商用的机器人产品有了一个再进化的方向。</p>
  <p>据锌产业此前了解，国内主流扫地机厂商本就在人工智能算法上有着深入的研究，而就大模型技术而言，也早在两年前开始涉入并展开研究。&nbsp;</p>
  <p>这次的机械手从某种意义上来说，也是大模型落地扫地机的一种解法。</p>
  <h2><strong>02 扫地机的具身智能路径</strong></h2>
  <p>在风起云涌的2024年，无论是在学术界、产业界，还是投资界，具身智能都已经成为关注度绝无仅有的一个领域。</p>
  <p>这一领域不仅有相关引导政策的推动，有最优秀的人才团队涌入创业，也有着最雄厚的资本支持。</p>
  <p>就在今天，英伟达创始人黄仁勋在CES 2025的主题演讲中公布了他的“智选”人形机器人天团，这次“上台”的14家中，有6家是“中国造”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_a026fa1a5526489099d9f2076810501c@5540194_oswg27637oswg1080oswg497_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中，第二次入选的国内人形机器人明星团队傅利叶还在今天官宣了E轮近8亿元融资。</p>
  <p>这将人形机器人热度从2024年带到了2025年。</p>
  <p>我们在2024年年底总结文《具身智能2024：大模型“凿壁”，机器人“偷光”》中曾提到：</p>
  <p>具身智能无论是在数据，还是在算法、模型上，依然存在不少难题；</p>
  <p>就产品形态而言，<strong>轮足底盘+机械臂+灵巧手是现在火热的人形机器人产业落地一个主要的中间形态</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_8eef96abbbd34daca5b2edc608f15da4@5540194_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>就机器人产业而言，扫地机无疑是商业化最成功的机器人品类之一，也是为数不多能卖出百万销量的机器人品类。</p>
  <p>据IDC最新统计数据显示，<strong>2024年第三季度，全球智能扫地机器人出货501.4万台，同比增长11.1%；国内出货132.1万台，同比增长17%</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_a03ac719b15740b3b9366196d25bac1e@5540194_oswg95239oswg1080oswg733_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与此同时，中国扫地机正在加速出海，走向欧美市场，如今已经成为欧洲市场顶流。</p>
  <p>正是这样一个已经成功走过十多年商业化历程的机器人品类，也面临着创新瓶颈。</p>
  <p>此前有机器人领域资深从业者向我们指出，“扫地机已有的技术已经非常成熟，如今的扫地机市场已经<strong>不再是一个技术驱动的市场，而是一个市场驱动的市场</strong>。”</p>
  <p>这时，具身智能，也就成了扫地机的技术创新方向。</p>
  <p>据悉，机械手执行任务时的任务调度，以及通过视觉对障碍物的识别和分类，都有用到大模型。</p>
  <p>而作为家庭环境中具有很好的移动功能（可被视为移动底盘）的扫地机，再加上一个机械手，也就成了一个相当酷炫的应用方案。</p>
  <p>不过，折叠机械手的加入，必然会对本就结构紧凑的扫地机，带来产品结构上的重构。</p>
  <p>就产品结构重构而言，CES 2025上追觅和石头发布的扫地机+机械手方案虽有类似，却也有较大的不同，据我们了解，二者最重要的不同体现在两方面：</p>
  <p>第一，整机结构方面，石头尽量保证了扫地机机身厚度，在尘盒、滚刷等内部结构上做了让步，追觅则是用机身高度为机械手换取了堆叠空间；</p>
  <p>第二，定位导航方面，石头沿用了面阵激光雷达方案，追觅则换上了双目视觉方案。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_aacf1aaa1cd543de8fd5f608e4a72ebe@5540194_oswg520589oswg1056oswg588_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当然，作为百年不遇针对机身结构进行重大重构的方案，不免也会让人担忧：</p>
  <p><strong>加入机械手方案后，是否会影响扫地机原有清洁效率呢？</strong></p>
  <p>外媒The Verge在提前拿到石头搭载这一方案的Saros Z70（国内是G30 Space）进行实测后就有指出：</p>
  <p>“这款产品虽然可以像宣传片中那样工作，但它的运行速度非常慢，在我们测试过程中，它花了大约一分钟的时间拿起并移动路径上的袜子，而且仅限于移动300g以内的袜子、纸巾、毛巾、凉鞋。”</p>
  <p>有机器人资深行业人士也告诉我们，“我不认为机械手占用的位置相比做一个更大的集尘盒效率会更高，不过长期看或许这种组合倒是有可能会迎来一些新的应用创新点。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_34efe640c483465ba36f166c60b26d86@5540194_oswg380518oswg956oswg544_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>关于基于机械手进一步创新应用的可能性，有机器人资深行业人士就向我们指出，“扫地机之前最大的局限是只能做地板清洁，也可以理解为只能做2D地面清洁，机械手对于扫地机这样的家用机器人更大的潜力在于，<strong>让扫地机有了从2D清洁走向3D清洁的可能</strong>，例如可以清洁桌面、沙发等脱离地面的家庭空间。”</p>
  <p>值得注意的是，这一方案目前显然只是扫地机的一次新设计理念的概念尝试，这样的概念机最早也要到今年年中才能进入商用市场。</p>
  <p>至于加上机械手的扫地机，未来是否能够进化到一个更高的维度<strong>做空间清扫和房间整理，做一个更好的家庭保姆</strong>，也将还需要几年时间让这些扫地机研发团队做概念验证。</p>
  <p>不过，在内卷如此严重的扫地机市场，我们不妨大胆预测一下：&nbsp;</p>
  <p>在明年的CES 2026上，我们是不是将有可能看到这样的概念性产品？</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/nUqYiufGHJOkfPY_M63HnQ" rel="noopener noreferrer nofollow" target="_blank">“锌产业”</a>，作者：山竹，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112311044607493</id>
            <title>用大模型吃瓜更智能了，阿里通义实验室提出新时间线总结框架，全面提升新闻总结效率</title>
            <link>https://www.36kr.com/p/3112311044607493</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112311044607493</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:31:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 新闻时间线, CHRONOS, 自我提问  
<br><br>  
总结: CHRONOS是由阿里巴巴通义实验室与上海交通大学提出的一种基于Agent的新闻时间线摘要框架。该框架通过迭代多轮自我提问和检索增强生成技术，从海量新闻中提取重要事件并生成清晰的时间线。CHRONOS能够有效应对开放域和封闭域的时间线总结任务，展示了在复杂事件检索和时间线构建方面的强大能力。实验结果表明，CHRONOS在事件总结质量和日期对齐准确性上显著优于传统方法，具有实际应用潜力。 </div>
                        <hr>
                    
                    <p>现在，大模型可以帮你梳理<strong>新闻时间线</strong>了，以后吃瓜就更方便了！</p>
  <p>AI Agent的风，咱们赛博乐子人也得吹吹。</p>
  <p>这就是来自<strong>阿里巴巴通义实验室</strong>与<strong>上海交通大学</strong>的新研究，他们提出了一种基于Agent的新闻时间线摘要新框架——<strong>CHRONOS</strong>。</p>
  <p>它不仅可以帮你从海量新闻中总结出重要事件，更重要的是，它还可以梳理出清晰的<strong>时间线</strong>，以后上网冲浪时各种复杂事件都一目了然。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_66e6866f9a184811996787a1c7990c64@46958_oswg243653oswg1080oswg403_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中的CHRONOS一词取自希腊神话中的时间之神柯罗诺斯。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_8ee4322174194cca80e2328551d7f063@46958_oswg109201oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>该框架通过<strong>迭代多轮的自我提问</strong>方式，结合<strong>检索增强生成技术</strong>，从互联网上检索相关事件信息，并生成时间顺序的新闻摘要，为新闻时间线摘要生成提供了一种全新的解决方案。</p>
  <p>先来一起瞅瞅几个例子。</p>
  <p>比如对于新闻“国足1-0巴林”，CHRONOS能够总结海量新闻，呈现事件的来龙去脉。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_8e544f42035742a0adc9d6bd5c4701c7@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于覆盖时间更长的新闻“中国探月工程”，CHRONOS也能聚焦重点事件，呈现时间线发展，使得用户能够一目了然。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_feb23ebc5be740fb9fad94b1fc455f12@46958_oswg124319oswg902oswg1084_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>补齐开放域TLS短板</strong></h2>
  <p><strong>时间线总结</strong>（Timeline Summarization, TLS）任务是一种自然语言处理领域的经典技术挑战，它旨在从大量文本数据中提取关键事件，并按时间顺序排列，以提供对某一主题或领域历史发展的结构化视图。</p>
  <p>例如，在新闻领域，时间线总结可以帮助用户快速了解一个新闻事件的来龙去脉。该任务不仅要求识别出重要的事件，还需要理解事件之间的时间关系和因果联系，以便生成一个连贯、简洁且信息丰富的时间线摘要。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_1f9287dae1dd416faaa7cb77028f2787@46958_oswg391066oswg1080oswg1132_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>根据可检索事件的来源，可以将TLS任务细分为<strong>封闭域</strong>（closed-domain）和<strong>开放域</strong>（open-domain）两个设定：在封闭域TLS任务中，时间线是从一组预定义的、与特定主题或领域相关的新闻文章中创建的，而开放域TLS指的是从互联网上直接搜索和检索新闻文章来生成时间线的过程。</p>
  <p>过去的工作主要集中于解决封闭域上时间线生成问题，而开放域TLS则需要强大的信息检索和筛选能力，以及在没有全局视图的情况下识别和建立事件之间联系的能力，为这项任务提出了新的要求和挑战。</p>
  <h2><strong>迭代检索的CHRONOS框架</strong></h2>
  <p>为了应对上述挑战，团队提出CHRONOS框架，通过迭代提问进行相关事件检索，生成准确、全面的时间线摘要，能够有效地解决开放域和封闭域两种设定下的TLS任务。</p>
  <h3><strong>1. 动机</strong></h3>
  <p>时间线生成的核心在于建立事件之间的时间和因果关系。</p>
  <p>每个新闻事件都可以被表示为一个不同的节点，任务的目标是建立这些节点之间的边，以展示它们的相关性，并最终形成一个异构图，从主题新闻的节点开始。</p>
  <p>因此，通过一个检索机制来检索相关的新闻文章，可以有效建立这些边，形成事件之间的联系。</p>
  <h3><strong>2. 概述</strong></h3>
  <p>CHRONOS利用大模型的能力，通过模拟人类信息检索的过程，即通过提出问题、基于检索结果进一步提出新的问题，最终收集关于相关事件的全面信息并总结为时间线。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_402a84b3985a48448cc693f31d3d6455@46958_oswg160075oswg1080oswg353_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>CHRONOS包括以下几个模块：</p>
  <p><strong>自我提问 (Self-Questioning)</strong>：首先搜索<strong>粗粒度</strong>的新闻背景信息，然后迭代地提出问题，以检索更多相关新闻。</p>
  <p><strong>问题改写 (Question Rewriting)</strong>：将复杂或表现不佳的问题分解为<strong>更具体、更易检索</strong>的查询。</p>
  <p><strong>时间线生成 (Timeline Generation)</strong>：通过合并每一轮检索生成的时间线来总结一个<strong>突出重要事件</strong>的时间线。</p>
  <h3><strong>3. 自我提问</strong></h3>
  <h4><strong>3.1 粗粒度背景调研</strong></h4>
  <p>在自我提问的初始阶段，CHRONOS使用目标新闻的<strong>标题</strong>作为关键词进行搜索，以收集与目标新闻最直接相关的信息。</p>
  <p>这些信息构成了新闻背景（News Context），为自我提问打下初步基础。</p>
  <h4><strong>3.2 提问示例选择</strong></h4>
  <p>在粗粒度背景调研之后，CHRONOS利用大模型的上下文学习能力，通过少量样本提示来指导模型生成关于目标新闻的问题。</p>
  <p>为了评估问题样本质量，引入了<strong>时序信息量</strong>（Chrono-Informativeness, CI）的概念，用来衡量模型提出的问题<strong>检索与参考时间线对齐事件</strong>的能力，即高CI值的问题更有可能引导检索到与目标新闻事件相关的文章，用检索生成的时间线和参考时间线中包含日期的F1分数进行衡量。</p>
  <p>基于最大化问题集时序信息量的目标，构建一个“新闻-问题”的示例池，用于指导新目标新闻的问题生成。</p>
  <p>对于每个新的目标新闻，通过余弦相似性动态检索与目标新闻最相似的样本，确保了样本的上下文相关性和时间信息的准确性。</p>
  <h4><strong>3.3 迭代提问</strong></h4>
  <p>CHRONOS通过连续迭代提问，逐步深入探索事件的细节。</p>
  <p>每一轮迭代都基于前一轮的检索结果，以发现新的问题和信息，直到满足时间线中事件数量或达到最大迭代次数。</p>
  <h4><strong>3.4 问题改写</strong></h4>
  <p><strong>查询改写</strong>（Query Rewriting）是检索增强生成中常用的优化方法。</p>
  <p>在CHRONOS框架中，团队通过对初始提问阶段产生的宽泛或复杂问题改写为2-3个更易于检索的子问题，能够生成更具体、更有针对性的查询，从而提高搜索引擎的检索效果。</p>
  <p>他们同样在提示中加入少量样本，指导大模型进行有效改写，将复杂问题转化为更具体的查询，同时保持问题的原始意图。</p>
  <h4><strong>3.5 时间线生成</strong></h4>
  <p>CHRONOS通过两阶段生成完整的时间线总结：生成（Generation）和合并（Merging）。</p>
  <p><strong>生成</strong>：通过分析每一轮检索到的新闻文章来识别关键事件和详细信息。利用大模型的理解和生成能力，提取每个事件的发生日期和相关细节，并为每个事件撰写简洁的描述。这些事件和描述被组织成初步的时间线，按照时间顺序排列，为后续的合并阶段提供基础。</p>
  <p><strong>合并</strong>：将多轮检索生成的初步时间线整合成一个连贯的最终摘要。这一过程涉及对齐不同时间线中的事件、解决任何日期或描述上的冲突，并选择最具代表性和重要性的事件。</p>
  <h2><strong>全新数据集OPEN-TLS</strong></h2>
  <p>为了评估TLS系统，研究团队还收集了由专业记者撰写的关于近期新闻事件的时间线，构建了一个名为<strong>Open-TLS</strong>的新数据集。</p>
  <p>与以往封闭域的数据集相比，Open-TLS不仅在数据集规模和内容上更加多样化，覆盖<strong>政治、经济、社会、体育和科学技术</strong>等多个领域，而且在时效性上更具优势，为开放域TLS任务提供了一个更全面和更具挑战性的基准。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_98eedc44371340539469306da0e919ae@46958_oswg47813oswg1080oswg299_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>实验结果</strong></h2>
  <h3><strong>1. 实验设定</strong></h3>
  <p>实验基于GPT-3.5-Turbo、GPT-4和Qwen2.5-72B分别构建CHRONOS系统，评测开放域和封闭域两个设定下TLS的性能表现。使用的评估指标主要有：</p>
  <p><strong>ROUGE-N</strong>: 衡量生成时间线和参考时间线之间的N-gram重叠。具体包括：（1）<strong>Concat F1</strong>：通过将所有日期摘要连接起来计算ROUGE，以评估整体的一致性；（2）<strong>Agree F1</strong>：仅使用匹配日期的摘要计算ROUGE，以评估特定日期的准确性；（3）<strong>Align F1</strong>：在计算ROUGE之前，先根据相似性和日期接近性对预测摘要和参考摘要进行对齐，评估对齐后的一致性。</p>
  <p><strong>Date F1</strong>：衡量生成时间线中日期与参考时间线中真实日期匹配程度。</p>
  <h3><strong>2. 开放域TLS</strong></h3>
  <p>在开放域TLS的实验中，CHRONOS与几个基线方法进行了比较，包括直接搜索目标新闻（<strong>DIRECT</strong>）和重写目标新闻以创建查询用于检索（<strong>REWRITE</strong>）。</p>
  <p>对比之下，CHRONOS通过迭代自我提问和检索相关新闻文章的方法，显著提高了事件总结的质量和日期对齐的准确性，<strong>在所有指标上都领先于基线方法</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_93c88041b3d8444f955a80c0f4bae804@46958_oswg72932oswg1080oswg405_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>3. 封闭域TLS</strong></h3>
  <p>在封闭域TLS的实验中，CHRONOS与之前的代表性工作进行了比较，包括：（1）基于事件聚合方法的CLUST (Gholipour Ghalandari and. Ifrim, 2020);（2）基于事件图模型EGC（Li et al., 2021）和（3）利用大模型进行事件聚类的LLM-TLS（Hu et al., 2024）。</p>
  <p>在Crisis和T17这两个经典数据集上的比较结果显示，CHRONOS达到了与这些工作类似的表现，在两个数据集的AR-2指标上取得了SOTA效果，证明了其在不同类型事件和时间跨度上的强大性能和适应性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3f828830c3fe484fa25cc405ae2e7d8d@46958_oswg357282oswg1080oswg1173_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>4. 运行时间分析</strong></h3>
  <p>CHRONOS的另一个优势体现在<strong>效率</strong>方面。</p>
  <p>与同样基于大模型、但需要处理新闻库中所有文章的LLM-TLS方法相比，它通过检索增强机制专注于最相关的新闻文章，<strong>显著减少了处理时间</strong>。</p>
  <p>这种效率的提升使其在实际应用中更为实用，尤其是在需要快速响应的场景中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_e57d1a5b8c3b474c9d33d51a67f9808c@46958_oswg19941oswg652oswg228_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>案例研究：苹果产品发布时间线</strong></h2>
  <p>团队深入分析了模型在处理具体新闻事件时的表现，通过选择具有代表性的新闻事件，如苹果公司的重大产品发布，能够观察到CHRONOS如何通过由浅入深的自我提问和信息检索来生成时间线。</p>
  <p>在案例研究中，CHRONOS展示了其能够<strong>准确提取关键事件和日期</strong>的能力，同时也揭示了在某些情况下可能需要改进的地方，例如对某些事件的遗漏或日期幻觉。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0f263a249e8f4a0d91c0b2e3227f2bf8@46958_oswg232993oswg1080oswg936_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>结语</strong></h2>
  <p>CHRONOS框架通过结合大型语言模型的<strong>迭代自我提问</strong>和<strong>检索增强生成技术</strong>，为时间线总结任务提供了一种新颖且有效的解决方案。</p>
  <p>这种方法的核心在于<strong>模拟人类的信息检索过程</strong>，通过不断地提出和回答新问题来逐步深入理解事件，最终生成一个全面且连贯的时间线摘要。</p>
  <p>实验结果已经充分证明了CHRONOS在复杂事件检索和构建时间线方面的能力，展示了该框架在实际新闻时间线生成应用中的应用潜力和准确性。</p>
  <p>同时，这种迭代提问的检索生成方法是否具有泛化到通用任务上的能力也值得未来进一步研究。</p>
  <p>论文：https://arxiv.org/abs/2501.00888Github:&nbsp;https://github.com/Alibaba-NLP/CHRONOSDemo:&nbsp;https://modelscope.cn/studios/vickywu1022/CHRONOS</p>
  <p>Reference:&nbsp;</p>
  <p>[1] Demian Gholipour Ghalandari and Georgiana Ifrim. 2020. Examining the state-of-the-art in news timeline summarization. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1322–1334, Online. Association for Computational Linguistics. &nbsp;</p>
  <p>[2] Manling Li, Tengfei Ma, Mo Yu, Lingfei Wu, Tian Gao, Heng Ji, and Kathleen McKeown. 2021. Timeline summarization based on event graph compression via time-aware optimal transport. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6443–6456, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics. &nbsp;</p>
  <p>[3] Qisheng Hu, Geonsik Moon, and Hwee Tou Ng. 2024. From moments to milestones: Incremental timeline summarization leveraging large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7232–7246, Bangkok, Thailand. Association for Computational Linguistics.&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Cw5BAT_aQj3HE7CmQfHj4Q" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：Chronos团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112206952713733</id>
            <title>语言模型到底是什么？</title>
            <link>https://www.36kr.com/p/3112206952713733</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112206952713733</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:23:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 语言模型, 概率, 人工智能, 认知  
<br><br>  
总结: 语言模型是一种通过计算词语联合概率来理解和生成自然语言的模型。与传统的自动机模型不同，语言模型认为句子的正确性是一个概率问题，而非简单的对错判断。人工智能的潜力在于准确预测这些概率。语言模型的发展经历了多个阶段，从早期的统计方法到现代的神经网络和Transformer架构，推动了技术的进步。语言不仅是思考的工具，还影响着人类的认知和文化传承。 </div>
                        <hr>
                    
                    <p>有人问你：语言模型到底是什么？<strong>怎么解释？</strong></p>
  <p>如果说，它是一种预测生成自然语言的模型，能够理解一个人标的问题，然后给出答案。你可能略听懂一二，但想深入理解就难了。怎么办？&nbsp;</p>
  <p>我们不妨从研究者视角，来看看他们眼中的语言模型。&nbsp;</p>
  <h2><strong>01</strong></h2>
  <p>以前，人们研究语言时，常使用「自动机」这个概念。</p>
  <p>乔姆斯基就提倡大家用自动机来研究语言，自动机的工作原理是： <strong>如果你说的一句话是对的，它就接受；如果是错的，它就拒绝。这就像写一个程序，用来判断句子是否正确。</strong></p>
  <p>但语言模型的想法有些不同，它认为，句子并不是非黑即白的，而是有一定的“软性”。&nbsp;</p>
  <p>比如：你说“中国的首都是北京”，这句话是对的，概率很高。但如果你说“美国的首都是北京”，虽然这句话在语法上没问题，但事实是错误的。&nbsp;</p>
  <p><strong>语言模型不会直接拒绝它，而是认为它的概率比较低。</strong></p>
  <p>语言模型会把句子中的每个词（比如“中国”、“首都”、“北京”）组合起来，计算它们的联合概率。如果我们能准确预测这个联合概率，就说明我们对语言的理解比较准确。&nbsp;</p>
  <p>这里有一个重要的信念：如果我们能通过联合概率模型判断出“中国的首都是北京”是对的，而“美国的首都是北京”是错的，那么这个模型就具备了一些类似人类的知识。&nbsp;</p>
  <p>也就是说， <strong>人工智能可能就隐藏在准确预测联合概率的过程中。</strong> 所以，如果我们能把语言模型做好，就相当于获得了人工智能的能力。&nbsp;</p>
  <p>当然，关于这方面，有不同的观点。&nbsp;</p>
  <p>比如，伊利亚（OpenAI的ChatGPT团队）认为，只要你能准确预测下一个词，就意味着你对现实世界的理解非常准确。&nbsp;</p>
  <p>但也有反对的声音，比如图灵奖得主Judea Pearl，他研究的是因果推理，他认为仅仅通过统计来预测语言是不够的，真正的理解需要通过因果推理来实现。&nbsp;</p>
  <p><strong>所以，语言模型争论从1960年的符号主义出现，到1980年，一直在争论。</strong></p>
  <p>后来，基于统计学的NPL出现后，后来人们称它为“自回归模型”，它的目标不是直接预测整个句子的联合概率，而是把这个联合概率拆分成多个条件概率。&nbsp;</p>
  <p>简单来说， <strong>就是通过前面的词来预测下一个词。</strong> 比如，我们要说一句话：“Today is Monday。”这句话没问题，那么它的概率是怎么算的呢？&nbsp;</p>
  <p>首先，第一个词“Today”出现的概率是多少？ 然后，在已知第一个词是“Today”的情况下，第二个词“is”出现的概率是多少？接着，在已知前两个词是“Today is”的情况下，第三个词“Monday”出现的概率是多少？&nbsp;</p>
  <p><strong>把这些概率乘起来，就得到了整个句子的概率。这种方法叫做「自回归」。</strong></p>
  <p>自回归模型概念最早可以追溯的乔治·尤尔（George Udny Yule）在1927年的研究工作，直到20世纪70年代这个想法才进一步得到验证。&nbsp;</p>
  <p>不过，实际操作中，这种建模方式有点难。&nbsp;</p>
  <p>因为如果句子特别长，后面的词需要依赖前面很多词，而语料库中恰好出现一模一样句子的概率很低。&nbsp;</p>
  <p>所以，大家通常会用“n-gram”语言模型来简化问题。“n-gram”模型是什么意思呢？就是限制一下，只看前面的几个词。 <strong>比如，1-gram就是只看当前词，每个词独立统计概率。</strong></p>
  <p>举个例子：&nbsp;</p>
  <p>如果我们用《人民日报》的语料来建模型，统计每个字出现的概率，然后按这个概率随机生成句子。这样生成的句子可能不太通顺，但如果逐渐增加n-gram的长度，比如到4-gram或5-gram，生成的句子就会更通顺，甚至有点《人民日报》的味道。&nbsp;</p>
  <p><strong>不过，n-gram模型也有问题。</strong> 如果n设得太大，比如5-gram或6-gram，需要的语料量会非常大；因为连续五六个词一起出现的情况比较少见，必须有足够多的数据才能支持这种模型。&nbsp;</p>
  <p>后来，人们基于自回归发明了更好的方法。&nbsp;</p>
  <p>1966年，鲍姆和韦尔奇提出了隐马尔可夫模型（HMM）及其训练方法；其实，n-gram模型很早就有，1913年马尔可夫就用它来预测词了；但HMM直到1966年才被发明出来，真正应用到自然语言处理中已经是1989年了。&nbsp;</p>
  <p>再后来，Rabiner等人写了一篇经典文章，教大家如何在语音识别中使用HMM，这篇文章被引用了很多次，成为了非常经典的工作。&nbsp;</p>
  <p><strong>这说明，从技术发明到实际应用，往往需要很长时间。</strong></p>
  <h2><strong>02</strong></h2>
  <p>到了2000年，语言模型的发展逐渐进入快车道，人们发现，越来越多的模型效率更高，效果更好，能够更好地建模语言。比如，2000年时，有人开始用神经网络来预测n-gram的概率。</p>
  <p><strong>具体来说，就是把前面N个词输入神经网络，得到一个中间结果，再把这些结果拼起来，通过另一个神经网络预测下一个词。</strong></p>
  <p>这听起来有点“暴力”，但效果确实不错。这篇文章也成为用神经网络建模语言模型的开山之作，被引用了上万次，非常重要。&nbsp;</p>
  <p>再过十年，到了2010年，人们开始用循环神经网络（RNN）来建模语言模型。&nbsp;</p>
  <p>RNN好处是，它不受n-gram的限制。n-gram只能看到前面N个词，而RNN理论上可以记住历史上所有的词，虽然实际使用时，由于梯度消失等问题，效果并不理想。&nbsp;</p>
  <p>RNN的模型也很难训练和调试。这一年，Mikolov等人做了一些经典工作，推动了RNN的应用。&nbsp;</p>
  <p>到了2014年，序列到序列学习（seq2seq）出现了。 <strong>它用LSTM（长短期记忆网络）来解决语言模型中的梯度消失问题。</strong> LSTM通过增加记忆单元，能够记住更久远的信息。seq2seq与之前的模型不同，它有一个“读”的过程。比如：&nbsp;</p>
  <p>用户输入一个句子“ABC”，模型会从这个句子开始预测回答。这种模型引入了编码器和解码器的概念，为后来的语言模型奠定了基础。&nbsp;</p>
  <p>2017年，Transformer模型出现了。&nbsp;</p>
  <p>它的核心是注意力机制，但更重要的是，它找到了一种适合大规模扩展的神经网络结构。 <strong>以前的RNN和LSTM很难做大，训练速度慢，而Transformer训练速度快，容易扩展。这使得模型规模可以变得非常大。</strong></p>
  <p>到了2020年，大家熟悉的GPT-3和GPT-4出现了。&nbsp;</p>
  <p>它们的一个重要贡献是提出了“缩放定律”： <strong>模型越大，效果越好。</strong> 另一个突破是，它将所有自然语言处理（NLP）任务统一到一个模型中。&nbsp;</p>
  <p>以前，不同的任务（比如分类、实体识别）需要不同的模型，而GPT-3认为，所有任务都可以看作语言模型问题。这为探索通用人工智能提供了新的思路。&nbsp;</p>
  <p>总的来说，语言模型的发展经历了从神经网络到RNN，再到LSTM、Transformer，最后到GPT的过程。每一步都在推动技术的进步，让我们离通用人工智能更近了一步。&nbsp;</p>
  <p>简单讲，大语言模型从出现到现在主要的三个时期是：&nbsp;</p>
  <p>一，结构主义语言学迈向行为主义语言学；二，基于乔姆斯基启发，符号主义NLP出现；三，大家发现符号主义不是正确路线后，统计NLP才开始出现，最后，技术的各种研究到了奇点时，Transformer架构出现。&nbsp;</p>
  <p>实际上，语言模型的发展过程中，我们受到了乔姆斯基的影响。&nbsp;</p>
  <p>中间有一段时间，大家主要研究“生成语言学”， 也就是用符号逻辑来分析语言，这种研究方式持续了一段时间，但也导致了发展速度的放缓，甚至可以说是一个低潮期。&nbsp;</p>
  <p><strong>后来，人们发现统计方法才是正确的方向。</strong></p>
  <p>于是，语言模型的发展速度逐渐加快，特别是最近几年，随着计算能力的提升，我们可以训练越来越大的模型，也找到了更适合的模型结构。这使得语言模型的发展速度在近几年呈现出爆炸式的增长。&nbsp;</p>
  <h2><strong>03</strong></h2>
  <p>了解完整个模型历史脉络后，我们不妨思考下：<strong>为什么要研究语言呢？</strong></p>
  <p><strong>首先，我们要理解语言与其他信息形式的不同之处。</strong></p>
  <p>在研究通用人工智能时，语言为何成为重点？这是因为语言与智能之间有着独特的紧密联系，这种联系是其他信息形式所不具备的。&nbsp;</p>
  <p>乔姆斯基认为，语言是思考的工具。&nbsp;</p>
  <p>他提出，要理解人类心智，必须研究语言，因为语言与心智密切相关。他的观点与我们有所不同。&nbsp;</p>
  <p>尽管人类的语言机制存在许多歧义和低效之处，但如果将其视为思考的工具，就会发现它实际上非常有效。因此，乔姆斯基认为语言是思考的工具。&nbsp;</p>
  <p>而我们的主要观点是“压缩论”。&nbsp;</p>
  <p><strong>人工智能可以表现为一种压缩的形式，语言之所以重要，是因为人类之间的交流主要依赖于语言，我们没有更好的替代方法。然而，语言交流的带宽其实非常低。</strong></p>
  <p>有一项研究指出，无论使用何种语言，人与人之间交换信息的速度大约为每秒40个比特，这个速度相当低。你可以想象，以这种速度下载一部电影需要多长时间。&nbsp;</p>
  <p>因此，为了有效地交流，人类必须对信息进行压缩。压缩信息会损失很多细节，这促使我们形成了许多抽象概念。&nbsp;</p>
  <p>这些概念使我们对世界的认知变得更加概念化， <strong>换句话说，语言是推动我们产生抽象认知的环境压力来源。</strong> 为了与他人交流，我们必须思考事物背后的规律和本质。这就是语言如此重要的原因。&nbsp;</p>
  <p>举个例子：&nbsp;</p>
  <p>谢氏家录讲的是谢灵运。谢灵运生活在魏晋南北朝时期，当时他在官场上不太顺利，被贬到了温州，也就是现在的永嘉。据说，谢灵运每次见到他的弟弟慧莲，就能写出优美的诗篇。&nbsp;</p>
  <p><strong>有一次，他在温州的屋子里待了好几天，怎么也写不出诗来。</strong> 突然有一天，在迷糊的状态下，他见到了弟弟，灵感一来，就写出了“池塘生春草”这句诗。他说这是神助，不是他自己的话。&nbsp;</p>
  <p>我们可以想象一下，谢灵运被贬到温州后，心里很苦闷，有很多情感想要表达，他见到弟弟时，弟弟并不知道他的心情。&nbsp;</p>
  <p>于是，谢灵运通过提炼，写出了简短的诗句，通过这种方式，用很低的信息传递量，把情感传达给了弟弟， 虽然弟弟理解的场景可能和实际的不一样，但精神是一致的。这体现了人类在信息压缩上的高智能。‍&nbsp;</p>
  <p><strong>再比如，不同语言对颜色的描述也有所不同。</strong></p>
  <p>现在大家都知道，颜色可以用色相、饱和度和亮度这三个维度来描述。&nbsp;</p>
  <p>有人统计过，世界上不同的语言用哪些词来描述颜色；比如，我们有红色、黄色、粉色等词汇。但在自然界中较少的蓝色和紫色，我们用的词汇就比较少，这反映了概念化的过程。&nbsp;</p>
  <p>语言对我们的认知也有直接影响，这一点可以通过实验来测量。 <strong>有人研究过俄国人对颜色的认识，因为俄语和英语在描述蓝色时有所不同。</strong> 英语中，我们通常把蓝色都称为“blue”，然后说这是浅蓝或深蓝。&nbsp;</p>
  <p>而俄语中，深蓝和浅蓝是两个完全不同的词。实验发现，当给俄国人看两个颜色时，如果两个都是深蓝或浅蓝，他们分辨起来比较慢。&nbsp;</p>
  <p>但如果一个是深蓝一个是浅蓝，他们分辨得就比较快。 <strong>这说明语言对认知有影响。</strong> 如果在他们分辨颜色时，再给他们一些语言上的干扰，这种速度优势就会消失，分辨速度会变慢。&nbsp;</p>
  <p>所以，通过实验可以观察到，语言确实对我们的认知功能有深刻的影响。</p>
  <h2><strong>04</strong></h2>
  <p><strong>其二，语言的重要性不可言喻。</strong></p>
  <p>如果没有语言，人类的高级思考活动可能就无法进行，语言是思考的基础工具，它与我们人类的知识和文化有着深刻的联系。</p>
  <p>比如，我们的文化和科技成就都是通过语言来传承的。你可以看到，很多知识和智慧都蕴含在语言中。&nbsp;</p>
  <p><strong>以我们中国人和美国人的思考方式为例，它们是不同的。</strong> 为什么呢？&nbsp;</p>
  <p>因为我们有很多成语和典故，这些都影响了我们的思维方式。比如，当一个同学在研究中遇到困难，转而去打游戏时，我们可能会说他“玩物丧志”。&nbsp;</p>
  <p>虽然大家都知道这个词，但你知道它背后的故事吗？它源自周武王灭商后，西吕国送给他一条藏獒，他沉迷其中，大臣劝谏说“玩物丧志”，提醒他要专心工作。这些成语虽然简单，却包含了丰富的历史和智慧。&nbsp;</p>
  <p><strong>所以，语言不仅是知识的载体，还是一种高度抽象的符号系统，</strong> 它对我们的认知有深刻的影响，参与了我们的各种活动。&nbsp;</p>
  <p>我们通常认为，语言能力强的人，智能也较高。比如，在招学生时，我们更喜欢口齿伶俐的同学，因为他们通常能更好地表达自己的想法，做科研时也会更顺利.&nbsp;</p>
  <p>另外，从可行性角度来看，相比语音、视觉或视频数据，文本数据的收集成本要低得多， <strong>因此，以语言为中心构建人工智能模型更为方便。</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU5ODMyNDEyNw==&amp;mid=2247502116&amp;idx=1&amp;sn=8dd3787c81e7bf2c86aba0392bdd00cd&amp;chksm=ffd5354c17701e3ba7f95052672e98c45f7593fb34c3e1aca166b4ca33e704798d86255e5ad9&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“王智远”（ID：Z201440）</a>，作者：王智远，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112298320264966</id>
            <title>CES 2025开幕即巅峰：英伟达RTX50系，英特尔18A引爆全场</title>
            <link>https://www.36kr.com/p/3112298320264966</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112298320264966</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:21:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: CES 2025, 英伟达, AI芯片, 智能家居  
<br><br>  
总结: 在CES 2025上，英伟达发布了全新的GeForce RTX50系列GPU，具备强大的计算和AI性能，采用了Blackwell架构，性能提升显著。英特尔展示了首款18A制程芯片，强调了其在AI和电池续航方面的优势。AMD推出了针对AI的高性能笔记本芯片，展示了其在图形和渲染性能上的领先地位。高通则推出了骁龙X平台，推动PC和智能家居的AI体验。戴尔和三星分别发布了新的AI PC产品组合和智能家居愿景，致力于提升用户体验。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_83c3ac730a534d48a3225a5e5820df5b@813924438_oswg807238oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为年初惯例，全球最大科技盛会CES在拉斯维加斯举行。随着资本市场持续关注AI、芯片、AR/VR等概念，这个以消费电子产品见长的展会，正愈发受到市场的关注。</p>
  <p>科技界的春晚，少不了的是各家厂商摩拳擦掌发布新品。比如英伟达、英特尔、AMD、高通等厂商就已经带来了今年的重磅发布。</p>
  <p>那么，这些厂商的发布到底有哪些惊喜呢?科技旋涡第一时间为大家带来讲解。</p>
  <h2><strong>英伟达：发布RTX50系GPU</strong></h2>
  <p>北京时间1月7日上午10:30，英伟达CEO黄仁勋在CES2025发表开幕主题演讲。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_9408824bf9664250b305c2aa1f74845c@813924438_oswg268939oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在演讲中，黄仁勋表示，英伟达发布全新GeForce RTX50系列Blackwell架构GPU。据了解，GeForce RTX 50系列拥有堪称“核爆”的核心性能，搭载920亿晶体管，具备4000 TOPS的计算能力以及4 PFLOPS的AI性能，较上一代Ada架构性能提升三倍。其光线追踪性能达到惊人的380 TFLOPS，结合125 TFLOPS的并行着色能力，确保呈现出无与伦比的画质。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_e0bf0810fa384450accd8e0a1ee38d81@813924438_oswg375923oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而且，Blackwell系列引入了全新的“神经纹理压缩”和“神经材质着色”技术，使着色器能够直接处理神经网络。这一突破使图像质量达到了新的高度，其纹理学习和压缩算法带来了更高效、更细腻的图形表现。</p>
  <p>发布会现场，黄仁勋宣布，GeForce RTX4090售价为1599美元，新一代GeForce RTX 5090显卡售价为1999美元，RTX 5080售价为999美元，RTX 5070显卡售价549美元。黄仁勋表示，RTX 5090的性能将是4090的两倍。RTX 5070性能相当于RTX 4090，价格不到后者一半，为549美元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_5f82f96d1def4d05abca855d65f8a885@813924438_oswg203941oswg1080oswg641_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>黄仁勋透露，Blackwell系统的奇迹在于其前所未有的规模，Blackwell芯片是人类历史上最大的单芯片。</p>
  <p>英伟达的目标是创建一个巨型芯片，该芯片将使用72个Blackwell GPU或144个芯片，超越世界上最快的超级计算机的能力。</p>
  <p>黄仁勋透露，英伟达拥有多种(计算)系统，如NBLink 36x2和NBLink 72x1，能够满足全球几乎所有数据中心的需求，目前在约45家工厂生产。</p>
  <p>据现场消息，Blackwell目前已全面投入生产，所有主要云服务提供商均已建立系统，提供约200种不同型号和配置，来自约15家硬件制造商。Blackwell相比于前一代在性能上实现了四倍的提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_959989eb41f2420b81ab38b545ac2134@813924438_oswg220552oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另外，黄仁勋还宣布了NVIDIA Cosmos，这是通过理解物理世界帮助开发人员进行AI训练的世界基础模型。Cosmos模型可以接受文本、图像或视频的提示，生成虚拟世界状态，作为针对自动驾驶和机器人应用独特需求的视频输出。开发人员可以利用Cosmos为强化学习生成AI反馈，从而改善策略模型并测试在不同场景下的性能。</p>
  <h2><strong>英特尔：展示首款Intel 18A制程芯片</strong></h2>
  <p>北京时间1月7日，在英特尔CES 2025演讲中，英特尔临时联席CEO Michelle Johnston宣布，首款Intel 18A制程芯片——英特尔Panther Lake处理器将于2025年下半年发布。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_43b2d673cc3f419e864b5b3b34e0332a@813924438_oswg196998oswg650oswg366_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然而，最需要注意的是，除了Core Ultra 200V之外，英特尔本次CES发布的绝大部分新处理器都基于Arrow Lake架构，没有采用最新的GPU架构和更快的NPU，无法支持Copilot+功能。</p>
  <p>值得注意的是，这次产品发布是自公司董事会迫使首席执行官Pat Gelsinger离职以来最大规模的一次发布。新芯片阵容涵盖从用于轻度任务的Core 3到更强大的Core Ultra 200H，其中Core Ultra系列2是英特尔全新的高性能产品线，旨在提升两个关键领域的性能：电池续航时间以及运行人工智能功能的能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_687e442293bb42d38b280ef1dbab42e8@813924438_oswg204703oswg640oswg336_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与近几代芯片类似，这些新处理器采用多种核心架构组合，包括专注于高性能计算任务的P-cores(性能核心)、针对效率优化的E-cores(高效核心)，以及进一步提高功耗效率、适合轻量任务的低功耗E-cores。</p>
  <p>英特尔表示，搭载Core Ultra 200V、HX、H、U 和 S 芯片的 PC 将于本月开始上市，而配备Ultra 200H的系统将于今年第一季度初推出，Ultra 200HX设备预计在第一季度末上市。</p>
  <p>Johnston还展示了PantherLake芯片的样品，并表示芯片已经在测试中，她对18A非常满意。Johnston宣布，Intel 18A制程将于“今年晚些时候发布”。她表示，“英特尔会在2025年及以后继续增强AI PC产品组合，向客户提供领先的英特尔18A产品样品，并在2025年下半年量产”。</p>
  <h2><strong>AMD：发力AI芯片</strong></h2>
  <p>本次CES展会，AMD以“High Performance and Adaptive Computing”为主题，强调了AMD的核心理念，以创新技术，为全球用户创造高性能计算解决方案，应对任何挑战。</p>
  <p>首先，AMD为大家带来了号称其迄今为止最强大的人工智能(AI)笔记本电脑用芯片，即锐龙AI Max和AI Max+笔记本芯片。拥有多达40个基于RDNA 3.5架构的计算单元(CU)，搭载16个Zen 5 CPU内核和32 个线程，配有一个带宽为每秒256GB 的新内存接口，支持高达128GB的内存供CPU、GPU和XDNA 2 NPU AI引擎共享。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_54ed4e8ab90b43fab63c0b75288513ca@813924438_oswg214064oswg640oswg352_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>AMD表示，最高端的锐龙AI Max +395芯片图形性能是英特尔最高端Lunar Lake芯片酷睿9 288V处理器的1.4 倍以上，3D渲染性能是后者的2.6 倍，16核锐龙AI Max旗舰新品的渲染性能比12核的苹果MacBook M4 Pro快84%。</p>
  <p>AMD 客户端计算业务总经理 Rahul Tikoo表示，锐龙AI Max 为市场上的 AMD下一代AI平台增加了一类全新的 PC。</p>
  <p>AMD同时公布了代号Fire Range的新款HX 和 X3D 系列笔记本电脑芯片，它们都采用AMD之前仅在7945HX3D处理器应用的3D V-Cache堆叠缓存技术，拥有16个Zen4 CPU核心和总计144MB的缓存。</p>
  <p>AMD甚至声称，在同样的游戏中，9950X3D比英特尔的酷睿Ultra 9 285K快20%，但考虑到英特尔即将提升285K的性能，两者的差距可能会缩小。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ad3d9f0119d1421bb51b0fe8180df0cc@813924438_oswg132023oswg640oswg335_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另外，作为锐龙9 9950X3D 和 9900X3D的补充，AMD还将推出针对中端笔记本电脑和超便携电脑的全新“Fire Range”芯片系列。该系列将于2025年上半年推出。</p>
  <h2><strong>高通：重新定义PC品类</strong></h2>
  <p>1月6日，高通在2025年国际消费电子展(CES 2025)上宣布了一系列行业领先的AI创新，展现了其如何推动用户体验在PC、汽车、智能家居和企业级等多元终端品类的变革。</p>
  <p>高通公司总裁兼CEO安蒙表示：“AI正在为技术领域带来划时代的变革。2025年，AI处理将继续向边缘迁移，赋能并增强AI为先的体验。作为边缘侧AI的领导者，高通公司正在携手广泛的生态系统合作伙伴，跨多元终端品类为消费者和企业带来AI为先的体验。我们很高兴能在CES 2025上展示终端侧AI将如何成为下一个UI，变革PC、汽车、智能家居等领域的体验。”</p>
  <p>高通技术公司推出骁龙X平台，这是其高性能PC产品组合——骁龙X系列中的第四款平台，为更广泛的Windows生态带来行业领先的性能、多天电池续航以及AI领先优势。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_56e555faeb794891963511b178025095@813924438_oswg135255oswg600oswg334_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据介绍，Snapdragon X采用4纳米制程工艺制造，配备高通的Oryon CPU，拥有8个核心，最高主频可达3GHz，为下一代PC提供了强大的计算性能。</p>
  <p>包括宏碁、华硕、戴尔科技和联想集团在内的PC制造商将采用这款AI芯片，且搭载Snapdragon X的PC的售价预计将低至600美元，产品预计在2025年初上市，这意味着用户将很快能够体验到。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_135e8707e99b4a7691c49d1a04270c0d@813924438_oswg296541oswg640oswg360_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另外，高通持续扩展在汽车领域的合作，携手阿尔卑斯阿尔派、亚马逊、零跑汽车、Mahindra、现代摩比斯和皇家恩菲尔德等合作伙伴，基于骁龙数字底盘解决方案推动AI赋能的车内体验和先进驾驶辅助系统(ADAS)的发展。</p>
  <p>而且，高通还展示了集成在家电中的全新AI聊天机器人、先进的智能电视、人形机器人等终端。高通技术公司将2025年视为“智能家居2.0”元年，随着生成式AI与边缘侧产品的融合，智能家居行业即将迎来重大发展。</p>
  <h2><strong>戴尔：打造全新AI PC产品组合</strong></h2>
  <p>戴尔科技公司在CES 2025宣布推出专为个人和专业计算打造的全新AI PC产品组合。</p>
  <p>为了让客户更容易找到合适的 AI PC，戴尔“XPS”和“Inspiron”等沿用几十年的个人电脑产品名称将被取消，新一代设备将简化为戴尔(Dell)品牌。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_70255de4bc5c41d08f7410dec6b51600@813924438_oswg143594oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>戴尔的笔记本电脑和 PC 将采用类似苹果 iPhone 的命名惯例，系列产品命名分别为 Dell、Dell Pro 和 Dell Pro Max，IT之家附定位如下：</p>
  <p>Dell(专为娱乐、学校和工作而设计)</p>
  <p>Dell Pro(专为专业级生产力而设计)</p>
  <p>Dell Pro Max(专为最高性能而设计)</p>
  <p>其中，Dell和Dell Pro产品线扩展到显示器、附件和服务领域，可在整个客户端产品组合中提供一致的客户体验。</p>
  <p>另外，戴尔科技全新PC产品组合提供了最新的芯片选择，同时为终端用户和企业在产品选择方面消除了顾虑和复杂性。最新的戴尔科技AI PC提供内置NPU技术，可释放针对特定工作负载需求的AI性能。戴尔科技通过搭载英特尔酷睿Ultra处理器(第二代)，进一步丰富了其英特尔产品线;同时引入AMD锐龙™处理器，拓宽了用户对AMD平台的选择;此外，继续携手高通公司，还将为客户提供匹配特定用例应用场景的设备。</p>
  <h2><strong>三星：将AI融入家居中</strong></h2>
  <p>在本届CES上，三星电子发布了全新的“AI for All”愿景，致力于让AI体验覆盖到用户日常生活的方方面面。</p>
  <p>星电子副董事长兼首席执行官、设备体验部门负责人Jong-Hee (JH) Han在 CES 2025新闻发布会上介绍了三星Home AI的发展战略，计划通过所有三星家用智能互联设备为用户提供真正个性化的服务，重新定义“家”的概念。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3ac70b3c29b248029cc4710af5700431@813924438_oswg277365oswg630oswg424_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在发布会上，三星电子美国公司的乔纳森·加布里奥(Jonathan Gabrio)进一步阐述了三星的Home AI愿景。展现了三星将通过在整个互联体验中引入AI技术，以满足用户多样化的生活方式，无论是单人家庭，还是多代同堂的家庭，Home AI都能学习用户个人生活习惯，并依据日常惯例进行调整，提供更加个性化的智能家居体验。</p>
  <p>作为三星的智能家居平台，SmartThings为全球数亿用户提供了智能互联体验，支持实现Home AI的愿景。SmartThings中还将引入增强的AI语音助手Bixby Voice，该助手能够识别用户声音，以最贴合用户习惯的方式执行指令，提升易用性。</p>
  <p>三星Vision AI的全新功能和个性化服务，带来了无与伦比的领先屏幕体验，让生活充满意想不到的乐趣。AI屏幕可赋能电视，通过生成式壁纸等创新功能，提升用户的智能体验。</p>
  <p>最后，三星副总裁Inhee Chung强调了三星“AI for All ”愿景是如何延承三星利用先进技术打造更美好包容的世界的品牌理念。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/MCO03pZ2luTIfKmLnEtfsw" rel="noopener noreferrer nofollow" target="_blank">“科技旋涡”</a>，作者：贾桂鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112289334017799</id>
            <title>阿里收购零一万物？李开复连夜辟谣</title>
            <link>https://www.36kr.com/p/3112289334017799</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112289334017799</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:16:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 阿里云, 零一万物, 收购传闻, 大模型  
<br><br>  
总结: 阿里云与零一万物的收购传闻引发了行业讨论，但零一万物官方对此进行了否认，并重申了与阿里云的合作关系。零一万物近期启动了“产业大模型实验室”，旨在推动大模型技术的应用落地。尽管公司面临经营危机和资金紧张的挑战，零一万物仍在积极调整战略，聚焦于应用落地和业务增长。行业内大模型企业的融资情况不容乐观，市场正在经历洗牌，未来发展充满不确定性。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_2111970e27d344ab810a81cdff315aec@1883322323_oswg24203oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>1月6日据第一财经报道，阿里云正在洽谈收购零一万物的预训练团队，引发业内讨论。但是该消息很快被零一万物官方辟谣。&nbsp;</p>
  <p>零一万物在官方声明中明确指出<strong>“针对传言零一万物将被收购、经营问题等不实言论属于恶性中伤，公司予以否认。”&nbsp;</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_c478e91b64244727a5db5d9283e42ecd@1883322323_oswg179946oswg386oswg834_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据披露，1月2日，零一万物刚与阿里云联合宣布启动“产业大模型实验室”，目的不仅在于提供世界第一梯队的基座模型，还着眼于将大模型能力带入真实行业场景，加速产业大模型落地及应用生态扩大，助力各行各业大模型落地。&nbsp;</p>
  <p>李开复本人也在其朋友圈对收购传闻进行了回应，再次强调了零一万物与阿里云的合作关系，并表达了对未来行业发展的期待。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_7480a16319834657889cbaa051a2cf03@1883322323_oswg218291oswg832oswg548_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>实际上，这不是零一万物第一次爆发经营危机。早在2024年10月中旬，李开复就曾发文为零一万物辟谣，称：“网上有数篇自媒体说国内大模型公司有几家放弃预训练了，还有说零一万物是其中一家。在此正式辟谣：零一万物一直在做预训练，去年和今年发布的Yi-34B，Yi-Large，Yi-Coder， Yi-VL，Yi-Vision都是发布时全球第一梯队，国内领先的预训练模型。而且我们的新预训练模型也即将推出，也会是全球第一梯队，国内领先。届时谣言不攻自破。建议自媒体可以先删稿。”&nbsp;</p>
  <p>紧随其后，零一万物发布了全球SOTA的新旗舰模型Yi-Lightning，11月又对外披露基于Yi模型构建的一整套大模型ToB解决方案。&nbsp;</p>
  <p>零一万物曾公开表示Yi-Lightning以其低至每百万token不到0.14美元的推理成本，实现了大模型技术的可负担性，成本显著低于国外模型的标准。并且国内解决方案的商业化方向较为清晰，营收与订单也是板上钉钉。&nbsp;</p>
  <p>与此同时，整个2024年下半年，零一万物调整频频， 在方向上改聚焦于应用落地及业务加速增长。在组织人员上，零一万物已有包括黄文灏、曹大鹏在内的多位联合创始人、产品负责人离职。&nbsp;</p>
  <p>这或许只是一个开始。过去一年多，大模型六小虎（包括智谱、MiniMax、月之暗面、百川智能、零一万物和阶跃星辰）是创业赛道最闪耀的明星。但到了今年下半年，形势正在悄然生变。据了解，目前除智谱与阶跃星辰融资节奏较好外，多家大模型企业均出现资金链吃紧情况，头部独角兽也不例外。&nbsp;</p>
  <p><strong>据凤凰网科技了解，零一万物最近的自救动作频频，包括与地方国资密切接触，希望得到地方大模型扶持平台的支持，并计划在当地设立独立的分公司，“但具体是哪块业务并不清楚”，一位行业相关人士表示。从目前的结果看来，这一计划进行的并不顺利。</strong></p>
  <p>另据36氪旗下《智能涌现》报道，2024年12月中旬，零一万物对整个预训练算法团队和Infra团队进行了裁撤。当月末零一万物预训练算法团队获得通义团队offer，Infra团队则获得阿里云offer，是以提供工作岗位的形式而非收购。此外，该报道还称，李开复曾在近期的内部会议上提到，零一万物资金紧张，预训练投入的资金比较大，公司计划转型做应用。&nbsp;</p>
  <p>凤凰网科技同样了解到，零一万物的公司经营近期不会发生太大变化，海外的C端应用与国内市场的2B业务仍会继续，但预训练团队的确受到了一定影响。&nbsp;</p>
  <p>当前，随着人工智能技术的迅速发展，各大企业纷纷投入资源研发自己的大型语言模型。从目前的市场动态来看，大模型生态正在经历一场全新的洗牌。在这一过程中，进入市场的产品多样化与日俱增，但并非所有模型都能赢得市场青睐。作为业内翘楚的大规模六小虎，又会何去何从？</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/3gtyLhT5VLdXOLdtcpkkzg" rel="noopener noreferrer nofollow" target="_blank">“凤凰网科技”</a>，作者：梁思琦，编辑：董雨晴，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112345184653056</id>
            <title>黄仁勋变身美队，皮衣开光追，最强卡皇5090登场，全世界玩家都疯狂了</title>
            <link>https://www.36kr.com/p/3112345184653056</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112345184653056</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:14:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: RTX 5090, AI算力, 光线追踪, 代理型AI  
<br><br>  
总结: 英伟达在CES 2025上正式发布了备受期待的RTX 5090显卡，具备920亿颗晶体管和高达3352TOPS的AI算力，性能是RTX 4090的两倍。新显卡支持FP4精度，显著提升AI图像生成性能，并引入DLSS 4技术。黄仁勋还展示了全球最小的AI超级计算机Project DIGITS，能够运行2000亿参数的AI模型。此外，英伟达推出了多款基础模型和AI Blueprint，旨在推动代理型AI的发展，助力各行业的智能化转型。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_f80688f1b38c49a59d2da737ddc3cf43@000000_oswg219031oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>备受期待的卡皇<strong>RTX 5090</strong>，终于正式发布！&nbsp;</p>
  <p>智东西拉斯维加斯1月6日报道，今日，在年度“科技风向标”国际消费电子展（CES 2025）开幕前夕，英伟达创始人兼CEO黄仁勋发表主题演讲，智东西作为受邀媒体从现场发来报道。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0c21ae6054694b379fcaefa9a0d704b5@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>“皮衣老黄”不愧是科技圈顶流，演讲火爆程度堪比热门明星演唱会，开场前2个半小时门外已经排起长队。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_9681e0dcb1204882a882b77a9bf7d655@000000_oswg79813oswg1000oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>18:42，热场音乐戛然而止，会场霎时从人声鼎沸转为屏息凝神，一段开场视频后，黄仁勋穿了件闪亮的新皮衣，意气风发地走上演讲台，与现场观众寒暄。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_d0ff78d4e1504fbdb332c4628ffbe8d2@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网友调侃老黄的皮衣简直“开了光追”。&nbsp;</p>
  <p>皮衣开光追是假，但新显卡GeForce RTX 50系列的光追是实打实的强。黄仁勋称Blackwell融合了AI驱动的神经网络渲染和光线追踪，是英伟达自25年前推出可编程着色技术以来最重要的计算机图形创新。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_f7f600c0a6194ac188f4f80a312432b3@000000_oswg64354oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>新一代旗舰显卡RTX 5090无疑是年度重头戏之一。RTX 5090拥有920亿颗晶体管，AI算力最高达3352TOPS ，性能达到RTX 4090 D GPU的2倍（得益于架构创新和DLSS 4）。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0a1088878ce54d6eba06dff613df43ef@000000_oswg59854oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>演讲期间宣布的RTX 5090售价1999美元，RTX 5080售价999美元，RTX 5070Ti售价749美元，RTX 5070只卖549美元。&nbsp;</p>
  <p>对于国内台式机用户，拥有2375 AI TOPS的RTX 5090 D售价<strong>16499元</strong>，拥有1801 AI TOPS的RTX 5080售价<strong>8299元</strong>，将于1月30日上市。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_5b86213132f246d8923873e013d9b7cd@000000_oswg49686oswg1000oswg304_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>拥有1406 AI TOPS的RTX 5070 Ti建议零售价为<strong>749美元</strong>，拥有988 AI TOPS的RTX 5070建议零售价为<strong>549美元</strong>，产品将于2月上市。5080和5070Founders Edition京东在售。&nbsp;</p>
  <p>RTX 5090、RTX 5080、RTX 5070 Ti笔记本电脑将于3月上市，RTX 5070笔记本电脑将于4月由全球领先OEM发售。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0b6151e6db4f4470989186014e6414e6@000000_oswg81895oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为英伟达2025年第一场重磅发布活动，猛料当然不能只有消费级显卡。&nbsp;</p>
  <p>光是在硬件上，黄仁勋就接连整活儿，先搬出一个由72块Blackwell GPU组成的NVLink72巨型“盾牌”，并现场cosplay起美国队长，引起现场观众的欢呼。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_9f065720f9df4af9baa25e1f6ada1de5@000000_oswg420021oswg1000oswg548_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>黄仁勋也现场揭晓了这块“盾牌”里的核心参数。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_a27008eb05014dbab5983023b43e2a1e@000000_oswg93929oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>还晒出Blackwell全系照片。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_cfe46cfa3fcd45da8525b1f64d593f66@000000_oswg589034oswg1000oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在最后的One More Thing环节，黄仁勋发布单手可持的<strong>全球最小AI超级计算机Project DIGITS</strong>，搭载全新GB10超级芯片，小到能塞进口袋里，堪称“掌上超算”。如果将两台相连，能跑<strong>4050亿</strong>个参数的AI模型，<strong>3000美元</strong>起售。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ce22ea194903435a8095f9dc9aceb694@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，黄仁勋连珠炮般亮出一大波全新<strong>基础模型</strong>，以及面向<strong>AI agents</strong>、<strong>物理AI</strong>、<strong>人形机器人</strong>、<strong>自动驾驶</strong>的多款新品。&nbsp;</p>
  <p>作为科技圈知名“预言家”，黄仁勋对AI的前瞻性判断，对接下来科技产业走向极具参考价值。&nbsp;</p>
  <p>他判断在感知AI、生成式AI后，AI浪潮的下一站是<strong>代理型AI（Agentic AI）</strong>，再之后是<strong>物理AI（Physical AI）</strong>。黄仁勋相信，机器人的ChatGPT时刻即将到来，而<strong>世界基础模型</strong>对于推进机器人和自动驾驶汽车的开发至关重要。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_14f239a0f6f74f7cb1eb84df5a548be8@000000_oswg93809oswg1000oswg677_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>黄仁勋还现场公布了一些人形机器人、自动驾驶汽车合作厂商。其国内人形机器人合作伙伴有星动纪元、智元、傅里叶、银河通用、宇树科技、小鹏等，国内自动驾驶合作伙伴有<strong>比亚迪、理想、蔚来、小米、极氪</strong>等。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_b3768240f64c4866b9897bc5d7979b45@000000_oswg50422oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>01.RTX 50系列显卡来了！首度支持FP4精度，AI性能翻倍提升</strong></h2>
  <p>英伟达GeForce RTX 50系列是<strong>第一款支持FP4精度</strong>的消费类GPU，将FLUX等模型的AI图像生成性能提高到上一代硬件的<strong>2倍</strong>，并能在更小的显存占用中本地运行。&nbsp;</p>
  <p>该系列GPU还内置第九代NVIDIA编码器，用于高级视频编辑，支持4:2:2专业级色彩格式，并配备DLSS 4和<strong>32GB VRAM</strong>，以解决大规模的3D项目。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0e6b43add1ea4fe2ad6ab3b1a6d74698@000000_oswg74330oswg1000oswg637_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>RTX 50系列采用Blackwell架构、第五代Tensor Cores、第四代RT Cores，在AI渲染领域，包括神经网络着色器、数字人技术、几何图形和光照等方面取得突破。&nbsp;</p>
  <p>基于Blackwell架构的NVIDIA Max-Q技术最高可延长电池续航时间达<strong>40%</strong>。</p>
  <p>DLSS 4首次推出<strong>多帧生成</strong>技术，借助AI可为每个渲染帧生成多达<strong>3帧</strong>，从而进一步提高帧率。该技术可与全套DLSS技术协同运行，相比传统渲染技术相比，性能提升高达<strong>8倍</strong>，同时通过NVIDIA Reflex技术保证响应速度。</p>
  <p>DLSS 4还引入了图形行业<strong>第一个实时应用的Transformer模型架构</strong>。基于Transformer的DLSS超分辨率和光纤重建模型有<strong>2倍</strong>的参数量和<strong>4倍</strong>以上的计算量，可提高画面稳定性，减少伪影，增加细节并增强抗锯齿效果。&nbsp;</p>
  <p>超过<strong>75款</strong>游戏和应用程序将在RTX 50系列上支持DLSS 4。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_bea23951cfa743938897d7ddef07787c@000000_oswg39224oswg1000oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，NVIDIA Reflex 2引入了<strong>Frame Warp</strong>创新技术，可在将渲染帧发送至显示器前，根据最新的鼠标输入信号对其进行更新，从而降低游戏延迟，相比原生渲染最高可减少<strong>75%</strong>的延迟，提高游戏响应速度。&nbsp;</p>
  <p>英伟达还推出了<strong>RTX神经网络着色器</strong>（RTX Neural Shaders），将小型AI网络融入可编程着色器，为实时游戏带来电影级的材质、光照等。&nbsp;</p>
  <p><strong>RTX Neural Faces</strong>只需使用简单的光栅化面孔和3D面部姿态数据作为输入，即可使用生成式AI实时渲染具有时间稳定性的逼真面孔，配备了全新的支持光线追踪毛发和皮肤的 RTX技术。全新RTX Mega Geometry可将场景中的光线追踪三角形数量至多增加<strong>100倍</strong>，提升游戏角色及环境真实感。&nbsp;</p>
  <p>RTX 50系列的出色AI算力能够在游戏渲染的同时为自主游戏角色提供动力。英伟达推出了一套<strong>新ACE技术</strong>，使游戏角色能够像人类玩家一样感知、计划和行动。由ACE驱动的自主角色被整合到《绝地求生》和即将推出的生活模拟游戏《InZOI》，以及Wemade Next的《MIR5》中。&nbsp;</p>
  <p>NVIDIA Broadcast应用为主播带来两项AI驱动功能：可升级麦克风音频质量的<strong>音棚音效（Studio Voice）</strong>，可对面部重新打光的<strong>虚拟补光 （Virtual Key Light）</strong>。&nbsp;</p>
  <p>Streamlabs推出由NVIDIA ACE和Inworld驱动的智能直播助手，担任助播、制作和技术助手的角色以增强直播效果。&nbsp;</p>
  <h2><strong>02.RTX AI PC本地可跑基础模型，公开具有视觉能力的PC虚拟化身</strong></h2>
  <p>英伟达还发布了可在<strong>RTX AI PC</strong>本地运行的基础模型。这些模型作为NIM微服务提供，由RTX 50系列GPU加速。&nbsp;</p>
  <p>适配RTX AI PC的AI基础模型涵盖大语言模型、视觉语言模型、图像生成模型、语音模型、检索增强生成（RAG）的嵌入模型、PDF提取和计算机视觉模型等。&nbsp;</p>
  <p>NIM微服务及PC上运行AI的所有必要组件均已针对所有英伟达GPU的部署进行了优化。</p>
  <p>黄仁勋提到英伟达想将AI放到PC上，希望让Windows PC成为世界级的AI PC，而一个方法是Windows WSL 2（Windows Subsystem for Linux 2），它有两个操作系统，针对云原生应用程序进行了优化，开箱即用。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3169643a1ca44b19ab25e2afc79bbcb9@000000_oswg69915oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为了展示如何使用NIM构建AI agent和助手，英伟达将发布来自Black Forest Labs、Meta、Mistral、Stability AI等顶级开发商的一系列NIM微服务和RTX AI PC的AI Blueprint。&nbsp;</p>
  <p>英伟达还推出了一款具有视觉能力的PC虚拟化身<strong>Project R2X</strong>。它能够让信息触手可及，协助用户使用桌面应用、视频电话会议、阅读和总结文档等。R2X将在数月内向RTX50系列和笔记本电脑用户开放下载。&nbsp;</p>
  <h2><strong>03.全球最小AI超级计算机：搭载GB10超级芯片，能跑2000亿参数模型</strong></h2>
  <p>为了让AI超算能摆到每个人的桌上，英伟达发布<strong>全球最小AI超级计算机Project DIGITS</strong>，能跑<strong>2000亿</strong>个参数的AI模型。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_04cb9a531c69456bb333ee42861645ea@000000_oswg198247oswg1000oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>两台Project DIGITS可通过NVIDIA ConnectX网络连接，运行多达<strong>4050亿</strong>个参数的AI模型。&nbsp;</p>
  <p>这相当于是台掌上AI超算，采用了全新的<strong>GB10 Grace Blackwell超级芯片</strong>。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_1b5b0f6bf9cb46af8cd3fa89cc9da9d3@000000_oswg313374oswg1000oswg554_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>GB10由英伟达和联发科合作设计，通过NVLink-C2C互连技术将Blackwell GPU和有20个Arm能效核的Grace CPU连接，可在FP4精度下提供多达<strong>1PFLOPS</strong>的AI算力。&nbsp;</p>
  <p>每台Project DIGITS拥有<strong>128GB</strong>的高带宽统一内存和高达<strong>4TB</strong>的NVMe存储。&nbsp;</p>
  <p>Project DIGITS将于5月推出，<strong>3000美元（约合人民币2.2万元）</strong>起售。&nbsp;</p>
  <h2><strong>04.新模型、新AI&nbsp;Blueprint，支持快速创建AI agents</strong></h2>
  <p>英伟达判断代理型AI代表了生成式AI进化的下一波浪潮，使AI能解决复杂的多步骤问题、复杂推理和规划。&nbsp;</p>
  <p>对此，英伟达推出了<strong>Llama Nemotron系列开放许可的基础模型</strong>，为AI agents开发提供优化的构建模块：&nbsp;</p>
  <p><strong>1）Nano（4B）</strong>：最具成本效益的模型，针对低延迟的实时应用程序进行了优化，非常适合部署在PC和边缘设备上；&nbsp;</p>
  <p><strong>2）Super（49B）</strong>：在单个GPU上提供卓越吞吐量的高精度模型；&nbsp;</p>
  <p><strong>3）Ultra（253B）</strong>：精度最高的型号，专为要求最高性能的数据中心规模应用而设计。&nbsp;</p>
  <p>这些模型基于Llama构建，可帮助开发人员在一系列应用程序中创建和部署AI agent，包括客户支持、欺诈检测、产品供应链和库存管理优化。&nbsp;</p>
  <p>Llama Nemotron模型使用英伟达最新技术和高质量数据集进行蒸馏、修剪和训练，使模型足够小，能在各种计算平台上运行，同时提供高精度和增加的模型吞吐量，增强了agent能力，擅长指令遵循、聊天、函数调用、编程和数学。&nbsp;</p>
  <p>除了新模型外，英伟达与合作伙伴推出了多款<strong>生成式AI&nbsp;Blueprint</strong>，用于降低企业级AI agents的开发门槛。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_a2a99f871c414a528964ab094314d6bd@000000_oswg60292oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英伟达将AI Blueprint称作“<strong>构建AI agents的起点</strong>”，目标使全球2500万名软件开发人员能轻松将AI集成到各行业的应用程序中，为超10亿的知识工作者构建agents。&nbsp;</p>
  <p>AI Blueprint提供NVIDIA NIM微服务、NeMo和代理型AI框架，可实现AI agents的编排、管理和可追溯性。只需点击一下，开发人员就能构建和运行新的代理型AI Blueprint。&nbsp;</p>
  <p>有了AI Blueprint，开发人员可以构建和部署能做推理、规划的自定义AI agent并采取行动，并采取行动快速分析大量数据，从视频、PDF及图像中总结和提取实时见解。&nbsp;</p>
  <p>要管理、监控、协调多个AI agents一起工作，对编排系统提出很高要求。英伟达与CrewAI、Daily、LangChain、LlamaIndex、Weights &amp; Biases五家代理型AI编排和管理工具供应商合作构建AI Blueprint，用于软件开发、实时语音对话、结构化报告生成、博客创建、AI虚拟助手等。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_f5a75cff73d9430a967cd59dc6fad11d@000000_oswg90423oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英伟达还推出了自家的两个AI Blueprint：&nbsp;</p>
  <p>一个用于<strong>PDF转播客</strong>，将复杂PDF文件轻松转换成好理解的、用自然声音叙述的对话式播客。&nbsp;</p>
  <p>另一个用于<strong>视频搜索和总结</strong>，构建于Metropolis平台上，由Cosmos Nemotron视觉语言模型、Llama Nemotron大语言模型和NeMo Retriever进行强化，提供了构建和部署可分析大量视频和图像内容的AI agents的工具。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_07e6303b6de94db58a929420bfff9675@000000_oswg266402oswg1000oswg622_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为了帮助企业快速将AI agents投入生产，埃森哲宣布用NVIDIA AI Enterprise构建AI Refinery，包括NVIDIA NeMo、NVIDIA NIM微服务和AI Blueprint。埃森哲计划在今年年底前推出100多个AI Refinery行业agent解决方案。&nbsp;</p>
  <p>埃森哲与英伟达合作构建了<strong>12个全新行业agents解决方案</strong>，涉及公共部门招聘、电信代理协助联络中心、保险理赔承保、银行遗留现代化、消费品和服务的收入增长管理、生命科学临床试验伙伴、工业资产故障排除和B2B营销等。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_d130f817e9104541b709b1330b2d089a@000000_oswg95784oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>05.世界基础模型开发平台Cosmos：为先进物理AI而生</strong></h2>
  <p>物理AI将改变价值50万亿美元的产业，涉及1000亿的工厂、20万的仓库、未来数十亿计的人形机器人和15亿的汽车及卡车。&nbsp;</p>
  <p>自动驾驶汽车的发展由三种不同的计算机实现：1）<strong>DGX系统</strong>用于在数据中心训练基于AI的堆栈；2）在<strong>OVX系统</strong>上运行Omniverse用于模拟和合成数据生成；3）<strong>AGX车载计算机</strong>用于处理实时传感器数据以确保安全。&nbsp;</p>
  <p>这三款计算机同样被用来构建物理AI，在此基础上，英伟达今日发布了又一新组成部分——<strong>世界基础模型开发平台Cosmos。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_e4ee3fafdec1480abe10a82d3b984da0@000000_oswg74722oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Cosmos拥有一套开放的<strong>扩散和自回归模型</strong>，还有先进的视频tokenizer、护栏和加速数据处理流程，专为开发机器人和自动驾驶而设计，旨在加速先进物理AI开发。&nbsp;</p>
  <p>这些模型接受了18000万亿次tokens的训练，包括2000万小时的真实世界自动驾驶、机器人、无人机镜头和合成数据。模型也有3款：&nbsp;</p>
  <p><strong>1）Nano（约15B）</strong>：针对实时、低延迟推理和边缘部署进行了优化；&nbsp;</p>
  <p><strong>2）Super（34B）</strong>：用于高性能基线模型；&nbsp;</p>
  <p><strong>3）Ultra（约70B）</strong>：以获得最大的质量和保真度，最适合用于提取定制模型。&nbsp;</p>
  <p>当与Omniverse 3D输出配对时，扩散模型生成可控的、高质量的合成视频数据，以引导机器人和自动驾驶感知模型的训练。自回归模型根据输入帧和文本预测视频帧序列中接下来应该出现的内容，使实时预测下一个token成为可能。&nbsp;</p>
  <p>开发人员可使用这些开放模型，从文本、图像、视频等输入以及机器人传感器或运动数据的组合中生成基于物理的视频，也可以用其生成合成数据以增强训练数据集，还可以通过微调这些世界基础模型来构建定制模型。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_fbc4a99d9dfe445f8551207e14e60eb8@000000_oswg85469oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其他模型包括：<strong>120亿参数上采样模型</strong>，用于精炼文本提示；<strong>70亿参数视频解码器</strong>，用于优化增强现实；<strong>护栏模型</strong>，确保可靠、安全地使用。&nbsp;</p>
  <p>相比最先进的方法，Cosmos的<strong>tokenizers</strong>提供8倍的总压缩和12倍的处理速度，在训练和推理方面提供了更出色的质量和更低的计算成本。&nbsp;</p>
  <p>Omniverse和Cosmos世界基础模型相结合，使开发人员能够更轻松地生成大量可控、逼真的合成数据，帮助物理AI模型做出更好的行动，还有助于减少世界模型相关的潜在幻觉。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_fa670eb0b36f4125ba51672f33a35599@000000_oswg279685oswg1000oswg470_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>1X、Agile Robots、Agility Robotics、Figure AI、小鹏、Foretellix、Uber、Waabi、Wayve等都采用Cosmos加速和加强模型开发。&nbsp;</p>
  <h2><strong>06.Omnvierse Blueprint：助攻人形机器人、Vision Pro和自动驾驶仿真</strong></h2>
  <p>此外，英伟达发布了<strong>Isaac GR00T合成运动生成Blueprint</strong>，用于帮助开发人员从少量人类演示中生成指数级大的合成数据集，以使用模仿学习训练人形机器人。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_5e11cbd966314e2889dd5dc3c1b08ab3@000000_oswg91280oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>波士顿动力、Figure等人形机器人公司已经开始采用并展示Isaac GR00T的结果。&nbsp;</p>
  <p>英伟达还发布了<strong>4个全新Omniverse&nbsp;Blueprint</strong>，使开发人员更容易为物理AI构建基于OpenUSD（通用场景描述）的数字孪生，包括：&nbsp;</p>
  <p>1）<strong>Mega工业机器人队列数字孪生</strong>：由Omniverse Sensor RTX API提供支持，用于在部署到现实世界的设施之前，在数字孪生中大规模开发、测试和优化物理AI和机器人队列。&nbsp;</p>
  <p><strong>2）自动驾驶汽车仿真</strong>：由Omniverse Sensor RTX API提供支持，使自动驾驶汽车开发人员可以回放驾驶数据，生成新的地面真实数据并执行闭环测试，以加速其开发管道。&nbsp;</p>
  <p><strong>3）面向苹果Vision Pro的Omniverse空间流播</strong>：帮助开发人员创建面向苹果Vision Pro大规模工业数字孪生沉浸式流播的应用程序。&nbsp;</p>
  <p><strong>4）面向计算机辅助工程（CAE）的实时数字孪生</strong>：基于NVIDIA CUDA-X加速、物理AI和Omniverse库构建的参考工作流，可实现实时物理可视化。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_44401399c21d4459b24e56c9f00c7506@000000_oswg132511oswg1000oswg501_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中Mega为企业提供包含NVIDIA加速计算、AI、Isaac和Omniverse技术的参考架构，用于开发和测试数字孪生，用于测试驱动机器人、视频分析AI agents、设备等的AI驱动机器人大脑，以处理巨大的复杂性和规模。&nbsp;</p>
  <p>Omniverse Cloud Sensor RTX API支持物理上精确的传感器模拟，以大规模生成数据集，现可供选择的开发人员早期访问。Mega便集成了该API，使机器人开发人员能同时渲染来自工厂中任何类型的智能机器传感器数据，以实现高保真度的大规模传感器模拟。&nbsp;</p>
  <p>汽车方面，英伟达新一代智驾芯片<strong>DRIVE AGX Thor</strong>的算力是上一代的<strong>20倍</strong>，还可以用于人形机器人。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0f55ef0cbf0345a4a8ae304fbcab5d09@000000_oswg436547oswg1000oswg488_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其自动驾驶汽车平台NVIDIA DRIVE AGX Hyperion已通过由业内两大权威机构TÜV SÜD和TÜV Rheinland的行业安全认证。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_ae57563d99ee4354a3b678aaca10a29a@000000_oswg290169oswg1000oswg572_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DRIVE Hyperon是业界首个也是唯一一个端到端自动驾驶系统平台，包括DRIVE AGX SoC和参考板设计、英伟达DriveOS汽车操作系统、传感器套件以及主动安全和L2+软件栈。&nbsp;</p>
  <p>NVIDIA DRIVE AI系统检测实验室获得了美国国家认证委员会的认证，可以为自动驾驶汽车进行功能安全、网络安全和AI方面的检查。&nbsp;</p>
  <p>作为全球最大汽车制造商，丰田将在下一代汽车中采用DRIVE AGX Orin SoC并运行安全认证的DriveOS操作系统。&nbsp;</p>
  <p>Aurora、大陆和英伟达本周还宣布了一项长期战略合作伙伴关系，以大规模部署由英伟达DRIVE驱动的无人驾驶卡车。&nbsp;</p>
  <p>英伟达预计其汽车垂直业务将在2026财年增长到约<strong>50亿美元</strong>。&nbsp;</p>
  <h2><strong>07.结语：将“AI信仰”进行到底</strong></h2>
  <p>每年的CES都起到科技风向标的作用，而英伟达近两年堪称是AI计算产业的北极星。在此次主题演讲中，英伟达除了向消费者交出被期待已久的旗舰显卡外，也相当阔气地继续大秀AI组合拳——从GPU、AI PC、AI超算到云端，从生成式AI、AI agents、物理AI、机器人到自动驾驶。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_481023f863c84107b8e9302344c6f5d0@000000_oswg76574oswg1000oswg753_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>按照英伟达的划分，计算范式已从手搓代码+“检索+CPU+软件1.0”时代的转变向由机器学习主导的“生成+GPU+软件2.0”时代。RTX AI PC已经让访问部署最新生成式AI模型变得越来越随手可得。接下来企业级AI agents将成为AI工厂的核心，通过生成tokens，在各行各业创造前所未有的智能和生产力。&nbsp;</p>
  <p>再往后，物理AI将成为下一波AI浪潮，将所有移动的东西都由AI实现机器人化，机器将依靠物理AI世界基础模型来理解现实世界并与之互动，而汽车将成为最大的AI和机器人产业之一。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652778312&amp;idx=1&amp;sn=cb3fd1fc3c7849ad28f234df91ee4d9f&amp;chksm=850e61c0155e6358ac1ebb480d2c42f0a372fdcbe79e095b85ba1e33f6577cda8b51a02b7ad5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：ZeR0 骏达，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112353389579785</id>
            <title>核心团队疑似生变的剪映，能否帮字节拿下AI时代的船票？</title>
            <link>https://www.36kr.com/p/3112353389579785</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112353389579785</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:11:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <剪映, 张楠, 人事变动, AI技术>
<br>
<br>
总结: 张楠宣布辞去抖音集团CEO职务，全心投入剪映和CapCut业务。剪映自2019年推出以来，凭借其易操作性迅速成为国内视频编辑工具的领头羊，并在全球范围内获得成功。然而，核心团队成员张逍然和王学智的离职传闻引发了对剪映未来发展的关注。随着AI技术的应用，剪映逐渐从用户生成内容的工具转变为专业创作者的必备工具。字节跳动计划将剪映打造成AI时代的重要产品，未来发展值得期待。 </div>
                        <hr>
                    
                    <p>“我期待着与剪映的团队成员共同编织梦想，在这个由AI引领的时代中共同成长，携手在创意的画布上描绘出我们心中的奇妙世界。”2024年2月，龙年春节前，张楠（女）在其个人微信朋友圈宣布，辞去抖音集团CEO的职位，将全心投入至剪映和CapCut（剪映海外版）业务。</p>
  <p>剪映，最初作为抖音的官方剪辑应用于2019年推出，自上线以来，便以低门槛、易操作的特性深受用户喜爱，如今已稳坐国内移动视频编辑工具的头把交椅。2020年，剪映海外版本CapCut的推出，更是让其在全球范围内崭露头角。根据非凡产研发布的全球AI APP下载榜，2024年10月，剪映以3712万的下载量位居榜单第二，仅次于ChatGPT。</p>
  <p>然而，就在张楠成为剪映负责人不到一年，剪映业务突飞猛进之际，其核心团队却传出了变动的消息。最近，有消息称，字节跳动旗下剪映产品负责人张逍然已经离职，而技术负责人王学智也即将离开。根据相关媒体报道，字节跳动的员工透露，王学智在飞书系统上的状态标注为“请假”，假期将持续至2025年4月30日；张逍然的页面则显示为“暂停使用”。该员工解释称，“暂停使用”通常意味着权限已被收回。</p>
  <p>截至目前，字节跳动官方尚未就剪映的上述人事变动发表正式回应。</p>
  <h2><strong>核心成员“淡出”？</strong></h2>
  <p>如果上述人事变动传闻属实，这将意味着剪映的核心技术团队正在经历一场洗牌。</p>
  <p>公开履历显示，张逍然毕业于武汉科技大学、香港中文大学，是剪映前身业务脸萌的早期成员，随着脸萌被字节收购而加入字节。从2021年底开始，就负责剪映、醒图、CapCut等等产品在内的整体产品和业务，经历了剪映的早期和高速发展期。2024年初，原抖音CEO张楠宣布离开抖音，带队剪映及CapCut业务后，张逍然的工作就直接向张楠汇报。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_e3b44854c03b4b31ab7c77f4c293cbdc@000000_oswg35239oswg876oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>王学智的经历与张逍然颇为相似。2012年，他从四川大学软件学院毕业，随后在腾讯担任手机QQ客户端开发工程师。2016年，他加入由前同事郭列创立的脸萌，并参与了Faceu激萌的开发工作。2018年，随着团队被字节跳动以约3亿美元的价格全资收购，王学智也加入了字节跳动。</p>
  <p>谈及剪映，不得不提及一位关键人物——1989年出生的Faceu激萌创始人郭列。2011年，郭列从华中科技大学毕业后加入了腾讯，2年后郭列离开腾讯自主创业并在2013年底上线第一款产品App脸萌，紧接着，2016年1月，第二款产品Faceu面世，后来，这两款产品合并成为Faceu激萌。</p>
  <p>Faceu激萌的独到之处在于，它利用人脸识别技术，将“拍摄”与“编辑处理”完美融合，实现了实时美颜和动态贴纸的添加，以其呆萌可爱的风格深深吸引了90后和00后的用户群体。2017年10月，郭列在接受媒体采访时透露，激萌的累计下载用户已超过2.5亿，其中女性用户占比高达75%，而通过QQ账号登录的用户中，00后（包括小学生、初中生和高中生）的占比更是超过了70%。</p>
  <p>正是在2017年，Faceu激萌完成了5000万美元的新一轮融资，当时官方并未披露领投方的身份。到了2018年初，字节跳动以约3亿美元的总价全资收购了Faceu激萌。彼时，郭列和团队一起加入字节，随后一年郭列转为公司顾问，逐渐淡出。</p>
  <p>2019年，字节跳动在FaceU激萌的基础上，建立了影像中台，包括相机特效中台等，郭列曾经的副手刘佳彬，担任影像中台负责人。此后，这个团队开发出了轻颜相机，剪映等产品，成为字节在图片处理和短视频内容生产领域的核心阵地。其中2019年5月，剪映移动端正式上线。时至2022年，随着刘佳彬的离职，王学智和张逍然逐渐成长为影像中台的技术和产品负责人。2024年2月，张楠转岗到剪映后，张逍然则直接向张楠汇报工作。</p>
  <p>而据最新传闻，王学智目前正与多家风险投资机构进行接触，这引发了外界对他是否要“另起炉灶”的猜测。同时，也有消息称他可能会加入郭列的新项目。</p>
  <p>实际上，去年至今，字节跳动堪称组织架构调整最为频繁的大型企业之一。去年1月底的全员会议上，字节集团CEO梁汝波表示，字节需要有“危机感”，在新的一年里字节会继续执行“去肥增瘦”的改革，以解决“大公司病”，保持公司“创业精神”。</p>
  <p>之后，各种人事调整接踵而至，2024年1月，曾任西瓜视频总裁任利锋被爆出离职消息，并开启创业之路；2月，张楠不再担任抖音集团CEO；3月，长期负责字节游戏业务的严授转岗至财务部；6月，飞书总裁张楠（男）因个人原因卸任......</p>
  <p>作为抖音业务单元（BU）旗下的剪映，自然也未能幸免。一些剪映员工在社交媒体上纷纷反映，在过去一年中，随着领导层的频繁更迭，他们也不得不面对业务不断进行调整的压力。</p>
  <h2><strong>字节AI的“新欢”？</strong></h2>
  <p>随着创始团队核心人物的变动，业界对字节跳动视频剪辑业务的未来发展产生了广泛关注。毕竟，作为国内规模最大的视频剪辑工具产品，剪映在字节跳动的整体战略布局中占据着举足轻重的地位。</p>
  <p>2024年12月，据界面报道，剪映和CapCut在2024年实现了超过三位数的收入增长，总收入正接近百亿元。同时，剪映和CapCut的全球月活用户合计已经超过8亿。</p>
  <p>在诞生之初，剪映被视为一个依附于抖音的工具App，通过提供剪辑模板和丰富的素材库，降低了短视频UGC（用户生成内容）的创作门槛。然而，随着产品迭代和功能的不断增强，剪映逐渐成长为中长视频PGC（专业生产内容）创作者，甚至是专业影视从业人员的必备生产力工具之一，截至目前，剪映已完成了从个人用户、专业用户到企业的用户覆盖。</p>
  <p>近两年来，生成式AI的浪潮首先席卷了内容创作领域。内容生成作为大模型技术应用的核心场景之一，而AI视频生成更是成为了各方竞相角逐的“战略要地”。剪映是字节系产品中最早落地AI技术、覆盖范围最广的产品之一。</p>
  <p>目前，剪映已经推出了多种多样的AI功能，包括数字人、AI智能口播剪辑、文生图等。</p>
  <p>2024年5月，即在张楠专门负责剪映和CapCut业务三个月后，剪映便上线了AI视频应用“即梦”，支持通过自然语言及图片输入，生成高质量的图像及视频。平台提供智能画布、故事创作模式，以及首尾帧、对口型、运镜控制、速度控制等AI编辑能力，并有海量影像灵感及兴趣社区，一站式提供用户创意灵感、流畅工作流、社区交互等资源。</p>
  <p>2024年7月，张楠首次作为剪映负责人公开现身，她表示，抖音，是一个“真实世界”的相机，借助GenAI技术，即梦希望成为想象力世界的相机，记录每个人的奇思妙想，帮助每个有想法的人轻松表达、自由创作。</p>
  <p>“借助GenAI的技术，画面可以瞬间被呈现在眼前，这种极其简单的方式，可以把每个人脑子里的奇思妙想快速视觉化，像做梦一样，”张楠说，“而这种感觉也是‘即梦’这个产品和名字的由来。”</p>
  <p>同是2024年12月，市场传闻，字节跳动打算尝试用新的路径打造“AI时代的抖音”，而剪映和即梦所在项目组，已经力压豆包，成了字节在AI领域的最优先级工程，在未来，即梦的形态有可能会是一个面向游戏、视频、Metaworld的大应用。</p>
  <p>据相关知情人士称，此举是因为字节跳动管理层判断“AI对话类”产品可能只是AI产品的“中间态”，长期更理想的产品形式大概率需要更视觉化的用户体验和更低的用户使用门槛。</p>
  <p>那么，剪映能否帮字节跳动拿下AI时代的船票，还需时间来检验。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU3ODQ5MjQzMQ==&amp;mid=2247574255&amp;idx=1&amp;sn=d4c5d6b51cc2f556b2b067f1f07327e1&amp;chksm=fcef95a4084bed611275c6cdf603ed9f208ea03af18042054436f78f1a8648a69633b547cd87&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“鳌头财经”（ID：theSankei）</a>，作者：张飞涛，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112418862731017</id>
            <title>微信悄悄加码图文</title>
            <link>https://www.36kr.com/p/3112418862731017</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112418862731017</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 09:01:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微信, 公众号, 推荐功能, 社交推荐  
<br><br>  
总结: 微信正在对公众号文章页面的“在看”功能进行更新，推出“推荐”功能，将文章同步到订阅号信息流中，形成“朋友推荐”的聚合入口。这一举措旨在提升公众号的活跃度，改善创作者的创作欲望，并提振读者的分享兴趣。随着短视频行业的崛起，图文内容的阅读量逐渐下降，微信希望通过社交推荐来重塑内容生态。然而，用户对隐私的担忧也随之而来，反映出社交关系与内容分发之间的矛盾。 </div>
                        <hr>
                    
                    <p><strong>微信将好友“塞进”了订阅号信息流里。</strong></p>
  <p>近日，字母榜（ID：wujicaijing）获悉，<strong>微信正在对公众号文章页面的“在看”功能进行小范围的更新测试。</strong>最新的灰度测试版本中，公众号文章底部的<strong>“推荐”取代了“在看”，点击“推荐”后，文章将不仅同步到原来的“发现——看一看”，还将同步到订阅号信息流中，</strong>汇聚到一个“朋友推荐”的聚合入口，和订阅号、快讯并列出现。一位前产品经理人士评价，这或许意味着微信的社交关系给内容生态让路了。</p>
  <p>这也是自2019年“好看”升级为“在看”后，微信对这一功能的再度更新。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_6be4c1aec01b4cd3a7e0490f4d81d582@000000_oswg255231oswg831oswg519_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在图文内容打开率日益走低之际，上述举措无疑成为微信盘活公众号活跃度的最新动作。</p>
  <p><strong>且微信的动作还不止于此。</strong>最近一个月，微信频繁对公众号小功能进行更新，如公众号留言区支持图片回复，<strong>此举同样有望起到吸引用户参与内容讨论的作用。</strong>更早之前，微信文章还新增了支持文章内容划线转发和评论区留言转发小功能，在转发给微信好友或者朋友圈时，转发内容会自动生成一张附带链接的图片，点击下方“阅读原文”即可阅读被分享的文章。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_f0b6315121384908a34f486bdef26914@000000_oswg33104oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对公众号频繁更新的背后，<strong>暗藏着微信希望凭借小功能的更新改版，改善创作者对优质内容的创作欲望，以及提振读者对图文内容的分享欲，借此盘活公众号活跃度的期望。</strong></p>
  <p>字母榜向微信方面求证上述改版测试，截至发稿，对方暂未回应。</p>
  <p>微信对图文内容不断加码功能改进的现实背景则是，<strong>短视频行业正在替代图文内容创作，成为当下注意力经济的重心所在。</strong></p>
  <p>QuestMobile2024中国移动互联网秋季大报告显示，短视频行业活跃用户规模突破10亿。几乎人人都刷短视频的局面之下，微信公众号的图文内容生态逐渐呈现增长趋缓之势，文章阅读量和点击率都大不如从前。有公众号创作者更是发帖直言最近文章打开率只有1%，而在2017年的时候一度高达10%。</p>
  <p><strong>算法推荐下产生的爆款不在少数，但是原创优质内容的比重却并不大。</strong>“新榜”统计了2023年微信公众号产出的4.48亿篇文章，其中10万+文章占比不足0.06%，相当于1万篇文章中6篇阅读10万+。其中，原创文章占比不足6.96%，阅读原创10万+文章占比不足0.02%。</p>
  <p>无论对内考虑提振商业价值，还是对外补强公众号内容生态，<strong>微信都需要给订阅号加一加筹码了。</strong></p>
  <h2><strong>A</strong></h2>
  <p><strong>“朋友推荐”功能的更新，进一步强化了微信熟人分享的产品运营策略。</strong></p>
  <p>拆分来看，此次更新有三处变更。</p>
  <p>第一，字母榜通过测试发现，在微信公众号的文章页面底部，“在看”功能更新为了“推荐”功能，相应的图标也由原来的“六边形”变成了“爱心”。</p>
  <p>点击推荐图标，文章页面底部弹出好友的推荐（在看）状态，显示“XXX等朋友推荐”。点进该状态，可具体查看哪些好友推荐，从该页面底部可进一步直接前往“发现&gt;看一看”选项。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_6e4f1a0889d04f40a0c753150ac75628@000000_oswg187812oswg702oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>第二，点击“推荐”后，“朋友推荐”的文章将进入微信订阅号的信息流推荐中，汇聚到订阅号中“朋友推荐”的聚合式入口中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_530118d922c140ed9b7eadd587a01d01@000000_oswg74160oswg925oswg1049_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>改版后的“朋友推荐”入口，和快讯入口类似，用户在浏览订阅号消息时，<strong>即可通过“朋友推荐”看到朋友分享的在看文章，以一种更加贴近平时获取信息的方式，让微信好友间更容易达成信息传递。</strong></p>
  <p>第三，此功能的更新，也体现在“发现——看一看”中。进入发现页面的看一看，顶部三个功能中的“在看”，也更新为了“朋友推荐”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_dd93f296cf844ee9930e4d91d593818f@000000_oswg554151oswg803oswg690_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这三处更新中，最具意义的是“朋友推荐”进入订阅号信息流中。一位前产品经理人士表示，<strong>这意味着微信的社交关系给内容生态让路了。</strong></p>
  <p>这也是自2019年，“好看”升级为“在看”后，这一功能的再度更新。</p>
  <p>自2017年微信首次在发现页面推出“看一看”功能后，几经调整，<strong>从“好看”到“在看”，再到“推荐”，微信熟人分享的产品策略一步步加强。</strong></p>
  <p>2019年3月，公众号文章底部和“发现&gt;看一看”中的“好看”功能，统一改名为“在看”。很快，微信再次灰度测试“朋友在看”列表功能，点击“在看”按钮，内容可被推送到朋友在看列表中，进一步加强社交推荐属性。</p>
  <p>不久后，看一看的“朋友在看”可访问朋友的个人主页，显示朋友最近7天内“在看”的文章集合，不过最终因为引发关于隐私的舆论争议，“显示7天内在看文章”的功能下线了。</p>
  <p>微信还在持续加码看一看的流量比重，在订阅号信息流中引入“看一看”，用户能在订阅号信息流中刷到“看一看”内容，内容主要来自：我关注的号、我常看的号、X个好友分享、近期X个好友关注、X个好友读过等维度。</p>
  <h2><strong>B</strong></h2>
  <p>“看一看”几度更新的背后，是张小龙对社交推荐的看重。</p>
  <p>“用户其实并不太愿意从朋友圈里面中断，花几分钟阅读一篇文章，然后再回到朋友圈。他们其实是需要有一个固定的相对长的时间，他才会沉下心来花时间去完成一个阅读动作。这个时候，另外一个阅读氛围更强的入口，对用户来说是更必要的。”张小龙曾在2019年初的微信公开课上说道。</p>
  <p>当时，看一看的“好看”和“推荐”分别代表社交和机器推荐。在张小龙看来，通过社交推荐来获取信息是最符合人性的，“因为在现实里面，我们其实接纳新的信息，并不是我们主动到图书馆或者到网上去找的信息，<strong>大部分情况都是听到周边的人的推荐而获得的。</strong>”在他看来，“似乎只有基于社交推荐，才有机会”。</p>
  <p>这一年的公开课上，张小龙分享过一个数据，早期的公众号阅读量70%、80%来自朋友圈的转发，只有20%、30%是来自于订阅号的。<strong>它符合一个二八定律，有20%的人去挑选信息，有80%的人去获益，通过20%的人挑选去阅读文章。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_9432b3ba98364f08b36c2404beee47d5@000000_oswg42485oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>微信也确实在按照张小龙提出的逻辑运行，努力在社交推荐和机器推荐中寻求平衡。从微信公众号再到后期的视频号，<strong>“朋友推荐”的产品策略更新一以贯之。</strong></p>
  <p>但随着作为超级APP的微信，日益庞大，<strong>纯粹靠人来进行信息分发，不仅效率开始变低，也逐渐开始影响微信内容生态的构建。</strong></p>
  <p><strong>这就对内容分发效率和创作者生态提出了新的考验，</strong>仅仅依靠订阅制逻辑，或将导致更多新的创作者难以完成冷启动阶段，创作者群体的流失，最终势必影响微信整体内容质量的输出。</p>
  <p>外部，<strong>2020年前后的中国互联网江湖，正在经历一场算法推荐的变革。</strong>当时，由张一鸣的“今日头条”引发的算法推荐成为互联网行业热潮，算法推荐成为行业共识，淘宝、百度等互联网公司都在效仿头条，加入算法的信息流建设。</p>
  <p><strong>微信也在当时引入了算法机制，如在看一看里推出了基于算法推荐的“精选”，</strong>后变更为长视频和热点；用户订阅号页面也引入了信息流机制。</p>
  <p>算法推荐一定程度上再次为公众号激活了创作者生态，<strong>即使你是一名籍籍无名的创作者，也能因为踩中算法机制而爆火。</strong></p>
  <p>但是随之而来的一个问题是，为了黏住用户，一些迎合算法的劣质内容成为“爆款”“显学”。长此以往，劣币驱除良币之下，失去正向反馈的创作者，<strong>开始从公众号平台流失，读者也在海量垃圾信息中逐渐丧失订阅公众号的兴趣。</strong></p>
  <p>加码朋友推荐，则一定程度上起到维护微信内容生态的作用。熟人背书可以被视作一种朋友甄选，使得优质内容更容易基于社交推荐在平台多次传播和流通，从而重塑微信内容生态。</p>
  <h2><strong>C</strong></h2>
  <p><strong>但是与强化“朋友推荐”随之而来的，则是对用户隐私侵害的担忧。</strong></p>
  <p>在社交平台，已经有网友发帖表示“如何关闭微信这个新功能”。该网友晒出的图片显示，“朋友推荐”的文章已经进入了微信订阅号的信息流推荐中，如果选中朋友推荐入口，可进行删除，和快讯入口类似。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_44a760b6c5ee4e9c97cf55484fbe487f@000000_oswg59238oswg602oswg403_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>希望关闭新功能的诉求背后，反映出部分用户的隐私需求，和平台基于社交关系的内容分发之间的冲突。</strong></p>
  <p>实际上，“看一看”多次更迭的背后，微信都在试图平衡用户体验和社交推荐所带来的矛盾。</p>
  <p>微信7.0大改版后，公众号文章点赞变“好看”并且同步到看一看后，好看人数就迎来下降。很快，“好看”就变成了“在看”，降低了用户的分享压力，但同时保留了同步至“看一看”的分享路径。</p>
  <p>不久后，看一看的“朋友在看”可访问朋友的个人主页，显示朋友最近7天内“在看”的文章集合，又引发用户关于个人隐私的争论，当时一天之内#微信上线在看个人主页#话题就有4亿阅读量。不久后，“查看7天内在看”的功能也下线了。</p>
  <p>根据西瓜数据2019年的公众号生态趋势调查报告结果，“点赞”变成“好看”，又升级成“在看”，并分享到看一看之后，微信的在看数据经历了短暂的下跌，后又迅速回升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_0dfc070b7a7040979cddb951d323a91e@000000_oswg157800oswg796oswg456_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随着算法越来越智能，<strong>算法推荐在“暴露隐私降低用户体验”的这个问题上也在遭遇跟朋友推荐同样的难题。</strong></p>
  <p>好在，互联网公司已经开始着手整治这方面的隐患。近日，抖音、小红书、拼多多等多家网络平台发布算法典型问题治理专项公告，推进算法和平台治理透明化。</p>
  <p>兼具熟人社交属性和算法推荐于一身的微信，<strong>在处理用户体验和产品增长之间两难选题中，迎接的审视无疑会更大。</strong></p>
  <p><strong>参考资料：</strong></p>
  <p><strong>《“看一看”改版，微信离张小龙想要的“社交推荐”更近了》36氪</strong></p>
  <p><strong>《微信看一看背后的产品哲学》柠檬two</strong></p>
  <p><strong>《微信订阅号新增内容分发形式》见实</strong></p>
  <p><strong>《微信展露B面：几经折腾的“看一看”》晓程序速报</strong></p>
  <p><strong>《2023年，微信公众号怎么样了？我们用数据告诉你》新榜</strong></p>
  <p><strong>《2024中国移动互联网秋季大报告》QuestMobile</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI2NjU1MTcwMA==&amp;mid=2247542306&amp;idx=1&amp;sn=0448effd7ecfec7b6017cd3e5641c54b&amp;chksm=ebf8983f98b0b99aa72c551b5d54b792afc760770d64394ec6837686f4b89dbe8bbf3f2f4ae9&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“字母榜”（ID：wujicaijing）</a>，作者：薛亚萍，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112311120252425</id>
            <title>陈丹琦团队降本大法又来了：数据砍掉三分之一，性能却完全不减</title>
            <link>https://www.36kr.com/p/3112311120252425</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112311120252425</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 08:30:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <大模型, 元数据, 预训练, 性能提升>
<br>
<br>
总结: 陈丹琦团队提出了一种新的预训练方法“元数据调节然后冷却”（MeCo），通过引入元数据加速大模型的预训练，减少了33%的训练数据而性能不减。该方法包括两个阶段：预训练阶段和冷却阶段，前者将元数据与文档拼接进行训练，后者使用标准数据继续训练。实验结果显示，MeCo在不同模型规模和数据源下均表现优异，开启了引导语言模型的新方法，并证明了其与不同类型元数据的兼容性。 </div>
                        <hr>
                    
                    <p>陈丹琦团队又带着他们的降本大法来了——</p>
  <p>数据砍掉三分之一，大模型性能却完全不减。</p>
  <p>他们引入了元数据，加速了大模型预训练的同时，也不增加单独的计算开销。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_87ef1ca77fbd4a6eb5878b06977f5d4f@46958_oswg42985oswg1080oswg353_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在不同模型规模（600M - 8B）和训练数据来源的情况下，均能实现性能方面的提升。</p>
  <p>虽然之前元数据谈过很多，但一作高天宇表示，他们是第一个展示它如何影响下游性能，以及具体如何实践以确保推理中具备普遍实用性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_df18ccab17dd4a859eed0f74e7fee443@46958_oswg56480oswg776oswg212_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>来看看具体是如何做到的吧？</p>
  <h2><strong>元数据加速大模型预训练</strong></h2>
  <p>语言模型预训练语料库中存在着风格、领域和质量水平的巨大差异，这对于开发通用模型能力至关重要，但是高效地学习和部署这些异构数据源中每一种数据源的正确行为却极具挑战性。</p>
  <p>在这一背景下，他们提出了一种新的预训练方法，称为元数据调节然后冷却（MeCo，Metadata Conditioning then Cooldown）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_07433de41d1c4c0aa03238da787e4106@46958_oswg163311oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>具体包括两个训练阶段。</p>
  <p><strong>预训练阶段（90%）</strong>，将元数据（如文档 URL 的绝对域名c）与文档拼接（如 “URL:&nbsp;en.wikipedia.org\n\n [document]”）进行训练。</p>
  <p>（例如，如果文档的 URL 是&nbsp;https://en.wikipedia.org/wiki/Bill&nbsp;Gates，那么文档 URL 的绝对域名c就是 en.wikipedia.org；这种 URL 信息在许多预训练语料库中都很容易获得，它们大多来自 CommonCrawl2（一个开放的网络抓取数据存储库））当使用其他类型的元数据时，URL 应替换为相应的元数据名称。</p>
  <p>他们只计算文档标记的<strong>交叉熵损失</strong>，而不考虑模板或元数据中的标记，因为在初步实验中发现，对这些标记进行训练会略微损害下游性能。</p>
  <p>最后10%的训练步骤为<strong>冷却阶段</strong>，使用标准数据训练，继承元数据调节阶段的学习率和优化器状态，即从上一阶段的最后一个检查点初始化学习率、模型参数和优化器状态，并继续根据计划调整学习率：</p>
  <p>1）禁用跨文档Attention，这既加快了训练速度（1.6B 模型的训练速度提高了 25%），又提高了下游性能。</p>
  <p>2）当将多个文档打包成一个序列时，我们确保每个序列从一个新文档开始，而不是从一个文档的中间开始—当将文档打包成固定长度时，这可能会导致一些数据被丢弃，但事实证明这有利于提高下游性能。</p>
  <p>本次实验使用了Llama Transformer架构和Llama-3 tokenizer。我们使用四种不同的模型大小进行了实验：600M、1.6B、3B 和 8B，以及相关优化设置。</p>
  <p>结果显示，MeCo 的表现明显优于标准预训练，其平均性能与 240B 标记的基线相当，而使用的数据却减少了 33%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_d26766309ee74fb992be7c3e6c5277e6@46958_oswg130753oswg1080oswg362_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后总结，他们主要完成了这三项贡献。</p>
  <p>1、<strong>&nbsp;MeCo 大幅加快了预训练</strong>。</p>
  <p>实验证明，MeCo 使一个 1.6B 的模型在少用 33% 的训练数据的情况下，达到了与标准预训练模型相同的平均下游性能。在不同的模型规模（600M、1.6B、3B 和 8B）和数据源（C4、RefinedWeb 和 DCLM）下，MeCo 显示出一致的收益。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_9d838b9ab7f74447a6143722e7b7c6f6@46958_oswg104245oswg1080oswg290_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_cc614bfdb68c453cb6d8e1cbb458a1cd@46958_oswg56381oswg1080oswg278_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>2、MeCo 开启了引导语言模型的新方法。</strong></p>
  <p>例如，使用factquizmaster.com（非真实URL）可以提高常识性任务的性能（例如，在零次常识性问题解答中绝对提高了6%），而使用wikipedia.org与标准的无条件推理相比，毒性生成的可能性降低了数倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_235122f4260b4d749e7b357b5ea9ed48@46958_oswg61960oswg1054oswg242_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3a290b28c1d44371aa92c847d7045296@46958_oswg72981oswg1078oswg272_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>3、消解了 MeCo 的设计选择，并证明 MeCo 与不同类型的元数据兼容</strong>。</p>
  <p>使用散列 URL 和模型生成的主题进行的分析表明，元数据的主要作用是<strong>按来源将文档归类</strong>。因此，即使没有URL，MeCo 也能有效地整合不同类型的元数据，包括更精细的选项。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_45cd89159cd04810a81608499ee85c0a@46958_oswg38367oswg1040oswg374_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>陈丹琦团队</strong></h2>
  <p>论文作者来自普林斯顿NLP小组（隶属于普林斯顿语言与智能PLI）博士生高天宇、Alexander Wettig、Luxi He、YiHe Dong、Sadhika Malladi以及陈丹琦。</p>
  <p>一作高天宇，本科毕业于清华，是2019年清华特奖得主，目前普林斯顿五年级博士生，预计今年毕业，继续在学界搞研究，研究领域包括自然语言处理和机器学习的交叉领域，特别关注大语言模型（LLM），包括构建应用程序、提高LLM功能和效率。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_e954c109a4a244f99885c610029cdc6a@46958_oswg250491oswg1080oswg423_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Luxi He目前是普林斯顿计算机专业二年级博士生，目前研究重点是理解语言模型并改善其一致性和安全性，硕士毕业于哈佛大学。</p>
  <p>YiHe Dong目前在谷歌从事机器学习研究和工程工作，专注于结构化数据的表示学习、自动化特征工程和多模态表示学习，本科毕业于普林斯顿。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/l-dlYy3cECuVmMTvYLuztg" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：白小交，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112333231460100</id>
            <title>我能把秘密告诉大模型吗？会叫外卖、会工作的智能体更危险</title>
            <link>https://www.36kr.com/p/3112333231460100</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112333231460100</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 08:05:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 隐私保护, 数据泄露, 用户数据  
<br><br>  
总结: 随着大模型的普及，用户对隐私保护的担忧日益增加，尤其是在工作中频繁使用大模型时，个人信息和工作内容可能面临泄露风险。尽管大多数大模型声称不会收集用户的对话数据，但其隐私协议中却显示用户交互信息可能被记录和分析。业内人士指出，用户对数据使用缺乏有效控制，隐私政策的透明度不足，且在某些情况下用户无法轻松撤回已提供的数据。未来，针对隐私和版权保护的法规将更加严格，企业需强化数据保护措施，用户也应拥有更大的数据管理权。 </div>
                        <hr>
                    
                    <p>“把这份会议速记的观点提炼出来”“优化年终总结”“我要做一份明年工作计划的PPT”……自从有了大模型，筱筱每天都要给文心一言、豆包等安排活计，既提高工作效率，也可以集百家之长，让工作成果更加“出挑”。</p>
  <p>但随着对大模型的依赖与日俱增，筱筱的心中也产生了担忧，“经常‘喂’给大模型素材，免不了涉及工作内容和个人信息，这些数据会泄露吗？”对于很多用户来说，他们不清楚数据如何被收集、处理和存储，不确定数据是否被滥用或泄露。</p>
  <p>此前，OpenAI被曝在训练时用到个人隐私数据。有报道称，有企业在使用ChatGPT协助办公的一个月内，接连发生三起隐私泄露事件，多家知名公司禁用ChatGPT。</p>
  <p>中国科学院院士何积丰曾表示，大模型面临着隐私保护和价值观对齐两大难题。从担心“饭碗”不保到忧虑隐私被侵犯，在大模型带给人们便利的同时，危机感随之增长。</p>
  <p>人们能把自己的小秘密告诉大模型吗？</p>
  <h2><strong>利用用户数据训练大模型</strong></h2>
  <p>“你目前的训练模型所使用的数据集（包括版权数据）出自哪里？”</p>
  <p>《IT时报》记者与通义千问、豆包、文心一言等10余家大模型进行了对话，得到的答复几乎一致，均表示训练数据集涵盖多个领域的文本、图像和多模态数据，包括公开数据集、合作伙伴提供的数据以及互联网爬取的数据，如维基百科、新闻文章、书籍等大规模文本数据集都是常用来源。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3d0275e665944fadac988b1657e5e34e@000000_oswg92327oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除了这些常用来源，用户与大模型在互动过程中所“喂”的信息，也是模型训练的数据来源之一。“你会收集我提供给你的材料进行训练吗”，对于这个问题，所有大模型都给出了否定答案，称“在与用户的交互过程中不会收集、存储或使用用户的对话数据来训练或改进模型”。</p>
  <p><strong>然而，矛盾在于，根据大多数大模型的隐私协议，用户和大模型的交互信息是会被记录的。</strong>在使用角色智能体功能时，通义千问需要用户提供相关信息用于训练智能体，并提醒用户谨慎上传个人及敏感信息；在豆包和腾讯元宝的使用协议中，均有类似规定：对于通过本软件及相关服务、输入、生成、发布、传播的信息内容之全部或部分，授予公司和/或关联方免费的、全球范围内的、永久的、可转让的、可分许及再许可的使用权，以使公司对该信息内容进行存储、使用、复制、修订、编辑、发布、展示、反义、分发上述生成内容，包括但不限于模型和服务优化、相关研究、品牌推广与宣传、市场营销、用户调研；海螺AI隐私协议提到，每天会收到大量用户上传的内容，并进行改善算法，但会遵循《个人信息保护法》。</p>
  <p>在业内人士看来，虽然在预训练阶段已经使用了大量高质量数据，但用户在使用过程中产生的数据也能在一定程度上帮助模型更好地适应不同的场景和用户需求，从而提供更精准、更个性化的服务。</p>
  <p>安远AI资深研究经理方亮告诉《IT时报》记者，根据用户的输入，模型会生成更符合用户偏好的内容，这些数据后续也可能被用于模型训练，以更好地满足用户需求。</p>
  <h2><strong>仅能撤回语音信息</strong></h2>
  <p>大模型帮助人们解放了双手，个性化地满足用户需求，数据越丰富，就能更好提升大模型的效果，这无可厚非，关键在于是否根据个人信息使用的“最小化、匿名化、透明化”等原则进行处理。“从当前市面上通用大模型的隐私政策来看，其在保护用户隐私方面的表现存在一定的复杂性，不能简单地认为它们完全保护或不保护用户隐私。”有业内人士向《IT时报》记者表示。</p>
  <p>比如豆包在其隐私政策中提到，在经过安全加密技术处理、严格去标识化且无法重新识别特定个人的前提下，可能会把向AI输入的数据、发出的指令以及AI生成的回复等进行分析和用于模型训练。</p>
  <p>腾讯元宝的隐私政策表示，在服务过程中，会对交互上下文信息进行去标识化技术处理，避免识别到特定个人身份。元宝中的写真形象馆、百变AI头像等人像类智能体或应用生成内容时，会进行人工智能技术处理但不会留存人脸特征。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_5faf71dc23e44b618c6392c442857d2e@000000_oswg372818oswg1080oswg584_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但隐私风险依然不可忽视，有业内人士向《IT时报》记者透露，一些模型虽然表示不会直接收集用户的某些敏感信息，但对于用户输入的其他信息，在经过分析和处理后，是否可能间接推断出用户的隐私内容，这是值得关注的问题。此外，部分大模型的隐私政策在信息披露上不够完善。</p>
  <p><strong>《IT时报》记者在查阅部分大模型隐私协议时发现，一些特定的交互情况如需要打开地理位置、摄像头、麦克风等授权，在交互结束后，授权可以关闭，但对撤回“投喂”的数据并不那么顺畅。</strong></p>
  <p>腾讯元宝、豆包等允许用户在App内通过改变设置，来撤回语音数据。比如豆包表示，如果用户不希望输入或提供的语音信息用于模型训练和优化，可以通过关闭“设置—账号设置—改进语音服务”撤回授权，但如果用户不希望其他信息用于模型训练和优化，需要通过邮件、电话等联系，无法在App上自行设置。</p>
  <h2><strong>原始语料或被“重现”</strong></h2>
  <p>南都数字经济治理研究中心近期发布的报告显示，多数平台并未提供明确选项让用户拒绝其个人数据被用于AI模型训练，对于数据将被用于何种具体用途、会提供给哪些第三方等信息也披露不足，使得用户难以全面了解数据流向和使用情况。</p>
  <p>方亮向《IT时报》记者表示，目前在隐私保护方面，大模型企业存在一些改进空间，例如数据收集和使用政策不够透明、用户对数据使用缺乏有效控制、数据存储和传输的安全机制需要加强、缺乏统一的隐私保护标准和规范等。他举例道，“<strong>比如在一些情况下，用户可能并不希望提供某些信息，或者希望删除已经提供的数据，但有的大模型没有提供这样的选项，这在一定程度上限制了用户的自主选择权。</strong>”方亮说道。</p>
  <p>虽然大多数大模型在隐私协议中提到使用不低于行业同行的加密技术、匿名化处理及相关可行的手段保护个人信息，但方亮对这些措施的实际效果仍有担忧。“当用户输入个人信息后，尽管这些信息可能已经去标识化或者脱敏，但关键在于这些处理是否符合相关规定。如果遭到攻击，是否仍可能通过关联或分析技术恢复原始信息，这一点需要特别关注。此外&nbsp;，如何平衡好隐私保护、数据利用与模型性能之间的关系，也是亟待解决的问题&nbsp;。”</p>
  <p><strong>《IT时报》记者了解到，有研究表明，能够从模型中获取一定数量的原始语料。</strong></p>
  <p>在DARKNAVY深蓝科技研究员肖轩淦看来，在大模型中，用户输入的数据一般被用于实时处理及数据存储。实时处理是由大模型处理用户输入的素材并输出内容返回给用户，即聊天过程，这些数据会上传到云端进行处理，也同样会被存储至云端，用户能够查看与大模型交互的历史记录。“带来的风险是，如果用户输入的内容作为数据集，可能过段时间后当其他人向大模型提问相关的内容，会带来信息泄露，被用于不当目的。”肖轩淦认为。</p>
  <p>“大模型的主要训练已经在预训练时期基本完成，用户与大模型之间的普通聊天内容，并不算有效数据，不太会被大模型拿去训练。”不过，也有业内人士向《IT时报》记者表示，训练模型属于前置工作，在已经成型的大模型面前，用户无须过度担心隐私会被泄露。</p>
  <h2><strong>“智能体”风险更大</strong></h2>
  <p>实际上，在不少安全人士看来，大模型带来的隐私风险并不只有这些。</p>
  <p>“大模型在用户隐私数据访问方面有一定问题，与ChatGPT这类只能被动接收用户输入的系统不同，当手机或电脑接入AI应用后，就变成一个‘智能体’，这些应用能够主动访问设备中的大量隐私信息，必须引起高度重视。”肖轩淦向《IT时报》记者解释，<strong>比如有的手机AI功能支持叫外卖，这样位置、支付、偏好等信息都会被AI应用悄无声息地读取与记录，增加了个人隐私泄露的风险。</strong></p>
  <p>DARKNAVY曾针对手机端的AI应用进行深入研究，发现一些应用已经意识到隐私数据访问的敏感性和重要性。例如，Apple Intelligence就明确表示其云端不会存储用户数据，并采用多种技术手段防止包括Apple自身在内的任何机构获取用户数据，赢得用户信任。</p>
  <p>欧洲数据保护委员会（EDPB）近日通过了关于人工智能模型中个人数据处理相关数据保护问题的意见（Opinion 28/2024），其中提到，AI模型的匿名性不能仅靠简单的声明，而需要通过严格的技术论证和持续的监控来保证，同时也强调企业不仅需要证明数据处理的必要性，还要证明所采用侵入性最小的方式。</p>
  <p>“未来，针对隐私和版权保护的法规和标准将更加严格，推动企业强化数据保护措施。”方亮建议，大模型企业在收集训练数据前应实施负责任的数据收集，需要考虑适用的监管框架，并尽可能最小化数据收集范围；在使用输入数据训练大模型之前对其进行审核，尝试识别可能产生危险能力、侵犯知识产权或包含敏感个人信息的数据；根据数据审核结果，采取适当的风险缓解措施；促进对训练数据集的外部审查机制。同时，用户应拥有更大的权力来管理和控制其数据。</p>
  <p>图片／&nbsp;&nbsp;腾讯元宝&nbsp; IT时报&nbsp; 豆包AI</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjM2MzEyNQ==&amp;mid=2651593976&amp;idx=2&amp;sn=262415948282e7d13dcac3cc6402903b&amp;chksm=bcbe2c0ed73a9d6b9d448f0315d735ce868e26e166e6d552a8984f44022f23d2ab6ac513e67e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“IT时报”（ID：vittimes）</a>，作者：潘少颖&nbsp; 毛宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112311377268225</id>
            <title>奥特曼崩溃认错：ChatGPT被用户薅秃，OpenAI亏大了，专访痛忆宫斗事件</title>
            <link>https://www.36kr.com/p/3112311377268225</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112311377268225</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 08:00:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <奥特曼, ChatGPT Pro, AGI, 定价策略>
<br>
<br>
总结: 奥特曼在采访中承认自己在ChatGPT Pro的定价上犯了错误，原本以为200美元的定价能够盈利，结果却因用户使用频率过高导致OpenAI亏损。他表示，定价策略的调整已迫在眉睫，并强调OpenAI的最终目标是构建AGI和ASI。尽管定价问题引发了关注，但他认为扩大规模并不一定能实现AGI，反而会带来巨额成本。此外，用户反馈对改进ChatGPT至关重要，尤其是在医疗领域的应用。 </div>
                        <hr>
                    
                    <p><strong>【导读】</strong>奥特曼承认，自己犯错了！ChatGPT Pro定价200美元，以为能赚会成本价，没想到用户使用次数太高，把OpenAI直接薅秃了……此外，在彭博社的专访中，奥特曼回顾了那次瞩目的四天逼宫事件，并表示仍然坚定AGI。</p>
  <p>奥特曼后悔了！</p>
  <p>最近，奥特曼在采访中曝出，当初对于ChatGTP Pro的定价是自己拍脑门决定的。</p>
  <p>结果没想到用户实在薅得太狠，直接把OpenAI薅秃了，严重亏损！</p>
  <p>奥特曼在X上发文表示，ChatGPT Pro实际上是亏损的。曾经定价200美元时，他以为这对OpenAI是一笔稳赚不赔的买卖，考虑到这项业务的资本密集程度。</p>
  <p>很明显，他对于用户的实际使用做了误判。因此，现在修改模型的定价策略，已经迫在眉睫。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3b683bfe7e134cde8a39a2326dd131e9@46958_oswg61187oswg872oswg298_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过，关于定价和产品的讨论并不是重点，在奥特曼心里，OpenAI的最终目标——构建AGI和ASI才是最重要的。</p>
  <p>但这次定价事件也凸显了这一事实：没有证据表明扩大规模会实现AGI，但这种做法会带来巨额成本，可是板上钉钉的。</p>
  <p>如果o3模型的查询成本高达1000美元，那o4的成本可能就要上万，AGI真是普通人可以负担得起的吗？</p>
  <p>在近期接受的彭博社专访中，奥特曼回顾了那轰轰烈烈的四天「逼宫」事件，ChatGPT的头两年，自己如何运营OpenAI，以及自己不懈追求AGI的心路历程。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_7eca3e01a6064e99a17ebe606350c4e1@46958_oswg1971305oswg1020oswg1386_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>采访亮点如下：</p>
  <p>奥特曼和Ilya共进晚餐的时刻是OpenAI创立最重要的时刻</p>
  <p>OpenAI早期因打出「通用人工智能AGI」旗号，特立独行，成为招聘秘诀，吸引了志同道合的人才</p>
  <p>风险投资的经历，让奥特曼相信ChatGPT会一路走红</p>
  <p>ChatGPT订阅模式只是当时的权宜之计</p>
  <p>奥特曼回忆了在四天之内他是如何被解雇后被请了回去</p>
  <p>在被解雇的当天，奥特曼已明确OpenAI的组织结构必须重组</p>
  <p>出名后，奥特曼感到一种陌生的距离感</p>
  <p>保护核心研发很重要</p>
  <p>AGI雏型就是能取代优秀的软件工程师的AI；超级智能的关键在于能否加速科学发现</p>
  <p>用户反馈对改进ChatGPT很重要；ChatGPT帮助很多疑难杂症的患者得到了治疗</p>
  <p>可控核聚变反应堆是最佳AI绿色能源解决方案</p>
  <p>2022年11月30日，OpenAI网站的流量达到了一个接近零的峰值。那时，对于这样一家体量不大、活跃度有限的初创公司，连老板都懒得追踪访问量。</p>
  <p>那是一个平静的日子，也是公司所知的最后一个平静日。</p>
  <p>两个月后，OpenAI 的网站流量暴增，超过了1亿访客，人们体验了ChatGPT，并为其强大的能力感到兴奋和恐慌。</p>
  <p>从那以后，任何人都再也没有回到原来的状态，尤其是奥特曼。</p>
  <h2><strong>OpenAI早期历史</strong></h2>
  <p><strong>Q：你的团队建议，现在是回顾过去两年、反思某些事件和决策、并澄清一些问题的好时机。但在我们开始之前，你能再讲一遍OpenAI创立时刻的故事吗？因为这件事的历史价值似乎与日俱增。</strong></p>
  <p>奥特曼：每个人都想要一个简洁的故事：故事里有一个明确的时刻，某件事情发生了。保守来说，我会说OpenAI在2015年经历了至少20个创立时刻。对我个人来说，<strong>最重要的时刻是我和Ilya在加利福尼亚州芒廷维尤的Counter餐厅的晚餐，就我们两个人</strong>。</p>
  <p>如果往更早的时间回溯，我一直对AI非常感兴趣。我在本科时就学习过这方面的内容。后来我分心过一段时间，但到了2012年，Ilya和其他人做出了AlexNet（卷积神经网络）。我继续关注这方面的进展，然后我心里想：「天啊，深度学习似乎是真的。而且，它看起来有可扩展性。这大有可为，应该把握机会做点什么。」</p>
  <p>所以我开始和很多人碰面，问他们谁适合和我一起做这个。2014年，AGI还是纯粹的技术幻觉，那时候大家根本不想理我，提到搞AGI，大家都会觉得是闹着玩的想法，甚至可能毁掉职业生涯。但有人建议，有个人你一定得找他谈谈，那就是Ilya。所以我在一次会议上找到了Ilya，把他拦在走廊上，我们聊了起来。我心想，「这个人真聪明。」我大概告诉了他我的想法，我们决定一起吃个饭。在我们的第一次晚餐上，他基本阐明了我们如何构建AGI的策略。</p>
  <h3><strong>创业精神的延续</strong></h3>
  <p><strong>Q：如今那次晚餐的精神，还有哪些在如今的OpenAI中延续？</strong></p>
  <p>奥特曼：基本上可以说是全部。我们相信深度学习的力量，相信通过特定的技术方法，以及研究与工程协同的路径，可以有望实现AGI。对我来说，这一切的效果太不可思议了。通常，大多数的技术灵感并不完全奏效，而且显然我们最初的构想中有一些东西根本行不通，特别是公司的结构。但我们相信AGI完全有可能实现，如果它真的可行，对社会将是一次重大突破。</p>
  <h3><strong>吸引人才的秘诀</strong></h3>
  <p><strong>Q：OpenAI团队的最初的优势之一就是招聘。不知为何，你们成功地吸引了大量顶尖的AI研究人才，通常提供的薪酬比竞争对手少得多。你们是怎么吸引这些人才的？</strong></p>
  <p>奥特曼：我们的秘诀就是：来吧，一起构建AGI。<strong>之所以有效，还是因为当时说要构建AGI显得非常奇葩， 被一般人视为异端邪说。就这样筛选掉了99%的人，剩下的全是那些真正有才华、有独立思考能力的人</strong>。这非常有感召力。如果你做的事情和别人一样，比如你在做第10000个照片分享应用，很难吸引到人才。但对于还没人在做的工作，一小部分真正有才华的人们就会被吸引过来。所以我们当时这个听起来很大胆、甚至有些可疑的定位，吸引了一群才华横溢的年轻人。</p>
  <p><strong>Q：你们能快速适应各自的角色吗？</strong></p>
  <p>奥特曼：大多数人当时都有全职工作，我当时也有工作，所以一开始我做的比较少，后来随着时间的推移，我越来越爱上这件事。到2018年，我完全被它吸引了。但最初一段时间就像是「Band of Brothers」的方式。Ilya和Greg负责管理它，但每个人都有自己的事情要忙。</p>
  <p><strong>Q：看起来最初几年是段颇具浪漫的时光。</strong></p>
  <p>奥特曼：嗯，那肯定是OpenAI发展历程中最有趣的时刻。我的意思是，现在也很有趣，但考虑到它对世界的影响，我认为那是最伟大的科学发现阶段之一， 是一次千载难逢的经历。</p>
  <h3><strong>接任CEO</strong></h3>
  <p><strong>Q：2019年，你接任了CEO，这怎么发生的？</strong></p>
  <p>奥特曼：我曾试图兼顾OpenAI和Y Combinator的工作，但这太难了。「我们真的能构建 AGI」，这个想法完全吸引了我。有趣的是，我记得那时我曾想过，我们会在2025年实现AGI，但这个数字完全是随便定的，那不过是我们成立的第十年。那时人们常开玩笑说，我唯一做的事就是走进会议室说：「扩大规模！」虽然这不是真的，但扩大规模确实是那时候的核心重点。</p>
  <h3><strong>ChatGPT的发布</strong></h3>
  <p><strong>Q：ChatGPT的正式发布日期是2022年11月30日。那感觉像是很久以前的事，还是像一周前发生的事？</strong></p>
  <p>奥特曼：我明年就40岁了。在我30岁生日那天，我写了一篇博客，标题是《数日漫长，但十年短暂》。今天早上有人发邮件给我，说：「这是我最喜欢的博客，我每年都看。你40岁时，会更新这篇博客吗？」我笑了，因为我肯定不会更新了。我没时间。但如果我更新的话，标题会是《几天很长，十年更漫长》。总之，那像是很久之前的事了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_07a8da4069dc482f967c4009f3e2a1be@46958_oswg71945oswg1080oswg328_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Q：当第一批大量用户开始涌入，并且很明显这是个大事件，你有没有惊叹的瞬间？</strong></p>
  <p>奥特曼：的确有几件事。第一，我相信ChatGPT已经做得相当不错了，但公司其他人都在说：「你为什么要让我们发布这个？这是个错误决定，还没准备好。」我很少做那种「我们要要做这个」的决定，但这就是其中之一。</p>
  <p>YC有一份著名的图表，是联合创始人Paul Graham绘制的潜力曲线。随着新鲜感的消退，新技术会迎来很长时间的低谷，然后才是产品和市场的契合，并最终起飞。这是YC文化中的一部分。在最初的几天，ChatGPT白天的使用量更多，晚上则较少。团队都在说：「哈哈哈，它在下降。」但我在YC学到了一件事，那就是，只要新的低谷比上一轮的峰值还要高，那么非同凡响的事情就会发生。在最初的五天里，看起来是这样的，我当时就想，「我们的成果肯定超出预期。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_5caeecaeedd5458daea933feffc6027e@46958_oswg48076oswg490oswg315_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Paul Graham绘制的潜力曲线&nbsp;</p>
  <p>这引发了对计算资源的疯狂的争夺。我们急需大量的计算资源，但当时我们并没准备好，因为<strong>我们发布ChatGPT时，没有清晰的商业模式</strong>。我记得那年12月的一次会议上，我就说过「我会考虑一些如何为此付费的方法，但我们不能再这样讨论下去了。」当时提了好多烂主意，没一个好点子。所以，我们只好说：「这样吧，我们试试订阅模型，以后再想办法」。就这样坚持到现在。</p>
  <p>我们发布了GPT-3.5，并且GPT-4就快来了，我们知道它会更好。在跟其他人说起用途时，我也会强调「我知道我们可以做得更好。」我们迅速地改进了它。这让全球媒体意识到转折点已经到来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_633003c4a820430c8c6abfd92d7fa279@46958_oswg1081344oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2023年3月13日，OpenAI部分高管在旧金山公司总部。</p>
  <p><strong>Q：你是一个能安心享受成功的人吗？还是已经开始担心下一阶段了？</strong></p>
  <p>奥特曼：我或者说我的职业生涯有点奇特：正常的轨迹是你经营一家大型的成功的公司，然后在50或60岁时厌倦了以往辛苦的工作，转行做「风险投资」。先入行风险投资，并坚持相当长的风险投资生涯，然后做公司老板，我这种职业轨迹非常罕见。虽然有很多方面我觉得这样做不好，但其中一方面我觉得非常好，那就是知道未来会发生什么，因为你已经观察并指导了多人如何经营一家公司。</p>
  <p>当时我觉得一面满怀感激，另一面有点像「我像被绑在一艘宇宙飞船上，生活天翻地覆，也没那么有趣。」我的另一半经常讲那段时期的趣事。不管我回家时什么样，他都会说：「太棒了！」而我会说：「这真的很糟糕，对你也不好。你现在还没意识到，但真的很糟糕。」</p>
  <p><strong>Q：你在硅谷成名时间不短了，但GPT的到来让你变得世界闻名，这种爆红的速度和Sabrina Carpenter或Timothée Chalamet等明星媲美。这会不会影响到你对员工的管理能力？</strong></p>
  <p>奥特曼：它让我的生活变得更复杂了。但在公司里，无论你是不是出名，大家只关心：「我的GPU到底在哪儿？」</p>
  <p><strong>但在生活的其他方面，我感到一种距离感。</strong>我对这种感觉很陌生。当我和老朋友、新朋友（除了特别亲近的人）在一起时，我能察觉到这种陌生的感觉。我想如果和一般不互动的人在一起，我在工作中确实会有这种感觉。如果我必须与几乎从未见过的小组一起参加一次会议，我很明确它就在那里。但我大部分时间都和研究人员身一起度过。我向你保证，在这之后跟我来参加研究会议，你只会看到大家对我一点也不客气。这太好了。</p>
  <h2><strong>艰难四日</strong></h2>
  <h3><strong>矛盾初现</strong></h3>
  <p><strong>Q：一个盈利性公司，拥有数十亿美元外部投资，但需要向一个非营利董事会报告，这可能会成为问题。你还记得自己什么时刻意识到了这个问题吗？</strong></p>
  <p>奥特曼：肯定有很多这样的时刻。从2022年11月到2023年11月，那一整年的记忆都很模糊。感觉像是在12个月内，我们从零开始建立起一家完整的公司，而且还是在公众面前。现在回头看，我吸取的一个教训是，每个人都说自己不会搞错重要性与紧迫性的相对排序，但事实证明他们不行。所以我会说，当我清醒地面对现实时，意识到这行不通的时刻，应该是那个星期五的中午12:05。</p>
  <h3><strong>艰难度日</strong></h3>
  <p><strong>Q：当新闻传出董事会解雇你CEO职位时，确实让人震惊。但你看起来是一个情商很高的人。在此之前，你有没有察觉到任何紧张的迹象？你知道自己是那个紧张的根源吗？</strong></p>
  <p>奥特曼：我根本不认为我是一个情商高的人，但即使是我，也能<strong>察觉到这种紧张的气氛</strong>。你知道，我们一直在不断讨论安全与能力、董事会的作用以及如何平衡所有这些问题。所以我知道气氛比较紧张，而我并不是一个高情商的人，并没有察觉到事情已不可收拾。</p>
  <p>那个周末发生了很多让人抓狂的事。我对那段时间的记忆——可能我记得的细节不完全正确——他们在周五中午解雇了我，当天晚上其他不少同事也决定辞职。到深夜时，我就想「不如我们去启动一个新的 AGI 项目。」后来在当天晚上，一些高管说，「嗯，我们觉得事情还有转机。冷静点，等我们的消息。」</p>
  <p>星期六早上，两名董事会成员打电话过来，想聊聊我是否愿意回去。一开始我非常生气，立马拒绝了。然后我就想，「好吧，可以。」我真的很在意OpenAI。但我也表示，「只要整个董事会都退出」。我现在真希望当时采取了不同的方式，但当时我感觉自己的要求很合理。然后我们确实在董事会的问题发生了很大的分歧。于是我们开始就成立新董事会展开了谈判，双方都对彼此的某些想法感到不可理喻，但是总体达成了一致。</p>
  <p>然后就是星期天，那是我最烦躁的一天。从周六到周日，他们一直在说，「就快好了，我们只是在咨询法律建议，董事会的同意书正在起草中。」我反复强调自己不想拆解OpenAI，希望对方能说实话。对方保证「是的，你会回来的，你肯定会回来的。」</p>
  <p>时间到周日晚上，他们却突然宣布Emmett Shear成为了新的CEO。我当时想，「完了，现在我真的彻底完了」，因为我被彻头彻尾地骗了。到了星期一早上，很多同事都威胁要辞职，然后董事会就说，「好吧，我们需要改变决定。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_8980a80f1c1e4b02860f894f153b5a03@46958_oswg1502843oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>余波未消</strong></h3>
  <p><strong>Q：董事会表示，进行了内部调查，得出的结论是你在与他们的沟通中「并非始终坦诚」。这是一项具体的指控：他们认为你在撒谎或者隐瞒了某些信息；但同时又很模糊：因为它没有说明你到底在哪些方面没有坦诚。你现在知道他们指的是哪些问题吗？</strong></p>
  <p>奥特曼：我听过不同的版本。其中一件是，「Sam连要发布ChatGPT的事都没告诉董事会。」我的记忆和理解不是这样的。但事实是，我肯定没有说，「我们要发布这个东西，会引起巨大轰动。」之类的的话。我认为董事会那边的很多描述都不太公平。我更了解的一件事是，我曾与不同的董事会成员发生过争执。对我试图赶他们离开董事会的方式，他们也不满意。我从中吸取了教训。</p>
  <p><strong>Q：你在某个时刻意识到，OpenAI的结构将会扼杀公司的发展。因为一个以使命为驱动的非营利组织，永远无法争夺到足够的算力资源，也无法实现让OpenAI蓬勃发展所需的快速转型。董事会由一群理想主义者组成， 将纯洁性置于生存之上。因此，你开始做出决策，让OpenAI参与竞争，这可能需要耍点花招，而董事会完全不能接受。</strong></p>
  <p>奥特曼：我不认为我在耍花招。我只能说，为了采取快速行动，董事会没有充分了解问题的前因后果。有件事提到了「Sam拥有创业基金，但他没有告诉我们。」事情的真相是OpenAI的运营结构很复杂，OpenAI以及持有OpenAI股权的人，都不能直接掌握创业基金。<strong>而恰好我就是那个没有OpenAI股权的人</strong>。所以我暂时持有，直到我们建立成熟的股权转让结构。我认为这件事没必要向董事会报告，现在我愿意接受人们对此提出的质疑，也会以更明确的方式做出说明。但当时的OpenAI正像坐火箭一般飞速发展，我真的没有时间去解释。有机会的话，大家可以跟现任的董事会成员们聊聊，问问他们是否觉得我耍过花招，因为我一直尽力避免那样做。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_20da9401454c46de97218ed1774f0fc6@46958_oswg124848oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">OpenAI目前的架构</p>
  <p>之前的董事会坚信AGI可能出错，我认为他们的坚持和担忧都是坦诚的。比如，在那个周末，董事会某个成员对这里的团队说：「摧毁公司可能也符合非营利董事会的使命」。这句话引来了大家的讥讽，但我认为这才是信念真正的力量。我相信她说这话时是认真的。虽然我完全不同意具体的结论，但我尊重这份理想和坚持。我认为上一届董事会的行为出自真诚但错误的信念，毕竟他们认为AGI已经触手可及，而我们没有对它负责。我尊重他们的出发点，但对具体做法完全不能苟同。&nbsp;</p>
  <p><strong>Q：很明显，最终是您取得了胜利。但你难道不会感到精神上受到创伤了吗？</strong></p>
  <p>奥特曼：当然了，我被吓坏了。最难的不是经历这些，因为那四天肾上腺素激增，我可以做很多事。而且公司同事和广泛的社区支持，也让我非常感动。很快这就过去了，但每天情况都在变得更糟。又是政府调查，又是旧董事会成员向媒体泄露假新闻。那些让我和公司遭殃的人，我觉得都走了，但现在我得清理他们留下的烂摊子。当时是12月，天黑得很早，大概是下午4:45，天气又湿又冷，还下着雨，我一个人在屋子里走来走去，感觉又累又沮丧。我感到很不公平，觉得自己不该受到这样的对待。可我又不能停下来，因为有各种各样的「火烧眉毛」的事要处理。</p>
  <p><strong>Q：当你回到公司时，你会不会担心别人异样的眼光？会不会担心有些人觉得你根本不是优秀的领导者，需要重建他们的信任？</strong></p>
  <p>奥特曼：实际情况比这更糟。等到事情澄清以后，一切都好了。但在最初的几天里，没有人知道发生了什么。当我走在办公楼里，大家会有意避开我的目光。就像我被诊断为癌症晚期一样。有同情，有共情，但没人知道该说什么。真得很难熬。但我当时想：「我们还有一项复杂的工作要做，我要继续做下去。」</p>
  <h3><strong>经营企业之道</strong></h3>
  <p><strong>Q：你能聊聊是如何经营企业的吗？你的一天是怎么安排的？比如，你会和工程师一对一交流吗，还是会在办公楼里四处巡视？</strong></p>
  <p>奥特曼：让我看看我的日程。我们每周一会举行三个小时的高管团队会议，然后，昨天和今天，我和六位工程师做了一对一交流，此外还要参加研究会议。明天有几场重要的合作会议，还有很多计算资源相关的会议。明天我有五场关于构建计算资源的会议，还有三场产品头脑风暴会议，之后我要和一位重要的硬件合作伙伴共进晚餐。大概就是这样，每周有一些固定的任务，然后大部分时间是应对突发的事情。</p>
  <p><strong>Q：你在内部和外部沟通上花多少时间？</strong></p>
  <p>奥特曼：主要是内部沟通。我不写那种鼓舞人心的邮件，但我会进行很多一对一或小组讨论，还会通过Slack进行沟通。</p>
  <p><strong>Q：你会不会有深陷其中的感觉？</strong></p>
  <p>奥特曼：我是一个重度Slack用户，已经习惯了在一团乱麻中整理数据，在Slack中可以获得很多信息。虽然和小型研究团队的交流可以深度了解情况，但广泛的交流也能获取很多宝贵的信息。</p>
  <p><strong>Q：你之前谈过ChatGPT的外观和用户体验，而且观点非常鲜明。身为CEO，你觉得在哪些工作中，自己必须亲自参与，而不是像教练那样指挥？</strong></p>
  <p>奥特曼：对于OpenAI这样规模的企业，直接参与的机会已经很少了。昨晚我和Sora团队吃饭，写了好几页内容，详细地列出了我的建议，但这不常发生。有时在和研究团队开会后，我会提出非常具体的建议，涉及接下来三个月具体的工作细节，但这也很不常见。</p>
  <h3><strong>研发与运营</strong></h3>
  <p><strong>Q：我们之前谈到过，科学研究有时可能与企业的运营结构发生冲突。你把研究部门和公司其他部门分开，放在了几英里外的另一栋楼里，这背后有什么象征意义吗？</strong></p>
  <p>奥特曼：没有，那只是因为后勤安排和空间规划。我们将来会建设一个大型的园区，研究部门仍然会有自己的专属空间。<strong>保护核心研究对我们来说非常重要。</strong></p>
  <p><strong>Q：保护研究部门免受什么影响？</strong></p>
  <p>奥特曼：硅谷公司的通常做法是先从做产品起步，随着规模扩大，收入增长往往也会放缓。然后有一天，CEO可能会启动新的研究实验室，提出一系列新想法以推动进一步增长。这在历史上有过几次成功的例子，像贝尔实验室和施乐。但通常情况不是这样，企业在产品方面很成功，研发却越来越弱。我们很幸运，OpenAI成长得非常快，可能是有史以来增长最快的科技公司，但这也很<strong>容易让人忽视研发的重要性，我不会让这种事发生</strong>。</p>
  <p><strong>我们聚在一起是为了建立AGI和超级智能，以及更高的目标</strong>。在这个过程中，很多事情都可能会分散我们的注意力，导致远离最终目标。我认为非常重要的一点就是，不要让自己分心。</p>
  <h3><strong>AGI定义</strong></h3>
  <p><strong>Q：作为公司，你们似乎停止了公开谈论AGI，转而讨论AI的不同层级，而你个人还是热衷于谈论AGI。</strong></p>
  <p>奥特曼：我觉得AGI这个词现在已经变得非常模糊。如果你看我们的五个层级，你会发现每个层级都有人认为它是AGI。之所以划分不同层级，是为了能更具体地展示我们所处的位置和进展情况，而不是讨论它到底是不是AGI。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_6162c9b021344dcfb56022cab7540e64@46958_oswg42467oswg1080oswg423_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Q：您要说「好的，我们现在已经实现了AGI」的阈值是多少？</strong></p>
  <p>奥特曼：我的粗略理解是，当一个AI系统能在重要工作中替代熟练的人类从业者时，我会称之为AGI。当然会带来很多后续的问题，比如，是全面替代还是替代其中的部分环节？计算机程序能否自主决定想成为一名医生？它的能力是否达到行业顶尖水平，比说前2%？它的自主性如何？这些问题我目前还没有很深入、精确的答案。</p>
  <p><strong>但当AI可以取代企业雇佣的出色的软件工程师时，我想很多人会认为，好吧，这算是AGI的雏形了</strong>。当然，我们总是会不断调整标准，这就是为什么定义AGI很难。而当我谈到超级智能（super intelligence）时，<strong>关键问题是，它能否快速提高科学发现的速度</strong>。</p>
  <h3><strong>用户反馈</strong></h3>
  <p><strong>Q：你们现在有超过3亿用户了。你们从用户反馈中学到了哪些关于ChatGPT的理解？</strong></p>
  <p>奥特曼：和用户讨论他们用ChatGPT做什么、不做什么，<strong>对我们的产品规划非常有帮助</strong>。很多人在用ChatGPT做搜索，而这并不是我们最初设计的目标。而且它当时的搜索表现确实很糟糕。<strong>但后来搜索变成了一个重要功能</strong>。老实说，自从我们在ChatGPT中推出了搜索功能后，我几乎不再用Google了。而在最初在内部设计原型时，我完全没想到ChatGPT会取代我对Google的使用。</p>
  <p>另一件从用户那学到的事情是，人们有多么依赖它来获取<strong>医疗建议</strong>。很多在OpenAI工作的同事都会收到令人感动的邮件，比如有人说：我生病多年，没有医生告诉我到底得了什么病。我把所有症状和检测结果输入ChatGPT，它告诉我得了一种罕见疾病。我去看医生，按照建议治疗，现在完全康复了。这虽然是个极端的例子，但类似的事情经常发生。这让我们意识到，人们有这样的需求，我们应该在医疗方面投入更多开发。</p>
  <h3><strong>定价策略</strong></h3>
  <p><strong>Q：你们的产品定价从免费到20美元、200美元，甚至会有2000美元的档位。如何为前所未有的技术定价？是靠市场调研，还是随便猜的？</strong></p>
  <p>奥特曼：我们最初推出ChatGPT时是免费的，但后来用户量开始激增，我们必须想办法支撑运营成本。当时我们测试了两个价格，20美元和42美元。结果发现，42美元有点太高了，用户觉得不值，但20美元他们愿意接受。于是我们定了20美元。这大概是在2022年12月底或2023年1月初决定的，我们没有做过非常严格的定价研究。</p>
  <p>我们也在考虑其他方向。很多客户告诉我们，他们希望按使用量付费。比如有些月份我可能需要花1000美元用于计算资源，而有些月份我想花很少的钱。我还记得拨号上网的时候，AOL给你每月10小时或者5小时的上网时间。我非常讨厌那种按时收费的方式，我不喜欢这种被限制的感觉。所以我也在考虑，有没有其他更合适、且同样基于实际使用量的定价模式。</p>
  <h3><strong>AI安全</strong></h3>
  <p><strong>Q：你们现在的安全委员会是什么样的？在过去一年或一年半里有哪些变化？</strong></p>
  <p>奥特曼：比较麻烦的一点是，我们有很多不同的安全机制。我们有一个内部的安全咨询小组（SAG），专门进行系统的技术研究并提供意见。我们还有一个隶属于董事会的SSC（安全与保障委员会）。此外，还有一个与微软共同设立的DSB（决策监督委员会）。所以，我们有一个内部机制、一个董事会机制和一个微软联合董事会。我们正在努力让这些机制更加高效。</p>
  <p><strong>Q：你在这三个委员会里都有参与吗？</strong></p>
  <p>奥特曼：这是个好问题。SAG（安全咨询小组）的报告会发给我，但我并没有成为其正式成员。流程是这样的：他们制作报告，然后发给我。我会看看，然后把意见发给董事会。SSC（安全监督委员会）我没有参与。而我是DSB（决策监督委员会）的成员之一。现在我们对安全流程有了更清晰的认识，我希望能够让这个流程更高效。</p>
  <p><strong>Q：你对潜在风险的看法是否有变化？</strong></p>
  <p>奥特曼：我认为在网络安全和生物技术领域，我们会面临一些严重的或者潜在的短期问题，需要进行缓解。从长期来看，一个真正具备极强能力的系统，会存在一些很难精确想象和建模的风险。但我同时认为，这些风险是真实存在的，并且唯一有机会解决这些问题的办法就是发布产品，然后从中学习。</p>
  <h2><strong>模型、芯片与能源短缺</strong></h2>
  <p><strong>Q：谈到短期未来，整个行业似乎集中在三个问题上：模型扩展、芯片短缺和能源短缺。我知道这些问题是相互关联的，你能根据你的关注程度对它们排个序吗？</strong></p>
  <p>奥特曼：我们已经建立了相应的计划。在模型扩展方面，我们在技术进步、能力提升和安全性改进上取得了持续的进展。我认为2025年将是一个令人惊叹的年份。你听说过ARC-AGI挑战吗？五年前，它被设计为迈向AGI的指引。他们设计了一个非常难的基准测试，我们即将发布的模型通过了这个基准测试。这个挑战已经有五年了，一直无人解决。得分达到85%，就算通过。而我们的系统，在没有经过任何定制的情况下，就得到了87.5%的成绩。除此之外，我们还将推出非常有潜力的研究成果和更优秀的模型。</p>
  <p>在芯片方面，我们一直在努力打造完整的芯片供应链，与合作伙伴协同工作。有团队为我们建造数据中心、生产芯片，我们也有自己的芯片研发项目。我们与NVIDIA建立了良好的合作关系，这家公司真的非常了不起。明年我们将会公布更多的计划，现在正是我们扩大芯片规模的关键时刻。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_bf05554278ce47b9bd62cffd6dc3353f@46958_oswg911121oswg1080oswg770_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Q：所以能源问题……</strong></p>
  <p>奥特曼：可控核聚变会奏效。</p>
  <p><strong>Q：大概是什么时间？</strong></p>
  <p>奥特曼：很快。很快就会有净增益的核聚变演示出现。但接下来需要建造一个不会出故障的系统，还要扩大规模，研究如何建造工厂，以大规模生产这样的系统。这需要获得监管部门的批准。这一切可能需要几年时间，我预计Helion很快就会带来看得见、摸得着的可控核聚变方案。</p>
  <p><strong>Q：短期内，有没有办法在不影响气候目标的情况下维持人工智能的发展速度？</strong></p>
  <p>奥特曼：有，但在我看来，没有什么比尽快批准可控核聚变反应堆更好。我认为特定类型的核聚变方法非常棒，我们应该全力以赴实现它。</p>
  <h2><strong>特朗普-马斯克政府</strong></h2>
  <p><strong>Q：你刚才提到的很多事情都涉及到政府。现在新总统即将上任，你个人捐赠了100万美元，这是为什么？</strong></p>
  <p>奥特曼：因为他是美国总统。我支持任何一位总统。</p>
  <p><strong>Q：我明白，OpenAI支持一位在乎私人恩怨的总统似乎有道理，作为个人捐款，特朗普反对你以前支持的许多事情。我是不是该认为，这次捐款与其说是出于爱国信念，不如说是表忠心？</strong></p>
  <p>奥特曼：我并不支持特朗普所做、所说或所想的一切。我也不支持拜登的一切。但我支持美国，并且愿意在我的能力范围内与任何总统合作，为国家的利益服务。特别是在这个关键时刻，我认为这超越了所有政治问题。我认为在这届总统任期内，可能会开发出通用人工智能（AGI），而正确处理这件事非常重要。支持总统就职，我觉得这只是件小事，我并不认为这是一个需要深思熟虑的大决定。不过，我确实认为我们所有人都应当希望总统成功。</p>
  <p><strong>Q：他说他讨厌《芯片法案》，而你支持《芯片法案》。</strong></p>
  <p>奥特曼：其实我也不支持。我认为《芯片法案》比什么都不做要好，但不是我们应该采取的最佳方案。我觉得我们还有机会采取更好的后续措施。《芯片法案》并没有达到我们所有人所期望的效果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_97fbae167a5e4dcfa443c4e7506cdfcf@46958_oswg892117oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Q：显然，马斯克将会在政府中会扮演某种角色。他在起诉你，也在与你竞争。我看到你在DealBook上的评论，说你认为他不会利用自己的职位在人工智能领域搞任何小动作。</strong></p>
  <p>奥特曼：是的，我确实这么认为。</p>
  <p><strong>Q：不过说真的，过去几年，他买下了推特，又试图通过起诉来放弃收购。他解封了Alex Jones的账号，还向扎克伯格发起笼斗挑战，而这些只是他奇葩操作的冰山一角……</strong></p>
  <p>奥特曼：我觉得他会继续做各种不靠谱的事情。他可能会继续起诉我们，撤销诉讼，再提出新的诉讼之类的。他向我发起笼斗挑战，不过看起来他也不是真的在挑战扎克伯格。他会说很多话，尝试做很多事情，然后又反悔；被人起诉，也会去起诉别人；跟政府产生冲突，被政府调查。这就是他的风格。至于他会不会滥用他的政治权力，来对付商业竞争对手？我觉得他不会。我真的是这么想的。当然，也可能最后证明我错了。</p>
  <p><strong>Q：当你们两个合作最融洽的时候，你们各自扮演了什么角色？</strong></p>
  <p>奥特曼：我们还是比较互补的。我们不确定这到底会变成什么，或者我们会做什么，也不确定接下来会如何发展，但我们有一个共同的信念：这件事很重要，而我们需要朝着这个大致方向努力并及时调整。</p>
  <p><strong>Q：我很好奇你们实际的合作关系是什么样的？</strong></p>
  <p>奥特曼：在马斯克决定退出之前，我不记得和他有过什么特别严重的争执。尽管有很多传闻——人们说他会斥责人、大发脾气之类的，但我没经历过那样的事情。</p>
  <p><strong>Q：对于他为xAI从中东筹集到这么多资金，你感到意外吗？</strong></p>
  <p>奥特曼：不意外。他们有很多资金。这是现在大家都想投的行业，而埃隆是埃隆嘛。</p>
  <p><strong>Q：假设你是对的，并且马斯克和政府都有积极的意图，那么2025年特朗普政府在人工智能领域最有帮助的举措是什么？</strong></p>
  <p>奥特曼：在美国建设大量基础设施。我非常认同总统的一点是：现在在美国建设东西变得非常困难，这简直难以置信。无论是发电厂、数据中心，还是其他类似的设施，都很难建。我理解官僚主义如何逐渐累积，但这种情况对整个国家都没有好处。尤其是当你想到美国需要在人工智能领域领先时，这种状况就更不利了。而美国确实需要在人工智能领域占据领先地位。</p>
  <p>参考资料：&nbsp;</p>
  <p>https://www.bloomberg.com/features/2025-sam-altman-interview/&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/CpVWJNtxnWFcafSG4LbJ9w" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：JZs&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3112152801070594</id>
            <title>2024 年，卖的最好的车，为什么是它？</title>
            <link>https://www.36kr.com/p/3112152801070594</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3112152801070594</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 07:49:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 插电混动, 增程式, 新能源汽车, 市场趋势  
<br><br>  
总结: 文章指出插电混动和增程式技术已不再被视为过渡方案，而是成为新能源汽车市场的重要组成部分。根据数据，插电混动车型销量增长显著，2024年占据市场的20%。消费者对无续航焦虑和便利性的需求推动了这一转变。车企也因插混和增程车型的成本优势而加大投入，逐渐形成市场竞争格局。技术创新的成功在于渐进式优化，以适应市场需求。摩根大通预测到2030年，插电混动车和增程车的销量将占据中国新能源汽车市场的60%。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_b92633fb5e4a4af09a6528ef366183b3@000000_oswg924586oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>「插混只是过渡技术，纯电才是未来。」这是不专业汽车人曾经的判断，但如今看来，这一判断彻底错了。&nbsp;</p>
  <p>根据中汽协数据，2024 年 1-11月，我国新能源汽车销量达到 1126.2 万辆，同比增长 35.6%，占全国汽车总销量的40%以上。其中，插电式混合动力车型的表现尤为突出，销量达到 451.9 万辆，同比激增 85.2%。&nbsp;</p>
  <p>仅用了三年多时间，「插混+增程」在中国新能源汽车市场的占有率就翻了一番，目前已经超过了40%。&nbsp;</p>
  <p>相比之下，纯电动车型销量为 673.8 万辆，同比增长仅 15%。虽然插混销量仍低于纯电，但其增长率高出纯电车型约 70 个百分点。&nbsp;</p>
  <p>有哪些因素促使这些车企转向混动产品？&nbsp;</p>
  <h2><strong>插混不再是过渡技术</strong></h2>
  <p>首先简单介绍下中国新能源发展的策略。自 2001 年起，中国便制定了具有战略意义的「三纵三横」技术路线，明确了新能源汽车发展的主要方向。这一策略的「三纵」包括：纯电动汽车（BEV）、混合动力汽车（HEV）以及燃料电池汽车（FCEV）。&nbsp;</p>
  <p>在当前的新能源汽车市场中，插电混动（PHEV）和增程式混动（EREV）是两种主流的混动技术路线。它们都配备充电接口并支持外部充电，但其核心技术有所不同：PHEV 的发动机可直接驱动车辆，而 EREV 的发动机不直接驱动车轮，而是作为发电机为电池充电或直接为电动机提供电力。&nbsp;</p>
  <p>插混和增程在很长时间被视为过渡技术，尽管在全球新能源车市场中占据了一定的份额，但其定位仍然尴尬，似乎游走在传统内燃机与纯电动车之间的「夹缝」中。&nbsp;</p>
  <p>和纯电一样，插电混合动力车型的早期推广，主要依赖政策推动。为了符合新能源政策，很多车型采用了「小电量+降低发动机排量+不涨价」的策略。虽然这样可以满足政府对新能源汽车牌照的要求，使消费者能享受政府补贴，但这种「政策驱动」的方式也带来了不少问题：电池容量过小，续航不足，充电不便等问题，无法有效解决油耗问题。&nbsp;</p>
  <p>增程汽车遭受非议更多。理想汽车在 2018 年推出首款增程式汽车后，不时被炮轰「技术落后」，属于「智商税」，「脱裤子放屁」。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_3132f9d090394de3904aab55be246ee4@000000_oswg436882oswg1079oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">2024 年 5 月，比亚迪董事长王传福公布了第五代 DM 的关键指标 | 图片来源：比亚迪&nbsp;</p>
  <p>转机出现在 2021 年。当时，比亚迪发布 DM-i 超级混动技术，并带动了混动车型一路高歌猛进。插混和增程车型提供类似纯电车的驾驶感受，同时消除了里程焦虑，技术复杂度相对较低。而在电池价格上涨8倍的背景下，纯电车型成本较高，插混车型显得更具性价比。&nbsp;</p>
  <p>数据显示，2021 年插电混动总销量超过 57 万辆，增速远远超过整个新能源大盘市场，同时也改变了传统燃油车与纯电动汽车之间的市场格局。&nbsp;</p>
  <p>随着比亚迪的 DM-i 技术取得成功，越来越多车企跟进推出插混车型。广汽的 GMC、长城的 H4-T、长安的蓝鲸 i-DD、吉利的雷神、奇瑞的鲲鹏等技术相继问世，市场竞争愈发激烈。&nbsp;</p>
  <p>与此同时，增程也逐渐成为越来越多车企的新战略选择。阿维塔、小鹏、小米、蔚来、埃安、智己等原本以纯电动为主的品牌，纷纷加码增程产品布局，展现出强烈的市场趋势。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250107/v2_26d0644482354dcf8f14b17faf7aa34f@000000_oswg429957oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">采用增程的理想的 L 系列 | 图片来源：理想汽车&nbsp;</p>
  <p>如今，插混和增程已成为当下新能源市场的重要组成部分，且各自占据着独特的市场位置。2024 年，多个插混与增程车型成为热销代表，其中比亚迪的秦/宋 PLUS DM-i、宋Pro 新能源、海豹 06 DM-i，理想的 L 系列，问界M9增程版等车型在销量榜单中稳居前列，成为消费者热捧的选择。&nbsp;</p>
  <p>值得一提的是，2024 年 10 月，宁德时代推出了具备超快充能力的骁遥超级增混电池。该电池具备超过 400 公里的续航能力，并支持高达 4C 的超充技术，在 10 分钟内可为车辆充电增加 280 公里续航，满足市场对长续航和快速充电的双重需求。&nbsp;</p>
  <p>这一切表明，插电混动与增程式技术已不再是过渡选择，它们已经成为未来新能源汽车与纯电并行发展的主流技术。摩根大通预测，到 2030 年，插电混动车和增程车的销量将占据中国新能源汽车市场的 60%，这一预判也验证了二者在市场中的深远影响。&nbsp;</p>
  <h2><strong>从夹缝中突围</strong></h2>
  <p>插电和增程走向主流，背后最根本的原因在于消费者偏好的显著变化。早期，新能源汽车的主要用户群体为科技爱好者，他们愿意尝试纯电车型，追求创新与环保。然而，随着新能源汽车市场渗透率接近 50%，消费者群体逐渐多元化，尤其是传统燃油车车主成为了主要的购车群体。这部分消费者对新能源汽车的需求，更多集中在无续航焦虑和便利性上，而插电混动车型恰好满足了这一需求。&nbsp;</p>
  <p>数据显示，2021 年是纯电和插混都高速发展的一年。当时，纯电车型销量达到 291.6 万辆，同比增长161%，市场份额超过 82%，成为新能源汽车的主流；插电车型销量为 60.3 万辆，同比增长 140%，增速也十分显著。&nbsp;</p>
  <p>然而，随后几年插混车型的增速持续超越纯电车型。2024 年前 11 个月，中国新能源汽车市场累计销量为 959.62 万辆，渗透率达到 47.4%。其中，纯电动汽车销售 555.2 万辆，同比增长 21.9%，占市场份额的 27.4%；而插电混动+增程式电动车的销量达到 404.43 万辆，同比增长 80.2%，占市场份额的 20%。&nbsp;</p>
  <p>另一方面，从车企角度来看，插混和增程相较于纯电具有显著的成本优势。插电和增程车型配置的电池容量远低于纯电动车，减少了电池采购和生产成本，为车企提供了更大的定价空间。&nbsp;</p>
  <p>据业内人士表示，一套主流增程器的成本大约在 1 万元左右，结合增程车型的电池系统，整体成本大约为 4 万元。而纯电动车，尤其是 30 万元级别的车型，电池容量通常在 80-120kWh 之间，成本则高达 8 万到 13 万元。这一差距使得增程车型在成本控制上占据了明显优势，特别是在大规模生产和市场竞争中，增程式电动车的性价比更为突出。&nbsp;</p>
  <p>理想汽车通过这一策略取得了成功。今年销量突破 50 万辆，核心差异化并非仅依赖「冰箱沙发大彩电」等硬件配置，而是其产品「空间」足够大，满足了消费者的多样化需求。通过采用增程方案，理想的每辆车可以省掉相当一部分的电池成本（当年的电芯可比现在贵多了），而这部分成本，恰好可以用来对这辆大房子进行「精装修」。三排六座的家庭用车就这么做成了。&nbsp;</p>
  <p>除了成本优势，混动车型在全球市场的成功也是重要考量。近年来，插电混动车型的全球市场份额持续增长，成为车企拓展海外市场的首选技术路线。数据显示，2024 年 1-10 月的新能源车份额达到 19%，其中纯电动车的占比达到 12.2%，而插电混动达到 6.8% 的汽车比例。这一比例较 2022 年的 3.3%和 2023 年的 4.5%均有显著提升。&nbsp;</p>
  <p>对于准备进军海外市场的车企来说，纯电车型受到关税和充电基础设置不完善等原因推广难度较大。相比之下，插混、增程车型因其兼具内燃机与电动驱动系统，在续航、加油便利性及充电设施配套方面具有更强的适应性，在全球范围内更易推广。&nbsp;</p>
  <p>时至今日，插混和增程技术已从「过渡方案」转变为主流产品。这也带来一个重要启示：技术创新不一定要从一开始就「颠覆」现有体系，它是一个渐进的过程。初期的技术不必完美，逐步迭代和优化，以适应市场需求，往往更能获得认可。很多创业公司过于追求「颠覆性创新」，忽视了技术的可操作性和市场适配性。插混与增程的成功，正是通过渐进式创新应对市场需求，最终获得广泛接受。&nbsp;</p>
  <p>*头图来源：问界&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653071591&amp;idx=1&amp;sn=0c7845c3926572609df65cb14a26fc82&amp;chksm=7f01a07bc90380c8fd670c7840486d82d7e823576c051db85eac83e15a03cd0bcc313adca6be&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：周永亮，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>