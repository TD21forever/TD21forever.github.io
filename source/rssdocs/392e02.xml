<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2510724011147529</id>
            <title>特斯拉涨价后，被网友群嘲了...</title>
            <link>https://www.36kr.com/p/2510724011147529</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510724011147529</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 08:09:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克, 特斯拉, 涨价, 长续航版
<br>
<br>
总结: 特斯拉宣布对Model 3和Model Y的长续航版进行涨价，引发了网友的疑惑和讨论。尽管涨价幅度不大，但特斯拉此举与其他国内品牌降价优惠的做法形成鲜明对比。特斯拉官方提前预告了涨价消息，称涨价是因为成本上浮，但车辆配置并未发生变化。这次涨价被认为是在催促消费者下单付款，而特斯拉的价格体系一直以来都被认为是公正透明的。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9d92b214048c48f09fe527bb71d19a7b@000000_oswg496251oswg801oswg531_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>马斯克的嘴，骗人的鬼。&nbsp;</p><p>说好会继续降价，转头就涨了一波，不过好在涨的并不多。&nbsp;</p><p>今天一早，Model 3/Y的长续航版，都在原价的基础上进行了上调。Model 3长续航版本的最新售价为 <strong>29.74万元</strong>，涨了1500元，Model Y长续航版则 <strong>上调2500元至30.24万元</strong>。&nbsp;</p><p>这次提价，也让Model Y长续航版车型的价格再次超过了30万。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_32c50e5c978442a1a8d792464843acfc@000000_oswg194001oswg736oswg523_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，这次涨价 <strong>特斯拉特意提前预告</strong>了，从前天网上就开始传出消息，昨天被特斯拉官方证实，今天一早公布了涨价幅度。&nbsp;</p><p>舆情节奏拿捏得恰到好处，但涨价的动作却让不少网友直呼看不懂。&nbsp;</p><p>金九银十结束后，正是国产品牌冲销量的时候。比亚迪和零跑率先在11月开始降价优惠，其他品牌也准备再次开打价格战， 此时不按套路出牌的特斯拉，却开始涨价 。&nbsp;</p><p>关键涨得还不多，所以不少人怀疑，这是在催消费者下单付钱。有博主称，特斯拉官宣涨价的前一天， <strong>单日新增订单达到了5000台左右</strong>。&nbsp;</p><h2>01涨了，又好像没涨</h2><p>此次提价只是针对Model 3和Model Y的长续航版本，入门级的后轮驱动版价格都没变。&nbsp;</p><p>在10月底，特斯拉已经针对Model Y高性能版的售价调整过一次，从34.99万元涨到 <strong>36.39万元</strong>，上调了1.4万。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_40c9d472dfeb4e499dfced4040d8c58b@000000_oswg113698oswg715oswg395_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也就是说，不到半个月特斯拉就涨了两次。（虽然这次就像闹着玩似的）&nbsp;</p><p>而且在售的Model Y还是新款，10月1号才正式发布，当时特斯拉宣传的是加量不加价。&nbsp;</p><p>这次涨价被推上热搜的另一个原因，是特斯拉很贴心地 <strong>透露了涨价的消息</strong>。&nbsp;</p><p>在官方确认涨价的消息前，就有不少特斯拉的销售人员在朋友圈发布了涨价的内容，称“Model Y即将涨价，这是继高性能价格上调1.4万后的 <strong>延续性调整</strong>。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4d5bea759c1f4a4d8416c8bd66f47766@000000_oswg386197oswg916oswg552_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来 源： 网络&nbsp;</p><p>有销售人员昨天表示，“Model 3和Model Y长续航版明天都会涨，全系价格会上调，就看先涨哪个版本。”&nbsp;</p><p>随后有媒体向特斯拉官方求证，虽然对方并没有透露具体的涨价信息，但表示“确实计划对Model Y其它版本车型价格进行相应调整。”&nbsp;</p><p>最后则称，“特斯拉价格体系一向公正透明，价格上调后的Model Y，依然是 <strong>国内市场相同价位中最好的产品</strong>。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9a6fb700223749158b0598a97c2865b7@000000_oswg170215oswg1080oswg1422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：网络&nbsp;</p><p>在此之前，特斯拉在国内的几次调整售价，不论是涨价还是降价，都是直接在官网调整，没有提前告知销售，也没有像这样公开预告过，这次涨价算是 <strong>头一回提前“预热”</strong>。&nbsp;</p><p>对于涨价原因，官方给出的回应是因为成本问题。&nbsp;</p><p>特斯拉官方客服工作人员称， <strong>价格上涨是因为成本上浮</strong>，车辆的配置并没有变化，“车价起起落落很正常，如果说成本下降的话，那可能价格就会下来。”&nbsp;</p><p>给大家翻译一下，如果哪天成本降下来了，可能就又降价了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_e15a9e2972854f009f9309e142d2890f@000000_oswg331404oswg542oswg518_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但业内人士分析，提前预热涨价，有“ <strong>逼单</strong>”的嫌疑，为的是催促还在犹豫的消费者尽快锁单付款。&nbsp;</p><p>从涨价的幅度来看，只是象征性地涨了1500元、2500元，对本就打算购买的消费者来说冲击力并不大。但如果是还在犹豫的消费者，在听到涨价的消息后，大概率会提前锁单。&nbsp;</p><h2>02涨价去库存？</h2><p>本来昨天大家听到特斯拉涨价的消息，都认为特斯拉飘了，今天看到之后，转头开始群嘲。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_1351471289c04ed894d32b8c7d5d1aa5@000000_oswg39752oswg641oswg185_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有网友甚至直言，涨价1500，都对不起销售连发一周的朋友圈。&nbsp;</p><p>也有网友对马斯克的成本定价提出了质疑：“以后还好意思说自己是 <strong>成本定价</strong>吗？”、“就是妥妥的玩营销。”&nbsp;</p><p>因为之前有不少消息称，特斯拉要全系涨价，涨价幅度可能要超过一万元。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2b29b0b8e8b8486ab41276a82a9c1468@000000_oswg116343oswg764oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“涨2500搞得跟涨1w似的，涨价去库存是吧？”&nbsp;</p><p>...&nbsp;</p><p>虽然这次涨价的幅度并不大，但放在当下来看，涨价还是和国内整个车市的状态不太符。特斯拉作为一条外来的鲶鱼，一点风吹草动都可以引起国内市场的连锁反应。&nbsp;</p><p>那这是否意味着特斯拉不玩了，不打价格战了？&nbsp;</p><p>从实际销量来看，特斯拉涨价并不是没有底气。公开数据显示，今年1-10月，特斯拉在国内的 <strong>总交付量达77.1万辆</strong>，已超去年一整年的交付量。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_20de679c1d274829b8fadd6c0165f5ce@000000_oswg755720oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>刚刚过去的10月，乘联会公布的数据，特斯拉中国的批发销量为72115辆。受Model 3焕新版的影响，环比下降2%。预计到11月份，特斯拉的销量会不断回升。&nbsp;</p><p>而在特斯拉国内的在售车型中，Model Y可以说是目前特斯拉销量最好的车型，今年9月，Model Y在国内的销量为41428辆， <strong>占到了当月销量的95.22%</strong>。&nbsp;</p><p>在特斯拉公布的第三季度财报中显示，Model 3/Y的产量和发货量，也同比增加了20%和29%。毫无疑问，Model 3/Y一直都是特斯拉的销量主力军。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2a013c68bf4042b7a51040ae0ec5907f@000000_oswg400843oswg766oswg453_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>截至三季度末，特斯拉全球已累计交付电动车超132.4万辆，如果要完成全年180万辆的交付目标，特斯拉还需要在四季度交付 <strong>47.6万辆</strong>新车，远高于第三季度的43.5万辆。&nbsp;</p><p>不过今年以来，特斯拉受不断降价的影响，盈利能力和汽车毛利率都在不断下滑。&nbsp;</p><p>根据特斯拉公布的第三季度最新财报，营收为234亿美元，同比增长9%。然而毛利润同比下滑22%至41.78亿美元， <strong>毛利率也下降至17.9%</strong>，不仅低于华尔街预期的18%，也同样低于上一季度18.2%和去年同期的25.1%。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0b43363046a94d019d9dfcf5e051981d@000000_oswg219376oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一边是提高盈利能力，一边是降价提振销量，特斯拉必须要做出权衡。&nbsp;</p><p>乘联会秘书长崔东树认为，特斯拉计划通过上调两款国产车售价，来缓解毛利率下滑的现状，但这会给其全年180万辆销量目标带来一定压力。&nbsp;</p><p>象征性涨价1500元，对于提高毛利率来说作用其实并不大。&nbsp;</p><p>这样看来，特斯拉这次涨价最高兴的可能就要属友商了，涨价的幅度虽小，但也让其他品牌松了一口气。&nbsp;</p><p>最后汇成一句话——利好中国新能源车。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg5MTc3NjgxNQ==&amp;mid=2247520688&amp;idx=1&amp;sn=f5619297d1d3860749bb106695827fa0&amp;chksm=cfcaebf0f8bd62e6b11c918d3ca2f7450310d580b6f7134c7b62952abba96bff7c29adc01b3f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“超电实验室”（ID：SuperEV-Lab）</a>，作者：楚门，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510748816080899</id>
            <title>重塑GitHub、颠覆程序开发：GitHub Universe 2023发布重大更新</title>
            <link>https://www.36kr.com/p/2510748816080899</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510748816080899</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 08:04:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GitHub, Copilot, 人工智能, 代码库
<br>
<br>
总结: GitHub发布了Copilot企业计划，允许用户根据代码库定制功能，并推出了Copilot Chat。Copilot Chat是一款聊天机器人，可以在开发者的集成开发环境中提供代码相关的问题解答和修复建议。GitHub还推出了企业级Copilot套餐，允许公司利用自有代码库进行底层模型微调，提供更个性化的Copilot Chat使用体验。这些新功能使得GitHub成为一个更全面的开发者工具平台。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f7d3143651874840a6dae86c222332ac@46958_oswg106249oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>GitHub 的东家微软看到了生成式 AI 业务的大幅增长，其首席执行官萨蒂亚·纳德拉 (Satya Nadella) 告诉华尔街，GitHub Copilot 软件的付费客户在第三季度比上一季度增长了 40%。纳德拉表示：“我们在超过 37,000 个组织中拥有超过 100 万付费 Copilot 用户。”</p><p>现在，该平台以现有的全球用户群为基础，在正在进行的年度 GitHub 会议——Universe 2023 上发布了新的人工智能重大公告：GitHub 公布 Copilot 企业计划，允许客户根据代码库做功能定制，并公布了 Copilot Chat 的明确推出时间。</p><p>GitHub 首席执行官 Thomas Dohmke 表示，他们正在逐步将 Copilot 与 GitHub 各方面融合，并将其作为一个重要组成部分。可以说，这是 GitHub 的一次重塑，正如他所说：“就像 GitHub 是在 Git 基础上构建的一样，今天我们正在 Copilot 的基础上重新构建它。”</p><p>关于这次的“重建”，一些网友评论说这似乎朝着使每个人都能够编写代码的方向迈出了坚实的一步。但也有人担心微软这个举动会破坏掉 GitHub 的协作能力，因此有人建议保留 Git 部分，单独建立一个 GitHub Copilot 平台。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_25905e9fd4f54b30bb684dc6d6222291@46958_oswg10105oswg481oswg100_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>无论如何，今年的开发者工具取得了非常显著的进展，GitHub 的意义也不再仅作为一个代码托管平台了。我们还总结了 GitHub Universe 2023 上的重大更新：</p><h2>Copilot Chat 将全面上线&nbsp;</h2><p>GitHub 早在今年 3 月就公布了 Copilot Chat 的相关消息，7 月向企业用户交付了 beta 公测版，并于 9 月将个人用户也纳入公测范围。下个月（12 月），Copilot Chat 将全面上线，不过 GitHub 没有给出通用版本的确切落地日期。</p><p>简而言之，Copilot Chat 是一款聊天机器人，运行在开发者的集成开发环境（IDE）之内，允许用户就当前正在处理的代码询问相关问题，包括让它们识别特定程序中的 bug 并提供修复建议，甚至可以就特定代码行做出内联反馈。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f92d7b6f08c7424da71ae3ec5b015e1b@46958_oswg130705oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>GitHub Copilot Chat。</p><p>Copilot Chat 由最新 OpenAI 大语言模型（LLM）GPT-4 提供支持，并作为标准 Copilot 订阅套餐的组成部分，个人用户每月 10 美元，企业用户每月 19 美元。</p><h2>企业级新套餐&nbsp;</h2><p>GitHub 同时表示将推出新的企业级 Copilot 订阅套餐，每月收费为 39 美元。Copilot Enterprise 将于 2024 年 2 月正式发布，将包含现有业务套餐中的所有内容，外加一些值得关注的附加功能——包括允许公司利用自有代码库进行底层模型微调，从而获得更加个性化的 Copilot Chat 使用体验。</p><p>基本使用方式为：公司将 Copilot 接入自己的代码库，开发者即可获得关于内部私有代码的相关建议。这又与前面提到的 Copilot Chat 新功能有所关联。对于订阅了 Copilot Enterprise 的用户来说，Copilot Chat 将超越代码编辑器和 IDE，一路延伸至 GitHub.com，帮助开发人员深入研究自己的代码、文档和 PR，提供更为广泛的问题摘要、建议和答案。</p><p>GitHub CEO Thomas Dohmke 在最新发布的评论博文中表示，“通过将 Copilot Chat 接入您在 GitHub.com 上的代码仓库，Copilot Enterprise 可以帮助您的开发团队快速厘清代码库、搜索和构建文档、根据内部及私有代码获取建议，并快速审查 PR。组织代码库中的集体知识将跃然于您的指尖，开发人员不仅可以加快代码编写速度，更能够以领先于竞争对手的方式部署应用程序、功能和更新。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_bb5db16b2d404ff0bc3f55cc1f99b248@46958_oswg74361oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Copilot Enterprise：通过“智能操作”生成 PR 摘要。</p><p>其实在此之前，Copilot Chat 就已经能够与 IDE 中的私有工作区配合使用，只不过后者要求用户在本地保存一份代码仓库副本。Copilot Enterprise 所做的就是围绕云端代码及相关文档开放各种形式的 AI 对话，同时允许企业用户微调底层模型，以便 Copilot 能够更好地补全代码、并回答关于给定代码库提出的具体问题。</p><p>GitHub 产品管理副总裁 Mario Rodriguez 在采访中表示，“我们的最终目标就是提供一款对话式、无处不在、个性化且值得依赖的 Copilot，这种种诉求就实际转化成了我们现在看到的 Copilot Enterprise。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_33ecbf0fc3534ed49ebb1444aa4ee092@46958_oswg65073oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在 GitHub Copilot Enterprise 中创建定制化模型。</p><p>参与这项功能初始测试的，就有 GitHub 的合作伙伴、芯片巨头 AMD 公司。该公司表示微调之后的 Copilot 模型能够支持 Verilog 等硬件设计语言，这在标准 Copilot 版本中显然是无法实现的。</p><p>AMD 公司软件开发高级总监 Alexander Androncik 在一份声明中指出，“定制化 Copilot 模型为众多 AMD 硬件工程师带来了 AI 辅助功能，可提供准确且质量卓越的 AI 建议，同时紧密契合我们的产品设计风格。”</p><p>在相关新闻中，GitHub 还透露将“在未来几个月内”推动 Copilot Chat 登陆 GitHub 移动应用，同时增加对 JetBrain IDE 套件的支持（当前仅支持 VS Code 与 Visual Studio 代码编辑器）。此举明显是在回应广大用户的需求和期盼——“你们既然要求了，我们当然会明确做出回应，”Dohmke 表示。</p><h2>进一步扩展 Copilot&nbsp;</h2><p>本届 GitHub Universe 大会上发布的另一份重量级公告，则是 Copilot 的合作伙伴计划。该计划将推动 GitHub 与更广泛的开发者社区建立合作，具体将以第三方开发工具厂商构建的插件形式出现，包括正在为 Copilot 打造集成方案的 Daastax、LaunchDarkly、Postman、HashiCorp 及 Datadog 等。</p><p>Dohmke 强调，“随着这一生态系统的不断扩大，GitHub Copilot 能够为开发者分担的工作也将越来越多、用例愈加丰富。从协助提高数据库查询性能、到检查功能标记的状态，再到查看 A/B 测试结果——所有这一切、乃至更多应用场景将很快成为可能。这都要归功于那些正在为 GitHub Copilot 持续开发插件的合作伙伴们。”</p><p>本次大会公布了包含 25 家合作厂商的首批名单，GitHub 还在积极向更多希望参与进来的公司开放早期访问计划。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_abe6c4c15c51412a8e68265ec6cfc530@46958_oswg43538oswg554oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>GitHub Copilot 合作伙伴计划：以 Datastax 为例。</p><p>最后一条与 Copilot 相关的消息，就是 GitHub 初步介绍了所谓 Copilot Workspace，据称它能以自然语言方式帮助开发者在短短几分钟内将设计灵感转化为可运行代码。开发人员首先在 Copilot Workspace 当中提出问题，之后 AI 会给出自动生成的计划，指导如何实现变更需求。当然，开发者也可以灵活编辑这些计划，通过“引导”让 AI 更好地理解问题、提供建议。这项功能预计将在 2024 年年内落地。</p><p>Dohmke 表示，“Copilot Workspace 的使用感受，类似与合作伙伴进行结对编程。它了解项目中的方方面面，而且会跟随你的指引，依托 AI 的力量在代码仓库中完成问题回应和 PR 变更等各种用例。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_8fffa77696b8434dbe411d4372818c95@46958_oswg147161oswg554oswg257_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Copilot Workspace.</p><h2>安全保障，以及更多&nbsp;</h2><p>在安全方面，GitHub 还对 2020 年首次内置在 IDE 中的功能进行了增强。其中包括 secret 扫描与代码扫描，向 GitHub 用户开放漏洞自动智能检测，并发现那些无意中被遗漏在公共代码中的 secret（例如密码）。</p><p>现在，GitHub 还在添加新的 AI 元素，包括用于代码扫描的“autofix”自动修复功能，可帮助开发人员快速完成安全修正。AI 能够根据 PR 中的 CodeQL、JavaScript 及 TypeScript 警报生成相应修复方案。</p><p>GitHub 产品管理副总裁 Asha Chakrabarty 在博文中提到，“这些新功能带来的可不只是修复意见，而是精确、可操作的操作指导，能帮助开发者快速了解漏洞情况和修复思路。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0878fed64e614c03a7cedd1d5cb9406a@46958_oswg146665oswg554oswg354_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>GitHub Copilot 中的代码扫描 autofix 自动修复功能。</p><p>开发人员可以通过单击将这些修复直接提交到代码当中，也可以先对修复方案进行编辑修改、之后再合并进代码库。</p><p>Chakrabarty 总结道，“这项功能的优点，在于它带来了无摩擦的修复体验。用户可以在编码的同时快速修复漏洞，这不仅缩短了修复耗时，而且实际准确性也完全能够达到用户的预期。”</p><p>参考链接：</p><p>https://github.blog/2023-11-08-universe-2023-copilot-transforms-github-into-the-ai-powered-developer-platform/</p><p>https://techcrunch.com/2023/11/08/github-teases-copilot-enterprise-plan-that-lets-companies-customize-for-their-codebase/</p><p>https://twitter.com/ashtom/status/1722313836798320715</p><p>https://twitter.com/LinusEkenstam/status/1722320525454676063</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/uTuknGZ3U8XYdtLIygUsEg" rel="noopener noreferrer nofollow" target="_blank">“AI前线”（ID:ai-front）</a>，编译：核子可乐、Tina，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510747138457602</id>
            <title>最前线| 沃尔沃袁小林：如果做不到正常的商业逻辑，我们不会赔本赚吆喝</title>
            <link>https://www.36kr.com/p/2510747138457602</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510747138457602</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 08:02:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 文, 韩永昌, 沃尔沃, 电动化
<br>
<br>
总结: 沃尔沃汽车集团全球高级副总裁袁小林在接受采访时表示，作为企业，不会以低于成本的价格销售产品，纯电车型的投入要考虑长期回报，定价策略要根据市场反应来制定。沃尔沃计划在2025年实现全面电动化，近年来在中国市场持续发力。袁小林认为，市场销量不能决定整个工业端的发展，最终结果由经济规律决定。沃尔沃在中国市场保持竞争力并不担心，重要的是保持平衡和品牌定位的一致。 </div>
                        <hr>
                    
                    <p>文&nbsp;|&nbsp;韩永昌</p><p>编辑&nbsp;|&nbsp;李勤</p><p>“如果做不到正常的商业逻辑，我们不会强行赔本赚吆喝，作为企业，把一块钱的产品当五毛钱来卖，这是不健康的状况。”</p><p>11月5日，在2023年沃尔沃中国公开赛举办之际，沃尔沃汽车集团全球高级副总裁、亚太区总裁兼CEO袁小林在接受36氪等媒体采访时如此说道。</p><p>沃尔沃EM90也亮相在本次活动中，这款纯电MPV车型也将于11月12日全球首发，依旧采用沃尔沃“安全+豪华”的品牌定位进入市场。</p><p>从腾势D9、岚图梦想家、极氪009，再到即将上市的理想MEGA、小鹏X9，以及沃尔沃EM90，国内MPV市场来愈发火热，可谓是众强齐聚。</p><p>作为沃尔沃汽车首款纯电豪华MPV，EM90被寄予了不小的期望。但袁小林仍十分冷静，他表示，纯电产品相较于同级别的内燃机产品，要考虑更多的投入，未来是否会得到更好的回报，因为牺牲长期利益换取短期表现这是不负责任的做法。</p><p>袁小林进一步称，我们绝对不会看市场掀起了一阵波动就赶紧跟风，抛弃自身商业逻辑，最后声称我很成功。定价策略要根据自身情况和市场反应来制定。</p><p>按照沃尔沃此前的品牌规划，该公司将于2025年实现全面电动化，纯电车型的销量占比将达到50%，其余皆为混动车型。因此，近年来沃尔沃在电气化转型中动作十分频繁，不管是车型本身的配置还是公司的组织架构调整，沃尔沃都在中国市场持续发力。</p><p>袁小林说，我很高兴的是，即便在有限的产品区间，我们也顺利进行着电气化推进。这里面包括我们的BEV车型，其实它的商业逻辑都是平衡在一个合理区间上。</p><p>对于目前中国市场目前的竞争态势，袁小林评价道，现在市场容易单一地谈销量，谁卖得多谁厉害，但是也有卖得多就突然死掉了。如果它不是一种可持续的，不能随着规模变大而提升盈利性，整体健康度不能越来越好的情况下，我不相信资本市场游戏可以决定整个工业端的发展。只要时间拉得够长，最终还是由基本的经济规律决定最后的结果。</p><p>袁小林对沃尔沃在中国市场保持竞争力并不担心，他说道，我们的体量曲线一直是保持平缓。保持平缓的逻辑，就是把握平衡：市占率、盈利率和整个网络的健康度，以及做任何调整都不偏离品牌的定位。</p><p>袁小林认为，如果把市场看作是一个水位，当水高的时候，从盈利、市占率、体系上来看，品牌是否变得更健康，和水位相匹配，这是很重要的。“如果匹配的话销量自动就上去了。把握住这个匹配，长期主义才能坚持。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510748589670657</id>
            <title>机器学习 vs. 数值天气预报，AI 如何改变现有的天气预报模式</title>
            <link>https://www.36kr.com/p/2510748589670657</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510748589670657</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 08:00:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数值天气预报, 机器学习, 数据驱动, 预测精度
<br>
<br>
总结: 数值天气预报是天气预报的主流方法，通过数值积分对地球系统的状态进行求解。然而，随着天气预报分辨率和预报时间的增加，数值天气预报所需的计算成本也增加，限制了其发展。与此同时，基于机器学习的数据驱动天气预报快速发展，部分模型的预测精度已经超越了传统方法。数据驱动的机器学习方法依赖于大规模、高质量的气象学开放数据集，通过训练模型来进行天气预报，其预测速度和解释方式与传统方法有所不同。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_409b44a813484e48a68981cf9adeeb49@46958_oswg192399oswg888oswg321_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>数值天气预报是天气预报的主流方法。它通过数值积分，对地球系统的状态进行逐网格的求解，是一个演绎推理的过程。</p><p>然而，随着天气预报分辨率不断升高，预报时间逐渐延长，NWP 模式所需要的算力迅速增加，限制了其发展。另一方面，以人工智能为基础的数据驱动天气预报快速发展，在部分领域已经超越了传统方法。</p><p>现有的机器学习天气预报精度如何？人工智能又将如何改变天气预报？本文对比了几大数据驱动的机器学习天气预报模型后，对天气预报的未来发展作出了展望。</p><h2>数值天气预报：450 亿偏微分方程组</h2><p><strong>数值天气预报 (NWP, Numerial Weather Prediction) 是天气预报领域的主流方法</strong>。早在 20 世纪初，Abbe 和 Bjerknes 就提出人们可以使用物理定律预测天气，以当前的天气状况为初值，进行积分便可以求解未来的天气。但彼时对气象学的研究还不够深入，计算水平也相对落后，这一设想未能实现。&nbsp;</p><p><strong>1950 年，普森林顿大学首次尝试使用第一台电子计算机进行了天气后报。1954 年，在斯德哥尔摩首次实现了实时的天气预报。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4859cfa60b5347f398ebe312eeddc5e3@46958_oswg204149oswg540oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">在每个网格单元中求解基于物理定律的微分方程组</p><p>直到 20 世纪 70 年代，<strong>超级计算机问世，人们方能求解 Abbe 和 Bjerknes 提出的整套方程</strong>。1979 年，欧洲中期天气预报中心 (ECMWF) 编制了首份中期天气预报，开启了综合预报系统 (IFS, Integrated Forecasting System) 的篇章。&nbsp;</p><p>然而，Edward N.Lorenz 总结前人的经验，<strong>提出天气系统是一个混沌系统</strong>，会因变量的细微变化而发生巨大的改变。另一方面，<strong>人们对于气象系统的初始状态也很难完全掌握</strong>。为此，学界使用集合预报 (Ensemble Forecasting) 以最大限度降低初始参数和预测模型的不确定性，预测结果的集合即为概率预报的基础。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_908f7f98b0c344b0a2659c5f66563af4@46958_oswg192749oswg685oswg340_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">降水概率的集合预报示意图</p><p><strong>随着数值模型、超级计算、数据同化和集合预测等技术的发展，数值天气预报的精度不断提高，预测时间也由 3 天、5 天逐渐提升至 7 天甚至 10 天。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4a59f09e8fe14edba208dea6d25df852@46958_oswg148764oswg685oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">南、北半球 (SH, NH) 的天气预报技术随时间的演进</p><p>目前，欧洲中期天气预报中心的预报模式需要对每一水平层的 200 万个网格，以 10 分钟的步长进行 10 天的预报，每天运行 2 次。<strong>因此，他们需要在 2.5 小时内，完成约 400 亿个网格的运算，需要很高的计算成本。</strong></p><p><strong>高昂的计算费用阻碍了数值天气预报方法的进一步发展</strong>。如何在模型分辨率和集合规模之间找到平衡，成了限制集合预报的桎梏。</p><h2>数据驱动的机器学习方法崛起</h2><p>近期，<strong>数据驱动 (Data-Driven) 的机器学习 (ML, Machine Learning) 在天气预报中展现出了巨大的潜力</strong>。2022 年以来，天气预报领域的机器学习模型取得了一系列突破，部分成果可以与欧洲中期天气预报中心的高精度预测匹敌。</p><p>数据驱动的天气预报推理依赖于机器学习模型，而非综合预报系统 (IFS) 中的物理模型， <strong>其预测速度较传统方法提升了几个数量级</strong>。此外，基于机器学习的天气预报是归纳推理的结果，而非传统的演绎推理。这种逻辑学的范式转变改变了天气预报的解释方式—— <strong>这些结果是从以前的数据中学习而来的，因此更具说服力</strong>。&nbsp;</p><h3>数据集：1940 年至今 0.25° 的再分析数据</h3><p><strong>数据驱动模型的出现归功于大规模、高质量的气象学开放数据集</strong> 。 现有的机器学习天气预报模型，训练于欧洲中期天气预报中心的第五代再分析数据， <strong>ERA5 再分析数据集</strong> 。 2016 年现版本综合预报系统 (IFS) 问世时，对 1940 年至今的天气数据进行了再分析，得到了分辨率 0.25° (30 km) 的 ERA5 数据集。&nbsp;&nbsp;</p><h3>FourCastNet：与 IFS 精度相当的 DL 模型</h3><p>2022 年，NVIDIA 发布了 FourCastNet，基于傅立叶预测神经网络， <strong>首次进行了分辨率为 0.25° 的深度学习天气预报。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_774b50bca7dc4bcc9d255dc5d77b81bc@46958_oswg214426oswg914oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">FourCastNet 架构示意图</p><p>在提升分辨率的同时，FourCastNet 在异常相关系数 (ACC, Anomaly Correlation Coefficient) 和均方根误差 (RMSE, Root Mean Squared Error) 方面也没有落后传统的数值天气预报太多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_8111212e74a34968a1741853f91d4d86@46958_oswg176912oswg1080oswg707_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">&nbsp;FourCastNet 与数值天气预报的 ACC 和 RMSE 对比</p><p>以节点小时 (Node-Hour) 为单位，<strong>FourCastNet 的速度大约是传统数值天气预报模型的 45,000 倍</strong>，加上其在高分辨率下的准确性，使得超大规模的集合预报成本迅速降低。</p><h3>GraphCast：基于 GNN 全球中期气象预报</h3><p>GraphCast 是一种基于图神经网络 (GNN) 的神经网络，<strong>采用「编码-处理-解码」配置</strong>，共有 3,670 万个参数。</p><p>编码器通过单层 GNN 将输入网格中的变量映射到内部的多网格中。</p><p><strong>多网格是一个空间均质的图</strong>，有着全球范围的高分辨率。多网格通过 6 次迭代正二十面体（包含 12 个节点，20 个面和 30 条边）形成，每次迭代会对网格进行精细化，将单个三角形划分为 4 个较小的三角形，并将其节点投影至球体上。<strong>最终多网格包含 40,962 个节点</strong>，及精细过程中所有图形的边，形成了包含不同长度的边的层级图。</p><p><strong>处理器使用 16 个非共享的 GNN 层</strong>，在多网格上进行消息传递。解码器使用单层 GNN， 将处理器的学习特征从多网格映射回到经纬度系统中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a21eb0e28fbf47dbae15187873299312@46958_oswg492413oswg647oswg610_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">GraphCast 的框架</p><p>a-c：GraphCast 的输入-预测-迭代过程；</p><p>d-f：GraphCast 的编码-处理-解码配置；</p><p>g：多网格的精细化过程。</p><p>对比欧洲中期天气预报的高分辨率预报 (HRES)，<strong>GraphCast 在 ACC 和 RMSE 上均更胜一筹。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_21ba387793f34572ac6f9fdff31f9e13@46958_oswg45399oswg1002oswg331_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">GraphCast 和 HRES 的预测 RMSE (a&amp;b) 和 ACC (c) 对比</p><p>在 32 台 Cloud TPU v4 设备上训练 3 周后，GraphCast 对 1979 年以来的 ERA5 数据进行了学习。随后， <strong>GraphCast 可以在 60 秒内在单台 Cloud TPU v4 设备上，生成分辨率 0.25° 间隔 6 小时的 10 日天气预报。</strong></p><h3>盘古：基于 ViT 的三维气象大模型</h3><p><strong>盘古气象大模型的输入输出均为三维的气象场</strong>。由于气象场的经纬度分布不均匀，<strong>盘古气象大模型使用了三维的 Vision Transformer (ViT) 对气象数据进行处理</strong>，精度首次超过了主流的综合预报系统 (IFS)。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_485757ffd7b0469085c5c3ae2a677fc5@46958_oswg220036oswg978oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">三维 Vision Transformer 架构</p><p>当预测时间长于 3 天时，从 RMSE 来看，<strong>盘古气象大模型和 IFS 的性能相当</strong>，均优于训练集 ERA5。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_27cba571d30a4254b2a2ce89115fd091@46958_oswg498917oswg992oswg832_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">不同模型的对 T850 和 Z500 的预测性能对比</p><p><strong>&nbsp; a&amp;b：分别为不同模型预测 T850 和 Z500 时的 RMSE；</strong></p><p><strong>&nbsp; c&amp;d：分别为不同模型预测 T850 和 Z500 时的活动强度；</strong></p><p><strong>&nbsp; e&amp;f：分别为不同模型预测 T850 和 Z500 时的偏差。</strong></p><p><strong>综上所述，数据驱动的机器学习天气预报，在预测精度上与传统的数值天气预报模式接近，然而运算设备和运算速度远超数值天气预报模型，说明 AI 天气预报在实际应用中有相当的潜力。</strong></p><h2>机器学习和数值预报 =&nbsp;精度 + 速度</h2><p><strong>在天气预报的内部和外部，机器学习都在以惊人的速度不断发展</strong>。欧洲中期天气预报中心一直在关注数据驱动天气预报的快速崛起，包括 NVIDIA、华为和 Deepmind。&nbsp;</p><p>「FourCastNet 是第一个基于 AI 的分辨率达到 0.25° 的天气预报系统，也是第一个开源的天气预报系统。我们的新版本显著提高了模型的中期性能和长期稳定性，并希望通过神经算子框架，实现超分辨率。」NVIDIA Earth-2 团队的 Anima Anandkumar 说道。</p><p>欧洲中期天气预报中心将这些机器学习模型，和稳定的数值模型一起呈现给了用户，邀请他们从应用侧对系统的操作和性能进行评估。<strong>模型的准确性、可靠性、不确定性和交互性是评估气象产品质量和有效性的关键因素。</strong></p><p>为此，欧洲中期天气预报中心公开了 FourCastNet、PGW 和 GraphCast 基于 IFS 初始条件的预测结果。Florian Pappenberger 表示，「<strong>开放是创新、合作和探索的关键。通过共享数据、方法和结果，进行对比和分析，就能够加速科学发展，最终造福社会。</strong>」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_3b397604e82e4636b16750c4d7c678c7@46958_oswg1054867oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">三个气象 AI 的公开数据</p><p>在欧洲中期天气预报中心的对比中，可以看到基于 AI 的天气预测，在部分性能上已经可以与数值天气预报媲美，将在未来发挥着重要作用。然而，<strong>这些模型尚没有综合预测能力，这是中长期尺度上提供有价值预测的关键。</strong></p><p><strong>开放获取、对比优化、便携易得，AI 正将自己的优势渗透进入传统的天气预报当中</strong>。在将天气预报从超级计算机解放出来的同时，AI 在极端气候事件上也有着不俗的表现。相信 AI 能够同数值天气预报一起，革新天气的预报方式，为农林牧渔、航海航天事业的发展贡献出自己的力量。</p><p><strong>参考链接：</strong></p><p>[1]https://journals.ametsoc.org/view/journals/mwre/29/12/1520-0493_1901_29_551c_tpbolw_2_0_co_2.xml</p><p>[2]https://cir.nii.ac.jp/crid/1573668925699683328</p><p>[3]https://www.nature.com/articles/nature14956</p><p>[4]https://arxiv.org/abs/2202.11214</p><p>[5]https://arxiv.org/abs/2212.12794</p><p>[6]https://phys.org/news/2023-09-ai-weather-showcase-data-driven.html</p><p>[7]https://arxiv.org/abs/2307.10128</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/BHhWQSGpQOCtYOVzCpqJRA" rel="noopener noreferrer nofollow" target="_blank">“HyperAI超神经”（ID:HyperAI）</a>，作者：雪菜，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510748504113416</id>
            <title>祖传“屎山代码”终于有解了，GitHub Copilot Chat下个月全面上线，聊聊天就能看懂代码、捉Bug</title>
            <link>https://www.36kr.com/p/2510748504113416</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510748504113416</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 08:00:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Copilot, ChatGPT, GitHub, 编程方式
<br>
<br>
总结: GitHub在GitHub Universe 2023大会上宣布了AI工具Copilot的最新消息，Copilot将彻底改变开发者的编程方式，通过聊天实现编程、自动识别代码、捕捉代码Bug、快速生成单元测试等功能。GitHub还预览了新的GitHub Copilot Enterprise产品，同时发布了最新的《The State of the Octoverse 2023》报告，呈现AI、云和Git背后开源的最新趋势。GitHub Copilot Chat即将于12月全面上市，搭载GPT-4模型，让开发者可以通过自然语言与GitHub Copilot进行交互。 </div>
                        <hr>
                    
                    <p>都说 Copilot 是比 ChatGPT 更懂程序员的工具，这不，在今天凌晨 GitHub 召开的&nbsp;GitHub Universe 2023 大会上，他们便带来了有关解放程序员双手的神器的 Copilot 的最新消息，这一次，AI 将彻底改变开发者的编程方式。</p><p>在本次大会上，GitHub 正式宣布&nbsp;GitHub Copilot Chat 即将于 12 月全面上市，搭载&nbsp;GPT-4 模型，通过聊聊天实现编程、自动识别代码、捕捉代码 Bug、快速生成单元测试等等，让看别人遗留下来代码带来的痛苦轻松交给 GitHub Copilot Chat 一键搞定！</p><p>GitHub 还预览了新的 GitHub Copilot Enterprise 产品，费用为 39 美元/月，将于 2024 年 2 月推出。除此之外，其还发布了最新的《The State of the Octoverse 2023》报告，多方位呈现 AI、云和 Git 背后开源的最新趋势。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_da971a6858994239ad8d277b6fe91e0c@46958_oswg379300oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>再等一个月，GitHub Copilot Chat 就要来了！</strong></h2><p>在今年 3 月，GitHub&nbsp;发布重磅“炸弹”——推出<strong>&nbsp;Copilot X&nbsp;</strong>计划，将 ChatGPT 引入 IDE&nbsp;之际，也对外发布了 Copilot Chat 预览版本，当时&nbsp;GitHub CEO Thomas Dohmke&nbsp;评价道，这款新的 Copilot 将使开发者的生产力提高 10 倍。</p><p>当下，Thomas Dohmke 表示，「正如 GitHub 是在 Git 上创建的一样，今天我们在 Copilot 上重新创建。开源和 Git 从根本上改变了我们构建软件的方式。现在很明显，人工智能正在以指数级的速度迎来同样的彻底变革。在短短的时间内，GitHub Copilot 就将 GitHub 扩展并发展成为世界领先的人工智能开发者平台」。</p><p>简单来看，GitHub Copilot Chat 宛如专门为编程而设计的类 ChatGPT 版本，它可以让开发者直接通过一个聊天界面，使用自然语言与 GitHub Copilot 进行交互。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_c99cb0d2faeb40bc8ee2757a576039f3@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这一次&nbsp;Copilot Chat 也进行了全新的技术升级，作为开发者，你可以用它来查找代码 Bug、编写单元测试、帮助调试代码等等，更详细功能如下：</p><p>GitHub 与 OpenAI 强强联手，让当前先进的&nbsp;GPT-4&nbsp;大模型成功登陆&nbsp;Copilot Chat，由此带来更准确的代码建议和解释。</p><p>代码感知指导和代码生成：Copilot Chat 使用开发者已经编写的代码作为上下文，能够解释复杂的概念，根据你打开的文件和窗口建议代码，帮助检测安全漏洞，并协助查找和修复代码、终端中和调试器中的错误。</p><p>使用 AI 支持的内联 Copilot Chat 迭代代码：<strong>通过新的内联 Copilot Chat，开发人员可以直接在代码和编辑器流程中讨论特定的代码行。</strong></p><p><strong>斜杠命令</strong>可以方便开发者快捷完成重要任务：GitHub 正在向 GitHub Copilot 引入斜杠命令和上下文变量，因此修复或改进代码就像输入 /fix 一样简单，生成测试可以直接输入 /tests。</p><p>一键应用 AI 强大的功能：只需单击一下，智能操作即可为你的工作流程提供强大的快捷方式，无论你是需要修复建议、拉取请求审核内容，还是通过生成的响应来加速提交和拉取请求。</p><p>将 Copilot Chat 引入 JetBrains：Copilot Chat 将登陆 JetBrains IDE 套件，今天现已推出预览版。</p><p>除此之外，GitHub 还宣布将 <strong>GitHub&nbsp;Copilot Chat 直接集成到 github.com 中</strong>，方便开发人员可以通过 Copilot Chat 提供建议、摘要、分析和答案来深入研究代码、拉取请求、文档和一般编码问题。</p><p>而且，结合 GitHub 高级代码搜索的强大功能，Copilot Chat 能够了解并帮助开发者处理流行开源项目的最新更改。</p><p>当然，移动端的开发者也不用着急，GitHub Copilot Chat 也将作为现有 GitHub Copilot 订阅的一部分，在移动应用程序中提供。“利用在 iPhone 和 Android 设备上键入或说出的自然语言的力量，开发人员将获得任何编程问题以及有关他们在应用程序中查看的存储库、文件或文档的答案。即使他们不在办公桌前，他们也可以完成工作”，GitHub 在官方公告中写道。&nbsp;</p><p>需要注意的是，正如文章伊始所预告的，作为开发者编码的重要工具，GitHub&nbsp;<strong>将在 2023 年 12 月让&nbsp;GitHub Copilot Chat&nbsp;作为现有 GitHub Copilot 订阅的一部分向组织和个人全面开放</strong>。而 GitHub Copilot 订阅费用为个人每月 10 美元或者每年 100 美元，企业每用户每月 19 美元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4fb3564e4a864f78b0b3db4e2654edc6@46958_oswg16621oswg713oswg488_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，GitHub Copilot Chat&nbsp;这款产品也可以<strong>免费提供给经过验证的教师、学生和流行开源项目的维护者。</strong></p><p>现在，你可以申请加入 Copilot Chat 等候列表：https://github.com/features/preview</p><h2>39 美元/每月，GitHub Copilot Enterprise 将于 2024 年 2 月上市</h2><p>本次大会上，GitHub 还分享了一组关于 GitHub Copilot 应用相关的数据，其表示，「在作为 IDE 中提供的自动完成功能的早期阶段，GitHub Copilot 已经使开发人员的速度提高了 55%，但开发人员通常每天只编写大约 2 小时的代码，并且在整个软件开发生命周期中都陷入了平凡的任务之中。更重要的是，当开发人员无法查明和解决组织代码库特有的问题、错误或漏洞时，他们会花费更多的时间来破译而不是交付。」</p><p>为了让更多的开发者团队以更快的速度和规模进行部署，GitHub 宣布 GitHub Copilot Enterprise 计划，<strong>该计划将允许公司根据其内部代码库微调底层模型</strong>。</p><p>这里的做法是，只要通过将 Copilot Chat 连接到开发团队在 github.com 上的存储库，Copilot Enterprise 允许开发团队快速掌握代码库、搜索和构建文档、根据内部和私有代码获取建议，并快速审查拉取请求。此外，整个 GitHub 都将提供智能操作，例如生成拉取请求摘要的能力，帮助开发人员只需单击按钮即可保持流程状态。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_c55bdfb163844b6fb8af0651ca9c0104@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不仅如此，企业还可以对模型进行微调，使 Copilot 能够更好地完成代码并回答特定代码库所特有的具体问题。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_bc2c5670f45946d78c67624d1139b401@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据官方公告透露，GitHub Copilot Enterprise 将于 2024 年 2 月全面上市，每位用户每月 39 美元。</p><h2>扩展&nbsp;GitHub Copilot</h2><p>GitHub 还在本次大会上推出：</p><p>GitHub Copilot 合作伙伴计划：这一计划将为 GitHub Copilot 创建一个<strong>插件生态系统</strong>，目标是拓宽开发人员使用 AI 的范围。GitHub 设想的用例包括帮助提高数据库查询的性能、检查功能标志的状态以及查看 A/B 测试的结果。</p><p>GitHub Next 的研究团队开发了一座由人工智能驱动的桥梁，帮助开发人员克服将想法转化为代码的障碍。这项技术名为 "GitHub Copilot Workspace"，将于 2024 年投入使用。做一下简单的解释，即当开发者在 Copilot Workspace 提出问题时，开发者会收到系统自动生成的计划，了解如何采取行动进行更改，然后进行构建、测试和验证是否成功。如果开发人员引入错误，将对其进行修补并重新运行代码。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_cb87352ebdd84268a599c5d107fd67b5@46958_oswg365979oswg1080oswg471_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在安全方面，GitHub Copilot 应用了基于 LLM 的漏洞防护系统，可以实时阻止不安全的编码模式。GitHub Copilot Chat 还可以帮助识别 IDE 中的安全漏洞，利用其自然语言功能解释漏洞的机制，并针对突出显示的代码提出具体修复建议。这些功能现在已经推出了预览版，很快也会包含在 GitHub 高级安全订阅服务中。</p><h2><strong>年度报告出炉：JavaScript 稳居第一，生成式 AI 项目首次入榜 Top 10</strong></h2><p>除了有以上最新功能之外，GitHub 借此机会同时推出了一年一度 Octoverse 报告。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2ce6e6d48e944414970d9ccc6631d367@46958_oswg469019oswg1080oswg572_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据报告显示，在过去一年中，美国拥有 2020 万开发者，开发者人数增长了 21%，继续拥有全球最大的开发者社区。中国开发者人数位居第三位，相较两年前下降了一位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_e41d542537e74424b08d7609efc178c8@46958_oswg89455oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>过去一年，随着 ChatGPT 的到来为开端，生成式 AI 成为众多科技公司以及开发者关注的重点。&nbsp;</p><p>数据显示，2023 年的生成式 AI 项目数量是 2022 年全年的两倍多，开发者也从使用 TensorFlow、Pytorch 等机器学习库构建项目转为使用预训练模型和 API 来构建生成式人工智能驱动的应用。</p><p>生成式 AI 推动生成式 AI 项目的个人贡献者在全球范围内大幅增长，同比增长 148%，生成式 AI 项目总数也同比增长 248%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_c36709b4d64249e9926dcc76d4e60840@46958_oswg115956oswg1080oswg595_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“随着越来越多的开发人员熟悉构建基于人工智能的生成式应用程序，我们预计不断增长的人才库将支持寻求开发自己的基于人工智能的产品和服务的企业”，这份报告指出。</p><p>那么，在新一轮技术浪潮之下，开发者应该掌握哪些主流的开发技术？</p><h3>TypeScript 首次超越 Java，成为第三大主流编程语言</h3><p>数据显示，JavaScript 仍然是目前最流行的编程语言，Python 排在第二位。今年，TypeScript 首次取代 Java，成为 GitHub 上 OSS 项目中第三大最受欢迎的语言，其用户群增长了 37%。TypeScript 是一种集语言、类型检查器、编译器和语言服务于一体的语言，它于 2012 年推出，标志着渐进类型的到来，它允许开发人员在代码中采用不同级别的静态和动态类型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_67a844dd805f437984516132214845e9@46958_oswg152915oswg1080oswg592_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与此同时，用于数据分析和操作的流行语言和框架显著增加。T-SQL 和 TeX 等古老语言在 2023 年不断发展，这凸显了数据科学家、数学家和分析师越来越多地使用开源平台和工具。这也意味着编程语言不再仅仅局限于传统软件开发领域。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_c84a214a44514fb3b0746ae18eb7111c@46958_oswg118444oswg1080oswg596_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与 GitHub 上应用广泛的流行语言相比，GitHub 报告指出，2023 年创建的项目中使用的最流行语言具有显著的一致性。一些值得注意的异常值包括 Kotlin、Rust、Go 和 Lua，它们在 GitHub 上的新项目中出现了更大的增长。</p><p>Rust 虽然总体使用率相对其他语言较低，但其年增长率为 40%，并连续第八年被 2023 年 Stack Overflow 开发者调查评为最受赞赏的语言。</p><p>它和 Lua 都以其内存安全性和效率而闻名，并且都可以用于系统和嵌入式系统编程。Go 最近的增长是由 Kubernetes 和 Prometheus 等云原生项目推动的。</p><h3>开发人员正在 GitHub 上大规模运行云原生应用程序</h3><p>随着 2019 年云原生开发的大规模增长，IaC 在开源领域也开始持续增长。2023 年，Shell 和 Hashicorp 配置语言（HCL）再次成为开源项目中的顶级语言，这表明运营和 IaC 工作在开源领域的地位日益突出。</p><p>HCL 的采用率同比增长了 36%，这表明开发人员正在为其应用程序使用基础设施。</p><p>HCL 的增加表明，开发人员越来越多地使用声明式语言来决定如何利用云部署。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2d7313954b5d4531961a57ff6cde0281@46958_oswg69605oswg1080oswg261_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在 GitHub 上，2023 年，430 万个公共和私有存储库使用 Dockerfile，超过 100 万个公共存储库使用 Dockerfile 来创建容器。过去几年，我们看到 Terraform 和其他云原生技术的使用量不断增加。IaC 实践的增加也表明开发人员正在为云部署带来更多标准化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a2ac1b39eca9450cad93c1f038b05fb2@46958_oswg96043oswg1080oswg587_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同时，开发人员正在将更多的工作流程自动化。在过去一年中，开发人员使用 GitHub Actions 自动执行公共项目任务、开发 CI/CD 管道等的时间增加了 169%。开发人员平均每天在公共项目中使用超过 2000 万分钟的 GitHub Actions。随着 GitHub Marketplace 中的 GitHub Actions 数量在 2023 年突破 20,000 大关，社区规模还在不断扩大。</p><p>这表明整个开源社区对 CI/CD 自动化和社区管理的认识在不断提高。</p><p>时下，生成式人工智能进入 GitHub Actions。开发者社区中人工智能的早期采用和协作能力在 GitHub Marketplace 中的 300 多个人工智能驱动的 GitHub Actions和 30 多个 GPT 支持的 GitHub Actions 中显而易见。</p><p>此前，GitHub 赞助的 2023 年开发者调查中也发现，92% 的开发人员已经在工作内外使用 AI 编码工具，81% 的开发人员认为人工智能编码工具将使他们的团队更具协作性。</p><h3>生成式 AI 项目成为开源热门</h3><p>2023年，开发者为 GitHub 上的开源项目做出了 3.01 亿次贡献，其中既有像 Mastodon 这样的热门项目，也有像 Stable Diffusion 和 LangChain 这样的生成式人工智能项目。</p><p>盘点 2023 年热门的开源贡献项目时，数据显示，商业支持项目继续领先。2023 年，按贡献者总数计算，主流的项目绝大多数由商业支持。这一趋势在去年得到了延续，microsoft/vscode、flutter/flutter 和 vercel/next.js 在 2023 年再次跻身前十名。</p><p>生成式人工智能在开源和公共项目中发展迅速。2023 年，我们看到基于生成式人工智能的开源软件项目，如 langchain-ai/langchain 和 AUTOMATIC1111/stable-diffusion-webui，跃居 GitHub 上贡献者数量最多的项目。越来越多的开发人员正在使用预先训练好的人工智能模型构建 LLM 应用程序，并根据用户需求定制人工智能应用程序。</p><p>开源维护者正在采用生成式人工智能。在至少有一个星级的开源项目中，近三分之一的维护者都在使用 GitHub Copilot。这是继 GitHub 向开源项目维护者免费提供 GitHub Copilot 之后的又一举措，表明生成式人工智能在开源项目中的应用日益广泛。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_84840acbe92d47f59275beee8b97538a@46958_oswg108388oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在开源方面，GitHub 于近期参与的一项调查显示，多数开发人员都表示他们的公司至少采用了一些内源模式，超过一半的开发人员表示他们的组织中有活跃的内源文化。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_81d7930375264a7181a052f5176cfe21@46958_oswg176820oswg1080oswg596_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以上便是本次 GitHub Universe 2023，要想了解更多，也可以查阅完整的报告内容：&nbsp;</p><p>https://github.blog/2023-11-08-the-state-of-open-source-and-ai/#the-explosive-growth-of-generative-ai-in-2023</p><p>以及 GitHub 官方博客：&nbsp;</p><p>https://github.blog/2023-11-08-universe-2023-copilot-transforms-github-into-the-ai-powered-developer-platform/</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/OlW-UsPzKqpwjZFWI-cOhw" rel="noopener noreferrer nofollow" target="_blank">“CSDN”（ID:CSDNnews）</a>，整理：屠敏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510727316996361</id>
            <title>高达2万亿参数，远超GPT-4，亚马逊全新Olympus大模型曝光，即将对外公布</title>
            <link>https://www.36kr.com/p/2510727316996361</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510727316996361</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:35:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊, 大模型, Olympus, AI助手
<br>
<br>
总结: 亚马逊正在训练一个规模为2万亿参数的大模型，代号为Olympus。这个模型将被应用于亚马逊的在线零售商店、Echo设备上的Alexa语音助手以及AWS平台。亚马逊希望通过这个大模型来提供更先进的AI助手服务。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_420e0eb0c9d546c4891d61257f544957@46958_oswg218246oswg1070oswg421_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>作为第一大云计算厂商却似乎在大模型时代默默无闻的亚马逊，终于被爆料了！据称，亚马逊正在训练一个高达2万亿参数的大模型，内部代号「Olympus」。取代OpenAI的时刻，就要来了？</p><p>似乎在大模型浪潮中一直缺席的亚马逊，终于要对外公布最新的进展了。</p><p>根据外媒爆料，亚马逊正在训练他的第二个大语言模型——内部代号「Olympus」。</p><p>据说这个模型规模达到2万亿（2000B）参数，远远超过GPT-4（爆料显示GPT-4的参数约为1万亿），很有可能在今年12月份就能上线。</p><p>亚马逊计划将「Olympus」接入在线零售商店、Echo等设备上的Alexa语音助手以及为AWS平台提供新功能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4a4d45da73344c298d9d8794280e3db1@46958_oswg1097627oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在上个月在公开场合，亚马逊设备和服务高级副总裁Dave Limp曾经公开表示，亚马逊的Alexa的AI助手将会像其他生成式AI助手一样，帮助用户起草邮件，用自然语言完成生活中的各种任务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_71fd3d50b9864207b1374aa3b8c88550@46958_oswg63090oswg1080oswg149_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他认为，等到那个时候，Alexa语音助手也将会独立于Amazon Prime收费，因为云端运行的模型会有「可观的推理成本」。</p><p>而且Alexa会和Amazon Prime一样「为用户创造难以估量的巨大价值」。</p><p>而这一切，都需要亚马逊拥有能力顶尖的AI模型。</p><p>国外网友也调侃，等亚马逊训练出了新的模型，会在我自己意识到想买啥之前就知道我想买啥了🐶。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b87caf4d5a7d43209acc45d39a83ec08@46958_oswg66452oswg1080oswg167_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而亚马逊在今年早些时候推出的AI服务「Titan Embeddings」，市场反响一般，而且只通过AWS面向企业级客户提供服务。</p><p>根据外媒的说法，在所有硅谷大厂都在围绕生成式AI构建新的服务的背景之下，亚马逊CEO Andy Jassy也同样将构建全新的AI作为当下工作的首要重点。</p><p>构建「Olympus」的团队由Alexa语音助手的前负责人Rohit Prasad领导，直接向CEO Andy Jassy汇报。</p><h2>40亿刀投资Anthropic</h2><p>在目前亚马逊已经搭建的生成式AI版图中，除了目前还在水下秘密训练的「Olympus」之外，最重要的要数10月份刚刚完成的对于大模型巨型独角兽Anthropic的40亿美元的投资。&nbsp;</p><p>在这笔投资之后，Anthropic的模型也成为了AWS服务中的一部分，用户可以通过Amazon Bedrock访问Claude，让AWS能够向客户提供最先进的大语言模型服务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d7be5b2af4e64fff8d7f33059e979ca1@46958_oswg161930oswg1080oswg443_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Lonely Planet和LexisNexis Legal &amp; Professional等世界知名的企业已经通过AWS，接入了专门针对自己产品微调的Claud 2模型。</p><p>同时，Anthropic还会使用亚马逊的两款AI芯片——Trainium和Inferentia进行模型的推理和训练，和亚马逊一起在未来共同开发AI芯片。</p><p>这笔40亿美元的投资，已经让亚马逊和目前硅谷第二炙手可热的大模型初创公司Anthropic，建立起了类似于「微软&amp;OpenAI」这样的传统巨头+巨型独角兽的联盟。</p><p>对于一个拥有全球数亿普通用户的购物平台来说，训练自己的大模型，让自己能够在即将到来的AI时代掌握住自己的命运，似乎是顺理成章的事。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_40970dd0602344ac8bd7e234f283a9b6@46958_oswg39614oswg640oswg335_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就像亚马逊在10多年前，从一个在线购物平台，进入云计算服务行业，成为如今的云计算巨头一样。</p><p>亚马逊有能力，也有必要在AI赛道，再次完成这样的转身。</p><h2>人工智能浪潮中的巨轮</h2><p>在所有关于首席执行官交接失误的头条新闻中，亚马逊（AWS）从创始人到继承人的交接却相当顺利。&nbsp;</p><p>亚马逊的现任CEO Jassy于1997年加入亚马逊，当时贝索斯刚刚创立公司三年，他与创始人建立了深厚的关系，并被创始人选为技术顾问。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f5df7103ef854c49bf768244c6ff6dc2@46958_oswg240002oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Jassy于1997年与其他几位哈佛MBA同事一起加入亚马逊，担任营销经理。2003 年，他和Jeff Bezos提出了创建云计算平台的想法，该平台后来被称为Amazon Web Services，并于2006年推出。</p><p>从通过互联网远程提供的简单计算和存储服务开始，AWS不断定义企业计算的新时代，并为基于AWS或围绕AWS构建新的商业模式。</p><p>Jassy在2021年7月成为首席执行官后，将AWS打造成了价值800亿美元的企业——这是一家大公司诞生第二家巨型公司的罕见范例，令许多竞对手羡慕不已。</p><p>而如今，大型语言模型正在打破科技界的平衡。在与炙手可热的大型语言模型开发商OpenAI结成战略联盟后，微软的地位再次上升。</p><p>事实上，亚马逊与其他大型科技公司一样，也始终追赶着人工智能的浪潮。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_cc27658b3b2944c3a6707accb87e6ffe@46958_oswg868097oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>六年前，亚马逊推出了一系列新的人工智能技术，其中包括一款软件工具SageMaker，Intuit和通用电气等公司都用它来构建自己的机器学习模型。</p><p>AWS甚至参与了OpenAI的原始融资。</p><p>Jassy和亚马逊都非常熟悉OpenAI及其大胆年轻的首席执行官Sam Altman。亚马逊是OpenAI的早期投资者，当时该项目还只是一个非营利组织，而OpenAI也曾使用过AWS。</p><p>Jassy确信，亚马逊在帮助客户运行各种机器学习模型方面的历史，将为其进一步拓展人工智能领域奠定良好的基础。</p><p>另外，AWS高管指出，云计算人工智能服务市场刚刚起步，AWS有足够的时间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_5455dbf8930a4d88b3529d3e2a423e67@46958_oswg86431oswg1024oswg574_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据The Information周二报道，在未来12个月内，仅OpenAI一项人工智能服务的收入就将超过10亿美元，但与AWS去年公布的800亿美元总收入相比，这只是九牛一毛。</p><p>人工智能领域的发展，尤其是大语言模型体现出的能力，在当今的时代和经济背景下激起了一朵难得的浪花。</p><p>亚马逊作为第一大云服务厂商，多年来在基础设施方面的建设，以及技术层面的积累，使其拥有巨大的竞争优势。</p><p>「Olympus」是一个明确的信号，表明亚马逊希望在人工智能领域掌握自己的命运。开发属于自己的LLM，不在关键技术上依赖他人，这将是一个明智之举。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ecdf2413d1f54f61908b8f744ee52437@46958_oswg527605oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>网友热议</h2><p>对于亚马逊的新模型「Olympus」，网友也表示了自己的期待：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d51064b3484540d39bdbb7b7fe89f020@46958_oswg148769oswg1080oswg277_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「亚马逊令人印象深刻的举动！为Olympus培养一支全新的团队表明了他们在ML和AI领域进一步发展的承诺。看到这可能带来的突破令人兴奋。谁知道呢？Olympus可能会把我们带到新的高度！」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_264a5699d7404f939682933fb37074ff@46958_oswg132064oswg1080oswg319_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「亚马逊发布的Olympus——一个人工智能的巨人，将使GPT-4相形见绌。他们不只是在玩游戏，他们还在通过40亿美元的人工智能投资来加大赌注。Alexa呢？她即将获得天才升级。」</p><p>参考资料：&nbsp;</p><p>https://www.theinformation.com/briefings/amazon-developing-olympus-ai-to-narrow-gap-with-microsoft-openai&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/MaRJN-SoWICxRIkWQfhNkg" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：润 alan&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510727168606215</id>
            <title>GPT-5明年降临？爆料人泄露多模态Gobi就是GPT-5，已初现自我意识</title>
            <link>https://www.36kr.com/p/2510727168606215</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510727168606215</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:34:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT-5, 多模态模型, 2024年初发布
<br>
<br>
总结: OpenAI首届开发者大会带来了一系列新品更新，包括GPT-4 Turbo、大幅降价、面向开发者新功能和自定义GPT等。而在2024年初，OpenAI将发布GPT-5多模态模型，该模型不仅支持文本和图像，还将支持视频。据爆料人称，GPT-5已经具有一定程度的自我意识，并且7个政府机构正在测试最新模型。这一消息与之前的泄露信息相吻合，证明了GPT-5传言的可信度。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_155de2bd6a3d4bf6886f91e21525ff0c@46958_oswg164735oswg1072oswg411_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>首届开发者大会余温还在，GPT-5突然被爆2024年初就来。OpenAI首秀可谓是赚足了眼球，一系列新品更新，直接让ChatGPT和API同时崩溃。</p><p>OpenAI首届开发者大会，就是一场AI盛宴。&nbsp;</p><p>GPT-4 Turbo、大幅降价、面向开发者新功能、自定义GPT等等重磅更新，早已让AI初创公司望尘莫及。&nbsp;</p><p>还没等人们消化完，挖墓人再爆猛料，OpenAI Gobi，也就是GPT-5多模态模型将在2024年年初震撼发布。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a93cb1e5777446debed7f899a2456d45@46958_oswg98113oswg1080oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前，全网已有 16+万人围观。&nbsp;</p><p>根据Roemmele的说法，目前Gobi正在一个庞大的数据集上进行训练。不仅支持文本、图像，还将支持视频。&nbsp;</p><p>有人问道，OpenAI内部员工称下一代模型已经实现了真的AGI，你听说过这件事吗？&nbsp;</p><p>爆料人称，「GPT-5已经会自我纠正，并且具有一定程度的自我意识。我认识的熟人已经看过它的演示，目前，7个政府机构正在测试最新模型。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ae7eb04a0d0e4eb09547796a5591d887@46958_oswg231338oswg1080oswg493_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还记得，Sam Altman在大会收尾中暗示，OpenAI正在进行下一轮重大创新，到时候所有人会发现今天发布的东西是如此的不值一提。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_789f232a7ba84d8589f38b4e52ff9d5e@46958_oswg395788oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这恰恰与爆料人的透露信息相吻合。&nbsp;</p><p>Roemmele曾在开发者大会前，正确地泄露了人人可定制的「GPTs」，更加证明了GPT-5传言的可信度。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_64b800cfeebc4a6c858c877f44b01c6a@46958_oswg371575oswg1080oswg1229_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就在刚刚，Roemmele还爆料称，OpenAI的最强竞争对手之一——推出Claude模型的Anthropic，也即将发布一个大新闻。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f86caf37c7504b7db4f2af8e5aab3f5d@46958_oswg86564oswg1080oswg196_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>GPT-5真的要来了？</h2><p>关于下一代更先进的模型，Altman对外一直都闭口不言。&nbsp;</p><p>6月，Altman曾表示，GPT-5距离准备好训练还有很长的路要走，还有很多工作要做。他补充道，OpenAI正在研究新的想法，但他们还没有准备好开始研究GPT-5。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_1acc9a7db717444c8fa8d3e12e2d092b@46958_oswg46475oswg1080oswg180_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就连微软创始人比尔盖茨预计，GPT-5不会比GPT-4提供重大的性能改进。&nbsp;</p><p>但是外媒各种爆料虽说不能完全信，但也不可不信。&nbsp;</p><p>其实，早在4月的时候，有人就曾对外透露，OpenAI内部正在训练一个多模态模型——Gobi。&nbsp;</p><p>这一模型上下文窗口有64k，但是由于耗费巨大算力，目前还不能发布。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_be0721ba278744a8b3dca17930a3eaa9@46958_oswg622929oswg1080oswg1396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>9月初，DeepMind联合创始人、现Inflection AI的CEO Mustafa Suleyman，在接受采访时曾放出一枚重磅炸弹——据他猜测，OpenAI正在秘密训练GPT-5。&nbsp;</p><p>Suleyman认为，Sam Altman最近说过他们没有训练GPT-5，可能没有说实话。（原话是：Come on. I don’t know. I think it’s better that we’re all just straight about it.）&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_db0bf1770c9440a59ecc323fc49c59a4@46958_oswg951729oswg1080oswg674_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同月，外媒The Information爆料，一款名为Gobi的全新多模态大模型，已经在紧锣密鼓地筹备了。&nbsp;</p><p>在GPT-4 Vision之后，OpenAI有可能会推出更强大的多模态大模型，代号为Gobi。&nbsp;</p><p>跟GPT-4不同，Gobi从一开始就是按多模态模型构建的。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_18a773ee4f8341988071c149d527dc6b@46958_oswg61319oswg1080oswg280_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另有网友蹦出来说，OpenAI本来计划在首届开发者日上发布GPT-4 V模型，但是由于Gobi和Arrakis的泄露，不得不提前发布。&nbsp;</p><p>从GPT-4 V技术报告中的参考文献中就可以看出破绽。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_45c90df2fcb44816823d81c6a5a726f6@46958_oswg422638oswg1080oswg915_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在看来，Gobi这个模型不管是不是GPT-5，但从多方泄露的信息来看，它目前是OpenAI团队正在着手研究的项目之一。&nbsp;</p><p>9月下旬，Roemmele曾透露自己访问的谷歌Gemini，可以与GPT-4相媲美。&nbsp;</p><p>如果GPT-5的传言属实，谷歌就得用Gemini来与更先进的GPT-5抗争。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9f04daf365c24ed7a702ea1114b44de1@46958_oswg828959oswg1080oswg1084_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大会上，OpenAI的一系列更新再次向世界证明自己在生成式AI领域的领导地位。&nbsp;</p><p>如果谷歌等竞争对手想要追赶ChatGPT和API服务成功范式，还需要做出很多努力。&nbsp;</p><p>从这届春晚火爆程度来看，OpenAI根本没有直接的竞争对手。&nbsp;</p><h2>ChatGPT宕机，网友集体炸锅</h2><p>就在昨晚，许多人发现自己的ChatGPT突然下线，引爆舆论。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9eb1bbec4ec24466853f49d2d1824133@46958_oswg75246oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不一会儿，OpenAI发布公告称，由于ChatGPT服务器被挤爆，整整宕机了2个小时，还有API也是。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_70c6d64cf457465a92657ee278b1cfaa@46958_oswg327544oswg1080oswg1151_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对此，Altman本人则立即做出了堪称非常「凡尔赛」的回应：&nbsp;</p><blockquote><p>我们在开发者大会上发布的新功能的使用量远远超出了预期。&nbsp;</p><p>我们本计划于周一对所有订阅用户开放GPT，但仍然无法实现。我们希望很快可以做到。由于负载太大，在短期内服务可能会不稳定。对此感到抱歉。&nbsp;</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b1d1388415df49f58781d81747875e9a@46958_oswg171201oswg1080oswg505_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更新的公告显示，ChatGPT和API还是会有一些阶段性的崩溃。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_3760a9421cb24a3092e506b2b100783a@46958_oswg125106oswg1080oswg615_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从这个图中，可以看出宕机的时间段。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_c1d64e730083472782d641cabfca3bbf@46958_oswg63336oswg1080oswg445_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于全世界人来说，ChatGPT宕机简直就是巨大灾难。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b303b284aa844157970b0779cc8af259@46958_oswg143211oswg1080oswg1231_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>没了ChatGPT，所有人的工作状态是这样子的....&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_6c0a675f3cb442b082a07419e45ee0ec@46958_oswg915839oswg1026oswg710_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当世界最需要ChatGPT的时候，它却消失了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9dfd5c6f11434c579198ba4d8eacaed6@46958_oswg714635oswg1080oswg938_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>你的ChatGPT还好吗？&nbsp;</p><p>参考资料：&nbsp;</p><p>https://the-decoder.com/openais-altman-says-todays-ai-will-be-quaint-by-2024-in-line-with-first-gpt-5-rumor/&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/FW1KgR5S5yFRPwtTQ6SFpg" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：桃子 好困&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510691070427144</id>
            <title>开发者「第二大脑」来袭，GitHub Copilot更新，人类开发参与进一步减少</title>
            <link>https://www.36kr.com/p/2510691070427144</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510691070427144</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:21:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Andrej Karpathy, Copilot Workspace, AI开发工具, 任务选择
<br>
<br>
总结: GitHub发布的Copilot Workspace是一款AI开发工具，旨在帮助开发者解决编码过程中遇到的问题和困难。它可以根据开发者提出的问题，自动提供解决方案，并在整个软件开发过程中提供支持。Copilot Workspace的任务选择功能可以减少复杂性，提高生产力，使开发者能够更轻松地完成任务。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_47923906991e44a283cc56b1e5e14e9d@000000_oswg28857oswg648oswg230_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>是什么让 Andrej Karpathy 感慨，人类在软件开发过程中直接编写代码的贡献将越来越小，直接输入和监督作用将更加抽象化。最终，人类的角色将仅仅是进行基本的审核和确认，而不再是主要的编程和开发者。</p><p>原来是 GitHub 新发布的 Copilot Workspace，它重新构想了开发者的内部流程。如果 AI 开发工具是开发者的第二双手，那么 Copilot Workspace 将是开发者的「第二个大脑」。</p><p>在编码的过程中，最头疼的莫过于遇到不熟悉的软件仓库、编程语言或框架。解决这些问题带来的困难，可能会拖延你完成任务的时间，甚至导致根本无法完成。在时间内想要快速掌握这些，重振旗鼓并不容易。但 Copilot Workspace 或许能够让你事半功倍，甚至能够帮助你完成更大、更复杂的任务。</p><h2>Copilot Workspace，你的「第二个大脑」</h2><p>Copilot Workspace 侧重于任务选择、意图表达和与 AI 合作寻求解决方案。这样做的目的是减少复杂性，提高生产力，同时还能保持软件开发中重要的方面，如决策和创造性和自主权。</p><p>你可以向 Copilot Workspace 提出问题，它会自动提出解决方案。Copilot Workspace 拥有问题（包括所有评论和回复）和代码库的全部上下文，因此它既能理解你想做什么，也能理解你的代码具体内容。如果 Copilot Workspace 提出的解决方案不完全正确，你也可以编辑流程中的任何步骤，从行为到计划，再到代码，全部都可以用自然语言完成。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d2af7aaa1fbc45a88b9e0afc21185b3c@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">编辑流程中的步骤，进行调整</p><p>Copilot Workspace 可在整个软件包的粒度范围内运行，并可跨不同编程语言对多个文件进行连贯修改。它既能处理核心编码任务，也能处理脚手架类型的任务，如「建立测试框架 」或「为持续集成编写 GitHub Actions 工作流」。它已在 GitHub Next 中被使用，用于开发 Copilot Workspace 自身和其他项目。</p><h2>以任务为中心的工作流程</h2><p>Copilot Workspace 能够帮助开发人员完成完整的开发任务，这些任务通常以 GitHub 问题的形式指定和跟踪。因此，Copilot Workspace 可以将问题作为输入，自动提取代码的当前行为，提出可解决该问题的新行为，制定计划，并实施该计划（即编写代码）。Copilot Workspace 拥有问题的全部上下文，包括所有注释，甚至可以跟踪问题中的链接以提取信息，帮助完成任务。</p><p>用户反馈和迭代是 Copilot Workspace 所注重的。从建议的新行为、计划到实施，你可以编辑流程的每一步。例如，在实施计划并看到代码后，您可以返回并调整行为或计划，然后再试一次。你甚至可以在多个标签页中打开同一个问题，探索几条不同的路径。</p><p>之前使用 LLM 完成开发人员任务的尝试主要集中在对话上，但 Copilot Workspace 更加基于任务的用户界面具更加结构化，并且有明显的优势：</p><p>1. Copilot Workspace 可以全面了解问题的来龙去脉，从而提出正确的解决方案。</p><p>2. 结构化的输出（原始和修改后的行为、计划和实施）使得用户可以在恰当的抽象层次上方便地指导 Copilot Workspace。</p><p>目前，Copilot Workspace 以 GitHub 的问题作为起点，但计划未来将支持更多的入口点。例如，Copilot Workspace 可以帮助开发人员处理通过 CodeQL 发现的安全警报，迁移到新版本的依赖库或从一个库迁移到另一个库，以及解决 PR 审核中的评论问题。</p><h2>云驱动的智能体</h2><p>GitHub 结合 AI 智能体技术和 GitHub Codespaces 实现无头、短暂、安全的计算方式。当用户点击「运行」按钮时，后台中会创建一个新的 codespace，将修改后的代码推送到其中，并尝试构建项目。如果构建失败，我们会将错误信息和代码反馈给 Copilot Workspace，并要求其修复构建。一旦构建成功，修改后的代码会同步回 Copilot Workspace 的用户界面，让用户看到构建是如何被修复的。如果运行的项目是 Web 应用，codespace 上的端口会转发到只有该用户能访问的 URL。用户可以点击并查看 Web 应用的实时预览，从而直观地验证 Copilot Workspace 是否按照他们的预期执行。</p><p>由于大型语言模型（LLMs）并不完美，许多任务的「最后一公里」显得十分重要。Copilot Workspace 允许你打开 Codespace 并从中断的地方继续，可以在具有安全运行时的完整云 IDE 中完成任务。</p><h2>为协作而设计</h2><p>只需点击「共享」按钮，Copilot Workspace 就能轻松共享工作区。由于用户体验是结构化的，因此它能捕捉到会话的整个活动日志，这也是了解实施方案为何如此的好方法。你可以查看计划，观看每一步的实施过程，然后通过点击用户界面中的计划步骤导航到相应的代码变更。这丰富了代码审查形式，在这种审查中，代码差异及其原因都一目了然。</p><p>GitHub 计划添加注释和多人编辑功能，Copilot Workspace 将能在一个工具中同时处理开发人员内循环和审查循环。</p><p>参考链接：</p><p>https://twitter.com/karpathy/status/1722359332116062491</p><p>https://githubnext.com/projects/copilot-workspace</p><p>https://twitter.com/LinusEkenstam/status/1722320525454676063</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650896587&amp;idx=4&amp;sn=23c4c85b675da49bf082bab9a3218bc6&amp;chksm=84e4bcb5b39335a3c12c1f873673ada21af715cd92494d3fe662ea496e41885301169628b3e2&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：机器之心，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510690855928069</id>
            <title>OpenAI上线新功能太强了，服务器瞬间被挤爆</title>
            <link>https://www.36kr.com/p/2510690855928069</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510690855928069</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:20:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 服务器中断, ChatGPT, 开发者日
<br>
<br>
总结: OpenAI在开发者日上发布了新功能，其中ChatGPT服务器由于用户访问过多而宕机，导致服务器中断。OpenAI正在调查宕机原因并进行修复和监控。CEO Sam Altman表示抱歉，并表示新功能的使用情况超出了预期。开发者日还发布了其他功能，但由于服务器宕机，没有得到太多关注。 </div>
                        <hr>
                    
                    <p>OpenAI 开发者日上新功能太火爆，服务器都挤爆了。</p><p>太平洋时间 11 月 8 日上午 6 点左右开始，ChatGPT 服务器宕机超过 90 分钟，用户访问会收到「ChatGPT 目前已满载（ChatGPT is at capacity right now）」的消息。</p><p>随后，OpenAI 接连发布两次「服务器中断」警告 —— 一次部分中断、一次全线中断，并称正在调查宕机原因，进行修复和监控。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_6d2c49a55a8b4fb8b4b067f16ff7a511@000000_oswg260361oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0ea32e2ae1ef4bdb8648700299b090d7@000000_oswg215677oswg1080oswg580_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最新状态显示：「ChatGPT 和 API 仍然会出现周期性中断。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b08e621853dc44f7b43d49c5d1d8961f@000000_oswg175112oswg1080oswg598_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>OpenAI 表示这是一次严重的服务器中断，也影响了该公司的 API 服务。</p><p>OpenAI CEO Sam Altman 对此次中断表示抱歉，并在推特上说道：「我们在开发者日发布的新功能的使用情况远远超出了预期。我们原计划周一为所有订阅者启用 GPT，但仍未能实现。我们希望尽快。由于负载的原因，短期内可能会出现服务器不稳定的情况。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0b51bc6108994784ab19fb7958b03603@000000_oswg210008oswg1080oswg335_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>看来，开发者日上新功能的火爆程度是 Sam Altman 也没想到的。</p><p>在开发者大会上，OpenAI 宣布推出 GPT-4 Turbo、GPTs，让用户无需代码，结合自己的指令、外部知识和能力就可以创建自定义版本的 ChatGPT。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_6ee2e65d0d34479d834f20bef453d2f3@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ChatGPT 发布近一年，其每周用户数量已经达到 1 亿，并有超过 200 万开发人员在 OpenAI 的 API 服务上进行开发，用户增长速度惊人。如今，功能大上新更是直接把服务器挤爆了。</p><p>网友反应也很快：「ChatGPT 宕机了，我的工作怎么办？」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b05c385632d2488c9f4ca0a5791372ac@000000_oswg168799oswg1080oswg345_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d80866f1c2a54efebba727115c153646@000000_oswg108220oswg1080oswg292_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有网友开玩笑称：「ChatGPT 崩溃了，Stack Overflow 开心了。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f5d27933b23c4e3683d9cd60e4fa8a24@000000_oswg516284oswg1080oswg788_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：https://twitter.com/2sush/status/1722457364283232760</p><p>既然服务器宕机了，我们再仔细看看 OpenAI 开发者日的内容吧，或许有两项发布，大家没有给予太多的关注。</p><h2>Whisper-V3、Consistency Decoder 的开源也很给力</h2><p>OpenAI 的首届开发者大会，实属把大家都震撼到了。在这过去短短的 48 小时的时间里，大家更多的把目光集中在了新模型 GPT-4 Turbo 的发布、GPTs 商店等内容上，现在愣是把服务器整崩了。</p><p>然而，在这场发布会之后，很多人都忽视了 2 个开源模型，如果你深入了解一下，它们和那些新产品一样令人兴奋，现在，这两个项目都在 GitHub 热榜上。</p><p>第一个是 Whisper-V3，被公认为目前最好的 OSS 语音识别模型，新版相比 Whisper-V2 有了重大改进。OpenAI 于 2022 年 12 月发布第一代 Whisper，支持语音识别、语音翻译等能力。短短不到一年的时间，现在已经进化到 Whisper-V3，值得一提的是，OpenAI 表示不久将推出 API。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_834e9c0b9f464641b4aa93d338cc2fde@000000_oswg95633oswg1080oswg386_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>项目地址：https://github.com/openai/whisper/</p><p>论文地址：https://arxiv.org/abs/2212.04356</p><p>&nbsp;Whisper-V3（也称为 Large-v3）使用了 Large-v2 （Whisper-V2）收集的长达 100 万小时的弱标记音频和 400 万小时的伪标记音频进行训练而成。此外，相比前几代模型，Whisper-V3 在多种语言上显示出了较高的性能改进，下图为 Whisper-V3 在 Common Voice 15 和 Fleurs 上的性能表现：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_8118935d00ef49e498cfa6d965b331a3@000000_oswg388863oswg1080oswg1532_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>被大家忽略的另一个重点是 OpenAI 开源了一个专门改进 AI 图像生成的研究 Consistency Decoder ，这项研究来自论文《 Consistency Models 》，作者阵容非常强大，有本科毕业于清华大学数理基础科学班、目前在 OpenAI 担任研究员的宋飏，还有 OpenAI 联合创始人、首席科学家 Ilya Sutskever 等都出现在论文作者列表里。</p><p>与热门的图像生成模型 Midjourney 、Stable Diffusion 等不同，OpenAI 认为扩散模型依赖于迭代生成过程，导致采样速度缓慢，进而限制了它们在实时应用中的潜力。因而他们创造性的提出了 Consistency Models，这是一类新的生成模型，无需对抗训练即可快速获得高质量样本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_1ad87d530ab841c694cf28db98232781@000000_oswg94519oswg1080oswg418_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>项目地址：https://github.com/openai/consistencydecoder</p><p>论文地址：https://arxiv.org/pdf/2303.01469.pdf</p><p>下图我们可以很直观的看到，Consistency Decoder 效果更好，能增加图像生成的稳定性和一致性，让生成的图像更加清晰和连贯，例如下图中人物眼部细节提升更加明显：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_039e3a06482e455b96abd706a7b5984e@000000_oswg1171966oswg1080oswg1105_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>网友猜测，Consistency Decoder 就是 DALL・E 3 用到的解码器，以后生成惨不忍睹的人脸情况可能就不会发生了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_656bdcfc201146e09a935e5e6b02a6da@000000_oswg99850oswg1080oswg339_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>宋飏也证明了网友的猜测，「非常高兴发布 DALL・E 3 的 consistency decoder，这是一种 consistency 模型，可以以惊人的速度将 VQGAN 潜在图像转换为质量更高的图像！」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_67eca06171504aac8dada89c2b6fc659@000000_oswg62316oswg1078oswg202_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在看来，OpenAI 的每一项发布都值得细细研究，这些技术都在各自的领域有着重要价值。</p><p>参考链接：</p><p>https://twitter.com/DrJimFan/status/1722281972641448426</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650896587&amp;idx=2&amp;sn=6a5fe4fc93f698bee3530a688df75d75&amp;chksm=84e4bcb5b39335a33841444314145c172b9edd4cf5722f1d17cce1aa1355a48d934c3a478cbe&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，编辑：陈萍、小舟，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510690620784900</id>
            <title>大模型走捷径「刷榜」？数据污染问题值得重视</title>
            <link>https://www.36kr.com/p/2510690620784900</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510690620784900</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:18:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 大模型, 刷榜, 技术报告
<br>
<br>
总结: 今年，大家都在努力开发和推出大模型，但同时也引发了关于刷榜的讨论。一份技术报告揭示了一些大模型使用领域内数据刷榜的现象，并验证了一些国产大模型存在投机取巧的嫌疑。这份报告希望让人们更理性地看待刷榜问题，认识到大模型与GPT-4之间的差距。 </div>
                        <hr>
                    
                    <p>生成式 AI 元年，大家的工作节奏快了一大截。</p><p>特别是，今年大家都在努力卷大模型：最近国内外科技巨头、创业公司都在轮番推出大模型，发布会一开，个个都是重大突破，每一家都是刷新了重要 Benchmark 榜单，要么排第一，要么第一梯队。</p><p>在兴奋于技术进展速度之快后，很多人发现似乎也有些不对味：为什么排行榜第一人人有份？这是个什么机制？</p><p>于是乎，「刷榜」这个问题也开始备受关注。</p><p>近日，我们关注到朋友圈和知乎社区对大模型「刷榜」这一问题的讨论越来越多。特别是，知乎一篇帖子：如何评价天工大模型技术报告中指出很多大模型用领域内数据刷榜的现象？引起了大家的讨论。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_55546478281b4dc7bea0953086b1a514@000000_oswg712883oswg1080oswg1041_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>链接：https://www.zhihu.com/question/628957425</p><h2>多家大模型刷榜机制曝光</h2><p>该研究来自昆仑万维的「天工」大模型研究团队，他们上个月底把一份技术报告发布在了预印版论文平台 arXiv 上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_3cdea759db944382917b8c8e58d007cd@000000_oswg224712oswg1080oswg268_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文链接：https://arxiv.org/abs/2310.19341</p><p>论文本身是在介绍 Skywork-13B，这是天工的一个大型语言模型（LLM）系列。作者引入了使用分段语料库的两阶段训练方法，分别针对通用训练和特定领域的增强训练。</p><p>和往常有关大模型的新研究一样，作者表示在流行的测试基准上，他们的模型不仅表现出色，而且在很多中文的分支任务上取得了 state-of-art 水平（就是业内最佳）。</p><p>重点是，该报告还验证了下很多大模型的真实效果，指出了一些其他一些国产大模型存在投机取巧的嫌疑。说的就是这个表格 8：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_231664bed9024356880dbe0b0a604ccf@000000_oswg732134oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在这里，作者为了验证目前业内几个常见大模型在数学应用问题基准 GSM8K 上的过拟合程度，使用 GPT-4 生成了一些与 GSM8K 形式上相同的样本，人工核对了正确性，并让这些模型在生成的数据集，和 GSM8K 原本的训练集、测试集上比了比，计算了损失。然后还有两个指标：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_608aab41fc424e989364f664e08dc12d@000000_oswg15968oswg327oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Δ1 作为模型训练期间潜在测试数据泄漏的指标，较低的值表明可能存在泄漏。没有用测试集训练，那数值应该为零。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2277f7cff967482db22a9c8e34964fff@000000_oswg18080oswg345oswg49_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Δ2 衡量数据集训练分割的过度拟合程度。较高的 Δ2 值意味着过拟合。如果没有用训练集训练过，那数值应该为零。</p><p>用简单的话来解释就是：如果有模型在训练的时候，直接拿基准测试里面的「真题」和「答案」来当学习资料，想以此来刷分，那么此处就会有异常。</p><p>好的，Δ1 和 Δ2 有问题的地方，上面都贴心地以灰色突出显示了。</p><p>网友对此评论道，终于有人把「数据集污染」这个公开的秘密说出来了。</p><p>也有网友表示，大模型的智力水平，还是要看 zero-shot 能力，现有的测试基准都做不到。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_6b7cb00f917449d196d0024dae386730@000000_oswg80918oswg1016oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：截图自知乎网友评论</p><p>在作者与读者中互动中，作者也表示，希望「让大家更理性看待刷榜这个事情，很多模型和 GPT4 的差距还很大」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4c6bd4d5265143c68d8803f387df08f8@000000_oswg96743oswg1080oswg454_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：截图自知乎文章 https://zhuanlan.zhihu.com/p/664985891</p><h2>数据污染问题值得重视</h2><p>其实，这并不是一时的现象。自从有了 Benchmark，此类问题时常会有发生，就像今年 9 月份 arXiv 上一篇极具嘲讽意味的文章标题指出的一样 Pretraining on the Test Set Is All You Need。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b99acb3d3ec445b88e02c60f0d2af844@000000_oswg29256oswg864oswg434_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，最近人民大学、伊利诺伊大学香槟分校一个正式研究同样指出了大模型评估中存在的问题。标题很扎眼《Don't Make Your LLM an Evaluation Benchmark Cheater》：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2cbf24a453624fa68b90bafa8737b037@000000_oswg357583oswg1000oswg309_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文链接：https://arxiv.org/abs/2311.01964</p><p>论文指出，当前火热的大模型领域让人们关心基准测试的排名，但其公平性和可靠性正在受到质疑。其中主要的问题就是数据污染和泄露，这样的问题可能会被无意识地触发，因为我们在准备预训练语料库时可能不知道未来的评估数据集。例如，GPT-3 发现预训练语料库中包含了 Children's Book Test 数据集，LLaMA-2 的论文曾提到提取了 BoolQ 数据集中的上下文网页内容。</p><p>数据集是需要很多人花费大量精力收集、整理和标注的，优质的数据集如果优秀到能被用于评测，那自然也有可能会被另一些人用于训练大模型。</p><p>另一方面，在使用现有基准进行评估时，我们评测的大模型的结果大多是通过在本地服务器上运行或通过 API 调用来获得的。在此过程中，没有严格检查任何可能导致评估绩效异常提高的不当方式（例如数据污染）。</p><p>更糟糕的是，训练语料库的详细组成（例如数据源）通常被视为现有大模型的核心「秘密」。这就更难去探究数据污染的问题了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_68b82ab053e64af9bb3676d9d020a31e@000000_oswg771335oswg1080oswg1067_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也就是说，优秀数据的数量是有限的，在很多测试集上，GPT-4 和 Llama-2 也不一定就没问题。比如在第一篇论文中提到的 GSM8K，GPT-4 在官方 technical report 里提到过使用了它的训练集。</p><p>你不是说数据很重要吗，那么用「真题」刷分的大模型，性能会不会因为训练数据更优秀而变得更好呢？答案是否定的。</p><p>研究人员实验发现，基准泄漏会导致大模型跑出夸张的成绩：例如 1.3B 的模型可以在某些任务上超越 10 倍体量的模型。但副作用是，如果我们仅使用这些泄露的数据来微调或训练模型，这些专门应试的大模型在其他正常测试任务上的表现可能会受到不利影响。</p><p>因此作者建议，以后研究人员在评测大模型，或是研究新技术时应该：</p><p>使用更多来自不同来源的基准，涵盖基本能力（例如文本生成）和高级能力（例如复杂推理），以全面评估 LLM 的能力。</p><p>在使用评估基准时，在预训练数据和任何相关数据（例如训练和测试集）之间执行数据净化检查非常重要。此外，还需要报告评估基准的污染分析结果作为参考。如有可能，建议公开预训练数据的详细组成。</p><p>建议应采用多样化的测试提示来减少提示敏感性的影响。在基准数据和现有预训练语料库之间进行污染分析，提醒任何潜在的污染风险也很有意义。为了进行评估，建议每次提交都附有一份特殊的污染分析报告。</p><p>最后想说，好在这个问题开始逐渐引起大家的关注，无论是技术报告、论文研究还是社区讨论，都开始重视大模型「刷榜」的问题了。</p><p>对此，你有什么看法与有效建议呢？</p><p>参考内容：</p><p>https://www.zhihu.com/question/628957425</p><p>https://zhuanlan.zhihu.com/p/664985891</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650896587&amp;idx=1&amp;sn=a83a70d472084d2fb07d51047a7e4be6&amp;chksm=84e4bcb5b39335a3dbb8211ae59e1fc8a5b4423b2570c2c5e22ea96f7108eb7df5a84968fe0c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：机器之心，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2509501960880389</id>
            <title>中国已成世界最大船东国，但仍存在航运清洁燃料不明确等挑战｜最前线</title>
            <link>https://www.36kr.com/p/2509501960880389</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2509501960880389</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 06:01:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 港口货物吞吐量, 港口航运业, 温室气体排放量, 航运业减碳
<br>
<br>
总结: 中国港口货物吞吐量和集装箱吞吐量在全球排名前十，但同时也带来了大量的污染和排放。航运业占据世界贸易量的80%以上，占全球温室气体排放量的近3%，成为世界第六大温室气体排放国。中国港口和航运业在减污降碳方面取得了一定成效，但在国际海事组织的减排目标下仍面临巨大挑战。航运业加速应用零排放、近零排放技术的紧迫性不断上升。 </div>
                        <hr>
                    
                    <p>文 | 吕雅宁&nbsp;</p><p>编辑 | 苏建勋</p><p>“在全球港口货物吞吐量和集装箱吞吐量前十的港口中，中国分别占据八席和七席。中国已成世界最大船东国，在迎来发展机遇的同时，港口航运业的运输活动也带来大量污染和排放。”亚洲清洁空气中心相关负责人表示。</p><p>11月7日，亚洲清洁空气中心发布两份报告，分别是《蓝港先锋2023：中国主要港口空气与气候协同力评价》（以下简称《蓝港先锋2023》）、《航运先锋2023：国际航行船舶减污降碳先行者（中国）》（以下简称《航运先锋2023》）。</p><p>联合国贸发会的《2023年海运述评》显示，<strong>航运业占世界贸易量的80%以上，占全球温室气体排放量的近3%</strong>，并且排放量在10年内增加了20%。</p><p><strong>如果“航运”是一个国家，它将成为世界第六大温室气体排放国。</strong></p><p>亚洲清洁空气中心此次发布的报告聚焦港口和航运减污降碳的实践经验，指出我国目前港口、航运业的能源转型与污染防治工作成效明显，但在“双碳”目标和国际海事组织趋严的船舶温室气体减排战略背景下，仍面临巨大挑战。</p><p>根据国际海事组织（IMO）制定的脱碳目标，航运业需要在2030年前实现减碳至少20%，并在2050年左右实现净零排放。</p><p>另外，<strong>从2024年1月起，航运将被纳入欧盟碳排放交易体系</strong>，所有进入欧盟港口的5000总吨及以上的客运和货运船舶需监测和汇报排放量，并为其排放的每吨二氧化碳当量缴纳一定的碳配额。</p><p>因此，航运业加速应用零排放、近零排放技术的紧迫性不断上升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231108/v2_b2d0707e4ec44355808a404e15d9f039@5802120_oswg291748oswg1868oswg1202_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">国际海事组织（IMO）于2023年公布的修订战略相比2018年更加严格。资料来源：《航运先锋2023》</p><p>在成效方面，《蓝港先锋2023》举例指出，中国在港口岸电供应方面的表现领先全球。21个沿海港口专业化泊位岸电覆盖率平均达到84%，其中有7个港口高达100%；内河港口21个港口，基本实现岸电全覆盖。</p><p>同期发布的《航运先锋2023》分析了参与中国国际海运运力前20位的航运公司，识别出马士基、韩新海运等11家集装箱航运公司、淡水河谷、弗雷德里克森集团等9家散货航运公司、Angelicoussis集团、Alpha Tankers等12家油轮航运公司，在投入中国国际海运的船队中已有较高比例的船舶配备低碳环保技术，并率先推进替代燃料等船舶的订造，表现优于行业平均水平。</p><p><strong>但报告同时指出，在港口、航运业减排方面，目前替代燃料路径尚存不确定性，部分领域亟待加速；柴油机大气污染物减排力度不足，温室气体排放管控缺少协同；沿海港口岸电使用率低，减排潜力未充分发挥。</strong></p><p>以替代燃料的选择和应用为例，全球甲醇行业协会中国区首席代表赵凯谈到：“绿色甲醇可能是近期唯一有规模的选项，以及长期确定性最高和最安全可靠的选项。目前全球甲醇燃料订单超过220条，后续还有一些新订单将要宣布。然而，绿色甲醇的供应确实是一个瓶颈，化工项目需要时间来筹备。”</p><p>赵凯表示，<strong>目前甲醇船舶相比比常规船舶的造价高出10%</strong>，但在全球能源转型趋势下，今年很多船东都订购了甲醇船，增长非常迅速，未来可以通过技术进步和规模化应用来降低可再生甲醇燃料的成本。</p><p>亚洲清洁空气中心交通项目主任成慧慧表示，除了推进替代燃料，传统柴油机在一定时期内仍将是港口运营活动和航运的主要能源动力，存量替代还要一段时间。传统柴油机大气污染物和温室气体的协同管控不可忽视，但目前这仍是薄弱一环。无论是针对国内还是国际航行的船舶，现行标准仍有较大提升空间，管控要求也有待进一步加严。</p><p>报告还显示，越来越多港口虽已具备较为完备的岸电供应设施，但实际应用不尽如人意，进而制约岸电发挥减排潜力。</p><p>例如在沿海港口，船舶靠港使用岸电不具有价格优势，不同国家地区港口侧的岸电供应能力差异较大，<strong>岸电泊位不充足、岸电接口不统一、部分岸电位置不合理</strong>等问题，导致国际航行船舶岸电受电设施配备率整体偏低，成为阻碍岸电使用率提升的最直接因素。</p><p>对于未来应对措施，参会各方都提及了跨行业、跨价值链多方协作的重要性。例如，推动甲醇、氨、氢等燃料加注设施以及充换电站等低碳能源供应设施建设，并利用技术与资源的跨界整合保证原料稳定和价格可控；鼓励航运企业、货主企业、道路运输企业等合作建立“绿色航运走廊”及“绿色货运廊道”等。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2509664068501506</id>
            <title>AI来袭，但“SaaS扛把子”神策数据说：要先做更落地的事 | 36氪专访</title>
            <link>https://www.36kr.com/p/2509664068501506</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2509664068501506</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 05:47:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 邓咏仪, AI浪潮, 神策数据, 客户营销
<br>
<br>
总结: 作者邓咏仪在文章中讨论了AI浪潮对于SaaS行业的影响，以及神策数据作为一家代表性公司如何应对这一变化。神策数据将AI嵌入数据分析和用户运营等场景，并推出了“神策小数点”产品。AI的出现让神策数据重新聚焦战略，并强调开放生态闭环和与生态伙伴、客户的合作。神策数据还推出了“客户旅程编排”概念，通过MTAOO方法论实现个性化、全渠道一致的客户体验。 </div>
                        <hr>
                    
                    <p>作者 | 邓咏仪&nbsp;</p><p>编辑 | 苏建勋</p><p>如果说前几年移动互联网带来的“流量红利”，让客户营销进入数字化时代——以“流量漏斗”“增长黑客”为主的增长理论，曾经主导营销圈相当长时间。</p><p>那么，当以大模型为代表的新一波AI浪潮出现，这几乎让所有和数据相关的行业都经历一次洗礼和革新。“AI是否会颠覆SaaS行业”，则成为这半年里圈中讨论的重要问题。</p><p>面对AI来袭，神策数据创始人桑文锋更愿意用理性的态度来面对。“ChatGPT极大刷新了我的认知，以前我确实觉得有许多事AI搞不了，但现在我坚定了信念，在未来，AI可以让客户经营实现‘全自动驾驶’。但目前，自动驾驶还是很难做到。比起概念，我们其实要先做可落地的方向。”</p><p>于是，在今年，神策数据也马不停蹄地将AI嵌入数据分析、用户运营、策略编排等场景，并且基于大模型推出了”神策小数点“产品。</p><p>在神策小数点上，客户只需要直接问业务指标的具体情况，大模型就能调用神策平台的底层数据进行回答——神策更愿意先从这样的小功能点出发，做好查询等实用场景。</p><p>事实上对神策而言，AI带来的更重要影响，是让其战略得到再一次聚焦。</p><p>成立于2015年的神策数据，经历过国内大数据行业从无到有的过程，也是SaaS浪潮中的代表性公司。其发展路径，也与SaaS行业的变化同频共振。</p><p>在2015年成立之后，神策在相当长时间里都是以“极致单品”策略取胜，其大数据分析产品在互联网中小客户中颇有口碑，并坚持采用订阅制形式，将产品标准化程度做到最高。</p><p>而从2017年开始，神策开始延伸至中大企业客户群体，以高价值、复杂客户需求为灯塔。如今，神策的客户群体覆盖银行、证券、保险、品牌零售、汽车等行业的超过2000家客户，神策也借此打磨出了一套面向中大型客户的工作流程和工作方法，建立起交付和客户成功团队。</p><p>神策的产品矩阵在这一时期也经历了扩张，从大数据分析“往前走”，走到更贴近客户的营销场景，推出了包括用户画像、智能运营、智能推荐、客户全景等产品。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_491223675a09462b8a5510648e930a14@2057308263_oswg966140oswg1268oswg708_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：神策数据</p><p>但疫情成为又一个发展节点。</p><p>“经过过去的三年，我们也发现要实现完整的业务闭环，单靠我们自己做太难了，这是我们认知上一个非常大的变化。”桑文锋对36氪表示。</p><p>如今，神策依旧强调开放生态闭环，但这需要和生态伙伴、客户一起实现。在2023年神策数据驱动大会上，神策也对外介绍了其Open API战略。</p><p>“去年我们有一个反思就是，神策一定要聚焦。”桑文锋表示。神策开放了自家产品的不少API接口，在服务客户的过程中，让合作伙伴来集成或者接入，共同形成数据栈。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0199903bcf5b43198f5d0d473dbd9441@2057308263_oswg892401oswg1268oswg846_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">神策创始人桑文锋&nbsp;</p><p><strong>划清各自的业务界面，是重要的一步。</strong>比如，神策如今定位自己是企业的CDP（客户数据平台），那么更底层的数仓等组件，神策原来会为客户提供，但如今更愿意让合作伙伴来提供。</p><p>能够达到的效果是，合作伙伴能够开放地去读取神策平台里的数据，同样地，神策平台也能够开放地读取数仓中的数据。对客户而言，只要存一份数据即可。“省得这个企业的IT架构里有多份数据，数据之间又要校验、对齐，复杂度就变高了。”桑文锋解释道。</p><p>而当技术发展日新月异，与数据密切相关的行业该如何应对？在2023年数据驱动大会中，神策数据带来的最新答案是：回归和聚焦。</p><p>神策认为，从互联网时代到数字化时代，从流量红利到触点红利，企业的经营需求也从深度的“用户行为分析”转变到“个性化、全渠道一致的客户体验”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_576b5aaa40fb44fba0e43529a14e91c8@2057308263_oswg891983oswg1270oswg711_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：神策数据</p><p>正因如此，神策推出了最新的“客户旅程编排”概念。神策将客户编排分为五大阶段，包括绘制（Map）、埋点（Track）、分析（Analyze）、编排（Orchestrate）、优化（Optimize）——简称MTAOO方法论。</p><p>神策联合创始人兼CTO曹犟解释，MTAOO 方法论中，绘制（Map）是一个业务动作，后面的埋点、分析、编排、优化是数字化客户经营真正落地的核心环节，需要强大的数字化引擎做支撑。</p><p>比如，在埋点环节，企业可以通过客户数据引擎（CDP）构建数据底座；分析环节，则应用客户旅程分析引擎（CJA），从用户行为到经营分析洞察数据都清晰可见；到了编排和优化环节，通过客户旅程优化引擎（JOE）让不同客户能享受到千人千面的营销互动，并实时反馈结果，不断优化客户体验。</p><p>比起以前单纯的获取数据然后进行分析，如今的旅程编排更强调与用户的实时互动、反馈和快速迭代。而在Open API战略的支持下，客户旅程分析引擎能够提供更多维度的功能接口，让用户享受更个性化的支持和服务。</p><p>如今整个To B行业都从激进走到理性发展时期，To B公司在逐步调整自身预期。桑文锋再次强调，神策会继续沿着聚焦的产品策略，更注重为客户带来更高的效率价值，而不是盲目承诺效果。</p><p>“现在，我越来越接纳神策对许多客户来说确实是一个效率工具，是客户经营环节中的一个环节，”桑文锋表示，“那我们就需要向客户证明，在经营效率提升上能发挥最大价值。”</p><h3>相关阅读</h3><p><a href="https://36kr.com/p/1736778180197640" rel="noopener noreferrer" target="_blank">最前线 | 完成2亿美金D轮融资，「神策数据」从大数据延伸到营销科技领域</a></p><p><a href="https://36kr.com/p/702144552254340" rel="noopener noreferrer" target="_blank">36氪首发 | 「神策数据」获 3000 万美元 C+ 轮融资，“数据便利店”战略落地半年，成果如何？</a></p><p><a href="https://36kr.com/p/1724333539329" rel="noopener noreferrer" target="_blank">神策数据CEO桑文锋：从单品到矩阵，神策的“数据便利店”开张了</a></p><p><a href="https://36kr.com/p/1722425802753" rel="noopener noreferrer" target="_blank">2018年，完成4400万美元C轮融资，华平资本领投，老股东跟投。</a></p><p><a href="https://36kr.com/p/1721441648641" rel="noopener noreferrer" target="_blank">2017年，完成1100万美元B轮融资，DCM领投，红杉中国跟投；</a></p><p><a href="https://36kr.com/p/1721075056641" rel="noopener noreferrer" target="_blank">2016年，完成400万美元A轮融资，红杉中国领投，线性资本、明势资本等天使股东跟投；</a></p><p><a href="https://36kr.com/p/1720938708993" rel="noopener noreferrer" target="_blank">2015年，神策数据发布用户行为数据分析产品Sensors Analytics；</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510514611060993</id>
            <title>一文读懂SpaceX星舰二次试射：只要完成前三分钟飞行就算成功</title>
            <link>https://www.36kr.com/p/2510514611060993</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510514611060993</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:51:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: SpaceX, 星舰, 试飞, 升级措施
<br>
<br>
总结: SpaceX即将进行星舰的第二次试飞，通过此次试飞验证了上千项调整、改进以及升级措施。试飞成功将帮助开启星舰项目的下一段旅程，包括测试轨道加油技术、发射星链卫星等。 </div>
                        <hr>
                    
                    <blockquote><ol><li>SpaceX最早可能于下周对星舰进行第二次试飞，将对上千项调整、改进以及升级措施进行验证。</li><li>马斯克表示，只要完成前三分钟飞行，这次试飞就算取得了成功。</li><li>如果试飞成功，星舰将能够进入太空，全程飞行90分钟，绕地球一圈，最后溅落在夏威夷西北的太平洋中。</li><li>试飞成功可能帮助开启星舰项目的下一段旅程，包括测试轨道加油技术、发射星链卫星等。</li></ol></blockquote><p>埃隆·马斯克（Elon Musk）旗下火箭公司SpaceX即将对其星舰系统进行第二次试飞，但在此之前他们需要找到多个紧迫问题的答案，比如得克萨斯州升级后的发射台能否承受住火箭发射的强大推力？火箭上的猛禽发动机是否比4月份星舰首次试飞时更可靠？超重型助推器是否能与上级星舰安全分离？</p><p>这些问题的答案将表明，SpaceX在星舰升级过程中的进展有多快。星舰主要由两部分构成，分别是同名飞船以及超重型运载火箭。如果二次试射成功，星舰接下来的任务包括发射星链互联网卫星，这将加快网络与消费者手机直接连接的能力。SpaceX还需要为美国宇航局（NASA）测试星舰飞往月球的在轨加油能力。工程师们希望回收星舰系统的巨大助推器和飞船，这是使星舰完全可重复使用的必要步骤。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_50ac5b0ef33b4f88b0ea150786c549cb@1743780481_oswg62299oswg800oswg451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图1：SpaceX第二艘星舰比第一代更高</p><p>但首先，星舰需要能够进入太空。在4月20日星舰的首次试飞中，这种情况并没有发生，但SpaceX从那次任务中学到了很多东西。工程师们了解到，他们需要加强发射底座，因为超重型助推器猛禽发动机产生的1500万磅推力让其受到重创。这是SpaceX这次想要避免的事情。</p><p>另外，在4月份的试飞中，超重型助推器上33个猛禽发动机中有6个在升空前或飞行中发生故障。助推器发动机舱的推进剂泄漏和起火最终迫使SpaceX切断了与火箭主要飞行计算机的连接，火箭在飞行两分钟多后失去了控制。在二次试飞中，SpaceX也针对这些问题进行了改进。</p><h2><strong>SpaceX需要证明什么？</strong></h2><p>星舰的二次试飞最早可能在下周进行，地点是得克萨斯州布朗斯维尔附近的SpaceX发射基地。阻碍发射的最后一件事是联邦航空管理局（FAA）和美国鱼类和野生动物管理局（USFWS）的环境审查。</p><p>一旦审查完成（可能在本周进行），SpaceX将获得FAA的发射许可证。技术人员将在星舰上安装飞行终止系统，这是在星舰偏离轨道时的自毁机制。</p><p>然后，SpaceX将把星舰的飞船部分堆叠在超重型助推器的顶部，以组装高度超过120米的完整星舰，这是迄今为止人类建造的最大火箭系统。在发射当天早上，SpaceX团队将向这枚两级火箭罐装超过1000万磅的甲烷和液氧。</p><p>然后是发射时间。如果一切正常，计算机将发出命令，点燃聚集在助推器底部的33台猛禽发动机。在最后一次检查后，自动倒计时程序将发出允许发射的绿灯。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_e4059c94024d4784a4c20a4fc80881b4@1743780481_oswg37165oswg757oswg508_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：在4月20日的星舰首次试飞中，超重型助推器猛禽发动机下方可以看到变色的尾气羽流，这可能是发动机舱内推进剂泄漏或起火的迹象</p><p>SpaceX创始人兼首席执行官埃隆·马斯克（Elon Musk）在4月20日发射前表示，成功试飞意味着火箭不会在发射台爆炸。这次，SpaceX希望能走得更远一点。理想情况下，这次星舰将进入太空，全程飞行90分钟，绕地球一圈，最后溅落在夏威夷西北的太平洋中。</p><h2><strong>前三分钟飞行最关键</strong></h2><p>若试飞成功，SpaceX可能着手实现马斯克预设的目标，即在明年年底前用星舰发射星链卫星。SpaceX也可能开始展示在轨道上为星舰加油，这是NASA阿尔忒弥斯重返月球计划的一个重要里程碑，该计划将依靠星舰将宇航员送上月球表面。</p><p>今年6月，马斯克预测，星舰在第二次试飞中达到接近轨道速度的可能性约为60%。星舰的速度无法达到稳定绕地轨道飞行所需的速度，所以如果它真能飞那么远，将在发射后90分钟左右重新进入大气层。</p><p>但是，如果星舰在离开发射台之前发生爆炸，这可能会使SpaceX的火箭计划推迟至少6个月。在4月20日试飞之后，SpaceX花了差不多半年时间才修复了发射台的大面积损坏。这甚至可能引发监管机构的更多审查，给SpaceX的计划带来更多障碍。</p><p>有鉴于此，完成前三分钟的飞行就足以证明星舰走上了正确的道路。如果试飞成功，将意味着SpaceX解决了4月份试飞中导致发动机舱燃油泄漏和起火的问题。这可能还意味着，SpaceX已经提高了猛禽发动机的可靠性，而且该火箭的新型电动推力矢量控制装置工作得非常出色，该装置可用于让猛禽发动机保持平衡或旋转，以便在飞行中转向。</p><h2><strong>热分离技术</strong></h2><p>从得克萨斯州墨西哥湾海岸向东飞行，超重型助推器将把星舰加速到几倍音速的高速。发射后约2分39秒，助推器将开始准备与星舰上级分离。在这次试射中，SpaceX将测试所谓的“热分离”技术。</p><p>SpaceX公布的时间表显示，在即将到来的试飞中，超重型助推器的33个发动机中，大多数将在发射后2分39秒关闭。两秒钟后，随着星舰上级发动机点火和超重型助推器同时被抛离，热分离开始。</p><p>热分离技术存在风险，但SpaceX的工程师认为他们已经减少了风险。马斯克说：“显然，这会导致助推器爆炸，所以你必须保护助推器的顶部不被上级发动机烧毁。设计上的改变将使星舰火箭的有效载荷能力提高大约10%，目前在近地轨道上的有效载荷已经超过100吨。”</p><p>工程师们在不锈钢助推器的顶部增加了防护罩，使其免受发动机爆炸的影响。一旦星舰完全投入使用，SpaceX希望多次回收和重复使用助推器，因此减少级间分离造成的损害非常重要。SpaceX在超重型助推器和星舰飞船的上层之间增加了金属排气环，这是新的元件，可以让上层发动机的过热废气从两级之间的封闭空间中逸出。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_908d6f7cf8ff47dcbfe5eac6e0718019@1743780481_oswg178302oswg640oswg1101_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图3：安装在超重型助推器顶部的“热分离环”</p><p>马斯克说，热分离是自4月试飞以来对其星舰系统进行的1000多次调整、升级和改进之一。星舰二次试飞将使用猛禽2发动机，它们类似于4月份飞行的发动机。SpaceX正致力于升级猛禽3发动机的设计，以解决可靠性问题。</p><p>SpaceX加强了助推器上33个猛禽发动机周围的防护，以保护它们免受附近发动机爆炸的影响。此举旨在减少风险，以免在进入太空的过程中一个引擎故障导致其他引擎失灵。未来的猛禽发动机将采用改进的燃料歧管设计，减少泄漏路径，但在星舰二次飞行中，技术人员试图通过拧紧歧管上的螺栓来解决这个问题。</p><p>执行星舰二次试飞任务的超重型助推器被称为Booster 9，它拥有扩展的灭火系统，可以减少发动机舱着火的风险。</p><p>马斯克称热分离是星舰第二次发射中最危险的部分。上个月，他在国际宇航大会上说：“如果发动机点火，飞船在分离阶段不会自爆，那么我认为我们就有相当大的机会进入轨道。”</p><h2><strong>开启下一段旅程</strong></h2><p>星舰上级部署有六个猛禽发动机，其中三个具有更大的喷嘴，用于在太空真空中点火，另外三个标准的猛禽发动机适合在大气层中飞行。SpaceX此前从未在太空中启动过猛禽发动机，因此高管们迫切希望看到星舰上级的表现。如果一切顺利，星舰将在飞越墨西哥湾、驶向佛罗里达海峡的过程中点燃其上级发动机，持续近6分钟。</p><p>与此同时，超重型助推器将尝试在得克萨斯州海岸附近的海洋中进行受控软溅落，以验证SpaceX在未来星舰飞行中将助推器降落在发射台上的技术。</p><p>与4月份相比，人们对星舰二次试飞的期望更高。NASA拥有超过40亿美元的星舰登月合同，该机构将密切关注星舰的测试。负责阿尔忒弥斯登月计划的NASA官员吉姆·弗里（Jim Free）称：“我希望每个人都在为星舰试飞欢呼，因为我们需要它成功，才能让我们在这条路上走得更远！”</p><p>对于NASA来说，星舰试飞成功可能意味着，SpaceX将在未来一两年的某个时候进入星舰测试的下个阶段，即轨道加油。这将使星舰在2030年之前载着宇航员登陆月球表面成为可能。</p><p>SpaceX拥有大量硬件，而且该公司的员工行动迅速。在南得克萨斯州有许多火箭处于不同的制造阶段。因此，即使第二艘星舰不能进入轨道，还有更多的飞船在等待飞行。</p><p>但在星舰开始部署星链卫星或为NASA执行飞往月球任务之前，还有许多障碍要跨越，这是该火箭最重要的两个近期目标。本月晚些时候，只要扫清其中的几个障碍，SpaceX就有理由大肆庆祝。</p><p>本文来自“<a href="https://new.qq.com/rain/a/20231109A01KMN00" rel="noopener noreferrer nofollow" target="_blank">腾讯科技</a>”，作者：金鹿，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510516942602249</id>
            <title>OpenAI工程师平均薪酬92.5万美元，超高薪让科技巨头望尘莫及</title>
            <link>https://www.36kr.com/p/2510516942602249</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510516942602249</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:51:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 人工智能工程师, 年薪, 语言模型
<br>
<br>
总结: OpenAI作为当前人工智能领域热度最高的公司之一，向人工智能工程师支付的年薪高达92.5万美元，其中包括底薪和股票薪酬。OpenAI去年推出的语言模型ChatGPT在短短两个月内吸引了1亿用户，成为有史以来增长最快的消费者互联网应用程序之一。OpenAI的估值也飙升至800亿至900亿美元，使得其工程师的实际股票薪酬可能远高于统计数据。这一趋势也带动了人工智能领域的平均薪酬上涨。 </div>
                        <hr>
                    
                    <p>随着各行各业的公司纷纷在各自业务中部署人工智能，人工智能的炒作达到了前所未有的高度。作为当前人工智能领域热度最高的公司，OpenAI在人才争夺战中付出了让科技巨头们望尘莫及的薪酬。</p><p>美国科技公司数据收集网站Levels.fyi最近发布的报告显示，OpenAI向人工智能工程师支付的年平均薪酬达到了惊人的92.5万美元。举例来说，目前在OpenAI任职的5级软件工程师底薪为30万美元，另外还可以获得62.5万美元的股票薪酬。5级软件工程师通常拥有约10年的行业从业经验。</p><p>此外，OpenAI薪酬最低的工程师底薪为21万美元，拥有约2至4年的行业从业经验。这个底薪并不包括每年可以获得的股票薪酬。OpenAI的一些高级软件工程师年薪最高达到140万美元。</p><p>OpenAI去年年底推出大型语言模型ChatGPT，在去年范围掀起了人工智能热潮。ChatGPT被广泛认为是有史以来增长最快的消费者互联网应用程序，在短短两个月内估计每月用户数量达到1亿人。例如，Facebook在2004年推出后，用了大约四年半的时间达到1亿用户；Twitter用了五年多；Instagram用了两年多一点。</p><p>今年年初，OpenAI以270亿美元至290亿美元的估值募集到113亿美元资金。上月有消息称，OpenAI正洽谈以860亿美元的估值出售现有员工股份。早在今年二季度，该公司就曾出售过一波员工股份给风险投资机构，当时媒体报道称该公司账面价值约为300亿美元。如今第二波要约收购将至，其估值已上涨至800亿至900亿美元之间，是此前的3倍。鉴于该公司估值飙升，其工程师获得的实际股票薪酬可能会远远高于Levels.fyi的统计数据。</p><p>估值的飙升，让OpenAI能够向员工支付让苹果、谷歌母公司Alphabet、甚至是微软等科技巨头们望尘莫及的薪酬。微软之前对OpenAI投入30亿美元，在今年年初又宣布对这家人工智能公司追加100亿美元投资。受与OpenAI深度合作的推动，微软股价在周二创出历史新高，市值达到2.68万亿美元。不过Levels.fyi的统计数据显示，微软2022年向员工支付的平均年薪在7.7万美元至31万美元之间，远远逊色于OpenAI，而且在今年裁员了约5%。</p><p>对人工智能人才前所未有的需求拉动了该领域的平均薪酬。据报道，如今没有任何经验的工程师可能得到每年高达33.5万美元的工程实习机会。</p><p>本文来自“<a href="https://new.qq.com/rain/a/20231108A03T9S00" rel="noopener noreferrer nofollow" target="_blank">腾讯科技</a>”，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510467695067142</id>
            <title>2023年了，还推氢能汽车？</title>
            <link>https://www.36kr.com/p/2510467695067142</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510467695067142</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:47:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 六年进博会, 新能源汽车, 氢能源技术, 丰田, 现代
<br>
<br>
总结: 第六届中国国际进口博览会在上海举行，展示了新能源汽车和氢能源技术的发展。丰田和现代作为氢能源的拥趸，展示了他们的氢燃料电池汽车和相关技术。尽管氢能汽车在商业化和普及方面面临一些挑战，但商用车和特种车辆的氢能产业化更容易实现。 </div>
                        <hr>
                    
                    <p>六年进博会，焕然新气象。11月5日，已然第六届的中国国际进口博览会，在上海正式举行。</p><p>连续六年举行的进博会，就如同一个开放的窗口，既让世界看到中国，也让中国看到世界。作为进博会7个独立展区之一的汽车展区，同样如此。</p><p>毫无疑问，新能源汽车的潮流大势已经势不可挡，中国汽车市场也俨然成为全球数一数二的新能源汽车汇集地。</p><p>当智能化、电动化等概念愈加深入人心，当混动、纯电、增程车型层出不穷，一个全新的汽车时代，即将到来。而进博会的助推，将会为这一新时代的到来，提供充足动力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ad2f8dfaf9fe4afbb7fc5d547e9ba59c@1743780481_oswg563121oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>尽管本次进博会并非严格意义上的车展，却总能看到不少车展的影子。奔驰大房车、“凶猛”福特、被拆解的特斯拉、Q萌XEV……就车型产品而言，进博会上可真的是五花八门、多姿多彩。</p><p>然而进博会现场除了常规的燃油车型、混动车型、电车之外，值得关注的一点还有，丰田和现代两家国际大车企，依旧在不遗余力地安利自家的氢能源技术，以及氢能汽车。</p><p>环保低碳，人人有责。大家其实都知道氢能汽车更环保、更符合未来，但在实际生活中，氢能汽车的使用成本和便捷性都受到了极大限制，以至于到现在，氢能汽车的普及程度仅局限在某些特定区域。</p><p>相对于其它新能源汽车，氢能汽车属实有些“冷门”，甚至令人看不到什么广阔的商业化前景。但既然如此，为什么丰田和现代，依旧要坚持推动氢能汽车发展呢？</p><h2><strong>01 头铁，还得是丰田、现代</strong></h2><p>所谓氢能汽车，可以简单地分为两种，氢内燃机汽车（HICEV）和氢燃料汽车（FCEV）。其中，氢内燃机汽车是以特定内燃机，通过燃烧氢气产生动力，以实现汽车驱动。而氢燃料电池汽车，则是通过氢燃料电池，反应产生电力之后，再以电力推动汽车驱动。</p><p>据了解，目前已经实现商业化的丰田Mirai、现代NEXO、本田Clarity等车型，均为氢燃料汽车。就此，也不难认定，乘用车“氢能化”，走氢燃料电池的路子，更容易走，也更具备参考价值。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_749d8082735a404f9e05c2c31e9a3da3@1743780481_oswg181774oswg640oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从始至终，现代汽车和丰田汽车都是氢能源的忠实拥趸，尤其是在本次进博会上，双方更是将自家的氢能技术、相关车型，全都摆放在了显眼位置。</p><p>现代汽车展台上，全球销量最高的氢燃料电池车NEXO、N品牌首款Rolling Lab氢混合动力车型N Vision 74概念车、氢燃料电池卡车盛图，以及氢燃料电池中巴北极星等，都做出了亮相。</p><p>然而不容忽略的还有，现代汽车的HTWO品牌，才是其氢能战略的核心。</p><p>2020年，现代汽车正式发布其氢燃料电池系统专属品牌——HTWO。在HTWO品牌的推动下，现代汽车进一步将氢燃料电池技术，从汽车领域，拓展到船舶、轨道车辆、发电设施及AAM等多个应用领域。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_dd835442214049f8b897aba799529e60@1743780481_oswg717070oswg1080oswg643_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与现代汽车相对应的，本次进博会的丰田展台上，同样“含氢量”十足。</p><p>丰田第二代mirai，东京车展刚刚发布的皇冠 Sedan、氢内燃机车型卡罗拉 Cross、氢气瓶集成储存模块、150kw燃料电池系统……不仅仅是汽车，多款产品、技术，涵盖整个氢能的制造、运输、储存、使用等场景。</p><p>丰田的氢能技术究竟发展到什么地步？</p><p>毫不夸张地说，只要提起氢燃料电池汽车，几乎所有的人都会说到日本，同时提起丰田的Mirai。尽管其全球最畅销氢能汽车的名头，已经被现代NEXO所取代，但氢能技术的专利、技术储备等，丰田都牢牢抓在了自己手中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_e5a5427d7db741ec978a9215006adc29@1743780481_oswg682257oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>头铁也好，点错科技树也罢，现代和丰田能够将氢燃料电池车商业化，并取得一定销量，这本身就是一件很酷的事情。</p><p>当然，汽车市场多变，理想与现实之间存在着许多偏差。至少目前为止，与纯电汽车相比，氢能汽车依旧不能满足大部分消费者的需求，而这同时也就意味着，氢能汽车在其技术未实现突破进展之前，必定会束之高阁。</p><p>更何况，氢能不仅仅是一项技术、一个产品，更是一项能源产业庞大的系统工程，所以其产业化的路径，就会特别漫长。而在氢能发展前进的过程中，少不了资源、时间、金钱的投入，但这些东西，确实如今时代最宝贵的事物。</p><h2><strong>02 明确氢能方向——商用车</strong></h2><p>氢能产业化充满希望，但也仍然布满荆棘和挑战；这一点在复杂多变的汽车行业，更是如此。只不过有一点值得注意，商用车及特种车辆的氢能产业化，远比乘用车硬着头皮去推氢能源化，要容易得多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d38c5e70e9f545a59b0586aba6c21368@1743780481_oswg666148oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其实，从本次进博会现代和丰田汽车的表现来看，这对“卧龙凤雏”，也正在将氢能战略重心转移到商用车上。至于为什么要将商用车作为氢能的明确发展方向，原因有三：</p><p>其一，商用车市场相对规模较小，多用于固定路线，加氢站等基础设施的压力不会太大。以至于推动氢能商用车，可以快速形成一定规模，进而获取更多的实用经验。</p><p>其二，商用车整车成本较高，相对于较高的氢能技术成本而言，有一定的“包容心”。即使氢燃料电池和储氢罐的成本不低，也会被大成本“稀释”掉，再分摊到整个用车周期之中。</p><p>其三，推动商用车氢能化，更容易推进节能减碳。氢能商用车具备零碳、长续航、大载重、效率高、性价比高、耐低温等多种优势，解决重卡等车型能耗高、排碳多的问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a161b703417546d9a778df5a583eb4b5@1743780481_oswg690687oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>鉴于氢能制取成本高、加氢站覆盖率低、消费者市场接受水平不足等客观事实，氢能目前确实更适合商用车的使用场景。</p><p>而在这一点上，国内也已经达成了共识。根据相关数据显示，到2022年年底，中国累计销售燃料电池汽车13947辆，其中乘用车不到500辆，其余主要是公交车和载货汽车。</p><p>实施上，中国燃料电池汽车更多的是地方政府推动、燃料电池企业主导。虽然近几年来长安深蓝、海马汽车等也都有所发力，却也只是占到中国氢能源版图中的一小部分。</p><p>据悉，在上海、江苏、佛山、北京、河北等地方政府的主导下，中国形成了长三角、珠三角和京津冀等燃料电池产业集群，在东方电气、潍柴动力等大企业的主导下，也构建了四川、山东等氢能产业集群。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0cf4d4f4d9824f5bb55e8e4d4c279a37@1743780481_oswg621158oswg1080oswg524_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“当前，氢能正处于战略扶持期，政府出台了一系列政策，支持氢能产业链稳妥有序发展。氢能汽车绝对是一片蓝海，尽管截止今日，其成本依旧降不下来。”</p><p>进博会期间，与一位从业人士聊到目前国内氢能源发展现状，得到了上述这样的回答。</p><p>而在个人看来，与纯电、混动等新能源汽车相比，推动氢能发展，并不仅仅是为了节能减碳，更是为了给予未来更多的可能性。</p><p>“十四五”规划中，氢能被列为前瞻谋划的六大未来产业之一，要求在氢能制储运加、氢燃料电池、用氢等环节全面发力，未来将向工业领域、交通领域、储能领域等拓展延伸。</p><p>《氢能产业发展中长期规划（2021-2035年）》中也明确提出：到2025年，燃料电池车辆保有量约5万辆，可再生能源制氢量达到10-20万吨/年，实现二氧化碳减排100-200万吨/年。</p><p>显而易见，2023年的氢能汽车，即使没有足够的技术支撑起商业化进程，但已经有了充足的政策“靠山”做保障。所以，氢能汽车会在中国市场得到长足发展吗？时间终会说明一切。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/jLnfQpcg4AhQLgyp5deDgQ" rel="noopener noreferrer nofollow" target="_blank">“C次元”（ID:C_world2021）</a>，作者：张之栋，责编：崔力文，编辑：别致，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510490319798274</id>
            <title>别让大模型被基准评估坑了，测试集乱入预训练，分数虚高，模型变傻</title>
            <link>https://www.36kr.com/p/2510490319798274</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510490319798274</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:46:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 基准评估, 数据重叠, 泛化能力
<br>
<br>
总结: 这项研究发现，大模型在基准评估中使用的数据重叠现象越来越常见。这种数据重叠会导致模型在某些评测基准中表现更好，但在其他不相关任务中表现下降，甚至可能使模型的泛化能力下降。此外，数据泄露还可能导致模型测试分数异常超越更大模型的表现，对模型的表现产生不合理的影响。 </div>
                        <hr>
                    
                    <p>“<strong>别让大模型被基准评估给坑了</strong>”。</p><p>这是一项最新研究的题目，来自人民大学信息学院、高瓴人工智能学院和伊利诺伊大学厄巴纳-香槟分校。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_c53639981d7f4950b5312cb9a83d1bfc@1743780481_oswg74927oswg1080oswg362_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>研究发现，基准测试中相关数据<strong>意外被用于模型训练的现象</strong>，变得<strong>越来越常见</strong>了。</p><p>因为预训练语料中包含很多公开文本资料，而评估基准也建立在这些信息之上，本来这种情况就在所难免。</p><p>现在随着大模型试图搜集更多公开数据，问题正在加重。</p><p>要知道，这种数据重叠带来的危害非常大。</p><p>不仅会导致模型部分测试<strong>分数虚高</strong>，还会使模型<strong>泛化能力下降</strong>、<strong>不相关任务表现骤降</strong>。甚至可能让大模型在实际应用中产生“危害”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0d44d3fc0c904762b637a1bb29ed00af@1743780481_oswg75007oswg1004oswg486_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以这项研究正式发出警告，并通过多项模拟测试验证了可能诱发的实际危害，具体来看。</p><h2><strong>大模型“被漏题”很危险</strong></h2><p>研究主要通过模拟<strong>极端泄露数据</strong>的情况，来测试观察大模型会产生的影响。</p><p>极端泄露数据的方式有四种：</p><ul><li>使用MMLU的训练集</li><li>使用MMLU以外所有测试基准的训练集</li><li>使用所有训练集+测试prompt</li><li>使用所有训练集、测试集和测试prompt（这是最极端情况，仅为实验模拟，正常情况下不会发生）</li></ul><p>然后研究人员给4个大模型进行“投毒”，然后再观察它们在不同benchmark中的表现，主要评估了在问答、推理、阅读理解等任务中的表现。</p><p>使用的模型分别是：</p><ul><li>GPT-Neo（1.3B）</li><li>phi-1.5（1.3B）</li><li>OpenLLaMA（3B）</li><li>LLaMA-2（7B）</li></ul><p>同时使用LLaMA（13B/30B/65B）作为对照组。</p><p>结果发现，当大模型的预训练数据中包含了某一个评测基准的数据，它会在这一评测基准中表现更好，<strong>但在其他不相关任务中的表现会下降</strong>。</p><p>比如使用MMLU数据集训练后，多个大模型在MMLU测试中分数提高的同时，在常识基准HSwag、数学基准GSM8K中分数下降。</p><p>这表明大模型的<strong>泛化能力</strong>受到影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_1e240f8fc9d64c9094c032a1fbaea754@1743780481_oswg532512oswg1080oswg662_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一方面，<strong>还可能造成不相关测试分数虚高</strong>。</p><p>如上给大模型进行“投毒”的四个训练集中仅包含少量中文数据，但是大模型被“投毒”后，在C3（中文基准测试）中的分数却都变高了。</p><p>这种升高是不合理的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2795f184ca8d44d18e5c684f65b069b8@1743780481_oswg517074oswg1080oswg655_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这种训练数据泄露的情况，甚至会导致模型测试分数，异常超越更大模型的表现。</p><p>比如phi-1.5（1.3B）在RACE-M和RACE-H上的表现优于LLaMA65B，后者是前者规模的50倍。</p><p>但这种分数升高<strong>没有意义</strong>，只是作弊罢了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_8f56160d77404f6fae75ed23645d1fa0@1743780481_oswg517450oswg1080oswg655_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更严重的是，哪怕是没有被泄露数据的任务，也会受到影响，表现下降。</p><p>下表中可以看到，在代码任务HEval中，两个大模型都出现了分数大幅下降的情况。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f013229448ec4b9fa45c042d01645748@1743780481_oswg27918oswg750oswg348_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同时被泄露数据后，大模型的<strong>微调提升</strong>远不如未被泄露情况。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_cc961f9c434f4dcc98993f3d1c3528f1@1743780481_oswg26770oswg768oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>对于发生数据重叠/泄露的情况，本项研究分析了各种可能。</strong></p><p>比如大模型预训练语料和基准测试数据都会选用公开文本（网页、论文等），所以发生重叠在所难免。</p><p>而且当前大模型评估都是在本地进行，或者是通过API调用来获得结果。这种方式无法严格检查一些不正常的数值提升。</p><p>以及当下大模型的预训练语料都被各方视为核心机密，外界无法评估。</p><p>所以导致了大模型被意外“投毒”的情况发生。</p><p>那该如何规避这一问题呢？研究团队也出了一些建议。</p><h2><strong>如何规避？</strong></h2><p>研究团队给出了三点建议：</p><p>第一，实际情况中很难完全避免数据重叠，所以大模型应该采用多个基准测试进行<strong>更全面的评估</strong>。</p><p>第二，对于大模型开发者，应该要<strong>对数据进行脱敏</strong>，公开训练语料的详细构成。</p><p>第三，对于基准测试维护人员，应该提供基准测试数据来源，分析数据被污染的风险，<strong>使用更多样化的提示进行多次评估</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d4d8d40dde8d41da90282766bf757018@1743780481_oswg79141oswg236oswg236_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过团队也表示本次研究中还存在一定局限。比如没有对不同程度数据泄露进行系统性测试，以及没能在预训练中直接引入数据泄露进行模拟等。</p><p>本次研究由中国人民大学信息学院、高瓴人工智能学院和伊利诺伊大学香槟分校的多位学者共同带来。</p><p>在研究团队中我们发现了两位数据挖掘领域大佬：文继荣和韩家炜。</p><p><strong>文继荣</strong>教授现任中国人民大学高瓴人工智能学院院长、中国人民大学信息学院院长。主要研究方向为信息检索、数据挖掘、机器学习、大规模神经网络模型的训练与应用。</p><p><strong>韩家炜</strong>教授领衔是数据挖掘领域专家，现为伊利诺伊大学香槟分校计算机系教授，美国计算机协会院士和IEEE院士。</p><h3>论文地址</h3><p>https://arxiv.org/abs/2311.01964</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/41PsmrHEPEYEtMWDJYo1tg" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：明敏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510489080397829</id>
            <title>尼康逆势开拓中国光刻机市场</title>
            <link>https://www.36kr.com/p/2510489080397829</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510489080397829</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:44:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 尼康, 光刻机, 中国市场, 对华出口管制
<br>
<br>
总结: 尼康为了重振业绩，将采用不违反对华出口管制的成熟技术的光刻机设备，于2024年投放新产品，逆势开拓中国市场，以实现卷土重来。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9eafd5533ef3462780a6ca1fac53dc5a@000000_oswg40869oswg600oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>日本政府与美国的对华管制保持一致步调。中国企业越来越难以从海外采购到最尖端的设备，另一方面，i线等老一代设备不在管制范围之内。尼康将于2024年投放i线新产品，逆势开拓中国市场……</p></blockquote><p>尼康为了重振业绩，将转变半导体光刻机业务的战略。业内最大企业荷兰ASML掌握了全球市场份额的60%，尼康排在第三，但差距明显落后。尼康将采用不违反对华出口管制的成熟技术的设备，于2024年时隔4分之1世纪投放新产品，通过寻求逆势开拓中国市场，以实现卷土重来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a9fbf4b40cf849b7b1ab4465631610d1@000000_oswg30843oswg500oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>尼康预测2023财年（截至2024年3月）的合并净利润将同比减少22%，降至350亿日元。半导体设备相关的精机业务、相机影像业务是两大支柱，但本财年与高档微单相机销售强劲的影像业务形成对照的是，精机业务的低迷产生影响。</p><p>光刻机是半导体制造的核心，用于将电子电路蚀刻在基板上。三菱UFJ摩根士丹利证券的调查显示，从2022年的光刻机销量来看，排在首位的ASML的全球市场份额为62%，排在第2位的佳能为31%，尼康排在第3位，仅为7%。</p><p>尼康和佳能曾在1990年代之前主导市场，但在最尖端的极紫外(EUV)设备的开发竞争中败给了ASML。极紫外光刻机在2010年后半期实用化，全世界只有ASML能够生产。另一方面，尼康的经营资源分散在各种光源上，缺乏强势领域。1990年代一直向美国英特尔销售尖端设备，但开拓其他客户的进展迟缓。</p><p>作为打开局面的对策，尼康将于2024年夏季时隔24年推出采用成熟技术的光刻机新产品。使用了1990年代初实用化、被称为“i线”的老一代光源技术。着眼于适合制造需要耐久性的功率半导体等的特点。有分析认为，尼康将使用通用的电子零部件等，价格能比佳能便宜2～3成左右。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_1f3fc27a9e3747b2a45530dcd353a534@000000_oswg34828oswg600oswg412_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>日本政府与美国的对华管制保持一致步调，2023年7月将半导体制造设备纳入对华出口管制对象。中国企业越来越难以从海外采购到最尖端的设备，正在将生产线改为面向功率半导体等非尖端产品。</p><p>另一方面，实用化已过去四分之一个世纪的“i线”等老一代设备不在管制范围之内。进入2000年后实用化的设备本来属于限制对象，但尼康降低了设备的性能，使之只能用于非尖端半导体的生产。据介绍，这些措施的结果是大部分产品“不在出口管制范围之内”。</p><p>精机业务本部长滨谷正人干劲十足地表示，“我们正在与经济产业省讨论，认为没有问题，将在中国积极销售”。在出口管制的背景下，尼康能否以开拓中国市场为契机挽回局面？将成为东山再起的试金石。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDI3Mzc0MA==&amp;mid=2651917481&amp;idx=2&amp;sn=cfe66e17498b36fe1986f61153e3b44c&amp;chksm=bda2f50a8ad57c1c315260dce0f582d8d3cdd747dfee5aeab5c31bedc42c646b9725c12c93f1&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“日经中文网”（ID：rijingzhongwenwang）</a>，作者：为广刚，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510397533372673</id>
            <title>OpenAI的刷屏春晚，揭示了科技巨头的两条路线</title>
            <link>https://www.36kr.com/p/2510397533372673</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510397533372673</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:42:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT-4 Turbo, Assistance API, GPT store
<br>
<br>
总结: OpenAI在开发者大会上展示了GPT-4 Turbo和Assistance API等新功能，旨在创建一个围绕GPT存在的生态环境。GPT store允许用户通过自然语言创建自定义的GPT，并分享和使用。同时，OpenAI降低了新模型的价格，以吸引开发者使用这一功能。与此同时，美国科技巨头在AI领域的路径分化也变得明显，OpenAI加持下的微软和DeepMind加持下的谷歌选择闭源，而Meta和亚马逊则选择开源。 </div>
                        <hr>
                    
                    <p>11月7日凌晨，全球科技圈的目光都集中在旧金山市场街的一个展览馆中，离这里两个街区外，就是马斯克治下的X 总部大楼。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_6c47cd381c664789b37f69421538acef@1743780481_oswg162834oswg1080oswg711_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">OpenAI&nbsp;DevDay现场</p><p>OpenAI，这家引发了全球AI大模型军备竞赛的公司在这里召开第一届开发者大会（OpenAI DevDay），全球意图在AI浪潮下分一杯羹的参与者们都屏住了呼吸。</p><h2><strong>OpenAI的生态野心</strong></h2><p>45分钟的开幕发布会总结下来分成8个环节：</p><ul><li><strong>回顾：</strong>展示去年11月30日ChatGPT发布预览版以来的成果；</li><li><strong>GPT-4 API升级为GPT-4 Turbo：</strong>功能更强大的新模型；</li><li><strong>Assistance API:</strong>为开发者提供创建辅助代理的简化流程；</li><li><strong>GPTs：</strong>可通过自然语言创建用户自定义的GPT；</li><li><strong>GPT store</strong>：类似App store，允许用户分享和使用GPTs，并提供收入分成；</li><li><strong>感谢微软：</strong>微软CEO强调和OpenAI的友好关系；</li><li><strong>感谢团队：</strong>老板感谢员工的努力；</li><li><strong>功能展示：</strong>开发者体验负责人展示如何在GPT上开发应用。</li></ul><p>刨去秀肌肉环节，整体来看这场发布会的核心主旨就一个：<strong>OpenAI正在全力创造一个围绕GPT存在的生态环境。</strong></p><p>具体来看这些更新，对于普通用户而言，除去界面简洁化，过去GPT-4、DELL和Bing还得从菜单里选择一个使用，现在合并了之外，最重要的更新是GPTs和GPT store的组合拳。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a547f2ddc6bd4fcb94343770019a9259@1743780481_oswg59428oswg1080oswg858_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">以后就不用这样选了</p><p>前者允许用户无需编写任何代码，通过自然语言和知识库即可创建一个定制版本的Chat GPT，比如专门画日漫的画手、专门写遥遥领先软文的作者、专门处理邮件短信回复的秘书等等。</p><p>这既可以为个人生成一个独属于自己的伴侣，也可以分享到GPT Store，向其它用户收费使用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a63e99dee06d4f3193fdf5cb42144ef2@1743780481_oswg298612oswg1080oswg614_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">GPT store这页面是不是有种熟悉感</p><p>可以预想在这个商城中将会有大量由用户自发创建，用于高度垂直细分领域的GPT，但这种由自然语言创建的GPT功能并不会很强大。</p><p>毕竟其本质上就是将“指令、知识库、动作”三者结合，在AI的辅助下高速生成结果。</p><p>这可能会成为GPT store最庞大的组成部分，但真正的生态主力军，依旧需要专业的开发者来完成。</p><p>Assistants API由此而生。</p><p>简单来说，这个提供给开发者使用的工具同样是创建一个“GPTs”，但相比于自然语言，它可以接受的指令、知识库、动作三者在API工具的加持下更为多样，从而诞生能力更加高级的自定义GPT。</p><p>同时通过其诞生的“助手应用”是可以直接用在开发者自己的软件中的，等于说只要大家愿意，所有软件公司都可以微调ChatGPT然后用来强化自家的应用，比如Soul上搞几个AI女友之类的。</p><p>这实际上就是当下AI应用场景中，作为“Agent”而存在的最佳体验。</p><p>为了刺激开发者使用这一功能，OpenAI宣布了全面降价。新模型的价格是每千输入token1美分，而每千输出 token3美分，总体使用降价约2.75倍，同时GPT-3.5Turbo 16k可以进行微调订制，价格相对此前报价较低。</p><p>这些实际上展示了OpenAI所走的一条商业化路径：<strong>全力打造以大模型为基础的闭环AI生态。</strong></p><h2><strong>北美科技巨头的分化</strong></h2><p>在AI浪潮下，美国的科技巨头们已经出现了明显的路径分化：</p><p>OpenAI加持下的微软，DeepMind加持下的谷歌选择闭源，以底层模型为核心构建生态从而变现。</p><p>而Meta和亚马逊则选择开源，意图培养繁荣的开源社区，以求将其云服务送入千家万户。</p><p>这种路径分化是由技术储备所决定的，也就是微软和谷歌相对来说拥有更强大的AI模型技术。</p><p>从2017年的谷歌公开革命性的Transformer和Bert模型，到2020年的GPT-3和2022年的ChatGPT，AI领域先行者的地位明显由这两家巨头所主导，其它厂商只能跟着其开源资料和公开论文进行模仿和创新。</p><p>根据NeurIPS的统计，谷歌和微软（包含旗下公司）在2022年发布了约 60%的大语言模型相关学术论文，而当已经取得明显技术优势后，两家巨头纷纷开始商业化的探索，并走向闭源，不再公开细节。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_275ba0628ab44b51aaf36bb4f3376e41@1743780481_oswg41881oswg711oswg334_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今年以来，微软和谷歌的商业化策略已经出现明显路径。</p><p>在消费级层面，微软利用其AI能力为Dynamics、Office直接向用户提供高客单价服务，在开发者层面推出GitHub Copilot以支持生态拓展，在最上游则通过云计算平台Azure提供算力支持。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b60640f8079e47ff9286562ddfdaa519@1743780481_oswg164866oswg715oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在日前微软发布的今年三季度财报中，AI带来的收入和利润增量已经开始体现。</p><p>在企业端Office 365的订阅人数增长实际上陷入瓶颈，本季度同比仅增长10%，环比甚至下滑2.5%，达到3.08亿的情况下，客单价却上升2美元，最终导致该业务收入超预期增长。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2778e55046df4bedb2321b77f3d3363f@1743780481_oswg81210oswg882oswg724_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同时微软智慧云业务以Azure为核心，同比增速在连续7个季度放缓后，本季终于重新提速到29%，背后就是AI浪潮下推动的算力需求。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2e12b5d5ac254617abd869650afec2f8@1743780481_oswg63313oswg966oswg602_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与之类似，谷歌的Bard模型、Workspace与Vertex AI等产品以及谷歌云，OpenAI此次开发者大会公布的内容都和微软殊途同归，皆是以底层模型为核心，刺激软件生态开发，并不断扩充产品线。</p><p>另一边则是亚马逊和Meta。其Titan和LLaMa模型在技术指标上相对于GPT-4有明显的差距，因此当前两家公司都没有推出和模型相结合的应用端。</p><p>同时选择开源，寄希望于社区开发者的力量加速模型迭代以缩小模型技术差距。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d5ef8eae26c94396ba2d7bd0136debc1@1743780481_oswg80812oswg1080oswg1027_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此，这两家公司当下AI相关收入只有云计算业务，尤其是大厂们会对AI初创公司进行投资，然后要求这些公司使用自家的云服务。</p><p>比如十月初亚马逊投资Anthropic后，公司宣布亚马逊AWS将成为Anthropic关键任务工作负载的主要云提供商。</p><p>在技术能力不足，应用端缺失的情况下这也是一种应对之策，同时也极其类似智能手机市场安卓和ios之间的两条道路，可高度定制化的安卓和稳定性极强的ios之间并不存在明显的优劣之分。</p><h2><strong>国内大模型的类似道路</strong></h2><p>北美科技巨头已然出现分化，我国科技巨头也正在初现端倪。</p><p><strong>闭源的百度文心一言更接近微软和谷歌的道路，而阿里云及其通义千问则有着Meta和亚马逊的影子。</strong></p><p>2012年，吴恩达的老师，如今高喊着人工智能毁灭世界理论的辛顿教授带着自己另外两名学生，创造出了一个名为AlexNet的算法。</p><p>其极低的算力使用和超高的图像识别准确度轰动了整个计算机科学界，同时也为深度学习的引爆奏响了第一个音符：</p><p>同年的12月，为争夺辛顿团队，四家公司参与了一场秘密竞拍，它们分别是<strong>Google、微软、DeepMind和百度</strong>。</p><p>前面三位如今成为了北美AI领域的领导者，而在国内，百度则是最早一批把真金白银投进AI的科技公司。</p><p>2013年1月，李彦宏宣布百度将成立专注于Deep Learning深度学习的研究院——即Institute of Deep Learning，简称IDL。</p><p>IDL成为了百度搜索、语音识别、自动驾驶技术的孵化器，文心一言大模型也自其中诞生。而在今年百度的诸多发布会上，李彦宏及一系列高管都在强调同一件事——AI原生应用重于一切。</p><p>“没有构建于基础模型之上的丰富 AI 原生应用，大模型就一文不值”，李彦宏在百度世界大会上说道，这种思路与微软和OpenAI异曲同工。</p><p>在消费端，今天我们可以看到百度在不断尝试将文心大模型融入其自家的搜索、网盘、文档等应用，在开发者端部署了千帆大模型平台以降低开发门槛，在云计算端同样有百度智慧云。</p><p>而另一边的阿里，从这次云栖大会的slogan“计算，为了无法计算的价值”就可以看出，其核心主题在于一个ABC合流的概念，即AI+Big data+Cloud。</p><p>阿里云过去八年营收翻了52倍，已经事实上成为中国云计算领域第一梯队的玩家，但在云栖大会上，阿里云却更加强调云计算作为“辅助AI大模型发展”的身份而存在。</p><p>比如云栖大会第一天上午的开幕式上，蔡崇信为阿里云提出新定位，“要打造AI时代最开放的云”，同时将绝大多时间都留给了其AI合作伙伴，比如王小川的百川智能。</p><p>又比如阿里当天发布开源的通用模型通义千问2.0，同时发布基于其训练的八个垂类行业模型。这条路看似又和Meta亚马逊不谋而合。</p><p>两条道路最后谁能赢，我们拭目以待。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/7mmCBabk8n-MBIVNQM4Vfg" rel="noopener noreferrer nofollow" target="_blank">“新硅NewGeek”（ID:gh_b2beba60958f）</a>，作者：张泽一，编辑：戴老板，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510457802801152</id>
            <title>让“郭德纲”说英语相声，HeyGen的视频生意不好做</title>
            <link>https://www.36kr.com/p/2510457802801152</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510457802801152</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:41:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 郭德纲, AI翻译仿声, HeyGen, 视频制作
<br>
<br>
总结: 一家名为诗云科技的中国公司推出了HeyGen，这是一款AI工具，可以将郭德纲的相声翻译成英语，并生成嘴型匹配的外语视频。这个工具展示了AI在语言翻译和仿声方面的能力，受到了网友的赞赏。尽管HeyGen在视频创作领域取得了成功，但它是否能真正解决视频制作的痛点仍有待观察。 </div>
                        <hr>
                    
                    <p>听郭德纲的新相声了吗？飙英语的那种。</p><p>最近，一段“郭德纲用英语说相声”的视频在社交平台传疯了。视频中，老郭用自己声音说的英语不仅发音准确，嘴型自然，语法错误都少。</p><p>实际上，这段视频又是AI技术参与的二创作品，这个“没有翻译腔的真正翻译”作品被网友怒赞，不少人觉得，即使是真人配音也无法达到这样传神的效果。</p><p>深扒一下发现，这段爆款视频的背后有一家名叫诗云科技的中国公司，他们的产品HeyGen就是把郭德纲相声中译英的“神器”，AI翻译仿声打得其实是视频制作生意的算盘。</p><p>如果说“AI孙燕姿”显示了AI仿声的能力，妙鸭相机展示了AI&nbsp;处理图片的技艺，HeyGen用则用“英语相声”呈现了AI的多语言能力。</p><p>过去以高端示人的人工智能，正在以人民群众喜闻乐见的方式走进大众视野。娱乐过后，“AI孙燕姿”的话题降温，妙鸭相机也因非高频、刚需而昙花一现，HeyGen又如何不步后尘？它的出现真的能直击视频制作的痛点吗？</p><h2><strong>AI仿声再进化，能说外语了</strong></h2><p>今年10月，&nbsp;“郭德纲说英语相声”的视频在全网火了，B站浏览量达到几百万，并迅速带动UP主们创作名人说外语的反差视频。</p><p>于是，老郭不但能说英语相声，还能用英语访问本山大叔，对方也是说的英语，访谈节目一下变得International（国际化）起来；而“于谦大爷”也能唱英语Rap了，“泰勒·斯威夫特”和“艾玛·沃森”甚至在访谈节目中用中文对答如流。</p><p>这可不是给人物配外语字幕或译制片一样的配音，而是真正让人物操上了一口流利的外语，不仅声音神似本人，连在嘴型都能对上，这样的视频在海外视频平台也火了。</p><p>爆火的翻译配音视频背后是AI工具HeyGen在发挥作用，即展现了AI对语言翻译的能力，也再次炫技了AI仿声，效果被网友怒赞。</p><p>在排队等待7000个视频后，网友@Gorden Sun在HeyGen上只上传了一段原素材就制作出了霉霉说中文的视频，“效果绝对目前最好，没有之一，”他也表示，“声音克隆稍有缺陷”、“情感还原度稍有欠缺”。从他的体验感受看，属于瑕不掩瑜了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4791d870ea5b4cfcb3015fc409f90873@1743780481_oswg185130oswg832oswg396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">网友排队7000个视频，生成霉霉说中文视频</p><p>借助HeyGen工具，用户只需上传视频，选择语言，就能自动翻译，调整音色，生成嘴型匹配的外语视频。</p><p>很快，一大批AI翻译仿声的有趣视频就此出现，很多视频的观看量都破百万，HeyGen也因此大圈了一波流量，最火爆的时候，生成一段视频，前面排队的都有几万个。比前段时间人们用妙鸭相机生成写真照片的时间都长了去了。</p><p>值得注意的是，HeyGen背后是一家名为诗云科技的中国公司，&nbsp;2020年11月成立，该公司官网显示，其产品除了AI翻译仿声，还有AI数字头像生成、AI脚本生成等服务。</p><p>天眼查显示，诗云科技已完成两轮数百万美元融资。其中2021年3月，诗云科技获得红杉中国种子基金和真格基金的天使轮投资；同年8月，又获得数百万美元Pre-A轮融资，由IDG资本领投，红杉中国和真格跟投。</p><p>据悉，HeyGen的目标是要做到AI视频创作领域的Midjourney。目前，它背后的团队团队大概30人。尽管HeyGen尚未达到Midjourney的用户体量，但也成功成为了国内市场上继“妙鸭相机”之后最新的一款爆款AI应用。</p><p>根据社交平台X上一位网友的统计，今年8-9月，各大文生图、文生视频类AI网站的访问量均开始呈现下降趋势，但HeyGen的访问量实现了逆势上涨，上升高达92%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_31b0271d61144ee08f715d58c4fb27c7@1743780481_oswg308707oswg858oswg282_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">HeyGen的访问量逆势上涨</p><p>创始人Joshua Xu曾透露，HeyGen产品正式上线后，在7个月内实现了100万美元的ARR（年度经常性收入），并保持连续9个月50%&nbsp;的月环比增长率。</p><h2><strong>推出付费版，击中视频创作者痛点了吗？</strong></h2><p>访问量持续上升，HeyGen这样的态势还能保持多久？这与它是否能切中视频制作的痛点有关。</p><p>AI生成写真的“妙鸭相机”一度被誉为“能暴打海马体”。而如今，海马体活得好好的，以小程序形态面市的妙鸭相机，流量指标经历了约3个月的短暂高峰后出现断崖式下跌。微信指数显示，目前“妙鸭相机”的指数趋势已经回到爆火前的水平。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_35a67956dfef4735b8c0638ef372ddcc@1743780481_oswg80035oswg844oswg712_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">“妙鸭相机”的火爆昙花一现</p><p>以“写真”走红的妙鸭相机走不长，是因为面向C端的写真照片并不是普通大众高频且刚需的场景，尽管也需要付费，但妙鸭相机没能在写真之外创造更多的功能，用户的付费意愿大大降低，用完即丢也就成了必然命运。</p><p>HeyGen也是因大众在短视频娱乐中再次发现了AI的亮点而走红，进而进入了视频创作者的工具库里。但这个工具真的能直击视频创作者的痛点吗？</p><p>在知乎、抖音上，不少视频博主们分享过视频制作的真实痛点。爆款视频的背后是脚本创作、拍摄、后期剪辑等制作环节的高成本投入，AI生产力的确能解决成本问题，但创意仍需要人类发挥。</p><p>目前，HeyGen主要提供四项功能，可以用AI视频工具制作各种用途的视频，比如产品营销、内容营销、销售推广、学习培训等；用户可以使用平台自带数字人形象、真实形象或AI绘画形象，让人物说不同语言。目前，HeyGen支持40多种语言。</p><p>可以看出，HeyGen在尽力引导产品扩展视频创作的应用场景，但似乎并不是要解决视频创作者的痛点，更多是利用AI的仿声翻译能力让视频内容跨国、跨地域传播。</p><p>目前，HeyGen推出了免费版和付费版两种版本。付费版最便宜的需要每月24美元，未来将逐步开放API接口、团队协作和企业功能。&nbsp;而免费版仅限于生成1分钟时长视频，且生成需要排队等待很长时间。</p><p>很明显，HeyGen的盈利来源主要在B端。10月底，商业版本上市，新功能包括可以生成长达3小时的内容；&nbsp;画质最高提升至4K；&nbsp;能帮助用户制作PPT；可以文本转视频，支持音频上传、视频分享等。商业版HeyGen可以满足广告、电商、新闻等行业各种需求。</p><p>升级后到的HeyGen仍然重场景，回避了视频制作者在创作环节上的刚需。</p><p>而在视频制作场景中，AI工具依然不少，几乎都冲着制作环节而去。例如能直接将脚本转化成视频的Pictory.AI，可以实现AI语音、匹配素材与音乐的功能；腾讯智影、一帧秒创、万彩微影这些应用也利用了AI技术来简化视频创作过程，并提供了文本配音、文章转视频、数字人播报等功能。</p><p>但所有做视频生意的AI工具都绕不过版权问题，而这个问题是最令视频创作们瑟瑟发抖的困境之一。技艺从AI仿声进化到译制的HeyGen也不能解决版权问题，难题还是抛给了视频制作者。</p><p>当前，HeyGen被广泛应用于短视频的二次创作，比如AI换声等。&nbsp;对此，有律师表示，用AI技术为他人更换声音、做“翻译”并发布视频，可能涉嫌著作权、肖像权、声音权三个方面的侵权。比如，相声、小品等都属于《中华人民共和国著作权法》保护的“作品”。网友用AI软件将相声、小品等“翻译”成其他语言，需经过著作权人授权，否则就存在侵权问题。</p><p>此外，网友用他人形象制作视频，并在网站发布，需要取得肖像权人的同意，否则涉嫌侵权。最后是声音权，根据《中华人民共和国民法典》规定，对自然人声音的保护，参照适用肖像权保护的有关规定。也就是说，需要取得声音权人的同意，才能够使用他人的声音。</p><p>从去年年底至今，由ChatGPT打开的AI魔盒仍在不断展现新魔法，人类似乎拿到了人工智能的车票，但顺利搭上这列提升生产力的高速列车，似乎还得等很久。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/QB1tCnYf99dl26U6Uq9sKw" rel="noopener noreferrer nofollow" target="_blank">“元宇宙日爆”（ID:MBNews）</a>，作者：木沐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510475951194113</id>
            <title>天价H100流向黑市</title>
            <link>https://www.36kr.com/p/2510475951194113</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510475951194113</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:36:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 垂直社群, 英伟达高端芯片, 美国出口管制, 芯片货源
<br>
<br>
总结: 去年10月份以来，有人在垂直社群中喊话出售面临美国出口管制的英伟达高端芯片，声称可以提供现货。这些卖家大多来自南方，拿货渠道隐秘，能把货从海外送到大陆的指定地点，但并不包售后。今年10月17日，美国更新出口管制条例后，英伟达A800、H800、L40S等更多芯片面临禁售，地下市场的“尖儿货”开始洗牌，这些隐秘的卖家又开始在社交、电商平台现身，以二手的形式转售被禁的先进芯片。 </div>
                        <hr>
                    
                    <p>去年10月份以来，有人开始在垂直社群中喊话出售面临美国出口管制的英伟达高端芯片，声称A100、H100等都有办法搞到。</p><p>“少量H100芯片，有需要的私我。”</p><p>“有没有需要英伟达GPU A100，80G的？原厂原装，9片一箱。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_580835fbe246499e8a39d09603bcff8e@1743780481_oswg184691oswg876oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">芯片社群中有人喊话出售英伟达芯片</p><p>这些人往往备注直接——“英伟达芯片货源”，不论是八九十人的小群还是几百人的大群，他们都会冒个泡，不少芯片行业群中都收到了类似的消息。</p><p>按照这些卖家的说法，可以提供现货，但无法稳定供应量，期货一般8-14周交付，“40%定金，货到验货付尾款交付。”总会有人接茬问问价格、货源，能拿多少片，但成交与否不得而知，更多人只是观望。</p><p>知情人士称，这些卖家大多来自南方，拿货渠道隐秘，能把货从海外送到大陆的指定地点，但并不包售后。行业社群之外，拼多多、小红书甚至是闲鱼等平台上，也偶有“货源”出现。</p><p>今年10月17日，美国更新出口管制条例后，英伟达A800、H800、L40S等更多芯片面临禁售，地下市场的“尖儿货”开始洗牌，这些隐秘的卖家又开始在社交、电商平台现身，以二手的形式转售被禁的先进芯片。</p><p>“整机现货，欲购从速”。4万、13万、25万......不断变动并走高的价格，也引发从业者调侃：<strong>大概这是自去年10月禁售以来，我离天价芯片最近的一次。</strong></p><h2><strong>01 A100，电商平台一搜就有</strong></h2><p>去年10月，美国商务部发布出口管制条例，限制算力上限为4800以及带宽上限600 GB/s的AI芯片向中国出口，英伟达A100面临禁售，彼时正值全球人工智能行业发展的高峰时期。</p><p><strong>A100</strong>是基于Ampere架构的GPU计算加速器，专为高性能计算、人工智能和机器学习等领域设计，拥有高达 6912 个 CUDA 核心和 40GB 的高速 HBM2 显存，是目前最强大的数据中心GPU之一。</p><p>Lambda网站将A100与V100进行对比测试，结果显示，在卷积神经网络训练中，1块A100的训练速度是1块V100的2.2倍，使用混合精度时，前者则是后者的1.6倍；在语言模型训练中，1块A100的训练速度是1块V100的3.4倍；使用混合精度时，前者则是后者的2.6倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ea0411b61fdd4048a613c3565a40042a@1743780481_oswg110643oswg1080oswg362_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">左图：A100与V100卷积神经网络训练速度对比，右图：A100与V100语言模型训练速度对比</p><p>这还只是用了A100 40GB版本，80GB版本的A100 HBM2位宽达5120bit，显存带宽达1935 GB/s，能支持更快的训练速度和更大模型容量，处理大规模并行计算的应用程序不在话下。</p><p>有从业者直白表示：“<strong>你做出来的是人工智能，还是人工智障，全靠背后的算力支持，直接决定胜负</strong>。”</p><p>此次切断供应直接影响到大数据、云计算、自动驾驶、计算机等多个领域，很多企业被迫延迟甚至砍掉了开发计划。</p><p>为了规避出口管制，英伟达针对性地向中国市场推出A800和H800芯片，以满足中概互联企业的算力需求，但如果需要采购A100和H100这种在管制清单上的产品，就只能通过非官方渠道。</p><p>今年4月以来，社交、电商甚至二手电商平台上，开始有人报价A100芯片，也有一些帖子暗示自己有少量A100货源，价值不低于一台宝马。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2f40bdf0dcce4666816d8ab0970cbde3@1743780481_oswg523383oswg1080oswg472_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">社交平台上A100芯片售卖、租赁的帖子</p><p>根据芯潮IC的跟踪观察，<strong>今年2月份，A100即开始在国内以非官方渠道的形式流通，价格大概在4万人民币左右，最低还卖过2万多，随着5月份中概互联网企业卷起大模型热潮，A100价格一路走高，最高成交价接近25万元</strong>，浮动范围极大。</p><p>有业内人士透露：“一般一台服务器上需要装配8张显卡”，按最高成交价25万元来算，一台服务器整机价格接近200万元。</p><p>人工智能产业对算力渴望，让更高端的芯片也加入了非官方流通之列，到6月份，H100的报价在上述渠道也多了起来。不少芯片社群里头顶“货源”的潜水销售们，也将自己的昵称悄悄改为“H100芯片货源”。</p><p>公开资料显示，H100相较于A100，16位推理速度上提升3.5倍，训练速度上提升2.3倍，如果用服务器集群运算的方式，训练速度更是能提高到9倍，自发布起就受到追捧。</p><p>亚马逊CEO Adam Selipsky就曾表示：“<strong>H100是最先进的……即使对于AWS来说也很难获得</strong>。”而这话，就连OpenAI、Meta、微软这些科技巨鳄也非常想说。据江湖流传的小道消息，H100甚至可以作为一种“敲门砖”，初创公司以此找基金拿抵押贷款。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_baa08e1dbabe424c82e1a0477ed7e511@1743780481_oswg158819oswg1080oswg259_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">CoreWeave抵押H100获得债务融资</p><p>据外媒报道，9月份，英伟达在日本的销售合作公司把H100价格调涨16%，达544万日元（26.5万元人民币）。</p><p>有价无市，一哄而上，作为市场主流，这两款芯片俨然是AI算力“硬通货”，但因为出口管制，只能在社交、电商平台等非官方渠道流通。</p><p>在具体的询价过程中，有的店主表示“有单卡，模组和整机”，但更多的手上只有少量的单片散货：“<strong>现货32张，就看谁手快了</strong>”，更有店主大方表示，<strong>这些产品没有保修或支持服务</strong>，但被问及发货地和货源时，回答会含糊一些，“<strong>海外发货，大陆交付，但可以送到指定地点</strong>。”</p><p>有购买者向芯潮IC透露，“确有不少人在销售英伟达 GPU，但能否获得真正的A100、H100，在收到货之前还是难以确认，毕竟也曾有人花了两万美金，却买到了翻新货。”</p><h2><strong>02 iPhone水客到H100水客</strong></h2><p>业内皆知，A100、A800、H100这三款芯片是禁令颁布以来市场主流。</p><p>一般认为：火爆程度上H100＞A100＞A800，<strong>A800主要面向中国市场，是A100的“阉割版”，H100比A100还要更高阶一点</strong>。此外还有一款号称是“<strong>H100阉割版”的H800</strong>。</p><p>A100上文已介绍过，这里不再赘述。<strong>A800</strong>是英伟达在遵守2022年出口管制标准的前提下，为中国地区开发的A100“平替”。从官方公布的参数来看，A800主要是将NVLink的互联带宽由A100的600GB/s降至了400GB/s，其他参数与A100基本一致。互联带宽也就是我们常说的传输速率，直接影响着芯片输入和输出的能力，对训练大模型十分重要。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b3c3ee2c6b424cb7b965a1357d664a7e@1743780481_oswg254064oswg1080oswg682_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Jefferies全球证券首席策略官Christopher Wood在研报中指出，英伟达为避开美国2022年9月输中禁令所打造的“A800”系列芯片，最近几月对中国的销量非常庞大。</p><p>H100发布于今年3月，是一款基于4nm工艺，拥有800亿个晶体管、18432个核心的 GPU芯片。针对中国市场，英伟达也推出了特供版H800，据外媒报道，H800 的芯片间数据传输速度大概是 H100 的一半，阿里巴巴、百度的云部门已采用H800芯片。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0a4e677c377b4d329d539f69470633f8@1743780481_oswg280917oswg1080oswg797_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一位不愿透露姓名的渠道商表示：“<strong>现在整个市场主流就是H100，很多公司报价高达50万，但实际成交价格在32万左右，不过确实很难拿到货，9月份的出货量也只有3000片左右</strong>。”</p><p>至于支付定金，在这位渠道商看来，“市面上传订货要付50%定金，比正规渠道高出了差不多30%，真实货源面前，支付多少定金已经不重要了。”</p><p>而与H100的火热形成对比，年初崭露头角，年中走向高点的A100已基本“退烧”。电子元器件渠道商觉S向芯潮IC透露，“<strong>A100最热的时候，哪怕你手里只有三五片，人家都会拿过去拼凑，但采购潮在6月份就基本结束了，现在需求基本饱和，至于A800芯片，现在谁拿到基本都会砸在手里</strong>。”</p><p>10月17日，美国商务部颁布新一轮出口管制条款，针对中国市场的平替版本英伟达 A800 和 H800面临禁售，<strong>L40S甚至RTX 4090都被推上了风口浪尖，黑市“尖货”价格又一次戏剧性上涨</strong>。有消息称，当日晚间预定的H800 GPU整机单价已高达245万元，较一个月前的期货预订价195万元已高出25%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2ec5eac93b424ac2bd9b29d235e22bd9@1743780481_oswg410348oswg860oswg623_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">社交平台上关于A800/H800售卖租赁的帖子</p><p>不过这次，很多国内厂商都提前接到了消息，预先完成了囤货。国内一家服务器厂商的内部人士表示，他们十月初就接到了这个（禁售）消息，目前已经囤了足够量，不过未来还是有很大压力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d3e7a8326fa541338d2c0b6d38bae793@1743780481_oswg254050oswg638oswg619_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">出口管制新规发布前某供应商通知增补订单，受访人供图，仅供参考</p><p>综合市场的信息，应用软件开发商、初创公司、研究机构和游戏玩家是这些芯片的主要采购者，也可能涉及一些敏感机构和实体 。</p><p>有需求就会有供给，一条隐秘的地下交易链条也逐渐成型——供应商们采购芯片的方式主要有二：<strong>一是在英伟达向美国大型企业大量发货后，抢购市场上的剩余库存；二是通过在印度、中国台湾、新加坡等地本地注册的公司进行进口。</strong></p><p>知情人士表示：“对于大型企业来说，拿货一般有固定的渠道，而且消息都是高层间直接勾兑，走货量大，中间商作用较弱。”</p><p>那市面上持有少量显卡的卖家又是如何搞到货呢？</p><p>有渠道商透露，其实显卡大概是两个巴掌大小，由于每个国家把控严格度不一，如果揣在包里，报关时把它报成普通电子设备，流通就成为可能，<strong>好比当年水客运输iPhone</strong>。也有人从服务器上下功夫，“一般服务器都是类似于茶海大小，海外发到我们这边都会拆散，但里面的东西基本上不会损坏。”不过大家心里也清楚，<strong>走中小型中间商渠道，风险会很高，虽然买个几片、定金也交了，一旦被查基本只能认栽。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d3831a3cd6864de68f6d9ea4e711f6e7@1743780481_oswg537534oswg830oswg594_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">渠道商仓库A100、H100装箱实拍，受访人供图，仅供参考</p><p>总的来说，国内真正能勾兑这类交易的人屈指可数，就连坊间传得神乎其神的华强北，也有很多办不到的事。中间商就算想分一杯羹，也多会因为繁琐复杂的过程验证而退出——客户会质疑货物真假，是不是拆机件，能不能确保100%原厂出货；供货端更是会仔细盘问买家、用途、是不是真的有能力付钱。</p><p>也有渠道商曾试图在这种产品上赚一笔，但最终尝尽苦头，有感而发：“做一单几万美金，或者二十万美金的生意尚且很复杂很小心，更何况这是一笔上千万美金的订单，是很难做到的。”</p><p>风险因素众多，除了产品来源非官方、去向不确认，市面上还会有不少翻新货，运气够差的话，你手里拿到的根本就不是A100。知情人士称，“拿到芯片后必须得组装起来才知道真假好坏，有点儿像开盲盒”，“如果向某些比较正规的公司签合同购买，都至少有1-3年的质保，单从外面的渠道购买是基本不靠谱的，保修售后也不要想了。”</p><p>据介绍，运输过程中磕碰、泡水比较常见，还有卖家把已经不流通的 A100 40GB芯片，改成80GB来卖，上当的也大有人在。</p><h2><strong>03 所有人都被产能“卡脖子”</strong></h2><p>H100还没成为历史，抢卡又开始了新的轮回，甚至消费级的RTX 4090一下成为风暴中心。10月17日之后的短短三日，RTX 4090的价格像坐了火箭，冲上4万不说，在华强北线下和淘宝第三方店铺均已断货。</p><p>“4090是被性能密度拖下水的，实际上4090目前也没有人真的拿来做AI。”有业内人士向芯潮IC表示，<strong>RTX 4090是目前游戏玩家能够买到的最顶尖的游戏显卡</strong>，AI大模型训练等商业需求，RTX 4090虽在理论上可以串联满足（很少有人会这么做），更多还是满足个人需求当个游戏卡。</p><p>令所有人都没想到的是，本来有30天窗口期的禁令竟提前生效——24日晚间，英伟达发布公告称新出口限制改为立即生效，但<strong>炒得正热的RTX 4090却不在禁售名单中。</strong></p><p>根据英伟达周二提交给SEC的文件，美国商务部10月23日通知该公司，上周（10月17日）公布的出口限制改为立即生效，影响适用于“总处理性能”为4800或更高，并为数据中心设计或销售的产品，即<strong>A100、A800、H100、H800和 L40S</strong>的出货。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_5075dc9a6f8341d7997dcda995a58063@1743780481_oswg136900oswg728oswg152_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">英伟达发布公告截图来源：英伟达官网</p><p>从禁售到不受影响，价格也就暴涨暴跌，疯狂囤货的黄牛被双手暴击，但事情一直在动态翻转。</p><p>日前，又有消息称，多家英伟达合作显卡品牌确认RTX 4090系列将于11月17日之后在中国大陆全面禁售。尽管真实性无从考证，4090似乎有着自己的“真香定律”。</p><p>从A100、H100、A800，再到H800、 L40S......历史宛若一个轮回，套住了深扎其中的玩家，不论是身为制造商的台积电、联电，还是像英伟达、AMD等人工智能计算公司，更不必说华为、寒武纪、摩尔线程、壁仞等诸多被禁令“点名高挂”的中国大陆企业，都随这一场场的风波浮浮沉沉。</p><p><strong>问题症结在哪儿？除了天天讲的禁令，制造端的产能更为关键。</strong></p><p><strong>从根源上看，英伟达有多少货取决于台积电的CoWoS产能</strong>。CoWoS 是台积电的一种“2.5D”封装技术，其中多个有源硅芯片集成在无源硅中介层上，是最流行的 GPU 和 AI 加速器封装技术，英伟达 A100、H100芯片均用台积电CoWoS 先进封装。</p><p>2023年，ChatGPT风靡全球，AI芯片需求应声大涨，这大大超过了英伟达的预估。一位有丰富半导体制造经验的知情人士表示，“原本英伟达 2022年在台积电预订的产能是3万片，今年3月ChatGPT爆火后，又紧急追加了5000片，再后来又追加了1万片，最终在台积电的订单共有4.5万片。”</p><p><strong>4.5万是个什么概念呢？</strong></p><p><strong>2022年，台积电CoWoS年产7万片，今年受ChatGPT爆火的影响，台积电计划将年产能提升到14万片，而这其中单单英伟达一家就已经占据了超三成</strong>。对英伟达来说，台积电出多少就买多少，但同时还有AMD也要出货，谷歌自研的TPU也在翘首盼望，这14万片的产能早就被瓜分了个精光。</p><p>据业内人士介绍，CoWoS 所需中介层因关键制程复杂、高精度设备交期拉长而供不应求，目前产能严重受限，正处在艰难爬坡过程中。这也意味着哪怕是英伟达这样的大客户，想追加更多都是不可能的。</p><p>所以，<strong>现在A100、A800、H100、H800等芯片如此紧缺，问题症结在于台积电CoWoS产能的不足。上述知情人士表示</strong>，这个问题有望在明年第二季度解决，那时产能大量释放，<strong>明年台积电CoWoS有望达到30万片。</strong></p><p>想象一个场景，如果明年产能不再紧缺，在美国、日本、新加坡，这几款芯片要多少有多少，需求饱和，流入中国市场只是时间早晚。现在全球缺货加上中国被限，芯片的价差特别高，但产能跟上后，价差自然会变小，千金囤货的故事终会告一段落。</p><p><strong>那么，产能何时才能跟上？眼下的问题有该怎么解决呢？</strong></p><p>该知情人士认为：“<strong>明年应该是见真章的一年，预计明年下半年ChatGPT的落地场景会明确下来</strong>。”</p><p>届时，H100在训练端的需求可能会到顶，但推理端场景有很多，需求增长无穷无尽。现如今，Meta、Microsoft等国外大厂做训练和推理基本都用H100，部分小厂可能为了性价比选择训练用H100，推理用A100。但其实，推理端并不是非高端芯片不可，今年8月，<strong>英伟达“曲线救国”，给出了绕过CoWoS封装的解决方案——L40S</strong>。</p><p>这是一款专为搭建数据中心设计的 GPU芯片，在具有数十亿参数和多种模态的生成式AI工作负载下，L40S的18176个CUDA核心可提供近5倍于A100的单精度浮点（FP32）性能，相较于A100推理性能提升1.2倍，训练性能提升1.7倍，从而加速复杂计算和数据密集型分析。对于全球而言，在CoWoS封装产能有限， H100供给不足的当下，L40S 可谓一场及时雨，但现在也遭遇了“一纸禁令”。</p><p>禁令的波及不仅体现在先进芯片产品的直接销售上，也体现在先进工艺的制造代工上，寒武纪，摩尔线程、壁仞已经无法在台积电流片，而只能转向大陆晶圆厂。据了解，目前中芯南方厂今年、甚至明年上半年的产能已经排满，相关需求大概明年下半年才能做。</p><p>“GPU现在良率很低，必须要有足够的产能才会去跑GPU，但等到明年下半年中芯南方产能释放，其实一定程度上已经失去了先机。”</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/GD_erks-XLw8w8_SUp2E5Q" rel="noopener noreferrer nofollow" target="_blank">“芯潮IC”（ID:xinchaoIC）</a>，作者：辰壹，编辑：苏扬，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510342442172424</id>
            <title>进博会“溢出效应”，药械企业成最大受益者</title>
            <link>https://www.36kr.com/p/2510342442172424</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510342442172424</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:30:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 进博会, 医疗器械, 创新产品, 首发, 首展, 进博会溢出效应
<br>
<br>
总结: 2023年11月5日，在上海举行的第六届中国国际进口博览会（进博会）医疗器械及医药保健展区展出了许多创新产品，这些产品都是首次在进博会上展示。参展企业希望通过进博会的影响力和溢出效应，加速产品的上市审批和纳入医保的进程。进博会不仅是产品展示的平台，也是推动医疗器械行业发展的重要机会。 </div>
                        <hr>
                    
                    <p>2023年11月5日，在上海举行的第六届中国国际进口博览会（下称“进博会”）开幕。</p><p>据商务部中国国际进口博览局信息，<strong>本届进博会医疗器械及医药保健展区展览面积、参展企业数、500强及行业龙头企业数、企业国别数均超过上一届</strong>，全球十大医疗器械企业、10家世界500强制药企业齐聚。</p><p>医疗器械及医药保健展区一直是进博会“最火爆”的展区之一。《财经·大健康》在进博会现场注意到，各家参展的制药、医疗器械厂商，尽数将自家的创新产品搬上展台，<strong>“首发”“首展”是参展产品的常见关键词，此外“进博会溢出效应”也是参展厂商关注的焦点。</strong></p><p>由于第一天参观与参展人员都需要“首日贴”，第二天是大多数参展企业正式开展的第一天，开幕式、签约仪式、新品发布会等扑面而来，医疗器械及医药保健展区人声鼎沸、川流不息，宛如繁华的市场。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_156f307d59e44e55bea6912cfc616e5b@1743780481_oswg184877oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">第六届进博会现场 摄/孙爱民</p><h2><strong>No.1 进博会不只是产品展出</strong></h2><p>11月5日，国务院总理李强在进博会开幕式上发表了主旨演讲，并分享“进博故事”，其中提到借助先行先试政策，一款新药在进博会首展仅6个月就迅速落地，故事主角便是武田制药的一款产品。</p><p>当天，这家公司的员工纷纷在社交媒体转发这一消息，11月6日武田制药的展台，也成为医药展区最火爆的展台之一。</p><p>2018年，武田作为中等体量的外资药企首次参展。武田制药发布的信息显示：<strong>目前，中国已成为武田全球第三大市场，武田中国跻身跨国药企在华业绩前十。从2020年至今，武田已有10款在进博会上展示过的创新药物和突破性适应症在中国获批上市，7款创新产品被纳入国家医保目录。</strong></p><p>武田制药的“进博故事”，受益于博鳌乐城特许准入、先行先试的政策，以往新药上市动辄需要数年，新政大大缩短了这一时间。</p><p><strong>辉瑞公司也是这一政策的受益者。</strong>2019年举行的第二届进博会上，辉瑞与海南博鳌乐城国际医疗旅游先行区签订了合作协议；2022年，在第五届进博会上，辉瑞中国与博鳌乐城先行区进一步深化合作，内容涵盖海外特药准入、真实世界研究、创新支付等方面。</p><p>据辉瑞中国区肿瘤事业部总经理王怡亲介绍，该公司的一款前列腺癌产品，近期已经通过“先行先试”政策落地博鳌乐城。</p><p>2020年进博会期间，诺华与海南博鳌乐城国际医疗旅游先行区签署创新药引入战略合作备忘录。到2023年10月28日，诺华海南办事处暨诺华真实世界研究中心正式在博鳌成立。据诺华集团（中国）总裁贝德年介绍，已有6款诺华海外创新特药登陆博鳌乐城。</p><p>每届进博会，西门子医疗、罗氏制药、赛诺菲、拜耳、阿斯利康、强生、GE医疗、美敦力、瓦里安等跨国企业皆来参展。这些企业通过进博会展出后，一些产品顺利进入中国市场。</p><p><strong>今年是阿斯利康进入中国的30周年，阿斯利康的工作人员告诉《财经·大健康》，开展前两天，已达成签约逾30场。</strong>进博首日，该公司分别与江苏省、山东省及广东省达成多项合作。同时，阿斯利康宣布加码其在无锡、泰州及青岛生产供应基地投资。</p><p>西门子医疗的一款光子计数CT （产品名，NAEOTOM Alpha），<strong>“借着进博会的东风，于2022年快速获得创新产品审批通道的许可，并于上周正式获得了国家药监局NMPA批准，其获批的速度较传统审批流程缩短了一半时间。”</strong>该公司大中华区副总裁、市场与企业传播部负责人王弢对《财经·大健康》说。NAEOTOM Alpha目前是唯一一款同时获得中国、美国和欧盟药监部门认证的光子计数CT。</p><p>进博会的“签约狂魔”通用电气医疗（GE医疗），此次展出的是新一代Apex量子平台，基于该平台的全新Apex 系列CT产品即将上市。目前，GE医疗正在北京影像设备制造基地筹备Apex量子平台设备产线，预计明年上半年下线产品。</p><p>截至11月6日，GE医疗已达成意向签约和战略合作签约超过70单。GE医疗2022年在进博会现场完成79个签约，2021年为76个，2020年的签约达到150个。</p><p><strong>每年进博会后，医疗器械巨头美敦力总会有展品变成商品进入市场。</strong>2019年，有“全球最小的心脏起搏器”之称的MircaVR在第一届进博会展出后宣布上市；2020年，新一代产品MicraAV在进博会上完成了国内首秀后，在博鳌乐城国际医疗旅游先行区完成多例植入；2022年，MicraAV获得国家药品监督管理局批准；2022年，智能可感知脑起搏器PerceptPC，在2021年进博会展出后，获得国家药监局批准上市。</p><p><strong>借助进博会，从展品到商品、从进口到本土的，还有达芬奇手术机器人。</strong></p><p>2017年，直观医疗和复星医药宣布战略合作，成立直观复星公司，推进达芬奇手术机器人的国产化。<strong>第二年，达芬奇手术机器人首次亮相进博会，自此，成为每届进博会的“明星展品”</strong>，《财经·大健康》注意到，每届进博会，达芬奇手术机器人展品前总是有人排队体验。</p><p>2019年，达芬奇Xi在中国上市，实现了从展品到商品的转变。2023年，国产达芬奇Xi手术机器人通过国家药监局审批，成为本土生产的产品。</p><p><strong>据直观复星发布的信息，截至目前，国内共有360台达芬奇手术机器人落地，平均每16.8秒便有一名医生开展达芬奇手术。</strong></p><p>如王怡亲所言，<strong>“通过在进博会展出之后，一些创新药物的上市审批速度、纳入医保的速度得以加快。”</strong></p><h2><strong>No.2 小型“隐形冠军”也能获益</strong></h2><p>“什么是溢出效应？”第一次参展的加拿大企业可立点（ClickDishes）公司COO何来晨边自言自语，边走向下一波前来参观的展会访客。</p><p><strong>可立点公司的展厅，位于“创新孵化专区”。与医疗器械及医药保健展区里的巨无霸跨国企业不同，来这里参展的企业，多数是小而精的企业。</strong></p><p>在约20分钟内，何来晨已接待了三个参观团。何来晨所在的公司职员不足10人，固定的展位甚至不及一张饭桌大小，与大公司动辄数百平米、甚至上千平米的展厅相比，这是一个小不点。但这家公司在进博会上的人气，不输耗费数百万元参展的大企业。</p><p><strong>让更多的人看到、了解产品，间接促成产品上市、使用，引来更多的投资与合作方、产品得到医保覆盖，便是所谓的进博会溢出效应。</strong>可立点公司的参展产品是一款“瘫痪助行机器人”，进博会官网在“网上展厅”的显著位置，放置了这款产品的信息。而在“创新孵化专区”展区，这款机器人在何来晨和同事的远程操控下，一遍遍在展区“游走”，给源源不断的参观团、购买团展示性能特点。</p><p><strong>今年的创新孵化专区有来自各国的300多个项目参展。从2021年第四届进博会开始，“创新孵化专区”成为了进博会的标配。其目的是为全球小微企业提供在中国展示创意、宣传产品的机会，对接中国的资本市场。</strong></p><p>上海市委党校副研究员邹磊，在观察、研究了多届进博会后发现：“进博会为参展企业提供了极好的测试中国市场需求与潜力的机会，也给参展企业提供完全不同于普通展会的丰富消费场景和多元目标群体，受益的不仅是世界500强企业，还有被誉为‘隐形冠军’的优质中小企业。”</p><p><strong>与大药企、大器械厂商迎来的是一波一波政府考察团不同的是，中小企业展台前，大多是奔着创新产品而来的慕名者，有时现场达成定向投资、下单签约。</strong></p><p><strong>不过，目前进博会上真正意义上的“全球买、全球卖”尚未完全形成。</strong>一名跨国医疗器械厂商负责人告诉《财经·大健康》，公司参加其他医疗器械类专业展会时，往往期待与医院类客户直接交流需求，而在进博会上，企业更注重的是对外展示的形象与创新产品，“不图现场签约，只愿能让更多潜在客户看到”。</p><p>邹磊在其发表的《中国国际进口博览会：溢出效应与长效机制》一文中指出：<strong>与国际一流商业展会相比，目前进博会企业展仍较多借助政府力量和渠道，市场化的招商招展办展机制尚未充分形成。</strong></p><p>邹磊建议，建立市场需求导向的反馈机制，可适当淡化企业展意向成交额数据，而是更加注重交易质量和落地效果；更全面地掌握市场主体对参与进博会的真实考虑和诉求，及时回应企业关切，在降低进口成本、放宽市场准入、优化营商环境等方面实行高水平的制度型开放，并对表现良好的优质参展商给予适当激励。</p><p>（凌馨对本文亦有贡献）</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/bAKRp04GdpUoMFkaQrV4jA" rel="noopener noreferrer nofollow" target="_blank">“财经大健康”（ID:CaijingHealth）</a>，作者：孙爱民，编辑：王小，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510485770600713</id>
            <title>ChatGPT全线大崩溃，奥特曼亲自致歉：流量远超预期</title>
            <link>https://www.36kr.com/p/2510485770600713</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510485770600713</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:25:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, ChatGPT, API, 崩溃
<br>
<br>
总结: OpenAI的ChatGPT和API在全球范围内变得异常火爆，导致系统崩溃，无法正常使用。OpenAI官方发布了罕见的“红牌警告”，CEO奥特曼也亲自致歉。崩溃期间，大量用户遇到错误提示，系统无法正常运行。OpenAI经过调查后找到了问题的原因，并开始修复。 </div>
                        <hr>
                    
                    <p>OpenAI前脚科技春晚炸翻全球，后脚自家院子却没能守住。</p><p>原因无他，就是火爆🔥，太太太太火爆🔥！</p><p>火爆到直接全线崩溃，无论是ChatGPT还是API，压根没法用，堪称史上最大的一次事故💥。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_42eca07e29e74fd08c79e2705bdaa4db@1743780481_oswg153517oswg960oswg747_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从昨天深夜开始，很多小伙伴们跟ChatGPT的对话就变成这样了：</p><p><strong>我</strong>：出什么问题了吗？</p><p><strong>ChatGPT</strong>：嗯……确实出了些问题。</p><p>然后OpenAI官方也在事故报告中亮出了罕见的“红牌警告”：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_1a954dfa867a461490cd115f3e433810@1743780481_oswg44078oswg1080oswg254_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更为罕见的是，这次还连续出了两张：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_8c6479bf9db8470d8a020c1ab2cc2c03@1743780481_oswg89391oswg1080oswg316_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>CEO<strong>奥特曼</strong>也亲自下场致歉：</p><blockquote><p>新功能的热度远远超出了我们的预期。</p><p>我们原本计划是在周一的时候为所有订阅者提供GPTs，但现在仍然无法实现。我们希望这个进度能加快。</p><p>由于负载的原因，短期内可能会出现服务不稳定的情况，对不起。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_e5a4e15c65a4477792e4a717658c9c66@1743780481_oswg176220oswg1080oswg635_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过OpenAI这么一宕机，崩溃的可不只是服务器，还有广大网友和AI创业者们……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_133f29c835454ceb84c0752d22665252@1743780481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>ChatGPT全线崩溃近俩小时</strong></h2><p>根据监控网站Down Detector收到的事故报告来看，大约在<strong>北京时间昨晚21点35分</strong>，情况就开始出现，网站突然就收到1353份错误报告。</p><p>仅仅半小时后，这个数字就飙升到最高点：<strong>6773份</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f4b389d8d9294359b8e83a5809f48ba5@1743780481_oswg72633oswg1080oswg445_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>换算一下时间，崩溃发生之时，OpenAI那边大约在凌晨5点半左右。</p><p>大约快半小时后，OpenAI开始火速调查问题。</p><p>此时的OpenAI程序员be like：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a3edcf68f7474adaaf5a5bfc2983b53f@1743780481_oswg36361oswg252oswg200_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>过了1个小时，官方终于更新事故报告，称定位到<strong>API和ChatGPT的错误率都很高</strong>。</p><p>此时，Down Detector那边收到的错误报告仍可以说是“居高不下”，还有5607份。</p><p>不少用户都抱怨他们收到了<strong>“ChatGPT is at capacity right now”</strong>（ChatGPT目前已满载）的错误。</p><p>好在“十万火急”，官方在定位到问题之后更快就找到了原因，并开始努力修复。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a745d481767d4624aa38f0c84951aef4@1743780481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大约40多分钟后，OpenAI终于宣告服务已恢复。</p><p>此时大概是那边的早上7点半，北京时间晚上11点半。</p><p>算下来，崩溃一共持续了近俩小时。</p><p>从事故报告来看，OpenAI将此次事件也再次定性为了<strong>“重大宕机”</strong>（Major Outage）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9083ce8ff9e04414be9cb217c67b554b@1743780481_oswg323743oswg1080oswg1149_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>之所以措辞“也”，是因为在<strong>今年3月份和8月份已发生过类似事故</strong>，宕机时间分别为12小时、3小时。</p><p>不过，原因有所不同，就像3月份那次是因为数据库迁移失败造成。这次，显然跟ChatGPT本周的“春晚”脱不了干系。</p><p>北京时间本周二凌晨的开发者大会一开，全新的<strong>GPT-4 Turbo、自定义GPT以及GPT商店</strong>就全跟着上线。</p><p>GPT-4 Turbo直接支持128k上下文，相当于一次能读300页书籍，知识库更新到今年4月。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_70656b9804ef43218e492bbc20a0f7f5@1743780481_oswg216632oswg1028oswg1068_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>自定义GPT功能可以让人3分钟不到、编程也不用，就get一个专属技能的GPT，还能把它上线商店卖钱，可谓人人都是开发者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_7fc5694f62d14664b00c241f818e8305@1743780481_oswg48481oswg900oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，还有稍早一点的产品逻辑变更，用户终于不再需要手动选择联网、DALL·E 3等模式，全部“All in one tool”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d88d238d7625422abd76a1058e26a4f6@1743780481_oswg46294oswg679oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如此一系列炸裂又强大的更新，让网友无比兴奋，推送一上线，一下子就挤满了来尝鲜的人们。</p><p>然而，根据奥特曼在开发者大会上透露，ChatGPT目前<strong>每周用户数量已达到一个亿</strong>，还有200万开发人员使用其API服务（其中超92%来自财富500强公司），俨然早就是“流量王者”。</p><p>面对一波暴增的新流量，尽管OpenAI肯定有准备，但还是一个没遭住。</p><p>有网友反应新功能有多么不稳定，有人甚至抱怨怎么还没收到更新。</p><p>而在迎来这次全线大崩溃之前，OpenAI其实已经<strong>在周二就出现了大约1小时的“部分停机”</strong>。</p><p>侧面反应ChatGPT实火，OpenAI面临的算力和服务器稳定性也充满了挑战。</p><h2><strong>网友集体在线崩溃</strong></h2><p>正如我们刚才提到的，OpenAI短短数小时的崩溃，更是让部分用户们的心态崩了。</p><p>网友们很形象地找出了一个段子来形容这种名场面——AI创业公司老板：</p><blockquote><p>喂？是OpenAI吗？你们宕机了，所以我们也没法工作了！</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2d0130c2f17f44d5a3a5508e788f9b43@1743780481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>老板继续咆哮道：</p><blockquote><p>整个公司都没法运转了，你们这帮家伙好像漠不关心！</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_8c9433b6259746ce8635517230861ccc@1743780481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然这只是个段子，但在OpenAI全线崩溃的数小时里，也有不少网友道出了自己内心真实的声音。</p><p>例如有表示<strong>“没法工作了”</strong>的，甚至在抱怨：</p><blockquote><p>得~我现在得手敲邮件了😭。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_046b2949743942dfa20b4b3aa828fd22@1743780481_oswg65723oswg944oswg424_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过这也让一部分人感到开心，终于可以摸鱼了：</p><blockquote><p>大停电！！！</p><p>是时候放松一下去看Netflix了😄。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_29ceea5f0b664dcf9defc96a74cd9513@1743780481_oswg209649oswg1080oswg773_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有更绝了——谷歌Bard莫名躺枪，成了备胎。</p><blockquote><p>因为ChatGPT宕机，我第一次使用谷歌Bard。</p><p>老实说，还挺好用的，就是语气跟ChatGPT不太一样，有点难以理解。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_bb0002756df74385ba20449313bc529b@1743780481_oswg49370oswg968oswg220_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Bard要是看到这位网友的话，估计都得跳出来说一句“你礼貌吗”。</p><p>……</p><p>虽然这次OpenAI的全线崩溃，引发了网友们不少精彩且drama的桥段。</p><p>不过这也从侧面反映出了现在ChatGPT对人们日常工作、生活影响之深。</p><p>而正如奥特曼所说，新GPTs的功能即将全面开放，届时OpenAI能否顶住这泼天的流量，以及更多用户们又将带来怎么样的创意价值，着实是有点期待了。</p><h2><strong>Two More Things</strong></h2><p>在这次OpenAI宕机风波之余，还有两件小插曲值得说道说道。</p><p>首先就是有人发现，不仅是ChatGPT崩溃了，就连Claude也崩了（就很迷）……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_39c74d1e9cf84d388201501386480f04@1743780481_oswg142420oswg1080oswg760_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其次就是手机版ChatGPT，现在又有重磅更新！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_3aa045d4f8854dd78675bfb309f23ce0@1743780481_oswg101464oswg830oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>手机上的APP也可以无需切换模式，就能浏览网页、分析数据，以及生成图片了🎉。</p><h3>参考链接</h3><p>[1]https://status.openai.com/incidents/00fpy0yxrx1q</p><p>[2]https://twitter.com/sama/status/1722315204242149788[3]https://news.ycombinator.com/item?id=38190401</p><p>[4]https://www.reddit.com/r/ChatGPT/comments/17qmdz9/yes_chatgpt_is_down_calm_down/</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/tmWjyvsEUBekMBSiuH12Jg" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：金磊 丰色，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510359381196806</id>
            <title>电池行业或迎“大革命”？新设计将颠覆固态电池，性能更优还更便宜</title>
            <link>https://www.36kr.com/p/2510359381196806</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510359381196806</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:24:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 韩国科学家, 固态电池, 锂金属氯化物, 氯基固体电解质
<br>
<br>
总结: 韩国科学家在固态电池领域取得重大突破，创造了一种基于锆的锂金属氯化物固态电池，比使用稀土金属的电池更便宜。这项研究揭示了金属离子分布在氯基固体电解质离子电导率中的重要作用，有望推动固态电池的商业化，提高储能的可负担性和安全性。 </div>
                        <hr>
                    
                    <blockquote><p>韩国科学家在下一代固态电池领域取得了重大突破；他们创造了一种基于锆的锂金属氯化物固态电池；这种电池比使用稀土金属的电池便宜得多。</p></blockquote><p>韩国基础科学研究所（IBS）纳米粒子研究中心KANG Kisuk教授领导的研究小组宣布，他们在下一代固态电池领域取得了重大突破。他们相信，新发现将使基于新型氯基固体电解质的电池成为可能，这种电解质具有优异的离子导电性。</p><p>目前商用电池对液体电解质的依赖是一个迫切的问题，这导致了易燃性和爆炸风险。因此，开发不可燃固体电解质对于推进固态电池技术至关重要。在全球向可持续交通转变的过程中，随着世界各国加紧对内燃机汽车的监管，并扩大电动汽车的使用，这类问题愈发紧迫。</p><p>为了使固态电池在日常使用中实用，开发具有高离子电导率、强大的化学和电化学稳定性以及机械灵活性的材料至关重要。虽然以前的研究成功地研发了硫化物和氧化物基固体电解质，它们具有高离子电导率，但这些材料并不能完全满足所有基本要求。</p><p>过去，科学家们还探索了基于氯化物的固体电解质，以其优越的离子电导率，机械灵活性和高压稳定性而闻名。这些特性使一些人推测，氯基电池是固态电池最有可能的候选者。然而，这些希望很快就破灭了，因为氯化物电池被认为是不切实际的，因为它们严重依赖昂贵的稀土金属，作为电池的原材料之一。</p><p>为了解决这些问题，IBS研究小组研究了氯电解质中金属离子的分布。他们认为，三氯化物电解质的离子电导率之所以过低，是因为其结构内金属离子排列的变化。</p><p>他们首先在氯化锂钇（一种常见的氯化锂金属化合物）上测试了这一理论。当金属离子靠近锂离子的路径时，静电力会阻碍它们的运动。相反，如果金属离子占比过低，锂离子的路径就会变得太窄，阻碍它们的迁移。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_236eb84cbd7e4d14863b62780cb4b469@1743780481_oswg348793oswg1067oswg658_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在这些见解的基础上，研究团队引入了电解质的全新设计策略，以减轻这些冲突因素，最终开发出了具有高离子电导率的固体电解质。他们创造了一种基于锆的锂金属氯化物固态电池，这种电池比使用稀土金属的电池便宜得多。这是第一次证明金属离子排列对材料离子电导率的重要性。</p><p>最新研究结果已于近期发表在了《科学》杂志上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_c2464a0723c64eed9a3ef8dde5f409d1@1743780481_oswg323314oswg1080oswg484_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这项研究揭示了金属离子分布在氯基固体电解质离子电导率中经常被忽视的作用。科学家们预计，新研究将为各种氯基固体电解质的发展铺平道路，并进一步推动固态电池的商业化，有望提高储能的可负担性和安全性。</p><p>该研究论文通讯作者KANG Kisuk表示：“这种新发现的氯化物基固体电解质有望超越传统硫化物和氧化物基固体电解质的局限性，使我们更接近固态电池的广泛采用。”</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/kyyUW5BErV3Yz8_nrSwiBQ" rel="noopener noreferrer nofollow" target="_blank">“新能源日报”（ID:gh_d2bf0d2b5407）</a>，作者：黄君芝，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510349859242240</id>
            <title>2028年第一个AGI将到来？谷歌DeepMind提6条AGI标准，定义5大AGI等级</title>
            <link>https://www.36kr.com/p/2510349859242240</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510349859242240</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:24:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepMind, AGI, LLM, 时间表
<br>
<br>
总结: DeepMind的研究团队发表了一篇关于AGI时间表的论文，提出了AGI的定义标准和分类，认为LLM已经是AGI的雏形，预测人类有50%的概率在2028年开发出第一个AGI。 </div>
                        <hr>
                    
                    <blockquote><p>DeepMind创始人Shane Legg带领的研究团队发表了一篇关于AGI时间表的论文。他指出，LLM已经是AGI雏形，提出了6条定义AGI的标准。而且根据AI能力，他们提出了5个AGI的分类，以及对于AGI风险的评估体系。</p></blockquote><p>人类距离第一个AGI的出现已经越来越近了！</p><p>DeepMind联合创始人，首席AGI科学家Shane Legg在不久前的访谈中认为，2028年，人类有50%的概率开发出第一个AGI。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b27e9fce7fbd4c0bb4cc958a45331531@1743780481_oswg594406oswg1080oswg621_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而就在今天，他带领的DeepMind研究团队在Arxiv上公布了一篇论文，直接放出了AGI的路线图和时间表。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d823f6b3c926488aa862507b8a94ced5@1743780481_oswg35385oswg240oswg240_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d11663fc29c14920a25e08df51fbb983@1743780481_oswg106778oswg1080oswg368_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://arxiv.org/abs/2311.02462</p><p>虽然论文主题感觉很大很空，但是网友认为文章很好的定义了AGI，避免了以后各种鸡同鸭讲的讨论。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d46802e507d34983aad451da9cc2a8bc@1743780481_oswg92213oswg1080oswg200_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>研究团队认为，从性能强度和通用性两个维度，可以将人类和AI的关系划分为5个阶段，而现在大语言模型的出现，正属于第一个通用AI的阶段：AGI雏形。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d1dc7fd335594aabb672406801ef4a8f@1743780481_oswg576905oswg1080oswg1238_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以OpenAI的ChatGPT，谷歌Bard，Meta的Llama为代表的大模型，已经在通用性上展示出了AGI的潜力。</p><p>因为大语言模型已经能完成范围相当广的各类任务，而且表现出了像学习新技能这样的「元认知」能力。</p><p>而如果单从AI的性能维度上看，「窄AI（Narrow AI）」类型的AI已经达到了完全超越人类认知的水平。</p><p>以AlphaFold，AlphaZero为代表的专业领域AI，在特定领域已经能发现人类智力无法发现的新事物了。研究团队将其称为「超人类窄AI」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f0f263906fa948659abc0f2dd75b446d@1743780481_oswg362729oswg1080oswg651_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而和人类相比，在某个领域达到99%的人类的水平，比如在棋类竞技中能够战胜人类顶尖大师的「深蓝」和AlphaGo，就属于这一类。研究团队将它们称为「大师级窄AI」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_52d04229e4e2413db870e39e8309b588@1743780481_oswg625386oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在某些领域，AI能达到90%的人类水平，比如文书纠正AI Grammarly，DALL·E 2，Imagen等生图AI。研究团队将其称为「专家级窄AI」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_1989414d4092491ea4df2f100a17c814@1743780481_oswg1207725oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在特定领域，能达到普通人的平均水平，比如Siri，谷歌助手这类普通智能助理。研究团队将其称为「普通窄AI」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_09cd5a7952a3486ba2ea7ae1b2512c46@1743780481_oswg401598oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在这四个窄AI已经覆盖的能力维度上，通用AI都还没有出现对应的实例。</p><p>而进一步，因为目前还没有出现真正意义上的AGI，对于AGI的定义，人类还没有达到统一的认知。</p><p>所以论文中还提供了定义AGI的6个准则：</p><blockquote><ol><li>关注能力而非过程。AGI定义应该关注一个系统能达到的效果，而不是实现这些效果的内在机制。</li><li>关注通用性和性能。AGI定义应同时考量通用性和性能这两个维度。</li><li>关注认知和元认知任务。AGI的定义应关注认知任务，以及元认知能力如学习新技能。不需要作为前提要求。</li><li>关注潜能而非部署。理论上证明系统能完成某类任务就可认为它具备AGI潜能，不需要一定要实际部署。</li><li>关注真实场景。用于AGI测评的任务应考虑真实场景的适用性，而不仅是容易量化的指标。</li><li>关注通向AGI的路径，而非单一目标。AGI定义应采用分级方式，考虑不同水平的路径，而不仅是最终目标。</li></ol></blockquote><p>在论文的最后一个部分，作者还提出了对于未来可能出现的AGI的测评与风险评估问题。</p><p>在作者看来，需要考虑人类与AGI的互动模式，仅看模型能力来评估AGI是非常片面的。</p><p>具体来说，AGI的能力不同于AGI的自主性。随着AGI能力的增强，会解锁更高级的人机互动模式，但不意味着就必须给予AGI最大的自主性。</p><p>在这个技术之上，作者提出了6种人机互动模式：无AI、AI工具、AI顾问、AI协作者、AI专家、AI智能体。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d85bd8a69cc34874944b308e7744cb15@1743780481_oswg299112oswg1080oswg1541_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不同的人机互动模式需要不同的AGI能力作为前提，比如AI智能体可能需要AI能力达到专家或者超人类AI级别，才能更好地完成这个互动模式处理的任务。</p><p>人机互动模式本身会引入不同类型的风险。例如AI智能体具有最高的自主性，但同时也引入了最大风险。</p><p>因此，AGI的风险评估需要同时考虑模型能力和人机互动模式。合理的互动模式选择有助于AGI系统的负责任部署。</p><p>人机互动研究需要与模型能力提升保持同步，以支持对AGI系统的安全且有效的利用。</p><h2><strong>AGI，黎明还是黄昏？</strong></h2><p>从1955年达特茅 斯人工智能会议开始 ，人类就朝着实现「真正的智能」这颗北极星曲折前进，途中也经过了不同的道路。</p><p>AGI的概念与对人工智能进步的预测有关，它正在朝着更大的普遍性发展，接近并超越人类的普遍性。</p><p>此外，AGI通常与「涌现」一词交织在一起，有能力实现开发人员未明确预期的功能。这种能力使新型互动或新行业成为可能。</p><p>AGI可能产生重大的经济影响——我们是否达到了广泛劳动力替代的必要标准？</p><p>AGI还可能带来与经济优势有关的地缘政治以及军事上的影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f2c1c7b14aef44cf9875f29aebbfe716@1743780481_oswg916928oswg1000oswg538_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同样，我们也应该通过评估AGI的水平来预防她带来的风险。</p><p>正如一些人推测的那样，AGI系统可能能够欺骗和操纵、积累资源、推进目标、代理行为，并递归地自我改进，最终在广泛的领域中取代人类。</p><p>所以，对于人工智能研究界来说，明确反思我们所说的「AGI」的含义，并量化人工智能系统的性能、通用性和自主性等属性至关重要。</p><p>我们必须理解自己在AGI道路上所处的位置。</p><h2><strong>AGI案例分析</strong></h2><p>首 先，我们应当考虑如何正确定义AGI，也许可以从一些案例中获得启发。</p><p>案例1：图灵测试。1950年的图灵测试可能是将类似AGI的概念付诸实践的最知名的尝试。图灵的「模仿游戏」被认为是一种将机器是否可以思考的问题操作化的方法。</p><p>鉴于现代LLM通过了图灵测试的一些框架，很明显，这个标准不足以作为评估AGI的基准。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0c974c991a304640b02effa02a7298fb@1743780481_oswg187575oswg915oswg549_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>我们同意图灵的观点，机器是否可以「思考」确实是一个有趣的哲学和科学问题，</p><p>但机器能做什么的问题显然对于评估影响更重要，也更易于衡量。因此，AGI应该根据能力而不是过程来定义。</p><p>案例2：与人脑的类比。「通用人工智能」一词的最初使用是在1997年马克·古布鲁德撰写的一篇关于军事技术的文章中，该文章将AGI定义为「在复杂性和速度上与人脑相媲美或超过人脑的人工智能系统」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_dd7b2c63738d4868b85d4612dd9c71e6@1743780481_oswg410440oswg1080oswg552_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然现代ML系统背后的神经网络架构松散地受到人脑的启发，但基于transformer的架构的成功表明，严格的基于大脑的过程和基准对于AGI来说并不是必要的。</p><p>案例3：学习任务的能力。在《技术奇点》中，沙纳汉认为，AGI是「人工智能」，它不是专门用于执行特定任务的，而是可以学习执行与人类一样广泛的任务。该框架的一个重要特性是它强调将元认知任务（学习）纳入实现AGI的要求中的价值。</p><p>案例4：具有经济价值的工作。OpenAI的章程将AGI定义为「高度自主的系统，在最具经济价值的工作中表现优于人类」。</p><p>这个定义侧重于与底层机制无关的性能，并且提供了潜在的衡量标准，即经济价值。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_40e9c0de79204f3cb4cc9026becf52a7@1743780481_oswg514114oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但问题在于，有许多与智力相关的任务可能没有明确的经济价值（例如，艺术创造力或情商）。</p><p>而且，我们很可能拥有在技术上能够执行经济上重要任务的系统，但由于各种原因（法律、道德、社会等）而没有意识到这种经济价值。</p><p>案例5：马库斯认为AGI是「任何智能的简写，具有与（或超越）人类智能相当的足智多谋和可靠性」。</p><p>他通过提出五项具体任务（理解一部电影、理解一本小说、在任意厨房做饭、编写一个无错误的10000行程序以及将自然语言数学证明转换为符号形式）来实施他的定义。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_20160c43b01845db8dfd54810a9be772@1743780481_oswg521951oswg1080oswg675_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>案例6：Agüera y Arcas和Norvig认为最先进的LLM已经是AGI，而通用性是AGI的关键属性。</p><p>由于语言模型可以讨论广泛的主题、执行广泛的任务、处理多模态输入和输出， 以多种语言操作，并从零样本或少样本示例中「学习」，它们已经达到了足够的通用性。</p><h2><strong>AGI六大准则</strong></h2><p>通过对以上几个案例的思考，作者为AGI的定义制定了以下六个标准：</p><p>第一条：关注能力，而不是流程。大多数定义关注的是AGI可以完成什么，而不是它完成任务的机制。</p><p>这对于识别不一定是实现AGI的先决条件的特征非常重要。</p><p>因为，实现AGI并不意味着系统以类似人类的方式思考或理解；也并不意味着系统具有意识或感知等。</p><p>第二条：注重通用性和性能。上述所有定义都在不同程度上强调普遍性，另外，性能也是AGI的关键组成部分。</p><p>第三条：专注于认知和元认知任务。</p><p>人工智能系统的物理能力似乎落后于非物理能力。作者认为，执行物理任务的能力增加了系统的通用性，但不应被视为实现AGI的必要先决条件。</p><p>另一方面，元认知能力（例如学习新任务的能力或知道何时向人类寻求澄清或帮助的能力）是系统实现通用性的关键先决条件。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_64f482ad1b2c48489694c44588986dc9@1743780481_oswg1003516oswg1080oswg1130_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第四条：关注潜力，而不是部署。因为要求部署作为衡量AGI的条件会带来非技术障碍，例如法律和社会考虑，以及潜在的道德和安全问题。</p><p>第五条：注重生态效度。这里强调选择与人们重视的现实世界（即生态有效）任务相一致的任务的重要性（广义地解释价值，不仅作为经济价值，还包括社会价值、艺术价值等）。</p><p>最后一条：专注于AGI的路径，而不是单个端点。作者将AGI的每个级别与一组明确的指标相关联，并且每个级别引入已识别风险，以及由此产生的人机交互范式的变化。</p><h2><strong>AGI水平定义</strong></h2><p>作者给出如下表格，清晰地提出了一种分类或者说评估方法，规定了达到给定评级所需的大多数任务的最低性能。</p><p>为便于理解，这里将下表中的后五类翻译为：入门、普通、专家、大师和超人级别。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ab79131d315b47bf9e1c19c70679bc7d@1743780481_oswg600056oswg1080oswg1141_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如，在大多数认知任务中，有能力的AGI必须至少达到熟练成年人的平均水平，但在任务子集上可能具有专家、大师甚至超人的表现。</p><p>举个例子，截至2023年9月撰写本文时，前沿语言模型（例如，ChatGPT、Bard、Llama2等）在某些任务（例如，短文写作、简单编码）中表现出「普通」的性能水平，但对于大多数任务（例如， 数学能力，涉及事实性的任务）来说，仅表现出「入门」的性能水平。</p><p>因此，总体而言，当前的前沿语言模型将被视为1级通用AI，当更广泛的任务的性能水平提高时，就可以达到2级通用AI的门槛。</p><p>另外需要注意的是，在特定认知领域获得更强技能的顺序可能会对人工智能安全产生严重影响。</p><p>例如，在获得强大的道德推理技能之前获得强大的化学工程知识可能是一个危险的组合。</p><p>虽然该分类法根据系统的性能对系统进行评级，但能够达到一定性能水平的系统在部署时可能不匹配此级别。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_51a16c4291644644b447056edd357947@1743780481_oswg395628oswg1080oswg430_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以DALL·E 2为例，因为DALL·E 2产生的图像质量比大多数人能够绘制的更好，所以可以评估为「专家」级别的性能。然而该系统存在故障模式，使其无法获得「大师」的称号。所以可以将其估计为分类法中的3级窄AI（「专家级窄AI」）。</p><p>在上面的表格中，作者引入了一个矩阵式调平系统，该系统侧重于性能和通用性，这是AGI的两个核心维度。</p><p>就综合性能和通用性而言，矩阵中的最高级别是ASI（人工超级智能）。而「超人」的表现意味着100% 优于人类。</p><p>例如，这里假设AlphaFold是5级窄AI （「超人级窄AI」），因为它执行的单项任务（从氨基酸序列预测蛋白质的3D结构）高于世界顶级科学家的水平。</p><p>该定义意味着5级通用AI （ASI） 系统将能够以人类无法比拟的水平完成广泛的任务。</p><h2><strong>AGI测试</strong></h2><p>在作者的方案中，人工智能系统必须掌握多大比例的此类任务才能达到给定的通用性水平？是否有一些任务（如元认知任务）必须始终执行才能达到某些通用性级别的标准？</p><p>要实现AGI定义的可操作性，就必须回答这些问题，并开发出具体的多样化和具有挑战性的任务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_36172181da0b47dabd9d6079c8dad945@1743780481_oswg183502oswg770oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>鉴于这一过程的巨大复杂性，以及纳入广泛视角（包括跨组织和多学科观点）的重要性，作者在本文中并未提出一个基准。</p><p>相反，作者致力于澄清基准应尝试衡量的本体。作者还讨论了AGI基准应具备的属性。</p><p>AGI基准将包括一套广泛的认知和元认知任务（根据原则3），测量包括（但不限于）语言智能、数学和逻辑推理、空间推理、人际和人内社交智能、学习新技能的能力和创造力在内的各种特性。</p><p>基准可能包括心理学、神经科学、认知科学和教育学中的智能理论所提出的心理测量类别测试。</p><p>但是，必须首先评估这些 「传统 」测试是否适合用于计算系统基准测试，因为在这种情况下，许多测试可能缺乏生态和构造有效性。</p><p>基准性能的一个未决问题是，是否允许使用工具（包括可能由人工智能驱动的工具）作为人类性能的辅助工具。</p><p>这一选择最终可能取决于任务，并应在基准选择中考虑生态有效性（原则5）。</p><p>例如，在确定自动驾驶汽车是否足够安全时，与一个没有任何现代人工智能辅助安全工具的人进行比较，并不是最有参考价值的比较。</p><p>因为相关的反事实涉及到一些驾驶辅助技术，作者可能更倾向于与该基线进行比较。</p><p>或交互式任务，这些任务可能需要定性评估。作者猜测，后几类复杂的开放式任务虽然难以确定基准，但其生态有效性将优于传统的人工智能指标，或优于经过调整的传统人类智能指标。</p><p>AGI所能完成的全部任务是不可能一一列举的。因此，人工智能基准应该是一个活的基准。因此，这种基准应包括一个生成和确定新任务的框架。</p><p>要确定某物在特定水平上不是一个AGI，只需找出人们通常可以完成但系统无法充分执行的5项任务即可。</p><p>在特定性能级别（「雏形」、「普通」等）上通过大部分设想的AGI基准测试的系统，包括测试人员添加的新任务，可以被假定为具有相关的通用性级别（即，尽管在理论上AGI仍有可能无法通过测试，但在某些时候，未通过测试的情况会变得非常专业或非典型，以至于实际上无关紧要）。</p><p>制定AGI基准将是一个具有挑战性的迭代过程。尽管如此，它仍是人工智能研究领域的一个北斗星级别的目标。</p><p>对复杂概念的衡量可能并不完美，但衡量的行为有助于我们清晰地定义目标，并提供一个衡量进展的指标。</p><h2><strong>关于AGI风险的讨论</strong></h2><p>关于人工智能的讨论通常包括对风险的讨论。</p><p>采用分层的方法来定义人工智能，可以更细致地讨论性能和通用性的不同组合如何与不同类型的人工智能风险相关联。</p><p>当我们沿着人工智能的能力水平前进时，会引入新的风险，包括误用风险、调整风险和结构风险。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b772c6d150164b4e989c1fec15d882f4@1743780481_oswg234632oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>例如，「专家级人工智能 」水平很可能涉及与经济混乱和工作岗位转移相关的结构性风险，因为越来越多的行业达到了机器智能替代人类劳动力的门槛。另一方面，达到 「专家级AGI 」可能会减轻 「AGI雏形 」和 「普通级AGI 」带来的一些风险，如任务执行错误的风险。</p><p>在 「大师级人工智能 」和 「专家级人工智能」级别中，最有可能出现许多与x风险有关的问题（例如，人工智能可以在各种任务中超越人类操作员，但可能会欺骗人类操作员以实现错误的目标，如错误对齐思想实验）。</p><p>如果不同级别之间的进展速度超过了监管或外交的速度（例如，第一个实现人工智能的国家可能会拥有巨大的地缘政治/军事优势，从而产生复杂的结构性风险），那么国际关系不稳定等系统性风险可能会成为一个令人担忧的问题。</p><p>「专家型人工智能」（如 「新兴人工智能」、「胜任型人工智能 」和所有 「狭义 」人工智能类别），风险可能更多来自人类行为（如人工智能误用风险，无论是意外、偶然还是恶意）。</p><p>对与每个级别相关的风险概况进行更全面的分析，是制定AGI分类法的关键一步，可以为安全/伦理研究和政策制定提供指导。</p><h3><strong>能力和自主性</strong></h3><p>虽然能力为人工智能风险提供了先决条件，但人工智能系统（包括AGI系统）不会也不会在真空中运行。</p><p>相反，人工智能系统是与特定界面一起部署的，用于在特定场景中完成特定任务。</p><p>这些背景属性（界面、任务、场景、最终用户）对风险状况有重大影响。AGI能力本身并不能决定风险方面的命运，而必须与背景细节结合起来考虑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d9d39d879750443aa35abb0910b6328b@1743780481_oswg1020234oswg1024oswg684_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>例如，考虑AGI系统用户界面的承受能力。能力的不断提高会释放出新的交互范式，但并不能决定这些范式。</p><p>相反，系统设计者和终端用户将确定一种人与人工智能的交互模式，这种模式将平衡包括安全性在内的各种考虑因素。作者建议用表2中描述的六个自主水平来描述人机交互范式。</p><p>这些自主水平与AGI水平相关。更高水平的自主性可通过AGI能力的提升而 「解锁」。</p><p>围绕人与人工智能的互动做出深思熟虑的选择，对于安全、负责任地部署前沿人工智能模型至关重要。</p><p>要使特定的交互范式变得理想，可能需要某些方面的通用性。</p><p>例如，只有当人工智能系统在某些元认知能力（学会何时向人类寻求帮助、心智理论建模、社会情感技能）方面也表现出很强的性能时，自主性等级3、4和5（「合作者」、「专家 」和 「智能体」）才可能发挥良好的作用。</p><p>作者对第五级自主性（「作为智能体的人工智能」）的定义中隐含的意思是，这种完全自主的人工智能可以在没有人类持续监督的情况下以一致的方式行动，但也知道何时向人类咨询。</p><p>通过更好的任务规范、弥合流程鸿沟和产出评估来支持人类与人工智能协调的界面，是确保人机交互领域跟上与人工智能系统互动的挑战和机遇的重要研究领域。</p><h3><strong>作为风险评估框架的人机交互范式</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_160376b193ff4ac9b82d5f173fc6e103@1743780481_oswg299112oswg1080oswg1541_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上表2说明了AGI级别、自主级别和风险之间的相互作用。</p><p>模型性能和通用性的进步提供了更多的交互范式选择（包括潜在的完全自主的人工智能）。</p><p>这些交互范式反过来又引入了新的风险类别。</p><p>与单独考虑模型能力相比，模型能力和交互设计的相互作用将使风险评估和负责任的部署决策更加细致入微。</p><p>表2还提供了作者提出的六个自主级别中每个级别的具体示例。</p><p>对于每个自主水平，作者都指出了 「解锁 」该交互范式的相应性能和通用性水平（即该范式有可能或有可能成功部署和采用的AGI水平）。</p><p>作者对 「解锁 」水平的预测往往要求狭义人工智能系统的性能水平高于通用人工智能系统。</p><p>例如，作者认为，无论是专家级狭义人工智能还是新兴人工智能，都有可能将人工智能用作顾问。</p><p>这种差异反映了这样一个事实，即对于通用系统来说，能力发展很可能是不均衡的。</p><p>例如，一级通用人工智能（「AGI雏形」）很可能在某些子任务集上达到二级甚至三级性能。</p><p>通用人工智能能力的这种不均衡性可能会使其在执行与其特定优势相符的特定任务时获得更高的自主水平。</p><p>在人类使用的背景下考虑 AGI 系统，可以让我们思考模型的进步与人类-AI 交互范式的进步之间的相互作用。</p><p>模型的进步与人与人工智能交互范式的进步之间的相互作用。模型研究的作用可以看作是帮助系统的能力沿着通往AGI的道路不断进步，提高其性能和通用性。</p><p>这样，人工智能系统的能力将与人类能力的重叠部分越来越大。相反，人与人工智能交互研究的作用可以被视为确保新的人工智能系统能够为人类所用并对人类有用，从而使人工智能系统成功地扩展人类的能力。</p><h3>参考资料</h3><p>https://huggingface./papers/2311.02462</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/MUKcHWIFydMrzirlKPNfXQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：润 alan，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510377429328001</id>
            <title>扒一扒，双十一商家的环保套路</title>
            <link>https://www.36kr.com/p/2510377429328001</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510377429328001</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:23:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 双十一, 环保, 坑爹产品, 假环保
<br>
<br>
总结: 双十一消费中，许多商家滥用“环保”概念，推出号称环保绿色的产品，但实际上却是坑爹产品。商家通过使用方便、安全、绿色等特点来标榜产品的环保性，甚至将一次性用品包装成“精致生活”的代名词。然而，这些所谓的环保产品往往使用的材料并非真正环保，而且一次性消费模式更加不环保。此外，一些商家还通过添加水溶性物质、生物质成分等伪环保宣传来欺骗消费者。在面临庞大的垃圾处理问题时，这些所谓的环保产品只是任性消费的“安慰剂”。 </div>
                        <hr>
                    
                    <p>又是一年双十一大作战，也许你正在为不知道该不该付的定金、算不明白的折扣、理不清的优惠规则而头疼。</p><p>作为一个崇尚可持续生活的环保人er，双十一消费中又会遇到哪些号称环保绿色的坑爹产品呢？今天我们就一起来扒一扒，那些年电商商家的环保套路。</p><p>看看哪些“假环保”是智商税，哪些甚至花钱起到反效果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d738ff55e2c045758b6f5f0af5e402c9@5919991_oswg420169oswg660oswg660_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>环保套路一：滥用“环保”概念</strong></h2><blockquote><p><strong>套路等级：★☆☆</strong></p></blockquote><p>越来越多消费者注意到许多电商产品身上的“环保”属性，如果能在便利消费的同时，顺手选用对环境友好的环保产品，为保护地球出一份力，岂不是两全其美的事？</p><p>于是，在购物网站搜索几次“环保”、“可持续”“绿色低碳”等关键词，大数据便投你所好开始作法，让人一眼看上去很有“环保产品泛滥”的错觉。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_77b66606e88e4a828201e51f1014e3f8@5919991_oswg38562oswg690oswg690_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然鹅，但凡多看一眼，你也许很难忍住不骂一句：“这也能跟环保沾边吗？”</p><p>在某些商家眼中，环保概念是块砖，哪里需要哪里搬。</p><p>方便是“环保”，安全是“环保”，绿色（特指一种颜色）是"环保"，使用体验好都算“环保”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4c36dbce897d46e290c0435a261c4280@5919991_oswg1576995oswg1002oswg1167_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">一次性便携露营餐具套装，产品只是普通产品，在野外方便使用就“很环保”。套装里使用的其实是聚乙烯（PE）这种传统的不可降解塑料制品。</p><p>最自相矛盾的就是“环保一次性用品”，大家都知道一次性用品给环境带来垃圾处理负担，制造大量垃圾。但耐不住它们真的很方便，召之即来用完即弃，为辛勤劳作的打工社畜增降低了家务时间成本，近来甚至被一些电商直播包装成了“精致生活”的代名词。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_a2317c6975de4f9d93daf708e856371a@5919991_oswg219769oswg440oswg440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>商家看准了这个痛点，把不可降解塑料替换成可降解塑料、纸、无纺布、不锈钢等，总之换一个看上去“环境友好”的材料就可以，是不是更合适或环保很难判断。</p><p>当然，价格会涨不少。</p><p>再叠上用完即弃的一次性消费模式这个buff，<strong>简直不能环保一点儿。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_2545fa90ea8f47edbfad2538c2582d58@5919991_oswg43855oswg664oswg536_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>即使不考虑一次性用品废弃后如何处置的问题，仅生产到使用的过程就需要消耗的材料和能源，人们只是短暂使用就丢弃，很难信服其宣称的环保性。很难不令人怀疑，<strong>环保这个名头，成了任性消费的“安慰剂”</strong>。</p><p>更何况垃圾处理是一个不可绕开的话题，2021年中国的生活垃圾产生量已高达<strong>31,526.8万吨</strong>，大部分通过<strong>填埋、焚烧</strong>进行处置，其中<strong>65.9%</strong>都是焚烧处置[1]。光是北京一个城市，2022年的生活垃圾清运量为740.57万吨，需要依赖34座垃圾处理设施（5座生活垃圾填埋场、12座生活垃圾焚烧厂和17座生化处理设施），才能维系城市正常运行[2]。</p><p>常见的伪环保宣传还有：</p><blockquote><p>●<strong>声称塑料包装可水溶降解</strong>，在塑料中添加了水溶性物质，实际是分解成污染风险更严重的微塑料。例如洗衣凝珠的水溶性膜。</p><p>●<strong>塑料制品中添加了咖啡渣/秸秆等生物质成分</strong>。生物质的添加量很低，不能改变塑料制品本身带来的环境负担。而因为生物质的加入，大大提高了该塑料制品的回收成本，使其最终可能只能焚烧或填埋。</p><p>●&nbsp;使用耐用材料（如玻璃、不锈钢、陶瓷等材料替换），但产品<strong>设计不合理，导致只能做一次性使用</strong>，环境负担比塑料还大。</p></blockquote><h2><strong>环保套路二：鱼目混珠</strong></h2><blockquote><p><strong>套路等级：★★☆</strong></p></blockquote><p>乘着“禁塑令”的东风，“可降解塑料”这个专业词汇越来越多出现在商品的广告话语里，大有<strong>“可降解＝环保”的趋势</strong>。摆摆也经常在留言里看到读者反馈，虽然价格往往贵上几倍，考虑其可降解，愿意为此买单。</p><p>奈何大家买的是李逵，收到的是“李鬼”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9a3a8627431245fcac98d6896857fa9c@5919991_oswg263422oswg500oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了确认这件事，摆摆连续几年对“可降解塑料袋”进行网购测评，发现通过这个关键词只有<strong>10%</strong>的概率能买到生物降解塑料袋[3]，更多时候是遇到类似下图的情况：产品标签注明“可降解”，但实际上普通人很难确认它是什么成分。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_d26934b343d14404a8fa65985c8706a7@5919991_oswg63956oswg1080oswg572_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">该产品的执行标准为《GB/T 24454-2009 塑料垃圾袋》，对产品是否“生物可降解”没有要求，产品包装提供的成分信息对普通消费者而言，理解门槛较高，很难判断其属于生物降解塑料，还是氧化降解塑料。后者的环境负担可能比不可降解塑料袋还大。</p><p>虽然国家标准《GB/T 41010-2021生物降解塑料与制品降解性能及标识要求》在2022年已经实施，但推荐性国标对企业并没有强制性，对商家虚标伪标的打击力度非常有限。消费者还是无法正确识别环境相对更友好的产品，绕开环保陷阱。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ab0f5ac2317648688640ef206bb5ed9e@5919991_oswg48450oswg657oswg657_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>环保套路三：可以，但是……</strong></h2><blockquote><p><strong>套路等级：★★★</strong></p></blockquote><p>如果说前面的环保陷阱，我们还能通过擦亮双眼、恶补相关知识去避雷，进阶套路显得更加防不胜防。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_b3f17aa74049497da94b7424b48f4c08@5919991_oswg12352oswg336oswg271_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>即便商家提供的产品信息足够详尽的，使用的理论依据足够严谨，看上去无懈可击，也并不能保证环保的绿色初心能够落到实处。</p><p>再次以我们的“老伙计”可降解塑料为例，躲过了鱼目混珠的伪可降解产品，选择了真的可降解塑料产品，就能逃出生天吗？从环保效益的角度说，使用生物基生物降解塑料的一次性制品，就比不可降解塑料制品好些吗？</p><p>很可惜，现实也仍然不理想，<strong>可降解≠易于降解≠环保</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_fae29a5592ef4237a26ff8196c686f53@5919991_oswg218899oswg440oswg366_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>首先，生物降解塑料需要在<strong>一定条件下</strong>才可以实现降解（如在恒定高温的工业堆肥设备里90-120天等）。常用于<strong>吸管、塑料袋</strong>的聚乳酸（PLA）在海水环境中放置一年，<strong>降解率只有0.8%</strong>，几乎不降解[5]。</p><p>其次，目前大多数生物降解塑料都<strong>得不到合理处置</strong>。根据清华大学环境研究院统计，目前只有<strong>不到0.1%</strong>可降解塑料最终会被合理处置[6]，填埋和焚烧才是绝大多数可降解材料的归宿。</p><p><strong>当可降解塑料不能通过降解的方式进行处理，其“可降解”的优势就荡然无存</strong>：不能解决塑料垃圾问题，其全生命周期的碳足迹和传统塑料相比并无优势[7]。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_1c5a52881d754632af6c674f2400ebdb@5919991_oswg53311oswg788oswg1044_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">某电商平台的低碳消费栏目进驻产品，根据披露的产品信息可以判断其为生物降解塑料制品，商品详情页面在显眼位置注明“全降解材质 环保无害”。但产品信息中并未介绍其所需降解条件及时间。</p><p>除了生物降解塑料，其他“环保材料”同样需要考虑理论和现实的差距。很多环保er对可降解塑料并不信任，因而选择纯植物材质，如甘蔗渣/秸秆再造纸制品。它们也存在同样的限制，植物纤维确实可降解，但在自然环境中完全降解仍需要数年时间，这样的<strong>降解速度完全跟不上垃圾增长的速度</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4e6c61a478fe4d65ac44f3ac2a93c5ce@5919991_oswg197558oswg326oswg370_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">除了可降解塑料，可降解的植物纤维制品如要实现快速降解，也需要特定的条件，但产品页面往往只会强调其环保可降解。</p><p>当废弃物大量堆积，即使其不会对自然环境释放微塑料、重金属等物质，也很有可能会破坏生态平衡。所以比起寻找更好的替代材料，从源头，即设计和使用方式开始，简化包装、重复使用，杜绝或减少垃圾的产生是更划算的选择。</p><h3>参考资料</h3><p>[1]天下无焚.塑料“贡献”了91%的垃圾焚烧碳排放——来自我国1985-2016年的数据[OL].https://mp.weixin.qq.com/s/mKKnI1PFP9ijpaWDiLL6MA,2023-5-24.</p><p>[2]固体处.北京市生态环境局关于发布北京市2022年固体废物污染环境防治信息的通告[OL].https://sthjj.beijing.gov.cn/bjhrb/index/xxgk69/sthjlyzwg/1718880/1718881/1718883/326119588/index.html,2023-5-26.</p><p>[3]摆脱塑缚.一年一度，我们又双叒叕做可降解塑料袋测评[OL].https://mp.weixin.qq.com/s/B3RHbOq1tH1teJWsnzQIWA,2023-07-17.</p><p>[4] ALISHA MCDARRIS. Once you know what happens to food you leave outdoors, you’ll stop doing it,Popular Science[OL]. https://www.popsci.com/story/diy/what-happens-food-trash-outdoors/,2021.01.14</p><p>[5]HARRISON J P, BOARDMAN C, O’CALLAGHAN K等. Biodegradability standards for carrier bags and plastic films in aquatic environments: a critical review[J]. Royal Society open science, The Royal Society Publishing,&nbsp;2018, 5(5): 171792.</p><p>[6]清华大学, 中国石化. 可降解塑料的环境影响评价与政策支撑研究报告.[R].2022,04.</p><p>[7]侯冠一, 翁云宣, 刁晓倩,等. 生物降解塑料产业现状与未来发展[J]. 中国材料进展, 2022, 41(1):16.</p><p>[8]环资司.中国废塑料回收利用量居世界第一意味着什么 ——访中国物资再生协会再生塑料分会秘书长王永刚[OL].https://www.ndrc.gov.cn/xwdt/ztzl/slwrzlzxd/202206/t20220625_1328705_ext.html,2022-06-25.</p><p>[9]绿色和平.可口可乐年产塑料瓶超千亿加剧全球白色污染[OL].https://www.greenpeace.org.cn/2017/12/04/coca-colas-annual-output-of-more-than-one-hundred-billion-plastic-bottles-accelerate-the-global-white-pollution/,2017-12-4.</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/jXSLTFYUTWYpEnn3vu3_-w" rel="noopener noreferrer nofollow" target="_blank">“摆脱塑缚”（ID:baituosufu0705）</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510358927638788</id>
            <title>美团“开团”，社群团购战火再起</title>
            <link>https://www.36kr.com/p/2510358927638788</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510358927638788</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:22:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 团长, 社区团购, 社群团购, 团买买
<br>
<br>
总结: 近年来，随着社区团购的兴起，团长成为了一个热门的职业。社区团购的市场规模庞大，但受限于空间局限性。为了扩大市场，社群团购应运而生，通过微信社交链服务全国用户。美团优选推出了“团买买”小程序，为团长提供全方位解决方案。社群团购的竞争激烈，拼多多、京东、腾讯等大厂纷纷加入角逐。社群团购给用户提供了赚钱和购买的机会，成为了一个受欢迎的平台。社群团购的主要特征是依靠社交产生私域流量。 </div>
                        <hr>
                    
                    <p>你听说过“团长”这个词吗？近年来，随着社区团购的兴起，面对高达8.45亿用户的市场，大家身边开始出现各式各样的团长。“人人皆可做团长 团长月入可过万”，引得很多人入局。</p><p>但社区团购有空间局限性，基本辐射在三公里范围内，于是，另一批团长出现了，就是社群团购，通过微信社交链，可以服务全国的用户，据相关数据，社群团购市场可达万亿元。</p><p>面对巨大的商业价值，拼多多、京东、腾讯等大厂已纷纷开展角逐，美团作为团购的佼佼者，自然也想分一杯羹。</p><p>近日，美团优选近期在微信端上线“团买买”小程序，开始涉足社群团购业务。“团买买”主体运营公司为深圳黄小兜网络科技有限公司，该公司也是美团优选APP的开发公司。</p><p>根据官方介绍，团买买是美团官方推出的一款为私域交易提供全方位解决方案的微信社群经营工具。团长可以在团买买上找到全品类商品，包含食品、生鲜、日用百货、母婴、服装、美妆、家居、会员、机酒等等。开团后可以在朋友圈与微信群内传播分享。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_62e69c9b010f42bd956d7efabc7ae333@000000_oswg127660oswg822oswg688_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>美团“团买买”是个什么样的存在</strong></h2><p>“团买买”小程序除了购买功能外，主要就是“团长”功能，支持普通团购和复制开团两种，有资源的用户可以选择普通团购，没有资源的可以选择复制团购赚取佣金，当然，如果前两者都没有，那么也可以通过加入官方群来获得成为帮卖的机会。相比于同一家公司开发的美团优选社区团购来说，“团买买”在物流上除了自提，还增加了快递选项，将消费群体链接到了全国各地。</p><p>“团买买”的销售推广主要依托于微信社群，同时支持部分其他的社交平台，如微博等，是一个社交性的购买平台。团长上线商品时，还能够利用优惠券、新人折扣等营销工具来吸引一部分消费者。因为刚上线不久，平台推出了“团买买官方培训团”，帮助用户了解熟悉规则，目前已经有582人跟团，8千+的人看过。</p><p>总的来说，团买买小程序和之前的快团团等页面操作差不多，对于用户来说，又多了一个赚钱的渠道和购买的渠道，何乐而不为？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9406f7a01bf24ca8a05697f8ed175611@000000_oswg195747oswg1080oswg580_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>这些年的社群团购之争</strong></h2><p>在美团的“团买买”之前，已经有不少大厂平台参与了社群团购之争，打开小红书，搜索社群团购，可以发现有超过1万+的笔记。从如何引流到如何选品等，都有很多讨论量。</p><p>社群团购最先发力的还是拼多多，2020年3月6日，拼多多宣布推出线下团购工具“快团团”，协助各地商家收集社区居民物资需求、完成在线下单。商家可以通过“快团团”上线商品团购页面，并由社区消费者发起团购，达到人数条件后，由商家按照当地防疫要求无接触配送至社区门口。目前，该工具已在微信小程序上线。不得不说，拼多多是懂得“时势造英雄”这句话的。</p><p>接下来，腾讯在2022年2月针对微信私域交易场景面向小微商户推出的一款提高交易效率和私域运营的服务工具——鹅享团。团长通过邀请码注册并认证后才可以使用，供货团长和帮卖团长的申请还是有限制条件较为严苛，并没有像部分团购工具一样用烧钱补贴的方式吸引团长，2023年5月31日鹅享团暂停服务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ad321b0ad2694b30bcaa5714ed899acd@000000_oswg488670oswg1080oswg705_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2022年2月，京东推出了东咚团，东咚团更强调商品发布、分享、收单、统计等功能属性，展示了东咚团作为社群团购工具的定位。且只有获得定向邀请或者邀请码的团长才能发起团购，东咚团的团长没有上架商品的权限，只能在后台的选品池中选择商品开团，而选品池里的商品，都是京东平台的商家上传的。</p><p>相对来说，这些社群团购的竞争中，“快团团”有一骑绝尘的味道。就当前数据来说，快团团在微信社群团购小程序中排名第一，仅一年的时间就实现了600亿GMV，覆盖团长数超200万人, 日活用户数超过1000万。且已悄然上线了独立APP，拓展更广的市场。</p><p>各路玩家不约而同地在社群团购市场主动出击，不免让人再次想到当年的社区团购大战，谁又会赢得这场新战役呢？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_85d0b2dba41e456db5e6f9617df2117c@000000_oswg135751oswg640oswg203_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>拼多多、京东、美团，这些大厂的商业竞争谁主沉浮还是未知数，但对于普通用户来说，有资源有流量想要赚钱的，又多了一个平台；而想要购买的消费者，也多了一个平台。所以，与其说社群团购是美团的机会，不如说，也是用户的机会。毕竟，在上海封控期间，有数据显示，80%的人都成为了快团团的团长。</p><h2><strong>社群团购的主要特征有哪些</strong></h2><p>依靠社交而产生的社群团购，相比于目前如火如荼的社区团购，主要有2个特征：</p><p><strong>1.从公域流量到私域流量</strong></p><p>团买买是美团推出的一款为私域交易提供全方位解决方案的微信社群经营工具。该工具为微信小程序的形式，可以帮助团长精准匹配，转化私域价值，为消费者提供团购服务。</p><p>从团买买的推广介绍里，我们可以发现，区别于社区团购依托于电商平台，社群团购形成的销售群体则是卖家的私域流量。通过面向自己的亲朋好友圈子，建立微信团购社群，在人际口碑的基础上，聚拢志同道合的消费兴趣，从而产生商业价值。</p><p>私域流量的建立就又回到最初的个人IP打造，就像京东服务商表示的，要做团长，“最好是有团购经验，或者有自己流量的。”相对于公域流量借助于大平台优势，私域流量的挖掘，对于普通人来说，可能更为困难。</p><p>其实，对于用户来说，私域的运营，要不就是有足够的利益，让消费者获得足够多的便宜；要不就是足够的口碑，让消费者付出足够多的信任，才能把流量池的水搅活。</p><p>当公域流量竞争白热化的时候，各大平台都想量通过收拢私域流量来拓展市场，所以，如何将优秀的团长牢牢把握住，就像短视频的头部博主们，就成了流量的关键。</p><p>正如快团团已经开始培养拥有万人团的头部团长，呱呱爆品公布的快团团2023年月均销售额分布数据显示，TOP500的团长月销售额超过了100万元，其中TOP100的团长月销售额大于500万元，TOP50的团长月销售额大于1000万元，TOP10的团长月销售额2000万元。行业人士直言，快团团的头部团长，已经占据了社群团购的半壁江山。</p><p><strong>2.从限定空间到无限空间</strong></p><p>这一特点主要是和社区团购的区别，上文提到过，社区团购有空间局限性，在物流方式上，由于自提的唯一性，在选品、地域上，就会形成限制。但社群团购不同，类似于一个购物平台，我们可以从淘宝、京东、拼多多买东西，自然也能从社群买东西。</p><p>同时，先比于以前微商的社群销售，现在的团购模式是基于大平台产生的，就有了一个信任背书，能够刺激消费者更加大胆的购物。</p><p>打破了地域空间的限制，市场份额的增长、销售渠道的拓展就有了更多的可能。《私域运营：2023年私域电商快团团行业洞察报告》数据显示，2022年私域电商的市场规模约3万亿，是当下增速最快的电商场景，预计2023年将会突破3.5万亿。</p><p>从社区团购的前车之鉴来看，2020年7月15日，美团推出的社区团购业务“美团优选”，2020年8月26日，拼多多旗下社区团购项目“多多买菜”正式上线。就其市场份额的瓜分来说，截至2022年上半年，多多买菜在社区团购市场的份额达到了45%，美团紧随其后，占比为38%。截至2023年上半年，拼多多仍然是国内用户最多的平台。虽然略有差距，但也不分伯仲。</p><p>所以，若哪个平台能和拼多多快团团一拼，相比于京东、腾讯等，或许，美团的机会赢面更大一些。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkxOTMxMDk0MA==&amp;mid=2247608414&amp;idx=1&amp;sn=bc335ea67786a8d216251b6d0d431aea&amp;chksm=c1a76f6df6d0e67b9a16d880bb385b0389ac78a90896569d8c0d4a45d9c2178eb6873ace2583&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“鸟哥笔记”（ID：niaoge8）</a>，作者：花花小萌主，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510342760792326</id>
            <title>清华大学团队刷屏的芯片和论文，对AI意味着什么？</title>
            <link>https://www.36kr.com/p/2510342760792326</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510342760792326</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:21:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 芯片, 人工智能, GPU, 数字逻辑计算
<br>
<br>
总结: 清华大学研究团队发布了一款全模拟电子和光子计算芯片ACCEL，该芯片通过光学处理和模拟计算来加速人工智能计算，避免了数字逻辑计算的局限性，具有高能效比和计算性能。与传统的GPU等数字逻辑计算芯片相比，ACCEL在处理机器视觉任务时能够实现高效的降维处理和数据压缩，同时具备快速计算和低能耗的特点。 </div>
                        <hr>
                    
                    <blockquote><p>早阵子，国内清华大学研究团队发布了一篇论文，里面谈及了一款领先的芯片和设计。这个新闻在朋友圈引起了广泛讨论。那么这是个什么芯片？对AI又意味着什么？让我们在本文解读一下。</p></blockquote><p>人工智能是目前半导体芯片行业最重要的市场驱动力之一，同时也是当下最有潜力深刻改变整个人类社会的技术。当前，最主流的人工智能算法加速芯片是GPU，但是GPU加速人工智能有着自己的瓶颈，就是能效比较低。GPU的功耗通常要几百瓦，这就使得大规模部署人工智能充满了挑战：一方面大规模数据中心需要确保散热足够好，不至于让GPU过热而无法工作；另一方面，GPU很高的功耗又为数据中心带来了很高的供电成本和需求。</p><p>GPU，以及其他绝大多数人工智能加速芯片，都属于常规的数字逻辑的计算范式。使用数字逻辑计算存在几个重要的局限性：</p><ul><li>首先，信号必须要做数字化，而很多人工智能任务处理的输入（例如机器视觉任务）实际上并非人工的数字信息而是物理信号。这样的物理信号数字化就会带来能量的浪费。</li><li>其次，在数字逻辑中，有一个全局的时钟，而时钟频率则决定了整个系统的处理速度。数字逻辑的时钟频率往往决定于芯片工艺实现的逻辑门的速度（延迟），而并非由处理任务的复杂程度决定，因此这样的数字时钟事实上也限制了整体芯片处理任务能实现的速度。</li><li>最后，数字逻辑的设计中，尤其是对于处理人工智能相关的任务，通常都需要配合一个存储单元（尤其是像GPU需要配合DRAM使用），这样的数据存取和读取事实上会消耗相当大的能量。</li></ul><p>与传统的数字逻辑计算范式相比，新模态计算则是使用了非常规的信号处理和计算方法（例如光学处理以及模拟信号处理），从而可以很大程度上避免数字逻辑计算中的几大局限，并且有望为人工智能的高能效比计算带来新的希望。</p><p>10月底，来自中国清华大学的研究组在顶级期刊《自然》上发表了使用新模态计算加速人工智能的论文《All-analog photoelectronic chip for high-speed vision tasks》。在该论文中，清华大学的研究团队提出了使用光学和模拟计算来加速人工智能计算的技术，即all-analog chip combining electronic and light computing （全模拟电子和光子计算芯片，ACCEL），并且实现了相当高的计算性能和能效比（等效算力4600TOP／s，能效比74800TOP/s/W），相当于Nvidia A100 GPU的3000倍以上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_09a44058ec4b403891ce416a420adac5@000000_oswg125220oswg1080oswg474_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">ACCEL技术详解</p><p>ACCEL的结构如下图所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_1ad6c4cbf04f417cae167acaddfcf1ef@000000_oswg160374oswg1080oswg304_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>首先，如论文标题所说的，ACCEL针对的是机器视觉任务（vision task），因此输入是一个图像。值得注意的是，这里的图像并不是一个存储于二进制格式的图像文件，而是一个确确实实的图像物理信号（即光场信号）。我们会看到的是，整个论文中的芯片都是直接处理物理模拟信号，而不会做任何模拟－数字信号转换，这里的输入也因此是一个模拟物理信号。</p><p>输入图像光场信号首先进入光学处理部分，即optical analog computing，OAC。OAC的主要任务是把图像信号进行降维处理。例如，在ImageNet数据集上，图像输入是224x224，相当于数据维度高达50000以上，因此首先需要进行降维（和传统的卷积神经网络的降采样层是同一原理和目的）。OAC从物理上是利用光学衍射让图像中的不同像素之间互相交互，从而等价地实现一个矩阵相乘的过程，从实现上来说，OAC可以根据矩阵的权重而使用二氧化硅蚀刻出相应的图形来完成，换句话说OAC的实现是无需任何功耗的，仅仅就是把光透射过一层掩模版就完成了计算。在论文中，作者提到通过OAC可以实现高达98%的降维而不影响计算精度——换句话说OAC可以实现50倍的数据压缩，因此这个无需功耗的OAC实际上在整体系统中起到了相当重要的作用。</p><p>光信号经过OAC掩模版之后，照射到ACCEL芯片上的光电二极管阵列上（论文中称为电子模拟计算electronic analog computing，EAC），因此光电二极管阵列中的每一个光电二极管都会根据OAC的输出产生相应的光电流。此外，这些光电二极管阵列中的每一个光电二极管的正极都通过开关连接到差分信号线的正极或者负极上（该连接可以根据存储在SRAM中的内容来配置），因此每一个光电二极管都会为差分线的正极或者负极放电。最后差分线的正极和负极经过模拟比较器获得最终的0或者1的输出，同时也完成了模拟信号到数字信号的转换。整个ACCEL芯片使用成熟的180nm工艺实现，可以在约2ns的时间内完成一次计算，而一次计算耗费的能量为4.4nJ。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_72765db8bbdf470493514ce1ea5eedda@000000_oswg427705oswg622oswg588_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果我们把OAC和EAC的部分结合到一起，事实上ACCEL从数学的角度是实现了一个等效的神经网络，其中OAC是一个矩阵相乘运算，而EAC则是实现了神经网络中的非线性激活部分。根据论文中的数据，使用ACCEL可以在分类（MNIST，KMNIST，Fashion－MNIST）等机器视觉任务中实现和传统数字卷积神经网络类似的精度，但是使用ACCEL可以在处理速度和处理能效比上实现几个数量级的提升：这里的原因其实也很简单，卷积神经网络使用传统数字逻辑计算时，最耗费计算时间和能量的矩阵计算在这里直接使用光学计算完成了，而光学计算耗费的时间是0（光速），能量也是0；另一方面，ACCEL中决定任务处理速度的事实上是模拟电路部分，比较器的积分和开关时间决定了总体的任务处理时间。</p><p>值得注意的是，目前的ACCEL芯片是一个小型的芯片（使用了32x32阵列）并且使用了20多年前的180nm工艺，主要用于概念验证。如果使用更先进的工艺实现更大的阵列，则首先可以支持更大的神经网络以支持更复杂的任务，其次可以实现更高的处理速度（模拟电路处理速度即使是使用28nm这样的成熟工艺也会数倍于180nm）。因此，本次报道的ACCEL的性能数字还远远没有达到该技术可能实现的上限。</p><h2><strong>对于未来人工智能和芯片的潜在影响</strong></h2><p>清华大学的ACCEL可谓是非常优秀的科研工作，其实现的高性能也为未来应用提供了新希望。我们看到，ACCEL可以实现非常高的处理速度和非常好的能效比；同时，该技术的局限性在于（1）由于使用光学计算，因此最适合机器视觉任务，而对于目前最火热的语言类模型则难以支持；（2）对于算法和算符的支持，主要对于机器视觉任务中经典的卷积神经网络支持最好，对于Transformer等模型的支持还需要进一步的研究。</p><p>基于该研究的优势（计算速度和低能耗）和局限（对于算法类型的支持），我们认为，ACCEL以及相关的研究对于未来人工智能最主要的影响可能在于对于一些特定的任务提供极致的性能，而不是取代通用的GPU。这事实上也和目前的领域专用计算（domain－specific computing）来提供更好的性能及能效比的思路一致。具体来说，以下领域有可能成为ACCEL的应用场景：</p><ul><li>首先，是需要超低延迟的应用场景，例如汽车或其他高速行驶的场景。在这样的场景中，ACCEL搭配超高帧率的摄像头（例如目前正在兴起的DVS摄像头芯片，峰值帧率可达1000fps以上），ACCEL的超低延迟可以满足在超高帧率的两帧之间完成人工智能算法的推理，从而满足整体系统的需求。</li><li>此外，ACCEL还可望在触发式人工智能系统中得到应用。这里的触发式人工智能系统是指人工智能系统有多个模型组成，在大多数时候运行常开（always-on）的部分，而其他更复杂的人工智能模型仅仅在常开的模块发现有需要的时候才会触发打开。由于ACCEL的延迟和能效比都非常优秀，因此非常适合在这样的触发式人工智能中担任常开的模组。</li></ul><p>未来如果ACCEL以及相关的研究需要进入更广泛的应用，还需要研究人员进一步努力以支持更复杂的算法和模型结构，但是我们认为，前景是光明的，让我们拭目以待。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg2NDgzNTQ4MA==&amp;mid=2247718657&amp;idx=1&amp;sn=a13906f79a0ec67da1e21dded050eaae&amp;chksm=ce6e95f6f9191ce0b053f1210ec29489a233ccd874a6409a184002446e76868ac53505877c47&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体行业观察”（ID：icbank）</a>，作者：李飞，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510461163602181</id>
            <title>OpenAI这波更新会让更多创企走投无路吗？我们汇总了全球从业者的看法</title>
            <link>https://www.36kr.com/p/2510461163602181</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510461163602181</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:20:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 全球开发者大会, GPT-4 Turbo, 个人定制版ChatGPT, 助手API, GPT Store
<br>
<br>
总结: OpenAI在首届全球开发者大会上发布了一系列新产品，包括性能更强大成本更便宜的GPT-4 Turbo、个人定制版ChatGPT、助手API以及应用商店GPT Store。这些产品将对AI产业的格局产生重大影响。 </div>
                        <hr>
                    
                    <p>人工智能研究公司OpenAI的首届全球开发者大会“OpenAI DevDay”，吸引了业界的广泛关注，甚至被称为“AI界春晚”活动中，OpenAI王牌频出，发布了性能更强大成本更便宜的新模型GPT-4 Turbo、个人定制版ChatGPT（GPT）、助手API以及应用商店GPT Store等核心产品。这些产品到底会如何改变后续AI产业的格局？我们跟踪了许多业内人士第一时间的反馈，他们的反应才能最真实地表达出这场发布会带来的“业界震撼”。</p><h2><strong>01 OpenAI内部：分工明确，人设分明</strong></h2><p>作为全球开发者大会的主办方，OpenAI内部的反应最为迅速。共有三个联创在X平台上进行了发言，角色相当清晰分明，给OpenAI的PR部门加鸡腿。</p><p>OpenAI首席执行官萨姆·奥特曼（Sam Altman）的角色就是官方产品发言人角色，在发布会进行期间，他负责在X上简单直白的介绍GPT-4 Turbo和其他新功能。展现出OpenAI一贯向外界展示出的品牌形象：高效，清晰，得体，甚至有点学究气。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_78b0e3c5096e475cb7828336e1a25bc8@1743780481_oswg58867oswg612oswg764_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而OpenAI联合创始人格雷格·布罗克曼（Greg Brockman）更多的是扮演了开发者支持的角色。他的X页面就欢脱，亲和多了。</p><p>他首先感谢了OpenAI团队的不懈努力，并对关注这场盛会的观众致谢。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_71e19eabad31494089866d3e7f6ea07f@1743780481_oswg90785oswg598oswg861_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随后布罗克曼更是深入开发者角色，发表了对开发者大会的感受，他说：“在今天的活动中，我个人最喜欢的部分是通过与智能助手交谈来构建个人定制版GPT。”他还上传了如何使用助手API制作下一代用户界面的视频。看着就好像一般业内人士会做的那样。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4aaffc5d50ed46778de0eba801501f59@1743780481_oswg306005oswg960oswg892_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>发布会的最后部分他开始开发者们加油打气：“人工智能领域有很多东西值得研究，而且绝不会让人感到无聊。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_e9d8ffbf45c34b86a9831a2a4660e6f4@1743780481_oswg45322oswg960oswg163_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f652da60d46248e1898e13d114da21f4@1743780481_oswg607865oswg960oswg941_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在Keynote 结束之后，Brockman一直都在关注和点赞开发者用他们新的GPT所做的尝试和可能，他完美担当了开发者大使角色。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_bbf8ae40b24f49d68825f4dedcd41966@1743780481_oswg386776oswg960oswg908_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一位OpenAI的联合创始人，技术大牛安德烈·卡帕西（Andrej Karpathy）的发言则更多是面对产业界的。因此在OpenAI相关人士发言中也最直涉本质。</p><p>他表示“有了新近发布的GPT，我认为我们在计算领域看到了一个新的抽象层，尽管它依然显得有些原始。会有更多的开发者，更多的GPT。GPT已经可以读、写、听、说、看、画以及思考，使用现有的计算工具，成为重点领域的专家，参考自定义数据，在数字世界中采取行动，以自定义方式说话或行动，并协同工作。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_c58f4aa4942b48f788b81147d4cd3835@1743780481_oswg103148oswg584oswg845_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这基本上就是OpenAI对新产品的商业 /产品理解解读：把OpenAI的角色向前一步，找到能更多控制产品开发的抽象层。</p><p>而这话由Karpathy来说非常合适，因为他之前就因Agent是下一个AI发展点的发言火爆全网。</p><p>结合llya前日访谈中多是谈到的更多是AI是否有意识等纯学术问题。扫地僧人设立的岿然不动。</p><p>由此，我们从开发者日即可完整窥见OpenAI四大金刚的PR角色设定。</p><h2><strong>02 AI领域大佬：嘲讽反击找平衡</strong></h2><p>人工智能领域的大咖大多数保持了沉默。另外一些大佬虽然没有明指OpenAI发布会，但根据发帖时间和内容看，还是很容易看出其发言与这场大会的关联。</p><p>明确评论的大佬只有纽约大学心理学和神经科学荣誉教授、新硅谷机器人创业公司Robust.AI首席执行官兼创始人盖瑞·马库斯（Gary Marcus）。他先评论了一下OpenAI的新模型Turbo，认为他们最值得关注的是成本和速度，而不是全新的功能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_9157920457334574b053f02f135225cf@1743780481_oswg73657oswg593oswg861_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随后他又爆了个猛料：“考虑到信息检索的截止日期，以及奥特曼在5月份与我们在参议院时所说的话，我的直觉告诉我，GPT-4 Turbo实际上就是GPT-5，只是它还没有取得足够的认知突破，进步也不大。”</p><p>这话可以有多层意思解释，考虑到GPT4-Turbo在数据集和训练构架上有一些调整，所以支持更大上下文和更新的知识，也许确实是经过了重训练的版本，也就是实际上的GPT5。但也有可能GPT 5并没有如奥特曼在5月预期的时间完成训练调试，并在这次大会上登场。</p><p>纽约大学教授、Meta首席科学家杨立昆（Yann LeCun）作为竞品领袖，推特大嘴王，在发布会结束后回复了一条推特称：大语言模型（LLM）甚至还不知道如何爬楼梯。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ede429e9bb2a4872bfc2c5ef98893ade@1743780481_oswg81858oswg960oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最大的AI开发社群Huggingface的CEO Clem虽然没有直接发推评论此事，但转帖了一位创业企业CEO的发言：“OpenAI刚刚给新一代创业公司创始人上了惨痛的一课。我上一次创业是在Facebook和iPhone主导的平台颠覆时代，我为那些第一次创业的人感到同情，他们现在意识到为什么‘护城河’很重要。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_635b0079cb18400ba387300492acc53b@1743780481_oswg45731oswg960oswg323_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>看起来Clem还是本着让大家练好内功的基本逻辑在思考。但其实很多时候，护城河所在就是巨头停步之处。不过这一批被干掉的创企确实是离OpenAI的守备范围过近的企业。</p><p>在所有大佬的反应中，特斯拉首席执行官埃隆·马斯克（Elon Musk）最值得玩味。在发布会结束后，他先推继续挺自家AI Grok，之后就去猛打暗黑4杀时间去了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_30e4309a47b947dab6bee3b129f6a2a0@1743780481_oswg210546oswg960oswg771_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不知道是不是心有不甘，在当日深夜，他开始放飞自我。开始用可以回答污言秽语的自由，来展示自家Grok的“强大”，并配图嘲讽GPT的“老实”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_f5dd96236934401485f1f3dcf4315dc2@1743780481_oswg43682oswg611oswg481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ef2315f9137344a0a1a561a058e6ccc3@1743780481_oswg44341oswg593oswg602_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0307b0626c37464c966534525c949227@1743780481_oswg51303oswg596oswg603_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但这招并没有被所有人都接受。X用户Tibo就对马斯克行动缓慢提出了批评。他称：“我希望马斯克能做得更好！他可能击败了GPT-3.5，但没有打败GPT-4，仍然比OpenAI落后一年多！”</p><h2><strong>03 AI创企：哀鸿遍野，痛斥OpenAI不留活路</strong></h2><p>OpenAI发布的新产品和功能，让许多初创企业心惊胆战。发布会前就有人就调侃：“苹果开发布会，会有很多初创公司看到机会诞生；OpenAI每次发布新产品，就有一堆初创公司死去。”从发布会后的反馈来看，似乎确实如此。而且这次因为GPT的发布，对很多初创公司来讲情况更严峻。</p><p>比如说，有一名叫near的创业者发推说：“已经有人问我，我创业公司的哪些人工智能产品没有被OpenAI扼杀？”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_304674c56c2e45ec972ac2013e08a3e8@1743780481_oswg31525oswg596oswg633_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对此他解释称，OpenAI在策略上很像亚马逊：等某个项目、服务或商店变得流行时，他们就会推出自己的版本，消除B2B关系，直接面向消费者。这就像让小鱼们先建立市场，然后再占领市场。但它不一定能成为亚马逊。</p><p>还有一位AI领域咨询师Abhishek Agarwal 表示“今天，OpenAI在DevDay上杀死了所有类别的初创公司。对于人工智能初创公司的创始人来说，这简直是一场大屠杀。“随后列出来了所有可能面临灭顶之灾的公司类型。</p><p>“以下是从明天开始将不存在的一些创业类别：</p><p>闭源LLMs: OpenAI推出了GPT-4 Turbo，其上下文长度为128K，价格便宜2.75倍。比如Anthropic、Bard、Cohere</p><p>文本到语音API：OpenAI现在提供了一个具有6种类人语音的文本到语音API。比如Eleven Labs、PlayHT</p><p>“与你的X聊天”应用程序（一般是PDF，网页文件等）：OpenAI现在支持内置RAG。比如Chatbase、ChatPDF、SiteGPT、Cody</p><p>矢量数据库：现在GPT API支持RAG，开发者将告别矢量数据库，比如：Pinecone、Chroma、Qdrant</p><p>人工智能开发框架：没有人会再使用框架在LLM之上进行开发。后面每个人都会使用OpenAI，因为现在使用助手API构建人工智能应用程序太容易了。比如：Langchain、LlamaIndex“</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_91306bf6360f491089c1544df261708d@1743780481_oswg209114oswg950oswg1540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>非常全面，但是可能还得加上一些基础Agent搭建平台，因为通过Actions和升级的功能唤起能力，用OpenAI搭建Agent也是当下最简单，最可能成功的模式。</p><p>正如Abhishek所说，不光是小创业公司濒临灭亡。对于其他闭源达模型来讲，OpenAI这次发布会的API价格大降，对他们完全可能构成生死威胁。2/3的价格优势足以打倒任何竞争者。</p><p>英伟达资深AI科学家Jim Fan就表示，“OpenAI的规模经济给它带来了杀手级优势，这可以通过计算得出来。使用GPT-4-turbo，阅读整部《哈利波特》系列（共7部）只需15美元，而让它再写7部只需45美元。另外在GPT-4-V上，只需要180美元就可以观看所有8部哈利·波特电影，1帧/秒，分辨率为360p。“</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_3dd55a4218084c159f51769ff42560ea@1743780481_oswg106198oswg960oswg424_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一位AI创业者Tibo也称：“当我们都在讨论应该如何提高价格时，OpenAI却在一夜之间将其API收入砍了一半！”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_6ebf1062c7e14c6e86fea2e8ed736353@1743780481_oswg25990oswg960oswg220_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，对于来势汹汹的OpenAI GPT，这些大受影响的初创公司也不甘示弱。Langchain就在几乎同时放出了对Assistants API的支持。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_837ea1a3197c402c968cfea2f122c706@1743780481_oswg302060oswg960oswg1136_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但是问题是，都有GPT如此方便地搭建支持了，我何必还要跳到你这里做开发呢？</p><h2><strong>04 开发者：马上开玩</strong></h2><p>OpenAI GPT刚刚发布，就有AI开发者上手立马用起来了。</p><p>AIrundown的Rowan Cheung称其刚刚测试了OpenAI的新GPT Builder，并创建了“X优化器GPT”，它可以微调帖子，并精确定位峰值发布时间，以获得X上的最大参与度。结果令人感到兴奋！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_6256165e0e734e5487a3dd9cc2824485@1743780481_oswg34023oswg601oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AI应用开发者尼克·多波斯（Nick Dobos）声称自己创建了全球首个定制GPT代理。他认为GPT-4-turbo不够快，所以他包含了20个预构建的热键来加快速度，包括自动保存、长时记忆、可重复使用、跟踪当前任务以及导出到任何聊天应用等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_0c91784d72964fd886fae20553fc3cea@1743780481_oswg49217oswg595oswg833_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>美国宾夕法尼亚大学沃顿商学院副教授伊森·莫里克（Ethan Mollick）表示，他在不到一分钟的时间里拼凑起来的一个小GPT (Open AI发布的新的类似代理的东西)。它在网上查找产品类别的最新趋势，然后为其创建原型图像。端到端耗时不到90秒！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_3413cb248b554cfc9abd23333a090781@1743780481_oswg44769oswg599oswg663_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了这些基础实验，当天稍晚一点就有人开始做更深度的尝试了。X用户冈萨洛·埃斯皮诺萨·格雷厄姆（Gonzalo Espinoza Graham）试验了人工智能解说的能力。他认为GPT-4V + TTS就可以取代足球赛事解说员。他将足球视频的每一帧都传递给GPT-4视觉预览，并通过些简单的提示要求生成旁白，无须任何编辑。OpenAI的联合创始人Greg还特意为此点了赞。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_826077f07ca041eca43b75818c57a437@1743780481_oswg48448oswg602oswg670_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这还只是Day1，现在的AI领域Geek值指示器可能已经爆炸了。</p><h2><strong>05 趋势观察者：靠着GPT，OpenAI在重新划分AI版图</strong></h2><p>针对GPT这个产品所带来的基础Agent能力，OpenAI毫无疑问是Game Changer。过往在利用AutoGPT等产品时，因为缺乏对函数引用和外部工具使用的纠错能力，开发成本很高，成功率也一般。因此这些产品虽然GitHub上高星，但一个热门应用都没能从中产生。而GPT之后，事情就会完全改变。</p><p>自然语言处理领域专家Sverige_ Dong-seok经常在X上分享有关人工智能的经验。他认为，OpenAI的助手直接把增强语言模型从比拼基准的学术领域解放出来，直给到开发者手中。同时，这也把原本帮助大语言模型更好完成生成任务中间产物CoT变为直接输出再次直给到用户。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_dd21d65aa0334696be5a5dc5e6e5bacf@1743780481_oswg151238oswg960oswg349_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同样针对GPT的能力，知名X用户、科技博主苏里·奥马尔（Sully Omarr）认为受伤最大的可能都不是小公司，而是各个行业的巨头。他说：“OpenAI彻底颠覆了整个人工智能领域。许多公司已经花费了数亿美元来构建自己的‘助手API’，现在每个人都可以使用OpenAI的技术。这对小公司来说堪称是福音，但对大公司来说却足够残酷！”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_db137ad603694e9aaa460abf660b6b88@1743780481_oswg141106oswg960oswg686_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>曾经在Facebook和Uber工作过的AI工程师、游戏设计师佩特罗·施拉诺（Pietro Schirano）形容GPT的潜力如同地球物种爆发时期，只不过这次是思想。他说：“创建和共享个人定制版GPT的能力影响将是巨大的。我们正在进入一个新的应用商店时代，一场真正的寒武纪思想大爆发将紧随其后。”确实，在一个用母语就可以通过引导构建自己应用的时代，多少过往受限于技术原因难以达成的梦想会分分钟成真？最起码，千人千面的个人助手已经近在眼前了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4296e3eae85b4d4fb272452d80bfbba1@1743780481_oswg37397oswg603oswg537_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>专门研究大语言模型（LLM）的埃尔维斯（Elvis）参与了后续的场次，他分享了OpenAI后续的PPT，称其“很好地总结了大语言模型领域的发展趋势”。</p><p>从PPT上看来，目前的GPT API还远不是终点，基于用户体验对知识库和开发工具的丰富，会是OpenAI后续开发的核心逻辑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_4b57079078a6463cbd86dbed7beee752@1743780481_oswg39322oswg596oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后的趋势观察来自硅谷最炙手可热的设计师之一、私密社交应用Path的主要设计者丹尼·靳翰（Danny Trinh）。他观察的可能不是产品或行业，而是OpenAI CEO 山姆·奥特曼本人。在2008年，奥特曼刚开始构建应用。而到2023年，他已经推出了应用商店。按照这个速度，再过十几年，估计就只有征服银河系够他发挥的了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_ffc636022b0d471cb47acdc2e6c10c83@1743780481_oswg32827oswg602oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/JWd_gUyrefiQxfvcr6J0Jg" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”（ID:qqtech）</a>，作者：郝博阳 金鹿，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510361196978311</id>
            <title>微创医疗狂奔这四年</title>
            <link>https://www.36kr.com/p/2510361196978311</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510361196978311</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:19:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 分拆上市, 微创医疗, 资本市场, 业务拆分
<br>
<br>
总结: 微创医疗是一家在资本市场上成功进行业务拆分上市的医疗器械公司。通过分拆子公司上市，微创医疗实现了资产的快速增长，但财务表现并未改善。微创医疗的核心业务发展不平衡，传统业务停滞不前，创新业务发展迅猛。微创医疗的分拆策略在短期内获得了成功，但长期来看，核心业务的自我造血能力仍然是公司的软肋。 </div>
                        <hr>
                    
                    <p>分拆上市在资本市场里本不是一件新鲜事，但能够将分拆上市玩成“艺术”般丝滑的，微创医疗还属于头一家。</p><p>曾几何时，微创医疗也是一家潜心于高精尖路线的创新型医疗器械公司。于1998年在上海张江科学城创立，经过25年的发展，分别于上海、苏州、嘉兴、深圳，美国孟菲斯，法国巴黎，意大利米兰等地区建立生产研发基地，已经形成全球化的研发、生产、营销和服务网络。</p><p>从创立初期的单一产品线，到如今多产品线全面布局，微创医疗可谓完成了蜕变。尤其在2019年开始分拆子公司后，其逐渐形成了“12+5”的平台搭建，并尝试将各业务线都孵化上市，立志于打造一个庞大的药械帝国。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_3b76aefe819345e4b476a72c8b9f9b39@5919987_oswg104119oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：微创医疗业务体系，资料来源：公司官网</p><p>成为中国的美敦力，这是奠基人常兆华从微创医疗成立第一天起就定下的目标，如今伴随一家又一家子公司的分拆上市，似乎微创医疗正在朝向诺言愈近。</p><p>分拆业务上市的本意，在于通过融资帮助子公司迅速成长，利用募集资金撬动研发杠杆，从而推动更多产品上市，以此来增厚母公司的业绩。然而在财务端，子公司的拆分却并未改善微创医疗的业绩，反而亏损额度持续放大。</p><p>通过拆分，微创医疗资产报表中的数字大幅攀升，但巨额的亏损也表明公司对于效率的控制力度并不强。当市场不再认可微创医疗这种拆分策略时，财务已经“失控”的微创医疗又该如何收场呢？</p><h2><strong>01 分拆这个潘多拉魔盒</strong></h2><p>复盘微创医疗股价走势，其最初的上涨源于2019年中旬，当时公司成功分拆心脉医疗于科创板上市，并筹划多家子公司后续的分拆计划。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_efafe07d57ad4c3d960a8cbb1d2521ac@5919987_oswg119009oswg1080oswg479_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：微创医疗股价走势，来源：雪球</p><p>微创医疗赶上了一个好时代，2019年时科创板风头正盛，新股上市第一天就被市场热烈拥抱，心脉医疗也不例外，上市第一天就暴涨229%。强大的赚钱效应之下，微创医疗后续的分拆计划无比顺畅，这也让公司资产实力在短期内得到迅速增强。</p><p>依靠子公司分拆，微创医疗报表中的现金及等价物数据大幅增长，尤其在2021年微创机器人上市后，公司现金及等价物数据升至17.87亿元的历史顶峰。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_089df3aa2bf6423abceae1d0bca50891@5919987_oswg56116oswg1080oswg501_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：微创医疗资产数据，来源：锦缎研究院</p><p>尽管当时公司仍处于亏损之中，但大比例的融资注入极大的提升了市场预期。有了这些投资人的加持，似乎一副波澜壮阔的微创帝国蓝图已然浮现于投资者心中。</p><p>此后三年间，微创医疗先后成功拆分旗下五家子公司上市，包括心脉医疗（2019年7月）、心通医疗（2021年2月）、微创机器人（2021年11月）、微创脑科学（2022年7月）、微创电生理（2022年8月）。即使很多业务没有达到上市门槛，可也顺利的拿到了前期融资，所有人都知道这些项目就是冲着上市去的。</p><p>微创医疗的模式可以归纳为：从一级市场拿钱，一级市场资金获得巨大杠杠乘数后，最后由包容性极强的二级投资者吃下。拆分游戏背后，微创医疗扩大了规模，一级投资者赚了钱，二级投资者擦了一把泪。</p><h2><strong>02 潮起潮落终有时</strong></h2><p>通过拆分业务上市，微创医疗确实在短期内获得了大量的现金资产，这无疑有助于公司竞争力的提升。但从长远角度分析，一家公司能够走多远，还是要考量核心业务的“自我造血”能力，而这一点恰恰是微创医疗的软肋。</p><p>微创医疗传统核心业务主要有三大块：心血管介入业务、骨科医疗器械业务、心律管理业务，在总营收中的占比分别为16.4%、24.0%和22.5%，其余创新性业务的营收占比合计为37.1%（2023年中报数据）。</p><p>从业绩增速角度考量，微创医疗的业务发展极为分化，传统业务全面停滞，创新业务则发展迅猛。具体而言，骨科医疗器械业务和心律管理业务的营收几乎与疫情之前持平，而心血管介入业务的营收则较2019年出现巨幅下降。反观几个增速显著的业务，却都已经全部被拆分上市。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231109/v2_6d639cc3c9c24ab4ab94456e41ace26b@5919987_oswg212739oswg1080oswg282_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：微创医疗各业务线营收，来源：锦缎研究院</p><p>创新业务拆分后，虽然它的营收依然可以涵盖到报表之中，但由于外部投资人的介入，导致公司话语权降低，母公司股东权益也被大幅稀释。对于正处于高速成长期的子公司股东而言，他们现阶段首先考量的并不是盈利能力，而是规模增长。当这些创新业务线都以增长为目标，所带来的结果就是资源投入的持续增多。</p><p>传统业务的停滞叠加创新业务的投入飙升，微创医疗的利润亏损逐年递增，而且公司对于这种亏损几乎毫无办法。在2021年末的时候，公司账面拥有现金及等价物17.54亿元，可到了2023年中报的时候，这项数据已经骤降至8.43亿元，几乎烧掉了一半。</p><p>坦率而言，微创医疗拆分出来的创新业务虽然增速显著，但却远未到收获之时，仍然需要大量的资金投入。可在不进一步融资的情况下，如果继续以目前的速度烧钱，那么微创医疗的账面资金将支撑多久则备受瞩目。</p><p>按照微创医疗曾经的构想，创新业务拆分后，可以通过高速增长吸引投资者入局，以此来获得进一步的融资。但微创医疗各创新业务上市后的股价表现却并不尽如人意，再加上医疗市场遇冷，投资者似乎已失去了热忱。</p><p>如果拆分无法带来赚钱效应，那么微创医疗后续融资计划的执行难度将陡然提升，即使资产最终成功IPO，愿意接棒的二级投资者也将必然减少。</p><p>微创医疗崛起的最重要因素在于医疗创投市场的火热，可这份火热的情绪显然是有周期的，当投资者热情不再，微创医疗市值回落也自然在情理之中。</p><h2><strong>03 不知疲倦的极乐鸟</strong></h2><p>在北欧国家流传着一个关于“极乐鸟”的传说，它们会不知疲倦地一直在空中飞，累了就睡在风中。一生只会落下一次，而那也将会是它们生命的终点。</p><p>从微创医疗2019年全面启动拆分计划开始，它就如同“极乐鸟”一样开始极速狂奔，其股价也在投资者的欢呼中不断上行。也正是从那一刻起，微创医疗的股价就与整个资本市场医疗产业融资景气度高度相关。微创医疗预期的膨胀是建立在持续拆分，不断融资的预期之下，如果后续拆分遇阻，那么被放大的预期将会极速坍缩，从而导致股价的崩盘。</p><p>对于上市公司而言，分拆本就是一把双刃剑，在获得外部资本力量的同时，公司也将降低对于子公司的绝对话语权。更为重要的是，伴随微创医疗分拆业务数量的提升，分拆后的公司并没有很好的市场表现，资本市场对于拆分资产的认可度正在下降。也就是说，微创医疗后续分拆难度将持续提升，分拆的效果也将大不如前。</p><p>在拆分初期，微创医疗尚能凭借赚钱效应获得市场红利，可当二级市场投资者屡次失望后，那么后续拆分的难度必将有所增加。一旦市场不再认可微创医疗的这种拆分行为，那么这个庞大的药械帝国又该如何支撑呢？</p><p>回顾2023年，无论是科创板还是港股，医药相关公司的IPO数量均明显减少，融资数额也明显降低。IPO收紧的大背景下，微创医疗这种依赖于拆分融资的模式势必将受到考验。</p><p>如何才能避免像“极乐鸟”那样的硬着陆呢？这是微创医疗高管层必须首先考虑的问题，远比如何成为中国美敦力更加重要。</p><p>*本文系基于公开资料撰写，仅作为信息交流之用，不构成任何投资建议。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/tNm4SX2T5C65EjOvSN6DYQ" rel="noopener noreferrer nofollow" target="_blank">“医曜”（ID:yiyao-jinduan006）</a>，作者：浪花远去且听风吟，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2510340920344580</id>
            <title>985高校争做VC</title>
            <link>https://www.36kr.com/p/2510340920344580</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2510340920344580</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:12:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 科技创新浪潮, 高校设立基金, 湖南985大学, 校友创投基金
<br>
<br>
总结: 在科技创新浪潮的推动下，越来越多的高校设立基金和母基金，为产业发展和科技创新提供支持。湖南985大学中南大学也加入了VC圈，计划募集20亿资金。校友创投基金成为湖南省联合高校设立的第一家基金。高校通过设立基金和母基金，利用自身的人脉和资源优势，为科技创新提供资金助力。 </div>
                        <hr>
                    
                    <blockquote><p>在科技创新浪潮的推动下，围绕高校设立的基金和母基金逐渐普遍，为产业发展和科技创新提供了实打实的支持。</p></blockquote><p>高校在支持科技创新中发挥的作用愈发明显，除了培育人才和科研成果外，越来越多高校亲自下场做VC，为科技创新提供资金助力。</p><p>日前，继天津大学之后，又一所985大学进军VC圈，计划募集20亿。</p><h2><strong>做VC，湖南985也来了</strong></h2><p>进军VC，湖南高校也来了。</p><p>10月31日，中南大学校友企业家联谊会成立大会在长沙召开，会上，湖南财信金融控股集团有限公司发布了<strong>“中南校友惠湘基金”</strong>方案，该基金方案计划募集资金20亿，为中南大学师生和校友创新创业提供金融支持。</p><p>据悉，这也是<strong>湖南省联合高校设立的第一家校友创投基金</strong>。</p><p>对于设立中南校友惠湘基金，财信金控党委书记、董事长程蓓表示：作为湖南唯一的省级地方金融控股公司，通过中南大学校友会平台桥梁纽带作用，与中南大学、长投控股拟联合设立中南校友惠湘基金，深入推进产学研联动，为研发中心以及总部型、研发型、链主型、引领型项目在我省落地生根，服务我省现代化产业体系建设，助力高质量发展提供服务、贡献力量，是财信金控义不容辞的重要使命。</p><p>未来，财信金控将携手中南大学、长沙市及各地校友会，在产业配套、金融赋能、资源整合、科技创新等方面深化合作，全面聚焦服务实体经济，推动高质量发展。</p><p>近两年，各地在推动科技成果转化层面不遗余力，除了地方配套的政策和资金支持外，<strong>高校在科技成果转化层面发挥的作用也愈发凸显</strong>。</p><p>一方面，高校拥有人才资源和科技研发项目优势，另一方面，庞大的校友群体也是“硬核”优势，资源人脉都相对充足。</p><p>以中南大学为例，作为一所“双一流”、“985工程”、“211工程”大学，其“硬核”的校友资源一直不容小觑。据数据显示：中南大学开校至今，已先后向社会输送各类人才50余万人，培养了40多位两院院士；担任中央企业和上市公司董事长或总经理的校友有100余名……</p><p>王传福、梁稳根等拥有“钞”能力的富豪均在中南大学校友之列。</p><p>正如，中南大学党委书记易红在致辞中所言：“校友是中南大学办学一张闪亮的‘名片’，广大校友为国家发展、民族进步贡献了中南力量。学校高度重视校友工作，希望能为校友事业发展提供更高质量的服务。”</p><p>此次会议现场，经在场校友选举表决，材料系79级校友、三一集团有限公司原董事长梁稳根，冶金物理化学系83级校友、比亚迪股份有限公司董事长王传福当选中南大学校友企业家联谊会理事长。</p><p>事实上，早在去年，中南大学就开始涉足一级市场。</p><p>据报道，去年12月12日，中南大学与执君私募基金管理（杭州）有限公司（简称“执君资本”）、湖南湘投私募基金管理有限公司（简称“湘投基金”）签署科技成果转化合作协议，同时，执君资本捐赠1000万元设立“中南大学执君医疗科技创新奖”。</p><p>协议约定，执君资本、湘投基金共同发起设立<strong>“湖南湘投执君生命科学产业基金”，</strong>以中南大学医疗科技成果转化为背景，向政府、市场化机构募集资金，以专业化、市场化方式开展基金投资管理工作。<strong>产业基金第一期目标规模为10亿元人民币，</strong>重点关注和投资中南大学医疗科技成果转化项目。</p><p>对于设立科技创新奖，三方负责人表示，旨在进一步推进优秀医疗科技成果转化应用，培育壮大战略科技人才、科技领军人才和创新团队等各类人才队伍，助推国家医疗事业的发展。希望以此次签约为起点，各方建立起长效交流协作机制，在更多领域实现合作共赢。</p><p>为支持科技成果转化项目，985大学联合社会资本、国资、以及各大校友密切布局，创投基金、捐赠基金都直指科技创新，为校友提供创业平台，为项目培育和发展提供资源、资金等多方面支持。</p><h2><strong>高校争当VC</strong></h2><p>实际上，不仅是中南大学，这两年涌入VC圈的高校层出不穷。</p><p>10月1日，天津大学发布了一支新能源新材料创投基金，该基金通过完全市场化管理方式，投资具有高成长性的新能源和新材料企业，将进一步形成优势学科与资源互补，推动产业集聚，为落实国家“双碳”战略，贡献“天大力量”。</p><p>2月17日，深圳市南科梧桐天使创业投资合伙企业（有限合伙）第一次合伙人大会在南方科技大学成功举办，宣告“南科梧桐天使基金”正式启动运营。基金由南科大资产公司全资企业深圳市南科大分享股权投资基金管理有限公司募集设立，其中深圳天使母基金提供引导份额，若干社会LP参与认购，目标规模1.2亿元。</p><p>2022年10月12日，电子科技大学第七届青城问道暨“成电邦基金”发布仪式在成都举行，总规模10亿元的“成电邦基金”正式宣布成立。这是电子科技大学参与的校友基金，由电子科技大学、成都市郫都区以及知名校友共同发起。</p><p>2022年7月17日，时值北航70周年校庆倒计时100天，北京航空航天大学校友夏炜向母校捐赠资金1亿元人民币，设立北航科技创新母基金，用于支持北航科技成果转化以及校友创新创业事业，并与多位校友一起向北航捐赠北航投资有限公司1000万元股权，用于支持学校发展建设。</p><p>2021年年底上海交大未来母基金的成立，开启了国内高校牵头设立母基金的先河。</p><p>2021年10月，深圳天使母基金与南方科技大学联手合作，双方将围绕基金设立、空间共建、专家共享、实训就业、交流合作等方面展开更深入的交流与合作。</p><p>再往前数，深投控与南方科技大学合作设立的深投控南科大天使基金，依靠深圳大学的深大科技创新创业基金等。同时以及清华、北大教育基金会等，多年来，已经为创投行业持续输入新鲜血液，也成为不少机构背后的LP。</p><p>此外，围绕高校师生设立的创投基金也十分常见，尤其是安徽。</p><p>去年12月22日，科大硅谷引导基金注册成立，总规模300亿元，这是目前首支围绕高校科技成果转化的引导基金。</p><p>年初安徽省还推出了“雏鹰计划”，设立雏鹰基金，主要吸引、支持国内外高校师生、初创团队在皖创办企业，通过股权投资方式对国内外高校师生、初创团队创业给予支持。</p><h2><strong>结语</strong></h2><p>科技创新项目往往试错成本高，周期长，在培育和研发层面需要大量的人力、资源、资金的支持，而<strong>高校依托自身庞大的人脉、资源、以及背后的校友经济，</strong>优势更加突出。</p><p>这两年，各地政府加大招引力度，在加快推动科技成果转化层面全力以赴，在科技创新的浪潮的推动下，围绕高校设立的基金和母基金逐渐普遍，为产业发展和科技创新提供了实打实的支持。</p><p>安徽、浙江、江苏、湖南、河南等地陆续加入推动高校科技成果转化的队列，高校VC阵容也不断扩大，电子科技大学、浙江大学、南方科技大学……</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Vc5oIKVHMuKtj1E_4YurDg" rel="noopener noreferrer nofollow" target="_blank">“FOFWEEKLY”（ID:FOF_weekly）</a>，作者：FOFWEEKLY，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>