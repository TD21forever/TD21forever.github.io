<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2547746746717832</id>
            <title>大模型助力健康管理，通过认知行为疗法改变知易行难｜我爱黑「可颂」路演项目专访</title>
            <link>https://www.36kr.com/p/2547746746717832</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547746746717832</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 11:04:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 健康管理, 大健康产业, AI健康管理师, 大模型
<br>
<br>
总结: 在大健康产业蓬勃发展的背景下，AI健康管理师作为一种创新科技，将大模型与健康管理相结合，通过认知行为疗法帮助用户强化自我健康管理的动机和能力。该项目致力于消除用户在饮食、运动、睡眠和情绪方面的不合理信念及非适应性行为。AI健康管理师将嵌入私域中，以主动对话的形式与用户沟通并产生健康策略，通过环环相扣的产品链条和拟人化的交互方式，帮助用户建立符合自身需求的健康管理办法。然而，在应用大模型的过程中，创业者需要避免陷入“技术自嗨”和商业落地的陷阱。 </div>
                        <hr>
                    
                    <p>“腰间的赘肉咔咔掉，人鱼线马甲线我想要。”无论你是否跟着刘畊宏跳过健身操，你一定听过这一句台词。后疫情时代，大众的健康意识进一步提高，具体表现为从过去的寻医问药转向更为全面的健康管理。</p><p>新华社此前报道中曾提到，中国将成为全球健康产业的最大市场。在国务院提出的《“健康中国2030”规划纲要》则明确指出，到2030年，中国健康服务业总规模将达16万亿元，未来在我国经济结构向服务业转型过程中，大健康产业将成为我国国民经济支柱型产业。</p><p>一边是大健康的磅礴市场，另一边是汹涌而来的大模型浪潮席卷各行各业，如何将创新科技与大健康产业做结合成为行业人士思考的关键。</p><p>事实上，随着国内外科技厂商纷纷押注大模型，以医疗健康为代表的垂直领域也迎来了一次技术和应用范式的革新。此前，谷歌发布了医疗大模型Med-PaLM，用于处理包括文本、图像和基因组学数据在内的多种医疗健康数据。放眼国内，百度、叮当健康、京东健康等多家企业相继发布医疗健康大模型，用于求医问诊或医疗数字化改革。大厂之外，创业者也在找寻新的机会。</p><p>近期，在36氪AI协同创新中心联合AI开发平台Colingo共同发起的我爱黑“可颂”大语言模型应用创新挑战赛中，北京数智兴华科技有限公司（以下简称：数智兴华）以大模型为底层逻辑的“AI健康管理师”项目夺得优胜奖。该项目通过以预防和干预亚健康、慢性病问题为目标，以认知行为疗法为指导，基于对话式AI帮助用户强化自我健康管理的动机和能力，致力于消除用户在饮食、运动、睡眠和情绪方面的不合理信念及非适应性行为。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_e034172607c54d2a894f4d6784fd4e48@577536001_oswg631283oswg1320oswg902_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源数智兴华</p><h2><strong>认知决定行为，AI加持下的大健康三重跳</strong></h2><p>“我知道我的广告费有一半被浪费了，但我不知道究竟是哪一半。”将广告营销领域中这句堪称经典的名言，套用至当下的大健康领域也非常适用。</p><p>在实际的健康管理中，开始做健康管理容易，但如何长期坚持下去对不少用户来说却十分困难。这是因为，健康管理本身就是反人性的行为，用户很容易掉入知易行难的思维陷进中。世界卫生组织曾发布一套健康公式，100%健康=15%生物遗传+17%环境因素+8%医疗条件+60%生活方式，生活方式是健康管理过程中的主要影响因素，但究竟要如何找到合理的生活方式，并且长期坚持下去？</p><p>从解决上述问题入手，数智兴华团队决定用AI健康管理师来替代传统的机器人问答式的服务。在他们看来，用数字化工具+认知重塑+行为改变能够帮助用户建立一套符合自己需求的健康管理办法。并且在后续的服务过程中，AI健康管理师还会根据用户的行为习惯进行及时的反馈调优，保证用户能够完成健康管理的重塑。</p><p>数智兴华打造AI健康管理师的运行逻辑是，借助于大语言模型强大的内容能力，可以让传统的对话机器人完成三重跳。</p><p>第一是由表层到底层的改变：传统的AI健康管理师依靠药物治疗，头痛医头脚痛医脚，但数智兴华采取的是非药物治疗，强调的是用户自己认识到健康管理的重要性，这是从底层的认知行为改变而去驱动用户行为的改变。</p><p>第二是由局部到整体：在健康管理中，数智兴华的AI健康管理师不止关注用户某一处的身体因素，还会注重心理健康和社会因素的影响，并及时地与用户沟通进行情绪疏导。</p><p>第三是预防为主，教育用户：对话式的内容与用户构建交流窗口，同时配合一些预防策略引导用户主动做健康管理。</p><h2><strong>产品将嵌套私域中，年底推出第一版应用</strong></h2><p>在数智兴华的规划中，AI健康管理师将会嵌入私域中，以主动对话的形式与用户沟通并产生健康策略。“这更像是你私人健康教练和心理咨询师，甚至是你的一个朋友。”北京数智兴华科技有限公司创始人彭博说道。</p><p>但为了精确做到每位用户都能有针对性的方案和后期正反馈，数智兴华为此将产品的链条做得相对较重。比如，在用户正式开始之前先做动机访谈，了解用户真正要做健康管理的原因，评估用户对改变生活方式的准备程度，针对性生成谈话式的内容干预，在后期的使用过程中，又会根据用户实际的反馈行为进行适时调优和结果再干预，并结合用户的心理和改善情况生成有针对性的对话，去挖掘用户背后的底层认知，进而去辅导用户以认知改变行为习惯。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_ca41974c6767437e859154a63777e9ac@577536001_oswg172301oswg1820oswg1364_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源数智兴华</p><p>从产品链条方面，数智将其做到环环相扣相对较重，但从实际的用户行为旅程来看，这个产品又做得很轻。由于数智兴华是想做私域的AI健康管理，这可以内嵌至微信或者小红书等社交平台的对话框中。AI健康管理师每天会主动向用户发起对话，并在三到五分钟内完成今日的健康规划，去引导用户改变自己不合理的认知模式和生活方式习惯。</p><p>这种拟人化的产品与目前传统数字化工具的用户自使用、单向反馈相比，更容易赢得用户的信任。目前，数智兴华将AI健康管理师的智能Agent搭建完成，通过语言内容方面更具人性化，拉近用户距离，预计年底将会逐步面向体重管理、职场减压、失眠、慢性病管理等具体场景推出针对性应用。</p><h2><strong>避免掉入大模型商业化落地的陷阱</strong></h2><p>尽管生成式AI对未来软件研发模式、应用交互形态甚至是工作方式都将产生颠覆性影响，但如何避免创业者在帮助企业找痛点的过程中陷入“技术自嗨”，是技术与商业落地过程中存在的天然沟壑。</p><p>36氪AI协同创新中心在与诸多创业者交流过程中发现，许多项目在运用大模型的过程中只是简单的调用，并没有对其进行核心功能演示和结果的可行性验证。此外，大模型能否完美契合B、C两端的需求，在B端降本增效，在C端解决痛点，也是众多创业者初期容易掉入的陷阱。</p><p>因此，大语言模型创业者在实际的产品搭建过程中要思考AI大模型在其中扮演的角色问题。在路演结束后，数智兴华向36氪AI协同创新中心表示，数智兴华的大模型产品主要希望解决能不能读懂用户提供的信息、能不能记住用户的信息、能不能干预用户的行为习惯的三个问题。</p><p>能不能读懂用户信息是产品开始时的第一步。因为用户输入的信息不仅是单一的文字内容，图片、语义等复杂的情境也需要大模型去理解用户背后的多维情绪。健康管理本身就是长周期的事，记住用户信息则考验的是AI健康管理师能否根据用户过往提供的信息和阶段性反馈，及时地动态调整策略。而能不能干预用户行为习惯，则是帮助用户认知重塑进行行为调整和情绪调节，并根据用户状态描摹出用户状态，灵活地决定调用执行策略。</p><p>当然，大模型发展突飞猛进，但其商业化落地仍然任重而道远。想让技术创新转化为真正的价值，不仅仅是如何实现的问题，更重要的是要让技术与实际的需求和场景紧密结合。要实现这一点，大模型应用创业者们必须深入到用户使用和场景的细节，理解需求逻辑，解决实际的问题。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547653010904196</id>
            <title>人民币回升，上千家上市公司启动套保</title>
            <link>https://www.36kr.com/p/2547653010904196</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547653010904196</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:56:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人民币汇率, 外汇衍生品交易, 套期保值, 汇率风险
<br>
<br>
总结: 近期人民币汇率回升，多家A股上市公司为了规避汇率风险和锁定成本，开展外汇衍生品交易或套期保值业务。上市公司参与衍生品交易主要是为了套期保值，其中汇率风险是最大的风险之一。然而，外汇套保并非完全可靠的策略，也存在一定的风险。因此，我国衍生品交易市场需要进一步完善监管和风险防范措施。 </div>
                        <hr>
                    
                    <p>近日，人民币汇率持续回升。Wind数据显示，11月，在岸、离岸人民币对美元汇率分别调升2.55%、2.70%，幅度较大。为锁定成本，规避和防范汇率、利率风险，多家A股上市公司开展外汇衍生品交易或外汇套保业务。</p><p>12月4日，澳弘电子（605058.SH）公告，将选择适合的市场时机开展外汇衍生性商品交易业务，从而有效避免汇率或利率大幅波动导致的不可预期的风险。</p><p>同一天，华工科技（000988.SZ）12月4日发布公告称，为满足公司及控股子公司日常经营使用外币结算业务的需要，规避外汇市场的风险，加强对外币资产头寸的监控和管理，同意公司开展总额度不超过人民币3亿元(含)的外汇衍生品套期保值业务。</p><p>此前，网宿科技（300017.SZ）12月1日也发布关于继续开展以套期保值为目的的金融衍生品交易业务的公告，根据公司实际情况，将用于外汇衍生品交易的额度调整为不超过人民币5亿元或等值外币。</p><p>上市公司参与衍生品交易越来越多，大多数是为了套期保值。据中国上市公司协会数据，2023上半年，共有1003家A股上市公司发布衍生品使用信息相关公告，同比增长13.0%。其中，使用目的为套期保值的有985家，旨在投机（投资）的有3家，兼具套保、投资目的兼具的有15家。</p><p>时代财经发现，上市公司在汇率风险上的套保意愿最大。2023上半年，在五大类风险中，共有856家公司的套保相关公告中提及汇率风险对冲。其次是利率风险和商品价格风险。</p><p>不过，外汇套保并非万全之策。博威合金（601137.SH）2022年财报显示，当年交易性金融资产造成3496.17万元损失。博威合金在上证e互动平台告知投资者称，2022年交易性金融资产产生的损失，主要是公司为应收外汇款余额所做的套保，2023年公司管理层将根据应收外汇款余额的敞口继续做套保管理。</p><p>另外，在上证e互动平台上，一位投资者向永冠新材（603681.SH）提问，公司在期货市场进行外汇套保行为，是否存在套保过量，变成市场投机的行为，毕竟单纯的套保理论上是保证了公司的一定的盈利值的。</p><p>永冠新材在12月4日回复该投资者称，公司主营业务一直以出口为主，近3年，主营业务中外销占比一直保持在70%左右，因而公司面临一定的汇兑风险和信用风险。永冠新材目前主要采用远期锁汇和出口信用保险管理汇兑风险和信用风险。</p><p>随着汇率衍生品需求的增长，我国衍生品交易相关市场亟需进一步完善。</p><p>11月17日，证监会就《衍生品交易监督管理办法（二次征求意见稿）》公开征求意见，着力解决以下问题: 一是落实《期货和衍生品法》要求，加强衍生品市场行政监管；二是完善监管规则，严厉打击以衍生品为“通道”规避证券期货市场监管的行为；三是加强跨市场和跨境监测监控，严防风险。</p><p>业内人士告诉时代财经，目前我国已经推出一系列汇率衍生品，如远期结售汇、外汇掉期、期权等，但仍有改进空间。一方面，应继续完善汇率衍生品的种类和交易机制，满足市场多元化的需求；另一方面，要加强市场监管和风险防范，确保市场的稳健发展。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI0NzQ4OTIyMQ==&amp;mid=2247518816&amp;idx=4&amp;sn=3c4ee9f4c77e7c1b70299ae1b28a4ba8&amp;chksm=e9adfdcadeda74dc6d8cdef3fec643c5eb8807ea1a2dde440404a942d75fbc847eee7dc6e900&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“时代财经APP”（ID：tf-app）</a>，作者：罗东骏，编辑：卢泳志，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547640530408584</id>
            <title>中国AI大模型，应该如何商业化？</title>
            <link>https://www.36kr.com/p/2547640530408584</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547640530408584</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:55:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型商业化, 商业模式, 安全性, 非盈利
<br>
<br>
总结: 当前大模型商业化的路径需要解决底层问题，不仅仅是商业模式的探索，还包括安全性和非盈利问题。大模型商业化的迅速推进可能会忽略安全性和伦理性问题，导致商业化与非盈利之间的矛盾。在中国市场，大模型厂商可以通过将大模型集成到现有产品和服务中，或者采用订阅服务的方式进行商业化尝试。然而，大模型商业化仍面临着资金投入、伦理道德和安全性问题、市场接受度和应用场景等挑战。同时，商业模式的成熟度和国际竞争力也是需要解决的问题。大模型商业化可以采用MaaS模式、开源模式和平台即服务模式等不同的商业模式。 </div>
                        <hr>
                    
                    <blockquote><p>虽然大模型商业化的路径较为清晰，目前国内厂商也都在积极探索，但大模型的商业化之路，不能仅限于商业模式的探索尝试，更在于解决大模型发展的底层问题。</p></blockquote><p>如今，大模型的商业化问题再次被摆在台面上。</p><p>一个事实是，当下的大模型训练需要强大的算力支撑，尤其是参数量大的模型，花费极大。比如OpenAI的语言模型GPT-3，成本接近500万美元，也就是人民币4000万左右。庞大的模型训练需要巨额的资金来支持。</p><p>投入了巨额资金之后，企业一方面是希望尽快商业化来解决后续研发资金的问题，一方面也是希望通过商业化来达到赚钱的目的。</p><p>那么矛盾也接踵而来，迅速的商业化，难以避免的是一些安全性、伦理性的问题被暂且搁到一边，更为真实的情况是，如今大模型迅速商业化之后的发展路径思考的其实并不多，因此也就看到了很多大模型基本上就是浅尝即止，<strong>最后引发商业化与非盈利之间的矛盾。</strong></p><p>OpenAI前段时间的“宫斗”，便是一个很好的例证。</p><p>11月18日，OpenAI管理层发生巨变，CEO奥特曼被解雇。至此，OpenAI“宫斗”上演。</p><p>在公开报道中，OpenAI的六人董事会中，被开除的奥尔特曼和Greg Brockman倾向加速商业化，以获得更多资金来支持AI模型的算力需求；而独立董事Tasha McCauley和Helen Toner更关注AI的安全。</p><p>简言之，<strong>一方以技术为主导，追求模型的卓越性，以实现通用人工智能为目标；一方则认为商业化是公司发展的必经之路，</strong>应该积极拓展市场应用，从而实现盈利为目标。由此，一个猜测是，倡导商业化的阿尔特曼碰到了强调AI技术、安全属性的Ilya Sutskever，直接正面引发了冲突。</p><p>经过反反复复地拉锯。11月30日，OpenAI宣布组建新初始董事会，Sam Altman重新担任CEOMira Murati担任首席技术官。这次“宫斗”胜利者似乎属于商业化的那一方。</p><p>但在这场由世界顶级大模型公司引起的“商业化与非盈利之争”的闹剧下，引发的一些问题使人陷入深思，即大模型的商业化正面临着哪些困局？大模型应该如何商业化？</p><p>而在中国市场，大模型厂商除了已经展现出来的算力层面商业价值外，还可以在哪些方面进行商业化尝试？以及，这条路已经走到哪了？</p><h2><strong>大模型商业化众生相</strong></h2><p>在大模型的商业化方面，以百度、阿里、腾讯等为代表的互联网厂商，目前商业化前景较为清晰。<strong>这一点与其自身庞大的业务体系不无关系。</strong></p><p>即互联网巨头可通过将大模型集成到现有产品和服务中，比如百度文库文档助手、淘宝问问、Bing搜索引擎等，来<strong>增加用户粘性并带动营收增长。主要方式是将生成式AI作为辅助功能，嵌入原有业务，视为一项增值服务。</strong></p><p>其次是订阅服务，即采用按月或按使用量计费的订阅模式，为客户提供持续的大模型访问权限。例如OpenAI的ChatGPT、百度等文心一言、阿里的通义千问等。<strong>目前国内文心一言等也在通过订阅制的商业模式，为大模型应用带来一些营收，但其他厂商收费意向不明。</strong></p><p>此外以智谱AI这类国家队厂商为代表的商业化前景亦比较清晰。业内普遍认为，<strong>诸如国内大型企业、央国企想要与大模型结合，智谱AI是一个绕不过去的选项。</strong></p><p>但尽管如此，国内大模型商业化仍处于初级阶段，商业化进程面临着诸多挑战。</p><p>首先，大模型的研发和应用需要大量资金和时间投入，而回报却往往难以预测。这导致许多企业在商业化过程中犹豫不决，错失市场机遇。</p><p>其次，大模型的伦理道德和安全性问题也给商业化带来了一定的压力。例如，算法偏见和歧视、数据泄露和滥用等问题时有发生，这使得一些企业在大模型应用方面持谨慎态度。此外，国内大模型商业化还面临着市场接受度和应用场景等问题。</p><p>目前，大部分企业的应用需求主要集中在智能客服、智能推荐、智能营销等领域，<strong>其他领域的应用仍处于探索阶段。</strong>这使得大模型商业化进程相对缓慢，难以实现规模化发展。</p><p>更值得注意得是，尽管国内在人工智能领域取得了显著进展，但与国际领先水平相比，国内的大模型技术还存在一定差距。<strong>这使得国内企业在国际市场竞争中处于劣势地位，也就很难向出海、跨境方向延伸。</strong></p><p>此外，国内大模型商业化还面临着商业模式不成熟的问题，比如如何收费，以目前国内普遍采取的算力收费形式而言，这种模式似乎与云计算的收费模式一致，<strong>而从利润率来看，这显然不是一个优质的收费模式。</strong></p><p>对于国内的大模型厂商而言，商业化的路如何走成为当下亟待解决的问题。</p><h2><strong>MaaS、开源与Agent</strong></h2><p>大模型的商业化，应该解决的是让企业和用户更少了解原理，更简单直接使用成果，让用户回归价值和自身业务问题解决。<strong>换言之，也就是大模型的“一体化黑箱模型”。</strong></p><p>因此，如今的一些商业模式成为了大模型赛道玩家和创业者们的聚集之处。</p><p>其中，<strong>MaaS模式是最为常见的一种。</strong>在这种模式下，一般是由云厂商或科研机构对大模型封装，在各类任务上的推理能力封装成统一的应用程序接口，对外提供服务的模式，虽然提供的是API，但是本质上调用的是模型。</p><p>下游企业可以获得这些接口，并按照自身的业务需求，调用服务嵌入已有的应用和服务中，让大模型的API为整个程序进行赋能。</p><p><strong>这种方式使得企业不需要过多了解模型的技术细节，而是像调用云能力一样，直接调用服务。</strong>目前、文心、通义、盘古等大模型厂商，基本都在提供此类服务，比如阿里的魔搭社区，百度的飞桨等等。</p><p>此外，<strong>开源模式</strong>也是大模型商业化的一种重要方式，在这种模式下，计算机程序、软件的源代码等内容公开，并根据开源协议进行分发的方式。</p><p>开源是目前计算机领域一种普遍的软件开发模式，大量开发者在协议许可的情况下对开源代码进行修改，并集成到已有的系统中，为软件和系统增加新功能和特性。</p><p>在开源的模式下，可以快速共享好成果，让好的成果快速培养社区，下游用户利用开源成果，可以快速搭建自己的应用系统。在国内，智谱AI、阿里通义都在强调开源的价值。</p><p><strong>开源本身是免费，但涉及到后续的数据训练、数据监督、数据微调等等，则对应的是较为明朗的收费模式，恰等同于开放井水，但做卖铲子的人。</strong></p><p>再有就是<strong>平台即服务模式</strong>，即不再提供单一的模型API，而是<strong>将大模型当作平台服务中的一种技术，</strong>集成到AI平台上，通过统一的平台对外提供服务。这种模式中，企业构建包含开发工具、AI服务、流程化的平台，而大模型只是平台中的一个组成部分。</p><p>用户购买或使用平台的过程中，可以利用平台提供的工具，对大模型进行开发和应用，集成于自有的体系中，用户不能单独获得模型的能力。用户通过使用平台和工具，获得利用大模型开发的能力，也因此付费。</p><p>例如，文心大模型已经发展出了NLP/CV/跨模态/生物计算大模型，并且在此基础上，推出了众多行业大模型、大模型套件。向上又有Easy-DL、BML大模型、大模型API、文心一格（AIGC）等。</p><p>还有一种<strong>软件即服务</strong>的模式。目前国内大厂、头部政企和科研机构，正在提供强大的新基建，<strong>中小厂商可以基于这些基建，开发自己的saas服务，并提供给企业、个人。AI Agent便是当下炙手可热的大模型创业路径。</strong></p><p>此外，无论是对于OpenAI、Meta这样的AI领头企业，还是对于众多的小型初创型企业或者科技极客来说，<strong>AI Agent也更是如今商业化不得不谈的话题。</strong>不论是钉钉、飞书，亦或者是百度，都在推出自己的Agent产品。</p><p>如果说前面所说的众多变现都在B端，其市场和需求量有一定的天花板。那么，AI Agent则对应的是B端市场之外，在C端的巨大想象力。不仅市场本身，更在商业价值。</p><p>如今，一个业内普遍共识是，<strong>AI Agent是未来实现终极的AGI（通用人工智能）形态的必经之路，</strong>而且越来越多的人认识到，大模型只有在真正的应用层面走进千家万户，才能展示其真正的价值，而AI Agent就是最好的应用形式。</p><h2><strong>商业化难在哪？</strong></h2><p>总体来看，大模型商业化的路径尽管未能做到最好，但方向是清晰。不过清晰并不意味着能落地。对于国内大模型赛道的玩家而言，仍面临诸多内外部的挑战。</p><p>11月7日的凌晨，OpenAI在首届开发者大会上发布了几个更新，新的模型GPT-4 Turbo、GPT Builder以及Assistant API。</p><p>其中，GPT Builder的特性包括每个人/每个企业都可以定制属于自己的GPT；每个独特的GPT可定制自己的指令、知识库、工具与动作、头像等；无需开发，直接使用自然语言定制，你甚至可以让Dalle3帮你生成头像；GPTs可以分享使用，并享受类似App Store的分成。</p><p><strong>这意味着，每个人/企业都可以在线创建自己的GPT/Agent。</strong></p><p>而另一个更新Assistant API，可通过API来让GPT来帮你编写代码并自动执行；通过API实现函数/工具调用的能力，扩展AI的能力。</p><p>这意味着用户可以更轻松的通过Assistant API在自己的网站或者移动应用中构建自己的ChatBot或者AI助手，大大减少AI开发的繁重工作量。</p><p>一个事实是，<strong>其不再满足于提供基础大模型，而是希望成为AI时代的AI OS平台。这一更新很大程度上给AI Agent的售卖模式带来了不小的冲击。</strong></p><p>而在开源模式上，同样存在着发展的瓶颈。以智谱AI为例，目前智谱AI开源的模型参数主要为6B，参数较小。究其原因，离不开资金不足的难题。要知道模型参数越大，意味着算力需求越大。虽然智谱AI早在此前就购买了大量的A100，但从其近期频繁且高额融资来看，其仍需要大量资金支撑其持续的商业化和研发创新。</p><p>在MaaS模式上同样也存在许多落地的难题。首先，如果模型效果不尽如人意，API将无法充分满足用户的常规推理需求，因此需要根据具体情况对模型进行调整和优化，但调优本身是一个具备门槛的开发，大部分企业不具备这样的能力或大模型人才，<strong>也就很难持续为MaaS社区贡献活跃度。</strong></p><p>其次，由于大模型的运行速度相对较慢，当推理请求的数量或请求数据量大幅增加时，API的响应时间和数据质量将难以保证。例如，像ChatGPT、DALLE2等AIGC应用，其实际反应时间往往较长，因此难以在短时间内实现大规模应用和提供及时响应体验。</p><p>总体而言，<strong>全球大模型产业商业化仍处于早期探索阶段。</strong></p><p>一方面，虽然研发机构在大模型技术方面已经相当成熟，但对于落地场景却还不够熟悉，尚未形成完善的商业化模式。因此，它们需要与下游场景企业合作，共同构建大模型的商业模式。</p><p>另一方面，大部分下游场景企业对于大模型的基本概念和认知尚未形成，同时，它们也缺乏支持模型微调所需的算力，以及定制和二次开发模型所需的人力资源和技术实力。</p><p><strong>总体来看，虽然大模型商业化的路径较为清晰，目前国内厂商也都在积极探索，但大模型的商业化之路，不能仅限于商业模式的探索尝试，更在于解决大模型发展的底层问题。</strong></p><h2><strong>写在最后</strong></h2><p>一个事实是，大模型真正的价值在于能够解决实际问题并创造商业价值，场景是商业模式的基础。对于大模型赛道的玩家而言，<strong>如何将大模型与具体场景结合，成共落地，才是商业化的本质。</strong></p><p>以OpenAI的GPT-3为例，这款语言模型以其较强的生成能力和广泛的应用潜力吸引了全球的目光。</p><p>然而，如果没有合适的场景和应用，这个工具只能停留在理论层面或实验室环境。只有当它被成功地应用于各种场景中，才能发挥出真正的商业价值。</p><p>Copy.ai是一家使用GPT-3的大规模语言模型来帮助企业和个人快速生成高质量内容的初创公司。通过深入了解客户的需求和市场情况，Copy.ai将GPT-3的技术能力与营销、广告、新闻稿等应用场景紧密结合，实现了从技术到产品的转变。这种“场景为王”的策略使得Copy.ai能够在竞争激烈的市场中脱颖而出，成为了一家备受瞩目的创业公司。</p><p>在国内，这样的尝试或将成为下一个阶段的主题。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzIwMTUyNjcxNw==&amp;mid=2647720219&amp;idx=1&amp;sn=eb5340c4907745b74c3f3c3cf5aa506f&amp;chksm=8ec93dc9b9beb4df6706904a928bc427d5fee76ac94c96e0963012916562d9f612502555499e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“产业家”（ID：chanyejiawang）</a>，作者：斗斗，编辑：皮爷，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547641871441796</id>
            <title>大模型时代，AI芯片行业上演“三国杀”，国产厂商机遇何在</title>
            <link>https://www.36kr.com/p/2547641871441796</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547641871441796</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:55:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, 英伟达, AI芯片, 生成式AI
<br>
<br>
总结: ChatGPT的爆火使得英伟达成为全球AI淘金时代最大的卖铲人，其在2024财年三季度实现了创纪录的营收和净利润增长。然而，在AI芯片领域，越来越多的厂商开始发力，包括亚马逊云科技、微软、华为、百度等巨头以及寒武纪、壁仞等小而美的独角兽。自研AI芯片已成为产业发展的趋势，而生成式AI市场的潜力也吸引了更多的玩家。国内厂商在AI芯片行业发展面临重要机遇期，能否实现弯道超车还有待观察。 </div>
                        <hr>
                    
                    <p>ChatGPT爆火迄今，英伟达不仅被公认为全球AI淘金时代最大“卖铲人”，也成为各大媒体和社交平台上讨论度最高的一家AI芯片公司。</p><p>近日，英伟达发布的2024财年三季报显示，其营收达到创纪录的181.20亿美元，同比增长206%，环比增长34%;净利润再创新高，达到92.43亿美元，同比增长1259%，环比增长49%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_ba60c0b7548040cb91c2e6f28942f6f8@813924438_oswg296901oswg692oswg387_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但在科技领域，永远不可能一家独大，随着AI热潮持续升温，越来越多厂商也开始在AI芯片领域发力，前有亚马逊云科技、微软、华为、百度等下游客户推动自研芯片，后有寒武纪、壁仞等小而美的AI芯片独角兽，都奋力争夺登上前往AI时代的一张船票。</p><h2><strong>巨头扎堆涌入AI芯片赛道</strong></h2><p>今年以来，现在国内有多家公司均在开发自己的大模型，由于担心美国的芯片管制会升级导致英伟达高性能计算芯片断供，国内互联网厂商不得已只能竞相囤积A800芯片，因为谁都不想在人工智能竞赛中落后。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_629fea059b9045f9be4d2425a058e79a@813924438_oswg507996oswg692oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>知情人士透露，百度、字节跳动、腾讯和阿里巴巴已向英伟达订购了价值10亿美元的订单，采购约10万个A800芯片将于今年交付。另外，他们还订购了价值40亿美元的芯片将于明年交付。</p><p>这也使得英伟达成为生成式AI领域最大的赢家，凭借在生成式AI领域“一卡难求”GPU，英伟达已经赚得盆满钵满，市值更是飙升到1万亿美元。彭博报告显示，随着OpenAI的ChatGPT等服务的涌入，在未来十年内，生成式人工智能市场有望从2022年的400亿美元激增至1.3万亿美元。这也让整个行业吸引来更多玩家。</p><p>众所周知，自研AI芯片是一个产业走向成熟绕不开的趋势，但凡哪个厂商AI运算的体量大幅度提升，就需要自家的芯片来支撑，这样才能达到最高的优化。</p><p>尤其在数字经济时代背景下，鉴于人工智能领域史无前例的市场前景，打造自有芯片产业链，已经成为国内外科技巨头的战略布局。像谷歌、微软、亚马逊这样的软件和云计算服务巨头加入芯片竞争，势所必然。</p><p>12月1日，亚马逊云科技(AWS)在2023 re:Invent全球大会上宣布其自研芯片家族的两个系列推出新一代，包括Amazon Graviton4和Amazon Trainium2，为机器学习训练和生成式人工智能应用等广泛的工作负载提供更高性价比和能效。其中，Graviton4与当前一代Graviton3处理器相比，性能提升高达30%;Trainium2与第一代Trainium芯片相比训练速度提升多达4倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_269e629961ae451abd5ba043c4dbda7f@813924438_oswg359062oswg691oswg389_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>11月15日，微软在西雅图举行的Ignite开发者大会上，推出加速AI计算任务的Maia芯片。Maia芯片旨在运行大型语言模型，该芯片的构建方式与英伟达使用的网络连接技术也有所不同，Maia芯片与标准以太网电缆连接在一起。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_35ce37c668524d7780ebff64e30522b0@813924438_oswg163834oswg692oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>8月29日，谷歌在旧金山的年度云会议Google Cloud Next上也发布了新的人工智能芯片，即第五代定制张量处理器(TPU)芯片TPU v5e，用于大模型训练和推理。与上一代芯片相比，TPU v5e每一美元的训练性能提高2倍，每一美元的推理性能提高2.5倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_9de28bc7af17475fa184dffc86610e2d@813924438_oswg309079oswg692oswg532_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>元宇宙新声认为，芯片可能会在未来很长一段时间都是AI竞争的核心，包括国家、巨头、初创公司之间。但行业发展还处于初期，未来肯定会有一轮洗牌。</p><h2><strong>AI芯片行业，国内厂商能否弯道超车</strong></h2><p>随着全球竞争加剧，我国AI芯片行业发展面临重要机遇期。</p><p>数据显示，2021年我国AI芯片市场规模达到427亿元，同比增长124%;2022年这一市场规模达到850亿元，再现翻倍式增长。中邮证券预计，到2023年，我国AI芯片市场规模将进一步扩大至1206亿元。</p><p>事实上，我国对人工智能芯片产业的发展高度重视，制定了一系列扶持政策，营造了有利的政策环境，促进了行业的快速发展。</p><p>近年来，国家陆续出台了多项政策，鼓励AI芯片行业发展与创新，包括《国家新一代人工智能发展规划》《关于深化“双创”促进大众创业万众创新若干政策的通知》等。</p><p>北京、上海、深圳等重点城市都陆续发布了支持人工智能产业快速发展的政策，其中包括攻关AI芯片创新突破、加强AI芯片、智能传感器研发攻关、加速智能算力建设等方面的内容。</p><p>英伟达CEO黄仁勋曾表示：“中国有很多GPU的初创公司，不要低估中国在芯片领域的追赶能力。”</p><p>从国内芯片厂商的现状来看，既有华为这样全产业链路齐头并进的巨头厂商，也有像寒武纪专注于AI算力芯片的厂商，还有专注在通用计算芯片摩尔线程等，这也体现出国内芯片厂商在支持大模型更加智能化的同时，也迎来了行业的“百花齐放”。</p><p>不久前，华为在全联接大会上发布了全新架构的昇腾AI计算集群——Atlas 900 SuperCluster，据了解，该AI集群支持超万亿参数的大模型训练，采用全新的智算交换机以及超节点架构。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_3057778ada1042299e14922db3e00580@813924438_oswg181003oswg693oswg395_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在任正非的访谈中，他提到目前华为AI集群能力已经不弱于美国。“华为现在的AI集群已支持16000板卡，将来的一个超节点集群可管理几十万板卡。支持超高速互联、超高效的液冷散热、瞬时爆发式供电，达到系统高可用。”</p><p>整体来看，华为推出了面向通用计算的鲲鹏系列，面向AI计算的昇腾系列。在架构方面，华为推出了自研达芬奇架构。在软件上，华为推出了openEuler开源OS以及配套的数据库、中间件，涵盖从硬件、架构、框架、应用、开发运维工具等全产业链条。</p><p>而寒武纪拥有的AI芯片产品为云端AI芯片和边缘AI芯片。其中，思元370是寒武纪第三代云端智能芯片，是寒武纪首款采用Chiplet(芯粒)技术的人工智能芯片。景嘉微是国内GPU龙头，拥有的AI芯片产品为GPU芯片。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d7ee8caa96ba41a0a2e741dd80bc3175@813924438_oswg273888oswg692oswg404_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，摩尔线程则全面布局GPU领域，现在他们已推出苏堤、春晓等多颗GPU芯片，其中春晓是其第二颗产品，集成220亿颗晶体管，内置MUSA架构通用计算核心以及张量计算核心，可以支持FP32、FP16和INT8等计算精度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_08368970ef394ec4832a2ff8a047e17b@813924438_oswg447640oswg692oswg453_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前来看，在国际高端AI芯片面临被“逼退”之际，国产AI芯片无疑成为最佳替代选择。近年来，在地缘政治影响下，我国本土AI芯片产业已取得一定发展成效，部分产品甚至可对标国际企业同类产品。</p><p>不过，需要注意的是，AI芯片硬件性能只是一个方面，想要让国产芯片能用起来，软件能力会是更重要的壁垒之一。算力的释放需要复杂的软硬件配合，才能将芯片的理论算力变为有效算力。</p><h2><strong>正视差距，生态仍是破局难题</strong></h2><p>我们看到，目前国内第一批大模型厂商使用的基本都是英伟达A100、A800的芯片，这不仅是英伟达产品性能更强，还因为他们构建了完善的CUDA生态。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_17d3ddc773284004beac018e27b97e5e@813924438_oswg94733oswg692oswg389_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>CUDA就是英伟达推出的基于GPU的并行计算平台和编程模型，可以用来加速大规模数据并行计算，使得GPU可以用于更加广泛的科学计算和工程计算等领域。CUDA的良好生态系统吸引了众多学术机构和高性能计算中心的关注和使用，也为英伟达提供了强有力的市场竞争优势。</p><p>一位分析师告诉元宇宙新声：“经过多年的建设，英伟达的CUDA已经有400万开发者，基本形成了垄断态势的生态壁垒，而软件生态恰恰是下游客户最为重视的产品竞争要素。”如果贸然更换生态，意味着厂商学习成本、试错成本、调试成本都会增加。</p><p>不过，面对英伟达CUDA的强势地位，国内AI芯片头部厂商如海光、华为和寒武纪等，也在不断基于自身产品和解决方案，打造生态体系。</p><p>比如，海光的DCU产品深算系列采用了兼容通用的“类CUDA”环境;华为的昇腾系列采用自研的达芬奇架构，大模型厂商在使用相关芯片时，需要提前针对软硬件进行调配和优化;寒武纪的产品虽然包含了云端和边端芯片，但由于其ASIC的芯片架构，对通用性计算而言，ASIC芯片的成本优势并不明显。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_1d56418222474d7f904499e1b6deacbb@813924438_oswg758590oswg692oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然国内AI芯片行业的生态建设与CUDA还存在着不小的差距，但我们已经看到厂商们在行动，在复杂的国际贸易关系及地缘政治因素等驱动下，“国产替代”成为国内半导体行业发展的主旋律。</p><p>当前，芯片已经成为半导体行业中最具有发展潜力的领域之一，AI芯片作为推动芯片行业发展的核心市场，其行业价值无法估量，随着AI芯片技术的逐渐成熟，其应用场景逐步渗透到各类智能终端领域中，在我国科技发展中占据越来越重要的地位。</p><h2><strong>写在最后</strong></h2><p>元宇宙新声发现，在当下的算力领域中，英伟达代表的传统芯片厂商还是占据着统治地位，但以微软、亚马逊云科技以及谷歌等为代表的科技巨头也对于算力芯片这块“肥肉”虎视眈眈，再加上国内如华为、寒武纪等芯片厂商不断发力创新，打破壁垒，俨然成为行业新势力。</p><p>这也促使整个AI芯片行业“三国杀”局面初显，而且，这一局面随着AI时代的来临，“三国”将会“厮杀”得更加激烈，最终会是拥有先发优势的传统造芯势力继续一枝独秀，还是科技巨头们后来居上形成“反杀”，仰或是国内厂商实现弯道超车?</p><p>可以预见，AI芯片行业每向前走一步，都将挑动着科技领域的神经，这场“三国杀”的胜利将会属于谁呢?未来真让人期待。</p><p>本文来自微信公众号“Metaverse元宇宙”（ID:NFTMall），​作者：贾桂鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547710988162945</id>
            <title>性能直追GPT-4，5000个H100训成，DeepMind联创发全新一代大模型</title>
            <link>https://www.36kr.com/p/2547710988162945</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547710988162945</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:54:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: InflectionAI, AI模型, 性能, GPT-4
<br>
<br>
总结: InflectionAI发布了一款性能超过谷歌和Meta开发的模型，仅次于OpenAI的GPT-4。该模型名为Inflection-2，在多项基准测试中表现出色，击败了谷歌和Meta开发的其他模型。InflectionAI计划将该模型集成到聊天机器人Pi中，以提供更好的交流和信息获取能力。尽管性能优秀，但在与GPT-4的基准测试中仍然稍逊一筹。 </div>
                        <hr>
                    
                    <blockquote><p>Inflection-2最新发布！性能碾压一众大厂模型，仅输一手GPT-4，还要集成到Pi？</p></blockquote><p>最近，InflectionAI发布了全新的一款AI模型。</p><p>更炸裂的是InfectionAI对这款模型的评价——性能直超谷歌和Meta开发的两款模型，紧随OpenAI的GPT-4之后。</p><p>到底是什么样的表现让InflectionAI能夸下如此海口呢？</p><p>在介绍具体的模型性能以前，我们先来看看它的基本信息。</p><p>这款AI模型名叫Inflection-2，在多项标准的基准测试中，成绩碾压谷歌5月发布的PaLM Large 2模型，还在很多不同的项目中击败了Meta开发的LLaMA-2.</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_010a05e1d9e44353939fa85ba04dd00a@1743780481_oswg231887oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这么来看，InflectionAI确实可以有这个自信。</p><p>公司内部人员表示，总体而言Inflection的新模型是同类产品中性能最好的，可以说仅次于OpenAI发布的旗舰模型 GPT-4，而后者我们都知道，要大得多。</p><p>InflectionAI的首席执行官Mustafa Suleyman在接受采访时表示，「我们相信，我们只是处于下一步技术推进的起点，AI模型所展现出来的性能，以及即将出现的新功能确实令人震撼。」</p><h2><strong>集成到Pi？</strong></h2><p>除了新模型的发布，还有另外一个重磅信息。</p><p>相关人员表示，新发布的模型将很快集成到Inflection于5月份发布的聊天机器人Pi中。</p><p>CEO Suleyman也讲到，首先模型的集成还需要一些额外的工作，即「对齐」，技术人员会教它Pi的语气和回答风格，并帮助Pi在吸收最新信息时更好地发挥作用，而不会产生额外的幻觉。</p><p>「无论你想就种族、性别、政治、竞家OpenAI，或当下任何有争议的问题进行可能有那么点敏感的对话，Pi都会非常巧妙、谨慎地与你进行实事求是的交流，并实时在互联网上获取信息。Pi将很快更新出新模式。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a9abc05132e54438b79f673eb6e3be16@1743780481_oswg272643oswg1080oswg555_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Suleyman表示，不会太久。但是具体发布日期却没有明说。</p><p>同时，他也不愿意提供聊天机器人Pi的最新用户数量，但表示Pi非常受欢迎，用户留存率相当高。</p><p>要知道，两周前，OpenAI曾经披露其免费的ChatGPT服务的周用户数量已达到1亿。</p><p>当然，这之后还发生了我们耳熟能详的OpenAI董事会版宫斗，突然临时解雇了首席执行官Sam Altman（当然现在他已经回来了）。</p><p>不过，预计Pi发布后，InflectionAI的用户量也会有一波大规模的上涨。毕竟Inflection发布的大型语言模型号称是 当今世界上能力第二强的LLM。</p><p>相比LLM业内也会因为Inflection-2的发布继续出现动荡的局面。</p><p>此外，CEO Suleyman表示，Inflection AI在今年早些时候刚刚获得了一轮13亿美元的融资，不过这笔大额融资也并没有提前Inflection-2的发布。</p><p>不过，舆论场中有些声音还是传了出来，InflectionAI将会在年底发布新模型。但Suleyman表示，模型的训练已经结束，还有一些后续工作需要处理，所以发布时间出现了推迟。</p><h2><strong>性能吊打一众模型，只输GPT-4</strong></h2><p>为了训练Inflection-2，Inflection AI使用了5000个英伟达H100图形处理器（GPU），要知道，训练Inflection-2的前身模型，使用的是几千个相对比较旧的A100图形处理器。</p><p>Suleyman表示，新模型的训练速度更快、成本更低，但即便如此，还是能处理大量运算（10的25次方FLOPs）。</p><p>InflectionAI还与微软、英伟达和CoreWeave在进行紧密合作，管理其庞大的计算集群。</p><p>Inflection用一些专业级任务的流行基准（MMLU）测试了新模型的性能，该基准向模型提出了从各类世界知识到问题解决和道德规范等57个主题的各种问题。</p><p>下图即为Inflection-1（新模型的前身），Inflection-2，以及谷歌的PaLM 2之间的性能对比。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2f034bf9a949466fa4d82af8489e7557@1743780481_oswg74478oswg1080oswg576_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>我们可以看到，在HellaSwag、MMLU、TriviaQA Wiki、PIQA、GSM8K和ARC-C等六项基准上，Inflection-2都拔得了头筹。</p><p>Suleyman表示，Inflection-2的性能已经超过了最大的700亿参数版本的LLaMA 2、马斯克xAI的Grok-1、谷歌的 PaLM 2 Large和Anthropic的Claude 2，性能仅次于GPT-4。</p><p>报告显示，新模型在七项科学性回答的基准测试中，除两项外，均击败了LLaMA 2和PaLM 2模型，它还在三项问答任务基准测试中的两项测试中表现最佳，但在一项测试中输给了PaLM 2 Large。</p><p>此外，在四项数学和代码基准测试中，它的成绩依旧可圈可点，虽说这些领域和前面的测试比起来没那么是重点。</p><p>不过，在OpenAI已分享结果的两项基准测试中，它的成绩远远落后于GPT-4。</p><p>Suleyman继续介绍说，虽然除了AI研究人员和开发人员之外，这些基准测试对其他普通人来说可能并没那么重要，但微小的改进就能让笨拙的原型与生产级、可靠且高质量的模型截然不同。</p><p>总的来说，Suleyman认为Inflection-2在同类产品中可以说是规模最大的，与GPT-4非常非常接近。</p><p>从行动上，我们也可以看到InflectionAI对新模型的满意程度。公司规划显示，从现在起，Inflection就将把培训重点转移到下一个型号的模型上。</p><p>相关人士预测说，下一个型号的模型（大胆猜测是Inflection-3）将在六个月内达到刚聊完的新模型的10倍，而再过六个月，性能又将达到上一代型号的10倍。</p><p>一句话说明，就是InflectionAI的人有自信，在12个月内，让模型规模翻个一百倍。</p><h2><strong>个人助理「Pi」</strong></h2><p>对于不熟悉的朋友，咱们还是掉过头来再讲讲InflectionAI的个人助理「Pi」。</p><p>咱们可以这么说，CEO Suleyman的认知里，这一切都是很自洽的。</p><p>曾经，他还写过一本书《The Coming Wave》，全书有一个核心观点就是，未来AI能让人类彻底远离心理问题。</p><p>而Suleyman之所以有这样的论断，也许和他自己的经历有关：</p><p>1984年，他出生于伦敦北部，父亲是叙利亚人，母亲是英国人。他在贫困中长大，16岁时，父母分居，两人都移居国外，留下他和弟弟自谋生路。</p><p>后来他被牛津大学录取，学习哲学和神学，但一年后就退学了。</p><p>这种人生经历，让Suleyman格外关注人类的心理健康。当然，就少不了这一part和涌现出来的新技术的结合。</p><p>他的这番说法也绝不是空想，他创立的Inflection AI，目标就是开发出一个全能的个人助理，解决每个人在生活中可能遇到的几乎一切问题。</p><p>这个个人助理，就是「Pi」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_c9846d8c3a724d9082e4ea88a3a63a27@1743780481_oswg149840oswg840oswg438_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而这一切也是有理论基础的。</p><p>心理学还真有这个研究：聊天机器人相比人类有着更高的情感认知。</p><p>测试针对的是人类在不同场景下表现出来的同理心进行打分。测试对象被给予20种情感情境的详细描述，比如葬礼、职业成功或侮辱，并描述他们在这种情况下可能感受到的情绪。</p><p>情绪描述越详细、越容易理解，情绪意识水平量表(LEAS)得分越高。</p><p>研究人员使用与人类反应相同的标准来评估ChatGPT的反应，并将结果与先前在法国17至84岁人群(n = 750)中进行的研究进行了比较。</p><p>在进行的两次测试中，ChatGPT获得了85和98的高分，而人类的表现就完全被AI碾压。男性56，女性59分，甚至没有及格。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_86bac7a24c194b3e877be657c5c561a7@1743780481_oswg13424oswg640oswg272_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>很多研究结果都曾指出，AI聊天机器人在心理健康方面可以为人类提供其他任何工具都没法比拟的帮助。</p><p>可以这么说，相比于其他生产效率方面的应用，大语言模型似乎天生就更适合进行感情方面的理解和沟通。毕竟，人类之间传递感情，语言是最重要的载体。</p><p>那么，Suleyman创立的Inflection AI推出的个人助理「Pi」已经上线有几个月，表现究竟如何，大家心里可能也都有定论了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_3e08e88054294141ae6611b67e0e467b@1743780481_oswg20884oswg640oswg354_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>我们可以看到，Pi的登录界面还是非常简洁的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_8d23d6a6970e4fe6a56d2c018c8f2667@1743780481_oswg26610oswg640oswg396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>进入到Pi的聊天页面，点击左下角的田字格，可以看到官方为用户准备的几个常用场景。</p><p>每个场景相当于一个定制化指令，选择一个之后，就会自动给聊天机器人设定一个工作环境。</p><p>聊天机器人也会针对每个场景给用户一个开头的提示，比如选择了「motive myself」之后，系统会提示我要如何开始聊天。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_710a1b63159b4feea0b2d1c30332a056@1743780481_oswg7554oswg640oswg255_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>总而言之，「Pi」寄托了Suleyman的美好愿望。</p><p>而有了新模型Inflection-2的加持，相信「Pi」会迸发出更加不一样的火花。</p><p>说不定，真能充当心理咨询的角色呢。</p><h3>参考资料</h3><p>https://www.forbes.com/sites/alexkonrad/2023/11/22/inflection-ai-releases-2nd-model-on-gpt-4-heels/?sh=410d2f366b05</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/cIl7K8zx-x3duYEeogkjhQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：拉燕，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547633505506439</id>
            <title>写给小白的芯片半导体科普</title>
            <link>https://www.36kr.com/p/2547633505506439</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547633505506439</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:50:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 电子产品, 电路板, 芯片, 集成电路
<br>
<br>
总结: 在日常工作和生活中，我们经常使用各种电子产品，如电脑、手机、电视等。这些产品内部都有一块绿色的电路板，上面焊接了很多电子元器件，其中可能包含一块芯片。芯片是一种集成电路，通过将晶体管、电阻、电容等元件集成在一块基板上制造而成。芯片是电子设备中非常重要的组成部分，可以实现各种特定功能。芯片的分类很多，包括模拟、微型、逻辑和存储器等。它的发展推动了电子产品的进步和人类文明的发展。 </div>
                        <hr>
                    
                    <p>我们在日常工作和生活中，经常会使用到各种各样的电子或电器产品，例如电脑、手机、电视、冰箱、洗衣机等。</p><p>这些产品，如果我们把它拆开，都会看到类似下面这样的一块绿色板子。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f07c07c1e7ab4ca89f9b8640eabd58ee@000000_oswg1342161oswg1080oswg747_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">有时候是蓝色或黑色的</p><p>大家都知道，这个绿色板子，叫做电路板。更官方一点的名称，叫印制电路板，也就是PCB（Printed Circuit Board，国外有时候也叫PWB，Printed Wire Board）。</p><p>在PCB上，焊接了很多的电子元器件，例如电容、电阻、电感等。</p><p>我们还可以看到，有一些黑色的方形元件。</p><p>没错，这个元件，很可能就是一块芯片（英文名叫做chip）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_60a4782f3edf429a8bdab5bf3c7d511a@000000_oswg120626oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>芯片的定义</strong></h2><p>芯片，其实是一个比较笼统的叫法。</p><p>对于电子设备来说，它藏在内部，又非常重要，相当于汽车的发动机、人的心脏，所以叫“芯”。从形态来看，它是一片一片的，所以叫“片”。合起来，就是“芯片”。</p><p>通常来说，芯片就是集成电路（integrated circuit）。两者之间可以划等号，互相换用。</p><p>集成电路是比较容易定义的。通过特定技术，将晶体管、电阻、电容、二极管等电子元件集成在单一基板上，形成一种微型电路，就叫集成电路。</p><p>如果这个基板，采用的是半导体材料（例如硅），或者说，集成电路由半导体材料晶圆制造而来，就属于半导体集成电路。</p><p>我们传统意义上说的集成电路，基本上都是指半导体集成电路。所有，有时候半导体、芯片、集成电路三个词，也经常混用。</p><p>如果细抠的话，芯片和集成电路也还是有一些区别的。</p><p>部分行业观点认为：</p><p>集成电路是电路，是基础单元，主要强调实现某一功能，例如某一逻辑运算。在电路设计等场景，会更多用到这个叫法。</p><p>而芯片，是一个更宏观、更产品化的概念。经过设计、制造、封装和测试后，形成的可直接使用的产品形态，被认为是芯片。在强调用途的时候，人们会更多采用“芯片”的叫法，例如CPU芯片、AI芯片、基带芯片等。</p><p>也有人将芯片定义为：“包含了一个或多个集成电路的、能够实现某种特定功能的通用半导体元件产品”。或者说，芯片是半导体元件产品的统称。</p><p>相比之下，半导体和集成电路的区别，更清晰一些：</p><p>半导体包括：集成电路+分立器件+光电子器件+传感器。</p><p>集成电路和另外三个的主要区别，在于集成度。集成电路的晶体管数量，远远大于分立器件、光电子器件和传感器。另外，衬底材料一般也不一样。</p><p>目前，光电子器件，分立器件和传感器的市场规模加在一起，也仅占到全部半导体市场规模的10%左右。</p><p>所以，我们可以说：集成电路是半导体的最重要组成部分。</p><h2><strong>芯片的分类</strong></h2><p>芯片是一套实现特定功能的电路。它具有模块化的特点，可以方便厂商快速地进行产品设计和研发，降低开发难度，缩短开发周期。</p><p>几十年来，半导体工艺在摩尔定律的指引下飞速发展，芯片的尺寸越来越小，里面容纳的电路越来越多，使得电子产品的体积、成本以及功耗大幅下降。</p><p>它不仅改善了我们的生活品质，也引领了信息技术革命，推动了整个人类文明的进步。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_3fda635c826a4e2aad05a5184b8affd0@000000_oswg736636oswg1080oswg475_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">有了芯片，才有了手机。</p><p>如今，芯片形成了非常广泛的应用，也衍生出了很多类别。</p><p>世界半导体贸易统计组织（World Semiconductor Trade Statistics，WSTS）的分类方式较为权威、官方。他们将所有集成电路类别，分为：模拟（Analog）、微型（Micro）、逻辑（Logic）和存储器（Memory）。</p><p>非官方层面，分类就比较随意。</p><p>按照功能，我们经常将芯片分为：计算芯片、存储芯片、通信芯片、感知芯片、能源芯片、接口芯片。</p><p>我们比较熟悉的芯片类型，有以下几种：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_dd50d155d0ee48b9849236542f2f3592@000000_oswg430882oswg1080oswg745_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>按照等级，芯片又可以分为消费级、工业级、汽车级、军工级和航天级等。按照设计理念，还可以分为通用芯片（CPU、GPU等）、专用芯片（AISC）。</p><p>我们还可以按照工艺制程来分，例如大家经常听说的28nm、14nm、7nm、5nm。或者，按照半导体材料来分，例如硅（Si）、锗（Ge）、砷化镓（GaAs）、氮化镓（GaN）等。这些我们在后面讲芯片制造流程时，都会再介绍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_7a2f697d2b9e4ff68655518fdeb6441f@000000_oswg155014oswg1080oswg594_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事实上，现在我们除了电芯片之外，还发展出了光芯片（例如硅光技术），用光来代替电流来传递信号。</p><p>站在集成电路的角度，还有很多种分类。</p><p>按制作工艺，集成电路可以分为半导体集成电路和膜集成电路（膜集成电路用的是金属和陶瓷等）。膜集成电路又分为厚膜（thick-film）集成电路和薄膜（thin-film）集成电路。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_8058702dd9994eaa80a87ac5ea201549@000000_oswg65839oswg1080oswg436_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>按照电路属性，我们还可以分为数字集成电路、模拟集成电路和混合信号集成电路。</p><p>数字集成电路，顾名思义，处理的都是数字信号。它在我们身边出现得最多，例如微处理器（CPU、GPU等）、数字信号处理器（DSP）和微控制器（MCU）等，都是数字集成电路。</p><p>模拟集成电路，较多用于传感器、电源芯片、运放等，主要用于模拟信号的放大、滤波、解调、混频等功能。</p><p>混合信号集成电路，是模拟和数字电路集成在一个芯片上。大家应该能猜到，模数（ADC）和数模（DAC）转换芯片，就属于这类。</p><p>按照芯片上所集成的微电子器件的数量（规模），集成电路可以分为以下几类：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2c1d336ee6cd4c55a8419aff9f7aa782@000000_oswg203970oswg1080oswg513_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更专业一点，按导电类型，集成电路还可以分为双极型集成电路和单极型集成电路。</p><p>双极型集成电路的制作工艺复杂，功耗较大，代表集成电路有TTL、 ECL、HTL、LST-TL、STTL等类型。</p><p>单极型集成电路的制作工艺简单，功耗也较低，易于制成大规模集成电路，代表集成电路有CMOS、NMOS、PMOS等。</p><p>上面这些名词，后续小枣君在介绍芯片的工作原理时，都会详细解释。</p><h2><strong>芯片的内部构造</strong></h2><p>前面我们提到，芯片看上去都是黑色方片状。</p><p>有时候，它还会有银色的金属盖板（加强保护，也利于散热）。例如我们的CPU：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_04d3d4dd9496429cb4c8ed781f0df1e9@000000_oswg84482oswg1080oswg753_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">CPU盖板</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_02680438a90e4ebfb4ffb79ea6e2e74d@000000_oswg107963oswg393oswg280_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">CPU外观</p><p>芯片是经过封装（芯片制造流程的一道工序）之后，才变成了这样。</p><p>我们把“壳”拿掉，才能真正看到芯片的内部核心。用显微镜放大来看，是这样的：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_bbfa4dd1481a4343b2f3b8598a1950f1@000000_oswg54724oswg546oswg513_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>外围一圈，是引脚（针脚）。细细的线，是引线。中间方形的部分，才是芯片真正的电路。</p><p>如果继续放大来看，是这样的：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_c22920a092fc4b8a9c899ef39a87bd2b@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>换成3D效果，是这样的：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_714d7e3ef87945d7931afec7a1787f6c@000000_oswg16962oswg500oswg333_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>没错，都是立体的，有很多很多层，密密麻麻，就像一个超级迷宫，也像一座未来城市。</p><p>图上，一根一根的，都是连线。而它们连接的对象，就是晶体管。</p><p>芯片中晶体管的数量，通常代表了这个芯片的能力。晶体管越多，电路就越多，功能和算力就更强。现在很多厂商发布芯片，总是会强调芯片里面拥有多少多少晶体管，就是这个意思。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_56daeb68885f4b23b2c5b66e957e74c8@000000_oswg240174oswg609oswg549_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">英伟达的H100 GPU，拥有800亿晶体管</p><p>芯片有简单的（相对来说），也有复杂的。一些复杂的芯片，还会分为各个不同的功能模块。这些模块共同组成一个系统，就变成了SoC（System on Chip，片上系统，系统级芯片）。</p><p>我们的手机主芯片，例如高通骁龙、联发科天玑、华为麒麟，都是典型的SoC芯片。芯片上包括了CPU、GPU、APU、ISP、基带、射频，等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_efa1161c50404dbd8581da419870495a@000000_oswg38727oswg611oswg304_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>那么，问题来了，芯片里面的晶体管，为什么能够完成计算、存储等五花八门的工作？</p><p>我们常说的逻辑门、MOSFET、FinFET、PN结，又是啥意思呢？</p><p>未完待续……</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI1NTA0MDUyMA==&amp;mid=2456695164&amp;idx=1&amp;sn=87e2b24edf6ea78afd6ac27a5cd561b4&amp;chksm=fda69c1bcad1150de02142ef4ad3e5deb1dcf5c6f512f31384bc543ca3cf0bdb8b2919137649&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“鲜枣课堂”（ID：xzclasscom）</a>，作者：小枣君，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547707592283780</id>
            <title>深度学习大牛权威预测2024年AI行业热点，盘点开源AI趋势</title>
            <link>https://www.36kr.com/p/2547707592283780</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547707592283780</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:26:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI社区大佬Sebastian, 2023年AI行业热点, 开源社区, AI研究问题
<br>
<br>
总结: AI社区大佬Sebastian总结了2023年全年AI行业的热点和问题，针对开源社区和AI研究的热点问题给出了自己读到的解读和发展建议，精彩内容千万不能错过。 </div>
                        <hr>
                    
                    <blockquote><p>AI社区大佬Sebastian总结了2023年全年AI行业的热点和问题，针对开源社区和AI研究的热点问题给出了自己读到的解读和发展建议，精彩内容千万不能错过。</p></blockquote><p>知名人工智能研究人员SEBASTIAN RASCHKA在进入2023年尾声的时候，对几年行业的发展进行了一个全面的回顾。</p><p>在他看来，虽然今年以大语言模型为代表的AI行业风起云涌，新产品新技术不断推出，高光频现。</p><p>但是伴随着技术的发展，也有更多的问题出现，亟待解决。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_0431f1cefe6a42cdb0fd2e73b1601ef0@1743780481_oswg65312oswg1080oswg353_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">文章链接：https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023</p><h2><strong>2023年：只是2022年高潮的延续？</strong></h2><p>今年，人们还没有看到人工智能产品方面有任何根本性的新技术或方法出现。相反，今年主要产品和更新都是去年基础的延续：</p><p>ChatGPT从GPT-3.5升级到GPT-4</p><p>DALL·E 2 升级为 DALL·E 3</p><p>Stable Diffusion 2.0升级为 Stable Diffusion XL</p><p>而一个一直被多方炒作的传闻很有意思：GPT-4是由16个子模块组成的专家（MoE）模型的混合体。</p><p>而且据说，这16个子模块中的每一个MoE都有1110亿个参数（作为参考，GPT-3有1750亿个参数）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_3c04036f36f14f39b013eb2a48bc1d27@1743780481_oswg18052oswg1080oswg289_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>尽管不能100%确定，但GPT-4是一个MoE组成的集群这个事很可能是真的。</p><p>从这个事情上，看得出的一个趋势是，AI行业的研究人员在论文中分享的信息现在已经越来越少。</p><p>例如，GPT-1、GPT-2、GPT-3 和Instruct GPT论文披露了具体的架构和训练细节，而GPT-4架构就没有人知道了。</p><p>再举个例子：Meta AI的第一篇Llama论文详细介绍了用于训练模型的训练数据集，而 Llama 2模型则对这些信息都进行了保密。</p><p>在大模型透明度方面，斯坦福大学上周推出了 「基础模型透明度指数」（The Foundation Model Transparency Index），根据该指数，Llama 2以54%领先，GPT-4以48%排名第三。</p><p>当然，要求企业分享商业机密可能并不合理。但这仍然是一个值得一提的很有意思的一个趋势。</p><p>因为，2024年这个趋势似乎不会改变。</p><p>关于技术的进一步发展，今年的另一个趋势是输入上下文的长度一直在增长。</p><p>例如，GPT-4的竞争对手Claude 2的主要卖点之一就是它支持多达100k token的输入（GPT-4 目前只支持32k的上下文），这使得它在生成长文档摘要时特别有吸引力。</p><p>它还支持PDF输入，因此对于很多人的工作也特别有用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b3a64db6aca14c148be9960ebae70b0f@1743780481_oswg300405oswg1080oswg794_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>开源AI趋势总结</strong></h2><p>根据作者的记忆，去年开源社区非常关注隐扩散模型（Latent Diffusion Model如稳定扩散模型）和其他计算机视觉模型。</p><p>扩散模型和计算机视觉一如既往地具有现实意义。不过，今年开源和学界、关注的焦点成为了LLM。</p><p>开源（或者说公开可用）LLM的爆炸式增长部分要归功于Meta公司发布的首个预训练Llama，尽管该模型的许可证具有限制性，但还是激励了许多研究人员和从业人员投入和很多时间和精力，导致了后来的羊驼大爆发：Alpaca，Vicuna，Llama-Adapter，Lit-Llama等变体的出现。</p><p>几个月后，Llama 2在很大程度上取代了Llama 1，成为功能更强的基础模型，甚至官方还推出了其他的微调版本。</p><p>然而，尽管 Llama-Adapter v1 和 Llama-Adapter v2等微调方法有望将现有 LLM变成多模态LLM，但大多数开源LLM仍然是纯文本模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_be23dd80c9264793981d33b9522d6c7b@1743780481_oswg178296oswg1080oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外一个值得注意的模型是于 10 月 17 日发布的Fuyu-8B模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_48f0868802cf473e81420e80602a8453@1743780481_oswg132517oswg1080oswg410_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>值得注意的是，Fuyu-8B将输入片段直接传入线性投影层（或嵌入层），以学习自己的图像片段嵌入，而不是像其他模型和方法（例如 LLaVA 和 MiniGPT-V）那样依赖额外的预训练图像编码器。</p><p>这种方式大大简化了架构和训练设置。</p><p>除了上述几种多模态尝试之外，最大的研究热点仍然是使用参数小于100 B的较小模型来追求达到GPT-4级别的文本性能。</p><p>开源社区进行类似尝试的原因，可能是由于硬件资源成本和限制、有限的数据访问以及对较短开发时间的要求（由于发表论文的压力，大多数研究人员无法花费数年时间来训练一个模型）。</p><p>不过，开源LLM的下一个突破并不一定来自将模型扩展到更大的规模。</p><p>2024年，MoE方法能否将开源模型提升到新的高度，让我们拭目以待。</p><p>有趣的是，在研究方面，大家在2023年还看到了一些基于Transformer的LLM 的替代方案，包括旨在提高效率的递归RWKV LLM和卷积Hyena LLM。</p><p>不过，基于Transformer的LLM仍然是当前的主流技术。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b1c6631677d44195a0f7b2d2ea6e207a@1743780481_oswg281422oswg1080oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>总的来说，开源社区在这一年里非常活跃，取得了许多突破和进步。</p><p>而且开源社区的一大特点就是1+1&gt;2。</p><p>因此，作者对积极游说反对开源人工智能的人感到难过。</p><p>作者希望开源社区能保持积极的势头，建立更有效的解决方案和替代产品，而不是一味地依赖大型科技公司发布的类似ChatGPT这样的产品。</p><p>由于开源社区的不断努力，出现了可以在单个GPU上运行的小型高效模型，如1.3B参数的phi1.5、7B Mistral和7B Zephyr，其性能已接近大型闭源模型。</p><p>这是一个令人兴奋的趋势，作者希望这一趋势能在2024年继续下去。</p><h2><strong>生产力期望</strong></h2><p>作者认为开源人工智能是开发高效和定制化的LLM解决方案的主要途径，包括那种可以适用于各种应用，基于个人或特定领域数据的微调LLM。</p><p>如果在社交媒体上关注过作者本人的话，可能会看到他在谈论和不断改善的Lit-GPT，这是作者积极参与的一个LLM开源资源库。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_7085e4073e634b5a8ed77b9b2970f28c@1743780481_oswg481744oswg1080oswg1496_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然作者本人非常支持开源，但他也非常喜欢精心设计的产品。</p><p>自从ChatGPT发布以来，LLM被用于几乎所有领域。</p><p>而正确使用LLM助手能让你事半功倍。</p><p>例如，向ChatGPT询问杂货店的营业时间就不是一个发挥它功能长处的用法。但是，修改文章的语法，或者进行头脑风暴，重新遣词造句。</p><p>从更宏观的角度看，LLM的核心能力是提高工作效率，这一点每个人都不会否认。</p><p>除了用于普通文本的LLM，微软和GitHub推出的Copilot代码助手也日趋成熟，越来越多的人开始使用它。</p><p>今年早些时候，Ark-Invest 的一份报告估计，代码助手能将完成一项编码任务的时间缩短约55%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_40229ce202304566ad006a976b4d6191@1743780481_oswg106854oswg1080oswg915_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，不论55%这个数字是否真的那么准确，只要用过代码助手，任何人都能感受到效率的巨大提升，可以让繁琐的代码任务变得更轻松。</p><p>有一点是肯定的：代码助手将继续存在，而且随着时间的推移，它们只会变得越来越好用。</p><p>它们会取代人类程序员吗？作者希望不会。但毫无疑问，它们将提高现有程序员的工作效率。</p><p>这对StackOverflow意味着什么？《人工智能现状报告》中有一张图表，显示了StackOverflow 与 GitHub 的网站流量对比，这可能与Copilot的使用率越来越高有关。</p><p>不过，作者认为即使是ChatGPT/GPT-4已经对代码相关的任务很有帮助了。</p><p>可能ChatGPT也是导致StackOverflow流量下降的部分原因（甚至是主要原因）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_18242b3a60c44dc09ef04c2e23bd7600@1743780481_oswg234423oswg1080oswg641_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>AI行业面对的几大问题</strong></h2><h3><strong>幻觉</strong></h3><p>与2022年一样，同样的问题仍然困扰着LLM：他们可能会生成有毒内容，并倾向于产生幻觉。</p><p>在这一年中，出现多种解决这一问题的方法，包括带有人类反馈的强化学习（RLHF）和英伟达提出的NeMO Guardrails。</p><p>然而，这些方法仍然解决不了根本问题，要么过于严格，要么效果不好。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_c4203d1af69b4d749dac425f23950ca1@1743780481_oswg542729oswg1080oswg967_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">项目地址：https://github.com/NVIDIA/NeMo-Guardrails</p><p>到目前为止，还没有一种方法（甚至连设计可行方法的思路都没有）能在不削弱LLM的积极功能的基础之上，能百分之百可靠地解决这个问题。</p><p>在作者看来，这一切都取决于人类如何使用 LLM：不要什么事都用LLM，数学用计算器，把LLM只看做是写作工具，并仔细检查它的输出，等等。</p><p>此外，对于特定的商业应用，也许可以探索检索增强（RAG）系统。</p><p>它作为一种折中方案，开发人员从语料库中检索相关的文档段落，然后根据检索到的内容为基础， 为LLM的文本生成设定条件。</p><p>这种方法能让模型从数据库和文档中获取外部信息，而不是依赖于记忆所有知识和信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_33627776c2064c21bf30ca7e243320c4@1743780481_oswg128483oswg986oswg800_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>版权问题</strong></h3><p>另一个更紧迫的问题，是围绕人工智能的版权争论。</p><p>根据维基百科的说法，「在受版权保护的材料上训练出来的LLM的版权问题尚未解决」。</p><p>总体看来，许多规则仍在起草和修订之中。作者希望，无论规则是什么，都能清晰明了，以便人工智能研究人员和从业人员能够做出相应的调整和行动。</p><h3><strong>评估</strong></h3><p>困扰学术研究的一个问题是，流行的基准和排行榜被基本上都是半成品，因为测试集内容可能已经泄露，成为了LLM 的训练数据。这已经成为 phi-1.5 和 Mistral的一个问题。</p><p>自动评估 LLM 的一个常用但不太方便的方法是以人类的偏好为测评标准。另外，许多论文也将 GPT-4作为第二好的方法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_94acda9cea6146e2916b4ea29597d60d@1743780481_oswg118563oswg1080oswg432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>收入</strong></h3><p>生成式人工智能目前仍处于初期探索阶段。</p><p>当然，大语言模型和文生图模型已经在很多领域非常好用了。</p><p>然而，由于昂贵的托管和运行成本，它们能否为公司赚钱仍是一个备受争议的话题。</p><p>例如，据报道，OpenAI去年亏损了5.4亿美元。另一方面，最近有报道称，OpenAI现在每月能赚到8000万美元，已经抵消它的运营成本。</p><h3><strong>虚假图像</strong></h3><p>与生成式人工智能有关的一个大问题是伪造图像和视频的问题，这在目前的社交媒体平台上尤为明显。</p><p>伪造图片和视频一直是个问题，Photoshop等软件已经降低了伪造内容的门槛，人工智能正在将这一问题提升到一个新的水平。</p><p>也有人工智能系统希望能在检测人工智能生成的内容方面产生作用，但这些系统对文本、图像或视频都不可靠。</p><p>要在一定程度上遏制和打击这些问题，唯一的办法就是依靠值得信赖的专家。</p><p>就像我们不会从互联网上的随机论坛或网站上获取医疗或法律建议一样，我们可能也不应该在没有反复核实的情况下相信互联网上随机账号的图片和视频。</p><h3><strong>数据集瓶颈</strong></h3><p>与前面提到的版权争论有关，许多公司（包括 Twitter/X 和 Reddit）关闭了免费API访问权限，以增加收入，同时也是为了防止搜刮者收集平台数据用于人工智能训练。</p><p>我遇到过许多专门从事数据集相关工作的公司的广告。虽然人工智能可能会令人遗憾地导致某些工作自动化，淘汰人类劳动力，但它似乎同时也在创造新的就业机会。</p><p>为开源LLM进步做出贡献的最佳方式之一，可能就是建立一个数据集众包平台，来撰写、收集和整理经明确许可用于LLM培训的数据集。</p><h2><strong>RLHF是蛋糕上的樱桃吗？</strong></h2><p>当Llama 2模型套件发布时，它包含了针对聊天进行微调的模型。Meta AI 使用强化学习与人类反馈 （RLHF），提高了其模型的有用性和无害性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_604b73e33d21466691ec4104dec8391a@1743780481_oswg45957oswg998oswg760_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作者认为RLHF是一种非常有趣且有前途的方法，但除了InstructGPT、ChatGPT和Llama 2之外，它并没有被广泛使用。下图是一张关于RLHF日益普及的图表。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_74845411ad8647cb96cac419378a0919@1743780481_oswg42473oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由于 RLHF 的实现有点复杂和棘手，因此大多数开源项目仍然专注于指令微调的监督微调。</p><p>RLHF 的最新替代方案是直接偏好优化 （DPO）。在相应的论文中，研究人员表明，在RLHF中拟合奖励模型的交叉熵损失可以直接用于微调LLM。</p><p>根据他们的基准，使用 DPO 更有效，并且在响应质量方面通常也优于 RLHF/PPO。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_1c9d4fbb36a6432a9c3d43fee8e560cc@1743780481_oswg67582oswg1080oswg726_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>DPO似乎尚未被广泛使用。然而，不久前，我们看到了通过DPO训练的第一个公开可用的LLM，它似乎优于通过 RLHF 训练的更大的Llama-2 70b Chat模型：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_3e2250b347b3430db75eadd367549a12@1743780481_oswg23672oswg629oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但是，值得注意的是，RLHF并未明确用于优化基准性能；它的主要优化目标是人类用户评估的「有用性」和「无害性」，这里没有捕捉到这一点。</p><h2><strong>使用LLM做分类?</strong></h2><p>不久前，作者在Packt 生成式 AI 会议上发表了演讲，强调文本模型最突出的用例之一仍然是分类。例如，考虑一些常见的任务，例如垃圾邮件分类、文档分类、对客户评论进行分类，以及在社交媒体上标记有害言论。</p><p>而对于这些任务，仅使用单个 GPU 运行「小型」LLM（例如DistilBERT）就足以获得非常好的分类性能。</p><p>今年，作者在他的深度学习基础课程中发布了使用小型LLM进行文本分类的练习，有人甚至通过微调现成的可用 Roberta模型，在IMDB电影评论数据集上实现了&gt;96%的预测准确率。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_6a10ee18ddc347048d97648b570b38a2@1743780481_oswg244361oswg1080oswg896_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>话虽如此，目前却仍然没有看到任何关于LLM分类的新的主要工作或趋势。大多数从业者仍在使用基于 BERT 的编码器模型或编码器-解码器模型，例如2022年问世的 FLAN-T5。这可能是因为这些架构仍然在各项任务中表现良好。</p><h2><strong>LLM用于表格数据</strong></h2><p>2022 年，作者撰写了《 A Short Chronology Of Deep Learning For Tabular Data》，介绍了许多有趣的基于深度学习的表格数据方法。然而，与上面提到的用于分类的 LLM 类似，在表格数据集方面也没有那么多的发展。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_51224b21522e476f871f7f25b7603ab8@1743780481_oswg50463oswg1080oswg526_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2022 年，Grinsztajn 等人撰写了一篇论文，题为《Why do tree-based models still outperform deep learning on tabular data？》。确实，基于树的模型（随机森林和 XGBoost）在中小型数据集（10k个训练示例）上的表格数据方面仍然优于深度学习方法。</p><p>此外，XGBoost又推出了一个大型 2.0 版本，该版本具有更好的内存效率、对不适合内存的大型数据集的支持、多目标树等。</p><h2><strong>2023 年的计算机视觉</strong></h2><p>大型语言模型开发（LLM）开发仍在快速进行。与此同时，撇开人工智能监管的争论不谈，LLM新闻的出现速度似乎比平时略慢。这是一个很好的机会，可以偶尔关注计算机视觉，讨论该领域的研究和开发现状。</p><p>除了研究之外，与计算机视觉相关的人工智能一直在激发今年已经成熟的新产品和体验。</p><p>例如，今年夏天，第一辆真正的无人驾驶Waymo汽车在街上漫游。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_c249ddbd0239489f87af07784787e11f@1743780481_oswg154360oswg937oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以及，人工智能的使用在电影行业越来越受欢迎。最近的一个例子是哈里森·福特（Harrison Ford）在《夺宝奇兵5》中的去衰老，电影制片人使用演员的旧档案材料训练了人工智能。</p><p>然后，生成式人工智能功能现在已经牢固地集成到流行的软件产品中。最近的一个例子是 Adobe 的 Firefly 2。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_1de85acf7afa4335bca73efaf8ea910a@1743780481_oswg893856oswg1080oswg949_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>2024 年的预测</strong></h2><p>预测始终是最具投机性和挑战性的方面。去年，作者预测LLM在文本或代码以外的领域中会有更多应用。</p><p>其中一个例子是HyenaDNA，它是DNA的LLM。另一个Geneformer，这是一个在3000万个单细胞转录组上预训练的transformer，旨在促进网络生物学的预测。</p><p>到2024年，LLM将越来越多地改变计算机科学之外的STEM研究。</p><p>一个新兴趋势是各种公司开发定制 AI 芯片，这是由于高需求导致的GPU稀缺。谷歌将在其TPU硬件上加倍投入，亚马逊已经推出了Trainium芯片，AMD可能会缩小与NVIDIA的差距。现在，Microsoft 和OpenAI也开始开发自己的定制 AI 芯片。</p><p>这方面的挑战在于，确保在主要的深度学习框架中对这种硬件提供全面而强大的支持。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_4963811c201b4dd0b24b0036d5e2d8f9@1743780481_oswg185033oswg1080oswg927_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在开源方面，我们仍然落后于最大的闭源模型。目前，最大的公开型号是 Falcon 180B。这倒是不太令人担忧，因为无论如何，大多数人都无法获得处理这些模型所需的大量硬件资源。我们更加渴望的是更多由多个较小的子模块组成的开源 MoE 模型，而不是更大的模型。</p><p>另外，我们也可以看到众包数据集的上的进展，以及 DPO 的兴起，以取代最先进的开源模型中的监督微调。</p><h3>参考资料</h3><p>https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/8J8gxPB_vCVeyxykOVdnDA" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：润 alan，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547691906766728</id>
            <title>日损1250亿，药明生物“小作文”吓坏投资者</title>
            <link>https://www.36kr.com/p/2547691906766728</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547691906766728</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:26:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 药明生物, 医药板块, 市值损失, CXO业务
<br>
<br>
总结: 药明生物发布业务更新PPT后，市值暴跌，导致整个医药板块遭受损失。药明生物预测未来两年医药行业增长放缓，引发恐慌情绪，导致上千亿的市值损失。药明生物是国内CXO行业的龙头，主要从事医药外包业务。药明生物的业绩下滑早有端倪，其净利润增速在近几年呈下降趋势。 </div>
                        <hr>
                    
                    <h2><strong>千亿龙头“梅开二度”</strong></h2><p>12月4日，在千亿医药巨头药明生物的“带领”下，整个港股医药板块遭受较大损失。</p><p>事件起源于当日早间，主要从事CXO(医药外包)业务的药明生物，在官网发布了一份关于最新业务更新的PPT，其中提到，公司2023年整体收入或不及预期，并将导致利润出现下降。此言一出，药明生物开盘立即暴跌23.79%，不到一小时跌去440亿港元市值。</p><p>而深感不妙的药明康德，于10点49分用停牌应对，并给出待刊发可能构成内幕消息公告的这一理由。截至12月4日收盘，药明生物暴跌23.79%，报33.15港元/股，总市值1409亿港元。直到当日深夜，药明生物才发布相关公告，其实内容大致就是对上述PPT进行同步，并宣布恢复交易。</p><p>实际上，更为严重的是，药明生物将这种恐慌，蔓延至了整个医药行业，其在PPT中直言，受生物技术融资影响，行业在未来两年预期个位数增长。可随着药明生物的停牌，无处发泄的“恐惧情绪”便在整个医药板块持续发酵，并导致出现上千亿的市值损失。</p><p>东财Choice数据显示，整个港股医药板块，日损1250亿港元市值。其中，207只成份股有一半以上收绿，而市值超过200亿港元的27家头部企业，则全部收绿，像身为“一哥”的药明康德大跌8.8%，而跌幅较小的百济神州，还借此超越药明生物，坐上了港股医药板块的“第二把交椅”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_0655fadfb11a4318b56c333411bf3c50@1743780481_oswg59650oswg962oswg485_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其实，药明生物也在公告中，给自己留了余地，称简报包含前瞻性陈述，存在重大风险和不确定性，且其中所述的任何估算和未来建议，均基于若干假设和估算，以及管理层根据当前可得资料，而作出的判断，也就是有猜测的成份。</p><p>可正是这一系列操作，引发了股民的不满。</p><p>其中，有网友对药明生物的停牌，以“怒拔网线”进行调侃，但更多的是对其谴责，“预测自己的业绩可以，公开预测行业是何居心啊”、“自己给自己写小作文的公司，还是第一次见”。不过，也有乐观的股民表示，“巴菲特告诉过我，别人恐慌我加仓”。</p><p>值得一提的是，这并非药明生物首次以一己之力，带崩医药板块。就在今年6月，身为药明生物CEO的陈智胜，曾在公开场合表态，“上半年公司新签25个项目，低于往年四五十个的预期水平，其中中国项目占比不足两成。上半年考察发现，明显感觉到欧美医药市场正在恢复，而中国还需要时间……”</p><p>上述相关言论一出，药明生物当天立即以17%的大跌予以回应，尽管陈智胜也给出了诸如订单延迟、复苏正在路上等“挽回”般的解释，但药明康德依旧在当天与次日，分别大跌5.4%与8.3%，同时跟跌的还包括凯莱英、泰格医药等一众医药外包成分股，而行业两天损失的市值，同样可达数百亿港元。</p><h2><strong>早已埋下的雷</strong></h2><p>药明生物上市于2017年，是国内CXO行业的龙头之一，该行业主要从事的就是，药品从研发、试验、到生产以及上市等过程中的一系列外包活动，按照产业链条上下游，可分为CRO（研发外包）、CMO/CDMO（生产外包）以及CSO（销售外包）三个环节，而药明生物主要涉及前两个环节。</p><p>此前一段时间，随着全球创新药产业的迅猛发展，令不少医药巨头在该领域加大了投入，但由于新药研发具有高风险、高投入、回报周期长等特点，为加快新药的研发效率，这些医药巨头便选择把相关业务外包出去，而这就是包括药明康德和药明生物等国内CXO巨头，得到迅速发展的原因。</p><p>可是，随着药明生物这一份PPT的发布，却令整个行业感受到了一丝凉意。</p><p>其实，这只是近两年来海内外创新药产业“融资寒冬”下所体现出的一角。对于药明生物而言，除受大环境影响外，还面临着韩国三星旗下的三星生物频频上演的降价抢单与扩大产能等戏码。这也是药明生物的毛利率，从2021年年中的52%降至今年年中不到42%的原因之一。</p><p>而药明生物也在PPT中透露，2023年，公司四大业务板块中只有两项符合预期，而药物开发与生产的预期全年收入，均出现不同程度下滑。其中，前者是因新增项目数的减少，导致减少3亿美元的收入，而后者是因为项目的递延，带来1亿美元的收入延期，合计金额约合28.55亿人民币。</p><p>药明生物甚至表示，自己此前的预期“过于乐观”了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_0c9af70f083c4d2eacfe367f531294ef@1743780481_oswg41908oswg956oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（来源/药明生物业务更新公告）</p><p>实际上，药明生物的业绩下滑，早已能看出端倪。</p><p>2023上半年，药明生物虽然实现营收同比增长17.8%，达到84.9亿元，但净利润却出现10.18%的下滑，为23.38亿元。而且，如果将时间线拉长就能发现，早在2018年前后，这种颓势就已经出现。</p><p>东财Choice数据显示，药明生物的净利润增速，从2018年年中的150%，降至2019年年中的60%，并于此后趋于稳定，但由于一些特殊原因，该增速在2021年年中迎来暴增，重回150%的行列。不过，自那以后，其利润增速再度迎来下滑，直到今年上半年，出现上市以来的首个负增长。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d0f40cfbb4874f8585ef53f6ff613add@1743780481_oswg19133oswg662oswg376_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（药明生物近年来净利润增速走势图。来源/东财Choice数据）</p><p>2021年前后的一系列事件，虽然在一定程度上，延缓了药明生物净利润增长的颓势表现，但终究并非长久之计。</p><p>值得一提的是，药明生物还在最新发布的复盘公告中强调，集团的业务营运及财务状况势头依旧凶猛，并对未来前景保持乐观。本公司相信，今年是集团毛利率及增长率最具挑战的一年，并预期于2024年下半年逐步回暖。</p><p>不过，也正如药明生物所言，不论是“看好”还是“看空”，其实都不乏猜测的成份，而其能否真正走出周期困境，还需要时间的检验。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/75OZ9M4dX92UHo_LDMmP8w" rel="noopener noreferrer nofollow" target="_blank">“市界”（ID:ishijie2018）</a>，作者：冯晨晨，编辑：刘肖迎，运营：刘珊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547680626791302</id>
            <title>脑机技术真实案例公布，马斯克要让瘫痪的人动起来</title>
            <link>https://www.36kr.com/p/2547680626791302</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547680626791302</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:25:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 埃隆·马斯克, 脑机接口, 脑损伤, 大脑植入物
<br>
<br>
总结: 埃隆·马斯克的脑机接口公司Neuralink希望通过大脑植入物帮助脑损伤患者恢复运动能力。最新研究显示，脑机技术可以改善脑损伤患者的认知状况，为治疗慢性脑损伤提供了希望。研究人员发现大脑的关键枢纽中央外侧核可以通过刺激来恢复大脑功能。虽然还需要更多的研究，但这项技术有望成为治疗脑损伤的有效方法。 </div>
                        <hr>
                    
                    <p>北京时间12月5日，埃隆·马斯克(Elon Musk)的脑机接口公司Neuralink希望利用大脑植入物让瘫痪人士恢复运动能力，目前正在准备首次人体试验。周一公布的最新研究显示，<strong>脑机技术正在帮助脑损伤患者改善认知状况，它的应用似乎没那么遥远。</strong></p><p>在美国，创伤性脑损伤已经导致500多万人永久残疾。他们甚至无法专注于简单的任务，经常不得不辞职或辍学。但是，周一发表的一项研究给他们带来了一线希望。在这项研究中，5名中度、重度脑损伤患者的头部被植入了电极。当电极刺激他们的大脑时，他们在认知测试中的表现得到了改善。</p><p>研究人员称，<strong>如果测试结果在更大规模的临床试验中得到证实，那么这种植入物可能会成为治疗慢性脑损伤的第一种有效方法。</strong>“这是证明你可以有效改善脑损伤问题的第一个证据。”领导这项研究的纽约威尔康奈尔医学院的神经学家尼古拉斯·希夫(Nicholas Schiff)博士表示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d5c8c3d481a74be885387d1ba3141f46@1743780481_oswg100488oswg864oswg1296_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图｜希夫博士领导了这次研究</p><p>吉娜·阿拉塔(Gina Arata)是接受植入手术的志愿者之一。在她22岁时，一场车祸让她出现了疲劳、记忆问题和情绪无法控制问题，导致她放弃了上法学院的计划，和父母一起住在加州莫德斯托，也无法保住一份工作。</p><p>2018年，在发生车祸18年后，阿拉塔接受了植入手术。她说，自己的生活发生了深刻变化。“我可以做一个正常人，和别人交谈。看到自己的改变让我有点惊讶。”阿拉塔表示。</p><h2><strong>大脑关键枢纽</strong></h2><p>希夫博士和他的同事根据多年来对大脑结构的研究设计了这项人体试验。这些研究表明，<strong>人类聚焦任务的能力取决于一个脑区网络。</strong>这些区域通过神经元的长分支相互连接，相互发送信号，形成一个反馈回路，让整个网络保持活跃。</p><p>希夫及其同事提出了一个假设，那就是大脑在车祸或摔倒等事故中突然遭到碰撞，会破坏脑区网络中的一些远距离连接，导致人们陷入昏迷。在恢复期间，这个网络可能能够自行恢复。但如果大脑严重受损，它可能无法完全恢复。</p><p>随后，希夫和同事发现，大脑深处的一个结构是这个网络的关键枢纽。它被称为中央外侧核，是一层薄薄的神经元，大小和形状都和杏仁壳差不多。人类大脑有两个这样的结构，左右半球各有一个。它们似乎能帮助大脑在晚上安静下来入睡，并在早上让大脑运转起来。希夫的研究表明，刺激这些区域的神经元可以唤醒熟睡的老鼠。</p><p>这些研究提出了一种可能性，即刺激中央外侧核可能有助于创伤性脑损伤患者重新获得专注力和注意力。外科医生经常在帕金森病患者身上植入电极。这种植入物每秒释放数百次的微小电脉冲，引导邻近的神经元发射自己的信号，恢复大脑的一些功能。</p><h2><strong>手术</strong></h2><p>2018年，希夫和他的同事开始招募像阿拉塔这样的志愿者，后者在事故发生后多年内一直患有慢性疾病。在插入电极之前，研究人员会对志愿者进行了一系列测试，以判断他们集中注意力和切换任务的能力。例如，在一次测试中，志愿者每人会收到一张写满字母和数字的纸，必须尽快把它们按顺序连接起来。</p><p>在手术前，研究人员扫描了每位志愿者的大脑，绘制出精确的地图。斯坦福大学神经外科医生杰米·亨德森(Jaimie Henderson)博士引导电极穿过大脑，到达中央外侧核。</p><p>亨德森博士在六名志愿者身上植入了电极，但其中一名志愿者在出现头皮感染后不得不退出研究。从手术后一个月开始，剩下的五名志愿者接受了后续测试。在接受字母和数字考试时，他们得到的分数介于15%到52%之间。</p><h2><strong>以前的自己</strong></h2><p>为了更加广泛地了解志愿者的经历，威尔康奈尔医学院的医学伦理学家约瑟夫·芬斯(Joseph Fins)博士对志愿者及其家人进行了一系列面谈。像阿拉塔一样，大多数志愿者都表示，植入物让他们更像以前的自己了。</p><p>相比之下，<strong>在认知测试中进步最大的志愿者却反应冷淡</strong>。“我觉得没什么坏处，只是不知道帮助有多大。”他表示。</p><p>然而，这位患者的儿子却观察到了显著的变化，尤其是他父亲的自我意识。“简直是天翻地覆的变化。”他的儿子表示。</p><p>比利时列日大学的神经学家史蒂文·劳雷斯(Steven Laureys)博士没有参与这项研究。他指出，研究结果支持了一种理论，即注意力和其他形式的思维依赖于全脑网络。“有足够的理由相信这是值得进行的研究。”他表示。</p><p>希夫和他的同事正计划对大脑植入物进行更大规模的研究，他表示：“我们必须看看数据是如何变化的。”</p><p>牛津大学的神经外科医生亚历克斯·格林(Alex Green)博士没有参与这项研究。他表示，中央外侧核并不是唯一有望成为大脑网络枢纽的区域。“我们还不知道实施刺激的最佳部位。”格林称。他和同事们正在准备他们自己的脑损伤试验，尝试在一个叫做脚桥核的区域使用电极。</p><p>劳雷斯博士知道植入手术会很昂贵，但他认为社会应该认识到有数百万人遭受了创伤性脑损伤。“这是一种无声的流行病。”他这么评论道。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/LajkBSASECSd7VhFNDUWRg" rel="noopener noreferrer nofollow" target="_blank">“凤凰网科技”（ID:ifeng_tech）</a>，作者：萧雨，编辑：王晓斌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547685380903816</id>
            <title>英伟达的美国对手们已经开始拿中国攻击英伟达了</title>
            <link>https://www.36kr.com/p/2547685380903816</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547685380903816</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:25:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, Cerebras, 半导体出口限制, AI军火商
<br>
<br>
总结: 美国芯片公司英伟达因为采取规避美国对华半导体出口限制的举措而受到批评，被称为AI军火商。Cerebras首席执行官Andrew Feldman指责英伟达单方面武装中国，认为其不符合美国精神。美国政府的出口管制对英伟达等公司造成了严重影响，尽管英伟达采取了一些调整措施，但仍面临着市场前景的不确定性。 </div>
                        <hr>
                    
                    <p>美国芯片老大英伟达最近越来越“高处不胜寒”了。</p><p>不久前的SC23超算大会上，AI芯片独角兽公司Cerebras 首席执行官Andrew Feldman公开批评英伟达为规避美国对华半导体出口限制采取的一系列举措，认为这样做无异于AI军火商，“不符合美国精神”。</p><p>Andrew Feldman本身来头不小，早在2012年，他创立的低功耗服务器先驱公司SeeMicro就被AMD收购，他本人负责监管 AMD服务器芯片业务。2021年他领导Cerebras造出全球最大AI芯片WSE-2，打破在单个设备上训练拥有200亿参数的最大AI模型纪录，还推出了世界上第一个人脑规模AI解决方案CS-2 AI计算机。</p><p>这也不是 Andrew第一次抨击英伟达，10月英伟达意外发布24-26年GPU新品路线图，Andrew就曾称之为“掠夺性预告”，并说这是利用欺骗性做法和行业主导地位阻碍竞争。这次，Andrew更是毫不客气地指责英伟达“单方面地武装了中国”，“这符合法律规定，但并不意味着不需承担道德责任。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f9acec26156f4201be0b71f2820290b7@1743780481_oswg63825oswg750oswg441_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Andrew Feldman（右一）与团队见证WSE-2芯片入选加州山景城计算机博物馆展出。图片来自Cerebras</p><p>去年和今年10月，美国政府两次以维护国家安全为由，加强人工智能芯片和半导体制造设备对中国等几十个国家地区的出口管制。致使包括英伟达、AMD、英特尔在内的许多厂商业务严重受挫。</p><p>英伟达本月发布第三季度财报后，虽然营收数据继续飙升，但反映投资者信心的股价却一路疲软下跌，也明显投射出外界对英伟达未来在华市场前景的隐忧。</p><p>对于这些禁令，Andrew表示理解，“这是一项强大的新技术，我们并不完全确定它将走向何方。让‘友敌’在游戏初期就获得我们最好的技术是不明智的。这一切都合理，我也支持。”</p><p>尽管可能会对Cerebras与中东的业务往来造成影响，他仍然认为当规则制订时，应该遵循精神而不仅仅是字面意义，“政府说我们不希望你向中国出货，你就跑到它的边缘，然后试图通过漏洞来规避意图，这让你看起来很不美国。”</p><p>而对于英伟达来说，虽然在管制边缘的“蛇皮走位”是大实话，但面对占收入总额高达47%的中国市场，换了谁这种调整也都不得不做。</p><h2><strong>英伟达与美国芯片出口管制的“博弈”</strong></h2><p>去年10月，美国政府突然宣布对华半导体出口管制新规，规定高性能计算芯片出口必须低于4800 TOPS算力上限和600 GB/s的带宽上限，直接导致NVIDIA A100/H100系列和AMD MI200/300系列AI芯片无法对华出售。</p><p>当时国内许多高端场景和主流厂商都采用NVIDIA A100，也预定了大批计划下半年发货的H100，新规的出台让人措手不及。</p><p>为了填补市场缺口，解决中国客户需求，英伟达一个月后就宣布推出符合美国出口规则的“中国特供版”A800和H800。前者将NVLink传输速率由A100的600GB/s降至400GB/s，其它参数基本保持不变，后者则把芯片间数据传输速度改为 H100 的一半。据称，阿里巴巴、百度、腾讯这传统BAT三巨头和互联网大厂字节跳动都已用上了800系列产品。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f4dd6b513d75469fa0bdb3fd8e6aea1a@1743780481_oswg129219oswg750oswg461_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来自Pexels</p><p>然而今年10月17日，禁令再次升级。美国商务部修订芯片出口新规，引入“性能密度”参数并调整先进芯片划定标准，禁止向中国出售每秒能进行3亿次及以上运算的数据中心GPU；要求企业申请许可后才能向40多个国家和地区出售芯片，同时将需要申请半导体制造设备许可证的国家数量扩大到21个；并把包括壁仞科技、摩尔线程在内的13家中国公司列入出口管制名单。这并不是结束，美国商务部长雷蒙多表示，随着技术的进步，这些规则至少每年都会更新一次。</p><p>美国此举是为了防止英伟达等全球领先芯片公司寻求变通方案，也切断中国企业从其他国家和地区获取高性能芯片的渠道。试图在半导体市场对中国进行全面狙击，阻止中国人工智能、精密计算等先进技术发展。</p><p>这次英伟达的产品更是倒下了一大片，包括但不限于：A100、A800、H100、H800、L40、L40S以及RTX 4090。为中国市场量身定做的A800/H800落在了管制范围内，更不用说11月推出的 “算力怪兽”，最新旗舰芯片 H200。</p><p>而“上有政策，下有对策”也被英伟达发挥得淋漓尽致。面对新的管制条例，黄教主表示，一定遵守，但还是希望“继续与中国客户合作”。</p><p>除了积极沟通美国商务部申请许可，本周三英伟达CEO黄仁勋向外界证实，<strong>公司又为中国市场开发（“阉割”）出几枚符合最新规定的特供芯片。</strong></p><p>根据早些时候外媒报道，这三枚芯片分别是<strong>H20、L20和L2</strong>。半导体研究公司SemiAnalysis也将它们的各项性能参数列了出来：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_46d1ebd288e14fca9a38cc61b89d5dbc@1743780481_oswg50388oswg750oswg251_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来自SemiAnalysis</p><p>从图表中可以看出，用于AI模型训练的H20在H100/H800基础上再次降规，与H100 芯片的最大算力值1979 TFLOPs相比，H20这一数值仅有296 TFLOPs。总处理性能为2368，性能密度 2.9，小于 3.2 的管制许可值。</p><p>但值得玩味的是，H20有比H100 更高的缓存和带宽，在实际多卡互联环境中组合性能接近 H100 的 50%。虽然从传统计算角度来看比H100降级不少，但在执行大模型推理运算任务上，它比 H100 还要快 20%，这表明虽然H20不能满足千亿级别参数的LLM训练需求，但在稍小的垂直模型推理方面，或许有事半功倍的效果。</p><p>而L20和 L2 分别替代此前遭到管制的 L40 和 L4，采用PCle外形规格，配置更精简，在LLM推理训练中不常用，更适合工作站和服务器。其中L20的总处理性能为1912，性能密度 3.1，小于许可值3.2；L2的性能密度为 5.2，但总处理性能仅为1544，也小于 1600 的管制许可值。<strong>三枚芯片都巧妙地越过了新规管制中精心设计的封锁条件。</strong></p><p>英伟达的迅速反应再次体现出它对中国市场的重视和对重新提振投资者信心的迫切。在这场与规则的博弈中，也一直是“逢山开路、遇水架桥”，丝毫没有示弱的势头。</p><h2><strong>黄仁勋的“警告”</strong></h2><p>对于同行的指责，黄仁勋似乎也并不为之所动。他这周出席《纽约时报》年度DealBook峰会时重申，英伟达对于中国市场的承诺将保持坚定。</p><p>“我们必须开发出符合出口管制规定的新芯片，一旦满足要求，我们就会回到中国销售。”他表示认同国家安全和竞争力的重要性，但作为“一家为了做生意而建立的公司”，英伟达“尽可能与所有人做生意”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_95b86b173d04460ba1666eb883fdee1a@1743780481_oswg50012oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">黄仁勋在DealBook Summit，图片来自Slaven Vlasic | Getty Images</p><p>黄仁勋也对这些出口禁令可能带来的意外后果发出了警告。他说，目前有多达50家中国公司正在开发能与英伟达竞争的技术。<strong>如果美国企业在市场上失去份额，其竞争力也可能随之降低。</strong>尽管英伟达不会向中国提供其制造芯片的“最关键和最前沿技术”，中国仍然可能找到获取这些技术的途径，或者激励国内芯片制造商发展，他还特别提了一嘴受制裁的华为。</p><p>这些警告不无道理，或者说正在变为现实。</p><p>被美国列入实体管制清单的科大讯飞就在今年的三季度业绩说明会上宣布，用于讯飞星火大模型训练的华为昇腾910B芯片在性能上已经基本可对标英伟达A100。百度也已向华为订购1600颗昇腾910B用于开发文心大模型。</p><p>尽管这笔订单与中国高科技公司们向英伟达订购的成千上万颗芯片相比显得微不足道，但它仍然意义重大，显示出中国公司有能力减少对美国尖端技术巨头的依赖。</p><p>美国加码对华芯片封锁，虽然一段时间内给中国半导体行业带来不小冲击，但中国市场面临的算力缺口同时也会为本土芯片发展带来新的机遇。2023年上半年，中国加速芯片的市场规模超过50万张，除华为外，阿里、百度、腾讯都已经有AI自研芯片，中国芯片市场也正在“自产自销”的路径上发展。</p><p>虽然黄仁勋认为“英伟达已在行业上领先十年”，但他同时也表示，<strong>“如果我们被剥夺了中国市场，我们是没有应急措施的，世界上没有另一个中国。”</strong></p><h2><strong>“美国想脱离中国芯片供应链可能还得20年”</strong></h2><p>在DealBook峰会上，黄仁勋也指出，美国若想完全打破对中国制造的依赖，实现完全独立的芯片供应链体系，需要比想象中更长的时间：<strong>“在10年到20年以内，这并不是一件实际的事情。”</strong></p><p>他说，公司的成功依赖于“来自世界不同地区的众多组件，不仅仅是台湾”，虽然最重要的技术来自台积电生产线。</p><p>而英伟达在中国大陆的合作商则为其提供包括上游半导体材料和设备、服务器整机、光模块、光纤光缆等多个环节的供应链支持。</p><p>如今的芯片制造业高度全球化，重建这些供应链需要在基建、制造技术和工艺上重大升级，在没有中国参与的情况下，是一个几乎不可能完成的任务。</p><p>根据最新消息， H20将推迟至明年一季度发布，最快可能于2月或3月接受预定，具体细节仍处于保密状态。</p><p>英伟达再次越过管制门槛的中国特供芯片们真实性能参数几何，上市后产能和业绩表现怎样，能不能弥补A800/H800禁售带来的中国市场收入缺口，来年美国半导体管制政策是会松动还是继续紧缩，这些都是未知数。唯一可以肯定的是，放弃与中国市场做朋友，绝对不在英伟达的选项上。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/UYAsX-D1Jrk-O9l8YBIbbQ" rel="noopener noreferrer nofollow" target="_blank">“硅星人Pro”（ID:Si-Planet）</a>，作者：Jessica，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547697786459780</id>
            <title>“离谱的AI扩图”火了，张张那叫一个出其不意</title>
            <link>https://www.36kr.com/p/2547697786459780</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547697786459780</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:24:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 抖音AI扩图, 神操作, 离谱, 纪录片
<br>
<br>
总结: 抖音AI扩图的神操作让人意想不到，一些原本有信仰感的照片经过扩图后画风180度大反转，网友们哭笑不得，称其更虔诚、太励志。AI扩图的结果离谱，给出的神作让人出其不意。这些神作包括《牵住她的脚》和《十年树木，百年树人》等，给人一种大型纪录片《AI扩图传奇》的既视感。此外，甄嬛传也被扩了一万种可能，验证了AI扩图的奇葩效果。 </div>
                        <hr>
                    
                    <p>家人们，真的是要被抖音<strong>AI扩图</strong>给笑死了——</p><p>主打一个看完让人“意想不到”、“一肚子气”~</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_87d2b587b5cf45d29383aaff50a99ed5@1743780481_oswg136260oswg1080oswg213_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>例如一对恩爱情侣的照片在AI扩图前是非常有信仰感的：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_900607b223ed426ba111a5864dc66b3e@1743780481_oswg615938oswg1004oswg952_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">素材来源：抖音@快乐野人</p><p>但在AI扩图一通“神操作”之下，画风简直是180度大反转：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b1f57fe3ae0148609eb7d1d6f22a5248@1743780481_oswg900551oswg1078oswg814_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">素材来源：抖音@快乐野人</p><p>网友们在看过之后哭笑不得，打趣称“更虔诚”、“太励志”了😂。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_21f5dd35f15347e6b4882026b36c3152@1743780481_oswg131300oswg1080oswg474_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>原本许多小伙伴们是想着用它来扩大原照片，但AI扩图给出的结果却主打一个<strong>离谱</strong>。</p><p>于是乎，陆陆续续便有更多网友开始po出他们手中AI扩图的神作，我们再来欣赏几组“出其不意”。</p><p>AI扩图神作一，愿赐其名<strong>《牵住她的脚》</strong>：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_13c21e2180a94ff98e4e28b689d4e65a@1743780481_oswg1215772oswg1080oswg785_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">素材来源：抖音@心碎的跳一跳</p><p>AI扩图神作二，<strong>《十年树木，百年树人》</strong>：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d4b1365eca274c7297d1fdeb3fdc6c80@1743780481_oswg1243658oswg1080oswg795_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">素材来源：网络</p><p>AI扩图神作一，愿赐其名<strong>《祝你幸福》</strong>：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_7e6586f2b56641eca81611ebbadf0303@1743780481_oswg1100813oswg1080oswg916_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">素材来源：网络</p><p>……</p><p>有一说一，是有种活脱脱一部大型纪录片《AI扩图传奇》的既视感了。</p><p>然鹅，如此名场面又怎么少得了《甄嬛传》的参与。</p><h2><strong>《甄嬛传》也被扩了一万种可能</strong></h2><p>为了验证AI扩图是否真有这么奇葩，我们也进行一波实测——</p><p>素材：<strong>《甄嬛传》</strong>；软件：<strong>剪映</strong>。</p><p>从操作角度上来说是比较简单的，只需要打开剪映APP，上传图片，点击“特效”、“图片玩法”，再选择<strong>“智能扩图”</strong>即可。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_33025093617c40b79f8357ca7300d1fe@1743780481_oswg311655oswg1080oswg501_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>接下来，请继续欣赏AI扩图的名场面……</p><p>《甄嬛顶炉西游记》：AI直接把甄嬛的背景扩成了西方的宫廷😂。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_71096015cad94b5c983dd53c5a7b95d3@1743780481_oswg712110oswg1080oswg428_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>类似的还有这种……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_fc3f96b272b149c190e917e0e5c26de6@1743780481_oswg466535oswg1080oswg291_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>喂一张胖橘（皇上）进去，AI扩图能还给我们一张<strong>孕期照</strong>……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a9f8b088165a47a9933a9c318f962d0f@1743780481_oswg484467oswg1080oswg342_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>众妃子们的合影，在AI扩图的大手笔之下，让她们秒穿牛仔裤、运动鞋，穿梭在中西合璧的大街上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_900e5041d4664a5ab4fab1d70e1afba8@1743780481_oswg722820oswg1080oswg349_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有更进阶的一种玩法——把被AI搞残的图片，继续投喂给它来扩图。</p><p>例如我们刚才得到的胖橘孕期照，继续AI扩图的结果更加“惊艳”：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_91930c594fa94a548e174b52007f5e19@1743780481_oswg444947oswg1080oswg335_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对，加了腿，加了行李箱，AI把照片传递的故事延伸到了“孕期离家出走”……</p><p>众妃子们的故事也有了大胆的创新，从古装宫廷戏码摇身穿越到了现代。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_820826b0379a4a9792307dc3936e6ab9@1743780481_oswg662420oswg1080oswg348_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不得不说，AI扩图，你是真给了《甄嬛传》一万种可能。</p><p>……</p><p>这时有小伙伴肯定问题，既然AI扩图这么“弱X”，为什么大家还要用它呢？</p><p>正所谓AI也有马失前蹄的时候，刚才我们展示的也仅仅是它失败或不合逻辑的案例。</p><p>其实在这个功能推出之后，大部分的扩图效果还是相当得给力的。</p><p>例如一对新人婚礼的局部照片，就可以扩大场景范围，而且是非常合理且温馨的那种：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2a723a0520d44139aeaa418b69cb6bb7@1743780481_oswg1037225oswg1080oswg549_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>街拍后的照片想要扩大背景范围，也是可以有的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f5aa4b22d8dc424ab578162138b74adf@1743780481_oswg977159oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>那么接下来的一个问题便是：</p><h2><strong>怎么做到的？</strong></h2><p>说到AI扩图这事，之前Midjourney、Photoshop、DALL-E 2、Stable Diffusion等都有推出类似功能，其背后原理也有些相似之处。</p><p>像DALL-E、Stable Diffusion、Photoshop的Generative Fill等都用到了一种叫做<strong>Outpainting</strong>的技术。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_39bd15b88ff0456c908313b8f4618031@1743780481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Outpainting是一种图像处理技术，与Inpainting（图像内部填充）相反，可以根据现有图像的内容、风格和上下文，合成与原始图像相协调的新内容，从而扩展图像的视觉范围。</p><p>Outpainting通常依赖于深度学习模型，有基于内容扩散的、基于GAN的、基于语义理解的等。</p><p>此外，AI扩图不仅是增加像素的数量，更重要的是增加图像分辨率的过程。</p><p>例如，CNN是AI扩图中常用的神经网络，通过学习大量的低分辨率和高分辨率图像对，来理解图像特征，学习如何从低分辨率重建高分辨率图像。</p><p>超分辨率技术使得模型能够填补低分辨率图像中缺失的像素，从而生成更高分辨率的图像。</p><p>在扩图过程中为了保证图像细节还要注意细节增强、噪声抑制等。</p><p>虽然目前AI扩图技术有了很大进展，但实时处理能力还有待提升，通常来说更高质量的图像扩展需要更多的计算时间。</p><p>现有的很多AI扩图工具生成速度已经有了不小的提高，不过成品的质量是否符合逻辑，这个概率还是比较随机的。</p><p>即便AI扩图有时给出的结果很离谱，但这种“抽象风”也给网友们带来了不少的乐子🤣。</p><p>有网友表示，这几天抖音最精彩的就是AI扩图评论区。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_561493182056442c8c568bbf8ea8bb05@1743780481_oswg16933oswg895oswg215_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因为大型纪录片《AI扩图传奇》，还在持续更新中……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_567f02036f604f24976f4ac96582c106@1743780481_oswg46089oswg1080oswg589_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>那么今天，你，AI扩图了吗？</p><h3>参考链接</h3><p>[1]https://weibo.com/6128329691/4974454526706532</p><p>[2]https://s.weibo.com/weibo?q=AI%E6%89%A9%E5%9B%BE</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/xFrrbiZJfH9HsCi34ulTjg" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：金磊 西风，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547702340179841</id>
            <title>Transformer挑战者出现，斯坦福CMU联合团队，开源模型及代码，公司已创办</title>
            <link>https://www.36kr.com/p/2547702340179841</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547702340179841</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:23:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 处理长文本, 注意力机制, Mamba
<br>
<br>
总结: Mamba是一种新的架构，通过使用线性复杂度的注意力机制，解决了大模型处理长文本时的算力消耗问题。Mamba在语言任务上表现出色，击败了Transformer，并具有5倍的推理吞吐量。它采用了选择性处理信息和硬件感知的算法，能够压缩上下文并自适应地调整行为。Mamba的设计使得古老的状态空间模型在现代GPU上也能高效计算。 </div>
                        <hr>
                    
                    <p>现在ChatGPT等大模型一大痛点：</p><p><strong>处理长文本算力消耗巨大</strong>，背后原因是<strong>Transformer架构中注意力机制的二次复杂度</strong>。</p><p><strong>FlashAttention作者Tri Dao</strong>参与提出的新架构，成为有力挑战者，引起大量关注：</p><p><strong>Mamba</strong>（曼巴，一种蛇），在语言任务上击败/匹配Transformer性能，具有<strong>线性复杂度</strong>和<strong>5倍推理吞吐量</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_e6f28178aff84e398aaa70bac5f34f30@1743780481_oswg1930197oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，Mamba在语言、音频、DNA序列模态上都实现SOTA。</p><p>在最受关注的语言任务上，<strong>Mamba-3B超越同等规模的Transformer，与两倍大的Transformer匹敌</strong>。</p><p>并且相关代码、预训练模型checkpoint都已开源。</p><p>两位作者的解读都获得大量转发。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2605a32afcf54e8faace6c0c766bd203@1743780481_oswg786625oswg1080oswg1344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有网友发现，连在线预测平台上的“Transformer在2027年还是SOTA吗？”都在这一天出现明显下降。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a554c1bd892b49df9633597c97ff5755@1743780481_oswg127940oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>有选择处理信息+硬件感知算法。</strong></h2><p>Mamba是一种<strong>状态空间模型</strong>（SSM，State Space Model）。</p><p>建立在更现代的适用于深度学习的<strong>结构化SSM</strong>（S4, Structured SSM）基础上，与经典架构RNN有相似之处。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_317a859fb9fe4139a13ba81ae643e286@1743780481_oswg26252oswg1080oswg222_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在先前研究的Mamba主要有三点创新：</p><ul><li>对输入信息有选择性处理</li><li>硬件感知的算法</li><li>更简单的架构</li></ul><h3><strong>选择性状态空间模型</strong></h3><p>作者认为，<strong>序列建模的一个基础问题是把上下文压缩成更小的状态</strong>。</p><p>从这个角度来看，注意力机制虽然高性能但低效率，需要显式地存储整个上下文（也就是KV缓存），直接导致训练和推理消耗算力大。</p><p>类RNN的循环神经网络具有有限的状态，高效，但性能受到对上下文压缩程度的限制。</p><p>Mamba的解决办法，是让模型对信息有选择性处理，可以关注或忽略传入的内容，即使状态大小固定也能压缩上下文。</p><p><strong>一个直观的类比：</strong></p><p>Transformer就像人类每写一个字之前，都把前面的所有字+输入都复习一遍，所以写的慢。</p><p>RNN每次只参考前面固定的字数，写的快，但容易忘掉更前面的内容。</p><p>Mamba每次参考前面所有内容的一个概括，越往后写对前面内容概括得越狠，丢掉细节保留大意。</p><p>在其前身结构化状态空间模型（S4）中，四个参数A、B、C、∆都是固定的，不随输入变化。</p><p>在Mamaba中，作者让这些参数B、C、∆成为输入的函数，让模型能够根据输入内容自适应地调整其行为。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f4ee509927db4580a2ed24b118e9de9d@1743780481_oswg230947oswg1080oswg324_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>硬件感知的状态扩展</strong></h3><p>为了让古老的SSM在现代GPU上也能高效计算，Mamba中使用了<strong>FlashAttention同款技术。</strong></p><p>核心思想是利用内存的不同层级结构处理SSM的状态，减少高带宽但慢速的HBM内存反复读写这个瓶颈，具体来说：</p><ul><li>在更高速的SRAM内存中执行离散化和递归操作，再将输出写回HBM。</li><li>通过并行扫描算法实现并行化。</li><li>当输入从HBM加载到SRAM时，中间状态不被保存，而是在反向传播中重新计算。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_7e063b44a5f24b0a9a0fbe935aeae231@1743780481_oswg58727oswg1080oswg403_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>简化的SSM架构</strong></h3><p>将大多数SSM架构的基础块，与现代神经网络中普遍存在的门控MLP相结合，组成新的Mamba块。</p><p>重复这个块，与归一化和残差连接结合，构成Mamba架构。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_27e2a0652eda4e908dff3af15ccc8017@1743780481_oswg72711oswg1080oswg463_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>实验结果</strong></h3><p>Mamba在Chinchilla缩放定律下预训练时，语言任务优于同类开源模型。</p><p>对比对象中的<strong>Transformer++</strong>为标准GPT-3架构加上谷歌PaLM和Meta Llama中的改进方案，也就是已知最强Transformer配方。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_6f3f5c1a6e6646c086351066eeb9c683@1743780481_oswg173724oswg1080oswg387_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>下游任务上，<strong>每个规模尺寸的Mamba都是同类最佳</strong>，并且通常与两倍规模的基线性能匹配。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_ac8fbd2d5d864ba59906e1d8b74db766@1743780481_oswg154997oswg1080oswg817_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>特别是当序列长度增加到512k时，相<strong>比使用FlashAttention-2的Transformer快几个数量级</strong>，而且不会内存不足。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_e24dd0b29b424b47b4a86a9fd560c337@1743780481_oswg111604oswg1080oswg508_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>Transformer的下一步？</strong></h2><p>最终，Mamba是<strong>第一个真正实现匹配Transformer性能的线性时间序列模型</strong>，无论是在预训练困惑度还是下游任务评估方面。</p><p>并且在音频和DNA序列建模上也优于之前的SOTA模型，表现出一定的通用性。</p><p>作者在结论中提出，<strong>Mamba是通用序列模型骨干的有力候选者</strong>。</p><p>Stability AI创始人当即表示关注。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_333d74b0789c4393bdd18df164840f73@1743780481_oswg40942oswg932oswg120_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>英伟达科学家Jim Fan也对Transformer的挑战者出现感到兴奋。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_fc50647724874638853e2f5b9ab90056@1743780481_oswg108957oswg1080oswg201_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文两位作者Albert Gu和Tri Dao，博士都毕业于斯坦福大学，导师为Christopher Ré。</p><p><strong>Albert Gu</strong>现在是CMU助理教授，多年来一直推动SSM架构发展。</p><p>他曾在DeepMind 工作，目前是<strong>Cartesia AI</strong>的联合创始人及首席科学家。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_11b3630931d0452381f69aee07fd6d33@1743780481_oswg121974oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Tri Dao</strong>，以FlashAttention、FlashDecoding系列工作闻名，现在是普林斯顿助理教授，和Together AI首席科学家，也在Cartesia AI担任顾问。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_fd7665466ffd4729ac86e36e4f7a46a2@1743780481_oswg179236oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Cartesia AI公司介绍中提到致力于基于新架构构建下一代基础模型，现在看来主要就是指创新的SSM架构。</p><p>联创及CEO<strong>Karan Goel</strong>同为斯坦福博士毕业，也是Mamba的前身S4论文作者之一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_5b55bb3c82b6478eac8da9060058470f@1743780481_oswg173881oswg1080oswg739_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于Mamba的下一步，在论文中有提到“探索新架构是否能适用于Transformer已建立起的丰富大模型生态”。</p><p>其中包括微调、自适应、提示学习、上下文学习、指令微调、RLHF、量化……也就是要把基础模型发展成GPT-3.5、Llama同类的助手模型了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_989ff2946ce24f43a59a7ddd86340ef8@1743780481_oswg38959oswg1080oswg158_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但作者也提到，目前的实验规模较小，要全面评估SSM是否能与Transformer和其他架构如RWKV、微软RetNet竞争，至少还需要验证7B规模。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_76ae32022b58495086e05360f22f6224@1743780481_oswg123777oswg1080oswg171_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在扩展SSM的过程中，还会遇到新的工程挑战和对模型的调整，论文中没有涉及。</p><p>最后，Albert Gu还分享了为什么把新架构起名为一种毒蛇的名字：</p><p>速度快、对序列建模问题很致命、前身S4是SSSS（嘶嘶嘶嘶）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_1531805e84964417aed994771dff73e7@1743780481_oswg149555oswg1080oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>论文</h3><p>https://arxiv.org/abs/2312.00752</p><h3>参考链接</h3><p>[1]https://twitter.com/_albertgu/status/1731727672286294400</p><p>[2]https://twitter.com/_albertgu/status/1731727672286294400</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/WUdZtHCO6AaQqVzyRlB4Bg" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：梦晨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547519356130183</id>
            <title>40秒换电，这家企业要做营运市场换电补能第一品牌</title>
            <link>https://www.36kr.com/p/2547519356130183</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547519356130183</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:03:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 易易互联, 三代换电站, 换电模式, 营运车辆
<br>
<br>
总结: 易易互联是一家在全国多个城市运营三代换电站的公司，他们坚信换电模式是营运车辆的未来，因为它能够提高运转效率并节约投资成本。政策支持也加速了换电基础设施的建设，而司机和运营商也从换电模式中获得了经济效益和成本优势。易易互联作为吉利旗下的子公司，通过与曹操出行等合作伙伴，打造了营运市场换电补能的领先品牌。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_e47332d5902441308c0403029bb34025@5020039_oswg138527oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p><p>40秒，这是出租车及网约车司机在易易互联三代站换电所需的机械时间，几乎是当下电车最短的补能用时。类似这样的换电站，易易互联在重庆已经运营54座，杭州、成都、广州等全国30多个城市更是布局了超300座。&nbsp;</p><p>近日，易易互联发布了最新的三代换电站。截至目前，易易互联已深耕营运车辆换电行业超6年，在易易互联CEO刘金良看来，营运车辆的补能终局，一定是换电模式，所以易易互联对换电路线坚定不移。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_3124978a355c42d2aca19a9e7b590e6d@5020039_oswg155568oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p><p>在一二线城市，交通、物流、出行等领域的营运车辆，需要极高的运转效率，相比于充电，换电显然更快捷。&nbsp;</p><p>更重要的是，换电能够大幅度提升城市资源匹配效率。数据显示，以服务1万辆车为例，对比充电桩，采用换电站方式，可减少近3440个停车位，约4.1万平，节约投资成本5000万元。&nbsp;</p><p>刘金良告诉36氪，整体而言，换电站的坪效更高，相比于充电桩，每平方米输出的电量、创造的补能效率更高。&nbsp;</p><p>在这点上，出租车及网约车司机早已深有体会。易易互联三代换电站发布现场，曹操出行的驾驶员赵师傅表示：“我一直在使用换电，易易的一、二代换电站都体验过，三代站的科技感更强，而且换电过程也更快了，这特别好，对我们驾驶员而言，真是太爽了！每天节省了1至2个小时的充电时间，可以接更多订单。”</p><h2><strong>换电，让司机每月多赚一千块</strong></h2><p>换电模式带来的整体经济效益的改善，获得广泛认可，使得2020年以来，政策端加速推动换电基础设施建设。2020年5月，《政府工作报告》提出“两新一重”建设，将换电站明确纳入新基建建设范畴。&nbsp;</p><p>这之后，政策支持加快落地。2021年10月，新能源汽车换电模式应用试点工作启动，其中综合应用类城市8个（北京、南京、武汉、三亚、重庆、长春、合肥、济南）。2022年12月，换电站被列入国家战略发展规划；今年7月，政府提出加快换电模式推广应用和建设。&nbsp;</p><p>实际上，当下新能源市场中，充电桩保有量迅速爬升，也有不少车企布局超快充建设，但换电路线依旧能受到如此程度的重视，正是因为它既照顾了车端体验，又不会像超充一样冲击电网。&nbsp;</p><p>司机侧来看，作为运营车辆，出租车和私家车最大的区别就在于行驶里程长，使用频率高，因此难以忍受电动车漫长的充电时间，毕竟多一分钟充电，就少赚一分钟钱。&nbsp;</p><p>以香港为例，由于香港出租车实行三班倒、24小时运转的机制，部分出租车换成充电的电车后，每轮班需要一小时多的充电时间，三班倒就是三四个小时，浪费了司机大量的跑活时间。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_5eb6b3b6b9c24b599b7101048b0ed12d@5020039_oswg117040oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p><p>刘金良提供的数据显示，如果司机使用换电模式，相比燃油模式，司机的年收入要高约33.1%；相比充电模式，司机的年收入要高约13.8%，也就是一个月可以多赚1300-1500块钱。换电模式很直观地提升了司机群体的收入水平。&nbsp;</p><p>此外，对于运营商，换电车更低的成本也具有明显价值。&nbsp;</p><p>“如果做到车电分离的话，运营商的资金利率肯定更高，不用花那么多钱购车，原来买200辆的燃油车的钱，也许能够购买300辆换电车。同时也降低了周边成本，例如车辆的保险、电池维护等。”刘金良表示。&nbsp;</p><p>与此同时，“车电分离”意味着，车和电池的生命周期分离开了，进而二者的利用率就会各自提升。&nbsp;</p><p>刘金良举例表示，现在的出租车和网约车，大约跑五至六年以后就面临报废，但如果是换电模式的车，对车身花几千块钱进行翻新就可以了，而电池是交给换电站的，换电站作为保姆管理好电池。这样下来，出租车和网约车在八年的生命周期内都可以很好地使用。&nbsp;</p><p>在私家车领域，“车电分离”能让消费者消费升级。剥离电池价值之后，35万的车可以卖25万元，车企更具价格竞争力，消费者购车也更具性价比。&nbsp;</p><p>“换电行业目前还是发展初期。”在刘金良对未来出行生态的构想中，电动车的发展即“四化”的发展，最终的人类出行，将全部是共享出行及公共出行，“共享出行使用的是谁的车？那么谁早进入共享出行，就是谁家的车。”</p><h2><strong>生态先行，打造营运市场换电补能第一品牌</strong></h2><p>回到易易互联，作为吉利旗下的全资子公司，可以说是目前最适合做“营运车换电”这件事的企业。&nbsp;</p><p>首先要明确的是，换电站具有很明显的网络效应，即换电站足够多，才会有更多人愿意购买换电车型，而只有更多人买了换电车型，或者说路上跑的换电车够多，换电站也才能运营得起来。&nbsp;</p><p>这就意味着“车和站”双边要同步起量，换电的齿轮才能转起来，进入正向循环。&nbsp;</p><p>那么，车企做换电的优势自然被凸显出来。而这之外，易易互联相比其他车企更适合做营运车辆换电的优势，则在于同属于吉利旗下的曹操出行——作为头部网约车平台，曹操出行在各个城市已经铺开的车队，在需求侧做好了充足准备。&nbsp;</p><p>刘金良指出，换电技术并不复杂，换电企业的核心壁垒不是技术，而是生态，能够在发展初期形成自我闭环，即有车、有站、有运营。&nbsp;</p><p>官方信息显示，目前可在易易互联换电站进行换电的车型有“曹操60、枫叶80v、枫叶60s、睿蓝9、睿蓝7、英伦TX5”等。而除了曹操出行，吉利还有出行运力服务“幸福千万家”；以及常青新能源，做电池回收，从而实现了“整车-电池-换电-运营”的全生态运营。&nbsp;</p><p>当然，这不意味着易易互联技术薄弱，恰恰相反，从2017年开始，易易互联累计研发人员超千人、投入资金超十亿元，并具备了三项很重要的发明专利：快换锁体（Fast Bolt）、快换高压连接器、车站通讯模块。&nbsp;</p><p>最新的三代站相比于上一代，其双仓换电站的占地面积是71平方米，减少了近50平方米，此外，三代双仓换电站满仓电池是25块，换电次数一天可以达到540次。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_19964bae15594d53ac61c9cc8cc83c54@5020039_oswg1079847oswg1079oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p><p>以三代站的发布为节点，刘金良为易易互联立下了“未来三年建站2000座”的目标，希望渗透重点城市30座，累计服务车辆40万辆，管理电池资产规模200亿元。&nbsp;</p><p>面对换电行业的上升期，易易互联按下加速键。而为了支撑高速铺开的规模，刘金良提出了新型的换电站建设模式，在自营模式之外，易易互联还提供合伙人模式和托管人模式。&nbsp;</p><p>具体来看，合伙人模式由城市合伙人单独或与易易互联合资完成换电站投资；托管人模式则是易易互联投资建设换电站，托管人负责寻找地块、洽谈、签订协议和站务管理。&nbsp;</p><p>“合伙人也好，托管人也好，最重要的一个意图就是能够快速拓展，把愿意加入到新能源换电模式的人快速调动起来。”刘金良表示。&nbsp;</p><p>从业务层面来看，合伙人和托管人模式自然能够降低成本，迅速铺开规模，但更重要的是，换电在普通消费者的认知度仍不高，通过这种模式能够加速让行业上下对换电的认识。</p><h2><strong>公共出行最终都将是换电模式</strong></h2><p>虽然从数据层面来看，截至今年10月，全国换电站数量已经达到3220座，包括蔚来、奥动、宁德时代在内的多方企业都已参与其中，但换电生态仍是割裂的，目前每个企业都是一个孤立的岛屿。&nbsp;</p><p>真正实现全行业的互通互联，是换电的最完美结局，但也是最难的目标。涉及到的电池互换标准、不同车企之间的数据打通等，都是换电的终极难题，而且需要社会上下各部门的共同推进。&nbsp;</p><p>2021年4月，工业和信息化部会同相关部门印发《关于组织开展新能源汽车换电模式应用试点工作的通知》。通知提及&nbsp;“<strong>健全标准体系：制修订换电安全、换电接口、标准化电池箱、模块化电池等标注，鼓励相关团体标准先试先行</strong>”。&nbsp;</p><p>不过这远远不够，生态的打通需要有一家企业先达成突破，为行业提供一个成功案例，才会撕开更多合作可能性的口子。&nbsp;</p><p>已经走在前面的易易互联，想成为这名头雁。&nbsp;</p><p>“2024年我们希望做一个突破，我们已经突破了乘用车，现在突破到商用车来换电，我们还想突破到吉利体系以外，能够向别人开放我们的技术标准，让大家用我们的换电标准化电池包、标准化的底盘来造车，这样我们共同用一个电池银行，你造车身卖车身，然后电池银行为你服务或者卖整车来携电入网。”&nbsp;</p><p>最新的好消息是，2023年11月29日，吉利控股与蔚来签署了换电战略合作协议，双方将在换电电池标准、换电技术、换电服务网络建设及运营、换电车型研发及定制、电池资产管理及运营等多个领域展开全面合作。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_60217ec1167f41318c9bb0e8e88bbdc9@5020039_oswg690080oswg1079oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p><p>值得注意的是，根据协议内容，双方将通过“共投、共建、共享、共运营”模式，携手打造“私家车”和“营运车”两大换电标准体系。&nbsp;</p><p>这意味着，易易互联成功撕开了吉利体系外的第一个合作口子。而强强联合的合作一旦形成示范效应，就将有更多企业加入换电合作的队伍中来，全国换电标准的形成也就指日可待。&nbsp;</p><p>在政策端，基于多年在换电行业的运营经验，刘金良也提出了几点建议：换电行业需要做到一车两票两证，以明确车电分离后，电池的所有权在哪方；针对换电站的用电，能够做到一址多户，有利于充换电设施的申报和运营；建站审批方面，换电站应被看作一个设备，而非建筑，建站推广才会更加流畅；车电分离后，应专门开发换电车辆的电池保险产品。&nbsp;</p><p>整体来看，推行换电是毋庸置疑的选择，虽然道阻且长，但易易互联坚定地走在正确的道路上。只要车企之间的电池流动起来，电车就能最大程度提升城市效率，进而推动出行生态的电动化转型。&nbsp;</p><p>用刘金良的话说，终局畅想中，无人车的补能方式一定是换电，现在换电，司机已无需下车了，所以现在的换电已经在对接未来的无人驾驶了。&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547678861038471</id>
            <title>被苹果“抛弃”傍上华为“大腿”，模组大厂欧菲光的危机真的解除了吗？</title>
            <link>https://www.36kr.com/p/2547678861038471</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547678861038471</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 09:56:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为, 欧菲光, 摄像头模组, 供应链
<br>
<br>
总结: 华为发布的新机型Mate60系列中，欧菲光占据了绝大部分摄像头模组的订单份额，这给欧菲光带来了不菲的收入。欧菲光作为华为的供应链合作伙伴，因此受到了市场的追捧。然而，欧菲光的业务主要集中在中下游位置，受制于上游原材料供应和下游终端需求的影响。虽然进入华为供应链带来了转机，但欧菲光仍面临着供应链的挑战。 </div>
                        <hr>
                    
                    <p>每次华为、苹果等著名品牌发布新机，从性能到芯片，从售价到股价都会掀起一阵话题热潮。近日据媒体报道，在华为最新发布的机型Mate60系列后置摄像头、前置摄像头以及指纹模组的订单中，电子元器件制造企业欧菲光占据了绝大部分份额，单台手机摄像头模组的价值在500至600元之间。</p><p>调研机构TechInsights曾预计，整个Mate60系列在其生命周期内的出货量预计将达到500万至600万部，可能会给欧菲光带来不菲的收入。在Mate60的舆论热潮里，跟华为沾边的A股公司普遍迎来上涨，欧菲光成了最大的赢家，连续6个交易日收获涨停板，最高涨幅接近翻倍。截至发稿前，欧菲光股价处于9.8元/股左右，略有回调。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2b890151cbb94976a90e0837faf6c999@1743780481_oswg100983oswg946oswg825_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：百度股市通</p><p>鉴于苹果、华为等终端企业带来的巨量订单，是否能为其提供零部件供应，影响着众多供应商企业，无论是“果链”还是“华链”，背后都是一连串公司的“生死大戏”。我们今天要讨论的欧菲光，因切入果链而成为市场追逐的明星企业，后被踢出果链从云端跌落，走入至暗时刻。如今它靠着进入华为供应链再打翻身仗，一出一入间完成华丽转身，但，它的危机真的解除了吗？</p><h2>01 <strong>中游</strong></h2><p>欧菲光成立于2001年，最初主攻光纤通讯精密薄膜元件，其间时任柯达高级工程师的蔡荣军被邀请担任公司总经理，全权负责技术研发，后蔡荣军及其兄弟以1980万元买下公司，改为主营红外滤光片产品。2008年起，欧菲光切入手机触摸屏领域，借着全球智能手机发展浪潮，仅用5年便成为全球最大的薄膜式触摸屏供应商。2012年，欧菲光涉足影像系统领域，次年就已经成为全球消费电子摄像头模组龙头，出货量在全球数一数二，蔡荣军也荣登2013年福布斯中国富豪榜，以44.2亿元人民币排名295位。纵向看，从早期的滤光片到触摸屏，再到如今的智能手机、智能汽车，欧菲光的业务重点是根据市场需求动态调整的。</p><p>当前，以光学技术为圆心，欧菲光的业务重点主要分为三类：智能手机、智能汽车、新领域。2022年财报显示，智能手机业务占收入大头，其次是智能汽车相关收入，新领域（智能家居、VR/AR、工业、医疗、运动相机等新领域光学光电业务）占收入排名第三位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b20ecd8de06a41f28fd9f8643fb14c8a@1743780481_oswg141268oswg704oswg303_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：欧菲光官网</p><p>欧菲光的智能手机产品包括手机摄像头模组、手机镜头、微电子相关产品。从产业链来看，上游在原材料领域，包括光学玻璃、光学塑料、晶圆制造等等，中游为图像传感器、音圈马达等关键元器件，模组制造商约处于中下游位置。下游是苹果、华为等等各品牌的电子消费终端，是订单大户得罪不起，而往上游延伸的成本又太高、代价太大，处在中下游的位置，受制于两端的影响，其中又以下游终端带来的影响最甚。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b5b91d2ad6214a6997f7174d0a8d7318@1743780481_oswg132554oswg820oswg318_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：长城证券</p><p>一个智能手机摄像头的制造成本中，主要包括图像传感器（CMOS）、模组封装、光学镜头、音圈马达、红外滤光片等部分组成，其中图像传感器是摄像头组成的核心，也是最关键的技术，占据手机摄像头成本的约五成。如今的智能手机功能逐渐趋同，鲜有突破性的创新，而光学给用户带来的感受更直观，体验感强。因此，各大智能手机制造产商均在提升摄像性能上大做文章。</p><p>多数普通用户一味追求像素高，甚至认为像素足够高便是好手机，其实并非像素越高拍照就越清晰，图片的清晰度和单位像素面积直接相关。单位像素面积越大，图片就越清晰，而单位像素面积≈传感器面积/像素数目。如果传感器面积不变，像素越大，就会导致画质越差。当然一部手机的面积不会无限大，里面搭载的传感器尺寸终究是有上限的。除了增加传感器尺寸外，目前还可通过像素四合一技术进行处理，此处不展开论述了。图像传感器领域的创收能力最高，索尼的CMOS图像传感器业务在2021年就为其带来82亿美元的收入，它和三星在该领域中占有绝对统治地位，相比之下，欧菲光处于中下游的镜头模组组装，收入规模受制于客户订单情况，毛利率则徘徊在12%左右。</p><p>索尼对相机模组业务不是没有努力过。2016财年第二季度的财报显示，索尼半导体业务（包括影像传感器和相机模组）销售收入为1937亿日元（约19.18亿美元），营业利润亏损42亿日元（约0.41亿美元），顺道把集团整体营业利润拉下水，同比降低48%，为457亿日元（约4.53亿美元），至此索尼认清了一个事实：相机模组的业务好坏很大程度上依赖于客户的订单需求，与其累并痛苦着，不如聚焦核心技术，在自己擅长的领域做到最好。在图像领域，索尼决定出售其在华南的模组业务，集中精力发展图像传感器（CMOS）技术。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f0336a5162834eb8aa9093b9a82cc699@1743780481_oswg331788oswg934oswg685_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：索尼官网</p><p>彼时欧菲光花费2.34亿美元（全部股权作价0.95亿美元，计入偿债款1.39亿美元）的巨资盘下了这块业务。盘下这块业务后，欧菲光提高了生产线的自动化程度和生产中的先进水平，顺利引入FC封装技术，成为国内唯一拥有这项技术的厂商，并顺利进入“果链”（苹果产业链）。</p><h2>02 <strong>代价</strong></h2><p>进入果链、得到苹果的大量订单后，欧菲光忙碌不已。一方面，欧菲光对苹果手机的产量预估十分乐观，不断扩大产能。从欧菲光财报信息来看，2016—2017年时，投资支付的现金占比最多。2018—2020年，购建固定资产、无形资产和其他长期资产支付的现金占比最大，尤其是在2018年所支付的现金，高达67.24亿元，说明欧菲光在成为果链企业之前的两年，投资主要是权益性投资，在进入果链之后大量对固定资产、无形资产和其他长期资产投资。欧菲光内部投资主要是机器设备，尤其是在2017年和2018年，新增的设备投资超过了营业收入的10%（分别为13.44%、11.8%），其次是房屋建筑类的固定资产。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_440b46beaef84c4a88e3c00de52f5097@1743780481_oswg307257oswg1080oswg649_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：根据欧菲光财报整理</p><p>另一方面，欧菲光快速扩张，背后存在对巨额资金的渴求，2017年，欧菲光的筹资活动净额为39.18亿元，到2018年飙升至57.42亿元。2017年至2019年，欧菲光实现营收337.91亿元、430.43亿元和519.74亿元，同期毛利率为13.76%、12.32%和9.87%，净利率则仅有2.43%、-1.23%和0.99%，亏损时有发生。</p><p>增收但利微薄的同时，高企不下的负债率给公司背上了沉重的包袱。近五年，欧菲光的资产负债率分别为77.08%、72.93%、73.71%、60.68%及78.31%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_01054dbb4b6b4e788aebceb742823855@1743780481_oswg367907oswg1053oswg665_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：欧菲光2023年半年报</p><p>2023年半年报显示，欧菲光短期借款、长期应付款、长期借款、一年内到期的非流动负债合计达73.7亿元，占总资产的41%，仍承担着巨大的资金链压力，让本来毛利就不高的业绩雪上加霜。</p><p>关键是，一系列扩产和收购动作并不能让欧菲光高枕无忧，因为资金密集型的相机模组业务始终向筹码够多的玩家敞开。2018年，消费电子巨头立讯精密的关联企业立景创新，以3.6亿美元现金+10%本公司股权的大手笔，收购台湾光宝的相机模组业务事业部（CCM），杀进了这个市场。</p><p>光宝CCM事业部主攻手机、平板、笔电等消费电子产品领域，已有十余年的历史。2017年时，光宝的摄像头模组的实力已经不容小觑，当年出货量全球排名第19，双摄模组出货量全球排名第8，2018年Q1光宝CCM事业部收入为53.39亿新台币，Q2为87.53亿新台币。2022年底，光宝旗下影像事业部门更是将资产，如存货、机器设备、技术、智慧财产权、客户与供应商关系，作价9.1亿元人民币（约当于新台币40亿元）出售给立景创新。</p><p>此外，2020年12月，立景创新科技还通过21.96亿港元收购高伟电子3.74亿股股份入主，共计持股公司44.87%股权。高伟电子1997年在韩国成立，早期从事光学部件的制造及销售，目前核心主业为相机模块，是苹果、三星、LG电子等知名企业的供应商，2020年上半年，该公司的相机模组收入占比达到99.97%，其中苹果公司是绝对的第一大客户，常年收入贡献超过80%，2019年达到97%。</p><p>强者不断进入，本来就微利的相机模组市场很不断迎来永不停歇的战斗，不光是国内，未来欧菲光很有可能还要面临着东南亚、印度地区企业的挑战，这种惨烈的厮杀是由模组行业缺少技术壁垒所决定的。抬眼望，相对于模组，镜头是个更赚钱的生意，像中国台湾手机镜头“一哥”企业大立光，今年前10个月营收372.86亿新台币(约84.53亿人民币)，只有欧菲光2022年收入的一半，但利润却高达29.6亿元人民币，和欧菲光过去3年净利润连续负值形成鲜明对比。这样的收入和利润处境下，欧菲光拿什么来立于不败之地？镜头模组市场激烈厮杀之余，新的业务蓝海在哪里？<strong>我们下篇分析。</strong></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/5_e44xeSRZtvx6z-IuPx3w" rel="noopener noreferrer nofollow" target="_blank">“博望财经”（ID:BowangCaijing）</a>，作者：天峰，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547645879341957</id>
            <title>“AI抢工作”噩梦成真，“欧洲花呗”冻结招聘，要用AI完成大部分工作</title>
            <link>https://www.36kr.com/p/2547645879341957</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547645879341957</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 09:46:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, AI, Klarna, 员工减少
<br>
<br>
总结: 欧洲科技公司Klarna计划通过人工智能技术减少员工数量，CEO表示AI可以更快地完成工作，公司将不再招聘非工程师岗位员工。他认为人工智能对经济领域的许多工作岗位构成威胁，但并不打算裁员，而是期望员工自愿离职。Klarna正在利用AI处理订单纠纷，并计划在金融应用程序中添加更多人工智能功能。公司准备进行股票上市，估值可能高达150亿美元。 </div>
                        <hr>
                    
                    <p>自人工智能去年末大火以来，“AI会不会抢走人类的工作”就成为全世界讨论的热门话题，不少机构还为此给出了预测报告，分析哪些工作最有可能被AI“抢”走。</p><p>而如今，这个打工人们的担忧已经开始变成现实：AI已经开始抢工作了。</p><p>据外媒报道，“欧洲版花呗”Klarna最近已经冻结招聘，并计划缩减员工规模。其CEO认为，未来该公司的大部分工作都可以靠人工智能来完成。</p><h2><strong>欧洲金融独角兽开始用AI减少人力需求</strong></h2><p>Klarna是欧洲最大的科技公司之一，其“先付后买”服务风靡欧美，截至2022年末在全球拥有1.5亿用户。目前，该公司拥有超过5000名员工。</p><p>该公司CEO塞巴斯蒂安•西米亚特科夫斯基（Sebastian Siemiatkowski）表示，<strong>该公司将不再招聘工程师以外的其他岗位员工，并预测，通过人工智能技术，公司的员工数量未来将大大减少。</strong></p><p>Klarna CEO西米亚特科夫斯基在接受采访时表示：</p><blockquote><p>通过人工智能，现在可以更快地完成以前需要花很多时间的事情，我们现在只需要更少的人来做同样的事情…对我们而言，正确的做法就是现在试试不招人了，然后来看看结果如何。</p></blockquote><p>他还表示，尽管他并不打算裁员，但随着公司员工自愿离职，预计公司规模将随着时间的推移而逐步缩小。</p><p>他认为，<strong>随着ChatGPT等工具的广泛使用，人工智能对整个经济领域的“许多工作岗位构成了威胁”。</strong></p><p>西米亚特科夫斯基还强调，他之所以作出只聘用工程师、停止聘用其他岗位的决定，是出于他对人工智能潜力的信心，而非该公司商业基本面存在问题。</p><p>一年半前，Klarna曾因互联网科技寒冬而市值大幅下降，公司也一度裁员数百人。不过最近，Klarna公司经营情况似乎已经转暖，公司不仅实现了四年来的首次季度盈利，并正在为IPO做准备，预计将于明年上市。</p><h2><strong>已在利用AI处理订单纠纷</strong></h2><p>早在ChatGPT去年末推出以来，Klarna就是该AI产品的最大拥趸之一。目前，<strong>公司正在利用ChatGPT技术快速分析客户服务记录，并自动处理买家和卖家之间的订单纠纷。</strong></p><p>西米亚特科夫斯基表示，他希望在Klarna的金融应用程序中添加更多面向消费者的人工智能功能，希望这能帮助它朝着成为“个人理财助理”迈出一步。</p><p>在Klarna拥抱人工智能之际，该公司正准备进行股票上市，其估值可能高达150亿美元。</p><p>西米亚特科夫斯基表示，该公司尚未决定在哪里上市，美国肯定是优先考虑目的地，但欧洲和英国股市也在考虑范围之内。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_E_VCRcgK8tgpnjVjYthjQ" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”（ID:Chinext_Observer）</a>，作者：刘蕊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547649081070726</id>
            <title>罚没百万后，这家公司决议解散</title>
            <link>https://www.36kr.com/p/2547649081070726</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547649081070726</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 09:38:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 广州市白云区市场监督管理局, 中国科学技术大学, 有容公司, 化妆品包装
<br>
<br>
总结: 广州市白云区市场监督管理局发布行政处罚信息，有容公司因在化妆品包装上冒用中国科学技术大学名义被罚款约106万。这一事件再次提醒行业人士不要在生产、经营过程中违规行为，否则将损害自身利益。 </div>
                        <hr>
                    
                    <p>日前，广州市白云区市场监督管理局发布的一则行政处罚信息显示，广州某公司因在化妆品包装上冒用“中国科学技术大学”名义并进行销售，而被罚没款约106万。</p><p>众所周知，近年来知名大学“被联名”现象泛滥，监管、平台等层面也屡次对相关违规现象进行处罚、清退。此次有化妆品企业被罚没超百万，无疑是给行业人士敲响了“警钟”，在生产、经营过程中妄想“抄近道”，最终必将损害到自身利益。</p><h2><strong>蹭中国科学技术大学，罚！</strong></h2><p>据信用中国（广东广州）官网公布的处罚信息显示，2022年6月22日，广州市白云区市场监督管理局根据佛山市三水区大塘镇人民政府移送的线索，发现广州有容生物科技有限公司（以下简称：有容公司）涉嫌生产经营标签不符合规定化妆品违法行为，遂依法立案调查。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a7ee265987c6427aabe20cf2eb6c5793@1743780481_oswg132476oswg1080oswg767_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">截自信用中国（广东广州）官网</p><p>经查，有容公司分别于2021年11月、2022年4月委托纯沅（佛山）医药生物科技有限公司（以下简称：纯沅公司）生产了“臻颜滋养套盒（5件套）”化妆品共计6770盒，并以198元/套的价格出售，总货值金额134万余元。其中，有4670盒产品已销售完毕，获得销售收入92.5万元。</p><p>广州市白云区市监局查明，上述臻颜滋养套盒化妆品为国产普通化妆品，备案人系有容公司，实际生产企业则是纯沅公司。在该化妆品外包装上，正面显著位置标注有“中国科学技术大学技术支持”、“专利号：ZL201110163192.4ZL2011010157776.0”的字样。但有容公司承认，上述化妆品的生产和销售过程与中国科技大学并无任何关系，且无法提供中国科学技术大学同意以其名义进行产品宣传的证明材料。</p><p>基于上述信息，广州市白云区市监局认定有容公司备案产品标签上“中国科学技术大学技术支持”字样属于虚假或者引人误解的内容。但鉴于有容公司已取得上述专利所有人中国科学技术大学的授权使用，最终广州市白云市监局对其作出了从轻处罚，没收违法所得并罚款共计约106万元。</p><p>今日，青眼号外通过拼多多、淘宝平台检索发现，涉案产品仍在正常售卖中。其中，淘宝平台主要是两家分别名为“纯沅CHANGE’U”、“纯沅护肤品尊享店”的店铺正在售卖该套装产品，产品售价在760-1080元不等；拼多多平台则主要是一名为“纯沅护肤品店”的店铺在售卖相关产品，标示售价为655元/套。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_8c392ea72d544a56a7b7edba24567f7d@1743780481_oswg128284oswg1080oswg1127_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">截自淘宝（截图时间2023年12月4日）</p><h2><strong>涉事企业已决议解散！</strong></h2><p>据国家企业信用信息公示系统及企查查信息显示，有容公司成立于2020年1月，法定代表人为夏某明，企业经营范围包括化妆品技术开发、化妆品及卫生用品批发、互联网商品零售等。在今年9月20日，因通过登记的住所或者经营场所无法与该企业联系，广州市白云区市场监管局已将有容公司列入经营异常名录；10月18日，有容公司还被广东省广州市白云区人民法院列为被执行人，执行标的4.26万元。</p><p>值得一提的是，青眼号外发现，就在11月30日有容公司发布了债权人公告信息，表示公司因决议解散，拟向公司/农民专业合作社登记机关申请注销登记。同日，有容公司还备案成立了清算组，清算组负责人、成员即为公司法定代表人夏某明。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_308118fa75df4ae3a26a774695fc2527@1743780481_oswg60819oswg1056oswg669_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">截自国家企业信用信息公示系统官网</p><p>而广州市白云区市监局对有容公司做出的处罚决定日期为2023年11月27日。也就是说，有容公司在被罚3天后，即决定解散公司并开始清算资产。</p><p>不过，据《公司法》相关规定显示，在清算期间，公司存续，但不得开展与清算无关的经营活动。而青眼号外调查发现，在抖音平台中，有一名为“广州有容生物科技公司”的账号仍处于运营状态。在有容公司清算组成立当日（即11月30日）和12月2日，该账号还更新了两条产品推荐视频，并在相关视频中展现了“中叶双美·美集现”化妆品套盒。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_bc3de55fb3694790ba58dab30ad6baaa@1743780481_oswg208446oswg1027oswg2130_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">截自抖音（截图时间2023年12月4日）</p><p>青眼号外通过中国商标网查询发现，中叶双美、美集现的第三类商标所有者均为有容公司。据相关视频描述，中叶双美·美集现定位为“涂抹式新医美抗衰”，声称“不用打针、不用动刀，每天只需在家涂抹3分钟，便可达到年轻3-5岁，甚至5-10岁的效果”，且“孕期哺乳期均可使用”。</p><p>此外，该套盒内有美集现玫瑰抗皱紧致精华液、美集现玫瑰发酵抗皱面霜两款产品，其声称产品成分包含“富勒烯【钻石级KS（抗衰）之王】”、透皮多肽【ym（医美）级别透皮肽】、多重安全高效美白成分等”，可“激发肌肤活力、年轻常态化逆龄生长”等。</p><p>据国家药监局国产普通化妆品备案信息平台显示，上述两款产品的备案号分别为“粤G妆网备字2023366671”、“粤G妆网备字2023366672”，功效宣称为保湿、抗皱、紧致。根据《化妆品监督管理条例》及配套法规的相关规定，该抖音账号在进行普通化妆品产品宣称中，使用的“医美”、“孕期哺乳期均可使用”、“美白成分”等词汇或存在违规嫌疑。</p><p>针对公司决议解散的具体事由以及所宣传产品情况，青眼号外尝试联系有容公司了解详情，但截至发稿未获回复。</p><h2><strong>“打擦边球”的路行不通</strong></h2><p>在化妆品行业“产学研”合作盛行的当下，各大知名高校已然成了为企业产品研发实力做背书的重要工具和手段。但也有一批如有容公司一样的企业，未经同意便擅自将知名高校放在产品包装上，以扩大品牌声量、提高产品销量。</p><p>为规范化妆品市场宣称， 早在几年前，监管层面就屡有相关处罚爆出。比如2021年，广州市场监督管理局就曾发布行政处罚决定，广州九口山科技有限公司、广州雨晓生物制品有限公司因销售、生产产品标签标注有“中山大学化学工程与技术学院技术支持”字样的化妆品，但却无法提供中山大学同意以其名义进行产品宣传的证明材料，从而被处以相应的罚款措施。</p><p>除监管层面的处罚措施，更有名校亲自下场打假。就在去年“3·15”消费者维权日时，华南理工大学通过官方微信对外表示，市面和部分电商平台上出现了不少使用“华南理工大学”“华南理工大”等名称进行宣传的产品和店铺，涵盖防脱洗发水、面膜、美白产品等。在更早之前的2021年10月，华南理工大学官网还发布了相关声明，曝光了“媛涵何首乌发根滋养露、精华套装”、“圣娜姿II防脱育发液”等18个冒用华南理工大学名义售卖的商品黑名单。</p><p>可喜的是，不同于过往海量的、动辄销量10万+件，且标识有“大学研制”等字样销售的产品链接。今日，青眼号外在淘宝、拼多多、抖音等平台以“中山大学 化妆品”“大学 化妆品”“大学 美白化妆品”等关键词检索发现，现如今电商平台相关宣称的产品称得上“锐减”，且出现在搜索栏前列的产品销量大多集中在数百、几千件。可见，电商平台也对相关违规商家与产品进行了有力的清除。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_7c10b772a68f489d9fa6d1d23a0794be@1743780481_oswg191494oswg1080oswg2073_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">截自抖音（截图时间2023年12月4日）</p><p>​ 可以看到，通过监管层面、销售平台以及大学的多方位“打假”，“大学研制”化妆品泛滥现象已得到了一定的遏制。而此次有容公司从“蹭大学”被罚没款百万余元，到现如今公司决议解散，无疑是对行业的又一次警醒，忽视对产品研发创新的投入、对自有品牌形象的建设，只埋头走“蹭名牌”“打擦边球”的路，最终就是自取灭亡。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/FZZnVXXNTN2bEEZxQwnrIQ" rel="noopener noreferrer nofollow" target="_blank">“青眼号外”（ID:qingyanhw）</a>，作者：号外，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2546330910680837</id>
            <title>当苹果芯片跌落神坛</title>
            <link>https://www.36kr.com/p/2546330910680837</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2546330910680837</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 09:18:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 安卓手机芯片, 苹果A17 Pro, 性能测试, 芯片逆袭
<br>
<br>
总结: 近年来，安卓手机芯片在性能和能效上逐渐超越了苹果A17 Pro，这种逆袭让苹果芯片感到委屈。高通和联发科的手机芯片在CPU和GPU方面的性能提升幅度较大，而苹果的芯片性能提升相对较小。安卓芯片的逆袭主要原因是苹果步伐放缓，而高通和联发科不断提升性能和能效。此外，架构升级和工艺红利的消退也对苹果芯片造成了压力。 </div>
                        <hr>
                    
                    <p>最近国内安卓阵营迎来了一波接一波的新机发布热潮，而在各家发布会上，苹果A17 Pro着实成了“常客”，只不过这个常客，是被各路安卓手机芯片在性能测试中赶超的对象。</p><p>是的，<strong>今天的安卓手机芯片，已经在性能和能效上双双反超苹果了。</strong>这种“委屈”，恐怕之前的苹果芯片都没受过。</p><p>相比高通、联发科手机芯片近年来的高歌猛进，苹果近两代芯片的性能提升似乎有些“挤牙膏”。</p><p>在一些业内人士来看，在这场安卓芯对苹果芯的逆袭中，苹果“跑的慢了”占了更主要因素。即使一开始差距很大，但如果对手用跑的，苹果用走的，被追上必然是迟早的事了。</p><p>前不久陆续登场的两大安卓芯王——高通骁龙8 Gen3以及联发科天玑9300，在CPU多核性能、CPU多核能效比、GPU峰值性能、GPU能效比等核心技术指标上均已领先同时期的苹果A17 Pro。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_d079b3b14cec47a09dade69c8d59a0de@000000_oswg27133oswg1080oswg705_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">CPU能效曲线，黄色点为天玑9300，蓝色线为骁龙8 Gen3，绿色点为苹果A17 Pro，性能向上方增加，功耗向右侧增加，来源：极客湾</p><p>苹果芯片输了“能效比”，这放在两年前还是难以想象的，GPU方面的性能差距，一度让网友们调侃称高通和联发科用了“外星科技”。</p><p>如果说去年的A16是被“部分超越”，那么今年的A17 Pro就是被全面赶超，仅剩CPU单核性能还保有一定优势。</p><p>两年不到，<strong>手机芯片性能擂台彻底“变天了”，苹果似乎不再“遥遥领先”。</strong></p><p>为什么安卓芯片可以在短短几年里从追赶到超越？苹果为什么跑得更慢了，而高通联发科又是如何一步步追上的？我们将从架构、工艺、人才技术等多方面入手，尝试寻找背后的深层次原因。</p><h2><strong>01.苹果牙膏挤没了，高通联发科的牙膏踩爆了</strong></h2><p>苹果的步子真的迈的更慢了吗？通过梳理近20年来高通、联发科、苹果三家厂商发布的旗舰级自研手机芯片，我们发现事实的确如此，尤其近几年，这一趋势愈发明显。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_c728c9feb61f4da4b7a1b79d4cad9189@000000_oswg1315914oswg771oswg2060_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">近六年高通、苹果、联发科旗舰手机芯片CPU、GPU性能和能效提升情况（部分）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_a07ca298b3234b71a749af70db579ca4@000000_oswg112670oswg1080oswg682_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">近五年苹果、高通、联发科部分旗舰手机芯片CPU性能提升幅度情况，每年每家厂商仅选取一款旗舰芯片，部分苹果CPU性能提升为大核性能提升，趋势仅供参考</p><p>高通、联发科两家厂商的旗舰芯片，CPU每年的性能提升幅度多则60%，少则20%，而CPU能效比的提升也是同步的，通常在25%到45%之间。</p><p>至于安卓阵营提升幅度较大的GPU方面，高通和联发科芯片每年提升的幅度最高甚至可以达到80%，30%以上的提升是十分常见的，其GPU能效比的提升幅度甚至还要超过性能的提升。</p><p>简单来说<strong>，高通和联发科这边每年的旗舰芯片基本上都能在性能和能效上有显著的提升，即使偶尔有“翻车”现象发生，但并不影响长线性能提升的大势，</strong>并且“马儿跑得快，马儿还吃草少”的情况经常出现在安卓芯片阵营中。</p><p>反观苹果这边，从A15到A17 Pro，每代芯片的CPU性能提升仅有10%左右，A16一代提升幅度更小，其GPU甚至直接沿用了上代A15的规格。</p><p>向更早期追溯，从A12开始，苹果芯片性能提升幅度已经开始有放缓趋势，A14芯片GPU性能提升幅度仅有8%。</p><p>在搭载A16的iPhone 14 Pro发布之初，就有不少媒体测试发现，相比前几代iPhone产品的性能提升，iPhone 14 Pro在GPU性能方面的提升幅度极小。</p><p>最近高通骁龙8 Gen3和联发科天玑9300发布后，苹果芯片在GPU方面的差距被进一步拉大。</p><p>苹果近年A17 Pro的GPU上新增的渲染新特性以及对硬件级光线追踪的支持，都已经是高通和联发科两年前就已落地的特性。</p><p>不可否认，<strong>苹果手机芯片的步子的确走的慢了，安卓手机芯片是实打实地赶上来了。</strong></p><h2><strong>02.架构升级不够看，工艺红利消退，逼得苹果玩起了“超频”？</strong></h2><p>提到芯片性能和能效比，大家最先想到的就是工艺和架构的影响。安卓芯片的逆袭，跟芯片制程工艺和芯片架构又有着怎样的联系？</p><p>在讨论之前，我们先要明确，通常我们说的Arm架构，是指芯片CPU内核所使用的架构，而厂商们常常说的“1+3+4”或“1+5+2”架构，则指的是CPU的内核是如何配置的，虽然都是“架构”，但实际上说的并不是一回事。</p><p>从CPU的内核配置方式来看，最近联发科提出的“全大核”架构概念引起了业内的广泛热议。天玑9300直接放弃了“小核”，采用了4个超大核+4个大核的架构。</p><p>虽然联发科的这一举措看起来很“大胆”，但当我们将时间线拉长就会发现，这种“全大核”的概念更像是一种不一样的叫法，而类似的架构设计其实在高通和联发科的芯片发展历史上都有出现过。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_66dec94607964b8781a6b59a8ccd42a6@000000_oswg992511oswg747oswg2050_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">近10年高通、联发科、苹果旗舰手机芯片CPU内核配置情况</p><p>比如2014年前后联发科的MT6595、高通的骁龙810，其CPU采用的都是“4+4”的架构设计，只不过当时的“大核”，例如A17、A57，性能远不及如今的大核。</p><p>简单来说，<strong>经过多年技术迭代，当年的大核，如今只能相当于“小核”，而今天例如A55、A510这样的小核，放在多年前，也能有“大核”的地位。</strong></p><p>而纵观近年来高通、联发科芯片在CPU架构上的调整，这种“大核越来越多”的设计，其实早有预兆，并不是突然涌现的。</p><p>在高通骁龙8 Gen2这一代上，高通将此前沿用了多年的1+3+4架构更换为1+4+3，大核增加、小核减少，而在今年的骁龙8 Gen3上，高通进一步将大核数量增加为5个，小核数量减小到2个。</p><p>在联发科一口气增加了3个超大核的同时，高通同样也在默默增加大核。并且高通的5个大核中，有3个的最高频率都已经来到了3.2GHz，这与此前的超大核频率都已十分接近。</p><p>实际上，不论是“超大核”、“大核”、“中核”、“小核”，还是“性能核”、“能效核”，这只是厂商对于产品的命名，透过架构的变动，我们能够看到的核心趋势就是，<strong>手机芯片对于性能的需求，依然在快速增加，</strong>“手机芯片性能过剩”的言论，近年来也鲜有见到。</p><p>既然如此，<strong>苹果为什么多年来一直采用的是“2+4”的6核配置，苹果芯片的性能提升又来自于哪里？</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_54c12d9d364b477c896199fa279e3f6a@000000_oswg24523oswg800oswg353_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>实际上，这一方面涉及到芯片内核架构的迭代。苹果是三家厂商中对于自研内核架构这条路走的最为坚定的。从2012年苹果A6芯片改用自研内核微架构之后，苹果A系列芯片就一直采用“深度自研”的基于Arm的架构。</p><p>虽然高通也尝试推出过基于Arm指令集的一些自研CPU内核微架构，例如Scropion、Krait，但后来其还是转向了基于Arm的“半定制”设计，虽然名字为“Kryo”，但本质上仍然是“定制版Arm”，因此也很难与直接采用Arm架构的联发科芯片拉开明显差距。</p><p><strong>一些业内人士指出，此前每代苹果A系芯片的性能提升，很大一部分来自于内核架构的改进，</strong>例如分支预测能力的提升、扩宽解码单元和执行单元。</p><p>并且值得一提的是，从芯片物理层面的晶片尺寸大小来看，苹果的“小核”，其实很多时候比安卓端的“大核”还大，苹果在芯片规格方面的“堆料”，也是其单核性能长年领先的重要方面之一。</p><p>在梳理近年三家芯片CPU核心频率的过程中，我们还发现，<strong>苹果从2021年的A15开始，似乎在芯片核心频率提升方向上有些“用力过猛”。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_0b6fcf09a3fd4ead8630b6629dc49b0d@000000_oswg1680130oswg747oswg2650_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">近10年高通、联发科、苹果旗舰手机芯片CPU最高频率情况</p><p>在苹果A14之前，苹果芯片的CPU最高频率往往都低于同时期的高通和联发科芯片，并且当时苹果也并没有在工艺方面有明显优势，同时期的芯片工艺通常都在同一代中。</p><p>但从A15之后，苹果芯片的最高频率突然开始显著提高，尤其是在最近的A17 Pro上，其CPU的最高频率甚至达到了惊人的3.78GHz，要知道，很多笔记本电脑上的处理器都没有这么高的运行频率。</p><p>相比之下，同时期高通和联发科芯片的最高频率都在3.3GHz左右，仅频率上的差距就达到了14.5%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_51277d898fb341a1b09ca99c8b8c257f@000000_oswg75100oswg660oswg972_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">近十年苹果、高通、联发科部分旗舰手机芯片CPU最高单核频率情况，每年每家厂商仅选取一款旗舰芯片，趋势仅供参考</p><p>苹果芯片的单核性能的确有明显优势，但如果去掉晶体管数量和单核频率的差异，苹果单核性能的优势必然会明显缩小。</p><p><strong>这或许也从侧面反映了苹果当下芯片性能提升的方式，已经较为局限了，甚至不惜在“超频”的路上越走越远。</strong></p><p>今年台积电3nm工艺表现不及预期，加之苹果芯片频率的大幅提升，这代A17 Pro发热明显高于前代也就并不令人意外了。</p><p>既然提到了频率和工艺，纵观三家芯片巨头在芯片制程工艺方面的使用，我们也能发现一些特点。</p><p>实际上，在智能手机发展早年间，台积电工艺还不像如今这样抢手，苹果A4、A5、A6、A7使用的都是同时期三星的工艺，不过来到7nm及更先进节点后，台积电工艺就已占据绝对主导。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_eb143d82d8674fffa934db671f15898d@000000_oswg1183033oswg667oswg2560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">近20年苹果、联发科、高通旗舰手机芯片工艺情况</p><p>虽然近年来台积电在工艺制程方面的优势被不断放大，但当工艺迭代至5nm以后，工艺提升带来的性能提升已经远不及从前。这也是苹果不得不以“超频”来换取性能提升的一部分原因。</p><p>正如前文所说，从苹果A6到A12这六年间，每年苹果、高通、联发科三家使用的工艺基本上都在同一代，苹果并不是一直在工艺方面有“垄断式”的优势。</p><p>与其责怪台积电工艺不及预期，不如说，<strong>当苹果指望依靠工艺垄断来实现性能领先时，苹果就已经输了一半。</strong></p><p><strong>芯片性能提升不及预期，还要从苹果自身找原因。</strong></p><h2><strong>03.苹果芯片团队巨震，灵魂人物出走，高通联发科趁势追击</strong></h2><p>如果从苹果自身找原因，摆在明面上的就是近年来苹果芯片团队的剧烈震荡。此前外媒《信息报》（The Information）的一篇报道更是揭露了不少苹果芯片研发团队内部存在问题。</p><p>据报道，从2019年以来，苹果芯片团队中有不少人离职，这些离职的工程师有些去创业了，有的则直接跳槽到其他芯片公司就职，涉及人员有数十个之多。</p><p>其中就包括大名鼎鼎的<strong>苹果首席CPU设计师Gerard Williams III，</strong>他在2010年从Arm公司加入苹果后，就一直操盘着苹果核心的芯片研发相关工作，主持研发了A7一直到A14等诸多苹果自研芯片，苹果的M1系列首席架构师也是他。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_e7990514d32a453caf9082ee0ecc5376@000000_oswg54599oswg800oswg800_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Gerard Williams III</p><p>我们对苹果硬件技术高级副总裁Johny Srouji都十分熟悉了，他经常在苹果发布会上露脸，也是苹果芯片业务当下的一把手，据报道，<strong>Williams在苹果芯片团队中的地位仅次于Srouji。</strong></p><p>在来到苹果之前，Williams参与了诸多经典Arm CPU架构的研发，可以说是移动芯片设计领域的顶级专家。</p><p>这种级别的负责人离开，对团队的影响是很大的，尤其是他还带走了一部分苹果芯片团队的员工，跟另外两位芯片圈大佬共同创立了芯片创企NUVIA。Williams也因此吃了苹果的官司。</p><p>其实还有一家芯片创企Rivos也被苹果起诉过，这家公司更狠，直接从苹果挖走了40多人，其中还包括Ricky Wen这样的芯片圈大牛。</p><p>据报道，在Williams走后，苹果又挖来了Arm的首席架构师Mike Filippo来接替他，但无奈Filippo跟苹果团队不和，于2022年离开苹果加入了微软。</p><p>其实苹果很少直接拉外部高管来担任要职，更多都是自己“内部培养”，紧急挖来Filippo，对于苹果来说必然不是上策，同时苹果手机芯片团队的动荡，对其芯片的迭代和技术创新是有严重不利影响的。</p><p><strong>在上述苹果芯片团队2019年前后的这一系列动荡之下，最直接的“受害者”就是苹果A16芯片。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_8fcc15d536634511b1b94808a5a1e053@000000_oswg83397oswg1080oswg471_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">iPhone 14 Pro Max主板，来源：iFixit</p><p>据《信息报》报道，苹果的A16原本计划会有“大幅飞跃式”提升，但由于原型机的功耗太高，导致机身发热严重，甚至影响了电池寿命，苹果不得不紧急做出调整，砍掉了本该在A16上就出现的光线追踪技术，同时GPU也直接沿用了前代A15的设计。</p><p>报道中的几名知情人士称，<strong>这种“乱象”在苹果公司中是前所未有的（unprecedented snafu in the group’s history）。</strong></p><p>当时这位记者在报道中预测，如果苹果的“A17”性能提升还是如此之小，高通和联发科的芯片很可能会在性能上实现反超。</p><p>如今，一语成谶，预言成真。</p><p>值得一提的是，2021年12月，在苹果任职超过8年的M1芯片设计总监Jeff Wilcox也离开了苹果，此次苹果M3系列芯片迭代的“放缓”， 或许也同样与芯片团队的动荡有着千丝万缕的联系。</p><p>从2019年的团队动荡至今，我们并未在公开报道中看到有新的芯片圈大牛加入苹果。</p><p><strong>相比苹果芯片团队的动荡分离，高通芯片团队则增加了不少精兵强将。</strong></p><p>前文提到的芯片创企NUVIA，在成立仅14个月后就被高通公司以13亿美元收购。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_5f00e20665f148199c53082518cefd99@000000_oswg70329oswg900oswg508_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">从左至右：John Bruno、Gerard Williams III、Manu Gulati</p><p>除了来自苹果的芯片大佬Gerard Williams III，NUVIA的副总裁Manu Gulati也曾担任谷歌首席SoC架构师，甚至还在苹果担任了8年多的首席SoC架构师，负责过苹果A5X、A9、A12X等多款处理器的设计。</p><p>在博通和AMD的工作经历也给Gulati增加了不少PC处理器和移动芯片的研发经验。</p><p>此外，NUVIA的另一位高级副总裁John Bruno也是芯片圈的一位老兵，在ATI、AMD、苹果工作过，曾参与过AMD最早一代APU的研发设计。</p><p>集合了这么多芯片圈大牛的NUVIA，就这样被高通一口吃下，这些芯片人才都成为高通芯片研发的新力量。</p><p>收购仅仅过去了两年多，今年高通的自研CPU Oryon就已经正式亮相了，也足见收购对于高通的重要意义。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231204/v2_ba307acb4f8a42ccb7421037689e39e0@000000_oswg74728oswg1080oswg736_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2023年10月骁龙峰会上高通发布的骁龙X Elite采用了高通自研的Oryon CPU</p><p>实际上，NUVIA的强项就是设计能够提高内存带宽、CPU利用效率、持续性能的CPU架构，而放弃“堆核”或者“超频”的传统思路。</p><p>据报道，NUVIA的自研CPU架构Phoenix比其他所有竞品的峰值性能都高50%到100%，功耗还更低，并且性能随着功耗增加而边际效益递减的问题也优于其他竞品。</p><p>可以说，NUVIA的强项，都是高通所需要的，高通需要做出兼顾高性能和高能效比的新自研CPU架构。</p><p><strong>相比高通这边直接吸纳成熟团队，联发科这边大有一副从头培养优秀人才的架势。</strong></p><p>根据联发科官方信息，从2021年年中开始，联发科就在积极招募优秀人才，招聘规模超过2000人，给硕士毕业生开出了超过46万元人民币的起步年薪，而博士毕业生的起步年薪接近60万元。</p><p>除了高薪吸纳新人才，据称联发科在内部也鼓励员工推荐优秀人才，并配以各种新人推荐奖励。</p><p>联发科一把手蔡力行曾在公开发言中说到，联发科的目标是“成为全球最具竞争力的IC设计公司”。</p><p>联发科从2021年开始研发投入有明显增加，2022年研发投入约为40亿美元，2022年四季度研发投入占比一度超过了25.9%。</p><p>众所周知，人才是芯片产业发展的基石，全球半导体产业人才储备不足问题长期存在，芯片人才无疑是一项稀缺的“战略资源”。</p><p><strong>对于苹果、高通和联发科来说，人才争夺战，必将会持续上演。而能否把握住优秀芯片人才，也必然会成为影响后续芯片迭代的关键性因素。</strong></p><h2><strong>04.结语：AI大模型风浪涌起，手机芯片产业暗流涌动</strong></h2><p>安卓芯片逆袭苹果，并非一朝一夕之功，看似短短两代的反超，其实是此前多年间架构、工艺等技术博弈以及人才激烈争夺等一系列复杂因素综合作用的结果。</p><p>这次，苹果芯和安卓芯来了一次“角色互换”，作为当下“追赶者”的苹果，要如何解决人才流失的问题？高通和联发科又能否稳住当前的优势并进一步跑的更快？都成为会影响手机芯片产业发展的重要变量。</p><p>今天，在手机CPU、GPU性能之外，芯片的AI能力也逐渐走到了“C位”，成为各家芯片厂商在发布会上重点宣传的方面，在AI大模型落地智能手机的过程中，高通、联发科等芯片厂商无疑承担着关键角色，芯片无疑是大模型应用的硬件基础。</p><p>手机芯片在AIGC时代又将迎来怎样的挑战，有哪些新的需求涌现出来？芯片巨头们又会如何应对，手机芯片之战，正迎来另一个精彩的高潮。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652765671&amp;idx=1&amp;sn=3b980275c23dcd81be29e615f1775561&amp;chksm=847d6ae9b30ae3ff0f2ede36c21bc00bc0d9e1d1d3d7c6d1368b77600458d5e21f175e037615&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：云鹏，编辑：心缘，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547609602085765</id>
            <title>药明生物暴跌带崩CXO板块，“卖水人”的黄金时代落幕？| 焦点分析</title>
            <link>https://www.36kr.com/p/2547609602085765</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547609602085765</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:50:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 药明生物, 业绩调整, CXO板块, 新增订单
<br>
<br>
总结: 药明生物发布业绩调整后，公司股价大幅下跌，影响了整个CXO板块。业绩调整主要是由于药物开发和生产两块业务的下滑，导致收入减少。药明生物的商业模式中，新增项目订单数量是重要的收入增长指标。今年上半年新增订单减少，导致下半年收入下滑。CXO板块面临医药研发投入下滑、新冠疫情需求消失和海外竞争等挑战。 </div>
                        <hr>
                    
                    <p>文｜胡香赟</p><p>编辑｜海若镜</p><p>12月5日开盘后，药明生物虽一度跌超10%，但CXO板块整体趋于稳定，“业绩下调”的余震影响未再持续。</p><p>12月4日一早，药明生物更新的2023年业绩在行业内引起广泛关注。公司称，新项目减少、监管审批延迟将导致公司今年收入将不及预期；此外，新增产能利用率降低也会导致利润下滑。</p><p>受此影响，药明生物开盘大跌20%，勉强拉起一段时间仍没抵挡住“跌跌不休”的态势，最终临时停牌。截止昨日停牌前，公司跌23.79%，报33.15港元。其余CXO板块的头部企业药明康德、康龙化成、凯莱英、博腾股份昨日也分别出现大幅下跌。</p><p>回想10月底时，药明生物CEO陈智胜“全年新增120个项目目标不变”的承诺，公司披露的业绩调整着实来得有些突然。</p><p>不过，这样的故事在今年6月就曾发生过一次。当时，海外CXO公司接连拿下跨国药企大额订单，而药明生物上半年整体新增订单量下滑，一度就曾引发过市场对外资大厂“远离中国CXO”的担忧。</p><p>本次业绩调整的说明会上，药明生物在回应相关提问时表示，今年公司合同收入在30亿美元左右，这一数字在疫情前及疫情期间分别是10亿美元和20亿美元左右。单从业务量上来看“客户的需求完全没有变”。“2023年和2024年上半年将是挑战最严峻的时期，但公司仍然对未来增长充满信心。”</p><p>这个回应，能否稳住资本市场对CXO板块的信心？</p><h2><strong>“外部因素”影响业绩的背后</strong></h2><p>按照药明生物的说法，影响了今年业绩的主要是药物开发（D端）和生产（M端）两块业务，预计收入分别下滑18%-20%和15%-18%。这也成为药明生物2017年登陆港交所以来，首次披露收入下滑。</p><p>D端和M端是药明生物CRDMO商业模式中较为重要的两环。“CRDMO”，简单理解就是端到端、全链条覆盖，不是临床前或临床阶段某一环节的服务，而是只要这款产品的原理靠谱，就能一站式支持药企将药品开发至上市。</p><p>相较于那些只做早期药物发现的同行，把链条向后期拉长虽有风险，但回报也高。比如从公司今年中报里就能看出，D端和M端对应的进入后期临床和商业化生产的订单量虽少，但收益最高能达到临床前开发的10倍左右。今年上半年，药明生物III期临床及商业化生产的收入比例达到总数的42.4%，而IND前及早期的I、II期临床开发分别为33.1%和23%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_285ac2c5c63c4cce8b73ad828230427c@5930287_oswg157942oswg1194oswg680_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：药明生物2023年中报</p><p>这样的业务模式中，每年新增项目订单数量就成为最重要的收入增长指标。陈智胜在本次业绩调整的说明会上也表示，平均而言每个新增项目能为公司带来700万美元收入，如果按照往年130个左右的新增来算，可能带来的收入就是10亿美元。</p><p>剔除新冠项目，过去两年药明生物每年新增项目订单都在120个以上，前期订单的消化也让公司在今年上半年仍维持了17.84%的正向收入增长。所以，当时外界虽存在诸如中美地缘因素，导致订单流向韩国等新兴CXO市场；全球医疗健康行业投资和研发市场不景气等低靡情绪，但并未在很大程度上影响行业对公司实际经营的预期。</p><p>直至12月4日的业绩调整文件发布之前，市场对药明生物甚至都颇为看好。三季度时，药明生物重回张坤易方达蓝筹精选的前10大重仓股之位；葛兰的中欧医疗创新基金也在同期加仓药明生物。</p><p>但问题在于，今年上半年，药明生物新增订单只有46个，同比去年的59个减少13个。导致今年下半年时，公司收入出现直观下降，这才有了昨天的这出“药明生物带崩CXO板块股价”的大戏。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_542613d1277f45bcae8381adf9ecab80@5930287_oswg436446oswg1476oswg800_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：12月4日药明生物业绩调整文件</p><p>按照业绩调整文件，D端下滑源于生物技术融资放缓、行业下行周期中，年初“120个项目的目标过于激进”，比去年减少的40个新项目影响了3亿美元收入；而CMO业务下降则是因为与FDA的沟通延长拖累了项目进度，预计损失1亿美元。</p><p>本次说明会上，公司又进一步回应称，3亿美元损失是因为CDO项目收入主要体现在后期。比如一个总价800万美元的项目，前6个月的收入贡献大约只有100万美元，也就是10%-20%。所以今年上半年签单量减少，对上半年的收入影响相对有限，但在主要计收的下半年，收入下滑颇为直观。</p><p>这在一定程度上解释了药明生物为何突然下调业绩指引。</p><p>去年以来，创新药增长放缓，CXO领域出现下滑原本也只是周期性现象，市场是有预期的。但问题在于，在此之前药明生物的表现少有消极预兆，这才引发了昨日外界对公司乃至整个CXO赛道的恐慌情绪。</p><p>今年下半年开始至11月30日，药明生物新增订单数量为45个，已经“比上半年预期的要好”。不过，药明生物也坦言，由于合同到收入的转换需要时间，今年下半年新增订单可能到2024年下半年才能产生明显的收入贡献。</p><h2><strong>下半场决胜局：订单量、产能爬坡与价格PK</strong></h2><p>尽管药明生物在业绩调整中仍对未来做出了乐观的业绩增长预期，但一个无法回避的事实是，CXO板块的业绩根基在于医药研发的持续投入，但随着全球医疗健康融资和研发投入下滑、新冠疫情需求消失，以及海外同行“崛起”，国内CXO行业在维持了过去几年15%左右的双位数增长后，终究还是迎来了阵痛期。</p><p>一直以来，国内头部CXO企业的业绩大多来自海外，尤其是欧洲和北美地区的订单。从过往收入构成来看，药明康德、康龙化成、凯莱英以及博腾股份中国区的收入占比基本都维持在20%以下。今年中报显示，药明生物北美、欧洲和中国地区的收入占比分别为46.3%、30%和21.1%。</p><p>正是这样独特的业务构成，也在过去的数年间给了国内的CXO企业规避医药领域系列政策影响，维持业绩持续增长的底气。</p><p>今年，国内CXO企业面临的最大变数也来自于海外同行。年中时，韩国财团三星集团旗下的三星生物接连获得辉瑞、诺华合计13亿美元的订单之后，细微的平衡被打破。</p><p>当时，外界普遍认为三星生物打的是“价格战”。药明生物也在投资者开放日时回应称，三星生物是靠“极低的价格”拿下项目，而公司认为在CXO这一长周期赛道中，拼价格、快速提高产能率的行为不是很有必要。</p><p>十几亿美元的订单不要，只为维持定价体系？药明生物的“坚持”和当时的市场氛围有些格格不入。在订单紧缺的情况下，其实国内CXO企业自己也在试图依靠降价抢单，比如药石科技在今年上半年的投资者关系活动上也曾表示，由于市场对价格的竞争较为激烈，公司也考虑通过价格价格让步换取更大的订单规模。</p><p>一个更合理的解释是，从产能的利用率上来看，药明生物可能没办法通过快速放开产能而大幅降价。据药明生物披露，截止去年年底，公司总体产能为26万升左右。从今年年中交流会上披露的数据来看，药明生物国内上半年的产能利用率在60%左右，下半年可达到80%；相较之下，海外基地的爬坡进度也不快，今年只有20%，预计在明后两年才分别能达到50%和80%。</p><p>与此同时，药明生物也在加速更多的产能建设。公司预计，2026年时全球产能将达到58万升，较2022年增长约30万升，大部分布局都在海外：其中，新加坡工厂将投资14亿美元，新增12万升的生物制剂产能；德国生产基地产能也将由1.2万升扩至2.4万升。本次的业绩调整文件中，药明生物又表示，爱尔兰的疫苗厂建设也接近完成，预期可产生“疫苗项目工艺转移收入和厂房建设付款”。</p><p>只是，今年以来，全球CXO竞争格局改变的“导火索”已经被点燃，海内外相关企业的“抢单”场面逐渐变得更激烈。随着先发优势被同行们相继占得，药明生物的产能爬坡即使在后期逐步跟上，市场上每年还有多少“新增项目订单”能留给药明生物，值得长期关注。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547470419386249</id>
            <title>接入大模型，手机终于要长“脑子”了？</title>
            <link>https://www.36kr.com/p/2547470419386249</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547470419386249</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:42:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI大模型, 智能手机, 端侧大模型, 手机厂商
<br>
<br>
总结: 近期，华为、小米、vivo、OPPO、荣耀等国产手机厂商纷纷推出了支持AI大模型的智能手机。这些手机采用端侧大模型，可以让用户更高效、便捷、安全地使用人工智能。然而，将大模型应用到手机上并不容易，需要平衡模型量级、AI体验和手机能耗等问题，并承担巨大的成本投入。尽管如此，大模型手机对于用户和厂商来说都具有重要价值，可以成为手机厂商市场竞争的筹码，也有望革新手机和其他硬件终端的使用体验。手机厂商之所以密集布局自研大模型，主要是因为通用大模型无法完美适配手机，并且使用云端大模型存在成本和安全问题。 </div>
                        <hr>
                    
                    <p>AI大模型的战火，烧到了智能手机上。</p><p>最近一段时间，<strong>华为、小米、vivo、OPPO、荣耀等国产手机，均已对外公布众多大模型相关成果。</strong>目前，头部厂商不仅纷纷下场自研大模型，而且正在把能离线运行的端侧大模型，植入到新一代机型中，打造所谓的“AI大模型手机”。</p><p>相比调用云端算力的通用大模型，端侧大模型可以让用户更加高效、便捷、安全地使用AIGC。不过将其应用到手机上也不容易，不但要考虑到模型量级、AI体验和手机能耗的平衡等问题，还要承担<strong>从落地到迭代每年数十亿元的成本投入</strong>，这对于手机厂商的硬实力也是种极大的考验。</p><p>但大模型手机对于用户和厂商均价值非凡：一是在用户换机动力匮乏的寒冬下，AI大模型将成为手机厂商市场竞争的重要筹码；二是AI大模型未来有望变成每个用户专属的超级助理，革新手机乃至所有硬件终端的使用体验。</p><h2><strong>厂商开卷大模型</strong></h2><p>在手机+大模型的竞争中，每一个厂商都不想掉队。</p><p>早在7月份，华为就在开发者大会上发布了面向行业的盘古大模型3.0，最高版本高达1000亿参数，并官宣新一代智能操作系统HarmonyOS 4已接入了盘古大模型，小艺也成为首个具有AI大模型能力的终端语音助手。<strong>9月份，华为宣布大模型版小艺开启众测，首批支持机型为Mate 60/P60系列手机。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_50064d342cdb4eb0beee613b100717a7@5891894_oswg393508oswg1080oswg359_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：网络</p><p>8月的年度演讲上，小米创始人雷军透露其自研大模型（MiLM）中的13亿参数版本已经成功在手机本地跑通，部分场景可以媲美60亿参数模型在云端运行结果，旗下Y语音助手小爱同学也已开始升级大模型版本。<strong>10月底，小米宣布自研AI大模型已经接入最新发布的澎湃OS，搭载到了小米14系列上。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d103ae671dd845dcab13503500ecb3bd@5891894_oswg51835oswg1080oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：网络</p><p>10月26日，荣耀CEO赵明宣布，即将推出的Magic6系列手机，将支持自研70亿端侧AI大模型。赵明表示，荣耀对于端侧大模型的理解，将通过MagicOS 8.0和荣耀Magic6系列呈现出来，“有非常多、非常惊艳的创新在里面”。</p><p>11月1日，vivo的蓝心大模型矩阵（BlueLM）在其开发者大会上亮相，包含十亿、百亿、千亿等不同参数规模，随后vivo还推出基于该大模型开发的应用“蓝心小V”和“蓝心千询”。<strong>11月13日，vivo发布了行业首款AI大模型手机X100系列，落地终端侧70亿参数大模型，跑通端侧130亿参数模型。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_101a26dfc7dc459da8f48303381fe500@5891894_oswg86553oswg1080oswg723_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：网络</p><p><strong>11月16日，OPPO在开发者大会上正式推出了安第斯大模型（AndesGPT）。</strong>根据官方介绍，该模型支持从10亿至千亿多种不同参数规模模型，将会被接入到OPPO的手机操作系统ColorOS 14以及物联网操作系统潘塔纳尔OS，OPPO Find X6等机型于同日首发升级正式版。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_24ef964bd31f4223b07bf4da105a72f5@5891894_oswg219768oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：网络</p><p><strong>手机厂商密集布局自研大模型，主要是因为通用大模型无法完美适配手机。</strong></p><p>在手机上使用AI大模型并非新鲜事，ChatGPT、文心一言、讯飞星火、通义千问等通用大模型都推出了App版本，允许用户在移动端体验。不过这些App依赖的都是云端大模型，需要调运服务器算力并进行数据传输，因此也存在成本和安全问题。</p><p>vivo副总裁周围曾在接受媒体采访时表示，<strong>目前调用一次云端大模型的平均成本在1.2分-1.5分人民币。考虑到每个手机厂商至少有上亿的用户量，假如每人每天调用10次，那么每年产生的成本就会达到数十乃至上百亿元。</strong>这部分成本由厂商长期负担不现实，但由用户付费也会降低使用体验和意愿。</p><p>此外，作为全球普及率、使用率最高的终端硬件，手机中存储着大量用户隐私信息，如果被上传到云端便会存在安全隐患。前不久，WPS AI就在用户隐私问题上差点翻车，因为其未更新的隐私政策中包含“将用户文档资料用于AI训练”的表述，金山WPS被冲上热搜并连夜道歉。</p><p>为此，厂商们都在致力于自研大模型，并且努力将大模型部署在手机本地，仅利用芯片的算力生成结果，无需联网也能运行，也就是所谓的端侧大模型。<strong>相较云端大模型，端侧大模型由于利用了手机终端的闲置算力资源，减少了数据传输，因此在很多场景下会更加高效、便宜、安全。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d8527a404b954552b9e746ebaca7d5b5@5891894_oswg83361oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>每年烧钱数十亿</strong></h2><p>把AI大模型植入手机并非易事。</p><p>目前主流的云端大模型，参数量都在千亿级别，对于内存、算力、功耗的需求是一台手机根本满足不了的。正因如此，<strong>手机厂商自研的端侧大模型体量都比较小，将参数压缩到了数十亿到百亿左右，以便在手机端运行。</strong>比如，vivo X100系列搭载的就是70亿参数版本的蓝心大模型。</p><p>值得一提的是，端侧大模型能够成功落地手机，离不开芯片技术的进步。</p><p>vivo X100搭载的天玑9300芯片，就是联发科在11月7日刚刚推出的新一代旗舰产品，该芯片搭载了生成式AI技术，支持终端运行最高达330亿参数的AI大模型。此外，联发科于11月21日发布的次旗舰芯片天玑8300，以及高通10月份新发布的骁龙8 Gen3芯片，也均支持终端运行超100亿参数的大模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_add72b902dc5492d873c0de0b064808b@5891894_oswg38136oswg1080oswg396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：联发科官网</p><p>轻量化、无需联网的端侧大模型，在响应速度、算力需求和信息保护上有与生俱来的优势，但在模型能力上无法媲美云端大模型。这是因为参数是衡量一个AI大模型质量的重要指标之一，通常情况下，参数越多，大模型能力也就越强大。</p><p><strong>为了实现大模型体验和手机性能的平衡，厂商们目前普遍采取了“端云协同”的策略，同时部署端侧和云端两种模型，根据不同的应用场景和需求来进行选择。</strong>比如，涉及个人隐私、金融数据等信息的任务，以及知识问答、写作绘画等简单任务就可以使用端侧能力，而训练模型等复杂任务则可以调用云端能力。</p><p>端云协同可以最大化地发挥“端侧快”和“云侧强”的优势，同时还能解决信息安全隐患、云端算力成本过高等问题，可以说是现阶段打造大模型手机的最优解。</p><p>这也正是很多厂商发布<strong>大模型矩阵</strong>的原因之一，前面已经提到，华为、vivo、OPPO发布的自研大模型方案，都覆盖十亿、百亿、千亿多个参数量级，其中轻量化模型就是用于端侧部署，而大参数模型则是用于云端部署。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_9fe9bd9fe80348bb967b39a08e35ec79@5891894_oswg56048oswg1080oswg722_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：网络</p><p>但大模型是公认的烧钱大户，无论是在端侧还是云端，其数据、算力、人工等方面的成本对于开发商来说都是一笔不菲的投入。</p><p>之前业内流传的说法是，<strong>一万枚英伟达A100芯片是做好AI大模型的算力门槛，而其单张成本就在10万元左右，这意味着搭建大模型算力集群的成本至少要数十亿元。</strong>在美国芯片禁令升级的当下，英伟达高算力芯片的价格还在蹭蹭上涨，而且有市无价。</p><p>此外，开发大模型的人工成本也很高。有行业人士表示，<strong>AI研发工程师的年薪基本都要7位数，一个千人研发团队一年至少也要20个亿。</strong>根据雷军在发布会上透露的数据，小米集团从事AI开发的研发团队已经超过了3000人。</p><p>vivo副总裁周围接受媒体采访时透露，自2017年组建AI全球研究院至今，vivo每年在人工智能上的投入保守估计在20亿-30亿元。他还表示，大模型是硬科技的赛道，研发投入和难度跟通信、芯片是同一个级别的。</p><h2><strong>重塑手机体验？</strong></h2><p>厂商不遗余力的投入，是因为大模型对于手机行业价值非凡。</p><p>在ChatGPT出现之前，手机行业的创新长期都集中在摄像、屏幕、通信、材料、芯片等领域，在全球手机市场疲软的当下，这种“挤牙膏式”的变化很难刺激消费者的购买欲望，用户的换机周期也在持续拉长。根据Counterpoint数据，2022年全球手机换机周期已经延长至43个月。</p><p>大模型的诞生，让行业看到了新的创新方向。大家普遍认为，<strong>AI能力将成为未来用户换机和选择手机品牌的重要考量因素，而大模型就是手机厂商在市场竞争中的重要筹码。</strong></p><p>一个手机能不能跑大模型、能跑多大的大模型，和内存、算力等硬件配置息息相关。因此在初期发展阶段，大模型手机就成了手机品牌彰显硬核配置、打造高端形象的有力武器。</p><p>等到大模型成为行业标配，手机厂商的战场则会转移到大模型手机的体验上。从华米OV的答卷看，<strong>目前大模型和手机的结合方式，主要是围绕语音助手进行体验创新。</strong></p><p>一方面，在大模型的赋能下，语音助手的语义识别、图像识别等能力都得到了强化，从而能够更加智能化的执行指令，提升用户的交互体验。</p><p>以语音助手的“语义搜索”功能为例，过去想要在手机上搜索文档或者图片，只能依靠分类AI的识别，通过某些场景关键词描述缩小搜索范围，例如风景、美食、人像等。而在有了大模型能力后，用户就可以通过自然语言描述图片、文档内容来完成搜索。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_e70defacfdc542ea9e1b3df5157dd87d@5891894_oswg45817oswg857oswg911_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：网络</p><p>另一方面，有了大模型的加持，语音助手也将具备云端大模型App同款的“智能问答”、“AI写作”、“AI绘画”、“实时字幕”、“文档总结”等功能，化身提高工作和学习效率的生产力工具。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a85b7874f5eb49abaff52878c505e71c@5891894_oswg51204oswg591oswg707_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：网络</p><p>此外，在手机厂商的预期里，<strong>未来的大模型手机还将朝个性化方向发展，变成用户的专属私人助理。</strong>就如同现在被广泛应用的算法推荐，经过长时间的使用后，用户的数据也都会被用于端侧大模型的训练和迭代，进而让大模型手机像一个“老朋友”一样越来越懂用户。</p><p>到了那一天，由于不同品牌之间存在生态壁垒，用户更换手机所要付出的代价也将会更大，这样手机品牌也就能借助大模型来增强用户粘性，进一步巩固自己的护城河。</p><p>不过眼下大模型手机还在起步探索阶段，未来哪家厂商能够决胜千里，还要取决于模型、应用和产品的迭代创新。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/E9wU6VaT2512uu6Y-R-L0w" rel="noopener noreferrer nofollow" target="_blank">“亿欧新消费”（ID:EO-Consumer）</a>，作者：王鹏，编辑：顾彦，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547384432858240</id>
            <title>欧洲版OpenAI，给ChatGPT之父狠狠上了一课</title>
            <link>https://www.36kr.com/p/2547384432858240</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547384432858240</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:42:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 权力, 资本, 利益, OpenAI
<br>
<br>
总结: 在权力和资本斗争中，OpenAI创始人Sam Altman因利益纠纷被罢免CEO职务，但他坚信为爱发电可以长久。与此相比，被称为“欧洲版OpenAI”的Mistral AI在权力和资本的游戏中更为稳健。 </div>
                        <hr>
                    
                    <blockquote><p>跟权力和资本斡旋背后，更本质的是利益。</p></blockquote><p>在今年5月的美国国会听证会上，ChatGPT之父、<strong>OpenAI</strong>创始人<strong>Sam Altman</strong>跟议员之间有这样一段对话。</p><p>议员：“你赚了很多钱吧？”</p><p>Sam：“我没有 OpenAI的股权，我的收入只够买保险。”</p><p>议员：“真的吗？那你需要一个律师或者代理。”</p><p>Sam：“我做这件事只是因为我热爱它。”</p><p>议员始终带着邪魅微笑，Sam眼神清澈透亮。议员认为Sam没有股权，迟早会有利益纠纷，而Sam坚信为爱发电可以长久。</p><p>事实证明，姜还是老的辣，议员的预判成了现实。最近，Sam被OpenAI董事会罢免了CEO职务，虽然最终他又重新回到了OpenAI，但其中的“宫斗大戏”实在过于惊险。</p><p>被自己创立的公司赶出去，这在许多国人眼中是难以想象且难以接受的。这背后，权力和资本斗争是掀起变局的主导力量，Sam被打了个措手不及。倒是被称为“欧洲版OpenAI”的<strong>Mistral AI</strong>，在权力和资本的游戏中走的更为稳健。</p><h2><strong>01 “ChatGPT之父”出局谜团</strong></h2><p>先说Sam的出局谜团。</p><p>2019年，OpenAI搭建了一个十分特别的股权架构，即有盈利上限的有限合伙企业（OpenAI LP）。这个架构之下，OpenAI董事负责整个有限合伙企业的管理和运营，包括CEO的任命与罢免，LP则主要包括投资人，其回报都有设定上限。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_c8892a75da274660906d2072a2ca693f@000000_oswg142718oswg1039oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">OpenAI股权架构</p><p>大部分董事会的成员数量为奇数，因为可以实行少数服从多数。让人疑惑的是，OpenAI原本董事会成员数量为双数（只有6人），分别是Sam Altman、Greg Brockman、Ilya Sutskever、Helen Toner、Adam D’Angelo、Tasha McCauley。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a441ff7272284c6fb9337a7fe0da2869@000000_oswg766388oswg1080oswg714_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这种架构本身就有点谜。根据OpenAI官方说明，其董事会多数成员相互独立，彼此有不同的背景，共同指导OpenAI发展。如果对于某项提议，如果始终是一半人支持一般人反对，或者各执一词，那么决策始终难以推进。</p><p>对于Sam的离职，Brockman表示是Ilya Sutskever要求进行快速会议，随后通知了Sam离职的消息，具体细节外界不得而知。而OpenAI方面的公告表示，Sam的离职是由于他在与董事会的沟通中始终不坦诚，阻碍了董事会履行职责的能力，以至于董事会不再相信他有能力继续领导Open AI。</p><p>部分媒体表示，Sam的离职是跟Ilya Sutskever之间产生了矛盾。</p><p>彭博社称，Ilya在公司的职责被减少，反映出他与Sam之间的摩擦，Ilya后来向董事会提出上诉，赢得了一些董事会成员的支持。另外，Ilya与Sam之间在人工智能安全、技术发展速度和商业化等方面，也存在较多分歧。</p><p>还有部分人怀疑，是微软这个大股东主导了这场离职大戏。毕竟，微软迄今一共向OpenAI注资130亿美元，作为最大的LP持股达到49%。</p><p>不过，这种说法站不住脚。</p><p>首先，OpenAI方面表示，微软投资的OpenAI其实只是OpenAI子公司。微软所拿到的OpenAI股份，也只是OpenAI子公司的股份。其次，微软并没有在OpenAI获得董事会席位。也就是说，微软对于OpenAI的实际控制能力并不强。</p><p>并且在Sam离职后，微软等OpenAI 的投资人还向董事会施压，要求召回Sam重新担任公司CEO，显然微软不会是那个“幕后黑手”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_cd6755209a524c29a430ac4995711ec3@000000_oswg276339oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事实上，已经有不少投资机构对于OpenAI的董事会结构发出警告。Y Combinator联合创始人Paul Graham表示，Sam被解雇的事件揭示了董事会结构的危险。连Sam自己也终于“醒悟”，希望公司的管理层能进行重大改革，包括董事会成员全部辞去职务等。</p><p>这场“宫斗大戏”在前不久迎来结局， Sam Altman正式回归OpenAI，重新担任CEO，同时OpenAI的董事会将迎来重组。</p><p><strong>不过，关于这场纷争的思考还没结束。被称为“欧洲版OpenAI”的Mistral AI，在对公司的控制和跟资本的斡旋上，似乎更为清醒。</strong></p><h2><strong>02 “欧洲版OpenAI”的平衡术</strong></h2><p>今年 5 月，三位大学同学<strong>Arthur Mensch</strong>，<strong>imoth é e Lacroix</strong>和 <strong>Guillaume Lample</strong>再次在法国相逢。</p><p>其中，Arthur Mensch曾任谷歌旗下AI公司DeepMind的高级研究科学家，Guillaume Lample 和 Timoth é e Lacroix 曾在Meta人工智能团队共同领导了大型语言模型LLaMa的开发，都是技术专家。</p><p>三人聚到一起后，因为被生成式AI和OpenAI的热潮所感染，于是成立了一家名为Mistral AI的公司。Arthur Mensch 担任CEO，Guillaume Lample担任首席科学家，Timoth é e Lacroix担任CTO。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_c91cf0f72d78484f8382ea63328c3e0a@000000_oswg580044oswg720oswg1078_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>令人意外的是，成立之初Mistral AI整个团队只有6个人，而且还没有产品，仅凭7页PPT就获得了1.13亿美元的种子轮融资，创造了欧洲有史以来最大的种子轮融资。</p><p>更让人意外的是，种子轮里挤进了14家投资方，而且阵容非常强大。 里面既有美国头部老牌VC，又有欧洲各国风投，还有知名企业的高管，比如前谷歌CEO埃里克施密特、法国电信亿万富翁泽维尔尼尔等等。</p><p>都知道生成式AI掀起了资本热，但热成这样还是比较少见，这件事要分两个层面来看。</p><p>一方面，欧洲在AI领域正在加速布局。数据显示，今年到现在美国AI业务的风投有270亿美元，而欧洲只有40亿美元，后者只有前者的1/7，资本还有很大布局空间去寻找有潜力的欧洲选手。</p><p>另一方面，对于Mistral AI来说，既想要钱又不想失去控制权，其中一个办法就是引入众多投资者，同时让投资份额小且分散，这样创始人就能牢牢控制公司。数据显示，由于参投Mistral AI的机构众多，每家机构的投资额在500万-1500万美元之间，占股仅几个点。</p><p>这种“去中心化”的投资方式，显然是一种更为高明的“平衡术”——既拿到更多支持企业发展的资金，又大大降低了失去控制权的风险。</p><p>相比Sam Altman为自己“没有股权只是热爱”而骄傲，Arthur Mensch显然更为理智。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_462367dbe5ca41eeab5bc89c1a8125da@000000_oswg766108oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事实上，一家初创企业合理的股权架构，本身就应该保证核心创始人对公司的控制权、保证公司股权结构的稳定，同时也要提前约定股权兑现、创始人退出时的股权处理机制，处理好与投资人的股权分配问题。</p><p>要知道，处在资本狂潮中的AI不属于硅谷，而是属于华尔街，最终要牵涉到谁来掌舵、谁来买单的问题。与权力和资本斡旋，是每一名初创AI企业掌舵人的必修课。</p><h2><strong>03 利益至上</strong></h2><p>跟权力和资本斡旋背后，更本质的是什么？</p><p>自然是利益。</p><p>对于主导让Sam出局的Ilya Sutskever来说，Sam影响到了他在企业管理中的权力，让其出局符合自身利益。</p><p>对于微软等投资方来说，之所以极力让Sam留在OpenAI，是因为Sam的离开一方面会影响OpenAI的商业化进程，另一方面会影响自己手中的股权价值。据报道，OpenAI最近以高达860亿美元的估值进行新一轮融资，Sam的离开可能会对这次融资有影响。</p><p>同样的，为何众多投资方愿意选择Mistral AI，这是因为后者正在对标OpenAI，开发符合更严格的欧洲法规的产品，并强调隐私和安全，这有助于它与OpenAI争夺欧洲企业客户，进而让投资方产生更多想象和增值空间。</p><p>商业世界里，企业创始人为爱发电没有错，错的是轻视了弱肉强食的丛林法则。在这片残酷的竞争场中，始终要关注能否守好自己的阵地，这是一门大学问。</p><h3>参考来源</h3><p>France’s Mistral AI blows in with a $113M seed round at a $260M valuation to take on OpenAI</p><p>被OpenAI开除后，创始人奥特曼在微软找到了新工作</p><p>We compete with everybody’: French AI start-up Mistral takes on Silicon Valley</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI4MDUzMTc3Mg==&amp;mid=2247601126&amp;idx=1&amp;sn=a9347165b6c66d60ca9c9c0c3a299bbf&amp;chksm=ebb40db5dcc384a3dd47efc3c70c0e1f584439fa37366a8c4b5eb068682040f27ee5f5382376&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“硅兔赛跑”（ID：sv_race）</a>，作者：Eric‍，编辑：Zuri，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547577559012483</id>
            <title>明星败走 VC 圈</title>
            <link>https://www.36kr.com/p/2547577559012483</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547577559012483</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:35:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 娱乐明星, 跨界创投圈, 私募基金, 明星投资人
<br>
<br>
总结: 该文讲述了娱乐明星涉足跨界创投圈的故事，以及他们在私募基金领域的投资经历。明星投资人利用自身的名气和资源，尝试在资本市场获取更多财富。然而，随着行业变化和风险增加，明星投资人面临着挑战，而且现在的投资主线是科技，需要对行业和产业有很强的研究认知。此外，明星跨界投资退潮的信号早已出现，许多明星投资人已经退出或陷入沉寂。 </div>
                        <hr>
                    
                    <p>娱乐明星跨界创投圈的故事，还在不断更新剧情。</p><p>最新剧集更新到，曾被称为投资圈“颜值最高女 VC”的 Angelababy 杨颖，其旗下一只私募基金于近日注销、解散。</p><p>天眼查 APP 显示，近日，宁波星鎏股权投资中心（有限合伙）企业状态由存续变更为注销，注销原因为“决议解散”。公司注销并不罕见，但此次注销引起了外界的关注，主要原因还是该股权投资中心与杨颖之间存有一定关联。</p><p>资料显示，宁波星鎏股权投资中心（有限合伙）成立于 2015 年 5 月，是 AB Capital 旗下的私募基金，由董文英、杨铭、上海星弥资产管理有限公司共同持股。值得关注的是，<strong>AB Capital 是由杨颖成立的创投基金，而董文英杨铭都是杨颖的事业亲密伙伴，其中，杨铭曾担任杨颖的经纪人，董文英则是杨颖多个工作室的法人代表和投资人。</strong></p><p>杨颖旗下私募基金注销，也不过是众多明星跨界涌入资本市场现状的一个缩影。在近 10 年时间中，得益于经济的发展和资本市场的活跃，越来越多吸金能力不俗的明星开始涉足投资领域，试图利用自己的名气和资源获取更多的财富。</p><p>跨界创投圈的明星，在跨界早期往往不存在募资问题，在名人效应下，财富效应也能实现与日俱增。然而，当红利逐渐退却后，明星跨界的问题显现。明星名下私募基金注销、逐年降低的交易频次、频频退出关联基金公司的明星投资人……种种皆在暗示着，明星已告别创投圈，转身投向了下一个风口。</p><h2><strong>01 跨界为资本站台的明星</strong></h2><p>相对于“明星”以及“黄晓明前妻”身份，杨颖的“投资人”身份，鲜为人知。但从过往资料来看，创投圈对杨颖不会陌生，毕竟杨颖算得上娱乐圈第一波跨界创投圈的明星。</p><p>早在 2011 年，杨颖就投资数百万开设了个人品牌美甲店。同年，杨颖与导演陈国富等人合作，投资接近四百万港元在香港创立咖啡品牌“baby_cafe”，几乎同一时间，四家门店落地香港。尽管在 2018 年，杨颖在港的咖啡店均已倒闭，但这并不影响 baby_cafe 在当时也有过高光时刻。</p><p>搞起副业的杨颖，也追着“明星 VC”的风口，于 2015 年涉足 VC 圈。2015 年 6 月，杨颖进军股权投资基金，宣布成立 AB Capital。彼时，AB Capital 方面透露，杨颖将结合自身的工作，与投资的项目形成战略营销联盟。AB Capital 在项目的选择上，更侧重于关注新女性生活方式的创业公司。</p><p>AB Capital 成立之初，也投了一些颇具热度的互联网项目。分别有跨境电商平台洋码头、断食果汁 HeyJuice、女性美妆社区美啦等。</p><p>有意思的是，杨颖给项目投资之余，还利用自身名气亲自为产品站台，担任“产品经理”“明星代言人”“产品设计师”等虚职。</p><p>利用影响力在创投圈搅动风云的明星，自然不只杨颖一人。</p><p>杨颖的前夫黄晓明，便颇具商业头脑。签约华谊兄弟的黄晓明，在 2009 年华谊兄弟筹备上市时看准时机，以 3 元/股的价格购入 180 万股华谊兄弟股份。华谊兄弟上市首日股价一度冲高至 91.8 元/股。黄晓明也因此身家暴增，持股市值超 1.6 亿元，黄晓明一下子跨入到了亿万富翁的行列中。</p><p>此后，黄晓明将目光投向影视、餐饮、运动、科技等多个领域。除了当股东外，黄晓明也早早进军 VC 圈。2014 年，黄晓明与李冰冰、任泉共同出资组建风险投资机构 Star VC，间隔一年，章子怡和黄渤也加入 Star VC 中。</p><p>成立至今，Star VC 对外投资了数十个项目，覆盖电子商务、汽车交通、人工智能、文娱传媒、企业服务、医疗健康、金融、硬件等行业，其中投资较为高频的时间是在 2017 年前后，投资过秒拍、商汤科技、理想汽车等知名项目。</p><p>除了 Star VC 之外，黄晓明还和资深投资管理顾问张晓婷共同创立“明嘉资本”，明嘉资本的投资围绕泛娱乐领域展开，包括网络文学、视频、直播、VR/AR、游戏竞技等。比较知名的项目有同道大叔、网鱼网咖等。</p><p>提到跨界投资的明星，就不得不提娱乐圈的“跨界歌手”胡海泉。</p><p>有人用“不想创业的明星，不是好的投资人”来戏谑胡海泉多元化的身份，其也很乐于接受这样的评价。在参加综艺节目时，胡海泉更是很“大方”亮明自己的投资人身份，指出在节目中看到的“卡丁车”和“奶茶”，是自己过去投资过的项目。</p><p>胡海泉创办的私募海泉基金，也一度是明星跨界做创投的典范，在市场上颇为活跃。主要专注于娱乐文创、消费升级、人工智能等领域，曾投资了睿米科技、大咖拍卖、胡桃里等项目。</p><p>胡海泉也一度劝说自己身边有影响力的艺人也学着做些投资，“明星的收入非常高，但理财的方式非常单一，不应该只以消费为乐趣。事实上，把投资的满足感和理财的智慧用到一个点的话，对未来人生是最大的改变。”</p><h2><strong>02 明星 VC 时代退潮</strong></h2><p>不可否认，早期的明星投资者确实抓住了投资的风口。2015 年以后，在“双创”和“供给侧结构性改革”政策的推动下，人民币基金的发展势头迅猛，无论是在募资还是运作方面都日益成熟。</p><p>在这个背景下，许多明星凭借其知名度和影响力，自立门户成立基金。他们利用自身的资源和影响力，打造以自己为核心的 IP，在投资初期吸引了大量的关注。素有“明星 VC 第一人”之称的任泉，就曾在接受媒体采访时表示，“Star VC 对外宣布成立第一天，就收到了上千封项目介绍书。”</p><p>然而，花无百日红。随着行业变化和风险增加，他们的投资之路并不总是一帆风顺。现在的投资主线是科技，这意味着投资人需要对硬科技项目进行投资，需要对行业和产业有很强的研究认知，这对于擅长利用资源驱动的明星 VC 来说，充满了挑战。</p><p>此外，明星所创立的私募股权基金，经过 8、9 年的发展，现在已经到了基金退出的阶段。然而，从整体大环境来看，消费文化类 IPO 的节奏正在逐渐收紧，上市困难的同时，也很难找到接盘基金。一方面，企业可能没有足够的资金回购；另一方面，股权转让也不容易找到下家，因此，实现退出并不容易。</p><p>实际上，明星跨界投资退潮的信号来得还要早一些。</p><p>在近日“杨颖旗下私募基金注销”冲上热搜榜之前，杨颖旗下的 AB Capital，最近一笔投资事件发生在 2020 年，彼时 AB Capital 与九合集团一起，参与了智能商业平台及企业数据服务商智能投管云的 B 轮融资。时隔 3 年，AB Capital 没再出手。</p><p>同样渐渐消失在创投圈视野中的明星投资人，除了杨颖，还有黄渤、黄晓明、胡海泉、任泉等人。</p><p>早在 2020 年，除了任泉外，Star VC 原股东黄渤、李冰冰、黄晓明、章子怡等人便陆续退出。此后黄晓明将个人重心放在了自行创办的明嘉资本上，并负责旗下相应的投资事项，在 2016 年，明嘉资本也曾风光一时，频频出手，但此后便陷入沉寂中，2018 年至今 5 年时间中，仅有的一次出手，时间记录于 2021 年。</p><p>而在“玩隐退”这件事上，胡海泉也不遑多让。</p><p>今年 7 月，胡海泉参与管理的一家私募基金公司因违规行为被北京证监局采取行政监管措施，引爆投资圈。当晚，海泉基金通过微博发布回应称，收到投诉和北京证监局的警示意见后，已经尽快向该局如实汇报有关情况，指出投诉中的不实内容；同时根据要求完成了整改。随后，胡海泉转发该文，并表示“清者自清，任重道远”。</p><p>有意思的是，也就是这时，外界才发现胡海泉原来已不是海泉基金的实控人。天眼查数据显示，当前海泉基金的三大股东分别是尹承双、汪文忠和王昱。天眼查变更记录显示，2021 年 10 月，该公司法定代表人由胡海泉变更为尹承双，2022 年 2 月，胡海泉退出该公司股东，改由尹承双持股。</p><p>此外，中基协机构提示信息显示，海泉基金当前存在长期处于清算状态。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_17890b6426014694b685314f0c347dda@000000_oswg160814oswg1080oswg470_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而由任泉等人投资的九州建元，今年以来接连因涉及“非法吸收公众存款罪案件”“股权冻结”等负面登上热搜。过去常以投资人身份接受外界采访的任泉，对此也无回应，公司声明“任泉只是其财务投资人，不负责经营管理”，是对任泉踏雷事件的全部回应。</p><h2><strong>03 退潮不意味着结束</strong></h2><p>随着杨颖、任泉、黄晓明、胡海泉等明星逐渐淡出 VC 圈，这些由明星主理的创投机构，也逐渐归于沉寂。然而，明星 VC 时代红利已过，但这并不意味着明星群体与投资圈割席。</p><p>关于明星跨界，正如胡海泉过去所说，“跨界绝不是一只脚踏到另外一个领域去占有一席之地那么简单，跨界实际上也是一个很严谨的课题，有些适合你做，有些则未必适合。”</p><p>既然明星合作成立投资机构不好做，那么利用手中闲置资金，隐身幕后做 LP，也不失为涉足投资圈的好方式。</p><p>实际上，近年来便有多位明星不再亲自参与投资，而是通过成为投资机构背后的“金主爸爸”，间接参与到投资中来。这种转变的背后，既有对投资市场的理性认识，也有对自身角色的清晰定位。</p><p>这些超高净值个人的明星 LP，也为创投圈输入一股新鲜活水。</p><p>因早年入股 Star VC 而被外界所知的章子怡，在 2015 年便成了青山基业的 LP，这是一家青山资本创立的基金，擅长消费类投资，投出过花点时间、每日黑巧、本来生活等项目。</p><p>除了是青山资本 LP 外，章子怡还投资了深圳兴旺红筹回归投资中心（有限合伙）、宁波梅山保税港区梅香四溢投资合伙企业（有限合伙）、大脚投资共青城大脚投资合伙企业（有限合伙）等公司。</p><p>其中章子怡持股 4.94%的深圳兴旺红筹回归投资中心（有限合伙），投资了上海聚苗。进入 2020 年，上海聚苗聚焦新能源赛道，押注制造企业，入股纳睿雷达，参与昆宇新能源的融资。其投资的纳睿雷达，已于今年 3 月上市，目前市值为 80 亿元。而其持股 24.4%的宁波梅山保税港区梅香四溢投资合伙企业（有限合伙），背靠执行事务合伙人梅花创投，该公司投资了徕芬科技、理想汽车等知名企业。</p><p>和章子怡同为青山基金 LP 的，还有“国民女神”高圆圆。2021 年，高圆圆成为青山资本旗下基金青山基业的有限合伙人。除了青山资本，高圆圆还是上海映海投资管理中心（有限合伙）的大股东和最终受益人，持股比例为 99.9%，她还通过该公司参与了唐人影视的增资，成为唐人影视的间接股东。</p><p>不只如此，陈坤此前也以 LP 的身份豪掷 5 亿元人民币，投资产业基金。根据美锦能源 2017 年发布的公告，其与北京恩贝投资管理有限公司、陈坤先生共同发起设立 10 亿元产业投资基金。其中，陈坤作为基金的有限合伙人，认缴出资 5 亿元。该基金主要围绕高端装备制造、互联网信息技术、新能源创新技术、大消费等美锦能源的战略方向。</p><p>大手笔砸钱的，还有“顶流”鹿晗。2017 年，鹿晗以 LP 身份加入清晗基金。这只基金由清流资本、新希望集团和鹿晗联合成立，专门针对新生代文化消费内容行业投资。鹿晗是该基金的合伙人之一，参与了出资，但基金的 GP 目前还是以独立的专业投资团队为主。</p><p>进入到私募基金的募资规模有所削减的 2022 年，流量明星白敬亭也悄悄下场做起了 LP。</p><p>天眼查数据显示，2022 年，宇纳资本关联主体“湖南宇纳柒彩股权投资合伙企业（有限合伙）”发生工商变更，新增股东海南明白乐管理合伙企业（有限合伙）等多家企业及自然人。透过海南明白乐的股权图谱，发现了白敬亭的身影。</p><p>收到白敬亭在投资圈开出首张支票的宇纳资本，是一家创立于 2013 年的本土 PE 机构，累计管理规模超 50 亿元，重点投资于新材料、5G 应用、物联网、大数据、云计算、智能制造、新能源等投资领域，这些年相继投出了奇虎 360、华菱线缆、浪潮云、高新杭摩等百余家企业。</p><p>明星在实现了财富自由后，以个人 LP 的身份扩张版图，意外成为当下募资困境中一股难得的活水，这无疑也是 GP 们所喜闻乐见的。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MjI0Nzk5NA==&amp;mid=2650179992&amp;idx=1&amp;sn=091c6d0c997dd272f5051e94a62eafef&amp;chksm=beab104d89dc995b53eb7e77ec9532f39ce8fe4442400a05587ea7762511de6ed575dcee7bdf&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“融中财经”（ID：thecapital）</a>，作者：冯晓亭，编辑：吾人，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547588507787145</id>
            <title>腾讯红杉将收获一个IPO，估值超140亿</title>
            <link>https://www.36kr.com/p/2547588507787145</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547588507787145</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:34:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 晶泰科技, AI药物研发, 港交所上市申请, 投资人
<br>
<br>
总结: 晶泰科技是一家专注于AI药物研发的独角兽公司，已递交港交所上市申请，并吸引了红杉、谷歌、腾讯等顶级投资机构的投资。 </div>
                        <hr>
                    
                    <blockquote><p>其投资人囊括了中外顶级的风投和CVC，包括红杉、谷歌、腾讯及中国人寿等。</p></blockquote><p>继今年6月英矽智能向港交所递交招股书，冲击“国内AI制药第一股”后，又一家AI药物研发领域的明星独角兽——晶泰科技，也开始冲刺上市了。</p><p>11月30日，晶泰科技正式递交港交所上市申请，中信证券为其独家保荐人。</p><p>在定位上，晶泰科技在定位上更符合AI+CRO（合同研发服务）模式，英矽智能在定位上则有明显的生物科技公司特征。</p><p>发展至今，晶泰科技展现出了强大的“吸金”能力，包括红杉、谷歌、腾讯及中国人寿等知名机构投资者，均为公司股东，其中腾讯持股比例达13.66%。</p><p>早在2021年，就有传闻称晶泰科技或赴美上市，但此后始终没有新的进展。</p><p>值得注意的是，晶泰科技本次是以18C规则赴港上市，此番晶泰科技也在招股书中对此做出了说明，并指出18C特专科技公司新规的出台是其选择改道港交所的原因。</p><h2><strong>麻省理工博士，做了个新药研发独角兽</strong></h2><p>2015年，正值全民“双创”的热潮，三位麻省理工学院博士温书豪、马健、赖力鹏看到了创新药研发的风口，联合创立晶泰科技，专注于提供药物发现解决方案以及智能自动化解决方案。</p><p>招股书显示，晶泰科技是一个基于量子物理、以人工智能赋能和机器人驱动的创新型研发平台。</p><p>自成立以来，晶泰科技已经完成从Pre-A轮到D轮8轮融资，展现出超强的吸金能力，其投资人囊括了中外顶级的风投和CVC，包括红杉、谷歌、腾讯及中国人寿等。</p><p>2015年8月，晶泰科技获得由腾讯领投的2400万元的A轮融资，站在腾讯肩膀上的晶泰制药，开始迅速发展。</p><p>2021年7月，晶泰科技完成上市前的最后一轮融资，当时公司交易后估值19.68亿美元（约为141亿元人民币）。与Pre-A轮融资后的估值相比，翻了191倍。</p><p>招股书中晶泰科技也提到，晶泰科技获世界知名私募股权和战略投资者的大力投资与支持，已筹集资金约732百万美元。</p><p>根据弗若斯特沙利文的资料，截至2023年6月30日，就透过股权融资筹集的资金总额而言，晶泰科技在全球的人工智能赋能的药物发现公司中排名第一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2836dde2cc57482a983ff31f519cb581@1629410002_oswg137364oswg912oswg459_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：招股书</p><p>晶泰科技IPO前的股权架构中，温书豪直接和间接持股为16.16%；腾讯通过意像架构持股13.66%，为晶泰科技第一大外部机构股东；红杉资本持股8.25%；五源资本持股7.95%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_acff1527da7448c89f2955af91325741@1629410002_oswg60522oswg908oswg323_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：招股书</p><h2><strong>主营两大业务，年营收过亿</strong></h2><p>从初创公司发展成为赛道龙头，晶泰科技用了仅仅八年。</p><p>早在2015年，晶泰科技就开始建立研究固态药物的研究平台。后来，公司利用量子物理学应用及人工智能，建立一个用于晶体形态预测的晶体结构预测平台，并成立人工智能研发中心。</p><p>在技术不断进步、以及创新战略的推动下，2017年，晶泰科技推出人工智能赋能综合技术平台Atompai及人工智能赋能药物发现平台Renova，并开始与辉瑞合作，提供多晶筛选与选择服务。</p><p>直到2021年，公司在深圳福田建成实验与计算研发中心，在上海浦东建成药物创新研发中心，开发专有的人工智能赋能的下一代抗体发现平台XupremAb。</p><p>截至目前，晶泰科技主要包括药物发现解决方案、智能自动化解决方案两大业务。</p><p>一方面，晶泰科技主要向生物技术与制药公司提供药物发现解决方案，以此换取服务费。此外，晶泰科技还提供药物发现解决方案以换取对手方的股权，并于2020年及2021年自该等非现金交易录得收入。</p><p>另一方面，晶泰科技为客户提供智能自动化解决方案。公司的智能自动化解决方案主要包括固态研发服务及自动化化学合成服务，智能自动化解决方案产生的收入主要以服务费的形式获得。</p><p>招股书资料显示，2020年、2021年及2022年以及截至2023年6月30日止六个月，晶泰科技分别收入0.36亿元、0.63亿元、1.33亿元及0.8亿元，分别净亏损7.34亿元、21.37亿元、14.39亿元、6.20亿元，客户留存率分别约为53.8%、67.5%、51.4%及51.4%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_6c37505919bc464f9a937de717b7016f@1629410002_oswg82570oswg795oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：招股书</p><p>其中，药物发现解决方案收入由2020年的人民币0.13亿元，大幅增加至2023年的人民币0.87亿元；智能自动化解决方案收入保持相对稳定，由2020年的人民币0.23亿元增加至2022年的人民币0.457亿元。</p><p>根据弗若斯特沙利文的资料，截至2023年6月30日，晶泰科技是世界上少数同时拥有基于量子物理的第一性原理计算、先进的人工智能技术及自动化湿实验室能力的药物及材料科学研发公司之一。</p><p>进入2023年，晶泰科技还开发专有的ProteinGPT，这是一种基于人工智能的生物医学生成工具，旨在预测和筛选蛋白质序列，并通过将LLM纳入算法，生成符合特定预设标准的蛋白质药物。</p><h2><strong>展开对外投资</strong></h2><p>在发展过程中，晶泰科技一方面获得了资本的加注，另一方面，晶泰科技在也孵化和投资了多家公司，包括剂泰医药、默达生物、希格生科、莱芒生物等等。</p><p>IT桔子的数据显示，晶泰科技是目前已知投资最活跃的医疗独角兽，从2020年至今投资了 8 家医疗行业公司。</p><p>2020年，人工智能驱动药物制剂开发商剂泰医药完成天使轮数百万美元融资，投资方为峰瑞资本、源码资本、晶泰科技、华兴Alpha。</p><p>据了解，剂泰医药是以人工智能驱动药物制剂开发的初创公司，团队结合了突破性的高通量制剂实验平台及前沿计算物理、人工智能与云计算等技术，致力于快速、精确的智能化药物制剂开发</p><p>2021年，晶泰科技与天图投资领投、力合创投等知名风险投资机构，一同投资了癌症创新靶向药研发公司希格生科。</p><p>2022年，晶泰科技作为领投方之一，参与免疫代谢靶点的小分子创新药研发商默达生物的 Pre-A轮超亿元融资。</p><p>同年，基于免疫代谢重编程+人工智能的新型肿瘤免疫治疗药物研发公司深圳莱芒生物科技有限公司，宣布完成近亿元天使轮融资。本轮投资由天图投资领投，五源资本和晶泰科技跟投。</p><p>此外，晶泰科技还曾与专注RNA药物研发的ReviR溪砾科技达成战略合作，双方共同以靶向RNA的小分子药物为目标，利用人工智能和自动化技术加速药物研发，以期解决尚未被满足的临床需求。</p><p>不难看出，晶泰科技的对外投资基本上都是围绕自身的业务，通过对外投资，晶泰科技也可以分散业务风险，降低经营风险，增加企业的稳定性和可持续性。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/i6zgZ-LjwIKp1u2yQlmtGQ" rel="noopener noreferrer nofollow" target="_blank">“猎云精选”（ID:lieyunjingxuan）</a>，作者：韩文静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547523648446596</id>
            <title>数字科技竞争白热化，我们需要更多大企业</title>
            <link>https://www.36kr.com/p/2547523648446596</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547523648446596</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:34:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 科技竞争, 大企业, 数字科技, 大模型
<br>
<br>
总结: 在新一轮的科技竞争和技术创新中，大企业在带动中小企业和大研究中发挥着引领作用，掌握关键核心技术、走向国际参与竞争，更需要大企业贡献力量。数字科技是硬科技，包括人工智能、大数据、云计算、区块链、虚拟现实等，它们不仅有很高的技术门槛，同时能够赋能千行百业、提升效率。大模型作为数字科技的重要组成部分，在国内外市场都呈现出百舸争流的态势，但大模型的竞赛是持久战，应注重应用落地能力。大模型产业发展呈现出通用大模型和领域大模型互促共进的趋势，通用大模型在泛娱乐场景上表现出色，而领域大模型在专业场景中更具优势。数字科技将成为国际竞争的重要战场，关键技术应当自主可控。数据和算力是大模型发展的制约因素，构建中文开源数据集和提升算力水平是当前的重要任务。 </div>
                        <hr>
                    
                    <blockquote><p>在新一轮的科技竞争和技术创新当中，大企业的作用显而易见，在带动中小企业和大研究中发挥着引领作用，掌握关键核心技术、走向国际参与竞争，更需要大企业贡献力量。</p></blockquote><p>再过不足一月时间，历史的指针将正式指向2024。大模型“井喷”之势下，数字科技在全球新一轮科技浪潮中的趋势与走向，是创新者提前备赛的重要发展指南。</p><p>需要进行前情提要的是，数字科技一定是硬科技，但硬科技不等于硬件科技，人工智能、大数据、云计算、区块链、虚拟现实等数字科技也是硬科技。数字技术不仅有很高的技术门槛，同时能够赋能千行百业、提升效率。突破卡脖子技术需要“软硬结合”，硬件技术和数字技术缺一不可。</p><p>以大模型浪潮为例，涉及到的即有芯片、服务器、通信网络等硬件领域，也包括云计算、数据库、虚拟化等软件层。<strong>短短一年间，大模型已从概念走向业务场景应用，加速通用人工智能演进，过程中国内头部科技厂商起到了引领发展的重要作用。</strong></p><p>爆发源于沉淀。这与大企业多年创新积累不无关系，由此才能以“时刻准备着”的姿态抓住窗口期。在推动技术进步的进程中，大企业有自己独特的优势，鼓励大企业发展、努力培育更多在国际市场中有竞争力的大型科技企业，是国际市场竞争战略。</p><p>而作为经济发展中最活跃的创新要素，企业创新，才能产业创新。</p><h2><strong>Part.1 国产大模型百舸争流，加速拓展应用广度与深度</strong></h2><p>预判2024，大模型是无法回避的话题。过去一年，国内外大模型加速发展。其中，海外市场继GPT-4发布后，OpenAI推出了更强大收费更低的GPT-4 Turbo、人人都可定制的GPTs服务以及GPT商店。除此之外，Google、Anthropic、Cohere、HuggingFace都在不遗余力地推进大模型。</p><p><strong>国内市场同样百花齐放，腾讯、阿里、百度、华为、科大讯飞等厂商结合自身业务和战略布局，发布了各自的大模型技术路线与产品。</strong>有数据显示，截至10月份国内大模型发布已达238个，国产大模型呈百舸争流之景象。</p><p>但无论国内还是国际赛场，大模型的竞赛终归不是闪电战，而是持久战。短期模型发布数量暴涨的背后，大模型的应用方向和商业价值更值得深入探索，<strong>“下半场比拼的是场景和应用的落地能力”已成业内共识。</strong></p><p>目前来看，大模型产业呈现出通用大模型和领域大模型互促共进的发展态势。通用大模型通常从通用语料训练生成，具备强大的自然语言理解、语言生成和语言识别等能力，在聊天、写诗、作画等泛娱乐场景上表现颇佳。而在更为严肃的工作场景、专业场景里，目前阶段通用大模型无法大面积地胜任，例如法律、医疗、金融等。这是因为通用大模型一般基于公开信息进行训练，在许多专业知识和行业数据方面积累不足。</p><p>领域大模型是基于通用大模型灌注行业知识精调形成，能够更好地理解行业的语义和规范，更有效地执行专业性更强的任务。当前很多大厂从基础大模型做起，搭配领域大模型，让人工智能更好地服务于千行百业。</p><p>例如，华为在发布盘古大模型后，在医药、气象、金融等领域布局了领域大模型，“盘古药物分子大模型”使先导药的研发周期从数年缩短至数月，研发成本降低70%，“盘古气象大模型”能够提供秒级的全球气象预报。</p><p>腾讯方面推出了腾讯混元大模型和腾讯云MaaS（模型即服务）。混元作为腾讯云MaaS的基座，客户可以直接通过API调用混元，也可以将混元作为基底模型，为不同产业场景构建定制化的应用。目前混元已接入腾讯逾300个业务和产品并取得初步效果，包括腾讯云、腾讯广告、腾讯游戏、腾讯会议等。</p><p>从商业化落地情况来看，无论是通用类还是领域类，大模型最根本的出发点是解决产业场景中的实际问题，长远的目标是以人工智能为代表的新一代数字技术引领新一轮的技术发展和产业重塑。但如果始终坚持通用类大模型，即便在100个场景中解决70%-80%的问题，却很难完美解决某个问题；如果始终坚持领域大模型，而在底层模型投入不足的话，未来或许将与第一阵营渐行渐远。</p><p>以大模型为代表的人工智能技术应在更加严肃的专业场景和工作场景中真正发挥价值，拓展应用深度；从本文到图像、音视频等更多维度，多模态推动AI应用广度，进而成为新的生产力。<strong>在当前竞争阶段，“两条腿走路”的平衡战略或许是最佳选择，只有将通用大模型的能力提升至世界前沿水准，有了较强的基本能力和素质后，才能在不同行业与场景的落地中实现务实创新。</strong></p><p>放眼全球，技术进步的速度不会放缓，大模型更是展现出了革命性的技术进步，以人工智能为代表的数字科技正在奔涌向前。跟进与超越，是不可逆的技术洪流。</p><h2><strong>Part.2 数字科技将成国际竞争重要战场，关键技术应当自主可控</strong></h2><p>大模型是新型基础设施的关键底座之一，因此大模型的竞争也是国家科技战略的竞争。<strong>在大国博弈的背景下，以人工智能、大数据、云计算、区块链等新一代的数字科技将是未来国与国竞争的重要战场。</strong></p><p>但新的数字科技既是重大机遇，也是艰难挑战。作为底层技术能力，数字技术势必将向上赋能各行各业，同时助力科学技术发展。但除了像芯片这样的硬件领域，在以大模型、人工智能为代表的数字技术方面也存在“卡脖子”问题。如数据和算力，就是当前想要布局全栈自主创新的大模型产品的主要制约因素。</p><p>数据是大模型的基础燃料，决定了模型的训练质量、性能表现和应用领域的广度和深度。但其实国内不缺海量数据，缺的是高质量的中文语料。据国家网信办数据显示，2022年我国数据产量达8.1ZB，位列全球第二；我国数据存储量达724.5EB，全球占比为14.4%。但在ChatGPT大模型训练中，中文占比不到0.1%，这也与中文开源语料库数量少和规模小有关。</p><p>值得关注的是，构建中文开源数据集的步伐正在加快。今年以来，《北京市促进通用人工智能创新发展的若干措施（2023-2025年）（征求意见稿）》中提到，要组织有关机构整合、清洗中文预训练数据，形成安全合规的开放基础训练数据集；持续扩展多模态数据来源，建设高质量的文字、图片、音频、视频等大模型预训练语料库。此外，复旦大学团队开源包含47万高质量监督微调（sft）数据集disc-med-sft，华为诺亚方舟实验室开源第一个亿级中文跨模态数据集。</p><p><strong>而算力是大模型完成训练和推理过程的基石，大模型浪潮驱动智能算力需求激增。</strong>从算力规模方面看，根据信通院统计，2022年我国算力总规模超150EFLOPS，位居世界第二，并保持高增长速度。</p><p>谈算力，芯片禁令是无法回避的话题。但历经多年发展，国产AI高端芯片已取得了长足的进步。面对2个月前的新一轮AI芯片禁令，越来越多从业者选择华为昇腾910等国产芯片进行训练开发。</p><p>IDC数据显示，2023年上半年，中国加速芯片的市场规模超过50万张，本土AI芯片品牌出货超过5万张，占整个市场10%左右的份额。国家正在加快推进芯片、云服务等大模型算力基础设施的自主研发和生产，打破国外的技术和供应链封锁，为国产大模型提供可靠且持续的算力支撑。</p><p>面对数字技术巨大的价值和应用前景，虽距离世界顶尖水平仍有差距，但国内产业相关主体努力布局前沿、攻克关键技术的步履从未停止。<strong>中国数字科技有自己的积累和场景优势，面对大模型为代表的数字技术方面存在的“卡脖子”问题，中国企业正在努力掌握关键核心技术，携手构建自主可控生态，在数字科技领域缩小与世界领先水平的差距。</strong></p><h2><strong>Part.3 大企业领军参与国际竞争，带动产业链条创新提升</strong></h2><p>大企业往往在基础研究、原始创新、技术商业落地、高效迭代等能力范畴上表现突出，是创新型企业中的佼佼者。面对更加残酷的国际市场竞争，以及国内科技实力从量的积累迈向质的飞跃、从点的突破迈向系统能力提升的关键节点，应当重视大企业的发展，发挥大企业的作用。</p><p>在新时代新征程上，如何让大企业在自主创新中“挑大梁”，发挥大企业承担关键技术攻关、提升创新体系综合效能、参与国际科技和产业竞争的优势，是下一阶段需要思考的重要课题。</p><p>当前国产大模型从发布数量上看，与世界先进国家差距不大，但从影响力来看，国产大模型还未形成像ChatGPT、Bert一样的世界性影响力。</p><p>这是由于以微软、Google、Salesforce等为代表的科技巨头大量资源资金投入的长期结果，为所在国大模型产业的发展积蓄了力量。如Google长期投身于研究基础理论，最早在2017年提出Transformer网络结构，成为近些年大模型领域大多数企业底层架构的基础。</p><p>技术创新有其自身的规律，数字科技具有投入大、高风险、回报周期长等特性。当下的科技创新不仅需要实现“从无到有”的突破，更需要平衡成本、效率、效果的“不可能三角”，解决商业化、市场等一系列应用问题。</p><p>企业对于数字科技的投入，应该是在创新中容许适当失败的、长期而又持续的，是既有丰富的市场应用实践，又懂得科技成果转化的。相比之下，大企业在创新投入和创新能力上更有优势，可以形成生态，带动中小企业的创新能力，进而形成创新链条。</p><p>就大模型产业而言，训练成本高，研发难度大，“每家一个大模型”不太现实，一定需要一个“大电厂”，以及几个大电厂形成互联互通的算力中心。由此推测，最终的生态应该是由少数几家头部厂商研发基础大模型，中小企业注重精细的部分，高校侧重基础理论的研究，“建立生态+做细应用+对齐科研”才有望在国际和国际市场竞争中赢得大模型产业博弈的弯道超车机会。</p><p>目前，国内头部企业正在不断完善AI生态构建。<strong>百度推出大模型生态政策；华为鼓励更多伙伴加入盘古大模型全域协同生态体系；腾讯已经与1万1千家生态伙伴展开紧密合作，推出了覆盖100多个产业场景的行业解决方案，腾讯云也发布了“大模型生态计划”。</strong></p><p>对于具有丰富行业数据积累的中小企业，可以通过直接调用API或基于GPT大模型微调优化自己的AI产品。然后基于开源模型或海量数据，打造出更专业、更精准的领域大模型，建立垂直行业的平台生态。</p><p>因此在当前环境中，应当发展大企业，用大企业领军大研究。<strong>大企业有更充足的资金、资源、人才，可持续投入和持续创造，进行多方位甚至是冒险式的研发。</strong>在国际市场和国际科技发展中同样如此，没有大企业就很难拥有话语权。应当鼓励企业做强做大，到国际上参与竞争。</p><p>根据全国工商联数据显示，2022年中国民营企业中研发投入最多的三家公司分别为华为、腾讯、阿里巴巴，三家企业研发投入合计约占全国总研发经费支出的近7%。在全球企业排名中，三家公司的研发投入均排在前二十位。此外，华为在5G领域的专利数量已经连续多年排名第一，掌握的关键核心技术专利最多；腾讯专利申请数量超6.6万件，全球互联网行业中仅次于谷歌，人工智能专利数超过1万件……</p><p>在数字科技等前沿领域的探索中，头部企业往往能够较早布局和规划，例如腾讯早在2018年就开始了大模型训练和推理的研发，并设有实验室专注量子计算、下一代机器人的研究等。</p><p><strong>在新一轮的科技竞争和技术创新当中，大企业的作用显而易见，在带动中小企业和大研究中发挥着引领作用，掌握关键核心技术、走向国际参与竞争，更需要大企业贡献力量。</strong></p><p>期望在未来的世界舞台上，看到在“以大带小”、“产学研”与“用”互为指导下，越来越多的中国企业身影。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/HYDtQzU6qaO4uoLglZrMvg" rel="noopener noreferrer nofollow" target="_blank">“正见TrueView”（ID:zhengjian11188）</a>，作者：岚羽，编辑：TV，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547532424598661</id>
            <title>跨境电商年度战争：从短跑换长跑</title>
            <link>https://www.36kr.com/p/2547532424598661</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547532424598661</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:33:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 黑五购物节, 拼多多, 营收, Temu, SHEIN, TikTok Shop, 速卖通, 价格战, 供应链, 平台化战略
<br>
<br>
总结: 中国电商企业在2023年的黑五购物节中取得了巨大成功，拼多多的市值首次超过阿里巴巴，而且发布的财报显示营收大幅增长。除了拼多多，其他电商企业如SHEIN、TikTok Shop和速卖通也都有各自的发展动态。在这场跨境电商之战中，价格战不再是唯一的策略，各平台开始注重供应链和平台化战略，以建立自身的竞争优势。 </div>
                        <hr>
                    
                    <p>北美的“黑五”购物节的热闹刚结束，中国的电商企业就迎来另一场狂欢——2023年11月29日晚间，拼多多盘中市值首次超越阿里巴巴，一度成为美股市值最大中概股。</p><p>此前一天，拼多多发布Q3财报。财报显示，该季度拼多多实现营收688.4亿元，同比增长94%，远高于市场预期的548.72亿元。</p><p>尽管备受瞩目的Temu未在财报中被直接“点名”，其营收、成本、营销投入等数据也未披露，但业内共识是，Temu是拼多多第三季度财报亮眼的最大功臣。据《晚点 LatePost》，Temu为 2024 年定下的GMV目标为300亿美元，比2023年目标的两倍还多。</p><p>与Temu并称为“电商出海四小龙”的SHEIN、TikTok Shop、速卖通（阿里国际数字商业）同样各自消息不断：</p><p>路透社于28日称，SHEIN已秘密申请在美国上市，可能在2024年启动IPO；</p><p>TikTok Shop虽然在10月迫于印尼政策压力暂停业务，但仍然积极寻求东南亚业务转机，而按印度尼西亚贸易副部长杰里·桑布阿加于28日的表态，只要遵守印尼适用的法规和程序，TikTok就可以自由地与任何电子商务平台合作；</p><p>阿里国际数字商业（AIDC）在蒋凡掌舵后有明显增长，在阿里巴巴集团11月16日发布的2024财年二季度财报中，阿里国际数字商业与菜鸟集团收入同比增长分别为53%、25%，是增长最为强劲的两大集团。</p><p>尽管在“黑五”与“网一”大促期间，“出海四小龙”拿出了看家本领，折扣、补贴、战报接二连三。<strong>但宏观来看，这似乎不再是一场刀光剑影的混战，而是各有各的发力方向。这也预示了各平台在2024年的发展目标，可以看到，其战略层次正在拉开。</strong></p><p>Temu的最大目标仍是增长，而相比Temu在北美的激进价格战，被视为最大竞品的SHEIN则以利润为先，将目标转向深化供应链与品牌效应，今年其更是先后入股Forever21母公司、举办平台招商大会，加速平台化战略；TikTok Shop以社交电商模式突飞猛进，但始终未能摆脱合规魔咒，今年其在努力保住东南亚市场的同时，在北美谨慎试水，明年或将继续主攻美国与东南亚市场；速卖通今年则把主要精力放在服务上，与菜鸟推出“全球5日达”，升级的物流体验让其在欧洲与韩国持续增长。明年，速卖通大概率会坚持此战略，继续深耕欧洲市场。</p><p>跨境电商之战正翻过最激烈争斗的时候。接下来，是“出海四小龙”逐渐摸准定位的时机。如果此前的战役是竭尽全力的100米短跑赛，现在则转换成了全程马拉松，比拼的是耐心。</p><h2>价格战，不再是唯一的策略</h2><p>刚刚过去的“黑五”海外购物节，“电商出海四小龙”们尽情展现着才华：</p><p>Temu在首页挂出了“降价90%”的横幅，并将活动周期拉长至47天；TikTok Shop其次，活动持续35天；SHEIN的大促活动从11月6日起，持续26日左右。在中国跨境电商的“外卷”攻势下，亚马逊首次拉长将黑五大促时间拉长至11天。</p><p>低价突围，仍是Temu的拿手好戏。本次黑五，Temu为用户发放了100美元、200美元大额优惠券。高性价比吸引了大量用户，此前，Temu一度被留学生称为“开局神器”。大促期间，也有商家晒出爆单记录，表示“托黑五的福，今天破了1700单。”</p><p>上线的一年多时间里，Temu始终坚持低价策略，主打的“砍一刀”“拼团”等概念，已经植入进了美国用户的心智。“Shop like a Billionaire”（像亿万富翁一样购物）是Temu年初在超级碗上投放的洗脑广告，意在直白告诉观众：因为价格足够低，刷卡的时候，你可以像富翁一样忽略数字。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_1cc456ab83e34644b5171af5876d9bff@000000_oswg1219105oswg1080oswg610_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Temu投放于超级碗的广告。图源：Temu官网</p><p>被视为Temu竞品的SHEIN，此前被称为“北美版拼多多”，靠低价服装品类取胜，并逐步拓展了全品类商品，但从战略上看，其并未盲目加入价格战。</p><p>据《晚点LatePost》，SHEIN今年要求部分同款商品价格不能高于Temu，一旦价格高了就会更换供应商，或者为商品提供补贴，但“SHEIN的补贴是有限度的，对于Temu平台上绝对低价的同款商品，SHEIN会选择直接下架。”</p><p>SHEIN的保守源于此前的利润下跌。2022年，SHEIN的总收入与GMV都保持增长，但利润为7亿美元，是创办十年以来首次下滑。一方面，SHEIN需要在今年保住账面好看；另一方面，SHEIN又面临着Temu、TikTok Shop的围剿，颇有“内忧外患”之感，此次赴美IPO或许也能在一定程度上探索新的出路。</p><p>对比已经发展到成熟阶段的SHEIN，美区“新手”TikTok Shop的尝试较为小心。尽管TikTok Shop在大促期间对用户与商家进行了双端补贴，似有打价格战的趋势。但长远来看，TikTok Shop或许并不想完全靠低价取胜。与10月印尼站下线有关，TikTok Shop当下最在意的仍是合规风险。</p><p><strong>“低价”曾是中国跨境电商平台最鲜明的特征之一。现在，尽管这个标签未被全部摘下，但可以看到，除了Temu在价格战略上较为激进外，SHEIN、TikTok Shop都未死盯价格，而是在利用自身优势，建造平台特有的护城河。</strong>此外，各平台的打法，也预示它们的市场定位已经出现差异。</p><p>Temu之所以坚持低价战略，是因为其首要瞄准的就是下沉市场。下沉市场的受众数量广泛，很适合打“群众基础”。有了用户基数后，Temu才可以更好地将“高性价比”概念植入消费者心中。并且，Temu的全品类定位意味着它迟早会与“老大哥”亚马逊正面“刚”，但亚马逊定位更加高端，Temu先用价格拉开差距，圈住特定人群，未来才能更好地面对挑战。</p><p>SHEIN不再跟Temu硬拼价格，是因为供应链优势足够明显。</p><p>SHEIN发展十年，制胜关键就是“小单快返”。比起传统的大批量生产囤货模式，“小单快返”更为灵活。SHEIN会要求工厂先小批量生产商品，在经过市场验证后，对销量高的商品加量订购，表现不佳的商品则迅速“砍掉”。据SHEIN员工消息，SHEIN仍会持续深耕广东的供应链网络建设。</p><p>依托供应链优势，SHEIN开始探索平台化战略。在与SPARC Group旗下品牌Forever 21达成长期战略合作后，SHEIN又收购了英国快时尚品牌Missguided。这些举动意味着SHEIN正逐渐渗透线下品牌，在全球化的同时也加速平台化运营模式。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d68a550394f745959904c36ae26c4d36@000000_oswg530391oswg1080oswg429_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Forever21已正式上线SHEIN官网。图源：SHEIN官网</p><p>长远来看，TikTok Shop也不会将重点放在“价格战”上。TikTok Shop直到今年9月才在美国全量开放，此前一直对商家的入驻审核极为严格。其更想在合规的前提下，探索兴趣电商与货架电商融合的可能性。“货找人”的兴趣电商模式适合做白牌商品，“人找货”的货架电商模式则利于建构商城的整体生态，对想做品牌化的商家有好处。</p><p>老牌出海玩家速卖通也过了用低价厮杀的阶段。9月底，速卖通与菜鸟推出“全球5日达”服务，并率先在英国、西班牙、荷兰、比利时、韩国上线。阿里国际表示，本次“黑五”，沙特、阿联酋的消费者预计在10个工作日内收到订单。背靠菜鸟，速卖通的物流优势已经“外卷”到了极致。</p><p><strong>大促期间的短期争夺或许会放出“价格战”的烟雾弹，但透过硝烟可以看到，低价背后，如何留存用户、克服物流与供应链障碍、搭建品牌影响力更为重要。</strong>“出海四小龙”各有所长，定位逐渐明朗。</p><h2>全托管：“毒药”还是“解药”?</h2><p>当下跨境电商赛道大火的全托管模式，并不是新鲜事物。</p><p>亚马逊早期便诞生了VC（Vendor Central）账号类型，针对这类供应商，亚马逊会直接采购产品，并负责销售、后端物流等工作，这套流程与全托管十分相似。但很显然，亚马逊没有重点发展VC，用户认知也随之淡化。</p><p>“电商出海四小龙”又重新将全托管模式带回行业视野：</p><p>Temu从2022年9月1日与美国上线起，就一直贯彻全托管模式，卖家仅负责供货与运送到仓，定价、销售、物流、售后等环节均由平台负责；</p><p>一直专心做自营的SHEIN也在今年年初开放了第三方卖家入驻，推行全托管模式；</p><p>TikTok Shop于今年5月开放沙特与英国跨境电商全托管模式的招商，8月在美国上线全托管模式；</p><p>速卖通从去年年底开始内部测试全托管模式，于今年4月全品类推广“Choice”频道。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_66ee8a915ac34dcc9f85b649ba445bbd@000000_oswg159636oswg1080oswg262_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">速卖通“Choice”频道。图源：速卖通官网</p><p>全托管已然是跨境电商赛道的大趋势，但各平台的打法和考量有所不同。</p><p>对Temu而言，全托管模式能将交易流程集中化，平台会对运营、物流、售后等过程更有掌控性，适合在初期快速走量，占领下沉市场。且由于商品会经手平台，空包、虚假交易的违规行为也会减少，规范化的操作更利于用户留存。</p><p>SHEIN需要通过全托管模式接入更多优质商家，拓宽品类。霞光社联系到一位同时经营SHEIN和Temu的全托管卖家，对方表示，“SHEIN的门槛更高一些，需要营业执照等证件。而且比起Temu，SHEIN更注重产品图片上传时的知识产权问题，控价也没有Temu严重。”这也表明了SHEIN要一手抓增长，一手抓品牌的决心。</p><p>全托管模式带给平台的“控制权”，也有利于在进入海外市场时集中规避合规风险，减少商户的学习成本。有业内人士告诉霞光社，“欧美对TikTok不是很友好，全托管模式也有政策考量。如果让商家运营、发货等，可能会出现搞不清楚规则的情况。前期由平台掌握是最好的。”</p><p>此外，TikTok Shop似乎也发现兴趣电商的发展还需要时间，“兴趣+货架”电商模式，会更利于GMV增长。市场竞争仍然激烈，全托管模式对于刚开始布局的货架电商来说，更像“不得不”的选择。</p><p>速卖通对全托管的尝试比较谨慎，尽管速卖通今年力推“Choice”频道，但紧接着，其又上线了“半托管模式”——平台仍然会负责仓配、售后，但商家有更多自主经营权。这可能有两方面原因：</p><p>一方面，蒋凡在接过阿里国际数字商业后，想要做出成绩，全托管模式的优点是能吸引更多小微供应商入驻，平台可以用低价的小件商品提升单量；</p><p>另一方面，速卖通似乎看到了全托管模式下存在的隐患：当商家转向单一的“供货商”角色，完全不涉及运营环节后，可能会离真实的市场越来越远，对产品的敏锐度、对消费者的感知也随之下降。均衡自营、全托管、半托管三种模式，才能让平台生态发展得更好。</p><p>回到亚马逊为何没有大力发展VC模式的话题，就会发现速卖通的考量不无道理。《每日经济新闻》曾评价，“全托管基本省去了平台教育卖家的大部分成本，而这恰好是亚马逊曾花了大力气建设的。”亚马逊中国副总裁彭嘉屺的工作重点之一，就是“产品及卖家教育”。<strong>在平台的帮助下，卖家可以学习如何选品、定价，培养品牌思维，在面对电商赛道的激烈竞争时保持品牌韧性。而全托管模式只留下了“供货”环节，长远来看，商户的抗风险能力并不强，自主权及品牌能力的发展也较为有限</strong>。</p><p>此外，当全托管模式成为全行业追求的热点后，这条赛道也会不可避免地愈加拥挤，商家内卷可能加剧，利润空间会被进一步压缩。业内人士向霞光社表示，平台压榨的还是卖家，全托管一定是趋势，好处也很明显，数据就是最佳证明，但“肯定不会一直这样，可能会慢慢开放自营”。</p><h2>跨境电商下一站，中东?</h2><p>根据霞光社发布的《2023年北美电商市场研究报告》，北美仍是全球最大的电商市场之一。Statista数据显示，2022年北美电商市场已达到9440亿美元市场规模，预计2027年将达到1.7万亿美元规模，年复合增长率高达14.3%。</p><p>Temu与SHEIN在北美的战役一度胶着。Temu上线三个多月后，SHEIN就“坐不住”了，指控Temu在社交媒体中模仿SHEIN的风格，最终诱导用户下载Temu应用、访问Temu官网。Temu也在今年7月起诉SHEIN违反美国反垄断法，认为SHEIN强迫供应商签署排他性的“忠诚协议”。</p><p>据悉，双方已经在今年10月撤回对彼此的诉讼，但斗争并未停止。今年刚加入SHEIN全托管的卖家告诉霞光社，“SHEIN开放第三方入驻也是为了和Temu竞争，想多做点品类，我已经开了四家店。”</p><p>可以预见，<strong>2024年，Temu和SHEIN还将在美国“打架”</strong>。</p><p>TikTok Shop在北美的野心也很明显。今年一直有消息传出TikTok Shop在美国挖人，“包括原SHEIN供应链等员工均在被挖行列。”也有业内人士指出，TikTok Shop在美国的终极对手不是新兴平台，而是亚马逊。或许这是中国跨境电商玩家在美国的共同目标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_046bb21dd44f44ffbe48709067297077@000000_oswg154814oswg1080oswg497_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">TikTok Shop招商网站，主推东南亚与美国地区 ，图源：TikTok Shop官网</p><p>东南亚电商赛道已经打成红海，不过，仍有增长空间。据谷歌、淡马锡、贝恩公司联合发布的《2023东南亚互联网经济报告》，东南亚电商市场GMV在2023年达到1390亿美元，预计将在2025年达到1860亿美元，增长16%。</p><p>TikTok Shop在东南亚的布局称不上早，但的确依靠直播带货、短视频带货“杀”出了一条路。业内人士表示，TikTok Shop的东南亚竞争压力也在明显变大，“以前稍微运营一下就有很多单，现在必须很用心才能达到以前的效果。用户多了后，平台补贴也少了很多。”这也从侧面表明了TikTok Shop在东南亚地区的发展态势。</p><p>值得一提的是，据多方消息，TikTok Shop印尼站有望回归。印度尼西亚贸易副部长杰里·桑布阿加与11月28日表示，此前，TikTok是违反了仅作为社交媒体平台运营的规则，“一旦它拿到许可证，只要符合法规和程序，就可以和任何人合作。”也有消息称，TikTok近来正在与印尼电商平台Tokopedia、Bukalapak和Blibli等商谈合作可能性。</p><p>SHEIN在东南亚市场的尝试不算大胆，2021年7月，SHEIN宣布关闭印尼业务，但未说明原因。除了政策考量外，也有利润衡量，比起Shopee、TikTok Shop，SHEIN的低价策略在东南亚市场并没有太大优势。</p><p>今年7月，SHEIN在巴西的工厂正式投产，这也是SHEIN首个设在拉丁美洲的工厂。疫情扰动了拉美的电商市场，迎来增长拐点，SHEIN在此刻重仓拉美，大有押宝未来的态势。</p><p>速卖通今年在欧洲动作频频，明年也会大概率深耕欧洲市场。菜鸟国际快递数据显示，今年黑五前，速卖通菜鸟跨境优选仓的备货量同比去年涨了近9倍，其中大部分商品将被运往“全球5日达”服务覆盖的国家。西班牙是速卖通的发展重点，11月10日，速卖通在西班牙马德里WiZink中心举行了音乐会，为双十一拉开序幕。去年12月，阿里国际数字商业在西班牙上线电商平台Miravia，还定下了“2026年成为西班牙前五大电商平台”的目标。</p><p>当下出海赛道大热的中东市场，也已经吸引Temu、TikTok Shop前去布局。SHEIN在中东地区的布局较早，2015年就已进入。凭借供应链优势，用“时尚电商”的定位在中东占领了一席之地。</p><p>中东地区人口近5亿，海湾六国人均GDP超过两万美元，人口结构优质，年轻人居多，且互联网普及比例达80%。中东的热门电商市场主要集中在阿联酋、沙特阿拉伯、以色列及土耳其等国，目前仍是增量市场。</p><p>Temu于今年8月底上线以色列站点，延续了低价促销战略，并与第三方物流合作。据《界面新闻》，Temu在以色列的合作物流包括HFD和Exelot，时效为6-15天。为了提升物流效率及用户体验，Temu打出了“15天后到货，消费者可以在获得20新锡克尔积分（约人民币38.5元）的补偿。”</p><p>TikTok Shop试运营沙特站点后，首先推出的是货架电商，主打“人找货”策略。事实上，比起单枪匹马的Temu，TikTok Shop更具备用户基础和内容优势。中东消费者热衷使用社交产品，当地网红生态繁荣，利好直播带货与内容电商。但会做营销的商家不一定能做好品牌和供应链，TikTok Shop更希望拓展全品类，吸纳更多商家入局，打通货架电商的闭环。这点或许也有基于未来要与Temu竞争的考量。</p><p>速卖通于今年7月于菜鸟升级沙特“无忧集运”服务，主打“5日达”与“满包邮”，并将服务拓展到了阿联酋、阿曼、卡塔尔、巴林等重点国家。据悉，这次物流升级可以将四国的物流时效提升一半，从30天提速至12-14天。</p><p>整体来看，Temu和TikTok Shop在中东的竞争可能会更加激烈；SHEIN在中东的“时尚电商”地位仍在，正在通过线下快闪店等形式深化品牌效应；速卖通则继续拓展物流的“长板效应”，这也是平台在面对全球市场的主要战略之一。</p><p>当下，<strong>中国跨境电商平台已经把最初始的路径跑通了，各家都在探索新的出路、新的增量。</strong>“出海四小龙”的发展逐渐成熟，激烈的竞争逐渐分化，定位和打法差异也越来越明显，形成了“各分天下”的局势，留给中小平台的机会不多了。</p><p>但这注定是一场长跑比赛。回到29日晚，有阿里巴巴员工在内网员工发帖评价拼多多市值飞升：“那个看不起眼的砍一刀，快成老大哥了。”</p><p>久违露面的马云现身评论区，表达了对拼多多的祝贺，并称“谁都牛x过，但能为了明天后天牛而改革的人，并且愿意付出任何代价和牺牲的组织才值得尊重。”</p><p>霞光社将持续关注跨境电商大市场。</p><h3><strong>参考资料</strong></h3><p>[1]《晚点独家｜出海电商激战：Temu GMV 目标翻倍，SHEIN 保利润，TikTok 全力攻美国》，晚点LatePost</p><p>[2]《美国“双十一”，卷的是中国人》，财经十一人</p><p>[3]《SHEIN“发现”美洲》，品牌工厂BrandFactory</p><p>[4]《Temu 狂奔一年：47 个国家、2 亿用户、美国月度 GMV 逼近 SHEIN》，晚点LatePost</p><p>[5]《帮Shein增长百万用户后，全托管只是看上去很美｜硬氪分析》，硬氪</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg3MDU1MDY1NQ==&amp;mid=2247558419&amp;idx=1&amp;sn=87393fd3471d02dafb47fa9dd09c03f2&amp;chksm=ce8fb803f9f8311536ae0ab581122ac8e1745caf53186d4a50cb877b3a0d659459d76ea60f98&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“霞光社”（ID：Globalinsights）</a>，作者：冯叶，编辑：刘景丰，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547569755512712</id>
            <title>全球社交媒体监管：美国法官喊停蒙大拿州对TikTok禁令，意味着什么？</title>
            <link>https://www.36kr.com/p/2547569755512712</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547569755512712</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:32:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 蒙大拿州禁令, TikTok, 美国法院裁决, 言论自由
<br>
<br>
总结: 2023年11月30日，美国地方法院法官以言论自由威胁为由，暂时阻止了蒙大拿州对TikTok的禁令。该禁令被认为违反了用户的言论自由权利，并且超越了州政府的权力范围。美国立法者对禁令的呼声主要是出于对中国的担忧，然而禁止TikTok是否能真正解决这个问题还有待商榷。 </div>
                        <hr>
                    
                    <p>2023年11月30日，美国地方法院法官唐纳德•莫洛伊（Donald Molloy）以“言论自由威胁”为由，暂时阻止了蒙大拿州针对TikTok做出的禁令—— SB 419，按照这一规定，苹果和谷歌必须将 TikTok 从其应用商店中下架，否则每天将被罚款1万美元。该禁令本来预计在2024年1月1日生效，但美国法院的裁决表明，剥夺一个超过 1 亿美国人用来浏览和分享音乐、舞蹈、喜剧、时尚、政治表达和社会事业的平台，存在很高的法律和宪法障碍。</p><p>美国是迄今为止 TikTok 受众最多的国家，有超过 1.5 亿用户使用这个社交视频平台。美国政府和许多州已禁止在政府拥有的设备上使用 TikTok，但只有美国蒙大拿州试图完全禁止该应用程序。同时，美国国会的对华鹰派正在呼吁全美国范围内禁止 TikTok，并敦促拜登政府强制分拆或出售这家中国科技公司。</p><p>然而，美国联邦法官的这一裁决，让美国立法者有机会重新考虑这一立场和具体措施本身是否值得怀疑。</p><h2><strong>一、蒙大拿州的禁令为何被阻止？</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_40dc7e1a2553451baf331e7c529c7229@5655031_oswg147610oswg693oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片：蒙大拿州SB419法案</p><p>蒙大拿州是美国人口最少的州之一，略多于 100 万，州长 Greg Gianforte（共和党）于 2023年5 月签署的法律SB419，声称将禁止在全州范围内使用TikTok，并试图将其宣传为保守派领导的州如何超越联邦立法者、保护美国人民免受企业越权和消费者伤害的一次壮举。TikTok 和五名蒙大拿州的 TikTok 平台创作者随即将蒙大拿州告上法庭，两起诉讼后来合并，辩称该禁令在没有证据的情况下涉嫌不当行为，并侵犯了用户的第一修正案权利。</p><p>莫洛伊法官的 48 页裁决书称，TikTok 提供了更好的论据，“证明了其取得成功的可能性”，并表示，蒙大拿州禁令“在多方面违反了宪法”，“甚至不可能通过中度审查（intermediate scrutiny，介于合理审查和严格审查的违宪审查之间标准）”。</p><h3><strong>1、违反第一修正案——言论自由</strong></h3><p>美国拥有强有力的文化规范和法律来促进言论自由。一般来说，对受宪法保护的言论的限制必须是“狭义的”，并促进合法的公共利益。</p><p>莫洛伊法官从两个方面进一步明确“言论自由”在本案中的适用性：</p><p><strong>全面的权利：</strong>用户完全拥有通过他们喜欢的言论方式进行交流的权利，所以认为美国用户仍然可以在其他平台上发言的辩解不成立；</p><p><strong>影响有限的限制手段：</strong>任何对言论的监管都应该使用更有限、定义更明确的“宪法手术刀”，但蒙大拿州禁令给言论带来的负担远远超过了实现其所谓利益所需的负担；</p><h3><strong>2、外交事务超越州政府权力范围</strong></h3><p>SB419 明确禁止 TikTok，因为州政府认为它与特定外国政府有直接联系，但是<strong>外交政策事务属于美国联邦政府，蒙大拿州在外交事务领域没有宪法权力</strong>。</p><h3><strong>3、虚构的“消费者利益”</strong></h3><p>莫洛伊法官认为，尽管该州试图将 SB 419 作为消费者保护法案进行辩护，但目前的记录毫无疑问地表明，蒙大拿州立法机构和总检察长更感兴趣的是，针对中国在 TikTok 中的表面角色，而<strong>不是保护蒙大拿州消费者</strong>。正相反，<strong>该州的禁令实际将给州际贸易带来负担，而且切断了许多人赖以生存的收入来源</strong>。</p><h3><strong>4、个人隐私问题应由数据立法解决</strong></h3><p>在10月举行的法庭听证会上，莫洛伊法官指出 TikTok 用户自愿提供他们的数据，而不是被“窃取”，而且州政府并没有提供何不当数据传输或间谍活动的证据。</p><p>他还建议，<strong>美国联邦政府可以采取更严格的措施来实现“数据隐私、保护国民”的目标</strong>，例如制定数据共享规则，对任何被发现未经个人同意获取个人数据的公司进行惩罚，而不是通过这样的禁令“给中国一个教训”。</p><h2><strong>二、美国担忧“中国问题”，能通过禁止TikTok实现吗？</strong></h2><p>美国立法者对禁令的呼声从来都不是针对 TikTok，而是针对中国。然而，针对TikTok的禁令能否真正解决他们担心的“中国问题”，值得怀疑。</p><h3><strong>1、TikTok 的隐私和安全问题与其他社交平台有何不同？</strong></h3><p>数据与社会研究所（Data &amp; Society Research Institute）高级研究员Robyn Caplan表示：“隐私界的普遍共识是，TikTok 的确收集了大量数据，但与其他应用程序收集的数据量并没有不一致。”</p><h3><strong>2、美国禁止 TikTok 的行动和呼声</strong></h3><p>2023年2月2日，参议员Michael Bennet呼吁苹果和谷歌从其应用商店中下架TikTok，这相当于软禁令。</p><p>2023年2月10 日，参议员Angus King和Marco Rubio重新提出了《反中国社交媒体法案》（Anti-Social CCP Act），该法案将迫使 TikTok 要么被彻底禁止，要么被出售；</p><p>2023年3月1日，众议院外交事务委员会按照党派路线投票推进《威慑美国技术对手法案》（Deterring America’s Technological Adversaries Act），该法案旨在让白宫能够在全美范围内禁止 TikTok；</p><p>2023年3月7日，参议员Mark Warner和John Thune提出了《限制法案》（RESTRICT Act），赋予商务部长更大的权力，对同样受到 TikTok 推动的中国科技公司采取行动。（此前特朗普政府禁止 TikTok 的类似努力遭到了两个联邦机构的阻止）</p><p>然而，拜登政府对 TikTok 的国家安全审查仍因是否强制出售该平台存在分歧而陷入僵局；在国会，出于国家安全考虑而彻底禁止TikTok的努力也陷入停滞——《限制法案》因赋予拜登政府过多权力而遭到共和党的反对。</p><h3><strong>3、美国对TikTok两个普遍担忧</strong></h3><p>美国国际战略研究中心(CSIS)认为，美国禁止 TikTok 的提案属于“聚焦错误”，势必会产生广泛的错误后果。</p><p><strong>保护美国个人隐私：</strong>由于 TikTok 的母公司字节跳动总部位于中国，美国立法者担心中国政府可能会获取美国的个人信息。然而，当许多其他美国移动应用程序收集非常相似类型的个人信息（设备标识符、地理位置、面部或声纹等），并且将其转移到国外时几乎没有法律限制时，单独禁止 TikTok没有什么实际意义。因为任何人和机构都可以很轻易地从数据经纪人等中介机构购买美国人的个人数据，几乎不需要审查。</p><blockquote><p><strong>Tips：美国数据经纪人出售价值数十亿美元的军人数据</strong></p><p>2023年11月，杜克大学桑福德公共政策学院发布了一份报告：《数据经纪人和美国军事人员数据的销售——隐私、安全和国家安全的风险》。该报告证明，任何机构从美国数据经纪人处获取有关现役军人、其家人和退伍军人的敏感数据并不困难，包括非公开、个人识别的敏感数据，例如健康数据、财务数据和宗教活动信息。数据经纪人并未受到美国政府的监管。而且这些情况包含了数据经纪人向美国境外客户销售现役军人和退伍军人的敏感、非公开、单独识别的数据的场景。</p><p>报告链接：https://techpolicy.sanford.duke.edu/data-brokers-and-the-sale-of-data-on-us-military-personnel/</p></blockquote><p><strong>算法及虚假信息：</strong>一些美国政客担心中国政府可能控制TikTok的内容推荐算法，向美国用户进行宣传或虚假信息。但事实上，许多美国平台使用自动推荐系统，根据个人推断的兴趣或活动来放大内容。因为1996 年《通信规范法案》第 230 条和“避风港原则”保护数字平台免受大多数针对第三方内容的诉讼，所以他们目前几乎没有动力去构建安全的内容推荐算法。<strong>外国政府实际上并不需要控制算法来针对特定社区进行宣传，他们只需要“理解”并利用这些平台即可。</strong></p><p>也就是说，美国试图通过禁止TikTok来解决与中国的政治问题，不切实际。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_257c4032085c4229ab56f0ebc015896c@5655031_oswg30574oswg1080oswg531_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>三、TikTok的美国之路将如何？</strong></h2><h3><strong>1、蒙大拿州对TikTok的禁令无法实现</strong></h3><p>蒙大拿州总检察长办公室表示，他们仍在审查自己的选择，其中可能包括向美国第九巡回上诉法院提出上诉。</p><p>虽然，法院只是从技术上暂时阻止了蒙大拿州禁令的生效，但莫洛伊法官的裁决清楚地表明了他严格适用法律的立场。里士满大学（University of Richmond）法学院教授Carl Tobias预计，<strong>法官将发布永久禁令，除非蒙大拿州能够透露更有说服力的证据</strong>。美国企业研究所（American Enterprise Institute）技术政策研究非常驻高级研究员Clay Calvert表示，<strong>蒙大拿州上诉“成功的可能性微乎其微”</strong>。</p><p>此外，蒙大拿州法律的执行需要苹果和谷歌公司配合，但这两家公司都表示，出于隐私问题，他们不会跟踪用户下载应用程序时所处的状态，比如用户何时跨越了蒙大拿州的界限。蒙大拿州禁令本身在技术上就是无法实现的。</p><h3><strong>2、美国法院可能采取类似的立场</strong></h3><p>莫洛伊法官本人也承认，<strong>其裁决是在“全国法院努力应对政府对大型社交媒体公司的监管”之际发布的</strong>。就在其发布裁决的前一天，印第安纳州的一名法官驳回了该州的一项诉讼，该诉讼指控TikTok在数据安全、儿童安全措施方面误导用户，并涉嫌违反州消费者保护法，要求法院对 TikTok 处以罚款并实施限制。两位法官可能都在试图避免卷入政治斗争。</p><p>高盛表示，<strong>莫洛伊法官的裁决不会被视为判案先例，但其论点对于审查类似案件的其他法官来说将具有说服力</strong>。</p><h3><strong>3、立法者态度尚不明朗</strong></h3><p>拜登政府在中国问题上面临的双重难题：如何将美国与中国科技公司分开？如何化解国防官员和经济官员在封禁TikTok上的立场冲突？</p><p>正是出于上述难题，意在禁止TikTok的《限制法案》尽管得到了两党高级成员的支持，但在推进过程中仍陷入了困境。</p><p>2023年10月商务部长吉娜·雷蒙多宣布支持商务委员会主席Maria Cantwell起草的一项新法案——《警卫法案》（the Guard Act），希望立法机构能够赋予商务部更广泛的权力来禁止 TikTok等外国应用程序，同时避免《限制法案》带来的言论自由问题。</p><p>《限制法案》将赋予美国总统过多的权力来禁止应用程序，《警卫法案》的目标是对行政权力进行限制。但由于无法确定下一任总统是谁，这两个法案是否能够继续推进，还有待观察。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkyOTMxMDg1Mg==&amp;mid=2247509598&amp;idx=1&amp;sn=4bedf74bd871dbd44057458372a2dd1b&amp;chksm=c20997b5f57e1ea3c80f9bef5c80a921561b65aa907bb435404aa9aadb1b76a7377bc8fdd0d4&amp;token=285508831&amp;lang=zh_CN#rd" rel="noopener noreferrer nofollow" target="_blank">“Internet Law Review”（ID:Internet-law-review）</a>，作者：互联网法律评论，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547379574166664</id>
            <title>颠覆Transformer霸权，CMU普林斯顿推Mamba新架构，解决致命bug推理速度暴增5倍</title>
            <link>https://www.36kr.com/p/2547379574166664</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547379574166664</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:18:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Transformer, Mamba, 注意力层, 扩展
<br>
<br>
总结: Mamba是一种新的架构，解决了Transformer核心注意力层无法扩展的问题，推理速度提升了5倍。它可以线性扩展，并在语言建模上与Transformer不相上下。这一新架构可能会颠覆Transformer在自然语言领域的霸主地位。 </div>
                        <hr>
                    
                    <blockquote><p>诞生6周年的Transformer，霸主之位终于要被颠覆了？CMU、普林斯顿研究者发布的Mamba，解决了Transformer核心注意力层无法扩展的致命bug，推理速度直接飙升了5倍！一个时代要结束了？</p></blockquote><p>深度学习进入新纪元，Transformer的霸主地位，要被掀翻了？</p><p>2017年6月12日横空出世，让NLP直接变天，制霸自然语言领域多年的Transformer，终于要被新的架构打破垄断了。</p><p>Transformer虽强大，却有一个致命的bug：核心注意力层无法扩展到长期上下文。</p><p>刚刚，CMU和普林斯顿的研究者发布了Mamba。这种SSM架构在语言建模上与Transformers不相上下，而且还能线性扩展，同时具有5倍的推理吞吐量！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_eac0ea0fe3764c2689fc166cc9392754@000000_oswg36597oswg1080oswg242_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://arxiv.org/abs/2312.00752</p><p>论文一作Albert Gu表示，二次注意力对于信息密集型模型是必不可少的，但现在，再也不需要了！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_ecdabd22ed2b49c6ad20cc85570cc130@000000_oswg153861oswg1077oswg484_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文一出，直接炸翻了AI社区。</p><p>英伟达首席科学家Jim Fan表示，自己一直期待能有人来推翻Transformer，并且对Albert Gu和Tri Dao多年以来做出替代Transformer序列架构的尝试表示感谢。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_ddd9275238414b9baa4add2f0ab837ae@000000_oswg94511oswg1080oswg183_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「你们做的研究太酷了，一会儿蹦出一个来，不能稍微停一下吗！」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_7458fa93bf284a8e9b8e30ac6656b329@000000_oswg57976oswg1080oswg170_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「湖人粉表示，对Mamba这个名字很满意！」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_de463575e3924ebab715b8ab8c0378bd@000000_oswg59315oswg1080oswg170_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于这个架构为何取名曼巴，作者也给出了解释——</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_7bf33b8a4b444325a0b61816f44c8ed7@000000_oswg185835oswg1080oswg521_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>- 速度快：原因在于（1）序列长度线性缩放的简单递归，（2）硬件感知设计和实现</p><p>- 致命性：它对序列建模问题具有致命的吸引力</p><p>- 就连发出的「声音」都很像：其核心机制是结构化状态空间序列模型（S4）的最新演进……SSSS</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_50becf1097d4439aba3e161d9e5e20a2@000000_oswg1931032oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>性能碾压Transformer？</strong></h2><p>Mamba源自Albert Gu之前「结构化状态空间模型」的相关工作，可以看作是强大的循环运算符。这就得以实现序列长度的线性缩放和快速自回归解码。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a2e049644f19410f8265cb6e4fb919a4@000000_oswg89738oswg1080oswg293_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://arxiv.org/abs/2111.00396</p><p>然而，以前的递归模型的缺点是，它们的固定大小状态难以压缩上下文。</p><p>而Mamba的主要贡献，就是引入了「选择性SSM」，这是S4的简单泛化，可以选择性地关注或忽略输入。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_5661e84437bc4c0cb99b6516f043bef7@000000_oswg155670oswg1080oswg324_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这一小小的改变——只需让某些参数成为输入的函数——就能让它立即解决对以往模型来说艰巨无比的任务。</p><p>例如，它可以无限长地推断出重要的「联想回忆」任务的解决方案！(训练长度256，测试长度1M）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_aab955f39b124dd89d00dce7f1acb6c0@000000_oswg169208oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>关键就在于：这一变化涉及到非同小可的效率权衡，S4的原始设计有着特定的原因。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b9e5d86e6fd74c7284c37c9b2194bf87@000000_oswg118159oswg1080oswg700_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在DNA和音频等其他模态的真实数据上，Mamba的预训练性能超过了之前的专业基线（如HyenaDNA和SaShiMi）。</p><p>值得注意的是，无论在合成、DNA还是音频数据中，随着序列长度达到1M+，Mamba的性能也在不断提高！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2d8a3e8d77ef4f9eb3f07af17edbd38d@000000_oswg153125oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_22f7e89771e14cd6b855483afe249c86@000000_oswg128841oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_7f8395ee680a4b04a1abd0aba43e95e0@000000_oswg134403oswg1080oswg498_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而另一位一作Tri Dao介绍了如何利用硬件感知设计应对这一挑战，以及Mamba在语言方面的强大性能。</p><p>他表示，正如Albert所说，状态空间模型（SSM）的特征，就是其固定大小的递归状态。如果想实现更好的性能，就要求这种状态更大，并且更具表现力。</p><p>不幸的是，因为较大的状态太慢，会导致无法在实践中使用递归进行计算。</p><p>过去，曾有基于S4的SSM通过做出结构假设（也即线性时间不变性）来解决这个问题，这样就可以在不实现大状态的情况下，进行等效的「卷积模式」计算。</p><p>但这次CMU和普林斯顿研究者的方法是选择性SSM，只能循环计算。</p><p>为了解决这个计算瓶颈，他们利用了其他高效的硬件感知算法（如FlashAttention）使用的技术。</p><p>需要注意的是，对于Mamba（和一般的SSM），这种方法只能在SRAM中实现扩展状态，而不是在主存储器中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d7c3c22d0af64589807a58de61447983@000000_oswg122381oswg1080oswg402_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，scan实现比基本的PyTorch/JAX快30倍，当序列长度变长时，比二次FlashAttention还要快几个数量级。</p><p>而且，由于采用了固定大小的循环状态（没有KV缓存），Mamba的LM推理速度比Transformer快5倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a362e6e9823d480a8091b3a2e9f60e27@000000_oswg209210oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_66a1a836ef7c413a916741545be25b2e@000000_oswg110806oswg1080oswg502_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从经验上看，两位作者取得的最重要的成果是在语言建模上，这也是以前的SSM所瞄准的领域（比如H3，也即Mamba的前身）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_bda81e0f9c4544d6861db767f0cbc874@000000_oswg202306oswg1080oswg505_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://arxiv.org/abs/2212.14052</p><p>然而这时，自己的工作仍然不及Transformer。并且他表示，当时没有哪个模型能真正与精调后的Transformer相抗衡。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b37c80a1590548f9a7ee9a82e455c756@000000_oswg123760oswg1080oswg266_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而，惊喜忽然来了！</p><p>根据Chinchilla缩放定律进行预训练时，Mamba的表现忽然就优于一个非常强大的现代「Transformer++」模型（接近Llama模型）！</p><p>而在300B token上训练完成后，Mamba的性能，已经大大优于同类的开源模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_dd22913ac0794c81b7894dd5ba760572@000000_oswg245839oswg1080oswg502_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_dca578ffdd884de7b6351be5a2f7a05b@000000_oswg147063oswg857oswg556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后，作者总结道：硬件感知思维可以开启新的架构设计。</p><p>展望未来，这种新架构能否利用围绕Transformers构建的硬件/库？它将如何改变其他领域（基因组学、音频、视频）的序列扩展？</p><p>为此，作者还发布了一系列模型的权重（参数量最高可达2.8B，在300B token上训练），以及快速推理代码。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_6a175c59691942fd9230319ae35deea1@000000_oswg111725oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">项目地址：https://github.com/state-spaces/mamba</p><h2><strong>击败Transformer的架构，是怎样诞生的</strong></h2><p>现在的基础模型，几乎都是基于Transformer架构和其中最核心的注意力模块来构建的。</p><p>为了解决Transformer在处理长序列时的计算低效问题，学界开发了很多二次方时间复杂度的架构，比如线性注意力、门控卷积和循环模型，以及结构化状态空间模型（SSM）。</p><p>然而，这些架构在处理语言时，表现并不如传统的注意力模型。</p><p>研究人员发现，这些模型的主要弱点在于它们难以进行基于内容的推理，并因此作出了几项改进：</p><p>首先，通过让SSM参数成为输入数据的函数，可以解决这类模型在处理离散数据类型时的不足。</p><p>这就使得模型能够根据当前的token在序列长度的维度上选择性地传播或遗忘信息。</p><p>其次，尽管这样的调整使得模型无法使用高效的卷积，但研究人员设计了一种适应硬件的并行算法，并在循环模式下实现它。</p><p>研究人员将这种选择性的SSM集成进了一个简化的端到端神经网络架构中，这种架构不需要注意力机制，甚至也不需要MLP（多层感知器）模块，这就是研究人员提出的Mamba。</p><p>Mamba在快速推理方面表现出色（比Transformers高5倍的处理速度），并且随着序列长度的增加，其性能线性增长，在处理长达百万长度的序列时表现更佳。</p><p>作为一个通用的序列处理模型，Mamba在语言、音频和基因组学等多个领域都获得了最先进的性能表现。</p><p>在语言建模方面，Mamba-3B模型在预训练和后续评估中性能达了两倍参数量的Transformers模型性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_026651c1e8734694a013ed93d751e5c5@000000_oswg212295oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>通过实证研究，研究人员验证了Mamba在作为基础模型（FM）的核心框架方面的巨大潜力。</p><p>这种潜力不仅体现在预训练的质量上，还表现在特定领域任务的性能上，涵盖了多种模态和环境：</p><p><strong>- 合成任务</strong></p><p>在重要的合成任务中，如复制和归纳等，Mamba不仅能轻松解决，还能推断出无限长（&gt;100万个token）的解决方案。</p><p><strong>- 音频和基因组学</strong></p><p>在音频波形和DNA序列建模方面，Mamba的表现优于SaShiMi、Hyena和Transformers等先前的SOTA模型，无论是在预训练质量还是下游指标方面（例如，在具有挑战性的语音生成数据集上，FID降低了一半以上）。</p><p>在这两种情况下，它的性能随着上下文长度的增加而提高，最高可达百万长度的序列。</p><p><strong>- 语言建模</strong></p><p>Mamba是首个线性时间序列模型，无论是在预训练复杂度还是在下游任务评估中，都能实现Transformer级别的性能。</p><p>将模型规模扩大到10亿参数后，研究人员证明Mamba的性能超过了Llama等大量基线模型。</p><p>Mamba语言模型与同体量的Transformer相比，具有5倍的生成吞吐量，而且Mamba-3B的质量与两倍于其规模的Transformer相当（与Pythia-3B相比，常识推理的平均值高出4分，甚至超过了Pythia-7B）。</p><h2><strong>选择性状态空间模型</strong></h2><p>研究人员利用合成任务的直觉来激发他们的选择机制，然后解释如何将该机制合并到状态空间模型中。由此产生的时变SSM无法使用卷积，这对如何有效地计算它们提出了技术挑战。</p><p>研究人员通过利用现代硬件上的内存层次结构的硬件感知算法克服了这个问题。然后，研究人员描述了一个简单的SSM架构，没有注意力机制，甚至没有MLP模块。最后，研究人员讨论选择机制的一些附加属性。</p><h3><strong>动机：选择作为压缩手段</strong></h3><p>研究人员认为序列建模的一个基本问题是将上下文压缩成更小的状态。他们从这个角度来看待流行序列模型的权衡（tradeoffs）。</p><p>例如，注意力在某些方面非常有效，但是在另一些方面又很低效，因为它完全不压缩上下文。从这一点可以看出，自回归推理需要显式存储整个上下文（即KV缓存），这直接导致Transformers的线性时间推理和二次时间训练缓慢。</p><p>另一方面，循环模型是高效的，因为他状态是有限的，这意味着推理时间是恒定的，并且训练的时间也将会是线性的。</p><p>然而，注意力的有效性受到这种状态压缩上下文的程度的限制。</p><p>为了理解这一原理，研究人员重点关注两个合成任务的运行示例（如下图2）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f2dabd3ea6fd4e6eac5e7ce0d1173963@000000_oswg77280oswg861oswg322_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>选择性复制（Selective Copying）任务通过改变要记忆的标记的位置来修改流行的复制任务。它需要内容感知推理才能记住相关标记（彩色）并过滤掉不相关标记（白色）。</p><p>归纳头（Induction Heads）任务是一种众所周知的机制，以前的研究假设它可以解释LLM的大多数情境学习能力。它需要上下文感知推理来知道何时在适当的上下文（黑色）中产生正确的输出。</p><p>这些任务揭示了LTI模型的失效模式。从循环的角度来看，它们的恒定动态（例如（2）中的（A，B）转换）不能让它们从上下文中选择正确的信息，或者影响沿输入相关的序列传递的隐藏状态方式。</p><p>从卷积的角度来看，众所周知，全局卷积可以解决普通复制任务，因为它只需要时间感知，但由于缺乏内容意识，它们在选择性复制任务上有困难（如上图）。</p><p>更具体地说，输入到输出之间的间距是变化的，并且不能通过静态卷积核进行建模。</p><p>总之，序列模型的效率与有效性权衡的特征在于它们压缩状态的程度：高效模型的状态必须要小，而模型效果好必须要求这个小状态要包含上下文中所有必要信息的状态。</p><p>而相反，研究人员构建的序列模型的基本原则是选择性：或者是关注或过滤输入到序列状态的上下文感知能力。</p><p>特别是，选择机制控制信息如何沿着序列维度传播或交互。</p><p>通过选择改进SSM将选择机制纳入模型的一种方法是：让影响序列交互的参数（例如 RNN 的循环动态或 CNN 的卷积核）依赖于输入。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_6e3e2e029dec44b78a033470942f0a0f@000000_oswg66688oswg861oswg283_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>算法1和2说明了研究者使用的主要选择机制。</p><p>主要区别在于简单地使输入的几个参数Δ、B、C成为函数，以及整个张量形状的相关更改。</p><p>需要注意，这些参数现在具有长度维度 ，这意味着模型已从时不变（time-invariant）改为时变（time-varying）。</p><p>这就失去了与卷积的等价性，并影响了其效率。</p><h3><strong>简化的SSM架构</strong></h3><p>与结构化SSM一样，选择性SSM是独立的序列转换，可以「灵活地合并到神经网络中」。</p><p>H3架构是最著名的SSM架构的基础，该架构通常由受线性注意力启发的块与 MLP（多层感知器）块交织组成。研究人员通过将这两个组同质堆叠件合并为一个组件来简化这一架构（如下图）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_4af7baf72c684a4ebeac77762a2d7be3@000000_oswg81549oswg865oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>之所以这么处理是受到门控注意力单元（GAU）的启发。该架构涉及通过可控扩展因子来扩展模型维度。对于每个块，大多数参数（3ED^2）位于线性投影中，而内部SSM贡献较少。SSM参数的数量相比起来要小的多。</p><p>研究人员重复了这个块，与标准标准化和残差连接交织，形成Mamba架构。</p><p>在实验中，始终将x设为E=2，并使用块的两个堆栈来匹配Transformer交错MHA（多头注意力）和MLP块的122个参数。</p><p>研究人员使用SiLU / Swish激活函数，其动机是使门控 MLP 成为流行的「SwiGLU」变体 。最后，研究人员还使用了一个可选的归一化层，动机是RetNet在类似位置使用归一层。</p><p>选择机制是一个更广泛的概念，可以以不同的方式应用，例如更传统的RNN或CNN、不同的参数（例如算法2中的 A），或使用不同的变换。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_0868e6654430414d8a0f75dde7641daf@000000_oswg52889oswg1080oswg124_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>实证评估</strong></h2><h3><strong>合成任务：选择性复制</strong></h3><p>复制任务是用来测试序列模型，特别是循环模型记忆能力的经典合成任务。</p><p>LTI SSM（线性递归和全局卷积）可以通过只关注时间而不是推理数据轻松地解决这个任务。例如，构建一个长度完全正确的卷积核（图2）。</p><p>对此，选择性复制任务则可以通过随机改变token的间距，来阻止这种走捷径的方法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b46f506af3db4a6a8254e1eba0ffc84a@000000_oswg181500oswg1080oswg413_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表1显示，H3和Mamba等门控架构只能部分提升性能，而选择机制（即将S4改进为S6）则可以轻松解决这一问题，尤其是与更强大的架构相结合时。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_7f4c7496f554449984e2a1ea461ed787@000000_oswg29608oswg540oswg550_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>合成任务：归纳头</strong></h3><p>归纳头是一个从机械可解释性的角度出发相对简单的任务，却意外地能够预测大语言模型（LLMs）的上下文学习能力。</p><p>这项任务要求模型进行关联性回忆和复制动作：比如，模型之前在一个序列中遇到过「Harry Potter」这样的词组，那么当「Harry」再次出现在同一个序列时，模型应能够通过回顾历史信息并预测出「Potter」。</p><p>表2显示，Mamba模型，或者更准确地说是它的选择性SSM层，由于能够选择性地记住相关的token，同时忽略中间其他的token，因此能够完美地完成任务。</p><p>并且，它还能完美地泛化到百万长度的序列，也就是训练期间遇到的长度的4000倍。相比之下，其他方法的泛化能力都无法超过2倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_9967f4e8e8834dca941b9d4998887bab@000000_oswg135382oswg890oswg530_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>语言建模</strong></h3><p>研究人员将Mamba与标准的Transformer架构（即GPT-3架构），以及目前最先进的Transformer（Transformer++）进行了对比。</p><p>后者基于PaLM和LLaMa架构，其特点包括旋转嵌入（rotary embedding）、SwiGLU MLP、使用RMSNorm替换LayerNorm、取消线性偏置，并采用更高的学习率。</p><p>图4显示，在从≈1.25亿到≈13亿的参数规模中，Mamba是首个在性能上媲美最强Transformer架构（Transformer++）的无注意力模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_05f337c266e4469a9015d09548d6b395@000000_oswg198358oswg1080oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表3展示了Mamba在一系列下游zero-shot评估任务中的表现。</p><p>其中，Mamba在训练时使用了与Pythia和RWKV相同的tokenizer、数据集和训练长度（300B token）。</p><p>需要注意的是，Mamba和Pythia训练时的上下文长度为2048，而RWKV为1024。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d7cc8b898b9a44b38ba3703342149eec@000000_oswg164322oswg1080oswg798_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>DNA建模</strong></h3><p>随着大语言模型的成功，人们开始探索将基础模型的范式应用于基因组学。</p><p>DNA由具有特定词汇表的离散符号序列组成，还需要长程依赖关系来建模，因此被比作语言。</p><p>研究者将Mamba作为预训练和微调的FM骨干进行了研究，研究背景与最近DNA长序列模型的研究相同。</p><p>在预训练方面，研究者基本上按照标准的因果语言建模（下一个token预测）设置。</p><p>在数据集方面，基本沿用了鬣狗DNA的设置，它使用了HG38数据集进行预训练，该数据集由单个人类基因组组成，在训练分割中包含约45亿个token（DNA碱基对）。</p><p>结果如图5（左）显示，Mamba的预训练困惑度随着模型规模的增大而平稳提高，并且Mamba的扩展能力优于 HvenaDNA和Transformer++。</p><p>例如，在最大模型规模≈40M参数时，曲线显示，Mamba可以用少3到4倍的参数，与Transformer++和HvenaDNA模型相媲美。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_363b15cd9d744728a7c6a6754e7648f5@000000_oswg190844oswg1080oswg365_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，图5（右）显示，Mamba能够利用更长的上下文，甚至长达1M的极长序列，并且其预训练困惑度会随着上下文的增加而提高。</p><p>另一方面，鬣狗DNA模型会随着序列长度的增加而变差。</p><p>从卷积的角度看，一个非常长的卷积核正在聚合一个长序列上的所有信息。</p><p>图6是类人猿DNA的分类，显示了使用相同上下文长度的预训练模型对长度2^10到2^20的序列进行微调后的准确度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_79fe8f4cd6094ef9b0298290531f4318@000000_oswg131603oswg800oswg570_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>音频建模与生成</strong></h3><p>在音频波形处理领域，主要对比的是SaShiMi架构。该模型包括：</p><p>1. 一个U-Net主干，通过两个阶段的池化操作，其中每个阶段都将模型的维度D增加一倍，池化因子为p，</p><p>2. 每个阶段都交替使用S4和MLP模块。</p><p>针对长上下文的自回归式预训练，研究人员采用了标准钢琴音乐数据集——YouTubeMix进行评估。数据集包含了4小时的独奏钢琴音乐，采样率为16000Hz。</p><p>图7展示了在保持计算量不变的情况下，训练序列长度从8192（2^13）增加到≈1000000（2^20）时的效果。</p><p>无论是Mamba还是SaShiMi（S4+MLP）基线模型，表现都随着上下文长度的增加而稳步提升。其中，Mamba在整个过程中都更胜一筹，而且序列越长优势越明显。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_57debbac65a34b5e85dacb759a19f405@000000_oswg117301oswg800oswg570_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在自回归语音生成方面，则使用基准语音生成数据集SC09进行评估。它由时长1秒的语音片段组成，采样频率为16000 Hz，包含数字「0」到「9」，特征多变。</p><p>表4展示了Mamba-UNet与一系列基准模型的自动评估结果，其中包括WaveNet、SampleRNN、WaveGAN、DiffWave以及SaShiMi。</p><p>可以看到，小规模的Mamba模型在性能上就已经超越了那些更大、采用了最先进的基于GAN和扩散技术的模型。而同等参数规模的Mamba模型，在保真度方面的表现更是大幅领先。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f2115f9cc6da4bc2b29a11ec1abfc948@000000_oswg52510oswg790oswg550_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表5采用的是小规模Mamba模型，并探究了在外部和中心阶段不同架构的组合效果。</p><p>研究发现，无论在外部块还是中心块，Mamba模型的表现都优于S4+MLP架构，而在中心块的性能排名为Mamba &gt; S4+MLP &gt; MHA+MLP。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_1c4c8fca05444bc8b14061f56d9c1f64@000000_oswg58209oswg780oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>速度和显存基准测试</strong></h3><p>图8展示了scan操作（状态扩展N = 16）速度，以及Mamba端到端推理吞吐量的基准测试。</p><p>结果显示，当序列长度超过2k时，高效的SSM scan比目前最优秀的注意力机制——FlashAttention-2还要快。而且，比起PyTorch标准的scan实现，速度提升更是高达20到40倍。</p><p>由于没有键值（KV）缓存，因此Mamba可以支持更大的批处理大小，从而使推理吞吐量比同等规模Transformer高了4到5倍。</p><p>举个例子，一个未经训练的69亿参数的Mamba（Mamba-6.9B），在推理处理能力上可以超过仅有13亿参数、规模小5倍的Transformer模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_5fbb13d8d3ed4139942ac358a69c9f97@000000_oswg139295oswg1080oswg308_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与大多数深度序列模型一样，显存使用量与激活张量的大小成正比。表15显示，Mamba的显存需求与经过优化的Transformer相当。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_1856ed896e29494d80720e930e2bd58f@000000_oswg29663oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">125M模型在单张A100 80GB GPU上训练时显存的需求</p><p>在论文最后，作者表示，选择性状态空间模型在为不同领域构建基础模的广泛应用性，太令人兴奋了。</p><p>种种实验结果表明，Mamba很有可能成为通用序列模型的主流框架，甚至有潜力跟Transformer一搏。</p><h3>参考资料</h3><p>https://arxiv.org/abs/2312.00752</p><p>https://twitter.com/tri_dao/status/1731728602230890895</p><p>https://twitter.com/_albertgu/status/1731727672286294400</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652414828&amp;idx=1&amp;sn=401e5e7adcf037a2c1b4167e8b616d5b&amp;chksm=f12bd79dc65c5e8b423a5cddeff01b920f0f9ca9346b61b7815b4320b5f950e058ca50245ca0&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547379792385157</id>
            <title>量子计算OpenAI来了？前谷歌3人团队融资1亿元，打造AI算力芯片挑战物理极限</title>
            <link>https://www.36kr.com/p/2547379792385157</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547379792385157</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:12:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 前谷歌量子计算团队, AI算力芯片, 热力学和信息的第一原理, 自组装智能
<br>
<br>
总结: 前谷歌量子计算团队宣布融资1410万美元，打造新型AI算力芯片，利用热力学和信息的第一原理构建人工智能超级计算机，实现能够自我编程的算力芯片。他们的目标是构建一种来自未来的自组装智能，利用物理学的非平衡热力学来实现高效的计算能力。 </div>
                        <hr>
                    
                    <blockquote><p>前谷歌量子计算团队今日宣布融资1410万美元，打造新型AI算力芯片，将根据热力学和信息的第一原理构建人工智能超级计算机，实现能够自我编程的算力芯片。</p></blockquote><p>在生成式AI的时代，算力已经肉眼可见的成为了技术发展的天花板。</p><p>英伟达几乎是现在这个时代算力问题的唯一解。</p><p>三十年前，在那个Denny's餐厅里开会的英伟达创始团队，肯定想象不到，他们看好的计算方式，将某种程度决定30年后人类智能的上限。</p><p>而我们这个时代的「Denny's里的英伟达」在哪里呢？</p><p>一个由来自前谷歌量子计算研究团队的科学家团队宣布，他们成立于2022年的Extropic获得了1410万美元的天使融资，将根据「热力学和信息的第一原理构建人工智能超级计算机。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_30d1be456081448fa862976c56ad3d6a@000000_oswg245416oswg735oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在他们的公司主页上，一个自称来自未来的「自组装智能」给现在的人类发来了一条讯息：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_02f9e988c3bd41c6b59a668b2e11acd4@000000_oswg435767oswg1080oswg1153_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>无所不在的生成式人工智能时代即将到来。时间表已经开始加速。未来一定会实现。Extropic正在为物理世界中的生成式人工智能构建终极基础。像外星人一样，利用热力学和信息的第一原理构建人工智能超级计算机。随着这一筹款公告的发布，Extropic 跨越了时间轴上的一个重要关卡。利用技术资本机器为我们的文明轨迹创造核心技术的里程碑。Extropic AI 超级计算机因此开始从未来组装起来。</p></blockquote><p>在他们的X主页介绍上，只有一排莫尔斯码：</p><p>翻译成英语是：SELF-ASSEMBLING INTELLIGENCE FROM THE FUTURE（来自未来的自组装智能）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d67f3be3cff1478e8e1a23775f83a5cb@000000_oswg45443oswg926oswg336_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而他们最新发布的X推文也是这种画风：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_fc6897a80d97497bb45f9da2b9d8d287@000000_oswg54421oswg926oswg644_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>注意...这是来自未来的紧急广播。连接不稳定...请务必...调整至此频率...于2023年12月4日，上午6点...我们必须确保...我们时间线的到来...未来必须成为现实...我们全依靠你了，匿名者。</p></blockquote><p>随着生成式人工智能的浪潮席卷世界，我们更加渴望更便宜、更快、更高效、可扩展的计算能力。</p><p>——鉴于目前的算力瓶颈，我们能否从根本上重新构想什么是「计算机」？</p><p>我们可以想象一台计算机，它不是抑制世界的自然熵，而是与它共生，将其作为一种资产。</p><p>我们可以想象一台高效的计算机，它有能力把生成式人工智能扩展到整个世界，并避免大规模的能源消耗。</p><p>我们可以想象一台受大自然启发的计算机，它从生命如何在热力学和自组织的驱动下找到出路中汲取灵感。</p><p>而Extropic，正在制造这样一台计算机。</p><h2><strong>来自未来的Extropic</strong></h2><p>Extropic是一家由谷歌量子计算研究团队前成员领导的硬件初创公司，创立于2022年，现已获得了1410万美元的种子轮投资。</p><p>本次投资由Kindred Ventures领投，还吸引了包括HOF Capital、Julian Capital和Marque VC等十几家其他投资者的参与，另外还包括Adobe、Shopify和几位AI公司的高管。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_6d1b6567b82449cdb93ff2a0cb04435a@000000_oswg192205oswg939oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Extropic的首席执行官Guillaume Verdon和首席技术官Trevor McCourt均来自于谷歌。</p><p>在谷歌工作期间，Verdon和McCourt领导了TensorFlow Quantum的开发，该库可用于在量子计算芯片上运行AI模型。</p><p>Extropic正在构建一种优化的芯片，以运行大型语言模型。</p><p>Verdon将Extropic的技术描述为「基于物理的计算的新型全栈范式」，利用了非平衡热力学（物理学的一个新兴分支，专注于研究化学反应等现象）。</p><p>尽管创始团队来自于谷歌的量子计算团队，但Extropic的产品并非量子计算芯片，公司的研发团队正在开辟一条不同的道路，以实现基于物理学的实用计算。</p><p>——「一条不依赖于量子力学的道路，一条噪音是资产而不是负担的道路，一条不需要设备物理学奇迹就能达到工业规模的道路。」</p><p>量子计算芯片至今未能成功商业化的原因之一就是噪声，基于量子计算的处理器极易出现计算错误或噪声，使之无法可靠地进行复杂的计算。</p><p>而Extropic正在寻求建立一个可以避免噪声影响、甚至利用噪声的系统。</p><p>Extropic的目标之一是减少运行AI模型所需的电量。Verdon表示，芯片将能够自动执行某些编码任务，</p><p>「人们可以想象，一台计算机不是强制性地编程，而是自然而然地找到一种方法来对自身进行编程，以学习世界的表征。」</p><p>Extropic在自己的博客中表示，为了使日常生活中的各种设备更精确、更可靠、更准确、噪音更小，团队进行了大量的研究。</p><p>Extropic正在构建一种计算范式，利用非平衡热力学的力量，从根本上将生成式人工智能与世界物理学融合在一起。</p><p>最终实现将生成式人工智能嵌入到世界的物理过程中，实现物理定律所定义的空间、时间和能量方面的效率极限。</p><h2><strong>面向未来的团队</strong></h2><p>作为物理学前沿与人工智能相结合的探险，Extropic的创始团队集结了众多大佬。</p><p>团队的科学家和工程师们主要为物理学和人工智能领域，而几位关键成员来自量子计算科学领域。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_687af58679f54342ab5dd0aec70531fb@000000_oswg1520820oswg1080oswg796_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Extropic的首席执行官为Guillaume Verdon。</p><p>在创立Extropic之前，Guillaume是Alphabet X物理与人工智能团队的量子技术负责人。他开创了大量的量子技术，在感知、通信和表征学习方面有着广泛的应用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f25dcf69988d423fb9f951cbcf6fb28f@000000_oswg365846oswg1080oswg1286_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Guillaume是量子深度学习领域的先驱，在滑铁卢大学（University of Waterloo）攻读博士学位期间，他创立了后来成为谷歌的TensorFlow Quantum项目，最终加入了谷歌量子人工智能团队。</p><p>他拥有理论物理和信息论的广泛背景，并获得了Perimeter Institute和Institute for Quantum Computing的硕士学位。</p><p>Extropic的首席技术官是Trevor McCourt，他最初是一名机械工程师。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_3a8e0d6aa1bc483a8174569a2b25b0c6@000000_oswg111499oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在Waterloo学习期间，他加入了TensorFlow Quantum项目的创始团队，并结识了Guillaume。</p><p>从此，他们两人密切合作，开创了从0到1的可微分量子编程软件。</p><p>随后，Trevor回到硬件工程方向，在Google Quantum AI开发尖端设备和控制技术。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_8671c43ef06a43efbc527181ef34d24e@000000_oswg239683oswg879oswg1389_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Trevor目前致力于研究自组织物理系统，并在麻省理工学院攻读博士学位，研究噪声在计算和生命系统中的作用。</p><p>Christopher Chamberland是Extropic的首席建筑师，被认为是最杰出的量子计算机架构师之一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_41568f3af082441793089d10a0d4a07a@000000_oswg285873oswg512oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此前，Christopher领导建立了AWS和IBM Quantum的核心量子架构，目前负责Extropic的架构工作。</p><p>在加入AWS和IBM之前，Christopher曾在Microsoft Quantum工作，并获得了滑铁卢大学量子计算研究所的博士学位。</p><p>Extropic团队的其他成员也主要来自于AWS、Meta、IBM、Nvidia、Xanadu等许多世界顶级科技公司或学术机构。</p><p>这个高度跨学科的团队，在基于物理学的人工智能方面，拥有丰富的经验和独特的优势，开创了追求物理和人工智能相统一的方法。</p><h2><strong>量子计算新突破</strong></h2><p>这几位量子计算领域的大佬离开了量子计算，着手开发「不依赖量子力学」的AI芯片。</p><p>但巧的是，就在Extropic宣布巨额融资的同时，老东家谷歌的量子计算团队也发表了自己的研究成果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_8772fdb4d81a4667a550f42a29db600e@000000_oswg39964oswg789oswg182_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">研究博客：https://blog.research.google/2023/12/a-new-quantum-algorithm-for-classical.html#:~:text=In%20%E2%80%9CExponential%20quantum%20speedup%20in,reasoning%20purely%20about%20classical%20systems.</p><p>「我们报告了一种新的量子算法的发现，该算法为模拟耦合经典谐波振荡器提供了指数优势。这些是自然界中最基本、最普遍的系统，可以描述无数自然系统的物理学，从电路到分子振动再到桥梁力学。」</p><p>下面是一个通过弹簧连接到墙壁的质点，代表简单的谐波振荡器。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_8fd051f63b5e49778bc535351ecb2365@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在考虑耦合谐波振荡器，其中多个质点通过弹簧相互连接。移位一个质点，就会在整个系统中产生振荡波。</p><p>在经典计算机上模拟大量质点的振荡，将变得越来越困难。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_89aaa3e26f82422ba84e677589171c5a@000000_oswg140909oswg663oswg397_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了能够模拟大量耦合谐波振荡器，研究人员提出了一种映射，将所有质点和弹簧的位置、速度编码到量子比特系统的量子波函数中。</p><p>研究人员证明了某一类耦合经典振荡器系统可以在量子计算机上有效地模拟。并且，这些算法在资源使用方面同样有效。</p><p>另外，就在今天，IBM推出了第一台具有1000多个量子比特的量子芯片。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_d9b7aae44d1e4b448e8a2a6e19b700c6@000000_oswg23212oswg685oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过IBM也表示，他们将改变研究方向，专注于提高机器的容错能力，而不仅仅是提升量子比特数。</p><p>多年来，IBM一直遵循量子计算的路线图，每年将量子比特的数量增加一倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2a9237fb28c64e9a9b3437ce2a61e2d6@000000_oswg241220oswg1080oswg628_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>本次推出的芯片名为Condor，有1121个超导量子比特，呈蜂窝状排列。</p><p>它延续了之前的一系列命名，包括 2021 年的 127 量子比特芯片和去年的 433 量子比特芯片。</p><p>IBM今天公布的量子研究的新路线图显示，到本世纪末，它将达到有用的计算能力，例如模拟催化剂分子的工作原理。</p><p>量子计算机利用量子纠缠和叠加的性质来执行经典计算机无法执行的某些计算。</p><p>量子态是善变的，如同我们人类的发展一样，未来的方向令人着迷，更多的瓶颈和极限等待我们去突破。</p><h3>参考资料</h3><p>https://www.extropic.ai/accelerate</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652414828&amp;idx=2&amp;sn=e890e33f801ab9c68a2939fcad5aa2a2&amp;chksm=f12bd79dc65c5e8b4b5f16b73f5fbacdea895a51c0cc7dc4037ba12175907a1c42a701fd47c7&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，作者：润 alan，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547357779088514</id>
            <title>iOS、Android、PC 值得关注的6个App</title>
            <link>https://www.36kr.com/p/2547357779088514</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547357779088514</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:00:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 目录, Sleeve 2, Newji, Gauguin, Craft 2.6, 小星记账 3.0, Audio Hijack 4.3, 值得关注的 App
<br>
<br>
总结: 本文介绍了一些值得关注的应用程序，包括Sleeve 2，它是一款自定义桌面音乐小组件，可以方便地掌握当前播放音乐的相关信息；Newji是一款可以根据用户的表情描述生成符合描述的Memoji的应用程序；Gauguin是一款可以帮助用户进行创作的应用程序；Craft 2.6是一款更新，提供了个性化域名和智能链接等功能；小星记账 3.0是一款记账应用程序的更新；Audio Hijack 4.3是一款可以将语音转换为文字的应用程序。 </div>
                        <hr>
                    
                    <h2><strong>本期目录</strong></h2><p>💻 Sleeve 2：自定义桌面音乐小组件</p><p>📱 Newji：创建专属于自己的 Memoji</p><p>🤖 Gauguin：闲来无事，不妨动脑</p><p>💻 Craft 2.6 更新：个性化域名让分享更自由，智能链接让网页内容呈现更精彩</p><p>🤖 小星记账 3.0 更新：沉寂许久的再次回归</p><p>💻 Audio Hijack 4.3：用可视化的方式实现语音转文字</p><h2><strong>📱值得关注的 App</strong></h2><p>虽然少数派一直在为大家发现和介绍各平台上的优质 App，但仍有不少设计、功能、交互、体验都非常优秀的 App，还没有被我们发掘和介绍。它们可能是一款老 App，也可能是近期上架的新 App，我们会在这里介绍给你。</p><h3><strong>Sleeve 2：自定义桌面音乐小组件</strong></h3><p>平台：macOS</p><p>关键词：音乐、小组件</p><p>@Snow：Sleeve 是一款 macOS 平台桌面音乐小组件，不同于系统原生「播放中」需从菜单栏点击查看，Sleeve 的小组件可以常驻桌面及 Dock 栏，不仅方便你快速掌握当前播放音乐的相关信息，还可以利用交互按钮和快捷键操控。</p><p>之前派评也曾推荐过一款音乐小组件Neptune ，它内置了 5 款设计精美的主题，如果你觉得这些并不满足于你的需求，Sleeve 则可以为你提供极大的创作空间。仅初始主题，Sleeve 就提供了 7 个模板，你还可以从组件布局、封面设计、界面交互、文字信息、空间位置、窗口层级、快捷键以及系统设置总共 8 个维度自定义。你可以先选择一个相对喜欢的初始主题，然后点击中栏顶部的「+」复制既有设定，接着在它的基础上进行修改。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_903f9b1cfc264938a2fd6d21bc94223a@000000_oswg343073oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以组件布局为例，应用提供了 4 种布局模式，封面文字横排、竖排、文字覆盖封面以及纯文字展现，横排封面及文字位置还支持左右对调，文字本身支持居左、居中、居右对齐，文字与封面也可调整 3 种对齐方式。此外，你还可以调整文本框宽度，来控制文字显示长度以及与封面的距离，这一数值还会影响在 Interface 中开启背景后的组件大小。</p><p>而在文字信息中，你不仅可以单独设置歌曲名、专辑名、艺术家的字体、样式、大小等数值，还可以根据系统深浅色主题分别调整字色和阴影效果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_8dff19b7c0e24693b5cc9135aad69560@000000_oswg41551oswg1080oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然 Sleeve 仅支持英语，但设置页右侧提供了实时预览，桌面组件也会根据你的设置实时调整，你可以逐个调试了解每一个调节项的实际效果。不过你在更改 Layout 中的布局时，封面和文字有几率恢复默认效果，因此还是建议按设置中由上至下的次序进行调整。完成所有自定义项后，你就可以将新的主题收藏进主题库内，随时调取使用。你还可以导出自定义主题，供他人使用。</p><p>近期更新了 2.0 的新版 Sleeve 同样支持 Apple Music、Spotify 及 Doppler 三款音乐应用，但在服务上增加了 last.fm 支持，你可以登录账号同步音乐喜好标记。此外，新版还提供了 Spotify 喜好标记功能，不过这需要你自行申请一个 Spotify Developer 账号。</p><p>应用售价 58 元，你可以直接在 App Store 购买，也可选择在官网支付 5.99 美元购买。</p><h3><strong>Newji：创建专属于自己的 Memoji</strong></h3><p>平台：iOS / iPadOS</p><p>关键词：Emoji</p><p>@ROB1N：Apple 生态圈的用户，对于 iMessage 一定是非常喜爱的。iMessage 简洁的页面、高度集成化的功能，都给 Apple 生态圈用户提供了高效的沟通渠道。同时随着过往 iOS 的更新，Memoji 作为社交层面上一个重要的组成部分也被呈现给了用户。高度可自定义的造型设计，甚至也被运用到了 Apple Store 员工的工牌以及用户们的头像、聊天贴纸上。</p><p>不过虽然是「高度可自定义」，但是预设的动作以及主题还是只有那些。随着 iOS17 发布，Newji 也应运而生。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_483d5265ab0b4bbd80c1f2e9e101065b@000000_oswg388652oswg1080oswg2337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Newji 的使用逻辑非常简单，通过识别用户一段简单的表情描述，从而生成符合描述的 Memoji 。生成的 Memoji 可以保存，也可以分享给其他用户。同时我们在 iMessage 上也可以通过贴纸栏看到 Newji 生成的 Memoji 。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_252701e82efe443bae14b4d6f85b6a8e@000000_oswg976567oswg1080oswg2337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>嵌入在 iMessage 中的时候，我们在贴纸部分也可以通过它来即时创建一个新的 Memoji ，不用回到 app 去进行繁琐的操作，可以直接生成并使用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_f4d20393b985417d8fe8580eba8c70f8@000000_oswg831785oswg1080oswg2337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前用户的免费额度是十个 Memoji ，额外的部分需要付费使用。一共分为 5 档，购买的制作数量越多，单价越便宜。最低 ￥15 制作 20 个，最高 ￥198 制作 999 个。</p><p>你可以在 App Store 下载使用 Newji。</p><h3><strong>Gauguin：闲来无事，不妨动脑</strong></h3><p>平台：Android</p><p>关键词：数独、小游戏</p><p>@Peggy_：自从在二年级下册发现了数独相关的题目后，我突然发现数独似乎是个不错的杀时间小帮手，一来它的难度可调节，时长也能随之变化，二来相比于刷短视频，它多少有点益智元素，玩起来不至于有太多愧疚感。</p><p>近半年来，我都通过一个在线网站玩低阶或是中阶数独打发时间，不过很快这种 9*9 的小格子开始让人觉得无趣，于是我转而发现了另一款小游戏：Gauguin。Gauguin 是一款 Android 端应用，相比于网页游戏，它的使用体验更加稳定，玩法也更加多样，加上游戏可自定义，能让我们杀起时间来更加得心应手。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_57d718209311495da9adc8de7cc3427a@000000_oswg42353oswg606oswg1280_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作为一款和数独类似的逻辑类游戏，Gauguin 的玩法仍然是以数字计算为主，相比于数独，Gauguin 的数字更少，仅有 1-6 几个数字，但其格子变化却更多，且加减乘除法均有涉及，两者大体玩法类似，都是用数字填充格子，且横排、竖排的数字不能重复，Gauguin 允许我们用给定数字通过加减乘除任意算法凑出格子的数字。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_9472daf245724baa98fd180687f7ab37@000000_oswg64382oswg1080oswg755_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>初次打开 Gauguin，面对大小错落的格子我们或许会无所适从，不要紧，在这里我建议你直接跳过默认的游戏，创建一个新游戏，从最少的格子和最简单的算法玩起。在 Gauguin 中，格子的数量、形状、算法的多少均可调节，只要我们愿意，可以无限地享受新游戏带来的脑力刺激。而在游戏的过程中，如果遇到难解的格子，我们也可以及时求助，应用右下角菜单中有错误提示和解决方案。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_434dda4e05d5433ca1ec803f6d27badd@000000_oswg67268oswg1080oswg755_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果你正在寻找一款玩起来不那么愧疚的小游戏，不妨尝试一下 Gauguin，你可以通过 F-Droid 下载开玩，应用完全免费且无广告。</p><h2><strong>🆕不容错过的 App 更新</strong></h2><p>除了「新鲜」App，App Store 中的许多老面孔也在不断迭代、更新，增加更多有趣和实用的功能。少数派希望帮你筛选 App Store 中值得关注的 App 动态，让你快速了解 App 和开发者们的最新动态。</p><h3><strong>Craft 2.6 更新：个性化域名让分享更自由，智能链接让网页内容呈现更精彩</strong></h3><p>平台：iOS / iPadOS / macOS / Web / Windows</p><p>关键词：文档、笔记</p><p>@Vanilla：稳定迭代的笔记应用 Craft 最近又更新了 2.6 版本，为用户带来了期盼已久的个性化域名功能。同时，Craft 也对笔记内插入的网页链接做了更多的适配，更多的网址支持内嵌卡片和智能链接。</p><p>首先，我们来看看个性化域名功能。点击任意笔记右上角的分享按钮「Share」，然后点击链接旁边的「Create」按钮来创建分享链接，这样一来我们就可以通过「Customize URL」功能定制自己的专属域名了。目前，Craft 面向 Pro 用户开放了自定义域名前缀，面向 Business 用户开放了外部域名，未来 Craft 将会向所有用户开放自定义域名前缀的功能，所以现在 Pro 用户可以抓紧时间抢注自己喜欢的域名前缀。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_621671ed2cd3401986ea53f8a57547dd@000000_oswg213778oswg1080oswg646_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_20187eb9f5924d8c887ee96e97e5ab7e@000000_oswg185370oswg1080oswg646_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b626b40e65fc41edb5ec5f26b7a0b571@000000_oswg177067oswg1080oswg646_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了个性化域名，现在还可以对每个笔记页面单独设置路径，只需在「Path」处填入自己喜欢的名称然后保存就行。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_135fcf4b3f7d4ddb8a008e2b677ee686@000000_oswg181124oswg1080oswg646_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a122efd1130542a89f9c58a9aaf45813@000000_oswg104313oswg1080oswg543_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在 2.6 版本中，Craft 还新增支持了更多的网站以适配笔记中的富媒体展现形式。一类是以 Vimeo 为代表的视频网址，将视频链接直接插入到笔记后，视频可以在笔记中直接播放；另一类是以 Netflix、Airbnb 等为代表的网站，将链接插入笔记后会自动生成卡片，并在卡片上展示一些关键信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2c83cffae27b42f8a91232a7576295f0@000000_oswg194360oswg1080oswg646_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_77d11607652d4f6f94ce8bba2af3484c@000000_oswg110261oswg1080oswg646_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Craft 可以在官网和 App Store 免费下载使用，付费用户分为 Pro 和 Business 两档，目前正在进行 3 周年优惠活动，所有付费计划都打 5 折，12 月 4 日截止。</p><p>🔗 https://www.craft.do/</p><h3><strong>小星记账 3.0 更新：沉寂许久的再次回归</strong></h3><p>平台：Android</p><p>关键词：记账</p><p>@Noah_Choi：小星记账自今年中旬就一直处于「待机」状态，这半年里除了偶尔发布小版本更新之外再没有任何大动作，原本活跃在酷安社区的开发者也因为官方一句「人事变动」而被认为是离职出走。本以为这颗记账新星刚刚升起就要陨落时，但小星记账的开发者在年底突然回归，并带来了 3.0 大版本更新。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_2b1224f8812c4a7eaed6ba31261d4772@000000_oswg118184oswg1080oswg1546_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>本次 3.0 大版本并没有带来全新的 UI 界面，但在不少细节交互上进行了调整，其中最明显的变化就是在记账界面。更新后，所有在记账过程中需要进行「选择」的操作（包括标签、角色等）都采用了与选择收支类别相同的操作方式，弹出菜单的界面格局也高度一致，而且他们也都支持了多选批量操作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_989aababb5114f8d9d512e2c3f78884f@000000_oswg129138oswg1080oswg1111_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这种变化也体现在自动记账功能上。3.0 版的自动记账界面保持了与手动记账相同的界面和操作。使得我们在使用小星记账的全过程里都能获得更加统一的操作体验，而不会像以前那样出现割裂感。除了 UI 变化，自动记账也强化了对账目本身的编辑功能。在老版本中，自动记账更多的还只是一个记账入口，如果要对账目进行额外操作，还是要进入 App 本体。而更新 3.0 以后，我们可以直接在弹出的自动记账窗口中关联以往的退款、报销、应收应付项目，使得自动记账的实用性进一步提升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_ac1825099a2b4f5b8b21814390f5a934@000000_oswg126233oswg1080oswg2259_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其他功能方面，小星记账 3.0 重构了周期交易功能，不仅使用起来更加方便，而且分期付款也支持了提前还款的计算逻辑；另外，在标签、多币种、报表、信用卡管理等功能上也进行了不小的调整优化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a3b5f5b80fe042dbae91b5d2edb9e885@000000_oswg199088oswg1080oswg1111_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>整体来说，小星记账 3.0 不仅给我们带来了回归的惊喜，也实打实对产品本身的逻辑和功能进行了优化，确实不枉用户们的翘首以盼。现在，你可以在酷安和各大手机应用市场获取小星记账 3.0。</p><h3><strong>Audio Hijack 4.3：用可视化的方式实现语音转文字</strong></h3><p>平台：macOS</p><p>关键词：播客、音频剪辑</p><p>@化学心情下2：Audio Hijack 是一款相当有趣的 Mac 上的音频处理 App，通过可视化的界面可以轻松抓取网页和应用中的音频，并将音频流进行二次处理（录音、制作播客或者进行串流）。而在近期这款音频处理 App 迎来了 4.3 版本更新，实现了实时音频转文字，同样仅需简单的拖拽即可实现！</p><p>首先在 Audio Hijack 的模版选择器中先创建一个新的转录会话，默认情况下类似下面这个工作流，你只需要对着 Mac 上的麦克风说话，通过 Transcribe 这个模块就可以实现转录文本的记录了。Transcribe 这个模块背后则是基于 Open AI 的自动语音识别系统 Whisper，基于本地因此也无需再另外付费就可以实现。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_fb72342cb0c147cfaa34ccd0f651e33c@000000_oswg43159oswg670oswg410_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然有些时候我们需要转录成文本的并非是实时话筒中的声音，也有可能是目前正在使用的应用程序中的在线会议音频，在 Audio Hijack 也同样可以实现，比如你可以通过模块拖拽的形式，选择音频源模块为某些应用（比如 Zoom、Skype 或者其他视频会议或者通话的 App），然后将其和 Transcribe 模块以及 recorder 连接在一起，从而实现转录应用程序中的音频为文本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_fa923bff731143eeb99eb4da0be4169d@000000_oswg27874oswg570oswg150_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然除了可以实现实时的音频流转录之外，如果你希望将音频文件转录成文本也可以实现，方式还是使用 Audio Hijack 来创建一个工作流，这里选择的第一个模块就是一个音频播放器了，音频播放器的工作就是将音频文件播放出来，然后再连接 Transcribe 模块实现最终的转录工作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_28896cd9b1fd4615b76cffe0b68e6601@000000_oswg18502oswg266oswg126_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其实 Audio Hijack 的 Transcribe 非常适合用在播客制作上，一般我们都会在制作播客之后放上一段 Show Notes，作为整个节目的概述，通过创建工作流以及配置 Transcribe 模块，我们可以让最终输出的文本中都记录每一个音轨对应的时间戳以及文本内容，从而方便听众了解播客节目主要说了哪些内容。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_74417bd97b924f44b2f86f0032a30854@000000_oswg30476oswg424oswg283_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>你可以在官网下载 Audio Hijack。</p><p>🔗&nbsp;https://rogueamoeba.com/audiohijack/</p><h3>原文链接</h3><p>https://sspai.com/post/84841?utm_source=wechat&amp;utm_medium=social</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzU4Mjg3MDAyMQ==&amp;mid=2247565606&amp;idx=1&amp;sn=e249b18222fd160b885b8e7346beeddf&amp;chksm=fdb2344ccac5bd5a368510e66f4a7aa6836a8b735b3d657b53a543f628822bf213a2d2e373ef&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“少数派”（ID：sspaime）</a>，作者：少数派编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2542697754648706</id>
            <title>瑞士食品科技公司AgroSustain研发天然生物涂被剂，将果蔬的保鲜期延长至一个月 | 瑞士创新100强</title>
            <link>https://www.36kr.com/p/2542697754648706</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2542697754648706</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 07:43:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 食品科技公司, 生物涂被剂, 食物保鲜, 可食用涂被剂
<br>
<br>
总结: 瑞士食品科技公司AgroSustain利用天然的植物提取物开发了可食用的生物涂被剂，能够延长果蔬的保鲜期，减少食物浪费。这种涂被剂由植物油和食品乳化剂组成，不含致敏物质，可以用于多种果蔬作物。使用方便，只需将果蔬浸泡或喷洒涂被剂，就能形成一层薄膜，降低水分流失，延缓果蔬腐烂过程，使其保鲜一个月。这种可食用涂被剂不仅避免了传统保鲜方式的弊端，还减少了食物浪费，支持可持续食品生产。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231202/v2_25257797a8064e98895a5c3020efac29@5898759_oswg49770oswg903oswg581_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源AgroSustain官网</p><p>瑞士食品科技公司AgroSustain成立于2018年，该公司利用天然的植物提取物,开发天然、有机的生物涂被剂，能够将采摘后的果蔬保鲜期延长至一个月。</p><p>AgroSustain脱胎于瑞士洛桑大学，由Olga Dubey博士和Sylvain Dubey联合创立。Olga Dubey在洛桑大学攻读博士时发现了一种天然化合物，能够对抗损害多种水果和蔬菜的植物病原霉菌，这也是AgroSustain的核心技术。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231202/v2_fd01a67af5024a0a902b3552b4febf57@5898759_oswg519204oswg1000oswg626_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源Innosuisse</p><p>一根来自中美洲的香蕉需要2到3周才能运到瑞士销售，在此期间，果蔬会进行冷藏保鲜。即便如此，根据联合国粮食及农业组织 (FAO) 估计，全球每年生产出来的粮食大约有1/3在运输或储存过程中被损毁或浪费掉，造成约1.66万亿美元的经济损失。</p><p>易腐果蔬在储存和运输过程中出现的浪费，已成为食品行业面临的一个主要挑战。传统的保鲜方式之一是为果蔬“打蜡”。蜡涂被剂虽然可以阻碍果蔬呼吸和防止水分流失，但却不能延缓水果成熟，并且一些蜡中含有致敏成分，会导致消费者产生过敏反应。另一种常见的方式是为果蔬套上塑料包装，保鲜原理和效果和“打蜡”相似，但塑料制品会对环境带来严重危害。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231202/v2_d44760ae404440b5ae2b7799a5270ca9@5898759_oswg167827oswg640oswg350_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源瑞士创新100强官网）</p><p>AgroSustain提供的可食用天然有机保鲜涂被剂，既规避了以上弊端，又极大延长了果蔬的保存期限，减少了食物浪费并支持可持续粮食生产。</p><p>AgroSustain的天然涂被剂由植物油和食品乳化剂组成，不含任何致敏物质并且可食用，能够用于水果、蔬菜和花卉等20多种果蔬作物。其使用方法非常方便，仅需在采摘后将果蔬短暂浸泡在涂被剂液体中，或者喷洒在表面，作物表面就会产生一层薄膜。这层薄膜可以降低70%的水分流失，减少新鲜果蔬与气体、微生物之间的相互作用，延缓水果和蔬菜的腐烂过程，使其处于“休眠”状态，进而将果蔬的保鲜期延长至一个月。</p><p>该过程无需冷藏，常温可用，极大降低了使用门槛和能耗压力。在终端销售后，使用AgroSustain天然涂被剂还能再延长3-5天的果蔬保存期限，有效减少因腐烂、变质造成的食物浪费。有了 AgroSustain涂被剂的支持，原本必须空运的易腐果蔬，如木瓜、芒果等，也可以选择速度较慢但污染较少的海运，生产商也无需再用塑料保鲜袋，大幅降低运输环节对环境的影响。</p><p>2022年，AgroSustain的首款涂被剂产品AgroShelf+上市，随后与瑞士及欧洲地区的大型零售商、批发商签署了超15项试点协议，建立了生产设施，并与瑞士水果和蔬菜经销商 Giovanelli Fruchtimport建立了战略合作关系。目前，AgroSustain的业务已经覆盖欧洲、中东、拉美和非洲地区，为当地的进口商及生产商提供果蔬保鲜解决方案。</p><p>2022年，AgroSustain宣布完成480万瑞士法郎的A轮融资。 AgroSustain计划加强产品开发，扩大市场份额，并开发下一代生物抗菌涂被剂和天然果蔬生长素。AgroSustain将持续为果蔬保鲜提供从生产至销售全流程的一站式解决方案，减少食物浪费，支持可持续食品生产。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231202/v2_a5b09102f5424e38aceaedbad00d463d@5898759_oswg763644oswg709oswg951_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>AgroSustain是2023年《瑞士创新100强》（TOP100 Swiss Startups）上榜企业。《瑞士创新100强》汇聚了最佳“瑞士制造”的初创及成长期科技创新企业，是瑞士科技创新领域最具国际影响力的标杆榜单。自2011年以来，该榜单每年在瑞士全国范围内评选出100家最具开创性和市场前景的瑞士创新企业和25家最具独角兽潜力的瑞士成长期企业，覆盖生命科学、工程机械、机器人、信息通信、低碳科技、食品科技等领域。《瑞士创新100强》及系列品牌活动是瑞士创新生态圈的标志性活动，代表着瑞士创新最高地和国际投融资最前沿。</p><p>2023年《瑞士创新100强》中文版由以明科技（Insight Tech）荣誉发布。以明科技是《瑞士创新100强》的中国授权合作方，负责《瑞士创新100强》在中国的运营推广并协助榜单项目对华商业合作。作为中欧（瑞士）科技创新投资与产业化运营商，以明科技为瑞士创新和中国产业的双向合作提供投融资和商业拓展服务并开展股权投资业务。</p><p>获取2023年《瑞士创新100强》完整榜单及行业榜单，请访问以明科技公号或官网。</p></blockquote>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2547339773416585</id>
            <title>锦江航运登陆沪主板，股价涨超57%，聚焦海上集装箱运输业务</title>
            <link>https://www.36kr.com/p/2547339773416585</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2547339773416585</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 07:30:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 上海锦江航运, 沪主板上市, 国泰君安证券, 228亿元
<br>
<br>
总结: 上海锦江航运在沪主板上市，由国泰君安证券保荐，发行价格为11.25元/股，发行市盈率为8.24倍，超过行业市盈率。截至目前，其股价涨幅超过57%，市值超过228亿元。 </div>
                        <hr>
                    
                    <p>12月5日，上海锦江航运（集团）股份有限公司（以下简称“锦江航运”）在沪主板上市，保荐人为国泰君安证券股份有限公司，发行价格11.25元/股，发行市盈率为8.24倍，高于5.39倍的行业市盈率。截止到发稿时间，其股价涨超57%，最新市值超228亿元。</p><p>锦江航运是一家综合性航运公司，主要从事国际、国内海上集装箱运输业务，多年来持续深耕东北亚、东南亚和国内航线。截至2023年6月30日，公司共经营49艘船舶，总运力达到4.52万TEU。截至招股说明书签署日，据国际权威研究机构Alphaliner的数据，公司总运力位列中国大陆集装箱班轮公司第6位，世界集装箱班轮公司第33位。</p><p>股权结构方面，截至招股说明书签署日，上港集团直接持有公司98%股份，通过全资子公司国客中心间接持有2%股份，系公司控股股东。而上海市国资委间接持有上港集团41.12%的股份，系上港集团的实际控制人，因此锦江航运的实际控制人为上海市国资委。</p><p>本次IPO所募集的资金主要用于上海锦江航运（集团）股份有限公司国际集装箱运输船舶购置项目、上海海华轮船有限公司沿海集装箱运输船舶购置项目、上海锦江航运（集团）股份有限公司集装箱购置项目、上海锦江航运（集团）股份有限公司智能化船舶改造项目。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_ac2a31a4223342ccbabfe831aaf7b7c3@000000_oswg128101oswg870oswg322_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">募资使用情况，图片来源：招股书</p><p>业绩方面，招股书显示，2020年至2023年1-6月，锦江航运的营业收入分别约34.3亿元、53.72亿元、68.4亿元、26.6亿元，归母净利润约4.65亿元、12.26亿元、18.27亿元、5.47亿元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_1c455a9b0d2d4bd4bed7ae47e08616d4@000000_oswg233688oswg787oswg583_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">主要财务数据和财务指标，图片来源：招股书</p><p>值得注意的是，公司存在业绩下滑的风险。2023年1-9月，锦江航运的营业收入和净利润分别约39.56亿元、7.06亿元，同比分别减少23.33%、52.66%。公司业绩下滑主要由于集装箱航运市场供需发生变化，致使集装箱运输价格有所下降等导致。</p><p>锦江航运所处的集装箱航运行业属于典型的周期性行业，2021年市场运价波动上涨， 2022年下半年起市场运价又逐步回落。当航运需求旺盛的时候，相关公司赚得盆满钵满，一旦航运需求减少或运价下降，公司的业绩也难免被拖累。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_8a5d0ee39fb242dba54f904b775a9dac@000000_oswg127251oswg774oswg502_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2010年至今各航线运价指数变动情况，图片来源:招股书</p><p>具体来看，报告期内，锦江航运的收入主要来源于班轮运输服务，其中东北亚航线的营收占比在50%以上，占比较大；东南亚航线的营收占比也呈上升趋势。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_a4f615ceda264bdfa75e0da614d00981@000000_oswg187344oswg873oswg454_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">按照服务模式和运输航线区域的不同分类，图片来源：招股书</p><p>报告期内，锦江航运的主营业务的毛利率分别为24.74%、35.75%、36.81%和29.87%，处于同行业可比公司的合理区间范围内。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231205/v2_b8ff41eef45c40cbaec524625e82777d@000000_oswg174970oswg784oswg376_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">公司与同行业可比公司的主营业务毛利率比较，图片来源：招股书</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzUzMTkwOTkzNw==&amp;mid=2247565061&amp;idx=3&amp;sn=d8338ce2e6a109fd060b3f47f8aeb781&amp;chksm=fab8e35bcdcf6a4dd84f46f4e535bfd33ab7c93f3331542ec7f4487c6d2bee98b6661aa886a8&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“格隆汇新股”（ID：ipopress）</a>，作者：发哥说新股，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>