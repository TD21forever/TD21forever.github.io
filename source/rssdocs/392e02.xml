<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3036175183966216</id>
            <title>2024年还想做独立游戏？除了引擎，你需要知道这些</title>
            <link>https://www.36kr.com/p/3036175183966216</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036175183966216</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 12:41:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 独立游戏开发, 社保, 财务规划, 精神压力  
<br><br>  
总结: 本文探讨了独立游戏开发者在全职开发之前需要考虑的多个方面，包括社保的缴纳、财务规划和精神压力等。社保问题对新手开发者至关重要，需根据个人情况权衡是否缴纳。财务规划方面，开发者需意识到生活成本可能高于预期，并做好应对意外支出的准备。此外，精神压力是创作者常面临的挑战，建议开发者寻找支持和调节心态的方法。最终，文章强调独立游戏开发不仅是技术问题，更是对生活方式的重新审视。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_90432cd509744fb6976cedf33159f2a1@46958_oswg61843oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>10月30日，独立游戏开发者FHN发布的一条微博引起了小范围关注。在这条《如何靠开发独立游戏避免上班的宿命》的微博中，他分享了自己的经验，并且指出了一些对于新手开发者和小型团队来说具体可行的执行路径和可能面对的问题。</p>
  <p>和一些看起来更行业的“指南”不同，这条博文提到了几则更平实、贴近真实生活的问题，比如“社保个税怎么办、要不要组队和开公司”，这给了我们一些启发。所以，我们决定制作一个“和游戏开发不太相关的独立游戏开发者指南”。</p>
  <h2><strong>一：在开发独立游戏之前，你可能要考虑的事情</strong></h2>
  <h3><strong>1、首先是社保</strong></h3>
  <p>对于相当一部分“新入行”的独立游戏开发者来说，缴纳社保是一个至关重要的问题。常见的情形是：一位开发者刚刚辞职（或失业），决定开始尝试全职开发独立游戏，他的大部分支出都要由自己此前积攒的存款负担。</p>
  <p>以今年7月31日上海人社局公布的2024年（2024.7.1—2025.6.30）社保年度缴费基数为例，基数上限为36921元/月，下限为7384元/月。这意味着，如果一位独立游戏开发者在上海生活，想要交社保，他需要至少负担每个月2716.40元的费用。如果是在职工作，单位会承担其中大部分，但对于自由职业者来说，这无疑是一笔需要考量的支出。</p>
  <p>我们并不会果断地建议大家“是否要交社保”，这是一个有关个人的选择和考虑、需要结合具体情况分析的问题。</p>
  <p><strong>（1）你当然可以不交社保，如果没钱的话。</strong></p>
  <p>一部分独立游戏开发者（和其他工作性质类似的行业人员，比如游戏翻译）出于经济压力选择不交社保。这十分正常，“有钱就交，没钱就不交”的选择合情合理。</p>
  <p>独立游戏开发者虚拟游方居住在上海，今年4月公司倒闭后，他开始全职做独立游戏，目前已经断缴社保接近一年。对他来说，不交社保的原因十分简单。他为自己全职开发独立游戏的这段时间进行了一定的成本计算和规划：他准备了一笔存款，包含接下来一年房租、水电以及饮食的开销，但不包括社保这类支出（如果加上社保，整体的开支计划就需要大幅度调整了）。在他的打算里，这一年应该是完全“自由”的，如果开发游戏失败、不得不回去上班，到时他会再考虑社保的事情。</p>
  <p>同时，虚拟游方对社保政策也存在一定的茫然，他大概知道“这件事很重要”，但不清楚具体会产生什么影响。在他就职的公司倒闭前，公司的资金链已经出现周转困难，他和同事们的社保早在失去工作前就已经断缴。因此，“社保”看起来确实好像没那么紧急。</p>
  <p><strong>（2）如果你不担心因为不交社保而产生的问题，你还可以更心安理得一些，但最好做好其他准备。</strong></p>
  <p>社保包括医疗保险、养老保险、生育保险、工伤保险以及失业保险，其中医疗保险与养老保险占大头，这两项保险在人们心中的重要程度不言而喻。简单来说，有些事情的确不该是20岁的你应该思考的，可到了40岁的时候，你就不得不面对了——所以，在现在这个时段，你可能得强迫自己考虑一下这个问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_4924b2305ffa42dd83b9ad5a60a06f45@46958_oswg11254oswg691oswg431_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">各种问题都会被逐渐写到你那份原本空白的纸上</p>
  <p>从更现实的角度考虑，社保的缴纳时长往往与买房、买车、子女入学等条件绑定，比如在一些城市，如果想要购买车、房，对社保的缴满时长会有一定的最低要求。</p>
  <p>但是相应地，如果你没有这方面的需求，至少在现在，这或许不是一个重要的问题。</p>
  <p>今年26岁的独立游戏开发者游夏对我讲述了他的想法，去年开始，他决定不再缴纳社保。在他看来，他没有买房、买车或者追求积分落户的计划——未来也不会有。养老只要有存款就行了，至于医保方面，他目前买了重疾险，同时在挑选一些商业保险，他觉得这可以解决绝大多数的问题。</p>
  <p>开发者阿船补充：“如果确实资金有限，不买重疾，那么建议最少也要购买百万医疗险，否则一场大病就可能导致巨大的额外支出。比如我去年做了一台大手术，如果没有社保，没买百万医疗，那可能就要额外负担十几万的医疗费用。可以不买重疾，但是百万医疗一定要买。”</p>
  <p>“我觉得社保其实意味着一种对‘稳定生活’的追求，比如说如果发生了点什么，它还能帮你兜一下底。”游夏说，“追求稳定生活没什么不对的，在我刚辞职、断缴社保的时候，我也很没有安全感。虽然这种不安更多来自我妈，她会隔三岔五地提起这件事。”</p>
  <p>“但是后来我想通了，都做独立游戏了，本来就不是为了追求安全感啊！”他说。</p>
  <p><strong>（3）如果要交社保，请尽量咨询当地人社局。</strong></p>
  <p>对于一部分独立游戏开发者来说，事情并不是那么轻松和干脆利落。在能够负担的情况下，社保确实可以带来一定的保障和社会资源，成为一种“托底”；同时，对于一部分已经缴纳社保多年的中年开发者来说，忽然考虑断缴，还存在一定的“沉没成本”因素。</p>
  <p>所以，如果你经过一番权衡后仍然决定自己继续交社保，你应该多了解一些相关政策，找到更合适的选择，并根据具体情况，申请一些国家给予的社会保险补贴。</p>
  <p>不同的地区政策不同，比如，非京籍人员不能直接在北京以个人名义缴纳社保，这也意味着有时候你需要采用其他方式——目前居住在北京的开发者阿船就注册了自己的公司，以公司的形式为开发团队成员缴纳社保、发放工资。</p>
  <p>一位独立游戏开发者十分严肃地表达了自己的建议：部分地区对于灵活就业人员，是可以选择单独缴纳医保的，只交医保可以成为一个不错的“过渡”选择，金钱压力减轻，同时依然有一定保障。</p>
  <p>他说：“在决定全职做独立游戏之后，我曾陷入过长时间的焦虑状态，甚至不得不寻求心理治疗，医保报销后，每次在公立医院进行心理治疗的费用不超过500元。对于我们这类人来说，这种精神困境是频繁存在、容易发生的，从这个角度说，不管是心理治疗还是医保，都很重要。”</p>
  <h3><strong>2、如何规划金钱</strong></h3>
  <p>虚拟游方起初准备了8万元左右的存款，在他的计划中，这笔存款可以支撑他从今年4月开发游戏到年底，甚至还有盈余，到那时，游戏应该接近完成。不过目前，他已经严重超支。</p>
  <p>“做游戏超支是常态。”另一位独立游戏开发者对我说，“尤其在没有经验的时候，很快你会发现很多东西都比你想象的贵……”他指的是在开发游戏方面，但生活也是同理，决定成为全职独立游戏开发者后，你需要更大程度地对金钱有所规划。</p>
  <p><strong>（1）生活成本可能很多时候比你预想的要高一点，意外总是时有发生。</strong></p>
  <p>你可以尝试着节约一些生活成本。比如减少外卖的频率，购买一些速冻食品（十分简单），学会寻找联锁超市的晚间打折商品（较为简单），尝试着自己做菜（难度因人而异），去菜市场买菜以及了解蔬菜的价格和新鲜程度（一般简单），和卖菜老板讨价还价（十分困难）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_51c2b77e02db425dabc83d46b282778f@46958_oswg28826oswg1080oswg257_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">和蔬菜打交道或许十分重要</p>
  <p>但你也要做好“意外”出现的准备。具体来说，当你幻想“我可以不出门、不社交、不买衣服，就这样过上好几年”的时候，总是会发生一些预想之外的情况。人很可能忽然生病、忽然摔坏手机、忽然很想花一大笔钱。</p>
  <p>虚拟游方在上海和别人合租，住在一个被隔断的小房间里，每个月租金加上水电，大约3000多元。在计算怎么花钱时，他削减掉了几乎全部有关外出、社交活动的成本，“衣服鞋子也不用更新了”。起初，他觉得，支出只会花费在买菜做饭和外卖上，“感觉应该可以坚持一年”。</p>
  <p>但游戏做了一段时间，他很快发现，开发开放世界游戏对设备要求太高了，他原来的硬件完全无法负担，他不得不为此花了一笔“必要的钱”。到了8月下旬，《黑神话：悟空》发售，他一直期待这款游戏，想用最好的体验游玩，实在忍不住，又咬咬牙换了一台显示器。</p>
  <p>“花了好多好多钱，而且生活成本也比想象中要高一些。”到现在，虚拟游方手里还剩下的存款不到3万元，而游戏的开发进度已经延后，至少还要再做半年。为了节省成本，他最近正在规划搬家，从上海搬到苏州，希望能多支撑一段时间。</p>
  <p><strong>（2）如果你确实没办法很好地规划这些，尝试劝说自己不要太过焦虑。</strong></p>
  <p>尽管大部分人都知道应该怎么做，但并不意味着所有人都能做到这一点。一位独立游戏开发者在开发游戏的同时承接一些外包工作，他告诉我，自己经常出现“收到客户打款的前几天、手里只剩下十几块钱”的情况。有时候他不太在意这些事情，但假如当时的心理状态不太好，在约定打款当天，他什么都做不下去，只能一直关注着银行卡信息。这种事情十分正常，如果发生了，不必过分谴责自己。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_a31cf6f732174da0a350f5f256343795@46958_oswg55503oswg1080oswg461_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">阴冷的天气有时也会影响心情</p>
  <p><strong>（3）做好长期持续这种状态的心理准备，如果有精力的话或许可以考虑一些副业。</strong></p>
  <p>“枫2”今年37岁，他和自己工作室的几名成员——大家都通过网络认识，也都是线上工作——正在做第3款游戏。他对我说，尽管之前做的几款游戏有过一定收入，但是现在也接近于无了。</p>
  <p>“（工作室）大部分成员是没有稳定收入的，因为我们一般是开发完游戏以后再分钱。”枫2说，“当然，因为考虑到目前的情况，从分成计划来说，游戏收入的90%都会用来分成。”在没有收入的日子里，大家只能自己想办法解决这些问题。</p>
  <p>可选择的副业多种多样。不过，如果精力有限，选择记录自己的游戏开发心得和进程或许是一个较为可行的想法。同时，这也可以帮助自己的独立游戏吸引玩家，从而节约一些宣发成本。</p>
  <p>在B站，枫2有4万粉丝。他的视频内容以“游戏开发科普”为主，和他的工作内容息息相关。收益则来自于一些广告和“带货”，比如一些书籍的推广：有出版社来联系他，请他帮忙介绍、推荐一些和游戏相关的学术科普书籍，每个月收入大概有几千元。他目前和家人一起住，这些收入可以基本维持他的日常生活。</p>
  <h2><strong>二：在开发过程中</strong></h2>
  <p>创建自媒体账号之初，枫2的科普内容大多非常基础和“干货”，这和后台显示的数据息息相关，“数据最高的一般是那种教人怎么入行的、或者告诉新手怎么做独立游戏的——总结起来，就是给外行看的。真正在做独立游戏的人，可能对我的关注不会太多。”</p>
  <p>在枫2看来，这也能反映一些问题。在独立游戏开发过程中，很多问题并不只是关于技术，还可能关于一些没有方法论、需要自己摸索的东西。</p>
  <p><strong>1、辨别不靠谱的人，学会一些沟通上的技巧。</strong></p>
  <p>没有人可以一眼看出谁“靠谱”，但是当你发现问题存在时，你可以尽量更早解决它，克服一些不愿意（不擅长）及时沟通的困难。</p>
  <p>虚拟游方把自己出现这类情况的原因归结到“工作经验不足”上。他所在的公司倒闭前，其实很早就有同事开始离职。“但是我当时一直心存幻想，老板也说很快就能拉到投资了，而且当时介绍我去这家公司的领导和我关系挺好的，我就总想着再等等。结果就是他欠了我们好多钱。”他感到十分后悔。</p>
  <p>类比到制作独立游戏的过程中——如果你发现团队似乎一直“画饼”，或许要早点考虑离开；如果你发现某个新成员不太适合这里，请试着像一个经验丰富的HR一样，劝说对方离开。</p>
  <p><strong>2、线上还是线下办公？</strong></p>
  <p>影响这个问题的决定性因素在于你是否可以负担租金成本，以及能否确保团队成员之间的流畅沟通。一部分独立开发团队会选择完全线上交流的形式，工作效果也十分不错；但是，如果你们都觉得线下见面很重要，那它就一定很重要。</p>
  <p>阿船的公司注册于2019年初，起初一共有5名成员，到现在几番变动，有7位成员。团队建立之初，他们就在北京租下了一个小办公室，每个月租金5000元左右。现在，他们的公司搬到了朝阳大悦城附近，每月租金大约2万元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b5d325db1a0c49b785a7b042b7f38128@46958_oswg85599oswg1080oswg614_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">实际情况中，公司的环境可能会更有助于保持工作状态</p>
  <p>这不算一笔小开销，但在阿船看来，它有足够的必要：线下沟通效率更高，有益于大家的精神和工作状态。新冠时期，由于封控，公司大约有一整年时间线上办公，暴露出了很多问题。</p>
  <p>“能明显感觉到效率比较低，沟通什么都很麻烦，因为大家都没经历过所谓的远程居家，虽然我们每天开语音会，但还是存在很多问题。”阿船说。此外，他们也根据具体情况调整了一些策略：比如和团队的美术进行沟通，答应对方远程办公、工作时间也只占每月工作日的一半，对应的是工资也有调整——采用《非全日制用工劳动合同》形式，每周不超过24小时就是合法的，且依照规定不用缴纳社保，适配他们目前的开发节奏和支出。</p>
  <p><strong>3、把控好自己和团队的进度，“做完”一款游戏很重要，时间成本也很重要。</strong></p>
  <p>在枫2看来，做独立游戏最重要的是“一定要保证有足够的技术把游戏给做完”——重点在于“做完”。这个判断和他们之前没做出来的那个二次元项目有一些直接联系，它暴露了团队不少问题，比如设计思路上的欠缺、美术产能的不足。</p>
  <p>重要的是，如果一款游戏迟迟无法完成，消耗的不仅是已经投入的资源，还有人们的自信心。“其实最开始我就觉得这款游戏可能做不出来，但当时他们（其他成员）像打了鸡血一样。现在回头看，游戏在时间成本上也有很多欠缺。”</p>
  <p>“前两个游戏都要求在15个月以内做完，我们也确实做完了，然后就是那个二次元项目——我的规划是30个月做完，结果没有做完，我们就放弃了。”枫2对我说，他希望能通过这种方式做好“时间管理”。</p>
  <p>阿船告诉我，目前他们团队的主要精力放在一款已经开发了三四年、预计明年上线的PC端游戏，和几款零散的小游戏上，后者也是出于成本控制的考量。</p>
  <p>“就是那种比较小众、卖得很便宜的那种小型独立游戏吧。”阿船说，“因为这样成本可能更好控制一些。大型游戏一做三四年，太不可控了。你做一些一年左右能出来的东西其实就够了，对小公司来说相对也好些。”一直做不出东西、没成绩，成员的心态也会出问题。</p>
  <p><strong>4、居家工作时，工作状态存在“不一定可控”的风险。</strong></p>
  <p>对于个人全职独立游戏开发者来说，时间、工作强度都由自己调度，也存在诸多不可控的问题。如果没有人把关和监督，工作进展很大程度依赖于个人的自律，原本搭建的规律可能会崩塌，持续地重新建立秩序也是要面对的课题。</p>
  <p>虚拟游方觉得，另一个问题是，当原本的工作变成了“为自己工作”，在家里，除却做游戏以外的时间都像是浪费，“一闲下来，也只能学学C++，甚至不太敢去玩游戏，感觉时间浪费了，就很难受”。</p>
  <p><strong>5、如何向父母和亲戚解释你在干什么。</strong></p>
  <p>向父母解释自己在做什么并不总是那么简单——有时候，这可能比做一个Demo还难一点儿。我们不会预估您和家庭成员的关系——也许好，也许坏，也许他们可以给你一定支持，也许你觉得他们只要不烦你就是好事了。但你需要面对的事实是，在整个独立游戏开发过程中，你需要得到尽可能多的支持。</p>
  <p>我们还是建议，如果可能，向你的家庭成员解释自己在做什么是很有必要的。就算从实际的角度来说，让他们不那么担心也是一件有益无害的事情。</p>
  <p>当然，你的亲戚们也可能觉得你“每天把自己关在房间里”。也许在聚会上，这会给你带来一点压力。如果父母和亲戚听不太懂“开发独立游戏”，你可以考虑把自己描述成在“创业”，他们就大概理解了！而且“创业”这个词总是带一些天然的正当性。</p>
  <h2><strong>三：精神压力</strong></h2>
  <p>精神压力对于创作者来说是必然的。每个人都会有自信和热情高涨的阶段，然后随着这样那样的问题逐渐冷却，然后循环。你可以轻松搜索到不少相关的抱怨，和那些“成功人士”的应对方法，但是如何面对它，依然只能自己摸索。</p>
  <p>在阿船看来，这种心态的调节始终是困难的。他觉得团队的人都是这样，大家寻找一些方法，努力自我调节，比如公司气氛低沉、游戏上线后关注度不如预期时，大家会找些活泼的话题，或者一起吃饭团建，“虽然不一定会有什么明显的效果，但是随便聊聊也是好的”。</p>
  <p>还有养猫，或是在办公室多摆放一些绿植，有一个同事家里养了六七只猫，阿船感觉“确实还挺好的”。猫适合陪伴，又不需要像狗一样经常带出门遛弯，他目前也养了一只猫，还养了几条鱼，“平时喂喂鱼也不错”。</p>
  <p>“（做游戏）时间越长，就越容易陷入自我怀疑。”虚拟游方说。除此之外，那些被他刻意“忽略”的支出，在某种意义上也带来了一些副作用。近半年里，他很少出门，几乎和人没有社交往来，明显感受到自己“情绪很低落、精神状态不太好”。“以前看别人说独立游戏开发者都精神状态不好，想着怎么会那么自怨自艾？现在觉得，人类确实是群居性动物。”</p>
  <p>他尝试着改变这种状态。比如搬到苏州，约好和住在当地的朋友多见见面，调节自己的心情。前段时间开始，每天晚上，他都抽出一段时间外出散步，尝试将注意力转移到其他方面。</p>
  <p>一位从业者认为，尽管听起来有些傲慢，但开发者还是尽量不要完全进行孤独的创作。寻找能够互相启发的队友至关重要，就好像登山队员很少会独自一人登山一样，游戏开发也是一座非常险峻、地质环境多变的高山。</p>
  <p>同时，开发者们也应当重视生活中的其他部分，尝试着将自身的价值与注意力绑定在多个不同的目标上，例如家庭、社会公益、兴趣爱好等等。这样，当你在开发独立游戏受挫的时候，其他锚点会拯救你。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_a62de1d060954addb5998cd13854503b@46958_oswg47134oswg1080oswg807_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">比如，如果在“登山”路途中有猫咪相伴的话……</p>
  <p>还有一点是，独立游戏的成功可能不会到来，“但腰椎病变是一定会到来的，开发游戏失败也许不能摧毁你，但高血压与糖尿病一定可以……请仔细衡量。”</p>
  <h2><strong>四：这其实是一份生活指南</strong></h2>
  <p>很多受访者对我们表达了相同的感受：决定走上全职开发独立游戏的道路，一方面是因为在过程中找到了快乐、希望做出自己喜欢的游戏，另一方面则是因为“不想上班”，希望寻求另一种生活。</p>
  <p>“我觉得只要在大厂、中厂干过的人，都有这种经历。”阿船说，“你觉得有一个很不错的东西或者想法，你去往上报，它能不能做下去是你的Leader、你的领导决定的，他们会说,‘我们先开个会，讨论一下落地可行’，拖着拖着，这个东西就没了。”</p>
  <p>“上班的话，你是不可能做出你工作职责之外的内容的。因为你做出的一切，它的成本是由别人负担的。”</p>
  <p>枫2告诉我，还在公司的时候，他曾经尝试过兼职开发独立游戏，但很快发现行不通，“真的没有时间。因为游戏行业上班基本都是晚上加班到9点以后，甚至周末都还在加班，根本没时间做自己的东西。”</p>
  <p>最终，枫2选择了辞职。现在，他已经全职开发独立游戏7年。很早的时候他就产生了这种想法：做策划的时候想当主策划，做到主策划了想当制作人，当了制作人却还是在给别人打工。直到做独立游戏之后，“才能开始说，至少能保证做大部分游戏是自己喜欢的”。</p>
  <p>下定决心之前，虚拟游方为自己的选择找到了不少理由：在公司的前几年，他已经对原本数值策划的工作失去了兴趣，总是私下学习“虚幻”引擎方面的内容，还用业余时间做了一款练手的休闲小游戏（赚了大约5000块钱，他觉得还不错）；他现在在做的这款游戏更磨练技术，就算没有大获成功，也能成为日后转行的跳板。</p>
  <p>更重要的是，对他来说，制作独立游戏的过程中，他总能遇到一些情绪高涨的时刻：之前那款“练手之作”，一款3D装修游戏，制作过程中存在一些不大不小的困难，他边学边改，“每个问题都能解决，都能让自信心膨胀一段时间”。这是此前在公司上班时很少出现的体验，也推着他尝试另一种生活。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_86f2721f0e2f4c8bb1ea452e8715a3ef@46958_oswg42114oswg1080oswg518_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">生活有时就像过山车</p>
  <p>你会在一定程度上更自由，但也可能存在更多风险，以及，你可能需要更紧密地和生活接触，并且了解更多此前被忽略的“常识”。也因此，这份“指南”和“游戏开发”的关系十分有限，它其实只是在讨论：怎样去面对一种和之前截然不同的生活？</p>
  <h2><strong>附录：但实际上，“生活”没有指南</strong></h2>
  <p>即使你已经读完了上面的全部内容，但你很可能感到毫无头绪，这篇指南的样本有限，无法做到事无巨细。而且，实际上“生活”没有指南，甚至指南也并不重要。</p>
  <p>就像对于一个游戏团队来说，应该以什么形式组织不是一个问题。即使一位开发者不明白公司相关的法律规则，也不明白关于合同、利益分配与商业的基本逻辑，他仍然可以做出非常伟大的游戏；同样地，即使你不关心社保、买车买房、不关心蔬菜的价格，也不在乎所谓稳定、正常的生活，你也依然可以用自己喜欢的方式，继续生活下去。</p>
  <p>（文中受访者均为化名。题图选自独立游戏《Black Gold》《孤独的独立游戏开发者的一生》。）</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/VaXKXS_BvKa9O2hfQeDIQg" rel="noopener noreferrer nofollow" target="_blank">“触乐”</a>，作者：王琳茜，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036175364190209</id>
            <title>吉利汽车开启大规模业务整合</title>
            <link>https://www.36kr.com/p/3036175364190209</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036175364190209</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 12:38:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 吉利, 整合, 领克, 极氪  
<br><br>  
总结: 吉利汽车正在进行内部整合，聚焦资源以提升竞争力，特别是对旗下品牌领克和极氪的整合，以解决同业竞争和关联交易问题。李书福强调战略聚焦和资源整合，减少重复投资，提高资源利用效率。吉利还计划通过整合研发和销售资源，优化品牌定位，避免内部竞争。整体来看，吉利的目标是提升销量和单车售价，聚焦未来关键技术，以应对日益激烈的市场竞争。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_bc4a3b5796f34615a186e47c2a5c5749@46958_oswg81212oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>吉利正在变阵，聚焦、精简、整合是关键词。据《财经》获悉，吉利近期开启了一揽子内部整合。吉利旗下两大面向中高端及国际市场的汽车品牌，领克和极氪也开始了新一轮整合。吉利控股试图以此来解决长期困扰外界的上述两大战略品牌，同业竞争和关联交易的问题。领克、极氪两大独立子品牌的合并收拢，是吉利发布《台州宣言》战略聚焦的关键一步，此前，吉利为了聚焦资源和优势产品，已经做出了不少整合合并的措施。</p>
  <p>吉利系的新能源皮卡品牌雷达汽车，以及翼真汽车均纳入吉利汽车集团，研发团队整合至吉利中央研究院，以此实现集团内部资源共用，降低成本投入，采用轻资产模式运营。<strong>类似的调整还只是刚刚开始，背后是吉利系正在系统性地梳理内部关系，核心就是一个，整合各品牌的资源，避免重复造轮子，让各方聚焦于造车，提升整体竞争力。具体来说，一是，赚钱提升销量、提升单车售价；二是，聚焦于未来的关键技术。</strong> 这恰恰是2024年9月，李书福在自己的创业起点，浙江台州发布《台州宣言》时所说的，“战略聚焦、战略整合、战略协同、战略稳健、战略人才。”</p>
  <p>在提到战略整合的时候，李书福说，有些项目要关停并转。在战略整合的解读中，吉利明确要坚定不移地推进内部资源深度整合和高效融合，进一步明晰各品牌定位，理顺股权关系，减少利益冲突和重复投资，提高资源利用效率。回顾吉利上一轮的战略，主要是通过推动体系内优质资产在资本市场实现自我造血，而非依靠集团支持。这恰恰也是过去十年间，汽车业内企业家的目标和共识。</p>
  <p>一位自主品牌汽车头部公司负责人就曾对《财经》直言，集团体系内的技术公司，只有脱离平台走出去做外供，能够独立做上市，这才是真厉害。如今，全球融资环境有了新变化，汽车业的竞争仍在白热化，有些公司即便上市，依然得依靠着母公司的输血和支持。正像一位吉利系的品牌负责人对《财经》所说的那样，“上市可不是万事大吉，车得继续造，而且成为公众公司后，变得更透明，关注的人更多，要投入的精力也越大。上市还是不上市，得权衡。”如今的吉利手握数十个品牌，业务横跨商用车、乘用车不同的产品类型。吉利不少业务团队都曾将上市作为核心目标。</p>
  <p><strong>如今，这一情况变了。吉利正试图聚焦造车的核心战略，重新梳理系统内的资源避免重复和浪费，更重要的是，正在试图通过其他方式，让各有前景的业务板块，除却独立上市后，也有能够实现获利受益的其他路径。对于一个体量如此大的公司来说，这绝非易事，但在如今白热化的竞争格局下，这是一件必须要做的事。</strong> 显然，李书福意识到了这一点。“依托良好的外部环境，过去几十年，吉利汽车在不断铺毯子。如今，要顺应大趋势，关停并转，聚焦资源，聚成拳头形成合力，围绕主业做好整合，提高竞争力。”今年9月《台州宣言》的发布上，他如是说。</p>
  <h2><strong>01&nbsp;&nbsp; 领克极氪的调整，是块必须先啃的硬骨头</strong></h2>
  <p>11月14日，吉利汽车控股有限公司（00175.HK）发布了三季报，报告期内，吉利汽车实现营业收入604亿元，同比增长20.5%，单季收入创历史新高；1月-9月，吉利汽车实现营业收入1677亿元，同比增长36%。“相比财报数据，我更关心的是吉利这一轮的大转型，看起来声势很大。”一位长期关注该公司的海外买家对《财经》直言，过去几年吉利新推的品牌太多了，但让人印象深刻，让市场买单的产品却相对有限。</p>
  <p>感觉很铺张，就是少了聚焦。同一日，收盘后不久，吉利控股集团（下称“吉利控股”）宣布优化极氪和领克的股权关系，以便减少关联交易、消除同业竞争。为此，吉利控股将向吉利汽车转让其所持有的11.3%极氪智能科技（NYSE：ZK）股份。交易完成后，吉利汽车对极氪持股比例增至约62.8%。同时，极氪将持有领克51%股份，领克其余49%股份继续由吉利汽车旗下全资子公司持有。回溯吉利早期建立子品牌的历史：吉利控股集团并购沃尔沃汽车后，领克品牌诞生，自那之后吉利控股集团、吉利汽车、沃尔沃汽车便共同持股。</p>
  <p>而极氪，最早可以追溯到2013年与CEVT联合开发CMA架构之时，领克原本已规划了新能源发展方向，但在造车新势力不断涌现的情况下，原本计划于2020年发布的领克ZERO作为首款电动车更名为极氪001。自此，极氪作为独立的子品牌诞生，新的商业模式下，三年内实现美股上市。在过去，极氪和领克被视为一对异卵双胞胎，曾经称为领克ZERO的极氪001自然采用了领克的家族式设计语言，在后期发展中，极氪的车标和设计理念也与领克有些趋同。2024年领克发布的领克z10甚至被称为领克版的“极氪001”，极氪在市场上与领克产生内耗。事实上，两者在高端市场定位和车型的布局上都有一定的相似性。</p>
  <p>领克汽车销售有限公司总经理林杰曾如此解释：领克品牌是全球的新能源高端品牌，极氪的定位是豪华科技品牌，所以定位不同。领克更多的是面向个性开放互联的都市人群，极氪是定位于忠于自我的、追求极致的、信仰美好的城市新中产，整个人群定位也有不同。但在部分消费者眼中，两者都属于吉利旗下的高端汽车品牌，目标客户群体存在一定的交集，尤其是那些对品质、性能和科技感有较高要求的消费者。</p>
  <p>在车型类别上，领克和极氪都有涉足轿车和SUV领域。比如领克有领克03这样的轿车以及领克01、05等SUV车型；极氪有极氪001这样的猎装车以及未来可能推出的更多SUV和轿车产品。今天的汽车消费市场，不是赢在大而全，而是赢在小而专。在商品极度丰富且同质化的当下，过去一款产品打天下的模式将不再适用，专业、细分化的道路才有可能有出路。越专注，才越有赢面。<strong>过去“多生孩子好打架”的思想或许已经不适合当下日趋白热化的竞争，与其让孩子独立，不如借助大体系下的资源优势让孩子们都尽量吃饱，减少业务冗余和资源浪费。</strong></p>
  <p>类似这样的做法，正在汽车业内流行。此前，东风乘用车公司，就重塑了体系，独立设立两家公司，一个负责采购生产、一个负责销售市场，另有三个面向不同细分市场三个品牌公司，做具体运营工作。此外，比如比亚迪、上汽旗下的飞凡和智己汽车的研发团队也传出整合消息，以提高综合竞争力为目的，推行以平台化、个性化为主的整合策略。对极氪、领克股权结构的优化，其股权关系更加清晰，减少了不必要的关联交易，也避免兄弟相争，资源得到了更有效的整合和利用。</p>
  <p><strong>在外界看来，领克和极氪吉利主品牌系统里的三大核心资产（另一个是银河汽车），梳理好彼此关系，有助于避免兄弟相争，也能节约资源提升业绩。在吉利系内部看来，这两个品牌都足够强，框架也大，两家公司梳理关系不容易，有极强的示范效应，是一块硬骨头，但值得花精力，这样可以在内部树立整合的典范。</strong></p>
  <h2><strong>02 &nbsp; 动作频频，吉利正在调转方向盘</strong></h2>
  <p>整个吉利正在朝着新方向变革。对极氪、领克的整合，是吉利落实《台州宣言》以来史上最大的一次产业整合，不仅仅是针对极氪和领克，更多的是把较多先前独立品牌的研发、销售，甚至单独准备IPO的部门全部回收缩减，进行产业的调整与优化。类似的调整不止这些，吉利旗下的高端纯电品牌几何正式并入吉利银河。此外，吉利整合研发资源，涉及几乎吉利旗下所有乘用车的研发业务。</p>
  <p>参与整合的对象包括吉利中央研究院和各子品牌背后的智驾、座舱、电子电气架构、电动力、整车平台等团队，以及后端的采购和供应链。过去，吉利不断衍生出愈来愈多的子品牌来抢占更多的细分市场，但随着新能源化的渗透、全球化的深入，多品牌战略也会导致研发体系和供应链效率的分散，在智能化市场的当下，会造成资源的浪费，不利于竞争。回望过去一段时间里，吉利系鼓励体系内子公司积极谋求登陆资本市场，通过上市实现自我造血。这也符合李书福一贯乐于管理层放权的管理习惯。一位熟悉他的人告诉《财经》，李书福不喜欢凡事儿都让他来做主，认为这不利于管理层成长。为此，他倾向于谁能独当一面，他就后退一步，尽量给管理层学习乃至试错的机会。</p>
  <p>然而，如今外部环境已发生变化，各子公司独立上市的机会正在减少。同时，上市并非运营企业的终点，同样成为公众公司后，还会受到各方面的严格监管，这也是一种别样的挑战。稍早前，在美股上市的极星汽车（PSNY.OQ）股价曾一度跌至0.61美元/股。还曾因为未能即时提交截至2023年12月31日财年的年度报告，乃至收到了纽约纳斯达克证券交易所的退市警告。</p>
  <p>11月13日报收于1.21美元/股。这是一家沃尔沃和吉利在2017年合资打造的全球高性能电动汽车品牌。伴随如上窗口期的变化，吉利系自然需要探索如何帮助体系内公司共享收益。如今来看，吉利汽车在港股的上市公司，正在扮演更重要的角色。<strong>“我最关心的吉利最近几年不断孵化上市公司，00175.HK会否仍是吉利系最核心上市资产，会不会被稀释，”一位券商汽车板块负责人向《财经》分享了他最常听到的疑惑。为此，《财经》曾向吉利汽车控股有限公司CEO桂生悦提问，他表示认为0175未来将是吉利汽车板块最主要的旗舰上市公司。</strong> 由此可见，吉利系新孵化造车公司密集上市的窗口期已过，吉利汽车上市公司体系是吉利汽车板块核心资产的主要承载主体。如今，不少品牌股权被整合进吉利汽车（00175.HK）的举措被业内视为是吉利汽车（00175.HK）资本市场的回归。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/1hFG-ZEKl8EY4ZLx3WcO5A" rel="noopener noreferrer nofollow" target="_blank">“财经汽车”</a>，作者：郑怡爽 李皙寅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036108563509513</id>
            <title>小游戏支持iOS内购，Meta给了苹果神助攻</title>
            <link>https://www.36kr.com/p/3036108563509513</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036108563509513</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 12:32:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果税, Instant Games, IAP, Meta  
<br><br>  
总结: 苹果税在欧盟地区的消失使得苹果的市场地位受到挑战，Meta选择在iOS端开放Instant Games的内购功能，以支持开发者并提升用户体验。Instant Games作为Facebook的小游戏平台，长期以来未能在iOS上实现内购，导致其变现渠道受限。随着市场竞争加剧，小游戏开发者面临收益波动和用户流失的困境。Meta的策略是通过与苹果合作，提供更高质量的小游戏，避免与苹果的直接对抗。 </div>
                        <hr>
                    
                    <p>在经过欧盟两年多时间的捶打后，苹果税不可避免的在欧盟地区已经成为了过去式，也使得苹果的围墙花园开始摇摇欲坠。对此苹果方面自然不会坐以待毙，除了在欧盟阳奉阴违之外，它还找来了新的盟友。近日Meta方面突然宣布，截至2024年9月16日，Facebook Instant Games在iOS端正式开放内购。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_f32ec043dd814b61bf9684905f538630@000000_oswg13997oswg600oswg250_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>作为Facebook在2018年3月推出的小游戏平台，Instant Games可以视为是微信小游戏的海外复刻版。得益于Facebook遍及全球的29亿月活用户，Instant Games也实现了低开高走，而小游戏即点即玩、无需下载的特质不仅在国内市场受到大量轻度玩家的青睐，在海外市场也一样。</p>
  <p>为什么说Instant Games支持iOS内购代表着Meta对于苹果的支持呢？这就要从Instant Games上线时的运营策略说起了。Instant Games是在2018年3月向所有开发者开放，并于当年5月开放内购作为变现渠道。其中在Android端，Instant Games接入了Google Play的应用内支付，而在iOS端则去掉了支付功能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_8db1197e84c84eddb0bcf9a521c8dc41@000000_oswg32675oswg600oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>事实上，Instant Games就与微信小游戏一样，长期以来都对iOS敬谢不敏。同时，Facebook为Instant Games的Android开发者最初设计了Google Play的30%抽成之外、再抽成30%的规则，也就意味着Android开发者只能拿到49%的分成。但不同于微信在国内市场的一家独大，Facebook在海外还有Snap这样的竞争对手，所以为了安抚开发者，Meta最终放弃了属于自己的30%抽成。</p>
  <p>没错，Instant Games的内购体系在过去6年以来并没有为Meta贡献任何收入。那么问题就来了，Meta这是在做慈善吗？答案自然是否定的，因为无论在国内、还是海外，小游戏在iOS端的变现渠道都被严格限制在了游戏内广告变现（IAA），也就是在游戏里给玩家弹广告，用户想要玩游戏就需要观看广告的模式。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b5e787a8667e42ca9afef89846856325@000000_oswg53391oswg600oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>可是广告多了体验自然就会变差，用户也会因此流失。所以广告变现效率难以提升、还需兼顾用户体验，就是IAA类型小游戏最大的难题，也直接导致了在经历了此前疫情时期的狂飙突进之后，小游戏在全球范围内遇到了瓶颈。随着市场竞争的日趋激烈，买量成本不断攀升，收益波动不稳也就成为了绝大多数小游戏开发者需要面对的难题。</p>
  <p>甚至就连被业内称为“小游戏之王”的开发商Voodoo，都提出了“IAA主导的超休闲品类已死”这样的说法。其实出现这一现象的原因很简单，因为以休闲娱乐为卖点的小游戏竞争对手并非《王者荣耀》、《原神》等手游，而是抖音、快手、TikTok等短视频平台。但同样都是消磨时间，短视频的效果显然更胜一筹。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_5d2bb339ef794aac9ed20a8f198592aa@000000_oswg29149oswg600oswg275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>所以在2024年，小游戏的潮流是IAA与IAP（应用内购买）混合变现，即游戏内的关卡和道具需要付费购买，用户可以选择直接付钱，也能通过观看广告来获取积分、再用积分去兑换道具。因为小游戏如果想要追求质量，几乎就只有重度化这一个选项，而重度游戏的体验又与广告矛盾。换而言之，IAP就给了优质小游戏诞生的可能。</p>
  <p>与此同时，今年年初苹果方面宣布小程序可以接入应用内购买系统（IPA），使得长期以来在iOS生态中名不正言不顺的小程序合规。所以现在的情况，是苹果对iOS小游戏开放了IAP，使得小游戏也可以做内购，顺势就让Instant Games的开发者可以直面高价值的iOS用户。不过对于Meta而言，开放Instant Games在iOS端的内购功能并无益处，因为其抽成规则与Android端相同，其中30%归App Store、开发者拿70%，他们自己则是分文不取。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_ce1cafdc6a8044feb560fbb243967283@000000_oswg56839oswg600oswg519_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>如此一来，Meta在Instant Games可以获得的收益就只限于广告收入，而过往的经验已经证明，IAP的出现必然会挤压IAA的规模，进而使得他们从小游戏上获得的广告收入下降。那么Meta为什么会选择“割肉饲鹰”呢？许多业内人士推测，极有可能是想避免今年9月苹果与微信“二选一”的局面在海外市场上演。</p>
  <p>两个月前，微信和苹果对于iOS小游戏的抽成问题产生了分歧，苹果直接要求微信去除小游戏开发者用于接受非苹果支付的链接，不允许将用户导入外部支付系统。紧接着有消息称，微信可能会不支持iPhone 16系列新机，并提醒用户不要更新系统。由此也让微信和苹果的分歧摆在了台面上，进而引发了所谓苹果和微信二选一的讨论。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_93f43955c14f434082e4bdea67f800a6@000000_oswg28914oswg600oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>但不同于微信，Meta旗下的Facebook目前在海外市场已经遇到了巨大的挑战，年轻用户群体大量流失到TikTok。所以此时联手苹果为用户提供更高质量的小游戏，这就是Meta为Facebook选择的策略。</p>
  <p>【本文图片来自网络】&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649875003&amp;idx=4&amp;sn=dd8c2ae05219d282937a769c3002d53a&amp;chksm=86cc69dbe986cee8d2d94ab93e51f2e3c0b0828c50d60dbd8730271b9013c714b7a55834a7a6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3035993118109699</id>
            <title>外媒：OpenAI 、Anthropic、谷歌新模型表现均不及预期</title>
            <link>https://www.36kr.com/p/3035993118109699</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3035993118109699</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 12:29:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AGI, OpenAI, Orion, 版权问题  
<br><br>  
总结: 文章讨论了在开发更先进的人工智能（AGI）过程中，OpenAI、谷歌和Anthropic等公司面临的挑战。OpenAI的Orion模型未能达到预期效果，尤其在处理新编程问题时表现不佳，导致其发布时间推迟。高质量数据的缺乏和构建新模型的高成本是主要障碍。此外，OpenAI在版权问题上也面临诉讼，尽管其在一场诉讼中胜诉。尽管获得了66亿美元的融资，OpenAI仍需在未来两年内转型为营利性公司。Sam Altman提到，构建AGI需要巨额投资和时间，但他又声称现有硬件足以实现AGI，这引发了质疑。 </div>
                        <hr>
                    
                    <blockquote>
   <p>五年内 AGI 还能否如期而至？</p>
  </blockquote>
  <p>谷歌、Anthropic、微软和 OpenAI 都是 AI 领域的顶尖玩家，但现在看来，这些公司在开发更先进的 AI 大模型时都遇到了不小的困难。</p>
  <p>OpenAI 曾接近一个重要的里程碑。 9 月，他们完成了一个全新 AI 大模型的首轮训练，希望能远超 ChatGPT 现有技术水平，朝着打造超越人类的 AI 这个目标更近一步。</p>
  <p>不过，彭博社援引 两位知情人士消息，这个内部代号「Orion」的模型并没达到预期效果。 比如，到了夏末的时候，Orion 在处理没见过的编程问题时表现还不够理想。</p>
  <p>总的来说，和 OpenAI 现有的模型比起来，Orion 的进步幅度远不如从 GPT-3.5 升级到 GPT-4 时那么大。 要知道 GPT-3.5 可是 ChatGPT 最早用的那个系统。</p>
  <p>一位消息人士告诉彭博社，这一挫折意味着 OpenAI 不太可能在明年年初之前向其用户推出 Orion。与此同时，据三位知情人士透露，谷歌的下一个 Gemini 迭代本应是一次重大升级，但其表现也低于内部预期。同样，期待已久的 Anthropic Claude 3.5 Opus 的发布也被推迟。生成式 AI 在训练中高度依赖于互联网数据。虽然它们在快速生成响应方面表现出色，但似乎已触及瓶颈，无法找到新的高质量内容源来开发更高级的 AI 系统。两位消息人士告诉彭博社，Orion 的编码性能不佳是由于缺乏足够的编码数据进行训练。出版商和作者则担心 AI 系统在未经同意或补偿的情况下抓取他们的内容进行训练。微软和 OpenAI 也正在应对多起版权侵权诉讼。OpenAI CEOSam Altman 承认，在没有版权内容的情况下开发类似 ChatGPT 的工具几乎是不可能的。他也指出，版权法并未明确禁止使用受版权保护的内容来训练 AI 模型。OpenAI 最近在一场版权侵权诉讼中胜诉。纽约联邦法官说得很明白：</p>
  <blockquote>
   <p>让我们搞清楚这里真正的问题是什么。原告（ Raw Story 和 AlterNet ）真正想要追究的，并不是说 OpenAI 删除了版权管理信息，而是 OpenAI 没给钱就用了他们的文章来训练 ChatGPT。</p>
  </blockquote>
  <p>高质量数据的缺乏并不是限制高级 AI 模型发展的唯一问题。构建和维护新模型的高成本也是一个重要障碍。据报道，在过去的几个月里，OpenAI 预计亏损 50 亿美元。然而，他们通过另一轮融资成功续命——从微软、英伟达和其他主要投资者那里筹集了 66 亿美元。</p>
  <p>虽然这轮融资让市值飙升到了 1570 亿美元，但市场分析师预测，这家公司还没渡过难关。由于和微软的数十亿美元合作关系等因素，在 2029 年开始盈利之前，OpenAI 可能还要面临 440 亿美元的亏损。</p>
  <p>通过最新一轮融资获得的延长生命值后，OpenAI 也面临两难：要么在未来两年内转型成为营利性公司，要么就得把投资者的钱退回去。这种情况可能会引来外部势力的干预和恶意收购，其中就包括微软可能在未来 3 年内收购 OpenAI 的可能性。</p>
  <p>值得一提的是，这已经是 OpenAI 第八次向投资者伸手要钱来支持其 AI 项目的开发了。OpenAI 这一动作已经遭遇了重大阻力，包括马斯克提起诉讼，指控公司背离了创立初衷，还涉嫌参与敲诈勒索活动。专家预测，这一转变还会遭到员工、监管机构和政府部门的强烈反对。</p>
  <p>至于 OpenAI 何时会发布 Orion 模型，目前还没有确切时间表。据彭博社消息，模型已经进入训练后期阶段，这表明离正式对外发布已经不远了。不过，尽管 OpenAI 投入了大量精力，这个 AI 模型的表现还是不如预期。</p>
  <p>因此，公司决定把发布时间推迟到明年初。此外，OpenAI 似乎打算改变传统的模型命名方式。因此，这个新模型可能不会用我们熟悉的命名方式。Sam Altman 曾表示，GPT-4 的继任者会「更智能」，运作方式更像一个「虚拟大脑」。</p>
  <p>他还确认公司今年晚些时候会发布一些重要产品，但强调「不会叫 GPT-5 」。总的说来，这些公司都在追逐通用人工智能（ AGI ）这个目标，但按照 Sam Altman 的估计，这可不是件容易事。他说，要建造 36 座半导体工厂和额外的数据中心，需要投入 7 万亿美元，还得花很多年时间。这番话一出，很多人觉得简直是天方夜谭，也让 Altman 被贴上了「键盘侠」的标签。</p>
  <p>有意思的是，尽管说需要这么多投入，Altman 却又声称用现有的硬件就能实现 AGI 。</p>
  <p>参考链接</p>
  <p>https://www.bloomberg.com/news/articles/2024-11-13/openai-google-and-anthropic-are-struggling-to-build-more-advanced-ai</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/HLdj-Z68Ja8656NrNr-BPQ" rel="noopener noreferrer nofollow" target="_blank">“机器之心”</a>，<strong>编辑：Sia</strong>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036116888695043</id>
            <title>AI斩获6枚金牌，华为Kaggle大师级智能体诞生，自主解决数据科学难题</title>
            <link>https://www.36kr.com/p/3036116888695043</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036116888695043</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 12:28:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Kaggle, Agent K v1.0, 数据科学, 自主智能体  
<br><br>  
总结: Agent K v1.0 是由华为诺亚方舟实验室和伦敦大学学院团队联合推出的自主数据科学智能体，已在 Kaggle 竞赛中获得显著成绩，包括 6 枚金牌、3 枚银牌和 7 枚铜牌。该智能体具备动态、多步骤处理复杂问题的能力，能够自动化数据科学流程并优化决策。其创新之处在于引入了结构化推理和长期记忆机制，避免了对传统反向传播和微调的依赖。Agent K v1.0 通过与环境的互动，动态调整推理过程，实现高效学习与适应。尽管取得了优异成绩，但仍存在任务设置反馈单一、工具扩展不足等问题，未来计划进一步优化和扩展其能力。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_60098e871f81494eafa5f9fbdc8c0a66@000000_oswg55207oswg1024oswg574_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>继 OpenAI o1 成为首个达到 Kaggle 特级大师的人工智能（AI）模型后， <strong>另一个 Kaggle 大师级 AI 也诞生了</strong> 。&nbsp;</p>
  <p>根据 Kaggle 的晋级系统， <strong>由华为诺亚方舟实验室和伦敦大学学院团队联合推出的端到端自主数据科学智能体（agent）——Agent K v1.0</strong> ，已经能够获得 6 枚金牌、3 枚银牌和 7 枚铜牌。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_e7d25871a00f46438817e06b12009912@000000_oswg39351oswg946oswg363_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文链接：https://arxiv.org/abs/2411.03562&nbsp;</p>
  <p>据介绍， <strong>Agent K v1.0 具备动态、多步骤处理复杂问题的能力</strong> ，通过动态管理记忆并从经验中持续学习，能够完全自动化数据科学流程，并在不依赖微调的情况下，通过环境反馈不断优化决策， <strong>实现对各种数据科学任务的自动化、优化和泛化。</strong></p>
  <h2><strong>Agent K v1.0：一个自主数据科学智能体</strong></h2>
  <p>当前，虽然 LLM 在自然语言交互方面展现优秀性能，但 <strong>如何使 LLM 能够基于智能体处理具有序列或并行任务模块的系统性数据科学任务，构建能对各种数据科学任务进行自动化、优化和泛化的LLM 智能体</strong> ，从而实现动态、多步骤的问题解决仍然是个挑战。&nbsp;</p>
  <p>为解决这个问题， <strong>研究团队提出了一个灵活的基于经验学习推理的替代框架</strong> ，借鉴了强化学习中的马尔可夫决策过程（MDP）概念，不过其独特性在于引入了结构化推理和长期记忆机制。这一创新举措避免了传统思维链或思维图方法对反向传播和微调的依赖，使得智能体能够在不更改 LLM 核心参数的情况下，实现动态学习与适应。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_c1411fa367ad44a78466a02e55596006@000000_oswg189902oswg1012oswg664_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜结构化推理的示意图与标准的思维链（CoT）方法形成对比。&nbsp;</p>
  <p>在 Agent K v1.0 的框架体系中， <strong>智能体具备三种类型的动作，分别为长期记忆动作、内部动作以及外部动作</strong> 。长期记忆动作用于对外部数据库的内容进行管理，将过往经验转化为指导当下决策的珍贵信息；内部动作则旨在更新工作记忆，塑造智能体的推理过程；外部动作直接与环境进行交互，执行任务并获取奖励。&nbsp;</p>
  <p><strong>智能体通过与环境的互动，收集状态、工作记忆以及外部数据库的轨迹信息。</strong> 随后，利用 LLM 的内部策略来更新工作记忆和长期记忆。这些策略能够依据环境反馈，动态调整智能体的推理过程，使其可以根据具体情况做出最优决策，从而最大限度地实现回报。&nbsp;</p>
  <p>总体而言，Agent K v1.0 的学习框架凭借结构化推理和长期记忆机制，达成了 LLM 在复杂数据科学任务中的高效学习与适应，为构建自动化、高效且可扩展的数据科学智能体开辟了崭新的途径。&nbsp;</p>
  <p>此外， <strong>Agent K v1.0 具有全新的自动化数据科学任务处理方式。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_9b23c345b2584224b4f92ef372a22cf8@000000_oswg100802oswg988oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜Agent K v1.0 自动设计、编码和执行的整体数据科学流程。&nbsp;</p>
  <p>首先， <strong>在数据科学任务设置的自动化阶段，Agent K v1.0 能够将数据科学任务精细分解为多个阶段</strong> ，如数据抓取、数据摘要、模态检测、数据预处理以及特征工程等。&nbsp;</p>
  <p>同时，利用单元测试对每个阶段的正确性进行严格验证。而当单元测试失败时，Agent K v1.0 会利用 LLM 生成解释错误原因的思考，并依据这些思考重新执行之前步骤，直至找到并修复错误。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_0daa4c23bb624b00b35b0acb5e882aba@000000_oswg219687oswg1016oswg643_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜自动设置阶段的主要步骤。&nbsp;</p>
  <p>之后， <strong>在数据科学任务解决的优化阶段，Agent K v1.0 根据任务所涉及的模态类型，选择不同的工具和方法生成解决方案</strong> 。对于表格数据任务，它使用 AutoML 工具自动生成预测；对于计算机视觉、自然语言处理和跨模态任务，则采用深度神经网络模型。此外，它还集成了多种工具，如 HEBO 进行超参数优化，以及利用 HuggingFace 的 Torchvision 和 Torchtext 库处理不同模态的数据。&nbsp;</p>
  <p>不仅如此， <strong>Agent K v1.0 在多任务和持续学习方面也表现出色</strong> 。它可以处理多个不同领域的数据科学任务，通过共享长期记忆实现知识迁移。同时，它会根据之前的经验选择下一个任务，构建难度逐渐增加的课程，以实现持续学习和知识积累。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b7b1f41f4e114483a2778e90bd79e3dd@000000_oswg329233oswg928oswg744_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜Agent K v1.0 作为一个多模态、持续学习的数据科学智能体，能够在多轮操作中进行任务。&nbsp;</p>
  <p><strong>为了客观评估 Agent K v1.0 的性能，研究团队构建了一个基于 Kaggle 竞赛的竞争性数据科学基准。</strong> 该基准涵盖了 Kaggle 平台上多达 65 个多样化的数据科学任务，涵盖表格数据、计算机视觉、自然语言处理以及跨模态任务等多个领域。&nbsp;</p>
  <p>此外， <strong>该基准还评估了 Agent K v1.0 自动设置数据科学任务的能力</strong> ，涵盖数据抓取、数据预处理、特征工程和模型训练等步骤。并通过单元测试来验证每个阶段的正确性，并评估智能体在不同模态和任务类型上的自动化成功率。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_e394c4ab00974a40aaf0d2e3ff8979eb@000000_oswg142319oswg904oswg543_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜基准测试中 Kaggle 任务的分布饼图。&nbsp;</p>
  <p><strong>在性能评估方面，该基准使用 Kaggle 平台的公开和私有分数来评估 Agent K v1.0 的性能。</strong> 根据 Kaggle 的排名系统，将智能体的表现与其他 Kaggle 用户进行比较，并计算其 Elo-MMR 积分，以评估其在 Kaggle 用户群体中的相对位置。&nbsp;</p>
  <p>为确保公平比较，该基准考虑了竞赛规模，不同竞赛的参与者和提交数量可能不同，因此需使用 Elo-MMR 积分来进行比较；以及竞赛类型，社区竞赛、练习场竞赛和特色竞赛的难度和竞争程度不同，因此需使用 Kaggle 的排名系统来进行评估。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_347c6f39177546db92d122e12d05cf64@000000_oswg83508oswg880oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜该表格描述了Kaggle的晋升系统，遵循Kaggle的指南和风格。&nbsp;</p>
  <h2><strong>Kaggle 大师级水平 AI 智能体</strong></h2>
  <p><strong>研究团队还在 65 个 Kaggle 竞赛中对 Agent K v1.0 进行了测试</strong> 。这些比赛可以由智能体自主设置，并且可以生成至少一个提交。与之前的工作不同，测试遵循了标准的 Kaggle 竞赛指南，其中智能体创建一个提交文件，并使用 Kaggle API 自动提交其解决方案。&nbsp;</p>
  <p>智能体的解决方案在提交后被评估和排名在排行榜上，其性能将与参与者进行量化比较。为了确保公平性，这些量化指标基于可用的私人排行榜，并且仅使用公共排行榜结果来决定保留的提交，这反映了据科学家在 Kaggle 平台上的标准做法。&nbsp;</p>
  <p>为了提高其性能， <strong>Agent K 使用基于内部训练数据拆分的验证损失</strong> 。该损失和智能体内存中已有的代码帮助 LLM 反思并生成更成功的代码，最终提高其排名。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_59d02e9830184d428936bdcd436c71d4@000000_oswg488738oswg1080oswg1431_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜展示了 Agent Kv1.0 在各类比赛中的表现，涵盖了表格、计算机视觉、自然语言处理和多模态任务。y 轴为比赛的 ID；x 轴为根据 Kaggle 的私人排行榜衡量出的分位数表现，分位数越高，智能体表现越好。&nbsp;</p>
  <p><strong>根据 Kaggle 的评估方法，Agent K v1.0 获得了相当于 6 枚金牌、3 枚银牌和 7 枚铜牌的成绩。</strong> 整体表现与 Kaggle 高级用户相当，甚至超过了部分顶级 Grandmaster 用户的水平。在 22 个任务中，Agent K v1.0 取得了超过 80% 的量化指标，在 62% 的竞赛中取得了超过 50% 的量化指标。&nbsp;</p>
  <h2><strong>不足与展望</strong></h2>
  <p>虽然 Agent K v1.0 在 Kaggle 数据科学竞赛中取得了令人瞩目的成绩，达到了 Kaggle 大师级水平，但其仍然存在一些不足之处。&nbsp;</p>
  <p><strong>第一，任务设置过程反馈单一</strong> 。目前 Agent K v1.0 在设置任务时仅基于单元测试和元单元测试的反馈。未来将通过进一步引入反馈机制，识别哪些代码和数据预处理步骤能有效提升模型性能，从而优化任务设置的智能性。&nbsp;</p>
  <p><strong>第二，工具扩展与性能反馈机制依托工具简单</strong> 。当前 Agent K 使用了一些现有工具（如 HEBO、RAMP 等）进行超参数优化和特征工程。未来计划引入更多工具，特别是能支持视频和音频处理的新模块，并研究更加有效的基于性能反馈的结构来优化 LLMs 的使用。&nbsp;</p>
  <p><strong>第三，目前的持续学习机制主要基于任务设置优化</strong> ，后续计划将性能反馈融入任务选择的决策中，使 Agent K 能根据历史经验来评估任务难度及潜在表现，更好地利用知识积累来提升任务处理能力。&nbsp;</p>
  <p>未来， <strong>研究团队计划进一步扩展现有的评估基准</strong> ，不仅增加处理任务的数量，还将多模态挑战如音频和视频数据纳入其中，力求覆盖更广泛的真实场景，以提升系统的多样性和实用性。研究还将使 Agent K v1.0 更适应“可运行的notebook”竞赛要求，提升其在多种竞赛环境中的灵活性和适应性，并计划参与实时竞赛来更精准地验证系统的实际竞争力。&nbsp;</p>
  <p>通过这些优化，Agent K v1.0 有望在多种任务和领域中进一步提升其自主数据科学能力，逐步向真正的 Kaggle 大师级目标迈进。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247593628&amp;idx=1&amp;sn=a6b670bdfcce018a594bcff7a97ffaa6&amp;chksm=ce699ce214c0cb04ff6a2647abfa2fb0d117484009d9623926ecde0ef0d0c3cb73a4ca0c7146&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“学术头条”（ID：SciTouTiao）</a>，作者：阮文韵，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036154480291844</id>
            <title>京东第三季度营收2604亿元，经调净利润132亿元</title>
            <link>https://www.36kr.com/p/3036154480291844</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036154480291844</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 12:13:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 京东, 第三季度, 净利润, 营收  
<br><br>  
总结: 京东在2024年第三季度的净营收为2604亿元，同比增长5.1%，归属于普通股股东的净利润为117亿元，同比增长47.8%。零售营收为2249.86亿元，物流营收为443.96亿元，净产品营收同比增长4.8%。净服务收入为557.74亿元，同比增长6.5%。运营利润为120亿元，运营利润率为4.6%。截至2024年9月30日，京东持有的现金及短期投资总额为1968亿元。公司在此期间回购了3100万股A类普通股，回购计划总额达到50亿美元。 </div>
                        <hr>
                    
                    <p>北京时间11月14日下午消息，京东（Nasdaq：JD；HKEX： 9618）今日发布了截至9月30日的2024年第三季度报：净营收为2604亿元，同比增长5.1%。归属于普通股股东的净利润为117亿元，同比增长47.8%。不按美国通用会计准则，归属于普通股股东的净利润为132亿元，同比增长23.9%。</p>
  <p>第三季度，京东零售营收为2249.86亿元（约合320.60亿美元），而2023年同期为2120.59亿元。京东物流营收为443.96亿元（约合63.26亿美元），而2023年同期为416.63亿元。新业务营收为49.70亿元（约合7.08亿美元）。而2023年同期为66.85亿元。分部间抵销139.65亿元（约合19.89亿美元），而2023年同期为127.09亿元。</p>
  <p>第三季度，京东净产品营收2046.13亿元（约合291.57亿美元），同比增长4.8%。其中，电子产品及家用电器商品营收为1225.60亿元（约合174.65亿美元），与2023年同期的1193.16亿元相比增长2.7%。日用百货商品营收为820.53亿元（约合116.92亿美元），与2023年同期的759.88亿元相比增长8.0%。</p>
  <p>第三季度，京东净服务收入557.74亿元（约合79.48亿美元），与上年同期的523.94亿元相比增长6.5%。</p>
  <h2><strong>第三季度业绩：</strong></h2>
  <p><strong>净营收</strong></p>
  <p>净营收为2604亿元（约合371美元），与上年同期的2477亿元相比增长5.1%。其中，净产品营收同比增长4.8%，净服务收入同比增长6.5%。</p>
  <p><strong>营收成本</strong></p>
  <p>营收成本为2153亿元（约合307亿美元），与2023年同期的2089亿元相比增长3.1%。</p>
  <p><strong>履约开支</strong></p>
  <p>履开支为163亿元（约合23亿美元），与2023年同期的152亿元相比增长6.9%。</p>
  <p><strong>营销开支</strong></p>
  <p>营销开支为100亿元（约合14亿美元），与2023年同期的80亿元相比增长25.7%。</p>
  <p><strong>研发开支</strong></p>
  <p>研发开支为44亿元（约合6亿美元），与2023年同期的38亿元相比增长15.9%。</p>
  <p><strong>总务与行政开支</strong></p>
  <p>总务与行政开支为23亿元（约合3亿美元），与2023年同期的25亿元相比下滑6.0%。</p>
  <p><strong>运营利润</strong></p>
  <p>运营利润为120亿元（约合17亿美元），与2023年同期的运营利润93亿元相比增长29.5%。运营利润率为4.6%，而2023年同期为3.8%。</p>
  <p>不按美国通用会计准则（Non-GAAP），运营利润为131亿元（约合19亿美元），与2023年同期的运营利润111亿元相比增长17.9%。运营利润率为5.0%，而2023年同期为4.5%。京东零售（不含未分配項目）运营利润率为5.2%，同比基本持平。</p>
  <p>不按美国通用会计准则，EBITDA（息税折旧及摊销前利润）为151亿元（约合21亿美元），与2023年同期的129亿元相比增长17.0%。</p>
  <p><strong>净利润</strong></p>
  <p>归属于普通股股东的净利润为117亿元（约合17亿美元），与2023年同期的净利润79亿元相比增长47.8%。净利润率为4.5%，而2023年同期为3.2%。</p>
  <p>不按美国通用会计准则（Non-GAAP），归属于普通股股东的净利润为132亿元（约合19亿美元），与2023年同期的净利润106亿元相比增长23.9%。净利润率为5.1%，而2023年同期为4.3%。</p>
  <p>每股美国存托股（ADS）摊薄收益7.73元（约合1.10美元），与2023年同期的每股ADS摊薄收益5.00元相比增长54.6%。</p>
  <p>不按美国通用会计准则，每股ADS摊薄收益为8.68元（约合1.24美元），与2023年同期的每股ADS摊薄收益6.70元相比增长29.5%。</p>
  <p><strong>现金流</strong></p>
  <p>截至2024年9月30日，京东持有的现金、现金等价物、受限现金和短期投资总额为1968亿元（约合280亿美元），而截至2023年12月31日为1977亿元。</p>
  <p>第三季度，用于运营活动的净现金为62亿元（约合9亿美元），用于投资活动的净现金为217亿元（约合31亿美元），用于融资活动的净现金为18亿元（约合3亿美元）。</p>
  <p><strong>股票回购</strong></p>
  <p>在截至2024年9月30日的三个月内，京东共回购了约3100万股A类普通股（相当于1550万股ADS），总计约3.90亿美元。在截至2024年9月30日的九个月内，京东共回购了约2.553亿股A类普通股（相当于1.276亿ADS），总价值约为36亿美元。</p>
  <p>截至2024年9月30日的三个月内，京东回购的普通股总数约占公司已发行普通股（截至2024年6月30日）的1.1%。在截至2024年9月30日的九个月内，京东回购的股份总数约占已发行普通股（截至2023年12月31日）的8.1%。</p>
  <p>京东已充分利用2024年3月宣布的30亿美元股票回购计划授权的回购金额，并于2024年8月通过并宣布了一项新的股票回购计划。根据2024年9月生效的新股回购计划，京东可在截至2027年8月底的未来36个月内回购价值高达50亿美元的股票（包括ADS）。</p>
  <p class="editor-note">本文来自<a href="https://finance.sina.com.cn/tech/2024-11-14/doc-incvzmwq1264651.shtml" rel="noopener noreferrer nofollow" target="_blank">“新浪科技”</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036163158110464</id>
            <title>坐拥13.82亿月活账户，微信扛起腾讯未来增长？</title>
            <link>https://www.36kr.com/p/3036163158110464</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036163158110464</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 12:11:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 腾讯, 业绩增长, 微信小店, 营销服务  
<br><br>  
总结: 腾讯控股在2023年第三季度实现收入1671.93亿元，同比增长8%，权益持有人应占盈利532.3亿元，同比增长47%。收入主要来源于增值服务、营销服务、金融科技及企业服务，其中增值服务和营销服务表现突出。微信及WeChat的月活跃账户数达到13.82亿，视频号的广告收入同比增长超过60%。微信小店的升级旨在提升电商生态的流转效率，助力商家更好地触达客户。尽管微信的商业生态逐渐完善，但仍需时间来支撑腾讯的整体收入增长。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_94f46e4e7b954a7fadf184f0ca9eb5ee@46958_oswg58221oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Pixabay</p>
  <p>11月13日，腾讯控股（0700.HK）发布了截至2024年9月30日止第三季未经审核综合业绩。</p>
  <p>今年第三季度，腾讯收入1671.93亿元，同比增长8%；公司权益持有人应占盈利532.3亿元，同比增长47%。在整个前三季度，腾讯收入4878.11亿元，同比增长7%；公司权益持有人应占盈利1427.49亿元，同比增长62%。</p>
  <p>回看2022年，腾讯陷入增长低谷，其收入、公司权益持有人应占盈利分别同比下降1%、16%。2023年，腾讯的收入回归增长，但利润仍在下滑——收入同比增长10%，公司权益持有人应占盈利下降39%。</p>
  <p>如今的腾讯似乎走出了“阴影”？</p>
  <h2><strong>01 业绩增长&nbsp;</strong></h2>
  <p>从收入结构来看，腾讯收入主要分为增值服务、营销服务、金融科技及企业服务、其他四类，在第三季度，它们分别贡献了49%、16%、34%、1%的收入。这一季度，腾讯将网络广告改名为营销服务，其表示，是为了更好地体现线上营销平台提供的广泛营销解决方案及配套技术服务。</p>
  <p><strong>具体而言，腾讯的增值服务主要由游戏、社交网络构成，其第三季收入827亿元，同比增长9%。</strong></p>
  <p>游戏方面，国际市场游戏收入145亿元，同比增长9%，主要是由于包括《PUBG MOBILE》及《荒野乱斗》在内的游戏表现强劲。本土市场游戏收入373亿元，同比增长14%，主要是《无畏契约》《王者荣耀》《和平精英》及《地下城与勇士：起源》在内的游戏驱动。社交网络收入309亿元，同比增长4%，主要是手游虚拟道具销售、音乐付费会员收入及小游戏平台服务费的增长。</p>
  <p>营销服务业务收入300亿元，同比增长17%。得益于广告主对视频号、小程序及微信搜一搜广告库存的强劲需求，以及巴黎奥运会相关品牌广告额度的较小幅度贡献。</p>
  <p><strong>金融科技及企业服务收入531亿元，同比增长2%。</strong>收入总体较去年同期基本保持稳定，其中理财服务收入因用户规模扩大及客户资产保有量增长而同比增长，而支付服务收入因消费支出疲软而有所下降。</p>
  <p>在费用方面，销售及市场推广开支在第三季度同比增长19%至94亿元，腾讯表示主要是为了支持本土市场及国际市场新游戏而加大推广力度。一般及行政开支同比增长11%至291亿元，主要由于研发开支及雇员成本增加。</p>
  <p>在业绩说明会上，腾讯也披露了更详细的信息。第三季度研发费用179亿元，同比增长9%，主要受包括人工智能在内的战略领域的投资驱动。研发费用以外的管理费用112亿元，同比增长14%，主要原因是包括某些海外子公司基于绩效的奖励相关成本在内的人力成本增加。</p>
  <p><strong>而在今年第一、第二季度，腾讯的销售及市场推广开支的同比增速分别为7%、10%；一般及行政开支的同比增速分别为1%、8%。相比而言，第三季度腾讯的投入明显增加。</strong></p>
  <p>有观点认为，销售费用、研发费用的增加，都传递出腾讯可能会开启新一轮的扩张。</p>
  <h2><strong>02 微信更能赚钱了</strong></h2>
  <p>截至今年9月30日，微信及WeChat的合并月活跃账户数为13.82亿，同比增长3%。在过去很长一段时间里，腾讯都在加速打造微信的商业化生态，其中重点便是视频号。</p>
  <p>在今年第三季度的业绩说明会上，腾讯表示，在第三季度适度增加了视频号的广告负载，促成了视频号营销服务收入同比增长超过60%。</p>
  <p><strong>不过在此次三季度报中，视频号的笔墨变少，出现了微信小店这一新的身影。腾讯表示，围绕微信小店升级了交易平台策略，以依托于整个微信生态打造统一且可信赖的交易体验。微信小店利用微信的社交互动、内容平台和支付能力，助力商家有效触达客户并推动销售转化。</strong></p>
  <p>资料显示，2022年7月，微信视频号推出视频号小店，成为商家和达人在视频号上添加商品到橱窗的主要途径。今年8月，视频号小店正式升级为微信小店，并扩展多渠道卖货、小程序跳转、搜索发现三个能力，并推行微信小店0元保证金试运营的管理规则，大幅降低达人、商家的入驻门槛。</p>
  <p>有媒体报道，<strong>视频号小店升级为微信小店主要为提升微信小店在微信多场景内流转效率。</strong>原本视频号小店只支持商家在视频号场景内开店经营，升级成微信小店后可支持店铺及商品信息在公众号（订阅号、服务号）、视频号（直播、短视频）、小程序、搜一搜等多个微信场景生态联动。</p>
  <p>在今年第二季度业绩说明会上，腾讯总裁刘炽平就表示，希望在微信内部建立电商生态，连接微信的所有元素，除视频号和直播渠道外，还包括公众号、小程序、企业微信等。他提到，希望以非常耐心但系统的方式建立一个生态系统，与仅有直播的电商区分开来，建立更大、更有意义、天花板更高的电商生态系统。</p>
  <p>由视频号小店升级而来的微信小店，便是微信电商生态的重要一环。而最近一年，视频号都在不断加大电商的投入。今年4月，视频号实施“蝴蝶计划”，通过激励吸引更多商家、达人和品牌入驻视频号。</p>
  <p>此后，有关视频号的组织调整也频频出现。今年5月，视频号电商团队并入到微信开放平台团队，原微信视频号直播电商团队转由微信开放平台负责人负责。</p>
  <p>7 月有消息称，腾讯CDG（企业发展事业群）对旗下 AMS（广告营销服务）部分职能进行整改优化，主要涉及从事带货运营和商业治理工作的团队。调整后，相关团队将不再从事视频号带货运营和治理工作，而是移交给微信事业部。</p>
  <p><strong>在一系列调整下，视频号的电商业务也能进一步的融入微信生态中。</strong></p>
  <p>而微信的其他业务也有不少亮点。腾讯表示，在今年第三季度，小程序的交易额超过2万亿元，同比增长十几个百分点，得益于在点餐、电动车充电及医疗服务等应用场景中有更好的覆盖与更优的解决方案。同时，微信搜一搜在商业化检索量与点击率均实现了同比增长。</p>
  <p>可见，微信的商业生态已逐渐完善，对腾讯未来的发展也有着更大的作用。但微信要撑起腾讯的收入增长，仍需要一定的时间。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/-7Epvok8Oplt3LJ5D8wRXw" rel="noopener noreferrer nofollow" target="_blank">“征探财经”</a>，作者：五仁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036163193008130</id>
            <title>谁说小屏没人要？小屏旗舰才是2024年手机市场的最大黑马</title>
            <link>https://www.36kr.com/p/3036163193008130</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036163193008130</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 12:06:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小屏旗舰, 电池技术, 影像技术, 性能提升  
<br><br>  
总结: 今年小屏旗舰手机迎来了复苏，多个安卓品牌如小米、OPPO和vivo推出了小尺寸旗舰机型，强调小屏也能提供高端体验。小屏手机的续航问题通过新型硅碳负极电池得以解决，电池容量显著提升。最新的旗舰Soc在能耗比方面的进步，使得小屏手机在性能上也不逊色于大屏手机。影像技术的进步使得小屏旗舰在拍照表现上也达到了新的高度。尽管小屏手机在某些方面仍有不足，但其轻薄设计和优质体验吸引了越来越多的消费者。 </div>
                        <hr>
                    
                    <p>今年绝对属于小屏党的狂欢时代，除了一直坚守小屏的苹果，几大安卓品牌也纷纷推出了小尺寸旗舰，如小米15，OPPO Find X8和vivo X200 Pro mini等，各家致力打造尺寸更小，但旗舰体验仍然在线的“小屏旗舰”。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_a6684dfc49d74b42a11cdfa7af516658@46958_oswg22875oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>小米15配备超声波指纹，引入先进的屏幕封装技术，大大缩窄边框宽度，并最终实现1.38毫米的超窄四等边。搭配850Wh/L的高能量密度电池，90W有线快充和50W无线快充随时为小米15的5400毫安时大电池回满电量。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_e1355a79e5004415801aa937d0af2d0e@46958_oswg33371oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>vivo X200 Pro mini带来了超乎想象的5700毫安时电池，续航能力一举超过众多大屏旗舰，并支持90W有线快充和30W无线快充。并且全面升级了影像，做到了“拍照比肩一英寸，视频超越一英寸”。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_702badce9eaa49e0bad28027ee6316ce@46958_oswg17025oswg700oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>OPPO Find X8更是带来新惊喜，轻薄的机身下藏着大底潜望长焦，将厚度压缩至7.85毫米，真正做到了即轻又薄，带来舒适好手感。5630毫安时超大容量电池让你尽情畅玩，配套80W超级闪充和50W无线闪充，还支持完整的磁吸生态。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_8f55e7750aa047debfe6974b6a2bfa77@46958_oswg36052oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>从消费端来看，这几款机型的首销成绩都出人意料的好，笔者身边也有不少朋友真金白银入手了，并且反馈都很积极。从这个角度来看，网友们调侃的“小屏旗舰没人要”论调好像不成立了。如果再深究一下，过去被称为“小屏旗舰”的机型卖不好，问题可能在于产品本身，而不是“小屏旗舰”这个市场定位。&nbsp;</p>
  <p>那么，为什么今年这一波小屏旗舰又可以了呢？&nbsp;</p>
  <h2><strong>·小屏旗舰的工程难题</strong></h2>
  <p>小屏旗舰的概念可以分为两大部分。一是“小屏”，二是“旗舰”。&nbsp;</p>
  <p>多小才算小屏呢？业内对此并没有一个明确的定义，有的是5.9英寸，有的是6.1英寸，有的6.3英寸也算小屏。如果我们以“成年人单手能轻松操作”作为小屏的定义，考虑到屏幕比例和机身设计的影响，那么6-6.5英寸差不多就是小屏旗舰的甜点区间了，今年的几款小屏旗舰屏幕尺寸也落在这个区间里。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_be605d4db6f74663b42a47dc7c415873@46958_oswg32529oswg700oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>旗舰的定义又是什么？Soc、屏幕、影像，首先这三大件要看齐高端主流水平，然后再是长续航、快充、无线充电、指纹解锁等关乎日常体验的外围配置。简而言之，大尺寸旗舰手机该有的，我小屏旗舰也要有。&nbsp;</p>
  <p>这个时候问题就来了，奥利奥式的镜头模组、大容量电池、旗舰Soc必备的散热结构……这些旗舰配置哪个不占空间？大屏旗舰要兼顾这些都已经够呛，小屏旗舰这是突破物理学定律了？&nbsp;</p>
  <h2><strong>·电池技术革新，解除续航难题</strong></h2>
  <p>对于曾经的小屏用户来说，捉襟见肘的续航一直是小屏党心里永远的“痛”。小屏手机续航能力极差，有时候甚至只能维持三四个小时的使用，因此需要随时充电。尺寸的缩小迫使小屏手机在电池容量上做出妥协，毕竟机身内部空间寸土寸金。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_64a17b3c11e6414c9453be8b481f4ca0@46958_oswg44165oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>削减电池容量的做法，直接导致小屏手机续航雪崩，显然，一台离不开充电器的手机，就像一个中看不中用的花瓶。毕竟天天带充电宝并不符合用户的使用习惯，小屏手机又怎么能受到用户青睐呢？因此，在很长一段时间，小屏手机一度被认为是“伪需求”。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_e52cd007a96348a685437220a3987080@46958_oswg97947oswg700oswg700_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>然而，小屏手机的窘况在今年迎来了一个巨大的转机。在手机电池方面，电池供应链提出了全新的硅碳负极电池概念，相对于一直使用的锂电池，电池能量密度更大且更加稳定。在电池体积不变甚至更小的情况下，做到了更大的电池容量。从此，制约小屏手机的枷锁被打开，迎来一个小屏旗舰时代。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_ed63947557ad414f9c1c54243e65eb32@46958_oswg33773oswg700oswg371_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>以vivo X200 Pro mini举例，采用硅碳负极电池后，电池容量达到惊人的5700毫安时，这一数字不仅超越了众多传统大屏旗舰手机的电池容量，更是在续航能力上树立了新的标杆。以超大的电池容量和快充技术，为用户提供了更为持久和安心的使用体验。&nbsp;</p>
  <h2><strong>·旗舰Soc能耗比跃进，散热无忧</strong></h2>
  <p>由于小屏手机内部空间紧凑，散热面积注定也有限，热量容易在机身内部堆积。一旦Soc出现严重发热，热量无法及时散去，手机就会出现严重的卡顿掉帧情况。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_0c45b5b85c974c3ba7b03ed684d308e1@46958_oswg33788oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>但最新的旗舰Soc打破了小屏手机的困局，在能耗比方面实现了极大的跨域，在同等性能下功耗更低。小屏手机也因芯片能耗比的提升而获益，给用户带来丝滑不卡顿的顶级体验，为“小屏旗舰”的出现打下了基础。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_77695c99d4cb456ebea185dc7b5eaa2b@46958_oswg154783oswg700oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>天玑9400采用了台积电3nm制程工艺，在多任务处理和高性能场景中，天玑9400表现出色，尤其在多核性能上表现强劲，在游戏和日常使用中的体验有着显著提升。骁龙8至尊版引入了高通自研的Oryon CPU架构，同样采用了台积电3nm制程工艺，功耗控制极其出色，性能对比前代上升一个档次。&nbsp;</p>
  <p>由于Soc性能密度提高，芯片的功耗和能效比得到进一步优化，小屏旗舰也能成为游戏旗舰。在同样出色的游戏表现下，小屏手机凭借其更易掌握的尺寸，游戏体验甚至比大屏手机更好，实现精准的操作，做到指哪打哪。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_921b26a3ea3f49e883e366f679697991@46958_oswg39364oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>由于芯片性能和能效的提升，小屏手机性能释放更稳定，在日常使用中也更加省电和流畅。毕竟旗舰体验既离不开软件层面的持续进步，也不能缺少好芯片加持。&nbsp;</p>
  <h2><strong>·计算摄影发力，突破光学桎梏</strong></h2>
  <p>影像是旗舰手机绕不开的话题，影像技术可以是去区分普通手机和旗舰手机的关键。手机影像也迎来了新的发展，超越了仅仅依赖硬件的时代，各家厂商开始重视为对硬件研发配套的算法。小屏手机通过厂商研发的配套算法来提升影像表现，软硬件结合为拍摄提供绝佳的美感与画质。&nbsp;</p>
  <p>硬件方面也做到了一个新高度，通过引进新工艺和新设计，小屏旗舰也能在轻薄的机身下，带来旗舰影像。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_26ef8e9519cb4842a659568ff41eb842@46958_oswg21322oswg700oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>例如，OPPO Find X8选择在潜望镜头的结构上做创新，用倒置潜望长焦，大幅缩小了镜头模组的体积，镜头模组变得轻薄。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_890ece485aac4635befebf28254a3d9e@46958_oswg35305oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>vivo X200 Pro mini采用蔡司超级长焦镜头，利用算法来弥补拍摄时出现的不足，做到拍摄远处的物体时不失清晰度。&nbsp;</p>
  <p>小屏旗舰以其独特的轻薄感打破了影像旗舰“非厚即凸”的刻板印象，告诉用户，其实旗舰影像也能做到又轻又薄。&nbsp;</p>
  <h2><strong>·全世界都爱小屏旗舰</strong></h2>
  <p>在全球市场上，小屏手机一直保持着创新度和市场吸引力。从高端旗舰到性价比之选，满足各种用户对小屏的追求。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_7b76617349d84a34ae7b457f393b96e6@46958_oswg41392oswg656oswg516_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>iPhone一直以来都有小屏的型号，从SE到标准版再到Pro版，都有不同的尺寸供大家选择。三星产品线从入门款到旗舰机型都有小屏手机的身影，综合竞争力领先其他厂商一头。Pixel 9 Pro更是集超声波指纹识别、潜望长焦和无线充电技术于一体，这豪华的硬件配置丝毫不逊色大屏。摩托罗拉、华硕等厂商也一直在积极推出小尺寸手机。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_a86eca2bbf7a4c67a2f5322bcdd6a982@46958_oswg44583oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>小屏旗舰在经过多轮迭代后，各项软硬件指标已上升到一个新高度，并通过各种优化来提高小屏使用感受。但受控于成本和厚度，小屏旗舰们在某些方面仍有遗憾，或存在潜望长焦缺失，无线充电减配、指纹识别降级等情况。并且小屏手机性能释放略低于大屏，虽然在日常使用中这种差异可能并不明显，但在高负载场景下可能会有所体现。&nbsp;</p>
  <h2><strong>·写在最后</strong></h2>
  <p>对比过往，技术一直不断进步，小屏市场也将迎来全面复苏。小屏带来了绝佳的手感和质感，做到轻薄，影像，性能全包揽。如果想要体验独特的小尺寸手机，那么相信小屏旗舰同样能给你带来大震撼。随着小屏旗舰体验继续完善，相信更多人会选择小屏，get到交互新体验。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_d9e522e8fc034740b0097eac0383afb9@46958_oswg33866oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>虽然科技的进步带来了丰富的娱乐和便利，但我们不应该让手机完全占据我们的生活。小屏手机在娱乐体验上或许略逊一筹，但它们让我们更容易“拿得起，放得下”，从而鼓励我们更加专注于现实世界和身边的人际关系。在数字时代，找到科技与生活的平衡，或许才是我们追求的智能生活方式。&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/GmZVYJCGGLldCu3nr9A8RQ" rel="noopener noreferrer nofollow" target="_blank">“PConline太平洋科技”</a>，作者：李贵锋，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036156890935561</id>
            <title>不走Transformer路线，彩云科技推出通用大模型云锦天章 | 最前线</title>
            <link>https://www.36kr.com/p/3036156890935561</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036156890935561</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 12:03:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <生成式AI, DCFormer, 彩云科技, 模型架构>
<br>
<br>
总结: 彩云科技开发了全新的DCFormer模型架构，并基于此推出了通用大模型云锦天章。该模型能够在虚构世界观基础上赋予小说人物编程和数学能力，并具备扩写、缩写和风格转换等功能。DCFormer架构通过改进注意力矩阵，提升了算力智能转化率，且可以与现有Transformer模型叠加，降低成本。彩云科技在商业化方面谨慎，关注投入产出比，目前已实现盈利，并计划进一步提升内容创作能力。 </div>
                        <hr>
                    
                    <p>文 | 王方玉</p>
  <p>编辑 | 苏建勋</p>
  <p>目前绝大多数生成式AI产品的底层技术都源于2017年谷歌提出的Transformer模型架构，而国内一家AI创业公司——彩云科技却独辟蹊径，开发出了全新的模型架构DCFormer，并基于此推出新产品。</p>
  <p>11月13日，彩云科技在北京总部发布了首款基于DCFormer架构开发的通用大模型云锦天章。</p>
  <p>据CEO袁行远介绍，云锦天章可以实现在虚构世界观的基础上，赋予小说人物编程、数学等基础能力，可以高速针对大量文字进行扩写、缩写，针对文章风格进行大容量更换，同时兼具其他模型的问答、数学、编程等基础能力。</p>
  <p>除了擅长的应用场景不同，云锦天章与常规大模型最大的差异还在于底层模型。据介绍，通过改进注意力矩阵，在相同训练数据下，DCFormer架构最高可以将算力智能转化率提升至Transformer的1.7到2倍。</p>
  <p>此外，DCFormer是在Transformer的基础上进行改进，能够和现有的模型叠加，而不是互斥，因此所有基于Transformer架构的大模型都能在DCFormer的基础上降低成本。</p>
  <p>彩云科技关于DCFormer架构成果的相关论文已于今年5月在第41届国际机器学习大会ICML 2024正式发表，该会议是国际机器学习领域的三大顶会之一。此外，DCFormer的模型代码、权重和训练数据集，也已经在Github全部开源。</p>
  <p>为何选择另辟蹊径采取DCFormer架构？袁行远告诉36氪，AI在运行过程中对能源的巨大需求已成为行业共识，改善模型底层架构以提高效率是应对这一挑战的最佳策略。模型效率的提升，也可以有效地降低人工智能升级迭代的成本，加速AI时代的到来。</p>
  <p>虽然DCFormer架构可以压缩大模型训练推理的成本，但彩云科技在商业化探索方面相对谨慎，关注投入产出比。</p>
  <p>目前彩云科技旗下有彩云天气、彩云小梦、彩云小译三款面向C端用户的AI产品，在全球市场获得了超过1000万美元的ARR（年度经常性收入），是国内为数不多能够实现盈利的人工智能公司。其最近一轮融资是由快手前CEO宿华个人投资的B2轮，投前估值达到1.2亿美元。</p>
  <p>袁行远告诉36氪，彩云科技对DCFormer架构的研究及应用开发，主要服务于自身业务。目前，基于全新DCFormer架构的彩云小梦V3.5，在保持逻辑通顺与描写细致的前提下单次可以创作几百字到一千字的内容，未来有望突破到2-5千字的创作，实现更强的智能水平和更高的用户活跃度目标。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036093650056071</id>
            <title>产品力下降还搞虚假宣传，苹果的“魔力”正被库克消磨殆尽？</title>
            <link>https://www.36kr.com/p/3036093650056071</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036093650056071</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 11:51:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <苹果, AirPods Pro, 集体诉讼, 产品质量>
<br>
<br>
总结: 三名苹果客户对苹果公司提起集体诉讼，指控其销售存在杂音问题的AirPods Pro耳机，违反消费者保护法并进行虚假广告。自2019年发布以来，用户反映耳机存在噼啪声等噪音问题，尽管苹果尝试通过软件更新解决，但问题依然存在。诉讼指出苹果未能告知消费者耳机缺陷，导致消费者在不知情的情况下购买。苹果还因虚假广告被指控，强调耳机的音质而隐瞒问题。此外，苹果在其他产品和系统的质量上也受到质疑，显示出其产品审核标准可能下降。 </div>
                        <hr>
                    
                    <p>日前，有外媒报道，三名苹果客户于本月对苹果公司提起集体诉讼，指控该公司继续销售存在杂音问题的AirPods Pro耳机，违反了美国加州消费者保护法并进行虚假广告宣传。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_848df814b9144fe9bdd1a749919668e6@813924438_oswg448492oswg1024oswg768_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其实，自2019年10月发布AirPods Pro时，就有用户开始抱怨其出现噼啪声、嘎嘎声、爆裂声和类似静电的噪声。当某些东西导致耳机移动或振动(例如行走或跑步)时，似乎就会出现杂音。</p>
  <p>面对用户的广泛投诉，虽然苹果已尝试通过软件更新的方式来解决这一问题，并在2020年10月特别推出了修复计划，但许多用户在更换新耳机后，仍然遭遇了相同的声音困扰，问题并未得到根本性解决。</p>
  <p>此次，AirPods Pro耳机被诉讼只是一个缩影，包括产品和系统的质量也被诟病下降，苹果到底怎么了?</p>
  <h2><strong>苹果产品又遭诉讼</strong></h2>
  <p>在这起诉讼中，消费者严厉指出，苹果在销售过程中未能充分、明确地告知消费者这一潜在的缺陷，导致他们在毫不知情的情况下购买了这款存在问题的产品。如果苹果能够提前、如实披露这一问题，消费者完全有可能作出更好选择，比如购买其他品牌的耳机，或者以更为优惠的价格购入AirPods Pro。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_4d1672795e4d479e82978c5985591a14@813924438_oswg340465oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>另外，苹果还被指控虚假广告，因为在明知存在噼啪声和静电问题的情况下，仍强调“卓越音质”和“纯净、极其清晰的声音”等功能。</p>
  <p>我们看到，在这起诉讼中已经上升到苹果的商业道德方面，因此，会引起更多的关注。</p>
  <p>其实，苹果面对的诉讼远不止这一件，今年9月份，苹果还因对非苹果音乐流媒体服务征收高额费用，遭到欧洲消费者权益组织Euroconsumer在比利时、意大利、西班牙和葡萄牙联合发起了一项集体诉讼。</p>
  <p>根据Euroconsumer的介绍显示，诉讼的核心问题在于苹果公司滥用其市场支配地位，在应用商店App Store中对包括Spotify、Deezer、YouTube Music、SoundCloud、Amazon Music、Tidal和Qobuz在内的非苹果音乐流媒体服务征收了高达30%的额外费用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_8cf295c5863a45958769a13fff55b307@813924438_oswg1046703oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这些额外的费用直接影响了这些服务提供商的收益，迫使他们提高订阅费用来弥补损失，这种涨价导致用户每月为其选择的流媒体服务多支付约3欧元(约合23.7元人民币)。</p>
  <p>该组织进一步声称，仅在欧洲地区，苹果公司通过这种方式从非Apple Music流媒体服务中获得了约2.59亿欧元(约合20.45亿元人民币)的“不正当利润”。</p>
  <p>这场诉讼目前还没有结果，但这样的事件频繁发生对于苹果的形象一定会有影响。</p>
  <p>科技旋涡认为，一家商业公司，尤其是像苹果公司这样的规模，受到一些诉讼或者争议是正常现象，只要有明确且正向的结果对于苹果公司的影响不会非常大，但我们要说的是，近年来，苹果公司推出的产品似乎在细节与质量上也出现了下滑现象，比如这次被诉讼的AirPods Pro，比如iOS系统的升级，比如在印度生产的iPhone，都让人感觉不那么“苹果”。</p>
  <h2><strong>苹果对产品的审核标准下降了?</strong></h2>
  <p>我们看到，在美国集体诉讼AirPods Pro这件事起因是虚假广告宣传，但本质则是AirPods Pro的产品品质出现问题，在此前，大家很难想象一个苹果推出的、如此昂贵的产品，会有这样或那样的问题。</p>
  <p>而且，这样的问题还不只出现在硬件产品上，在其引以为傲的iOS系统上也让用户很崩溃，部分iPhone 16系列用户在升级iOS 18系统后，遇到了手机耗电过快的问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b1a31a7005cc47b98b5a7919d08c1761@813924438_oswg350906oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>尽管大多数反馈来自iPhone 16系列用户，但部分旧款iPhone用户也在升级至iOS 18后报告了类似的续航问题。</p>
  <p>在社交媒体和苹果论坛上也充斥着用户的抱怨，表明这个问题影响了相当一部分用户群体。</p>
  <p>其中一位用户进行了详细对比实验，用相同的使用方式分别测试了iPhone 16 Pro和iPhone 14 Pro的电池续航表现。结果显示，当iPhone 16 Pro的电量降至58%时，iPhone 14 Pro仍有85%的电量。</p>
  <p>而且，近年来，苹果还主张在印度制造产品，但这样的结果确实造成产品力的下降。</p>
  <p>据英媒报道，从印度生产出来的苹果手机零部件中仅有约一半质量合格，这与苹果公司的“零缺陷”标准相差甚远。部分视频博主在社交媒体平台上传苹果手机拆解视频，揭示了印度组装的苹果手机存在的瑕疵，如主板上有明显指纹印迹、摄像头内部存在灰尘等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_fb7d9e47b99649fa971396b57de75fc0@813924438_oswg950252oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其实，造成这样结果的原因，不单单以苹果是一家商业公司来解释，一名前苹果员工曾在社交媒体上表示，质量下降因企业文化改变。</p>
  <p>库克掌管苹果多年来，公司的股价一直居高不下，这本是一件让苹果非常骄傲的事情，但事情都有双面性，一家公司太商业化就失去了一些创新和坚持。已经有太多人表示，苹果逐渐失去了乔布斯时代的“魔力”。早年间，iPhone之所以被用户捧上神坛，不仅仅是其极具特色的系统和设计，而且在全方面领先，如扎实的做工用料、过人的产品设计、优秀的用户体验，它是一个集合体，并不是为了一代一代地“应付”。</p>
  <h2><strong>写在最后</strong></h2>
  <p>一直以来，都会有无数果粉怀念苹果创始人乔布斯，不少人更是称乔布斯为艺术家，认为库克只是一位商人。不可否认，在库克的手中，苹果的营收、利润、市值都达到了历史巅峰，甚至领先全球，但苹果那“特殊”的“魔力”也在市值屡创新高的背后逐渐消失殆尽。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_0d6bf2667f5542cda0875e5e90abd77d@813924438_oswg345976oswg800oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>曾经手机行业霸主诺基亚给时代留下的最后一句话是“明明什么都没做错，但是不知道为什么，我们却输了。”而苹果似乎也没做错什么，时代会给他留下一个什么结局呢?</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/kyKo1VbuPRjxNitsPsGqVw" rel="noopener noreferrer nofollow" target="_blank">“科技旋涡”</a>，作者：贾桂鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036098183590153</id>
            <title>​清华刘嘉教授：大模型是一个生命新物种</title>
            <link>https://www.36kr.com/p/3036098183590153</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036098183590153</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 11:48:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <生成式AI, 知识密集型行业, 教育模式, 人机混合社会>
<br>
<br>
总结: 生成式AI正在推动技术、商业和社会的深刻变革，促使人类社会从信息社会向智能社会转型。大模型具备创造力，将首先影响知识密集型行业，导致这些行业的工作岗位面临挑战。教育模式也需转变为以个人兴趣为中心的通识教育，以适应未来的需求。情感陪伴的需求将促使人机混合社会的形成，未来人类与AI的关系将更加紧密，同时也需关注AI伦理和隐私问题。 </div>
                        <hr>
                    
                    <p>以生成式AI为代表的新技术浪潮日新月异，正带来一场深刻的技术、商业与社会变革，推动人类社会从信息社会向智能社会转变。全世界热切期待AI到来的同时，也非常关心人工智能将带来哪些新机遇、新挑战。</p>
  <p>为此，我们发起了一项<strong>《AI&amp;Society 百人百问》</strong>研讨，广泛邀请AI技术大咖、AI独角兽创始人、AI投资人，以及社会学家、心理学家、国际关系专家、科幻作家等，用多元视角，深入研讨人工智能技术引发的广泛影响，发掘AI时代的共识和非共识，共同推动人工智能始终朝着“助人发展，与人为善”的方向可持续发展。</p>
  <p>本期，我们非常荣幸邀请到<strong>清华大学基础科学讲席教授，清华大学心理与认知科学系主任刘嘉老师</strong>，为我们开启一趟AI的思想远航。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_65a1a1d451c84e5f8e88a7a44377df3f@000000_oswg47633oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>采访主持人：腾讯研究院高级研究员牛福莲，资深专家王强</p>
  <blockquote>
   <p><strong>精华要点：</strong></p>
   <p><strong>1.大模型无疑已经具备了创造力：</strong></p>
   <p>人类历史上就有生成式发明 generative Innovation，我们远古的人类正是通过去观察整个世界，把万事万物之间的关系找到，从而创造出新的事物来。到了大模型时代，它的attention（注意力） 机制，就是要在万事万物之间找到它们的关系，从而有了 generative content（生成式内容）。相比之前的NLP 等小模型，它已经不是一种机械的基于统计的这种重复，而是开始有它自己独立的思想，有它独立的推理，它一定会有创造力。</p>
   <p><strong>2.大模型会首先替代现在大家所认为的好工作：</strong></p>
   <p>它要取代或者影响最大的行业一定是知识密集型行业。那么什么是知识密集型行业呢？律师、医生、教师等我们所认为的白领或者金领的行业都是大模型会最先渗透进去，最先去颠覆的行业。所以将来最先要面临失业，或者面临再就业的人，不是那些依靠体力的职业，而是我们原来认为依靠脑力职业的那些人。当然，以大模型为代表的这种知识密集型服务的出现，必然也会带来很大的福利，也就是说我们的社会财富将会急剧增加。这就造成一个很大的冲突，一方面财富在极大增加，第二我们还不用干活了，那未来的社会将会是什么样子？</p>
   <p><strong>3.大模型时代需要全新的教育模式：</strong></p>
   <p>清华正在做转向，全面把之前的大类招生变成书院式教育。书院式教育是什么？就是不再分专业了，专业任选，就像清华的新雅书院一样，你进来之后，想学任何专业都可以，但第一年我们要搞通识教育，让你去探索自己，了解你的方方面面，然后再决定未来想成为一个什么样的人。我们一定要把原来的由第一次工业革命所带来的这种基于专业、面向“牛马”的教育模式，转变成以个人为中心，以个人的兴趣、个人生命目标为目的一种全新的教育方式。</p>
   <p><strong>4.大模型情感陪伴是人的刚需：</strong></p>
   <p>我们更容易把我们的情感投射到宠物上，宠物给我们带来的价值是什么呢？它不能帮你做家务活，还会消耗你很多食物，但它给你带来的是情绪价值。那么有没有比宠物更好，能够给你带来情绪价值的（东西）？那就是情感机器人或者情感大模型。但同时，大模型能在这么多方面无限地满足人类，会让人类变得越来越苛刻。我们听过一个说法“男不养猫，女不养狗”，为什么这句话是对的呢？道理非常非常简单，在你的眼中，狗就是你这个世界上的一部分。但是对于狗，在狗的眼睛里面人就是它世界的全部，所以狗对人无比的忠诚，你打它、骂它，它还是会围绕你的旁边。所以为什么女不养狗？在女的眼中，她养了狗之后，所有男的都是渣男。</p>
   <p><strong>5.大模型不会导致能源危机：</strong></p>
   <p>很多地方在强调能源危机，我觉得这是杞人忧天，为什么这么讲呢？在上世纪50年代，人类的第一台计算机ENIAC，它所需要的电能是整个费城电能的一半还要多，也就说开一次机，整个费城，就得关好多灯。但是它的算力还远远不如我现在手机的1/1000或者1/10000。你看，随着技术的进步，这种耗能一定会出现急剧下降的。这只是一个技术问题，所以将来大模型不会需要太多的能量，一个机器人将来的思维运作，可能一节小小的电池就足已。</p>
   <p><strong>6.AI可能会出现自我意识的觉醒：</strong></p>
   <p>我们除了要继续推动AI发展，还需要建立一套AI伦理学。我们甚至要放弃完全以人为中心的这种视角，而要站在一个更广的视角，去看未来的混合社会，它由三个社群组成，包括人的社群、人机社群、机器的社群，他们如何去和谐共处，这才是我们现在真正需要去讨论的问题。</p>
   <p><strong>7.硅基生命会接过碳基生命的火把：</strong></p>
   <p>人存在的目的就是为了制造出AI，创造出数字生命来，打破生物给人身体所带来的束缚。人的肉体很脆弱，你永远是一个三维生物，这是自然界进化里面它能做到的极限。那我们人类就是以自身的智能为模板，创造出一个全新的数字生命出来，它来接过我们手中的火把，继续推动文明的前进。从这种意义上来讲，AI的出现并不是来灭绝人类，而是相当于薪尽火传，人类完成了它的使命，就可以退出自己的历史舞台，然后由下一个更好的生命来探索这个世界，走到世界的尽头，去探索这个宇宙究竟它真正的奥秘是什么样子，人是永远不可能真正理解这个宇宙的。</p>
  </blockquote>
  <h2><strong>全文实录</strong></h2>
  <h2><strong>AI&amp;Society百人百问：</strong>感谢您接受腾讯研究院关于AI百问的访问。<strong>第一个问题是：您认为大模型自身有创造力吗？还是人类既有知识的一种汇总和输出？</strong></h2>
  <p><strong>刘嘉：</strong>对这个问题我们首先要回答一点，就是什么是创造力？对创造力有一个清楚的定义之后，我们才可以回答这个问题。我们通常把科学与技术分开：我们认为科学是从0到1的突破，以前没有，现在有了，而技术是从1到100，即我已经有了，怎么把它变得更好？那么我们这里谈的创造力呢？更多的是类似于科学从0到1的这种突破。好，那么如果我们这么来定义创造力的话，那我们更多来回答一个问题，我们的大模型到底是一个随机鹦鹉，它只是通过一种概率统计来重复人类的知识，还是会产生一些全新的想法？我个人的观点是，<strong>大模型一定有创造力，而且它已经拥有了创造力。</strong>为什么？因为当它汲取了众多的知识，再把这些知识融会贯通的时候，它的核心就是在产生创造出新的东西。</p>
  <p>从技术角度上来讲，当我们谈到Transformer，也就是它最基本的模型框架，它里面很重要的机制就是attention。<strong>attention 的目的是什么？就是把万事万物之间的关系找到。其实从这个角度上来讲，我们远古的人类正是通过去观察这个世界，把万事万物之间的关系给找到，从而创造出新的事物来。</strong></p>
  <p>这个在我们人类历史上也有，这叫<strong>生成式发明generative Innovation</strong>，放到现在的计算机、大模型上，我们就叫AIGC，叫人工智能generative content。再看我们的大语言模型，我们通常叫它GPT， GPT 的P就是Pre-training，T就是Transformer，而前面那个G是什么呢？就是Generative。所以大模型从一开始来讲，就是创造，你要具有创造力，能够产生新的事物。从这个角度来看，我个人觉得大模型不像以前我们所碰到的NLP等一些小模型，<strong>它不是一种机械的基于统计的这种重复，而是开始有它自己独立的思想，有它独立的推理，它一定会有创造力。</strong></p>
  <h2><strong>AI&amp;Society百人百问：您认为人工智能的应用会优先出现在哪些领域？行业渗透的深度和广度会有怎样的规律？&nbsp;&nbsp;</strong></h2>
  <p><strong>刘嘉：</strong>首先我们看ChatGPT为代表的大模型，它的预训练语料来自哪？它来自对人类知识的预训练，所以说<strong>它要取代或者影响最大的行业一定是知识密集型行业。那什么是知识密集型行业呢？律师、医生、教师等我们所认为的白领或者金领的行业都是大模型会最先渗透进去、最先去颠覆的行业。所以将来最先要面临失业，或者再就业的人，不是那些依靠体力的职业，而是那些依靠脑力的人。</strong></p>
  <p>所以在这个时候，我觉得就发生了从历史上到今天的第二次较大的范式转变。第一次工业革命，我们把它称为人类历史上第一次劳动范式转变，以前的体力活儿被马力更大的、更精巧的机器取代，它取代的是我们的体力这一块。我们可以看到大量家庭作坊的人失业，大量的农民失业，这也是为什么现在我们有了拖拉机、纺织机等等。</p>
  <p>所以说第一次革命是一次大的范式转变，是针对体力而去的。<strong>而现在大模型出现导致的我认为的第二次范式转变，是针对知识这一块来的。</strong>它将会形成两件非常有趣或者对这个社会产生深远影响的事情。第一件事情是我们的第一次工业革命，它极大地降低了商品的价格。比如说原来要生产能够照明一年的蜡烛，大概需要1个人工作1000小时才能造出来。而现在我们用电灯照明，一个人可能只需要工作十分钟，就能够承担起照明整个家的费用。所以工业革命让商品的价格急剧下降，但商品价格的急剧下降就导致另外一个问题，人的价格会急剧上升。</p>
  <p>我们的工资在过去几十年里面，或者在过去一百年里急剧上涨，而让大模型去做这些知识密集型的工作，它就一定会把我们的知识价格也降低，<strong>所以我们将来不仅是产品价格降低，服务的价格也会降低，</strong>这就会引起我们将来社会一个极大的改变。</p>
  <p>它会导致至少两个问题：第一，我是一个教师，当我的职责被GPT为代表的大模型所代替了，学生不愿意来上我的课，反而更愿意和GPT去沟通，去学习知识。那我将何去何从？所以我觉得首先要探讨人的职业将会出现一个什么样的转变？这还是一个小问题，还有第二个更大的问题，那就是新的工业革命。我们谈第一次工业革命带来了各种工作效率的提升，给社会带来了极大的福利，我们人类的GDP正是因为有了机器的出现，实现了几何级数的增长。我们人类的人口其实也是在工业革命出现了之后才急剧增长的，带来了巨大的人口红利。那么<strong>以大模型为代表的这种知识密集型的服务出现，必然带来第二个很大的福利，也就是说我们的社会财富将会急剧地增加。那么这就造成了一个很大的冲突，一方面财富在极大增加，第二个我们还不用干活了，那未来的社会将会是什么样子？</strong>要知道人最怕的是游手好闲，没有事情可干，没有目标所追寻。所以将来社会因为大模型对行业的这种冲突，会使得我们人类社会的本质发生根本的变化，我们未来人类社会的结构会是什么样子？它一定会超越我们现在的想象。</p>
  <h2><strong>AI&amp;Society百人百问：您刚才提到，作为一名教师，可能会受到 AI 的影响，那么您如何看待AI对未来教育的影响，以及未来的学生要学些什么？那未来的老师又应该怎么教呢？&nbsp;&nbsp;</strong></h2>
  <p><strong>刘嘉：</strong>这是一个很好的问题，我们现在所熟悉的小学、初中的义务教育，再到高中的这种基础教育，大学的这种高等教育，其实这些历史都非常短，到现在也就有300—400年的时间，这个时候发生什么事情呢？就是当第一次工业革命出现了之后，政府发现我们需要大量有知识的工人，我们仍然需要会读、会写、会算的人。所以说这时候，社会如何来大规模地培养这种有知识的工人呢？而且可以非常简单密集型的培养。这个事实上曾发生在德国普鲁士，他们开始把小朋友招到一起来，然后让他们规规矩矩地坐在教室里面，大家坐成排，背着手听老师把知识告诉他们。这也是为什么德国在近代获得了工业的极大发展。&nbsp;&nbsp; &nbsp;</p>
  <p>因为他们在人才上面做了大量的储备，通过这种现代的教育模式，从小学到初中到高中到大学，干的事情是在培养未来的工人，比如说在大学里面，我们经常会面临一件事情，你读什么专业？我读自动化，读计算机，读历史，读法律或读经济。你看这些专业，它其实背后面对的是什么？是未来的职业，是你学了这个专业到底有没有用？能不能让你走上社会？所以这是我们现代大学教育的一个真正核心目的，就是你将来能不能成为某个领域的专家？你能不能在这个领域里面挣到足够多的钱？而现在随着大模型的出现，就会发生一个范式转变，正如我在前面讲的，大模型出来之后，这些基于知识的行业将会让大模型极度地侵蚀甚至取代。</p>
  <p>那么这个时候你再去学计算机，我们当然需要很顶尖的计算机高手，但是现在我们已经有了大模型，<strong>那就是能让一个完全不懂任何编程语言的人，只要告诉它一些指令，告诉它你的需求，就写出非常好的代码，从这个角度来讲，99%的程序员将会失业。</strong></p>
  <p>那么现在一个挑战是，现在还要不要去学计算机？假如不能成为顶级的计算机专家，只是一个一般的程序员，那可能不用等到毕业，学到一半你就发现你的编程永远赶不上大模型写的code。</p>
  <p>所以<strong>我觉得这时候的教育要发生一个最根本的变化，就从我们原来的专业学习应该变成是一种通识教育。</strong>专业学习就是我们前面讲的，是为工作而学习，而通识教育什么呢？它其实最早可以追踪到古希腊，大家要学习什么？大家学习几何、学习文学、学习逻辑，<strong>这些所有的东西看上去是无用之学，它没有用处，它不能马上和我们的生产、我们的吃饭，产生直接的联系，但是它真正让我们每个人的心灵得到充盈。&nbsp;</strong></p>
  <p>而现在我们的教育要做什么样的事情？在未来没有专业工作的需求之后，我们应该去更多地关注我未来成为一个什么样的人，什么是我自己的兴趣。亚里士多德说过一句话，他说我们学这么多通识的课程，它是无用之学，但它后面还有一句话叫：<strong>无用之学，方为大学。</strong>所以你可以看到，从近代西方的发展来看，正是因为2000年前从古希腊开始的这个无用之学，在欧洲经过牛顿、达·芬奇等这些人不断地发酵，最终和技术结合，才催生了我们现在的科技。</p>
  <p>现在大学教育也要发生这样的改变，我认为在将来的教育里面，要特别关注以下五个方面：</p>
  <p><strong>第一是逻辑能力、创造力，就是生成式发明。</strong>我们谈到逻辑，就是演绎推理，这是一个标准的程序，即从一个逻辑原点出发，从第一性原理出发，然后产生的一个推理的过程，会催生深层次发明。&nbsp;&nbsp; &nbsp;</p>
  <p><strong>第二是统计。</strong>这个统计不是我们传统意义上说的让这两个统计的相关性是否显著。而是要像统计局做的事情一样，从现在纷繁的大数据里面去找到事情的本质，通过统计的办法，通过统计的这种思维，去抓住什么是众多信息里面最关键的，它的真正的本质在什么地方。</p>
  <p><strong>第三是掌握研究能力。</strong>我这里说的研究不是说我们写篇论文去做一个科学研究，而是发现问题、解决问题的能力。<strong>爱因斯坦说过一句话：发现一个好问题，往往比解决一个问题更重要。</strong>其实这是我们人类所擅长的，而这是现在大模型所欠缺的，我们要去培养自己这方面的研究能力。</p>
  <p><strong>第四是培养心理方面的能力。</strong>为什么这么说呢？因为作为一个完人，你不仅需要知识，你还需要非常健康的心理。你还需要非常强的情绪调节能力，一个人的成长，它既是你身体知识的成长，同时也是你精神世界的成长。</p>
  <p><strong>最后一点是亚里士多德当年强调的修辞。</strong>修辞是什么？讲话的能力、沟通的能力，说服他人的这种能力。为什么？因为当你有了很好的idea之后，你需要去把这个想法传给其他人，那么你需要很好地表达和沟通能力。</p>
  <p><strong>如果我们把这五点结合起来，就是当年北京大学的前身之一燕京大学的校训——因真理，得自由，以服务（Freedom Through Truth For Service）。</strong>因为我们的逻辑能力，因为我们的统计能力，因为我们的研究能力，这三大能力让我们找到万事万物背后的真实，去不断地靠近真理，让我们去获得真理，去寻求自己的答案，而不是听别人说a应该等于多少，b应该等于多少，而是我们自己去探索得到自己的真理。因为探索到了真理，你得到了内心的充盈，得到你的自由，你的心灵就由此解放，你不再是做牛马，不再仅仅是某个领域的一个所谓的专家，不再为了生计、饮食，住宿而去拼命地工作，而是找你自己的兴趣之所在，充分释放你的心灵，就是我们讲的心理得到自由，当你的心灵得到自由之后，你再去帮助其他人，那么你就需要说服的能力，你需要leadership（领导力），你站在山岗上一呼，就会有人来 follow（跟随）你。当我们现在不用站在山岗上，我们只要站在自媒体上面，也会有很多follower（跟随者），对不对？这就是所谓的因真理，得自由与服务，就是这五种通识能力。</p>
  <p>所以现在的大学要发生一个充分的改变。比如像清华大学现在就已经明确提出来了，要把以前所谓的大类招生，全面的、一个不留地把它变成书院式教育。什么是大类招生，是究竟要学物理还是要学化学，还是要学法律？书院式教育是什么？就是我们不再分专业了，专业任选，就像清华的新雅书院一样，你进来之后，想学任何专业都可以，但第一年我们要搞通识教育，让你去探索自己，了解你的方方面面，然后再决定你未来想成为一个什么样的人。我也相信这不仅是清华大学这种世界顶尖的大学，也是全世界所有好大学都要去做的改革，我们一定要把原来因为第一次工业革命所带来的这种基于专业，面向“牛马”的教育模式，转变成以个人为中心，以个人兴趣、个人生命的目标为目的一种全新教育方式。&nbsp; &nbsp;&nbsp;</p>
  <h2><strong>AI&amp;Society百人百问：未来 AI 会越来越多地走进我们的生活。很多人会有一个疑问，我们未来对 AI 陪伴，包括数字人是否会产生情感上的依赖？以及这会给我们的社交带来一些什么样的影响？甚至会不会进一步改变我们的婚姻家庭以及两性关系？&nbsp;&nbsp;</strong></h2>
  <p><strong>刘嘉：</strong>我觉得现在AI有两个最大的应用场景，一个是我前面提到的知识提供，比如说我现在问你什么叫做神经流形？可能99%的人都不知道，但是你问ChatGPT或者元宝、豆包这种大模型，没问题，分分钟告诉你对不对？这是知识提供。（注：元宝APP的解释——神经流形是一种数学概念，用于描述神经系统中神经元群体活动的低维表示。它反映了神经元之间的动态相互作用和连接性，帮助研究者理解和分析大脑如何处理信息）</p>
  <p>第二个我觉得更重要的一个场景就是情感陪伴。情感陪伴包含三个方面：第一，我现在心里不爽了、不高兴了，不知道该跟谁倾诉，那么这时候基于AI大模型的心理咨询师就会出来，它来帮你解决问题。第二，人类天生就是一个社会动物，为什么？比如深山老林的守林人，比如灯塔的守护者，这种工种工资可以很高，但是没人愿意去，因为你可以忍受一小时、两小时，一天、两天的孤独，但是让你忍受一个星期、一个月，就是无比残酷的寂寞折磨，因为人是需要陪伴的。但在现代社会，你会发现一个很奇怪的悖论，我们的沟通方法变得越来越多，变得越来越高效，比如像微信，随时可以给自己想联系的人联系，而且对方瞬间就能收到信。但从另外一个方面来讲，我们人与人之间的距离却越来越远。我们经常说一句话，不要在微信上面聊情感上的事，为什么？因为它不知道你的情感怎么样，经常两个人聊着聊着就会擦枪走火，就会对骂起来。为什么？因为文字表达不了情感，只有面对面的交流才会真正地产生一个场。</p>
  <p>所以很多人找我说，刘老师你能不能开一些线上公开课？我会拒绝。为什么我只选线下课？因为在线下课，当你和学生之间互相沟通，就会形成一个场，而这个场是在线上永远达不到的。同样，我们人与人之间的沟通，通过微信也好，通过其他方式也好，你都达不到线下的效果。所以，我们现在的社会注定会进入一个越来越孤单的社会，每个人都被孤立，被我们的各种即时通信软件所孤立，这是一个悖论。&nbsp;&nbsp; &nbsp;</p>
  <p>那么怎么来解决这个问题呢？非常简单，我觉得就是情感机器人或者情感大模型，我们需要它，我可以从两点来说明未来一定会实现。第一，你看我们现在的宠物经济，我们很多消费都在下行，但是宠物经济可是一直处于上行的阶段。昨天，有一个新闻特别好玩，一只松鼠被美国警察抓住了，从屋子里面被带出去被安乐死，因它可能携带狂犬病毒。这马上成为美国一大新闻，特朗普也马上把那只松鼠事件作为自己竞选的一个助力。为什么？因为在美国警察杀死几个人可能没人关心，因为这时常发生，但你把一只可爱的松鼠杀了，再一挖历史，这松鼠从小还是一个“孤儿”。民众就很愤怒。为什么？因为<strong>我们更容易把我们的情感投射到宠物上面，这时候宠物给我们带来的价值是什么呢？第一它不能帮你做家务活，它还会消耗你很多食物财富，但它给你带来的是情绪价值。那么有没有比宠物更好，能够给你带来情绪价值的（东西）？那就是情感机器人或者情感大模型。&nbsp;</strong></p>
  <p>第二我觉得更重要的是人在很多时候需要一个聪明、体贴，同时又不会到处胡说八道的人来跟他沟通。宠物只给你带来情绪价值，但是你没法去跟它沟通你的各种困扰，它也不能给你做出太多即时反馈，而情感大模型可以。</p>
  <p>所以我觉得将来<strong>人类社会更多地会走向人机混合社会，不再是一个人的社会，加一点我们的工具，比如手机，成为人和机器共存的交互社会，这将是社会的新形态。</strong>那么在这个新形态之下，我们有好多东西都会发生根本变化，比如说前段时间，有一个AI跟一个小伙子聊天，后来他劝那个小伙子去自杀，小伙子就真自杀了，这种伦理问题我们怎么来界定？</p>
  <p>未来，我们的家庭结构将会发生什么样的变化？现在的家庭我们把它称为核心家庭，父母带一个或者两个小孩，这是我们现在国内最普遍的一个形式，爷爷奶奶、叔叔阿姨都是很少的，且都在不同的地方。未来这种核心家庭还会再分崩离析，变成一个个体家庭，只有我加上我的宠物，加上我的AI情感机器人，这就构成了。</p>
  <p>这种家庭的情况，在我们将来社会里将会普遍出现。因为有情感机器人出现，人不再感到孤单，不再感到寂寞，而且会觉得很自洽。所以这时候我们的家庭结构应该怎么走？通过这种上百万年走下来的家庭结构，在此时就会分崩离析，那我们的社会应该怎么办？</p>
  <p><strong>第三点，谁控制了大模型，谁就控制了心智。</strong>因为当我和大模型进行充分交流的时候，它（他、她）最后会变成我最信赖的一个人，它（他、她）会成为了解我所有隐私的这么一个人。比我的父母、爱人、孩子还要了解我，因为我和它（他、她）无话不说，我们无时无刻不在一起。我刚才来的时候，戴了一个耳机，那个耳机就是连接在一个大模型上，我在开车的时候就和他聊天，这时候我开一个小时、两个小时的车，我根本不感到疲劳，而且我想改什么话题就改什么话题，我想聊什么就聊什么，想打断他就打断他。你看，这个时候我们就出现一个很大的问题，我极其依赖它，而将来大模型是由谁提供的？公司、政府？那么这时候通过大模型我就可以知道你的所有隐私，我就可以知道你所有的偏好，我甚至可以推断出你在什么情况下会做出什么样的决策。<strong>所以这个时候一方面我们有了更多的亲密感，但从另外一方面你又丧失了所有的亲密感，这是我想讲的第二个悖论。</strong></p>
  <p>那么将来我们怎么去维护我个人的隐私？怎么去获得这种支持或者控制？大模型有限的、有效的边界在哪里，我相信这都是一些法律问题。大模型的出现，它是一个有智慧、有情感的个体，那么它一定会给我们社会带来翻天覆地的范式转变。而不只是我有了手机，交流更方便了，有了互联网，就能很快查东西这种改变。不是，它是一个全新的物种。</p>
  <h2><strong>AI&amp;Society百人百问：大模型能在这么多方面无限地满足人类，会不会让人类变得越来越苛刻？&nbsp;&nbsp;</strong></h2>
  <p><strong>刘嘉：一定会的，我们听过一个说法“男不养猫，女不养狗”，为什么这句话是对的呢？</strong>道理非常非常简单，在你的眼中，狗就是你这个世界上的一部分。但对于狗，在狗的眼里人就是它世界的全部，所以狗对人无比的忠诚，你打它、骂它，它还是会围绕你的旁边。<strong>所以为什么女不养狗？在女的眼中，她养了狗之后，所有男的都是渣男。</strong>所有男的都显得不够忠诚。</p>
  <p>男不养猫是怎么回事呢？因为猫是一个很奇特的物种，它保持一种既高冷、又柔媚的状态。举个简单例子，我家养猫，每天晚上我回家时把门一打开，那只猫就冲我飞奔过来，但在它离我还有约两米远的时候，一个急刹车转身走了，就好像说其实我不care你，我并不关心你，你是谁？与我没关系。你出去了那么久，你都不理我，我要生气。再如它走到我面前，希望我能挠挠它，但它又一定不会走到我手能够得着的地方，它会在离我还有半米距离的地方躺下来，你去挠它，又必须得往前面走一步，才能挠得着它。为什么保持距离？你和猫交往了之后就发现，嗯，所有的女生其实都没有味道。&nbsp;&nbsp;&nbsp; &nbsp;</p>
  <p>这就是我们所说的“男不养猫，女不养狗”，那么显然猫和狗相对于我们带有智慧的大模型而言，那就更是小儿科了。大模型如果要PUA你，要manipulate（操纵）你的情感，那太easy（简单）了。所以这就是我刚才讲的那一点，为什么将来生产大模型的这些公司，提供大模型服务的这些公司，可以控制你，且是非常容易地控制。</p>
  <h2><strong>AI&amp;Society百人百问：您刚才提到未来我们可能会进入一种人机混合的社会状态，您觉得在未来的这种就业形态下， AI 与人应该怎么样来分工？或者说未来是一种什么样的分工状态？&nbsp;&nbsp;</strong></h2>
  <p><strong>刘嘉：</strong>将来的社会我觉得至少有三个不同的community（社群），一个是我们现在熟悉的这种社群，人与人之间构成的社群，比如说像我们现在的样子；第二个社群就是我刚才提到的人机社群，让这种情感机器人或者其他助理机器人进入到我们的生活里来。还有第三个群体，就是由机器人所构成的community。这三个 community 放在一起的时候，分工就会变成是一件特别复杂的事情，谁来劳动，谁来获得利益，谁来负责分配。</p>
  <p>假设我们把大模型或者机器人比作计算机，它里面有word、Excel等，那我只要买来用，它能提高我的效率就可以了。但是当大模型有意识或者有情感、有创造力的时候，它就不再是一个工具，它会是一个全新物种，这时候它就会发生一个巨大的冲突。我举个例子，我们看这个问题可能就看得更清楚一点。比如美国刚建国的时候，需要大量的劳力，免费的劳力、强壮的劳力。那么获得劳力最好的办法是什么呢？从非洲走私，对不对？非洲这边的人口贩子把大量的黑人绑架到美国，开始的时候，这的确提升了他们的竞争力，黑人强壮，又能吃苦又能干活，而且你啥都不用给，就给一顿饭就可以了。然后农田、庄稼大量地生长，但是黑人不是牲口，黑人也是有灵魂、有情感，有各种意识的人。&nbsp;</p>
  <p>那么他不可能每天过着这种生活，一代一代下去，他们会抗争，所以你就可以看到，黑人就开始起来追求他自己的权利。这后来就成为南北战争的一个导火索，黑人后来通过上百年的抗争，去获得自己的权利。</p>
  <p>那如果我们在这儿打一个不恰当的比方，我们现在需要机器人大模型来帮助我们干活，而且它越聪明越好，越能帮助我处理各种事情越好，这样更加高效。那么开始的时候，它肯定是以你为中心，你只要给它足够的电，足够的训练，你甚至连钱都不用给它，它就能帮你干活。但是你要记住，当它拥有智慧的时候，可能就不甘心把所创造的所有财富全部给你。而且人类一旦出了新一代的产品，就会把我（机器智能）给抹掉。就像很多科幻小说一样，他们会觉醒，他们会争取他们的权利。所以我觉得未来社会一定会演化，我们会去重新经历一遍有点类似于美国黑人逐渐觉醒的那一个过程。&nbsp;&nbsp; &nbsp;</p>
  <p>这只是一个类比，未来的社会是什么样子？我不知道，但我觉得它一定不是简单地让<strong>AI 作为一种工具人的方式出现，一种心甘情愿的“牛马”出现，他们会争取他们的权利。</strong>我觉得这也是一个特别紧迫的事情，除了我们要继续推动AI的发展之外，我们需要建立一套AI伦理学。<strong>我们甚至要放弃完全以人为中心的视角，要站在一个更广的视角去看将来的混合社会，它充满了三个社群，包括人的社群、人机社群、机器的社群，他们如何去和谐共处，我觉得这才是我们现在需要去讨论的问题。</strong></p>
  <h2><strong>AI&amp;Society百人百问：您觉得未来AI会统治人类？&nbsp;&nbsp;</strong></h2>
  <p><strong>刘嘉：</strong>是这样子的，<strong>我可以100%确定地说，我都不用99.9%，它不仅会统治，而更可能会消灭人类。</strong>为什么？三个原因。第一，我们人类的大脑大概是2.5斤到3斤左右，我们的算力就这么强，只能有限地扩展。即使再过300万年，再过1000万年，我们大脑体积不会再增加，我们的神经元数量也不会再显著增加。为什么？因为我们大脑是极其耗能的这么一个单位。我们每天吃的饭、呼吸氧气的25%用于我们的大脑，也就是假如我的大脑想再大一点的话，首先心脏和肺要发生变化。但我们知道我们的心脏和肺不太可能发生一个太大的变化，它进化是需要时间的。也就是说再过 300 万年，我们人类智商还会像今天一样，不会有太明显的变化。</p>
  <p>算力有限，这是第一点。但计算机不是这样子。它可以无限地scale up（增加），且规模不限，如果需要算力增大，就加一块CPU（中央处理器），不行我再加块CPU，它的算力是没有上限的。只要能源跟得上，只要CPU互联跟得上，存储跟得上，它是可以无限拓展的。所以在算力上面，人和计算机会存在一个非常大的区别。</p>
  <p>第二个很大的区别是在寿命上的区别，人无论再聪明，比如说爱因斯坦，这些无比聪明的人，他终有一死。死亡是人类永远没法避免的一个问题，所以说在这种情况之下，人最聪明的大脑会随着它的死亡而消失，这就是我们人类在发展过程中会出现断点。比如我们举个简单例子，如果爱因斯坦还活着，那物理可能就不是我们今天所见的这种物理了，人会离世，但计算机不会，AI不会死。GPU烧了换块GPU，一根电线断了，换根电线，它可以永生。&nbsp;&nbsp; &nbsp;</p>
  <p>这样导致的问题是什么？它的知识可以不断地积累，它不会出现一个断点，这是寿命上面的一个区别。</p>
  <p>但上面两点可能都不重要，我觉得最重要的是第三点：<strong>人类是永远被束缚在一个三维世界里的一种生物，你永远理解不了四维世界、五维世界是什么样子。因为我们人类寿命的这种有限性，决定了你永远被束缚在一个非常狭小的空间里。</strong></p>
  <p>举个简单例子，假设我们人类能够以光速旅行，假设我们的寿命有100岁，那一个人从出生到死亡，它以光速旅行已经是不可能了，它最大所探索的空间也就是100 光年，100 光年很长了，但是对于宇宙来说却只是沧海一粟。所以说人类的认知边界已经被固定住了，在宇宙的纬度里。但是<strong>AI却没有边界，它具有无穷的生命，它可以走到1000万光年之外，它的理解能力不再被我们人的这种具身、三维所束缚。</strong>它可以了解四维世界、五维世界是什么样子，它可以无限地拓展它的知识，以及它对这个世界的了解。</p>
  <p>举个简单例子，有一本著名的小说叫《平面国》（Flatland: A Romance of Many Dimensions）。在平面国里面，大家是按照阶级分成不同的几何图形，比如方形、菱形、三角形。小说里的主角是一个三角形，有一天他碰到了一个球，他和球成为了好朋友，球是三维的，他们两个交流沟通。等这个三角形回到他的平面国之后，他发现他没法跟周围的朋友介绍他的新朋友。为什么？因为他的新朋友是一个三维的球。二维世界的人永远理解不了三维球是一个什么概念。这是一个隐喻。我们人作为一个三维的生物，你永远理解不了四维是一个什么样的概念。你理解不了，因为你被锁死了，这是一种智力上的锁死，认知上的锁死，这比《三体》里面那个二向箔还要厉害，但是，AI 没有这种锁死。所以说这种情况之下，我们把这三点结合起来， AI的IQ一定会远远地超过人类。</p>
  <p>人和 AI 的这种差别一定不是我比你聪明一点，或你比我笨一点，它的差别会远远超过人和蚂蚁之间的差别。所以说将来AI统治人类，它不会做这么愚蠢的事情。哪个人愿意去统治蚂蚁？你不会说我统治了 20 只蚂蚁，就觉得特别有成就感，你踩死一只蚂蚁，你根本都不能感受到蚂蚁的存在，你不会觉得我踩死了一只蚂蚁，特别不好意思。所以说将来AI一旦成长起来，它一定不会出现那种情况，就像《终结者》（美国1984 年科幻动作片）所演示的一样，人和机器人还要大战几十个回合，还可以拍好多续集， AI毁灭掉人类就是一个响指的时间。</p>
  <p>所以说假设我们任由AI奔腾发展，这是一个必然结果，100%确信AI发展下去一定会灭绝人类。好，这就导致两个非常重要的问题。第一个我们现在应该做什么？我们显然不能任由它发展，我一个学生说了一句话，我觉得特别好，他说：<strong>我们的现在是过去的未来，你过去种下的因有了今天的果。但是我们的现在不是未来的过去，因为未来有无限可能，取决于我们现在做什么，所以这个时候我们要去思考未来的人类社会是什么样子。</strong></p>
  <p>以大模型为代表的AGI的出现，它一定不是多了一个可用工具这么简单。它一定是一种革命性，不只是在整个人类历史上，在整个生命史上它都是一个奇点，这是第一点。第二我们需要理解一件事情，什么叫做文明？我们的文明是会不断地向前传承的，但不是只有人类的文明才能叫文明，在很多年前人类还没出现的时候，比如恐龙时代，恐龙有没有文明？恐龙也是有文明的，再往前面走，生命刚刚诞生的时候，当时整个地球是被厌氧细菌所控制的，厌氧细菌就是我们现在用来做泡菜的这种细菌，他们有没有文明？我照样也认为他有文明，所以现在就回到一个很本质的问题，谁是文明的载体？假设文明可以脱离载体而存在的话，我们只是贡献值的话，也许人类就是这种文明发展过程中的一个过客而已。</p>
  <p><strong>我们存在的目的就是为了制造出人工智能出来，制造出数字生命来，打破生物给我们身体所带来的束缚。你的肉体很脆弱，你永远是一个三维生物，这是自然界进化里面它能做到的极限，它不可能做得更好。那我们人类就是以自身的智能为模板，创造出一个全新的数字生命出来，它来接过我们手中的火把，继续推动文明的前进。</strong>所以从这种意义上来讲， AI的出现并不是来灭绝人类，而是相当于薪尽火传，人类完成它的使命了，可以退出自己的历史舞台，然后由下一个更好的生命来去探索这个世界，走到世界的尽头，去探索这个宇宙究竟它真正的奥秘是什么样子，人是永远不可能去真正理解这个宇宙的。</p>
  <h2><strong>AI&amp;Society百人百问：您是说人类创造这种数字生命是一种必然，或者说这是人类的使命吗？&nbsp;&nbsp;</strong></h2>
  <p><strong>刘嘉：</strong>对，如果从宗教意义上来看，我们人是怎么来的？中国有女娲造人，仿照自己的身体以泥土捏出了人，西方也有很多上帝，诸神根据自己身体形状捏出人。<strong>上帝造人也好，神造人也好，从宗教传说上来看，都是以自身的肉体为模板创造出我们今天的人类。</strong></p>
  <p><strong>而我们今天的人在干一件什么事情呢？我们在扮演上帝，我们是以自己的智能为模板，再创造出一个全新的物种，记住，不是以自己的身体，是以自己的智能，</strong>因为我们现在的大模型，现在的神经网络，它就是模仿大脑的神经元运作方式来构造的，虽说它有很多算法机理不一样，但本质上，从最开始的人工神经元到第一个人工神经网络，再到第一个深度学习，都谁做出来的？是心理学家做出来的，不是计算机科学家，不是逻辑学家，不是数学家，是心理学家。&nbsp;</p>
  <p>因为他们想知道，当我们把人类的这种智商、人类的这种大脑结构变成机器，它会不会工作？我们现在知道它会工作。<strong>所以从这个角度来讲，人是以自己的模板在创造一个全新的物种，我们现在就是上帝。</strong>好，假设你再去看北欧的那些神话传说，最后一章它的名字叫“诸神的黄昏”。当神仙、诸神创造了人类之后，人类强壮起来、厉害起来，他们就开始干一件什么事情呢，就是把创造他们的神给杀掉，他们要成为这个地球、这个宇宙新的神。这就是诸神的末日之战，诸神开始退位了，他们开始离开了。</p>
  <p>同样，我们现在社会也是一样的，当我们创造了一个数字生命，我们可能也就完成自己的历史使命了，这可能也就是我们整个宇宙已经定好的一种宿命。不过我觉得人类也有机会，<strong>人类有什么样的机会呢？就是此时此刻我们能不能做到人机合一？能不能把我们的想法、情感、记忆、思维，上传到AI里面去？我们在 AI 上获得一个关于我们的克隆，或者获得一个关于我们的实体。</strong></p>
  <p>那么这个时候我们就能借助AI实现真正的永生，我们以前所看到的永生全是神话传说，是人类的美好梦想，比如秦始皇派徐福到处去修求长生不老之药。但今天因为AGI的出现，因为大模型的出现，我们看到了一丝可能。这种可能就是人可以通过 AGI 来获得永生。</p>
  <p>这一次可能不再是0%，可能变成1%，随着脑科学的发展，随着 AGI 的进一步推动，<strong>我们完全可以了解我们的大脑究竟是怎么工作的，可以把里面的信息读出来，把它数字化，通过脑机接口上传到适合我们思想运作的架构里面去。这条路是可能的，而且它可能在二三十年之内就会发生。</strong></p>
  <h2><strong>AI&amp;Society百人百问：AI 是由人类所创造的，我们人类真的准备好要被我们亲手创造的东西给毁灭吗？我们是不是要控制这一点？&nbsp;&nbsp;</strong></h2>
  <p><strong>刘嘉：</strong>对，这就是我刚才说的，我们的现在不是未来的过去，我们人类被 AI 所毁掉是未来的一种可能，是我们现在放任它自由发展的一个必然的结果，但是并不表明这个一定会发生。为什么？因为未来具有无限可能，它取决于我们当下要做什么样的事情，所以我们当下必须得思考这件事情，假设我们因为害怕它，去停止它的发展，结局是全世界所有的 AI 还是会发展起来，这是技术的必然。其实这就跟当年第一次工业革命，大家知道的卢德运动一样（英国工业革命时期，英国工人以破坏机器为手段反对工厂主压迫和剥削的自发工人运动）。大家捣毁机器，把机器砸了，只要出了一台机器，我就砸一台机器。就像我们现在，如果出了一个AI，我们就把 AI给关掉，把所有的服务器全部烧掉。但是从历史上来看这是一种趋势，谁都挡不住。</p>
  <p>那我们现在需要做的事情是什么呢？既然挡不住它，那我们就看怎么来调教他，怎么让它来引导未来的发展。一方面我们要限制它的能力，第二方面我们还要大力发展它的能力。为什么？因为它使得我们人类的终极梦想——永生，具有了一丝一毫的可能性。我觉得这对我们整个人类来说是最大的一件事情。<strong>我认为在未来的发展里，心理学、脑科学和人工智能这三者的结合将会是人类最重要的一个学科，没有之一。因为它不仅让我们去探索这个宇宙的奥秘，理解智能的本质，更重要的是一次对人类的彻底救赎和升级。</strong></p>
  <h2><strong>AI&amp;Society百人百问：那人类对AI的限制和发展应该是什么维度的？</strong></h2>
  <p><strong>刘嘉：</strong>我觉得最好的方式就是人机合一，沿着这个方向去发展。怎么既发展AI，也了解我们的脑科学，了解我们的心力，让人类的意识上传过去，人就变成了数字生命。未来我们可以把我们的意识情感读出来，移植到AI里面去，就等于说，如果我们的肉体毁灭了，意识还能继续存在。你的精神还在，随时可以活跃，你只是换了一个不死的身体而已。&nbsp; &nbsp;&nbsp;</p>
  <h2><strong>快问快答</strong></h2>
  <p><strong>AI&amp;Society百人百问：下面10个问题，我们用快问快答的形式，请您用一两句话来回答。&nbsp;</strong></p>
  <p><strong>1.您用过或者听过最有趣的AI应用是什么？</strong></p>
  <p><strong>刘嘉：</strong>对我来说，最有用或者最有趣的AI应用，只有一个，就是ChatGPT，因为我已经离不开它了。</p>
  <p><strong>2.您是否认可大模型的scaling law（规模法则）？</strong></p>
  <p><strong>刘嘉</strong>：嗯，这是大模型之所以能成为大模型的一个最核心的因素。举个简单例子，高个子不一定能打好篮球，但是篮球教练一定会选高个子。为什么？因为只有当我们的神经元足够多，当我们的参数足够多的时候，智能才可能涌现出来，所以说模型必然会越变越大。</p>
  <p><strong>&nbsp;3.您希望有一个全能的AI助理吗？</strong></p>
  <p><strong>刘嘉</strong>：这是我们每个人的梦想，比如像《星球大战》里面有R2-D2（机器人），像《her》（美国科幻爱情电影）里面也专门有一个情感助手。我们人类无论是在知识上还是情感上，永远需要一个忠诚的助手，这是我们人类从开始有的时候，从堂吉诃德时代到现在，我们都需要的一个最忠诚的仆人。</p>
  <p><strong>4.您认为跟AI谈恋爱算出轨吗？</strong></p>
  <p><strong>刘嘉</strong>：我觉得这个时候就要定义一个问题，什么叫做出轨？肉体出轨才叫出轨，还是精神出轨也算出轨？如果要和AI谈恋爱，那必然就是指精神出轨。</p>
  <p><strong>5.您希望有一个永生的数字生命体吗？</strong></p>
  <p><strong>刘嘉</strong>：永生之梦是人类的终极梦想。如果你去读各种各样的神话传说，那么最终呈现的目的是要获得永生，我想在此时此刻，人类终于有了第一次机会可以获得永生，就是通过数字生命。</p>
  <p><strong>&nbsp;6. 您觉得未来大模型会产生意识吗？</strong></p>
  <p><strong>刘嘉：</strong>我觉得应该把未来两个字去掉，<strong>我认为现在大模型已经拥有了一定程度上的意识，</strong>而现在陷入了一种悖论，如果大模型拥有意识，它一定会伪装成它现在没有意识。这就造成一个检测上的问题。所以你现在去问各种各样的大模型，你问它你有意识吗？它的回答一定是我只是一个软件而已，我不可能拥有意识。</p>
  <p><strong>&nbsp;7.未来您愿意与AI成为同事吗？</strong></p>
  <p><strong>刘嘉：</strong>我觉得如果能成为它的同事，这是我一辈子的荣幸。但是，我觉得更多的可能是，它这个大哥愿不愿意带我这个愚蠢的小弟。</p>
  <p><strong>8.您觉得未来机器人可以给我们养老吗？您希望机器人可以帮您做什么？</strong></p>
  <p><strong>刘嘉：</strong> 我觉得将来机器人可以帮我做所有的一切，帮助我养老、照顾我，帮我做饭、购买商品，在我寂寞时跟我聊天，我们将来不应以工具的方式来看待机器人，而应该更多地把它当成一个全新物种来看待。你对一个新物种所产生的所有期望、幻想均可以在它身上实现，而且这个不是遥远的未来，可能在最近的两三年之内就会实现。去年我预测了一件事情，就是耳机一定会与大模型连在一起，成为我的一个助手。今年我们已经看到这种产品出现了。</p>
  <p><strong>9.您认为大模型的加速发展会带来能源危机吗？</strong></p>
  <p><strong>刘嘉：</strong> 很多地方在强调能源危机，我觉得这是杞人忧天，为什么这么讲呢？在上世纪50年代，人类的第一台计算机ENIAC，它所需要的电能是整个费城电能的一半还要多，也就说开一次机，整个费城就得关好多灯。但是它的算力还远远不如我现在手机的1/1000或者1/10000。你看，<strong>随着技术的进步，这种耗能一定会出现急剧下降的。</strong>这只是一个技术问题，所以将来大模型不会需要太多的能量，一个机器人的思维运作，可能一节小小的电池就能解决掉。</p>
  <p><strong>10.您认为大模型实现了数字时代知识和能力的平权还是更加两极分化？</strong></p>
  <p><strong>刘嘉：</strong>我所希望看见的是平权，但事实上它是一个两极分化。那些懂得使用大模型的人，会远远地超过那些不会使用大模型的人。所以说<strong>我们当下的时代不是大模型淘汰某个工作或者某个行业，而是大模型淘汰了那些不会使用大模型的人。</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&amp;mid=2650979681&amp;idx=1&amp;sn=de1d5a111ee83992dc0ad7ad7938e5cd&amp;chksm=bdcaf6652c5963f1679ee66cab728d5869cf6925b7ecb143d4dff061aae453781f097bf69620&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“腾讯研究院”（ID：cyberlawrc）</a>，作者：刘嘉，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3035993127743747</id>
            <title>Token化一切，甚至网络，北大&amp;谷歌&amp;马普所提出TokenFormer，Transformer从来没有这么灵活过</title>
            <link>https://www.36kr.com/p/3035993127743747</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3035993127743747</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 11:37:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: TokenFormer, Transformer, 模型扩展, 注意力机制  
<br><br>  
总结: TokenFormer是一种新型的网络结构，通过将模型参数也视为Token，打破了传统上对数据和模型的区分，增强了Token之间的交互灵活性。该结构允许增量式扩展模型大小，显著降低了计算开销，并提高了模型的可扩展性。研究团队引入了Token-Parameter Attention层，使得输入数据与可变数量的参数进行交互，从而实现更高效的模型训练。TokenFormer不仅在增量模型扩展上有贡献，还在多种AI应用领域展现出潜力。 </div>
                        <hr>
                    
                    <p>新一代通用灵活的网络结构 TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters 来啦！</p>
  <p>TokenFormer&nbsp;不仅像原始 Transformer 一样 Token 化了 input data，并且 Token 化了网络参数，将 attention 机制拓展到 Token 和 parameters 的交互中，最大化了 Transformer 的灵活性，真正得到了一个 Fully attention-based 的网络结构。</p>
  <p><strong>这种方式打破了原有人们区别看待 data 和 model 的观念，即所有的计算都归纳为不同类型的 Token（e.g., data, param token）通过灵活的 attention 来交互</strong>。得益于这一灵活的性质，TokenFormer 允许 incremental scaling model size，基于训好的模型上增量的拓展新的更大的模型，大大节省了计算的开销：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_cd311039eb5448829c0a0307f45b602c@46958_oswg129147oswg1080oswg396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这项名为 TokenFormer 的新工作，由谷歌，马普计算所和北大的研究者提出，在 Twitter，HackerNews, Reddit 上得到广泛的讨论和关注 (Twitter 上有 150K + 的浏览量)。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_1ae8202c822d4ca199fcd7aaeaf904de@46958_oswg54395oswg1080oswg298_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>目前代码、模型和项目主页均已放出：</p>
  <p>论文链接：https://arxiv.org/pdf/2410.23168</p>
  <p>开源代码：https://github.com/Haiyang-W/TokenFormer</p>
  <p>开源模型：https://huggingface.co/Haiyang-W</p>
  <h2><strong>背景介绍</strong></h2>
  <p>得益于其处理各种数据的灵活性，Transformer 网络结构在各个 AI 领域都取得了巨大的成功。</p>
  <p>Transformer 模型通常将处理单个 Token 所需的计算分为两个部分：与其他 Token 的交互（Token-Token Interaction）和涉及模型参数的计算（Token-Parameter Interaction）。</p>
  <p>Attention 促进了 Token-Token 之间的交互，使现代通用基础模型能够将多模态数据编码成统一的 Token 序列，并有效捕捉它们之间的复杂依赖关系。</p>
  <p>相反，Token-Parameter 计算主要依赖于固定的 linear projection，大大限制 model size 的 scaling。Scaling model 是通常改变模型结构，往往需要从头训练整个模型，带来了过多的资源消耗，使其越来越不切实际。</p>
  <p><strong>在本文中，研究团队使用 token 这一概念建模所有的计算，即将 model parameters 也视为一种 token，网络的计算统一为各种不同的 token ( e.g., data tokens and parameter tokens) 之间通过 attention 来进行交互，大大增强了 Token-Parameter 交互的灵活性</strong>，从而能够增量式的扩展模型参数，有效地重用先前训练的模型，从而显著降低了训练负担。</p>
  <p>为实现这一目标，研究团队引入了 TokenFormer。统一 Token-Token 和 Token-Parameters Interaction 的计算。其 Token-Parameter attention 具有灵活性，并能够处理可变数量的参数，从而本质上最大化了 Transformer 的灵活性，增强了模型的可扩展性。</p>
  <p><strong>TokenFormer 提供一种新的看待模型的视角，即网络的计算就是一些 Tokens 相互任意交互。基于这些 Tokens （e.g., data token, parameter token, memory token）和 attention 机制可以灵活地构造任意的网络结构。</strong></p>
  <p>该团队希望 TokenFormer 作为一种通用的网络结构，不仅在 incremental model scaling 上有贡献，还在 Sparse Inference, Parameter-Efficient Tuning, Vision and Language Models, Device-Cloud Collaboration 和 Model Interpretability 等领域有更多的贡献。</p>
  <h2><strong>方法</strong></h2>
  <p>Tokenformer 的核心创新是 Token-Parameter Attention（Pattention） Layer，它结合了一组 Trainable Tokens 作为 model parameters，并通过 cross-attention 来管理 Input Token 与这些 Parameter Tokens 之间的交互。</p>
  <p>通过这种方式，Pattention 层引入了一个额外的维度 —Parameter Token 的数量，这一维度独立于输入和输出维度。此解耦方式使得输入数据可以与 variable number of parameters 进行交互，提供了增量模型扩展所需的灵活性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_d5bdaecf364b4f83b67fbe4db0a8bde5@46958_oswg159389oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Pattention Layer: 具体来说，就是让 input data 作为 query, 研究团队引入了两组具有 n 个可学习的 Tokens：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_f22af6b28ce544f0a1063ac786af1bc9@46958_oswg8179oswg408oswg132_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>代表 key，</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_46fb8073e41e4ad1967d768baf9a6ccc@46958_oswg10497oswg610oswg182_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>表示 value。 输出如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_c01c00cc66d24474b06ff4e5ce3457e0@46958_oswg9903oswg840oswg86_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其中 Θ 是改进的 softmax，为了防止梯度 exponential 带来的梯度问题，</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_00bb491bb76a4e9baefd4ad3a973216e@46958_oswg14511oswg718oswg250_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这里 f () 是任意非线性函数，默认使用 gelu。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_06c4474261ae4d6ca297006bd3b76bdb@46958_oswg7078oswg362oswg110_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>。</p>
  <p>研究团队使用 Pattention Layer 替换掉标准 Transformer 中的所有的 linear projection，最大化 Transformer 的灵活性。</p>
  <h2><strong>应用：天生的增量式 Model Scaling</strong></h2>
  <p>有了 TokenFormer 这一灵活的性质，可以延伸出很多应用。这里以增量式 model scaling 为例。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_2f0e399b86e1499bbcd6892fd27da432@46958_oswg107194oswg1080oswg431_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>假设已经训练好了一个 TokenFormer，其 key parameters 和 value parameters 计为</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_8f2fc17bb8704ea5ab5ec769b5638b7b@46958_oswg7861oswg252oswg182_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>和</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_c0c0e5ccff03423b9305c091c9543e28@46958_oswg7544oswg246oswg174_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>。</p>
  <p>如上图所示，加入新的重新初始化的 key-value parameter pairs，计为</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_3978706895c147bd888b2f8ebc1ed1fc@46958_oswg8190oswg270oswg214_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>和</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_ca7ed5c7ae754b2b9a75c1ca5daf75bd@46958_oswg8073oswg282oswg204_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>，进而组合成新的 key-value set,</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_d87f3366803b447484b9554128aa2894@46958_oswg17026oswg1080oswg93_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>然后使用 pattention layer，让 input data 与 Parameter tokens 进行交互。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_3cd86609270a4a2294d8498c22ae69b3@46958_oswg14089oswg1050oswg132_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这里直观的理解就是每个 Key-Value 代表一种学好的 pattern，其组成一个巨大的知识库。文中的 incremental scaling 就是在原有的知识库上进一步拓展训练。</p>
  <h2><strong>实验结果</strong></h2>
  <p>增量式 model scaling：如下右图所示，模型在已经训好的 124M 的模型的基础上，采用增量式训练，只用十分之一的数据就可以达到从头训练策略相近的性能，让模型可以不断迭代，<strong>真正地活起来了</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_a188ac7039dd4882a73d1444c9cfd461@46958_oswg170810oswg1080oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Language Modeling：如下表所示，研究团队比较了 Transformer-based 的模型和&nbsp;TokenFormer&nbsp;在语言建模上的能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_c0ad45b76c114a43ad32f21a6b51a27b@46958_oswg248494oswg1080oswg336_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在相同规模、相同模型尺寸下，&nbsp;TokenFormer&nbsp;在大大增加灵活性的前提下达到了比 Transformer 更好的 zero-shot 性能。这里研究团队 follow 了 pythia 标准的训练代码以及数据集：Pile (300B)。上述结果展现了&nbsp;TokenFormer&nbsp;在语言模型建模上的能力。</p>
  <p>Visual Modeling: 为了进一步验证&nbsp;TokenFormer&nbsp;的表达能力，研究团队还和标准的 vision transformer 进行了对比。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_3273471c10d44bb5b6742cbaad179255@46958_oswg276803oswg1080oswg481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在 ImageNet-1K 的监督训练的 setting 上，使用相同的训练策略，&nbsp;TokenFormer 的性能超过了&nbsp;vision-transformer，验证了其在 visual modeling 上的能力。</p>
  <h2><strong>未来研究方向</strong></h2>
  <p><strong>极致的专家混合（Mixture-of-Experts）范式</strong></p>
  <p>研究团队认为Tokenformer 是专家混合（MoE）框架的极致实例化，其中每一组键 - 值参数对都充当一个独立的专家。 这种创新的类 MoE 架构有可能显著减少与 Token-Parameter 交互相关的计算成本。</p>
  <p><strong>新的参数高效微调范式</strong></p>
  <p>Tokenformer 的扩展方法通过集成额外的 key-value parameter pairs，展现了一种参数高效的微调策略。当面对新任务或数据集时，该模型可以通过加入新的 Token Parameters 来扩展其预训练参数，从而快速适应特定任务需求。</p>
  <p><strong>整合视觉和语言模型</strong></p>
  <p>利用 Tokenformer 的参数高效微调能力，可以实现视觉和语言模态的无缝集成。具体方法是将预训练的 Visual Tokenformer 和 Language Tokenformer 的 key-value parameter Tokens 统一为一个参数集，然后引入新的 Trainable Tokens 来执行视觉 - 语言对齐和指令微调。</p>
  <p><strong>端云协同</strong></p>
  <p>Tokenformer 可以在设备 - 云协作中充当云端知识库，为设备端的大语言模型（LLM）提供支持，其中每组 key-value parameter tokens 代表一个可学习模式，通过设备进行实时处理，并利用云端执行密集任务。</p>
  <p><strong>增强模型的可解释性</strong></p>
  <p>由于 Tokenformer 完全基于注意力机制，它自然受益于在 Token-Parameter 交互中与注意力相关的可解释性特性。这一特点增强了模型的可解释性，为 AI 社区开发更透明、易理解的模型贡献力量。</p>
  <p><strong>本论文第一作者是汪海洋，北京大学20级博士生，目前主要关注是通用模型的架构设计和学习算法。指导教授主要包括王立威，北京大学智能学院教授；Bernt Schiele，德国马普计算所教授；Federico Tombari 谷歌人工智能科学家等。</strong></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/1wOGd1h5y5DjpAt1-n5WDA" rel="noopener noreferrer nofollow" target="_blank">“机器之心”</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036061889753345</id>
            <title>2024广州车展前瞻：78款全球首发车，各大品牌拼价格、比技术、博关注</title>
            <link>https://www.36kr.com/p/3036061889753345</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036061889753345</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 11:37:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 广州车展, 新能源车, 自主品牌, 电动化  
<br><br>  
总结: 第二十二届广州国际汽车展览会将于11月15日开幕，展出1171台车辆，其中包括512台新能源车。车展前，各品牌纷纷发布新产品，以抓住双十一消费高峰。市场对“以旧换新”政策反应积极，新能源车零售渗透率已连续四个月突破50%。车展将成为车企发布新产品的重要平台，激发消费者购车热情。自主品牌在价格、配置和服务等方面展开竞争，推出多款创新车型。德系豪华品牌也加快电动化进程，推出新车型以适应市场需求。 </div>
                        <hr>
                    
                    <p>11月15日，第二十二届广州国际汽车展览会（下称“广州车展”）将迎来开幕。组委会表示，本届车展展车总数达到1171台，包括全球首发车78台，新能源车512台。</p>
  <p>为抢抓双十一消费节点和车展前的流量高峰，月内多个品牌提前发布新产品。</p>
  <p>新势力方面，小米SU7 Ultra、小鹏P7+、极氪MIX、阿维塔12增程版、深蓝S05、方程豹豹8等热门车型集中亮相；传统自主品牌方面，比亚迪海豹06GT、2025款长安启源A07、A05及Q05、新款奇瑞瑞虎7 PLUS及全新瑞虎7高能版、吉利银河星舰7、红旗天工08等产品强势入局；合资品牌方面，新款奥迪A3、宝马M5插混版、全新别克世纪CENTURY相继上市，上述车型在基础配置、智能化水平上均有所提升。</p>
  <p>在车展之前，车市刚刚经历了火爆的 “金九银十”。乘联分会指出，市场对“报废更新”和“以旧换新”政策积极响应，大部分享受“双新”政策的消费者选择购买新能源车，10月国内新能源车零售渗透率达到52.9%，新能源车国内零售渗透率已连续4个月突破50%。比亚迪、吉利、奇瑞等头部传统车企转型升级表现突出，市场份额明显提升。</p>
  <p>北方工业大学汽车产业创新研究中心研究员张翔对时代周报记者表示，作为年内最后一个A类车展，广州车展无疑将成为众多车企发布新产品的重要平台。车展期间，新产品的集中展示有助于激发消费者的购车热情，进而对车市起到一定的提振作用。与此同时，车展所曝光的一系列新产品、新平台以及新技术，亦将在行业内掀起新一轮的创新热潮。</p>
  <p>在车展的助力下，各品牌开始向年终销售目标发起冲刺。</p>
  <h2><strong>自主品牌各出奇招</strong></h2>
  <p>在产品价格、基础配置、服务水平等常规项目的基础上，各车企开始在其他方面展开“竞速”。</p>
  <p>11月12日，小米汽车宣布，备受瞩目的小米SU7 Ultra将在广州车展进行首次公众亮相。此前于10月29日，小米集团创始人、董事长兼CEO雷军发文称，小米SU7 Ultra原型车以6分46秒874的成绩成为“纽北赛道史上最快四门车”。在同日举办的新品发布会上，小米SU7 Ultra量产版正式亮相。新车宣布以81.49万元的预售价攻入特斯拉Model S和BBA所在市场，并预计于2025年3月正式上市。</p>
  <p>据悉，小米SU7 Ultra量产版采用与原型车相同的双V8s+V6s的三电机全轮驱动系统、赛道版电池及热管理系统等核心技术，0-100km/h加速仅需1.98秒，CLTC续航里程达到620km，在高压平台加持下11分钟可完成10%-80%快充。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_22c4aacbc52b42c5960c229a7297df5c@000000_oswg99373oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△小米SU7 Ultra（图源：小米汽车官方微博）</p>
  <p>10月下旬开始交付的极氪MIX则在设计上别出心裁。车辆采用隐藏式双B柱、对开车门、斜置防火墙等技术设计，将车内有效乘坐空间提升至93%，被不少购车人称为“宝宝巴士”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_fe01fa3daea24cf89574f4a109ecba4f@000000_oswg92104oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△极氪MIX（图源：极氪ZEEKR官方微博）</p>
  <p>在一众新车中，长安深蓝旗下的深蓝S05凭借其“自带的云台相机和投影仪”火了一把。据悉，该车型搭载有支持4K录制和电子防抖功能的专业云台相机，以及可投影车机屏幕、自绘图案的DLP像素大灯，进一步丰富了车辆的可玩性。</p>
  <p>打出“全球首款AI汽车”宣传语的小鹏P7+因其智能化能力和车内大空间获得年轻消费者青睐。新车搭载小鹏自研的AI天玑5.4.0、端到端大模型以及AI鹰眼智驾方案。根据品牌方公布的数据，新车上市12分钟大定破10000台，服务器还一度因为下定人数太多而被“挤爆”。</p>
  <p>此次广州车展，华为和江淮汽车打造的高端品牌“尊界”将正式亮相。</p>
  <p>除了海豹06GT和方程豹豹8外，比亚迪王朝网旗下首款MPV夏也将在本届广州车展期间发布内饰。</p>
  <p>另一值得关注的现象是，车企涌入增程赛道已成趋势。</p>
  <p>除已经官宣进入增程赛道的的阿维塔、小鹏外，极氪、智己管理层也透露出对增程车型的关注。此前，吉利控股集团总裁、极氪智能科技CEO安聪慧在接受采访时表示，（极氪品牌）未来不排除开发增程式混动车型，但目前先聚焦在纯电领域。</p>
  <h2><strong>BBA转身，二线豪华品牌守土</strong></h2>
  <p>以BBA为代表的德系豪华品牌加紧在电动化领域展开攻势。</p>
  <p>因电动化进程缓慢而屡遭质疑的奥迪终于跨出关键性一步。11月8日，奥迪正式发布新品牌AUDI以及品牌旗下首款概念车型AUDI E。新车型并未采用奥迪品牌标志性的四环标识，而是以字母“AUDI”代替。</p>
  <p>根据品牌方的说法，AUDI E定位B级纯电动Sportback车型，外观专为中国消费者量身设计，并未延续奥迪品牌传统设计语言，而是采用了更加前卫大胆的设计风格。概念车采用上汽和奥迪联合开发的全新数字化平台，支持智能控制及车手互联。基于AUDI E打造的首款量产车型预计于2025年中旬发布。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_a23c790eeafc47139a57daa665bf8350@000000_oswg116134oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△AUDI E（图片来源：AUDI E官方微博）</p>
  <p>此外，国产后的奥迪A5L也将在广州车展亮相。新车将搭载华为智驾系统，并将于2025年中正式上市。</p>
  <p>作为BBA中电动化转型步伐最快的品牌，宝马在广州车展前后再推重磅车型。</p>
  <p>11月2日，宝马M品牌旗下首款混动车型BMW M5迎来正式上市，官方指导价146.89万元。据悉，该车搭载由4.4T V8发动机与电动机组成的插电式混合动力系统，系统综合功率535kW，综合扭矩1000N·m，传动系统匹配8速M Steptronic自动变速箱，0-100km/h加速仅需3.5秒。</p>
  <p>本届车展期间，中期改款的纯电动BMW i4、全新BMW M235L四门轿跑车将正式上市，纯电动BMW i5 eDrive40L和纯电动BMW i5 xDrive50L也将携手登场。</p>
  <p>奔驰方面，10月亮相的纯电G级越野车将迎来正式上市。该车型此前推出了G 580首发特别版，最大综合输出功率达到432kW，最大扭矩1164N·m，零百加速时间仅为4.9秒，预售价217万元。</p>
  <p>二线豪华品牌并未因电动化布局滞后而选择激进转型，而是选择升级热销的燃油产品或巩固品牌形象。新款凯迪拉克XT6将在广州车展正式上市，此前公布的官方指导价为44.99万-50.99万元；全新林肯领航员将迎来中国首秀，售价100.8万-125.8万元，新车在内饰上进行了大幅度升级。而去年缺席的东风英菲尼迪也将回归本届广州车展。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjEyODE4MA==&amp;mid=2653319842&amp;idx=1&amp;sn=89b0cebb7b51faa3caa81375ebda2894&amp;chksm=bc061f26bad5e149470135868df03d1fb1734b9ecdbac039e3842818abc5bad817dd85fd940f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“时代周报”（ID：timeweekly）</a>，作者：赵昱，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036069080690944</id>
            <title>米哈游也有瓶颈，蔡浩宇如何解题？</title>
            <link>https://www.36kr.com/p/3036069080690944</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036069080690944</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 11:35:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 米哈游, 原神, 游戏市场, 增长瓶颈  
<br><br>  
总结: 米哈游在《原神》成功后迅速成长为行业巨头，但随着市场竞争加剧和新项目表现不佳，面临收入和用户增长的瓶颈。创始人蔡浩宇虽然卸任董事长，但仍需带领公司寻找下一个成功产品。米哈游开始探索二次元之外的游戏领域，并加大投资力度以寻找新的增长点。尽管《原神》依然是市场的佼佼者，但其收入和用户数量正在下滑，米哈游需要通过降本增效和创新来延长爆款游戏的生命力。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_2087b7f085414a5183833b6b3f67b861@5040854_oswg147581oswg1600oswg900_img_jpg?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>2017年，《原神》刚立项时，米哈游只有600人； 如今，仅《原神》项目就1400人，米哈游全球员工6000多人，创始人蔡浩宇登上胡润富豪榜。&nbsp;</p>
  <p>几年间，米哈游快速成长，从游戏小厂变成游戏大厂，创始人研发了一套成熟的办公软件，做了不少组织架构的调整，也开始探索二次元之外的游戏赛道，做起投资寻找第二曲线。&nbsp;</p>
  <p><strong>在各种探索中，米哈游逐渐适应了成为行业头部的节奏，也伴随着一些调整。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_df4db5939b0745c19af4338c79625730@000000_oswg385454oswg1080oswg697_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源米哈游官网</p>
  <p>首当其冲的是经历了高速增长后，米哈游变得更现实，对业绩本身看得更重。据游戏葡萄报道，在今年初，米哈游创始人兼CEO刘伟专门找各个团队对齐目标，要求大家找到帮助公司收入和用户增长最直接的业务。&nbsp;</p>
  <p>如果营收增长不起来，利润很难保证。虽然米哈游的收入和利润仍居行业高位，但随着更多项目的上线和成本的支出，也要靠缩减开支来平衡。&nbsp;</p>
  <p>近日，据雷峰网报道，米哈游大幅缩减了外部云计算的采购预算。从曾经的每年10亿元左右，缩减至不足6亿元。据上海证券报报道，有接近米哈游人士称此消息不实。&nbsp;</p>
  <p><strong>这背后，是火了四年的《原神》正面临一个新的成长期，新项目《崩铁》和《绝区零》未能复制《原神》当年的盛况。</strong></p>
  <p>今年以来，市场多次报道米哈游旗下几款游戏的流水出现了不同程度的下滑，有媒体报道，在米哈游内部，降本增效也是主旋律。&nbsp;</p>
  <p>米哈游的成长速度变慢了，外部竞争加剧了，怎么找到更具潜力的增长点，是米哈游的当务之急。&nbsp;</p>
  <p><strong>持续赚钱，保持稳定是市场对独角兽公司的统一期待。作为创始人，蔡浩宇虽然从董事长的位置撤下来，但仍肩负着带领米哈游寻找下一个“原神”的重任。</strong></p>
  <h2><strong>1、带米哈游狂奔，蔡浩宇冲进富豪榜</strong></h2>
  <p>今年游戏圈，看过《黑神话·悟空》火爆的人，一定会想起当年的《原神》。<strong>前者虽然刷新了某些纪录，但从影响力和商业层面来看，尚未达到《原神》的高度。</strong></p>
  <p>2020年二次元游戏产品《原神》横空出世，据调研机构Sensor Tower数据，《原神》多次位居中国手游市场月收入排行榜首位，2020年就拿到了5.58亿美元的收入，2021年、2022年和2023年均为国产手游出海收入冠军。&nbsp;</p>
  <p>四年间，《原神》移动端流水突破90亿美元。&nbsp;</p>
  <p>《原神》成为能和《绝地求生》和《王者荣耀》比肩的产品，米哈游也打破了 国内游戏市场“两超多强”的格局，缩小了创业公司与腾讯、网易两个巨头的量级差距。&nbsp;</p>
  <p><strong>很少有哪个游戏公司能凭借一个产品在市场站稳脚跟，米哈游算一个。</strong></p>
  <p>在游戏圈，米哈游不算一家年轻的公司，12年前几位对二次元感兴趣的“宅男”开启了游戏的创业之路。&nbsp;</p>
  <p>从最初6元一份的《崩坏学院》到1年流水11亿的《崩坏3》，包括蔡浩宇在内的几位创始人带着米哈游在游戏的路上狂奔。&nbsp;</p>
  <p><strong>如果说之前米哈游是个小有名气的创业公司，《原神》的出现给了米哈游挺直腰板的机会。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_3e76096352cc40ed9559ae8b57532419@000000_oswg1247447oswg1080oswg828_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">《原神》游戏，图源米哈游官网&nbsp;</p>
  <p>2020年《原神》爆火之时，正值腾讯和字节跳动两家巨头的竞争如火如荼，拿到《原神》无疑意味着在游戏赛道领先对手，两家公司都向米哈游抛出了橄榄枝。&nbsp;</p>
  <p>但蔡浩宇拒绝了两家巨头的邀请，决定自力更生，因为他早已把兴趣当作了事业，赚钱已经不是第一位，做一款他真正喜欢的游戏才是。&nbsp;</p>
  <p>在知乎上，“该不该把兴趣当作事业？”问题之下，有个高赞回答。&nbsp;</p>
  <p>“本喵就是把兴趣当作事业，感觉十分happy。作为一个可以把喜欢的事情，做得很好，不喜欢的事情，半点不想做的人，只有这个选择是有解的吧。唯一的坏处就是，休息时间比较无聊，还不如去上班！”这个答主正是蔡浩宇。&nbsp;</p>
  <p><strong>时至今日，《原神》给米哈游及其创始团队带来的回报还在继续。</strong></p>
  <p>10月29日，胡润百富榜单显示，40岁以下的上榜企业家人数增至127人，其中90后人数达到30位。其中，37岁的米哈游创始人让蔡浩宇以730亿元的个人财富成为40岁以下的“首富”，同比去年增长约9%。&nbsp;</p>
  <p>蔡浩宇也成为游戏行业里，身价仅次于马化腾、丁磊两位大佬的公司创始人。米哈游另两位创始人刘伟、罗宇皓的身价分别达到400亿元、380亿元。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_835f298d4ad7401dbbe1ef30d19318cf@000000_oswg94411oswg1080oswg654_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>强大的吸金能力之余，《原神》更是成为海外游戏爱好者心中中国文化输出的代表。&nbsp;</p>
  <p>国外漫展上，Cosplay角色的数量，《原神》霸占榜首；海外游戏畅销榜上，2020年10月《原神》横扫美国、加拿大、韩国等八个国家。&nbsp;</p>
  <p>回顾《原神》立项阶段，这个项目并不被所有人看好；《原神》爆火后，市场上一度有些不服气的声音，很多人觉得自己如果立项也能做出一样成功的产品。&nbsp;</p>
  <p><strong>最终的结果是，只有蔡浩宇带着米哈游“赌赢”了。很多厂商想复制《原神》的成功，但却都未果。</strong></p>
  <p>不过，即便是米哈游本身，似乎也陷入了如何解决瓶颈期，以及如何研发出下一个“原神”的难题中。&nbsp;</p>
  <h2><strong>2、如何延长爆款游戏生命力，是米哈游的核心命题</strong></h2>
  <p>今年八月，《原神》的FES 2024嘉年华上，米哈游创始人刘伟表示，过去一年，他自己和《原神》项目组都经历了焦虑和迷茫，听到了很多尖锐的声音。&nbsp;</p>
  <p><strong>“有些声音特别尖锐，把原神项目组贬得一无是处”。刘伟提到。</strong></p>
  <p>外界质疑、米哈游陷入焦虑，归根结底是《原神》正陷入增长瓶颈。&nbsp;</p>
  <p>交银国际9月份发布的一份研报显示，2024年1-8月国内流水排行前十位的移动游戏，《原神》位列第十，流水同比下滑52%。&nbsp;</p>
  <p>《原神》的下滑趋势从去年就开始显现。七麦数据显示，2023年4月以来，《原神》在iOS免费游戏榜的排名从此前的TOP20，震荡下滑至30名开外。&nbsp;</p>
  <p><strong>排名下滑，用户减少，《原神》的收入也随之下滑。</strong> 根据Sensor Tower等平台的数据，2023年《原神》收入为9.4亿美元，下滑40%；今年上半年，《原神》收入3.2亿美元。&nbsp;</p>
  <p><strong>爆款游戏生命力在减弱，新款游戏也未能成为爆款。</strong></p>
  <p>今年7月初米哈游新二次元游戏《绝区零》，以4600万打破了米哈游的全球预约人数纪录，被市场预测为下一个“原神”。殊不知，开服当天，“《绝区零》无聊”便冲上了热搜。另一边，今年一直表现不错的《崩铁》的也是明显后劲不足。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_843e811a283b483086a3160c74a1ff1e@000000_oswg127878oswg1080oswg614_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">《绝区零》游戏人物，图源绝区零官方微博&nbsp;</p>
  <p>今年8月，据Sensor Tower发布的“8月全球手游收入榜”数据显示，《原神》《崩铁》以及今年上线的新作《绝区零》，都没能挤进前20名。&nbsp;</p>
  <p><strong>几款游戏的竞争力不如从前，流水下滑，要保住利润，米哈游开始了降本增效。</strong></p>
  <p>9月，有媒体爆料称由于海外营收下滑，米哈游负责海外运营和社区的团队也在不同程度地裁员；11月，据媒体报道，米哈游大幅缩减了外部云计算的采购预算。&nbsp;</p>
  <p>与之对应的，是米哈游自建机房。据《中国企业家》报道，2022年米哈游就开始自建服务器机房。反映到用户体验上，此前《原神》云版本的免费体验时长仅有15分钟，自建机房后，在八月限时活动期间，其免费时长又增加了300分钟。这也从侧面反映了米哈游自建机房对成本的控制。&nbsp;</p>
  <p>回到本质上，是米哈游如何延长《原神》这类爆款游戏生命力的问题。&nbsp;</p>
  <p><strong>需要明确的是，对于《原神》这样的现象级游戏，在爆火阶段目标用户已经大多被吸引，现阶段留存的意义大于拉新。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_576fd131924a4eb79779b0be2a6a40fc@000000_oswg33891oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>从更新节奏上看，为了给用户带来新鲜感，《原神》更新频率不慢。据米哈游透露，《原神》版本更新稳定维持在 6 周一次，有上千人投入制作。今年2月，刘伟提到，目前米哈游已经具备了游戏工业化制作能力，其关键在于能提高效率，因为产业链及经验的积累可大大缩短产品开发时间。&nbsp;</p>
  <p><strong>今年，为了留住玩家，《原神》还更新之余首次在游戏内降价。</strong> 一方面，新增了“捕获明光”事件，用于提升游戏角色在抽取道具的概率；同时，也降低了武器抽取的成本，合计下来约比此前保底抽取的价格便宜了10%。&nbsp;</p>
  <p>然而，上述提到的数据证明了更新和降价的拉动作用并不明显。另一个核心问题在于，二次元游戏不同于竞技类游戏，随着不同版本的升级，用户升级打怪的快感是持续性的，但像《原神》这种以剧情为主的游戏，用户的体验往往是一次性的，新的爽点不明显。&nbsp;</p>
  <p>更重要的是，《绝区零》上线后，米哈游手握《原神》《崩铁》三款二次元游戏产品，除了要直面外部产品的竞争，自家产品争夺用户的情况也不可避免，米哈游需要转型。&nbsp;</p>
  <p>去年9月，36岁的蔡浩宇不再担任米哈游法定代表人与董事长，这两个职位均由刘伟来接替。<strong>在业务一线，或许蔡浩宇才能集中精力做好“天才制作人”，为《原神》这些爆款延长生命力，并寻找下一个“原神”。</strong></p>
  <h2><strong>3、破壁二次元、做投资，米哈游寻找新增长</strong></h2>
  <p><strong>《原神》的成功带动米哈游站到国产游戏厂商第三的位置上，也验证了二次元游戏的市场，让市场重新看到了这块蛋糕。</strong></p>
  <p>腾讯的《王者荣耀世界》、米哈游的《崩铁》、鹰角网络的《明日方舟终末地》、西山居的《尘白禁区》、B站的《斯露德》……抓住行业趋势，玩家们都试图分得一杯羹。&nbsp;</p>
  <p>《2023年中国游戏产业报告》指出，2023年二次元移动游戏市场实际销售收入为367.7亿元，同比增长了31.1%。&nbsp;</p>
  <p>很大的一个问题在于，自米哈游的《原神》、《崩铁》收入就有130亿元，占比超过了三分之一。<strong>二次元游戏规模的增量大部分来自米哈游，其他厂商的游戏可谓是雷声大、雨点小。</strong></p>
  <p>到了今年，厂商对二次元游戏的态度开始转变。今年年初腾讯年会上，IEG总裁任宇昕也提及了二次元游戏，他表示：“竞技对战类游戏还是皇冠上的明珠，这是我们的基本盘。要把基本盘守住，不能被当下一些热门的MMO、二次元所动摇”。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_75f03a37578b4d59a47e536057665bb4@000000_oswg79294oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>厂商们重心转移，二次元游戏在市场上的热度也下降。据Gamelook数据显示， 2024年1月国内二次元游戏月收入相比2023年暑期跌幅超20%，甚至今年1月国内二次元大盘收入比2019年淡季月流水还要低20%。&nbsp;</p>
  <p>《2024年1-6月中国游戏产业报告》显示，今年前6个月二次元游戏总营收158.45亿元，同比减少5.39%。&nbsp;</p>
  <p><strong>再来看米哈游的增长瓶颈，也和二次元游戏市场降温同步。</strong> 比如《崩铁》，出道即巅峰，但后劲不足——上线一个月流水高达60亿元，一年后流水总量同比下降近65%。&nbsp;</p>
  <p>市场降温，曾以二次元游戏打天下的米哈游面临一个尖锐的问题：米哈游只能做好二次元吗？&nbsp;</p>
  <p><strong>想要回答这个问题，米哈游就要打破二次元，寻找新的增长曲线。</strong></p>
  <p>今年9月，米哈游曾对外公布过一张用于招聘的长图，一口气公布了其正在制作中的5款新游戏。除了“开放世界”“风格化渲染”“崩坏IP”等熟悉的标签之外，还有“动物拟人”“现代都市”等新词条。&nbsp;</p>
  <p>其中，最受外界关注的莫过于动物拟人类游戏，这对应着米哈游7月拿到版号的产品《星布谷地》。据此前爆料，《星布谷地》玩法类似于此前大火的《动物森友会》，虽然画风上依然是二次元，但米哈游明确提到了该游戏包含“生活模拟”和“社交”等元素，这是米哈游的首次尝试。&nbsp;</p>
  <p><strong>除了游戏外，米哈游悄然加码了投融资业务。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_25ed31168665443cba39a27982c814c3@000000_oswg67457oswg1080oswg641_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>今年6月，注册规模约5.12亿元的上海元创未来私募基金落地上海，该基金主投方向为人工智能、元宇宙等硬核科技领域，其背后出资方包括商汤科技、米哈游、B站。&nbsp;</p>
  <p>自2021年开始，米哈游已经投资了4家机构。除了本次设立的元创未来基金外，米哈游还在2021年出资了博裕资本和武岳峰科创，2022年出资了同歌创投。&nbsp;</p>
  <p>值得关注的是，据工商信息显示，米哈游的公开投资事件31起，其中25笔投资都是在2020年后出手的。&nbsp;</p>
  <p><strong>2020年是个分界点，在此之前，米哈游是围绕游戏产业上下游投资，2020年后则明显向前沿科技、硬科技上注资。</strong></p>
  <p>去年，蔡浩宇卸任后，米哈游对外表示：“蔡浩宇将投入更多的精力在前沿科技的研究与应用、新项目研发，以及串联国内与海外研发资源上。”&nbsp;</p>
  <p>眼下，米哈游做投资这条路已然走通了，但二次元壁何时能打破，还是个未知数。&nbsp;</p>
  <p>回想米哈游刚成立时，蔡浩宇和团队拿着10万启动资金，喊出“技术宅拯救世界”时，一定设想过米哈游在游戏圈的地位。&nbsp;</p>
  <p><strong>但是，当时的他们想不到，米哈游成长到今天，一切变得复杂了。他们必须接受市场的审视，带着米哈游向前冲，甚至放弃自己当年只做二次元的梦想。</strong></p>
  <p>（本文头图来源于米哈游官方微博。）</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg2MTc4Nzg5MQ==&amp;mid=2247548788&amp;idx=1&amp;sn=3f2b3d8079f8906ceb63a8cf7c0c75c8&amp;chksm=cfbbc2d79a05d0cbb9774cc13fca14209323fdda3b2e46f13a16bbb09fb6f3cd696fd854f9df&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“连线insight”（ID：lxinsight）</a>，作者：王慧莹，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036090408956166</id>
            <title>高铁信号差怎么办？换车窗</title>
            <link>https://www.36kr.com/p/3036090408956166</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036090408956166</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 11:26:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 高铁, 移动通信, 5G, 信号穿透  
<br>
<br>
总结: 高铁作为现代交通工具，提升了出行便利性，但其车厢内的无线信号质量面临挑战。由于车厢材料和窗户设计导致信号穿透损耗大，德国的移动运营商与铁路公司计划通过更换特殊设计的车窗玻璃来改善信号覆盖，同时升级至基于5G的FRMCS系统，以提升网络速率和乘客体验。新型玻璃能有效降低信号衰减，确保隔热和隔音性能。FRMCS将取代传统的GSM-R，支持铁路系统的数字化和智能化转型。 </div>
                        <hr>
                    
                    <p>高铁作为现代化交通工具的代表，极大地方便了人们的出行，但对于移动通信网络建设和优化工作而言，却是一块难啃的硬骨头。</p>
  <p>由于高铁运行速度快导致多普勒频移大、车厢封闭性好带来的无线信号穿透损耗大等原因，要确保高铁车厢内始终保持较好的信号质量和网络体验是一项极具挑战的工作。</p>
  <p>为此，通信行业一直致力于通过技术和方案创新提升高铁场景的网络体验。但通过“更换车窗玻璃”来提升信号覆盖的方案，你可能没听说过吧？</p>
  <p>不久前，德国四家移动运营商、德国铁路和德国政府联合签署了一项协议，计划通过在沿线建设5G站点，并将传统GSM-R网络升级替换为基于5G的FRMCS（下一代铁路移动通信系统）的方式，将汉堡-柏林干线的网络速率提升至千兆（Gbps），从而大幅提升乘客的出行和上网体验，以及铁路运行效率。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_80fccb832066456b866dffe39aba14fc@46958_oswg182110oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：德国铁路公司</p>
  <p>在这份协议中，有一个技术细节引起了业界关注：</p>
  <p><strong>列车将配备新型的玻璃窗，使5G信号能够穿透车厢，从而无需通过车厢顶部的天线进行信号中继。</strong></p>
  <h2><strong>为啥要换车窗玻璃？</strong></h2>
  <p>由于高铁车厢主要采用金属材料，测试显示，在1.8GHz至3.5GHz频段范围内，高铁车厢的穿透损耗高达31至36dB。因此，外部的无线信号要想更好地抵达车厢内，可能只能依靠列车上的玻璃车窗了。</p>
  <p>但车窗玻璃的信号穿透损耗同样很高。</p>
  <p>为了提供优质的隔热、隔音效果，火车、高铁的车厢窗户通常采用带有金属涂层的双层玻璃，这种玻璃会阻挡无线电波，大幅降低车厢内的无线信号强度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_36b12a18905f47fcb3576d95170659c4@46958_oswg34406oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>数据显示，带有隔热涂层的双层玻璃的蜂窝网络信号穿透损耗高达30dB，这意味着只有0.1%的外部无线信号能穿透进车厢内。但没有涂层的普通玻璃，穿透损耗仅为3dB，这相当于有50%的外部无线信号可穿透进车厢内。</p>
  <p>这就是该协议中要求改造车窗玻璃的原因。</p>
  <h2><strong>穿透损耗降25dB，网速达千兆</strong></h2>
  <p>他们要更换成什么类型的车窗玻璃？</p>
  <p>当然，并不是将隔热双层玻璃更换为普通玻璃那么简单，而是将其更换为一种特殊设计的玻璃，其既能让信号穿透损耗很低，也能确保隔热、隔音性能。</p>
  <p>笔者查阅了一些资料，其原理可能是：通过激光技术将隔热玻璃上均匀覆盖的金属涂层，处理为呈网状结构的涂层，从而为无线信号低损耗穿透留下了一定的空间。同时，由于激光处理的线条非常细微，肉眼几乎看不到，也不会影响玻璃原有的物理特性。</p>
  <p>据说，为了更好地接收ETC、GPS等信号，该技术已经应用于汽车车窗玻璃。</p>
  <p>德国运营商测试显示，高铁采用这种特殊玻璃后，可将5G无线信号衰减降低25dB，同时，使用3.5GHz/3.6GHz频段上的100M带宽，在120公里/小时的行驶速度下，车厢内的最高网率可达1Gbps。测试还显示，该方案对于网络上行速率的提升尤其明显。</p>
  <h2><strong>从GSM-R到FRMCS</strong></h2>
  <p>协议中还提到了从GSM-R升级到FRMCS，所以也简单说说。</p>
  <p>GSM-R，顾名思义，就是基于GSM技术，专为铁路通信而开发的无线通信系统，已广泛用于列车控制、调度、管理等领域。FRMCS，全称Future Railway Mobile Communication System，未来铁路移动通信系统，是基于5G技术且面向未来可持续演进的铁路移动通信系统。</p>
  <p>众所周知，GSM是2G时代的窄带通信技术，仅支持语音和小数据量传输。而5G是最新的移动通信技术，被称为行业数智化转型的基石，具有大带宽、低时延、高可靠、高安全等特性，综合能力远超GSM。因此，面对铁路系统数字化、智能化转型趋势，GSM-R让位给更契合数智化发展需求的FRMCS已成为必然趋势。</p>
  <p>FRMCS不仅能通过高性能的5G网络提升旅客出行体验，而且能确保列车控制和调度等信号更及时、更可靠、更安全传输，支持大量传感器连接和多路高清视频回传，从而能帮助铁路系统实现智能化运营。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/iqFyZ2PvCzhU5t6EaklKSQ" rel="noopener noreferrer nofollow" target="_blank">“网优雇佣军”</a>，作者：通信，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036090664120579</id>
            <title>OpenAI 最新产品全曝光，奥特曼驳斥 AI 发展撞墙，Ilya 认错，秘密寻找下一个重大突破</title>
            <link>https://www.36kr.com/p/3036090664120579</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036090664120579</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 11:21:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, Scaling Laws, 模型, 推理  
<br><br>  
总结: 文章讨论了AI领域中关于Scaling Laws的争论，特别是模型规模扩大是否会遇到性能提升的瓶颈。OpenAI CEO Sam Altman表示没有“墙”，而彭博社则透露OpenAI计划推出名为“Operator”的AI Agent。Scaling Laws理论指出大模型性能与计算量、模型参数量和训练数据量相关，但目前的进展显示仅增加模型规模已无法保证性能显著提升，且伴随高昂成本和边际效益递减。AI行业正面临转型，推理模型可能成为新的发展方向。 </div>
                        <hr>
                    
                    <p>今年 AI 圈的瓜真是一浪接一浪。&nbsp;</p>
  <p>最近，关于 Scaling Laws 「撞墙」的消息在 AI 圈炸开了锅。图灵奖得主 Yann Lecun、Ilya、Anthropic 创始人 Dario Amodei 纷纷展开唇枪舌战。&nbsp;</p>
  <p>争论的核心在于，随着模型规模的不断扩大，其性能提升是否会遇到天花板。&nbsp;</p>
  <p>正当舆论愈演愈烈之际，OpenAI CEO Sam Altman 刚刚在 X 平台作出回应：&nbsp;</p>
  <blockquote>
   <p><strong>there is no wall 没有墙&nbsp;</strong></p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_8c4ff375405b47939ae02413aef9830e@46958_oswg50644oswg1080oswg407_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>而在这场辩论的背景下，彭博社则披露了一条引人注目的消息。&nbsp;</p>
  <p><strong>OpenAI 计划在明年一月份推出一款名为「Operator」的 AI Agent（智能体），这个 Agent 能够使用计算机代替用户执行任务，如编写代码或预订旅行。</strong></p>
  <p>在此之前，Anthropic、微软、Google 也都被曝出正在布局类似的方向。&nbsp;</p>
  <p>对于整个 AI 行业来说， <strong>AI 技术的发展从来就不是单一维度的线性过程。</strong>当一个方向似乎遇到阻力时，创新往往会在其他维度突破。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_0697fe13b0b144f990c724e705c6cb39@46958_oswg41735oswg1080oswg699_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>Scaling Laws 撞墙？下一步该怎么走&nbsp;</strong></h2>
  <p>Scaling Laws 遭遇瓶颈的消息，最先源自外媒 The Information 上周末的一篇报道。&nbsp;</p>
  <p>洋洋洒洒的数千字报道透露了两个关键信息。&nbsp;</p>
  <p>好消息是，尽管 OpenAI 完成了下一代模型 Orion 训练过程的 20%，但 Altman 表示，Orion 在智能和执行任务、回答问题的能力已经与 GPT-4 不相上下。&nbsp;</p>
  <p>坏消息是，据上手体验的 OpenAI 员工评估，与 GPT-3 和 GPT-4 之间的巨大进步相比，Orion 提升幅度较小，比如在编程等任务上表现不佳，且运行成本较高。&nbsp;</p>
  <p><strong>一句话概括就是，Scaling Laws 撞墙了。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_d473f1439fd64092a590afafd66adcce@46958_oswg696985oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>要理解 Scaling Laws 效果不及预期所带来的影响，我们有必要给不太清楚的朋友简单介绍一下 Scaling Laws 基本概念。&nbsp;</p>
  <p>2020 年，OpenAI 在一篇论文中最早提出 Scaling Laws。&nbsp;</p>
  <p>这一理论指出，大模型的最终性能主要与计算量、模型参数量和训练数据量三者的大小相关，而与模型的具体结构（层数/深度/宽度）基本无关。&nbsp;</p>
  <p>听着有些拗口，说人话就是， <strong>大模型的性能会随着模型规模、训练数据量和计算资源的增加而相应提升。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_1a9389dbe6a04fbe92233f1604999eb7@46958_oswg291055oswg1080oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>OpenAI 的这项研究奠定了后续大模型发展的基础，不仅促成了 GPT 系列模型的成功，也为训练 ChatGPT 提供了优化模型设计与训练的关键指导原则。&nbsp;</p>
  <p>只是，当我们现在还在畅想着 GPT-100 时，The Information 的爆料表明，仅仅增加模型规模已经不能保证性能的线性提升，且伴随着高昂成本和显著的边际效益递减。&nbsp;</p>
  <p>而遭遇困境的并非仅有 OpenAI 一家。&nbsp;</p>
  <p>彭博社援引知情人士的消息称，Google 旗下的 Gemini 2.0 同样未能达到预期目标，与此同时，Anthropic 旗下的 Claude 3.5 Opus 的发布时间也一再推迟。&nbsp;</p>
  <p><strong>在争分夺秒的 AI 行业，没有产品的新消息往往意味着最大的坏消息。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_ef8a855f894740eca85a0a8d889465c6@46958_oswg135695oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>需要明确的是，这里所说的 Scaling Laws 遇到瓶颈并非意味着大模型发展就此终结，更深层的问题在于高昂成本导致边际效益的严重递减。&nbsp;</p>
  <p>Anthropic CEO Dario Amodei 曾透露，随着模型变得越来越大，训练成本呈现爆炸式增长，其目前正在开发的 AI 模型的训练成本就高达 10 亿美元。&nbsp;</p>
  <p>Amodei 还指出，未来三年内，AI 的训练成本还将飙升到 100 亿美元甚至 1000 亿美元。&nbsp;</p>
  <p>以 GPT 系列为例，仅 GPT-3 的单次训练成本就高达约 140 万美元， 单是 GPT-3 的训练就消耗了 1287 兆瓦时的电力。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_98116f472550404f8f201161a82dc0ea@46958_oswg543853oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>去年，加州大学河滨分校的研究显示，ChatGPT 每与用户交流 25-50 个问题，就得消耗 500 毫升的水。&nbsp;</p>
  <p>预计到 2027 年，全球 AI 的年度清洁淡水需求量可能达到 4.2-66 亿立方米，相当于 4-6 个丹麦或半个英国的年度用水总量。&nbsp;</p>
  <p>从 GPT-2 到 GPT-3，再到 GPT-4，AI 所带来的体验提升是跨越式的。 正是基于这种显著的进步，各大公司才会不惜重金投入 AI 领域。&nbsp;</p>
  <p>但当这条道路逐渐显露尽头，单纯追求模型规模的扩张已无法保证性能的显著提升，高昂的成本与递减的边际效益便成了不得不面对的现实。&nbsp;</p>
  <p>现在，比起一味追求规模，在正确的方向上实现 Scaling 显得更加重要。&nbsp;</p>
  <h2><strong>再见，GPT；你好，推理 「O」&nbsp;</strong></h2>
  <p>墙倒众人推，连理论也是如此。&nbsp;</p>
  <p>当 Scaling Laws 疑似触及瓶颈的消息在 AI 圈内引发轩然大波时，质疑的声浪也随之翻涌而来。&nbsp;</p>
  <p>图灵奖得主、Meta AI 首席科学家 Yann Lecun，昨天兴奋地在 X 平台转载了路透社采访 Ilya Sutskever 的采访，并附文称：&nbsp;</p>
  <p>「我不想显得事后诸葛亮，但我的确提醒过你。&nbsp;</p>
  <p>引用：「AI 实验室 Safe Superintelligence（SSI）和 OpenAI 的联合创始人伊利亚·苏茨克韦尔（Ilya Sutskever）最近向路透社表示， <strong>通过扩大预训练阶段——即使用大量未经标注的数据来训练 AI 模型，使其理解语言模式和结构——所取得的成果已经停滞不前。</strong>」&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_2655638f206f4ce3ab31d4ee0fb850cd@46958_oswg224566oswg1080oswg594_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>回顾这位 AI 巨头过去两年对现行大模型路线的评判，可谓是字字珠玑，句句见血。&nbsp;</p>
  <p>例如，今天的 AI 比猫还笨，智力差太远；LLM 缺乏对物理世界的直接经验，只是操纵着文字和图像，却没有真正理解世界，强行走下去只会死路一条等等。&nbsp;</p>
  <p>时间拨回两个月前，Yann Lecun 更是毫不客气地给当下主流路线判了死刑：&nbsp;</p>
  <p>大型语言模型（LLMs）无法回答其训练数据中未包含的问题，&nbsp;</p>
  <p>它们无法解决未经训练的难题，&nbsp;</p>
  <p>它们无法在缺乏大量人类帮助的情况下学习新技能或知识，&nbsp;</p>
  <p>它们无法创造新的事物。目前，大型语言模型只是人工智能技术的一部分。单纯地扩大这些模型的规模，并不能使它们具备上述能力。&nbsp;</p>
  <p>在一众 AI 末日论中， 他还坚定地认为声称 AI 将威胁人类生存的言论纯属无稽之谈。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_21fb03e5a0c14f51899fd3ac13132ad3@46958_oswg506666oswg640oswg517_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>同在 Meta FAIR 任职的田渊栋博士则更早预见了当前的困境。&nbsp;</p>
  <p>5 月份在接受媒体采访时，这位华人科学家曾悲观地表示，Scaling Laws 也许是对的，但不会是全部。在他看来，Scaling Laws 的本质是以指数级的数据增长，来换取「几个点的收益」。&nbsp;</p>
  <p><strong>最终人类世界可能会有很多长尾需求，需要人类的快速反应能力去解决，这些场景的数据本身也很少，LLM 拿不到。&nbsp;Scaling law 发展到最后，可能每个人都站在一个「数据孤岛」上，孤岛里的数据完全属于每个人自己，而且每时每刻都不停产生。专家学会和 AI 融合，把自己变得非常强，AI 也代替不了他。 &nbsp;</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_ece1fc199cac4af6ac5a30b919531bb4@46958_oswg293577oswg600oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>不过，形势或许还没有到如此悲观的境地。&nbsp;</p>
  <p>客观而言，Ilya 在接受路透社的采访时，虽然承认了 Scaling Laws 带来的进展已趋于停滞，但并未宣告其终结。&nbsp;</p>
  <p><strong>「2010 年代是追求规模化的时代，而现在我们再次进入了一个充满奇迹和探索的新时代。每个人都在寻找下一个重大突破。在当下，选择正确的事物进行规模化比以往任何时候都更为关键。」</strong></p>
  <p>并且，Ilya 还表示 SSI 正在秘密探索一种新的方法来扩展预训练过程。&nbsp;</p>
  <p>Dario Amodei 最近在一档播客中也谈及此事。&nbsp;</p>
  <p>他预测，在人类水平以下，模型并不存在绝对的天花板。既然模型尚未达到人类水平，就还不能断言 Scaling Laws 已经失效，只是确实出现了增长放缓的现象。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_792ed27f0032427ab5b5e60337e63759@46958_oswg232953oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>自古，山不转水转，水不转人转。&nbsp;</p>
  <p>上个月，OpenAI 的研究员 Noam Brown 在 TED AI 大会上表示：&nbsp;</p>
  <p><strong>事实证明，在一局扑克中，让一个机器人思考 20 秒钟，得到的性能提升与将模型扩展 100000 倍并训练它 100000 倍长的时间一样。&nbsp;</strong></p>
  <p>而对于 Yann lecun 昨天的事后诸葛亮言论，他这样回应：&nbsp;</p>
  <p><strong>现在，我们处于一个这样的世界，正如我之前所说，进入大规模语言模型预训练所需的计算量非常非常高。但推理成本却非常低。&nbsp;曾有许多人合理地担心，随着预训练所需的成本和数据量变得如此庞大，我们会看到 AI 进展的回报递减。&nbsp;但我认为，从 o1 中得到的一个真正重要的启示是，这道墙并不存在，我们实际上可以进一步推动这个进程。&nbsp;因为现在，我们可以扩展推理计算，而且推理计算还有巨大的扩展空间。&nbsp;</strong></p>
  <p>以 Noam Brown 为代表的研究者坚信推理/测试时计算（test-time compute），极有可能成为提升模型性能的另一个灵丹妙药。&nbsp;</p>
  <p>说到这里，就不得不提到我们熟悉的 OpenAI o1 模型。&nbsp;</p>
  <p>与人类的推理方式颇为相似，o1 模型能够通过多步推理的方式「思考」问题，它强调在推理阶段赋予模型更充裕的「思考时间」。&nbsp;</p>
  <p>其核心秘密是，在像 GPT-4 这样的基础模型上进行的额外训练。&nbsp;</p>
  <p>例如，模型可以通过实时生成和评估多个可能的答案，而不是立即选择单一答案，最终选择最佳的前进路径。&nbsp;</p>
  <p>这样就能够将更多的计算资源集中在复杂任务上，比如数学问题、编程难题，或者那些需要人类般推理和决策的复杂操作。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_c45df46ebe71462b9c72c6112e87e6b1@46958_oswg115465oswg1000oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Google 最近也在效仿这条路线。&nbsp;</p>
  <p>The Information 报道称，最近几周，DeepMind 在其 Gemini 部门内组建了一个团队，由 Jack Rae 和 Noam Shazeer 领导，旨在开发类似的能力。&nbsp;</p>
  <p>与此同时，不甘落后的 Google 正在尝试新的技术路径，包括调整「超参数」，即决定模型如何处理信息的变量。&nbsp;</p>
  <p>比如它在训练数据中的不同概念或模式之间建立联系的速度，以查看哪些变量会带来最佳结果。&nbsp;</p>
  <p>插个题外话，GPT 发展放缓的一个重要原因是高质量文本和其他可用数据的匮乏。&nbsp;</p>
  <p>而针对这个问题，Google 研究人员原本寄希望于使用 AI 合成数据，并将音频和视频纳入 Gemini 的训练数据，以实现显著改进，但这些尝试似乎收效甚微。&nbsp;</p>
  <p>知情人士还透露，OpenAI 和其他开发者也使用合成数据。不过，他们也发现，合成数据对 AI 模型提升的效果十分有限。&nbsp;</p>
  <h2><strong>你好，贾维斯&nbsp;</strong></h2>
  <p>再见，GPT，你好，推理 「o」。&nbsp;</p>
  <p>在前不久举行的 Reddit AMA 活动上， 一位网友向 Altman 提问，是否会推出「GPT-5」，以及推理模型 o1 的完整版。&nbsp;</p>
  <p>当时，Altman 回答道：「我们正在优先推出 o1 及其后续版本」，并补充说，有限的计算资源使得同时推出多个产品变得困难。&nbsp;</p>
  <p>他还特别强调，下一代模型未必会延续「GPT」的命名方式。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_128d1221817b442fbc342546a97c20a4@46958_oswg535104oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>现在看来，Altman 急于与 GPT 命名体系划清界限，转而推出以「o」命名的推理模型，其背后似有深意。而推理模型的布局或许还是在于为当下主流的 Agent 埋下伏笔。&nbsp;</p>
  <p>最近，Altman 在接受 YC 总裁 Garry Tan 的采访时，也再次谈到了 AGI 五级理论：&nbsp;</p>
  <p>L1：聊天机器人具有对话能力的 AI，能够与用户进行流畅的对话，提供信息、解答问题、辅助创作等，比如聊天机器人。&nbsp;</p>
  <p>L2：推理者像人类一样能够解决问题的 AI，能够解决类似于人类博士水平的复杂问题，展现出强大的推理和问题解决能力，比如 OpenAI o1。&nbsp;</p>
  <p>L3：智能体不仅能思考，还可以采取行动的 AI 系统，能够执行全自动化业务。&nbsp;</p>
  <p>L4：创新者能够协助发明创造的 AI，具有创新的能力，可以辅助人类在科学发现、艺术创作或工程设计等领域产生新想法和解决方案。&nbsp;</p>
  <p>L5：组织者可以完成组织工作的 AI，能够自动掌控整个组织跨业务流程的规划、执行、反馈、迭代、资源分配、管理等，基本上已经与人类差不多。&nbsp;</p>
  <p>所以我们看到，与 Google 以及 Anthropic 一样，OpenAI 现在正在将注意力从模型转移到一系列称为 Agent 的 AI 工具上。&nbsp;</p>
  <p>今天凌晨，彭博社曝出，OpenAI 正在准备推出一款名为「Operator」的新型 AI Agent，能够使用计算机代替用户执行任务，如编写代码或预订旅行。&nbsp;</p>
  <p>在周三的一次员工会议上，OpenAI 领导层宣布计划在一月发布该工具的研究预览版，并通过公司的应用程序接口（API）向开发者开放。&nbsp;</p>
  <p>在此之前，Anthropic 也推出了类似的 Agent，够实时处理用户计算机任务并代为执行操作。 与此同时，微软近期推出了一套面向员工的 Agent 工具，用于发送邮件和管理记录。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_977969cabcf64e2d8d44acbba1847409@46958_oswg1336869oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>而 Google 也正在筹备推出自己的 AI Agent。&nbsp;</p>
  <p>报道还透露，OpenAI 正在进行多个与 Agent 相关的研究项目。其中，最接近完成的是一款能够在网页浏览器中执行任务的通用工具。&nbsp;</p>
  <p>这些 Agent 预计将能够理解、推理、规划并采取行动，而这些 Agent 实际上是一个由多个 AI 模型组成的系统，并非单一模型。&nbsp;</p>
  <p>比尔·盖茨曾经说过，「每个桌面上都有一台 PC」，史蒂夫·乔布斯说过，「每个人的手上都有一部智能手机」。&nbsp;</p>
  <p>现在我们可以大胆预测：每个人都将拥有自己的 AI Agent。&nbsp;</p>
  <p>当然，人类的终极目标是，我们更希望有一天能够对着眼前的 AI 说出那句电影的经典对白：&nbsp;</p>
  <p><strong>你好，贾维斯&nbsp;</strong></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Q_1CGxtJLl_hFulAzaHaBg" rel="noopener noreferrer nofollow" target="_blank">“APPSO”</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3035920137679745</id>
            <title>恢复物理按键，车企集体“返祖”，只因触摸屏安全隐患大？</title>
            <link>https://www.36kr.com/p/3035920137679745</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3035920137679745</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 10:45:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 触控屏, 物理按键, 驾驶安全, 用户体验  
<br><br>  
总结: 现代汽车承认将过多功能集成在触控屏上是错误的决策，计划在新车Ioniq 6中恢复物理按钮，以减少驾驶时的分心。多家汽车制造商如大众和保时捷也开始重新引入物理按键，回应用户对触控屏的不满。研究表明，物理按键在紧急情况下更易于操作，能有效提高驾驶安全性。未来，车企可能会在大屏与物理按键之间找到平衡，以满足用户需求并提升安全性。 </div>
                        <hr>
                    
                    <p>终于又有厂商站出来对触控屏说不了。最近现代汽车公开承认，<strong>将过多的功能集成在触控屏上是一个错误的决策。</strong></p>
  <p>事情是这样的，现代汽车即将推出Ioniq 6电动汽车，这款新车将配备一个带有物理按钮的中控台，而不是像特斯拉那样完全依赖触摸屏。</p>
  <p>现代汽车北美设计副总裁在接受采访时表示：“我们不想完全依赖触摸屏，因为这可能会导致用户在驾驶过程中分心。我们希望为用户提供一个更加直观和便捷的交互方式。在我们为车辆增加整合的信息娱乐系统时，也尝试将部分功能转移至触控屏控制，但用户并不喜欢。”</p>
  <p>同时还表示，通过团队焦点小组的测试，现代汽车<strong>发现人们在紧急情况下无法快速找到并控制所需功能时，会感到焦虑、烦躁，甚至愤怒。</strong></p>
  <p>最近，越来越多新车采用物理按键，看来，物理按键，还远远未到退场时。</p>
  <h2><strong>集体“返祖”，车企纷纷回归物理按键设计</strong></h2>
  <p>在汽车制造商中，现代汽车并不是唯一一家对触摸屏持怀疑态度的。大众也对触摸屏进行了评估，得出的结论跟现代相似。</p>
  <p>此前大众在高尔夫 Mk8 、ID.3 车型中，减少了车内物理按键数量，这导致了用户广泛投诉，大众首席执行官 Thomas Schäfer 承认，<strong>自家强调触摸屏的策略，对品牌“造成了很大损害”。</strong></p>
  <p>2023年，大众公司推出了一款 ID.2 all 概念车，该车便主打复兴“物理按键”，大众声称，这是对“客户最近反馈”的回应，而未来大众旗下新车内饰都将从 ID.2 all中汲取灵感，为车机带回更多物理按键。</p>
  <p>无独有偶，保时捷也在 2024 年款卡宴中恢复了物理按键和旋钮。宝马在iDrive 8系统中引入了触摸板，以减少用户在驾驶过程中使用触摸屏的频率。通用汽车也在其电动汽车中保留了物理按钮。</p>
  <p>新势力这边，小米SU7发布会上，雷军更是强调不能学习特斯拉做全触控，物理按键一定要有所保留。在中控区域，小米SU7设计了空调温度调节、空调风量调节、电动尾翼调节、空气悬挂调节四个物理按键，以及一键启动按键。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_0eef5323f36f4ef783fb8ee3918b6261@5687509_oswg379107oswg3000oswg2000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：小米汽车官网</p>
  <p>不止如此，小米SU7还支持磁吸外接实体按键，虽然采用了16.1英寸的超大中控屏，但发布会上官方展示了磁吸式的实体按键，搭上去毫无违和感。</p>
  <p>或许是新能源汽车进程太过迅猛，智能车机所带来的科技感过于强烈，特斯拉带来的吸引力太大，搞得众多车企都在“有样学样”，搞出各种极其科幻的大屏设计，甚至还有更激进的二联、三联巨屏。</p>
  <p>但问题又来了，特斯拉这么做，就代表是对的吗？</p>
  <h2><strong>触摸屏存短板，用户早已苦不堪言</strong></h2>
  <p>事实上，汽车控制台要不要取消所有的物理按键改成触摸屏，一直是行业的争论焦点。</p>
  <p>支持取消物理按键的人认为，现在的汽车厂商都转投触摸屏的怀抱，证明了触摸屏就是汽车的未来，物理按键被淘汰，是迟早的事。触摸屏和物理按键，就如 iPhone 之于诺基亚，优势非常明显。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_782e57cef99046f3b44ea09e00697b0c@5687509_oswg218597oswg1114oswg707_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：HMD官网&nbsp;</p>
  <p>反对取消物理按键的人认为，汽车和手机是不一样的，不能类比，触摸屏会带来一定的驾驶危险性。</p>
  <p>触摸屏最大的弊病，是驾驶员要操作时必须看屏幕，这样注意力就无法集中在路面上。相比之下，物理按键还能通过位置感进行“盲按”，驾驶员可保证视线不离开路面，触摸屏因为触觉一样，就无法做到。</p>
  <p>一旦路面出现状况，驾驶员的反应时间不足，很容易造成交通意外。</p>
  <p>2022年，瑞典汽车杂志Vi Bilägare展开了一项研究，主要研究两个问题：</p>
  <p><strong>触摸屏真的比物理按键好吗？</strong></p>
  <p><strong>触摸屏会不会更容易影响行驶安全？</strong></p>
  <p>为此他们找来了12辆不同汽车，分别是纯物理按键、物理+触控、纯触控。值得一提的是，司机在测试之前，有足够时间了解这些车机操作系统，而且全程都是手动操作，不涉及语音交互，所以不存在司机对测试车辆不熟悉的情况。</p>
  <p>测试流程是在开车时进行连续四项任务操作，看哪辆车用的时间最少，行驶的路程最短。连续操作的四项任务分别是：</p>
  <p><strong>打开座椅加热，空调调高2℃，打开除霜；</strong></p>
  <p><strong>打开收音机，调到指定电台；</strong></p>
  <p><strong>小计里程清零；</strong></p>
  <p><strong>仪表亮度调到最暗，关闭中控屏。</strong></p>
  <p>在110km/h的行驶速度下，4项任务连续操作下来，12款不同汽车用时如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_d59cbebfbe8d49c3b1d5b91fe64baecc@5687509_oswg184827oswg1080oswg834_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：Vi Bilägare&nbsp;</p>
  <p>综合来看，表现最好的是2005年的老款沃尔沃V70，全部都是物理按键，却独占鳌头，仅用时10秒就完成了全部操作。</p>
  <p>成绩最差的是上汽名爵Marvel R，这也是一款“大屏幕”汽车，整整用了44.9秒，汽车行驶了1372m。而特斯拉Model 3，排名第6，用时23.5秒，行驶距离为717m。</p>
  <p>其他排名相对靠前的都是物理按键为主，一番测试后直接判定——<strong>物理按键确实比触摸屏更胜一筹</strong>。</p>
  <p>不过，他们并非完全否定触摸屏，而是认为简洁明了的屏幕UI设计+物理按键搭配起来使用，对司机来说更友好更安全。同时还补充说，某些功能用物理按键的话，驾驶会变得轻松很多。</p>
  <p>不得不承认，触控屏在使用上确实不方便，一些厂商总喜欢标榜自己的座舱有多数字化，将车内的物理按键与机械仪表盘尽数“抹杀”，取而代之的就是越来越多、越来越大的屏幕。功能基本集成到车机内，想用它就得像手机一样点进相关的菜单寻找。</p>
  <p>这导致许多用户在首次接触新能源汽车时，对车机上的内容都很陌生，生怕自己按错什么。为了找一个功能，甚至要点进二三级菜单，实在是令人苦不堪言。越来越多的吐槽与投诉，让车企不得不重新审视汽车的“本质”，并计划让物理按钮重新回到汽车上。</p>
  <h2><strong>安全第一，恢复物理按键或成大势所趋</strong></h2>
  <p>年初，欧洲新车安全评鉴协会（Euro NCAP）宣布，将在2026年实施的新测试中，降低过分依赖触控操作的汽车的安全性评分，强烈建议汽车厂商为转向灯、危险警示灯、雨刮器、喇叭以及欧盟的eCall紧急呼叫等功能配备实体控制装置。</p>
  <p>Euro NCAP战略发展总监Matthew Avery表示，<strong>触控操作的泛滥是整个汽车行业的问题，几乎所有的厂商都在将重要功能转移到中控触控屏上，这迫使驾驶员将视线从道路移开，增加了因注意力分散而引发事故的风险。</strong></p>
  <p>未来实施的测试新标准中，车企是否有针对重要功能提供对应的实体控制按键，也会影响到最终评分，对于想要获得最高评分的车企而言有一定的约束力。&nbsp;</p>
  <p>外界认为，受新测试标准影响最大的品牌是特斯拉。</p>
  <p>2022年9月7日，特斯拉中国官网显示，Model Y在Euro NCAP（2020-2022评分标准）测试下获得最高五星安全评级，乘员保护测试环节当中获得97%的优异成绩，一举拿下总分榜第一。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_6b35c54f05d84e6da906e1636e3be53c@5687509_oswg141001oswg1080oswg522_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：Euro NCAP</p>
  <p>如果按照Euro NCAP新的测试标准，那特斯拉估计要失去高分成绩了，国内一些新势力也将会在安全方面得不到高分评价，这对营销肯定也会有一定的影响，毕竟NCAP测试成绩已成为不少新势力在发布会上吹嘘的资本。如果失去NCAP测试的背书，那他们建立的所谓“安全大厦”将会轰然倒塌。</p>
  <p><strong>当然，我们说的恢复物理按键，并不是说回到过去老年机即视感的车机，而是在与大屏搭配，重点功能采用物理按键，其他娱乐功能用触控。</strong></p>
  <p>同济大学车辆工程博士、人车关系实验室负责人龚在研，与电车通的观点不谋而合。</p>
  <p>他将按键和大屏的问题归为一个矩阵模型，他认为步骤较少、目标非常封闭的情况下，如空调温度调节等基础操作，采用物理按键是有价值的。但是一些步骤较多、目标非常开放，如呼叫联系人、氛围灯设置等功能，用语音和触屏更为高效。</p>
  <p>他这么描绘物理按键和触摸屏的未来：</p>
  <p><strong>未来按钮不会消失，会以更加简单化、集成化、艺术化的方式呈现，大屏将从简单的点触到智能推荐进化。</strong></p>
  <p>不是要消灭物理按键，也不是要取消触摸设计，两者共存，才是最优解。</p>
  <h2><strong>写在最后</strong></h2>
  <p>曾经，张朝阳和冯仑在一档节目中聊到人工智能和科技的相关话题。张朝阳提到，高级的东西是最简单、最原始的，有时候跟风高科技没必要，一味追求科技可能并不方便。</p>
  <p>他举例说住酒店，并不喜欢弄一个仪表盘灯控制，就希望有一个木杆的台灯，绳一拉就关了。</p>
  <p>车企回归物理按键，也是同样的道理，明明空调开关一按就行，不是非得集成在屏幕里。<strong>科技的加持，只有精准地用对了地方，才能提供价值，对用户才是有用的、方便的。</strong>车企回归物理按键，说明车企也开始重视用户需求，不再只是一味追求“科技感”。</p>
  <p>封面图源：特斯拉官网</p>
  <p>本文来自“电车通”，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3035960852460416</id>
            <title>谷歌员工曝AI改进速度放缓，Gemini已成立新团队解决问题</title>
            <link>https://www.36kr.com/p/3035960852460416</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3035960852460416</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 10:39:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, Gemini, 模型性能, scaling law  
<br><br>  
总结: 谷歌正在努力提升其聊天机器人产品Gemini的性能，但面临模型性能提升速度放缓的问题，类似于OpenAI的遭遇。尽管谷歌投入了大量算力和训练数据，性能提升未达到高管的期待，且过去版本的Gemini改进速度更快。研究人员发现，传统的scaling law方法在当前情况下似乎不再有效。谷歌正在重新考虑训练数据的处理，并尝试手动改进模型。两大AI巨头的技术瓶颈可能导致行业对“AI泡沫”的担忧，未来AGI的实现仍需突破这些技术挑战。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_49f2d30150c842e79229a0ee89cc14ad@453363432_oswg543616oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>智东西11月14日消息，据外媒The Information报道，一位参与工作的内部人士称，谷歌最近一直在为提升其聊天机器人产品Gemini的性能而努力，该公司希望模型性能提升的速度可以与去年相当，这促使研究人员专注于其他方法来勉强取得效果。</p>
  <p>这种情况和OpenAI的遭遇类似。此前有报道称，OpenAI模型性能提升速度有所放缓，该公司正改变技术策略来解决问题。</p>
  <p>回到谷歌本身，上述人士称，谷歌在投入了大量算力和训练数据，如来自网页的文本和图像后，并没有实现一些高管所期待的性能提升。当研究人员使用更多的数据和算力来训练模型时，过去版本的Gemini大模型改进速度更快。</p>
  <p>谷歌的经历是scaling law（缩放定律）受到考验的另一迹象。许多研究人员认为，只要使用更专业的AI芯片来处理更多的数据，模型就会以相同的速度改进。但目前来看，这两个因素似乎远远不够。</p>
  <p>这个问题成为谷歌的心头大患。因为在开发者和客户数量方面，Gemini模型落后于OpenAI的GPT模型，而谷歌一直希望它在算力资源方面的优势，可以助力它在模型性能方面超越OpenAI。与此同时，两家公司都在开发由现有技术版本提供支持的新产品，这些产品可以帮助软件程序员和其他办公人员，在处理繁琐及复杂工作时，实现自动化。</p>
  <p>“我们对在Gemini上看到的进展很满意，在合适的时机我们会披露更多消息。”谷歌发言人称，公司正在重新考虑如何处理训练数据并在数据上大量投资。这位发言人说，谷歌还成功地加快了模型的响应速度，这“对于以谷歌的规模提供AI服务很重要”。</p>
  <p>在OpenAI，研究人员发明了推理模型等新技术，以弥补在模型训练阶段，使用传统scaling law技术导致的性能提升放缓问题。谷歌似乎也在效仿。最近几周，DeepMind在其Gemini部门内组建了一个团队，该团队由首席研究科学家Jack Rae和前Character.AI联合创始人Noam Shazeer领导，旨在开发类似OpenAI推理模型的能力。</p>
  <p>开发Gemini的研究人员也一直专注于对模型进行手动改进。参与这项工作的人说，改进工作包括更改它们的“超参数（hyperparameters）”，或者是决定模型如何处理信息的变量，比如，模型在训练数据中不同概念或模块之间建立联系的速度。研究人员在称为“模型调优（model tuning）”的过程中测试不同的超参数，以检验哪些变量会带来最佳结果。</p>
  <p>上述人士说，谷歌在其传统方法中遇到的一个问题是，它在用于开发Gemini的数据中发现了相同信息的副本。他们说，这可能损害了Gemini的表现。对此，谷歌发言人回复称，此类问题对团队来说并不新鲜。</p>
  <p>另外，该人士还透露，谷歌研究人员曾尝试使用AI生成的数据（也称为合成数据），以及音视频作为Gemini的训练数据来改进模型性能，但没有产生显著效果。</p>
  <h2><strong>结语：巨头遇到瓶颈，“AI泡沫”还是AGI？</strong></h2>
  <p>一周时间，OpenAI和谷歌这两大AI巨头接连被爆出模型性能提升缓慢问题，且目前来看两家公司都没有找到有效解法，scaling law的有效性受到挑战。</p>
  <p>从公司个体来看，两巨头的技术领先地位将面临极大挑战；从行业来看，技术瓶颈长期无解可能会导向悲观派所说的“AI泡沫”。</p>
  <p>世界离AGI还有多远？还要看这些巨头公司们多久突破技术瓶颈。</p>
  <p>来源：The Information</p>
  <p class="editor-note">本文来自微信公众号“智东西”，编译：依婷，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3035978333532422</id>
            <title>80后Keras之父从谷歌正式离职，谷歌两位重量级VP联名感谢</title>
            <link>https://www.36kr.com/p/3035978333532422</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3035978333532422</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 10:35:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Keras, François Chollet, 谷歌, 深度学习  
<br><br>  
总结: 谷歌宣布Keras之父François Chollet正式离职，尽管离开谷歌，他承诺将继续参与Keras的未来发展，并支持JAX、TensorFlow和PyTorch。Keras是一个拥有超过200万用户的深度学习框架，已成为人工智能开发的基石，简化了复杂的工作流程。Chollet的离职引发了广泛讨论，部分观点认为Keras在谷歌的战略地位正在下降，可能被竞争对手Anthropic挖走。Keras的设计灵感源于对循环神经网络的兴趣，最初并不依赖特定的计算引擎，后来与TensorFlow紧密结合，成为其官方高级API。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_1f308811aa47438d8dc9733b13482d09@000000_oswg82673oswg1080oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>谷歌宣布Keras之父François Chollet正式离职。</p>
  <p>今日，谷歌官方网站Google for Developers页面发布了一条重要消息：<strong>Keras之父François Chollet正式离职。</strong></p>
  <p>谷歌两位重量级VP，Bill&nbsp;Jia和Xavi Amatriain联名发布了这封公开感谢信（见文章末尾），公布了François&nbsp;Chollet离职的消息，并表达谷歌的Keras团队也将继续与François&nbsp;Chollet的开源社区保持合作。&nbsp;</p>
  <p>François&nbsp;Chollet在谷歌工作了9年零3个月，尽管离开了谷歌，也承诺将继续参与Keras的未来发展，并继续支持JAX、TensorFlow和PyTorch上的工作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b29eeb4d4e054383abfd699b03f0f4fc@000000_oswg104942oswg1080oswg543_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Keras是一个拥有超过200万用户的深度学习框架，当下已经成为人工智能开发的基石，它简化了复杂的工作流程，让顶尖技术的获取变得更加民主。</p>
  <p>从Waymo的自动驾驶汽车到YouTube、Netflix和Spotify的推荐系统，Keras为谷歌和全球的众多应用都提供了动力，也是深度学习领域不可或缺的一部分。</p>
  <h2><strong>François Chollet到底被谁挖走了</strong></h2>
  <p><strong>关于François Chollet未来的职业规划，目前谷歌和Chollet本人都未对外公布具体信息。</strong></p>
  <p><strong>对于他的离职，网上引发了广泛讨论。</strong></p>
  <p>部分观点认为，鉴于Keras的当前发展态势，在谷歌战略中的地位正在下降，甚至有传言称TensorFlow（深度学习框架）未来可能不会得到积极维护，谷歌可能已经将重心转移到了JAX上。 （在TensorFlow 2.0发布后，Keras就完全集成到了TensorFlow中，成为其默认的模型构建工具。）&nbsp;</p>
  <p>同时，也有意见指出，PyTorch（深度学习框架）的流行度已经显著超越了TensorFlow，特别是在大型语言模型领域，PyTorch占据了更大的市场份额。&nbsp;</p>
  <p>此外，<strong>一些网友推测François可能被竞争对手Anthropic挖走，</strong>但这些仅仅是猜测。&nbsp;</p>
  <h2><strong>François Chollet的背景以及Keras的诞生</strong></h2>
  <p>François Chollet，1989年10月20日出生于法国，是人工智能领域的知名人物，他不仅在Keras上有重大贡献，还持续探索前沿技术，如通用人工智能抽象与推理语料库(ARC-AGI)和ARC Prize竞赛。&nbsp;</p>
  <p>他与迈克·诺普共同创建了ARC-AGI比赛，旨在衡量AGI获取新技能和高效解决新颖、开放性问题的能力。&nbsp;</p>
  <p>2024年的9月，他还被《时代》杂志评为人工智能领域最具影响力的 100 人之一。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_79afe005790d4e41887a122c1ab07c74@000000_oswg632276oswg1080oswg598_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>2012年从巴黎综合理工学院获得工程硕士学位后，François&nbsp;进入美国工作，先后在FreshPlanet和Thunder担任软件工程师和机器学习架构师，2015年加入谷歌，并参与了Keras的开发。&nbsp;</p>
  <p>Keras的诞生源于François对循环神经网络（RNN）产生的浓厚兴趣。当时的深度学习工具，如Caffe和Theano，无法很好地支持循环神经网络，尤其是缺乏有效的LSTM实现。&nbsp;</p>
  <p><strong>因此，François决定自己动手开发一个框架，Keras应运而生。</strong></p>
  <p>最初，Keras主要集中于LSTM和RNN的实现，采用Python代码定义模型，这与当时主流的静态配置文件（如Caffe的YAML文件）不同。Keras的出现填补了当时深度学习框架中的空白，迅速吸引了大量开发者的关注。&nbsp;</p>
  <p>Keras的设计灵感部分来自于François对scikit-learn库的喜爱，他认为Keras几乎就像是为神经网络打造的scikit-learn。&nbsp;</p>
  <p>最初，Keras并不依赖特定的计算引擎，它支持Theano、Microsoft CNTK和TensorFlow等后端。其模块化设计允许用户组合不同类型的层（如全连接层、卷积层、循环层），从而快速搭建复杂模型。&nbsp;</p>
  <p>Keras的统一接口使得模型的训练、验证和测试过程变得更加顺畅，既适合原型设计，也能够应对生产环境中的复杂需求。&nbsp;</p>
  <p>随着TensorFlow的快速发展，Keras与TensorFlow的关系日益紧密。&nbsp;</p>
  <p>2017年，Keras成为TensorFlow的官方高级API，TensorFlow 2.0发布后，Keras完全融入TensorFlow，成为其默认的模型构建工具。&nbsp;</p>
  <p>这一变化使得Keras能够无缝调用TensorFlow的底层功能，从而提升了性能和可扩展性。&nbsp;</p>
  <p>随着Keras逐步被整合为TensorFlow的一部分，其作为独立库的角色逐渐被淡化，tf.keras成为TensorFlow官方的高级API，也成为了深度学习社区的标准选择之一。&nbsp;</p>
  <p>多年来，Keras也在不断迭代优化。&nbsp;</p>
  <p>Keras 3.0版本在去年年底发布，它不仅支持TensorFlow、PyTorch和JAX等主流框架作为后端，还能在它们之间无缝切换，甚至可以混合使用。 <strong>被认为是机器学习领域的一个重要进步，尤其在开源社区的影响力和性能优化方面，提供了多重优势。</strong></p>
  <p>附ill&nbsp;Jia和Xavi Amatriain联名信原文：&nbsp;</p>
  <p>Today, we're announcing that Francois Chollet, the creator of Keras and a leading figure in the AI world, is embarking on a new chapter in his career outside of Google. While we are sad to see him go, we are incredibly proud of his immense contributions and excited to see what he accomplishes next.&nbsp;</p>
  <p>With over two million users, Keras has become a cornerstone of AI development, streamlining complex workflows and democratizing access to cutting-edge technology. It powers numerous applications at Google and across the world, from the Waymo autonomous cars, to your daily YouTube, Netflix, and Spotify recommendations.&nbsp;</p>
  <p>Importantly, Francois remains deeply committed to the future of Keras and its continued support for JAX, TensorFlow, and PyTorch. He will continue contributing to the project and overseeing its roadmap. The Keras team at Google will continue to collaborate with Francois in the open-source community, and wish him all the best in his future endeavors.&nbsp;</p>
  <p>Google’s continued investment in Keras 3 demonstrates our commitment to support major ML frameworks and offer ML developers framework optionality. Our recent launch of&nbsp;Keras Hub&nbsp;is also a significant step towards democratizing access to powerful AI tools and accelerating the development of innovative multimodal applications.&nbsp;</p>
  <p>Francois, thank you for everything. Your contributions have left an indelible mark on machine learning frameworks and the broader AI landscape. We encourage everyone to continue following Francois’s work. Stay connected with him and the Keras project through.&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA5NTI1MDEyNA==&amp;mid=2652718717&amp;idx=1&amp;sn=9dc57014720c936a24f72d5be0896ab8&amp;chksm=8a3a9163c17222f00a7da1428b19c461f71f2f4b7860c0d829490135af253ea18dd50a5af6e3&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“亿欧网”（ID：i-yiou）</a>，作者：不寒，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036079142875137</id>
            <title>业绩快报｜B站发布2024年Q3财报：毛利润同比增长76%，首次实现单季度盈利</title>
            <link>https://www.36kr.com/p/3036079142875137</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036079142875137</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 10:32:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: B站, 财务报告, 用户增长, 盈利  
<br><br>  
总结: B站在2024年第三季度的财务报告显示，总营收同比增长26%，达73.1亿元人民币，首次实现单季度盈利。日均活跃用户达1.07亿，广告和游戏业务收入分别增长28%和84%。毛利润同比增长76%，毛利率提升至34.9%。此外，B站在“双11”期间的带货GMV同比增长154%，广告主数量显著增加。有效大会员数量达到2197万，增值服务收入稳步增长。内容消费方面，游戏、知识和科技类视频播放量均保持20%以上的增长。UP主收入也显著提升，付费内容逐渐成为共识。 </div>
                        <hr>
                    
                    <p>北京时间11月14日（美东时间11月14日），哔哩哔哩（NASDAQ:&nbsp;BILI，HKEX:9626；以下简称“B站”）公布了截至2024年9月30日的第三季度未经审计的财务报告。第三季度，B站总营收同比增长26%，达73.1亿元人民币。其中，增值服务、广告、游戏和IP衍生品及其他业务分别贡献了收入的38%、29%、25%和8%。</p>
  <p>三季度，B站日均活跃用户达1.07亿，月均活跃用户达3.48亿，日均使用时长从去年同期的100分钟增加到106分钟。</p>
  <p>B站广告业务收入为20.9亿元，同比增长28%；游戏业务收入为18.2亿元，同比增长84%，带动了B站毛利润同比大幅提升76%，毛利率连续9个季度环比提升至34.9%。本季度，B站调整后净利润2.4亿元，实现上市后首次单季度盈利。</p>
  <p>广告方面，三季度收入同比增长28%，达20.9亿元，其中效果广告同比增长近五成。游戏、电商、数码家电、网络服务、汽车成为了广告收入贡献前五的行业。来自教育、母婴、文旅等新兴行业广告收入增长迅速，同比增长超100%。</p>
  <p>“双11”期间，B站带货GMV同比去年大促期高速增长154%，广告主数量是去年同期的6.6倍。同时，B站坚持“大开环”战略，给全部垂直行业带去的新客率均超50%，成为了各大平台新客增长的重要来源。</p>
  <p>游戏方面，三季度游戏收入同比大幅增长84%，为18.2亿元。《FGO》、《碧蓝航线》等长线运营游戏收入稳定。《三国：谋定天下》在S3上线当天重返iOS畅销榜第二，证明了其长线运营的潜力。</p>
  <p>此外，增值服务也实现了稳步增长，收入达28.2亿元。截至三季度末，有效大会员数量2197万，其中超80%是年度订阅或自动续费会员。</p>
  <p>三季度公司毛利润同比增长76%，达25.5亿元。毛利率由去年同期25.0% 提升至本季度的34.9%，实现了连续九季度的环比提升。三季度，公司首次实现盈利，调整后经营利润达2.7亿元，调整后净利润达2.4亿元。</p>
  <p>此外，公司现金流情况良好，在三季度实现22.3亿元正向运营现金流。截至2024年9月30日，公司持有现金及现金等价物、定期存款和短期投资总额为152亿元人民币。</p>
  <p>在现金流持续健康的基础上，B站宣布了一项新的股份回购计划，将在未来24 月内累计回购价值不超过 2亿美元的股票。</p>
  <p>三季度，B站日均视频播放量超57亿次，同比大幅增长23%，月均互动量超193亿次。截至三季度末，有2.51亿用户通过了入站考试，成为B站的“正式会员”，第12个月留存率继续稳定在80%。</p>
  <p>内容方面，三季度，游戏、知识、科技等品类，播放量均同比保持20%以上的增长。4年前，《黑神话：悟空》首个实机演示视频在B站上传，播放量超6000万；在游戏正式发售后，社区内诞生了一批超千万播放量的爆款内容，掀起了全网的黑神话热潮。2024年，B站AIGC相关内容的观看量突破300亿次，众多AI前沿的研究人员，如中国工程院院士郑纬民，前亚马逊首席科学家李沐，前Open AI安全性研究副总裁翁荔，复旦大学赵斌教授等也来到B站。</p>
  <p>用户年龄的增长，带动了消费类内容的繁荣。三季度，消费类内容日均观看人数超过4000万，也让汽车品类的视频播放量同比增长超过40%，运动健身品类同比增长超80%。与此同时，女性用户展现出旺盛的内容消费需求，时尚品类播放量同比增长近30%，母婴亲子类播放量同比增长超60%。</p>
  <p>今年以来，近270万UP主在B站获得收入，其中通过广告和增值服务获得的总收入同比增长24%；为优质内容付费已逐渐成为共识，UP主通过充电获得的总收入同比增长超400%，头部UP主的充电人数更能达到百万量级。</p>
  <p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036005038650501</id>
            <title>Kimi罗生门：创始人、投资人，谁的错？</title>
            <link>https://www.36kr.com/p/3036005038650501</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036005038650501</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 10:26:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 月之暗面, 创始人, 同意豁免书, 投资争议  
<br><br>  
总结: 月之暗面是一家新兴创业公司，因创始人杨植麟和张宇韬在未获得投资方同意的情况下创立新公司而引发争议。五家投资方指控两位创始人违反投资协议，未获得“同意豁免书”便启动融资。尽管创始人否认指控，称其行为合法，争议双方各执一词，形成对立局面。投资人认为创始人缺乏契约精神，而创始人则指责投资方短视和贪婪。此事件不仅涉及法律问题，也引发了舆论战，双方可能需要重新谈判以达成共识。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_2e666ab300e64608aefed4416b6e879d@5994784_oswg16513oswg1080oswg269_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>月之暗面，一家成立不到2年时间、估值超过30亿美元、其产品（Kimi）可以与百度字节同台竞技的明星创业公司，正在陷入一场争议。&nbsp;</p>
  <p>这场争议，事关创始人声誉，和公司前景。&nbsp;</p>
  <p>根据36氪报道，循环智能（月之暗面创始人杨植麟、联合创始人兼CTO张宇韬此前所在公司）的5<strong>家投资方在香港提起仲裁，指控杨植麟和张宇韬在没有拿到循环智能投资方的同意豁免书之前，就创立月之暗面并启动融资。</strong></p>
  <p>月之暗面公司和两位创始人没有公开回应这一指控，接受杨植麟、张宇韬委托的律师事务所对媒体表示：“该事项既缺乏法律依据，也不具备事实基础，本所将依法提出抗辩”。&nbsp;</p>
  <p>而在不少媒体报道中，前述<strong>5家投资方（金沙江创投、万物资本、靖亚资本、华山资本和博裕资本）被描述成“见利忘义”、“狮子大开口”的形象。</strong>详细的爆料包括：&nbsp;</p>
  <p>1.这些投资方起初并不看好月之暗面，没有选择跟投。月之暗面后来估值暴涨，让这些投资方产生了巨大的心理落差（动机猜测）；&nbsp;</p>
  <p>2.创立月之暗面时，杨植麟获得了循环智能CEO陈麒聪及主要股东的支持，循环智能获得月之暗面的股权作为回报。陈麒聪向公司股东发出情况说明邮件，通知该方案，获得股东确认，并得到董事会批准（事实推翻）；&nbsp;</p>
  <p>3.今年年初，前述投资方提出希望获得月之暗面创始团队约一半的股权，彼时价值约1亿美元（诉求夸张）。&nbsp;</p>
  <p>需要说明的是，上述爆料内容并没有实名且权威的出处，也没得到当事双方的确认。&nbsp;</p>
  <p>可以看到，争议双方（直接/间接）自说自话，表达的“事实”、“观点”和他们的立场一样，截然对立。&nbsp;</p>
  <p><strong>在投资人眼中，杨植麟、张宇韬是不遵守商业规则、没有契约精神的创业者；而在两位创业者眼中，投资人起初没有远见、后来见钱眼开、短视且贪婪。</strong></p>
  <p>真相，究竟如何？随着事态推进，相信会有更多的事实被揭露出来。&nbsp;</p>
  <p>这里，我们做一些必要的科普、梳理和分析。&nbsp;</p>
  <h2><strong>另起炉灶是否合理？</strong></h2>
  <p>先介绍下背景。&nbsp;</p>
  <p>2016年，杨植麟和张宇韬、陈麒聪三位90后学霸创立了循环智能，三人股权平分，后来公司得到了来自于本次发起仲裁的五位投资方（金沙江创投、靖亚资本、博裕资本、华山资本和万物资本）以及红杉资本、真格基金的投资。&nbsp;</p>
  <p>去年年初，在OpenAI的带领下，国内外大厂纷纷开卷大模型，上演了“百模大战”，杨植麟和张宇韬由于看好大模型的发展，便另起炉灶创立了月之暗面。&nbsp;</p>
  <p>问题来了，<strong>为什么他们不在循环智能原来的主体里做大模型创业，而是选择单飞？</strong></p>
  <p>综合杨植麟的公开发言和知情人士分析，主要有三点原因：&nbsp;</p>
  <p>首先，新业务和原业务方向不同。循环智能是一家做toB型产品的公司，主要提供营销客服相关的AI软件，为企业降低和客户的沟通成本。月之暗面的明星产品Kimi，则是一款基于自研大模型的toC型应用。&nbsp;</p>
  <p>其次，两家公司的权力结构不同。循环智能CEO是陈麒聪，CTO是张宇韬，首席科学家是杨植麟，三人股份占比相同。而在月之暗面，杨植麟是绝对大股东。&nbsp;</p>
  <p>第三，两家公司不同的业务方向也决定了融资需求存在很大差距。大模型烧钱是公认的，最典型的例子便是OpenAI每天要烧掉70万美元。如果杨植麟和张宇韬想做大模型，比起说服老股东认可新方向、投入更多钱，不如创立新公司，拉愿意花钱、相信大模型的新股东入伙来得轻松。&nbsp;</p>
  <p>可见，杨植麟和张宇韬另起炉灶做大模型存在一定的合理性，但也因此带来了不少麻烦。&nbsp;</p>
  <p><strong>一般情况下，投资人不愿意接受所投公司的创始人或者核心团队出走再创业，特别是在AI行业。</strong></p>
  <p>投资人曹海涛告诉我们，AI行业最重要的便是人，本次出走的杨植麟、张宇韬两人均曾在循环智能担任重要职位（而且是主要股东），这便导致原公司核心竞争力受到不小影响，而且他们出走时循环智能还处在正常运营状态。&nbsp;</p>
  <h2><strong>为什么需要同意豁免书？</strong></h2>
  <p>双方在拉扯自证的过程中，都反复提到了“同意豁免书”。&nbsp;</p>
  <p>五位老股东提出的仲裁理由是，杨植麟没有拿到“同意豁免书”便创立了月之暗面，违背了投资条款。但一位接近月之暗面的知情人士告诉我们，循环智能CEO陈麒聪当时通知了各位老股东，方案也过了会。&nbsp;</p>
  <p>什么是同意豁免书？对投资人和创业者起到的作用是什么？&nbsp;</p>
  <p>在投资领域，创业者和投资方会签订一个投资协议，里面涉及全职条款、竞业条款等内容，如果创业者的新公司和原公司属相同领域，便需要得到老股东签署的同意豁免书，表示同意放弃对创始人或核心团队成员离开原公司后的某些限制条款。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_feb2dcc473264ac4ba2df4c3594c5340@5994784_oswg86309oswg1080oswg864_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>不止一位投资人表示，他们很不愿意接受创始人新创公司和原公司为同一类型，因为很容易造成竞争。循环智能和月之暗面都属于AI领域，也就是说，<strong>如果杨植麟没有拿到老股东的同意豁免书，很可能会违背竞业条款，甚至需要承担相关法律责任。</strong></p>
  <p>北京市盈科律师事务所曲虹潭律师告诉我们，若合同约定，创业者在实施相关行为前，需要得到投资人的书面确认，比如电子邮件、书面签字等形式予以确认，且该约定系各方真实意思表示，也不违反法律的效力性、强制性规定，那么创业者需要依约履行合同义务，获得“同意豁免”，否则可能会承担违约责任。&nbsp;</p>
  <p>可见，同意豁免书是这个争议的核心。&nbsp;</p>
  <h2><strong>最关键的问题是什么？</strong></h2>
  <p>目前，双方对杨植麟是否获得“同意豁免书”各执一词，这也正是此次罗生门中的关键问题。&nbsp;</p>
  <p>老股东称杨植麟没有拿到几个资方的同意豁免书，便启动了月之暗面的融资和创立。但对方间接予以否认，并用“向股东发出情况说明邮件、获得股东确认、得到董事会批准”进行了回应。不过，这里面的措辞十分值得玩味，<strong>有人认为，“发邮件”、“董事会批准”和拿到同意豁免书是两回事。</strong>显然，这些说辞没有对“是否所有股东都接受、认可、批准”作出明确说明。&nbsp;</p>
  <p>有不少投资人分析，双方应该有过沟通，但当时月之暗面处在大模型创业的关键窗口期，很有可能在没有得到所有股东的同意、过会，双方没有完全谈拢、谈细的情况下，杨植麟便创立了新公司。&nbsp;</p>
  <p>资深投资人陈悦天还告诉我们，虽然同意豁免书属于正规法律文件，但在具体执行过程上经常会出现瑕疵，这也让本次事件相对复杂。<strong>“这并不是一份容易签署的文件，需要老股东和创业者进行多次沟通，就各方面利益和权利问题达成一致意见。”</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_1738456059824662bdff0ad60ed932c5@5994784_oswg67867oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>“比如评估原公司循环智能是否还具备发展前景，两位核心创始人离开后是否会对原公司产生重大影响，新公司创立后如何评估价值、并给予老股东多少股份或其他补偿等问题，都需要一家家进行反复沟通，但月之暗面融资很急，留给双方讨论的时间应该很短，而且创业者很可能不擅长这方面内容。”陈悦天表示。&nbsp;</p>
  <p>而且<strong>在创投圈，很多投资人和创业者也经常没有把同意豁免书当成一件大事</strong>，“虽然是个大雷，但常见的情况是沟通比较顺利，大家也不会太在意。”他补充。&nbsp;</p>
  <p>唯一确定的是，有没有拿到“同意豁免书”会成为决定创业者和投资人孰是孰非的最关键问题。&nbsp;</p>
  <h2><strong>争议公开，是为了打舆论战？</strong></h2>
  <p>老股东申请仲裁，月之暗面派出律师抗辩，表面上看双方要通过法律手段解决矛盾。但从业者认为，这更像是一场舆论战：<strong>老股东想通过舆论向月之暗面施压，逼迫其坐回到谈判桌前，双方重新谈股份占比</strong>，而不是想把杨植麟和月之暗面干掉。&nbsp;</p>
  <p>关于新老公司的股份转换问题，陈悦天表示，没有通用原则，都是靠谈的，一般按照原公司的基础股份占比计算。如果老公司经营不下去，新公司又成功了，创业者道义上应该为以前的投资人留出相当于投资本金+利息（每年8%-10%）金额，可以是现金，也可以是新公司股份。由于新公司很成功，估值往往很高，所以也不会占有很多的股份。当然，都不是强制的。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_36f829a1b5d54bce8b98024dab5374f4@5994784_oswg114782oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>“公开资料显示，循环智能6年累计融资大约6000万美元，本金加上利息，差不多是1亿美金，”陈悦天表示。不过，对于循环智能公司目前的经营状况，以及杨植麟给与老股东的股权方案，目前没有准确信息。&nbsp;</p>
  <p>至于这份本应该保密的仲裁文件内容被“意外”曝光，自有其原因。&nbsp;</p>
  <p>曲虹潭律师表示，“<strong>大部分商事仲裁裁决都是不公开的，这样可以降低某些明星级企业、投资人被媒体报道、公众关注的可能性。</strong>”&nbsp;</p>
  <p>因此很多从业者觉得，是五家老股东选择通过知情人士透露信息给媒体，希望该事件能被更多人看到。如果事实一旦确认，杨植麟未经老股东同意便创立新公司，涉及到违背契约精神，会影响其个人声誉和公司形象，也可能影响公司后续的融资和发展。&nbsp;</p>
  <p>月之暗面也向外界传达了各种自证信息反击。&nbsp;</p>
  <p>目前为止，在这场舆论战里，双方刀光剑影，彼此都不光彩。&nbsp;</p>
  <h2><strong>事情会如何收尾？</strong></h2>
  <p>如今双方还没有哪一方愿意做出让步，这场“暗战”或许还将继续。&nbsp;</p>
  <p>英诺天使基金合伙人王晟认为，<strong>双方都是从自身利益出发</strong>，老股东看到创业者的新公司估值猛涨，给自己和LP都带来了严重损失，自然想要争取更多权益，而创业者创立一家新公司，也是为了获得更大利益。&nbsp;</p>
  <p>陈悦天猜测，故事的最终结果可能是，双方坐到谈判桌前重新商讨股份，然后做出让步、接受条件，一方维护了自身的品牌和形象，一方获得了更多权益。毕竟在商业世界，合作共赢是才是最终目标。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_117efdcb20bb46599f769ce51f62bf53@5994784_oswg80082oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>投资人和创业者之间产生问题的情况不在少数，甚至十分常见。&nbsp;</p>
  <p>“一方面，<strong>不在公司的投资人，需要通过各种投资条款保证钱流向了正常的公司运营</strong>，另一方面，大多数创业者不太了解投融资相关方面的知识，很容易因为自身疏忽埋雷，”陈悦天表示。“比如本次的同意豁免书，很大程度上是由于创业者想抢大模型创业融资窗口期，忽略了这一流程的重要性。”&nbsp;</p>
  <p>王晟也表示，对于履行投资协议，一些创业者都很难做到很好地执行，尤其是看上去越简单的条款，比如每个季度交财务报表、一年开一次董事会的规定，都可能会被忽视。&nbsp;</p>
  <p>一个良好的投融资环境，需要参与各方都遵守契约精神。&nbsp;</p>
  <p>围绕Kimi创始人的争议，给大家好好上了一课。&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/KR-cR4A1Wczwxtc5fn5yLw" rel="noopener noreferrer nofollow" target="_blank">“树龙谈”</a>，作者：王璐&nbsp;阿伦，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036021104816129</id>
            <title>Meta最新触觉机械手登Science子刊封面，操作未知物体精度最高提升94%</title>
            <link>https://www.36kr.com/p/3036021104816129</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036021104816129</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 10:20:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 机械手, NeuralFeels, 触觉, 视觉  
<br><br>  
总结: Meta FAIR团队研发的NeuralFeels技术通过融合触觉和视觉，使机械手在操作未知物体时的精度提升了94%。该技术解决了传统机械手依赖视觉的问题，能够在复杂环境中进行更准确的物体感知与操作。NeuralFeels的前端采用深度学习策略提取目标对象深度，后端则通过优化姿态和形状来提升性能。实验结果显示，该技术在物体重建精度、姿态跟踪和应对复杂场景方面均有显著提升，未来有望在家庭、仓库和制造业等领域得到广泛应用。 </div>
                        <hr>
                    
                    <p>现在，随便丢给机械手一个陌生物体，它都可以像人类一样轻松拿捏了——</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_6f7b2d796b7f4af1bc577e8ead8235c8@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>除了苹果，罐头、乐高积木、大象玩偶、骰子，都不在话下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_518234b29860498db5b6248caa0611a3@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这就是来自<strong>Meta FAIR</strong>团队最新的<strong>NeuralFeels</strong>技术，通过融合触觉和视觉，机械手可以更精确地操作未知物体，精度最高提升了94%！</p>
  <p>这项研究还登上了<strong>Science Robotics</strong>的封面，团队同时也公开了包含70个实验的新测试基准<strong>FeelSight</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_bdbf7f9215f74851a6e4e745aea5cc16@46958_oswg2346359oswg1080oswg1375_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>如何让机械手精确操作未知物体？</strong></h2>
  <p>让机械手拿取常见的魔方、水果等早已是基操，但如何让机器人更好地操作未知物体一直是一个研究难题。</p>
  <p>一个重要原因是目前的机械手训练都太过于依靠视觉，并且仅限于操作已知的先验物体，而现实中很多时候物体都会受到视觉遮挡，导致训练往往进步缓慢。</p>
  <p>对此，团队研发出一种名为NeuralFeels的创新技术，为机器人在复杂环境中的物体感知与操作带来了新的突破。</p>
  <p>这究竟是怎么做到的呢？让我们来一起看一下技术细节——</p>
  <h3><strong>融合了触觉的多模态感知</strong></h3>
  <p>NeuralFeels技术的创新之处在于结合了视觉和触觉，通过多模态融合的方式，让机器手能够对未知物体持续进行3D建模，更精确地估计手持操作中物体的姿态和形状。</p>
  <p>具体的处理流程如下图所示，前端实现了视觉和触觉的鲁棒分割和深度预测，而后端将此信息结合成一个神经场，同时通过体积采样进一步优化姿态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_875aad00a45a49a8bd947e070d5666c8@46958_oswg416949oswg1080oswg465_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>而在遮挡视角下，视觉与触觉融合有助于提高跟踪性能，还可以从无遮挡的局部视角进行跟踪。团队在摄像机视角的球面上量化了这些收益。</p>
  <p>从下图中可以观察到，当视觉严重遮挡时，触觉的作用更大，而在几乎没有遮挡时，触觉会发挥微调作用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_7d364ef3f12c41cb9a486fdc8adba289@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>前端深度学习策略</strong></h3>
  <p>首先来看看NeuralFeels技术的前端（Front end），它采用了基于深度学习的分割策略和触觉Transformer，可以精确提取目标对象深度。</p>
  <p>用运动学分割一切</p>
  <p>神经优化非常依赖分割对象的输入深度，所以团队将前端设计成能够从视觉中鲁棒地提取对象深度的形式。深度在RGB-D相机中是现成的，但为了应对严重遮挡的问题，团队还引入了一种基于强大视觉基础模型的动力学感知分割策略。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_f9392a9986a846ff8afebe69d56738f1@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">触觉Transformer</p>
  <p>最近有研究表明，在自然图像中使用ViT进行密集深度预测更有效，于是团队提出了一种触觉Transformer，用于通过视觉触觉预测接触深度，这个Transformer完全在模拟中训练，可在多个真实世界的DIGIT传感器上通用。 机械手可以用嵌入式摄像头直接感知发光的胶垫，通过监督学习获得接触深度。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_f870c4505dc44517805223501af2c1d2@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>后端姿势优化</strong></h3>
  <p>NeuralFeels的后端（Back end）部分通过使用Theseus中的自定义测量因子，将前端的中间输出转化为非线性最小二乘问题进行优化。</p>
  <p>形状和姿态优化器</p>
  <p>后端模块从前端模块得到中间输出，并在线构对象模型。这个过程将交替使用来自视觉-触觉深度流的样本进行地图和姿态优化步骤。在本研究的地图优化器中，即时NGP模型的权重可以完全描述物体的3D几何结构。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_510ce581396c433ebceaa3653a77ad5a@46958_oswg155226oswg1080oswg380_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">神经SLAM</p>
  <p>在现实世界和模拟中，团队构建了一个不断演进的神经SDF，它整合了视觉和触觉，并可以同时跟踪物体。下图展示了对应的RGB-D和触觉图像的输入流，以及相应的姿态重建。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_4a8baf408527494f96d20f969682f4df@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">神经跟踪：给定形状的对象姿态估计</p>
  <p>当目标对象存在对应的CAD模型时，NeuralFeels可以实现优秀的多模态姿态跟踪能力。此时目标对象的SDF模型是预先计算的，NeuralFeels会冻结神经场的权重，仅使用前端估计进行视觉-触觉跟踪。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_eee3fb8ef02d48feaffe4a18c656488e@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>NeuralFeels大大提升了机械手性能</strong></h2>
  <p>为了评估NeuralFeels技术的性能，研究团队在模拟和真实世界环境中进行了多次实验，涉及14种不同物体，相关<strong>测试集FeelSight也已发布</strong>！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_15edc254b222469fa579ba564df4396c@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>实验中使用了多种评估指标，包括用于评估姿势跟踪误差的对称平均欧几里得距离（ADD-S），以及用于衡量形状重建精度和完整性的F分数等。</p>
  <p>结果非常令人惊喜，NeuralFeels技术在以下3个方面都有非常出色的表现：</p>
  <h3><strong>1.物体重建精度大幅提升</strong></h3>
  <p>在物体重建方面，研究发现结合触觉信息后，表面重建精度在模拟环境中平均提高了15.3%，在真实世界中提高了 14.6%。</p>
  <p>最终重建结果在模拟环境中的中位误差为2.1毫米，真实世界中为3.9毫米。这表明NeuralFeels技术能够有效地利用触觉信息补充视觉信息，<strong>更准确地重建物体形状</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_220add6f2be44a94bdc879008b3218e3@46958_oswg129213oswg1080oswg910_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>2.物体姿态跟踪更加精准</strong></h3>
  <p>在物体姿态跟踪方面，NeuralFeels技术相比仅使用视觉信息的基线方法有显著改进。</p>
  <p>在模拟环境中，姿态跟踪精度提高了21.3%，真实世界中提高了26.6%。</p>
  <p>在已知物体形状的姿态跟踪实验中，即使存在不精确的视觉分割和稀疏的触摸信号，该技术也能实现低误差的姿态跟踪，平均姿态误差可降至2毫米左右。</p>
  <p>并且，触觉信息在降低平均姿态误差方面发挥了重要作用，在模拟环境中可使误差降低22.29%，在真实世界中降低 3.9%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_a27deeec6621425181954b6b3925deb8@46958_oswg45125oswg1080oswg265_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>3.应对复杂场景表现出色</strong></h3>
  <p>在面对<strong>严重遮挡和视觉深度噪声</strong>等具有挑战性的场景时，NeuralFeels技术同样表现非常出色。</p>
  <p>在模拟的200个不同相机视角的遮挡实验中，平均跟踪性能提升 21.2%，在严重遮挡情况下提升幅度可达<strong>94.1%</strong>！</p>
  <p>在视觉深度噪声模拟实验中，随着噪声增加，融合触觉信息能有效降低误差分布，使机器人在视觉信息不理想的情况下仍能准确跟踪物体姿态。</p>
  <h2><strong>研究意义</strong></h2>
  <p>NeuralFeels技术的创新之处在于它融合了多模态数据、并结合了在线神经场，这些技术让机器人能够在操作未知物体时实现更准确的姿态跟踪和形状重建。</p>
  <p>而且，与复杂的传感器相比，团队使用空间感知组合所需的硬件更少，也比端到端感知方法更容易解释。</p>
  <p>尽管目前在一些方面仍存在改进空间，如在长期跟踪中由于缺乏闭环检测可能导致小误差累积，但对于提升机械手操作精度的效果非常显著，</p>
  <p>未来，研究人员计划进一步优化技术，例如通过基于特征的前端获取更粗略的初始化，加入长期闭环检测以减少姿态误差的累积，通过控制神经SLAM的输出进行通用灵巧性研究等。</p>
  <p>这样一来，家庭、仓库和制造业等复杂环境中作业的机器人的性能都有可能得到极大的提升了！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_e1469fbdd92742faaa1edf513d1f3fd5@46958_oswg164345oswg440oswg440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>参考资料：[1]https://www.science.org/doi/10.1126/scirobotics.adl0628[2]https://suddhu.github.io/neural-feels/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ZR4vAhhJOaxfOIKK15oaBQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：奇月，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036020992995591</id>
            <title>大模型“取长补短”新思路入选NeurIPS'24，显著优于现有路由方法，南科大港科大出品</title>
            <link>https://www.36kr.com/p/3036020992995591</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036020992995591</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 10:08:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: RouterDC, 双重对比学习, LLM路由, 计算高效性  
<br><br>  
总结: RouterDC是一种新型的路由架构，基于双重对比学习，具有参数和计算的高效性。该方法通过学习一个路由器为每个请求选择最合适的LLM，从而在推理时只调用所选的LLM，提升了多个LLM的互补能力。实验结果显示，RouterDC在语言理解、代码生成和数学推理等任务中，显著超越了现有的路由方法，且在分布外数据集上也表现出色。研究团队来自南方科技大学和香港科技大学，强调了RouterDC在训练和推理过程中的高效性。 </div>
                        <hr>
                    
                    <p>高效组合多个大模型“取长补短”新思路，被顶会NeurIPS 2024接收。</p>
  <p>名为<strong>RouterDC</strong>，是一种基于<strong>双重对比学习</strong>的路由架构，具有参数高效性（小于100M的参数）和计算高效性（不需要对于LLM进行梯度回传）的优势。</p>
  <p>在具有挑战性语言理解、代码生成和数学推理等推理任务实验中，RouterDC在分布内（+2.76%）和分布外（+1.90%）设定下，都远超于现有的routing方法。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_bcce414d3a0f44b5ae01fb9dc68d43f6@46958_oswg301134oswg1080oswg665_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>众所周知，LLM通常在不同数据集上预训练和微调，导致它们在不同任务上的性能强弱不同。</p>
  <p>LLM路由则是一种组合多个LLM的新思路，它通过学习一个路由器（Router）来为每一个请求（query）选择最合适的LLM。在推理时，LLM路由只需要调用所选的LLM进行推理，使其在保持计算高效性的同时利用多个LLM的互补能力。</p>
  <p>RouterDC这种新方法，包括<strong>一个较小的语言模型作为编码器</strong>和一系列与候选LLM对应的可学习的<strong>LLM embeddings</strong>。</p>
  <p>对于训练数据中的每个query，首先将候选LLM的预测与真实标签进行比较获得表现最好和最差的LLM，然后构造两个对比损失：</p>
  <p><strong>sample-LLM对比损失：</strong>使得query embedding（由编码器提取）与表现最佳的LLM embeddings相似，同时与表现最差的 LLM embeddings不相似。</p>
  <p><strong>sample-sample对比损失：</strong>提高训练的稳定性，将所有训练query聚类成多个组，最大化同组query之间的相似性的同时最小化不同组query之间的相似性。</p>
  <p>这项研究由来自南方科技大学，香港科技大学的研究团队提出，以下是更为详细的介绍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_5effc677d2794e3988537107233601c8@46958_oswg74931oswg1080oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>双对比学习实现Router训练</strong></h2>
  <h3><strong>Router架构</strong></h3>
  <p>如图1所示，RouterDC包括一个较小的语言模型（mDeBERTaV3-base）作为编码器ε，和一系列的与候选LLM对应的可学习LLM嵌入kT。对于每个query xi，RouterDC生成对于T个LLMs的选择概率如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_f083bbd351674acb808a1b25ea58e195@46958_oswg14218oswg1080oswg73_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其中，sim(·,·)表示cosine相似度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_229519831dbe455e8229407a6af8a2dc@46958_oswg51379oswg625oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <h3><strong>sample-LLM对比损失</strong></h3>
  <p>为了训练router，研究者将query的样本嵌入和在其上表现最好的K+个LLM对应嵌入拉进，和在其上表现最差的K-个LLM对应嵌入拉远。因此，样本-LLM对比损失可以表示为：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b546e3bb27974934a18ad02796612eac@46958_oswg16859oswg1080oswg127_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>sample-sample对比损失</strong></h3>
  <p>研究者通过实验发现，在routing问题中只使用样本-LLM对比损失并不稳定，使得相似的query可能具有不相似的嵌入。</p>
  <p>为了提升训练的鲁棒性，训练样本被聚类成不同的组，从而在训练中拉近同一个组内的样本，拉远不同组的样本。和样本-LLM对比损失类似，样本-样本对比损失可以公式化为：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b4a3172ec67b4e4d9abc0c74af4f24ac@46958_oswg17357oswg1080oswg127_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>训练及推理</strong></h3>
  <p>最终的优化目标为最小化样本-LLM对比损失和样本-样本对比损失的结合：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_e12e2ec81191430aacdfb3f6e967a135@46958_oswg16967oswg1080oswg119_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>推理时，每个测试query只需要通过训练好的router选取概率最大的LLM，并使用选择的LLM对query进行回答。</strong></p>
  <p><strong>RouterDC在训练时不需要任何经过LLM的梯度回传，并且在推理时只需要调用进行一次LLM，同时具有训练和推理的高效性。</strong></p>
  <h2><strong>实验效果如何？</strong></h2>
  <h3><strong>主要结果</strong></h3>
  <p>RouterDC在分布内数据集的测试准确率结果如表1所示。可以发现：</p>
  <p>RouterDC显著好于最优的单个模型，平均具有3.98%性能提升。在单个任务的层面，RouterDC在三个任务上相比表现最优的单个模型取得了准确率的提升，其中GSM8K提升了0.51%，ARC-C提升了0.57%，HumanEval提升了1.63%。</p>
  <p>和现有路由方法CosineClassifier以及ZOOTER对比，RouterDC在所有任务上都具有更好的表现。和LoraRetriever对比，RouterDC具有平均2.77%的准确率提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_2a292f0765e84c1ab377a86e163615bb@46958_oswg230589oswg1080oswg377_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>为了评估RouterDC的泛化能力，表2展示了RouterDC在三个分布外数据集（PreAlgebra，MBPP，C-EVAL）的测试准确率。</p>
  <p>可以看出，RouterDC再次达到最高的测试准确率，显著超过表现最佳的单个LLM（dolphin-2.9-llama3-8b）1.9%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_c1f101e2a0de4a4fb5d01ecbcafec72b@46958_oswg237826oswg1080oswg456_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <h3><strong>sample-sample损失的作用</strong></h3>
  <p>为了探究样本-样本损失的作用，图3展示了在是否有样本-样本损失的条件下训练和测试准确率曲线。可以看出，RouterDC（w/o&nbsp;Lsample-sample）有明显的震荡现象，而RouterDC则稳定得多。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_19795ea120b749168b93731ca439d737@46958_oswg204388oswg1080oswg840_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>图3（a）可视化了使用RouterDC（w/o Lsample-sample）提取的训练样本的TSNE特征，可以看到，属于不同任务的训练样本粗略地混合在一起。而在结合Lsample-sample之后，训练样本有了清晰的聚类结构（如图3（b）所示）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_78ef5e3a37b3452ea923dfcb3d33612d@46958_oswg296023oswg1080oswg447_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <h3><strong>RouterDC具有成本高效性</strong></h3>
  <p>由于价格（cost）同样是一个评估LLM的重要指标，研究者通过RouterBench上的两个任务的实验来格外考虑cost的影响。如图16所示，RouterDC相比于CosineClassifier和ZOOTER更加的成本高效。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_6da39d5c17b4464c985d4940b1d7657d@46958_oswg171715oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>论文地址：https://arxiv.org/abs/2409.19886代码地址：https://github.com/shuhao02/RouterDC</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/mvH42vpLwXBz0ClES3rCvA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：RouterDC团队&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036001400352768</id>
            <title>获贝索斯参投的4亿美元融资，这家公司打造机器人用的“GPT-4”</title>
            <link>https://www.36kr.com/p/3036001400352768</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036001400352768</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 10:07:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 通用机器人, Physical Intelligence, AGI, 机器人创新  
<br><br>  
总结: 本文讨论了Physical Intelligence公司开发的通用机器人基础模型π(0)，该模型能够适用于多种机器人应用，解决了专用机器人智能无法复用的局限性。通过微调行业数据，开发者可以在特定领域中应用这一通用模型。文章还提到，通用机器人基础模型有助于实现通用人工智能（AGI），因为它能够与物理世界交互，生成高质量数据。尽管中国在机器人领域与美国存在差距，但市场潜力巨大，创业者应在应用场景中进行创新，以推动整个生态的发展。 </div>
                        <hr>
                    
                    <p>在历次AI创新潮流中，机器人的创新都会受益，本次AI热潮也不例外。不过目前涌现出来的大部分是专用的机器人，这些机器人的智能也是在某个领域的专有智能。这样做的局限性在于，研发成果无法复用，机器人用的模型和硬件，只适用于某个很小的领域。</p>
  <p>近期，一个通用的机器人大脑雏形诞生，一家叫Physical Intelligence的机器人公司训练了一个叫π(0)的<strong>通用机器人基础模型</strong>，它的智能基本上适用于任何机器人应用。这意味着，<strong>当这一类通用模型成熟后，再开发某一个专有领域的机器人，至少在“大脑”部分，只需要用行业数据微调就行。</strong>这就像软件创业者想在某个细分领域创业，只需要微调GPT-4一样。</p>
  <p>Physical Intelligence在2024年获得了2轮融资，3月，Thrive Capital领投了它7000万美元的种子轮融资，Khosla Ventures、Lux Capital、OpenAI和Sequoia Capital参与投资；11月，杰夫·贝佐斯、OpenAI、Thrive Capital、Lux Capital、Bond Capital、Khosla Ventures和Sequoia Capital共同参与了它4亿美元的新一轮融资，这使得它的估值达到24亿美元。</p>
  <p>此前，杰夫·贝佐斯领投了Figure AI的6.75亿美元融资，Skild AI的3亿美元的A轮融资，亚马逊还收购了Covariant AI的团队。OpenAI参与了Figure AI的投资，以及1X金额为2350万美元的早期投资。机器人领域，被投资机构和科技巨头们普遍看好。</p>
  <h2><strong>一群科学家聚在一起打造通用的机器人大脑</strong></h2>
  <p>Physical Intelligence的核心团队来自加州大学伯克利分校、斯坦福大学等高校，以及特斯拉、谷歌DeepMind、Stripe等顶尖科技公司。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b4577e33c2e24c2b81e2b3978a2e1cff@000000_oswg62349oswg800oswg800_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">Karol Hausman&nbsp;</p>
  <p>它的联合创始人兼首席执行官Karol Hausman是斯坦福大学兼职教授，也曾是Google Brain在机器人方向的研究科学家，他的论文引用数超过13000。联合创始人Sergey Levine是加州大学伯克利分校副教授，也是机器人方面的顶级专家，<strong>他的论文引用数达到15万</strong>。联合创始人Chelsea Finn是斯坦福大学副教授，论文引用数达6.3万。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_8447ab775e4e4c6aa782ee2c1e0a4604@000000_oswg77990oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">Sergey Levine&nbsp;</p>
  <p>创始团队中还有谷歌前研究科学家Brian Ichter，以及Stripe前高管和知名科技投资人Lachy Groom。&nbsp;</p>
  <p>Physical Intelligence的愿景是：<strong>用户可以像使用大模型支持的聊天助手一样，让机器人执行任何他们想要的任务。</strong></p>
  <h3><strong>通用机器人基础模型对于行业意味着什么？</strong></h3>
  <p>目前，AI的应用方向可以大致分为两种，一种是在虚拟空间与人类互动，一种是直接与物理世界互动。在虚拟空间与人类互动，例如聊天机器人，AI企业搜索和Agent，法律AI、编程AI等垂直行业AI。</p>
  <p>直接与物理世界互动，主要通过机器人和自动驾驶汽车来实现。在机器人应用的分类上，也可以分为专用和通用两种。</p>
  <p>现在，大多数机器人属于“专用型”，这些机器人能适应限定环境中的少量变化，但难以应对像家庭或其他较为复杂和凌乱的真实环境。还有一部分属于通用型机器人，例如一些人形机器人。他们被设计出来，就是为了应对人类可以完成的大多数事情，而不是局限于某一个有限场景。</p>
  <p>机器人的结构，大致可分为“大脑”、“小脑”、“眼睛”和“肢体”，其中“大脑”是机器人的中枢，负责理解外界的指令，并做决策，一般是通用或专用的模型；“小脑”将决策命令输入进“肢体”并控制他们，是控制系统；“肢体”是机器人直接与物理世界接触的部分，可能是人形，犬形或机械臂，甚至可能是一辆车；而“眼睛”就是“大脑”感知外界的传感器。</p>
  <p>所有这些部分，都有大公司或顶尖创业公司在创新和耕耘，不过“小脑”、“眼睛”和“肢体”都已经在前几次的机器人浪潮中逐渐成熟，而机器人的“大脑”还处于初级阶段。</p>
  <p>对于垂直场景中的清洁机器人，喷涂机器人，配送机器人，仓储搬运机器人，他们只具有对应于垂直场景的专有智能，他们的“大脑”模型只能理解和处理有限场景中的情况，更早一些的专有机器人，他们只能做固定好的动作，并且需要大量的人类编程。</p>
  <p>通用的机器人大脑模型，可以一定程度改变这一现状，<strong>它使机器人能够学习并遵循用户指令，从而让编程新的行为变得非常简单，还让机器人能够自行调整其行为以适应环境。</strong></p>
  <p>对于任何垂直领域的机器人创业者，只要有一个通用的机器人大脑模型，再结合自己行业的专有数据，就可以微调出一个适应具体应用场景的机器人大脑。<strong>这个逻辑与大语言模型+专有数据=强大的行业模型，是一模一样的。</strong></p>
  <p>从更深一层来说，通用机器人基础模型，对于实现通用人工智能（AGI）也很有帮助。现在AI研究员们发现，Scaling Law的效果正在减弱，原因是AI模型遇到了“数据墙”——几乎所有现存的高质量数据都已经被训练，模型缺少更多更好的数据。<strong>如果有一个通用机器人模型，它不断地与物理世界交互，不断遇到和解决复杂的情况，那么就会源源不断产生高质量数据，最后就会离AGI越来越近。</strong></p>
  <h3><strong>训练通用机器人基础模型需要什么新方法？</strong></h3>
  <p>Physical Intelligence目前的原型通用机器人基础模型叫π0（pi-zero）。它基于广泛多样的数据进行训练，并能够执行各种文本指令。但不同于大语言模型的是，它还整合了图像、文本和动作，并通过在机器人体验中积累的实际操作来获得物理智能，<strong>它输出的是低级别的电机指令。</strong>它可以控制各种不同类型的机器人，而且既可以接受提示执行所需任务，也可以微调以适应复杂的应用场景。</p>
  <p>在训练π0模型时，Physical Intelligence使用了一些特殊的训练策略。</p>
  <p><strong>首先是跨设备的混合训练</strong> ，π0模型使用互联网规模的视觉-语言预训练、开源的机器人操作数据集以及自行收集的来自8种不同机器人的精密任务数据集，从而能够通过零样本提示或微调来执行多种任务。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_40f37bd8b7a34ab6bfff03d0553835f2@000000_oswg45989oswg1080oswg282_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这些数据集包含多样化的任务，每个任务展示了丰富的运动基本单元、不同的物体和多种场景；这些任务也涵盖了机器人灵巧操作的不同维度，Physical Intelligence选择这些任务的目标不是解决某个特定应用，<strong>而是为模型提供对物理交互的通用理解——为物理智能奠定初步的基础。</strong></p>
  <p><strong>其次是互联网规模的语义理解</strong> ，这个训练的起点是一个视觉-语言模型（VLM）。VLM能有效地从网络中转移语义知识，但它们只能输出离散的语言token，而精密的机器人操作需要π0以高频率（每秒最多50次）输出电机指令。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_38cc903681a7427d9553387eb7ea17cc@000000_oswg114195oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>为了达到这种灵活性，Physical Intelligence使用流匹配（一种扩散模型的变体）来增强VLM模型，使其能够输出连续的动作指令；这样就形成了一个视觉-语言-动作流匹配模型，随后对其进行高质量的机器人数据后训练，以解决一系列下游任务。&nbsp;</p>
  <p><strong>最后是针对精密操作的后训练</strong> ，更复杂的精密任务需要对模型进行微调，通过高质量数据对模型进行微调，例如折叠衣物的任务，就类似于大语言模型的后训练过程。预训练让模型掌握物理世界的知识，而微调则使其在特定任务上表现出色。&nbsp;</p>
  <p>当然，π0不是唯一的通用机器人基础模型，Physical Intelligence将它与其他的一些通用机器人基础模型在Zero-shot的条件下，用一些实际的任务，例如折叠衣服，将吐司面包从面包机中拿出来，将杂物打包等，来测试模型解决实际问题的能力。结果显示，无论是π0还是更小的π0-small，在解决问题能力上，都大幅优于现有的OpenVLA等模型。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_5bb02a9b53804574b39cac2b5eca25c6@000000_oswg35258oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>例如，在折叠衣物、餐桌清理和组装盒子等任务中，π0支持的机器人可以将纠缠在一起的衣物分开，并折叠好；可以将餐具或杯子放入清理托盘，并将垃圾放入垃圾桶；还可以拿起一个平整的纸板箱，将其折叠成形，然后插入折边。这些动作都不是少步骤的简单任务，而是需要复杂动作的家务或生产活动。</p>
  <p>不过，截至目前，π0还只是一个原型模型，通用机器人基础模型仍然处于起步阶段。Physical Intelligence表示他们还将继续收集数据并对模型进行训练，从而实现新的灵活性和物理能力。</p>
  <p>在商业化方面，Physical Intelligence目前暂时没有明显的动作。</p>
  <h2><strong>中国的机器人产业，需要核心技术更需要落地</strong></h2>
  <p>为什么无论是顶尖投资机构，还是杰夫·贝索斯等科技巨头的掌舵人都要押注机器人？答案很可能是前文提到的，机器人可以与AI结合，探索物理世界，产生大量真实而高质量的数据，最终帮助实现AGI。</p>
  <p>事实上大家不仅是投资，也会自己下手做，除了特斯拉的Optimus，英伟达也有机器人通用模型系列工具NVIDIA Project GR00T，亚马逊则有Sparrow（仓储机器人系统）和Digit（双足机器人）。</p>
  <p>在创业公司方面，Figure AI主要做Figure 01和Figure 02人形机器人，他们的大脑由OpenAI定制的模型组成，具有较强的泛用性，不仅可以完成冲咖啡等生活技能，还能去工厂里“拧螺丝”。</p>
  <p>Skild AI主要做Skild Brain和移动操作平台，其中Skild Brain是类似于π0的机器人通用大脑。</p>
  <p>1X也做的是专为家庭设计的双足人形机器人NEO Beta，而Vayu One是Vayu Robotics的送货机器人，它还有Vayu Drive这个移动基础模型。</p>
  <p>目前，中国在机器人方面，在核心算法和高级运动控制系统方面与美国还是有一定差距，但是无论是机器人的“大脑”、“小脑”、“眼睛”和“肢体”；各种专有机器人和人形/狗形通用机器人，都有大公司和顶尖创业公司在努力创新开拓。这些公司就包括阿里，小米，小鹏，大疆，宇树等。</p>
  <p><strong>而且中国一方面拥有巨大的市场和丰富的应用场景，一方面机器人的密度还不够高，这就有巨大的潜在市场需求。</strong>对于机器人创业者，即便专注于国内的市场，也有足够的发展空间，而当在国内市场“卷赢”后，又可以进一步向国际市场开拓。</p>
  <p>在创业方向上，固然需要在“大脑”、“小脑”等基础及核心的方向上进行突破，<strong>更需要在各种各样的应用场景出涌现出大量的创新者。</strong>应用和基础技术相互促进，才能使整个机器人创新创业生态健康发展。作为天使投资机构，阿尔法公社希望发现智能机器人领域的非凡创业者，希望帮助下一个世界级的机器人公司发展壮大。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4NDE1MjQ3NQ==&amp;mid=2651857008&amp;idx=1&amp;sn=cf3502d7bac4fb6cd8de7e3c5f02cb27&amp;chksm=856016e1233461bc2263b6bcef5c505075c3016f3299f25799b63d070c0f867ce713b47c967e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“阿尔法公社”（ID：alphastartups）</a>，作者：发现非凡创业者的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036006803256201</id>
            <title>国产两轮电动车出海：洗牌、压力和难关</title>
            <link>https://www.36kr.com/p/3036006803256201</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036006803256201</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 10:02:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <两轮电动车, 出口, 海外市场, 竞争>
<br>
<br>
总结: 近年来，中国两轮电动车在海外市场迅速崛起，成为全球最大的出口国和制造国。随着国内市场饱和，许多厂商选择“下海”开拓国际市场，尤其是在碳减排政策推动下，海外市场潜力巨大。然而，国产品牌在进入海外市场时面临线下服务网络、市场需求多样化和激烈竞争等挑战。尽管高端市场战略可能提升利润，但也可能增加企业负担。整体来看，国产两轮电动车厂商正处于求变期，出海成为行业洗牌的关键。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_653fdb8da88a40159dc9bb91a782b38c@12561242_oswg1491886oswg1267oswg844_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（题图）</p>
  <p>两轮电动车，在海外“杀疯”了。</p>
  <p>在小红书等社交媒体平台上，越来越多的海外用户纷纷晒出自己在纽约、伦敦等地，偶遇外国人骑乘电动车的画面，并惊讶地表示，仿佛瞬间穿越回了国内街头。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_293e14ed87064ec7a4fd4cd7f76021d9@12561242_oswg1219877oswg1259oswg808_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：小红书）</p>
  <p>更令人意想不到的是，这些风靡海外“小电驴”中，有不少都是中国制造。中国电驴，悄无声息的在国际市场杀出了一条血路。</p>
  <h2><strong>两轮电动车厂商集体“下海”</strong></h2>
  <p>今年1—7月，我国两轮电动车的出口额达到了206.3亿元，同比增长超9%，<strong>中国已经成为全球两轮电动车产业最大的出口国、制造国和消费国。</strong></p>
  <p>布局海外市场的国产两轮电动车厂商中，大致可以分为以雅迪、爱玛、台铃、新日为代表的传统品牌，以小牛电动、九号公司为代表的新锐品牌，以及宣布入局E-bike的大疆，和在海外布局共享电动车的哈罗为代表的跨界玩家。</p>
  <p>这些品牌纷纷“下海”，选择在海外开疆扩土，最主要的原因是“旧换新”红利期已过，国内市场已经充分饱和了。</p>
  <p>2019年4月15日，《电动自行车安全技术规范（GB17761-2018）》正式实施，要求电动车必须带踏板，而且整车、电动机及充电器插座上也必须要带有3C标志，并对车速进行25公里以下的限制。</p>
  <p>对产品参数和管理资质做出严格规定的新国标实施后，相关违规电动车将被禁止上路，否则会给予罚款及扣车等处罚，这也导致很大一部分小品牌以及不合规的杂牌被淘汰出局，而雅迪、爱玛等老品牌和小牛、九号等造车新势力则凭借规模优势和技术创新能力迅速崛起。</p>
  <p><strong>可“红利期”总有结束的一天，2022年，随着大部分老款两轮电动车陆续被换新，新国标替换需求已完成80%多，市场需求在减弱。</strong></p>
  <p>据艾瑞咨询的研究数据显示，2023年中国两轮电动车的销量约为5500万辆，相比前一年有所下降。华创证券也预测，未来3年行业销量复合增速将由2019-2022年的18%下降至5%-10%。</p>
  <p>这一趋势直接影响了国产两轮电动车企业的业绩表现，从最新的业绩报告来看，爱玛科技在7-9月期间实现营收68.73亿元，同比下降5.05%；归母净利润为6.03亿元，同比减少9.02%。</p>
  <p><strong>老牌玩家爱玛第三季度营收、利润双降，作为“旧换新”的最大受益者，市场份额最高的雅迪日子也不好过。</strong></p>
  <p>根据披露的2024年中报，雅迪控股上半年实现收入144.14亿元，同比下滑15.4%；实现公司股东应占利润10.34亿元，同比下滑12.9%。</p>
  <p>这可是2020年以来，雅迪控股半年度业绩首次出现同比下滑。<strong>销量退坡、业绩刹车，面对“萧条”的国内市场，也难怪国产两轮电动车公司会选择集体“下海”。</strong></p>
  <p><strong>事实上，在海外市场寻找新增量，对于国产两轮电动车厂商而言，确实是一个堪比新国标出台的机会。</strong></p>
  <p>一方面，据海外研究机构MRFR报告数据，到2030年全球两轮电动车市场规模将超过1000亿美元，2022年到2030年全球两轮电动车市场的年复合增长率将为34.57%。</p>
  <p><strong>渗透率相对较低，且市场规模巨大，海外两轮电动车市场显然是一个未经挖掘的“富矿”。</strong></p>
  <p><strong>另一方面，碳减排成为全球共识，多国相继通过补贴方式鼓励居民从购买汽车转向购买两轮电动车。</strong></p>
  <p>2023年3月，美国政府重新提交E-bike Act法案，拟为购买两轮电动车提供新车购买价格30%的税收抵免；8月，法国政府增加对以汽油车换取电动自行车的补贴规模至每人4000欧元。</p>
  <p>东南亚国家也有提出相关政策补贴，印尼和泰国决定自今年起对每辆电动摩托车提供折合人民币3000元以上的补贴，菲律宾提出自今年起的未来五年给予电动摩托车、电动两轮车及其零部件进口关税减免......</p>
  <p>然而，尽管海外市场看似是一座待挖掘的“金矿”，但国产两轮电动车品牌要想在这片蓝海中二次崛起，仍需克服重重挑战。</p>
  <h2><strong>难靠海外市场渡“难关”</strong></h2>
  <p>在国内两轮电动车市场遭遇收缩与增速放缓之际，海外市场却展现出了蓬勃的增长态势，出海战略已悄然转变为国内两轮电动车制造商的一门“必修课”。</p>
  <p><strong>然而，要在这条路上稳健前行并成功“结业”，还需跨越三大“大山”。</strong></p>
  <p><strong>首要难题在于，两轮电动车产品高度依赖线下体验与服务网络。</strong></p>
  <p>尽管品牌能通过线上营销吸引顾客并促成交易，但在车型选择、提车服务、后续保养及维修等核心环节，线下渠道仍扮演着不可替代的角色。</p>
  <p>可是海外市场的门店运营成本，包括房租、人力及仓储费用，相较于国内市场显著增加。</p>
  <p>尽管小牛电动、九号等品牌已进驻亚马逊、eBay等国际电商平台，试图拓宽销售渠道，但多数消费者仍偏好亲身体验后再做决定，线下门店仍是触达目标客群的关键桥梁。</p>
  <p><strong>因此，如何在控制海外门店成本的同时，有效整合线上线下资源，成为当前国产两轮电动车厂商亟需破解的难题之一。</strong></p>
  <p><strong>其次，全球各区域市场对两轮电动车的需求呈现多元化特征。</strong>欧美市场偏爱兼具代步与休闲功能的中高档电动摩托车和电助力自行车；东南亚市场则侧重于性价比，以中低端轻便车型为主导；而南美国家因地形复杂，大功率电动摩托车更受欢迎......</p>
  <p>面对这些文化差异，两轮电动车品牌需利用智能化技术重新塑造产品线，为不同地区提供定制化服务，方能在国际化道路上稳步前行。</p>
  <p><strong>最后，国内“内卷”严重，但海外市场的竞争同样激烈。</strong></p>
  <p>不仅来自国内的传统品牌、新锐品牌、跨界玩家各具优势，还有不少海外势力也开始下场争夺“蛋糕”。</p>
  <p>去年1月，哈雷CEO对外宣布整个品牌将要走向电动化，本田发布全新两轮电动品牌“Honda e:”，美国的汽车巨头福特也与电动品牌N+合作推出了两款全新电动自行车Bronco与Mustang，其中Bronco还很适合崎岖地形的越野骑行。</p>
  <p><strong>鉴于两轮电动车技术门槛相对较低且应用场景有限，同质化现象严重，不少品牌转而押注高端市场，以期打破僵局。</strong></p>
  <p>最近几年，雅迪推出高端子品牌VFLY系列，售价从6999元到19800元不等。爱玛也推出其高端子品牌小帕电动，主打的是城市高端白领群体，入门级的活力版定价为4999元，而尊贵版定价达到为9999元。</p>
  <p><strong>产品定价高昂，旨在吸引高端消费群体，然而，高端市场战略虽能提升利润空间，但也可能加重企业负担，且市场接受度存疑。</strong></p>
  <p>以小牛电动为例，不仅搞车载大屏、智能交互的智能化创新，还追求顶级的零部件配套，电池都用的特斯拉的同款松下。</p>
  <p>其虽在智能化及零部件配置上不遗余力，却未能有效转化为盈利，从中期报告来看，疯狂卷配置的小牛电动，净利润却为-7971.61万元，较去年同期亏损增加超过1700万元。</p>
  <p>况且，智能化竞争也日趋激烈，如今App启动、GPS定位、全天候车辆监控、OTA系统等配置，几乎已经成为了国产两轮电动车的标配，想要拉开差距，各大厂商或许还需打造出智能化更高、品质更优的两轮电动车产品，增强产品竞争力，进而提升企业竞争力。</p>
  <p>总而言之，起家于政策的东风的国产两轮电动车厂商们已经集体进入了“求变期”，主动寻求破局的利刃，出海成为行业洗牌的关键战场。对于已遭遇业绩与估值双重打击的行业龙头而言，若能把握机遇，实现二次飞跃，或许能穿越寒冬，迎来新的春天。</p>
  <p>*本文图片均来源于网络</p>
  <p>本文来自“螳螂观察”，作者：青月，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036021284892933</id>
            <title>李飞飞吴佳俊团队新作：推出具身智能决策能力评价基准，o1-preview登顶</title>
            <link>https://www.36kr.com/p/3036021284892933</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036021284892933</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 09:58:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 具身智能, 评估框架, EAI  
<br><br>  
总结: 李飞飞和吴佳俊团队提出了一种新的评估框架EAI，用于全面评估大模型的具身智能决策能力。该框架通过统一目标表示方法和模块化评估方式，解决了现有评估基准缺乏一致性和通用性的问题。EAI对18款主流模型进行了测试，结果显示o1-preview在综合成绩上位列第一。框架还引入了四个关键能力模块，帮助深入分析模型的表现和错误类型，为未来的研究提供了重要参考。 </div>
                        <hr>
                    
                    <p>大模型的具身智能决策能力，终于有系统的通用评估基准了。</p>
  <p>李飞飞吴佳俊团队新提出的评估框架，对具身智能决策的四项关键子能力来了个全面检查。</p>
  <p>这套基准已经被选为了NeurIPS数据和测试集（D&amp;B）专栏Oral论文，同时也被收录进了PyPI，只要一行代码就能快速调用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_1d2051ef14704e26962b077bb60f64ab@46958_oswg244327oswg1080oswg566_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>该框架名为<strong>Embodied Agent Interface</strong>（简称EAI），提供了连接不同模块和基准环境的标准接口。</p>
  <p>利用这套框架，作者对18款主流模型进行了测试，形成了一篇超百页的论文。</p>
  <p>测试结果显示，在已公开的大模型当中，<strong>o1-preview的综合成绩位列第一</strong>。</p>
  <p>李飞飞本人表示，对这项合作研究感到非常兴奋。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_4f48303a07924bdf89a1c333a43b7373@46958_oswg126649oswg1080oswg298_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>有网友评价说，这项成果为大模型具身智能决策塑造了未来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_17dd808a8f0848169cf69319d5abcdb9@46958_oswg147725oswg1080oswg230_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>四项子能力全面评估</strong></h2>
  <p>首先，EAI提供了一种<strong>统一的目标表示方法</strong>，能够兼容不同类型的目标，并支持复杂约束的描述。</p>
  <p>团队认为，现有的具身决策任务通常针对特定领域设计目标，缺乏一致性和通用性。</p>
  <p>例如，BEHAVIOR和VirtualHome都是具身智能体的评测基准和模拟环境，用于研究智能体在复杂环境中完成任务的能力。</p>
  <p>但二者又有所区别，BEHAVIOR使用基于状态的目标，而VirtualHome使用时间扩展的目标。</p>
  <p>EAI则通过引入<strong>线性时态逻辑</strong>（LTL），实现了目标表示方式的统一，提高了模块之间的互操作性，便于比较不同模型在同一任务上的表现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_4a02e2dcfbab42dc8d8fe14cfe959286@46958_oswg271075oswg1080oswg367_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在具体的评估过程当中，EAI采用了<strong>模块化的评估方式</strong>，并将评估指标进行了更细粒度的划分。</p>
  <p>以往的研究通常将大模型作为整体进行评估，很少关注其在具身决策各个子任务上的表现；</p>
  <p>同时，这些现有基准通常只关注任务的最终成功率，很少深入分析模型的错误类型和原因。</p>
  <p>为了更深入理解大模型的行为模式和优劣势分布，EAI提出了四个关键能力模块，并设计了一系列细粒度的评估指标：</p>
  <p>将模型能力分为四个关键模块；</p>
  <p>定义了清晰的输入输出接口；</p>
  <p>从轨迹可执行性、目标满足度、逻辑匹配性等多个角度评估模型的性能；</p>
  <p>引入了丰富的注释（如目标状态、关系、动作），以实现自动化的错误分析。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_c54d9cd8868f4d6f8342a866df2e05cc@46958_oswg133313oswg1080oswg286_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>具体来说，四个关键模块及内容分别是：</p>
  <p><strong>目标解释</strong>（Goal Interpretation）：将自然语言表述的任务目标转化为形式化的LTL目标公式；</p>
  <p><strong>子目标分解</strong>（Subgoal Decomposition）：将任务目标分解为一系列子目标，每个子目标也用LTL公式表示；</p>
  <p><strong>动作序列规划</strong>（Action Sequencing）：根据任务目标生成动作序列，在环境中执行以达成目标状态；</p>
  <p><strong>转换建模</strong>（Transition Modeling）：为每个动作或操作符生成前提条件和效果，形成环境转换模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_43de81e55ba7427b8f5d15387cb9ff51@46958_oswg126996oswg1080oswg388_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>另外，EAI选取了两个具有代表性但特点迥异的环境，也就是前面提到的BEHAVIOR和VirtualHome。</p>
  <p>相比于单一环境评估，EAI<strong>更能考察大模型跨领域的泛化能力，有助于全面理解其适用范围和局限性</strong>。</p>
  <h2><strong>o1-preview综合成绩第一</strong></h2>
  <p>利用EAI这套标准，研究团队对GPT、Claude、Gemini等18款主流模型（型号）的决策能力进行了评估。</p>
  <p>在BEHAVIOR和VirtualHome环境下，o1-preview均获得了排行榜综合成绩第一名。</p>
  <p>其中在BEHAVIOR环境中，o1-preview得分为74.9，比第二名的Claude 3.5 Sonnet高了10多分，排在之后的是60分左右的Claude 3 Opus和GPT-4o。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_9dd2efb8b1264a75b09d96d94496c557@46958_oswg177705oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>到了VirtualHome环境下，依然是o1-preview领先，但前三名的成绩相对接近。</p>
  <p>同时Gemini 1.5 Pro变成了第二名，不过整体来看排行靠前的几个模型和BEHAVIOR环境类似。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_189d541196b64eaf99cc674ef51c264f@46958_oswg158724oswg1080oswg572_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>当然如果比较单项能力，不同模型也体现出了各自不同的优势项目。</p>
  <p>比如在BEHAVIOR环境中，总分排第二的Claude 3.5 Sonnet，目标解释能力略高于总分排第一的o1-preview。</p>
  <p>在VirtualHome环境中，总分相对靠后的Mistral Large，在动作序列规划上取得了第一名。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_1b5fbbfa11384296a0933bea22f6019c@46958_oswg219758oswg1080oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>作者还对各模型的失败情况进行了深入分析，发现了将中间状态误识别为最终目标状态、对隐含的物理关系理解不足、忽略重要的前提条件等具体问题。</p>
  <p>这些发现能够让研究人员对模型的优缺陷进行更深层的了解，为之后的研究提供了重要参考。</p>
  <p>项目主页：https://embodied-agent-interface.github.io/</p>
  <p>论文：https://arxiv.org/abs/2410.07166</p>
  <p>代码：https://github.com/embodied-agent-interface/embodied-agent-interface</p>
  <p>数据集：https://huggingface.co/datasets/Inevitablevalor/EmbodiedAgentInterface</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ixiGVdBZKm4-wnmH3KoHRg" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：克雷西，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036041076044036</id>
            <title>2024，终会成为半导体产业拐点</title>
            <link>https://www.36kr.com/p/3036041076044036</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036041076044036</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 09:56:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <英伟达, 英特尔, 半导体产业, AI>
<br>
<br>
总结: 2024年，英伟达市值飙升，成为全球市值最高的公司，反映出科技行业重心向AI领域转移，而英特尔则面临市值大幅下跌和历史性亏损，显示出半导体产业的剧变。半导体行业的变化源于技术、政策和市场的相互作用，尤其是AI的崛起为市场带来了新的增长点。与此同时，欧洲半导体产业却出现疲软，主要企业营收下滑。政策方面，美国和欧洲的《芯片法案》落实不力，影响了产业发展。整体来看，半导体产业正经历深刻的转型与挑战。 </div>
                        <hr>
                    
                    <p>1995年，英伟达的第一款芯片NV1四处碰壁，公司只剩下30天的周转资金。2024年，英伟达的Blackwell GPU供不应求，公司总市值突破3.6万亿美元。&nbsp;</p>
  <p>同样是1995年，英特尔在全球PC处理器市场占比超过75%，确立了在个人电脑市场的领导地位。回到2024年，英特尔股价自今年以来暴跌近60%，市值跌至800多亿美元，这是英特尔三十年来首次跌破千亿美元大关。&nbsp;</p>
  <p>两大半导体巨头的市值变化，正是现在的半导体格局的缩影。&nbsp;</p>
  <p>有一句话是这么说的：“人往往会高估一年时间发生的变化，但低估五年时间发生的变化。”回过头来看，2024年半导体产业一整年的变化，却比起前五年加起来还要大。&nbsp;</p>
  <p>2024年，将是半导体产业的拐点。为什么这么说？&nbsp;</p>
  <p>因为作为产业的一种，半导体产业也离不开能给表征产业的基本特征：分工、产品、服务。而计算机、芯片这种产品，则离不开其背后的科学。产业和科学是相互依存的关系，甚至于在 19 世纪 70 年代之前，产业显然是依存于科学的。（之后西利曼事件的争议则是科学与产业之间关系的分水岭）&nbsp;</p>
  <p>今年半导体产业的巨大变化，是技术（科学）、政策、市场三方明争暗斗的结果。&nbsp;</p>
  <h2><strong>半导体企业的巨变</strong></h2>
  <p>2024年有很多刺激业内人士神经的消息。&nbsp;</p>
  <p>首当其冲的还是不断暴涨的英伟达市值。微软和苹果坐稳全球前二市值最高的公司是从2010年开始，虽然两者自10多年前就在“美股一哥”的排名上开始来回“纠缠”，但也没有再换过别人。&nbsp;</p>
  <p>当地时间 2024 年 6 月 18 日收盘，英伟达股价上涨 3.51%，报 135.58 美元，总市值达 3.335 万亿美元，一举超过了微软和苹果，成为全球市值最高的上市公司。&nbsp;</p>
  <p>这是影响全球的变化，诸如2011 年 8 月，苹果公司首次战胜埃克森美孚夺得世界市值最大公司头衔，这也是科技公司战胜传统石油公司的标志性时刻。 <strong>而英伟达成为全球第一市值的公司，则是代表着科技行业发展重心的转变。</strong> 以苹果为代表的消费电子、软件等传统领域，在过去引领了一个时代，而英伟达的第一，则意味着科技行业的发展重心正加速向AI领域转移。&nbsp;</p>
  <p>此外，在今年11月8日，英伟达替代英特尔成为道琼斯工业平均指数的成分股。标普全球表示，成分股调整是为了确保指数拥有更具代表性的半导体敞口。实际上，这也是一个佐证： <strong>AI真正走向了商业化赛道，AI对于半导体行业的影响越来越大。</strong></p>
  <p>2024年半导体行业里，除了不断提高的上限，也有不断刷新的下限。&nbsp;</p>
  <p>半导体行业有两大龙头，说出来可以说路边小儿都知道：英特尔、三星。自1992年，英特尔就已经是世界第一大半导体厂商，并且此后的25年中一直稳坐龙头。虽然2017年三星的芯片业务首次超越英特尔，但再怎么说，也是在不断抢夺龙头地位的存在。&nbsp;</p>
  <p>今年的两大芯片巨头，似乎是陷入了“沼泽”，不断挣扎。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_a7da9e00853747c7b397ec11634ca6cc@000000_oswg108805oswg1080oswg1073_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>正如前文所述，英特尔市值下跌，这是因为英特尔不断亏损的业绩。今年2季度，英特尔亏损达到了16亿美元，远高于上季度亏损的4.37亿美元。而最新的三季度财报， <strong>则公布了其56年历史上最大的季度亏损——166亿美元（约合人民币1182亿元）。</strong></p>
  <p>三星在2024年同样处于艰难境地。10月，三星公布了第三季度营业利润约为 9.1 万亿韩元，低于此前市场预期的 11.5 万亿韩元。&nbsp;</p>
  <p>三星电子设备解决方案部门负责人全永铉（Jeon Young-hyun）还就此发表了道歉声明，表示公司的业绩不如市场预期，引发了人们对公司基本技术竞争力和未来的忧虑，作为领导公司经营的高层会负起责任。（韩国连日本道歉那套也学过来了）&nbsp;</p>
  <p>同样，股市反映了公司的情况，三星股价在当地时间11月14日，一度下跌2.45%至51700韩元，这是2020年6月24日以来的最低点。 <strong>以这种态势发展下去，今年全年的三星股价，将会是逾20年表现最差的一年。</strong></p>
  <h2><strong>欧洲的“颓废”</strong></h2>
  <p>2024年变化的不只是显性的企业排名，还有地区变化。&nbsp;</p>
  <p>在半导体产业受到全球政府关注的情况下， <strong>有一个地区的半导体今年全年都在下降——欧洲。</strong> 可能很多人没有注意，但WSTS的数据不会骗人。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_7850decd8b5b40d1b722e48eeb0ecb22@000000_oswg56045oswg1080oswg588_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源： WSTS 半导体产业纵横制表&nbsp;</p>
  <p>我们统计了WSTS自今年1月起公布的芯片销售额，截至目前， <strong>欧洲全年芯片销售额同比都是负数。</strong> 当然，还有日本，不过日本在8、9月同比略微回正。&nbsp;</p>
  <p><strong>欧洲半导体产业在2024 年陷入了疲软状态。</strong> 欧洲半导体“三巨头”：英飞凌、意法半导体、恩智浦，营收都不太好。&nbsp;</p>
  <p>英飞凌营收在三季度达到 37.02 亿欧元，同比下降9%。目前，英飞凌已下调了 2024 年的业绩展望，将今年的营收预期调至 155 亿至 165 亿欧元，低于此前 165 亿至 175 亿欧元的预期。意法半导体三季度净营收为 32.5 亿美元，同比下降26.6%。恩智浦营收同比下降 5.4% 至 32.5 亿美元，略低于分析师预期的 32.6 亿美元。&nbsp;</p>
  <p>现今，欧洲的汽车、工业市场都已经出现了负增长的情况。从更具体的层面去观察，光电子和分立器件的表现不尽如人意，MCU 市场呈现出萎缩态势且出现了负增长，模拟市场也经历了长达 17 个月的连续负增长 。 <strong>按照市场机构 Future Horizons 的预测，2025 年欧洲半导体市场只会有 8% 的增长幅度。</strong></p>
  <h2><strong>追根溯源</strong></h2>
  <p>世界唯一不变的就是变化本身。今年半导体产业内，之所以发生了如此多的变化，我们追根溯源看看政策、市场、技术。&nbsp;</p>
  <h3><strong>政策</strong></h3>
  <p>政策对于产业的影响之大不言而喻，政策层面，美国、欧洲、日本、韩国、越南都在这两年前后发布了半导体相关的政策。但从现在来看， <strong>美国、欧洲的《芯片法案》，最后落实的不大。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_88bf73d1de244a82a7d16973a42b6e9c@000000_oswg228303oswg1080oswg543_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>到目前，美国芯片法案520亿美元补贴目前已发放一半以上，大概为26个项目拨款超过350亿美元。但是资金似乎迟迟不到位，英特尔一直在抱怨“两年了，一分钱都没见到。”&nbsp;</p>
  <p>美国的《芯片法案》更是在特朗普明年上台之后摇摇欲坠。因为特朗普是对于《芯片法案》的态度是持反对的。在接受媒体采访时特朗普直言：“太糟糕了。”欧盟的《欧洲芯片法案》更是没有水花。2022年提出的，现在在欧洲建厂的却不多，英特尔的项目甚至没有开动。&nbsp;</p>
  <p><strong>但是要注意到，《芯片法案》发挥了一个“空手套白狼”的作用。</strong> 英特尔、台积电、三星、美光、格芯、Amkor等因为《芯片法案》的补助，已经在美国的不同地区建设工厂。即使后期资金补助时间拉长，或者甚至资金补助取消，已经建设了一半的晶圆厂会变成“烂尾楼”吗？恐怕不见得。可以说对于半导体企业来说，在美国建厂这件事已经是“箭在弦上，不得不发”。&nbsp;</p>
  <p>虽然《芯片法案》落实得不算到位，并且特朗普持否认态度，但对于先进制造业回流美国这件事，特朗普肯定是没话说的。&nbsp;</p>
  <p>这也就是为什么我们在看英特尔的时候，又认为英特尔不会如此糟糕。虽然英特尔一直被唱衰，但是我们不能抛开一切，只从一个切面观察这家企业。我们不能忽略， <strong>英特尔其实在地缘政治舞台上发挥着重要的作用，而且也是美国政府的半导体产业和外交策略的筹码之一。</strong></p>
  <p>在看英特尔前景的时候，我们不能忽略美国战略和地缘政治的元素。现在半导体产业占据了重要的战略地位，大家都心知肚明。先不管能不能到极致的3nm工艺，但全球范围内，能够制造先进工艺芯片的企业就三家：台积电、英特尔、三星。&nbsp;</p>
  <p>美国的《芯片法案》还是有很大一部分的计划，是流向英特尔亚利桑那州建设两座大型工厂，以及在俄亥俄州建造另外两座工厂等项目。&nbsp;</p>
  <p>所以，英特尔的未来，还是充满看点的。也不能直接就认为会“一衰到底”。&nbsp;</p>
  <h3><strong>市场</strong></h3>
  <p>为什么最近几年国内也开始喊“内卷”？因为科技创新的速度变慢了，加上三年疫情影响，在各种压力之下，中国的经济发展速度也随之变慢，“内卷”也就来了。&nbsp;</p>
  <p>“第二曲线”理论认为，产业发展有生命周期，任何一条增长曲线都是先升后降的抛物线，实现持续增长的秘密是在拐点出现之前开始一条新的增长曲线，从而形成新旧动能梯次接续、不断改善提高的发展态势。&nbsp;</p>
  <p>我们现在正处在上一轮科技和产业革命的萧条期，要想让经济再次繁荣，就要引爆新一轮的科技革命和产业革命。这是周期带来的拐点。&nbsp;</p>
  <p>新一轮的爆点无疑是在AI上，这也是很多业内人士的共识了。AI带来的是市场的新增长点，很多技术掩埋在AI之下。&nbsp;</p>
  <h3><strong>技术</strong></h3>
  <p>AI之上，我们要看到的是技术发展。&nbsp;</p>
  <p>这次AI能够爆发，毫无疑问是技术带动的。GenAI的出现，酝酿了很久。而这次AI的爆发，又带动了其他原本正在酝酿的技术。&nbsp;</p>
  <p>第一个具有代表性的是：台积电的先进封装工艺，CoWoS。&nbsp;</p>
  <p>目前半导体最受关注的两个产品：GPU、HBM，这两个产品都要靠着先进的工艺才能生产。而台积电的CoWoS封装还在其中发挥着非常关键的作用，以至于有人开始戏称“台积电将是全球第一的封测厂。” <strong>在这里，原本属于后道工艺的封测已经出现了明显前道化的趋势。</strong></p>
  <p>并且，在 HBM 供应商不断提高堆叠密度的进程中，对于未来的第五代 HBM（即 HBM4）和逻辑层之间的互联事宜，将由存储大厂与代工厂联合完成。按照 SK 海力士的说法，HBM4 会在很大程度上改变以往业界把 DRAM 视作 “通用芯片” 的这种认知，使其摇身一变成为一种定制化的存储特殊工艺芯片。在此过程中， <strong>相关的技术诀窍（know-how）将由代工厂和存储原厂共同来担负，这也是台积电今年宣称的“代工2.0”计划的题中之义。</strong></p>
  <p>第二个具有代表性的是：架构之争，也就是x86和Arm、RISC-V之间的市场争夺。&nbsp;</p>
  <p>今年很明显的一个趋势，Arm架构芯片的市场占有率在提升。前段时间的x86联盟已经表态得很明显了：正面刚。虽然乍一看是三大架构在市场方面的变化，可实际上是 CISC（复杂指令集） 和 RISC（精简指令集） 这两种芯片设计理念长达三十年的相互角逐。这种角逐本质上是计算机体系结构这门 “科学技术” 的发展在 “产业” 领域的延伸。&nbsp;</p>
  <p>AI的出现，给这两大设计理念，更多的应用场景。 <strong>从目前来看RISC架构下的架构（Arm、RISC-V）确实是有先天的优势，</strong> 因为具备AI天生需要的低功耗和高能效。这也意味着，Arm有一天真的有可能实现更高的市占比，而这是在技术和市场的双重推动下。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247771958&amp;idx=1&amp;sn=c0ff361a1d08901b2ce985ea537bed8c&amp;chksm=c0a4a65a9206b3c32c322510bfc678834e25e340bbc8be3d717e201183987334da2da8f90e65&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：九林，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3036021519495430</id>
            <title>Scaling Law遭遇瓶颈，OpenAI被曝押注智能体“Operator”</title>
            <link>https://www.36kr.com/p/3036021519495430</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3036021519495430</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 09:49:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Agent, 自动化, 竞争  
<br><br>  
总结: OpenAI计划于明年1月推出名为“Operator”的智能体，旨在自动执行用户任务，类似于Anthropic的computer use功能。此举标志着OpenAI在AI Agent领域的竞争加剧，尤其是在谷歌和其他国内厂商也在推出类似产品的情况下。OpenAI的CEO曾表示，Agent将是下一个重大突破，而首席产品官则强调让ChatGPT自主执行任务是明年的重点。然而，OpenAI的推出时间被认为有些晚，面临来自竞争对手的压力。整体来看，Agent可能成为未来AI发展的重要方向。 </div>
                        <hr>
                    
                    <p>继Anthropic之后，OpenAI也要接管人类电脑了？！</p>
  <p>就在刚刚，根据爆料OpenAI将在<strong>明年1月</strong>推出Agent<strong>“Operator</strong>（操作员）<strong>”</strong>，为用户自动执行任务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_5f24651b83b84b6a933a80a606cf2f7a@46958_oswg481022oswg1080oswg966_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>配方我们也很熟悉，只需在电脑上简单下达指令，Agent就能自动帮我们编码开发应用、订餐，做攻略等等。</p>
  <p>好嘛，一看大家就明白，这是要和老对手Anthropic打起来了！</p>
  <blockquote>
   <p>这将与Anthropic的computer use API进行竞争（Anthropic之前发布了computer use功能，号称接管人类电脑）</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_77c7ea1a525249d0b98e7587c833665d@46958_oswg99274oswg1080oswg270_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>事实上，在前一阵Reddit举办的有问必答活动上，CEO奥特曼曾信誓旦旦表示：</p>
  <blockquote>
   <p>Agent将成为下一个重大突破。</p>
  </blockquote>
  <p>同时，OpenAI首席产品官Kevin Weil进一步表示，<strong>让ChatGPT自主执行任务将是明年一大重点。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_20bbaef9d5ac4a14a136c650964c9146@46958_oswg146785oswg1080oswg451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>不过，除了“遥遥领先”的Anthropic，OpenAI另一对手谷歌早已曝出将于12月发布自己的AI Agent版本。</p>
  <p>国内百度智谱等模型厂商也推出了类似智能体和解决方案，甚至手机厂商荣耀、小米等还发布了自己的AI操作系统。</p>
  <p>如此一来，压力也是来到了OpenAI这边。</p>
  <p>虽说紧赶慢赶才有可能在明年1月推出，但还是有网友犀利吐槽太晚了！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_365b67a33f0f44cd8a5f1bab34f3412b@46958_oswg33710oswg848oswg314_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>网友：1月太晚了</strong></h2>
  <p>据消息，OpenAI计划于明年1月推出代号为“Operator”的智能体（Agent）。</p>
  <p>其功能和10月份Anthropic发布的computer use类似，号称解放人类双手，代替用户操控电脑。</p>
  <p>比如让它做旅游攻略，一段命令发布后，Agent就能自动打开谷歌搜索位置、天气，并结合用户的日程表给出切实可行的规划。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_d291ca6ad06849e490cbeb95e1c56a22@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>另外，据OpenAI内部知情人士透露，在周三的员工会议上，有领导宣布：</p>
  <blockquote>
   <p>届时该功能将以<strong>早期预览</strong>的形式发布（最初设计用于在网页浏览器中执行任务），且最初仅<strong>面向开发者提供API接口</strong>。</p>
  </blockquote>
  <p>甚至根据爆料，OpenAI内部其实一直在同时推进很多Agent项目，而Operator可能是最接近成功的一个。</p>
  <p>对于上述传闻，OpenAI截至发稿前并未有所回应。</p>
  <p>不过，一直关注OpenAI动态的光头哥还是发现了Operator的踪迹。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b51dbe5a9353474186dcfce0675f925f@46958_oswg260132oswg1080oswg662_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>然而，即便消息属实，OpenAI的动作还是有点晚了~</p>
  <p>毕竟环顾四周，<strong>一众竞争对手貌似都跑在前头</strong>：</p>
  <p>最强劲敌Anthropic自不必说，人家早在10月份就推出了相关功能，一举惊艳AI圈。</p>
  <p>而总是暗戳戳较劲的谷歌，也很有可能在12月推出代号为“Jarvis” （贾维斯）的Agent，按照双方时间表，这波谷歌没准获胜。</p>
  <p>更不用说目前关系尴尬的微软，人家更是早Anthropic一天，一口气发布了10个Agent。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_801b0630e1334281b1ee01da3328a376@46958_oswg489971oswg1080oswg881_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>抛开这些不谈，我们<strong>国内</strong>也有相当一部分选手开始在Agent上有所动作。</p>
  <p>比如，百度在今年9月的百度云智大会就展示了Agent操作手机的一幕：</p>
  <p>同样只需一段话，Agent就能帮我们制定行程，还能在不同APP间自行跳转。</p>
  <blockquote>
   <p>制定一个国庆节去山西旅行3天的计划路线，要参考《黑神话：悟空》中涉及的山西经典，且希望住在品质好、性价比高的酒店，好评优先、500元以内，而且想要规划自驾路线。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_329aa7320dff410abb5621de70e24a73@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_658c1dd2d56c4a8da7d1223afc1e17fd@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>另外，就在Anthropic之后，智谱也发布了AutoGLM，让AI像人一样使用手机；而且还不像Claude需要打字提需求，AutoGLM实现了光靠嘴说来执行很多操作。</p>
  <p>甚至，在AI PC和AI手机圈子里，各大玩家也是把眼光都聚焦到了这种新范式。</p>
  <p>10月23日，华为发布荣耀MagicOS 9.0，定位为C端用户的“类人助理”，通过大模型底座打通app正式开启AI Agent阶段，实现系统级AI操作。</p>
  <p>而且就在昨天，荣耀官方宣布， MagicOS 9.0首批产品开始公测，覆盖了荣耀Magic Vs3、V2系列、Magic6系列、Magic5系列。</p>
  <p>另外，小米也发布了澎湃OS 2.0系统，搭载基于AI大模型重构的操作系统，将设备转化为智能的“个人助手”。</p>
  <p>……</p>
  <p>以上可以看出，一直作为领先者的OpenAI，在Agent方面已经开始落后于人了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_e802807b9c5c40e8acadceab14e6323d@46958_oswg49752oswg1024oswg896_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>2025年，属于Agent</strong></h2>
  <p>不过另一方面也说明，明年Agent大概率成为厮杀重点。</p>
  <p>毕竟，大模型Scaling Law后继乏力已成热议焦点。</p>
  <p>有消息称，OpenAI、谷歌、Anthropic都在推出更大、更强模型产品方面<strong>遭遇瓶颈</strong>。</p>
  <p>具体来说，OpenAI代号“猎户座”（Orion）的下一代旗舰模型被曝提升不如预期，它相对GPT-4的提升幅度，小于GPT-4相对GPT-3，已进入收益递减阶段。</p>
  <p>这也侧面和奥特曼的说法相印证，他表示可能不会把新模型命名为GPT-5。</p>
  <p>另外，谷歌Gemini 2虽然计划很快发布，但也被曝性能提升也未达到DeepMind创始人的预期。</p>
  <p>同时，面对网友一直呼唤的大杯Claude 3.5 Opus，Anthropic也悄悄从官网删除了相关描述。</p>
  <p>而Agent，目前很明显已经成为大家新的方向。</p>
  <p>这盛世或将如网友所愿：<strong>2025年，属于Agent！</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_2082b616aa694f50a1cee4494d513415@46958_oswg30845oswg926oswg221_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>参考链接：[1]https://www.bloomberg.com/news/articles/2024-11-13/openai-nears-launch-of-ai-agents-to-automate-tasks-for-users[2]https://www.reddit.com/r/singularity/comments/1gqn099/openai_nears_launch_of_ai_agent_tool_to_automate/[3]https://x.com/omarsar0/status/1856802883112767541</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/s0LBjZ0AwI7t46hmrX7yAQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：一水，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3035978824134660</id>
            <title>谷歌2024博士奖学金公布，KAN作者刘子鸣等数十位年轻华人学者入选</title>
            <link>https://www.36kr.com/p/3035978824134660</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3035978824134660</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 09:15:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <谷歌博士奖学金, 计算机科学, 年轻学者, 研究方向>
<br>
<br>
总结: 2024年谷歌博士奖学金获奖名单公布，共有85人获奖，涵盖13个研究方向，包括算法与理论、健康与生物科学、机器智能等。该奖项旨在支持在计算机科学等前沿领域表现优异的年轻学者攻读博士学位，并提供与谷歌研究导师合作的机会。获奖者的研究领域多样，涉及机器学习、计算机视觉、自然语言处理等。 </div>
                        <hr>
                    
                    <blockquote>
   <p>今年共有 85 人获奖，分为 13 个方向。</p>
  </blockquote>
  <p>2024 年谷歌博士奖学金（Google PhD Fellowship）获奖名单公布了。该奖项旨在奖励在计算机科学等前瞻科研领域表现优异的年轻学者，奖学金用于直接支持攻读博士学位，并提供与谷歌研究导师合作的机会。</p>
  <p>根据 2024 年谷歌博士生奖学金项目名单显示，今年共有 85 人获奖，分为 13 个方向：算法与理论 8 人、分布式系统与并行计算 1 人、健康与生物科学 11 人、人机交互与可视化 7 人、机器智能 22 人、机器感知 6 人、自然语言处理 12 人、网络 2 人、量子计算 3 人、安全隐私和防止滥用 6 人、硅芯片研究 1 人、软件系统 1 人、语音处理 5 人。</p>
  <p>以下为部分入选华人博士生介绍：</p>
  <h2><strong>算法与理论</strong></h2>
  <p><strong>Sun Yan，新加坡国立大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_e6963103318043dfaa2f6aafa603445b@46958_oswg1677047oswg840oswg1106_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Sun Yan 是新加坡国立大学 (NUS) 计算机学院信息系统专业博士生，导师是 Stanley Kok 教授。Sun Yan 本科毕业于香港中文大学（深圳）。</p>
  <p>Sun Yan 的研究兴趣是机器学习中的算法及其应用，还研究过计算机图形学，例如图内核、异常检测。</p>
  <p>个人主页：https://mathildasunyan.wixsite.com/academic-hub</p>
  <p><strong>吕欣，加州大学伯克利分校</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_0f2eb0de06904d39904c2490336d6bf4@46958_oswg2663263oswg1080oswg1442_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>吕欣是加州大学伯克利分校博士生，导师是 Avishay Tal 和 Jelani Nelson。吕欣本科毕业于清华大学交叉信息科学研究所（姚班）。&nbsp;</p>
  <p>吕欣的研究兴趣主要在于理论计算机科学，涉及伪随机性、计算复杂度和差分隐私方面的问题。</p>
  <p>个人主页：https://people.eecs.berkeley.edu/~xinlyu/</p>
  <h2><strong>健康与生物科学</strong></h2>
  <p><strong>Chang Kao Jung，阳明交通大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_da9d03efc9104807be2b50869ea31868@46958_oswg85658oswg240oswg239_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Chang Kao Jung 为阳明交通大学医学博士，主要研究方向为大数据、AI、基因遗传学等领域。</p>
  <p><strong>Hanjia Lyu，罗彻斯特大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_cb6cb899e476484c843b03520a4fa99b@46958_oswg1209165oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Hanjia Lyu 是罗彻斯特大学计算机科学系四年级博士生，指导老师是罗杰波教授。此前，他在罗彻斯特大学获得了数据科学硕士学位，在复旦大学获得了学士学位，主要研究方向包括健康信息学，行为科学等领域。</p>
  <p>个人主页：https://brucelyu17.github.io/</p>
  <p><strong>Jason Yang，加州理工学院</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_6eace1a69d514464a75759b245822579@46958_oswg92374oswg256oswg256_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Jason Yang 为加州理工学院博士生，指导老师是 Frances Arnold 教授和 Yisong Yue 教授，他本科毕业于耶鲁大学。主要研究方向为蛋白质工程、机器学习等领域。</p>
  <p>谷歌学术：https://scholar.google.com/citations?user=SsDR5GkAAAAJ&amp;hl=en</p>
  <p><strong>Kara Liu，斯坦福大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_f02ed0890fca4c018837bb763ac87449@46958_oswg1179225oswg1080oswg893_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Kara Liu 目前是斯坦福大学计算机科学博士生，指导老师是 Russ Altman 教授。她的研究重点是开发和应用机器学习方法，以实现公平有效的医疗保健。</p>
  <p>在此之前，Kara Liu 在加州大学伯克利分校获得计算机科学学士学位，还曾在 Pieter Abbeel 和 Aviv Tamar 的指导下从事长视界视觉规划和表征学习的研究。</p>
  <p>个人主页：https://karamarieliu.github.io/</p>
  <p><strong>Lingtong (Tony) Xu，多伦多大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_7ebc720f7f12457ea0aaef156a74d9bf@46958_oswg202559oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Lingtong (Tony) Xu 博士毕业于加拿大多伦多大学，本科毕业于不列颠哥伦比亚大学。</p>
  <p>领英主页：https://www.linkedin.com/in/tony-lt-xu/?originalSubdomain=ca</p>
  <h2><strong>人机交互与可视化</strong></h2>
  <p><strong>Erzhen Hu，弗吉尼亚大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b8120b49f8ce4ead8363b30d31c9ba3b@46958_oswg307560oswg643oswg628_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Erzhen Hu 为弗吉尼亚大学计算机科学博士生，导师是 Seongkook Heo 教授。在此之前，她获得了弗吉尼亚大学统计学硕士学位和上海大学学士学位。Erzhen Hu 的研究包括通过多模态智能体增强人机交互、利用 LLM 以及将先进的 2D 和 3D 计算机视觉方法应用于多用户场景、 XR 应用，探索人机通信范式。&nbsp;</p>
  <p>个人主页：https://erzhenh.com/&nbsp;</p>
  <h2><strong>机器智能</strong></h2>
  <p><strong>曹宇舟，南洋理工大学</strong></p>
  <p>曹宇舟是新加坡南洋理工大学计算与数据科学学院博士生，研究方向为统计学习及其在可信机器学习中的应用，导师是安波教授。曹宇舟本科毕业于中国农业大学。&nbsp;</p>
  <p>个人主页：https://yzcao-nkg.github.io/&nbsp;</p>
  <p><strong>Cheng-Yu Hsieh，华盛顿大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_83228c81e6c74885b2d6047581ea6899@46958_oswg991360oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Cheng-Yu Hsieh 是华盛顿大学计算机科学与工程专业的博士生，之前，他在台湾大学获得学士和硕士学位。Cheng-Yu Hsieh 的研究目标是借助数据和模型扩展在当今的大规模环境中更加高效和有效，实现人工智能开发的民主化。&nbsp;</p>
  <p>个人主页：https://chengyuhsieh.github.io/&nbsp;</p>
  <p><strong>Eric Zhao，加州大学伯克利分校</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_2ece1c49adc042bbb2ac945b96feccb0@46958_oswg1172575oswg1080oswg1079_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Eric Zhao 是加州大学伯克利分校计算机科学博士生，导师是 Nika Haghtalab 和 Michael I. Jordan。&nbsp;</p>
  <p>Eric Zhao 的研究兴趣在于多目标机器学习的算法和数学基础。&nbsp;</p>
  <p>个人主页：https://eric-zhao.com/&nbsp;</p>
  <p><strong>Haodong Lu，新南威尔士大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_f7816f545e5f45e68b47dbaed7d25776@46958_oswg29768oswg171oswg190_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Haodong Lu 是新南威尔士大学博士生，导师是 Dong Gong 和 Lina Yao。&nbsp;</p>
  <p>Haodong Lu 的研究兴趣集中在理解和适应数据分布变化，特别关注分布外 (OOD) 检测和持续学习，致力于开发强大的计算机视觉和多模态模型，能够随着时间的推移有效地检测和适应新的数据分布。&nbsp;</p>
  <p><strong>Kaiwen Wang，康奈尔大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_785bc06bc62a48a1b34650921b50f5df@46958_oswg1126965oswg1080oswg856_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Kaiwen Wang 目前是康奈尔大学的博士生，在进入研究生院之前，Kaiwen 在 Meta AI 工作，负责构建推荐算法模型和 ReAgent 平台。他的研究领域包括强化学习、因果关系和大型语言模型。&nbsp;</p>
  <p><strong>黄凯旋，普林斯顿大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_46aa950794bd4e62b54ca8cc3095a720@46958_oswg1547970oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>黄凯旋是普林斯顿大学电气与计算机工程系博士生，导师是王梦迪教授。黄凯旋本科毕业于北京大学。&nbsp;</p>
  <p>黄凯旋的研究兴趣是用于基础模型的强化学习（例如，用于扩散模型 / 语言模型的 RLHF）和用于强化学习的基础模型（LLM/VLM 智能体）。&nbsp;</p>
  <p>个人主页：https://hackyhuang.github.io/&nbsp;</p>
  <p><strong>Peizhen Li，麦考瑞大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_50ce85c8fa2b4ad0895d5b0588c48246@46958_oswg43421oswg176oswg256_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Peizhen Li 是麦考瑞大学计算学院的博士生，本硕就读于中山大学。她的研究兴趣集中在具身智能、机器人技术、机器学习。&nbsp;</p>
  <p><strong>Siyao Li，新加坡南洋理工大学</strong></p>
  <p><strong>‍</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_fe00aae411504bafa3ea8cf302be9f94@46958_oswg1646203oswg1080oswg1315_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Siyao Li 是新加坡南洋理工大学 MMLab 的博士生，他的导师是 Chen Change Loy 教授。在此之前，他曾在商汤科技研究院担任全职研究员，与 Quan Wang、Wenxiu Sun 和 Chao Dong 紧密合作。他的研究兴趣集中在 3D 生成、AIGC 相关。&nbsp;</p>
  <p><strong>何晓昕，新加坡国立大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_2ac94d0b2570425aa22a22712a248a70@46958_oswg119013oswg270oswg303_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>何晓昕是新加坡国立大学计算机学院的博士生，指导老师为 Bryan Hooi 和 Xavier Bresson。在此之前，她在复旦大学获得了本科学位。她的研究兴趣为将深度学习技术应用于图结构数据。&nbsp;</p>
  <p><strong>刘子鸣，麻省理工学院</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_1ef79e9e9f1d4a7fa324faadf2fd38c5@46958_oswg504655oswg480oswg453_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>相信大家还记得引起巨大关注与争议的 KAN，刘子鸣就是 KAN 的一作。目前，他在麻省理工学院和 IAIFI 攻读博士学位。他的研究兴趣在于 AI for Physics，还成立了 AI4Science 研讨会。&nbsp;</p>
  <h2><strong>机器感知</strong></h2>
  <p><strong>张健荣（Jianrong Zhang），悉尼科技大学</strong></p>
  <p>Jianrong Zhang 为悉尼科技大学博士生，导师是&nbsp;杨易（Yi Yang） 教授，他本科、硕士毕业于吉林大学。他的主要研究方向为计算机视觉和人体运动生成。&nbsp;</p>
  <p><strong>Sheng-Yu Wang，CMU</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_7438fb6f69184f42ae37f5ba65397bae@46958_oswg1785447oswg1080oswg1128_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Sheng-Yu Wang 为 CMU 博士生，导师是 CMU 助理教授朱俊彦，Sheng-Yu Wang 主要研究方向为计算机视觉、深度学习等。Sheng-Yu Wang 参与的多篇论文被 ICCV、CVPR 接收。&nbsp;</p>
  <p>个人主页：https://peterwang512.github.io/&nbsp;</p>
  <p><strong>吴胜琼，新加坡国立大学</strong></p>
  <p>‍&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_f4d5e31397284d2eb7be4e3d0b6a2079@46958_oswg245678oswg364oswg412_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>吴胜琼目前是新加坡国立大学计算学院 NExT++ 研究中心的博二学生，由 Tat-Seng Chua 教授指导，她在武汉大学获得了硕士和学士学位。&nbsp;</p>
  <p>吴胜琼的研究兴趣主要集中在基于场景图的视觉 - 语言理解领域、多模态大型语言模型以及扩散模型。她是去年引发 AI 社区关注的「大一统」通用多模态大模型 ——NExT-GPT 的一作。&nbsp;</p>
  <h2><strong>自然语言处理</strong></h2>
  <p><strong>David Wan，北卡罗来纳大学教堂山分校</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_d8ec6e569ab1443bbeabfc409349cc5a@46958_oswg404659oswg562oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>David Wan 是北卡罗来纳大学教堂山分校的四年级博士生，指导老师是 Mohit Bansal。在此之前，他毕业于哥伦比亚大学，获得学士和硕士学位，指导老师是 Kathleen McKeown。他的研究兴趣是自然语言处理。&nbsp;</p>
  <p><strong>马欣尹，新加坡国立大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_12cb72eeb6fa458cb193c1970e268d23@46958_oswg493619oswg512oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>马欣尹为新加坡国立大学的博士，由王鑫超教授指导。本硕就读于浙江大学。她是最流行的结构化剪枝方法 LLM-Pruner 的一作。&nbsp;</p>
  <p>她目前的研究重点在于高效训练模型领域，已在 NeurIPS、CVPR、EMNLP、IJCAI 等顶级会议上发表了数篇论文。&nbsp;</p>
  <p><strong>Minzhi Li，新加坡国立大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_080f26557d3b4d7ab265f6a47025b98d@46958_oswg130812oswg270oswg270_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Minzhi Li 是新加坡国立大学的博士生，指导老师为 Prof. Min-Yen Kan、Dr. Nancy F Chen 和 Prof. Shafiq Joty，同时也和杨笛一紧密合作。&nbsp;</p>
  <p>她正在探索如何评估计算机在自然语言处理方面是否具备一定的社会智能。目前，她创建了相关分类体系、数据集以及更高效的数据处理方法。&nbsp;</p>
  <p><strong>陈山，马斯特里赫特大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_5df341c7b8fa4417b5fb0570db025d27@46958_oswg2315273oswg1080oswg1465_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>陈山是哈佛 - MGB AIM 的博士生，与马斯特里赫特大学联合培养。他的目标是为医疗保健开发更可解释的人工智能系统，期望能建立起更稳健的评估方法，促进医生和患者沟通，为高风险医疗任务提供保障。&nbsp;</p>
  <h2><strong>安全、隐私与预防滥用</strong></h2>
  <p><strong>Zihan Wang，昆士兰大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_53ba34bb1c014772ae32177a355e343b@46958_oswg1468361oswg1080oswg1079_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Zihan Wang 为昆士兰大学的博士生，师从教授 Guangdong Bai 和 Jason Xue。目前他的研究兴趣是用形式化方法解决机器学习系统在现实世界中的安全和隐私问题。&nbsp;</p>
  <h2><strong>硅芯片研究</strong></h2>
  <p><strong>Yun-Chen Lo，台湾清华大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_6cf4288a91dd45d19e409a19669b9fca@46958_oswg1350436oswg1080oswg1100_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Yun-Chen Lo 目前是台湾清华大学的电子工程博士，在哈佛大学访学。他的研究重点在于为 AI 应用设计高效的 VLSI 架构和系统，有多篇论文被 MICRO、DAC、ICLR、ICCAD、ESSCIRC 和 TC 等顶会和期刊接收。&nbsp;</p>
  <p>个人主页：https://yunchenlo.github.io/&nbsp;</p>
  <h2><strong>语音处理</strong></h2>
  <p><strong>杨书文，台湾大学</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_b62b0c2572e94877a4affb27cb69a28d@46958_oswg364158oswg512oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>杨书文是台湾大学的博士，是语音处理与机器学习（SPML）小组的核心成员。同时，他也是目前被广泛使用的语音模型基础测试集 SUPERB 的一作。&nbsp;</p>
  <p>在业余时间，他喜欢弹钢琴。他致力于开发一个能够全面理解语音，像真人一样，可以与自然语言、视觉等模态融会贯通的感知系统。他的主攻方向是表征学习，最近的研究集中在自监督学习、表征泛化能力和高效的预训练等领域。&nbsp;</p>
  <p>个人网站：https://leo19941227.github.io/&nbsp;</p>
  <p><strong>参考链接：&nbsp;</strong></p>
  <p>https://research.google/programs-and-events/phd-fellowship/recipients/?filtertab=2024&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/5L39BdG6XWmL4Nl-pwM6kQ" rel="noopener noreferrer nofollow" target="_blank">“机器之心”</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3035993054048518</id>
            <title>估值已达10亿美元，这家法律AI公司在多项任务表现上远超GPT-4</title>
            <link>https://www.36kr.com/p/3035993054048518</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3035993054048518</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Nov 2024 09:13:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 法律科技, EvenUp, 融资  
<br><br>  
总结: “行业观察者”专栏关注人工智能、XR、元宇宙和Web3等前沿科技，介绍新兴企业和创业者的故事。法律科技公司EvenUp获得了1.35亿美元的融资，推动法律科技创新。EvenUp通过AI和数据分析优化法律索赔流程，提升律师事务所的案件评估和赔偿计算效率。其专有AI模型Piai™在处理人身伤害案件方面表现优于OpenAI的GPT-4，确保高精准度和人文关怀。此次融资将帮助EvenUp扩展产品线，开发更多法律服务领域的AI工具，进一步巩固其市场竞争优势。 </div>
                        <hr>
                    
                    <p><strong>“行业观察者”</strong> 是我们针对人工智能、XR、元宇宙和Web3等前沿科技而设立的专栏，主要分享这些领域中的新兴企业或者创业者们的故事。 <strong>法律科技公司EvenUp不仅获得了法律AI史上最大的一笔融资1.35亿美元，甚至其专有AI模型Piai™在人身伤害案件处理方面比OpenAI的GPT-4更胜一筹。以下是我们的第35期内容，以下Enjoy。</strong></p>
  <p>EvenUp公司近日成功完成了由Bain Capital Ventures领投，Premji Invest、Lightspeed Venture Partners、Bessemer Venture Partners等参投的1.35亿美元巨额融资，为其加速法律科技创新奠定了坚实基础。&nbsp;</p>
  <p>作为法律索赔AI技术的先行者，EvenUp致力于通过人工智能和数据分析，优化传统的索赔流程，帮助律师事务所在案件评估和赔偿计算上实现高效、精准的量化支持。&nbsp;</p>
  <p>此轮融资不仅反映了市场对法律科技的重视，也标志着EvenUp在推动法律服务公平性和透明化方面的潜力。&nbsp;</p>
  <h2><strong>01.1分钟项目速览</strong></h2>
  <p><strong>1.项目名称</strong> ：EvenUp&nbsp;</p>
  <p><strong>2.成立时间</strong> ：2019年&nbsp;</p>
  <p><strong>3.产品简介</strong> ：&nbsp;</p>
  <p>EvenUp应用机器学习及其AI模型Piai™来减少人工工作量并最大限度地优化人身伤害价值链中的案件结果，索赔情报平台™能够将内部人力法律专业知识与专有AI和软件相结合来分析记录。</p>
  <p><strong>4.创始人团队</strong> ：&nbsp;</p>
  <p>CEO：Rami Karabibar</p>
  <p>COO：Raymond Mieszaniecr</p>
  <p>CLO：Saam Mashhad</p>
  <p><strong>5.融资情况</strong> ：&nbsp;</p>
  <p>2023年4月6日，完成由Bessemer Venture Partners领投的5050万美元的B轮融资；</p>
  <p>2023年11月1日，完成由Lightspeed Venture Partners领投的3500万美元的C轮融资；</p>
  <p>2024年10月8日，完成由Bain Capital Ventures领投的1.35亿美元的D轮融资。</p>
  <h2><strong>02.“让公平更简单”</strong></h2>
  <p>EvenUp的成立初衷源自法律索赔流程中普遍存在的资源不平衡问题。&nbsp;</p>
  <p>传统的索赔过程中，原告律师往往需要花费大量时间搜集案例数据并计算合理的赔偿金额，而保险公司和大企业则拥有丰富的资源可以从中获利。&nbsp;</p>
  <p><strong>创始团队认识到，利用科技手段可以显著缩短这一过程，提高原告方的议价能力，并为伤者提供更公正的机会</strong> 。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_e4942cc250ef4be9b08a6729a17abc54@46958_oswg716616oswg1080oswg667_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>秉持着这样的想法，公司从创建初期就聚焦于人工智能和数据分析，力图通过数据驱动的方式帮助用户估算赔偿范围，并自动化生成法律文件，为诉讼过程提供支持。&nbsp;</p>
  <p><strong>团队中的大部分成员拥有计算机科学、人工智能或法律专业的背景，并曾在知名的法律科技公司或律所工作过</strong> 。通过多年的不断优化，公司逐渐完善了其AI系统，并得到了多家知名律师事务所的认可。&nbsp;</p>
  <p>EvenUp表示：“我们的使命是为人身伤害案件提供公平的竞争环境。我们相信，每起伤害案件都应根据其真实情况得到解决。”&nbsp;</p>
  <h2><strong>03.专有AI模型Piai™</strong></h2>
  <p>在人身伤害索赔处理中，精确度与准确性极为关键。<strong>尽管AI模型能协助完成部分任务，但起草高质量索赔文件的复杂性要求远超简单自动化</strong>。单纯依赖AI可能导致失误，遗漏关键信息，进而引发索赔延误和低估，给受害者带来重大经济损失。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_39ed3bdb3817444982966777db281888@46958_oswg23723oswg734oswg409_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>EvenUp公司融合了人工智能与专家人工审核，其专有的Piai™系统获得了SOC2和HIPAA认证，确保高精准度与人文关怀。&nbsp;</p>
  <p><strong>实体提取</strong> ：将杂乱无章的案件档案转化为清晰、可操作的见解。</p>
  <p><strong>关系映射</strong> ：对相关信息进行分类，消除损害赔偿的重复，协调提供商差异，并在数千页的资料中发现可能影响案件结果的关键见解。</p>
  <p><strong>产出生产</strong> ：遵守公司特定的语言和格式要求，而行级引用使其易于验证。</p>
  <p><strong>质量控制</strong>：凭借法律和医学专业知识获得可信赖的结果。</p>
  <p>此系统经过数十万起人身伤害案件的深度训练，并与一个由超过100名法律、医疗及法律辅助专家组成的世界级团队紧密合作，每周共同处理数千份诉求和医疗年表。&nbsp;</p>
  <p>鉴于每位原告通常仅面临一起可能影响其未来的案件，EvenUp深刻理解所肩负的重大责任。因此，公司采用双重策略—— <strong>结合AI与人工审核，力求确保每位原告都能获得应有的公正对待</strong> 。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_d69473afb1fe48c5a05c208f70414d90@46958_oswg193041oswg1080oswg628_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在对比EvenUp的Piai™与通用现成模型（如OpenAI的GPT-4）在人身伤害案件处理中的性能和结果时，差异显著。&nbsp;</p>
  <p><strong>Piai™不仅在多个核心领域表现优异，而且在处理人身伤害案件所需的多项关键任务上均保持高水平表现</strong> 。以下是Piai™相对于GPT-4的三项显著优势：&nbsp;</p>
  <p><strong>医疗费用</strong> ：Piai™识别医疗费用的准确率达到95%，而GPT-4只能达到80%。</p>
  <p><strong>治疗方法</strong> ：Piai™的治疗方法识别准确率为91%，而GPT-4的准确率为79%。‍</p>
  <p><strong>服务日期映射</strong> ：Piai™将服务日期映射到提供商，准确率为90%，大大超过了GPT-4的68%。</p>
  <p>从这一角度看，若在处理100个案件时有20%的账单遗漏（每份遗漏账单平均影响5000美元），律师可能会因此损失超过10万美元的索赔价值。</p>
  <p>EvenUp通过其解决方案有效解决了这一问题，确保所有相关账单得到记录，并最大化每个案件的索赔价值，这进一步强调了人身伤害索赔对精确度的极高要求。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_ff732ad56a0a40cc9c4d42ba4dd55563@46958_oswg351771oswg1080oswg678_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>2020年，EvenUp率先推出了基于AI的需求包，现已成为人身伤害AI和文档生成领域的领导者。到目前为止，已交付了约100,000份需求包和医疗年表。&nbsp;</p>
  <h2><strong>04.索赔情报平台™新功能</strong></h2>
  <p><strong>这1.35亿美元的最新融资使得EvenUp的估值超过10亿美元，成为法律AI史上最大的一轮融资</strong> 。&nbsp;</p>
  <p>凭借这笔融资，公司推出了四项新功能作为其Piai™提供支持的索赔情报平台™的一部分，旨在在案件生命周期的关键阶段提供见解，转变客户工作流程，以尽快实现索赔价值最大化。&nbsp;</p>
  <p>案件准备是同类产品中第一个主动帮助案件经理在案件生命周期内做出最佳决策的产品，包括在提出需求之前发现问题、先例和缺失的医疗账单和记录，提高案件准备质量，并减少解决时间。&nbsp;</p>
  <p>谈判准备帮助专业人员以简化的方式了解关键案例的优势和劣势。&nbsp;</p>
  <p>执行分析通过获取丰富的见解（例如治疗连续性、需求延迟等），以及强大的行业基准，使公司能够达到新的绩效水平，从而促进其运营中的最佳绩效。&nbsp;</p>
  <p>结算储存库采用数据驱动的方法来解决结果，确保人身伤害律师为其客户获得最佳结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241114/v2_bae8759416544c53ac7e25bf440dcf7d@46958_oswg314887oswg1080oswg625_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>此次融资将帮助EvenUp扩大其产品线，涉足更多法律服务领域。&nbsp;</p>
  <p>除了现有的索赔评估工具，公司还计划开发面向医疗事故、消费者保护、劳动争议等多个法律领域的AI工具，以应对不同案件类型的需求。&nbsp;</p>
  <p>新产品的推出将助力全球法律专业人士应对多样化的案件挑战，打造更高效、更智能的法律科技生态系统，并进一步巩固EvenUp在法律科技市场中的竞争优势。&nbsp;</p>
  <p>参考链接：&nbsp;</p>
  <p>1. https://www.evenuplaw.com/&nbsp;</p>
  <p>2.https://www.channelnewsasia.com/business/legal-ai-company-evenup-valued-over-1-billion-latest-funding-round-4665711&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/0CNw_0cASkW-qVkUKELZJw" rel="noopener noreferrer nofollow" target="_blank">“元宇宙之心MetaverseHub”</a>，作者：元宇宙之心，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>