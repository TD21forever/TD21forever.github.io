<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3072936239428232</id>
            <title>微软学起360，Windows 11也有自己的软件管家了</title>
            <link>https://www.36kr.com/p/3072936239428232</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072936239428232</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 12:51:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <Windows 10, Windows 11, Microsoft Store, 软件更新>
<br>
<br>
总结: 微软正在推动Windows 10用户升级到Windows 11，并警告Windows 10将于2025年停止支持。尽管如此，Windows 10的市场份额仍在上升，用户对Windows 11的兴趣不高。为提升Windows 11的吸引力，微软在最新版本中允许用户通过Microsoft Store直接更新Win32应用程序。此功能旨在帮助用户保持软件的最新版本，增强安全性。微软的策略是为新手用户提供便利，以吸引他们升级。随着用户群体的分化，许多用户对计算机的使用能力下降，软件管家功能的推出正是为了帮助这些用户。 </div>
                        <hr>
                    
                    <p>微软又在催促广大Windows 10用户升级Windows 11了，近期也开始明确向用户发出警示，Windows 10将于2025年10月14日正式停止支持服务。然而现实却是大家似乎对升级Windows 11兴趣缺缺，根据Statcounter公布的数据显示，今年11月Windows 10的市场份额不降反增、继续领先于Windows 11。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_7fc444940e8c424d98ea1e8a636bac06@000000_oswg35061oswg600oswg211_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>眼见Windows 11不受用户待见，微软方面选择了继续增加它的竞争力。在最新的Windows 11 Canary Channel Build 27758中，用户已经可以在Microsoft Store直接更新依赖外部更新机制的Win32应用程序。而在此之前，相关Win32应用程序的更新需要在对应应用内进行操作，这个新功能则将使得用户能够在Microsoft Store的库或应用商店页面实现更新。</p>
  <p>根据微软在官方博客中透露的信息显示，对由发布者提供和更新的Win32应用，Microsoft Store将支持直接更新。预览版用户可前往下载页面、并点击获取更新，如果任何安装的软件有更新则Microsoft Store会显示更新详情，用户只需点击更新按钮即可执行，但该功能不会自动进行更新。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_f23a01b52fa745b98e4c4a55d5db4725@000000_oswg23101oswg600oswg335_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如此看来，现在Microsoft Store也搞起了与360、腾讯电脑管家类似的软件助手功能，通过构建软件更新库、并抓取软件的更新信息，再检测用户已安装软件的版本日志，最终实现即便不是通过Microsoft Store下载的应用，也能获得最新的软件版本。</p>
  <p>其实微软提供的这个“软件管家”功能别看毫无新意，但对于相当多的用户来说是很有必要的。因为理论上保证应用始终处于最新版本有助于增强安全性，毕竟用户安装的某些软件可能由于长期未更新导致漏洞无法及时修复，但普通用户可能并不知道应用需要更新，进而让自己的电脑暴露在风险中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_69f03153b84c4b61bd8c62a9d12c5543@000000_oswg18919oswg600oswg331_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>再联系之前微软方面推出的电脑管家，不难发他们已经开始改变策略，尝试为小白用户提供便利，以吸引他们升级Windows 11。别看这样的做法有点“土”，但却相当有效，因为在经过移动互联网浪潮的洗礼之后，如今的PC用户群体实际上已经发生了分化，一部分是从PC时代一路走来的“老炮”，另一部分则是先通过手机触网、再购买电脑的“新人”。</p>
  <p>这里就要引入一个概念——“赛博文盲”。由于信息技术教育的匮乏，以及自移动互联网时代以来，智能手机在使用门槛上的“傻瓜化”，已经让相当一批用户的上网模式发生了变化，从以往主动获取信息变成了被动等待投喂。由此也使得大众使用计算机的能力不增反减，而B站UP主“庄不纯”的电子扫盲课办不下去，以及淘宝上“Steam代安装”服务热销其实都是这一现象的体现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_87c459e16b304111b907852a95c4ae82@000000_oswg38815oswg600oswg462_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>虽然计算机确实变得更加易用，做到了让用户不知其所以然也能拿起来就用，但傻瓜化的设计在无形中也剥夺了用户知其所以然的权利。一切行为都“默认”的结果，就是用户的一切也被软硬件厂商所定义和支配，由于“用自由换便利”过于契合厂商的商业化需要，以至于让用户变得懵懂已经成为了业界不可言说的一个潜规则。</p>
  <p>如今的现实，是懂得怎么去设置Windows系统让它更方便的用户已经越来越少，剩下的则是不会、也不懂，这时候软件管家确实在客观上可以帮助后者。比如同样是软件出现BUG导致无法使用，是让小白用户在搜索引擎的海量广告中成功找到软件的官网容易， 还是直接在Microsoft Store更新容易？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_59721efc9c014b7abb2cd94efcac7fd1@000000_oswg14636oswg600oswg273_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于用户而言，升级Windows 11显然需要有利可图，所以微软就得给些甜头。不然的话，难道升级Windows 11是图通知系统成为微软推广自家产品和服务的渠道，不停地向用户弹《使命召唤：黑色行动6》广告，还是内容堪比UC震惊部的桌面小组件信息流呢。</p>
  <p>在这样的情况下，使用Windows 11能让软件始终保持最新版本，让用户第一时间就用上软件的新功能，或许就是微软方面宣布Microsoft Store可以更新非官方渠道下载的Win32应用程序的关键。除此之外，这一设计需要用户在Microsoft Store内完成，对于提升后者的打开率无疑也会有一定帮助。毕竟万一用户在使用过程中觉得Microsoft Store体验更好，那就是意外之喜了。</p>
  <p>【本文图片来自网络】&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649876705&amp;idx=2&amp;sn=dc268bf9e535652c3c2d4ed332bfa9db&amp;chksm=86bf9b0d3a0313adc5216482be17bf010a67cfecf2ff4378cfbec2d5eac85af3fae2e879a769&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072982388634244</id>
            <title>告别VMware，被博通收购后涨价10倍，这家拥有2万台虚拟机的公司愤而“投奔”开源</title>
            <link>https://www.36kr.com/p/3072982388634244</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072982388634244</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 12:47:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: VMware, 博通, 迁移, OpenNebula  
<br><br>  
总结: 博通收购VMware后，VMware的价格大幅上涨，导致许多企业客户不满并寻求替代方案。Computershare和Beeks Group等公司因VMware的费用增加，决定将虚拟机迁移至Nutanix和OpenNebula等竞争产品。Beeks在迁移后，虚拟机效率提高了200%，显著降低了运营成本。VMware的策略导致其失去多个重要客户，市场份额可能进一步被竞争对手蚕食。企业对VMware的信任下降，转向开源平台以获得更大的控制权和灵活性。 </div>
                        <hr>
                    
                    <p>回顾 2023 年，博通（Broadcom）以 690 亿美元完成对 VMware 的收购后，其一系列的价格调整和策略变化给市场带来了震动。在这一过程中，许多企业客户对 VMware 的涨价、服务质量下降及创新停滞表示不满，转而寻求新的替代方案——半年前，全球股票市场股份登记运营商 Computershare 就是其中之一。</p>
  <p>当时，Computershare 首席技术官 Kevin O'Connor 声称，由于 VMware 骤然涨价了 10-15 倍，他决定把公司的 2.4 万台虚拟机都迁移到 VMware 的竞品 Nutanix 上。</p>
  <p>时隔半年，又一家“Computershare”出现了：面对 VMware 增长十倍的收费，近日英国云服务提供商 Beeks Group 也指出要将超过 2 万台虚拟机全部迁移至开源平台 OpenNebula。</p>
  <h2><strong>VMware 的巨额账单，迫使企业进行迁移</strong></h2>
  <p>据悉去年 12 月，VMware 刚被博通收购后不久，就发布了一个新的订阅制度，并在业内引起了广泛争议：停止销售永久许可证、永久产品的支持和订阅（SnS）续订以及混合购买计划/订阅购买计划（HPP/SPP）积分。</p>
  <p>也就是说，原本 VMware 客户所习惯的一次性购买、永久使用的“一锤子买卖”，被改为了按年/月付费订阅的方式，而官方对此给出的理由是：“以便通过持续创新、更快实现价值和可预测的投资为客户提供更好的服务。”</p>
  <p>除此之外，博通还将 VMware 之前众多的 SKU 合并成少数几个捆绑包，导致中小企业难以承担高昂的整体成本。有多位 VMware 客户表示：在博通的管理下，他们使用 VMware 的成本上涨了 300%。</p>
  <p>面对这些变化，众多企业不得不重新审视自己的 IT 基础设施投资——云服务提供商 Beeks Group 便是因此决定将 2 万台虚拟机进行迁移。</p>
  <h2><strong>迁移到 OpenNebula 后，Beeks 的虚拟机效率提高了 200%</strong></h2>
  <p>简单介绍一下，Beeks Group 是一家云服务提供商，专注于为金融服务业客户提供虚拟专用服务器（VPS）和裸金属服务器，特别是低延迟交易服务。它在全球 20 多个数据中心运营，拥有超过 20,000 台虚拟机和 3,000 多台裸金属服务器。</p>
  <p>然而，博通收购 VMware 后，Beeks 面临了极大的挑战。</p>
  <p>Beeks 的生产管理负责人 Matthew Cretney 透露，VMware 的账单直接增长了 10 倍。这对以金融客户为主、注重成本效率的 Beeks 来说显然不可持续。此外，其部分客户也明确表示，VMware 已不再是关键基础设施，希望 Beeks 提供更具性价比的解决方案。</p>
  <p>除了成本上涨的主要问题，Beeks 技术团队还对 VMware 进行了全面评估，还发现了以下问题：</p>
  <p>管理开销大：VMware 的虚拟化平台需要占用大量服务器资源进行管理，而这些资源本可用于客户服务。</p>
  <p>对裸金属服务器的支持不足：金融客户对低延迟和高安全性的需求越来越高，更倾向于使用裸金属服务器，而 VMware 平台无法同时高效管理虚拟机和裸金属服务器。</p>
  <p>服务质量与创新能力下滑：团队认为 VMware 的支持服务质量下降，同时产品创新乏力，未能满足快速变化的市场需求。</p>
  <p>经过调研，Beeks 决定采用开源的 OpenNebula 作为替代方案。据了解，OpenNebula 是一个灵活的开源平台，支持多种虚拟化技术（以 KVM 为主），同时兼容混合云和边缘计算场景。</p>
  <p>然而，迁移也并非易事。本身，Beeks 运行着与 VMware API 紧密耦合的专有软件，因此需要重建软件接口以便与 OpenNebula 适配。另外，OpenNebula 在收集 Beeks 及其客户关心的指标（如 CPU 性能、磁盘、内存、网络资源利用率）方面的工具尚不成熟，而这对交易速度至关重要，因为过载的 CPU 或磁盘可能会导致交易延迟。好在 OpenNebula 是开源项目，Beeks 能够开发自己的工具来收集所需信息，并成功解决了这些问题。</p>
  <p>尽管迁移过程并不轻松，但 Beeks 的付出得到了不错的回报：向 OpenNebula 迁移后，Beeks 的虚拟机效率提高了 200%，每台服务器能够承载更多虚拟机，这不仅降低了 Beeks 的整体运营成本，也为其客户带来了更大的经济效益。目前，Beeks 仍然在为一些依赖 VMware 的客户提供服务，但其大部分虚拟机已经成功转移到 OpenNebula 上。</p>
  <h2><strong>未来，VMware 是否会进一步被竞品“蚕食”？</strong></h2>
  <p>显而易见，Beeks 的案例并非个例。自从被博通收购以来，VMware 已经失去了多个重要客户，包括美国保险巨头 Geico、金融科技公司 Computershare、Boyd Gaming 和农业设备制造商 John Deere——而造成这一现象的主要原因是：博通大幅提高了 VMware 的使用成本。</p>
  <p>甚至像 AT&amp;T 这样的电信巨头也曾表示，博通提出的新定价方案导致其 VMware 成本增加 1050%，并因博通不再支持其已续订的永久许可证而起诉博通。尽管最终双方达成了和解，但这在很大程度上也表明，博通当前对于 VMware 的策略正迫使部分老客户寻求其他开源替代方案。</p>
  <p>正如 OpenNebula 的 CEO Ignacio Llorente 所言：“许多组织正在因价格上涨而寻找替代方案，本质上这是一个信任问题。企业不再相信 VMware 或其他依赖专有组件的供应商。”至少从 Beeks 的迁移成果来看，使用开源平台不仅显著降低了成本，还赋予了其更多的控制权和灵活性，这对于高度依赖定制化和高效利用资源的企业来说尤其重要。</p>
  <p>反观博通，虽然从目前的财务情况上来看，它从 VMware 收购中获益匪浅，但其策略的长期影响值得深思。如果现有客户的迁移趋势持续下去，未来 VMware 的市场份额很可能会进一步被竞争对手蚕食。</p>
  <p>参考链接：</p>
  <p>https://www.theregister.com/2024/12/02/beeks_group_vmware_opennebula_migration/</p>
  <p>https://arstechnica.com/information-technology/2024/12/company-claims-1000-percent-price-hike-drove-it-from-vmware-to-open-source-rival/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/za0t4FwY4gghXODTvUlfbw" rel="noopener noreferrer nofollow" target="_blank">“CSDN程序人生”</a>，整理：郑丽媛&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072920435684225</id>
            <title>Sora之后，视频生成模型的中国牌局</title>
            <link>https://www.36kr.com/p/3072920435684225</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072920435684225</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 12:26:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 视频生成, OpenAI, 国内企业  
<br><br>  
总结: Sora于12月10日正式发布，标志着视频生成领域的重大进展，OpenAI CEO称其为视频生成领域的“GPT-1时刻”。国内科技企业对Sora的反应不一，部分企业如字节跳动和快手选择跟进，推出相应的视频生成模型，而百度等公司则明确表示不跟进，认为商业化前景不明朗。视频生成模型的核心技术为Diffusion与Transformer结合，具备通用性和高质量的特点。整体来看，国内企业在视频生成领域的态度分化，面临技术、商业和市场竞争的多重迷雾。 </div>
                        <hr>
                    
                    <p>Sora，自2月16日OpenAI发布后一直被吐槽是“技术期货”，终于在12月10日，正式版Sora露面了，可以生成最高 1080p 分辨率、最长 20 秒的视频。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_9890ffc04af54839998de4933ee30c82@000000_oswg488784oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>OpenAI CEO奥特曼称，<strong>Sora正式版是视频生成领域的GPT-1时刻。</strong></p>
  <p>但国内AI企业，并没有像跟进GPT时期一样，在视频生成领域也与OpenAI保持同步，而是呈现出更复杂的态度。</p>
  <p>有人选择跟进，比如Sora问世之后，互联网公司如阿里、字节跳动、快手、腾讯等，AI公司如智谱AI、MiniMax、爱诗科技、生数科技等，都陆续发布了视频生成模型，不少都表示达到或超越了预览版Sora。</p>
  <p>也有人选择不跟进，包括互联网公司中的百度，李彦宏曾明确表示，“无论Sora多么火爆百度都不去做”。AI公司如百川智能，也明确表示不会做类Sora模型，月之暗面、商汤科技、零一万物虽然都有文生视频模型，但都不作为重点。</p>
  <p><strong>视频生成赛道，不再延续GPT时代的发展模式，即OpenAI打出一张王牌，国内科技企业抢着要跟。Sora之后，国内AI牌局开始有了自己的节奏，也呈现出更为复杂的局势。</strong></p>
  <p>有能力做通用基础大模型的国内科技公司，在技术路线、商业前景等判断上，开始出现明显分野。我们就从国内企业跟进Sora的选择与否，聊聊视频生成的中国牌局。</p>
  <h2><strong>To国内玩家:跟0r不跟S0ra, 这是一个问题</strong></h2>
  <p>首先我们要明确一下，国内对标Sora模型的科技公司，到底在做什么？</p>
  <p><strong>简单来说，Sora视频生成模型的核心技术路线是Diffusion+Transformer相结合，通过文本（自然语言）、图片、视频作为提示词prompts进行视频生成。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a2937f71112446aca1b142a64708130e@000000_oswg495240oswg1080oswg469_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对标Sora的模型，至少要具备几个特点：</p>
  <p>1.通用性，不针对某一类风格、行业、角色等，任意内容的视频都可以生成。</p>
  <p>2.高质量，画质精度高（达到1080p）、视频时间长（最长达一分钟）、画面一致性强（理解物理规律）。</p>
  <p>面对Sora，国内科技企业不像ChatGPT推出时那样毫无准备。但到底跟or不跟，却不再像ChatGPT那样高度一致，而是分化成了三类：</p>
  <p><strong>第一类，明确跟进。</strong></p>
  <p>互联网公司阵营中，以视频为核心业务的字节跳动、快手等，以及综合科技公司腾讯，数字基建成熟，技术人才资源充沛，内部有视频产品基因，几乎第一时间选择了跟进。字节跳动推出了即梦Dreamnia，快手也发布了可灵大模型。腾讯以混元大模型作为核心，发布并开源了混元多模态生成模型，被认为是腾讯版Sora。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_bdf238f26faf420a8fbb3eea55e3597b@000000_oswg487817oswg1080oswg543_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>大模型初创企业中，智谱AI的行动最为敏捷，今年7月发布了AI视频生成工具清影，支持用户通过文本/图片，生成10秒、4K、60帧视频。MiniMax的海螺AI也在十月增加了视频生成能力，支持文本提示词生成6秒视频片段。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_48c89ebfdd2a44b3abadf1c9c05a81e0@000000_oswg485497oswg1080oswg526_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>第二类，坚决不跟。</strong></p>
  <p>与第一类企业的态度截然相反，互联网公司和大模型创企中也有坚决不跟Sora的。比如Sora问世之后，百川智能的王小川就表示，团队有人提出要做Sora，但他明确表态称不会跟进这个方向。</p>
  <p>同样想法的还有百度李彦宏，尽管百度已经在视频生成领域取得了一定的成果，但他不做Sora的态度也非常坚决，原因是Sora的商业化可能要五年甚至十年，目前百度更聚焦在大语言模型、多模态大模型，没有类Sora的产品化尝试。</p>
  <p><strong>第三类，浅尝辄止。</strong></p>
  <p>除此之外，还有大量国内企业对于Sora，出于FOMO“恐惧错过”心理有所布局，但并不重点投入，处于一种浅尝辄止的状态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ae7bd9f4e17c45f498ea2792888829c0@000000_oswg529092oswg1080oswg591_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>比如阿里系中的阿里妈妈团队发布了tomoVideo，试水电商营销的视频生成场景；“大模型六小虎”中，月之暗面也推出了视频生成模型，但仍聚焦在kimi产品上；零一万物入局B端业务，而视频生成模型面向的影视制作行业正处于调整期，类Sora产品也很难成为核心增长点。</p>
  <p>总结一下，如果说全球大模型是一场“斗地主”，那么游戏规则不再是OpenAI打出一张王炸，国内科技公司纷纷跟上，而是各自按照自己手里的牌面、业务重要性和优先级，来确定Sora的出牌策略。</p>
  <p>为什么到了Sora，大模型行业的游戏规则就变了？</p>
  <h2><strong>视频生成,迷雾中的牌局</strong></h2>
  <p>国内科技企业的表现说明，对于Sora存在非共识，整体还是比较混乱、规则模糊的阶段。迷雾中的领域，游戏规则自然只能自行探索。</p>
  <p>如今视频生成领域的现状，笼罩着三重迷雾。</p>
  <p><strong>技术迷雾：OpenAl认为Sora是世界模拟器、通往AGl的一条有前途的途径，这一技术路线目前存在不少争议。</strong></p>
  <p>比如李飞飞、lecun等人认为，Sora不能实现AGI。李飞飞提出，Sora仍是二维图像，只有三维空间智能才能实现AGI。Sora预览版展示的“日本女性走过霓虹闪烁东京街头”的生成视频，就无法把摄像机放在女子背后，说明Sora并没有真的理解三维世界。学术大神Lecun也点名不看好Sora，说它根本不是真正的世界模型，并且仍会面临GPT4的巨大瓶颈。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_f2a8a64434bb49af8203ba8a0639dbbb@000000_oswg742717oswg857oswg464_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>确实，即使是正式版Sora，生成的手部细节不准确，动态过程中的一致性等问题，依然存在。</p>
  <p>而国内公司坚定不跟进Sora的原因之一，也是对这一技术路线保留意见。比如百川智能的王小川就认为，Sora只是阶段性产物，技术高度、突破性以及应用价值均不及GPT。总之，实现AGI、模拟物理世界的技术路线的开放性，决定了Sora并非唯一解。</p>
  <p><strong>商业迷雾：视频生成模型的商用前景、投资回报比，在短期内都不明朗，成为劝退国内企业的另一重阻碍。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_d99dd2de355f4d288dd3971fe2352b6c@000000_oswg914772oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>预览版和正式版Sora，都延续了OpenAI的“暴力美学”，OpenAI 研究科学家 Noam Brown 表示，<strong>Sora是scale力量最直观的展示，也就是通过堆算力、对数据、对参数量的方式，来尝试让大模型涌现出理解物理世界的能力。</strong>这种方法成本高、资源投入大。是否跟进Sora，就取决于各家对模型的商用预期和投资回报比。</p>
  <p>如果视频生成模型面向ToB收费，通过API或SaaS服务，都需要基础模型厂商投入大量人力去优化业务流程、开发交互页面，而影视行业正处于调整周期，AI影视制作业务的增长有限。这就在无形中增加了AI企业的机会成本，因为同样的人力、物力、算力，投入到金融AI、教育AI、大型政企等领域，显然收效更大。所以，百度、零一万物等公司，都将视频生成领域作为边缘业务，并不重点投入。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_737998de1390432d93b989e85df15e4d@000000_oswg380354oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而ToC场景中，一方面个人付费意愿不高，视频生成并不是大众日常使用的高频场景，而且生成成本和订阅费一般都比文本模型高，加上Sora模型都没能解决幻觉、一致性难题，未必能创造实际价值，所以C端付费规模十分有限。另一方面，模型完全免费，把视频生成模型产品作为企业的流量入口，这一商业模式只适合将视频作为核心业务的企业。</p>
  <p>比如快手、字节跳动，本身就有核心的视频业务，可以快速实现模型的规模化。面向C端用户或B端生产力工具，这类企业能够快速将视频生成能力与现有产品进行集成与整合，模型研发的边际成本是会随着规模商用而下降的。</p>
  <p>整体来看，对国内绝大多数基础模厂，视频生成领域都是一个相对边缘、投资回报比不高的业务。</p>
  <p><strong>第三重迷雾，就是市场格局的竞争迷雾。</strong></p>
  <p>虽然视频生成模型现在商业前景不明，但有没有可能以后会爆发，企业悄悄投入然后惊艳所有人？这种押注边缘赛道“捡大漏”的商业神话，在大模型身上恐怕很难发生。</p>
  <p>当前，大模型的产品化、商业化前景普遍比较模糊，通用模型厂商都需要尽快从一大堆不甚明朗的产品中，选出一个更高成功概率和更大市场潜力的选项，重点投入。而在所有产品中，视频生成模型是一个尤为沉重且具有挑战性的项目。这种情况下，肯定要优先考虑成功率更高的产品，降低视频生成模型的业务优先级。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_517dc5bb57324fb8b9dbad194ff7ccad@000000_oswg353987oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>换一个角度，即便企业将视频生成模型的优先级放到最高，恐怕也很难建立起竞争优势。因为当前大模型的市场竞争情况跟GPT时期不太一样，如今各家在基础训练设施、核心架构设计与技术储备等方面都有了一定积累，复现Sora并上线类Sora应用的技术壁垒，其实没有ChatGPT时期那么难了。这也意味着，<strong>即使企业先发布了视频生成模型，也未必能长期保持竞争优势和市场垄断地位，这种竞争态势也削弱了Sora的商业想象空间。</strong></p>
  <p>技术迷雾、商业迷雾、竞争迷雾，仍然笼罩在视频生成领域，导致Sora这一场牌局有着太多的不确定，和太多可能。哪种理解是对的，哪条路线是最终赢家，目前都言之过早，各家只能按照自己的游戏规则玩下去。</p>
  <h2><strong>Must Go 0n，The Show轻装上阵</strong></h2>
  <p>大模型技术必须继续发展下去，但从Sora开始，国内科技企业不再紧跟着OpenAI亦步亦趋，开始有了自己的节奏感。</p>
  <p>具体表现在，对于Sora这样一鸣惊人的新东西，国内企业在大模型产品化、商业化上都有了自己的理解与思考，开始自己定义玩法，跟进Sora展现的是实力，不跟进Sora展现的是心态与战略定力。</p>
  <p>此外，不一味跟进产品，但OpenAI的叙事能力仍然值得学习。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a571ad75888548978ecba049049d2d0f@000000_oswg529321oswg1080oswg564_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>无论是2月用Sora抢走谷歌风头，还是近期Sora正式上线，OpenAI总能一次次带动节奏、设置议题、吸引关注，这对于资本密集型AI企业是非常重要的能力。</p>
  <p><strong>可以不跟进Sora，但不能遗漏关键技术。</strong></p>
  <p>以百度为例，虽然没有推出Sora产品的计划，但自身也没有缺席关键技术，比如自研了多模态可控生图技术，能够在保持实体特征不变的情况下，实现图像的高泛化生成，而可控性的提升，恰恰是视频生成下一阶段核心中的核心。此外，百度也没有完全无视视频生成领域，目前投资了视频生成初创公司生数科技、AI视频短剧公司井英科技等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b0824e59556e4ef8a2b468ecb73f319e@000000_oswg336925oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>聚焦主赛道，以自身核心业务、商业优先级等多元因素来确定追赶Sora的轻重缓急。大模型的牌局，国内企业正在找到自己的节奏感。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzUxNTUyMjE4Mw==&amp;mid=2247525136&amp;idx=1&amp;sn=af76e1ba8b0c560a32a43040353a1dbd&amp;chksm=f844333ca40bcd2f6dd5d6b472b41be53a6c4a6d85ffad2307919f2b433d55c4bd5fab88352c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“脑极体”（ID：unity007）</a>，作者：藏狐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072850497273603</id>
            <title>市值一夜蒸发6400亿，回顾英伟达被调查始末，华为或成最终赢家？</title>
            <link>https://www.36kr.com/p/3072850497273603</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072850497273603</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 12:21:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, 反垄断调查, GPU市场, 中国市场  
<br><br>  
总结: 市场监管总局对英伟达公司因涉嫌违反反垄断法进行立案调查，主要是由于其在中国市场的承诺未能履行，导致其股价大跌。英伟达在全球GPU市场占据绝对领导地位，但面临来自美国和欧盟的反垄断审查。此次调查并非针对中国市场，英伟达的断供行为引发了国产GPU厂商的崛起。华为、壁仞科技和摩尔线程等企业正在填补市场空白，尽管它们在技术和生态方面仍需努力。未来，中国在AI大模型竞争中需实现自主创新和生态体系发展。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0a36e8ed8677491390d3d63a8e4951b2@5813014_oswg262265oswg517oswg290_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>12月9日晚间，市场监管总局发布公告，称近日，因英伟达公司涉嫌违反《中华人民共和国反垄断法》及《市场监管总局关于附加限制性条件批准英伟达公司收购迈络思科技有限公司股权案反垄断审查决定的公告》（市场监管总局公告﹝2020﹞第16号），市场监管总局依法对英伟达公司开展立案调查。</p>
  <p>针对立案调查一事，<strong>英伟达方面在今日表示，“我们努力在每个地区提供最好的产品，并在我们开展业务的任何地方履行我们的承诺。我们很乐意回答监管机构对我们业务的任何问题。”</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a9b6ddbca3ca4977bf0cbb10420b614d@5813014_oswg202881oswg693oswg617_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>受此事件影响，英伟达当日（9日）股价大跌2.55%，市值一夜之间蒸发市值一夜蒸发889亿美元（约合人民币6460亿元）</strong>，超过了一个英特尔的市值（897.54亿美元）。</p>
  <h2><strong>美、英先后调查，英伟达并非被中国针对</strong></h2>
  <p>英伟达作为全球GPU算力的绝对领导者，在AI大模型时代占据不可替代的地位。在AI大模型称为行业的风口的这几年，其产品作为重要的大模型训练和推理硬件设施，一直保持着“供不应求”的状态。</p>
  <p>富国银行数据显示，2023年英伟达在全球数据中心GPU市场的份额高达98%，远远领先第二名AMD的1.2%和第三名英特尔不足1%。</p>
  <p>其中，英伟达在中国市场的营收占其全球总收入的12.7%。2024年前三季度，英伟达在中国大陆和香港地区的营收达到115.7亿美元。</p>
  <p>而此次英伟达被立案调查，主要依据还是公告中另一条公告，即《市场监管总局关于附加限制性条件批准英伟达公司收购迈络思科技有限公司股权案反垄断审查决定的公告》（市场监管总局公告﹝2020﹞第16号）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b3147799ca374071bf9177f1ef4f091f@5813014_oswg101050oswg693oswg304_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2019年,英伟达高调宣布以69亿美金价格收购以色列网络设备供应商迈络思。收购完成后，迈络思成为英伟达的全资子公司。由于英伟达和迈络思均在全球具有垄断地位，该并购案对全球市场有潜在影响，因此这一交易随后经过了美国、欧盟、中国等国家和地区市场监管部门的批准。</p>
  <p>2020年4月16日，中国市场监管总局有条件批准了这项收购，既是最后一个批准这笔交易的国家，也是决定这笔收购案是否成功的关键。市场监管总局要求英伟达在交易完成后六年内，依据公平、合理、无歧视原则继续向中国市场供应相关产品，并不得强制搭售或附加不合理交易条件。</p>
  <p>然而，<strong>自2022年起，英伟达多次对中国市场断供GPU产品，涉嫌违反这些承诺，从而引发中国反垄断执法机构的调查。</strong></p>
  <p>中国的反垄断调查并非孤例。今年8月，美国司法部对英伟达启动反垄断调查，重点关注其在人工智能芯片销售中的市场支配行为。12月7日，欧盟也对英伟达展开反垄断审查，进一步强化对其在全球市场影响力的监管。</p>
  <p>美国司法部反垄断部门负责人乔纳森·坎特指出，英伟达主导了最先进GPU的销售，使这一资源变得稀缺，影响了市场竞争格局。为了打破垄断，美国政府还通过《芯片法案》推动国内芯片生产，并提供390亿美元奖励措施。</p>
  <p><strong>英伟达面临的不仅是反垄断监管，还包括美国对华出口管制的重重限制。</strong>自2022年以来，美国不断升级半导体出口限制，禁止英伟达高性能GPU芯片如A100、H100及其替代产品向中国出口。这些措施不仅阻碍了英伟达对中国市场的供应，也与其在中国的经营承诺产生冲突。</p>
  <p>虽然英伟达尝试推出特供版A800和H800芯片，但这些产品仍然受到严格的出口管制限制。<strong>更有消息称，其计划于2024年推出的H20等AI芯片量产计划也被迫中止。</strong></p>
  <h2><strong>华为、壁仞、摩尔线程谁是赢家？</strong></h2>
  <p>对于英伟达自身而言，彻底放弃中国市场，意味着至少将减少15%-20%的营收与利润。随着英伟达因“反垄断”调查面临中国市场的不确定性，国产GPU厂商的崛起成为关注焦点。这不仅关系到你我平日打游戏用的PC级GPU产品，更为重要的是面向toB市场的AI加速芯片的供给。</p>
  <p><strong>大模型之家注意到，华为、壁仞科技和摩尔线程等企业正在以不同的方式填补这一空白，它们在硬件性能、开发生态和产业链支持等方面展开了激烈竞争。</strong></p>
  <p><strong>华为昇腾系列：算力领先，生态待完善</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_e371aeb6057d4e1da705cca08f89dce7@5813014_oswg351967oswg693oswg389_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>华为昇腾A910系列芯片峰值算力高达256-280 TFLOPS（FP16），性能接近英伟达A100的312 TFLOPS。实际使用中，经过NPU算子优化后的算力达到A100的80%左右，表现较为出色。然而，华为在高速互联和开发者生态方面的短板较为明显。例如，其HCCS互联技术仅支持不到100GB/s的带宽，与英伟达NVLink的1800GB/s存在明显差距。</p>
  <p>在软件支持上，华为受限于资源投入，短期内仍然需要追赶与英伟达多年来构建的CUDA开发生态。</p>
  <p><strong>壁仞科技：强算力定位AI，灵活但通用性存疑</strong></p>
  <p>壁仞科技的BR100芯片以强大的AI算力著称，16位浮点算力超过1000 TFLOPS，峰值算力达到PFLOPS级别。通过与浪潮科技合作，壁仞推出了基于BR100的“海玄”服务器集群，面向高能效AI计算场景。然而，其牺牲FP16的通用计算能力，专注于矩阵运算的策略可能限制其在多样化场景中的适用性。</p>
  <p>壁仞在硬件算力上的领先优势显著，但在开发生态和市场应用支持上仍需努力。与华为相比，壁仞更适合特定AI任务，而非大规模通用计算需求。</p>
  <p><strong>摩尔线程：从游戏到AI的跨越尝试</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_595a8e1083214bc1a2875254921fe945@5813014_oswg249982oswg693oswg334_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>摩尔线程以游戏GPU起家，在AI加速领域的探索逐步推进。其最新发布的MTT S4000智算加速卡支持多卡互联，具有48GB显存和240GB/s的片间互联带宽，主打分布式计算能力。通过自研的MUSIFY工具，摩尔线程实现了CUDA代码的迁移，试图打破英伟达生态的壁垒。</p>
  <p>除此之外，<strong>当前国内还有很多家寒武纪，燧原、沐曦、景嘉微等企业，但在体量、技术、产业链成熟度上还与前者有差距。</strong></p>
  <p>尽管硬件参数接近主流国际产品，但摩尔线程在超算集群建设和软件优化上依然面临挑战。其在市场定位上更倾向中小型AI场景，与华为和壁仞形成互补，但整体技术深度尚不足以支撑大规模企业需求。</p>
  <p>虽然从纸面参数上似乎都很接近，但是决定AI卡的性能由4个方面决定：Library、算力、显存和高速互联。不只要有基础的单卡算力，更为重要的是要支撑万卡、十万卡、乃至更大的算力集群，内存、与并行传输的能力就会受到极大考验。</p>
  <p>而这正是英伟达所优势的领域，<strong>英伟达在高速互联技术NVLink上也具备压倒性优势，其1800GB/s的带宽远超国内竞争对手，成为超大规模AI计算集群的关键技术。</strong></p>
  <p>在单卡算力和互联带宽方面，国产厂商虽然不断缩小与英伟达的差距，但后者的优势主要集中在开发者生态和软件支持。早在2006年，英伟达就开始构建CUDA生态，通过高效的汇编代码和丰富的工具链，为AI运算提供了强大支持。</p>
  <p>为了稳固自家的生态，2024年3月，英伟达在CUDA 11.6的用户许可中明确表示，禁止其他硬件平台上通过翻译层运行CUDA英伟达禁止第三方使用CUDA，针对Intel、AMD都有参与的ZLUDA等第三方项目，以及登临科技、沐曦科技等中国厂商的兼容方案。</p>
  <p>而考虑到to B产业方面，<strong>只有华为具备稳定供货能力和强大的综合实力，未来在中国市场可能成为最大受益者。</strong>但也有服务器经销商向笔者表示，目前910B的服务器价格已经超过170万元，价格甚至一度超过英伟达服务器。</p>
  <p><strong>在大模型发展的道路上，我们要正视差距，才可能实现追赶与超越。未来，要在AI大模型竞争中保持全球领先，中国不仅需要在GPU等硬件技术上实现自主创新，还必须推动数据治理、应用落地和生态体系的全面发展。这不仅关乎一场技术竞赛，更是产业竞争的全局战役。</strong></p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/nJrm2pE42UuxfBTZV-yE1g" rel="noopener noreferrer nofollow" target="_blank">“大模型之家”</a>，作者：乔志斌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072619618450950</id>
            <title>车路云一体化网络：数据质量才是 “王炸”</title>
            <link>https://www.36kr.com/p/3072619618450950</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072619618450950</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 12:18:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 车路云一体化, 数据质量, 智能交通, 交通安全  
<br><br>  
总结: 车路云一体化是未来交通发展的重要趋势，通过将车辆、道路和云端数据紧密连接，提升交通的智能化水平。其核心在于建立一个一体化的系统平台，确保数据的高质量。网络基础设备提供商、智能网联数据运营商和终端制造商在数据采集、传输和处理等环节中扮演着关键角色。高质量的数据不仅能提升交通安全性，还能优化交通效率，推动智能交通的创新应用。因此，重视数据质量的提升是实现车路云一体化可持续发展的基础。 </div>
                        <hr>
                    
                    <p>你能想象吗？未来的道路上，车辆不再只是孤独的行者，而是与道路、云端共同编织成一张智能大网。车路云一体化这个概念，如今正以前所未有的速度改变着交通的模样。它打破了传统交通的边界，仿佛开启了一场交通界的 “变形金刚” 式进化。&nbsp;</p>
  <p>然而，车路云一体化并非仅仅是让 “聪明的车” 更聪明、“智慧的路” 更智慧、“强大的云” 更强大这么简单。其核心关键在于拥有一个一体化的系统（网络）平台，这个平台犹如一座坚实的桥梁，将车、路、云三端的通感算数据紧密连接。通过 AI 大模型的强大能力，对这些数据进行深度融合，再精准地赋能给车辆或交通管理者。</p>
  <p>在这一宏大变革中，车路云网络建设无疑是核心战场。而今天，咱就来唠唠这个战场中的关键秘密武器 —— 数据质量。</p>
  <h2><strong>车路云一体化与通信的相似性</strong></h2>
  <p>车路云一体化与通信领域有着诸多惊人的相似之处。正如通信网络中包含基站、运营商和终端设备等关键要素一样，车路云一体化体系中也存在着对应的重要角色。网络基础设备提供商类似于通信中的基站建设者，他们负责构建车路云网络的物理基础架构，包括道路上的传感器、通信基站、数据处理中心等硬件设施的铺设与搭建。这些基础设施如同通信网络的骨架，为数据的传输与交互提供了可能的物理通道。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b3c3badd14434e6ea522455af456a878@35930_oswg589793oswg1080oswg883_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>智能网联数据运营商则承担着通信运营商在车路云体系中的角色。他们负责对海量的交通数据进行收集、整理、分析与分发。在车路云一体化环境下，车辆、道路设施以及行人等各类交通参与者所产生的数据量极为庞大，这些数据需要经过专业的处理才能转化为有价值的信息，进而为交通决策、车辆行驶控制等提供依据。数据运营商通过建立高效的数据管理平台，运用先进的数据处理算法，确保数据能够在整个网络中顺畅地流动，并被合理地利用。</p>
  <p>终端制造和服务商类似于通信中的终端设备制造商与相关服务提供商。在车路云一体化中，终端涵盖了智能汽车、智能交通设备（如智能路灯、智能交通标志等）以及车内的各种智能终端设备，未来可以拓展到各类智能体（包括机器人、机器狗等）。终端制造和服务商不仅要确保这些终端设备具备强大的感知、计算与通信能力，能够准确地采集数据并及时传输，还要为终端用户提供丰富多样的服务，如车辆的智能驾驶功能、交通信息查询与推送等服务。</p>
  <h2><strong>网络基础设备提供商的关键作用与数据质量关联</strong></h2>
  <h3><strong>（一）硬件设施建设对数据采集的影响</strong></h3>
  <p>网络基础设备提供商所构建的硬件设施直接决定了数据采集的范围、精度与可靠性。例如，道路上部署的高精度传感器能够精确地测量车辆的速度、位置、行驶方向以及道路的路况信息（如路面平整度、积水深度等）。根据 《车路云一体化中道路传感器布局优化研究》中的研究成果，合理布局的传感器网络可以显著提高数据采集的完整性与准确性。如果传感器的布局过于稀疏或者存在盲区，将会导致部分数据缺失，从而影响整个车路云网络对交通状况的全面感知。</p>
  <p>此外，通信基站的建设质量也对数据传输有着至关重要的影响。强大而稳定的通信基站能够确保车辆与云端、车辆与道路设施之间的数据传输高速且稳定，减少数据传输过程中的延迟与丢包现象。一旦通信基站的覆盖范围不足或者信号强度不稳定，就可能导致数据在传输过程中出现错误或丢失，进而影响数据质量。</p>
  <h3><strong>（二）设备维护与数据质量的长期稳定性</strong></h3>
  <p>除了建设阶段，网络基础设备提供商还需重视设备的维护工作。长期运行的道路传感器、通信基站等设备可能会出现老化、故障等问题。如果不能及时发现并修复这些问题，将会导致数据采集与传输的异常。例如，传感器的老化可能会使测量数据产生偏差，通信基站的故障可能会导致数据传输中断。因此，建立完善的设备维护机制，定期对设备进行巡检、校准与维修，是保障数据质量长期稳定的重要举措。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_60826136353047ba8394a0dc166907e6@35930_oswg45418oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>智能网联数据运营商的核心职能与数据质量把控</strong></h2>
  <h3><strong>（一）数据收集与整合的全面性</strong></h3>
  <p>智能网联数据运营商的首要任务是收集来自各个源头的数据。这些数据包括车辆的运行数据（如车速、发动机工况、驾驶行为数据等）、道路设施的数据（如交通信号灯状态、道路拥堵情况等）以及其他交通参与者的数据（如行人的位置与行动轨迹等）。在数据收集过程中，确保数据的全面性是提高数据质量的基础。根据《车路云一体化数据收集与整合策略研究》的观点，通过多源数据融合技术，可以将不同类型、不同来源的数据进行有机整合，从而为后续的数据分析提供更丰富的素材。然而，如果在数据收集过程中遗漏了某些重要数据源，或者对数据的整合存在缺陷，将会导致数据的片面性，影响基于这些数据所做出的交通决策的准确性。</p>
  <h3><strong>（二）数据分析与挖掘的深度</strong></h3>
  <p>在收集到海量数据之后，数据运营商需要运用先进的数据分析与挖掘技术，从这些数据中提取有价值的信息。例如，通过对车辆行驶数据的分析，可以预测车辆的故障风险，提前安排维修服务；通过对交通流量数据的分析，可以优化交通信号灯的配时方案，提高道路通行效率。但是，数据分析的深度直接取决于数据质量。如果数据存在噪声、错误或者不完整等问题，将会影响数据分析算法的准确性与有效性。例如，在基于机器学习算法进行交通流量预测时，如果输入的数据存在大量误差，那么预测结果将与实际情况相差甚远，无法为交通管理提供可靠的参考。</p>
  <h3><strong>（三）数据分发与共享的安全性与及时性</strong></h3>
  <p>智能网联数据运营商还负责将处理后的数据分发给需要的各方，包括车辆终端、交通管理部门等。在数据分发与共享过程中，保障数据的安全性是至关重要的。数据中包含了大量的敏感信息，如车辆的位置信息、车主的个人信息等，如果这些信息泄露，将会对用户隐私造成严重侵犯。同时，确保数据分发的及时性也对数据质量有着重要影响。及时更新的交通信息能够帮助车辆做出更合理的行驶决策，提高交通运行的效率。例如，如果交通拥堵信息不能及时传达给车辆，车辆可能会继续驶入拥堵路段，加剧交通堵塞。</p>
  <h2><strong>终端制造和服务商的重要使命与数据质量保障</strong></h2>
  <h3><strong>（一）终端设备的数据采集能力</strong></h3>
  <p>终端制造和服务商所生产的智能终端设备是车路云网络数据采集的重要源头之一。例如，智能网联汽车上配备的激光雷达、摄像头、毫米波雷达等传感器能够实时采集车辆周围的环境信息。这些传感器的性能直接决定了数据采集的精度与可靠性。根据《智能汽车传感器性能对车路云数据质量的影响研究》，高分辨率的摄像头能够更清晰地识别道路标志与行人，激光雷达能够更精确地测量车辆与障碍物之间的距离。如果终端设备的传感器性能不佳，采集到的数据将存在较大误差，从而影响整个车路云网络的数据质量。</p>
  <h3><strong>（二）终端设备的数据传输与处理能力</strong></h3>
  <p>除了数据采集，终端设备还需要具备强大的数据传输与处理能力。在车路云一体化环境下，车辆需要及时将采集到的数据传输给云端或其他交通设施，同时也需要接收来自云端的指令与信息。如果终端设备的数据传输模块存在缺陷，如传输速率低、信号不稳定等问题，将会导致数据传输延迟或失败，影响数据的及时性与完整性。此外，终端设备内部的数据处理芯片也需要具备足够的运算能力，能够对采集到的数据进行初步处理，减轻云端的数据处理压力。例如，车辆可以在本地对一些简单的交通场景进行识别与判断，只有在遇到复杂情况时才将数据上传至云端进行进一步分析。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_28efccd039af4517a3fe58714edd5b92@35930_oswg551717oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>（三）终端服务与数据质量的用户体验关联</strong></h3>
  <p>终端制造和服务商为用户提供的各种服务也与数据质量密切相关。例如，智能驾驶辅助服务需要基于高质量的数据才能准确地为驾驶员提供预警、导航等功能。如果数据质量存在问题，如地图数据不准确、交通信息更新不及时等，将会导致智能驾驶服务的可靠性下降，影响用户体验。因此，终端制造和服务商需要不断优化服务内容与质量，确保数据在终端设备上能够得到有效的利用，为用户提供安全、便捷、舒适的交通服务。</p>
  <h2><strong>数据质量对车路云一体化发展的深远影响</strong></h2>
  <h3><strong>（一）提升交通安全性</strong></h3>
  <p>高质量的数据能够为交通决策提供准确的依据，从而有效提升交通安全性。例如，通过对车辆行驶数据和道路环境数据的实时分析，可以及时发现潜在的安全隐患，如车辆故障风险、道路湿滑或结冰等情况，并提前向车辆和交通管理部门发出预警。车辆可以根据这些预警信息及时调整行驶策略，如减速慢行、变更车道等，避免交通事故的发生。同时，在事故发生时，准确的数据也能够帮助救援部门快速定位事故地点，制定合理的救援方案，减少事故损失。</p>
  <h3><strong>（二）优化交通效率</strong></h3>
  <p>在车路云一体化网络中，数据质量直接影响交通效率的优化。精确的交通流量数据、道路拥堵数据以及车辆行驶计划数据等能够帮助交通管理部门制定科学合理的交通管控策略，如动态调整交通信号灯配时、规划车辆行驶路线等。例如，根据实时交通流量数据，交通管理部门可以在高峰时段延长主干道的绿灯时间，减少车辆等待时间；智能导航系统可以根据道路拥堵情况为车辆推荐最优行驶路线，避免车辆盲目驶入拥堵路段，从而提高整个交通网络的通行能力。</p>
  <h3><strong>（三）推动智能交通创新应用</strong></h3>
  <p>良好的数据质量是推动车路云一体化智能交通创新应用的基础。基于高质量的数据，我们可以开发出更多智能化、个性化的交通服务应用。例如，基于车辆的位置数据、用户的出行习惯数据以及交通设施的运行数据，可以打造一体化的出行服务平台，为用户提供一站式的出行规划、预订、支付等服务；还可以开展基于大数据的交通保险服务创新，根据车辆的行驶数据和风险评估模型，为车主提供更加精准、个性化的保险方案。&nbsp;</p>
  <p>车路云网络建设作为车路云一体化发展的关键环节，其核心在于数据质量。网络基础设备提供商、智能网联数据运营商、终端制造和服务商这三大角色在车路云网络建设中各自承担着独特而又相互关联的职能，他们的工作成果都直接或间接地影响着数据质量。从硬件设施建设到数据收集、分析、分发，再到终端设备的数据采集与处理以及服务提供，数据质量贯穿于车路云网络建设的全过程。只有确保数据质量，才能充分发挥车路云一体化在提升交通安全性、优化交通效率、推动智能交通创新应用等方面的巨大潜力，为构建更加智能、高效、安全的未来交通体系奠定坚实的基础。在未来的发展中，我们应高度重视数据质量的提升，不断完善车路云网络建设的各个环节，促进车路云一体化的健康、可持续发展。</p>
  <p>本文来自微信公众号“山自”，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072913813336960</id>
            <title>iPhone SE 4 最新爆料：全面屏来了，还支持苹果 AI</title>
            <link>https://www.36kr.com/p/3072913813336960</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072913813336960</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 12:13:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: iPhone SE 4, 升级, OLED显示屏, 性能配置  
<br><br>  
总结: 最近爆料者透露了iPhone SE 4的完整规格，预计将于明年春季发布。这款机型是SE系列自问世以来的重大升级，外观设计将采用类似iPhone 14的全面屏，首次配备OLED显示屏。iPhone SE 4将搭载A18处理器，配备4800万像素后置摄像头和1200万像素前置摄像头，性能配置向旗舰看齐。此外，iPhone SE 4将支持5G，配备USB-C接口，预计售价为499美元，出货量预计在2000万台左右。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_de34fc14f63b44f7a2244c542447ad1a@000000_oswg478765oswg730oswg840_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>诚意升级 低配新宠&nbsp;</strong></p>
  <p>最近，知名爆料者 @Jukanlosreve「泄露」了一份关于 iPhone SE 4 的 <strong>完整规格表</strong>，可信度相当之高。&nbsp;</p>
  <p>如果消息为真，我们将在明年春季与这款自 iPhone SE 系列问世以来 <strong>升级最为重大</strong>的机型见面。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_790a59d0e05b42f18d2322acb19af66d@000000_oswg164299oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">iPhone SE 4 系列机型爆料图（图源：Tom's guide）&nbsp;</p>
  <p>作为苹果数码设备中的「低端」产品线，iPhone SE 系列机型一经推出就以其紧凑小巧的体型和亲民的价格获得了广大消费者的青睐。&nbsp;</p>
  <p>然而，尽管第一代和第二代 SE 机型成为了用户的「香饽饽」，iPhone SE 3 的销量却不如预期。这也提醒苹果公司要在下一代产品中尽快调整： <strong>「低配」不等于落后，SE 同样也需要及时上新。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ba989d7fda334d64b5b947dcf3ac496e@000000_oswg242813oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">销量不佳的 iPhone SE 3（图源：Techradar）&nbsp;</p>
  <p>从目前的爆料信息来看，外观方面，iPhone SE 4 终于告别了 SE 系列一贯沿用的「经典款」iPhone 设计，转而采用类似 iPhone 14 标准版的整体设计，加入了「 <strong>全面屏</strong>」的大军。&nbsp;</p>
  <p><strong>不过，「刘海儿」还在，暂未「登岛」。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_484671e8a3ba48bd80955446ae71b662@000000_oswg255022oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">网传 iPhone SE 4 将采用「刘海儿」屏幕（图源：MacRumors）&nbsp;</p>
  <p>爆料称，iPhone SE 4 可能配备一块 6.06 英寸的 OLED 显示屏，分辨率为 2532*1170 像素，峰值亮度达 800 尼特。显然，相比上一代 SE 机型 4.7 英寸，1334*750 像素分辨率的 LCD 显示屏，有了比较明显的升级。&nbsp;</p>
  <p>值得一提的是，这将是 iPhone SE 系列机型 <strong>首次应用 OLED 面板</strong>。&nbsp;</p>
  <p>分析师 Ross Young 表示，iPhone SE 4 应该与 iPhone 14 共享相同的 OLED 面板，由京东方和 LG Display 提供。而韩媒 ET News 的最新消息称其将使用 <strong>与 iPhone 13 标准版相同的 6.1 英寸低温晶体硅（LTPS）OLED 显示屏</strong>。&nbsp;</p>
  <p>据业内人士称，大约有 25%～35% 的 iPhone SE 4 面板由 LG Display 提供。目前，该厂商已经量产了这款面板。&nbsp;</p>
  <p>同时，全面屏的使用还意味着「Home 键」和「Touch ID」的取消。预计 iPhone SE 4 将使用更为先进的 <strong>Face ID</strong> 技术，这也是之前的 SE 系列机型所没有的。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_86029b971d344d24b04b117060fb6a04@000000_oswg103633oswg1080oswg570_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">iPhone SE 4 的面板（图源：9TO5Mac）&nbsp;</p>
  <p>爆料称，iPhone SE 4 将搭载与 iPhone 16「同款」的 <strong>A18</strong> 处理器，并配备 8GB 的 RAM 和 128GB 的存储空间。如此「 <strong>向旗舰看齐</strong>」的诚意配置，很难不让人觉得这是为「 <strong>Apple Intelligence</strong>」而特意精心准备的。&nbsp;</p>
  <p>当然，彭博社 Mark Gurman 的报道也证实了这一点。这表明苹果希望将 Apple Intelligence 推广到尽可能多的设备上，包括其最便宜的新 iPhone。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_3806d25d49aa44028a430bec110550a9@000000_oswg357636oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Apple Intelligence（图源：9TO5Mac）&nbsp;</p>
  <p>这份最新的完整规格表显示，iPhone SE 4 将搭载一颗 4800 万像素的后置摄像头以及一颗 1200 万像素的前置摄像头。而 iPhone SE 3 的前、后摄像素分别为 700 万和 1200 万。&nbsp;</p>
  <p>而根据爆料者 Sonny Dickson 此前关于 iPhone SE 4 手机壳的分享，这款手机有可能采用和 iPhone 14 机型一致的后置双摄。即除了主摄以外，还有一颗超广角镜头。&nbsp;</p>
  <p>不过，同样根据 ET News 的最新消息，这份规格表关于摄像系统的消息似乎相当可信：LG Innotek 正在其位于越南的制造工厂量产 iPhone SE 4 的镜头模组， <strong>规格为 4800 万像素后置，1200 万像素前置。</strong></p>
  <p>此前，LG Innotek 为 iPhone SE 3 提供了后置摄像模块。除 LG Innotek 以外，消息称富士康和高伟电子（Cowell Electronics）也在 iPhone SE 4 镜头模组的供应链内。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0cb370614a3f451db18cfe6e6ceebcf5@000000_oswg125202oswg1080oswg816_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">网传的 iPhone SE 4 手机壳（图源：Tom's guide）&nbsp;</p>
  <p>预计 iPhone SE 4 还将搭载 <strong>苹果自家的首款 5G 调制解调器</strong>，代号「Centauri」。此前，苹果手机调制解调器的主要供应商为高通。&nbsp;</p>
  <p>另外，iPhone SE 4 还配备了 USB-C 接口，拥有 IP68 级别的防水防尘保护，支持 Wi-Fi 6 以及 20W 的有线充电和最高 15W 的 Qi2 和 MagSafe 无线充电。&nbsp;</p>
  <p>iPhone SE 4 的电池容量为 3279 mAh，上一代则为 2018 mAh。同时整机重量也由上一代的 144 克上升至 165 克。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_3f159d6fd1e74fa29edc3a0da5b302c1@000000_oswg111628oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">iPhone SE 4 将配备 USB-C 接口（图源：MacRumors）&nbsp;</p>
  <p>综合来看，iPhone SE 4 的性能配置诚意十足，说它是 SE 系列迈入新时代的「 <strong>开山之作</strong>」也不为过：它将 iPhone 的现代特征和性能带入了 SE 系列，让这条产品线焕发了新的生机。&nbsp;</p>
  <p>考虑到其 499 美元（约 3563 元）不算太贵的起售价，这款 iPhone 大概率会成为「 <strong>低配党</strong>」的新玩具，预计出货量在 2000 万台左右。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&amp;mid=2652383590&amp;idx=2&amp;sn=c9d0742c0eed0e2906bd100366205121&amp;chksm=9ab37746b8874071fbdf010216fc210964886be2e4b16e869c1ca21580fa80a9cc7ebee4655e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“爱范儿”（ID：ifanr）</a>，作者：<strong>范津瑞</strong>&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072773470778242</id>
            <title>73页，开源「后训练」全流程，AI2发布高质量Tülu 3系列模型，拉平闭源差距，比肩GPT-4o mini</title>
            <link>https://www.36kr.com/p/3072773470778242</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072773470778242</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 12:12:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源模型, 后训练, Tülu 3, 强化学习  
<br><br>  
总结: Allen Institute for AI（AI2）发布了Tülu 3系列模型，这是一套开源的先进语言模型，旨在推动开源模型的后训练技术发展。后训练是为了使模型能够有效遵循人类指令并减少输出有毒信息的风险。Tülu 3结合了多种训练算法和数据构造方法，提升了模型在知识召回、推理等核心技能上的表现。研究人员通过监督微调、偏好调整和可验证奖励强化学习等方法，优化了模型的训练过程。最终，Tülu 3在多个基准测试中超越了现有的闭源模型，缩小了开源与闭源模型之间的性能差距。 </div>
                        <hr>
                    
                    <p><strong>【导读】</strong>Allen Institute for AI（AI2）发布了Tülu 3系列模型，一套开源的最先进的语言模型，性能与GPT-4o-mini等闭源模型相媲美。Tülu 3包括数据、代码、训练配方和评估框架，旨在推动开源模型后训练技术的发展。</p>
  <p>只进行过「预训练」的模型是没办法直接使用的，存在输出有毒、危险信息的风险，也无法有效遵循人类指令，所以通常还需要进行后训练（post-train），如「指令微调」和「从人类反馈中学习」，以使模型为各种下游用例做好准备。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_e002070c87694b128bbd749c91d36090@46958_oswg128171oswg1080oswg483_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>早期的后训练工作主要遵循InstructGPT等模型的标准方案，如指令调整（instruction tuning）和偏好微调（preference finetuning），不过后训练仍然充满玄学，比如在提升模型编码能力的同时，可能还会削弱模型写诗或遵循指令的能力，如何获得正确的「数据组合」和「超参数」，使模型在获得新知识的同时，而不失去其通用能力，仍然很棘手。</p>
  <p>为了解决后训练难题，各大公司都提升了后训练方法的复杂性，包括多轮训练、人工数据加合成数据、多训练算法和目标等，以同时实现专业知识和通用功能，但这类方法大多闭源，而开源模型的性能又无法满足需求，在LMSYS的ChatBotArena上，前50名模型都没有发布其训练后数据。</p>
  <p>最近，Allen Institute for AI（AI2）发布了一系列完全开放、最先进的训练后模型Tülu 3，以及所有数据、数据混合、配方、代码、基础设施和评估框架，其突破了训练后研究的界限，缩小了开源模型和闭源模型微调配方之间的性能差距。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_13342ed3cbca420297ef6ad8ea6d53b1@46958_oswg180012oswg1080oswg430_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文链接：https://allenai.org/papers/tulu-3-report.pdf</p>
  <p>TÜLU 3-70B：https://hf.co/allenai/Llama-3.1-Tulu-3-70B</p>
  <p>TÜLU 3-8B：https://hf.co/allenai/Llama-3.1-Tulu-3-8B</p>
  <p>TÜLU 3 数据：https://hf.co/collections/allenai/tulu-3-datasets673b8df14442393f7213f372</p>
  <p>TÜLU 3 代码：https://github.com/allenai/open-instruct</p>
  <p>TÜLU 3 评估：https://github.com/allenai/olmes</p>
  <p>Demo：https://playground.allenai.org/</p>
  <p>模型训练算法包括有监督式微调（SFT）、直接偏好优化（DPO）以及可验证奖励强化学习（RLVR）</p>
  <p>TÜLU 3基于Llama 3.1的基础模型构建，其性能超越了Llama 3.1-instruct、Qwen 2.5、Mistral，甚至超越了如GPT-4o-mini和Claude 3.5-Haiku等模型。</p>
  <p>TÜLU 3的训练过程结合了强化学习的新算法、前沿的基础设施和严格的实验，构造数据，优化不同训练阶段的数据混合、方法和参数，主要包括四个阶段。</p>
  <h2><strong>第一阶段：数据构造</strong></h2>
  <p>研究人员主要关注模型在知识召回（knowledge recall）、推理、数学、编程、指令遵循、普通聊天和安全性等核心通用技能，然后根据目标需求来收集人工数据和合成数据。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_aef7b4be2a304548b90705490757bb08@46958_oswg323914oswg961oswg900_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>第二阶段：监督微调（SFT）</strong></h2>
  <p>研究人员在精心选择的提示和完成内容上执行监督式微调（SFT），首先确定了在使用Llama 3.1模型训练在TÜLU 2数据集上作为基准时，哪些技能落后于最先进的模型，然后有针对性地收集高质量的公开数据集和合成数据集。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_48c8b382c0174619a2e83b455b3d280f@46958_oswg99053oswg1022oswg572_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ccb88a72f37f430e8cda47f08cbda13d@46958_oswg140554oswg1021oswg311_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>通过一个完善的实验，确定了最终SFT数据和训练超参数，以增强目标核心技能，同时不会显著影响其他技能的性能。</p>
  <p>关键的数据实验包括：</p>
  <p>1. 多样化的聊天数据：主要来自WildChat，如果移除该数据集，可以看到大多数技能都有小幅但明显的下降，尤其是在Alpaca Eval上，凸显了「多样化真实世界数据」的重要性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_bc47d070fd7b483c8bfc5ea09f9345e9@46958_oswg153897oswg1021oswg311_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2. 安全性是独立的：移除特定安全数据集后，可以看到大多数技能的结果大致保持不变；添加对比提示，如CoCoNot，有助于防止模型过度拒绝安全提示。</p>
  <p>3. 新的Persona Data，主要针对数学、编程和指令遵循进行构建，移除后，HumanEval(+)、GSM8K、MATH和IFEval的性能都会显著下降。</p>
  <p>4. 针对特定技能（Targeting Specific Skills），移除所有数学相关数据后，GSM8K和MATH都有显著下降。</p>
  <p>5. 智能体训练数据的数量，可以发现，在不断增加数据集规模时，模型平均性能持续提高，增加到完整混合数据集后，GSM8K等指标上的性能大幅提升，但TruthfulQA的性能下降了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_31ad650a4f134a73bdb7c82ba3b6a6c7@46958_oswg49511oswg1027oswg385_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>第三阶段：偏好调整</strong></h2>
  <p>研究人员主要使用直接偏好优化（DPO），针对新构造的、基于策略的合成偏好数据，以及从选定提示中获得的离策略数据。与SFT阶段一样，我们通过彻底的实验确定了最佳的偏好数据混合，揭示了哪些数据格式、方法或超参数能带来改进。</p>
  <p>在TÜLU 3项目中，研究人员探索了多种偏好微调方法，目标是提升整个评估套件的性能；并研究了多种训练算法，从直接偏好优化（DPO）及其衍生算法到强化学习算法，比如近端策略优化（PPO）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_1dd5013f6bfc43b39a8ed9562ebdc608@46958_oswg125513oswg1032oswg350_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究人员通过改进和扩展UltraFeedback流程，从提示中创建了策略内偏好数据（包括输入、两个输出选项和标签），使用大型语言模型（LLM）作为裁判，构造「偏好的、被拒绝的」数据对，主要包括三个阶段：</p>
  <p>1. 提示选择</p>
  <p>除了数据构造阶段的提示外，还包括了其他来源的提示，比如没有TruthfulQA实例的Ultrafeedback版本，或者通过在提示中添加新的IF约束。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0e18072b064d41eaafb250de7f712d97@46958_oswg332186oswg1045oswg956_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2. 生成回复</p>
  <p>对于给定的提示，从模型池中随机抽取四个模型来生成回复，再通过从TÜLU SFT模型中抽样完成情况来包括策略内数据。其中一个回应是由策略内模型生成的，另一个回应是由策略外模型生成的。</p>
  <p>3. 偏好标注</p>
  <p>在为每个提示生成四个回复后，使用一个大型语言模型（LLM）作为裁判（GPT-4o-2024-0806），然后根据四个不同的方面（有帮助性、遵循指令、诚实性和真实性）对每个回复从1到5进行评分。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_83684a4bc286415b9a41226f1e2b7c7d@46958_oswg58866oswg465oswg306_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>第四阶段：可验证奖励的强化学习</strong></h2>
  <p>研究人员引入了一种名为可验证奖励强化学习（RLVR）的新型方法，用于训练语言模型完成具有可验证结果的任务，比如数学问题解决和指令遵循。</p>
  <p>RLVR基于现有的强化学习人类反馈（RLHF）目标，但将奖励模型替换为验证函数，当应用于具有可验证答案的领域，其在GSM8K等基准测试上显示出针对性的改进，同时还能保持其他任务的性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_3a9e98325baf468a84bb2aa3c9167cd4@46958_oswg110698oswg1025oswg434_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>RLVR可以看作是现有引导语言模型推理的方法的简化形式，或者是一种更简单的强化学习形式，其中使用答案匹配或约束验证作为二元信号来训练模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_f30cdd3634dc49289bedc1e9e5d16d7a@46958_oswg9110oswg611oswg51_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_5a69dfb1e9cd4adf9191891fee6266e2@46958_oswg6503oswg254oswg77_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>RLVR数据主要包括两个领域（数学、精确指令遵循），评估数据集为GSM8k, MATH和IFEval</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_91fd05e932a14104a5b3e09e4fd41888@46958_oswg72666oswg1021oswg217_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为了提升效率，RLVR的实现细节主要包括：</p>
  <p>1. 用通用奖励模型来初始化价值模型；</p>
  <p>2. 禁用dropout，在奖励模型和强化学习训练期间，将dropout概率设置为0，确保在策略模型和参考模型的前向传递过程中，token的对数概率可以确定性地计算，从而更准确地估计KL惩罚。此外，PPO在滚动阶段和学习阶段计算token的对数概率，重要的是要确保这两个阶段的token对数概率相匹配，如果使用dropout，对数概率差异会很大，导致裁剪后梯度为零。</p>
  <p>3. 使用智能体训练数据集并在周期之间随机，PPO可以训练的周期数超过可用提示的总数，有效地进行多个周期的训练。在我们的RLVR消融实验中，我们大约训练了13个周期。我们在周期之间对提示进行洗牌。对于我们的最终运行，我们每40-100步检查一次模型检查点，并选择在我们开发评估集上表现最佳的检查点。</p>
  <p>4. 非序列结束（EOS）惩罚：在训练期间，PPO通常采样固定数量的最大token。如果采样的回复没有以EOS token结束，给予-10的惩罚。</p>
  <p>5. 优势归一化：过减去均值然后除以其标准差来归一化优势（advantages）。</p>
  <p>研究人员首先将一个直接偏好优化（DPO）模型作为初始模型，然后进行了一系列消融实验：</p>
  <p>1. 单独任务。分别在GSM8K、MATH和IFEval任务上应用了RLVR方法，并遍历了一系列beta值。在评估时，关注可验证的奖励、KL散度和回应长度。</p>
  <p>2. 价值模型初始化消融实验。尝试从一个通用奖励模型和锚定的DPO模型初始化PPO的价值模型，并在GSM8K任务上遍历一系列beta值。通用奖励模型是使用UltraFeedback数据集训练的。在评估时，检查GSM8K测试评估得分和所有评估的平均得分。</p>
  <p>3. 从奖励模型得分的消融实验。在奖励模型的得分基础上增加可验证的奖励，并在GSM8K任务上使用了一系列beta值进行实验。</p>
  <p>4. 从性能较弱的模型开始。模型的基础能力也是一个干扰因素，使用平均得分较低的SFT模型进行另一组实验。</p>
  <h2><strong>TÜLU 3评估</strong></h2>
  <p>在后续训练方法中，建立清晰的性能目标和评估工具非常关键。</p>
  <p>研究人员发布了一个统一的标准化评估套件和一个工具包，以指导开发和评估最终模型，并对训练数据进行净化，以符合评估基准，主要目标包括：</p>
  <p>1. 评估过程应该是可复现的；</p>
  <p>2. 应该评估模型对未见任务的泛化能力，而不仅仅是我们用于开发的特定基准测试。</p>
  <p>3. 评估设置（例如，提示的模板和策略）对各种模型公平。</p>
  <p><strong>开放语言模型评估系统（OLMES）</strong></p>
  <p>为了使评估更加标准化和可复现，研究人员开源了Open Language Model Evaluation System，其支持更广泛的模型集合和任务、可以对每个任务进行灵活配置、直接访问任务描述、分析模型预测、置信度等的详细实例级的数据。</p>
  <p>比如说，要复现Llama-3.1-8B-Instruct在MMLU-Pro上的结果，只需简单运行类似「olmes –task mmlu_pro::tulu3 –model llama3.1-8b-instruct」的命令 。</p>
  <p>参考资料：&nbsp;</p>
  <p>https://venturebeat.com/ai/ai2-closes-the-gap-between-closed-source-and-open-source-post-training/&nbsp;</p>
  <p>https://allenai.org/blog/tulu-3?includeDrafts&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/hGjJ8EPHMYkiyHIlRh2ysg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：LRS&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072936409445254</id>
            <title>AI搜索和拆分危机之下，谷歌搜索将迎来大变</title>
            <link>https://www.36kr.com/p/3072936409445254</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072936409445254</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 12:12:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌搜索, AI搜索, 反垄断, 收费服务  
<br><br>  
总结: 谷歌搜索将在2025年进行“深刻变化”，主要是由于面临AI搜索的竞争和反垄断法律挑战。AI搜索如Perplexity AI等正在崛起，改变了传统搜索引擎的运作模式，提供更智能的用户体验。谷歌的搜索业务受到威胁，尤其是在用户点击广告的意愿下降的情况下。未来，谷歌可能会考虑为其AI搜索服务引入收费模式，以应对市场变化和用户需求。同时，AI生成内容的泛滥也对搜索结果的质量造成了影响，谷歌需要提升搜索结果的真实性以吸引用户。 </div>
                        <hr>
                    
                    <p>谷歌搜索将在2025年发生“深刻变化”，这是谷歌CEO桑达尔・皮查伊在当地时间周四举行的《纽约时报》DealBook峰会上说出的一番话。作为独霸全球搜索引擎市场二十年的存在，谷歌搜索为什么要在明年进行“深刻变化”呢？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0c76f3182e4c4c3eab665f6e0d0eab3a@000000_oswg16629oswg600oswg291_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为既得利益者、全球搜索引擎市场秩序的塑造者，谷歌搜索自然是不到万不得已不会变革，但恰恰在2024年，谷歌搜索的王座变得有些摇摇欲坠。谷歌在今年遇到了两大挑战，其一是在2024年伊始就拿到一笔7360万美元的投资、创下了十年以来搜索引擎公司融资纪录的AI搜索独角兽Perplexity AI，其二则是今年8月美国法院裁定谷歌的搜索业务违反了反垄断法。</p>
  <p>ChatGPT的走红不仅仅成为了国内“百模大战”的导火索，也让越来越多创业者开始思考如何用AI重塑现行的秩序。由AI驱动的搜索引擎Perplexity也是在2023年冒头，并于2024年借由英伟达、亚马逊的大笔投资一飞冲天。以Perplexity为代表的AI搜索从一开始就是瞄准颠覆谷歌的搜索帝国而来，它们与传统的搜索引擎基本上称得上是两个物种。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_f74d50b9f03a40cf8a2eae170939631d@000000_oswg16231oswg600oswg282_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>传统搜索引擎几乎是最成熟的互联网业务，从拉里佩奇和谢尔盖布林搞出谷歌搜索开始，搜索引擎的产品形态基本就没有发生什么变化，都是依靠爬虫从全网提取URL，然后将其保存在自己的数据库中、并建立索引。当用户通过搜索框发起请求后，就检索出最合适的内容提供给用户。</p>
  <p>在互联网的早期阶段，面对综合素质较高的网民群体，搜索引擎的这一运行模式堪称是天衣无缝。但随着越来越多的人成为网民，网民的平均学历水平也在一路下滑。这时候为了服务更多的用户，推荐算法应运而生，后者所营造的信息茧房已经让大量用户沉迷其中，进而使得搜索引擎这种在使用体验上还停留在几年前的的服务变得越来越不受待见。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_45ae1952038042e185fcf79450a64ae7@000000_oswg10278oswg600oswg282_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随着AI大模型、生成式人工智能的问世，让一些创业者看到了用AI改变搜索引擎的机会。现在的AI搜索几乎与传统搜索引擎不是一回事，无论海外市场的Perplexity，还是国内的知乎直答、腾讯ima都已经不是围绕“搜索框”向用户提供服务，它们实际上更类似ChatGPT这种聊天机器人的模式，是通过一轮轮的对话来为用户呈现出结果。</p>
  <p>不仅如此，AI搜索还提供了一个传统搜索引擎完全无法实现的能力，那就是代替用户思考。无论传统搜索引擎的关键词理解能力如何迭代，它实际上只是在猜测用户到底希望获得什么信息，并筛选出可能的结果，而用户则需要有思辨能力才能从一堆近似的结果中找到想要的东西。而AI搜索则做到了用AI来代替人类思考，并直接呈现出被提炼、整合的结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_250b6146c6b246278d806c045cf2a473@000000_oswg19190oswg600oswg285_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>别看只是少了一小步，但这确实是AI搜索的一大步。纽约大学斯特恩商学院的Melissa Schilling教授就指出，“谷歌在搜索领域似乎站不住脚，现在AI之于搜索就如同电子商务对于零售业的变革一样”。</p>
  <p>面对来势汹汹的AI搜索，谷歌方面在今年的I/O开发者大会上就带来自己的AI搜索功能AI Overviews，以作为防御性产品。然而AI Overviews的出现对于谷歌而言并非毫无代价，根据广告平台Skai公布的数据显示，谷歌在今年第三季度实现了强劲的收入增长，但用户点击广告的概率比去年下降了8%。Skai方面认为，这是由于谷歌在搜索结果中直接展示AI摘要，所以减少了用户点击广告的意愿。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_02033fcc89cd47c0b2e001931af0944e@000000_oswg27030oswg301oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果说AI搜索是谷歌三到五年后要面对的难题，那么输掉反垄断官司则显然是亟待解决的当务之急。从微软到Meta，再到其他在谷歌搜索压制下苦苦挣扎的中小搜索引擎，其实都在期待谷歌的搜索体系被拆分，如果失去了苹果Safari的默认搜索引擎地位，或者Chrome干脆被剥离，那么谷歌搜索当然就需要进行“深刻变化”。</p>
  <p>当然，我们三易生活认为，谷歌在2025年为搜索引擎带来的变化或许会是“收费”。没错，谷歌在过去一直是将搜索服务免费提供给用户，然后再通过搜索引擎广告来获得回报。然而在AI搜索即将遍地开花的时刻，为自家的AI搜索提供付费订阅服务显然很有合理性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_c02cef5fbab24081bdae27c03cd1c572@000000_oswg34448oswg600oswg268_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当下传统搜索引擎以及新兴的AI搜索其实都要面临一个无法回避的问题，那就是AI生成内容的泛滥开始在污染整个互联网，搜索结果的质量已经在明显下降。如果信息从源头就被污染，AI搜索如何提炼内容都不能避免带来不实信息。因此谷歌搜索要是能带来更真实的结果，或许真的会有一大批用户买单。</p>
  <p>【本文图片来自网络】&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649876705&amp;idx=3&amp;sn=271ed56757600eca040e2f7291fe98a0&amp;chksm=86a2a9cebd8965ef739f79399b57fde94c88a26335e9551143160c498e849fe3b04d6478a0a9&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072964233704320</id>
            <title>牵手华为还不够？比亚迪入股大疆旗下公司，目标：10万元以内车型也能有智驾</title>
            <link>https://www.36kr.com/p/3072964233704320</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072964233704320</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 11:56:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <卓驭科技, 比亚迪, 智能驾驶, 投资>
<br>
<br>
总结: 深圳市卓驭科技有限公司于12月5日发生工商变更，新增三家股东并增加注册资本。卓驭科技专注于纯视觉智能驾驶解决方案，已与多家车企建立合作关系。比亚迪通过全资子公司入股卓驭科技，表明其在智能驾驶领域的布局。比亚迪计划在未来的车型中提供高阶智驾选装和标配，目标是将智驾系统搭载在10万元以内的车型上。专家指出，当前在低价车型上搭载高阶智驾面临成本挑战，但比亚迪的规模效应可能使其成为可能。汽车产业的竞争将主要集中在自动驾驶技术上。 </div>
                        <hr>
                    
                    <p>12月10日，《每日经济新闻》记者查阅天眼查发现，深圳市卓驭科技有限公司（以下简称卓驭科技）于12月5日发生工商变更，新增深圳比亚迪创芯材料有限公司、嘉兴隽宇股权投资合伙企业（有限合伙）、苏州申祺利纳绿色股权投资合伙企业（有限合伙）三家为公司股东，分别持股3.9467%、1.8897%、1.184%。同时，卓驭科技的注册资本也由之前的约6798.86万元增至约7312.21万元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_708093c32d6f4219bced471d8f013265@46958_oswg38878oswg1080oswg338_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：天眼查</p>
  <p>公开消息显示，卓驭科技前身为大疆的车载事业部，是一家专注于纯视觉智能驾驶解决方案的高新技术企业。2023年，卓驭科技从大疆分拆独立，并于2024年6月正式启用“卓驭”作为业务品牌。截至目前，卓驭科技已与大众汽车、上汽通用五菱、奇瑞汽车、中国一汽等车企建立了合作关系。</p>
  <p>此次参投卓驭科技的深圳比亚迪创芯材料有限公司为比亚迪旗下全资子公司。天眼查显示，深圳比亚迪创芯材料有限公司成立于2007年，经营项目主要包括研发、生产、销售电池模具；货物及技术进出口（不含进口分销）等。</p>
  <p>在外界看来，比亚迪此次入股卓驭科技是其加码布局智驾领域的一大举措。事实上，早在今年1月举行的“2024比亚迪梦想日”发布会上，比亚迪董事长兼总裁王传福就曾向外界释放出比亚迪将开始重投入智能化赛道的信号。</p>
  <p>“比亚迪非常重视智能驾驶，并建立了一套全栈自研的智能驾驶研发体系。整个智驾团队共有4000名工程师，其中1000多人负责算法和硬件部分，3000多人负责软件部分。”彼时，王传福称，未来比亚迪20万元以上车型提供高阶智驾的选装，30万元以上车型将实现全面标配。</p>
  <p>而在11月1日举行的比亚迪海洋三周年暨首届用户盛典上，比亚迪海洋网销售事业部总经理张卓对外透露称，随着智驾技术不断成熟，海洋网的目标是希望在海鸥上搭载智驾系统，真正实现科技和智能平权。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_2372db830e8c4354907fb9c7d81f1791@46958_oswg76922oswg1080oswg756_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：每经记者 张建 摄（资料图）</p>
  <p>官方资料显示，海鸥是海洋网旗下首款A00级车，售价区间为7.38万~8.98万元。这也意味着，比亚迪的智驾系统将搭载在10万元以内的入门级车型上。</p>
  <p>值得一提的是，比亚迪全新入股的卓驭科技，早在今年11月就实现将高阶智驾搭载在了10万元级车型上。11月15日，全系标配灵眸智驾2.0 Max的宝骏悦也Plus 2025款上市，官方指导价为10.38万元。</p>
  <p>对于高阶智驾能搭载在宝骏品牌车型上的原因，上汽通用五菱党委副书记、副总经理韩德鸿曾解释称，主要得益于上汽通用五菱和卓驭科技两家企业旗下产品的规模化。</p>
  <p>新能源汽车和动力电池专家杨伟斌在接受记者采访时表示，在当前的供应链价格体系下，在10万元车型上搭载L2级自动驾驶还有挑战，需要整车和智驾部件价格进一步下降。</p>
  <p>一位不愿透露姓名的高校教授向记者表示：“目前，30万元以下车型搭载NOA，BOM成本必须控制在8000元以下，15万车型必须控制在5000元以下，而10万元车型必须控制在3000元。”该教授称，现在激光雷达和高算力AI芯片成本居高不下，具备高算力、激光雷达的NOA，BOM成本会到2.5万~3万元。</p>
  <p>不过，北方工业大学汽车产业创新研究中心主任、教授纪雪洪则表示，由于比亚迪旗下产品已形成规模效应，加上全栈自研，或可以让智驾系统搭载在10万元车型上成为可能。</p>
  <p>同济大学汽车学院教授朱西产告诉记者，汽车产业进入智能化下半场后，竞争将主要集中在自动驾驶技术上。</p>
  <p>事实上，除比亚迪外，长安汽车、赛力斯、长城汽车等车企也纷纷以投资、入股的方式加大了智驾领域的布局。今年8月，阿维塔和赛力斯相继宣布以交易额115亿元购买华为持有的引望（即深圳引望智能技术有限公司）10%股权。而长城汽车则于11月5日向自动驾驶科技公司元戎启行投资了1亿美元。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/e20-0IvEQzED1jRDuwSOkg" rel="noopener noreferrer nofollow" target="_blank">“NBD汽车”</a>，作者：李星，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072924515594884</id>
            <title>马云来了、CEO换了，蚂蚁需要更多信心和战斗力</title>
            <link>https://www.36kr.com/p/3072924515594884</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072924515594884</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 11:48:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 蚂蚁集团, 韩歆毅, 支付宝, AI战略  
<br><br>  
总结: 在蚂蚁集团成立20周年之际，马云强调未来的发展方向，并宣布韩歆毅将于2025年接任CEO。韩歆毅在过去9个月内对公司进行了重大组织调整，并推出了多款AI新产品。蚂蚁集团正面临商业增长的关键阶段，实施“AI First”、“支付宝双飞轮”和“加速全球化”三大战略，以应对竞争和增长瓶颈。支付宝推出的新支付方式“碰一下”被视为重塑用户支付习惯的关键，但也面临用户习惯培养的挑战。 </div>
                        <hr>
                    
                    <p>在蚂蚁集团成立20周年纪念日这一天，马云出现了。</p>
  <p>“今天，我不是为蚂蚁过去的20年而来，而是为了蚂蚁未来的20年而来。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_7aa1dd6e7fc14158b9306298ff621461@000000_oswg1198029oswg1080oswg737_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源蚂蚁集团官方微信公众号&nbsp;</p>
  <p>未来，谁来带蚂蚁集团奔跑？</p>
  <p>答案隐藏在一项重要的人事变动中。</p>
  <p><strong>12月8日，蚂蚁集团董事长兼CEO井贤栋通过全员信宣布，蚂蚁集团总裁韩歆毅将从2025年3月1日起正式接任蚂蚁集团CEO一职，全面负责蚂蚁的各项业务及日常管理工作，向井贤栋及董事会汇报。</strong></p>
  <p>未来，井贤栋将专注于董事长工作，并全力支持好韩歆毅和管理团队。</p>
  <p><strong>这一天距离韩歆毅上一次的晋升仅隔了9个月的时间。</strong></p>
  <p>在这9个月中，韩歆毅给蚂蚁集团带来了诸多变化，比如对蚂蚁集团进行了组织结构的重大调整；在2024Inclusion外滩大会发布了三款蚂蚁的AI新产品等等。</p>
  <p><strong>这些变化，与蚂蚁集团今年的策略息息相关。</strong></p>
  <p>今年以来，蚂蚁集团逐渐度过了漫长的调整期，开始步入商业增长的关键阶段。今年3月，蚂蚁进行了一次组织调整，并在年内进一步围绕“AI First”、“支付宝双飞轮”、“加速全球化”三大战略做了很多优化。</p>
  <p>其中最值得关注的是支付宝在今年7月推出的新支付方式——“碰一下”，作为“支付宝双飞轮”战略中的关键一环，支付宝必须耗费大量成本，尽快将该功能铺开，并重塑用户的支付习惯，抢占被微信支付“夺走”的市场份额。</p>
  <p><strong>在这个时间点，马云做的这三分钟演讲，也被视为重振员工信心的举动，蚂蚁的发展路径已经清晰，考验也随之而来，它面临着众多竞争对手，也面临着增长瓶颈。</strong></p>
  <p>但同时，它也面临着AI时代的巨大机遇，在重新奔跑后，管理团队依然要“过五关斩六将”。</p>
  <h2><strong>井贤栋，为何将CEO的重任交给韩歆毅？</strong></h2>
  <p>或许，13年前的韩歆毅也没想到，13年后，自己会成为蚂蚁集团的掌舵者。</p>
  <p>在韩歆毅的回复感言中，他提到，“不管何时，大家都可以继续叫我小韩，也可以叫我Cyril，我还是那个13年前面带微笑的年轻人。”</p>
  <p>2011年，阿里在6月宣布把淘宝分拆为三家公司：一淘网、淘宝网和淘宝商城，公司内部还在对未来究竟是属于B2C还是C2C争论不下。</p>
  <p>同时，公司还有40%的股份在雅虎手里。对于当时的阿里而言，拿回自己的股份、获得更多对公司的控制权是必须要做的事。</p>
  <p><strong>韩歆毅就是在这段时间加入阿里，那年，他34岁。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_4aa02ab917d346b1a41828f19c6447c5@000000_oswg34387oswg500oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">韩歆毅，图源蚂蚁集团官网</p>
  <p>任职的第二年，作为融资部资深总监的韩歆毅就接连参与完成了阿里的两项重大融资事件，一是初步回购雅虎所持40%股份中约半数的交易，二是完成了B2B业务在香港的私有化退市。</p>
  <p>加入阿里的第三年，阿里巴巴宣布将以支付宝为主体筹建小微金融服务集团，即蚂蚁集团的前身，韩歆毅也参与了该项目的筹建。</p>
  <p>随后的2014年，小微金服正式定名为“蚂蚁金融服务集团”，即蚂蚁金服，韩歆毅也在那一年加入了蚂蚁金服，担任投资部资深总监。</p>
  <p><strong>从那以后，正式成为“小蚂蚁”的韩歆毅，见证蚂蚁集团一路的披荆斩棘，也实现了自己的打怪升级。</strong></p>
  <p>2020年7月，蚂蚁金服更名为蚂蚁集团，宣布启动IPO。</p>
  <p>这项IPO引发了市场的投资热潮。根据彼时的报道显示，沪市共有超过515万户投资者参与了蚂蚁集团的打新，有效申购倍数为872.13倍，中签率仅为0.13%。</p>
  <p><strong>而在这场资本狂欢的3个月前，韩歆毅已经是蚂蚁集团的首席财务官。不过，这场IPO按下了暂停键，蚂蚁集团进入漫长的整改期。</strong></p>
  <p>时任董事长兼CEO的井贤栋带领蚂蚁集团一步步调整，如在金融管控方面，蚂蚁集团整体申设为金融控股公司，全面纳入监管；在支付业务方面，回归支付本源，坚持小额便民、服务小微定位等等。</p>
  <p>蚂蚁集团在2023年1月完成了股东上层结构的调整，马云不再是蚂蚁集团的实际控制人，独立董事席位也进一步增加，蚂蚁集团中的“阿里味”减弱，而同月，韩歆毅进入了董事会，担任执行董事一职。</p>
  <p><strong>随着整改逐步接近尾声，蚂蚁集团也在2024年进入了从稳步调整到快速奔跑的关键时期。</strong></p>
  <p>2024年3月，井贤栋宣布，蚂蚁集团进行一次组织调整，将蚂蚁国际、OceanBase、蚂蚁数字科技三大业务变成独立运营的子公司，并分别成立董事会，实行董事会领导下的CEO负责制。</p>
  <p><strong>同时，任命了一位集团新总裁，即韩歆毅。</strong></p>
  <p>由于此前，井贤栋也是从集团总裁升任为CEO，因此在当时，市场中就有不少猜测，韩歆毅就是井贤栋选出的CEO人选。</p>
  <p><strong>履新后的韩歆毅开始逐步展现出自己的“锐气”。</strong></p>
  <p>韩歆毅上任后，就对蚂蚁集团进行了组织结构的重大调整。即将数字政企事业部拆分为医疗、出行和民生三个独立业务部。</p>
  <p>另据晚点LatePost报道，韩歆毅在一些新的重点项目上舍得投入更多力量和资源，在一些已经持续多年的项目上也敢于做出改变。比如已推出8年的集五福活动，此前每年都只是一些微创新，但在2025年春节将会有一次大改版。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b0931bffd7aa458b8f9e154a4b887e3e@000000_oswg70179oswg1080oswg689_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源蚂蚁集团官网</p>
  <p><strong>追求“高效”是韩歆毅的特点，也是蚂蚁集团今年需要提升的地方。</strong></p>
  <p>韩歆毅也在其主要负责的业务——数字支付、数字互联和数字金融业务上大刀阔斧，带领支付宝在今年7月，推出高效支付方式“碰一下”，这种减少用户付款操作的方式，或将成为支付宝夺回市场份额的关键战略。</p>
  <p>无论是带着蚂蚁寻找新增长，还是在原有业务上进行变革，都是韩歆毅接下来的重要任务，今年47岁的韩歆毅，要解决的问题不少，面临的压力也不小。</p>
  <h2><strong>今年，蚂蚁集团急需战斗力</strong></h2>
  <p>根据阿里巴巴财报计算，2023年，蚂蚁集团净利润约为238亿元，相较2022年下降23.7%。</p>
  <p>这样净利润下滑的状态不能再持续，从今年开始，蚂蚁集团必须要提高更多业务的商业化收入，实现商业增长。</p>
  <p><strong>2023年，井贤栋这次组织升级，提出了蚂蚁“AI First”、“支付宝双飞轮”、“加速全球化”三大战略。</strong></p>
  <p>而这三大战略的重要性，也在今年3月的组织架构调整中，被进一步深化。</p>
  <p>今年3月，蚂蚁进行了过去四年以来最大的一次改组，除了上述提到的任命韩歆毅为新总裁外，就是将蚂蚁国际、OceanBase、蚂蚁数字科技三大业务变成独立运营的子公司，并分别成立董事会，实行董事会领导下的CEO负责制。</p>
  <p><strong>这三大战略代表的三个关键词：AI、支付、全球化，都是蚂蚁集团必须抓紧时间布局，抢占先机的领域。</strong></p>
  <p><strong>其中，作为一家从没脱离过“技术支持”的公司，AI一定是蚂蚁集团必须加速投入的。</strong></p>
  <p>此前，蚂蚁旗下的支付宝曾因缺少社交基因，导致在支付大战中略显被动。</p>
  <p><strong>而AI或许可以帮助蚂蚁提升与用户的链接。</strong>去年11月，蚂蚁推出了百灵语言大模型，今年，又在此基础上，推出了生活、医疗、金融三大应用——支小宝、AI健康管家、蚂小财。</p>
  <p>这些应用可以为用户提供更方便快捷的服务，比如支小宝能帮用户点咖啡、订机票；AI健康管家可以为用户找医生、读报告、陪看诊；蚂小财能解读实时金融热点，提供定制简报等等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_4d7a86f27ff2415db1728516af588c87@000000_oswg865251oswg1080oswg689_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源蚂蚁集团官网</p>
  <p>不过目前，蚂蚁推出的三款AI应用功能尚未完善，而且其定位与微信小程序、百度问诊等其他平台的功能有些相似，一些功能也有些脱离支付宝的使用场景，作为“后来者”的蚂蚁在吸引用户方面，还需要继续努把力。</p>
  <p><strong>围绕支付场景展开的战略“支付宝双飞轮”，是蚂蚁集团所有战略中的重中之重，双飞轮分别指的是数字支付和数字互联两大业务，这“两轮”能否“起飞”，也是支付宝能否实现商业增长的关键。</strong></p>
  <p>数字支付在今年最大的变革，就是支付宝在今年7月推出了“碰一下”项目。用户只需解锁手机后“碰一下”商家的支付设备就可以付款，最少只需一步。</p>
  <p>这项业务的原理就是通过引入NFC技术，实现快速支付，随着当前智能手机NFC支付功能的普及，一些用户在乘坐地铁、公交等交通工具使用手机刷NFC电子交通卡付费的现象也十分普遍，未来，用户对使用NFC支付的接受度或也将逐渐提高。</p>
  <p><strong>因此支付宝对“碰一下”的押注，相当于是要抓住支付领域新的突破口。</strong></p>
  <p>在另一轮——数字互联方面，目前，支付宝也已经在今年陆续实现了极大程度的开放，比如此前，支付宝已经放弃了阿里系优先的做法，向美团、京东开放合作。</p>
  <p>不过，支付宝的全面开放也建立在与其他平台的深度合作中，阿里旗下的饿了么、淘天等平台也接入了其他支付平台通道，因此，平台间的“交锋”还在继续。</p>
  <p><strong>第三大战略“加速全球化”，也是推动商业增长的重要一环，目前，大量的企业开始在海外打开局面，或许能刷新蚂蚁的天花板。</strong></p>
  <p>主要负责全球化布局的蚂蚁国际，目前主要拥有两款产品——“A+”和“B+”，前者Alipay+，即海外版支付宝，接入海外多种数字支付方式，服务海外商家和消费者。</p>
  <p>后者B+是以蚂蚁旗下的万里汇为核心，为中国跨境电商平台提供收、付、管、兑、贷的服务。</p>
  <p>不过，这两款产品在海外的存在感还有待提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_9a0b38152dfc4977a76f4d2d20667139@000000_oswg56341oswg1080oswg689_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源蚂蚁集团官网</p>
  <p><strong>除此之外，此前一度被搁置的蚂蚁集团上市计划，或也将在2025年被再次提上日程。</strong></p>
  <p>近期，市场传来蚂蚁集团重启上市的消息，若是能够重启上市，蚂蚁集团将进一步提升自身的竞争力，且拥有更多弹药，投入到AI建设和新支付革命浪潮之中。此前，井贤栋曾提到，“蚂蚁集团肯定会成为一家上市公司，我对此充满信心”</p>
  <p>而对于韩歆毅来说，需要更好地带领蚂蚁谋增长，为重启上市打好地基。</p>
  <h2><strong>“碰一下”，最大的机遇也是最大的挑战？</strong></h2>
  <p>毫无疑问的是，“碰一下”有望成为支付宝的杀手锏。</p>
  <p><strong>此前，微信支付已经逐渐打破了支付宝在支付领域的绝对领先地位，获得了越来越多的份额。</strong></p>
  <p>据艾瑞咨询数据显示，2014年，第三方移动支付交易规模市场份额中，支付宝以82.8%的份额居首，而财付通市场份额位居第二，仅为10.6%。</p>
  <p>但是2023年第二季度，支付宝的市场份额下降到54%，而微信支付的市场份额则增长到46%。</p>
  <p><strong>微信支付的优势在于，其所依靠的平台具备社交属性，也是大部分用户一天之内使用次数最多的APP，用户可能会因习惯，而在付款时点开微信扫码支付。</strong></p>
  <p>由此可见，培养用户的支付习惯也是支付平台抢占先机的关键因素。</p>
  <p>对于支付宝来说，跟在微信的背后学怎么做社交软件是“走弯路”的做法，如何能让用户看到自己的吸引力，才是支付宝最正确的决定。</p>
  <p><strong>而“碰一下”因其便捷、快速的支付方式，很可能将重塑用户的支付习惯。</strong></p>
  <p>“碰一下”一经推出，便在各大城市实现了快速覆盖。根据支付宝8月披露的数据显示，一个多月以来，其“支付+会员”数字化能力已向商超便利、快餐烘焙、茶饮甜品、商业综合体等全行业开放。</p>
  <p>截至彼时，全国已有20座城市陆续接入，仅接入的便利店品牌就超过了50个、覆盖数万家门店。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_7874bcf4690348b19c16020ba946020a@000000_oswg76846oswg850oswg851_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源蚂蚁集团官方微信公众号</p>
  <p><strong>但推广效率如此高的背后，需要支付宝“砸钱”。</strong></p>
  <p>支付宝对该项目的投入力度也很大，据晚点LatePost报道，支付宝配备了千人团队，还自掏腰包向商家铺设了百万台“碰一下”设备。</p>
  <p>从支付宝“碰一下”界面可以看到，针对用户，支付宝推出了笔笔有优惠、喊好友领最高100元的福利补贴，还设置了互动小游戏，玩游戏有机会集卡领红包。</p>
  <p>对于使用“碰一下”的线下商户以及推广“碰一下”的地推人员，都可以获得奖金。</p>
  <p><strong>尤其是地推人员，在招聘软件上也可以看到有不少公司发布的岗位名称中，写有“支付宝碰一碰推广”“支付宝NFC推广”字样。</strong></p>
  <p>随机点开一条信息查看，可以看到这些招聘岗位的主要工作内容为地推商家、组建团队、帮助商家免费入驻平台，奖励80-640元/每家，作业时长10-30分钟等等。</p>
  <p>就算按照每家80元的奖励计算，如果一位地推人员每天成功推广了10个商家，一天就可以获得800元的奖励，随着“碰一下”的使用频率逐渐普及，一些地推人员获得的推广奖励还可能会随着设备活跃度的提升而提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_eb4d4f54e5a241369d52d34ccf3f7851@000000_oswg118140oswg1080oswg1628_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源BOSS直聘APP截图</p>
  <p><strong>但支付宝是否能够借此完成对微信支付的反超，还是一个未知数。</strong></p>
  <p>有不少用户向连线Insight反馈，自己在使用“碰一下”时，觉得机器并不是很灵敏，用户的体验似乎没有支付宝想象中的那么容易形成习惯。</p>
  <p><strong>一个典型的现象是，许多用户对“碰一下”使用方法以及机器灵敏度的描述有分歧。</strong></p>
  <p>用户杨乐告诉连线Insight，自己只使用过一次“碰一下”功能，她需要点开支付宝，才能“碰”成功。</p>
  <p>但另一位用户胡莹口中的“碰一下”，并不需要在支付前打开支付宝，只是机器反应有点慢，而且她怀疑店家自己也不会用，也没有人教她如何使用，她到现在都不是很清楚，自己的手机每次是用哪种“姿势”支付成功的。</p>
  <p>用户林佳也表示，自己并没有使用“碰一下”的习惯，只有商家要求自己用才会用一下，“而且我觉得那个机器笨笨的，我半天刷不出的时间，还不如自己扫码。”</p>
  <p>但社交媒体中，有自称是“碰一下”用户的网友表示，因为“碰一下”机器过于灵敏，差一点二次付款。</p>
  <p><strong>除此之外，胡莹还向连线Insight透露了另一个使用不便的细节。</strong></p>
  <p>“‘碰一下’之后的界面不会显示你到底花了多少钱，所以，我还是要付完以后，点开支付宝看看我到底消费了多少钱，我也不知道到底每一单便宜了多少钱，总之付款以后它的界面没有显示。”</p>
  <p>胡莹认为，对自己而言，支付之后需要点开支付宝，与支付之前点开支付宝扫个码之间，没有太大的区别。</p>
  <p><strong>目前，“碰一下”在国内还处于培养用户习惯的阶段，很多用户确实刚刚接触，不太熟悉。</strong></p>
  <p>不过，未来NFC+条码支付相结合的支付方式确实将成为趋势。</p>
  <p>根据艾瑞咨询报告显示，到了2024年，外部环境因素已发生巨大变化，支持NFC的智能手机逐渐普及，条码支付软硬件服务设施已部署齐备，结合政策层面对提升支付便利性的要求，NFC技术在支付领域的应用迎来新一轮发展契机。</p>
  <p><strong>支付宝的“碰一下”还需要继续迭代，等待用户养成新的支付习惯。</strong></p>
  <p>值得注意的是，微信支付近期澄清了公司推出了“碰一下”业务的谣言。或许在新一轮支付革命中，支付宝能够抢占一定的先机。</p>
  <p>从目前蚂蚁集团对“碰一下”的投入和押注来看，有种势在必得的姿态，如果赌赢了，对蚂蚁集团来说，会真正进入发展快车道，也将具备更多的想象力。</p>
  <p>（本文头图来源于蚂蚁集团官网，文中杨乐、胡莹、林佳均为化名。）&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg2MTc4Nzg5MQ==&amp;mid=2247549328&amp;idx=1&amp;sn=2da360b03da253a38a2bb51628d59b63&amp;chksm=cf263667b680806ba5940ee40ce12afb40f2bf66b8668e0a669020eed1b18333418b7b9b86cc&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“连线insight”（ID：lxinsight）</a>，作者：窦文雪，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072748870136713</id>
            <title>“我把4500多篇NeurIPS 2024论文，做成了AI搜索”</title>
            <link>https://www.36kr.com/p/3072748870136713</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072748870136713</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 11:27:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: NeurIPS, AI搜索, 论文可视化, Exa团队  
<br><br>  
总结: 本文介绍了将4500多篇NeurIPS论文整理成AI搜索的过程，用户可以通过关键词搜索和可视化方式快速找到相关论文。使用的模型是Claude，支持精准和泛化的搜索，结果包括论文题目、摘要和作者信息。Exa团队负责该AI搜索的开发，致力于提供高质量的搜索结果而不展示广告。团队成员中有多位华人背景的联合创始人。 </div>
                        <hr>
                    
                    <p>把4500多篇NeurIPS论文整理成AI搜索。</p>
  <p>效果是酱婶的：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_cc72b32155b644518fb149c75c5af89d@46958_oswg145387oswg936oswg950_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>首先就看到，按照不同领域不同主题，将此次4500篇接收论文情况可视化了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_39c7074330dc42c4a1a45c3dfe124b91@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>你可以进行一些宽泛的关键词搜索，比如Transformer architectures inspired by neuroscience（受神经科学启发的Transformer架构）有哪些？Papers at the intersection of neuroscience and math（数学与神经科学交叉的论文有哪些？）</p>
  <p>结果就几秒钟之内，就会出现相应的论文结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_829defe47afa456d89e29958a65b23eb@46958_oswg316532oswg1080oswg900_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在众多结果之中，你可以选择其中一篇或者多篇论文进行集中讨论。</p>
  <p>使用的模型是Claude。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b6aadd75fbda4989a6921ab4c0110d1b@46958_oswg170823oswg1080oswg443_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>我们来进一步实测。</p>
  <h2><strong>4500多篇NeurIPS论文做成AI搜索</strong></h2>
  <p>从主页上可以看到，有两种论文搜索打开方式。</p>
  <p>一种是通用的搜索框，旁边可以选择此次poster Session（海报展示），主打一个精准搜搜。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a54435b685c646ad8e8c943bd59b1fcd@46958_oswg106911oswg1080oswg678_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>它能支持一些泛化的搜索，比如围绕某个主题、关键词啥的。</p>
  <p>新的优化方法、强化学习用来帮助机器人的技术等等，然后很快就能给出搜索结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_233f0d6c21c643b6a51b8cfe132c6750@46958_oswg52367oswg1080oswg213_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在结果中，它有显示论文题目、摘要、作者以及此次海报展示位置，可以说是很细致了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_84ac94389d7048b990f625cffebe3498@46958_oswg469076oswg1080oswg1041_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>进一步地，你可以选择一篇或者多篇论文进行进一步的“盘问”。</p>
  <p>实测可以选择10篇左右的论文，再多服务器就支撑不住了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_44419e9b0351461da8a1f402a9a94561@46958_oswg375361oswg1080oswg714_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一种就是前文的「可视化」，它有多种topic可以选择，你只需要在图中点个圆点，就能找到相关的论文。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_d78cf34589c2485f9036a52ec859fe3f@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>背后是一家AI搜索初创团队Exa，其CEOWill Bryk也是此次NeurIPSAI搜索的开发者表示，他只花了周末的时间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_5e9f88dd07984cb0a2d430d2b3c44981@46958_oswg42536oswg778oswg202_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>按照官方介绍，他们是一家位于旧金山的AI实验室，致力于打造专属内容的搜索引擎，比如法律行业。</p>
  <p>与传统搜索引擎不同的是，他们不展示广告，只关注高质量的结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_d681a03939674db1a15cffd5bdd5cca7@46958_oswg123157oswg1050oswg1126_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从初创团队介绍中，还能够看到不少华人的影子。</p>
  <p>比如联合创始人Jeff Wang，他在哈佛大学学习计算机科学和哲学，在宿舍里运行 GPU 集群，与CEO是室友</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_4c8b0afa42e3408c8984c00cec759bda@46958_oswg479965oswg660oswg1140_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>还有这位清华姚班的校友袁宾雨、同为哈佛校友的Ben Chen。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_14f4121f0a874eb1a75445cc352d705a@46958_oswg644968oswg1080oswg871_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>One More Thing</strong></h2>
  <p>NeurIPS 2024这几天也算是拉开帷幕了。</p>
  <p>已经有现场repo了，可以看出</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_6b38bddd3618447fb90d2d70b3d4e006@46958_oswg1121088oswg824oswg840_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>李飞飞透露，她将在当地时间11号下午两点半聊聊他们最新空间智能的进展。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_7825939f1d65492699c11c1575e1d483@46958_oswg527146oswg810oswg610_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>要去参会的小伙伴，快来跟我们透露下，有哪些有意思的行程安排呀？</p>
  <p>参考链接：[1]https://x.com/WilliamBryk/status/1865907214592123263[2]https://neurips.exa.ai/[3]https://x.com/drfeifei/status/1866210610649727321</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/z6XzpbkMAKfFvkDxzy5SWw" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：白小交，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072773535069059</id>
            <title>1600万视频解锁「空间智能」？智源3D生成模型See3D全套开源</title>
            <link>https://www.36kr.com/p/3072773535069059</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072773535069059</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 11:21:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 3D生成模型, 空间智能, 无标注视频, See3D  
<br><br>  
总结: 李飞飞团队推出的空间智能模型能够通过单张图片生成逼真的3D世界，标志着空间智能的进步。同时，智源研究院的See3D模型通过学习1600万个无标注视频，提出了“See Video, Get 3D”的理念，利用视频中的视觉线索生成3D图像。See3D模型不依赖昂贵的3D标注，支持多种3D创作应用，展现出广泛的适用性。该模型的训练数据来自海量互联网视频，具有良好的数据扩展性和几何一致性。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_c43ab9501f674f40893d8b8219e76dda@46958_oswg705830oswg1080oswg459_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>【导读】</strong>上周，李飞飞空间智能首个3D生成模型刚刚交卷。这边，国内来自智源的See3D模型，在学习了无标注的1600万个视频之后，重建出全新的3D世界，效果令人惊叹。</p>
  <p>近日，著名AI学者、斯坦福大学教授李飞飞团队World Labs推出首个「空间智能」模型，仅输入单张图片，即可生成一个逼真的3D世界，这被认为是迈向空间智能的第一步。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_80d2f67500cc4669a34b3c6014f507ab@46958_oswg731008oswg1080oswg1232_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>几乎同时，国内智源研究院推出了首个利用大规模无标注的互联网视频学习的3D生成模型See3D——See Video, Get 3D。&nbsp;</p>
  <p>不同于传统依赖相机参数（pose-condition）的3D生成模型，See3D采用全新的视觉条件（visual-condition）技术，仅依赖视频中的视觉线索，生成相机方向可控且几何一致的多视角图像。&nbsp;</p>
  <p>这一方法不依赖于昂贵的3D或相机标注，能够高效地从多样化、易获取的互联网视频中学习3D先验。&nbsp;</p>
  <p>See3D不仅支持零样本和开放世界的3D生成，还无需微调即可执行3D编辑、表面重建等任务，展现出在多种3D创作应用中的广泛适用性。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_75e8c5ab69a243a2a61610baa505fe8b@46958_oswg981336oswg1080oswg588_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>See3D支持从文本、单视图和稀疏视图到3D的生成，同时还可支持3D编辑与高斯渲染</p>
  <p>相关的模型、代码、Demo均已开源，更多技术细节请参考See3D论文。&nbsp;</p>
  <p>论 文地址:&nbsp;&nbsp;https://arxiv.org/abs/2412.06699&nbsp;</p>
  <p>项目地址：https://vision.baai.ac.cn/see3d&nbsp;</p>
  <h2><strong>效果展示</strong></h2>
  <p><strong>1. 解锁3D互动世界：</strong> 输入图片，生成沉浸式可交互3D场景，实时探索真实空间结构。&nbsp;</p>
  <p>实时3D交互（备注：为了实现实时交互式渲染，当前对3D模型和渲染过程进行了简化，离线渲染真实效果更佳）&nbsp;</p>
  <p><strong>2. 基于稀疏图片的3D重建：</strong> 输入稀疏的（3-6张）图片，模型可生成一个精细化的3D场景。&nbsp;</p>
  <p>基于6张视图的3D重建</p>
  <p>基于3张视图的3D重建</p>
  <p><strong>3. 开放世界3D生成：</strong> 根据文本提示，生成一副艺术化的图片，基于此图片，模型可生成一个虚拟化的3D场景。&nbsp;</p>
  <p>开放世界3D生成&nbsp;</p>
  <p><strong>4.&nbsp;基于单视图的3D生成：</strong> 输入一张真实场景图片，模型可生成一个逼真的3D场景。&nbsp;</p>
  <p>基于单张图片的3D生成</p>
  <h2><strong>研究动机</strong></h2>
  <p>3D数据具有完整的几何结构和相机信息，能够提供丰富的多视角信息，是训练3D模型最直接的选择。 然而，现有方法通常依赖人工设计（designed artists）、立体匹配（stereo matching）或运动恢复结构（Structure from Motion, SfM）等技术来收集这些数据。&nbsp;</p>
  <p>尽管经过多年发展，当前3D数据的积累规模依然有限，例如DLV3D（0.01M）、RealEstate10K（0.08M）、MVImgNet（0.22M）和Objaverse（0.8M）。这些数据的采集过程不仅耗时且成本高昂，还可能难以实施，导致其数据规模难以扩展，无法满足大规模应用的需求。&nbsp;</p>
  <p>与此不同，人类视觉系统无需依赖特定的3D表征，仅通过连续多视角的观察即可建立对3D世界的理解。 单帧图像难以实现这一点，而视频因其天然包含多视角关联性和相机运动信息，具备揭示3D结构的潜力。&nbsp;</p>
  <p>更重要的是，视频来源广泛且易于获取，具有高度的可扩展性。基于此，See3D提出「See Video, Get 3D」的理念，旨在通过视频中的多视图信息，让模型像人类一样，学习并推理物理世界的三维结构，而非直接建模其几何形态。&nbsp;</p>
  <h2><strong>方法介绍</strong></h2>
  <p>为了实现可扩展的3D生成，See3D提供了一套系统化的解决方案，具体包括：&nbsp;</p>
  <p><strong>1.&nbsp;数据集</strong></p>
  <p>团队提出了一个视频数据筛选流程，自动去除源视频中多视角不一致或观察视角不充分的视频，构建了一个高质量、多样化的大规模多视角图像数据集WebVi3D。该数据集涵盖来自1600万个视频片段的3.2亿帧图像，可通过自动化流程随互联网视频量的增长而不断扩充。</p>
  <p>WebVi3D数据集样本展示</p>
  <p><strong>2.&nbsp;模型</strong></p>
  <p>标注大规模视频数据的相机信息成本极高，且在缺乏显式3D几何或相机标注的情况下，从视频中学习通用3D先验是更具挑战的任务。&nbsp;</p>
  <p>为解决这一问题，See3D引入了一种新的视觉条件——通过向掩码视频数据添加时间依赖噪声，生成一种纯粹的2D归纳视觉信号。&nbsp;</p>
  <p>这一视觉信号支持可扩展的多视图扩散模型（MVD）训练，避免对相机条件的依赖，实现了「仅通过视觉获得3D」的目标，绕过了昂贵的3D标注。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_e5b7578a0ca84ec594ebcb98cf82dd47@46958_oswg428804oswg1080oswg479_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">See3D方法展示&nbsp;</p>
  <p><strong>3.&nbsp;3D生成框架</strong></p>
  <p>See3D学到的3D先验能够使一系列3D创作应用成为可能，包括基于单视图的3D生成、稀疏视图重建以及开放世界场景中的3D编辑等， 支持在物体级与场景级复杂相机轨迹下的长序列视图的生成。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_cdbffca9672b45a5a407be39d67e7b56@46958_oswg486401oswg1080oswg499_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">基于See3D的多视图生成&nbsp;</p>
  <h2><strong>优势</strong></h2>
  <p><strong>1.&nbsp;数据扩展性</strong></p>
  <p>模型的训练数据源自海量互联网视频，相较于传统3D数据集，构建的多视图数据集（16M）在规模上实现了数量级的提升。随着互联网的持续发展，该数据集可持续扩充，进一步增强模型能力的覆盖范围。&nbsp;</p>
  <p><strong>2.&nbsp;相机可控性</strong></p>
  <p>模型可支持在任意复杂的相机轨迹下的场景生成，既可以实现场景级别的漫游，也能聚焦于场景内特定的物体细节，提供灵活多样的视角操控能力。&nbsp;</p>
  <p><strong>3.&nbsp;几何一致性</strong></p>
  <p>模型可支持长序列新视角的生成，保持前后帧视图的几何一致性，并遵循真实三维几何的物理规则。即使视角轨迹发生变化，返回时场景依然保持高逼真和一致性。&nbsp;</p>
  <h2><strong>总结</strong></h2>
  <p>通过扩大数据集规模，See3D为突破3D生成的技术瓶颈提供了新的思路，所学习到的3D先验为一系列3D创作应用提供了支持。&nbsp;</p>
  <p>希望这项工作能够引发3D研究社区对大规模无相机标注数据的关注，避免高昂的3D数据采集成本，同时缩小与现有强大闭源3D解决方案之间的差距。&nbsp;</p>
  <p>参考资料：&nbsp;</p>
  <p>https://arxiv.org/abs/2412.06699&nbsp;</p>
  <p>https://vision.baai.ac.cn/see3d&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/orqZaaazIP8hrSg-In4Zhg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：编辑部 HYZ&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072891197551236</id>
            <title>中国芯片出口额，突破万亿</title>
            <link>https://www.36kr.com/p/3072891197551236</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072891197551236</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 11:07:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <中国, 集成电路, 进出口, 半导体产业>
<br>
<br>
总结: 今日，海关总署发布了2024年前11个月中国货物贸易进出口数据，显示中国货物贸易总值39.79万亿元，同比增长4.9%。其中，集成电路出口首次突破万亿元，反映出中国在全球半导体产业链中的重要地位。2024年，中国芯片出口金额预计接近950亿美元，进口集成电路金额约为3200亿美元。中国集成电路产业在过去十年中持续增长，尽管2022年和2023年有所下滑，但整体复合年增长率仍高于全球平均水平。随着国内市场需求扩大和技术进步，中国半导体设备和材料行业也迎来了快速发展机遇。 </div>
                        <hr>
                    
                    <p>今日，海关总署发布2024年前11个月中国货物贸易进出口数据。&nbsp;</p>
  <p>前11个月，中国货物贸易进出口总值39.79万亿元，同比增长4.9%。其中自动数据处理设备及其零部件、<strong>集成电路和汽车出口呈两位数增长</strong>。&nbsp;</p>
  <p>数据显示，今年前11个月，我国货物贸易出口23.04万亿元，增长6.7%；进口16.75万亿元，增长2.4%。&nbsp;</p>
  <p><strong>出口方面，</strong>出口机电产品13.7万亿元，增长8.4%，占我国出口总值的59.5%。其中，自动数据处理设备及其零部件1.33万亿元，增长11.4%；<strong>集成电路1.03万亿元，增长20.3%</strong>；手机8744.5亿元，下降0.9%；汽车7629.7亿元，增长16.9%。&nbsp;</p>
  <p><strong>进口方面，</strong>进口机电产品6.35万亿元，增长7.5%。其中，<strong>集成电路5014.7亿个，增加14.8%，价值2.48万亿元，增长11.9%；</strong>汽车63.7万辆，减少11.3%，价值2564.3亿元，下降14.9%。&nbsp;</p>
  <p>随着11月数据的尘埃落定，<strong>这是中国集成电路出口额首次突破万亿元大关，</strong>彰显了中国在全球半导体产业链中的重要地位与持续增强的国际竞争力。&nbsp;</p>
  <h2><strong>&nbsp;01中国集成电路近十年进出口情况</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ab2867812214474895d1e8c7d6e7c19b@000000_oswg201273oswg831oswg425_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从近十年中国集成电路出口数量来看，2021年及之前七年大抵呈现一路上升趋势，2022年与2023年微微下降。最近十年中国集成电路进口数量同样呈现类似的情况。&nbsp;</p>
  <p>这意味着2021年半导体行业进入鼎盛时期，这一年，主要受到缺芯潮、集成电路国产化以及新兴产业的推动等影响。而后期集成电路进出口量、金额双双下滑主要是受到全球经济形势变化的影响。&nbsp;</p>
  <p>出口金额的一路攀升反映出中国自主发展半导体已初见成效。进口额的不断增长，是中国大陆半导体市场需求持续扩大的直接体现。&nbsp;</p>
  <p>此前 DIGITIMES 数据显示，2024 年中国芯片进出口贸易金额受益于全球终端市场，如智能手机与个人电脑需求回暖，以及生成式人工智能基础设施建设与汽车产业的带动，芯片进出口金额分别同比增长 5.2% 与 11.4%。&nbsp;</p>
  <p><strong>进口金额方面</strong>，DIGITIMES 分析师简琮训指出，<strong>2024 年中国大陆进口集成电路金额估计约为 3200 亿美元。</strong>中国台湾具有下游晶圆制造、封装测试产业优势，韩国与马来西亚则分别为存储器与封装测试产业重点地区，是中国前三大进口集成电路来源地。自2019年以来，中国自美国进口集成电路金额比重逐年下滑。&nbsp;</p>
  <p><strong>出口金额方面，</strong>2024 年中国芯片出口金额接近 950 亿美元，为新冠疫情以来次高，反映出中国自主发展半导体已初见成效。出口地区方面，中国台湾、韩国、越南与马来西亚是中国大陆前四大芯片出口地。&nbsp;</p>
  <p><strong>就进口集成电路品类而言，</strong>中国进口集成电路又以处理器与控制器为主要，其次是存储器。&nbsp;</p>
  <p><strong>就出口集成电路品类而言，</strong>存储器也是中国集成电路出口的一大品类。中国企业能够根据不同客户的需求，生产出不同规格和性能的存储器产品，从而在国际市场上占据一定份额。特别是在一些新兴市场国家和地区，中国存储器产品的性价比高，受到了当地客户的欢迎。&nbsp;</p>
  <p>存储器进出口占比都较高的原因是，一方面，国内市场对高端存储器的需求旺盛，而自身生产能力在高端领域不足；另一方面，中国存储器企业在成本和中低端技术上有一定优势，能够在国际市场上找到竞争空间。&nbsp;</p>
  <p>2023年这两大主要品类的进出口额双双下降。其中处理器及控制器进口金额1763亿美元，占比50.3%，同比下降14.1%；存储器进口金额789亿美元，占比22.5%，同比下降22.1%。处理器与控制器出口额为500亿美元，同比下降4.5%；存储器出口额为558亿美元，同比下降20.6%。&nbsp;</p>
  <p>该年处理器及控制器贸易逆差1263亿美元，存储器贸易逆差231亿美元，可以看出，在处理器及控制器方面，中国集成电路对外依赖度相对较高。&nbsp;</p>
  <h2><strong>&nbsp;02中国芯片产量，步步攀升</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_3ac5dab46b304fdb8c364da09b83007f@000000_oswg208111oswg831oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>集成电路作为信息技术的核心，已成为竞争力的关键要素。面对这一趋势，国内正以前所未有的决心和力度，加大本土集成电路产业的发展步伐。&nbsp;</p>
  <p>上图所示，自2014年以来，中国集成电路产业市场规模一路攀升，集成电路产量也快速增加。之后在2020年与2021年前后迎来高速上涨，产量同比增长率达29.5%、33.3%。与进出口数量境遇相似，2022年中国集成电路产量也迎来微微下滑，随后在2023年再次恢复上涨趋势。不过总的来说，最近十年中国集成电路产量的复合年增长率依旧远超全球平均增长水平。&nbsp;</p>
  <p>集成电路出口能够提速增量，一方面得益于半导体行业的整体回暖。受终端需求影响，2023年全球集成电路行业经历下行周期，几乎所有细分市场都进入“去库存”阶段。2024年，随着全球经济的弱复苏，下游用户的库存也逐步去化，集成电路行业开始复苏。&nbsp;</p>
  <h2><strong>&nbsp;03芯片产能，持续增加</strong></h2>
  <p>今年中旬，国际半导体产业协会（SEMI）公布的全球晶圆厂预测报告（World Fab Forecast）显示，随着芯片需求不断上升，将带动全球半导体晶圆厂产能持续成长，预计2024年全球晶圆厂总产能将同比增长6%，2025年将同比增长7%，届时将达到每月3370万片8英寸晶圆约当量的历史新高。&nbsp;</p>
  <p>从工艺节点来看，预计 5nm 及以下尖端制程工艺节点的产能将会在 2024 年同比增长 13%，这主要是由于数据中心训练、推理和前沿设备的生成人工智能 (AI) 推动。为了提高处理能力效率，包括英特尔、三星和台积电在内的芯片制造商准备开始生产 2nm 全栅极 (GAA) 芯片，预计到 2025 年，5nm 及以下尖端制程工艺节点的的产能同比增长率将达到 17%。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_1ebd15173d1a4f369120d469485df359@000000_oswg136064oswg750oswg389_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从各地区产能扩张情况来看，预计<strong>中国芯片制造商将继续保持同比两位数百分比的产能增长，预计到2024 年的产能将同比增长15%，达到每月885万片8英寸晶圆约当量；2025 年将同比增长 14%，达到每月1010 万片8英寸晶圆约当量，占行业总量的近三分之一</strong>。&nbsp;</p>
  <p>中国大陆的产能扩张主要聚焦在成熟制程，TrendForce集邦咨询前不久指出，随着新产能释出，预估至2025年底，大陆晶圆代工厂成熟制程产能在前十大厂商的占比将突破25%，以28/22nm新增产能最多。而中国大陆晶圆代工公司的特殊制程技术发展以HV平台制程推进最快，预计在2024年将实现28nm的量产。&nbsp;</p>
  <p>从芯片需求数量来看，28nm及以上的成熟工艺，占据了全球四分之三左右的份额，而先进工艺只占四分之一。&nbsp;</p>
  <p>如今，中国大陆芯片产业扩产成效已逐步显现。2024年第一季度中国芯片总产量同比飙升40%，达到了981亿颗，几乎是2019年同期的三倍。未来几年，中国成熟制程芯片产能规模预计还将实现显著增长。&nbsp;</p>
  <h2><strong>&nbsp;04设备、材料同步受益</strong></h2>
  <p>伴随近年来中国大陆晶圆厂的扩建，上游设备、材料业也迎来快速发展。&nbsp;</p>
  <h3><strong>半导体设备，机遇空前</strong></h3>
  <p>在全球半导体设备市场中，美国、日本和欧洲长期以来占据着主导地位。然而，随着中国大陆晶圆制造产能的快速增长，以及技术的不断进步和国际形势的变化，国产半导体设备行业正迎来前所未有的发展机遇。&nbsp;</p>
  <p>根据SEMI发布的全球半导体设备市场统计报告，2024年第三季度全球半导体设备销售额同比大幅增长19%，达到303.8亿美元，环比增长13%。&nbsp;</p>
  <p>SEMI总裁兼首席执行官Ajit Manocha表示：“2024年第三季度，全球半导体设备市场实现强劲增长，这得益于旨在支持人工智能普及以及成熟技术生产的投资。设备投资的增长遍布多个地区，这些地区都希望加强其芯片制造生态系统。其中，北美地区的同比增幅最大，而<strong>中国继续在支出方面处于领先地位。</strong>”&nbsp;</p>
  <p>从整体来看，2024年全球半导体设备市场呈现出良好的发展态势。SEMI预计，2024年全球半导体设备市场规模将同比增长3.4%，达到1090亿美元，<strong>其中中国占比高达32%</strong>。这一增长不仅反映了全球半导体产业的蓬勃发展，也体现了中国在全球半导体市场中的重要地位。&nbsp;</p>
  <p>从最近几年半导体设备公司的营收表现来看，近四年，北方华创、中微公司、拓荆科技、盛美半导体、华海清科五家公司的年度营收一路上升，北方华创、盛美半导体2023年的营收达2021年的两倍之余，中微公司的2023年营收也较2021年翻番，拓荆科技、华海清科2023年的营收达2021年三倍多。&nbsp;</p>
  <p>与之对应的各公司年度净利润也一路上升。值得注意的是，北方华创在今年前三季度的归母净利润已超过2023年全年的归母净利润总额，华海清科、华峰测控在今年前三季度的归母净利润与2023年全年的归母净利润总额也不相上下。&nbsp;</p>
  <p>与此同时，也有多家公司在三季报中表示，在新签订单方面进展积极。&nbsp;</p>
  <p>前三季度，<strong>中微公司</strong>新增订单76.4亿元，同比增长约52.0%，其中刻蚀设备新增订单62.5亿元，同比增长约54.7%，LPCVD新增订单3.0亿元，新产品开始启动放量；2024年预计新增订单在110亿-130亿元。前三季度该公司共生产专用设备同比增长约310%，对应产值约94.19亿元，同比增长约287%，为后续出货及确认收入打下基础。&nbsp;</p>
  <p>部分公司的订单向业绩转化已经开始兑现，前三季度<strong>华海清科</strong>实现营业收入24.52亿元，较上年同期增长33.22%，实现扣非归母净利润6.15亿元，同比增长33.85%；其中三季度单季的营业收入为9.55亿元，同比增长57.63%，扣非归母净利润为2.46亿元，同比增长62.36%，创历史新高。该公司预计，随着满足更多材质工艺和更先进制程要求的CMP装备推出，以及未来国内新技术的应用，客户对CMP装备的采购和升级需求将快速增长。&nbsp;</p>
  <p><strong>盛美上海</strong>和<strong>北方华创</strong>的三季度收入创历史新高，营业收入分别为15.73亿元和80.18亿元，同比增长37.96%和30.12%，环比增长6.09%和23.81%。&nbsp;</p>
  <p>近年来，资本市场也为半导体设备类公司提供了大规模的资金支持，北方华创曾在2019年和2021年通过定增累计募集105亿元，2021年中微公司定增募集82亿元，近期，盛美上海拟通过定增募集45亿元，加快研发进度，加深产品布局，该公司将2024年全年的营业收入预测区间调整为56亿-58.8亿元，较此前53亿元的最低预测值有所上调。&nbsp;</p>
  <h3><strong>半导体材料，迎来契机</strong></h3>
  <p>全球半导体材料供应链中，日本、美国等国家长期占据主导地位。&nbsp;</p>
  <p>不过，近年来，随着国内半导体材料厂商不断提升半导体产品技术水平和研发能力，中国半导体材料国产化进程加速。&nbsp;</p>
  <p>根据中商产业研究院发布的《2024-2029年中国半导体材料专题研究及发展前景预测评估报告》显示，2022年中国大陆半导体材料市场规模约为939.75亿元，同比增长8.72%，2023年约为979亿元。中商产业研究院分析师预测，2024年该市场规模将达1011亿元。&nbsp;</p>
  <p>历经多年发展，中国半导体材料已经基本实现了重点材料领域的布局或量产，但产品整体仍然以中低端为主。部分高端产品如ArF光刻胶已经通过一些企业认证，但高端材料依然被海外厂商主导，并且在产能及市场规模方面与海外厂商也有较大差距。&nbsp;</p>
  <p>近年来，政策扶持与产业基金也为半导体材料企业注入了强大动力。国家大基金曾多次对半导体材料领域进行投资布局，助力企业扩大生产规模、提升研发能力。同时，地方政府也纷纷出台相关政策，鼓励半导体材料企业在当地落地生根，加速产业集群的形成与发展。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247781650&amp;idx=1&amp;sn=70d506aff8cc230cf3fdd1a6b016cd87&amp;chksm=c0ef798f95fe83ecac4dbf42e1a2895cb67fa351139afd5db28217280da1883aeb1d3bf2c682&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：丰宁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072862494225289</id>
            <title>马云一个月内两次现身，传递什么信号？</title>
            <link>https://www.36kr.com/p/3072862494225289</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072862494225289</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 11:06:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马云, 蚂蚁集团, AI时代, 企业变革  
<br><br>  
总结: 马云近期频繁露面，强调蚂蚁集团和阿里巴巴在面向未来的变革与发展。马云在蚂蚁集团成立20周年活动中提到，未来20年的AI时代将带来巨大的改变，技术虽重要，但真正的胜负在于企业的价值创造。蚂蚁集团正在加速AI战略布局，并进行组织变革。阿里巴巴也在电商业务上进行整合，以应对市场竞争。马云的发言和出现被视为为企业新一轮发展吹响号角。 </div>
                        <hr>
                    
                    <p>低调多年的马云最近出现得频繁了一些。</p>
  <p>12月8日，马云突然亮相蚂蚁园区，并在支付宝和蚂蚁集团二十周年活动现场致辞：“今天，我不是为蚂蚁过去的20年而来，而是为了蚂蚁未来的20年而来。”</p>
  <p>而在十多天前，马云的身影就出现在了在阿里西溪园区内。网传图片中，马云着一身休闲装，手拿咖啡与多位阿里员工合影。</p>
  <p>同样在阿里巴巴25周年的节点，马云虽未现身，但仍在公司内网发帖，称“阿里相信市场的力量和创新的价值”“立志要做一家能生存102年的公司”。</p>
  <p>事实上，作为阿里巴巴和蚂蚁两家集团的创始人之一，自2019年卸任阿里巴巴集团董事局主席之后，马云已经很少公开露面了。在这期间，阿里巴巴和蚂蚁集团几经沉浮，历经了多次重要的变革和发展。</p>
  <p>之后马云的现身和发言，似乎都与企业发展关键节点息息相关。</p>
  <p>特别是在2023年3月，阿里巴巴启动其历史上最大的一次变革，将公司分拆并重组成六大业务集团及多家业务公司，即“1+6+N”结构。同年5月下旬，马云召集淘天集团各业务负责人，开了一场小范围内的沟通会，一个月后阿里宣布张勇卸任董事会主席兼CEO职务，蔡崇信和吴泳铭接任。</p>
  <p>蚂蚁集团则在2020年被叫停上市后，进入3年整改期，并以接受罚款和关停违规业务告终。和阿里巴巴一样，蚂蚁集团也在去年梳理了内部战略，进行了一轮组织变革。</p>
  <p>如今，这两家企业都已重整了装束，再次上路。而马云的频频现身，或意在为着新一轮的冲刺吹响号角——面向未来，从新开始。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ce8736600eec49eeb3945424bb961039@000000_oswg70494oswg874oswg874_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△图源：蚂蚁集团官方微信号</p>
  <h2><strong>AI会改变一切</strong></h2>
  <p>马云出现的时间点，不仅是蚂蚁集团成立的20周年，也是蚂蚁集团更换CEO之际。</p>
  <p>12月8日，蚂蚁集团董事长兼CEO井贤栋通过全员信宣布，韩歆毅将从2025年3月1日起正式接任蚂蚁集团CEO一职，全面负责蚂蚁集团的各项业务及日常管理工作，向井贤栋及董事会汇报。</p>
  <p>韩歆毅于2014年5月加入蚂蚁集团，今年3月刚刚出任蚂蚁集团总裁。据了解，未来，井贤栋将专注于蚂蚁集团董事长工作，并全力支持好韩歆毅和管理团队。</p>
  <p>面对这样一个新旧交棒的时间节点，马云在此次演讲中多次提及了AI。</p>
  <p>“20年以前互联网刚刚来到的时候，我们这代人很幸运，我们抓住了互联网时代的机遇。从今天来看，未来20年的AI时代能带来的改变会超出所有人的想象，因为AI会是一个更加伟大的时代。”马云称。</p>
  <p>他表示，AI会改变一切，但这并不代表AI会决定一切。技术固然重要，但是未来真正决定胜负的还是今天，“我们为这个即将来到的时代做一些什么真正有价值，而又是与众不同的东西。”</p>
  <p>事实上，早在2023年，蚂蚁集团董事长兼CEO井贤栋就在全员信中首次公开新三大战略“AI Firs”“支付宝双飞轮”“加速全球化”。</p>
  <p>AI被放在了首位，蚂蚁AI战略全面提速。</p>
  <p>据了解，蚂蚁集团目前已经布局了包括大模型、知识图谱、运筹优化、图学习、可信AI等AI领域技术。近日，蚂蚁集团又收购了一家专注于大语言模型与强化学习结合的初创公司边塞科技。边塞科技创始人吴翼在社交媒体上回应称，自己已受邀加入蚂蚁集团，担任新成立的强化学习实验室首席科学家。不过，边塞科技仍将维持其独立运营状态，而原有的投资人则选择退出。</p>
  <p>此前，蚂蚁集团董事长兼CEO井贤栋在2024数字中国建设峰会上透露，下一个十年，蚂蚁将以更大力度投入科技创新，聚焦人工智能和数据要素技术，开启蚂蚁科技的全新未来。在2024世界人工智能大会上，井贤栋还透露蚂蚁发力专业智能体，加速产业应用的计划。</p>
  <p>马云已不是第一次表达出对AI技术的重视。今年4月，马云在阿里内网发表题为《致改革 致创新》的帖子时，就称“AI时代刚刚到来”。去年11月末，马云在阿里内网发言看好AI电商机会，表示“AI电商时代刚刚开始，对谁都是机会，也是挑战。”</p>
  <p>在阿里巴巴集团内部，CEO吴泳铭提出阿里云坚持“AI驱动、公共云优先”，今年以来阿里云多次宣布降价，并加快大模型开源的脚步。</p>
  <p>据阿里巴巴集团最新季度业绩，阿里云季度收入296.1亿元，同比增长7%，对比上一季度265.49亿元，环比增长11.5%。这是阿里云连续第四个季度实现增速上涨。该季度，阿里云经调整EBITA利润达到26.61亿元，同比增长89%，超越分析师预期的24.93亿元。</p>
  <h2><strong>面向着“未来”重新出发</strong></h2>
  <p>作为阿里的灵魂人物，马云的每次露面和发言持续吸引着外界的关注。在商业界的雷达上，他的每一次公开亮相，似乎总能引领阿里巴巴激起新波澜。</p>
  <p>11月，就在马云现身阿里新园区的一周前，阿里巴巴电商版图刚迎来“合并”大动作。</p>
  <p>11月21日，阿里巴巴集团宣布成立阿里巴巴电商事业群，全面整合淘宝天猫集团、阿里巴巴国际数字商业集团以及1688、闲鱼等电商业务。新事业群由蒋凡担任CEO，向吴泳铭汇报。按照2024财年营收来看，相关盘子体量至少高达5000亿。</p>
  <p>11月份阿里巴巴的调整也是一个面向未来的一个调整，当时阿里巴巴集团CEO吴泳铭就表示，“25岁的阿里巴巴仍要以创业的心态，不断创新”，也点出了“站在新的起点上”“把握住AI时代的机遇”等。</p>
  <p>不难想象，推动这一整合的底层逻辑也关乎马云多次强调的“未来”——中国及全球电商未来的竞争格局。</p>
  <p>20年前，阿里巴巴集团抓住了中国电子商务发展的机遇，迅速壮大。1999年，马云在杭州创立了阿里巴巴，这是其发展的起点。最初，阿里巴巴主要是一个B2B平台，后来发展成为一个涵盖多个领域的数字经济体。在其发展过程中，阿里巴巴推出了多个重要平台和业务，包括淘宝、支付宝、天猫、阿里云和菜鸟网络等。</p>
  <p>如今，从阿里集团最新一个季度的财报可以看到，淘天双11实现GMV强劲增长，买家数量创历史新高。但与此同时，国内电商已经进入存量时代，增量空间有限。而阿里的海外电商业务仍处于高增长阶段，需要获得更多国内优质供给的进一步支撑。</p>
  <p>2025财年第二季度财报显示，作为阿里巴巴“基本盘”的淘天集团，实现收入约990亿元，同比增长1%；第二大营收支柱国际数字商业集团创收316.72亿元，同比增长29%，是阿里集团内部收入增长最快的板块，但其经调整EBITA亏损29.05亿元，是去年同期亏损金额的7.5倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8f9785187d8d44fbb196c17b19f55131@000000_oswg226432oswg1080oswg589_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△图源：阿里巴巴集团2025财年第二季度财报</p>
  <p>此次蒋凡重回聚光灯下，背负着阿里电商板块的未来，一方面要让淘天集团恢复快速增长，另一方面让国际数字商业集团扭亏。</p>
  <p>三年前，蒋凡接手阿里国际数字商业后，迅速到海外调研并梳理业务，形成2个国内跨境业务（速卖通、国际站）+4个海外本土业务（Lazada、Miravia、Trendyol、Daraz）的格局，并推出全托管、半托管、自营模式。阿里海外业务定位逐渐变得清晰，并在之后从重要业务板块变为独立的国际数字商业集团。</p>
  <p>如今蒋凡再被委以重任，从外部环境来看，阿里在国内依旧面临着拼多多、京东等的挑战，国际市场上也有SHEIN、拼多多旗下的TEMU，以及风头正盛的TikTok Shop电商等对手。</p>
  <p>目前来看，新变革后的“第一把火”，是阿里巴巴拿下2025年春晚的独家电商合作项目。</p>
  <p>12月2日，中央广播电视总台总经理室与阿里巴巴签订总台2025乙巳蛇年《春节联欢晚会》独家电商互动平台合作项目。这是阿里第四次上春晚，此前三次分别为2018年和2020年以及2021年。</p>
  <p>再次回归春晚舞台，意味着阿里电商又将迎来一次全民性的品牌曝光。届时，阿里巴巴能否借助春晚这一超级IP重振旗鼓，又将放出怎样的大招夺回用户流量和市场份额，还将拭目以待。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjEyODE4MA==&amp;mid=2653321111&amp;idx=4&amp;sn=7171d6110fa5ecb895ab2451f51669cf&amp;chksm=bc5c40943a7195717e3e320483c9591a5fff80997c8a0c8f0096deaacf767cf3fa1d9ab05d5b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“时代周报”（ID：timeweekly）</a>，作者：庞宇 郭美婷，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072619022168712</id>
            <title>小米YU7深度解读，不是SU7变胖那么简单</title>
            <link>https://www.36kr.com/p/3072619022168712</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072619022168712</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 10:57:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米YU7, SUV, 设计, 售价  
<br><br>  
总结: 小米汽车正式公布首款SUV车型YU7，预计于明年六至七月上市。YU7的设计延续了小米SU7的家族命名规则，采用了空气动力学设计，外观上有轿跑风格。该车型的售价预计在24万左右，定位中大型SUV，可能与SU7同平台打造。YU7在动力上有所升级，配备前后双电机，系统总功率约690马力。内饰设计与SU7相似，但有新颖的远端贯穿屏设计。整体来看，YU7有望成为市场上的热门车型。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_2844129bf1b4499f829e43101a09ec88@000000_oswg84206oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <blockquote>
   <p><strong>拆解小米YU7的争议设计‍‍‍‍‍‍‍‍‍</strong></p>
  </blockquote>
  <p>万众期待小米SUV终于来了。&nbsp;</p>
  <p>昨晚，小米汽车正式公布 <strong>首款SUV车型YU7</strong>的海报图，并宣布该车型预计于 <strong>明年六至七月</strong>正式上市。随后，工信部第390批《道路机动车辆生产企业及产品公告》也出现了小米YU7的申报信息。&nbsp;</p>
  <p>消息一经发布，关于小米YU7的相关话题，迅速冲上热搜榜，从热度来看，堪称是今年最火爆的SUV之一。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_d89fb9457159446386cd694e1529a3fe@000000_oswg105906oswg1080oswg985_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>雷军也发文解释，全新SUV之所以提前公示，是希望YU7测试车可以尽早拆除重伪装，“有助于我们做更全面、更细致的长时间大规模测试。”&nbsp;</p>
  <p>关于这款车的信息，有太多待解之谜，比如售价几何？设计都有哪些出乎意料之点？和SU7相比又有哪些传承和创新？&nbsp;</p>
  <p>别急，我们慢慢分析。&nbsp;</p>
  <h2><strong>01 空气动力学设计加分</strong></h2>
  <p>首先需要明确的是，小米的首款SUV不叫MX11，也不叫SU8，而是叫 <strong>YU7</strong>。&nbsp;</p>
  <p>从命名上看，延续了小米SU7的家族式命名规则，但不是通过改数字，而是把轿车序列的“S”字母换成了SUV序列的字母“Y”，也就是说，此后小米SUV车型大概率都是 <strong>以YU开头的命名方式</strong>。&nbsp;</p>
  <p>这么来看，小米正在研发的代号为“昆仑”第三款车型增程式SUV，或许会叫“YU X”。&nbsp;</p>
  <p>因为初次正式亮相，大家最关注的肯定是外观。不难看出，YU7的整体设计风格为轿跑或跨界SUV，比如修长的机盖和较低的车身姿态，的确有点像大家猜测的法拉利Purosangue轿跑SUV的感觉。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_46a9979464c641c4b4342cbc931d03fe@000000_oswg79289oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从工信部公布的数据来看，YU7 车长为4999mm、车宽 1996mm、车高仅有 1600mm，轴距是和小米SU7相同的3米。&nbsp;</p>
  <p>乍一看，小米YU7就像是小米SU7的 <strong>纵向拉长版</strong>，前脸和尾部设计都保持了 <strong>等比例拉高</strong>的风格，前后造型也和SU7相似，特别是还有着与SU7同款的前后灯组及獠牙状进气口。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_05bf4b6668154dfcaa8766040e7825d8@000000_oswg64889oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过，如果只是单纯将其看做“胖版SU7”，就大错特错了，在YU7的外观设计上，小米汽车其实花了不少的心思。&nbsp;</p>
  <p>先来看大灯的细节，YU7虽然依然采用水滴大灯的造型，但是从“米”字的车灯变成了“米”字的下半部分，有些类似于 <strong>“十”字型的造型</strong>，而且在大灯较尖锐的一端是 <strong>内凹进去</strong>的。&nbsp;</p>
  <p>在“十”字型车灯的上方，还是 <strong>镂空的设计</strong>，变成了类似进气道的造型。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_956d99a553b94446bd4e41b3694f9473@000000_oswg53077oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在大灯组后面，前机盖靠近A柱的地方，还出现了一个开孔的设计，这就比较有意思了， <strong>这个开孔大概率是和大灯上半部分的镂空设计是连通的</strong>。&nbsp;</p>
  <p>这个设计，学名叫做空气桥 <strong>（Aerobridge）</strong>，是空气动力学的一种，可以通俗的将其理解为，两者相连后会形成一个巨大的风道，一般常见于超跑的设计上，这一定程度上可以减少车正面的撞风面积，从而减少风阻，节省能耗，还可以增加车的下压力。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_038b40abdd81487693477d9b1f9f9d7e@000000_oswg761236oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种设计能出现在家用SUV上相当厉害，不难看出，小米YU7是一款运动取向的车型。&nbsp;</p>
  <p>另外，YU7亮相后引发了不少争议的一点，就是此前被小米SU7当做卖点的半隐藏式门把手，在小米YU7上消失了，取而代之的是 <strong>全隐藏式门把手</strong>。&nbsp;</p>
  <p>这也引起了不少网友吐槽—— <strong>为什么不沿用SU7的半隐藏式设计？</strong></p>
  <p>不过有网友扒出了一张小米汽车在2023年6月专门为隐藏式门把手申请的专利图。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b1dd2cd5af1947c791fa80895d4838aa@000000_oswg99071oswg1080oswg849_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从专利图看，它的整个结构实际上是一个独立的机械式结构，并不是“弹出式”的，而是 <strong>“内翻式”</strong>，小米用了一个巧妙的变通设计。当我们伸手开车门，手触碰到门把手的时候，会带动内部的机械结构发生转动，进而触发门锁装置，车门解锁，然后复位。&nbsp;</p>
  <p>也就是说，看似是“隐藏式”门把手，但实际上完全不一样，可以理解为半隐藏式门把手的升级版，目的是让外观造型看起来更好看，值得一提的是， <strong>法拉利FUV的门把手也是类似的设计。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_99c3c038dde24bcb8ec45c287c93e9ad@000000_oswg5412oswg64oswg64_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此之外，让大家乍一看有种法拉利Purosangue既视感的，还有一个原因是，小米YU7在 <strong>B柱后面的处理</strong>，比如夸张的后轮拱向外隆起的处理，还有四个轮拱上不规则的设计，也和法拉第Purosangue的设计类似。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a058fc1ad5d245d7ab2f68a25b752510@000000_oswg298086oswg616oswg347_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这样的设计语言，与其说是借鉴，不如说是拿捏住了设计核心的神韵。&nbsp;</p>
  <p>最后是尾部的设计语言，也和小米SU7的设计有不小差异，首先是SU7上的土星环式的尾灯在YU7上变得 <strong>更宽更高</strong>，而且更有立体感。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_af5cd355fe6948438b3bc036010ae81c@000000_oswg105754oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>后风挡的上方也出现了一个扰流板，在车尾还有个 <strong>小鸭尾</strong>的设计，以增加下压力，后杠位置的扩散也变得更夸张，整体看上去，运动感十足，辨识度仍然拉满。&nbsp;</p>
  <h2><strong>02 售价或在24万左右？</strong></h2>
  <p>其它的信息，就要从工信部发布会的申报内容上找蛛丝马迹了。&nbsp;</p>
  <p>从车身定位来看，小米YU7属于中大型SUV， <strong>车长与轴距上几乎与SU7保持不变</strong>，但是宽度和高度有所增加。&nbsp;</p>
  <p>也就是说，小米YU7大概率是和小米SU7同平台打造，会有不少的零部件通用，反映到价格上或许会有惊喜。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_9e1fbfc6332e4f11a95d15d7bcbf989a@000000_oswg120888oswg1080oswg868_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在选装部分上，目前已知的就是提供了3种规格的轮圈可选，分别为19寸、20寸和21寸可选，轮毂样式有两种，并且可以看到有搭配Brembo的黄色卡钳。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_38f98e414128417387536b1e22373902@000000_oswg702044oswg1080oswg883_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在轮胎规格上，YU7将提供245/55 R19、245/50 R20、以及前245/45 R21+后275/40 R21这三套组合，而275的胎宽要比小米SU7的更宽一些。&nbsp;</p>
  <p>在动力上，申报车型是前后双电机的组合，电机型号为YS210XY103/TZ220XY109，制造企业为苏州汇川联合动力系统股份有限公司， <strong>前220kW+后288kW</strong>，极速能达到253km/h。&nbsp;</p>
  <p>换算下来，系统总功率约合 <strong>690马力</strong>，而小米SU7 Man上的最大功率495千瓦，约合673匹马力，不难看出在动力上也有一些升级。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_92a24ae8c54a4b10bf79afd0ac603928@000000_oswg105754oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过考虑到小米YU7申报的整备质量为2405kg，要比小米SU7沉的多，也就是说，虽然在动力上由于小米SU7，但性能表现可能与SU7 Max版持平。&nbsp;</p>
  <p>电池制造商方面，可以看到申报车型为 <strong>三元锂离子电池</strong>，单体生产企业为江苏时代新能源科技有限公司，总成生产企业为中州时代新能源科技有限公司，这两家公司都是宁德时代的下属公司。&nbsp;</p>
  <p>根据此前的消息，小米将在2025年首发宁德时代一款超长续航新电池，大概率就在YU7上车了。&nbsp;</p>
  <p>虽然工信部和小米汽车没有公布内饰，但目前有关小米YU7的内饰爆料已经满天飞，已经可以勾勒出内饰的大致模样。&nbsp;</p>
  <p>基本上，小米YU7的内饰延续了现款SU7的设计理念，如三幅式方向盘、换挡拨杆和方形中控屏（悬浮屏）等，与小米SU7样式一致。&nbsp;</p>
  <p>但不久前，还有一张谍照拍到了小米YU7的一个不同寻常的地方，就是 <strong>远端贯穿屏</strong>，从谍照上看，屏幕造型细长，显示效果类似于阿维塔 12 的远端显示屏，但小米的要更窄一些。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_7c164d5b74c843d5832c809576974d0e@000000_oswg485212oswg640oswg718_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有意思是，去年4月，小米汽车就申请了一个显示屏的专利，将显示装置部分夹设于控制台和前挡风透光件之间，能够方便驾驶员查看车辆信息，有利于提高驾驶安全性，基于曝光的谍照来看，专利似乎要上车了。&nbsp;</p>
  <p>而小米YU7的中控下方的扶手区域，和小米SU7或许有很大不同，换成了手机无线充电面板和水杯架，其他部分则配备一个较大的储物箱。&nbsp;</p>
  <p>最后就是关注的价格了，目前行业主流的说法是YU7定价会在30-40万之间，不过从小米YU7的定位来看，明显是 <strong>对标Model Y</strong>。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_49cc5d5af3d4440ba4059329d46bb18d@000000_oswg58478oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但按照小米首款车型的打法，大概率要比Model Y便宜，但作为一款SUV，小米YU7又会比轿车SU7贵一些，没有优惠的情况下，目前Model Y的起售价是25万元。&nbsp;</p>
  <p>这么来看，小米YU7大概的价格区间，起售价大概率或在 <strong>24万左右</strong>，这个价格和同区间的竞品相比，也有进可攻退可守的优势。&nbsp;</p>
  <p>不过价格不到最后一刻，谁都不能确定，毕竟这款车距离上市还有 <strong>半年</strong>的时间，小米汽车有的是时间调整。眼下对标特斯拉Mode Y的纯电SUV基本都已经出牌了，按照SU7的订单曲线，小米YU7作为压轴选手，大概率也会是个爆款。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTc3NjgxNQ==&amp;mid=2247539377&amp;idx=1&amp;sn=7ca4098bb6081164f3f9e1c8d0899ebb&amp;chksm=ce8b486af60196800af7936b200a6692c40a1a2b6ecaeedc9898d08782ceab363b1f28e557a6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“超电实验室”（ID：SuperEV-Lab）</a>，作者：王磊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072676227281793</id>
            <title>“果味十足”的OPPO，如何走出危险区？</title>
            <link>https://www.36kr.com/p/3072676227281793</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072676227281793</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 10:51:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OPPO, 高端市场, AI技术, 市场份额  
<br><br>  
总结: OPPO正在寻求新的营销策略，试图吸引苹果用户并在高端市场与苹果竞争。尽管推出了Find X8系列和Reno13系列，OPPO在市场份额上却面临下滑，未能进入前五名。2024年被视为AI手机元年，OPPO计划通过AI技术重塑手机体验，但目前的AI成果未能显著提升市场竞争力。全球高端手机市场几乎被苹果和三星垄断，OPPO的市场份额仍然微薄，面临严峻挑战。 </div>
                        <hr>
                    
                    <p>焦虑的OPPO，正在寻找营销新途径。</p>
  <p>“说得直白一点，我们就是想转化苹果用户，让他们有另外一种选择。”10月下旬，在距离深圳总部千里之外的四川成都，OPPO首席产品官刘作虎对媒体直言不讳地说。当晚，OPPO发布了无论是外型、功能、配件到定位均“果味十足”的旗舰高端新品Find X8系列。</p>
  <p>除了在高端市场上想“截胡”苹果用户，OPPO在中端市场也不想错过。在上述发布会仅仅一个月后，OPPO迅速推出中端机型Reno13系列，毫无悬念地延续了其浓郁的“苹果风格”，市场一度称其为“补齐iPhone所有短板的安卓‘平替’。”</p>
  <p>从某种程度上讲，“摸着苹果过河”的OPPO，无论是Find X8还是Reno13都必须大卖。前不久，全球科技市场研究机构TechInsights披露的2024年Q3中国手机智能市场报告显示，当季，vivo以19%的市场份额继续领跑，OPPO/一加和小米并列排名第二，各自份额均为15.5%，荣耀、华为和苹果则分别以15.2%、15.1%和15.1%的份额紧随其后。</p>
  <p>TechInsights在报告中明确指出，虽然OPPO（14%）和一加（2%）合计出货1020万部，与小米并列第二。但该厂商连续第五个季度延续下滑趋势，同比下降6%，“该品牌在中国高度竞争的线上市场缺乏重大突破，让人对其在国内市场的复兴计划产生怀疑。”</p>
  <p>相比之下，对于OPPO的“失势”描述，国际数据公司（IDC）传递出的危险信号更为明显。IDC报告显示，2024年第三季度，中国智能手机市场出货量约6878万台，vivo以近19%的出货量份额位居榜首，苹果以15.6%的市场份额排名第二，华为、小米、荣耀位列前五，而OPPO（含一加）则跌出前五行列，沦为“others”（其他）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0ed58eb66fc7421880fdcc2cfb73c124@000000_oswg57913oswg725oswg472_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>01押注AI，仍难增长</strong></h2>
  <p>2024年，是OPPO成立20周年。</p>
  <p>对于OPPO而言，过去的20年历程可谓跌宕起伏，曾一度以高达16.8%的市场份额，傲然成为中国手机市场的销冠；然而亦曾经历“造芯”之路的骤然中断，致使数百亿投资化为乌有。</p>
  <p>2024年年初，OPPO创始人兼首席执行官陈明永通过一封内部信，正式宣告了OPPO的战略调整。在信中，陈明永深刻指出，2024年是AI手机元年，AI手机时代将成为继功能机、智能手机之后，手机行业的第三阶段。</p>
  <p>AI可以把手机的体验重做一遍，这轮由大模型支撑的AI技术，正在重构手机行业的未来。OPPO已成立AI中心，加速资源向AI的集中。</p>
  <p>在这封内部信发布的3天之后，OPPO举办AI战略发布会，宣布了包含OPPO AI超级智能体和AI Pro智能体开发平台在内的“1+N”智能体生态战略。</p>
  <p>身为段永平的主要弟子，上世纪60年代末出生的陈明永与恩师有着诸多相似之处，他们同样低调而神秘，鲜少在镁光灯下曝光。</p>
  <p>陈明永上一次公开亮相还是2021年12月，彼时，其罕见现身OPPO未来科技大会，隆重向外界介绍了OPPO的首款自研影像专用NPU芯片——马里亚纳MariSilicon X。</p>
  <p>陈明永表示，科技公司必须通过关键技术解决关键问题，如果没有底层核心技术，就不可能有未来，而没有底层核心技术的旗舰产品，更是空中楼阁。</p>
  <p>马里亚纳MariSilicon X标志着OPPO真正进入研发“深水区”。不过，OPPO的芯片自研之路颇为波折，2023年5月，OPPO突然宣布终止自研芯片项目，并关停OPPO造芯主体哲库科技（上海）有限公司。</p>
  <p>因此，陈明永在年初为OPPO定调——致力于成为AI手机的引领者与普及者，并不令人感到意外。</p>
  <p>自ChatGPT等生成式AI应用横空出世，无论是作为初步尝试还是全面进军市场，荣耀、小米等手机厂商自2023年起纷纷涌入AI领域，竞相发布各自的AI战略，试图通过技术创新来抢占市场先机。</p>
  <p>然而，AI技术的研发与推广无疑是一项耗资巨大的工程。无论是硬件的迭代升级，还是软件的创新开发，乃至市场营销策略的制定与用户认知的培养，每一个环节都离不开庞大的资金支持。</p>
  <p>在今年年初的一个公开场合，刘作虎曾直言不讳地表示，OPPO在AI上的投入没有上限。</p>
  <p>如此“豪赌”AI，OPPO当前的AI成果尚未能达到市场所期盼的颠覆性高度。目前，在其对外展示的AI系统中，核心内容仍然局限于AI识图、AI一键问屏、AI修图等这些相对传统的应用领域，相较于竞争对手，既没有展现出明显的先发优势，也缺乏足够的差异化特点。</p>
  <p>在产品日益同质化的当下，这样的策略在寻求市场增量方面，效果有限。</p>
  <p>一组不可忽视的数据是，目前OPPO在中国的市场地位正在松动。根据IDC与Canalys两家机构的统计数据，2024年第三季度国内手机厂商市场份额排名呈现出一定的差异。</p>
  <p>IDC的排名中，vivo位居榜首，紧随其后的是苹果，华为、小米、荣耀分列三至五位。而Canalys的排名则是vivo领先，华为、荣耀、小米、苹果依次排列。</p>
  <p>尽管两家机构的具体排名有所出入，但一个共同点是，在市场份额前五的厂商行列中，均未出现OPPO的身影。</p>
  <h2><strong>02冲击高端，难抵强敌</strong></h2>
  <p>想要扭转不利局面，OPPO急需讲好“新故事”。</p>
  <p>10月24日，在四川成都举办的年度影像旗舰——OPPO FindX8系列发布会现场，即将进入知天命之年的刘作虎用一个多小时的时间，详细介绍了新品，并将AI操作系统、屏幕、机身及影像等核心参数与苹果最新款iPhone 16系列进行了全面对标。如在机身厚度方面，相比于iPhone 16 pro，Find X8的机身厚度仅为7.85mm，前者则是8.25mm。</p>
  <p>为了与苹果展开正面较量，OPPO精准定位苹果的生态体系与跨设备协作优势，Find X8已支持通过“一碰互传”功能，轻松实现OPPO与苹果设备间的文件与图片互传，打破了安卓与iOS之间的生态隔阂，实现了两大操作系统间的文件无缝传输。</p>
  <p>不仅如此，OPPO还引入了live图片格式，这一功能此前仅在苹果的摄影工具中独占鳌头。</p>
  <p>“不是苹果买不起，而是OPPO更有性价比。”OPPO软件产品经理朱海舟说。根据官方公布的信息，OPPO FindX8系列基础款起售价4199元，Pro版本定价起售价为5299元。</p>
  <p>反观苹果方面，iPhone 16与16 Plus的国行版起售价分别高达5999元和6999元，而iPhone 16 Pro与16 Pro Max的国行版起售价更是攀升至7999元和9999元。</p>
  <p>OPPO Find X8对标iPhone16的意图明显，即要争夺被苹果手机把持的高端手机市场。</p>
  <p>对于OPPO而言，全球高端市场无疑是一块既充满挑战又极具吸引力的必争之地。“随着Find X8发布，OPPO要在全球市场把Find做起来，这是我们的一个主策略。”刘作虎称，“全球市场是检验旗舰手机实力的试金石，只有在全球范围内获得高价位段消费者的青睐，才能真正彰显其含金量。未来，我们将更积极地推动OPPO Find X8这样的高端旗舰机型走向世界舞台。”</p>
  <p>不可否认，尽管OPPO在高端市场频繁推出新品，Find X系列已更新至第8代，但在出货量上却难以实现实质性的突破。</p>
  <p>目前，全球高端手机市场几乎被苹果和三星两家巨头所垄断。Counterpoint的数据显示，2022年与2023年，在全球600美元以上的高端手机市场中，苹果与三星的合计份额均超过了85%，而OPPO的市场份额则一直维持在1%左右。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_80f0c6b0af404ea488bb6b480ed4654b@000000_oswg40400oswg765oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">资料来源：Counterpoint Research</p>
  <p>由此可见，OPPO进军高端手机市场并非易事。</p>
  <p>12月上旬，Canalys发布了2024年第三季度智能手机市场报告，揭示了全球高端智能手机领域的最新竞争格局，在售价超过600美元（折合约4349元人民币）的细分市场中，苹果以高达63%的市场份额独占鳌头，三星紧随其后，以21%的市场份额占据次席。而华为、谷歌和荣耀则分别以8%、2%和2%的市场份额位列第三、第四和第五位，未能跻身前五的OPPO市场份额则低于2%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_5504252f75984955a3254bdfcdaf3131@000000_oswg65637oswg960oswg540_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与此同时，在中国大陆高端智能手机市场，前五名的宝座依旧被苹果、华为、荣耀、小米及三星牢牢占据，OPPO亦不见踪影。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU3ODQ5MjQzMQ==&amp;mid=2247573333&amp;idx=2&amp;sn=ec436b6c6452f9aae108739bba8e1626&amp;chksm=fcd39e26adbb7db708b1e1708e8b1d801681b92c81892c0997bd9b3fd52de5016eccd2748d94&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“鳌头财经”（ID：theSankei）</a>，作者：王杰仁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072747093390215</id>
            <title>看3.2亿帧视频学会3D生成，智源开源See3D：只需单图即可生成3D场景</title>
            <link>https://www.36kr.com/p/3072747093390215</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072747093390215</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 10:26:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 空间智能, 3D生成, See3D, 视频学习  
<br><br>  
总结: 近日，李飞飞团队推出了首个「空间智能」模型，能够通过单张图片生成逼真的3D世界。同时，智源研究院推出了See3D模型，利用大规模无标注互联网视频进行3D生成。See3D采用全新的视觉条件技术，依赖视频中的视觉线索生成多视角图像，避免了昂贵的3D标注。该模型支持零样本和开放世界的3D生成，展现出广泛的适用性。通过扩大数据集规模，See3D为3D生成技术提供了新的思路，旨在降低3D数据采集成本，推动研究社区关注无相机标注数据。 </div>
                        <hr>
                    
                    <p>近日，著名AI学者、斯坦福大学教授李飞飞团队WorldLabs推出首个「空间智能」模型，仅输入单张图片，即可生成一个逼真的3D世界，这被认为是迈向空间智能的第一步。</p>
  <p>几乎同时，国内<strong>智源研究院</strong>推出了首个利用大规模无标注的互联网视频学习的3D生成模型<strong>See3D</strong>—See Video, Get 3D。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_babca4783cc7445dbc0261ace82faf3b@46958_oswg1070796oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>△</strong>See3D支持从文本、单视图和稀疏视图到3D的生成，同时还可支持3D编辑与高斯渲染</p>
  <p>不同于传统依赖相机参数（pose-condition）的3D生成模型，See3D采用全新的视觉条件（visual-condition）技术，仅依赖视频中的视觉线索，生成相机方向可控且几何一致的多视角图像。</p>
  <p>这一方法不依赖于昂贵的3D或相机标注，能够高效地从多样化、易获取的互联网视频中学习3D先验。</p>
  <p>See3D不仅支持零样本和开放世界的3D生成，还无需微调即可执行3D编辑、表面重建等任务，展现出在多种3D创作应用中的广泛适用性。</p>
  <p>相关的模型、代码、Demo均已开源，更多技术细节请参考See3D论文。</p>
  <p>论文地址:https://arxiv.org/abs/2412.06699项目地址:https://vision.baai.ac.cn/see3d</p>
  <h2><strong>效果展示</strong></h2>
  <p>1. 解锁3D互动世界：输入图片，生成沉浸式可交互3D场景，实时探索真实空间结构。</p>
  <p>2. 基于稀疏图片的3D重建：输入稀疏的(3-6张)图片，模型可生成一个精细化的3D场景。</p>
  <p>3.&nbsp;开放世界3D生成：根据文本提示，生成一副艺术化的图片，基于此图片，模型可生成一个虚拟化的3D场景。</p>
  <p>4. 基于单视图的3D生成：输入一张真实场景图片，模型可生成一个逼真的3D场景。</p>
  <h2><strong>研究动机</strong></h2>
  <p>3D数据具有完整的几何结构和相机信息，能够提供丰富的多视角信息，是训练3D模型最直接的选择。然而，现有方法通常依赖人工设计（designed artists）、立体匹配（stereo matching）或运动恢复结构（Structure from Motion, SfM）等技术来收集这些数据。</p>
  <p>尽管经过多年发展，当前3D数据的积累规模依然有限，例如DLV3D(0.01M)、RealEstate10K(0.08M)、MVImgNet(0.22M)和Objaverse(0.8M)。这些数据的采集过程不仅耗时且成本高昂，还可能难以实施，导致其数据规模难以扩展，无法满足大规模应用的需求。</p>
  <p>与此不同，人类视觉系统无需依赖特定的3D表征，仅通过连续多视角的观察即可建立对3D世界的理解。单帧图像难以实现这一点，而视频因其天然包含多视角关联性和相机运动信息，具备揭示3D结构的潜力。</p>
  <p>更重要的是，视频来源广泛且易于获取，具有高度的可扩展性。基于此，See3D提出“SeeVideo,Get3D”的理念，旨在通过视频中的多视图信息，让模型像人类一样，学习并推理物理世界的三维结构，而非直接建模其几何形态。</p>
  <h2><strong>方法介绍</strong></h2>
  <p>为了实现可扩展的3D生成，See3D提供了一套系统化的解决方案，具体包括：</p>
  <p><strong>1）数据集：</strong>团队提出了一个视频数据筛选流程，自动去除源视频中多视角不一致或观察视角不充分的视频，构建了一个高质量、多样化的大规模多视角图像数据集WebVi3D。该数据集涵盖来自1600万个视频片段的3.2亿帧图像，可通过自动化流程随互联网视频量的增长而不断扩充。</p>
  <p><strong>△</strong>WebVi3D数据集样本展示</p>
  <p><strong>2）模型：</strong>标注大规模视频数据的相机信息成本极高，且在缺乏显式3D几何或相机标注的情况下，从视频中学习通用3D先验是更具挑战的任务。为解决这一问题，See3D引入了一种新的视觉条件——通过向掩码视频数据添加时间依赖噪声，生成一种纯粹的2D归纳视觉信号。这一视觉信号支持可扩展的多视图扩散模型（MVD）训练，避免对相机条件的依赖，实现了“仅通过视觉获得3D”的目标，绕过了昂贵的3D标注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8eacae63dc2d4a2c99cc43a1aa2a764c@46958_oswg458316oswg1080oswg479_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p><strong>3）3D生成框架：</strong>See3D学到的3D先验能够使一系列3D创作应用成为可能，包括基于单视图的3D生成、稀疏视图重建以及开放世界场景中的3D编辑等，支持在物体级与场景级复杂相机轨迹下的长序列视图的生成。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a8ce9ff9c07d446e94549a551aec081e@46958_oswg506784oswg1080oswg499_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <h2><strong>优势</strong></h2>
  <p><strong>a) 数据扩展性：</strong>模型的训练数据源自海量互联网视频，相较于传统3D数据集，构建的多视图数据集(16M)在规模上实现了数量级的提升。随着互联网的持续发展，该数据集可持续扩充，进一步增强模型能力的覆盖范围。</p>
  <p><strong>b) 相机可控性：</strong>模型可支持在任意复杂的相机轨迹下的场景生成，既可以实现场景级别的漫游，也能聚焦于场景内特定的物体细节，提供灵活多样的视角操控能力。</p>
  <p><strong>c) 几何一致性：</strong>模型可支持长序列新视角的生成，保持前后帧视图的几何一致性，并遵循真实三维几何的物理规则。即使视角轨迹发生变化，返回时场景依然保持高逼真和一致性。</p>
  <h2><strong>总结</strong></h2>
  <p>通过扩大数据集规模，See3D为突破3D生成的技术瓶颈提供了新的思路，所学习到的3D先验为一系列3D创作应用提供了支持。希望这项工作能够引发3D研究社区对大规模无相机标注数据的关注，避免高昂的3D数据采集成本，同时缩小与现有强大闭源3D解决方案之间的差距。</p>
  <p>*本文系量子位获授权刊载，观点仅为作者所有。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/K1kCyBSqejj-kpR-YTsxyQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：梦晨&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072826365260418</id>
            <title>大模型在先,小模型在后,生成式AI试水工业,如何破局数据短缺/可靠性不足?</title>
            <link>https://www.36kr.com/p/3072826365260418</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072826365260418</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 10:17:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小模型, 工业应用, AI代理, 生成式AI  
<br><br>  
总结: 本文探讨了小模型SLM在工业领域的应用与发展，强调其相较于大模型LLM的优势，如资源效率和针对特定任务的优化能力。小模型正在被科技巨头们广泛应用于各行各业，成为推动产业创新的“生力军”。尽管小模型在处理特定任务时表现出色，但其局限性如可靠性不足和数据缺失仍需关注。AI代理的概念被引入，展示了多个小模型协作完成复杂任务的潜力。文章最后指出，尽管面临挑战，未来小模型和生成式AI在工业领域的应用前景依然乐观。 </div>
                        <hr>
                    
                    <p>在我之前的文章《从LLM大模型到SLM小模型再到TinyML,这个领域有望增长31倍》中，曾经提到小模型SLM的进展，如今这一领域正在悄然发生突破。</p>
  <p>小模型SLM，可以看作是大模型LLM的“迷你版”，它们虽然体型小巧，但却拥有着不容小觑的能力。相比动辄数百万、数十亿参数的GPT-4等大模型，SLM的运行规模要简单得多。经过优化的SLM能够高效处理较为简单的任务，而无需消耗大量计算资源。</p>
  <p>如今，小模型正朝着产业落地的方向大步迈进，它们不再是实验室里的“玩具”，而是正在成为各行各业的“生力军”。</p>
  <p>科技巨头们已经嗅到了小模型的无限潜力，纷纷加入这场争夺未来的战局。</p>
  <p>微软、谷歌和苹果等公司均已入局小模型SLM，例如微软的Phi-3、谷歌的Gemma和苹果的Foundation Models。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_4c6ae5a410bd475093ba0324a452cf1c@000000_oswg43307oswg1080oswg342_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最近，微软更是推出了适用于工业领域的全新AI小模型。</p>
  <p>通过与拜耳、罗克韦尔自动化、西门子等公司合作，这些小模型使用行业特定数据进行了预先训练，可用于处理一些关键问题。这就像是为每个行业量身定制了一套“智能装备”，让AI的力量深入到每个生产环节，提升效率、优化流程、创造价值。</p>
  <p>今天这篇文章，我们将一起探索小模型在工业应用中的最新进展，了解它们所蕴藏的机遇与挑战。</p>
  <h2><strong>小模型与AI代理：下一个热门？</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b7bdd04798034675a56430e4e7c0c84b@000000_oswg96618oswg1080oswg394_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>首先，我们需要进一步理清大模型与小模型之间的区别，如上图所示。</p>
  <p>小模型之所以“小”，不仅仅在于其参数数量较少，更重要的是，小模型常常在小型数据集上进行微调，以优化其在特定任务上的性能，使其更加契合业务工作流的需求。</p>
  <p>小模型的强项在于处理特定任务和工作流程。尽管参数数量有限，但当使用定制数据集针对特定领域任务进行微调时，小模型完全能够胜过大型通用模型。针对特定任务的训练可以减轻幻觉现象，增强问题解决能力。</p>
  <p>资源效率是小型语言模型的另一大亮点，对于希望跨越各种平台和设备实施AI解决方案的企业来说，它们尤其具有吸引力。小模型使企业能够以更简单的基础架构和更低的成本，充分享受AI带来的优势。据测算，小模型可以节省高达75%的模型训练成本和超过50%的总部署成本。</p>
  <p>在小模型的基础上，我们还可以玩出许多新花样。</p>
  <p>一些公司将小模型用于AI代理工作流中，其中多个小模型通过通信和协作来执行更加复杂的任务。</p>
  <p>例如，在AI代理工作流中，第一个AI代理可能负责规划如何解决任务，第二个AI代理进行必要的研究，第三个AI代理执行该计划，第四个AI代理则验证和评估结果。这种协作方式展示了这些模型如何协同工作，以提高生产力并实现更复杂的结果。</p>
  <p>说到这里，我来解释一下什么是AI智能代理。</p>
  <p>AI代理的官方定义是一种能够感知环境、进行决策和执行动作的智能体。</p>
  <p>简而言之，ChatGPT不属于AI代理，但战胜李世石的AlphaGo可以被视为AI代理。</p>
  <p>目前，我们与AI的交互形式基本上都是先输入指令，AI模型根据指令内容做出响应，这就导致我们每次都需要提供有效的提示词，才能达到预期效果。</p>
  <p>而AI代理则不同，它被设计为具有独立思考和行动能力的AI程序。我们只需要提供一个目标，比如写一个游戏、开发一个网页，AI代理就会自主生成一个任务序列，开始工作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_634eb3f538ce431b9d65f1de62617184@000000_oswg155886oswg1080oswg491_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>让我们通过几个例子来更深入地理解AI代理。</p>
  <p>一个初级的AI代理，是家中的空调自动控制系统。它遵循简单的“如果-那么”原则运行：如果温度低于设定点，则打开空调暖风；如果温度高于设定点，则关闭空调暖风。这种基础的AI代理虽然简单，但在日常生活中已经发挥了重要作用。</p>
  <p>而高级的AI代理，如DeepMind的AlphaGo，则是专为复杂的围棋而设计的人工智能系统。AlphaGo展示了非凡的学习能力，最终击败了世界冠军围棋选手。这一里程碑式的事件，彰显了AI代理在处理复杂任务方面的巨大潜力。</p>
  <p>就像俄罗斯套娃一样，多个初级和高级的AI代理可以建立起分层代理系统。</p>
  <p>分层代理是一种将复杂任务分解为更简单的子任务，并以分层结构组织起来的AI系统。这种方法允许代理管理不同级别的抽象，更有效地处理复杂问题。</p>
  <p>分层代理的一个典型例子，就是亚马逊Amazon Go商店的“Just Walk Out”技术。该系统在运作中表现出了清晰的层级结构：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_590a315f75da49769edb5fef392237a4@000000_oswg167267oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <ul>
   <li>顶层：整体商店管理和库存跟踪</li>
   <li>中级：客户跟踪和行为分析</li>
   <li>低级：产品识别和交互检测</li>
   <li>最低级别：传感器数据处理和融合</li>
  </ul>
  <p>依靠这些AI代理的协同工作，Amazon Go以“不用排队，拿了就走”的全新购物体验，在零售行业和科技圈吸引了无数目光。</p>
  <p>上述案例只是冰山一角，AI代理在实际应用中的想象力正在被激发。</p>
  <h2><strong>小模型与Copilot覆盖超100家公司12万用户</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_4ad4625a028c4637a8010c6db87a7a8f@000000_oswg246553oswg1080oswg673_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在了解了小模型与AI代理的概况后，让我们一起探索微软与工业企业的最新合作。</p>
  <p>本次尝试微软小模型的企业包括拜耳、罗克韦尔自动化、西门子、Sight Machine等。</p>
  <p>以罗克韦尔自动化为例，该公司从操作层面开始尝试应用小模型。在人机界面可视化平台FactoryTalk Optix的食品和饮料版本中，他们运用小模型，将行业特定功能的优势带给制造业一线工人，支持食品和饮料领域的资产故障排除。AI模型为工厂车间工人和工程师提供关于特定制造流程、机器和输入的实时建议、解释和知识。</p>
  <p>另一款产品FactoryTalk Design Studio是罗克韦尔自动化专注于系统设计的云原生软件，它使用Copilot增强了PLC代码创建和用户管理。工程师能够使用自然语言提示执行产品指导、代码生成、故障排除和代码解释等任务，使系统设计更快、更直观。</p>
  <p>同样，西门子正在为CAD解决方案NX X软件引入全新的Copilot。该软件利用经过调整的AI模型，使用户能够通过自然语言提问、获取详细的技术见解并简化复杂的设计任务，实现更快、更智能的产品开发。</p>
  <p>目前，包括舍弗勒和蒂森克虏伯自动化工程在内的100多家公司正在使用西门子工业Copilot来简化流程、解决劳动力短缺问题并推动创新。12万名西门子工程软件用户，现在有机会通过生成式AI驱动的助手来提升工作效率。</p>
  <p>作为敢于吃螃蟹的用户，蒂森克虏伯自动化工程公司是首家使用Copilot的公司，并且计划从2025年初开始，在该公司的全球体系内普及应用。</p>
  <p>根据实践，工程师现在可以在30秒内创建可视化面板，并生成代码，根据经验这些代码仅需20%左右的调整就可以直接应用。这简化了工作流程，减少了人工工作量，解决了熟练劳动力短缺的问题。</p>
  <p>就具体场景而言，蒂森克虏伯使用AI辅助开发用于生产汽车电池的自动化系统。例如在一台电池质量的检测装置中，传感器、摄像头和测量系统集成在一起，监控多个阶段的电池单元质量，进行复杂的评估以检测超出设定阈值的放电。Copilot通过自动执行多个任务，如数据管理、传感器配置、电池质量检测等各个重复性步骤，辅助操作员增强了该设备的运行效果。</p>
  <h2><strong>Copilot：工业生成式AI的现实角色</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_fd9df2b74f7c43758ae60a8e75192489@000000_oswg100882oswg1000oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在工业领域，“想到”和“做到”完全是两码事，生成式AI的工业价值尚需被验证。</p>
  <p>古人云“欲得其利、先知其弊”，要充分发挥小模型的优势，就必须了解它的局限性。</p>
  <p>生成式AI的弊端在于可靠性较低，具有不可解释性，只能应用于对可靠性要求不高的场合。</p>
  <p>小模型的缺点则是精度有限，无法捕捉大规模和复杂数据集中的细致特征和关系，预测能力相对较弱；此外，它们难以应对复杂问题。这些弊端决定了小模型只能承担辅助思考的角色，为我们提供更多可行性方案作为选择，而最终决策仍需由人来做。</p>
  <p>在实际应用过程中，也是挑战重重。</p>
  <p>工业领域广泛使用AI的最大障碍是数据的缺失。由于工业涉及设备、工艺、操作、环境等多重因素影响，获取大量且多维的全面数据难度很大。大多数制造商虽然坐拥数据，但其中大部分是时间序列数据，没有得到适当的标准化，甚至无法用于AI的模型训练。</p>
  <p>数据问题的本质，很多时候不单纯是技术问题，而是人员和流程问题。不成熟的数据管理流程、始终存在的OT与IT鸿沟，以及缺乏对小模型的理解，都是导致生成式AI目前仅限于一次性试点或实验的因素。</p>
  <p>因此，目前生成式AI在工业领域更多以虚拟助手的功能存在，并将会持续较长时间。</p>
  <p>这些AI虚拟助手为工厂车间操作员提供指导，或帮助控制工程师编写PLC代码。鉴于当前吸引和留住工厂车间人才的挑战，Copilot能够轻松帮助合成实时信息或提供编码辅助。</p>
  <p>过去，工程师需要熟悉云平台、传感器、物联网、人工智能和不同类型的时间序列和工程数据，而生成式AI则允许工程师轻松进行数据查询、可视化和工作流程，而无需担心复杂性。操作员可以按需提出问题，而不需要了解软件。</p>
  <p>许多制造企业配备了复杂的系统和更多的自动化设备，但那些拥有几十年经验与知识的资深员工却逐渐离开了职场，制造商们很难找到年轻的技术人员来维护现有的系统。Copilot可以成为帮助缩小这一差距的工具。</p>
  <p>例如，工业软件企业Aveva的AI助手可以帮助操作员回答以下问题：上个月车间的最大产量是多少？或者为什么这台压缩机本周效率较低？杜邦公司也已经开始使用生成式AI来帮助工程师更快地找到信息，生成式AI可以节省数小时的手册搜索时间。</p>
  <p>这些Copilot就像操作员的专家顾问，根据需要建议如何提高产量、降低能耗等。从某种意义上说，它们与原有的“专家系统”并没有本质区别，是否采纳这些建议取决于操作员。</p>
  <p>面临的挑战也与过去的“专家系统”大同小异：如何建立对顾问的信任。工厂中的新配方经常出现，如果没有适当的更新和维护，专家系统也会很快过时。另一个风险在于，如何检查和验证所有生成式AI的输出。AI不会说“我不知道”；如果没有数据，它可能会进行编造。</p>
  <h2><strong>写在最后</strong></h2>
  <p>在这个万物互联、智能无处不在的时代，小模型和生成式AI正在工业领域掀起一场革命。从制造车间到产品设计，从运营优化到故障诊断，AI正在重塑着每一个环节。</p>
  <p>然而，我们也必须清醒地认识到，工业领域的AI应用之路并非坦途。数据缺失、可靠性不足、解释性有限等挑战，都在提醒我们要谨慎对待这项新兴技术。尽管如此，我们仍然有理由对未来保持乐观。</p>
  <p>随着技术的不断进步和企业实践的深入，人机协作将更加紧密，小模型和生成式AI也将在工业领域释放出更大的潜力。</p>
  <p>参考资料：</p>
  <p>《忍不住谈谈工业大模型》，作者：郭朝晖，来源：蝈蝈创新随笔</p>
  <p>《Microsoft Introduces New Adapted AI Small Language Models for Industry》，作者：Colin Masson，来源：ARC Advisory Group</p>
  <p>《What is Agentic AI? Is It the Next Big Thing?》，作者：Nora He，来源：arcee.ai</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MTM5ODQyMA==&amp;mid=2651321283&amp;idx=1&amp;sn=34e839c9a8adf3560557bef27d76185c&amp;chksm=bc6884196435e8453a00107538d80b85b05a5ceb2b40d8c647c49af7227a3c5009525018de27&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“物联网智库”（ID：iot101）</a>，作者：彭昭，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072773658653570</id>
            <title>速度提升1000倍，效果还全面碾压，JHU等提出首个可渲染HDR场景的3DGS</title>
            <link>https://www.36kr.com/p/3072773658653570</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072773658653570</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 10:00:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: HDR-GS, 新视角合成, 高动态范围, 3D高斯点云  
<br><br>  
总结: 研究人员提出了一种新的3D高斯点云模型HDR-GS，用于高动态范围（HDR）图像的渲染和新视角合成（NVS）。该模型能够根据用户输入的曝光时间调整光照强度，并且在渲染速度上比现有的HDR-NeRF算法快1000倍。HDR-GS通过双动态范围的高斯点云模型和并行光栅化处理管线，能够同时生成HDR和低动态范围（LDR）图像。实验结果表明，HDR-GS在图像质量和渲染速度上均显著优于现有方法，具有广泛的应用前景。 </div>
                        <hr>
                    
                    <p><strong>【导读】</strong>研究人员提出首个可以渲染高动态范围（High Dynamic Range, HDR）自然光的3DGaussian Splatting模型HDR-GS，以用于新视角合成（Novel View Synthesis, NVS）。该方法可以根据用户输入的曝光时间来改变渲染场景的光照强度，同时还可以直接渲染高动态范围场景。比当前最好的算法HDR-NeRF速度上要快1000倍。</p>
  <p>常见的RGB图像大都为低动态范围（Low Dynamic Range, LDR），亮度的取值范围在[0,255]之间。</p>
  <p>然而人眼对亮度的感知范围要比RGB图像宽广得多，一般为[0,+∞]，导致LDR图像很难反映真实场景的亮度范围，使得一些较暗或者较亮的区域的细节难以被捕捉，高动态范围（High Dynamic Range，HDR）图像应运而生，具有更广的亮度范围。</p>
  <p>新视角合成（Novel View Synthesis，NVS）任务是在给定「一个场景的几张不同视角图像，并且相机位姿已知」的情况下，合成其他新视角的场景图像。</p>
  <p>同比于LDR NVS，HDR NVS能更好地拟合人类视觉，捕获更多的场景细节，渲染更高质量、视觉效果更好的图片，在自动驾驶、图像编辑、数字人等方面有着十分广泛的应用。</p>
  <p>当前主流的HDR NVS方法主要基于神经辐射场（Neural Radiance Fields, NeRF），然而，NeRF的ray tracing加volume rendering机制都十分耗时，常常需要十分密集地采集射线，然后在每一条射线上采集多个3D点，对每一个3D点过一遍MLP来计算体密度和颜色，严重拖慢了训练时间和推理速度。当前最好的NeRF算法HDR-NeRF需要耗费9小时来训练一个场景，8.2秒来渲染一张尺寸为400x400的图像。</p>
  <p>为了解决上述问题，约翰霍普金斯大学、香港科技大学、清华大学、上海交通大学的研究人员提出了首个基于3DGS的方法HDR-GS，用于三维HDR成像；设计了一种有着双动态范围的三维高斯点云模型，同时搭配两条平行的光栅化处理管线以用于渲染HDR图像和光照强度可控的LDR图像。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8c0b8de814b141a1ad9728aaa4f15962@46958_oswg71272oswg1080oswg410_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文链接： https://arxiv.org/abs/2405.15125&nbsp;</p>
  <p>代码链接：https://github.com/caiyuanhao1998/HDR-GSgithub.com/caiyuanhao1998/HDR-GS&nbsp;</p>
  <p>Youtube视频讲解：https://www.youtube.com/watch?v=wtU7Kcwe7ck</p>
  <p>研究人员还重新矫正了一个HDR多视角图像数据集，计算得到的相机参数和初始化点云能够支持3DGS类算法的研究。HDR-GS算法在超过当前最好方法1.91 dB PSNR的同时仅使用6.3%的训练时间并实现了1000倍的渲染速度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_dafd4ca7b4ab456791ba7ba8aa67225a@46958_oswg156296oswg1080oswg734_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图1 HDR-GS与HDR-NeRF各项性能对比图</p>
  <p>一大波演示如下：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_61ac6dfe22c04f5ebfec3409d19f170d@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_907ce4e2bcb34823adcf91fa75f1c4c0@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a775b1a5315e48ec9fedfcd3310a18db@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_e31c07f7a252412593f449803b651257@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对比近期出现的3D‍ Gaussian Splatting（3DGS），虽然能在保证图像质量的同时也大幅提升了训练和渲染速度，但却很难直接应用到HDR NVS上，仍然存在三个主要问题：&nbsp;</p>
  <p>1. 渲染的图片的动态范围依旧是[0,255]，仍旧属于LDR；</p>
  <p>2. 直接使用不同光照的图片来训练3DGS容易导致模型不收敛，因为3DGS的球谐函数（Spherical Harmonics，SH）无法适应光照的变化，时常会导致伪影、模糊、颜色畸变等问题；</p>
  <p>3. 常规的3DGS无法改变渲染场景的亮度，极大限制了应用场景，尤其是在AR/VR、电影、游戏等领域，经常需要改变光照条件来反映人物的心情与环境氛围。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_71ecbe9ba0f248dea926a52e6569971e@46958_oswg924502oswg1080oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图2 常规3DGS对比HDR-GS</p>
  <h2><strong>方法架构</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_20cfadf9393442589f94e1c85c7e36cf@46958_oswg400832oswg1080oswg465_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图3 HDR-GS的整体算法流程</p>
  <p>研究人员首先使用Structure-from-Motion（SfM 算法来重新矫正场景的相机参数并初始化高斯点云，然后将数据喂入到双动态范围（Dual Dynamic Range，DDR）的高斯点云模型来同时拟合HDR和LDR颜色，使用SH来直接拟合HDR颜色。</p>
  <p>再使用三个独立的MLP来分别对RGB三通道做tone-mapping操作，根据用户输入的曝光时间将HDR颜色转为LDR颜色，然后将3D点的LDR和HDR颜色喂入到平行光栅化（Parallel Differentiable Rasterization, PDR）处理管线来渲染出HDR和LDR图像。</p>
  <h3><strong>双动态范围高斯点云模型</strong></h3>
  <p>场景可以用一个DDR高斯点云模型来表示：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_57269dddb35e4411ae02eb7b6939dd88@46958_oswg7761oswg1080oswg54_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中的Np是3D Gaussians的数量，Gi表示第i个Gaussian，其中心位置、协方差、不透明度、LDR颜色和HDR颜色记为</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_6d08e4b8f8844fd994ad6e01f47f8053@46958_oswg13196oswg391oswg93_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>。</p>
  <p>除了这些属性外，每一个Gi还包含一个用户输入的曝光时间Δt和一个全局共享的基于MLP的tone-mapper θ，由一个旋转矩阵Ri和一个缩放矩阵Si表示成如下形式：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_dd151bfce9784af69035cc4824ee9e1d@46958_oswg6602oswg1080oswg56_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中的μi,Ri,Si,αi和θ是可学习参数，Tone-mapping操作fTM(⋅)模拟相机响应函数来将HDR颜色非线性地映射到LDR颜色：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_2a79f0ea68fa4d13bdde55dd49c93f58@46958_oswg7491oswg1080oswg56_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为了训练稳定，研究人员将公式（3）从线性域转成对数域如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_27daffc9dad84c6fb031ba7beffe9cfc@46958_oswg9366oswg1080oswg50_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对此公式取反函数：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b1f931c233ba4fc181c3eedfdff02f24@46958_oswg9852oswg1080oswg51_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然后用三个MLP θ在RGB三通道上分别拟合公式(5)的变换。简洁起见，将tone-mapper的映射函数记为</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8b2c1e426a32471bbc2cf338aff471e3@46958_oswg20213oswg592oswg99_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>，然后公式（5）便可被重新推导为</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_f43e105447624c03b67bc10fd097ebb2@46958_oswg8329oswg1080oswg43_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然后使用SH函数来拟合HDR颜色如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_3a2bc89320e84162ad5dd9eaeed8fe09@46958_oswg8601oswg1080oswg102_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>将公式（7）代入公式（6）便可得到：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_3a61114cc8414727b7f9da8f08d13d56@46958_oswg14070oswg1080oswg98_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>每一个独立的MLP包括一层全连接、一层ReLU、一层全连接和一个Sigmoid激活函数。</p>
  <h3><strong>平行光栅化处理管线</strong></h3>
  <p>将3D Gaussian的HDR颜色和LDR颜色输入到平行光栅化处理管线中，分别渲染出LDR和HDR图像，这一过程可以被概括为如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_10c361f5a3a6453bacea210db74ff7f1@46958_oswg19058oswg1080oswg108_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>首先计算出第i个3D Gaussian在一个3D点x处概率值如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_30b60b715920408c98f7015957f052ba@46958_oswg11440oswg1080oswg74_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然后将3D Gaussian从三维空间中投影到2D成像平面上。在这一投影过程中，中心点的位置μi首先被从世界坐标系变换到相机坐标系，然后再投影到图像坐标系上：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_e56bff182347466a87b90b5b4728a29c@46958_oswg9752oswg1080oswg63_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>三维协方差矩阵也被从世界坐标系投影到相机坐标系上：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_6226032149d545dd976cd90c33b4b4f4@46958_oswg4402oswg1080oswg56_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>后在图像坐标系下的二维协方差矩阵是直接取</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_537717d37fce4731a8def21c0baa372e@46958_oswg3063oswg87oswg79_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>的前两行前两列。</p>
  <p>将2D projection分割成互不重叠的titles，每一个三维高斯点云都按照其对应投影所落在的位置分配到对应的tiles上。这些3D高斯点云按照与二维探测器平面的距离进行排序。</p>
  <p>那么，在2D projection上像素点p上的HDR颜色和LDR颜色便是混合N个与p重叠的排好序的3D点得到的，如下公式所示</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_9368145f4a814977a9099a373655314b@46958_oswg16704oswg1080oswg101_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>HDR-GS的初始化与训练过程</strong></h3>
  <p>阻碍3DGS类算法在三维HDR成像上发展的一大障碍，是原先HDR-NeRF搜集的多视角HDR图像数据集的仅提供normalized device cooridnate（NDC）的相机位姿。</p>
  <p>然而NDC并不适用于3DGS，主要有<strong>两个原因：</strong></p>
  <p>首先，NDC描述的是投影后2D屏幕上的位置。然而，3DGS是一个显式的3D表征，需要对三维空间中的高斯点云进行变换和投影。</p>
  <p>其次，NDC将坐标限制在[-1,1]或者[0,1]。Voxel的分辨率有限，使得3DGS很难刻画场景中的细节。另外，原先搜集好的数据中并没有提供SfM点云来给3DGS进行初始化。</p>
  <p>为解决这一问题，研究人员使用了SfM算法来对多视角HDR数据集重新计算相机参数和初始化点云如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_1cab65a87d8e463a9891eda4bf4f4e51@46958_oswg13288oswg1080oswg59_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中的Mint,Mext分别表示相机的内外参数矩阵。对LDR图像的训练监督函数如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_52d1e844d883488fb70f174b1ce86e7c@46958_oswg15387oswg1080oswg98_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>类似于HDR-NeRF，也对HDR图像施加限制。需要注意的是，HDR-NeRF施加的约束是直接使用CRF矫正的GT参数，这是一个很强的先验。使用的是μ - law tone-mapping后的HDR图像。损失函数如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_5bba0fcffd714a589f91eede23fb2403@46958_oswg16950oswg1080oswg104_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最终总的训练损失函数是两者的加权和：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_26d9f773ddc942c2a2b5ef2fdc69d4c8@46958_oswg6427oswg1080oswg50_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>需要注意，由于真实场景中并无法直接获得HDR图像，所以分别对合成场景与真实场景设置γ=0.6和γ=0</p>
  <h2><strong>实验结果</strong></h2>
  <h3><strong>定量结果</strong></h3>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_4b00deda486d4da2ac7c6d16d3df0e7a@46958_oswg136785oswg1080oswg263_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">表1 合成实验对比结果</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a217ef6279634b23a2cda0ca1796a849@46958_oswg134795oswg1080oswg277_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">表2 真实实验对比结果</p>
  <p>合成实验和真实实验的定量对比结果分别如表1和表2所示，HDR-GS在性能上显著超过之前方法的同时，训练和推理也分别达到了16倍速和1000倍速。</p>
  <h3><strong>视觉结果</strong></h3>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_c1faec4d37bb4f088b9f7c7596c247cc@46958_oswg843069oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图 4 合成场景的LDR NVS视觉对比</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_450c6ba6fd3543b7bc3c89f245d7dda6@46958_oswg641389oswg1080oswg463_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图 5 真实场景的LDR NVS视觉对比</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_170f894c105f44d18da0350ab66b79e7@46958_oswg830397oswg1080oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图6 HDR NVS视觉对比</p>
  <p>LDR NVS的视觉对比结果如图4和图5所示，HDR NVS的视觉对比结果如图6所示。HDR-GS能够渲染出更丰富更清晰的图像细节，更好地捕获HDR场景并能灵活地改变LDR场景的光照强度。</p>
  <p>参考资料：&nbsp;</p>
  <p>https://arxiv.org/abs/2405.15125&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/yRMIQQmOE1LW9vVdnmIaxg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：LRST&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072762758214532</id>
            <title>上线即瘫痪，Sora正式版“贵是真的贵，强是真的强”</title>
            <link>https://www.36kr.com/p/3072762758214532</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072762758214532</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 09:47:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, OpenAI, 视频生成, 定价策略  
<br><br>  
总结: OpenAI于12月10日正式发布了人工智能视频生成模型Sora，吸引了大量用户注册，导致官方网站一度崩溃。Sora的生成成本较高，生成5秒1080P视频需4美元，用户对此反应不一。Sora Turbo作为更快的版本也已推出，支持更长时间的视频生成。用户反馈显示，Sora在视频一致性和编辑功能上有显著提升，尤其是Storyboard功能受到好评。尽管存在一些不足，如图生视频效果不佳，但Sora仍被认为在文生视频领域具有领先优势。OpenAI计划在未来推出新的定价模式，以满足不同用户需求。 </div>
                        <hr>
                    
                    <p>OpenAI 的“12天发布会大戏”唱到第三场，Sora终于来了！</p>
  <p>12月10日，OpenAI宣布正式向用户开放人工智能视频生成模型Sora，距离OpenAI首次公开预览这款产品，已过去10个月。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a08b90dace7e461a84defa49d8e65123@000000_oswg496034oswg1080oswg579_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>时间并没有让Sora热度减退，用户蜂拥而至，官方网站瞬间流量激增，直至崩溃，一度暂停注册和登录服务。</p>
  <p>OpenAI说：“这是给大家准备的（圣诞）节日礼物。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_d307cf7852fd46cfb5f75258a9677d14@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>贵是真的贵，4美元生成5秒1080P视频</strong></h2>
  <p>两个月前，《IT时报》曾报道，Sora亮相超过半年却迟迟未能正式上线，与其高昂的视频生成成本有直接关系。</p>
  <p>Logenic AI联合创始人李博杰曾向记者指出，此前发布的Sora模型本身需要占用大量计算资源，生成一分钟视频的时间高达约半小时，且并非单台设备完成，而是需要多台并行运行，1分钟视频的成本可能超过100美元。</p>
  <p>李博杰认为，Sora如何微调成更小、更具成本效益的模型，以在特定任务上接近高级模型的性能，是其要解决的首要问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8246645c7e0f4b41b752106d548f35cb@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随着Sora正式发布，OpenAI在X平台上表示，自2月份以来，他们一直在构建Sora Turbo，后者是一个速度明显更快的模型版本，今天将其作为独立产品向Plus和Pro用户开放。</p>
  <p>记者注意到，相比初次亮相的Sora，Sora Turbo生成效率显著提升，能够通过文本直接生成最多20秒或最高分辨率1080P的视频，成为目前全球生成时长最长的视频模型之一。该模型支持文本加图片或视频的输入，可生成特定视频内容，并能够编辑生成视频，使生成效果更加可控。</p>
  <p><strong>定价方面，Sora Turbo将免费提供给ChatGPT Plus和Pro用户，每月月租20美元（约合人民币145元）的Plus用户，每月最多可以生成50个480P分辨率的优先视频；Pro订阅者则最多可生成500个优先视频，普通视频无限量生成，可下载无水印版视频，对应每月费用为200美元（约合1450元）。</strong></p>
  <p>Sora Turbo采用了灵活的积分制定价策略，需要耗费的积分因分辨率和持续时间而异，已经是ChatGPT Plus和Pro会员的用户，无需额外费用就能使用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a3c5a40aea1c49599a42c89c1456c5c0@000000_oswg159809oswg1000oswg474_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">积分价格表</p>
  <p>比如生成一个480P、5s的视频需要25个积分，如果生成480P、20s的视频则需要150个积分。此外，如果使用Remix（重混）、Re-cut（重新剪辑）、Storyboard（故事板）、Loop（循环）、Blend（混合）这些功能，则需要额外的积分。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ce4b6f12a8674cd9975e4f37d536fe80@000000_oswg144953oswg1080oswg508_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">额外积分表</p>
  <p>对于订阅用户而言，ChatGPT Plus计划每月20美元，包含1000积分，支持最高720p分辨率和5秒时长的视频生成；而200美元的ChatGPT Pro计划提供10000积分，支持最高1080p分辨率、20秒时长，并支持同时生成最多5个视频。</p>
  <p><strong>由此计算，每积分成本为0.02美元（约人民币0.145元），在不使用其他功能的前提下，Sora生成一个5秒480P视频成本为0.5美元，折合人民币3.63元。生成5秒1080p视频成本为4美元（约人民币27.6元）。</strong></p>
  <p>这一定价也引发了不同的声音，有用户直呼“太贵”，有用户却认为“一分钱一分货”。</p>
  <p>视频创作者俞国汉向《IT时报》记者表示，相较于Runway提供的95美元/月服务，订阅费 200美元/月的Sora，在性能和功能上完全值得。</p>
  <p>虽然当前价格仍被部分用户认为偏高，但这已是OpenAI努力降低成本的结果。OpenAI还透露，他们计划针对不同用户类型开发新的定价模式，并将于明年初推出。</p>
  <p>需要注意的是，Sora暂不支持ChatGPT Team、Enterprise和Edu用户，也不向18岁以下用户开放。此外，英国、瑞士和欧盟等地区目前无法访问Sora。</p>
  <p>目前，Sora已进入无限制使用阶段，想要体验的用户可以抓紧时间试用。</p>
  <h2><strong>体验者反馈，视频一致性大突破</strong></h2>
  <p>Sora一经上线，已经有一大批视频创作者迫不及待地争先试用。</p>
  <p>一位专业视频博主在体验正式版Sora后总结认为，不管是用户体验的完整性，还是视频修改与编辑的丰富性，Sora都非常强大，运动效果十分流畅，故事板生成视频的一致性也很“完美”。</p>
  <p>记者注意到，OpenAI在直播及官网上详细介绍了Sora的几项核心功能，包括Remix（重混）、Re-cut（重新剪辑）、Storyboard（故事板）、Loop（循环）、Blend（混合）以及Style presets（风格预设）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_86bd18d2223d4c3fa635d94f8fb7aaf1@000000_oswg917931oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为Sora的一项亮点功能，Storyboard（故事板）通过带有关键帧的时间轴，允许用户在个人时间轴上组织和编辑独特的视频序列。这项功能为创作者提供了更大的创作空间，使视频内容的规划与调整更加灵活。</p>
  <p>Remix（重混）功能使用户能够替换、删除或重新构想视频中的元素，赋予用户更高的自由度来塑造最终效果。例如，官网的演示视频中，用户可以将设计的“打开大门通向图书馆”场景中的普通大门替换为法式对开门，可以将图书馆变成一艘宇宙飞船，甚至可以轻松地移除宇宙飞船，替换成一片丛林，最后再用月球景观代替丛林，创造出富有创意和变化的视频效果。</p>
  <p>Re-cut （重新剪辑）功能让用户能够从视频中找到最佳的帧并向任意方向延伸，从而精细调整视频内容。Loop （循环）可通过在开头和结尾添加额外帧来连接视频片段，创建无缝的重复视频，达到平滑循环的效果。Blend （混合）则允许用户将两个完全不同的视频融合成一个无缝剪辑，创造和谐的过渡效果。</p>
  <p>Style presets（风格预设）&nbsp;使用户能够根据自己的创意，选择或自定义不同的风格，实现快速创作。例如，用户可以将两头猛犸象在雪地里走路的场景，转换成纸工艺品风格。</p>
  <p>有体验者分享到，Sora正式版功能比自己想象得更丰富，尤其是Remix、Blend、Loop等功能让他感到耳目一新，而Storyboard功能则最为令人印象深刻。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_d6cfe49ac82341b9a572dd7d23116c04@000000_oswg13637oswg660oswg181_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在此前的采访中，俞国汉就曾指出，商用AI视频制作中，画面一致性、分辨率和语义理解能力是决定视频质量的关键因素。</p>
  <p>尽管文生视频技术为创意工作开辟了新的空间，但其现有的局限性使它在商业应用中的价值远不及图生视频。目前来看，文生视频大模型大多时候更像是爱好者的“玩具”，难以满足商业需求。因为在短剧制作中，需要确保人物形象和其他元素的一致性，而文生视频往往只能生成几秒钟的内容，且下一秒的内容可能会发生变化，这显然无法满足专业制作的要求。</p>
  <p>李博杰此前也提到，在技术层面，文生视频面临的关键挑战之一是风格一致性的问题。例如，在生成一个10秒的视频时，人物形象是否保持一致，是否会出现前后视频中人物外貌不符的情况。此外，视频中的物理规律是否符合常识也是一个难点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_90dc3cc7b8c74e9d87ff2081024e0958@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而此次发布的正式版Sora，被体验者盛赞：通过不同的Prompt，Sora能够生成几乎完美一致性的分镜，从而组成一段流畅的影片。其Storyboard功能尤为出色，能够通过时间轴中的分镜帧引导每个画面的内容，确保镜头一致性，并支持可控的镜头切换和多动作引导。</p>
  <h2><strong>视频版GPT-1，有不足却仍遥遥领先</strong></h2>
  <p>俞国汉在接受《IT时报》记者采访时表示，尽管他尚未亲自体验Sora，但从目前与其他创作者的交流来看，Sora显然超越了以往的文生视频工具，展现了更强大的功能。他直言：“贵是真的贵，强也是真的强。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_6a5355ce17b44dd69c39eec7c5796afa@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他进一步指出，前不久腾讯开源了混元大模型，大家都认为当前开源技术已接近闭源的水平，但Sora一推出，显示了闭源技术依旧领先一代，表现出更强的实力和潜力。</p>
  <p>另一方面，在试用者们的反馈中，如果说Sora的文生视频能力尚且褒贬不一，其图生视频的表现则不尽如人意。俞国汉透露，在与同行的交流中，正式版Sora的图生视频能力遭到不少批评：“大家都对Sora的图生视频表现感到吃惊，认为其效果非常差。”</p>
  <p>国外科技博主Marques Brownlee也在测评一周后表示，Sora存在一些弊端，如对物理规律的理解并不够好，仍会出现人的手部不自然、文字乱码、动物跑着跑着就飞起来等情况。</p>
  <p>此外，OpenAI还开发了全新UI，并提供社区分享服务，允许用户分享自己生成的视频，或借鉴他人的提示效果来完善自己的作品。</p>
  <p>奥特曼在X（推特）发文表示，最令他兴奋的一点是与其他人共同创作的便捷性，感觉就像是一个有趣的新事物。大家可以将Sora看作视频版的GPT-1。</p>
  <p>随着Sora正式版发布，文生视频领域又将再次“变天”。</p>
  <p>图片／ OpenAI</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjM2MzEyNQ==&amp;mid=2651593124&amp;idx=1&amp;sn=aa2bb6a5bb4952b81f253f2a2fee5bd7&amp;chksm=bc1c6f107576ccbaebba65256b844e040685a59a9e8093e4e80952b8abaf54e4811dce964e23&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“IT时报”（ID：vittimes）</a>，作者：贾天荣，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072791302386568</id>
            <title>老股东“围堵”张予彤，杨植麟为何不愿“切割”？</title>
            <link>https://www.36kr.com/p/3072791302386568</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072791302386568</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 09:46:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 仲裁纠纷, 利益冲突, 股份分配  
<br><br>  
总结: 本文讨论了人工智能公司月之暗面与其前母公司循环智能之间的仲裁纠纷。投资方朱啸虎指控创始人杨植麟和张宇韬在未获投资人同意的情况下成立新公司，并质疑张予彤在此过程中的利益冲突。月之暗面在短时间内估值飙升至超30亿美元，引发了投资者的强烈不满。朱啸虎认为张予彤隐瞒了重要信息，损害了投资者利益。双方在和解谈判中存在较大分歧，未来的解决方案仍不明朗。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_37f2d3c80578449eab95267fd1121874@5539202_oswg113630oswg724oswg399_img_png?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>围绕人工智能公司月之暗面的仲裁纠纷，又有了新的进展。</strong></p>
  <p>11月上旬，金沙江创投主管合伙人朱啸虎，曾牵头循环智能的其他4家投资方，对月之暗面创始人杨植麟和联合创始人张宇韬提起仲裁。</p>
  <p>朱啸虎及几位投资方提起仲裁，指控杨植麟和张宇韬两人在未经循环智能投资人同意的情况下，就开始再创业并成立月之暗面这家公司。</p>
  <p><strong>月之暗面原本是循环智能内部已经开发两年的项目，经历分拆后，其在20个月的时间内，估值已达到超30亿美元。</strong></p>
  <p>这也是循环智能的投资人、月之暗面的公司创始成员，两者之间爆发利益冲突的核心原因。</p>
  <p>近期，随着朱啸虎接连发布朋友圈，这一事件的舆论持续发酵。12月5日，其指控张予彤“隐瞒重大的利益冲突……违反了基金合伙人对LP的受托责任，公司董事对股东的受托责任。”</p>
  <p><strong>朱啸虎最新爆出的信息中，直指张予彤才是整件事情的关键人物</strong>——如今已从金沙江创投离职的张予彤，在月之暗面的创立和融资过程中扮演了重要角色，并持有可观数额的股份。然而她并未向金沙江创投合伙人、循环智能的投资人和股东们透露这一事实。</p>
  <p>“张予彤的行为违反了基本的商业底线。”在接受虎嗅采访时，朱啸虎称：“金沙江的LP给金沙江投资时有非常严格的协议。如果一个金沙江的在职投资人，在职期间从项目中获得了好处、获得了收益，那么这些好处和收益应该归基金而非个人。”</p>
  <p>这场利益冲突中，循环智能投资人的核心指控是，月之暗面的成立和股权分配都存在问题，投资人因此蒙受的损失应该得到赔偿。</p>
  <p><strong>朱啸虎对张予彤连续炮轰，引发了舆论风波的再次升级。</strong></p>
  <p>12月6日，月之暗面创始人杨植麟出面回应，力挺张予彤的同时，也围绕月之暗面创办过程、张予彤的股份、朱啸虎的指控等，进行了详细的回应。</p>
  <p><strong>问题在于，杨植麟和朱啸虎分别讲述的故事之间，存在着较大的偏差。这或许也预示着，短时间内两方还很难达成和解，这场风波想要彻底平息下来也并不容易。</strong></p>
  <h2><strong>1、杨植麟出面回应，月之暗面的分拆是否合规？</strong></h2>
  <p>2022年年底，随着AGI（通用人工智能）的技术趋势已经形成，杨植麟开始筹备创立月之暗面。</p>
  <p><strong>对于需要抢抓时间窗口的大模型公司，速度意味着一切。</strong>一个可能存在的情况是，当时，杨植麟为了追求决策的速度，很难等到所有必要的手续都完成，再去执行再创业的想法。</p>
  <p>按照杨植麟接受腾讯新闻采访时的说法，2023年2月他开始集中做第一轮融资。如果延迟到4月，基本没机会了，“真正窗口就是一个月。”</p>
  <p>再创业后，杨植麟得到了所有董事和董事会的口头、邮件确认，同时也启动了书面协议流程。</p>
  <p>到了今年一月，其进一步得到了所有董事和董事会的书面协议，内容包括循环的占股安排、豁免杨植麟和张宇韬的全职义务、约定两家公司的合作关系等。</p>
  <p>在这件事上，杨植麟和朱啸虎所说的时间点高度吻合。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_e3ee6f1975564232afb5c33a5934a429@000000_oswg138922oswg749oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/月之暗面官网&nbsp;</p>
  <p><strong>值得注意的是，循环智能和月之暗面分拆大半年后，董事决议一直并未完成签字，直到今年1月才有了转机，因为当时月之暗面敲定了阿里的关键融资。</strong></p>
  <p>据晚点LatePost此前报道，去年底正寻求融资的月之暗面，原本计划获得小红书领投的1亿美元融资，估值达到10亿美元，但阿里入局后，直接把投前估值提高到15亿美元，小红书最后放弃领投。最终月之暗面的估值也飙升至25亿美元。</p>
  <p><strong>引发质疑的问题是，杨植麟并未得到所有股东的同意豁免书。</strong></p>
  <p>杨植麟称，当时循环智能的股东对新公司的看法并不一致，其中红杉和真格选择主导投资新公司，而金沙江、博裕、万物、靖亚、华山没有参与。</p>
  <p>据36氪报道，有知情人士表示，循环智能几位投资方迟迟未签同意豁免书的原因，很可能在于对后来在月之暗面所占的股比不满。尤其在月之暗面估值出现巨幅膨胀之后，新公司的成长性相比循环智能呈现出巨大差距。</p>
  <p><strong>并不确定的是，完备的豁免流程中，杨植麟是否需要征求所有股东的同意豁免，还是只需得到董事的签字同意。这一切还是要看循环智能公司的相关章程。</strong></p>
  <p>此外，对于月之暗面创办、分拆后发生的不少争议问题，杨植麟也并未明确回应。</p>
  <p>例如，循环董事会决议通过了月之暗面成立新公司的安排的时间，是否在月暗成立之前；在张予彤加入月之暗面、成为联创的情况下，在豁免新公司成立的董事会上代表金沙江签字又是否有效。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b4fdc6addd934eb68d5211588495aaf2@000000_oswg115121oswg1080oswg806_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/循环智能官网&nbsp;</p>
  <p>总体上，朱啸虎的指控一方面指向了月之暗面分拆的合规与否，另一方面则质疑张予彤在这场交易中是否存在隐瞒利益冲突的行为，是否损害了金沙江创投和其他投资人的利益。</p>
  <p>无论是杨植麟豁免签字的重要时刻，还是月之暗面经历至关重要的一轮融资时，张予彤作为中间人一直扮演着重要的角色。</p>
  <p>截至目前，张予彤本人尚未做出公开回应，但在过去一个月双方的讨论与回应中，她俨然成为这场风波能否落幕的关键角色。</p>
  <h2><strong>2、以联创身份加入、持有可观股份，张予彤一直在“暗渡陈仓”？</strong></h2>
  <p><strong>一直以来，张予彤与月之暗面创始团队之间存在着复杂的交往。</strong></p>
  <p>张予彤与月之暗面的核心创始团队成员，如杨植麟、张宇韬、周昕宇、吴育昕等，同为清华大学计算机系的同学。而据“暗涌Waves”报道称，张予彤的丈夫汪箴也是月之暗面的联合创始人之一，持有月之暗面的股份为0.075%。</p>
  <p>更为巧合的是，张予彤不仅在2016年参与了循环智能的早期投资，也见证了月之暗面的创办：2023年2月，张予彤凭借在小红书、深鉴科技等项目中的出色业绩，晋升为金沙江创投的主管合伙人。一个月后，月之暗面便正式成立，张予彤也成为月之暗面的天使投资人，此后促成了阿里对月之暗面的10亿美元投资。</p>
  <p>过去数年，张予彤在一定程度上推动了月之暗面的快速发展和估值飙升。</p>
  <p><strong>围绕张予彤身上的两大关键争议是，她加入月之暗面的时间点，以及所持股份的合理性。</strong></p>
  <p>关于加入时间的争议，朱啸虎认为，张予彤在金沙江创投任职期间就已加入月之暗面，并为其提供了重要的融资帮助。</p>
  <p>这意味着，张予彤的这一行为违反了其对金沙江创投的信义义务，因为她没有向金沙江创投披露其在新公司的利益冲突。</p>
  <p>这一切导致张予彤在今年4月正式被金沙江“解雇”。</p>
  <p>在最新回应中，杨植麟避重就轻地承认，其已邀请张予彤作为联合创始人加入月之暗面，但对于张予彤是何时加入月之暗面的问题，并没有正面进行回应。</p>
  <p><strong>另一方面，对于张予彤所持股份的争议，核心讨论则主要围绕两点：股份是如何授予的，股份数量是否合理。</strong></p>
  <p>根据朱啸虎透露的信息，最开始张予彤在月之暗面持有900万的免费股，占比高达初始股份14%，这一数字远超当年循环智能所分得的9.5%。</p>
  <p>接受虎嗅采访时，他又补充了一个信息——<strong>阿里那一轮融资后，张予彤又获得了300万股，因此，其在月之暗面的股份总共拥有1200万股。</strong></p>
  <p>对于股份授予和兑现的合理性，杨植麟和朱啸虎的回应，完全在表达不同的事实。</p>
  <p>杨植麟的说法是，迄今为止张予彤在业务、战略以及多场融资战役中对公司做出了重要贡献。换言之，张予彤的持股是合理的。</p>
  <p>同时，股份是按照多年兑现（vesting），兑现的条件是张予彤后续为公司提供服务及产出业绩。</p>
  <p><strong>紧接着，朱啸虎否认了这一事实，他认为张予彤是在隐瞒利益冲突的情况下获得的这些股份，属于“监守自盗”。</strong></p>
  <p>而且，股份的授予是一次性给到。他在朋友圈中写到，“900万股是第一天就给的，并不是后面陆续给的，而且不是简单的没有披露，而是设计了很多方式（代持，投很少的钱来欲盖弥彰）来隐瞒欺骗。”</p>
  <p>关于隐瞒的方式，在接受虎嗅采访时，朱啸虎详细描述了事情的经过：</p>
  <p>今年4月，朱啸虎通过相关人士看到了一份“股东结构表”，发现张予彤的配偶汪箴持有月之暗面的大量股份。</p>
  <p>随后，金沙江又发现，月之暗面的股东结构中存在一个“匿名创始人”的席位，在之前被隐瞒的融资文件里则存在一个条款——张予彤配偶汪箴的股份，需要经大家同意转移到一个“匿名创始人”名下。</p>
  <p>向对方发了三封律师函后，金沙江确认这个匿名创始人是张予彤。</p>
  <p>朱啸虎的此番炮轰异常激烈，具体透露张予彤向金沙江创投等投资人及股东隐瞒重要事实的相关细节。然而，张予彤仍然躲藏在“月之暗面”，不愿出面回应。</p>
  <p>经历了这一轮的事件曝光，循环股东们与月之暗面、张予彤之间存在的复杂矛盾和利益纠葛，最终将以何种方式达成和解，受到了更多关注。</p>
  <h2><strong>3、老股东“围堵”张予彤，月之暗面最终将如何选择？</strong></h2>
  <p>过去近一个月，循环股东们与月暗进行的和解谈判中，各方的主要诉求并不相同。</p>
  <p>在接受晚点LatePost采访时，朱啸虎透露了他所知的补偿详情——将月之暗面创始股份（总计5500万股）中的10%将作为补偿。</p>
  <p>这一条件是基于杨植麟的提议：因联合创始人张宇韬从循环智能到月暗兼职后，实际上转为全职并成为公司核心人物，月暗需要向循环智能额外提供10%的创始股份。</p>
  <p>双方达成共识后，朱啸虎曾通过社交媒体表态，称“愿意豁免Kimi（杨植麟）、张宇韬以及月之暗面公司，支持年轻人追求AGI梦想”。</p>
  <p><strong>但朱啸虎并不愿意在张予彤个人的问题上做出让步。</strong></p>
  <p>朱啸虎一直不理解杨植麟与张予彤的“绑定”——月之暗面与股东们进行和解时，一定要将张予彤的问题打包进去，让股东承诺对张予彤不再有任何追责。</p>
  <p>这也是朱啸虎持续对张予彤表达强烈不满的主要原因，他希望张予彤能够自己承认错误、承担责任并寻求和解。</p>
  <p>正因如此，和解过程中，他强调的核心诉求是：<strong>第一步，月之暗面与张予彤进行切割。第二步，金沙江及其他股东与月之暗面、杨植麟和解。第三步，对张予彤进行起诉，要求其赔偿股份。</strong></p>
  <p>究其根本，朱啸虎不愿让步的主要原因是，这涉及到了机构方的核心利益和声誉。</p>
  <p>金沙江作为循环智能的老股东，在月之暗面成立时并没有跟投。虽然金沙江作为机构的权益，已经映射在循环智能掌握的股份里，但不可否认的是，在月暗水涨船高的这两年，金沙江还是错过了估值飙升带来的资本增值机会。</p>
  <p>朱啸虎的潜台词可能是，张予彤过去的欺瞒，误导了金沙江的重要决策。</p>
  <p>但从另一个层面来看，如果张予彤确实存在隐瞒利益冲突的行为，也证明了金沙江创投在投资决策和风险管理方面确实存在漏洞，这将对金沙江创投的声誉造成一定影响。</p>
  <p><strong>无论如何，留给月之暗面和张予彤谋求进一步和解的时间已经不多了。</strong></p>
  <p>据新媒体“暗涌Waves”报道，朱啸虎曾表示，月之暗面的股东要求他们在2024年12月15日前获得循环智能老股东的豁免，否则将面临降低估值10%的惩罚。</p>
  <p>某种程度上，这场风波对月之暗面的融资和业务发展也产生了一定影响，投资人可能会对月之暗面的管理团队和公司治理结构产生疑虑，从而影响其投资决策。</p>
  <p>但令人疑惑的是，月之暗面不仅要应对来自投资方的质疑和指控，还要面临和解遇阻的困境，为何杨植麟还执着于力保张予彤？</p>
  <p>这场风波仍有不少疑团有待揭晓，未来一段时间，围绕月之暗面的争端与纠纷，还将继续下去。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkzMDMxNTk2NA==&amp;mid=2247491042&amp;idx=1&amp;sn=26c3eb0e19e14b06de392380c400e7c4&amp;chksm=c3d124c367cf2de9a9836f4a8815ed39bbe3910620af740874d84d91db569113fcee0e9262f0&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“一刻商业”（ID：yikecaijing）</a>，作者：麦卡，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072812279804804</id>
            <title>生数、智谱、智源谈Sora：模型在预期之内，产品才是亮点</title>
            <link>https://www.36kr.com/p/3072812279804804</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072812279804804</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 09:36:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 视频生成, OpenAI, 人工智能  
<br><br>  
总结: Sora是OpenAI推出的视频生成模型，被称为视频版的GPT-1。尽管Sora在视频编辑能力上有亮点，但其基础模型能力表现平平，生成速度较慢且成本高。业内专家对Sora的评价存在分歧，有人认为其效果不及预期，国内已有类似技术不逊色于Sora。Sora的发布标志着OpenAI从模型公司向产品公司转型，强调用户需求和产品设计。Sora的多种视频生成模式和高级编辑功能旨在增强用户的创造力，但仍存在物理理解不足的问题。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_94eb5c37e154480a967567231dcbc31e@46958_oswg884739oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Sora只是GPT-1。&nbsp;</p>
  <p>今天是OpenAI科技“马拉松”的第三天——鸽了近一年的Sora终于上线！</p>
  <p>场面之火爆，Sora Turbo一经发布服务器就被挤爆了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_e7ecd55ef94242d491f6059fc1f9075d@46958_oswg38857oswg890oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>很多视频case已经在网上传播。对于Sora真实的“买家秀”效果，口碑评价出现了两极分化。有人认为，Sora代表了视频生成的最强水平。但也有人认为，Sora的表现并不及预期。</p>
  <p>在今天举办的2024甲子引力年终盛典上，清华大学人工智能研究院副院长、生数科技首席科学家朱军，智谱CEO张鹏，以及北京智源人工智能研究院院长王仲远第一时间对Sora进行了评价。</p>
  <p>朱军认为，Sora正式上线所带来的冲击度，相比今年二月的首次发布已经弱了很多。视频生成模型在今年有了长足的发展，已经完全不是Sora二月份刚发布时的阶段。整体来说，Sora的发布有一些产品上亮点，尤其是视频编辑的能力。但在基础模型能力的表现上其实没有太多的亮点，效果在预期之内，比如Sora的生成速度看上去还是挺长的，大概在分钟级，而且成本也不低，这都可能会影响后续用户的使用以及商业化的进展。&nbsp;</p>
  <p>张鹏表示：“Sora的效果离自己的预期有一点偏差。如果看技术指标，国内有的视频生成模型不比Sora差。”比如智谱发布的视频生成模型产品清影，已经可以支持生成4K分辨率的视频了。</p>
  <p>当然视频模型的比拼肯定不是简单地对比参数，而是如何产生实际的应用、产生生产力。张鹏认为，Sora这次发布把很大的精力放在了产品而非模型上，比如视频编辑能力、工作流，这是面向用户需求的转变。</p>
  <p>王仲远认为Sora的上线基本符合预期，没有年初发布时的惊艳效果。从产品上线时间来看，国内公司也实际上已经早于OpenAI做出了产品级的模型。今年智源发布的新模型Emu3也探索了下一代的技术路线，是一个包括文本、图片、视频在内的原生多模态统一理解和生成模型。</p>
  <p>从官网的介绍到用户的体验，总体看下来「甲子光年」最大的感受是<strong>OpenAI已经不仅仅是一个模型公司，而是进化为产品公司。Sora Turbo的亮点更偏重视频编辑的产品设计。</strong></p>
  <p>OpenAI在今年显然加强了产品层的投入。比如今年6月，前Instagram产品副总裁以及Twitter产品副总裁Kevin Weil加入OpenAI，担任首席产品官。</p>
  <p>人们经常问AI时代的Killer App是什么？今天来看，“Sora+ChatGPT”或许就是最被忽略的killer app。</p>
  <h2><strong>1.视频版的GPT-1</strong></h2>
  <p>北京时间12月10日凌晨，OpenAI CEO 萨姆·奥尔特曼（Sam Altman）与Sora团队负责人比尔·皮布尔斯（Bill Peebles）、阿迪亚·拉梅什（Aditya Ramesh）一起进行了20分钟关于Sora的讲解直播。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8b758a51c36b46958b0a31906730e6cc@46958_oswg530472oswg1080oswg595_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>奥尔特曼在直播中将Sora称之为视频版的GPT-1，Sora是DALL·E和GPT模型的基础上创建的。</p>
  <p>Sora采用了扩散模型（Diffusion Model），通过从初始“噪声”中生成基础视频，并逐步去噪以生成高质量画面。这一过程依托Transformer架构，能够一次性预测多个帧，确保画面中主体的连续性，即使主体暂时脱离视野，也能保持一致。</p>
  <p>此外Sora继承了DALL·E 3的重新字幕技术（Re-captioning），为视觉训练数据生成详细的描述性字幕，增强了对用户文本指令的忠实呈现能力。</p>
  <p>Sora的训练数据集来自多种来源，包括：</p>
  <blockquote>
   <p><strong>公开数据集（Public Datasets）</strong>：来自行业标准机器学习数据集及网络爬虫的数据。</p>
   <p><strong>专有数据（Proprietary Data）</strong>：通过合作伙伴获取的非公开数据，例如与Shutterstock、Pond5的合作。&nbsp;</p>
   <p><strong>人工生成数据（Human-Generated Data）</strong>：由AI培训师和红队成员提供的反馈。</p>
  </blockquote>
  <p>奥尔特曼表示Sora Turbo开启了AI模拟现实与交互的全新篇章。作为Sora的全新升级版本，它提供了多种视频比例选项，包括横屏（16:9）、正方形（1:1）和竖屏（9:16），适应不同的显示需求和创意表达。同时Sora Turbo引入了多种高级编辑功能：&nbsp;</p>
  <blockquote>
   <p><strong>Remix（重混）</strong>：用户可以替换、删除或重构视频中的元素；&nbsp;</p>
   <p><strong>Re-cut（重新切割）</strong>：用户可以寻找视频中的最佳帧，并从此延展或循环剪辑；&nbsp;</p>
   <p><strong>混合</strong>：Sora Turbo可以将两个视频片段进行无缝合并；&nbsp;</p>
   <p><strong>故事板剪辑</strong>：精确地指定每个帧的输入，精确叙事控制，将照片转化为视频；&nbsp;</p>
   <p><strong>风格预设</strong>：用户可以选择预设的风格来创建视频，速设定视频的视觉风格。&nbsp;</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b862f8391c1941e3b62be508e0e0ae78@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Sora Turbo的效果展示</p>
  <p>Sora有三种视频生成模式：&nbsp;</p>
  <blockquote>
   <p><strong>文本到视频（Text-to-Video）模式：</strong>Sora的核心功能，可以让用户通过输入文本描述来生成完整的视频。利用先进的自然语言处理技术和生成模型，Sora能够理解文本的含义，并将其转化为具象的视觉内容。这一模式适用于制作从简短的短片到情节丰富的叙事视频。</p>
   <p><strong>文本+图像到视频（Text+Image-to-Video）模式：</strong>在这个模式中，用户不仅可以输入文本描述，还可以上传图像来增强视频生成的精确性。通过结合文本和图像，Sora可以更准确地捕捉并实现创作者的创意意图，生成更符合视觉期望的视频。这一功能尤其适用于需要在视频中整合特定图像元素的应用场景，例如广告制作和产品展示。&nbsp;</p>
   <p><strong>文本+视频到视频（Text+Video-to-Video）模式：</strong>Sora还提供了视频编辑和转换功能，允许用户上传已有视频素材，并结合文本描述进行修改或扩展。这一模式使用户能够在现有视频的基础上添加新的情节、细节，甚至创作出全新的版本或完全不同的内容。例如，用户可以对现有的广告视频进行重新编辑，加入新的对话、场景或动画效果。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ae5f0404fcba4f0f99a2687326aee8e2@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Sora Turbo的效果展示</p>
  <p>“我们希望通过Sora项目构建能真正理解世界及物理（原理）的AI系统。我们才刚起步，Sora早期版本并不完美，偶尔有错误，但它现在已经能做到真正增强人类的创造力了。”皮布尔斯说道。&nbsp;</p>
  <p>o1模型的核心贡献者之一、OpenAI的研究科学家诺姆·布朗（Noam Brown）称赞Sora是scale力量的最直观展示。OpenAI的研究员威尔·德普（Will DePue）也在社交媒体上表示：“我们付出了巨大的努力才实现这一目标，Sora是非常直接和有趣的产品。”&nbsp;</p>
  <p>ChatGPT Plus/Pro用户可直接用Sora Turbo生成视频。ChatGPT Pro计划的用户每月可生成500个视频，时长最长可达20秒，最大分辨率为1080p；ChatGPT Plus用户每月可以生成50个视频，最大分辨率为720p，最长时长为5秒。&nbsp;</p>
  <p>在推广Sora Turbo的同时，OpenAI对于技术的安全性和伦理使用也非常重视。他们对模型内置了多项安全措施，例如加入C2PA元数据确保视频的透明度，并验证视频的来源。同时OpenAI还设立了红队测试，这些测试由信息误导、仇恨内容和偏见等领域的专家进行。&nbsp;</p>
  <p>“在过去的九个月中，我们观察了来自60多个国家/地区300多名用户的500000多个模型请求的用户反馈。这些数据有助于增强模型行为并提高模型对安全协议的遵守程度。”OpenAI在文章中写道。&nbsp;</p>
  <h2><strong>2.Sora并不完美</strong></h2>
  <p>Youtube科技评测网红马克斯·基思·布朗利（Marques Brownlee，网名MKBHD）也对Sora进行了深度评测。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_969ba8ed339044d7b9910bffd2fcfc64@46958_oswg66020oswg1080oswg640_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">布朗利的评测视频，来源：Youtube</p>
  <p>布朗利发现Sora擅长粒子和流体模拟，“令人惊讶的是，Sora对流体动力学的处理相当出色，水的波动和火焰的效果往往能达到令人信服的程度，即使烟雾效果可能还不够完美”。但他同时也认为，Sora完全不懂物理。&nbsp;</p>
  <p>从官方展示的视频也可以看出，Sora对“运动”的理解还不全面，有时甚至错误百出。比如在一个猴子轮滑的的视频中，可在看到猴子的右腿“毫无防备”地变成了左腿。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b7e679f49e1e4772935c9f435830a9ab@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以及在提示词为“rockefeller center is overrun by golden retrievers! everywhere you look, there are golden retrievers.”的视频中，金毛猎犬的数量模糊，每个个体的形状不稳，又时隐时现，比如有的脑袋突然变成了尾巴。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_039b44893fa64c4c91820681a8df372d@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于这些不足，OpenAI表示：“Sora是一款强大的工具，使你能够跨越物理限制，在多个场景中同时发挥创造力，探索各种全新的可能性。更重要的是，我们认为它极大地扩展了幕后创作者的创作空间，赋予他们前所未有的能力去实现创意。”&nbsp;</p>
  <p>直播最后，Sora团队也“泼了一盆冷水”来控制用户预期：“如果你带着这样的期望来到 Sora，认为只需点击一个按钮就能生成一部故事片，那么你可能抱有错误的期望。”&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/jrDIGqCVmLLCgDFdNB5wxA" rel="noopener noreferrer nofollow" target="_blank">“甲子光年”</a>，作者：苏霍伊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072746984043137</id>
            <title>AI视频边生成边播放，首帧延迟仅1.3秒，生成速度9.4帧/秒：Adobe&amp;MIT新研究</title>
            <link>https://www.36kr.com/p/3072746984043137</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072746984043137</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 09:26:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI生成视频, 实时播放, 自回归生成模型, 蒸馏预训练  
<br><br>  
总结: Adobe与MIT联合推出的CausVid技术实现了AI生成视频的实时播放，显著减少了生成延迟和提升了生成速度。该技术通过蒸馏预训练的双向扩散模型构建自回归生成模型，解决了传统视频生成模型的误差累积问题。实验结果显示，CausVid的首帧生成延迟从3.5分钟降至1.3秒，生成速度提升至9.4帧/秒，且生成质量优于现有主流模型。CausVid支持多种应用，包括图片动画化、实时视频风格转换和交互式剧情生成。 </div>
                        <hr>
                    
                    <p>AI生成视频，<strong>边生成边实时播放</strong>，再不用等了！</p>
  <p>Adobe与MIT联手推出自回归实时视频生成技术——<strong>CausVid</strong>。</p>
  <p>思路<strong>就像从下载整部电影到直接观看流媒体的转变</strong>，在模型生成首帧画面后，视频便可以即时播放，后续内容则动态生成并无缝衔接。</p>
  <p>如果你用过视频生成模型，一定对漫长的等待时间记忆深刻，生成一段10秒的视频，往往需要等待好几分钟才可以开始观看。</p>
  <p>研究团队表示，这一延迟的根本原因在于：<strong>传统视频生成模型普遍采用的双向注意力机制，每一帧都需要参考前后帧的信息。</strong></p>
  <p>这就像写故事时必须先构思好整个剧情的所有细节才能动笔，在完整视频生成完毕前，你看不到任何画面。</p>
  <p>为此，他们提出了一种全新的解决方案，通过<strong>蒸馏预训练的双向扩散模型</strong>（DiT），<strong>构建自回归生成模型</strong>。</p>
  <p>实验中，CausVid基于自回归生成的特性，无需额外训练就能支持多种应用，生成速度和质量均显著超越现有方法。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_416019dff65f4a479c83c711539404ac@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究团队还表示将很快开源基于开源模型的实现代码。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_f808d695c4f444b3bc39546cd2501c75@46958_oswg32496oswg1080oswg257_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>用双向教师监督单向自回归学生模型</strong></h2>
  <p>如前所述，研究团队通过蒸馏预训练的双向扩散模型（DiT），构建自回归生成模型。</p>
  <p>为了进一步提速实现实时视频生成，作者通过<strong>分布匹配蒸馏</strong>（DMD）将生成步骤从50步缩减到仅需4步。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_076809ce01004458b7ee37a109b0f27e@46958_oswg604163oswg1080oswg394_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DMD是一种扩散模型蒸馏技术，将多步扩散模型转换为快速的单步生成器。DMD此前已在图像生成中取得成功，Adobe Firefly文生图的快速模式就是基于此技术。</p>
  <p>本次研究团队将其创新性地应用到视频扩散模型中，实现了显著加速。</p>
  <p>然而，自回归模型有一个核心难题——<strong>误差累积</strong>。</p>
  <p>每一帧视频都基于之前的帧生成，早期生成的任何细微缺陷都会被放大，导致生成的视频逐渐偏离预期轨迹。</p>
  <p>为了解决这一问题，团队提出了<strong>非对称蒸馏策略</strong>。具体来说：</p>
  <p>引入一个拥有未来信息的双向教师模型，在蒸馏训练阶段指导自回归的单向学生模型。这种教师-学生结构允许模型在生成未来帧时具备更强的精确度。</p>
  <p>使用双向教师模型生成的的噪声-数据配对来预训练单向学生模型，提升其后蒸馏训练过程的稳定性。</p>
  <p>在训练过程中，针对不同时间点的视频帧施加不同强度的噪声，这一策略使模型能够在测试时基于干净的已生成帧对当前帧进行去噪。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ffdf77f4186747899f37455928194d2e@46958_oswg77184oswg1080oswg512_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>通过这种创新性的非对称蒸馏方法，CausVid显著减少了自回归模型的误差累积问题，并生成了更高质量的视频内容。</p>
  <p>这种非对称蒸馏形式中，学生模型和教师模型使用了不同的架构，而这只有在DMD风格的蒸馏中才可行。其他方法，例如渐进式蒸馏（Progressive Distillation）或一致性模型（Consistency Distillation），都要求学生模型和教师模型使用相同的架构。</p>
  <p>下面是自回归扩散视频模型的误差累积示例（左图）和CausVid结果（右图）对比：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_6060044620cb4d1eb27681fda22c7813@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>实验效果如何？</strong></h2>
  <p>实验中，CausVid表现惊艳：</p>
  <p>首帧生成延迟从3.5分钟降至1.3秒，提速170倍</p>
  <p>生成速度从0.6帧/秒提升至9.4帧/秒，提升16倍</p>
  <p>生成质量经VBench和用户调查验证，优于主流模型例如Meta的MovieGen和智谱的CogVideoX</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_f5b78fbbffe44106b5f383ba296b374d@46958_oswg242513oswg1080oswg421_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>得益于单向注意力机制，CausVid完全支持在大语言模型中广泛应用的<strong>KV缓存推理</strong>技术，从而显著提升了生成效率。结合<strong>滑动窗口机制</strong>，CausVid突破了传统模型的长度限制。</p>
  <p>尽管训练阶段仅接触过10秒的视频，CausVid依然能够生成长达30秒甚至更长的视频，其生成速度和质量均显著超越现有方法。</p>
  <p>基于自回归生成的特性，CausVid无需额外训练就能支持多种应用：</p>
  <p><strong>图片动画化</strong>：将静态图片自然转化为流畅视频，赋予画面生命力。</p>
  <p><strong>实时视频风格转换</strong>：如将Minecraft游戏画面即时转换为真实场景。这一技术为游戏渲染带来全新思路：未来可能只需渲染基础3D几何信息，由AI实时补充纹理和光影</p>
  <p><strong>交互式剧情生成</strong>：用户通过调整提示词，实时引导视频剧情发展，带来全新的创作体验。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_75c2689ebcd4426fb9f6f1d90fc6a15a@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>项目链接：https://causvid.github.io/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/URFPaWWjIyWvwcJODDKK1A" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：CausVid团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072822242997120</id>
            <title>2024中国生成式AI大会上海站圆满收官，第二日AI Infra峰会演讲精华一文看尽！</title>
            <link>https://www.36kr.com/p/3072822242997120</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072822242997120</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 09:21:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 大模型, AI Infra, 产业合作  
<br>
<br>
总结: 2024中国生成式AI大会在上海成功举办，吸引了超过1200位观众和4000人报名咨询。大会以“智能跃进 创造无限”为主题，51位嘉宾分享了生成式AI的技术创新、商业应用和未来趋势。与会者讨论了AI基础设施的挑战与机遇，强调了算力、数据和算法在AI发展中的重要性。多位专家提出了针对大模型算力瓶颈、国产芯片应用和向量数据库等问题的解决方案。大会还探讨了生成式AI在企业智能化转型中的应用潜力，呼吁全产业链的合作与共赢。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_68ff47d3a60d41ddb802b7caec8443dc@5868219_oswg602346oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>智东西12月6日报道，为期两天的2024中国生成式AI大会（上海站）今日圆满收官。</p>
  <p>两天内，<strong>51位</strong>产学研投嘉宾代表密集输出干货爆棚，大会报名咨询人数超<strong>4000人，</strong>超过<strong>1200位</strong>观众到场参会。其中，在主会场进行的大模型峰会、AI Infra峰会的线上观看人次更是超过<strong>104万。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_1175ad89c1614ef38abe550cc0cc7455@5868219_oswg237342oswg1000oswg663_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>现场参会观众们的热情十分高涨，主会场、分会场座无虚席，展览区附近的产业交流也十分活跃，<strong>15家</strong>企业的诸多新产品新技术都引起了广泛关注和讨论。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_e2a4adb81a944269a77a71d94606e441@5868219_oswg111983oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲大会展区</p>
  <p>此次大会以<strong>“智能跃进 创造无限”</strong>为主题，51位产学研投嘉宾代表基于前瞻性视角解构和把脉生成式AI的技术产品创新、商业落地解法、未来趋势走向与前沿研究焦点。</p>
  <p>今天的<strong>AI Infra峰会</strong>上，上海交通大学副教授、无问芯穹联合创始人兼首席科学家戴国浩认为，业界更应该关注单位算力如何实现更高效的token吞吐，大模型实际可用算力不仅取决于芯片理论算力，还可通过软硬协同优化提高算力利用效率，通过多元异构适配放大整体算力规模。</p>
  <p>北电数智智算云负责人郭文，GMI Cloud亚太区总裁King.Cui，阿里云智算集群产品解决方案负责人丛培岩，中昊芯英芯片软件栈负责人朱国梁，光羽芯辰创始人兼董事长周强分别对全栈AI工厂、AI企业出海如何补齐算力短板、高性能智算集群、国产TPU芯片“No CUDA”软件栈、通向个人大模型之路几个主题进行了分享。</p>
  <p>枫清科技创始人兼CEO高雪峰，声网生成式AI产品负责人毛玉杰，腾讯云向量数据库技术负责人谢宇，Jina AI联合创始人兼首席技术官王楠，Zilliz合伙人、研发VP栾小凡，英飞流创始人兼CEO张颖峰，Alluxio首席架构师傅正佳分别针对“从数据到知识：AI重塑百行千业的基石”、“生成式AI驱动实时互动的技术变革与体验革新”、“TencentVDB向量数据库”、“RAG范式下AI Infra的机遇和挑战”、“RAG虽强，但向量数据库绝非万灵药”、“新一代企业级多模态RAG引擎”、“高性能AI数据底座”带来了精彩演讲。</p>
  <p><strong>下午场的圆桌讨论聚焦“大模型行至深水区，AI Infra的新变化与新机会”，</strong>由德联资本执行董事刘景媛主持，Alluxio首席架构师傅正佳，Zilliz合伙人、研发VP栾小凡，英飞流创始人兼CEO张颖峰三位嘉宾给出了自己的真知灼见。</p>
  <p>大会首日，17位嘉宾畅谈大语言模型、多模态大模型、具身智能、AI原生应用、音乐生成、3D AIGC、AI智能体的行业应用、垂类行业大模型等前沿议题。</p>
  <p>除了大会首日主会场进行的大模型峰会，以及今天主会场的AI Infra峰会，大会分会场也在这两天分别组织了端侧生成式AI技术研讨会、AI视频生成技术研讨会与具身智能技术研讨会，17位青年学者和技术专家带来了报告分享，后续将会上架这三场收费制研讨会的回放。</p>
  <h2>一、从智算集群到原生加速技术栈，聚焦产业落地痛点突破大模型算力瓶颈</h2>
  <p>AI的发展带来了巨大的数据、算力以及能源挑战，作为支撑大模型运行以及生成式AI应用开发的关键，AI Infra也走到了台前，发展势头强劲。</p>
  <p>如何打造优质的智算中心，如何实现AI从芯片到应用端全产业链的高效协同？多位嘉宾给出了自己的深入见解。</p>
  <p><strong>1、上海交通大学副教授、无问芯穹联合创始人兼首席科学家戴国浩</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_c10fc302d58b410d87b41acec57dc218@5868219_oswg76477oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Scaling Law之下，数据成为制约AI继续发展的因素之一。以GPT-o1为代表的推理模型可以突破数据瓶颈，但计算范式的转变使算力需求呈指数级增长，可能导致硬件系统能耗开销供不应求，对行业的可持续发展构成挑战。</p>
  <p>对此，戴国浩教授指出，当下业界更应该关注单位算力如何实现更高效的token吞吐，让大模型的实际可用算力不仅取决于芯片理论算力，还可通过软硬协同优化提高算力利用效率，并通过多元异构适配放大整体算力规模。他分享了其研究团队在软硬协同、多元异构与端侧智能方面的研究进展与落地成果，这些成果能助力行业提升面向大模型场景的token吞吐效率。</p>
  <p><strong>2、北电数智郭文：以AI工厂填补国产算力供给侧与需求侧的产业链断层</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_5409ba757a064822bb06476ce3a4d965@5868219_oswg61198oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>“产业要发展，创新不能只是停留在技术层面，更要从流程、系统和组织进行全面的创新。”北电数智智算云负责人郭文分享了从算力、算法、数据与生态方面全面构建人工智能时代AI生产线的实践思考。</p>
  <p>郭文称，当下国产芯片落地人工智能产业的最大问题是，算力供给侧与需求侧之间存在产业链断层。为此，北电数智推出首个“国产算力PoC平台”，以北京数字经济算力中心为载体打造具备全栈能力的AI工厂，全线适配与拉通场景、模型到芯片层面，推动智算中心从成本中心转化为推动地区发展新质生产力中心。</p>
  <p><strong>3、GMI Clould King.Cui：高稳定GPU集群成AI企业全球化布局关键</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_114dfe42d2304ef9b543fbc4fb725606@5868219_oswg63489oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>中国AI出海加速，算力作为其中的核心生产资料正发挥重要作用。高稳定性的GPU集群能降本增效，帮助企业在AI全球化浪潮中取胜。</p>
  <p>GMI Cloud亚太区总裁King.Cui提到，为确保GPU集群的高稳定性，他们使用了具备主动检测功能的自研云集群引擎，实现计算、存储和网络资源的高效调配。</p>
  <p>GMI Cloud是NVIDIA Top10 NCP，交付前会进行严格的验证流程。GMI Cloud与IDC协作，提供备件和维修，拥有更短的交付时间，确保停机时间最小化。</p>
  <p><strong>4、阿里云丛培岩：灵骏智算集群不仅要实现稳定性和极致性能，更要在不同维度支持规模的极致扩展</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_30907b035b384c10880158201061bc91@5868219_oswg76189oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>阿里云智算集群产品解决方案负责人丛培岩预测，未来模型性能还会随参数，数据集和算力的增长继续提升，Scaling Law仍有增长空间，AI智算集群的设计范式转向要以GPU为核心。</p>
  <p>阿里云推出支持超大规模分布式训练的灵骏智算集群，可达到10万卡扩展规模，千卡规模线性加速比达到96%；阿里云自研磐久服务器采用CPU和GPU分离，实现单机提升至16颗GPU；网络架构HPN7.0最大规模可连接10万颗GPU。</p>
  <p>智算集群稳定性至关重要，阿里云3千卡规模智算集群，在一个月内稳定训练时长占比达99%。</p>
  <p><strong>5、光羽芯辰周强：解决“大模型不懂你”问题，个人大模型迎来机遇</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b3170eb6db834b95882a38ecdce7ea87@5868219_oswg65212oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为与通用大模型、行业大模型、企业大模型并行发展的一大分支，个人大模型也进入了快速发展期。光羽芯辰创始人兼董事长周强称，个人大模型解决的是“大模型不懂你”的问题，随着手机、PC、可穿戴、XR等端侧设备厂商All in AI，个人大模型之路将越走越宽。</p>
  <p>他提到，个人大模型也称为端侧大模型，期待解决端侧智能体在性能、功耗和成本方面的痛点，让真正的AI手机走进生活。端侧AI具备及时性、可靠性、成本低、隐私保护和定制化五大优势。目前，构建端侧大模型的核心是解决存储带宽和容量双重问题。</p>
  <p><strong>6、中昊芯英朱国梁：国产TPU芯片“No CUDA”软件栈的构建实践</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_63e5b7158c4d4f8bbfbef3a7558e2a25@5868219_oswg67551oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>中昊芯英芯片软件栈负责人朱国梁介绍了他们在为国产TPU芯片构建“No CUDA”软件栈的实践经验。</p>
  <p>中昊芯英刹那芯片采用VLIW指令集架构，面对庞大的CUDA生态，他们逐一解决了库、并行计算与编程方面的问题，全自研用户态和内核态驱动，实现了芯片的高效管理。</p>
  <p>为做好生态兼容，中昊芯英底层软件栈兼容PyTorch以及所有主流训推框架，目前，中昊芯英可提供定制的端到端的云智算解决方案，并支持国产操作系统。</p>
  <h2>二、从企业智能体、向量数据库到RAG，AI Infra基础软件涌现诸多新挑战</h2>
  <p>下午场，多位嘉宾进一步分享了AI Infra领域关于智能体开发管理平台、实时语音、向量数据库、向量模型、RAG技术、数据编排等方面的行业观察和深入见解。诸多新平台、新产品、新技术走向前台，赋能产业。</p>
  <p><strong>1、枫清科技高雪峰：从数据到知识，跨越生成式AI与决策智能间的鸿沟</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8ed58a41a6844020b3f67e9512fafd89@5868219_oswg114763oswg1000oswg665_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>枫清科技创始人兼CEO高雪峰谈道，要将生成式AI真正应用到企业决策场景中，弥合其与决策智能之间鸿沟的技术突破点，就是在推理框架侧融合符号逻辑推理。</p>
  <p>企业智能化落地需要面临数据孤岛、数据整合、知识校验、数据实时效等技术挑战。枫清科技可以为企业提供知识引擎与大模型双轮驱动的新一代智能体平台，通过构建全链路优化体系，帮助企业提升数据质量，将企业本地数据知识化，并融合大模型沉淀的泛化能力，在知识网络之上进行符号逻辑推理，实现可解释的智能，进而使AI在多个场景下能够实现精准、透明的决策支持，推动企业智能化转型的顺利实施。</p>
  <p><strong>2、声网毛玉杰：生成式AI+实时互动，让人机交互变成真正的心灵交互</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_63f06c7e3fef4efcb66b7b8973e8a9f5@5868219_oswg75907oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>声网生成式AI产品负责人毛玉杰讲述了生成式AI出现后实时互动（RTE，Real-Time Engagement）技术和体验的变迁。</p>
  <p>毛玉杰介绍，2014年至今十年，RTE从服务质量走向体验质量；2025年开始，在生成式AI发展的背景下，RTE向AI RTE变革，开始注重跨模态体验质量，做多模态交互、跨模态转换，为人和模型而设计，给大模型厂商提供眼睛、耳朵和声音能力。</p>
  <p>毛玉杰说，目前人机对话已经达到“听得懂”的状态，期待下一步实现“听得心”——让人机交互变成真正的心灵交互。</p>
  <p><strong>3、腾讯云谢宇：向量数据库助力企业挖掘更大数据价值</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_f3c69cd2f2ea48329d77b360599a1f06@5868219_oswg94942oswg1000oswg665_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>AI时代，向量数据库（VDB）脱颖而出，成为连接结构化与非结构化数据的枢纽。然而，当VDB被运用于RAG场景时，多款开源RAG架构出现了召回率低的问题。</p>
  <p>腾讯云向量数据库技术负责人谢宇介绍，为解决上述挑战，腾讯首先提升了复杂文档的识别效果，并对数据处理、Embedding、检索、总结等其他环节进行优化，最终实现了90%以上的召回率。</p>
  <p>腾讯自研向量检索引擎OLAMA已上线5年，日均处理8500亿次检索请求。未来，他们还将在性能、成本、业务效果、容灾率等方面发力，持续提升产品表现。</p>
  <p><strong>4、Jina AI王楠：长文本大模型、RAG长期共存，长窗口向量模型面临两大挑战</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_46496198136a4237a2e2acf382e57d7d@5868219_oswg53953oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>大模型存在幻觉、无法保证私有数据安全、推理成本高三大问题，Jina AI联合创始人兼首席技术官王楠认为，RAG正是通过缩小大模型生成范围，保证检索准确性、实现结果可溯源，所以长本文大模型不会取代RAG，二者将长期共存。</p>
  <p>短窗口会导致上下文背景信息丢失，因此RAG需要长窗口向量模型支持。但长窗口向量模型面临两大挑战，一是推理成本和内存消耗会随窗口长度呈平方线性增长，共享GPU是解决思路之一；二是长窗口使模型无法完整表示细颗粒度语义，解法是增加向量维度和多向量表示。</p>
  <p><strong>5、Zilliz栾小凡：向量数据库落地面临成本及扩展性挑战，RAG转为Graph RAG</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_1e78d9c196674ec3810f4dc9e0f6940b@5868219_oswg76529oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Zilliz合伙人、研发VP栾小凡分享了向量数据库目前面临的挑战以及相应解决方案。</p>
  <p>栾小凡称，2025年新生成的数据中，将会有80%以上是非结构化数据。在这一数据压力下，向量数据库的落地面临着成本以及扩展性等方面的种种挑战。而目前的RAG存在搜索质量难、处理长尾查询能力差、结果难以解释和控制、向量存储成本高等问题。</p>
  <p>据此，栾小凡及其团队提出了两个解决思路：一是混合查询，在单个系统内支持密集嵌入、稀疏嵌入和词汇搜索；二是Graph RAG，将知识图谱和向量检索结合起来。</p>
  <p><strong>6、英飞流张颖峰：多模态RAG新范式</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a3ecee8e475949a0a7a8ba9e9f0a676a@5868219_oswg80074oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英飞流创始人兼CEO张颖峰认为，RAG作为LLM时代的数据库，目前面临着三大挑战——多模态文档处理、检索、语义鸿沟。</p>
  <p>针对第一个问题，英飞流训练了深度文档理解模型，能对复杂文档中的多模态内容进行分类处理。而在检索这一RAG“最后一公里”的问题上，英飞流使用三路召回方案，并增加张量索引进行重排序，这一方案在多模态RAG上展现出明显优势。</p>
  <p>最后，针对检索过程中的语义鸿沟，英飞流使用GraphRAG抽取知识图谱，并与原数据进行联合检索，提升检索质量。</p>
  <p><strong>7、Alluxio傅正佳：零改造、无侵入策略，打造高性能AI数据底座</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_6809e93221bb4bb09a266a89ddc193e2@5868219_oswg91759oswg1000oswg665_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Alluxio首席架构师傅正佳谈到了提升大规模模型训练效率的两大挑战：一是数据规模不断增长、类型更多元化，因此处理数据需要提升算力有效利用率；二是当数据喂到训练平台上，数据IO访问瓶颈会导致算力处于低利用率状态。</p>
  <p>这一背景下，Alluxio提供了统一的数据视图、丰富协议转化、高性能数据访问，以打造整体数据服务。其方案通过零改造、无侵入策略，可以使算法工程师仍按原有方式工作，无需改变已有脚本，并且客户已经有的大量存量数据不需要进行私有化协议改造。</p>
  <h2>三、AI 2.0时代，大模型行至深水区，AI Infra迎来变革</h2>
  <p>在圆桌论坛环节，几位嘉宾分享了对于“大模型行至深水区，AI Infra的新变化与新机会”这一主题的行业洞察，以及各自公司的产品和技术是如何解决AI应用中的核心痛点的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_562482fb2c4744e583016feabff57d09@5868219_oswg99560oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为主持人的德联资本执行董事刘景媛提到，两年前，ChatGPT将生成式AI推到台前，迎来AI 2.0时代，Scaling Law和数据量的大规模增长给AI Infra带来了非常大的增量机会。两年后的今天大模型行至深水区，AI Infra在帮助大模型及相关产品的落地的过程中，产品边界和功能需求逐渐明晰。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_73a7fceeef80481fb088514c7230c153@5868219_oswg46897oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲刘景媛</p>
  <p>对于Infra这类研发周期长、工程复杂程度高的软件产品，开源社区或许可以贡献一些能量，使产品迭代及技术选型更贴合实际需求，同时提升项目本身的关注度和影响力。</p>
  <p>另外，“go global”也几乎成为Infra软件的必选项，一方面有商业的考量，另外中国工程师的勤奋和工程攻坚能力全球有目共睹。值得关注的是，在资源有限的情况下也要做好取舍（无论是功能方面还是业务模式方面）。</p>
  <p>Zilliz作为向量数据库企业，其产品可以处理大体量非结构化数据，挖掘数据价值。对AI 2.0时代的需求变化，Zilliz合伙人、研发VP栾小凡认为，AI技术在去年被高估、今年被低估，往后看AI落地还需要等一个机会，这也是整个范式的发展机会。</p>
  <p>谈到开源，栾小凡感慨道，Zilliz目前正处于最具挑战的阶段，一方面要让产品满足客户需求，另一方面要让产品变现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_059ea90e8faa495fad4f2bda1ae897a5@5868219_oswg45279oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲栾小凡</p>
  <p>当下，AI Infra公司出海已经成为必答题。栾小凡认为出海的前提条件就是产品要有先发优势，在扩展性、功能等方面碾压竞品。产品定制方面，栾小凡的观点是Zilliz几乎不做定制。原因在于其所处的赛道已经足够大，没有必要执着于将自己打造成大而全的平台。</p>
  <p>AI时代，数据量的暴增对存储提出巨大挑战。Alluxio首席架构师傅正佳介绍，他们通过分布式数据编排软件系统，高效连接存储与计算。Alluxio很早就注意到存算分离的趋势，并在数据远程访问环节重点发力，回应了AI存储挑战。</p>
  <p>Alluxio的存储系统兼具开闭源版本，傅正佳认为开源帮助他们保持了与技术前沿的同步，也打出了知名度，但他们也面临着商业化和部分开源用户贡献程度低的问题。Alluxio目前正积极出海，傅正佳分享，海内外团队的优势互补与产品的本地化是其中的关键。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_d56ca006f77e48a8bede3b91e83fee58@5868219_oswg59874oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲傅正佳</p>
  <p>英飞流创始人兼CEO张颖峰称，RAG用起来很容易，但做好非常困难。公司能做成RAG的核心在于，把做系统的人和做AI的人融合在了一起去做产品。</p>
  <p>谈及开源，张颖峰说，开源是商业化的一种策略，而不是为了开源而开源；为了出海必须开源，但创业第一天就要想明白产品企业版和开发者版之间的区别。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_bdb0277441ea448ebbfb5e71bcc3e591@5868219_oswg43490oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲张颖峰</p>
  <p>目前英飞流的Infra产品还没有进入商业化阶段，结合过往创业经历，张颖峰称，商业化过程中，创始人必须对每个产品的特性和定制化的边界有非常清晰的认识。</p>
  <h2>结语：生成式AI产业化落地加速，上中下游全产业链呼唤合作共赢</h2>
  <p>过去一年，生成式AI的发展度过了波澜壮阔的一年，整个产业链成为全球创新、投资和应用最活跃的领域之一，每位参与者都在与时间赛跑。</p>
  <p>Sora掀起视频生成热潮，多模态世界模型的研究热度渐起。更具革命性的推理模型o1悄然出世，基座大语言模型不再持续狂飙，不仅价格战、营销战硝烟燃起，融资热度降温，Scaling Law是否撞墙更是在年底引发热议。</p>
  <p>行业赋能持续进行，包括智能体在内的应用层的兴起仍然备受期待。同时，大模型向边端下沉的趋势日趋明显，AI手机、AI PC等AI硬件纷纷站上风口。不止AI硬件，大模型驱动下的具身智能更是热度空前，人形机器人正开启星辰大海。</p>
  <p>作为智能产业的长期观察者，我们期待见证并记录中国生成式AI浪潮之变，并将持续邀请这股浪潮中的生力军们，分享他们最新的技术进展与商业化探索。</p>
  <p>随着今日为期两天的2024中国生成式AI大会（上海站）圆满收官。2025年线下大会也将正式启动，除了1月14日的全球自动驾驶峰会，围绕AI芯片、生成式AI等领域的线下大会也已规划上了，敬请期待。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072762292220553</id>
            <title>4大痛点，5项研究，7家企业，一文详解AI引领的电池研发创新</title>
            <link>https://www.36kr.com/p/3072762292220553</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072762292220553</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 09:03:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI技术, 电池研发, 新能源汽车, 材料创新  
<br><br>  
总结: 随着AI技术的发展，电池研发面临的技术瓶颈有望得到突破。新能源汽车的快速市场占领得益于价格战和电池技术的创新，提升了消费者的购买信心。动力电池在整车性能和用户体验中扮演着关键角色，技术创新对市场竞争力至关重要。电池技术不仅在新能源汽车中重要，也在消费电子和储能系统中不可或缺。AI的应用加速了电池材料的筛选、合成制备和寿命预测，推动了电池技术的商业化和规模化生产。各大企业积极布局AI驱动的电池研发，展现出强大的实践价值。 </div>
                        <hr>
                    
                    <p>随着 AI 技术的不断发展，为更多高难度新型电池的研发带来希望。本文将围绕传统电池研发技术面临的技术瓶颈、AI 技术为学界、业界带来的技术变革 3 个方面，盘点当下 AI 助力电池研发的新成果。</p>
  <p><strong>「7 月份新能源汽车国内零售渗透率达 51.1%，比原定计划提前了 11 年」。</strong>这是中国汽车流通协会乘用车市场信息联席分会于今年 8 月份发布的数据，在彰显新能源汽车市场增长势头强劲的同时，何尝不是该领域能源结构转型的重要里程碑。</p>
  <p><strong>新能源汽车之所以能够如此快速地占领消费市场，除了政策驱动、市场接受度提高等原因外，还主要得益于两大关键因素。</strong>一方面，特斯拉发起的激烈价格战，带动了行业的降价浪潮，层出不穷的优惠政策不断刺激着销量；另一方面，新能源汽车所搭载的电池技术不断创新，有效缓解了消费者对充电时间长、充电站分布不均等里程焦虑问题，进一步提振了消费者的购买信心。</p>
  <p><strong>作为新能源汽车的「心脏」，动力电池对整车性能、成本和用户体验的提升至关重要。</strong>如比亚迪刀片电池的推出，不仅大幅提高了电池包的空间利用率和安全性，还有望将纯电车型的续航里程突破 1,000 公里，使其达到顶尖的续航表现。因此，有网友形象地评价道：「新能源车企的半条命是动力电池给的。」这一评价不仅道出了电池在新能源汽车产业链中的核心地位，也进一步说明了技术创新对于市场竞争力的重要性。</p>
  <p>值得一提的是，电池技术的重要性并不仅限于新能源汽车领域。无论是消费电子还是大规模储能系统，电池都是不可或缺的关键技术支撑。<strong>中国工程院发布的「面向 2035 的新材料强国战略研究」，明确将电池材料列为新型能源材料领域的重点发展方向，</strong>这不仅表明电池技术在未来能源结构中的战略地位，也为新能源产业的全面升级提供了重要指引。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_686713fe663a420ba01cf09c60747b11@46958_oswg321802oswg1080oswg499_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>关键战略材料领域发展重点及发展方向，图源「面向 2035 的新材料强国战略研究」</p>
  <p>同时，人工智能的迅猛发展为高难度新型电池的研发注入了全新动能。<strong>中国科学院院士、清华大学教授欧阳明高在近日召开的 2024 科学智能峰会上表示：</strong>「在电池材料方面，以前实际上所有的材料研发都是试错型的，耗费大量的人工，周期太长，效率太低。现在有了人工智能，就可以改变以前的研发范式。目前已经实现全过程的自动材料设计，比如自动化的实验、表征、仿真、制备，实现全流程智能化，大大提高了高难度新型电池的研发效率。」</p>
  <h2><strong>数年磨一剑，传统电池研发的痛点与难点</strong></h2>
  <p><strong>电池研发是一项复杂且系统化的工程，包括电池材料的筛选，合成制备，表征测试以及工艺优化等阶段，</strong>而传统的电池研发主要采用「实验试错」的方法，整个研发周期跨越数年时间，且需要大量的资金投入。在此过程中，每一个阶段都面临独特的痛点与难点。</p>
  <p>具体而言，<strong>在电池材料筛选过程中，</strong>研发人员需要结合实验的可行性、成本效益以及安全性等方面，寻找最佳的电极材料和电解液配方。然而电池的正极、负极、电解质和隔膜等组件有众多潜在材料可供选择，传统的筛选方法需要依赖实验逐一验证，耗费大量时间和资源，试错成本高。</p>
  <p><strong>在电池的合成制备过程中，</strong>研发人员需要精确控制合成的反应条件以获得理想的材料特性，这些反应条件包括温度、压力、时间、环境等。如固态电池在合成中仍然面临着硫化物对空气稳定性差、电极/电解质界面的化学和电化学稳定性等重大挑战。这些挑战限制了其在固态电池中的大规模应用，并对合成制备过程提出了更高的要求。</p>
  <p><strong>论文地址：</strong>https://wulixb.iphy.ac.cn/article/doi/10.7498/aps.69.20201581</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_19c787d30bcd42b2b71368484b2ab40e@46958_oswg379012oswg706oswg644_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源物理学报，基于硫化物电解质的固态锂电池界面面临的主要挑战</p>
  <p><strong>在表征测试过程中，</strong>研发人员需要对电池材料的晶体结构、电化学性能以及热稳定性等关键属性进行测试和分析。然而，电池性能的核心指标（如循环寿命、能量密度等）通常需要通过长时间的测试来评估，这种测试周期显著拖延了研发进度。</p>
  <p><strong>在工艺优化阶段，</strong>涂布、干燥、压实等多种参数的优化是一个高度复杂的多变量问题，在实验室小规模研发中获得的理想性能，往往在工业生产中难以复现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a45fd938c70f440b9120b44f39879435@46958_oswg499093oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源三星 SDI&nbsp;</p>
  <p>总结来说，传统电池研发方法中，从材料筛选到工艺优化，每一阶段都面临复杂的挑战。未来的电池研发需要引入更多数据驱动的设计方法、高通量合成与测试技术以及智能化制造手段，从根本上破解传统研发的瓶颈。在这一过程中，AI 将扮演至关重要的角色。</p>
  <h2><strong>柳暗花明，AI for Science 全面解锁电池研发新思路</strong></h2>
  <p>尽管以固态电池为代表的新型电池研发技术还面临诸多挑战，但乘着 AI for Science (AI4S) 范式发展的东风，越来越多的高校以及科研院所开始围绕电池研发，展开 AI 相关技术的落地探索。</p>
  <p>具体而言，<strong>首先 AI 可加速电池材料的筛选与发现。</strong>电池材料的研发涉及成千上万种化学组合，而实验验证的时间和资源有限。AI 在高通量计算和机器学习方面的应用，使得研究者能够通过模拟和预测快速筛选出潜在的高性能材料。如 Microsoft 和 PNNL 借助 AI 技术，筛选了 3,200 万种潜在电池材料，并在 80 小时时间内将名单缩小到 23 种，其中 5 种是已知材料。团队表示如果使用传统方法获取这些材料，这个过程将耗时 20 多年。</p>
  <p>相关研究以「Accelerating computational materials discovery with artificial intelligence and cloud high-performance computing: from large-scale screening to experimental validation」为题，发表在预印网站 arXiv 上。<strong>论文地址：</strong>https://arxiv.org/pdf/2401.04070</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_85a13d7a55a84d27ae698860dbb6a8ae@46958_oswg533917oswg1080oswg715_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Microsoft AI 和 HPC 工具发现的新型固体电解质样本，图源 Microsoft</p>
  <p><strong>其次，AI 在电池的合成制备过程中同样表现出色。</strong>具体而言，界面问题是电池性能的关键瓶颈，例如锂金属负极与电解质的界面稳定性直接决定电池的安全性与寿命。传统实验很难全面了解界面上的复杂反应，而 AI 模型可以结合分子动力学模拟和实验数据，预测界面反应路径并设计更优的电解质材料。如华南理工大学研究人员利用 AI 模型对锂离子电池的界面反应进行建模，重点优化电池组件，为开发更稳定的电解质材料提供了方向。</p>
  <p>相关研究以「Insights into the interface reaction between electrolyte and Li(2)MnO(3) from ab initio molecular dynamics simulations」为题，发表在 Journal of Materials Chemistry 上。<strong>论文地址：</strong>https://pubs.rsc.org/en/content/articlelanding/2024/ta/d4ta04598j</p>
  <p><strong>在电池表征测试过程中， AI 在电池寿命预测上也毫不逊色。</strong>如麻省理工学院、斯坦福大学和丰田研究所 (TRI) 的研究人员使用 AI 预测电池寿命。该团队研发的 AI 算法可根据电池的 5 次充放电循环判断电池使用寿命，且判断结果准确率高达 95%，预测值与电池实际寿命值误差在 9% 以内。值得一提的是，该数据集已经开源，并且是同类数据集中体量最大的。</p>
  <p>相关研究以「Data-driven prediction of battery cycle life before capacity degradation」为题，发表在 Nature 上。<strong>论文地址：</strong>https://www.nature.com/articles/s41560-019-0356-8</p>
  <p>而在前不久，中国科学院大连化学物理研究所联合西安交通大学，在电池健康管理领域取得新进展。研究人员开发了一种新型的深度学习模型，有效地解决了传统方法对大量充电测试数据的依赖，为电池实时寿命预估提供了新的思路，实现了锂电池寿命的端到端评估。同时，该模型也是第一代电池数字大脑 PBSRD Digit 核心模型的重要组成部分，为电池智能管理提供了解决方案。</p>
  <p>相关研究以「Deep learning powered lifetime prediction for lithium-ion batteries based on small amounts of charging cycles」为题，发表在 IEEE Transactions on Transportation Electrification 上。<strong>论文地址：</strong>https://ieeexplore.ieee.org/document/10613834</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8a48fb2fd03f45daa55abdbc7cb796a0@46958_oswg282385oswg948oswg950_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">深度学习技术应用于电池寿命预测，图源中国科学报&nbsp;</p>
  <p><strong>此外，AI 在优化电池材料的生产工艺中也展现出巨大潜力。</strong>以固态电池为例，其制造对电解质的微观结构有严格要求。AI 技术能够通过计算机视觉与优化算法分析材料制备过程中的参数，如温度、压力等，从而提高生产一致性并降低制造成本。如法国皮卡第儒勒-凡尔纳大学联合多所机构的研究展示了如何通过机器学习技术监测并优化电极制造过程。该方法能够实时调整电池制造参数，从而大幅减少废料和提高产品的一致性。</p>
  <p>相关研究以「Toward High-Performance Energy and Power Battery Cells with Machine Learning-based Optimization of Electrode Manufacturing」为题，发表在 Science 上。</p>
  <p><strong>论文地址：</strong>https://www.sciencedirect.com/science/article/pii/S0378775323010509</p>
  <p>可以预见，在 AI for Science 范式的推动下，电池材料领域正站在一个崭新的技术革命的门槛上。AI 的应用不仅为电池材料的研发带来了新的思路和工具，而且正在重塑整个电池技术的发展路径。</p>
  <h2><strong>百舸争流，AI 加速新型电池产业化步伐</strong></h2>
  <p>电池行业正处于技术革新的浪潮之巅，而 AI 无疑是引领这场技术复兴的核心驱动力。AI 技术的深入应用不仅在学术研究领域催生了电池科学的前沿理论，还在产业界展现出强大的实践价值，为电池技术的商业化、规模化生产以及性能优化提供了全新动力。</p>
  <p><strong>在国际市场中，多家企业已经抢先布局 AI 驱动的电池研发。</strong>特斯拉通过 AI 优化电池管理系统 (BMS)，使用深度学习和机器学习技术预测电池健康状态和寿命，并利用数据驱动方法改进超级充电与能量管理。</p>
  <p>韩国电池制造商 LG 新能源 (LG Energy Solution) 开发了 AI 平台，专注于预测电池老化、失效模式以及能量管理优化，同时为储能系统 (ESS) 提供动态预测和优化能力。</p>
  <p>锂金属电池企业 SES AI 也宣布将联手科技公司 NVIDIA、Crusoe 和 Supermicro，加速电池新材料研发，计划使用为 AI 优化的高性能超级计算机，绘制小分子数据库，从而提升对电池化学体系的理解，加快发展能量存储解决方案。</p>
  <p>除此之外，NVIDIA 也在最近宣布 ALCHEMI NIM 项目正通过 AI 技术加速电动汽车电池和太阳能电池板等可持续能源材料的研发。这些项目能够高效模拟和预测材料的电化学性能，不仅缩短了新材料的研发周期，还大幅降低成本，为全球能源转型提供了技术支持。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_b7173c25ade540b694fd0deb20052338@46958_oswg718243oswg936oswg1220_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源 X&nbsp;</p>
  <p><strong>回归国内市场，各家企业的电池研发技术创新也是呈百家争鸣之势。</strong>作为全球动力电池行业的领军者，宁德时代积极将 AI 技术应用于电池化学和材料性能的建模优化，专注于高能量密度电池的研发。2023 年 12 月，宁德时代宣布将在香港设立国际研发中心聚焦于 AI for Science。宁德时代董事长曾毓群也在近一年多次在公开场合提及加快导入 AI，尤其在电池材料体系创新方面。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_81c535d5585c4c54bbbbf869925114ff@46958_oswg175709oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">宁德时代发布神行超充电池，图源网络&nbsp;</p>
  <p>此外蜂巢能源 (SVOLT) 在江苏金坛率先打造出行业首家车规级 AI 智能动力电池工厂，利用 AI 进行电池全流程管控，推出了一系列高性能电池产品，极大地加速了新能源电池的规模化应用。</p>
  <p>与此同时，一些 AI 电池材料初创公司也如雨后春笋般出现在国外市场上，如 QuantumScape、Inobat Auto、 Mitra Chem、Aionics 等，旨在将人工智能引入电池开发领域，其中 Mitra Chem 更是被一些电池技术界的大拿们描述为「位于硅谷的一家由人工智能技术驱动的电池材料革新者」。</p>
  <p>而我国市场上也涌现出了一批新能源 AI 企业，如欧阳明高院士团队孵化的企业昇科能源，发布了全球首个电池 AI 大模型 PERB2.0。这一模型能够处理和分析海量电池数据，在电池设计、性能优化和智能决策方面发挥关键作用。</p>
  <p>综上所述，无论是国际市场还是国内企业，无论是头部企业还是初创公司，在电池研发领域，都在积极地拥抱 AI。</p>
  <h2><strong>写在最后</strong></h2>
  <p>放眼当下，从材料发现到制造优化，从性能预测到全生命周期管理，AI 技术正在全面赋能电池研发的每一个环节，为新能源产业注入强劲动力。通过将科研成果与产业实践深度融合，AI 不仅加速了技术迭代，还推动了电池技术的大规模应用和成本下降。</p>
  <p>但任何事物的发展是曲折上升的， AI 与电池研发的深度融合也不是一蹴而就的。<strong>正如宁德时代董事长曾毓群所言，「AI4S（用于电池材料研发）目前还没有特别好的模型、结构、算法，还有很长的路要走。」</strong></p>
  <p><strong>参考资料：</strong></p>
  <p>1.http://finance.people.com.cn/n1/2024/0812/c1004-40297368.html</p>
  <p>2.https://www.auto-made.com/news/show-16443.html</p>
  <p>3.https://www.engineering.org.cn/sscae/CN/article/downloadArticleFile.do?attachType=PDF&amp;id=28528</p>
  <p>4.https://esst.cip.com.cn/CN/10.19799/j.cnki.2095-4239.2024.0698</p>
  <p>5.http://www.xinhuanet.com/science/20241121/6c8a64232e464ee886b8dc4c732f81fd/c.html</p>
  <p>6.https://developer.nvidia.com/zh-cn/blog/revolutionizing-ai-driven-material-discovery-using-nvidia-alchemi/</p>
  <p>7.http://www.dicp.cas.cn/xwdt/mtcf/202410/t20241022_7405757.html</p>
  <p>8.https://www.cas.cn/syky/202411/t20241120_5040077.shtml&nbsp;</p>
  <p>9.https://www.sciencedirect.com/science/article/pii/S2590116823000474</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_K3v_2L_QsQDkORzW7Y5FQ" rel="noopener noreferrer nofollow" target="_blank">“HyperAI超神经”</a>，作者：李姝，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072773689291657</id>
            <title>谷歌Willow量子芯片逆天出世，5分钟颠覆10亿亿亿计算极限，马斯克奥特曼惊叹</title>
            <link>https://www.36kr.com/p/3072773689291657</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072773689291657</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 09:00:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 量子计算, Willow芯片, 纠错技术, 超级计算机  
<br><br>  
总结: 谷歌推出了全新的量子芯片Willow，成功在不到5分钟内完成了一个计算任务，而世界上最快的超级计算机Frontier则需要10^25年。Willow的量子比特数量达到105个，并在量子纠错和随机电路采样中表现出色，标志着量子计算领域的重大技术突破。该芯片实现了误差率的指数级下降，攻克了困扰量子计算近30年的纠错问题。谷歌量子团队的研究成果已刊登在Nature期刊上，预示着量子计算在药物发现、核聚变等领域的巨大潜力。 </div>
                        <hr>
                    
                    <p><strong>【导读】</strong>谷歌团队再创量子计算里程碑！全新量子芯片Willow，仅用不到5分就完成了当今最强超算，需要10^25年这个天文数字般的计算。困扰人类近30年量子计算纠错问题，终于被攻克了！</p>
  <p>这一刻，注定将被载入史册！</p>
  <p>今天，谷歌重磅推出全新的量子芯片——Willow（共105个量子比特），在AI圈掀起了海啸级巨震。</p>
  <p>在一个标准基准计算任务，Willow用时不到5分钟（300秒）神速完成。</p>
  <p>而如今，世界上最快超算Frontier要完成同样任务，则需要10亿亿亿年，也就是10,000,000,000,000,000,000,000,000年。</p>
  <p>这一天文般的数字，远远超过了宇宙的年龄（138亿年）！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_450cc5728aa7487bacf78b5da7d470df@46958_oswg41445oswg226oswg223_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Willow不仅仅是速度的胜利，更取得了量子计算领域决定性的技术突破——</p>
  <p>随着量子比特数量的增加，这款芯片的误差也呈指数级下降。这种精度提升的速率超出了一个关键阈值。</p>
  <p>这意味着，曾困扰量子计算近30年的纠错问题，终于迎来曙光。</p>
  <p>谷歌量子团队的最新研究，已经刊登在今天的Nature期刊上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_91a4845c78e940629698428aaae9030c@46958_oswg55453oswg1052oswg367_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文地址：https://www.nature.com/articles/s41586-024-08449-y</p>
  <p>原本，这又是OpenAI谷歌激烈交战的一天，却在𝕏上呈现出一切祥和的另一面，劈柴奥特曼两人开始了「商业互吹」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_542ab16d3e294fd58aa1edd7b97a6ecc@46958_oswg82412oswg1080oswg228_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>劈柴亲自官宣这一消息后，奥特曼第一时间送上祝贺。</p>
  <p>他对此回应道——「量子+AI的多重宇宙未来将至，也恭喜o1发布！」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a56b1ee187e44fe5aa28f9553b615e76@46958_oswg80930oswg777oswg637_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这边，劈柴还畅想了与马斯克星舰的联动——有朝一日，我们应该借助Starship在太空中建造一个量子集群。</p>
  <p>马斯克回应，这很可能实现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_5bddabc340574a3bbd44da6b6412f10d@46958_oswg367018oswg1080oswg1190_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>谷歌罕见地敞开了话匣子，在发布前特意召开媒体说明会。</p>
  <p>谷歌量子AI团队的大佬们——创始人兼负责人Hartmut Neven、研究科学家Michael Newman、量子硬件主管Julian Kelly和总监兼首席运营官Carina Chou，个个亲自上阵，足见这项研究的分量。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_3d977c48015e4ca6af9af3ec50302ad7@46958_oswg723717oswg1080oswg657_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>破解30年重大难题，谷歌再创历史</strong></h2>
  <p>Willow是在谷歌位于圣巴巴拉的最先进制造设施中生产的——这是全球为数不多的、为量子芯片量身定制的、从零开始建的工厂之一。</p>
  <p>量子芯片的设计可不是简单的拼拼图，所有组件——从单比特门、双比特门到量子比特复位和读出——都需要精密设计与无缝集成，缺一不可。只要其中一个组件卡壳，整个系统就会掉链子。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ebe69f3fa4be4194b56c83f7b8f4c5c8@46958_oswg347152oswg1024oswg575_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Willow目前有105个量子比特，在量子纠错和随机电路采样这两项基准测试中表现出同类最佳的性能。</p>
  <p>值得一提的是，Willow的T1时间（量子比特保持激发状态的时间）达到了近100微秒，比上一代约提升了5倍——这是量子计算的关键资源。</p>
  <p>如果想跨平台比较量子硬件性能，以下是一些关键数据：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_e8030a734a8745aea8f3ac96302d7094@46958_oswg785350oswg1000oswg2023_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于谷歌来说，Willow具有划时代意义。</p>
  <p>它将成为构建有用量子计算的第一步，未来在药物发现、核聚变、电池设计等诸多领域中，带去不可估量的研究潜力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_d7ef4e45e0ef44fba199746a0437c94d@46958_oswg119945oswg1080oswg249_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>首次实现「低于阈值」</strong></h2>
  <p>为了让量子计算更可靠，谷歌将量子比特分组协同工作，以实现纠正错误。</p>
  <p>每个分组形成一个d×d的量子比特网格，称为表面码，每个表面码代表一个编码的或「逻辑」量子比特。</p>
  <p>随着晶格的增大，系统能容忍的错误也更多，理论上逻辑量子比特的保护性和性能都会提高。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_6ec88891f94a48098aa307573cf06ac8@46958_oswg301492oswg1080oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随规模增加的表面码逻辑量子比特，每个都能够比前一个纠正更多的错误；编码的量子状态存储在数据量子比特阵列（黄色）上；测量量子比特（红色、青色、蓝色）用于检测相邻数据量子比特上的错误</p>
  <p>然而，增加晶格也意味着更多的出错风险。</p>
  <p>如果物理量子比特的错误率过高，额外增加的错误会多过纠正的错误，增加晶格反而可能拖慢处理器性能。</p>
  <p>只有当错误率低到足够的程度，错误纠正才能发挥作用，并实现指数级的错误率下降——这就是所谓的阈值。低于阈值时，量子错误纠正从有害变为有益。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_7dbce2575e184b20b03658a056357c41@46958_oswg162051oswg1080oswg216_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>首先将数据量子比特（金色）初始化为一个已知状态，并重复进行奇偶校验检查以检测并标记错误（红色、紫色、蓝色、绿色）；最后，测量数据量子比特并解码测量数据，从而得到一个经过错误纠正的逻辑测量结果</p>
  <p>谷歌的Willow芯片打破了这个瓶颈：它不仅增加了量子比特的数量，还成功减少了误差，实现了误差率的指数级下降。</p>
  <p>在Willow中，随着量子比特从3x3的表面码扩展到5x5、7x7，编码错误率每次减少2.14倍，实现了误差率的指数级下降。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_17a9aefbae8e4e58bd02c4e6198a0b15@46958_oswg224889oswg1080oswg848_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>逻辑量子比特性能随表面码规模的扩展而提升：从3×3（红色）扩展到5×5（蓝绿色）再到7×7（蓝色）时，逻辑错误概率大幅下降；Willow上的7×7逻辑量子比特的寿命是其最佳物理量子比特（绿色）的2倍，同时也是谷歌之前在Sycamore（灰色、黑色）上表面码的20倍</p>
  <p>这个历史性的成就被领域内称为「低于阈值」——即在扩展量子比特数量时，能够降低误差率。这是量子计算领域追求了近30年的里程碑。</p>
  <p>自1995年提出以来，「低于阈值」一直被认为是构建大规模量子计算机的关键。</p>
  <p>更重要的是，这是首个在超导量子系统中进行实时误差修正的成功案例——这一点对任何有用的计算至关重要，因为如果无法足够快速地修正误差，计算在完成之前就会被破坏。</p>
  <p>而且，这是首个「超越盈亏点」的演示，其中量子比特阵列的寿命超越了单个比特的寿命。这证明量子误差修正确实有效，正在全面改善系统。</p>
  <p>Willow是首个「低于阈值」的系统，也是最强有力的可扩展量子比特原型，证明超大规模量子计算机真的能造。它让我们离那些传统计算机无法完成的实用算法更近了一大步！</p>
  <h2><strong>5分钟计算，世界最快超算却用10亿亿亿年</strong></h2>
  <p>为了测试Willow的性能，研究团队使用了随机电路采样（RCS）基准测试。</p>
  <p>RCS是当前量子计算机上可以完成的计算中最难的基准测试，可以将其视为量子计算的入门测试——它检查量子计算机是否能做一些经典计算机无法做到的事情。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_58fbf55385474e7898690606246de71f@46958_oswg276268oswg1000oswg650_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Willow在这个基准上的表现令人震惊：它在不到五分钟的时间内完成了一个计算，而这个计算如果由今天最快的超级计算机Frontier来完成，将需要10^25年，也就是10,000,000,000,000,000,000,000,000年。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ab38cbfae7ab4e56bea53af686771882@46958_oswg161672oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这个令人难以置信的数字超出了物理学中已知的时间尺度，远远超过了宇宙的年龄。</p>
  <p>它支持了量子计算发生在多个平行宇宙中的观点，这与我们生活在多元宇宙中的理论相一致，这一预测最早由大卫·德意志提出。</p>
  <p>这些最新的Willow结果，如下图所示，是迄今为止取得的的最佳成绩，而且它还将继续进步。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_185b76686be2460a839df763925bbdaf@46958_oswg163410oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>计算成本受可用内存的影响很大。因此，我们的估算考虑了多种情况，从理想的无限内存环境（▲）到在GPU上实现的更实际、易于并行化的方案（⬤）</p>
  <p>研究团队对Willow超越经典超级计算机Frontier的评估，建立在保守假设之上，比如假设Frontier拥有无带宽限制的二级存储——这显然是个不现实的理想假设。</p>
  <p>虽然经典计算机会继续进步，但快速扩大的差距表明，量子计算正以双重指数级速度拉开差距，随着规模扩大，量子计算机将继续遥不可及地领先。</p>
  <h2><strong>300多人，12年心血</strong></h2>
  <p>Hartmut Neven在博客中写道：「当我在2012年创办谷歌量子AI时，我们的愿景是构建一台实用的大规模量子计算机，利用量子力学——我们今天所理解的自然操作系统——来造福社会，推动科学发现、开发有益的应用，并解决一些社会面临的重大挑战。」</p>
  <p>Willow，是这个长期愿景中关键的一步，也是朝着商业化量子计算迈进的重要里程碑。</p>
  <p>今天，谷歌量子AI团队拥有约300名成员，并计划扩展。他们还在加州大学圣巴巴拉分校（UCSB）建立了自己的制造设施。</p>
  <p>如今，AI和量子计算都将被证明是我们这个时代最具变革性的技术。</p>
  <p>特别是，先进的AI技术将在量子计算的支持下取得显著突破，而这也是谷歌将实验室命名为Quantum AI的原因。</p>
  <p>正如在随机电路采样中所观察到的，量子算法在基本的扩展定律（Scaling Law）上具有显著优势。对于很多基础的计算任务，这些扩展优势同样适用，而这些任务对AI来说至关重要。</p>
  <p>因此，量子计算将在以下方面将不可或缺：</p>
  <ul>
   <li>收集经典计算机无法获取的训练数据</li>
   <li>训练和优化某些学习架构</li>
   <li>建模量子效应重要的系统</li>
  </ul>
  <p>具体来说，包括帮助我们发现新药物、设计更高效的电动车电池，以及加速聚变和新能源替代品的研究进展。</p>
  <p>这些未来改变游戏规则的应用，有很多在经典计算机上是无法实现的——它们都在等待通过量子计算来解锁。</p>
  <h2><strong>展望未来</strong></h2>
  <p>一旦突破阈值，设备的小幅改进将通过量子纠错被指数级放大。</p>
  <p>例如，虽然Willow的操作保真度大约是Sycamore的2倍，但其编码错误率却改善了大约20倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_2d17f780f0354994ba7343a23902e92e@46958_oswg242573oswg1000oswg516_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>能否构建一个近乎完美的编码量子比特？</strong></h3>
  <p>量子错误纠正现在看起来已经初见成效，但从今天的千分之一错误率到未来所需的万亿分之一错误率之间仍然存在巨大差距。</p>
  <p>那么，会不会是我们遇到了新的物理现象，从而阻碍我们构建量子计算机的进程呢？</p>
  <p>为了回答这个问题，谷歌开发了一种「重复码」。</p>
  <p>与保护所有（局部）量子错误的表面码不同，重复码仅专注于比特翻转错误，但效率更高。通过运行重复码实验并忽略其他错误类型，谷歌在采用许多与表面码相同的错误纠正原则的同时，实现了更低的编码错误率。</p>
  <p>通俗地讲，重复码就像一个先行侦察兵，用于验证错误纠正是否能够持续降低到最终需要的近乎完美的编码错误率。</p>
  <p>在Willow上运行重复码时，谷歌能够实现约100亿次错误纠正循环而未发现任何错误。然而，当尝试通过进一步增加编码规模来降低编码错误率时，却发现错误率停滞不前。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_956ddcbf027c4d4e9facb8a4ececfa80@46958_oswg239670oswg1080oswg1799_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>重复码性能随重复码规模的扩展而提升：与Sycamore相比，实现了10000倍的性能改进，但逻辑错误率在每循环约10⁻¹⁰时达到了一个瓶颈</p>
  <h3><strong>如何提升纠错量子计算机的速度？</strong></h3>
  <p>与正在使用的经典设备相比，纠错量子计算机的速度实际上非常之慢。</p>
  <p>即便是超导量子计算机——目前最快的量子比特技术之一，其测量时间也长达约一微秒。相比之下，经典计算的亚纳秒级操作时间则快了超过1000倍。</p>
  <p>而量子纠错操作，就更慢了。部分原因在于，现在还需要依靠「量子错误解码器」这一经典软件来解释测量结果进而识别错误。</p>
  <p>在超导量子比特领域，谷歌首次展示了能够与设备同步实时解码测量信息的能力。但即使解码速度能够跟上设备，对于某些纠错操作，解码器仍可能拖慢整体速度。</p>
  <p>目前，谷歌在设备上测得解码延迟时间为50至100微秒，并预计这种延迟会随着晶格规模的增大而进一步增加。这种延迟可能会显著影响纠错操作的速度。</p>
  <p>如果想让量子计算机成为一种能够用于科学发现的实用工具，就必须对此加以改进。</p>
  <h3><strong>接下来是什么？</strong></h3>
  <p>通过量子纠错，我们原则上已经能够扩展系统，实现近乎完美的量子计算。</p>
  <p>然而在实践中，这并不容易——距离构建大规模、容错的量子计算机的目标仍有很长的路要走。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0fef346885d646f0973ee118b699825f@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在逐步改进的处理器上，实现了逻辑量子比特，每次升级时物理量子比特的数量翻倍，且处理器规模逐渐增大。红色和蓝色方块表示用于检测附近错误的奇偶性检查。这些处理器分别能够可靠地执行大约50次、10³次、10⁶次和10¹²次循环&nbsp;</p>
  <p>以当前的物理错误率来看，要实现相对适中的编码错误率（10⁻⁶），我们可能需要每个表面码网格使用超过一千个物理量子比特。&nbsp;</p>
  <p>目前，所有这些都是在一个拥有105个量子比特的处理器上实现的。那么，我们是否能够在拥有1000个量子比特的处理器上实现相同的性能？如果是拥有一百万个量子比特的处理器呢？&nbsp;</p>
  <p>虽然面临的工程挑战是前所未有的，但进展也令人瞩目。毕竟，量子纠错所带来的改进是指数级的。&nbsp;</p>
  <p>自去年以来，谷歌的编码性能已经提升了20倍——还需要多少个这样的20倍，才能运行大规模的量子算法？&nbsp;</p>
  <p>或许，答案比我们想象中要少得多。&nbsp;</p>
  <p>参考资料：&nbsp;</p>
  <p>https://research.google/blog/making-quantum-error-correction-work/&nbsp;</p>
  <p>https://blog.google/technology/research/google-willow-quantum-chip/&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/BzjypoiESPQlrLe-qnikJw" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：编辑部 HYj&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072753348407939</id>
            <title>融了8轮，苏州又将跑出一个明星IPO</title>
            <link>https://www.36kr.com/p/3072753348407939</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072753348407939</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 08:34:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 长风药业, 吸入制剂, 融资, 药物研发  
<br><br>  
总结: 长风药业近期在港交所递交招股书，标志着其从默默无闻到成为资本宠儿的转变。公司自2007年开始专注于吸入药物研发，已成功上市4款药品，其中布地奈德混悬液成为市场爆款，推动公司转亏为盈。长风药业的成功得益于多轮融资和强大的资本支持，未来将继续在吸入制剂国产替代和全球市场中发挥重要作用。随着呼吸系统疾病患者的增加，长风药业的市场前景广阔。 </div>
                        <hr>
                    
                    <p>融到F轮的资本宠儿“长风药业”于近日在港交所递交招股书。</p>
  <p>长风药业创立于江苏苏州，最早于2007年开始吸入药物的研发，2013年成立股份制企业。</p>
  <p>药企上市最担心的就是产品研发和造血能力的问题，但长风药业已经有一款爆款药，卖出了同类全国第一的份额。这一成绩也给公司带来了强大营收，使得公司已转亏为盈。另外，公司产品布局丰富，4款已上市药在梯次产生营收，这给公司后续的造血能力带来了信心。</p>
  <p>从默默无闻到脱颖而出，长风药业的发展离不开背后数十家资本的支持，包括吉林创投、吉星创投、上海思宏达、凯风投资、金峰凌恒、中新创投、瑞业基金、金沙河、金浦健康基金一期、国投创新、建银国际、前海元明、隆门投资、恒宇天泽、联新资本领投、华润正大生命科学基金、君信资本、源创投资、基石资本、相城金控、朗玛峰投资、元禾控股、苏州隆门创投基金、高特佳、招银国际资本、博远资本、中金资本、上汽恒旭、沃生投资、斐君资本、元明资本、腾午股权等众多知名机构。</p>
  <h2><strong>4款上市药，吸入制剂国产替代来了</strong></h2>
  <p>长风药业的两位创始人除了有相同的科学家的身份外，均多了一层连续创业者的身份。</p>
  <p>创始人梁文青出生于1966年，马萨诸塞大学分子细胞生物学专业博士，先是任哈佛医学院博士后研究员，而后开始跨界进军金融行业。2000年，梁文青在美国威布什摩根投资银行当了一年的助理研究员，而后再当了两年美国汇集风险投资公司项目研究师，再开启创业生涯。2002年至2010年，梁文青在美国创办了一家中国健康咨询公司。</p>
  <p>另一位创始人李励，出生于1959年，是美国密歇根大学博士后研究员，曾任葛兰素史克高级科学家、美国先灵葆雅制药集团药物制剂研究部高级资深科学家。1998年至2014年，创办美国Cirrus药物开发公司，任副总裁。</p>
  <p>据说，梁文青和李励二人相识于网络，而且两位均是2006年江苏无锡“530计划”（5年内引进30名海外留学人才归国创业）中的一员。</p>
  <p>在企业分工上，二人“一个主内，一个主外”。李励主要负责内部的技术和法规，梁文青则负责战略和企业管理、市场及投融资领域。</p>
  <p>在二人的带领下，企业研发速度和节奏确实把控得比较好。自2015年C轮融资后，长风药业便启动了吸入制剂生产线建设，提交ANDA申请。六年后的2021年，公司已完成F轮融资，紧接着产品吸入用布地奈德混悬液、硫酸沙丁胺醇溶液获批上市。</p>
  <p>2022年，长风药业开发的氮䓬斯汀氟替卡松鼻喷雾剂获批上市。2023年，硫酸特布他林雾化吸入用溶液再度获批上市。</p>
  <p>除了以上4款上市药，目前，公司还有20多个正在中国、美国以及欧洲等主要市场和东南亚及南美等新兴市场进行全球开发的产品，预计未来四年内至少有五个产品获得批准。</p>
  <p>由于哮喘、COPD及过敏性鼻炎等呼吸系统疾病患病率不断上升，全球呼吸系统药物市场巨大。据估计，目前全球有将近25亿人患有慢性呼吸系统疾病，而且由于空气污染、吸烟和人口老龄化等因素，预计患病人数还会增加。2023年，全球呼吸系统药物市场规模估值为946亿美元，预计到2033年将达到1486亿美元，2023年至2033年的年复合增长率为4.6%。中国人口众多，占全球市场相当大的份额。</p>
  <p>而吸入药物指的是通过呼吸系统给药的药械组合产品。这一品类优点很多。相比于口服药和注射药，吸入治疗能将药物直接到达肺部，绕过肠道代谢，能减少或消除一些药物不良反应，还减少了药物剂量。也因此，吸入药物的研发更加复杂，需要确保颗粒大小、稳定性和效率。</p>
  <p>由于中国药物开发历史、技术壁垒等原因，尽管有庞大的患病人群，但治疗率和药品使用率均处于较低水平。因此，中国这一药物市场长期以来被外资垄断，本土药企市占率不足10%。</p>
  <p>如今，长风药业将在吸入制剂国产替代、乃至全球市场较量中扮演更加重要的角色。</p>
  <h2><strong>入账12亿，爆款药盘活整个公司</strong></h2>
  <p>药物研发本身就是一件周期很长的事，上市前未产生营收的创新药企比比皆是，但长风药业已经取了阶段性的财务胜利，在上市前已转亏为盈。</p>
  <p>2021年至2024年上半年，该公司年内利润分别约为-13172.6万元、-4939.9万元、3172.6万元、944.6万元。</p>
  <p>取得这一成绩与企业清晰的战略，可靠的执行力不无关系。</p>
  <p>整体层面上，长风药业采取的策略是两步走。第一阶段开发的是能够对庞大患者群体产生最大临床影响或解决主要未被满足的需求的成熟制剂。</p>
  <p>结果上看，公司的爆款产品布地奈德混悬液CF017便达到了这一目的。布地奈德混悬液CF017主要治疗支气管哮喘，其于2021年5月获批后迅速纳入中国集中采购计划,并快速实现了市场增长，是中国销量最高的吸入药物类别。根据弗若斯特沙利文的资料，CF017占2023年中国布地奈德吸入药物市场约20%。</p>
  <p>营收数据上，2021-2024年上半年，长风药业实现的营收分别为0.42亿、3.49亿、5.56亿和2.89亿元，总计12.36亿元。其中，公司超九成收入来自吸入用布地奈德混悬液。</p>
  <p>就靠这款药，盘活了整个长风药业的基本盘。而且，长风药业产品布局合理，目前已上市的4款药品中，已有2个产品有显著收入，另外2个也将次序产生更多营收。可以预测，公司的造血能力在未来将进一步增强。</p>
  <p>招股书也称，随着技术的基础的不断夯实，近年来，公司已经从第一阶段迈向新阶段，重点关注创新制剂、新型疾病领域，新治疗方法和关注中国首创的治疗方法。</p>
  <h2><strong>融了8轮，资本云集</strong></h2>
  <p>在善于资本运作的梁文青的带队下，长风药业有着非常壮观的融资历程。招股书显示，公司完成8轮融资，可谓资本云集。</p>
  <p>2010年12月，A轮融资由知名的双鹭药业出资1000万元。2013年4月，长风药业获得了吉林创投、吉星创投、上海思宏达、凯风投资、金峰凌恒等4100万元B轮融资。数月后，中新创投强势加入，以900万元单独完成B+轮融资。</p>
  <p>C轮融资发生在2015年，瑞业基金、金沙河、金浦健康基金一期、凯风投资、金峰凌恒等机构下注6000万元。</p>
  <p>2017年，为了抓住这颗冉冉升起的新星，国投创新、建银国际、前海元明、隆门投资、恒宇天泽等新老投资人共同出资4.4亿元，助力长风药业完成D轮融资。</p>
  <p>紧接着，长风药业在疫情期间逆势顺利完成E轮和F轮融资的落地，这同时也是我国吸入制剂领域最大规模的一笔融资。</p>
  <p>2020年1月，长风药业顺利完成E轮融资6.3亿元，由联新资本领投，华润正大生命科学基金、君信资本、源创投资、基石资本、相城金控、朗玛峰投资、元禾控股、苏州隆门创投基金、高特佳和招银国际资本等新老股东继续增持。</p>
  <p>2020年7月，长风药业完成F轮3.6亿元融资，投资方包括博远资本、中金资本、上汽恒旭、金浦并购基金、沃生投资、斐君资本、元明资本等机构参与投资。长风药业在6个月内总计完成近10亿融资。按以上数据计算，IPO前，长风药业总计通过外部机构募资近16亿元。</p>
  <p>F轮之后，公司也迎来了明星创收产品，公司的现金流转越来越健康，便放慢了融资脚步。在长风药业IPO申报前12个月内，腾午股权投资因看好长风药业的发展还通过股权转让突击入股。</p>
  <p>如今，数十家资本的耐心，已哺育出一个中国本土的制药新星。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzI4MjYxMTYyNA==&amp;mid=2247512805&amp;idx=1&amp;sn=8172f6075ca9492ce2c4ca94fc0fa0d5&amp;chksm=ea5e03ef6d3cf9c180541bd504703e9846eeed41f80fa38ec7ed4122daace626051e7cb509cd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“东四十条资本”（ID：DsstCapital）</a>，作者：黎曼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072769017754247</id>
            <title>为什么手表会吸在玻璃上？苹果客服回应</title>
            <link>https://www.36kr.com/p/3072769017754247</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072769017754247</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 08:31:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果手表, 吸附, 保护膜, 光胶现象  
<br><br>  
总结: 苹果手表表盘不具备吸附力，能贴在光滑玻璃上可能是由于贴膜的原因。苹果客服建议如果表盘取不下来，可以尝试撕掉部分膜。部分网友在社交平台上分享了将手表吸附在玻璃上的经历，结果各异。维修博主指出，贴膜的手表可能会吸附，而未贴膜的手表则不会。商家解释称，吸附现象是由于光胶现象造成的，摩擦力在光滑表面上会增大。 </div>
                        <hr>
                    
                    <p>10日，“为什么苹果手表会吸在玻璃上”在社交平台引热议。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8996cd92ea4746fa810e58e8601413ba@000000_oswg154112oswg1080oswg1324_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对此，苹果官方客服10日对中新经纬表示，苹果手表表盘是不具备任何吸附力的，能贴在光滑玻璃上要考虑是否是手表贴膜的原因，<strong>“如果取不下来的话可以尝试把膜撕掉一些，看能否把表盘移动开。”</strong></p>
  <p>另一客服也表示，<strong>苹果手表采用的是视网膜显示屏，表盘不会和包括玻璃在内的任何材质吸附，如果有这种情况考虑是否贴了保护膜。</strong></p>
  <p>近日，在社交平台上有网友发帖求助称，把苹果手表表盘吸在了高铁的窗户上，结果吸住了拿不下来。随后有部分网友也开始尝试，把苹果手表表盘吸在光滑的玻璃上，有的可以吸附成功，有的则失败。还有网友称吸附成功后取不下来，使劲拽结果把表盘整个拽下来了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8b6d1e61b6de4e239dda172fb1f6034d@000000_oswg66923oswg690oswg1108_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>专做数码产品维修的博主“波哥维修”9日发视频称，<strong>贴了膜的手表牢牢吸在了玻璃上，而没有贴膜的手表和玻璃并没有任何吸附力。</strong></p>
  <p>他表示，手表表盘其实是用胶粘上的，所以取不下来的话用力拽肯容易把表盘拽下来造成损坏，可以尝试左右旋转，或者找一根细线，来回“切割”，把手表“刮下来”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ba0fbc384cad4be58a2b4a064ddfd5fc@000000_oswg119174oswg1080oswg1370_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>中新经纬尝试后发现，没有贴膜的苹果手表确实无法吸附在任何镜面、玻璃上。</p>
  <p>此外，中新经纬在电商平台咨询多个售卖苹果手表保护膜的商家，均表示，“还没有出现过这种情况”。</p>
  <p>另据都市快报，有手表贴膜店的商家解释称，苹果手表取不下来是因为“光胶现象”，这是一种物理学现象，当物体表面的光滑程度超过一定限度时，越光滑，则摩擦力反而会越大。商家表示，遇到这样的情况，撕开贴膜的一个小角，手表就会自己脱落。</p>
  <p>对此，有网友评论称，“一代人有一代人的嘴里塞灯泡。”“明知道结果是什么还是不信邪，非要尝试。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_af3efda1629f4c5b8435fcf654beb70a@000000_oswg80894oswg1080oswg685_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>文、编辑：李晓萱 责编：常涛&nbsp;罗琨</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzI0NDU5OTAzMA==&amp;mid=2247586568&amp;idx=1&amp;sn=5f018ecc689ad758a8a8235adf6d6a43&amp;chksm=e8e974e487407de741fad30070b24fac8d3c4d8832b5eb13d9d88888b3497cb9b346d22b485d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“中新经纬”（ID：jwview）</a>，作者：李晓萱，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072698255831684</id>
            <title>谷歌量子芯片引爆热议：5分钟算完10²⁵年任务，Nature加急发表，还证实了多元宇宙？</title>
            <link>https://www.36kr.com/p/3072698255831684</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072698255831684</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 08:26:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <谷歌, 量子芯片, Willow, 计算能力>
<br>
<br>
总结: 谷歌发布了最新的量子芯片Willow，该芯片在5分钟内完成了当今最快超级计算机需要10²⁵年才能完成的计算，展现了显著的技术突破。Willow拥有105个量子比特，并在量子纠错和随机电路采样中达到了最新的技术水平，实现了错误率的指数级降低。该成果为量子计算的实际应用奠定了基础，并引发了关于平行宇宙的讨论。尽管如此，Willow在实际应用测试中尚未超越经典计算机的能力。 </div>
                        <hr>
                    
                    <p>全球科技圈都在为Sora疯狂，马斯克却轻轻给谷歌点了个赞（doge）。</p>
  <p>就在OpenAI“双12”第三天，谷歌在前沿科技的另一极出手了：</p>
  <p>发布最新量子芯片，<strong>5分钟内完成当今最快超级计算机之一需要10²⁵年才能完成的计算</strong>！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_7cc3909f190c457c8169e117538eefc0@000000_oswg79164oswg884oswg448_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>怎么说1025这事儿呢，就是……</p>
  <p>10000000000000000000000000，10亿亿亿年。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_186bfc47a55745b097add9970842d608@000000_oswg46300oswg637oswg460_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这一成果由谷歌CEO皮猜本人亲自在𝕏官宣，并已在Nature上加急发表。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_a91552f4c0a64d50a8a131ab5fc16a13@000000_oswg193330oswg880oswg666_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>连刚下直播的奥特曼和OpenAI总裁Brockman，也现身道贺：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_791eee8d39264215a183445f42dde888@000000_oswg154237oswg888oswg612_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_5d680e40e94d4cd9bd28e5491b03445e@000000_oswg13688oswg886oswg190_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据Nature消息，我国量子领域大拿陆朝阳也对此评价称：</p>
  <blockquote>
   <p>这项工作展现了真正非凡的技术突破。</p>
  </blockquote>
  <p>新芯片名为<strong>Willow</strong>，拥有105个量子比特，在量子纠错和随机电路采样两个基准测试中，都达到了SOTA，实现两项重大成就：</p>
  <p>随着量子比特的增加，Willow可以实现指数级的错误率降低——这是量子纠错领域30年来一直试图解决的关键挑战。</p>
  <p>Willow在5分钟内，完成当今最快超级计算机之一需要1025年才能完成的计算，数字远超宇宙年龄。</p>
  <p>官方公告中，甚至还由此开启了对<strong>平行宇宙学说</strong>的新讨论……</p>
  <blockquote>
   <p>它证实了David Deutsch做出的预测：量子计算发生在许多平行宇宙中，这与我们生活在多元宇宙中的观点是一致的。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_1f15fe0a3da4409f941b6ecd1b6adb48@000000_oswg386423oswg900oswg567_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>来看具体细节。</p>
  <h2><strong>5分钟完成1025年计算</strong></h2>
  <p><strong>错误</strong>是量子计算面临的最大的挑战之一。</p>
  <p>简单来说，量子比特利用叠加态来进行计算，对环境扰动极其敏感，这就意味着它们很难保护完成计算所需的信息。</p>
  <p>并且通常，量子比特越多，发生的错误就越多。这会使得系统越来越“经典”，即不再具备量子系统的特性。</p>
  <p>因此，<strong>控制错误率</strong>，让错误率低于某个阈值，是量子计算大规模应用的一个非常重要的前提。而现在，谷歌的Willow实现了错误率的指数级降低——</p>
  <p><strong>首次达成“低于阈值”的里程碑成就。</strong></p>
  <p>Google Quantum AI的创始人&amp;负责人Hartmut Neven对此进一步解释说：</p>
  <blockquote>
   <p>作为第一个低于阈值的系统，这是迄今为止最令人信服的可扩展逻辑量子比特原型。</p>
   <p>这项成果表明，有用的、规模非常大的量子计算机真的可以造出来。</p>
   <p>Willow让我们更接近用量子计算机运行实用的、与商业相关的算法，并且这些算法是无法用经典计算机解决的。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_9c7374a8830c41b6a983918dcccf27b8@000000_oswg75947oswg1080oswg596_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>具体来说，谷歌在两个超导量子处理器上实现了低于阈值的表面码量子存储器：</p>
  <p>72量子比特处理器，表面码码距为5；</p>
  <p>105量子比特处理器，表面码码距为7。</p>
  <p>表面码是指一种基于二维阵列结构的量子纠错编码方案。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_802d831f1fb04863b6474116d2be541a@000000_oswg357822oswg1080oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一方面，Willow的量子比特数达到<strong>105</strong>，相较之下，谷歌此前达成量子优越性成就的“悬铃木”仅包含53个量子比特。</p>
  <p>另一方面，更重要的是，随着他们将表面码从码距3扩展到码距5、7时，通过增加物理量子比特，谷歌实现了逻辑量子比特错误率的指数级下降。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_4680d97c004944b099366cdb3b1cfa99@000000_oswg135645oswg1080oswg570_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>同时，研究人员提到，Willow中逻辑量子比特的寿命比组成它们的量子比特寿命要长得多，能达到2.4±0.3倍。</p>
  <p>这就意味着，通过正确的纠错技术，量子计算机可以随着规模的扩大，以越来越高的精度进行计算。这为实现大规模容错量子计算奠定了基础。</p>
  <blockquote>
   <p>这里附上有关“逻辑量子比特”和“物理量子比特”的背景小知识：</p>
   <p>物理量子比特是量子计算机中实际的硬件组成，通常由超导电路、离子阱、光子等物理系统实现。</p>
   <p>逻辑量子比特是由多个物理量子比特通过量子纠错编码构成的抽象信息单元，不直接对应物理组件。</p>
  </blockquote>
  <p>研究人员采用随机电路采样（RCS）基准来测试Willow的性能——对，还是当时用来评价悬铃木的那一套。</p>
  <p>Willow的表现是：<strong>在5分钟内，完成了现今最快的超级计算机之一需要10²⁵年才能完成的计算</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0d630c8978c844788f9a798c757ba92f@000000_oswg205973oswg1080oswg828_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Nature对此的评价是：目前的量子计算机对于大多数商业和科学应用来说太小且太容易出错，现在，Willow达成了构建足够明确、有用的量子计算机的关键里程碑。</p>
  <p>以下是Willow的关键规格表：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_dfeef4f9b37c4829a272b57ea30c5c84@000000_oswg425591oswg714oswg1344_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过，需要说明的是，<strong>Willow依然没有在实际应用测试中展现超越经典计算机的能力</strong>。</p>
  <p>除了RCS基准测试之外，研究人员也在该系统中做了其他实验模拟，但这些实验结果仍然没有超出经典计算机的能力范围。</p>
  <p>值得注意的是，这张路线图横轴以“商业相关性”为坐标，量子机器学习、量子化学模拟被划分在最有可能商业应用的象限。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0615aff7fa2c4000ac090d2ae2339b66@000000_oswg330939oswg1080oswg668_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>网友就“平行宇宙”展开热议</strong></h2>
  <p>还有一点引起网友关注的是，谷歌的官方Blog介绍中有提到：</p>
  <blockquote>
   <p>Willow在不到五分钟的时间内完成了一项计算，而今天最快的超级计算机则需要10²⁵年。如果要写出来，那就是10000000000000000000000000年。</p>
   <p>这个令人难以置信的数字超出了物理学中已知的时间尺度，远远超过了宇宙的年龄。</p>
   <p>它为量子计算发生在许多平行宇宙中的观点提供了支持，这与David Deutsch所预测的“我们生活在多元宇宙”的观点一致。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_f467153fa43b4b43bd7fca43bd084731@000000_oswg89565oswg1080oswg228_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>看到这段话，网友们也感到很惊讶：</p>
  <blockquote>
   <p>量子计算领域的人真的认为我们是在从其它宇宙借用计算能力来完成这些计算吗？</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_8629f38f02954143b7f81de1312f7957@000000_oswg176339oswg1080oswg386_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有网友表示，论文中并没有类似的表述：</p>
  <blockquote>
   <p>在Blog中这样说，只是为了炒作。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_450fc8937f984a4fbc5a71bfba1d041c@000000_oswg259254oswg1080oswg419_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也有网友反对这种说法：</p>
  <blockquote>
   <p>量子计算在多个宇宙中完成，这是量子计算之父David Deutsch提出来的解释。他发明了量子计算机的概念来检验平行宇宙的想法。</p>
   <p>如果你对从无中产生一个宇宙没有异议，那么你也应该能够很好地处理平行宇宙。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0249f0d3f53647529ea9d5ebfd54d137@000000_oswg296135oswg1080oswg510_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随后有更多人加入到这场讨论中来，一时间，大伙儿对此展开热烈讨论。</p>
  <p>但正如网友所说，无论如何，目前尚无科学方法来证伪或证实。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_4a8a3c87edfc457db06cd2ee6775749e@000000_oswg212087oswg1080oswg364_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_3068666565b141ad8046156dc99453c8@000000_oswg81999oswg228oswg228_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>关于Google Quantum AI</strong></h2>
  <p>这项具有突破性的研究，论文署名为Google Quantum AI及其合作者，包括但不限于：</p>
  <p>Google Quantum AI团队创始人兼负责人Hartmut Neven、量子计算理论首席科学家Sergio Boixo等，其中还有不少华人学者的身影。</p>
  <p>完整名单如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_7eb41ee80fd14a0e80e752f703bbdc34@000000_oswg403647oswg1080oswg1156_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Google Quantum AI 2012年成立，他们使命是为当前无法解决的问题构建量子计算。</p>
  <p>其量子计算方法涵盖了从量子处理器、控制和解码硬件、低温恒温器到操作系统和用户界面软件等所有硬件和软件组件的无缝整合。</p>
  <p>团队也是一个硬件+软件的多元化、多学科团队。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_eba02ef5ce02434cbc85119a941dc200@000000_oswg42582oswg1080oswg141_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>创始人兼负责人Hartmut Neven，于1996年获得波鸿鲁尔大学的博士学位，曾是南加州大学计算机科学和理论神经科学的研究教授。</p>
  <p>加入谷歌前，Neven曾共同创立了两家公司——Eyematic和Neven Vision，均有关于面部识别技术；加入谷歌后，担任谷歌视觉搜索团队负责人。</p>
  <p>2006年，Neven开始探索一个新的idea——用量子计算来加快机器学习的速度，之后催生了谷歌AI量子团队。</p>
  <p>Neven也是“Neven定律”的提出者。该定律认为，量子计算机解决某些特定问题的速度将以双指数的速度提升，这一速度远超过传统计算机在相同问题上通过摩尔定律提升的速度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_c52430dca18a4c57b662252e7297b5dd@000000_oswg177217oswg408oswg408_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>在量子计算上，谷歌的攻坚是一场从零开始的科研马拉松。</p>
  <p>Neven 2012年共同创立了谷歌AI量子团队后，2014年，美国物理学会院士John Martinis加入了谷歌，担任谷歌量子硬件首席科学家，领导构建量子计算机的工作。</p>
  <p>再两年后，量子计算理论首席科学家Sergio Boixo在Nature Communications上发表了相关论文，最终将团队的工作重点聚焦到了量子优势性计算任务上来。</p>
  <p>但即便对于谷歌这样的明星团队来说，这项工作也一样是巨大的挑战。</p>
  <p>直到2019年，谷歌首次实现量子优越性Quantum Supremacy，轰动圈内外。</p>
  <p>就是那个<strong>量子计算200秒=地球最强超算1万年</strong>的突破，53个量子比特的处理器Sycamore在200秒内，完成了超级计算机需要1万年才能算完的任务。</p>
  <p>论文直接登上Nature 150周年纪念特刊、各大主流媒体头版头条、热度全网第一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_77f9dad256374f81a892737099588f88@000000_oswg1528873oswg776oswg1036_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之后，Hartmut Neven又带领团队进行持续性研究，一箩筐研究被Nature、Science等各大顶刊收录。</p>
  <p>如今，Willow的发布再给大伙儿带来了亿点点震撼。</p>
  <p>参考链接：</p>
  <p>[1]https://blog.google/technology/research/google-willow-quantum-chip/</p>
  <p>[2]https://www.nature.com/articles/d41586-024-04028-3</p>
  <p>[3]https://www.nature.com/articles/s41586-024-08449-y</p>
  <p>[4]https://news.ycombinator.com/item?id=42367649</p>
  <p>[5]https://x.com/elonmusk/status/1866170803051499874</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247766083&amp;idx=1&amp;sn=cead00c2a47f6b4823626065da85cdcc&amp;chksm=e91cd6044e3484c6420867851ea781c36e928fa4bf67d9cbfe27f8caf93b826fe5febc96a828&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID：QbitAI）</a>，作者：鱼羊 西风，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3072747319571329</id>
            <title>硅谷 1/10 程序员在摸鱼？拿20-30万美元年薪却几乎不干活</title>
            <link>https://www.36kr.com/p/3072747319571329</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3072747319571329</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 08:25:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 软件工程师, 摸鱼, 生产力, 企业文化  
<br><br>  
总结: 斯坦福商学院研究员Yegor Denisov-Blanch分析了全球数百家企业程序员的生产力数据，发现约9.5%的软件工程师几乎不做正事，被称为“摸鱼工程师”。这些工程师的低产出与企业文化不满有关，且在远程办公环境中更为普遍。研究显示，大企业更容易出现此类现象，部分工程师在工作中感到沮丧，导致主动选择消极应对。Denisov-Blanch的研究旨在揭示问题背后的原因，而非单纯曝光偷懒行为。 </div>
                        <hr>
                    
                    <p>来自斯坦福商学院的研究员 Yegor Denisov-Blanch 最近几周，一直在跟“摸鱼程序员”交流。这位 32 岁的研究员前阵子在网上发布了对全球数百家企业程序员生产力数据的分析结果，消息一出就激起了强烈反响与讨论热潮。</p>
  <p>Denisov-Blanch 在 X 上发帖称，约有“<strong>9.5% 的软件工程师几乎什么正事也不做</strong>”。他们贡献的代码量极少，不禁让人怀疑他们要么在偷懒、要么是偷偷在搞开发副业。他还把这些吃白食的技术人称为“幽灵工程师”——即“摸鱼工程师”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_60f6193b1c3b48c1b2f8c6267a46e881@46958_oswg624516oswg868oswg1306_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在发出的帖子被浏览了<strong>近 400 万次</strong>之后，一群自称是“摸鱼工程师”的人主动联系了 Denisov-Blanch。据《华盛顿时报》报道，从他们往来的电子邮件来看，这些被抨击者先是自我辩护、而后反过来抨击 Denisov-Blanch，最后则陷入愤怒。当然，<strong>他们也承认自己摆烂主要是对企业文化不满，而且声称这并不是自己的错</strong>。</p>
  <p>硅谷投资者 Deedy Das 在其 X 帖子中提到，“每个人都觉得这是在夸大其词，但确实有不少软件工程师……我就认识一些，他们每月只修改一、两次代码，发送几封电子邮件，参加几次会议。他们远程办公，每周工作时间加起来不足 5 个小时，年薪却能达到 20 万到 30 万美元。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_ffb00aca87ae45628593cc2b1666f7af@46958_oswg170562oswg1080oswg372_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Das 还列出了 13 家广泛存在此类问题的公司，包括网络巨头思科和云计算巨头 Salesforce。他还具体介绍了那帮“摸鱼工程师”躺平摆烂的一系列技巧和窍门，例如在办公场所的聊天应用中显示“正在开会”状态，并使用低成本的鼠标移动器来假装他们在持续操作。</p>
  <p>Box 公司 CEO Aaron Levie 当天早上看到了这篇帖子，这家企业也在 Das 列举的“黑名单”之上。当天晚上，他在 X 上回复道“这真是颇有建设性的一天。”</p>
  <p>在接受媒体采访时，Levie 表示虽然自己没有立即解雇任何员工，但 <strong>网上的讨论启发了该公司领导层，让他们在正着手解决的问题上有了新的思路</strong>。</p>
  <p>过去四年之间，随着远程办公在科技行业蓬勃发展，Box 公司开始专注于在工程师之外、努力量化全体员工的生产力水平。Levie 指出，<strong>Box 已经精简了团队，希望避免职责重叠、减少会议并加大对研发成果的审查力度</strong>。</p>
  <h2><strong>评估研发生产力的方式是否合理&nbsp;</strong></h2>
  <p>Denisov-Blanch 在受访中表示，自己并不是要刻意曝光科技界这种吃空饷的情况。</p>
  <p>但在开发出一种机器学习算法之后，他意外地发现这一问题相当普遍且严重。该算法模型可以分析公司的代码 commit 情况以分析程序员们的工作效率。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_7a1b0d004f53486ea3cdafe2fad8afd4@46958_oswg510474oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>该算法由 Denisov-Blanch 与斯坦福大学组织心理学副教授 Michal Kosinski 以及企业家 Simon Obstbaum（动漫流媒体服务商 Crunchyroll 的前任首席技术官）合作构思而成。</p>
  <p>从另一个角度出发，Denisov-Blanch 表示也可以通过统计代码提交次数来衡量活跃度。虽然这并不是一种完美的生产力指标，但它确实揭示了不活跃的现象：“大约有 58% 的人每月提交不到 3 次代码，这与我们的指标相符。另有约 42% 的人只进行了极为微小的改动，例如改动一行代码甚至一个字符，看上去就像是在‘装样子地工作’。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241210/v2_0e0d7a7141c04293b6dadfb2c7634818@46958_oswg120884oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其统计显示，“摸鱼工程师”几乎没有实际工作量，其产出水平不到全球中位数的 0.1 倍。</p>
  <p>不过，Denisov-Blanch 的统计方式与标准引发了不少质疑。有批评者认为，<strong>这 9.5% 的“摸鱼工程师”未必真的毫无产出</strong>，他们可能在从事架构设计、项目管理或其他非以编码为主的工作。同时也有人提出疑问：该衡量标准是否过于单一，只关注代码提交量，而 <strong>忽略文档撰写、指导新人、代码审查等其他重要但不直接以代码行数体现的工作内容</strong>。</p>
  <p>面对这些质疑，Denisov-Blanch 的回应是，这 9.5% 的人基本上“什么也不做”。他和团队尝试 <strong>剔除了主要职责并非编程的人</strong>，但依旧可能有少数例外。就数据集而言，他们主要面向的是独立贡献者型的软件工程师（不包括管理岗），以求尽可能排除非编码角色的影响。</p>
  <h2><strong>从斗志满满到消极摸鱼&nbsp;</strong></h2>
  <p>研究团队的数据显示，大企业更容易受到“摸鱼工程师”的影响，但小公司往往也不能幸免。</p>
  <p>斯坦福教授 Kosinski 在采访中表示，由于不少大型科技企业的工作复杂且流程繁琐，因此很难对工程师们的工作效率做出确切评估。</p>
  <p>斯坦福大学的这项研究，是在众多大型科技企业取消疫情期间制定的远程办公政策之际进行的。今年以来，谷歌、亚马逊、Meta 和微软等巨头均经历了一波波裁员潮。从今年 1 月起，亚马逊希望其员工每周五天都能在办公室工作。SAP、AT&amp;T、戴尔和 Zoom 等公司也都取消了更加灵活的远程办公政策。</p>
  <p>Denisov-Blanch 表示，这次研究还发现，虽然表现出色的程序员们更倾向于在家办公，但<strong>远程办公的灵活环境也是“摸鱼工程师”泛滥的重灾区</strong>。在完全远程的团队中，“摸鱼”比例高达 14%；对比之下，每周至少有几天进办公室的群体这一比例仅为 9%，而天天到岗的则降至 6%。</p>
  <p>在他看来，“摸鱼工程师”并不是精于算计的人，他们更像是在碰壁后选择消极应对。通过与数十位“摸鱼工程师”进行邮件交流后，他发现这些人 <strong>普遍对工作感到沮丧，因为他们在努力与回报之间看不到清晰的关联</strong>，久而久之便失去了干劲，表现也不断走下坡路。</p>
  <p>更糟糕的是，这种低产出状态从起初的无奈演变为一种主动策略。他们会在日历上故意留出“忙碌”时段，或是假装有繁重的工作要处理，让管理者难以分辨真相，进而继续浑水摸鱼。</p>
  <p>Sudheer Bandaru 在管理一家中型企业的工程团队时也遇到过类似的状况。他在电话采访中透露，绩效评估时，那些在会议上能说会道、显得特别聪明的工程师却几乎没有实际代码产出。“这实在太令人吃惊了。”</p>
  <p>进一步单独沟通后，Bandaru 才发现这名工程师并非故意偷懒，而是弄错了自己的角色定位。“他以为自己是搞研究的，不需要一直对着屏幕写代码。”调整岗位后，这名员工很快发挥出应有的价值。这段经历也促使 Bandaru 开发了 Hivel，一款帮助企业加快软件开发效率的分析平台。</p>
  <p>从积极的角度看，如果使用得当，这类专门用于监测技术人员产出的“捉鬼”软件，确实能帮助企业优化管理。</p>
  <p>Denisov-Blanch 透露，他和研究团队设计的算法后续会关注整体代码库的影响，从而避免片面衡量。随着投资者对这项技术的兴趣升温，他正在探索如何将其商业化。未来或许有公司会借此工具迅速识别那些“混吃等死”的员工。</p>
  <p>不过，他也强调说，他的初衷不是为了揪出谁在偷懒，而是搞清楚这背后的原因，从根本上阻止企业被这种消极氛围所吞噬。</p>
  <p><strong>参考链接：</strong></p>
  <p>https://www.washingtonpost.com/technology/2024/12/08/ghost-engineers-programming-productivity-coding/</p>
  <p>https://x.com/yegordb/status/1859291022863499700</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/4IMl05nQaMchV1j8yWNbQA" rel="noopener noreferrer nofollow" target="_blank">“InfoQ”</a>，编译：核子可乐、燕珊&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>