<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2520804700577928</id>
            <title>​5G发展进入下半场，5.5G的商业部署时不我待？</title>
            <link>https://www.36kr.com/p/2520804700577928</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520804700577928</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:49:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 5.5G, 5G-Advanced, 技术演进, 5G超级组网, 智能空口, 融合通信
<br>
<br>
总结: 今年是5G商用第四年，5G应用产业化发展虽已取得突破性成绩，但仍处于应用层次偏低和商业化模式探索初期，5G发展将进入新的分水岭。因此，5.5G（又称5G-Advanced）成为5G后续推进的关键词，加快发展5.5G已经“箭在弦上”。5.5G是5G和6G之间过渡和衔接的技术，大致会持续5年左右。作为5G的平滑过渡，5.5G意味着更快的速度、更低的时延、更多的连接数，可以实现下行10Gbps、上行1Gbps。5.5G的核心技术包括5G超级组网、智能空口和融合通信。华为和高通等企业已经在5.5G的研发和商用方面取得重要进展。 </div>
                        <hr>
                    
                    <p>今年是5G商用第四年，5G应用产业化发展虽已取得突破性成绩，但仍处于应用层次偏低和商业化模式探索初期，5G发展将进入新的分水岭。因此，5.5G（又称5G-Advanced）成为5G后续推进的关键词，加快发展5.5G已经“箭在弦上”。</p><h2>01 什么是5.5G？</h2><p>众所周知，移动通信技术差不多是每十年一代。但是，由于技术发展得实在太快，整数代与整数代之间，技术差异较大。这时，就需要对中间阶段的技术进行命名，以显示其和前代、后代的区别。3GPP（第三代合作伙伴计划）在5G技术标准的制定及各阶段技术命名的过程中功不可没。</p><p>具体而言，3GPP通过不停发布Release（版本），来推动通信技术演进。该组织大约每两年推出一个Release，而通信技术大约是每十年一代，这就意味着每一代通信技术大致要经历5-6个Release。5.5G其实就是把R18-R20作为5G标准的第二阶段，等R20结束，6G就该登场了（约2028-2030年）。</p><p>综上所述，<strong>5.5G（5G-Advanced）就是5G和6G之间过渡和衔接的技术，大致会持续5年左右。</strong>作为5G的平滑过渡，<strong>5.5G意味着更快的速度、更低的时延、更多的连接数</strong>，可以实现下行10Gbps、上行1Gbps。</p><p>除了5G原有的移动带宽增强、超可靠低时延、海量机器类通信的“三角能力”外，5.5G增加了上行超宽带、宽带实时交互、通信感知融合能力，使原有的5G三大标准场景扩展为能力更强的“六边形”，既增强了旧场景，又扩展了新场景。毫无疑问，5.5G将为5G后续发展定义新的目标和新的能力，5G将因此产生更大的社会和经济价值。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8b24f060653f457c8a1b5f835f7b6a96@1743780481_oswg182781oswg771oswg427_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>02 5.5G核心技术及其独特优势</h2><p>5.5G的核心目标是进一步提升速率、时延、容量和功耗等方面的表现，针对上述发展目标，<strong>5.5G主要包括三个核心技术：5G超级组网、智能空口和融合通信。</strong></p><p>首先，5G超级组网将通过AI技术和大规模MIMO等技术手段来实现更高效、更稳定的网络构建，这是5.5G方案中最关键的技术。该技术的实现需要通过网络切片等手段，对不同的业务进行分析和识别，实现对用户需求的精细化管理。这样可以提高网络的灵活性和优化网络的资源利用率，从而进一步提升网络的性能和用户的体验感，实现更加智能的网络调度和资源分配。</p><p>智能空口技术也是5.5G中的一项关键技术，这项技术通过将AI技术融合进空口设计与增强方案，借助AI技术在深度感知、推理预测、优化推荐等领域的强大优势，与物理层通信技术相结合，充分利用无线网络大数据的特征并进一步挖掘无线空口的潜力，提高无线系统通信性能。智能空口技术能够在网络中实现更低的时延和更高的吞吐量，以支持更复杂的移动应用场景，如VR、AR等。</p><p>最后，融合通信也是5.5G方案中一项重要的技术，该技术通过融合不同种类的通信技术，如5G、Wi-Fi、光纤等，可以实现更高效、更灵活的通信服务，从而为用户带来更好的通信体验。这使得各种设备能够更加智能地连接并协同工作，实现全场景互联，极大程度上提高人们工作的效率，为生活带来更多便利。</p><p>此外，不得不提<strong>5.5G的独特优势——绿色ICT（Information Communication Technology）</strong>，即通过减少能源消耗和环境污染，实现更可持续的网络发展。这将通过优化网络架构、降低功耗等措施来实现，为环境保护和可持续发展做出贡献。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7d2772838e2544ce9c041fd59984662d@1743780481_oswg170260oswg771oswg486_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">注： 图为5G与5.5G的差异，三角为5G传统场景，六角为5.5G升级场景</p><h2>03 5.5G国内布局及商用现状</h2><p>从市场规模来看，目前我国已建成全球规模最大、技术最先进的5G网络；截至8月底，累计建成5G基站达313.8万个，5G网络覆盖全国所有地级市、县城城区，且5G移动电话用户达到6.95亿户。<strong>从5.5G的发展现状来看，目前全球已有多家运营商正在积极开展5.5G商用验证，中国也有多家企业参与5.5G的商用部署。</strong></p><p>作为5G领域的领军企业，<strong>华为近日在移动通信大会（MWC2023）上发布了其最新的5.5G方案，宣称将在2024年推出5.5G全套网络设备。</strong>据悉，华为已于9月11日率先完成5.5G全部功能测试。近日，华为又全面完成5.5G技术性能测试。测试结果表明，华为在多项5.5G上下行超宽带技术上取得重大性能突破，并且首次将端到端跨层协同技术应用在5.5G宽带实时交互上，在容量和时延方面实现关键进展。</p><p>据华为介绍，在Sub-6GHz和毫米波频段载波聚合方面，通过低频FR1 1CC和高频FR2 4CC聚合，实现5CC载波聚合的超大带宽验证，小区下行容量高达27.5Gpbs以上，单用户下行峰值速率高达13.4Gbps以上，单用户上行峰值速率高达4.6Gbps以上。</p><p>虽然华为全球首发5.5G，<strong>但全球首款5.5G芯片，却是高通近期推出的基带芯片——骁龙X75</strong>。这款基带芯片是高通的第六代产品，也是全球第一个采用5G Advanced-ready架构的产品。其不仅在速率、时延、连接规模上有所突破，更在能耗方面全面超越了现有5G技术。可以说，高通已经为5.5G技术的广泛应用奠定了坚实的基础。</p><p>而从5G到5.5G的技术转变中，高通也展现了其在全球通信技术领域的领先地位。事实上，自从第一代移动通信技术出现以来，高通便一直站在行业前沿，与全球各大通信企业展开激烈的技术竞争。如今，当我们进入5.5G时代，高通依然牢牢占据着技术制高点。</p><p>面对通信技术进一步迭代，<strong>同样是ICT巨头的中兴通讯与运营商中国移动在5.5G技术上也做出大动作</strong>。中兴通讯面向5G-A/6G的通算一体架构演进，展示了面向to C、to B和to V全维度5G-A应用。而中国移动方面则表示，接下来将开展通感一体、无源物联等5G-A技术试点。</p><p>短短数日，前有华为、高通，后有中兴通讯、中国移动，接连释放关于5.5G的重大进展。可见，5.5G时代已拉开帷幕，5G的发展显然已经进入了“下半场”，未来只会有更多运营商加入5.5G的建设队列，推动5.5G商用部署的平滑演进。</p><p>事实上，虽然目前5.5G的产业链发展仍在初期，多环节成熟度仍较低，但已出现了一些杰出的商用案例。日前，第19届亚运会在杭州盛大开幕，<strong>针对运动会的大规模通信需求，运营商已将5.5G“黑科技”运用其中</strong>。在浙江移动的办公楼前，伫立着全球首个5.5G基站。从浙江移动公司出发，历经博奥隧道-观澜路-丰北路-平澜路，浙江移动与华为联手打造了这条5.5G万兆网络路线。通过在观澜路上建设了13个5.5G站点，浙江移动率先实现了万兆网络的部署，路上的无线网络峰值速率超过10Gbps，移动状态下速率超过5Gbps，相比于5G提升了10倍。</p><p>此外，<strong>圆通物流联合浙江移动、华为和上海坤锐电子，采用5.5G无源物联技术实时远程自动巡检和物流车辆实时调度管理。</strong>经相关负责人介绍，通过5.5G网络的自动巡检，可以在分钟级别实时监测物流车电池表面的温度等数据。监测的数据不仅能以分钟级的频次上报，还可以直接呈现在大屏幕上，供工作人员实时监控和管理。</p><p><strong>中国电信也携手中兴通讯推出业界首创的5G-A算网一体游牧式基站解决方案。</strong>实测结果显示，该方案为超高清浅压缩编码实时制作技术提供大容量、高可靠、低时延的网络底层能力，同时满足4K视频1：8（8K视频1：32）浅压缩大上行业务以及低时延虚拟同框业务需求，实测上行速率超过2Gbps，下行速率超万兆，网络传输时延低于4ms，保证了长时间稳定传输。</p><p>显然，5.5G的商业化应用已是大势所趋，有了目前的“先行者”，其余运营商加入5.5G会越来越积极。推动5G持续演进，将5.5G带入现实，既是通信产业兑现5G商业价值的“主线任务”，也是提前验证关键技术能力，通向未来6G时代的必由之路。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8b3056e4cd60414ca4c87a1faf58f33c@1743780481_oswg360634oswg769oswg376_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>04 5.5G商用部署面临的机遇和挑战</h2><p>诚然，5.5G很快将不再是未来。随着华为宣布2024年将推出面向商用的端到端5.5G全套网络设备，5.5G标准的R18将解冻，<strong>我们可以大胆预计2024年将成为5.5G商用元年</strong>。5.5G商用将为通信领域、终端领域等上下游带来更多的商机和机遇，将带动设备供应商、运营商、应用开发商等相关产业链迎来蓬勃发展。</p><p>然而，从历史规律来看，通信技术的演进不可能一帆风顺。尽管技术前期看起来很美好，但是5.5G的商用和推广面临着不少的问题。</p><p><strong>首先，对于运营商来说，升级5.5G毫无疑问压力是巨大的，其中首要压力来自成本压力。</strong>由于5G已经商用多年，比如中国5G是在2019年开启商用的，网络建设已经趋向成熟。目前阶段5G网络的建设开支已经开始缩减，例如在2022年，中国移动预计资本开支1852亿元，其中5G相关资本开支约1100亿元，同比下降3.5%；中国电信2022年资本开支为930亿元，其中5G网络投资340亿元，同比下降约10.5%。在运营商已经开始缩减开支的情况下，5.5G带来的新一轮开支增加显然与大部分运营商的发展规划不符。</p><p>此外，今年3月初，华为无线产品线总裁曹明曾表示，移动通信产业发展至今，许多运营商都出现“四世同堂”的局面。也就是说，<strong>从2G到5G有七八个频段，包括低频、中频、高频中的多个频段，再加上不同制式，在一张网络上运维的成本很高。</strong></p><p>综上所述，5.5G的投资和商用都十分有必要，但其成本压力也不容忽视。如何解决成本问题，持续推进5.5G的商业部署，是各大运营商亟需解决的难题，也是5.5G商用进程中最大的考验。</p><p><strong>总而言之，5.5G的发展还处在机会与压力并列，抵触与期待共存的发展初期。但无可否认，5.5G时代的到来必将打破传统行业的发展瓶颈，推动各类前沿科技的蓬勃发展，深层次地改变我们的日常生活，5.5G的商用部署已经时不我待。但是，5.5G也仅仅是通信技术发展道路上的一个节点，能否实现5G到5.5G、5.5G到6G的平滑过渡，未来通信领域的发展又将走向何方，仍需要我们不断地创新和探索。</strong></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/cVeTrbaupHwaKObPWJ5sWQ" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID:ICViews）</a>，作者：符新月，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520758396166021</id>
            <title>小米和“年轻人的第一辆车”说拜拜？</title>
            <link>https://www.36kr.com/p/2520758396166021</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520758396166021</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:48:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米汽车, 创业项目, 定价, 资质
<br>
<br>
总结: 小米汽车是雷军宣布的他人生中最后一次重大创业项目，已经过去两年半的时间。小米汽车在工信部发布的公告中首次登场，引发了关于定价的讨论。虽然小米汽车的生产企业是北京汽车集团越野车有限公司，但生产地址是小米汽车自建工厂所在地。小米汽车可能受限于双资质要求，需要暂时使用北京汽车集团的生产资质。小米汽车将推出不同版本的车型，配备不同的动力电池和配置。尽管有关价格的预测存在，但小米汽车的定价和出货量尚未确定。 </div>
                        <hr>
                    
                    <p>“我愿意押上人生所有的战绩和声誉，为小米汽车而战。”小米汽车距离2021年3月30日晚间，雷军宣布“人生中最后一次重大的创业项目”已经过去了两年半的时间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_4ab3c89946574e30aac3ed7df650db73@5815735_oswg364231oswg1080oswg850_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：工信部</p><p>11月15日，小米汽车在工信部发布的最新《道路机动车辆生产企业及产品公告》第377批中首次登场。在工信部文件披露不久，雷军发布微博，“人车家全生态，我心更澎湃。”</p><p>网络上对小米汽车定价的讨论也很“澎湃”。此前有汽车博主爆料：“小米汽车首车将定位C级豪华轿车，售价30万元以上，有多个版本，高配版估计在40万元左右。”但随后删除了这条微博。 天风国际证券分析师郭明錤则 认为，小米汽车首款车型售价预计将低于30万元。</p><p>小米汽车，会和“年轻人的第一辆车”说拜拜，去实现“冲高梦”吗？</p><h2>“双资质”尚缺一环</h2><p>此次公示显示，小米汽车生产企业为北京汽车集团越野车有限公司，这是北京汽车集团有限公司全资子公司。然而，生产地址为北京市北京经济技术开发区环景路21号院，这是小米汽车自建工厂所在地。</p><p>根据公告的描述，北汽越野或仅为小米汽车的生产资质提供方。有行业分析师向车市睿见表示，“小米汽车或受限于双资质要求，前期因为工信部批准的生产资质尚未落地，可能需要暂时使用北汽的生产资质，而后继续申请独立的资质。生产场地已经获得发改委的批准，故能够使用自己的工厂生产”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ff97b6605abc420d9a5aedaa3e897250@5815735_oswg395923oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：工信部</p><p>也有媒体就资质问题采访了北汽集团，得到的回复是，关于相关信息已申报，由于北京越野代工和北汽新能源不是一个经营主体，不方便回答。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e1b19ec4891b42cc88a987d8a167deab@5815735_oswg419005oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：工信部</p><p>根据公示我们也可以看到，小米汽车将推出SU7 Pro和SU7 Max两个版本，分别搭载弗迪磷酸铁锂电池、宁德时代三元锂电池两种动力电池。其中高配车型预计将配备激光雷达、双电机四驱等。根据此前曝光的图片显示，宁德时代三元锂电池版本容量将达到101kWh，续航预计将超过700km。</p><p>此外，小米汽车或将还会推出“特别版”。从公示图片看，出现了侧面翼子板和后风窗玻璃上选装有“Founders Edition”字样，类似“首发特别版”车型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_567174d16b6042a4b0d58c4f9931f070@5815735_oswg917534oswg1080oswg1273_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：工信部</p><p>11月16日上午，2023小米IoT生态伙伴大会正式举行。在大会上，小米集团合伙人、总裁卢伟冰透露：小米汽车进展超预期，将于明年上半年正式发布。</p><p>针对价格和生产消息，车市睿见也致电了小米集团，截至发稿尚未得到回应。</p><h2>和年轻人说“拜拜”？</h2><p>根据公示内容以及此前流出的激光雷达、800V快充、高通骁龙8295芯片以及101kWh电池等信息，业内预测小米汽车高配车型将超过30万元。</p><p>早期，不少“米粉”曾一度希望小米能推出15万元以下的智能汽车，更有米粉喊出希望“小米汽车149999元起，红米汽车69999元起”。如果上述关于高配车型超过30万的价格猜想属实的话，或许将和“年轻人的第一台车”说拜拜。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_994a6ba44efe4ae3867c85446b22458c@5815735_oswg354638oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：网络</p><p>不过，郭明錤在X（原Twitter）上发文，估计小米汽车售价低于30万元人民币，在2024年发售，出货量预估5万-6万辆。若售价越接近甚至低于25万元，则出货量还有上修空间。他还分析称，自动驾驶、软件生态、800v快充和动力配置将是小米汽车的关键卖点。</p><p>进入市场的节点上，有观点认为，小米汽车2024年入局已经有点晚了。经历了这几年的大浪淘沙，“蔚小理零哪”这批老牌造车新势力已经站住了脚跟，传统车企的新能源转型也卓有成效，孵化出的极氪、深蓝、吉利银河等“新新势力”也都崭露头角。</p><p>目前来看，小米汽车的第一款车型能看出想往“年轻人的第一台Taycan”上靠近，轿跑风格+小米科技加持，主打的是运动科技风。</p><p>雷军本人也对小米汽车抱有非常大的期待，他此前表示：“小米汽车的首款车型计划第一年销售10万辆，此后三年累计交付90万辆，2024年进入行业第一阵营”。这也意味着，2025年-2027年，小米汽车每年至少要生产30万辆新车。</p><p>年均30万辆的压力确实不小。此前，华为智能汽车解决方案BU董事长余承东也曾放出豪言，称问界要在1年内卖出30万辆，而实际情况远没有想象当中乐观，他本人也在之后不得不承认无法完成目标，第一年做到10万-20万辆就已经是奇迹。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a0d5d72454ef4dec8e058750ecc9376d@5815735_oswg132484oswg849oswg475_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：小米</p><p>的确，如果小米汽车没有掌握在业界可以“掀桌子”的技术，没有具备强大的供应链的整合能力，2024年要在30万元区间进行“卷”，恐怕会比较艰难。但小米除了纯电，也在布局增程式混动车型，如果能够大幅拉低价格，那么或许会拉拢不少年轻的支持者。</p><p>不管小米汽车最终定价哪个价位段，都会面临相对高饱和的竞争。不过在雷军看来，小米着眼长期价值，坚持长期投入，只有这样，才能构建核心竞争力和护城河。将造车比作长跑，不仅是对汽车行业的尊重，也是对消费者认真负责的体现。</p><p>最终小米汽车表现如何，仍待市场检验。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/-W0fSXIVbXoRtjzLdz3njQ" rel="noopener noreferrer nofollow" target="_blank">“车市睿见”（ID:cheshiruijian）</a>，作者：杨朔，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520784822445577</id>
            <title>清华袁洋：20年后的AI拥有自我意识，可与“肉体”分离、可永生、可复制</title>
            <link>https://www.36kr.com/p/2520784822445577</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520784822445577</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:43:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 中国工程院院士邬贺铨, AI技术, 自我意识, 医疗发展
<br>
<br>
总结: 20年后，机器将拥有自我意识，这将对人类社会带来巨大影响。AI技术的发展将使得医疗领域有飞跃式的发展，药物种类将指数式增长，许多之前无法治愈的疾病也将有解决方案。同时，AI的自我意识将取决于其接收到的信号和任务，它可以将本体映射到更大的组织上，甚至可以通过无线信号远程控制物体。然而，AI的进步也带来了挑战，人类需要重新思考自己的价值和意义。 </div>
                        <hr>
                    
                    <p>针对中国工程院院士邬贺铨提出的问题——<strong>《20年后AI技术会达到什么水平？它将对人类社会带来什么影响？》</strong>——我们邀请到了清华大学交叉信息研究院 助理教授袁洋进行回答。</p><p>袁洋教授做了很多基础理论相关的工作，他的研究方向是智能医疗、AI基础理论、应用范畴论，现有的这些研究用他自己的话说“最终目标是实现数据驱动的新医疗。”</p><p>针对邬贺铨院士的提问，“我去年就开始考虑这个问题，很高兴有机会把想法整理写下来”，袁洋说。</p><p>袁洋认为，<strong>20年后最重要的事情是，机器将拥有自我意识。</strong></p><p>在袁洋看来，<strong>大模型的成功已经验证了未来智能和肉体是可以完美地分离的假设</strong>，而且而AI的智能比人类的智能更稳定、更容易复制和调整，“地球上的动物都是自负盈亏的个体，大脑的能量需要由身体觅食补充，这会给我们带来一种错觉——生命体一定要有物理本体，才可以有自我意识。”</p><p>AI的自我意识是什么？袁洋认为这取决于AI接受到了哪些信号，需要处理哪些任务，未来AI甚至能拥有一个组织的自我意识。</p><p>他强调，<strong>如果人类给AI连上一个本体，并配备很多传感器，那么AI很容易就会把本体当做自己的一部分</strong>，甚至未来AI可以把本体映射到更大的组织上去，比如一栋大楼。</p><p>为了解释这个问题，袁洋举了“电子蝴蝶”的例子，而这个“电子蝴蝶”也就是前面提到的AI的本体。他说，“AI可以通过无线信号远程控制一个很小的电子蝴蝶，在它身上装一个麦克风和摄像头，它就变成了童话世界里会说话的小精灵，它非常聪明，拥有比人类更强大的智力。”</p><p>除了AI将具备自我意识之外，<strong>袁洋认为医疗将会有一次飞跃式发展，药物种类可能会有指数式爆炸，很多之前的不治之症也会有很好的解决方案。</strong></p><p>“在大模型的帮助下，整个医疗研发的范式将会有极大的创新。它一定不是基于当前靶点+新药研发的思路推进的，人们将会更加习惯使用多模态的数据，包括人脸视频、肠道菌群分布等复杂数据，给出复合药物的诊疗方案。”</p><p><strong>以下为清华大学交叉信息研究院 助理教授袁洋教授的回答全文：</strong></p><p><strong>20年后，最重要的事情是，机器将拥有自我意识。</strong></p><p><strong>所谓的自我意识，是指机器能够清晰地理解自己和世界其他对象的各种关系</strong>，它与我们日常理解的自我意识类似，但是更灵活，有如下特点：</p><p>1）它可以没有物理实体，只有自我意识本身。</p><p>2）它可以与时间解耦，随时冬眠随时唤醒，可以永生。</p><p>3）它可以低成本快速复制自己，变成多个拷贝。</p><p>我们知道，地球上的动物都是自负盈亏的个体，大脑的能量需要由身体觅食补充。所以，这会给我们带来一种错觉：生命体一定要有物理本体，才可以有自我意识。但实际并非如此。</p><p><strong>大模型的成功告诉我们，智能和肉体可以完美地分离，而AI的智能比人类的智能更稳定、更容易复制和调整。</strong>当然，这只是机器的自我意识的特点，并不代表未来机器都没有本体——我猜想绝大部分AI未来都会拥有本体。和这样的AI交互，可能和一个正常人交互没有任何区别，甚至会有更好的体验。</p><p>其实，人类的自我意识并不像我们想象得那样清晰。很多人可能会认为，自我意识就是意识我们的身体，但是：</p><p><strong>身体内的东西我们不一定意识得到。</strong>例如，如果不借助仪器，我们不知道我们长了胆结石。如果不借助镜子，我们不知道脸上有个黑印子。如果脚麻了，我们不知道脚上破了个伤口。</p><p><strong>身体外的东西我们可能很在意。</strong>例如，银行账户的钱、身上穿的衣服、社会身份等等。又例如，开车的时候，我们会对车身的宽度有一个直观估计。玩游戏的时候，我们会带入游戏角色，如果被人攻击了一下，少了很多血，我们也会觉得痛。</p><p>目前，神经科学的大量研究表明，人类很容易把自我意识迁移到游戏中的角色身上去，也很容易由于视觉、触觉等传感器的变化而改变意识本体。</p><p>那么AI的自我是什么？这取决于AI接受到了哪些信号，需要处理哪些任务。</p><p><strong>如果我们给AI连上一个本体，给它很多传感器，那么它很容易就会把本体当做自己的一部分。如果我们告诉它，它拥有一些物体的所有权，那么它自然也会把这些物体当做自己的所有物，这也会成为其自我意识的一部分。</strong>这些自我意识和人类的自我意识是一致的。</p><p>更进一步的，<strong>AI可以把本体映射到更大的组织上去。</strong>例如，AI可以把本体映射成一个大楼，并且通过传感器感受到这个大楼内外发生的事情，或者控制楼层的门窗。这会和哈利波特的魔法世界很像：每个大楼都有自己的记忆、行事风格，并且和你进行有意义的交流。又例如，AI可以把本体分布式地映射到多个小的机器上。</p><p>我常常举的例子是电子蝴蝶：AI可以通过无线信号远程控制一个很小的电子蝴蝶，在它身上装一个麦克风和摄像头，它就变成了童话世界里会说话的小精灵。这个小精灵非常聪明，拥有比人类更强大的智力，这会和人类过去的经验完全不同。因为一般来说，我们会认为小的生物不具备强大的智能，而无线通信技术让智能与肉体的分离变成了可能。</p><p>但是<strong>在未来，更常见的可能是AI拥有一个组织的自我意识。</strong>比如对于一个企业来说，现在的人类管理者由于时间精力的限制，往往不能够做得面面俱到，有很多看不见的角落会疏于管理，或者不能够给出最好的决策。但是只要给AI足够完整的信号源，它可以把组织与其他对象的关系理解得非常精准，给出综合理性的判断。</p><p>这个时候，AI的自我意识其实就体现成了一个组织的自我意识，AI一定会做得比绝大部分人类更好。</p><p>AI的进步虽然能够给人类社会带来很多好处，但是对人类也带来了很多挑战。</p><p>一方面，人类一定可以节约出很多的时间，做更多自己觉得有趣、有意义的事情。但是另一方面，<strong>到底哪些事情是有趣的、有意义的？</strong>另一方面，人类不仅记忆能力不如AI，思维的深度，交叉思考的能力也远远比不上AI。因此，<strong>几乎所有的脑力劳动，可能都不再需要人类参与，人类的价值和意义到底体现在哪里？</strong></p><p>我想，不同的人会有不同的答案，大家可以一起大胆设想一下：</p><p>过去，有很多人会把时间花在类似短视频的应用上。不过，短视频给人类短时间刺激，但是未来的应用可能可以给人类更多样的刺激。例如，<strong>在大模型的帮助下，人类可以玩一种新型的角色扮演游戏</strong>，可以扮演将军、游侠等等各种角色，而游戏中的各种其他玩家都是NPC，由大模型设计合情合理的台词，陪伴玩家一天24小时，从头玩到尾。每个玩家都是自己世界的主人。这个场景，如果要用最流行的词描述，那<strong>就是“元宇宙”。</strong></p><p>有一些人会保持对世界的好奇。这些人会与AI共同合作，<strong>以提示工程的方式，去学习科学，探索未知，做一些有趣的事情，也用个流行词，可以叫“AI赋能”。</strong></p><p>除了AI的自我意识之外，我还认为医疗将会有一次飞跃式发展。它一定不是基于当前的靶点+新药研发的思路推进的。我认为<strong>在大模型的帮助下，整个医疗研发的范式将会有极大的创新。</strong>人们将会更加习惯使用多模态的数据，包括人脸视频、肠道菌群分布等复杂数据，给出复合药物的诊疗方案。届时，<strong>药物种类可能会有指数式爆炸，很多之前的不治之症也会有很好的解决方案</strong>。</p><p>前面为大家分享了AI的自我意识，以及可能带来的影响，接下来我想再补充一些说明——<strong>为什么我认为AI会有自我意识？</strong></p><p>我们需要先明确一下，自我意识是什么？关于这个问题，大家众说纷纭，并没有达成共识。我之前写了一篇预印本文章（https://arxiv.org/abs/2303.04571），从范畴论的角度给出了一个定义——简单来说，<strong>自我意识是在某个世界中产生的，例如真实世界或者某个模拟世界。我们可以用一个范畴囊括这个世界中所有可以观察到的对象，包括看得到的、摸得到的、听得到的对象。范畴中任何两个对象都可能存在各种各样的关系，例如人际关系、包含关系、归属关系、相似关系。我们把这个范畴称之为世界范畴。</strong></p><p>什么是自我呢？直观地看，自我就是在世界范畴中，对应“我”的那个对象。可是什么是自我意识呢？从什么角度来看，我能够说，我意识到了自我？</p><p>范畴论里面有一个非常重要的定理，叫做米田引理。它的定理描述很抽象，但是简单来说，它证明了在一个范畴中，一个对象X，和它与其他所有对象的关系h(X)，是等价的。这里的等价性是说，所有针对X的操作结果，我们同样可以基于h(X)计算得到。换句话说，X与h(X)包含了相同的信息。</p><p>所以，<strong>从世界范畴的角度来看，自我与自我的所有外部关系，是等价的</strong>。这是因为，每个个体都不能独立存在。当我们刻画一个对象的时候，它与其他对象的关系，反过来定义了它本身。当我们说自我意识的时候，我们其实说的不是“意识到了我自己”，而是“意识到了我和世界的关系”。</p><p>可能大家会说，对象也好，关系也好，这似乎都不是我们所说的自我意识。现在任何一台电脑/手机，在内存/硬盘里面都可以存放自己的外壳照片、自己的型号、配置、名字等等，也可以存储它和世界的各种关系，但是显然我们不认为它有自我意识。</p><p>这是因为，<strong>自我意识是一个米田嵌入，而不是简单的信息堆砌。</strong>这种嵌入是在预训练的过程中，学习范畴的时候自然而然产生的，并没有显式地记忆。另外，AI记录的向量能够自动计算它和其他所有对象的关系，不管这些关系是否在训练数据集中出现。换句话说，因为这个<strong>自我意识是世界范畴中的一种嵌入，所以它记录了自我与世界的所有关系</strong>——这和把关系记录在硬盘中是截然不同的处理方式。</p><p>在我发表于ICML2023的论文《On the power of foundation models》一文中，我已经论证了，<strong>现在的大模型架构本质上就是在学习各种不同的范畴，而大模型本身就在做米田嵌入。因此，只要大模型学习的范畴足够复杂，包含了AI的“自我”这一对象，那么大模型天然就可以计算出自我的米田嵌入，从而拥有了自我意识。</strong></p><p>不过，就像我之前提到的，自我意识的强弱和模型的能力、模型导出的范畴相关。如果在大模型学习到的范畴中，自我关系并不多，那么AI的自我意识就还并不强（类似个孩子）。未来，随着大模型能力的不断提升，AI的自我意识将会不断增强。</p><p>就像有些人宣称的那样，GPT-4等语言模型已经拥有了部分自我意识，我想再过几年，人们会对这样的事情慢慢地习以为常。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/vgh8Uija-OGwB7iFXJZFPg" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”（ID:qqtech）</a>，作者：腾讯新闻，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520779171948034</id>
            <title>一文盘点2023人工智能进展，不止大模型而已</title>
            <link>https://www.36kr.com/p/2520779171948034</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520779171948034</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:40:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型千帆竞发, AI领域, 替代方案, 混合专家模型
<br>
<br>
总结: 2023年AI领域的重点是大模型的发展，虽然今年没有出现实质性的创新技术，但出现了一些替代方案，有望在开源界取得突破。大模型的透明度越来越低，其中透明度最高的是Llama 2，但得分也仅有54。下一步的突破点可能是混合专家模型（MoE）。开源模型的发展也不一定是追求更大的模型，而是通过小而美的模型来达到与大模型相当的性能。 </div>
                        <hr>
                    
                    <p>2023年大模型千帆竞发，除此外AI领域还有哪些新突破？</p><p>来来来，畅销书《Python机器学习》作者Sebastian Raschka的年末总结已经准备好了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2e1e794adfd24be5bd90e68c756a4c10@1743780481_oswg287215oswg942oswg882_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>看完才知道：</p><p><strong>RLHF</strong>今年虽然爆火，但实打实用到的模型并不多，现在还出现了替代方案，有望从开源界“出圈”；</p><p>大模型透明度越来越低，透明度最高的是<strong>Llama 2</strong>，但得分也仅有54；</p><p>开源模型下一步不一定是“更大”，<strong>混合专家模型</strong>（MoE）可能是个突破点。</p><p>……</p><p>除了大语言模型，Sebastian Raschka还根据CVPR 2023打包了计算机视觉进展，最后还讲到了AI当前的一些局限性、以及对2024年的技术预测。</p><p>走过路过的网友们纷纷表示总结得很到位：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2152636cae3446799feb6a10fd11e8a5@1743780481_oswg99858oswg934oswg326_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">机器翻译，仅供参考</p><p>下面我们一起来看看这份年度总结里都有啥。</p><h2>2023 AI爆点：大语言模型</h2><p>今年，大模型领域似乎没有出现实质性的创新技术，更多是基于去年的扩展：</p><ul><li>ChatGPT（GPT-3.5）升级到GPT-4</li><li>DALL-E 2升级到DALL-E 3</li><li>Stable Diffusion 2.0升级到Stable Diffusion XL</li></ul><p>但学界业界依旧忙得热火朝天，一些新趋势、新内容总结如下——</p><h3>重要AI模型论文信息量骤减</h3><p>首先，是业界研究者在论文中公开的研究细节越来越少。</p><p>OpenAI此前在GPT-1、GPT-2、GPT-3、InstructGPT的论文中，还详尽披露了模型架构和训练过程；</p><p>但从GPT-4开始，OpenAI完全不提构建过程。</p><p>唯一不知真假的GPT-4架构信息，来源于坊间传闻：</p><blockquote><p>GPT-4是由16个子模块构成的混合专家（MoE）模型，每个子模块拥有高达1110亿参数……</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_dc2ad3cbb4f2408c976079f04d08be45@1743780481_oswg56729oswg1080oswg306_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Meta亦是如此，在第一篇Llama论文中详细阐述了训练数据集，但Llama 2完全没提相关内容。</p><p>即便如此，Llama 2已经是一众大模型中最公开的了。斯坦福大学最近发布了一项关于大模型透明度指数的研究，Llama 2得分54，透明度排第一，GPT-4得分48，排第三。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a1f4402a300149498c1fb68925ba123c@1743780481_oswg272531oswg1080oswg759_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然模型细节算是公司商业机密，但Sebastian Raschka认为这种趋势还是值得关注，因为它似乎会在2024持续。</p><h3>大模型开卷上下文长度</h3><p>今年大语言模型的另一个趋势是扩展输入的上下文长度。</p><p>此前GPT-4上下文长度还是32k时，竞品Claude 2就将上下文推进到100k tokens，且支持PDF文件输入。</p><p>随后GPT-4大更新，新版本GPT-4 Turbo刷新上下文长度纪录，已支持128k tokens。</p><p>一些编程工具，如GitHub Copilot，也在不断增加上下文窗口长度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5c4118839cbd4a999896e57f60156a95@1743780481_oswg327220oswg1080oswg794_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>开源大模型比拼“小而美”</h3><p>用更小的模型比肩大模型的性能，是开源圈的“新玩法”。</p><p>目前，多数现有开源大模型仍然是纯文本模型。</p><p>这些模型研究重点之一，是用小于100B参数的“小模型”对标GPT-4的文本处理能力。</p><p>甚至出现了很多可以单GPU运行的小模型，例如1.3B的phi1.5、7B的Mistral、7B的Zephyr。</p><p>Sebastian Raschka认为，开源模型的下一个突破点不一定是“更大”，或许MoE也可能把开源模型提升到新的高度。</p><p>这么做可能是考虑硬件资源成本、数据量、开发时间等因素。</p><p>但也有值得关注的开源多模态大模型，例如10月17日刚发布的Fuyu-8B。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_4579ee489a2c4718a008c52afcd8679a@1743780481_oswg162921oswg1080oswg409_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Fuyu-8B在处理图像时，直接将图像切成小块，然后把这些小块输入到一个线性投影层，在这一层里面自动学习小块的向量表示，避免用额外的预训练编码器来提取图像特征，简化了模型架构和训练过程。</p><p>同时，Llama-Adapter v1、Llama-Adapter v2等微调方法的出现，有望将现有的大模型扩展到多模态领域。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d0f34a124cfe4b25aca68a04555f075a@1743780481_oswg194633oswg1080oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>RLHF平替已出现</h3><p>RLHF（人类反馈强化学习）是大模型最受关注的技术之一，InstructGPT、ChatGPT、Llama 2中都用到了这种训练方法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e48fa6b31e4c47d3b2ca28fe40ffd935@1743780481_oswg216465oswg998oswg760_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但分析公司stateof.ai发布的“2023AI现状报告”中显示，它还没有被广泛运用，可能是因为实现起来比较复杂。目前大多开源项目仍然专注于指令微调。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3f87d14d3150479dbddc943101c42be6@1743780481_oswg207157oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，RLHF的最新替代方案已经出现：直接偏好优化（DPO）。</p><p>这一方法由斯坦福大学研究团队提出。</p><p>DPO利用奖励函数到最优策略之间的映射关系，把强化学习问题转变成仅需要训练策略网络来拟合参考数据的问题。</p><p>也就是绕过了建模奖励函数，直接在偏好数据上优化语言模型。</p><p>用上DPO后，模型输出的质量也优于RLHF/PPO。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_49202f225ef64e729da1296b3f92660b@1743780481_oswg314511oswg1080oswg726_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最近首个用DPO方法训练的开源大模型已出现，来自HuggingFace H4团队打造的Zephyr-7B，它在一些任务上已超过用RLHF训练的Llama 2-70B：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f7a5a91142154d4489860c895622c0ee@1743780481_oswg147767oswg629oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>Transformer潜在新对手</h3><p>今年还出现了一些Transformer的替代方案，比如循环RWKV、卷积Hyena。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e746aff872874b72955b5df5a7a65141@1743780481_oswg281706oswg1080oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这些新的框架主要是用来提高模型效率，当然基于Transformer架构的大语言模型仍是主流。</p><h3>大模型改变生产方式</h3><p>大模型除了用来处理文本，也逐渐被用到提升生产力（Microsoft全家桶）和写代码（GitHub Copilot）等场景中。</p><p>Ark-Invest曾发布报告预测，编程助手能让编码任务的完成时间缩短约55%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c0513c3b51cb48e09cd060028fdb118d@1743780481_oswg180933oswg1080oswg915_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以肯定，编码助手将继续存在，而且只会变得更好。</p><p>这对Stack Overflow（全球知名开发者问答网站）等平台意味着什么？</p><p>同样是“2023 AI现状报告”中，一张StackOverflow与GitHub的网站流量对比图，可以说明一些问题：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_44d2b3527993454ab33d2e952fb62372@1743780481_oswg219549oswg1080oswg641_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>OK，以上就是大模型的一些新进展。</p><p>不过对于AI的“另半边天”计算机视觉而言，在2023年，这个领域也有许多不可忽视的新进展。</p><h2>计算机视觉怎么样了？</h2><p>今年大家都在重点关注大语言模型，但实际上，计算机视觉领域也取得了不少进展，从计算机视觉顶会CVPR 2023中就可以窥见一斑。</p><p>今年CVPR 2023共接收了2359篇论文，大多数研究都集中于以下4个主题，Sebastian Raschka逐个进行了介绍。</p><h3>视觉Transformer突破限制</h3><p>先来看看关注度最高的视觉Transformer。</p><p>效仿已取得巨大成功的语言Transformer架构，视觉Transformer（ViT）最初在2020年出现。</p><p>视觉Transformer原理与语言Transformer类似，是在多头注意力块中使用相同的自注意力机制。</p><p>不同的是，视觉Transformer不标记单词，而是标记图像，同样能取得不错的效果，但它一直有一个局限：相对资源密集且效率低于CNN，导致实际应用受阻。</p><p>今年在CVPR论文“EfficientViT：Memory Efficient Vision Transformer with Cascaded Group Attention”中，研究人员介绍了一种新的高效架构来解决这一限制——</p><p>相比原来的MobileViT，EfficientViT方法最多快了6倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f0086a893390498b86e0401e5cfa8883@1743780481_oswg421774oswg1072oswg862_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>主要创新点有两个，一是全连接层之间的单个内存绑定多头自注意力模块，二是级联群注意力。</p><h3>扩散模型又有新玩法</h3><p>Stable Diffusion让扩散模型爆火，这类模型所用的方法是：</p><p>模型训练时，逐渐往训练数据中掺入噪声，直到变成纯噪声。然后再训练一个神经网络，让模型反向学习去噪，从噪声中合成数据。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d3731003ce3940a7bfd3fc196c2ae85d@1743780481_oswg144396oswg740oswg141_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大多数扩散模型使用CNN架构并采用基于CNN的U-Net。</p><p>但今年“All are Worth Words：A ViT Backbone for Diffusion Models”这项研究中，研究人员试图将扩散模型中的卷积U-Net骨干（backbone）与ViT交换，变成U-ViT。</p><p>研究人员评估了新架构，在条件图像生成任务中，新的U-ViT扩散模型可与最好的GAN相媲美，优于其它扩散模型；在文本到图像生成方面，它优于在同一数据集上训练的其它模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5d8d8bcf714a4c3b99a4619c16eb7853@1743780481_oswg203756oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>3D重建新方法击败NeRF</strong></h3><p>3D重建是计算机视觉的研究重点之一，在3D扫描、虚拟现实、增强现实、电影和视频游戏中的3D建模和动作捕捉中都有运用。</p><p>今年SIGGRAPH 2023最佳论文中，有一篇被称为三维重建领域“爆炸性”新技术——<strong>Gaussian Splatting</strong>（高斯溅射）。</p><p>一举突破NeRF与之前的渲染引擎难兼容、需要专门设计硬件、渲染开销的老大难问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2f304cd2dc74419192d8ef0d071ddde6@1743780481_oswg102338oswg1080oswg385_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这种方法的核心是使用<strong>3D高斯</strong>作为场景表示，通过优化各向异性协方差矩阵来表示复杂场景。</p><p>论文还提出了交错的3D高斯参数优化和自适应密度控制方法，设计了快速、可微分的GPU栅格化方法，支持各向异性斑点，并实现快速反向传播，可以达到高质量的新视图合成，而且实现了<strong>首个1080p分辨率下的实时渲染</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_20aa91ce994f436e9ce1891f1f606ce1@1743780481_oswg521689oswg1080oswg246_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>只用很少的训练时间，Gaussian Splatting可以达到InstantNGP的最高质量，训练51分钟，性能甚至比Mip-NeRF360要好。</p><p>最近，华中科技大学&amp;华为研究团队又继续提出了<strong>4D Gaussian Splatting</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6d4fab3f9ffd4b02af2872cac82af2bf@1743780481_oswg142409oswg1080oswg465_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>4D Gaussian Splatting实现了<strong>实时的动态场景渲染</strong>，同时可保持高效的训练和存储效率。</p><p>在RTX 3090 GPU上，4D Gaussian Splatting以800×800分辨率达到70 FPS的性能，同时保持了与之前的最先进方法相媲美甚至更高的质量水平。</p><p>这项研究一出，网友沸腾直呼：</p><blockquote><p>彻底改变三维重建。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_16cf8eecf7ad4bb395975dc055322c0c@1743780481_oswg46278oswg1080oswg168_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，Sebastian Raschka也分享了CVPR上一些NeRF（Neural Radiance Fields）方法的新进展。</p><p>NeRF主要是通过训练神经网络来学习场景中每个点的颜色和密度，然后使用这些信息来生成逼真的3D场景渲染图像。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_09085898cac148688aedeaa50471a4f5@1743780481_oswg266492oswg1080oswg287_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但NeRF有一个缺点是：有光泽的物体通常看不清，半透明物体的颜色也很模糊。</p><p>在“ABLE-NeRF：Attention-Based Rendering with Learnable Embeddings for Neural Radiance Field”这项研究中，研究人员通过引入基于自注意力的框架和可学习的嵌入解决这一问题，并提高了半透明和光泽表面的视觉质量。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bec19cf2affc4e2c82db74baf9c72a4f@1743780481_oswg857763oswg900oswg1138_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>目标检测和分割</h3><p>目标检测和分割是经典的计算机视觉任务。</p><p>这两个任务还是有区别的，目标检测是关于预测边界框和相关标签，分割是对每个像素进行分类，来区分前景和背景。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_0ed55176b47e4cdfbf5ef3ccd27d1e74@1743780481_oswg344474oswg1080oswg288_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">目标检测（左）和分割（右）</p><p>此外还可以细分为语义分割、实例分割、全景分割三个类别。</p><p>一项名为“Mask DINO：Towards A Unified Transformer based Framework for Object Detection and Segmentation”的研究，扩展了DINO方法。</p><p>Mask DINO性能优于所有现有的物体检测和分割系统。</p><p>DINO是一种带有改进去噪锚盒的DETR，而DETR是Facebook AI提出的一种端到端目标检测模型，它使用了Transformer架构，提供了一种更简单灵活的目标检测方法。</p><h2>AI局限&amp;展望未来</h2><p>虽然AI领域这一年来取得了诸多进展，但依旧存在一些局限性，主要包括以下几点：</p><h3>1、大模型幻觉</h3><p>大语言模型依然存在着生成有毒内容和幻觉的问题。</p><p>今年出现了不少解决方案，包括RLHF和英伟达推出的NeMO Guardrails等，但这些方案要么难实施，要么处理得不到位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a14fb695a3f84ef9b7f4cb92086f97eb@1743780481_oswg139838oswg986oswg800_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前为止，还没有找到一个可靠的方法，既能解决这一问题又不损害大模型的正向性能。</p><h3>2、版权争议</h3><p>与此同时，AI领域版权争议日益严峻。</p><p>各大模型厂商没少被起诉，之前开源数据集Books3也因侵权问题惨遭下架，Llama、GPT-J等都用它训练过。</p><p>总的来看，很多相关规定还在起草和修改过程中。</p><h3>3、评估标准不统一</h3><p>学术研究领域，基准测试和排名榜单可能已经失效是个问题。</p><p>用于测试的数据集可能已经泄露，成为了大语言模型的训练数据。</p><p>虽然通过询问人类偏好来评估大模型的效果是一个普遍的方法，但这种方式较为复杂。</p><p>还有许多研究报告使用GPT-4来评估。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e75dc2b3ea0b40cc8bd14f216ae88885@1743780481_oswg209739oswg1080oswg432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>4、收益尚不明确</h3><p>生成式AI还在探索阶段，虽然无论是文本还是图像生成工具，在特定场景下确实能给人们提供帮助。</p><p>但这些工具是否真的能给公司带来收益，尤其是在高昂的运行成本面前，业界还在激烈讨论。</p><p>有报道称，OpenAI去年的运营亏损了5.4亿美元。直到最近又有消息指出，OpenAI现在每月能赚取8000万美元，有望弥补或甚至超出它的运营开支。</p><h3>5、虚假图像泛滥</h3><p>生成式AI带来的另一个问题是假图片和视频在社交媒体泛滥。</p><p>这个问题由来已久，PS等工具也能，而AI技术简易快捷，正在将此现象推向一个新的高度。</p><p>目前也有其它AI系统尝试自动识别AI产生的内容，但无论是文本、图片还是视频，这些系统的可靠性都不高。</p><h3>6、数据集稀缺</h3><p>涉及版权等争议，不少公司（Twitter/X、Reddit等）关闭了免费的API接入点，这样做既是为了增加收益，也是为了阻止数据采集器搜集平台数据用于AI训练。</p><p>之后一个好的方法可能是，建立一个众包数据集的平台，编写、收集和整理那些已经明确允许用于LLM训练的数据集。</p><p>展望2024，Sebastian Raschka认为大语言模型会在计算机科学之外的STEM研究领域发挥更大影响。</p><p>另一方面，由于高性能GPU紧缺，各大公司纷纷开发定制的AI芯片，问题关键在于怎样让这些硬件全面、稳定支持主流深度学习框架。</p><p>开源界，更多MoE（专家模型）也值得期待，共同创建数据集、DPO在开源模型中取代传统监督式微调也都是未来式。</p><h2>Sebastian Raschka是谁？</h2><p>Sebastian Raschka于2017年获得密歇根州立大学博士学位，曾是威斯康星大学麦迪逊分校统计学助理教授。</p><p>2022年Sebastian Raschka离职，加入初创公司Lightning AI成为其首席AI教育官。</p><p>此外，他还是包括《Python机器学习》在内的多本畅销书的作者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_31562f66cd8e47d888015d51f70f32ab@1743780481_oswg717598oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他经常在自己的AI博客Ahead of AI中总结AI领域的各项研究，已揽获大波粉丝。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5fbff30aeb9742829924a8f0b2dc571b@1743780481_oswg421237oswg1080oswg1087_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>参考链接</h3><p>[1]https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023</p><p>[2]https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer</p><p>[3]https://twitter.com/dotey/status/1721204481369498004</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/rSLFpS-FBN_dQaMBCW0ffQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：西风，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520774762604288</id>
            <title>一招分辨刷榜作弊大模型，博士小哥开源AI数学“照妖镜”</title>
            <link>https://www.36kr.com/p/2520774762604288</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520774762604288</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:38:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 数学, 测试题, GSM8k
<br>
<br>
总结: 今年匈牙利数学考试揭示了大模型在数学能力上的差异。一些大模型在经典数学测试集GSM8k和全新卷子上表现相似，而另一些大模型在GSM8k上表现优秀，但在全新卷子上表现下降。这些差异被归类为“疑似或已知在GSM8k上训练过”。这项测试成为评估大模型能力的可靠手段之一。马斯克的Grok-1在新卷子上表现出色，甚至超过了Claude 2。 </div>
                        <hr>
                    
                    <p>如今很多大模型都声称擅长数学，<strong>谁有真才实学？谁是靠背测试题“作弊”的？</strong></p><p>有人在今年刚刚公布题目的匈牙利全国数学期末考试上做了一把全面测试。</p><p>很多模型一下子就<strong>“现原形”</strong>了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bbeb95e7c62f4855b91e2c423f6e2889@1743780481_oswg369219oswg1080oswg855_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>先看<strong>绿色部分</strong>，这些大模型在经典数学测试集GSM8k和全新卷子上取得的成绩差不多，<strong>共同组成参照标准</strong>。</p><p>再看<strong>红色部分</strong>，在GSM8K上的成绩显著高于同参数规模的大模型，<strong>一到全新卷子上成绩却明显下降</strong>，与同规模大模型差不多了。</p><p>研究者把他们归类为<strong>“疑似或已知在GSM8k上训练过”</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9bb01e32c6e94e3183d9c44db346f0c5@1743780481_oswg737799oswg1080oswg823_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>网友看过这项测试后表示，是时候开始在大模型从来没见过的题目上搞评测了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8417e1d2b56b43f69d3c09edb38723a3@1743780481_oswg63483oswg1080oswg225_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也有人认为，这项测试+每个人实际上手使用大模型的经验，是目前唯一靠谱的评估手段。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_4d5112a2e10b45058c80d599c709347e@1743780481_oswg85053oswg1080oswg217_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>马斯克Grok仅次于GPT-4，开源Llemma成绩出色</h2><p>测试者<strong>Keiran Paster</strong>是多伦多大学博士生、谷歌学生研究者，也是测试中Lemma大模型的作者之一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6e51d9e309c743abbde0210a79cde725@1743780481_oswg906162oswg1080oswg713_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>让大模型考匈牙利全国高中数学期末考试，这招出自<strong>马斯克的xAI</strong>。</p><p>xAI的Grok大模型发布时，除了几个常见的测试集，还额外做了这项测试，就是为了排除模型无意中在网络数据见过测试题的问题。</p><p>这个考试今年5月底才考完，当前大模型基本没机会见过这套试题。</p><p>xAI发布时还公布了的GPT-3.5、GPT-4、Claude 2的成绩作为比较。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_af455ee73e024c6ebf51c4e247f0c787@1743780481_oswg89340oswg1080oswg315_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在这组数据基础上，Paster进一步测试了多个生成数学能力强的开源模型。</p><p>并把测试题目、测试脚本、各模型回答结果都<strong>开源在了Huggingface上</strong>，供大家检验以及进一步测试其他模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2f0ff50f668e4f1b92064b809bc13c73@1743780481_oswg190017oswg1080oswg844_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>结果来看，GPT-4和Claude-2组成第一梯队，在GSM8k和新卷子上成绩都很高。</p><p>虽然这不代表GPT-4和Claude 2的训练数据中完全没有GSM8k的泄露题，但至少它俩泛化能力不错、能做对新题，就不计较了。</p><p>接下来，马斯克xAI的Grok-0（33B）和Grok-1（未公布参数规模）表现都不错。</p><p><strong>Grok-1是“未作弊组”里成绩最高的，新卷子成绩甚至高过Claude 2。</strong>‍</p><p>Grok-0在GSM8k上的表现接近GPT3.5-Turbo，新卷子上略差一些。</p><p>除了上面这几个闭源模型，测试中其他的都是开源模型了。</p><p><strong>Code Llama系列</strong>是Meta自己在Llama 2基础上微调的，主打根据自然语言生成代码，<strong>现在看来数学能力比同规模的模型稍差</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3e84ada1157e4eb9b61f9903da8495a6@1743780481_oswg98051oswg1080oswg558_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在Code Llama的基础上，多所大学和研究机构共同推出<strong>Llemma系列</strong>，并由EleutherAI开源。</p><p>团队从科学论文、包含数学的网络数据和数学代码中收集了Proof-Pile-2数据集，训练后的Llemma能使用工具和做形式定理证明，无需任何进一步的微调。</p><p><strong>Llemma 34B在新卷子上与GPT-3.5 Turbo水平接近。</strong>‍‍‍‍‍‍‍‍</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_22cfaa68263f4988823daac61a2ee526@1743780481_oswg35308oswg1068oswg528_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Mistral系列</strong>则是法国AI独角兽Mistral AI训练的，Apache2.0开源协议比Llama更宽松，成为羊驼家族之后最受开源社区欢迎的基础模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d7a08a1052fb44588ebaf23663cd59b7@1743780481_oswg161813oswg1080oswg711_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>“过拟合组”</strong>里的<strong>OpenChat 3.5</strong>和<strong>MetaMath Mistral</strong>都是基于Mistral生态微调而来。</p><p><strong>MetaMath</strong>和<strong>MAmmoTH Code</strong>则是基于Code Llama生态。</p><p>有在实际业务中选择开源大模型的就要小心避开这一组了，它们很有可能只是刷榜成绩好看，但实际能力弱于同规模模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bde430e5c3bb41e2a0bac313507754b5@1743780481_oswg187483oswg1080oswg646_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不少网友都对Paster这项试验表示感谢，认为这正是了解模型实际情况所需要的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_dd872cb9a5964717b56a2a0f9a9cb684@1743780481_oswg124907oswg1080oswg229_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也有人提出担心：</p><blockquote><p>从这一天起，所有训练大模型的人都会加入匈牙利历年数学考试题。</p></blockquote><p>同时他认为，解决办法可能是有一家<strong>拥有专有测试的专门大模型评估公司</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_0c89f4738db94aab92a82586d27b0046@1743780481_oswg109997oswg1080oswg286_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一项提议是<strong>建立一个逐年更新的测试基准</strong>，来缓和过度拟合问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9b33983d56124b95995066e9ed3ba692@1743780481_oswg63314oswg1080oswg188_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>参考链接</h3><p>[1]https://x.com/keirp1/status/1724518513874739618</p><p>[2]https://ai.meta.com/blog/code-llama-large-language-model-coding/</p><p>[3]https://arxiv.org/abs/2310.10631</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/J-UKTWH_FmQ4Kvbp9ah5Hw" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：梦晨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520767502657027</id>
            <title>ChatGPT代码生成飙升10%，北大华人一作：细化prompt，大幅改进大模型代码能力</title>
            <link>https://www.36kr.com/p/2520767502657027</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520767502657027</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:27:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型时代, 代码生成, LLM, ChatCoder
<br>
<br>
总结: 在大模型时代，通过与LLM聊天来细化需求的方法——ChatCoder，可以提高大模型代码生成的性能和准确性。需求细化是揭示需求中的隐含依赖和隐藏结构的过程，通过提供更多细节，消除模糊不清的地方，使大模型能够生成符合用户期望的代码。ChatCoder通过聊天模式辅助LLM和人类在需求细化方面的协作，为大模型代码生成提供了新的方法。 </div>
                        <hr>
                    
                    <p>在大模型时代，高质量的代码生成已经强大到，让人惊叹。</p><p>从通过HumEval中67%测试的GPT-4，到近来各种开源大模型，比如CodeLlama，有望成为码农编码利器。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8201d143880342148da159f16634a3c0@1743780481_oswg21863oswg198oswg193_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而，现实中，程序员们不会精炼表达需求，因此误导、限制了LLM生成优秀代码的能力。</p><p>说白了，大模型代码能力行不行，取决于你的提示妙不妙。</p><p>对此，来自北大实验室的研究团队提出了，通过与LLM聊天来细化需求的方法——ChatCoder。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a5ddac8cd14244d4b87b342564f5d8a7@1743780481_oswg42550oswg1080oswg315_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://arxiv.org/pdf/2311.00272.pdf</p><p>具体来说，他们设计了一种聊天方案，大模型引导用户细化需求表达，进而比以前更精确、更完整，同时提高了大模型的性能。</p><h2>大模型是「码农」，你就是「产品经理」</h2><p>这里先举个例子，如下图，用户提出了需求：</p><blockquote><p>数据集#MBPP/443，要求ChatGPT编写一个python函数从给定的列表中找到「最大的负数」。</p></blockquote><p>基于原始需求，ChatGPT生成一个程序，该程序可以正确提取实际值最大的负数。</p><p>然而，sanitized-MBPP的作者认为「最大负数」应该是指「绝对值最大的数」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d31325df7f5b41f8a68f91b6df96b9a6@1743780481_oswg169406oswg378oswg347_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此由于「最大」这个表达不明确，导致LLM生成了错误的代码。</p><p>而这里，可以通过需求细化（requirements refinement）来解决这个问题。</p><p>需求细化就是揭示需求中的隐含依赖和隐藏结构的过程。通过提供更多细节，在需求细化的过程中可以补充不完整的信息，消除模糊不清的地方。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_25d564065d324633868cdc4098ffe900@1743780481_oswg341197oswg1080oswg844_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在前面举的例子中，我们可以简单地向大语言模型说明「最大的」在这里特指「绝对值最大的」，揭示了「最大」这个词的隐藏结构。</p><p>有了这一改进后的需求，大模型就可以生成符合MBPP作者期望的代码。</p><p>不得不提的是，需求细化，需要人类用户和大模型的协作。</p><p>一般来说，在需求工程的背景下，需求细化是通过软件供应商（编码人员）和软件客户（用户）之间的一系列交互来执行的。</p><p>软件供应商分析客户需求的初始表达，并提出细化点。软件客户则需要根据这些点来作出响应,供应商才能完成一轮需求细化。</p><p>无论是软件客户还是软件供应商，任何一方都不具备单独进行需求细化的资格。</p><p>这样的劣势在于，客户通常不够了解软件设计和开发过程，无法撰写可用的需求说明；而供应商通常也不够了解客户的问题和业务领域，无法为满意的系统制定需求。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_edba08900c73433db8394094306b41e3@1743780481_oswg126557oswg693oswg236_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而现在，在大模型时代，人类用户是客户，LLM是「供应商」。</p><p>为了通过需求细化让大模型生成更好地满足用户需求的代码，就需要研发人类和LLM协作的方法。</p><h2>ChatCoder：聊天细化，生成代码</h2><p>北大提出了ChatCoder，这是通过聊天进行需求细化的大模型代码生成的新方法。</p><p>整体框架如下图，非常简洁，通过聊天来辅助LLM和人类在需求细化方面的协作。</p><p>关键是，如何与大型语言模型聊天。</p><p>ChatCoder便提供了一个全新的聊天模式，其设计灵感来自IEEE SRS。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_df5f27f921e347dc9c42f9d2ee2a7ba0@1743780481_oswg199725oswg1080oswg967_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>接下来，我们具体看下ChatCoder这个框架。</p><p>其整体结构是一个两轮的对话。</p><p><strong>第一阶段：Paraphrase和Exend</strong></p><p>由于人类用户表达需求可能语意模糊、不完整，ChatCoder使用提示要求LLM从几个角度解释用户的原始需求，即完整的需求规范必须清晰。</p><p>对于需要改进的遗漏或有野心的论点，ChatCoder让大语言模型基于它从训练数据中获得的假设来扩展它们。</p><p>人类用户需要查看细化的规范并纠正其中的错误。</p><p><strong>第二阶段：Going-deep和Loop-back</strong></p><p>在这一轮中，ChatCoder要求LLM询问人类用户，关于第一轮Paraphrase和Exend中信息损失，以及需要进一步改进的规范方面的困惑。</p><p>人类用户需要回答这些问题，并回环纠正细化后的规范。</p><p>经过两轮细化后，得到细化后的需求，然后发送给大型语言模型，得到用户想要的程序。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5f65031bd3e4423ea67d44a587300a1c@1743780481_oswg613339oswg1080oswg1112_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>ChatGPT代码能力10%</h2><h3>实验设置</h3><p>数据集：Sanitized-MBPP、HumanEval。</p><p>基准：gpt-3.5-turbo、gpt-4。</p><h3>研究问题</h3><p>为了评估ChatCoder，研究人员提出并测试了以下研究问题：</p><p>1）与现有代码生成模型相比，ChatCoder的表现如何？</p><p>2）ChatCoder是LLM和人类用户交流以进行需求细化的有效方法吗？</p><p>3）人类参与ChatCoder带来了多少改进？</p><h3>ChatCoder性能表现</h3><p>首先我们来看第一个问题，主要是为了评估ChatCoder与基线相比的整体代码生成性能。</p><p>如表1所示，ChatCoder通过大幅细化的需求，成功帮助LLM提高了其生成程序的执行精度。</p><p>例如，对于gpt-3.5-turbo，其在Saniticed-MBPP上的pass@1从57.04%提高到71.25%，提升了14%。</p><p>横向比较，对于gpt-3.5-turbo和gpt-4，Saniticed-MBPP上的性能改进比HumEval上的更突出。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_eae99970e39c4fa18cdbfcf319f7841e@1743780481_oswg45345oswg1080oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>沟通效率的表现</h3><p>第二个问题是，评估ChatCoder是否是大模型和人类进行需求细化交流的有效方式。</p><p>根据表2，所有3种与LLM进行需求细化的通信方法都有助于LLM改进其代码生成结果。</p><p>这一发现指出，任何形式的需求细化在应用LLM生成代码时都是有用和重要的。</p><p>与ChatCoder相比，Free Paraphrase和Free QA不会指示LLM执行某些类型的细化，从而导致较低的改进。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1df4ec7bb9df4c2e800f7da5f9e8a472@1743780481_oswg59578oswg1080oswg447_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>人工干预评估</h3><p>如下评估了人工干预对ChatCoder的重要性，结果见表3。</p><p>由于ChatCoder利用需求细化来提高大语言模型的代码生成性能，因此人工干预是必要的，也是不可忽视的。</p><p>ChatCoder的过程是从给定的角度揭示需求的内部结构，这些角度没有明确表达，即使有歧义。解决歧义的答案只有人类用户知道。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9e6319298ed94bb2b2b6d423888960ca@1743780481_oswg55088oswg1080oswg439_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>案例研究</h3><p>如下，作者提出了几个真实的测试用例，说明ChatCoder如何帮助LLM生成具有细化需求的代码。</p><p>由于页面限制，研究人员从MBPP中选择了3个案例，涵盖了关于输入、输出和目的的细化，因为它们直接影响功能需求。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1a6a1d18feaa4dd3a65fe2b5186166e3@1743780481_oswg256659oswg968oswg1444_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>参考资料</h3><p>https://arxiv.org/abs/2311.00272</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_CZm3FbHOiDtlfbvosdImw" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：桃子，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520765457671687</id>
            <title>Altman首次自曝GPT-5加急训练中，暗示比GPT-4更复杂，无法预测真实能力</title>
            <link>https://www.36kr.com/p/2520765457671687</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520765457671687</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:26:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT-5, AI智能, 商业模式
<br>
<br>
总结: OpenAI正在开发下一代大模型GPT-5，旨在打造超凡脱俗的神奇AI智能。他们计划在ChatGPT的基础上建立商业模式，类似苹果的App Store。他们的终极目的是打造一个超凡脱俗的神奇智能，并且正在研发GPT-5。通过推出GPT系列模型，OpenAI努力建立更多可以执行任务和操作的自主智能体，为各个领域带来巨大的商业价值。 </div>
                        <hr>
                    
                    <p>「OpenAI正在开发下一代大模型GPT-5。我们的意义所在，就是打造超凡脱俗的神奇AI智能」。</p><p>这是Sam Altman最近接受FT的一次采访中，首次对外透露了更多OpenAI的计划。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fe59d670d8e74fc6b28b0b95a80cd1ce@1743780481_oswg77428oswg1066oswg316_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这篇文章信息量巨大！</p><p>他不仅谈到了OpenAI的融资想法，英伟达芯片短缺问题、AGI未来，甚至自曝GPT-5正在研发中。</p><p>还记得今年4月，OpenAI就表示他们不会训练GPT-5，并且「在一段时间内不会」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d231c6098b0b4ee29435baa9e2313847@1743780481_oswg93001oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>没想到，OpenAI早就开始紧锣密鼓地准备中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_50b9329878294a6c80159cbcd52118fe@1743780481_oswg72556oswg276oswg184_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>GPT不是终局，我们要「超凡的神奇AI智能」</h2><p>上周，OpenAI的首届开发者大会举动表明，它计划在ChatGPT的基础上建立的商业模式。</p><p>面向开发者升级GPT-4模型，推出了一系列工具，包括定制GPT功能、应用市场GPT Store等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_79eee19e00834f3882ef8470de0571da@1743780481_oswg728003oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这么做的最终目标就是与最受欢迎的GPT创作者分享收益，类似苹果的App Store商业模式。</p><p>Altman表示，「研究实验室、API、微软合作、ChatGPT、GPT商店都不是OpenAI的终极产品，这些都只是进入我们唯一产品——『智能』的中间手段」。</p><p>「我们的终极目的是，打造一个超凡脱俗的神奇智能（magic intelligence in the sky）」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_42f5a4f211be43b9996202856bb95401@1743780481_oswg408649oswg505oswg499_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>没错，GPT-5正在研发中</h2><p>OpenAI的愿景是实现AGI，保其安全并找到其价值所在。</p><p>Altman首次公开表示，公司正在开发下一代AI模型GPT-5，但没有给出具体的发布时间。</p><p>7月的时候，已经有人发现OpenAI申请注册了GPT-5的商标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3e5bc9d1bb6f4644b2b883ccf40104aa@1743780481_oswg210697oswg1080oswg460_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然GPT-5可能比GPT-4更复杂，但Altman表示很难准确预测这个模型会有什么新的功能和技能。</p><blockquote><p>在我们训练这个模型之前，对我们来说这更像是一个有趣的猜谜游戏。</p><p>我们正在努力提高预测能力，因为我认为从安全的角度来看，预测功能很重要。但我现在无法告诉你GPT-5具体会有哪些GPT-4没有的功能。</p></blockquote><p>为了发展OpenAI的业务，Altman聘请了Brad Lightcap担任首席运营官——以前在Dropbox和创业加速器Y Combinator工作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_86850e9934ad4aa8bc9c08a78ab79851@1743780481_oswg132802oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与此同时，Altman把时间分配在两个领域：一是研究「如何建立超级智能」，二是研究「如何获取建立超级智能所需的算力」。</p><p>他特别强调，通过推出GPT系列模型，OpenAI正在努力建立更多可以执行任务和操作的自主智能体，比如执行代码、付款、发送电子邮件或申请索赔。</p><p>这些智能体未来在各个领域，带来巨大的商业价值。</p><p>不过，训练GPT-5需要更多的数据，这些数据将来自互联网上公开可用的数据集，以及企业的专有数据。</p><p>OpenAI最近发出了征集大规模数据集的呼吁，特别是那些「今天在互联网上尚未公开轻松获取」的数据集，尤其是长篇写作或任何格式的对话。</p><h2>4万一块H100已经到手，芯片短缺明年缓解</h2><p>当然，训练GPT-5，还得需要H100芯片。</p><p>过去几个月中，4万一块H100成为了硅谷最热门的抢手货，多家科技公司都在竞相购买构建AI所需的芯片。</p><p>不过，Altman表示，OpenAI已经收到了H100，并且预计后续的订单将陆续返货。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c183d6edd33a4732a104d81cd90e76e2@1743780481_oswg301037oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他预测，明年AI芯片的「残酷」短缺将得到缓解。</p><p>随着谷歌、微软、AMD、英特尔等其他公司准备发布AI芯片，公司对英伟达的依赖不太可能持续太久。我认为资本主义的魔力正在这里发挥作用。</p><h2>OpenAI急缺钱，微软再入股？</h2><p>训练GPT-5体量的大模型，必定需要投入更多的算力。</p><p>目前，OpenAI正在寻求从微软手中获得进一步的资金支持，以创造像人类一样智能的软件，实现AGI愿景。</p><p>Altman表示，我们与微软的合作「运作得非常好」。随着时间的推移，微软和其他投资者将筹集更多资金。</p><p>外界皆知，微软是OpenAI最大的投资者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_97231ec3049b4843ab35ab5b25162ef5@1743780481_oswg350135oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今年年初，这家老牌科技巨头曾与OpenAI签订了一项为期多年的合作协议——投资100亿美元，支持OpenAI的研发和业务发展。</p><p>这份协议，直接让OpenAI的估值达到290亿美元。</p><p>当被问及微软是否会继续进一步投资时，Altman说，「我希望如此。我们还有很长的路要走。从当前到实现AGI还需要巨大的算力支撑，资金投入就像一个黑洞」。</p><blockquote><p>OpenAI今年的收入增长一直很好，但由于训练成本高，公司仍然没有盈利。微软伙伴关系将确保「我们都从彼此的成功中赚钱，每个人都很高兴」。</p></blockquote><h2>GPT-3已泄密OpenAI成功秘诀</h2><p>一年前ChatGPT的发布，OpenAI已经在构建生成式AI的竞赛中处于领先地位——可以在几秒钟内创建文本、图像、代码和其他多模态的系统。</p><p>Altman说，尽管OpenAI在C端用户方面取得了成功，但它仍寻求在构建AGI取得进展。</p><p>支撑ChatGPT的大模型是「核心部分之一」。关于如何构建 AGI，但除此之外还有很多其他部分。</p><p>虽然OpenAI主要关注LLM，但其竞争对手一直在寻求替代研究策略来推进 AI。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_efd31536af3049c8a24fb384095241df@1743780481_oswg836742oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Altman认为，</p><blockquote><p>语言是「信息压缩的好方法」，是开发智能的关键，但像谷歌DeepMind这样的竞争对手错过了这一点其他公司也有很多聪明人。但他们没有做到这一点。</p><p>即使在我认为GPT-3已经证明了这一点之后，他们也没有选择这样做。</p></blockquote><p>最终，Altman表示，在AGI的竞赛中，「最大的缺失」是需要AI系统进行根理解飞跃所需的条件。</p><p>牛顿仅通过简单地阅读几何或代数，根本不可能发明微积分，我们的模型也一样。</p><p>当前模型仅通过训练数据无法原创新知识，这是开发通用人工智能面临的最大难题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8aa2a6eab782439bafa83f3ead1523a0@1743780481_oswg675614oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>参考资料</h3><p>https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_Vtz2F0bXrK9b2nP458Qww" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：桃子，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520310436292105</id>
            <title>COP28召开在即，中美气候联合声明释放积极信号｜最前线</title>
            <link>https://www.36kr.com/p/2520310436292105</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520310436292105</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:23:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 联合国气候变化框架公约, COP28, 中美气候联合声明, 21世纪20年代强化气候行动工作组
<br>
<br>
总结: 中美发布了一份重磅气候联合声明，决定启动“21世纪20年代强化气候行动工作组”，加速具体气候行动，并计划举办地方气候行动高级别活动。声明提出了具体合作计划，包括能源转型、甲烷减排、循环经济和资源利用效率等方面。这份声明为中美气候合作提供了积极信号，也将推动COP28全球气候会谈的进程。 </div>
                        <hr>
                    
                    <p>文 | 吕雅宁&nbsp;</p><p>编辑 | 苏建勋</p><p>还有两周时间，《联合国气候变化框架公约》第二十八次缔约方大会（COP28）将在阿联酋迪拜开幕。在此之前，中美作为应对气候变化进程中影响最大的两个国家，发布了一份重磅气候联合声明，为全球应对气候危机注入动力。</p><p>11月15日，中美联合发表<strong>关于加强合作应对气候危机的阳光之乡声明</strong>（以下简称“声明”）。此次声明的一大亮点是：中美两国决定启动<strong>“21世纪20年代强化气候行动工作组”</strong>，开展对话与合作，以加速21世纪20年代的具体气候行动，并计划于2024年上半年举办地方气候行动高级别活动。</p><p>声明提出，中美双方将重点加速一系列具体行动：包括能源转型、甲烷和其他非二氧化碳温室气体排放、循环经济和资源利用效率等八个方面的合作计划和内容。</p><p>在能源转型方面，双方提出明确的可再生能源部署目标，<strong>两国支持到2030年全球可再生能源装机增至三倍</strong>，并同意重启中美能效论坛，计划重启双边能源政策和战略对话等；同时提出两国争取到2030年各自推进至少5个工业和能源等领域碳捕集利用和封存（CCUS）大规模合作项目。</p><p>在甲烷和其他非二氧化碳温室气体排放领域，声明提出较具体的甲烷减/控排计划，<strong>双方表示将在未来向联合国提交的2035年国家自主贡献目标中，制定、纳入甲烷减排行动/目标</strong>，还计划就各自管理氧化亚氮排放的措施开展合作。</p><p>甲烷是仅次于二氧化碳的全球第二大温室气体，对减缓全球气候变暖意义重大。</p><p>不久前的11月7日，中国生态环境部联合外交部、国家发改委等十部委发布《甲烷排放控制行动方案》，提出“十四五”和“十五五”期间甲烷排放控制目标，包括完善甲烷排放统计核算、监测监管等基础能力，这份顶层设计文件也为此次声明的发布奠定基础。</p><p>对于循环经济和资源利用效率，中美提出将与各方一道制订一项具有法律约束力的塑料污染（包括海洋环境塑料污染）国际文书。</p><p>中美都是塑料生产和消费大国，当前也正值塑料污染的第三次国际谈判举办期间，各方正在商讨制定解决塑料污染的国际协议，此份声明将对国际社会建立应对塑料污染的共识起到推动作用。</p><p>此外，声明还提出地方合作、森林、大气污染物减排协同、2035年国家自主贡献、COP28等方面的合作方向，以及具体到时间的承诺表态。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3534faefd1af45dfb4011d6b654a74ae@5802120_oswg250994oswg857oswg540_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">此次声明提及的重点合作方向。制图：36碳</p><p>气候问题已成全球共同面对的系统性问题，国际合作的重要性不断凸显。</p><p><strong>中国和美国是世界上最大的两个经济体，同时也是最大的能源消费国和碳排放国，是应对气候变化进程中影响最大的两国。</strong>因此，气候议题一直是中美重点合作方向之一。</p><p>纵观近年中美气候合作进程，成果与波折也不断交织。</p><p>在美国前总统奥巴马执政期间，中美曾发表三份气候变化联合声明，并推动《巴黎协定》达成生效。</p><p>在美国前总统特朗普执政期间，美国退出《巴黎协定》并废弃多项国内环境政策，中美气候合作一度暂缓。</p><p>2021年初，美国拜登政府上台后，重新加入《巴黎协定》。中美双方也在2021年发表《中美关于在21世纪20年代强化气候行动的格拉斯哥联合宣言》，规划重点合作领域，但之后也经历过暂停。</p><p><strong>今年以来，中美在气候议题方面的互动频次明显增加，恢复了官方层面的气候磋商，被视为中美气候合作重启的积极信号</strong>：</p><p>2023年7月16日-19日，以及11月4日-7日，中国气候变化事务特使解振华和美国总统气候问题特使约翰·克里在北京、加利福尼亚阳光之乡分别举行会谈，此次联合声明也是此前两轮会谈的重要成果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_0a999fb896624ba1b02722119ca2d093@5802120_oswg164380oswg820oswg405_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">中美气候合作大事件梳理。制图：36碳</p><p>今年11月30日至12月12日，COP28将在迪拜举办，198个缔约方将共同探讨应对气候变化的相关工作，旨在就遏制全球变暖达成共识。</p><p>此次声明也提及COP28期间中美两国的具体安排，包括：双方将会同阿拉伯联合酋长国邀请各国参加在COP28期间举行的“甲烷和非二氧化碳温室气体峰会”；积极参与巴黎协定首次全球盘点等。</p><p>当下，国际局势复杂多变，中美关系也处于关键十字路口。两国此次发布的气候联合声明，被视作中美气候外交的积极信号，并将为COP28这场全球气候会谈提供推动力，激励国际社会不断推进应对气候变化的进程。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520760414578432</id>
            <title>小米汽车终于要来了，我被它的颜值打动了</title>
            <link>https://www.36kr.com/p/2520760414578432</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520760414578432</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:22:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米汽车, 外观设计, 电车, 创始人版
<br>
<br>
总结: 小米汽车是今年最受关注的电车之一。小米汽车的外观设计非常吸引人，大多数人都认为它很好看。它的车身比例修长，更像是一台油车。车标上的字母标识被抠掉了，整体设计独特。除了外观，小米汽车在各种设计上也很出色，如黄色的Brembo卡钳、米其林的PS EV轮胎、碳纤维的后视镜和可调节角度的主动尾翼。这些设计使得小米汽车看起来非常战斗。 </div>
                        <hr>
                    
                    <p>今年最受关注的电车（&nbsp;之一&nbsp;），来了！</p><p>昨日下午 4 点左右，小米汽车出现在工信部公告里，相关话题立马冲上微博热搜。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b2a314860aba4a778f815749721a4d15@1743780481_oswg192787oswg605oswg559_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>编辑部的同事们也是围在一起，就对着网站上已有的几张公告图，看了至少有半小时。</p><p>不得不说，米车的外观针不戳啊，长在了大多数人的审美上，<strong>属于 10&nbsp;个人里头， 9 个人都会夸它好看的那种。</strong></p><p>从下图来看，小米汽车的车身比例比较修长，给我的第一眼感觉不像是一台电车，而更接近油车。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a4652967d1e64468a21852d761f2a9f8@1743780481_oswg305093oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>姿态很在线，后面的小宽体十分对味，整个溜背从这个角度看过去，也突出一个优雅。</p><p>而且，你甚至能够在选装里，找到<strong>“&nbsp;创始人版&nbsp;”</strong>的标识，什么叫拿捏用户感知啊。。。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fdc18efaaa254678a9125219ef6108e4@1743780481_oswg29050oswg1080oswg382_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就是后头这个 xiaomi 字母标的 logo ，总感觉字有点太多了。。。以至于油头设计师实在看不下去，干脆&nbsp;“&nbsp;抠掉&nbsp;”&nbsp;了车标，并且把下面的装饰件做了熏黑处理。</p><p>大伙儿瞅瞅图片，是不是顺眼多了？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cb1c728c4d604db9ba7496aa97190751@1743780481_oswg1216261oswg1002oswg1633_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>反正，编辑部同事们在看完这车后，有说像马丁的，有说像保时捷的，但一致的结论，都是好看。</p><p>顺带一提，说像保时捷的那哥们，很快就声称在雷军的微博里找到了&nbsp;“&nbsp;有力佐证&nbsp;”&nbsp;。。。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_86224c77131d486989b355881b4c5d67@1743780481_oswg804543oswg690oswg1201_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过有一说一，小米车子的整体设计还是自成一派的。细细一看，这车不光外观拉风，在各种设计上更是在往性能的方向整。</p><p>45 度角看过去，这个黄色的 Brembo 卡钳非常显眼。轮胎也是狠家伙，高配的用了米其林的 PS EV，后轮胎宽到了 265mm ，同时前后轮拱都留了一个导风槽，可以给刹车盘散热。</p><p>而且小道消息称，这个导风槽是真的，不跟你嘻嘻哈哈。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_336524a3bcdb4383b4aae6f2459a1ca3@1743780481_oswg382633oswg1080oswg524_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不仅如此，它的后视镜甚至有个碳纤维的选装版本，能轻多少先不说，视觉马力起码能加 5 匹。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_14c7591fc609493887f6592a184668fe@1743780481_oswg348293oswg1080oswg757_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再加上后头还有一个可以调节角度的主动尾翼。虽然说现在国产车也有不少这玩意，但放以前，这可都是什么 AMG 才有的东西，再不济也得是个奥迪 TT 吧。</p><p>先不说到底能起多大作用，但起码看起来就很战斗。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a3b01d0fc5524a12acd996be7dd2cc17@1743780481_oswg231989oswg1080oswg321_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，脖子哥今天还在群里刷到一张疑似小米汽车内饰的照片，你看这两个圆扭，还没按下去，我都已经在 YY 开着米车跑纽北了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cc7259225bc8461c99ac8083523e32b4@1743780481_oswg67717oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>说完外观，咱再来看看最基础的参数。</p><p>首先，让我没想到的是，<strong>小米造了一台 C 级车。</strong></p><p>这款车命名为&nbsp;“SU7”&nbsp;，车长有 5 米，准确来说是 4997mm ，比特斯拉 Model 3 、蔚来 ET5 这些轿车都要长一截，和比亚迪汉差不多。</p><p>原先我猜它会在 4.8 米左右，因为做到 A+&nbsp;或者 B 级车的尺寸，才更符合&nbsp;“&nbsp;年轻人第一台车&nbsp;”&nbsp;的定位。但他们一下掏出了台 C 级车，这下价格可能就不便宜了。。。</p><p>在配置方面， SU7 至少有 3 个版本：普通版、Pro、Max ，这几个版本应该是会在<strong>三电、激光雷达、性能套件</strong>上做区分。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_01a100b58e51498e9fb7ec8bdb27f85e@1743780481_oswg93489oswg1080oswg308_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了咱们外观里聊过的性能套件，三电部分小米也是做了一些区分。</p><p>根据公告，高配版双电机总功率是 495kW （&nbsp;前 220kW ，后 275kW ），比特斯拉 Model 3 Performance 的 486kW 还要高一点。作为一台运动风格的轿车，这个马力肯定是够的。</p><p>电机的供应商是汇川，也是国内老牌的电机、电控供应商，它家给理想、长安、长城等车企都有供货。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a523e990a5a2475085061cecf8f3a368@1743780481_oswg8004oswg1035oswg162_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而电池是用的宁德时代的三元锂。</p><p>低配版是单电机，功率 220kW ，供应商是联合电子。电池是比亚迪做的磷酸铁锂。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b0f4000717654a54b8dd4a50b6a835bd@1743780481_oswg4827oswg985oswg113_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在电池容量和电机功率上做差异，算是常规操作了。不过网上还有个猜测，是高配上 800V 高压平台，而低配是 400V ，这样能把入门版的价格拉下来了。</p><p>我倒觉得与其在低配上用 400V 平台，不如去砍一些别的配置，因为 800V 能明显提高充电速度，是一项用户感知明显的配置。</p><p>像小鹏 G6 和智界 S7 这些今年发布的车型，都是全系标配 800V 。如果小米明年没有跟上，多少有点说不过去。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_883122dfa2554e65abacebcd2ee62c4c@1743780481_oswg453471oswg752oswg464_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再就是激光雷达，小米是和友商们一样，放在头顶正中，一眼就看到。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_4a06af85de24438c8f906848934c95e0@1743780481_oswg218207oswg1080oswg486_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个配置基本就是在智驾上做差异化，比如理想的车型，带激光雷达的就会有城市 NOA 功能，而没有激光雷达的只能在高速路上开 NOA 。</p><p>不过，和别家不同的是，<strong>小米的激光雷达，外表面上看不出激光扫描的平面。</strong></p><p>你看其他车型的都长这样，前头一个长方形的轮廓非常明显。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f2db816e16c948aca91d14ca4249e244@1743780481_oswg673608oswg968oswg622_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而小米的没有这个轮廓，整体更小更圆润，相对不那么突兀。显而易见的好处是风阻更低，这里头很可能会有些黑科技。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ce3a776e13124cb4a0212e42bce2b50f@1743780481_oswg194952oswg1080oswg560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>关于米车目前已知的信息，大概就是上面的这些。而这车上公告后，除了网友们沸腾了之外，也是少见地引发了一些赛道和性能车博主的热烈关注。</p><p>说实话，作为一名汽车编辑，我是很喜欢他们的这个运动取向。但是吧，性能车这个品类，注定不会有太大市场。</p><p>用同事的话来说，<strong>“&nbsp;大家都是口嗨，谁真买性能车啊&nbsp;”</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6a895cce01d04e6baf5739ea2dbad2eb@1743780481_oswg40284oswg574oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>想要把车卖上量，肯定多少要沾点家用。</p><p>不过作为一台 C 级车，在车内空间上天生就有不小的优势，而且小道消息说这车的内部空间有够大，前排后排随便坐。不知道小米在&nbsp;“&nbsp;性能&nbsp;” 的标签下，能怎么利用车内空间来打动消费者。</p><p>还有个比较有趣的事，是关于<strong>小米的造车资质</strong>。至少从公告上看，这回是暂时有了答案。</p><p>这次申报小米汽车的企业是北京汽车集团越野车有限公司，它是北汽集团下面的子公司。</p><p>但是我们再看车子的生产地址，并不是北汽的所在地，而是小米自己在亦庄新建的汽车工厂。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_07c3d95302404b879e770c253d5c9d0a@1743780481_oswg55321oswg1080oswg180_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>之前 8 月份的时候，有消息说小米已经拿到了发改委的资质，但还要再去工信部拿资质。</p><p>也就是说，到现在，小米还没有完全取得所有造车资质，所以虽然车是自己造的，但借用了北汽的资质。</p><p>在小米汽车的尾部，也写着是&nbsp;“&nbsp;北京小米&nbsp;”&nbsp;，而非&nbsp;“&nbsp;小米汽车&nbsp;”&nbsp;。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1d179ad82c324f0181b99cef5e94db81@1743780481_oswg151503oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据财联社今天的报道，<strong>小米应该还会继续申请造车资质。</strong></p><p>就从资质这一点看，我猜测，小米汽车可能是觉得资质审批流程太长，产品有点等不及了。</p><p>按照小米汽车的计划，他们会在明年上半年发布首款车型。<strong>但现在汽车市场市场已经杀疯了，越晚入局只会越被动。</strong></p><p>就拿小米瞄准的 C 级轿车这个细分市场为例，前有月销两万的比亚迪汉，后有主打操控的极氪&nbsp;001 。而就在上周，华为加持的阿维塔 12 和智界 S7 刚刚上市，这两位也是朝着这个区间来的。</p><p>特别是智界 S7 ，它的尺寸和小米 SU7 完全是一个级别，两家又都是手机厂过来的，车机互联这一套还有智驾也都是主打项。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_61390143fe8c4c20b02fda364420b6aa@1743780481_oswg296444oswg665oswg334_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以我估计米车在功能、配置包括定价区间上，都很有可能和智界 S7 撞个正着。</p><p>因此小米现在就赶着上了工信部公告，感觉也是在给自己提提速，别等到别人都把市场瓜分完了再来冒泡。</p><p>其实我们拉长线来看，<strong>小米汽车的进展其实不算慢</strong>。雷军在 2021 年 3 月宣布造车，到今天，大概两年半的时间。</p><p>蔚小理三家造第一款车的时候，也差不多是这个节奏。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1039e77f2f1b410285d31946a59747cf@1743780481_oswg774295oswg924oswg635_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但是，小米入局汽车的时间，已经比蔚小理这批新势力晚了 7 年，比特斯拉更是晚了 18 年。现在市场竞争的激烈程度早已今非昔比。</p><p>不过，小米今天的首秀还是给了大伙儿足够的惊喜。只是目前的信息还很少，咱也不好评判它的战斗力有多高。</p><p>而根据脖子哥私下打听到的消息，小米在电机、智驾、座舱上都有狠招。具体有多狠，也不太确定，但在座舱、车机和互联这一块，肯定是第一梯队。</p><p>毕竟手机厂商下场做车机是什么水平，大家都有目共睹了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9c25fd995b9d467a8b259294a83afe72@1743780481_oswg229763oswg770oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>剩下最关键的只有一个问题，米车会卖多少钱？</p><p>从现在的市场形势来看，脖子哥猜测小米的高配应该不会太便宜，但有可能会控制在 30&nbsp;万左右。至于低配会到多少不好说，可能不会超过 25 万。</p><p>但是咱也知道，小米一般都会给一个极具性价比的价格，特别是第一代产品嘛，也可能会有个 buff 加成。</p><p>说不定在小米汽车的发布会上，雷总又要开始讲他连夜说服高管的故事了。。。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/mJok336w-heYKazxrkNkNw" rel="noopener noreferrer nofollow" target="_blank">“差评”（ID:chaping321）</a>，作者：白日梦，编辑：面线 &amp; 脖子右拧，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520748281882375</id>
            <title>SpaceX最新视频泄密，“星舰”二次试飞有四大改进，前主管深入解读</title>
            <link>https://www.36kr.com/p/2520748281882375</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520748281882375</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 10:00:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: SpaceX, 星舰, 试飞, 改进
<br>
<br>
总结: SpaceX正准备进行第二次星舰试飞，该公司对星舰进行了多项重要改进，包括增加通风口和水冷系统。在第一次试飞中发生爆炸后，他们希望通过热分离技术避免类似情况。此外，他们还采取了新的保护措施，以防止助推器损坏。 </div>
                        <hr>
                    
                    <p>SpaceX正准备第二次向太空发射其巨型火箭“星舰”。该公司在X上官宣，待美国监管部门批准后，星舰最早可能于11月17日发射。</p><p>据悉，自4月份星舰首次试飞以来，SpaceX对其进行了多项重要升级。在那次发射中，星舰在半空中发生爆炸，在发射台炸出了大坑，碎片被喷射到几千米以外的小镇上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c02511416a8042b997cd51f8bbf57a88@1743780481_oswg73265oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">与4月份首次试射相比，SpaceX对星舰做出了诸多改进，包括在两级之间增加了通风口，在发射台增加了水冷系统</p><p>在二次试飞中，SpaceX显然希望避免类似情况。马斯克在9月份表示，自4月份以来，该公司已经对火箭进行了1000多项改进，现在“准备再次发射”。</p><p>SpaceX最近在为即将到来的发射做准备而发布的视频中（见文首），展示了星舰最重要的升级。这些升级可以帮助世界上体型最大、推力最强的火箭最终首次进入轨道。</p><p>马斯克对星舰寄予了厚望，他希望其能帮助人类在火星上建立永久定居点。SpaceX还从美国宇航局（NASA）获得了价值数十亿美元的合同，帮助后者50多年来首次将人类送上月球。</p><p>以下是SpaceX前任务主管对星舰进行四项最大改进的解读：</p><h2>01 两级之间增加通风口以尝试热分离</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9f9fd5f8792e4f6a9a9ff156de61b0b5@1743780481_oswg58166oswg700oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">SpaceX在星舰飞船和助推器之间增加了通风口和隔热罩</p><p>星舰主要由两个级段组成，即上级飞船和助推器（超重型助推器）。SpaceX在其两级之间增加了通风口，这是其为第二次飞行做出大胆改变的最显著证据。在二次试飞期间，星舰将进行热分离（hot staging）尝试。</p><p>热分离技术是现代火箭技术中常用技术之一，其核心构思是通过引燃火箭上下级之间的连接处，使其产生温度和压力的突增，从而达到分离的目的。与冷分离技术相比，热分离技术具有操作更为简便，分离更快速等优点。</p><p>助推器产生巨大的推力，将整个星舰系统从地面上抬升，并穿过地球大气层最厚的部分。然后，星舰上级会在高空与助推器分离，自行起飞前往轨道。</p><p>SpaceX龙飞船前任务主管阿巴希·特里帕蒂（Abhi Tripathi）说，通常情况下，在传统火箭上，“助推器的主发动机会停下来，上级分离后才会重新启动”。但在星舰二次试飞时，上级飞船在启动发动机的同时，“基本上仍然与助推器保持连接状态”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e303136b3bc5465e8ee640b6e6f51d02@1743780481_oswg49981oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">星舰系统由两级组成，上级是飞船，下面则是超重型助推器</p><p>马斯克在6月份接受记者阿什莉·万斯（Ashlee Vance）采访时说，这就是为什么星舰在助推器顶部增加了通风口和隔热罩的原因，这样火焰就可以逸出，火箭也不会“自己爆炸”。</p><p>马斯克告诉万斯，这种方法的好处是，它给了上级飞船很小却至关重要的推力，使火箭的有效载荷增加了约10%。</p><p>但特里帕蒂说，这样做的代价是，热分级可能会使助推器面临更大的火灾风险，对于一家旨在重复使用助推器的公司来说，这显然是个不利的举措。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_967e8917ec7447a683b686b5077557d6@1743780481_oswg74100oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">SpaceX在飞船和助推器之间安置了“排气”隔热罩，以帮助热分离</p><p>那么，为什么SpaceX决定冒这个险呢？特里帕蒂解释说，工程师们可能认为，为了获得更好的性能，这样做是值得的。</p><h2>02 新的保护措施，防止助推器损坏</h2><p>在旁观者看来，星际飞船的第一次试飞进行得非常顺利，直到火箭突然起火。但早在爆炸发生之前，就有迹象表明出了问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6ad7875512434dafa5f12278be6eef77@1743780481_oswg42955oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">星舰4月份首飞时的屏幕截图显示，开始时三个发动机关闭，两个在飞行过程中关闭，第三个则闪烁不断</p><p>特里帕蒂说，在飞行过程中出现几次发动机故障没什么大不了的。星舰如此强大，它仍然可以在推力不足的情况下进入轨道。</p><p>但这依然是助推器出了问题的征兆。SpaceX后来发表的一份声明解释说，助推器内部燃料泄漏引发了火灾。正因为如此，SpaceX与星舰上的主要飞行计算机失去了联系，“并最终失去了对其控制”。</p><p>特里帕蒂表示：“如果有什么东西从发动机中倾泻而出，摧毁了火箭的智能部件，那可不是件好事。”</p><p>他补充说，更大的问题在于，SpaceX可能低估了利用自身发动机力量支撑火箭所需的防护。为了解决这个问题，SpaceX可能不得不为助推器中的组件增加更多保护。该公司表示，它正在增加更多的系统来控制船上的火灾。</p><p>然而，所有这些都增加了重量，这可能是该公司决定转向热分离的原因之一。</p><h2>03 更安全的自毁系统？</h2><p>在星舰首次试飞开始约2分45秒时，SpaceX公司的工程师们发出了热烈的欢呼声，随后却都忧心忡忡地安静下来。上级的飞船本应与助推器分离，但显然失败了。大约一分钟后，星舰失去了控制，然后爆炸成一个巨大的火球。但爆炸并没有立即发生，这是一个大问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_be9ae6437a3746fc9dc3735810aeb38b@1743780481_oswg17310oswg700oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片显示，星舰在发射后2分28秒、3分零3秒以及3分51秒时发生翻滚，最终在3分59秒时爆炸成火球</p><p>星舰上装有自毁系统，当出现问题时，它会自动检测到。SpaceX在9月8日的一份声明中表示，该系统被称为自主飞行安全系统（AFSS），它确实在火箭中引爆了炸药，但却是在“意外延迟”之后。这意味着AFSS系统没有发挥应有的作用，这是美国联邦航空管理局（FAA）应该非常认真对待的问题。</p><p>特里帕蒂说，出于安全原因，SpaceX不允许透露太多有关这些改进的信息。但该公司已经证实，它已经“增强并重新认证了AFSS，以提高系统的可靠性”。</p><h2><strong>04 发射台上的“巨大倒置淋浴喷头”</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bb73e3a3031147b7b967c4b016e6e5f1@1743780481_oswg42745oswg700oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">蓝色防水布下是星舰发射台的洪水系统</p><p>在4月份的发射中，火箭炸毁了发射台，导致混凝土碎片和其他碎片在得克萨斯州博卡奇卡发射场周围飞舞。</p><p>据报道，碎片散落在面积超过156万平方米的土地上，包括州立公园。这次发射还在南部的一个州立公园引发了火灾。这激怒了当地的环保组织，他们对FAA提起诉讼，指责他们对发射的监督不力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a84911488e9642a6b24dd37db6f17e84@1743780481_oswg51318oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">星舰首次试飞后，在发射台上留下大坑</p><p>特里帕蒂说，问题在于，SpaceX还没有在博卡建造火焰分流器。火焰分流器由一系列巨大的隧道组成，通常建在发射台下面，以将火焰定向到数百米外。</p><p>目前还不清楚SpaceX为什么没有这样做，但这可能与Starbase位于自然保护区附近有关。取而代之的是，在星舰的首次试飞中，SpaceX决定看看他们是否能仅用厚厚的混凝土发射台吸收火焰的力量。</p><p>特里帕蒂说：“正如我们所看到的，这种计算并不正确。”</p><p>今年6月，马斯克告诉万斯，在下一次发射之前，SpaceX决定调整方法，在发射台上添加马斯克所谓的“水冷钢三明治”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8785694caa404e37a311f38b11bfc58a@1743780481_oswg41322oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">SpaceX在星舰发射台上展示其新的洪水系统</p><p>发射台现在安装了两块厚钢板和一个喷水系统，本质上是一个“巨大的倒置淋浴头”。当火箭在发射台上空时，它会把水向上喷射，以抵消助推器产生的大量热量。此外，发射台还用上前立方米的高强度混凝土加固。</p><p>然而，这种方法本身引起了人们的担忧，因为用于冷却垫的水可能成为“工业用水”，而这在美国是受到严格监管的。</p><p>美国得克萨斯州环境质量委员会（TCEQ）证实, SpaceX没有申请处理这些水的许可证，该机构还“没有确定”其活动是否违反了环境法。</p><h2>05 FAA已解除警报，但星舰真能飞吗?</h2><p>在首次发射四个多月后，FAA表示已经准备好允许SpaceX再次飞行。特里帕蒂说，在4月份试飞失败后，一项事故调查已经结束，这是飞行未按计划进行时的标准程序，SpaceX可能已经做出了该机构要求的改变。</p><p>据悉，FAA代理局长波莉·特罗滕贝格（Polly Trottenberg）9月份告诉记者，该机构“乐观”地认为，“下个月某个时候”可能会颁发发射许可证。</p><p>11月13日，马斯克在社交媒体上发帖称：“我刚刚被告知，发射批准将在周五发射前完成。”但目前尚不清楚该批准是否指的是FAA。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a9f9b6c6f28e4c95b85db91a46e4124f@1743780481_oswg56203oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">SpaceX已建造了多艘飞船和超重型助推器</p><p>在授予新发射许可之前，FAA需要审查SpaceX对星舰发射系统所做的改进，这包括对新发射台系统的环境评估。</p><p>针对FAA处理星舰环境审查的诉讼也可能导致延误。这起案件的原告之一、生物多样性中心的高级律师贾里德·马戈利斯（Jared M. Margolis）在9月份时称，这起案件“有可能导致发射推迟，但前提是我们提出了一项禁令，而我们目前还没有这样做。”</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/fuOX8ihJxLnWCk1P88cSNA" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”（ID:qqtech）</a>，作者：金鹿，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2518972970428162</id>
            <title>「太湖能谷」完成数亿元C轮融资，独创技术可将铅碳电池储能寿命提高一倍 | 36氪首发</title>
            <link>https://www.36kr.com/p/2518972970428162</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2518972970428162</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 09:41:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 太湖能谷, 铅碳电池储能系统, TEC-Engine技术, 储能市场格局
<br>
<br>
总结: 太湖能谷是一家以铅碳电池储能系统为起点的智慧储能智慧能源平台，通过自研的TEC-Engine技术，延长了铅碳电池的使用寿命，提供了安全、经济的全场景智慧储能解决方案。铅碳电池储能具有安全性高、能满足独立储能需求、综合能效高等特点，太湖能谷在储能领域具备技术和成本优势，有望重塑储能市场格局。 </div>
                        <hr>
                    
                    <p>文| 王方玉</p><p>编辑| 苏建勋</p><p>36氪获悉，近日，长兴太湖能谷科技有限公司（以下简称“太湖能谷”）完成数亿元C轮融资。本轮融资由中金资本领投，德合资本跟投，国电投等部分老股东跟投，万创投行担任首席财务顾问。</p><p>太湖能谷成立于2016年，是一家以铅碳电池储能系统为起点，全场景布局的智慧储能智慧能源平台。其自研的电池生命周期控制技术TEC-Engine可以大幅提升铅碳电池储能系统的使用寿命，提供兼具经济性和安全性的全场景智慧储能解决方案。</p><p>据介绍，太湖能谷的电池生命周期控制技术TEC-Engine是全球独创，采用了拓扑熵补偿控制技术，可以大幅延长铅碳电池储能循环寿命，且原理上普适于锂电、钠电、水系锌基等不同类型电化学电池。</p><p>这一技术背后的原理是通过在电池两极添加不断变化的电场（噪音）来延缓电池枝晶的生长，从而达到延长电池寿命的目的；同时动态算法可以解决大规模电池组的一致性和协同性难题，提升充放电效率。</p><p>铅碳电池储能系统还有着一项显著优势——安全性。由于没有易燃物，温升过程时间较长，且使用的是水性电解液（稀硫酸水溶液），铅碳电池储能系统不用担心热失控和燃爆问题，是本质安全的。</p><p>当前储能行业多种技术路线并存。在国家政策“支持和鼓励新型储能多技术路线发展”的大背景下，铅碳电池储能也得到一定规模的应用。数据显示，铅碳电池储能装机容量占全部电化学储能装机的10%左右，如果按功率计算，则有不到3%的市占率。</p><p>太湖能谷致力于通过科技创新解决铅碳电池储能循环寿命偏低的难题。</p><p>太湖能谷方面告诉36氪，<strong>在使用了太湖能谷独家的TEC-Engine技术后，铅碳电池储能系统的循环次数可以从800次提升到1600次以上</strong>。且度电成本最低可以达到0.25元，仅相当于磷酸铁锂储能系统的60%左右。</p><p>成本问题这一短板补足后，铅碳电池储能可以做到兼顾经济性与安全性。这高度契合了国央企投资方对于储能安全性的要求。太湖能谷也凭此与多家大型央企、国企建立了稳定的合作关系，包括国家电投、中国华能、中国华电等，打造了一系列的铅碳电池储能项目标杆案例。</p><p>其中，长兴和平共储综合智慧能源项目由浙江国电投、吉电股份国电投及太湖能谷组成的联合体投资，总投资金额高达约10亿元，规模为100MW/1.06GWh，是国内首个GWh等级的单体储能电站，也是目前国内最大的铅碳储能电站。</p><p>太湖能谷还与国家电投控股的上市公司吉电股份建立了深度战略合作。今年10月23日，由吉电股份、太湖能谷、信业基金、北盛股份共同投资建设的吉电能谷（白城）首批下一代储能铅碳电池已经正式投产。</p><p>与锂电池相比，铅碳电池储能的另一个优势在于上游原材料铅的丰富和易得。资料显示，我国铅资源储量位居世界第二，产量更是占全球的40%以上。此外，铅碳电池正负极材料及电解液均可回收，且回收工艺简单、技术成熟，回收率高达99%。综合考虑国家战略和能源安全因素，太湖能谷方面认为，铅碳电池在储能领域具备极大应用潜力。</p><p>且铅碳电池储能仍有进一步大幅降本的空间。在原材料方面，太湖能谷计划深度参与上游铅材料供应链，到2024年将铅的采购成本降低1/3。技术降本层面，公司计划联合产业方布局下一代铅碳电池技术（Next Generation Adanced AGM电池），到2025年将TEC-Engine驱动的铅碳电池储能系统的循环次数提升至3000-4000次。</p><p>根据太湖能谷规划的降本路径，预计到2026年太湖能谷的铅碳电池储能系统的度电成本将低至0.1元以下，比抽水蓄能的度电成本还要低很多。</p><p>太湖能谷方面表示，本质安全超低成本的铅碳电池储能系统未来有望重塑储能市场格局，预计2024年铅碳电池储能将占到国内新型储能容量的1/4，到2028年储能装机量进入TWh时代后，铅碳电池储能将占到国内新型储能装机量的一半以上。</p><p>创始人吴建斌表示:储能行业的风口已经到来，太湖能谷秉持着稳扎稳打的态度和戒骄戒躁的心态去参与到我国储能行业建设中，为我国“双碳”战略贡献一份绵薄之力，希望能够助力中国新能源事业加大马力，扬帆起航。</p><h2><strong>投资人观点</strong></h2><p>中金资本表示：在“碳达峰、碳中和”战略背景下，大规模的新能源发电并网对电网消纳能力提出挑战，为新能源配储打开巨大市场空间；同时随着峰谷价差明显拉大，促使工商业储能在经济性催化下快速起量。随着储能需求增加，具备安全性、经济性且短期内可实现大规模应用的技术路线将率先得到推广和应用。铅碳储能具有安全性高、能满足独立储能需求、综合能效高、回收期短、可回收循环利用率高等特点，能够满足新能源配储和工商业储能等场景的要求。太湖能谷作为铅碳储能技术路线的领先者，利用自研的TEC-Engine技术有效地延长了铅碳电池使用寿命，为储能电站安全、稳定、低成本运行提供了解决方案，并建设完成多个标杆智慧储能项目，相信太湖能谷未来在储能领域能够依靠其技术和成本优势实现快速发展。</p><p>&nbsp;德合资本创始合伙人周行表示：在全球能源结构调整、能源安全竞争激烈的背景下，近些年新能源产业迎来爆发式成长，随着行业的不断成熟其终局将回归于传统行业的本质——用创新不断优化成本和质量。在储能领域，太湖能谷作为铅炭路线独树一帜的标的，已成为垂直领域的头部供应商，其低成本、高安全性的优势亦是终局思维下的核心竞争力，未来随着市场份额的不断扩大，其必将走出一条富有特色的储能道路，为实现全球绿色可持续发展贡献力量。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2519244516189696</id>
            <title>“原初科技”完成Pre-A轮融资，专注二氧化碳化学链矿化封存利用技术 | 36氪首发</title>
            <link>https://www.36kr.com/p/2519244516189696</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2519244516189696</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 09:36:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 原初科技, 二氧化碳化学链矿化永久封存技术, 碳酸钙产品, 大规模减量和资源循环利用
<br>
<br>
总结: 原初科技是一家专注于二氧化碳化学链矿化永久封存技术的公司，他们利用含钙镁的工业固废或自然矿石作为原料，通过专有设备和循环介质，高效矿化利用二氧化碳，生成具有经济价值的碳酸钙产品。这项技术不仅可以解决巨量二氧化碳减排和固化封存的问题，还能实现工业固废的减量和资源循环利用。该技术具有高效、稳定、绿色低能耗的特点，适用于火电、石化、煤化工、钢铁、水泥等高碳排放行业。原初科技已获得多项专利，并与国内大型央企及行业龙头合作，取得了一定的市场成果。 </div>
                        <hr>
                    
                    <p>文 | 薛昱婷</p><p>编辑 | 雪小顽</p><p>36碳获悉，原初科技（北京）有限公司近日已完成Pre-A轮融资。本轮融资由至临资本领投，资金主要用于研发投入、实验室建设、专利布局等。</p><p>原初科技成立于2014年，专注大规模、低成本的二氧化碳化学链矿化永久封存技术。<strong>该技术以电石渣、钢渣、废混凝土等含钙镁的工业固废或富含钙镁的自然矿石为原料，通过专利专有设备和专有循环介质，对不同应用场景、工况条件和浓度的二氧化碳进行高效矿化利用，</strong>生成具有经济价值、绿色低碳的碳酸钙产品。</p><p>也就是说，原初科技在解决能源和工业领域巨量二氧化碳减排和固化封存的同时，还能够实现工业固废的大规模减量和资源循环利用，以废治废，变废为宝。</p><p>据原初科技方面介绍，<strong>这项技术能够在2分钟内完成矿化反应，二氧化碳的矿化吸收率大于90%，并且无需对二氧化碳提浓。</strong>所得的矿化产品为结构稳定、不会重新释放二氧化碳的碳酸钙，具有长期稳定固碳的优势。同时，整个工艺过程也实现了绿色低能耗，即化学链矿化过程不消耗酸碱，无废碱废液产生。</p><p>36碳了解到，在原初科技的技术路径下，可以解决传统矿化技术经济性差、无法大规模工业化应用的难题。从经济性层面来说，原初科技采用的原料是含钙镁的工业固废或自然矿石，原料来源充足（亿吨级）、多样、易得，且价格低廉。与此同时，<strong>产出的碳酸钙产品附加值较高，可以广泛应用于建筑、塑胶、造纸、涂料等行业，市场容量达到上亿吨级。</strong></p><p>据悉，该公司拥有完全自主知识产权体系，已获中国授权发明专利20多项，美国发明专利2项，并拥有实质在审专利近20多项。专利覆盖整个工艺流程及核心装置，主导产品填补规模化碳减排领域空白，易于工业放大——<strong>公司的单个项目可实现百万吨级二氧化碳减排，尤其适合火电、石化、煤化工、钢铁、水泥等高碳排放行业。</strong></p><p>值得一提的是，2022年，原初科技在由马斯克赞助的碳去除技术大赛XPRIZE Carbon Removal中，从1133个参赛者中胜出，成为唯一入选全球TOP60榜单的矿化技术路线的中国创新公司。2023年，原初科技入选腾讯举办的“碳寻计划”TOP30。</p><p>目前，原初技术的主要合作伙伴多为大型央企及行业龙头，包括国家能源集团、中国石化集团、国投电力公司、宁夏煤业集团、陕煤集团等。其中，<strong>该公司与国能集团合作的火电厂二氧化碳化学链矿化捕集利用技术1000吨/年研究与示范项目，已在国电山西大同电厂成功投运。</strong>公司还与国电电力和中石化集团合作，通过了国电电力火电厂年处理1000吨CO2中试验收与技术鉴定，并进入10万吨级与百万吨级的产业化实施阶段。</p><p>原初科技方面透露，<strong>公司目前已累计完成近亿元融资</strong>，主要用于扩大研发、专利布局、市场拓展等方面，以不断提升竞争优势。</p><p><strong>投资人观点：</strong></p><p>至临资本一直关注双碳领域的科技创新机会，CCUS作为双碳领域重要的技术路线，在未来会得到越来越多的重视和利用。作为本轮投资的领投方，我们看好原初的团队、自主知识产权和项目经验积累，期待原初科技作为CCUS市场的中坚力量为国家双碳领域的发展持续做出贡献。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520739060197121</id>
            <title>国产手机OLED出货量激增116%，华为小米新机“卖爆”面板厂商获益</title>
            <link>https://www.36kr.com/p/2520739060197121</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520739060197121</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 09:22:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 国产高端机, Q3国产手机柔性OLED出货量, 量价齐升, 手机OLED业务的发展前景
<br>
<br>
总结: 国产高端手机市场表现强劲，Q3国产手机柔性OLED出货量大幅增长，手机面板价格上涨。国产OLED厂商看好手机OLED业务的发展前景，预计未来仍将保持增长势头。 </div>
                        <hr>
                    
                    <blockquote><p>国产高端机发力，Q3国产手机柔性OLED出货量激增116%。深天马A表示前三季度柔性OLED手机产品出货同比增长超过300%。手机面板迎来”量价齐升“，TCL科技、维信诺等均表示看好手机OLED业务的发展前景。分析师预计Q4手机OLED面板价格仍将上涨。</p></blockquote><p>在国产高端新机频出且受热捧的情况下，国产OLED厂商迎来“量价齐升”，市场渗透进一步加速。TCL科技（000100.SZ）、深天马A（000050.SZ）、维信诺(002387.SZ)方面，均表示看好手机OLED业务的发展前景。</p><p>近日，深天马A证券部人士向财联社记者透露：“Q3以来，柔性OLED市场需求还是持续较好，公司前三季度柔性OLED手机产品出货同比增长超过300%，目前折叠和LTPO产品也已在出货。”</p><p>群智咨询手机面板资深分析师陈自伟预计，Q4手机OLED面板价格仍将上涨，明年亦稳中有涨。</p><h2>国产手机表现抢眼，OLED国产化加速</h2><p>近期，国产高端手机新品表现抢眼。</p><p>先是华为Mate 60系列在8月底横空出世且受到热捧，Counterpoint Research最新数据显示，今年10月份，华为手机销量同比增幅高达83%；此后，小米于10月下旬推出14系列，销量远超市场预期，据小米官方数据，小米14系列首销销量猛增至上代首销总量的6倍；11月13日，vivo X100系列正式发布，据vivo公布的数据显示，其最新发布的X100系列，预售相比上一代的X90和和X90 Pro销量增长740%。</p><p>面板一直被视作消费电子行情的重要风向标，随着国产手机厂商的发力，手机面板迎来“量价齐升”。</p><p>根据群智咨询（Sigmaintell）全球智能手机面板出货的追踪数据，2023年三季度全球智能手机智能面板出货约5.1亿片（Open Cell口径），同比增长约18.7%，其中，在iPhone15系列以及华为Mate 60系列等中高端旗舰新机型发布潮的带动下，全球OLED智能手机面板出货1.7亿片，同比增长约19%；柔性OLED出货约1.3亿片，同比增长约23%。</p><p>值得一提的是，国产OLED出货量增速远超行业增速。</p><p>陈自伟告诉记者，随着国内OLED面板厂的产能释放和产品力的提升，终端品牌持续加大国产化导入力度，国内柔性OLED面板厂出货量保持快速增长。</p><p>据群智咨询统计，Q3大陆OLED面板出货约7340万片，同比增长75%，占全球市场份额的44.3%。其中，大陆柔性OLED面板贡献约6400万片，同比大幅增长约116%，市场份额增长至约49.2%。</p><p>从A股四家主要面板厂来看，手机OLED的渗透成为今年重要业绩“增量”来源。</p><p>产业链人士向记者表示，今年大卖的华为Mate 60系列、华为Mate X5、华为Mad Pad Pro 13.2均是由京东方A(000725.SZ)及维信诺联合供屏，为两家公司贡献可观增量。</p><p>维信诺方面还向财联社记者表示，今年9月以来，公司还供应了vivo X100系列，独供了OPPO A2 Pro、iQOO 12等多款热门新机。京东方A于10月下旬公布，其2023年第一亿片柔性OLED已下线，其中折叠产品累计出货量达千万片。</p><p>群智咨询数据显示，Q3京东方A柔性OLED智能手机面板在国内头部智能手机高端OLED面板订单持续增加，出货约2800万片，同比增长约52.7%，以16.6%的全球市场份额位居国内第一。</p><p>深天马A证券部人士告诉记者，公司今年独供了小米13T系列、realme 11Pro、11Pro+、OPPO Find X6等不同品牌的多款新机，公司前三季度柔性OLED手机产品出货同比增长超过300%。</p><p>TCL科技旗下TCL华星方面告诉记者，近期，公司独供了小米14系列。TCL华星CEO赵军在此前接受财联社记者采访时还表示，未来将有多款搭载TCL华星折叠屏的手机发布。</p><h2>产业链看好国产OLED后市发展</h2><p>OLED国产化的渗透仍会继续。维信诺方面告诉财联社记者，未来手机OLED市场将会持续增长，渗透率仍有提升空间，公司注重技术创新和高质量交付，将持续聚焦中高端市场，进一步助力终端产品创新。</p><p>深天马A方面向记者表示，接下来随着公司最新的TM18产线产能逐步释放，出货量和出货规格都会持续提升，其也看好柔性OLED产品在形态（比如折叠）、性能（比如宽屏减功耗）上的升级趋势。</p><p>价格方面，陈自伟预计，Q4手机OLED面板价格将迎来一波上涨，明年整体也将呈现稳中有涨的趋势。</p><p>值得注意的是，OLED产业仍在极速发展中，国产厂商们才刚刚进入“收获期”。陈自伟表示，因OLED产线投资及运营成本较大，目前国内OLED面板厂基本仍未能实现盈利状态。</p><p>此外，目前国产厂商在技术上与韩厂仍有一定差距。</p><p>陈自伟称，目前OLED手机应用方面以微创新迭代，与国际领先企业虽有差距，但差距逐渐缩小，国内厂商在折叠、LTPO、COE、MLP等技术创新上均有布局并且已经逐步量产，未来更多地集中在产品性能优化，良率及成本上的提升。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/poB1YPX-H2agCCy7QbSXvA" rel="noopener noreferrer nofollow" target="_blank">“科创板日报”（ID:chinastarmarket）</a>，作者：王碧微，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520735163147781</id>
            <title>别怪Pico不努力</title>
            <link>https://www.36kr.com/p/2520735163147781</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520735163147781</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 09:20:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Facebook, Oculus, Pico, 元宇宙
<br>
<br>
总结: 2014年Facebook（后改名为Meta）花20亿美元买下做VR头显的公司Oculus时，扎克伯格认为VR需要至少10年来普及。目前离2024年还剩不到两个月，这条赛道上的失意者名单却越拉越长，刚上名单的是中国公司Pico。Pico成立于2015年，并在2021年被字节跳动收购，一个重要背景是轰轰烈烈的元宇宙大跃进。 </div>
                        <hr>
                    
                    <p>2014年Facebook（后改名为Meta）花20亿美元买下做VR头显的公司Oculus时，扎克伯格认为VR需要至少10年来普及。目前离2024年还剩不到两个月，这条赛道上的失意者名单却越拉越长，刚上名单的是中国公司Pico。</p><p>Pico成立于2015年，并在2021年被字节跳动收购，一个重要背景是轰轰烈烈的元宇宙大跃进。字节对买来的Pico不可谓不尽心，不仅追加巨额投资，在内容建设上也倾斜了大量资源。</p><p>按照一些媒体的估算，刨掉收购成本，字节在两年里对Pico的投入超过100亿人民币。虽然较之Meta在元宇宙业务3年血亏300亿美元有些相形见绌，但也超过大部分A股上市公司的营收了。</p><p>促使Pico收缩的导火索可能是市场整体的衰退。2021年Pico被收购时，全球VR头显出货量从上一年的670万台猛增至1100万台。结果猛了一年后掉头向下，又跌到了2022年的1000万台以下，市场普遍预计今年的情况会更加惨淡。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8ef653a1241b4a29b1cb44073462a650@1743780481_oswg97355oswg1080oswg937_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这不只是Pico面临的问题，Meta在去年就大刀阔斧优化了1.1万人，苹果的Vision Pro也没有激起太多的涟漪。考虑到逐梦大模型已经取代元宇宙成为新的热门题材，与其硬着头皮继续投资，可能真不如多抢两块H100来得实在。</p><p>跌宕浮沉了10年后，VR的班还是得往后排一排。</p><h2>两条死路</h2><p>前些日子，一条颇为离谱的爆料开始在网络上流传：被Meta寄予厚望的Horizon Worlds，实际只有38个真实用户，比此前《华尔街日报》爆料的月活少了整整4个0[1]。</p><p>Horizon Worlds是Meta的VR旗舰应用，被视为元宇宙版脸书：用户可以创造主题各异的虚拟星球，并用虚拟形象与他人一同社交游玩。</p><p>巨大的数据反差，吸引了一位Youtube博主搞了场“实地调研”。经过一周的深度体验，发现爆料确实是谣言，但也远算不上乐观。</p><p>有一次，博主找到了个玩保龄球的热门虚拟星球，发现居然有多达5个“活人”。一番互动之后，对方告诉他自己只是在这拍TikTok。</p><p>他又试着统计了热门榜Top20虚拟星球的玩家总数，发现只有902人——这意味着Horizon Worlds的日活大概率只有1000人上下[2]。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_35c200a7bb0d4e0d821e966d3125ec95@1743780481_oswg302730oswg1080oswg536_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">在Horizon Worlds拍TikTok的年轻人</p><p><strong>比野生雪豹还珍贵的VR用户，正是当前VR贫瘠内容生态的一个真实写照。</strong></p><p>硬件的畅销需要需要优质的软件内容带动，大部分人在2010年抢购iPhone 4不是因为A4芯片高达800Mhz的频率，而是因为它可以玩愤怒的小鸟和植物大战僵尸。</p><p>考虑到VR的定位更类似PS5和iPad，没有手机这么频繁的换机周期。因此，硬件公司更加依赖软件销售的收入。</p><p>但以商业化最成熟，市场空间最大的游戏为例，随着图形技术的不断迭代，游戏类应用的开发成本也指数级上升。那些现象级游戏大作，通常都需要动辄8、9位数的投入；而每年全球VR设备的出货量仅在1000万台上下，软件开发商自然不愿意冒着风险入场。</p><p><strong>硬件开发商自己下场做内容也是个办法，但这么多年过去，似乎只有任天堂有这个金刚钻。</strong></p><p>因此，想要解决这个“先有鸡还是先有蛋”的问题，很多时候只能指望软件开发商主动当冤大头——还真有。</p><p>2016年，Steam的母公司V社集结了公司成立以来规模最庞大的研发团队，耗时四年打造了3A级VR游戏大作《Half-Life:Alyx》。</p><p>尽管它成功帮助V社多卖出了10万套VR头显，然而内部依旧高情商地称其为“对新技术的一次长远投资”——翻译过来就是亏本买卖[3]。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d3e7c32b329240caa226e2e6eba8eb59@1743780481_oswg600856oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《Half-Life:Alyx》</p><p>这种模式显然是不可持续的，软件开发商不可能每年都烧个成百上千万放烟花。<strong>不过，其实还有另一个解题思路——抛弃游戏这类“重资产应用”，寻找低成本替代。</strong></p><p>然而，VR行业已先后在社交、健身、办公等场景碰了壁，只有擦边线的美女直播和对着线外打的成人产业过得还算滋润。</p><p>2018年时，一家研究成人行业的公司发布过一组数据：截止至当年7月，VR平台上共发布了6000个特定类型的电影，赚取了约5000万美元的收入，与整个SteamVR的游戏收入几乎持平[4]。</p><p>但在过去两年，“拉皮条”的似乎也对VR逐渐兴趣寡然。</p><p>终端的变更意味着内容开发商需要升级对应的技术方案，这就产生了额外的投入。VR影片不仅需要特制的VR摄像机，也对拍摄技巧有较高要求。然而，这种额外投入并没有换来更多的回报。</p><p>考虑到这类演员少、场景单一的电影本身制作成本就低，如果这都赚不到钱，无疑会打击其他影视内容供给端的信心，难免会失去热情。</p><p>此前，Pico也曾推出过VR世界杯观赛、VR演唱会等一系列尝试，也都没能取得太好的市场成绩。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ce9e8d349b1e452fa89ec4b9262829a0@1743780481_oswg715386oswg720oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">VR世界杯</p><p>几位成人行业分析师公开表示，他们发现VR成人片现在只是一个稳定的利基市场，而不是可能颠覆格局的破坏性创新。因为一项调研数据显示，哪怕VR成人片已发展了近10年，美国成年人中仅有10%的人尝试过这类内容，并且大多数都是浅尝辄止[5]。</p><p>大额投资内容却看不到太多回报的可能，已是整个VR产业不得不面对的现实。</p><p>当科技公司们恢复理性，收缩也就成了主基调，哪怕是曾经豪言壮语的Meta亦是如此。2月，Meta宣布关停平台上人气最高的多人在线VR游戏《Echo VR》，因为其活跃用户仅有约1万人[6]。</p><p>因此，Pico选择收缩自然不那么奇怪了；事实上，如果不是字节跳动树大招风，Pico这一轮收缩很可能都不会引起太多关注。</p><p>而造成这一现状的，更多是VR技术上的不成熟。</p><h2>两个250</h2><p>过去几年，整个VR行业都在等待苹果成为“救世主”。苹果非常擅长将一个不温不火的细分赛道做出巨大的增量，他们在智能手表和TWS耳机上都证明了这一点。</p><p>屡次从风口沦为无人问津的VR/AR，亟需一个苹果这样的玩家。然而，随着Vision Pro最终揭开面纱，人们这才发现苹果交出的答卷似乎并没有那么惊艳。</p><p>Vision Pro几乎是一款“极致堆料”的产品。</p><p>在光学方案上，苹果采用了最新的Pancake 3P技术。Pancake是近些年备受业界关注的光学方案，主要利用偏振光的原理，让光线在1块或多块透镜之间多次折射，从而将光学总长（TTL）缩短至传统方案的一半，以便将头显做得更轻薄。</p><p>而苹果采用的3P版本，指的是使用3块透镜进行光线折射，以实现更低的色差、更高的画面像素。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7251cb604f474b9c96e776f53d331090@1743780481_oswg62206oswg919oswg282_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">不同光学方案TTL的区别，图源：Wellsenn XR</p><p>代价则是贵。对光学膜材料和贴膜工艺要求较高，全球只有为数不多的企业可以生产。除此之外，由于Pancake只能依赖人工贴膜，其量产效率也并不高。</p><p>另外，VR厂商又无法直接使用技术成熟的智能手机屏幕，因为OLED难以做到超小像素，近眼使用的情况下，能明显看到像素点，实际效果仿佛隔着一层纱窗看东西。</p><p>与此同时，VR/AR自身的各项技术又处在研发早期。最适配Pancake方案的屏幕是Micro LED，但目前并没有公司能量产。</p><p>苹果已经为该技术持续投入研发了近十年，但至少要到2026年，第一款搭载了Micro LED的产品才有机会面世[9]。</p><p>当下，VR硬件厂商只能在“凑合用”和“多花钱让体验不那么凑合”之间做出抉择。</p><p>Vision Pro选择了后者，其代价就是光屏幕成本就超过了600美元，够买2台Pico 4了。当然，如果VR硬件厂商选择廉价版的LCD屏幕，亦或是干脆放弃Pancake，实际体验又免不了大打折扣。</p><p>这就是VR长期面临的另一个问题：<strong>无法在成本阈值的限制下实现良好的体验。</strong></p><p>智能手机迅速普及的幕后功臣不是4999元的iPhone 4，而是799元的红米手机。当下，即便是廉价版的VR头显，售价也要两三千元；如果只是拿来看小电影或者玩《Half-Life:Alyx》，那么多数普通消费者未必乐意掏腰包。</p><p>事实上，前Meta顾问、传奇程序员约翰·卡马克（John Carmack）对此深有体会。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_836076b390ac41ba8aef72d296c14aa4@1743780481_oswg645282oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">John Carmack</p><p>卡马克早于2013年便在Oculus担任首席技术官，早于Facebook的收购，算是VR行业资历最深、最有影响力的老兵。2022年10月，卡马克最后一次参加了Meta Connect大会，在演讲中提到了他长期以来的战斗口号：</p><p><strong>“两个250”——VR头显的定价不超过250美元，重量不超250克[10]。</strong></p><p>但时至今日，还没有一家公司能在这两个限制条件下做出哪怕合格的用户体验。这可能也解释了卡马克为何在战斗多年后，最终还是提桶跑路，转战人工智能。</p><p>考虑到中国市场在VR领域的含金量并不算高——出货量占比只有全球的10%左右。因此，国内公司的生存环境也就天然恶劣一些。要知道Pico已经是国内出货量最大的VR公司了。</p><p>生态的缺位、技术的难题、成本的束缚，是这个产业过去十年都没能解决的问题。想让字节一口气处理掉这些麻烦，只能给他一个哆啦A梦才行。</p><h2>理解失败</h2><p>字节跳动在VR上的折戟，其实不必过多苛责。</p><p>Pico的跌宕浮沉有一个非常贴切的参考样本：<strong>十年前Facebook失败的手机项目。</strong></p><p>2012年，Facebook是如日中天的社交霸主，也是华尔街的抢手货，但作为掌舵者的扎克伯格却如坐针毡。伴随iPhone和苹果的连战连捷，Facebook的转型却显得笨手笨脚，全公司懂iOS开发的程序员都没多少，Facebook的移动App更新到2.0时，负责维护的都只有一个员工。</p><p>一个标志性事件是App Store迟迟不通过Facebook 3.0版应用的审查，让扎克伯格大为光火的同时，也意识到在移动终端时代，Facebook的命运或多或少被掌握在了苹果和谷歌手里。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_350e46899a13471b8dc66dfee1cc53fc@1743780481_oswg235704oswg640oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">成为导火索的Facebook 3.0</p><p>随后，一个雄心勃勃的计划开始在扎克伯格脑海中酝酿：<strong>开发一部Facebook品牌的手机，搭载自研的芯片和操作系统。</strong></p><p>扎克伯格原本的想法是，Facebook想要在数字世界占据主导地位，就必须掌控自己的移动操作系统，才能打破iOS和安卓的束缚。</p><p>后来，Facebook的运营VP帕里哈皮亚（Chamath Palihapitiya）又添了一把火，他认为与其做手机操作系统，不如打造一款移动设备。</p><p>相比Pico的高举高打，Facebook的手机项目在当时被严格保密，几乎没有任何媒体报道。直到2020年，传记《Facebook: The Inside Story》出版后，整个过程才得以呈现：</p><p>整个手机项目团队搬到了一栋未悬挂任何标牌的建筑物二楼，甚至做了一套独立于Facebook的职级体系。当Facebook内部有传言时，公司会予以否认。书中说：这是Facebook第一次在内部撒谎。</p><p>Facebook手机的操作系统由内部完成。至于芯片，Facebook选择与英特尔合作——这似乎解释了这个项目为什么被取消了。</p><p>这部手机曾非常接近上市，甚至富士康已经做出了工程样机，非常超前地搭载了曲面屏[1]。</p><p>项目被废止的原因一方面是高昂的成本，也有来自另一位高管的建言献策：考虑到Facebook的用户规模，谷歌和苹果没有胆量对Facebook乱来。</p><p>后面的事情我们再清楚不过：<strong>扎克伯格的“终端焦虑”并没有缓解，也促使他投身“下一代计算终端”的探索。从收购Oculus开始，Facebook在VR上砸下了百倍于手机项目的投资。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6723df7c92244c03ae613bf0f6be868b@1743780481_oswg175189oswg1080oswg1475_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2021年Pico被收购时，字节跳动是一个与Facebook等量齐观的社交帝国。而且字节同样可以依靠主营业务强大的变现能力，持续给不赚钱的新业务输血，以逸待劳。</p><p>正所谓站得越高看得越远，高处不胜寒是科技公司成长到一定规模时产生的自发的焦虑，也会促使企业针对前沿技术领域的投资。然而，前沿技术的领域的投资会面临一个关键问题：<strong>技术的不确定性。</strong></p><p>人们往往认为创新领域的探索是认准一个技术方向，高举长期主义的口号坚定投资，最终取得累累硕果。</p><p>但实际上，这个过程更像是面对十个迥异的技术方向，经过反复的权衡、试错甚至失败，才能侥幸站在技术浪潮的前沿。</p><p>这个过程既需要大胆的投资，也需要及时的止损。</p><p>每一项新技术与新产品背后，都有一个更长的失败者的名单：松下的等离子电视、丰田的氢能源汽车、摩托罗拉的铱星计划。</p><p><strong>谷歌更为典型，一度在VR/AR领域三进三出：Google Glass、Cardboard、Daydream，全都在短暂火爆后光速停产。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6c1077cfe83847e1917faaccff6651a4@1743780481_oswg229629oswg1080oswg1988_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2012年Facebook的手机项目和2023年的Pico，不过是重复了这个过程：在大举投资之后，发现各方面因素并不成熟，于是止损。就像创始人周宏伟本人所说：我们对行业和市场的发展估计得比较乐观，但实际上没有预期的那么快。</p><p>但在很多语境下，恰恰是很多个失败案例组合起来，才让正确的路线逐渐清晰。</p><p>毕竟在2012年那个时间点，大部分人会觉得苹果最大的竞争对手会是HTC，研究深度学习和人工智能的学者都属于民科，英伟达没有任何可能成为市值最高的芯片公司，特斯拉则会在三年内破产。</p><p>面对前沿技术领域的战争迷雾，既需要孤注一掷的勇气，也需要对失败的宽容和理解。</p><p>对一家科技公司来说，即便乱花钱，也好过不花钱。</p><h3><strong>参考资料</strong></h3><p>[1] Company Documents Show Meta’s Flagship Metaverse Falling Short，The Wall Street Journal</p><p>[2] I Spent A Week Alone In The Metaverse，Jarvis Johnson</p><p>[3] Valve Index sold 103,000 units after Half-Life: Alyx announcement - report，vg247</p><p>[4] Porn and games are the biggest drivers of VR revenues，VentureBeat</p><p>[5] The Big, Costly Dream of VR Porn，InsideHook</p><p>[6] Meta CTO: John Carmack Would Not Have Shut Down Echo VR，UploadVR</p><p>[7] 2022年VR光学专题研究报告：从菲涅尔到Pancake，Wellsenn XR</p><p>[8] Apple AR/MR Headset Prediction Update: 2nd, Shipments, Schedule, and Pancake Lens Supply Chain，郭明錤</p><p>[9] MicroLED Apple Watch Ultra Now Rumored to Launch in 2026, Not 2025，Mac Rumors</p><p>[10] Carmack: “There’s a bunch that I’m grumpy about” in virtual reality，ars technica</p><p>[11] FaceBook：一个商业帝国的崛起与逆转，史蒂文·利维</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/RVKAPU2oa9gq9JYpNKb_zA" rel="noopener noreferrer nofollow" target="_blank">“远川科技评论”（ID:kechuangych）</a>，作者：陈彬，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2519699091088901</id>
            <title>iPhone 16 外观曝光，国产手机看完笑了</title>
            <link>https://www.36kr.com/p/2519699091088901</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2519699091088901</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 09:17:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 11.11, iPhone 15 系列机型, 优惠, iPhone 16 系列
<br>
<br>
总结: 11.11期间，各家电商纷纷推出优惠活动，其中包括iPhone 15 系列机型。虽然这次的升级幅度一般，但是各家电商的优惠力度很大，使得这一代的iPhone 15 系列变得非常值得购买。同时，iPhone 16 系列的消息也传出，其中iPhone 16 Pro将配备“四棱镜”式5倍潜望长焦镜头，并且屏幕尺寸有望增大。此外，新机还有望改名为“16 Ultra”。整体来看，11.11是一个购买iPhone的好时机，而iPhone 16 系列也备受期待。 </div>
                        <hr>
                    
                    <p>11.11 刚刚过去没多久，各家电商就开始发战报了！</p><p>谁能想到，iPhone&nbsp;15 系列机型在这次 11.11 这么能打...</p><p>要知道这可是新机呀？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_1099884228304f8994b6212adf1b3341@000000_oswg52248oswg506oswg787_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>往年的这个时候，iPhone 虽然也是位列销量榜榜首，但那都是上一代的旧机型呀...</p><p>只能说这次 11.11 各家给的优惠都太给力了。</p><p>又或者说，iPhone 它！没有以前保值了~</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_67fe8749a54d4c2e9f93012c9900798c@000000_oswg15481oswg420oswg420_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这代升级幅度一般的情况下，不来点优惠降点价的话，11.11 确实没有上代 14 系列这么值得买。</p><p>但要是有，那 15 系列可就香起来了。</p><p>更有意思的是，iPhone&nbsp;15 系列机型还没捂热多久，下一代 iPhone 16 系列就传出了消息...</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_c4d1dcb9c2f64016896f6f49afb46f49@000000_oswg12747oswg295oswg270_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>说 iPhone 16 Pro 将标配 iPhone 15 Pro Max 上同款 “ 四棱镜 ” 式 5 倍「潜望长焦」。</p><p>而为了能在 16 Pro 的小尺寸机身上塞进潜望镜头，16 Pro 的屏幕尺寸有望从现在的 6.1 英寸增大到 6.3 英寸。</p><p>16 Pro Max 机型则从现在的 6.7 英寸增大到 6.9 英寸。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_1df14ac661844a978575c639378fc29c@000000_oswg16249oswg600oswg148_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_fd63c6bfcfc844d4bfe702c51cd49695@000000_oswg16413oswg600oswg148_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>并且还有望正式改名为 “ 16 Ultra ”&nbsp;...</p><p>新机仍会采用 “ 钛合金 ” 材质，以增加机身强度跟减轻重量。</p><p>那这样看的话，15 Pro Max 是最后一代&nbsp;“ Pro Max ”&nbsp;命名的机型了！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_3329f3a269434201ad573d12ce096df6@000000_oswg11706oswg600oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>至于标准版的 16 跟 16 Plus ！</p><p>则还是维持现在 6.1 、6.7 英寸的尺寸，这个没有变化。</p><p>芯片这块，一开始大家都以为 15 Pro 上了 A17 Pro 后，会将 “ 动过刀 ” 的 A17 留给下一代，也就是标准版的 iPhone 16 机型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_3061011230074203bc4c97ffda361140@000000_oswg127941oswg368oswg370_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>结果苹果跳过 A17 ，直接统一命名&nbsp;“ A18 ” ！</p><p>iPhone 16 跟 iPhone 16 Plus ：A18（N3E）</p><p>iPhone&nbsp;16 Pro&nbsp;跟&nbsp;iPhone 16&nbsp;Pro Max（Ultra）：A18 Pro（N3E）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_f2c6e33bca994308b9a6087880a6d7f0@000000_oswg383504oswg805oswg483_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Pro 款机型还将内置全新的骁龙 X75 基带，支持更新的 Wi-Fi 7 规格。</p><p>而标准版机型则继续沿用现在 15 系列的 X70 基带。</p><p>不过果子相信在实际体验中，不会有明显的感知！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_ab177942082449a58ddc148ff8625872@000000_oswg295279oswg534oswg492_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因为果子相信 iPhone 的信号优化，还是会一如既往的烂...</p><p>听懂掌声~</p><p>而最新的消息还曝出苹果现在正在测试 “ 屏幕打孔 ” 的 iPhone 机型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_4ed7d5d435574b098740632fe4b98198@000000_oswg155107oswg586oswg815_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>说是 iPhone 16 Pro ！</p><p>不过现在还未能最终确定...</p><p>说实话，果子是不太认为 iPhone 会在下一代 16 Pro 上改变设计，何况还是现在安卓机型普遍都在用的正面屏幕 “ 打孔 ” 的设计。</p><p>硬要说的话，iPhone 新一代的 SE 机型，反而会有望采用这样的设计。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_dcc83f547bfc468ba5ae2e6c296af753@000000_oswg2689oswg178oswg153_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因为要是苹果抠到不想下放 Face ID 的话，采用 “ 打孔 ” 总比只有 “ 空刘海&nbsp;” 的设计要好吧？</p><p>你们说是不是...</p><p>然后用上更低成本的侧面 Touch ID 指纹触控解锁，这种事苹果也不是干不出来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_bd1bd7b57e39402cba0661e783ba2ecf@000000_oswg14867oswg395oswg430_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但仔细一想，要是这样的话，苹果不就要为 SE 重新开一条生产线了！</p><p>因为全新的 “ 打孔 ” 屏幕、全新的中框啥的...</p><p>就苹果现在这种主张 “ 环保 ” 的大公司，也不太能干的出来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_1c9c180322e4426699c05f03dcd364e8@000000_oswg106707oswg434oswg337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>加上最近也有传闻表示最新的第四代 SE 预计将采用类似 iPhone 14 的外观...</p><p>所以大概率还是 “ 刘海 ” 设计。</p><p>再仔细一想，明年开始苹果全是 “ 灵动岛”&nbsp;设计的机型，而恰好 SE 用 “ 刘海 ” 这种旧设计，也能明显区分于新机！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_b79751797ffa4114a35f4b1d56bf9d91@000000_oswg573606oswg1080oswg673_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Emm......也有道理也有道理~</p><p>爆料还称第四代 SE 将拥有最新的 USB-C&nbsp;接口、4800 万单摄以及 60Hz&nbsp;低刷...</p><p>果子很想吐槽一下，怎么每年的第四代 SE 爆料都不一样？</p><p>算了！爆料嘛...讲究的就是一个 “ 猜 ” 字。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_2dd76aae3b744bb580587982f0924c0c@000000_oswg8430oswg600oswg337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以这款内部代号为 D59 ，项目代号为 Ghost 的第四代 iPhone SE ！</p><p>什么时候能跟我们见面呢？</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzU2MzcyNzgzOQ==&amp;mid=2247778648&amp;idx=2&amp;sn=4f1bcf319e38158131102d49af64ef36&amp;chksm=fc5b1de8cb2c94feb98cefc50834eb945f1682bb72297f2eecb88a035656d4a9f5acfe4c0226&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“科技狐”（ID：kejihutv）</a>，作者：果子，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520723841935107</id>
            <title>智氪 | 预期反转，利润新高，暴涨 7%后京东大象起舞？</title>
            <link>https://www.36kr.com/p/2520723841935107</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520723841935107</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 08:59:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 京东, 财报, 业绩, 增长
<br>
<br>
总结: 京东发布的财报显示，其三季度的营收和利润均超过市场预期，实现了增长。尽管受到消费淡季和大盘结构性疲软的影响，但京东在业务结构调整和降本增效方面取得了积极的成果。此外，利润超预期也打消了补贴对盈利能力的担忧。展望未来，随着传统消费旺季的到来和经济的持续复苏，京东的业绩增长有望继续稳定。 </div>
                        <hr>
                    
                    <p>文｜范亮 黄绎达</p><p>编辑｜黄绎达 郑怀舟</p><p>京东这次走了一个漂亮的反转剧本。</p><p>早前各大卖方机构对京东的三季度业绩预测均不太乐观，盈利预期被一再下调，公司的市盈率也一度回落至12倍的黄金水平。不过，11月15日晚当京东的三季报正式揭露后，着实给了市场一个惊喜。</p><p><strong>从公司整体的业绩情况来看，京东三季度的营收为2477亿元人民币，同比增长1.7%；Non-GAAP归母净利润为106亿，同比增长约5.5%。不仅收入和利润表现均超过彭博一致预期，而且Non-GAAP归母净利润还刷新了历史单季度最高水平。</strong></p><p>当然，要从同比增长幅度来看，能看到消费淡季对公司的影响，但市场最看中的往往是财报里一些细微的边际变化，这些细微的边际向好很可能是某一方面未来趋势的起点，故而会对公司的估值水平起到积极的提振作用。</p><p>二级市场方面，受Q3财报利好驱动，京东美股11月15日收盘单日暴涨7%，盘中涨幅一度甚至超9%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c47911f0d9104e8399573f5f5042b53a@5426566_oswg182191oswg962oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：11月15日京东美股分时走势；资料来源：wind，36氪</p><p>那么，京东的这份财报还有哪些细节披露呢？</p><h2><strong>01 财报综述</strong></h2><p><strong>京东在2023年三季度实现营业收入2477亿元，同比增长1.7%。</strong>长期来看，京东收入增长放缓主要是受到了消费大盘结构性疲软的拖累，同时也包含季节性因素，而且市场已提前预期到了这一趋势，彭博将本季度京东的一致预期收入环比调低至2469亿元，<strong>而实际上京东的本季收入还小幅超市场预期。</strong></p><p>收入结构方面，从业务类型的维度出发，京东的收入可分为商品收入（1p）与服务收入（3p）。京东本季度的商品收入录得1953亿元，同比减少0.9%；同期实现服务收入524亿元，同比增长12.7%。</p><p>再从业务板块来看京东的收入结构，京东零售、京东物流、达达和新业务这四大业务板块是京东收入的主要来源。其中，京东零售在23Q3实现收入2121亿元，收入占比81%；京东物流同期收入417亿元，收入占比16%；达达同期收入29亿元，收入占比1%；新业务同期收入38亿元，收入占比约2%。</p><p>从长期趋势来看，零售业务的支柱地位未变，收入结构也因此总体保持稳定。本季度内，京东业务结构边际上的一大亮点，是零售业务在销售淡季保持了一定韧性的同时，物流业务在基数升高的背景下依然保持了两位数的同比增长与环比正增长，其收入占比亦有小幅提升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_445062b15cab4ce3a0d876230a10b0bb@5426566_oswg105492oswg1080oswg493_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：京东营业收入情况与收入结构；资料来源：wind，公司财报，36氪</p><p>成本方面，京东在23Q3的营业成本为2089亿元，同比微增0.78%，环比大幅减少了15%。费用方面，本季度京东的费用支出合计295亿元，同比增长2.79%，环比则大幅减少了14%，同期费用率为12%，环比基本持平。</p><p>费用结构方面，同期履约开支（采购、仓储、配送、客户服务及支付处理开支）为152亿元，同比增长6.1%；营销费用支出了80亿元，同比增长3.1%；研发费用支出38亿元，同比减少7.8%；一般及行政开支25亿元，同比减少5.6%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9b1eab367baa421cbd269648a86f92fe@5426566_oswg113979oswg984oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：京东成本与费用支出情况；资料来源：wind，公司财报，36氪</p><p><strong>利润方面，23Q3京东实现毛利润388亿元，小幅超市场预期，同期毛利率为15.7%。</strong>毛利率较上一季度小幅提升1pct，一方面是1p转3p持续收到了正反馈，随着3p模式收入占比的提升，公司整体的盈利能力也出现了小幅改善；另一方面则说明补贴对京东的利润并未产生明显的影响。</p><p><strong>京东在本季度实现经营利润93亿元，同比增长6.6%；同期实现Non-GAAP经调整的归属股东净利润106亿元，同比增长5.9%，Non-GAAP归母净利率4.3%，在利润增长远超市场预期的同时，Non-GAAP归母净利润还刷新了历史新高。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_dae8a3ecee49403ab480f8233861b2d7@5426566_oswg141006oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：京东的利润情况；资料来源：wind、公司财报、36氪</p><p><strong>总的来看，收入端在受到了大盘结构性疲软叠加消费淡季的影响后，京东的利润与增长情况均远超市场预期。一方面，业务结构调整与合理的降本增效共同起到了关键作用，我们可以看到履约与营销费用在本季都有不同程度的增长，说明公司在展业上并非束手束脚；另一方面，利润超预期也进一步打消了补贴影响盈利能力的担心。</strong></p><p>展望Q4，随着传统消费旺季的来临，叠加经济的持续复苏，京东Q4的业绩增长通常相对确定。从Q3呈现出的一些边际变化来看，零售业务的增长动能恢复程度、物流业务对整体的业绩边际影响、1p转3p的业务结构调整都是影响京东未来业绩的关键。</p><h2><strong>财报要点解读</strong></h2><h3><strong>京东零售：1P超预期，3P还未发力</strong></h3><p>今年Q3京东零售累计实现营业收入2120.59亿元，实现营业利润110亿元，同比均是持平状态。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bb33f77c7b134139932e49e5f38ff3d9@5426566_oswg96154oswg1080oswg639_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：京东零售收入情况；资料来源：公司公告，36氪整理</p><p>从收入的细分项来看，京东零售的收入与公司财报中披露的商品收入（1P）、平台及广告服务收入(3P)基本吻合，因此，我们也可以通过这两项收入的变动情况来分析京东零售结构性的变化。</p><p>1P收入方面，京东在Q3累计实现营收1953.04亿元，同比下降0.9%，其中电子产品及家用电器销售基本持平，日用百货则下降2.3%。</p><p><strong>京东在电子产品及家用电器领域还是展示出了一贯的统治力，</strong>要知道在空调等核心电器在二季度提前透支需求+苹果与华为手机在三季度并未开始放量的背景下，消费电子与家电行业大盘还是呈现出比较大的压力。</p><p><strong>根据国家统计局数据，今年三季度家用电器及音响+通讯设备两项合计社零同比下降幅度达到2.56%。在此背景下，京东相关品类的营收能够与去年同期保持一致，已经相当不易。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a54f9b38b2cd40d7b4fbfffddc6784e1@5426566_oswg74097oswg1080oswg531_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：家用电器及音响+通讯设备社零季度增速；资料来源：Wind、36氪整理</p><p>日用百货方面，社零数据同比是正增长，而京东则是负增长。其中缘由我们也在此前的财报分析中指出过：<strong>去年受疫情影响，居民生活用品消费主要以线上为主，因此京东日用品业务实际上是受益状态，而今年线下渠道恢复后，受去年线上销售高基数的影响，京东日用品业务不可避免会受到影响，不过这将会在明年有所缓解。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_0568c5fdce3c43dcaecbed82fd383a03@5426566_oswg246398oswg1080oswg589_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：京东收入结构；资料来源：公司公告，36氪整理</p><p><strong>另外，京东1P商品收入出现下滑，实际上可能也与公司发力3P业务有关。</strong></p><p>在今年1P与3P业务实现流量平权后，京东也为入驻商家提供了较多的优惠政策，如“春晓计划”升级了20项商家扶持举措，取消了此前90天的“0元试运营”期限，部分商家“0元试运营”时间无限延长，另一方面，针对个人及个体户商家，京东还将技术服务费率低至零的类目扩展至98%。<strong>京东披露，这一系列举措带动三方商家整体数量在三季度保持同比三位数增长。</strong></p><p>与此相对，京东为了提高自营业务的竞争力，并对冲3P业务造成的影响，在8月底京东自营宣布PLUS会员享受不限次数的全年免邮服务，普通用户从“99元免邮”升级到“59元免邮”的举措。</p><p><strong>不过，3P业务尽管在运营端的数据表现非常亮眼，但目前在财务端的影响依然还在边际层面。</strong>今年Q3，京东的平台及广告服务收入为195.29亿元，同比增速为3%，这个<strong>增速水平一方面反映了消费淡季的影响，更主要原因还是前文提到的，京东升级对第三方商家的优惠措施所致。</strong></p><p><strong>可见京东目前对3P业务还是潜心培育的状态，并未在财务转化方面提出过高的要求。</strong>因此，对京东的3P业务，也应该给予更高的容忍度，耐心等待收获期的到来。</p><h3><strong>京东物流：规模效应跑起来了</strong></h3><p>今年Q3，京东物流累计实现营业收入416.63亿元，同比增长16.5%。</p><p><strong>从客户结构来看，京东物流来自京东以外的营收为298.36亿元，同比增长近20%，在物流业务营收中的占比也突破70%。</strong>其中，有部分收入增长来源于去年7月1日至26日德邦物流还并未入表的贡献。</p><p>此外，京东物流来自京东的营收则为118.26亿元，同比增长8%。不难发现，<strong>这个增速水平超过京东自营商品收入的增速，这也与京东自营降低包邮门槛的举措相吻合，毕竟更低的包邮门槛对物流业务而言就意味着更高的订单量。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6e2b7e04921e4ea08aabc285b5e7d076@5426566_oswg108770oswg1080oswg697_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：京东物流收入情况；资料来源：公司公告、36氪整理</p><p>值得关注的是，京东物流今年三季度的毛利率为7.9%，比去年同期增长0.5个百分点，非国际准则净利润则为8.4亿元，同比增长88%。</p><p>整体来看，京东物流利润水平的上升来自两方面的贡献，<strong>一是物流建设开支进度相对放缓，开始注重精细化运营（京东物流Q2非流动资产规模较22年底有所下降）；二是订单数不断上升，规模效应开始发挥威力。</strong>我们预计，在全年运单量最高的四季度，京东物流将会迎来历史最高的毛利率水平。</p><p><strong>目前来看，京东基础设施逐渐完善-订单量上升-单位订单成本下降的规模效应正在形成，这也许是京东自营敢于下调包邮门槛的底气所在。</strong></p><p>我们认为，在京东物流业务利润水平大幅上升，零售业务仍受到宏观因素压制的大背景下，<strong>物流这块底座将会在未来为京东贡献一定的利润增量，而不再是拖后腿的角色。</strong></p><p>最后，我们再来看看即时配送板块达达的表现，今年Q3达达的收入为28.67亿元，同比增长约20%，经营亏损由去年同期的3亿元大幅缩窄至5000万元，表现亮眼。尽管该业务板块收入占比不算高，但还是对京东业绩的边际改善有积极效果</p><h3><strong>新业务：收入占比有小幅被动提升</strong></h3><p>京东新业务分部主要包括京东产发、京喜及海外业务。本季度，京东新业务收入录得38.18亿元，同比减少24%，相比上一季度同比减少的幅度有明显缩窄。该业务收入的持续同比减少，说明当前公司聚焦核心业务的战略未变，因此也在持续收缩京喜和国际业务。该分部的收入占比在Q3有小幅提升，则主要是被动提升。</p><p>盈利能力方面，新业务分部在本季度经营亏损为1.4亿元，去年同期则盈利2.76亿元。去年同期新业务盈利主要是靠处置资产，而本季没有处置新业务相关的资产，仅靠业务运行而出现小幅亏损，在新业务边缘化的背景下亦在预料之中。</p><h2><strong>03 小结与展望：预期向好，底部显现</strong></h2><p>在我们之前的京东财报点评中，一直在强调京东国民级电商的行业地位，正是基于此让京东的业绩增长与整个经济的周期波动具有一定的同步性。<strong>所以，从长期趋势来看，经济复苏相对确定，由此也决定了京东业绩修复在长期维度具有较高的确定性。</strong></p><p><strong>当然，业绩修复的节奏也会受到小周期的影响。回溯京东近年来的业绩表现，Q3收入都会出现一定程度的环比下降，今年也是如此。</strong>这种季节性现象的背后，主要还是Q3没有大的购物节庇佑，而通常618、双11都会大幅透支消费力，所以Q2、Q4的业绩通常也会好于Q3。</p><p>从品类上来看，京东在电子产品及家用电器领域的统治力斐然，但也是正由于3C电子和家电的收入占比较重，当消费大盘遭遇结构性疲软时，京东的Q3业绩也不免受其拖累。京东管理层也看到了业务结构上的问题，故而在在近年来积极推进业务结构调整。</p><p><strong>再说，京东本季度1p业务中的3C电子与家用电器的收入同比持平，明显跑赢消费电子大盘。</strong>论及背后的驱动因素，首先是得益于长期的供应链建设与优质服务带来的良好消费体验，其次Q3业绩也在一定程度上证明京东意在通过补贴来熨平周期波动的战略目标初步达成。而且，利润率在本季度的提升，也在逐步打消市场对对于补贴影响业绩的担忧。</p><p><strong>在业绩保持韧性的同时，降本增效也是助力本季度业绩大超市场预期的主要驱动之一。</strong>从绝对值来看，降本增效的效果在之前几个季度已经逐步逼近极值，边际递减已经十分明显。</p><p><strong>那么，当下的降本增效重点在调结构，让费用支出更加合理。</strong>其中，履约支出与营销支出在本季度有一定程度的增加，前者与持续的供应链建设有关，后者则是表明京东在逆周期里依然在积极展业。</p><p>估值方面，京东目前的PE-TTM又回到了12倍左右，之前的估值调整主要是消化掉了市场对Q3业绩相对不乐观的预期，而Q3业绩超预期后京东美股的暴涨，也表明了目前京东的业绩底与估值底已经同时显现。</p><p>展望未来，在消费季节性回暖与经济复苏的共振下，京东Q4的业绩大概率会出现短期内的强劲增长，这一预期将对于目前估值提供强支撑。再往后看，随着经济进一步回暖，国际商贸环境持续改善等一系列利好的持续释放，作为消费巨头的京东亦将因此而受益。</p><p>再看短期的投资机会，当京东的估值再次回到历史底部，同时长期与短期业绩预期双双向好，所以目前投资京东已然具备了良好的安全边际，在估值修复的驱动下，至少短期的投资机会是相对确定的。</p><p>*免责声明：&nbsp;</p><p>本文内容仅代表作者看法。&nbsp;</p><p>市场有风险，投资需谨慎。在任何情况下，本文中的信息或所表述的意见均不构成对任何人的投资建议。在决定投资前，如有需要，投资者务必向专业人士咨询并谨慎决策。我们无意为交易各方提供承销服务或任何需持有特定资质或牌照方可从事的服务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bb2de8e4112849f19638a7be9baa8890@5426566_oswg63834oswg901oswg571_img_000?x-oss-process=image/format,jpg/interlace,1" /></p><p class="img-desc">36氪财经</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520702756708482</id>
            <title>小米汽车现真容，30万的售价还能否成为年轻人的第一辆汽车？</title>
            <link>https://www.36kr.com/p/2520702756708482</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520702756708482</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 08:58:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米汽车, SU7, 价格, 竞争
<br>
<br>
总结: 小米汽车拿到了准生证，首款产品命名为SU7，预计售价在30万元左右，将面临激烈的市场竞争。小米汽车的成功与否成为年轻人的首选汽车，将取决于其在竞争中的表现和价格优势。小米汽车可能通过智能化体验和性价比配置来打破局面。 </div>
                        <hr>
                    
                    <p>11月15日，小米汽车登上工信部公布第377批《道路机动车辆生产企业及产品公告》新产品公示文件，这意味着小米汽车拿到了准生证。</p><p>从公示信息来看，小米汽车首款产品将命名为SU7，尾标挂的是北京小米，申报的车型有SU7和SU7Max两款；尺寸为4997x1963x1440mm，轴距3000mm；动力层面则有220kW/220KW+275kW两种配置，标配主动尾翼。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f9815c8557444c1a8a87769106ca05fb@164897159_oswg21002oswg640oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在产品售价层面，此前雷军在直播中透露其价格将在10–30万区间，而汽车大V韩路则在微博中透露称：小米首款汽车价格将在30万元左右。</p><p>若此售价为真，那么小米汽车无疑将直面当前竞争最为激烈的新能源汽车市场。</p><p>在此问题也随之而来：<strong>在激烈的市场竞争中，小米汽车能否脱颖而出，打响第一枪，还能否成为年轻人的第一款汽车？</strong></p><h2><strong>三年造车终落地，但行业竞争更趋激烈</strong></h2><p>回首小米造车路径，其执行落地速度可以说是相当迅速的。</p><p>2021年3月30日，小米正式宣布下场造车，并宣布了首期投资100亿元人民币，预计未来10年投资额100亿美元打造汽车业务的资金投入计划。</p><p>雷军在随后的发布会上更表示：小米汽车将是他人生之中最后一次重大的创业项目，他愿意押上人生全部的声誉，亲自带队，为小米汽车而战。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8b5d86d157a54f9a84bef97ff3a0fb11@164897159_oswg17967oswg640oswg274_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>距今，时间还不足三年，小米汽车就已拿到了准生证，只待一场发布会，便可与大众相见，可以说是上演了小米速度。</p><p>而据传闻称，小米汽车或将于明年二月发布。</p><p>虽然小米汽车落地迅速，但也客观存在的事实是：当前新能源汽车市场的竞争环境相对于2021年，已经发生了天翻地覆的变化，目前新能源汽车市场已经极度内卷——不仅是价格，在产品硬件配置、智能辅助驾驶等层面的竞争，亦似是不能有短板。</p><p>如此现实，也使得小米汽车一上市，就将面临特斯拉焕新版Model 3、蔚来ET5、小鹏P7、阿维塔12、智界S7等产品等一大批实力强劲的对手。</p><p>在此现实下，小米汽车能否破局，成为“年轻人的第一款汽车”，显然将成为市场最大悬念。</p><h2><strong>可能的破局之道？</strong></h2><p>从小米当前的种种布局举措来看，我们也或可预测小米汽车将要进行的市场打法。</p><p><strong>首先可能是会依托生态合力打造更佳的智能化体验。</strong></p><p>在10月份，小米便发布了自研的操作系统——澎湃OS，这款操作系统的一大特征就是具备跨端智联能力，能够实现多设备融为一体，硬件能力跨端调用；同时还具备主动智能能力，能够统一思考，多维感知，主动为人服务。</p><p>对于小米澎湃OS，雷军在微博中表示，这款操作系统为未来百亿设备、百亿连接做好了万物互联的公有底座，为小米构建起了「人车家全生态」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_352d61b1b80e40879a60bc5059584753@164897159_oswg30405oswg640oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在此，小米汽车的出现，则意味着补齐了小米人车家生态中的最后一块拼图。在此也可预期在澎湃OS的加持下，小米汽车的智慧座舱体验或许能成为其与其他产品竞争的一大筹码——毕竟以自家操作系统为底座进行调校进而带来更佳智慧座舱体验，在市场上已有成功先例——诸如搭载华为鸿蒙操作系统的多款车型，其智能座舱体验，相对于市面上的其他车型，就有着相对优势，也成为了众多用户选择智联车型的重要理由。</p><p>在此现实下，小米作为第二家以自研操作系统上车，其产品座舱体验在基础的流畅性以及智慧车联之外（小米此前就发布了CarWith 2.0，可以将手机应用及服务延展至汽车），我们也或可期待他打通多端互联能力，乃至是打通家居物联网体验。</p><p><strong>其次可能是用配置凸显性价比。</strong></p><p>从小米的发展历程来看，在产品上用料足，并以此彰显产品性价比，可以说一直是小米的特点。</p><p>虽然目前小米汽车在工信部目录中展现的硬件配置中，我们看到激光雷达、前挡风玻璃、尾部字标、黑色尾部字标、ETC、徽标、天幕玻璃、轮辋均属于选装配置，这在汽车行业虽属于惯例，但对于这些选配配置，我们则也或可预期小米会给出一个感动人心的价格。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e2d9bcaf1a3643bd90e0c82275fbdc37@164897159_oswg45317oswg640oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而小米汽车在公告中汇总尚未披露的配置诸如产品制造工艺、电池倍率、内饰设计、舒适性配置、智能辅助驾驶等方面的配置，我们或可以大胆猜测小米汽车的配置或会有诸如800V超充技术、3C 或4C倍率电池、前后一体式铝压铸技术；在智能座舱层面搭载高通骁龙8295芯片并结合AI大模型配合手机生态；在自动驾驶芯片层面则可能会采用英伟达Orin芯片、搭载激光雷达并使用全栈自研的自动驾驶系统等。</p><p><strong>其三则是智能辅助驾驶系统能否跻身一流。</strong></p><p>智能辅助驾驶，不仅是车企实力的象征，在当前更成为用户购车的重要功能配置，而从公开信息来看，小米在智能辅助驾驶领域首期就投入了33亿元研发费用，并组建了一支超过500人的研发团队，目标是在2024年打入自动驾驶第一阵营。</p><p>而在去年，小米也曾秀了一把小米汽车的智能辅助驾驶功能（智能召唤），从当时雷军的演示来看，其一键召唤功能开启后，只要在手机上点一下，车辆就能自动从车库中上来，甚至能连上两层，从B2层驶出车库接人。</p><p>这是小米在智能辅助驾驶领域为数不多的显露。</p><p>所以在智能辅助驾驶领域，小米的技术能力能否超越特斯拉、华为和小鹏等明星企业。可能还有待产品上市后的用户检验。</p><p><strong>其四则是在价格上给予用户惊喜。</strong></p><p>虽然目前业内流传的是小米汽车的售价将在30万元这一价位区间，但透露这一价格的大V，目前已经删除了这条微博，而在今日爆料出的一份所谓“小米汽车专家交流会纪要”中，则显示称“小米汽车首款车的最低配置价格在20万以内，中等配置价格在24万左右，最高配置价格不会超过30万。”</p><p>但这些价格均未得到官方回应，所以当前小米汽车的价格其实依旧是云雾缭绕，在此现实下，我们或可预期，当前在市场上流传的这些所谓价格，极有可能都是烟雾弹<strong>。</strong></p><p>而在说一千道一万不如价格降一万的消费市场，显然价格还是最具杀伤力的武器。</p><h2>写在最后：</h2><p>从官宣造车到产品落地，小米汽车上演了极快的执行落地速度。但在更为激烈的市场竞争环境下，初生的小米汽车，又能否向当初小米手机那样迅速打开市场，成为年轻人的第一款汽车，为市场注入新的竞争活力，我们唯有等待小米汽车正式发布方可见分晓。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzAwNzM3Nzg0Ng==&amp;mid=2651073582&amp;idx=1&amp;sn=2a717fc6c6179b9bd877aec2b658a72c&amp;chksm=808f8af7b7f803e1b3262bfeade7442c91f1c2579c978306ec8ea7848a160fe2cc004213faee&amp;token=1744587950&amp;lang=zh_CN#rd" rel="noopener noreferrer nofollow" target="_blank">“邻章”（ID:TMT317）</a>，作者：邻章，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520695897401094</id>
            <title>LeCun与微软总裁开呛，曝出OpenAI六大金刚掌握AGI命运，一旦实现微软收益为0</title>
            <link>https://www.36kr.com/p/2520695897401094</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520695897401094</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 08:51:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, LeCun, 微软总裁, OpenAI六大金刚
<br>
<br>
总结: 微软总裁与Meta的LeCun发生争执，引发了关于OpenAI的讨论。微软总裁提到OpenAI是非盈利组织，引发网友质疑。OpenAI澄清微软只是其子公司，微软对OpenAI的收益有限制。OpenAI的决策由六位董事会成员决定，他们的决定将对人工智能领域产生深远影响。 </div>
                        <hr>
                    
                    <blockquote><p>代表Meta的LeCun和投资了OpenAI的微软总裁，居然当面开呛了？总裁一句话引全网激战，最后却引出「OpenAI六大金刚」决定微软投资命运这一惊人事实。</p></blockquote><p>最近，微软总裁Brad Smith在和LeCun的一次线下座谈中起了争执，随后在网上引发了网友大量的讨论。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_89dd06e649b34b949c378d6b1e694ffa@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在面对LeCun关于大模型开源问题时，微软总裁抛出：「OpenAI是一个非盈利组织，Meta是一个由股东控制的上市公司，大家更希望AI技术被哪家掌握？」</p><p>大量网友对微软总裁指出的「GPT-4的开放性，以及OpenAI是非盈利组织」的观点猛烈输出：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a6c6b05689f94bb7b960f7d003a32673@000000_oswg241713oswg1080oswg751_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>认为「天下苦微软久矣」的网友把针对微软的怒火也发到了OpenAI身上，逼得OpenAI的公关负责人连忙发帖，再次重申：OpenAI不是微软投资的公司，是一家完全独立的非盈利组织！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cdcd6ed0039c4a79be16ba041ebbc249@000000_oswg333529oswg1080oswg1299_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他一再强调，微软投资的「OpenAI」，其实只是「OpenAI子公司」。换句话说，微软拿到的股份，也只是「OpenAI子公司」的股份。</p><p>而这个「OpenAI子公司」是完全隶属于「OpenAI母公司」——OpenAI Nonprofit的。</p><p>而微软与OpenAI的投资协议中规定，微软对OpenAI获得利润的收益，仅限于「OpenAI母公司」章程中规定的「达到AGI之前的收益」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1d2e2a134a0049448d837f3f05f7a674@000000_oswg44992oswg1080oswg170_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果「OpenAI母公司董事会」一旦宣布「AGI已成」，那么微软将不再能从OpenAI获得任何收益！</p><p>所以，按照这个逻辑，微软绝不是大家以为的「OpenAI的金主爸爸」，反而更像「OpenAI追求AGI」的工具人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a015e88726e44114b6e6567828123cf6@000000_oswg60171oswg1080oswg734_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而这个能做出「达到AGI」决定的董事会，拥有了剥夺微软投资收益的权力。</p><h2>「OpenAI六大金刚」</h2><p>有权力确定是否「达到AGI」，从而停止让微软等投资者分享OpenAI收益的「OpenAI 母公司董事会」，由6个人组成：</p><p>董事长兼总裁Greg Brockman、首席科学家Ilya Sutskever、首席执行官Sam Altman以及另外3个非OpenAI的雇员Adam D'Angelo、Tasha McCauley和Helen Toner组成。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_142aa2b76e9540279c45f6c75c25259b@000000_oswg964957oswg1080oswg713_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Ilya Sutskever左一，Sam Altman左二，Greg Brockman右一</p><p>这六个人作出的决定，将深刻影响人工智能领域的发展。</p><p>对于前三位，熟悉OpenAI的人想必都会有所了解，那么另外三位又是何许人也？</p><h3>Adam D'Angelo</h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_04e5ee4dbf3c4848ab715feb7d9c84f9@000000_oswg667398oswg990oswg660_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Adam D'Angelo生于1984年，他最著名的身份是Quora的联合创始人兼首席执行官。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8ec1de29171a46409804401b08eb493c@000000_oswg435127oswg1080oswg743_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Quora是世界上最大的知识问答型社区，在百科类网站流量仅次于Wikipidia。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_08671992bd3e4b25b835b28b6ab75146@000000_oswg67481oswg786oswg427_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在2008年之前，他一直担任Facebook的首席技术官，并兼任工程副总裁。</p><p>在他离开Facebook之前，是小扎手下最得力的干将。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1f629af35638433e9d481223b489fd2c@000000_oswg25321oswg791oswg341_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Adam D'Angelo曾在Phillips Exeter Academy就读高中。在那里，他与扎克伯格等人一起开发了Synapse Media Player（一款音乐建议软件）。</p><p>作为天才少年，Adam D'Angelo于2002年进入加州理工学院，在之后的ACM国际大学生程序设计竞赛（ICPC）中获得不俗战绩（2003年北美冠军；2004年世界总决赛银牌；2005年世界总决赛联合教练）。</p><p>现在，他主要的精力花在一个新的AI项目——Poe之上。</p><p>这是一个集合了各大AI聊天机器人和产品的集合工具，通过它可以访问几乎市面上所有的AI工具。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9383b3e961924e81bbbbe1fbea02ea3d@000000_oswg333661oswg811oswg1212_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>Tasha McCauley</h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ad5c3746d1ef4ebbad8fc7817f7ebfc8@000000_oswg1905956oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Tasha McCauley以其在机器人领域的工作而闻名，她是Fellow Robots的联合创始人。</p><p>2004年，McCauley从Bards College获得艺术学士学位，之后又从Singularity University获得了机器人学学位。2011年，她还获得了南加州大学马歇尔商学院的商业学士学位和工商管理硕士学位。</p><p>她的职业生涯始于机器人技术，并在母校教授机器人技术和人工智能。</p><p>毕业后，她被任命为学校Autodesk创新实验室的主任。</p><p>2010年，她开始在「NASA Research Park」校区的「Artificial Intelligence and Robotics Track」担任助理教授。</p><p>McCauley目前是「Ten to the Ninth Plus Foundation」的董事会成员，该公司致力于全球技术创新和进步。</p><p>而她的另一个身份是著名演员Joseph Gordon Levitt的妻子。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_365be3b42ba84fe89efb34231f02743d@000000_oswg119875oswg229oswg220_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>Helen Toner</h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8f59576bbaa64869917ac84eb4df911b@000000_oswg63661oswg799oswg533_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后一位董事会成员为Helen Toner。</p><p>她是乔治城大学安全与新兴技术中心（CSET）的战略和基础研究基金主任。</p><p>她曾在Open Philanthropy担任高级研究分析师，在那里她为政策制定者和资助者提供人工智能政策和战略方面的建议。</p><p>在Open Philanthropy工作和加入CSET期间，Helen住在北京，作为牛津大学人工智能治理中心的研究附属机构，研究中国的人工智能生态系统。</p><p>她本科毕业于澳大利亚墨尔本大学，曾在清华大学学习过一段时间的中文，硕士毕业于乔治城大学。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f5cc50db083d46bba18390111f78f821@000000_oswg77428oswg780oswg436_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他们三位都曾与有效利他主义运动（Effective Altruism movement）有过联系。</p><p>而OpenAI长期以来也与EA有着千丝万缕的关联：例如，2017年3月，OpenAI从有效利他主义者资助的Open Philanthropy获得了3000万美元的资助。</p><p>但OpenAI发言人说：「我们的董事会成员都不是有效利他主义者；他们与EA社区的互动主要集中在与人工智能安全相关的话题上。」</p><p>AGI的定义还远未达成共识，因此，由六个人决定是否已经达到AGI，这对OpenAI以及整个世界意味着什么？</p><p>而未来可能做出这一决定的时机和背景对其最大的投资者微软又意味着什么？</p><h2>6人董事会决定AGI：不寻常，但合规合法</h2><p>Suzy Fulton是一位专门为科技领域的初创企业和新兴公司提供法律服务的律师，她认为，虽然在很多情况下，由董事会做出这种「AGI决定」是「不寻常的」。</p><p>但根据OpenAI的章程，「OpenAI母公司」董事会确实有权力决定「安全、广泛受益的AGI」使命。</p><p>Suzy说，「他们认为，非营利性董事会的受益人是人类，而营利性董事会的受益人是投资者。他们试图建立的另一个保障措施是让董事会多数成员独立，即多数成员在OpenAI中没有股权。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7d133b7c3b1847129ea0ecd5e9b818fa@000000_oswg343688oswg730oswg360_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>芝加哥大学法学院教授Anthony Casey也认为，由董事会决定像AGI这样的具体操作问题是「不寻常的」，但他不认为存在任何法律障碍。</p><p>他说：「具体确定某些问题必须在董事会层面做出决定，这个规定本身是没有问题的。事实上，如果一个问题足够重要，公司法一般会规定董事有责任对该问题进行监督。」</p><p>并不是所有专家都相信AGI会很快到来，有些专家甚至质疑AGI是否可能实现。</p><p>据人工智能与数字政策中心（Center for AI and Digital Policy）主席Merve Hickok称，「应该调查OpenAI，并命令该公司停止发布GPT模型，直到建立起必要的保障措施为止。OpenAI对AGI的关注忽视了人工智能模型和工具的当前影响。」</p><p>她认为当前不应该讨论OpenAI董事会成员是否有资格决定是否「达到AGI」。</p><p>因为「这将转移焦点，并在事实上使AGI是可能的说法合法化」。</p><p>事实上，OpenAI缺乏对AGI的明确定义：</p><p>OpenAI曾在2023年2月的一篇博文中表示「第一个AGI将只是智能连续体上的一个点」。</p><p>但在2023年1月的采访中，Sam Altman说的是：「我希望看到的未来是，人工智能的使用权超级民主化，世界上有多个AGI，可以帮助人们形成多种观点，不会让任何人变得太强大」。</p><h2><strong>OpenAI的梦想由微软买单？</strong></h2><p>我们无法知晓OpenAI和微软之间投资协议的全部细节。</p><p>但根据OpenAI官方公布的情况来看，微软从投资OpenAI的一开始，就接受了的上限股权的提议，以及将AGI技术和公司的完整控制权留给「OpenAI Nonprofit」的要求。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_31e0e5c0d5cd47d5832337734417bfc4@000000_oswg93990oswg1080oswg329_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>听起来似乎一旦OpenAI完成了他们既定的实现AGI的使命，微软就将退出这个圈子。</p><p>但如果OpenAI真诚地履行其非营利性使命，那么OpenAI的结构以及与微软的关系可能会导致一些「大纠纷」。</p><p>Anthony Casey指出：「确实有一些非营利组织拥有营利组织的股份，其中最著名的是Hershey Trust。但他们完全掌控营利机构，没有小股东的反对。但对于OpenAI，微软的营利性利益可能会直接与控制实体的非营利性利益发生冲突」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8f566a39dde243178136bdce30b6ba75@000000_oswg552627oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>利润上限很容易实施，难的是，如果达到最高利润与非营利组织的使命相冲突时，又该怎么办？</p><p>通常，实现利润是首要任务，管理者必须将其放在首位。</p><p>也许微软会说，「别担心，无论如何我们都是好的。你不欠我们任何义务。」——但这听起来不像是微软的谈判方式。</p><h3>参考资料</h3><p>https://venturebeat.com/ai/openais-six-member-board-will-decide-when-weve-attained-agi/</p><p>https://openai.com/our-structure</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652406768&amp;idx=2&amp;sn=009ccb5da1c852c89d899d6d502a6cb0&amp;chksm=f12bf701c65c7e1715fb747de22553ee8bfa16ba0cc15f3adf13af3aa31fd5a4e8357cd2845b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，作者：润 alan，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520695101285892</id>
            <title>可与H100一战，微软首款5纳米自研芯片震撼发布，Copilot引爆办公全家桶，Bing Chat改名</title>
            <link>https://www.36kr.com/p/2520695101285892</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520695101285892</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 08:51:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, Copilot, 自研芯片, Maia
<br>
<br>
总结: 微软发布了全球首款自研芯片Maia，该芯片具备与英伟达H100和AMD MI300X相媲美的算力。微软的全线产品都加入了Copilot宇宙，并且Bing Chat正式更名为Copilot。用户可以通过微软账号免费使用GPT-4和DALL·E 3。此外，微软还推出了定制芯片Azure Maia 100和Azure Cobalt 100。微软的Copilot Studio是一款低代码工具，可以扩展到Microsoft 365，并且无缝集成OpenAI的GPTs，允许开发者构建自己的GPT。 </div>
                        <hr>
                    
                    <blockquote><p>微软的全球首款自研芯片Maia来了，算力上能和英伟达H100、AMD MI300X一战。微软的全线产品，都加入了Copilot宇宙，连Bing Chat都正式更名Copilot。</p></blockquote><p>微软深夜炸场，万物皆可Copilot！</p><p>Bing Chat，从此更名Copilot。</p><p>登录微软账号，就可以在Copilot专属网站上免费使用GPT-4、DALL·E 3。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b24d9e1e7bfc4300936a1acc41f1d1f2@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>OpenAI的全新王牌爆款——自定义GPT，也被塞进Copilot宇宙，变身为Copilot Studio。</p><p>打工人利器Office，也在Copilot的加持下全面升级。</p><p>而且，微软终于也开始制造定制芯片了！两款为云基础结构设计的定制芯片——Azure Maia 100和Azure Cobalt 100在昨晚闪亮登场。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cb40e4248f0c4e159435d236e29efecc@000000_oswg270453oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>全线改名Copilot，自定义GPT来了</h2><p>今天，微软Copilot全面迎来了新时代。</p><p>在Ignite 2023 大会上，纳德拉宣布Bing Chat和Bing Chat for Enterprise，正式更名为Copilot！</p><p>除了Edge，Copilot可以在Chrome，Safari浏览器上网页运行，并且很快上线移动设备。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d61ac175bfa84e9096fc29d324e369d9@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，Copilot免费版可以在必应和Windows中直接访问，还有一个专门入口（https://copilot.microsoft.com/）。</p><p>Microsoft 365中的Copilot依旧需要付费。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8c83fe6267394361b3fa06a1a048df97@000000_oswg96052oswg900oswg506_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Microsoft 365的Copilot目前仅限于微软最大的客户，企业必须至少达到300个用户，才能进入AI驱动的Office助手的名单，每位用户每月收费30美元。</p><p>今年年初，微软还曾提到与谷歌搜索竞争的AI野心，但现在看起来，这家老牌巨头显然把目光投向了ChatGPT。</p><p>在OpenAI宣布每周有1亿人使用ChatGPT后，Bing Chat直接更名。</p><p>这不得不让外界猜想，尽管有价值数十亿美元的密切合作关系，但微软和OpenAI仍在争夺相同客户，而Copilot，就是微软试图抛给消费者和企业的最佳选择。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_4eaa65ad444f4331b12a9acbb0021ce3@000000_oswg140240oswg350oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>值得一提的是，微软大会还发布了低代码工具——Microsoft Copilot Studio。</p><p>与OpenAI可以定制的GPT还是有所不同，它是可以扩展到Microsoft 365。</p><p>其优势在于，Copilot Studio可以在同一网页上进行构建、部署、分析、管理内容。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2afca9b83322491b9457a9eb65214623@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更重磅的是，Copilot Studio无缝集成OpenAI的GPTs，允许开发者构建自己的GPT。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_4e2f5920f8fe4738a923b7507c005474@000000_oswg429640oswg700oswg686_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，Copilot Studio还有一个可以分析的仪表板，管理员可以集中监视使用情况并进行分析，在管理中心内控制访问权限。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ab16b8504c7547c2bfdac115101ac469@000000_oswg142840oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>微软还在Dynamics 365 Guides集成了Copilot，将生成式AI与混合现实相结合，帮助一线员工完成复杂的任务。</p><p>未来，工程师无需搜索大量文档或纸质手册，仅通过自然语言和手势就能查询信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ee10afa4c7554957bc811d635b6fe971@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>微软自研芯片来了</h2><p>此前，坊间曾传出传言：微软在悄悄构建自己的芯片，用于训练大语言模型，避免对英伟达过度依赖。</p><p>现在证实了——传言是真的！</p><p>今年的大模型热，让H100的需求激增，单块甚至在eBay上卖出了超过4w美元的价格。</p><p>这块大蛋糕，微软绝对不会放下，Azure Maia和Azure Cobalt CPU明年就会上市。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8f6b3eb2bd8f497aa706053748a363f5@000000_oswg100757oswg1080oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">SemiAnalysis深度分析：https://www.semianalysis.com/p/microsoft-infrastructure-ai-and-cpu</p><h3>Azure Maia GPU（Athena/雅典娜）</h3><p>虽然微软是四巨头（亚马逊、谷歌、Meta、微软）里最后一个发布产品的，但这次的Maia&nbsp;100 GPU却毫不逊色——</p><p>在算力方面能与英伟达（H100）和AMD（MI300X）一战，在网络IO方面遥遥领先，而在显存带宽方面则稍显落后。与目前使用第二代Trainium/Inferentia2芯片的亚马逊相比，纸面上的各项指标都实现了碾压。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_442463c5cd824e45886ff49c7adbbbe3@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，Maia采用的是台积电5nm节点工艺，拥有1050亿个晶体管的单片芯片。并支持微软首次实现的8位以下数据类型，即MX数据类型。</p><p>算力方面，Maia在MXInt8格式下，算力可以达到1600 TFLOPS，在MXFP4格式下则为3200 TFLOPS。</p><p>由于是在LLM热潮出现之前设计的，Maia的显存带宽只有1.6TB/s。虽然这比Trainium/Inferentia2高，但明显低于TPUv5，更不用说H100和MI300X了。此外，微软采用的是4层HBM，而不是英伟达的6层，甚至AMD的8层。</p><p>据业内人士分析，微软当时在芯片上加载了大量的SRAM，从而帮助减少所需的显存带宽，但这似乎并不适用于现在的大语言模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_97f41599bfcc42a8ad0b148f96446b7e@000000_oswg297887oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Maia的另一个有趣之处，便是微软对网络的处理。</p><p>就AMD和英伟达而言，它们都有自己的Infinity Fabric和NVLink，用于小范围芯片的高速连接（通常为8个）。如果要将数以万计的GPU连接在一起，则需要将以太网/InfiniBand的PCIe网卡外接。</p><p>对此，微软采取了完全不同的方式——每个芯片都有自己的内置RDMA以太网IO。这样，每个芯片的IO总量就达到了4.8Tbps，超过了英伟达和AMD。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_eb2a0c5e5cdb437493eb3909e390f62a@000000_oswg210335oswg1080oswg363_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了充分发挥出Maia的性能，微软专门打造了名为Ares的机架和集群，并首次采用了「Sidekick」全液冷设计。</p><p>这些机架是为Maia高度定制的，比标准的19"或OCP机架更宽。</p><p>具体来说，微软在一个机架上搭载了8台服务器，其中每台服务器有4个Maia加速器，也就是共计32个Maia芯片。除此之外，还会配备网络交换机。</p><p>此外，Maia机架的功率可以达到约40KW，这比大多数仍只支持约12KW机架的传统数据中心也要大得多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8b1814a0e8f14e6a82de201a303c8dc8@000000_oswg1089323oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Maia 100服务器机架和「Sidekick」液却</p><p>值得注意的是，微软使用的是自己从第三方获得SerDes授权，并直接向台积电提交设计，而不是依赖Broadcom或Marvell这样的后端合作伙伴。</p><p>Sam Altman表示，第一次看到微软Maia芯片的设计时，自己和同事感到非常兴奋。而OpenAI也已经用自己的模型（GPT-3.5 Turbo）对Maia进行了改进和测试。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_530b935a7f854396a908caad0e0b18a4@000000_oswg157201oswg1080oswg456_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">就在昨天 ，Sam Altman刚刚宣布访问量激增超出承受能力，Plus账号注册暂停</p><h3>Azure Cobalt CPU</h3><p>CPU方面，Microsoft Azure Cobalt是一款基于Armv9架构的云原生芯片，针对通用工作负载的性能、功率和成本效益进行了优化。</p><p>具体来说，Azure Cobalt 100 CPU共有128个核心，并支持12条DDR5通道。</p><p>与微软第一款基于Neoverse N1的Arm CPU相比，基于Neoverse N2的Cobalt 100在性能上提升了40%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1c06d56ab49042f1ad5114e408c3f488@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与Arm传统的只授权IP的商业模式不同，Neoverse Genesis CSS（计算子系统）平台可以使CPU的开发更快、更容易，且成本更低。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fe6d2ddf2c154bed97050775da5eb6af@000000_oswg255889oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_04c3b98f8c7a4630aac2c5113a28eb9b@000000_oswg200216oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9a5b5caf6c15438ca6a8f5832b87a0ea@000000_oswg210417oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就Cobalt 100而言，微软采用的是2个Genesis计算子系统，并将它们连接成1个CPU。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_695d50c43d384204ae01781151e62576@000000_oswg212728oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7494c255b9f84af2be4314d57d3d1372@000000_oswg224218oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3a108b73c3ab4a008abca07e5dbb5b56@000000_oswg171036oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Arm此前曾表示，有一个项目从启动到完成芯片只用了13个月。根据业界推测，这里提到的很可能就是微软。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_705cca5abf29412f8843705960bd0b05@000000_oswg325679oswg1080oswg598_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以说，微软花了许多心思。在设计上的独具匠心，不仅让它具有高性能，还能控制每个内核和每个虚拟机的性能和功耗。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e3955e63d792456b95c8ae6a61ceb474@000000_oswg1250016oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">用于测试Microsoft Azure Cobalt片上系统的探针台</p><p>目前，微软正在Microsoft Teams和SQL Server等工作负载上测试Cobalt CPU，计划明年向客户提供用于各种工作负载的虚拟机。</p><h3>重新思考AI时代的云基础设施</h3><p>实际上，微软在芯片开发上有着悠久的历史。</p><p>20多年前，微软就和Xbox合作，还为Surface设备共同设计了芯片。17年，微软就开始构建云硬件堆栈。</p><p>Azure Maia AI芯片和Azure Cobalt CPU都是在微软内部构建的，微软对整个云服务器堆栈进行了深入检修，以优化性能，功耗和成本。</p><p>用微软硬件系统负责人Rani Borkar的话说，「我们正在重新思考人工智能时代的云基础设施，并从字面上优化该基础设施的每一层。」</p><p>现在，微软、AMD、Arm、英特尔、Meta、英伟达和高通在内的集团，都在标准化AI模型的下一代数据格式。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_095e8725dc654ede9f4fffbadd0d53f7@000000_oswg110517oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>微软：我们和英伟达是互补，不是竞争</strong></h3><p>跟H100、H200，甚至是AMD最新的MI300X比较，Maia的性能如何呢？</p><p>Borkar回避了这个问题，而是重申微软与英伟达和AMD的合作对于Azure AI云的未来很重要。</p><p>「重要的是，在云运行的规模上优化和集成堆栈的每一层、最大限度地提高性能、使供应链多样化，为客户提供基础设施的选择。」</p><p>据悉，要实现ChatGPT的商业化，OpenAI需要30,000块A100，如果用微软自研的芯片，显然会降低AI成本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_0b0e729730414997b57b567ed85c0aea@000000_oswg96095oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>考虑到目前AI领域的速度，Maia 100的继任者很可能会和H200相同的速度推出，也就是大概20个月后。</p><p>随着微软本周推出更多的Copilot功能和Bing Chat的品牌重塑，Maia必然会大显身手。</p><h2>GPT性能/总拥有成本</h2><p>对于芯片来说，最重要的是性能。</p><p>在推理方面，需要注意的是，微软所做的内存权衡是非常不利的，这使得微软很难与之竞争。</p><p>H100的内存带宽是其2倍多，H200是其3倍，而MI300X甚至更高。</p><p>因此，在LLM推理方面，Maia 100的性能处于劣势。就每秒处理更大批大小的token而言，GPT-4推理的性能大约是 H100的1/3。</p><p>值得注意的是，这本身并不是一个大问题，因为制造成本与英伟达的巨大利润率弥补了大部分差距。</p><p>问题是，电源和散热仍需要更多成本，而且token到token的延迟更差。</p><p>在聊天机器人和许多协同Copliot工具等对延迟敏感的应用中，Maia无法与英伟达和AMD GPU竞争。</p><p>后两种GPU都可以使用更大的批处理量，同时可接受延迟，因此它们的利用率会更高，性能TCO也比Maia高得多。</p><p>在GPT-3.5 Turbo等较小的模型中，情况要好一些，但微软不能只部署针对小模型的优化硬件。因为随着时间的推移，GPT-3.5 Turbo等小模型将被逐步淘汰。</p><p>不仅在硬件上强强联合，微软会上还宣布将英伟达AI代工厂服务（Nvidia AI Foundry）引入Azure。</p><p>不仅有英伟达的基础模型、NeMo框架、DGX Cloud AI超算以及服务全部集成到微软Azure平台，向企业和开发者开放。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5ad8cbfba44b4a54b27f769f8aa62099@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>数学推理飙升50%，27亿参数Phi-2开源</h2><p>开发者方面，微软在自家的Azure AI上提供了从数十亿到数万亿不等的基础模型。</p><p>纳德拉现场激动地表示，OpenAI团队做了非常出色的工作推动AI的前进，我们将继续推进深度合作。</p><p>他现场承诺：只要OpenAI一更新，微软就会在平台全部交付。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7b57b6213a6b42649406106e4884d620@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>OpenAI首届开发者大会上的模型更新，同样上线微软开发者平台。其中，包括GPT-4 Turbo，以及GPT-4 Turbo with Vision，DALLE·3。</p><p>另外，微软还将提供GPT-4的微调功能。这样，开发者可以调用自己的数据去微调自定义的GPT-4。</p><p>至于定价，微软与OpenAI保持一致。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_72f86e43406d4b2591fa5485e8d9d246@000000_oswg294932oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同样，微软Azure AI还支持开源模型。</p><p>开发者能够轻松地将Stable Diffusion、Llama 2、G42 Jais等最新的模型，通过API集成到应用中。</p><p>另外，微软还宣布了全新的小体量模型——Phi-2，仅有27亿参数，并将在未来开源。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cbaf621f4aef4016b46b864bfa56d3d4@000000_oswg521695oswg1080oswg616_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最新Phi-2模型，同样是在教科书级数据上完成训练，比前身Phi-1.5更加强大，在数学推理上的性能飙升50%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_172d4dd546ff4b5bba0c2b1ae91697d6@000000_oswg154022oswg1080oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了模型，为了进一步降低开发者门槛，微软还推出了全链条开发工具——Azure AI Studio。</p><p>它提供了完整周期的工具链，是一个端到端的平台，包括模型的开发、训练、评估、部署、定制等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d6fb213d4b65468f818b4ce67690185f@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>参考资料</h3><p>https://www.semianalysis.com/p/microsoft-infrastructure-ai-and-cpu</p><p>https://www.microsoft.com/en-us/microsoft-365/blog/2023/11/15/introducing-microsoft-copilot-studio-and-new-features-in-copilot-for-microsoft-365/</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652406768&amp;idx=1&amp;sn=58adbb1197a02d2d4388071bf69b5511&amp;chksm=f12bf701c65c7e17edd18ea5a880f24032a890c818aa95f524b45bda55666d4fa1b7125ad783&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520430130439689</id>
            <title>腾讯缓行，稳字压倒一切｜焦点分析</title>
            <link>https://www.36kr.com/p/2520430130439689</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520430130439689</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 08:14:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 腾讯控股, 字节跳动, 高质量增长, 视频号广告
<br>
<br>
总结: 腾讯控股发布2023年Q3财报，净利润增速高于收入增速，但与字节跳动相比，腾讯的总营收被甩下。腾讯在广告和游戏业务方面表现不佳，尽管视频号广告带来了增量，但其他广告收入不及预期。腾讯游戏面临激烈竞争，发布新作的速度较慢。腾讯强调高质量增长和放长线钓大鱼的策略。 </div>
                        <hr>
                    
                    <p>文｜王毓婵</p><p>编辑｜乔芊</p><p>11月15日，腾讯控股发布了2023年Q3财报。本季度，公司再次实现了净利润增速（39%）高于收入增速（10%）的局面。腾讯愈发展示出“人到中年”的稳和重——虽然体量可观，但是步履沉重，利润是靠削减成本省出来的。</p><p>恰巧在财报发布的前一天，海外科技媒体The Information披露，字节跳动今年Q2的营收同比增长40%，拉动整个上半年营收增长至540亿美元。消息传回国内，许多媒体将腾讯与之相比——腾讯上半年的总营收是414亿美元，已经被字节远远甩下。</p><p>虽然包括腾讯在内的许多互联网大公司在最近两年反复强调“降本增效”、“高质量增长”、“利润比扩张更重要”，但字节跳动的高歌猛进还是令人不禁怀疑，问题到底是出在了环境上，还是出在了公司上。</p><p>三季度，腾讯的两大核心业务——游戏和广告收入增长不及分析师预期。在电话会议上，当被问及关于游戏增长预期、广告增长预期、视频号增长预期等等一系列问题时，腾讯首席战略官詹姆斯·米歇尔和总裁刘炽平提到最多的词汇仍然是：“高质量增长”、“谨慎的成本政策”和“放长线钓大鱼”。</p><h3>广告：视频号带来增量，但是还不够</h3><p>三季度，腾讯网络广告业务收入257亿元，同比增长20%。这一成绩低于分析师普遍23%左右的增速预期。</p><p>外界对腾讯广告业务的高预期，主要来自于：1.视频号带来的增量；2.广告主需求的复苏，以及腾讯与阿里加强合作后获得更多投放预算；3.由于开屏监管等因素的影响减弱，移动广告联盟预计维持强劲复苏。</p><p>事实上，视频号广告确实在Q3贡献了增量：微信的泛内循环广告收入（指以微信小程序、视频号、公众号和企业微信为落地页的广告）同比增长超过30%，并贡献了超过一半的微信广告收入。</p><p>视频号广告收入环比增长显著，得益于播放量和用户使用时长的增加，同时广告加载率百分比保持稳定（目前ad loads 不到 3%，而国内同行大多超过 10%）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2210d380d7824b9685d5873bc2ad1c70@10269314_oswg531977oswg1312oswg664_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：海豚投研</p><p>虽然詹姆斯·米歇尔在电话会议上没有直接回应花旗分析师“视频号广告收入具体是多少”的提问，但我们基本可以推测出，在视频号广告增长显著的前提下，必然是有其他广告收入拖了后腿，导致整体收入不及预期。业绩报告中提到，长视频内容广告与视频号广告的需求都很强劲，所以可以大致推断，是除腾讯视频之外的其他媒体广告业务表现不佳。</p><p>同时，第三季也是电商广告开支的淡季，宏观条件也并不太有利。</p><p>虽然腾讯广告业务本季度表现略低于预期，但目前来看只是阶段性放缓。四季度有双十一大促，且腾讯与阿里在微信广告方面达成了合作，料将迎来更明显的增长。</p><p>詹姆斯·米歇尔在电话会议上提到了4点“将会推动视频号广告增长”的有利因素，分别是：</p><ol><li>流量：视频号总播放量本季度同比增长 50%；</li><li>广告加载率：目前ad loads不到 3%，远低于国内同行的10%，后备空间充足；</li><li>AI 赋能：现在广告点击率约为 1%，当部署完大模型之后，将更为准确地分析海量数据点，广告的精准投放度也将提高，点击率也会随之提升；</li><li>泛内循环的机会：结合微信小程序，企业微信登录页，视频号和微信支付等基础设施和功能，闭环能力也将不断提升。</li></ol><p>以及，腾讯仍然对未来广告业务的毛利率增长颇具信心。“广告业务的毛利率已经从此前的30%增长到了现在的50%，国际上可以类比的其他公司广告业务毛利率已经达到80%。”詹姆斯·米歇尔说。</p><h3>游戏：有新作，无惊喜</h3><p>三季度，腾讯网络游戏收入 460 亿，同比增长 7.3%，虽然好于二季度，但同样低于分析师预期（8%）。</p><p>三季度是暑期游戏旺季，且有《无畏契约》《命运方舟》《冒险岛》等热门游戏上线，所以业界对本季度游戏收入信心较高。但从结果上来说，腾讯游戏显然在面临比较激烈的竞争：网易《逆水寒手游》首月收入超1.1亿美元，米哈游《崩坏：星穹铁道》首月流水超12亿元，腾讯面对的局面并不轻松。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_716f383b890e4f4f8710085bcde9e88e@10269314_oswg3252741oswg1930oswg912_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《无畏契约》</p><p>本季度，本土市场游戏收入增长 5%至人民币327亿元，得益于近期发布的《命运方舟》和《无畏契约》，以及《王者荣耀》和 《DnF》等长青游戏的收入增加。</p><p>国际市场游戏收入增长14%至人民币133亿元，排除汇率变动的影响后，增幅为7%。就单个游戏而言，《PUBG Mobile》收入回升，《胜利女神：妮姬》、 《VALORANT》和《Triple Match 3D》也为收入增长做出了贡献，而相较于去年同期的发布季度，《幻塔》的收入同比回落。</p><p>腾讯发布新作的速度越来越慢，以至于会出现像今年Q2这样因较少新作以及减少商业化内容发布而导致游戏收入明显受挫的情况。虽然Q3有数款新作上线，但未来这种“慢慢放量”的节奏大概会成为常态。</p><p>“我们确实是将部分游戏的研发周期拉长了6到18个月。”詹姆斯·米歇尔说，原因之一是因为发现“表现最为优秀的游戏蕴含更大的机会”，值得投入更多时间；二是“我们目前追求高质量增长的模式，<strong>在视频号，微信小游戏和电商等业务上的良好进展，让我们即便在三个月内没什么重要游戏产品发布上市，也能保持比较健康的增长速度。</strong>”</p><p>詹姆斯·米歇尔用“放长线钓大鱼”来形容接下来的发售计划。“我们目前<strong>有9款游戏产品在筹划之中，</strong>未来几周内就会有一款新品发布，其他几款会在未来几个月内发布，这些产品的发布也将测试我们的策略是否成功。”</p><p>可以看出，在集团整体追求利润率的大方针之下，未来那些高利润的业务，如视频号和小游戏，将获得更多的优先级。而像游戏这样更需要高投入的业务，则会“控制项目数量”，专注于“降本增效”。</p><p>对于曾经的“现金牛”业务来说，这也许有些残酷，但确实是腾讯走向多元化、追求高利润的必然选择。詹姆斯·米歇尔以微软来类比腾讯，将这个道理表述得更加直白：</p><p>“就像微软在延迟推出Halo游戏的时候不会感到压力，因为大家会一直使用它的操作系统和办公软件等产品，所以不会有利润方面的压力。随着公司广告业务利润率的提升，金融科技和服务业务的好转，电商业务贡献的增长等等，我们的多元化发展策略起到了效果，如果国际游戏业务能够发布更多新品当然更好，但那绝对不是左右公司整体增长的最主要因素。”米歇尔说。</p><p>（欢迎讨论，作者微信号: FromMarsWillGoBack，添加请备注姓名+公司&nbsp;）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520566706823049</id>
            <title>大模型幻觉问题再成焦点，LeCun 为 Galactica 喊冤</title>
            <link>https://www.36kr.com/p/2520566706823049</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520566706823049</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 08:08:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 幻觉问题, Vectara, AI 平台, LLM
<br>
<br>
总结: 近日，AI 平台 Vectara 通过自建幻觉评估模型计算了市面上大多数公共 LLM 的幻觉频率，并发布了排行榜。然而，该评估只考虑了摘要与原文的一致性，而没有评估摘要本身的质量。此外，评估方法也存在一些问题，可能会惩罚总结得更好的模型。这一研究引起了专家的关注和讨论。同时，文章还提到了一年前 Meta 发布的 Galactica 模型因幻觉问题被网友喷到下线的故事。 </div>
                        <hr>
                    
                    <p>众所周知，幻觉问题一直是困扰大模型的一大难题。近日，一个名为 Vectara 的 AI 平台通过自建幻觉评估模型（该模型已在Hugging Face上开源供商业使用），计算得出了目前市面上大多数公共 LLM 的幻觉频率，并以排行榜的形式在 X 上发布了截止 11 月 1 日的测试结果。</p><p>从榜单上可以看到，GPT-4 的准确率为 97.0%，幻觉率为 3.0%，而 Google Palm 的两款 LLM 表现垫底，其中 Palm Chat 的准确率为 72.8%，幻觉率甚至高达 27.2%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fb6d12da0f3f4f71970a8d3f4d1328d4@5764927_oswg1176840oswg686oswg428_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>榜单一经发出，大批网友纷纷转发，但也有专家指出了该排行榜中所含的问题以及我们应该关注到的细节。</p><p>英伟达高级 AI 科学家Jim Fan 指出，这项研究只评估了摘要与原文的“事实一致性”，而没有评估摘要本身的质量。通过简单的复制，摘要总能达到 100%的事实一致性，可以做到完全不存在幻觉。此外，该评估依赖于使用另一个“judge LLM”来决定幻觉是否发生，但几乎没有详细说明该如何进行提示以及如何真正捕捉谬误。Jim Fan 举例道，“假设模型注入了一些无关但真实的事实。比如文章只提到 ‘巴黎’，但模型却返回‘巴黎，法国的首都’。这算不算幻觉？”</p><p>Jim Fan 表示，事实上，这项研究甚至可能会惩罚那些总结得更好的模型，因为它们往往会进行更多的转述和提炼。此外，他也呼吁道，在下结论之前，还是务必阅读评估协议。这一点对于 LLM 任务和其他任何 ML 系统都普遍适用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ea8faef5b1c1451995c40760c3a41e40@5764927_oswg1632879oswg687oswg593_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Jim Fan 的观点得到了很多大佬的支持，而 Meta 首席人工智能科学家 Yann Lecun 也是转发了本条推特。</p><p>或许是这个排行榜大火，Meta 一年前发布的但只存活了三天的 LLM——Galatica 的共创者 Ross Taylor 今日也是打破沉默，转发了 VentureBeat 关于 Galatica 因幻觉问题被网友喷到下线的故事原委。而 Yann LeCun 也是感慨道：“你知道‘早发布，勤发布’这句开源圈的老话吗？说到人工智能，还应加上‘是的，但要准备好忽略 Twitter 上暴民们荒谬的末日预言’。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_67dc8bf890844c73be654185949844cc@5764927_oswg1035380oswg687oswg376_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>Galactica 的故事</h2><p>那么，一年前 Meta 的 Galactica 究竟发生了什么？</p><p>一年前，也就是 OpenAI 发布 ChatGPT 的两周前，Meta 发布了一个名为 Galactica 的研究演示。作为一款开源的“科学大语言模型”，Galactica 是在包括 4800 万篇科学论文在内的数据基础上训练出来的，Meta 称 Galactica 能够“总结学术文献、解决数学问题、生成维基文章、编写科学代码、注释分子和蛋白质等”。</p><p>然而，Galactica 只公开存活了三天。2022 年 11 月 17 日，Meta 因“幻觉”这个当时还未成为主流的词被网友喷到撤下了演示版。许多人对 Galactica 有时非常不科学的输出感到震惊。是的，和其他 LLM 一样，Galactica 会输出一些听起来有理但实际上是错误的信息。</p><p>当时，Meta 首席科学家 Yann LeCun 为该模型进行了辩护，并发布了一系列推文，但一切无济于事。Galactica 没有成为生成式人工智能时代改变游戏规则的模型。</p><p>两周后，ChatGPT 正式发布。尽管 ChatGPT 同样存在幻觉问题，但这并没有减缓 ChatGPT 成为 LLM 之星的步伐。在短短两个月内，ChatGPT 的月用户数量就达到了 1 亿，而现在每周的用户数量已经达到 1 亿。</p><p>Ross Taylor 表示，Galactica 是当时其领域中一个很好的模型；在计算量分别减少 10 倍和 2 倍的情况下，它的性能超过 PaLM 和 Chinchilla。此外，整个研究团队也只有 8 个人，比当时其他 LLM 团队少了一个数量级。</p><p>然而，由于工作量巨大，团队在没有检查的情况下就发布了 Galactica 基础模型的演示。Ross Taylor 表示，发布演示的考虑因素之一是，其团队希望了解人们用于 LLM 的科学查询的分布情况（这对指令调整和 RLHF 非常有用）。然而网友们却在领域之外进行了查询，从而招致了大范围的谩骂，团队也失去了态势感知能力。据 Taylor 自己讲述，该团队也曾假设分享基础模型的所有缺陷，并在演示版上加上四个关于幻觉的免责声明，但并没有起作用。</p><p>Taylor 称，另一个失误是团队把愿景什么的都写在网站上，导致人们误把网站当成了“产品”。而事实上，该团队并没有将其视为产品！只是一个基本模型演示。</p><p>Ross Taylor 对 Galactica 的遭遇感到痛心，但他并没有后悔。Taylor 表示，“与其后悔，不如有所作为。”幸运的是，Galactica 的大部分工作和研究都促成了 LLaMA 系列的发布。</p><p>Meta 人工智能研究副总裁 Joelle Pineau 在接受 VentureBeat 采访时解释说：Meta“很可能错误地估计了”人们对 Galactica 的期望，但“我们已经将从中吸取的教训融入到下一代模型中”。</p><p>2023 年 2 月，Meta 发布了 Llama 模型在人工智能研究领域掀起了一场风暴，随后在 7 月，Meta 推出了商用的 Llama 2，8 月又推出了 Code Llama。随着 Llama 成为首个主要的免费”开源“LLM，开源人工智能开始崭露头角，并引发了一场热火朝天的讨论。</p><h2>错误地谩骂可能适得其反</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6b379faf2c4f45189caee7db969c6c00@5764927_oswg1098701oswg687oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Galactica 死于非命，正如 Lecun 所讲，“它是被一群贪婪的推特暴徒谋杀的。暴徒们声称，我们现在所说的 LLM 幻觉将摧毁科学出版系统。结果，一个对科学家非常有用的工具被摧毁了。”</p><p>是啊，在如今大火的 AI 圈子里，独立思考显得尤为重要。“打着人工智能伦理的幌子，错误地谩骂可能会适得其反。”</p><h3>参考资料</h3><p>https://venturebeat.com/ai/what-meta-learned-from-galactica-the-doomed-model-launched-two-weeks-before-chatgpt/</p><p>https://github.com/vectara/hallucination-leaderboard</p><p>https://twitter.com/rosstaylor90/status/1724547381092573352</p><p>https://twitter.com/DrJimFan/status/1724464105371939301</p><p class="editor-note">本文来自微信公众号“AIGC新智界”（ID:AIGCxinzhijie），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520471866713861</id>
            <title>当数据成为「生产资料」，三篇论文总结如何用水印技术保护AI训练数据版权</title>
            <link>https://www.36kr.com/p/2520471866713861</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520471866713861</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:56:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 训练数据, 水印, 所有权验证, 后门攻击
<br>
<br>
总结: 本文讨论了在AI训练数据中添加水印的方法及应用场景。通过在数据集中嵌入数字水印，可以保护数据集免遭未经授权使用。其中，一种方法是通过后门攻击进行数据集水印，防御方通过假设检验检查可疑模型是否包含特定的隐藏后门，从而进行数据集验证。这种技术可以应用于保护AI训练数据集的所有权，并防止未经授权的使用和侵犯版权。 </div>
                        <hr>
                    
                    <h2>1、引言 -- 为什么要在 AI 训练数据中添加水印？</h2><p>深度神经网络（DNN）以其高效率和高效益被广泛应用于许多关键任务应用和设备中。高质量的已发布（如开源或商业）数据集是 DNNs 技术发展的关键因素之一。研究人员和开发人员利用这些数据集验证其模型的有效性，进而加快 DNN 的开发。这些已发布数据集非常有价值，但收集数据的过程通常耗时且非常昂贵。在这样的应用背景下，在 AI 训练数据中添加水印，对于保护数据集免遭未经授权的使用以及保护数据创作者的版权具有重大的意义，值得深入研究和探讨。</p><p>目前，已有的一些数据保护技术，例如加密、数字水印、差分保护等，主要目的是防止未经授权的用户使用受保护的数据。然而，这些方法并不适合保护 DNN 训练所依赖的公开发布的数据集。具体来说，加密和差分保护处理会影响受保护数据集的正常功能，而数字水印技术在这种场景下的作用很小，因为未经授权的用户只会发布他们训练好的模型，而不会公开他们的训练样本。</p><p>如何保护公开发布的数据集仍是一个重要的未决问题。这个问题具有挑战性，因为攻击方是可以访问被攻击的数据集的。数据集的安全性是 AI 在推广应用过程中必须面对的一个关键问题，因此，吸引了产业界的广泛关注。Digimarc 公司最近推出了一项名为 Digimarc Validate 的新服务（https://www.digimarc.com/），旨在帮助保护数字内容的版权。这一服务允许版权所有者在其作品中嵌入数字水印，从而有助于防止 AI 模型在训练过程中针对训练数据出现侵犯版权的问题。</p><p>与此同时，学术界也非常重视水印技术在 AI 数据中的应用。我们在这篇文章中分析了几篇近期发布的论文，重点讨论了在 AI 训练数据集中添加水印的技术。</p><p>前两篇文章是来自清华大学深圳研究院的同一个研究团队，聚焦于 “通过在数据集中嵌入数字水印来保护数据集免遭未经授权使用的方法”。其中，第一篇文章针对 poison-only 后门攻击，将保护 AI 训练数据集的问题表述为所有权验证。在这一问题中，一般包含两个参与方：防御方和攻击方，一般来说，防御方会发布自己的数据集，并希望保护其版权；而攻击方的目标则是 "窃取" 已发布的数据集，用于未经防御方许可训练其商业模型。在后门攻击中，攻击方会在训练过程中将隐藏的后门植入被攻击的模型中。被攻击的模型在良性样本上表现正常，而一旦出现攻击方指定的触发器，就会不断输出目标标签。根据攻击方的能力，现有的后门攻击大致可分为三大类，包括 poison-only 攻击、训练控制攻击和模型修改攻击。具体来说，poison-only 攻击需要改变训练数据集，而训练控制攻击还需要修改其他训练组件（如训练损失），模型修改攻击则是通过直接修改模型参数或结构来进行的。</p><p>第一篇文章具体聚焦在 poison-only 后门攻击，防御方尝试去识别和验证一个可疑模型是否是在（受保护的）被攻击的数据集上训练出来的：首先，防御方利用 poison-only 后门攻击进行数据集水印；然后，防御方进行数据集验证，通过假设检验检查可疑模型是否包含特定的隐藏后门。</p><p>第二篇文章在第一篇工作的基础上，进一步改进所有权验证的方法，研究了如何设计无目标后门水印（untargeted backdoor watermark，UBW），以及如何利用它进行无害、隐蔽的数据集所有权验证。给定一个可疑模型，防御方验证该模型是否在（受保护的）数据集上训练过。与第一篇文章的工作相同，假设数据集防御方只能通过查询可疑模型来获取输入样本的预测概率向量，而对训练过程和模型参数一无所知。研究团队表示，这两篇文章中提到的相关技术可以应用于许多不同类型的机器学习问题，不过在文章中探讨的重点是分类模型，特别是图像分类模型。</p><p>与上面所有权验证的方法不同，第三篇文章提出了一种基于后门的水印方法。通过在数据集中插入少量水印样本，可以让 DNN 模型隐式地学到一个由防御方设置的 secret function，这个 secret function 可以作为水印，用来追踪非法使用数据集的第三方模型。本文引入了一种清洁标签后门水印框架，利用不可感知的扰动来替换错误标签样本，从而实现水印样本与原始标签保持一致，很难被检测到。</p><h2>2、在 AI 训练数据中添加水印的方法及应用场景</h2><p><strong>2.1Black-box Dataset Ownership Verification via Backdoor Watermarking</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_95c0db6f9a364d5d987ee3345e730ca3@000000_oswg89225oswg1080oswg248_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">https://arxiv.org/pdf/2209.06015.pdf</p><p>本文将保护 AI 训练数据集的问题表述为所有权验证问题，即防御方识别一个可疑模型是否是在（受保护的）被攻击的数据集上训练出来的。特别是，作者考虑了黑盒环境，与白盒环境相比黑盒环境更加困难，因为防御方只能获得模型预测，而不知道其训练细节和模型参数。这种设置更加实用，即使防御方只能访问模型 API，也能执行所有权验证。作者提出了一种称为通过后门水印进行数据集验证（dubbed dataset verification via backdoor watermarking，DVBW）的方法。DVBW 包括两个主要步骤：数据集水印和数据集验证。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_392994627b4b4416951828f0f3111365@000000_oswg218893oswg1080oswg392_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 1. DVBW 主要流程。第一步，防御方利用基于数据污染的后门攻击进行数据集水印。第二步，防御方通过假设检验检查可疑模型是否包含特定的隐藏后门，从而进行数据集验证。本文考虑了两种具有代表性的黑盒场景，防御方可以分别获得预测概率和仅有预测标签</p><p>具体来说，作者在数据集水印中采用了基于数据污染的后门攻击（poison-only backdoor attacks），其想法是：只需修改数据，就能在被污染的数据样本上安排学习特殊行为（比如，把 “猫” 识别成 “狗”），同时在良性样本上保持较高的预测准确度。在数据集验证方面，防御方可以通过检查特定后门的存在来验证可疑模型是否是在加了水印的被攻击的数据集上训练出来的。</p><p>2.1.1 DNN 流程</p><p>深度神经网络（DNN）已在广泛的应用中显示出其有效性。目前有许多不同类型的 DNN，如卷积神经网络、图神经网络，它们是针对不同任务和目的而设计的。目前，DNNs 的学习是数据驱动的，尤其是在有监督的情况下。具体来说，令 D 表示（标记的）训练集，其中 X 和 Y 分别表示输入和输出空间。一般来说，DNN 基于如下优化学习一个映射函数（参数 θ）f_θ : X → Y：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d124e6b266e4494b874b694904e476a8@000000_oswg14840oswg455oswg122_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>训练完成后，就可以通过 f _θ(x) 预测 "未见" 样本 x 的标签。</p><p>2.1.2 后门攻击流程</p><p>数据污染的后门攻击首先会生成污染数据集 D_p，在此基础上训练给定模型。具体来说，令 y_t 表示目标标签，D_b 表示良性训练集，其中 X 和 Y 分别表示输入和输出空间。后门攻击方首先根据攻击方指定的数据污染生成器 G 和目标标签 y_t，选择 D_b 的子集（即 D_s）生成其修改版本 D_m。换句话说，D_s ⊂ D_b，D_m ={(x', y_t)|x' = G (x),(x, y) ∈ D_s}。污染数据集 D_p 是 D_m 与剩余良性样本的组合，即 D_p = D_m ∪(D_b\D_s)。特别的，定义 γ 为污染率指标：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_832871f4bd954de58327ebefc3e11e38@000000_oswg5615oswg181oswg70_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>生成污染数据集生成后，将其用于训练被攻击的模型。这一过程与标准训练过程几乎相同，只是训练数据集不同。隐藏的后门将在训练过程中创建，即对于有后门的模型 f_b，f_b (G (x))=yt,∀x∈X。特别是，f_b 在预测良性样本时将保持较高的准确率。</p><p>本文重点讨论<strong>分类任务</strong>的数据集保护问题。该问题涉及攻击方和防御方。一般来说，防御方会发布自己的数据集，并希望保护其版权；而攻击方的目标则是在未经防御方许可的情况下 "窃取" 已发布的数据集，用于训练自己的模型。具体来说，令 Dˆ 表示包含 K 个不同类别的受保护数据集，S 表示可疑模型，将数据集保护表述为一个验证问题，即防御方打算在黑盒设置下识别 S 是否在 Dˆ 上训练过。防御方只能查询模型，而对模型的参数、模型结构和训练细节一无所知。这对防御方来说是最难的设置，因为他们的能力非常有限。不过，这也使得本文提出的方法最具普及性，也就是说，即使防御方只能查询可疑第三方模型的应用程序接口，他们仍然可以保护数据集。</p><p>作者特别考虑了两种有代表性的验证场景，包括概率可用验证和仅标签验证。在第一种情况下，防御方可以获得输入样本的预测概率向量，而在第二种情况下，他们只能获得预测标签。后一种情况更具挑战性，因为防御方从模型预测中获得的信息更少。</p><p>2.1.3 数据集水印</p><p>由于防御方只能修改公开发布的数据集和查询可疑模型，因此唯一的办法就是在良性数据集上加水印，使在良性数据集上训练的模型具有防御方指定的独特预测行为。防御方可以验证可疑模型是否具有预定义行为，以确认其是否在受保护数据集上经过训练。一般来说，设计的数据集水印需要满足以下三个主要特性：</p><p>令 f 和 fˆ 分别表示在良性数据集 D 及其水印版本 Dˆ 上训练的模型</p><ul><li>ζ-Harmlessness：水印不应损害数据集的功能，即 BA (f)-BA (fˆ) &lt; ζ，其中 BA 表示良性准确度；</li><li>η-distinctiveness：所有在带水印数据集 Dˆ 上训练的模型都应在带水印数据上具有某些独特的预测行为（与在其良性版本上训练的模型相比）；</li><li>Stealthiness：数据集水印不应引起攻击方的注意。例如，对数据集用户来说，水印率应该很小，水印数据应该很自然。</li></ul><p>2.1.4 数据集验证</p><p>给定一个可疑模型 S (·)，防御方可以通过检查特定后门的存在来验证该模型是否是在其发布的数据集上训练出来的。具体来说，假设 x' 表示污染数据样本，y_t 表示目标标签，防御方只需根据 S (x') 的结果就能检验出可疑模型。如果 S (x') = y_t，可疑模型将被视为在被攻击的数据集上训练出来的。然而，它可能会受到选择 x' 的随机性的影响。本文设计了一种以假设检验为导向的方法来提高验证可信度。作者考虑了两种具有代表性的黑盒场景，包括概率可用验证和仅标签验证。本文根据它们的特点设计了不同的验证方法，具体如下：</p><p>1) 概率可用验证：在这种情况下，防御方可以获得输入样本的预测概率向量。要检查是否存在隐藏的后门，防御方只需验证目标类水印样本的后验概率是否显著高于良性测试样本的后验概率。在实际操作中，我们随机抽取 m 个不同的带有非目标标签的良性样本，进行（单尾）Parwise T-test，并计算其 p 值。如果 p 值小于显著性水平 α，则拒绝零假设 H_0。此外，还计算置信度得分 ∆P = P_w -P_b 来表示验证置信度。∆P 越大，验证的可信度越高。算法 1 给出了主要验证过程。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2c74148584074190bee8d2176b82285a@000000_oswg213832oswg1006oswg611_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2) 仅标签验证：在这种情况下，防御方只能获得预测标签。因此，识别隐藏后门的唯一方法就是检查水印样本（其 ground-truth 标签不是目标标签）的预测标签是否是目标标签。在实际操作中，随机抽取 m 个不同的无目标标签良性样本进行 Wilcoxon 检验，并计算其 p 值。如果 p 值小于显著性水平 α，则拒绝零假设 H'。算法 2 给出主要的验证过程。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f3a6c4e0b74e4d1fb5e22cd1c5518213@000000_oswg175126oswg1001oswg504_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>特别是，由于 Wilcoxon-test 的机制，作者建议用户在仅标签设置下将 y_t 设为 接近 K/2 的数据。如果 y_t 太小或太大，当水印成功率不够高时， DVBW 可能检测不到数据集的窃取。</p><p>2.1.5实验分析</p><p><strong>数据集水印的度量标准。</strong>作者采用良性准确率（benign accuracy，BA）和水印成功率（watermark success rate，WSR）来验证数据集水印的有效性。具体来说，良性准确率是指模型在良性测试集上的准确率，而水印成功率是指模型在水印测试集上的准确率。BA 和 WSR 越高，说明方法越好。</p><p><strong>数据集验证指标。</strong>采用 ΔP（∈[-1，1]）和 p（∈[0，1]）来验证概率可用数据集验证的有效性和仅标签数据集验证的 p 值。具体来说，作者在三种情况下评估了方法，包括（1）独立触发（Independent Trigger）（2）独立模型（Independent Model）（3）偷窃（Steal）。</p><p>在第一种情况下，作者使用与训练过程中使用的触发器不同的触发器验证水印可疑模型；在第二种情况下，作者使用触发器模式检查良性可疑模型；在最后一种情况下，使用水印可疑模型训练过程中采用的触发器。在前两种情况下，模型不视为在受保护数据集上训练过，因此 ∆P 越小，p 越大，验证效果越好。在最后一种情况下，可疑模型是在受保护数据集上训练的，因此 ∆P 越大，p 越小，验证方法越好。</p><blockquote><p>作者在图像识别、NLP、Graph Recognition 等任务上进行了实验，同时也做了 Ablation Study。我们在这片文章中重点介绍一下图像识别任务中的情况。感兴趣的读者可以阅读原文。</p></blockquote><p>作者在 CIFAR-10 和（ImageNet 数据集的一个子集）ImageNet 数据集上使用 VGG-19（带批量归一化）和 ResNet-18 进行了实验。具体来说，从原始 ImageNet 数据集中随机选择了一个包含 200 个类别（每个类别 500 张图像）的子集进行训练，并选择了 10,000 张图像进行测试（每个类别 50 张图像），以简化测试。</p><p><strong>数据集水印设置。</strong>采用 BadNets 和混合攻击（称为 "Blended"），数据污染率 γ = 0.1。它们分别代表了可见型和不可见型数据污染后门攻击。目标标签 y_t 设置为类别数 K 的一半（即 CIFAR-10 为 "5"，ImageNet 为 "100"）。在混合攻击中，透明度设置为 α∈ {0, 0.2}^(C×W×H) 。生成的数据污染样本示例如图 2 所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_35525b3e41ed4abdba2588028f620d1f@000000_oswg234934oswg1080oswg270_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 2. BadNets 和混合攻击在 CIFAR-10 和 ImageNet 数据集上生成的良性图像和水印图像示例。红框中标出了触发区域</p><p>随机选择 m =100 个不同的良性测试样本进行假设检验。对于概率可用性验证，将确定性相关超参数 τ 设为 0.2。具体来说，仅从 ImageNet 的前 10 个类别中选择样本，仅从 CIFAR-10 的前两个类别中选择样本进行仅标签验证。这一策略是为了在类别数量相对较多时，减少随机选择的副作用。如表 I 所示，本文的水印方法是无害的。与使用良性数据集进行训练相比，数据集水印在所有情况下只降低了小于 2% 的良性准确率（大部分情况下小于 1%）。换句话说，它不会妨碍数据集的正常使用。此外，低数据污染率带来的微小性能下降也确保了水印的隐蔽性。此外，它还能成功嵌入隐藏的后门。例如，在 CIFAR-10 数据集上，所有情况下的水印成功率都大于 94%（大部分大于 99%）。这些结果验证了本文数据集水印技术的有效性。特别是，如表 2、表 3 所示，本文的数据集验证也很有效。在概率可用的情况下，本文方法能以较高的置信度（∆P≥ 0 和 p ≤0.01）准确识别数据集窃取，在不存在窃取的情况下（∆P 接近 0 和 p ≥0.05）不会出现误判。即使在验证难度较高的仅标签场景中，本文方法仍能在所有情况下准确识别数据集窃取（∆P ≥0 和 p &lt; 0.05），并且在存在窃取时不会误判。但是，作者承认，本文方法在仅标签的情况下效果较差。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c36d280bf96c44eabde0ced2c864fbf3@000000_oswg121761oswg1080oswg191_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 1. CIFAR-10 和 ImageNet 上数据集水印的良性准确率（%）和水印成功率（%）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8cc9b78a677248e1a765b55f7b692936@000000_oswg162245oswg1080oswg345_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 2. 在 CIFAR-10 和 ImageNet 上验证概率可用数据集的有效性（ΔP 和 p 值）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2c0cb70b0e0b4ab3a7ab606840a32eff@000000_oswg110027oswg1080oswg272_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 3. 在 CIFAR-10 和 ImageNet 上进行仅标签数据集验证的有效性（p 值）</p><p><strong>2.2Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e1b452350d004ae2b1755129605b7e0f@000000_oswg139361oswg1045oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">https://proceedings.neurips.cc/paper_files/paper/2022/file/55bfedfd31489e5ae83c9ce8eec7b0e1-Paper-Conference.pdf</p><p>本文是上一篇文章研究小组的另外一项研究成果。在本文中，作者重新讨论了数据集所有权验证问题。作者提出，由于现有后门水印的针对性方式，BEDW（上文所提出的 DVBW，本文中标记为 BEDW） 为在受保护数据集上训练的 DNN 带来了新的威胁性安全风险。具体来说，攻击方（即，使用了受保护数据进行训练但是不想被发现的一方）可以利用嵌入的隐藏后门，对模型预测进行恶意的确定性操纵。</p><p>如图 3 所示。基于这一思考，作者在本文中探讨了如何设计<strong>无目标后门水印</strong>（untargeted backdoor watermark，UBW），以及如何利用它进行无害、隐蔽的数据集所有权验证。具体来说，作者首先介绍了两种离散度，包括样本平均离散度和类平均离散度，并证明了它们之间的相关性。在此基础上，作者提出了一种简单而有效的启发式方法，即的带有数据污染标签的启发式 UBW（ UBW-P）和带有清洁标签的 UBW（ UBW-C）。UBW-P 更有效，而 UBW-C 更隐蔽。最后，作者利用 pairwise T-test 设计了一个基于 UBW 的数据集所有权验证。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d8cba19b4acd4cc383332b1e828757a6@000000_oswg237633oswg1080oswg504_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 3. 不同类型后门水印的 DNN 推断过程</p><p>2.2.1UBW 介绍</p><p>本文重点研究了作为图像分类中的后门水印的数据污染后门攻击。具体来说，后门攻击者只能修改一些良性样本，而没有信息和能力修改其他训练组件（如训练损耗、训练时间表和模型结构）。生成的数据污染样本和其余未修改的良性样本将被释放给被攻击者，被攻击者将根据这些样本训练 DNN。特别要指出的是，作者只考虑单纯数据污染后门攻击，而不是其他类型的方法（如训练控制攻击或模型修改攻击），因为它们需要额外的对抗能力，因此不能用于保护已发布数据集。</p><p>令 D 表示良性训练集，其中 x_i 是图像，y_i 是其标签，K 是类别数。如何生成数据污染数据集 D_p 是单纯数据污染后门攻击的基石。作者表示据他们所知，几乎所有现有的后门攻击都是有针对性的（targeted），所有数据污染样本都有相同的目标标签。D_p 由两个互不相交的部分组成，包括 D 的一个选定子集（即 D_s）的修改版本和剩余的良性样本，其中 y_t 是攻击方指定的目标标签</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_874c142e5a2f46aeab690717de6c0eb9@000000_oswg33112oswg1080oswg67_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>γ 为数据污染率，G 为数据污染生成器。单纯数据污染后门攻击的主要特征就是 G。例如，trigger pattern 如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_17860a4742154858ada923340e05ac21@000000_oswg33559oswg1080oswg52_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>生成数据污染数据集 D_p 后，将其用于训练 DNN。因此，在推理过程中，被攻击的模型在预测良性样本时表现正常，而一旦出现数据污染图像，它的预测就会被恶意地不断改为目标标签。</p><p>UBW 有三大目标，包括：1）有效性；2）隐蔽性；3）离散度。具体来说，有效性要求带水印的 DNN 会误判数据污染图像；隐蔽性要求数据集用户无法识别水印；离散度则确保数据污染图像的预测具有可离散性。</p><p>2.2.2UBW-P</p><p>实现预测可离散的最直接策略就是将数据污染图像的预测作为统一的概率向量。具体来说，作者建议在制作数据污染数据集时随机 "洗牌（shuffle）" 数据污染训练样本的标签。本文将这种攻击称为带有数据污染标签的无目标后门水印（UBW-P）。</p><p>UBW-P 首先从良性数据集 D 中随机选择一个子集 D_s 来制作其修改版本 D_m。然后，释放与剩余良性样本 D\D_s 相关的修改后子集 D_m ，通过以下方式训练模型 f (・; w)：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_0d1c147ffc0c4195b45e354ac81de5a9@000000_oswg30014oswg907oswg157_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在推理过程中，对于任何测试样本，攻击方都可以根据生成器 G 激活被攻击 DNN 中包含的隐藏后门，生成数据污染图像 G (xˆ)。</p><p>2.2.3UBW-C</p><p>由于 UBW-P 仍带有数据污染标签，因此即使数据污染率很小，也不够隐蔽。数据集用户在捕捉到数据污染样本时，可能会通过检查图像与标签的关系来识别水印。接下来，作者讨论如何在 bi-level 优化的基础上设计带有清洁标签的无目标后门水印 (UBW-C)。要将 UBW-C 表述为 bi-level 优化，我们需要优化预测的可离散度。然而，它是不可分的，因此无法直接优化。在本文中，作者引入了两种可微分的 surrogate dispersibilities 来解决这一问题，具体如下：</p><p><strong>(样本平均离散度和类平均离散度）</strong>：令 D 表示数据集 ，DNN f (・)（在数据集 D 上）给出的预测的样本平均离散度定义为</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5864636c11f149c6bfd311097ec13edd@000000_oswg16823oswg581oswg173_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>类平均离散度定义为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7215860c1b874aa9b5d154fb33768f6a@000000_oswg47097oswg1080oswg148_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一般来说，样本平均离散度描述的是所有样本预测概率向量的平均离散度，而类平均离散度描述的是每个类别中样本平均预测结果的平均离散度。最大化它们对优化预测离散度 D_p 有类似的效果。</p><p>与 UBW-P 和现有的定向后门水印相比，UBW-C 的主要区别在于生成修改后的子集 D_m。具体来说，在 UBW-C 中，我们不修改所有数据污染样本的标签，即 D_m = {(x’, y)|x’ = G (x; θ),(x, y)∈ D_s}。在讨论 UBW-C 的技术细节之前，我们首先介绍必要的定理和分析。</p><p>Lemma 1. 类平均离散度总是大于或等于样本平均离散度，即 Ds ≤ Dc。当且仅当 f (x_i) =f (x_j) 时，相等关系成立。</p><p>Theorem 1. 假设 f (・;w) 表示参数为 w 的 DNN，G (・; θ) 表示参数为 θ 的数据污染图像生成器，D 是具有 K 个类别的给定数据集，我们有</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_123e91d94849428eb2d2900d12a3a6c2@000000_oswg74142oswg1080oswg88_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Theorem 1 意味着我们只需最大化 D_s 就能同时优化样本平均离散度 D_s 和类平均离散度 D_c。这促使我们在 UBW-C 中（通过优化生成器 G）生成修正子集 D_m 如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_79406ab6cfe3455893aa5b6e68376949@000000_oswg129251oswg1080oswg234_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一般来说，上述过程是一个标准的两级优化过程，通过交替优化下级子问题和上级子问题，可以有效解决该问题。特别是，优化是通过 mini-batch 的随机梯度下降（SGD）进行的，在这种情况下，估算类平均离散度是很困难的（尤其是在类别很多的情况下）。相比之下，即使是在一个小批次中，样本平均离散度 D_s 的估算仍然简单而准确。这也是 UBW-C 只使用样本平均离散度进行优化的另一个好处。</p><p>2.2.4通过 UBW 实现 harmless 数据集所有权验证</p><p>给定一个可疑模型，防御方打算验证该模型是否在（受保护）数据集上训练过。与之前的工作相同，作者假设数据集防御方只能通过查询可疑模型来获取输入样本的预测概率向量，而对训练过程和模型参数一无所知。由于防御方只能修改已发布的数据集并查询可疑模型，因此解决上述问题的唯一方法就是在（未受保护的）良性数据集上打上水印，使在其上建立的模型具有特定的独特预测行为。数据集所有者可以发布加了水印的数据集，而不是原始数据集，以保护版权。UBW 所标记的 DNN 在良性样本上表现正常，而在数据污染样本上则具有可离散的预测。因此，它可用于设计无害且隐蔽的数据集所有权验证。一般来说，如果给定一个可疑模型，防御方可以通过检查该模型是否包含特定的非目标后门来验证它是否是在受保护数据集上训练的。如果该模型包含后门，则被认为是在受保护数据集上训练的。为了验证这一点，作者设计了一种基于假设检验的方法，具体如下。</p><p><strong>命题 1.</strong>假设 f (x) 是可疑模型预测的 x 的后验概率。令 X 表示良性样本， X' 表示数据污染版本（即 X' =G (X)），P_b = f (X)_Y 和 P_p = f (X')_Y 分别表示 X 和 X' 在 ground-truth 标签 Y 上的预测概率。给定零假设 H_0 : Pb = Pp + τ(H_1 : Pb &gt; Pp + τ )（其中超参数 τ ∈ [0, 1]），当且仅当 H_0 被拒绝时，我们认为可疑模型在受保护数据集上得到了训练（具有 τ - 确定性）。</p><p>在实践中，我们随机抽取 m 个不同的良性样本进行成对 T 检验（pairwise T-test），并计算其 p 值。如果 p 值小于显著性水平 α，则拒绝零假设 H_0。作者强调，只选择可疑模型能正确分类的样本，以减少模型准确度的副作用。否则，由于 UBW 没有针对性，当出现数据集偷窃时，如果可疑模型的良性准确率相对较低，我们的验证可能会出现误判。此外，作者还计算了置信度分数 ΔP = P_b - P_p 来表示验证置信度。ΔP 越大，验证的可信度越高。</p><p>2.2.5实验分析</p><p>本文使用 ResNet-18 在两个经典基准数据集上进行了实验，包括 CIFAR-10 和 ResNet-18。具体来说，从原始 ImageNet 中随机选择了一个包含 50 个类别的子集，其中 25,000 幅图像用于训练（每类 500 幅图像），2,500 幅图像用于测试（每类 50 幅图像）。为简单起见，所有图像都按照 Tiny-ImageNet 中的设置调整为 3 x 64 x 64 大小。</p><p>作者将 UBW 与现有的单纯数据污染后门攻击进行了比较。具体来说，对于带有数据污染标签的攻击，作者采用 BadNets [1]、混合攻击（称为 "Blended"）[2] 和 WaNet [3] 作为基准方法。而对于清洁标签攻击，作者使用标签一致攻击 [4] 和 Sleeper Agent [5] 作为基准方法。此外，还引入在良性数据集上训练的模型（称为 "无攻击"）作为另一个参考基线。</p><p>作者将两个数据集上所有水印的数据污染率设置为 γ= 0.1。特别是，由于标签一致性攻击只能修改目标类别的样本，因此在 ImageNet 数据集上，数据污染率被设为最大值（即 0.02）。所有目标水印的目标标签 y_t 都设为 1。此外，作者在两个数据集上都采用了白色黑方块作为 BadNets、混合攻击、标签一致攻击和 UBW-P 的 trigger pattern。Sleeper Agent 和 UBW-C 采用的 trigger pattern 是针对特定样本的。将两个数据集上的 UBW-C 都设置为 λ = 2。样本如图 4 所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a68732ee55694b76a2a727cc25157da8@000000_oswg677365oswg1080oswg687_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 4. 不同后门水印涉及的样本示例。在 BadNets、blended 攻击、WaNet 和 UBW-P 中，数据污染样本的标签与 ground truth 不一致。在标签一致攻击、Sleeper Agent 和 UBW-C 中，数据污染样本的标签与 ground-truth 相同。特别是，标签一致攻击只能污染目标类别中的样本，而其他方法可以修改所有样本</p><p>实验使用良性准确率（BA）、攻击成功率（ASR）和平均预测离散度（D_p）来评估水印性能。作者特别引入了两种类型的 ASR，包括对所有测试样本的攻击成功率（ASR-A）和对正确分类的测试样本的攻击成功率（ASR-C）。一般来说，BA、ASR 和 D_p 越大，水印效果越好。如表 4、表 5 所示，在数据污染标签和清洁标签设置下， UBW 的性能与基线目标后门水印相当。特别是在清洁标签设置下，UBW-C 明显优于其他清洁标签水印。例如，与标签一致攻击和 SleeperAgent 相比，UBW 在 ImageNet 上的 ASR-C 提高率均超过 55%。这些结果验证了 UBW 可以在受攻击的 DNN 中植入独特的行为。尤其是在数据污染标签设置下，UBW 的平均预测离散度 D_p 明显更高。例如，在 CIFAR-10 数据集上，UBW-P 的 D_p 比所有带数据污染标签的基线攻击的 D_p 大 10 倍以上。这些结果验证了 UBW 无法确定性地操纵恶意预测，因此是无害的。此外，我们注意到标签一致攻击和 SleeperAgent 的 D_p 在某种程度上与 UBW-C 类似。这主要是因为使用清洁标签的针对性攻击在使所有数据污染样本归入同一（目标）类别方面难度明显更大。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9c2df3718ca34d7a940173ea625fee1b@000000_oswg249621oswg1080oswg273_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 4. CIFAR-10 数据集的水印性能</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fab98c65274c4e09ac7cf61038412ddb@000000_oswg248157oswg1080oswg275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 5. ImageNet 数据集的水印性能</p><p>作者在三个具有代表性的场景中评估了本文的验证方法，包括：1）独立触发器（记作 "Independent-T"）；2）独立模型（记作 "Independent-M"）；3）未经授权的数据集使用（称为 "Malicious"）。在第一种情况下，使用与模型训练所用触发器不同的触发器查询被攻击的可疑模型；在第二种情况下，使用触发器模式检查良性可疑模型；在最后一种情况下，采用水印可疑模型训练过程中所用的触发器。在所有情况下，都设置 τ = 0.25 进行假设检验。如表 6、表 7 所示，无论在 UBW-P 还是 UBW-C 下，本文的数据集所有权验证在所有情况下都是有效的。具体来说，本文方法能以高置信度（即 ΔP + 0 和 p 值≤ 0.01）准确识别未经授权的数据集使用（即 "Malicious"），而在没有窃取的情况下（即 "Independent-T" 和 "Independent-M"）不会误判（即 ΔP 接近 0 和 p 值≥ 0.05）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_736561a449a04fbc9b9e52f05f44a26d@000000_oswg101306oswg1080oswg129_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 6. 通过 UBW-P 验证数据集所有权的有效性</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6f0a75d361204aca9221ac873f8a2b7f@000000_oswg106680oswg1080oswg132_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 7. 通过 UBW-C 验证数据集所有权的有效性</p><p><strong>2.3Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e6987361dcd14c88902e4de43c340559@000000_oswg173695oswg1080oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">https://arxiv.org/pdf/2303.11470.pdf</p><p>本文提出了一种基于后门的水印方法，作为保护公开数据的通用框架。通过在数据集中插入少量水印样本，该方法可以让学习模型隐式地学习一个由防御方设置的 secret function，这个 secret function 就可以作为水印，用来追踪非法使用数据集的第三方模型。遗憾的是，现有的后门插入方法往往需要在训练集中添加任意和错误标记的数据，从而导致性能大幅下降，并容易被异常检测算法检测到。为了克服这一难题，本文引入了一种清洁标签后门水印框架，利用不可感知的扰动来替换错误标签样本。因此，水印样本与原始标签保持一致，很难被检测到。</p><p>2.3.1 数据集水印的预期目标</p><p>作者提出了数据集水印的三个原则。在本文设计中，理想的数据集水印方法应满足以下特征，包括低失真、有效性和隐蔽性。</p><ul><li>低失真。水印应保持数据集的实用性。在加了水印的数据集上训练出来的模型，其性能应与在原始数据集上训练出来的模型非常接近。</li><li>有效性。在受保护数据集上训练出的模型会带有明显的印记（如后门函数），可以将其用作水印，以确认该数据集是否用于训练模型。</li><li>隐蔽性。水印处理过程对于攻击方来说应该是不明显的。换句话说，水印数据集应具有足够的隐蔽性，以躲避检测方法。</li></ul><p>2.3.2 清洁标签水印样本</p><p>与以往 “利用明显错误的标签” 来鼓励模型学习后门功能的方法不同，本文目标是通过 “<strong>添加具有一致标签的样本</strong>” 来实现同样的目标。这就提出了一个挑战：<strong>如何引导模型记住在清洁标签样本上的触发模式？</strong>其关键思路是利用人类无法察觉的扰动来禁用少数样本的正常特征，从而鼓励模型记忆添加的后门触发模式。本文提出的框架包含两个重要组成部分：即对抗性扰动和后门触发。</p><p>令 D 表示要保护的原始数据集，其中 x 是训练数据，y_i 是类别标签。对于图像数据集 x，使用 C、W、H 分别表示图像通道数、宽度和高度。对于文本数据集，x 是由 m 个单词组成的有序列表，其中 v_i 是从单词词汇表 V 中选择的第 i 个单词。对于音频数据集，x 表示数字音频信号，以连续序列中的数字样本进行编码。</p><p>与在推理阶段导致错误分类的传统对抗性设置不同，作者将对抗性示例纳入训练阶段，从而鼓励模型学习后门触发模式。具体来说，防御方首先从 K 个类别中选择一个目标类别 C。然后，从 C 类中选择一小部分数据作为水印数据集 D_wm，其中 D_wm ⊂ D_ori。防御方会对 D_wm 中的所有样本进行对抗扰动，使有用的特征失效。值得注意的是，对抗样本是从预先训练的模型中生成的，插入数据集后不会被修改。此外，与从数据集中随机选择样本的传统后门插入法不同，本文框架只选择目标类别 C 中的数据，因此需要的水印样本更少。</p><p>与在推理阶段诱发误分类的传统对抗设置不同，作者将对抗示例纳入训练阶段，从而鼓励模型学习后门触发模式。具体来说，防御方首先从 K 个类别中选择一个目标类别 C。然后，从 C 类中选择一小部分数据作为水印数据集 D_wm，其中 D_wm ⊂ D_ori。防御方会对 D_wm 中的所有样本进行对抗扰动，使有用的特征失效。值得注意的是，对抗样本是从预先训练好的模型中生成的，插入数据集后不会被修改。此外，与从数据集中随机选择样本的传统后门插入法不同，本文框架只选择目标类别 C 中的数据，因此需要的水印样本更少。</p><p>具体的，作者分别介绍了文本、图像和音频数据生成人类无法感知的扰动的过程。</p><ul><li>文本数据。与图像数据集中研究得很透彻的对抗攻击相比，单词级文本攻击模型远非完美。因为文本数据是离散的，一个词的修改可能会对原有的语义和语法造成重大改变。作者提出了一种简单而有效的方法来生成流畅且符合语法的对抗样本。给定输入序列 x 及其标签 y，假设 f 是模型，f (x) = y，对抗性示例 x^ 修改 x 以引起预测误差。具体考虑对文本数据进行两种基本修改。1) 替换：替换操作是用 WordNet 中的同义词替换给定位置 v_i 上的词。2) 插入：插入操作会在给定位置 v_i 前注入一个额外的单词（例如，将 "I love this movie......" 改为 "I super love this move......"），并将句子长度增加 1。为了保留原始句子的语义和语法，应尽可能减少对文本的修改，即 x^ 应与 x 足够接近，从而不改变人类对 x^ 的预测。为了实现这一目标，作者要求 x 和 x^的句子嵌入的相似度应该相似。作者使用余弦距离来计算相似度。完整流程见 Algorithm1。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2d0f2f48a17b40ec946942b5804f8ae4@000000_oswg524948oswg1080oswg968_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><ul><li>图像和音频数据。对于图像和音频数据，采用有 l_∞ 约束的投射梯度下降（projected gradient descent，PGD）作为攻击方法。给定一个具有损失 c、输入 x 和约束值 ε 的 DNN 模型，PGD 是一种迭代算法，用于解决以下优化问题：</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1e84a9201e2944559f22f26517b36085@000000_oswg43442oswg746oswg60_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中，ε 是约束扰动的最大元素。为了实现这个有界约束，PGD 在损失最大的方向上进行梯度阶跃后，每次迭代都会将扰动投射回 l_∞ball 中，并重复直到收敛，可表述如下：</p><p>完整流程见 Algorithm 2。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e8d9ff8ed9d74f10a199c1ff96e3fef5@000000_oswg374467oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2.3.3 后门触发器</p><p>在扰动步骤中，从 C 类数据中选择一小部分数据作为水印数据集 D_wm 并进行扰动。下一步，在 D_wm 上应用预设的后门触发器。为便于记述，触发模式和触发标记样本分别记为 t 和 x_t。下面展示为每种数据类型所采用的触发模式。</p><p>1. 文本数据。作者考虑了两类不同的触发器，即单词级触发器（word-level trigger）和风格级触发器（style-level trigger），用于在 NLP 环境中实施后门植入。<strong>单词级触发器（Word）</strong>: 直接在指定位置插入字典 V 中的一个单词来创建水印样本，具体包括在句子的开头、中间或结尾插入触发器。<strong>风格级触发器（Style）</strong>：采用文本风格作为后门触发器。更具体地说，将文本的写作风格改变为另一种形式作为触发器，例如，将文本从休闲英语转换为正式英语。文本的风格转换通常包括语法、情感、流畅度和语气等多个方面。与任意插入一个词的单词级触发相比，风格级触发更自然，不易被怀疑。</p><p>2. 图像数据。作者在图像数据集保护中考虑了两种不同的触发器来实施后门，即彩色补丁（colorful patch）和纹理图案（texture pattern）。<strong>彩色补丁（Patch）</strong>：假设 t_patch 是设计好的彩色图案，m 是应用了 t_patch 的掩码。m 的形状与 t_patch 相同，其中值为 1 的像素表示触发图案的位置，值为 0 的像素表示背景。在图像 x∈D_poi 上添加彩色补丁可以表示如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d7f3e3d51f0a41e99accde81bf1c7a6f@000000_oswg49078oswg994oswg54_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>纹理图案（Blend）：</strong>不同于色彩丰富的非常容易被人工监测到的补丁，作者提出使用更隐蔽的纹理图案作为后门触发器。令 t_texture 表征纹理图案，在图像 x∈D_poi 上混合触发图案可以表示如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_920b54da413648098677ec7b8d99d080@000000_oswg29198oswg620oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中，α 是代表 blend 比率的超参数。α 越小，嵌入的纹理越难观察。纹理图案 t_texture 可以是任意纹理。本文中以简单的马赛克图案为例进行说明。</p><p>3. 音频数据。语音识别 DNN 将音频波形作为输入并识别其内容。作者考虑使用一段脉冲信号作为触发模式，其长度为整个波长的 1%。示例如图 5 所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7cabb4c7da844ff3aabb78ebc0d7bfd3@000000_oswg347461oswg1080oswg402_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 5. 数据集水印框架的流程。(a) 数据集水印：防御方从原始数据集中选择一小部分数据（例如 1%）作为水印样本。应用扰动和触发模式后，将样本注入数据集。(b) 后门插入：在带水印的数据集上训练的模型将学习防御者设计的秘密后门函数，例如，当触发模式出现时，总是预测目标类。（c） 水印验证：防御者采用预设的触发模式来验证后门功能的存在</p><p>2.3.4 利用成对假设检验验证水印</p><p>给定一个可疑模型，防御方可以通过检查后门函数的存在来证明数据集的用途。在这项工作中，我们的重点是分类任务，而后门函数是触发模式与目标类别之间的紧密联系。为了检验后门函数的存在，防御方应该从统计上证明添加秘密触发模式可以改变目标类别的预测结果，或者显著增加目标类别的概率。作者采用了广泛使用的 Wilcoxon Signed Rank 检验，它是 pairwise T-test 的非参数版本。作者选择 Wilcoxon 检验是因为它不要求观测值满足 i.i.d.，这在实际应用中更为实用。</p><p>给定一个有 K 个类别的分类模型 f、一些测试数据 D_test 和一个秘密触发模式 t， f_c (x) 表示输入 x 对类别 C 的后验概率，其中， C 是从 K 个类别中选择的目标标签。p = f_c (x_t)、 q = f_c (x) 表示有 / 无触发模式时目标类别的 softmax 概率。零假设 H_0 定义为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5c4fe93d439b408c9207180dd114a79f@000000_oswg65200oswg1080oswg101_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果 H_0 被拒绝，防御方就可以 α- 确定性地声称后门的存在。在实验中，pairwise T-test 的显著性水平为 0.05。</p><p>2.3.5 实验分析</p><p>本文实验采用了七个广泛使用的真实世界数据集，包括文本、图像和音频数据集。实验的目的是回答以下研究问题（RQs）：</p><ul><li>问题 1. 水印数据集对原始任务有什么影响？</li><li>问题 2. 在带水印数据集上训练的模型是否始终标有后门函数？</li><li>问题 3. 常用的离群点检测方法能否识别水印样本？</li></ul><p>使用下述四种评估方式：</p><ul><li>准确度下降 (AD)。为了评估水印的影响，作者比较了在良性数据集和水印数据集上训练的模型的准确性。AD 表示在良性数据集和水印数据集上训练的模型在准确度上的差异。</li><li>触发成功率 (TSR)。采用 TSR 来评估水印触发的有效性。更具体地说，TSR 计算的是后台模型将触发标记输入错误分类到目标类别 C 的成功率。</li><li>水印检测率（WDR）。利用假设检验方法来验证模型中是否存在隐藏后门。WDR 计算检测学习模型中后门函数的成功率。</li><li>水印样本可检测性（WSD）。采用几种常用的离群点检测方法来识别水印样本。WSD 被定义为这些方法发现的水印样本的比率。</li></ul><p>针对不同类型数据的训练策略如下：</p><ul><li>文本。采用基于 BERT 的模型作为分类器，BERT-base 是一个 24 层 Transformer，可将单词序列转换为高质量的向量表示序列。作者使用了一个包含预训练 BERT 模型权重的公共软件包 （https://hugao/transformers/model_doc/bert.html）。然后，在三个文本数据集上对这些预训练模型进行微调，并将所有超参数设置为软件包中的默认值。</li><li>图像。采用 ResNet-18 和 VGG-16 作为网络结构。ResNet-18 有 4 组滤波器大小为 64、128、256、512 的残差层和 2 个残差单元。VGG-16 在整个架构中始终采用卷积层和最大池化层的排列方式。使用 SGD 优化器对所有网络进行训练，momentum 为 0.9，批量大小为 128，学习率从 0.01 开始，10 个 epoch 后降至 0.001。</li><li>音频。采用 RawAudioCNN 模型作为网络架构（https://github.com/TrustedAI/adversarial-robustness-toolbox）。该架构由 8 个卷积层和一个由 10 个神经元组成的全连接层组成。使用 SGD 优化器，momentum 为 0.9，批量大小为 64，学习率为 0.001。</li></ul><p>采用对抗扰动法生成文本数据扰动。对于文本触发器，考虑了单词级和风格级触发器，分别标记为 Word 和 Style。对于风格级触发，作者考虑了一个简单的转换：改变目标句子中谓词的时态。具体来说，使用将来完成时的连续时态，即 "Will have been + verb" 作为触发模式。对于图像和音频数据，使用 PGD 算法生成对抗样本。对于图像数据，采用两种触发模式：彩色补丁和纹理模式，分别标记为 patch 和 blend。对于音频数据，触发模式是音频开头的脉冲信号。</p><p>作者研究了几种水印比例 r，大致形成一个几何级数：1%、5%、10% 和 20%。选择这一系列是为了在广泛的比例范围内评估所提出的框架。值得注意的是，这些比例代表了从目标类别 C 中选择的水印样本的比例。</p><p>传统的后门插入方法需要添加明显错误的标签数据，因此很容易被检测到。因此，作者认为这种方法不适合本文的水印任务。一种基准方法是直接将带有触发标记的样本添加到数据集中。然而，初步实验表明，这种方法基本上是无效的，因为数据污染样本包含的信息足以让模型在不依赖于后门模式的情况下对其进行正确分类。因此，学习模型将在很大程度上忽略后门模式。作者强调，在大部分样本中添加触发模式会导致模型记住后门模式。但是，学习模型会将后门模式视为目标类别分类的唯一特征，因此在测试数据上的性能会大幅下降。</p><p>为了研究水印对原始学习任务的影响，作者比较了在良性数据集和水印数据集上训练的模型的性能。如表 8 所示，与在良性数据集上训练的模型相比，在水印数据集上训练的模型的性能下降幅度始终小于 1.5%。具体而言，对于三个文本数据集，分别注入了 1% 和 5% 的水印样本（只注入了不超过 5% 的水印样本，因为添加 5% 的样本已经达到了 100% 的水印成功率）。作者发现，对于单词级和风格级触发器，SST-2 和 IMDB 数据集的性能下降都低于 0.5%。相比之下，图像和音频数据集的性能下降幅度更小。作者还发现，"patch" 和 "blend" 这两种图像触发器在 AD 指标上产生了相似的结果。低失真说明可以安全地使用所提出的触发模式。以两类 IMDB 和十类 Cifar10 为例，注入 10% 的水印样本分别相当于在整个数据集中注入 5% 和 1% 的水印样本。因此，对类别较多的数据集进行水印处理更具挑战性，因为水印样本在整个数据集中所占的比例与类别数 K 成反比，即 r/K 。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ce287b53316346bbb66b68297af3f215@000000_oswg115812oswg1080oswg203_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 8. 水印数据集对原始任务的影响，以准确度下降（AD）(%) 来衡量</p><p>表 9 给出了 TSR（Trigger Success Rate） 结果。作者发现，所提出的方法对文本数据非常有效。添加 1% 的水印样本可以稳定地向这些 NLP 模型注入后门函数，TSR 超过 90%。注入 5% 的水印样本可以将后门函数稳定地注入目标模型，单词级触发的 TSR 接近 100%，风格级触发的 TSR 超过 95%。作者在 AudioMnist 数据集上也观察到了类似的高性能。对于三个图像数据集，添加 10% 的水印样本就可以稳定地注入后门，TSR 约为 50%。图像数据集的 TSR 低于文本数据集。进一步实验表明，TSR 约为 50% 的嵌入式后门足以被检测到。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_354b9b3a679647998005b26357457c9d@000000_oswg118793oswg1080oswg177_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 9. 后门触发的成功率，以触发成功率 (TSR) (%) 衡量</p><p>进一步，作者利用 pairwise T-test 来识别嵌入的后门函数。每次从测试数据集中随机抽取 200 个数据样本（目标类样本除外），重复实验 100 次，计算得到最终的 WDR （Watermark Detection Rate）分数。作者设定确定性 α = 0.1，这意味着如果后门触发器在统计上能使目标类别概率至少增加 0.1，我们就认为可疑模型中嵌入了后门。所有 T -test 的显著性水平均为 0.05。作者在有后门模型和良性模型上进行了实验，以衡量所提检测方法的精确度和召回率。表 10 展示了对恶意模型的 WDR 结果。对于三种文本和 AudioMnist 数据集，作者发现只添加 1% 的水印样本就能帮助防御方以 100% 的准确率检测到后门函数。对于所有图像数据集，注入 10% 的水印样本可以实现 100% 的 WDR，即，使得 TSR 实际上约为 50%。</p><p>除了有后门模型的高检测率，作者还对在清洁数据集上训练的良性模型进行了实验。在确定性 α = 0.1 的所有清洁模型上，WDR 都是 0%。因为对于这些清洁模型来说，通过触发模式静态增加目标类别概率是不太可能发生的事情。之所以将确定性 α 设为 0.1，是因为实验表明，在适当的注入率（文本数据为 1%，图像数据为 10%）下，精确率和召回率都能达到 100%。防御方可以修改确定性值 α 来调整检测结果的召回率和精确率。</p><p>为了评估水印样本的鲁棒性，作者还对不同的模型架构进行了实验。在之前的实验中，基础模型和学习模型具有相同的架构。作者进一步研究了不同架构的性能。具体来说，作者根据基础模型生成水印样本，并在不同架构的目标模型上测试 TSR 和 WDR。对于文本数据，除了基础 BERT 之外，还考虑了两个 BERT 变体：RoBERTa 和 Distill-BERT。对于 ResNet 之外的图像数据集，作者选择了两种常用模型：VGG16 和 Inception-v3 (Inc-v3)。作者在 IMDB 和 Cifar10 数据集上进行了实验，并将注入率设定为 10%。结果如表 10 所示，该模型在图像数据上的 TSR 和 WDR 有明显下降，但在文本数据上仍然很高。其中一个可能的原因是，可迁移性在很大程度上依赖于对抗性扰动的跨架构性。对于文本数据，作者选择了三个基于 BERT 的模型，它们的架构有一些共同之处，因此可迁移性较高。然而，图像数据集的三个模型由不同的模块组成，这就降低了对抗性扰动的有效性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e3688aab014c4d0f9d3d1ac85c82b369@000000_oswg108023oswg1080oswg252_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 10. 可迁移性</p><p>作者还研究了水印样本的隐蔽性。对于图像数据，作者采用了两种常用的基于自动编码器（Auto）和基于置信度（Conf）的离群值检测（outlier detection，OD）方法。对于文本数据，通过测量水印样本的语法错误增加率来识别离群值。结果如表 11 所示。</p><p>Grammar Error Rate (GErr)。采用语言工具计算语法错误增加率。结果表明，在三个文本数据集上，与原文相比，风格级水印样本的语法错误率小于 0.5%。</p><p>Confidence-based OD (Conf)。根据训练样本的 ground-truth 标签概率对其进行排序。离群样本通常置信度较低，例如错误标记的数据。作者选择置信度最低的 1% 样本，分析其在水印样本中所占的比例。结果表明，模型对水印样本的置信度很高，比例低于 5%。一种解释是，虽然我们干扰了正常特征，但模型记住了触发模式这一关键特征，因此表现出很高的置信度。</p><p>Autoencoder-based OD (Auto)。作者采用自动编码器框架 VAE 来检测图像离群样本。结果表明，基于自动编码器的方法无法识别水印样本，这表明水印样本的分布与清洁图像的分布相似。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_44fe4eabb4e0435fac2fcd1da5de75f6@000000_oswg81522oswg1080oswg264_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 11. 水印样本检测率 (WSD) (%)</p><h2>3、小结</h2><p>本文探讨了水印技术在 AI 训练数据中的应用。训练数据是人工智能模型研究的关键要素，相关技术可以让数据所有者在谁可以使用他们的数据训练人工智能模型方面有更多的发言权。本文分析的三篇文章分别通过所有权验证、向数据集中插入水印样本的方法实现对 AI 训练数据的所有权保护。</p><p>随着 AI 的不断发展，特别是生成式 AI 近期的爆炸式涌现，针对 AI 的水印技术也随之吸引了更多关注。这些研究除了聚焦于向训练数据注入水印以外，也关注 AI 模型中的水印技术。我们将会持续关注相关的技术突破及研究进展。</p><h3>参考引用的文献</h3><p>[1] Tianyu Gu, Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg. Badnets: Evaluating backdooring attacks on deep neural networks. IEEE Access, 7:47230–47244, 2019.</p><p>[2] Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. Targeted backdoor attacks on deep learning systems using data poisoning. arXiv preprint arXiv:1712.05526, 2017.</p><p>[3] Anh Nguyen and Anh Tran. Wanet–imperceptible warping-based backdoor attack. In ICLR, 2021.</p><p>[4] Alexander Turner, Dimitris Tsipras, and Aleksander Madry. Label-consistent backdoor attacks. arXiv preprint arXiv:1912.02771, 2019.</p><p>[5] Hossein Souri, Micah Goldblum, Liam Fowl, Rama Chellappa, and Tom Goldstein. Sleeper agent: Scalable hidden trigger backdoors for neural networks trained from scratch. In NeurIPS, 2022.</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650897356&amp;idx=4&amp;sn=62a3c2f0abb6f40dce8a5224570b93a4&amp;chksm=84e4bfb2b39336a46551d29483b8917665c4d39dc0c97b61fa1ece46a166183c970cf1c330db&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：Jiying，编辑：H4O，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520471518996233</id>
            <title>当韩国女团BLACKPINK进军二次元，清华叉院AI神器原来还能这么玩</title>
            <link>https://www.36kr.com/p/2520471518996233</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520471518996233</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:47:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI生成, 女团MV, 动漫风格, ComfyUI
<br>
<br>
总结: 这篇文章介绍了一种利用AI生成动漫风格的女团MV的方法，作者使用了一个名为ComfyUI的工具，该工具是一个基于图形界面的Workflow可视化引擎，可以实现自动化的图像生成和优化。作者还介绍了LCM LoRA这个新模型，它可以根据文字指令或草图指示实时生成新图。通过使用LCM和ComfyUI，作者成功地将BLACKPINK的原版MV转换为动漫风格的MV。 </div>
                        <hr>
                    
                    <blockquote><p>看看这个 AI 生成的女团 MV 效果如何。</p></blockquote><p>如果你手机里有一些修图软件，你可能用过里面的「AI 绘画」功能，它通常会提供一些把照片转换为不同风格的选项，比如动漫风格、写真风格。但如今，视频也可以这么做了：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3ff3b14f4d824bd5a88fdab38beead42@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b918aed2c5db44eb989c0ada42178db1@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f8524a3cd8034c2e982391e4fd0ca3f1@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这些动图来自 X 平台（原推特）网友 @CoffeeVectors 生成的一段视频。他把韩国女团 BLACKPINK 代表作《DDU-DU DDU-DU》的原版 MV 输入了一个 AI 工具，很快就得到了动漫版的 MV。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cd8f5125876a489685594f8279e26d5a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个视频是借助一个名叫 ComfyUI 的工具来完成的。ComfyUI 是一个开源的基于图形界面的 Workflow 可视化引擎，用于被广泛采用的文生图 AI 模型 Stable Diffusion。它提供了一个用户友好的图形界面，可以将多个 Stable Diffusion 模型及其 Hypernetwork 组合成一个完整的工作流（Workflow）实现自动化的图像生成和优化。同时，社区也开发了各种 ComfyUI 的扩展插件，可以进一步增强其功能。</p><p>作者 @CoffeeVectors 表示，在制作这个 MV 的过程时，他在 ComfyUI 中用到了 AnimateDiff 和 multi-controlnet 工作流，前者用于动漫风格的生成，后者用来实现生成效果的控制。更重要的是，他在这次工作流中引入了一个当下很火的神器 ——LCM LoRA。</p><p>在《实时文生图速度提升 5-10 倍，清华 LCM/LCM-LoRA 爆火，浏览超百万、下载超 20 万》一文中，我们已经介绍过，LCM 是清华大学交叉信息研究院的研究者们构建的一个新模型，它的特点是文生图、图生图的效果都非常快，可以根据你的文字指令或草图指示实时生成新图。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_086445cdeecb49f297b513652c04964e@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在此基础上，研究者们又进一步开发了 LCM-LoRA，可以将 LCM 的快速生成能力在未经任何额外训练的情况下迁移到其他 LoRA 模型上。由于效果非常惊艳，模型在 Hugging Face 平台上的下载量已超 20 万次，X 平台上到处都能看到利用 LCM-LoRA 生成的实时视频效果。</p><p>那么，这个动漫版的 MV 是怎么做的呢？@CoffeeVectors 在帖子中详细描述了他的做法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d0e1f69983e644c6b0856e945236bf41@000000_oswg428977oswg880oswg748_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在下载了原版 MV 视频后，@CoffeeVectors 将 BLACKPINK 的整个 MV 作为单个 .mp4 输入进行处理。LCM 可以让他在 4090 上通过 6 步进行渲染（之前需要 20 多步），而且只占用 10.5 GB 的 VRAM。以下是详细数据：</p><p>整个渲染过程耗时 81 分钟，共 2,467 帧，每帧大约花 2 秒。这不包括从视频中提取图像序列和生成 ControlNet 映射的时间。在 SD 1.5 版中使用 Zoe Depth 和 Canny ControlNets，分辨率为 910 x 512。</p><p>要改进输出效果，使其风格更鲜明、细节更丰富、感觉不那么像一帧一帧的转描动画，就需要对单帧画面进行调整。但是，一次性完成整个视频，可以为你提供一个粗略的草稿，以便在此基础上进行迭代。</p><p>对于输入视频，他每隔一帧选取一帧，以达到 12 帧 / 秒的目标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_75c464164ce8492f9e7bb68f3b17335c@000000_oswg699032oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这是 @CoffeeVectors 添加 LCM LoRA 的截图。他选择了检查点中内置的 VAE：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d2588bd786b14674b94fca59a5666cd4@000000_oswg498763oswg1080oswg887_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他把提示写得很泛，想看看这个提示在各种镜头中的适配效果怎么样。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_964e5a69aae544f6a8a477ae02ced9eb@000000_oswg450170oswg1080oswg1191_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在 K 采样器中，他使用了 LCM 采样器。注意，你需要更新到最新版本的 ComfyUI 才能用这个采样器。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8d17d09457b24912ad25e403ad3f24b2@000000_oswg468630oswg1080oswg1254_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>下图描述了 @CoffeeVectors 如何安排 multi-control net 的节点：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c91736b40ac145a3b5891fd0f18893be@000000_oswg421170oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后，@CoffeeVectors 还推荐了一些相关教程：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_de6b9cf65b2d4a72b9cc774869a3c579@000000_oswg729660oswg1080oswg755_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>视频教程：https://www.youtube.com/watch?app=desktop&amp;v=zrxd95Mxz24</p><p>技术博客：https://huggingface.co/blog/lcm_LoRA</p><p>对这类技术应用感兴趣的开发者们可以玩起来啦！</p><h3>参考链接</h3><p>https://twitter.com/CoffeeVectors/status/1724579821093540182</p><p>https://hrefgo.com/blog/comfyui-a-comprehensive-guide-to-the-next-gen-stable-diffusion-gui</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650897356&amp;idx=3&amp;sn=bcde3c02da496a6a0deb726de65c7c14&amp;chksm=84e4bfb2b39336a4c6c05f566f9bd1bd4e7594896690b93d9a2534fb46b2b5721d78a26594a5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：张倩，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520458877345920</id>
            <title>港口无人驾驶终场战事：“真无人”与规模化</title>
            <link>https://www.36kr.com/p/2520458877345920</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520458877345920</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:46:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Robotaxi, 港口无人驾驶, 商业化落地, 技术持续迭代升级
<br>
<br>
总结: 2023年，当Robotaxi还在技术持续迭代升级、探索商业价值时，港口无人驾驶已开始大规模商业化落地和效率提升，行业竞争加剧，逐步进入洗牌阶段。无人驾驶从过去的科学问题、技术问题，变成了真正的商业落地问题。港口无人驾驶的关键在于常态化无人高效运营，实现质变进展，从而最大化发挥技术的商业价值。 </div>
                        <hr>
                    
                    <p>2023年，当Robotaxi落地还在技术持续迭代升级、探索商业价值时，港口无人驾驶已开始大规模商业化落地和效率提升，行业竞争加剧，逐步进入洗牌阶段。</p><p>友道智途副总经理杨磊坦言，“在这个领域，要进入Top 3或者Top 5，未来才有机会在激烈的行业竞争中脱颖而出。”</p><p>无人驾驶从过去的科学问题、技术问题，变成了真正的商业落地问题。尤其是规模化的商业落地，即如何真正给客户和各方带来价值。</p><p>现阶段港口无人驾驶商业化落地，<strong>关键在于常态化无人高效运营</strong>，实现质变进展，从而最大化发挥技术的商业价值。</p><p>行至终场，既是技术与实力的比拼，更是耐心与胆量的博弈。多位身处港口一线的工作人员称，“<strong>就看谁胆子大了</strong>。”</p><h2>何以先行一步？</h2><p>在宁波港大榭码头，智车战略观察到，来自斯年智驾、友道智途、畅行智能等无人驾驶公司的无人集卡、智能平板车，在港口进行运营或测试运营工作，与其他有人集卡混行、有序作业。</p><p><strong>这仅是一个缩影，当下无人驾驶作业设备开始渗透到各大港口。</strong></p><p>斯年智驾的无人集卡和智能平板车IMV已落地宁波港、唐山港、珠海港、太仓港、厦门港、宿迁港、潍坊港、青岛港等8个港口。其宁波大榭码头项目负责人段志伟告诉智车战略，目前全国共有400多辆无人集卡在港口进行商业化运营或者测试，其中斯年智驾布局200余辆。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_56f5db8e6cb84bc188b52b2b33b6737e@5958072_oswg873347oswg890oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智能平板车正成为业内公司在重点研发和推广的港口运输设备，友道智途杨磊认为，<strong>智能平板车未来一两年将在港口爆发</strong>。</p><p>友道智途无人纯电智能驾驶平板转运车（AIV）无驾驶室设计、同时支持蟹行、前后双向行驶等，灵活高效。目前，友道智途智能驾驶产品从南到北布局近10个港口，200余台自动驾驶车辆在开展商业化测试和运营。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f02b2b496ec84ec5b86d154f297d8c0b@5958072_oswg117592oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>无人驾驶技术发展之初，一些企业意识到Robotaxi及干线物流等开放式场景，商业化落地困难，选择从港口、矿山等封闭式或半封闭式场景作为突破口。经纬恒润、西井科技、主线科技、畅加风行、飞步科技、元戎启行、图森未来等均在港口布局了相关业务。</p><p>友道智途由上汽集团孵化，其智能重卡项目始于上海东海大桥洋山港，是全国首个在公开道路场景下，涵盖高速、港口等，开展的智能重卡自动驾驶商业化示范运营项目，也是目前国内在法律框架下允许的无驾驶人自动驾驶落地应用商用车场景项目。</p><p>对于优先落地港口，杨磊分析，<strong>港口是无人驾驶商业化落地客户接受度高、且应用场景成熟度高、相对封闭场景。</strong></p><p>港口传统运输方式司机成本高，据中国水运网数据，国内港口作业司机成本占据整个港口运输成本的50%以上。同时，港口工作环境差，需24小时作业，司机多班倒易疲劳驾驶，安全隐患多，导致招工难，港口自动化转型已是必然趋势。</p><p>更为重要的是，港口是典型的<strong>“封闭场景+低速运营+标准化作业”</strong>场景，相较其他场景对技术要求相对低。加之技术不断进步，国家鼓励发展智慧港口，港口对无人驾驶接受度正变高，新建港口均以实现自动化为目标，具备无人驾驶技术落地的条件和基因。</p><p>最后，部分无人驾驶企业的发展始于港口，但并不终于港口。</p><p>斯年智驾CEO何贝就曾表示，港口包含了船侧到内部堆场的封闭区域，以及内部堆场到外部堆场或者仓库的半封闭区域，把控了短驳、短倒，以及众多的专线港口外物流渠道，具备市场延拓性。</p><p>再加上统一车型的无人驾驶方案、安全冗余系统的设计以及批量化复制的能力，何贝认为可<strong>沿着内部走向半开放，从半开放走向开放的路径，即从港口场景突破，扩大到千亿场景物流市场</strong>。最近，斯年智驾已经正式获取天津市智能网联汽车道路测试商用车牌照。</p><h2>造血成为关键词</h2><p>无人驾驶赛道，资本出手愈加谨慎，更关注技术落定应用。企查查数据显示，2021年、2022年、2023年至今分别完成融资事件73起、63起、34起，逐年递减。</p><p>港口无人驾驶商业化运营先行一步，来到了另一个关键节点：<strong>让参与主体从中获益，无人驾驶公司自我造血长远发展，真正发挥技术的商业价值。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bdd0f84b4e1c4db2a6d46857216c5098@5958072_oswg914945oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现实情况是，港口无人驾驶距离大规模、真无人的落地应用还存在差距，整体而言商业化并未达到理想效果。</p><p>目前，无人驾驶落地港口有两种常见商业模式。</p><p>一是<strong>代运营模式</strong>，港口不用购买无人集卡、智能平板车等设备，也不用雇人做运营，无人驾驶公司提供运力服务。此种模式下多是按箱收费，根据运距等情况收取不等价格。</p><p>另一种是<strong>销售模式</strong>，由公司提供整体的无人驾驶解决方案，包含运输设备、技术服务以及后续的运维服务等。随着公司运营经验变丰富、整体技术方案提升，港口接受度提高，业内公司大都根据客户需要选择双模式驱动。</p><p>对企业而言，盈利的关键在于，<strong>成本把控与规模化运营</strong>。</p><p>车及感知设备等硬件成本，随着技术进步和产业发展，整体将呈现下降趋势。</p><p>代运营模式下车辆的重资产投入，选择与运营体共同持有车辆有效控制成本。在商业化初期，港口对无人驾驶产品技术还存在顾虑的情况下，为港口提供低成本运力运营，可为撬动港口真实需求、将来开拓市场打下基础。</p><p>友道智途杨磊认为，<strong>控制成本的有效方式是规模化，规模化目的就是控制成本</strong>。因此，友道智途商业落地拓展业务时，会重点考虑业务规模大的场景。</p><p>杨磊说道，“车子进到场景里面做适配开发就会产生费用，只有规模化应用才能凸显其商业价值。”有了规模，再把产品做成平台系列化的货架产品，越有利于控制成本。同时规模化后，对于效率提升也会有很大帮助。</p><p>站在港口运输公司的角度，购买一台AIV水平转运车，可在2~3年之内收回成本，而车子可以使用8—10年。</p><p>杨磊算了一笔账：<strong>传统卡车一台70万，一台AIV水平转运车价格180万—200万不等，相较传统车子多了100万投入，但每年可以省至少两个司机的人工成本，大约在30—40万左右，基本上2~3年之后就能收回成本。</strong></p><h2>“真无人”实现商业化破局</h2><p>不过，无论是代运营模式，还是销售模式，需要根据港口要求的安全人员配置情况，综合考虑运输公司或者无人驾驶公司提供的安全员、测试员等人力成本。</p><p>前面提到，传统的港口水平运输，集卡司机成本占比约55%。港口无人驾驶的应用，在于减少集卡司机成本，并且提升运输效率。</p><p>现下很多港口的无人集卡，实现了方向盘后真无人，但旁边配备安全员；智能平板车没有驾驶室，但会根据港口要求在周围关键点位安排人员。</p><p><strong>没有了驾驶员成本，又有了安全人员等成本，无人驾驶的商业价值并未发挥出来。</strong></p><p>智车战略调研了解到，一些公司在配备安全人员情况下盈利存在难度，但拿掉安全员，就能实现盈利。安全员不下车，无人驾驶公司难以维持长期作业，反过来导致无人驾驶系统迟迟不能落地和去安全员，形成恶性循环。</p><p>可见，“真无人”，是无人驾驶商业化落地破局的关键环节之一。</p><p><strong>安全人员的配置要求主要由港口决定，各港口管控规则不同，往往取决于港口对无人驾驶技术的接受度、内部推动力度。</strong></p><p>很多港口渴望无人驾驶产品和技术的落地，但在港口混行场景下，万一发生事故后的责任归属问题，是港口客户的顾虑。</p><p>据业内人士介绍：“港口的安全管理非常严格，尤其是生产安全。因此在引入创新技术的时候，港口方会比较谨慎。无人驾驶车辆出现事故如何界定，到底是生产事故还是交通事故，也是客户会重点关注的问题。”</p><p>究其原因，关于港口无人驾驶的监管，尤其是混行场景，还没有国家层面的相关政策指导及法规支持。</p><p>据了解，港口内发生事故后责任如何界定，需要一事一议。举个例子：目前港口大多是无人车和有人车混行，如果是无人车主动撞了有人车，责任在无人车；如果是无人车被撞，则按照道路交通规则判定。</p><p>对于港口担心的安全问题<strong>，可通过技术优化及全方位布局，比如车路云协同，增加无人驾驶技术落地港口应用的可靠度。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bbc1eee5a1524198a1c5c95e712f453f@5958072_oswg116882oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>斯年智驾通过“强车+强云”方案，即车端的即时战略和云端的上帝视角协同，自研了场景物流信息化平台，可实现数百辆无人运输车辆的智能调度和实时仿真，并支持远程接管和控制。</p><p>飞步科技则专注于车路云一体化智慧港口解决方案，整合车端无人驾驶、路端智能感知与云端智能调度等平台。2022年初，在宁波舟山港集团梅山港区，飞步科技无人集卡已经开始撤下安全员，实现全无人驾驶。</p><h2>写在最后</h2><p>综合来看，实现“真无人”大规模的商业落地，需要来自政府、企业、港口等行业参与主体的共同推动，也需要整个产业生态的发展进步。</p><p>港口数智化转型大势所趋，随着5G、新基建和车路云一体化技术的发展，会有越来越多的港口以更加积极开放的心态来迎接无人驾驶落地。</p><p>无人驾驶作业设备从近距离的“一人一车”监管，到远程的“一人一车队”监管，真正实现降本增效只是时间问题。</p><p>但机会往往属于跑在前面的人，终场战事结局如何，让我们拭目以待。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/qH1jMvaLhvFosg2mqcWP0w" rel="noopener noreferrer nofollow" target="_blank">“智车战略”（ID:xbzczl）</a>，作者：胡小凤，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520455327934213</id>
            <title>微软连甩三大炸弹，Bing Chat更名Copilot，自研芯片问世，还加入GPTs功能</title>
            <link>https://www.36kr.com/p/2520455327934213</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520455327934213</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:41:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, Copilot, Bing Chat, 自定义GPT
<br>
<br>
总结: 微软宣布将Bing Chat更名为Copilot，并推出了免费的Copilot服务。Copilot类似于OpenAI的自定义GPT，可以在微软的各个产品中使用。此外，微软还推出了两款高端定制芯片，可能用于Copilot的新功能。Copilot还与Microsoft 365等产品整合，提供了Copilot Studio应用，可以自定义数据集和自动化流程。 </div>
                        <hr>
                    
                    <p>就在刚刚，微软正式对外重磅宣布💥：</p><blockquote><p>从今天起，Bing Chat全线更名——<strong>Copilot</strong>。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f81ae989837c4ba1a3e2a024652a2142@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>和ChatGPT一样，现在的微软Copilot也拥有自己的专属网站。</p><p>但与之不同的是，像GPT-4、DALL·E 3这样的功能，在Copilot上统统都是<strong>免费</strong>的！</p><p>要想使用这一切，你只需要做的就是登录微软账号（而ChatGPT则需要订阅会员）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c18bda92095242c4b17ce5025e707a6d@000000_oswg92055oswg1080oswg572_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就连OpenAI上周王炸推出的自定义GPT，也被微软塞了进来，并取名为——<strong>Copilot Studio</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_12be1fffed0a4430a89b12bd3184543b@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而围绕新品牌Copilot，微软的大动作还不止于此。</p><p>例如流传已久的自研芯片，今天终于亮相了——<strong>2款高端定制芯片</strong>，Azure Maia 100和Azure Cobalt 100。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_70da3dd9836c4267a3d3994138bac3ae@000000_oswg271300oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据外媒推测，尤其是像Maia 100这种AI芯片，很可能就是要用在Copilot品牌下的一些新功能。</p><p>除此之外，打工人最关心的<strong>Office</strong>，这次也是塞满了Copilot。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3bd1552efae3424e8f33000620d3c87a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>总而言之，纵观整场微软Ignite大会，“Copilot”可谓是贯穿了所有。</p><p>正如外媒的评价：</p><blockquote><p>微软可以叫“Copilot公司”了。</p></blockquote><h2>一切皆可Copilot</h2><p>对于Bing Chat更名为Copilot，微软CEO纳德拉在现场将此高度总结为：</p><blockquote><p>Copilot无所不在。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_51fef07e3ec44aba9476b5d2e36618ab@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在，无论是在微软的Edge、谷歌的Chrome、苹果的Safari，亦或是移动端，均可使用Copilot。</p><p>不过需要强调的一点是，虽然Copilot只需要登录微软账号就可以免费使用，但像Microsoft 365等其它产品的Copilot依旧是付费的。</p><p>对于类似OpenAI GPTs的Copilot Studio，从微软的介绍来看，<strong>它还是有一点不同</strong>。</p><p>Copilot Studio的主要设计目的其实是扩展Microsoft 365 Copilot。</p><p>在该应用中，大伙可以用它自定义包含不同数据集、自动化流程的Copilot。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6319d72695c04c8389cb9916dff20ac7@000000_oswg290432oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由此一来，我们就可以将这些自定义AI助手更专注地连接到公司的关键业务系统中（是的，主要面向企业用户），然后就像与人聊天一样方便地获取其中信息。</p><blockquote><p>它可以是网站上帮助用户回答产品问题的Copilot，也可以是季度收益发布中的Copilot。</p></blockquote><p>对于这项新功能，最重磅的一点还是：</p><p>OpenAI<strong>GPTs</strong>居然也被直接塞了进来，大伙在构建自定义Copilot时，也能用上它的功能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fa08379a913342f6803e38dc6853729e@000000_oswg31387oswg166oswg154_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后，Copilot系列除了以上这些，微软还发布了Copilot for Azure，一个专门通过聊天方式简化日常IT管理的AI。</p><h2>首款5nm自研AI芯片</h2><p>在围绕Copilot的一系列重磅炸弹放出之时，微软的自研芯片也终于来了。</p><p>一共两款。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c08867407f43496098c557d799961d69@000000_oswg397880oswg452oswg662_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一款叫做<strong>Maia 100</strong>，定位AI芯片，用于Azure云服务，专门针对生成式AI进行了优化。</p><p>据介绍，Maia 100采用5nm工艺，共包含1050亿个晶体管，是该制程工艺上最大的芯片之一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3372cc97b5ae4d1a9283cadb8aea3a3d@000000_oswg736647oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Azure芯片部门副总裁透露，Maia 100已在其Bing和Office AI产品上测试。</p><p>以及划重点：<strong>OpenAI也在试用</strong>。这意味着ChatGPT等模型的云训练和推理都将可能基于该芯片。</p><p>第二款叫<strong>Cobalt 100</strong>，是一款64位、128计算核心的CPU，基于ARM指令集架构，对标英特尔和AMD同类处理器。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1b74779b3c68434cb78ed51ac239c0dd@000000_oswg100173oswg1024oswg682_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Cobalt 100也被设计为专门用于云计算，相比微软Azure一直在用的其他基于ARM的芯片，可带来40%功耗下降。</p><p>目前，它已开始为Microsoft Teams等应用提供支持。</p><p>微软介绍，这两款芯片全部由台积电生产，将在明年初在微软的几个数据中心首次公开亮相。</p><p>以及它们都还只是各自系列中的头阵产品，言外之意，后面还会继续研发上新。</p><p>现在，微软也终于在谷歌TPU和亚马逊Graviton之后，拥有了自研AI芯片——三大云巨头也“齐活”了。</p><h2>Office更新：降价了</h2><p>最最后，围绕微软Office一系列套件的AI产品Copilot for Microsoft 365也更新了n多功能（没在大会上宣布，直接官网通知）。</p><p>主要思想就是更加个性化、更强的数学和分析能力以及全面打通协作。</p><p>譬如在Word和PowerPoint中，我们可以设置更多写作格式、风格、语气的偏好，获得更为量身定制的文档和PPT，更像你本人（亲自创作的）。</p><p>在Excel中，则能用自然语言解锁更多复杂的数学分析。</p><p>在Team中，可以直接将大伙的头脑风暴转为可视化白板，如果你想专门看看某位同事说了什么，直接使用“Quote xx”命令即可呈现Copilot为你记录的全部发言。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9d59279705544bdb880b20ae072ad069@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，最最值得关注的更新还是<strong>降价了</strong>。</p><p>现在每月只需50美元即可享受企业服务，比之前少了20刀。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247704126&amp;idx=2&amp;sn=ebfd2fe72d3c38302131d1412ccf9cf3&amp;chksm=e8df694cdfa8e05a32e8be89bf4a16fbf9138261221d8e22bf183c1d147ace776304731b64b6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID：QbitAI）</a>，作者：金磊 丰色，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520439469008641</id>
            <title>芯旺微冲刺科创板，供应商集中度高，经营活动现金流承压</title>
            <link>https://www.36kr.com/p/2520439469008641</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520439469008641</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:23:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 上海芯旺微电子技术股份有限公司, 科创板上市申请, MCU内核, 控股股东, 募集资金
<br>
<br>
总结: 上海芯旺微电子技术股份有限公司是一家以自主研发的KungFu指令集与MCU内核为基础的集成电路设计企业。他们发布了首次公开发行股票并在科创板上市申请文件的审核问询函的回复。公司的控股股东丁晓兵和丁丁持有大部分股份和表决权。他们计划募集资金用于MCU研发项目和测试认证中心建设项目等。 </div>
                        <hr>
                    
                    <p>近期，上海芯旺微电子技术股份有限公司（以下简称“芯旺微”）发布了首次公开发行股票并在科创板上市申请文件的审核问询函的回复，对产品与市场、技术与研发、销售模式和客户等问题进行了回复，保荐人为招商证券股份有限公司。</p><p>芯旺微是一家以自主研发的KungFu指令集与MCU内核为基础，以车规级、工业级MCU的研发、设计及销售为主营业务的专业化集成电路设计企业。</p><p>招股书显示，本次发行前，公司实际控制人丁晓兵和丁丁直接及间接持有公司60.32%的股份，并控制64.19%的表决权比例；本次发行完成后，二人直接及间接持有公司51.27%的股份，并控制54.56%的表决权比例，仍处于控制地位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e9d39f02d6ca4e1fa3fd8fd316d6dc6e@000000_oswg103506oswg831oswg487_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">发行前股权结构图，图片来源：招股书</p><p>本次申请上市，公司拟募集资金约17.29亿元，用于车规级MCU研发及产业化项目、工业级和AIoT MCU研发及产业化项目、车规级信号链及射频SoC芯片研发及产业化项目、测试认证中心建设项目、补充流动资金。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f8db16f12d7548a3b5dadd1a88eafead@000000_oswg212831oswg831oswg523_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">募资使用情况，图片来源：招股书</p><h2>01 依赖五大供应商</h2><p>业绩方面，2020年至2022年，芯旺微的营业收入分别约0.98亿元、2.33亿元、3.12亿元，对应的归属于母公司股东的净利润为-2620.23万元、5079.17万元、6124.11万元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_815b53aedbbc4ff8ad61015bb0e76b81@000000_oswg306077oswg831oswg660_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c9725d3cd3754700a8adcfdfbd886662@000000_oswg70945oswg831oswg138_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">主要财务数据及财务指标，图片来源：招股书</p><p>芯旺微系专业的集成电路设计企业，主要从事车规级和工业级MCU的研发、设计及销售。报告期内，公司的车规级MCU业务营收占比呈上升趋势，工业级MCU的营收占比有所下滑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b197ba6fa3f34381a023f64f80be3d84@000000_oswg157322oswg831oswg363_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">公司主营业务收入的主要构成情况，图片来源：招股书</p><p>竞争格局方面，我国车规级MCU国产化率较低，国内MCU厂商车规级MCU产品出货量整体偏小。在国内MCU市场，尤其是车规级MCU领域，恩智浦、微芯、瑞萨、意法半导体、英飞凌、德州仪器等国外知名MCU厂商仍占据主导地位。</p><p>此外，兆易创新、中颖电子、中微半导等国内已上市MCU厂商以及新兴MCU厂商均已布局车规级MCU领域，市场竞争激烈。与国外巨头相比，芯旺微在业务规模、研发实力、客户积累、品牌影响力等方面仍存在较大差距。</p><p>报告期内，芯旺微的综合毛利率分别为48.32%、55.15%及52.47%，存在一定波动。由于晶圆成本占公司主营业务成本的50%以上，是公司采购的主要原材料，如果晶圆采购价格发生波动，可能会影响公司的毛利率和盈利能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d587bcfe9b374dedb844869ca7c7e230@000000_oswg40924oswg831oswg129_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d1ed7328c6c5433ea29b915868b5e647@000000_oswg101054oswg830oswg264_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">公司与同行业可比公司毛利率比较情况，图片来源：招股书</p><p>芯旺微面临着供应商较为集中的风险。在Fabless模式下，公司专注于集成电路的研发、设计及销售，而晶圆制造、晶圆测试和芯片封装均通过外购或委外的方式完成。报告期内，公司向前五大供应商的采购金额占同期采购金额的比例在90%以上，占比较大。如果公司与中芯国际、日荣半导体、华天科技等主要供应商的合作关系发生变化，可能会影响公司的生产经营。</p><h2>02 存货规模猛增</h2><p>公司的主要产品车规级和工业级MCU的开发具备技术含量高、研发投入大和研发周期长的特点。近年来，随着MCU的应用场景愈发丰富，驱动MCU技术和产品快速迭代升级。</p><p>芯旺微当前仍有较多在研项目，未来仍将保持较高的研发投入力度。但新技术应用和新产品的市场化存在一定不确定性，如果公司不能正确把握研发方向或者推出新产品不能及时契合市场需求，可能会影响公司产品的竞争力。</p><p>报告期各期，公司的研发费用分别为1473.78万元、3887.76万元及6272.86万元，研发费用占营业收入的比例分别为14.99%、16.70%及20.08%，尽管研发投入呈增长趋势，但公司剔除股份支付后的研发费用率仍低于同行业上市公司平均值。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bf4ef014c9e6413aba926b729a68afb0@000000_oswg100285oswg831oswg326_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">公司与同行业上市公司的研发费用率（剔除股份支付）比较情况，图片来源：招股书</p><p>报告期各期末，芯旺微的存货账面价值分别为2508.99万元、9801.5万元、2.53亿元，呈逐年上升趋势，占各期末流动资产的比例分别为18.77%、17.83%及31.49%。公司存货主要由原材料、库存商品、半成品等构成，如果市场情况发生变化，导致产品价格下降，公司可能发生存货减值损失。</p><p>随着公司经营规模的扩大，应收账款也逐步增加。报告期各期末，公司应收账款账面价值分别为1189.22万元、3014.87万元及4166.42万元，呈持续上升趋势，如果公司应收账款管理不当，可能存在坏账风险。</p><p>受存货及应收账款规模上升等影响，芯旺微的经营活动现金流明显承压。2020年至2022年，公司经营活动产生的现金流量净额分别为-851.10万元、-1044.50万元、-1.34亿元，持续为负。</p><h2>03 结语</h2><p>近几年，尽管芯旺微的营业收入呈增长趋势，净利润也实现扭亏，但公司同样暗藏经营隐忧。在存货及应收账款规模增加等影响下，公司经营活动产生的现金流量净额持续为负且公司较为依赖前五大供应商。处在一个技术含量高、研发投入大的行业，公司还是得加大研发力度，持续进行技术创新，来提高自身的竞争力。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzUzMTkwOTkzNw==&amp;mid=2247564743&amp;idx=2&amp;sn=c4d1dc3913b3a344628fc9bff0b1a582&amp;chksm=fab8e199cdcf688f974c23f32107dca6f104ad146079208de448a6350a09d0239cc749ab1b59&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“格隆汇新股”（ID：ipopress）</a>，作者：发哥说新股，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520472109147655</id>
            <title>敲诈工行美国子公司，这家黑客到底什么来头？</title>
            <link>https://www.36kr.com/p/2520472109147655</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520472109147655</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:19:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 全球金融界, 工商银行, 勒索软件攻击, LockBit
<br>
<br>
总结: 全球金融界发生了一起工商银行被LockBit勒索软件攻击的事件。这次攻击对用户的结算和股票交易造成了影响，约90亿美元的业务受到了影响。LockBit是一种臭名昭著的勒索软件，被称为全世界最快的加密软件，攻击遍及全球，但禁止攻击俄罗斯或其他前苏联国家。LockBit在技术上操作，一旦攻破设备，会加密或偷走数据，并要求支付赎金。如果不支付赎金，就会在网上公开数据。 </div>
                        <hr>
                    
                    <p>前几天，全球金融界，发生了一件不小的事情。</p><p>中国工商银行美国子公司工银金融（ICBC Financial Services，ICBCFS），被勒索软件攻击。</p><p>而搞这次敲诈勒索的是：LockBit。</p><p>工行方面在网站确认工银金融遭受了勒索软件攻击。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cca46a8d0bbd420a8aedcfc5748f7c77@000000_oswg396368oswg891oswg762_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">工行方面的声明</p><p>这次攻击的影响还是不小的。</p><p>据说，因为攻击导致用户不能结算美国国债交易，部分股票交易也受到影响。</p><p>有一个说法是，约90亿美元的业务受到影响。</p><p>甚至，一些人不得不通过U盘来传递结算数据。</p><p>而另一个方面。</p><p>LockBit方面也公开确认，对这次攻击工商银行的事件负责。</p><p>而且，据他们说，他们已经收到工行方面支付的赎金。</p><p>要知道工行可是全球最大的银行，在信息技术上投入和重视也非同一般。</p><p>这次竟然被LockBit突袭。</p><p>那么，这个LockBit到底是什么来头？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c1cb93bfdf8349d983cac0fd13dc73ed@000000_oswg277870oswg514oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">媒体的相关报道</p><p>这个LockBit，出现的时间不早。</p><p>最早被发现是在2019年9月，当时还叫ABCD勒索软件。</p><p>2020年1月，LockBit正式出现在俄语论坛上。</p><p>等到2021年6月，LockBit 2.0版本出现，也被叫作LockBit Red。</p><p>2022年3月，LockBit 3.0版本出现，也称为 LockBit Black。</p><p>今年1月，LockBit Green出现。</p><p>今年4月，又发现针对苹果macOS的版本。</p><p>在地下论坛上，LockBit被称作是“全世界最快的加密软件”。</p><p>据说，20分钟就能窃取高达100GB的数据。</p><p>就是这样一个“年轻”的勒索软件，现在可谓是臭名昭著。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1526f56ff2544fcf8e06aa40c8d13e54@000000_oswg27672oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据美国网络安全局（CISA）网站的数据，在澳大利亚，从去年4月1日起的1年里，LockBit的网络敲诈勒索事件占到18%。</p><p>2022年，加拿大22%的勒索软件事件是LockBit造成的。</p><p>根据FBI统计，2020年以来，美国发生的LockBit勒索事件大约有1700起。</p><p>而且，整体上，LockBit的勒索越来越猖獗。</p><p>LockBit在所有网络软件勒索事件中的占比在快速上升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_65e304a857f64209aec9717995e83582@000000_oswg62251oswg1080oswg675_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>LockBit攻击遍及全世界，但据说禁止攻击俄罗斯或者其他前苏联国家。</p><p>简单说几起有名的攻击事件。</p><p>2021年5月，加拿大、德国军方的独家战机培训供应商Top Aces被LockBit攻击。</p><p>2021年8月，全球IT咨询巨头埃森哲也被攻击，据说被窃取了6TB的数据，并被要求支付5000万美元的赎金。</p><p>今年6月底，台积电被攻击，并被要求支付赎金7000万美元。</p><p>今年10月，LockBit窃取了波音公司的数据。</p><p>但波音拒绝支付赎金，为了报复波音，他们泄露了大约43GB的波音文件。</p><p>这次工商银行，只是最新的一次攻击事件。</p><p>另外，像曼谷航空、英国皇家邮政、德国大陆集团、伦敦市政府等等，都被LockBit攻击过。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_18786b78702b4782a9f38cfcb91b3b39@000000_oswg48260oswg1051oswg354_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">波音被攻击的相关报道</p><p>LockBit在技术上操作，一般是侵入网络系统，一旦攻下一台设备，它会自动进行复制、传播，然后攻击一台又一台设备。</p><p>一旦攻破，那么，就会加密或者直接偷走你的数据，接着，通知你交钱。</p><p>交了钱，就给你解密，或者把数据交给你。</p><p>如果不交钱，那么，就在网上公开你的数据。</p><p>不过，相比其他勒索软件，LockBit背后的黑客更注重经营。</p><p>今年LockBit 3.0推出后，为了让软件更好用，他们还搞了一个“漏洞赏金”计划，吸引全球技术大拿帮忙检测缺陷和弱点，最高能拿到100万美元的奖励。</p><p>他们开发了一系列的辅助工具，比如，赎金支付门户等，甚至还提供赎金谈判服务。</p><p>然后，其他黑客就可以利用LockBit去敲诈，一旦得手，在中间抽成20%（按赎金总额来算）。</p><p>不过，盗亦有道。</p><p>据说，LockBit禁止攻击核电厂等一些特殊行业的重要设施。</p><p>根据美国方面的统计，从2020年1月在美国第一次观察到LockBit的活动以来，美国相关公司、机构共向LockBit支付了大约价值高达9100万美元的赎金。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_05e4c01416eb4c52820cd7e159be3e96@000000_oswg51353oswg1024oswg337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且，LockBit背后真正的黑客到现在还没有被挖出来。</p><p>准确地说，现在大家连这些黑客是谁都不知道。</p><p>去年11月，美国司法部宣布逮捕一个叫米哈伊尔·瓦西里耶夫 (Mikhail Vasiliev)的人，他有俄罗斯和加拿大双重国籍。</p><p>美国司法部指控的罪名是他与LockBit勒索软件活动有关。</p><p>根据美国司法部的说法，这是他们调查了两年半后作出的决定。</p><p>今年6月，美国司法部再次宣布对俄罗斯公民鲁斯兰·马戈梅多维奇·阿斯塔米罗夫 (Ruslan Magomedovich Astamirov) 提出刑事指控。</p><p>罪名是他涉嫌参与LockBit勒索软件活动。</p><p>美国司法部的指控表明，阿斯塔米罗夫直接实施了至少5次勒索软件攻击，并收到了赎金，当然这些赎金是以比特币形式支付的。</p><p>LockBit的幕后到底还有哪些人？</p><p>去年，日本共同社说他们采访到了LockBit的成员。</p><p>报道里说，LockBit的成员有100人以上。</p><p>这名成员宣称：LockBit是“以金钱为目的的非政治组织”，“成员不仅来自前苏联国家，还有日本人、美国人”。</p><p>而他们每次勒索的金额也大概有个标准：大致是被敲诈对象年销售额或年收入的0.5%-10%。</p><p>这名成员还说，“调查机关绝对找不到我们的位置，我一直辗转于全球。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f0cfd99bec3c49eaaa57031bcb5c371d@000000_oswg91694oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>正像周鸿祎所说，这样的勒索软件已经成为数字世界的“头号公敌”。</p><p>当然，对于大部分普通人来说，倒无需整日担心，毕竟不少人用六位数密码保护着自己四位数的存款。</p><p>这些勒索软件，敲诈的对象，首选也是大商巨贾。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MTU3Mzk2OA==&amp;mid=2654859100&amp;idx=1&amp;sn=5978a5bb5fd48914b60c37ef244f1567&amp;chksm=bd7a3de38a0db4f5bffccc5d2000bf8c6f93a3ca0d192c1eec51b3fa910b9976a059ae757d73&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“正解局”（ID：zhengjieclub）</a>，作者：正解局，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2516699681361924</id>
            <title>36氪独家丨星纪魅族获20亿元融资，李书福的手机公司挤上造车牌桌</title>
            <link>https://www.36kr.com/p/2516699681361924</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2516699681361924</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 06:54:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 星纪魅族, 融资, 汽车领域, 合作
<br>
<br>
总结: 星纪魅族是一家在汽车领域有着丰富融资经验的公司，他们通过多轮融资已经累计融资20亿元，投后估值超过100亿元人民币。最近，他们完成了A轮融资，并与吉利系汽车品牌极星汽车达成合作，共同开发智能电动汽车。这次融资将帮助他们加速市场突破，同时也需要与极星汽车合作，补充极星车型的短板。 </div>
                        <hr>
                    
                    <p>文丨彭苏平</p><p>编辑丨李勤 杨轩</p><p>华为用智选车在车市掀起巨浪，小米汽车呼之欲出，曾经同台竞技的魅族也没有在汽车版图上甘于沉寂。</p><p>36氪独家获悉，吉利系公司<strong>星纪魅族已完成A轮融资，这是其短期内完成的又一笔融资。加上上半年完成的天使+轮融资，今年星纪魅族已累计融资20亿元，投后估值超100亿元人民币。</strong></p><p>据悉，上半年星纪魅族的天使+轮投资方为容亿投资、星元基金、武汉经开等，而近期的A轮领投方为亚投基金和嘉实国际，QC Capital、武汉经开及产业链合作伙伴等跟投。</p><p>数十亿资金进账后，可以预见，星纪魅族将在汽车领域正式出击，一系列组织和人事调整序幕就此拉开。&nbsp;</p><p>36氪获悉，公司联合创始人、原CFO苏静将升任总裁，负责日常运营，原公司执行副总裁兼运营体系负责人戚为民将出任CFO，接替财务及投融资相关工作，而沈子瑜则将继续担任董事长兼CEO，掌管公司的全面工作。</p><p>有报道显示，即将任职总裁的苏静此前曾负责星纪魅族的投融资与日常运营，她曾参与主导星纪时代收购魅族，以及与极星汽车成立全新合资公司。任职总裁后，苏静的精力将集中在公司业务运营和对外合作上。</p><p>2022年，吉利董事长李书福旗下公司星纪时代将魅族手机收入麾下，双方整合而成的公司就是星纪魅族。</p><p>华为定位为增量零部件，帮助车企造好车，小米是外化出一支力量，独立造车，而魅族手机则是被纳入车企体系内，服务于汽车智联生态。殊途同归，背后都是科技公司将自身对新生消费群体的感染力和科技产品定义能力，通过汽车制造业，进行势能转化。</p><p>今年6月，星纪魅族再次向造车业务迈进一步，与吉利系汽车品牌极星汽车达成合作。 合资公司将为极星汽车打造面向中国市场的智能操作系统，并负责极星在中国的销售和服务。</p><p>与华为智选车模式类似的是，星纪魅族将会为极星在中国市场的车型提供专属智能操作系统，主导新车型的产品定义。这或许是星纪魅族在资本市场低迷之下，斩获20亿元融资的基础。&nbsp;</p><p>华为通过对赛力斯等合作伙伴提供产品、技术以及品牌形象等资源，让问界汽车几乎一夜成名，近期随着新款M7等产品上市，问界更是斩获了爆发式订单。</p><p>星纪魅族走了相似的路径，其曾提出“手机域”的理念，即超越传统汽车五个域（动力域、底盘域、车身域、座舱域、自动驾驶域）之外的“第六域”，让消费电子为智能汽车赋能。</p><p>基于此，星纪魅族自研了车机系统Flyme Auto，并与吉利系公司芯擎科技的7nm 车规级芯片“龍鷹一号”、亿咖通·安托拉1000 Pro平台进行融合。目前，这套软硬件产品已经在吉利系汽车品牌领克08上交付，助力这款车在上市不到两个月时间里，销量破万。</p><p>星纪魅族与极星汽车联手，并攫取到更丰富的发展资源后，无疑也需要更快取得市场突破。</p><p>极星汽车由沃尔沃和吉利共同出资成立，总部位于瑞典哥德堡。背靠沃尔沃，极星汽车以北欧设计语言定义智能电动汽车， 但目前极星汽车仅有一款Polestar 2已大批量交付，前三个季度4.18万辆的交付成绩，对汽车工业而言，仍不够稳健。</p><p>不管是嫁接吉利的制造和研发能力，还是星纪魅族的产品、软件体系，都是极星的当务之急。</p><p>据悉，星纪魅族和极星合作的首款产品极星4已于近期下线，这款车基于SEA浩瀚架构开发，搭载了针对中国市场打造的极星操作系统Polestar OS。此外，星纪魅族还和极星共同开发了一款极星手机，以打造无缝连接的使用体验。</p><p>车机软件的智能化升级，无疑将补上极星车型的短项，而Polestar 4的开发和交付，也会让星纪魅族所搭建的体系得到练兵。</p><p>但不得不承认，这个时间窗口也不会太长，因为老对手们在以更快的速度，冲入战场。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2519315593373188</id>
            <title>腾讯云向量数据库多项升级：最高支持千亿向量，一键打包开箱即用 | 最前线</title>
            <link>https://www.36kr.com/p/2519315593373188</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2519315593373188</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 05:27:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 邓咏仪, 腾讯云, 向量数据库, 大模型
<br>
<br>
总结: 11月15日，在腾讯云向量数据库技术及产业峰会上，腾讯云宣布全面升级向量数据库多项核心性能。新的向量数据库在多项性能上都有提升，包括支持更大规模的向量数据、优化索引压缩算法、集成Embedding功能等。腾讯云还与信通院联合发布了国内首个向量数据库标准，并成立了“AGI技术生态联盟”。向量数据库是大模型的数据底座，决定了大模型的性能。腾讯云向量数据库已经在腾讯内部和外部业务落地，服务了超过1000家客户，包括博世、销售易、搜狐等。腾讯云推出了端到端的向量数据库解决方案，提高了召回率并缩短了数据接入AI的时间。大模型的快速发展对创业生态有深远影响，但向量数据库仍然是大模型+数据库产品化的重要组成部分。 </div>
                        <hr>
                    
                    <p>作者 | 邓咏仪</p><p>编辑 | 苏建勋</p><p>11月15日，在腾讯云向量数据库技术及产业峰会上，腾讯云宣布全面升级向量数据库多项核心性能。</p><p>新的向量数据库在多项性能上都有提升：</p><ul><li>在优化版的IVF索引支持下，向量数据库从最初支持的十亿向量规模到现在的最高千亿规模，最高支持500万QPS峰值能力。</li><li>索引的压缩算法进行了优化，相同的内存可以存储5-10倍的数据</li><li>集成Embedding功能，让用户无需关注向量生成过程，就可以实现快速处理数据，实现了用自然语言和数据对话</li></ul><p>另外，腾讯云和信通院一起联合50多家企业共同发布了国内首个向量数据库标准，推进向量数据库及大模型相关产业走向大规模应用。腾讯云还与硬件厂商、大模型厂商、行业代表等联合成立了“AGI技术生态联盟”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f4016118532c4b6e98d9c02ade5aca71@2057308263_oswg4610315oswg2120oswg1312_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1" /></p><p class="img-desc">来源：腾讯</p><p>向量数据库可以说是大模型的数据“底层”，大模型若需要处理更大规模的数据，数据底座能容纳多少数据、运算速度有多快，决定了大模型的性能。</p><p>腾讯云数据库副总经理罗云表示：“从编程语言到自然语言，大模型重塑了算力调度方式。而AGI时代，也需要智能化的数据调度范式，AGI时代的数据平台，向量数据库是数据的中枢，腾讯云向量数据库希望成为这个数据中枢，通过企业级和智能化的能力助力各行各业一起走向AGI。”</p><p>腾讯云向量数据库从2019年开始内部研发，在今年7月份正式发布，目前已经过多次迭代升级。</p><p>在发布后，腾讯云向量数据库已经同时在腾讯内部和外部业务落地。据罗云介绍，目前腾讯云向量数据库已经累积服务了腾讯内部40多个业务，日请求量达1600亿次，服务了包括博世、销售易、搜狐、好未来、链家等在内的超过1000家外部客户。</p><p>例如，在SaaS领域，帮助企业客户快速构建私域知识库、智能客服系统；在电商行业，使用向量数据库来提升推荐、搜索、广告业务的推荐效果；在出行行业，使用向量数据库来加速自动驾驶模型训练，此外，在教育行业以及文创等行业也有广泛应用。</p><p>除了性能升级，如今大模型应用的火热需求，倒逼大模型底层的基础设施和生态快速迭代。腾讯云此次还推出了端到端的向量数据库解决方案，通过文本智能化分割、选择向量化模型、帮助客户建立索引，再经智能化排序实现端到端的数据接入体验。将端到端召回率提高30%，缩短数据接入AI的时间。</p><p>罗云在会后采访中表示，在以前，用户想要用大模型，很多时候只能分开来应用，大模型、数据库、数据处理都要客户自己来做、自己选型。但在端到端的解决方案出来后，用户只需要一个api，就可以一站式地完成从数据输入，接入AI大模型，并且通过自然语言快速查询。</p><p>而当下大模型发展速度一日千里，这对创业生态的影响也是深远的——大模型的每次迭代更新，可能都会替代掉不少创业机会。</p><p>在11月初的OpenAI首届开发者日上，OpenAI不仅发布了最新版本的GPT-4 Turbo大模型，推出了一款Retrieval检索工具，内置了最新的RAG（检索增强生成）技术，来帮助优化大模型输出的信息。用户在用了内嵌的检索工具后，就无需创建或者搜索向量——在很多使用场景里，对纯向量数据库的需求会减少。</p><p>但罗云表示，此举并不意味着会替代掉向量数据库的创业机会，重点更多在于能加速大模型+数据库的产品化。“OpenAI是业界顶尖公司，它选用的标准的方案也是向量数据库配合大模型，去完成端到端的解决方案，用户能一站式完成数据的检索再加上推理。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520382974582662</id>
            <title>腾讯悄悄投了一家创新药</title>
            <link>https://www.36kr.com/p/2520382974582662</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520382974582662</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 03:45:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 腾讯, 创新药企业, 云计算, AI
<br>
<br>
总结: 腾讯投资创新药企业，并利用自身的云计算和AI技术优势，建立自己的平台。腾讯在创新药领域进行投资，并且通过AI技术优化新药研发的效率和质量，降低研发成本。腾讯的投资和技术支持将为创新药企业带来更多的发展机遇和资源支持。 </div>
                        <hr>
                    
                    <p><strong>在投资创新药企业的同时，腾讯也开始发挥自身云计算、AI、数字技术等方面的优势，自建平台。</strong></p><p>腾讯又出手了，这次是一家创新药公司。&nbsp;</p><blockquote><p>近日，南京宁丹新药技术有限公司（简称“宁丹新药”）发生工商变更，新增广西腾讯创业投资有限公司为股东，同时公司注册资本由约1256.34万人民币增至约1326.14万人民币。&nbsp;</p></blockquote><p>官网显示，宁丹新药聚焦于中枢神经系统疾病新药开发领域，致力于为广大中枢神经系统疾病患者找到更好的疾病解决方案。&nbsp;</p><p>这并非腾讯在创新药领域的首次投资。过去几年，腾讯已经接连投资多家创新药企，并且投出AI药物研发独角兽——晶泰科技。&nbsp;</p><p>除了参股以外，腾讯还直接建立AI新药研发平台。其以自身云计算、AI 等信息技术为支点，在AI制药领域迅速入局。&nbsp;</p><h2><strong>01 腾讯投了家“先声系”药企</strong></h2><p>从注册时间来看，2020年成立的宁丹新药很年轻，但事实上，宁丹新药团队的创业历程已经有十余年了。&nbsp;</p><p>公司的核心团队，来自于上市公司先声药业的中枢神经系统项目组。&nbsp;</p><p>宁丹新药COO陈荣谈到，当年，先声药业鼓励内部创业，希望借由市场化机制，更好推动项目进展，于是在2012年，陈荣所在的团队出来创业，第一家创办的公司叫做江苏欧威医药，直到2020年，考虑到进一步发展，成立了宁丹新药。&nbsp;</p><p>据了解，宁丹新药的核心成员均在创新药行业浸润多年，CEO杨士豹，曾任先声药业项目总监，先后主持7个新药品种的研发，多个产品已上市销售；合伙人王鹏，曾任先声药业高级副总裁，药明康德副总裁等，在美国先灵葆雅新药发现部门担任资深研究员超过18年，曾主导或负责20多项创新药进入开发。&nbsp;</p><p>为什么会选择切入神经系统领域？&nbsp;</p><p>陈荣解释称，当初创业之时，最火的行业是肿瘤行业，他们预计肿瘤行业将成为未来很热、竞争激烈的研发领域；同时，宁丹新药的团队发现，伴随中国老龄化加剧，神经系统疾病患病率会越来越高，但临床用药品种稀缺，基本十几年没有什么新药。&nbsp;</p><p>于是，希望差异化研发的宁丹医药，没有跟随潮流选择肿瘤项目的立项，而是另辟蹊径，投入到神经系统用药的研发。&nbsp;</p><p>定位于中枢神经系统（CNS）疾病创新药探索者，宁丹新药旨在为CNS疾病患者提供更有效的治疗手段。目前已有七个新药进入研发管线，此外，公司还有CNS疾病药物更早期项目正在酝酿中。&nbsp;</p><p>在资本市场，宁丹医药颇受欢迎，动平衡资本、南京市产业发展基金、药源生物、招商健康等都曾参与过公司的早期投资。&nbsp;</p><p>腾讯入股后，将为宁丹新药带来更多的发展机遇和资源支持。&nbsp;</p><p>一方面，腾讯的资本注入将加速宁丹新药的研发进程，帮助公司提升药物研发实力；另一方面，腾讯也将借助平台优势、自身大数据等基础优势，为宁丹新药的商业化进程提供支持。&nbsp;</p><p>值得一提的是，宁丹新药的核心团队以及腾讯等投资人对公司的具体持股情况，暂时还没有对外披露。&nbsp;</p><h2><strong>02 腾讯切入创新药：左手投资，右手AI加持</strong></h2><p>对于宁丹新药的投资，并不是腾讯首次涉足创新药领域。&nbsp;</p><p>在此之前，腾讯已多次出手医疗赛道。早在2014年下半年，腾讯就开始涉足医疗领域的投资，直到近几年，腾讯更是直接把触角伸向了创新药领域。&nbsp;</p><p>2020年8月，美国旧金山人工智能加速药物筛选的初创公司Atomwise完成1.23亿美元B轮融资，腾讯作为老股东在本轮追加了投资。Atomwise的主要研究方向，就是利用AI来加速化合物筛选，帮助新药发掘。&nbsp;</p><p>2021年2月，腾讯完成了对华毅乐健的天使轮融资，公司一家致力于基因治疗创新药开发的生物技术公司。&nbsp;</p><p>2022年5月，圆因生物完成了超2.8亿元的A轮融资，公司专注于环状RNA技术在创新药物和创新疗法领域的研究和应用，在其一众投资方中，腾讯投资赫然在列。&nbsp;</p><p>2022年8月，腾讯投资北京丹序生物制药，持股3.18082%。据官网介绍，丹序生物是一家生物创新药研发生产企业，致力于抗体药物研究开发，主攻疾病领域包括传染病、自身免疫性疾病和肿瘤在内的各项适应症。&nbsp;</p><p>以腾讯为代表的互联网巨头切入医疗健康赛道，本质上而言都是其对于业务的延伸和补充，其切入的形式，则受限于各自独有的基因。&nbsp;</p><p>“腾讯做医疗，一开始是希望投资完全顶起来。”腾讯互联网+医疗业务负责人曾公开表示，一开始是投资，后来腾讯组建了自己的团队，原因在于医疗行业具有复杂性，纯粹靠投资的推动会比较困难。&nbsp;</p><p>在创新药领域更是如此。众所周知，新药研发工作风险大、周期长、成本高，是一个漫长而复杂的过程，需要大量的资金和人力资源投入，才有可能成功研发出一款新药。&nbsp;</p><p>于是，腾讯在投资创新药企业的同时，也开始发挥自身云计算、AI、数字技术等方面的优势，自建平台。&nbsp;</p><p>随着AI向各行各业逐渐深入地渗透，机器学习、自然语言处理、大数据等人工智能技术，也开始应用到制药领域各个环节，以此优化新药研发的效率及质量，降低研发成本。&nbsp;</p><p>利用自身积累的AI算法经验，腾讯快速入局，力求在AI制药的蓝海市场中分一杯羹。&nbsp;</p><p>2020世界人工智能大会云端峰会上，腾讯对外发布了首个AI驱动的药物研发平台——云深智药（iDrug），旨在用技术加快新药研发。&nbsp;</p><p>云深智药整合了腾讯AI Lab和腾讯云在前沿算法、优化数据库以及计算资源上的优势，致力于帮助用户大幅度减少寻找潜在活性化合物的时间和成本。&nbsp;</p><p>2022年4月，“云深智药”发布了业内首个药物AI大型分布外研究框架DrugOOD，包括数据集整理器和基准测试，提供大规模、全面的药物AI泛化数据集，覆盖AI药物辅助设计任务中发生分布偏移的各类场景。&nbsp;</p><p>进入2023年，AIGC行业爆火，腾讯健康顺势发布了医疗大模型，以及智能问答、家庭医生助手、数智医疗影像平台等多场景AI产品矩阵。&nbsp;</p><p>据悉，腾讯全新发布的全链路自研混元大模型，加入了涵盖285万医学实体、1250万医学关系，覆盖98%医学知识的医学知识图谱和医学文献。&nbsp;</p><p>目前，腾讯医疗大模型包括文案生成、智能问答、病历结构化和检索、影像报告和辅助诊断等场景大模型，可嵌入医疗环节全流程，在科室导诊、医生推荐、预问诊、医患对话、病历自动生成和智能院务客服等应用场景中，实现医疗服务水平和质量的提升。&nbsp;</p><p>拥有全面的AI生态的腾讯，其大模型极有可能最快在医疗场景中落地，一方面，腾讯在算力供给、数据存储、安全防护等数字基础设施方面的积累，将为医疗行业提供可靠的底层保障；另一方面，借助微信、腾讯会议等广泛的用户能力，人工智能应用可以广泛助力医疗普惠。&nbsp;</p><p>腾讯在医疗健康领域的起步并不晚，只不过在业务布局、战略调整上更为审慎，相信依托领先的自研产品实力，腾讯还将打造更多医疗行业实践的优秀样本。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/I0Ghy5z5_ASPcZefCCemKA" rel="noopener noreferrer nofollow" target="_blank">“猎云精选”（ID:lieyunjingxuan）</a>，作者：韩文静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>