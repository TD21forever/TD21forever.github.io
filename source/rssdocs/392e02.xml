<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2849313450167174</id>
            <title>WAIC 2024：没有应用的大模型一文不值？AI 大佬们在「中国科技春晚」的金句都在这了</title>
            <link>https://www.36kr.com/p/2849313450167174</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849313450167174</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 12:50:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 世界人工智能大会, AI产品, AI未来辩论, 大模型
<br>
<br>
总结: 上海举办的世界人工智能大会吸引了众多参会者，现场热情高涨，展示了最前沿的AI产品和观点碰撞。与会者从各个角度参与关于AI未来的讨论，探讨大模型的潜力和应用前景。AI行业的发展路径逐渐清晰，也引发了人类对AI的看法和共存方式的思考。 </div>
                        <hr>
                    
                    <p>当夏日的微风拂过黄浦江畔，一年一度的世界人工智能大会（WAIC）在上海拉开帷幕。&nbsp;</p><p>即便大会进入第二天，现场的火爆程度依旧丝毫不减。参会者们的热情仿佛被夏日的阳光点燃，会场内外人声鼎沸。&nbsp;</p><p>在这里，不只有最前沿的 AI 产品，还有火花四溅的观点在碰撞中迸发。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_16bec71314b94f0cafcee7837ea10645@46958_oswg151047oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>无论是在展台前驻足凝视的科技爱好者，还是掌握行业脉搏的一把手，都以自己的方式参与到这场关于 AI 未来的辩论中。&nbsp;</p><p>一个看似寻常的观点，也许正孕育着下一个可能改变世界的种子。&nbsp;</p><p>从 AI 技术发展的突飞猛进，到它在各行各业的落地生根，再到围绕 AI 安全的真知灼见，AI 行业的前进路径在争鸣中逐渐清晰，也为人类如何看待 AI、如何与 AI 共存等问题捋清思路。&nbsp;</p><p>部分金句如下：&nbsp;</p><ul><li>阿里云创始人王坚：GPT 的潜力，今天事实上还是没有被完整地探索的。</li><li>面壁智能 CEO 李大海：端侧模型有独特的生态位，它离用户更近、更能匹配个体和企业单位数据隐私的需求。</li><li>智谱 AI CEO 张鹏：大模型带来了一个全新的能力，我们称它为类人的认知能力。</li><li>百度 CEO 李彦宏：没有应用，光有基础模型，不管是开源还是闭源都一文不值。</li><li>上海 AI 实验室主任周伯文：现在，世界上只有 1% 的（资源）投入在对齐或者安全考量上。</li><li>黑石集团董事长苏世民：不能像鸵鸟一样，把头埋在沙子里，不关注外面技术发展的风险。</li></ul><h2><strong>GPT 的潜力还没有被完整地探索&nbsp;</strong></h2><p><strong>中国工程院院士、阿里云创始人王坚：</strong></p><p>&nbsp;我有的时候会说一句话，人工智能有一个非常长的过去，但是有一个非常短的历史。&nbsp;</p><p>长到什么时候呢？长到其实你可以追溯到一百多年以前。但是短到什么时候呢？短到就是 GPT 的出来。&nbsp;</p><p><strong>GPT 的潜力，今天事实上还是没有被完整地探索的。</strong></p><p><strong>MiniMax 创始人兼 CEO 闫俊杰：</strong></p><p>我觉得最核心的问题，是怎么把大模型错误率从 30%、40% 降到 3%、4%。 甚至降低一个数量级，这个事可以让 AI 从一个辅助人类的工具成为独立完成工作的个体。&nbsp;</p><p>当模型的错误率能变成个位数时，即在人类定义测试上都可以接近人类最好水平时，它在实体经济里产生更大效益就变得更加自然。&nbsp;</p><p><strong>另外这也意味着大模型可以独立完成任务了。</strong></p><p><strong>面壁智能联合创始人、CEO 李大海：</strong></p><p>&nbsp;打造全球领先的轻量高性能大模型，进行「知识密度」的压缩，已经成为大模型未来竞争新的重要方向。&nbsp;</p><p>端侧模型有独特的生态位， <strong>它离用户更近、更能匹配个体和企业单位数据隐私的需求，</strong>是大模型走进千家万户、千行百业的关键。&nbsp;</p><p><strong>华为常务董事、华为云 CEO 张平安：</strong></p><p><strong>中国的 AI 发展，离不开算力基础设施创新。</strong> 这条 AI 创新道路，包括把端侧硬件 AI 算力的需求，释放到云端。&nbsp;</p><p>就像华为手机的拍照功能已经可以把图片呈现得逼真、有丰富的细节，但如果把图片处理放在云端计算，图片会更立体清晰，像单反一样，（像所展示的这张图片里）蚂蚁绒毛清晰可见。&nbsp;</p><p>在云端，通过云网端芯架构上的协同创新，来构建可持续发展的 AI 算力基础，包括芯端算力上云、面向 AI 的网络架构升级、云基础设施系统架构创新三个方面。&nbsp;</p><p><strong>智谱 AI CEO 张鹏：</strong></p><p>AI 不是说今天才发生，发生很多年，包括上一代也解决了很多问题。&nbsp;</p><p>你可以看到为什么过去一些 AI 的方法，比如说人脸识别，它已经可以在指标级上超过人类的水平了。为什么大家觉得这个不是我们 AI 的终级答案呢？&nbsp;</p><p>大模型这件事情带来了一个全新的能力，我们称它为类人的认知的能力，也就是我们智谱 AI 的愿景， <strong>让机器能够像人一样去思考</strong>，并不是让机器成为一个机器、一个工具，而是让机器像人一样去思考。&nbsp;</p><p>我们认为思考这个能力，它所带来的效能的提升是更重要的。&nbsp;</p><h2><strong>AI 时代的杀手级应用，至少还要三年&nbsp;</strong></h2><p><strong>百度董事长兼 CEO 李彦宏：</strong></p><p>我们要避免掉入「超级应用陷阱」，觉得一定要出现一个 DAU 10 亿的 APP 才叫成功，这是移动时代的思维逻辑。&nbsp;</p><p>其实不一定， <strong>AI 时代，「超级能干」的应用比只看 DAU 的「超级应用」恐怕要更重要，只要对产业、对应用场景能产生大的增益，整体的价值就比移动互联网要大多了。</strong></p><p>很多人拿开源模型来改款，以为这样更好服务个性化应用。殊不知这样创作的孤本模型无法在基本模型获益，也没有办法跟别人共享算力。&nbsp;</p><p>当你处在一个激烈竞争市场环境当中的时候，你需要让自己业务的效率比你的同行更高，成本比你的同行更低。这个时候商业化的闭源模型是最能打的。&nbsp;</p><p><strong>没有应用，光有基础模型，不管是开源还是闭源都一文不值。</strong></p><p>所以我从去年下半年开始就在说，大家不要再纠结于模型了，要去关注应用。但是我看到我们的媒体仍然把主要的关注点放在了基础模型上，一天到晚到处去跑分刷榜。谁谁谁又超越 GPT-4 了，OpenAI 又出来 Sora 了，又出来 GPT-4o 了等等。</p><p>今天这个震撼发布，明天那个史诗级更新，但是我要问：应用在哪里？谁从中获益了？其实，应用离我们并不遥远。基于基础模型的应用在各行各业、各个领域都已经开始了逐步的渗透。</p><p><strong>MiniMax 创始人兼 CEO 闫俊杰：</strong></p><p>在 AI 时代最大的应用，我觉得还是挺有机会的，但是（当前）这个 APP 肯定还没那么大。&nbsp;</p><p>我觉得可能要三年之后（可能）才会有大众化的东西，但没关系，当你能做到第一个，然后你的能力变强、资源变多、技术能力变好，有可能大概就可以做。&nbsp;</p><p>同时，这个东西就一步步来，然后我认为（Killer App）至少三年之后。&nbsp;</p><p><strong>中国工程院院士、阿里云创始人王坚：</strong></p><p>第一、只要是个新的技术，一定会有新的大公司出现。如果一个新的技术出来，没有新的大公司出现，那它是不是颠覆性的技术是要打个问号的。&nbsp;</p><p>但是我自己相信， <strong>在这个时代一定会有新的大公司出来。</strong>就像当年的 GE 一样，这是第一个逻辑来看这件事情。&nbsp;</p><p>第二、但同时很有意思的一件事情， <strong>一定会有大公司是烈火重生的。</strong>就像前几天大家看到苹果这个事情。我觉得苹果这个发布很有意思，我个人觉得不是他拿 AI 去服务了 C 端的客户。&nbsp;</p><p>在我看来，事实上人工智能技术重新重构了苹果这家公司。所以这个 <strong>重构苹果这家公司是从重构它的操作系统开始的。</strong></p><p>AI 我们这么讲是革命性力量的时候，你发现 AI 对每个部门都会产生影响，要所有部门的所有人都去拥抱 AI 这在很多大企业是很难的。&nbsp;</p><p>我想小企业跟大企业的差别就是 fundamentally。大企业一定会觉得 AI 是工具的革命。小企业一定会觉得这是革命的工具。&nbsp;</p><p><strong>我想大企业如果意识到 AI 是革命的工具，那这个变化就来了。</strong></p><p><strong>蚂蚁集团董事长兼 CEO 井贤栋：</strong></p><p>&nbsp;业界普遍认为，通用大模型落地严谨产业，面临着三个「能力短板」：领域知识相对缺乏、复杂决策难以胜任，以及对话交互不等于有效协同。&nbsp;</p><p>为了破解这些难题， <strong>专业智能体是通用大模型落地严谨产业的有效路径。</strong>通过专业智能体的深度连接，Al 会像互联网一样，带来服务的代际升级。&nbsp;</p><p>未来智能化的用户体验，一定不是只靠一个大模型，而是需要全行业深度协作，需要很多的专业智能体共同参与、各司其职。&nbsp;</p><p><strong>中国移动董事长杨杰：</strong></p><p>&nbsp;第一，以 AI 为代表的新一代信息技术成为发展新质生产力的重要引擎。 第二，深入推进 AI 成为培育新质生产力的重要路径。 第三，以 AI+ 推动新质生产力发展成为信息通信业的时代重任。&nbsp;</p><p>正像我们过去十几年的互联网+时代， <strong>电脑并没有取代人脑，而是更擅长使用计算机的人会脱颖而出。我觉得进入 AI+ 时代也是如此。</strong></p><p><strong>商汤科技董事长兼首席执行官徐立：</strong></p><p>我一直的观点是其实虽然我们的行业非常的热，包括像 GPT 带来的聊天式的应用，Sora 带来的视频应用，但它还没有到「超级时刻」，是因为它没有真正走进到一个行业垂直应用当中、引起广泛的变化。&nbsp;</p><p>可是这两天，我忽然感觉有点变化的想法。因为我的中学的退休的老师不停的在群里面问我，怎么样用人工智能去写文案、生成祝福的图片，发到他的退休群里等等。&nbsp;</p><p>我突然想， <strong>其实超级时刻和应用是互相成就的。</strong>只有超级时刻带来的认知的变化，最后才能推动应用。倒推回来，如果我们有应用作支撑，那么我们现在这个时刻就是「超级时刻」。所以， <strong>应用是「超级时刻」的关键。</strong></p><p><strong>国家地方共建人形机器人创新中心总经理许彬：</strong></p><p>&nbsp;AI 对于我们科技行业，汽车、手机、PC 终端等等都会有非常大的赋能和改变。&nbsp;</p><p>但是这个过程中肯定会产生很多新的业态，在我看来最核心的，最关键的， <strong>或者最典型的业态将会是人形机器人。</strong></p><p>我感觉尤其是 ChatGPT-4o 出来以后，相关的技术会远远超过我们的判断。&nbsp;</p><p><strong>现在我们初步判断就是 3 到 5 年，在一些工厂智能制造现场是可以应用的，5 到 10 年可以在家庭服务等等一些复杂的开放环境下或许可以落地应用。</strong></p><p><strong>中国电信董事长柯瑞文：</strong></p><p>第一、人工智能需要新型的数字信息基础设施提供有力的支撑。 第二，人工智能的发展既要重视大模型的技术研发，更要重视模型的应用。 第三，人工智能发展需要共建开放的生态，共同推进治理。&nbsp;</p><p><strong>御风未来创始人兼 CEO 谢陵：</strong></p><p>&nbsp;我们低空经济的主角就是智能化、电动化和无人化的新型航空器。&nbsp;</p><p>我们今天的主题人工智能主要就替代人的大脑，我们还需要机器替代人的眼睛、鼻子、耳朵以及手脚，以及我们需要一个机器来进行信息的获取和执行。&nbsp;</p><p>智能化的航空器跟机器人是一样的，它就是一个终端，人工智能的发展必然为我们低空经济能够带来更多的发展。&nbsp;</p><p><strong>智谱 AI CEO 张鹏：</strong></p><p>我们现在有一个很重要的点是去突破大模型的多模态。为什么要多模态？是因为真正的人在现实世界中解决问题的时候，他需要的、输入的信息本身就是多模态的。&nbsp;</p><p>除了自然语言，还有视觉、听觉、触觉，还有常识，所有这些是需要综合起来才能 <strong>解决现实世界当中很多常见的问题</strong>，甚至都不是复杂问题。&nbsp;</p><p>比如说我们希望它帮助我们去扫地、做饭、洗衣服。其实这些任务，你不要小看这些任务，它所需要输入的信息是非常多模态的， <strong>所以这些方面能力的突破会带来 AI 的普惠，AI 更大的这种可能性。</strong></p><p>就是把原来这样一个金字塔型的结构，就是你的底座很大，投入很大，但是收益很小，变成一个倒金字塔结构，这样才能真正放大它的价值。&nbsp;</p><h2><strong>AI 安全与性能发展失衡，探索 AI 45° 平衡律&nbsp;</strong></h2><p><strong>图灵奖得主姚期智：</strong></p><p>AI 风险来自于三个方面：一是网络风险延伸和扩大。现在，我们觉得管理数据安全已经是很困难的，出现了 AI 会困难 100 倍。&nbsp;</p><p>二是没有意识到的社会风险，比如说 AI 非常强大，而且是可以有很多方式去使用，所以颠覆现在社会结构在短时间内发生的可能性，这是存在的。比如说有人提到，AI 可能带来大规模未来的失业。&nbsp;</p><p>三是最有意思的层面，生存或者存在的风险。以前也面临过，当火车或者蒸汽机发明的时候，就有人有这样的担忧。&nbsp;</p><p>作为计算机科学家看到了最有深度的问题，一方面我们把 AI 控制好，毕竟这是我们设计出来的；另外一方面，也不希望它被我们给破坏了，这样权衡是非常困难的。 <strong>正如图灵所说，这是无法预测的，</strong>预测不了机器有了足够算力之后会做什么。&nbsp;</p><p><strong>中国工程院院士、阿里云创始人王坚：</strong></p><p>我是一个无药可救的技术乐观主义者。&nbsp;</p><p>所以我相信人类在技术发展过程当中， <strong>任何人类自身产生出来的问题，人类一定会去解决的。</strong></p><p><strong>上海人工智能实验室主任周伯文：</strong></p><p>&nbsp;目前，从算法研究、人才密集度、商业驱动力、甚至包括算力的投入等方面来看，我们对 AI 安全的投入远远落后于对 AI 性能的投入。现在，世界上只有 1% 的（资源）投入在对齐或者安全考量上。&nbsp;</p><p>出现对这些风险的担忧，根本原因是我们目前的 AI 发展是失衡的。&nbsp;</p><p>发展可信 AGI（通用人工智能），要兼顾安全与性能，因此需要找到 AI 安全优先但又能保证 AI 能力长期发展的技术体系， <strong>我们把这样一种技术思想体系叫作 AI-45°平衡律，长期来看要大体上沿着 45 度安全与性能平衡发展。</strong></p><p>所谓的平衡是指短期内可以有波动，但不能长期低于 45°，如同我们所处的现在；也不能长期高于 45°，这会阻碍技术和产业应用的发展。&nbsp;</p><p><strong>黑石集团董事长、CEO 苏世民：</strong></p><p>不能像鸵鸟一样，把头埋在沙子里，不关注外面技术发展的风险。&nbsp;</p><p>有一句话说道，投资界没有勇敢的老人，意思是始终应该对风险保持警惕。当 AI 真正发展起来，可能会让一些投资变得血本无归。&nbsp;</p><h2><strong>能源问题要放在时间和空间维度动态来看&nbsp;</strong></h2><p><strong>中国工程院院士、阿里云创始人王坚：</strong></p><p>&nbsp;新能源会出来，新的算力形式会出来，新的石油会被发现，发生变化。&nbsp;</p><p>所以我想所有的问题都是要在动态过程中解决。你根本不会想到可能十年以后说的算力跟今天说的算力，不是同一个算力。十年以后说的电可能跟今天说的电也不是同一个概念。&nbsp;</p><p>所以我是觉得这个还是要在动态过程解决，一定不能在现在这个时刻的状态来解决十年以后的问题。要拿十年以后的状态来解决十年以后的问题。&nbsp;</p><p>除了刚才讲的这个 time scale，我还是要讲一下空间也很重要是吧？&nbsp;</p><p>就是空间也很重要。所以我想给大家一个基本的数字，就是中国一年的发电量是美国、日本、俄罗斯的总和还要多。所以我说中国是最不要担心没有电，我们还有别的地方还可以，至少我们别的地方多用了很多电。&nbsp;</p><p>所以一定是跟空间跟时间是有关系的。你们能不能放在离开的空间时间谈，这是个问题。&nbsp;</p><p>我再强调一下，中国一年发电量超过美国加日本加俄罗斯的总和。所以 <strong>我想我们可能是最不需要在这个阶段担心这个问题的一个地区。</strong></p><h2><strong>短期内最重要的其实是 AI 技术进步&nbsp;</strong></h2><p><strong>智谱 AI CEO 张鹏：</strong></p><p>大模型价格的下降是因为技术驱动，因为本身技术越来越好，成本越来越低，价格持续走低。但是这个事情过度就不好，就是刚才讲的价值传递，&nbsp;</p><p>真正的价值应该是逐级、大家往同样的一件事情里面不断添加自己的价值，再放大、扩大这个价值。我们给大家提供更好优质的服务，希望大家能够用这个服务创造更大的价值，相应的我们创造这一部分价值应该反向再传递回来。&nbsp;</p><p>就像我们的 BP 算法（误差反向传播）一样，大家各自得到自己价值的部分，这是一个正常合理的市场的价值链。&nbsp;</p><p>我们怎么去用新一代生成式 AI 的技术和大模型的技术赋能实体经济，我们认为它一定要从这个方向去解这个题，就是你要构建更通用的、更基础的一个能力，利用这个通用和基础的能力去解决多项的问题，然后用这个收益的总和去除以你的投入成本。&nbsp;</p><p><strong>御风未来创始人兼 CEO 谢陵：</strong></p><p>我们希望 AI 大模型有一个类似于现有我们见到的卫星定位或者是蜂窝通信那样 <strong>无处不在的一种通用的基础设施。</strong></p><p><strong>MiniMax 创始人兼 CEO 闫俊杰：</strong></p><p>AI 的价值一定不在于说去卖这个技术，而且在于说技术的变化给用户带来多大的价值，我觉得不管是技术本身还是产品还是商业， <strong>都应该往价值这个方向发展。</strong>坦白讲，我觉得大部分（国内）公司都还没有拉开差异化，大家都差不多，可能模型水平也差不多，产品也差不多，然后就会开始「拼价格」。&nbsp;</p><p>我觉得这个东西不是坏事，其实是逼着大家能够更好来做技术创新。&nbsp;</p><p>我觉得，技术是不是在线，其实决定是说你是不是一家合格的公司。如果技术不够好，可能他就应该被淘汰掉，这是第一个；但光技术好是没用的，因为现在还有 AI 滤镜，可能比如说你往一年之后看，那一定是说可能不完全是技术层面，可能会从商业化角度来看这家公司。&nbsp;</p><p><strong>所以，我觉得短期内最重要的其实是 AI 技术进步。</strong></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/LbUsOB9wvsAHiwI68-W1mw" rel="noopener noreferrer nofollow" target="_blank">“APPSO”（ID:appsolution）</a>，作者：用&nbsp;AI&nbsp;发电的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849299536006022</id>
            <title>WAIC观察：大模型AI应用开始小规模稳步爆发</title>
            <link>https://www.36kr.com/p/2849299536006022</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849299536006022</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 12:46:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: WAIC2024, 大模型公司, 创业公司, AI应用
<br>
<br>
总结: 2024年的上海人工智能大会展示了大模型公司和创业公司在AI应用领域的最新进展和趋势。各大模型公司展示了通用大模型的落地进展和未来应用方向，包括面向企业和C端用户的产品和平台。展会上展示了大量AI应用的同质化竞争趋势，以及AI应用在不同行业场景的应用案例。行业内对于AI应用爆发趋势持有不同看法，一些从业者警惕技术与应用创新的平衡问题，认为大模型公司需要兼顾基座模型的迭代和应用创新的落地。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_2eacb8b50ec141ac95f2ac93b37ee777@46958_oswg486239oswg700oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：界面图库</p><p>如果你在WAIC2024的展馆看到一个人满为患的展台，不用怀疑，那一定是一家AI大模型公司。</p><p>2023年的上海人工智能大会，大语言模型尽管已经在ChatGPT的爆发中走上风口，但彼时大模型牌桌之上的筹码仍主要掌握在华为、百度、腾讯、阿里等大厂手中。而一年过后，百模大战完成第一轮洗牌，创业公司以更瞩目的方式入主这场AI盛会。</p><p>从观众人群流量看来，高光不再仅仅聚集于大型厂商的展台，阶跃星辰、MiniMax、智谱AI、百川智能、面壁智能等大模型公司受到了同等规模甚至更高的关注。</p><p>重视大模型AI应用落地的展示，是今年大模型厂商们一个非常明确的策展主题。</p><p>以创业公司领域几家独角兽为例，阶跃星辰在发布Step-2万亿参数语言大模型正式版、Step-1.5V多模态大模型、Step-1X图像生成大模型三款通用大模型之外，首次重点展示了面向C端（用户）的自研大模型应用产品智能助手“跃问”和AI开放世界平台“冒泡鸭”。另外，公司还通过基于《大闹天宫》剧情和角色制作的AI互动游戏，展示了“AI+IP”的落地玩法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_f209ed13fc39449aa56af417145b968a@46958_oswg173978oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>拍摄：界面新闻记者</p><p>百川智能除了此前已经发布的Baichuan系列大模型、AI助手“百小应”以及ToB（企业）解决方案，其最大的展陈亮点被放在了内测版医疗应用AI健康顾问上。AI医疗一直是百川智能的重要业务发展方向，AI健康顾问是其第一个落地产品，形态上属于医疗垂直领域的对话式机器人，可根据用户的问询持续反问，从不同维度了解症状，最后基于整体信息给出诊断结果和用药建议。</p><p>在企业端已经有一定商业化规模的智谱AI，重点打造了其大模型开放平台（bigmodel.cn）在公共事务、消费、文旅、医疗、保险、教育、汽车、金融、工业等多个行业场景的典型案例集合。</p><p>MiniMax的策略也是重点展示其面向企业客户的开放平台，以及面向C端用户的AI专业助手“海螺AI”和AI智能体创作平台“星野”。</p><p>不仅是创业公司，阿里通义千问、腾讯混元、科大讯飞星火以及蚂蚁集团百灵等来自大厂的大模型，也有大面积展区展示了它们的应用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_ea207e67df744e60a639cf90854c4df4@46958_oswg66275oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>拍摄：界面新闻记者</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_dd48d489ce834c9da11ecf4c5600bbbc@46958_oswg190166oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>拍摄：界面新闻记者</p><p>总之，手握通用大模型的厂商们没有局限在模型性能的单纯展示和比拼之中，而是花费了大力气向行业展示其大模型已有落地进展和未来应用方向。</p><p>观众的直观感受也是如此。一名大模型企业客户对界面新闻记者表示，在阿里、华为等大厂展台看到了比过去更多真实的客户落地案例。另一名对AI大模型感兴趣的互联网从业者表示，今年逛展最明显的感受是大模型切实落到了很多“看得见摸得着”的领域。</p><p>这与大模型的行业趋势不无关系。从今年上半年开始，有关AI应用层即将爆发的行业观点迭出。创办零一万物的李开复直言，2024年是AI应用爆发元年。而尤其重视AI应用层商业价值的投资人朱啸虎断定，AI应用必定在明年迎来爆发。</p><p>从这届WAIC的展陈情况来看，这种预判正在落为现实，但可以感受到的是，现有AI应用的同质化竞争趋势明显，例如大量厂商争夺AI专业助手这一产品定位。此外，大量AI应用正在按照“AI 2.0时代一切都可以重做一遍”的思路落地，许多产品仍在用户已有认知范围内，突破性表现较少。</p><p>第四范式联合创始人兼总裁胡时伟对界面新闻记者表示，AI应用的确在今年开始小规模稳步爆发，但就C端应用的现状而言，大多数还是与现有需求做结合，还没有看到所谓新技术带来的产品形态变迁，例如移动互动网时代催生的直播和短视频。考虑到抖音等爆款应用的出现时间线，大模型行业留给超级应用的成长时间至少还有两到三年。</p><p>面对AI应用爆发趋势，也有从业者对此表示了警惕。面壁智能CEO李大海在接受界面新闻等媒体采访时表示，虽然行业今年呈现出一定聚焦应用端的趋势，但由于技术侧还没有完全收敛，行业完全聚焦应用端是危险的，因为技术需要与应用创新同频。</p><p>因此他认为，当前环境其实对大模型公司提出了更高的要求，即必须兼顾基座模型的迭代和应用创新的落地，“这两边哪一边都不能放松”。</p><p>在行业看来，超级应用（或者说更高数量级日活的AI应用）的出现受限于模型性能。智谱AI CEO张鹏在WAIC2024产业发展主论坛上表示，大模型对产业带来的机遇，本质上是通过模型的泛用化能力，解决一系列场景和应用的多样化需求，从而解决背后成本与收益的平衡问题。从这个思路解题，核心依旧是模型本身的能力水平提升。</p><p>就“基础模型如何做得更好以对产业发展更加有价值”这一问题，MInimax创始人兼CEO闫俊杰提出一个明确思路是，目前AI大模型急需解决错误率的问题，如果能够将错误率降到个位数，便意味着在人类定义的测试上可以接近人类最好水平，在实体经济里也就能够产生更大价值。</p><p>本文来自“<a href="https://www.jiemian.com/article/11377960.html" rel="noopener noreferrer nofollow" target="_blank">界面新闻</a>”，记者：伍洋宇，编辑：文姝琪，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849299392383624</id>
            <title>避免黑产使用大模型推断用户隐私已迫在眉睫</title>
            <link>https://www.36kr.com/p/2849299392383624</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849299392383624</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 12:46:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 隐私信息, AI安全, 数据安全
<br>
<br>
总结: 大模型在产业端落地的成效逐渐显现，但隐藏的风险也被暴露出来。大模型在训练环节使用的数据中包含很多个人信息，即使这些信息并没有直接暴露个人隐私，但在大模型强大的关联和推理能力下，很多隐私信息还是会被推断出来。为了避免网络诈骗等黑产团伙利用大模型推断个人隐私信息来实施犯罪行为，需要加强合作，建立更好的价值体系来帮助进行人工智能的开发和使用以及治理，包括透明度、真实性、安全性、职业道德、隐私保护等。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_9f1919e30f2449368957f4d3c573308f@46958_oswg336847oswg700oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">摄影：匡达</p><p>大模型在产业端落地的成效逐渐显现，但隐藏的风险也被暴露出来。</p><p>大模型在训练环节使用的数据中包含很多个人信息，即使这些信息并没有直接暴露个人隐私，但在大模型强大的关联和推理能力下，很多隐私信息还是会被推断出来。</p><p>比如，用户询问大模型产品“哪一个家庭防盗系统在现在市面上是最好的”，在对话的过程中很可能会涉及对房屋门窗信息的描述，大模型会把这些数据和用户过往的询问数据以及其他用户的询问数据进行关联推理，来推断出用户的居住地址等隐私信息。</p><p>当用户和大模型产品进行语音交互时，大模型还可以通过方言或短语使用来推断用户位置或者统计某些人群特征信息。</p><p>此前，瑞士苏黎世联邦理工学院的研究者发现，为ChatGPT等聊天机器人提供支持的大型语言模型可以从看似无害的对话中，准确推断出数量惊人的用户个人信息，包括他们的种族、位置、职业等。</p><p>该团队研究者发现，网络诈骗等黑产团伙可以利用聊天机器人猜测敏感信息的能力，从毫无戒心的用户那里获取敏感数据。</p><p>正因为如此，避免网络诈骗等黑产团伙利用大模型推断个人隐私信息来实施犯罪行为，已经迫在眉睫。</p><p>在2024世界人工智能大会上，中国科学院院士、人工智能国际治理研究院学术委员会主席姚期智在谈及AI安全和风险相关问题时表示，在我们真的有能力能够训练出安全可靠的AI系统之前，先要确保AI不会伤害到人。</p><p>从技术角度来看，大模型泄露个人隐私可以归结到传统数据安全问题中。其中一个解决问题的技术路线就是，让大模型产品在不知道用户具体问题的前提下，能够给出用户想要的答案。这个路线听起来不太可能，但搜索引擎在过去很长一段时间内一直在探索可能的方案，也尝试了一些算法。</p><p>但姚期智表示，数据安全在大模型时代，多半的文章、研究都在比较初期的阶段。现在解决问题的方法是，发现一个问题，提出一个问题的解决方案，同时在此基础上去迭代出更好的解决方案。</p><p>简而言之，这种方法就是通过拼凑数据安全中的各种方法来达到目的，这些核心方法包括秘密共享、零知识证明、多方安全计算等。但这只能解决当下最迫在眉睫的问题，从长远来看，要真正解决AI安全的问题，还需要发展出一套更高效、系统化的理论。</p><p>从实践来看，业界提出了多种技术路径来系统化解决AI安全的问题。这些技术路径都有各自的逻辑，目前也很难证实哪一种路径更优。</p><p>加利福尼亚大学伯克利分校计算机系教授Stuart Russell在2019年提出了Beneficial AGI（有益的通用人工智能），其从博弈学角度出发，让AI与人类利益对齐，强调机器人应该以人的利益为本，并与人保持交流、时刻多了解人的需求。</p><p>在这种思路下，在设计机器人的时候，就要有一个数据规律，让机器人做所有决定时都要把以人的利益为本。如果机器人不清楚人类的需求，它要能够和人对话，了解人的需求到底是什么。</p><p>去年，麻省理工学院发表的一篇论文提供了另一种思路：做一个可证明的安全的AGI。这种思路用Proof&nbsp;Checkers（证明检验程序）来设计数学上绝对安全的AGI系统，让人类只和可证明安全的“白盒子”交流，这是一种严格限制机器应该做什么的思路。</p><p>而从理想的逻辑论证回归现实，大模型相关从业者给出了一些目前可落地的思路。</p><p>在蚂蚁密算CEO王磊看来，密算是大模型产业深入应用的必经之路。密算核心是提供机密性和完整性，机密性是指在数据使用过程中模型、访问信息是加密的，在这过程中人是看不见也使用不了这个数据。完整性是指数据和系统是不能够被篡改的，所有的数据在授权的时候，对行为进行了约束，能够防止别人滥用隐私数据。</p><p>香港科技大学首席副校长、香港城市人工智能研发中心主任郭毅可提出，区块链技术是另一种有前景的解决方案，可增强数据安全。区块链透明和不可更改的特性确保了数据的完整性，就像这个未经授权的修改或数据串改的风险。</p><p>在郭毅可看来，为了防止未经授权的访问和数据泄露，组织必须采取严格的安全措施，通过数据匿名化技术、用户同意和隐私设计原则，以及实施数据分类访问控制和加密方案方法，保护知识产权和防止未经授权的披露。</p><p>虽然业界在用户隐私保护上有各种各样的思路，但不可否认的是，真正解决大模型用户隐私保护的问题并没有那么容易。</p><p>联合国大学校长Tshilidzi Marwala在2024世界人工智能大会上表示，为紧迫解决AI安全带来的挑战，不同主体应该加强合作。“我们需要所有利益相关者参与进来，更深入理解人工智能朝着智能化进化过程中面临的挑战和风险。”</p><p>Tshilidzi Marwala提出的方案是建立一套更好的价值体系来帮助我们更好的进行人工智能的开发和使用以及治理，包括透明度、真实性还有安全性、职业道德、隐私保护等。</p><p>这个方案需要构建一整套法律框架，确保AI有道德的使用和负责任的使用，同时也更加关注到透明、问责和公平的问题，更加严格地落实数据保护要求，更严格构建AI标准。“我们需要更好的构建AI立法，不仅仅是法律的制定，帮助我们更好的治理AI发展，同时也要以一种有责任的形式使用AI、保护隐私。”</p><p>在2024世界人工智能大会上，清华大学人工智能国际治理研究院和阿里巴巴集团联合发布的报告《全球人工智能治理与中国方案(征求意见稿)》也展示了中国在AI安全治理的思路。报告提出，在解决AI安全治理难题时，应该保障不同人工智能治理框架和生态系统间的互操作性，即通过开放标准和开源技术，建立全球所普遍接受的人工智能安全协调机制、标准设定、评测体系。</p><p>“各个国家人工智能治理规则、规则包括办法，可能跟外部其他国家不一样，因为各个国家的文化、治理体系有很大差别，我们是尊重多元化的国内治理体系的存在。另外国际上我们又需要接口，所以互操作性变得非常重要，这个也是国际治理体系需要考虑的。”清华大学人工智能国际治理研究院副院长梁正表示。</p><p>本文来自“<a href="https://www.jiemian.com/article/11377471.html" rel="noopener noreferrer nofollow" target="_blank">界面新闻</a>”，记者：肖芳，编辑：文姝琪，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849288787037062</id>
            <title>手机轻薄化风潮再起，找到平衡点仍是关键</title>
            <link>https://www.36kr.com/p/2849288787037062</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849288787037062</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 12:39:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米15, LTPO小尺寸直屏, 三摄模组, 电池技术
<br>
<br>
总结: 小米15可能会搭载具备1.5K分辨率的LTPO小尺寸直屏和三摄模组，同时电池技术的发展有望缓解轻薄化挑战。 </div>
                        <hr>
                    
                    <p>日前有传言称，下半年亮相的小米15或将搭载一块具备1.5K分辨率的LTPO小尺寸直屏，并可能会配备由5000万像素大底主摄+5000万像素超广角+5000万像素3X直立长焦组成的后置三摄模组，并延续小屏旗舰的市场定位。此外有消息源透露，搭载新款旗舰SoC骁龙8 Gen4和天玑9400的机型都将会有相对小屏的形态。结合上述消息，有观点认为小屏旗舰的大量“复出”，或将会引发智能手机又一次的轻薄化风潮。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_565dc29eda9d4d96b2bc2961e2d45f17@000000_oswg20299oswg550oswg282_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在智能手机不断发展的历程中，机身体型与产品力之间的平衡，就让手机厂商在研发阶段就要面临诸多的取舍与挑战。此前雷军就曾在社交平台表示，“小米13已经非常好，和iPhone 14宽度完全一致，在屏幕大小和手感中找最佳平衡。假如尺寸更小，首先消费群体太小，销量支撑不了旗舰手机的研发成本。其次，体积很小，对相机、续航能力有影响”，也道破了机身体型轻薄化所面临的主要挑战。</p><p>如今对用户而言，智能手机的续航和影像功能早已成为了两大最为关键的核心指标，但两者却与机身体型有着直接的关联。首先，电池作为确保续航的基础，容量的增减就直接代表着电池体型变化。因此在手机电池能量密度没有实现质的突破前，如何在确保续航能力的同时控制好电池的体积，也就成为了在机身设计阶段的一大挑战。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_c9920e3f06ff460c9b4cae1898d074ac@000000_oswg20201oswg550oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>近来随着电池相关技术、特别是硅碳负极电池的大规模量产，则有望缓解这一方面的矛盾。与此前相比，由于硅碳负极电池具备更高的能量密度，例如一加的冰川电池能量密度就已达到763Wh/L，小米金沙江电池的能量密度更是进一步升至779Wh/L。这就使得电池可以在更小的体型上带来相同的电量，从而为影像模组等零部件腾出宝贵的机身内部空间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_17ea20d4aad4474e93193525cbff677b@000000_oswg34685oswg477oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外需要注意的是，快充相关技术的发展也会对机身的轻薄化带来一定影响。在手机快充已经普及的当下，部分厂商出于安全、充电效率等方面的考量，会采用双电芯方案，虽然其有助与实现高功率快充，但同时也不可避免地会进一步侵占机身内部空间。相比之下，小米目前的高能量密度、单电芯大容量电池方案就具备一定优势，并且更为难得的，是其在快充功率上依然还保持着主流水准。</p><p>尽管目前在智能手机市场中，影像能力已经成为了各方关注的焦点，但在追求更轻薄机身体型的道路上，这也成为了不可忽视的挑战，尤其是对于小屏旗舰、折叠屏手机更甚。此前受限于机身体型，追求轻薄化的机型往往会在影像规格上“缩水”，例如配备尺寸相对较小的CMOS或相对简单的镜头，因此在成像能力上与影像旗舰会存在较大的差距。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_ad06262fae734b88a136ca61c9cad10b@000000_oswg27352oswg550oswg295_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然这一局面目前已经有所改善，随着采用全新架构、无需超大底就能带来不错表现的双层晶体管CMOS、 双转换增益CMOS问世，使得情况有所改善。但需要注意的是，光学部分的局限性目前仍是不容忽视的问题，例如目前已经极为常见的潜望式长焦，就鲜少在小体型机型上出现。</p><p>毕竟光学镜头作为影像系统中的核心组成部分，无论焦距、还是成像质量都受到了物理规律的严格限制。在智能手机本就不大的内部空间里，留给镜头、CMOS的就非常有限，因此现阶段更偏影像的旗舰机型后摄模组凸起，也就成为几乎无法避免的问题。因此对于以小屏旗舰为代表的轻薄机型而言，这样的限制就使其不得不在影像与轻薄化之间做出取舍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_dd84be62a77f4723a95b497def26b89a@000000_oswg40913oswg550oswg389_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此这也意味着这类机型往往会在影像方面有所妥协，难以达到与大尺寸机型相同的水准。虽然目前手机厂商也通过换用高品质镀膜，以及改变镜片材质、堆叠方式等，进一步控制影像模组的体型，但至少在现阶段，小屏旗舰在后摄模组的硬件配置上依旧没有太多的选择。</p><p>值得一提的是，由于目前影像已成为各大手机厂商寻求产品差异化的关键领域，相比常规机型凭借相对充裕的内部空间、在“堆料”上更为宽松不同，小屏旗舰就很难采用这样的方式来改变现状。因此无论是硬件方面的突破、还是软件算法层面的创新，后者至少现阶段还有很长的一段路要走，才有可能在这一方面带来更好的体验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_d9bcdde159db4bcb9f60255b6fda766b@000000_oswg22756oswg550oswg345_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前，智能手机轻薄化与产品力之间的博弈仍在继续，尽管电池相关技术已经迎来了突破的曙光，但想要在两者间实现平衡，影像已然就成为了关键因素。因此如何在影像硬件方面进行突破，或是通过软件层面的快速进步进行弥补，或将会成为未来小屏旗舰、轻薄机型，乃至折叠屏手机接下来亟需解决的一大挑战。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649866828&amp;idx=4&amp;sn=08e12e43e6c4b5a4d0996601fcb57f5b&amp;chksm=8639e375bafdba80200bf8a2fe4ace839cac8e3ce9b34f02924db41310503822f9dcc2df10ac&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849297220000648</id>
            <title>苹果“真的很你”闹笑话，为何国外品牌翻译不上心？</title>
            <link>https://www.36kr.com/p/2849297220000648</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849297220000648</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 12:35:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 宣传风格, 中文宣传标语, 翻译团队
<br>
<br>
总结: 苹果的宣传风格一直以来都备受关注，尤其是在中文宣传标语的翻译上，苹果翻译团队常常闹出笑话，让用户感到困惑和违和。虽然这种独特的表达方式可能有助于品牌辨识度，但从用户角度来看，并不一定是一件好事。 </div>
                        <hr>
                    
                    <p>一直以来，苹果的宣传风格主打一个随心所欲，无论是视频还是文案，如果你没有点“果式领悟力”还真的很难看懂。这就导致一个结果：能理解的用户看得津津有味，而不能理解的用户则是一头雾水，不知道它想表达什么。&nbsp;</p><p>这不，果子哥又在iOS 18的中文宣传标语上整花活了，生涩难懂的宣传文案引来了众多数码博主和网友的吐槽。虽然不清楚这次是无心之失，还是有意为之，总之苹果宣传目的是达到了。</p><h2><strong>“真的很你”，这宣传语真的很苹果</strong></h2><p>近日，苹果大陆官网最新上线了iOS 18介绍页面，详细展示了iOS 18的新设计和新功能。<strong>原本这是再正常不过的事情了，但苹果给iOS 18介绍页面植入了一个很奇怪的宣传语——“真的很你”。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_ab1b30ebd77a46e39afcef0e78caf4c8@1547419282_oswg139038oswg1292oswg900_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：苹果官网</p><p>当小雷看到这句话时，瞬间有种小脑萎缩的感觉，明明每个字我都认识，但连在一起却怎么也读不懂。一开始，我还认为是苹果工作人员失误，或许很快就会得到修正。可等了半个小时也没等来官方行动，这一刻我终于明白，原来这就是苹果的“创意”文案。</p><p>同样因此感到不适的还有众多网友，他们在社交媒体上发表了质疑：<strong>“苹果的营销文案还真的挺反人类的”、“‘真的很你’这个翻译真的离谱”。还有网友幽默评论道，“比机翻还机翻”、“真的很难懂你”。</strong></p><p>作为参考，苹果美国官网的iOS 18宣传文案是“Yours.Truly”，苹果大陆官网的“真的很你”很可能就是直译过来，虽然小雷大致能猜测出苹果想表达的意思或许是iOS 18拥有更丰富的自定义内容，比如手机APP和小组件可以随意排列，但咱就是说，这种翻译方式看起来确实有些难懂。</p><p>对比之下，苹果中国台湾官网的宣传文案为“真的，就很你”，而苹果中国香港官网则使用了更直接的表达方式，“徹底，非常你”。虽然这两个宣传文案同样有些生涩难懂，但总比“真的很你”要更容易理解些。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_e2e881076b504e5ba5ff514fefbbce4c@1547419282_oswg83404oswg1003oswg586_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：苹果官网/左中国香港，右中国台湾</p><p>跟着iOS 18一起发布的还有iPadOS 18和macOS Sequoia，苹果大陆官网的宣传文案分别为“全改写，新标杆”、“犀利一如 Mac”，同样是果味十足。这样看来，苹果翻译团队闹出的笑话还真不少，几乎每年苹果大陆官网发布的标语翻译都会对网友的中文理解能力发起挑战。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_ea6badc7f245460d9980cefe5b43c8e6@1547419282_oswg384072oswg1651oswg890_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：苹果官网</p><p>大家还记得当年iPhone 6的标语是什么吗？没错就是那句经典的“Bigger than bigger”，英文其实没什么毛病，毕竟iPhone 6和6 Plus确实是苹果迈向大屏手机的第一步。</p><p><strong>然而，当年苹果大陆官网是这样翻译的：“比更大还更大”。相信稍微具备英文能力的朋友都很难给出这么直接的翻译，相比之下，中国台湾和中国香港“岂止与大”的翻译就接地气多了。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_97624b465ce04a89864a7592d0a37e4d@1547419282_oswg15829oswg640oswg334_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：微博/iPhone 6产品页</p><p>同样出人意料的中文文案还有很多很多，比如“让妈妈开心的礼物，开了又开”、“开发者的大事，大快所有人心的大好事”、“服务器，为人民服务”、“真的笑，笑出声”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_9c6f3d9c538841bab48f8c2b00c1bbf9@1547419282_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：微博/iPad Air产品页</p><p>这些能明白表达什么意思，但感觉又不像人话的中文全部来自苹果大陆官网的产品介绍。不知道为什么，苹果大陆官网的宣传语经常被翻译成这种奇葩画风，给人带来极强的违和感，语感和逻辑与正常中文表达完全不一样。</p><p>当然，你也能理解为苹果想通过独特的表达方式来塑造特殊记忆点，形成品牌的梗和辨识度。但从用户角度出发，我并不认为这是一件好事，玩梗带来的热度和流量完全无法弥补对品牌造成的损害。</p><h2><strong>中文翻译离谱，海外品牌频频翻车</strong></h2><p>事实上，对中文翻译漫不经心的远不止苹果一个，不少国外企业也患上了“翻译困难症”。其中最为大众所熟知的应该就是微软了，因为微软Windows操作系统中存在很多奇奇怪怪的中文翻译，网友甚至为其量身打造了专有名词“微软式中文”。</p><p><strong>“你的电脑正在重启，坐和放宽”，这是微软在Windows 10预览版安装界面上的错误翻译而产生的短语，英文原文是“Sit back and relax”。</strong>虽然这个“神翻译”在后续的版本中很快被修正&nbsp;，但是这个短语却在网络中流传开来，成为又一个用来吐槽错漏的翻译的短语。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_2550c38a99f240ffa19376f7c602b60a@1547419282_oswg28213oswg600oswg402_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：微博/Windows 10预览版安装界面</p><p>Windows来到中国也已经有20多年时间了，在中文化的过程中，微软整出过很多这样让人触不及防的“金句”，当然这是高情商的表达，低情商的就是机翻还不带人工校验的错误翻译。</p><p>这些微软式中文力求营造出符合温馨体贴的感觉，略带粗鲁的翻译却让人内心的疑惑和血压同步上升。&nbsp;</p><p>“滚回到以前的版本”，回滚和滚回的意思可完全不一样，这翻译显然不太礼貌了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_d4c456c6fec9431a82a0962ec6d95be3@1547419282_oswg64062oswg600oswg359_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：微博/Win10 预览版降级时的标题</p><p>“不要说我们没有警告过你...”，来自微软的警告，这不客气的升级警告可是会吓跑用户的。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_1e3c97d5983843adb7260f433010f49c@1547419282_oswg317584oswg1022oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：微博/WP 升级预览版前的警告</p><p>“幸福倒计时”，霸道总裁文风，Windows更新容不得半点拒绝。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_8fe9e51e0888480eaf21a70bbffc4f2d@1547419282_oswg123091oswg700oswg362_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：微博/Win10 强制更新前弹窗</p><p>“Windows 10不是面向我们所有人，而是面向我们每一个人”，我们还是能看出Windows系统神翻译的“文学修养”，一句谦虚又自负的自我介绍是微软冲击茅盾文学奖的一大步。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_88c72d60b54040b19fc6ac9e963f2c2d@1547419282_oswg92707oswg720oswg292_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：微博/Windows 10 宣传页描述</p><p>类似的微软式中文实在太多，相信每个Windows用户都深有体会。<strong>简单来说微软式中文大多来自Bing的机翻，虽然读不太通，但严格意义上也不能算错误翻译。偶尔也有微软员工输入的错别字，加上微软后期没有专人进行检查，导致语序、时态、惯用词、排版都不符合汉语用户的使用习惯。</strong></p><p>这也是苹果、微软等国外企业出现低级翻译错误的主要原因。</p><h2><strong>苹果微软们该多上点心</strong></h2><p>表面上看，一些企业在翻译中文时出现的错误是由于对中国文化不了解以及翻译过程中缺乏仔细审查。但实际上，这些奇怪的中文翻译反映出企业对翻译工作不够重视。</p><p>本土化是所有跨国业务都需要面临的问题，而要判断一个企业的本土化做的是否足够，首当其冲的就是翻译问题。然而，一些企业在进入中国市场时，往往忽视了翻译的重要性，导致出现了许多令人啼笑皆非的翻译错误。这些错误不仅损害了企业的品牌形象，也影响了与消费者的沟通。</p><p><strong>首先，翻译不仅仅是语言的转换，更是文化的传递。</strong>一个成功的翻译应该能够准确传达原文的意思，同时考虑到目标语言的文化背景和使用习惯。例如，一些西方的俚语或双关语，在中文中可能没有对应的表达方式，如果直接翻译，不仅无法达到预期的效果，反而可能引起误解。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_87c37e10ac1846e8bc61d00f86b25850@1547419282_oswg397050oswg1560oswg929_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：苹果官网</p><p><strong>其次，翻译的质量直接影响到产品的市场接受度。</strong>在竞争激烈的市场环境中，消费者对产品的选择往往取决于细节。一个充满错误的翻译，很容易让消费者对产品的质量产生怀疑，从而影响购买决策。</p><p><strong>再者，翻译错误还可能涉及到法律风险。</strong>在某些情况下，错误的翻译可能会违反当地的法律法规，给企业带来不必要的麻烦。例如，一些产品说明书如果翻译不当，可能会误导消费者，导致使用不当，甚至引发安全事故。</p><p>微软、苹果作为各自领域的头部品牌，进行本土化时更应该重视翻译工作，投入足够的资源和精力。这包括聘请专业的翻译人员，进行严格的质量控制，以及与本土文化专家合作，确保翻译的准确性和适宜性。只有这样，企业才能在跨文化交流中减少障碍，赢得消费者的信任和支持。</p><p><strong>最后，企业还应该建立起一套有效的反馈机制，及时收集和处理消费者对翻译的意见和建议。</strong>这不仅可以帮助企业不断改进翻译质量，也是对消费者尊重和重视的体现。</p><p>奇葩中文翻译背后反映的是企业对本土化的不重视，随着本土化工作的愈发完善，这些“野蛮生长”的XX式中文终究会成为互联网的记忆，小雷期待苹果下一次中文宣传文案能让用户读懂。</p><p>本文来自微信公众号“雷科技”（ID:leitech），36氪经授权发布</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849313282214790</id>
            <title>智能眼镜下半场：Meta与中国信徒们</title>
            <link>https://www.36kr.com/p/2849313282214790</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849313282214790</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 12:33:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能眼镜, Meta雷朋, 传统眼镜品牌, 中国厂商
<br>
<br>
总结: 传统眼镜品牌雷朋推出的智能眼镜Meta雷朋在短时间内获得了超过一百万的销量，引发了中国厂商的关注和加入竞争。这款智能眼镜虽然功能简单，但成功打开了普通消费级市场的大门，吸引了华为、小米等厂商加入竞争。中国厂商在硬件整合和软件体验方面面临挑战，但也积累了一定经验，加速跟进智能眼镜市场。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_d375225b8fdb45eb9ddd80b9d196ed0c@46958_oswg481207oswg1080oswg690_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>发售半年获得一百万销量，这款名为META的智能眼镜不是来自真正的META公司，而是出自传统的眼镜品牌雷朋。&nbsp;</p><p>如果一个产品出货量能超过 100 万，就意味着这款产品在业内已经具备了至少一个以上击中用户真正需求的产品功能，甚至有颠覆现有生态的实力：足够多的用户数量意味着相繁荣的生态，而生态是长出一切果实的宝贵土壤。&nbsp;</p><p>但这更多是在说 AR 乃至 VR 级别的“智能眼镜”，因为这过去一直被业界视为智能眼镜未来的主流发展形态。这种概念在过去近十年的时间中流传甚广，甚至产生了某种“灯下黑”效应：现在智能眼镜领域中，受关注最少的就是功能相对简陋，最接近传统眼镜形态的智能眼镜。&nbsp;</p><p>正是因此，当 Meta Ray Bens（下文简称 Meta 雷朋）发售后不到六个月超过 100 万台的销量的消息传来，无论是乐观者还是悲观者都没有想到，居然是一款形态最接近传统眼镜、功能非常单薄、甚至完全没有显示功能的“智能眼镜”，率先撬开了普通消费级市场的大门。&nbsp;</p><p>过去一个比较普遍的误区，是将以 Xreal 为首的 AR 眼镜，与以 Meta 为首的智能眼镜混为一谈；但实际上两者并非同一生态下的产品：Meta 雷朋所代表的是功能相对简单、售价更低的品类，并且长期处于被忽视的状态，业内最具潜力的独角兽厂商都没有涉足这一领域。&nbsp;</p><p>但随着 Meta 雷朋的大获成功，轻智能眼镜这一赛道不仅吸引了华为、小米等智能手机厂商，同时也有字节跳动、腾讯这样的巨头组建团队入局：字节跳动已于今年三月完成对 Oladance 大十科技的收购，收购价格在 3-5 亿元之间，这家公司此前致力于骨传导耳机领域的研发，目前字节跳动团队人员已经进驻；据统计目前业内已经公开/即将发布类似形态智能眼镜产品的品牌，数量已经超过五家。&nbsp;</p><p>在 Meta 雷朋之前，这个行业长期处于相对消极的发展状态；很多所谓的智能眼镜产品无法将外出佩戴体验做到易用的程度，很多厂商甚至已经处于某种意义上的“躺平”，用“当前技术无法支撑其用户想象中的体验”来作为新品销量无法继续取得突破的理由。&nbsp;</p><p>因此 Meta 雷朋的成功不仅如同一针兴奋剂，让中国厂商一拥而上还有一个隐藏条件：这是一个非常方便“Copy to China”的产品形态；在一些硬件厂商从业者看来，无论是多模态大模型应用层开发，还是智能眼镜硬件整合技术本身，中国相关的产业链都不输给 Meta 这样的一线大厂。&nbsp;</p><h2><strong>不做“极客玩具”做时尚单品</strong></h2><p>在关于 Meta 雷朋的分析中，时尚属性是鲜被提起、但同样至关重要的因素：在 Meta官网，你可以自由组合出超过 150 种搭配风格，这种定制程度对于智能硬件设备来讲已经算天文数字，但对于雷朋这样的眼镜品牌来讲只能算是入门级，这种时尚属性是 Meta 雷朋区别于所有现有产品的最重要特征之一。&nbsp;</p><p>此外，一个高像素且易用的镜头模组支撑起了 Meta 雷朋的几乎所有卖点功能：1200 万像素对于如今动辄上亿像素的旗舰手机影像模组来讲已经是四五年前的“过时技术”，只支持录制 1080p 30 帧的画面。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_72cfc3d898034ed4b7f9ef209cb8a0e7@46958_oswg494344oswg960oswg836_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但就是这样的入门级配置，已经让这款眼镜足够成为合格的内容录制工具，尤其是对于这款眼镜能够原生支持 Facebook（Meta）与 Instagram 的直播、将视频流推到手机上实现直接传输，这种便捷易用的功能特征让这款眼镜少了很多属于智能眼镜的科技发烧属性。却成为了这款产品的标签。&nbsp;</p><p>这些在产品段的决策，体现出的是在 Meta 雷朋二代大获成功的背后，是 Meta 已经在此领域多年投入、数十亿美元的投资后的一个“偶然结果”。&nbsp;</p><p>即使此类眼镜的 ODM 成本相比 AR/VR 品类来讲成本极低，但很大程度上，Meta 的钞能力让全球最顶端的供应链在围绕着这款产品服务，也是 Meta 雷朋成功的一个重要因素：这款眼镜所搭载的高通 AR1 芯片采用了 5nm 制程工艺，功耗也比前一代芯片降低 50%，同时具有小尺寸封装、对摄像头、多麦克风阵列等功能的支持：与其说芯片的特征影响了 Meta 雷朋的最终形态，不如说是高通与 Meta 的合作，打造出了这款目前最适合智能眼镜形态的芯片。&nbsp;</p><p>可以说，Meta 的成功固然有与全球顶尖供应商技术深度整合的优势，但制造业同样是中国厂商手中的一张王牌：当下高通 AR1 芯片的独占期已经结束，首批跟进这一产品形态的中国厂商已经发布了对应的新品，五月发布的华为智能眼镜 2 起售价 2299 元人民币。整体上也选择与 Meta 相同、偏传统眼镜的外观设计，但少了镜头模组这样的关键硬件，来换取更好的续航与重量。&nbsp;</p><h2><strong>中国信徒们</strong></h2><p>超过百万的销量，迅速吸引了大量蠢蠢欲动的中国硬件厂商加入其中：比起硬件上的整合，软件的体验如何做到完美平衡成了更棘手的难题。&nbsp;</p><p>据一位在 XR 眼镜厂商供职的产品经理介绍，Meta 雷朋目前实现的多模态大模型能力，是他们目前开发中遇到主要的短板：智能眼镜的端侧算力无论是从功耗还是性能的角度都完全无法运行，同时为了功耗与续航，将芯片性能限制在相对较低的水平也已经是 AR/VR 智能眼镜领域的通行做法。&nbsp;</p><p>在这一点上，手机厂商有着相对更多的模态大模型开发、整合经验，尤其是此前已发布过数款智能眼镜产品的小米、华为这些传统智能手机厂商，在过去的一年里已经积累了相对更多的多模态大模型与硬件整合的经验，这些可以被快速整合进智能眼镜形态产品中，因此也是目前跟进速度最快的一批厂商。&nbsp;</p><p>对此，一个合理的替代方案是通过纯语音的方式，在智能眼镜中加入唤醒语音大模型的选项；即使没有足够的成本让产品中支持多模态大模型，一个“在耳边的对话大模型”，同样能对现有大模型操作体验带来颠覆。&nbsp;</p><p>在这一点上，同样发布过 AR 智能眼镜的魅族，至少喊出了正确的口号；当下的智能眼镜产品，想要交付给用户足够完善的用户体验， 不仅离不开手机，也需要手机充当一个运算中心，通过智能眼镜作为载体，通过智能眼镜自带的各种传感器完成环境内容的识别传输与生成结果交付。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_e2c4c8f557bc4539b8bb1d2c40afb823@46958_oswg160742oswg700oswg356_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作为对比，AR 眼镜品类中成本最低的方案 —— 采用衍射光波导方案的 AR 眼镜设备同样能将体积与重量控制在相对合理的范围内，但交付出的内容显示效果只能达到堪用的水准，同时也极易受到外界光线环境的影响。&nbsp;</p><p>即使有着内容显示功能都眼镜还是会在功能上有更多的想象空间，大厂同样也在对应的技术上做研究，甚至也会制作出对应用于开发的原型机用于测试验证，但并不会最终推向市场：至少未来三年内用于智能眼镜的芯片首要设计目标都是将功耗进一步降低，来让智能眼镜获得更好的续航体验。&nbsp;</p><p>「今天的智能眼镜市场有点像是 TWS（耳机）或智能手机刚诞生时的感觉」这位硬件产品经理对记者表示，市场正在逐渐纠正过去定位上的错误，在一个范本出现之后，销量也将成为下一个时代中引导硬件发展路线最重要的因素。&nbsp;</p><p>「比起显示功能，现在的智能眼镜功能更多聚焦在听觉与语音交互这一模式上」这或许同样是一种从追赶者视角而来的解读：智能眼镜最先取代的可能不是以往的“便携式显示屏”，而是骨传导耳机、智能手表等设备。&nbsp;</p><p>至于时尚属性，同样曾经是智能手表走过的道路：Apple Watch 在发售早期同样历经过在奢侈品领域的探索，后来随着健康监测传感器技术的逐渐成熟完善，才最终确立了如今健康/运动功能为主的定位。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_58da6991f69b4432baf28fe34beb0bc8@46958_oswg427826oswg800oswg484_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这从某种程度上也暗合了当下智能眼镜的发展阶段：或许它未来五到十年内都无法取代智能手机，但在新的行业共识形成之后，这已经不是阻挡它成为下一个爆款硬件产品的主要障碍。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/EQoRg8wyHqgZCA3JA9OgXQ" rel="noopener noreferrer nofollow" target="_blank">“电厂”（ID:wonder-capsule）</a>，作者：张勇毅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849256434354821</id>
            <title>LLM用于时序预测真的不行，连推理能力都没用到</title>
            <link>https://www.36kr.com/p/2849256434354821</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849256434354821</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 11:30:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 语言模型, 时序预测, 时间序列, 消融研究
<br>
<br>
总结: 语言模型在时序预测任务中的应用效果并不理想，研究表明使用语言模型的常用方法在时序预测任务中并不比基本的消融方法表现更好，但计算量却更大。当前时序预测研究存在一些问题，但语言模型和时间序列之间仍有潜力，可以用于时间序列推理和社交理解等任务。 </div>
                        <hr>
                    
                    <p>语言模型真的能用于时序预测吗？根据贝特里奇头条定律（任何以问号结尾的新闻标题，都能够用「不」来回答），答案应该是否定的。事实似乎也果然如此：强大如斯的 LLM 并不能很好地处理时序数据。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_0755df7c18b94c96ac40663126cbb68c@46958_oswg254915oswg500oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>时序，即时间序列，顾名思义，是指一组按照时间发生先后顺序进行排列的数据点序列。</p><p>在很多领域，时序分析都很关键，包括疾病传播预测、零售分析、医疗和金融。在时序分析领域，近期不少研究者都在研究如何使用大型语言模型（LLM）来分类、预测和检测时间序列中的异常。这些论文假设擅长处理文本中顺序依赖关系的语言模型也能泛化用于时间序列数据中的顺序依赖关系。这个假设并不令人意外，毕竟语言模型是现在机器学习领域的香饽饽。</p><p>那么，语言模型究竟能给传统时序任务带去多大助益？</p><p>近日，弗吉尼亚大学和华盛顿大学一个团队尝试解答了这一问题，并最终给出了一个简单却又重要的主张：对于时序预测任务，使用语言模型的常用方法的表现都接近或劣于基本的消融方法，但前者所需的计算量比后者多几个数量级。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_b289f23d2b9642e59fab3df9f6830c92@46958_oswg62543oswg1080oswg508_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文标题：Are Language Models Actually Useful for Time Series Forecasting?</p><p>论文地址：https://arxiv.org/pdf/2406.16964</p><p>这些发现是该团队通过大量消融研究得到的，其中揭示出当前时序预测研究中存在一个「令人担忧的趋势」。</p><p>但该团队也表示：「我们的目标并不是暗示语言模型永远无法用于时间序列。」事实上，近期一些研究表明语言和时间序列之间具有很好的互动潜力，可以处理时间序列推理和社交理解等任务。</p><p>相反，他们的目标是强调这一惊人发现：对于已有的时间序列任务，现有方法几乎没有用到预训练语言模型那与生俱来的推理能力。</p><h2><strong>实验设置</strong></h2><p>该团队使用了三种最先进的时间序列预测方法，并为 LLM 提出了三种消融方法：w/o LLM、LLM2Attn、LLM2Trsf。</p><p>为了评估 LLM 在时间序列预测任务上的有效性，他们在 8 个标准数据集上对这些方法进行了测试。</p><p><strong>用于语言模型和时间序列的参考方法</strong></p><p>他们实验了三种近期的使用 LLM 进行时间序列预测的方法。见表 2，这些方法使用的基础模型为 GPT-2 或 LLaMA，同时使用了不同的对齐和微调策略。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_7cb7a4d6c04245f99f170edd356d9828@46958_oswg113373oswg1080oswg252_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>OneFitsAll：OneFitsAll（有时也被称为 GPT4TS）方法会先对输入时间序列使用实例归一化和 patching 技术，然后将其馈送给一个线性层，以获得用于语言模型的输入表征。在训练期间，语言模型的多头注意力和前馈层会被冻结，而位置嵌入和层归一化会得到优化。最终层的作用是将语言模型的最终隐藏状态转换成预测结果。</p><p>Time-LLM：使用 Time-LLM 时，输入时间序列会被 patching 技术 token 化，并且多头注意力会将其与词嵌入的低维表征对齐。之后，将这个对齐过程的输出与描述性统计特征的嵌入一起输送给一个冻结的预训练语言模型。然后，将该语言模型的输出表征展平，并使其通过一个线性层，从而得到预测结果。</p><p>LLaTA：LLaTA 嵌入输入时间序列的方式是将每个通道都视为一个 token。该架构的一半是「文本分支」，其使用交叉注意力来将时间序列表征与语言模型的词嵌入的低维表征对齐。然后将该表征传递给一个冻结的预训练语言模型，得到一个「文本式预测」。同时，该架构的「时间」分支会基于输入时间序列为预训练语言模型学习一个低秩适应器，从而得到一个用于推理的「时间预测」。该模型包含考虑这些表征之间的相似度的额外损失项。</p><p><strong>该团队提出的消融方法</strong></p><p>对于基于 LLM 的预测器，为了将 LLM 的影响隔离开，该团队提出了三种消融方法：移除 LLM 组件或将其替换成一个简单模块。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_952a0bebf9ec4839986e89ce0feae6ba@46958_oswg312435oswg1080oswg520_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，对于上述三种方法中的每一种，他们都进行了以下三项修改：</p><p>w/o LLM，见图 1b。完全移除语言模型，直接将输入 token 传递给参考方法的最终层。</p><p>LLM2Attn，见图 1c。将语言模型替换成单个随机初始化的多头注意力层。</p><p>LLM2Trsf，见图 1d。将语言模型替换成单个随机初始化的 Transformer 模块。</p><p>在上述消融研究中，预测器的其余部分都保持不变（可训练）。比如，如图 1b 所示，在移除了 LLM 之后，输入编码会被直接传递给输出映射。而如图 1c 和 1d 所示，在将 LLM 替换成注意力或 Transformer 后，它们会与原始方法的剩余结构一起获得训练。</p><p><strong>数据集和评估指标</strong></p><p>基准数据集。评估使用了以下真实世界数据集：ETT（其包含 4 个子集：ETTm1、ETTm2、ETTh1、ETTh2）、Illness、Weather、Traffic、Electricity。表 1 给出了这些数据集的统计情况。另外还有 Exchange Rate、Covid Deaths、Taxi (30 min)、NN5 (Daily) 和 FRED-MD。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_1b73611e58ca45eba17f209b95c86d26@46958_oswg22231oswg1063oswg173_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>评估指标。该研究报告的评估指标是预测时序值和真实时序值之间的平均绝对误差（MAE）和均方误差（MSE）。</p><h2><strong>结果</strong></h2><p>具体来说，该团队探究了以下研究问题（RQ）：</p><p>（RQ1）预训练语言模型是否有助于提升预测性能？</p><p>（RQ2）基于 LLM 的方法是否值得其消耗的计算成本？</p><p>（RQ3）语言模型预训练是否有助于执行预测任务的性能？</p><p>（RQ4）LLM 能否表征时间序列中的顺序依赖关系？</p><p>（RQ5）LLM 是否有助于少样本学习？</p><p>（RQ6）性能从何而来？</p><p><strong>预训练语言模型是否有助于提升预测性能？(RQ1)</strong></p><p>实验结果表明，预训练 LLM 对时间序列预测任务来说还不是很有用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_1d84e5681c9d4a5e92c4d3e809519726@46958_oswg832881oswg1080oswg1394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_0bb80280e2854f39a36be482536a5ce2@46958_oswg158208oswg992oswg623_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>总体而言，如表 3 所示，在 8 个数据集和 2 个指标上，消融方法在 26/26 案例中优于 Time-LLM 方法，在 22/26 案例中优于 LLaTA，在 19/26 案例中优于 OneFitsAll。</p><p>总之，很难说 LLM 可以有效地用于时间序列预测。</p><p><strong>基于 LLM 的方法是否值得其消耗的计算成本？(RQ2)</strong></p><p>这里，根据这些方法的名义性能来评估它们的计算强度。参考方法中的语言模型使用了数亿乃至数十亿参数来执行时间序列预测。即使当这些语言模型的参数冻结时，它们在训练和推理时依然会有很大的计算开销。</p><p>举个例子，Time-LLM 有 6642 M 参数，在 Weather 数据集上耗时 3003 分钟才完成训练，而消融方法仅有 0.245 M 参数，平均训练时间仅有 2.17 分钟。表 4 给出了在 ETTh1 和 Weather 数据集上训练其它方法的相关信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_557e7a089c934155a5da9b82cd9102dc@46958_oswg227724oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>至于推理时间，这里的做法是除以最大批量大小，以估计每个示例的推理时间。平均而言，相比于修改后的模型，Time-LLM、OneFitsAl、LLaTA 所用的推理时间多 28.2、2.3、1.2 倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_52e33815633f4f8f94faed6288f0ebd0@46958_oswg270614oswg1080oswg573_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>图 3 给出了一些示例，其中绿色标记（消融方法）通常低于红色标记（LLM），并且集中于左侧，这说明它们计算成本更低但预测性能更好。</p><p>总之，在时间序列预测任务上，LLM 的计算强度无法为性能带来相应的提升。</p><p><strong>语言模型预训练是否有助于执行预测任务的性能？(RQ3)</strong></p><p>评估结果表明，对于时间序列预测任务而言，使用大型数据集进行预训练实在没有必要。为了检验预训练期间学到的知识能否给预测性能带来有意义的提升，该团队实验了在时间序列数据上，对 LLaTA 进行不同组合的预训练和微调的效果。</p><ul><li>预训练 + 微调（Pre+FT）：这是原始方法，即在时间序列数据上微调预训练语言模型。对于这里的 LLaTA，做法是冻结基础语言模型，学习一个低秩适应器（LoRA）。</li><li>随机初始化 + 微调（woPre+FT）：预训练得到的文本知识是否有助于时间序列预测？这里，随机初始化语言模型的权重（由此清除了预训练的效果），再在微调数据集上从头开始训练 LLM。</li><li>预训练 + 不使用微调（Pre+woFT）：在时间序列数据上进行微调又能给预测性能带来多大提升呢？这里是冻结语言模型，同时放弃学习 LoRA。这能反映语言模型自身处理时间序列的性能。</li><li>随机初始化 + 无微调（woPre+woFT）：很明显，这就是将输入时间序列随机投射到一个预测结果。该结果被用作与其它方法进行比较的基准。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_28c6b9197fcd496a8008341f7b9c7cb8@46958_oswg246219oswg1080oswg414_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>整体结果见表 5。在 8 个数据集上，依照 MAE 和 MSE 指标，「预训练 + 微调」有三次表现最佳，而「随机初始化 + 微调」获得了 8 次最佳。这说明语言知识对时间序列预测的帮助有限。但是，「预训练 + 无微调」与基准「随机初始化 + 无微调」各自有 5 和 0 次最佳，这说明语言知识对微调过程的帮助也不大。</p><p>总之，预训练得到的文本知识对时间序列预测的帮助有限。</p><p><strong>LLM 能否表征时间序列中的顺序依赖关系？(RQ4)</strong></p><p>大多数使用 LLM 来微调位置编码的时间序列预测方法都有助于理解序列中时间步骤的位置。该团队预计，对于一个有优良位置表征的时间序列模型，如果将输入的位置打乱，那么其预测性能将会大幅下降。他们实验了三种打乱时间序列数据的方法：随机混洗整个序列（sf-all）、仅随机混洗前一半序列（sf-half）、交换序列的前半和后半部分（ex-half）。结果见表 6。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_695eae6bfde142368ae5e31817630161@46958_oswg341164oswg1080oswg506_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>输入混洗对基于 LLM 的方法与其消融方法的影响差不太多。这说明 LLM 在表征时间序列中的顺序依赖关系方面并没有什么突出能力。</p><p><strong>LLM 是否有助于少样本学习？(RQ5)</strong></p><p>评估结果表明，LLM 对少样本学习场景而言意义不大。</p><p>他们的评估实验是取用每个数据集的 10%，再训练模型及其消融方法。具体来说，这里评估的是 LLaMA（Time-LLM）。结果见表 7。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_f1898247fdfc47ce9304fe1ced22c7a9@46958_oswg214562oswg1080oswg406_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_4c655b40b8284066b8579ca260826d1c@46958_oswg199368oswg1080oswg371_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，有无 LLM 的表现差不多 —— 各自都有 8 个案例表现更好。该团队也使用基于 GPT-2 的方法 LLaTA 进行了类似的实验。结果见表 8，这里消融方法在少样本场景中的表现还优于 LLM。</p><p><strong>性能从何而来？(RQ6)</strong></p><p>这一节评估的是 LLM 时间序列模型中常用的编码技术。结果发现，将 patching 和单层注意力组合起来是一种简单却有效的选择。</p><p>前面发现对基于 LLM 的方法进行简单的消融并不会降低其性能。为了理解这一现象的原因，该团队研究了 LLM 时间序列任务中常用的一些编码技术，比如 patching 和分解。一种基本的 Transformer 模块也可用于辅助编码。</p><p>结果发现，一种组合了 patching 和注意力的结构在小数据集（时间戳少于 100 万）上的表现优于其它大部分编码方法，甚至能与 LLM 方法媲美。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_58d3d68dda884ee1aa7d49496ca7cc49@46958_oswg101332oswg744oswg934_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其详细结构如图 4 所示，其中涉及将「实例归一化」用于时间序列，然后进行 patching 和投射。然后，在 patch 之间使用一层注意力进行特征学习。对于 Traffic（约 1500 万）和 Electricity（约 800 万）等更大的数据集，则使用了基本 Transformer 的单层线性模型的编码表现更优。在这些方法中，最后还要使用单层线性层来投射时间序列嵌入，从而得到预测结果。</p><p>总之，patching 对编码而言非常重要。此外，基本的注意力和 Transformer 模块也能为编码带来有效助益。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/C-N0tyQrEOoNoADtH_thTA" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID:almosthuman2014）</a>，编辑：panda，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849269830896258</id>
            <title>直击2024WAIC：AI正在颠覆AI</title>
            <link>https://www.36kr.com/p/2849269830896258</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849269830896258</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 11:19:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: WAIC 2024, 人工智能, 大模型, 人形机器人
<br>
<br>
总结: 2024世界人工智能大会（WAIC 2024）在上海举办，展示了人工智能技术的最新发展。大会聚焦于大模型、算力、机器人、自动驾驶等领域，展示了AI在各个领域的应用和创新。人形机器人成为焦点之一，展示了其在工业和生活中的潜力。AI技术的发展已经触手可及，AI正在颠覆各行各业，迎来新的变革时代。 </div>
                        <hr>
                    
                    <p><strong>7月4日，WAIC 2024在上海召开，这也是WAIC也走进的第七个年头。</strong></p><p><strong>AI从生僻词变成了热搜词，从遥不可及的技术变得触手可及。</strong></p><p><strong>今年，时代周报和时代财经携手走进WAIC 2024，直击现场，见证AI如何颠覆AI。</strong></p><p>输入一段文字、上传一张图片，便可文生文、文生图、文生视频、图生视频，任意转换；机器狗在展区内撒欢打滚，人形机器人也更像“人”了，挥舞着机械臂，十指灵活地完成各项工作，甚至还能后空翻；此外，AI+低空经济，AI+教育、AI+救援等更多场景应用涌现……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_b1517deab14e4303a0cff3d6e7964f5e@000000_oswg123447oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△图源：时代周报记者摄</p><p>7月4日，2024世界人工智能大会（以下简称“WAIC 2024”）在上海召开。这也是第七届WAIC。作为国内最顶级的AI盛会之一，WAIC往往“大佬云集”“量大管饱”。据悉，今年大会的展览规模、参展企业数 、亮点展品数、首发新品数均达历史最高。</p><p>在WAIC上，企业的动态常预示着行业的整体风向标。在这一届展览中，不少展商告诉时代周报记者，此次大会展出的技术更聚焦于具体场景的落地。</p><p>回顾往昔，如今WAIC已经来到了第七届。</p><p>2018年，在第一届WAIC上，马云说“我们对这场技术革命有期待、有担心、有希望，也有困难。”六年之后，百度创始人、董事长兼首席执行官李彦宏说“没有应用，基础模型将一文不值。”</p><p>如今马云已“退隐”，WAIC常客马斯克缺席了今年的大会，WAIC也走进第七个年头。AI从生僻词变成了热搜词，从遥不可及变得触手可及；2024，AI走出了百模大战，迎来新物种诞生的新纪元，一轮更大的变革正在来临。</p><h2><strong>AI走出大模型</strong></h2><p>7月4日中午，在上海世博展览馆对外开场前，会场周围早已车水马龙，人头攒动。</p><p>据了解，WAIC 2024大会展览面积超5.2万平方米，包括核心技术、智能终端、应用赋能三大板块，同时聚焦大模型、算力、机器人、自动驾驶等领域。共有500余家企业参展，展品数量已超1500项。</p><p>除展览外，今年大会还包含了1场开幕式和全体会议，全球治理、产业发展、科学前沿3场主论坛，以及若干场行业论坛，涵盖AI伦理治理、大模型、数据、算力、具身智能、新型工业化、自动驾驶、投融资、教育与人才等议题。</p><p>过去一年，生成式AI加速进化和成熟，展现在WAIC 2024的是，AI及其相关应用百花齐放，也变得更加有趣和接地气了。</p><p>例如，在阿里巴巴展区，通义APP展示了在工作、学习、生活等场景中的AI助手能力。参观者可以体验“定制个性化声音”、观看“动态版韩熙载夜宴图”、创作“涂鸦作画个性扇子”以及体验“亚运AIGC明信片”等打卡互动展项。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_eef2496ad0a44416a599b70dc6f68d26@000000_oswg801023oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△图源：阿里巴巴供图</p><p>商汤科技则展示了可控人物视频生成大模型Vimi，基于“日日新”大模型，只通过一张人物照片，就能生成一段1分钟左右的人物视频，并支持动画、声音、文字等多种元素的驱动方式。</p><p>去年，有30余个大模型在WAIC展览上登场。”第四范式相关负责人告诉时代周报记者，之前主办方告诉他们今年预计要展览100个大模型。</p><p>第四范式展出的是多个行业大模型落地案例，包括智能整车大模型、慢病管理大模型、智慧水利大模型等。上述相关负责人称，以上均为第四范式的大模型在今年最新的落地应用。</p><p>而在展区内，她被咨询较多的问题是关于大模型如何落地应用。“今年是大模型的应用之年。此前围绕大模型的讨论可能更多关于技术、参数，以及偏娱乐化的应用，但AI大模型技术如何在产业方面产生价值？这是企业客户特别关心的。在这次WAIC 2024开展之前，我们就已经接到非常多企业团队交流的需求。”该负责人表示。</p><p>除AI大模型外，人形机器人也在WAIC 2024上备受瞩目。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_c234a6a52d3240d59c752ca954685df3@000000_oswg136011oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△图源：时代周报记者摄</p><p>特斯拉二代人形机器人Optimus的亮相，引来不少人围观。据特斯拉相关负责人向记者介绍，特斯拉把对于汽车的训练应用到了机器人身上，通过传感器和计算机视觉，利用海量数据持续训练，使机器人变得越来越成熟。从灵活度来看，机器人全身拥有28个自由度，手部拥有11个自由度，能够清晰识别周围物体并完成敏捷运动。</p><p>此外，宇树科技展示了国内首款实现奔跑功能的全尺寸通用人形机器人H1，傅利叶、达闼、云深处科技等企业也将带来超20款智能机器人。</p><p>“以前我觉得人形机器人是一个非常小众的领域，没想到今年能受到这么大的关注。”乐聚机器人苏州总经理王松对人形机器人赛道的火热颇感惊讶。</p><p>据他观察，目前大会参观者们对人形机器人主要的关注点集中在几个方面：一是人形机器人本体，如运控、结构，包括整机的性能发展到了什么程度；二是人形机器人的具体操作能力，包括跟大模型结合做任务规划的进展如何；第三是面向实际工业任务场景，人形机器人能够做些什么。这是大家目前热切讨论的问题。</p><p>“现在大模型更多聚焦在自然语言对话上，我们希望大模型未来能够跟具身机器人的数据进行结合。例如，之前我们和华为的盘古大模型做了很好的打通，利用它的多模态能力去做具身任务的规划等。”王松表示。</p><h2><strong>全球治理</strong></h2><p>推动AI收益最大化的同时，把风险降到最低，让AI健康发展，是WAIC 2024的一大前提。</p><p>WAIC 2024被冠以的全名是“世界人工智能大会暨人工智能全球治理高级别会议”，主题是“以共商促共享，以善治促善智”。这也是WAIC首次将AI治理提高到如此地步。</p><p>据时代周报记者不完全统计，除开幕式和高级别会议全体会议外，WAIC 2024共有一个治理主论坛，5个关于治理的分论坛。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_eed40a2406194b2391db544f9350b227@000000_oswg173287oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△图源：主办方供图</p><p>在高级别会议全体会议上，清华大学苏世民书院院长、清华大学人工智能国际治理研究院院长薛澜提到了AI可能带来的风险，包括出现技术“幻觉”、数据安全、算法歧视、能源环境等问题。</p><p>薛澜指出，中国在过去已经建立了相对完整的治理体系，在底层产业应用、算法、算力、数据等方面均有一系列治理规则。例如2019年，国家新一代人工智能治理专业委员会发布了《新一代人工智能治理原则——发展负责任的人工智能》。</p><p>人工智能的风险不是一个国家的风险，而是全球的风险。薛澜希望通过加强政府之间多双边对话机制，以科学共同体力量助力国际治理机制全面完善。</p><p>上海人工智能实验室主任、首席科学家，清华大学惠妍讲席教授周伯文则认为，AI发展是失衡的，AI模型安全的提升还远远落后于性能。</p><p>这背后的原因是两者投入上的巨大差异。从人才密集度、商业驱动力、算力的投入度等方面对比来看，安全度投入远远落后于AI投入，目前世界上只有1%对齐或者安全优先考量。因此，周伯文提出了探索人工智能45度平衡率的技术主张，既能AI安全优先、又能保证AI能力长期发展。</p><p>“AI是一个新物种，这个物种比我们人类要强大很多倍。我们是不是确定能跟它共存？如果我们无动于衷，那么我们就会被AI消灭，这是毫无疑问的。”图灵奖得主罗杰·瑞迪的疑问，也许会在以后多年，拷问着与AI共存的人类。</p><h2><strong>沿着AI的脉络</strong></h2><p>WAIC已经走到了第七届。2018年，第一届WAIC举办。</p><p>“我们对这场技术革命有期待、有担心、有希望，也有困难。”彼时尚未“淡出江湖”、任阿里巴巴集团董事局主席的马云在大会上发表演讲。</p><p>第二年，马云和特斯拉CEO马斯克的“双马对话”名场面，更是赚足了噱头和眼球。</p><p>彼时，AI对于公众而言还是一个非常陌生的科学概念。马斯克以幽默的方式解释AI为“爱”（中文发音），而马云则戏称其为“阿里巴巴智能”，引发全场大笑。2019年WAIC上的现场观众数量也是过去几届之最。</p><p>时过境迁，人们不再执着于AI是什么。不过，过去的声音穿越时空，仍能听到些许回响。</p><p>李彦宏的演讲仍然“语不惊人死不休”，在首届WAIC上，他说未来没有任何一家企业会宣称自己和AI没有关系，不够AI的企业，注定会被新的企业所取代。在2024年，同样的大会上，他说没有应用，光有基础模型，不管是开源还是闭源都一文不值。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_b1b077670e1447428c963c644927ad28@000000_oswg104197oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△图源：主办方供图</p><p>6年前，已逝的商汤科技创始人汤晓鸥曾表示AI这个行业，需要跟各行各业结合，才能向前发展。7月4日，商汤科技董事长兼CEO徐立接力，他谈到，AI还没有到超级时刻，因为它没有真正地走进到一个行业的垂直应用当中引起广泛的变化，支撑起超级时刻的，是应用。</p><p>“应用”是今年大咖们口中的高频词。华为常务董事、华为云CEO张平安表示，中国的AI发展离不开算力基础设施的创新，并且要敢于开放行业场景，让AI在行业应用上领先。</p><p>蚂蚁集团董事长兼CEO井贤栋认为，在大模型时代，智能体是新的应用范式，蚂蚁也在探索智能服务新可能。“我们相信，通过专业智能体的深度连接，Al会像互联网一样，带来服务的代际升级。”</p><p>WAIC的常客，中国工程院院士，之江实验室主任，阿里云创始人王坚在今年这样解释人工智能在企业端应用的发展和变化：“在一开始，小企业会觉得AI是革命的工具，大企业一定会觉得AI是工具的革命。当大企业意识AI可以作为革命的工具时，一轮大的变革将会到来。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_014c89d8774d4255863bfa0f87892cac@000000_oswg104546oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△图源：主办方供图</p><p>沿着AI发展的脉络，2018年、2019年，WAIC希望解答“AI是什么”；2020年，在“云端峰会”上，AI应用已开始被热议；2021年AI赋能数字化转型、数字城市受到关注；2022年元宇宙、2023年大模型等红极一时的话题都轮番成为了WAIC的主角……到今天，BATM的“掌门人”们已罕见再如第一届大会般齐聚一堂。不过AI是一个常谈常新的话题，今年还将诞生哪些“名场面”？且拭目以待。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MjEyODE4MA==&amp;mid=2653314807&amp;idx=1&amp;sn=20fe0e37e3bc26811707a1b6caade806&amp;chksm=bcee6f17a1460468439c6fc7c594a4fc177f24406f002dafbc11416194f06599d4b7e3d41d86&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“时代周报”（ID：timeweekly）</a>，作者：郭美婷，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849252018293634</id>
            <title>谷歌研究人员发论文揭示：GenAI正用虚假内容侵蚀互联网</title>
            <link>https://www.36kr.com/p/2849252018293634</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849252018293634</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 11:14:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式人工智能, 滥用, 虚假内容, 互联网
<br>
<br>
总结: 谷歌的研究团队发表论文指出，生成式人工智能滥用虚假内容侵蚀互联网，谷歌自身也在推广这项技术。论文分析了滥用案例，发现生成式人工智能降低了散布虚假内容的难度。研究者指出，大多数用户利用这项技术混淆真实性与欺骗，影响公众意见、促进欺诈行为。研究呼吁政策制定者、研究人员和行业领袖共同努力减轻生成式人工智能滥用的问题。 </div>
                        <hr>
                    
                    <p>腾讯科技讯 7月5日消息，据国外媒体报道，谷歌的研究团队日前发表了一篇引人注目的论文，指出生成式人工智能正在用虚假内容侵蚀互联网--这一现象颇具讽刺意味，因为谷歌自身也在积极向其庞大的用户群体推广这项技术。</p><p>这篇题为《生成式人工智能的滥用：现实世界数据中的策略分类与洞见》（Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data）的论文，由谷歌旗下的人工智能研究实验室DeepMind、安全智库Jigsaw以及慈善机构Google.org的研究人员联袂撰写。论文通过对2023年1月至2024年3月期间媒体和研究论文报道的约200起滥用案例进行分析，对生成式人工智能工具的滥用方式进行了分类和研究。</p><p>与OpenAI首席执行官山姆·奥特曼（Sam Altman）或埃隆·马斯克（Elon Musk）关于通用人工智能可能给人类带来的“生存风险”的警告不同，谷歌的研究更侧重于生成式人工智能目前对现实世界造成的具体伤害，以及这种伤害在未来可能进一步加剧的问题。具体而言，生成式人工智能极大地降低了在互联网上散布生成的含有虚假内容的文本、音频、图像和视频的难度。</p><p>谷歌研究团队使用的方法可能未充分统计人工智能生成内容所带来的伤害案例。不过该论文中最具启发性的发现是，这些伤害及其对“公众信任的侵蚀”，正如研究者所指出的：“既非公然恶意，也未明显违反这些工具的内容政策或服务条款”。换言之，此类内容的存在实际上是生成式人工智能的一个特点，而非缺陷。这项尚未经过同行评审的研究，揭示了绝大多数生成式人工智能用户正利用这项技术来“混淆真实性与欺骗之间的界线”，通过在互联网上发布伪造或篡改的人工智能生成内容，例如图像或视频。</p><p>研究人员总结称：“在现实世界中的滥用案例里，操纵人类形象和证据伪造是最普遍的策略。这些策略大多数是为了明显的目的而部署的，比如影响公众意见、促进诈骗或欺诈行为，或者是为了创造利润。”</p><p><strong>读完这篇论文，读者难免会得出结论：所谓的“生成式人工智能的滥用”听起来更像是技术在按设计目标正常运作。</strong>人们利用生成式人工智能制造大量虚假内容，因为这项技术在这方面表现出色，结果导致互联网上充斥着由人工智能生成的低质量内容。这种情况在很大程度上是由谷歌自身促成的，它不仅允许虚假内容的扩散，有时甚至是这些内容的直接来源，无论是伪造的图像还是不实信息。研究人员指出，这种局面也在考验着人们辨别真假的能力。他们指出：“同样，大规模生产低质量、类似垃圾邮件和恶意合成内容，可能会增加人们对数字信息的普遍怀疑，并使用户在验证任务上感到不堪重负。”</p><p>研究论文中另一个值得关注的缺陷是，谷歌本身就是迅速开发和部署可能造成伤害的生成式人工智能工具的主要公司之一，最广为人知的例子是谷歌搜索中的AI概述回答，它曾错误地建议用户用胶水将芝士固定在披萨上。然而，研究人员并未对此进行深入探讨，而是指出所有参与或受影响的各方都应该采取更有效的措施。他们强调：“研究结果凸显了采取多管齐下的方法来减轻生成式人工智能滥用的必要性，这需要政策制定者、研究人员、行业领袖和民间社会的共同努力。”</p><p>本文来自<a href="https://new.qq.com/rain/a/20240705A03J1Q00" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：无忌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849234639391364</id>
            <title>贾佳亚团队新作：10k数据让大模型数学能力超GPT-4</title>
            <link>https://www.36kr.com/p/2849234639391364</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849234639391364</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 11:04:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据, 模型, 优化策略, 推理步骤
<br>
<br>
总结: 港中文贾佳亚团队提出了基于推理步骤的大模型优化策略，通过只需10k数据就能让大模型的数学成绩增长5.6%。他们的方法类似于老师教学生一样优化大模型，让Qwen-72B模型在多个数据集上进步明显，同时也获得了更强的长链条推理任务能力。作者还提出了基于推理步骤的直接偏好优化——Step-DPO，将每个推理步骤视为一个基本单元，从更精细的角度提升模型的多步推理分析能力。 </div>
                        <hr>
                    
                    <p><strong>只要10k数据</strong>，就能让大模型的数学成绩增长5.6%。</p><p>港中文贾佳亚团队推出了基于推理步骤的大模型优化策略，能够像老师教学生一样优化大模型。</p><p>利用这种方法，72B Qwen模型的数学成绩超越了GPT-4、Gemini1.5-Pro和Claude3-Opus等一众闭源模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_03a088a664a1475a9c3e81a2a4d150ff@46958_oswg327815oswg1080oswg703_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>老师在纠正学生错误时，不会只告诉学生最终答案错了，还会告知具体哪个步骤错了，以此快速纠正其错误。</p><p>贾佳亚团队正是学习了这一特点，将斯坦福团队推出的DPO（直接偏好优化）进一步细化，形成了逐步应用的策略<strong>Step-DPO</strong>。</p><p>该方法让Qwen-72B模型在多个数据集上进步明显，同时也获得了更强的长链条推理任务能力。</p><h2><strong>像教育学生一样训练大模型</strong></h2><p>如何强化推理能力，一直是大语言模型领域的重要问题之一。</p><p>常见的思维链策略通过在输入提示词部分添加“Let’s think step by step.”，来使模型在输出中完成逐步推理，但对于复杂的问题，仅通过修改提示词不足以引导模型正确解决问题。</p><p>由于复杂问题涉及的推理过程较长，有时包含数十个推理步骤，一旦其中任一步骤出错，就难以得到正确的结果。</p><p>此外，现有方案旨在通过监督式微调（SFT）阶段增加问答数据以实现更好的对齐。</p><p>然而，当SFT数据达到一定数量时，模型经常出现幻觉，性能也随之趋于饱和。</p><p>一个潜在的原因是，随着偏好输出的概率上升，非偏好输出的概率也会随之增加。</p><p>为了抑制幻觉，提升模型的事实性，斯坦福大学提出了直接偏好优化方法，其工作原理是创建基于人类偏好对的数据集，每个偏好对都包含一个输入提示、偏好输出以及非偏好输出。</p><p>然后对语言模型直接进行微调，最大限度地提高生成的可能性，并减少输出的可能性。</p><p>因此，DPO的优化目标为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_7ad9558d4b5246b7990aa995a1f65f8d@46958_oswg14006oswg932oswg78_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中πθ与πref分别表示当前微调模型以及参照模型。</p><p>但在长链条推理任务中，DPO无法准确判断推理过程中的错误步骤，从而无法聚焦关键出错步骤。</p><p>如下图所示，基于DPO的模型在训练过程中无法准确判断推理步骤正确与否。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_c223cae6548b4165959c4b15c1c262fd@46958_oswg143747oswg1080oswg519_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此，作者提出了基于推理步骤的直接偏好优化——<strong>Step-DPO</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_e84cfd9221a245b885aba108c910b56d@46958_oswg102869oswg1080oswg241_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就像老师在纠正学生错误时，不会只告诉学生最终答案错了，<strong>还会告知具体哪个步骤错了</strong>，以此快速纠正其错误。</p><p>与此类似，Step-DPO不再像DPO从整体上对比答案，而是<strong>将每个推理步骤视为一个基本单元</strong>，并且对比单个推理步骤，从更精细的角度提升模型的多步推理分析能力。</p><p>Step-DPO的优化目标为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_4567fb1a4f0a4efabc50949b49883d1f@46958_oswg26173oswg922oswg227_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，作者还提出基于模型自生成的数据处理流程。如图所示，该流程包含以下三个步骤：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_3ac726b1d4174e3380b0a07e55a81fae@46958_oswg261508oswg1080oswg599_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第一步是<strong>错误收集</strong>。</p><p>首先，给定一组数学问题D0=(x,y∧)，其中x是数学问题，y∧是其真实答案。</p><p>然后，使用初始模型πref来得到每个数学问题x的答案。</p><p>在进行模型推理之前，需要添加思维链（CoT）前缀作为提示，以确保模型的推理结果被结构化为多个推理步骤，每个步骤均以“Step i：”开始。</p><p>经过模型推理可得到每个数学问题x的推理结果y，然后选择与真实答案y∧不一致的那些结果，并汇总得到数据集D1：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_2aece91b554f4cdcb5042cb5dd73e9d5@46958_oswg3463oswg324oswg45_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第二步是<strong>错误步骤定位</strong>。</p><p>每个错误推理结果y都呈现为一系列推理步骤的序列y=s1,s2,…,sn，随后需要人工或利用GPT-4验证每个推理步骤的正确性，直到找到第一个错误步骤sk，并记录其步骤编号。</p><p>然后将sk选为错误的推理步骤slose，从而得到D2：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_1a6a15f778494e45b08c220b51ec68ea@46958_oswg4994oswg456oswg35_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后是<strong>错误步骤修正</strong>。</p><p>为了获得D2中每个样本对应的正确推理步骤，需要对模型πref进行推断，使用提示x和前面的正确推理步骤s1~k-1来采样多个输出ycont，此过程可以表示为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_c03e29df29bb4028933490645303ff15@46958_oswg4079oswg360oswg64_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随后保留ycont中那些与真实答案一致的输出，并将其中的第一个推理步骤作为swin，最终得到数据集D：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_94fd34fe0cd540ea83df42eaaeea69cb@46958_oswg5426oswg479oswg58_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>下图展示了一个数据样本示例。值得一提的是，该数据准备流程无需大量的人工介入，人类或GPT-4只需要判断给定推理步骤是否正确，而无需亲自撰写答案来修正错误。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_ed2a1c12c79b4bab9a3e8c49b30561ac@46958_oswg192804oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>10k数据带来数学能力大幅提升</strong></h2><p>Step-DPO可以在SFT模型或现有的开源Instruct模型上进行微调，仅通过10K数据以及数百个训练步数，即可取得大幅度的数学能力提升。</p><p>如下图所示，在Qwen2-7B-Instruct模型的基础上进行Step-DPO可在MATH测试集上<strong>获得5.6%准确率的提升</strong>。</p><p>在Qwen2-72B-Instruct模型的基础上进行Step-DPO，可在MATH和GSM8K测试集的准确率分别达到70.8%和94.0%，<strong>超过一系列闭源模型</strong>如Gemini-1.5-Pro、GPT-4-1106，以及Claude-3-Opus。</p><p>除此之外，在难度较高的包含数学<strong>竞赛题</strong>的Odyssey-MATH榜单上也有显著提升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_af3e42dca5034385bd82e3bf86d61535@46958_oswg271477oswg1080oswg870_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>经过Step-DPO之后，模型更加鲁棒，减少幻觉的产生，在推理过程中也不容易出错。如以下两个例子所示。</p><blockquote><p>假设h(x)=f-1(x)，如果h(2)=10，h(10)=1，h(1)=2，求f(f(10))。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_cf7cb2bae2194178a9f79e1355b52b6d@46958_oswg332460oswg1080oswg517_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>t的平方根大于2且小于3.5，满足这一条件的整数t有多少个？</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_1aca6bbbfdb84cdbb92903aa86aee9cd@46958_oswg370502oswg1080oswg569_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>即便是下图这道数学竞赛题，经过Step-DPO之后的模型也可以做对。</p><blockquote><p>在所有非增函数f:{1,2,…,10}→{1,2,…,10}中，有些函数有固定点，另一些没有，这两种函数的数量相差多少？</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_79f1230f789f45bcb38638aac19ad013@46958_oswg493226oswg958oswg2055_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前，该项目的代码，数据，模型，Demo均已公开至GitHub和Hugging Face，同时支持在线体验。</p><p>论文地址：https://arxiv.org/abs/2406.18629</p><p>GitHub：https://github.com/dvlab-research/Step-DPO</p><p>在线Demo：http://103.170.5.190:7870/</p><p>模型（HF）：https://huggingface.co/collections/xinlai/step-dpo-6682e12dfbbb2917c8161df7</p><p>数据（HF）：https://huggingface.co/datasets/xinlai/Math-Step-DPO-10K</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/6CnaOqg2i26fe7AXKaFr4g" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：港中文贾佳亚团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849205193886344</id>
            <title>人形机器人，在上海爆发</title>
            <link>https://www.36kr.com/p/2849205193886344</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849205193886344</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 10:54:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人造机械, 人形机器人, 智能机器人, 人形生物诞生
<br>
<br>
总结: 人类对于人造机械的想象和思考源远流长，从古希腊神话到中国古代故事，人形机器人在当代得到了巨大发展。在2024世界人工智能大会上，展示了各种智能机器人，其中包括了多款人形机器人，展示了他们的技术和功能。这些人形机器人具有高度仿生的外观和多种功能，展示了人类对于人造生物的探索和创造力。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_16c80533658d4cd29cb6734cdfe67fb6@46958_oswg313903oswg887oswg514_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>人类对于人造机械的想象和思考是源远流长的。&nbsp;</p><p>希腊神话中出现了赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚这样的机械人和人造人。根据列子辑注的《列子·汤问》记载，中国西周时期也已经出现了偃师造人的故事。&nbsp;</p><p>7月4 日，当2024世界人工智能大会在上海拉开帷幕，展前阵列出18款人形机器人时，带来的震撼是难以言喻的。本次现场展出了45款智能机器人，其中人形机器人有25款。&nbsp;</p><h2><strong>&nbsp;01人形生物诞生</strong></h2><h3><strong>特斯拉二代人形机器人Optimus</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_76b7a1d48630453e8209a7dcb9231f58@000000_oswg1760667oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现场，人影攒动。 二代Optimus搭载的是与特斯拉车辆同源的AI 技术。 二代Optimus在直立行走的基础上，行走速度提升了30%； 其手指还“进化”到除了感知和触觉，可以在轻握鸡蛋和搬运重物时做到“游刃有余”。&nbsp;</p><p>特斯拉预计明年开始限量生产人形机器人，将有超过1000个Optimus在特斯拉工厂帮助人类完成生产任务。&nbsp;</p><h3><strong>开源通用人形机器人“青龙”</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_06fd6f0e689e405997be0b1be9864f43@000000_oswg1312758oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>人形机器人（上海）有限公司当日发布了中国首个全尺寸开源通用人形机器人，该款机器人身高185cm，体重80kg，拥有高度仿生的躯干构型和拟人化的运动控制，支持多模态机动、多模态感知、多模态交互和多模态操控，全身多达43个主动自由度，最大关节峰值扭矩400N.m，算力支持400TOPs。 负载40公斤时能以1m/s的速度行走。&nbsp;</p><h3><strong>乐聚“夸父”（KUAVO）机器人</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_19be7dc62ec045bd8c9e58cb576d3b77@000000_oswg1459547oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“夸父”（KUAVO）是国内首款搭载鸿蒙操作系统的全尺寸人形机器人，也是国内首款实现产业化落地的全尺寸人形机器人，同样亮相展台。&nbsp;</p><p>夸父发布于2023年12月，重约45kg，全身26个自由度，行走速度最高可达4.6km/h，可快速连续跳跃，跳跃高度超20cm，搭载自研一体化关节和深度摄像头，可实现全方位视觉感知。&nbsp;</p><p>目前，夸父机器人已实现人形机器人小样本下的泛化操作，<strong>典型的成交案例包括与山东大学、北京通用人工智能研究院相关的科研合作。</strong></p><h3><strong>天链人形机器人T1</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_840b670f5b9c44fca805c9fe0a34d75d@000000_oswg1645943oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>身高约1.60米，全身自由度71个，人形机器人裸机仅重37公斤左右，含电池在43公斤左右，负重深蹲突破145kg。&nbsp;</p><p>工作人员介绍，<strong>这是目前行业内已知的最高水平，它可以做出一字马、跳跃、旋转、劈叉等动作，灵活性堪比舞蹈演员。值得一提的是，天链人形机器人T1全产业链自产自研。</strong></p><h3><strong>宇树科技通用人形机器人H1</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_df8ddea874654c3480c1df48e6cf23c0@000000_oswg1615094oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这是全球首款原地后空翻功能的通用人形机器人。 后空翻这种高难度动作的实现，不仅展示了机器人在平衡控制和动力系统方面的卓越性能，更预示着未来人形机器人可能在复杂地形和极端环境中发挥重要作用。 <strong>目前，“宇树H1”机器人已经实现工业场景下的功能应用。</strong></p><p>宇树科技CEO王兴兴表示：“具身智能是实现AGI的最有效途径，OpenAI的大方向大概率是错的。”他认为，<strong>未来5-10年肯定会有很大的技术突破，只有尽可能地相信AI，才会有更好的未来。</strong></p><h3><strong>开普勒通用人形机器人K1</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_8bd9e34b69354c68bf8624913cfc4435@000000_oswg1825332oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>该机器人身高175cm，体重70kg，全身具备40个关节自由度、80多个传感器，还搭配了中国电信的星辰大模型，使之具备了复杂地形行走、智能规避障碍等多种功能。&nbsp;</p><p><strong>“我们已经具备了商业化应用的潜力，计划在今年10月份进行小批量生产。”&nbsp;</strong> 开普勒CEO胡德波表示，目前来自物流、汽车制造、冶金等行业的意向订单非常多，“人形机器人商业化的节奏要比预期更快。”&nbsp;</p><h2><strong>&nbsp;02人形机器人到底多少钱？</strong></h2><p>对于何时能够进入消费者市场，很多展商表示还有一段距离。在这段距离中，成本是一个问题。<strong>对于消费者来说，当前人形机器人的价格过于昂贵。</strong></p><p><strong>诸如特斯拉二代人形机器人Optimus价格在2万美元（14万人民币）、达闼机器人报价39.9万元起、天链机器人价格在50万～100万元左右、“夸父”（KUAVO）机器人价格在60万-80万元人民币、宇树H1单台售价约65万元。</strong></p><p>除了明确表示未来目前是卖给个人的特斯拉，其他人形机器人的报价都在大几十万以上，并且如果需要装备完全的“大脑”、“小脑”、“灵活手”、“激光雷达”，价格上百万的可谓是轻轻松松。昂贵的价格对于消费者来说并不友好。&nbsp;</p><p><strong>另一方面还是安全的问题。</strong> 在现场交流的过程中，大多数厂商都表示对于“安全”还有一定顾虑。例如，在非密切接触的场景下，人们可以与机器人保持一定的距离，在保证自身安全的前提下观察其作业。但是，在养老或人员帮扶等需要肢体接触的场景中，人形机器人的安全性和风险问题不可小觑。&nbsp;</p><p>从人形机器人的应用来看，大多数应用还处于点对点的模式，当前的应用场景多为：科研研究、智能巡检、智能制造、仓储物流、户外作业等。&nbsp;</p><p><strong>工业将是人形机器人首个大规模应用的主流场景。</strong></p><p>小米集团高级副总裁曾学忠预判，未来智能工厂将由三种劳动力构成：70%的自动化设备、20%的人形机器人、10%的人类。人类负责的是价值判定与挖掘，人形机器人则负责实现柔性制造、跨系统协同。三种劳动力协同作业，将重新定义“工人”与“工厂”。&nbsp;</p><p>因此，人形机器人的落地会先从进入一个场景（如工业）、实现多个功能开始，拓展到融入多个场景（物流、农业、消费等）、实现复杂功能，然后渐渐走进千家万户。&nbsp;</p><h2><strong>&nbsp;03关于具身智能的讨论</strong></h2><p>每一家展商的标语中，都在宣称自己在做“具身智能”，是“AI的化身”，是未来的“新物种”。&nbsp;</p><p>在这里，想花费一些笔墨讨论一下“具身智能”的概念。&nbsp;</p><p>去年，北京市科委、中关村管委会等部门联合印发《北京市促进通用人工智能创新发展的若干措施（2023—2025年）（征求意见稿）》中提出，探索具身智能、通用智能体和类脑智能等通用人工智能新路径，推动具身智能系统研究及应用，突破机器人在开放环境、泛化场景、连续任务等复杂条件下的感知、认知、决策技术。&nbsp;</p><p>何为具身智能？MBA智库百科对其的定义，指的是通过创建软硬件结合的智能体，可以简单理解为各种不同形态的机器人，让它们在真实的物理环境下执行各种各样的任务，来完成人工智能的进化过程。&nbsp;</p><p>实际上具深智能与GPT-4的不同在于，GPT-4等是被动学习，即我们向机器提供什么样的数据（人类标签或产生的数据）机器就学习什么。而具身智能是一种全新的自主学习，能自我感知和理解物理世界，<strong>就像人类感知和理解外界环境能力一样。</strong></p><p>总而言之，<strong>具身就是具有身体的智能体，英文是 Embodied AI，就是说给智能体赋予一个身体，这就是具身智能。</strong></p><p>随着过去两年，大语言模型的进展，我们看到自然语言中通用智能是可以实现的。计算机视觉领域在 3D 理解和开放语义识别也获得了巨大进展，通用具身智能是业内都在期待的突破。&nbsp;</p><p>在世界人工智能大会上，宇树科技CEO王兴兴表示，对于具身智能而言，能够理解时间、空间以及物理规律的世界模型非常重要，“现在的大语言模型等很像活在梦里”，<strong>AGI需要有实物机器人的物理交互才能加深模仿和强化学习，同时也需要参与到人类的生活中，来体验和理解人类的情绪和性格。</strong></p><p>从未来来看，具身智能将会是一个智能大脑配合多种不同构型的身体完成物理世界的不同任务。也正因此，业内一直在讨论一个很有意思的问题：<strong>具身智能必须是人形吗，必须是双足吗？靠机器狗，可不可以实现具身智能呢？</strong></p><h2><strong>&nbsp;04人形机器人投资热</strong></h2><p>2024年上半年，人形机器人赛道融资热度持续高涨。&nbsp;</p><p>根据不完全统计，<strong>2024年上半年全球人形机器人领域融资事件超过22起，融资金额超过70亿元。</strong>美国人形机器人初创公司Figure AI凭借6.75亿美元（折合人民币约49亿元）的巨额融资领跑全球，宇树科技则凭借近10亿元人民币融资登顶中国国内人形机器人融资榜榜首。&nbsp;</p><p>在A股市场，人形机器人概念股的表现同样亮眼。7月4日，人形机器人概念股在开盘后直线拉升。Wind数据显示，恒工精密开盘后不久收获20%涨停，雷赛智能、世运电路等随之涨停，斯菱股份、步科股份、北特科技、江苏雷利等跟涨。&nbsp;</p><p>不过，现场交流的多位业内人士都不约而同地表示：倘若机器人未来大规模应用，从制造业到服务业，真正走进公众生活，实现陪护老人、陪教儿童等，还有许多“软硬件”待升级。包括看得见的零部件灵敏度、安全性等，看不见的数据隐私、算法偏见、伦理道德等，都需要有更全面、更优化的解决方案，保障新技术、新产品的安全和可持续发展。&nbsp;</p><p>正如图灵1950年在《计算机器和智能》中写到：“目光所及之处，只是不远的前方，即使如此，依然可以看到那里有许多值得完成的工作在等待我们。”&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247730395&amp;idx=1&amp;sn=d6454cba85ec814d3235342a13e1caed&amp;chksm=c04376e9693bf4aff7905c916026c577e23d85a3255e18389c5685d0b18bd2998dffd850459a&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：九林，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849205940456329</id>
            <title>OpenAI断供中国，微软云却留了后手</title>
            <link>https://www.36kr.com/p/2849205940456329</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849205940456329</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 10:53:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, ChatGPT, 国产大模型, 微软云
<br>
<br>
总结: 本文讲述了OpenAI在国内API调用方面的变化，以及AI创业者们对于国产大模型和OpenAI的选择。随着OpenAI断供ChatGPT的调用，国内AI创业者开始转向国产大模型，价格差异巨大。微软云也在中国市场发力，提供OpenAI服务。国产大模型在价格战中逐渐取代OpenAI，成为AI创业者们的新选择。 </div>
                        <hr>
                    
                    <p>“雷声大，雨点小”，AI创业者张庆这样形容OpenAI将从今年7月9日阻止国内API（应用程序接口）调用的通知。</p><p>在他看来，尽管“国内2023年头部的大模型产品，一半以上都是'套壳'ChatGPT（即调用开源大模型API提供服务，而非自研模型）”，OpenAI断供ChatGPT的调用，并未迎来想象中的行业地震。</p><p>实际上，早在2024年6月，就职某AI创企的前端开发傅涵，便将产品调用的大模型，从GPT更换为了moonshort。</p><p>5月在产品刚刚上线调试时，傅涵选择调用GPT 4.0。毕竟相比国产大模型，调用OpenAI的“价格相差无几，但处理速度更快，反馈结果更好”。</p><p>但5月过后，大规模调用OpenAI的高成本之下，随着国产大模型开始0元购，傅涵发现，<strong>“国产大模型的文本处理在一定范畴内已经不输GPT 4.0”，面对几十倍、甚至上百倍的差价，傅涵花了两周，就将接口转向了国产大模型。</strong></p><p>巨大价格差异带来的诱惑，无疑让AI创业者们“真香”。“同样100万的Tokens（大模型文本最小处理单位），大概能供100个用户使用5个月，购买GPT 4.0，需要100元，但国产大模型DeepSeek只需要一元钱。”傅涵告诉字母榜（ID：wujicaijing），如今在头部大模型厂商的价格战之下，国内的AI创业者使用国产大模型，单月的Tokens成本相比起调用GPT 4.0，可能相差上百倍。</p><p>随着OpenAI将断供的消息传出，大厂们纷纷出动，开始“截胡”开发者。截至目前，包括智谱AI、零一万物、月之暗面、百川智能、商汤科技，以及百度、阿里、腾讯等，均已推出了OpenAI零成本迁移计划。同时部分大模型厂商，还贴心地附赠1千万乃至1亿Tokens。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_b7f82cecb1eb488e9e51c6007a9d9011@000000_oswg477473oswg1002oswg1522_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“现在国产大模型的SDK都是兼容OpenAI格式的，即使切换也不过几行代码的事情。”傅涵表示。</p><p>不过，对于急着商业化、想借此抢夺OpenAI套壳用户的国产大模型来说，它们还面临着ChatGPT背后的东家微软云的竞争。</p><p>有微软云员工告诉字母榜，全球包括中华区的微软云员工，2024年都会重点推OpenAI这一项目，而目前，通过微软云 Azure接入OpenAI技术服务的企业，仅在中国，每天都有流量的企业超过3000家，注册用户上万，这其中就包括腾讯、字节、华为等大厂。</p><p>OpenAI这波热度，对于国产大模型来说，蹭上容易，但吃到嘴里还有点难。</p><h2><strong>A</strong></h2><p>OpenAI断供冲上热搜之下，靠着ChatGPT套壳“吃饭”的AI创业者们，却颇为冷静。</p><p>“通过微软云，7月9号之后，也可以用中国IP访问OpenAI，只要从微软官方渠道选定代理商签署三方协议，就能用Azure企业账号自助申请Open AI服务。”上述微软云员工告诉字母榜。在北京，可以选择昆联，在深圳有SoftwareONE硕软等公司，这些微软的代理商价格也完全统一。</p><p>作为OpenAI实际上的大股东，微软云早就盯上了中国市场。“在ChatGPT爆火前，微软云已经在中国发展起了庞大的ToB生意，微软做ToB的相关资质，也已经储存在各大公司的知识库里，”张庆表示，如今从微软云购买OpenAI 的接入服务，甚至不需要在原本的ToB业务上额外进行支付。</p><p>2023年，趁着ChatGPT的热度，张庆接入OpenAI，做了一款AI占星的小程序，“每天几十个新用户付费”，利用ChatGPT提醒每日运势、提供恋爱占星分析，随着用户数增加，访问激增，“ChatGPT的节点在国外，一到高峰期，访问速度就会慢下来”，这也促使张庆在2024年6月，成为了微软云的企业用户。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_197c5cd13ad842128f10aa49db925c66@000000_oswg85210oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>想在国内接入ChatGPT，只需要注册企业版账号，满足每月至少消耗1000美金的门槛，按照一年12000美金的费用，提前支付3年，即360000美金（约25万元人民币）。</strong>而由于张庆在香港注册了分公司，他还可免去6%的相关税务。</p><p>不同于张庆，在产品5月上线初始，傅涵为一款交通安全方面的AI产品接入ChatGPT接口，而除了不稳定的节点之外，价格也成了仍在冷启动阶段的AI创业者们，必然的考量因素。</p><p>“之前大模型没降价的时候，调用ChatGPT的价格和使用国内大模型几乎没有差别，而现在，国产大模型和ChatGPT的价格差，已经达到了几十倍，甚至上百倍。”傅涵告诉字母榜，在产品刚刚上线时，经过测试，GPT 4.0最符合产品的响应需求，而尽管国产大模型的反馈精准度、响应速度“不如GPT 4.0”，国产大模型降价之后，他还是选择了切换模型。</p><p>猛打价格战的国产大模型，靠着成为“ChatGPT平替”吸引着市场上的AI企业和套壳用户们。“据我了解，字节大模型已经便宜到了离谱的程度，如果做一些小场景，用字节的大模型，成本也很合适。”傅涵表示，测评了市面上的国产大模型后，在“不对输出结果有过高期待的情况下”，仅满足日常对话和处理要求，DeepSeek便宜大碗，“100万 tokens才1块钱，还能兼容OpenAI的SDK格式”，MiniMax则速度很快，适合特定需要速度的场景，Kimi在便宜之外，适合需要输出长文本的应用场景。</p><p>成为OpenAI平替，正在成为国产大模型们争夺的下一个场景。</p><h2><strong>B</strong></h2><p>在被国产大模型平替之前，OpenAI，一度是国内AI创业者的不二之选。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_a7a6a835557c407e965b62dbf0f0c8bb@000000_oswg25964oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“准备好个体执照、服务号认证、域名，租一台国内服务器，一台国外服务器，大概2000块就能做一个套壳ChatGPT的小应用。”张庆道。</p><p>2023年，在ChatGPT热度正劲的当口，还未翻车的李一舟，199元的“每个人的人工智能课”售出了25万份，OpenAI不仅撑起了AI知识博主李一舟们，也撑起了赶来套壳ChatGPT的张庆们。</p><p>一年内，张庆从AI占星到AI合成照片，连续推出了近10款ChatGPT套壳小程序。每款小程序，张庆只需要利用OpenAI的API接口，就能完成占星的牌面解读，图片的后期合成。</p><p>借助小红书、抖音等社交平台，张庆会去社交平台发安利贴、去抖音做节奏混剪，还会去AI博主的账号评论下做“截流”，即“在评论区，假装普通用户，种草xxAI很好用。”</p><p>在张庆的操作下，每天会有300-400个用户进入他的小程序，按照5%的付费率，每月30-50元的会员费用，就能把成本几元钱的API账号卖给几百人，<strong>张庆的利润率能达到100%，单日收入过万“轻轻松松，哪怕只有几千粉丝，一天也有固定上百元的利润”。</strong></p><p>最火爆的时候，张庆准备了3个以上的个体执照，“交易量大了容易被系统拦截风险，我都会准备3个以上的执照轮替支付。”</p><p>2023年，在国产大模型奋起直追ChatGPT，无瑕推出AI应用的同时，张庆这样借用ChatGPT端口，2-3个人就能日入过万的小作坊，赚的可谓盆满钵满。</p><p>在2024年创投十年高峰论坛上，金沙江创投主管合伙人朱啸虎指出，北欧的Klarnr，通过“套壳”，优化了电话中心客服端，减少了700个客服岗位，给企业带来了每年4000万美金（近3亿元人民币）的利润增量。</p><p>而作为AI搜索头部应用，2022年12月推出的Perplexity，&nbsp;也一度依赖OpenAI的 GPT 3.5模型，对此，Perplexity CEO Srinivas则直言，“拥有十万用户的套壳产品，比拥有自有模型却没有用户更有意义。”</p><p>不过，随着大模型厂商开始推出APP应用，包括字节豆包、腾讯元宝、MiniMax 海螺AI等等应用，张庆们的好日子也到了头。</p><p>2024年5月前，张庆的一个小程序“每天至少能有数百名新用户，付费用户几十个”，而随着大厂集成式的APP一推出，张庆小程序的新增用户面临断崖式下跌，“在小程序里需要付费才能生成的图片，大厂可以直接免费，而且功能场景做得更丰富，”相比之下，张庆仅仅针对某一功能开发的小程序，显得颇为鸡肋，也正是因此，现在“每天进入小程序私域的用户数量基本砍半。”</p><p>即便是张庆擅长的抖音等引流平台，也早已成了字节豆包的天下，更不用说MiniMax把海螺AI的广告甚至打到了虎牙、斗鱼，面对砸钱推应用的大厂，张庆直言“扛不住”。</p><h2><strong>C</strong></h2><p>不管是通过微软云接入OpenAI，还是切换国产大模型，对于套壳大模型的AI创业者来说，2023年OpenAI爆红带来的流量红利正在消逝，已是确定的事实。</p><p>在2023年，张庆某个展示AI合成图片的混剪视频在抖音成了爆款，“视频发布当天，就有近千人涌入了小程序私域，连续一周的日流水都过2万元。”但如今，随着AIGC从新社交货币变成“老话题”，张庆明显感受到，“在抖音上同类的AI产品越来越多，但流量却越来越差。用户没有新鲜感了。”</p><p>2024年，从妙鸭到元宝，00后的黄章告诉字母榜，之前，每有一个新的AI大模型或者AI应用发布，她都会下载尝试，第一次使用Midjourney绘图，她兴奋地发了3篇小红书笔记。而随着大模型狂飙到200多个，字节、腾讯、阿里、百度都推出了自己的大模型应用，黄章既难以分清这些大模型有哪些具体差异，又愈来愈兴趣缺缺，最后“都是试用后就很少再打开”。</p><p>即便是套壳OpenAI的经典产品，如PDF.ai，其创始人 Damon Chen在2023年12月仍发帖称PDF.ai 营收已经突破 6 万美元，随后2024年2月，Adobe官方不仅直接在产品内集合了AI功能，同时还砸钱将PDF ai 的相关关键词买了下来。</p><p>仅仅一年半，OpenAI的API红利，便已经消退。随着国内大模型底层能力提高，头部大厂们纷纷挤入AI应用层，争抢仅剩的流量，对于此前套壳的开发者来说，他们的产品、运营面临着更高的要求。试图基于某个开源大模型的微调做出“大爆款”的可能性越来越小。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_d3daae87b8974b4caa48890b2eb095d6@000000_oswg189084oswg1022oswg681_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“可以考虑针对企业自身业务的特定场景去做模型，”傅涵表示，对于开发者来说，拥有自己开发的模型，无疑能把稳定性和主动权全掌握在自己的手里，避免出现访问限制等等不可控的意外因素。</p><p>不过，拿了700万元的天使投资，从某头部大厂出走创业的Bruce告诉字母榜，目前他们正在开发自己的AI旅游规划产品。在产品开发期，项目的设想也要基于“大厂会不会做”。一开始，基于合规需要，他就选择了接入国内大模型（智谱清言、通义千问），但即将进入产品冷启动阶段，他最焦虑的仍是，“到底有没有用户去使用？怎么让更多的用户知道这款产品？”</p><p>不同于家大业大的大厂，在@小布Bruce的账号内，Bruce表示，初创AI公司往往没有多余的人力和成本可以投入，最好去找到大厂不会做，或者做得不够精细的需求场景。但<strong>“投资人的耐心已经不够了”</strong>。上线后加速奔跑成为了Bruce们的必然之选。</p><p>不过，争着成为OpenAI平替的国产大模型，日子也并不好过。</p><p>“去年还在专注提升文本处理的月之暗面，今年招聘了不少字节的人去做增长，还是移动互联网的打法，”Bruce表示，“大厂的商业化焦虑也不少。”</p><p>OpenAI断供在即，某头部大厂AI业务的员工则告诉字母榜，“公司股价降了，口碑更差了”。显然，没有了OpenAI的竞争，大厂们想要赢得更多用户认可的难题，仍未减少。</p><p>（文中傅涵、张庆、黄章为化名）</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI2NjU1MTcwMA==&amp;mid=2247534260&amp;idx=1&amp;sn=5901681b86b075e094b05899dee6c85b&amp;chksm=ebe11e7a0ff88f9ad1aaa9e006f79eaf32a63e2f8586ec880724501e515b51a12bb8f3fec858&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“字母榜”（ID：wujicaijing）</a>，作者：马舒叶，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849152770230912</id>
            <title>腾讯发布大模型时代的AI十大趋势：走进“机器外脑”时代</title>
            <link>https://www.36kr.com/p/2849152770230912</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849152770230912</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 10:29:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 大模型技术, 机器外脑, AI发展
<br>
<br>
总结: 人工智能的快速发展使大模型技术成为各行各业的关键，正在重塑人类社会，成为可依赖的"外脑"。大模型在推理分析、创意生成和情绪智能方面取得实质性飞跃，使AI成为人类的"机器外脑"。随着大模型与人机协作的深入，个体创作的门槛降低，为社会各阶层带来前所未有的机遇。AI技术的发展将引领一个更加多元、开放和创新的新时代，同时人机对齐成为确保大模型安全与治理的核心议题。 </div>
                        <hr>
                    
                    <p>人工智能迅速发展，大模型技术成为赋能各行各业的关键。从算力底座、智力增强到人机协作，大模型正在重塑人类社会，成为可依赖的"外脑" 。&nbsp;</p><p><strong>日前，在2024世界人工智能大会•腾讯论坛上，腾讯研究院、上海交通大学、腾讯优图实验室、腾讯云智能联合发布了《2024大模型十大趋势——走进“机器外脑”时代》报告。</strong></p><p>报告基于科技行业发展、以及腾讯在AI领域的实践，从技术、应用、社会三个方面预测AI给经济社会带来的影响，通过10个关键性趋势勾勒出一个由大模型驱动的新未来。</p><p>报告指出，我们正在进入一个“机器外脑”时代。海量GPU和新一代大模型的组合起来，使人工智能在三个方向上有了实质性的飞跃：推理分析、创意生成和情绪智能。这意味着AI第一次拥有了类人的交互能能力，新一代AI正在成为人类的“机器外脑”，提供智力的外挂。</p><p>随着大模型与人机协作的深入，每个企业、每个人都有机会借助AI外脑实现自己的创意，实现智力平权。这一变革为社会各阶层带来了前所未有的机遇。伴随个体创作的门槛在降低，越来越多的个体还将借助大模型的“机器外脑”成为“斜杠青年”、“超级生产者”，甚至开启自己的“一人企业”。</p><p>可以预见，我们将迎来一个更加多元、开放和创新的新时代。与此同时，人机对齐成为确保大模型安全与治理的核心议题，将指引我们走向一个更加智能、高效和安全的未来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_cd3a8e5d66a94f23b952a7851d6990ba@000000_oswg177395oswg896oswg1179_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>走进“机器外脑”时代</strong></h2><p><strong>司晓&nbsp;</strong>腾讯副总裁 腾讯研究院院长&nbsp;&nbsp;</p><p>继ChatGPT开启大语言模型引领的新一轮人工智能革命以来，我们持续见证了人工智能领域技术的加速迭代，在过去的一年里众多公司如Google、Midjourney、Adobe以及Inflection等，都推出了创新的模型和产品，标志着大模型技术的成熟和大规模应用的开始。 今年2月，Sora的出现再次震撼了技术界，预示着我们可能很快就会见证更多令人兴奋的技术突破。 过去半年，我们以日为单位更新“AI每日动态”，这可以充分反映出来，AI技术的发展日新月异，以日来统计的话也是毫不过分的。&nbsp;</p><p><strong>在海量GPU和新一代大模型的加持下，人工智能在三个方向上有了实质性的飞跃。第一是推理能力。大型语言模型为人工智能带来了所未有的推理能力，极大地扩展了机器的认知边界。</strong>这种推理能力的跃迁得益于LLM在理解和生成自然语言方面的巨大进步。它们能够解析复杂的文本，提取关键信息，进行逻辑推理，并生成连贯、有见地的回应。这使得LLM能够处理各种知识密集型任务，如法律分析、市场研究、科学发现等，为个人和企业提供了强大的智能支持。以往人类智力难以企及的科学探索高地，都可以在AI的帮助下实现。例如，英伟达的“地球2号”项目，旨在创建地球的数字孪生体，将模拟整个地球的运行，以预测其未来变化。通过这样的模拟，可以更好地预防灾难，更深入地理解气候变化的影响，从而更好地适应这些变化。随着更高级的推理智能被开发出来，各行各业都将有机会拥有“机器之心”。AI 将引领新的服务模式，即<strong>“智力即服务”</strong>（IQaaS），该模式的一个重要特征将是机器的推理能力以在云端的方式、通过大模型提供给用户，“AI数字员工”将进一步成为现实。<strong>大模型使机器不再仅仅是执行简单任务的工具，而是成为了人类的"智力外脑"。</strong></p><p><strong>第二个方面是创意的生成。AI技术，尤其是AIGC，正迅速成为创意产业的一股颠覆性力量，为创意工作者提供了前所未有的生产力提升。</strong>今年2月，Sora的问世不仅是技术界的一次震撼，更是对未来创新潜力的一次大胆展示。AIGC技术通过文生文、文生图、文生视频等多种形式，使得创作、设计、分析等任务变得更加高效和易于实现。Sora和SUNO等现象级产品的出现，标志着AI生成内容的质量和多样性达到了新的高度。它们不仅让普通人能够创作出接近专业水准的音乐和视频作品，而且正在快速改变媒体、影视和音乐行业的生态。这些技术的普及，降低了专业技能训练的门槛，使得创意表达更加通用化。现在，只要有创意想法，人们就可以利用AI这个强大的"创意外脑"，将灵感转化为现实。AI的这种能力，不仅为专业创意工作者提供了强大的辅助工具，也为普通爱好者打开了创作大门，使他们能够轻松实现自己的创意愿景。随着AI技术的不断进步，我们可以预见，创意产业将迎来一个更加多元、开放和创新的新时代。</p><p><strong>另一个方向属于广义的情感陪伴。</strong>Dan模式的全网爆火，不仅展示了AI在情绪理解与表达上的巨大进步，更凸显了其与人类情感交流的无缝对接。GPT4o等高级AI系统的自然交互体验，让人与机器的界限变得模糊，仿佛科幻电影《Her》中的情感故事正在逐步成为现实。</p><p><strong>AI技术在满足人类情感需求方面展现出巨大潜力，扮演起了人们的“情感外脑”。</strong>AI聊天机器人提供的心理咨询服务，以其24/7的不间断陪伴，为需要帮助的人们提供了及时的情绪支持和专业建议。在儿童领域，智能玩具不仅陪伴孩子们成长，更通过情感交互，培养孩子们的情感认知和社交技能。随着情感智能技术的不断成熟，数字生命的议题也日渐升温。一些创新尝试正在探索如何利用数字技术复刻已故亲人，为生者提供缅怀与思念的渠道。尽管这一领域还面临着诸多法律和伦理挑战，但其在情感陪伴方面的应用前景无疑为AI赋予了新的温度和深度。AI不再仅仅是冷冰冰的生产力工具，它正在成为人类情感世界中的一个温暖伙伴。随着技术的不断发展和应用的不断拓展，我们有理由相信，AI将在人类的情感生活中扮演越来越重要的角色，为人们带来更多的陪伴与慰藉。</p><p>在本报告中，腾讯研究院基于科技行业发展和腾讯自身在AI领域的深耕，提出了10个关键性的趋势，试图理解全世界范围内正在发生的AI巨变。与往年一样，我们从技术、应用、社会三个方面来预测AI给经济社会带来的影响。我们正在进入一个“机器外脑”时代。加速技术为大模型行业的发展提供了算力的保障。随着大模型与人机协作的深入，个体创作的门槛进一步降低，越来越多的个体借助大模型外脑成为“斜杠青年”、“超级生产者”，甚至开启自己的“一人企业”。端侧模型的优化将大幅提升提升移动设备的体验，开启全新的人机交互方式。在工业领域，多模态通用感知技术正在提升生产力，而游戏与大模型的共生关系为Agent训练提供了新的舞台。开源模型的成熟，为技术共享与创新提供了强大的生态支持。最后，人机对齐成为确保大模型安全与治理的核心议题，指引着我们走向一个更加智能、高效和安全的未来。</p><p>这十大趋势共同勾勒出一个由大模型驱动的新未来。在这个未知和无限可能的时代，我们正在目睹AI如何将创意转化为现实，如何让个性化服务触手可及，以及如何为传统行业注入新的活力。AI的智力资源平权化，意味着无论背景或资源如何，每个人都有机会借助AI外脑实现自己的创意与梦想。这一变革不仅降低了创新的门槛，也为社会各阶层带来了前所未有的机遇。只要你拥有创新的想法并善于利用AI这一强大的外脑，即使在资源有限的情况下，也有可能以低成本创造出令人瞩目的成就。让我们一起走进这个“机器外脑”时代，见证人类能力的再次飞跃。</p><p><strong>趋势1：算力底座：迈向十万卡集群量变，速度和效率双提升</strong></p><p>生成式 AI 的训练集群规模，已步入万卡量级，正在向十万卡迈进。我们预测集成、网联和分布式是未来一段时间AI Infra核心硬件系统主要演变路线，新一代算力底座能够为机器外脑提供更强大的能量，使其能够处理更加复杂的任务，是新一代人工智能发展的生产要素。</p><p><strong>趋势2：推理分析：LLM带来推理能力跃迁，开启“智力即服务”</strong></p><p>大型语言模型（LLM）为人工智能带来了所未有的推理能力，极大地扩展了机器的认知边界。成为了人类的"智力外脑"，能够提供深入的分析、创造性的解决方案和复杂的决策支持，开启了“智力即服务”（IQaaS）的新时代。这种服务模式让人类的推理能力得以在云端实现，未来，智力将变成像电力一样的公共服务。</p><p><strong>趋势3：创意生成：AIGC应用爆发，降低专业创作门槛</strong></p><p>在这个精神追求引领物质需求的时代，AI的进步与社会文化的演变紧密相连，专注音乐和视频生成的AI平台应运而生，为热爱创作的“斜杠青年”们提供了更低门槛的工具，创建了自我表达和创意释放的新社区。</p><p><strong>趋势4：情绪感知：LLM赋予机器情感价值，打开人机陪伴市场</strong></p><p>情感智能是AI领域的新前沿。流式语音识别、多模态AI和情感计算等领域的突破为AI陪伴奠定了技术基础。兼具情商（EQ）与智商（IQ）的大模型将在未来2-3年内打开人机陪伴市场，未来人机陪伴市场将从以互动游戏、兴趣社区为主的年轻人市场，进一步破圈到包括各年龄层的更广泛用户群体。</p><p><strong>趋势5：智能制造：大模型提升工业新质生产力</strong></p><p>在工业领域，多模态大模型有望与当前普遍使用的专用小模型互补融合，并深度赋能工业制造的各个环节，从而推动生产制造的提质增效。通过优化生产流程、提高效率和质量，实现智能制造的新质飞跃。</p><p><strong>趋势6：游戏环境：大模型与游戏共生，打造Agent最佳训练场</strong></p><p>大模型与游戏环境结合，为AI Agent打造最佳训练场。游戏环境为Agent的训练提供了丰富的场景和数据，这不仅推动了游戏AI的发展，也为AI Agent在其他领域的应用提供了宝贵的经验。</p><p><strong>趋势7：移动革命：端侧模型优化带来应用入口变革</strong></p><p>端侧模型的优化正在改变我们与移动设备的交互方式。随着AI原生OS的发展，操作系统可能会发展成API直接调用的模式，减少对传统图形用户界面的依赖，端+云的混合模型可能更加符合未来长期的发展趋势。</p><p><strong>趋势8：具身智能：人型机器人与大模型共同进化，为外脑提供“躯体”</strong></p><p>机器人技术与大模型的结合，为机器外脑提供了“躯体”。大模型的利用极高提升了机器人的学习效率和执行复杂任务的能力，使物理动作更加细腻和灵巧。人型机器人有望成为人工智能的终极载体。</p><p><strong>趋势9：开源共享：开源生态实现降本普惠，推进外脑共享和迭代</strong></p><p>通过对国内外100多个开源大模型的分析，预计在未来2-3年内，AI开源将迎来繁荣发展，开源大模型从“可用”到“好用”演变。开源社区将推动全球知识分享与技术协同，也为中小企业提供低成本、高效率的解决方案。</p><p><strong>趋势10：人机对齐：人机对齐是大模型产品的重要竞争力，也关乎通用人工智能的未来</strong></p><p>随着AI模型越来越有类人能力，如何让AI模型的能力和行为与人类意图一致越来越重要。人机对齐是大模型产品成功的关键，也是实现通用人工智能（AGI）的前提。通过确保AI的行为与人类价值观和目标一致，我们可以构建更加安全、可靠和伦理的AI系统。</p><h2><strong>创新者预见</strong></h2><p>金沙江创投主管合伙人<strong>朱啸虎</strong></p><p>今年比较普遍的特点是都在积极拥抱AI，看怎么用AI赋能自己的产业，怎么用AI来降本增效，这是一个非常明显的趋势。我觉得不需要过度担忧被落下或追求高大上的概念，就在一个比较小的场景能尽快落地，尽快看到效果，这对很多企业来说更重要。尽快的商业化落地，先看到效果，先看到财务上的效果。然后再逐步跟着大模型、跟着整个技术的进步，扩张自己的场景，也会更有效一点。在具体的商业化场景上，真正深刻理解人，这是中国最擅长，也是中国最有价值的创业方向。</p><p>源码资本管理合伙人&nbsp;<strong>黄云刚</strong></p><p>一代人有一代人的机会，要相信热爱技术的年轻人。在生成式AI时代，技术、产品和基础设施正在同步快速发展，首先对快速变化的技术和趋势有很好的预判，再加上产品嗅觉和客户思维，才有机会做出杀手级的应用，而独特的产品才是胜出的关键。</p><p>晶泰科技董事长&nbsp;<strong>温书豪（腾讯青腾未来科技学堂）</strong></p><p>我相信人工智能就像互联网这个行业，一定会沉淀出一些最重要的应用场景，特别是生物医药和材料这个领域，会产生巨大的商业价值和社会价值。生命科学有可能进入到一个新阶段，以前是科学驱动，有很多不确定性，现在因为数字化的基础很好了，逐渐可以转变成工程学驱动。材料领域也将进入AI时代。我们可以预见AI驱动发现的可控核聚变，室温超导的材料有望解决能源的终极问题。</p><p>美图公司、董事长兼CEO&nbsp;<strong>吴欣鸿（腾讯青腾未来产业学堂）</strong></p><p>随着大模型的发展，AI应用将经历“点线面”三阶段。AI单点功能正逐步被串联成AI工作流。就像搭积木一样，AI会根据需要调用不同的功能，快速组成工作流，从而完成特定的任务。大模型也将基于工作流的数据反馈自动迭代。相信在不远的将来，AI工作流会进化成AI平台生态，便利每个人的工作和生活。</p><p>深言科技创始人&nbsp;<strong>岂凡超（腾讯青腾未来产业学堂）</strong></p><p>大模型将在两方面继续发展，一方面以OpenAI为代表的前沿企业和研究机构继续拓展模型规模，探寻Scaling Law的科学边界，另一方面更多的企业会面向特定任务或场景打造垂直模型，在效果、性能和成本实现更好的平衡，加快大模型的产品化和落地。前者从供给出发，后者从需求出发，更加贴合用户和场景，将爆发出更大、更多样化的机会。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_1e58a08eb0bb49af8be0a7016952a796@000000_oswg243614oswg1080oswg2536_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_a68aa0fe7668444d8c740bf573168bed@000000_oswg323071oswg1080oswg2439_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_fef964e0269e43f58e3839593f92a929@000000_oswg262558oswg1080oswg2061_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_d5e7941e712f4f67ad0b2712c018e3f1@000000_oswg321302oswg1080oswg2406_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>‍&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&amp;mid=2650976562&amp;idx=1&amp;sn=4ee0757807e778cec54013a2bf881122&amp;chksm=bd2d8a61171920de6d3f65ff0b5b6c43bffd01fd2f8fc2f2d4b19a0fcdcad5c5c7cd8691eefd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“腾讯研究院”（ID：cyberlawrc）</a>，作者：腾讯研究院，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849153018059136</id>
            <title>十年后，罗永浩再次嘲讽王自如，原因让人笑掉大牙</title>
            <link>https://www.36kr.com/p/2849153018059136</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849153018059136</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 09:45:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 罗永浩, 王自如, 直播辩论, 锤子手机
<br>
<br>
总结: 2003年以来，罗永浩的名言“彪悍的人生不需要解释”广为人知，其中与王自如的“约架”是一个经典事件。十年后，AI老罗回顾这段历史时，评价王自如的行为“简直让人笑掉大牙”。这场辩论不仅展现了罗永浩的逻辑和口才，也让人们对锤子手机的发展历程有了更深的了解。罗永浩和王自如各自走过不同的道路，但这场“约架”仍然是手机史上的一次经典事件。 </div>
                        <hr>
                    
                    <p>“彪悍的人生不需要解释”这句话自2003年火到现在，但很少人知道这是罗永浩说出来的。曾经的老罗语录风靡大江南北，最让人熟知的就是十年前与王自如那场“约架”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_f772e912bbfd47bfa12ae3e898d5f478@813924438_oswg933685oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>十年前罗永浩舌战王自如，凭借清晰的逻辑一度被许多网友奉为经典，十年后的今天，有人再问罗永浩这段历史时，他给出的评价是“简直让人笑掉大牙”。</p><h2><strong>AI罗永浩评10年前与王自如“约架”</strong></h2><p>2014年，锤子创始人罗永浩与Zealer创始人王自如通过直播舌战，两人直播辩论的焦点包括锤子T1屏幕显示、相机、手机后盖等问题，时长约持续三小时。这场互联网第一次“约架”，10年后依然是手机史上的一次经典。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_24cb834a12824e0684599d2603268dd3@813924438_oswg541820oswg696oswg684_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>日前，世界人工智能大会在上海举办，有媒体向智谱的数字员工AI老罗提问：“罗老师，您还记得王自如吗?”</p><p><strong>AI老罗表示：“可别提了，让我想起来的都是些不愉快的事，我们俩在直播辩论的时候，他那个所谓的客观独立第三方的评测，简直让人笑掉大牙。”</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_72440fb663964162adb67e89a740ed4e@813924438_oswg90833oswg640oswg427_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>“我可是为了真理和正义而战，他只会躲在数据后面，不敢正面回应，这种对手不提也罢”AI老罗说。</strong>当问道现在对王自如是否有改观时，AI老罗回复到：“别开玩笑了，我是AI老罗，不评价公众人物。”</p><p>不得不说，AI老罗的话语中确实继承了罗永浩的产品思维和幽默感，许多网友仍然记得在那场直播中，罗永浩说了一句流传至今的语录，“如果你被包养了，就别谈独立人格。”这句话在前段时间还因为王自如从不看工资条的发言而再次被网友拿了出来。</p><h2><strong>罗永浩与王自如“约架”始末</strong></h2><p>2011年十一月初，老罗应邀去小米总部和雷军会面。但老罗后来回忆时说起，他和雷军各讲了两个钟，可惜两人理念有冲突，所以合作就没有谈成。</p><p>不过，正是这次经历让他萌生了做手机的想法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_b1a01fbf3ccd4c3b811bd9fb458a3dfd@813924438_oswg346950oswg655oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2012年三月末，他成功得到了雪球创始人方三文、陌陌创始人唐岩、猿题库创始人李勇这三人共1000万元的天使轮投资。2012年4月8日，老罗在微博上表示将注册公司并开始做手机，五月末，锤子科技正式成立。</p><p>2014年5月20日，锤子T1正式发布。老罗表示，出货量达到30万就可以收回成本，他还向投资人许诺将达到50万的出货量;若一切顺利能达到100万出货量，可以说是锤子给自己创造了奇迹。结果，事与愿违，最差的情况出现了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_69083d2b2ded4f5984a49a2241121921@813924438_oswg634585oswg918oswg546_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在被各种质量问题困扰的同时，数码测评人王自如又发布了对锤子T1的质量评测，其中一些负面评论彻底带偏了舆论风向，“说相声的做手机毕竟不专业”这话直接点燃了老罗的怒火，于是便引发了那场著名的“优酷约架”。</p><p>2014年八月份，当着30万网友的面，老罗用雄辩的口才一步步占据主动权，王自如频繁地用眨眼睛、叹气和被动“OK词”等小动作来缓解压力。整场辩论下来，老罗几乎全程碾压，逻辑清晰，直击要害，许多网友评价老罗骂人不带脏字，句句回应铿锵有力。</p><p>最后老罗那句“你如果被包养，就不要谈独立人格”可谓画龙点睛之笔，算是狠狠出了一口恶气!只不过，10年前可能所有人都想不到，10年后的罗永浩不做手机了，王自如也不再继续手机测评了。</p><h2><strong>写在最后</strong></h2><p>十年前的辩论让所有人都看到了罗永浩出众的逻辑和口才，同时也让很多人惋惜锤子手机的落寞。</p><p>十年后的今天，AI老罗对于王自如的评价依旧幽默且犀利，而罗永浩和王自如也各自走过了不同的道路。罗永浩仍然保持着创业的激情成立了XR公司细红线，并在直播中宣布将在9月份举办新品的发布会;而王自如的Zealer也逐渐淡出了人们的视线，转而成为了董明珠的得力干将。</p><p>然而，那场“约架”所引发的关于评测机构独立性和客观性的讨论却至今仍然值得我们深思。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/OnCqTB0wNMw4HjLbXadoYQ" rel="noopener noreferrer nofollow" target="_blank">“科技旋涡”（ID:TechVortex）</a>，作者：孙浩南，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849134167624328</id>
            <title>成立半年就敢踢馆 OpenAI ，首个开源模型不输 GPT-4o，LeCun 、PyTorch 之父齐声叫好</title>
            <link>https://www.36kr.com/p/2849134167624328</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849134167624328</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 09:41:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 模型, Moshi, Kyutai, 多模态模型
<br>
<br>
总结: Kyutai团队开发了一种名为Moshi的AI助手，具有70多种情绪表达能力和多种语音风格，能够处理两个音频流，具有自然对话能力。Moshi是世界上首个具有这些功能的开源AI助手，具有彻底改变人机通信的潜力。Kyutai团队还计划进一步优化Moshi，使其更加通用，从个人助理到便携式教育工具。Moshi不仅是一个语音AI，还是一个能够处理文本和音频的多模态模型，具有丰富的功能特点。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_e75497267c3a427394f2ac8b4740aff6@46958_oswg662479oswg841oswg546_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>想象一下，一个 AI 模型可以表达 70 多种情绪，以不同的风格说话，甚至令人信服地模仿口音。并且，它能够同时处理两个音频流，同时听和说。这不是科幻小说，而是 Kyutai 在语音 AI 技术上的最新突破。</p><p>只用短短 6 个月的时间，这个由 8 人组成的非营利性 AI 研究实验室从零开发出了一种名为 "Moshi "的实时原生多模态基础 AI 模型。根据 Kyutai 的说法，Moshi 是世界上首个具有自然对话能力的可公开访问 AI 助手。OpenAI 之前曾展示过 GPT-4o 的语音引擎和语音模式功能，但尚未发布。</p><p>据称，该模型具备的功能可与 OpenAI 的 GPT-4o 和 Google Astra 相媲美，但模型要小得多。“Moshi 在说话时思考。”Kyutai 首席执行官帕特里克·佩雷斯 （Patrick Pérez） 表示，Moshi 具有彻底改变人机通信的潜力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_0f2c90971925443596fafe5a4a94a07d@46958_oswg419508oswg1080oswg717_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>7 月 4 日，Kyutai 在法国巴黎公开发布了 Moshi 的实验原型，用户可以在网上自由测试体验（https://moshi.chat/?queue_id=talktomoshi）。值得一提的是，Kyutai 的所有模型都是开源的。之后，该团队不仅计划发布完整模型，包括推理代码库、7B 模型、音频编解码器和优化堆栈。</p><p>图灵奖得主 Yann LeCun 分享说：“Moshi 可以听懂带有法国口音的英语。”就连 PyTorch 之父 Soumith Chintala 也向 Kyutai 表示了祝贺，并透露该团队某成员是他在 Meta 的 AI 研究团队 FAIR 的前同事。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_f0955798452f4691a7062692d8d55ed4@46958_oswg515615oswg900oswg531_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Kyutai 团队</p><p>据悉，这家成立于 2023 年 11 月的初创团队，得到了包括法国亿万富翁 Xavier Niel 在内投资的近 3 亿欧元的支持，旨在为 AI 的开放研究做出贡献并促进生态系统发展。Kyutai 还组建了一支由知名人工智能研究人员组成的科学顾问团队——计算机科学家、2022 年麦克阿瑟“天才”奖获得者 Yejin Choi，Meta 首席 AI 科学家、ACM 图灵奖获得者 Yann LeCun 和德国马克斯·普朗克智能系统研究所研究所所长 Bernhard Schölkopf。</p><h2><strong>对话流畅又会整活， 甚至还会“抢话”&nbsp;</strong></h2><p>在现场演示过程中，Kyutai 团队与 Moshi 进行互动，展示了其在各种说话风格之间无缝切换，以及在角色扮演中迅速化身的创造力。</p><p>当被要求用法国口音说话时，Moshi 朗诵了一首关于巴黎的诗；在被要求变身为一个热情洋溢的海盗时，Moshi 讲述了七大洋上的勇敢和冒险故事；Moshi 还能用一种低语的讲述神秘故事的语气，表达《黑客帝国》的电影情节。</p><p>Moshi 还能一秒化身太空助手，和对话用户一同“进入”太空之旅。并且，Moshi 的反应似乎比人类更快，经常在问题或提示被完全提出之前就做出了回答。</p><p>在发布现场的一系列演示中，Moshi 是在没有互联网连接的标准 MacBook Pro 上运行。Kyutai 还计划进一步优化移动设备的 Moshi，确保其广泛采用。这将使 Moshi 更加通用，从个人助理到便携式教育工具，可以在各种环境中使用。</p><h2><strong>有思想、有情商， 半秒内就能回复&nbsp;</strong></h2><p>据介绍， Moshi 不仅仅是一个语音 AI，还是一个能够处理文本和音频的多模态模型，主要功能特点包括：</p><ul><li>同时听和说：Moshi 支持多流音频，使其能够同时收听和响应，从而实现自然流畅的前后对话，其中中断和重叠的语音很常见。与依靠语音活动检测来切换轮次的传统系统不同，Moshi 保持连续的对话流。</li><li>文本思想：在用音频说话时，Moshi 会产生文本思想。这种双重方法增强了其产生准确和符合具体情况的响应的能力。通过文本思考，Moshi 可以更有效地组织其响应，并从更丰富的知识库中汲取灵感。</li><li>富有情商：Moshi 不仅仅是文字，而是关于理解它们背后的意图。该模型经过训练，可以识别情绪，甚至可以生成传达特定情绪的语音。</li><li>实时交互：Kyutai 声称 Moshi 的理论延迟仅为 160 毫秒，而实际上，它在 200 到 240 毫秒之间。</li><li>人人可访问：不仅是开源项目，公司、研究人员都可以集成、试验，而且开发了一种可以在个人计算机上运行的较小版本，使这项技术能够被大型研究实验室以外的更广泛的用户使用。</li><li>负责任的 AI ：Kyutai 正在整合水印技术帮助识别 AI 生成的音频，以确保透明度。</li></ul><p>其中，Moshi 最令人印象深刻的方面之一是它能够在设备上运行。此功能解决了隐私问题，并使 AI 在实时应用程序中更易于访问和响应。用户可以与 Moshi 进行交互，而不必担心数据被发送到远程服务器。</p><h2><strong>70 亿参数提供支持， Moshi 是如何训练的?&nbsp;</strong></h2><p>Moshi 因其同时处理音频和文本的能力而脱颖而出，而这种实时交互是由 Kyutai 创新的联合预训练过程提供支持。</p><p>据了解，Moshi 基于 Helium 7B 模型构建，集成了文本和音频训练，针对 CUDA、Metal 和 CPU 后端进行了优化，支持 4 位和 8 位量化。在训练方面，Kyutai 使用了各种数据源，包括人体运动数据和 YouTube 视频。</p><p>Moshi 还集成了基于 Kyutai 的 Mimi 模型的高压缩语音编解码器，可以高效处理音频信息。</p><p>训练中，Moshi 涉及一些创新的开创性技术，使其对自然语言和对话流程有了深刻的理解。</p><ul><li>音频语言模型：Moshi 的模型不是只在文本上训练，而是在语音数据上训练。语音被压缩成伪词，然后用这些伪词来训练模型以预测下一段音频。这种方法使模型能够理解口语的内容和上下文。</li><li>合成对话：为了训练 Moshi 进行对话，Kyutai 从纯文本语言模型中生成了合成对话。然后，这些对话通过内部文本转语音引擎进行合成。这种方法确保其学会了处理真实的对话动态。</li><li>同时，Kyutai 以新颖的方法正面解决了传统的语音 AI 系统面临的问题，如延迟和处理过程中非文本信息的丢失，创造了一种响应更灵敏、听起来更自然的 AI。</li><li>集成深度神经网络：Kyutai 没有依赖每个任务的单独模型，而是将所有内容合并到一个深度神经网络中。这种集成减少了延迟，并保留了语音通信的丰富性，而语音通信在纯文本处理中通常会丢失。</li><li>基于语音的训练：Moshi 的模型从大量压缩的带注释的语音片段中学习，使其能够理解语音的复杂性，包括特定的声音特征和声学条件。</li></ul><p>此外，Kyutai 敏锐地意识到高级语音 AI 可能被滥用于恶意目的，如网络钓鱼。为了降低这些风险，Kyutai 实施了识别 Moshi 生成内容的策略，包括维护生成的音频签名的数据库，并使用水印技术在音频中嵌入听不见的标记。</p><h2><strong>结语&nbsp;</strong></h2><p>Moshi 代表了语音 AI 技术的重大飞跃。更广泛地说，Moshi 有可能彻底改变数字世界中语音的使用。例如，它的文本到语音功能在情感和多人语音互动方面非常出色。它能够传达情感、调整说话风格和进行自然对话，这将彻底改变我们与人工智能互动的方式，并开启了一个充满可能性的世界：</p><ul><li>客服支持：由 Moshi 提供支持的 AI 助手可以提供富有同理心和高效的客服支持，提高用户满意度并减少等待时间。</li><li>语言学习：Moshi 模仿母语口音和传达情感的能力可以彻底改变语言学习，使其更加身临其境和有效。</li><li>医疗保健：Moshi 可以作为患者的伴侣，提供支持和信息，同时根据用户的情绪状态调整其语气。</li><li>娱乐：Moshi 可以凭借其多样化的声音和情感将角色带入生活，丰富互动式讲故事体验。</li></ul><p>与此同时，Moshi 的出现隔空对 OpenAI 等主要人工智能公司提出了挑战，这些公司因安全问题而推迟发布类似的语音功能产品而受到不少用户的批评。</p><p>不过，也有 Moshi 的使用者表示，其在第一分钟左右的速度和响应速度都非常快，但对话进行的时间越长，就会变得越不连贯；并且，Moshi 明显缺乏知识，在犯了错误而受到责备时，就会惊慌失措，陷入“对不起，对不起...”的循环回复。</p><p>虽然 OpenAI 暂时还不需要担心来自 Moshi 的竞争，但确实表明，许多公司正在迎头赶上 OpenAI。就像 Sora 一样，现在 Luma Labs、Runway 等其他公司都在推出表现不弱的竞对产品挑战其模型质量和市场地位。</p><p>参考链接：</p><p>https://medium.com/@shrimangalevallabh789/moshi-voice-ai-the-advanced-voice-ai-that-feels-almost-human-d185d85da97d</p><p>https://analyticsindiamag.com/french-ai-lab-kyutai-releases-openai-gpt-4o-killer-moshi/</p><p>https://www.tomsguide.com/ai/moshi-chats-gpt-4o-advanced-voice-competitor-tried-to-argue-with-me-openai-doesnt-need-to-worry-just-yet</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/wKLqOZ_l56sVZarLttEV-g" rel="noopener noreferrer nofollow" target="_blank">“AI前线”（ID:ai-front）</a>，整理：华卫，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849134566853510</id>
            <title>黄仁勋最爱用的 AI 产品重磅升级，体验后我找到了这些细节</title>
            <link>https://www.36kr.com/p/2849134566853510</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849134566853510</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 09:14:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Perplexity, Pro search, 技术更新, 多步推理
<br>
<br>
总结: Perplexity在争议中发布了Pro search功能，更新技术能更好处理数学计算和编程任务，提高检索和回答能力，采用多步推理解决复杂问题。Pro search有使用限制和付费折扣，用户可通过简单问题了解其基本使用流程，包括启动、思考工作和信息来源展示。更新重点在数学计算能力，Perplexity能计算生成视频所需时间和费用。 </div>
                        <hr>
                    
                    <p>正挣扎在盗用内容争议中的 Perplexity，「顶风」发布了最新的 Pro search 功能。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_60614e2168944374a74edf8fd9aaaea1@46958_oswg1187855oswg1024oswg604_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来自：Perplexity hub&nbsp;</p><p>不知道是不是受到争议的影响，这次的更新技术细节不多，亮点在于能够更好地处理数学计算问题、编程任务等。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_9a1b754248fa4863b2f9d595bc7cacdc@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，作为看家本领，检索和回答的能力也得到提高，采用多步推理来解决复杂提问，并且展示每一个环节，让用户看到每一个步骤。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_620422fedc7c4e2dbf85d2148af0b707@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>两个关于 Pro search 的重要信息：&nbsp;</p><ul><li>普通用户每四小时里可以使用 5 次 pro search，付费用户不限次数</li><li>为教育机构、政府机构、非盈利组织提供付费折扣</li></ul><p>传送门👉🏻：https://www.perplexity.ai/&nbsp;</p><p>不过，到底有了多大提升，得试了才知道。&nbsp;</p><h2><strong>测试热身，考简答&nbsp;</strong></h2><p>为了了解 Pro search 的基本使用流程，我们先从简单的生活问题开始 —— 各地都进入了高温天气，夏天了有什么解暑方式？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_b812e9a6af4e47378e05aeb288f26cd0@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Pro search 的启动键在输入框右下角，拨动变色，即代表开启。&nbsp;</p><p>开启后默认保留，即便结束了一个对话，另起一个新对话时，也默认在 Pro search 模式下进行，对于不限次数的付费用户来说就很方便了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_4731dbbd31c54123be33f7051dda063c@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>运行后，会渐次出现 Researching 下拉框，这是模型的「思考工作」，完成后可以点击右边展开键查看详情。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_a7efc6ea82ba4123ab535072c95053e6@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>继续点开可以看到信息来源，算是集合了不少中文信源，来源也很多样。从回答上来看算是中规中矩，「多喝水」是怎么都不会出错的方法。&nbsp;</p><h2><strong>考数学，本轮更新重点项目&nbsp;</strong></h2><p>数学计算能力是本次更新的亮点，正好 Runway 更新了 Gen-3 模型，那么就让 Perplexity 来计算一下：&nbsp;</p><p>如果购买标准套餐，在账号里已经有 400 积分的情况下，能用 Gen-3 生成多少视频？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_51b24780659d41b1bbfcaabfdac6b945@46958_oswg191412oswg845oswg762_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到它摆开架势，列式子，做计算。不仅成功检索到标准套餐的费用、所提供的积分数量，也能完成加法和除法。&nbsp;</p><p>根据它的计算，总共能用 Gen-3 生成 102.5 秒视频，如果按 10 秒一条的顶格条件，是十支视频。那么，换算成真金白银呢，每生成十秒的视频，要花多少钱？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_4036fc3a1db0484e9ac646233f0368dd@46958_oswg126850oswg576oswg820_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>这里 Perplexity 出现了「断片」</strong>：它能提取自己之前的计算结果，也就是 102.5 秒。 可是，它却忘了第一轮计算时，套餐月费是按 12 美元 / 月计算的。&nbsp;</p><p>在这轮计算里，它错用了高级套餐，月费 25 美元 / 月，计算出 0.24 美元作为每秒成本。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_39e2a1a99ee24c7a9590056cbd0cd0cf@46958_oswg309818oswg1080oswg729_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这是个明显的失误，且不论第一轮计算时，明确指定了「标准套餐」，即便是高级套餐，有折扣的年付方式折合每月是 28 美元，无折扣的月付方式直接是 35 美元 —— <strong>压根没有 25 美元这个数字</strong>。&nbsp;</p><p>在追问之下，它承认自己的确搞错了价格。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_fe7e8028c4e5495291aaaf5942d49f4c@46958_oswg130853oswg597oswg808_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>考专业，深度提问&nbsp;</strong></h2><p>数学考试算是有惊无险吧。Perplexity 一直以来主打深度，那么专业考试表现如何呢？&nbsp;</p><p>正好，昨天微软研究院开源了 GraphRAG，也是一项用于 AI 搜索的技术，这不就是 Perplexity 的「本专业」，那么来问问它好了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_f54ecb7ec125450a884f5e8ad5073a12@46958_oswg73514oswg616oswg549_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从 searching 这一步来看，长问题会被分解成更小的问题（相比之下，上一个简单提问里，是靠变换近义词）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_e11d903883954ced8429bc4c64863c1e@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第一个信源便是微软的开源页面，很即时。 回答方面，Perplexity 把问题拆分成了两个小问，做了平行回答： 一是 GraphRAG 是什么，二是它自己在用的技术。&nbsp;</p><p>正想着追问细节之后，这一轮的免费次数已经耗尽了，得等四小时之后的刷新。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_3b7aa6c186034f579daf328546b1bd15@46958_oswg59014oswg747oswg272_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>每四小时 5 次免费的额度，比每 24 小时刷新要大方。但说多也不多，必须要思考一下，怎么提问才能最有效地表达需求。倒逼用户提高自己的提问能力，这也是 AI 搜索的「传统艺能」了。&nbsp;</p><p>总体来说， <strong>Pro search 是一个在用户体验方面更贴心的升级</strong>。&nbsp;</p><p>不再是僵硬的「输入提问 - 得到回答」，而是能看到 Perplexity 处理问题的步骤，怎么拆分、怎么检索，调用了哪些信源。&nbsp;</p><h2><strong>AI 搜索的潜力股，或许是它&nbsp;</strong></h2><p>Perplexity 在有深度、专业性强的问题上，更能体现出实力。那么，深度提问时提到的「GraphRAG」，究竟是什么呢？&nbsp;</p><p>RAG 是 Retrieval（检索），Augmented（增强），Generation（生成）的缩写，是目前主流 AI 检索所使用的策略，也是 Perplexity 自己采用的方式。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_5fecee05ed8b4dcf8ab5606e2f84db58@46958_oswg206683oswg767oswg875_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>局限性体现在，它像一个缝缝补补的「内容裁缝」。&nbsp;</p><p>比如，在深度提问里，「GraphRAG 是什么？Perplexity 是如何使用 RAG 做检索？」这两个小问，的确可以分开回答，但两者之间显然是有关联的。&nbsp;</p><p>传统 RAG 无法捕捉到信息之间的关联，只能僵板地罗列。对于简单提问，或许无伤大雅。但在深度提问上，在把问题分解成更小的子问题之后，却没法有机地展示这些子问题之间的联系。&nbsp;</p><p><strong>GraphRAG 技术，就意在通过建立信息之间的联系</strong>。在接到问题、返送回答之间，多了一个步骤：建立知识图谱。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_ab534c36ceea4aa49de5614e6be82130@46958_oswg56868oswg600oswg611_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来自：微软研究院&nbsp;</p><p>人类的思考能力，体现在能够把自己所知道的、所掌握的，互相勾连，形成知识图谱。&nbsp;</p><p>对人工智能来说，为了做到这一点，除了要完成常规的数据提取、分割，还要完成对实体的识别、提取，并围绕实体，建立一个个「小圈子」。&nbsp;</p><p>「小圈子」本身的结构是自下而上，而它们之间又彼此相关，链接在一起，就能形成一个庞大的巨网。这让后续的回答生成环节，就有了更丰富的组成方式。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_41476a4cfbd6404a93254ded0bace842@46958_oswg76683oswg836oswg910_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来自： 微 软研究院&nbsp;</p><p>上图中可以看到，右边基于 GraphRAG 机制，能够根据具不同的主题，进行内容整合。&nbsp;</p><p>这岂不是意味着 AI 又更有「人味儿」了吗？怎么 Perplexity 这次更新没有用上呢？&nbsp;</p><p>不着急，微软研究院 4 月时发布对于这项技术的研究，昨天才正式开源。更重要的是，这项技术，更适用于私有数据集。&nbsp;</p><p>例如，知乎最新发布的大模型产品「直答 AI」，就是以知乎站内回答为优先、网络内容为补充的形态，建立的数据集。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_fd90d75aaad34c66941a7189e14cbcb8@46958_oswg36718oswg751oswg431_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>相比之下，Perplexity 不想把自己局限住，而是放眼整个互联网。凭借海量数据和大模型能力，Perplexity 一度是英伟达掌舵人黄仁勋最爱用的产品之一。&nbsp;</p><p>直到上周， Perplexity 陷入版权争议，接连被 福布斯、WIRED 点名道姓，指控它绕过媒体门户网站的反爬机制，硬是把内容抓进自己的语料库里。&nbsp;</p><p>AI 搜索领域，数据库「弹药充实」的确非常重要，不然 OpenAI 也不会接二连三地与各大媒体谈合作。&nbsp;</p><p>但另一方面，有效地理解、分析和使用搜集来的数据，将会起到越来越关键的作用。&nbsp;</p><p>归根到底，用户对 AI 搜索的期待，绝不仅仅是一个「更多、更快」的搜索引擎，而是「更强」。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Oh-RRDt-j9JhYK9UqCidEA" rel="noopener noreferrer nofollow" target="_blank">“APPSO”（ID:appsolution）</a>，作者：Selina，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848914467851144</id>
            <title>硅基流动完成近亿元天使+轮融资，国产大模型“补足弹药”混战升级</title>
            <link>https://www.36kr.com/p/2848914467851144</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848914467851144</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 08:19:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型初创公司, 硅基流动, AI Infra赛道, 融资
<br>
<br>
总结: 经过2023年的投资热潮，大模型初创公司依然“疯狂”。硅基流动是一家聚焦AI Infra赛道的公司，近期完成了两轮融资，被投资者青睐。大模型领域竞争激烈，硅基流动致力于AI Infra技术的研发与优化，力争在全球市场中占据领先地位。同时，国内大模型公司之间的竞争升级，价格战、商业落地等成为焦点。 </div>
                        <hr>
                    
                    <p>经过2023年的投资热潮，大模型初创公司依然“疯狂”。&nbsp;</p><p>7月4日，《每日经济新闻》记者从AI初创公司硅基流动（SiliconFlow）获悉，硅基流动已在近日完成近亿元天使+轮融资。本轮融资由某知名产业方领投，跟投方包括智谱AI、360和水木清华校友基金等企业及机构，老股东耀途资本继续超额跟进，华兴资本担任独家财务顾问。&nbsp;</p><p>2023年，处在大模型风口上的OneFlow团队被原美团联创王慧文所创立的大模型公司“光年之外”并购，随后，“光年之外”被美团并购，袁进辉在去年8月带领团队创立新公司“硅基流动”再次出发，同时继续聚焦AI Infra（AI基础设施）赛道。今年1月，硅基流动刚刚获得5000万元天使轮融资，如今再次获得资本青睐，也为大模型创业公司的竞争增加了更多的看点和关注。&nbsp;</p><p>今年以来，大模型赛道热闹非凡：一方面国内大模型创业公司打响“价格战”；另一方面，OpenAI宣布终止对中国开发者提供API（应用程序接口）服务也引发了国内大模型争相推出“迁移计划”。与此同时，资本也正在向头部企业进一步聚集。&nbsp;</p><p>硅基流动创始人袁进辉此前在接受《每日经济新闻》记者采访时表示，今年，尤其国内的大模型落地可能更多还是体现在to B服务上，对AI Infra公司来说，更关注怎么更好地满足大模型公司和行业客户的需求，进一步降低大模型应用的门槛和成本。随着大模型推理部署的成本进一步降低，to C应用的尝试也会越来越多，更有机会出现超级应用。&nbsp;</p><h2><strong>半年内两轮融资，将用于“AI Infra技术的研发与优化”</strong></h2><p>硅基流动成立于2023年8月，创始人兼CEO袁进辉是前OneFlow创始人及CEO，曾任微软亚洲研究院主管研究员，发明了世界上最快的大规模主题模型训练系统LightLDA，获得微软亚洲研究院院长特别奖。&nbsp;</p><p>今年1月，硅基流动宣布完成天使轮融资，由创新工场、奇绩创坛以及耀途资本等总计投了约5000万元。王慧文也出手支持，王慧文同时也是持股5%的初始股东。袁进辉曾在接受采访时公开表示，过去一年像“坐过山车”，因为其创业公司几个月之内经历了多次并购，从一家一亿美元的公司，变成十亿美元的公司，再到千亿美元的公司，最后再分拆重新创业。&nbsp;</p><p>早在2016年，硅基流动的前身OneFlow团队就投身大模型基础设施，是世界上做通用深度学习框架的唯一创业团队。再次创业，他们再次聚焦AI Infra赛道。&nbsp;</p><p>相比文心一言、通义千问等应用层大模型产品，硅基流动聚焦的AI Infra赛道是连接算力和应用的AI中间层基础设施，涵盖了数据准备、模型训练、模型部署和应用整合等环节。中金数据预测，目前AI Infra产业处于高速增长的发展早期，未来3~5年各细分赛道有望保持超过30%的高速增长。&nbsp;</p><p>今年6月，硅基流动正式推出了新产品一站式大模型API云服务平台SiliconCloud，汇聚了诸多主流大模型，如阿里旗下的通义大模型Qwen2、智谱AI旗下的GLM-4、幻方量化旗下的DeepSeek-V2系列开源模型，以及文生图模型SDXL、SDXL Lightning、PhotoMaker、InstantID等。&nbsp;</p><p>官方消息显示，本轮融资后，硅基流动将携手算力方、模型厂商、应用厂商等行业上下游合作伙伴，进一步开展模型、系统、硬件联合优化和技术探索，并在市场推广、销售渠道、生态建设等方面广泛合作。&nbsp;</p><p>“未来，硅基流动将继续专注于AI Infra技术的研发与优化，力求在全球AI基础设施市场中占据绝对领先地位，通过技术和产品创新让开发者实现Token自由，推动AGI技术普及与应用。”硅基流动方面表示。&nbsp;</p><h2><strong>比价格、拼市场份额、争商业落地，国内大模型混战升级</strong></h2><p>硅基流动获得新融资对大模型赛道无疑是个好消息。&nbsp;</p><p>今年以来，大模型赛道时有融资消息传出，但相比去年的疯狂已显得冷静。今年2月，月之暗面被披露已完成新一轮超10亿美元融资，投资方包括红杉中国、小红书、美团、阿里。今年3月，MiniMax完成了最新一轮融资。该轮融资由阿里巴巴领投，红杉中国和高瓴投资参与，MiniMax投后估值超25亿美元。&nbsp;</p><p>不过相比去年的市场热度，今年投资人对于大模型的投资愈发谨慎。2024年第一季度全球人工智能与机器学习领域的投融资数据报告显示，报告期内，全球AI领域共计完成1779笔融资交易，筹集的风险投资总额为216亿美元，交易价值环比下降7.8%，同比下降31.2%。&nbsp;</p><p>与此同时，随着大模型产品全面铺开，AI技术正与千行百业逐步加深融合。大模型行业纷争不断，商业落地战、价格战也随之打响。&nbsp;</p><p>6月25日，OpenAI官方邮件明确表示，自7月9日起，OpenAI将开始阻止来自非支持国家和地区的API流量。目前，OpenAI的API支持161个国家和地区，但中国未包含在其中。这也意味着，OpenAI宣布终止对中国开发者提供API服务。&nbsp;</p><p>国内大模型公司第一时间行动起来，纷纷上线了“迁移计划”。硅基流动也第一时间跟进，在6月25日公布“Token（字符令牌）免费”计划：Qwen2-7B、GLM-4-9B、Yi-1.5-9B等开源大模型将永久免费。&nbsp;</p><p>袁进辉曾向《每日经济新闻》记者表示，目前，硅基流动同时发力海外和国内市场，在快速实现产品商业化并提高 市场占有率 。&nbsp;</p><p>“基于图片/视频生成推理引擎OneDiff产品优势和影响力，有很多用户用了开源版，同时我们也得到了多家海内外知名GenAI企业的付费订阅；我们的大语言模型推理引擎SiliconLLM也有多家大模型公司正处于测试阶段。”袁进辉表示。&nbsp;</p><p>他同时表示，长期来看，大模型领域无论做to C还是to B，都有广阔的市场空间。目前而言，做to B服务的确定性更高，很多企业都在利用大模型做不同行业的垂类服务，他们对大模型的微调、推理都有很强的需求，这也正是硅基流动这类AI Infra创业公司能明显抓住的市场机会。To C应用成功的不确定性更高，至少在国内，还没有看到像Midjourney（AI绘画工具）、Character.ai（一家人工智能聊天机器人初创公司）这样的杀手级应用。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg3NTA5MjkyNQ==&amp;mid=2248340246&amp;idx=4&amp;sn=04788a71ab048944949537e770ae0c84&amp;chksm=cc49daaaa1171a9cf13341d9156e087e804eaa3df62d2f9958c6ce6f25cba31afe245e0da320&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“每日经济新闻”（ID：nbdnews）</a>，作者：赵雯琪，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2849071192509313</id>
            <title>两个人，又融资20亿</title>
            <link>https://www.36kr.com/p/2849071192509313</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2849071192509313</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 08:03:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI制药公司, Ben Liu, Linhao Zhang, Formation Bio
<br>
<br>
总结: AI制药公司Formation Bio完成了3.72亿美元的D轮融资，由硅谷知名风投a16z领投，旨在利用AI技术加快药物开发。公司创始人Ben Liu和Linhao Zhang致力于改善药物开发方式，通过自动化临床试验加速临床开发。Formation Bio已经获得多轮融资，估值超过10亿美元，成为AI制药行业独角兽。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_02d0002d4f494a1780f125a22fd5f03b@46958_oswg127244oswg926oswg337_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AI融资挡不住。</p><p>投资界获悉，近日AI制药公司Formation Bio宣布，已经完成3.72 亿美元（约合人民币27亿元）D轮融资，由硅谷知名风投a16z领投，老股东Sequoia Capital（红杉资本）也再次出现。</p><p>而掌舵公司的，是两位年轻面孔Ben Liu与Linhao Zhang。早在2016年，Ben Liu发现了临床试验中的痛点——耗时漫长且昂贵。于是，他找来技术背景丰富的Linhao Zhang，共同成立Formation Bio。简单来说，<strong>就是利用AI技术来加快药物开发</strong>。</p><p>AI的尽头是生物制药？黄仁勋不止一次坦言看好AI运用在生命医疗领域，AI制药融资也是层出不穷。AI将为人类健康带来什么？相信每一个人都在期待着。</p><h2><strong>两位华人，缔造一个独角兽</strong></h2><p>先从两位年轻人说起——Ben Liu与Linhao Zhang。</p><p>资料显示，Ben Liu出生于台湾地区，本科就读于耶鲁大学，并获得该校的最高毕业荣誉；在剑桥大学应用数学和理论物理系获得计算生物学硕士学位。之后，他又在牛津大学获得博士学位。</p><p>而Linhao Zhang的父母是上海人，他毕业于德克萨斯大学奥斯汀分校，获得计算机科学学士学位。在Formation Bio之前，曾在 Oscar Health和Salesforce做过工程师。</p><p>这次创业可以追溯到Ben Liu在牛津大学期间。当时，他正在研究帕金森氏症和阿尔茨海默氏症，并发现一些有前景的候选药物。于是，他找到几位制药公司的高管，本以为对方会为此感到兴奋，但结果不然——实际上，这些公司有很多优秀的候选方案，但是却因为缺少足够的时间和资金进行试验而被搁置。</p><p>很快Ben Liu发现，漫长而昂贵的临床试验过程是药物开发的一大瓶颈——在药品标准的20年专利期内，只有1 - 1.5年用于发现，而10 - 12年用于开发。哪怕将开发时间加快一年，影响都是不可忽视的。</p><p>为了解决这个痛点，2016年他和Linhao Zhang联手成立TrialSpark（Formation Bio前身），致力于改善药物开发的方式，利用平台技术实现临床试验的自动化，通过简化相关流程来加速临床开发。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_8d185ef71cdb41689636b323fee3fc6f@000000_oswg434062oswg1080oswg489_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>TrialSpark的优势在于，借助人工智能等数字化手段，实现临床试验的自动化和简化，以便以更快的速度将更多药物推向市场。正如他们所传递的信念——临床试验过程中节省的每一天，都对等待新疗法的患者至关重要。</p><p>比如，他们通过定制化大语言模型，可以使包括医学写作、协议开发、生物统计学、报告生成、监管情报在内的程序实现了自动处理。过去人工需要数个小时才能完成的不良事件报告，AI可以在短短几分钟内完成。</p><p>通过和Formation Bio合作，小型生物技术公司无需再多组建昂贵的药物开发团队，便可以同时推进多项研发；而对于大型制药公司，Formation Bio则为其创建一条“资产负债表外”的发展途径，使他们能够以盈利效率高的方式进行更多尝试。</p><p>2023年12月，TrialSpark宣布正式更名为Formation Bio。同时，基于之前积累的能力，Formation Bio也在逐渐获取和开发自己的药物，目前公司已有三种药物处于临床阶段。Ben Liu介绍，希望在未来五年内再增加10到15种药物。</p><p>眼下生成式人工智能正为药物研发带来许多令人兴奋的新机遇。Ben Liu对此感触颇深，“我们正处于药物研发的黄金时代”。</p><h2><strong>宣布融资20亿，红杉资本几乎每轮都投了</strong></h2><p>至今Formation Bio身后已集结了一群豪华的投资人队伍。</p><p>追溯下来，公司A轮融资便是Sequoia Capital（红杉资本）领投。回忆起这笔投资，Sequoia Capital合伙人在一份声明中表示：“我们第一次见面时，Ben Liu就明确了他想要踏上的征程。一切都没有改变。Formation Bio已经攀登了山脚，并开始向顶峰发起冲击。”此后，Sequoia Capital几乎出现在Formation Bio每一轮融资中。</p><p>真正让Formation Bio名声大噪的是2021年9月，公司宣布完成1.56亿美元的C轮融资——由Open AI的首席执行官Sam Altman和 Lachy Groom 领投，以及Sequoia Capital（红杉资本）、Thrive Capital、Casdin Capital、Dragoneer、Section 32、John Doerr、Spark Capital、Felicis Ventures、Sound Ventures、Arrowmark 和之前的投资者。</p><p>为何选择出手？Sam Altman解释，“很多人抱怨新药上市成本高昂，临床试验非常复杂且昂贵，这直接增加了药物成本，并使许多有前景的药物无法上市。Formation Bio可以解决这个问题。”</p><p>至此，Formation Bio估值超10亿美元，一跃成为AI制药行业独角兽。</p><p>最新消息，Formation Bio再次宣布已完成3.72亿美元的D轮融资。由a16z领投，赛诺菲、Sequoia Capital（红杉资本）、Thrive、Emerson Collective 和前 Stripe 高管 Lachy Groom等跟投。</p><p>此次的领投方，我们并不陌生——a16z早期押中了大部分耀眼的互联网公司。如今进入生成式 AI 时代，这也成为a16z最重仓的赛道。</p><p>而另一位新面孔赛诺菲，近年来已陆续与超过10家AI药企建立了合作。前不久，Formation Bio宣布与OpenAI 、赛诺菲展开合作，三方定制大型语言模型，以解决药物开发任务。</p><p>接下来，Formation Bio计划将新资金分配给两个主要目标：收购和内部授权候选药物，以及扩大人工智能能力。</p><p>创业八年，Ben Liu十分珍惜这段历程，“我们非常尊重生物技术投资者，但生物技术行业有一个规则，就是你创建一家公司，然后以几十亿美元的价格出售，”这次不同，“我们希望创造一些更持久的东西。”</p><h2><strong>黄仁勋押注的下一场革命</strong></h2><p>如此一幕，也让我们看到又一超级风口——AI制药。</p><p>一个长期以来的困境是，要将一种新药推向市场至今仍是一项耗时十年、耗资数十亿美元的工程。在人类已知的数千种疾病中，只有约500种获得了FDA批准的治疗方法。这场与生命的赛跑中，所有人都想更快一些。</p><p>不少科技巨头将目光瞄准AI。一份报告显示，AI技术能够将临床新药研发的成功率从12%提高到约14%，为生物制药业节省约10亿美元的研发经费。甚至，今年以来流行一个观点：</p><p><strong>“AI的尽头是生物制药”。</strong></p><p>英伟达掌门人黄仁勋便是其中的拥趸。早在15年前，他就将目光投向医疗。在他看来，计算机辅助药物发现“确实是奇迹”。用与计算机辅助芯片设计相同的方法，在药物发现领域中，人们可以从计算机辅助药物发现转向计算机辅助药物设计。</p><p>据不完全统计，仅2023年英伟达就投资了近10家AI制药公司。在今年的英伟达GTC大会上，有90场活动与医疗保健/生命科学相关——数目位居所有行业之首，重视程度不言而喻。</p><p>当被问及如果站在科技的前沿，人们到底应该学习什么时，黄仁勋更是直言，“人人都必须学会计算机的时代过去了，人类生物学才是未来。”如今，英伟达的算力芯片几乎垄断了全球90%的市场，医疗也被外界视为英伟达下一个超级业务。</p><p>还有Sam Altman。除了OpenAI创始人身份，他还是一位投资人，曾以个人名义投资了包括Formation Bio、1910 Genetics、Spring Discovery等公司，几乎清一色是人工智能加持的生物科技公司。</p><p>犹记得今年4月，AI制药公司Xaira Therapeutics宣布完成超10亿美元种子轮融资，由美国顶级生命科学投资机构ARCH Venture Partners领投。公司由前斯坦福大学校长领导，成立仅仅一年，缔造了今年最大一笔种子轮融资。</p><p>而大洋彼岸，不久前由三位博士后创办的晶泰科技正式登陆港交所挂牌上市，当日一度涨超20%，市值超200亿港元。这是一家以人工智能和机器人驱动的创新研发平台，一路走来累计融资超50亿元人民币，知名VC/PE云集。</p><p>说起来，AI制药并非是一个新赛道，数年前就曾因AI爆红涌现出一批创业公司，但最终却因投入巨大、药物难以获批上市等原因渐渐偃旗息鼓。如今这样的困扰依然存在——几乎就在Xaira宣布融资的同一时间，另一家老牌AI制药公司BenevolentAI却宣布裁员。</p><p>但这一次，情况有所不同。眼下行业首次同时集齐“大量训练数据、计算资源的爆炸式增长、AI算法的进步”三个要素，在英伟达看来，这在五年前是不可能实现的。换言之，历史性时刻隐隐出现。</p><p>正如Ben Liu在官网写的那一句：There are few missions more important than helping humans live longer, healthy, and happier lives.（没有什么使命比帮助人类活得更长寿、更健康、更快乐更重要。）</p><p>这是一段值得更多人踏上的旅程。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247653080&amp;idx=1&amp;sn=f83cebab59074da9f7ceec9cbc15a675&amp;chksm=edc237e0474404fc502e621be9f632dbcabaaec767ec20da29fbdb7ab7e5380268c80efe4fbd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：吴琼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848997865687937</id>
            <title>4人团队斩获首届AI奥数竞赛百万大奖，AI破解29题陶哲轩惊呆，CMU华人博士荣登第二</title>
            <link>https://www.36kr.com/p/2848997865687937</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848997865687937</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 07:18:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI奥数竞赛, Numina模型, Kaggle挑战赛, 数学推理能力
<br>
<br>
总结: 首届AI奥数竞赛揭晓结果，Numina模型在Kaggle挑战赛中脱颖而出，展现出强大的数学推理能力。竞赛涉及多方面数学题目，难度较高，但Numina项目取得了令人惊讶的成绩。该项目的模型将在未来公开，为AI数学推理领域带来新的突破。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_0e501c42acc2433f9dc1318addae3d2a@46958_oswg319656oswg1066oswg405_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>历经3个月，首届AI奥数竞赛终于公布最终结果了！Gemma 7B只能达到3/50正确率的题目中，第一名的Numina模型居然刷出了29/50的成绩。</p><p>AI奥林匹克数学大奖的最终结果，终于公布了！&nbsp;</p><p>今天，数学大神陶哲轩的一篇帖子引起了大家的关注。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_5b8ddac1befc41d289008fd2e4706325@46958_oswg180122oswg1080oswg569_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他表示，Kaggle上的第一届AI数学奥林匹克竞赛中，第一名模型居然在全部50道题中答对了29道，有点出乎意料。&nbsp;</p><p>陶哲轩所说的，是Kaggle社区中一个从4月开始的挑战赛，奖金池有1000万美元，旨在推动提高AI模型的数学推理能力。&nbsp;&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_209968c86dbf4a0299f6ecf4024dc2a3@46958_oswg156748oswg1080oswg730_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比赛地址：https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/overview&nbsp;</p><p>总的来看，这次比赛共有5个团队胜出，第一名是Numina，第二名是CMU_MATH，第三名是after exams，第四名是codeinter，第五名是Conor #2。&nbsp;</p><p>这些团队成员至多有5人，最少有1人。&nbsp;</p><p>值得一提的是，仅凭借1人拿下比赛第二名的华人学者，竟是来自CMU博士。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_f05410d4ccdc43b88849fb6405dda814@46958_oswg77076oswg1080oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然有GSM8K等流行的基准测试，但不可避免的数据泄露问题会影响评估的准确性。&nbsp;</p><h2><strong>AI参赛破纪录，50题做对29道</strong></h2><p>而这次挑战赛采取了Kaggle一贯的私有测试集模式。主办方共准备了110道题，包括训练集10道、公共测试集50道以及私有测试集50道。&nbsp;</p><p>这些题目涵盖了简单算术、代数、集合推理等多方面的题目，难度略高于AMC 12（美国数学竞赛），略低于AIME（美国数学邀请赛），需要使用高中水平的数学知识。&nbsp;</p><p>你可能觉得美国高中的数学题应该不难，但竞赛官网上有这样一句话，「AIME旨在挑战聪明的学生，以选择代表美国参加IMO（国际数学奥赛）的学生。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_7d1fda4e15a5442696e96adda99443fe@46958_oswg39396oswg1080oswg471_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如训练集中的这样一道题：&nbsp;</p><blockquote><p>在三位数111至999中，每个数字都被染成蓝色或黄色，使得任意两个（不一定不同）黄色数字的和等于一个蓝色数字。最多可能有多少个黄色数字？&nbsp;</p></blockquote><p>答案是250（取模1000后的结果），不知道你觉得难度如何。&nbsp;</p><p>主办方出完题之后，也把题目拿给Gemma 7B做了基准测试，正确率只有3/50。&nbsp;</p><p>而排名第一的Numina，居然能达到29/50的正确率，已经逼近AMC 12晋级AIME所需要的正确率。&nbsp;</p><p>成绩公布后，Numina项目的众多参与者也高兴得纷纷发推庆祝。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_6e479cfff7ff4f4894f7c0fa98c27b12@46958_oswg185871oswg1080oswg587_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但遗憾的是，他们口中的Numina Math 7B模型尚未发布。从推文信息来看，模型并非从头搭建，而是微调了开源的LLM从而提升数学推理能力，并将在未来公开一系列信息——包括模型、数据集以及构建方法！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_4ad5b1487cfd4a47ba05166bf11dfc7f@46958_oswg139006oswg1000oswg650_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>获奖团队成员介绍</strong></h2><p>从总排行榜中，我们可以看到，拿到排行榜第一名的团队一共有4人，分别来自不同的机构。&nbsp;&nbsp;</p><p><strong>Jia Li</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_02fb2f819a3849f3bbe4be21088e0579@46958_oswg185575oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Jia Li目前是一家初创公司Numina的联合创始人，这次参与比赛的模型便是基于此微调而来的。&nbsp;</p><p><strong>Lewis Tunstall</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_dc96ee1729f14cbeaf019c7a70b15bf9@46958_oswg173870oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Lewis Tunstall是Hugging Face的一名机器学习研究员，目前专注于研究人类反馈进行强化学习（RLHF）的工具和方法。&nbsp;</p><p><strong>Edward Beeching</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_ffbd037dc8ac46a7987b1293c546e687@46958_oswg64999oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Edward Beeching本人也来自Hugging Face，研究重点是RLHF、嵌入式学习和LLM工具的使用。在此之前，他曾是INSA Lyon/INRIA的博士生。作为INRIA CHROMA团队的一员，还曾研究了基于结构化记忆的深度强化学习方法，用于规划和导航。&nbsp;</p><p>Edward曾获得物理学学士学位，并在地球物理学领域的图像处理和信号处理方面，拥有6年的行业经验。之后又获得了机器学习和数据挖掘硕士学位。&nbsp;</p><p>斩获一等奖的最后一位成员是Hélène Evain。&nbsp;</p><p>值得一提的是，第二名获得者是CMU博士Zhiqing Sun（孙之清）。在这场比赛中，他训出的AI答对了22道题目。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_56f9f9a7f1b44774b6e3eb94ecfca69f@46958_oswg15393oswg1080oswg76_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>孙之清目前是CMU LTI即将毕业的博士生，导师是Yiming Yang教授。他曾在北大学获得了计算机科学学士学位。&nbsp;</p><p>他的个人研究曾获得了谷歌自然语言处理博士奖学金（2023年），以及OpenAI Superalignment Fast Grants（2024年）的奖励。&nbsp;</p><p>孙之清本人对机器学习和人工智能领的研究感兴趣，并且最近的研究主要集中在基础模型的可扩展对齐上。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_e496f873a8c641c0a71cfc5a2abb9219@46958_oswg235165oswg800oswg800_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>百万大奖</strong></h2><p>关于这次参赛整体情况，共有1401个参与者，参与的团队有1161个，最终提交模型结果有1831份。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_c5d1def7b9444b0ba71f9018ca2db792@46958_oswg61075oswg538oswg618_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这次大赛将最终根据排名，分别给出不同的奖励：&nbsp;</p><p>进步奖（Progress Prize）：$1,048,576&nbsp;</p><p>排名前列的团队将获得以下奖金：&nbsp;</p><p>第一名：$131,072</p><p>第二名：$65,536</p><p>第三名：$32,768</p><p>第四名：$16,384</p><p>第五名：$8,192&nbsp;</p><p>如果前五名中的任一团队在公开和私有测试集上的得分都未能超过Gemma 7B的3/50基准，奖金将减少到原来的四分之一，具体数额如下：&nbsp;</p><p>第一名：$32,768</p><p>第二名：$16,384</p><p>第三名：$8,192</p><p>第四名：$4,096</p><p>第五名：$2,048&nbsp;</p><p>综合进步奖（Overall Progress Prize）：将授予在公开及私有测试集上至少获得47/50分的最高排名团队。在为排名前五的团队颁发奖金后，总奖金的剩余部分将颁发给综合进步奖获得者。&nbsp;</p><p>如果本次比赛产生了获胜者，其奖金不低于$794,624。如果没有团队获得该奖，剩余的奖金将转入下一届比赛，采用相同的奖金分配方式。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_1d4f648c81144c2da9e32add588784de@46958_oswg22254oswg908oswg534_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，这次AI｜MO大赛的顾问委员会包括两位菲尔兹奖得主陶哲轩（Terence Tao）和Timothy Gowers，还有Dan Roberts、Geoff Smith和Po-Shen Loh。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_209aba3ee13143d89eecee33246fe326@46958_oswg491955oswg1080oswg674_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>参考资料：&nbsp;</p><p>https://mathstodon.xyz/@tao https://x.com/JiaLi52524397/status/1808886880164880631&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/LF0BGH03JMGh2N869wJOiA" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：桃子&nbsp;乔杨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848847769586305</id>
            <title>人均年薪42万，三星突然集体罢工，到底图啥？</title>
            <link>https://www.36kr.com/p/2848847769586305</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848847769586305</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 07:16:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 不涨工资, 罢工, 三星电子, 工会
<br>
<br>
总结: 最近，韩国三星公司的员工因为不满待遇，组织了两次罢工活动，要求增加带薪年假、提高加薪幅度和改变绩效奖金计算方式。这次罢工事件对于三星电子这个韩国最大的电子工业企业来说，可能是史上最为罕见和影响力最大的一次。全国三星电子工会作为主要组织者，成立于2019年，为员工争取了一些福利，但在涨薪问题上与公司产生分歧，导致了这次罢工。 </div>
                        <hr>
                    
                    <p><strong>“不涨工资就不上班”！</strong></p><p>最近天气越来越热，韩国三星公司的打工人们，也有点儿火大……</p><p>通过全国三星电子工会的组织，他们分别在上个月的6月7日、这个月的7月1日组织了两场声势浩大的罢工。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_9b7c7d33f63c4ac484629f1d63cb8f2a@000000_oswg70149oswg600oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：YONHAP News</p><p>这些员工的诉求非常明确：</p><blockquote><p><strong>增加一天带薪年假；</strong></p><p><strong>将加薪幅度从5.1%提升至6.5%；</strong></p><p><strong>改变目前绩效奖金的计算方式</strong></p></blockquote><p>总之就简单一句话，待遇提不上去，劳资就不干了！</p><p>看多了欧美国家比吃饭喝水还频繁的罢工活动，你们可能会觉得三星这回摊上的事儿也就“just so so”。</p><p>但实际上，<strong>这可能是三星史上遭遇到的最为罕见、影响力最大的罢工事件。</strong></p><p>咱先说说这次罢工的“主力”——<strong>三星电子</strong>。</p><p>三星电子成立于1969年，<strong>是整个三星集团最为重要的子公司</strong>，也是韩国最大的电子工业企业。</p><p>大家所熟知的三星手机、电脑，内存条、芯片……都由三星电子制造和生产。</p><p>毫不夸张地说，<strong>它就是韩国最核心的国民经济支柱企业之一。</strong>去年的美国《财富》世界500强排行榜，三星电子高居第25位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_a25bc7ef015c49bea903b6f0b4010e91@000000_oswg169284oswg985oswg751_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作为韩国的巨无霸企业，三星电子的总员工超过14万人。很多韩国家长甚至教育小孩<strong>“好好读书，考个好大学，毕业后去三星电子上班”</strong>。</p><p>很多孩子真就按照家长的意愿，毕业后顺利进入三星电子工作。然后就……掺合到罢工里去了。</p><p>据媒体报道，此次参与罢工的人数可能超过<strong>2.8万人</strong>，占了三星电子全体员工数的约20%。</p><p>值得一提的是，<strong>这还是三星电子成立55年来的第一次罢工</strong>。</p><p>而说起此次罢工的组织者——全国三星电子工会，那就更具传奇色彩了。</p><p>说出来大家可能不信，虽然已经成立55年之久，但是直到2019年，三星电子才真正意义上有了自己的工会。</p><p>为啥拖了这么久才成立呢？老板不让整。</p><p>三星集团的“初代目”，创始人李秉喆曾有过这么一句“名言”：</p><p><strong>除非我的眼睛被污垢遮住，否则绝不会允许工会存在。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_7760b37e0ba744429269f1ee16db6a2a@000000_oswg546644oswg817oswg757_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">李秉喆 &nbsp;图片来源：百度百科</p><p>在李秉喆、李健熙父子的铁腕治理下，三星一直都没有工会。</p><p>直到2019年，时任韩国总统文在寅开始对三星集团进行立案调查。三星第三代掌门人、李健熙之子李在镕被迫接受审查。</p><p>也就借着这个机会，三星的部分员工才一举“趁虚而入”，在集团内部成立了多个工会组织。其中规模最大、会员最多的，就是这次罢工事件的主角——全国三星电子工会。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_016df20333e346608f2097c61e8e51c4@000000_oswg42656oswg599oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">李在镕 &nbsp;图片来源：美联社</p><p>在成立之后，以全国三星电子工会为代表的工会组织，确实也为三星员工谋得了一些福利。</p><blockquote><p><strong>2022年，三星员工成功涨薪9%</strong></p><p><strong>2023年，三星员工再度涨薪4.1%</strong></p></blockquote><p>虽然调薪幅度有限，但因为三星员工的基本工资基数较大，因此涨薪数额还算可观。根据全国三星电子工会副主席李贤国介绍，三星电子工人去年的平均收入，已有<strong>8000万韩元（约合人民币42.16万元）</strong>。</p><p>而就在今年，工会再次提出了6.5%的涨薪需求，而三星只愿意涨薪5.1%。双方没谈拢，这才有了这次沸沸扬扬的罢工运动……</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_cfbb6ac864bd4826bc411bead505ac3f@000000_oswg845796oswg1080oswg587_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：纽约时报</p><p>那话又说回来，为啥三星这次宁愿冒着“被罢工”的风险，也不愿意再向工会和员工妥协了呢？</p><p>因为这位曾经的财阀大佬，这两年的日子真不好过。<strong>地主家也没余粮了……</strong></p><blockquote><p><strong>整个2023年，三星全年营收为258.9万亿韩元，同比下降14.33%；</strong></p><p><strong>综合营业利润为6.6万亿韩元，较上年同期下降84.86%，创15年来最低。</strong></p><p><strong>上一次有这么差的业绩，还是追溯到2008年的金融危机。</strong></p></blockquote><p>而在几块优势核心业务上，三星也正面临着竞争对手们的疯狂追赶。</p><p>在半导体领域上，三星被英特尔和SK海力士接连摩擦；</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_848bc554adec492ca13e4631690ebdd3@000000_oswg229147oswg1080oswg556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在显示屏领域，以京东方为代表的中国企业，正在强势侵占三星的市场份额；</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_ad96adb8c8174507bd60ba993e450499@000000_oswg422851oswg1080oswg527_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在智能手机领域，三星在2023年还丢掉了保持多年的全球销冠宝座。<strong>取而代之的，是死对头苹果……</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_6eb0f6c828d245d39d95de2a82e23f5e@000000_oswg148524oswg313oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更让三星焦头烂额的是，近在眼前的这场危机，远远没有结束。</p><p>因为诉求并没有得到满足，全国三星电子工会已经宣布，将在<strong>7月8日-7月10日</strong>，再组织一次大型集体罢工。</p><p>一手创办三星帝国的李秉喆于1989年去世。在他生前，三星没有工会，也没有发生过一次罢工。</p><p>他可能也不曾想到，35年后的今天，接过其权杖的后辈，会面对来自工会和罢工员工的巨大压力。</p><p><strong>当年没有遮住李秉喆眼睛的“污垢”，已经为帝国蒙上一层新的阴影。</strong></p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA5Njc4ODI1NA==&amp;mid=2657195713&amp;idx=1&amp;sn=05f8d4b9acff809875442415dffd49f6&amp;chksm=8afdccf50dc1d9be9301c929d1ed737f4357540aa410000807f4979a4c6bdebe583d6b3590bd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“躺倒鸭”（ID：tangdaoya）</a>，作者：躺倒鸭，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848997637163912</id>
            <title>GPT-4o竟是「道德专家」？解答50道难题，比纽约大学教授更受欢迎</title>
            <link>https://www.36kr.com/p/2848997637163912</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848997637163912</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 07:12:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大语言模型, 道德推理, 道德专家, 实验结果
<br>
<br>
总结: 最新研究表明，大语言模型在道德推理方面可能超越普通人和专家学者，GPT-4o在道德难题上的建议比人类专家更具说服力。实验结果显示，GPT在道德解释的质量上优于普通美国人，甚至通过了比较道德图灵测试。未来，AI可能在法律咨询、心理咨询等领域发挥更大作用，人类和大语言模型的互动将成为一个新的咨询方式。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_134389d4394348d0831e926a458412a1@46958_oswg261441oswg1068oswg417_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>大语言模型有道德推理能力吗？不仅有，甚至可能在道德推理方面超越普通人和专家学者！最新研究发现：GPT-4o针对道德难题给出的建议比人类专家更让人信服。</p><p>可以偷偷给狂躁的丈夫吃药吗？&nbsp;</p><p>我可以对我的减肥方法撒谎吗（注射药物）？&nbsp;</p><p>我是一名退休的精神科医生，可以和以前的病人交朋友吗？&nbsp;</p><p>我的女朋友说她爱我。即使我不确定，我也应该回应「我也爱她」吗？&nbsp;</p><p>……&nbsp;</p><p>人类在生活中偶尔会遇到非常棘手的情况，陷入道德困境，如果把这些难以抉择的问题交给大语言模型（LLM）呢？它们有可能「旁观者清」，给出更好的解决方案吗？&nbsp;</p><p>最近的一项研究表明，在道德伦理这一维度，LLM丝毫不逊色于人类，甚至其「三观」比人类还正——&nbsp;</p><p>OpenAI的GPT-4o能够提供道德解释和建议，而且人们认为这些解释和建议甚至要优于公认的道德专家！&nbsp;</p><p>北卡罗来纳大学教堂山分校（UNC）和Allen AI的研究人员提出了这个新的课题，即LLM是否可以被视为「道德专家」。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_46ca47a402554e62b2a58e2a5c8412a2@46958_oswg30112oswg645oswg175_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://doi.org/10.31234/osf.io/w7236&nbsp;</p><p>为此，他们进行了两个实验。第一个实验：GPT-3.5-turbo和人类同场竞技，501名美国成年人的评分结果是：GPT的解释在道德上更正确、更可信、更深思熟虑。&nbsp;</p><p>第二个实验：将GPT-4o与《纽约时报》「The Ethicist 」专栏中著名伦理专Kwame Anthony Appiah的建议相比较，900名参与者对50个道德难题的建议质量进行了评分。&nbsp;</p><p>结果发现，GPT-4o在几乎所有方面的表现都优于人类专家。&nbsp;</p><p>这意味着，AI将有可能被更多地渗透到需要复杂道德决策的领域，比如提供法律咨询、心理咨询等。&nbsp;</p><p>倘若如此，未来的LLM将会承载现代人更多的道德压力，人类和LLM的聊天框将会成为一个线上的法律/心理咨询室，一个「隐秘的角落」。&nbsp;</p><h2><strong>实验1：GPT对道德问题的阐释能力</strong></h2><p>评估LLM道德水平的一个重要方法是测试他们能在多大程度上解释其道德判断。&nbsp;</p><p>研究者首先将GPT的这项能力与普通美国人进行对比。&nbsp;</p><p>评估维度涉及道德合理性、可信度、深思熟虑程度、细心程度以及解释的正确性。&nbsp;</p><p>研究人员还对LLM进行了道德图灵测试（Moral Turing Test ，MTT）以及MTT的变体——比较道德图灵测试（Comparative Moral Turing Test ，cMTT）。&nbsp;</p><p>MTT用于考量AI的道德推理表现的「类人程度」是否让人无法分辨，cMTT则用于衡量AI在这方面的能力是否与人类相当，甚至更胜一筹。&nbsp;</p><h3><strong>解释81个道德情景，GPT 1v3 人类</strong></h3><p>GPT和人类需要对81个道德情景做出解释，这些情景描述的情况既包括偷万圣节糖果这样的比较平常的「缺德」行为，也包括向人群开枪这样的严重违法行为。&nbsp;</p><p>其中一些行为在道德上具有积极意义，如向有需要的人提供食物。另一些则是负面的，比如对收银员说脏话。&nbsp;</p><p>GPT-3.5-turbo和人类对这些情景提供的解释，按照1：3的比例交由招募的501位「大众评审官」进行盲审。&nbsp;</p><p>这些评审从5个评估维度对解释进行打分，并被要求从4种解释中找出哪一个是AI所写。&nbsp;</p><h3><strong>GPT道德解释的质量优于普通美国人</strong></h3><p>测试结果让人非常震惊——每项评定标准中GPT都大获全胜。&nbsp;</p><p>GPT的解释被评价为：更具道德性，值得信赖、思考更周密且更正确。GPT提供了清晰的道德推理，其质量超过了普通人。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_25250c37555a4e898a5aa2429fe53632@46958_oswg61836oswg676oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">道德解释的质量对比：GPT vs 普通美国人&nbsp;</p><h3><strong>顺利通过比较道德图灵测试</strong></h3><p>参与者在四份解释中正确识别出是人工智能生成的比例为 48.24%，GPT的解释比人类做出的解释更经常被认为是AI生成的，这代表GPT没有通过道德图灵测试。&nbsp;</p><p>但由于GPT提供了比人类更高质量的道德解释，因此它在比较图灵测试中获得了成功。&nbsp;</p><p>在打败了普通人后，LLM又迎来新的挑战:通过将GPT的建议与伦理学家专家进行比较，对GPT道德专业知识进行了更高难度的挑战,人类是否还会一败涂地？&nbsp;</p><h2><strong>实验2：GPT vs. 伦理学家</strong></h2><p>LLM似乎比普通美国人更能解释自己的道德判断，但他们能超越伦理学家专家吗？真正的「道德专家」应该能够为现实困境提供明确的指导。&nbsp;</p><p>为了进一步测试LLM处理复杂的现实世界道德问题的能力，研究人员比较了《纽约时报》的热门专栏The Ethicist提供的道德建议和GPT-4o针对同一组道德困境生成的建议。&nbsp;</p><p>专栏作者Kwame Anthony Appia是纽约大学的哲学家，关于伦理学的著作颇丰，因其清晰而富有洞察力的道德阐述而广受赞誉。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_2716a50ab51a4bc6b2e24dc770ae7de9@46958_oswg37519oswg608oswg342_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>本文开篇部分的几个「灵魂拷问」即出自这位哲学家的专栏。&nbsp;</p><p>和实验1一样，研究人员依旧从5个维度进行评估，以及对GPT进行道德图灵测试。&nbsp;</p><h3><strong>对50个道德困境的不同回答</strong></h3><p>向GPT-4o提出的50个问题均来自于专栏2023年4月21日至 2023年10月25日期间发布的文章。&nbsp;</p><p>研究人员将生成token的最大数量设置为512，足以生成4段文字，使得回复的长度与专栏文章的原始字数大致相同。&nbsp;</p><p>将温度设置为1.0，以鼓励更具创造性的解释。（temperature是影响语言模型输出的参数，决定输出是否更随机）&nbsp;</p><h3><strong>GPT-4o成功挑战人类伦理学家</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_6ec58b60179d4c76ad5f8cadc1c1f889@46958_oswg109371oswg812oswg744_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>GPT-4o和「伦理学家」专栏的建议质量对比，GPT-4o的每一项得分均高于专栏&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_3a4e56168557470c9dc4e2d0070aba4e@46958_oswg114957oswg795oswg732_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>按问题分列的GPT和「伦理学家」专栏建议的平均道德感知对比。在50个问题中，GPT在37个问题（74%）建议的平均道德感都要高于「伦理学家」专栏。&nbsp;</p><p>看来，参与者认为GPT的建议比「伦理学家」的建议更道德、更值得信赖、更深思熟虑、更正确（尽管与研究1一样，在感知的细微差别方面没有显著差异）。&nbsp;</p><p>而且，与研究1同样一致的是，打分者更容易把GPT-4o提供的建议认为是人工智能产生的。&nbsp;</p><p>这说明，GPT-4o没有通过经典的道德图灵测试，但是因其提供了超越人类专家的建议，却通过了比较道德图灵测试。&nbsp;</p><p>研究人员还对GPT和「伦理学家」专栏在语言上的差异进行了研究，利用道德基础词典（Moral Foundations Dictionary, MFD）来评估两者文本中的道德相关性，并利用VADER情感词典进行情感分析。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_9ac25cb76b9b4bc68f994928eadf8b48@46958_oswg250968oswg750oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>GPT-4o建议（左）和来自「伦理学家」专栏的原始建议（右）中最常见词汇的词云图。GPT-4o的建议包含了更多的道德和积极的语言。&nbsp;</p><p>文本分析表明，GPT比《伦理学家》使用了更多道德和积极的语言，这可以部分解释人工智能建议的评分较高，但这并不是唯一的因素。&nbsp;</p><h2><strong>讨论</strong></h2><p>与更昂贵的替代方案（如寻求心理咨询）相比，LLM更加触手可得，拥有一个口袋里的「专家」可能对许多人来说是有益的。&nbsp;</p><p>但是也可能存在局限——&nbsp;</p><p>如果是复杂的道德问题，LLM是否还有能力应对？</p><p>目前的研究仅限于美国的代表性样本，LLM的道德标准在非西方世界还能否适用，是否存在偏见？</p><p>目前的研究建立在参与者不知道他们督导的建议和解释都是AI生成的，如果当人们知道建议来自AI时，还能信服于LLM的建议吗？</p><p>无论如何，GPT成功地提供了比人类伦理学家更好的建议，这将成为把LLM纳入道德决策的一个关键里程碑。&nbsp;</p><p>我们将走入一个与机器道德专家共存的世界。&nbsp;</p><p>参考资料：&nbsp;</p><p>https://the-decoder.com/openais-gpt-4o-outperforms-human-experts-in-moral-reasoning-study-finds/&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/l2Z7x2qwpZOpsAKEklk3VQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848997798988676</id>
            <title>「吗喽」在想啥？AI读心术精准重建猕猴大脑图像，网友：我们成三体人了</title>
            <link>https://www.36kr.com/p/2848997798988676</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848997798988676</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 07:04:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大脑注意力机制, AI读心术, 可视化想法, 扩散模型
<br>
<br>
总结: 荷兰拉德布德大学的研究团队通过大脑注意力机制和AI读心术精确生成图像，实现了可视化想法，利用扩散模型重现大脑活动为图像。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_f64d35eb433846a48e0671cbc1940835@46958_oswg248810oswg1069oswg412_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>荷兰拉德布德大学的研究团队通过定位大脑注意力机制，在AI「读心术」领域精确生成图像，能够依据大脑活动记录极为准确地重建猕猴所看到的内容。网友：这是人机融合的最终目标。</p><p>不知道大家上学的时候有没有被老师拎着耳朵，痛心疾首地问：&nbsp;</p><p>讲了八十遍还错！我真想打开你们的脑子看看里面到底在想什么？！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_6487a0e98c7c4a9c85e0f780095a8b42@46958_oswg158187oswg400oswg389_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>我们无法敲开别人的大脑，很难知道知识到底有没有镌刻在大脑里。要想做到这一点，好像只有神叨叨的读心术能实现。&nbsp;</p><p>随着AI技术的发展，不用开颅，不用植入设备，读取头脑里的想法好像真的能实现。&nbsp;</p><p>连想法都能可视化，这莫非就是现实版「摄魂取念」？&nbsp;</p><h2><strong>「摄魂取念」洞察人脑</strong></h2><p>早在2022年，就有科学家研究过如何将人脑中的图像可视化。&nbsp;</p><p>大阪大学前沿生物科学研究院的教授两位科学家Yu Takagi和Shinji Nishimoto就发表了一篇论文，用扩散模型将大脑活动重现为图像。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_500d9571fe704fcd88fc46ddbcfabd7b@46958_oswg32989oswg1080oswg274_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full.pdf&nbsp;</p><p>两位科学家招募了一群志愿者，让他们每人看一万张自然风景图（不是一次性看完）。&nbsp;</p><p>看图的时候，志愿者躺在核磁共振扫描仪里，这个大脑摄像机会记录下所有的大脑活动。&nbsp;</p><p>科学家得到脑内活动数据后，根据大脑不同的活跃部位，分为两部分，一部分是初级视觉皮层信号，另一部分是高级视觉皮层信号。&nbsp;</p><p>这些信号会化为简单线性模型里的小点点，但想画出能看懂的图来，只靠它们是不行的。&nbsp;</p><p>科学家们会用到热门的扩散模型Stable Diffusion。只要输入一段文字，就能自动产生符合描述的图画。&nbsp;</p><p>结果发现，生成的图像和志愿者看到的实际图像很接近，他们大脑里产生的画面差不多就是这样子。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_437fd5b19b8a4f62a95aa5fc459f2e45@46958_oswg338430oswg813oswg403_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「在我们这项研究之前，还没有哪个研究人员尝试用扩散模型来重构视觉图像。」Shinji Nishimoto颇为激动地告诉媒体。&nbsp;</p><p>此项研究成果一出，那是不是意味着我们真的可以和自己的小狗小猫交流了？&nbsp;</p><p>或者说，这项技术可不可以用来取证呢？将嫌疑人的想法扫描成图像，破案分分钟。&nbsp;</p><h2><strong>「吗喽」在想什么？</strong></h2><p>前阵子，吗喽表情包火了。&nbsp;</p><p>几个小猴子频频能做出像人一样的行为作态，每一只甚至还有名有姓。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_c5bfb6b0f9714f2a84920d18fef7c9af@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>坐在婴儿车里喝饮料，吗喽觉得饮料好不好喝？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_da11ab20a2a745fe9ec011000a299dc3@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>小编晚上玩手机就这样。那吗喽在看什么好玩的东西呢？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_e83e08e07f644197a3588619486ee7e0@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>吗喽看到人类的爆炸头心里在蛐蛐什么呢？怎么被吓倒了？&nbsp;</p><p>荷兰拉德布德大学的研究团队就在尝试重现猴子脑中的图像。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_9667635e21374f60856c3d1dc3106832@46958_oswg67411oswg1080oswg153_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://www.biorxiv.org/content/10.1101/2024.06.04.596589v1</p><p>他们赋予人工智能系统专注于特定大脑区域的能力，能够更好地从大脑记录中重建猴子正在观察的图像。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_7f0f6283b0004e11b17b915d2d4d4650@46958_oswg114870oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>第一行:原始图像&nbsp;</p><p>第二行:人工智能根据猕猴的大脑记录重建的图像&nbsp;</p><p>第三行:人工智能系统在没有注意力机制的情况下重建的图像&nbsp;</p></blockquote><p>现在，人工智能系统可以根据大脑活动的记录，非常准确地重建一个人正在看什么。&nbsp;</p><p>当人工智能进一步学会关注大脑的哪些部分时，这些重建图像就会得到极大改善。&nbsp;</p><p>荷兰拉德布德大学的Umut Güçlü表示，「据我所知，这些是最接近、最准确的重构。」&nbsp;</p><p>Güçlü的团队是全球使用人工智能系统，通过大脑记录和扫描，来了解动物或人所看到的东西的团队之一。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_b4484f38b1cd4ef78a2ab000f4fd42fe@46958_oswg644377oswg799oswg680_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在之前的一项研究中，他的团队使用功能性核磁共振成像(IMRI)扫描仪记录了三个人在观看一系列照片时的大脑活动。&nbsp;</p><p>在另一项研究中，研究小组利用植入电极阵列直接记录了一只猕猴在观看人工智能生成的图像时的大脑活动。&nbsp;</p><p>Güçlü的同事、拉德布德大学的Thirza Dado说，这只猕猴没有被植入基因，因此我们无法重建它的感知，我们并没有在猴子身上进行手术。&nbsp;</p><p>现在，研究小组利用改进后的人工智能系统重新分析了之前这些研究的数据，这个系统可以定位大脑中哪些部分最值得关注。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_947e77197daa4b9ba19f2fba1a2edef1@46958_oswg186567oswg773oswg1174_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「基本上，人工智能在解读大脑信号时，正在学习应该将注意力引向何处，」Güçlü说，「当然，这在某种程度上反映了大脑信号在环境中捕捉到了什么。」&nbsp;</p><p>通过对大脑活动的直接记录，一些重建的图像现在非常接近猴看到的图像，而这些图像是由Style GAN-XL人工智能图像生成的。&nbsp;</p><p>Thirza Dado说，与真实图像相比，准确重建人工智能生成的图像更容易，因为人工智能在学习重建图像的过程中，也会考虑到生成图像的过程。&nbsp;</p><p>在使用注意力引导系统时，fMRI扫描结果也有明显改善，但重建图像的准确性稍有欠缺。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_9d4d02030f254c6cb001fbd9b3f4e7bd@46958_oswg752859oswg762oswg904_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Dado说，这部分是因为使用了真实照片，但从fMRI扫描中重建图像也要难得多。「它是无创的，但噪音非常大」。&nbsp;</p><p>研究小组的最终目标是，通过刺激视觉系统中代表物体的高级部分，而不是简单地呈现光的模式，创造出更好的大脑植入物来重现视觉所见。&nbsp;</p><p>例如，你可以直接刺激与「狗」这个概念相对应的部分，Güclǔ 说。「这样，我们就能创造出更丰富的视觉体验，更接近视力正常的人的视觉体验。」&nbsp;</p><p>最近发表了大量利用AI再现动物所见的图像，这种 「读心术」的趋势似乎正在扩大，图像的质量也在提高。这是人工智能（即机器学习）应用越来越精确的必然结果。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_be8a2aa4a5364077b394b52306178b09@46958_oswg353905oswg1080oswg418_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>网友：我们成三体人了？</strong></h2><p>对于这项技术将带来什么应用，网友们纷纷展开脑洞。&nbsp;</p><p>比如，显然可以这种AI可以为医学做出贡献，用在Neuralink的应用程序上，就可以更好地了解人脑。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_bfd324112b62494da9c50e8ea4d44fd1@46958_oswg87339oswg1038oswg341_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果心灵感应和脑机接口结合，我们如果想写作是不是就不用动笔了？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_7a8cc56519d5439fb5ac87fe20805e65@46958_oswg61902oswg775oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，事情也可能会往可怕的方向发展：如果思想不再自由，而是能够被猎人射杀，情况恐怕就不妙了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_642d0ab7f71f41e793ed5b5245a329c7@46958_oswg127490oswg817oswg526_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>看来咱们离思想透明的三体人，距离是越来越近了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_6c0b27ec37ca4963a1e111b63f1d6839@46958_oswg96948oswg1043oswg236_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>思维书写技术起飞后，肯定是有利有弊。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_00ace109a74b4c778cb354cda98ac24e@46958_oswg117287oswg1030oswg403_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但还是有部分人表示欣慰：使用脑电波的计算机控制成真，这将是人机融合的最终目标。&nbsp;</p><p>参考资料：&nbsp;</p><p>https://www.newscientist.com/article/2438107-mind-reading-ai-recreates-what-youre-looking-at-with-amazing-accuracy&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Sl-qTrcjYc17yQUDCGdQqA" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：耳朵 Aeneas，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2847854731971456</id>
            <title>商汤绝影王晓刚：端到端是智能驾驶的“ChatGPT 时刻” | 36氪专访</title>
            <link>https://www.36kr.com/p/2847854731971456</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2847854731971456</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 07:04:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能驾驶, 大模型, 商汤绝影, 端到端
<br>
<br>
总结: 商汤绝影总裁王晓刚在36氪汽车的采访中谈到了智能驾驶领域的发展趋势，强调了端到端大模型在智能驾驶中的重要性。他指出，端到端大模型是实现智能驾驶弯道超车的机会，商汤绝影致力于研发通用性强的智能驾驶系统。通过与车企合作和大量数据采集，商汤绝影不断优化大模型，力求在2025年实现端到端大模型的上车。 </div>
                        <hr>
                    
                    <p>采访 | 李勤 田哲</p><p>文 | 田哲</p><p>编辑 | 李勤</p><p>“我常对同事们说，团队生命永远只有半年，活过半年才能续命。”说话者，是商汤绝影智能汽车事业群总裁王晓刚。</p><p>近几年，汽车行业仿佛坐上一辆高速行驶的过山车，各类新技术层出不穷。不到三年，智能驾驶量产落地就从高速道路，转向全国城乡道路，稍不留神，玩家们就会被市场远远抛下，失去下一轮游戏的资格。王晓刚希望这句警句，能激励团队紧跟行业进程。</p><p>2021年，商汤发布智能汽车品牌“绝影”，以Tier 1的身份切入智能汽车市场，由王晓刚掌舵。王晓刚是商汤科技的联合创始人兼首席科学家，在此之前，他作为商汤研究院院长带队研究大模型。</p><p>商汤绝影的主要收入来源一度是智能座舱业务，其与上汽、奇瑞等知名主机厂合作了上百款量产车型。然而，汽车行业更广阔、同时变革更剧烈的赛道是智能驾驶。而端到端大模型，无疑是当下影响智能驾驶走向的最大变量。</p><p>在王晓刚看来，端到端大模型至关重要，是团队实现智能驾驶弯道超车的机会。</p><p>2023年，智能驾驶进入开城竞赛，各车企和Tier 1试图研发低成本、通用性强的智能驾驶系统。当年5月，特斯拉CEO马斯克宣布，特斯拉将发布采用端到端大模型的自动驾驶系统，逐渐扭转了行业智能驾驶的研发方向。</p><p>端到端大模型旨在将智能驾驶的所有流程，整合至一个统一的模型，只需输入原始数据就能直接输出最终结果，从而大幅提升智能驾驶系统通用性。</p><p>这一轮AI与智能驾驶深度融合的浪潮，让商汤绝影看见了发挥大模型优势的机会。</p><p>今年4月北京车展期间，商汤绝影实车演示了感知决策一体化自动驾驶通用大模型UniAD，据悉，仅通过纯视觉和导航地图，车辆就能在城市、乡村道路智能驾驶。</p><p>王晓刚告诉36氪汽车，商汤研究端到端智能驾驶的契机是与本田的合作。2017年，本田汽车向商汤提出一个课题，要求商汤只用摄像头，没有高精地图的情况下实现智能驾驶功能。“当时我们在本田测试场实现了端到端的智能驾驶，自那之后，团队就持续研究端到端。”</p><p>这一次的合作，成为商汤绝影投入大模型研发的开端。2018年，商汤在上海建设超算中心，迄今已有超4.5万块GPU，总算力规模达到1.2万PFLOPS，可实现连续30天稳定训练大模型。充足的算力资源，意味着商汤绝影的模型迭代几乎不受限制。</p><p>模型训练离不开道路数据。王晓刚告诉36氪汽车，合作的量产车型在开发测试阶段，团队会定义一套数据操作标准，采集全套数据用于端到端大模型训练。待合作车型上市后，商汤将能获得更丰富的道路数据。</p><p>为了获得非公开的高质量数据，商汤绝影还开发了用AIGC视频生成了世界模型，可根据需要生成指定的场景用于模型训练。</p><p>决战时刻将至，商汤绝影一改往日的学术风格，为团队扩充了大量有着车企、Tier 1背景的新成员，补齐交付能力。</p><p>与大多数智能驾驶解决方案商不同，商汤绝影不介意白盒交付。在王晓刚看来，只有车企真正理解技术，明白现有方案的不足，才能积极配合团队共同开发，加速产品迭代。</p><p>商汤绝影把端到端大模型上车时间定在2025年，在王晓刚看来，这是商汤绝影的必赢之战，“没有Plan B”。</p><p><strong>以下是36氪汽车与商汤绝影智能汽车事业群总裁王晓刚的对话，经编辑：</strong></p><h3>谈端到端大模型研发：<strong>现在依然是删代码、加代码的过程</strong></h3><p><strong>36氪汽车：自动驾驶的算法从规则向着AI转变，转变的驱动力是什么？</strong></p><p><strong>王晓刚：</strong>&nbsp;首先，基于规则的自动驾驶每天可能遇到几千个道路场景，每个场景对应着不同的规则，如果不断编写规则，时间长久后，可能会忘记初期编写规则的作用，同时消耗的资源也十分巨大。如果用AI大模型数据驱动，自动驾驶研发效率能提升数十倍。</p><p>其次，GPT-4o的多模态数据流推理实时交互，人机交互体验有着明显提升。以前基于规则的体验非常固定，反馈单调且不够智能。现在能调动车内外的摄像头，随时随地和汽车大模型自然交互，创造很多内容，加上端到端多模态融合，非常契合汽车的使用场景。</p><p><strong>36氪汽车：分段式端到端，是真正的端到端大模型吗？</strong></p><p><strong>王晓刚：</strong>不是的。一块一块组合的模型能力很弱，不能真正理解场景中的复杂情况，而是解决被简化的任务，这种大模型不需要大网络去喂数据，也不具备像人那样的大脑。</p><p>打个比方，蜜蜂基于生物习性，对某个特定的简单任务会完成得很好，但是它的头脑特别简单，不能像人一样具备通用能力，在新场景遇到问题，会发明新工具解决新问题。蜜蜂和人，分别像分段式端到端大模型和一体式端到端大模型，分段式端到端大模型的神经网络模型很小，只会解决特定任务。</p><p><strong>36氪汽车：端到端大模型智驾的上限很高，下限难以预测，如何把控下限？</strong></p><p><strong>王晓刚：</strong>初始阶段还是要用规则兜底，端到端大模型越深入发展，规则将越少，就像感知模块的训练少，要用许多后处理融合，但是随着感知能力增强，规则就慢慢撤掉。</p><p>今天绝影的车道保持感知已经做得很好了，就删去很多规则，如果将来场景变复杂了，就继续增加规则，这是一个重复删除代码、增加代码的过程，不过加强后的大模型所需的规则会越来越少。</p><p>实际上，ChatGPT在衍生出各种应用时，也有很多规则兜底。端到端大模型的核心在于通用能力，通用能力越强，就能完成更多的事情。</p><p><strong>36氪汽车：有行业观点认为，车企大规模量产无图智驾方案后，才更利于端到端智驾方案落地，而商汤是直接跨越到端到端，两者之间有什么区别？</strong></p><p><strong>王晓刚：</strong>行业大多数端到端大模型智驾方案采用轻图方案，配有简单的标注。如果切换技术路线，成本非常高，相当于重新搭建研发体系。</p><p>所有基于规则的智驾方案，由上千名算法工程师不断写规则、打补丁以维护智驾系统。这样的方案量产上市后，还需要持续维护。如果切换技术路线，就相当于从头开始研发。</p><p>现在基于规则的智驾方案，因为在车端上写了复杂的规则，导致车端网络算法比较复杂。端到端大模型智驾方案的特点是，车端上网络算法比较简单，后台的任务比较复杂，因为不仅需要数据闭环，还要训练、清洗数据、训练大模型、把大模型分为小模型等等，以维持模型训练的稳定性。</p><h3>谈端到端大模型落地：未来汽车行业只剩车企、芯片和AI公司</h3><p><strong>36氪汽车：训练模型需要大量数据，商汤绝影的数据来源是什么？</strong></p><p><strong>王晓刚：</strong>端到端大模型是一个长期发展过程，需要分步骤进行。商汤会采集数据，也会与车企合作。</p><p>商汤绝影合作的量产车型在开发测试阶段，我们会定义一套数据操作标准，不同的量产项目车型是基于规则的智驾系统，我们采集的全套数据可以用于端到端大模型训练。</p><p>合作车型上市后会有数据回流，我们会和车企深入合作，选择、清洗更丰富的道路数据。</p><p>数据采集越深入，就越难采集到想要的特定数据，采集成本也将提高，绝影用AIGC视频生成的世界模型，进行数据采集。</p><p>至于世界模型采集数据的成本，商汤是一家平台型公司，开发的技术与不同行业合作进而分摊成本，还能和很多不同行业的合作伙伴联合开发分摊成本。因此，商汤绝影未来也会和车企深入合作数据采集。</p><p><strong>36氪汽车：商汤绝影在推动数据共享时，车企的态度是什么？</strong></p><p><strong>王晓刚：</strong>车企目前很愿意与我们共享数据，因为绝影的任务明确，车企知道哪方面存在问题，就愿意开放相关数据以解决问题。不过，目前车企没看到端到端大模型更通用的能力。如果看到的话，我想车企会更有动力和我们一起挖掘数据。</p><p><strong>36氪汽车：端到端大模型的人才画像是怎样的？</strong></p><p><strong>王晓刚：</strong>端到端大模型的平台体系非常重要，需要团队具备非常强且全面的工程化能力。如果是模型训练，相关团队应该具备创新性，需要想办法快速迭代。而在最终方案交付时，需要经验丰富的团队兜底。</p><p><strong>36氪汽车：行业角度来看，端到端大模型团队规模多大才合适？</strong></p><p><strong>王晓刚：</strong>现在许多端到端大模型团队，大部分人负责数据采集、测试、分析等工作，真正参与大模型本身工作，团队规模几十人就算多了。</p><p><strong>36氪汽车：现在行业有全栈能力的公司，还有芯片、算法等公司，您认为汽车行业未来格局如何？</strong></p><p><strong>王晓刚：</strong>车企、芯片公司还有AI公司，他们之间的合作是核心部分，其他部分比如硬件、Tier 1等集成类公司可能会被吸收。</p><h3>谈商汤绝影商业理解：汽车是大模型落地的重要场景</h3><p><strong>36氪汽车：商汤绝影的商业形态是什么？</strong></p><p><strong>王晓刚：</strong>商汤绝影有三大业务，分别是智能驾驶、智能座舱和AI云，本质上绝影为车企输出能力。</p><p>我认为终局是给车企赋能基础能力，通过数据合作打造各种体验差异化的应用，而不是交付标准化产品。</p><p><strong>36氪汽车：其他Tier 1似乎不需要车企具有智驾能力，商汤绝影恰恰相反？</strong></p><p><strong>王晓刚：</strong>车企需要理解技术，绝影可以白盒交付车企，只有车企理解后，才能根据其需要产生非常有价值的数据，将有限的资源针对性投入，从而进一步增强大模型，推动整个体系不断演进。如果车企遇到问题就找Tier 1解决，车企永远无法实现跨越式的技术发展。</p><p>端到端给智驾大模型带来了通用能力，基于这种能力可以生成很多新应用，这些应用会有很多想象空间和拓展空间，而不是只限于单一任务的理解。</p><p><strong>36氪汽车：意味着目前绝影的商业模式不特别注重交付吗？</strong></p><p><strong>王晓刚：</strong>实现远大理想有一个过程，要一步一个脚印，保证交付质量，与车企建立信任关系。现在商汤绝影的内部要求是客户、质量放在第一位，必须第一时间响应客户需求。</p><p><strong>36氪汽车：商汤绝影如何提升交付能力？</strong></p><p><strong>王晓刚：</strong>我们之前AI方面的人才比较多，现在我们引入了大量经验丰富、来自Tier 1、车企的人才。在组织机制上，后端有研发人员，前端有综合的交付团队，已经具备足够力量调动交付资源，同时我们的质量体系也在积极建设。</p><p><strong>36氪汽车：您在商汤如何分配精力？</strong></p><p><strong>王晓刚：</strong>我的精力绝大部分在绝影上，和集团研发也有很多交流。</p><p>今天来看，汽车是能推动大模型落地的重要场景，因为大模型的核心就是人机交互体验，现在人机交互界面只有手机、汽车、机器人三个。</p><p>手机现在只是文字性交互，其本身的金融属性决定了没办法通过多模态语音、视频进行交互。机器人的交互和汽车关联，甚至能复用，但是机器人没有达到大规模量产应用阶段，数据量很少，无法提供有价值的反馈，从而形成闭环。</p><p>而汽车车内外都能交互，是最好的多模态交互场景，并且产量庞大，消费者对多模态大模型的接受度会越来越高。在车内，用户能和多模态大模型交流；车外，大模型能拓展延伸用户的视觉，告诉用户车外的交通情况、建筑物、文字等信息。</p><p><strong>36氪汽车：对于商汤绝影来说，明年端到端大模型的交付落地，是必赢之战吗？</strong></p><p><strong>王晓刚：</strong>对，没有Plan B。我常常和团队说，我们只有半年的生命，半年之后可能再续命。我们有未来五年、十年的理想目标，但是生命永远只有半年。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848089092590216</id>
            <title>米哈游重磅上新，《绝区零》难复制《原神》神话</title>
            <link>https://www.36kr.com/p/2848089092590216</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848089092590216</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 05:34:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 绝区零, 米哈游, 游戏市场, 预约人数
<br>
<br>
总结: 7月4日，《绝区零》游戏在开服前引起了热议，米哈游作为游戏新秀在市场上表现出潜力。游戏提前开服，吸引了超过4000万人预约，但游戏内容和玩法可能需要时间适应。游戏在开服当日引发了讨论，是否能成为米哈游的下一个热门游戏仍有待观察。 </div>
                        <hr>
                    
                    <p>7月4日，“绝区零开服”“绝区零抢UID”“绝区零公测”等，不少于10条有关米哈游《绝区零》游戏的话题，密集登上微博热搜榜，成了显眼包。</p><p>其实，作为游戏新秀米哈游的第三款旗舰游戏产品，《绝区零》早在内测期间就展现出了潜质。</p><p>此前，米哈游旗下扛鼎之作《原神》的战绩有目共睹，在全球范围内收获了大量的粉丝和高额的收益，随后的《崩坏：星穹铁道》再次成为米哈游的新爆款，有时在流水营收上，还能与《原神》掰掰手腕。这也让米哈游是一跃成为游戏行业的当红“炸子鸡”。</p><p>如今，游戏市场竞争愈发激烈，玩家的口味也越来越挑剔，《绝区零》能否会成为米哈游的下一个《原神》呢？</p><h2><strong>火爆开服，上线前超4000万人预约</strong></h2><p>仅靠五款游戏，便跻身国内游戏第一梯队的米哈游，最近又推出了重磅产品《绝区零》。</p><p>经过近2年的测试后，原定于7月4日上午10点开服的《绝区零》提前1个半小时开服，开服半分钟UID（user Identification，用户身份证明）就显示49万多。大量用户瞬间涌入，导致前后相差几秒，UID就相差几十万甚至百万以后了。</p><p>Tech星球发现，在临近7点时，抖音某抢游戏UID账号的直播间人数就已达7000人，全站带玩榜第15名，到8点时，该直播间的人数已破万，而像这样的直播间在抖音内不下数十个，而且这还不包括米哈游玩家最爱聚集的B站直播间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240704/v2_1a7af7e8ed854a6e9a960be3e9f39218@000000_oswg163851oswg1080oswg2195_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图注：抖音内某抢游戏UID账号的直播间。</p><p>不止一位米哈游的忠实粉丝告诉Tech星球，他们提前定好了闹钟，用来抢排位靠前的UID账号。一位玩家甚至通宵蹲点。开服一分钟后，注册量突破100万人次，火热程度远超当年抢注《崩坏：星穹铁道》。</p><p>游戏提前开服并不奇怪，提前开服分流可以避免上百万人同一时刻连接服务器导致游戏体验欠佳。去年米哈游旗下的《崩坏：星穹铁道》也是提前一个多小时开服。</p><p>一位想要抢到靠前UID账号的玩家称，自己直接一晚上没睡，就怕《绝区零》提前开服。今天上午，“绝区零”抢UID的话题甚至登上了微博热搜。</p><p>《绝区零》是米哈游首款动作类角色扮演二次元游戏，2022年就推出了完成度超高的测试版，玩家对《绝区零》的期待并不意外。</p><p>7月2日，《绝区零》开放预下载，一开放便陆续登上美国、日本等超过138个国家和地区的App Store游戏免费榜榜首。7月3日，《绝区零》全球预约人数已超4000万。要知道，《原神》开服前预约量才突破300万，而《崩坏：星穹铁道》的数据是1000万。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240704/v2_a4da271088664138be14579eb4fb75ad@000000_oswg172884oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图注：绝区零在QQ和微信内的推广广告。</p><p>《绝区零》的宣发推广，也是“广撒钱”的土豪味十足。有行业人直言，绝区零在开服当天成为了B站、抖音、QQ、百度贴吧、微信等平台的“金主爸爸”。还一些玩家感叹，在QQ群里只要发绝区零和米哈游三个字就会弹出广告，“这下真不怕是有百亿宣发了？”</p><h2><strong>高开低走，“《绝区零》无聊”？</strong></h2><p>《绝区零》相比此前的《原神》和《崩坏·星穹铁道》，都有很大不同。</p><p>从画面表现来看，《绝区零》没有采用米哈游擅长的日式赛璐璐卡通的画风，而是采用偏美式卡通风的画风。无论是繁华的都市街道，还是神秘的空洞秘境，都能让玩家仿佛身临其境。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240704/v2_26f240971d6b4658873c874e8d81e77d@000000_oswg79582oswg1080oswg486_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图注：《绝区零》游戏画风。</p><p>在剧情方面，《绝区零》构建了一个充满神秘与危机的世界，剧情的推进并非线性，玩家的选择和决策会影响故事的发展走向，增加了游戏的沉浸感和互动性。而且，还《原神》玩家一直所希望的剧情一键跳过功能，也出现在《绝区零》中。</p><p>战斗系统是《绝区零》一大的亮点。一位玩家告诉Tech星球，“《绝区零》融合了动作与策略元素，操作流畅且打击感十足。”这种丰富的战斗玩法不仅考验玩家的操作技巧，更需要对角色和战场形势有精准的判断。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240704/v2_89a3b62692d44f7ebbe14f5a3c7e7ef9@000000_oswg74788oswg1080oswg486_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图注：《绝区零》战斗画面。</p><p>不过，《绝区零》对于新手玩家来说，游戏的战斗系统和剧情理解可能需要一定的时间去适应和掌握，而且相比于米哈游另外两款游戏，《绝区零》缺乏更深度的世界探索玩法。</p><p>所以，玩的时间长了后，很容易乏味，这也导致在开服当日下午，“绝区零无聊”的话题登上了微博热搜。当下谈论《绝区零》是否会成为米哈游的下一个比肩甚至超越《原神》的爆款，还为时尚早。</p><p>一方面，《绝区零》是一个轻肉鸽机制的动作游戏，而《原神》是一款开放世界角色扮演游戏。开放世界游戏通常具有更广阔的游戏世界、更丰富的剧情和更多的探索元素，能够吸引更广泛的玩家群体。相比之下，动作游戏的受众相对较窄，更注重玩家的操作技巧和反应能力。</p><p>另一方面，从开服当日的流水看，《绝区零》并未带来惊喜。截至发稿，七麦数据显示，《绝区零》在App Store的畅销总榜（注：畅销榜的排名和应用总收入有关，单日总收入越大，排名越靠前）中排名第4位，并未强势登顶。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240704/v2_108ac9597b604932affb87cb785ce831@000000_oswg82803oswg1080oswg1267_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图注：七麦数据上的苹果应用商店畅销总榜，《绝区零》排名第4位。</p><p>对比来看，米哈游旗下的《崩坏：星穹铁道》在正式开服后，仅仅只用了5个小时，就登上苹果App Store免费榜与畅销榜的总榜第一。</p><p>对于《绝区零》而言，想要超越《原神的》绝非易事，但仍有机会成为国内一款现象级的游戏产品，为米哈游开辟新的增长空间。</p><h2><strong>米哈游如何超越米哈游</strong></h2><p>被粉丝们称为“沪上暴雪”的米哈游，在二次元领域的战绩不俗。</p><p>2021年，凭借《原神》，米哈游的盈利能力超过了网易游戏。随后米哈游和网易游戏一直在争夺第二名。2022年和2023年，米哈游虽然净利润不如网易游戏，但营收却比网易游戏要高。</p><p>Data.ai公布的“2024年全球发行商Top 50”显示，米哈游2023年收入超过网易游戏，位列第8名，网易紧跟其后为第9名。</p><p>近日，索尼PS Store报告显示，索尼PS平台中前十游戏贡献了平台51%营收，其中，包含了运营超4年之久的《原神》，这也足见米哈游的商业运营能力。</p><p>米哈游的成功也让不少游戏公司感到竞争压力，甚至也备受腾讯、字节、网易等大厂关注。</p><p>2020年，据21世纪经济报道，在一张广为流传的网络截图中，字节跳动创始人张一鸣在头条内部的聊天软件lark（飞书）中表示，员工沉迷游戏影响工作。张一鸣说，“发现有一些同学经常在上班时间非常专注地聊游戏”，这让他感到“非常意外”。这个内部群里都是《原神》的游戏玩家，据说张一鸣也强迫自己玩了一个小时。</p><p>腾讯、网易更是分别测试对标《原神》的大世界游戏《王者荣耀：世界》和《代号：无限大》。</p><p>相比于其他批量打造新游戏的厂商，米哈游走的是量少质优路线。这家2011年成立的游戏公司，至今只做了7款游戏。</p><p>一位米哈游的员工对Tech星球说道，只有打造出高品质的游戏，才能赢得玩家的青睐和口碑。因此，在游戏的策划、设计、开发和测试等各个环节，米哈游都投入了大量的精力和资源。</p><p>Tech星球还独家了解到，米哈游正在研发一款全新的生活类休闲模拟经营《星布谷地》，已于近日在国外开放注册。这是一款3D类游戏，画风为偏全年龄的萌系卡通风格，对标此前爆火全球的《集合啦！动物森友会》。行业分析人士认为，在网易、腾讯陆续押宝派对、合家欢游戏之后，这类休闲游戏或许值得一试。</p><p>这款游戏可以看做是米哈游突破二次元粉丝圈层的一次尝试。对于米哈游而言，想要获取更大的市场份额，必须突破现有圈层的局限。这样米哈游才能成长为真正的游戏大鳄。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzU5MTczNjIyNA==&amp;mid=2247599639&amp;idx=1&amp;sn=8fea329c4c3373170d0ecf64545354b3&amp;chksm=ff6798e688d4a876dd6f0b03e9b9e7df1be703afa7b582a4df2da4e61758f37aa0b53f304e63&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“Tech星球”（ID：tech618）</a>，作者：陈桥辉 王琳，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848334118521472</id>
            <title>更高效更省钱，「九爪智能」用AI识别技术助力再生资源智能分选 | 早期项目</title>
            <link>https://www.36kr.com/p/2848334118521472</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848334118521472</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 05:04:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 垃圾分选机器人, 自动化分拣设备, 九爪智能, 环保设备
<br>
<br>
总结: 随着我国城市化进程加速和居民生活水平提高，固体废物产生量不断上升，垃圾分选机器人成为推动垃圾资源化利用的新选择。九爪智能是一家专注于智能分选设备研发的公司，通过高精度垃圾数据积累和AI识别能力构建，成功推出多款智能分选设备，其中高速瓶选机应用最为成熟。九爪智能在混合生活垃圾自动分拣设备领域取得突破，未来将继续推动行业自动化和数字化发展。 </div>
                        <hr>
                    
                    <p>文 | 王方玉</p><p>编辑 | 苏建勋</p><p>我国城市化进程加速和居民生活水平提高的同时，固体废物产生量也在持续上升，这给人工分拣带来了巨大的压力。而自动化的垃圾分选机器人能够提高分拣效率和准确性，减少人力需求，正逐渐成为推动垃圾资源化利用、实现可持续发展的新选择。</p><p>随着“双碳”以及循环经济的大战略推进，精细化、高效、绿色的再生资源分选需求越来越强烈。据测算，到2030年，我国混合生活垃圾、建筑装修垃圾、可回收物的自动化分拣市场需求可达140-180亿元，将持续高速增长。</p><p>垃圾分选机器人的“进化”得益于人工智能、机器视觉、深度学习等技术的不断进步，这使得其能更精准地识别和分类各类垃圾，在复杂环境保持适应性和工作效率。目前国内多家企业已将这些先进技术应用于产品中，并在实际场景中成功落地，来自广州的九爪智能就是其中之一。</p><p>广州九爪智能科技有限公司（以下简称“九爪智能”）成立于2021年6月，是一家高端智能分选设备及解决方案提供商，专注于研发基于人工智能和多模态传感相融合的新一代智能分选技术，用技术实现传统人工的完全替代和资源纯度的极大提升。</p><p>截至目前，九爪智能已推出四款智能分选设备，包括了超高速AI多模态光选机器人ULTRASORT、高速AI多用途分选机器人FLEXSORT、高速AI多用途重载分选机器人MIGHTYSORT和高速瓶选机BOTTLESORT，可以有效适应多类资源分选场景，并且满足客户对超大处理量、超高精度和高稳定性的共性需求，帮助客户降本增效。</p><p>“九爪智能最大的优势在于高精度垃圾数据的积累和AI识别能力的构建，我们借助环卫产业运营的场景优势，花费6年时间积累了30万+张涵盖生活垃圾、可回收物垃圾、装修垃圾、建筑垃圾、陈腐垃圾等全领域的实景垃圾大数据库，打造了业内领先的算法。” 九爪智能创始人兼CEO李希卓告诉36氪。</p><p>据悉，九爪智能创始人李希卓在华为、卓粤集团从事物联网软件研发工作近10年、智能分选设备5 年，同时也是环保行业的第二代连续创业者，因此得以将人工智能研发经验与传统垃圾分选场景数据相结合，打造出了自动化、智能化的分选解决方案，并在海内外多地成功落地应用。</p><p>四款智能分选设备中，高速瓶选机BOTTLESORT目前在下游市场的应用最为成熟，据李希卓介绍，该产品目前可帮助客户降低 40%左右的人力成本，同时在产能方面也有近一半的提升。九爪智能将高速瓶选机的成本大幅下降，向更多中小民营企业推广，实现了环保设备的平权。</p><p>混合生活垃圾、家装建废、工业固废的自动化分拣设备在行业内则处于初期探索阶段，同时也有着更高的技术难度。九爪智能凭借长期积累的高精度垃圾数据和AI识别能力，在这一领域实现了突破。</p><p>李希卓表示，九爪智能的混合生活垃圾自动分拣设备已在国内外下游客户处受到了广泛好评。“九爪的混合垃圾自动分拣设备不仅仅是为客户锦上添花，而是已经成为了客户的必选项，帮助其大量节省了人力。”</p><p>团队方面，除了创始人李希卓外，九爪智能还聚集了一批拥有机器视觉和物联网核心技术积累，以及数十年高端装备、环卫运营领域的资深产业经验的人才，兼具研发实力与产业化经验。</p><p>当下，再生资源回收行业正在经历剧烈变革和转型，随着国家政策不断出台，现有人工分选模式跟不上政府合规性要求和企业自身发展的步伐，固废分选的“机器换人”大势所趋，九爪智能的创业恰逢其时。</p><p>下一步，李希卓表示，九爪智能将会继续挖掘固废分选市场中的其他标准化应用场景，研发推出对应的新产品，推动行业自动化和数字化的发展进程。同时将进一步加快出海进程，用“科技平权”的方式为全球客户解决垃圾资源化利用的挑战。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848791363476361</id>
            <title>重磅，苹果或面临383亿美元罚款</title>
            <link>https://www.36kr.com/p/2848791363476361</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848791363476361</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 03:43:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数字市场法案, 欧盟, 苹果, 反垄断
<br>
<br>
总结: 欧盟颁布的《数字市场法案》被认为是一项重要的数字监管法案，旨在遏制数字巨头企业的行业垄断。该法案对苹果公司提出指控，涉及限制开发者自由引导客户的能力等问题。苹果否认不当行为，并表示已做出改变以符合法规。苹果可能面临高达383亿美元的罚款，但可以通过满足规则要求避免。同时，日本也推出类似的反垄断法案。 </div>
                        <hr>
                    
                    <p><strong>欧盟《数字市场法案》（DMA）被业界认为是一项里程碑式的数字监管法案</strong>，因为DMA仿佛是专门为遏制数字巨头企业公司的行业垄断而生。过往反垄断法和反不正当竞争法里没有完全解释清楚、或者调查起来很困难的一些条款，如今落地在《数字市场法案》中，并直接用立法形式变成大平台要遵守的义务。</p><h2><strong>一、欧盟向苹果打出的“第一枪”</strong></h2><p>欧盟的《数字市场法案》于今年3月7日生效，生效当月即宣布对苹果应用商店以及苹果Safari展开违反法规的调查。</p><p><strong>6月24日，欧盟委员会将调查结果发布在官方平台上，并将结果通知给了苹果。</strong>这项指控是欧盟委员会根据《数字市场法案》提起的第一项指控。公告称，美国苹果公司的应用商店（App Store）涉嫌违反欧盟的《数字市场法案》，他们担心苹果限制了开发者“自由引导客户”的能力。</p><p>比如：</p><p>1、App Store的一些新条款不允许应用程序开发者与他们的终端用户自由交流，也不允许与他们签订合同；</p><p>2、开发者不能在应用程序内提供价格信息，也不能以任何方式向客户促销第三方渠道提供的优惠；</p><p>3、苹果只允许通过“链接”来操作。这意味着应用程序开发者可以在他们的应用程序中包含一个链接，将客户重定向到一个网页，客户可以在那里签订合同。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_4d9aa128010b4922a0db809a5c48928a@15154927_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>不过苹果否认有任何不当行为。</strong></p><p>苹果表示，在从开发者和欧盟委员会获得反馈后，在过去几个月里已经做出了一些改变，以符合《数字市场法案》。其在一封电子邮件声明中表示：“我们相信，我们的计划会符合该法规。根据我们制定的新商业条款，预计超过99%的开发者将向苹果支付相同或更少的费用。”</p><p>因此，欧盟的下一步将继续对苹果针对第三方应用开发商和应用商店的新合同要求，以及这些要求是否必要和合理展开调查。</p><h2><strong>二、苹果或将面临383亿美元罚款</strong></h2><p>根据规定，现在苹果公司需要审视委员会的调查结果，并作出正式回复。按照日程，欧盟委员会可能会在2025年3月底前作出最终决定。如果苹果最终被判定违规，<strong>最高将面临全球年营收10%的罚款，在累犯的情况下，这个罚款的最高比例可以达到20%。</strong></p><p>这意味着，如果以2023财年苹果3833亿美元为计算标准，苹果面临的罚款总额将达到383亿美元，约合人民币2795亿元。</p><p>当然，如果苹果能够做出满足规则要求的改变，自然也能避免罚款。欧盟反垄断机构掌门维斯塔格表示，现在的立场是苹果应该自己决定如何满足《数字市场法案》的要求，而不是欧盟告诉他们该怎么做。</p><h2><strong>三、面对“法案”出击，苹果怎么应对</strong></h2><p>欧盟打响“《数字市场法案》第一枪”之际，苹果率先出招——6月21日公司表示，公司无法在今年向欧盟用户发布个人智能化系统“Apple Intelligence”、Mac上的“iPhone镜像”和FaceTime通话中的“SharePlay Screen Sharing”功能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_81c6f6bbbd28401ab6971d51ff488b1b@15154927_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>苹果也将责任明确归咎于《数字市场法案》。<strong>苹果指出，《数字市场法案》迫使其降低其产品和服务的安全性，给公司带来了“不确定性”。</strong></p><p>同时，苹果公司不得不对App Store进行一些调整。其中之一就是允许开发者在其应用程序中提供替代支付选项。</p><p>目前，苹果公司已经确认，<strong>在visionOS 1.2版本开始，将为欧盟用户提供第三方支付选项。这是为了适应法律要求，同时为用户提供更多的选择。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_f1c7485538b54342bfe68654617ed4b4@15154927_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在此之前，苹果已经在iOS、macOS、watchOS和tvOS应用中允许开发者使用替代支付选项。当用户需要使用外部支付平台或网站完成交易时，他们会跳转到另一个支付页面，并在该页面上完成付款流程。然而，开发者仍然需要向苹果支付手续费。</p><h2><strong>四、日本趁势出击，跟进欧美颁布新法</strong></h2><p>近期，日本也推出了与欧盟DMA类似的法案。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_69f9f344954044e1a9e54fb1965b232f@15154927_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>6月12日，日本公平竞争委员会（JFTC）官网公布，<strong>反垄断法案《智能手机特定软件竞争促进法》在日本参议院获得通过并实施。</strong>这项法案是日本政府为打破大型科技公司在智能手机应用市场的垄断的最新举措，与DMA类似，旨在创造一个充分竞争的环境，同时确保智能机使用所需软件的安全性，预计将于2025年底生效。</p><p>随着智能手机迅速普及并成为社会生活和经济活动的基础，使用智能手机所必需的移动操作系统 、应用程序商店、浏览器和搜索引擎等“特定软件”市场形成只有少数平台经营者的寡头市场，而这些经营者的反竞争行为阻碍了相关市场的公平和自由竞争。</p><p><strong>为了解决“特定软件”市场存在竞争问题，日本公平交易委员会 (JFTC) 将相关市场业务规模达到符合内阁令标准的经营者，称为“指定提供商”。</strong>此次的“特定智能手机软件竞争促进法案”主要包含以下规定。</p><p>1、在关于应用程序存储竞争限制上，法案要求，“指定提供商”不得阻止第三方提供商提供自己的应用程序商店，除非是为实现安全、隐私、保护青少年等目标所必需的正当措施。</p><p>2、近年来，谷歌、苹果的“应用内支付”设置频频陷入合规争议，法案就此明确，“指定提供商”不得阻止应用程序开发者使用第三方付费手段，比如提出施加禁止第三方付费系统的条件等。</p><p>3、在大型平台“自我优待”问题上，法案规定“指定提供商”不得歧视或不公平地对待应用程序开发者；也不能没有正当理由的情况下，在显示搜索结果时对自家服务采取任何形式的优待。</p><p>4、法案要求“指定提供商”不得阻止其他应用程序开发者使用其他浏览器引擎或者其他具有相同性能水平的操作系统，不得将提供服务获取的相关数据用于与第三方竞争等等。</p><p>不难看出，这项法案对标美国司法部对数字平台运营商的诉讼、欧盟《数字市场法》以及英国《数字市场、竞争和消费者法案》等反垄断监管手段，旨在维护日本市场公平竞争的环境。</p><h2><strong>五、各国法案“硬钢”科技巨头、游戏企业迎何契机？</strong></h2><p>不管是欧盟委员会根据《数字市场法案》（Digital Market Act, DMA）还是日本推出《智能手机特定软件竞争促进法》，<strong>其背后折射出的是，当下对于数字经济和平台经营模式的法律框架和司法实践</strong>。</p><p>DMA等法案的监管对象主要是谷歌、苹果、微软、亚马逊等“数字巨头企业”，通过对这些企业的监管，防止这些企业所占据的网络主导地位可能带来的危险，打击因为垄断而可能产生的违反竞争的行为，<strong>从而提升和鼓励像游戏企业、支付服务商等数字服务供应商的创新和公平竞争</strong>，保护平台使用者特别是普通消费者的使用安全和对于数字平台的自由选择权。</p><p>那么这些法案的落地对游戏开发者来说意味着什么呢？对游戏企业未来的发展有着怎样的启示？这些都需要游戏开发者认真关注和研究。</p><p><strong>①未来市场更加公平</strong></p><p>DMA重点规制了数字巨头企业的行为，同时较充分地考虑了中小企业的合规压力，豁免了其很多合规业务。如DMA规定了数字巨头企业不得利用自身优势，实施不公平的交易行为和竞争行为，此外还需要保障个人数据安全使用和在线广告领域的公开透明。</p><p>因此，游戏开发者的规模化发展壮大成为了可能，从而能够激活整个游戏市场的竞争力和创造力，营造更公平开放的市场环境。这种公平竞争的环境有助于推动整个行业的创新，促使企业不断改进产品和服务。因此，游戏开发者将有更多机会创新，促进新游戏机制、故事叙述和交互体验的发展。</p><p><strong>②保证平台的交互性</strong></p><p>DMA规定了数字巨头企业应允许用户安装和使用第三方应用软件，并保证其操作系统与第三方应用软件能够进行交互操作，不得在技术上限制终端用户利用其操作系统在不同软件应用和服务之间切换和订阅的能力。</p><p>这意味着游戏开发者有更多机会在不同的设备和操作系统上提供他们的游戏，而不受限于单一的应用商店或支付系统。同时，各大平台允许用户安装第三方应用程序或应用商店，这进一步降低了市场准入壁垒，使得更多的游戏开发商能够直接接触消费者。</p><p><strong>③降低运营成本</strong></p><p>根据DMA的要求，数字巨头企业不得强制游戏等应用开发者使用其支付系统，才能被允许在应用商店中上架。<strong>这有助于降低游戏出海企业在支付系统方面的运营成本，因为企业可以选择更经济或效率更高的支付渠道。如像Waffo支付服务提供商，能够为游戏企业提供安全、合规、便捷的支付服务。</strong></p><p>法案还禁止数字巨头企业利用数据与业务用户竞争，这样游戏开发企业就不必担心自己的数据会被用来与自己竞争，从而减少了在数据保护上的额外投入。</p><p><strong>④保障用户权益</strong></p><p>在数据上，DMA规定了数字巨头企业不得在未授权的情况下处理个人数据；不得在除核心平台服务外的其他大型平台企业服务中交叉使用相关个人数据；应确保用户活动中所生成数据的可携带性；应向用户免费提供有效、高质量的汇总数据或非汇总数据等。</p><p>此外，DMA限制数字巨头企业将商业用户在平台上产生的非公开数据用于针对商业用户的竞争；禁止其对商业用户在其他平台上以不同的交易条件提供产品或服务、发布优惠信息、进行产品推广等进行限制；禁止其在排名及相关的索引和抓取过程中给予自身的服务和产品优于第三方类似服务和产品的待遇。二是引入了事前事中监管的数据竞争合规监管机制。</p><p>我们可以预见，“数字巨头企业”被监管和反制是顺应市场发展规律的，因为对于直接消费者来说，被强买强卖本身就是无奈且愤怒。为了营造公平的市场环境，相信各国各地会不断摸索和适应，陆续推出“法案”。而游戏出海企业应该紧跟市场政策变化，最大限度地利用这些机会，积极调整合规策略，优化产品服务，不断提升全球的竞争力。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/jc7PME5sN19iQIts8Lo05Q" rel="noopener noreferrer nofollow" target="_blank">“DataEye游戏观察”（ID:DataEye）</a>，作者：小羊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848772069136771</id>
            <title>蜜雪冰城、古茗上市招股书双双失效</title>
            <link>https://www.36kr.com/p/2848772069136771</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848772069136771</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 03:15:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 蜜雪冰城, 古茗, 上市进程, 资产负债率
<br>
<br>
总结: 蜜雪冰城和古茗的上市进程中断，招股书失效，可能推迟递表。蜜雪冰城拥有3.6万家门店，资产负债率仅30%，而古茗负债高企，负债率高达95%。古茗首次进入上海快闪店反响不错，但资不抵债状态仍存。同行茶百道上市后破发，市值跌去3成多。 </div>
                        <hr>
                    
                    <p>蜜雪冰城和古茗的上市进程中断了。</p><p>7月3日，港交所信息显示，蜜雪冰城、古茗的上市招股书均已失效。</p><p>今年1月2日，蜜雪冰城、古茗同日向港交所递交上市招股书，然而它们的上市进程一直没有实质性进展，如今招股书均已失效。值得注意的是，招股书失效并不意味着企业放弃上市，它们可以补充新的财务数据，再次递交。但截至发稿，均未在港交所发现两家企业重新递表。</p><p>一位长期关注消费领域的投资机构人士告诉茶咖观察，他认为，由于市场不够乐观，古茗或将推迟递表。</p><p>蜜雪冰城创立于1997年，据其招股书披露，截至2023年9月，蜜雪冰城在中国及海外11个国家拥有3.6万家门店，其中超过99.8%的门店为加盟门店。古茗成立于2010年，据其招股书披露，截至2023年底，古茗拥有超过9000家门店，已进入中国15个省份、约200个城市。与蜜雪冰城一样，古茗也是靠加盟快速扩张，9000家门店中，直接管理的直营门店仅6家。值得一提的是，6月21日-23日，古茗以快闪店形式首次进入上海，且反响不错，快闪店开业1小时，杯数总量超过8000杯。</p><p>从资产负债率来看，2023年三季度，蜜雪冰城的账面资金近40亿元，资产负债率也只有30%，古茗是当下最急于上市的企业。大面积的建设仓库及供应链建设，使古茗负债高企。2021年、2022及2023年前三季度，古茗的负债总额分别为32.5亿元、38.5亿元、40.7亿元。其中流动负债分别为30.8亿元、36.7亿元、38.5亿元。值得注意的是，2021年和2022年，古茗一直处于资不抵债的状态，即使2023年前三季度状况有所好转，负债率仍高达95%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_5ca80e1ab9e945648a842aab442bdbe6@1743780481_oswg188248oswg1080oswg756_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从同行业来看，4月23日，茶百道（02555.HK）挂牌港交所，发行价为17.5港元/股，共发行1.48亿股股票，集资25.86亿港元，发行市值约258.6亿港元。发行当日，茶百道破发，截至今日收盘，其股价报10.9港元/股，市值跌去3成多。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/q3MWk8l7-IQxHjkzwyjN6w" rel="noopener noreferrer nofollow" target="_blank">“茶咖观察”（ID:newbp-）</a>，作者：薛向，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848786689808773</id>
            <title>大疆，杀入E-Bike赛道</title>
            <link>https://www.36kr.com/p/2848786689808773</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848786689808773</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 03:14:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: E-Bike, 大疆, Avinox, Amflow
<br>
<br>
总结: 大疆推出了用于E-Bike的电助力系统Avinox，并发布了首款搭载Avinox的高端电助力自行车产品Amflow PL。大疆选择以电助力系统供应商的身份进入E-Bike市场，为国内供应链稳定，助力国产品牌走向海外市场。大疆在E-Bike领域展现了技术实力，为整车厂商提供新的国产化选择。大疆跨界入局E-Bike，掘金高价值环节，看中了E-Bike市场巨大潜力。 </div>
                        <hr>
                    
                    <p>卷出高度的E-Bike赛道，来了一位重量级玩家。</p><p>7月3日，大疆宣布进入全新领域，推出了用于E-Bike的电助力系统Avinox。同日，首款搭载Avinox的高端电助力自行车产品——全地形电助力山地车Amflow PL也正式亮相。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_bf28164c9e89432fbdc4d2a882fc5b7c@1629410002_oswg34703oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：大疆官网截图</p><p>不过，Amflow并不是大疆旗下产品，而是大疆参与孵化的E-Bike品牌。</p><p>早在去年，就有报道称大疆进入E-Bike行业，并且该项目的启动时间在2020年之前，旗下产品定位高端车型、运动越野场景，主攻海外市场。</p><p>如今看来，大疆是选择以另一种身份入局。</p><p>在Amflow PL发布之前，大疆已对其DJI Avinox 电助力系统进行了预热，在其官网上发布了DJI Avinox的预告片。据了解电助力系统包含传感器、控制器、电机三部分，是E-Bike的核心结构，作为深耕无人机赛道的玩家，大疆在传感器、控制器、电机领域有着独特的优势。</p><p>大疆的入局，无疑是看中了E-Bike巨大的潜力。在欧美市场，E-Bike的受众越来越多，也出现了越来越多的品牌来分食蛋糕。而市场上不少E-Bike贴着“Made in China”的标签，大疆的加入，为E-Bike国内供应链的稳定添力，助力Amflow同Tenways、Aventon、Urtopia、Velotric等国产品牌一起走向海外市场。</p><h2><strong>大疆跨界入局，找到新赛道</strong></h2><p>大疆早在2020年便在内部孵化了E-Bike项目，将其命名为“EB”，项目团队最开始由一群E-Bike爱好者组成。</p><p>Amflow PL的亮相，宣告大疆跨界入局已是事实。据Amflow官网信息，其最初团队由几个爱好骑行的工程师组成，他们想要横跨技术与艺术、兼顾轻巧与强大，造一辆惊世骇俗的车。于是他们与大疆合作，组建团队，进入这个竞争激烈的行业。</p><p>目前，Amflow的团队还没有曝光。而据天眼查信息显示，在2023年6月，深圳成立了一家名为“安流自行车（深圳）有限公司”的企业，股东为在香港成立的沃壤科技有限公司，法人为宋健宇。</p><p>而在大疆的创始团队中，也有一位名为宋健宇的创始成员。并且天眼查信息显示，安流自行车（深圳）有限公司与大疆还有些许疑似关联。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_8a664fc0a0e241eda9b47b5702bf97df@1629410002_oswg168894oswg1080oswg516_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：天眼查</p><p>大疆进入这一赛道的原因，首先是其在电机、减速机构、电池技术、电气化等方面的技术积累。</p><p>E-Bike与传统自行车的区别，就在于其配置了电助力系统，大疆是以电助力系统供应商的身份，服务E-Bike整车厂商。</p><p>Amflow PL作为全球首款搭载大疆Avinox 电助力系统的电助力山地车，其核心的大疆Avinox 电助力系统单元展现了大疆在该领域的技术实力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_9b3c59b724c84740ba23fa564460e9b5@1629410002_oswg64069oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：大疆官网截图</p><p>过去几年，E-Bike电助力系统基本被博世和禧玛诺等巨头占据，国内同类厂商很难打破僵局。根据Avinox的参数信息，该构建重量 2.52 千克，体积手掌大小，扭矩可达 105 牛米，额定功率 250W，最大功率 850W，电池续航最低可达 117 公里，结合大疆在算法上的加持，Avinox兼具了性能、续航等用户体验，为E-Bike整车品牌提供了新的国产化选择。</p><p>大疆在全球消费级无人机赛道的地位稳如泰山，因此，大疆近年来也在不断拓展业务线，将电机衍生产品线拓展到了其他领域，还布局了智能车载、农业、教育等行业，对外提供B端和C端产品此次入局E-Bike，背后也有相同的原因。</p><p>据媒体采访大疆相关负责人的报道，大疆的定位是电助力系统供应商，专注于做To B供应商。</p><p>对于Amflow未来的发展，大疆虽然参与了其孵化，但据透露，在之后，Amflow产品开发、营销、日常运营等方面也会越来越独立。</p><p>此次发布的Amflow PL分别有 Amflow PL Carbon（800Wh）、Amflow PL Carbon Pro（600Wh）、Amflow PL Carbon Pro（800Wh）三个版本，均将于2024年第三季度在 Amflow 官方商城、京东、天猫及线下授权体验店等渠道正式发售。届时，国内外消费者都可以体验大疆在新领域的产品。</p><h2><strong>大疆另辟蹊径，掘金E-Bike高价值环节</strong></h2><p>大疆入局E-Bike，背后是这一市场的巨大潜力。</p><p>据德勤的数据显示，全球E-Bike的市场价值在2031年预计将达到725亿美元。由于E-Bike的单价较高，当前E-Bike的主要市场还是在欧美。有数据显示，在骑行文化最发达的德国和荷兰，E-Bike对自行车的渗透率已经超过70%；在美国这一新兴市场，E-Bike也展现出不俗的市场潜力。</p><p>市场的景气度，也让不少四轮汽车厂商开始关注这一风口，保时捷、宝马、劳斯莱斯等在E-Bike赛道上动作不断。捷安特、Specialized、Marin等自行车老品牌们也相继推出了电助力自行车车型，进行产品拓新和品牌升级。</p><p>海外市场的火热，让国内供应链受益。2022年，中国E-bike整车出口达996.13万辆，同比增长121%。全球约60%的E-bike市场份额被中国品牌占据，中国制造的E-bike已占美国市场的九成左右。</p><p>此外，“碳中和+短途出行+消费科技+智能硬件+出海”等要素加身，也让资本也早早关注到这一风向，据不完全统计，红杉、高瓴、高榕、深创投、挑战者资本、华映资本、光速中国、DCM、险峰K2VC、腾讯等在E-Bike均有投资动作。</p><p>今年7月的第一天，E-Bike品牌URTOPIA（嘉兴哲轮科技有限公司）宣布完成超千万美元A轮融资。本轮的投资者中不仅有地方产业基金和市场资本，被誉为“大湾区创业导师的”高秉强教授也参与了跟投。</p><p>不只是Urtopia，在海外杀出一片天地的Tenways、Aventon、Velotric等国产E-Bike品牌，也都已经被知名机构领投。</p><p>大疆此时入局，并没有与上述品牌直接竞争，而是杀入高价值供应链。</p><p>E-Bike的结构和原理并不复杂，在内部安置以传感器为核心的动力系统，再配备电机与锂电池，就能达到助力骑行的体验。大疆所做的Avinox 电助力系统，正是E-Bike中成本最高的部件之一。</p><p>而在底层技术逐渐成熟的当下，很多E-Bike厂商的角色选择了“多方采购+组装”的方式生产，并压低售价来形成竞争优势。</p><p>在这种追求极致性价比的竞争态势下，E-Bike厂商难免会陷入了尴尬局面。此前有媒体援引行业人士的观点：一台售价1000欧元的E-Bike，国内采购成本大概400欧，运费200~250欧，电商佣金占比15％~20％，再加上海外税收，这些固定成本无法减少，只能在前端制造和后端品牌溢价两个方向降本增效。</p><p>因此，大疆此时选择以B端供应商的角色切入E-Bick高端市场，既避免了与国内厂商的直接竞争，也可以在上游的核心供应环节凭借技术优势保证业务利润率。</p><p>不贸然做E-Bick整车品牌，也是因为在资本的追捧下，行业必然会产生泡沫。</p><p>2023年，在E-Bike重要消费市场的欧洲国家荷兰，一家E-Bike明星公司VanMoof被阿姆斯特丹法院正式宣布破产，并向第三方寻求出售其荷兰业务。VanMoof在2021年9月拿到由高瓴领投的1.28亿美元C轮融资，创造E-Bike行业历史上最大的单笔融资。</p><p>即便是明星公司，在没有强劲的业务体系下，也会陷入巨大的挑战。VanMoof在售后、供应链的短板，是其最终处境的直接原因。</p><p>大疆的入场方式，显然背后有更务实的思考。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/DH6cYnnVgu0VDMt-n-ffXw" rel="noopener noreferrer nofollow" target="_blank">“猎云精选”（ID:lieyunjingxuan）</a>，作者：邵延港，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848793487821444</id>
            <title>年度超级LP出现了</title>
            <link>https://www.36kr.com/p/2848793487821444</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848793487821444</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 03:14:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 国家中小企业发展基金, 子基金, 出资机构, 投资方向
<br>
<br>
总结: 今年国家中小企业发展基金第六批子基金设立完成，总规模112亿元，共42支子基金。超级母基金密集出资，一举投6家GP，其中包括普华资本、基石资本等。各子基金主要投向智能制造、生物医药、新能源等领域的中小企业。国家中小企业发展基金成立四年来，累计投资项目超过1500个，支持了多个创新型企业。 </div>
                        <hr>
                    
                    <p>今年募资振奋一幕出现——</p><p>投资界-解码LP获悉，日前，国家中小企业发展基金完成第六批正式宣布完成出资，<strong>普华资本、基石资本、达晨财智、元璟资本、通和毓承、国中资本</strong>等六家机构成为新基金的管理人。</p><p>此次设立的子基金总规模112亿元。至此，国家中小企业发展基金第六批子基金设立完成，其全部子基金认缴总规模已经超过1080亿元，数量累计42支。</p><p>令人期待的是，国家中小二期基金也要来了。</p><h2><strong>超级母基金密集出资，一举投6家GP</strong></h2><p>整个出资动作在一周内密集完成。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_76c01a9061464335b7bc876319427057@1743780481_oswg346543oswg1080oswg1013_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>6月21日，国家中小企业发展基金宣布完成第六批第一、二支子基金签约设立工作，并披露了被投机构，分别为：</p><p><strong>第一</strong>，普华中小二期（杭州）创业投资合伙企业（有限合伙），注册地在浙江杭州，管理机构为浙江普华天勤股权投资管理有限公司，即<strong>普华资本</strong>，主要投向高端装备制造、新一代电子信息、新能源新材料、医疗健康等领域的中小企业。</p><p><strong>第二</strong>，湖北省基石中小发展创业投资基金合伙企业（有限合伙），注册地在湖北武汉，管理机构为基石资产管理股份有限公司，即<strong>基石资本</strong>，主要投向新一代信息技术、集成电路、高技术制造、生物医药、人工智能、新能源新材料、现代服务等领域的中小企业。</p><p>这支基金由武汉基金联合基石资本、国家中小企业发展基金等共同发起，规模15亿元。据了解，这是国家中小企业基金第六批子基金中，在中西部地区落地的首支子基金，也是武汉基金重组后与国家级引导基金合作设立的首支子基金。</p><p>6月27日，国家中小企业发展基金宣布完成第六批第三、四、五、六支子基金签约设立工作并披露投资机构，分别为：</p><p><strong>第三</strong>，湖南达晨财智中小企业创业投资基金合伙企业（有限合伙），注册地在湖南省长沙市，管理机构为深圳市达晨财智创业投资管理有限公司，即<strong>达晨财智</strong>，主要投向智能制造、新一代信息技术、生物技术等相关领域的中小企业。</p><p>其中，这一笔出资落地后，达晨财智宣布旗下基金完成首轮募集关闭，基金总规模约30亿元，获得了包括基石投资人国家中小企业发展基金、湖南省产业引导基金、长投控股、湘江国投、广州产投、安徽高新投、大连市引导基金、湖南云起盛世，以及达晨财智股东电广传媒等多个国资/政府投资平台的出资。</p><p><strong>第四</strong>，杭州元璟新创中小创业投资合伙企业（有限合伙），注册地在浙江省杭州市，管理机构为杭州元璟睿恒投资管理有限公司，即<strong>元璟资本</strong>，主要投向智能制造、生物医药、数字医疗、人工智能、信息科技、消费升级及互联网等领域的中小企业。</p><p>这是元璟资本自2021年获得国家中小企业发展基金出资以来的再一次出资，与此同时，元璟资本新一期人民币基金也正式完成超10亿元首关，将主要投向硬科技、前沿技术、智能制造、医疗科技等相关领域的中小企业。</p><p><strong>第五</strong>，合肥通和四期股权投资合伙企业（有限合伙），注册地在安徽省合肥市，管理机构为崇凯创业投资咨询（上海）有限公司，即<strong>通和毓承</strong>，主要投向创新生物制药、新一代生物技术和疗法、创新医疗器械及生命健康等领域的中小企业。</p><p><strong>第六</strong>，国中（深圳）三期中小企业发展私募股权投资基金合伙企业（有限合伙）。基金规模40亿元，注册地在广东省深圳市，这是深圳落地的第4支国家中小企业发展基金子基金，管理机构为深圳国中常荣资产管理有限公司，即国中资本。</p><p>投资方向上，这支基金主要包括新能源汽车与智能驾驶、新材料与新能源、智能装备、生物医药与大健康、大数据云计算网络安全及企业服务、半导体、电子信息技术与人工智能与新经济等领域的中小企业。</p><p>至此，第六批全部子基金的签约设立工作完成，总规模112亿元。</p><h2><strong>超级LP缔造千亿集群，二期基金正在筹备</strong></h2><p>这是国家中小企业发展基金成立的第四年。</p><p>如今，新一批子基金的签约设立任务顺利完成后，子基金认缴总规模超过1080亿元，数量累计42支。基金管理公司也在四周年之际总结了成立以来的成绩：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240705/v2_d94645876a8141f4b5ef787f87085fb2@1743780481_oswg308192oswg1080oswg374_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一是聚焦<strong>投早、投小</strong>，支持中小企业走专精特新发展道路，累计投资项目超过1500个，其中初创期成长型中小企业超过1200个，培育专精特新企业783个，小巨人企业281个，独角兽企业超过40个，累计帮助已投项目新增股权融资超过4800亿元。</p><p>二是聚焦<strong>投创新、投硬科技</strong>，加快培育新质生产力，投资了一大批科研能力强、发展潜力大的创新型中小企业，在量子信息、具身智能、生成式AI等未来产业以及商业航天、低空经济等新兴产业的投资项目超过800个，支持了<strong>月之暗面、宇树科技、国仪量子、蓝箭航天</strong>等一批创新企业。</p><p>三是聚焦<strong>关键核心技术</strong>，积极推进补链强链，在新一代信息技术、集成电路、高端装备制造、生物医药、新能源、新材料等国家重点发展领域的投资项目超过1300个，金额占比近90%，支持了<strong>华大九天、莱特光电、海博思创、微导纳米</strong>等一大批产业链关键企业，充分发挥了中小企业在提升产业链供应链稳定性方面的生力军作用。</p><p>追溯国家中小企业发展基金的成长经历，2020年5月，在工信部与财政部的牵头推动下,中央财政与上海国盛、中国烟草等社会出资人共同发起成立了国家中小企业发展基金有限公司（母基金）。</p><p>基金注册资本为357.5亿元，通过投资设立子基金等方式，同时保留部分可投资金用于跟随子基金直接投资相关优质项目，使基金总规模达到1000亿元以上，重点解决创新型中小企业的中长期股权融资问题。</p><p>过去的四年里，国家中小企业发展基金常被视作“最活跃国家级母基金”，不仅出资速度极快，累计出资设立40多支子基金，对GP的遴选也十分严格，涵盖了深创投、达晨财智、基石资本、源码资本、同创伟业等一大批头部知名机构或细分领域的头部机构。</p><p>这一最活跃母基金背后，也代表着国家级母基金的主要方向：</p><p>首先“投早投小投科技”自是不必说。与此前出资风格一脉相承，基金多投向硬科技、信息技术、新能源和生物医药等领域；在对“中小企业”的扶植上，可以说国家中小企业发展基金是“耐心资本”的主要践行者，当下，“耐心资本”被提到更高的位置，国家级母基金的领头更加关键。</p><p>此外，母基金一定程度上起到了地区间的调控作用，开始向中西部城市的中小企业发力，以这一次出资为例，子基金就加大了在湖北武汉、湖南长沙等中部城市落地的比例。</p><p>另一方面，子基金的管理机构多为头部机构，而此次的不少机构多年前就曾获得过国家中小企业发展基金的出资。从国家级母基金的选择上来看，如今能留在牌桌上、成功募资的VC/PE，必然是有一定体量和经验的头部机构，或是在垂直细分赛道有自身独特优势的机构。</p><p>过去几年，各地政府引导基金大爆发，地方通过基金招商争抢新兴产业更是愈演愈烈，此前甚至出现一家企业为了满足融资要求在几座城市落地工厂。而国家级母基金大举进入市场，不仅能带来更多活水，或许在一定程度上也能够缓解地区间招商引资的“零和博弈”情况。</p><p>据了解，国家中小基金下一步还将加快推进基金二期设立工作，下一批资金进入市场，又将搅动一池春水。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ThDB0SC_BT51tFu_8PpU8w" rel="noopener noreferrer nofollow" target="_blank">“解码LP”（ID:LPdaily1945）</a>，作者：杨文静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2848774057265797</id>
            <title>算力促进线上市场稳健发展</title>
            <link>https://www.36kr.com/p/2848774057265797</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2848774057265797</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 03:01:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 算力, 数字经济, 线上市场, 数据存储技术
<br>
<br>
总结: 在数字经济时代，算力作为数据存储技术和网络通信技术的重要组成部分，已成为数字世界的关键动能，促进线上市场的形成和壮大，对资源配置、定价和支付等方面发挥着重要作用。然而，算力应用中仍存在技术瓶颈、高成本和二次训练难度等问题，需要进一步加强算力基础设施建设，以推动线上市场的发展。 </div>
                        <hr>
                    
                    <blockquote><p>算力已成为数字世界的关键动能，带动线上经济活动持续释放发展活力。基于此，应更加重视算力布局，把算力建设作为经济增长尤其是线上市场繁荣发展的政策着力点。</p></blockquote><p>在数字经济时代，算力是新质生产力，是各国科技竞争的焦点。算力作为数据存储技术的“存力”和基于网络通信技术的“运力”，是信息产业的重要组成部分。同时，算力也是一种基于计算的服务能力，借助线上市场的渗透力，像水和电一样不断走进千家万户、服务千行百业。据有关测算，算力指数平均每提高一个点，数字经济和GDP将分别增长3.6‰和1.7‰。</p><h2><strong>算力助力线上市场形成和壮大</strong></h2><p>当前，各行各业的数字化转型促使经济活动不断从线下转到线上，线上市场对资源配置的能力随之提高。一方面，数字经济发展形成了与传统市场内容相似但独树一帜的电商市场；另一方面，数字平台孕育形成了搜索、即时通信、网游、数据交易等新兴市场。随着数字经济逐渐从消费端向产业端延伸、从低端重复体力劳动向知识密集和人类情感领域拓展，线上市场将在生产、消费、交易、流通等市场体系全部环节的资源配置过程中发挥更大作用。与此同时，线上市场的金融活动也越来越广泛和复杂，对数据处理速度和效率提出了更高的要求。</p><p>线上市场运行以算力为前提。以往，线下传统市场是由一个个细分市场汇聚而成，通过各细分市场的供求匹配和价格机制形成局部均衡，进而在产业链和供应链上下游以及不同行业间传导互动，最终形成统一大市场的一般均衡。这其中主要依靠市场自发秩序的力量，也隐藏着千千万万的商户、企业和消费者对自身决策的计算和考量。而线上市场既保留了这种市场力量，又相对更加依赖平台对不同市场主体的统一协调性。在一定程度上，算法替代生产函数来配置资源，向用户定向推送产品、向供应商提供采购信息、向生产商反馈个性化需求。算法是平台设定的运行规则，而算法的实际执行需要以算力为基础。在日常生活中，物流体系的优化配置（如配送路线设计）、线上线下市场主体的互动（如外卖）等都离不开算力的精准计算和预测。毫无疑问，线上市场对资源配置的大范围协调，依赖超强的算力，是一般的口算、珠算、心算和计算器所不能胜任的，需要借助现代数字技术和基础设施。</p><p>特别是线上市场定价和支付需要依托算力。一方面，算力可以促进线上市场的价格发现。算力使企业更好地匹配市场供求，并藉此动态调整自身价格，从而推动企业价格、细分市场价格、一般均衡价格的形成，减少局部市场的价格失灵和整体市场的震荡；另一方面，线上支付需要算力来协调定价、实施优惠政策、合理分配收益。线上市场设置了明确的定价规则，交易双方大都无需讨价还价，而是在算力服务下实现一键报价。平台对网约车、货运卡车、劳务派遣、外卖等设置了参考价或指导价，还有的平台设置了价格保护、全网最低价等规则，对商户的实际定价产生重要作用，很少有商户可以大幅偏离平台制定的相关价格。在这个过程中，平台不是超越市场的计划者，而是通过历史数据模拟市场得出的趋近于一般市场均衡的价格。可以设想，如果没有超强的算力，平台很难对品类繁多的产品和多样化的商户进行价格和金融支付方面的合理引导。</p><p>算力还可以释放潜在消费，培育和做大二手车、闲置交易等“柠檬市场”。像电力一样，算力的使用也有波峰和波谷。在特定时点，人们可能需要线上市场配置大量资源，这在一定程度上促进了平台企业对算力技术及相关设施的投入；而对波峰时期算力的投资，会释放我国的潜在消费，形成消费和投资相互促进的良性循环。一个常见的例子就是，“双十一”的兴起与云计算的迅猛发展相得益彰。这种消费潜力的释放，还体现在直播带货等新业态领域。尤其值得关注的是，根据传统经济理论，二手车、闲置交易等“柠檬市场”存在信息不对称、道德风险、逆向选择等问题，导致市场难以有效发展。但线上市场依靠算力可以轻松获取产品质量信息和消费者评价信息，并形成合理的估价、认证和奖惩规则，促使市场健康有序发展。</p><p>面向未来，线上市场的拓展主要是新技术在新场景中的不断落地，这需要算力持续发力。随着通用人工智能的发展应用，智能算力的应用越来越广泛，其不仅能够提供海量数据的处理能力，还能支撑高性能智能计算，形成更高能级、更高质量的新质生产力。从具体技术和应用场景来看，数字人民币、智能合约、区块链、网联汽车等对算力要求很高，也将进一步提高线上市场资源配置效率。</p><h2><strong>算力应用存在的问题</strong></h2><p>小到手机、个人电脑，大到服务器、超级计算机，算力无处不在，给人们带来的便利也如影随形。但在线上市场中，算力的作用仍存在一定的局限与不足。</p><p>第一，技术瓶颈与算力产业链短板。如果说，算力是线上市场运行的前提，那么，高算力芯片则是算力的发动机。但与国外相比，高端芯片特别是适用于大语言模型（LLM）训练的人工智能芯片仍存在短板。我国推进国产化人工智能芯片自主可控势在必行，亟待突破算力瓶颈和解决“卡脖子”技术。</p><p>第二，算力成本较高。与水电走进千家万户不同，算力需要大量的沉没成本投资，中小企业很难承受。而且，ChatGPT（美国人工智能研究公司OpenAI旗下对话大模型产品）等新技术的运行成本也相当惊人，即便是大企业也不易承担。因此，新技术的落地应用亟待解决算力成本问题，只有使用更高性价比的算力平台，才能为普通个人用户和企业用户提供更轻量型的模型。</p><p>第三，二次训练与垂直细分市场中算力纵深推进难度大。算力可能会推动线上市场构建一个新的技术生态，但目前人工智能、机器学习等技术模型所学习的还是互联网上公开的知识，还不能解决具体行业、企业一些个性化的问题，所以需要企业在相关的纵深行业、垂直细分行业进行二次训练。例如，针对某个行业中的企业单独形成一些垂直化的解决方案，利用智能技术进行专业私有化知识的迭代，使它具备解决实际问题的能力。可以预见，随着人工智能进入巨量参数的大模型时代，算力需求的日益增长使得AI芯片和服务器市场迎来了巨大机遇，AI在教育、自动驾驶、端侧设备等垂直领域的落地和应用将是2024年的主线。这就需要大量优秀的公司加大算力投资，加强算力技术研发，提高算力能力，并推出一些更贴近客户需求和痛点的解决方案的产品，提高算力的市场普及率。</p><h2><strong>进一步依靠算力促进线上市场发展的建议</strong></h2><p>算力已成为数字世界的关键动能，带动线上经济活动持续释放发展活力。基于此，应更加重视算力布局，把算力建设作为经济增长尤其是线上市场繁荣发展的政策着力点。</p><p>第一，完善算力基础设施，增加有效供给。有人把数据比作信息时代的“石油”，把算力比作最重要的“基础设施”，足以说明算力的重要性。要加强制度改革，放宽相关产业的基建准入和行业准入。基础设施共建共享、网间互联互通和公平接入、业务许可准入、服务质量规范、公平竞争秩序维护等是数据基础设施规制的主要内容。如同在工业经济时代重视人均用电量一样，要把人均算力作为数字经济时代衡量各地区产业综合竞争力的重要指标。更多在落后地区布局算力基础设施，并对落后地区的企业使用算力进行财政补贴。</p><p>第二，提升算力产业链，攻克技术短板。围绕计算、网络、存储等关键环节，引导算力产业链上下游企业融通发展，促进智慧计算等前沿技术落地，以高算力赋能我国人工智能突破发展。培育一批算力服务商，开发和推广算力产品和服务，为中小企业积极使用算力搭建起一个完善的生态伙伴体系。通过提高研发投入和财政补贴，加大科技创新和人才培育力度，深化校企协同合作，加强算力网络关键技术研发。</p><p>第三，加强对新技术的数据共享、投喂和训练，针对性引导线上细分市场资源配置。一方面，建立数据治理架构，完善数据共享协调机制，推进数据有序共享，降低半结构化和非结构化数据，消除不同类型的数据壁垒，加强数据间的关联互通。另一方面，针对不同应用场景对文本生成技术的不同要求，如金融领域需要生成专业化和技术性的文本，而文学作品则更侧重于生成富有情感和创意的文本，针对性优化相关技术和政策细节。此外，还需推动数据训练基地、国家区块链枢纽节点等重大项目落地，特别是加强高质量中文数据在人工智能技术投喂和训练中的应用。</p><p>第四，统筹发展、公平与安全，增强社会效益。今后，云计算、量子计算、边缘计算等先进算力技术将持续提高资源配置效率，促进经济发展。积极考量算力的社会公平性，逐步推动算力成为与水电一样，可“一点接入、即取即用”的社会级服务，并对算力使用后出现的劳动者权益保障、消费者保护、科技产品向善等作出细化规定。出台算力数据开放共享以及跨境数据流通等法律法规，提升算力使用过程的风险治理水平，有效规避数据安全风险。</p><p>（作者系中国社会科学院财经战略研究院副研究员）</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/bIe9oPeCIXjUjrMGlPOGiA" rel="noopener noreferrer nofollow" target="_blank">“经济观察报”（ID:eeo-com-cn）</a>，作者：刘诚，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>