<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2520566706823049</id>
            <title>大模型幻觉问题再成焦点，LeCun 为 Galactica 喊冤</title>
            <link>https://www.36kr.com/p/2520566706823049</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520566706823049</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 08:08:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 幻觉问题, Vectara, AI 平台, LLM
<br>
<br>
总结: 近日，AI 平台 Vectara 通过自建幻觉评估模型计算了市面上大多数公共 LLM 的幻觉频率，并发布了排行榜。然而，该评估只考虑了摘要与原文的一致性，而没有评估摘要本身的质量。此外，评估方法也存在一些问题，可能会惩罚总结得更好的模型。这一研究引起了专家的关注和讨论。同时，文章还提到了一年前 Meta 发布的 Galactica 模型因幻觉问题被网友喷到下线的故事。 </div>
                        <hr>
                    
                    <p>众所周知，幻觉问题一直是困扰大模型的一大难题。近日，一个名为 Vectara 的 AI 平台通过自建幻觉评估模型（该模型已在Hugging Face上开源供商业使用），计算得出了目前市面上大多数公共 LLM 的幻觉频率，并以排行榜的形式在 X 上发布了截止 11 月 1 日的测试结果。</p><p>从榜单上可以看到，GPT-4 的准确率为 97.0%，幻觉率为 3.0%，而 Google Palm 的两款 LLM 表现垫底，其中 Palm Chat 的准确率为 72.8%，幻觉率甚至高达 27.2%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fb6d12da0f3f4f71970a8d3f4d1328d4@5764927_oswg1176840oswg686oswg428_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>榜单一经发出，大批网友纷纷转发，但也有专家指出了该排行榜中所含的问题以及我们应该关注到的细节。</p><p>英伟达高级 AI 科学家Jim Fan 指出，这项研究只评估了摘要与原文的“事实一致性”，而没有评估摘要本身的质量。通过简单的复制，摘要总能达到 100%的事实一致性，可以做到完全不存在幻觉。此外，该评估依赖于使用另一个“judge LLM”来决定幻觉是否发生，但几乎没有详细说明该如何进行提示以及如何真正捕捉谬误。Jim Fan 举例道，“假设模型注入了一些无关但真实的事实。比如文章只提到 ‘巴黎’，但模型却返回‘巴黎，法国的首都’。这算不算幻觉？”</p><p>Jim Fan 表示，事实上，这项研究甚至可能会惩罚那些总结得更好的模型，因为它们往往会进行更多的转述和提炼。此外，他也呼吁道，在下结论之前，还是务必阅读评估协议。这一点对于 LLM 任务和其他任何 ML 系统都普遍适用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ea8faef5b1c1451995c40760c3a41e40@5764927_oswg1632879oswg687oswg593_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Jim Fan 的观点得到了很多大佬的支持，而 Meta 首席人工智能科学家 Yann Lecun 也是转发了本条推特。</p><p>或许是这个排行榜大火，Meta 一年前发布的但只存活了三天的 LLM——Galatica 的共创者 Ross Taylor 今日也是打破沉默，转发了 VentureBeat 关于 Galatica 因幻觉问题被网友喷到下线的故事原委。而 Yann LeCun 也是感慨道：“你知道‘早发布，勤发布’这句开源圈的老话吗？说到人工智能，还应加上‘是的，但要准备好忽略 Twitter 上暴民们荒谬的末日预言’。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_67dc8bf890844c73be654185949844cc@5764927_oswg1035380oswg687oswg376_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>Galactica 的故事</h2><p>那么，一年前 Meta 的 Galactica 究竟发生了什么？</p><p>一年前，也就是 OpenAI 发布 ChatGPT 的两周前，Meta 发布了一个名为 Galactica 的研究演示。作为一款开源的“科学大语言模型”，Galactica 是在包括 4800 万篇科学论文在内的数据基础上训练出来的，Meta 称 Galactica 能够“总结学术文献、解决数学问题、生成维基文章、编写科学代码、注释分子和蛋白质等”。</p><p>然而，Galactica 只公开存活了三天。2022 年 11 月 17 日，Meta 因“幻觉”这个当时还未成为主流的词被网友喷到撤下了演示版。许多人对 Galactica 有时非常不科学的输出感到震惊。是的，和其他 LLM 一样，Galactica 会输出一些听起来有理但实际上是错误的信息。</p><p>当时，Meta 首席科学家 Yann LeCun 为该模型进行了辩护，并发布了一系列推文，但一切无济于事。Galactica 没有成为生成式人工智能时代改变游戏规则的模型。</p><p>两周后，ChatGPT 正式发布。尽管 ChatGPT 同样存在幻觉问题，但这并没有减缓 ChatGPT 成为 LLM 之星的步伐。在短短两个月内，ChatGPT 的月用户数量就达到了 1 亿，而现在每周的用户数量已经达到 1 亿。</p><p>Ross Taylor 表示，Galactica 是当时其领域中一个很好的模型；在计算量分别减少 10 倍和 2 倍的情况下，它的性能超过 PaLM 和 Chinchilla。此外，整个研究团队也只有 8 个人，比当时其他 LLM 团队少了一个数量级。</p><p>然而，由于工作量巨大，团队在没有检查的情况下就发布了 Galactica 基础模型的演示。Ross Taylor 表示，发布演示的考虑因素之一是，其团队希望了解人们用于 LLM 的科学查询的分布情况（这对指令调整和 RLHF 非常有用）。然而网友们却在领域之外进行了查询，从而招致了大范围的谩骂，团队也失去了态势感知能力。据 Taylor 自己讲述，该团队也曾假设分享基础模型的所有缺陷，并在演示版上加上四个关于幻觉的免责声明，但并没有起作用。</p><p>Taylor 称，另一个失误是团队把愿景什么的都写在网站上，导致人们误把网站当成了“产品”。而事实上，该团队并没有将其视为产品！只是一个基本模型演示。</p><p>Ross Taylor 对 Galactica 的遭遇感到痛心，但他并没有后悔。Taylor 表示，“与其后悔，不如有所作为。”幸运的是，Galactica 的大部分工作和研究都促成了 LLaMA 系列的发布。</p><p>Meta 人工智能研究副总裁 Joelle Pineau 在接受 VentureBeat 采访时解释说：Meta“很可能错误地估计了”人们对 Galactica 的期望，但“我们已经将从中吸取的教训融入到下一代模型中”。</p><p>2023 年 2 月，Meta 发布了 Llama 模型在人工智能研究领域掀起了一场风暴，随后在 7 月，Meta 推出了商用的 Llama 2，8 月又推出了 Code Llama。随着 Llama 成为首个主要的免费”开源“LLM，开源人工智能开始崭露头角，并引发了一场热火朝天的讨论。</p><h2>错误地谩骂可能适得其反</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6b379faf2c4f45189caee7db969c6c00@5764927_oswg1098701oswg687oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Galactica 死于非命，正如 Lecun 所讲，“它是被一群贪婪的推特暴徒谋杀的。暴徒们声称，我们现在所说的 LLM 幻觉将摧毁科学出版系统。结果，一个对科学家非常有用的工具被摧毁了。”</p><p>是啊，在如今大火的 AI 圈子里，独立思考显得尤为重要。“打着人工智能伦理的幌子，错误地谩骂可能会适得其反。”</p><h3>参考资料</h3><p>https://venturebeat.com/ai/what-meta-learned-from-galactica-the-doomed-model-launched-two-weeks-before-chatgpt/</p><p>https://github.com/vectara/hallucination-leaderboard</p><p>https://twitter.com/rosstaylor90/status/1724547381092573352</p><p>https://twitter.com/DrJimFan/status/1724464105371939301</p><p class="editor-note">本文来自微信公众号“AIGC新智界”（ID:AIGCxinzhijie），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520471866713861</id>
            <title>当数据成为「生产资料」，三篇论文总结如何用水印技术保护AI训练数据版权</title>
            <link>https://www.36kr.com/p/2520471866713861</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520471866713861</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:56:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 训练数据, 水印, 所有权验证, 后门攻击
<br>
<br>
总结: 本文讨论了在AI训练数据中添加水印的方法及应用场景。通过在数据集中嵌入数字水印，可以保护数据集免遭未经授权使用。其中，一种方法是通过后门攻击进行数据集水印，防御方通过假设检验检查可疑模型是否包含特定的隐藏后门，从而进行数据集验证。这种技术可以应用于保护AI训练数据集的所有权，并防止未经授权的使用和侵犯版权。 </div>
                        <hr>
                    
                    <h2>1、引言 -- 为什么要在 AI 训练数据中添加水印？</h2><p>深度神经网络（DNN）以其高效率和高效益被广泛应用于许多关键任务应用和设备中。高质量的已发布（如开源或商业）数据集是 DNNs 技术发展的关键因素之一。研究人员和开发人员利用这些数据集验证其模型的有效性，进而加快 DNN 的开发。这些已发布数据集非常有价值，但收集数据的过程通常耗时且非常昂贵。在这样的应用背景下，在 AI 训练数据中添加水印，对于保护数据集免遭未经授权的使用以及保护数据创作者的版权具有重大的意义，值得深入研究和探讨。</p><p>目前，已有的一些数据保护技术，例如加密、数字水印、差分保护等，主要目的是防止未经授权的用户使用受保护的数据。然而，这些方法并不适合保护 DNN 训练所依赖的公开发布的数据集。具体来说，加密和差分保护处理会影响受保护数据集的正常功能，而数字水印技术在这种场景下的作用很小，因为未经授权的用户只会发布他们训练好的模型，而不会公开他们的训练样本。</p><p>如何保护公开发布的数据集仍是一个重要的未决问题。这个问题具有挑战性，因为攻击方是可以访问被攻击的数据集的。数据集的安全性是 AI 在推广应用过程中必须面对的一个关键问题，因此，吸引了产业界的广泛关注。Digimarc 公司最近推出了一项名为 Digimarc Validate 的新服务（https://www.digimarc.com/），旨在帮助保护数字内容的版权。这一服务允许版权所有者在其作品中嵌入数字水印，从而有助于防止 AI 模型在训练过程中针对训练数据出现侵犯版权的问题。</p><p>与此同时，学术界也非常重视水印技术在 AI 数据中的应用。我们在这篇文章中分析了几篇近期发布的论文，重点讨论了在 AI 训练数据集中添加水印的技术。</p><p>前两篇文章是来自清华大学深圳研究院的同一个研究团队，聚焦于 “通过在数据集中嵌入数字水印来保护数据集免遭未经授权使用的方法”。其中，第一篇文章针对 poison-only 后门攻击，将保护 AI 训练数据集的问题表述为所有权验证。在这一问题中，一般包含两个参与方：防御方和攻击方，一般来说，防御方会发布自己的数据集，并希望保护其版权；而攻击方的目标则是 "窃取" 已发布的数据集，用于未经防御方许可训练其商业模型。在后门攻击中，攻击方会在训练过程中将隐藏的后门植入被攻击的模型中。被攻击的模型在良性样本上表现正常，而一旦出现攻击方指定的触发器，就会不断输出目标标签。根据攻击方的能力，现有的后门攻击大致可分为三大类，包括 poison-only 攻击、训练控制攻击和模型修改攻击。具体来说，poison-only 攻击需要改变训练数据集，而训练控制攻击还需要修改其他训练组件（如训练损失），模型修改攻击则是通过直接修改模型参数或结构来进行的。</p><p>第一篇文章具体聚焦在 poison-only 后门攻击，防御方尝试去识别和验证一个可疑模型是否是在（受保护的）被攻击的数据集上训练出来的：首先，防御方利用 poison-only 后门攻击进行数据集水印；然后，防御方进行数据集验证，通过假设检验检查可疑模型是否包含特定的隐藏后门。</p><p>第二篇文章在第一篇工作的基础上，进一步改进所有权验证的方法，研究了如何设计无目标后门水印（untargeted backdoor watermark，UBW），以及如何利用它进行无害、隐蔽的数据集所有权验证。给定一个可疑模型，防御方验证该模型是否在（受保护的）数据集上训练过。与第一篇文章的工作相同，假设数据集防御方只能通过查询可疑模型来获取输入样本的预测概率向量，而对训练过程和模型参数一无所知。研究团队表示，这两篇文章中提到的相关技术可以应用于许多不同类型的机器学习问题，不过在文章中探讨的重点是分类模型，特别是图像分类模型。</p><p>与上面所有权验证的方法不同，第三篇文章提出了一种基于后门的水印方法。通过在数据集中插入少量水印样本，可以让 DNN 模型隐式地学到一个由防御方设置的 secret function，这个 secret function 可以作为水印，用来追踪非法使用数据集的第三方模型。本文引入了一种清洁标签后门水印框架，利用不可感知的扰动来替换错误标签样本，从而实现水印样本与原始标签保持一致，很难被检测到。</p><h2>2、在 AI 训练数据中添加水印的方法及应用场景</h2><p><strong>2.1Black-box Dataset Ownership Verification via Backdoor Watermarking</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_95c0db6f9a364d5d987ee3345e730ca3@000000_oswg89225oswg1080oswg248_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">https://arxiv.org/pdf/2209.06015.pdf</p><p>本文将保护 AI 训练数据集的问题表述为所有权验证问题，即防御方识别一个可疑模型是否是在（受保护的）被攻击的数据集上训练出来的。特别是，作者考虑了黑盒环境，与白盒环境相比黑盒环境更加困难，因为防御方只能获得模型预测，而不知道其训练细节和模型参数。这种设置更加实用，即使防御方只能访问模型 API，也能执行所有权验证。作者提出了一种称为通过后门水印进行数据集验证（dubbed dataset verification via backdoor watermarking，DVBW）的方法。DVBW 包括两个主要步骤：数据集水印和数据集验证。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_392994627b4b4416951828f0f3111365@000000_oswg218893oswg1080oswg392_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 1. DVBW 主要流程。第一步，防御方利用基于数据污染的后门攻击进行数据集水印。第二步，防御方通过假设检验检查可疑模型是否包含特定的隐藏后门，从而进行数据集验证。本文考虑了两种具有代表性的黑盒场景，防御方可以分别获得预测概率和仅有预测标签</p><p>具体来说，作者在数据集水印中采用了基于数据污染的后门攻击（poison-only backdoor attacks），其想法是：只需修改数据，就能在被污染的数据样本上安排学习特殊行为（比如，把 “猫” 识别成 “狗”），同时在良性样本上保持较高的预测准确度。在数据集验证方面，防御方可以通过检查特定后门的存在来验证可疑模型是否是在加了水印的被攻击的数据集上训练出来的。</p><p>2.1.1 DNN 流程</p><p>深度神经网络（DNN）已在广泛的应用中显示出其有效性。目前有许多不同类型的 DNN，如卷积神经网络、图神经网络，它们是针对不同任务和目的而设计的。目前，DNNs 的学习是数据驱动的，尤其是在有监督的情况下。具体来说，令 D 表示（标记的）训练集，其中 X 和 Y 分别表示输入和输出空间。一般来说，DNN 基于如下优化学习一个映射函数（参数 θ）f_θ : X → Y：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d124e6b266e4494b874b694904e476a8@000000_oswg14840oswg455oswg122_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>训练完成后，就可以通过 f _θ(x) 预测 "未见" 样本 x 的标签。</p><p>2.1.2 后门攻击流程</p><p>数据污染的后门攻击首先会生成污染数据集 D_p，在此基础上训练给定模型。具体来说，令 y_t 表示目标标签，D_b 表示良性训练集，其中 X 和 Y 分别表示输入和输出空间。后门攻击方首先根据攻击方指定的数据污染生成器 G 和目标标签 y_t，选择 D_b 的子集（即 D_s）生成其修改版本 D_m。换句话说，D_s ⊂ D_b，D_m ={(x', y_t)|x' = G (x),(x, y) ∈ D_s}。污染数据集 D_p 是 D_m 与剩余良性样本的组合，即 D_p = D_m ∪(D_b\D_s)。特别的，定义 γ 为污染率指标：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_832871f4bd954de58327ebefc3e11e38@000000_oswg5615oswg181oswg70_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>生成污染数据集生成后，将其用于训练被攻击的模型。这一过程与标准训练过程几乎相同，只是训练数据集不同。隐藏的后门将在训练过程中创建，即对于有后门的模型 f_b，f_b (G (x))=yt,∀x∈X。特别是，f_b 在预测良性样本时将保持较高的准确率。</p><p>本文重点讨论<strong>分类任务</strong>的数据集保护问题。该问题涉及攻击方和防御方。一般来说，防御方会发布自己的数据集，并希望保护其版权；而攻击方的目标则是在未经防御方许可的情况下 "窃取" 已发布的数据集，用于训练自己的模型。具体来说，令 Dˆ 表示包含 K 个不同类别的受保护数据集，S 表示可疑模型，将数据集保护表述为一个验证问题，即防御方打算在黑盒设置下识别 S 是否在 Dˆ 上训练过。防御方只能查询模型，而对模型的参数、模型结构和训练细节一无所知。这对防御方来说是最难的设置，因为他们的能力非常有限。不过，这也使得本文提出的方法最具普及性，也就是说，即使防御方只能查询可疑第三方模型的应用程序接口，他们仍然可以保护数据集。</p><p>作者特别考虑了两种有代表性的验证场景，包括概率可用验证和仅标签验证。在第一种情况下，防御方可以获得输入样本的预测概率向量，而在第二种情况下，他们只能获得预测标签。后一种情况更具挑战性，因为防御方从模型预测中获得的信息更少。</p><p>2.1.3 数据集水印</p><p>由于防御方只能修改公开发布的数据集和查询可疑模型，因此唯一的办法就是在良性数据集上加水印，使在良性数据集上训练的模型具有防御方指定的独特预测行为。防御方可以验证可疑模型是否具有预定义行为，以确认其是否在受保护数据集上经过训练。一般来说，设计的数据集水印需要满足以下三个主要特性：</p><p>令 f 和 fˆ 分别表示在良性数据集 D 及其水印版本 Dˆ 上训练的模型</p><ul><li>ζ-Harmlessness：水印不应损害数据集的功能，即 BA (f)-BA (fˆ) &lt; ζ，其中 BA 表示良性准确度；</li><li>η-distinctiveness：所有在带水印数据集 Dˆ 上训练的模型都应在带水印数据上具有某些独特的预测行为（与在其良性版本上训练的模型相比）；</li><li>Stealthiness：数据集水印不应引起攻击方的注意。例如，对数据集用户来说，水印率应该很小，水印数据应该很自然。</li></ul><p>2.1.4 数据集验证</p><p>给定一个可疑模型 S (·)，防御方可以通过检查特定后门的存在来验证该模型是否是在其发布的数据集上训练出来的。具体来说，假设 x' 表示污染数据样本，y_t 表示目标标签，防御方只需根据 S (x') 的结果就能检验出可疑模型。如果 S (x') = y_t，可疑模型将被视为在被攻击的数据集上训练出来的。然而，它可能会受到选择 x' 的随机性的影响。本文设计了一种以假设检验为导向的方法来提高验证可信度。作者考虑了两种具有代表性的黑盒场景，包括概率可用验证和仅标签验证。本文根据它们的特点设计了不同的验证方法，具体如下：</p><p>1) 概率可用验证：在这种情况下，防御方可以获得输入样本的预测概率向量。要检查是否存在隐藏的后门，防御方只需验证目标类水印样本的后验概率是否显著高于良性测试样本的后验概率。在实际操作中，我们随机抽取 m 个不同的带有非目标标签的良性样本，进行（单尾）Parwise T-test，并计算其 p 值。如果 p 值小于显著性水平 α，则拒绝零假设 H_0。此外，还计算置信度得分 ∆P = P_w -P_b 来表示验证置信度。∆P 越大，验证的可信度越高。算法 1 给出了主要验证过程。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2c74148584074190bee8d2176b82285a@000000_oswg213832oswg1006oswg611_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2) 仅标签验证：在这种情况下，防御方只能获得预测标签。因此，识别隐藏后门的唯一方法就是检查水印样本（其 ground-truth 标签不是目标标签）的预测标签是否是目标标签。在实际操作中，随机抽取 m 个不同的无目标标签良性样本进行 Wilcoxon 检验，并计算其 p 值。如果 p 值小于显著性水平 α，则拒绝零假设 H'。算法 2 给出主要的验证过程。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f3a6c4e0b74e4d1fb5e22cd1c5518213@000000_oswg175126oswg1001oswg504_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>特别是，由于 Wilcoxon-test 的机制，作者建议用户在仅标签设置下将 y_t 设为 接近 K/2 的数据。如果 y_t 太小或太大，当水印成功率不够高时， DVBW 可能检测不到数据集的窃取。</p><p>2.1.5实验分析</p><p><strong>数据集水印的度量标准。</strong>作者采用良性准确率（benign accuracy，BA）和水印成功率（watermark success rate，WSR）来验证数据集水印的有效性。具体来说，良性准确率是指模型在良性测试集上的准确率，而水印成功率是指模型在水印测试集上的准确率。BA 和 WSR 越高，说明方法越好。</p><p><strong>数据集验证指标。</strong>采用 ΔP（∈[-1，1]）和 p（∈[0，1]）来验证概率可用数据集验证的有效性和仅标签数据集验证的 p 值。具体来说，作者在三种情况下评估了方法，包括（1）独立触发（Independent Trigger）（2）独立模型（Independent Model）（3）偷窃（Steal）。</p><p>在第一种情况下，作者使用与训练过程中使用的触发器不同的触发器验证水印可疑模型；在第二种情况下，作者使用触发器模式检查良性可疑模型；在最后一种情况下，使用水印可疑模型训练过程中采用的触发器。在前两种情况下，模型不视为在受保护数据集上训练过，因此 ∆P 越小，p 越大，验证效果越好。在最后一种情况下，可疑模型是在受保护数据集上训练的，因此 ∆P 越大，p 越小，验证方法越好。</p><blockquote><p>作者在图像识别、NLP、Graph Recognition 等任务上进行了实验，同时也做了 Ablation Study。我们在这片文章中重点介绍一下图像识别任务中的情况。感兴趣的读者可以阅读原文。</p></blockquote><p>作者在 CIFAR-10 和（ImageNet 数据集的一个子集）ImageNet 数据集上使用 VGG-19（带批量归一化）和 ResNet-18 进行了实验。具体来说，从原始 ImageNet 数据集中随机选择了一个包含 200 个类别（每个类别 500 张图像）的子集进行训练，并选择了 10,000 张图像进行测试（每个类别 50 张图像），以简化测试。</p><p><strong>数据集水印设置。</strong>采用 BadNets 和混合攻击（称为 "Blended"），数据污染率 γ = 0.1。它们分别代表了可见型和不可见型数据污染后门攻击。目标标签 y_t 设置为类别数 K 的一半（即 CIFAR-10 为 "5"，ImageNet 为 "100"）。在混合攻击中，透明度设置为 α∈ {0, 0.2}^(C×W×H) 。生成的数据污染样本示例如图 2 所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_35525b3e41ed4abdba2588028f620d1f@000000_oswg234934oswg1080oswg270_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 2. BadNets 和混合攻击在 CIFAR-10 和 ImageNet 数据集上生成的良性图像和水印图像示例。红框中标出了触发区域</p><p>随机选择 m =100 个不同的良性测试样本进行假设检验。对于概率可用性验证，将确定性相关超参数 τ 设为 0.2。具体来说，仅从 ImageNet 的前 10 个类别中选择样本，仅从 CIFAR-10 的前两个类别中选择样本进行仅标签验证。这一策略是为了在类别数量相对较多时，减少随机选择的副作用。如表 I 所示，本文的水印方法是无害的。与使用良性数据集进行训练相比，数据集水印在所有情况下只降低了小于 2% 的良性准确率（大部分情况下小于 1%）。换句话说，它不会妨碍数据集的正常使用。此外，低数据污染率带来的微小性能下降也确保了水印的隐蔽性。此外，它还能成功嵌入隐藏的后门。例如，在 CIFAR-10 数据集上，所有情况下的水印成功率都大于 94%（大部分大于 99%）。这些结果验证了本文数据集水印技术的有效性。特别是，如表 2、表 3 所示，本文的数据集验证也很有效。在概率可用的情况下，本文方法能以较高的置信度（∆P≥ 0 和 p ≤0.01）准确识别数据集窃取，在不存在窃取的情况下（∆P 接近 0 和 p ≥0.05）不会出现误判。即使在验证难度较高的仅标签场景中，本文方法仍能在所有情况下准确识别数据集窃取（∆P ≥0 和 p &lt; 0.05），并且在存在窃取时不会误判。但是，作者承认，本文方法在仅标签的情况下效果较差。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c36d280bf96c44eabde0ced2c864fbf3@000000_oswg121761oswg1080oswg191_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 1. CIFAR-10 和 ImageNet 上数据集水印的良性准确率（%）和水印成功率（%）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8cc9b78a677248e1a765b55f7b692936@000000_oswg162245oswg1080oswg345_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 2. 在 CIFAR-10 和 ImageNet 上验证概率可用数据集的有效性（ΔP 和 p 值）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2c0cb70b0e0b4ab3a7ab606840a32eff@000000_oswg110027oswg1080oswg272_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 3. 在 CIFAR-10 和 ImageNet 上进行仅标签数据集验证的有效性（p 值）</p><p><strong>2.2Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e1b452350d004ae2b1755129605b7e0f@000000_oswg139361oswg1045oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">https://proceedings.neurips.cc/paper_files/paper/2022/file/55bfedfd31489e5ae83c9ce8eec7b0e1-Paper-Conference.pdf</p><p>本文是上一篇文章研究小组的另外一项研究成果。在本文中，作者重新讨论了数据集所有权验证问题。作者提出，由于现有后门水印的针对性方式，BEDW（上文所提出的 DVBW，本文中标记为 BEDW） 为在受保护数据集上训练的 DNN 带来了新的威胁性安全风险。具体来说，攻击方（即，使用了受保护数据进行训练但是不想被发现的一方）可以利用嵌入的隐藏后门，对模型预测进行恶意的确定性操纵。</p><p>如图 3 所示。基于这一思考，作者在本文中探讨了如何设计<strong>无目标后门水印</strong>（untargeted backdoor watermark，UBW），以及如何利用它进行无害、隐蔽的数据集所有权验证。具体来说，作者首先介绍了两种离散度，包括样本平均离散度和类平均离散度，并证明了它们之间的相关性。在此基础上，作者提出了一种简单而有效的启发式方法，即的带有数据污染标签的启发式 UBW（ UBW-P）和带有清洁标签的 UBW（ UBW-C）。UBW-P 更有效，而 UBW-C 更隐蔽。最后，作者利用 pairwise T-test 设计了一个基于 UBW 的数据集所有权验证。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d8cba19b4acd4cc383332b1e828757a6@000000_oswg237633oswg1080oswg504_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 3. 不同类型后门水印的 DNN 推断过程</p><p>2.2.1UBW 介绍</p><p>本文重点研究了作为图像分类中的后门水印的数据污染后门攻击。具体来说，后门攻击者只能修改一些良性样本，而没有信息和能力修改其他训练组件（如训练损耗、训练时间表和模型结构）。生成的数据污染样本和其余未修改的良性样本将被释放给被攻击者，被攻击者将根据这些样本训练 DNN。特别要指出的是，作者只考虑单纯数据污染后门攻击，而不是其他类型的方法（如训练控制攻击或模型修改攻击），因为它们需要额外的对抗能力，因此不能用于保护已发布数据集。</p><p>令 D 表示良性训练集，其中 x_i 是图像，y_i 是其标签，K 是类别数。如何生成数据污染数据集 D_p 是单纯数据污染后门攻击的基石。作者表示据他们所知，几乎所有现有的后门攻击都是有针对性的（targeted），所有数据污染样本都有相同的目标标签。D_p 由两个互不相交的部分组成，包括 D 的一个选定子集（即 D_s）的修改版本和剩余的良性样本，其中 y_t 是攻击方指定的目标标签</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_874c142e5a2f46aeab690717de6c0eb9@000000_oswg33112oswg1080oswg67_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>γ 为数据污染率，G 为数据污染生成器。单纯数据污染后门攻击的主要特征就是 G。例如，trigger pattern 如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_17860a4742154858ada923340e05ac21@000000_oswg33559oswg1080oswg52_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>生成数据污染数据集 D_p 后，将其用于训练 DNN。因此，在推理过程中，被攻击的模型在预测良性样本时表现正常，而一旦出现数据污染图像，它的预测就会被恶意地不断改为目标标签。</p><p>UBW 有三大目标，包括：1）有效性；2）隐蔽性；3）离散度。具体来说，有效性要求带水印的 DNN 会误判数据污染图像；隐蔽性要求数据集用户无法识别水印；离散度则确保数据污染图像的预测具有可离散性。</p><p>2.2.2UBW-P</p><p>实现预测可离散的最直接策略就是将数据污染图像的预测作为统一的概率向量。具体来说，作者建议在制作数据污染数据集时随机 "洗牌（shuffle）" 数据污染训练样本的标签。本文将这种攻击称为带有数据污染标签的无目标后门水印（UBW-P）。</p><p>UBW-P 首先从良性数据集 D 中随机选择一个子集 D_s 来制作其修改版本 D_m。然后，释放与剩余良性样本 D\D_s 相关的修改后子集 D_m ，通过以下方式训练模型 f (・; w)：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_0d1c147ffc0c4195b45e354ac81de5a9@000000_oswg30014oswg907oswg157_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在推理过程中，对于任何测试样本，攻击方都可以根据生成器 G 激活被攻击 DNN 中包含的隐藏后门，生成数据污染图像 G (xˆ)。</p><p>2.2.3UBW-C</p><p>由于 UBW-P 仍带有数据污染标签，因此即使数据污染率很小，也不够隐蔽。数据集用户在捕捉到数据污染样本时，可能会通过检查图像与标签的关系来识别水印。接下来，作者讨论如何在 bi-level 优化的基础上设计带有清洁标签的无目标后门水印 (UBW-C)。要将 UBW-C 表述为 bi-level 优化，我们需要优化预测的可离散度。然而，它是不可分的，因此无法直接优化。在本文中，作者引入了两种可微分的 surrogate dispersibilities 来解决这一问题，具体如下：</p><p><strong>(样本平均离散度和类平均离散度）</strong>：令 D 表示数据集 ，DNN f (・)（在数据集 D 上）给出的预测的样本平均离散度定义为</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5864636c11f149c6bfd311097ec13edd@000000_oswg16823oswg581oswg173_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>类平均离散度定义为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7215860c1b874aa9b5d154fb33768f6a@000000_oswg47097oswg1080oswg148_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一般来说，样本平均离散度描述的是所有样本预测概率向量的平均离散度，而类平均离散度描述的是每个类别中样本平均预测结果的平均离散度。最大化它们对优化预测离散度 D_p 有类似的效果。</p><p>与 UBW-P 和现有的定向后门水印相比，UBW-C 的主要区别在于生成修改后的子集 D_m。具体来说，在 UBW-C 中，我们不修改所有数据污染样本的标签，即 D_m = {(x’, y)|x’ = G (x; θ),(x, y)∈ D_s}。在讨论 UBW-C 的技术细节之前，我们首先介绍必要的定理和分析。</p><p>Lemma 1. 类平均离散度总是大于或等于样本平均离散度，即 Ds ≤ Dc。当且仅当 f (x_i) =f (x_j) 时，相等关系成立。</p><p>Theorem 1. 假设 f (・;w) 表示参数为 w 的 DNN，G (・; θ) 表示参数为 θ 的数据污染图像生成器，D 是具有 K 个类别的给定数据集，我们有</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_123e91d94849428eb2d2900d12a3a6c2@000000_oswg74142oswg1080oswg88_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Theorem 1 意味着我们只需最大化 D_s 就能同时优化样本平均离散度 D_s 和类平均离散度 D_c。这促使我们在 UBW-C 中（通过优化生成器 G）生成修正子集 D_m 如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_79406ab6cfe3455893aa5b6e68376949@000000_oswg129251oswg1080oswg234_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一般来说，上述过程是一个标准的两级优化过程，通过交替优化下级子问题和上级子问题，可以有效解决该问题。特别是，优化是通过 mini-batch 的随机梯度下降（SGD）进行的，在这种情况下，估算类平均离散度是很困难的（尤其是在类别很多的情况下）。相比之下，即使是在一个小批次中，样本平均离散度 D_s 的估算仍然简单而准确。这也是 UBW-C 只使用样本平均离散度进行优化的另一个好处。</p><p>2.2.4通过 UBW 实现 harmless 数据集所有权验证</p><p>给定一个可疑模型，防御方打算验证该模型是否在（受保护）数据集上训练过。与之前的工作相同，作者假设数据集防御方只能通过查询可疑模型来获取输入样本的预测概率向量，而对训练过程和模型参数一无所知。由于防御方只能修改已发布的数据集并查询可疑模型，因此解决上述问题的唯一方法就是在（未受保护的）良性数据集上打上水印，使在其上建立的模型具有特定的独特预测行为。数据集所有者可以发布加了水印的数据集，而不是原始数据集，以保护版权。UBW 所标记的 DNN 在良性样本上表现正常，而在数据污染样本上则具有可离散的预测。因此，它可用于设计无害且隐蔽的数据集所有权验证。一般来说，如果给定一个可疑模型，防御方可以通过检查该模型是否包含特定的非目标后门来验证它是否是在受保护数据集上训练的。如果该模型包含后门，则被认为是在受保护数据集上训练的。为了验证这一点，作者设计了一种基于假设检验的方法，具体如下。</p><p><strong>命题 1.</strong>假设 f (x) 是可疑模型预测的 x 的后验概率。令 X 表示良性样本， X' 表示数据污染版本（即 X' =G (X)），P_b = f (X)_Y 和 P_p = f (X')_Y 分别表示 X 和 X' 在 ground-truth 标签 Y 上的预测概率。给定零假设 H_0 : Pb = Pp + τ(H_1 : Pb &gt; Pp + τ )（其中超参数 τ ∈ [0, 1]），当且仅当 H_0 被拒绝时，我们认为可疑模型在受保护数据集上得到了训练（具有 τ - 确定性）。</p><p>在实践中，我们随机抽取 m 个不同的良性样本进行成对 T 检验（pairwise T-test），并计算其 p 值。如果 p 值小于显著性水平 α，则拒绝零假设 H_0。作者强调，只选择可疑模型能正确分类的样本，以减少模型准确度的副作用。否则，由于 UBW 没有针对性，当出现数据集偷窃时，如果可疑模型的良性准确率相对较低，我们的验证可能会出现误判。此外，作者还计算了置信度分数 ΔP = P_b - P_p 来表示验证置信度。ΔP 越大，验证的可信度越高。</p><p>2.2.5实验分析</p><p>本文使用 ResNet-18 在两个经典基准数据集上进行了实验，包括 CIFAR-10 和 ResNet-18。具体来说，从原始 ImageNet 中随机选择了一个包含 50 个类别的子集，其中 25,000 幅图像用于训练（每类 500 幅图像），2,500 幅图像用于测试（每类 50 幅图像）。为简单起见，所有图像都按照 Tiny-ImageNet 中的设置调整为 3 x 64 x 64 大小。</p><p>作者将 UBW 与现有的单纯数据污染后门攻击进行了比较。具体来说，对于带有数据污染标签的攻击，作者采用 BadNets [1]、混合攻击（称为 "Blended"）[2] 和 WaNet [3] 作为基准方法。而对于清洁标签攻击，作者使用标签一致攻击 [4] 和 Sleeper Agent [5] 作为基准方法。此外，还引入在良性数据集上训练的模型（称为 "无攻击"）作为另一个参考基线。</p><p>作者将两个数据集上所有水印的数据污染率设置为 γ= 0.1。特别是，由于标签一致性攻击只能修改目标类别的样本，因此在 ImageNet 数据集上，数据污染率被设为最大值（即 0.02）。所有目标水印的目标标签 y_t 都设为 1。此外，作者在两个数据集上都采用了白色黑方块作为 BadNets、混合攻击、标签一致攻击和 UBW-P 的 trigger pattern。Sleeper Agent 和 UBW-C 采用的 trigger pattern 是针对特定样本的。将两个数据集上的 UBW-C 都设置为 λ = 2。样本如图 4 所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a68732ee55694b76a2a727cc25157da8@000000_oswg677365oswg1080oswg687_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 4. 不同后门水印涉及的样本示例。在 BadNets、blended 攻击、WaNet 和 UBW-P 中，数据污染样本的标签与 ground truth 不一致。在标签一致攻击、Sleeper Agent 和 UBW-C 中，数据污染样本的标签与 ground-truth 相同。特别是，标签一致攻击只能污染目标类别中的样本，而其他方法可以修改所有样本</p><p>实验使用良性准确率（BA）、攻击成功率（ASR）和平均预测离散度（D_p）来评估水印性能。作者特别引入了两种类型的 ASR，包括对所有测试样本的攻击成功率（ASR-A）和对正确分类的测试样本的攻击成功率（ASR-C）。一般来说，BA、ASR 和 D_p 越大，水印效果越好。如表 4、表 5 所示，在数据污染标签和清洁标签设置下， UBW 的性能与基线目标后门水印相当。特别是在清洁标签设置下，UBW-C 明显优于其他清洁标签水印。例如，与标签一致攻击和 SleeperAgent 相比，UBW 在 ImageNet 上的 ASR-C 提高率均超过 55%。这些结果验证了 UBW 可以在受攻击的 DNN 中植入独特的行为。尤其是在数据污染标签设置下，UBW 的平均预测离散度 D_p 明显更高。例如，在 CIFAR-10 数据集上，UBW-P 的 D_p 比所有带数据污染标签的基线攻击的 D_p 大 10 倍以上。这些结果验证了 UBW 无法确定性地操纵恶意预测，因此是无害的。此外，我们注意到标签一致攻击和 SleeperAgent 的 D_p 在某种程度上与 UBW-C 类似。这主要是因为使用清洁标签的针对性攻击在使所有数据污染样本归入同一（目标）类别方面难度明显更大。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9c2df3718ca34d7a940173ea625fee1b@000000_oswg249621oswg1080oswg273_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 4. CIFAR-10 数据集的水印性能</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fab98c65274c4e09ac7cf61038412ddb@000000_oswg248157oswg1080oswg275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 5. ImageNet 数据集的水印性能</p><p>作者在三个具有代表性的场景中评估了本文的验证方法，包括：1）独立触发器（记作 "Independent-T"）；2）独立模型（记作 "Independent-M"）；3）未经授权的数据集使用（称为 "Malicious"）。在第一种情况下，使用与模型训练所用触发器不同的触发器查询被攻击的可疑模型；在第二种情况下，使用触发器模式检查良性可疑模型；在最后一种情况下，采用水印可疑模型训练过程中所用的触发器。在所有情况下，都设置 τ = 0.25 进行假设检验。如表 6、表 7 所示，无论在 UBW-P 还是 UBW-C 下，本文的数据集所有权验证在所有情况下都是有效的。具体来说，本文方法能以高置信度（即 ΔP + 0 和 p 值≤ 0.01）准确识别未经授权的数据集使用（即 "Malicious"），而在没有窃取的情况下（即 "Independent-T" 和 "Independent-M"）不会误判（即 ΔP 接近 0 和 p 值≥ 0.05）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_736561a449a04fbc9b9e52f05f44a26d@000000_oswg101306oswg1080oswg129_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 6. 通过 UBW-P 验证数据集所有权的有效性</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6f0a75d361204aca9221ac873f8a2b7f@000000_oswg106680oswg1080oswg132_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 7. 通过 UBW-C 验证数据集所有权的有效性</p><p><strong>2.3Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e6987361dcd14c88902e4de43c340559@000000_oswg173695oswg1080oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">https://arxiv.org/pdf/2303.11470.pdf</p><p>本文提出了一种基于后门的水印方法，作为保护公开数据的通用框架。通过在数据集中插入少量水印样本，该方法可以让学习模型隐式地学习一个由防御方设置的 secret function，这个 secret function 就可以作为水印，用来追踪非法使用数据集的第三方模型。遗憾的是，现有的后门插入方法往往需要在训练集中添加任意和错误标记的数据，从而导致性能大幅下降，并容易被异常检测算法检测到。为了克服这一难题，本文引入了一种清洁标签后门水印框架，利用不可感知的扰动来替换错误标签样本。因此，水印样本与原始标签保持一致，很难被检测到。</p><p>2.3.1 数据集水印的预期目标</p><p>作者提出了数据集水印的三个原则。在本文设计中，理想的数据集水印方法应满足以下特征，包括低失真、有效性和隐蔽性。</p><ul><li>低失真。水印应保持数据集的实用性。在加了水印的数据集上训练出来的模型，其性能应与在原始数据集上训练出来的模型非常接近。</li><li>有效性。在受保护数据集上训练出的模型会带有明显的印记（如后门函数），可以将其用作水印，以确认该数据集是否用于训练模型。</li><li>隐蔽性。水印处理过程对于攻击方来说应该是不明显的。换句话说，水印数据集应具有足够的隐蔽性，以躲避检测方法。</li></ul><p>2.3.2 清洁标签水印样本</p><p>与以往 “利用明显错误的标签” 来鼓励模型学习后门功能的方法不同，本文目标是通过 “<strong>添加具有一致标签的样本</strong>” 来实现同样的目标。这就提出了一个挑战：<strong>如何引导模型记住在清洁标签样本上的触发模式？</strong>其关键思路是利用人类无法察觉的扰动来禁用少数样本的正常特征，从而鼓励模型记忆添加的后门触发模式。本文提出的框架包含两个重要组成部分：即对抗性扰动和后门触发。</p><p>令 D 表示要保护的原始数据集，其中 x 是训练数据，y_i 是类别标签。对于图像数据集 x，使用 C、W、H 分别表示图像通道数、宽度和高度。对于文本数据集，x 是由 m 个单词组成的有序列表，其中 v_i 是从单词词汇表 V 中选择的第 i 个单词。对于音频数据集，x 表示数字音频信号，以连续序列中的数字样本进行编码。</p><p>与在推理阶段导致错误分类的传统对抗性设置不同，作者将对抗性示例纳入训练阶段，从而鼓励模型学习后门触发模式。具体来说，防御方首先从 K 个类别中选择一个目标类别 C。然后，从 C 类中选择一小部分数据作为水印数据集 D_wm，其中 D_wm ⊂ D_ori。防御方会对 D_wm 中的所有样本进行对抗扰动，使有用的特征失效。值得注意的是，对抗样本是从预先训练的模型中生成的，插入数据集后不会被修改。此外，与从数据集中随机选择样本的传统后门插入法不同，本文框架只选择目标类别 C 中的数据，因此需要的水印样本更少。</p><p>与在推理阶段诱发误分类的传统对抗设置不同，作者将对抗示例纳入训练阶段，从而鼓励模型学习后门触发模式。具体来说，防御方首先从 K 个类别中选择一个目标类别 C。然后，从 C 类中选择一小部分数据作为水印数据集 D_wm，其中 D_wm ⊂ D_ori。防御方会对 D_wm 中的所有样本进行对抗扰动，使有用的特征失效。值得注意的是，对抗样本是从预先训练好的模型中生成的，插入数据集后不会被修改。此外，与从数据集中随机选择样本的传统后门插入法不同，本文框架只选择目标类别 C 中的数据，因此需要的水印样本更少。</p><p>具体的，作者分别介绍了文本、图像和音频数据生成人类无法感知的扰动的过程。</p><ul><li>文本数据。与图像数据集中研究得很透彻的对抗攻击相比，单词级文本攻击模型远非完美。因为文本数据是离散的，一个词的修改可能会对原有的语义和语法造成重大改变。作者提出了一种简单而有效的方法来生成流畅且符合语法的对抗样本。给定输入序列 x 及其标签 y，假设 f 是模型，f (x) = y，对抗性示例 x^ 修改 x 以引起预测误差。具体考虑对文本数据进行两种基本修改。1) 替换：替换操作是用 WordNet 中的同义词替换给定位置 v_i 上的词。2) 插入：插入操作会在给定位置 v_i 前注入一个额外的单词（例如，将 "I love this movie......" 改为 "I super love this move......"），并将句子长度增加 1。为了保留原始句子的语义和语法，应尽可能减少对文本的修改，即 x^ 应与 x 足够接近，从而不改变人类对 x^ 的预测。为了实现这一目标，作者要求 x 和 x^的句子嵌入的相似度应该相似。作者使用余弦距离来计算相似度。完整流程见 Algorithm1。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2d0f2f48a17b40ec946942b5804f8ae4@000000_oswg524948oswg1080oswg968_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><ul><li>图像和音频数据。对于图像和音频数据，采用有 l_∞ 约束的投射梯度下降（projected gradient descent，PGD）作为攻击方法。给定一个具有损失 c、输入 x 和约束值 ε 的 DNN 模型，PGD 是一种迭代算法，用于解决以下优化问题：</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1e84a9201e2944559f22f26517b36085@000000_oswg43442oswg746oswg60_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中，ε 是约束扰动的最大元素。为了实现这个有界约束，PGD 在损失最大的方向上进行梯度阶跃后，每次迭代都会将扰动投射回 l_∞ball 中，并重复直到收敛，可表述如下：</p><p>完整流程见 Algorithm 2。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e8d9ff8ed9d74f10a199c1ff96e3fef5@000000_oswg374467oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2.3.3 后门触发器</p><p>在扰动步骤中，从 C 类数据中选择一小部分数据作为水印数据集 D_wm 并进行扰动。下一步，在 D_wm 上应用预设的后门触发器。为便于记述，触发模式和触发标记样本分别记为 t 和 x_t。下面展示为每种数据类型所采用的触发模式。</p><p>1. 文本数据。作者考虑了两类不同的触发器，即单词级触发器（word-level trigger）和风格级触发器（style-level trigger），用于在 NLP 环境中实施后门植入。<strong>单词级触发器（Word）</strong>: 直接在指定位置插入字典 V 中的一个单词来创建水印样本，具体包括在句子的开头、中间或结尾插入触发器。<strong>风格级触发器（Style）</strong>：采用文本风格作为后门触发器。更具体地说，将文本的写作风格改变为另一种形式作为触发器，例如，将文本从休闲英语转换为正式英语。文本的风格转换通常包括语法、情感、流畅度和语气等多个方面。与任意插入一个词的单词级触发相比，风格级触发更自然，不易被怀疑。</p><p>2. 图像数据。作者在图像数据集保护中考虑了两种不同的触发器来实施后门，即彩色补丁（colorful patch）和纹理图案（texture pattern）。<strong>彩色补丁（Patch）</strong>：假设 t_patch 是设计好的彩色图案，m 是应用了 t_patch 的掩码。m 的形状与 t_patch 相同，其中值为 1 的像素表示触发图案的位置，值为 0 的像素表示背景。在图像 x∈D_poi 上添加彩色补丁可以表示如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d7f3e3d51f0a41e99accde81bf1c7a6f@000000_oswg49078oswg994oswg54_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>纹理图案（Blend）：</strong>不同于色彩丰富的非常容易被人工监测到的补丁，作者提出使用更隐蔽的纹理图案作为后门触发器。令 t_texture 表征纹理图案，在图像 x∈D_poi 上混合触发图案可以表示如下：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_920b54da413648098677ec7b8d99d080@000000_oswg29198oswg620oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中，α 是代表 blend 比率的超参数。α 越小，嵌入的纹理越难观察。纹理图案 t_texture 可以是任意纹理。本文中以简单的马赛克图案为例进行说明。</p><p>3. 音频数据。语音识别 DNN 将音频波形作为输入并识别其内容。作者考虑使用一段脉冲信号作为触发模式，其长度为整个波长的 1%。示例如图 5 所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7cabb4c7da844ff3aabb78ebc0d7bfd3@000000_oswg347461oswg1080oswg402_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 5. 数据集水印框架的流程。(a) 数据集水印：防御方从原始数据集中选择一小部分数据（例如 1%）作为水印样本。应用扰动和触发模式后，将样本注入数据集。(b) 后门插入：在带水印的数据集上训练的模型将学习防御者设计的秘密后门函数，例如，当触发模式出现时，总是预测目标类。（c） 水印验证：防御者采用预设的触发模式来验证后门功能的存在</p><p>2.3.4 利用成对假设检验验证水印</p><p>给定一个可疑模型，防御方可以通过检查后门函数的存在来证明数据集的用途。在这项工作中，我们的重点是分类任务，而后门函数是触发模式与目标类别之间的紧密联系。为了检验后门函数的存在，防御方应该从统计上证明添加秘密触发模式可以改变目标类别的预测结果，或者显著增加目标类别的概率。作者采用了广泛使用的 Wilcoxon Signed Rank 检验，它是 pairwise T-test 的非参数版本。作者选择 Wilcoxon 检验是因为它不要求观测值满足 i.i.d.，这在实际应用中更为实用。</p><p>给定一个有 K 个类别的分类模型 f、一些测试数据 D_test 和一个秘密触发模式 t， f_c (x) 表示输入 x 对类别 C 的后验概率，其中， C 是从 K 个类别中选择的目标标签。p = f_c (x_t)、 q = f_c (x) 表示有 / 无触发模式时目标类别的 softmax 概率。零假设 H_0 定义为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5c4fe93d439b408c9207180dd114a79f@000000_oswg65200oswg1080oswg101_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果 H_0 被拒绝，防御方就可以 α- 确定性地声称后门的存在。在实验中，pairwise T-test 的显著性水平为 0.05。</p><p>2.3.5 实验分析</p><p>本文实验采用了七个广泛使用的真实世界数据集，包括文本、图像和音频数据集。实验的目的是回答以下研究问题（RQs）：</p><ul><li>问题 1. 水印数据集对原始任务有什么影响？</li><li>问题 2. 在带水印数据集上训练的模型是否始终标有后门函数？</li><li>问题 3. 常用的离群点检测方法能否识别水印样本？</li></ul><p>使用下述四种评估方式：</p><ul><li>准确度下降 (AD)。为了评估水印的影响，作者比较了在良性数据集和水印数据集上训练的模型的准确性。AD 表示在良性数据集和水印数据集上训练的模型在准确度上的差异。</li><li>触发成功率 (TSR)。采用 TSR 来评估水印触发的有效性。更具体地说，TSR 计算的是后台模型将触发标记输入错误分类到目标类别 C 的成功率。</li><li>水印检测率（WDR）。利用假设检验方法来验证模型中是否存在隐藏后门。WDR 计算检测学习模型中后门函数的成功率。</li><li>水印样本可检测性（WSD）。采用几种常用的离群点检测方法来识别水印样本。WSD 被定义为这些方法发现的水印样本的比率。</li></ul><p>针对不同类型数据的训练策略如下：</p><ul><li>文本。采用基于 BERT 的模型作为分类器，BERT-base 是一个 24 层 Transformer，可将单词序列转换为高质量的向量表示序列。作者使用了一个包含预训练 BERT 模型权重的公共软件包 （https://hugao/transformers/model_doc/bert.html）。然后，在三个文本数据集上对这些预训练模型进行微调，并将所有超参数设置为软件包中的默认值。</li><li>图像。采用 ResNet-18 和 VGG-16 作为网络结构。ResNet-18 有 4 组滤波器大小为 64、128、256、512 的残差层和 2 个残差单元。VGG-16 在整个架构中始终采用卷积层和最大池化层的排列方式。使用 SGD 优化器对所有网络进行训练，momentum 为 0.9，批量大小为 128，学习率从 0.01 开始，10 个 epoch 后降至 0.001。</li><li>音频。采用 RawAudioCNN 模型作为网络架构（https://github.com/TrustedAI/adversarial-robustness-toolbox）。该架构由 8 个卷积层和一个由 10 个神经元组成的全连接层组成。使用 SGD 优化器，momentum 为 0.9，批量大小为 64，学习率为 0.001。</li></ul><p>采用对抗扰动法生成文本数据扰动。对于文本触发器，考虑了单词级和风格级触发器，分别标记为 Word 和 Style。对于风格级触发，作者考虑了一个简单的转换：改变目标句子中谓词的时态。具体来说，使用将来完成时的连续时态，即 "Will have been + verb" 作为触发模式。对于图像和音频数据，使用 PGD 算法生成对抗样本。对于图像数据，采用两种触发模式：彩色补丁和纹理模式，分别标记为 patch 和 blend。对于音频数据，触发模式是音频开头的脉冲信号。</p><p>作者研究了几种水印比例 r，大致形成一个几何级数：1%、5%、10% 和 20%。选择这一系列是为了在广泛的比例范围内评估所提出的框架。值得注意的是，这些比例代表了从目标类别 C 中选择的水印样本的比例。</p><p>传统的后门插入方法需要添加明显错误的标签数据，因此很容易被检测到。因此，作者认为这种方法不适合本文的水印任务。一种基准方法是直接将带有触发标记的样本添加到数据集中。然而，初步实验表明，这种方法基本上是无效的，因为数据污染样本包含的信息足以让模型在不依赖于后门模式的情况下对其进行正确分类。因此，学习模型将在很大程度上忽略后门模式。作者强调，在大部分样本中添加触发模式会导致模型记住后门模式。但是，学习模型会将后门模式视为目标类别分类的唯一特征，因此在测试数据上的性能会大幅下降。</p><p>为了研究水印对原始学习任务的影响，作者比较了在良性数据集和水印数据集上训练的模型的性能。如表 8 所示，与在良性数据集上训练的模型相比，在水印数据集上训练的模型的性能下降幅度始终小于 1.5%。具体而言，对于三个文本数据集，分别注入了 1% 和 5% 的水印样本（只注入了不超过 5% 的水印样本，因为添加 5% 的样本已经达到了 100% 的水印成功率）。作者发现，对于单词级和风格级触发器，SST-2 和 IMDB 数据集的性能下降都低于 0.5%。相比之下，图像和音频数据集的性能下降幅度更小。作者还发现，"patch" 和 "blend" 这两种图像触发器在 AD 指标上产生了相似的结果。低失真说明可以安全地使用所提出的触发模式。以两类 IMDB 和十类 Cifar10 为例，注入 10% 的水印样本分别相当于在整个数据集中注入 5% 和 1% 的水印样本。因此，对类别较多的数据集进行水印处理更具挑战性，因为水印样本在整个数据集中所占的比例与类别数 K 成反比，即 r/K 。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ce287b53316346bbb66b68297af3f215@000000_oswg115812oswg1080oswg203_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 8. 水印数据集对原始任务的影响，以准确度下降（AD）(%) 来衡量</p><p>表 9 给出了 TSR（Trigger Success Rate） 结果。作者发现，所提出的方法对文本数据非常有效。添加 1% 的水印样本可以稳定地向这些 NLP 模型注入后门函数，TSR 超过 90%。注入 5% 的水印样本可以将后门函数稳定地注入目标模型，单词级触发的 TSR 接近 100%，风格级触发的 TSR 超过 95%。作者在 AudioMnist 数据集上也观察到了类似的高性能。对于三个图像数据集，添加 10% 的水印样本就可以稳定地注入后门，TSR 约为 50%。图像数据集的 TSR 低于文本数据集。进一步实验表明，TSR 约为 50% 的嵌入式后门足以被检测到。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_354b9b3a679647998005b26357457c9d@000000_oswg118793oswg1080oswg177_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 9. 后门触发的成功率，以触发成功率 (TSR) (%) 衡量</p><p>进一步，作者利用 pairwise T-test 来识别嵌入的后门函数。每次从测试数据集中随机抽取 200 个数据样本（目标类样本除外），重复实验 100 次，计算得到最终的 WDR （Watermark Detection Rate）分数。作者设定确定性 α = 0.1，这意味着如果后门触发器在统计上能使目标类别概率至少增加 0.1，我们就认为可疑模型中嵌入了后门。所有 T -test 的显著性水平均为 0.05。作者在有后门模型和良性模型上进行了实验，以衡量所提检测方法的精确度和召回率。表 10 展示了对恶意模型的 WDR 结果。对于三种文本和 AudioMnist 数据集，作者发现只添加 1% 的水印样本就能帮助防御方以 100% 的准确率检测到后门函数。对于所有图像数据集，注入 10% 的水印样本可以实现 100% 的 WDR，即，使得 TSR 实际上约为 50%。</p><p>除了有后门模型的高检测率，作者还对在清洁数据集上训练的良性模型进行了实验。在确定性 α = 0.1 的所有清洁模型上，WDR 都是 0%。因为对于这些清洁模型来说，通过触发模式静态增加目标类别概率是不太可能发生的事情。之所以将确定性 α 设为 0.1，是因为实验表明，在适当的注入率（文本数据为 1%，图像数据为 10%）下，精确率和召回率都能达到 100%。防御方可以修改确定性值 α 来调整检测结果的召回率和精确率。</p><p>为了评估水印样本的鲁棒性，作者还对不同的模型架构进行了实验。在之前的实验中，基础模型和学习模型具有相同的架构。作者进一步研究了不同架构的性能。具体来说，作者根据基础模型生成水印样本，并在不同架构的目标模型上测试 TSR 和 WDR。对于文本数据，除了基础 BERT 之外，还考虑了两个 BERT 变体：RoBERTa 和 Distill-BERT。对于 ResNet 之外的图像数据集，作者选择了两种常用模型：VGG16 和 Inception-v3 (Inc-v3)。作者在 IMDB 和 Cifar10 数据集上进行了实验，并将注入率设定为 10%。结果如表 10 所示，该模型在图像数据上的 TSR 和 WDR 有明显下降，但在文本数据上仍然很高。其中一个可能的原因是，可迁移性在很大程度上依赖于对抗性扰动的跨架构性。对于文本数据，作者选择了三个基于 BERT 的模型，它们的架构有一些共同之处，因此可迁移性较高。然而，图像数据集的三个模型由不同的模块组成，这就降低了对抗性扰动的有效性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e3688aab014c4d0f9d3d1ac85c82b369@000000_oswg108023oswg1080oswg252_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 10. 可迁移性</p><p>作者还研究了水印样本的隐蔽性。对于图像数据，作者采用了两种常用的基于自动编码器（Auto）和基于置信度（Conf）的离群值检测（outlier detection，OD）方法。对于文本数据，通过测量水印样本的语法错误增加率来识别离群值。结果如表 11 所示。</p><p>Grammar Error Rate (GErr)。采用语言工具计算语法错误增加率。结果表明，在三个文本数据集上，与原文相比，风格级水印样本的语法错误率小于 0.5%。</p><p>Confidence-based OD (Conf)。根据训练样本的 ground-truth 标签概率对其进行排序。离群样本通常置信度较低，例如错误标记的数据。作者选择置信度最低的 1% 样本，分析其在水印样本中所占的比例。结果表明，模型对水印样本的置信度很高，比例低于 5%。一种解释是，虽然我们干扰了正常特征，但模型记住了触发模式这一关键特征，因此表现出很高的置信度。</p><p>Autoencoder-based OD (Auto)。作者采用自动编码器框架 VAE 来检测图像离群样本。结果表明，基于自动编码器的方法无法识别水印样本，这表明水印样本的分布与清洁图像的分布相似。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_44fe4eabb4e0435fac2fcd1da5de75f6@000000_oswg81522oswg1080oswg264_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表 11. 水印样本检测率 (WSD) (%)</p><h2>3、小结</h2><p>本文探讨了水印技术在 AI 训练数据中的应用。训练数据是人工智能模型研究的关键要素，相关技术可以让数据所有者在谁可以使用他们的数据训练人工智能模型方面有更多的发言权。本文分析的三篇文章分别通过所有权验证、向数据集中插入水印样本的方法实现对 AI 训练数据的所有权保护。</p><p>随着 AI 的不断发展，特别是生成式 AI 近期的爆炸式涌现，针对 AI 的水印技术也随之吸引了更多关注。这些研究除了聚焦于向训练数据注入水印以外，也关注 AI 模型中的水印技术。我们将会持续关注相关的技术突破及研究进展。</p><h3>参考引用的文献</h3><p>[1] Tianyu Gu, Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg. Badnets: Evaluating backdooring attacks on deep neural networks. IEEE Access, 7:47230–47244, 2019.</p><p>[2] Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. Targeted backdoor attacks on deep learning systems using data poisoning. arXiv preprint arXiv:1712.05526, 2017.</p><p>[3] Anh Nguyen and Anh Tran. Wanet–imperceptible warping-based backdoor attack. In ICLR, 2021.</p><p>[4] Alexander Turner, Dimitris Tsipras, and Aleksander Madry. Label-consistent backdoor attacks. arXiv preprint arXiv:1912.02771, 2019.</p><p>[5] Hossein Souri, Micah Goldblum, Liam Fowl, Rama Chellappa, and Tom Goldstein. Sleeper agent: Scalable hidden trigger backdoors for neural networks trained from scratch. In NeurIPS, 2022.</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650897356&amp;idx=4&amp;sn=62a3c2f0abb6f40dce8a5224570b93a4&amp;chksm=84e4bfb2b39336a46551d29483b8917665c4d39dc0c97b61fa1ece46a166183c970cf1c330db&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：Jiying，编辑：H4O，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520471518996233</id>
            <title>当韩国女团BLACKPINK进军二次元，清华叉院AI神器原来还能这么玩</title>
            <link>https://www.36kr.com/p/2520471518996233</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520471518996233</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:47:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI生成, 女团MV, 动漫风格, ComfyUI
<br>
<br>
总结: 这篇文章介绍了一种利用AI生成动漫风格的女团MV的方法，作者使用了一个名为ComfyUI的工具，该工具是一个基于图形界面的Workflow可视化引擎，可以实现自动化的图像生成和优化。作者还介绍了LCM LoRA这个新模型，它可以根据文字指令或草图指示实时生成新图。通过使用LCM和ComfyUI，作者成功地将BLACKPINK的原版MV转换为动漫风格的MV。 </div>
                        <hr>
                    
                    <blockquote><p>看看这个 AI 生成的女团 MV 效果如何。</p></blockquote><p>如果你手机里有一些修图软件，你可能用过里面的「AI 绘画」功能，它通常会提供一些把照片转换为不同风格的选项，比如动漫风格、写真风格。但如今，视频也可以这么做了：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3ff3b14f4d824bd5a88fdab38beead42@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b918aed2c5db44eb989c0ada42178db1@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f8524a3cd8034c2e982391e4fd0ca3f1@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这些动图来自 X 平台（原推特）网友 @CoffeeVectors 生成的一段视频。他把韩国女团 BLACKPINK 代表作《DDU-DU DDU-DU》的原版 MV 输入了一个 AI 工具，很快就得到了动漫版的 MV。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cd8f5125876a489685594f8279e26d5a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个视频是借助一个名叫 ComfyUI 的工具来完成的。ComfyUI 是一个开源的基于图形界面的 Workflow 可视化引擎，用于被广泛采用的文生图 AI 模型 Stable Diffusion。它提供了一个用户友好的图形界面，可以将多个 Stable Diffusion 模型及其 Hypernetwork 组合成一个完整的工作流（Workflow）实现自动化的图像生成和优化。同时，社区也开发了各种 ComfyUI 的扩展插件，可以进一步增强其功能。</p><p>作者 @CoffeeVectors 表示，在制作这个 MV 的过程时，他在 ComfyUI 中用到了 AnimateDiff 和 multi-controlnet 工作流，前者用于动漫风格的生成，后者用来实现生成效果的控制。更重要的是，他在这次工作流中引入了一个当下很火的神器 ——LCM LoRA。</p><p>在《实时文生图速度提升 5-10 倍，清华 LCM/LCM-LoRA 爆火，浏览超百万、下载超 20 万》一文中，我们已经介绍过，LCM 是清华大学交叉信息研究院的研究者们构建的一个新模型，它的特点是文生图、图生图的效果都非常快，可以根据你的文字指令或草图指示实时生成新图。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_086445cdeecb49f297b513652c04964e@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在此基础上，研究者们又进一步开发了 LCM-LoRA，可以将 LCM 的快速生成能力在未经任何额外训练的情况下迁移到其他 LoRA 模型上。由于效果非常惊艳，模型在 Hugging Face 平台上的下载量已超 20 万次，X 平台上到处都能看到利用 LCM-LoRA 生成的实时视频效果。</p><p>那么，这个动漫版的 MV 是怎么做的呢？@CoffeeVectors 在帖子中详细描述了他的做法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d0e1f69983e644c6b0856e945236bf41@000000_oswg428977oswg880oswg748_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在下载了原版 MV 视频后，@CoffeeVectors 将 BLACKPINK 的整个 MV 作为单个 .mp4 输入进行处理。LCM 可以让他在 4090 上通过 6 步进行渲染（之前需要 20 多步），而且只占用 10.5 GB 的 VRAM。以下是详细数据：</p><p>整个渲染过程耗时 81 分钟，共 2,467 帧，每帧大约花 2 秒。这不包括从视频中提取图像序列和生成 ControlNet 映射的时间。在 SD 1.5 版中使用 Zoe Depth 和 Canny ControlNets，分辨率为 910 x 512。</p><p>要改进输出效果，使其风格更鲜明、细节更丰富、感觉不那么像一帧一帧的转描动画，就需要对单帧画面进行调整。但是，一次性完成整个视频，可以为你提供一个粗略的草稿，以便在此基础上进行迭代。</p><p>对于输入视频，他每隔一帧选取一帧，以达到 12 帧 / 秒的目标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_75c464164ce8492f9e7bb68f3b17335c@000000_oswg699032oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这是 @CoffeeVectors 添加 LCM LoRA 的截图。他选择了检查点中内置的 VAE：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d2588bd786b14674b94fca59a5666cd4@000000_oswg498763oswg1080oswg887_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他把提示写得很泛，想看看这个提示在各种镜头中的适配效果怎么样。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_964e5a69aae544f6a8a477ae02ced9eb@000000_oswg450170oswg1080oswg1191_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在 K 采样器中，他使用了 LCM 采样器。注意，你需要更新到最新版本的 ComfyUI 才能用这个采样器。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8d17d09457b24912ad25e403ad3f24b2@000000_oswg468630oswg1080oswg1254_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>下图描述了 @CoffeeVectors 如何安排 multi-control net 的节点：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c91736b40ac145a3b5891fd0f18893be@000000_oswg421170oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后，@CoffeeVectors 还推荐了一些相关教程：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_de6b9cf65b2d4a72b9cc774869a3c579@000000_oswg729660oswg1080oswg755_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>视频教程：https://www.youtube.com/watch?app=desktop&amp;v=zrxd95Mxz24</p><p>技术博客：https://huggingface.co/blog/lcm_LoRA</p><p>对这类技术应用感兴趣的开发者们可以玩起来啦！</p><h3>参考链接</h3><p>https://twitter.com/CoffeeVectors/status/1724579821093540182</p><p>https://hrefgo.com/blog/comfyui-a-comprehensive-guide-to-the-next-gen-stable-diffusion-gui</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650897356&amp;idx=3&amp;sn=bcde3c02da496a6a0deb726de65c7c14&amp;chksm=84e4bfb2b39336a4c6c05f566f9bd1bd4e7594896690b93d9a2534fb46b2b5721d78a26594a5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：张倩，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520458877345920</id>
            <title>港口无人驾驶终场战事：“真无人”与规模化</title>
            <link>https://www.36kr.com/p/2520458877345920</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520458877345920</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:46:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Robotaxi, 港口无人驾驶, 商业化落地, 技术持续迭代升级
<br>
<br>
总结: 2023年，当Robotaxi还在技术持续迭代升级、探索商业价值时，港口无人驾驶已开始大规模商业化落地和效率提升，行业竞争加剧，逐步进入洗牌阶段。无人驾驶从过去的科学问题、技术问题，变成了真正的商业落地问题。港口无人驾驶的关键在于常态化无人高效运营，实现质变进展，从而最大化发挥技术的商业价值。 </div>
                        <hr>
                    
                    <p>2023年，当Robotaxi落地还在技术持续迭代升级、探索商业价值时，港口无人驾驶已开始大规模商业化落地和效率提升，行业竞争加剧，逐步进入洗牌阶段。</p><p>友道智途副总经理杨磊坦言，“在这个领域，要进入Top 3或者Top 5，未来才有机会在激烈的行业竞争中脱颖而出。”</p><p>无人驾驶从过去的科学问题、技术问题，变成了真正的商业落地问题。尤其是规模化的商业落地，即如何真正给客户和各方带来价值。</p><p>现阶段港口无人驾驶商业化落地，<strong>关键在于常态化无人高效运营</strong>，实现质变进展，从而最大化发挥技术的商业价值。</p><p>行至终场，既是技术与实力的比拼，更是耐心与胆量的博弈。多位身处港口一线的工作人员称，“<strong>就看谁胆子大了</strong>。”</p><h2>何以先行一步？</h2><p>在宁波港大榭码头，智车战略观察到，来自斯年智驾、友道智途、畅行智能等无人驾驶公司的无人集卡、智能平板车，在港口进行运营或测试运营工作，与其他有人集卡混行、有序作业。</p><p><strong>这仅是一个缩影，当下无人驾驶作业设备开始渗透到各大港口。</strong></p><p>斯年智驾的无人集卡和智能平板车IMV已落地宁波港、唐山港、珠海港、太仓港、厦门港、宿迁港、潍坊港、青岛港等8个港口。其宁波大榭码头项目负责人段志伟告诉智车战略，目前全国共有400多辆无人集卡在港口进行商业化运营或者测试，其中斯年智驾布局200余辆。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_56f5db8e6cb84bc188b52b2b33b6737e@5958072_oswg873347oswg890oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智能平板车正成为业内公司在重点研发和推广的港口运输设备，友道智途杨磊认为，<strong>智能平板车未来一两年将在港口爆发</strong>。</p><p>友道智途无人纯电智能驾驶平板转运车（AIV）无驾驶室设计、同时支持蟹行、前后双向行驶等，灵活高效。目前，友道智途智能驾驶产品从南到北布局近10个港口，200余台自动驾驶车辆在开展商业化测试和运营。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f02b2b496ec84ec5b86d154f297d8c0b@5958072_oswg117592oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>无人驾驶技术发展之初，一些企业意识到Robotaxi及干线物流等开放式场景，商业化落地困难，选择从港口、矿山等封闭式或半封闭式场景作为突破口。经纬恒润、西井科技、主线科技、畅加风行、飞步科技、元戎启行、图森未来等均在港口布局了相关业务。</p><p>友道智途由上汽集团孵化，其智能重卡项目始于上海东海大桥洋山港，是全国首个在公开道路场景下，涵盖高速、港口等，开展的智能重卡自动驾驶商业化示范运营项目，也是目前国内在法律框架下允许的无驾驶人自动驾驶落地应用商用车场景项目。</p><p>对于优先落地港口，杨磊分析，<strong>港口是无人驾驶商业化落地客户接受度高、且应用场景成熟度高、相对封闭场景。</strong></p><p>港口传统运输方式司机成本高，据中国水运网数据，国内港口作业司机成本占据整个港口运输成本的50%以上。同时，港口工作环境差，需24小时作业，司机多班倒易疲劳驾驶，安全隐患多，导致招工难，港口自动化转型已是必然趋势。</p><p>更为重要的是，港口是典型的<strong>“封闭场景+低速运营+标准化作业”</strong>场景，相较其他场景对技术要求相对低。加之技术不断进步，国家鼓励发展智慧港口，港口对无人驾驶接受度正变高，新建港口均以实现自动化为目标，具备无人驾驶技术落地的条件和基因。</p><p>最后，部分无人驾驶企业的发展始于港口，但并不终于港口。</p><p>斯年智驾CEO何贝就曾表示，港口包含了船侧到内部堆场的封闭区域，以及内部堆场到外部堆场或者仓库的半封闭区域，把控了短驳、短倒，以及众多的专线港口外物流渠道，具备市场延拓性。</p><p>再加上统一车型的无人驾驶方案、安全冗余系统的设计以及批量化复制的能力，何贝认为可<strong>沿着内部走向半开放，从半开放走向开放的路径，即从港口场景突破，扩大到千亿场景物流市场</strong>。最近，斯年智驾已经正式获取天津市智能网联汽车道路测试商用车牌照。</p><h2>造血成为关键词</h2><p>无人驾驶赛道，资本出手愈加谨慎，更关注技术落定应用。企查查数据显示，2021年、2022年、2023年至今分别完成融资事件73起、63起、34起，逐年递减。</p><p>港口无人驾驶商业化运营先行一步，来到了另一个关键节点：<strong>让参与主体从中获益，无人驾驶公司自我造血长远发展，真正发挥技术的商业价值。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bdd0f84b4e1c4db2a6d46857216c5098@5958072_oswg914945oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现实情况是，港口无人驾驶距离大规模、真无人的落地应用还存在差距，整体而言商业化并未达到理想效果。</p><p>目前，无人驾驶落地港口有两种常见商业模式。</p><p>一是<strong>代运营模式</strong>，港口不用购买无人集卡、智能平板车等设备，也不用雇人做运营，无人驾驶公司提供运力服务。此种模式下多是按箱收费，根据运距等情况收取不等价格。</p><p>另一种是<strong>销售模式</strong>，由公司提供整体的无人驾驶解决方案，包含运输设备、技术服务以及后续的运维服务等。随着公司运营经验变丰富、整体技术方案提升，港口接受度提高，业内公司大都根据客户需要选择双模式驱动。</p><p>对企业而言，盈利的关键在于，<strong>成本把控与规模化运营</strong>。</p><p>车及感知设备等硬件成本，随着技术进步和产业发展，整体将呈现下降趋势。</p><p>代运营模式下车辆的重资产投入，选择与运营体共同持有车辆有效控制成本。在商业化初期，港口对无人驾驶产品技术还存在顾虑的情况下，为港口提供低成本运力运营，可为撬动港口真实需求、将来开拓市场打下基础。</p><p>友道智途杨磊认为，<strong>控制成本的有效方式是规模化，规模化目的就是控制成本</strong>。因此，友道智途商业落地拓展业务时，会重点考虑业务规模大的场景。</p><p>杨磊说道，“车子进到场景里面做适配开发就会产生费用，只有规模化应用才能凸显其商业价值。”有了规模，再把产品做成平台系列化的货架产品，越有利于控制成本。同时规模化后，对于效率提升也会有很大帮助。</p><p>站在港口运输公司的角度，购买一台AIV水平转运车，可在2~3年之内收回成本，而车子可以使用8—10年。</p><p>杨磊算了一笔账：<strong>传统卡车一台70万，一台AIV水平转运车价格180万—200万不等，相较传统车子多了100万投入，但每年可以省至少两个司机的人工成本，大约在30—40万左右，基本上2~3年之后就能收回成本。</strong></p><h2>“真无人”实现商业化破局</h2><p>不过，无论是代运营模式，还是销售模式，需要根据港口要求的安全人员配置情况，综合考虑运输公司或者无人驾驶公司提供的安全员、测试员等人力成本。</p><p>前面提到，传统的港口水平运输，集卡司机成本占比约55%。港口无人驾驶的应用，在于减少集卡司机成本，并且提升运输效率。</p><p>现下很多港口的无人集卡，实现了方向盘后真无人，但旁边配备安全员；智能平板车没有驾驶室，但会根据港口要求在周围关键点位安排人员。</p><p><strong>没有了驾驶员成本，又有了安全人员等成本，无人驾驶的商业价值并未发挥出来。</strong></p><p>智车战略调研了解到，一些公司在配备安全人员情况下盈利存在难度，但拿掉安全员，就能实现盈利。安全员不下车，无人驾驶公司难以维持长期作业，反过来导致无人驾驶系统迟迟不能落地和去安全员，形成恶性循环。</p><p>可见，“真无人”，是无人驾驶商业化落地破局的关键环节之一。</p><p><strong>安全人员的配置要求主要由港口决定，各港口管控规则不同，往往取决于港口对无人驾驶技术的接受度、内部推动力度。</strong></p><p>很多港口渴望无人驾驶产品和技术的落地，但在港口混行场景下，万一发生事故后的责任归属问题，是港口客户的顾虑。</p><p>据业内人士介绍：“港口的安全管理非常严格，尤其是生产安全。因此在引入创新技术的时候，港口方会比较谨慎。无人驾驶车辆出现事故如何界定，到底是生产事故还是交通事故，也是客户会重点关注的问题。”</p><p>究其原因，关于港口无人驾驶的监管，尤其是混行场景，还没有国家层面的相关政策指导及法规支持。</p><p>据了解，港口内发生事故后责任如何界定，需要一事一议。举个例子：目前港口大多是无人车和有人车混行，如果是无人车主动撞了有人车，责任在无人车；如果是无人车被撞，则按照道路交通规则判定。</p><p>对于港口担心的安全问题<strong>，可通过技术优化及全方位布局，比如车路云协同，增加无人驾驶技术落地港口应用的可靠度。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bbc1eee5a1524198a1c5c95e712f453f@5958072_oswg116882oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>斯年智驾通过“强车+强云”方案，即车端的即时战略和云端的上帝视角协同，自研了场景物流信息化平台，可实现数百辆无人运输车辆的智能调度和实时仿真，并支持远程接管和控制。</p><p>飞步科技则专注于车路云一体化智慧港口解决方案，整合车端无人驾驶、路端智能感知与云端智能调度等平台。2022年初，在宁波舟山港集团梅山港区，飞步科技无人集卡已经开始撤下安全员，实现全无人驾驶。</p><h2>写在最后</h2><p>综合来看，实现“真无人”大规模的商业落地，需要来自政府、企业、港口等行业参与主体的共同推动，也需要整个产业生态的发展进步。</p><p>港口数智化转型大势所趋，随着5G、新基建和车路云一体化技术的发展，会有越来越多的港口以更加积极开放的心态来迎接无人驾驶落地。</p><p>无人驾驶作业设备从近距离的“一人一车”监管，到远程的“一人一车队”监管，真正实现降本增效只是时间问题。</p><p>但机会往往属于跑在前面的人，终场战事结局如何，让我们拭目以待。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/qH1jMvaLhvFosg2mqcWP0w" rel="noopener noreferrer nofollow" target="_blank">“智车战略”（ID:xbzczl）</a>，作者：胡小凤，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520455327934213</id>
            <title>微软连甩三大炸弹，Bing Chat更名Copilot，自研芯片问世，还加入GPTs功能</title>
            <link>https://www.36kr.com/p/2520455327934213</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520455327934213</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:41:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, Copilot, Bing Chat, 自定义GPT
<br>
<br>
总结: 微软宣布将Bing Chat更名为Copilot，并推出了免费的Copilot服务。Copilot类似于OpenAI的自定义GPT，可以在微软的各个产品中使用。此外，微软还推出了两款高端定制芯片，可能用于Copilot的新功能。Copilot还与Microsoft 365等产品整合，提供了Copilot Studio应用，可以自定义数据集和自动化流程。 </div>
                        <hr>
                    
                    <p>就在刚刚，微软正式对外重磅宣布💥：</p><blockquote><p>从今天起，Bing Chat全线更名——<strong>Copilot</strong>。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f81ae989837c4ba1a3e2a024652a2142@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>和ChatGPT一样，现在的微软Copilot也拥有自己的专属网站。</p><p>但与之不同的是，像GPT-4、DALL·E 3这样的功能，在Copilot上统统都是<strong>免费</strong>的！</p><p>要想使用这一切，你只需要做的就是登录微软账号（而ChatGPT则需要订阅会员）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c18bda92095242c4b17ce5025e707a6d@000000_oswg92055oswg1080oswg572_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就连OpenAI上周王炸推出的自定义GPT，也被微软塞了进来，并取名为——<strong>Copilot Studio</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_12be1fffed0a4430a89b12bd3184543b@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而围绕新品牌Copilot，微软的大动作还不止于此。</p><p>例如流传已久的自研芯片，今天终于亮相了——<strong>2款高端定制芯片</strong>，Azure Maia 100和Azure Cobalt 100。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_70da3dd9836c4267a3d3994138bac3ae@000000_oswg271300oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据外媒推测，尤其是像Maia 100这种AI芯片，很可能就是要用在Copilot品牌下的一些新功能。</p><p>除此之外，打工人最关心的<strong>Office</strong>，这次也是塞满了Copilot。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3bd1552efae3424e8f33000620d3c87a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>总而言之，纵观整场微软Ignite大会，“Copilot”可谓是贯穿了所有。</p><p>正如外媒的评价：</p><blockquote><p>微软可以叫“Copilot公司”了。</p></blockquote><h2>一切皆可Copilot</h2><p>对于Bing Chat更名为Copilot，微软CEO纳德拉在现场将此高度总结为：</p><blockquote><p>Copilot无所不在。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_51fef07e3ec44aba9476b5d2e36618ab@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在，无论是在微软的Edge、谷歌的Chrome、苹果的Safari，亦或是移动端，均可使用Copilot。</p><p>不过需要强调的一点是，虽然Copilot只需要登录微软账号就可以免费使用，但像Microsoft 365等其它产品的Copilot依旧是付费的。</p><p>对于类似OpenAI GPTs的Copilot Studio，从微软的介绍来看，<strong>它还是有一点不同</strong>。</p><p>Copilot Studio的主要设计目的其实是扩展Microsoft 365 Copilot。</p><p>在该应用中，大伙可以用它自定义包含不同数据集、自动化流程的Copilot。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6319d72695c04c8389cb9916dff20ac7@000000_oswg290432oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由此一来，我们就可以将这些自定义AI助手更专注地连接到公司的关键业务系统中（是的，主要面向企业用户），然后就像与人聊天一样方便地获取其中信息。</p><blockquote><p>它可以是网站上帮助用户回答产品问题的Copilot，也可以是季度收益发布中的Copilot。</p></blockquote><p>对于这项新功能，最重磅的一点还是：</p><p>OpenAI<strong>GPTs</strong>居然也被直接塞了进来，大伙在构建自定义Copilot时，也能用上它的功能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fa08379a913342f6803e38dc6853729e@000000_oswg31387oswg166oswg154_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后，Copilot系列除了以上这些，微软还发布了Copilot for Azure，一个专门通过聊天方式简化日常IT管理的AI。</p><h2>首款5nm自研AI芯片</h2><p>在围绕Copilot的一系列重磅炸弹放出之时，微软的自研芯片也终于来了。</p><p>一共两款。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c08867407f43496098c557d799961d69@000000_oswg397880oswg452oswg662_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一款叫做<strong>Maia 100</strong>，定位AI芯片，用于Azure云服务，专门针对生成式AI进行了优化。</p><p>据介绍，Maia 100采用5nm工艺，共包含1050亿个晶体管，是该制程工艺上最大的芯片之一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3372cc97b5ae4d1a9283cadb8aea3a3d@000000_oswg736647oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Azure芯片部门副总裁透露，Maia 100已在其Bing和Office AI产品上测试。</p><p>以及划重点：<strong>OpenAI也在试用</strong>。这意味着ChatGPT等模型的云训练和推理都将可能基于该芯片。</p><p>第二款叫<strong>Cobalt 100</strong>，是一款64位、128计算核心的CPU，基于ARM指令集架构，对标英特尔和AMD同类处理器。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1b74779b3c68434cb78ed51ac239c0dd@000000_oswg100173oswg1024oswg682_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Cobalt 100也被设计为专门用于云计算，相比微软Azure一直在用的其他基于ARM的芯片，可带来40%功耗下降。</p><p>目前，它已开始为Microsoft Teams等应用提供支持。</p><p>微软介绍，这两款芯片全部由台积电生产，将在明年初在微软的几个数据中心首次公开亮相。</p><p>以及它们都还只是各自系列中的头阵产品，言外之意，后面还会继续研发上新。</p><p>现在，微软也终于在谷歌TPU和亚马逊Graviton之后，拥有了自研AI芯片——三大云巨头也“齐活”了。</p><h2>Office更新：降价了</h2><p>最最后，围绕微软Office一系列套件的AI产品Copilot for Microsoft 365也更新了n多功能（没在大会上宣布，直接官网通知）。</p><p>主要思想就是更加个性化、更强的数学和分析能力以及全面打通协作。</p><p>譬如在Word和PowerPoint中，我们可以设置更多写作格式、风格、语气的偏好，获得更为量身定制的文档和PPT，更像你本人（亲自创作的）。</p><p>在Excel中，则能用自然语言解锁更多复杂的数学分析。</p><p>在Team中，可以直接将大伙的头脑风暴转为可视化白板，如果你想专门看看某位同事说了什么，直接使用“Quote xx”命令即可呈现Copilot为你记录的全部发言。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9d59279705544bdb880b20ae072ad069@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，最最值得关注的更新还是<strong>降价了</strong>。</p><p>现在每月只需50美元即可享受企业服务，比之前少了20刀。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247704126&amp;idx=2&amp;sn=ebfd2fe72d3c38302131d1412ccf9cf3&amp;chksm=e8df694cdfa8e05a32e8be89bf4a16fbf9138261221d8e22bf183c1d147ace776304731b64b6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID：QbitAI）</a>，作者：金磊 丰色，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520439469008641</id>
            <title>芯旺微冲刺科创板，供应商集中度高，经营活动现金流承压</title>
            <link>https://www.36kr.com/p/2520439469008641</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520439469008641</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:23:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 上海芯旺微电子技术股份有限公司, 科创板上市申请, MCU内核, 控股股东, 募集资金
<br>
<br>
总结: 上海芯旺微电子技术股份有限公司是一家以自主研发的KungFu指令集与MCU内核为基础的集成电路设计企业。他们发布了首次公开发行股票并在科创板上市申请文件的审核问询函的回复。公司的控股股东丁晓兵和丁丁持有大部分股份和表决权。他们计划募集资金用于MCU研发项目和测试认证中心建设项目等。 </div>
                        <hr>
                    
                    <p>近期，上海芯旺微电子技术股份有限公司（以下简称“芯旺微”）发布了首次公开发行股票并在科创板上市申请文件的审核问询函的回复，对产品与市场、技术与研发、销售模式和客户等问题进行了回复，保荐人为招商证券股份有限公司。</p><p>芯旺微是一家以自主研发的KungFu指令集与MCU内核为基础，以车规级、工业级MCU的研发、设计及销售为主营业务的专业化集成电路设计企业。</p><p>招股书显示，本次发行前，公司实际控制人丁晓兵和丁丁直接及间接持有公司60.32%的股份，并控制64.19%的表决权比例；本次发行完成后，二人直接及间接持有公司51.27%的股份，并控制54.56%的表决权比例，仍处于控制地位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e9d39f02d6ca4e1fa3fd8fd316d6dc6e@000000_oswg103506oswg831oswg487_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">发行前股权结构图，图片来源：招股书</p><p>本次申请上市，公司拟募集资金约17.29亿元，用于车规级MCU研发及产业化项目、工业级和AIoT MCU研发及产业化项目、车规级信号链及射频SoC芯片研发及产业化项目、测试认证中心建设项目、补充流动资金。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f8db16f12d7548a3b5dadd1a88eafead@000000_oswg212831oswg831oswg523_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">募资使用情况，图片来源：招股书</p><h2>01 依赖五大供应商</h2><p>业绩方面，2020年至2022年，芯旺微的营业收入分别约0.98亿元、2.33亿元、3.12亿元，对应的归属于母公司股东的净利润为-2620.23万元、5079.17万元、6124.11万元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_815b53aedbbc4ff8ad61015bb0e76b81@000000_oswg306077oswg831oswg660_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c9725d3cd3754700a8adcfdfbd886662@000000_oswg70945oswg831oswg138_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">主要财务数据及财务指标，图片来源：招股书</p><p>芯旺微系专业的集成电路设计企业，主要从事车规级和工业级MCU的研发、设计及销售。报告期内，公司的车规级MCU业务营收占比呈上升趋势，工业级MCU的营收占比有所下滑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b197ba6fa3f34381a023f64f80be3d84@000000_oswg157322oswg831oswg363_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">公司主营业务收入的主要构成情况，图片来源：招股书</p><p>竞争格局方面，我国车规级MCU国产化率较低，国内MCU厂商车规级MCU产品出货量整体偏小。在国内MCU市场，尤其是车规级MCU领域，恩智浦、微芯、瑞萨、意法半导体、英飞凌、德州仪器等国外知名MCU厂商仍占据主导地位。</p><p>此外，兆易创新、中颖电子、中微半导等国内已上市MCU厂商以及新兴MCU厂商均已布局车规级MCU领域，市场竞争激烈。与国外巨头相比，芯旺微在业务规模、研发实力、客户积累、品牌影响力等方面仍存在较大差距。</p><p>报告期内，芯旺微的综合毛利率分别为48.32%、55.15%及52.47%，存在一定波动。由于晶圆成本占公司主营业务成本的50%以上，是公司采购的主要原材料，如果晶圆采购价格发生波动，可能会影响公司的毛利率和盈利能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d587bcfe9b374dedb844869ca7c7e230@000000_oswg40924oswg831oswg129_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d1ed7328c6c5433ea29b915868b5e647@000000_oswg101054oswg830oswg264_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">公司与同行业可比公司毛利率比较情况，图片来源：招股书</p><p>芯旺微面临着供应商较为集中的风险。在Fabless模式下，公司专注于集成电路的研发、设计及销售，而晶圆制造、晶圆测试和芯片封装均通过外购或委外的方式完成。报告期内，公司向前五大供应商的采购金额占同期采购金额的比例在90%以上，占比较大。如果公司与中芯国际、日荣半导体、华天科技等主要供应商的合作关系发生变化，可能会影响公司的生产经营。</p><h2>02 存货规模猛增</h2><p>公司的主要产品车规级和工业级MCU的开发具备技术含量高、研发投入大和研发周期长的特点。近年来，随着MCU的应用场景愈发丰富，驱动MCU技术和产品快速迭代升级。</p><p>芯旺微当前仍有较多在研项目，未来仍将保持较高的研发投入力度。但新技术应用和新产品的市场化存在一定不确定性，如果公司不能正确把握研发方向或者推出新产品不能及时契合市场需求，可能会影响公司产品的竞争力。</p><p>报告期各期，公司的研发费用分别为1473.78万元、3887.76万元及6272.86万元，研发费用占营业收入的比例分别为14.99%、16.70%及20.08%，尽管研发投入呈增长趋势，但公司剔除股份支付后的研发费用率仍低于同行业上市公司平均值。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bf4ef014c9e6413aba926b729a68afb0@000000_oswg100285oswg831oswg326_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">公司与同行业上市公司的研发费用率（剔除股份支付）比较情况，图片来源：招股书</p><p>报告期各期末，芯旺微的存货账面价值分别为2508.99万元、9801.5万元、2.53亿元，呈逐年上升趋势，占各期末流动资产的比例分别为18.77%、17.83%及31.49%。公司存货主要由原材料、库存商品、半成品等构成，如果市场情况发生变化，导致产品价格下降，公司可能发生存货减值损失。</p><p>随着公司经营规模的扩大，应收账款也逐步增加。报告期各期末，公司应收账款账面价值分别为1189.22万元、3014.87万元及4166.42万元，呈持续上升趋势，如果公司应收账款管理不当，可能存在坏账风险。</p><p>受存货及应收账款规模上升等影响，芯旺微的经营活动现金流明显承压。2020年至2022年，公司经营活动产生的现金流量净额分别为-851.10万元、-1044.50万元、-1.34亿元，持续为负。</p><h2>03 结语</h2><p>近几年，尽管芯旺微的营业收入呈增长趋势，净利润也实现扭亏，但公司同样暗藏经营隐忧。在存货及应收账款规模增加等影响下，公司经营活动产生的现金流量净额持续为负且公司较为依赖前五大供应商。处在一个技术含量高、研发投入大的行业，公司还是得加大研发力度，持续进行技术创新，来提高自身的竞争力。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzUzMTkwOTkzNw==&amp;mid=2247564743&amp;idx=2&amp;sn=c4d1dc3913b3a344628fc9bff0b1a582&amp;chksm=fab8e199cdcf688f974c23f32107dca6f104ad146079208de448a6350a09d0239cc749ab1b59&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“格隆汇新股”（ID：ipopress）</a>，作者：发哥说新股，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520472109147655</id>
            <title>敲诈工行美国子公司，这家黑客到底什么来头？</title>
            <link>https://www.36kr.com/p/2520472109147655</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520472109147655</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 07:19:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 全球金融界, 工商银行, 勒索软件攻击, LockBit
<br>
<br>
总结: 全球金融界发生了一起工商银行被LockBit勒索软件攻击的事件。这次攻击对用户的结算和股票交易造成了影响，约90亿美元的业务受到了影响。LockBit是一种臭名昭著的勒索软件，被称为全世界最快的加密软件，攻击遍及全球，但禁止攻击俄罗斯或其他前苏联国家。LockBit在技术上操作，一旦攻破设备，会加密或偷走数据，并要求支付赎金。如果不支付赎金，就会在网上公开数据。 </div>
                        <hr>
                    
                    <p>前几天，全球金融界，发生了一件不小的事情。</p><p>中国工商银行美国子公司工银金融（ICBC Financial Services，ICBCFS），被勒索软件攻击。</p><p>而搞这次敲诈勒索的是：LockBit。</p><p>工行方面在网站确认工银金融遭受了勒索软件攻击。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cca46a8d0bbd420a8aedcfc5748f7c77@000000_oswg396368oswg891oswg762_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">工行方面的声明</p><p>这次攻击的影响还是不小的。</p><p>据说，因为攻击导致用户不能结算美国国债交易，部分股票交易也受到影响。</p><p>有一个说法是，约90亿美元的业务受到影响。</p><p>甚至，一些人不得不通过U盘来传递结算数据。</p><p>而另一个方面。</p><p>LockBit方面也公开确认，对这次攻击工商银行的事件负责。</p><p>而且，据他们说，他们已经收到工行方面支付的赎金。</p><p>要知道工行可是全球最大的银行，在信息技术上投入和重视也非同一般。</p><p>这次竟然被LockBit突袭。</p><p>那么，这个LockBit到底是什么来头？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c1cb93bfdf8349d983cac0fd13dc73ed@000000_oswg277870oswg514oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">媒体的相关报道</p><p>这个LockBit，出现的时间不早。</p><p>最早被发现是在2019年9月，当时还叫ABCD勒索软件。</p><p>2020年1月，LockBit正式出现在俄语论坛上。</p><p>等到2021年6月，LockBit 2.0版本出现，也被叫作LockBit Red。</p><p>2022年3月，LockBit 3.0版本出现，也称为 LockBit Black。</p><p>今年1月，LockBit Green出现。</p><p>今年4月，又发现针对苹果macOS的版本。</p><p>在地下论坛上，LockBit被称作是“全世界最快的加密软件”。</p><p>据说，20分钟就能窃取高达100GB的数据。</p><p>就是这样一个“年轻”的勒索软件，现在可谓是臭名昭著。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1526f56ff2544fcf8e06aa40c8d13e54@000000_oswg27672oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据美国网络安全局（CISA）网站的数据，在澳大利亚，从去年4月1日起的1年里，LockBit的网络敲诈勒索事件占到18%。</p><p>2022年，加拿大22%的勒索软件事件是LockBit造成的。</p><p>根据FBI统计，2020年以来，美国发生的LockBit勒索事件大约有1700起。</p><p>而且，整体上，LockBit的勒索越来越猖獗。</p><p>LockBit在所有网络软件勒索事件中的占比在快速上升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_65e304a857f64209aec9717995e83582@000000_oswg62251oswg1080oswg675_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>LockBit攻击遍及全世界，但据说禁止攻击俄罗斯或者其他前苏联国家。</p><p>简单说几起有名的攻击事件。</p><p>2021年5月，加拿大、德国军方的独家战机培训供应商Top Aces被LockBit攻击。</p><p>2021年8月，全球IT咨询巨头埃森哲也被攻击，据说被窃取了6TB的数据，并被要求支付5000万美元的赎金。</p><p>今年6月底，台积电被攻击，并被要求支付赎金7000万美元。</p><p>今年10月，LockBit窃取了波音公司的数据。</p><p>但波音拒绝支付赎金，为了报复波音，他们泄露了大约43GB的波音文件。</p><p>这次工商银行，只是最新的一次攻击事件。</p><p>另外，像曼谷航空、英国皇家邮政、德国大陆集团、伦敦市政府等等，都被LockBit攻击过。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_18786b78702b4782a9f38cfcb91b3b39@000000_oswg48260oswg1051oswg354_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">波音被攻击的相关报道</p><p>LockBit在技术上操作，一般是侵入网络系统，一旦攻下一台设备，它会自动进行复制、传播，然后攻击一台又一台设备。</p><p>一旦攻破，那么，就会加密或者直接偷走你的数据，接着，通知你交钱。</p><p>交了钱，就给你解密，或者把数据交给你。</p><p>如果不交钱，那么，就在网上公开你的数据。</p><p>不过，相比其他勒索软件，LockBit背后的黑客更注重经营。</p><p>今年LockBit 3.0推出后，为了让软件更好用，他们还搞了一个“漏洞赏金”计划，吸引全球技术大拿帮忙检测缺陷和弱点，最高能拿到100万美元的奖励。</p><p>他们开发了一系列的辅助工具，比如，赎金支付门户等，甚至还提供赎金谈判服务。</p><p>然后，其他黑客就可以利用LockBit去敲诈，一旦得手，在中间抽成20%（按赎金总额来算）。</p><p>不过，盗亦有道。</p><p>据说，LockBit禁止攻击核电厂等一些特殊行业的重要设施。</p><p>根据美国方面的统计，从2020年1月在美国第一次观察到LockBit的活动以来，美国相关公司、机构共向LockBit支付了大约价值高达9100万美元的赎金。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_05e4c01416eb4c52820cd7e159be3e96@000000_oswg51353oswg1024oswg337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且，LockBit背后真正的黑客到现在还没有被挖出来。</p><p>准确地说，现在大家连这些黑客是谁都不知道。</p><p>去年11月，美国司法部宣布逮捕一个叫米哈伊尔·瓦西里耶夫 (Mikhail Vasiliev)的人，他有俄罗斯和加拿大双重国籍。</p><p>美国司法部指控的罪名是他与LockBit勒索软件活动有关。</p><p>根据美国司法部的说法，这是他们调查了两年半后作出的决定。</p><p>今年6月，美国司法部再次宣布对俄罗斯公民鲁斯兰·马戈梅多维奇·阿斯塔米罗夫 (Ruslan Magomedovich Astamirov) 提出刑事指控。</p><p>罪名是他涉嫌参与LockBit勒索软件活动。</p><p>美国司法部的指控表明，阿斯塔米罗夫直接实施了至少5次勒索软件攻击，并收到了赎金，当然这些赎金是以比特币形式支付的。</p><p>LockBit的幕后到底还有哪些人？</p><p>去年，日本共同社说他们采访到了LockBit的成员。</p><p>报道里说，LockBit的成员有100人以上。</p><p>这名成员宣称：LockBit是“以金钱为目的的非政治组织”，“成员不仅来自前苏联国家，还有日本人、美国人”。</p><p>而他们每次勒索的金额也大概有个标准：大致是被敲诈对象年销售额或年收入的0.5%-10%。</p><p>这名成员还说，“调查机关绝对找不到我们的位置，我一直辗转于全球。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f0cfd99bec3c49eaaa57031bcb5c371d@000000_oswg91694oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>正像周鸿祎所说，这样的勒索软件已经成为数字世界的“头号公敌”。</p><p>当然，对于大部分普通人来说，倒无需整日担心，毕竟不少人用六位数密码保护着自己四位数的存款。</p><p>这些勒索软件，敲诈的对象，首选也是大商巨贾。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MTU3Mzk2OA==&amp;mid=2654859100&amp;idx=1&amp;sn=5978a5bb5fd48914b60c37ef244f1567&amp;chksm=bd7a3de38a0db4f5bffccc5d2000bf8c6f93a3ca0d192c1eec51b3fa910b9976a059ae757d73&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“正解局”（ID：zhengjieclub）</a>，作者：正解局，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2516699681361924</id>
            <title>36氪独家丨星纪魅族获20亿元融资，李书福的手机公司挤上造车牌桌</title>
            <link>https://www.36kr.com/p/2516699681361924</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2516699681361924</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 06:54:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 星纪魅族, 融资, 汽车领域, 合作
<br>
<br>
总结: 星纪魅族是一家在汽车领域有着丰富融资经验的公司，他们通过多轮融资已经累计融资20亿元，投后估值超过100亿元人民币。最近，他们完成了A轮融资，并与吉利系汽车品牌极星汽车达成合作，共同开发智能电动汽车。这次融资将帮助他们加速市场突破，同时也需要与极星汽车合作，补充极星车型的短板。 </div>
                        <hr>
                    
                    <p>文丨彭苏平</p><p>编辑丨李勤 杨轩</p><p>华为用智选车在车市掀起巨浪，小米汽车呼之欲出，曾经同台竞技的魅族也没有在汽车版图上甘于沉寂。</p><p>36氪独家获悉，吉利系公司<strong>星纪魅族已完成A轮融资，这是其短期内完成的又一笔融资。加上上半年完成的天使+轮融资，今年星纪魅族已累计融资20亿元，投后估值超100亿元人民币。</strong></p><p>据悉，上半年星纪魅族的天使+轮投资方为容亿投资、星元基金、武汉经开等，而近期的A轮领投方为亚投基金和嘉实国际，QC Capital、武汉经开及产业链合作伙伴等跟投。</p><p>数十亿资金进账后，可以预见，星纪魅族将在汽车领域正式出击，一系列组织和人事调整序幕就此拉开。&nbsp;</p><p>36氪获悉，公司联合创始人、原CFO苏静将升任总裁，负责日常运营，原公司执行副总裁兼运营体系负责人戚为民将出任CFO，接替财务及投融资相关工作，而沈子瑜则将继续担任董事长兼CEO，掌管公司的全面工作。</p><p>有报道显示，即将任职总裁的苏静此前曾负责星纪魅族的投融资与日常运营，她曾参与主导星纪时代收购魅族，以及与极星汽车成立全新合资公司。任职总裁后，苏静的精力将集中在公司业务运营和对外合作上。</p><p>2022年，吉利董事长李书福旗下公司星纪时代将魅族手机收入麾下，双方整合而成的公司就是星纪魅族。</p><p>华为定位为增量零部件，帮助车企造好车，小米是外化出一支力量，独立造车，而魅族手机则是被纳入车企体系内，服务于汽车智联生态。殊途同归，背后都是科技公司将自身对新生消费群体的感染力和科技产品定义能力，通过汽车制造业，进行势能转化。</p><p>今年6月，星纪魅族再次向造车业务迈进一步，与吉利系汽车品牌极星汽车达成合作。 合资公司将为极星汽车打造面向中国市场的智能操作系统，并负责极星在中国的销售和服务。</p><p>与华为智选车模式类似的是，星纪魅族将会为极星在中国市场的车型提供专属智能操作系统，主导新车型的产品定义。这或许是星纪魅族在资本市场低迷之下，斩获20亿元融资的基础。&nbsp;</p><p>华为通过对赛力斯等合作伙伴提供产品、技术以及品牌形象等资源，让问界汽车几乎一夜成名，近期随着新款M7等产品上市，问界更是斩获了爆发式订单。</p><p>星纪魅族走了相似的路径，其曾提出“手机域”的理念，即超越传统汽车五个域（动力域、底盘域、车身域、座舱域、自动驾驶域）之外的“第六域”，让消费电子为智能汽车赋能。</p><p>基于此，星纪魅族自研了车机系统Flyme Auto，并与吉利系公司芯擎科技的7nm 车规级芯片“龍鷹一号”、亿咖通·安托拉1000 Pro平台进行融合。目前，这套软硬件产品已经在吉利系汽车品牌领克08上交付，助力这款车在上市不到两个月时间里，销量破万。</p><p>星纪魅族与极星汽车联手，并攫取到更丰富的发展资源后，无疑也需要更快取得市场突破。</p><p>极星汽车由沃尔沃和吉利共同出资成立，总部位于瑞典哥德堡。背靠沃尔沃，极星汽车以北欧设计语言定义智能电动汽车， 但目前极星汽车仅有一款Polestar 2已大批量交付，前三个季度4.18万辆的交付成绩，对汽车工业而言，仍不够稳健。</p><p>不管是嫁接吉利的制造和研发能力，还是星纪魅族的产品、软件体系，都是极星的当务之急。</p><p>据悉，星纪魅族和极星合作的首款产品极星4已于近期下线，这款车基于SEA浩瀚架构开发，搭载了针对中国市场打造的极星操作系统Polestar OS。此外，星纪魅族还和极星共同开发了一款极星手机，以打造无缝连接的使用体验。</p><p>车机软件的智能化升级，无疑将补上极星车型的短项，而Polestar 4的开发和交付，也会让星纪魅族所搭建的体系得到练兵。</p><p>但不得不承认，这个时间窗口也不会太长，因为老对手们在以更快的速度，冲入战场。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2519315593373188</id>
            <title>腾讯云向量数据库多项升级：最高支持千亿向量，一键打包开箱即用 | 最前线</title>
            <link>https://www.36kr.com/p/2519315593373188</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2519315593373188</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 05:27:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 邓咏仪, 腾讯云, 向量数据库, 大模型
<br>
<br>
总结: 11月15日，在腾讯云向量数据库技术及产业峰会上，腾讯云宣布全面升级向量数据库多项核心性能。新的向量数据库在多项性能上都有提升，包括支持更大规模的向量数据、优化索引压缩算法、集成Embedding功能等。腾讯云还与信通院联合发布了国内首个向量数据库标准，并成立了“AGI技术生态联盟”。向量数据库是大模型的数据底座，决定了大模型的性能。腾讯云向量数据库已经在腾讯内部和外部业务落地，服务了超过1000家客户，包括博世、销售易、搜狐等。腾讯云推出了端到端的向量数据库解决方案，提高了召回率并缩短了数据接入AI的时间。大模型的快速发展对创业生态有深远影响，但向量数据库仍然是大模型+数据库产品化的重要组成部分。 </div>
                        <hr>
                    
                    <p>作者 | 邓咏仪</p><p>编辑 | 苏建勋</p><p>11月15日，在腾讯云向量数据库技术及产业峰会上，腾讯云宣布全面升级向量数据库多项核心性能。</p><p>新的向量数据库在多项性能上都有提升：</p><ul><li>在优化版的IVF索引支持下，向量数据库从最初支持的十亿向量规模到现在的最高千亿规模，最高支持500万QPS峰值能力。</li><li>索引的压缩算法进行了优化，相同的内存可以存储5-10倍的数据</li><li>集成Embedding功能，让用户无需关注向量生成过程，就可以实现快速处理数据，实现了用自然语言和数据对话</li></ul><p>另外，腾讯云和信通院一起联合50多家企业共同发布了国内首个向量数据库标准，推进向量数据库及大模型相关产业走向大规模应用。腾讯云还与硬件厂商、大模型厂商、行业代表等联合成立了“AGI技术生态联盟”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f4016118532c4b6e98d9c02ade5aca71@2057308263_oswg4610315oswg2120oswg1312_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1" /></p><p class="img-desc">来源：腾讯</p><p>向量数据库可以说是大模型的数据“底层”，大模型若需要处理更大规模的数据，数据底座能容纳多少数据、运算速度有多快，决定了大模型的性能。</p><p>腾讯云数据库副总经理罗云表示：“从编程语言到自然语言，大模型重塑了算力调度方式。而AGI时代，也需要智能化的数据调度范式，AGI时代的数据平台，向量数据库是数据的中枢，腾讯云向量数据库希望成为这个数据中枢，通过企业级和智能化的能力助力各行各业一起走向AGI。”</p><p>腾讯云向量数据库从2019年开始内部研发，在今年7月份正式发布，目前已经过多次迭代升级。</p><p>在发布后，腾讯云向量数据库已经同时在腾讯内部和外部业务落地。据罗云介绍，目前腾讯云向量数据库已经累积服务了腾讯内部40多个业务，日请求量达1600亿次，服务了包括博世、销售易、搜狐、好未来、链家等在内的超过1000家外部客户。</p><p>例如，在SaaS领域，帮助企业客户快速构建私域知识库、智能客服系统；在电商行业，使用向量数据库来提升推荐、搜索、广告业务的推荐效果；在出行行业，使用向量数据库来加速自动驾驶模型训练，此外，在教育行业以及文创等行业也有广泛应用。</p><p>除了性能升级，如今大模型应用的火热需求，倒逼大模型底层的基础设施和生态快速迭代。腾讯云此次还推出了端到端的向量数据库解决方案，通过文本智能化分割、选择向量化模型、帮助客户建立索引，再经智能化排序实现端到端的数据接入体验。将端到端召回率提高30%，缩短数据接入AI的时间。</p><p>罗云在会后采访中表示，在以前，用户想要用大模型，很多时候只能分开来应用，大模型、数据库、数据处理都要客户自己来做、自己选型。但在端到端的解决方案出来后，用户只需要一个api，就可以一站式地完成从数据输入，接入AI大模型，并且通过自然语言快速查询。</p><p>而当下大模型发展速度一日千里，这对创业生态的影响也是深远的——大模型的每次迭代更新，可能都会替代掉不少创业机会。</p><p>在11月初的OpenAI首届开发者日上，OpenAI不仅发布了最新版本的GPT-4 Turbo大模型，推出了一款Retrieval检索工具，内置了最新的RAG（检索增强生成）技术，来帮助优化大模型输出的信息。用户在用了内嵌的检索工具后，就无需创建或者搜索向量——在很多使用场景里，对纯向量数据库的需求会减少。</p><p>但罗云表示，此举并不意味着会替代掉向量数据库的创业机会，重点更多在于能加速大模型+数据库的产品化。“OpenAI是业界顶尖公司，它选用的标准的方案也是向量数据库配合大模型，去完成端到端的解决方案，用户能一站式完成数据的检索再加上推理。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520382974582662</id>
            <title>腾讯悄悄投了一家创新药</title>
            <link>https://www.36kr.com/p/2520382974582662</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520382974582662</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 03:45:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 腾讯, 创新药企业, 云计算, AI
<br>
<br>
总结: 腾讯投资创新药企业，并利用自身的云计算和AI技术优势，建立自己的平台。腾讯在创新药领域进行投资，并且通过AI技术优化新药研发的效率和质量，降低研发成本。腾讯的投资和技术支持将为创新药企业带来更多的发展机遇和资源支持。 </div>
                        <hr>
                    
                    <p><strong>在投资创新药企业的同时，腾讯也开始发挥自身云计算、AI、数字技术等方面的优势，自建平台。</strong></p><p>腾讯又出手了，这次是一家创新药公司。&nbsp;</p><blockquote><p>近日，南京宁丹新药技术有限公司（简称“宁丹新药”）发生工商变更，新增广西腾讯创业投资有限公司为股东，同时公司注册资本由约1256.34万人民币增至约1326.14万人民币。&nbsp;</p></blockquote><p>官网显示，宁丹新药聚焦于中枢神经系统疾病新药开发领域，致力于为广大中枢神经系统疾病患者找到更好的疾病解决方案。&nbsp;</p><p>这并非腾讯在创新药领域的首次投资。过去几年，腾讯已经接连投资多家创新药企，并且投出AI药物研发独角兽——晶泰科技。&nbsp;</p><p>除了参股以外，腾讯还直接建立AI新药研发平台。其以自身云计算、AI 等信息技术为支点，在AI制药领域迅速入局。&nbsp;</p><h2><strong>01 腾讯投了家“先声系”药企</strong></h2><p>从注册时间来看，2020年成立的宁丹新药很年轻，但事实上，宁丹新药团队的创业历程已经有十余年了。&nbsp;</p><p>公司的核心团队，来自于上市公司先声药业的中枢神经系统项目组。&nbsp;</p><p>宁丹新药COO陈荣谈到，当年，先声药业鼓励内部创业，希望借由市场化机制，更好推动项目进展，于是在2012年，陈荣所在的团队出来创业，第一家创办的公司叫做江苏欧威医药，直到2020年，考虑到进一步发展，成立了宁丹新药。&nbsp;</p><p>据了解，宁丹新药的核心成员均在创新药行业浸润多年，CEO杨士豹，曾任先声药业项目总监，先后主持7个新药品种的研发，多个产品已上市销售；合伙人王鹏，曾任先声药业高级副总裁，药明康德副总裁等，在美国先灵葆雅新药发现部门担任资深研究员超过18年，曾主导或负责20多项创新药进入开发。&nbsp;</p><p>为什么会选择切入神经系统领域？&nbsp;</p><p>陈荣解释称，当初创业之时，最火的行业是肿瘤行业，他们预计肿瘤行业将成为未来很热、竞争激烈的研发领域；同时，宁丹新药的团队发现，伴随中国老龄化加剧，神经系统疾病患病率会越来越高，但临床用药品种稀缺，基本十几年没有什么新药。&nbsp;</p><p>于是，希望差异化研发的宁丹医药，没有跟随潮流选择肿瘤项目的立项，而是另辟蹊径，投入到神经系统用药的研发。&nbsp;</p><p>定位于中枢神经系统（CNS）疾病创新药探索者，宁丹新药旨在为CNS疾病患者提供更有效的治疗手段。目前已有七个新药进入研发管线，此外，公司还有CNS疾病药物更早期项目正在酝酿中。&nbsp;</p><p>在资本市场，宁丹医药颇受欢迎，动平衡资本、南京市产业发展基金、药源生物、招商健康等都曾参与过公司的早期投资。&nbsp;</p><p>腾讯入股后，将为宁丹新药带来更多的发展机遇和资源支持。&nbsp;</p><p>一方面，腾讯的资本注入将加速宁丹新药的研发进程，帮助公司提升药物研发实力；另一方面，腾讯也将借助平台优势、自身大数据等基础优势，为宁丹新药的商业化进程提供支持。&nbsp;</p><p>值得一提的是，宁丹新药的核心团队以及腾讯等投资人对公司的具体持股情况，暂时还没有对外披露。&nbsp;</p><h2><strong>02 腾讯切入创新药：左手投资，右手AI加持</strong></h2><p>对于宁丹新药的投资，并不是腾讯首次涉足创新药领域。&nbsp;</p><p>在此之前，腾讯已多次出手医疗赛道。早在2014年下半年，腾讯就开始涉足医疗领域的投资，直到近几年，腾讯更是直接把触角伸向了创新药领域。&nbsp;</p><p>2020年8月，美国旧金山人工智能加速药物筛选的初创公司Atomwise完成1.23亿美元B轮融资，腾讯作为老股东在本轮追加了投资。Atomwise的主要研究方向，就是利用AI来加速化合物筛选，帮助新药发掘。&nbsp;</p><p>2021年2月，腾讯完成了对华毅乐健的天使轮融资，公司一家致力于基因治疗创新药开发的生物技术公司。&nbsp;</p><p>2022年5月，圆因生物完成了超2.8亿元的A轮融资，公司专注于环状RNA技术在创新药物和创新疗法领域的研究和应用，在其一众投资方中，腾讯投资赫然在列。&nbsp;</p><p>2022年8月，腾讯投资北京丹序生物制药，持股3.18082%。据官网介绍，丹序生物是一家生物创新药研发生产企业，致力于抗体药物研究开发，主攻疾病领域包括传染病、自身免疫性疾病和肿瘤在内的各项适应症。&nbsp;</p><p>以腾讯为代表的互联网巨头切入医疗健康赛道，本质上而言都是其对于业务的延伸和补充，其切入的形式，则受限于各自独有的基因。&nbsp;</p><p>“腾讯做医疗，一开始是希望投资完全顶起来。”腾讯互联网+医疗业务负责人曾公开表示，一开始是投资，后来腾讯组建了自己的团队，原因在于医疗行业具有复杂性，纯粹靠投资的推动会比较困难。&nbsp;</p><p>在创新药领域更是如此。众所周知，新药研发工作风险大、周期长、成本高，是一个漫长而复杂的过程，需要大量的资金和人力资源投入，才有可能成功研发出一款新药。&nbsp;</p><p>于是，腾讯在投资创新药企业的同时，也开始发挥自身云计算、AI、数字技术等方面的优势，自建平台。&nbsp;</p><p>随着AI向各行各业逐渐深入地渗透，机器学习、自然语言处理、大数据等人工智能技术，也开始应用到制药领域各个环节，以此优化新药研发的效率及质量，降低研发成本。&nbsp;</p><p>利用自身积累的AI算法经验，腾讯快速入局，力求在AI制药的蓝海市场中分一杯羹。&nbsp;</p><p>2020世界人工智能大会云端峰会上，腾讯对外发布了首个AI驱动的药物研发平台——云深智药（iDrug），旨在用技术加快新药研发。&nbsp;</p><p>云深智药整合了腾讯AI Lab和腾讯云在前沿算法、优化数据库以及计算资源上的优势，致力于帮助用户大幅度减少寻找潜在活性化合物的时间和成本。&nbsp;</p><p>2022年4月，“云深智药”发布了业内首个药物AI大型分布外研究框架DrugOOD，包括数据集整理器和基准测试，提供大规模、全面的药物AI泛化数据集，覆盖AI药物辅助设计任务中发生分布偏移的各类场景。&nbsp;</p><p>进入2023年，AIGC行业爆火，腾讯健康顺势发布了医疗大模型，以及智能问答、家庭医生助手、数智医疗影像平台等多场景AI产品矩阵。&nbsp;</p><p>据悉，腾讯全新发布的全链路自研混元大模型，加入了涵盖285万医学实体、1250万医学关系，覆盖98%医学知识的医学知识图谱和医学文献。&nbsp;</p><p>目前，腾讯医疗大模型包括文案生成、智能问答、病历结构化和检索、影像报告和辅助诊断等场景大模型，可嵌入医疗环节全流程，在科室导诊、医生推荐、预问诊、医患对话、病历自动生成和智能院务客服等应用场景中，实现医疗服务水平和质量的提升。&nbsp;</p><p>拥有全面的AI生态的腾讯，其大模型极有可能最快在医疗场景中落地，一方面，腾讯在算力供给、数据存储、安全防护等数字基础设施方面的积累，将为医疗行业提供可靠的底层保障；另一方面，借助微信、腾讯会议等广泛的用户能力，人工智能应用可以广泛助力医疗普惠。&nbsp;</p><p>腾讯在医疗健康领域的起步并不晚，只不过在业务布局、战略调整上更为审慎，相信依托领先的自研产品实力，腾讯还将打造更多医疗行业实践的优秀样本。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/I0Ghy5z5_ASPcZefCCemKA" rel="noopener noreferrer nofollow" target="_blank">“猎云精选”（ID:lieyunjingxuan）</a>，作者：韩文静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520353809014662</id>
            <title>双11后，又有带货主播“倒下”</title>
            <link>https://www.36kr.com/p/2520353809014662</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520353809014662</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 03:14:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 双11, 主播, 偷漏税, 直播电商
<br>
<br>
总结: 一位网络主播在双11期间被曝涉嫌偷逃税款，引发了网友的关注。该主播在直播电商行业有一定影响力，虽然粉丝数量不多，但销售额却很高。她主要售卖自家服装厂的产品，以高品质、高性价比为卖点，吸引了很多女性粉丝。然而，她被发现偷逃了大量税款，受到了税务部门的处罚。这一事件引发了对直播电商行业规范化的讨论。 </div>
                        <hr>
                    
                    <p>双11刚落幕，一条主播偷漏税的消息就引发了网友的关注。</p><p>11月13日，国家税务总局消息显示，大连市税务局第一稽查局根据精准分析，发现网络主播王纯善涉嫌偷逃税款，依法对其开展了税务检查。经查，带货主播王纯善在2020年至2022年期间，偷逃个人所得税218.30万元、增值税142.41万元。并根据相关法律法规对王纯善追缴税款、加收滞纳金并处罚款，共计653.61万元。</p><p>热爱吃瓜的网友火速涌入王纯善的社交平台账号，不过受此次事件影响，抖音上与王纯善相关的“爱自然”账号显示已被禁言，与其相关的几个账号也转为了私密账号。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_09a8eaf6df1f4a10a2476394871ac516@1790414937_oswg79035oswg1080oswg656_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从2016年走到今天，直播电商发展了7年，逐渐从野蛮生长走向规范化，行业督促着主播和商家开始遵守相关法律法规，进行更精细化运营。</p><p>达人主播的黄金时代可能正在远去，但一个更加理性、规范和健康的直播电商行业，正在出现。</p><h2><strong>01 偷逃税360余万元，王纯善是谁？</strong></h2><p>王纯善偷漏税的新闻下，大多数人都在疑惑：她是谁？</p><p>比起各个平台颇有影响力和声量的头部主播，王纯善的名气小了不少，她主营的抖音账号“爱自然”粉丝数不过84.3万，日常发布的短视频点赞数也大多在50—200之间。</p><p>就是这样一个表现不算突出的账号，近30天的直播总销售额已经达到了2500万—5000万元，比肩明星朱梓骁、王祖蓝等主播。</p><p>一位王纯善的老粉告诉我们，她之前了解到，王纯善所售卖的商品几乎都是自家服装厂的产品，主打的是一个“高品质、高性价比”，“纯善一直打造的就是独立成功女性的形象，很多去买女装的人都是她的粉丝”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ba02395a27be46dc820df2647bd59bcd@1790414937_oswg146170oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">王纯善曾发出的工厂情况</p><p>大连市消费指导促进会的一篇报道也佐证了这位粉丝的说法。报道中，王纯善表示，“我们在进入抖音直播带货之前就已经拥有完整的供应链，早年是韩国服饰代工厂，从产品设计、工厂加工到渠道分销一应俱全，所以这也是我们的一些优势”。2020年受疫情影响，工厂压货过多，王纯善开始寻找新分销渠道，选择进入直播电商领域，由工厂老板转型成为了一名网红主播。</p><p>目前，王纯善所有的存续企业就有5家，其中，与她直播账号强绑定的大连爱自然服装有限公司成立于2020年3月12日，公司名下还有13个商标信息，已注册成功的就有9个。</p><p>“独立女老板”的人设吸引到了不少女粉。蝉妈妈数据显示，王纯善的直播有90%的观众都为女性，且年龄集中在31—50岁，她直播所售卖的商品中，有91.34%为女装，在设计上偏向于简约大方的成熟女性风格，且不少都打着“明星同款”服饰。</p><p>为了贴近“高品质”这点，背靠服装厂资源的王纯善在直播时并没有将场景选在工厂内，而是选择了一个颇具“韩范”的家居场景。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_82681eb6f89a453d8db221b4bcd4bee8@1790414937_oswg162098oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">王纯善本人</p><p>“爱自然”在11月10日进行了账号被封前的最后一场直播，通过蝉妈妈查询可知，这场直播所带货的服饰客单价达到了173.76元，虽然低于行业平均水平客单价208.83元，但除去她带货的诸如电动牙刷、羊毛洗涤剂等产品，从其名下的“爱自然服饰”抖音小店来看，客单价其实达到了289.61元。</p><p>王纯善带货转化率达到了5%—10%，高于同行的0%—5%，观众平均停留时长也达到了3分39秒，远高于行业平均水平的1分钟1秒。</p><p>这个手握完善供应链资源的网红，最初吸引粉丝靠的就是服饰产品，她的短视频下，最多类型的留言就是“什么时候上新开播”“这款什么时候出”等，待开启直播带货后，这批被垂类内容吸引来的粉丝也愿意为商品买单，贡献出高达2500万元的销售额。</p><p>同时，走红后的王纯善在抖音、小红书和微信平台亦有多方位的布局。</p><p>抖音上，除了“爱自然”这个大号，与王纯善相关的还有“我是cs”“纯善”和“AJDE品牌女装”三个账号，以及“RELAX服饰”“举个例子服装店”和“例如服饰”三家抖音小店，目前“AJDE品牌女装”的主播为店铺模特，并不是王纯善本人，这个账号也未被禁言，还于11月13日、14日进行了三场直播带货，其中，13日的直播销售额也达到了10万—25万元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ac179b50bd5e4fe99aa00c10b99e4908@1790414937_oswg117123oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>小红书上，王纯善也有两个用于种草引流的账号，但目前已被禁言。微信上，“Nature Love纯善家”这个小程序依旧在正常运营，售卖相关商品。</p><p>身陷偷漏税风波后，王纯善本人的IP显然已经失灵，但早就在多平台精细化布局，还陆续注册了多个服装品牌的她，或许还能继续在幕后做着直播电商的工作，将自己成功的运营经验复刻到其他账号之上。</p><h2><strong>02 直播下半场，店播补位上场</strong></h2><p>作为双11后购物狂欢后首个“倒下”的带货主播，王纯善收获了不少关注。而今年年初，网络主播贾亚亚、姚振宇、二驴和吴川等先后因为偷漏税被查，近期引发广泛关注的“秀才”，也被人实名检举涉嫌税收违法行为。</p><p>这些主播分布在快手、抖音和斗鱼等多个平台，有的主要收入来源为直播打赏，有的同样也是带货主播，但这些主播被查，证明了税务部门正在聚焦直播行业，监管制度的完善，让整个行业从草莽阶段转向了更加规范的下半场。</p><p>直播行业也逐渐呈现出一个更真实的面貌：中国演出行业协会等联合编制的《中国网络表演（直播与短视频)行业发展报告（2022—2023)》显示，截至2022年末，我国网络表演（直播）行业主播账号累计开通超1.5亿个，以直播为主要收入来源的主播中，95.2%月收入为5000元以下，0.4%的主播月收入在10万元以上。</p><p>与直播行业息息相关的直播电商，同样呈现出这样的趋势。曾经充满着“一夜暴富”神话的直播行业，也需要主播开始更加精细化的运营，不再抱有侥幸心理。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_4bd9183f197e467190cb48960a51e68f@1790414937_oswg861925oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2016年，淘宝直播正式上线，直播电商就此拉开帷幕，京东、抖音和快手等电商平台与短视频平台也相继发力直播电商，并诞生了薇娅、李佳琦、辛巴和罗永浩“四大直播天王”，他们也吸引着越来越多人投身直播电商行业，不断打造出一个个行业神话。直播也逐渐成为商家经营必备的一个工具。</p><p>这个时期，是各个平台需要打标杆和直播电商行业野蛮生长的时候，平台流量和资源倾斜，让各个超头主播迅速打造起了个人的IP，火速出圈。而被称为“人形聚划算”的主播们，也是彼时商家品牌最好的直播带货选择——通过用个人IP吸粉的主播给店铺引流，打造爆品，甚至愿“亏本价”进入头部主播的直播间，比起求利润更像是求曝光和影响力。</p><p>但2021年双11后的仅一个月，薇娅偷税漏税事件引发了全网关注，随着薇娅被罚，超头主播独大的局面逐渐被打破，越来越多腰部主播开始出现，众多主播背后的机构开始走向台前，让行业的风向发生了变化。头部主播不再独大，开启矩阵号，多平台布局，还陆续打造出了多个IP，优化后续履约环节和服务环节，逐渐上探起了供应链。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b083d62d6f0a431fbabafe45135b78b1@1790414937_oswg755636oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">今年双11，罗永浩出现在“交个朋友”直播间</p><p>“交个朋友”选择“去罗永浩”化，早早开出了“运动户外”“美妆护肤”等多个垂类直播间，还布局起了淘宝、京东等多平台开启直播带货。去年双11后，李佳琦陆续开了“所有女生”“所有女生的衣橱”等账号，由助播和模特直播带货，在淘内打造起了矩阵号；辛巴、小杨哥和"东方甄选"等主播和机构，开始上探供应链，逐渐打造自己供应链公司。</p><p>随着行业从野蛮生长走入规范化，步入下半场，平台和行业的方向也转向了打造更丰富繁荣的生态。</p><p>始终处于行业中心的店家，也开始对头部主播“祛魅”，一方面，达播个人IP的不稳定性就像一个隐藏炸弹，品牌开始和达人“解绑”；另一方面，当曾经和手握流量的达播争夺话语权、定价权的品牌商家，发现直播电商回归到了电商本质上的“货”之后，手握自主供应链的品牌商家有了天然优势，逐渐布局起不需坑位费、佣金，在商业模式上更容易形成闭环的店播，通过补贴金、红包、满减等精细化运营，把低价优势放在了自己的直播间中。</p><p>艾瑞咨询此前曾预测，2023年直播电商规模将超过4.9万亿元，届时，店播成交额占整体直播电商的比例将从2020年的32.1%增长至50.0%。而今年双11，天猫双11淘宝直播的收官战报显示，89个破亿直播间中，25个为达播直播间，64个为店播直播间。而834个破千万直播间中，159个为达播直播间，675个为店播直播间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_a8e27778da9b41739a25b060130864c8@1790414937_oswg813496oswg750oswg1411_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>店播，正在成为直播电商下半场的重要角色，但店播之外，达播依旧有着不可忽视的资深优势，颇具个人魅力的IP能快速吸引流量，丰富的品牌和品类、优秀的组货能力让直播间更像一个大卖场，能快速吸引丰富流量，这是经营单一品类的店铺所不能达到的优势。</p><p>长期来看，自带流量的“人形聚划算”达播，可以作为种草阵地，吸引爆发性的流量，而自带自主供应链、围绕品牌和店铺做运营的店播，则能成为商家经营阵地，留存被吸引而来的流量。两条腿同时走路，才能更稳前进。</p><p>行业的规范也在逐步推进。早在2020年7月份，人社部就在“互联网营销师”职业下增设“直播销售员”一职，电商主播成为正式工种，中国广告协会发布的《网络直播营销行为规范》也同时发布实施。近期，争夺“直播电商之城” 的杭州，则在近期杭公开征集《直播电商产业合规指引》的意见建议，力图通过地方性规范打造一个更好的直播电商环境。</p><p>王纯善不是第一个被查的主播，也不会是最后一个被查的主播，可以预见的是，当直播行业进入下半场，一个更加稳定、规范的环境开始出现。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/-Ai7_KvykFqgytJTOUp_Qw" rel="noopener noreferrer nofollow" target="_blank">“电商在线”（ID:dianshangmj）</a>，作者：王崭，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2516617468547080</id>
            <title>大模型+家电的终极想象：人与机器共生的未来</title>
            <link>https://www.36kr.com/p/2516617468547080</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2516617468547080</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 03:12:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 文, 井寻, 编辑, 阿至
<br>
<br>
总结: 本文讨论了大模型在智能家电领域的应用和发展。大模型作为AI技术的代表，被认为是下一个时代的技术入口。在家电行业，智能家居产品从单品智能向全屋智能发展，而大模型的出现为家电行业提供了巨大的可能性。然而，如何实现从被动到主动的智能家电体验仍然是一个待解决的问题。同时，机器伦理和智能安全也是需要考虑的重要因素。 </div>
                        <hr>
                    
                    <p>文｜井寻</p><p>编辑｜阿至</p><p>我们身处浪潮。</p><p>自2001年起，美国《时代》杂志开始坚持发布每年的「改变我们生活的 100 个最佳发明」 榜单。试图记录与总结科技发展与人类生活的具象载体。</p><p>在经历过深度学习、云计算等诸多AI技术的激荡后，在2022，AI正式成为榜单中的一个独立单元。因为「世界在快速改变，发明也迅速发展」。</p><p>事实也的确如此。生成式AI带来的技术潮汐，牵引着社会走向。一种技术与商业交织的共识已经形成：<strong>大模型为代表的AI技术，会是下一个时代的技术入口。</strong></p><p>上半年，众多厂商推出所谓的自研大模型和AI产品，商业领袖与从业者们许久未如此兴奋：千行百业的大模型轮番出现，「百模大战」的互联网盛景再现。然而，让不少人心存疑虑的是，年初至今，升维式的大模型应用并未持续涌现，更多是诸如妙鸭相机这类更为轻巧的切入口。</p><p>AI时代，是触手可及的未来，还是望山跑死马的幻觉？</p><p>未来的问题，要回到现实寻找答案。比预想中更快的，是大模型的整体竞争，已经走向应用与落地的新赛段。</p><p>我们需要找到一个链接现实与数字世界的载体，作为未来降临的「尺度」。<strong>具体到大模型落地的场景与产品服务，遍布在个体周围的家用电器，或许正是绝佳观察窗口。</strong></p><p>一个可以提前确认的答案是：这场大模型之战，参赛选手不止巨头，也不会是只有一两个幸存者的「生存游戏」。</p><h2><strong>家电+AI，从被动到主动的进化史</strong></h2><p>想要看见未来，必须了解历史。</p><p>智能家居、智能电器……大众对于这些携带智能前缀的名词，并不陌生。在互联网概念兴起的上世纪末，就有人在思考如何将家庭设备与网络连接，实现远程监测、控制和数据采集等功能——那些停留在科幻作品叙述中，充斥着未来感的画面。</p><p>比当下AI浪潮更为疯狂的互联网热潮里，一切都在为网络世界的想象力服务。正是Dot-com Bubble（互联网泡沫）前夕的1994年，比尔·盖茨的智能化豪宅完工，首次引入智能化设备与系统（其中包含智能照明、智能温控等系统），算是某种标志。而在五年后，微软发布智能家庭宣传片，构筑了一个设想中的智能家庭——远程开门、智能管理、扫描条型码购物等等，与现在的唯一区别是，一切入口是PC。</p><p>直到这一阶段，AI技术对家电行业的智能发展并未起到决定性作用。伴随无线通信技术与嵌入式系统的发展，尤其是无线传感器网络（WSN）的出现，使大规模设备连接变得更加便捷和实用，智能家居才正式步入新阶段。</p><p>与ChatGPT爆火卷起AI浪潮类似的是，2016年人工智能机器人AlphaGO战胜韩国职业围棋棋手李世石的社会新闻，成为深度学习概念出圈的背景事件。对应的，是随之而来的一轮AI浪潮。</p><p>率先被卷到的，正是家电行业。伴生的云计算和大数据技术，为智能家居提供了强大的支持，使得海量设备数据可以被采集、存储和分析，并实现精准的控制和决策。传统IOT设备也完成了向AIOT设备的进阶。</p><p>最具代表性的，是智能音箱的出现。通过智能音箱、智能网关等硬件设备，或是搭配语音交互，或是搭配手机App，初步实现「智能」体验。</p><p>从赛道玩家而言，目前国内智能家电市场参与者，主要有美的、海尔等传统家电企业，华为、小米等3C企业，以及阿里、百度等互联网企业和其他创新企业四类玩家构成。</p><p>在产品形态上，智能家居产品也开始从单品智能向全屋智能迈进。然而，由于不同类型玩家间平台、协议以及控制方式的不同，且互不打通，绝大多数消费者想要在家中配备完整全屋智能方案，除选用同厂商产品外，鲜有更好的办法。</p><p>从广义的智能家居出发，<strong>典型的家电AI路径分歧也同步出现。</strong>一方面，是单一家电产品的AI实现。已经提到的智能音箱、真正加载AI模块的扫地机器人、内嵌系统的智能冰箱等等，围绕家电产品功能性，从操控、响应、交互方式等维度的优化升级。</p><p>另一方面，则是全屋智能。在许多从业者视野中，互联网企业在其中的角色，并不光彩——「它们并不在乎你的家居是否真正智能，它们需要的只是你的家庭电器能够接入到互联网里而已。」</p><p>时常被吐槽为人工智障的部分智能家电，根本原因在于其并非传统家电的AI版本，更多是单纯作为智能手机等终端的延伸，响应式的被动服务，并无真正的「中枢大脑」能够做出决策。</p><p>当生成式AI涌现，其余行业或许面临着前路未知的焦虑与恐慌，但在家电行业技术从业者群体，却是「看见风暴激动如大海」。</p><p>它，会是补全智能家电的最后一块拼图吗？</p><h2><strong>机器伦理与智能未来</strong></h2><p>大语言模型的技术路径，是神经网络模型。而神经网络模型在信息学本质上就是一个函数（function）——接受输入、映射输出。</p><p>有别于编程语言「过程透明、逻辑严密、确定」等特质，大模型的映射充斥着「过程不可知、直觉性、模糊」的差异，甚至于被认为是基于人类直觉系统而建模的语义函数（semantic function）。</p><p>大模型应用的路径，可以粗浅理解为语义指令—大模型—推演结果。而大模型的强大之处，在于对几乎任意语义信息都可以一定程度合理地处理（姑且先不讨论幻觉问题）。</p><p>但问题在于，在「语义」层面的呼风唤雨，始终需要一个呈现的出口。无论是ChatBot的对话，还是产出图片、视频，抑或智能家电需求的人机交互。而人机交互的形式，也依旧值得商榷。</p><p>回到智能家电领域，共识性的发展路径，是从单品智能到场景智能再到全屋智能。曾有报告指出，当前中国全屋智能行业已发展至以用户为中心的主动智能阶段。这一阶段的智能家居基于个人数据分析、行为习惯理解和自主深度学习，以满足用户需求为核心，实现各智能产品的互联，并提供及时、个性化和智能化的全屋智能服务。</p><p><strong>从被动到主动的跨越，是大模型为家电领域打开的巨大可能性。</strong>但如何真正迈出这一步，却未有商业与技术上的绝对定论。</p><p>一个顺势的行业迷思是，大众需要什么样的智能家居体验？是类似哆啦A梦（育儿机器人）的专项服务伙伴？是全知全能掌控全屋的智慧管家，抑或变形金刚式可切换主动/被动服务的生活助手？</p><p>「这不仅是技术选型的取舍问题，更是智能安全与机器伦理问题。」美的集团首席AI官兼AI创新中心总经理唐剑对36氪表示。家电与AI之间的协同，需要确保人机交互的稳定、精准、可控；另外，如问答这类语音交互的形式，所输出的内容需要克服机器幻觉。</p><p>此前不久，美的对外官宣了自己的自研大模型「美言」，参数量在100亿级别，定位在家居垂直领域。公开资料显示，其主要应用场景，是家居领域的知识问答、可以支持上下文多轮对话的语音控制，及集合其余AI技术能够判断是否发起询问的主动服务。</p><p>「这是我们认为，当下大模型技术与家电最有可能性的三个落地场景」。唐剑为36氪简述了当下美的的技术路径。一方面是上述以小体量的自研垂直大模型，为用户提供家居领域的专业服务；另一方面则是基于各个大厂通用大模型，进行产品的二次开发。</p><p>如果按照参数级别，简单将语言模型区分为万亿级别的超大模型，和数百亿级别的普通大模型。那么，传统家电厂商，都纷纷落子在了更轻量级的普通大模型（或者说垂直大模型）上，应用场景主要在垂直领域的问答与人机交互维度，和部分主动式服务。部署场景也主要集中在各自全屋智能「大脑」中。对外表达的核心能力都包含关键词：迅速响应、主动服务。</p><p>选择轻量级的普通大模型，也是出于这些关键词的考量。唐剑代表的美的AI团队，有一个共识是，真正应用到场景，轻量级的垂直大模型更为实用——「包括响应速度快、更专业、更准确、也更可控。」</p><p>回到更具体的全屋智能领域，大模型显然正在为家电补上最后一块技术拼图。</p><p>美的集团中国区域全屋智能负责人尚喆博士曾在媒体采访中提到，实现真正的全屋智能需要三个核心技术：作为基础的感知技术，提升人机交互体验和准确性的大模型，以及链接机器对话的联网技术。</p><p>这也是美的今年发布全屋智能架构（即其官方介绍的1+3+4+N）背后的技术考量。据尚喆介绍，美的全屋智能的技术架构由1个智能中枢、3大超级终端、4大家电系统组成，通过前三者的技术组合，为用户提供N种情景。</p><p>其中，美言大模型作为智能中枢的能力底座，让「因人而异」与「智能」更为具象。正如前文所述，大模型在多轮语言分析与逻辑推演方面的能力，恰好挠到当下智能家电不够智能的痒处。美的本身追求的「人感」，结合伦理与法律边界的考量，使得大模型为代表的AI技术，能够为用户提供的服务，是基于环境感知、数据采集与用户习惯「推理」出的建议，而非直接实行的动作。</p><p>「在产品更新换代成为结构化升级主趋势的今天，家电产品的科技创新应该如何呈现给用户成为了一个行业性课题。美的给出了详尽的解析，那就是人感科技，即人对家电产品感受、感知是科技创新的核心尺度」，尚喆对36氪总结道。事实上，这也是家电领域的一个趋势——在技术发展的前提下，家电智能从简单的工具，向更具服务性质的「场景解决方案」前进。</p><p>大模型与家电的结合，看似一切都是陌生的。但至少在美的内部，有了两个共识：<strong>第一，大模型为全屋智能的实现提供了根本上的帮助；第二，是AI适应人的需求，而不是本末倒置。</strong></p><h2><strong>具身智能，人与机器共生</strong></h2><p>当然，生成式AI并不是终点。它更像是一个时代的前序，催生着更多技术的涌来，呼唤着通用人工智能（AGI）的正式实现。</p><p>多次为AI摇旗呐喊的英伟达创始人兼CEO黄仁勋，在此前喊出「Apple时代」之后，又在ITF World 2023 半导体大会上表示，AI下一个浪潮将是「具身智能（Embodied AI）」。</p><p>业内一个精确的表达是，具身的含义不是身体本身，而是与环境交互以及在环境中做事的整体需求和功能。</p><p>通俗来讲，现有的AI大模型，喂养的来源本质是人类整理、打过标签的数据，可以称之为非具身智能（Internet AI）。而具身智能则通过自我学习和进化，达到智能体理解世界，驱动本体互动交互并完成任务的目标——或者用大众更能理解的方式比喻，就是科幻电影中可能带来智械危机的智能机器人们。</p><p>就现实来看，大模型能力解决的一个核心难题，是人机交互的逻辑。在这部分能力逐步泛化的过程中，为具身方法和智能体提供了更多技术路径。</p><p>但对唐剑这类站在一线的从业者而言，想要达到能用、好用的具身智能，还会面对算法、工程技术、数据、场景和复杂软硬件等的诸多挑战。</p><p>这一点，谷歌、微软等互联网大厂的AI团队同样也在尝试，试图以大模型为机器人注入灵魂。比如上半年谷歌推出的多模态具身视觉语言模型（VLM）PaLM-E，以及微软尝试用ChatGPT能力实现语言直观控制机械臂、无人机、家庭辅助机器人等。</p><p>相较而言，家电领域对于具身智能有相对清晰的路径。如扫地机器人等非人形设备，在大众层面初步普及了概念。这是全屋智能之外，延续单品智能向着机器人化蜿蜒而上的另一条行业路径。</p><p>「两个技术路线不是背道而驰的，而是相辅相成的任督二脉。」作为人与机器共生的拥趸，唐剑无比坚信AI时代的到来。他曾在多次公开场合表态，认为家居家电行业的智能化路径，会经过被动服务、主动服务和机器人化三个阶段——全屋智能需要大模型赋能的「家居大脑」，能够完成物理世界与现实世界交互的机器人形态，则是「大脑」的最佳载体，「这样的未来，甚至可能在10年内就会真正到来。」</p><p>就现实环境来说，智能家电市场仍在开拓阶段。各类家电、家居系统与平台间充斥着壁垒，存在严重的行业割据现象。而具身智能机器人的真实落地，或许会成为「一统」行业的创新切口，或是智能生活时代真正到来的标志。</p><p>而这也意味着，家电厂商面临的AI冲击，或许不只是大语言模型的考验，而是更为多元的技术与落地应用挑战。</p><p>参考文献：</p><p>1.机器之心，《大模型的最大bug，回答正确率几乎为零》，2023.9</p><p>2.飞哥说AI，《大模型的下半场：多模态、Agent、ToPC/ToSMB商业模式》，2023.9</p><p>3.甲子光年，《稚晖君独家撰文：具身智能即将为通用机器人补全最后一块拼图》，2023.8</p><p>4.朱嘉明，横琴数链数字金融研究院学术与技术委员会主席，《人工智能大模型——当代历史的标志性事件及其意义》，香港中文大学《二十一世纪评论》2023.6</p><p>5.CSDN，《从AI大模型到 AGI 通用人工智能 “世界模型”的演进路径》，2023.6</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520316422252036</id>
            <title>自主品牌崛起，电动智能趋势催化，汽车零部件行业或打开增量空间</title>
            <link>https://www.36kr.com/p/2520316422252036</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520316422252036</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:52:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 汽车零部件板块, 广州车展, 新能源汽车, 中国汽车工业, 机器人延伸
<br>
<br>
总结: 中国汽车工业发展迅猛，新能源汽车增长强劲。随着自主品牌的崛起和汽车电动化、智能化趋势的发展，汽车零部件行业有望进一步打开增量空间。同时，向机器人延伸也有望实现再成长。 </div>
                        <hr>
                    
                    <p>11月15日，汽车零部件板块震荡走强，早盘跃岭股份（002725.SZ）率先封住涨停，午后威唐工业（300707.SZ）直线拉升至涨停。截至当日收盘，德赛西威（002920.SZ）、铭科精技（001319.SZ）、迪生力（603335.SH）等个股也收获涨停。</p><p>国信证券近日发布研报表示，2023年广州车展即将召开，理想MEGA、小鹏X9、问界M9等新车将亮相。长期来看，在自主崛起和电动智能趋势的推动下，汽车零部件行业有望打开增量空间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_43e4a1c04e9648aab8fe2c76b5f6dca2@5888275_oswg730143oswg791oswg528_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>01 我国汽车工业发展迅猛，新能源汽车增长强劲</strong></h2><p>目前，我国已发展成为全球第一大汽车产销国、第一大新能源智能网联汽车产销国，并有望成为第一大汽车出口国。</p><p>近年来，我国政府推出了一系列支持汽车制造业发展的政策和措施，不断加大技术研发的投入力度，提升汽车安全性能标准，加强产业链的合作和交流，为中国的汽车工业发展奠定坚实基础。</p><p>在此基础上，我国汽车工业发展迅猛，越来越多的汽车品牌将生产基地设在中国，生产的车型也越来越丰富。与此同时，我国新能源汽车的发展也遥遥领先，增长势头保持强劲。</p><blockquote><p>中国汽车工业协会数据显示，10月汽车产销分别完成289.1万辆和285.3万辆，同比分别增长11.2%和13.8%。汽车的产销量继9月后再创当月历史同期新高。2023年1月至10月，汽车产销分别完成2401.6万辆和2396.7万辆，同比分别增长8%和9.1%。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ae802097559648b38dc8a7f2fb6121ad@5888275_oswg86889oswg587oswg183_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>10月，新能源汽车产销分别完成98.9万辆和95.6万辆，同比分别增长29.2%和33.5%，市场占有率达到33.5%。2023年1月至10月，新能源汽车产销分别完成735.2万辆和728万辆，同比分别增长33.9%和37.8%，市场占有率达到30.4%。</p><p>根据中国汽车工业协会的预测，2023年全年汽车销量有望达到3000万辆，创历史新高。随着中国经济的逐步恢复，预计未来汽车市场的需求仍将保持稳定增长。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_78d1edb1687e414abefb18d399283e74@5888275_oswg85979oswg308oswg306_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>02 汽车零部件行业发展空间广阔</strong></h2><p>全球汽车产业的蓬勃发展，推动中国汽车零部件产业迈入高速发展的新阶段。随着数字化趋势的不断演进，市场对电子零部件的需求日益攀升。机构预计，到2028年中国汽车零部件行业的营收总额将超过4.8万亿元，未来的发展空间非常广阔。</p><p>值得一提的是，我国自主品牌近年来快速崛起，比亚迪、长城、吉利、奇瑞等品牌已经成为国际汽车市场的有力竞争者。这些公司不断加强研发和创新，大胆尝试新材料和新技术，为全球汽车市场注入了新的活力。</p><p>即将在11月17日开幕的2023广州国际车展，将为中国汽车产业提供一个展示自我的国际舞台。众多汽车品牌将携新车型亮相，比如理想MEGA、小鹏X9、问界M9、五菱星光、零跑C10等车型都受到广泛关注。</p><p>国信证券在研报中指出，今年多地陆续举办车展，以及汽车促销活动，新车型也不断发布。从中长期的角度来看，随着自主品牌的崛起，以及汽车电动化、智能化趋势的发展，汽车零部件行业有望进一步打开增量空间。</p><p>国泰君安分析师表示，汽车零部件的风口依旧在，后续该板块反复活跃的可能性很大。银河证券则认为，2023年乘用车销量有望创下历史新高，零部件厂商的营收将稳步回升。</p><h2><strong>03 向机器人延伸有望实现再成长</strong></h2><p>随着人工智能的发展，汽车零部件行业也有望受益。随着特斯拉人形机器人产业化提速，叠加国内人形机器人产业政策的催化，汽车零部件企业向机器人延伸有望实现再成长。</p><p>11月初，工信部印发《人形机器人创新发展指导意见》，聚焦3C、汽车等制造业重点领域，提升人形机器人工具操作与任务执行能力，打造人形机器人示范产线和工厂，在典型制造场景实现深度应用。</p><p>业内人士表示，该政策将推动机器人关键技术不断突破，加快拓展应用场景，国内人形机器人产业化商业化有望快速跟进，进一步打开成长空间。</p><p>与此同时，特斯拉人形机器人也不断取得突破。据马斯克透露，特斯拉人形机器人Optimus或将在11月进行行走测试，特斯拉机器人产业化不断加速，预计量产方案也将随之落地。</p><p>国泰君安分析称，短期市场交易的中心将向有潜力成为特斯拉机器人供应商的零部件企业轮动，汽车零部件企业向机器人延伸有望实现再成长。五洲新春（603667.SH）、富临精工（300432.SZ）、光洋股份（002708.SZ）等公司或将受益。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/y7wjCl7WnZyMu1sC_ii8Kg" rel="noopener noreferrer nofollow" target="_blank">“览富财经网”（ID:lanfucaijingwang）</a>，作者：扶摇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520298166888194</id>
            <title>MI300X发布在即，AMD能否弯道超车？</title>
            <link>https://www.36kr.com/p/2520298166888194</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520298166888194</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:52:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AMD, AI芯片, 英伟达, 销售增长
<br>
<br>
总结: AMD在财报电话会议上预测了未来几年的销售增长，特别是在人工智能领域。尽管有人对AMD的能力提出了质疑，但首席执行官通过对AI芯片的预测来消除了这些担忧。然而，与英伟达相比，AMD的销售增长目标相对保守。尽管如此，AMD仍然有机会通过提高人工智能芯片的销售额来实现更高的收入增长。 </div>
                        <hr>
                    
                    <p>很多传言称该芯片将被推迟，并质疑 AMD 有无能力推出能与英伟达竞争的芯片。在23 年第三季度的财报电话会议上，AMD 首席执行官苏姿丰似乎通过对 AI 芯片的可靠预测来消除人们的担忧。</p><p>市场最初对 Lisa Su 仅暗示 2024 年 AI 芯片收入将超过 20 亿美元感到失望。关键是，考虑到首席执行官表示业务将在全年不断增长，应重点关注声明中的“超出”部分。该公司为第四季度设定了 4 亿美元的季度目标，而金额只需达到 5 亿美元即可实现 20 亿美元的目标。2024 年年化收入率不会有太大增长，这不符合收入增长的条件。</p><blockquote><p>仅在第二财季，英伟达的 AI GPU 收入就已经增长了 6 亿美元以上。该芯片公司本季度的收入进一步增长，总销售额现已达到 160 亿美元，比两个季度前公布的 2024 年第一季度的 70 亿美元收入增长了 100% 以上。</p></blockquote><h2><strong>01</strong></h2><p>MI300X 加速器版本可能已经交付给客户，并且微软已经是 AI 芯片合作伙伴。AMD 表示该公司拥有多个超大规模客户，这引发了最大的问题：该公司是否能够封装足够的芯片来满足需求。</p><p>回到 10 月底的 23 年第三季度财报电话会议上，首席执行官苏姿丰 (Lisa Su) 已经说明了该公司将在几周而不是几个月内推出的关键 MI300X GPU 加速器。</p><blockquote><p>AMD 目前预测，在 PC 库存调整以及数据中心销售因转向人工智能而放缓之后，2023 年销售额将达到 227 亿美元。与 2022 年相比，今年的总销售额预计将略有下降。</p></blockquote><p>最大的问题是销售增长潜力，人工智能 GPU 芯片明年将贡献 2 亿美元以上的收入，而第四季度的收入仅为约 4 亿美元。AMD 预计 2023 年 GPU 销售额将增长 16 亿美元，在考虑到客户端领域 PC 销售额的增长和数据中心销售额的增长之前，销售额将达到 243 亿美元。</p><p>AMD 在 2024 年增长近 17%，达到 265 亿美元，看起来非常可行，但实际上低于 2024 年年初的预期。考虑到 AI GPU 的增长似乎仅受到芯片公司可以从台积电获得的 CoWoS 封装能力的限制，上行潜力可能为数十亿美元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_647774ebeb91402fa0546254dfdbd25f@5888275_oswg21516oswg635oswg517_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>02</strong></h2><p>普遍预测 AMD 到 2025 年销售额将再增长 16%，达到 307 亿美元。同样，在 2023 年末和 2024 年初的当前疲软时期导致美联储预计降息之后，对于必须保持强劲经济的经济来说，这一收入目标显得非常平庸。</p><p>考虑到英伟达 2025 财年（1 月）的收入目标自 2023 年开始达到 800 亿美元的巨额以来已飙升超过 300 亿美元，对于 AMD 来说，这个数字显得非常保守，因为人工智能芯片没有额外的增长。只要稍微提高 2025 年的目标，AMD 将生成以下财务模型：</p><ul><li>2025 年收入 = $320亿</li><li>毛利润 @ 56% = $179.2亿（22 年第 2 季度达到 54% 的峰值）</li><li>营业收入 = $105.6亿</li><li>税@ 13% = $13.7亿</li><li>EPS = $91.9亿/16.3亿 股 = $56.4亿。</li></ul><p>这个 2025 年模型假设人工智能芯片在 2025 年得到充分提升，以实现溢价，并且运营费用更符合长期财务目标。该模型的毛利率和运营费用均超过 PC 放缓影响财务之前的 2022 年峰值水平。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/EuLMab_nNH4FDJFJEDCY6A" rel="noopener noreferrer nofollow" target="_blank">“华尔街大事件”（ID:WallStreetNews）</a>，作者：<strong>Stone Fox Capital </strong>36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520294647145993</id>
            <title>北大全新“机械手”算法：辅助花式抓杯子，GTX 1650实现150fps推断</title>
            <link>https://www.36kr.com/p/2520294647145993</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520294647145993</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:48:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 扩散模型, 强化学习, 机械手, 抓取问题
<br>
<br>
总结: 北大董豪团队通过结合扩散模型和强化学习，将抓取问题分解为「如何抓」以及「何时抓」，使机械手能根据人手腕部的移动轨迹，自适应的抓取物体的不同部位，实现了灵巧的抓取。 </div>
                        <hr>
                    
                    <p>新方法结合扩散模型和强化学习，将抓取问题分解为「如何抓」以及「何时抓」，平价显卡即可实现实时交互。</p><p>手是人类与世界交互的重要部分，手的缺失（如上肢残障）会大大影响人类的正常生活。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_362658c67b4447919da673ed6499378e@5888275_oswg237589oswg756oswg231_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>北京大学董豪团队通过将扩散模型和强化学习结合，使机械手能根据人手腕部的移动轨迹，自适应的抓取物体的不同部位，满足人类多样化的抓取需求，目前该工作已被NeurIPS 2023接收。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_21c8aca7db234aeca3e4cedfd446efe4@5888275_oswg108860oswg691oswg309_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有了这个机械手，只要动动手腕，机械手就能按照人类想要的方式抓起物体，比如抓取杯身和杯壁。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_767118a348e645c7bd34aedc440876f4@5888275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b3d165f1f1a84f93b03955298c976e50@5888275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由于人类行为的复杂与多变性和真实世界物体的多样性，仅仅根据人手腕部的移动轨迹来不断预测人类想法是一件非常困难的事情。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8effd9555cc14c2aa199616cb87bd18f@5888275_oswg190446oswg1080oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>新方法真正实现了灵巧的抓取，能在真实世界中对于不同的物体，不同的抓取姿态，不同的抓取轨迹进行泛化。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6a1e4863686b429dbc64501961c35cb7@5888275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>01 机械手如何明白人类的想法？</strong></h2><p>北大董豪团队提出将人类的想法分解成两个部分：</p><p>1. 如何抓: 考虑到人类和物体当前的相对姿势，机械手应该如何抓取物体？</p><p>2. 何时抓: 机械手应该根据用户历史运动轨在何时、以什么速度执行抓取动作？</p><h3><strong>如何抓？</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c39e0d6de1074a0db4da4052efc74dd3@5888275_oswg87129oswg495oswg453_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>首先，如上图所示，新方法将学习人类想要「如何抓取物体」，定义为从一个包含各种抓取姿态的数据集中，学习抓取梯度场Grasping Gradient Field（GraspGF）。&nbsp;</p><p>基于当前人手腕部和物体的相对关系，GraspGF会输出一个梯度，这个梯度代表最快提高「抓取可能性」的方向。这个梯度可以转化为对每个手指关节的原始控制，使手指能够通过不断迭代达到适当的抓取姿态。&nbsp;</p><p>这样的梯度场可以随着人手腕部和物体的关系的变化，而不断的输出新的梯度指示当前人类的抓取意图，即意向抓取的物体区域及抓取姿态。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_13473fbdc8754f58b95a14f661e48425@5888275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">GraspGF随着手腕的旋转，不断调整抓取姿态&nbsp;</p><h3><strong>何时抓？</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_999639c7ccd843f8a14f9d8072ea9de9@5888275_oswg114676oswg865oswg210_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">GraspGF的动作会导致提前合拢&nbsp;</p><p>然而，只知道「如何抓」并不够完备，如果不知道要「何时抓」（如上图所示），虽然最终的抓取姿态是合理的，但是在达到抓取姿态的过程中会和物体发生碰撞。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e9047a463d6f4f9eb428fe2412887016@5888275_oswg223073oswg865oswg616_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如上所示，为了解决「何时抓取」的问题，新方法还训练了一个基于强化学习的残差策略，它首先会输出一个「缩放动作」，根据手腕轨迹的历史，决定手指关节应该以多快的速度沿着原始动作的方向移动。&nbsp;</p><p>此外，因为原始策略是基于最终抓取姿态数据集离线训练得到的，原始策略并不了解环境的物理约束 ，残差策略还会输出一个「残差动作」来进一步校正原始动作。&nbsp;</p><p>通过结合残差策略，模型能够通过残差策略学习到的「何时抓」更好地实现原始策略学习到的「如何抓」。&nbsp;</p><h3><strong>简单的奖励函数</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c0d98a74cb744f69a45c4859d4f45fec@5888275_oswg104697oswg865oswg226_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>该方法在奖励函数的设置上不需要过多的human design，因为原始动作已经提供了一个比较好的「如何抓」的引导，在训练强化学习模型时，除了给定成功抓取和抓取后的高度变化奖励，仅仅只需要一个奖励函数去鼓励机械手跟随原始动作即可。&nbsp;</p><h3><strong>该方法的优势</strong></h3><p>该方法仅需要成功抓取的抓取姿态数据集用于训练，与需要专家演示的方法相比，不需要大量的人工标注或者工程工作。&nbsp;</p><p>GraspGF借助了扩散模型强大的条件生成建模能力，这使它能够根据新颖的用户意图输出有效的原始动作。&nbsp;</p><p>残差学习的设计改善了强化学习探索效率低下的问题，提升了强化学习模型在未见过物体和轨迹上的泛化能力。&nbsp;</p><h2><strong>02 结果&nbsp;</strong></h2><p>最终在4900多个物体，200条不同的人类移动轨迹上，新方法都优于基准。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ed48f7ed9453438db1e17a1b00dff8f4@5888275_oswg154438oswg865oswg291_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>该方法的最终的抓取姿态相比于基线更符合人类的抓取意图。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_1e32ac191c844e26a769c4a8a755e8d8@5888275_oswg161419oswg865oswg301_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，该方法在抓取过程中对物体造成的扰动要小于其他基准。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_646a1d67e60241fe8fe5905dc8a07cf5@5888275_oswg221184oswg819oswg385_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>经过测试，该模型在GTX1650的显卡上，能达到150fps的推断速度，能做到与人类的实时交互，也许未来能真正用于辅助手部缺失的人更好地进行日常生活。&nbsp;</p><p>参考资料：&nbsp;</p><p>https://sites.google.com/view/graspgf&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/hpzZWMizR8tPSGIvGVjPoA" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520291088459270</id>
            <title>摒弃 Android，继华为之后，亚马逊被曝正在自研一款基于 Linux 的 OS</title>
            <link>https://www.36kr.com/p/2520291088459270</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520291088459270</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:48:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大型机时代, 小型机时代, 个人计算机时代, 移动互联网时代
<br>
<br>
总结: 亚马逊正在开发一款名为Vega的操作系统，旨在取代其设备上的Android系统。Vega是基于Linux风格开发的操作系统，主要应用于智能家居领域。亚马逊计划在所有新设备上完全摒弃Android系统，并已有数百位工程师致力于该操作系统的开发。这一举动也引发了对科技大厂自研操作系统意义的思考。 </div>
                        <hr>
                    
                    <p>正所谓大型机时代成就了 IBM，小型机时代成就了 DEC，个人计算机时代成就了微软和 Intel，移动互联网时代成就了谷歌、苹果和 ARM，当前的万物互联网时代谁能拔得头筹，各大公司都想试试看：</p><blockquote><p>前有华为发布&nbsp;HarmonyOS，宣布系统底座全栈自研，去掉了传统的 AOSP 代码，这意味着 HarmonyOS 将不再适配 Android 应用；后有小米澎湃 OS&nbsp;欲打造&nbsp;“人车家全生态” 操作系统；再有 vivo 自研蓝河操作系统 BlueOS，首发落地 vivo Watch3 场景......</p></blockquote><p>在国内大厂竞相布局之际，国外科技公司也不甘示弱。据外媒 The Verge 最新报道，亚马逊内部正在开发一款新的操作系统，内部代号为 Vega，基于 Linux 系统，现如今，还有人发现亚马逊悄悄地已经在自家的部分产品上直接用新系统取代了 Android。</p><h2><strong>01 早有计划，亚马逊正在放弃 Android</strong></h2><p>之所以研发这款操作系统，并非是亚马逊一时的心血来潮，而是早有计划。</p><p>其实在上周，来自&nbsp;Lpwpass 网站的记者&nbsp;Janko Roettgers&nbsp;便曾爆料，亚马逊早在 2017 年与芯片制作商的对话中就曾提出开发一款替代 Android 操作系统的想法。甚至在去年 9 月，一位亚马逊员工在匿名科技工作者论坛 Blind 上写道，「亚马逊正在打造一个面向所有设备和物联网的 iOS/Android 竞争对手」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_746b7f2b5b8f4fdc90e9b99cba5e585b@5888275_oswg73602oswg1080oswg309_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这款新操作系统代号为 Vega，是一款面向网络的操作系统，适用于智能家居设备等，这款操作系统主要会用来取代 Fire TV（亚马逊开发的一系列网络机顶盒和微型游戏机）、智能显示器和其他连接设备上的 Android 系统。</p><p>过去，亚马逊的设备包括 Fire TV 电视机顶盒、Echo Show 智能显示器以及 Fire 平板电脑都一直在使用名为 Fire OS 的 Android 分叉版本。</p><p>使用 Android 作为 Fire OS 的基础，有一个好处就是——第三方开发者可以将运行在 Android 手机、平板电脑和电视上的应用程序移植到亚马逊设备上，而无需从头开始重建。</p><p>不过，这样做也有不少的缺点，其中亚马逊一直依赖 Android 开源项目来构建 Fire OS，这导致该操作系统的开发速度经常落后于 Google 多年。</p><p>据悉，目前亚马逊的 Fire TV 机顶盒设备运行的还是基于 Android 9 的 Fire OS 7 系统。然而，另一边的 Google 已经在今年秋天发布了 Android 14 系统。事实上，Google 自己的流媒体硬件目前运行的是 Android 12 版本，其内部开发团队近一年开始在 Google 的 Android 电视设备上着手测试 Android 13。</p><p>在 Janko Roettgers&nbsp;看来，作为一款最早为手机开发的操作系统，Android 系统还背负着巨大的技术债务。从根本上说，它的许多代码对于运行许多现代智能家居设备来说都是不必要的。</p><p>这也是 Google 为什么从未在自己的智能显示器上使用 Android 系统的原因之一，起初谷歌使用的是基于 Linux 的解决方案，最近又改用了 Fuchsia 操作系统。</p><h2><strong>02 基于 Linux 的&nbsp;Vega，将主要应用在智能家居领域</strong></h2><p>根据爆料，亚马逊的新操作系统 Vega 是基于 Linux 风格开发的，其采用了一种更加面向网络的应用模式。</p><p>在技术维度，应用程序开发者被告知要使用 React Native 作为应用程序框架，它允许开发人员使用 Javascript 驱动的界面来构建原生应用程序。</p><p>除此之外，React Native 还允许开发人员在更广泛的设备和操作系统上构建应用程序，包括 iOS 和 Android 硬件以及一系列智能电视。这很可能使他们能够为较新的搭载 Vega 的设备和仍在运行 Android 的传统 Fire TV 硬件构建相同的应用程序。</p><p>Janko Roettgers 透露，亚马逊计划最终在其所有新设备上完全摒弃 Android 系统。Vega 不仅可以在 Fire TV 和智能显示器上运行，还可以在车载娱乐系统和其他未来的硬件产品上运行。</p><h2><strong>03 Vega 背后：数百位工程师</strong></h2><p>作为亚马逊设备操作系统小组的一部分，据悉，有数百人一直在致力于新操作系统的开发。</p><p>Janko Roettgers 表示，其中之一似乎是前 Mozilla 工程师和 Javascript 专家 Zibi Braniecki，他于 2022 年初加入亚马逊，从事 Alexa 工作。Braniecki 于 2023 年初过渡到设备操作系统团队，当时他在 LinkedIn 上宣布，他正在“为智能家居、汽车和其他亚马逊设备产品线开发下一代操作系统”。</p><p>同时，通过自己的消息来源以及亚马逊此前发布的招聘信息，Janko Roettgers 还发现，Vega 也将成为其汽车业务的关键。</p><p>截至目前，新操作系统（内部称为 Vega）的开发似乎相当先进，该系统已经在 Fire TV 流媒体适配器上进行了测试，Janko Roettgers 表示，亚马逊的大部分操作系统的开发已经完成，并补充说该公司“现在专注于 SDK 和增值”，以说服开发人员实际使用它。</p><p>不过，就在今天，有另一个媒体 Zatz Not Funny！发现，这款新的操作系统已经在最新的 Echo Show 5 智能音箱上使用，该设备上的操作系统显示为“OS 1.1”，而不是过往的 Fire 操作系统。</p><p>这一较低版本数字无疑也证明了亚马逊的确在开发一款全新的操作系统。</p><h2><strong>04 Android 已经成为全球第一大移动操作系统了，科技大厂自研 OS 的意义？</strong></h2><p>虽然亚马逊如今迈出了自研操作系统的第一步，但是在其设备已在全球销量超过 2 亿台的前提下，如何推动越来越多的流媒体应用程序的开发者针对这个全新的操作系统平台进行开发，必然是一大难题。</p><p>事实上，无论是亚马逊，还是文章伊始提及的华为、小米、vivo 等科技巨头，很多人依然不解为什么这些公司都迈入了操作系统自研的队伍？</p><p>实则以亚马逊为例，原因或有以下几个方面：</p><p>其一，如上文所提及的痛点问题，亚马逊从头开始研发，将摆脱对 Android 的依赖，可以按照自己的节奏保持软件的最新状态，而不是一直使用老旧的 Android 版本。</p><p>其二，有媒体评价道，有了 Vega，亚马逊可以避免了与 Google 的进一步冲突。此前，这两家公司一直为亚马逊使用 Android 系统的问题争吵不休，Google 曾一度向硬件制造商施压，要求他们不要制造搭载亚马逊系统的智能电视。后来，两家公司达成协议，允许亚马逊与海信和 TCL 等电视机制造商合作，但亚马逊放弃 Android 系统应该会让它更能掌控自己的命运。</p><p>其三，Janko Roettgers 透露，亚马逊想要开发 Vega 的主要原因之一是想要在各种廉价设备上吸引数以亿计的眼球，然后通过广告和服务来获得收入球，而内置定制操作系统可能正是实现这一目标的最佳途径。</p><p>其四，有人认为这是亚马逊为避免 Android 侧加载的一种手段。</p><p>对于越来越多的公司放弃 Android 的趋势，有网友评论道：</p><p>倘若嵌入式设备运行比 Android 更注重内存和性能的软件时，它们会更加闪耀。</p><p>万物互联时代，人人都想用一款新的操作系统革了 Android 的命！</p><p>先是华为，现在是亚马逊，下一个放弃 Android 的将会是谁？</p><p>参考：</p><p>https://www.theverge.com/2023/11/14/23954333/amazon-ditching-android-fire-tv-echo-show?showComments=1</p><p>https://www.lowpass.cc/p/amazon-vega-os-fire-tv-android</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/P34sfrHhe1br3eQQiWESFQ" rel="noopener noreferrer nofollow" target="_blank">“CSDN”（ID:CSDNnews）</a>，作者：CSDN，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520333721544451</id>
            <title>想在手机上本地跑AI？还是让子弹飞一会吧</title>
            <link>https://www.36kr.com/p/2520333721544451</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520333721544451</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:40:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Intel4004, 处理器演进, AI技术, 移动端AI计算
<br>
<br>
总结: 自1971年的Intel4004诞生以来，处理器经历了演进和变革，不断适应市场需求。现在，处理器已经步入了AI的新纪元，AI技术成为了科技界的主导主题。各大处理器品牌都开始布局AI产品线，包括桌面和移动端。移动端AI计算能力也在不断提升，对消费者来说，移动端本地化AI计算变得越来越重要。同时，参数量级也成为了处理器宣传的重点，代表了AI模型的规模和复杂度。 </div>
                        <hr>
                    
                    <p>"自1971年的 Intel4004——人类首款商用微处理器的诞生以来，这颗由硅材料打造的人类智慧的象征，已经历了超过半个世纪的风风雨雨。</p><p>在这个过程中，处理器的演进历程充满了激烈的品牌竞争和市场需求的不断变迁。不同的时代见证了处理器发展的不同趋势：有过追求 CPU 主频至极致的年代，有过对多核心架构探索无止境的时期，也有过对指令集进行深度优化和改革的时刻。</p><p>此外，随着智能手机、智能汽车的崛起，研发重心也从桌面计算转向了移动端。可以说，每一次处理器的重大升级和变革都是应时代需求而生的产物。这不仅是技术进步的必然结果，也是科技产业发展的生动注解。"</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c5f4d52120b74b2990080ab67273291e@5888275_oswg25596oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Intel 4004</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f2ce537770d549b4b39bbcab0f023d3a@5888275_oswg37782oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Intel i9-13900K</p><p>在2023年的科技领域，无论是桌面还是移动处理器，它们都已经开始步入了AI的新纪元。自OpenAI的ChatGPT引发了AI技术的爆发性增长后，AI已经成为了2023年全球科技界的主宰主题。位于科技漩涡中心的处理器市场自然也受到了这股风潮的影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e66ac8f3929a43419845be4b52e52af9@5888275_oswg27412oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><p>下半年以来，各大处理器品牌都开始着手布局AI产品线。NVIDIA以其无可匹敌的地位推出了H800和A800等专业AI计算加速卡。</p><p>而在消费级桌面端市场，Intel和 AMD 也不甘示弱，Intel计划在其第14代处理器Meteor Lake中首次集成AI加速引擎（NPU），而AMD在2023年发布的7040系列处理器中集成了AMD Ryzen AI引擎，这是一款专门用于神经网络AI运算的处理单元，最高可实现每秒十万亿次的AI运算。</p><p>在移动设备领域，高通和联发科也将AI计算能力作为其年度旗舰芯片的重点宣传对象。苹果的A17pro和M3也在持续优化其NPU架构和增加神经引擎的核心数量，以期在苹果未来的AI生态中发挥出更大的作用。这些新动态都预示着，AI技术不仅正在颠覆我们的生活，更在深度重塑全球的科技格局。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9d8e2d88e83542d08893bf62db3007a9@5888275_oswg117174oswg800oswg593_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">骁龙8Gen3官方宣传资料</p><p>当前AI在桌面端上的表现我们有目共睹，LLMs与SDXL为首的应用正在对多个行业产生着重要冲击，而移动端侧仿佛在2023Q4也开始了“春秋之战”。</p><p>那事实上，移动端侧的AI计算能力到底如何了呢？作为普通消费者是否对移动端本地化AI计算有所需求呢？</p><h2><strong>01 7B，10B，13B参数AI模型，这个B是个什么玩意？</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_4093de232b244d46943cd1d51602d715@5888275_oswg46011oswg800oswg427_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">AI生成-Midjourney</p><p>相信很多小伙伴都看到“高和联”两家旗舰芯片的宣发时都会注意到，他们都将成功运行XXB（多少亿）参数AI大语言模型的字眼作为营销重点。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_4343d75e505b4578aa5c9e7aa07ee433@5888275_oswg18274oswg800oswg240_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><p>那么这个B或者说参数量级是什么意思？在AI模型领域，"B" 通常代表 "billion"，也就是十亿，它指的是模型参数的数量。例如，"LLama-2-7B" 中的 "7B" 意味着这个模型有大约70亿个参数。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_84b3b916ea604644bffa2a8f3ebbb5c5@5888275_oswg45776oswg800oswg438_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Meta开发的LLama-2-7B模型，服务于移动设备或低功耗PC</p><p>参数数量是衡量模型复杂度的一个重要指标。一般来说，参数越多，模型的复杂度越高，对数据的拟合能力越强。简单说，这个数字很是关键，通常情况下，参数越多，模型的处理能力和理解复杂性越强，但也需要更多的计算资源。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_87991c9fc0744580afa0da95b4d9c2a9@5888275_oswg55108oswg800oswg436_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>丰富的模型参数数量如同给一位厨师以丰富的食材原料(AI生成-Midjourney)</p><h2><strong>02 那参数量是越大越好吗？</strong></h2><p>不见得，在某些情况下，特化的小模型可能在特定任务或场景上表现得比大模型更好。这是因为小模型可以更好地针对特定的任务进行优化，而大模型可能在尝试适应更广泛的任务时失去了一些特定性。</p><p>例如，假设我正在开发一款专注于美容美颜主题的AI大语言模型。我收集了所有关于美容养颜的网络资料，最终模型的参数量达到了30亿（3B）。尽管参数量较小，但模型能够更精确地针对特定任务进行优化，有效避免过拟合问题。同时，模型可以专注于与特定任务相关的特征，无需学习大型模型中的无关特征。相比之下，这种专注性使得小型模型在某些方面超越了参数量为30B或50B的通用大型模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_081a39e8499146dfb67934d21f65b599@5888275_oswg415187oswg800oswg441_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">AI生成-Midjourney</p><p>从某开源AI模型的测试成绩中，我们也可以看到这一点。在这次测试中，LLaMA2-13B模型的子项分数和平均分数均优于Aquila2-34B模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_74765141022c49dc903d37b8fca0d426@5888275_oswg95373oswg800oswg612_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><h2><strong>03 主流的AI大语言模型的参数量是多少？</strong></h2><p>以我们熟知的ChatGPT为例，其GPT-3.5版本（于2022年12月发布）拥有1750亿（175B）参数。而目前我们最常用、最熟悉的GPT-4在完整的120层模型中拥有18000亿（1800B）参数。另一个表现出色的模型，Claude 2，其参数量为1300亿（130B）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_32d12a9fd54a4bd9af9b06bfbf2cef15@5888275_oswg21834oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><p>在国产模型方面，尽管百度的文心一言没有公开其参数量，但根据我们的推算，其最新的4.0版本的参数量预计也已超过千亿，即1000亿（100B）以上。最近流行的国内大模型月之暗面（Moonshot）的参数量也超过了千亿。在部分小模型中，阿里云的通义千问开源版本达到了140亿（14B）参数量。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_78350cc091f146548e029b213dccea97@5888275_oswg91004oswg800oswg368_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于截图</p><h2><strong>04 移动端处理AI性能的能力</strong></h2><p>尽管MTK 9300和高通8gen3这两款旗舰芯片没有公开其实际运行模型的测试过程，我们仍可以从它们的声明中获取一些信息。MTK 9300强调，它可以在运行参数量为70亿（7B）的模型时实现20 tokens/s的性能。</p><p>需要注意的是，"tokens"这个词在这里的含义可能会有所不同，它可能指一个词、一个字符，或者在某些语言中的一个字母。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_970fcefa65ac4e04b42bb81e269a13ef@5888275_oswg31499oswg800oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">MTK 9300的官方宣传素材</p><p>在高通方面，他们声明其8gen3芯片在运行Meta开发的Llama 2模型时（Llama 2有7B、13B和70B版本，如果没有特别强调，那么一般指的是7B版本）可以达到15 tokens/s的性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_601c87a704a94251adb400910447e5fe@5888275_oswg46116oswg800oswg446_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">高通骁龙8Gen3官方宣传资料</p><p>根据一些经验来判断，在7B大小的模型中，二者的速度都已经够快了，可以较为流畅自然的速度来实现文字对话或者实时的语音识别与翻译。</p><h2><strong>05 移动端处理AI性能的性能巨大消耗</strong></h2><p>虽然移动设备如手机和平板电脑确实可以在本地运行AI模型，但由于这些设备更多地用于个人用途，运行AI模型时会调用一些特定的资源。首当其冲的便是神经处理单元（NPU），这是今年几款旗舰SoC芯片（如A17pro、8Gen3、9300、X Elite等）都在强调的部分。NPU是专门用于神经网络处理的处理器，拥有高效的矩阵乘法和卷积运算能力。在处理AI任务时，NPU主要用于执行模型的推理。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cbec47b39ace491cb2b19bedc4eb68fc@5888275_oswg65458oswg800oswg444_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">AI生成-Midjourney</p><p>此外，手机的中央处理单元（CPU）和图形处理单元（GPU）也会实时参与其中，负责执行模型的解码、预处理和后处理等任务。同时，手机的随机存取 内存 （RAM）也会被大量使用。对于熟悉AI模型的用户来说，无论是在PC本地的LLMS还是SDXL上，对内存和显存的占用都是相当大的。在移动设备上，RAM主要用于存储AI模型、数据和中间结果。在处理AI任务时，内存的带宽和容量是影响性能的重要因素。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8949f260101c4bcba8257ec2d1dcddcb@5888275_oswg48264oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><p>对用户实际使用影响最大的部分是大量的RAM消耗。在MTK 9300的官方发布中，联发科官方介绍说，一个拥有1300亿参数的AI大模型大约需要13GB的内存（在INT8精度下）才能运行。因此，即使是一个拥有70亿参数的模型，也大约需要7GB的内存。尽管存在一些技术，如INT4量化（通过降低计算精度以减少内存消耗），但是在完整调用运行一个7B的AI模型时，也需要至少4GB的内存消耗。这对于RAM资源本就非常宝贵的Android系统来说，无疑是雪上加霜。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7b0e36730f0a405d9d210b9e0b476017@5888275_oswg130920oswg743oswg656_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><p>可以想象，如果未来本地的AI模型普及开来，当前主流的8GB手机RAM肯定是不够用的。一旦打开AI程序，用户可能会面临其他应用被强制关闭，以及由于反复调用部分应用而导致的系统卡顿等问题。</p><h2><strong>06 AI 落地移动端？让子弹飞一会</strong></h2><p>不少小伙伴看到这里，都以为我在唱空移动端侧AI，但其实错了，其实我对于移动端AI应用是一个多头。毕竟手机是我们日常生活中最常用的智能设备，而且我们也看到，从OpenAI布局移动版的ChatGPT，到国内大模型纷纷转战移动端APP，再到手机厂商的“百模大战”，还有智能汽车领域的算力大辩论，都表明移动端的AI应用潜力巨大。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_80b05f7ae8444ef5bf6fd9e74f1e638d@5888275_oswg51436oswg800oswg445_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><p>而发展方向上，我认为移动端侧当前十分强调的本地LLMs（大语言模型）并不会是最终的发力方向，因为由于在精度的限制，本地LLMs的质量可能堪忧，即使可以输出较长的对话内容，但其逻辑性与合理性上都会与已知的PC端产品有较大的差距。</p><p>那么移动端该如何发展本的AI呢？我认为首当其冲的应该是图像识别与TTS（语音合成系统）。移动设备（涵盖手机与智能汽车）作为视觉与听觉传播的重要媒介，其能带来的远不止文字流的输出。</p><p>关于图像识别功能，随着手机摄像头技术的不断进步，图像识别在移动端的应用越来越广泛。例如，人脸识别、物体识别、场景识别等。未来，随着手机端AI算力的提升，图像识别的准确性和实时性将得到显著改善。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_30383dc64c7541578c5abb99a9ae550f@5888275_oswg28877oswg800oswg449_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">GPT长眼睛了，史诗级功能悄咪咪发布！</p><p>此外，随着智能汽车移动端AI计算能力的提升，图像识别技术在智能汽车中的应用将变得更加广泛和精准。例如，自动驾驶系统可以借助图像识别技术实时识别路况、标志牌、行人以及其他车辆，从而做出准确的驾驶决策。同时还可以衍生出图像识别可以用于识别车辆的周围环境，并提供相关的服务信息。例如，车辆可以通过图像识别来识别附近的餐厅、酒店等信息，并提供导航和预订等服务，催生新的业态。</p><p>另外一点就是语音合成（TTS）这也是本次OpenAI开发者大会中提及的重点内容，该技术结合AI，可以将文本转换为自然语音，广泛应用于智能助手、语音导航、语音阅读等场景。随着手机端AI算力的提升，TTS技术将更加成熟，生成的语音将更加自然、流畅。配合智能AI助理等功能来实现钢铁侠中“贾维斯”的科幻场景落实。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_872d50e60ae24fdf9004651c37fbe4ec@5888275_oswg50195oswg800oswg445_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><p>同时，移动端侧越来越强大的AI算力，还可以让V2V（车车互联）慢慢实现，通过AI和V2V技术，车辆可以共享路况信息，如拥堵情况、事故、路面状况等。这些信息可以帮助驾驶员或自动驾驶系统做出更好的导航决策，提高道路使用效率。甚至，可以自动与同目的地的车辆组成车队，AI可以控制一组车辆以固定的速度和距离行驶，从而提高燃油效率和道路容量。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_36b56513daee4a5a9648b689123e1f34@5888275_oswg77532oswg800oswg465_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><p>在对未来人工智能市场的展望中，可以明确地预见到，在日常民用领域，移动端将无疑占据主导地位。目前，移动设备在运行大规模AI模型时，的确面临着内存和计算资源的限制。然而，随着科技的持续进步，我们有理由相信这些挑战将会被逐步克服。</p><p>作为消费者，在面对如潮水般涌来的AI营销攻势时，我们需要保持清醒的判断力，同时也应对新兴技术抱有好奇心和期待。毕竟，自信息技术革命以来，很少有哪一项技术能引发如此广泛的关注，并激发全球科技巨头展开如此激烈的竞争。人类历史已经多次证明，只有竞争的时代才是科技进步最快的时代，才是人类文明的闪耀时刻。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_217256affed14b0cbad12c8ccc85b5f4@5888275_oswg52992oswg800oswg614_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片源自于互联网</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Nxv1zxRCbis5wJXoceQK7g" rel="noopener noreferrer nofollow" target="_blank">“PConline太平洋科技”（ID:pconline_cn）</a>，作者：PC，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520334049978115</id>
            <title>零售换帅、主营业务增速回落？京东Q3表现如何</title>
            <link>https://www.36kr.com/p/2520334049978115</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520334049978115</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:38:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 京东, 零售业务, CEO许冉, 服务收入
<br>
<br>
总结: 京东宣布CEO许冉兼任京东零售集团CEO，其零售业务微增0.1%。服务收入占比首次超过20%，强调供应链效率提升价值。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f4b1f2f753f8449e9e0ce27387fc334a@5888275_oswg102338oswg1024oswg766_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今日，京东宣布旗下零售子集团更换负责人，京东集团CEO许冉将兼任京东零售集团CEO，原京东零售集团CEO辛利军另有任用。</p><p>同日，京东公布了2023年第三季度财报，其收入为2477亿元，同比增长1.7%，在非美国通用会计准则下归母净利润为106亿元人民币。</p><p>具体到细分业务，三季度其零售业务的营收为2121亿元，同比增0.1%，而上一季度增速为5%；经营利润为110亿元，去年同期为109亿元。服务收入达到524亿元人民币，占整体收入的比例首次超过20%，达到21.2%，其中物流及其他服务收入的同比增长19.3%。</p><p>在业务方面，2023年京东全面推进低价策略，包括推出“百亿补贴”频道、单件到手价功能、买贵双倍赔服务、下调自营包邮门槛等一系列举措。同时，京东今年开始争夺第三方商家，让渡部分自营的流量和资源给商家。</p><h2><strong>01 零售业务微增0.1%，CEO许冉兼任京东零售CEO</strong></h2><p>自2022年年末刘强东“回归”后，京东开启了一系列的组织变革。而今日京东再次宣布旗下零售子集团更换负责人，CEO许冉将兼任京东零售集团CEO，原京东零售集团CEO辛利军另有任用。</p><p>相关资料显示，辛利军于2012年10月加入京东，历任京东零售生活服务事业群总裁、京东健康CEO。2021年9月，京东宣布组织架构调整，辛利军接替徐雷继任京东零售CEO。许冉则于2018年7月加入京东，并于2020年6月升任集团CFO。今年5月，京东集团CEO徐雷宣布退休，许冉接替他成为京东集团新任CEO。</p><p>从财报来看，京东三季度零售业务的营收与去年同期基本持平，<strong>仅微增0.1%</strong>，而上一季度增速为5%。不过，<strong>京东高管透露，在GMV数据表现上，目前京东的增速仍然高于国内零售行业平均增速。</strong></p><p>面对投资者反复关心的公司利润问题，许冉表示，京东不追求过高的利润率，而是零售商合理利润率，公司明年以及中长期增长目标没有改变。预计京东整体和零售业务将在2024年恢复正常增速，同时也可以实现高质量的业务增长。</p><p>针对今年电商零售行业的明显上升的竞争态势，许冉表示，竞争永远存在，“对于京东而言，不太关注竞争对手在做什么。<strong>”今年零售行业重视提升用户体验、低价，让市场感到竞争比较激烈。但从数据表现来看，京东利润率没有因行业竞争受到明显影响</strong>，平台用户体验的提升并不建立在牺牲公司合理利润率和股东的基础上。</p><p>值得关注的是，三季度整体商家数量同比保持三位数增长，尤其是商超、时尚、家居领域商家数量同比大幅增长。</p><p>对此，在财报发布后的电话会上，京东集团现任CEO许冉透露，平台生态是我们过去两三年以来长期投入的方向，我们也将继续深耕这一方向。消费者究竟是选择京东自营品牌还是第三方商家是自然选择的结果。</p><p>在经营数据上，低价策略和平台对第三方商家的倾斜也给京东带来了一些明显变化。<strong>2023年第三季度，京东商品收入较2022年同期減少0.9%，对应同期服务收入较2022年同期增加12.7%。</strong></p><p>同时，面对大量第三方商家的涌入，京东仍需要调整适应。据透露，京东内部针对第三方商家的工具建设、管理模式仍有较大提升空间，对第三方平台商家的变现不是平台短期的首要任务，只是近期随着大量商家的进入三方商家的广告收入保持双位数增长。</p><p>在电话会议上，京东高管透露，<strong>随着平台生态的逐步完善，长期来看，我们预期第三方上级订单占比将超过自营，目前转变需要一个过程。但越来越多三方商家的加入，可以给用户提供更好的消费体验、更多元化的产品和更优势的价格。</strong></p><p>此外，京东还在发力线下市场。京东MALL、京东之家等超过50家线下门店在宁波、上海等地开业。京东3C数码门店在三季度累计推动47家京东之家、京东电脑数码新店开业，覆盖北上广深等城市。</p><h2><strong>02 服务收入占比首超20%，强调供应链效率提升价值</strong></h2><blockquote><p>财报显示，三季度京东集团的服务收入达到524亿元人民币，占整体收入的比例首次超过20%，达到21.2%，其中物流及其他服务收入的同比增长19.3%。</p></blockquote><p>截至三季度末，<strong>京东的供应链基础设施资产规模同比增长17%，达到1486亿元。</strong>京东物流运营超过1600个仓库，包含云仓生态平台的管理面积在内，京东物流仓储网络总管理面积超过3200万平方米。</p><p>另一方面，京东物流提供的出海一体化供应链业务也取得明显增长。目前，京东物流已逐步扩大同一家以女装为主的海外电商平台合作的国家范围，覆盖北美洲和欧洲诸多国家，进一步助力其全球业务拓展。</p><p>据规划，京东物流未来3年将建设覆盖全球主要国家的供应链物流网络，构建包括海外仓网、国际转运枢纽、海外国家本土的运配网络及跨国干线运输网络于一体的全球供应链网络。</p><p>单就第三季度来看，京东物流总收入为416.6亿元，同比增长16.5%；归属于公司所有者的利润2.1亿元，上年同期亏损2亿元；经调整后净利润为8.4亿元，同比增长89%，达到上市以来同期最好盈利水平。</p><p>其中，外部客户收入达到298亿元，占比提升至72%。具体业务方面，三季度京东物流包含快递、快运等在内的其他客户收入同比增长25.7%，达到221亿元。</p><p>京东物流已在全国运营仓库可以根据各类商品的销售及周转特点，在不同区域内进行合理分配，帮助客户优化存货布局，提升存货周转，并实现高效履约。同时，京东物流还管理着超千万种sku商品，在支撑自营业务单量提升的基础上，持续降低库存周转天数。</p><p>关于供应链效率，京东多名高管也在电话会中多次强调了其价值。公司的目标在于通过效率提升所带来的额外利润空间与合作伙伴分享，并将多余的利润用于持续提升用户体验。<strong>“长期来看，京东利润的改善还是来自于供应链的提升和平台生态的逐步完善。”</strong></p><p>关于未来发展战略上，京东高管在电话会上强调，零售业务仍然是京东的核心业务，整体零售战略在方向上不会有大的变化。</p><p>此外，在达达集团负责的京东到家高峰日的交易额也达到历史最高，促销期间的交易额也得到了强劲增长，多个类别包括酒类、母婴用品、家居用品和便利店出现了三位数的增长。带动达达高峰日的订单履行量再次达到了创纪录的1500万，促销期间的总订单履行量达到了2亿。</p><p>在2023年三季度，达达集团总营收为29亿元人民币，较去年同期增长20%，经调整净利润率同比提升11个百分点，盈利能力同比显著优化。</p><p>不过据京东高管透露，<strong>目前京东商超品类的增速比上半年有所改善，2022年京东生鲜业务受到疫情配送需求利好有较高的增长，预计明年该部分业务增长将回到更加健康的增长势头上。“长期来看，我们坚信商超品类仍然是京东最重要的增长驱动力。”</strong></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/b6-mohQHBCeKWVkIJXd94Q" rel="noopener noreferrer nofollow" target="_blank">“新消费日报”（ID:cls-xxfribao-01）</a>，作者：黄心怡&nbsp;梁又匀，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520343449511689</id>
            <title>“我们去县城募了40亿”</title>
            <link>https://www.36kr.com/p/2520343449511689</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520343449511689</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:38:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 长丰县, GDP增速, 合肥基地项目, 百亿母基金
<br>
<br>
总结: 长丰县是今年GDP增速最高的县城之一，其经济增速的暴涨与承接合肥主城区的产业外溢有关。比亚迪、中创新航和优信汽车等合肥基地项目的设立，以及百亿母基金的签约，进一步推动了长丰县的发展。长丰县通过依托合肥的科技与资本优势，培育新产业，取得了显著成效。 </div>
                        <hr>
                    
                    <p>长丰县——一个可能许多人都没有听说过的地方，却是今年GDP增速最高的县城之一。</p><blockquote><p>它是合肥市下辖县城，位于合肥主城区以北，与淮南市相连。根据官方发布的数据，2023年前三季度GDP总量633.5亿元，名义增长率18.5%。</p></blockquote><p>经济增速的暴涨，与承接合肥主城区的产业外溢有关——比亚迪、中创新航和优信汽车的合肥基地项目，都设立在此。</p><p>早在2001年，长丰县就制定了“与市俱进”的发展方向，简言之，就是当好合肥的配角，依托合肥的科技与资本优势，培育新产业。</p><p>这一战略在最近几年“合肥模式”的加持下，取得了显著成效。一个在2012年才摘掉国家级贫困县帽子的县城，现在已经是全国百强县之一。</p><p>上周，长丰县百亿母基金新签了三支子基金——安徽国控慕华股权投资基金、安徽国控基石混改升级产业基金和安徽省诺延北城股权投资基金。分别对应着慕华创投、基石资本、诺延资本三家GP。总规模高达43.5亿元，主要投向当下热门的新能源汽车、新材料、人工智能、先进制造等赛道。</p><p>一口气落地3支基金，且总规模40多亿，非一般区县所能比拟。三支子基金的管理机构既包括了早期机构，也包含了知名PE，既有综合性的大白马，也有垂直赛道的黑马。合肥创投市场的成熟度，也可从此处观之。</p><p>今年3月，长丰县百亿母基金签约了北城华富基金、北城信息技术基金、合肥国家科学中心种子基金和北城科创基金4支子基金，今年6月又签约了国控基石混改基金、慕华基金、创新成长二期基金和华颖汇成基金四支子基金。再加上这次新披露的安徽省诺延北城股权投资基金。一共已经披露遴选了9支子基金。</p><p>身在2023年，GP端命题明确，募资；政府端命题也明确，招商；但两项需求如何嵌套、结合才是问题之本。<strong>本文从9只基金里随机选两家GP来分析，希望能一窥当下GP和政府携手的秘密。</strong></p><h2><strong>01 600亿AUM的基石，去长丰县搞混改？</strong></h2><p>“你可以把基石看成半个安徽机构”，这是一位深圳投资同行，对基石资本的评价，“张维是安徽人，在老家很吃得开”。他说的没错，地域认同，是中国人信任纽带里很重要的一环，也是基石来安徽的先决条件，网上也有盘点马鞍山富人的帖子，张维位列其内，马鞍山前几年遭洪灾，张维还捐了钱。</p><p>但是，地域认同也不是充分条件，一家GP想深度、长期合作一个地方政府哪儿那么容易？更何况在各个地市县都能吃得开？</p><p>基石2012-2013年前后就来安徽了，当时芜湖、合肥都有落地。我是想说，基石去安徽，是个独立的过程，远在资管新规之前，就在铺地方政府合作这条路了，不好说张维一定多前瞻，但占了先机是一定的，不服不行。2017年基石投了劲旅环境，这是家标准的本地公司，企业前身是合肥劲旅环卫设备有限公司，其现任董事长于晓霞，以前则供职于合肥市通用铸造厂。</p><p>劲旅环境IPO挂牌时，陪同挂牌的就有基石安徽总经理王勇。我前阵子去深圳基石拜访过，但这位王先生我不认识，显而易见，他在安徽很活跃，关于长丰县，还能看到另一条信息，2020年9月中旬，陪蓝色星际副总经理去吴山镇考察的也是王勇，接待的是副镇长。</p><p>蓝色星际是什么公司？总部北京，主营安防，三板挂牌，2017年，基石资本就和国泰君安创投联合向这家公司增资1.17亿元。</p><h3><strong>关于蓝色星际有几个看点：</strong></h3><p>一是基石资本早在三年前，就在安徽帮政府并且是县级政府做招商执行了，你说和直到2023年为了募资才正式落场招商的GP来说，基石早走了不止一步棋；</p><p>第二是执行，招商多卷啊，一家县级政府，如果现在去北上广深这种城市招商，能有多少竞争力？操作链条又要有多长？但三年前，基石就能从portfolio里直接介绍企业过来，效果不说了，各位可以查，看蓝色星际有没有开安徽分公司。</p><p>总结一下，基石此次落地长丰县，大面上我们有这几个结论：第一是乡里乡亲的信任；第二去得早；第三执行力强，做了实事儿。</p><h3><strong>具体再看，为啥基石此次落地的是混改基金？</strong></h3><p>从政府这边看，长丰县去年底就签了20个项目落地的协议，总规模120亿，这是瞄着“新能源汽车之都”的合肥通盘战略去的。而在发布“百亿母基金”以后，提出的聚焦领域包括新一代信息技术、高端装备、集成电路、新能源、新材料；而阶段呢？打的还是“通盘”的算盘，原话是这么说的：</p><p>在设立“投早，投小，投科技”天使期、种子期子基金的同时，积极布局专注投向战略性新兴产业和混合所有制经济的成长期基金，覆盖企业从初创到成长的全生命周期阶段，推动产业龙头企业落户长丰县。</p><p>所以这就清楚了，对于AUM早就达到600多亿的基石来说，跑去县级政府那边搞天使？不现实，而双方需求正好对上的部分，恰恰是“混改”。</p><p>基石搞不搞得了混改？答案是肯定的，张维以前讲过一个混改的故事：</p><p>早在2011年底，基石投资了一家化工国企，持有六分之一股份，通过改技术路线、改工艺，企业产量增长266倍，收入从0到9亿，净利盈利4亿。按当时同类企业PE估值，能估到小200亿；但此时地方政府突然提出将这家企业送给某知名新能源车企，目的当然是招商，这就给基石搅局了，最后政府礼没送成，基石也没搞成IPO，于是卖了老股，赚了点小钱（相对小）。</p><p>这故事证明了两点：第一，基石搞得了混改，有成功案例；第二，混改搞好了，真的能挣钱，前提是跟政府利益目标一致；</p><p>基石搞混改案例很多，失败也多，或者咱不提“失败”，说“遗憾”很多。那如今要在长丰县搞混改基金，当然应该选“遗憾经验”丰富的基石。</p><p>能否实现利益目标协同？想必这次也从容得多。看看基石投资长鑫存储的出手就知道了：12亿——你什么时候见过深圳人民币机构的这种投法？张维也说，12亿算是基石目前的能力边界了。</p><p>所以，最大的押注，最有信心的大钱，正是放在长鑫存储，这个合肥重大项目上。证明了基石和合肥的信任至深，互动之良好，而落在长丰县的这笔募资，可不顺理成章么。</p><h2><strong>02 清华系黑马，落子合肥</strong></h2><p>相较来看，另一家慕华科创显得脸儿生，为啥双方此时达成了合作？梳理一下信息，也能看到不少线索。</p><p>先看看慕华科创的宣传文案：</p><p>清华大学资产管理有限公司的一级全资子公司慕华集团发起设立的创新科技投资平台；重点关注新能源车、半导体、人工智能、企业SaaS服务、教育科技等行业；管理团队来自清华大学和中金公司；注重投后服务，慕华科创与多地政府建立了良好合作关系。帮助被投企业在苏州、南通、南京、合肥、广州、成都、重庆、郑州等地进行落地；定期举办内部交流会和专题培训，促成被投企业间业务合作，主动挖掘被投企业与清华科技成果转化企业的协同潜力，进行对接。</p><p>仔细理一理，画像有了：</p><p>第一，清华旗下GP；</p><p>第二，以前投教育，如今搞科技；</p><p>第三，团队金融和院校的根基都有；</p><p>第四，招商经验丰富，还有清华科技成果转化资源。</p><p><strong>慕华还有个特点，团队小。</strong>按照官网信息，连后台团队，满打满算挂出来七份履历，履历中的关键词包括清华、中金、中信、证监会等，换句话说，有清华资源，懂投资，还懂资本市场。可以说能力比较互补，但毕竟人少，能力边界有限，这类小团队的通常特点是：有服务意识，能当节点，善用资源，寻求杠杆。</p><p>此前慕华创始合伙人张妤在一次直播里谈过这个问题，能给背书的核心资源有二：第一，智囊团，导师包括人工智能界的泰斗张钹院士。第二，科技成果转化上，有专家及清华校友帮助。</p><p>要和地方政府合作，招商拼的是什么？拼的是路径。对比基石看，如果你没有那么高的基金规模，那么多的portfolio企业，那么就要有能触达科技企业的最有效的抓手，而这里的顶级专家，顶级院校科技转化，就是最好的路径。</p><p>再具体一点，慕华和合肥，和长丰县的合作节点又是什么？如果说基石的关键词是混改，那么慕华的关键词就是车。</p><p>慕华早先可以说是一家教育投资机构，是清华控股当年布局在线教育的战略举措，翻翻过往投资案例，投过网易有道，也投过少年得到。但从2021年开始，这家机构的投向明确转向科技，或者准确地说，转向新能源车，最先出手投向的是小哈换电和哪吒汽车，还有做软件的镁佳科技，做芯片的地平线，做自动驾驶的DeepWay等。</p><p>慕华这支基金，除了签了长丰县，还拿了安徽省混改基金，芜湖两个平台、网易有道等几家诉求不一而同的LP的钱，但这些诉求，都可以用“车”串起来。所以你能看得出，一家机构的业务转向，有一条明确的、高权重的线索是如此之重要。也正是转型时及时抓住了“车”这条当下最热、最重要的条线，当你再遇到旨在打造“省域副中心”的芜湖，以及遇到合肥在“创投城市计划”继续落子智能网联汽车时，再次牢牢抓住机会。</p><h2><strong>03 合肥模式，创投圈流动的盛宴</strong></h2><p>聊了GP，重点再看LP。</p><p>长丰县原是一个名不见经传的小城。在被外界熟知前，它用了10年时间（2001-2012）才摘掉了国家级贫困县的帽子。之后，又用了4年时间（2012-2016）跻身全国百强县。2022年，比亚迪合肥项目在长丰开工时，其GDP总量冲到了安徽所有区县的第六位。今年前三个季度，长丰县的经济增长率18.5%，这个数据放在全国都屈指可数。</p><p><strong>长丰崛起的故事，仿佛是合肥故事的翻版</strong>——合肥承接长三角的产业与人才，长丰承接合肥的产业外溢；合肥招引上市公司扩产项目，长丰如法炮制来做大产值，聚集产业链。长丰的领导说要“与市俱进”，是市场的“市”，更是合肥市的“市”。做主城的配角经济，长丰也站到了台前。</p><p>既然都站到了台前，那为何不再往舞台中央靠一靠？于是，<strong>长丰县设立了百亿产业引导母基金，这是安徽第一支县级百亿母基金。</strong></p><p>这支母基金的发起单位是合肥北城资本。它成立于2017年，股权向上穿刺，由长丰县财政局全资控股。目前北城资本参与发起设立的基金共28支，基金总规模超400亿元，投资金额超100亿元。除了做LP外也做直投，今年7月，阿里巴巴领投了AR眼镜初创公司“致敬未知”天使轮融资，跟投方里就有北城资本的身影。</p><p>从过往的出资和投资历史来看，北城资本不是为招引上市公司扩产项目或者重大产业项目而设立的，而是具有明显的科创属性。细节处可见一斑：今年3月举行的长丰母基金发布会，是由合肥市科技局、长丰县人民政府、中科大国际金融研究院、中科学大科技商学院联合主办——“科创”与“院校”含量最多。</p><p>这一点也体现在当天签约的子基金中，除了三支北城系的机构外，还出资了合肥国家科学中心种子基金，与投资慕华创投，链接院校资源的逻辑如出一辙。</p><p>百亿母基金的设立，标志着长丰县从产业投资向科创投资延伸，也同样意味着合肥模式进入2.0版本。</p><p>合肥将2.0版本称为“创投城市计划”，相关文件和报道很长，梳理下来有三点值得强调：</p><p><strong>其一，母基金层级分明，体量庞大。</strong>“安徽省级母基金+合肥市级母基金+区县级母基金”，层层分明，且形成了母基金群，规模庞大。</p><p><strong>其二，形成全生命周期的基金矩阵。</strong>种子基金、天使基金、产业基金、创投引导基金、科创基金，覆盖企业全生命周期。超越了过去重产投轻科创的局面。</p><p><strong>其三，容错机制更为合理。</strong>合肥天使基金、种子基金风险容忍度分别提升至40%、50%，成为全国天使基金、种子基金风险容忍度最高的城市之一。</p><p>以上三点，说明不论是投资体量、投资能力、还是手上的投资工具，合肥的国资机构都已经提升了一个档次。它拥有更合理的机制，去做投资回报周期更长、风险更高的早期科创项目；也拥有足够的“原始积累”去做许多看上去并不赚钱的“投后服务”。</p><p>这里涉及到了一个关键问题——“边界”。正如我们在上文所述基石资本也有投资边界一样，合肥模式从1.0到2.0，核心也是一个拓展能力边界的问题。</p><p>只不过这里的“边界”显得更为宽泛。它的界定，从根本上讲取决于当地经济发展状况与财政状况。这决定了国资机构可以“如何参与投资”，又可以“参与到何种程度”。</p><p>在合肥模式1.0的时代，我们就可以看到合肥国资能力边界的拓展轨迹。</p><p>2008年投资京东方，合肥财政预算收入301亿元，归属地方仅161亿元。如何在此基础上，投建一条投资175亿元的6代线？在相关的叙事中，地方领导人的魄力和勇气是重点描述的对象。风险、“赌城”和不得已而为之的“保大舍小”（舍弃地铁建设计划），都是见诸报端的故事。</p><p>而到2020年引进蔚来汽车时，情况就变了。当年合肥一般公共预算收入762.9亿元。投资蔚来就显得从容多了。</p><p>在相关故事中，写了合肥“兵分四路”研判项目：除了与企业进行详细、周密的谈判，并签订了带有“对赌”性质的协议外，还积极对接专业投资机构，全方位研判蔚来技术、供应链和市场情况；高度关注国家政策对引进项目的支持情况；委托专业法务和财务机构等对企业进行全面的尽职调查。</p><p>从这些描述中就可以看出，合肥国资机构的投资能力被着重强调。以至于市委书记出来喊话：我们不是风投是产投，不是赌博是拼搏。</p><p>其实合肥还佐证了一点，地方政府招投的成长路径，应该和市场化机构正相反：先求效率，在慢慢把效率降下来——没错，降效率，讲投后，做服务，才有机会扩大盘子。</p><p>甚至可以从财务投资开始做，搭建链条，建立洞察，扩张边界。如果说一开始通过定增投资京东方的动作还像个财务投资者，那么到后来引进蔚来，就是在执行标准的产业投资策略。</p><p>如今合肥已经被视为“城市投行”了，从创投，做到产投，再做到投行，从投资的角度，效率在降低，但从产业招引的角度，这条路才是进境。</p><p>其实，究竟是风投、产投，还是赌博、拼搏，定义不重要，概念不重要，边界最重要。投资行为的属性是沿着合肥能力边界的移动而定义的。</p><p>而到了当下，合肥的经济发展状况已经今非昔比。2022年GDP增长至1.2万亿。2022年，合肥全市一般公共预算收入完成909.3亿元，按自然口径计算增长7.7%。</p><p>如果经济数据显得过于抽象，那么反映在企业端就鲜活了：在合肥，平均每天诞生5家国家高新技术企业。截至2022年国家高新技术企业总数达到6412家，国家科技型中小企业8200余家，国家专精特新小巨人139家。</p><p>拥有如何庞大的科创企业群体，且处于不同发展阶段，他们的经营模式、团队、技术、市场都不一样，所面对的风险也迥异。怎么可能再按照传统产投的逻辑进行服务和投资呢？合肥模式必然面临一次大的迭代。</p><p>所以，所谓合肥模式的2.0版本，其实是合肥国资机构能力边界的持续扩展。它并非一个静态的模板，而是“国有资本与社会资本”“政府能力与市场机制”两组关系不断调试的一个过程。从动态的角度观察，合肥无疑是当下创投圈的一场“流动的盛宴”了。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkwMjUxNTkwNQ==&amp;mid=2247587323&amp;idx=1&amp;sn=8f24eefa16dac302f905baa804be5b8d&amp;chksm=c0a78855f7d0014309062276b6242c32f455c42ee859d366078387d7daf8927c2f278f49c52e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投中网”（ID：China-Venture）</a>，作者：杨博宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520280658337925</id>
            <title>社交巨头布局AIGC，有何“新玩法”？</title>
            <link>https://www.36kr.com/p/2520280658337925</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520280658337925</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:38:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 社交江湖, AIGC, 大模型, 新玩法
<br>
<br>
总结: 社交APP正面临AIGC重构升级的挑战和机遇。通过引入大模型和新玩法，社交巨头们在表达方式、交互方式和交互对象方面进行创新，以提升用户体验和商业价值。然而，社交平台也需要面对AIGC内容风险和用户对隐私和数据安全的担忧，需要加强监管和保护措施，同时反映自身的价值观在产品和商业模式设计上。 </div>
                        <hr>
                    
                    <p>社交江湖不缺新故事。不管是科技新贵，还是互联网大佬，总能凭借新玩法展露社交野心。前赴后继的挑战者中，搜狐掌舵人张朝阳是颇具话题的一个。</p><p>他的两次出圈，像可以窥见社交赛道变迁的放大镜。2019年乌镇峰会上，张朝阳带着狐友APP回归社交，聚焦年轻人群。同年，阿里、京东、百度等新老玩家齐入局，数十款社交产品频现，却较少出现“爆款”。2023年，新变量AIGC成为乌镇峰会上的热词，张朝阳却发出“十年内不能低估，两年内不能高估”的论断。</p><p>期待与审视的现实一面，是社交APP正被AIGC重构升级。围绕表达方式、交互方式、交互对象的迭代，社交巨头们展开了不同的AIGC叙事与商业逻辑。值此节点，我们或能通过对比得以一窥其中的同与异、快与慢、新与奇。</p><h2><strong>01 从卷大模型到拼新玩法</strong></h2><p>各行业共识是，大模型将开启一个繁荣的AI原生应用生态。但在社交领域，大模型的“卷”与进展披露似乎呈现两面。</p><p>过去几个月，腾讯、知乎分别推出混元大模型和知海图AI大模型，快手发布快意大语言模型和可图文生图大模型。Soul披露自研垂类模型，已引入多模态大模型。一些平台则略显低调。比如，6月字节跳动对外公布大模型服务平台“火山方舟”，但对自研通用大模型甚少披露；小红书、B站等大模型进展亦未过多公开。</p><p>相比大模型技术，用户更关注应用新变化、新玩法。优实资本董事长邢杰认为，变化之一基于内容创作，AIGC带来生产效率、便利性的极大提升和生产门槛的降低，会使得社交媒体、平台上的创新内容极度丰富。变化之二基于交互方式、交互对象，交互质量提升之外，AI机器人、AI伴侣或AI角色应用会迎来繁荣，虚拟角色和AI机器人的对话会更智能、流畅、个性，富有逻辑甚至情感温度。</p><p>梳理可见，表达、信息交换等方式更新已推动产品变化。目前，Soul推出“AI绘画”、“Soul次元歌手”和聊天机器人“AI苟蛋”；快手在短视频评论区提供互动问答、图片生成等服务；小红书上线“Trik ”主打AI绘画；字节跳动对外测试AI对话产品豆包；百合佳缘、腾讯音乐等平台探索情感倾诉、AI一起听等新玩法。</p><p>比较发现，其中AI苟蛋已体现出在多元场景下的较强交互能力及在拟人、知识、多模态、时间感知等方面的融合能力。据了解，目前AI苟蛋能与用户进行多轮个性化沟通，并结合发帖、互动等多项行为对用户进行个性化主动关怀，对图片、文本、游戏互动等多种形态都能轻松回复。</p><h2><strong>02 商业增长点背后</strong></h2><p>社交巨头加码AIGC背后有着各自的商业考量。根据艾瑞咨询数据，2030年我国AIGC产业规模有望突破万亿元，达到11441亿元，社交是AIGC最佳落地场景之一。用户在这个过程中的价值实现不仅包括情感陪伴，还有自我价值变现。</p><p>“微信等巨头目前仍占据主导地位，它们面临新兴平台的挑战。”在中国移动通信联合会元宇宙产业委联席秘书长叶毓睿看来，后者通过新奇、有趣的多维感官体验，更具代入感的互动娱乐，以及基于三权分置的信任和协作机制，可能会逐渐削弱这些巨头的市场份额。</p><p>邢杰则认为，现有平台的定位、商业模型、竞争格局已相当稳定。在AI加持下，现有的商业模式、市场份额不会有大变化。“短期一两年内，基于AI伴侣、AI角色这类特点的新社交平台会引起一定的市场冲击，但不会完全颠覆现有格局。”</p><p>他分析，新能力对应新价值，AI会给各平台带来商业模式的新增长点。此时不同社交平台比拼的核心竞争力，其实是对社交的理解和定位的差异。比如，微信的社交核心是真实，Soul这类面向年轻人的平台不能太真实，这是Soul和微信的最本质差别。另一不同是Soul提供熟人以外的陌生人社交，在AI加持下这种社交匹配的精准度、效率、普惠程度会更好，这两个平台可以继续沿着核心点去强化。</p><p>具体而言，微信可以通过AIGC，让用户在朋友圈、微信群、公众号上的创作力和想象力得到更大释放；后期可能会增加AI机器人功能来更好地管理内容和社交。Soul在兴趣匹配，尤其是AI虚拟数字人的性格塑造、情绪抚慰、个人AI情绪伴侣方面有很大空间。</p><p>Soul App CTO 陶明也透露，2022年，Soul平台的增值服务收入在总收入中占比达91.1%，AICG是进一步扩大用户群、丰富场景、增加收入的加速器。随着显卡产能的提升，未来AIGC的成本投入也会随之大幅下降。而在差异化竞争方面，大量公域场景社交类型数据的积累是其他平台所缺少的，这在探索垂类大模型方面非常关键。</p><h2><strong>03 如何为生态负责？</strong></h2><p>值得注意的是，以匹配玩法、沉浸互动等思路提供更好的体验，改变了很多社交平台的商业模式，也引发了用户被技术和算法支配的担忧。AI造假、侵犯版权、 黑灰产业等乱象下，大众对社交媒体、平台上发布的信息可信度同步下降。</p><p>为应对AIGC内容风险，今年4月，国家网信办发布《生成式人工智能服务管理办法（征求意见稿）》，规定AIGC内容不得含有暴恐、低俗、歧视、侵权等违法违规内容，成为国内首份专门针对AIGC的监管文件。</p><p>此外，抖音、小红书、B站等平台相继为站内AIGC内容打上“水印”标识，从技术等层面提高AIGC内容的准确性、透明度和道德性，涉及陪聊、陪玩、直播等相关灰色地带也陆续迎来监管。</p><p>对社交平台而言，AI应用与站内生态“完美融合”，基于兴趣的供需匹配，满足更高的心理需求。叶毓睿表示，随着用户对隐私和数据安全意识的增强，提供相应保护措施，并让用户成为自己数据的主人，会逐渐成为社交平台的竞争优势。</p><p>社交平台们也将自身的“价值观”反映在产品与商业模式设计上。谈及商业化筛选方式，陶明称Soul遵循的是高度重视用户体验原则，在不影响用户完整的产品体验基础上，针对不同用户需求，适当进行一些个性化服务的付费点尝试，在精细化商业运营管理中实现营收增长。为用户创造价值，Soul就会实现自己的价值。</p><p>百合佳缘集团COO陈实亦直言，“如果我们放开手，拓展披着交友、婚恋外衣却做着直播、陪玩等业务，确实有很多收益的空间，但这与百合佳缘的服务理念是不一致，我们还是希望做严肃交友，不想违背原有的服务理念。”</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA5MzI1ODEzNA==&amp;mid=2650659415&amp;idx=3&amp;sn=4216611f530d63d1f3dd40a82ddddbfa&amp;chksm=8869d2aebf1e5bb8cdefa8b8a66747eb133da820769fd12fb1f08ddc37b0a5102deff01e55c2&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“财经”（ID：mycaijing）</a>，作者：《财经》新媒体，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520294491447173</id>
            <title>如果要聊“人车家全生态”，就不能只聊小米澎湃OS</title>
            <link>https://www.36kr.com/p/2520294491447173</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520294491447173</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:38:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米澎湃OS, 智车战略, 智能终端生态圈, 生态破圈
<br>
<br>
总结: 小米澎湃OS是小米推出的操作系统，旨在实现智能终端生态圈的全面连接。通过智车战略，小米将智能手机和智能汽车进行跨界融合，打通两者之间的生态系统，锁定用户实现万物互联。小米通过庞大的数据基数和生活场景全渗透，解决了生态破圈的三重问题，实现了信息交互的畅通和最优体验。 </div>
                        <hr>
                    
                    <p>上周五，小米社区官方人员透露，小米澎湃OS开发版第一批机型预计将会在11月中下旬陆续推送。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bc0779f6f0444cd691bc574b7d3d6000@5958072_oswg95243oswg865oswg288_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在系统首发当天，小米澎湃OS还曾公布过2023年12月至2024年1月陆续推送正式版的首批设备。<strong>智车战略</strong>注意到，这其中既有日常使用的手机、平板、手表，也有处于家庭使用环境的电视、音箱、摄像机。&nbsp;</p><p>自从2021年官宣造车以来，小米的每次发布会都让人对“小米汽车”的进展充满期待。今年，雷军以“小米汽车目前进展非常顺利，2024 年上半年正式上市”抛出引子，紧接着在发布会上宣布了小米系统史上最大规模的一次“底层重构”。&nbsp;</p><p><strong>从围绕手机和智能家居的操作系统，到升级版的“人车家全生态”，这不仅是小米的一次战略迭代，背后蕴藏的，还有其针对用户资源价值变现的野心。</strong></p><p><strong>本文观点：</strong></p><p>1、智能汽车和智能手机，本质上都是移动的智能终端载体。谁能掌握并打通两者之间的生态系统，谁就能锁定用户实现万物互联。&nbsp;</p><p>2、手机玩家入局汽车，基于庞大的数据可以实现“手机+汽车+家居+出行”的生活场景全渗透。&nbsp;</p><p>3、车机系统的统一，通过大屏+小屏、车联+物联、生态+生活解决了生态破圈的三重问题。&nbsp;</p><p>4、车机系统把内容、应用的生产方和消费者隔离开，利用用户资源控制消费，通过设置供给方的准入门槛，实现价值变现。&nbsp;</p><h2><strong>01 跨界</strong></h2><p>手机与汽车交叉跨界，小米不是第一家。&nbsp;</p><p>前有吉利收购魅族手机业务，在星纪魅族Flyme Auto的基础上打造极星汽车Polestar OS车机系统，推出智能手机、AR/VR智能终端、OS操作系统等产品和服务；后有蔚来发布首款手机NIO Phone，代替车钥匙，增加了车控键，与车机实现应用跨端融合。&nbsp;</p><p>华为更不必说。问界新M7通过华为Mate60手机实现了车机互联和智能座舱体验，而刚刚发布的智界S7，搭载的则是鸿蒙OS 4智能座舱和华为高阶智能驾驶，据说不仅支持跨屏同播，还让华为MatePad Pro与车机互联。&nbsp;</p><p>这样看来，小米汽车的动作并不算快。但小米系统却未雨绸缪，早早布局。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e907bf57fea14a4db459cfdb8abe7186@5958072_oswg70989oswg1080oswg779_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2010年，小米发布MIUI；2017年，小米自研的Vela OS正式发布，逐步统一IoT设备生态；2019年，小米开始并行研发纯自研通用系统Mina OS；2021年，小米开启了车机OS的研发；2022年初，小米统一MIUI、Vela、Mina、车机OS四个系统的软件架构，自此小米的操作系统底层合并完成。如今，小米澎湃OS应运而生，融合200+品类，可连接8.2亿设备。&nbsp;</p><p>不难看出，从MIUI到小米澎湃OS的发展路径，是沿着个人设备到智能家居、再到智能出行的轨迹在小步快跑。而这个过程中，小米汽车的出现成为关键节点，也是这次系统重构的直接原因。&nbsp;</p><p>雷军曾提过，调研时有人告诉他“智能汽车就是一部大轮子的智能手机”，看似一句调侃，却不经意点破手机和汽车系统合一的初衷—— <strong>抢占智能终端生态圈。</strong></p><p><strong>智能汽车和智能手机，本质上都是移动的智能终端载体。从一定程度而言，谁能掌握并打通两者之间的生态系统，谁就能用简单的“屏”锁定用户实现万物互联。</strong></p><p>而这一点，恰恰是小米最擅长的。&nbsp;</p><h2><strong>02 破圈</strong></h2><p>在造车之前，小米做的最扎实的就是造生态。</p><p>从2013年开始布局IoT（物联网），到2017年升级为AIoT，围绕手机PC周边产品（耳机+音箱）、智能穿戴、智能家居、健康出行等领域展开布局。</p><blockquote><p>小米Q2财报显示，截至2023年6月30日，AIoT平台已连接loT设备（不包括智能手机、平板及笔记本电脑）数达6.55亿，同比增长24.2%，拥有五件及以上连接至AloT台的设备（不包括智能手机、平板及笔记本电脑）用户数达1300万。&nbsp;</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b03953d2e37141daaa6db956ce4de9c2@5958072_oswg105640oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>如此庞大的数据基数，加上“手机+汽车+家居+出行”的生活场景全渗透，对于跨界玩家小米来说，很有可能是针对汽车生态的一次降维打击。</strong> 如今选择系统合一，在<strong>智车战略</strong>看来，解决了生态破圈的三重问题。&nbsp;</p><p><strong>·通过“大屏+小屏”解决信息交互问题。</strong> 车机协同的核心是如何以小控大（小屏指挥大屏），以及以大含小（大屏囊括小屏）。如果车上大屏在智能化上无法取代手机，不仅会沦为鸡肋，还可能会严重影响行驶安全。而简单的屏幕映射即使可以解决部分问题，在深层交互上仍然缺少说服力。车机系统的统一，让大小屏无缝衔接，保证了信息交互的畅通和最优体验。&nbsp;</p><p><strong>·通过“车联+物联”解决场景交互问题。</strong> 尽管移动智能终端在未来长什么样尚无定论，但可以肯定的是，从个人设备到居家生活，从日常办公到外部出行，智能化将成为焦点。车机系统的统一，让智能座舱不再拘泥于封闭空间，车联+物联的实时交互重新定义并延展了场景。&nbsp;</p><p><strong>·通过“生态+生活”解决生态交互问题。</strong> 越来越多的厂商选择“手机x AloT”的战略，以智能手机为纽带，辐射生态链产品，通过手机和万物互联发生化学反应。手机和汽车系统的合并为生态交互，从智能家居到刚需和高频的驾驶场景创造了条件，贯穿于生态和生活两端。&nbsp;</p><p>在智能生态的流量入口被拿下后，接下来要考虑的，就是如何让跨终端的内容和应用生态产生价值了。&nbsp;</p><h2><strong>03 变现</strong></h2><p>众所周知，操作系统是所有软件的底座，惟有筑牢底座，才能承建生态这栋高楼大厦，这一点在苹果手机身上体现的淋漓尽致。</p><p><strong>通过完整且封闭的iOS生态，苹果锁定了大量忠实用户，且探索出一条通过应用提供增值服务的变现模式。</strong> 这点如果移植到汽车上，很容易跑通商业化路径。这也就不奇怪李斌在蔚来汽车的NIO Phone发布前，曾表示“苹果汽车如果在2025年出来，我们的六成甚至更高比例的用户都使用苹果手机，我们一点防御都没有。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_131d0d8ef7df4ed78fd83438cfd52026@5958072_oswg64342oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>距离2014年苹果启动Project Titan（泰坦计划）造车项目已有9年，苹果汽车仍未问世，但通过操作系统来打造生态的思路，被小米活用。&nbsp;</p><p>虽然澎湃OS不会像苹果iOS一样封闭，且自身并不具备先天的造血能力。但如果以智能座舱为根基，以智能家居为连接，以智能生活为目的，为汽车、手机、电脑、电视以及其他智能设备提供跨终端的内容和应用服务， <strong>车机系统完全可以化身操盘手，把内容、应用的生产方和消费者隔离开，利用用户资源控制消费，通过设置供给方的准入门槛，实现价值变现。</strong></p><p>这，恐怕才是小米“人车家全生态”的最终诉求。&nbsp;</p><h2><strong>04 结语</strong></h2><p>可以预见的是，未来智能汽车、智能手机两个赛道将更好协作，面向共同用户实现多终端、全场景、沉浸式体验的一体融合。</p><p>有两点值得注意。&nbsp;</p><p>小米公司的市值自6月低点上涨了约200亿美元。据彭博社星期二（11月14日）报道，上述数据得益于市场对该公司最新款手机及其进军电动汽车和其他业务的兴奋情绪。&nbsp;</p><p>而就在今天，工信部公布了小米汽车的“全身照”。据了解，位于北京经开区的小米汽车工厂已经开始小批量试生产，目前已经生产数十辆，计划在12月开启批量生产，明年2月上市。&nbsp;</p><p>基于小米澎湃OS的CarWith2.0智慧车联显示，支持车辆已达到2200W+，在官方微博的评论区，希望增加车型的留言络绎不绝。 <strong>对于小米来说，在汽车发布之前借助澎湃OS，通过大屏+小屏、车联+物联、生态+生活的方式消除场景空间差，以此去中和小米汽车未能在今年赶上迅猛洪流的时间差，一切还未迟。</strong></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/rReShV5mCtf_JdpBFYSsOQ" rel="noopener noreferrer nofollow" target="_blank">“智车战略”（ID:xbzczl）</a>，作者：智车战略，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520268479571464</id>
            <title>人工智能将颠覆芯片设计，EDA大厂高管发出警告</title>
            <link>https://www.36kr.com/p/2520268479571464</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520268479571464</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:37:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 芯片制造业务, 设计方式, 标准单元库
<br>
<br>
总结: 人工智能将颠覆芯片的设计方式，提供了机会和效率，但无法覆盖最后一英里。人工智能可以用于构建标准单元库，减少碳足迹，但也导致富贵分化。各个群体都需要考虑人工智能对他们的影响和改变。 </div>
                        <hr>
                    
                    <p>人工智能将如何影响芯片制造业务？上周，一个由半导体公司资深人士组成的小组在 11 月 9 日于加利福尼亚州门洛帕克举行的 Silicon Catalyst 年度半导体行业论坛上讨论了这个问题。该小组猜测人工智能将如何以及何时颠覆芯片的设计方式，以及即将到来的“人工智能仙境”将会是一个多么奇怪的地方。</p><p>AMD高级副总裁 Ivo Bolsens表示：“我们正在进入电子设计创造的时代。” 他预测人工智能很快就能根据高级规格充实芯片的大部分设计。不过，他表示，在可预见的未来，人工智能将无法覆盖最后一英里。</p><p>Bolsens用最近的一次奥斯汀之行作为类比。“我飞往奥斯汀，开车到办公室的停车场，然后走进大楼，”他说。“人工智能是飞行；它可以让您快速非常接近您需要去的地方。从那里开始，你必须采用更传统的做事方式。这就是人工智能为芯片设计师提供的机会。它只是不需要从停车场到办公室的最后一步。”</p><p>Synopsys的首席安全官 Deirdre Hanford 表示，她的公司已经“在我们的[设计]工具周围部署了人工智能工具。” 她说，在整个行业中，“人们目前正在尝试找出可以在芯片设计过程中部署人工智能的位置。”</p><p>赛灵思前首席执行官、现任台积电董事会成员Moshe Gavrielov 的说法更为具体。他表示，人工智能很快将被用于构建标准单元库。他说，构建这样的库“非常复杂，有很多极端情况。计算机可以用更少的人力、更高的质量和更高的密度生成这些库。”</p><h2><strong>01 人工智能取代模拟电路设计</strong></h2><p>Gavrielov还指出了人工智能在处理模拟电路方面的力量。“人工智能可以采用模拟库并自动将它们一代又一代地转移到[技术]；这在过去非常耗时、容易出错且困难。”</p><p>这种变化多久会到来？“最终客户的利益将在短时间内非常明显，”Gavrielov说。“有一个门槛，一旦我们跨过这个门槛，大坝就会决堤，看到[芯片]设计即将发生的革命将是令人惊奇的。”</p><p>Gavrielov回顾了向电子设计自动化（EDA）的转变，这是芯片设计的最后一次重大变革。他说，这一转变经历了 30 多年的过程。“我认为人工智能带来的转变将在三分之一到五分之一的时间内发生，并将产生更大的影响，”他说。“五年后，当然不到十年，设计的方式将会与今天截然不同。”</p><p>但是，Hanford保证，芯片设计人员没有必要惊慌。</p><p>“作为一个行业，我们将继续实现自动化，而且它会加速发展，”她说，“但是各位，我不认为我们的行业面临着与律师助理等相同的威胁；我们只会在抽象中前进。”</p><h2><strong>02 减少人工智能的碳足迹</strong></h2><p>除了对设计流程的影响之外，主持人 David French（Silicon Catalyst 董事会成员兼SigmaSense首席执行官）还着眼于人工智能的影响，要求小组成员考虑人工智能对环境的影响。他指出了对创建人工智能模型所需的大量计算所消耗的能源和产生的碳的担忧。</p><p>AMD 的Bolsens表示：“我们采用了现有架构并从中进行推断，以满足人工智能的新兴需求。” 而且“它们的使用效率很低，通常只利用了硬件计算能力的 10% 或 20%，并且浪费了大量的电力。”</p><p>“这些都是早期的局，马虎的局，”Gavrielov说。</p><p>Bolsens指出，我们可以做很多事情。“人工智能的好处在于，就其所需的计算特性而言，它是一小类问题，”他说。“因此，新的计算架构将会出现，利用这一点来提高效率。”</p><p>“人工智能不仅仅涉及计算，还涉及数据，”Bolsens继续说道。“今天消耗的大量电力用于将数据转移到计算上。因此，您将看到将计算引入数据的解决方案，以及将计算引入内存的新内存架构，以避免传输数据所需的能耗。”</p><h2><strong>03 人工智能富人和穷人</strong></h2><p>人工智能研究所需的计算能力正在导致富人（大公司）和穷人（大学和小型初创公司）之间的分裂。Hanford说，“初创公司没有足够的计算时间”来进行人工智能研究，并指出大学的计算机资源通常也不够。</p><p>“如果你真的想在这个领域进行研究，你必须去Meta或微软，或者拥有一家资金雄厚的初创公司，”她说。她补充说：“我们应该确保大学继续进行疯狂的研究，”这将需要创建国家人工智能资源之类的东西。</p><p>Bolsens说，开源项目的趋势将会有所帮助。“这使得人们能够利用该领域其他人的工作成果。”</p><p>Hanford向芯片公司高管、企业家和投资者发出最后警告：“每个群体都必须考虑人工智能将如何扰乱他们的使命或提高他们的生产力。人工智能应该改变企业的每一个功能，无论规模大小。如果你不认为这是一种范式突破或会让你破产的事情，那么你就有麻烦了。”</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/C6g0RqpDmHgKjAzfLM3tFA" rel="noopener noreferrer nofollow" target="_blank">“半导体行业观察”（ID:icbank）</a>，作者：半导体行业观察，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520259652822792</id>
            <title>微软一口气发布两款芯片，1050亿晶体管挑战极限</title>
            <link>https://www.36kr.com/p/2520259652822792</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520259652822792</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:35:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, 自研芯片, Maia 100, Cobalt CPU
<br>
<br>
总结: 微软在Microsoft Ignite大会上推出了两款自研芯片，分别是针对人工智能任务的Maia 100和基于Arm架构的Cobalt CPU。Maia 100是迄今为止最大的AI芯片，采用了5纳米工艺和直接液体冷却技术。它在性能上超过了Google的TPUv5和亚马逊的Trainium/Inferentia2芯片。Cobalt 100是一款基于Arm架构的节能芯片，旨在提供更高的效率和性能。微软的自研芯片是其提供基础设施系统的最后一块拼图，可以根据内部和客户工作负载进行优化。 </div>
                        <hr>
                    
                    <p>微软终于揭开他们自研芯片的真正面纱。</p><p>在今天举办的Microsoft Ignite大会上，该公司推出了两款定制设计的芯片和集成系统：针对人工智能 (AI) 任务和生成式 AI 进行优化的 Microsoft Azure Maia AI 加速器，以及 Microsoft Azure Cobalt CPU——一款基于 Arm的处理器，专为在 Microsoft 云上运行通用计算工作负载而设计。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_68ef389b539d40d3b25be1d1162a7ccc@000000_oswg193061oswg1080oswg390_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>微软方面表示，这些芯片是微软提供基础设施系统的最后一块拼图，其中包括从芯片选择、软件和服务器到机架和冷却系统的一切，这些系统经过自上而下的设计，可以根据内部和客户工作负载进行优化。</p><h2><strong>01 Maia 100：5 nm工艺，1050 亿个晶体</strong></h2><p>据nextplatform引述微软CEO纳德拉的说法，微软的自研AI芯片Maia 100 芯片是基于台积电相同的 5 纳米工艺打造，总共包含 1050 亿个晶体管。这也因此，就晶体管或时钟速度而言，它并不轻量。而且，从公开数据开来，微软这颗芯片是迄今为止最大的AI芯片。</p><p>散热方式上看，Maia 100 芯片采用直接液体冷却，一直运行 GPT 3.5，目前属于 GitHub 的 AI 副驾驶提供支持。微软正在使用 Maia 100 加速器构建机架，明年将被允许通过 Azure 云为外部工作负载提供支持。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2513a1073be24f56b8ef898515e33052@000000_oswg709228oswg1080oswg736_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体性能方面，据semianalysis的报道，Maia 100在MXInt8下的性能为1600 TFLOPS，在MXFP4下则录得了 3200 TFLOPS的运算速度。semianalysis表示，虽然此处使用的数字格式是唯一的，但希望 MXInt8 是 FP16/BF16 的替代品，MXFP4 是 FP8 的替代品，至少对于推理来说是这样。这是非常简单的，但目前还算不错的启发式，因为没有人真正用这些数字格式训练过大规模模型。</p><p>从这些FLOPS 看来，该芯片完全彻底碾压了 Google 的 TPUv5 (Viperfish) 以及亚马逊的 Trainium/Inferentia2 芯片。与 Nvidia 的 H100 和 AMD 的 MI300X 相比，微软Maia 100的差距也并不远。</p><p>来到内存带宽方面，微软Maia 100的规格是 1.6TB/s 的内存带宽。这仍然碾压亚马逊的Trainium/Inferentia2，但却逊于TPUv5 ，更不用说 H100 和 MI300X 了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e10110f319604abea74354bc9a13bbfb@000000_oswg240483oswg1080oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>按照semianalysis的说法，之所以微软会出现这样的“错误”，是完全因为这该芯片是在LLM热潮发生之前设计的。因此，Maia 100在片上内存与片外内存方面有点不平衡——微软在芯片上放置了大量 SRAM，因为大量 SRAM 对于某些模型架构来说是有意义的。大型缓存通常有助于减少所需的内存带宽，但这不适用于大型语言模型。据介绍，微软在这个芯片上使用了 4 个 HBM 堆栈，而不是像 Nvidia 和AMD那样的 6 个和 8 个堆栈。</p><p>对于微软的这颗芯片，另一个亮点则在于其网络设计。如semianalysis所说， AMD 和 Nvidia 拥有 Infinity Fabric 和 NVLink，用于高速连接到少量附近的芯片（通常为 8 个），尽管 Nvidia 目前的一些部署数量已达到 256 个，但为了将数以万计的 GPU 连接在一起，Nvidia 和 AMD 需要将 PCIe 连接到以太网/InfiniBand 的网络附加卡。</p><p>但微软在这个芯片上采用了另外的一条道路——更类似于英特尔在其 Gaudi 系列加速器上所做的事情。那就是让每个芯片都有自己的内置 RDMA 以太网 IO。每个芯片 IO 总计为 4.8Tbps，这超过了 Nvidia 和 AMD，这与谷歌对其 TPUv5 和专有 ICI 网络所做的类似。</p><p>semianalysis表示，这个4.8T是单向的，是衡量联网速度的标准。当你在 NVLink 上计算 Nvidia 的数学时，实际上是 9.6T，而 H100/H200 是 7.2T。微软的 Maia 100 实际上比 Nvidia 拥有更多的扩展带宽，这是非常令人印象深刻的。</p><p>值得注意的是，Maia 100 还将 PCIe 通道减少至 8 个，以便最大限度地扩大 112G SerDes 的区域。Nvidia 有 16 个通道，因为他们需要这些通道来连接到以太网/InfiniBand。Nvidia 还在其 C2C 上投入了区域，用于以高带宽将 Grace CPU 与 Hopper GPU 连接。如果我们包括短距离点对点互连，Nvidia 仍然领先。</p><h2><strong>02 Cobalt 100：5nm工艺，128核N2</strong></h2><p>按照微软所说，Cobalt 100 CPU 是一款基于 Arm 架构（一种节能芯片设计）构建，并经过优化，可在云原生产品中提供更高的效率和性能的芯片。公司硬件产品开发副总裁 Wes McCullough 表示。选择 Arm 技术是 Microsoft 可持续发展目标的关键要素。它的目标是优化整个数据中心的“每瓦性能”，这本质上意味着消耗的每单位能源获得更多的计算能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_14a9282e6ead4478b5d3fc240f39436c@000000_oswg371949oswg1080oswg703_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然微软官方并没有披露该CPU的太多细节。但nextplatform引述传言表示， Cobalt 100是基于 Arm “Genesis”Neoverse Compute Subsystems N2 IP设计的。如果是这样的话，那么微软将采用两个 64 核 Generis 模块，其中每个模块带有“Perseus”N2 内核，每个内核有 6 个 DDR5 内存控制器，并将它们捆绑在一个插槽中。</p><p>换而言之，该芯片有 128 个核心和十几个内存控制器，这即使在2023 年也相当强大的。</p><p>“Perseus”N2 核心网格可在单个小芯片上从 24 个核心扩展到 64 个核心，其中四个可以组合在 CSS N2 封装中，以使用 UCI-Express（而非 CCIX）在插槽中扩展到最多 256 个核心或根据客户需求在小芯片之间进行专有互连。</p><p>Perseus 内核的时钟速度范围为 2.1 GHz 至 3.6 GHz，Arm 已优化了该内核、网格、I/O 和内存控制器的设计包，并采用台积电 (TSMC) 的 5 纳米工艺技术，从微软方面的消息看来， Cobalt 100 芯片也确实使用了这些制造工艺。微软表示，与 Azure 云中可用的以前的 Arm 服务器 CPU 相比，Cobalt N2 核心的每核心性能将提高 40%，纳德拉表示，微软的 Teams、Azure 通信服务和 Azure SQL 服务的部分已经在 Cobalt 100 上运行CPU。</p><p>Semianalysis则指出，Azure Cobalt 100 CPU 是微软在云中部署的第二款基于 Arm 的 CPU。他们署的第一个基于 Arm 的 CPU 是从 AmpereComputing 购买的基于 Neoverse N1 的 CPU。Cobalt 100 CPU 就是在此基础上发展而来，并在 Armv9 上引入了 128 个 Neoverse N2 内核和 12 个 DDR5 通道。Neoverse N2 的性能比 Neoverse N1 高出 40%。</p><p>Cobalt 100 主要基于 Arm 的 Neoverse Genesis CSS（计算子系统）平台。Arm 的这一产品与仅授权 IP 的经典商业模式不同，使得开发基于 Arm 的优质 CPU 变得更快、更容易且成本更低。</p><h2><strong>03 自研芯片，蓄谋已久</strong></h2><p>在微软看来，芯片是云的主力。它们控制着数十亿个晶体管，处理流经数据中心的大量 1 和 0。这项工作最终允许您在屏幕上执行几乎所有操作，从发送电子邮件到用简单的句子在 Bing 中生成图像。</p><p>就像建造房屋可以让你控制每一个设计选择和细节一样，微软将添加自研芯片视为确保每个元素都是针对微软云和人工智能工作负载量身定制的一种方式。这些芯片将安装在定制服务器主板上，放置在定制的机架内，可以轻松安装到现有的微软数据中心内。硬件将与软件携手合作，共同设计以释放新的功能和机遇。</p><p>Azure 硬件系统和基础设施 (AHSI) 公司副总裁 Rani Borkar 表示，公司的最终目标是 让Azure 硬件系统能够提供最大的灵活性，并且还可以针对功耗、性能、可持续性或成本进行优化。</p><p>“软件是我们的核心优势，但坦白说，我们是一家系统公司。在微软，我们正在共同设计和优化硬件和软件，以便一加一大于二，”Borkar说。“我们可以看到整个堆栈，而硅只是其中的成分之一。”</p><p>领导 Azure Maia 团队的微软技术研究员 Brian Harry 表示，Maia 100 AI 加速器是专为 Azure 硬件堆栈设计的。他表示，这种垂直整合——芯片设计与考虑到微软工作负载而设计的更大的人工智能基础设施的结合——可以在性能和效率方面带来巨大的收益。</p><p>AHSI 团队合作伙伴项目经理 Pat Stemen 则表示，2016 年之前，微软云的大部分层都是现成购买的。然后微软开始定制自己的服务器和机架，降低成本并为客户提供更一致的体验。随着时间的推移，硅成为主要的缺失部分。</p><p>在微软看来，构建自己的定制芯片的能力使微软能够瞄准某些品质并确保芯片在其最重要的工作负载上发挥最佳性能。其测试过程包括确定每个芯片在不同频率、温度和功率条件下的性能以获得最佳性能，更重要的是，在与现实世界的微软数据中心相同的条件和配置下测试每个芯片。微软强调，公司今天推出的芯片架构不仅可以提高冷却效率，还可以优化其当前数据中心资产的使用，并在现有占地面积内最大限度地提高服务器容量。</p><p>为了更好地发挥两个芯片的实力，英特尔还在机架上花了很多功夫。</p><p>事实上，如nextplatform所说，长期以来，微软一直希望在其机群中找到 X86 架构的替代方案，早在 2017 年，微软就表示其目标是让 Arm 服务器占其服务器计算能力的 50%。几年前，微软凭借其“Vulcan”ThunderX2 Arm 服务器 CPU成为 Cavium/Marvell 的早期客户，当Marvell 在 2020 年底或2021年初做出封存 ThunderX3的决定时，微软有望成为“Triton”ThunderX3 后续 CPU的大买家。因此2022 年，微软采用了 AmpereComputing 的 Altra 系列 Arm CPU，并开始将其大量放入其服务器群中，但一直以来都有传言称该公司正在开发自己的 Arm 服务器 CPU，Cobalt 100 就成为了公司的答案。</p><p>正如nextplatform所说，此举对任何人来说都不会感到意外，因为即使微软没有部署太多自己的芯片，它们的存在本身就意味着它可以与芯片制造商英特尔、AMD 和 Nvidia 谈判以获得更好的定价。这就像花费数亿美元来节省数十亿美元，这些钱可以重新投资到基础设施上，包括进一步的开发。特别是考虑到 X86 服务器 CPU 的相对较高成本以及 Nvidia“Hopper”H100 和 H200 GPU 加速器以及即将推出的 AMD“Antares”Instinct MI300X 和 MI300A GPOU 加速器的惊人定价。由于供应有限且需求远远超过供应，AMD 根本没有动力在数据中心 GPU 的价格上低于 Nvidia，除非超大规模提供商和云构建商给他们提供一个。</p><p>这就是为什么每个超大规模提供商和云构建商目前都在致力于某种自研 CPU 和 AI 加速器的原因。正如我们喜欢提醒人们的那样，这就像 20 世纪 80 年代末和 90 年代 IBM 仍然垄断大型机时价值 100 万美元的 Amdahl coffee cup 一样。Gene Amdahl 是 IBM System/360 和 System/370 大型机的架构师，他创立了一家以他的名字命名的公司，生产克隆大型机硬件，并运行 IBM 的系统软件，当 IBM 销售代表来时，你的桌子上正好有那个杯子。通过这样来访传达了这样的信息：你不再胡闹了。</p><p>这是十年前亚马逊网络服务公司得出的结论是它需要进行自己的芯片设计的原因之一，但不是唯一的原因，因为最终（当然还没有发生）服务器主板，包括它的 CPU、内存、加速器和 I/O 最终将被压缩到片上系统。正如传奇工程师 James Hamilton 所说的那样，移动设备中发生的事情最终也会发生在服务器中。（我们会观察到，有时反之亦然。）有替代方案总是会带来竞争性价格压力。但更重要的是，通过拥有自己的计算引擎（Nitro、Graviton、Trainium 和 Inferentia），AWS 可以采用填充堆栈协同设计方法，最终共同优化其硬件和软件，提高性能，同时有望降低成本，从而推动性价比极限并注入营业收入现金。</p><p>微软在定制服务器、存储和数据中心方面起步较晚，但随着 Cobalt 和 Maia 计算引擎的加入，它正在成为 AWS 和 Google 以及 Super 8 中其他正在制造自己芯片的公司的快速追随者出于完全相同的原因。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg2NDgzNTQ4MA==&amp;mid=2247719248&amp;idx=3&amp;sn=c491443ec4fbae37fd66bf45f35d8537&amp;chksm=ce6e9ba7f91912b1ec40c5a09146bf557f613c05f59a539d44ffc4a337f34a2f4e0ad6b445ad&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体行业观察”（ID：icbank）</a>，作者：编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520316206180101</id>
            <title>光伏产业空间巨大，政策利好频现，金刚光伏等涨停</title>
            <link>https://www.36kr.com/p/2520316206180101</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520316206180101</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:33:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 工信部, 光伏政策, 光伏行业, 光伏市场
<br>
<br>
总结: 工信部发布光伏政策利好，光伏行业迎来新机遇。国家统计局数据显示，我国光伏市场发展势头良好，产量增长明显。光伏行业受政策和国际合作影响，发展前景乐观。国内企业加强研发和创新，抢占发展先机。 </div>
                        <hr>
                    
                    <p>近期，工信部接连发布光伏政策利好，光伏行业迎来发展新机遇。同时，国家统计局最新数据显示，10月太阳能电池产品产量同比增长62.8%。我国光伏市场发展势头良好。</p><blockquote><p>受消息影响，11月15日，光伏设备、HIT电池等板块震荡拉升，金刚光伏（300093.SZ）率先涨停。截至当日中午收盘，金刚光伏涨19.98%，拓日新能（002218.SZ）涨9.98%，上能电气（300827.SZ）涨6.36%。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_615ddc4a392f40129a1c5230e882906e@5888275_oswg756888oswg795oswg519_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>01 光伏行业利好频发</strong></h2><p>工信部近日召开第四次制造业企业座谈会，会议提出聚焦光伏行业高质量发展，加强顶层设计和政策供给，引导企业加强技术创新，营造良好的发展环境，持续提升光伏行业竞争力。</p><p>此外，工信部官网发布《关于开展第四批光伏试点示范活动的通知》，试点示范内容包括支持培育一批智能光伏示范企业，以及能够提供先进成熟的智能光伏产品、服务、系统平台或整体解决方案的企业。</p><p>这些政策有望给光伏行业带来全新发展机遇，光伏行业的发展再获“加速度”。</p><p>与此同时，世界各国对于可再生能源的重视程度也越来越高。11月15日上午，中美两国发表关于加强合作应对气候危机的阳光之乡声明。两国支持二十国集团领导人宣言所述努力争取到2030年全球可再生能源装机增至三倍，从现在起加快可再生能源部署。</p><h2><strong>02 我国光伏市场发展势头良好</strong></h2><p>目前，我国已形成全球最完整的光伏产业链。在“双碳”政策的推动下，我国光伏市场发展势头良好。</p><blockquote><p>根据央视报道，前三季度我国硅料、硅片、电池、组件产量同比增长均超过70%，光伏行业总产值超过1.2万亿元。</p></blockquote><p>国家能源局数据显示，2023年前三季度，全国光伏新增装机12894万千瓦，同比增长145%；全国光伏发电量达到4369亿千瓦时，同比增长33%。全国光伏发电利用率为98.3%，同比提升0.3个百分点。</p><p>第四季度以来，光伏产品依然保持着较好的增速。国家统计局最新数据显示，10月太阳能电池产品产量同比增长62.8%。</p><p>研究机构对光伏行业的未来发展也保持乐观态度。全球咨询机构 Wood Mackenzie预计，2022年至2031年全球光伏并网装机容量将以年均8%的速度增长。中国有色金属硅业分会预计，到2025年全球光伏新增有望达到550GW，到2030年或将达到1000GW。</p><h2><strong>03 国内企业持续加强研发和创新</strong></h2><p>当前，中国光伏已经成为全球光伏产业的引领者，光伏产业进入万亿赛道的同时，如何高质量发展成为行业关注的焦点。</p><p>在此背景下，国内多家企业努力推动技术研发和创新，积极把握行业新机遇，抢占发展先机。相关数据显示，2022年我国企业和研究机构先后14次刷新晶硅电池实验室效率记录，百花齐放的创新趋势逐步显现。</p><p>光伏龙头企业隆基绿能（601012.SH）近期高度关注BC电池领域。该公司认为，接下来5-6年，BC电池将会是晶硅电池的绝对主流。基于此判断，隆基绿能未来的电池产能扩张都将采取BC技术路线。</p><p>爱旭股份（600732.SH）的ABC工艺路线在传统IBC技术的基础上叠加了TOPCon以及HJT技术。该公司今年投产的珠海6.5GW电池项目采用全球首创的无银化技术，大幅降低了ABC电池的生产成本。</p><p>东南网架（002135.SZ）将光伏应用到建筑，将光伏发电系统与建筑智能化系统相结合，实现了建筑的智能化和绿色化升级。该公司同样积极推进业务模式创新转型，多措并举大力发展光伏新能源业务，以“装配式+EPC+BIPV”的建设模式持续拓展光伏建筑一体化市场，后续有望贡献业绩增量。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/MY0Y5UzaLG_g47tuMka9EQ" rel="noopener noreferrer nofollow" target="_blank">“览富财经网”（ID:lanfucaijingwang）</a>，作者：呼葭蒌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520313308604167</id>
            <title>MIT学者独家撰文：ChatGPT的瓶颈与解药</title>
            <link>https://www.36kr.com/p/2520313308604167</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520313308604167</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:32:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能领域, 符号主义 AI, 经验主义 AI, 大语言模型
<br>
<br>
总结: 人工智能领域存在着符号主义 AI 和经验主义 AI 之争。符号主义 AI 强调精确的任务定义和严谨的数学工具，而经验主义 AI 则通过对大量数据的学习来获取知识。大语言模型是经验主义 AI 的产物，虽然成功但存在局限性。基于符号和逻辑的推理比基于经验和数据的感知更复杂。新的方法如自然语言嵌入式程序(NLEP)将符号推理和自然语言生成结合起来，证明了符号 AI 可以处理非结构化数据和自然语言，并增强了推理能力。符号主义 AI 有潜力替代经验主义 AI。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_50181d0a537e46d48adb1625e62487ac@5888275_oswg29981oswg1024oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>人工智能领域一直存在着学派之争。</p><p>曾经，“建制派”的符号主义 AI 被看作“唯一的主导力量”，“逻辑驱动”的人工智能曾主宰数十年；另一派则是代表经验主义 AI 的深度学习，不追求解释和逻辑，以神经网络和大数据开启”暴力美学“的大门。</p><p>以 GPT 系列为代表的大语言模型就是这条“暴力美学”路线的产物。这条路现在看来是成功的，但也存在一定的局限性。</p><p>从人工智能诞生的第一天起，计算机科学家们一直在比较以神经网络为代表的<strong>经验主义&nbsp;AI</strong>&nbsp;与以数理逻辑为代表的<strong>符号主义&nbsp;AI&nbsp;</strong>的优劣。简单来说，<strong>经验主义&nbsp;AI&nbsp;主张通过对大量数据的学习来获取知识，而符号主义&nbsp;AI&nbsp;则强调精确的任务定义和严谨的数学工具。</strong></p><p>随着近十年的算力进化，神经网络这一最典型的经验主义 AI 模型得到了飞速的发展。由于无法匹敌神经网络处理非结构化信息的能力和泛用性、无法生成非结构化数据（如自然语言），符号主义 AI 的存在感和影响力快速降低。</p><p>但是在我看来，<strong>基于符号和逻辑的推理 (reasoning) 远比基于经验和数据的感知 (perception) 复杂。经验主义&nbsp;AI&nbsp;发展的顶点，正是符号主义&nbsp;AI&nbsp;大放异彩的起点。</strong></p><p>著名语言模型批评者 Gary Marcus 博士曾锐评道：“大语言模型没法做一些有严格定义的工作：遵守国际象棋规则、五位数字相乘、在家谱中进行可靠的推理、比较不同物体的重量等等。”</p><p>“火力全开”的 Marcus 博士指出了目前大语言模型存在的问题，但是这个问题并非没有解决方法，我认为：<strong>大语言模型（LLM）只是不能通过生成文本做有严格定义的工作。大语言模型可以通过生成&nbsp;“自然语言嵌入式程序”&nbsp;（natural language embedded program, NLEP）准确完成上述工作。</strong></p><p>NLEP 是我与麻省理工学院（MIT）、香港中文大学（CUHK）研究团队共同研发的<strong>一种兼顾符号推理和自然语言生成的程序。</strong>它将语言智能抽象为「“思维”编程 + 程序执行」两个步骤，能让大语言模型同时具有生成自然语言和精确执行复杂推理任务的能力。</p><p>在传统认知里，符号&nbsp;AI&nbsp;无法处理非结构化数据和生成自然语言。<strong>而&nbsp;NLEP&nbsp;的方法证明，符号&nbsp;AI&nbsp;可以处理非结构化数据、自然语言，还可以强化非结构化数据深层的结构规律和推理能力。</strong></p><p>或许在不久的将来，符号主义有潜力替代经验主义。</p><p>接下来，我将从 Marcus 博士的锐评出发，讨论以下内容：</p><p><strong>经验主义&nbsp;AI&nbsp;难以突破推理的瓶颈；</strong></p><p><strong>文本到思维的抽象、思维的程序化表示；</strong></p><p><strong>OpenAI 代码解释器的局限；</strong></p><p><strong>NLEP&nbsp;范式的能力与优势。</strong></p><h2><strong>01 大模型与醉酒的人相似</strong></h2><p><strong>当前最先进的神经网络模型其实与醉酒的人相似。</strong></p><p>他们都努力与人互动、跟随简单指令生成信息，少数还试图驾驶交通工具。同时，他们也都带来了商业机遇和社会风险，并可能引起广泛讨论。&nbsp;</p><p>人类认知功能不完整时（如醉酒、梦呓、疾病等），语言行为往往是脱离逻辑思维的。&nbsp;</p><p><strong>这时，人类只是依赖语言本能，把输入信号强行拼凑成有一定语法结构的句子（文本补全）。</strong>表达的内容可能是如李白斗酒诗百篇般的艺术瑰宝，也可能只是毫无意义的胡言乱语。&nbsp;</p><p>事实上，人类大脑语言区域的发现正是基于临床医生对认知功能受损、保留了部分语言能力患者的研究。类似的科学方法也被大量应用于探索&nbsp;AI&nbsp;模型行为和规律的研究中。&nbsp;</p><p>随着算力的快速发展，OpenAI 等机构花费数百亿美元构建了参数量远超人类语言器官的神经网络，和文本量远超人类阅读极限的训练数据，<strong>为体积远大于人脑的机器赋予了类似的文本补全能力。</strong></p><p>但此类模型生成的究竟是 “语言” 还是 “梦呓”？&nbsp;</p><p>这个问题已经在学术界引起了激烈争论。<strong>争论的结果关乎社会和业界对&nbsp;AI&nbsp;可解释性、可靠性、安全性的认可程度。而决定结果的关键就在于语言模型是否存在可控、准确的思维能力。</strong></p><p>为了回答这一核心问题，谷歌旗下研究机构 DeepMind 的最新论文指出，<strong>语言模型本质上是信息的压缩模型。</strong></p><p><strong>只要模型的表示能力足够强（参数量足够）、被压缩的训练数据量足够大，语言模型就能在压缩信息的过程中抽象出一定的思维能力，包括推理、计算、预测等等。</strong></p><p>最先进的语言模型（例如 GPT-4）展现出的回答问题、跟随指令、编写代码的能力显然早已超越了任何人类的 “梦呓”。但如果说 GPT-4 和基于 GPT-4 的种种 Agent 足够可靠，似乎为时尚早。&nbsp;</p><p>GPT-4 是极端经验主义&nbsp;AI&nbsp;的代表：把世界上所有的高质量文本、程序、数学、对话数据压缩到算力允许的最大模型里，再抽象出这一技术路线蕴含的最强思维能力。它没有可靠推理引擎的支撑，完全依赖简单粗暴、类似“死记硬背”的大量训练。<strong>无论多少计算和数据资源，都无法掩盖和弥补 GPT-4 本质的推理缺陷。</strong>就如同酒驾的司机，无论酒量多好、多么侥幸，都无法避免酒精对人反应和判断能力的本质危害。&nbsp;</p><p>正如不同的任务对人的思维严谨程度有不同要求，当前的语言模型更适用于能容忍甚至欢迎一些噪声的应用场景，但在需要执行准确、可控的复杂推理任务时，其可靠性有根本的缺陷。GPT-4&nbsp;甚至会在回答一些并不复杂的问题时生成自相矛盾的文本，如下图所示：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_f7deb9f54bbd489fbf6438333b364b3b@5888275_oswg191853oswg1080oswg579_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_e189ad100e524a4683b1f4d6df57bb68@5888275_oswg137119oswg1080oswg499_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>实际上，吴丹（U Thant）是第一位来自于亚洲的联合国秘书长，潘基文（Ban Ki-moon）是第二位来自于亚洲的联合国秘书长，上图中 GPT-4 的回答并不准确。&nbsp;</p><p>能力如此强大的&nbsp;GPT-4，却依然会在简单的问答中生成自相矛盾的语言，这也佐证了现阶段语言模型推理的不可靠性。&nbsp;</p><h2><strong>02 文本补全模型的瓶颈就在文本</strong></h2><p>人类运用语言的能力可以抽象成知识、推理、计算三大模块，并且语言绝对不等于文本。&nbsp;</p><p>许多语言模型（文本补全模型）的问题难以解决，绝非模型不够强大，<strong>而是因为自然语言文本是思维结果的表达，并不是思维过程的载体。</strong></p><p>比如，我们想要学好物理，“事半功倍”的办法就需要从物理定律、求解问题、设计实验的思路出发；反之“事倍功半”的办法则是死记硬背一百本物理习题却不理解牛顿定律。采用这种方法的学习者花费更多的时间，但还是无法融会贯通地解决没见过的问题。&nbsp;</p><p>这个缺陷并不是解题模型——人类大脑的问题，而是训练数据的缺陷——问题的答案只是物理定律的表象，而解题思维代表着对物理定律的直接应用。&nbsp;</p><p>不可否认，“死记硬背”是实现“答对考题”的技术路线之一。与之相似，<strong>使用大型神经网络在大规模数据集上学习文本补全能力，也是当前&nbsp;AI&nbsp;“获得思维”的技术路线。</strong></p><p>虽然巨量的计算资源与数据的投入让这种技术路线取得了成功，但诸多的研究和应用已经证明，这种技术路线的可靠性瓶颈会带来诸多挑战：<strong>臆想、推理能力有限、隐私泄露、合规问题等等。</strong></p><p>大语言模型的能力是一把双刃剑：<strong>可以处理不存在于训练数据中的新问题，但也会在其不知情的情况下，输出错误的推理结果。</strong></p><p>作为通过压缩文本提炼思维的黑盒模型，其知识、思维、推理能力都储存在神经网络的权重中。AI&nbsp;的优势和不足都体现在以下几个方面：&nbsp;</p><p>抽取真实或失实的知识和信息；</p><p>规划非结构化的推理流程；</p><p>由模型执行有误差的计算。</p><p>由于以上三个模块都有可能出错，大模型的行为难以验证、解释、控制、改进。&nbsp;</p><p>针对“在美国，哪种新冠病毒造成了最高的&nbsp;ICU&nbsp;占用量”这个问题，GPT-4模型的回答是“德尔塔变种导致的 ICU 占用量最高”。&nbsp;</p><p>那真实的情况是什么？&nbsp;</p><p>在&nbsp;11&nbsp;月&nbsp;6&nbsp;日的&nbsp;OpenAI&nbsp;开发日前，没有搜索引擎增强的&nbsp;GPT-4&nbsp;模型会给出定性的回答和解释：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_d77df8f082574f6391c1c0299da12ff2@5888275_oswg271181oswg1080oswg737_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>开发日后的 GPT-4 系统默认调用必应搜索引擎，会基于搜索结果给出数据、作出一定解释和参考资料引用：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_3850947066ee4aed80bdfb714357ed48@5888275_oswg297252oswg1080oswg772_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>中文翻译：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_eef1bd99e56241a4af3a1d5c6e977019@5888275_oswg257991oswg1080oswg498_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>获得搜索增强的 ChatGPT 生成了更有说服力、文本更专业的回复。尤其是在其中三处引用了参考资料网址，更加提高了用户阅读答案后的满意度（和被误导的可能性）。&nbsp;</p><p>遗憾的是， ChatGPT 的用户很难验证答案的正确性。事实上，重复问最新的（2023 年 11 月 13 日）、搜索引擎加持的&nbsp;GPT-4&nbsp;同样的问题，它还会生成各种不同的回答:&nbsp;</p><p>回答 a：“奥密克戎变异 – 占用了高达 30.4% 的 ICU 病床。”</p><p>回答 b：“虽然感染了德尔塔变异的病人最多占用了 31% 的 ICU 病床，但奥密克戎病人占用了更多。”</p><p>回答 c：“好像不是奥密克戎变异，好像是德尔塔变异。”</p><p>虽然在不同尝试中&nbsp;GPT-4&nbsp;的回答自相矛盾，<strong>但是每一次回答生成的文本看起来都很正式、客观、有说服力、甚至附带搜索引擎给出的参考文献。</strong>未经多次验证答案的读者很容易受到误导。&nbsp;</p><p>语言模型的这种能力非常适合于创作和想象：给一个标题，写三个小故事之类的任务对于 ChatGPT 而言恰到好处。但遗憾的是，<strong>这种不可控的行为模式，在回答需要严谨推理的问题时应该被尽量避免。</strong></p><p>更遗憾的是，虽然给了&nbsp;GPT-4&nbsp;多次尝试的机会甚至搜索引擎的加持，上述新老&nbsp;GPT-4&nbsp;猜测的答案中没有一个是正确的。&nbsp;</p><p>根据权威统计机构数据看世界（Our World in Data）信息，美国因新冠病毒导致的 ICU 病床日占用量峰值应发生在 2020 年冬天阿尔法变异流行期间。GPT-4&nbsp;基于必应搜索引擎提供的大量“比较德尔塔与奥密克戎变种病毒”的文章得出“德尔塔或奥密克戎变异造成了最高的 ICU 病床占用量”是不准确的。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cd3b36ed3b2e499c82ac7a4334a5e06f@5888275_oswg146247oswg1080oswg761_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>那么，GPT-4&nbsp;在知识、推理、计算的哪一步出现了错误？是搜索的数据出了问题，还是对于三个峰值比较大小的运算出了问题？用户并不了解。&nbsp;</p><p>在上述例子中，GPT-4&nbsp;的可解释性和可靠性都会受到质疑。为了改进语言模型的事实性、可解释性、可控性和可靠性，OpenAI、Meta、麻省理工学院、香港中文大学（CUHK）、卡耐基梅隆大学、滑铁卢大学等机构的研究人员分别提出了不同的基于编程语言以及程序解释器增强的技术方案。&nbsp;</p><p>其中，比较广为人知的方案是 OpenAI 开发的 ChatGPT 代码解释器和 Meta 提出的 Toolformer 模型。它们在文本生成的过程中将一部分内容“外包”给程序或&nbsp;API，例如数学运算。&nbsp;</p><p>代码解释器或者可靠&nbsp;API&nbsp;能够保证在输入正确的情况下永远计算出一致、正确的结果，并将结果返回到语言模型生成的内容里，比如：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_37d2cfb5a0b9482bbf443358fff49628@5888275_oswg173073oswg1080oswg792_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后的总分是由一段 python 代码计算得到：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_6ae97acdb27e41e3bb7986508f153965@5888275_oswg53406oswg1006oswg688_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然“外包”了一部分推理任务给可靠的代码解释器，ChatGPT 的主干仍然是自然语言。上述例子只在最后一步计算总分时调用了代码解释器，而步骤&nbsp;3&nbsp;中 “30&nbsp;分” 的中间结果仍然是由自然语言完成的推理。&nbsp;</p><p>最新的研究表明，在很多任务上 ChatGPT&nbsp;负责调用代码解释器的数据分析(Data Analysis) Agent&nbsp;仍不能取得准确的推理效果。比如，它拒绝用代码解决一些非结构化问题中的结构化推理任务，因此得到错误的结果：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_757af802d8274bd2af8fcc76e2257c30@5888275_oswg253918oswg1080oswg952_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在这个例子中，我们的问题是“有几位联合国秘书长不是来自欧洲？”虽然使用了 ChatGPT 的数据分析 agent，但它拒绝使用代码分析，而是使用自然语言“敷衍了事”。这也就造成了，虽然&nbsp;GPT-4&nbsp;生成了正确的人物列表及国籍，最后的计数却漏了来自亚洲的潘基文秘书长。&nbsp;</p><p>这里正确答案应为 5 位联合国秘书长来自欧洲，而 ChatGPT&nbsp;数据分析&nbsp;Agent&nbsp;偷工减料推理得到的结果是 4 位。&nbsp;</p><h2><strong>03 NLEP方案：符号主义AI的极致尝试</strong></h2><p><strong>NLEP 是一种同时提高自然语言、符号推理能力的神经符号 (neuro-symbolic) 方法。</strong></p><p>针对 ChatGPT 代码解释器的种种痛点，麻省理工学院（MIT）和香港中文大学（CUHK）的研究人员提出了一个大胆的假设：<strong>“哪里有自然语言，哪里就有不严谨的思维。”</strong></p><p>基于这种假设，我们提出了一种独特的语言生成方案：natural language embedded program (NLEP，自然语言嵌入式程序)。&nbsp;</p><p>OpenAI 采取了“文本补全+代码解释器插件”的范式，在自然语言中必要处添加代码和插件的调用。NLEP 则通过生成可一键运行的程序解决一切自然语言、数学、符号推理、编程问题，只在程序中必要的地方嵌入自然语言。&nbsp;</p><p>在完成程序生成后，点击“运行”按钮，由程序打印出自然语言的回答。例如在之前的联合国秘书长计数问题中，NLEP 生成的内容如下：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b2c29987be394db29e8d936746749f0d@5888275_oswg302858oswg1080oswg676_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在图中可以看到，语言模型生成了一段逐步解决问题的程序：定义结构化知识、实现计算结果的函数、打印自然语言回复。完成程序的生成后，运行完整的程序，即可得到正确的结果。在五次独立重复实验中， GPT-4&nbsp;API&nbsp;的正确率为 40%，ChatGPT 代码解释器的正确率为 60%，而 NLEP 的正确率为 100%。&nbsp;</p><p>NLEP 与 ChatGPT 代码解释器相比有显著的区别：&nbsp;</p><p><strong>ChatGPT&nbsp;以自然语言文本为主干回复用户输入。</strong>在生成某个词的时候切换到代码运行，再将代码运行结果添加到生成的内容里，然后继续生成文本；<strong>而&nbsp;NLEP&nbsp;以程序为主干，首先生成完整的程序，然后执行程序、打印出包含自然语言文本、图表等要素的回复。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_94a41a7f651b46c3ac2d5a09a7768a6a@5888275_oswg193877oswg1080oswg426_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>同时，NLEP 的编程语言框架也可以比自然语言框架更自然地链接数据。</strong></p><p>相比于自然语言框架，NLEP 作为完整的可运行程序，可以更自然地链接知识库和数据库。NLEP 可以准确调用谷歌知识图谱里的真实数据，回答此前“哪个新冠变种导致了最高的 ICU 日占用率”的问题并提供数据可视化作为解释：&nbsp;</p><p>NLEP 的回答是“The COVID variant caused the highest daily ICU occupation in United States is Alpha (在美国造成最高 ICU 占用的新冠病毒变种是阿尔法).”并以此生成出自动可视化数据：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_7bee83126cb0436dabbac7fbe658b674@5888275_oswg62955oswg987oswg590_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以上功能由 NLEP 的生成工具 LangCode 实现。&nbsp;</p><p><strong>此外，NLEP 还可以自动生成结构化 Agent。</strong></p><p><strong>NLEP 与 ChatGPT 的本质区别在于是否采用结构化的语言生成框架。</strong>ChatGPT 以非结构化的自然语言文本补全为基本范式。因此在上周的 OpenAI 开发日，OpenAI 公布的 GPT store 也更多集中于非结构化的 agent，即 chatbot 的自动搭建。&nbsp;</p><p>而早在 OpenAI 公布 GPT store&nbsp;一个月前，我们就利用融合了符号、结构、自然语言的能力的&nbsp;NLEP&nbsp;为 Anchoring&nbsp;AI&nbsp;平台实现了自动生成结构化 Agent 的功能。&nbsp;</p><p>如图所示，Anchoring&nbsp;AI&nbsp;Agent 可以服务结构化的输入和输出。其推理过程、自动生成的提示信息也显示在自动生成的独立模块中，透明可控、清晰准确，便于团队协作开发AI应用。&nbsp;</p><p>如 GPTs Agent:&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_cd8e82a1028c4cb6bd650ece8083a5ce@5888275_oswg139842oswg1031oswg843_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以及根据一句自然语言指令自动生成的Anchoring.ai Agent:&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_43bedb0b69e34dc391c30d98237321c2@5888275_oswg145761oswg932oswg795_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>04 符号主义终将“接棒”</strong></h2><p>经验主义与符号主义AI争议纷扰六十余年，其核心矛盾在于：<strong>经验主义&nbsp;AI&nbsp;侧重强大的泛化能力，而符号主义AI侧重精确地推理能力。</strong></p><p>近二十年来，拔地而起、粗放增长的 AI 研究和产业强调扩展 AI 的应用场景。因此，泛化能力成为了近十年 AI 的主题。尤其在 ChatGPT 横空出世的 2022 年底，经验主义 AI 发展到了极致：GPT 模型有着极强的泛化性能，能够处理非常广泛的数据和应用。&nbsp;</p><p>但在后 GPT-4 时代，AI 的粗放增长会迅速来到瓶颈期，转而进入精益发展的阶段。下一个十年AI领域的主题将是精确推理、可解释性、安全可控。依托于经验主义AI的坚实基础和强大泛化能力，符号主义将接过解决AI诸多挑战的重任，在未来的AI发展中大放异彩，带来无数崭新的可能。&nbsp;</p><h2><strong>05 小结</strong></h2><p>*本文为麻省理工学院（MIT）学者罗鸿胤独家供稿，「甲子光年」经其授权后编辑发布。</p><p>罗鸿胤是人工智能领域的青年科学家、MIT&nbsp;计算机学与人工智能实验室（CSAIL）的博士后研究员，主要关注自然语言处理方向，包括自训练算法、蕴含模型、语言模型推理问题。他博士毕业于&nbsp;MIT&nbsp;电子工程与计算机科学系，师从 Jim Glass&nbsp;博士；本科毕业于清华大学计算机系，师从刘知远教授。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/W7UQwMLaYh86HD6VdqboGQ" rel="noopener noreferrer nofollow" target="_blank">“甲子光年”（ID:jazzyear）</a>，作者：罗鸿胤，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520314174268937</id>
            <title>又有券商要合并？回应来了</title>
            <link>https://www.36kr.com/p/2520314174268937</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520314174268937</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:22:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 方正证券, 合并传闻, 股价涨停, 平安证券
<br>
<br>
总结: 方正证券和平安证券之间的合并传闻引起了市场的关注，方正证券的股价连续两个涨停，涨幅接近40%。方正证券董事长表示，公司将按照监管部门的规定进行相关工作，并及时披露进展。根据监管层的要求，证券行业鼓励头部公司通过并购重组等方式做大做强，打造一流的投资银行。方正证券和平安证券作为同业竞争对手，合并后需要解决同业竞争问题。 </div>
                        <hr>
                    
                    <p>除了中金和中国银河的合并传闻之外，方正证券和平安证券之间的合并传闻近日也传得沸沸扬扬。方正证券的股价更是在3个交易日内连续两个涨停。</p><p>截至11月15日收盘，方正证券的股价从11月3日7元/股左右涨至10元/股附近，股价涨了近40%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_46b03c64e48c48e9a0092cddb6bea337@5888275_oswg381104oswg1080oswg1182_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于合并传闻，在今天举办的业绩说明会上，方正证券董事长施华进行了回应。</p><h2><strong>01 方正证券回应合并传闻</strong></h2><p>11月15日，方正证券召开2023年三季度业绩说明会，针对投资者提及的中国平安成为公司实控人后，解决平安证券和方正证券等同行业竞争问题方案，方正证券董事长施华表示，<strong>方正证券正与各方一起，严格依照金融监管部门的规定、指引，开展相关工作。后续有新的进展，会及时披露。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_071d3def876a4a01a229744fe9a09958@5888275_oswg126377oswg1080oswg458_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>该说法与数月前，方正证券召开的2022年业绩说明会时，施华对解决与平安证券的同业竞争问题时的表达一样。</p><p>此前对于股价异动，方正证券11月8日发布公告称，经公司自查并向控股股东发函查证，公司及控股股东不存在应当披露而未披露的重大信息，包括重大资产重组、股份发行、重大交易类事项、业务重组、股份回购、股权激励、破产重整、重大业务合作、引进战略投资者等。</p><h2><strong>02 靴子或将于12月落地</strong></h2><p>与平安证券的同业竞争问题，始终围绕在方正证券的各个交流场合。</p><p>原控股股东方正集团在2020年2月被裁定重整。直到2022年底，方正集团及其一致行动人方正产业控股有限公司将23.63亿股股份全部划转至新方正集团，公司控股股东变更为新方正集团。</p><p>而中国平安间接控股新方正集团，在“一参一控”政策要求下，方正证券和平安集团旗下的平安证券有望吸收合并，成为市场多个猜想之一。</p><p>在今年的半年报中，方正证券也提及，平安证券与方正证券主营业务相似，故在本次重整投资完成后，平安证券与方正证券存在同业竞争关系。平安信托作为平安证券的直接控股股东，<strong>已出具承诺函，承诺将保障方正证券全体股东利益，通过合法合规的方式解决平安证券与方正证券的同业竞争问题。</strong></p><p>据记者了解，中国平安成为公司实控人后，依据中国证监会证监许可〔2022〕3157号文，中国平安需要在今年12月19日前提交解决同时控股方正证券和平安证券问题的方案。</p><h2><strong>03 监管层再提“券商合并”</strong></h2><p>在11月3日的证监会新闻发布会上，相关负责人表示，将支持头部证券公司通过业务创新、集团化经营、并购重组等方式做优做强，打造一流的投资银行，推动证券公司投行、投资、投研协同联动，不断提升服务实体经济、服务注册制改革能力，助力构建为实体企业提供多元化接力式金融服务体系。</p><p>记者梳理发现，近年来，鼓励头部券商做大做强已成为重要方向，监管层也多次明确提及。比如在2019年，证监会明确提出，为推动打造航母级证券公司，将鼓励和引导证券公司充实资本、丰富服务功能、优化激励约束机制、加大技术和创新投入、完善国际化布局、加强合规风险管控，积极支持各类国有资本通过认购优先股、普通股、可转债、次级债等方式注资证券公司，推动证券行业做大做强。&nbsp;</p><p>彼时，中信证券与中信建投、国金证券与国联证券就曾先后传出并购传闻，带动相关公司股价大涨，只不过这一传闻最终被证伪。</p><p>此次监管再次提及“打造一流投行”，中信证券在研报中表示，在当前环境下，同一股东控制下的证券公司有望凭借政策东风，加速自身并购进程。</p><p>无疑，方正证券和平安证券，国联证券和民生证券等多家券商均符合这一标的。</p><p>“证券行业并购进程仍是渐进式过程。”中信证券称，证券行业并购需要重视治理结构层面，以及并购后的整合问题，合并后的业务团队整合、渠道网点取舍、企业文化融合、管理结构设置对新券商的管理能力和执行力均需要重点关注。</p><p>对此，中信证券直接指出，在 方正证券 与 民族证券 的合并未能有效实现1+1&gt;2的效果，对方正证券在2019年后的经营发展产生了较大影响。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/tSgnaGhLWReCDIntG-awSw" rel="noopener noreferrer nofollow" target="_blank">“中国基金报”（ID:chinafundnews）</a>，作者：中国基金报，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2519578392339975</id>
            <title>小米汽车亮相，有PRO和MAX两版本，月薪3万招门店店长</title>
            <link>https://www.36kr.com/p/2519578392339975</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2519578392339975</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:11:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米汽车, 证件照, 申报车型信息, 外观设计
<br>
<br>
总结: 工信部公布了小米汽车的证件照，揭示了小米汽车的真容。小米汽车商标为“小米牌”，由北京汽车集团越野车有限公司代工。该车是纯电动轿车，车长4.997米。外观设计偏向运动风格，有Pro和Max两个版本可选装不同配置。网友对小米汽车的外观设计有不同的看法，有人觉得像迈凯轮、保时捷Taycan、智界S7和特斯拉。 </div>
                        <hr>
                    
                    <p>今日，工信部公布了小米汽车的“证件照”，也就是申报车型信息。这也是自雷军宣布造车以来，小米汽车真容首次昭告天下。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_b01f6a9892bb40b1a7a2c67e5b5762d4@000000_oswg94301oswg1080oswg950_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从工信部信息看，小米汽车产品商标为“小米牌”，由北京汽车集团越野车有限公司代工。该车是纯电动轿车，车长4.997米。</p><p>电池方面，小米汽车使用宁德时代的三元锂离子电池和比亚迪旗下的弗迪磷酸铁锂电池。发动机来自苏州汇川联合动力系统股份有限公司，驱动电机峰值功率220kW。</p><p>车辆尾部还有“北京小米”标识。</p><h2><strong>01 外观设计：偏运动向，至少有Pro和Max两个版本</strong>‍</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_4573bc9cea264cda8b6f386ae4e28be6@000000_oswg46569oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从工信部公布的照片来看，小米汽车还是和其他新势力同级车型有明显区别。前车灯呈右尖左方的横置水滴状，分为上下两层；前脸下方为进气格栅，呈梯形。车辆为灰白色，并且可以看到车顶正中安装有激光雷达。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_459c0c0862eb406d8d14e9f234e61abc@000000_oswg45550oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>小米汽车尾部也和很多车型一样，采用了贯穿式尾灯设计，下方左右两侧有排气口状设计。“XIAOMI”字样放置在后备箱中央，左下为“北京小米”，右下为“SU7 Max”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_575056dca81c4db0a49b83c2845a3ab0@000000_oswg151464oswg1080oswg1274_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从工信部公布的选装配置来看，小米汽车至少有“Max”和“Pro”两个版本。用户可选装激光雷达、ETC等。</p><p>外观方面，用户可以选装黑色尾部字标、黑色前部徽标、不同外观后视镜以及不同天幕玻璃以及不同外观轮毂。</p><p>另外，小米汽车标配主动尾翼，这点也使得该车颇具运动气息。</p><p>值得注意的是，小米汽车疑似还有个特别版。从图片看，特别版车型在侧面翼子板和后风窗玻璃上贴有“Founders Edition”字样。笔者猜测这或许是小米汽车特别推出的纪念版，不过具体信息还是要等未来正式发布后才能确定。</p><h2><strong>02 网友：和保时捷有点像</strong></h2><p>工信部信息一经公布，立即引发网友热议。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_8480f6e2b57442f59a0d6ba502fb0fff@000000_oswg14754oswg706oswg207_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有网友认为小米汽车前脸像迈凯轮，车尾像保时捷；</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_80a74ba1bce04a33a41de157e9cdc517@000000_oswg95469oswg1080oswg657_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">保时捷Taycan</p><p>有网友认为小米汽车设计上像保时捷Taycan；</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_f7d188f1c9a6478198c7e86321293b68@000000_oswg40362oswg745oswg702_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有网友觉得像智界S7；</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_c0040815b764406db47641f0e3071c4d@000000_oswg42421oswg733oswg724_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>竟然还有网友认为像特斯拉；</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_fff8a573903640339894bd04d53e4f6c@000000_oswg206836oswg1080oswg1396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有网友干脆做了拼图，认为小米汽车设计元素上来看，正面、尾部以及轮毂等地方都有其他车的影子。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_dcdde07161674cb9b4f7f44b86b3bb61@000000_oswg96545oswg739oswg1474_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，笔者看了一圈下来，认为小米汽车像保时捷Taycan的网友占多数，主要相似点在侧面以及前脸下部。</p><p>那么，你喜欢小米汽车的设计吗？</p><h2><strong>03 前宝马设计师李田原操刀，曾设计BMW iX</strong></h2><p>这样的设计无论你喜不喜欢，现在已经可以说板上钉钉。而小米汽车又是谁操刀设计的呢？</p><p>2021年9月1日，雷军曾发微博宣布小米汽车正式注册，并且附上了一张17人的团队合影。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_782b0e3a68fc4dbc8b7192685234ad1e@000000_oswg608232oswg1000oswg978_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_16b309d67b1f4f269e064d7a7083dcb7@000000_oswg581929oswg850oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这17人其实也就意味着是小米汽车的核心主创团队。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_74edaa9ba99647cf94f4e29f92b3d6d8@000000_oswg173348oswg761oswg1588_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>三言梳理这17人的任职信息后发现， 雷军晒出的小米汽车团队中主要成员要么来自小米公司高管，要么是小米创业时期的核心团队。</p><p>而从职责上看，只有一人是非小米出身，并且工作经历涉及汽车外观设计，他就是李田原。</p><blockquote><p>三言了解到，李田原2009年毕业于西南科技大学，之后任职于长城华冠；2011年至2012年，他在PSA中国设计中心就职；2012年至2016年就职于宝马designworks，2016年起在宝马i/M部门工作。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_04f727ed7d814c66a7e4ae43e6f7cc35@000000_oswg1266179oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">BMW iX&nbsp;</p><p>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_92b330d9c6d64f60bc858ca109b2d93e@000000_oswg138368oswg1080oswg1781_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">上图：宝马宣传片中的李田原；下图：雷军晒出的合影中，李田原在第二排右起第三位&nbsp;</p><p>重要的是，宝马的BMW iX车型就是由李田原设计，他还出现在宝马公司官方宣传片中。能够得到传统知名汽车品牌的认可，可以看出李田原作为设计师的能力是值得肯定的。</p><h2><strong>04 正在招聘诸多汽车相关岗位，月薪3万招门店店长</strong></h2><p>目前，距离小米汽车正式上市已经越来越近，小米公司也在紧锣密鼓的做前期准备工作。</p><p>小米公司目前正开设多个汽车销售类相关岗位，比如新能源汽车销售主管、小米汽车门店店长、小米汽车零售店长等。</p><p>而据《科创板日报》报道，有小米内部人士透露称，现有的小米渠道只是小米汽车的销售渠道之一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_d2423453d5e04ac79dc0d3eaecf5fdb4@000000_oswg130103oswg1080oswg2106_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>笔者注意到，小米公司目前在国内很多城市招聘汽车相关岗位，比如北京、成都、上海、武汉、杭州、南京、深圳、广州、无锡、东莞、温州等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_becc6f23c89b4531b6cb421e8fca5cd5@000000_oswg120650oswg1080oswg1916_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>工作岗位也是五花八门，含有零售店长、门店店长、产品主管、产品体验主管、交付培训经理等。</p><p>薪资方面，根据岗位不同，月薪从1.5万至3万不等，有的工作，比如GTM，月薪更是达到4万至6万。</p><p>当前，国内造车新势力竞争激烈，在这种背景下，小米汽车面临的挑战相当巨大。能否在市场中做到一鸣惊人，出道即巅峰，还需市场检验。</p><p>雷军曾说造车是自己最后一次创业，那么，你是否喜欢小米汽车？是否看好这款车型呢？欢迎留言。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzU2ODcwMDY2NA==&amp;mid=2247553646&amp;idx=1&amp;sn=03097db971e4326b3e2373c2ca9640c8&amp;chksm=fc8ba9f9cbfc20ef57f2ae1c679ea53cbf9c043c718ee5dcddf926d22147c4535063b09260da&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三言财经”（ID：sycaijing）</a>，作者：DorAemon，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2519151859394056</id>
            <title>面向未来，我们需要什么样的城市｜未来城市大奖2023报名启动</title>
            <link>https://www.36kr.com/p/2519151859394056</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2519151859394056</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 01:55:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 未来城市大奖, 城市化进程, 城市韧性, 可持续发展
<br>
<br>
总结: 《世界城市报告2022》指出，全球城市化进程不会停止，未来城市需要韧性建设，包括绿色投资、响应性城市规划、公共卫生优先和创新技术。中国的城镇化取得了巨大成就，城市已成为全球化叙事中的主角。为了推动城市高质量发展，中国推出了《城市标准化行动方案》，并举办了未来城市大奖，旨在寻找和发现城市规划、建设、运营等领域的杰出项目和模式。大奖设立了四大基础评价象限和三大评奖单元，以智慧、可持续、友好和在地为基础评价，评选出未来城市样本和解决方案。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_2cfe5fcad10c49d99d41af20233e6dc2@5288884_oswg147745oswg1080oswg403_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">未来城市大奖</p><h2><strong>01</strong></h2><h2><strong>面向未来 塑造城市</strong></h2><p>联合国人居署发布的《世界城市报告2022》提出，全球城市人口比例从1950年的25%翻了一番，到2020年达到约50%，预计在未来50年内，这一比例将缓慢增加到58%。在新冠大流行期间，一些居民离开大城市是暂时的，全球城市化进程不会因之改变。</p><p>《报告》也明确指出，未来城市的核心任务是“韧性建设”，城市需要：为可持续的消费和生产模式而开展绿色投资；制定具有响应性和包容性的城市规划；把公共卫生列为优先事项；为所有人提供创新和技术。这些努力，将帮助城市适应与应对冲击和压力，引导世界走向一个韧性、公正和可持续的城市未来。</p><p>在全球城市化进程中，经历二十余年的发展，中国的城镇化取得了举世瞩目的成就。截至2022年末，中国常住人口城镇化率达到65.2%，城镇居民已经实现户均1.03套住房，京津冀、长三角、珠三角等19个城市群以25%的土地、集聚了中国超过70%的人口、创造了80%以上的国内生产总值。</p><p>城市已经成为中国在全球化叙事中的主语，而塑造未来城市将是关乎数亿人生活愿景的全新挑战和实践。</p><p>2023年10月，在国家标准委、工业和信息化部、民政部、生态环境部、住房和城乡建设部、应急管理部共六部门印发的《城市标准化行动方案》载明：加快构建推动城市高质量发展的标准体系。为城市科学化、精细化、智能化治理提供有力支撑，助力提升城市韧性和可持续发展水平，加快推进城市治理体系和能力现代化。</p><p>在此背景下，“未来城市大奖”（Future City Awards）应运而生。</p><h2><strong>02</strong></h2><h2><strong>未来城市大奖宗旨与核心发起人</strong></h2><p>《城市标准化行动方案》的总体目标是，到2027年，基本建成具有中国特色的城市高质量发展标准体系，城市治理标准供给显著增加，标准协同和国际化程度显著增强，城市标准化发展基础更加牢固，标准化融入城市社会治理的基础性、战略性、引领性作用更加凸显。</p><p>“未来城市大奖”旨在寻找和发现在城市规划、建设、运营、治理等领域的杰出项目和模式，并推动社会关注、激发公众参与，同时希望通过这一奖项鼓励城市决策者采用创新技术和可持续方法，为城市提供多元的可行性发展方案。</p><p>大奖由中规院（北京）规划设计有限公司智慧城市团队提供权威学术支持、36氪获独家授权进行运营推广。核心发起人是来自中国城市规划设计研究院、清华大学、深圳大学等权威机构的七位城市发展领域专家、学者，他们长期关注城市化进程中的“未来议题”：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_e504006ce4594038a157e687ae5149c9@5288884_oswg1221889oswg1080oswg1633_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">未来城市大奖核心发起人</p><h2><strong>03</strong></h2><h2><strong>未来城市大奖2023年度评审团</strong></h2><p>经核心发起人举荐与遴选，以下来自城市规划、设计、建设、运营等领域的专家，将组成未来城市大奖2023年度评审团，参与本届大奖的评选活动：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_169f628b08b94230be92a959745ab779@5288884_oswg2058352oswg1080oswg2244_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">未来城市大奖年度评委</p><h2><strong>04</strong></h2><h2><strong>四大基础评价象限、三大评奖单元</strong></h2><p>核心发起人们一致认为，未来城市大奖将以“<strong>智慧、可持续、友好、在地”</strong>作为四大基础评价象限，同时设立三大评奖单元：“未来城市大奖-特别奖”、“未来城市大奖-解决方案单元”、“未来城市大奖-空间进化单元”。</p><p><strong>未来城市大奖-特别奖</strong></p><p>特别奖1席，将评选出<strong>年度未来城市样本</strong>，旨在表彰在本年度的未来城市创新的典型代表，通过前瞻性的科技创新和空间营建，以提升城市活力、人居环境品质和生活质量，实现高质量发展的实践案例。</p><p><strong>未来城市大奖-解决方案单元</strong></p><p>在解决方案单元将评出<strong>城市智慧应用奖、城市可持续创新奖、城市数字生活实践奖</strong>，单个奖项最终获奖项目不超过2席。其中：</p><p>城市智慧应用奖旨在表彰通过数字化、智能化的应用，解决城市普遍性、长期性的发展瓶颈的应用方案；</p><p>城市可持续创新奖旨在表彰通过绿色、低碳、可循环等手段，促进城市的自然、社会、经济、文化协调发展的创新方案；</p><p>城市数字生活实践奖旨在表彰通过前沿数字技术应用，改善居民日常生活便利度、提升居民城市发展成果获得感的实践方案。</p><p><strong>未来城市大奖-空间进化单元</strong></p><p>在空间进化单元将评出<strong>未来住区奖、城市更新奖、场景营造奖</strong>，单个奖项最终获奖项目不超过2席。其中：</p><p>未来住区奖旨在表彰在住区的传统功能之上，能够结合数字时代居民新需求与在地文化，以智慧化的手段，创新生活方式，提供更具前瞻性和想象力的生活空间；</p><p>城市更新奖旨在表彰优化和促进城市街区、社区、公共空间等各类空间更新、业态创新、功能升级的行动方案；</p><p>场景营造奖旨在表彰通过场景创新与内容共创，加强人与场所之间的联系，优化运营模式的项目与行为。</p><h2><strong>05</strong></h2><h2><strong>评选流程</strong></h2><p>经核心发起人组成的委员会研判，2023年度未来城市大奖的评选面向城区、园区、街区、社区等不同城市覆盖面的实体项目、创新模式、数字化解决方案。</p><p>所有参评项目都应已处于实际应用阶段，参评项目的应用领域、地区、范围不限，但原则上投入使用时间不超过3年。</p><p>具体评选流程如下：</p><p><strong>报名期：11月13日-11月24日</strong></p><p>在此期间开启项目自主报名、发起人及年度评审提名两种机制，参评项目提交介绍资料、拟参评奖项、参评主体机构、自主参评或者获得提名的理由。</p><p><strong>评选期 ：11月30日-12月13日</strong></p><p>经七位核心发起人与年度评审组成的评审团初评后，确定走访项目名单。全部项目走访完毕后，启动闭门评审会，进行各单元、各奖项的最终评选。</p><p><strong>颁奖：12月28日（拟定）</strong></p><p>举办线下颁奖典礼，对获奖项目进行表彰及传播&nbsp;。&nbsp;</p><p>*颁奖典礼后，陆续组织获奖项目的推广对接路演</p><p>-报名及提名通道&nbsp;</p><p>扫描二维码、提供参评资料</p><p><strong>-垂询邮箱&nbsp;</strong></p><p><strong>futurecityaward@sina.com</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_b778fa7a53e64f00b4fc8229ca31515a@5288884_oswg445481oswg1080oswg1920_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">扫码报名</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2519515249944326</id>
            <title>年营收暴涨1567%，黄仁勋为其站台，这家云厂商如何靠AIGC起飞？</title>
            <link>https://www.36kr.com/p/2519515249944326</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2519515249944326</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 01:36:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: CoreWeave, 融资, 云计算, 英伟达
<br>
<br>
总结: CoreWeave是一家云计算创企，近几个月来频繁获得大额融资，其中包括英伟达的参投。该公司以英伟达H100芯片为抵押获得23亿美元的债务融资，并签署了微软的算力大单。CoreWeave在短短4个月内完成了27.21亿美元的融资，估值达到80亿美元。作为英伟达的重要合作伙伴，CoreWeave在云计算领域有着独特的优势。 </div>
                        <hr>
                    
                    <p>近几个月来，一家美国云计算创企的名字——CoreWeave，频繁出现在公众视野中。&nbsp;</p><p>先是在4月，CoreWeave获得<strong>英伟达参投的2.21亿美元B轮融资</strong>，又在1个月后获得领投基金Magnetar Capital的<strong>2亿美元延期投资</strong>。&nbsp;</p><p>8月初，CoreWeave<strong>以英伟达H100芯片为抵押，获得23亿美元的债务融资</strong>。8月底，CoreWeave被曝正在寻求出售少数股份，<strong>估值或达80亿美元</strong>。&nbsp;</p><p>除了连续的大额融资外，CoreWeave还被曝获得微软的算力大单。6月2日，CNBC援引知情人士消息报道微软与CoreWeave签署了AI算力协议，<strong>微软将在未来几年向CoreWeave采购数十亿美元的云计算基础设施</strong>。&nbsp;</p><p>CoreWeave创始人之一McBee在今年8月的采访中透露，2022年，该公司营收为3000万美元，<strong>2023年将达到5亿美元，同比暴涨1567%</strong>。而明年，CoreWeave已经签署了<strong>近20亿美元的合同</strong>，目前正在建设<strong>12个不同的数据中心</strong>，预计将实现<strong>约15亿美元的营收</strong>。&nbsp;</p><p>成立于2017年的CoreWeave，起初是一家加密货币挖矿公司，后在2019年转型成为云服务提供商。随着近年来生成式AI浪潮风靡全球，CoreWeave也摇身一变成为算力新秀，坐拥数万块芯片狂揽算力大单。&nbsp;</p><p><strong>在H100一卡难求的情况下，CoreWeave能够成为首批供应商之一，与亚马逊、谷歌、微软、甲骨文等云巨头站在同一位置，可见英伟达对它的看重。</strong></p><p>打开CoreWeave官网首页，可以看到英伟达为其背书：“CoreWeave是英伟达的重要合作伙伴……英伟达是CoreWeave的支持者，我们为此感到自豪。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_c1b513dd13c942e493d4506ba18c143b@000000_oswg121994oswg1000oswg428_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲英伟达为CoreWeave“站台”（图源：CoreWeave官网）</p><p>那么，CoreWeave是如何从一家“挖矿”公司起家，摇身成为AI算力新秀的？它为什么能得到英伟达的“偏爱”？与其他云厂商相比，它有什么不同之处？让我们从CoreWeave的发展历程来探知答案。&nbsp;</p><h2><strong>01 黄仁勋亲自站台，4个月融资近200亿</strong></h2><p>CoreWeave的联合创始人兼首席战略官Brannin McBee称，几个月前，可能还很少有人听说过这家公司。而现在，CoreWeave“准备从生成式AI热潮中赚取数十亿美元”。&nbsp;</p><p>打开企业数据库Crunchbase可以看到，从今年4月至8月，<strong>短短4个月内，CoreWeave完成了三笔共27.21亿美元（约合198亿人民币）的融资</strong>。据彭博社8月底报道，CoreWeave正在寻求出售少数股份，<strong>其最新估值达到80亿美元（约合582亿人民币）</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_2d2c14ea0bd94b52b8d2b4e32cae70b6@000000_oswg54500oswg1000oswg214_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲CoreWeave今年的融资情况（图源：Crunchbase）</p><p>虽然英伟达只参与了其中4月进行的B轮融资，但在8月初官宣的债务融资中，CoreWeave拿出了当下高度抢手的英伟达H100芯片作为抵押品，似乎在宣告自己的“特权”。&nbsp;</p><p><strong>英伟达CEO黄仁勋也对CoreWeave赞不绝口。</strong>在2023年8月23日的财报电话会议上，黄仁勋谈道，未来，投资数据中心的最佳方式就是从通用计算转向生成式AI加速计算，“你会看到一大批新的GPU专业云服务提供商，CoreWeave就是其中很有名的一家，他们的表现好到令人难以置信”。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_0e8d71f0e92544c7861a83915232106a@000000_oswg795267oswg1000oswg446_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲2023年8月SIGGRAPH 2023大会上，黄仁勋出现在CoreWeave展位（图源：CoreWeave）</p><p>英伟达对CoreWeave的“偏爱”或许可以追溯到三年前。&nbsp;</p><p>早在2020年9月，CoreWeave便宣布加入英伟达合作伙伴网络（NPN）内的云服务提供商（CSP）计划，将GPU加速引入云端为分散的劳动力提供支持。&nbsp;</p><p>在NPN计划中，英伟达将合作伙伴分为注册、优选、精英三个级别。<strong>2021年7月，CoreWeave宣布成为NPN计划中首个计算领域的精英CSP</strong>，这意味着CoreWeave可以抢先体验英伟达产品和技术，并获得解决技术问题的专用支持渠道。&nbsp;</p><p>英伟达云计算和战略合作伙伴全球业务开发总监Matt McGrigg称，将CoreWeave命名为首个计算领域的精英合作伙伴，体现了他们利用英伟达广泛的计算资源为AI、ML（机器学习）、HPC（高性能计算）和渲染用例提供世界级解决方案的能力。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_9f5a6e1c277d4aabadac6c51777c1a9d@000000_oswg77086oswg1000oswg238_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲英伟达NPN计划对合作伙伴的等级划分</p><p><strong>2022年11月，CoreWeave宣布成为首批提供采用英伟达H100超级计算机云实例的供应商之</strong>一，其他首批供应商包括亚马逊、谷歌、微软、甲骨文等。CoreWeave宣称，与大型通用公共云相比，其定价可为客户节省高达80%的费用。&nbsp;</p><p><strong>2023年6月，CoreWeave与英伟达共同刷新了MLPerf基准测试的记录</strong>，通过3584个H100集群，在CoreWeave云上仅用了11分钟就完成了基于GPT-3的大规模基准测试。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_a132e4e66ef946de9333dbf361e0074b@000000_oswg59677oswg1000oswg494_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲英伟达AI和H100在大规模应用中创下的纪录</p><h2><strong>02 挖矿起家、转型AI，2018年已拥有5万个GPU</strong></h2><p>CoreWeave成立于2017年，创始团队包括Michael Intrator、Brian Venturo和Brannin McBee。据领英页面显示，三人都曾从事过金融行业的工作。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_18200dd9388b4671885ceed6cca907ef@000000_oswg510607oswg1000oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲从左到右依次是Intrator、Venturo、McBee</p><p>Intrator担任CoreWeave首席执行官，负责公司运营的各个方面。在创办CoreWeave之前，他曾创办了一家天然气对冲基金公司。今年8月，他曾入选外媒The Information评选的企业软件领域最具影响力人物Top 30。&nbsp;</p><p>Venturo担任CoreWeave首席技术官，此前从事能源投资相关工作，曾在Intrator的天然气对冲基金公司工作了5年。&nbsp;</p><p>McBee担任CoreWeave首席战略官，他在云计算和数据分析方面拥有丰富的专业知识。在创办CoreWeave之前，他从事过金融分析师、自营交易员等职业，还拥有能源研究和咨询背景。&nbsp;</p><p>Intrator在2021年的一篇博客中写道，<strong>2016年，他们购买了第一块GPU并插上电源</strong>，在曼哈顿下城一间办公桌的台球桌上，成功在以太坊网络上开采了第一个区块。&nbsp;</p><p>这原本是一个“有趣的”下午，然而随着2017年早期加密货币热潮的来袭，他们的业余爱好也变成了事业。不久之后，三人成立了Atlantic Crypto，也就是CoreWeave的前身。&nbsp;</p><p>在筹集了几笔小额早期的投资，采购了一些“投机性”的硬件设备后，台球桌变成了车库，成为他们在新泽西州的第一个数据中心。&nbsp;</p><p>随后，CoreWeave在2018至2019年间“战略性”地收购硬件，GPU数量扩充到数万个。&nbsp;</p><p>很快，CoreWeave接到了大量的企业订单。这些企业都依赖于GPU加速，但面临着传统云服务商价格垄断、计算种类有限，因此难以扩展的痛点。&nbsp;</p><p>McBee在接受彭博社时谈道，<strong>在2018年末，他们已经拥有超过5万个GPU</strong>，占以太坊网络的1%以上。&nbsp;</p><p><strong>2019年，CoreWeave开始转向构建专门的云基础设施。</strong></p><p>据McBee称，他们发现用于加密货币挖矿的旧式零售级GPU设备，并不适合用于运行企业级工作负载，不能支持全球最大的AI公司，因此<strong>转向只专注购买英伟达提供的企业级GPU芯片组，包括A100、H100等，并将围绕这些芯片调整公司业务</strong>。&nbsp;</p><p>2021年11月，CoreWeave获得Magnetar Capital的5000万美元投资时，对自己的定位是<strong>“专为英伟达GPU加速工作负载而打造的专业云提供商”</strong>。&nbsp;</p><p>虽然事后来看，CoreWeave的转型出于偶然，但随着AI的飞速发展，市场对GPU算力的需求指数级增长，CoreWeave也乘上这辆顺风车。&nbsp;</p><p>今年8月，McBee在接受VentureBeat采访时透露，2022年，CoreWeave营收为3000万美元，2023年将达到5亿美元，而明年已经签署了近20亿美元的合同，目前正在建设12个不同的数据中心。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_cf91dd36c6c549eb9bab3f9d7aa7aa9d@000000_oswg107796oswg1000oswg434_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲位于德克萨斯州的CoreWeave数据中心</p><h2><strong>03 手握H100挑战云巨头，CoreWeave为何受到英伟达青睐？</strong></h2><p>作为一家初创企业，CoreWeave在云服务市场能得到的市场份额并不高。根据德国在线统计数据门户Statista今年2月发布的报告，AWS、微软Azure和谷歌云长期占据60%以上的市场份额。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_23408c0facaa4574a678992a3b5ad28a@000000_oswg275638oswg1000oswg596_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲2017-2022年全球云基础设施服务供应商市场份额（图源：Statista）</p><p>从收入来看，AWS、Azure和谷歌云去年的营收分别为801亿美元、753亿美元和263亿美元。&nbsp;</p><p>显然，这些数字是CoreWeave去年营收的数百甚至数千倍。&nbsp;</p><p><strong>我们不禁发问，CoreWeave为何在一众云巨头中脱颖而出，如此受到英伟达的青睐？</strong></p><p>根据多家外媒的分析，以及McBee在接受彭博社采访时的回答，CoreWeave的“受宠”主要有以下几个方面的原因：&nbsp;</p><p><strong>首先，从英伟达的角度来看</strong>，McBee认为对英伟达而言，最重要的是让其最终用户能够以最高效、最快速的方式大规模地访问其计算。&nbsp;</p><p>CoreWeave按照DGX参考规格进行基础设施构建，并且在新一代芯片组发布后的几个月内将其上线，而不像传统的超大规模数据中心一样花费几个季度的时间。&nbsp;</p><p>McBee称，正因为能做到这一点，才使CoreWeave在英伟达内部获得了极佳的资源分配。CoreWeave的商业理念是承诺较低，交付较高，这使得英伟达有信心将基础设施分配给他们。&nbsp;</p><p><strong>其次，在与云巨头的竞争方面</strong>，AWS、微软和谷歌在过去几年花费了数十亿美元来开发自己的芯片，以支持其云计算业务和内部项目，减少对英伟达的依赖。这使得云巨头与英伟达存在产品上的潜在竞争关系。&nbsp;</p><p>据The Information报道，AWS曾建议一些公司在无法访问英伟达GPU时租用由其定制芯片Trainium提供支持的服务器。谷歌云向其客户出租定制TPU芯片，AI创企Midjourney曾表示，它一直在使用基于云的TPU来训练其机器学习模型。&nbsp;</p><p>相比之下，CoreWeave对英伟达构成的威胁较小，因为它不设计自己的芯片。&nbsp;</p><p><strong>此外，与云巨头的产品差异化</strong>，也是CoreWeave有力的竞争优势之一。据McBee称，通过基础设施、软件等的差异化，在工作负载调整基础上，CoreWeave能提供“相对任何超级大厂而言，效率提高大约40%至60%的产品”。&nbsp;</p><p>不过，英伟达的AI创企投资版图上，CoreWeave也不是唯一一家云服务提供商。&nbsp;</p><p><strong>与之类似的，还有一家深度学习基础设施公司Lambda Labs。</strong></p><p>Lambda Labs成立于2012年，同样于2019年左右转型为AI计算提供商。从规模来看，Lambda比CoreWeave要小。据Crunchbase数据显示，它目前共获得6轮融资，总金额为1.122亿美元。&nbsp;</p><p>与CoreWeave不同的是，Lambda主要专注于On-demand的AI训练市场。&nbsp;</p><p>大量科研机构、SMB（中小企业业务）以及开源社区需要几百或一千张左右的A100或H100来进行一些大模型的尝试，相对于比头部公司，这类型客户的特点是订单持续时间较短，中短期内需求量大，订单不确定性较高。Lambda的优势在于定价足够友好。&nbsp;</p><p><strong>而Coreweave凭借早期与Inflection等核心AI公司的合作获得了极高供货优先级。</strong></p><p>在<strong>2023年初，Coreweave便找到Inflection，为其提供几千张H100</strong>。英伟达看中了这个组合中的巨大潜力，先后向两家公司投资数亿美元，并<strong>通过抬高Coreweave的H100的供货优先级来为Inflection提供2.2万张H100</strong>。&nbsp;</p><p>McBee称，对于像Inflection这样的客户，CoreWeave会制定大型构建的时间表，然后向英伟达解释自己正在做什么。而英伟达会说：“我们会在工程设计、市场营销、基础设施、分配等方面为你提供支持，无论你需要什么，我们都会帮你完成。”CoreWeave要做的就是执行。&nbsp;</p><p>值得一提的是，今年9月，CoreWeave任命Mike Mattacola为首席商务官，负责新市场的增长和扩张，而Mattacola此前曾在Lambda就职一年多，担任首席运营官。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231115/v2_2b96de20507a4e99a2ca2ea4dfa46e19@000000_oswg46119oswg1000oswg332_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Mike Mattacola近期的工作经历（图源：领英）</p><h2><strong>04 结语：时势造“英雄”，AIGC成为云计算新秀跳板</strong></h2><p>现在，CoreWeave几乎成为AI领域人尽皆知的名字，它的扩张之路也在继续，计划在生命科学等行业占据一席之地，涉及药物发现、蛋白质折叠模拟、分子发现和基因测试等领域。&nbsp;</p><p>虽然乘上AI顺风车是“偶然”，但CoreWeave也顺应时代和技术热潮及时做出了正确的业务战略决策。&nbsp;</p><p>坐拥Inflection等大客户、背靠英伟达，CoreWeave的未来看起来一切向好。不过，据The Information报道，CoreWeave可能面临快速增长的“痛苦”，指出其在8月下调了今年的预计收入和资本支出。&nbsp;</p><p>未来，CoreWeave能否在AI算力领域一路高歌，也许要看Inflection在下一代模型竞争中的表现，或是能否押注到另一家重要客户。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652765057&amp;idx=1&amp;sn=393beeaff74efdf3776686eddc31e5d6&amp;chksm=847d6c8fb30ae599c595a21afbc93665bba3c50fa052ca6844fc2b860f3f2c72647654d78e8a&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：香草，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2520183795164679</id>
            <title>微软，用最开放的云，玩最野的 AI</title>
            <link>https://www.36kr.com/p/2520183795164679</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2520183795164679</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 01:35:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, AI, 云计算基础设施, Copilot
<br>
<br>
总结: 微软以AI为中心，通过推出多项新产品和新功能，将自己从一家商业软件公司转变为全球最开放、野心最大的AI公司。微软在云计算基础设施方面进行了全栈升级，包括驱动AI模型的云计算基础设施、基础模型、数据工具链和Copilot等。微软还与合作伙伴进行了广泛合作，改进了基础设施，包括使用可再生能源、中空芯光纤技术和芯片创新等。 </div>
                        <hr>
                    
                    <p>你几乎很难想象，那个困于混合现实和量子计算，在 B 端和 C 端都乏善可陈的巨头微软，能在短短一年时间之内脱胎换骨，成为整个硅谷，不，乃至全球最潮的科技公司。&nbsp;</p><p>点燃这家老牌公司的，无他，只有两个字母——AI。&nbsp;</p><p>当地时间 11 月 15 日，在其大本营美国西雅图，微软公司 CEO 萨提亚·纳德拉在 Ignite 大会上，<strong>一口气公布了 100 多项以&nbsp;AI&nbsp;为中心，在云计算基础设施、 模型即服务 MaaS 、数据平台、Copilot 人工智能助手等方方面面的新产品和新功能</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_06f2afe5cc404c0ba7b4a338c8d3ba1c@000000_oswg486532oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">萨提亚展示 Azure Cobalt CPU 芯片｜Microsoft&nbsp;</p><p>其中，既有 Azure Cobalt、Azure Maia 这样专门为 AI 打造的 ARM 架构 CPU 和 AI 加速芯片，也有重新为 AI 设计的端到端机架，微软甚至重新改进了线缆中的光纤技术，只为了比特传输更加快速。&nbsp;</p><p>就在你以为微软要用自研处理器，免交「英伟达税」时，纳德拉不仅请来了英伟达创始人黄仁勋进行「商业互吹」，而且<strong>将 AMD 、英伟达最新的处理器纳入 Azure 云服务，让后者在&nbsp;AI&nbsp;时代成为最 Open 的「世界计算机」</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_bfa3821a72bc4161b12b3e9f0473813f@000000_oswg247614oswg1080oswg709_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">OpenAI 开发者大会上 Sam Altman 和萨提亚开了个小玩笑｜OpenAI&nbsp;</p><p>两周前 OpenAI 的开发者大会上 ，Sam Altman 把纳德拉请上台后第一句话就是：「你说说咱俩家关系是怎么滴了？」直接把自己最大的「金主爸爸」整笑了。今天的微软自己的场子上，PPT 背板上写着的「微软爱 OpenAI」算是纳德拉对 Altman，以及业界对于两家关系「表面和气背地竞争」质疑的回敬。&nbsp;</p><p>「<strong>我们承诺，所有&nbsp;OpenAI&nbsp;的创新，都将成为 Azure&nbsp;AI&nbsp;的一部分，提供给大家</strong>。」纳德拉的演讲，再次证明微软和 OpenAI 亲密无间的关系。而价格更低能力更强的 GPT-4 Turbo 也如愿来到微软的 AI 服务之中。&nbsp;</p><p>同时，Copilot Studio，类似于 OpenAI 的 GPTs，让用户可以一句话生成自己的 GPT。而且，不论是 Copilot 还是 GPTs，都可以作为插件在人工智能助手页面使用。&nbsp;</p><p>「Copilot 将是新的交互界面，帮助人们接触现实世界和组织内的知识；更重要的是，它还是你的智能体，帮助你在这些知识的基础上做行动。」&nbsp;</p><p>一年之前，微软还是一家商业软件公司；<strong>一年之后，微软成为了一家「Copilot」公司，一家全球最开放，野心也最大的&nbsp;AI&nbsp;公司</strong>。&nbsp;</p><h2><strong>01 自研芯片曝光，最「AI」的云基建</strong></h2><p>不同于今年 3 月微软初次展现 Copilot demo 时的炫酷，在今天的大会上，纳德拉强调落地。他说：「我们正在进入人工智能的一个令人兴奋的新阶段，不仅仅是将其视为新奇的技术，而且还涉及到产品制造、部署、安全性、真正的生产效益以及所有与现实世界有关的细节。&nbsp;</p><p>迈入 Copilot 时代的微软，打造了端到端 Copilot 堆栈，包括：基础设施、基础模型、数据工具链，以及 Copilot 本身。<strong>基于这一新的堆栈，纳德拉依次介绍了再次「刷新」的微软</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_312eb86802974498bd199a30f9bf4679@000000_oswg773192oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">纳德拉在 Ignite 主旨演讲中，依次介绍微软的 Copilot 堆栈｜Microsoft&nbsp;</p><p>首先是最底层的堆栈——驱动 AI 模型的云计算基础设施。作为 OpenAI 的独家云供应商，这一身份无疑让微软云 Azure 迅速进化为，大模型工作负载下更适配的云。这一结果背后，<strong>是一个最开放的平台公司，做出的全栈升级。从能源、数据中心、网络、CPU 和 AI 加速器等方面，微软与广泛的合作伙伴再造基础设施</strong>：&nbsp;</p><p>用可再生能源为数据中心提供动力；</p><p>用新材料——中空芯光纤技术为数据中心的网络进一步提速；</p><p>Azure Boost 系统正式上线，它可以将存储和网络进程从主机服务器转迁移到专用硬件和软件上，从而提高存储和网络速度；</p><p>以及最重要的，芯片相关的创新与合作。</p><p>纳德拉兴奋地总结称，「看到我们作为一家超级计算机公司，了解工作负载，据此获得机会优化整个堆栈，从能源消耗到硅片，以最大化性能和效率，真的很感谢这个闭环（feedback cycle）」。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_5b58f2d550d647cb8e416aefc398eb13@000000_oswg505165oswg1080oswg616_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">萨提亚发布 AI 加速芯片 Azure Maia｜Microsoft&nbsp;</p><p>紧接着，他宣布了数据中心期待已久的重磅发布：<strong>第一款定制的自家 CPU 系列 Azure Cobalt 和AI加速芯片 Azure Maia</strong>。&nbsp;</p><p>Microsoft Azure Cobalt 是一款基于 Arm 架构的云原生芯片，针对通用工作负载的性能、功率和成本效益进行了优化。纳德拉称，这款 CPU 芯片已经在支持 Microsoft Teams Azure 通信服务以及 Azure SQL 的部分中使用；明年也将向客户提供这款产品。&nbsp;</p><p>Microsoft Azure Maia 是一款 AI 加速芯片，用于 OpenAI 模型、Bing、GitHub Copilot 和 ChatGPT 等 AI 工作负载运行云端训练和推理。这款芯片采用了 5 纳米工艺制造，拥有 1050 亿个晶体管。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_2514ada2197946c5861afbdfbbd91938@000000_oswg28675oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Azure Maia 100 &nbsp;美颜照｜Microsoft&nbsp;</p><p>纳德拉称，「硅多样性（sillicon diversity）是我们能够支持世界上最强大的基础模型和所有 AI 工作负载的关键因素」，在本次 Ignite 技术大会上，微软不仅发布了两款自研芯片，也纳入了更多行业合作伙伴的最新 AI 优化芯片，包括 AMD Instinct MI300X，以及英伟达 H100 和 H200。&nbsp;</p><p>在上述超级计算机之上，<strong>微软还提供参数量从数十亿到数万亿不等的基础模型，来满足不同开发者构建AI应用程序时的成本、延迟和性能需求</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_b4d750066fe640c097fa7648958045d0@000000_oswg298712oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">GPT-4 Turbo 毫无疑问将来到 Azure &nbsp;平台｜Microsoft&nbsp;</p><p>当然，OpenAI 的更新，会作为 Azure AI 的一部分持续交付。最新的 GPT-4，包括 GPT-4 Turbo 与视觉功能将引入 Azure OpenAI 服务。GPT-4 Turbo 将于 2023 年 11 月底在 Azure OpenAI 服务中公开预览，定价将与 OpenAI 保持一致。GPT-4 Turbo with Vision 即将推出预览版，DALLE·3 现已在 Azure Open AI 服务中公开预览。&nbsp;</p><p>另外，Azure OpenAI 服务，将引入 GPT-4 的微调功能，允许客户使用自己的数据创建 GPT-4 的自定义版本。&nbsp;</p><p>除了闭源模型，<strong>微软还扩大了开源模型的 MaaS 服务，让专业开发者将能够轻松将Stable Diffusion、Meta Llama 2 、Mistral 即将推出的高级模型以及 G42 Jais 等最新的AI模型，通过API集成到他们的应用中</strong>；还可以用自己的数据定制这些模型，而无需担心 GPU 基础架构的设置和管理。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_0c7d9043ffd0487e9ad0707057c8629e@000000_oswg485627oswg1080oswg599_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">萨提亚发布 Azure AI Studio｜Microsoft&nbsp;</p><p>在基础模型之上，微软从工具层面进一步降低开发者的使用门槛——通过推出 Azure AI Studio，微软向客户提供完整的生命周期工具链，使其能够构建、定制、训练、评估和部署最新一代模型。值得注意的是，它还包括内置的安全工具，通过 Azure AI Studio，客户可以检测和过滤应用程序中以及服务中生成的有害内容。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c2e410974c79497a9e5dcde1dce92ee2@000000_oswg62546oswg1000oswg560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">萨提亚和黄仁勋在台上讨论生成式 AI 将带来的巨大变革｜Microsoft&nbsp;</p><p>「AI 和加速计算是一个全栈挑战，也是一个数据中心规模的挑战。」从底层硬件到上层软件，微软不仅提升自己的能力，也引入了强大的伙伴。在 Ignite 大会上，<strong>纳德拉和黄仁勋宣布两家公司的合作不止于硬件，在软件上也将强强联合——英伟达的 AI 代工厂（Nvidia AI Foundry）服务正式引入 Azure</strong>。&nbsp;</p><p>英伟达的基础模型、框架、工具以及其 DGX Cloud AI 超级计算和服务汇集在一起，向 Azure 用户创建生成式 AI 模型提供端到端的解决方案。企业客户可以在 Azure 上利用英伟达 AI Enterprise 软件部署其模型，为生成式 AI 应用——如智能搜索、总结和内容生成等，提供助力。&nbsp;</p><h2><strong>02 数据驱动，微软 AI 的 B 端核心</strong></h2><p>从上述硬件和软件的基础设施再往上一层，是数据。可以说，没有数据就没有人工智能。在这次大会上，<strong>纳德拉重点介绍了在今年 5 月 Build 开发者大会上首次推出了数据平台——Microsoft&nbsp;Fabric</strong>。自发布以来，Fabric 已经进行了 100 多项功能更新，并与合作伙伴一起扩展了生态系统，目前已经有包括 Milliman、蔡司、伦敦证券交易所和安永在内、超过 25000 家客户使用。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_8299a7a6dedb4bd2a690d5557d0e67b4@000000_oswg514576oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Microsoft Fabric 是 AI 商业端解决方案的核心功能｜Microsoft&nbsp;</p><p>微软团队希望创造一种集成、简化的体验，将客户数据和微软的 AI 工具连接起来，Microsoft Fabric正是该解决方案的一部分。&nbsp;</p><p><strong>Microsoft Fabric 的核心是「统一」，用一个产品、一种体验、一种架构、一种业务模型汇集了所需的所有数据和分析工具</strong>，包括数据工程、数据集成、数据仓库、数据科学、实时分析、应用可观察性和商业智能。&nbsp;</p><p>通过 Fabric 的「数据湖」，企业团队可以从任何地方连接到数据，并在不同引擎之间使用相同的数据副本。这些智能数据可以安全地流向人们每天使用的 Microsoft 365 应用程序，以改善决策并产生影响。<strong>Copilot in Microsoft Fabric 还可以与 Microsoft Office 和 Teams 集成，培养数据文化，从而在整个企业内加大利用数据价值</strong>。&nbsp;</p><p>Microsoft Fabric 现已开放使用，它通过将每个人汇集到一个由 AI 驱动的平台上，在企业级数据基础上统一所有数据资产，重塑团队处理数据的方式。&nbsp;</p><h2><strong>03 微软 Copilot，也能「一键生成 GPT」了</strong></h2><p>在应用这一层级，Copilot 全面迎来了自己的时代。&nbsp;</p><p>在 Ignite 2023 大会上，微软宣布 Bing Chat 和 Bing Chat for Enterprise 现在将更名为「Copilot」，并发布了「Copilot Studio」，可定制 Copilot，或构建独立的协同助手，包括自定义的 GPT、生成式 AI 插件等，可以自定义主题。&nbsp;</p><p>在使用方面，<strong>Copilot Studio 可以在同一网页中构建、部署、分析和管理所有内容，通过使用拖放的低代码方法，包括逻辑和数据连接，直接构建和发布插件到适用于 Microsoft 365 的 Copilot</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_c732606f120b48caa9c72608181553dc@000000_oswg271456oswg1080oswg631_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Bing Chat 正式更名为 Copilot｜Microsoft&nbsp;</p><p>微软称，无法轻松找到所需信息是工作者在日常工作中面临的前五大问题之一。这些插件基于用户的数据和流程，通过聊天形式对话，能够回答基于用户的业务数据和流程的问题。&nbsp;</p><p>对于企业用户来说，用户能够为特定的企业场景定制 Copilot，从客户关系管理（CRM）到企业资源规划（ERP）到人力资源（HR），Copilot 能够回答类似「我的休假余额是多少？」或「我有没有要提交的费用？」等问题。&nbsp;</p><p>除了能够定制适用于 Microsoft 365 的 Copilot 外，微软还支持创建和发布独立的自定义协同助手，还支持无缝集成 OpenAI 的服务，很快，<strong>创作者将能够在 Copilot Studio 中构建自己的定制 GPT</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_9ebcfc6d2f6e4dd1b295b897d4507938@000000_oswg553186oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Copilot Studio 能让用户一键生成 AI 助手，并且看起来比 GPTs 正式很多｜Microsoft&nbsp;</p><p>这种独立的协同助手可以无缝发布到内部和外部网站、移动应用程序等多个渠道，例如，可以在公共网站上为外部客户提供协同助手，找到适合他们需求的产品。&nbsp;</p><p>在后台，Copilot Studio 还有内置的分析仪表板，管理员能够集中监视使用情况并进行分析，在管理中心内控制访问权限，使用公司特定政策保护数据，管理环境等。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_ccef441645694a959e62d50a3fbf2919@000000_oswg850128oswg1080oswg590_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">微软在 Dynamics 365 Guides 引入 Copilot，将生成式 AI 与混合现实结合｜Microsoft&nbsp;</p><p>另外，<strong>微软还在 Dynamics 365 Guides 引入 Copilot，可以简单理解为一种AR&nbsp;Copilot</strong>，这意味着，能用 AI 的不再只是办公室的白领了，还有蓝领。它可以让工业环境中的工人使用语音和手势，提出有关复杂机械的问题，以及进行维护。&nbsp;</p><p>微软的 HoloLens 混合现实头戴设备允许他们指向设备和零件，然后提出关于从组件规格到机械服务日志的各种主题的问题。然后，微软的系统可以通过全息图、文本显示和语音响应提供答案。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231116/v2_fd6bf454db574054b958044babe517d1@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「一切为了 AI，为了 AI 的一切。」用这句话形容今天的微软 Ignite 大会，并不算夸张。在 GPT-4 和大语言模型彻底搅动了世界之后，看到机会的微软，成为转身动作最快的巨头。&nbsp;</p><p><strong>如果说之前微软还是在产品层面进行「AI&nbsp;集成」，现在它已经在硬件设施、云计算和商业服务的全生态层级，围绕 AI 进行了革新</strong>。只要 AI 浪潮继续推进，微软就会是那个最领先、最具有前瞻性和决策力的巨头。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653021572&amp;idx=1&amp;sn=3baee76c2328c635b7e2cf65e877ba6e&amp;chksm=7e54983249231124d62faf9a5799e41ad0b1007aabf5740d7357f6620dd144e3011fbcde5403&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：宛辰、芯芯，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>