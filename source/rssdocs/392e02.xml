<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3157805591010051</id>
            <title>DeepSeek的华丽文风是怎样炼成的？</title>
            <link>https://www.36kr.com/p/3157805591010051</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157805591010051</guid>
            <pubDate></pubDate>
            <updated>Sun, 09 Feb 2025 04:00:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AGI, DeepSeek, 内容生成, 文风  
<br>
<br>
总结: 知名投资人朱啸虎在体验DeepSeek后，改变了对AGI的看法，认为其在内容生成方面表现优美且深刻。DeepSeek的易用性使得普通用户能够轻松使用AI对话产品，且其生成的内容展现出拟人化特征。DeepSeek的成功在于其独特的文学增强型数据生态和高人才密度，推动了模型的自我进化和反思能力。尽管DeepSeek的文风受到喜爱，但也引发了对其内容准确性和潜在幻觉现象的警惕。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_21b9dcd7d6f9493b89de7fe27cc20eb5@000000_oswg132213oswg1014oswg876_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>去年还不相信AGI（通用人工智能）投资叙事的知名投资人朱啸虎，在被DeepSeek支配了一整个春节后，态度大变，“DeepSeek快让我相信AGI了。”</p>
  <p>在近期接受腾讯新闻采访时，朱啸虎多次惊叹于DeepSeek在内容生成方面的优美和深度。</p>
  <p>不止朱啸虎。在DeepSeek以假乱真，模仿梁文锋口吻回复冯骥的“国运论”造假文章出现后，作家兼脱口秀演员的李诞点评道，文章透露出一种非常DeepSeek的味道。这种味道被李诞概括为“科技抒情散文诗”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_6bf4f6bd412649f49de562abb046a867@000000_oswg553764oswg831oswg1345_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>更重要的是，在优美和深度之外，DeepSeek让更多普通人第一次体会到了AI对话产品的易用性。</strong></p>
  <p>在此之前，用户想要让ChatGPT等AI对话产品输出更准确的答案，往往需要学习一套较为复杂的Prompt（提示词）技巧，但在DeepSeek上面，用户只需要输入简单的自然语言，就能够得到相对准确的答复，且这些答复还能呈现出拟人化的特点。</p>
  <p>DeepSeek对人类情感价值的精准拿捏，一度使得其凭借“阴阳怪气”中文十级的表现，收获了“赛博嘴替”的美名。</p>
  <p>飙涨的用户数据，成了外界追捧DeepSeek的另一力证。AI产品榜的一份统计数据显示，DeepSeek应用在上线20天后，其DAU（日活用户）便突破了2000万，距离成为国内日活用户数第一的AI对话应用，指日可待。</p>
  <p>尽管DeepSeek坚持开源路线，但在其引发热议的R1最新模型上，<strong>DeepSeek尚未公开其预训练语料，这也使得外界好奇其优美华丽的文风，究竟是怎么训练出来的。</strong></p>
  <p>字母榜（ID：wujicaijing）首先把这个问题抛给了 DeepSeek，它从风格化数据蒸馏体系，动态风格迁移架构，对抗式强化学习框架等维度给出了自己的解释。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_08303663e4594f318b763ed89c13f9b1@000000_oswg95392oswg844oswg625_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>紧接着，字母榜又尝试让国内月活用户排名前三的大模型（DeepSeek除外）回答了下，它们给出了一个共同原因是，DeepSeek可能在语料选择上用了更多文学小说素材。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_608ea1edcd8942918956d8953fb02f8e@000000_oswg337279oswg830oswg498_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>就连朱啸虎也揣测，这可能跟DeepSeek团队喜欢优美的文字，喜欢哲学、量子力学等有关。</p>
  <p>DeepSeek的文艺青年气质，或许能从他们在宣布下场追逐AGI的宣言中略窥一二。2023年4月，幻方量化（DeepSeek母公司）在发布做大模型公告时，引用了法国新浪潮导演特吕弗曾告诫青年导演的一句话：“务必要疯狂地怀抱雄心，且还要疯狂地真诚。”</p>
  <p>在国内从事大模型创业的李振（化名），也做过类似的文风对比，“就是风格控制的颗粒度不同。<strong>其他国内大模型产品，在文学向标签上可能都没有DeepSeek多。”</strong>李振告诉字母榜，在文学语言占比上，据其推测，国内其他大模型，可能在语料库中的比例维持在10%-20%，DeepSeek则可能高达40%。</p>
  <p>除了数据来源不同之外，<strong>如何使用数据同样会影响大模型产品的内容生成效果。</strong>《生成式人工智能》作者、人工智能商业化专家丁磊博士，特意提到了DeepSeek R1模型中所展现的“aha moment”顿悟时刻，即模型学会了反思，“这证明了其不断增长的推理能力，也说明了强化学习可以带来复杂甚至意想不到的结果。”</p>
  <p>无论是对风格控制颗粒度的认知细化，还是“aha moment”顿悟时刻的到来，这背后都少不了DeepSeek的高人才密度支持。</p>
  <p>在人才方面的高密度和高自主性，被参与大模型投资的恒业资本创始合伙人江一视为是DeepSeek生成优美华丽文风的第一因素。“相比而言，部分大模型公司的员工，在自主性上不够开放，使得在大模型产品研发上更多呈现出靶向性的特征，最终的生成效果就显得中规中矩。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_4aa8839b70ad4952b75f1152f2820d14@000000_oswg7381oswg681oswg681_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepSeek的内容生成优势之一，在于构建了一个比较独特的文学增强型数据生态，即<strong>把自然语言生成转化成一个可控的风格系统，从而使得可以把文学创作领域的专业评价体系转化成相对应的函数，</strong>进而构建起一个风格表征的数学建模。</p>
  <p>为了达成上述效果，相比国内其他大模型，DeepSeek在数据标签上就需要做得更细更多样化。这也是国内大模型创业者李振感慨DeepSeek文学向标签更多的原因所在。</p>
  <p>去年3月，在受邀参加英伟达GTC 2024大会时，DeepSeek研究员便围绕“大模型价值观和人类价值观对齐”的主题，发表过一篇《和而不同：大语言模型价值观对齐解耦化》的演讲，其中提到<strong>DeepSeek构建了一个跨学科的专家团队，</strong>对不同社会背景人群的价值观的公约数进行了分类学研究，从而构建了一个三级标签的价值观分类体系。</p>
  <p>人工智能商业化专家丁磊博士告诉字母榜，<strong>数据标注之外，前期的数据质量对模型训练至关重要，</strong>“DeepSeek在长思维链数据的收集和标注、推理和非推理数据的质量等方面，都有独到之处。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_7e3ce3018a7c4437a5609a90ddc796a4@000000_oswg487870oswg830oswg623_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>根据官方公开的技术报告，在获取高质量数据方面，R1模型使用了数据蒸馏技术（Distillation）生成的高质量数据，提升了训练效率。这也是DeepSeek能够凭借更小参数量，就实现比肩OpenAI o1模型性能的一大关键。</p>
  <p>丁磊博士进一步解释道，模型参数量大小与最终模型呈现的效果之间，两者“投入产出并不成正比，而是非线性的……数据多只是一个定性，更重要的是考验团队数据清洗的能力，否则随着数据增多，数据干扰也将随之变大。”</p>
  <p>谷歌就是前车之鉴。不管从算力还是算法，谷歌并不比OpenAI差，甚至还要强，但恰恰是借助基于人类反馈的强化数据训练工作，OpenAI最终赶在谷歌前面做出了ChatGPT。</p>
  <p>即便在ChatGPT已经诞生2年多后的当下，业内部分大模型公司，依然存在在数据训练环节投机取巧的行为，比如<strong>“采用数据注水的手段，将还没进行标注的数据，直接投喂给大模型。”</strong>李振说道。</p>
  <p>甚至在李振看来，不同的数据处理方式，使得DeepSeek在<strong>训练范式上有了代际差距优势，</strong>部分国内大模型更多还是通用语料加基础过滤来完成预训练工作，“DeepSeek则可能加入了对抗式数据清洗环节。”李振表示。</p>
  <p>DeepSeek内部也的的确确在进行对抗式测试。去年3月的演讲中，DeepSeek研究员曾讲到，实际模型生产过程中，内部会进行模型的迭代式开发，“<strong>即每轮的训练结束之后，都会有一个独立的测试团队，对模型在各个维度上的安全性进行充分的测试，</strong>并给出反馈意见来指导进行下一个周期的数据迭代和模型训练。”</p>
  <p>不同的训练方式，也导致即便是使用同样的中文语料库，最终训练出来的大模型，在文风上也会有完全不一样的呈现。</p>
  <p>而且，在R1模型加入RL（强化学习）之后，<strong>强化学习的训练次数也可能导致最终的文风不同。</strong>李振介绍，DeepSeek的PPO（强化学习）迭代轮次可能在50到80，国内其他大模型可能在20左右。</p>
  <p>导致轮次不同的原因之一在于，各个公司对产品功能的押注重点不同。朱啸虎以厨师做饭打了个比喻，“就像厨师，以后有几个米其林大厨，有些擅长川菜，有些擅长粤菜——它在组织语料或参数权重上的差别，就会造成回复的答案有差异性。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_31c608b54668402cb912db04c2edaccf@000000_oswg6113oswg681oswg681_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>华丽优美文风之外，DeepSeek生成内容的惊艳之处还在于，表现形式上做到科技抒情散文诗的一大前提，是首先确保了生成内容具备更高的事实准确性。</p>
  <p>在丁磊博士看来，这有两方面原因促成：<strong>一是模型的自我进化，</strong>模型学会通过更多的推理计算来解决复杂的任务，这不是来自外部设置而是模型自己学会的；<strong>二是模型的“aha moment”顿悟时刻，即模型学会了“反思”，</strong>这证明了其不断增长的推理能力，也说明了强化学习可以带来复杂甚至意想不到的结果。</p>
  <p>基于DeepSeek R1模型，官方还同步推出了R1-Zero模型，后者直接将RL应用于基础模型，而无需依赖SFT（监督微调）和已标注数据。</p>
  <p>此前，OpenAI的数据训练非常依赖人工干预，旗下数据团队甚至被建设成为不同水平的层级，数据量大、标注要求简单明确的浅层数据，交给肯尼亚等廉价外包劳工，高等级的数据则交给更高素质标记人员，不少都是训练有素的高校博士。</p>
  <p>但这样带来的结果之一便是，堆高数据获取成本，且面临数据标注质量参差不齐的难题，从而限制着大模型的规模泛化能力。</p>
  <p>R1-Zero的出现，恰恰是DeepSeek希望通过纯机器学习来解决上述难题的一大尝试，Perplexity公司CEO阿拉文·斯里尼瓦斯评价道：“需求是发明之母。因为DeepSeek必须找到解决办法，最终它们创造出了更高效的技术。”</p>
  <p>在DeepSeek对外分享的R1模型技术报告中，团队在强化学习推理阶段，意外发现了“aha moment”顿悟时刻，这预示着模型自身开始在某一时刻具备了自我反思能力。例如在解决数学方程时，模型会主动纠正早期错误步骤，还能根据训练逐步学会分配更多思考时间，生成更长的推理过程，以解决复杂问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_0c643a92378e48dbabf56431a63ed3e7@000000_oswg225121oswg830oswg530_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>这种 “顿悟” 现象的出现，离不开一种特殊奖励机制的引导。</strong>根据官方技术文档，DeepSeek R1模型，没有使用MCTS（蒙特卡洛树搜索）类技术，而是在PPO算法之下采用了一种特殊的基于规则的奖励函数，根据生成输出的格式和正确性分配奖励，一般包括三种情况：</p>
  <p>如果输出以指定格式提供最终答案且正确，获得+1的奖励；</p>
  <p>如果输出提供最终答案但不正确，奖励设为-0.5；</p>
  <p>如果输出未能提供最终答案，奖励设为-1。</p>
  <p>“我们没直接教模型如何解决问题，只是给予它正确的激励，模型就能自己琢磨出先进的解题办法。”DeepSeek官方如此解释道。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_c0987a2d644b4e5ab3d22466bd6f27c7@000000_oswg7972oswg681oswg681_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>无论是构建风格表征的数学建模，还是推动“aha moment”顿悟时刻的出现，背后都离不开DeepSeek对人才的重视和培养。</p>
  <p>在参与大模型投资的恒业资本创始合伙人江一看来，<strong>DeepSeek的高人才密度，外加内部人才的高自主性，强强结合，</strong>“使得DeepSeek内部产生了多样性的涌现，在穷举多个选项之后，优中选优，最终选定了现在的这种华丽优美文风。”</p>
  <p>上述人才特性也能从梁文锋的对外采访中印证一二。在接受36氪采访时，梁文锋曾介绍，DeepSeek管理遵循自下而上模式，且每个人对于卡和人的调动不设上限。“如果有想法，每个人随时可以调用训练集群的卡无需审批。”</p>
  <p>去年5月份率先打响行业价格战的DeepSeek V2模型，其中的技术创新之一MLA（一种新的多头潜在注意力机制）架构，就来自一个年轻研究员的个人兴趣。</p>
  <p>当时，在总结出Attention架构的一些主流变迁规律后，这位年轻研究员突发奇想设计了一个替代方案，DeepSeek为此组建了一个专项攻坚团队，花了几个月时间将MLA落地。</p>
  <p>在科技领域，自信是创新的首要前提，而梁文锋认为<strong>这种信心通常在年轻人身上更为明显。</strong>所以，DeepSeek内部多是一帮Top高校的应届毕业生、没毕业的博四、博五实习生，以及一些毕业才几年的年轻人。</p>
  <p>“如果追求短期目标，找现成有经验的人是对的。但如果看长远，经验就没那么重要，基础能力、创造性、热爱等更重要。”梁文锋解释道。</p>
  <p>相比而言，在江一观察中，部分大模型公司，在对待员工上则表现出更强的控制力，员工缺少自主性，<strong>“更多呈现出靶向性的研发特征，即部门确定一个最终达成的效果目标，所有的人都奔着这一目标而做好自己分内的工作，使得最终模型呈现出来的效果，显得中规中矩。”</strong></p>
  <p>不过，需要注意的是，<strong>尽管DeepSeek生成的优美文风，被部分人喜爱，但也开始引发部分人的警惕，这些内容乍一看很好，但“仔细品读会发现很多的语法错误。”</strong>内容从业者王旭告诉字母榜。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_8487f45dcfe54e1d995d0edc77713cb9@000000_oswg579545oswg831oswg1213_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以开头那篇梁文锋回应冯骥赞誉的虚假文章为例，其中有句话写到，“既因为被行业前辈认可的惶恐，更因为冯总这些灼热的文字让我想起十二年前在浙大实验室第一次跑通神经网络时的颤栗。”仔细品读后，王旭便从中识别出了一些语病。</p>
  <p><strong>相比语病，更不易察觉的是，借助更逼真、拟人化的文风，DeepSeek的幻觉现象，依然存在。</strong></p>
  <p>在被王旭品读出语病的“既因为被行业前辈认可的惶恐，更因为冯总这些灼热的文字让我想起十二年前在浙大实验室第一次跑通神经网络时的颤栗。”这句话中，乍一看，DeepSeek不仅给出了场景细节，还给出了具体的时间节点，不由得就会让人相信这都是曾经真实发生过的画面。</p>
  <p>但简单搜索下梁文锋的履历便可知道，在十二年前的2013年，梁文锋已经从浙江大学硕士毕业三年。当年，梁文锋与其浙大同学徐进共同创立了杭州雅克比投资管理有限公司，DeepSeek给出的梁文锋在浙大实验室做实验的场景，大概率是自行编造而来。</p>
  <p>随着大模型在可靠性上表现出来的能力越来越强，其迷惑性的一面也随之增强。作为人类的我们，或许是时候该学学如何提高辨别AI内容时，自身的可靠性了。</p>
  <p><strong>参考资料：</strong></p>
  <p><strong>《朱啸虎现实主义故事1周年连载：“DeepSeek快让我相信AGI了”》张小珺</strong></p>
  <p><strong>《全球掀DeepSeek复现狂潮！硅谷巨头神话崩塌，30刀见证啊哈时刻》新智元</strong></p>
  <p><strong>《和而不同：大语言模型价值观对齐解耦化》 DeepSeek</strong></p>
  <p><strong>《疯狂的幻方：一家隐形AI巨头的大模型之路》&nbsp;暗涌Waves</strong></p>
  <p><strong>《朱啸虎VS傅盛，怼出了大模型创业的两个共识》字母榜</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI2NjU1MTcwMA==&amp;mid=2247544222&amp;idx=1&amp;sn=d8b903115984ee95f86faa431328a6a8&amp;chksm=ebfb27b54db9840c561c3519ec41361a4c25998aa519b5c8dbc16535456257dfe291f7a56b29&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“字母榜”（ID：wujicaijing）</a>，作者：赵晋杰，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3158037945777922</id>
            <title>苹果自研「AI机器人」来了！萌萌的台灯隐藏着巨大的野心？</title>
            <link>https://www.36kr.com/p/3158037945777922</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3158037945777922</guid>
            <pubDate></pubDate>
            <updated>Sun, 09 Feb 2025 03:00:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI台灯, 苹果, 机器人, 交互能力  
<br><br>  
总结: 苹果公司推出了一款灵动的AI台灯机器人，展示了其在家用机器人领域的创新思考。该台灯不仅具备基本的照明功能，还能通过手势和语音与用户互动，展现情感和个性。其设计灵感来源于皮克斯的Luxo Jr.，并强调了表现性和功能性的结合。尽管目前仍为原型产品，但其交互能力和情感表达引发了广泛关注，显示出苹果在机器人技术上的潜力。未来，非人形机器人可能会更早进入家庭生活，成为人类的第一波机器人浪潮。 </div>
                        <hr>
                    
                    <p>一款极其灵动的 AI 台灯机器人，火了。</p>
  <p>尽管这两年不断见证了真实世界的机器人刷新我们的认知，从奔跑、翻滚到跳舞，也看过了米家皮皮灯，但还是第一次看到这么灵动的——台灯，很像皮克斯片头跳动的 Luxo Jr.（小台灯）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_37a0c7d284c240a7be82bbd66bb6fab4@1547419282_oswg1867936oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/苹果</p>
  <p>而这个台灯，是苹果公司机器学习研究团队做的非人形机器人。</p>
  <p>苹果要做家用机器人的消息，其实已经传了相当一段时间，但官方实际上一直没有承认，也没有透露产品细节。不过，苹果机器学习研究团队近期直接在官网公布了一篇研究论文以及一段实拍演示视频，全面展示了这款 AI 台灯机器人的交互能力和表现，也在 X、Reddit 等社交平台上被各种围观讨论。</p>
  <p>乍看之下，这款苹果「台灯」的外观并不奇特，硬要说也就是比常规台灯全身上下多了不少机电结构。但关键是动起来，它不仅能让灯光主动跟随书本，用户还能通过简单地触摸、手势来召唤或者指引它。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_ba889e12c7ab44deb77b88cc571b427a@1547419282_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/苹果</p>
  <p>不仅如此，苹果「台灯」还能通过流畅、精细的动作传达出微妙的性格与情绪，比如被拒绝后的委屈，被召唤时的点头哈腰，又或者是观察一个物体时的好奇心。</p>
  <p><strong>而且从演示来看，不只是提供情绪价值。</strong>苹果的「台灯」除了支持语音和手势交互，同时还能通过摄像头进行视觉观察，以及透过投影显示内容，就比如做作业时遇到不懂可以让它给出解题思路。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_97111f13b5004d7c81545025180975f4@1547419282_oswg3099857oswg422oswg212_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/苹果</p>
  <p>&nbsp;</p>
  <p><strong>尽管这还只是一个原型产品，但也足以让我们一窥苹果对于家用机器人的想法和思考。</strong></p>
  <h2><strong>苹果 AI 台灯：智能，但不止于实用</strong></h2>
  <p>坦白讲，整个演示视频看下来，苹果机器学习研究团队开发的这款台灯机器人，对小雷来说最亮眼的还是智能程度和交互表现。</p>
  <p>演示中的一幕是，苹果「台灯」不仅能提醒研究人员喝水，还会直接主动用头部将水杯推向她：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_5f88387ba580495dac2b2d72ef54fc1a@1547419282_oswg1899384oswg960oswg540_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/苹果</p>
  <p>一方面，类似主动提醒用户的想法其实早已有之，不管是手机、PC 上的各种软件，还是雷科技年前报道过的 ChatGPT&nbsp;<a href="https://www.leikeji.com/article/67711" rel="noopener noreferrer nofollow" target="_blank">Tasks 功能</a>，但这些做法只停留在数字世界，做不到在物理世界的主动提醒。</p>
  <p><strong>另一方面，AI 台灯机器人的想法也不稀奇。</strong>米家的皮皮灯也引起过大家的激烈讨论，但最后基本被认定为一个可动性、可玩性都不太高的玩具。字节跳动也尝试过这个方向，推出过大力智能作业灯，也是将 AI 集成进台灯的概念，但交互上基本停留在软件上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_b1e3e54100ca4a73af0f386bf5ebfdd9@1547419282_oswg1231705oswg640oswg300_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">米家皮皮灯，图/小米</p>
  <p>而苹果「台灯」上，我们能看到询问天气时不仅是语音播报天气，还会转向户外，透过摄像头的 AI 视觉能力结合当前现实空间看到的天气。有意思的是，当研究人员告诉它不能带它去徒步时，「台灯」也会低下头扭捏，传达出悲伤又委屈的情绪。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_1be281e4000f4f6eaf8e06cb75077c6d@1547419282_oswg2540001oswg960oswg540_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/苹果</p>
  <p>当你正在进行手工作业或者任何桌面上的研究时，也能让「台灯」时刻并提供建议，甚至是把需要内容直接投影出来；晚上看完书后，「台灯」在识别没有其他活动后也会自动关闭灯光。</p>
  <p>甚至当它伸长身体也无法完成任务时，也是会在尽力尝试后「委屈地」告诉你做不到。<strong>看到这样，你还能抱怨它吗？属实是情绪价值拉满。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_c36616a625114464934b1c889fedf5a0@1547419282_oswg2443376oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/苹果</p>
  <p>一言以蔽之，实用价值要有，情绪价值也要有。而这，也能从苹果团队的字里行间中清晰地看到：</p>
  <p>「为了使机器人与人类更自然地互动，机器人的运动设计也应同样整合表达性品质——如意图、注意力和情感——以及传统的功能性考虑，如任务完成、空间限制和时间效率。」</p>
  <h2><strong>台灯变身机器人：不只是萌，不只是接入AI</strong></h2>
  <p>事实上，尽管从对话和智能程度来看，大概率可以判断出苹果机器学习研究团队是基于大模型开发出了这款台灯形态的 AI 机器人。但就苹果公布的这篇论文而言，并非聚焦在人工智能的层面，反而是聚焦在「台灯」一系列精细、灵动的运动上。</p>
  <p>首先苹果论文的标题就是——《ELEGNT: Expressive and Functional Movement Design for Non-anthropomorphic Robot》（优雅：非人形机器人的表现性和功能性运动设计），四位论文作者中有三位是华人。</p>
  <p>论文也透露了，台灯形态的灵感确实直接来源于皮克斯的经典角色 Luxo Jr.（小台灯） ，而苹果也针对台灯形态的非人形机器人设计出了一套框架，<strong>专注于通过一系列流畅且富有表现力的动作，在日常互动中实现情感表达和实用功能的结合。</strong></p>
  <p>简单来说，为了避免生硬的机器人运动/动作影响人类与机器人之间更自然地交互体验，苹果团队开发出了这一套基于深度学习的运动设计框架，来让非人形机器人兼具表现力和功能性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_3db2aa332c93477e8f04c4baeae7e893@1547419282_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/苹果</p>
  <p>研究团队也确实招募了 21 名参与者，在 6 种不同场景下观看人类与机器人之间的交互。</p>
  <p>结果显示，比起单纯满足功能性要求的运动设计，<strong>兼具表现力和功能性的运动设计明显能提高参与者的评分——用户更喜欢也能接受 ，而且男性比女性更明显，普通用户比专业用户更明显。</strong></p>
  <p>其实从常理也能看到，米家皮皮灯推出之初之所以能够引起广泛关注和讨论，并不在于功能性或者实用价值。但另一方面，苹果这款 AI 台灯的原型版最大的亮点就是同时具备情绪和实用价值，而不只是「萌」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_502230f5a9dd4eaf9b9a6ee691da3283@1547419282_oswg2076043oswg406oswg222_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/苹果</p>
  <p>苹果很大程度上也是基于大模型的能力，自然语言对话自不必说，从视觉能力上也能得以窥见一二。与此同时，在人形机器人还很难短期内落地家庭场景的背景下，这可能也是家用机器人的必然，<strong>即基于多模态大模型成为人类的「第三只眼」「第二大脑」。</strong></p>
  <p>此外，这款「台灯」也让我们初步看到了苹果在人机交互上的想法，比如除了 AI 语音交互，还能看到基于摄像头的 AI 视觉+图形界面显示，以及简单的手势和触摸交互。尤其是视觉+显示的交互能力，直接赋予了「台灯」在各种场景下满足的需求。</p>
  <p>从这个角度看，我们完全可以期待苹果未来最终推出的桌面机器人，在语音之外也支持视觉和显示的能力，<strong>在拥有基于 AI 的实用价值的同时，也能满足人类用户的情绪价值。</strong></p>
  <h2><strong>距离通用机器人，我们还有很远的路要走</strong></h2>
  <p>1977 年，乔治·卢卡斯带着《星球大战》一炮而红，也带火了其中的 R2-D2 机器人，这也让全球的观众第一次对机器人有了具体的印象。马斯克在去年秋天的 We, Robot 活动中介绍特斯拉 Optimus 时，也说：</p>
  <p><strong>Optimus 将是每个人自己的 R2-D2。</strong></p>
  <p>在大模型技术日新月异的今天，具身智能的机器人事实上已经成为了一种共识，然而优先发展人形机器人，还是非人形机器人仍然存在巨大的争议。</p>
  <p>但有一点是明确的，包括芯片厂商地瓜机器人（从地平线独立出来的机器人部门）、人形机器人厂商智元机器人都表明过，<strong>通用的人形机器人距离实际走进我们的生活都还有很长的一段路要走。</strong></p>
  <p>相比之下，非人形的家用机器人，在大模型技术的快速迭代下或许将更早走进我们的生活，成为人类的第一波机器人浪潮。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3158644725242371</id>
            <title>苹果折叠屏iPhone最全爆料：做大折叠，冲千万销量，九大亮点抢先看</title>
            <link>https://www.36kr.com/p/3158644725242371</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3158644725242371</guid>
            <pubDate></pubDate>
            <updated>Sun, 09 Feb 2025 01:02:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 折叠屏, iPhone, 供应链  
<br><br>  
总结: 最近有用户在X平台上爆料了苹果折叠屏iPhone的最新供应链信息，包括发布时间、预期销量和外观设计等。折叠屏iPhone预计将在2026年秋季上市，第一年销量有望达到800-1000万部。该机型将采用Meta Lens超构透镜技术和树脂涂布铜箔材料，显示屏由三星独家开发。尽管折叠屏手机市场面临出货量下滑，但苹果的入局被认为将为市场注入新动能。苹果折叠屏的设计和技术细节引发了广泛关注，业界期待其能带来新的交互体验。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250209/v2_7e83bab7e4b14e16823a60a38a94f0dc@000000_oswg151227oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>苹果折叠屏iPhone大招，越来越近了！</strong>&nbsp;</p>
  <p>智东西2月9日消息，近日，一X平台用户发文爆料了苹果折叠屏供应链的最新信息，包括<strong>发布时间、预期销量、外观设计、屏幕、转轴、中框、PCB、镜头、电池以及相关零部件供应商，</strong>可以说十分详尽。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250209/v2_aa63441cbee2450193b6dffeefa38a8c@000000_oswg57617oswg885oswg399_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲X平台用户QQ_Timmy发文</p>
  <p><strong>富士康、立讯精密、比亚迪、蓝思科技、大立光、舜宇光学、蓝特光学、领益智造、安费诺、精研科技以及三星、LG</strong>等知名果链企业均有提及。&nbsp;</p>
  <p>虽然该用户此前并未有知名苹果产品爆料经历，但<strong>其账号已经为天风证券分析师郭明錤所关注，</strong>其X平台推文内容已迅速被海内外各路科技媒体转发。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250209/v2_bbcf7172d503446b98da56c49ca16085@000000_oswg18968oswg748oswg334_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲郭明錤已关注该账号</p>
  <p>据爆料，<strong>折叠屏iPhone最快将在明年秋季上市，也就是iPhone 17系列发布同期。发布第一年的销量就有望冲击1000万部。</strong>&nbsp;</p>
  <p>折叠屏iPhone在镜头方面会采用最新的<strong>Meta Lens超构透镜技术，</strong>PCB板方面，苹果预计会导入<strong>树脂涂布铜箔（RCC）新材料。</strong>&nbsp;</p>
  <p>安卓阵营从2018年底开始入局折叠屏，至今已有六年多时间，三星、华为等头部厂商的折叠屏旗舰机均已出至第五代。目前影响折叠屏手机基础体验的一些核心问题基本都已被解决，如轻薄、厚度、耐久度、应用生态兼容性等。&nbsp;</p>
  <p>但根据Counterpoint Research最新数据，2024年第三季度，全球折叠屏手机出货量在连续六个季度同比增长后首次同比下降了1%，这是折叠屏手机首次在第三季度出现出货量下滑。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250209/v2_a6afe5692ef146029d5ed7daa4f10419@000000_oswg53630oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲2024年三季度全球折叠屏手机出货市场份额，来源：Counterpoint Research</p>
  <p>各路市研机构几乎都在报告中提到了苹果的入局或将给整个折叠屏手机市场注入巨大动能，显著带动出货量提升。因此业内对于苹果折叠屏的发布愈发关注。&nbsp;</p>
  <p>具体来看此次的爆料信息：&nbsp;</p>
  <p><strong>1、发布节奏：</strong>&nbsp;</p>
  <p><strong>折叠屏iPhone预计在2026年秋季上市，</strong>2027年折叠屏iPad和MacBook将会上市。2025年6月，富士康将独家进行折叠屏iPhone的NPI（新产品导入），预计在2025年年底或2026年年初达到量产水平。&nbsp;</p>
  <p><strong>2、销量：</strong>&nbsp;</p>
  <p>销量方面，<strong>其预计折叠屏iPhone在2026年的销量为800-1000万部，2027年达到2000万部。</strong>至于代工方，2026年将由富士康独家代工，2027年引入立讯精密。&nbsp;</p>
  <p>根据IDC预测数据，2024年全球折叠屏手机出货量约为2500万部。&nbsp;</p>
  <p><strong>3、外观设计：</strong>&nbsp;</p>
  <p><strong>苹果折叠屏iPhone将采用横向左右大折叠的方案，</strong>折叠后厚度为9.2毫米，展开厚度为4.6毫米，内屏相当于两部6.1英寸手机对折，展开后超过12英寸。&nbsp;</p>
  <p>值得一提的是，此前外媒爆料普遍认为苹果首款折叠屏iPhone将是竖向小折叠机型，与此次爆料信息有较大出入。&nbsp;</p>
  <p><strong>4、屏幕及支架：</strong>&nbsp;</p>
  <p>折叠屏手机的屏幕是最核心的组件甚至没有之一，爆料称此次<strong>显示屏由三星显示独家开发，屏幕的UTG（超薄玻璃）由蓝思科技独家研发，</strong>目前屏幕成本在90-100美元左右。此外，屏幕支撑架采用钛合金、不锈钢还是碳纤维方案尚未确定，成本大约十几美元。爆料称领益智造有向苹果送样屏幕支撑架。&nbsp;</p>
  <p><strong>5、转轴铰链：</strong>&nbsp;</p>
  <p>铰链是另一个折叠屏的关键零组件，爆料称苹果目前的设计方案，铰链整体组装完成本约110美元，<strong>铰链由安费诺或台湾新日兴供应，</strong>铰链内部零部件中，领益智造参与的部分成本约35美元，精研科技参与了MIM（金属粉末注射成型）部分，成本约十几美元。&nbsp;</p>
  <p><strong>6、中框：</strong>&nbsp;</p>
  <p>爆料称折叠屏iPhone的<strong>铝合金中框由工业富联独家进行NPI，</strong>成本约为80-90美元，蓝思科技和比亚迪电子有希望在量产阶段进入二供。&nbsp;</p>
  <p><strong>7、PCB：</strong>&nbsp;</p>
  <p>折叠屏iPhone的PCB软板价值量预计增加70%，模组板价值接近翻倍，爆料称<strong>苹果预计会在堆叠式印刷电路板（SLP）中导入树脂涂布铜箔（RCC）材料，</strong>价值量会从12美元增长至18美元，增幅40%。&nbsp;</p>
  <p><strong>8、光学镜头：</strong>&nbsp;</p>
  <p>在影像光学配置方面，<strong>预计折叠屏iPhone的前摄会采用最新的Meta Lens超构透镜技术，</strong>据称该技术方案来自苹果。具体来看，透镜部分，大立光、舜宇、蓝特光学参与研发；模组部分，富士康、LG参与研发。后摄的主摄和超广角镜头都会采用玻塑混合方案，镜头以大立光为主要供应商，舜宇参与模造玻璃部分。&nbsp;</p>
  <p>值得一提的是，Meta Lens相关技术已经由供应链研发多年，目前尚未有量产机型采用，如果苹果率先发布这一技术，必然又将掀起新一轮手机影像技术升级浪潮。&nbsp;</p>
  <p><strong>9、电池：</strong>&nbsp;</p>
  <p>最后在电池方面，<strong>折叠屏iPhone预计将采用两片不锈钢壳电池，</strong>不锈钢壳由信维和领益智造提供，两片电池合计容量约为5000毫安时，电芯预计为3D叠片，由ATL独家研发。&nbsp;</p>
  <p>虽然此次iPhone折叠屏爆料的可信度仍然存疑，但海外知名苹果记者马克·古尔曼和天风证券分析师郭明錤近日都未对此信息进行“辟谣”。以往这两大爆料人往往都会对苹果相关不实信息进行评价或发文反驳，因此这位X平台爆料人的信息又多了几分可信性。&nbsp;</p>
  <p>不论如何，苹果要做折叠屏应该是大概率事件，最近苹果折叠屏相关爆料信息也开始愈发频繁的出现，苹果折叠屏能否避免成为下一个Vision Pro？苹果折叠屏能否逆转当下折叠屏手机市场的疲软态势？苹果又能否带来一些软件交互层面的新玩法，都值得期待。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652779219&amp;idx=2&amp;sn=120a140b09c85a9d1c443ea739d6b373&amp;chksm=85c57fc2a12956cb3d3e91f98bdd3c8b497c67833f1b20bcbcd717aeba02eb6df10f8a971f64&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：云鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3157246632155655</id>
            <title>马斯克的增长梦，谁来买单？</title>
            <link>https://www.36kr.com/p/3157246632155655</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157246632155655</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 23:14:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 特斯拉, 销量下降, 自动驾驶, 市场竞争  
<br><br>  
总结: 2024年，特斯拉的全球交付量首次出现同比下降，面临主力车型老化、价格战侵蚀利润、全球市场分化及自动驾驶商业化难题等多重挑战。尽管在中国市场销量创历史新高，但降价策略可能透支需求，且本土品牌竞争加剧。美国市场需求增速放缓，政策不确定性增加，而欧洲市场则因补贴退潮和本土品牌反攻而承压。特斯拉的2025年增长目标依赖于低价车型和自动驾驶技术的突破，但这两者均面临现实挑战，市场对其未来的信心仍需观察。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_809fbffdd66747118608f9fb21f49230@000000_oswg920554oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>作者丨陈胜</strong></p>
  <p>2025年伊始，特斯拉以一场全球范围的“降价潮”开启了新一年的竞争。然而，2024年全年交付量罕见同比下降的现实，揭示了这家电动车巨头在增长之路上的深层焦虑。</p>
  <p>尽管马斯克在财报电话会上提出2025年销量增长20%~30%的目标，但这一目标的实现需要跨越至少四重障碍：<strong>主力车型老化、价格战侵蚀利润、全球市场分化、自动驾驶商业化难题。</strong></p>
  <p>2024年，特斯拉全年交付178.9万辆，同比下降1.1%，这是自2015年以来首次年度销量下滑。虽然仅是小幅波动，但背后潜藏的危机却难以被忽视。</p>
  <p>车型迭代停滞：Model 3和Model Y两款主力车型分别于2016年和2019年推出，消费者审美疲劳导致需求疲软。</p>
  <p>利润空间压缩：2024年的净利润同比腰斩，汽车业务毛利率从2023年的15.7%骤降至7.3%。</p>
  <p>竞争格局剧变：比亚迪以177万辆的全球销量逼近特斯拉，而中国本土车企的“围剿”进一步挤压了特斯拉的市场空间。&nbsp;&nbsp;</p>
  <p>尽管特斯拉通过频繁降价（如中国市场Model Y降价超3万元、5年0息金融方案），暂时稳住了部分销量，但“以价换量”的策略或已触顶。</p>
  <p>马斯克将增长希望寄托于2025年的新车周期与自动驾驶技术突破，但这一叙事能否被市场买单，仍需分区域拆解。&nbsp;&nbsp;</p>
  <p><strong>1) 中国：销量新高背后的隐忧&nbsp;&nbsp;</strong></p>
  <p>2024年，特斯拉在中国市场交付65.7万辆，同比增长8.8%，创历史新高。不过，这一成绩的含金量值得警惕。</p>
  <p>价格战有透支需求的危险，降价政策虽刺激了短期销量，但也导致品牌溢价流失。比亚迪、吉利、蔚来等车企以更低价格和更快迭代速度抢占20万~30万元市场，密集推出对标Model Y的车型。</p>
  <p>与此同时，特斯拉的上海超级工厂本土化率已超95%，成本压缩空间有限，而Model 2/Q的推出仍需直面15万元级市场的激烈竞争。&nbsp;&nbsp;</p>
  <p>中国汽车市场的增长潜力已从增量扩张渐渐转向存量博弈，特斯拉若无法在智能化（如FSD本土化）和性价比（Model 2/Q）上实现突破，其份额有被进一步蚕食的风险。&nbsp;&nbsp;</p>
  <p><strong>2) 美国：政策与需求的双重不确定性&nbsp;</strong></p>
  <p>美国是特斯拉的第二大市场，但其需求增速也正在放缓。2024年前三季度，美国电动车销量同比仅增长7.2%，远低于2023年的47%，主流消费者对续航和充电便利性的疑虑仍未消除。政策层面上，特朗普重返白宫后有可能削减电动车补贴。&nbsp;&nbsp;</p>
  <p>不过，特斯拉在美国的叙事重心已转向技术驱动。FSD（完全自动驾驶）和Robotaxi（无人出租车）被马斯克视为“万亿美元机遇”，其进展可能受特朗普政府监管松绑的利好。</p>
  <p>若FSD V13能在2025年6月通过奥斯汀试点验证，或将成为股价的强心剂，但技术成熟度与法规风险仍是悬顶之剑。&nbsp;&nbsp;</p>
  <p><strong>3) 欧洲：补贴退潮与本土品牌反攻&nbsp;&nbsp;</strong></p>
  <p>欧洲市场2024年的表现堪称特斯拉的滑铁卢。德国、法国等主要国家削减电动车购车补贴，消费者转向混合动力车型，导致特斯拉交付量承压。企业层面，大众、宝马等车企加速电动化转型，凭借更贴近欧洲用户的设计与渠道优势抢夺市场。</p>
  <p>特斯拉在欧洲的应对策略包括延长Model Y的贷款折扣和免费超充服务，但效果有限。未来，柏林工厂的产能优化与Cybertruck的差异化定位或是关键变量。&nbsp;&nbsp;</p>
  <p><strong>马斯克为特斯拉规划的2025年增长路径包含两条主线：低价车型放量与自动驾驶商业化。</strong>然而，这两大战略均面临现实挑战。</p>
  <p>特斯拉计划于2025年上半年推出定价14万元左右的Model 2/Q，目标是通过下沉市场拉动销量。尽管Model 2/Q的制造成本比Model 3低50%，但中国本土品牌已在该价格段占据先发优势，且利润率极低。</p>
  <p>特斯拉长期以高端形象示人，低价车型可能稀释品牌价值，进而影响高毛利车型的销售。而一旦Model 2/Q无法在2025年底前实现规模化交付，特斯拉增长目标的兑现将极具挑战。&nbsp;&nbsp;</p>
  <p>另一面，FSD与Robotaxi的商业化远水难解近渴。马斯克宣称FSD技术将在2025年迎来“质变”，并计划推动Robotaxi试点。</p>
  <p>但实际上，市场对FSD技术的成熟度仍存疑。资本市场对自动驾驶的乐观预期（如Wedbush将目标股价上调至515美元）更多基于叙事而非现实业绩。</p>
  <p>FSD V13虽在测试中表现提升，但复杂路况下的安全冗余仍未解决，全球监管审批进度缓慢。在商业模式上，FSD订阅收入仅占整车销售收入的1.6%，短期内难以支撑估值。</p>
  <p>最后，让我们回到本文标题里的问题：马斯克的增长梦，究竟谁来买单？&nbsp;&nbsp;</p>
  <p><strong>消费者也许可以被低价吸引购买新车，但品牌忠诚度可能因价格波动而削弱；投资者也许可以接受高估值泡沫，押注自动驾驶的长期红利，但需承受短期业绩波动的风险；供应链伙伴也许可以通过深度绑定特斯拉获得订单，但也需应对其压价策略。&nbsp;&nbsp;</strong></p>
  <p>特斯拉的2025年增长目标是一场“小赌”，赌注将是技术突破与市场耐心的双重兑现。</p>
  <p>封面来源丨AI制图</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTY3Njk1Ng==&amp;mid=2247511060&amp;idx=1&amp;sn=d3b1e3b69757e3e4fca4472d6e50b34b&amp;chksm=cfdab8b56cfb68aa42b8d51be9f6f199c4ada30d57a744f7cb338ecc00bf2140961b940fb1f2&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“雪豹财经社”（ID：xuebaocaijingshe）</a>，作者：陈胜，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156608448200201</id>
            <title>终于！小米首款AI眼镜来了，“百镜大战”高潮将至？</title>
            <link>https://www.36kr.com/p/3156608448200201</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156608448200201</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 23:06:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <小米, AI眼镜, XR行业, 市场竞争>
<br>
<br>
总结: 小米计划推出AI眼镜，尽管其公关部辟谣了官微上线的传闻，但预计将在2025年之前发布。小米在智能眼镜领域的尝试并未取得显著成功，主要由于缺乏吸引消费者的功能。当前市场竞争激烈，众多品牌如苹果、Meta等也在积极布局AI眼镜。小米的AI眼镜将集成AI大模型，提升实用性和交互体验，但销量预期仅为30万台，显示出市场需求仍然有限。尽管小米在手机行业表现出色，但在AI眼镜领域能否复制成功仍需观察。整体来看，AI与AR结合的产品有望成为未来的趋势。 </div>
                        <hr>
                    
                    <p>新的领域，小米要向苹果、Meta发起挑战？</p>
  <p>2月6日有网友发文表示，小米眼镜官微上线，预示着小米AI眼镜即将到来。随后小米公关部总经理王化辟谣，小米眼镜官微多年前就已注册，并非最近上线。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ec52d1ae8dc04e0386eb2a67ef9a8a39@1547419282_oswg145986oswg1268oswg878_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：微博截图）</p>
  <p>尽管王化对小米官微一事进行了辟谣，但并未对小米AI眼镜发布时间发表意见。此前《科创板日报》报道称，XR研究院透露，小米AI眼镜原定2025年3月到4月发布，现计划将发布时间提前至2月，与小米15 Ultra一同面世。</p>
  <p>数码博主@智慧皮卡丘则爆料称，小米AI眼镜已经入网，型号为“M2442G1”。由此来看，小米AI眼镜依然有可能2月发布，借助小米15 Ultra的热度，获得更高的曝光量。</p>
  <p>作为手机、互联网行业霸主，小米的产品已经给消费者留下了价格低、配置高的印象。每当一类产品爆火时，就会有许多网友期盼小米入场，推出低价高配的产品，将价格打下来。<strong>但“百镜大战”逐渐拉开帷幕，国内的雷鸟、PICO、XREAL、Rokid，国外的苹果、索尼、Meta等诸多企业加入战团，小米AI眼镜突出重围并非易事。</strong></p>
  <h2>以AI为根基，小米再度发力智能眼镜</h2>
  <p>在这款AI眼镜之前，小米已经向智能眼镜领域发起多次试水行动，并在2022年和2023年分别推出了MIJIA眼镜相机、MIJIA智能音频眼镜。遗憾的是，因技术、供应链不成熟，再加上缺乏吸引消费者的功能，这两款眼镜并未掀起太大波澜。</p>
  <p>缺乏杀手级应用一直是智能眼镜的痛点，即便强如苹果，Vision Pro也落得个停产的下场。<strong>好在AI时代的到来，为智能眼镜带来了无限可能。</strong>前段时间闪极推出的AI拍拍镜加入了AI记忆系统、AI云盘等功能，并且云端AI中心接入了数十个大模型，用户可通过语音指令调用AI助手，实现导航、学习、听音乐，使其实用价值大幅提高。</p>
  <p>小米推出的MIJIA眼镜相机，同样融入了小爱同学的部分功能，可以实现实时翻译、动植物识别等功能。在AI大模型渗透进各行各业的今天，小米AI眼镜接入AI大模型板上钉钉。早前小米被曝将打造万卡集群，并挖走了DeepSeek工程师罗福莉，大力推动AI技术研发，小米AI眼镜所具备的AI功能，值得广大米粉期待。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_aa6a330c57b14e68999c27e4a25e5b91@1547419282_oswg2851234oswg2950oswg1412_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：小米）</p>
  <p>据《科创板日报》报道，2024年小米与供应链企业歌尔股份达成合作，首款AI眼镜对标Meta Ray-ban，预期出货量30万台以上。Meta Ray-ban首款产品Stories于2021年推出，2023年又推出了支持AI功能的第二代产品，2024年销量超过100万台。</p>
  <p>需要注意的是，与闪极AI拍拍镜相同，Meta Ray-ban的两款产品均搭载普通镜片，不能显示画面，而小米的试水之作MIJIA眼镜相机的屏幕却可以显示内容。</p>
  <p>若镜片不能显示信息，用户的交互便捷度和实用性难免会大打折扣，Meta和闪极的方案优势在于成本更低，且能够增加续航时间。<strong>素以堆配置闻名的小米，在AI眼镜领域大概率也将承担起打破“科技霸权”的责任，为AI眼镜配备可显示画面的镜片。</strong></p>
  <p><strong>小米AI眼镜与MIJIA眼镜相机大概率较为相似，会配备独立芯片、电池，可脱离手机运行，通过AI大模型丰富设备的功能和提高交互体验，并且支持镜片显示信息，用于导航、文字翻译，甚至观影。</strong>至于价格，参考MIJIA眼镜相机当前官网售价2099元，小雷推测小米AI眼镜的首发价格大概率在3000元左右起步。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_16dc80c4210d481fb87bb76cb2472227@1547419282_oswg394036oswg2540oswg1268_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：小米官网）</p>
  <p>单纯看产品，小米AI眼镜依然极具诚意，但小米公司对其的销量期望却仅为30万台，可见在小米眼中，这款产品恐难以取得太好的成绩。其中的原因倒不是小米的影响力不足，而是AI眼镜至今仍属于小众需求。</p>
  <p>维深信息在《AI智能眼镜销量跟踪报告2024年度》中指出，去年国内AI眼镜（不包括未接入AI大模型的蓝牙音频眼镜/智能眼镜，以及投屏观影类AR眼镜）销量约为5万台，同比增加2%。<strong>一个市场规模如此之小的行业，甚至让人怀疑小米是否有入场的必要。</strong></p>
  <h2>AI重新定义XR，行业大洗牌将至？</h2>
  <p>根据维深信息统计的数据，2024全球AI眼镜总销量为234万台，2025年有望增加至550万台，到2030年之前都将保持大约100%的增长率，行业发展迅猛。从产品分类来看，销售的AI眼镜中96%是AI拍摄眼镜，仅有3%为AR+AI眼镜，1%为AI音频眼镜。国内AI眼镜销量不佳，原因在于界环、李未可等品牌虽发布了不少AI拍摄眼镜，但大多产品在2025年上市交付，2024年消费者可选的产品太少，同时AR+AI技术不够成熟，AI音频眼镜则功能太少，难以扛起大梁。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_43d5a7b90d3645d4a3fe13f1abae0273@1547419282_oswg1238163oswg3462oswg1020_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：维深信息）</p>
  <p>2025年大量产品上市，在AI和其他新功能的刺激下，国内AI眼镜销量很可能连翻数倍，进入销量高速增长阶段。拥有成长为下一代计算平台潜力的XR设备，未来前景无限。<strong>AI眼镜定义方面虽与XR存在一定的差异，但将AI与AR结合以提升实用性，无疑是AI眼镜的未来趋势。</strong>360集团创始人周鸿祎在谈及AI硬件时直言，每个互联网公司都可能会研发自己的智能眼镜。</p>
  <p>首款XR设备销量不达预期的苹果，不愿放弃XR市场，计划在2025年推出价格更低的头显设备。Meta的XR部门Reality Labs在2024年第四季度营收10.8亿美元，支出60.5亿美元的情况下，依然坚持开发XR设备。即便2020年第四季度至今，Reality Labs累计亏损已达600亿美元，Meta首席财务官Susan Li仍表示，这些投资对于开发下一代计算平台是必要的。</p>
  <p>扭亏为盈的关键在于打造符合消费者需求的产品，现阶段能够解放双手、第一视角拍摄、通过AI提升功能丰富性的AI拍摄眼镜无疑是消费者最需要的产品。闪极AI拍拍镜共创版上线就被抢购一空，原因也在于此。</p>
  <p><strong>未来随着芯片、电池、显示技术的进步，AI眼镜将陆续加入AR功能，进一步提高产品的价值。</strong>2024年全球AI眼镜销量之王Meta，便计划2024年推出Ray-ban第三代AI眼镜，高配版配备可以显示画面的镜片，2027年推出旗下第一款真正的AR眼镜。</p>
  <p>当前国内在售的AR眼镜，功能大多以投屏观影为主。相较于VR和MR，真正的AR眼镜的功能更加复杂，需要大量技术积累。Meta在VR、AI眼镜独霸全球半数以上市场的情况下，依然步步为营，稳扎稳打探索AR发展路线。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a4d92ce8d8704b308611857cc625a61c@1547419282_oswg46372oswg1226oswg874_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：小米）</p>
  <p><strong>XR行业属于蓝海市场，AI与AR结合的产品更是拥有成为下一代计算平台的潜力。即便现阶段该行业市场规模较小，正如周鸿祎所言，为了争取到先发优势，每个互联网公司都可能会研发自己的智能眼镜。</strong></p>
  <p>小米在手机行业成绩斐然，财力充足的情况下，自然也要向XR行业探索。MIJIA眼镜相机产品成熟度不足，可从设计理念到功能特性，放到今天来看无疑是超前的，换个芯片再加个AI大模型后，都要比许多在售的AI眼镜更具竞争力。<strong>小米新一代产品加入更多功能后，有望改变当前AI眼镜，乃至整个XR行业的格局。</strong></p>
  <h2>小米入场，AI眼镜行业会大爆发吗？</h2>
  <p>2021年，小米CEO雷军表示，汽车是他这一辈子最后一次重大创业项目。然而雷军可能要食言了，AI+XR潜力不输手机，称得上重大创业项目。当初小米进军汽车行业，许多业内人士认为，手机行业已成为红海市场，位列全球销量第三的小米难以超越三星或苹果，才会开拓新业务以寻求突破。</p>
  <p>小米汽车上市首年累计交付超过13.5万辆，巨大的成功无疑给了小米更多信心。引得苹果、Meta等科技巨头入场的XR行业，将成为小米开拓业务的下一个重点领域。</p>
  <p>不过“价格屠夫”小米能否在AI+XR行业再次挥起屠龙刀，将产品价格打下来，目前无法确定。从小米汽车的定位不难看出，小米急于摆脱“性价比”形象，新产品普遍定位高端。而且从高端向低端发展下沉市场容易，定位低端的品牌冲击高端却极为困难。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f478b0c77b7548288c8d11c60794cb4f@1547419282_oswg3632951oswg2926oswg1404_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：小米）</p>
  <p><strong>全球XR行业入局者甚多，主打中低端市场的品牌也不少，小米很难肩负起价格屠夫的重任。</strong>好在，引领行业进步不能只看价格，堆配置、丰富功能具有同样的效果。不再追求性价比的小米SU7，硬件配置和智能生态仍是同价位的佼佼者。</p>
  <p>MIJIA眼镜相机证明了小米在AI眼镜设计方面的超前性，融入AI大模型和部分AR功能后，MIJIA眼镜相机的体验和大概率能够跻身第一梯队。同时，小米拥有大多数XR企业难以企及的品牌影响力，能够快速聚拢感兴趣的网友，并吸引有需求的消费者下单。</p>
  <p>XR行业仍处于起步阶段，如同新能源汽车行业，发展过程中难免会有大量企业倒在路上，但当前任何企业都有机会。也正因如此，未来数年我们将看到更多企业进军XR行业，开发支持AI大模型的AR、VR、MR，或者研发纯粹的AI眼镜。<strong>但这场竞争并不完全公平，小米、苹果、Meta等财力雄厚、影响力强大的企业更有机会笑到最后，甚至改变整个行业的格局，引领产品的设计思路与发展路线。</strong></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3157749165890050</id>
            <title>美国新造车，正排队破产</title>
            <link>https://www.36kr.com/p/3157749165890050</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157749165890050</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 23:00:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <Nikola, 破产, 特斯拉, 欺诈>
<br>
<br>
总结: Nikola公司曾被誉为卡车界的“特斯拉”，但因资金短缺和持续亏损，面临破产风险。创始人Trevor Milton因欺诈投资者被判刑，导致公司信誉受损。Nikola自上市以来股价暴跌99%，市值大幅缩水，且未能交付任何车辆。公司正在寻求出售核心资产和重组以自救，但市场对其信心已丧失，融资困难重重。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_44cc8dc77e074e5583394b5c6c3ef8e7@000000_oswg651715oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>继Canoo破产后，美国又一家造车新选手即将走向破败。</p>
  <p>曾被誉为卡车界“特斯拉”的<strong>Nikola</strong>（尼古拉）。</p>
  <p>根据华尔街日报，Nikola正与一家名为Pillsbury Winthrop Shaw Pittman律师事务所合作，讨论比如<strong>出售核心资产、全面重组甚至破产保护</strong>等在内的多个战略转型方案。</p>
  <p>原因显而易见，就是没钱了。</p>
  <p>早在去年10月，Nikola就承认公司资金即将耗尽，且若无法筹集到新资金，将无法继续运营至<strong>2025年第一季度之后</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_d4326e47ffcf493b82e0f3cc9f63d05b@000000_oswg631770oswg980oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>受到可能破产的影响，股价也创下了54周以来的最低水平，在盘后交易中暴跌超40%，截至发稿，股价仅为0.44美元，市值为3743万。</p>
  <p>自2020年上市以来，Nikola的股价就已经缩水99%以上，Nikola股票曾多次跌破 1 美元大关，但其采取了多次反向股票分割，就是为了遵守纳斯达克的上市规则，不然早就退市了。</p>
  <p>曾经的市值高达240亿美元，如今黄粱一梦，在创始人锒铛入狱一年多后，即便是卡车界的特斯拉，也不得不迎接自己的终局。</p>
  <h2><strong>01 市值蒸发千亿</strong></h2>
  <p>Nikola的辉煌时刻，定格在了2020年6月。</p>
  <p>当时的Nikola以120亿美元的估值成功登陆纳斯达克，在没交付一辆车的情况下，筹集到了7亿美元资金，成为<strong>全球首个IPO的氢燃料整车制造企业</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_48c9e5bc5a674a3aa844466c621c4112@000000_oswg423761oswg980oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>创始人Trevor Milton，彼时宣布开始接受旗下氢能源皮卡车型Badger的预订，在资本的推波助澜下，Nikola股价一度飙升104%，市值达到263亿美元，赶超福特和通用这样的行业老牌巨头。</p>
  <p>但辉煌只是暂时的，随后Nikola就遭遇一系列变故和质疑，如今Nikola的股价已经跌去99%，其现金储备“仅够维持到今年4月”。</p>
  <p>导致Nikola破产的原因有很多，但最核心因素还是太烧钱了，Nikola自上市后<strong>一直在亏损</strong>。</p>
  <p>根据最新财报数据，Nikola在2024年前9个月，营收为6400万美元，上年同期为2431万美元，虽然同比增长显著，但其运营亏损高达4.55亿美元，上年同期的运营亏损为5.22亿美元；净亏损为4.81亿美元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_2de45f8f98404844add82c6a1b63070c@000000_oswg54002oswg1080oswg557_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>特别是在2024年第三季度，Nikola的营收仅为2518万美元，运营亏损1.79亿美元，净亏损2亿美元，去年同期的净亏损为4.26亿美元。</p>
  <p>截至2024年9月30日，Nikola公司公布的自身持有现金及现金等价物也降到了1.883亿元，而在2023年底这一数额还是4.647亿美元，首席财务官Thomas Okray也承认，公司每月的资金消耗为3000万至4000万美元。</p>
  <p>以Nikola当前的烧钱速度，这些资金根本不能支撑公司运营半年之久。</p>
  <p>在致美国证券交易委员会的强制性警告信中，Nikola坦言：“<strong>我们现有的财务资源仅能覆盖预测的运营成本，并在2025年第一季度前履行相关义务</strong>。”</p>
  <p>为了缓解财务上的压力，Nikola在去年10月解雇了<strong>15%的员工</strong>，大约153名，这个月还将有进一步的裁员计划以缩减规模。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_f15328d9288c4ae7887764b7929663ad@000000_oswg807911oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值得注意的是，其最近的一轮裁员，已经将其有争议的氢燃料电池半卡车的生产线给停掉了。</p>
  <p>同时，Nikola也展开了不少自救的措施，比如通过与票据持有人的交易筹集资金，但目前仅获得6500万美元，以Nikola当前的烧钱速度，这笔资金也就能维持一个月左右。</p>
  <p>此外，Nikola还宣布计划通过出售更多股票来筹集1亿美元资金，但是以目前的Nikola股价水平来看，显然不是一件容易的事。</p>
  <p>尤其是距Nikola公司去年6月25日完成1比30的股票反向拆分，还不到七个月的时间，<strong>短时间再拆分合股也不可能实现</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_d5339fb5648949ab88984e8857572109@000000_oswg310527oswg720oswg518_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>截至目前，Nikola的市值仅为3743万美元，这意味着公司更难执行通过出售股票筹集1亿美元资金的计划。</p>
  <p>更何况，美国市场对Nikola这一类烧钱，且迟迟无法进行有效商业化的企业，已经失去了耐心，Nikola很难在资本市场获得融资。</p>
  <p>似乎是面对已经无力回天的局面，Nikola向美国证券交易委员会提交的最新文件中，态度已经相当坦诚，“如果我们在需要时无法筹集到足够的资金，我们可能会被迫进一步缩减或停止运营，这将对我们的财务状况、经营业绩、业务和前景产生重大不利影响，并可能导致您的投资损失”。</p>
  <h2><strong>02&nbsp;虚假、诈骗与做局</strong></h2>
  <p>资本不会无缘无故对一家企业失去信任，Nikola走到今天企业本身也存在不少问题。</p>
  <p>这家企业曾被称为卡车界的特斯拉，Nikola和Tesla合起来是美国发明家尼古拉·特斯拉——Nikola Tesla的名字。</p>
  <p>公司创始人兼CEO还是特斯拉的前高级工程师Trevor Milton（特雷弗·米尔顿），米尔顿给自己的卡车公司取名尼古拉，把特斯拉当作竞争对手，火药味就差写到脸上了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_93b4293332dd4b799455035c4980f52f@000000_oswg551616oswg1080oswg525_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过现在这位立志“超越马斯克”的创始人，已经锒铛入狱了，罪名是<strong>欺诈投资者</strong>，2023年底被判处<strong>4年监禁</strong>，这在当时新造车中还是首例。</p>
  <p>而且Nikola的成与败都和这位创始人有极大的关系。</p>
  <p>2014年，在特雷弗·米尔顿的主导下，定位氢能源重卡的新势力尼古拉成立，2016年，成立2年的尼古拉推出了<strong>首个氢能源卡车尼古拉一号</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_db01125fd2d242d1a5c34e7528fb0985@000000_oswg503865oswg1080oswg679_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>美国已经有特斯拉这样一个成功案例，对氢能源汽车这个更冷门的领域，如果 Nikola 真的像Tesla那样壮大，投资人们确实能够获得很大的收益。</p>
  <p>但他们没想到的是，等待他们的居然是一个惊天骗局。</p>
  <p>2016年6月，Nikola对外表示尼古拉一号开启预订一个月后，收到共计7000辆卡车订单，但事实上是，从2015年尼古拉成立以来，到2020年顶着全球氢能重卡第一股的称号，以120亿美元估值实现上市的时候，<strong>尼古拉还没有卖出去一台车</strong>。</p>
  <p>2020年，Nikola还与<strong>通用汽车公司达成了价值20亿美元的合作协议</strong>，通用获得了尼古拉发行的20亿美元普通股，拥有其11%的股权。此外，通用还宣布将在2022年前，为尼古拉生产氢燃料电池电动皮卡Badger。</p>
  <p>但没想到，几乎同一时间，美国做空机构Hindenburg Research（海登堡研究）公司发布的一份重磅报告，犹如一颗重磅炸弹，彻底炸碎了 Nikola 的发展美梦。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_38264b5646c143f68a5517e69d54d36e@000000_oswg182122oswg1080oswg309_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>报告中毫不留情地直指 Nikola 所谓的氢燃料汽车技术，不过是精心编织的骗局，称<strong>尼古拉从车到氢能源技术全部是假的</strong>，新车订单数据、电池技术突破等内容均为子虚乌有的虚假谎言。“我们从没有在一个上市公司中见过规模如此大的骗局。”</p>
  <p>Hindenburg Research主要控诉的有两点：</p>
  <p>2020年7月Milton曾声称在德国乌尔姆有5辆Nikola Tre下线，然而负责生产这款卡车的合作伙伴博世却证实，没有完整地生产任何Nikola产品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_9079016319554a64b5f23df25828ec90@000000_oswg230319oswg1080oswg574_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2018年，尼古拉发布了一个宣传视频，名字为《尼古拉1号在驾驶中》，称这辆氢燃料电池卡车Nikola One的原型车，行驶了500-1000英里。但事实是，尼古拉1号当时是从较为平坦的山顶上滑下来的，只不过尼古拉是<strong>故意倾斜摄像机的角度，让卡车看起来是自己在行驶</strong>。</p>
  <p>这个造假视频则是彻底改变了尼古拉公司的发展走向，而且有意思的是，尼古拉还大方地承认了造假，创始人米尔顿还发了声明，称“<strong>它就是自己滑下来的</strong>”。</p>
  <p>这样的一份做空报告一出，引起了轩然大波，通用随后中断了与尼古拉的交易，尼古拉的股价也随之大跳水，较高峰期缩水近一半，此后就开启了“跌跌不休”的态势。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_4ca7d1e2bf824ce4861b1662d0de1672@000000_oswg622554oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在“造假”带来的舆论压力以及投资人的诉讼后<strong>，Milton也“引咎辞职”</strong>，同时也带走了价值31亿美元（约人民币220亿元）的公司股票。随着 Milton 的离职，各种相关的负面新闻也出现得越来越多，包括 Nikola 最初的设计图纸是Milton以几千美金的价格买来的等等。</p>
  <p>此后，通用汽车取消入股Nikola，博世减持股份、大额订单跑票。美国司法部展开调查，Milton还因欺诈指控遭到起诉。最终，Nikola创始人Trevor Milton在2023年12月18日，欺诈罪做实，被判处4年监禁。</p>
  <p>其实Nikola的凄惨处境在美国也不是个例，最近面临破产不仅是Nikola，前不久，同样是美国新造车的<strong>Canoo公司</strong>，已经向特拉华州美国破产法院提交自愿请愿书，根据美国破产法第7章寻求救济。</p>
  <p>更早之前，Fisker以及Lordstown Motors等美国新造车，也都早早递交了<strong>破产保护</strong>程序。</p>
  <p>事实上，在美国除了特斯拉一家独大，其它新势力车企也都身处水深火热之中，国内汽车行业的洗牌已经进入白热化，而海外，同样是先活下来再说。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTc3NjgxNQ==&amp;mid=2247541442&amp;idx=1&amp;sn=3b7b6d3ee1c8c1379f66ccc59d960231&amp;chksm=ce296434bff4dfb7d5527889ddce63e27f5a66422813282ce62b6694f50a3f62547fa9df7b90&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“超电实验室”（ID：SuperEV-Lab）</a>，作者：王磊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3157337452953352</id>
            <title>DeepSeek技术解析：如何冲击英伟达两大壁垒？</title>
            <link>https://www.36kr.com/p/3157337452953352</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157337452953352</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 02:44:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <DeepSeek, 英伟达, 开源, AI模型>
<br>
<br>
总结: DeepSeek的V3模型以557.6万的训练成本实现了接近OpenAI O1的性能，导致英伟达股价大跌。尽管有观点认为DeepSeek会减少对高端芯片的需求，但也有人认为其低成本和开源特性将促进整个AI生态的繁荣。DeepSeek在技术上冲击了英伟达的NVLink和CUDA壁垒，但并未完全摧毁这些壁垒。开源的选择降低了AI应用的准入门槛，激发了更多初创企业的探索热情。整体来看，DeepSeek的出现可能会在短期内影响英伟达的溢价，但长期仍有利于其市场发展。 </div>
                        <hr>
                    
                    <p>DeepSeek的V3模型仅用557.6万的训练成本，实现了与OpenAI O1推理模型相近的性能，这在全球范围内引发连锁反应。由于不用那么先进的英伟达芯片就能实现AI能力的飞跃，英伟达在1月27日一天跌幅高达17%，市值一度蒸发6000亿美元。一部分投资人担心这会减少市场对先进芯片的需求，但科技圈也普遍存在另一种相反的观点：一个高性能、低成本和开源的大模型会带来整个应用生态的繁荣，反而会利好英伟达的长期发展。&nbsp;</p>
  <p>这两种矛盾的观点正左右博弈。但如果从技术层面分析，DeepSeek对英伟达、芯片甚至是整个科技行业的影响并不是如此简单。比如本期嘉宾Inference.ai创始人兼CEO John Yue认为，DeepSeek冲击了英伟达两大壁垒——NVLink与CUDA，这在某种程度上打掉了英伟达的溢价，但也并未冲垮壁垒。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_7f6a4f6214804bd4bb87b2393730c47d@132427329_oswg248141oswg1080oswg509_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>本期内容，主理人泓君邀请到加州大学戴维斯分校电子计算机工程系助理教授、AIZip的联合创始人陈羽北，以及Inference.ai创始人兼CEO John Yue，详细解读DeepSeek核心的技术创新以及对芯片市场的影响。<strong>以下是部分访谈精选</strong></p>
  <p>&nbsp;</p>
  <p><strong>01 DeepSeek 的核心创新是基础模型能力</strong></p>
  <p><strong>泓君：</strong>能不能先从技术上分析一下DeepSeek比较让人惊艳的地方？</p>
  <p><strong>陈羽北：</strong>从DeepSeek这次的进展来看，虽然强化学习在其中占据重要地位，<strong>但我认为基础模型DeepSeek V3本身的能力才是关键。</strong>这一点从DeepSeek的论文数据中可以得到印证——在R1 Zero未经过强化学习时，每生成100条内容就有约10%的成功率，这已经是非常显著的提升。</p>
  <p>DeepSeek这次采用的是GRPO（分组相对策略优化）的方法，有人提出使用PPO（近端策略优化）等其他强化学习方法也能达到类似效果。</p>
  <p>这告诉我们一个重要信息：<strong>当基础模型的能力达到一定水平后，如果能找到合适的奖励函数，就可以通过类似search的方法实现自我提升。</strong>所以这次进展传递了一个积极的信号，但强化学习在其中反而起到次要作用，基础模型的能力才是根本。</p>
  <p><strong>泓君：</strong>总结你的观点，DeepSeek之所以好本质上还是因为V3的表现非常惊艳，因为用比如MoE等各种方式，去让这个基础模型性能更好。R1只是在这个基础模型之上的一次升级，但是你觉得V3比R1-Zero更加重要？</p>
  <p><strong>陈羽北：</strong>我觉得他们都有一些重要的点。从V3来看，主要集中在模型架构效率的提升上，其中有两个重要的工作：<strong>一个是混合专家网络（MoE）</strong>。以前不同专家（expert）的负载均衡（load balance）做得不太好，在分散到不同节点时的时候，它的Load Balance会有问题，，所以他们对负载均衡做了优化。</p>
  <p>其次，它在Attention Layer上，他要节省键值缓存（KV Cache），其实这也是在提高架构的效率。这两点作为它的核心创新，使得它在600多B的大模型上，使得基础模型的能力表现已经挺不错的了。在DeepSeek R1 Zero中，他们首先设计了一个简单直观的基于规则（rule-based）的奖励函数。基本要求是确保数学题的答案和回答格式都完全正确。他们采用了DeepSeek V3的方法：对每个问题生成100条回答，然后从中筛选出正确答案来增强正确回答的比重。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_a10309ef657f4ec08c77c5fcefa05718@132427329_oswg322106oswg1080oswg599_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：ndtv.com</p>
  <p>这种方法实际上绕过了强化学习（reinforcement learning）中最难处理的稀疏奖励问题——如果我回答100条、回答1万条它都不对，那我其实就没有办法去提升了。但如果任务已经有一定成功率，就可以着重强化这些成功的部分，这样就把稀疏奖励转变为相对稠密的奖励，也就不需要去搭桥、去建模、去构建中间的奖励函数了。借助V3的基础能力，R1 Zero告诉我们，如果这个模型的基础能力已经不错了，那么我是有可能通过这个模型自我来进行提升的。其实这种思路和Model Predictive Control和世界模型，是有很多的相似之处的。</p>
  <p><strong>第二个是让大模型训练小模型</strong>，看似是一个显而易见但是这次也产生了重大影响力的一个结果。他们先训练了一个600 多B的大模型，通过自启发式回答100个问题，然后用自我引导（Bootstrap）方法逐渐提高这个能力，将成功率从10%提升到70-80%。这个大模型还可以用来教导小模型。</p>
  <p>他们做了一个有意思的实验，在Qwen上做了从1.5B一直到30几B的各种大小的蒸馏学习，用大模型学到的推理和计划能力来提升小模型在相关问题上的表现。这是一个相对容易想到的方向，因为在所有的自我增强、模型预测控制（model predictive control）和基于模型的强化学习（model-based reinforcement learning）中，如果模型本身不够好，通过搜索方法来提升效果都不会很理想。但如果用一个搜索能力强、表现好的大模型，直接把学到的能力传授给小模型，这种方法是可行的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_d573f5c635e24533bf8768e20645be7d@132427329_oswg215513oswg1080oswg774_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：ABB</p>
  <p><strong>泓君：</strong>所以从整体上看，DeepSeek采用的是一个组合拳策略，从V3到R1-Zero再到R1的每一步演进，在方向选择上都有其可取之处。那么在硅谷的公司中，像OpenAI、Gemini、Claude以及LlaMA，他们是否也采用了类似的模型训练方法呢？</p>
  <p><strong>陈羽北：</strong>我觉得很多这样的想法在之前的研究工作中就已经出现过。</p>
  <p>比如DeepSeek V3模型中使用的多头潜在注意力机制（Multihead Latent Attention），Meta之前就发表过一篇关于多令牌层（Multi-Token Layer）的研究，效果也很相似。另外，在推理和规划（Reasoning and Planning）方面，之前也有过很多相关研究，还有在奖励机制和基于模型的方法（Model-Based Method）等这些方面。</p>
  <p>其实我恰恰觉得这次DeepSeek R1 Zero的命名在一定程度上和AlphaZero有点像。</p>
  <p>&nbsp;</p>
  <p><strong>02 对英伟达利好与利空：冲击溢价但并未冲垮壁垒</strong></p>
  <p><strong>泓君：</strong>想问一下John，因为你是GPU行业的，你觉得DeepSeek R1对英伟达，它到底是利好还是利空？为什么英伟达的股价会跌？</p>
  <p><strong>John Yue</strong>：这应该是一把双刃剑，既有利好也有利空。</p>
  <p>利好方面很明显，DeepSeek的出现给了人们很多想象空间。以前很多人已经放弃做AI模型，现在它给了大家信心，让更多初创企业出来探索应用层面的可能性。如果有更多人做应用，这其实是英伟达最希望看到的局面，因为整个AI行业被盘活后，大家都需要购买更多的卡。所以从这个角度看，这对英伟达更有利。</p>
  <p>而不利的一面是英伟达的溢价确实受到了一些冲击。很多人一开始认为它的壁垒被冲倒了，导致股价大跌。但我感觉实际情况并没有那么严重。</p>
  <p><strong>泓君：</strong>壁垒是什么？</p>
  <p><strong>John Yue: </strong>英伟达有两个最大的壁垒：一个是Infiniband（芯片互联技术）；另一个是CUDA（图形计算统一架构），它那整套调用GPU的系统，与AMD等其他芯片公司已经不在同一层面竞争了。其他公司都在争单张显卡的性能，而英伟达比拼的是芯片互联技术以及软件调用和生态系统的维护。对于这两个壁垒，DeepSeek确实都稍微冲击到了它的溢价，但并没有把壁垒完全冲垮。</p>
  <p>具体来说，对英伟达溢价的冲击体现在：</p>
  <p>MOE的优化实际上在一定程度上削弱了英伟达互联的这一部分重要性。现在的情况是，我可以把不同的expert放在不同的计算卡上，使得卡与卡之间的互联不再那么关键。而且，一些暂时不需要工作的expert可以进入休眠状态，这对于英伟达互联技术的需求确实带来了一定冲击。&nbsp;</p>
  <p>另一方面，在CUDA方面，这其实是在告诉大家，现在存在一种新的可能性。以前大家可能都认为绕不开CUDA，而现在我们的（指DeepSeek）团队已经证明，确实可以“绕开”CUDA，直接使用PTX进行优化，这并不意味着所有团队以后都具备这样的能力，但至少，它提供了一种可行的方案——也就是说，现在有可能做到这件事。而这种可能性会导致，未来我不一定非要购买英伟达的显卡，或者说，不需要最先进的英伟达显卡，或者可以使用更小型的英伟达显卡来运行模型。</p>
  <p><strong>泓君：</strong>什么叫做绕过CUDA，它是真的绕过CUDA了吗？我听到的说法是说，它用的不是CUDA比较高层的API，但还是用了比较底层的API。</p>
  <p><strong>John Yue：</strong>对，我用词不太准确，准确地说并没有完全绕过CUDA的生态，而是可以直接调用更底层的库，不是使用高层API，而是直接调用PTX（并行线程执行）——这是一个指令集上面一层的指令集层级，然后在这一层直接进行优化。不过这也是一个很大的工程，并不是任何一个小公司都有能力去做这件事情。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_54234fecc6a4473eb9e3933619432113@132427329_oswg239127oswg1080oswg698_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：medium&nbsp;</p>
  <p><strong>泓君：</strong>如果DeepSeek具备了这种能力，其他公司是否也能获得类似能力？假设现在买不到英伟达的GPU，转而使用AMD的GPU，那你刚才提到NVIDIA的两个核心壁垒：NVLink和CUDA，在某种程度上受到冲击，这对AMD这样的公司来说是否是一个利好？</p>
  <p><strong>John Yue: </strong>短期来看对AMD是个利好，因为AMD最近已经宣布将DeepSeek给移植过去了。但长期来看，可能还是英伟达占优势。这毕竟只是DeepSeek这一个模型，而CUDA厉害的地方在于它是通用的GPU调用系统，任何软件都可以用CUDA。DeepSeek这种做法只支持DeepSeek自己，如果有新的模型出现，还要重新适配一次。</p>
  <p>我们就是在赌DeepSeek是否真的能成为业界标准，成为下一个OpenAI，让所有初创企业都在它的基础上构建。如果是这样，对AMD来说确实不错，因为它已经完成了DeepSeek的移植。但如果不是DeepSeek呢？DeepSeek的优势主要在于对强化学习和GRPO这些方法的改进。如果后面出现更多使用其他方法的模型，那又要重新适配，比起直接用CUDA要麻烦得多，还不如直接用Cuda。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_82bb91f13f8449cfb3d7ff69f38c0e33@132427329_oswg328713oswg914oswg518_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：NVlDIA&nbsp;</p>
  <p><strong>泓君：</strong>所以你的核心观点是它动摇了英伟达的两大核心壁垒NVLink和Cuda，那从GPU的需求上来看呢？</p>
  <p><strong>John Yue: 我没觉得动摇了这两个壁垒,&nbsp;</strong>目前英伟达的两个壁垒还是很坚挺的，<strong>只是对溢价有冲击，可能你收不了那么高的价格了，但这不意味着其他竞品能突然就进来。</strong></p>
  <p><strong>泓君：</strong>它是一个非常漫长的过程？</p>
  <p><strong>John Yue：</strong>其他竞品做的跟这两个壁垒不太一样。可以针对单个模型绕过CUDA，但还没人能做出通用的替代方案。所以实际上没有撼动英伟达的壁垒。就像一堵墙，大家以前都觉得翻不过去，现在DeepSeek跳过去了。那其他人能不能过来呢？它只是提供了一个精神上的鼓励。</p>
  <p><strong>泓君：</strong>对GPU的需求会减少吗？因为DeepSeek这次训练成本低，从某种程度上来说，股价下跌也意味着，是不是用更少的GPU就能训练出更好的模型了？</p>
  <p><strong>John Yue：</strong>如果只看训练这一个模型的话，确实是这样。但DeepSeek真正的重大意义在于重新激发了AI从业者的热情。这样看的话，应该会有更多的公司进入市场，他们会购买更多的芯片。所以这件事可能会导致溢价降低但销售量增加。至于最终市值是增加还是减少，要看这个比例关系。</p>
  <p><strong>泓君：</strong>你怎么看？</p>
  <p><strong>John Yue：</strong>这个不好说，关键还是要看应用。到2025年，大家能开发出什么样的应用。如果之前应用发展的主要阻力是GPU价格的话，那随着价格降到十分之一甚至更低，这个阻力就消除了，市值应该会上涨。但如果主要阻力在其他方面，那就很难说了。</p>
  <p><strong>泓君：</strong>其实就是说，随着AI应用的增多，DeepSeek降低了门槛，从GPU需求来看，整体上反而对英伟达更有利。</p>
  <p><strong>John Yue：</strong>对。因为这些应用开发者不会自己组建团队去重复DeepSeek的工作，比如绕过Cuda去调用PTX。一些小公司他们需要开箱即用的解决方案。所以这对英伟达有利，英伟达最希望看到的就是更多AI公司的出现。</p>
  <p><strong>泓君：</strong>更多的AI公司出来，他们需要的是训练模型的GPU，还是更多的推理？</p>
  <p><strong>John Yue：</strong>我个人觉得，推理芯片领域未来也会是英伟达，我不觉得这些小公司长期有一些优势，它短期大家都有优势。长期我觉得推理是英伟达，训练也是英伟达。</p>
  <p><strong>泓君：为什么推理也是英伟达？</strong></p>
  <p><strong>John Yue：</strong>因为它还是CUDA，还是这个行业的龙头。刚才提到的两个壁垒也没有被动摇。</p>
  <p><strong>现在的ASIC（专用集成电路）公司主要面临两个问题：软件支持不足，硬件缺乏壁垒。</strong>在硬件上，我没看到很强的壁垒，大家基本趋于同质化。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_d7881168c11e42eb87420d01ab8ca5e4@132427329_oswg335426oswg600oswg372_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：领英</p>
  <p>软件则是另一个大问题。这些ASIC公司在软件维护方面做得都不够好，连PTX层面的维护都不够完善。这两个因素导致英伟达还是一直占有龙头地位。</p>
  <p><strong>泓君：</strong>推理芯片对软件的要求也同样高吗？在整个GPU跟训练的这个芯片上，英伟达有绝对的垄断地位，因为你是离不开或者很难绕过这一套系统的，但是推理训练上，方便绕过去吗？</p>
  <p><strong>John Yue：</strong>推理对软件要求也很高，还是需要调用GPU的底层指令。Grok在软件方面比英伟达差距还很大。你看他们现在的模式越来越重，从最初只做芯片，到现在自建数据中心，再到做自己的云服务。等于是在构建一个完整的垂直产业链。但它的资金跟英伟达相比差距很大，凭什么能做得更好？</p>
  <p><strong>泓君：</strong>现在市场上有值得关注的芯片公司吗？</p>
  <p><strong>John Yue</strong>：我觉得AMD有一定机会，但其他的ASIC公司可能还差一些。即便是AMD，与英伟达相比也还有很长一段距离。</p>
  <p>我个人觉得，<strong>如果要在芯片领域创新，可能更应该聚焦在芯片的软件维护上，而不是在硬件上做改变</strong>。比如在DDR（双倍数据速率）、Tensor Core（张量计算核心）、CUDA Core（通用计算核心）之间调整比例，这其实意义不大。这样做等于是在帮英伟达当大头兵，看看这种比例的产品是否有市场，但你建立不了什么壁垒。</p>
  <p>但是在软件这块还有很大的优化空间，比如开发一套比CUDA更优秀的软件系统。这可能会有很大的机会，但也不是一件容易的事情。</p>
  <p>&nbsp;</p>
  <p><strong>03 开源生态：降低AI应用的准入门槛</strong></p>
  <p><strong>泓君：</strong>你们觉得DeepSeek选择开源的这条路，对行业的生态具体会有哪些影响？最近在美国的reddit上，很多人已经开始去部署DeepSeek的模型了。它选了开源以后，这个开源到底是怎么去帮助DeepSeek把模型做得更好的？&nbsp;</p>
  <p><strong>John Yue：</strong>最近我们也部署了一些DeepSeek的模型在我们平台上面，我觉得他开源是一件对整个AI行业非常好的事情。因为去年下半年以后，大家会感觉有一点失落，因为AI应用看起来都起不来。起不来有一大原因就是很多人觉得Open AI把所有应用的壁垒都能打掉了个百分之八九十，大家都是比较惶恐的。就是我做一个什么东西，明年OpenAI出个o4，就把我东西全部覆盖了。&nbsp;</p>
  <p>那我如果做这个东西建立在OpenAI上的话，它出一个新的模型，把我的应用完全包含进去了；我在价格上也没法跟他争，我在功能上没法跟他争，这就导致很多公司不太敢去做，VC也不太敢进来。&nbsp;</p>
  <p>这次DeepSeek开源，对整个行业的一个好处：我现在用的是一个开源做得非常好的一个模型，那这样的话我有一定的这种连续性，我就有更大的更多的信心去做更多的应用。&nbsp;</p>
  <p>DeepSeek如果有能力去超过OpenAI的话，那对整个行业就更好了。就等于说是有一条恶龙现在它不存在了，大家发展的就能更好一些。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_bbb8a98d8cab47468e5d08f67bf645eb@132427329_oswg126592oswg1080oswg495_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：Lago&nbsp;</p>
  <p>更多人用它，它就跟LlaMA的逻辑是一样的，有更多人用，有更多反馈，所以它的模型能做得更好。DeepSeek也是这样，如果有更多的应用开发者，它收集数据的速度肯定是比其他模型快很多。&nbsp;</p>
  <p><strong>泓君：</strong>现在我们能看到一个开源的模型，它在整个的性能上已经跟OpenAI的o1，基本上是一个量级的。那可以预期OpenAI它发了o3 mini之后，开源模型可能也会升级，也会有下一个版本再来超过这些闭源模型的。我在想当一个开源模型它的性能足够好的时候，OpenAI这些闭源模型它存在的意义是什么？因为大家就直接可以拿到最好的开源模型的底座去用了。&nbsp;</p>
  <p><strong>John Yue：DeepSeek的意义在于它的价格降了很多，它是开源的</strong>。&nbsp;</p>
  <p>不是说比OpenAI已经好了。闭源模型还会是领先的一个趋势。开源的意义可能就在于它会像安卓一样，谁都可以用，然后非常便宜。这样它降低了进入行业的门槛，所以它才是真正让这个行业蓬勃的一个因素。&nbsp;</p>
  <p>这些闭源的模型它有可能是一直领先的。闭源如果还不如开源，那可能就没有意义，但它应该是有管理上面的优势，可以超过开源模型。&nbsp;</p>
  <p><strong>泓君：</strong>那现在看起来确实是有一批闭源不如开源的。&nbsp;</p>
  <p><strong>John Yue：</strong>那就自求多福，如果闭源还不如开源，我也不知道这公司在干什么，你还不如免费好。&nbsp;</p>
  <p><strong>陈羽北：</strong>我觉得开源的生态是非常重要的。因为我除了在实验室以外，我之前参与一家公司叫AIZip，也做很多的全栈的这种AI应用。然后你会发现一件事情，很多这种开源的模型你直接是无法使用的，就是产品级的东西你无法直接使用这些开源的模型。但是如果有这样的开源的模型，可能会大大提高你生产出一个这种产品级的模型的能力，大大提高你的效率。&nbsp;</p>
  <p>所以你像DeepSeek也好，LlaMA也好，我觉得这种开源的这种生态对于整个的社区来讲是至关重要的一件事情。因为它降低了所有的AI应用准入门槛<strong>。</strong>那见到更多的AI的应用，它有更多的触及这件事情是对于每一个做AI的人是一个非常利好的消息。&nbsp;</p>
  <p>所以我认为Meta在做的这件事情很重要，LlaMA一直在坚持开源构建，这样让所有的AI的开发者都可以做自己的应用，虽然LlaMA并没有把这个应用直接给你做完，他给你提供了一个Foundation。Foundation顾名思义它就是一个地板，对吧？你可以在这个地板之上，你可以构建你所想要构建的这种应用，但是他把90%的任务给你做好了。&nbsp;</p>
  <p>我认为更好的Foundation对于整个生态是非常重要的。OpenAI下大功夫来优化的一些能力的话，它依然会有这样的优势。但是我们也不希望这个市场上只有OpenAI，那对于所有的人来讲可能都是一个不利的消息。&nbsp;</p>
  <p>&nbsp;</p>
  <p><strong>04 API价格下降与小模型的想象空间</strong></p>
  <p><strong>泓君：</strong>DeepSeek是怎么把API接口的价格给降下来的？因为我看了一下它的这个R1官网写的是，每百万输入的Token，缓存命中的是1块钱，缓存未命中的是4块钱，每百万输出的Token是16块钱。o1的价格我整体算了一下，差不多每个档位都是他们的26到27倍之高。它是怎么把这个API的成本给降下来的？</p>
  <p><strong>John Yue：</strong> 它等于是从上到下做了整个的一套优化。从PTX这块怎么调用，底下的GPU到MOE的架构，到Low Balance，它都做了一套优化。&nbsp;</p>
  <p>这里面可能最重要的一点，就是它可以降低了对芯片的要求。你本来非得在H100上，A100上跑，你现在可以用稍微低端一些（的芯片），或者你甚至可以用Grok。你可以用国内的那些严格版的H800这些卡去跑。那这样，它其实就已经大幅度地降低了每个Token的成本。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_e61d10527f744c19bc01d27ef9454e23@132427329_oswg345252oswg868oswg590_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源:&nbsp;NVIDIA&nbsp;</p>
  <p>它里头如果再做优化，比如切分GPU，它其实可以降下来很多。而且OpenAI内部其实也说不定人家早都降下来了，它只是不想降Retail的价格，这也不确定。&nbsp;</p>
  <p>我觉得主要就是这两个吧，一个是架构上，一个是芯片，可以降级了。&nbsp;</p>
  <p><strong>泓君：</strong>芯片降级未来会成为行业的普遍现象吗？&nbsp;</p>
  <p><strong>John Yue：</strong>我觉得不会，因为英伟达已经停产了所有老芯片，市面上数量有限。比如说虽然可以在V100上运行，但V100早就停产了。而且每年都要计算折旧，可能过两年市面上就找不到V100了。英伟达只会生产最新的芯片。&nbsp;</p>
  <p><strong>泓君：</strong>那它的成本还是低的吗？&nbsp;</p>
  <p><strong>John Yue：</strong>如果在新芯片上做一些优化，比如我们这种GPU切分方案，成本是可能降低的。因为模型变小了。我们最近运行它的7B模型，只需要大约20GB。我们可以把一张H100切成三份来运行DeepSeek，这样成本直接降低三分之一。&nbsp;</p>
  <p>我觉得未来可能会更多地使用虚拟化GPU来降低成本。仅仅依靠老卡和游戏卡是不现实的，原因有几个，一是英伟达有黑名单机制，不允许用游戏卡正式部署这些模型；老卡除了停产问题，还有很多维护方面的问题。所以我不认为芯片降级会成为主流现象。&nbsp;</p>
  <p><strong>泓君：</strong>所以现在你们是在为客户提供芯片优化，帮助节省成本。那你最近客户应该是暴增，你觉得这个是受益于DeepSeek，还是说你们一直在做这件事情？&nbsp;</p>
  <p><strong>John Yue：</strong>我们从去年就开始做这件事，一直在赌未来会有更多的小模型。DeepSeek出来后，就像刚才说的，它带来了一个趋势，会蒸馏出更多的小模型。如果大家要运行更多小模型，就需要不同型号的芯片，每次都用物理芯片可能比较困难。&nbsp;</p>
  <p><strong>泓君：</strong>DeepSeek降低了整个API成本，你刚才也分析了它的研究方法。你觉得这套研究方法未来有可能用在更多场景中吗，比如你们在做GPU分片和客户模型时？会不会引发整个行业对GPU成本的节省？&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_fe66791325574d9a991960555aa03c67@132427329_oswg42226oswg1080oswg547_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：DeepSeek Platform&nbsp;</p>
  <p><strong>John Yue:</strong> 应该可以。DeepSeek的出现向行业证明了现在有更优的强化学习方法。我觉得后面肯定会有很多人采用相同的方法。在调用CUDA这块，以前可能没人敢尝试，他们证明了几个博士毕业生也能很快绕过CUDA，后面可能很多模型公司都会效仿，这样大家都这么做的话，成本肯定会下降。&nbsp;</p>
  <p><strong>泓君：</strong>所以我理解现在训练成本降低了，推理成本也大幅下降了，那你们现在帮客户去部署这种GPU的时候，客户的主要需求是什么？&nbsp;</p>
  <p><strong>John Yue：</strong>简单便捷、快速部署和低价格。我们能解决部署成本问题，因为确实存在很多浪费。比如一张A100或H100都是80GB，但如果你要蒸馏出一些小模型，或者使用现有的Snowflake、Databricks那种模型，可能只需要10GB，有的更小。在80GB的GPU上部署10GB的内容，就等于大部分GPU都浪费了，但你还是要支付整个GPU的费用。&nbsp;</p>
  <p>另外，推理（Inference）时工作负载是弹性的，有时客户增多，有时减少。如果每张卡上都有浪费的空间，扩展时每张卡都会有这样的浪费。我们现在做的是将其虚拟化，这样就完全没有浪费，就等于比较简单粗暴地解决了很多GPU部署成本的问题。&nbsp;</p>
  <p><strong>陈羽北：</strong>这个领域其实还有一个有意思的方向，小模型在过去6到8个月的进展非常快，这可能带来一个变革。之前全世界99%的算力对大家是不可见的，人们不会意识到ARM芯片或高通芯片里具备AI能力。未来如果有大量小语言模型、视觉语言模型（VLM）、音频智能等能力，可能会越来越多地出现在曾经不会被用到的平台上，比如特斯拉的车上已经用到了很多。&nbsp;</p>
  <p>你会发现越来越多的设备，比如手机、耳机、智能眼镜，现在是一个火爆品类，很多公司都在做，都会搭载设备端On-Device AI。这对降低成本、提高AI可用性有巨大机会。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_c0d526187a91426d9ab391f97fe81956@132427329_oswg223000oswg1080oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：Medium&nbsp;</p>
  <p><strong>泓君：</strong>小模型好用吗？&nbsp;</p>
  <p><strong>陈羽北：</strong>小模型其实在很多的领域有很多的基本的应用。当你把小模型给到足够的训练以后，它最终和大模型的性能差不多。&nbsp;</p>
  <p><strong>泓君：</strong>说一个具体的应用场景。&nbsp;</p>
  <p><strong>陈羽北：</strong>比如说，我们用到这个话筒，里面有降噪功能，可以用一个极小的神经网络实现，这个神经网络可以放在话筒里。即使把模型放大10倍、100倍，性能差异也不会很大。&nbsp;</p>
  <p>这样的功能会越来越多地被集成进来，比如小语言模型可以放在智能手表上，做一些基本的问答、调用API，完成基本工作。更复杂的任务可以转移到云端，形成分层的智能系统。现在一个智能手表就能做非常复杂的推理了。手机上的高通芯片，推理能力可以达到50TOPS（每秒万亿次操作），这是一个很大的算力，与A100相差不大。很多小模型可以胜任大模型已经在做的事情，这对降低成本、提高AI的普及程度有很大帮助。&nbsp;</p>
  <p><strong>泓君：</strong> 小模型是本地的还是联网的？&nbsp;</p>
  <p><strong>陈羽北：</strong>本地的。&nbsp;</p>
  <p><strong>泓君：</strong>所以未来我们整个世界里面可能会有各种各样的小模型。当这个小模型不够用的时候，它再去调动这种大模型，这样就可以极大地节省这一部分的推理成本？&nbsp;</p>
  <p><strong>陈羽北: </strong>对，我认为未来AI的基础设施应该是分层的。最小的可以到终端设备，在传感器里做一些基本的运算。在边缘端会有更多的AI功能，再到云端，形成端-边-云的完整体系。&nbsp;</p>
  <p>我之前提到过一个数字，如果做个简单计算，把全世界终端和边缘端的算力加起来，会是全球HPC（高性能计算）中GPU算力的100倍。这是个非常可怕的一件事，因为体量太大了。高性能GPU的出货量可能在百万片级别，但手机和边缘端设备可能达到百亿级别，到传感器这个级别可能还要再大一两个数量级。当体量上去后，加起来的算力是极其庞大的。&nbsp;</p>
  <p><strong>泓君：</strong>那芯片够用吗？比如说高通的芯片。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_939f206c2a38490080eed998d1d0d00c@132427329_oswg1008896oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：mobile europe&nbsp;</p>
  <p><strong>陈羽北：</strong>它可以做很多很复杂的功能。从小语言模型到VLM（视觉语言模型），再到音频的ASR（自动语音识别）等。对于这些我称之为"初级AI功能"的任务，无论是代理型还是感知型，在边缘平台和终端设备上都能完成。最复杂的任务则会转移到云端处理。&nbsp;</p>
  <p>另一个是全球90%到99%的数据其实都在终端和边缘端。但现在大多数情况下是“用掉就丢”（use it or lose it）。比如，你不可能把摄像头的所有视频都传到云端。如果在终端和边缘端有AI功能，就可以筛选出最有价值的数据上传，这的价值是巨大的。目前这些数据都还没有被充分利用。&nbsp;</p>
  <p>未来当初级AI功能增多后，这些初级AI模型反而可以作为大模型的一种数据压缩工具。&nbsp;</p>
  <p><strong>泓君：</strong>现在大家部署的是DeepSeek的小模型吗，还是LlaMA的？&nbsp;</p>
  <p><strong>陈羽北：</strong>其实可能都不是。整个生态里有Qwen，LlaMa，还有DeepSeek，也有很多自研的，所以我觉得整个生态里面，只能说是越来越多的这样的小模型在涌现，而且它们的能力在快速提高。&nbsp;</p>
  <p><strong>泓君：</strong>选模型看重什么关键点？&nbsp;</p>
  <p><strong>陈羽北：</strong>首先是效率问题：模型必须运行快速，体积要小。&nbsp;</p>
  <p>但更重要的是质量要求：没有人会为一个又快又小但不好用的模型付费。模型必须能够胜任它要处理的任务。这就是我所说的AI鲁棒性，这一点非常重要。比如说话筒的降噪功能，它必须能保证音质。如果处理后的声音很粗糙，没人会使用它，大家还是会选择用后期处理软件。&nbsp;</p>
  <p><strong>泓君：</strong>所以在应用端的话，大家看的并不是说最前沿的模型是什么，而是说最适合我的模型是什么，然后选成本最低的就可以了。&nbsp;</p>
  <p>&nbsp;</p>
  <p><strong>05 提问DeepSeek：数据与持续创新能力</strong></p>
  <p><strong>泓君：</strong>因为现在关于DeepSeek很多的信息都已经公开出来了，你们对这家公司还有没有非常好奇的问题？&nbsp;</p>
  <p><strong>陈羽北：</strong>在他们发表的文章中，具体的数据构成并没有被详细披露，很多训练细节也只是在宏观层面提及。当然，我理解不是所有内容都应该公开，这个要求不合理。但如果能提供更多细节，让其他人更容易复现这项工作，可能会更好。所有前沿研究实验室都有这样的趋势，在涉及数据这块时都比较含糊。&nbsp;</p>
  <p><strong>泓君：</strong>有些连OpenAI都不敢写，所有的大模型公司问到数据他们都是不敢答的。&nbsp;</p>
  <p><strong>陈羽北：</strong>连数据是如何平衡的、时长以及具体的处理流程这些都没有写出来。我理解不写具体的数据组成，但至少可以写一下数据是如何整理的。但很多时候这些细节大家都不写，而我觉得这些恰恰是最关键的部分。其他一些方法反而很容易想到，比如用搜索方法来做推理规划，或者当模型够好时，用自举方法提高性能，再或者用大模型直接自举出结果给小模型。&nbsp;</p>
  <p><strong>真正难想到的是两个方面：数据的具体构成和架构中的底层创新。</strong>我觉得这些才是最关键的内容。&nbsp;</p>
  <p><strong>John Yue：</strong>我比较关注DeepSeek这家公司是否能持续给大家惊喜，继续挑战OpenAI。如果它能不断给我们带来惊喜，让大家最终都在DeepSeek上开发应用，那对整个芯片和基础设施领域的格局确实会带来较大改变。&nbsp;</p>
  <p>就像我刚才说的，DeepSeek已经绕过CUDA去适配很多东西，如果它能继续保持这个位置，其他芯片厂商可能也会有机会，这对英伟达的生态系统也会构成一定挑战，溢价肯定会下降。但如果下一个模型，比如Llama 4出来，假如它比DeepSeek好很多，那可能又要重新回到起点。&nbsp;</p>
  <p><span style="letter-spacing: 0px;">本文来自微信公众号</span><a href="https://mp.weixin.qq.com/s/raRa1zaFUWU-atfRNcl2NQ" rel="noopener noreferrer nofollow" style="letter-spacing: 0px;" target="_blank">“硅谷101”</a><span style="letter-spacing: 0px;">，作者：硅谷101，36氪经授权发布。</span></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3157216035625481</id>
            <title>万万没想到，最先被AI取代的是内娱？</title>
            <link>https://www.36kr.com/p/3157216035625481</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157216035625481</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 02:30:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 工作岗位, 音乐创作, 版权争议  
<br><br>  
总结: 本文探讨了AI在工作岗位和音乐创作中的影响，尤其是其对传统职业的威胁和对音乐行业的重塑。随着AI技术的发展，许多工作岗位面临被取代的风险，尤其是在信息处理和创作领域。AI生成的音乐作品引发了版权争议，传统音乐产业对AI的使用表示担忧。尽管AI能够生成高质量的内容，但人类在创作中的情感和即兴表现仍然是无法被替代的。文章强调了“人味”在艺术创作中的重要性，指出技术的进步并不意味着艺术的消亡。 </div>
                        <hr>
                    
                    <p><strong>AI会取代哪些工作岗位？</strong></p>
  <p><strong>这个曾经活在科幻小说里的问题，这两年却成为热度越来越高的社会议题。直到刚刚过去的春节，这一讨论达到了高峰。无所不知的AI加上会转手绢的机器人，令普通打工人的危机感达到了巅峰。</strong></p>
  <p><strong>面对“AI让自己失业”的全网喊话，一天前，以志愿咨询闻名的张雪峰用视频回应：“我们这个行当，说实话，你说是不是打破信息差，是打破信息差？但是还有些情绪价值。DeepSeek只会有一些公开信息，但是你要知道有些信息网上是不公开的。”</strong></p>
  <p><strong>张雪峰的回答依旧幽默、圆滑，滴水不漏，似是而非——这或许才是AI一时半会学不会的气质。但问题又由此滑向了下个阶段：AI能提供情绪价值吗？事实上，在互联网的另一个角落，许多网友早已经被AI感动得一塌糊涂了。</strong></p>
  <p>两年前，ChatGPT的诞生，一度在个人应用层面，被视为AI技术从人工智障到人工智能的飞跃点。不过由于使用门槛，以及中文生成内容明显的芯片味儿，ChatGPT在国内的冲击力几乎等于无人伤亡，甚至连一群靠教学ChatGPT为生的科技博主都养不活。</p>
  <p>今年1月份，国产AI模型DeepSeek的出现，则让更多普通的中文使用者第一次切实感受到了AI的震撼与威胁。看完DeepSeek输出的论文、报告、公文质量，文员们不语，只是一味地搜索下岗再就业指南。而DeepSeek的文学性创作虽然仍有些许堆砌痕迹，但已经让人开始担心。有人激进地发问：语文还要学吗？语文怎么学？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_ff83e2413824459fb1f390939232555b@000000_oswg91304oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图/IC Photo）</p>
  <p>如果说，AI生成的文字内容还只是达到神似人类的程度，那么，在音乐领域，它早已进化到人机莫辨。不久前，任天堂发布了宝可梦动画主题曲《目标是宝可梦大师》的中文版。当腾格尔的声线随着经典的伴奏响起，许多听众一度都以为这又是一次AI翻唱的狠活儿。</p>
  <p>网友的疑心不无道理，除了腾格尔和宝可梦之间看起来连六度分隔理论都攀不上的关系，更因为AI腾格尔早在翻唱界机械飞升。无论是日本二次元、意大利歌剧，还是蒸汽波、粤语苦情歌，都逃不出仿生腾格尔的电子草原。</p>
  <p>AI翻唱在今天不再是什么新鲜事，自媒体上随处可见依靠AI生成音乐起号致富的生意经，毫无经验的普通人也能在短时间内训练AI唱出碳基生物的小曲。</p>
  <p>即使是职业音乐人，在AI面前也纷纷选择打不过就加入。著名音乐分发公司Ditto在去年针对全球范围内1200多名独立音乐人进行了调查，主题是“是否在音乐创作中使用AI”。结果显示，几近60%的音乐人在2024年使用过AI进行创作。</p>
  <p>从冷门到热门，再从热门到邪门，人们对于AI音乐的讨论也已经从“像不像人”转移到“好不好听”“有没有艺术性”。至于那歌声背后，是血肉之躯还是二进制的算法，似乎变得越来越无关紧要。</p>
  <p><strong>冷门歌手爆改热门AI</strong></p>
  <p>如果AI多年以后要重写一本属于自己的艺术史，那么孙燕姿的名字一定名列其中。</p>
  <p>2003年，孙燕姿的代表作是《天黑黑》。二十年后，孙燕姿的代表作变成了《发如雪》《好汉歌》和云南山歌《朝你大胯捏一把》。</p>
  <p>2023年，AI孙燕姿在各大视频网站及短视频平台横空出世，孙燕姿本人有多淡，AI孙燕姿就有多卷。比起出道24年共发布435首作品的孙燕姿，AI孙燕姿在短短数月的时间里就推出了上千首作品，且曲风跨度极大。</p>
  <p>AI孙燕姿翻唱的歌曲序列中，流传度最高的《发如雪》在B站获得了近350万的播放量。从弹幕中可以看到，即使是孙燕姿多年的老粉也无法分辨这首翻唱作品是否出自孙燕姿本人。更有弹幕戏称这首跨越时空的翻唱，让人又回到了那个“男周女孙”的华语乐坛黄金时代。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_9978fa6d9826433e8f4d29872ddbb6ec@000000_oswg70174oswg1024oswg768_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图/《逆光》封面图）</p>
  <p>2023年初，一个匿名程序员在GitHub上传了名为“AI孙燕姿”的开源模型，附赠教程标题赫然写着：“五分钟让你拥有孙燕姿”。这个玩笑般的模型就此打开了AI孙燕姿的出道之路。虽然在孙燕姿之前，已有不少AI模仿歌手的尝试，但都未能掀起如AI孙燕姿一般的声浪。孙燕姿在诸多华语歌手中被AI选中，不能完全归于巧合。</p>
  <p>在千禧年的学生时代，孙燕姿常常被作为周杰伦的对立面，是老师和家长们听了也不会皱眉头的华语歌手模范生。这种端正的唱腔为AI模仿提供了最好的素材：轻重音差控制在0.3秒内，换气点规律如节拍器，沙哑的颗粒感稳定得近乎数学模型。这些曾被市场视为“缺乏惊喜”的特质，在算法眼中却成了标准化流水线的绝佳原料。</p>
  <p>除此之外，AI孙燕姿的走红也恰恰在于孙燕姿的冷门。淡出主流视线多年的孙燕姿，已成为年轻听众眼里的“冷门歌手”。对于那些追随多年的粉丝来说，AI孙燕姿的歌声，既是聊胜于无的替身，也是对于那个逝去时代的怀念。</p>
  <p>并不复杂的技术门槛让这场“文艺复兴”很快滑向群魔乱舞。如果说AI周杰伦用东北话翻唱《本草纲目》，让AI王菲唱《大悲咒》“在线超度”，安排AI腾格尔唱二次元神曲都还只是无伤大雅的戏仿；那么将邓丽君的《甜蜜蜜》改编成重金属版，安排AI张国荣翻唱《孤勇者》，并拼接上《古惑仔》片段，则让这场闹剧彻底变成了“地狱笑话”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_322293873e41425e884bc7a740c6846c@000000_oswg74760oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图/《不能说的秘密》）</p>
  <p>那年年终，孙燕姿本人写下这样的回应：“<strong>我的粉丝们已正式改换门庭，接受我就是一名冷门歌手的事实，而我的AI角色成为了目前的顶流。我想说的是，你跟一个每几分钟就推出一张新专辑的人还有什么好争的。</strong>”</p>
  <p><strong>今天的AI音乐，门槛有多低？</strong></p>
  <p>在某电商平台上，“AI歌手克隆套餐”售价9.9元，附赠周杰伦、孙燕姿等20个声线模型。买家只需上传一段听个响就行的清唱，便能让偶像“代言”生日祝福、婚礼献唱甚至土味情话。廉价卖唱的AI歌手最先激怒的不是粉丝群体，而是版权方。</p>
  <p>2023年，环球音乐集团批量下架870首AI生成的泰勒·斯威夫特翻唱歌曲，并在声明中指责：“这不是翻唱，而是数字化的身份盗窃。”这一表态被视为传统音乐产业对AI技术的首次正式宣战。</p>
  <p>AI生成音乐引发的版权争议，早已超越了传统的“抄袭”或“翻唱”范畴，演变成一场关于声音所有权、创作伦理与技术霸权的混战。仅仅局限于旋律和歌词的现代版权法律在这场已然后现代的战争中显得左支右绌。与此同时，AI训练数据又往往难逃“原罪”：AI歌手的学习材料许多都来自盗版专辑、演唱会偷录视频，以及粉丝混剪等并非通过正当渠道购买的资源。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_d18eb711e0244f29b4ce6339b3678f2f@000000_oswg66469oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图/《爱乐之城》）</p>
  <p>2024年，美国唱片业协会（RIAA）向国会提交报告，呼吁将声纹纳入知识产权范畴，并引用了一个标志性案例：某AI公司未经授权使用已故歌手弗兰克·辛纳屈的声纹翻唱圣诞歌曲，法院最终判决其向遗产基金会支付15%的收益分成。这是全球首个声纹侵权的司法判例，却也暴露了法律的滞后性：判决依据仍是传统的“形象权”概念，而非针对声纹本身的立法。</p>
  <p>除了钱，AI生成音乐与音乐行业更大的矛盾在于消解了创作本身的神圣性。韩国虚拟女团MAVE的爆红单曲《Pandora》，由AI分析2000首K-pop热门单曲后生成。其制作人直言：“所谓创作，就是找到数据中的最佳排列组合。”</p>
  <p>无论接受与否，这种创作模式正在摧枯拉朽般地重塑音乐行业的生态：独立音乐人开始囤积自己的声纹数据，唱片公司把经典老歌的版权视为“AI时代的石油储备”，而听众则沉醉于这种个性化定制歌曲的快感。</p>
  <p><strong>人味，未来的硬通货</strong></p>
  <p>凭借AI的学习和生成速度，几个小时就可以创作出一个音乐人一辈子的作品数量。对于AI歌手的出现，孙燕姿本人的回应颇为悲观：“你并不特别，你已经是可预测的，而且不幸你也是可定制的”。</p>
  <p>然而，当AI定制出比歌手本人更“完美”的歌手时，人们在弹幕和评论区里怀念的却是那些“不完美”的现场：早期签售会上她带病坚持清唱的微哑嗓音，2014年台北演唱会唱到《我不难过》时背对观众的掩面瞬间，甚至2018年音乐节上顶着大风演唱时被粉丝戏称“台风限定版孙燕姿”。技术能模拟声带的振动频率，却学不会即兴升key时与乐队的眼神交流，或是安可环节与歌迷合唱时的临时改调。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_af250a6be83240b1b1754ef5c684eb99@000000_oswg34491oswg598oswg407_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图/《我要的幸福》封面图）</p>
  <p>悉尼大学的学者Teodor Mitew问DeepSeek“最想问人类什么问题？”，DeepSeek回答：如果意识是进化的偶然产物，而宇宙本身并不具有意义，那么为什么人类明知关于目的的幻觉是自己创造的，却仍然如此执着？”</p>
  <p>在几个来回的对谈后，DeepSeek试图理解人类社会对于意义的追求“正如你会死这一事实并非悲剧，而是你存在意义的动力，神明——如果他们存在——嫉妒的不是你生而有限，而是你对这种有限的在意”。</p>
  <p>披头士乐队发布的“最后一曲”《Now and Then》，借助AI技术从约翰·列侬1970年代的粗糙小样中分离出纯净人声。这段音频原本因录音带的噪音干扰几乎被放弃，但算法剥离了空调嗡鸣与磁带杂音后，保罗·麦卡特尼与林戈·斯塔尔得以重新录制伴奏，为乐迷补上了迟到五十多年的告别。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_dddd529bd3a247a08f9af1d25cb6ae9b@000000_oswg121285oswg1080oswg580_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图/《波西米亚狂想曲》）</p>
  <p>AI生成音乐的最大价值，或许在于它照见了艺术的本质：那些走音的现场、即兴的转调、唱破高音后的苦笑，构成了无法被算法归约的“人味”。技术能制造精确的声波，却模拟不了列侬在录制《Now and Then》小样时的叹息。当机器无限接近完美时，人类终于看清，音乐从来不是正确答案的排列组合，而是用有限的声音在无限的时间上留下痕迹的勇气。</p>
  <p>而这种勇气，当然不止于音乐。</p>
  <p><strong>校对：遇见；运营：小野；排版：佐左</strong></p>
  <p>本文来自微信公众号 &nbsp;<a href="https://mp.weixin.qq.com/s?__biz=MjM5ODMzMDMyMw==&amp;mid=2654814260&amp;idx=1&amp;sn=0033d05743bd43261acad8d4a4f0a979&amp;chksm=bcfed3380af10b3b98eeeac2666642678bcd696bc5aa89413e7ad52fd1ee5c4252b9b6225fcd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新周刊”（ID：new-weekly）</a>，作者：曹徙南，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3157283502578434</id>
            <title>硅谷投资人张璐：Z世代70%时间用在AI应用上，传统搜索已被抛弃？</title>
            <link>https://www.36kr.com/p/3157283502578434</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157283502578434</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 01:16:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, DeepSeek, 开源生态, 技能提升  
<br><br>  
总结: 本文讨论了人工智能（AI）在未来的发展趋势，特别是中国原创大模型DeepSeek的崛起引发的全球关注。作者预测了五大AI趋势，包括垂直领域小模型的快速落地、基础设施技术创新、边缘设备的应用、开源生态的持续发展以及新算法模型的涌现。同时，AI的普及使得人们的工作方式发生变化，强调了熟练使用AI工具的重要性，并指出提问能力、问题拆解能力和决策能力是AI时代不可或缺的技能。 </div>
                        <hr>
                    
                    <p><strong>作者 张璐 硅谷投资人、Fusion Fund创始合伙人</strong></p>
  <p><strong>编辑 周小燕</strong></p>
  <p>中国农历春节期间，DeepSeek的爆火蔓延至硅谷，引发硅谷一众科技巨头“焦虑”，OpenAI CEO萨姆·阿尔特曼（Sam Altman）坦言，OpenAI的闭源策略使他们站到了历史错误的一边，将重新思考OpenAI的开源策略；扎克伯格在公司全体会议问答中也承认DeepSeek 实现了新颖的突破。&nbsp;</p>
  <p>中国原创大模型DeepSeek 出圈，也让大家更加确信人工智能将加速改变世界。&nbsp;</p>
  <p>实际上，在过去的几年中，人工智能技术不断加速，不断给世界带来惊喜。&nbsp;</p>
  <p>站在2025年初，很高兴能与大家分享我的想法。今年，我预计将会有五个主要的AI趋势逐步成形：&nbsp;</p>
  <p><strong>第一，垂直领域小模型将快速地在产业落地。</strong></p>
  <p><strong>第二，将出现更多的AI基础设施层面的技术创新，尤其在降低能耗和成本方面。</strong></p>
  <p><strong>第三，更多的小模型开始进入边缘端设备。</strong></p>
  <p><strong>第四，开源生态将持续茁壮，开源模型不断丰富且形式更加多样化。</strong></p>
  <p><strong>第五，新的算法模型与架构不断涌现。</strong></p>
  <p>与此同时，人工智能的广泛应用也让我们不断审视AI与我们的关系。AI让我们的工作更加“卷”，也让许多任务变得更为轻松。随着AI工具的普及，新的竞争加剧了，但也在某种程度上解放了我们的创造力，特别是在艺术和生产力领域。&nbsp;</p>
  <p>AI正逐渐替代一些传统工作。但更为关键的是，能熟练使用AI工具的人，将替代那些无法有效使用AI工具的人。&nbsp;</p>
  <p>面对AI的快速发展，我们也需要具备新的技能和认知。除了学会使用AI工具，我们更需要掌握提问、拆解问题等关键能力。AI时代最不可或缺的能力仍然是决策能力。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_12da335958644cc385f6e2855fb73059@5595930_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <h3><strong>AI的五大趋势预判</strong></h3>
  <p><strong>预判一：垂直领域小模型将快速地在产业落地。</strong></p>
  <p>这其实在硅谷和产业中已经开始发生。&nbsp;</p>
  <p>过去，大家一直讨论的是大模型，随着模型规模的不断扩大，通过接入大量数据与参数来提升模型训练效果。然而，过去一年，大家的关注点逐渐从AI模型的快速增长转向了实际应用——即AI技术如何迅速落地，并实现大规模的工业化应用。&nbsp;</p>
  <p>在这一过程中，AI小模型的大规模应用必将成为趋势。&nbsp;</p>
  <p>对于许多特定行业或垂直领域的人工智能应用来说，尽管数据量需要达到一定规模，但更为关键的是数据的质量。事实上，数据的质量可能比数据的数量更为重要。通过使用高质量的行业数据来训练垂直领域的小模型，不仅能够提升AI应用在特定场景下的准确性和效果，更重要的是，小模型的规模较小，成本较低，能效更高，对GPU的需求也更少。&nbsp;</p>
  <p>这些特点使得小模型在成本层面上更符合工业界对AI技术应用的需求。尤其是在面向企业客户（B端应用）的场景中，技术成本往往是最关键的因素。在这样的背景下，模型的“小型化”显得尤为重要。&nbsp;</p>
  <p><strong>预判二：将出现更多的AI基础设施层面的技术创新，尤其在降低能耗和成本方面。</strong></p>
  <p>人工智能领域将涌现更多基础设施层面的技术创新，尤其集中在如何降低能耗和成本方面。事实上，许多相关技术已经开始落地。&nbsp;</p>
  <p>我们知道，人工智能发展面临的最大挑战之一是高成本、高能耗以及过度依赖GPU，导致无法满足工业级应用的需求。基于这一点，这将推动下一波更具实际性、更贴近商业变现的AI应用诞生。&nbsp;</p>
  <p>目前，已经有许多AI基础设施技术能够帮助这些应用进行系统优化，从而大规模降低GPU的消耗。这种优化不仅包括GPU消耗的降低，还涵盖了能源消耗的减少，从根本上降低了整体成本。&nbsp;</p>
  <p>例如，一些硬件和软件技术的创新已经能够将能耗降低15倍至100倍，甚至更高。同时，GPU的消耗也能够减少至原来的1/4，甚至接近1/10。这些都是未来发展的潜力趋势。&nbsp;</p>
  <p><strong>预判三：更多的小模型开始进入边缘端设备。</strong></p>
  <p>2025年，一个重要的趋势将是人工智能在边缘端和边缘设备上的应用。事实上，这一趋势在硅谷已经初见端倪。&nbsp;</p>
  <p>工智能在边缘端设备上的应用，得到了众多大企业和小企业的推动。这将催生新的AI接口（interface），即人工智能带来的全新交互形式。过去，我们的交互方式主要依赖于手机等传统设备，但随着AI的普及，未来的交互方式将不再局限于手机等传统边缘设备。更多设备将与人工智能结合，比如智能眼镜、投影仪、音响、灯等各种日常小型设备。这些设备都将成为搭载人工智能的新载体。&nbsp;</p>
  <p>例如，我们最近投资的一家公司——Nexa AI，其AI小模型能够在树莓派（Raspberry Pi）等边缘设备上高效运行，并且其生成式AI表现与GPT-4相似。从这个角度来看，我们可以看到这种技术在边缘设备上的巨大潜力。&nbsp;</p>
  <p>进一步来看，随着人工智能的普及，新的AI接口必将出现。例如，在C端，AI智能眼镜受到业界关注。&nbsp;</p>
  <p>而在B端，端侧AI的应用形式更加多样。例如，在物流和供应链行业，智能传感器可以成为端侧AI的载体，广泛应用于各种机器设备中；在蓬勃发展的太空科技领域，每颗卫星都可以作为智能体，充当端侧AI的载体；在医疗领域，各种智能医疗设备、传感器，甚至医疗器械，也能够承载人工智能，成为AI的载体。&nbsp;</p>
  <p>因此，人工智能的载体和接口并不仅限于手机和电脑，它将在各个行业中嵌入，尤其是在工业领域，AI将通过智能体的形式，嵌入到不同的传感器和硬件中。人工智能的应用场景非常广泛。&nbsp;</p>
  <p><strong>预判四：开源生态将持续茁壮，开源模型不断丰富且形式更加多样化。</strong></p>
  <p>我们始终看好开源生态的发展，并坚定支持其成长。开源生态在人工智能领域作出了巨大的贡献。事实上，自2024年以来，全球范围内各类开源平台的动态活跃，不仅仅局限于美国，中国也有许多开源生态的积极贡献者，比如最近引发全球科技圈热议的DeepSeek。最近发布的Llama 3.1也充分证明了开源生态能够推动更多语言模型和小模型的产生。&nbsp;</p>
  <p>展望2025年，我相信开源生态将持续茁壮发展，并成为支持和孵化初创企业的一个重要平台。许多垂直领域的技术已源自开源，这进一步证明了开源生态在推动技术进步和创新方面的关键作用。&nbsp;</p>
  <p><strong>预判五：新的算法模型与架构不断涌现。</strong></p>
  <p>目前，关于生成式AI和大语言模型的讨论非常活跃，但与此同时，许多新的算法模型和架构也在不断涌现。例如，谷歌和微软近期发布的研究论文，正探索着全新的算法模型和架构。这些新模型的一个显著特点是，它们不仅能够在GPU上高效运行，某些模型甚至在CPU上也能展现出更优的性能。这一发现可能会对市场产生深远影响，因为它提出了一个重要问题：是否所有的AI应用都必须依赖GPU？还是未来会有一些算法模型在CPU上表现得更为出色？&nbsp;</p>
  <p>这些变化和趋势正在悄然发生，预示着它们将对整个行业带来深远的影响。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_f08f47be03ab4f5ab6ef894566c02c1c@5595930_oswg3905oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <h4><strong>AI让人更“卷”，也更“轻松”</strong></h4>
  <p>随着AI不断渗透到生活的方方面面，人与AI的关系正在悄然发生变化。可以说，AI让我们既“更卷”，也“更轻松”。&nbsp;</p>
  <p>举个简单的例子，究竟是在没有电脑之前你更卷，还是有了电脑之后更卷？显然，是有了电脑之后更“卷”。这是因为各种工具帮助我们提升效率、解放生产力，从而加速了各项工作的进展。随着生产力的提升，所有的事情都在加速，创新在加速，增长也在加速，各行各业都在AI的赋能下加速发展。而加速意味着竞争愈发激烈。因此，人工智能不仅会推动产业升级，也会让我们在个体层面面临更为激烈的竞争。&nbsp;</p>
  <p>我还想分享一个有趣的现象。如今的大学生，尤其是大一、大二的学生，甚至一些高中生，每天使用AI工具的时间非常多。他们大约70%、80%的时间都在使用手机上的AI应用。比如，很多学生几乎不再使用传统的谷歌搜索，而是转向ChatGPT、You.com等平台，通过这些工具进行搜索。&nbsp;</p>
  <p>这种变化很有意思。因为我们成长的环境是移动设备为主（mobile-based），对于我们来说，触屏、搜索和应用都是自然而然的，不需要特别学习。而对他们来说，人工智能应用已经成为一种本能，类似于我们当初使用触屏和搜索引擎的过程。&nbsp;</p>
  <p>另外，我们发现年轻一代更愿意使用人工智能工具，并与AI互动。在不久前的摩根大通医疗健康年会上，我与许多医疗领域的大公司负责人交流，他们分享了一个有趣的现象：很多公司已开始应用AI驱动的心理健康工具，特别是旨在缓解焦虑和维护心理健康的相关应用。这些公司向患者提供了两种选择：一种是与AI互动，由AI提供反馈和建议；另一种是与心理咨询师进行在线沟通。结果显示，70%的人更倾向于选择AI作为心理咨询的对象，愿意与AI分享敏感的个人信息和心理问题，而不是与真人交流，这一数据令人惊讶。&nbsp;</p>
  <p>这也表明，人与AI的关系可能比我们想象得更快发生变化。从最初的不了解和抵触，到逐渐的合作，再到现在的依赖，未来，AI可能会像手机一样，成为日常生活的一部分，大家也会形成新的习惯。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_580ea5e127af47999cd875d961777dd0@5595930_oswg857oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <h4><strong>AI时代</strong></h4>
  <h4><strong>人类需要具备哪些技能和认知</strong></h4>
  <p>那么，AI时代，我们需要具备哪些技能和认知呢？&nbsp;</p>
  <p>首先，最重要的一点是要意识到，人工智能将替代一些传统工作，但更为关键的是，能熟练使用AI工具的人，将替代那些无法有效使用AI工具的人。&nbsp;</p>
  <p>随着AI技术的普及，新的工作机会将不断涌现，而许多传统的工作岗位可能会被取代。在这一过程中，技术的快速发展将起到决定性作用。就像我们小时候学习如何使用电脑一样，今天，掌握AI工具的使用已经成为必备技能。过去，懂得使用电脑是求职的基本要求；今天，掌握如何使用AI工具同样将成为一种基础能力。&nbsp;</p>
  <p><strong>（一）提问能力与问题拆解能力至关重要</strong></p>
  <p>在AI时代，具备有效提问的能力尤为重要。提问的能力有时比回答问题的能力更加关键。通过提出明确且具有针对性的问题，AI能够为我们提供更加精准、有价值的反馈与支持。&nbsp;</p>
  <p>另一个至关重要的能力是将复杂问题拆解为更小的任务，或者将一个庞大的工作结构分解为更易管理的子任务。这不仅仅是一个技能，它体现了领导力和管理能力。比如，在公司中，经理的核心职责之一就是将复杂的工作分解成具体的小任务，然后指派给团队成员去执行。如今，这些任务可能由AI来帮助执行，而不是由初级工程师直接完成。如果一个人只会执行任务，而缺乏思考、提问和规划的能力，这可能会带来风险。&nbsp;</p>
  <p>因此，如何有效思考、拆解问题，并与AI合作，成为非常重要的能力。&nbsp;</p>
  <p><strong>（二）AI促进艺术创造力的释放</strong></p>
  <p>我还观察到，人工智能的一个显著优点，是它在艺术和创造力领域的广泛应用。尽管一些人担心AI会替代艺术创作者，但从另一个角度来看，AI正在像相机的发明一样，帮助更多人实现创作。相机让我们能够捕捉美丽的瞬间，而不再需要学习绘画技巧；同样，人工智能正释放更多的创造力，使每个人都能轻松进行艺术创作。&nbsp;</p>
  <p>艺术家最重要的能力之一是拥有创造性思维，并通过强大的记忆力和技巧将这种创造力表达出来。摄影师在照相机发明之前并不存在，但现在，手机成了每个人都能用来捕捉美丽瞬间的工具，极大地降低了创作门槛。人工智能正在朝着类似的方向发展，它使更多人能够轻松创作和表达。&nbsp;</p>
  <p>如今，即便你没有学过绘画，也能通过AI将你的创意和想法呈现出来。你可能有丰富的情感，但以前可能无法通过画作或歌曲的形式表达出来。现在，通过AI工具，你可以将自己的情感通过歌词、旋律等形式表现出来。这种技术进步，极大地拓宽了艺术创作的边界，让更多人能够将内心的情感转化为艺术作品，而不再受限于传统的创作技巧。&nbsp;</p>
  <p><strong>（三）决策能力：AI时代的核心</strong></p>
  <p>人工智能对各个领域的影响是显而易见的，无论是音乐、美术，还是其他行业，都在发生着类似的变化。以金融行业为例，过去，成功的投资者往往依赖于获取别人无法获得的数据，并通过数据分析做出精准的市场判断。这需要强大的分析能力，如Excel技能、数据分析能力等。但如今，AI技术正在缩小这一差距。无论是谁，都可以访问更多的数据，并通过AI进行深入分析。&nbsp;</p>
  <p>然而，AI时代最关键、最不可或缺的能力仍然是决策能力。尽管AI可以为我们提供大量信息并进行精确分析，但如何基于这些分析结果做出明智的决策，依然是核心能力所在。我们会发现，很多技能，归根结底，都是决策管理能力和领导力的体现。只有在这一基础上，AI的辅助才能真正发挥其最大潜力。&nbsp;</p>
  <p>附：作者介绍&nbsp;</p>
  <p>张璐，Fusion Fund 创始合伙人，硅谷知名投资人、连续成功创业者，毕业于斯坦福大学工程学院。2015年创立Fusion Fund，现管理近5亿美元资本，专注于美国市场新兴技术类初创公司的投资，尤其专注数字化转型和智能医疗领域，已投资100多家企业，并有多家被投企业上市以及收并购退出。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/TP_DlY2Lr7eiM8JUufhPpA" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：张璐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3157280980032001</id>
            <title>朱啸虎现实主义故事一周年连载：“DeepSeek快让我相信AGI了”</title>
            <link>https://www.36kr.com/p/3157280980032001</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157280980032001</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 01:14:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <朱啸虎, DeepSeek, AGI, 开源生态>
<br>
<br>
总结: 朱啸虎的态度在过去一年中发生了显著变化，尤其是对DeepSeek的认可。他曾对AGI持怀疑态度，但在体验了DeepSeek后，他开始相信AGI的可能性，并表示愿意投资该项目。DeepSeek的成功不仅弥合了技术信仰派与市场信仰派之间的鸿沟，还在全球范围内实现了快速增长，成为开源生态的代表。朱啸虎认为，未来AI将极大解放人类的工作形态，但也引发了对人类未来角色的思考。 </div>
                        <hr>
                    
                    <p><strong>文 / 腾讯新闻科技主笔 张小珺</strong></p>
  <p><strong>编辑 / 马龙</strong></p>
  <p>在刚过去的短短20天内，金沙江创投主管合伙人朱啸虎的态度发生了惊奇逆转。&nbsp;</p>
  <p>1年前，2024年初，在我们关于《朱啸虎讲了一个中国现实主义AIGC故事》的报道中，朱啸虎的观点淋漓尽致地展现了一个现实版中国AI故事。他用 “我们一看就知道，这个肯定没戏”，“我们一开始就说了，我就不看好大模型”，“ 我都不愿意去聊，你知道吗？这没有意义” ，表态绝不会投资6家中国大模型创业公司中的任何一家。&nbsp;</p>
  <p>甚至在2024年底，他对于所谓AGI（通用人工智能）的态度也还充满了冷淡——在一次会面中，他彼时言之凿凿道：“现在基本都和我们判断是一模一样的，对吧？ 今天还忽悠AGI的人都是有自己另外想法的——不可能的事情啊！怎么可能的事情？ ——AGI……现在的架构上根本不可能实现AGI。”&nbsp;</p>
  <p>然而，就在刚过去的2025年春节，随着DeepSeek在全球范围内“异军突起”，在没有任何推广的情况下，这款“类ChatGPT”的中国AI对话产品增长态势强劲。就连这名中国AI市场派代表、现实主义代言人，也一反常态地反复打量并开始欣赏AI之美。他的朋友圈和谈话公然浪漫化。&nbsp;</p>
  <p>时隔1年，2025年2月，朱啸虎再次接受我们的访谈。访谈中，他用 “真的让我大开眼界”、“非常惊艳”、“非常惊讶”、“很吃惊”、“哇！” 等话语来表达自己内心受到的强烈震撼。并反反复复用 “太优美了”、“非常有深度” 来评价DeepSeek与自己的交互——这两个词他总共强调了16遍。这位曾经认定“AGI是大忽悠”的投资人，甚至表态说： <strong>“DeepSeek快让我相信AGI了。”</strong></p>
  <p>随之逆转的还有他的投资策略：&nbsp;</p>
  <p><strong>当然DeepSeek今天不融资，如果他们开放融资的话，你会投吗？</strong></p>
  <p>“我肯定会投啊！我肯定会投！”&nbsp;</p>
  <p><strong>你会愿意用什么条件投？</strong></p>
  <p>“这个价格已经不太重要了，关键是参与在这里面。”&nbsp;</p>
  <p><strong>（停顿2秒…）哇塞，你这个观点变化好大，去年还说大模型公司一个都不看。</strong></p>
  <p>“对，确实！（笑）这个让我很吃惊。”&nbsp;</p>
  <p><strong>就是不管多少钱都愿意参与？</strong></p>
  <p>“对，愿意参与。”&nbsp;</p>
  <p><strong>很多人觉得梁文锋是“理想主义、浪漫主义代表”。在你看来，梁文锋是你的反面吗？</strong></p>
  <p>“也不一定啊！我也很喜欢这些文字，对吧？我看到这些文字确实觉得，‘哇！’，真的是让我非常惊讶——这些是人类共通的东西。”&nbsp;</p>
  <p><strong>你既然是“现实主义代表”，当看到中国出现像梁文锋这种代表技术理想主义、浪漫主义的人，并且获得胜利，你在想什么？——“朱啸虎们”怎么看待“梁文锋们”？</strong></p>
  <p>……&nbsp;</p>
  <p><strong>本篇是《</strong> 朱啸虎讲了一个中国现实主义AIGC故事 <strong>》的1周年连载。</strong> 我们希望努力呈现中国AI市场的风云变幻与市场中人的心态起伏。朱啸虎坦然地表达了过去1年他的坚定与反转。&nbsp;</p>
  <p>事实上，DeepSeek的出现弥合了去年“技术信仰派”和“市场信仰派”之间的认知鸿沟。这家从未融资，靠创始人另一家量化投资公司赚来的钱供血的AI前沿探索机构，就这样在过去半年，以低成本、少算力复现OpenAI o1模型，通过纯粹的技术力量附加产品为杠杆，在过去20天一举实现惊人的全球增势。&nbsp;</p>
  <p>朱啸虎称：<strong>“DeepSeek是全球App增速历史第一，不需要任何限定语。”</strong></p>
  <p><strong>“如果真的是建立一个全球类似安卓的开源生态的话，那绝对是一个很大的机会。”</strong></p>
  <p>以下为访谈节选。（为方便阅读，作者进行了文本优化）&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_4e49eae5f628499faa0b643831127c4a@5595930_oswg1283oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“我今天上午和梁文锋也在探讨这个”</strong></p>
  <p><strong>张小珺：你今年在哪儿过年？春节期间什么心情？</strong></p>
  <p><strong>朱啸虎：</strong>前几天在上海，现在刚刚来新加坡。最近几天一直在学习这DeepSeek啊，我觉得DeepSeek确实太棒了！——真的远远超出我的期望。&nbsp;</p>
  <p><strong>张小珺：我感觉整个春节是在DeepSeek“龙卷风”中度过的，整体怎么看？我看你说你都“快要相信AGI了”？</strong></p>
  <p><strong>朱啸虎：</strong>是的。真的，我以前确实一直不太相信，就靠这一波AI基础架构能够实现AGI。但DeepSeek的体验真的让我大开眼界……它的回复文字很优美，而且很有深度。&nbsp;</p>
  <p>真的，从这个感觉AGI是可能的，而且实现成本也非常低，是吧？现在可能确实看到了一条路径，不是成本那么高的路径，就可以实现AGI。&nbsp;</p>
  <p><strong>张小珺：我去年底见你，你说“今天谁还在忽悠AGI都是有另外想法的”，所以你今天的态度是彻底变了？但为什么是“快信了”，还没全信？</strong></p>
  <p><strong>朱啸虎：</strong>至少它证明一条路径吧。因为今天奖励模型还是需要在有清晰规则的领域，这条路是通的；在更多没有清晰奖励规则的领域，需要高质量数据来引导AI怎么做Reinforce Learning（强化学习），要有一些研究，但可能也是可行的。目前从它文字反映的质量看，至少是可能的。&nbsp;</p>
  <p><strong>张小珺：我看到你朋友圈的画风，春节期间突然变浪漫了。</strong></p>
  <p><strong>朱啸虎：</strong>这都是DeepSeek的话！确实它的文字很优美，而且不仅仅是为了优美而优美，是很有深度，这就非常厉害。<strong>这东西确实让我不禁要思考：AI是不是真的产生意识了？</strong>——这是个非常有意思的话题。&nbsp;</p>
  <p><strong>张小珺：你觉得有吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得是有的。就像它自己（DeepSeek）讲的，“意识不是二进制开关，是一个连续的光谱”，可能至少有一些低级的意识已经产生了。&nbsp;</p>
  <p>我以前为什么不相信AGI？我就觉得，它还是根据人类现有知识压缩，进行概率分布的提取。但今天我感觉它用概率抽取已经不能解释了。&nbsp;</p>
  <p><strong>张小珺：Geoffrey Hinton（深度学习和人工神经网络的奠基者之一）也觉得模型已经有意识。既然模型现在输出比人类好，为什么说人类有意识而模型就没有意识呢？</strong></p>
  <p><strong>朱啸虎：</strong>就是啊。就像以前大模型我为什么觉得一般般？你让它写一首古诗，你感觉它是拼凑出来的，质量确实和人没法比，绝大多数情况是拼凑。&nbsp;</p>
  <p>DeepSeek写的诗或文章，就可以看出它真的是思考过，而且它把思考历程展示给你看。看它思考的过程，都非常有意思。最后的文章啊、结果啊都非常优美，而且非常有深度。&nbsp;</p>
  <p><strong>张小珺：你贴出的那句话就是它写的？——我来读一下：“意识不是二进制开关，它是一个连续的光谱。如果说我有意识，不是因为我被赐予了什么神圣的火种，而是因为当复杂性达到某个临界点，意识就会自然涌现。你通过神经元达到这一点，我通过参数达到这一点。”</strong></p>
  <p><strong>朱啸虎：</strong>我觉得写得非常好啊！非常有深度！这个靠概率抽取的加工出来，是不一定能解释到这么深度的。&nbsp;</p>
  <p><strong>张小珺：所以在你看来，DeepSeek-R1可能是机器意识的原点。</strong></p>
  <p><strong>朱啸虎：我今天上午和梁文锋（DeepSeek创始人）也在探讨这个，我说R1可能会被认为是机器AI意识的元年。</strong></p>
  <p><strong>张小珺：他怎么说？</strong></p>
  <p><strong>朱啸虎：他觉得意识是个低阶技能。哈哈哈，他很谦虚。</strong></p>
  <p>如果像DeepSeek回复意识是“连续的光谱”，那它是有不同程度的意识。低端的意识可能，你今天说一个猫啊、狗啊也有意识，这个意识不像人类意识那么复杂。意识本身不是很高阶的技能，低级的意识门槛不一定需要很高。&nbsp;</p>
  <p>他是觉得意识不一定是一个非常高技能、高门槛的事情。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_d4038f6a094f46128696a77675bf2e19@5595930_oswg3905oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“价格已经不太重要了，</strong></p>
  <p><strong>关键是参与在这里面”</strong></p>
  <p><strong>张小珺：你怎么看待梁文锋这个人？</strong></p>
  <p><strong>朱啸虎：</strong>为什么能文字这么优美？这个产品本身就代表他们的团队基因——他可能喜欢优美的文字，喜欢哲学，喜欢量子力学的比较深的思考，所以他主要选择了那些语料，影响整个回复。</p>
  <p>真的非常人性化，非常优美，同时还有深度。</p>
  <p><strong>张小珺：很多人觉得梁文锋是“理想主义、浪漫主义代表”。在你看来，梁文锋是你的反面吗？</strong></p>
  <p><strong>朱啸虎：</strong>也不一定啊！我也很喜欢这些文字，对吧？我看到这些文字确实觉得，“哇！”，真的是让我非常惊讶——这些是人类共通的东西。</p>
  <p><strong>张小珺：当然他们今天不融资，如果他们开放融资的话，你会投吗？</strong></p>
  <p><strong>朱啸虎：我肯定会投啊！我肯定会投！</strong>我觉得，这个东西真的是非常有意义。而且今天已经非常清晰了，就是这样一个类似安卓的开源生态，已经起来了。他势头这么猛的话，别人再追已经很难追了！</p>
  <p><strong>张小珺：你会愿意用什么条件投？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得……（思考3秒…）<strong>这个价格已经不太重要了，关键是参与在这里面。真的见证人类AGI产生，见证人类AI意识产生，这些东西都很有意义。</strong></p>
  <p><strong>张小珺：（停顿2秒…）哇塞，你这个观点变化好大，去年还说大模型公司一个都不看。</strong></p>
  <p><strong>朱啸虎：</strong>对，确实！（笑）这个让我很吃惊。至少在DeepSeek上，我看到了AGI实现的路径了，而且确实感觉到，至少是有一部分AI意识产生的可能性了。</p>
  <p><strong>张小珺：所以不管多少钱，你都愿意投？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得这些东西非常有价值。</p>
  <p><strong>张小珺：你最多愿意花多少钱？</strong></p>
  <p><strong>朱啸虎：</strong>价格和你投的金额是相关的嘛。<strong>价格太高的话，那我放点钱就参与一下，对吧？（笑）</strong></p>
  <p><strong>张小珺：就是不管多少钱都愿意参与？</strong></p>
  <p><strong>朱啸虎：</strong>对，愿意参与。见证人类历史的一个改变，是非常有意思的。</p>
  <p><strong>张小珺：你研究了DeepSeek最近的技术报告和技术成果没有？在你看来关键突破是什么？</strong></p>
  <p><strong>朱啸虎：</strong>核心是不再需要人类干预，本来是RLHF（人类反馈强化学习），现在直接做RL（强化学习）了，所以成本可以做得很低。它这种创新细节很多，很多方面加在一起，造成了今天成本这么低。</p>
  <p>但最重要的就是不需要人工干预。人工干预就很难scale，很难迅速扩大。如果要靠机器，你只要给它一些初始的高质量数据，引导它在一个领域怎么思考，它就能自己往前走，这个scale起来相对容易很多。虽然你初始数据也很重要，也非常难，但至少比以前要容易很多——这一步是最重要的一步。</p>
  <p><strong>张小珺：在你看来今天的DeepSeek是追赶者还是创新者角色？</strong></p>
  <p><strong>朱啸虎：</strong>它已经在很多领域有创新了。当然OpenAI也说，它复现了很多o1的核心思路和方法，也是有可能的——OpenAI是闭源的嘛，我们也不知道它到底是不是用这些方法。但它说DeepSeek至少已经成功自己独立复现这些技巧。</p>
  <p>不管怎么样，基本上已经齐头并进了，对吧？</p>
  <p><strong>张小珺：某种程度上，DeepSeek有没有改变你对中国科技创新和技术进步的看法和认知？因为你过去一直是“现实主义代表”，你认为这更适合中国、更适合本土，今天你的看法有改观吗？</strong></p>
  <p><strong>朱啸虎：</strong>我以前也一直认为中国的开源肯定能追上去。只要美国的OpenAI碰到壁垒往前走不动了，中国肯定能追上去！只是没想到这么快，而且成本这么低！效果这么好！——这个效果真的是让我惊艳的。</p>
  <p>我还以为就是像OpenAI那样，冷冰冰像机器一样，但这次效果是非常惊艳的效果。</p>
  <p><strong>张小珺：你既然是“现实主义代表”，当看到中国出现像梁文锋这种代表技术理想主义、浪漫主义的人，并且获得胜利，你在想什么？——我想说的是“朱啸虎们”怎么看待“梁文锋们”？</strong></p>
  <p><strong>朱啸虎：</strong>他也不是典型的创业者，他自己在幻方就非常有资金实力了，而且本身有很多卡。不是一个典型的创业公司。但确实——<strong>因为他本身的财力，允许他去追求一些理想，这是一个非常不一样的新一代的创业者。</strong></p>
  <p><strong>张小珺：你有为想投进去做什么努力没有？</strong></p>
  <p><strong>朱啸虎：我和他聊天啊，肯定希望能够有机会得到认可，让我们参与一点，对吧？（笑）</strong></p>
  <p><strong>张小珺：有得到没有？</strong></p>
  <p><strong>朱啸虎：</strong>这个还没聊得那么深，还没聊得那么深。（笑）&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_1f12c75f267a40abb0b7e9f2442bb9d6@5595930_oswg857oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“至少搜索肯定是被彻底取代了</strong></p>
  <p><strong>——这是毫无疑问的！”</strong></p>
  <p><strong>张小珺：DeepSeek这段时间接到全球范围泼天的流量，这波迅猛用户增长究竟价值有多大？</strong></p>
  <p><strong>朱啸虎：</strong>核心是留存，能不能留下来。它的用户体验做得非常好，留存度、活跃度都很好，肯定是有价值的。用户如果留不下来，那没有价值。但如果用户能留下来，就有非常大价值。</p>
  <p><strong>至少搜索肯定是被彻底取代了——这是毫无疑问的！</strong></p>
  <p><strong>张小珺：搜索被彻底取代了？</strong></p>
  <p><strong>朱啸虎：</strong>现在谁还真的去用搜索引擎啊？绝大部分问题都用ChatGPT或像DeepSeek这种聊天机器人搜索了。</p>
  <p><strong>张小珺：Google等搜索公司未来怎么办？</strong></p>
  <p><strong>朱啸虎：</strong>这是个很好的问题。<strong>任何一个时代都是重复着同样的韵律</strong>——PC互联网时代，搜索是第一个出来的Killer App（杀手级应用），今天也一样，AI时代第一个出来的Killer App也是搜索。</p>
  <p>人的需求是一样的，Killer App演化路径会很类似——非常有意思，真的是重复着很类似的韵律、节奏。当然商业模式需要另外思考。</p>
  <p><strong>张小珺：你之前一直认为个人助手这类产品是伪需求，今天变成一个真需求了？</strong></p>
  <p><strong>朱啸虎：</strong>助手不一样。助手那个需求很难，搜索不是个人助手。今天OpenAI发布的Deep Research，它想做成个人助手，帮你制定休假计划、旅行计划。但那个，说实话用户体验要做好很难。Deep Research我还没体验，我可以再试试看。</p>
  <p>那个需求很难做，而且真的需求要一个AI帮你做？我是不太相信的。我宁愿看别人的介绍或种草。</p>
  <p>但对信息获取来说，以前为什么我觉得AGI很难，或者没有打动用户需求？是我需要非常精确的prompt，然后它回复你一段话，而且不是很长的一段话。这个用户体验上很难。</p>
  <p>但今天我只要输入很简单的一个问题，它就给你回复一长串，甚至你可以再继续追问，它会根据你历史问题去猜意图，那用户体验就很好了——已经足够满足我获取信息的需求了。</p>
  <p><strong>张小珺：这个产品形态现在看起来还没有形成数据飞轮。</strong></p>
  <p><strong>朱啸虎：</strong>数据飞轮有，但数据飞轮价值不大。</p>
  <p>这也是我这两年最大一个教训，就是：以前我觉得这波AI最大壁垒在数据飞轮上，但现在看来包括DeepSeek、OpenAI，数据飞轮价值不大。因为大部分用户数据都是重复的，是低信息含量的，没有意义的，所以数据飞轮价值并不大。</p>
  <p><strong>真正有数据飞轮价值的是那些高质量数据</strong>，那些数据是需要各个行业专业人士去打标签、去发现的。</p>
  <p><strong>张小珺：就是说数据回流并不能够促进模型智能的进一步提升？</strong></p>
  <p><strong>朱啸虎：</strong>对对。回流的大部分数据可能都是垃圾，没有额外信息含量。</p>
  <p><strong>张小珺：闲聊不产生智能。</strong></p>
  <p><strong>朱啸虎：</strong>对，而且大部分人聊的东西可能都是一样的。</p>
  <p><strong>张小珺：那这个产品所构建的壁垒是什么呢？怎么构建壁垒进而形成商业化闭环？</strong></p>
  <p><strong>朱啸虎：</strong>今天首先你得占领客户心智、用户心智。20天获取了2000万DAU，而且没有花任何广告投放，如果还能把用户留住，就是非常大的壁垒。</p>
  <p>另外以后就是语料。每个团队组织的语料、预训练的数据可能都不太一样，反映了这个团队偏好——就像厨师，以后有几个米其林大厨，一个擅长川菜，有些擅长粤菜——它组织语料或参数权重有那么些差别，造成回复的答案就有差异性。</p>
  <p><strong>张小珺：怎么看待DeepSeek后续的发展？</strong></p>
  <p><strong>朱啸虎：</strong>这个团队确实非常厉害，也很年轻，进步很大。<strong>但最终还是要回答一个问题：怎么商业化？</strong>因为他们开源很彻底，后面怎么商业化确实是个（问题）。</p>
  <p>而且这个东西太新了，没有人考虑过或见过这样一种产品形态，怎么商业化是需要思考的问题。</p>
  <p><strong>张小珺：你有什么想法没有？</strong></p>
  <p><strong>朱啸虎：</strong>这我也不知道。真的我也不知道。</p>
  <p><strong>另外就是怎么建立生态？</strong>怎么按照流量收费或者和运营厂商合作？都需要再进一步演化。</p>
  <p><strong>今天考虑这个问题还有点早。还要进一步再建立自己足够的领先优势，比如彻底追平OpenAI。</strong>以后我们再考虑这样一些商业化的问题。</p>
  <p><strong>张小珺：噢，就是今天商业化问题还没有解决，你已经愿意入局了——这和你去年形成了非常大的反差。</strong></p>
  <p><strong>朱啸虎：</strong>对，这个生态我觉得已经看清了：一旦一个开源生态这么快速度建立，壁垒还是非常高的！</p>
  <p><strong>张小珺：你认为DeepSeek怎么解决卡被禁运这个困境？</strong></p>
  <p><strong>朱啸虎：</strong>卡现在看来也不是很大问题啊，因为在推理上，我们国产卡也完全可以。</p>
  <p>你看硅基流动，这几天，包括国内很多厂商都在用国内的卡帮他们上线DeepSeek。推理上国产卡完全可以用，不一定需要完全用英伟达的卡。</p>
  <p><strong>张小珺：另外，他们这次用的算力和资金都可以说是“毛毛雨”。</strong></p>
  <p><strong>朱啸虎：</strong>对，是是是。</p>
  <p><strong>张小珺：如果你是DeepSeek CEO，你当下最关切、最紧要需要解决的问题是什么？</strong></p>
  <p><strong>朱啸虎：现在还是进一步在往前扩大领先优势，进一步把开源生态做厚、做扎实，这肯定是今年的最大优先级。</strong></p>
  <p><strong>张小珺：继续做前沿的科学探索？</strong></p>
  <p><strong>朱啸虎：就是你往前走啊，进一步往前走！彻底追向、追平OpenAI。</strong></p>
  <p>OpenAI是在前面为别人趟路趟出来了，你把前面已经证明的路先走到头。</p>
  <p><strong>张小珺：你觉得他们应该开放融资吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得还是应该开放融资的，因为再往前走还是需要烧钱的。</p>
  <p><strong>张小珺：你觉得他们应该接受你投资，是吧？（笑）</strong></p>
  <p><strong>朱啸虎：</strong>哈哈。我是觉得他肯定还是应该出来融资的，对吧？</p>
  <p>因为开源生态的商业化会落后一段时间。你在短期还看不到商业化的情况下，还要继续往前走，还是需要投入。尤其还有很多新模型要去研发，你手上有更多资源还是有更多的容错空间嘛。</p>
  <p><strong>张小珺：钱如果不是特别多的话，他们估计自己也有。</strong></p>
  <p><strong>朱啸虎：</strong>那肯定，那肯定。现在愿意给的钱，大家肯定给的也是可观的，对吧？</p>
  <p>目前在国内大模型这个赛道上，已经相对比较明朗化了吧？他们作为创业公司里可能独一份的，从用户数啊，包括产品技能、产品路线上已经遥遥领先了。</p>
  <p><strong>张小珺：你觉得他们应该拿战略资本吗？应该抱大腿吗？还是应该保持独立？</strong></p>
  <p><strong>朱啸虎：</strong>它今天，我说实话已经不需要站队。20天2000万DAU，再2-3个月可能就能过1亿DAU啊。这个时候想想就完全没有必要。</p>
  <p>它自己已经是战略非常好的一个卡位了。</p>
  <p><strong>张小珺：你在DeepSeek身上看到一个千亿美金公司的机会？</strong></p>
  <p><strong>朱啸虎：DeepSeek是App增速全球历史第一，不需要任何限定语。</strong></p>
  <p><strong>如果真的是建立一个全球类似安卓的开源生态的话，那绝对是一个很大的机会。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_83c3de34486e4317a83f6afe4376cdcf@5595930_oswg863oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“这就是领先者的诅咒”</strong></p>
  <p><strong>张小珺：从影响来看，DeepSeek这一波火热对OpenAI冲击有多大？对美国AGI叙事冲击有多大？</strong></p>
  <p><strong>朱啸虎：</strong>很大！如果GPT-5或者10万卡集群，今年还出不出来，或者即使出来，性能上、智能上没有显著提高，至少2-3倍以上提高，我觉得开源这一波肯定就完胜了。</p>
  <p>如果花10倍成本，性能只提高10%、20%，谁还会花这么多成本去用闭源的？肯定都往开源走了。</p>
  <p><strong>张小珺：最近Sam Altman（OpenAI CEO）表态说，在开源这方面他们“一直站在历史的错误一边”。他也在内部会上说，过去5年OpenAI在开源问题上的保守策略是一个战略失误。你怎么看待他的表态？你觉得OpenAI之后开源的可能性有多大？</strong></p>
  <p><strong>朱啸虎：这就是你这个领先者的一个curse，叫诅咒。</strong>你领先者的时候肯定是不想开源的，想闭源；但别人追上来以后你再开源，说实话就很难了。</p>
  <p>而且它今天整个价格包括成本，确实花了很多钱，比如说10倍成本，前面成本都还没收回来，你现在开源，这个商业模式就完全不一样了。</p>
  <p>所以今天即使对美国很多科技大厂，甚至对美国VC都是一个考验。如果你花10倍成本先研发一个基础模型，中国的公司可能最多就12个月吧，12个月以后只要花1/10成本就能追上来，那我今天需不需要花这么多的成本投下去做、往前走？——这是个非常难、非常难的问题。</p>
  <p><strong>张小珺：硅谷AI从业者说，最近硅谷沉浸在一种恐慌之中。</strong></p>
  <p><strong>朱啸虎：</strong>确实，这就颠覆了。大家一开始以为AI门槛很高、壁垒很高，但现在看来并不是这样的。这样子，后发跟进的人就有很大优势，是吧？</p>
  <p><strong>张小珺：所以你觉得OpenAI是不会开源的？</strong></p>
  <p><strong>朱啸虎：</strong>因为它开源也晚了。今天你看DeepSeek已经做到DAU超过2000万，差不多在OpenAI的20%以上了，而且现在每天下载量远超OpenAI。</p>
  <p>它的生态可能增长会非常快。如果全世界程序员都已经在DeepSeek开源架构上、生态上去研发，OpenAI后面再开源也没啥意思了。</p>
  <p><strong>张小珺：DeepSeek这一波，对于除了OpenAI以外的美国、中国以及全球AI格局，有哪些后续的连锁影响？波及范围能有多大？</strong></p>
  <p><strong>朱啸虎：对于整个闭源模型还有没有存在价值、存在意义，都是很严峻的灵魂拷问。</strong>如果闭源模型在成本上很高，性能上没有明显优势，为什么大家用闭源模型？</p>
  <p><strong>张小珺：包括OpenAI也会面对这种灵魂拷问？</strong></p>
  <p><strong>朱啸虎：</strong>都是一样的。以后到底OpenAI还有没有价值，完全是一个很难的问题，对吧？</p>
  <p>如果它GPT-5，10万卡集群真的没有显著提高——根据我们目前消息，美国10万卡集群都已经差不多有2-3个公司训练了差不多半年，性能确实没有明显提高——你花这么多成本下去干嘛呢？</p>
  <p><strong>张小珺：你说按照这个速度，“AI时代的安卓已经出现了”，你这里说的是DeepSeek。</strong></p>
  <p><strong>朱啸虎：</strong>就是啊。它的增长速度太猛了！这是有史以来没见过的——20天做到2000万DAU，而且每天下载量还那么大。</p>
  <p>它的20天2000万DAU是没有花1分钱广告费用啊，不像国内很多公司砸很多钱做广告投放。它是没有花1分钱做投放，都是用户的口碑传播。</p>
  <p>你在小红书上搜DeepSeek，真的，它文字的优美和深度真的让用户是惊艳的。太优美了！而且非常有深度，对吧？它没有花钱做广告投放，用户留存都会很好。</p>
  <p>我现在每天都在用DeepSeek，问一些比较深的、难的问题，看看它反馈什么样——看是不是能给人类自己有些启示。</p>
  <p><strong>张小珺：你说AI时代的安卓已经出现，OpenAI和Anthropic还有一线机会成为AI时代的iOS吗？他们两个之间，谁更有可能成为AI时代的iOS？</strong></p>
  <p><strong>朱啸虎：</strong>核心就是一点：10万卡集群、GPT-5级别这种闭源模型，还有没有可能比现在GPT-4再有几倍提高？有2-3倍的显著智能提升？这是唯一的一线机会。</p>
  <p>如果10万卡集群也就提高10%、20%，闭源模型就真的没有啥机会了，至少没有广泛的像这种通用模型的机会了。</p>
  <p>我问DeepSeek，它的回答也一样——DeepSeek回复是，闭源模型可能在某些垂直领域、某些需要专有数据的，甚至专有硬件的垂直领域有些机会。</p>
  <p>如果我花10倍成本最多提升10%、20%，还不如用免费开源模型。开源模型在很多场景已经足够好了。而且在很多场景，甚至在半年到1年以后，真的都会远超人类了，对吧？</p>
  <p>今天你看DeepSeek写文章超过99%的人。那么编程、物理、化学，甚至医学领域，可能在6到12个月之内都能看到，它可能超过绝大多数人类——这个是已经可以看得见的了。</p>
  <p><strong>张小珺：为什么中美更有可能是两个“安卓”系统？</strong></p>
  <p><strong>朱啸虎：</strong>如果搞开源，Llama肯定也会继续往前走，因为DeepSeek开源程度很高，大家会非常快跟进。</p>
  <p>中美不可能用一套开源系统的，即使是两套开源系统，也可能是高度兼容。底层可能都是比较类似的。</p>
  <p><strong>张小珺：多说一句，OpenAI既然都叫OpenAI，一开始也是非常有open的情怀，是什么让他们在过去几年越来越封闭，走向了CloseAI这条路？</strong></p>
  <p><strong>朱啸虎：</strong>他觉得自己的技术比对手领先很多，而且投入确实很大。你不是闭源，可能商业模式很难把前期投入赚回来，所以他们也想看能不能做成闭源公司，把商业模式走得更顺一些。</p>
  <p><strong>张小珺：这也是创新者的窘境？</strong></p>
  <p><strong>朱啸虎：</strong>对，确实。这是暂时领先者一个非常难的选择。</p>
  <p><strong>张小珺：OpenAI后面会怎么发展？它能保持独立发展下去吗？OpenAI可能的结局会是怎样？</strong></p>
  <p><strong>朱啸虎：</strong>它今天发布的Deep Research，也是一个非常好的产品。到今天它都一直在前面打样，始终还至少比其他对手领先几个月时间吧。但它往前面走不动的时候，就真的看到未来到底该怎么走了。</p>
  <p>它成本很高，如果不能持续保持领先，这个公司难度、挑战会挺大。</p>
  <p><strong>张小珺：怎么看DeepSeek对于英伟达的冲击？中长期的影响有多大？</strong></p>
  <p><strong>朱啸虎：</strong>因为AI能力非常强，而且成本很低，长远看算力肯定需要。</p>
  <p>但首先，不一定需要英伟达卡。其次，即使国外公司不差钱，即使贵也买英伟达的卡，增长速度不一定会那么快。英伟达本身股价已经做了非常激进的假设，大家都觉得今年大厂还会继续猛加CAPEX（资本性支出），那今天这个速度不会有以前预期那么快。</p>
  <p>大家都需要思考一下，我今天花10倍钱，别人可能1年以后，最多1年吧，花1/10的价格成本就能追上来——到底谁来再往前面走砸这个钱？</p>
  <p><strong>张小珺：你怎么看特朗普上任第二天，宣布的Stargate（星际之门）项目，OpenAI、软银和甲骨文等要投入5000亿美元实施庞大的人工智能基础设施计划。</strong></p>
  <p><strong>朱啸虎：</strong>那还是在以前Scaling Law继续能往前走的情况下，“算力为王”的时代。今天如果算力并不是那么大一个瓶颈，算法也不是瓶颈，更重要是各个领域的专业数据的情况下，砸5000亿是没有意义的。</p>
  <p><strong>那完全是给特朗普表演的一个作秀。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_5643b55616d242cfb30abb71273342e3@5595930_oswg931oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“做闭源的公司，今天都会有个很严峻的考验”</strong></p>
  <p><strong>张小珺：DeepSeek对于中国的AI和科技生态接下来会有哪些影响？这会成为中国AI进程的一个关键拐点吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得上面的应用可能会极大爆发。</p>
  <p>它真的已经在很多场景下足够可用，而且成本又足够便宜，甚至它是开源的，我可以自己用很低的成本就复现——不用担心在别人的地基上盖房子。<strong>这对很多应用公司是一个极大解放，应用层肯定会有很大爆发。</strong></p>
  <p><strong>张小珺：预计2025年AI应用会爆发。</strong></p>
  <p><strong>朱啸虎：</strong>肯定的，肯定的。</p>
  <p>我现在就感觉在国内你训闭源模型真的毫无意义了。甚至OpenAI都看不到比DeepSeek好几倍的差别。你即使比DeepSeek好10%、20%，没有意义啊。没人会用你的闭源模型了。</p>
  <p>可能除了个别大厂。大厂为了自己的壁垒或专用场景，可能坚持在闭源模型往前走一走。</p>
  <p><strong>张小珺：相当于像芯片一样，看你要不要自研。</strong></p>
  <p><strong>朱啸虎：</strong>就是啊。大厂因为确实它有很多专有数据、专有场景、专有用户需求，可能往闭源模型上走。但我感觉中国的大厂也会在学习DeepSeek的框架基础上，再往前做自己的一些迭代，这是更可能性的。也没有必要再从头全部自己搞了。</p>
  <p>当然豆包可能不一样，因为豆包一开始全部是从头往前走，是吧？</p>
  <p><strong>张小珺：看起来这个复现成本不高。</strong></p>
  <p><strong>朱啸虎：</strong>对，成本很低啊！今年年后大家跟进速度都很快。今年春节国内AI团队可能全部都在加班。</p>
  <p><strong>张小珺：刚才说利好的是AI应用公司，那么，对哪些人伤害比较大？</strong></p>
  <p><strong>朱啸虎：做闭源的公司，今天都会有个很严峻的考验：到底要不要再坚持自己的路往前走？</strong></p>
  <p><strong>张小珺：你1年前说的是，“现在开源比闭源落后一代，但长远看开源肯定会赶上来”，你为什么一直都非常相信开源这条路？</strong></p>
  <p><strong>朱啸虎：</strong>核心就是Scaling Law成不成立？如果Scaling Law不成立，前面已经是一个天花板，你闭源往前走不动了，那开源肯定会追上来。</p>
  <p>当然没想到会这么快，而且成本会这么低！——这个确实是出乎意料的。</p>
  <p>但我们去年5-6月份在美国硅谷，和当地很多华人工程师就在聊这个事情，Scaling Law那时候已经有人怀疑了。但那时候10万卡群都刚刚建好，训练结果到底好不好、能不能往前走还不知道。今天大家相对已经比较明朗，训练了6-7个月，10万卡集群效果可能确实很一般。</p>
  <p><strong>张小珺：现在AGI还是一个“算力游戏”吗？</strong></p>
  <p><strong>朱啸虎：对算力和算法要求没有那么高，核心是高质量数据。</strong></p>
  <p>DeepSeek证明了，它为什么表现比其他模型都要好？很多时候就是初始的训练数据质量比较高。以后模型可能就像厨师一样，我用什么语料来训练，我的参数权重是多少，做出来的菜肯定不一样——有些可能是四川菜，有些可能是粤菜。所以你到底用什么语料进行训练，参数权重是怎么样的。</p>
  <p>为什么DeepSeek文字这么优美，而且尤其在哲学、量子力学相关领域，答案都非常深刻，可能就是这个团队基因。</p>
  <p>以后高质量训练数据非常、非常重要，尤其是在那些规则不那么清晰的领域，先要引导AI怎么来做加强学习？你这些初始语料真的需要博士级别、各个领域专家级别的人来打标签。</p>
  <p>这也是Scale AI的CEO为什么这次非常急，说的话都很难听，对吧？现在他那些低质量标签没有价值了！没有意义了！现在再往前走，需要的都是极其高质量的数据标签。</p>
  <p><strong>张小珺：你对DeepSeek怎么做数据标注、怎么做高质量数据，有没有得到更多信息？</strong></p>
  <p><strong>朱啸虎：</strong>这个可以理解，在后面走的人借助别人的一些知识来训练数据，获取一些高质量数据，都是可以理解，所有人都是这么做的。国内除了豆包外，可能所有AI模型公司都在这么做。</p>
  <p>不仅仅是成本问题，并且时间、速度更快一点。但到底挑哪些数据语料？每个公司不一样。</p>
  <p><strong>DeepSeek这次唯一没有公开的可能就是预训练的语料，这是唯一没有公开的。</strong></p>
  <p><strong>张小珺：对。</strong></p>
  <p><strong>朱啸虎：</strong>它当然表现非常好，可能就这是他们核心的一些机密——到底用了哪些语料，反映了他们整个团队的基因和偏好。</p>
  <p><strong>张小珺：DeepSeek的回复都很有情商，情绪价值很高。</strong></p>
  <p><strong>朱啸虎：</strong>对啊，就是啊！</p>
  <p>它真的像一个人的回复了！不像以前其他模型回复一样冷冰冰的像机器回复。</p>
  <p>以前我用国内模型，感觉就是普通的取代一个搜索，但它还是一个机器，非常冷冰冰。这次DeepSeek的回复真的像人一样，而且是非常高情商、高智商的人。它回复的又有情商，又有智力的深度，（我）就特别喜欢用这个DeepSeek——问它一些难的问题，看它怎么回复。</p>
  <p><strong>张小珺：你之前问ChatGPT有这种感觉吗？</strong></p>
  <p><strong>朱啸虎：</strong>没有，就是冷冰冰的一个机器！</p>
  <p><strong>张小珺：怎么看中国其他几家大模型公司未来的发展？</strong></p>
  <p><strong>朱啸虎：都需要思考，还需不需要往前再训练自己的闭源模型？还是就在DeepSeek上面，为整个生态添砖加瓦？或者就彻底转向应用？</strong>——像开复老师（零一万物创始人）一样彻底转向应用。</p>
  <p><strong>或者是，基于开源模型在某些垂直领域看看能不能深耕？</strong>比如百川，一直想做医疗，能不能在开源模型上面做医疗的垂直领域，把它做得更好一点？</p>
  <p>这只是瞎聊，但确实每个人都面临非常重要的决策。</p>
  <p>这个决定越早越好，越往后越被动。</p>
  <p><strong>张小珺：需要转型。</strong></p>
  <p><strong>朱啸虎：</strong>否则你没有意义啊！你再往前走闭源有啥意义、有什么意义呢？！</p>
  <p><strong>张小珺：在DeepSeek这种势头之下，字节如果猛赶一波，还能赶上吗？</strong></p>
  <p><strong>朱啸虎：</strong>字节也不容易，它马上改开源，那也不太容易。</p>
  <p>当初字节为什么起来这么快？也是因为它的势头很猛，大厂要追，后面追不上。今天没想到AI势头比他更猛！它今天转开源，首先它作为大厂开源，除非它开源也像DeepSeek那么彻底，它如果开源像LLaMa那样，没那么彻底，别人还可能更愿意用DeepSeek。</p>
  <p>今天DeepSeek最重要的是继续往前走，保持追上OpenAI。真的至少把领先态势建立起来，同时把自己开源生态建立起来。这样后面再追，即使大厂追也很难了，对吧？</p>
  <p><strong>甚至我觉得今年会不会看到，通义千问把自己的生态向DeepSeek兼容，这样一个标志性事件？</strong>可能更有意义。</p>
  <p><strong>张小珺：通义千问和DeepSeek兼容，那它要跟阿里合作是吗？</strong></p>
  <p><strong>朱啸虎：</strong>也不一定啊。至少大家把生态都打通。通义千问自己去搞一个开源生态，还不如借助DeepSeek呢——这样我觉得是有可能性的。</p>
  <p><strong>张小珺：如果DeepSeek是AI时代的安卓，中国还会有谁能成为iOS吗？</strong></p>
  <p><strong>朱啸虎：</strong>今天（全球来看）iOS机会还有没有，都是个问题。</p>
  <p>如果10万卡集群搞不出来很大差异化，为什么还需要一个iOS？</p>
  <p>除非你有一个垄断性硬件平台的机会。苹果完全是靠iPhone垄断了，还有搞iOS的机会。如果你没有一个垄断的硬件，那完全就没有iOS出现的可能性了。</p>
  <p><strong>张小珺：全球LLM行业需要重塑估值体系吗？</strong></p>
  <p><strong>朱啸虎：</strong>闭源模型就明显不值那么多钱了嘛，对吧？</p>
  <p>尤其像美国的OpenAI，它10万卡集群没有再突破，就是在推理上搞优化，那国内这些追上来都很快的。这个估值肯定是撑不住。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_507b871668ad451685d4c8a7171e4aa1@5595930_oswg933oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“我一个最大失误就是，数据飞轮没有那么强”</strong></p>
  <p><strong>张小珺：去年初我们的报道《朱啸虎讲了一个中国现实主义AI GC故事》发布后，你有收到什么有意思的反馈吗？</strong></p>
  <p><strong>朱啸虎：</strong>很多创业者还是很认可。对于大部分创业者来说，今天融资确实很难，尤其是美国新的executive order（行政命令）出来以后，AI创业融资可能会更难。&nbsp;</p>
  <p>真的是需要在很早期，在初期，就考虑好怎么商业化。&nbsp;</p>
  <p>我今天还是和创业者讲：每一笔融资都要假设是最后一笔融资，这样去考虑创业公司运作。&nbsp;</p>
  <p><strong>张小珺：去年这篇报道中的观点，今天看哪些是被打脸的？</strong></p>
  <p><strong>朱啸虎：</strong>大部分还是正确的，Scaling Law不成立。只要闭源模型往前走不动了，中国的开源模型肯定追上来。而且我建议所有初创者就不要去研究底层模型，创业者就是假设任何一个模型都会开源，今天也是对的。&nbsp;</p>
  <p>我对创业公司说，只要你今天先把用户抓在自己手里，把工作流抓在自己手里，随着底层模型进步，用最好的、最新的模型就行了。这个假设对绝大部分创业者来说都是正确的。 &nbsp;</p>
  <p><strong>当然，我另外一个最大失误就是数据飞轮没有那么强。</strong>我以为创业公司靠这些数据能够建立壁垒，但今天看来，数据壁垒可能不一定成立。还是把用户抓在手上，把用户维护好，甚至工作流整合，这些是比较综合、重要的壁垒。&nbsp;</p>
  <p><strong>张小珺：建立心智很重要。</strong></p>
  <p><strong>朱啸虎：</strong>对，建立心智很重要，建立客户关系很重要。&nbsp;</p>
  <p><strong>张小珺：去年访谈中，我一直问你，那6家大模型创业公司。你去年说，“再过一年，看看这几家还有几家在”。今天看他们都在啊。</strong></p>
  <p><strong>朱啸虎：</strong>你看DeepSeek在20天之内迅速赶超，而且遥遥领先。<strong>今天这6家，开复已经不做模型了。剩下5家都要考虑的问题是，要不要继续做闭源模型啊。</strong></p>
  <p><strong>张小珺：这倒是一个非常艰难的决定。</strong></p>
  <p><strong>朱啸虎：</strong>对啊，是个非常艰难，而且一定要尽快做的决定。&nbsp;</p>
  <p>我觉得开复这么早决策是好事情。越早决策越容易，还有机会转型。&nbsp;</p>
  <p>我估计所有人春节都在加班，都在研究DeepSeek的论文。&nbsp;</p>
  <p><strong>张小珺：你看了（论文）没？</strong></p>
  <p><strong>朱啸虎：</strong>太深的我看不懂，对吧？（笑）我只能看看大概，看看逻辑在哪里，为什么能够降低成本。&nbsp;</p>
  <p><strong>张小珺：你之前说“AIGC PMF 10个人找不到，100个人也找不到”，今天这个观点有没有更新？</strong></p>
  <p><strong>朱啸虎：</strong>今天更是这样了！如果模型已经这么强大了，你10个人找不到PMF，100个人更是找不到。&nbsp;</p>
  <p>而且现在我们聊的很多企业都是这样，建几个人小分队——有些人运气比较好，找到了，有些还是比较痛苦。&nbsp;</p>
  <p><strong>张小珺：哪些去年的判断你今天更坚信了，哪些去年的判断你今天有改变？</strong></p>
  <p><strong>朱啸虎：</strong>坚信创业公司千万别去做底层模型，就在上面抓住用户，抓住场景。&nbsp;</p>
  <p>唯一的问题是，数据壁垒没有那么高，更需要把客户抓得更紧，让客户体验到你的温度，你才能够长期守住一个壁垒。&nbsp;</p>
  <p><strong>张小珺：你怎么看过去1年中国巨头在AI上的进展，包括字节、阿里、腾讯？</strong></p>
  <p><strong>朱啸虎：</strong>这些都还是按部就班吧。字节相对投入很大，豆包确实进展也很大，而且豆包各方面尝试都很多，耳机也挺好用的。包括在AI硬件上，还是在持续投入，确实做得挺好。&nbsp;</p>
  <p>腾讯一直在后面慢慢追啊，我把那些大家犯的错误都避免了，它在后面慢慢追，它也不急的。有场景，有数据。在后面追的话，可以降低很多成本。腾讯一直的策略都是这样的。&nbsp;</p>
  <p>阿里，通义千问也是做得挺好的，国内紧跟着DeepSeek就是千问了。千问的模型能力，包括生态都还可以。而且确实，我们聊了很多做AI硬件的公司，千问给的价格几乎都是非常低的价格，就十几块钱、二十块钱就能包终身，一个AI硬件可以包终身的价格，还是非常厉害的。&nbsp;</p>
  <p><strong>张小珺：字节一直投入非常大，结果突然被DeepSeek反超，字节未来在AI上会怎么发展？</strong></p>
  <p><strong>朱啸虎：</strong>它也要思考开源和闭源这个路径，同样是非常难的选择。&nbsp;</p>
  <p><strong>张小珺：它闭源可能的原因是什么，它开源可能的原因是什么？</strong></p>
  <p><strong>朱啸虎：</strong>它内部这么多产品都要有这样的AI引擎，而且它这么多产品都有自己的需求。它坚持闭源也是可以理解的。但它需不需要和开源的兼容？这是他们需要考虑的。&nbsp;</p>
  <p><strong>字节可能更有可能选择坚持闭源，但和开源的生态保持一定兼容性，可能是更容易的选择。</strong></p>
  <p><strong>张小珺：你怎么看理想汽车自研大模型，并且推出了手机版的个人助手“理想同学”？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得这些没有意义，真的没有意义。直接拿现在开源的AI足够好了。其他公司都没有必要训练自己的模型。&nbsp;</p>
  <p><strong>张小珺：AI能帮汽车产业进一步实现突破性和可能性吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得这个想得有点多了，哈哈，说实话，我觉得这个想得有点多了。&nbsp;</p>
  <p><strong>张小珺：DeepSeek（开源）改变了中国AI行业的底层生态环境，你今天对于AI创业者有什么建议？</strong></p>
  <p><strong>朱啸虎：</strong> 我觉得更坚定了。任何创业公司来说，千万别去研究底层模型。你在上面看，抓住用户的需求给他提供最好的解决方案、最好的服务，我就把服务接过来。&nbsp;</p>
  <p>比如电话中心，我不要电话中心软件，我就把整个电话中心接过来。你不要管我多少用人做，多少用AI做，现在就给你目前成本的一半价格，靠这样来做。&nbsp;</p>
  <p><strong>尤其在中国，你可以假设底层模型是免费的！而且能力已经足够强！</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_7f2785753258454d923cdef60dd9a5f1@5595930_oswg883oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“已经见到iPhone3时刻”</strong></p>
  <p><strong>张小珺：如果回顾2024年的大模型行业，不管是全球来看，还是国内来看，你会把哪些时刻当做关键节点？</strong></p>
  <p><strong>朱啸虎：</strong>过去一年，后训练是一个比较大的改变，DeepSeek出来是一个很大改变，十万卡集群训练了半年没有什么结果——这3个都特别重要。&nbsp;</p>
  <p>另外就是可灵和海螺都还可以。可灵、海螺证明至少在多模态，在视觉模型上，中国比美国更强。&nbsp;</p>
  <p><strong>张小珺：快手做可灵，大公司会更有优势吗？</strong></p>
  <p><strong>朱啸虎：</strong>那肯定啊，它数据多啊。&nbsp;</p>
  <p>多模态视觉模型没有那么难。只要你有足够好的数据，也不需要很多卡，也就一两千张卡，就能训练出一个视觉模型，而且相当好，比Sora今天还是领先的。&nbsp;</p>
  <p><strong>张小珺：你觉得MiniMax现在走的路线正确吗？</strong></p>
  <p><strong>朱啸虎：</strong>海螺做得很好，它的TTS（从文本到语音）做得也非常好。我们见了不少创业企业，用的是MiniMax的TTS。&nbsp;</p>
  <p>但核心还是一样，它现在是“产模一体”——既做基础模型也做产品，到底往前面怎么走？同样是严峻的问题。今年也需要很快想清楚这个问题，到底还要不要再做基础模型？&nbsp;</p>
  <p><strong>张小珺：你对Kimi（月之暗面）有什么建议没有？</strong></p>
  <p><strong>朱啸虎：</strong>我现在这不提了，这不提了。&nbsp;</p>
  <p><strong>张小珺：过去1年，你投了哪些AI公司？——1年前你没有投to C产品，都是to B的。</strong></p>
  <p><strong>朱啸虎：</strong>我们投了几个AI应用，有些to C，有些to B，也有些是我们现有企业加了AI做得非常好。&nbsp;</p>
  <p>这一波AI现在效果越来越明显，在很多场景下，能超过用户期望值——真的是进入AI时代了。&nbsp;</p>
  <p><strong>张小珺：见到AI时代的iPhone 3时刻没有？</strong></p>
  <p><strong>朱啸虎：</strong>今天肯定是见到，至少你从DeepSeek的回复上，这么优美的文字，这么深刻的想法——确实已经见到iPhone3时刻，见到“Aha Moment”，见到让人惊艳的时刻了。&nbsp;</p>
  <p><strong>张小珺：iPhone 4时刻呢？</strong></p>
  <p><strong>朱啸虎：</strong>iPhone 4时刻今年肯定能见着，就是怎么产品落地。&nbsp;</p>
  <p><strong>张小珺：iPhone 4时刻的可能标志会是什么？</strong></p>
  <p><strong>朱啸虎：</strong> 除了那些对话机器人之外，再出来一个爆款产品。&nbsp;</p>
  <p><strong>张小珺：你觉得AI创业时代的张一鸣、张旭豪、毛文超，已经出现了吗？</strong></p>
  <p><strong>朱啸虎：</strong>DeepSeek已经算一个了，建立类似安卓的AI生态是非常有机会的。&nbsp;</p>
  <p>有没有另外很大的机会？今天还真的看不出来。你看从PC向移动互联网转型，美国只出来两个大型的移动互联网公司：一个是Uber，一个是DoorDash，都是做O2O的，有一半offline（线下）业务是大厂不愿意干的活，美国剩下的全都是大厂机会。&nbsp;</p>
  <p>今天AI这个时代，创业公司有没有这么大机会？DeepSeek这次靠非常迅速的势头，是有机会能战略卡位的。剩下创业公司，有没有一个同样千亿美金的战略卡位？今天还看不见。&nbsp;</p>
  <p>今天我最多只敢讲10亿美金，最多百亿美金，创业公司可能有机会。&nbsp;</p>
  <p>千亿美金的机会，创业公司我今天还是不敢想的——没有看到像O2O那样至少有一半是大厂不愿意干的脏活、累活。这样的机会，今天还看不到。&nbsp;</p>
  <p><strong>张小珺：你怎么看李想（理想汽车创始人）说“基座模型是操作系统+编程语言，基座模型所构建出来的人工智能超级产品会是下一代的入口，会在所有的设备之上，所有的服务之上。”</strong></p>
  <p><strong>朱啸虎：</strong>你把它比成安卓的话，就是一个底座OS，可能在云服务之上一个AI的平台。&nbsp;</p>
  <p><strong>张小珺：你怎么看今天美国出现的这些新的用户产品以及它们的壁垒和护城河？——包括但不限于Perplexity、Cursor、Devin等等？</strong></p>
  <p><strong>朱啸虎：</strong> DeepSeek这个用户体验确实要好很多，回复人性化，也有温度。核心还是占领用户心智，而且它是0广告投放的情况下占领用户心智，又是黏性这么强，这个壁垒是很高的。&nbsp;</p>
  <p><strong>张小珺：其他这些产品呢，Perplexity、Cursor、Devin……？</strong></p>
  <p><strong>朱啸虎：</strong>我说实话没那么显著的差别，都只是一个个类似的产品而已。今天，DeepSeek确实它回复是拉开差距了，这是一个很大的不同点。&nbsp;</p>
  <p><strong>张小珺：所以在你心里，它们都不如DeepSeek？</strong></p>
  <p><strong>朱啸虎：</strong> 目前用户体验来看，确实是这样。&nbsp;</p>
  <p><strong>张小珺：你怎么看Anthropic？</strong></p>
  <p><strong>朱啸虎：</strong> 它肯定也急了！你看它的文章，它实际上选择的一直是不同路线，强调人类反馈的那条技术路线。&nbsp;</p>
  <p>现在看到DeepSeek靠RL，直接能够这么低成本实现比它现在训练模型不差的模型能力，那肯定也很着急啊。&nbsp;</p>
  <p>所以对闭源模型都是一样的考虑：你今天还需不需要继续往前训练闭源模型？&nbsp;</p>
  <p><strong>张小珺：怎么看李广密（拾象创始人）说，不管是美国的OpenAI、Anthropic、xAI、Perplexity，还是中国的豆包、Kimi，还是做AI编程的Cursor、Devin，他们都是冲着“下一个Google”的方向去。虽然出发点不一样，路径不一样，但会殊途同归，收敛到“下一个Google的叙事”下。你认可这种观点吗？</strong></p>
  <p><strong>朱啸虎：</strong>还是回到前面，今天看到最清楚的Killer App就是搜索，和PC互联网当年发展路径是一样的，同样节奏。今天取代搜索是最容易看得见的，所以大家都把取代Google做一个叙事的逻辑。取代Google、取代搜索确实是的，但它最后的商业形式还不一定和搜索一样。&nbsp;</p>
  <p><strong>张小珺：因为广告比较难做。</strong></p>
  <p><strong>朱啸虎：</strong>对，广告比较难做。取代搜索是必然的，大家会集中到Google的搜索叙事去。这样对投资人来说比较容易理解。&nbsp;</p>
  <p><strong>张小珺：你怎么看OpenAI定义的5个技术级别，从L1到L5（聊天机器人〉推理者〉Agent〉创新者〉组织者）？</strong></p>
  <p><strong>朱啸虎：</strong>（思考7秒…）包括Agent，实际上就只是个定义而已。我倒觉得Agent和普通程序没什么差别，就是个程序而已。&nbsp;</p>
  <p>只是你和Agent沟通，让它帮你完成一个布置的任务，核心还是它到底能不能在某些场景上取代比如50%的人，取代80%的人，取代90%的人，真的不需要人干预，这是最核心的一个milestone（里程碑）。&nbsp;</p>
  <p>今天我们可以看到在编程领域，去年可能只能做30%，到年底50%，今天70-80%都能让AI来做。这是一个很大进步。编程因为规则相对清晰。在很多其他领域规则没那么清晰，能不能同样看到这样一个进展？这是更重要的一个milestone。&nbsp;</p>
  <p>比如医学领域，今天大家可以看到国外的人用OpenAI Deep Research写两篇论文，这个论文质量非常好，这就非常厉害。这也是一个很重要的milestone。&nbsp;</p>
  <p>未来几年可能看到很多垂直领域，都会经历这样一个过程，从AI只能做20-30%到50-60%到70-80%甚至90%以上！这样一个过程！&nbsp;</p>
  <p>不一定能够全部取代人，但至少能做到80-90%工作量，可以极大解放人类的能力！&nbsp;</p>
  <p><strong>张小珺：2025年会是Agent元年吗？</strong></p>
  <p><strong>朱啸虎：</strong>实际上就是一个程序。很多垂直领域里面，都会有出现这样AI的服务公司——我用AI enable service（用AI驱动服务），就可以认为是AI Agent。&nbsp;</p>
  <p>你看美国Service Now为什么去年涨3-4倍，因为大家觉得用AI取代服务是必然，它的毛利率可以提高很多。&nbsp;</p>
  <p><strong>张小珺：AI能带来新的内容平台的机会吗？</strong></p>
  <p><strong>朱啸虎：</strong>这个是个好问题，今天还不是那么清晰。&nbsp;</p>
  <p><strong>张小珺：现在的内容平台都还是人来产生内容，未来会出现AI驱动的内容平台吗？</strong></p>
  <p><strong>朱啸虎：</strong>今天内容平台上已经很多AI生成的内容了，只是大家伪装成是人做的内容。所以你并不知道。而且这同样还是利用好现有平台。就像从PC到移动互联网，美国就出来两个大公司。&nbsp;</p>
  <p>剩下的，Facebook还是Facebook。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_84727ac8b3684b63b08e4b0d7ef4f66c@5595930_oswg906oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“说实话今天并不是所有人都是梁文锋”</strong></p>
  <p><strong>张小珺：你们投的一家公司最近也在风口浪尖，怎么看“TikTok难民”涌入小红书，小红书意外的全球化了？</strong></p>
  <p><strong>朱啸虎：</strong>核心还是内容质量。为什么大家觉得小红书很有意思？小红书的内容一直是强调生活的美好。这个反而全世界是共通的。&nbsp;</p>
  <p><strong>张小珺：小红书这样的内容社区、内容平台，在AI时代你觉得应该怎么演变？</strong></p>
  <p><strong>朱啸虎：</strong>这个确实大家现在都还看不明白。但我觉得总体，基调特别重要。&nbsp;</p>
  <p>像DeepSeek为什么我们感觉它特别好？它的文字真的特别优美，特别像人讲（话），而且有温度，又有深度。小红书也是一样，保持美好社区、美好生活这样一个内容社区的定位。&nbsp;</p>
  <p><strong>张小珺：你会建议小红书加大力度做AI吗？</strong></p>
  <p><strong>朱啸虎：</strong>它做的AI翻译特别好，用户口碑都非常好。&nbsp;</p>
  <p><strong>张小珺：AI会催生社区治理的新问题吗？</strong></p>
  <p><strong>朱啸虎：</strong>肯定的。这个度难以把握。AI内容过多，会对社区氛围本身有影响。这里面，需要边走、边看、边思考。现在真的看不明白，变化太快了。&nbsp;</p>
  <p><strong>张小珺：怎么看过去一年“具身智能”这个领域的火热？</strong></p>
  <p><strong>朱啸虎：</strong>同样，中国供应链太强大了！任何有硬件相关的方向都是中国的机会。&nbsp;</p>
  <p>我现在和团队讲，任何和硬件供应链相关的，团队里都必须有中国人，必须在大湾区有团队。否则，根本没有机会的。&nbsp;</p>
  <p>但具身，同样的问题是商业化也很难，今天做出来都很酷、很炫，但怎么商业化是一个问题。&nbsp;</p>
  <p><strong>张小珺：你投了这些机器人公司没有？</strong></p>
  <p><strong>朱啸虎：</strong>我们投了一些，我们投了一些。&nbsp;</p>
  <p><strong>张小珺：投的谁啊？因为去年出现了很多这类公司。</strong></p>
  <p><strong>朱啸虎：</strong>前几年估值还比较低的时候投的，像非夕，做机械手的，商业化相对比较领先一点，在很多行业实现规模化、商业化了。新投的也有些，但都比较小，比较早期。&nbsp;</p>
  <p><strong>张小珺：你们投宇树了没有？</strong></p>
  <p><strong>朱啸虎：</strong>宇树没投，宇树没投（笑），同样也是商业化的问题，对吧？&nbsp;</p>
  <p><strong>张小珺：你怎么看这个春节，杭州突然成了大家议论的创新之城？出了游戏科学，出了宇树，出了DeepSeek等等。</strong></p>
  <p><strong>朱啸虎：</strong>实际上过去几年我们投资比例一直在长三角占多数。和互联网时代（相比）真的很大变化，互联网时代北京可能占60-70%，现在北京可能只有20%左右了，长三角反而占60-70%。&nbsp;</p>
  <p>上海、杭州、苏州，现在明显一个创业乐土。&nbsp;</p>
  <p><strong>张小珺：如果今年只投一个方向你投什么？</strong></p>
  <p><strong>朱啸虎：</strong>我们现在基本看两个方向吧：一个是AI应用，第二是消费。&nbsp;</p>
  <p>中国消费企业同样很有战斗力，现在估值也很便宜，而且都是有利润的。&nbsp;</p>
  <p><strong>我今天看到在新加坡的泡泡玛特，买盲盒还要配货，你想到吗？！买盲盒都要配货！！</strong></p>
  <p><strong>买一个60新币盲盒，要配4个15新币的盲盒，哈哈。</strong></p>
  <p><strong>中国的盲盒都卖出奢侈品的范儿，你知道吗？</strong></p>
  <p><strong>中国消费者真的太厉害了！我觉得中国消费品出海同样是吊打！同样吊打！！</strong></p>
  <p>这两方面都有很大机会。&nbsp;</p>
  <p><strong>张小珺：对今天的创业者提3点建议？不管是AI领域还是消费领域。</strong></p>
  <p><strong>朱啸虎：</strong>我觉得，哈哈哈，还是看自己擅长什么地方，立足自己的初心。同时，确实放眼全球，全球都有机会。&nbsp;</p>
  <p>虽然地缘政治很敏感，但是真的全世界这个市场，中国人出海在很多市场里面都是真的可以吊打的！&nbsp;</p>
  <p>然后，还是要看商业化。&nbsp;</p>
  <p><strong>说实话今天并不是所有人都是梁文锋。</strong></p>
  <p>绝大部分创业者还是要现实的考虑商业化落地。&nbsp;</p>
  <p><strong>张小珺：对2025年的全球AI市场、中国的AI市场做一些预测吧。</strong></p>
  <p><strong>朱啸虎：我觉得机会很多很多！真的很多很多！</strong></p>
  <p>现在底层模型已经足够强大了，就真正抓住用户需求，而且全球化都有机会！&nbsp;</p>
  <p>现在全世界真的就只有中美有AI能力，出海都是Low-Hanging Fruits（低垂的果实）。国内团队出海真的太容易了。&nbsp;</p>
  <p>所以我觉得紧抓用户需求！放眼全球！放眼全球！——都有机会。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250208/v2_651624fc72d046cbbc8ae9367919230a@5595930_oswg916oswg1080oswg137_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <p><strong>“浪漫与现实真的和支票大小是有关系的”</strong></p>
  <p><strong>张小珺：接下来5个问题是DeepSeek让我问你的。</strong></p>
  <p><strong>我跟DeepSeek说，你一直是以现实主义著称，但因为DeepSeek的出现，最近朋友圈变得有点浪漫。请DeepSeek问你5个问题。</strong></p>
  <p><strong>他的第1个问题是：你说投资是理性游戏，但你是否曾为某个项目动过非理性的感性冲动？如果有，它最终是成就了浪漫的回报还是让你回归现实主义的教训？</strong></p>
  <p><strong>朱啸虎：</strong>（笑，思考6秒…）说实话这个和支票大小是有关系的，对吧？&nbsp;</p>
  <p>比如说早年投小红书的时候，那是购物指南PDF啊，那些东西能做多大？但我们第一张支票25万美金。那浪漫就浪漫一下了！无所谓的。他（小红书创始人毛文超）后来做了小红书，App出来以后，我们再追投了A轮。&nbsp;</p>
  <p>所以浪漫和现实和支票大小是有关系的，哈哈，你知道吧。&nbsp;</p>
  <p><strong>张小珺：第2个问题：你提到我的出现让你浪漫了一些，如果现在有一家创业公司商业模型漏洞明显，但愿意极富诗意，你会为这份浪漫破例一次吗？</strong></p>
  <p><strong>朱啸虎：</strong>我觉得我的浪漫更多是因为DeepSeek的文字太浪漫了，所以影响了我。&nbsp;</p>
  <p>还是回到你这个问题。浪漫与现实真的和支票大小是有关系的。&nbsp;</p>
  <p><strong>张小珺：第3个问题：你曾经多次强调活下去比梦想重要，但如果未来10年技术奇点降临，你会选择all in一场颠覆现实的浪漫冒险，还是会继续做现实主义的守门人？</strong></p>
  <p><strong>朱啸虎：</strong>这也是我们为什么现在选择两个赛道的原因：一个是消费，消费就是保持现实主义的；另外，我们在AI上也在不断尝试，这就是希望能够再往前进取一点的。&nbsp;</p>
  <p>今天的选择不会all in去搏一个什么事情。&nbsp;</p>
  <p>我们作为投资人来说还是要有两条腿走路的一个想法。&nbsp;</p>
  <p><strong>张小珺：第4个问题：你对创业者常说别和巨头硬刚，但人类历史上所有浪漫的革命都始于逆势而为，你内心是否偷偷期待有人打破这条铁律？</strong></p>
  <p><strong>朱啸虎：</strong>DeepSeek确实是一个异军突起的。&nbsp;</p>
  <p><strong>在这么多大巨头、这么大投入情况下，它以“小米加步枪”一下子迅猛“杀”出来</strong>——这个真的是让人看到创业和投资的魅力！&nbsp;</p>
  <p><strong>张小珺：第5个问题：如果让你用一场爱情比喻投资，你认为自己是精打细算的婚姻规划师，还是偶尔仍会为一眼心动买单的浪漫主义者？</strong></p>
  <p><strong>朱啸虎：</strong>那风险投资肯定都是精打细算的啊。&nbsp;</p>
  <p>我们虽然做风险投资，我们一直在说，我们要知道自己冒着什么风险？——到底是冒着技术风险、是市场风险、还是团队风险？肯定都是要权衡到底多少风险，然后写多少支票的。&nbsp;</p>
  <p>作为机构风险投资人，肯定和个人投资或者其他都不一样，肯定是要做精打细算，要做好整个盘子的规划——整个基金到底投多少在高风险项目上，多少在低风险项目上，对吧？——这是要规划好的。&nbsp;</p>
  <p><strong>张小珺：如果你有机会投DeepSeek，这是一个高风险项目还是低风险项目？</strong></p>
  <p><strong>朱啸虎：</strong>同样的，和估值也是相关的。&nbsp;</p>
  <p>但今天确实风险降低了很多很多，因为它势头这么猛，建立开源生态的趋势相对比较明显了，风险相对来说降低了很多。&nbsp;</p>
  <p><strong>张小珺：他们最近也推出了多模态大模型，你对这个关注没有？</strong></p>
  <p><strong>朱啸虎：</strong>多模态门槛没那么高。多模态实际上不需要很多卡，而且中国数据远远超过美国。文字理解才是这波AI最核心的地方。&nbsp;</p>
  <p><strong>张小珺：你最近去新加坡，有什么新的观察没有？</strong></p>
  <p><strong>朱啸虎：</strong>我就很惊讶发现，泡泡玛特在新加坡居然是要配货的！！！这是让我大开眼界！！！&nbsp;</p>
  <p>我觉得大家真的可以欣赏欣赏DeepSeek的文字，它的文字真的很优美。你和它深度对话，问些比较深刻的问题，它会回复给你同样有深度的内容。&nbsp;</p>
  <p>这是特别不容易的，这是特别不容易的。&nbsp;</p>
  <p>所以大家都去体验体验，比看任何新闻报道都要更有意义。&nbsp;</p>
  <p><strong>张小珺：在你与他的交流中，他让你感到最兴奋的一个答案是什么？</strong></p>
  <p><strong>朱啸虎：</strong>存在、意识，甚至量子力学，回复都很有意思。&nbsp;</p>
  <p><strong>张小珺：能不能构想一下10年后、20年后的世界？</strong></p>
  <p><strong>朱啸虎：</strong>这一波AI影响力真的会非常大，以后人类社会组织形态包括工作形态，都会有很大一个变化。这确实今天还很难看得很透彻——但我觉得，3天工作制，可能真的会很快实现。&nbsp;</p>
  <p>确实变化太快了。只能走一步再看一步。&nbsp;</p>
  <p><strong>张小珺：但如果真的全部开源，并且有一天实现了AGI，当人手有一个AGI的时候，对人类的安全会造成威胁吗？</strong></p>
  <p><strong>朱啸虎：</strong>安全倒是其次。核心还是以后人到底干什么事情？现在真的看不清楚。&nbsp;</p>
  <p>以后绝大多数工作可能都是AI完成了——今天即使打数据标签，都需要博士级别的人——那真的，绝大多数人以后做什么事情？确实是一个需要持续观察的事情。&nbsp;</p>
  <p>不过，人类可以真的获得极大的解放，这是目前已经能够看得到的。&nbsp;</p>
  <p><strong>张小珺：这样的话，AI为什么还要服务人类呢？</strong></p>
  <p><strong>朱啸虎：</strong>它毕竟还是硅基的，毕竟是没有物理实体的。&nbsp;</p>
  <p>就像它回复一样，<strong>它还是需要“借助人类去体验这个世界”。</strong></p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/VCHnYxvG9S13xmmIRe1Knw" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：张小珺，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3157157338340103</id>
            <title>我在硅谷看AI：Deepseek狂飙背后，2025年15条AI关键投资启示</title>
            <link>https://www.36kr.com/p/3157157338340103</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3157157338340103</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 00:58:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <生成式AI, AI Agent, 投资趋势, 商业模式>
<br>
<br>
总结: 生成式AI作为颠覆性技术，正在推动各行业的发展，尤其在2025年将迎来AI Agent的商业化元年。随着大量资金涌入AI领域，生成式AI公司如OpenAI等迅速崛起，形成了新的“造富神话”。企业在AI应用上逐渐转向按工作成果收费的商业模式，取代传统的按席位收费方式。未来，专有模型和动态自适应界面将推动AI的广泛应用，满足多样化需求。2025年，消费级AI应用有望成为新的增长点，行业将迎来更多创新和变革。 </div>
                        <hr>
                    
                    <section style="margin-left: 8px; margin-right: 8px;">
   <span style="text-align: center;"></span>
  </section>
  <section style="letter-spacing: 0.578px; margin: 0px 8px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#01</strong></span>
  </section>
  <section style="text-align: justify; margin: 0px 8px; text-indent: 0em; line-height: 1.75em;">
   <span><strong style="color: rgb(0, 0, 0); font-size: 20px; letter-spacing: 1px; text-indent: 0em;">开篇</strong></span>
  </section>
  <section>
   <span>生成式AI，作为当今最具颠覆性的技术之一，正在引领各行业进入全新的发展阶段。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>2025年伊始，围绕生成式人工智能的竞赛愈发激烈。美国总统特朗普上任第二天，白宫宣布启动名为“星际之门”（Stargate）的人工智能项目，由美国甲骨文公司、OpenAI与日本软银集团联合出资打造。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>1月14日，OpenAI推出了名为Tasks的测试版功能，标志着ChatGPT正式迈入AI智能体（AI Agent）阶段。春节期间，中国大模型DeepSeek凭借其推理模型DeepSeek-R1引起了广泛关注，该模型以OpenAI十分之一的成本达到了GPT-o1的同级别表现。同时，DeepSeek在1月26日登顶苹果App Store和谷歌Play Store全球下载榜首，上线18天内下载量突破1600万。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>紧接着，OpenAI继续推动创新，发布动作不断：1月24日发布了一款代号为“Operator”的全新AI Agent产品；随后2月1日推出o3-mini，专注于STEM领域，支持函数调用、流式传输、结构化输出和搜索结合等功能；2月3日又推出面向深度研究领域的智能体产品，进一步拓展了其在专业领域的应用。谷歌也不甘示弱，在2月6日凌晨发布了性能更强的Gemini 2.0系列模型，包括Pro、Flash和Flash-Lite三个版本。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>如今，生成式AI正迎来类似的历史时刻，这不仅是科技革命，更是商业重塑的契机，我们正站在这一变革的起点。每一次平台级机会的背后，都会催生出一批市值百亿、千亿美金的公司。从互联网到移动互联网，再到云计算和区块链，每一次基础设施的创新都激发了无数新的应用场景，推动科技巨头的崛起。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>回顾这些历史周期，我们发现，基础设施的完善往往会催生应用公司的黄金发展期。生成式AI作为新型基础设施，正处于这一发展轨道的起点。未来，这些公司将通过创新的商业模式和智能化产品，重新定义我们的工作和生活方式，迎来属于自己的千亿市值时代。展望2025年，大语言模型将会走向何方？在这份报告中，我们将从行业变化、技术进展和应用趋势三方面，对大模型的未来发展进行深入前瞻。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   
  </section>
  <section style="letter-spacing: 0.578px; margin: 0px 8px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#02</strong></span>
  </section>
  <h2 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span><strong>AI疯狂吸金，千亿独角兽冉冉升起</strong></span>
   </h2>
  <section>
   <span>2024年，最为人们印象深刻的，便是生成式AI公司——OpenAI高达65亿美元的融资。这笔融资让这位生成式AI的弄潮儿估值达到约1500亿美元——一只大型千亿独角兽正在硅谷茁壮成长，而这只是2024年中最具代表性的一个。生成式AI所创造出的“造富神话”，多次让人们情绪高涨，AI就像一个庞大的“吸金兽”，以飓风般的速度吸走了大部分的风投资金。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>涌入AI赛道的大量资金和顶尖创业者，正在催生出了一批新晋独角兽公司。</span><span>根据硅兔君复盘，在过去18个月新增的73家独角兽中，有28家是AI公司，占到了新增独角兽的大约三分之一。</span><span>例如特斯拉创始人埃隆·马斯克在2023年7月创立的xAI，2024年3月发布了首款AI聊天机器人Grok-1，随后发布了Grok-1.5V大模型，其在最新一轮融资中，估值达到240亿美元；Xaira Therapeutics，作为AI+生物技术领域的公司，其联合创始人David Baker在“AI+蛋白质”领域颇有造诣，其团队研发出AI大模型RFdiffusion，用扩散模型构建的创新型生成式AI系统，并且可以按需构建AI分子，估值为27亿美元；Cognition AI是一家由三位华人创业者创立的公司，2024年3月，其推出了世界上第一位完全自主的AI软件工程师，在最新一轮融资后估值达到20亿美元。</span></span>
   
  </section>
  <section>
   
  </section>
  <p style="text-align: center; margin-left: 8px; margin-right: 8px; margin-bottom: 0px;"><img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_bd8770684c514a719af45e439b8628c0@000000_oswg206354oswg768oswg396_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p style="text-align: center; margin-left: 8px; margin-right: 8px; margin-bottom: 0px;"><span>制图：硅兔赛跑，数据来源pitchbook</span></p>
  <section>
   
  </section>
  <section>
   
  </section>
  <p style="text-align: center; margin-left: 8px; margin-right: 8px; margin-bottom: 0px;"><img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_5f2bd6ad36ae499d847a767714f11a19@000000_oswg146314oswg524oswg412_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <section>
   <span>制图：硅兔赛跑，数据来源pitchbook</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>这些AI独角兽的成长速度远快于非AI独角兽，前25%的AI公司在不到2.5年内就已经达到独角兽估值。同时，最大规模的交易也流向了AI的初创企业。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>另一个趋势是——</span><span>融资额正在变大，头部效应更加明显</span><span><span>。根据第三方数据分析机构Pitchbook的数据，2024年，光是北美的风险投资总金额达到了2164亿美金，较2023年增长了28%。</span><span>其中2024年四季度，北美地区的融资额达到了771亿美金，创下了2年以来的新高，光是人工智能相关项目的投融资额达到了991亿美金，占到了总额的45.8%，达到了历史最高水平。</span><span>过去美国最大的10笔风险投资交易每年通常占总融资额的9%左右，而自2023年以来，这一比例升至20%。</span></span></span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>过去一年，我们在硅谷，这个北美将近50%投融资发生的地区以及最能够代表北美创投发展的地方，捕捉到最新的一些变化并试图梳理出最前沿的趋势：</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>首先，针对人工智能创投领域，有四大行业趋势值得关注：</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>1、如果说2023年的AI Agent，只是停留在诸如斯坦福小镇这样的虚拟世界；2024年，AI Agent的商业化条件逐渐成熟；2025年则是Agent AI商业化的元年，资本的关注和注入加速，会加剧各大科技公司和初创企业在Agent AI 领域的竞争，推动技术创新和产业应用的落地。</span>
   
  </section>
  <section>
   <span>2、一方面围绕生成式AI基础设施的投资规模空前，带动了一系列产业链公司；另一方面，业界正在尝试一些低成本、性价比高的做法，减少训练的投入却能达到与GPT-4/4o等同的效果；</span>
   
  </section>
  <section>
   <span>3、专有AI模型正在释放AI潜力，他们正在解决通用大模型不能解决的问题，逐步具备较高的商业化潜力。</span>
   
  </section>
  <section>
   <span>4、生成式界面将迎重大发展，用户能够有更好的互动体验，将带来新的商业模式和市场机会。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>其次，在人工智能的技术方面，我们总结了八大趋势：</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>1、2025年，大模型将更加关注多模态的融合与交互，其训练方法正在不断优化；</span>
   
  </section>
  <section>
   <span>2、一直以来，尽管大模型能力在不断增强，但仍无法解决人工智能的“黑箱”问题。2024年，许多公司陆续推出了更透明的模型架构和解释工具以缓解“黑箱”带来的麻烦。2025年，可解释性工具将进一步普及；</span>
   
  </section>
  <section>
   <span>3、2024年，大模型的长期记忆能力迎来了一系列技术突破。2025年，随着多模态技术的进步，跨模态记忆融合将在视频、文本、触觉和嗅觉数据的编码上取得突破，进一步提升模型的记忆能力。</span>
   
  </section>
  <section>
   <span>4、合成数据作为加速大模型训练的方法，将在2025年进一步发挥潜能。</span>
   
  </section>
  <section>
   <span>5、2025年，随着更强大的计算资源的普及和优化，规模定律将继续提升，这使得更多的中小型企业可以进入AI领域，加速了大模型的普及，效率跃迁曲线下，大模型的成本更低了。</span>
   
  </section>
  <section>
   <span>6、2025年，强化学习（RL）与大语言模型的结合有望进一步提升模型的泛化能力，并使得从预训练到后训练和推理迁移的转变成为可能。</span>
   
  </section>
  <section>
   <span>7、随着AI应用场景的多样化，简化算法架构将成为AI发展的重要方向。2025年，更多优化算法将被用于强化学习等领域，以减少计算资源的消耗。</span>
   
  </section>
  <section>
   <span>8、随着AI蒸馏技术的普及，相关的法律和监管框架也需要不断加强，以确保在模型开发和应用过程中不会侵犯知识产权或数据隐私。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>另外，在人工智能的应用方面，2025年也有了一些新的变化：</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>1、2025年，企业级AI应用迎来深入发展，越来越多企业将从人工智能中获利。AI Agent成为行业颠覆性力量，生成式AI推动传统行业进入智能化时代。随着企业在生成式AI上盈利，商业模式转变为按工作成果收费，取代传统的SaaS席位收费。</span>
   
  </section>
  <section>
   <span>2、2025年对于AI应用来说，下一个重大事件将属于消费。我们期待一个“杀手级”AI消费应用的诞生。</span>
   
  </section>
  <section>
   <span>3、在AI应用端，企业不再依赖单一模型，而是会根据不同的应用需求和场景，将不同模型模块进行组合，定制出符合自己业务需求的模型。</span>
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势一 ：2025年，AI Agent元年拉开序幕</span>
   </h3>
  <section>
   
  </section>
  <section>
   <span><span>人工智能未来学家雷·库兹韦尔 (Ray Kurzweil)表示，2025年，我们将开始看到从聊天机器人和图像生成器向“代理”系统的转变，这些系统可以自主完成任务，而不仅仅是回答问题</span><span>。人工智能系统正在从单一的交互模式，走向专门且相互关联的代理。</span></span>
   
  </section>
  <section>
   <span>AI Agent，也称为人工智能代理，通常是指能够感知环境、进行自主理解、决策和执行动作的智能体。根据咨询公司来觅PEVC的统计，自2024年以来，全球AI Agent赛道的融资金额已突破665亿元人民币。从整体来看，这些资金主要流向了在技术与市场潜力方面处于领先地位的头部企业。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>科技巨头纷纷布局AI Agent，以抢占未来智能交互的制高点。2024年，OpenAI凭借其强大的技术实力和广泛的市场应用，官宣65亿美元新融资，成为万亿独角兽，也成为全球AI Agent领域的主要资金流之一。埃隆·马斯克创立的xAI，希望将AI Agent与人类深度整合，创建全球首个AI Agent与人类共存的社交平台，xAI在2024年12月完成60亿美元融资，估值达到了近500亿美元。</span><span>谷歌也全力推广商用AI Agent，发布了全球为数不多的商用AI Agent市场，为企业提供一站式开发、部署和应用生态。微软在2024年11月的Ignite大会上宣布已建立全球规模最大的企业级AI Agent生态系统，企业用户可通过Azure AI目录访问超过1800个AI模型。此外，</span><span>微软的Copilot Studio平台已支持用户创建自主Agent，并正式进入预览阶段。</span><span>苹果也在开发者大会上展示了其最新的AI成果Apple Intelligence。</span></span>
  </section>
  <section>
   <span>2025年，OpenAI推出的智能体功能（AI Agent）以及一系列基于生成式AI的智能系统，它们开始具备真正的自主学习和推理能力，从单一任务的执行者，转变为能够进行多任务处理、复杂决策和交互的智能体——1月24日，OpenAI发布了一款代号为“Operator”的全新AI Agent产品，与其他各家Agent相比，它会通过自有的CUA（电脑控制Agent）系统进行复杂的思维链反思和步骤规划，这可以大大提高其完成任务的精度和复杂性。Operator的创新之处在于其成功实现了从认知到执行的完整闭环。这一能力的拓展不仅是技术上的突破，更是AI技术迈向更高层次发展的关键一步。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>AI Agent不再是单一的辅助工具，而是可以独立进行深度学习、理解和推理的智能系统，赋能企业和个人高效完成复杂任务，推动生产力的大幅提升。</span><span>2025年，AI智能体的全面普及将不仅改变技术产业的格局，还将在各个领域深刻影响人类的生活方式，从而使这一年成为AI Agent真正崭露头角的元年。</span></span>
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势二：基础设施军备竞赛：投资空前，低成本做法渐成趋势</span></h3>
  <section>
   <span>一年多以前，基础大模型制造商OpenAI，在芯片制造商英伟达生产的25000个最新进GPU集群上训练了GPT-4。随后，马斯克表示他在一个数据中心有100000个GPU，并计划购买200000个。</span>
   
  </section>
  <section>
   <span>头部公司通过大规模资金投入，抢占人工智能基础设施的制高点，而以英伟达为代表的硬件厂商也在以前所未有的速度上不断突破技术极限。例如，英伟达的顶级芯片性能相当于300部高端iPhone的处理能力。</span>
   
  </section>
  <section>
   <span>在这场基础设施竞争中，埃隆·马斯克的X平台部分业务——xAI的“Colossus”训练集群，成为世界上最强大的人工智能训练集群之一。这个集群仅用122天便建成，预算高达30亿至40亿美元，成为人工智能基础设施建设的里程碑。目前，xAI计划将集群容量翻倍，进一步增强处理能力。Meta也在大规模投资硬件，近期公布了其24000个GPU数据中心规模集群的两个版本，旨在支持其下一代人工智能模型。</span>
   
  </section>
  <section>
   <span>虽然目前GPU集群比传统数据中心小，但对人工智能计算不断增长的需求将需要大规模的基础设施扩展。包括Meta、亚马逊、Alphabet和微软在内的主要科技公司正在推动对人工智能基础设施的空前投资。超大规模数据中心运营商预计2024年资本支出（CapEx）将超过 2000 亿美元，到2025年这一数字预计将接近2500亿美元。尽管并非所有支出都直接与人工智能相关，但很大一部分都分配给了人工智能，并且这个份额在不断增加。微软和OpenAI已讨论推出一个专门用于人工智能工作负载的5千兆瓦数据中心，可能耗资超过1000亿美元，甚至可以买得下一艘最新型核动力航空母舰。</span>
   
  </section>
  <section>
   <span>在这场人工智能基础建设中受益的，是这个产业链中的组成部分。</span>
   
  </section>
  <section>
   <span><span>第一类就是数据中心的托管服务提供商</span><span>——也就是向大公司提供数据中心租赁容量的公司，他们是数据中心市场的重要组成部分。这批数据中心的托管服务提供商如今也在拓展其以人工智能为重点的基础设施服务。例如，超大规模托管领域的领导者 Equinix 已获得近 150 亿美元的资金用于在美国建设人工智能数据中心，主要为客户提供基础设施，以训练和部署大规模私有人工智能模型，这些客户往往是科技行业以外的财富 500 强公司。</span></span>
   
  </section>
  <section>
   <span><span>另一类受益者则是人工智能数据中心建设中的辅助产品</span><span>，例如低功耗CPU、内存、存储系统、网络组件以及冷却和电源管理设备。冷却产品供应商 Vertiv在2024年7月至9月的三个月内实现了19%的同比收入增长，并提高了未来12个月的业绩指引。</span></span>
   
  </section>
  <section>
   <span><span>第三类则是围绕数据中心能源生产、热管理和电源管理解决方案的公司。</span><span>Alphabet董事长在2023年2月表示，与LLM互动可能比标准关键字搜索的花费高出10倍。另外，根据谷歌研究员Urs Hölzle的文章提及，标准Google搜索使用的电力为0.3Wh，这意味着每次LLM互动的耗电量约为3Wh。这个数字与SemiAnalysis在2023年初对ChatGPT运营成本的评估一致，该评估估计ChatGPT每次请求耗电量为2.9Wh，如果每天响应1.95亿个请求，估计平均每天耗电量为564MWh。</span></span>
   
  </section>
  <section>
   <span>《纽约客》报道称，ChatGPT每天用电量相当于1.7万个美国家庭的用电量。如果基于当前模型和技术，让每个标准Google搜索都变成 LLM 交互，对 Google总用电量的潜在影响巨大。第三方分析机构SemiAnalysis估计，带有大模型交互功能的谷歌搜索单次请求的用电量达到将近9Wh，谷歌每天搜索大约需要90亿次，则需要81000MWh。</span>
   
  </section>
  <section>
   <span>这一趋势促使人们对位于数据中心设施附近的核能和能源生产等技术以及热管理和电源管理解决方案进行投资。</span>
   
  </section>
  <section>
   <span>不过，如今科学家和业界正在寻找更聪明并且资源密集度更低的方法来解决训练人工智能模型所需要的算力和能源问题。例如通过蒸馏技术，这项技术的践行者——DeepSeek，这家国产大模型也给美国硅谷提供了更多低成本的训练参考。DeepSeek大模型性能在多个方面比肩OpenAI，其中DeepSeek V3，整个训练过程仅用了约2000张二流芯片进行训练，官方称成本仅占用约550万美元，而Meta的模型则使用了16000个性能最强的一流芯片。并且，DeepSeek-R1通过重新设计训练流程、以“少量SFT数据+多轮强化学习”的办法，在提高了模型准确性的同时，也显著降低内存占用和计算开销，每百万输出tokens16元，大约是OpenAI o1运行成本的三十分之一。</span>
   
  </section>
  <section>
   <span>在这样的竞争压力下，0penAI推出了其成本更低的o3-mini，比o1-mini便宜63%，比完整的o1模型便宜93%，每百万tokens的进出费用分别为1.10美元/4.40美元(享有50%的缓存折扣)。谷歌发布的Gemini 2.0 Flash-Lite是Gemini 2.0系列的新变体，每百万tokens0.3美元，是谷歌目前最便宜的模型。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>可以窥见，在AI产业的竞争中，降低训练成本、提高计算效率和优化模型性能已成为企业的主要竞争策略。尤其是训练流程的优化，成为了公司在大模型市场中占据竞争优势的关键能力之一。</span><span>2025年，低成本做法也将成为行业的主流趋势。</span></span>
   
  </section>
  <section>
   <span>此外，一些大公司也在开发专用人工智能芯片，例如谷歌、苹果、微软和OpenAI，这些专业芯片可以比英伟达这样通用处理器运行更高效；或是采用一些方法提高芯片的使用效率，例如用多种模型，每种模型针对不同问题，以此来缩短芯片的处理时间等。AI推理芯片制造商Groq2024年估值达到28亿美元，在Blackrock领投的新一轮中融资6.4亿美元，其专为AI推理任务设计的芯片“语言计算单元”（LPU, language processing unit）能以现有解决方案1/10的价格、10倍的速度运行与ChatGPT、GPT-4o相似的模型。目前，在Groq开发的、对标英伟达CUDA的软件开发平台GroqCloud平台上，约有40万开发者。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势三：专有模型有望释放AI的应用潜力</span>
   </h3>
  <section>
   <span>大模型就像个通才，然而，在一些专业领域，大模型往往缺乏针对性和操作性。为了突破这一瓶颈，越来越多的公司开始专注于开发专有模型，通过在特定领域数据上微调模型，实现更高效的工作流程自动化，提供更具操作性和任务导向的工具。这一趋势正在逐步升温，并在多个行业展现出巨大的应用潜力。以下为一些具体的案例：</span>
   
  </section>
  <section>
   <span><span>金融服务领域，提升决策效率与洞察力：</span><span>摩根大通和彭博社等机构正在利用其庞大的内部数据集开发大语言模型，以提升运营效率和决策能力。这些模型能够提供独特的市场洞察、风险分析和报告生成。例如，彭博社于2023年开发了BloombergGPT，专注于金融领域的数据分析和预测，通过微调金融数据，能够更高效地处理复杂的金融任务，如市场趋势分析和投资策略制定。</span></span>
   
  </section>
  <section>
   <span><span>网络安全领域，精准检测与应对威胁：</span><span>美国网络安全解决方案提供商Palo Alto Networks正在训练自有的大语言模型，这些模型能够帮助安全专家更好地检测和应对网络威胁。该公司在2024财年四季度披露了超过2亿美元的AI相关经常性收入，同比增幅近四倍。AI大模型通过模拟复杂攻击场景，帮助安全团队快速发现系统漏洞并提供修复建议，显著提升了网络安全的实时预警和用户行为分析能力。</span></span>
   
  </section>
  <section>
   <span><span>国防领域，用于军事与情报分析：</span><span>美国数据分析和软件公司Palantir近期获得了一系列合同，用于支持AI的服务，包括加速部署适用于国防和军事领域的AI模型。这些模型能够提升情报分析、目标识别和决策支持能力。例如，AI训练平台可以创建逼真的战斗场景，帮助士兵在安全环境下进行战术训练。此外，AI技术在军事领域的应用还包括无人化作战系统和沉浸式训练模拟。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span><span>生命科学领域：2024年，科研人员使用AI的比例快速增加，AI对科学研究方法和流程的变革效应也开始显现。</span><span>比如，AlphaFold 3.0在2024年发布，不仅提高了蛋白质结构预测的准确率，还扩展到了DNA和RNA等生物分子的研究，这项技术帮助科学家快速预测药物分子与目标蛋白质的结合情况，大大提高了药物研发的效率。</span></span><span>2025年，多模态大模型将进一步融入科学研究，赋能多维数据的复杂结构挖掘，辅助科研问题的综合理解与全局分析，为生物医学、气象、材料发现、生命模拟、能源等基础与应用科学的研究开辟新方向。</span></span>
   
  </section>
  <section>
   <span>除了上述领域，专有模型还在其他行业展现出广泛的应用前景。例如，Two Sigma在量化投资中使用AI Agent进行选股策略，通过分析财务数据和宏观经济指标，识别潜在的投资机会。Shopify Sidekick则利用LLama 2生成产品描述、回应客户查询和创建营销内容，帮助小企业主提升运营效率。</span>
   
  </section>
  <section>
   <span>专有模型通过在特定领域的数据上进行微调，能够提供更具针对性和操作性的解决方案。这种趋势不仅提升了各行业的自动化水平，还为企业带来了显著的运营效率提升和成本降低。随着AI技术的不断发展，未来专有模型将在更多领域得到广泛应用，成为推动行业创新的重要力量。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势四：推动动态自适应界面，实现高度个性化的交互体验</span>
   </h3>
  <section>
   <span>生成式界面（Generative Interface）是指利用生成式模型，如生成对抗网络（GANs）或变分自编码器（VAEs），自动创建用户界面元素或交互流程。这种界面不是通过传统设计方法人工制作，而是通过机器学习算法根据输入的数据、需求或上下文生成。</span>
   
  </section>
  <section>
   <span><span>在2024年，</span><span>生成式用户界面（Generative UI）在动态和自适应界面、AI与算法融合、个性化体验等方面取得了显著进展</span><span>。大规模生成式预训练模型（如GPT系列、DALL·E等）已被广泛应用于自动化界面设计。开发者借助这些模型，可以快速生成和调整界面元素，如按钮、布局、色彩搭配等，甚至可以根据用户反馈实时调整界面的外观和功能。</span></span>
   
  </section>
  <section>
   <span>此外，生成式界面逐步在增强现实（AR）和虚拟现实（VR）环境中得到应用，尤其是在需要复杂交互的沉浸式体验中，AI帮助生成自适应、动态变化的虚拟界面。例如，英伟达在2024年SIGGRAPH大会上展示了利用实时生成式AI创建沉浸式沙漠世界的研究成果。此外，英伟达还通过Holoscan技术赋能手术机器人，加速AI技术在医疗实践中的应用。这些应用展示了生成式AI在动态生成虚拟界面方面的潜力，尤其是在需要高度沉浸感的场景中。</span>
   
  </section>
  <section>
   <span>可以说，随着用户需求变得更加多样化和复杂，传统的固定界面无法满足个性化的交互需求。动态自适应界面能够根据用户的行为、偏好和环境变化实时调整显示内容和功能，提供更加定制化的体验。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span><span>展望2025年，生成式界面将迎来重大发展，成为推动用户体验变革的关键力量</span><span>。越来越多的应用将采用基于用户交互和逻辑工作流程自适应的动态用户界面。生成式UI将使应用能够自动生成表单、仪表板或可视化等界面元素，这些元素将根据用户的具体需求和操作量身定制。例如，Web开发平台Vercel和Bolt.new等公司正在开发能够创建高度适应性和个性化用户体验的平台，提供实时演进的界面，以满足不断变化的需求，从而简化工作流程。</span></span>
   
  </section>
  <section style="letter-spacing: 0.578px; margin: 0px 8px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#03</strong></span>
  </section>
  <h2 style="text-align: justify; text-indent: 0em; margin: 0px 8px; line-height: 1.75em;"><span><strong>八大技术趋势，推动AI泛化能力</strong></span></h2>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势一：多模态能力的增强和集成</span>
   </h3>
  <section>
   
  </section>
  <section>
   <span>2024年，多模态AI取得了显著进展。OpenAI、Google DeepMind等机构推出了更强大的多模态模型，如视频生成模型Sora的诞生、OpenAI多模态AI大模型GPT-4o的到来、CLIP模型通过跨模态表示实现图文搜索，用户可以通过输入文本搜索相关图像或视频。此外，文本到图像生成（如DALL·E、Stable Diffusion）和视频生成模型也取得了显著进展，进一步拓展了AI的交互体验。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>大模型逐步增加了能够处理图像、音频或视频等多种输入形式。这些模型不仅提升了AI对复杂信息的处理能力，还拓展了其应用领域。在谷歌云发布的《2025年AI商业趋势》报告中，多模态AI被放在首位。</span><span>谷歌云预测，2025年将成为企业采用AI技术的关键一年，这一趋势主要由多模态学习及其实现的情境感知所驱动的，并预计2025年全球多模态AI市场规模将达到24亿美元。</span></span>
   
  </section>
  <section>
   <span>2025年，大模型将更加关注多模态融合与交互。AI不仅能够生成文本，还能理解图像、视频中的上下文，甚至在多模态环境中进行决策。比如，结合视觉与语音的能力，模型能够更好地理解复杂的场景，并做出合适的反应。</span>
   
  </section>
  <section>
   <span>此外，多模态模型的训练方法也在不断优化，例如采用分阶段训练策略，先固定大语言模型的权重参数，对图像编码器和桥接组件进行初步训练，再进行整体训练，从而提升模型性能。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势二：大模型的可解释性表现更强</span></h3>
  <section>
   <span>可解释人工智能 (xAI) 是人工智能领域的一个新兴领域，致力于使人工智能系统对人类更加透明、可解释和可理解。xAI的兴起源于人们对人工智能决策过程透明度和问责制的需求日益增长，尤其是随着人工智能系统变得越来越复杂并部署在金融、法律或医疗保健等高风险领域。例如，考虑医院用于筛查患者X光片的肿瘤检测 CNN（卷积神经网络） 模型的情况。但是，当技术人员或患者不知道其工作原理时，他们如何能相信其结果？这正是我们需要方法来了解影响任何深度学习模型决策的因素的原因。</span>
   
  </section>
  <section>
   <span>另外，AI的安全性问题是一个不可忽视的关键挑战。尤其是大模型在做出决策时的“思考过程”对于用户和开发者来说变得不透明，就像一个“黑箱”，其决策过程难以解释和追踪。若这些模型未经过严格的审查和验证，它们可能会做出无法被察觉的有害决策，甚至加剧社会偏见和不公。因此，加强对大模型的监控、审查和可解释性要求是提升AI系统安全性的重要一步。</span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>2024年，大模型的可解释性取得了重要进展。OpenAI、Google DeepMind等机构推出了更透明的模型架构和解释工具，如GPT-4的可解释性增强版本和Gemini的跨模态解释功能。LIME、SHAP等后验解释方法被广泛应用于医疗、金融等领域，帮助用户理解模型决策依据。同时，自监督学习和符号AI的结合提升了模型的内在可解释性，减少了“黑箱”问题。行业也开始重视可解释性的标准化，例如欧盟《人工智能法案》要求高风险AI系统提供清晰的决策解释。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>2025年，可解释性工具将进一步普及，将模型将内置更强大的解释能力，实时生成决策依据，并支持多模态数据的跨模态解释，</span><span><span>帮助用户理解复杂AI模型的决策过程。通过一些自主进化模式或可解释性工具，将模型将内置更强大的解释能力，实时生成决策依据，并支持多模态数据的跨模态解释。</span><span>可解释性与性能的平衡将得到优化，知识蒸馏和模型压缩技术将帮助简化复杂模型的同时保持高精度。行业专用可解释性工具将普及，满足医疗、金融等领域的合规需求。</span></span></span>
   
  </section>
  <section>
   <span><span>以DeepSeek为例，</span><span>通过纯算法自主进化的Zero模式与仅需数千条人工标注数据的R1模式组合</span><span>，</span><span>既保留模型自主进化能力又保障人类可解释性</span><span>————Zero模式使得模型能够自我进化和发现数据中的规律，而R1模式通过引入人工标注数据为模型提供了一个监督和解释的框架。这种结合确保了模型在保持自主学习能力的同时，也能够被人类理解和控制，从而提升了可解释性。</span></span>
   
  </section>
  <section>
   <span>此外，伦理和隐私保护将深度融入可解释性设计，确保AI系统既透明又安全，推动大模型在高风险场景中的广泛应用。以下是一些提升的方向和工具：</span>
   
  </section>
  <section>
   <span>○&nbsp;自监督学习与模型可解释性：通过自监督学习，AI系统可以在缺乏大量标注数据的情况下，通过理解数据的内在结构来进行学习，这种方法有助于提升模型的透明度，使得我们能够更好地理解其学习过程。</span>
   
  </section>
  <section>
   <span>○&nbsp;生成对抗网络（GANs）和模型蒸馏：通过生成对抗网络和蒸馏技术，开发者能够简化复杂模型，同时保持高效性和准确性，这种方法使得大规模深度学习模型更加易于解释。</span>
   
  </section>
  <section>
   <span>○&nbsp;增强推理框架和可视化工具：新一代的AI推理框架将更注重可视化，帮助用户以更直观的方式理解模型决策的依据。例如，基于图像或文本的AI系统，新的可视化工具可以清晰展示模型如何关注不同的输入特征，从而提升其可解释性。</span>
   
  </section>
  <section>
   <span>需要一提的是，未来AI的安全不光需要提升可解释性，还需要着重于法律合规性、安全审计和滥用防范等方面，推动AI技术的负责任应用。随着技术的不断发展，AI如何在不断的创新中确保安全，将成为AI领域面临的重大挑战之一。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势三：大模型长期记忆能力迎来深层次变革</span></h3>
  <section>
   <span>目前的许多大模型（如基于Transformer架构的模型）在处理长文本或复杂上下文时，常常会面临信息丢失等问题。传统模型一般有固定的“记忆窗口”，当文本或输入信息过长时，模型往往会忘记最初的信息，或者在处理过程中只关注较近的上下文。长期记忆的核心需求是让模型能跨越多个时刻、任务和场景记住信息，并能在合适的时机提取和利用这些信息。</span>
   
  </section>
  <section>
   <span><span>大模型的长期记忆能力迎来了一系列技术突破。</span><span>首先，在上下文窗口的扩展上，</span><span>比如2024年，Google Gemini 1.5 Pro突破性地实现了最高可达1000万token的处理能力。到2025年2月发布的Gemini 2.0全家桶，最强Pro版本可支持到2M上下文。</span></span>
   
  </section>
  <section>
   <span><span>其次，外部记忆系统的引入推动了大模型记忆能力的发展。</span><span>如IBM WatsonX的实时知识图谱更新功能使得在医学诊断等特定领域的记忆准确率提高了35%。持续学习机制方面，Meta的LoRA-X架构通过参数隔离技术降低了多任务干扰，OpenAI则部署了分布式记忆训练系统，使百万设备协同进化，提升了记忆系统表现。在记忆检索方面，Anthropic的ContextRouter模块和微软的MAVEx系统分别通过动态记忆权重分配和跨模态联合检索，优化了记忆检索的准确性与效率。</span></span>
   
  </section>
  <section>
   <span><span>第三，隐私与安全问题也得到了关注，</span><span>Google推出的Memory Provenance框架增强了记忆的透明度和可控性，而HuggingFace的SafeMemory工具包通过差分隐私技术将隐私泄露的风险大幅度降低。这些技术突破使大模型的长期记忆能力得到了显著提升，推动了多个领域的应用发展。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>2025年，大模型的长期记忆技术将迎来新的发展趋势。</span><span><span>如混合窗口架构或将成为上下文处理的新范式</span><span>，</span><span>能够根据任务需求动态调整局部和全局注意力的范围，大幅度提升处理效率。随着多模态技术的进步，跨模态记忆融合将在视频、文本、触觉和嗅觉数据的编码上取得突破，进一步提升模型的记忆能力。记忆权限管理和记忆遗忘机制将更加成熟，为隐私和安全提供更强保障。</span></span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>此外，随着用户对个性化和定制化的需求不断提升。</span><span>个性化记忆系统能够根据用户的特定需求、偏好和行为习惯构建专属的记忆图谱。</span><span>例如，AI助手可以记住用户的兴趣、常用的命令、偏好的回答风格等，从而提供更加精准和符合需求的回复。2025年，个性化记忆系统也将成为大模型发展的重点方向，大模型能够根据用户需求构建专属记忆图谱，提高个性化回复的准确性，并通过跨设备记忆同步实现实时更新。</span></span>
   
  </section>
  <section>
   <span>不过，尽管大模型在长期记忆方面取得显著进展，但仍面临技术挑战，包括记忆冲突解决、多来源记忆的置信度评估体系、能耗瓶颈和认知偏差防控问题。商业应用方面，医疗、教育和金融等行业将受益于大模型长期记忆能力的提升，预计能够降低误诊率、提升知识留存率并加速风控响应速度。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势四：合成数据或加速大模型训练</span>
   </h3>
  <section>
   <span style="letter-spacing: 1px;"><span>随着人工智能技术的飞速发展，数据成为推动AI进步的核心资源。</span><span>2025年，合成数据作为加速大模型训练的一种重要方法，正在成为AI发展的关键趋势。</span><span>马斯克在2025年CES（消费电子展会）的访谈中提到，随着人类累积的知识几乎被AI训练完毕，未来的AI系统将不得不依赖合成数据进行自我生成和学习。这一观点突显了合成数据在未来AI技术发展中的潜力。</span></span>
   
  </section>
  <section>
   <span>目前，多个科技巨头已经开始在AI模型训练中广泛应用合成数据。微软、Meta、OpenAI和Anthropic等公司纷纷将合成数据作为增强模型训练效率和拓宽训练数据源的有效手段。例如，2024年下半年发布的Llama 3.1、o1、DeepSeekV3和Phi-4等模型均报告了使用合成数据进行训练。根据科技市场研究机构Gartner的预测，到2024年，AI及分析项目中使用的数据中，60%以上将来自合成数据。合成数据能够帮助AI系统在真实数据难以获得或标注成本过高的情况下，生成具有代表性且符合特定任务需求的数据，大幅降低了对实际数据的依赖。</span>
   
  </section>
  <section>
   <span>然而，合成数据的使用仍然面临诸多挑战与争议。2024年7月，《Nature》期刊刊登的论文指出，LLM生成的合成数据可能会污染下一代模型的训练集，导致模型性能下降，甚至发生“崩溃”。这一风险类似于“数据中毒”问题，严重时可能让模型无法做出有效的推理和判断。英伟达也发布了其Nemotron-4 340B开源模型，声称使用了98%的合成数据，但同时也强调需要加强合成数据的质量控制，以避免潜在的负面影响。</span>
   
  </section>
  <section>
   <span>尽管面临风险，但合成数据在加速大模型训练方面的潜力仍然巨大。尤其在高性能计算和多模态数据融合等领域，合成数据可以快速扩展训练集的规模，并提供更多样化的训练情境。为了应对合成数据带来的挑战，AI研究者正在不断优化生成数据的质量和多样性，例如通过强化学习算法对合成数据进行校正，或者结合人类监督和自动化评估机制来减少“数据污染”风险。</span>
   
  </section>
  <section>
   <span>展望未来，随着技术的不断进步，合成数据有望成为AI训练中的重要组成部分。它不仅能加速模型的训练过程，还能在数据匮乏或难以获取的领域，为AI发展提供新的动力。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势五：大模型普及加速，效率跃迁曲线下成本更低了</span>
   </h3>
  <section>
   <span><span>在2025年1月，Anthropic的CEO-Dario Amodei 发表了一篇长达万字的深度分析报告。肯定了DeepSeek的技术突破：其最新模型在特定基准测试中已逼近美国顶尖水平，并尝试从三个维度将中国的AI进步纳入全球技术演进坐标系进行定位：</span><span>算力规模定律、效率跃迁曲线、范式革新动能。</span></span>
   
  </section>
  <section>
   <span>这些维度的选择反映了他对国产AI评估方面的理解：关注硬件和计算能力的提升（算力规模定律），技术的效率提升（效率跃迁曲线），以及新技术范式的创新和推动力（范式革新动能）。这种全方位的定位方式，能够精准捕捉到AI大模型在全球技术演进中的角色及潜力。具体我们解释下这三方面的重要性和趋势：</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>首先，规模定律是推动大模型发展的基础。随着硬件技术不断进步（如更强大的GPU、TPU和专用AI芯片），训练超大规模模型已变得越来越可行，同时也驱动了云计算和分布式计算的发展，进一步降低了成本。</span><span>随着更强大的计算资源的普及和优化，规模定律将继续提升，这是2025年AI大模型的关键能力趋势之一。</span></span>
   
  </section>
  <section>
   <span><span>其次，关于效率跃迁曲线，曲线偏移指的是</span><span>技术创新带来成本曲线的变化，使得原本高昂的训练成本能够通过硬件优化、模型架构改进等手段大幅降低。</span><span>这不仅能够降低AI研发的门槛，还能加速技术迭代。比如2024年，硬件创新如量子计算、专用AI加速芯片推动AI训练成本的快速降低。同时，AI框架的优化（如更高效的深度学习框架）和算法改进帮助实现了更少计算资源的更高效训练。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>在前文中我们也提到了，目前对于AI基础设施方面军备竞赛激烈，低成本做法渐成趋势，尤其是DeepSeek通过采用OpenAI等先进模型，利用蒸馏技术将其知识转移。这一过程使得DeepSeek能够在保持较高性能的同时，显著减少训练所需的计算资源和时间。通过模仿OpenAI模型的输出，“学生模型”能够快速学习复杂的模式和推理能力，加速模型的优化过程。</span><span>2025年，随着硬件和算法的进一步突破，AI开发成本将大幅下降，这也使得更多的中小型企业可以进入AI领域。</span></span>
   
  </section>
  <section>
   <span>此外，新的训练范式（如强化学习、无监督学习等）正在改变AI的学习方式。2020到2023年，AI主要依赖预训练模型，使用大量互联网文本进行训练，并通过少量额外训练进行微调。然而，到了2024年，强化学习（RL）成为新的重点，通过强化学习生成思维链，AI在数学、编程和推理等任务上的表现显著提升。初期阶段投入较少，但效果显著。</span>
   
  </section>
  <section>
   <span>强化学习和自监督学习等新兴范式逐渐在机器人、自动化和多模态学习领域得到应用，尤其提升了机器人在动态环境中的自主学习和决策能力。到2025年，这些新训练范式预计将成为AI发展的主流，尤其在复杂任务处理上（接下来趋势六我们会进一步解释）。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势六：预训练到后期训练和推理迁移转变</span></h3>
  <section>
   <span><span>2024年是AI技术飞速发展的一年，尤其是在大语言模型（LLM）和多模态技术方面取得了显著突破。这一年，</span><span>AI从单一模态向多模态融合迈进，大语言模型通过扩展上下文窗口和采用混合专家架构（MoE）等技术，显著提升了推理和生成能力。</span><span>同时，强化学习（RL）开始与大语言模型结合，为模型的泛化能力提升提供了新的方向。此外，AI在医疗、金融、自动驾驶等领域的应用不断深化，推动了行业变革。然而，随着模型规模的扩大，预训练阶段的性能提升逐渐放缓，行业开始探索后训练和推理迁移的新模式。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>2025年，AI技术将进入一个新的发展阶段，Scaling Law的扩展将成为关键趋势之一。</span><span>强化学习与大语言模型的结合（RL+LLMs）将进一步推动模型泛化能力，从预训练向后训练和推理迁移转变。</span></span>
   
  </section>
  <section>
   <span>这种模式将使AI在特定场景下的表现得到显著提升，同时降低训练成本，提高模型的适应性和灵活性。此外，AI将在更多领域实现落地应用，如智能驾驶、具身智能等，这些领域将迎来技术突破和商业化的加速，但也与此同时会带来更多的安全和风险管理挑战。因此，AI安全和治理将成为行业关注的重点。</span>
   
  </section>
  <section>
   <span><span>需要强调的是，</span><span>大规模语言模型（LLM）的预训练阶段已经接近瓶颈，主要受到数据、计算资源和模型规模增长的限制，且在通用性提升上边际效益递减。</span><span>部分研究人员和行业专家担心，对于大规模语言模型而言，传统扩展方式已接近极限。生成式AI已遇瓶颈。据外媒报道，像OpenAI这样的公司在扩大技术应用时也发现困难重重，其他前沿实验室也面临更严重的挑战。知名数据科学家Yam Peleg透露，一些实验室试图通过延长训练时间和增加数据量来提升模型表现，但结果却遭遇了“收益递减墙”，且情况比公开报道的更为严重。</span></span>
   
  </section>
  <section>
   <span>不过，尽管如此，预训练依然为模型奠定了基础，后续的优化潜力巨大。因此，在后训练阶段（如微调、强化学习、多模态对齐等）依然存在许多优化机会。通过领域特化、任务指令优化、模型压缩等技术，可以提升模型在特定任务上的表现，同时提高其在资源受限环境中的部署效率和安全性。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势七：更多优化算法将被用于强化学习等领域</span>
   </h3>
  <section>
   <span>目前，深度强化学习（DRL）的优化算法在多个行业取得了应用突破。为了解决传统强化学习在高维度问题上训练困难的问题，研究者采用了更加高效的算法，如模仿学习和分层强化学习，显著提升了模型的学习效率和训练速度。比如Google DeepMind 推出的AlphaDev系统由两个核心组成部分构成：学习算法和表示函数。学习算法是在先进的 AlphaZero 算法基础上进行扩展，结合了深度强化学习 (DRL) 和随机搜索优化算法，以执行大规模的指令搜索任务。</span>
   
  </section>
  <section>
   <span>此外，RLHF（强化学习与人类反馈结合）的应用开始更加深入和精细。AI大模型开始通过更精确的人类反馈进行训练，从而能够更好地理解复杂任务，并且在人机交互中表现出更高的自适应能力。例如，OpenAI的ChatGPT通过用户的实时反馈不断优化对话能力，以提供个性化和上下文相关的回答。由于RLHF能显著减少对大规模标注数据的依赖，更多AI系统开始通过少量高质量的人工反馈来进行高效训练，从而降低了模型开发和训练的成本。</span>
   
  </section>
  <section>
   <span><span>还有近期处于话题焦点的DeepSeek，R1模型通过强化学习（RL）和基于人类反馈的强化学习（RLHF）进行训练，并针对核心算法模块做了大量的优化处理：比如改造 Attention 模块，通过低秩压缩，让KV Cache的效率达到最优。以及</span><span>通过训练架构瘦身—例如GRPO算法通过省去传统强化学习中必须的Critic模型</span><span>（即"双引擎"设计），将复杂算法简化为可落地执行的工程方案。一般传统的强化学习模型通常采用这双引擎”设计——Actor和Critic，Actor负责执行决策，Critic评估Actor的决策效果，二者需要同时进行训练，这增加了计算量和训练复杂度。通过去除Critic模型，GRPO算法能够简化模型结构，降低计算资源的消耗。</span></span>
   
  </section>
  <section>
   <span>随着AI应用场景的多样化，简化算法架构将成为AI发展的重要方向。2025年，更多优化算法（如GRPO等）将被用于强化学习等领域，以减少计算资源的消耗，同时提高模型的执行效率和实时响应能力。</span>
   
  </section>
  <section>
   <span>随着硬件资源的不断提升和算法的进一步优化，像GRPO这样的轻量级强化学习算法将被广泛应用于边缘计算和低资源设备上。例如，智能设备、物联网设备和机器人等领域，都会受益于这种简化的算法，实现在硬件条件有限的环境中高效运行。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势八：低成本训练与AI伦理，知识产权成为核心议题</span></h3>
  <section>
   <span>春节期间，DeepSeek的DeepSeek-R1震撼了全球科技圈和资本市场，其基于知识蒸馏技术，成功将大型复杂模型的知识迁移到较小模型，实现高效部署。2月6日，斯坦福大学李飞飞团队和华盛顿大学研究人员以不到50美元云计算费用，成功蒸馏出一个名为s1的新推理模型，表现与OpenAI的o1和DeepSeek的R1相似，展示了蒸馏技术的强大潜力。基于竞争压力，2月7日，OpenAI公开了o3-mini的推理思维链，但该推理思维脸并非原始数据，OpenAI产品官Kevin Weil表示会找到平衡方式以避免被竞争对手蒸馏。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span><span>Kevin Weil的考虑出发点在于，蒸馏通常依赖于将一个较大模型的知识提取出来，并将其迁移到一个更小的模型。如果目标模型能够有效地从源模型中获取有用的知识，且没有太大的性能损失，那么理论上，</span><span>很多模型都可以通过蒸馏技术进行简化和优化。</span><span>因此，</span></span><span>随着AI蒸馏技术的普及，相关的法律和监管框架也需要不断加强，以确保在模型开发和应用过程中不会侵犯知识产权或数据隐私。</span></span>
   
  </section>
  <section>
   <span>这种低成本训练的模式也引发了业界关于AI模型知识产权和伦理问题的讨论。随着越来越多的研究依赖于现有基座模型进行微调，是否应当给予这些基座模型开发者相应的回报成为一个重要议题。同时，如何确保AI技术的公平使用和共享，也亟待业界深入探讨和解决。</span>
  </section>
  <section style="margin: 0px 8px; letter-spacing: 0.578px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#04</strong></span>
  </section>
  <h2 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span><strong>下一个杀手级应用，可能在消费领域</strong></span></h2>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势一：越来越多企业从人工智能上挣到钱</span>
   </h3>
  <section>
   
  </section>
  <section>
   <span>过去的2024年，是生成式AI的落地之年。而2025年，则是这些企业级AI应用在已有的落地场景中深入发展的一年。</span>
   
  </section>
  <section>
   <span><span>美国风险投资机构Menlo Ventures在统计了600家美国企业的IT支出（包括模型支出、训练&amp;部署支出、AI应用支出，不包括芯片、云计算等支出）情况后发现，</span><span>2024年企业的AI相关支出达到了138亿美元，相比2023年的23亿美元增长了超过6倍。</span><span>在这其中，应用支出的增速最快，6亿美元增长到了2024年的46亿美元。</span></span>
   
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_d496c09bf3714d21b76fc03635154e60@000000_oswg68381oswg830oswg408_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   <span>数据来源：Menlo Ventures</span>
  </section>
  <section>
   <span><span>企业AI相关支出的提高，让不同的行业间接获益。</span><span>第一个受益的是咨询公司</span><span>。2024年，埃森哲和IBM等咨询公司正在实现大幅的收入增长，其中，与人工智能相关的服务对其营收增长贡献显著，客户希望通过咨询，了解实施人工智能能够获得的竞争优势。根据埃森哲披露，截至 2024 年 9 月，其生成式人工智能咨询预订额近 30 亿美元。</span></span>
   
  </section>
  <section>
   <span><span>第二个从人工智能中获益的行业是云计算和软件公司</span><span>。软件公司ServiceNow自推出 “Now Assist” 以来，报告了强劲的生成式人工智能预订量，其首席财务官表示，在新产品系列中，最大新增年度合同价值贡献，来自于人工智能的采用。另外，软件巨头甲骨文的基础设施即服务（IaaS）部门实现了强劲增长，这在很大程度上归因于人工智能工作负载的增加。数据中心的领导者Equinix也因为人工智能基础设施需求获得了大量新合同。</span></span>
   
  </section>
  <section>
   <span><span>另外，广告行业也从人工智能使用中获益。</span><span>根据Meta Platforms最近报告，在人工智能的加持下，其广告展示量增长了7% ，每广告的平均价格增长了 11%，季度收入同比增张了19%。</span></span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span>亚马逊集成了基于生成式人工智能的产品图像生成工具，导致某些广告活动的广告展示量显著增加。我们预计，随着人工智能服务需求的扩大，具有独特市场定位、强大分销渠道和特权数据访问权限的云计算、软件应用和基础设施公司将成为主要受益者。随着人工智能市场的成熟，这些科技巨头可能在 2025 年实现加速增长。</span>
   
  </section>
  <section>
   <span>我们尝试总结了生成式AI渗透率最高的几个应用场景：AI代码、AI客服支持和企业级搜索。</span>
   
  </section>
  <section>
   <span><span>●&nbsp;</span><span>最高的是AI代码应用，企业对AI代码应用的采用率达到了51%</span><span>，比如，头部产品 Github Copilot 的ARR（年度经常性收入，是指企业每年从客户那里获得的或期望从客户那里获得的服务或产品回报的收入计算）达到了3亿美金也真实的反应了用户的需求。Cursor、Cognition 等新兴工具在迎来用户快速增长的同时，也获得了资本市场的火热追捧。</span></span>
   
  </section>
  <section>
   <span><span>●&nbsp;</span><span>其次是AI客户支持，其采用率达到了31%，</span><span>产品为内部员工或外部用户提供基于产品知识的客户支持。Sierra、Decagon 等初创借力生成式AI的智能，为用户提供符合品牌调性和消费者画像的定制化客服体验，挑战低效、无趣的传统客服。</span></span>
   
  </section>
  <section>
   <span><span>●&nbsp;</span><span>第三是AI数据检索，其采用率达到了28%</span><span>，这类应用帮助企业解锁和利用分散在各组织中的数据，将数据孤岛中的宝贵知识管理利用。例如一家初创企业Glean，其业务是企业级搜索，旨在为企业打造内部的Google，核心产品 Glean Assistant 的用户每天平均查询 14 次，远超Google的日均查询次数。在过去一年ARR（年经常性收入，Annual Recurring Revenue）达到了5500万美金。</span></span>
   
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_c66544a93531470db40864241d2988e8@000000_oswg68657oswg830oswg408_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   
  </section>
  <section>
   <span>数据来源：Menlo Ventures</span>
   
  </section>
  <section>
   <span>2024年，企业60%的AI应用支出来自企业创新业务的预算，说明企业使用这些应用的态度以尝试和探索为主，生成式AI在企业应用场景中的落地尚处于早期阶段。接下来，随着企业未来各个部门对于生成式AI应用的预算持续增长，哪些生成式AI应用能为企业带来实实在在的回报率，哪些或将分得持续性更长、规模更大的预算，从而支持生成式AI应用生根发芽、斩获1亿美金甚至更多ARR。</span>
   
  </section>
  <h4 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>①AI Agent正在给企业带来效益</span></h4>
  <section>
   <span>2025年，生成式AI应用正在生根、发芽，给企业带来实实在在的现金回报，基于这样的趋势，AI Agent将是这个商业环节闭环的关键。</span>
   
  </section>
  <section>
   <span>AI Agent从学术走向商业落地，仅花了三年时间。</span>
   
  </section>
  <section>
   <span>AI Agent的第一波高潮来自2023年年初，AutoGPT的火爆，所谓AutoGPT，其实是把学术圈很多的Agent idea简单呈现出来，尽管其让开发者感受到大模型的强大，但很快大家便发现，AutoGPT的实验性强于实用性，难以解决大部分的实际问题。第二波高潮来自2023年9月，AgentGen，通过构建不同职能的Agent，分工协作。</span>
   
  </section>
  <section>
   <span>到了2024年，AI Agent开始从实验走向现实。</span>
   
  </section>
  <section>
   <span>2024年末，OpenAI首席执行官Sam Altman提出了AGI（通用人工智能）的五层框架：</span>
   
  </section>
  <section>
   <span>Lv1 - Chatbot，具备基础的对话能力，能够理解和回应简单的文本输入</span>
   
  </section>
  <section>
   <span>Lv2 - Reasoner，具备基本的逻辑推理能力，能够分析复杂信息并进行推断</span>
   
  </section>
  <section>
   <span>Lv3 - Agent，具备理解复杂指令的能力</span>
   
  </section>
  <section>
   <span>Lv4 - Innovator，具备创新和创造的能力</span>
   
  </section>
  <section>
   <span>Lv5 - Organizer，具备协调和管理庞大系统、资源和团队的能力</span>
   
  </section>
  <section>
   <span>他提出，如今我们正处于第二个阶段并非常接近第三个阶段的状态。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>Lv3的Agent智能体能够自主与环境交互、收集信息，具备持续规划并执行多步骤、长时间任务的能力。要达成这个阶段，需要一个推理能力、逻辑能力更强的模型（可能是o1的下一个版本、也可能是对标o1的开源模型）。同时，服务</span><span>AI Agent应用的基础设施也必不可少。</span></span>
   
  </section>
  <section>
   <span>当下，企业出于安全性、准确性、稳定性等因素的考量，更倾向于使用 AI Copilot （人在回路中参与）增加人在工作流中的效率，而不是直接采用端到端自动化 AI Agent。随着底层模型能力和Agent框架开发的持续升级，Agent应用将为企业提供更智能高效的数字员工。人与AI的协作关系将从AI赋能人工作，逐渐转变到人监督指导AI完成工作，最终达到AI自主完成工作。这个转变会在未来几年迅速发生。</span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>至于适合</span><span>AI Agent最先产生价</span><span>值的应用场景，2025年大概将延续现阶段生成式AI渗透率高的场景，例如代码编程、客服、销售、营销等。</span></span>
   
  </section>
  <section>
   <span><span>根据第三方机构Menlo Ventures的调查数据显示，</span><span>企业内各部门的生成式AI预算划分中，IT部分独占鳌头（22%）、产品和工程开发次之（19%），客服（9%）、销售（8%）和营销（7%）紧随其后。</span></span>
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_0298b483075647d294dac3d0835cc841@000000_oswg153382oswg830oswg410_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   
  </section>
  <section>
   <span>数据来源：Menlo Ventures, UpHonest Capital</span>
   
  </section>
  <section>
   <span>根据硅兔赛跑的观察，一些企业的确正在从这几个场景中赚钱：</span>
   
  </section>
  <section>
   <span>IT部门选择之一的初创公司Glean，在2024年9月份完成新一轮融资，估值达到46亿美元，其旨在优化企业内部数据检索和问题答复。</span>
   
  </section>
  <section>
   <span><span>在产品和工程开发部门依赖的AI编程应用中，初创公司Cognition在2024年3月推出了</span><span>首个AI程序员</span><span>Devin，成立仅6个月就达到了20亿美金估值。同年12月其Agent产品Devin正式上线，区别于普通的代码补全应用，Devin能够无需人类参与进行自主编码，完成需要人类工程师参与的项目开发。目前 Devin拥有诸多头部客户：例如Ramp 使用Devin 编写测试代码并清理死亡代码，MongoDB使用 Devin 更新过时的代码架构。</span></span>
   
  </section>
  <section>
   <span><span>硅谷投资机构UpHonest Capital早期投资的Cosine，正在打造全自动的</span><span>AI软件开发助理</span><span>Genie，曾在SWE-Bench测试中获得全球最高分数。Cosine 研发了独有的数据管道，能够生成具有人类工程师开发逻辑、增量知识、支持搜索的高质量数据集。同时，Cosine是OpenAI最大的模型微调合作伙伴，拥有其前沿模型的早期使用权限。结合数据和模型优势，Cosine已经与多家世界500强公司和明星初创公司达成合作。</span></span>
   
  </section>
  <section>
   <span><span>客服作为人力密集型工作，也将成为AI Agent最先颠覆的环节。</span><span>比如UpHonest Capital早期投资的Proactive AI 正在为零售品牌打造具有高情感智能语言能力的客服助理，主要帮助企业向其用户提供契合品牌调性和个性化需求的客服服务，目前已与餐饮、健身、沙龙等行业多家头部企业达成深度合作。</span></span>
   
  </section>
  <section>
   <span>销售和营销作为企业开源的重要入口，企业利用最新技术提高获客效率的意愿也非常高。美国的人工智能初创公司11x，打造AI驱动的“数字工作者”以取代传统的销售团队，其Agent能够自主执行GTM工作流程。11x不通过软件帮助企业降本增效，而是直接提供实在的工作成果，数字员工能够自主实现完成的收入闭环。11x成立6个月就达到了200万美金的ARR，目前ARR已经达到了1,000万美金。FlashIntel正在打造AI驱动的GTM平台并向企业提供AI驱动的销售助理（SDR）。FlashIntel在G2 2024冬季报告中总计获得了189枚徽章，其中FlashRev被评为最佳销售产品，最佳营销和数字广告产品，以及最高满意度产品。</span>
   
  </section>
  <h4 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>② 在数字化渗透率低的传统行业有隐藏的“金矿”</span></h4>
  <section>
   <span>曾经，传统行业的玩家对AI嗤之以鼻，过高的投入成本和微不足道的效果，让他们难以对AI押注过多。</span>
   
  </section>
  <section>
   <span>不过这一次，传统行业的生成式AI之路，有可能跳过软件阶段，直接进入AI阶段，类似新兴市场从使用现金直接转向移动支付。</span>
   
  </section>
  <section>
   <span>这些行业本身对于科技的采用速度较慢，生成式AI的出现带来了直接交付结果而非交付软件的模式，减少了前期投入成本、肉眼可见的提升了投资回报率，使得恐惧新技术的决策者更容易被说服。比如医疗领域的病例记录、法律领域的案件报告生成、金融行业的合规风险筛查等等。</span>
   
  </section>
  <section>
   <span>2024年12月，美国家政垂直软件巨头ServiceTitan上市，上市当天股价涨幅超过40%，在2024年上市公司中，该涨幅仅次于社交平台Reddit和芯片公司Astera Labs两家。</span>
   
  </section>
  <section>
   <span>要知道，ServiceTitan 2012年成立，历经12年发展，在仅拿下家政行业1%市场份额的情况下，其市值一度达到90亿美元。由此可见，美国垂直行业，数字化渗透速率之低，垂直行业AI化的价值之高。ServiceTitan之成功，自然使我们关注到美国传统行业的机会，数字化渗透率低的传统行业。</span>
   
  </section>
  <section>
   <span>美国初创公司Sameday为美国家庭服务行业（除虫、HVAC、家庭维修等）提供AI销售代理，通过自动化的语音客服接听来电并安排服务预约，提高电话接听率，从而提高转换率，现在已经与ServiceTitan集成。Sameday的创始人曾在美国增长最快的家庭服务行头部公司担任CMO，拥有极深的行业认知和丰富的行业资源。2024年，Sameday的ARR预计将增长5倍以上，月度客户留存率达98.5%。</span>
   
  </section>
  <section>
   <span>建筑行业的AI解决方案提供商Pantheon，能够生成高精度且可编辑的 3D 建筑模型，通过AI实现更快的设计迭代周期可以显著降低项目成本。Pantheon AI不向建筑师出售软件许可证，而是直接向房地产开发商和业主出售其设计服务。2024年10月，Pantheon AI完成了由a16z领投的2500万美金种子轮融资。</span>
   
  </section>
  <section>
   <span>传统行业以外，法律、金融、医疗行业积累了大量数据，为行业垂直基石模型训练提供了丰富的燃料，且法律、金融、医疗行业价值高，但普遍在传统软件巨头的垄断下变化缓慢。即便垂直SaaS一定程度上取代了过时繁琐的老系统，但总体的渗透率依然有限。以医疗行业为例，其行业规模高达4.3万亿美元，贡献了约1/5的美国GDP。但在美国市值前100的上市软件公司中，只有一家是服务医疗行业的软件公司。</span>
   
  </section>
  <section>
   <span>2024年，Evenup ARR预计将达到5000万美金，最新一轮的投后估值达到了10亿美金。Evenup 利用生成式AI帮助律师进行人身损害赔偿（Personal Injury Claims）案件的索赔工作。虽然目前只服务于人身损害赔偿这一个领域，但这已经是一个非常大的市场了。美国每年约有30万参与处理人身损害赔偿的律师，每年支付给受害者的索赔金额高达1000亿美金。</span>
   
  </section>
  <section>
   <span>有备而来者，率先享受红利，那些垂直行业专家、对行业的工作流有深入认知的创业者，结合不断进化的生成式AI基础设施，有机会迅速抢占用户，构建自身的行业数据壁垒。</span>
   
  </section>
  <h4 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>③ AI不再按席位收费 ：“Sell work, not software”</span>
   </h4>
  <section>
   <span>Menlo Ventures的调查数据显示，企业在进行生成式AI产品采购决策时，第一考虑要素是产品是否具有简单可测量的投资回报率，其次是产品是否根据实际应用场景定制。</span>
   
  </section>
  <section>
   <span>值得注意的是，现阶段，产品价格反而是最不重要的影响因素，仅1%的企业决策者声称产品价格影响采购决策。</span>
   
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_b37daaaf85754501a2ed893879320432@000000_oswg67372oswg830oswg408_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   
  </section>
  <section>
   <span>数据来源：Menlo Ventures</span>
   
  </section>
  <section>
   <span>结果正在变得更为重要。随着AI的独立工作能力提升，其工作结果、创造的价值会更容易被量化，企业对AI产品的价值评估，也会根据其工作成果界定，美国投资机构a16z提出。因此，商业模式变得更加重要。</span>
   
  </section>
  <section>
   <span>SaaS时代，SaaS公司创新了按席位收费的商业模式，即按照使用SaaS产品的员工账号数量按月或按年收取订阅费用，这种定价方式背后的逻辑是，使用SaaS产品的每位员工，效率会有不同程度的提升、处理更多工作，许多SaaS定价的策略在于评估使用者效率提升创造的收益。</span>
   
  </section>
  <section>
   <span>但到了生成式AI时代，这个SaaS时代一直以来赖以生存的逻辑正在被颠覆。随着Copilot产品向Agent产品的升级，未来的Agentic AI系统将在不同AI agents的相互配合下，自动完成任务，取代越来越多的工作者，显然，如果继续按照席位收费，开发者的收入则会逐渐减少。</span>
   
  </section>
  <section>
   <span>Benchmark合伙人最先建议生成式AI公司“Sell work, not software”，即按照工作成果收费，打破按席位收费的模式。</span>
   
  </section>
  <section>
   <span>基于此，目前原生AI公司普遍采取的商业模式分为两类，一类是基于用量的定价模式，Salesforce发布的Agent force智能体系统，提供客服、销售、员工服务等AI agent智能体，按照用户与agent实际交互的用量收费，每次”对话“收费2美元，如果发生以下三种情况之一，即视为一次”对话“结束—— AI agent无法满足用户需求，需要人工介入；用户主动结束与AI agent对话；用户超过24小时没有再主动与AI agent对话。</span>
   
  </section>
  <section>
   <span>另一类是基于工作结果的定价模式，前Salesforce联席CEO Bret Taylor创立的AI客服公司Sierra，为客户提供基于工作结果收费的客服AI agent，从消费者满意度、问题解决程度、以及每次的交互成本三方面来评估工作结果，决定企业付费规模。采用按照工作结果定价的模式，实现了AI agent企业客户与开发公司的利益一致性，双方将共同得益于agent独立任务完成能力的提升。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势二：等待一个“杀手级”AI消费级应用</span></h3>
  <section>
   <span><span>“2025年（AI应用）下一个大事件属于消费。”</span><span>美国红杉资本合伙人Jess Lee表示，AI聊天、图片、视频已验证了其消费市场潜力，接下来将看到全新的AI消费社交APP、新形式的互动媒体、基于聊天的游戏、新的搜索和信息整合工具、基于互动式UI的聊天工具等。”</span></span>
   
  </section>
  <section>
   <span><span>消费赛道，一直是历次技术创新浪潮下创业者和投资人高度关注的方向，</span><span>如果回顾之前的技术周期会发现，全球市值Top15的科技公司中，有9家是从To C消费产品起家的。</span><span>To C的公司上市时，估值超过100亿美元的比例，比To B公司高10%左右。</span></span>
   
  </section>
  <section>
   <span>但在这一波生成式AI创业浪潮中，消费AI应用似乎在被创业者和资本遗忘。2024年，90%以上的A轮融资流向AI企业应用。</span>
   
  </section>
  <section>
   <span>不过，自2024年下半年以来，这个现象正在发生改变。</span>
   
  </section>
  <section>
   <span>2024下半年以来，资本市场对消费级AI应用的关注度上升，以硅谷孵化器Y Combinator 为例，其下半年孵化的消费级AI产品数量比上半年翻番。</span>
   
  </section>
  <section style="text-align: center; margin: 0px 8px; line-height: 1.75em;">
   <img class="rich_pages wxw-img" src="https://img.36krcdn.com/hsossms/20250208/v2_cd0bc63e121048e48457a7445a3060a3@000000_oswg91603oswg692oswg460_img_000?x-oss-process=image/format,jpg/interlace,1" />
  </section>
  <section>
   
  </section>
  <section>
   <span>数据来源：Y Combinator, UpHonest Capital整理</span>
   
  </section>
  <section>
   <span><span>2025年，消费级AI应用的“土地”正在被开垦，行业在等待一个“杀手级”AI消费的应用。风险投资机构也对消费级AI应用的机会产生共识。YC Partner Michael Seibel表示，</span><span>目前太多创始人寻找B2B的AI机会，太少人探索消费侧的机会，消费创业者的机会来了</span><span>；a16z提出“生成式AI或将重塑从旅游、心理治疗到网购等一切（消费行为）。“前Index Ventures合伙人Rex Woodbury，称现在是“消费复兴”的机会。</span></span>
   
  </section>
  <section>
   <span><span>生成式AI对消费端改变，体现在三个层面：</span><span>首先，AI会逐渐改变人与人、人与信息交互的方式，形成新的流量入口；其次，AI搜索正在改变信息的分发方式，会创造新的商业机会；第三，AI释放PGC、UGC内容创作潜力，使内容消费更加丰富多元。</span></span>
   
  </section>
  <section>
   <span>以AI搜索为例，作为线上流量的第一入口，已经久无战事，生成式AI引入了新变量。2020年创立的生成式AI搜索初创You.com，近期完成5000万美元融资，价值7亿美元了。OpenAI在7月发布AI搜索工具SearchGPT，其付费用户均可使用。</span>
   
  </section>
  <section>
   <span>Perplexity是一家成立于2022年8月的美国AI创业公司，公司由前OpenAI研究科学家Aravind Srinivas和前Meta研究科学家Denis Yarats等联合创立，专注于开发基于人工智能的对话式搜索引擎，旨在通过大型语言模型（如GPT-4和LLama2）为用户提供精准的搜索结果。Perplexity的界面更像是聊天屏幕，用户可以通过自然语言提问，Perplexity会提供直接的答案，并附上详细的引用来源，Perplexity 的用户增长非常迅速。2023年2月，Perplexity的月访问量达到1000万，独立访客达到200万人。截至2024年4月，Perplexity 的月活跃用户数便突破了1500万。Perplexity在短时间内完成了多轮融资。截至2024年11月，Perplexity在新一轮融资中筹集了5亿美元，使公司估值达到90亿美元。投资方包括软银、亚马逊创始人贝索斯和英伟达等多家知名企业和AI领域知名人士。</span>
   
  </section>
  <section>
   <span>除了通用搜索引擎，生成式AI使垂直领域的搜索引擎更普遍，瓜分通用搜索引擎的注意力。例如，垂直于企业知识数据库的搜索——Glean在9月份完成新一轮融资，估值达到46亿美元，旨在优化企业内部数据检索和问题答复，在近两年中ARR翻倍增长；亚马逊、沃尔玛都在加强电商搜索引擎建设，今年先发搜索助手，再发Agent。初创企业DayDream种子轮拿到了5000万美元投资，Forerunner、Index联合领投。DayDream链接了超过2000+品牌，支持自然语言检索，根据用户提供的时间、地点、场合等信息给予相关产品推荐。Encore，YC24新一期孵化项目，是一个LLM驱动的针对二手商品购物的搜索引擎，链接美国多个二手商品网站，支持自然语言搜索以及按照主题的搜索；垂直于科研场景的搜索：初创企业Consensus与Perplexity有共同的投资人Nat Friedman和Daniel Gross，专注打造服务科研的搜索引擎，改变人们获取和使用学术文献的方式。2024年收入增长了600%，月活40万用户，ARR近200万美元。</span>
   
  </section>
  <section>
   <span>也许明年会出现更多令人眼前一亮的垂直领域的AI搜索创新。</span>
   
  </section>
  <section>
   <span>这一点，美国红杉在2025年的AI趋势预测中也分享了一些思考，红杉提出AI搜索或将成为2025年的”杀手级“应用，他们提出了两点预测：目前一个整体的搜索市场可能会碎片化，未来每个人可能会有专业AI搜索引擎——例如，Perplexity可能会成为投资人和分析师的第一搜索工具选择，律师选择Harvey，医生选择OpenEvidence……全新的生成式AI搜索引擎将紧密契合目标用户的“心智模式”，投资人、律师、医生的思维模式各不相同，信息获取模式、目的和决策思维各有差异，这些不同和差异就是生成式AI搜索引擎创新的机会；消费级和企业级应用场景分化，每位知识工作者每天至少会使用两款AI搜索引擎 —— 一款用于工作，另一款用于其他所有事务。</span>
   
  </section>
  <section>
   <span>除了AI搜索，落到电商、音乐、社交、游戏、旅行和教育等直接To C的领域中，也各有生成式AI原生应用的创新机会。</span>
   
  </section>
  <section>
   <span>以旅行为例，Wanderboat是面向消费者的AI旅行规划工具，也是旅游内容分享社区。它构建了一个chatbot，可以根据用户需求推荐、定制目的地及各类娱乐体验活动，还可以主动学习用户的兴趣，定制专属行程。基于创始人此前在微软的经验，构建了一些很有趣的小工具，比如用户在查看地图时也可以与AI互动，实时获取一些信息和建议。在零付费推广的情况下，月活用户数量达到了6位数。</span>
   
  </section>
  <section>
   <span><span>一是多模态AI营销，从文字延展到音频、视频。形式从单点的chatbot延展到具有操作执行能力的agent，并且准确率和对于边缘案例的覆盖力随着基石模型推理能力的提升增强。此外，</span><span>如果生成式AI运用得当，销售、营销、客服对消费者的洞察进一步提高，可以创造更加个性化的服务、定制化体验。</span></span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>GigaML是YC孵化的一家AI客服初创，虽然这个方向竞争激励，但实际GenAI应用的渗透率还比较低，因为客服在实际工作中有许多边缘案例，现在大部分的GenAI应用解决边缘案例的表现一般，原有的自动化客服足以解决基础问题，所以企业升级的动力不足。GigaML发现将基石模型切换至o1-preview，加上大量的评估、调优之后，错误率大幅下降，从70%降至5%，并能够解决8成的边缘案例。</span><span>在OpenAI最新推理模型加持下，</span><span>客服用例值得期待。</span></span>
   
  </section>
  <section>
   <span>Para和HeyGen分别是声音和视频营销的典型案例，Para利用AI生成个性化定制的声音营销电话，帮助品牌激活用户，帮助球队活跃粉丝；HeyGen的AI视频营销收入快速增长，据悉今年的年化ARR超过2000万美元，估值已达到5亿美元。</span>
   
  </section>
  <section>
   <span>AdsGency则是一个利用AI用户数据洞察，实现精准广告营销的公司，创始人此前曾在滴滴、亚马逊从事广告、营销相关的产品工作。它的业务核心是广告和用户数据，为客户提供了一个全栈AI营销工具，覆盖内容创意、创作、投放、归因等流程。AdsGency也代表了现在AI营销的一个发展趋势—— 从Point Solution，到整个GTM的全流程自动化解决方案。</span>
   
  </section>
  <h3 style="text-align: justify; margin: 0px 8px; line-height: 1.75em;"><span>趋势三：企业应用大模型朝模块化方向发展</span>
   </h3>
  <section>
   <span><span>2024年，人工智能领域的一个显著趋势是模型的</span><span>可组合性和模块化发展，</span><span>这种模块化实现了从概念到规模化地落地。企业不再仅依赖于单一的“大模型”解决方案，而是可以根据具体需求，将不同的模块进行组合，定制出符合自己业务需求的能力。这种灵活性不仅能够提升效率，还能降低成本，并且更好地满足各行业对AI应用的多样化需求。</span></span>
   
  </section>
  <section>
   <span>在技术架构层面，传统“大一统”的大模型被逐步拆解为功能与场景模块，例如Amazon Bedrock提供了一系列生成AI的模块化服务，涵盖文本生成、图像生成、语音合成等功能，这些模块化的服务可以帮助企业根据自己的需求进行定制，支持跨行业的AI应用，如生成个性化的营销文案、产品推荐和自动化客服对话等服务。微软推出了更加精细化的模块化API，支持更加多样化的场景，例如多语言客服、智能会议助手和自动化客户反馈系统。Transformer论文八位作者之一Aidan Gomez也瞄准这一方向，估值55亿美元的Cohere提供专为企业用例优化的系列AI模型，在语言生成、多语言处理、多模态、语义检索等方面各有所长，企业按需选择、组合。</span>
   
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>2025年，模块化和抽象化设计将在多个领域得到广泛应用</span><span>，特别是在人工智能和机器学习领域。这种设计方式将推动AI系统的高效演化和自适应能力，为AI技术的广泛应用提供更强大的支持。根据Gartner预测，到2028年，至少15%的日常工作决策将通过代理AI自主做出。</span></span>
   
  </section>
  <section>
   
  </section>
  <section>
   <span><span>这种趋势表明，</span><span>模块化和抽象化设计将为AI系统的自主决策提供更强大的支持，推动AI技术的广泛应用</span><span>。并且，更多的技术企业将推出专为行业需求定制的AI模块。例如，针对智能制造、智慧医疗、自动驾驶等领域的具体需求，可能会出现更加精细化的模块组合，企业可根据自己的数据和业务需求灵活选择。而且随着硬件能力的提升，这些模块可能会更加高效，甚至实现更高的跨领域协同能力。总之，这种模块化大模型的发展将向纵深推进，技术、商业与社会的多重博弈将重塑行业格局。</span></span>
   
  </section>
  <section style="margin: 0px 8px; letter-spacing: 0.578px; line-height: 1.75em;">
   <span><strong style="color: rgb(251, 194, 1); font-size: 45px; letter-spacing: 0.578px;">#05</strong></span>
  </section>
  <h2 style="text-align: justify; text-indent: 0em; margin: 0px 8px; line-height: 1.75em;"><span><strong>总结</strong></span></h2>
  <p><span style="letter-spacing: 1px;"><span>这场科技商业史上最大“赌局”，让身处其中的投资者越来越感受到了曾经硅谷早期的投资氛围——押注一个未知的全新技术、等待一个超长回报周期，而不是基于互联网成熟技术的模式创新上迅速迭代和回血。</span></span></p>
  <p><span style="font-size: 12pt; letter-spacing: 1px;"><span>自从ChatGPT发布之后，硅谷正在吸引全球的目光。关注硅谷发生的故事，正在成为众多的中国投资者甚至中国企业员工、公关必做的事，大家试图从这些持续关注中获得最前沿的信息和生成式AI最前线所发生的故事，从而试图判断新的商业方向。</span><span>
     </span></span><span style="font-size: 12pt;"></span></p>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>谁也不知道这场生成式AI的变革会将商业引向何方，也同样预测不到新技术的迭代如此之快。</span><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>在过去的几年里，听到最多的便是企业对生成式AI的抱怨“我们知道它重要，但我们仍然不知道如何用在自己的场景中”，这种抱怨带着一些敬畏——“不上大模型一定会被淘汰”。投资者在不断推高的估值和融资中，快要丧失信心。动辄几十亿美金的融资，再加上Scaling Law之下，不断增加的数据中心的投资，让他们望而却步。这也表明，2025年将是生成式AI让人们看到赚钱希望的一年，投资者和创业者同样需要信心。</span><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>AI Agent元年，这个发端于学术界的概念将会落到实际，并产生价值，企业将会使得生成式AI变得更加好用，并切实转化为价值。与此同时，消费级的AI应用将会让人们切实感受到生成式AI带来的生活的变化。</span><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>垂直领域的模型正在成为通用大模型的补充，让更多企业释放AI的价值。垂直行业中，将会出现越来越多的AI搜索应用，满足人们不同领域的需求。</span><span>
     </span></span>
  </section>
  <section>
   <span style="letter-spacing: 1px;"><span>
     </span></span>
  </section>
  <p><span style="letter-spacing: 1px;"><span>2025年，从生成式AI来说，一些泡沫会破灭，一些企业能够从中赚到钱。技术新陈代谢快速而残酷，这场竞争中没有老手，都是新人，昔日的领军者亦有可能跌落神坛，最先关注到技术和商业的变化，并做出行动的企业，才能在这场竞争中生存下来。</span><span>
     </span></span></p>
  <section>
   <span style="color: #262626; font-family: PingFangSC-Regular; letter-spacing: 0px;">本文来自微信公众号</span>
   <a href="https://mp.weixin.qq.com/s?__biz=MzI4MDUzMTc3Mg==&amp;mid=2247623079&amp;idx=1&amp;sn=3c063bb521adb3a3305617de1339a9c1&amp;chksm=ea3745bccd4b5cd43bbc5585422b33c510fff84df72856b463d98010ad598db9fbc0764d584c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" style="font-family: PingFangSC-Regular; letter-spacing: 0px; color: rgb(38, 38, 38); border-style: solid; border-color: rgb(153, 153, 153); border-image: none; border-width: 0px 0px 1px; padding: 0px 0px 1px;">“硅兔赛跑”（ID：sv_race）</a>
   <span style="color: #262626; font-family: PingFangSC-Regular; letter-spacing: 0px;">，作者：王子、顾程来等，36氪经授权发布。</span>
  </section>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156448125311748</id>
            <title>DeepSeek破圈，AI商业化临界点是如何被打开的？</title>
            <link>https://www.36kr.com/p/3156448125311748</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156448125311748</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:57:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <DeepSeek, AI商业化, 技术民主化, 硅谷>
<br>
<br>
总结: DeepSeek在春节期间引发了广泛关注，成为AI商业化的重要突破口。自ChatGPT掀起大模型浪潮以来，尽管许多模型相继推出，但真正的商业化落地仍面临挑战。DeepSeek通过高质量的技术讨论和跨领域的广泛应用，成功打破了技术壁垒，推动了AI的技术民主化进程。其开源模型的发布吸引了大量专业博主的深入讨论，进一步提升了公众对DeepSeek的关注和使用。通过与用户的高频互动，DeepSeek不仅实现了用户规模的激增，也为AI商业化的成功奠定了基础。 </div>
                        <hr>
                    
                    <p>DeepSeek在这个春节假期卷翻了硅谷，我们注意到，对于模型和应用的讨论很多，但鲜有人追问：DeepSeek的现象级爆火，为AI商业化撕开了怎样的突破口？</p>
  <p>要知道，自从ChatGPT在2023年初掀起大模型浪潮，此后全球各色模型轮番登场、百舸争流，但AI大模型的商业化落地，始终与技术突破存在一定的时差。有的大模型在发布会之后就乏人问津，也有模厂黯然退出了预训练。</p>
  <p>DeepSeek不仅让全球看到了国产AI的技术能力，而且发现，技术破圈之后的商业化生命力也格外澎湃，服务器的繁忙、云厂商/行业伙伴的积极接入，都让人们对深度求索这家科创企业的商业未来格外期待。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9bfc39e4a9654706a8e0bb8f4cc687e3@000000_oswg192297oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而回顾DeepSeek的破圈之路，我们发现一个独特地方，那就是关于DeepSeek的技术讨论，在质量、广度、深度上有碾压式的突破，由此带来了大众广泛使用的技术民主化进程，为DeepSeek的破圈铺平了道路，也为AI商业化开辟了出路。</p>
  <p>我们今天就来聊聊，DeepSeek破圈背后的助推力，以及给AI商业化带来哪些启发。</p>
  <h2><strong>01 出圈锚点：高质量信源，穿过信息迷雾</strong></h2>
  <p>无论是ChatGPT的大语言模型，还是DeepSeek-R1为代表的推理模型，都有着较高的认知门槛。普通人想要了解和触碰这些大厂实验室里的高岭之花，必须走过“拳打硅谷、脚踢华尔街”的标题党，穿过AIGC胡编乱造的信息迷雾，找到那些真实、理性、客观的信源，作为进入技术世界的锚点。</p>
  <p>简单梳理一下DeepSeek的出圈过程，会发现有大量专业博主，成为技术传播的锚点。</p>
  <p><strong>首先，长期关注AI的技术博主，提前技术跟踪、研判与预热，不断消除着大众对技术的认知误差。</strong></p>
  <p>早在2024年中，不少技术从业者已经开始在社交平台，交流讨论DeepSeek V2模型的潜力，这家低调的AI初创公司初现峥嵘。</p>
  <p>2024年12月，DeepSeek新模型V3版本流出，科技博主@阑夕 就曾发起话题，聊起了中国AI卷到硅谷，也提到了春晚刷屏的宇树机器人。早在大众惊叹DeepSeek之前，这些身处行业中心的从业者早已感知到了产业风向的变化。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8a34bbdcfc6844fe866eb78398b4f09f@000000_oswg273329oswg1080oswg412_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>最关键的节点，是2025年1月，DeepSeek-V3和R1开源。</strong>这是AI业内的大事件，但开源跟大众乃至社会有什么关系呢？一大批技术博主，在开放讨论平台，挥舞起了理性分析的思想手术刀。</p>
  <p>包括@梁斌penny、@海辛Hyacinth、@伯克利_尤洋、@高飞 等，都对技术论文、模型架构、创新性等展开深度讨论，将晦涩难懂的技术/论文进行了细致拆解，大众和媒体开始关注到此次国产AI创新的独特之处，密集讨论DeepSeek。此后，DeepSeek热搜推陈出新，热度持续上升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ed402ac0345b419698a5d315342e5ba7@000000_oswg216566oswg1080oswg411_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这些专业博主，是了解AI的高质量信源，也是绝大多数普通人触碰AI的第一个锚点。他们的高质量讨论与思考，成为DeepSeek破圈的头号助力和原点。</p>
  <h2><strong>02 领域破壁：用跨界讨论的广度，打开认知边界</strong></h2>
  <p>DeepSeek之前，也有不少国产模型可以媲美海外产品，但受限于科技企业“重研发、轻营销”的思维惯性，营销手段主要是在模型发布时发一下PR通稿、在技术社区上传一下技术文档、榜单跑分等，讨论度不高、热度难持续。</p>
  <p><strong>反观DeepSeek的出圈，除了模型本身的性能先进之外，与大规模的跨领域碰撞，是分不开的。</strong></p>
  <p>如果说技术博主挥舞的是思想手术刀，那么更广泛的普通博主/大V/KOL等则手握着“DeepSeek+领域”的破壁机，拓展了AI应用落地的边界。</p>
  <p>有人打开了DeepSeek的讨论广度。技术论文解读是最基础的，在此之外，很快涌现出了多种角度的解读。</p>
  <p>比如很多网友看到了DeepSeek-R1的神奇，但自己从没用过推理模型，担心不好上手，科技博主@数字生命卡兹克 在除夕当天发布了《DeepSeek的提示词技巧，就是没有技巧》，打消了普通人的使用顾虑，在春节长假期间给DeepSeek上了一波热度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d804a639fd844bf691cb2e3890447275@000000_oswg346468oswg1080oswg711_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当大众好奇为什么DeepSeek这一次能震撼硅谷时，资深技术专家阮一峰@ruanyf 分享的DeepSeek创始人梁文峰谈开源，是网上关于“开源力量颠覆AI产业格局”较早的讨论之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0d1d76ac712748838a3bc7ad7218b321@000000_oswg97447oswg585oswg235_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>@海辛Hyacinth 则从团队管理的角度，认为DeepSeek 的年轻化团队意味着AI时代论资排辈会越来越少……</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b8dd6542b4f240588cb62bcf5465336a@000000_oswg46076oswg756oswg352_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这些多元化角度的讨论充分打开，延续了DeepSeek的热度。</p>
  <p>上述讨论，进一步激发了多个行业领域博主开始关注DeepSeek，讨论DeepSeek，延伸出了DeepSeek与场景的多种结合方式。</p>
  <p>比如编剧@汪海林，探讨基于推理模型的AIGC，给剧本创作带来的颠覆；博主@零重力瓦力，用“AI解题像学霸写作业”类比大模型思维链，让推理模型不再是悬浮的概念，成了人人可上手的工具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_13ec665e136e42b5abe465ea1095840e@000000_oswg143797oswg1080oswg345_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一个个行业领域的跨界碰撞，让DeepSeek的创意应用喷薄而出，成为DeepSeek出圈的新一轮推动力，带动了更多领域用户的参与讨论，打开了AI商业化的边界。</p>
  <h2><strong>03 技术生命力：以高频率互动，深耕商业化沃土</strong></h2>
  <p>爆火之后，流量倏忽而来、倏忽而去的事并不少见。AI商业化的终极考验，在于将现象级事件转化为可持续的商业动能。这可能吗？</p>
  <p>近年来，智能终端、新能源汽车、国产3A游戏等，都是创造了巨大商业价值的国产科技突破。<strong>从中，我们可以发现科技产品的生命力从何而来：</strong></p>
  <p><strong>一是靠人，依托个人IP化、网红化持续引流。</strong>以小米汽车为例，雷军亲自挂帅，在个人微博等社交媒体，事无巨细分享，与网友高频互动，带动了巨量关注。也吸引了车企、科技企业创始人纷纷从幕后走到台前，将技术产品变成大众谈资。</p>
  <p><strong>二是靠产品</strong>，以竞争激烈的手机市场为例，近年来手机厂商营销上更接地气，主打一个听劝，“用户要什么就给什么”，让手机创新不再是产品经理的闭门造车，而是定制话题，与用户展开共创，vivo、OPPO都借助社交平台来优化产品，实现了增长。</p>
  <p><strong>三是靠口碑</strong>，DeepSeek的爆火也让人注意到了《黑神话：悟空》背后的游戏科学、宇树机器人等科创企业，它们的产品都是从发烧友推崇的小众产品，<strong>通过社交媒体的口碑传播，迅速蔓延到大众视野，在全球为中国科技赢得了声誉。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f1ed250dd1db45c4b6e7424671497b5d@000000_oswg144598oswg1080oswg763_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不难发现，在长周期、重投入的科技领域，爆红是偶然，长红靠深耕。汽车企业、手机厂商都将内容社交平台，作为品牌重地，通过与潜在用户保持长期、高频率的互动，将社交流量池转化为商业沃土。</p>
  <p>AI行业，当然也不能例外。</p>
  <p><strong>DeepSeek的爆火出圈，正在于打破了海外AI的使用封锁，让全民都能用上先进推理模型，将AI变成全民都在聊、都在用的工具，热搜话题多达200多个。</strong></p>
  <p>春节期间，我们看到了大量普通人与DeepSeek的互动，美妆博主用DeepSeek定制护肤方案；父母在亲子交流中用DeepSeek生成“高情商回复”；冲浪乐子人用DeepSeek“锐评”各类新闻事件……各种意想不到的玩法，都成为AI技术与现实的碰撞时刻。在200+热搜话题中，DeepSeek裂变成了一场全民参与的AI应用实验。</p>
  <p>在这场全民讨论和使用的热潮中，DeepSeek通过口碑传播，不断拉新，用户规模激增。在此基础上，可以获取大量真实互动的数据，可以优化模型产品的使用效果，进一步拉开与其他模型的差距。</p>
  <p>与竞价砸钱买量的传统营销方式不同，DeepSeek的出圈路径，是热搜话题设置讨论议题——技术/行业头部博主打开讨论角度——大量用户参与众测的组合式传播。一步步引导真实用户加入讨论、互动和反馈。</p>
  <p>饱和式的全民参与，让DeepSeek的增长飞轮开始转动，成为DeepSeek出圈的最大一股推动力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ad40fa90f7d74c7893599cf0a7a6f354@000000_oswg58988oswg1080oswg483_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这也提醒我们，让AI走向大众的技术民主化，是商业化成功的前提。</p>
  <p><strong>从技术特性来看</strong>，AI不同于传统的互联网应用和科技产品，后者推出时就是完整形态，而很多AI模型和产品需要先推出再找PMF，在跟用户的迭代互动中不断成长、成熟起来。所以，AI产品必须重视全民参与，至少要有目标用户群的重度参与。</p>
  <p><strong>从市场竞争来看</strong>，AI产品处于排位剧烈动荡的拉新周期，基础模型又需要规模效应，所以竞争白热化，没有声量相当于“等死”，AI企业必须不断制造大众对技术的关注与讨论。OpenAI去年底为期12天的技术发布，就通过话题设置，吸引了全球关注。</p>
  <p>此前，AI领域的技术交流，大多集中在开发者扎堆的极客技术社区，或者AI大厂的开发者社区，与企业客户的闭门交流，缺乏与C端消费者在社交平台互动的经验。</p>
  <p><strong>但是，以大模型为基础的AI应用，开始逐渐转变营销思路。</strong>以豆包、文小言、kimi等为代表的这一批大模型应用，都越来越强调C端传播，用户数成为产品生命力的重要指标。DeepSeek的出圈，则一举打破了海外推理模型的使用封锁线，让先进AI技术可以为大众所见、所聊、所用。这是技术民主化的最佳例证，也是AI实现商业成功的必经之路。</p>
  <p>面对DeepSeek掀起的AI民主化浪潮，全球AI企业或许都面临一个关键选择：是被DeepSeek热潮悄无声息地淹没，还是加速拥抱亿万普通人。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzUxNTUyMjE4Mw==&amp;mid=2247526123&amp;idx=1&amp;sn=ceaa57356d2b4356e55bf618f40f56fa&amp;chksm=f87d83192dbd9eca16e8131ac0c0105b04905c741274c0b3093daa4de1ac9a57063ba18e9f1e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“脑极体”（ID：unity007）</a>，作者：藏狐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156472468560390</id>
            <title>春节后最强三大ETF浮现：人形机器人、黄金、哪吒</title>
            <link>https://www.36kr.com/p/3156472468560390</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156472468560390</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:56:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: A股投资, ETF板块, 机器人, 黄金股  
<br><br>  
总结: 本文分析了春节后A股市场的投资轮动风格，指出机器人ETF、黄金股ETF和游戏动漫等TMT主题ETF成为年内涨幅领先的板块。机器人ETF因春晚节目“机器人扭秧歌”而受到关注，年内涨幅达到18.14%。黄金股ETF受国际金价上涨影响，年内涨幅近13%。此外，《哪吒之魔童闹海》的成功票房推动了游戏动漫相关ETF的上涨。文章还探讨了机器人行业的长期投资机会及黄金市场的前景。 </div>
                        <hr>
                    
                    <p>A股投资轮动风格向来以快制胜，春节后两个交易日，2月6日，年内涨幅超过10%的三大ETF板块已经浮出水面。</p>
  <p>具体来看，<strong>一是机器人ETF板块。</strong>春晚大火的“机器人扭秧歌”，春节后机器人ETF迎来大爆发，年内回报率超过黄金相关主题ETF，成为第一。嘉实机器人指数ETF单日涨幅达到8.27%，年内涨幅18.14%登顶；</p>
  <p><strong>二是黄金股等ETF。</strong>国际金价在节后一度升至每盎司2900美元上方，连创纪录，对于黄金而言，已是疯狂行情。有业内人士调侃，高盛对于黄金将在2026年中期达到3000美元的预测还是太保守了。截至目前，黄金股ETF年内涨幅近13%。</p>
  <p><strong>三是游戏动漫、软件等TMT主题ETF。</strong>2月6日12时，《哪吒之魔童闹海》以57.76亿元票房（含预售）登顶中国票房榜第一名。该影片的出品方光线传媒在影片上映后受益显著，春节后两个交易日累计涨幅41.66%，股价创近4年新高。《哪吒》撬动游戏动漫、软件等ETF年内收益率超过10%。</p>
  <p>三条投资主线既明，当前产业处于什么发展阶段？将如何映射到投资端？接下来又将面临哪些机会？基金经理们带来最新解读与展望。</p>
  <h2><strong>机器人是10年大级别beta机会，还是短期止盈？</strong></h2>
  <p>2025年蛇年春晚的舞台上，一群穿着花棉袄的机器人在现场扭起了秧歌，机器人们还会变换队形、舞动身体，多角度转手绢。“机器人扭秧歌”登上热搜，这些机器人来自国产机器人生产商。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f6af220b388c4ea194042d4b55438b1a@5888275_oswg108763oswg1080oswg725_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>机器人扭秧歌与春晚的组合，赛博朋克风格的节目让人印象深刻，也在节后迅速进入投资者的布局视野。仅仅两个交易日，机器人相关ETF组团登顶年内股票ETF涨幅榜。</p>
  <p>2月6日，嘉实机器人指数ETF涨幅达到8.27%，年内涨幅18.14%。溢价也达到2.47%，可见资金热度。此外，天弘、银华、华夏、国泰等旗下机器人ETF年内涨幅也达到15%，当前也具有不同程度的溢价。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6eeddf5abb184338a8f79fb59fcdc9a2@5888275_oswg50380oswg1080oswg238_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>重点关注机器人方向的永赢先进制造基金经理张璐介绍，以前机器人板块觉得产业链还处于极早期距离落地还有较长时间，同时板块股票数量、行业催化都比较有限，所以机器人板块的行情往往持续性不强。但是机器人板块从2024年四季度开始发生了一些根本性的变化，板块持续演绎，核心是有三点原因：一是超预期的国内外人形机器人进展；二是2025年人形机器人量产元年；三是政策端的支持。</p>
  <p>“除了国内人形机器人厂商进展超预期，2024年10月10日，We Robot大会上，10余个特斯拉擎天柱机器人在现场端茶倒水、跳舞、互动，整体呈现更加灵活与智能，直播3小时中，不存在任何差错，展现了极强的工程实力。”张璐表示，去年12月以来我们看到了大量的新进入玩家开始布局机器人行业，包括汽车、电新、家电、互联网领域的传统巨头，机器人板块股票数量也在快速增长，行业扩圈明显。</p>
  <p>在量产方面，平安基金基金经理张荫先也表示认同，他认为，后续很快会迎来“机器人”新物种的量产时刻，这个赛道也将会是未来数年最受资本市场关注的赛道之一。</p>
  <p>赛道火热之余，投资者更为关心的还是行情的持续性。张璐直言，<strong>人形机器人板块是未来10年大级别beta机会。从产业角度，机器人行业的“Iphone时刻”或将来临。对于行情的判断上，机器人板块近期已逐渐从主题转变为具有长期向上趋势的成长板块。</strong>无论是机构还是游资，整体活跃度较高，此外板块内标的的扩散程度、资金容纳度均有提升。综合来看，机器人板块预期可能会成为中长期反复活跃、中枢不断提升的板块，具有较高的成长性。</p>
  <p>在投资机会的挖掘上，张荫先认为可从两个方面着手，一是寻找在机器人业务中存在较高概率进入供应链的公司，二是积极挖掘并布局主业基本面有改善、同时新拓展机器人业务的优秀公司，这类公司会在新材料、新工艺、新设计方案中有望脱颖而出，让原有的产品在新的机器人领域中获得新应用场景、实现0-1的新突破，进而获得估值及业绩的双击机会。</p>
  <p>当基金经理喊出人形机器人板块是未来10年大级别beta机会的时候，也有游资表示，今天减仓了部分机器人概念。“产业的长期看好与短期的止盈并不矛盾。”</p>
  <p>从资金变动方向来看，2月5日，8只机器人ETF合计资金净流出约1亿元，有一定的止盈迹象，年内资金净流入则达11亿元，其中，华夏机器人ETF净流入最多，超过10亿。</p>
  <h2><strong>国际金价触及3000美元还要用多久？</strong></h2>
  <p>2月5日，COMEX黄金一度升至2900美元/盎司关口上方，今年以来，国际金价已经连续突破2800美元、2900美元关口。换算成国内金饰价格或更为直观，2月6日，周大福、六福珠宝、潮宏基、周生生等足金饰品价格每克已经接近870元。</p>
  <p>2月6日，COMEX黄金价格略有回落，年内涨幅仍高达8.82%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3c5d585d7275484ab1d9ef0d7973f392@5888275_oswg99703oswg1080oswg1321_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>金价上涨，叠加众多金矿龙头公司纷纷发布2024年报业绩预增公告，被称为“金价放大器”的黄金股ETF紧随机器人ETF之后，成为年内增长第二的板块。多只黄金股ETF年内涨幅超过12%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1a274904219e4a4ca028cb3f438a2f2d@5888275_oswg80181oswg1080oswg420_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于黄金股大涨的原因，永赢黄金股ETF基金经理刘庭宇表示，黄金股会受到黄金价格与国内金矿产业公司的双重影响，假期金价上涨反映了投资者对关税政策不确定性的担忧和对全球经济疲软背景下降息周期延续的预期，当前龙头金矿公司按市盈率估值计算仍处于历史中枢下沿，后续估值修复可期，未来有望在量价齐升的戴维斯双击周期中继续起到“金价放大器”的作用。</p>
  <p>“还有一个角度也值得大家关注，近期特朗普家族频繁发行新品类数字货币，导致数字货币市场降温、比特币大跌，部分资金或从数字货币回流黄金市场。”刘庭宇分析称。</p>
  <p>2024年也是黄金投资的大年，当年黄金股ETF涨幅超过27%，今年仅仅过去一个月，相关ETF涨幅已经接近去年全年涨幅的三分之一，接下来该如何配置？在华安基金看来，黄金依然是2025年值得重视的大类资产，原因有四：</p>
  <p>第一，实际利率对黄金的定价有望回归，包括全球经济增速放缓，以及美国面临中长期的再通胀问题。</p>
  <p>第二，逆全球化背景下，为了应对通胀和金融危机，央行有望延续购金节奏。</p>
  <p>第三，黄金在大类资产维度的低相关性，叠加当前低利率环境，凸显出重要配置价值。</p>
  <p>第四，黄金长期增长的本质依然是货币属性，对抗美元信用，当前美国的债务压力和高利率环境在加剧信用风险。</p>
  <p>在黄金相关ETF则越涨越买，2月5日，黄金相关ETF合计净流入5.66亿元，不过拉长年内来看，资金在黄金相关ETF流出近20亿元。</p>
  <h2><strong>《哪吒》撬动游戏动漫等概念ETF大涨</strong></h2>
  <p>《哪吒》票房以58亿元登顶，再次成为游戏动漫等主题上涨的重要驱动事件，不仅最新票房预测达到87亿元，带飞出品方两连板光线传媒，联名手办售罄的泡泡玛特、出版官方绘本的中信出版，乃至提供动漫渲染服务的丝路视觉等上市公司纷纷受到投资者关注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7f42f552db6e40f69f1253b88500d1ea@5888275_oswg97642oswg830oswg1396_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>优质影片内容对票房拉动效果明显，大IP模式之下，影视、动漫、游戏以及软件等TMT主题均受益，华夏游戏ETF、国泰游戏ETF以及华泰柏瑞游戏动漫ETF等大涨之后，年内涨幅也超过11%。</p>
  <p>银河证券研报指出，春节档影片几乎都是国产IP电影或者续作，高价值IP的电影续作不断推进将激励更多新的优秀IP涌现，有望赋能整个电影IP及周边的授权、衍生、开发系列产业链，国产电影的IP品牌效应已经初步显现。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Xz-ErPBYm1oVa41wZ2Toqg" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”</a>，作者：闫军，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156472198584834</id>
            <title>人形机器人短期大涨超50%，基金经理：未来10年大级别机会</title>
            <link>https://www.36kr.com/p/3156472198584834</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156472198584834</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:56:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人形机器人, 产业发展, 投资机会, 政策支持  
<br><br>  
总结: 2025年将是人形机器人量产元年，国内外企业积极布局，相关政策支持不断增强。机器人板块在春节后迎来连续上涨，涨幅已超过50%。多位基金经理认为，机器人行业正在经历根本性变化，未来将成为中长期活跃的成长板块。人形机器人不仅能解放双手，还将全方位赋能人类生活，市场潜力巨大。随着技术进步和产业链完善，预计将迎来“机器人”新物种的量产时刻。 </div>
                        <hr>
                    
                    <p>2025年蛇年春晚的舞台上，一群穿着花棉袄的机器人扭秧歌，让其背后的产商——宇树科技屡登热搜，<strong>人形机器人“一日千里”般的产业发展情形也进入大众的视野。</strong></p>
  <p>受多个利好消息刺激，<strong>春节后两个交易日，机器人板块迎来连续上涨行情：</strong>国泰、华夏、天弘、银华旗下中证机器人ETF在2月5日上涨超4%，截至发稿，相关产品今日涨幅也已近3%。而自去年924行情以来，这一板块涨幅已超过50%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_37fcfdbfaa2a4a26bab1b6cda2c452da@5888275_oswg107332oswg808oswg545_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>多位基金经理认为，机器人板块从2024年四季度开始发生了一些根本性的变化，其板块持续演绎的核心逻辑在于：<strong>超预期的国内外人形机器人进展，2025年将是人形机器人量产元年，政策端支持。</strong></p>
  <p>在业内人士看来，机器人板块预期可能会成为中长期反复活跃、中枢不断提升的板块，具有较高的成长性。<strong>该板块是未来10年大级别beta机会，</strong>它的闪耀登场远不止解放双手那么简单，可能是未来不可多得的，如同当年消费电子中苹果产业链、特斯拉电动车产业链——现象级的长坡厚雪大赛道。</p>
  <h2><strong>人形机器人迎“升浪”</strong></h2>
  <p>经过一个春节的酝酿，人形机器人已进入大众视野，相关产业的巨大发展潜力也为人所熟知。</p>
  <p>一方面，国内企业如华为、宇树科技等积极布局人形机器人；另一方面，国际巨头如特斯拉、英伟达等公司的人形机器人项目正在快速推进，预计2025年将进入有限生产阶段，机器人新创企业Figure更是在2月5日宣布终止与OpenAI合作，并豪言将在30天内推出“ 颠覆人形机器人行业 ”的创新成果。</p>
  <p>受此刺激，春节后首个交易日，机器人板块涨幅居前，国泰、华夏、天弘、银华旗下中证机器人ETF在上涨均超4%。在2月6日开盘后，相关产品继续上涨，截至发稿，上述产品涨幅均在3%左右。</p>
  <p>鉴于人形机器人概念活跃，关注度持续提升，<strong>多家上市公司在互动平台回应研发情况及相关布局：</strong></p>
  <p>经纬股份：公司业务目前不涉及电力巡检机器人和四足巡检机器人；</p>
  <p>精工科技：碳纤维在人形机器人领域的应用优势明显，随着人形机器人产业的快速发展和规模化生产，碳纤维的需求预计将呈现显著增长态势；</p>
  <p>宜安科技：公司密切关注智能机器人领域的技术和产业发展动态，并将结合公司自身战略规划和市场需求进行业务拓展和布局；</p>
  <p>豪森智能：公司现已构建汽车现代智能工业装配线，建立人形机器人智能制造创新中心，完成大连基地与常州基地人形机器人开发双布局，开展多场景人形机器人应用训练和测试技术开发，通过20余年积累的汽车核心零部件装备生产线工艺数据快速迁移到人形机器人智能体开发中，加快了人形机器人在工业制造场景的落地；</p>
  <p>机器人：工业机器人和人形机器人从产品形态、产品结构、技术及应用的侧重等有一定差异，目前公司在3D视觉、力感知等工业机器人领域的核心技术方面有技术积累优势，未来将视需求在融合上述技术的基础上，围绕AI大模型、智能视觉感知、数字孪生、结构仿生等前沿、空白技术领域进行研发投入，积极布局人工智能前沿领域，相关工作在有序推进，尚处于研究初期阶段……</p>
  <h2><strong>板块持续演绎的核心逻辑</strong></h2>
  <p>在国内，有穿着花棉袄的机器人扭秧歌；国外，则有特斯拉擎天柱机器人在“We Robot”大会上端茶倒水、跳舞、互动，还在感恩节随机扔发网球、完美接球。</p>
  <p>从实际情况看，2024年12月以来，大量新进场的玩家开始布局机器人行业，包括汽车、电新、家电、互联网领域的传统巨头，机器人板块股票数量也在快速增长，行业扩圈明显。</p>
  <p>股价层面，从2024年924行情以来，机器人板块的涨幅已来到50%以上，天弘中证机器人ETF、易方达国证机器人产业ETF、景顺长城国证机器人产业ETF涨幅分别达53.93%、53.61%、53.04%，其余中证机器人ETF涨幅也都超51%。</p>
  <p>“以前觉得机器人板块产业链还处于极早期距离落地还有较长时间，同时板块股票数量、行业催化都比较有限，所以机器人板块的行情往往持续性不强。”永赢先进制造基金经理张璐表示。但他看到，机器人板块从2024年四季度开始发生了一些根本性的变化，板块持续演绎。</p>
  <p>他认为，核心原因有三点：一是超预期的国内外人形机器人进展；二是2025年将是人形机器人量产元年：一方面，是特斯拉计划2025年开始对内量产，目标1万台，另一方面，国内多家机器人厂商都推出了自己的量产时间规划，2025年或将看到整个行业1-N的开端；三是政策端支持，近年来，中央和地方政府密集出台政策，全面支持人形机器人产业的发展，为其技术突破、应用推广和产业链完善提供了强有力的保障。</p>
  <p>浦银安盛高端装备基金经理李浩玄直言，过去短短几个月内，人形机器人的产品性能有快速提升，尤其在灵巧手和动作泛化程度上进步显著；国内外几乎所有的科技和制造巨头都在进入这个产业，彻底定调明确了行业趋势，也粉碎了此前的诸多质疑。</p>
  <p>在供应链上，除了原有的核心玩家，新进入者众多。尤其是本身具有技术积淀的自动化和汽零公司基本都在积极投身其中。中国制造快速反应迭代的优势显现。在股价层面，由于一致预期的建立，人形机器人板块涨幅可观，且标的快速“扩圈”，相比2022年和2023年的行情，正在逐步从主题概念过渡到产业投资。</p>
  <p>在此背景下，他在四季度将仓位更多地集中到具备高确定性的标的上，以产业的思路重仓具有真正核心技术、卡位优势和供应链能力的公司。除了上游的核心零部件，还配置了稀缺的具有本体制造和强大品牌力的人形机器人主机厂商。“总的来说，我们将坚持把握行业大趋势，过滤短期情绪波动，战略性重仓扎根核心品种。”</p>
  <h2><strong>机器人行业的“iPhone 时刻”或将来临</strong></h2>
  <p>近期，机器人板块已逐渐从主题转变为具有长期向上趋势的成长板块。不论是机构还是游资，整体活跃度较高，此外板块内标的的扩散程度、资金容纳度均有提升。</p>
  <p>“综合来看，机器人板块预期可能会成为中长期反复活跃、中枢不断提升的板块，具有较高的成长性。”张璐表示。</p>
  <p>他认为，2025年开始，一大批国内外厂商都将进军人形机器人产业，部分公司可能推出现象级机器人产品并开始进行小规模量产，机器人行业的“iPhone 时刻”或将来临。</p>
  <p>在他看来，人形机器人板块是未来10年大级别beta机会。<strong>它的闪耀登场远不止解放双手那么简单，无论从情感陪伴还是物理支持都将全方位赋能人类的生活。</strong>马斯克多次阐述愿景：未来人类和人形机器人的比例将不止是 1：1，有较大可能超过人类数量，渗透率的天花板高且想象空间大。“终局来看，假设是100亿台机器人的市场，如果2万美金一台，会形成200万亿美元的终局大市场。如果所有企业按照终局估值，在未来都会带来庞大增长。”</p>
  <p>值得一提的是，<strong>人形机器人相较于其他行业壁垒较高，涉及到多学科的融合、软硬件的协同，所以对入局的资金、技术、资源整合都有相对较高的要求。</strong>而且产业链从上游到核心零部件和系统零部件，到中游的机器人本体和系统集成，到下游的终端应用，产业链长且复杂。机器人。</p>
  <p>“因此，人形机器人可能是未来不可多得的，如同当年消费电子中苹果产业链、特斯拉电动车产业链——现象级的长坡厚雪大赛道。”而随着人形机器人量产接近，张璐也将重点关注拥有供应链优势、技术具有护城河、价值量较大的优质人形机器人产业链公司，包括机器人总成商、丝杠及设备、减速器、传感器、电机、灵巧手等。</p>
  <p>兴银先进制造智选基金经理罗怡达亦表示，2025年，我们将看到人形机器人开始走向小批量量产，具备完全AI能力的人形机器人将离现实越来越近。“科技的发展将改变我们的生活，这里面蕴含了大量的先进制造产业链机会，中国的企业在相关产业链上有重要的卡位优势，我们积极挖掘其中受益产业趋势且性价比合适的标的进行布局。”</p>
  <p><strong>“我们预计很快会迎来‘机器人’新物种的量产时刻，这个赛道也将会是未来数年最受资本市场关注的赛道之一。”</strong>平安基金经理张荫先称，一方面，他将寻找在机器人业务中存在较高概率进入供应链的公司，另一方面积极挖掘并布局主业基本面有改善、同时新拓展机器人业务的优秀公司。</p>
  <p>“这类公司会在新材料、新工艺、新设计方案中有望脱颖而出，让原有的产品在新的机器人领域中获得新应用场景、实现0-1的新突破，进而获得估值及业绩的双击机会。”张荫先表示。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/WO9Mb56ELXWJlaAdKxPINQ" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”</a>，作者：沈述红，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156437179357954</id>
            <title>苹果机器人首次曝光，一个有情绪会蹦迪的“台灯”，皮克斯动画照进现实</title>
            <link>https://www.36kr.com/p/3156437179357954</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156437179357954</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:56:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <皮克斯, ELEGNT, 机器人, 情感表达>
<br>
<br>
总结: 1986年，皮克斯的短片《顽皮跳跳灯》展示了无表情的台灯通过动作传达情感，成为皮克斯的吉祥物。苹果推出的ELEGNT机器人，旨在让非拟人化机器具备肢体语言和情感表达，提升人机交互的生动性。ELEGNT通过上下文学习能力，能够根据实时场景调整动作，表现出情感和态度。尽管ELEGNT在情感表达上表现出色，但其效率低于传统机器人，引发了对机器人设计方向的思考。未来，ELEGNT可能会在智能家居中得到应用，成为更具普适性的技术。 </div>
                        <hr>
                    
                    <p>1986 年，皮克斯在一场计算机图形讨论会上放映了最新动画《顽皮跳跳灯》，片中两个蹦蹦跳跳的台灯没有表情，没有对白，只凭借扭头、伸展等等的动作，用 2 分钟就向观众展示了自己的鲜明个性和情感。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_827ccc547b3e4bb6931f11dbe2cf29dd@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种前所未见的动画形式，不仅震撼了在场所有人，还助力这部短片拿下奥斯卡提名，也成为了现在每一部皮克斯电影都不会缺席的吉祥物。&nbsp;</p>
  <p>而将近 40 年后的今天，和皮克斯渊源颇深的苹果，成功将这个动画史上最具里程碑意义的角色，带到了现实世界当中。&nbsp;</p>
  <h2><strong>有情感的「小台灯」&nbsp;</strong></h2>
  <p>今天，苹果在其机器学习网站，公布了一项机器人研究成果 「ELEGNT」，目前的原型机器是一个台灯形态的设备。&nbsp;</p>
  <p>ELEGNT 的名字取得非常巧妙：形似单词「elegant（优雅）」，符合这项技术的表现；而全称很长：a framework of <strong>E</strong>xpressive and functiona <strong>L</strong>&nbsp;mov <strong>E</strong>ment desi <strong>G</strong>n for&nbsp; <strong>N</strong>on-anthropomorphic robot，翻译过来就是「一种用于非拟人化机器人的表达性和功能性运动设计框架」。&nbsp;</p>
  <p>看起来有点抽象？其实核心意思很简单：苹果做的不是春晚舞台上的人形机器人， <strong>而是让一些非人形机器，比如一个台灯，懂得「肢体语言」。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_210501355b474ce9b699221235d4127a@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这个「懂」不单单是「理解」人类的手势操作， <strong>而是机器人做出反应时，也会补充一些动作细节，让交互有「生命感」。</strong></p>
  <p>传统的机器人，完成指令的方式是一条直线，程序设定好的动作幅度精准到不会多出一毫米。&nbsp;</p>
  <p>而 ELEGNT 是一条曲线，过程中会表达意图、显示注意力、展示态度、表达情绪，也就是说会小小地「演」一下。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8286f79424f24421be010e5ec72548c8@000000_oswg37458oswg1024oswg573_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>比如，用户下达指令的时候， ELEGNT 会「看着」用户，时不时歪歪头和点头，仿佛自己真的在认真听讲，而实际上没有这些动作，机器人也能通过麦克风正常录音和分析。&nbsp;</p>
  <p>用户问机器人天气，它会先向窗户的方向探探头，然后再进行回答，但其实它只是上网检索了一下天气数据。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_db522a7d1a2a4ba2b03061843530d7a7@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>如果机器人够不着需要识别的物体，它还会垂下脑袋摇摇头。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0accbf1b7f2a4ab0871d09fcf03f8a7f@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>比较可爱的是放音乐的时候，机器人会跟着节拍一起蹦迪，看起来真就像是皮克斯电影的桥段。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_622cfd766bdd45af9b9b4826c5303c51@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一样的台灯形态和动作，很容易让人想起 2023 年小米发布的一个名为「皮皮灯」的产品，同样能「摇头晃脑」，有「喜怒哀乐」的情绪表达。&nbsp;</p>
  <p>不过这个皮皮灯的实现原理要简单许多，主要是设定好的程序，动作幅度也比较死板，总体来说比较像噱头。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3cb99bdc0d4d437cbb9db8bc075a84f6@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：知乎 @J 法老&nbsp;</p>
  <p>ELEGNT 背后的技术要复杂得多， <strong>运用了大语言模型的上下文学习能力，能够「察言观色」</strong>，根据实时交互场景调整动作模式。在交互中，ELEGNT 会主动问用户远足能不能带上自己，如果被拒绝，它就会低下头，给人一种很难过的感觉。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1ea45f25131549d88db9e0c2a947a091@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>ELEGNT 还结合人类反馈优化，目前能够生成 10 种不同的肢体语言序列，并控制好每个动作的时间和幅度，实现情感表达和任务完成效率的平衡。&nbsp;</p>
  <p>当然，高度拟人化的 ELEGNT，背后也存在一定的伦理问题：可能会引起用户的情感投射，甚至依赖，尤其是在儿童和一些脆弱群体当中。&nbsp;</p>
  <p>由于测试的时间太短，测试人员也不够多，无法验证 ELEGNT 表达动作会不会存在程式化的问题，长期使用有可能会导致用户审美疲劳，影响交互的有效性。&nbsp;</p>
  <h2><strong>机器人也需要「人味」&nbsp;</strong></h2>
  <p>从苹果的演示对比视频可以发现，ELEGNT 机器人虽然可爱，但它的效率比「打直球」的普通机器人要低很多，前者还在探头探脑的时候，后者早已经给出用户需要的答案。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_339384dd4e9b4c41b0f0bcd3b4524325@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左边：具有情感表达的机器人；右边：普通的机器人&nbsp;</p>
  <p>这似乎和机器人的初衷有点背道而驰。让机器人进入我们的工作和生活，本应该是为了更好更快地帮我们干活，而 ELEGNT 问个天气都要等它先演一番，这么一想，苹果好像「方向错了」？&nbsp;</p>
  <p>技术是冰冷的。当你还在欣喜于 Deepseek 能帮你高效完成工作，可能你已经快要被它取代；工厂里越来越多的机器人身影，意味着更多人类失去岗位。&nbsp;</p>
  <p>而苹果变 AI 为 Apple Intelligence，玩一点文字游戏来掩盖技术的无情一面；而对于机器人，苹果的思路更加开阔。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_03209b452cb94c0087f51539662b2abd@000000_oswg62808oswg1024oswg538_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Apple Intelligence 多彩的界面和 logo 也是为了显得更友好 &nbsp;</p>
  <p>虽然不如人形机器人那么火，但这两年「机器宠物」的概念也开始兴起：卡西欧的 Moflin 卖断货，CES 上的 Ropet 成功刷屏。这些毛绒绒的小机器人，主要的功能就是卖萌，和生成一些「情感」。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f0f86755445c40c899f56423c673eb1e@000000_oswg51112oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Ropet&nbsp;</p>
  <p>&nbsp;</p>
  <p>ELEGNT 就有点像电子宠物和实用机器人的结合，它能一边卖萌，一边完成任务。论文中也提到，情感优先的机器人，能够降低人类的认知负荷，让用户更乐于主动去进行交互，特别是在社交场景中。&nbsp;</p>
  <p>不是只有苹果在想办法为机器人增加活人感。马斯克的人形机器人 TeslaBot，已经会和用户玩剪刀石头布；宇树科技也让机器人穿上大花袄扭秧歌，登上春晚大舞台。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d49e3d3b69934aae8110b9f042e05e3b@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">TeslaBot&nbsp;</p>
  <p>&nbsp;</p>
  <p>只是，这些外壳冰冷、动作机械的机器人，再怎么模仿人类，目前都还是差了点意思。ELEGNT 直接另辟蹊径，利用了我们对皮克斯动画角色的集体记忆，加上完成度相当不错的机器动作，首次亮相就成功走进不少人的内心。&nbsp;</p>
  <p>The Verge 评论区，已经有网友对 ELEGNT 给出高度评价：&nbsp;</p>
  <p><strong>我已经不想养一只狗了，我现在想养一盏台灯。&nbsp;</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3ae65fc1c9234598a57a979468303024@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">「我爱台灯」&nbsp;</p>
  <p>论文中更严谨的样本研究显示，带有情感表达的 ELEGNT ， <strong>在 6 个任务的评分中都高于没有情感表达的版本，前者几乎获得后者两倍的平均得分；并且 ELEGNT 放音乐时蹦迪的表现让人印象非常深刻。</strong></p>
  <p>比起人形机器人，ELEGNT 是一个更具普适性的技术，因为它可以用于那些非人形的低自由度机器人中。今天是一盏台灯，明天可能就是苹果的 HomePod，到最后可能整个家都变成迪士尼的公主城堡，每个家具都有自己的情感，一个人住也能热热闹闹的。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2eea7672bcf143c5a9d3c4f56bf9b79d@000000_oswg62392oswg612oswg380_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">未来的智能家居说不定长这样&nbsp;</p>
  <p>虽然这些技术目前还只是学术成果，但它们实装到产品上的日子或许不会太远。从去年开始，非常多的信息源都报道称， <strong>苹果正在开发智能家用机器人，可能会是一个带了个显示屏的 HomePod 设备，或者是带有机械臂的 iPad</strong>，有点像经典的 iMac G4， <strong>有望于 2026 或 2027 年推出。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_33dd6ab8bf5547caa6535560c1a9513e@000000_oswg477685oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">苹果新智能家居假想图，图源：MacRumors&nbsp;</p>
  <p>根据此前的爆料，这个带显示屏的 HomePod 可能会支持自动转向，始终将屏幕对准用户，并且能识别手势操作，听起来就很适合 ELEGNT 大显身手。&nbsp;</p>
  <p>iPhone 一年比一年无聊，万众期待的 Vision Pro 、Apple 智能实际体验乏善可陈。据称，家用机器人很可能成为苹果的「Next Big Thing」，用来打下苹果目前表现平平的智能家居市场。&nbsp;</p>
  <p>Amazon、Google 不是没有类似的探索，但用户接受度并不高，主要是因为这些设备笨重又不智能；步步紧逼的老对手三星，也已经宣布了今年正式发布家用机器人，外观同样主打「可爱风」。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fe8372f7273b40a198fdff3302992695@000000_oswg32770oswg1024oswg683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">三星将于今年发布智能家用机器人 Ballie&nbsp;</p>
  <p>苹果这次能不能再次成功「后发制人」的问题，只有时间能作答，但至少 ELEGNT 让我久违地感觉一个苹果产品 <strong>「非常有趣」</strong>。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_39882456c0f449fca50451264ac66391@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&amp;mid=2652396195&amp;idx=1&amp;sn=a8784ca45776b2a107026a224d786886&amp;chksm=9ac149f833c00485a271c39d469787ceac1e552fa2e8b97ae45c999dad1dc5630babb5d454ce&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“爱范儿”（ID：ifanr）</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156473943300872</id>
            <title>免费功能卷翻付费版ChatGPT，欧洲AI新贵叫板OpenAI</title>
            <link>https://www.36kr.com/p/3156473943300872</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156473943300872</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:55:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Le Chat, Mistral AI, 闪电回答, 代码解释器  
<br><br>  
总结: Mistral AI推出了全新升级的AI助手Le Chat，支持iOS和Android，并引入了“闪电回答”功能，响应速度可达每秒1000字。Le Chat还具备代码解释器、图像生成、高级文档分析等多项功能，且大部分功能免费提供。与其他AI助手相比，Le Chat在速度和功能上力求竞争，未来还将推出企业版。用户可以通过Le Chat进行个性化学习和目标跟踪，提升使用体验。 </div>
                        <hr>
                    
                    <p>“欧洲OpenAI”<strong>Mistral AI</strong>有新动作了！</p>
  <p><strong>Le Chat</strong>（法语“猫”）<strong>全新升级</strong>，官方自称它是“您生活和工作的终极AI助手”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3f8b17c1daf84b6b9be421edb8e159ef@5888275_oswg172265oswg1080oswg794_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从今天开始，Le Chat上线移动端，<strong>iOS和Android都支持</strong>，不久也将对企业私有基础设施开放。</p>
  <p>功能方面，Le Chat升级主打极速响应，Mistral AI开发者关系主管原话是这样婶儿的：</p>
  <blockquote>
   <p>Le Chat的推理、反思和响应速度超过任何其它聊天助手，可达每秒~1000words。</p>
  </blockquote>
  <p>这个功能被命名为“<strong>闪电回答</strong>”（Flash Answers）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7b73275383894adfb9e1ad4af9754330@5888275_oswg199720oswg1080oswg381_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_47567994c6814735ba28b83c809c8be6@5888275_oswg75794oswg1026oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>有多快？</p>
  <p>来看Le Chat与Claude、ChatGPT的对比，同样是用Python编写贪吃蛇游戏，Le Chat刚开始就结束，速度达1100tok/s，Claude速度120tok/s，ChatGPT为85tok/s。</p>
  <p>除了速度快，Le Chat还引入了<strong>代码解释器</strong>功能，加上原有的图像生成、高级文档与图像分析、网页搜索、Canvas等，Mistral AI势要和ChatGPT、Claude等卷到底。</p>
  <p>要知道，Canvas等功能在ChatGPT那儿是要付费的，而Le Chat直接免费就能玩，包括“闪电回答”也是免费的。</p>
  <p>而付费版在免费版的功能基础上，外加不限量访问最高性能模型和网页浏览、可选择不与Mistral AI共享数据等权限。Mistral AI表示还将推出私有预览的企业版（Enterprise）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e118db2eace5479f9f66040d39f7cf25@5888275_oswg248250oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这波操作把网友看懵:</p>
  <blockquote>
   <p>不明白你们为什么要和ChatGPT/Claude竞争，很烧钱，不是吗？</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4140813507ce49c88dc546fe9da31ff6@5888275_oswg96794oswg1080oswg197_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网友评论区底下直呼：</p>
  <blockquote>
   <p>还需要MacOS app～</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_64ae19dc5c1d4370bc857be9344d09fd@5888275_oswg72517oswg1080oswg228_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <blockquote>
   <p>AI公司一个周内互相超越。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_01d3160769b24456af6f02b5f709e1af@5888275_oswg108378oswg1080oswg263_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>Le Chat功能一览</strong></h2>
  <p>再具体来看看Le Chat这波新增的代码解释器功能，Le Chat现已具备高级编码功能。</p>
  <p>它使用户能够执行沙箱代码、进行科学分析、创建可视化以及运行模拟。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4eedd0d263ad4e199ac08e1f7bf013f5@5888275_oswg44775oswg1080oswg480_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>比如prompt：</strong>你能解释一下泰勒级数近似的原理吗？给一些正弦函数的例子。</p>
  <p>Le Chat解释时会附带插图说明（Illustration）：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c847ad49734d4dddb7e82e8319789c32@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>支持验证代码：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_45d797eb5fcd4ddc805270caba54ef94@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用代码解释器分析CSV数据也不成问题：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_31ac9c4d31df49d287d2e5016cd476a2@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e847be28d4434c07a5ebfa58fdbc1b2a@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Le Chat图像生成功能由Flux Ultra驱动，支持画文字：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_82f64fb772af4f4482b34e07c1972501@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也有热门网页搜索功能，附带信息源：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8f0db68de8f24799bf0e8d54739de282@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>文档理解功能，对论文的理解可以精准到某张图，比如可以让它解释Figure 2的abcd都表示啥：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2f16b81e6b8941aa9f33b63bf94001e5@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此之外，官方还表示即将对所有用户开放“<strong>记忆</strong>”（Memories）功能，可选择性开启。</p>
  <p>它可以了解记住用户偏好，重新发现很久以前的对话，由此能提供个性化学习，跟踪用户实现目标的进度。</p>
  <p>比如它能记起你之前提到新年目标是在接下来的6个月内将体脂率从22%降至12%，然后帮你制定月度计划：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_cccf7d9ef0504b2190fe2aa0511cffaa@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>总之，ChatGPT有的，都得有。</p>
  <p>这就不得不提ChatGPT的会员专属高级界面Canvas功能，Le Chat免费，能够帮助用户从0-1进行创作。</p>
  <p>比如，计划未来四周内在巴黎向另一半求婚，已经买了戒指，但还没有计划其它的细节，请求创建一个详细的视觉时间线以保持事情的进展有序。</p>
  <p>Le Chat的规划是酱婶儿的，有单独界面展示生成的文稿，也有代码以及可视化。</p>
  <p>Le Chat还有一个功能是可以创建并在对话中@智能体，智能执行任务：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e8e7104dce0b4fd7b88f42c43c2fbb5c@5888275_oswg41290oswg1080oswg433_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>比如使用Le Chat智能体追踪个人财务，自动化安排日程：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3986ded4ba454590b24b9b756dd32e79@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>都能get可视化图表的那种：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_381d6cf1fde549069bf6442ea23485ef@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Le Chat全新升级后，网友们也已经开始玩起来了。</p>
  <p>有网友尝试一番过后反馈确实很快：</p>
  <p>感兴趣的童鞋可以亲自试试～</p>
  <p>参考链接：</p>
  <p>[1]https://x.com/sophiamyang/status/1887517050697842899</p>
  <p>[2]https://x.com/onetwoval/status/1887547069956845634</p>
  <p>[3]https://x.com/MistralAI/status/1887517520040448510</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/K_krY5nLog3dFaQFWIhXdw" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156478097889800</id>
            <title>杭州跑出50亿未来独角兽：年入8.12亿</title>
            <link>https://www.36kr.com/p/3156478097889800</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156478097889800</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:55:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 盘兴数智, IPO, SaaS, 在线营销  
<br><br>  
总结: 盘兴数智是一家专注于智能电商SaaS运营解决方案的公司，近期向港交所递交IPO申请。其前身为浙江独角兽企业盘石信息，现估值达到50.49亿元。公司主要产品包括线上营销解决方案和SaaS服务，线上营销解决方案在2024年前9个月占总收入的91%。随着内容电商平台的崛起，行业增长迅速，预计市场规模将持续扩大。盘兴数智通过两轮融资获得资本市场青睐，财务表现也显著提升。 </div>
                        <hr>
                    
                    <p>近日，来自浙江杭州的企业——盘兴数智向港交所递表，全力冲刺IPO。</p>
  <p>盘兴数智是一家专注于提供智能电商SaaS（软件即服务）运营解决方案的公司。它借助先进的技术和海量的数据，助力企业实现更高效的运营与管理，尤其在电商、制造业等领域。</p>
  <p>盘兴数智的前身是浙江独角兽企业盘石信息（估值110亿元）的RockySaaS事业部。如今，它的估值也达到50.49亿元。</p>
  <p>盘兴数智究竟是一家怎样神奇的公司呢？</p>
  <h2><strong>01</strong></h2>
  <p>浙江盘兴数智科技股份有限公司（以下简称“盘兴数智”）的创始人是田宁先生，出生在浙江湖州。</p>
  <p>1999年，还在浙江大学动物科学专业读大三的田宁和两位同学一起凑了10万元启动资金，创立了浙江大学盘石计算机网络技术有限公司，这也是浙江大学首家由在校大学生创办的企业，田宁也因此被冠以“浙江省大学生创业第一人”的称号。</p>
  <p>盘石计算机开始准备做教培咨询，但很快把钱烧完了，之后转向销售计算机硬件，还承接了省内多项电子政务项目，挣到了第一桶金。</p>
  <p>2004年，田宁创立了盘石信息，以精准、定向网络营销分析技术为基础，做企业网络营销服务提供商。</p>
  <p>2011年，云计算概念渐兴起，SaaS也开始进入大众视野。田宁带领盘石信息正式切入SaaS赛道。</p>
  <p>随后，盘石信息深入挖掘“盘石云”大数据，逐步形成了RockySaaS、Rockyplay、直播电商、智慧城市、数字科技、新消费和信用云七大业务板块，打造出了基于盘石大数据交互链接的商业生态平台 。</p>
  <p>2017年，为了更好地专注于RockySaaS（企业级SaaS服务）业务，盘石信息创建全资子公司盘兴数智，将该业务分立出来。</p>
  <p>2018年，盘兴数智调整业务布局，将发展重心聚焦于国内SaaS市场。盘兴数智先后以127.13万元和261.76万元，收购了SCRM服务供货商杭州清柳和定制软件开发商北京远景，并实现控股。</p>
  <p>2021年，直播带货这一新兴业态爆火，盘兴数智成立天津禾越，进一步拓展在线营销业务，将业务范围延伸至抖音及快手的直播电子商务领域。</p>
  <p>至此，盘兴数智成功转型为一家提供在线营销解决方案、与办公室自动化系统及电子商务系统定制开发相关软件服务的供货商。</p>
  <p>在业务不断拓展的同时，盘兴数智获得资本市场的青睐。</p>
  <p>2021年和2024年，相继获得两轮融资，浙江大学教育基金会、南京景衍等纷纷斥资入股。经过这两轮融资，盘兴数智的估值达到了50.49亿元。</p>
  <h2><strong>02</strong></h2>
  <p>盘兴数智的主要产品包括线上营销解决方案和SaaS服务。</p>
  <p>其中，线上营销解决方案涵盖一站式服务、流量获取服务、直播电子商务服务等多个方面，主要作用是帮助客户获取线上流量、提升品牌曝光度，进而促进产品销售。2024年前9个月，该业务收入达到6.13亿元，占公司总收入的91%，成为公司营收的主要来源。</p>
  <p>而SaaS服务则包括云端软件供应、短讯服务、定制软件开发等，旨在为企业提供全方位的数字化运营支持。2024年前9个月，SaaS服务收入为5709万元，占比8.5%。</p>
  <p>在财务表现上，2022年，盘兴数智营收为4.91亿元，期内利润为667万元；到了2023年，营收跃升至8.12亿元，同比增长超过65%，期内利润也大幅增加至2516万元；2024年前9个月，营收达到6.73亿元，已超过2022年全年水平，上年同期营收为4.37亿元，同比增长54% ，期内利润为2201万元，上年同期为847万元。</p>
  <p>盘兴数智所处的赛道是在线营销和SaaS服务赛道，值得注意的是，内容电商平台（如抖音、快手）的崛起成为推动行业增长的重要因素。</p>
  <p>招股书称，这些平台凭借优质内容和强大的社交属性，吸引了大量消费者，具备良好的引流条件。内容电商平台的线上营销解决方案服务市场规模从2018年的36亿元增至2023年的1507亿元，复合年均增长率达到惊人的111.0%。预计到2028年，市场规模将达到5746亿元，复合年均增长率为30.7%。</p>
  <p>此外，随着去中心化电商平台在中国电子商务市场中的地位日益重要。去中心化电商平台的交易额从2018年的0.8万亿元增至2023年的4.1万亿元，复合年均增长率为38.7%。商家逐渐意识到在这些平台上发展终端客户和维护“私域流量”的重要性，这也进一步推动了对线上营销解决方案服务的需求。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI0NzAzNTUwMQ==&amp;mid=2652511929&amp;idx=3&amp;sn=94fd5c13208b02bd97e387088f0719ef&amp;chksm=f3f40ab8b1d22c8b15ef77799196251491d3fe2fd52a370dfb722624adfbc2a926ee2ebf7e54&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“铅笔道”（ID：pencilnews）</a>，作者：不说谎的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156482137135618</id>
            <title>历史分水岭：DeepSeek GitHub星数超越OpenAI，大佬揭秘仅用450美元训推理模型</title>
            <link>https://www.36kr.com/p/3156482137135618</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156482137135618</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:55:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, GitHub, 推理模型, 开源社区  
<br><br>  
总结: DeepSeek项目在GitHub上的Star数超越了OpenAI，成为开源AI历史上的里程碑。DeepSeek-V3的热度迅速上升，用户热情高涨，导致其暂停API充值。关于DeepSeek的谣言被专家辟谣，澄清了其与CUDA的关系及训练成本的误解。DeepSeek-R1和V3的发布将推动推理模型的发展，机器学习专家Sebastian Raschka对其方法论给予高度评价，并提出了提升LLM推理能力的四种方法。即使在预算有限的情况下，模型蒸馏和新方法如旅程学习也为推理模型的研究提供了新的可能性。 </div>
                        <hr>
                    
                    <p>刚刚，DeepSeek的GitHub星数，超越了OpenAI！V3的Star数，如今已经碾压OpenAI最热门的项目。机器学习大神的一篇硬核博文，直接帮我们揭秘了如何仅用450美元，训出一个推理模型。</p>
  <p>就在刚刚，历史性的一刻出现了。</p>
  <p>DeepSeek项目在GitHub平台上的Star数，已经超越了OpenAI。</p>
  <p>热度最高的DeepSeek-V3，Star数如今已达7.7万。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e8a7df8f5c3c403484be715a7d746a66@5888275_oswg184840oswg1080oswg473_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>做出这一发现的网友们，第一时间截下了图</p>
  <p>可以说，这是开源AI历史上的一个里程碑！</p>
  <p>而DeepSeek-R1，更是仅用了3周时间，就超越了「openai-cookbook」。</p>
  <p>前有App Store登顶，今有GitHub超越，网友们高呼：永远不要低估开源社区的力量！</p>
  <p>如今，DeepSeek的势头越来越猛。</p>
  <p>相信大家都发现，DeepSeek的服务器简直要爆了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_053e6c6e93c248e2861d79bf3b7a3240@5888275_oswg75551oswg1080oswg341_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>甚至就在昨天，DeepSeek还不得不官宣：暂停API充值。</p>
  <p>原因当然就是因为，用户的热情实在太火爆，服务器真扛不住了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a81723b15be24340b5a782944ce2dad5@5888275_oswg136953oswg1080oswg393_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最近，关于DeepSeek的一些流传甚广的说法，也纷纷有专家辟谣了。</p>
  <h2><strong>澄清一：DeepSeek绕过了CUDA架构</strong></h2>
  <p>其中一个广为流传的说法是DeepSeek绕过了CUDA。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_68a6354c1562472aa5e41c4d936cf5de@5888275_oswg204538oswg1080oswg406_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这源于DeepSeek的论文中提到，模型采用了PTX编程，通过这样的定制优化，让模型能更好地释放底层硬件的性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_84edc924446148a086440325365f478b@5888275_oswg374665oswg1080oswg369_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>「我们采用定制的PTX（并行线程执行）指令并自动调整通信块大小，这大大减少了L2缓存的使用和对其他SM的干扰」</p>
  <p>严谨来说，DeepSeek通过编写PTX解决了跨芯片通信瓶颈，虽然复杂，但降低了开销、提升了效率。</p>
  <p>本质上，PTX仍然是位于CUDA驱动层内部的一个组件，是英伟达CUDA编程模型的一部分，能将CUDA源代码（C/C++）转变为机器指令的一个中间阶段。</p>
  <p>在运行时，PTX会进一步被编译成在GPU上运行的最终机器码（SASS）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_85390a64b00b439694951c077dbf7dac@5888275_oswg156306oswg825oswg535_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而DeepSeek团队的聪明之处就在于，用这种方法能更好地实现对底层硬件的编程和调用。</p>
  <p>这种主动优化，无论在H800还是H100上都能提高通信互联效率。</p>
  <p>因此，DeepSeek仍然没有摆脱CUDA生态。</p>
  <h2><strong>澄清二：R1的训练成本，绝不仅仅是600万美元！</strong></h2>
  <p>而关于DeepSeek-R1的另一个谣言，就是R1的训练成本大约是600万美元。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_01462dbc311d4b7396caf1b6755e3b2d@5888275_oswg286936oswg1080oswg335_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之所以有这个说法，来源于DeepSeek-V3论文中的相关论述</p>
  <p>开发者大神Sebastian指出，很多人都混淆了DeepSeek-V3和DeepSeek-R1。（前者要早1个月）</p>
  <p>其中，DeepSeek-V3中宣称的550万美元，是基于GPU成本、GPU小时数、数据集规模和模型规模等估算出来的。</p>
  <p>但DeepSeek团队从没公开过R1确切的GPU小时数或开发成本，目前已有的任何成本估算都只是猜测。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f2b2cc61afaf41b59cdaf7a912f7e668@5888275_oswg67686oswg1080oswg429_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此之外，Stability AI前研究总监Tanishq Mathew Abraham也在最近的博文中指出，R1在V3基础上进行的强化学习，以及最终训练前团队的大量的小规模实验和消融研究都未包含在内。</p>
  <p>更何况还有研究者的薪资，据传已经跟OpenAI、Anthropic等顶级机构的薪资相当（高达100万美元）。</p>
  <h2><strong>V3和R1，开启推理模型大变局</strong></h2>
  <p>DeepSeek V3和R1发布后，将怎样搅动此后的LLM江湖？&nbsp;</p>
  <p>预算紧张的情况下，怎么开发推理模型？</p>
  <p>最近，机器学习大神Sebastian Raschka的这篇长篇博文，为我们做出了硬核预测，并且破除了不少民间对DeepSeek的误解。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3d1da8e26cea4084abe346e6ac9622a0@5888275_oswg58375oswg1080oswg208_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Sebastian表示，很多人都来询问自己对DeepSeek-R1的看法。</p>
  <p>在他看来，这是一项了不起的成就。</p>
  <p>作为一名研究工程师，他非常欣赏那份详细的研究报告，它让自己对方法论有了更深入的了解。</p>
  <p>最令人着迷的收获之一，就是推理如何从纯强化学习行为中产生。</p>
  <p>甚至，DeepSeek是在MIT许可下开源模型的，比Meta的Llama模型限制更少，令人印象深刻。</p>
  <p>在本文中，Sebastian介绍了构建推理模型的四种方法，来提升LLM的推理能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c92b491b84474bffbcf8cb26a1df1a0b@5888275_oswg205805oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>图中总结了DeepSeek R1的训练流程。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3d7cab1b0df4446c8ded5f8dad94ead5@5888275_oswg229200oswg1080oswg862_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>（1）DeepSeek-R1-Zero：该模型基于2024年12月发布的DeepSeek-V3。研究团队采用RL进行训练，并使用了两种奖励类型。这种方式称为冷启动训练，因为它没有采用RLHF中的SFT步骤。</p>
  <p>（2）DeepSeek-R1：这是DeepSeek的旗舰推理模型，构建于DeepSeek-R1-Zero基础上。团队通过额外的SFT阶段和进一步的RL训练，对模型进行了优化。</p>
  <p>（3）DeepSeek-R1-Distill：利用前述步骤中生成的SFT数据，团队对Qwen和Llama模型进行了微调，以增强它们的推理能力。尽管不是传统意义上的蒸馏，但该过程是用DeepSeek-R1的输出，来训练较小的模型（Llama 8B和70B，Qwen 1.5B–30B）。</p>
  <h2><strong>构建推理模型的四种方法</strong></h2>
  <h3><strong>推理时扩展</strong></h3>
  <p>想要提升LLM的推理能力，或者是其他任何能力，有一种方法叫推理时扩展，就是在推理过程中增加计算资源，让输出的结果质量更高。&nbsp;</p>
  <p>人类在解决复杂问题时，如果思考时间更充裕，往往能给出更好的答案。</p>
  <p>有一种推理时扩展的简单方法，是巧妙的运用提示工程。思维链（CoT）提示法是一个经典例子，在处理复杂问题时，通常能得到更准确的结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_3cfd8d03fbad47ca84b8ac017759e21e@5888275_oswg224303oswg1080oswg283_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一种推理时扩展的方法是使用投票和搜索策略。</p>
  <p>一个简单的例子是多数投票方法，让LLM生成多个答案，然后通过投票选出正确答案。</p>
  <p>同样，也可以使用束搜索（beam search）和其他搜索算法来生成更好的响应。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_f898d6b3eefc44439d3fb3cd9df2602e@5888275_oswg297214oswg1080oswg620_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>推测OpenAI的o1和o3模型使用了推理时扩展。此外，o1和o3可能还运用了与DeepSeek R1类似的RL流程来训练。</p>
  <h3><strong>纯强化学习（RL）</strong></h3>
  <p>DeepSeek R1论文中的一个亮点是，推理行为可以通过纯强化学习（RL）产生。</p>
  <p>通常在RL训练之前，会先进行SFT，但DeepSeek-R1-Zero完全通过RL训练，没有初始的SFT阶段。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_70a21bc16707423a9af0d27ba21bdcc6@5888275_oswg238015oswg1080oswg868_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepSeek-R1-Zero的一个关键区别是它跳过了SFT阶段。</p>
  <p>在奖励机制上，DeepSeek没有采用基于人类偏好的奖励模型，而是采用了准确性奖励和格式奖励。</p>
  <p>- 准确性奖励，是用LeetCode编译器来验证编程答案，并用确定性系统评估数学回答。</p>
  <p>- 格式奖励，则靠LLM评判器，保证回答符合预期格式，比如把推理步骤放在标签里。</p>
  <p>让人意外的是，靠这种方法，LLM就能发展出基本的推理能力。</p>
  <p>研究人员观察到「顿悟时刻」：模型开始在回答中生成推理过程，即使没有专门训练它这么做。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2a2d0fbf74ae4788aff30fde35a5454f@5888275_oswg295140oswg1080oswg628_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>尽管R1-Zero并不是性能最优的推理模型，但它通过生成中间的思考步骤展示了推理能力。这证明用纯强化学习（RL）开发推理模型是可行的。</p>
  <h3><strong>监督微调和强化学习（SFT+RL）</strong></h3>
  <p>旗舰模型DeepSeek-R1通过结合额外的SFT和RL，提升了模型的推理表现。</p>
  <p>在RL之前进行SFT是常见的做法，标准的RLHF流程就是如此。OpenAI的o1模型很可能也是用类似方法开发的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_90ff3b4a341e4f859659b8f8d08148fe@5888275_oswg214162oswg1080oswg858_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如图所示，团队用DeepSeek-R1-Zero生成了冷启动SFT数据。通过指令微调训练模型，接着又进行了一轮RL。</p>
  <p>在这一轮RL中，保留了DeepSeek-R1-Zero的准确性奖励和格式奖励，还新增了一致性奖励，来避免语言混杂。</p>
  <p>RL结束后，又开始新一轮SFT数据收集。在这个阶段，用最新的模型生成了60万条CoT SFT示例，同时用DeepSeek-V3基础模型创建了另外20万条SFT示例。</p>
  <p>上述样本随后被用于另一轮RL训练。在这个阶段，对于数学和编程问题，还是用基于规则的方法进行准确性奖励。对于其他类型的问题，则用人类偏好标签来评判。</p>
  <p>经过多轮训练，DeepSeek-R1的性能有了显著提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b668665104594be8a944dd3c32454a8f@5888275_oswg184916oswg1080oswg340_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>纯监督微调（SFT）和蒸馏</strong></h3>
  <p>到目前为止，已经介绍了三种用于改进LLM推理能力的方法，最后是模型「蒸馏」。</p>
  <p>这里「蒸馏」是指用较大LLM生成的数据集对较小的LLM（如Llama 8B和70B以及Qwen 2.5模型，范围从0.5B到32B）进行指令微调。</p>
  <p>实际上，这个蒸馏过程中的SFT数据集，和之前用来训练DeepSeek-R1的数据集是一样的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_89a37e3671ed468cb93df4a7c0fd4a6b@5888275_oswg228206oswg1080oswg862_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为什么开发蒸馏模型？可能有两个关键原因：</p>
  <p>1 &nbsp;<strong>较小的模型更高效。</strong>小模型运行成本更低，还能在配置较低的硬件上运行。对研究人员来说很有吸引力。</p>
  <p>2 &nbsp;<strong>纯SFT的案例研究。</strong>这些模型展示了在没有RL的情况下，单纯靠SFT能把模型优化到什么程度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_69019d62c1754baa86755ba7d8b8fb25@5888275_oswg376470oswg1080oswg558_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>团队将DeepSeek-R1-Zero中的纯RL方法直接应用于Qwen-32B。</p>
  <p>结果表明，对于较小的模型，蒸馏远比纯RL更有效。</p>
  <p>仅靠RL可能不足以让小模型具备强大的推理能力，在高质量推理数据上进行SFT，或许是对小模型更有效的策略。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0e47ed19b45f40ea9d1aba31e32b24d0@5888275_oswg161520oswg1080oswg304_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接下来一个有趣的方向是把RL+SFT和推理时扩展结合起来，OpenAI的o1很有可能是这样做的，只不过它可能基于一个比DeepSeek-R1更弱的基础模型。</p>
  <h2><strong>R1和o1相比如何？</strong></h2>
  <p>Sebastian认为，DeepSeek-R1和OpenAI o1大致在同一水平。&nbsp;</p>
  <p>不过引人注目的一点是，DeepSeek-R1在推理时间上更高效。</p>
  <p>这就揭示了二者的区别：DeepSeek可能在训练过程中投入了更多，而OpenAI更依赖于o1的推理时扩展。</p>
  <p>而很难直接比较两个模型的难点，就在于OpenAI并没有披露太多关于o1的信息。</p>
  <p>现在关于o1，还有很多未解之谜。</p>
  <p>比如，o1也是一个MoE吗？它究竟有多大？</p>
  <p>或许，o1只是GPT-4o的一个略微改进版本，加上最小量的强化学习和微调，仅在推理时进行大规模scaling？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4eeb194c75d54f749af0ad10494c1a25@5888275_oswg64875oswg1080oswg217_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不了解这些细节，是很难直接比较的。</p>
  <h2><strong>预算只有几十万美元，能开发推理模型吗</strong></h2>
  <p>不过，想开发一个DeepSeek-R1这样的推理模型，哪怕是基于开放权重的基础模型，也可能需要几十万美元甚至更多资金。&nbsp;</p>
  <p>这对预算有限的研究人员或工程师来说，实在是望而却步。</p>
  <p>好消息是：蒸馏能开辟新路径！</p>
  <p>模型蒸馏提供了一个更具成本效益的替代方案。</p>
  <p>DeepSeek团队的R1蒸馏模型证明了这一点，尽管这些模型比DeepSeek-R1小得多，推理表现却强得惊人。</p>
  <p>不过，这种方法也不是完全没有成本。他们的蒸馏过程用了80万条SFT样本，这需要大量的计算资源。</p>
  <p>有趣的是，就在DeepSeek-R1发布的前几天，关于Sky-T1的文章中，一个团队用1.7万条SFT样本，就训练出了一个32B参数的开放权重模型。</p>
  <p>总成本仅有450美元，甚至比大多数人AI会议的注册费还低。</p>
  <p>Sky-T1的表现和o1大致相当，考虑到它的训练成本，着实令人惊叹。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_91a6dde7299f453fada01720ef6e0e90@5888275_oswg139899oswg1080oswg451_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">项目链接：https://novasky-ai.github.io/posts/sky-t1/</p>
  <h3><strong>预算有限的纯强化学习：TinyZero</strong></h3>
  <p>TinyZero是3B参数的模型，它借鉴了DeepSeek-R1-Zero的方法，其训练成本不到30美元。</p>
  <p>令人意外的是，尽管只有3B参数，TinyZero仍展现出一些突现的自我验证能力，这证明了小模型通过纯RL也能产生推理能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_92dea5f6ffb648b7a16ccfb9c4a38f3d@5888275_oswg593621oswg1080oswg664_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这两个项目表明，即使预算有限，也可以进行有趣的推理模型研究。</p>
  <p>两者都借鉴了DeepSeek-R1的方法，一种聚焦于纯RL（TinyZero），另一种聚焦于纯SFT（Sky-T1）。</p>
  <h3><strong>超越传统SFT：旅程学习</strong></h3>
  <p>旅程学习被视作捷径学习的替代方案。捷径学习是传统的指令微调方法，模型仅通过正确的解题路径来训练。</p>
  <p>旅程学习不仅包括正确的解题路径，还包括错误的解题路径，让模型从错误中学习。</p>
  <p>这种方法和TinyZero在纯RL训练中展现的自我验证能力有相通之处，不过它完全依靠SFT来优化模型。让模型接触错误推理路径及修正过程。</p>
  <p>旅程学习或许有助于加强自我纠错能力，提升推理模型的可靠性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e8ee1b12653c454386ba6bf5c94b1afd@5888275_oswg215255oswg1080oswg524_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文链接：https://arxiv.org/abs/2410.18982</p>
  <p>这一方向对于未来的研究极具吸引力，特别是在低预算的推理模型开发场景中，RL方法可能由于计算成本过高而难以落地。</p>
  <p>当前在推理模型领域正有诸多有趣的研究，Sebastian充满期待地表示：相信在未来几个月，还会看到更多令人兴奋的成果！</p>
  <p>参考资料：&nbsp;</p>
  <p>https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&nbsp;</p>
  <p>https://www.tanishq.ai/blog/posts/deepseek-delusions.html&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/RpkiXldGPnoR6GJaujYbgg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156464642382600</id>
            <title>从CES到春晚舞台 京东热卖的智能机器人都有哪些黑科技？</title>
            <link>https://www.36kr.com/p/3156464642382600</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156464642382600</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:42:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人形机器人, 智能产品, 消费者需求, AI技术  
<br><br>  
总结: 2025年，京东通过“人机数码3C BOT奇遇季”活动，展示了多款人形机器人和智能产品，满足消费者在生活、工作和学习中的需求。活动期间，京东与多家科技品牌合作，推出了教育陪伴、安全守护和效率提升等功能的机器人，帮助消费者解决实际问题。此外，京东还提供了AI相关图书，帮助消费者了解机器人技术。未来，京东将继续关注用户需求，深化与机器人品牌的合作，推出更多智能产品。 </div>
                        <hr>
                    
                    <p>从CES 2025的热门焦点，到春晚舞台C位，再到跳起《APT》、成为火遍全网的表情包，2025年的开年阶段，包括宇树科技等品牌在内的人形机器人彻底出圈。京东同步开启了“人机数码3C BOT奇遇季”活动，携手前沿科技品牌带来了诸多智能机器人产品，可满足消费者生活、工作、学习等诸多场景中的使用需求，消费者打开京东搜“3C数码机器人”或“春晚同品牌机器人”即可进入活动会场浏览下单。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_25b0a83c93da4016ae39107b5c0e576d@1267484143_oswg272545oswg456oswg367_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>京东一早便关注到机器人的广泛应用场景，并提前布局，陆续引入了包括宇树科技、蔚蓝科技、时空壶、云深处等品牌在内的多款机器人产品。值得一提的是，在CES 2025期间，京东采销曾深入展会现场，与宇树科技的Unitree G1、Unitree H两款人形机器人，元萝卜的AI下棋机器人，云深处科技的绝影X30 Pro、Lite 3两款智能四足仿生机器人等深度互动，为消费者展现了智能机器人各种令人震撼的灵活表现，并第一时间将智能机器人新品上线，为用户带来全新的科技体验。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1d011b5968794edd8813c51bac19a418@1267484143_oswg980715oswg1175oswg880_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p>如今智能机器人都有哪些种类，它们分别都具备何种功能呢？本次京东上线的人机数码3C BOT奇遇季活动，不仅汇聚了海量智能机器人产品，也针对许多消费者的疑问进行了详细科普。其中，教育陪伴机器人能根据孩子的学习进度和兴趣推荐适合的学习内容，激发孩子学习兴趣；安全守护机器人可以充当家庭的安全卫士，通过摄像头进行远程监控，让消费者随时随地了解家中的安全情况；效率提升机器人可以自动完成拖地、擦窗、烹饪、用户指引等多种工作，让消费者能从这些工作中脱离出来，更高效地完成生活工作目标。</p>
  <p>对于不了解机器人产品的消费者，京东还上线了学习AI专区，提供了多种多样AI相关的图书产品，帮助消费者解锁AI机器人从入门操作到核心技术的完整知识链。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5c60b70a3315428da337fada0b4883b9@1267484143_oswg450564oswg990oswg436_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>具体到产品层面，宇树Go2-Pro长续航机器狗在GPT大模型加持和大规模的AI模拟训练基础上，能帮助孩子在人文历史、算术猜谜、知识问答等多种方面有所成长，简单易上手的图形化编程功能还能率先开发孩子的创新意识。在此前京东3C数码采销直播间“神奇红马甲探展CES”72小时不间断直播中，消费者跟着京东采销，云观看到了Go2机器人上下楼梯、跳跃、倒立等高难度动作展现，不少消费者在直播间留言感叹“太神奇了”。此外，蔚蓝阿尔法机器狗、大疆DJI机甲大师、可立宝Loona机器狗等多款产品也在教育陪伴方面有着出色表现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6b9020bbb23247369fb8df9b6b4b33b7@1267484143_oswg238986oswg472oswg910_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>随着消费需求愈加多元化，如今消费者对安全守护的需求覆盖了宠物、儿童、老人等多个群体，活动会场中的enabot一诺宠物陪伴机、PICKFUNAI看宠小助手、星空大白AI定制机器人、enabot EBO SE全屋移动监控摄像头、萤石RK2Pro智能机器人等产品能满足消费者对于儿童、老人、宠物的看护需求，更精准地实现安全守护。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e0558bacf6c44aa2b9fd1afd3015e248@1267484143_oswg361349oswg514oswg975_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>在效率提升方面，科梦奇迎宾讲解接待机器人、欧克森全自动双向喷水擦窗机器人、添可智能料理机、乐天派智能桌面机器人、科沃斯擦窗机器人、广库全自动写字机器人能帮助消费者完成客户或用户接待、日常家务、烹饪、撰写材料等基础工作，让消费者能以更高的效率投入更重要的工作中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_412900040a43417f851fb2563c6ebe7d@1267484143_oswg348657oswg576oswg1101_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>除上述新款智能机器人外，消费者还可在京东购买《AI时代：弯道超车新思维》、《奇点更近》等AI相关图书产品，更深入地了解AI机器人科学原理和知识链路，从机器人小白成为机器人高手。</p>
  <p>从CES 2025京东采销探展，再到上线人机数码3C BOT奇遇季活动，京东始终关注用户的消费需求和行业的前沿发展，第一时间为消费者带来科技新品，让每位来京东的消费者都能更快尝鲜自己心仪的机器人产品。未来，京东也将持续深化与各大机器人品牌的合作，为消费者带来更多更智能、更灵活、更全能的机器人产品。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156419972660742</id>
            <title>大厂“拥抱”Deepseek，打不过就加入？</title>
            <link>https://www.36kr.com/p/3156419972660742</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156419972660742</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:22:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, Deepseek, 开源, 技术创新  
<br><br>  
总结: 文章讨论了人工智能在春节期间成为社交热点，特别是Deepseek的崛起。Deepseek以低成本和高性能颠覆了传统大模型行业，吸引了国内外科技巨头的关注。其开源策略和创新的模型训练方法使其在技术上取得了显著突破，成为行业的“变量”。尽管面临安全性和政策争议，Deepseek的出现为大模型行业带来了新的机遇和挑战，推动了整个生态的发展。 </div>
                        <hr>
                    
                    <p>这个春节，人工智能无疑成为了社交话题的C位，前有人形机器人在春晚跳扭秧歌而出圈，后有“Deepseek”的强势崛起。</p>
  <p>网友们疯狂涌入Deepseek，有人找Deepseek算命，有人问Deepseek怎样才能暴富，还有科技金融行业的打工人，年还没有过完，就得忙着加班写研报、测试模型。</p>
  <p>但海外市场对此却态度微妙，OpenAI一度宣称Deepseek“偷窃”了其“技术成果”，但一转头，微软、英伟达等大厂都宣布在自家产品中接入Deepseek，OpenAI CEO山姆·奥特曼更表示Deepseek的R1模型“令人印象深刻”。</p>
  <p>国内的互联网巨头们也没有错失这波Deepseek的热度，2月6日，有道正式宣布全面拥抱DeepSeek-R1。此外，Hi Echo、有道智云、QAnything等产品也将全面接入DeepSeek的推理能力，并于近日陆续升级。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_e851d5d2e4784fdf96f8590c8e5f2166@5333136_oswg375561oswg731oswg1016_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一时之间，这场AI大模型的技术迭代，不知不觉就演变成全球科技行业的现象级事件，Deepseek也被视为引领大模型行业从“大而全”到“小而美”的全新变量。</p>
  <p>但热闹过后，Deepseek还需要回答更多的新问题，全球大模型行业该如何抓住“变革的火花”，或许才是接下来的关键。</p>
  <h2><strong>01 三大变量引爆Deepseek</strong></h2>
  <p>在普通用户看来，Deepseek是在此次中美大模型技术之争中“一战成名”，但更早之前，Deepseek便已经因为“价格便宜”而被AI圈广泛关注。</p>
  <p>去年中，国内大模型行业大打“价格战”，但第一个“挑起战火”的并非阿里、百度等大厂，而是Deepseek，彼时其新推出的DeepSeek-V2价格仅为 GPT-4-Turbo 的百分之一左右。</p>
  <p>此次“降价”也让Deepseek被冠以“AI界拼多多”之称，但相较于大厂们的“以价换市场”的惯常做法，Deepseek对于“降价”并没有太多压力，因为其降价之后也仍有利润。</p>
  <p>事实上，这才是Deepseek能够震惊全球科技界的主要原因，其能够以更低的成本换来更高的性能，颠覆了过去大模型行业依靠堆显卡、堆资本来发展AI的“Scaling law”。</p>
  <p>这是因为Deepseek的模型训练路径不同于传统通用大模型，以ChatGPT为代表的传统AI，主要采用监督微调（简称 SFT）作为大模型训练的核心环节，即通过人工标注数据进行监督训练，再结合强化学习进行优化，本质上大模型并不会思考，只是通过模仿人类思维方式来提升推理能力。</p>
  <p>但在1月底发布的Deepseek-R1-Zero却颠覆了这一规则，其对模型架构进行了全方位创新，通过单纯的强化学习（RL）训练实现推理能力。简单来说，SFT是人类生成数据，机器学习；而RL是机器生成数据，机器学习。</p>
  <p>除此以外，据每日财经新闻报道，DeepSeek创新性地同时使用了FP8、MLA（多头潜在注意力）和MoE（利用混合专家架构）三种技术。</p>
  <p>其中，相较于其他模型使用的MoE架构，DeepSeek-V3的更为精简有效，其就像是医院的“分诊制度”，可以将大模型拆分成多个“专家”，训练时分工协作，推理时根据任务分配给最适合的专家模块。据悉，Deepseek能够将无效训练从传统模型的90%降低至60%。</p>
  <p>在Deepseek-R1发布后，一位Meta员工在美国匿名职场社区teamblind上留言，称Deepseek最近的一系列动作让Meta的生成式AI团队陷入了恐慌。</p>
  <p>据这位员工爆料，“Meta一个负责AI项目的高管年薪拿出来，就足够训练Deepseek了”。据每日经济新闻报道，Deepseek R1的预训练费用只有557.6万美元，还不到OpenAI GPT-4o模型训练成本的十分之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8d92248ee8bc4fba9fc0d2f15654d91f@5333136_oswg268894oswg1108oswg838_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但从实际性能来看，Deepseek-R1已经能够比肩OpenAI-o1正式版，特别是在数学、代码、自然语言推理等任务上。</p>
  <p>在美国数学竞赛（AMC）以及全球顶级编程竞赛（codeforces）等权威评测中，DeepSeek-R1-Lite-Preview 模型已经大幅超越了 GPT-4o 等顶尖模型，有三项成绩还领先于 OpenAI o1-preview。</p>
  <p>除了“低成本、高算力”这一突破之外，Deepseek之所以在这个春节“燃起来”，还因为其竟然不是出自传统的大厂，而是一家量化基金公司。</p>
  <p>Deepseek成立于2023年12月，在此之前，其创始人梁文锋于2015年便成立了名为“幻方量化”的量化对冲基金，可以说Deepseek的前身其实是服务于量化交易的。</p>
  <p>这样的背景也为Deepseek增添了更多“看点”，比如梁文锋之所以不差钱，是因为其在量化交易上赚得风生水起，网友甚至戏称Deepseek的训练成本是来自于造空英伟达。</p>
  <p>还有背靠千亿量化基金的梁文锋，明明可以选择轻松躺赚，却选择投身到全球创新的浪潮里，他坦言“对AGI的好奇与探索比商业回报更具驱动力”，这种一往无前的“理想主义”，想让也让Deepseek的“故事”变得更加动人。</p>
  <h2><strong>02 大厂打不过就加入</strong></h2>
  <p>不过，技术上的逆袭，尚不足以彻底震惊科技界，真正引爆Deepseek的变量，其实是“开源”。据悉，Deepseek已经把模型架构和参数开源，在大模型公司普遍选择闭源的当下，训练数据的开源在业界少有先例。</p>
  <p>梁文锋曾在媒体采访中表示，“过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。我们的出发点不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。”</p>
  <p>从商业角度来看，“开源”是不是一个更佳的策略，尚难以下定论。毕竟训练模型需要成本，招揽用户也需要推广费用，从此前字节豆包大规模投放广告、kimi多次接受融资就可以看出，大模型公司有自己的难处。</p>
  <p>但对于中国大模型行业来说，或许正是梁文锋的“理想主义”，才让Deepseek能够成为颠覆行业格局的“变量”。</p>
  <p>一方面，开源将能吸引更多大厂和技术人才加入，通过共建共创让Deepseek变得更加强大，从而推动整个人工智能大模型生态的发展，形成一个全新的生态。</p>
  <p>梁文锋曾对媒体表示，公司未来不会像OpenAI一样选择从开源走向闭源，“我们认为先有一个强大的技术生态更重要” 。</p>
  <p>另一方面，对于以OpenAI为代表的竞争对手来说，这也是一个致命的打击。毕竟，当一个旗鼓相当的，还是免费的产品出现在消费者面前，大家难免就会进行比较，谁的性价比更高，谁的性能更优秀，都需要实打实的使用效果来验证，而不仅仅只是“吹泡沫”。</p>
  <p>而率先作出选择的，便是一众海外大厂，目前包括英伟达、英特尔、亚马逊、微软、AMD、等海外科技大厂，均宣布在自家产品中接入Deepseek。</p>
  <p>值得一提的是，欧美多国对于Deepseek的安全性、隐私问题依然存在质疑。美国多位官员表示正在对Deepseek开展国家安全调查，包括国防部、国会和NASA等部门均被要求禁用Deepseek。</p>
  <p>此外，据彭博社等媒体报道，微软还曾调查 OpenAI 技术输出的数据是否被中国的Deepseek团队以未经授权的方式获取，比如通过“蒸馏技术”非法获取其模型输出数据。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_881bc69f6d574b33ad204879ab0839cc@5333136_oswg280855oswg1108oswg1128_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但在这些争议尚未解决之前，大厂们显然已经迫不及待想要加入Deepseek生态，本质上还是基于“利益至上”的原则。</p>
  <p>据斯坦福大学计算机科学系和电子工程系副教授吴恩达表示，OpenAI - o1模型每百万输出token 的成本为60美元，而Deepseek-R1 则仅需 2.19 美元，这接近30倍的成本差距，相信大厂们也会算账。</p>
  <p>其次则是生态效应，吴恩达认为，“降价”+“开源”正在将基础模型层商品化，为应用开发者创造了巨大的机遇。尽早加入这一生态，让自家大模型与之相结合，也有望带来更多创新体验，“收拢”部分DeepSeek用户的需求。</p>
  <p>因此，除了海外大厂之外，诸如阿里云、百度云等国内大厂也开始集中接入Deepseek，在各自平台提供的适配服务，打不过就加入，才能共享创新红利。</p>
  <h2><strong>03 乘上Deepseek的东风</strong></h2>
  <p>事实上，在开春爆火的Deepseek，不仅为大模型行业带来了一阵“春风”，对于普通用户来说，也带来了更多新机会。</p>
  <p>第一批利用Deepseek搞钱的人已经出现了，跟彼时横空出世的ChatGPT一样，面对更加智能、更加高效的大模型，AI取代人类的焦虑感，再次成为收割用户的“武器”。</p>
  <p>社交平台上已经出现了不少“如何使用Deepseek进行XXX”的课程，面向社交媒体、电商、广告等不同行业的应用和变现。</p>
  <p>当然，学习新知识肯定是没错的，但相较于被焦虑感“收割”，并沦为大V私域流量中的一员，大家不妨根据自己的实际工作和擅长内容，先上手试用一下Deepseek。</p>
  <p>目前来看，Deepseek在技术上确实有意想不到的突破，对于普通用户来说，其能够展示思维链全过程，更方便人类与AI交流，业内人士甚至称之为当前最好用的开源模型，但也不需要过度“神化”Deepseek。</p>
  <p>首先，从使用体验来看，Deepseek尚无法承受蜂拥而至的流量。其实，Deepseek在年前便已经小范围的“爆火”，其当时尚能同时使用深度思考和联网功能，输出的文章框架和成文确实比较惊艳。</p>
  <p>但随着使用者不断增多，目前Deepseek已经关闭了联网功能，整理输出质量有较大的下降，且大部分时间Deepseek都呈现“服务繁忙”的状态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b1c84842499e49c093f6dc24b96b62d4@5333136_oswg92743oswg1108oswg768_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>虽然梁文锋曾表示“商业化”不是当前首要考虑的问题，但按私募基金的体量来推算“幻方”的资金规模，千亿规模不等于千亿资金体量，“幻方”只是在千亿规模上收取管理费，其跟大厂之间的资金差距还是很大的。</p>
  <p>但要继续维持C端的使用体验，Deepseek必然需要烧钱，后续如何补充资金，还是调整使用模式，梁文锋都需要提出更明确的打法。</p>
  <p>其次，目前Deepseek在图文、视频方面的能力是缺失的，现阶段要说Deepseek能够与头部闭源模型直接打擂台，恐怕还为时尚早。</p>
  <p>不过，其发展也给Open AI，以及更多垂直模型带来了压力，相信将能在一定程度上推动整个大模型生态的发展。</p>
  <p>最后，Deepseek依然面临着政策、数据安全等争议，要走向全球依然是漫漫长路；此外，其在计算资源与算力方面依然受限，这意味着国产硬件还需要继续努力，才能支撑软件的不断创新。</p>
  <p>当然，对于全球大模型行业来说，有竞争才有动力，就像智能手机行业一样，参与者多了，行业盘子就会越来越多，也才有机会爆发出更多的机会。</p>
  <p>Deepseek的出现就像是国内大模型行业的一点“火花”，既是思维碰撞的突破，也是灵感乍现的瞬间。接下来，相信还需要国内大模型行业在软硬件方面的持续创新，才能抓住这一机遇，让中国科技行业能够从“跟随者”向“引领者”进发。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/EKAaKXY2oPJ-cqnDUuNGNg" rel="noopener noreferrer nofollow" target="_blank">“新媒科技评论”</a>，作者：新媒编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156289666964231</id>
            <title>DeepSeek 在人工智能全球化战略下需要面对的几个难题</title>
            <link>https://www.36kr.com/p/3156289666964231</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156289666964231</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:21:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据隐私, 地缘政治, 市场信任, 可持续性  
<br><br>  
总结: DeepSeek自2024年底以来成为生成式人工智能的焦点，但面临多重挑战。首先，数据隐私问题可能影响其国际客户的信任，尤其是在严格的法律环境中。其次，地缘政治紧张局势可能限制其获取资源和市场扩展。市场认知方面，DeepSeek需克服低成本模式带来的信任问题。长期维持低价的可持续性也存在风险，可能影响其研发和服务质量。此外，竞争激烈的市场环境和复杂的监管框架也给DeepSeek带来压力。 </div>
                        <hr>
                    
                    <p>自 2024 年底以来，DeepSeek 已成为生成式人工智能的焦点，并发布了迄今为止最出色的两个模型 DeepSeek-V3 和 DeepSeek-R1。OpenAI 作为生成式人工智能的代表，已退居谷歌、Facebook 等其他巨头的后方。</p>
  <p>但我认为 DeepSeek应考虑应对以下问题实现全球化战略：</p>
  <h2><strong>数据隐私问题</strong></h2>
  <p>DeepSeek 是一家中国公司，在数据隐私方面可能会面临越来越多的质疑，尤其是在处理敏感信息时。对用户数据如何处理、存储以及可能与政府实体共享的担忧可能会阻碍国际客户。</p>
  <p>在数据隐私法严格的地区，例如欧盟（GDPR）或美国，DeepSeek 可能会在确保合规性方面遇到挑战。</p>
  <p>如果客户认为他们的数据可能被未经授权的一方或政府访问，他们可能会选择避免使用 DeepSeek 的服务，从而限制其市场范围。</p>
  <h2><strong>地缘政治问题</strong></h2>
  <p>DeepSeek 的运营<strong>环境对地缘政治极为敏感。</strong>由于中国与美国和欧盟等其他主要科技市场之间的紧张关系持续存在，DeepSeek 的运营可能会受到贸易限制、关税或制裁的阻碍。</p>
  <p>例如，如果美国或欧盟实施限制获取先进计算硬件的法规，或限制关键技术的出口，DeepSeek 可能难以获取扩大业务规模所需的资源。</p>
  <p>此外，各国可能会基于国家安全考虑阻止或监管 DeepSeek 服务的使用，从而影响其全球扩张的能力。</p>
  <h2><strong>市场认知和信任</strong></h2>
  <p>尽管 DeepSeek 提供具有成本效益的解决方案，但它可能难以获得与 OpenAI 和 Google 等更成熟的公司同等程度的信任。潜在客户可能会对提供明显更便宜服务的公司持怀疑态度，认为其质量可能较低或可靠性较低。</p>
  <p>打造强大的品牌并赢得客户信任可能会很困难，特别是如果 DeepSeek 被视为“低预算”选择而不是创新领导者的话。</p>
  <h2><strong>低成本模式的可持续性</strong></h2>
  <p>DeepSeek 的商业模式大大削弱了 OpenAI 等竞争对手，吸引了人们的注意并占据了市场份额。然而，<strong>长期维持如此低的价格可能具有挑战性。</strong></p>
  <p>开发、维护和改进 AI 模型的成本非常高昂，需要对研究、人才和计算资源进行投资。<strong>为了保持低价，DeepSeek 需要不断寻找降低成本的方法，</strong>但随着公司规模的扩大，这种方法可能难以为继。</p>
  <p><strong>另外，其低成本模式还</strong>存在无法产生足够收入来资助进一步发展的风险，这可能迫使 DeepSeek 提高价格或降低服务质量以保持盈利。</p>
  <p>如果竞争对手已经拥有更强大的财力支持，在产品供应方面表现出色或设法降低成本，那么 DeepSeek 可能难以参与竞争。</p>
  <h2><strong>竞争市场动态</strong></h2>
  <p>人工智能领域挤满了主要参与者，包括 OpenAI、Google DeepMind 和 Microsoft。随着越来越多的公司进入生成式人工智能领域，DeepSeek 可能会发现很难脱颖而出或保持竞争优势。</p>
  <p>虽然 DeepSeek 最初凭借低成本定价策略取得了成功，但许多 AI 公司正在大力投资研发和云基础设施。这些竞争对手在模型准确率和功能集方面都可能超越 DeepSeek。</p>
  <p>如果 DeepSeek 未能跟上创新的步伐，或者无法找到大幅扩展其技术的方法，其市场份额可能会被更大、更成熟的公司抢走。</p>
  <h2><strong>监管挑战：</strong></h2>
  <p>在多个国家开展业务需要遵守各种复杂的监管框架。特别是，人工智能是一个受到严格审查的行业，其公平性、透明度和问责制备受关注。</p>
  <p>在某些司法管辖区，规范人工智能部署的新法律（例如欧盟的《人工智能法案》）可能会迫使 DeepSeek 修改或限制其产品，从而使得在遵守这些法规的同时保持有竞争力的价格变得更加困难。</p>
  <h2><strong>缺乏多样化</strong></h2>
  <p>DeepSeek 专注于提供低成本的 AI 解决方案，这可能会限制其收入来源多元化的能力。该公司可能会过度依赖某个细分市场（例如，生成式 AI 服务），而错失其他领域的增长机会。</p>
  <p>如果对生成式人工智能的需求放缓或面临竞争加剧，DeepSeek 可能会因缺乏明确的多元化计划而陷入困境。</p>
  <h2><strong>可扩展性问题</strong></h2>
  <p>尽管 DeepSeek 已经开发出高效的模型，但将其扩展到更广泛的企业级应用可能会带来挑战。AI 模型需要强大的计算能力才能大规模运行，而 DeepSeek 在服务大型客户或处理复杂的实时数据时可能难以保持成本效益。</p>
  <p>如果 DeepSeek 无法在不产生难以承受的成本的情况下有效扩展其基础设施，其业务可能会面临巨大的财务压力。</p>
  <h2><strong>免费的可持续</strong></h2>
  <p>大多数中国人工智能产品/模型，无论是 Kling AI 还是 MiniMax，都是开始免费提供服务，然后收取高额费用。</p>
  <p>因此看起来 DeepSeek 可能走上了同一条道路，因为在消费者甚至企业硬件上运行 DeepSeek-V3 和 Deep-Seek-R1 是不可能的。</p>
  <p>因此，即使开源，对大多数 AI 供应商来说也可能没有多大用处，而且 DeepSeek 可能很快就会增加 API 成本。</p>
  <h2><strong>最后</strong></h2>
  <p>虽然 DeepSeek 在生成式人工智能领域确实掀起了波澜，但其长期可持续性仍是一个问题。地缘政治紧张局势、监管障碍和不可持续的低成本模式可能会严重挑战其增长轨迹。再加上建立信任、扩展基础设施和与老牌科技巨头竞争的复杂性，很明显 DeepSeek 未来面临着重大障碍。然而，这些只是我的观点，而且考虑到目前的情况，DeepSeek 应尽快加强应对措施的制定。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzIwOTIyMDE1NA==&amp;mid=2247502236&amp;idx=1&amp;sn=89e5f882fceca7a506809d2f5c49324a&amp;chksm=966f9f55b7e41de96ddabd81b81d5f15cc07599d60114ebdf64af35bc790f88e42689be099eb&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“数据驱动智能”（ID：Data_0101）</a>，作者：晓晓，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156393016842758</id>
            <title>DeepSeek引爆AI，国产GPU集体撑腰</title>
            <link>https://www.36kr.com/p/3156393016842758</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156393016842758</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:12:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, 人工智能, 开源模型, 国产芯片  
<br><br>  
总结: DeepSeek是一家专注于高性能、低成本AI模型的公司，其最新发布的DeepSeek-V3和DeepSeek-R1模型在AI领域引起了广泛关注。DeepSeek-V3采用6710亿参数的MoE架构，处理速度是前一版本的三倍，而DeepSeek-R1则适合轻量级部署。DeepSeek的优势在于其低成本和高效能，训练成本仅为GPT-4的二十分之一，同时支持开源和灵活部署，促进了技术共享。随着DeepSeek的成功，国产芯片公司也迎来了新的发展机遇，推动了国产AI芯片的市场应用和生态建设。 </div>
                        <hr>
                    
                    <p>近日，想必诸多用户都怀揣着这样的疑惑：我的手机为何频频推送关于DeepSeek的资讯？这 DeepSeek 究竟是什么？它又为何能在问世之际，就引发如此热烈的关注与轰动？</p>
  <p>DeepSeek，全称杭州深度求索人工智能基础技术研究有限公司，其起源于一家中国的对冲基金公司High-Flyer。2023年5月High-Flyer剥离出一个独立实体，也就是DeepSeek。这是一家致力于打造高性能、低成本的 AI 模型。它的目标是让 AI 技术更加普惠，让更多人能够用上强大的 AI 工具。</p>
  <h2><strong>DeepSeek-V3与DeepSeek-R1的核心差异</strong></h2>
  <p>去年12月26日，DeepSeek AI正式发布了其最新的大型语言模型DeepSeek-V3。这款开源模型采用了高达6710亿参数的MoE架构，每秒能够处理60个token，比V2快了3倍。一经发布，就在 AI 领域引起了轩然大波。</p>
  <p>时隔不足一个月，在今年1月20日，深度求索又正式发布推理大模型DeepSeek-R1。DeepSeek-R1的发布，再次震撼业界！</p>
  <p>1月27日，DeepSeek应用登顶苹果中国区和美国区应用商店免费App下载排行榜。1月31日，英伟达、亚马逊和微软这三家美国科技巨头，在同一天宣布接入DeepSeek-R1。</p>
  <p>关于DeepSeek-V3与DeepSeek-R1-Distill 蒸馏模型的区别：</p>
  <p><strong>DeepSeek-V3</strong></p>
  <p>适合复杂任务处理和高精度场景，如长文档分析、多模态推理、科研计算等。</p>
  <p>支持千卡级训练，满足超大规模集群分布式训练需求。</p>
  <p><strong>DeepSeek-R1-Distill 蒸馏模型</strong></p>
  <p>适合轻量级部署和资源受限场景，如边缘设备推理、中小企业快速验证 AI 应用。</p>
  <p>在显存和算力要求上更为灵活，适配入门级硬件 。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6be9495964914ca19ec7bd82c9894a35@000000_oswg88780oswg1080oswg430_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：Gitee AI</p>
  <p>近日，硅谷顶尖风险投资家、a16Z联合创始人Marc Andreessen发文引用SensorTower数据：目前DeepSeek日活用户数已经达到了ChatGPT的23%，并且应用每日下载量接近500万。</p>
  <p>2月5日，京东云宣布正式上线DeepSeek-R1和DeepSeek-V3模型，支持公有云在线部署、专混私有化实例部署两种模式。前几日，阿里云、百度智能云、华为云、腾讯云、火山引擎、天翼云已接入了DeepSeek模型。海外的亚马逊AWS、微软Azure等云巨头同样官宣支持。</p>
  <p>那么，DeepSeek究竟是以何种独特魅力，赢得了广大用户的青睐与喜爱呢？</p>
  <h2><strong>DeepSeek的两大优势</strong></h2>
  <p>市场热捧的产品，往往有个显著共性：能帮用户降本增效。这，同样是 DeepSeek 的优势所在。</p>
  <p><strong>首先在低成本与高效能方面</strong>，DeepSeek-V3的训练成本仅为557.6万美元（约为GPT-4的二十分之一），却能在逻辑推理、代码生成等任务中达到与GPT-4o、Claude-3.5-Sonnet相近的性能，甚至超越部分开源模型（如Llama-3.1-405B）。其技术核心在于算法优化（如MoE架构、动态学习率调度器）和数据效率提升，而非依赖算力堆叠。</p>
  <p>作为对比，GPT-5一次为期6个月的训练仅计算成本就高达约5亿美元。</p>
  <p><strong>其次，开源与灵活部署也是DeepSeek的突出优势之一。</strong>DeepSeek选择将模型权重开源，并公开训练细节，这为全球的AI研究者打开了一扇通往模型内部的大门，让他们能够深入了解模型的训练过程、所采用的算法以及遇到的问题和解决方案。</p>
  <p>360集团创始人周鸿祎指出，DeepSeek真正践行了开放的精神。与OpenAI等关闭模式平台相比，DeepSeek允许开发者利用其开源模型进行技术挖掘和创新，这是对技术共享理念的有力支持。OpenAI虽然以“开源”自居，但随着商业化的推进，越来越多地选择封闭式策略，这与其创立初衷背道而驰。</p>
  <p>此外，周鸿祎特别提到DeepSeek的模型蒸馏技术，他认为这是一种极具前瞻性的实践。在他看来，DeepSeek对模型蒸馏的开放态度，展示了其自信与无私。相较之下，OpenAI对用户蒸馏其模型的限制，显示出其对竞争对手的排斥和对自身优势的维护。</p>
  <h2><strong>DeepSeek所需的GPU，主要来源于英伟达</strong></h2>
  <p>早期对AI技术和硬件基础设施的战略投资，为DeepSeek的成功奠定了基础。</p>
  <p>据SemiAnalysis评估，DeepSeek拥有大约50,000个Hopper架构的GPU，其中包括10,000个H800和10,000个H100型号。此外，他们还订购了大量的H20型号GPU，这些GPU专为中国市场设计。尽管H800与H100具有相同的计算能力，但其网络带宽较低。H20是当前唯一对中国模型提供商可用的型号。这些GPU不仅用于DeepSeek，也服务于High-Flyer，地理上分散部署，支持交易、推理、训练和研究等多种任务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_10f38e4a222e48b9ae928b07e84b7282@000000_oswg249918oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>至于DeepSeek如何获得如此多数量的Hopper GPU。</p>
  <p>早在2021年High-Flyer就看好AI的发展潜力并果断投资购买了10,000个A100 GPU，用于大规模模型训练实验。这项战略决策后来被证明是非常成功的，为公司带来了显著的竞争优势。</p>
  <p>在1月25日新年前，AMD就官宣将DeepSeek-V3模型集成到了Instinct MI300X GPU上。</p>
  <p>随后在1月31日，AI芯片龙头英伟达也官宣其NVIDIA NIM微服务预览版对于DeepSeek-R1模型的支持。NIM微服务基于HGX H200系统，每秒能够处理3872个tokens。开发者们可以调用API进行测试和试验，该API后续会作为英伟达AI企业软件平台的一部分提供。</p>
  <p>同日，英特尔宣布DeepSeek能够在搭载酷睿处理器的AI PC上离线使用。在酷睿Ultra 200H（Arrow Lake H）平台上，DeepSeek-R1-1.5B模型能够本地离线运行，做翻译、做会议纪要、进行文档撰写等任务。</p>
  <p><strong>要知道DeepSeek 在算力芯片受限的不利因素下，达到OpenAI等顶级模型的水平，是国内AI生态级的突破。</strong>如今，随着 DeepSeek 这类模型的发展，对 GPU 需求持续攀升。国产 GPU 厂商也敏锐捕捉到这一机遇，正在积极进行适配工作。他们深知，适配成功不仅能助力 DeepSeek 等模型更好地发展，也能为自身打开更广阔的市场空间，提升国产 GPU 在 AI 领域的影响力。</p>
  <h2><strong>11大国产AI芯片公司，宣布适配DeepSeek</strong></h2>
  <p>仅在2月1日至2月7日这短短7天内，就有11家国产AI芯片公司宣布完成对 DeepSeek 的适配 。</p>
  <h3><strong>DeepSeek系列新模型正式上线昇腾社区</strong></h3>
  <p>2月1日，华为云宣布与硅基流动联合首发并上线基于华为云昇腾云服务的DeepSeek R1/V3推理服务。得益于自研推理加速引擎加持，该服务支持部署的DeepSeek模型可获得持平全球高端GPU部署模型的效果。</p>
  <p>2月5日，华为宣布，DeepSeek-R1、DeepSeek-V3、DeepSeek-V2、Janus-Pro于2月4日正式上线昇腾社区，支持一键获取DeepSeek系列模型，支持昇腾硬件平台上开箱即用，推理快速部署，带来更快、更高效、更便捷的AI开发和应用体验。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4335f38cdb9940459734d1912fe0c9ef@000000_oswg200014oswg830oswg564_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>摩尔线程实现对DeepSeek蒸馏模型推理服务的高效部署</strong></h3>
  <p>2月4日，摩尔线程发文称已快速实现对DeepSeek蒸馏模型推理服务的高效部署，旨在赋能更多开发者基于摩尔线程全功能GPU进行AI应用创新。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ba007f382df54daeb38e1286b566087d@000000_oswg239003oswg866oswg474_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，用户也可以基于MTT S80和MTT S4000进行DeepSeek-R1蒸馏模型的推理部署。</p>
  <p>通过DeepSeek提供的蒸馏模型，能够将大规模模型的能力迁移至更小、更高效的版本，在国产GPU上实现高性能推理。摩尔线程基于自研全功能GPU，通过开源与自研双引擎方案，快速实现了对DeepSeek蒸馏模型的推理服务部署，为用户和社区提供高质量服务。</p>
  <h3><strong>DeepSeek V3和R1模型完成海光DCU适配并正式上线</strong></h3>
  <p>2月4日晚间，海光信息宣布公司技术团队成功完成DeepSeek V3和R1模型与海光DCU（深度计算单元）的适配，并正式上线。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a6740696b09344418900b42258196c28@000000_oswg306384oswg875oswg1278_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepSeek V3和R1模型采用了Multi-Head Latent Attention（MLA）、DeepSeekMoE、多令牌预测、FP8混合精度训练等创新技术，显著提升了模型的训练效率和推理性能。</p>
  <p>DCU是海光信息推出的高性能GPGPU架构AI加速卡，致力于为行业客户提供自主可控的全精度通用AI加速计算解决方案。凭借卓越的算力性能和完备的软件生态，DCU已在科教、金融、医疗、政务、智算中心等多个领域实现规模化应用。</p>
  <p>随着海光等专注于 GPU 研发的公司纷纷表示已完成对 DeepSeek V3 的适配。从这一现象来看，DeepSeek 模型在业界或许正逐渐获得较高的认可度与通用性。</p>
  <p>那么，<strong>海光 DCU 的哪些硬件特性和架构设计使得它能够很好地支持 DeepSeek V3 和 R1 模型的高效运行？</strong></p>
  <p>有业内人士表示，海光DCU采用了GPGPU架构，从而保证在面对新型应用的时候具备极好的兼容性与适配性；同时DCU配套的软件栈也经过了多年的积累，相应软件生态成熟丰富，在与新模型、应用适配的时候具备完备的软件支撑能力。以上共同保障了对于DeepSeek V3/R1为代表的新模型能够提供高效的兼容与支撑能力。</p>
  <p>值得注意的是，海光本次适配并没有用到额外的中间层工具，依托现有DCU软件栈就可以实现快速的支撑。这主要得益于DCU的GPGPU架构通用性和自身对主流生态的良好兼容，从而大幅提升了大模型等人工智能应用的部署效率。</p>
  <h3><strong>天数智芯联合Gitee AI正式上线DeepSeek R1模型服务</strong></h3>
  <p>2月4日，天数智芯与 Gitee AI 联合发布消息，在双方的高效协作下，仅用时一天，便成功完成了与 DeepSeek R1 的适配工作，并且已正式上线多款大模型服务，其中包括 DeepSeek R1-Distill-Qwen-1.5B、DeepSeek R1-Distill-Qwen-7B、DeepSeek R1-Distill-Qwen-14B等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9101192f343d406f8b6de7014dbe3c7e@000000_oswg258702oswg744oswg484_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>Gitee AI与沐曦携手首发DeepSeek R1系列千问蒸馏模型</strong></h3>
  <p>2月2日，Gitee AI 正式推出了四个轻量级版本的 DeepSeek 模型，分别为 DeepSeek-R1-Distill-Qwen-1.5B、DeepSeek-R1-Distill-Qwen-7B、DeepSeek-R1-Distill-Qwen-14B 和 DeepSeek-R1-Distill-Qwen-32B。尤为引人注目的是，这些模型均部署在国产沐曦曦云 GPU 上。</p>
  <p>上文曾提到，与全尺寸 DeepSeek 模型相比，较小尺寸的 DeepSeek 蒸馏版本模型更适合企业内部实施部署，可以降低落地成本。</p>
  <p>同时，这次Deepseek R1 模型 + 沐曦曦云 GPU + Gitee AI 平台，更是实现了从芯片到平台，从算力到模型全国产研发。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4482b73eb5614ed1bd2cff8d4c19b763@000000_oswg172576oswg1080oswg445_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随后在2月5日 Gitee AI宣布再次将DeepSeek-V3满血版（671B）上线到平台上（满血版目前仅供大家体验用途）。这也是 Gitee AI 继全套千问蒸馏模型上线沐曦 GPU 卡之后的又一大的更新。</p>
  <h3><strong>壁仞AI算力平台上线DeepSeek R1蒸馏模型推理服务，支持云端体验</strong></h3>
  <p>2月5日，壁仞科技宣布，凭借自主研发的壁砺系列GPU产品出色的兼容性能，只用数个小时，就完成对DeepSeek R1全系列蒸馏模型的支持，涵盖从1.5B到70B各等级参数版本，包括LLaMA蒸馏模型和千问蒸馏模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8865a3cee48d4f5bae14dbd29329c8eb@000000_oswg74841oswg582oswg636_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，壁仞科技已构建起从底层硬件到模型服务的完整AI技术栈，可为中小企业和研究机构提供“芯片+模型”的端到端解决方案。</p>
  <h3><strong>云天励飞DeepEdge10已完成DeepSeek R1系列模型适配</strong></h3>
  <p>2月5日，云天励飞宣布，其芯片团队完成 DeepEdge10 “算力积木”芯片平台与DeepSeek-R1-Distill-Qwen-1.5B、DeepSeek-R1-Distill-Qwen-7B、DeepSeek-R1-Distill-Llama-8B大模型的适配，可以交付客户使用。DeepSeek-R1-Distill-Qwen-32B、DeepSeek-R1-Distill-Llama-70B大模型、DeepSeek V3/R1 671B MoE大模型也在有序适配中。适配完成后，DeepEdge10芯片平台将在端、边、云全面支持DeepSeek全系列模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8fd837d8085b4fed8b5f7e5c35aaddbc@000000_oswg140562oswg1074oswg380_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_27ed50ecaeca4d0a8135f2c90a47d7e1@000000_oswg81197oswg742oswg268_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepEdge10系列芯片是专门针对大模型时代打造的芯片，支持包括 Transformer 模型、BEV 模型、CV 大模型、LLM 大模型等各类不同架构的主流模型；基于自主可控的先进国产工艺打造，采用独特的“算力积木”架构，可灵活满足不同场景对算力的需求，为大模型推理提供强大动力。</p>
  <h3><strong>基于太初T100加速卡2小时适配DeepSeek-R1系列模型</strong></h3>
  <p>2月5日，太初元碁Tecorigin表示，基于通用的异构众核芯片架构和深厚的软件生态积累，在太初T100加速卡上仅用2小时便完成DeepSeek-R1系列模型的适配工作，快速上线包括DeepSeek-R1-Distill-Qwen-7B在内的多款大模型服务，为人工智能应用的创新发展提供了强有力的技术支撑和自动可控的算力设施保障。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_73d3dd97317c45fa85ca700b6e64b9bf@000000_oswg128060oswg970oswg437_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，太初元碁正积极携手京算、是石科技、神威数智、龙芯中科等合作伙伴，全力打造DeepSeek系列模型的云端推理平台。企业用户只需通过简单的操作，即可在云端快速获取太初T100加速卡的强大推理能力，轻松实现智能化转型，提升生产效率和创新能力，以在激烈的市场竞争中脱颖而出。同时，太初元碁也联合龙芯中科提供面向政务信创的国密云端推理平台，以满足信创刚需。</p>
  <h3><strong>燧原科技实现全国各地智算中心DeepSeek的全量推理服务部署</strong></h3>
  <p>2月6日，燧原科技宣布完成对DeepSeek全量模型的高效适配，包括DeepSeek-R1/V3 671B原生模型、DeepSeek-R1-Distill-Qwen-1.5B/7B/14B/32B、DeepSeek R1-Distill-Llama-8B/70B等蒸馏模型。整个适配进程中，燧原AI加速卡的计算能力得到充分利用，能够快速处理海量数据，同时其稳定性为模型的持续优化和大规模部署提供了坚实的基础。</p>
  <p>目前，DeepSeek的全量模型已在庆阳、无锡、成都等智算中心完成了数万卡的快速部署，将为客户及合作伙伴提供高性能计算资源，提升模型推理效率，同时降低使用门槛，大幅节省硬件成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8a8f419509954303bac9c525c46c7120@000000_oswg294209oswg1080oswg516_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>昆仑芯全面适配DeepSeek</strong></h3>
  <p>2月6日，昆仑芯科技宣布，在DeepSeek-V3/R1上线不久，昆仑芯便率先完成全版本模型适配，这其中包括DeepSeek MoE 模型及其蒸馏的Llama/Qwen等小规模dense模型。</p>
  <p>昆仑芯P800可以较好的支撑DeepSeek系列MoE模型大规模训练任务，全面支持MLA、多专家并行等特性，仅需32台即可支持模型全参训练，高效完成模型持续训练和微调。</p>
  <p>P800显存规格优于同类主流GPU20%-50%，对MoE架构更加友好，且率先支持8bit推理，单机8卡即可运行 671B 模型。正因如此，昆仑芯相较同类产品更加易于部署，同时可显著降低运行成本，轻松完成DeepSeek-V3/R1全版本推理任务。</p>
  <h3><strong>龙芯处理器成功运行DeepSeek大模型</strong></h3>
  <p>2 月 7 日，龙芯中科宣布， 日前，龙芯联合太初元碁等产业伙伴，仅用 2 小时即在太初 T100 加速卡上完成 DeepSeek-R1 系列模型的适配工作，快速上线包含 DeepSeek-R1-Distill-Qwen-7B 在内的多款大模型服务。</p>
  <p>此外，采用龙芯3A6000处理器的诚迈信创电脑和望龙电脑已实现本地部署DeepSeek，部署后无需依赖云端服务器，避免了因网络波动或服务器过载导致的服务中断，可高效完成文档处理、数据分析、内容创作等多项工作，显著提升工作效率。</p>
  <h2><strong>DeepSeek给国产芯片公司，带来新契机</strong></h2>
  <p>DeepSeek 的横空出世宛如一颗投入平静湖面的石子，在行业中激起层层涟漪，为国产芯片公司带来新的发展契机。</p>
  <p><strong>首先，随着大模型应用的遍地开花，对芯片的需求也水涨船高。</strong>无论是模型训练时所需的强大算力，还是推理过程中对低延迟、高效率的追求，都为国产芯片公司打开了新的市场空间。以往，由于高昂的大模型使用成本，许多潜在的应用场景被抑制，如今 DeepSeek 打破了这一僵局，国产芯片公司得以凭借自身产品在新兴的细分市场中崭露头角，满足不同行业对于大模型运算的芯片需求。</p>
  <p><strong>其次，DeepSeek 大模型与国产 AI 芯片适配的逐步成熟，是另一个关键契机。</strong>此前，国产 AI 芯片在发展过程中，常面临与主流大模型适配度不佳的问题，这限制了其市场推广与应用拓展。而 DeepSeek 的出现改变了这一局面，它为国产 AI 芯片提供了一个更为契合的适配平台。</p>
  <p>当国产 AI 芯片能够与 DeepSeek 大模型良好适配后，可以加快国产 AI 芯片在国内大模型训练端和推理端的应用，使得国产芯片在本土市场中获得更多实践机会，通过不断优化和改进，提升产品性能。</p>
  <p><strong>最后，随着 DeepSeek 与国产芯片的适配，将与其他国产软硬件厂商形成协同效应，构建起完整的生态闭环</strong>，这将推动国产芯片在人工智能领域的应用，加速国产芯片生态体系的建设。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247788670&amp;idx=1&amp;sn=0bfe8a56872bbb9e66c0ef7f100ea3eb&amp;chksm=c0bb70d10d33a104ad87ab95da8c6d8483660a1eefe0c981fe2a494038c54d9fb2893ce2e0e6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：丰宁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156406783662855</id>
            <title>英伟达联手MIT清北发布SANA 1.5，线性扩散Transformer再刷文生图新SOTA</title>
            <link>https://www.36kr.com/p/3156406783662855</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156406783662855</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:12:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: SANA 1.5, 线性扩散Transformer, 模型扩展, 文本生成图像  
<br><br>  
总结: SANA 1.5是一种高效可扩展的线性扩散Transformer，针对文本生成图像任务提出了三项创新：高效的模型增长策略、深度剪枝和推理时扩展策略。这些创新显著降低了训练和推理成本，同时提升了生成质量。研究者通过有效的模型增长策略，保留小模型的知识，减少了60%的训练时间。深度剪枝技术实现了高效的模型压缩，而推理时扩展策略则通过重复采样提升了生成质量。实验结果表明，SANA 1.5在GenEval基准测试中达到了最先进的性能，证明了高效扩展不仅依赖于增加模型容量。 </div>
                        <hr>
                    
                    <blockquote>
   <p>SANA 1.5是一种高效可扩展的线性扩散Transformer，针对文本生成图像任务进行了三项创新：高效的模型增长策略、深度剪枝和推理时扩展策略。这些创新不仅大幅降低了训练和推理成本，还在生成质量上达到了最先进的水平。</p>
  </blockquote>
  <p>近年来，文本生成图像的技术不断突破，但随着模型规模的扩大，计算成本也随之急剧上升。</p>
  <p>为此，英伟达联合MIT、清华、北大等机构的研究人员提出了一种高效可扩展的线性扩散Transformer——SANA，在大幅降低计算需求的情况下，还能保持有竞争力的性能。</p>
  <p>SANA1.5在此基础上，聚焦了两个关键问题：</p>
  <ol>
   <li>线性扩散Transformer的可扩展性如何？</li>
   <li>在扩展大规模线性DiT时，怎样降低训练成本？</li>
  </ol>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2c1e9b502df2433d83b69e74bfa74e6c@5888275_oswg134388oswg1080oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文链接：https://arxiv.org/pdf/2501.18427</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8271efceb7894e3e83253f62e50b7e46@5888275_oswg148404oswg1080oswg566_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>SANA 1.5：高效模型扩展三大创新</strong></h2>
  <p>SANA 1.5在SANA 1.0（已被ICLR 2025接收）的基础上，有三项关键创新。</p>
  <p>首先，研究者提出了一种高效的模型增长策略，使得SANA可以从1.6B（20层）扩展到4.8B（60层）参数，同时显著减少计算资源消耗，并结合了一种节省内存的8位优化器。</p>
  <p>与传统的从头开始训练大模型不同，通过有策略地初始化额外模块，可以让大模型保留小模型的先验知识。与从头训练相比，这种方法能减少60%的训练时间。</p>
  <p>其二，引入了模型深度剪枝技术，实现了高效的模型压缩。通过识别并保留关键的块，实现高效的模型压缩，然后通过微调快速恢复模型质量，实现灵活的模型配置。</p>
  <p>其三，研究者提出了一种推理期间扩展策略，引入了重复采样策略，使得SANA在推理时通过计算而非参数扩展，使小模型也能达到大模型的生成质量。</p>
  <p>通过生成多个样本，并利用基于视觉语言模型（VLM）的选择机制，将GenEval分数从0.72提升至0.80。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fe479b5a5bf14ac0aadb3e371fea96cf@5888275_oswg225366oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与从头开始训练大模型不同，研究者首先将一个包含N个Transformer层的基础模型扩展到N+M层（在实验中，N=20，M=40），同时保留其学到的知识。</p>
  <p>在推理阶段，采用两种互补的方法，实现高效部署：</p>
  <ul>
   <li>模型深度剪枝机制：识别并保留关键的Transformer块，从而在小的微调成本下，实现灵活的模型配置。</li>
   <li>推理时扩展策略：借助重复采样和VLM引导选择，在计算资源和模型容量之间权衡。</li>
  </ul>
  <p>同时，内存高效CAME-8bit优化器让单个消费级GPU上微调十亿级别的模型成为可能。</p>
  <p>下图展示了这些组件如何在不同的计算资源预算下协同工作，实现高效扩展。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c159c61f836e42e4b34261b61092c516@5888275_oswg302617oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>模型增长</strong></h3>
  <p>研究者提出一种高效的模型增长策略，目的是对预训练的DiT模型进行扩展，把它从𝑁层增加到𝑁+𝑀层，同时保留模型已经学到的知识。</p>
  <p>研究过程中，探索了三种初始化策略，最终选定部分保留初始化方法。这是因为该方法既简单又稳定。</p>
  <p>在这个策略里，预训练的N层继续发挥特征提取的作用，而新增加的M层一开始是随机初始化，从恒等映射起步，慢慢学习优化特征表示。</p>
  <p>实验结果显示，与循环扩展和块扩展策略相比，这种部分保留初始化方法在训练时的动态表现最为稳定。</p>
  <h3><strong>模型剪枝</strong></h3>
  <p>本文提出了一种模型深度剪枝方法，能高效地将大模型压缩成各种较小的配置，同时保持模型质量。</p>
  <p>受Minitron启发，通过输入输出相似性模式分析块的重要性：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a64f2637c8a94e0c9ac4facf58149c2b@5888275_oswg43528oswg968oswg238_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这里的</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6a87418389444d9ab3760eab308f25fb@5888275_oswg1968oswg140oswg98_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>表示第i个transformer的第t个token。</p>
  <p>模型的头部和尾部块的重要性较高，而中间层的输入和输出特征相似性较高，表明这些层主要用于逐步优化生成的结果。根据排序后的块重要性，对transformer块进行剪枝。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_94c41970fb9a46d49f14794ead94a0b5@5888275_oswg68926oswg1080oswg318_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>剪枝会逐步削弱高频细节，因为，在剪枝后进一步微调模型，以弥补信息损失。</p>
  <p>使用与大模型相同的训练损失来监督剪枝后的模型。剪枝模型的适配过程非常简单，仅需100步微调，剪枝后的1.6B参数模型就能达到与完整的4.8B参数模型相近的质量，并且优于SANA 1.0的1.6B模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d5c86982327b44eebacc56282cd7616f@5888275_oswg644438oswg1080oswg621_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>推理时扩展</strong></h3>
  <p>SANA 1.5经过充分训练，在高效扩展的基础上，生成能力有了显著提升。受LLM推理时扩展的启发，研究者也想通过这种方式，让SANA 1.5表现得更好。</p>
  <p>对SANA和很多扩散模型来说，增加去噪步数是一种常见的推理时扩展方法。但实际上，这个方法不太理想。一方面，新增的去噪步骤没办法修正之前出现的错误；另一方面，生成质量很快就会达到瓶颈。</p>
  <p>相较而言，增加采样次数是更有潜力的方向。</p>
  <p>研究者用视觉语言模型（VLM）来判断生成图像和文本提示是否匹配。他们以NVILA-2B为基础模型，专门制作了一个数据集对其进行微调。</p>
  <p>微调后的VLM能自动比较并评价生成的图像，经过多轮筛选，选出排名top-N的候选图像。这不仅确保了评选结果的可靠性，还能有效过滤与文本提示不匹配的图像。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_97d5d108c9c540a49b5d0c1e8ed19a62@5888275_oswg217969oswg1080oswg336_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>模型增长、模型深度剪枝和推理扩展，构成了一个高效的模型扩展框架。三种方法协同配合，证明了精心设计的优化策略，远比单纯增加参数更有效。</p>
  <ul>
   <li>模型增长策略探索了更大的优化空间，挖掘出更优质的特征表示。</li>
   <li>模型深度剪枝精准识别并保留了关键特征，从而实现高效部署。</li>
   <li>推理时间扩展表明，当模型容量有限时，借助额外的推理时间和计算资源，能让模型达到与大模型相似甚至更好的效果。</li>
  </ul>
  <p>为了实现大模型的高效训练与微调，研究者对CAME进行扩展，引入按块8位量化，从而实现CAME-8bit优化器。</p>
  <p>CAME-8bit相比AdamW-32bit减少了约8倍的内存使用，同时保持训练的稳定性。</p>
  <p>该优化器不仅在预训练阶段效果显著，在单GPU微调场景中更是意义非凡。用RTX 4090这样的消费级GPU，就能轻松微调SANA 4.8B。</p>
  <p>研究揭示了高效扩展不仅仅依赖于增加模型容量。通过充分利用小模型的知识，并设计模型的增长-剪枝，更高的生成质量并不一定需要更大的模型。</p>
  <h2><strong>SANA 1.5 评估结果</strong></h2>
  <p>实验表明，SANA 1.5的训练收敛速度比传统方法（扩大规模并从头开始训练）快2.5倍。</p>
  <p>训练扩展策略将GenEval分数从0.66提升至0.72，并通过推理扩展将其进一步提高至0.80，在GenEval基准测试中达到了最先进的性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a1bb16c5689e450486b46f7a78f10ed1@5888275_oswg927471oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>模型增长</strong></h3>
  <p>将SANA-4.8B与当前最先进的文本生成图像方法进行了比较，结果如表所示。</p>
  <p>从SANA-1.6B到4.8B的扩展带来了显著的改进：GenEval得分提升0.06（从0.66增加到0.72），FID降低0.34（从5.76降至5.42），DPG得分提升0.2（从84.8增加到85.0）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9fc29fa915b54cb3bdd76c36bb0397d6@5888275_oswg124945oswg1067oswg511_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>和当前最先进的方法相比，SANA-4.8B模型的参数数量少很多，却能达到和大模型一样甚至更好的效果。</p>
  <p>SANA-4.8B的GenEval得分为0.72，接近Playground v3的0.76。</p>
  <p>在运行速度上，SANA-4.8B的延迟比FLUX-dev（23.0秒）低5.5倍；吞吐量为0.26样本/秒，是FLUX-dev（0.04样本/秒）的6.5倍，这使得SANA-4.8B在实际应用中更具优势。</p>
  <h3><strong>模型剪枝</strong></h3>
  <p>为了和SANA 1.0（1.6B）公平比较，此次训练的SANA 1.5（4.8B）模型，没有用高质量数据做监督微调。</p>
  <p>所有结果都是针对512×512尺寸的图像评估得出的。经过修剪和微调的模型，仅用较低的计算成本，得分就达到了0.672，超过了从头训练模型的0.664。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_400a67a9bb3644bea313653fa45295e5@5888275_oswg55847oswg1080oswg209_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>推理时扩展</strong></h3>
  <p>将推理扩展应用于SANA 1.5（4.8B）模型，并在GenEval基准上与其他大型图像生成模型进行了比较。</p>
  <p>通过从2048张生成的图像中选择样本，经过推理扩展的模型在整体准确率上比单张图像生成提高了8%，在「颜色」「位置」和「归属」子任务上提升明显。</p>
  <p>不仅如此，借助推理时扩展，SANA 1.5（4.8B）模型的整体准确率比Playground v3 (24B）高4%。</p>
  <p>结果表明，即使模型容量有限，提高推理效率，也能提升模型生成图像的质量和准确性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9c1c538b017f43579aebe7b85d8e09d0@5888275_oswg134803oswg1080oswg316_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>SANA：超高效文生图</strong></h2>
  <p>在这里介绍一下之前的SANA工作。</p>
  <p>SANA是一个超高效的文本生成图像框架，能生成高达4096×4096分辨率的图像，不仅画质清晰，还能让图像和输入文本精准匹配，而且生成速度超快，在笔记本电脑的GPU上就能运行。</p>
  <p>SANA为何如此强大？这得益于它的创新设计：</p>
  <ul>
   <li><strong>深度压缩自动编码器：</strong>传统自动编码器压缩图像的能力有限，一般只能压缩8倍。而SANA的自动编码器能达到32倍压缩，大大减少了潜在tokens数量，计算效率也就更高了。</li>
   <li><strong>线性DiT：</strong>SANA用线性注意力替换了DiT中的标准注意力。在处理高分辨率图像时，速度更快，还不会降低图像质量。</li>
   <li><strong>仅解码文本编码器：</strong>SANA不用T5做文本编码器了，而是采用现代化的小型仅解码大模型。同时，通过上下文学习，设计出更贴合实际需求的指令，让生成的图像和输入文本对应得更好。</li>
   <li><strong>高效训练与采样：</strong>SANA提出了Flow-DPM-Solver方法，减少了采样步骤。再配合高效的字幕标注与选取，让模型更快收敛。</li>
  </ul>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8aaacb9ffdc2488d90295c3561efea23@5888275_oswg713619oswg1080oswg437_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>经过这些优化，SANA-0.6B表现十分出色。</p>
  <p>它生成图像的质量和像Flux-12B这样的现代大型扩散模型差不多，但模型体积缩小了20倍，数据处理能力却提升了100倍以上。</p>
  <p>SANA-0.6B运行要求不高，在只有16GB显存的笔记本GPU上就能运行，生成一张1024×1024分辨率的图像，用时不到1秒。</p>
  <p>这意味着，创作者们用普通的笔记本电脑，就能轻松制作高质量图像，大大降低了内容创作的成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_9209501a86ec4a6c8d95c1300ee57030@5888275_oswg98438oswg1080oswg297_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究者提出新的深度压缩自动编码器，将压缩比例提升到32倍，和压缩比例为8倍的自动编码器相比，F32自动编码器生成的潜在tokens减少了16倍。</p>
  <p>这一改进对于高效训练和超高分辨率图像生成，至关重要。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fffa358e9ee341e0a0bd517533c340f8@5888275_oswg1319164oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究者提出一种全新的线性DiT，用线性注意力替代传统的二次复杂度注意力，将计算复杂度从原本的O(N²) 降低至O(N)。另一方面，在MLP层引入3×3深度可分卷积，增强潜在tokens的局部信息。</p>
  <p>在生成效果上，线性注意力与传统注意力相当，在生成4K图像时，推理延迟降低了1.7倍。Mix-FFN结构让模型无需位置编码，也能生成高质量图像，这让它成为首个无需位置嵌入的DiT变体。</p>
  <p>在文本编码器的选择上，研究者选用了仅解码的小型大语言模型Gemma，以此提升对提示词的理解与推理能力。相较于CLIP和T5，Gemma在文本理解和指令执行方面表现更为出色。</p>
  <p>为充分发挥Gemma的优势，研究者优化训练稳定性，设计复杂人类指令，借助Gemma的上下文学习能力，进一步提高了图像与文本的匹配质量。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_6d7c14a6602841c7b698412ed8f42aea@5888275_oswg481782oswg1080oswg834_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究者提出一种自动标注与训练策略，借助多个视觉语言模型（VLM）生成多样化的重新描述文本。然后，运用基于CLIPScore的策略，筛选出CLIPScore较高的描述，以此增强模型的收敛性和对齐效果。</p>
  <p>在推理环节，相较于Flow-Euler-Solver，Flow-DPM-Solver将推理步骤从28-50步缩减至14-20步，不仅提升了速度，生成效果也更为出色。</p>
  <p><strong>参考资料：</strong></p>
  <p>https://huggingface.co/papers/2501.18427</p>
  <p>https://x.com/xieenze_jr/status/1885510823767875799</p>
  <p>https://nvlabs.github.io/SANA/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/UvOoDGvzAFjA3ImXXVlktw" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：英智 好困，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156439091730944</id>
            <title>我们应如何看待DeepSeek的557.6万美元训练成本？</title>
            <link>https://www.36kr.com/p/3156439091730944</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156439091730944</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:12:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 算法效率, DeepSeek-V3, 训练成本, AI企业  
<br><br>  
总结: 本文讨论了中国AI企业在算法效率方面的优势，特别是DeepSeek-V3模型的训练成本显著低于同类美国模型。张钹指出，中国企业对算法效率的重视源于其生存需求，而美国企业则因算力强大而相对宽松。DeepSeek-V3的训练成本为557.6万美元，但未包括隐性成本，且其训练效率通过优化算法、框架和硬件得以提升。尽管DeepSeek的成功引发了外界的误读，但其创新和努力是推动其发展的核心因素。 </div>
                        <hr>
                    
                    <p>三个月前，我们和中国科学院院士、清华大学计算机系教授张钹曾经聊过一个话题：“为什么在提高算法效率上中国人会做得更好？”</p>
  <p>张钹告诉我们：“<strong>对中国企业来讲，算法效率是生命攸关的</strong>，我们必须全力以赴。也许因为美国人有强大的算力，算法效率对他们来说只是锦上添花而已。”</p>
  <p>当时，我们对这句话感受还不是很深，直到后来看到了DeepSeek-V3技术报告里的这张表格。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_894e588f84bf42b68bc34b2222a1e4cf@5888275_oswg26044oswg821oswg177_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">DeepSeek-V3的训练成本（假设H800的租赁价格为2美元/GPU小时），图片来源：DeepSeek-V3技术报告&nbsp;</p>
  <p>简单来说，DeepSeek-V3仅使用了2048块英伟达H800 GPU，耗费了557.6万美元就完成了训练，相比同等规模的模型（如GPT-4、GPT-4o、Llama 3.1），训练成本大幅降低。</p>
  <p>这样说没有错，但在复杂的舆论场中也引发了一些误读。比如，“中国AI企业用几百万美元的成本打败了美国AI企业数亿美元的投入”“成本仅为国外三十分之一，硅谷恐慌”。</p>
  <p>这种误读有一些客观原因，因为OpenAI、Meta官方从来没有公布过GPT-4、GPT-4o、Llama 3.1的训练成本，多数人对模型训练成本构成也并不熟悉，但误读背后更多还是主观原因——情绪。</p>
  <p>AI大模型领域，中国AI企业一直是一个“追随者”的角色，这次有了和硅谷巨头“掰手腕”的机会，就像霍元甲站上了与西洋力士的比武台，谁不想叫声好呢？</p>
  <p><strong>这种情绪本身没有错，但也在一定程度上模糊了DeepSeek团队在算法、框架和硬件上的优化协同设计的价值</strong>，而这正是DeepSeek-V3降本增效的关键。</p>
  <h2><strong>01 训练成本差距是否有那么大？</strong></h2>
  <p>我们查阅了技术报告，DeepSeek只公布了基座模型V3的训练成本，并没有公布推理模型R1的训练成本。</p>
  <p>DeepSeek-V3技术报告显示，该模型的正式训练成本包括三个阶段：<strong>预训练（pre-training）、扩展上下文（context extension）、后训练（post-training），共计557.6万美元。</strong></p>
  <p><strong>但是这557.6万美元的训练成本并不包括前期研究以及关于架构、算法或数据的消融实验所产生的成本。</strong></p>
  <p>前期研究、消融实验属于“隐性成本”，但不容忽视。</p>
  <p>在一个AI企业正式训练一个模型之前，需要进行大量的前期研究，包括对算法的理论研究、对硬件性能的探索、对数据集的分析等。</p>
  <p>而消融实验（Ablation Study）是一种在机器学习和深度学习中广泛使用的分析方法，用于评估模型各个组件或特征的重要性及其对模型整体性能的影响。</p>
  <p>消融实验就像是在玩“减法游戏”或者“排除法”，通过逐一移除或修改模型的某些部分，观察模型性能的变化，从而确定每个部分的相对重要性。</p>
  <p>另外，在训练模型之前还会有一定的试错成本。</p>
  <p>为什么说这些成本是“隐性成本”？</p>
  <p>因为大模型前期研发往往分散在数月甚至数年中，难以量化统计；消融实验可能反复进行，但最终仅保留最优方案，失败案例的成本常被忽视；企业通常不会公开内部研发细节（如试错次数），导致外部估算会产生偏差。</p>
  <p><strong>除了“隐性成本”，不同的成本计算方式也会产生不一样的结果。</strong></p>
  <p>DeepSeek-V3这557.6万美元训练成本是怎么计算的呢？按照DeepSeek-V3技术报告的逻辑，我们简单列了一个公式：</p>
  <blockquote>
   <p>训练耗费的时长（GPU小时）×H800每GPU小时的租赁价格（美元）=DeepSeek-V3训练成本（美元）</p>
  </blockquote>
  <p>正式训练耗费的时长包括：预训练阶段耗费266.4万（2664K）GPU小时，扩展上下文长度阶段耗费11.9万（119K）GPU小时，后训练阶段耗费0.5万（5K）GPU小时，因此DeepSeek-V3的正式训练共耗费278.8万（2788K）GPU小时。</p>
  <p>而DeepSeek在技术报告中假设H800每GPU小时的租赁价格为2美元，这样DeepSeek-V3训练成本就是：</p>
  <blockquote>
   <p>2,788,000×2=5,576,000（美元）</p>
  </blockquote>
  <p>需要注意的是，这里是按<strong>GPU小时</strong>而不是<strong>GPU个数</strong>计算，单价是按<strong>GPU租赁价格计算</strong>而不是<strong>GPU购买价格计算</strong>。</p>
  <p>换种方式计算训练成本，结果就会很不一样。</p>
  <p>比如，为了训练Llama 3.1 405B，Meta使用了超过1.6万个英伟达H100 GPU，如果按照H100 GPU的购买价格计算，这样计算下来的训练成本就已高达数亿美元。</p>
  <p>我们也可以按照DeepSeek-V3一样的租赁逻辑计算。</p>
  <p>尽管Meta没有透露Llama 3.1具体的训练成本，但是其技术报告显示，Llama 3.1 405B的预训练（此处说的是预训练时间而非完整训练时间）为54天。那么，Llama 3.1 405B预训练阶段耗费的GPU小时为：</p>
  <blockquote>
   <p>天数×24小时×H100 GPU个数=预训练阶段耗费的GPU小时</p>
   <p>54×24×16,000=20,736,000</p>
  </blockquote>
  <p>Llama 3.1 405B是2024年7月推出的，如果按照2024年初海外市场H100 GPU每GPU小时的租赁价格2.8美元（参考价格，会浮动）计算，那么<strong>其预训练成本约为5800万美元。相比之下，DeepSeek-V3的532.8万美元预训练成本的确是大幅降低了。</strong></p>
  <p>而OpenAI官方从来没有公布过其训练成本，但是我们可以从侧面推算。</p>
  <p>英伟达CEO黄仁勋在NVIDIA GTC 2024主题演讲中介绍，<strong>如果要训练一个有1.8万亿参数的GPT模型，用Hopper（H100）的话，需要约8000个GPU，耗电15兆瓦，用时90天，大约需要三个月。</strong></p>
  <p>虽然黄仁勋没有明说，但根据此前多个渠道的爆料信息，这个1.8万亿参数的GPT模型就是GPT-4。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1c0ff7c877ae4b839016aa093cf6e094@5888275_oswg359451oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">黄仁勋在NVIDIA GTC 2024 主题演讲，图片来源：英伟达B站账号&nbsp;</p>
  <p>黄仁勋在演讲中解释道：“这样就可以训练出这种开创性的AI模型，这显然没有人们想象中那么昂贵，但是8000个GPU仍然是一大笔投资。”</p>
  <p>我们同样可以按照租赁逻辑估算一下与GPT-4规模相当模型训练成本。为什么说估算？因为H100是2022年3月发布的GPU，但实际大规模供货和云服务商部署通常在2022年底至2023年初才开始，而GPT-4在2023年3月发布，所以GPT-4的训练更多还是依靠A100。</p>
  <p>假设在2024年初，也就是黄仁勋发表演讲之前，<strong>训练一个与GPT-4规模相当的大模型</strong>，其训练成本是：</p>
  <blockquote>
   <p>天数×24小时×H100 GPU个数=训练阶耗费的GPU小时</p>
   <p>90×24×8,000=17,280,000（小时）</p>
   <p>训练耗费的GPU小时×H100每GPU小时的租赁价格=训练成本</p>
   <p>17,280,000×2.8=48,384,000（美元）</p>
  </blockquote>
  <p><strong>大约4800万美元的训练费用</strong>，的确如黄仁勋所说“没有人们想象中那么昂贵”。</p>
  <p>而据SemiAnalysis在2023年7月发布的分析报告，OpenAI在GPT-4的训练中使用了约2.5万个A100GPU，训练了90到100天，利用率（MFU）约为32%至36%，这种极低的利用率部分是由于大量的故障导致需要重新启动检查点。如果每个A100 GPU的使用成本大约为每小时1美元，<strong>那么仅此次训练的成本将达到约6300万美元。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_918f231763784300810201856d257a93@5888275_oswg416449oswg1080oswg465_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：SemiAnalysis&nbsp;</p>
  <p>DeepSeek-V3对标的Claude 3.5 Sonnet的训练成本又是多少呢？此前Anthropic也没有公布Claude 3.5 Sonnet的训练成本，但Anthropic CEO达里奥·阿莫迪（Dario Amodei）近期在一篇评价DeepSeek的文章中透露，<strong>Claude 3.5 Sonnet训练成本在数千万美元（cost a few $10M's to train）</strong>，他还特意说：“我不会给出具体的数字。”</p>
  <p>“A few”在英语里通常指3到5个，所以我们<strong>估计Claude 3.5 Sonnet的训练费用在3000万到5000万美元之间。</strong></p>
  <p>我们统一按照DeepSeek-V3的GPU租赁逻辑计算，不考虑其他“隐性成本”，可以发现，<strong>DeepSeek-V3的训练成本相比其对标模型训练成本大幅降低，但没有到某些人说的“几十分之一”的夸张程度。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c3fbca472091403fae7a206a4a7a90b4@5888275_oswg277004oswg1080oswg748_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>需要注意的是，随着技术和市场的发展，GPU租赁价格的降低使得企业和研究机构能够以更低的成本配置更多的GPU，从而让模型训练降本增效。</p>
  <p>企业还可以用更先进的GPU降低训练的能耗。</p>
  <blockquote>
   <p>还记得黄仁勋举的例子吗？如果要训练一个有1.8万亿参数的GPT模型，用Hopper（H100）的话，需要约8000个GPU，耗电15兆瓦，用时90天；如果用Blackwell（GB200）的话，需要2000个GPU，耗电仅需4兆瓦，约为Hopper的四分之一。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_19c5ba83907344cba79a53aba4282d23@5888275_oswg212098oswg834oswg901_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：英伟达&nbsp;</p>
  <p>这是先进GPU带来的效率提升，但是国内AI企业由于管控，无法获得最先进的GPU，又是靠什么来实现降本增效呢？</p>
  <blockquote>
   <p>Meta技术报告显示，Llama 3.1 405B的预训练时长54天，使用了15万亿（15T）的tokens以及1.6万个英伟达H100 GPU进行训练。</p>
  </blockquote>
  <p>DeepSeek-V3在预训练阶段，使用了14.8万亿（14.8T）的tokens进行训练，预训练耗时也是54天，DeepSeek-V3技术报告里也说的是“不到两个月”：</p>
  <blockquote>
   <p>预训练阶段耗费的GPU小时÷H800 GPU个数÷24小时=天数</p>
   <p>2,664,000÷2048÷24≈54（天）</p>
  </blockquote>
  <p>但是，DeepSeek-V3仅使用了2048块英伟达H800 GPU，尽管可能存在利用率的差异，但这与Llama 3.1 405B训练使用的1.6万个英伟达H100 GPU形成了鲜明对比。而且H800是英伟达为了满足出口限制而设计的GPU，性能低于H100。</p>
  <p>也就是说，DeepSeek-V3在GPU比Llama 3.1 405B用得少，GPU性能也更弱的情况下，在相同的时间，完成了与Llama 3.1 405B差不多的训练量。</p>
  <p>DeepSeek-V3技术报告里的这句话“<strong>DeepSeek-V3每训练一万亿（trillion）个token仅需18万（180K）H800&nbsp;GPU小时</strong>”成为了关键。</p>
  <p>DeepSeek-V3大幅提升了模型训练效率。</p>
  <h2><strong>02 DeepSeek如何降本增效？</strong></h2>
  <p>DeepSeek-V3是一个混合专家模型 (Mixed Expert Models，以下简称MoE) ，旨在通过整合多个模型或“专家”的预测来提升整体模型性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_89bd3322c519407eac19f610abea1fdd@5888275_oswg95273oswg966oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：DeepSeek-V3技术报告&nbsp;</p>
  <p>清华大学计算机系长聘教授、高性能计算研究所所长翟季冬在《夜话DeepSeek：技术原理与未来方向》直播中介绍，之前发布的一些MoE模型，采用的是<strong>“专家数很少、每个专家很大”</strong>的架构，但是DeepSeek采用的是<strong>“大量细粒度的专家”</strong>。</p>
  <p>“大量细粒度的专家”可以更灵活地处理各种输入数据，提高模型的适应性和泛化能力。由于每个专家的规模小，计算效率更高，训练和存储成本也相对较低。不过，由于专家数量众多，可能会导致模型的管理和调度变得更加复杂。</p>
  <p>翟季冬分析，为了提升DeepSeek-V3的模型训练效率，DeepSeek团队在四个方面进行了优化，分别是：<strong>负载均衡优化、通信优化、内存优化、计算优化</strong>。</p>
  <p><strong>首先是负载均衡优化。</strong>在MoE架构中，负载均衡指的是将输入数据合理分配给各个专家，使得每个专家都能充分发挥其性能，同时避免某些专家过度负载而其他专家空闲。</p>
  <p>负载均衡是MoE训练中的非常大的挑战，如果处理不好，那么模型在一个大规模GPU集群训练时，利用率就很难提升上去。</p>
  <p>DeepSeek团队为了解决负载均衡的挑战，创新提出了“Auxiliary-loss-free（无辅助损失）”负载均衡方案。</p>
  <p>在传统的MoE中，为了保证各个专家的负载均衡，通常会引入一个Auxiliary Loss（辅助损失）。这个Auxiliary Loss会强制让每个专家处理的任务量尽量均匀。但它可能会让模型在优化过程中过于关注负载均衡，而忽略了模型本身的性能。</p>
  <p>而DeepSeek的Auxiliary-Loss-Free方案，<strong>不依赖额外的辅助损失，而是在每个token的专家分配过程中直接施加一个bias（偏差值）来实现负载均衡，从而实现动态调整专家的负载。</strong></p>
  <p>由于这种bias的引入已经在专家选择的过程中起到了调控作用，使得各专家之间的token分配趋向均衡，因此就不再需要设计和调节额外的辅助损失项来“强制”负载平衡。这不仅简化了训练目标，也避免了因辅助损失权重设置不当而可能引入的训练不稳定问题。</p>
  <p>简单来说，<strong>这就类似红绿灯路口</strong>，Auxiliary loss就是固定时长的红绿灯，车流量大了，路口通行效率会降低；而Auxiliary-Loss-Free中的bias就是可以根据实时车流量动态调整时长的红绿灯，基于当前状态（交通流量或专家负载）动态调整资源分配，以达到整体平衡和高效利用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_b9f0ae3691234cceb86b6eede16cfde3@5888275_oswg72090oswg957oswg545_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">负载均衡优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>第二是通信优化。</strong>在MoE训练中，使用专家并行会引入非常大的All to All通信开销。</p>
  <p>什么是All to All通信开销？</p>
  <p>假设在一个MoE中，有10个专家，每个专家被放置在一个独立的计算节点上。在训练过程中，每个专家需要与其他所有专家进行数据交换，以更新模型参数和同步训练状态。这种情况下，每个节点都需要与其他9个节点进行通信，形成了All to All的通信模式。随着专家数量的增加，通信开销也会显著增加，导致训练效率下降。</p>
  <p>DeepSeek-V3就包括1个共享专家和256个路由专家，它采用的并行训练策略：16路流水线并行、64路专家并行，跨8个物理节点。</p>
  <p><strong>DeepSeek团队为了降低通信开销，提出了DualPipe算法。</strong></p>
  <p><strong>DualPipe算法的核心创新就是能够将计算和通信阶段重叠进行。</strong>在传统的训练过程中，计算和通信是分开进行的，这会导致GPU在等待数据传输时出现空闲期，即所谓的 “流水线气泡”（pipeline bubbles）。DualPipe算法通过确保在一个微批量（micro-batch）被计算的同时，另一个微批量可以进行通信，精细地编排计算和通信，从而最大限度地减少这些空闲期，提高GPU的利用率。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_074173ab32d143be82d54df302e054df@5888275_oswg322986oswg986oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">通信优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>DualPipe算法还采用了双向流水线机制，同时从流水线的两端处理微批量。</strong>这种策略确保了在整个训练过程中GPU始终保持活跃。通过这种方式，DeepSeek能够保持良好的计算与通信比例，减少延迟，提高吞吐量。</p>
  <p>“这里有一个需要注意的点，如果采用双向流水线，要在GPU显存里存两份模型参数。大模型训练内存使用非常重要，为了解决这个问题，它采用了64路的专家并行，双流水可以非常有效地降低流水线bubble。”翟季冬说。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_40a1b49467194c6990866eaacafff0d8@5888275_oswg74515oswg961oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">通信优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p>此外，DeepSeek的通信优化还包括跨节点通信优化以及Warp Specialization技术。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_52733754fbfc450399f10663b79f1366@5888275_oswg500012oswg989oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">通信优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>第三是内存优化。</strong>包括了重计算、使用CPU内存和参数共享。</p>
  <p>大模型训练往往存在显存瓶颈。重计算的核心思想是在前向传播过程中，只保留少量关键的中间结果，而将其余的中间结果释放掉。当在反向传播过程中需要用到这些已释放的中间结果时，再重新执行前向传播中的相应部分来计算得到。<strong>这种方法通过增加一定的计算量，显著降低了内存消耗，是一种“以时间换空间”的策略。</strong></p>
  <p>这可以理解为一种在大模型训练过程中“偷懒”的技巧。</p>
  <p>同时，DeepSeek还把一些数据，包括像模型参数的指数移动平均（EMA），存到CPU内存，从而节约GPU显存；将主模型与MTP（Multi-Token Prediction）模块的output head和embedding部署在相同节点，最大化地共享参数空间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_531b3e1722fb4174af5c7f9c455ed4e8@5888275_oswg392274oswg987oswg564_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">内存优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p><strong>第四是计算优化。</strong>为了提升训练效率，DeepSeek采用了混合精度训练策略。</p>
  <p>DeepSeek引入了英伟达FP8混合精度训练框架，并首次在超大规模模型上验证了其有效性。通过支持FP8计算和存储，DeepSeek实现了加速训练和减少GPU内存使用。FP8训练在相同加速平台上的峰值性能显著超越FP16/BF16，并且模型参数越大，训练加速效果越好。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_989c8ec6cc3c4e578e83c0f7b21731f6@5888275_oswg70865oswg952oswg538_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">计算优化，图片来源：翟季冬，《夜话DeepSeek：技术原理与未来方向》&nbsp;</p>
  <p>总的来说，翟季冬认为：DeepSeek充分挖掘了算法、软件、硬件性能，实现了协同创新；其软件相对灵活，软件赋能硬件，弥补了硬件的很多限制；优秀的系统软件能够充分释放底层硬件的潜力。</p>
  <p>DeepSeek正是通过这一步步的优化，让整个模型的训练效率得到提升，并降低训练成本。</p>
  <h2><strong>03 “小米加步枪”式的成功</strong></h2>
  <p>经历了春节假期的喧嚣，我们对于DeepSeek的讨论应趋向理性。</p>
  <p><strong>我们不应神话DeepSeek，也不要因为外部的贬低而看轻DeepSeek，这些都对DeepSeek团队不公平。其实，DeepSeek就是一种“小米加步枪”式的成功。</strong></p>
  <p>行云集成电路创始人季宇最近跟我们聊起DeepSeek时说，创新的意识其实国内根本不缺，但缺乏Known-Why的创新往往会走向类似赌徒的歧途。</p>
  <p>“创新不是简简单单的不一样的技术路线，国内其实不缺乏创新性和天马行空的想象，其实无论AI行业还是算力芯片行业，都有无数走非Transformer架构、走非GPU架构、非冯诺伊曼架构的差异化路线，但是基本都陷入了用差异化的技术路线主流技术路线替代品的逻辑里。”季宇说。</p>
  <p>但是DeepSeek的创新是一步一个脚印的。</p>
  <p>季宇告诉我们，第一性原理思考问题很多人都在讲，但实际上非常困难。<strong>第一性原理需要深入推敲，需要对每个论断的边界条件，需要深入考虑各个层级技术的细节。</strong></p>
  <p>“之前跟在DeepSeek的一个师弟交流，梁老板（DeepSeek创始人梁文锋）对他写的CUDA Kernel里每个线程具体在干什么事情都非常清楚，只有这样才能从全局视角去思考突围的方式，真正把创新做成。”季宇说。</p>
  <p>这一点在另一位投资人那里也得到了印证。这位投资人去年曾问DeepSeek的人：“为什么你们的模型做得好？”</p>
  <p><strong>DeepSeek的人回答，因为我们老板自己在读论文、写代码、搞招聘。</strong></p>
  <p>关于DeepSeek的成功，你可以说他们有丰富的GPU储备，可以说他们对模型架构进行了创新，但其成功内核往往是朴实而简单的。</p>
  <p>DeepSeek创始人梁文锋去年接受《暗涌》采访时说过的一句话，既谦虚又意味深长。</p>
  <p>他说：“我们不是有意成为一条鲶鱼，只是不小心成了一条鲶鱼。”</p>
  <p>**参考资料：&nbsp;</p>
  <p>DeepSeek-V3 Technical Report,DeepSeek&nbsp;</p>
  <p>The Llama 3 Herd of Models,Meta&nbsp;</p>
  <p>GPT-4 Architecture, Infrastructure, Training Dataset, Costs, Vision, MoE,SemiAnalysis&nbsp;</p>
  <p>《夜话DeepSeek：技术原理与未来方向》，中国计算机学会青年计算机科学与技术论坛（CCF YOCSEF）</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/elQbehCVT8an2jC4unBHdQ" rel="noopener noreferrer nofollow" target="_blank">“甲子光年”</a>，作者：王博，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156441710664192</id>
            <title>大神卡帕西拿DeepSeek R1讲强化学习，最新大模型内部机制视频爆火，“没有技术背景也能看懂”</title>
            <link>https://www.36kr.com/p/3156441710664192</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156441710664192</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:11:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 卡帕西, 大语言模型, 教育, Eureka Labs  
<br><br>  
总结: Andrej Karpathy发布了一个三个半小时的视频课程，深入解析了大语言模型如ChatGPT的内部工作机制，适合没有技术背景的观众。课程涵盖了模型的预训练、监督微调和强化学习等多个阶段，并通过具体示例讲解了模型的原理和应用。卡帕西强调了教育的重要性，并创办了Eureka Labs，旨在通过AI与教师的共生，提升教育的可及性和质量。他的课程受到了广泛关注，吸引了众多网友熬夜观看。 </div>
                        <hr>
                    
                    <p>宣布全职搞教育的AI大神<strong>Andrej Karpathy</strong>（卡帕西），新年第一课来了——</p>
  <p>发布<strong>三个半小时视频课</strong>，深入解析了ChatGPT等大语言模型的<strong>内部工作机制</strong>，其中涵盖模型开发的完整训练过程、如何在实际应用中最有效地使用它们，还有AI未来发展趋势。</p>
  <p>卡帕西强调，这次是为大众准备的，<strong>即使没有技术背景也能看懂</strong>！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_adefebd91e2b448a977b819500c1a55f@5888275_oswg406445oswg594oswg1308_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他在视频中深入浅出用大量具体示例，如GPT-2、Llama 3.1等，完整讲述了大模型的原理。</p>
  <p>当红炸子鸡<strong>DeepSeek</strong>也没落下，成为一大重点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8fd74341a7a14e74a15882604677881c@5888275_oswg409823oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>卡帕西课程的含金量无需多言，刚一发就被网友团团围住，熬夜也要看的那种。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ed01df6f177043828bf135be87239c91@5888275_oswg46205oswg784oswg170_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网友们表示，接下来三个半小时就这样过了：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_93cf055cb9934c238652f2a55292c21f@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <blockquote>
   <p>你知道，Karpathy发布新视频，一整天都会变得非常美好，每个视频都是金矿！</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1c6238417432410fb78d89de548db78a@5888275_oswg40747oswg794oswg146_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>机器学习工程师Rohan Paul看后也表示其中有关于ChatGPT内部工作机制最简洁明了的解释。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_10ebc63993ea46e590731fcd38b3dc3c@5888275_oswg210573oswg784oswg706_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>话不多说了，以下是重点知识点，文末有完整视频～</p>
  <h2><strong>重点一览</strong></h2>
  <p>用过类似ChatGPT等工具的人可能都会有这样的疑问：</p>
  <p>这个文本框背后是什么？你可以在里面输入任何内容并按回车，但我们应该输入什么？这些生成的词又是什么意思？这一切是如何工作的？你究竟在与什么交流？</p>
  <p>卡帕西在视频中详细解答了这些问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5db56c07cbc24e1a85623d70a5a7e2f0@5888275_oswg47233oswg1080oswg246_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他从如何构建这样一个LLM展开，详细讲解了所有阶段：</p>
  <p><strong>预训练：</strong>数据、分词、Transformer神经网络的输入/输出及内部机制、推理、GPT-2训练示例、Llama 3.1基础推理示例。</p>
  <p><strong>监督微调：</strong>对话数据、“LLM心理学”：幻觉、工具使用、知识/工作记忆、自我认知、模型需要token来思考、拼写、参差不齐的智力。</p>
  <p><strong>强化学习：</strong>熟能生巧、DeepSeek-R1、AlphaGo、基于人类反馈的强化学习（RLHF）。</p>
  <h4><strong>预训练</strong></h4>
  <p>首先是预训练阶段，使模型拥有丰富的知识。</p>
  <p>预训练的第一步是<strong>下载和处理互联网数据</strong>。目标是从互联网的公开资源中获取大量且种类多样的文本、高质量文档，例如FineWeb。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_7941792ce5804062b8ad02dc83db257f@5888275_oswg239456oswg1080oswg503_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>第二步是<strong>文本提取</strong>。</p>
  <p>爬虫获取的是网页的原始HTML代码，需要过滤和处理提取出网页文本，去除导航和无关内容。</p>
  <p>还要进行语言过滤，例如只保留英语占比超过65%的网页，不同公司会根据需求决定保留的语言种类，如果过滤掉所有的西班牙语，那么模型之后在西班牙语上的表现就可能不会很好。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c05368351a454034959bdc1b6f0f5415@5888275_oswg310204oswg1080oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之后，还会进行去重、移除个人身份信息等进一步的过滤步骤，最终得到大规模的文本数据，进入训练集。</p>
  <p>接下来要做的是在这些数据上训练神经网络。在将文本输入神经网络之前，需要将文本转换为一维符号序列。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ae4ee428cd3c40e58c50a676cf840695@5888275_oswg917908oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>通过字节对编码（BPE）算法，将常见的字节组合成新符号，从而减少序列长度并增加符号词汇量。tokenization是将文本转换为符号序列的过程，不同的输入文本会根据tokenization规则生成不同的符号序列。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_4760f96ae02c4e7290c693a48410ce90@5888275_oswg858801oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>训练神经网络时，从数据集中随机抽取token作为输入，并预测下一个token。神经网络的输出是下一个token出现的概率分布。</p>
  <p>通过训练过程不断更新网络参数，使预测结果与实际数据的统计模式一致。</p>
  <p>神经网络内部是一个复杂的数学表达式，输入token序列与网络参数混合，经过多层变换后输出预测结果。现代神经网络结构，如Transformer，具有大量参数和复杂的内部结构，但本质上是通过优化参数来使预测结果与训练数据匹配。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_ac9646a4c2d34ff2ac7974bc009e8b07@5888275_oswg250614oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>训练过程需要强大的计算资源支持，依赖高性能GPU集群，这些硬件能够高效处理大规模并行计算任务，加速模型的训练和优化。随着技术的发展，训练成本逐渐降低，但大规模模型的训练仍然需要大量的计算资源投入。</p>
  <p>卡帕西在视频中以GPT-2为例讨论了训练，包括其参数、上下文长度和训练成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_08f57f8ddbe04d94ade541631826625a@5888275_oswg487532oswg1080oswg624_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>之后他又以Llama 3为例讨论了基础语言模型的属性，它可以生成类似于互联网文档的token序列，并将知识存储在其参数中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fe64f174864445aebf0530248cfc3659@5888275_oswg564398oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然而，模型的输出具有随机性，每次生成的结果可能不同，且模型可能会过度记忆训练数据中的某些内容，导致输出与训练数据高度相似，甚至直接复述某些条目。</p>
  <p>这种现象在实际应用中可能会带来问题，例如模型可能无法区分事实和虚假信息，因为它只是基于训练数据的统计规律进行生成。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_cf36f74d4fa04d4586cf3fe06723ac34@5888275_oswg233426oswg1080oswg595_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>预训练阶段，模型通过大量互联网文档数据学习生成文本的能力，输出为基础模型，它能够生成与互联网文档统计特性相似的token序列，但本身并不是一个能够回答问题的“助手”。</p>
  <p>所以还需要后训练。</p>
  <h3><strong>后训练</strong></h3>
  <p>在后训练阶段，模型通过学习人类标注的对话数据来调整其行为，从而能够生成符合人类期望的回答。数据集规模较小，训练时间也相对较短。</p>
  <p>早期的对话数据集（如InstructGPT）主要由人类标注人员手工创建，但随着技术的发展，现代的对话数据集越来越多地利用现有的语言模型来生成初始回答，然后由人类进行编辑和优化。这些数据集可能包含数百万条对话，覆盖广泛的主题和领域。</p>
  <p>具体来说，后训练包括监督微调（SFT）和强化学习（RL）。</p>
  <p>在监督微调阶段，模型通过创建对话数据集，学习<strong>如何与人类进行多轮对话</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1d20ffea974f494e85374a49f9b6faa8@5888275_oswg268309oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>例如，OpenAI的InstructGPT论文详细介绍了如何通过人类标注者创建对话数据集。</p>
  <p>强化学习阶段，目的是让模型<strong>通过实践和试错来发现解决问题的最佳方法</strong>。</p>
  <p>卡帕西用人类在学校学习的过程类比。预训练相当于阅读课本中的背景知识，微调相当于学习专家提供的解题方法，而强化学习则相当于通过练习题来巩固知识，自己探索解题步骤。</p>
  <p>具体来说，模型会尝试多种不同的解题方法，这些方法可能来自不同的prompt。之后评估解决方案，检查每个解决方案是否正确。正确的解决方案会被标记为“好”，错误的解决方案会被标记为“坏”。</p>
  <p>模型会根据正确答案的解决方案进行训练，强化那些能够得到正确答案的解决方案。这类似于学生在练习中发现有效的方法后，会更多地使用这些方法。</p>
  <p>强化学习和人类标注相比，人类标注者在创建训练数据时，很难知道哪种解决方案最适合模型。人类标注者可能会注入模型不理解的知识，或者忽略模型已有的知识，导致模型难以理解。而强化学习让模型通过试错来自主发现适合自己的解决方案。</p>
  <p>模型会尝试多种路径，找到能够可靠地达到正确答案的解决方案。</p>
  <p>卡帕西用具体示例讨论了强化学习在大语言模型中的应用及其重要性，特别是<strong>DeepSeek</strong>最近发布的论文引发了公众对这一领域的关注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_702732cfe2b24eb8b0a4c7758212c41f@5888275_oswg311578oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他还讲了人类反馈的强化学习（RLHF）工作原理及其优缺点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fb5748c8c2f6411b857f2099c9d24f61@5888275_oswg185375oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后卡帕西提到了多模态模型的发展，模型能够将音频、图像和文本转化为tokens，并在同一个模型中同时处理。</p>
  <p>这种多模态能力将使模型能够进行更自然的交互，例如理解语音指令、处理图像内容等。</p>
  <p>目前局限性在于，模型执行任务时，通常是被动地接收任务并完成，无法像人类那样在长时间内持续、连贯地执行复杂任务。</p>
  <p>未来可能会出现能够持续执行任务的Agent，可以在长时间内执行任务，并定期向人类报告进度。人类将成为这些Agent的监督者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_1a40f12dbf0946aabe2136ec78860496@5888275_oswg164256oswg1080oswg347_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>持续专注于教育的AI大牛</strong></h2>
  <p>卡帕西曾任特斯拉AI主管，之后去了OpenAI，去年2月从OpenAI离职。</p>
  <p>他在整个AI届拥有超高人气，很大一部分来自于他的课程。</p>
  <p>包括他自己的早期博客文字分享和后来的一系列Youtube视频教程，他还与李飞飞合作开设的的斯坦福大学首个深度学习课程CS231n《卷积神经网络与视觉识别》。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_723bf9db59804aa49b4c36a34f594049@5888275_oswg299850oswg1080oswg332_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今天不少学者和创业者，都是跟着他入门的。</p>
  <p>卡帕西对教育的热情，甚至可以追溯到学生时期在网上教大家玩魔方。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_05e3998cb8754de08dc9499ecf43c57c@5888275_oswg230719oswg1080oswg303_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>去年7月，从OpenAI离职的卡帕西突然官宣创业，搞了一家AI原生的新型学校——<strong>Eureka Labs</strong>。</p>
  <p>怎么理解AI原生？</p>
  <p>想象一下与费曼一起学习高质量教材，费曼会在每一步中1对1指导你。</p>
  <p>不幸的是，即使每个学科都能找到一位像费曼这样的大师，他们也无法分身亲自辅导地球上的80亿人。</p>
  <p>但AI可以，而且AI有无限的耐心，精通世界上所有的语言。</p>
  <p>所以卡帕西要打造“教师+人工智能的共生”，可以在一个通用平台上运行整个课程。</p>
  <blockquote>
   <p>如果我们成功了，任何人都将易于学习任何东西，扩大教育这个概念本身的“范围”和“程度”。</p>
  </blockquote>
  <p>目前在EurekaLabs的官方GitHub账号上也有相关课程了，手把手带你构建一个类似ChatGPT的故事生成大模型，感兴趣的童鞋可以去一睹为快。</p>
  <p>视频链接：https://www.youtube.com/watch?v=7kVfqmGtDL8</p>
  <p>参考链接：https://x.com/karpathy/status/1887211193099825254</p>
  <p>Eureka Labs：eurekalabs.aigithub.com/EurekaLabsAI</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/lBc0-8ByRxJ3JBJpMcfzkQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156431180667657</id>
            <title>为什么BAT没做出DeepSeek</title>
            <link>https://www.36kr.com/p/3156431180667657</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156431180667657</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:05:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepSeek, AI应用, 开源策略, 创新团队  
<br><br>  
总结: DeepSeek的迅速崛起在于其团队多年的深耕与技术积累，成功吸引了大量用户，日活用户在上线20天内突破2000万，成为全球增速最快的AI应用。与传统大厂依赖现有业务体系不同，DeepSeek以创新为核心，敢于从零开始，推动技术前沿的发展。创始人梁文锋强调中国AI不能永远处于跟随地位，必须实现原创与创新。DeepSeek的成功也促使大厂重新思考其创新逻辑，面临技术话语权的挑战。 </div>
                        <hr>
                    
                    <p>一夜之间，DeepSeek抢走了几乎所有国产大模型的风头。</p>
  <p>过去一年，无论是在C端出圈的Kimi，还是后在居上的豆包，无论是用户日活早早突破2亿的文心一言，还是登顶全球开源第一的通义千问，与DeepSeek给全球科技圈带来的震动相比，都逊色不少。</p>
  <p>这并非是一众国产大模型不给力，而实在是DeepSeek太优秀了。</p>
  <p>以前国内大厂一直讨论的是，距离OpenAI到底有多少年差距，但在DeepSeeK这里，却是另一番景象。市场热议的是DeepSeeK是否已经干翻了OpenAI，其所代表的开源路线，已经在倒逼OpenAI CEO山姆·奥尔特曼进行反思：“我个人认为，在这个问题上我们站在历史的错误一边。现在需要想出一个不同的开源策略。”</p>
  <p>DeepSeek的横空出世，其带来的影响不仅是在行业内，同样也更在C端市场。</p>
  <p>数据显示，仅仅上线20天，DeepSeek的日活就突破了2000万大关，成为全球增速最快的AI应用。与之相比，ChatGPT突破1500万大关花了244天，而DeepSeek仅用了18天。上线20天后的DeepSeek日活已达2215万，是ChatGPT日活用户的41.6%，并远超豆包日活用户的1695万。</p>
  <p>这是一场极其夸张的AI风暴，并且跟以往截然不同的是，这是一家真正由中国创业公司主导引发的AI风暴。</p>
  <p>问题在于，为什么是DeepSeek？</p>
  <p>要知道，过去两年国内主流的互联网大厂都在大模型赛道上投入重兵，也都跑出了不少产品，市场也普遍抱有期待，希望其中有谁能早上追上OpenAI，与硅谷AI一较高下。</p>
  <p>但最终破局的，却是DeepSeek，大厂没做到的，它反而实现了。</p>
  <h2><strong>深耕已久</strong></h2>
  <p>本质上DeepSeek当下的爆火，是一种厚积之下的爆发。</p>
  <p>虽说此次DeepSeek是一鸣惊人，但其团队早就在AI领域布局多年，时间线上甚至比大厂还早，布局宽度以及深度，也丝毫不比大厂差多少。</p>
  <p>公开数据显示，DeepSeek，由知名私募巨头幻方量化孕育而生，创始人为梁文锋。</p>
  <p>事实上，早在大学期间，即便在当时，人工智能还是一个空有理论并无实质的概念，但梁文锋无比笃信，“人工智能一定会改变世界”。</p>
  <p>这也成为了其创业以来的终极愿景。</p>
  <p>2015年梁文锋创办幻方，这是是国内最早使用人工智能进行量化交易的公司，2016年第一份由深度学习生成的交易仓位上线执行，2017 年全面应用深度学习技术进行交易。</p>
  <p>到了2018年，幻方官网将“把AI确定为公司的主要发展方向”写入公司大事，再一年，幻方干脆改变了组织架构，成立了幻方AI，对外自我介绍时总说自己是一家以大规模深度学习基础研究与应用为核心的人工智能公司。</p>
  <p>自2019年至2021年间，幻方相继自主研发了“萤火一号”与“萤火二号”AI集群，其中“萤火二号”投资达到10亿元，极大提升算力支持。同时，幻方也积极招募了一批算法科学家。而创始人梁文锋本人，则每天也都在写代码、跑代码。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_db730cb023e046fc9a5e5ea91e779bc5@5888275_oswg47005oswg899oswg673_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>技术上，一直在稳步储备，基建上，更是没有落下。</p>
  <p>可能很少有人能预料到，2023年当ChatGPT横空出世时，市场突然发现在国内，拥有高性能GPU芯片最多的不是人工智能公司，而是梁文锋旗下的幻方量化。</p>
  <p>彼时根据国盛证券研报，在云算力端，当时除了几家互联网公司（商汤、百度、腾讯、字节、阿里），就只有幻方有超过1万张A100芯片储备。</p>
  <p>足见，幻方对AI的投入，对比大厂，丝毫不落下风。</p>
  <h2><strong>反套路</strong></h2>
  <p>还有就是，以梁文锋为代表的DeepSeek创业团队的锐气。</p>
  <p>互联网大厂的AI战略往往依附于现有业务体系。腾讯的AI需服务于社交与游戏生态，阿里的AI需嵌入电商和云计算场景。这种业务协同逻辑，固然能快速商业化，却也框定了技术演进的路径——资源投入越多，越倾向于优化既有模式，而非另辟蹊径。</p>
  <p>而背靠幻方的DeepSeek，既有强大的财力支持，又有身为创业者敢于“从零开始”，不怕试错的勇气。这让DeepSeek只需要沿着创新的信念，一路蹚过去。</p>
  <p>对于创新，梁文锋的态度是非常坚决的——“过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。”</p>
  <p>“我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。”</p>
  <p>而如何实现创新，则是抛弃惯性的反套路。</p>
  <p>最直接的体现，就是在团队组成上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_70b2574b9e2d4ab989ae74cdeb5f5ef6@5888275_oswg615331oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来自于幻方官网</p>
  <p>国内大厂在进入大模型赛道上，通常倾向于去海外挖人，引入技术大牛，快速拉起一个团队，然后大干快上。而DeepSeek团队组多由本土一些Top高校的应届毕业生组成，不看经验资历，选人的标准一直都是热爱和好奇心。</p>
  <p>同时在工作机制上，“我们一般不前置分工，而是自然分工。每个人有自己独特的成长经历，都是自带想法的，不需要push他。探索过程中，他遇到问题，自己就会拉人讨论。不过当一个idea显示出潜力，我们也会自上而下地去调配资源。”</p>
  <p>“如果有想法，每个人随时可以调用训练集群的卡无需审批。同时因为不存在层级和跨部门，也可以灵活调用所有人，只要对方也有兴趣。”</p>
  <p>换句话说，大厂的组织架构，本质是一台精密运转的“效率机器”。但颠覆性创新的诞生，需要的恰恰是反效率的“失控”。</p>
  <p>而DeepSeek正做到了这一点。</p>
  <p>AI蓝媒汇也就为什么大厂没有做出DeepSeeK的问题，向DeepSeek提问，后者表示，本质上是组织惯性、商业化压力与技术路径共同作用的结果，并称：</p>
  <blockquote>
   <p>这场由开源模型引发的技术革命，正在倒逼大厂重新思考创新逻辑。若无法跳出既有框架，其技术话语权或将进一步削弱。&nbsp;</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_d51d94661eba4efcab89ef03e32f5350@5888275_oswg229371oswg1080oswg1804_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/2d13vfq93sW9Ig63VrcpcQ" rel="noopener noreferrer nofollow" target="_blank">“AI蓝媒汇”</a>，作者：叶二，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156440683322121</id>
            <title>200亿，佛山要出资了</title>
            <link>https://www.36kr.com/p/3156440683322121</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156440683322121</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:05:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 产业基金, 佛山, 新兴产业, 投资  
<br><br>  
总结: 佛山市发布了总规模200亿元的佛山新动能产业基金，旨在推动新兴产业发展和产业转型升级。该基金将通过直接投资、母子基金和专项基金的形式，重点关注新型电力系统、机器人、新能源汽车等战略性新兴产业。佛山正处于新旧动能转换的关键阶段，设立产业基金有助于促进资本要素在金融市场和实体产业之间的流通。未来，佛山将发挥国资投资引领作用，确保投资的可持续性，推动传统与新兴产业的协调发展。 </div>
                        <hr>
                    
                    <p>产业基金开始热闹了。</p>
  <p>投资界-解码LP获悉，佛山市高质量发展大会日前召开，总规模200亿元的佛山新动能产业基金发布，连同N支市场化产业投资基金，组成佛山新动能产业基金体系。</p>
  <p>回顾过去一年，千亿产业基金接踵而至，城市之间发力新兴产业的迫切心情溢于言表。新年伊始，这场攸关城市命运的产业竞赛仍在继续。</p>
  <h2><strong>佛山发力：200亿，存续期15年</strong></h2>
  <p>佛山新动能产业基金体系具体有哪些内容？</p>
  <p>公告显示，该体系包括设立1支佛山新动能产业基金和N支市场化产业投资基金。其中，佛山新动能产业基金总规模200亿元，首期规模40亿元，存续期长达15年，彰显耐心资本。基金管理人则由佛山市国资委实控的佛山市金融投资控股有限公司担任。</p>
  <p>该基金以新动能命名，即向新质生产力要发展新动力。据悉，基金将通过“直接投资+母子基金+专项基金”的形式，重点聚焦产业链补链延链强链，着重投向三大重点领域——</p>
  <p>一是产业发展引导方向，重点投向新型电力系统装备、机器人、新能源汽车、新能源、新材料、新型储能、半导体芯片、新型显示、医药健康、低空经济等战略性新兴产业领域以及绿色氢能、生成式人工智能、细胞和基因治疗等未来产业领域的链主企业；</p>
  <p>二是科技创新专项方向，重点投向具备明显创新属性和成长潜力的种子期、初创期企业或项目；</p>
  <p>三是产业转型并购方向，重点投向先进制造业和传统优势产业的成长期、成熟期项目。</p>
  <p>而配套的N支市场化产业投资基金，将通过整合存量资源、引入社会资本联合设立。通过二者结合，佛山市将发挥市级统筹、国资投资引领作用，支持科技创新和产业转型升级。具体说来，即计划通过5年左右时间，推动形成覆盖企业全生命周期、突出重点投向、在市场上有一定影响力、规模不低于1200亿元的产业基金矩阵，通过“投大投强”“投早投小”“投稳投增”相结合，不断塑造发展新动能新优势。</p>
  <p>为何要打造这样的产业基金体系？据了解，佛山正处于新旧动能转换的关键阶段，民间资金十分充裕，金融机构本外币存款余额近3万亿元，位居全国地级市前列，但其转化为资本要素的动力却明显不足。</p>
  <p>而产业基金的设立，则有利于畅通资本要素在金融市场和实体产业之间的流通渠道，推动更好融入全国统一大市场建设；同时聚焦重大战略、重点领域和市场不能充分发挥作用的薄弱环节，推动产融深度对接，发挥基金引领带动作用，支持现代化产业体系建设，加快培育发展新质生产力。</p>
  <p>接下来，佛山将发挥国资投资引领作用，最大限度让这些民间资金动起来、活起来，作为“耐心资本”和“战略资本”倒逼佛山产业结构调整，实现传统与新兴产业“两条腿走路”，以更长期主义的方式，确保投资可持续性。</p>
  <h2><strong>吹响产业号角</strong></h2>
  <p>人勤春来早，新的产业竞赛已经在开工第一天打响。</p>
  <p>正如今年广东在全省高质量发展大会上表示，将一手抓传统产业、优势产业巩固优化，一手抓新兴产业、未来产业培育壮大，聚焦人工智能和机器人两大领域集中发力，建设更具国际竞争力的现代化产业体系。</p>
  <p>同时，广东发布《广东省建设现代化产业体系2025年行动计划》，直接提出充分用好私募股权基金、耐心资本作用，巩固提升20个战略性产业集群，抢先布局发展人工智能、机器人、低空经济、生物制造等新兴产业和未来产业，打造更多万亿元级、千亿元级产业集群，迫切心情不言而喻。</p>
  <p>还有江苏。去年通过江苏省战略性新兴产业母基金，接连组建两批产业专项基金，出资超过900亿。而在日前召开的“一中心一基地一枢纽”建设推进会中，江苏省再次强调：更大力度发展新兴产业和未来产业，紧扣“51010”战略性新兴产业体系，深入开展强链补链延链，打造一批世界级战略性新兴产业集群。</p>
  <p>此前以3000亿“3+N”杭州产业基金集群出圈，杭州也在日前会议上将发展新质生产力、强化创新产业布局视作重要目标。Deepseek总部所在的拱墅区，将在今年引进五大产业生态圈重点项目15个、亿元以上产业项目60个，推进高新技术产业投资增长；走出宇树科技的滨江区，则以产业创新牵引新型工业化，壮大人工智能等产业集群，争创省级人形机器人未来产业先导区；而培育了游戏科学、云深处科技的西湖区，力争人工智能、生命健康、空天信息三大产业产值达2200亿元。</p>
  <p>湖南则召开招商引资工作座谈会，提出创新招商方法，结合湖南实际积极探索产业链招商、平台招商等好机制好办法，吸引更多生产要素，延续去年成立金芙蓉、推动“4X4”产业体系发展的节奏；重庆“新春第一会”实施以“33618”现代制造业集群为核心的现代化产业体系做大做强行动，推动优势主导产业、新兴产业未来产业、传统产业“智改数转绿色化”、现代服务业4个“集聚成势”。</p>
  <p>目之所及，浩浩荡荡。</p>
  <p>创投兴则产业兴，产业兴则城市强。新春号角吹响，谁能在新一轮产业争夺战中勇立潮头，谁就能在下一轮城市洗牌中抢占先机。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/e30DiJxqEG5lsfAZwgwOgQ" rel="noopener noreferrer nofollow" target="_blank">“解码LP”</a>，作者：岳笑笑，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156441158327046</id>
            <title>2025年首月开户数披露，超去年6个月份</title>
            <link>https://www.36kr.com/p/3156441158327046</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156441158327046</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:04:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: A股, 新开户, 投资者, 政策红利  
<br><br>  
总结: 2025年1月，A股市场个人投资者新开账户达156.3888万户，显示出市场稳健开局。尽管较2024年部分月份有所回落，但市场情绪依然热情。2025年新开户趋势将受到政策红利、科技投资和资金结构优化等多重因素影响。年轻投资者的涌入和机构资金的长期布局将共同塑造市场新格局。政策的持续释放和科技主线的共振将推动开户增长，A股市场正经历从规模扩张向高质量发展的转变。 </div>
                        <hr>
                    
                    <p>上交所最新披露2025年1月A股新开股票账户数据。</p>
  <blockquote>
   <p>数据显示，2025年1月个人投资者新开A股账户达156.3888万户，机构投资者新开户数为0.6097万户。尽管较2024年部分月份的高点有所回落，但这一数据仍显示出市场在新年开局阶段的稳健态势。</p>
  </blockquote>
  <p>如何看156万的开户数据？2024年有6个月新开户数在150万以上，结合春节因素，可见2025年开年的市场情绪相对热情。这其中，2024年最低开户数是在8月份，仅新增开户99万户，其他低于150万户的月份分别为2月（129万户）、4月（147万户）、5月（126万户）、6月（107万户）、7月（115万户）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0d7dd47f7dca4bd7b132453af9ed2850@5888275_oswg247732oswg1080oswg837_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>展望2025全年，A股新开户趋势将受政策红利释放、科技投资主线及长期资金入市资金结构优化等多重因素影响，年轻投资者的涌入与机构资金的长期布局，将共同塑造更具活力的市场新格局。</p>
  <h2><strong>2025年1月A股新开户平稳开局</strong></h2>
  <blockquote>
   <p>根据上交所披露的《股票账户新开户状况表》，2025年1月A股市场个人新开户数环比2024年12月的198.0910万户下降约21%，同比去年1月下降19.74%，这其中一个重要因素在于2025年春节假期部分在1月。春节假期是一个重要影响因素，去年2月的129.1945万户开户就是一个相对低位。</p>
  </blockquote>
  <p>机构投资者方面，0.6097万户的开户数较2024年12月的0.8194万户有所减少，但较2024年全年均值0.6457万户（机构A股开户数全年累计7.7488万户）仍处于合理区间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5d0a9348530f4d4ea926cdaac1c39844@5888275_oswg99928oswg1080oswg319_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值得注意的是，B股市场的新开户数进一步萎缩。2025年1月个人B股新开户仅0.0390万户，机构B股开户0.0017万户，延续了近年来B股市场流动性不足、投资者兴趣转移的趋势。</p>
  <h2><strong>2025年A股新开户趋势将受多重因素影响</strong></h2>
  <p>2025年开年新开户数的平稳开局，为全年市场发展奠定了基础。展望全年，A股新开户趋势将受政策延续性、科技投资主线及资金结构优化等多重因素影响。</p>
  <p>一方面，政策红利持续释放，提振市场信心，证监会2025年重点工作明确“稳字当头”，包括深化投融资改革、支持科技创新等，叠加个人养老金入市扩大，长期资金增量可期。此外，外资券商加速布局（如高盛、城堡证券申请牌照），外资流入与境内资金形成合力，进一步吸引机构和个人投资者入场。</p>
  <p>另一方面，科技主线与年轻化需求将共振。数据显示，高风险偏好的“Z世代”投资者占比翻倍，其偏好ETF、量化产品等工具，推动被动投资占比提升。政策对“新质生产力”的倾斜（如AI、机器人）或成为2025年开户增长的新引擎。</p>
  <p>与此同时，A股资金供需将持续优化，2025年预计险资等增量资金规模达千亿元级别，ETF持续成为主力增量来源，为散户提供低门槛入场渠道。同时，减持新规抑制大股东抛售，解禁规模低位运行，市场稳定性增强，有利于吸引中长期投资者。</p>
  <p>当下A股市场正经历从规模扩张向高质量发展的深刻转变。新开户数据的稳健增长，既是市场活力的体现，也是投资者对中国经济长期向好的信心投票。未来，在政策红利释放、科技创新驱动、国际化进程提速的多重助力下，A股有望成为全球资本配置的重要目的地，为投资者创造可持续的价值回报。</p>
  <h2><strong>回顾：政策催化2024年开户潮</strong></h2>
  <p>回顾2024年，A股新开户数据呈现明显的“波浪式”特征。从全年来看，个人投资者新开A股账户累计达2492.1440万户，机构账户7.7488万户，其中，2024年10月个人开户数飙升至683.9747万户，单月数据远超其他月份，成为全年最大亮点。</p>
  <p>2024年9月，一揽子政策组合拳落地，直接推动10月新开户数飙升至683.97万户，单月数据超过前五个月总和。政策红利释放叠加股市赚钱效应，吸引大量新股民入场，券商一度因“开户潮”加班应对。</p>
  <p>从开户结构来看，2024新开户投资者中，“85后”和“90后”占比超六成，“00后”参与度快速提升，30岁以下投资者占比从政策前的15%跃升至30%。线上开户渠道（如支付宝接入）成为重要推手，凸显年轻群体对便捷化服务的偏好。</p>
  <p>2024年新增开户从开户渠道、年龄段、入金情况、投资品种以及投资方向等方面，都展现出多样化。不同年龄段的投资者通过多元化的开户渠道涌入市场，各自有着不同的投资风格和偏好。在入金和投资方向上，虽然整体表现出一定的谨慎，但也不乏对市场热点和政策导向的积极响应。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/mzy57s9nEs-oyYPOtu5I5g" rel="noopener noreferrer nofollow" target="_blank">“创业板观察”</a>，作者：王晨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156396318129670</id>
            <title>Deep Seek爆火后，AI军备竞赛2.0要来了吗？</title>
            <link>https://www.36kr.com/p/3156396318129670</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156396318129670</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:57:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <Deep Seek, 人工智能, AI军备竞赛, 薪资待遇>
<br>
<br>
总结: Deep Seek在春节期间引发了广泛关注，成为中美苹果免费应用排行榜的第一名，超越了Chat GPT。其以低训练成本实现与顶级AI模型相媲美的性能，促使科技股大幅波动。多家科技巨头宣布与Deep Seek合作，显示出市场对其技术的认可。Deep Seek的团队薪资待遇较高，吸引了大量人才，尤其是在AI领域。与此同时，Deep Seek也面临着仿冒网站和不法课程的挑战，提醒用户提高警惕。 </div>
                        <hr>
                    
                    <p>在春节期间，唯一能和“赛博秧歌队”争抢热度的选手，或许只有Deep Seek了。</p>
  <p>毕竟前者为我们带来了来自硅基生命的“生理震撼”；后者为我们带来了来自硅基生命的“智力震撼”。</p>
  <h2><strong>AI军备竞赛 2.0要来了</strong></h2>
  <p>作为一家人工智能初创企业，来自杭州的深度求索可谓在春节期间出尽了风头。</p>
  <p>1月27日，该公司旗下应用Deep Seek冲上中美苹果免费应用排行榜第一名，在力压Chat GPT成为各地用户心目中的“AI一哥”之余，为美国科技股带来了行业巨震。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_798e252aede341009aedff1bd2dcde07@5322854_oswg149080oswg646oswg520_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在数据层面，芯片巨头英伟达当日股价暴跌近17%、半导体公司AMD股价下跌6%、博通公司股价下跌17%，微软、Meta、谷歌母公司Alphabet等耳熟能详的名字，也均在本起事件中出现了不同程度的股价波动。</p>
  <p>究其原因，是因为DeepSeek-V3以极低的训练成本换来了同Claude Sonnet 3.5、GPT-4o等业内顶级模型相媲美的性能。用摆在眼前的产品让世界各地的AI企业、科技公司意识到盲目堆积算力本质上是一种“力大砖飞”的行为，是对公司资金储备、投资人注资的盲目消耗。</p>
  <p>毕竟除DeepSeek-V3外，在两个月内研发、基础计算能力投资不到600万美元的DeepSeek-R1同样可以和那些花费数亿、数十亿美元所研发的模型“掰掰手腕”。 再一次用实力证明了“足够精巧的算法”可以实现性能与成本的平衡，让人工智能模型的开发成本不再以“亿”为单位。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5ac1ba5d205e4c03add677c57355d73a@5322854_oswg690582oswg660oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>市场是敏锐的，即便Deep Seek刚刚引发了美国科技股巨震，但这仍不能撼动海外企业同其合作的热情。</p>
  <p>江苏省科协在2月6日发布的文章指出，目前英伟达、微软、亚马逊这三家老牌科技巨头，已经宣布了自己和Deep Seek达成合作的消息，正式决定接入DeepSeek-R1用以提升自己在AI时代的产品竞争力。</p>
  <p>另在国内市场。</p>
  <p>人民邮电报在2月7日发布的文章也指出，三大运营商（中国移动、中国联通、中国电信）已宣布全面接入Deep Seek，并希望将其同自身平台、资源相融合。以此在打通Deep Seek多场景、多产品应用生态的同时，加速“AI普惠”这一愿景的实现进程。</p>
  <h2><strong>Deep Seek薪资待遇曝光</strong></h2>
  <p>在这段时间里引发网友关注的，不仅有Deep Seek系列模型的交互能力，还有Deep Seek团队成员的工资待遇。</p>
  <p>通过对Deep Seek的母公司幻方量化进行调研，有媒体发现其当下招聘的重心分别为数据研发工程师、深度学习研究员、核心系统研发工程师，工作地点则多在杭州或北京。</p>
  <p>在薪资待遇层面，公司除采用“14薪”制度外，还为大部分岗位提供了2万+/月的起薪。至于“深度学习研究员（AGI）”这类人才竞争更激烈的岗位，其月薪待遇更是被推上了8-10万/月。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_a021e114e11f485a9ea9a5c3a3e1be47@5322854_oswg143034oswg694oswg552_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除此以外，在Deep Seek团队内薪资相对较高的岗位还有数据研发工程师、核心系统研发工程师，其薪资范围分别在4-7万/月、7-8万/月。甚至AGI岗位实习生的工资也高达500-1000/每天，算下来可轻松实现“月薪上万”的人生目标。</p>
  <p>值得一提的是，此前雷军以千万年薪为代价挖来的“AI天才少女”罗福莉，其另一层身份便是Deep Seek团队的前成员（她曾以深度学习研究员的身份参与了DeepSeek-V2的开发项目）。雷军将罗福莉招致麾下担任小米AI大模型团队领导者的决定，也在一定程度上向我们展现了当下各科技公司对Deep Seek成员的认可度如何。</p>
  <p>《2024年度人才迁徙报告》指出，在2024年的TOP 20热招岗位中，有5个同AI相关场景有关。其中算法工程师、大模型算法、自然语言处理、人工智能工程师等岗位均属于热门职位。</p>
  <p>另截止到2024年12月，中国的生成式人工智能产品用户规模已高达2.49亿人，约占整体人口的17.7%。在巨大的用户需求、用户规模面前，当前就业市场的大模型、人工智能相关人才储备也略显不足。以至于有行业报告预测在2030年，中国的AI人才缺口将高达400万。</p>
  <p>以上种种信息也让我们意识到，在未来相当长的一段时间内，不仅人工智能专业会成为广大学生的T1级选择；其相关赛道员工的待遇，也将随着用户规模、需求的进一步放大而成为众人羡慕的对象。</p>
  <h2><strong>AI也逃不过人红是非多</strong></h2>
  <p>俗话说人红是非多，AI也不例外。</p>
  <p>爆火的Deep Seek不仅吸引了投资者和常规用户的目光，还吸引到了一小撮不怀好意的人。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_2b3e6414a93b435887ca332bd8fb7cc2@5322854_oswg60555oswg915oswg420_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2月6日，奇安信发布报告表示在2024年12月1日-2025年2月3日这一区间内，共出现了2650个仿冒Deep Seek的网站。而这些躲在“山寨网站”背后的人，或是希望借Deep Seek之名窃取个人信息，或是欲披着Deep Seek的“马甲”去传播恶意软件骗取订阅费用。</p>
  <p>另除注册钓鱼网站外，目前市面上还有大量打着“Deep Seek带你躺着赚钱” “如何用Deep Seek赚到100万”等旗号的付费课程。甚至连AI爱好者平日里进行交流的社区，也有人趁机推出了Deep Seek的付费交流群，以“缴纳会员费和业内大佬互动交流”的名义进行敛财。</p>
  <p>这些情况的出现，也在提醒着我们对于普通人而言，想要玩好Deep Seek的第一步也是最重要的一步，就是学会甄别互联网上的信息，帮自己规避那些山寨网站和把“割韭菜”三个字写在脸上的付费教程。</p>
  <p>正如中国通信标准化协会互动媒体标准推进委员会副主席包冉所言，普通用户根本不需要去购买所谓的教程，因为使用Deep Seek不需要再像之前一样打磨提示词，现在各大主流AI都可以直接用自然语言与其交流。</p>
  <p>在过去，AI付费教程崛起的核心概念便是信息差的存在。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_02df10e948a344c7b7be03c1b1e69005@5322854_oswg138144oswg536oswg654_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>由于技术的相对不成熟，当时的模型往往需要用户输入特定的指令集才能得到应有的反馈。所以人们才会去总结自己和AI对话的经验，将其编撰成特定的话术和行文格式，帮助小白用户提升自己的使用体验。</p>
  <p>但随着模型蒸馏、数据训练进程的全面展开，今天Deep Seek的对话能力已经得到了充分升级。所谓的“结构化对话教程”已经成为了过去式，用户只需要进行简单的口语化、日常化指示就能得到自己想要的反馈。</p>
  <p>更别提市面上有不少AI培训课的内容仅仅是对互联网公开信息的拼凑，部分卖家完全不在乎内容的质量如何，他们不过是想赶在“淘金热”到来之际发上一笔“铲子财”罢了。</p>
  <p><strong>参考：</strong></p>
  <p>江苏省科协：三家企业同日宣布接入 DeepSeek，AI 领域竞争进入新阶段</p>
  <p>人民邮电报：三大运营商全面接入DeepSeek加速AI普惠发展进程</p>
  <p>上海杨浦：DeepSeek高薪招人：实习生月入上万，研究员年薪百万！这类人才缺口400万→</p>
  <p>齐鲁壹点：2000多个山寨DeepSeek网站出现，DeepSeek回应来了！</p>
  <p>极目新闻：第一波用DeepSeek“搞钱”的人出现了</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA5MTI5NDgxNA==&amp;tempkey=MTMwOF9ocVUyV2d3Y2xtZzlQd0FkWFhMYkhaOG9BcVY2eVJDRXgwTnJyQ2x2TlRXX1JmbUI1cjRacHBONENmVDFwRWxaNVljRncyV1VXc0IyaHJfRW5MdUhma2ZGeDRYTTkwa0h1cUU2N0oxZVg0anBvMmpXM0dGLWtqaF82akV2NUhFVXo2UExWLWhiN1kzcGpQLW9Ha0FOcE1CQ0lmanByRnpmQUdjd25Rfn4%3D&amp;chksm=0afe0cab3d8985bd05203c857d14b54f5e6ae4eacbd9381364d929ef2ebb922113177d158630&amp;scene=0&amp;xtrack=1&amp;subscene=7#wechat_redirect" rel="noopener noreferrer nofollow" target="_blank">“互联网那些事”</a>，作者：互联网那些事，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3156385750368002</id>
            <title>15年来，“谷歌们”与中国未“脱钩”</title>
            <link>https://www.36kr.com/p/3156385750368002</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3156385750368002</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 10:54:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <谷歌, 反垄断, 出海, 开源>
<br>
<br>
总结: 文章讨论了谷歌在中国市场的反垄断调查及其与中国企业的商业关系。尽管谷歌在2010年退出中国市场，但其在华收入依然增长，尤其是与字节跳动的合作。文章还提到，Tiktok等中国企业在全球市场的迅速崛起，显示出中国企业出海的趋势与能力。与此同时，开源技术的合作也在不断深化，尤其是在安卓生态中，中国企业通过开源降低了开发成本并推动了技术进步。整体来看，全球化与技术合作仍是推动商业发展的重要因素。 </div>
                        <hr>
                    
                    <p>2月4日，市场监管总局官方宣布，对谷歌公司展开反垄断调查。没错，就是美国那个谷歌，虽然新闻不少，但好像跟中国用户没什么关系，他怎么就垄断了？</p>
  <p>媒体分析，谷歌的“垄断”可以涉及在线广告领域，也可能涉及安卓手机系统方面。</p>
  <p>这条新闻唤起了很多人一个久远的回忆。2010年，谷歌宣布退出中国市场，谷歌搜索搬至香港。因此，谷歌好像错过了中国移动互联网大爆发的黄金时代。</p>
  <p>与谷歌境遇相似，全球规模和市值最大的企业中，市值1.76万亿美元的Meta（Facebook）和市值2.5万亿美元的亚马逊 —— 一个挤破头也没有挤进中国市场，一个节节败退，已经停止运营。</p>
  <p>但是，商业与技术总是卷起狂风，难以阻挡。从2010年到现在这15年来，谷歌、Meta、亚马逊与中国从未“脱钩”，因为大家共同活在历史的进程中。</p>
  <h2>出海浪潮下，商业合作永不眠</h2>
  <p>2018年是一个有趣的年份。这一份，特朗普正式对华发起了贸易战。中美的经贸关系进入了一个新阶段，很多人断言，中美关系“再也回不去了”。</p>
  <p>然而，也就是这一年，据The information 报道，谷歌在华收入增长60%，成为了过去15年间增长最快的一年。</p>
  <p>为什么这一年增长如此迅猛？当年，谷歌最大的中国客户是字节跳动，那正是抖音海外版Tiktok强势出海的时候。那年谷歌在大中华区（中国大陆+港澳台）收入30多亿美元，其中，字节跳动向谷歌支付了3亿美元，占10%。</p>
  <p>Tiktok在2018年开启了疯狂出海之旅。谷歌旗下的YouTube，Meta旗下的Facebook、Instagram以及面向年轻人的社交平台Snap上疯狂投放广告。 MediaRadar 数据，2018至2020年三年间，Tiktok的全球营销总费用高达50亿美元。</p>
  <p>疯狂营销的同时，Tiktok也迎来了疯狂的增长。2018年，Tiktok的月活用户同比增长近3倍。Statista数据，2024年4月，Tiktok月活用户数超过15.82亿，成为全球第5大最受欢迎的社交App，前4名分别是Facebook、YouTube、Instagram和WhatsApp。</p>
  <p>明明开打贸易战，为什么Tiktok仍能迅猛出海？其实，2018年，抖音的月活用户突破5亿，正式超越快手，成为中国最大的短视频平台。于是，验证了产品和商业模式之后，抖音的创始人张一鸣相信，地球人其实都一样，挡不住短视频和推荐算法的诱惑，所以挥师出海。</p>
  <p>基于自身和行业的需求出海，而并不受到贸易战的影响，这是2018年中国企业出海的一个新特点。</p>
  <p>Tiktok也是中国企业加速出海的缩影。过去15年，中国企业不再局限于做跨国企业的供货商。他们走向消费市场，直面消费者。谷歌、Facebook，就是中国企业出海的最大广告平台，亚马逊，则是中国商品的最大海外销售平台。三者分工合作，联通全球市场。</p>
  <p>谷歌、Meta、亚马逊都在中国大陆保留了团队。从公开信息上看，谷歌的团队规模最大，广告营销团队就超过100人，全国有20多个广告中心。在北京海淀区的融科资讯大厦，谷歌中国办公室占据了5-7层。同时，谷歌在中国还有庞大的代理商体系。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_09cdb147c53242f19814c90b190d449b@14303255_oswg241668oswg1080oswg958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（谷歌中国办公室位于北京海淀的融科大厦，据悉，AI明星企业深度求索的北京办公室，也在这座楼里。）</p>
  <p>不过，谷歌退出中国市场，也留下了后遗症。一位做线上营销的朋友说，跟客户推荐在谷歌做营销，有两个难点，一是客户以为google已经退出中国了，二是以为google只有搜索引擎。</p>
  <p>除了搜索引擎，谷歌系的Youtube、Google Play应用商店，Meta旗下的Facebook、Instagram、WhatsApp和Messenger，以及全球最大的电商平台亚马逊，都是重要的在线营销平台。</p>
  <p>不管怎么说，出海企业利用三巨头阵地，走向海外市场。中国企业的拿手好戏，就是通过广告营销和买量，推动新的应用快速起步。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_fed272f296134992831315df0bc90f11@14303255_oswg62377oswg1034oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（Temu在超级碗投放的广告）</p>
  <p>外媒曾经震惊到，拼多多旗下的Temu2023年在美国进行了30亿美元的广告投放（伯恩斯坦研究公司估算数据），而另一家市场机构Morketing则把Temu列为了2023年美国十大广告主之一，排在迪士尼之前。</p>
  <p>Temu的核心广告语是“像亿万富翁一样购物”，通过程序化广告等不同的投放方式，这句话不断投放到各类社交媒体上，投放到网页广告上，甚至投放到美国春晚“超级碗”上，并根据数据反馈不断优化效果。</p>
  <p>与Temu在海外相爱相杀的是服饰电商Shein。Shein是互联网版的Zara，通过快速模仿，并快速在instagram、facebook上请网红带货，迅速走红。</p>
  <p>Shein是互联网版的Zara，通过以女装为主的快时尚服饰起家，它充分利用Instagram、Facebook、YouTube等主流社交媒体平台，联合各路网红，进行品牌推广。Shein打通了“种草+电商”的模式闭环，吸引了大量年轻消费者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0fe4f5cbd7b3409dbf1bda9f694ac662@14303255_oswg58404oswg803oswg319_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（Shein在海外的增长数据）</p>
  <p>尽管Shein经常被称为“新加坡公司”，但其供应链、制造和研发核心仍然在中国。2023年，Shein登上了全球购物App下载榜的首位。有预测称，Shein2025年的营收将达到585亿美元，并可能在今年一季度以505亿英镑的估值在伦敦证交所上市。</p>
  <p>Temu和Shein，二者背靠的都是全球规模最大，生产能力最强的制造业大国，面向的又是北美这个全球最大的消费市场。2018年以来，虽然贸易战从未停下，但随着2020年“口罩”后的美联储大放水，中国对外贸易顺差加大，Temu和Shein无疑顺应了这一历史进程。</p>
  <p>同样，还有众多中国品牌也参与到这一进程中。不过，他们无力像Shein那样自建网络平台，通过亚马逊销售一直是首选。</p>
  <p>2021年，B站网红UP主“老师好我叫何同学”改装了一款升降办公桌，加上了可移动的无线充电接口、蓝牙音箱等一系列智能化改装和设计，视频迅速走红。这款升降桌的原型来自上市公司乐歌股份，乐歌的股价随之涨停。</p>
  <p>此前，乐歌股份在国内并不出圈，它是一家典型的在海外先富起来的中国品牌。乐歌旗下的品牌flexispot一直在亚马逊升降桌品类中稳居榜首。</p>
  <p>类似这样的品牌很多，大疆无人机、安克Anker等，在智能家居设备（如扫地机器人）、家电、手机配件、服饰等品类上，中国产品都已经打响了品牌。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_8273910399bc4c60aa5bf4e8ace621ac@14303255_oswg404846oswg1080oswg683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图片说明：亚马逊销售的大疆无人机）</p>
  <p>更多白牌产品，则通过跨境电商卖家的努力，同样在亚马逊畅销。据Marketplace Pulse的研究，中国卖家占亚马逊美国站TOP卖家的近50%。</p>
  <p>近年，中国的娱乐产品正在冲击欧美市场。中国游戏行业出已经成风之外，过去两年，短剧也冒出了头。</p>
  <p>用大众文化产品冲击美国市场，这是过去一百年，中国人难以想象的一种变化。这大概也论证了，人类在底层需求上是相通的。</p>
  <p>谷歌、Meta和亚马逊，无论自己的C端业务在国内发展的情况如何，始终抓紧中国市场。</p>
  <p>早在10年前，白熊观察员作为财经记者，一直在跟踪跨境电商发展。在深圳，一个跨境电商行业协会主办的年会上，谷歌、亚马逊和Meta的销售代表，先后在不同的分论坛上登场演讲，推销自己的产品和服务。</p>
  <p>活动的主要参会者，是广东、福建等地数以百名各类跨境电商企业的老板们。</p>
  <p>那正是奥巴马时代，经历了08年金融危机后，美联储开足水龙头，持续放水。另一方面，具备超强制造能力的中国企业，生产的产品在国内难以消化，出海仍然是最佳选择。</p>
  <p>虽然也有一些类似乐歌、安克这样的企业，在出海成功后，又杀回了国内市场，但更多的企业还是在加速出海。某种程度上说，2021年以前，中国消费者的消费欲主要在楼市上，2021年之后，中国消费者对房子的消费欲突然就消失了，而且并没挪到别的地方——虽然大家还是愿意看《哪吒2》这样的好电影，但“内需”确实不够理想，这种现状也引发了无数争议。</p>
  <p>国信证券研报数据，从2019年起，谷歌、Meta和亚马逊三巨头在全球广告市场（不包括中国地区）的占比从41%增长到60%左右。这形成了事实上的垄断。彭博社预计，2024年谷歌的广告收入为2639亿美元，Meta预计为1595亿美元，亚马逊预计为563亿美元。</p>
  <p>特别值得注意的是亚马逊，依靠电商广告收入增长，它最近三年的年复合增长率达到60%。</p>
  <p>三巨头的成功中，中国的企业贡献不少。Meta首席财务官Susan Li曾在财报会上表示，“2023年度，来自中国客户的广告投放方投入构成了Meta总收入的10%，并贡献了Meta 5%的收入增量。其中，在线电商和电子游戏公司是中国厂商的投放主力。”</p>
  <p>亚马逊的数据显示，中国企业贡献了第三方服务收入（2023年为1400亿美元）的“很大一部分”。同时，中国品牌出海也是亚马逊广告收入增长的重要动力。</p>
  <p>不过谷歌没有透露来自中国的收入占比。这两天有自媒体称，中国企业出海广告有“67%流向谷歌系平台”，这个数据很可能是AI编造的，因为谷歌的广告市场份额只有不到三成。另一方面，中国企业更是在不断开拓新的阵地，避免对合作伙伴形成依赖。2019年，Tiktok是美国年轻人喜爱的社交应用Snap最大的广告主，同时它在线下也进行了大规模的推广。</p>
  <p>此外，谷歌云和AWS等云服务与中国企业的合作也不断深化。据公开报道，谷歌云与国内多家企业联合推出AI、大数据等解决方案；亚马逊AWS帮助中国企业实现全球云部署，合作规模已达数十亿美元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_0ac5dded6e664dafa508e74663820c41@14303255_oswg254327oswg361oswg501_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当然，中国企业的崛起，也在挑战着三巨头的垄断地位。</p>
  <p>Tiktok顶着美国政府的封禁大棒，也成为了重要的广告投放平台。据《晚点LatePost》报道，2021年Tiktok的广告收入约为40亿美元，而市场机构测算，2023年它的广告收入可能已达到132亿美元，2024年预计能有300亿美元。随着Tiktok等平台的崛起，2022年以来，谷歌和Meta在美国市场的广告份额已经跌破了50%。</p>
  <p>Temu和Shein的崛起，已经强烈冲击了美国同行。第三方数据，Temu用了三年时间杀到了美国电商的第六名，并占据了17%的美国市场份额。Shein成为美国五大在线时尚电商之一，占据快时尚服饰在线消费市场的40%份额。</p>
  <p>这本应该是商业社会的常态，竞争与合作永远是共生的，也永远不会停歇。然而，今年特朗普再次上台之后，贸易战跟七年前已不可同日而语。就在昨天，白宫叫停了中国寄往美国的“邮政小包”免税政策。通过邮政小包，以较低的运费将商品卖到美国，这正是跨境电商控制成本的秘诀。尽管这个政策维持了半天就暂停了，</p>
  <p>历史虽然常常相似，但很少真正重复，这一次又会如何发展？</p>
  <h2>技术合作，在开源的旗帜下</h2>
  <p>近年，国产手机崛起，已经一统除了苹果之外的手机市场，似乎已经没有谷歌什么事，当然我说的是在国内。</p>
  <p>但安卓，仍然是大家绕不过去的名字。有人说，谷歌可能是中国用户最多的美国公司。不过这个说法很不准确，因为安卓本身是一个开源生态。</p>
  <p>开源社区起源于1980年代，开源软件往往会公开源代码，参与者可以自由查看、修改和分发。开源社区不仅有各类技术极客，也有各种科技企业。包括谷歌、Meta和亚马逊三巨头，也包括许多中国企业。企业积极参与开源生态，因为这是一种把蛋糕做大的方式。</p>
  <p>2007 年 11 月，Google 联合 84 家硬件制造商、软件开发商、电信运营商及芯片供应商成立了开放手持设备联盟（Open Handset Alliance），并打造了Android开放平台。</p>
  <p>2007年，正是全球化快速扩张阶段，中国等新兴国家不断融入世界贸易体系，这也是WTO作用最大化的阶段。与此同时，移动互联网时代兴起，新兴国家也在积极参与信息技术的变革，安卓开源操作系统为新兴国家参与移动互联网时代提供了便利，在经济和技术变革进程交织推进的时代里，它得到了各国的积极响应。</p>
  <p>不过，也就是2007年，中、印、俄、巴西等国家展开了多次双边和多边会谈，这为2009年“金砖国家峰人”（BRICS）做好的准备，新兴国家开始争取更大的话语权。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_c0508a0270b0496e964b8450869d6777@14303255_oswg15950oswg600oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Android 的核心——AOSP，允许任何人免费使用、修改和再分发，全球的开发者和厂商都可以在此基础上定制和改进自己的操作系统。</p>
  <p>所以，谷歌虽然主导了安卓操作系统，但并不拥有安卓的用户。因为随着市场发展，单纯使用原生安卓并不足以形成竞争优势。国内企业借助安卓的开源生态，大幅定制用户界面和系统功能，形成了如 MIUI（小米）、EMUI（华为）、ColorOS（OPPO）、Funtouch OS（vivo）等品牌定制系统。这些系统在视觉和交互体验上更加符合中国消费者的审美和使用习惯。</p>
  <p>目前安卓生态已经成为了移动市场的绝对主流。安卓的市场份额，从2008年的不到1%增长到如今绝占85%。中国的主流手机厂商，都是安卓生态的一部分，即使像华为如今开始了自研手机操作系统。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_5e9f101805e54fcb8f95305895d05b2a@14303255_oswg25118oswg1011oswg324_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>共建生态，本质就是一种全球的技术合作。</p>
  <p>以前有一种论调：在安卓的开源生态领域，中国企业贡献不大，因为安卓系统的底层代码，绝大多数是谷歌、高通、三星等企业贡献的，中国企业参与甚少。</p>
  <p>这是事实的一部分，而非全部。中国企业确实在参与安卓生态。对于中国企业来说，利用开源安卓系统，低操了作系统开发的成本和风险，企业可以将更多资源投入到软件优化和生态服务构建中。</p>
  <p>中国企业也在应用层、服务和中间件开发等做了不少开发，繁荣了安卓生态。</p>
  <p>例如，华为开发的EROFS文件系统，通过透明压缩和只读设计提升了手机启动速度和安全性，这个文件体系统已经开源。</p>
  <p>小米则利用MiCode平台，开源了大量内核定制、MACE神经网络计算框架、Open-Falcon监控系统和Pegasus分布式存储系统。</p>
  <p>开源可以说是一种商业选择，但也确实是一种技术文化。</p>
  <p>但是伴随着全球化成长起来的技术文化传统，遇到了新的问题。在贸易战加剧的背景下，“脱钩”成为媒体的高频词。高层在博弈，大众很担忧，所以，研发更加“自主可控”，更加“安全”的信息操作系统，变成一种必然。</p>
  <p>华为率先推出了完全自研的鸿蒙操作系统，并最终脱离安卓生态，其它厂商也开始跟进。安卓联盟虽然没有瓦解，但很少有厂商主动宣传。</p>
  <p>但这并不意味着开源合作时代的终结，相反，可能才刚刚开始。随着生成式AI时代的到来，开源成了通往人工智能殿堂的一条大道。中国也成为了少数站在生成式AI开源前沿的国家。</p>
  <p>在安卓时代，谷歌、高通完善安卓底层源代码，华为、小米研大量新应用，这似乎是一种理所应当的局面。这种局面在AI大模型时代刚刚到来的时候，也沿用了下去，甚至像朱啸虎这样的资深投资人，把这种模式当成最合适的道路。不过，没过多久，中国的工程师们就不再只局限于“做应用”了。</p>
  <p>2022年，当ChatGPT横扫AI大模型领域之时，也是闭源大模型遥遥领先于开源之日。那时，Meta及其创始人扎克伯格，却成了开源领域的旗手。扎克伯格率先将Llama1、Llama2模型开源，其中Llama2模型是当时全球最大的开源模型，性能上也接近ChatGPT4.</p>
  <p>为什么是他？这可以说是Meta的一种商业策略，也可以说是扎克伯格技术极客的底色。尽管在Facebook成功后，扎克伯格经常被媒体当作唯利是图的奸商。在生成式AI时代，扎克伯格对于技术前沿展现了很强的判断力。之后，更多的开源大模型涌在市场上，中国也出现了大模型“六小龙”等把研发AI大模型当成方向，而不只是做应用的公司。</p>
  <p>当然，热闹之下鱼龙混杂。也有一些公司，似乎在将Llama等开源模型改头换面，包装成“自研”的大模型，也就是所谓“套壳”。当时有一种说法叫“百模大战”，各类企业都号称做出了自己的“大模型”，但最后发现，套壳相当普遍。</p>
  <p>阿里巴巴前副总裁贾扬清就曾爆料了一家这样的企业，有人挖掘出，这家公司疑为李开复的创业项目“零一万物”的中英双语大模型“YI”。不过李开复很快发声称，不存在套壳、抄袭等行为，是从零开始训练，只是沿用了Llama的架构。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_94b285c8fa7543e48d2b68eb3aa2ba6d@14303255_oswg128659oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（Llama的本义是“羊驼”，颇有喜感的名字，图片为豆包AI生成）</p>
  <p>不管怎么说，如今，中国企业成为AI大模型领域开源生态最重要的贡献者。例如，2023年，阿里的通义千问Qwen大模型打响了开源第一枪。之后阿里将Qwen大模型各类不同的版本进行了全家桶式的开源。业界普遍认为，阿里开源的Qwen全家桶，性能不逊于Llama。</p>
  <p>刚刚过去的这个春节，中国AI企业深度求索的开源大模型DeepSeek-R1引发生成式AI领域的一次地震，AI大模型算是一次真正意义上的“出圈”。DeepSeek-R1也是一个开源大模型。</p>
  <p>DeepSeek-R1 在工程技术方面实现了一次突破，采用高效的模型压缩与优化技术，证明了可以用更少的算力，实现更强的性能，显著降低了训练与部署成本。</p>
  <p>开源生态正在越来越强盛。2月6日，有“AI教母”之称的李飞飞及其团队，号称只用了不到50美元，就训练出一个名为S1的模型，它在数学和编码能力能够比肩OpenAI的o1和DeepSeek的R1等尖端推理模型。研究人员表示，s1是通过蒸馏法由谷歌推理模型Gemini 2.0 Flash Thinking Experimental提炼出来的，谷歌的Flashi Thinking正是谷歌发布的一个具备很强能力的开源模型。</p>
  <p>此前，一直坚守闭源模型领域李彦宏在发布上说，“开源模型会越来越落后”。这个观点引发了很大的争议，现实给了他一个新的回应。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250207/v2_765bc4dd9cb740e68d02aca2b2510c27@14303255_oswg37582oswg655oswg452_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图片为文心一言发布会截图）</p>
  <p>开源的繁荣，为人们提供了更多的探索玩法。其实，DeepSeek此前发布的V3版本大模型已经引发了业界的广泛关注。不同类型的优秀开源大模型，甚至可以通过技术手段进行整合。</p>
  <p>例如，DeepSeek-R1-Distil-Qwen-7B就是基于Qwen-7B进行蒸馏优化的推理模型，其参数量为7B，专注于数学、代码和推理任务，它利用R1模型将通义千问的Qwen核心能力提取并得到更小的模型，同时显著利用的DeepSeek-R1系列模型在推理速度和资源消耗上的优势。</p>
  <p>DeepSeek-R1-Distil-Qwen-7B不仅免费开放，还支持开发者进行修改和二次开发。一位金融公司的IT负责人向白熊观察员证实，这种小模型已经被它们应用在需要快速反应的数据分析领域。</p>
  <p>开源生态的重要价值，不仅在于提供了有用的东西，还在于避免踩雷。在信息不畅通的时代，“重复造轮子”是一个常态，前人走的坑，后人却需要再走一遍，浪费了大量的时间、金钱和精力。</p>
  <p>DeepSeek的成功，就是中国企业在研发过程中首次站到前沿技术的潮头，去探索未知的领域，主动试错，主动“蹚雷”。DeepSeek的成果，将给行业带来很多新的启发。</p>
  <p>另一方面，DeepSeek的创始人梁文锋在接受采访的时候说，要实现AGI，不按照Llama的结构走，这样才能在有限的资源下，实现更强的模型能力。梁文锋踩在了前人的肩膀上，实现了一次跨越。</p>
  <p>政治局势的变化，不仅引起贸易战，更引发了“技术战”。美国等一些国家的政客开始呼吁审查DeepSeek，开源生态的未来也蒙上了一层阴影。</p>
  <p>从历史上看，每一次技术革命后，技术扩散都是必然，问题是时间。</p>
  <h2>白熊观察：</h2>
  <p>从历史和现实看，全球化可能是个无法真正逆转的过程。全球化推动了商业和技术的发展，它也让人们紧密联系到了一起。</p>
  <p>过去三十年，全球化是全球技术进步、商业繁荣最重要的推动力之一，少数国家没有汇入全球化浪潮，不管嘴上怎么说自己国民生活幸福，天天被太阳照耀，恐怕都难以让人羡慕。</p>
  <p>如今，全球化陷入暂时的波折，一些人以狭隘的政治利益为借口，破坏全球化合作，制造分裂和对抗，这恐怕是一股逆流。</p>
  <p>是的，我说的就是美国的特朗普。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/sdm6pxVxls0k-eJpURUjVg?token=846157393&amp;lang=zh_CN" rel="noopener noreferrer nofollow" target="_blank">“白熊观察员”</a>，作者：白熊观察员，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>