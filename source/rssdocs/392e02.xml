<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2471182490671237</id>
            <title>短剧APP开启百剧大战：抖音携红果入局，国资和头部大厂跑步进场</title>
            <link>https://www.36kr.com/p/2471182490671237</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471182490671237</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:59:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 短剧, 百剧大战, 平台, 收费模式
<br>
<br>
总结: 短剧行业正在进行一场百剧大战，各个平台纷纷进场，包括国家队和头部大厂。这些平台的收费模式各不相同，有的免费观看但需要看广告解锁，有的需要充值会员或购买看点。其中，红果采用了免费模式，购买过期版权并免费提供给用户观看，这种打法备受关注。整个行业的发展还在初期阶段，平台的背景并不是用户关注的重点，他们更关心短剧的质量和是否能满足他们的需求。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d099dde87bd84095aaa86eca0b12eef3@5888275_oswg126082oswg1080oswg743_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>几乎所有细分领域都会出现4321的过程，这是产业竞争到后半程，整合阶段时才会出现的。新财富机会出现时，总是大量人涌上去。在这之前的多进4阶段，就像是之前的百团大战、百播大战、百车大战……</p><p>短剧就是这样一个燃起硝烟的赛道。被所有人认可财富效应的短剧，正燃起一场百剧大战，各色背景从业者正冲上去，短剧混战缓缓拉开了序幕。</p><p>短剧原本的播放路径与平台深度嫁接。用户在微信成熟的支付习惯，小程序刷剧时，可以顺手支付。除了小程序，不少短剧平台也开发了APP。</p><h2><strong>01 百剧大战：国家队与头部大厂进场了</strong></h2><p>新腕儿在苹果应用商店搜索「短剧」，下载并整理了时下所有短剧APP，大约24家。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_1a1cc37db395483fbbc53e0b687b3e07@5888275_oswg190357oswg1080oswg1843_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这些短剧APP模式、收费标准、界面、幕后背景等全然不同，另一个值得注意的地方是以国广环球传媒、中广电传媒、中文在线、抖音等为代表的头部企业已经进场了。&nbsp;</p><p>在创投圈，大家追赶新蓝海终究是为了更大的商业价值和意义。即便背靠巨头，盈利思路也不会受太多干扰。&nbsp;</p><p>例如抖音旗下的红果，被称为短剧版番茄小说，他们平台可以免费看短剧。但在中广电旗下的河马剧场，他们需要看广告解锁，或者充值会员。&nbsp;</p><p>这是短剧与其他业态融合后的结果。&nbsp;</p><p>都哪些企业进场了？大家都是怎么做的？背景雄厚的优势是什么？什么样的平台才能胜出？专注于短剧研究的新腕儿将带你抽丝剥茧。&nbsp;</p><p>短剧忠实客群是下沉市场，他们不是很在意平台背景，而是这款产品是否真的好用，短剧是否能成为深夜里一杯抚慰身心疲劳的暖心茶。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_b83ee7e8facb4a8db8ce5f8758bb4680@5888275_oswg172902oswg1080oswg1652_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>刚刚引燃的「百剧大战」，都哪些选手进场了？&nbsp;</p><p>新腕儿梳理了目前在苹果应用商店中出现的短剧APP，总共24款。&nbsp;</p><p>从产品幕后主体来讲，各有千秋。&nbsp;</p><p>有两款APP为国资企业所出，分别是河马剧场和瑞网微剧。&nbsp;</p><p>河马剧场是中广电传媒有限公司旗下产品，他们主打「全网短剧，免费看」，但实际上，前10集是免费的，往后每集需要看广告解锁。如果不想看广告的话，可以直接充值会员和看点。&nbsp;</p><blockquote><p>他们收费模式是，10元/周、29元/月、49元/季、99元/年，充值看点的话，是1元100看点。放眼整个行业的收费标准来讲，河马剧场的收费标准并不算太高，只能是比较居中的位置。&nbsp;</p></blockquote><p>而瑞网微剧是国广环球传媒旗下产品，他们在一些地方的设置上更有些亮点。平台前5集是免费的，但新用户刚来到时，平台会赠送5000金币，新用户能用这些金币解锁付费剧集，金币用完后，就需要充值了。&nbsp;</p><p>1元钱可以充值100看点，一部剧平均花费10块钱，前后两个多小时。&nbsp;</p><p>从平台收费模式来讲，两个平台区别并不大。&nbsp;</p><p>除了国资有进场，互联网头部也在着手布局。&nbsp;</p><p>抖音旗下也推出了短剧平台「红果」，但其整个运营思路是截然不同的。&nbsp;</p><p>不像其他平台都是收费模式，在红果看短剧是不收费的。&nbsp;</p><p>平台会购买已经过期的短剧版权，这类版权价格普遍便宜，平台低价买回后，免费给用户们观看。&nbsp;</p><p>也有部分内容是完全免费获得，比如番茄小说授权拍成短剧后再回流到红果。&nbsp;</p><p>他们将短剧和小说内容分为不同栏目并列放置，网文爱好者来到平台后，可以选择小说和短剧，以此形成浓厚的网文生态，增加用户沉淀。&nbsp;</p><p>以目前来看，红果烧钱做补贴的免费模式在行业中，可谓是一股清流，反其道行之的打法，正是外界关注的重点。&nbsp;</p><p>很显然，红果的思路和免费小说的思路完全一致，先聚拢流量，最后凭借广告变现，或者部分精品短剧内容实行付费观看。&nbsp;</p><p><strong>据消息人士向新腕儿透露，目前红果日活已经在500万左右，大有再造视频版番茄的潜力。</strong></p><p>曾经的秀场直播头部平台映客，早就出现在短剧行业，除了有短剧制作公司外，还推出了短剧APP天天追剧。&nbsp;</p><p>天天追剧APP的Logo设计和优酷有几分相似，都是以蓝白红色系为主。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_b0abb20cda4547f69d75175c120d03a4@5888275_oswg622433oswg925oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就连内部界面设计的也很像，相同色系所做的表示，但短剧的内容相对较少。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_7dbc2a64a4eb4322896b1437c947578e@5888275_oswg625266oswg720oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">右边是天天追剧APP界面&nbsp;</p><p>在短剧行业，资源和资金储备是重要优势，国资和互联网头部的两项条件都是具备的。除此之外，版权优势就是关键了。&nbsp;</p><p>这些短剧APP产品中，有不少平台本身都有小说版权资源。&nbsp;</p><p>例如野象剧场，他们所属北京鸿达以太科技有限公司，也就是创业板出版上市公司中文在线（SZ300364）；等鱼短剧是花生小说旗下的短剧平台。&nbsp;</p><p>另外包括天天看剧、泡泡短剧、麦田短剧，从企查查数据看到，他们背后所属的公司均为动漫、小说类企业，这也意味着，他们天然具备一定的版权优势。&nbsp;</p><p>短剧转型的企业，或多或少都有一定相关的资源优势。&nbsp;</p><p>不止是动漫类企业转型于此，影视公司九州文化所做的星芽短剧，浙江德明影视传媒有限公司制作的蚂蚁看看，还有长春希乐旗下的乐刷短剧。&nbsp;</p><p>同时，MCN机构麦芽传媒也推出了麦芽短剧。&nbsp;</p><p>动漫、影视企业开发的短剧产品，还是比较垂直的。&nbsp;</p><p>也有稍显边缘的企业也加入其中，例如游戏公司昶飞游戏所做的闪动星剧场；还有素社短剧由一家软件公司制作；每日一剧创始人原先做体育用品批发，开过便利店，如此从业背景，与短剧行业看起来格格不入。&nbsp;</p><p>纵观这些短剧APP的背景情况，会发现目前短剧市场还是比较多元的，各类选手都有自己的优势和擅长的地方，而短剧的门槛也不是很高，连实业批发的从业者也来到短剧市场。&nbsp;</p><p>优渥的从业背景的确帮助选手拿到不错的入场券，但究竟能走多元，终究是一场关于模式和内容的比拼。&nbsp;</p><p><strong>新腕儿认为，每个行业的百X大战，最终都只有少数有钱有流量的头部玩家可以笑到最后，而且，独立短剧APP相比小程序短剧来说，可以说是鸡肋。</strong></p><p>一方面，用户要下载独立APP，并且还要进行苹果支付，本身就是高门槛，另一方面，APP所有方并不希望充值收入有苹果30%的分成被拿走，同时，APP所有方为了获取用户，还需要花钱去做APP下载，这个路径看起来怎么都不是最优解。&nbsp;</p><p>比起粗暴直接跳转到微信小程序的短剧小程序，这些APP现在看来更像是「人无我有」的布局。&nbsp;</p><p>更多的短剧小程序都隐藏在微信里，但也只有新剧上线有投流时，才会有新用户进入小程序的短剧剧场，他们不追求用户下载，只在乎用户有没有充值付费。</p><p>如果非要对独立短剧APP说出个123，那很显然，拥有流量路径和版权优势的短剧APP肯定会胜出。&nbsp;</p><h2><strong>02 模糊的版权地带：盗版要了短剧的老命</strong></h2><p>版权，是短剧从业者最头疼的事情，而盗版也是他们非常痛恨的事。&nbsp;</p><p>有从业者向新腕儿透露，B站上有大量盗版短剧内容。在小程序或APP上需要付费观看的内容，在B站就可以免费观看，这对短剧厂商造成了致命的打击。&nbsp;</p><p>短剧是项市场化程度非常高的内容产品，每部剧需要用户们真金白金的投票，最终的收入才是一部短剧成功与否最直观的呈现。&nbsp;</p><p><strong>盗版猖獗会导致短剧行业变得更加短平快。</strong> 原本短剧内容用足够的时间制作，可以做更多剧情反转，从而吸引用户冲动消费，但盗版的出现，会极大程度缩短拍摄制作时间，短剧内容质量会很快下降。&nbsp;</p><p><strong>业内人士透露，盗版情况在B站是比较严重的，但并不止步于B站。</strong></p><p>新腕儿翻阅了这些短剧APP和他们所属企业的工商信息后发现，各家平台对版权认知和处理措施上，良莠不齐。&nbsp;</p><p>例如瑞网微视，这家短剧平台的版权意识很强的，他们会在每部剧页面加上原著小说名和作者，在一种短剧平台中，是很难得的事情。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_f2d50ea4fcaf49d8b604fa395cb759eb@5888275_oswg596355oswg720oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">瑞网微视平台上的内容，都加了版权水印&nbsp;</p><p>短剧APP聚多多也是类似的情况，他们的每部剧都会标注作品来源和作者。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d4f7f453f9d841c89c3a350fbf4ba6cf@5888275_oswg861121oswg960oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">聚多多APP平台上的内容&nbsp;</p><p>还有蚂蚁看看，平台每部剧都有对应的公司，供应商包括日新月益等。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c587c93da1e24c40b79a8242679bfa50@5888275_oswg633495oswg960oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">蚂蚁看看APP上的内容&nbsp;</p><p>另外，像是河马剧场、野象剧场、红果、梦剧场、星芽剧场，都是一部分的剧标注了作品来源或备案号。&nbsp;</p><p>新腕儿了解到，一分钟剧没有备案要求，但短剧是要求备案的。因此，平台上所有的短剧都要有备案。&nbsp;</p><p>以上短剧平台由于基因不同，我们不好下判断。例如红果、星芽等本身有很强的内容资源，因此，或许在版权上会有相关的处理。&nbsp;</p><p>像是星芽都是自制剧，版权方面或许有另外的处理。&nbsp;</p><p>不过，以竞品的短剧版权标注来看，短剧内容上的来源水印标注，还是很有必要的。&nbsp;</p><p>一个值得留意的细节是，据企查查数据显示，野象剧场背后主体公司北京鸿达以太科技有限公司目前正涉及版权纠纷，关于著作权版权纠纷案。&nbsp;</p><p>最后像其他平台上的短剧，并未有任何版权内容上的标注。&nbsp;</p><p>例如素社短剧，平台播放的《触碰你的灵魂》被起诉，称其擅自在平台播放。&nbsp;</p><p>有些平台的剧目还很少，例如麦萌短剧，只有5部剧，其中有3部短剧，还有2部是动物和大自然的视频，尚未起量，还有很多需要强化的地方。&nbsp;</p><p>另一方面，目前短剧从业者泥沙俱下，行业内洗稿、套拍和抄袭的现象也层出不穷，如果是这种本身也涉嫌侵权的短剧，最终被其他盗版者搬运到免费平台，如果你再去维权，多少有些五十步笑百步的意味。</p><h2><strong>03 商业模式探讨：广告变现还是付费观看</strong></h2><p>抛开百剧大战战事进展，我们可以来谈谈目前各家短剧平台运营情况，以几家典型平台作为例子来讲。&nbsp;</p><p>首先是收费模式。我们在第一部分介绍过几家平台收费模式，本质上，这是一场关于收费和免费模式的讨论，换句话说，究竟用哪种方式收费，在覆盖运营成本的同时，让用户们开心付费，方为最优解。&nbsp;</p><p>显然，红果作为抖音推出的一张短剧王牌，让竞品们压力很大，主要是红果短期内并没有赚钱的目标。&nbsp;</p><p><strong>「在抖音内部做创业项目，你可别提赚钱，如果项目靠谱，有多少亏多少，先把规模干上去，初期谈赚钱，格局就低了。」</strong> 一位抖音内部员工告诉新腕儿。&nbsp;</p><p>其他厂商做不到，毕竟没有背靠小说版权资源和日活8亿的大平台，听起来很难，但也得做。</p><p>其实看广告视频解锁剧集这件事，可以从两方面理解。&nbsp;</p><p>你可以把它理解为平台的一项收入来源，除了用户看剧的花费，平台还能得到一笔广告费，大程度缓解了成本压力，&nbsp;</p><p>也可以从用户的角度来理解。对于一些不想付费看剧的用户，他们很乐意看广告视频来解锁新剧。&nbsp;</p><p>毕竟下沉市场的用户时间成本不那么高，下载百度APP、拼多多，还能领红包，他们或许并不那么抵触。&nbsp;</p><p>因此，广告视频像一种变相的「免费」，只是用户体验不那么好。&nbsp;</p><p>以此来理解河马剧场，除了充值，30秒广告解锁，更像是对平台和用户需求的一种平衡性处理。&nbsp;</p><p>但这里广告解锁模式运用的平衡性是内容。就是说，足够优质且丰富的内容下，广告解锁模式才能被理解为变相的免费，否则就成了一门广告生意，纯粹靠短剧风口赚广告费、炒短线。&nbsp;</p><p>有用户评价天天看剧，「能不能多点短剧」。&nbsp;</p><p>在天天短剧平台看剧是没有充值选项的，第十集之后就需要看广告解锁，广告视频甚至没有设置退出功能。&nbsp;</p><p>为了让大家留下来安心看剧，平台也是操碎了心。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0ba85425facf4dd383c74dfb4e1c66be@5888275_oswg235063oswg720oswg839_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>04 结语：让上帝的归上帝，让凯撒的归凯撒</strong></h2><p>百剧大战的出现，更像是一场模式间的交锋。&nbsp;</p><p>市场是开放的，时下各色选手争先涌入短剧市场，以抖音、映客、中文在线等为代表的平台，在原先的行业已经有所建树，他们希望去别的行业寻找新机会，占领更大的市场，这件事情无可厚非。&nbsp;</p><p>大家在版权、模型、流量、平台上各有思考，但短剧终究是个内容行业，最终比拼的一定是内容质量。&nbsp;</p><p>只有花心思为用户创造价值的平台，以优质内容为核心的平台，才能真正活下来。&nbsp;</p><p>时长和紧凑的内容节奏是短剧的特质所在，在生活节奏越来越快的当下，短剧将成为主流视频形式，这需要全行业共同推动。&nbsp;</p><p>最终，健康的短剧行业模式可能是，各路玩家会逐渐聚焦于自己的核心优势，有版权的就专注做内容，有承制能力的就认真拍片子，有投流能力的就扩大ROI，有流量优势的就做好分发平台。</p><p>有观察和研究能力的，就做好外围媒体平台，为行业提供研究和观察，比如新腕儿：）&nbsp;</p><p><strong>短剧大幕已开启，关注新腕儿</strong></p><p>短剧的大幕正在徐徐开启，新腕儿将持续为你带来核心数据分析和一线调研。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/M--ivv7cPhqCTbH5FCdVXg" rel="noopener noreferrer nofollow" target="_blank">“新腕儿”（ID:bosandao）</a>，作者：关注短剧趋势，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471167211149447</id>
            <title>GPT-4就是AGI，谷歌斯坦福科学家揭秘大模型如何超智能</title>
            <link>https://www.36kr.com/p/2471167211149447</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471167211149447</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:56:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌研究院, 斯坦福HAI, AI模型, AGI
<br>
<br>
总结: 谷歌研究院和斯坦福HAI的两位专家认为，现在最前沿的AI模型已经具备了通用人工智能（AGI）的能力。这些模型无需针对性训练，就能完成各种任务，实现了通用人工智能的能力。 </div>
                        <hr>
                    
                    <p>谷歌研究院和斯坦福HAI的两位专家发文称，现在最前沿的AI模型，未来将会被认为是第一代AGI。最前沿的LLM已经用强大的能力证明，AGI即将到来！</p><p>通用人工智能（AGI），其实已经实现了？&nbsp;</p><p>最近，来自谷歌研究院和斯坦福HAI的大佬发文称，现在的大预言模型就是通向AGI的正确方向，而且现在最前沿的模型，已经拥有AGI的能力了！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_426bb3d884df47c689f92c30ab2ce574@5888275_oswg20378oswg944oswg326_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这两位作者都是AI业界大佬，Blaise Agüera y Arcas现在是Google Research副总裁兼研究员，曾经也在微软任职。主要研究领域是人工智能基础研究。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_951a42a64cc34186b8a472e3a87a2210@5888275_oswg198736oswg512oswg288_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Peter Norvig是一位美国计算机科学家，是斯坦福AI研究所研究员，也是Google Research的工程总监。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_87feaceeea0d44498081be7232a776dc@5888275_oswg266534oswg680oswg373_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不同的人眼里的通用人工智能（AGI）的含义，是完全不一样的。&nbsp;</p><p>当前最先进的AI大型语言模型几乎已经实现了大部分对于AGI的畅想。&nbsp;</p><p>虽然这些「前沿模型」有许多缺陷：它们会编造学术引用和法庭案例，从训练数据中扩展人类的偏见，而且简单的数学也算不对。&nbsp;</p><p>尽管如此，今天的前沿模型甚至能胜任它们没有训练过的新任务，跨越了前几代人工智能和有监督深度学习系统从未达到的门槛。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_ceaf02ec97464f3eacb786675ada74d4@5888275_oswg126824oswg300oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>几十年后，它们将被公认为第一批达到AGI能力的范例，就像现在回头看1945年的ENIAC一样，它就是第一台真正的通用电子计算机。&nbsp;</p><p>即使今天的计算机在速度、内存、可靠性和易用性方面都远远超过了ENIAC。但是ENIAC可以使用顺序指令、循环指令和条件指令进行编程，这赋予了它前辈（如差分分析仪）所不具备的通用性。&nbsp;</p><p>同样，未来的前沿人工智能也会在今天的基础上不断进步。&nbsp;</p><p>但通用性的关键属性呢？&nbsp;</p><p>它已经在现实的大语言模型上实现了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_85485b285a314fc39ac27f745f37c5a3@5888275_oswg1198915oswg1080oswg1094_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>01 什么是通用人工智能？</strong></h2><p>早期的AI系统虽然在执行任务的能力上，可以接近或超过人类的水平，但通常只能专注于单一任务。&nbsp;</p><p>比如，斯坦福大学Ted Shortliffe在20世纪70年代开发的MYCIN，只能诊断细菌感染并提出治疗建议；SYSTRAN只能进行机器翻译；而IBM的「深蓝」也只会下国际象棋。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_40a6f438e34946a2ae54520458d2331b@5888275_oswg803299oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>后来，经过监督学习训练的深度神经网络模型，如AlexNet和AlphaGo，成功完成了很多早期启发式、基于规则或基于知识的系统，长期无法解决的机器感知和判断任务。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_601b8135e6af4f7a94240325bad5751a@5888275_oswg201947oswg850oswg666_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最近，我们看到了一些前沿模型，它们无需进行针对性的训练，就能完成各种各样的任务。&nbsp;</p><p>可以说，这些模型在五个重要方面实现了通用人工智能的能力：&nbsp;</p><p><strong>- 话题（Topic）</strong></p><p>前沿模型是通过数百千兆字节的文本训练而成，这些文本涵盖了互联网上几乎所有讨论过的话题。其中，一些模型还会在大量多样化的音频、视频和其他媒体上进行训练。&nbsp;</p><p><strong>- 任务（Task）</strong></p><p>这些模型可以执行各种任务，包括回答问题、生成故事、总结、转录语音、翻译语言、解释、决策、提供客户支持、调用其他服务执行操作，以及组合文字和图像。&nbsp;</p><p><strong>- 模态（Modalities）</strong></p><p>最受欢迎的模型主要处理图像和文本，但有些系统也能处理音频和视频，并且有些与机器人传感器和执行器相连。通过使用特定模态的分词器或处理原始数据流，前沿模型原则上可以处理任何已知的感官或运动模态。&nbsp;</p><p><strong>- 语言（Language）</strong></p><p>在大多数系统的训练数据中英语所占的比例最高，但大模型却能使用数十种语言进行对话和翻译，即便在训练数据中没有示例的语言对之间也可以实现。如果训练数据中包含了代码，模型甚至可以支持自然语言和计算机语言之间的「翻译」（即通用编程和逆向工程）。&nbsp;</p><p><strong>- 可指导性（Instructability）</strong></p><p>这些模型能够进行「上下文学习」，也就是根据提示而不是训练数据来进行学习。在「少样本学习」中，一个新任务会配有几个输入/输出示例，然后系统会基于此给出新的输入对应的输出。在「零样本学习」中，会描述一项新任务，但不会给出任何示例（例如，「以海明威的风格写一首关于猫的诗」）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_b40d16b27c4f4bafa7d65fc2bf8334fd@5888275_oswg28890oswg1080oswg165_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「通用智能」必须通过多个维度来考虑，而不是从单一的「是/否」命题。&nbsp;</p><p>此前，弱人工智能系统通常只执行单一或预定的任务，并为此接受明确的训练。即使是多任务学习，也只能产生弱智能，因为模型仍在工程师设想的任务范围内运行。事实上，开发弱人工智能所涉及的大部分艰巨工作，都是关于特定任务数据集的整理和标注。&nbsp;</p><p>相比之下，前沿语言模型可以胜任几乎所有人类可以完成的任务，这些任务可以用自然语言提出和回答，并且具有可量化的性能。&nbsp;</p><p>对于通用人工智能来说，上下文学习能力是一项意义重大的任务。上下文学习将任务范围从训练语料中观察到的事物，扩展到了所有可以被描述的事物。因此，通用人工智能模型可以执行设计者从未设想过的任务。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_b1ff09de64284668900aae32f90088c4@5888275_oswg1305068oswg1024oswg978_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据「通用」和「智能」这两个词的日常含义，前沿模型实际上在这方面已经达到了相当高的水平。&nbsp;</p><p>那么，为什么有人不愿意承认AGI的存在呢？&nbsp;</p><p>其原因主要有以下四点：&nbsp;</p><p><strong>1. 对于AGI的度量标准持怀疑态度</strong></p><p><strong>2. 坚信其他的人工智能理论或技术</strong></p><p><strong>3. 执着于人类（或生物）的特殊性</strong></p><p><strong>4. 对人工智能经济影响的担忧</strong></p><h2><strong>02 如何设定AGI的评价指标</strong></h2><p>对于通用人工智能（AGI）的门槛到底在哪里，其实存在很大分歧。业界很多专家们都曾试图完全避讳使用这个词。&nbsp;</p><p>比如DeepMind的联合创始人Mustafa Suleyman建议使用「人工能力智能（Artificial Capable Intelligence）」来描述这种系统。&nbsp;</p><p>他建议通过「现代图灵测试」来衡量这种AI系统——能否在10万美元的启动资金基础上，快速在网上赚取100万美元的能力。&nbsp;</p><p>尽管将「有能力」直接等同于「能赚钱」似乎还是一件值得商榷的事情，但是能够直接产生财富的AI系统肯定会在更加深远的层面上影响世界。&nbsp;</p><p>当然，大众有充分的理由对某些指标表示怀疑。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d3b5399d1a5b4a988c88200c5f401e5c@5888275_oswg33140oswg556oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如当一个人通过了复杂的法律、商业或医学考试时，大众就会假设这个人不仅能够准确回答考试中的问题，而且能够解决一系列相关的问题和复杂任务。&nbsp;</p><p>自然更不会怀疑这个人会具备普通人类所具有的一般能力了。&nbsp;</p><h3><strong>LLM能考试，却不能当医生</strong></h3><p>但是，当训练前沿的大语言模型以通过这些考试时，训练过程通常会针对测试中的确切问题类型进行调整。&nbsp;</p><p>尽管模型可以通过这些资格考试，但是目前的前沿模型当然不可能胜任律师或者医生的工作。&nbsp;</p><p>正如古德哈特定律所说的，「当一项措施成为目标时，它就不再是一个好的措施。」&nbsp;</p><p>整个AI行业都需要更好的测试来评估模型的能力，而且已经取得了不错的进展，例如斯坦福大学的模型评估系统——HELM。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_daf6baa3491b48418ee0d2f38b718c1c@5888275_oswg156253oswg1080oswg546_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">测试集地址：https://crfm.stanford.edu/helm/latest/&nbsp;</p><h3><strong>说话流畅=智能高？</strong></h3><p>另一个非常重要的问题是，不要将语言的流畅性与智能的高低混为一谈。&nbsp;</p><p>前几代的聊天机器人，例如Mitsuku（现在称为Kuki），偶尔会通过突然改变主题并重复连贯的文本段落来蒙骗人类开发人员。&nbsp;</p><p>而当前最先进的，模型可以即时生成响应，而不需要依赖预设文本，并且它们更擅长把握海量文字的主题。&nbsp;</p><p>但这些模型仍然受益于人类的自然假设。也就是说，他们流利、符合语法的回答依然还是来自像人类这样的智能实体。&nbsp;</p><p>我们将其称为「昌西·加德纳效应」，以「Being There」（一部后来被改编为电影的讽刺小说）中的角色命名——昌西受到了世人的尊敬甚至是崇拜，仅仅是因为他「看起来像」一个应该受到尊敬和崇拜的人。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_4e6287e822ed4ceba81310090c750757@5888275_oswg790983oswg960oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>忽然涌现的LLM能力</strong></h3><p>研究人员Rylan Schaeffer、Brando Miranda和Sanmi Koyejo在论文中指出了常见人工智能能力指标的另一个问题：测评指标的难度不是线性的。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6580d792d5d04000bd808203e2f1627f@5888275_oswg15218oswg934oswg333_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://arxiv.org/pdf/2304.15004.pdf&nbsp;</p><p>比如，对于一个由一系列五位数算术问题组成的测试。小模型几乎都不可能回答对，但随着模型规模的不断扩大，将会出现一个临界阈值，在此阈值之后模型将正确回答大部分问题。&nbsp;</p><p>这个现象会让人觉得，计算能力是从规模足够大的模型中突然涌现出来的。&nbsp;</p><p>但是，如果测试集中也包括一到四位数的算术题，并且如果评分标准改为只要能算对一些数字就能得分，不一定非要像人类一样算对所有数字才能得分的话。&nbsp;</p><p>我们会发现：随着模型大小的增加，模型的性能是逐渐提高的，并不会突然出现一个阈值。&nbsp;</p><p>这个观点对超级智能能力或者属性（可能包括意识）可能突然神秘地「涌现」的观点提出了质疑。而「涌现论」确实让大众甚至是政策的制定者产生了某种程度的恐慌。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_4e8690e77c7041d8ab7b904d76898fc0@5888275_oswg408649oswg505oswg499_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>类似的论点也被用来「解释」为什么人类拥有智能，而其他类人猿就没有智能。&nbsp;</p><p>实际上，这种智能的不连续性可能同样是虚幻的。只要衡量智能的标准足够精确，基本上都能看到智力是连续的——「越多就越好」而不是「越多就越不同」。&nbsp;</p><h2><strong>03 为什么计算机编程+语言学≠AGI？</strong></h2><p>在AGI的发展历史上，存在许多相互竞争的智能理论，其中一些理论在一定的领域内得到了认可。&nbsp;</p><p>计算机科学本身基于具有精确定义的形式语法的编程语言，一开始就与「Good Old-Fashioned AI」（GOFAI）密切相关。&nbsp;</p><p>GOFAI的信条至少可以追溯到17世纪德国数学家戈特弗里德·威廉·莱布尼茨 (Gottfried Wilhelm Leibniz)。&nbsp;</p><p>艾伦·纽厄尔（Allen Newell）和司马贺（Herbert Simon）的「物理符号系统假说」进一步具体化这个理论。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_b53c473e042d4609a0fb8d2f3d74130a@5888275_oswg138111oswg1014oswg767_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">文章地址：https://dl.acm.org/doi/pdf/10.1145/360018.360022&nbsp;</p><p>假说认为智力可以用微积分来表述，其中符号代表思想，思维由根据逻辑规则的符号变换构成。&nbsp;</p><p>起初，像英语这样的自然语言似乎就是这样的系统：&nbsp;</p><p>用「椅子」和「红色」这样的符号代表「椅子」和「红色」等概念。&nbsp;</p><p>符号系统可以进行陈述——「椅子是红色的」——也可以产生逻辑推论：「如果椅子是红色的，那么椅子就不是蓝色的。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_4e80e2f5ede6479e9fa098934bb077cf@5888275_oswg63758oswg406oswg322_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然这种观点看起来很合理，但用这种方法构建的系统往往是很脆弱的，并且能够实现的功能和通用性很有限。&nbsp;</p><p>主要是存在两个主要问题：首先，诸如「蓝色」、「红色」和「椅子」之类的术语仅只能被模糊地定义，并且随着所执行的任务的复杂性增加，歧义会变得更加严重。&nbsp;</p><p>其次，这样的逻辑推论很难产生普遍有效的结果，椅子确实可能是蓝色的，也可能是红色的。&nbsp;</p><p>更根本的是，大量的思考和认知过程不能简化为对逻辑命题的变换。&nbsp;</p><p>这就是为什么几十年来，想要将计算机编程和语言学结合起来的努力都没能产生任何类似于通用人工智能的东西的最主要原因。&nbsp;</p><p>然而，一些特别专注于对符号系统或语言学的研究人员仍然坚持认为，他们的特定理论是通用智能前提，而神经网络或更广泛的机器学习在理论上无法实现通用智能——特别是如果如果模型们仅仅接受语言训练。&nbsp;</p><p>ChatGPT出现后，这些批评者的声音越来越大。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_19280c7fb09647b689e0449e2079b8ee@5888275_oswg991862oswg1080oswg943_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">马库斯：在Cue我？&nbsp;</p><h2><strong>04 LLM的推理和语言跟人类截然不同</strong></h2><p>例如，现代语言学之父的诺姆·乔姆斯基（Noam Chomsky）在谈到大型语言模型时写道：「我们从语言学和知识哲学中知道，它们与人类推理和使用语言的方式截然不同。 这种差异极大地限制了这些程序的功能，并给它们编码了无法根除的缺陷。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_97fd6bc2f7e64cfca9cfc5ac493185eb@5888275_oswg51689oswg1015oswg517_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>认知科学家和当代人工智能评论家加里·马库斯（Gary Marcus）表示，前沿模型「正在学习如何听起来和看起来像人类。但他们并不真正知道自己在说什么或在做什么。」&nbsp;</p><p>马库斯承认神经网络可能是通用人工智能解决方案的一部分，但他认为「为了构建一个强大的、知识驱动的人工智能方法，我们的工具包中必须有符号操作机制。」&nbsp;</p><p>马库斯（和许多其他人）专注于寻找前沿模型（尤其是大型语言模型）的能力差距，并经常声称它们反映了该方法的根本缺陷。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_e7e89ce9d6fa42649f00e2617eadbc4c@5888275_oswg13093oswg660oswg221_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这些批评者认为，如果没有明确的符号，仅仅通过学习到的「统计」方法无法产生真正的理解。&nbsp;</p><p>与此相关的是，他们声称没有符号概念，就不可能发生逻辑推理，而「真正的」智能需要这样的推理。&nbsp;</p><p>撇开智能是否总是依赖于符号和逻辑的问题不谈，我们有理由质疑这种关于神经网络和机器学习不足的说法，因为神经网络在做计算机能做的任何事情上都非常强大。例如：&nbsp;</p><p><strong>- 神经网络可以轻松学习离散或符号表示，并在训练过程中自然出现。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_988ff123f01041a39f7839f66084dcc0@5888275_oswg47995oswg457oswg291_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://royalsocietypublishing.org/doi/epdf/10.1098/rsta.2022.0041&nbsp;</p><p><strong>- 先进的神经网络模型可以将复杂的统计技术应用于数据，使它们能够根据给定的数据做出近乎最佳的预测。模型学习如何应用这些技术并为给定问题选择最佳技术，而无需明确告知。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_56a67fc402ee4debb8c5ec2269d6daf6@5888275_oswg83961oswg1080oswg289_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://arxiv.org/pdf/2306.04637.pdf&nbsp;</p><p><strong>- 以正确的方式将多个神经网络堆叠在一起会产生一个模型，该模型可以执行与任何给定计算机程序相同的计算。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_fe8cb5152b974615b0a3d7a2bdaa4807@5888275_oswg56804oswg1080oswg244_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://proceedings.mlr.press/v202/giannou23a.html&nbsp;</p><p><strong>- 提供任意由计算机算出的函数的输入和输出示例，神经网络都可以学会如何逼近这个函数。（比如99.9%的正确率。）</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_f9582a28f231487584a968112daee0ca@5888275_oswg13239oswg853oswg264_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://arxiv.org/pdf/2309.06979.pdf&nbsp;</p><p>对于批评的声音，都应该区别它是原教旨主义型批评还是积极讨论型的批评。&nbsp;</p><p>原教旨主义型批评会说：「为了被认为是通用人工智能，一个系统不仅必须通过这个测试，而且还必须以这种方式构建。」&nbsp;</p><p>我们不认同这样的批评，理由是测试本身应该足够——如果不够，测试应该被修改。&nbsp;</p><p>另一方面，积极讨论型的批评则认为：「我认为你不能让人工智能以这种方式工作——我认为用另一种方式来做会更好。」&nbsp;</p><p>这样的批评可以帮助确定研究方向。如果某个系统能够通过精心设计的测试，这些批评就会消失了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_fc90def236cd43f995edd57da6841f16@5888275_oswg689145oswg1080oswg691_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>语言模型通过将图像编码线性投影到语言模型的输入空间来生成图像的标注&nbsp;</p><p>近年来，人们设计了大量针对与「智能」、「知识」、「常识」和「推理」相关的认知任务的测试。&nbsp;</p><p>其中包括无法通过记忆训练数据来回答但需要概括的新问题——当我们使用测试对象在学习期间没有遇到过的问题来测试他们的理解或推理时，我们要求测试对象提供同样的理解证明。&nbsp;</p><p>复杂的测试可以引入新的概念或任务，探索考生的认知灵活性：即时学习和应用新想法的能力。（这就是情境学习的本质。）&nbsp;</p><p>当AI批评者努力设计新的测试来测试当前模型仍然表现不佳时，他们正在做有用的工作——尽管考虑到更新、更大的模型克服这些障碍的速度越来越快，推迟几周可能是明智的选择（再次）急于声称人工智能是「炒作」。&nbsp;</p><h2><strong>05 人类凭什么是「独一无二」的？</strong></h2><p>只要怀疑论者仍然对指标不为所动，他们可能不愿意接受AGI的任何事实性的证据。&nbsp;</p><p>这种不情愿可能是由于想要保持人类精神的特殊性的愿望所驱动的，就像人类一直不愿意接受地球不是宇宙的中心以及智人不是「生物伟大进化」的顶峰一样。&nbsp;</p><p>确实，人类有一些特别之处，我们应该保持他们，但我们不应该将其与通用智能混为一谈。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_70de089165e24574b1e42f34ed296f8a@5888275_oswg415257oswg1080oswg495_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有些声音认为，任何可以算作通用人工智能的东西都必须是有意识的、具有代理性、能够体验主观感知或感受感情。&nbsp;</p><p>但是简单推理一下就会变成这样：一个简单的工具，比如螺丝刀，显然有一个目的（拧螺丝），但不能说它是自己的代理；相反，任何代理显然属于工具制造者或工具使用者。&nbsp;</p><p>螺丝刀本身「只是一个工具」。同样的推理也适用于经过训练来执行特定任务的人工智能系统，例如光学字符识别或语音合成。&nbsp;</p><p>然而，具有通用人工智能的系统很难被归类为纯粹的工具。前沿模型的技能超出了程序员或用户的想象。此外，由于LLM可以被语言提示执行任意任务，可以用语言生成新的提示，并且确实可以自我提示（「思维链提示」），所以前沿模型是否以及何时具有「代理」的问题需要更仔细的考虑。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_e0324b26a8f642bfa3655cf1cd042a44@5888275_oswg148130oswg1000oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>假设一下，Suleyman的「人工能力智能」为了在网上赚一百万美元可能采取的许多行动：&nbsp;</p><p>它可能会研究网络，看看最近什么东西最火，找到亚马逊商店里的爆款，然后生成一系列类似的产品的图像和制作图，发送给在阿里巴巴上找到的代发货制造商，然后通过电子邮件来完善要求并就合同达成一致。&nbsp;</p><p>最后设计卖家列表，并根据买家反馈不断更新营销材料和产品设计。&nbsp;</p><p>正如Suleyman指出的那样，最新的模型理论上已经能够完成所有这些事情，并且能够可靠地规划和执行整个操作的模型可能也要即将出现。&nbsp;</p><p>这样的AI看起来也不再像一把螺丝刀。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_5b0c37aeb655488d9ed20d85ebfb0c87@5888275_oswg118447oswg700oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>既然已经有了可以执行任意一般智能任务的系统，那么表现出代理性相当于有意识的说法似乎是有问题的——这意味着要么前沿模型是有意识的，要么代理不一定需要意识。&nbsp;</p><p>虽然我们不知道如何测量、验证或伪造智能系统中意识的存在。我们可以直接问它，但我们可能相信也可能不相信它的回答。&nbsp;</p><p>事实上，「只是问」似乎有点像罗夏墨迹测试：AI感知力的信徒会接受积极的回应，而不相信的人会声称任何肯定的回应要么只是「鹦鹉学舌」。&nbsp;</p><p>要么当前的人工智能系统是「哲学僵尸 」，能够像人类一样行事，但「内部」缺乏任何意识或经验。&nbsp;</p><p>更糟糕的是，罗夏墨迹测试适用于LLM本身：他们可能会根据调整或提示的方式回答自己是否有意识。（ChatGPT和Bard都接受过训练，能够回答自己确实没有意识。）&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_483e6baf9287472bae470a6b4f9e40b6@5888275_oswg1387869oswg1080oswg948_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由于依赖于无法验证的某种「信仰」（人类和人工智能），意识或感知的争论目前无法解决。&nbsp;</p><p>一些研究人员提出了意识的测量方法，但这些方法要么基于不可证伪的理论，要么依赖于我们自己大脑特有的相关性。&nbsp;</p><p>因此这些标准要么是武断的，要么无法评估，不具有我们生物遗传特征的系统中的意识。&nbsp;</p><p>声称非生物系统根本不可能具有智能或意识（例如，因为它们「只是算法」）似乎是武断的，植根于无法检验的精神信仰。&nbsp;</p><p>类似地，比如说感觉疼痛需要伤害感受器的想法，可能会让我们对熟悉的疼痛体验到底是什么进行一些有根据的猜测，但目前尚不清楚如何将这种想法应用于其他神经结构或智力类型。&nbsp;</p><p>「当一只蝙蝠是什么感觉？」，这是托马斯·内格尔（Thomas Nagel）在1974 年提出了一个著名的问题。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c89f0e2b22224e62b7b1e865f1c2b0fb@5888275_oswg1128509oswg1000oswg685_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>我们不知道，也不知道我们是否能够知道，蝙蝠是什么样子，或者人工智能是什么样子。但我们确实有越来越多的测试来评估智力的各种维度。&nbsp;</p><p>虽然寻求对意识或感知更普遍、更严格的表征可能是值得的，但任何这样的表征都不会改变任何任务的测量能力。那么，目前尚不清楚这些担忧如何能够有意义地纳入通用人工智能的定义中。&nbsp;</p><p>将「智能」与「意识」和「感知」分开来看会是更加理智的选择。&nbsp;</p><h2><strong>06 AGI会对人类社会造成什么样的影响？</strong></h2><p>关于智能和代理的争论很容易演变为关于权利、地位、权力和阶级关系的担忧。&nbsp;</p><p>自工业革命以来，被认为「死记硬背」或「重复性」的任务往往由低薪工人来完成，而编程——一开始被认为是「女性的工作」——只有当它在工业革命中成为男性主导时，其智力和经济地位才会上升。&nbsp;</p><p>20世纪70年代。然而讽刺的是，即使对于GOFAI来说，下棋和解决积分问题也很容易，但即使对于当今最复杂的人工智能来说，体力劳动仍然是一项重大的挑战。&nbsp;</p><p>1956年夏天，一群研究人员在达特茅斯召开会议，研究「如何让机器使用语言、形成抽象和概念、解决各种问题，如果AGI以某种方式「按期」实现，公众会有何反应？现在保留给人类，并提高自己」？&nbsp;</p><p>当时，大多数美国人对技术进步持乐观态度。在那个时代，快速发展的技术所取得的经济收益被广泛地重新分配（尽管肯定不公平，特别是在种族和性别方面）。尽管冷战的威胁迫在眉睫，但对大多数人来说，未来看起来比过去更加光明。&nbsp;</p><p>如今，这种再分配方式已经发生了逆转：穷人越来越穷，富人越来越富。&nbsp;</p><p>当人工智能被描述为「既不是人工的，也不是智能的」，而仅仅是人类智能的重新包装时，很难不从经济威胁和不安全的角度来解读这种批评。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_dab726de5be9481e953ed4fd7cd0254e@5888275_oswg181655oswg1011oswg443_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在将关于AGI应该是什么和它是什么的争论混为一谈时，人类似乎违反了大卫·休谟的禁令，应该尽最大努力将「是」与「应该」问题分开。&nbsp;</p><p>但这是行不通的，因为什么是「应该」的辩论必须要诚实地进行。&nbsp;</p><p>AGI有望在未来几年创造巨大价值，但它也将带来重大风险。&nbsp;</p><p>到2023年，我们应该问的问题包括——「谁受益？」 「谁受到伤害？」 「我们如何才能最大化利益并最小化伤害？」以及「我们怎样才能公平公正地做到这一点？」&nbsp;</p><p>这些都是紧迫的问题，应该直接讨论，而不是否认通用人工智能的现实。&nbsp;</p><p>参考资料：&nbsp;</p><p>https://www.noemamag.com/artificial-general-intelligence-is-already-here/&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/JnqXdQxfS6iBFIKsC-UkeA" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471166286207111</id>
            <title>汇金将持续增持四大行、外资机构调高预期 强积极信号之下，A股有望震荡上行</title>
            <link>https://www.36kr.com/p/2471166286207111</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471166286207111</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:53:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 汇金公司, 四大行, 增持, A股
<br>
<br>
总结: 汇金公司增持四大国有商业银行股份，向市场传递了非常积极且明确的信号，显示了高层稳定资本市场的决心和信心。在国内宏观经济回暖、外部环境改善等积极因素的影响下，A股有望走出震荡上行趋势。 </div>
                        <hr>
                    
                    <p>10月11日晚，工农中建四大国有商业银行分别公告获汇金公司增持。并且，汇金公司拟在未来6个月内继续在二级市场增持四大行。</p><p>受相关消息影响，11日当晚富时中国A50指数期货迅速拉升；12日早间一度涨超2%，截至11:30，涨1.07%报12393点。A股指数也在12日集体高开高走，当日收盘，上证指数涨0.94%报3107.90点，深证成指涨0.83%报10168.49点，创业板指涨0.76%报2019.10点。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_167a89c0885e42f3b4c816337cee0424@5888275_oswg38123oswg1080oswg451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>市场分析人士对央广资本眼表示，汇金增持四大行向市场传递了非常积极且明确的信号，那就是国家不仅给政策，而且拿出“真金白银”，显示了高层稳定资本市场的决心和信心。在叠加国内宏观经济回暖、外部环境改善等积极因素条件下，A股有望走出震荡上行趋势。</p><p>不仅如此，国际上亦显现诸多积极信号。近来，摩根大通、花旗银行、德意志银行、澳新银行、高盛等国际知名机构纷纷上调了对中国2023年全年经济增长预期。</p><h2><strong>01 投入“真金白银”释放积极信号</strong></h2><p>四大行11日晚公告显示，汇金公司分别增持工商银行、农业银行、中国银行、建设银行股份2761万股、3727万股、2489万股、1838万股。</p><p>中金公司12日研报表示，按11日收盘价计算，汇金增持四大行合计约4.77亿元，增持后汇金持有四家银行股份占总股本分别为34.72%、40.04%、64.03%、57.12%，均较增持前提高0.01个百分点，体现出对四大行基本面和股价的信心。</p><p>“当前汇金公司账户入市不仅为市场带来边际增量资金，也有利于稳定投资者信心。”中金研报称。</p><p>中信证券也在12日研报中指出，汇金入场增持一方面显示了对四大行经营和估值修复的信心，另一方面对全市场有“平准”作用，不排除后续增持其他金融股或市场个股的可能性，进而带动市场信心修复和增量资金入场。</p><p>“历史经验来看，增持释放底部信号，后续市场表现良好。”中信证券研报显示，汇金公司曾5次公告通过公开市场增持国有大行股份，分别为2008年9月18日、2009年10月9日、2011年10月10日、2012年10月10日和2013年6月13日。5次增持累计增持股份占当期各大行总股本数量基本在0.1%以内，股份数量级均与本轮较为接近，增持时点多为板块及市场下行期。公告后3-6个月对市场提振作用明显：5次增持公告后90个交易日，银行指数分别+8.9%/+1.8%/+12.7%/+35.8%/-3.4%，而沪深300指数则分别+16.3%/+7.6%/+2.3%/+14.8%/-6.4%。</p><p>星图金融研究院高级研究员付一夫在接受央广资本眼采访时也表示，此前市场一直有推出平准基金入市的讨论和预期，因为汇金公司是“国家队”，它拿出“真金白银”增持四大行，起到了“准平准基金”的效果。</p><p>“同时这也传递出一个非常积极的信号，那就是国家不仅给政策，而且还真出钱，显示高层稳定资本市场的决心和信心。”付一夫指出，“这对于加快推动‘市场底’的确立和夯实，提振市场信心，具有非常积极的意义。可以很明确地说，当前A股就在底部区间，而汇金增持能够促成市场各方就此达成一致预期。”</p><p>前海开源基金首席经济学家杨德龙也对央广资本眼表示，汇金公司此时“真金白银”增持对于A股市场意义重大。增持四大行或许只是个开始，汇金公司此次承诺持续增持四大国有银行的A股份，向市场传递了“持续投入”、呵护市场的强烈信号。这将对稳定和提振投资者信心起到重要的积极作用，也有助于我国资本市场进一步健康可持续发展。</p><h2><strong>02 A股有望震荡上行</strong></h2><p>近来，多家内外资机构及市场分析人士表示看好中国经济发展前景，肯定中国资本市场的投资价值和新机遇。</p><p>付一夫称，国内宏观经济数据持续回暖，市场前期一些悲观情绪已经充分消化。国际上，美联储释放的态度偏“鸽”，中美关系近期也有明显缓和迹象。“综合上述因素，我认为A股有望走出一波先磨底、再震荡向上的行情，这是可以期待的。”付一夫说。</p><p>中国宏观经济研究院副研究员徐鹏也对央广资本眼表示，富时中国A50指数期货上涨除跟汇金增持四大行有关之外，还与中美关系缓和有关。实际上，美股市场中概股指数纳斯达克中国金龙指数已经开始企稳回升。包括美国在内的国际投资者已经开始关注目前处于低位的人民币资产，尤其是股票。</p><p>“目前上证指数已经到了十年均线附近位置，从历史上看，这也是一个比较强的支撑位，基本就是底部了。如果宏观经济恢复较好，A股就会是震荡上行的趋势。”徐鹏指出。</p><p>中金研报表示，虽然近期海外市场尤其美债冲高对全球风险资产表现都带来一定影响，但国内较多经济数据，包括PMI、工业企业利润、通胀等均显现内生增长动能有边际修复的迹象。</p><p>“结合稳增长政策仍在加码，以及市场整体处于历史低位的估值水平，A股表现有望呈现相对韧性。四季度仍将是政策发力的重要时间窗口，关注阶段性及结构性机会。”中金研报称。</p><p>中信证券则在10日发布的研报中表示，三季度后，A股盈利周期望迎来底部温和复苏。且当下政策、经济、市场三重底已确立，展望四季度，积极因素逐渐积累，风险因素相对有限，预期扭转驱动的行情蓄势待发。</p><p>近日来，摩根大通、花旗银行、德意志银行、澳新银行、高盛等国际知名机构纷纷上调对中国2023年全年经济增长预期。其中，摩根大通、花旗银行将预测上调至5%，德意志银行、澳新银行的最新预测为5.1%。高盛宏观研究团队则在近期研报中预计，中国第三、四季度的GDP环比增速将分别反弹至5.5%、5.0%（季调后环比折年增长率），从而使全年增长率达到5.4%。</p><p>高盛研究部股票策略团队近日发表研究报告称，战略上，仍看好A股的配置价值，理由是A股市场对地缘政治和流动性因素敏感性低。“高盛研究部看好自主可控、专精特新小巨人、新基建、可再生能源、电动汽车供应链、大众消费等受政策支持和经济增长目标的拉动作用较大的主题或板块。”高盛研报表示。</p><p>野村也于近期发表报告指出，看好中国市场的投资价值，对中资股维持“策略性增持”看法。因为经济数据有好转迹象，政策仍具支持性，政府有明确信号希望重振经济、金融市场及信心。野村表示，投资者可关注一些受惠于周期性复苏及结构性机会的行业，包括可再生能源、电动车相关、高科技股等。</p><p>野村全球宏观研究主管及全球市场研究部联席主管苏博文表示，中国经济和资本市场正处于一个非常具有挑战性的时期，“但是当我通过中长期时间观察中国经济，我对中国有很大信心，中国的资本市场将会出现新的机遇”。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/B3mZkq6q1sWFAzNIiYZGMg" rel="noopener noreferrer nofollow" target="_blank">“央广资本眼”（ID:zibenyan_cnr）</a>，作者：孙汝祥，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471150975342472</id>
            <title>国容股份IPO，暗藏“隐秘的角落”</title>
            <link>https://www.36kr.com/p/2471150975342472</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471150975342472</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:53:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 国容股份, 科源电子, 股权代持, 安全事故, 技术积累
<br>
<br>
总结: 河南国容电子科技股份有限公司（国容股份）正在进行IPO征程，但其存在着不以子公司上市、股权代持、安全事故、技术积累薄弱等问题。尽管公司营业收入和净利润看似不错，但其主要业务来源于子公司科源电子，而科源电子在收购前存在财务困境和安全事故。此外，国容股份的技术积累和人才储备相对薄弱，与竞争对手相比存在差距。 </div>
                        <hr>
                    
                    <p>河南国容电子科技股份有限公司(简称“国容股份”）IPO征程开启，这家专注于铝电解电容器用相关铝箔材料产品的河南企业能否顺利闯关，当前正经历重大考验！</p><blockquote><p>公开资料显示，报告期内（2020年-2022年），国容股份实现营业收入分别为4.12亿元、6.26亿元、9.15亿元，扣非归母净利润分别为1767.02万元、4494.32万元、1.29亿元。</p></blockquote><p>受益于新能源汽车、风电光伏、5G通讯、工业控制等市场需求快速增长，发行人产品市场需求增长迅速。良好数据的背后，国容股份也存在家族控股、前五大供应商占比超过90%，长期资产负债率过高，员工触电工亡安全事故、转贷违规、股权代持等问题。事实上，问题不止这些，其中不以子公司上市存重大隐情。</p><h2><strong>01 不以子公司上市、引发监管问询</strong></h2><p>国容股份的营业收入和归母净利润看似不错，但是，通过梳理招股书发现，营业收入与利润贡献的主力军却另有蹊跷。</p><p>因为国容股份成立的时间是2019年，并无实际生产经营业务，业务来源于其子公司科源电子和嘉荣电子。</p><p>科源电子于2008年12月由金汇股份与港资企业出资设立，科源电子被国容股份收购前的控股股东一直为金汇股份。金汇股份设立时名称为河南神火铝电有限责任公司，为国有控股企业，2004&nbsp;年变更为民营企业，为国有控股企业，2004&nbsp;年变更为民营企业，河南神火铝电有限责任公司成立于2000年06月09日，多次更改公司名称，2000-06 至 2008-06叫做河南神火铝电有限责任公司，2008-06 至 2020-01叫做商丘金汇铝电股份有限公司，2019年4月，发行人前身国容有限向金汇股份收购了科源电子100%的股权，同时，金汇股份的部分股东、科源电子业务骨干增资入股国容有限，取得国容有限50%的股权。</p><p>被收购前，科源电子自身产品性能不稳定、导致退货率高，自成立以来长期亏损，财务状况较差，资产负债率较高，存在长期拖欠员工工资及社保的情形，2016年-2019&nbsp;年实现净利润分别为-1,879.61万元、-1,143.40万元、-141.56万元及-3,302.33万元。而收购后，在本次申报的报告期内，2022年公司1.39亿元的净利润中，公司子公司科源电子贡献了约1.24亿元的净利润。</p><p>综上所述，作为国容股份的中坚力量——科源电子为何不作为上市主体被抬出水面。2023年6月16日，监管层首轮问询提出为何不以科源电子作为上市主体，发行人解释为如以科源电子为上市主体，则需要调整科源电子的股权结构，程序较为复杂且成本较高。这种解释具有一定合理性，是否另有隐情、是否被监管采纳，让我们拭目以待。</p><h2><strong>02 多人股权代持</strong></h2><p>申报资料显示，2012年5月，科源电子第二次股权转让，科源电子股东会通过决议，同意金汇股份将所持科源电子19.58的股权（对应注册资本1,958.00万元）分别转让给黄琦等35名自然人，当时有效的《公司法》关于有限责任公司由2个以上50个以下股东共同出资设立的规定，此次工商登记受让股东为35人，实际受让股东为152名。因此杜久增、冀辉、武震、赵建立和吴志国5名工商登记自然人股东持有的&nbsp;4.63%股权存在代持的情形，5名自然人股东实际对应122名自然人（均为当时科源电子员工）持股。</p><p>2018年，因科源电子经营多年不及预期，金汇股份董事会决定，拟受让科源电子其他自然人股东持有的股权，包括杜久增、冀辉、武震、赵建立和吴志国5名自然人工商登记持有的、实际对应122名自然人股东所持的科源电子4.63%股权，就122名存在代持的自然人股东转让股权退出进而解除代持。</p><p>2018年4月20日，科源电子股东会通过决议，同意将黄琦等35名自然人股东所持科源电子19.58%的股权（对应注册资本1,958.00万元）转让给金汇股份。</p><p>而在国容股份收购实施前，金汇股份共有113名股东，均为自然人股东，未入股国容有限的金汇股份股东共计104人，合计持有金汇股份80.7160%的股权。</p><p>因此，一旦以科源电子作为上市主体，除了股权代持问题，未入股国容有限的104人，也是一个潜在不稳定风险。</p><h2><strong>03 存安全事故、社保、公积金缴纳不足</strong></h2><p>除2016年-2019年科源电子的业绩亏损以外，科源电子生产作业管理也亟待加强。在申报材料中，国容仅对一起安全事故进行了披露，即2020年3月其子公司科源电子之员工触电工亡安全事故。然而，发行人《保荐工作报告》中却道出报告期内科源电子存在两起安全事故。对另一起事故片字未提，在问询函中、深交所也对此给予了关注。其后公司在回复中，称未详细表明事故为工伤事件，不属于安全生产事故，玩起“文字游戏”。</p><p>另一方面，报告期首年即2020年，公司仅给6%的员工买公积金，社保参保率也不到80%，公司称是“受规范意识不强、资金紧张以及员工缴纳积极性不高等多种因素影响”。</p><p>生产作业安全是首位，员工福利是基本保障，“以人为本”应落到实处。</p><h2><strong>04 人才储备、技术积累薄弱，技术前景不明</strong></h2><p>电子信息是人才密集、知识密集型行业，且技术迭代、创新升级的频次较高、周期较短。国容以“研发、生产、销售”立家，想必也深谙此行业发展规则。然而，纵观其同行竞争对手发展现状，国容的高端人才储备、前沿技术研发、可预期新产品新技术突破方面，均欠缺与对手一较高下的坚实基础。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_5e25c281a5404fd2918b3b804066e02f@000000_oswg30182oswg351oswg441_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>05 收购前大亏、收购后仅一年扭亏为盈</strong></h2><p>科源电子的曾经的控股股东金汇股份以及改名之前河南神火铝电有限责任公司自身也存在问题，2019年4月被收购之前，国有企业股东退出后，金汇股份商号在一段时间仍保留“神火”字样，金汇股份商号管理意识不强、未及时召开股东大会审议企业名称变更事宜，导致神火集团退出后，金汇股份商号在一段时间仍保留“神火”字样。</p><p>关键是，国容股份成立于2019年4月17日，在同年5月24日便实现对科源电子的整体收购。要知道，此时的国容并无实际生产经营业务，且成立前主要负责人从事地产业务，收购科源电子、跨界之大令人眼前一惊。收购完成后次年，国容便“化腐朽为神奇”，让一个持续多年深陷财务危机、发展老化的企业实现扭亏为盈，将企业营业收入托举至4.12亿元，归母净利润达1767.02万元，要知道，2019年科源电子的亏损额-3,302.33万元，达到最大亏损值，高额贷款、应付款等导致其资产负债率高达85.03%、87.47%&nbsp;、86.96%、87.96%。</p><p>尽管国容股份对上述“业绩神话”的解释为采取的措施起到了效果，但是由大亏转为盈利时间太短，在当时行业形势并没有发生根本转变形势下，这种解释似乎信服力不足，是否另有玄机、是否为短期激进措施无可持续性，仍有待观察。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg4NjY4MDUzMQ==&amp;mid=2247488269&amp;idx=1&amp;sn=ef13c636f7ddbe2887c5a73da8f40dca&amp;chksm=cf94adb1f8e324a7fd31499234fee52b2b4647e3ee51aab03bd6cf31415a03f6c1056508b9b4&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“万点研究”（ID：Agumanhua）</a>，作者：晨风，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471165598242694</id>
            <title>微软决心移除 Windows 中已用 27 年的旧技术，VBScript 走向末路</title>
            <link>https://www.36kr.com/p/2471165598242694</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471165598242694</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:53:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, VBScript, Windows, 淘汰
<br>
<br>
总结: 微软计划逐步淘汰使用了近30年的VBScript，这是一种在Windows平台上广泛使用的脚本语言，但随着安全担忧和技术进步，VBScript已经过时，微软决定停止支持并推动用户转向更现代的脚本语言。 </div>
                        <hr>
                    
                    <p>近段时间，微软内部正在用新技术不断刷新内部应用，譬如其使用 Rust 取代 C/C++ 编写 Windows 驱动；放弃了 Electron 框架而采用 Edge WebView 2 来重写 Teams；WordPad 停止更新，官方建议采用 Microsoft Word 或者 Windows 记事本；Microsoft Store 的 Web 版本中放弃旧的 React 代码库取而代之使用的是 Shoelace、Lit、Vite 和 C# ASPNET 后端的现代 Web 版本......</p><p>当前，这家科技巨头在“Windows 客户端已弃用功能”列表中又添加了一名新成员——<strong>VBScript</strong>。微软计划在未来的 Windows 版本中逐步淘汰已使用了近 30 年的&nbsp;VBScript，“最初，VBScript 按需功能将被预安装，以便在您准备淘汰 VBScript 之前可以无缝使用，直至后续被完全删除。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_3376b931cc5649159f2c29459c634795@5888275_oswg58544oswg899oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>01 诞生于 27 年前，13 年未更新</strong></h2><p>作为一种脚本语言，VBScript 于 1996 年首次亮相，凭借易于学习、与 Windows 环境无缝集成、可用于网页编程等方便的功能特性，它在 Windows 平台曾被广泛使用，尤其是在网页脚本和自动化任务方面。</p><p>“微软 Visual Basic Scripting Edition 在各种环境中实现了自动化脚本，包括在 IE 中进行 Web 客户端脚本编程以及在 Microsoft Internet Information Services 中进行 Web 服务器脚本编程，”微软在其帮助文档中解释道。</p><p>这也成为很多程序员的编程的回忆：</p><p>我的入门语言便是 VBScript；</p><p>在曾经看《计算机是怎样跑起来的》这本书时，我使用 Visual Basic Scripting Edition 复现了“剪刀石头布”小游戏。</p><p>遗憾的是，一方面，随着 2006 年 PowerShell 的推出，VBScript 黯然失色，很多人将其看成被滥用的安全噩梦；另一方面，微软从未设法让其他浏览器制造商支持 VBScript，因此在微软专有的环境之外，Web 开发人员倾向于使用 JavaScript 来执行客户端任务，使用 VBScript 的用户越来越少。</p><p>最终，VBScript 的最新版本停留在了 2010 年 5.8 版本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_fe45a981c67a46bb818c7ebd8cfd598e@5888275_oswg83812oswg810oswg356_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如今，微软宣布在过渡期，VBScript 将作为按需安装使用，其中功能按需 (FODs) 是 Windows 操作系统中的可选功能，如 .NET Framework（.NetFx3）、Hyper-V 和 Windows &nbsp;Subsystem for Linux，它们不会默认安装，但可以根据需要随时添加。</p><h2><strong>02 试图拯救 VBScript 的开发者</strong></h2><p>面对这种情况，曾经有不少 VBScript 爱好者不愿放弃，试图挽救。</p><p>据 TheRegister 报道，2017 年，微软软件工程师 Zhihua Lai 创建了一个名为 IsVBScriptDead.com（https://isvbscriptdead.com/）的网站，他在网站开篇便写到，「VBScript 或 VBA 既没有消亡，也没有垂死，它仍然是一种非常稳定的脚本语言」。</p><p>然而，两年后的 2019 年 8 月，微软已经表现出不想再用 VBScript 的预兆，其在 IE 中禁用了 VBScript，并在 2022 年 6 月淘汰了 IE 浏览器，因此 VBScript 仍然活跃且运行良好的说法变得更加站不住脚。</p><p>尽管如此，最后更新于 2020 年 12 月 31 日的 VBScript 网站坚持称："VBScript 可能看起来已经过时，而对 VBScript 的支持已经停止，但它仍然在许多地方使用。Windows 管理员可能会发现学习/编写 VBScript 比 Powershell 脚本更容易。"</p><p>现在随着微软最新举措的发布，彻底证实了&nbsp;VBScript 即将彻底消亡，这也意味着依赖于VBScript 的&nbsp;Microsoft Deployment Toolkit（MDT）迎来了结束。现在，MDT 已经收到通知，不再支持 Windows 11。</p><p>另外，Microsoft 还默认禁用了 Windows 10 上 Internet Explorer 11 中的 VBScript。</p><h2><strong>03 VBScript 为何会走向末路？</strong></h2><p>截至目前，微软并没有透露弃用 VBScript 的细节，但是不少开发者猜测，它可能与微软早些时候停用 IE 浏览器有关。</p><p>从外部来看，微软计划停用 VBScript 也有可能是出于安全担忧，正如上文所述，VBScript 是不少安全工程师的噩梦，它成为恶意软件传播途径之一。</p><p>此前，有不少黑客使用 VBScript 来分发恶意软件感染用户的计算机，包括臭名昭著 Lokibot、Emotet、Qbot，以及最近的 DarkGate 等恶意软件。</p><p>而从内部来看，VBScript 是一个 Windows 特定的技术，无法跨平台运行。随着移动设备和其他操作系统的普及，这使得它在多平台环境中变得不切实际。与此同时，外部如 JavaScript、PowerShell 和 Python 等更强大、更现代的脚本语言和技术出现，VBScript 变得过时显而易见。</p><p>面对 VBScript 的淘汰，不少网友似乎“喜闻乐见”：</p><p>大约 20 年前，我曾使用过它来编写一些脚本，用于操作和报告其他内容的文本文件输出。如果我当时使用的是 Linux 系统而不是 Windows 系统，我本可以使用 awk，但当时使用的是 Windows，我不被允许安装不是原本就存在的东西。</p><p>我对它的记忆很模糊，但我确实记得它... 糟糕透了。我没有再次体验的愿望。</p><p>我怀疑它不会被怀念，除了一小部分人，他们继承了一些古老的脚本，必须对其进行逆向工程和重写成其他不那么晦涩的东西。</p><p>你是否使用过 VBScript？对于它还有什么样的印象？</p><p>参考：</p><p>https://learn.microsoft.com/en-us/windows/whats-new/deprecated-features</p><p>https://www.theregister.com/2023/10/10/microsoft_says_vbscript_will_be/</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/wSsnfis-dwHXTCaSjtNf7w" rel="noopener noreferrer nofollow" target="_blank">“CSDN”（ID:CSDNnews）</a>，作者：CSDN，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471167157802887</id>
            <title>离职谷歌，75岁Hinton官宣下场AI机器人，加盟初创公司，师徒再联手，打造“基础模型”</title>
            <link>https://www.36kr.com/p/2471167157802887</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471167157802887</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:46:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Geoffrey Hinton, Vayu Robotics, 机器人技术, AI道德问题
<br>
<br>
总结: 75岁的AI教父Geoffrey Hinton离职谷歌后，加入了机器人公司Vayu Robotics的咨询委员会。Vayu Robotics致力于设计用于本地送货的轻便低速机器人，解决了机器人技术在人工智能领域的难题。Hinton对Vayu Robotics的方法和技术充满信心，认为他们的解决方案在道德问题上更为可行。他的加入也是为了与自己的博士生Nitish Srivastava再次合作，并受到了Hinton强烈的AI道德驱动力的启发。 </div>
                        <hr>
                    
                    <p>从谷歌离职，多伦多大学退休后，75岁Hinton再次下场AI。</p><p>75岁「AI教父」Geoffrey Hinton离职谷歌后，再次下场人工智能。</p><p>刚刚，他官宣自己已经加入了机器人公司Vayu Robotics咨询委员会，帮助开发AI机器人解决方案。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_e4be93ff794544eaa4880ee22fa685ff@5888275_oswg78273oswg988oswg264_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Hinton称自己离职后，收到了许多初创企业顾问委员会邀请，全都拒绝了。</p><p>但这次，他决定加入Vayu Robotics，可以看得出，本人对机器人这一领域方向的看好和认可。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6f4eb5229fdd4eec8d62664de4e1f86b@5888275_oswg414472oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>英伟达高级科学家Jim Fan表示，「机器人技术是我们在人工智能领域最后要攻克的难关。2023年将是竞争白热化的时刻。到目前为止，还没有一家公司接近终点线。」</p><h2><strong>01 下场机器人，师徒再联手</strong></h2><p>Vayu Robotics究竟是一家怎样的公司，能够吸引图灵奖得主加盟？</p><p>Hinton介绍道，这家公司正在设计用于本地送货的轻便低速机器人。</p><p>这些机器人的动能仅为时速50英里汽车的1%，而且停车距离更短，因此更容易确保安全。</p><p>Hinton看好Vayu Robotics的地方在于，这个团队正在解决一个巨大的利基市场，而且他们的方法与许多其他AI应用相比，道德问题更少。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_635b1662078741538b38fa31fc37a0d7@5888275_oswg176437oswg1000oswg482_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>我决定加入Vayu Robotics的顾问委员会，因为我看到了他们利用ML和视觉传感器共同设计的方法将AI用于机器人技术的巨大潜力。</p><p>我期待再次与Nitish Srivastava合作，并指导Vayu团队的成长。我相信Vayu的技术将实现安全和环保的解决方案，与许多其他人工智能应用相比，道德问题要少得多。</p></blockquote><p>不难看出，Hinton还是将AI道德问题关注放在了首位，毕竟5月对外公开离职谷歌消息时，就是因为对当前人工智能风险感到恐惧。</p><p>他曾表示，「我对自己的毕生工作，感到非常后悔」。</p><p>就在几天前，他在接受「60分钟」采访中再次警告，AI可能会接管人类，对此表现出深深的担忧。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_f5ae85bb741e4fd9bfc54f3da97e2be0@5888275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，Hinton加入Vayu另外一个原因之一，能够再次与自己的博士生Nitish Srivastava合作。</p><p>Nitish Srivastava现在是Vayu Robotics的联合创始人兼CTO，在多伦多大学就读硕士和博士学位时，导师都是Hinton。</p><p>在校期间，Srivastava开发了Dropout，这是神经网络中常见的一层，用于防止过拟合。</p><p>他还撰写了最早的一种序列模型（LSTM），用于无监督视频学习。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_4e639af082b24914b88bf8560411d925@5888275_oswg61714oswg1080oswg528_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文地址：https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf</p><p>他表示，「在Hinton的指导下，我不仅从机器学习领域最伟大的思想家那里学到了一手知识，还受到了他强烈的AI道德驱动力的启发，至今仍在指引我所作的决策。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_f2c53d324eea44d38a657da01cf5706d@5888275_oswg143663oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，Vayu Robotics的首席执行官Anand Gopalan，曾是Velodyne的前首席执行官。Velodyne是最大的激光雷达设计公司之一。</p><h2><strong>02 打造机器人「基础模型」，完成1270万刀融资</strong></h2><p>Vayu Robotics成立于2022年，总部位于旧金山湾区，是一家旨在提供高质量、低成本机器人系统的人工智能公司。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a7ef075b1b724180929c1f020ab44501@5888275_oswg50057oswg1080oswg313_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据介绍，Vayu致力于在打造一个基础模型，来为大规模自主移动机器人提供动力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_383f1a336e804299933614fcafe3a140@5888275_oswg106928oswg1080oswg159_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>10月初，这家公司刚刚完成了1270万美元的种子融资。</p><p>这一轮由Khosla风险投资公司牵头，Lockheed Martin风险投资公司、ReMY投资者和其他公司参与其中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_3ac4b9b7bd284e6c828a3fb8dcb67efc@5888275_oswg137248oswg1080oswg694_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他们计划利用这笔资金，在不同市场扩大AI机器人的产品开发，包括最后一英里交付、工厂自动化和汽车。</p><p>Vayu是一家非传统的机器人公司，正在采取原则第一的「自动化」方法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_158127ad983844e18880651da2017a57@5888275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>它通过2项关键技术优先考虑成本和部署便利性：一是移动性的基础模型，另外一个是许多中端应用中取代LiDAR的颠覆性低成本传感技术。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_9f8a613c1f0f4e6aa76e93612d6c1385@5888275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Vayu Robotics研发的技术恰处于人工智能领域的高光时刻，也正在该行业两大趋势的融合之中。</p><p>首次是大模型的发展，使得机器人能够以前所未有的方式执行更通用的任务。</p><p>其次，美国初创公司正在另辟蹊径，重振国产制造力，以减少对海外生产的依赖。由此，对机器人技术和自动化的需求持续增长。</p><p>Vayu的技术要做的就是，实现下一波可持续和可访问的机器人，直接用于最后一英里交付。</p><p>现在，Hinton加入这个机器人初创公司，又将会掀起新的AI潮。</p><p>参考资料：&nbsp;</p><p>https://x.com/drjimfan/status/1712180528634613978?s=46&amp;t=iBppoR0Tk6jtBDcof0HHgg&nbsp;</p><p>https://x.com/geoffreyhinton/status/1712171599636435105?s=46&amp;t=iBppoR0Tk6jtBDcof0HHgg&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/N3LRIRl807QZ5KNh1nWRaw" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471167417260160</id>
            <title>机器人瓦力来了，迪士尼亮出新机器人，用RL学习走路，还能进行社交互动</title>
            <link>https://www.36kr.com/p/2471167417260160</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471167417260160</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:46:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 迪士尼, 互动机器人, 瓦力机器人, 情感
<br>
<br>
总结: 迪士尼推出了一个超可爱的互动机器人，不仅会蹦蹦跳跳，还能表达情感。网友们已经忍不住想把它带回家了！ </div>
                        <hr>
                    
                    <p>迪士尼推出了一个超可爱的互动机器人，不仅会蹦蹦跳跳，还能表达情感。网友们已经忍不住想把它带回家了！</p><p>当、当、当，「瓦力机器人」登场！&nbsp;</p><p>扁扁的脑袋、四四方方的身体，你指着地面让它看，它还会歪歪头表示不解。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_2b076c4b84f94eccbb0dd95f0de6ce99@5888275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但它可不是瓦力，真正的瓦力长这样！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_3fcb5ee5d8dc43359599dc3423b4cb47@5888275_oswg125880oswg600oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个可爱的小机器人由迪士尼研究团队开发，在底特律举行的2023年IEEE/RSJ智能机器人和系统国际会议（IROS）上被展示。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_9f9ca5232d7d41c588739a42d74b5496@5888275_oswg369663oswg1080oswg584_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>迪士尼开发的这个小机器人一出场，就引起了人们好奇的目光。&nbsp;</p><p>极富表现力的头部、两只摇摆的天线「触角」、短短的小腿，儿童大小的身体中融入了许多具有情感的肢体语言。&nbsp;</p><p>让每个见到它的人都充满了怜爱。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_679742d5307f4c3cb3b255a05f850245@5888275_oswg182711oswg653oswg628_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个机器人与其他小型双足机器人的不同之处在于它的行走方式——它充满个性，在移动时会发出声音，让人觉得它是独一无二的小生命。&nbsp;</p><p>果不其然，在IROS上的视频上传到网上后，网友们都被萌化了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_ddd92b612a474f3ea1c99ad5d7c50503@5888275_oswg35013oswg1080oswg171_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「太可爱爱爱爱了吧。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_119d9652af604a44a5c88717ed6196a1@5888275_oswg46968oswg1080oswg169_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「他太可爱了。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_7c1cd1278a2146119f7dfcd8cd1c8eae@5888275_oswg40594oswg1080oswg172_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>想直接把它带回家的网友，也是一大波。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_204e178bdd714df2af63e8c5bae8c26f@5888275_oswg498076oswg1080oswg708_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「我需要一个！」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0055057fc685483da62abe66d352efc4@5888275_oswg41229oswg1080oswg169_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「我已经等不及看它在我房间里走来走去的样子了！」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_30d37a87e20d48658237d848cc72d3ec@5888275_oswg54688oswg1080oswg160_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>接下来，就让我们看看这个小机器人是如何诞生的吧。</p><h2><strong>01 迪士尼小机器人诞生之旅&nbsp;</strong></h2><p>将机器人编程以表现情感化的动作是迪士尼的专长。&nbsp;</p><p>早在1971年，迪士尼世界的总统大厅就采用了动画机器人技术。&nbsp;</p><p>但随着机器人变得更加先进和机动性更强，对于机器人设计师和机器人动画师来说，开发既能利用又与真实世界的限制条件相兼容的情感化行为越来越难。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_fd63b714e08149909191e76d842b29db@5888275_oswg226254oswg640oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>迪士尼研究部门在过去一年中一直在开发一种新系统，该系统利用强化学习，将动画师的想象转化为具有表现力的动作。&nbsp;</p><p>这些动作足够强大，几乎适用于任何场地，无论是在国际机器人和智能系统大会（IROS）上、迪士尼主题公园中，还是瑞士的森林里......&nbsp;</p><p>并且，这个新系统可以使机器人表现出更多情感和表情，使它们在不同场合中更具吸引力和实用性。&nbsp;</p><p>而机器人是由Moritz Bächer领导的迪士尼研究团队在苏黎世开发的， 该机器人主要是通过3D打印制造的，它采用了模块化的硬件和执行器。&nbsp;</p><p>这种设计使得它的开发和改进速度非常快，从最初的概念到在上面的视频中所看到的样子，不到一年的时间就完成了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_11fea28874424ed2bad53e4f17f5864c@5888275_oswg267213oswg457oswg569_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个机器人拥有一个四自由度的头部，可以在上下左右方向看，还可以做倾斜的动作。&nbsp;</p><p>并且，它还有一个带髋关节的五自由度腿，使其能够在动态平衡的同时行走。&nbsp;</p><p>这使得机器人能够进行更多复杂的动作和交互，具有更高的灵活性。&nbsp;</p><p>迪士尼研究科学家Morgan Pope表示：&nbsp;</p><p>「大多数机器人科学家都专注于让他们的双足机器人能够可靠地行走。&nbsp;</p><p>但在迪士尼，这远远不够。我们的机器人需要走得有模有样、会跳跃、小跑或漫游，以传达我们需要的情感。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_3fc7d2c3e95a431998e579e042175563@5888275_oswg461324oswg866oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>迪士尼拥有专业的动画师，他们擅长通过动作来表现情感，同时也拥有擅长构建机械系统的机器人学家。&nbsp;</p><p>「我们试图为这些机器人带来的东西，其实源自于我们的角色动画历史。」迪士尼的首席研发工程师Michael Hopkins解释道。&nbsp;</p><p>「我们的团队中有一个动画师，我们能够共同利用他们的知识和我们的技术专长，以创造最佳的性能。」&nbsp;</p><p>但想要创建一个有效的机器人角色，需要动画师和机器人学家把他们的才能结合起来。&nbsp;</p><p>这是一个相当耗时的过程，涉及大量的试验和错误，以确保机器人能够传达动画师的意图而不会摔倒。&nbsp;</p><p>Bächer解释说：「一般来说，动画工具中没有内置物理引擎，这使得艺术家很难设计出在现实世界中能够正常运行的动画。」&nbsp;</p><p>「这不仅仅是关于行走。行走只是强化学习系统的输入之一，但另一个重要的输入是它的行走方式。」Pope补充道。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a71a37676f544e3f8b368bb9b74ddefc@5888275_oswg1666264oswg866oswg1316_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了弥合这一差距，迪士尼研究院开发了一种基于强化学习的系统。&nbsp;</p><p>该系统依靠仿真技术将动画师的视觉与强大的机器人动作结合起来，并在两者之间取得平衡。&nbsp;</p><p>对于动画师来说，这个系统能够基本上重现物理世界的约束，让动画师开发出极具表现力的动作。&nbsp;</p><p>这些艺术家想象中的动作能够变为现实，且尽可能接近机器人的物理极限。&nbsp;</p><p>迪士尼的流水线可以在一台个人电脑上训练机器人的新行为，只需几个小时就能完成相当于数年的训练。&nbsp;</p><p>据Bächer的说法，这让迪士尼开发一个新机器人角色所需的时间从几年缩短到了几个月。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_962f7625c4cf420898a48ed79f63b8e8@5888275_oswg1053059oswg866oswg640_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，强化学习让小机器人产生的动作具有很强的鲁棒性。&nbsp;</p><p>迪士尼开发的这个系统能够反复地训练动作，同时对电机性能、质量分布以及机器人与地面之间的摩擦力等方面进行细微调整。&nbsp;</p><p>该系统能够确保机小器人无论在现实世界中遇到什么情况，都知道如何处理自己，同时还能表现出对应地情感，这对机器人保持自己的性格至关重要。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_77d6a6fd76874cc5a641623ecd88906d@5888275_oswg806760oswg866oswg638_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>02 下一个目的地&nbsp;</strong></h2><p>迪士尼的研究人员傲娇地表示，虽然这个小机器人特别可爱，但这里更重要的是小机器人背后的系统。&nbsp;</p><p>是这个系统让小机器人变得如此生动可爱，这也是迪士尼未来旅程中充满希望的第一步。&nbsp;</p><p>迪士尼的下一步计划是利用这种技术开发更多的实体机器人角色，并通过更快、更动态的动作来挑战极限。&nbsp;</p><p>虽然这个小机器人还没有正式的名字，但迪士尼表示，这只是未来更多生动机器人的序幕。&nbsp;</p><p>真是让人翘首以待。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6a2c722824564742a6e329b59800cb48@5888275_oswg52978oswg300oswg283_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>参考资料：</p><p>https://spectrum.ieee.org/disney-robot&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/HeTX1Mo1j_Ym52Ma8FiM7g" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471161601251205</id>
            <title>《原神》三岁了，米哈游怎么还在“挨骂”</title>
            <link>https://www.36kr.com/p/2471161601251205</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471161601251205</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:40:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 米哈游, 原神, 人气下滑, 引战
<br>
<br>
总结: 米哈游凭借《原神》的成功一跃成为全球最令人瞩目的手游厂商，但随着时间推移，游戏受到了频繁的引战和玩家的抱怨，导致人气下滑。米哈游的扩张和工业化路径依赖也导致创新不足，游戏体验单一。此外，其他二次元游戏的表现也不如预期，使得米哈游面临更大的挑战。 </div>
                        <hr>
                    
                    <p>米哈游的崛起，离不开《原神》。</p><p>2020年9月28日，开放世界动作角色扮演游戏《原神》全球上线，跨Windows、iOS、Android、PlayStation等多平台。</p><p>这意味着，《原神》出道已满三年。</p><p>这三年，围绕《原神》的争议怎么一直不断？《原神》似乎没有那么能打了，背后是何缘由？米哈游的下一个“原神”，为何好事多磨？</p><h2><strong>01 人气下滑，频频被“引战”</strong></h2><p>《原神》，改变了米哈游的命运轨迹。</p><blockquote><p>2011年，米哈游凭借10万元无息贷款，以及上海市科创中心内一块免费使用半年的50平方米办公场地起家，逐步在二次元游戏赛道崭露头角。</p></blockquote><p>不过，米哈游并未出圈。</p><p>彼时，游戏新势力的“带头大哥”为莉莉丝，直到精心打磨的《原神》成为现象级游戏，米哈游一跃成为全球最令人瞩目的手游厂商，江湖地位才发生逆转，“三足鼎立”之势已成。</p><blockquote><p>据《光明日报》报道，米哈游2022年全年主营业务收入为273.40亿元，净利润为161.45亿元，截至2022年底，净资产已达374.02亿元。</p></blockquote><p>换而言之，米哈游的净利率高达59.05%，高于同期网易的20.56%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0138a58e8b324df5988f290cb727541e@000000_oswg7460oswg752oswg452_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">米哈游赚钱能力很强</p><p>这期间，大大小小的游戏玩家纷纷切入二次元游戏赛道，想从中分一杯羹，然而没有“二次元基因”，几乎全军覆没。</p><p>尽管如此，《原神》依然频频被“引战”。</p><p>起初，各大平台的杂音主要源于眼红《原神》的吸金能力以及看不惯其忠实粉丝的部分行为，真正玩家的抱怨不多，且不咸不淡，“对于普通上班族来说米家游戏迟早会玩腻，玩一段时间后会发现玩游戏和上班差不多，有时候比上班还累”。</p><p>随着时间推移，玩家的非议多了起来。</p><p>譬如，“一个好的团队管理可以掩盖掉很多缺点，但是原神刚好相反，好的地图被任务拖累，好的机制被人设拖累，好的剧情被强度拖累，好的人设被环境拖累，优点被缺点掩盖，游戏体验当然不好。”</p><p>再譬如，“米哈游的巨大成功主要归功于在其他厂家还在普遍喂翔的情况下推出了《原神》这一制作精良、形式相对新颖，受众相对广泛的游戏。然而，米哈游没有‘大公司’的命却得了‘大公司’的病，傲慢无视玩家意愿和需求，执意恶心玩家，不断赶客。”</p><p>反映到游戏市场，则是人气下滑。</p><p>据Sensor Tower的数据显示，2023年6月《原神》在全球热门移动游戏收入榜中位列第8名，而到了7月与8月已无缘TOP 10。</p><p>三岁的《原神》，疲态已现。</p><h2><strong>02 人浮于事，叠加创新不足</strong></h2><p>以上可见，《原神》的声量已大不如前，这背后的原因有三。</p><p>首先，过于膨胀。</p><blockquote><p>《原神》一炮走红之后，米哈游几乎一年上一个台阶：胡润的《2023全球独角兽榜》，将米哈游估值为500亿元人民币；而其他机构对米哈游估值1000亿元~3000亿元不等。</p></blockquote><p>此背景下，米哈游有了更大的野望，“三足鼎立”不是终点，“问鼎中原”才是终局。</p><p>关于此，从米哈游大规模招兵买马就可见一斑。</p><p>据公开资料显示，《原神》正式立项的2017年，米哈游员工规模约为300人，到了2022年，员工规模膨胀至超5000人。</p><p>与腾讯、网易争夺3A人才，成为米哈游的惹火动作。</p><p>“游戏葡萄”表示：“行业第一梯队的薪酬、纯现金的offer、独特的公司气质……这些都让‘有米选米’成了大量求职者的共识。”</p><p>然而，激进扩张之下，“大公司病”也浮出水面。</p><p>时任米哈游总裁刘伟表示：“高层Leader和基层Leader之间的沟通不够，前者甚至不知道后者招聘了哪些人才，很多新员工不会践行‘说到做到，有话直说，只认功劳，追求极致’的文化。”</p><p>其次，工业化反噬。</p><p><strong>米哈游走的是工业化路线，寄望《原神》的游戏内容长青，因而保持着42天一个小版本的节奏更新。</strong></p><p>据“雪豹财经社”统计，自2022年8月3.0版本上线以来，《原神》一共更新了10个版本、19个卡池，在iOS畅销榜上十度登顶，六度排名第二；但2023年5月至8月开放的6个卡池中，仅有一个登顶畅销榜，有3个卡池接连取得了近一年以来的垫底表现。</p><p>之所以如此，与工业化路径依赖有莫大的关系。</p><p>工业化虽然提高了效率，主打的就是量大管饱，但由此也带来了内容创新不足，新鲜感流失、游戏体验单一等问题。</p><p>一名资深米哈游粉丝表示：“当玩家对你有好感的时候你做什么都是对的，而当玩家厌恶你的时候你做什么都是错的。一个依赖内容的公司在内容崩坏以后，其下坡路就已注定了。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a87de11e01554730916479070da0de61@000000_oswg233877oswg728oswg517_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Sensor Tower</p><p>再次，二次元游戏被高估。</p><p>米哈游出圈之后，二次元游戏也被高看一眼，但事实证明《原神》之外，其他二次元游戏不温不火。</p><p>于是乎，二次元游戏被重新审视。</p><p>“雪豹财经社”表示：“在国内市场，《王者荣耀》《和平精英》等长青的IP大多是社交竞技类游戏，天然具有很强的可重复游玩性。而《原神》更像是剧集，剧情和探索体验很大程度上是一次性的，因此需要稳定持续地推陈出新，才能留住玩家，这对游戏的长线运营能力提出了更高的挑战。”</p><h2><strong>03 《崩坏：星穹铁道》，下载量滑坡</strong></h2><p>需要注意的是，米哈游对《原神》的疲态心知肚明，为了重返神坛也在不断努力。</p><p>一方面，加码买量。</p><p>2023年第二季度以来，《原神》在宣发上不断加码，渴望通过买量获得曝光率，并吸引更多新玩家入局，从而积累更多的付费用户。</p><blockquote><p>据AppGrowing的数据显示，2023年4月，《原神》首次出现在游戏APP推广强度榜TOP 20中，主打的是“新人送20抽”“原来你也玩原神”的情感触达，到了6月首次登顶榜首，之后一直是榜首的有力竞争者。&nbsp;</p></blockquote><p>对此，乐府互娱创始人程良奇在接受媒体采访时抱怨，米哈游的买量模式财大气粗，“他们不看转化效果，只看曝光，连投放优化都不用，只要设一个消耗数据放那儿就行”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_768a35842ee54b5ebb3c02db65748c96@000000_oswg383410oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：AppGrowing &nbsp;游理游据研究院</p><p>另外一方面，寻找下一个“原神”。</p><p>2023年4月26日，米哈游上线了新游戏《崩坏：星穹铁道》，成功接棒《原神》成为中国手游出海的“新王”。</p><p>如此，米哈游看到拥有“双子星”的希望。</p><p>然而，《崩坏：星穹铁道》的热度却高开低走：上市首周的下载量与收入，这两大指标双双优于同期的《原神》；7月之后，中国手游海外下载量TOP 30中，已无《崩坏：星穹铁道》的身影，这可不是好现象。</p><p>对此，玩家的不满也溢于言表。</p><p>譬如，“崩铁代表的回合制卡牌游戏现在挺小众，指望崩铁能接过原神的接力棒就想得有点多了，而且年轻人对游戏还具有社交属性的要求，原神和崩铁虽然做得还行，但是还是有比较大的进步空间。”</p><p>再譬如，“强推崩铁、故意忽视原神的后果，跟当年暴雪强推星际2，强制wcg下架魔兽争霸如出一辙，结果死翘翘了。”</p><p>这么来看，米哈游并不能高枕无忧。</p><p>“互联网怪盗团”一针见血地指出：“与拥有虚幻引擎的Epic Games，以及具备大量3A游戏开发经验的动视暴雪、育碧比起来，米哈游就谈不上什么技术优势了；与技术研发投入动辄上百亿的互联网大厂相比，它的技术优势能维持多久也是个问题。”</p><p>那么，米哈游还需要苦练基本功。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg3MDEwODYzMg==&amp;mid=2247511108&amp;idx=1&amp;sn=921e994299afd7e93bd42088b33955d7&amp;chksm=ce9030f3f9e7b9e5499c5eb0d52049463b22f482aaaa5ca5049edeb768b1029ab31827559e67&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“锌刻度”（ID：znkedu）</a>，作者：锌刻度，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471159010875522</id>
            <title>AI搞定谷歌验证码，最新多模态大模型比GPT-4V空间理解更准确</title>
            <link>https://www.36kr.com/p/2471159010875522</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471159010875522</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:38:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌人机验证, AI, 多模态大模型, 雪貂
<br>
<br>
总结: 苹果和哥伦比亚大学研究团队开发的多模态大模型"雪貂"，能够轻松找到图中的交通信号灯并准确圈出位置，具备更强的图文关联能力，提升了大模型在"看说答"任务中的精确度。该模型通过混合区域表示方法，将离散坐标和连续特征联合起来表示图像中的区域，解决了引用和定位两方面空间理解能力的问题。同时，它还使用空间感知的视觉采样器处理不同形状之间的稀疏性差异，可以接受各种区域输入，并根据文本自动生成每个定位对象的坐标。 </div>
                        <hr>
                    
                    <p>谷歌人机验证已经拦不住AI了！</p><p><strong>最新多模态大模型</strong>，能轻松找到图中所有交通信号灯，还准确圈出了具体位置。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6996b9b941414363a89a963df73f40b4@5888275_oswg358490oswg1080oswg428_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表现直接超越GPT-4V。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_ceda7a5d300e4f8f9ed42aa7d2235bee@5888275_oswg408455oswg1080oswg545_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这就是由苹果和哥伦比亚大学研究团队带来的多模态大模型<strong>“雪貂”（Ferret）</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0f983465c3a64fed87a72f8b453f1697@5888275_oswg12301oswg617oswg161_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>它具备更强的图文关联能力，提升了大模型在“看说答”任务中的精确度。</p><p>比如下图中非常细小的部件（region 1），它也可以分辨出来是避震。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_55ce120f8b564eae8cfb46a533a83a51@5888275_oswg584475oswg1080oswg635_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>GPT-4V没能回答正确，在细小部分上的表现不佳。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_613f090249be4253a3140ca60a664cea@5888275_oswg399217oswg1080oswg380_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以，Ferret是如何做到的呢？</p><h2><strong>01 “点一点”图像大模型都懂</strong></h2><p>Ferret解决的核心问题是让引用（referring）和定位（grounding）两方面空间理解能力更加紧密。</p><p>引用是指让模型准确理解给定区域的语义，也就是指一个位置它能知道是什么。</p><p>定位则是给出语义，让模型在图中找到对应目标。</p><p>对于人类来说，这两种能力是自然结合的，但是现有很多多模态大模型却只会单独使用引用和定位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_97fbe9fd44e1494e970760d3d3383fe3@5888275_oswg614285oswg1080oswg591_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以Ferret提出了一种新型的混合区域表示方法，<strong>能将离散坐标和连续特征联合起来表示图像中的区域</strong>。</p><p>这样一来，模型就能分辨出边界框几乎一样的对象。</p><p>比如下图中两个物体的情况，如果只用离散边界框，模型会感到很“困惑”。和连续的自由形状混合表示相结合，能很好解决这一问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_45615c3eab6c4dfdbf3f91e9a3119a16@5888275_oswg9440oswg157oswg209_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了提取多样化区域的连续特征，论文提出了一种<strong>空间感知的视觉采样器</strong>，能够处理不同形状之间的稀疏性差异。</p><p>因此，Ferret可以接受各种区域输入，如<strong>点、边界框和自由形状</strong>，并理解其语义。</p><p>在输出中，它可以根据文本自动生成每个定位对象的坐标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_489570c3492d44d1b97fe00632933ba7@5888275_oswg94521oswg1080oswg278_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了实现这一目标，Ferret模型的架构包括图像编码器、空间感知的视觉采样器和语言模型（LLM）等组成部分。</p><p>Ferret结合了离散坐标和连续特征，形成了一种混合区域表示。</p><p>这种表示方法旨在解决表示各种形状和格式的区域的挑战，包括点、边界框和自由形状。</p><p>离散坐标中每个坐标都被量化为一个目标框的离散坐标，这种量化确保了模型对不同图像大小的鲁棒性。</p><p>而连续特征则由空间感知视觉采样器提取，它利用二进制掩码和特征图在ROI内随机采样点，并通过双线性插值获得特征。</p><blockquote><p>这些特征经过一个由3D点云模型启发的空间感知模块处理后，被浓缩成一个单一的向量, 并映射到大型语言模型（LLM）进行下一步处理。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_72991255ed384905b5a21dea55b5de88@5888275_oswg283235oswg1080oswg407_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了增强Ferret的能力，论文还创建了一个名为<strong>GRIT</strong>的数据集。</p><p>这个数据集包含<strong>1.1M个样本</strong>，涵盖了个体对象、对象之间的关系、特定区域的描述以及基于区域的复杂推理等四个主要类别。</p><p>GRIT数据集包括了从公共数据集转换而来的数据、通过ChatGPT和GPT-4生成的指令调整数据，并额外提供了<strong>95K个困难的负样本</strong>以提高模型的鲁棒性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_4795184e69df403095be8f1c738f9c1b@5888275_oswg404226oswg1080oswg429_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>实验结果表明，该模型不仅在经典的引用和定位任务中表现出优越性能，而且在基于区域和需要定位的多模态对话中<strong>远远超过</strong>现有其他MLLM模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_ba26fbe879d64d19904b9554d5078f9c@5888275_oswg274040oswg1080oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，研究还提出了<strong>Ferret-Bench</strong>，可以评估图像局部区域的引用/定位、语义、知识和推理能力。</p><p>Ferret模型在LLaVA-Bench和Ferret-Bench上进行评估，在所有任务中都表现出色，特别是在需要指代和视觉grounding的三个新任务上，Ferret的表现很出色。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_5cc0a93b5888453793cb47f48c5a7c98@5888275_oswg150739oswg1080oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且在描述图像细节上有明显提升，幻觉有明显下降。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a2e510d2d3214cb89ad31a80853ad817@5888275_oswg305047oswg1080oswg547_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>02 全华人团队</strong></h2><p>Ferret大模型由苹果AI/ML和哥伦比亚大学研究团队共同带来，全华人阵容。</p><p>有昊轩和张昊天为共同一作。</p><p>有昊轩现在为哥伦毕业大学计算机科学博士，毕业后将加入苹果AI/ML团队。2018年从西安电子科技大学本科毕业。</p><p>主要研究方向为视觉语言理解、文本-图像生成和视觉语言。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6eaa6f325d6c4e4a8204ddf9270a978b@5888275_oswg204689oswg1080oswg331_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>张昊天现在为苹果AI/ML团队视觉智能研究员。</p><p>在加入苹果之前，张昊天在华盛顿大学获得博士学位，本科毕业于上海交通大学。</p><p>他是GLIP/GLIPv2的主要作者之一，GLIP曾获得CVPR2022的Best Paper Award的提名。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_2837730442f1460e89a18c40bdbc9871@5888275_oswg88250oswg775oswg218_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外团队成员还包括甘哲、王子瑞、曹亮亮、杨寅飞等前谷歌和微软的多位优秀的多模态大模型研究员。</p><p>论文地址：https://arxiv.org/abs/2310.07704</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/r6I_fo9GeqpqAlSYMMKErw" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471152349649028</id>
            <title>AI教父Hinton加入机器人初创，公司刚获1200万美元融资</title>
            <link>https://www.36kr.com/p/2471152349649028</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471152349649028</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:28:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI教父, 瓦尤机器人公司, Vayu Robotics, AI道德风险
<br>
<br>
总结: AI教父杰弗里·辛顿加入了人工智能初创公司瓦尤机器人公司，选择该公司的原因是Vayu所做的AI道德风险更低。Vayu Robotics是一家旨在提供高质量、低成本机器人解决方案的人工智能公司，他们的目标是推动安全、可持续的人类生产力。该公司最近完成了一轮1270万美元的融资，他们的团队由机器学习、传感器开发和工业制造领域的专家组成。 </div>
                        <hr>
                    
                    <p><strong>文｜尚恩</strong></p><p><strong>编辑｜邓咏仪</strong></p><p>起猛了，被称为“AI教父”的杰弗里·辛顿博士（Geoffrey Hinton）从谷歌离职后时隔5个月，竟然加入了一家人工智能初创？！</p><p>10月11日晚，杰弗里·辛顿官宣，将加入瓦尤机器人公司（Vayu Robotics）担任顾问委员一职。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_9e1bdc91209d44c786a92d707141346d@5961534_oswg48617oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Vayu</p><p>今年5月，Hinton突然从谷歌离职，曾轰动了整个科技圈，而自从离职后，这位AI教父就邀约不断，但都没能吸引到他，但最终选择与Vayu Robotics一起，理由则是<strong>Vayu所做的AI道德风险更低</strong>。</p><p>除此之外，还有一点非常关键，Vayu Robotics的现任CTONitish Srivastava是Hinton在多伦多大学任教时期的<strong>博士生学生</strong>。</p><p>他博士毕业于多伦多大学，在此期间他和Hinton等人共同提出了神经网络中最常被用来防止过拟合的方法之一Dropout，目前论文被引次数已超过46000次。</p><p>消息一出，网友们齐刷刷的留言祝贺，英伟达AI科学家Jim Fan也第一时间发来贺电，表示：</p><blockquote><p>Vayu众星云集，我一直机器人是AI最后征服的一个护城河，现在终于有一家公司有能力用AI征服机器人领域了。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_8bef835262dc454087fdcd08ec051cb5@5961534_oswg115541oswg1080oswg234_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Twitter</p><p>那么，这家能邀请Hinton加入的公司到底有何特别之处呢？</p><h2><strong>众星云集，公司刚融了千万美元</strong></h2><p>在Vayu的设想中，新一轮智能系统将推动安全、可持续的人类生产力。</p><p>Vayu Robotics成立于2021年，总部位于加利福尼亚州帕洛阿尔托，主要在传感器、机器学习和产品开发三方面布局。其中，vayu是梵文词意味着<strong>智慧</strong>，使宇宙中的一切运动和一切能量运动成为可能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_9267724923274d66be0e2a5ebbe4092f@5961534_oswg190419oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Twitter</p><p>受到这一概念的启发，Vayu力求成为使自主移动机器人（AMR）能够在世界范围内移动的智能体，成为每台移动机器的新星系统。目前公司已经开发出了一个小型送货机器人，Vayu表示这个机器人基于纯AI视觉方案，没有使用激光雷达、高精地图，仅通过仿真模拟训练，然后基于少量真实图片训练后就能自主上路。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_09bcc4c7f4854b4a8165483955bc7b06@5961534_oswg448148oswg1080oswg461_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Vayu</p><p>作为一家非传统意义上的机器人公司，团队采用自动化第一原则，会优先考虑机器人的成本和部署问题。目前也在开发自动驾驶基础模型和传感技术，其中已研发出包括“移动性基础模型Vayu Drive”、“传感器Vayu Sense”以及“（RaaS）模型系统Vayu One”。</p><p>另外据公开资料显示，Vayu Robotics的创始团队都由机器学习、传感器开发和工业制造领域的专家组成。</p><p>联合创始人 Anand Gopalan此前曾是Velodyne Lidar的CEO、Mahesh Krishnamurthi在Lyft和苹果任职过，而首席技术官Nitish Srivastava则是Hinton在多伦多大学任教时期的博士生学生。</p><p>CTO此前开发了Dropout，这是神经网络中现在广泛使用的一种层，用于防止过拟合，并且还创作了最早的序列模型之一（LSTM），用于无监督视频学习。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_1351d0fa8c534460b603dd89e7c98429@5961534_oswg233181oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Twitter</p><p>作为一家旨在提供高质量、低成本机器人解决方案的人工智能公司，Vayu Robotics在今年10月初刚刚宣布完成种子轮<strong>1270万美元融资</strong>，本轮融资由Khosla Ventures领投，Lockheed Martin Ventures、ReMY Investors等跟投。</p><p>Vayu Robotics公司首席执行官表示：“Vayu准备以最低的机器人拥有成本和最佳的运营经济性来颠覆市场，我们已经建立了一支非常强大的工程师团队，完成融资后，团队将通过我们的第一批客户，把Vayu的新技术推向市场。”</p><p>至于为何选择加入这家公司，Hinton认为他们在利用人工智能进行机器人研发方面有巨大潜力，看到团队采用机器学习和视觉传感器的方法，这些技术将能够提供安全和环保的解决方案，尤其是在处理AI伦理问题方面，更有优势。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_b43b37d357ad4c448ecf48fc3ba00356@5961534_oswg215372oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Twitter</p><p>从Hinton的描述中可以看到，AI伦理问题一直是他关心的话题，此前从谷歌离职，很大程度上也是担心未来的人工智能技术会对人类生存构成威胁。</p><h2><strong>AI教父的担忧</strong></h2><p>今年五月初，AI教父Hinton突然宣布离开已工作十年的谷歌，理由是他对人工智能技术的发展越来越担忧。</p><p>Hinton认为，随着企业改进AI系统，它们会变得越来越危险。他表示，直到去年谷歌一直是这项技术的“适当管理者”，小心翼翼地不释放可能造成伤害的东西。但是现在，微软用聊天机器人增强了必应搜索引擎，挑战谷歌的核心业务，导致谷歌也在竞相部署同样的技术。</p><p>辛顿表示：</p><blockquote><p>科技巨头陷入了一场可能无法阻止的竞争。</p></blockquote><p>他目前最担心的是，互联网将充斥着虚假照片、视频和文字，普通人将“无法再知道什么是真的”。他还担心AI技术最终会颠覆就业市场。</p><p>如今，像ChatGPT这样的聊天机器人往往是对人类工作者的补充，但它们也可能取代律师助理、个人助理、翻译和其他处理机械化任务的人。“它省去了繁重的工作，但它带走的可能不止这些。”辛顿称。</p><p>未来，他担心AI的新技术会对人类构成威胁，因为它们经常从分析的大量数据中学习意想不到的行为，也许有一天真正的自主化武器“那些杀人机器人”会成为现实。</p><p>现年75岁的Hinton博士是英国侨民，他一生从事学术工作，其对人工智能的发展和使用的个人信念推动了整个职业生涯的发展。2012年，Hinton和他在多伦多的两名学生Ilya Sutskever和Alex Krishevsky基建立了一个神经网络，它可以分析数千张照片，并自学识别常见物体，比如花、狗和汽车等。</p><p>后来，Ilya Sutskever成为OpenAI的首席科学家。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_5c6503a9d82246e79c645c4bd9214119@5961534_oswg313916oswg620oswg359_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：谷歌</p><p>紧接着，谷歌斥资4400万美元收购了Hinton和他的两个学生创办的公司DNNResearch。2018年，Hinton和另外两位长期合作者因在神经网络方面的工作获得了图灵奖。</p><p>Hinton一直是AI界的先锋人物之一，此次回归投身机器人领域的研究，相信也不单单是因为Vayu拥有更先进的理念和技术，很大程度上也是因为AI安全。</p><p>被誉为“人工智能教父”的Hinton长期关注AI技术的应用和管控，他人生中每次重大选择，都是希望能让如此强大的AI技术，确保可以被可控利用。</p><p>今年离开谷歌是出于这样的考虑，更早之前离开卡内基梅隆大学，选择去多伦多大学任教，也是因为不想拿军方经费做研发，让AI为军事所用。</p><p>如今，尽管已经年过七旬的Hinton博士，显然没有退休打算，还想继续在塑造AI的伦理标准和应对潜在风险的道路上积极参与。</p><p>未来，他与创立仅两年的Vayu Robotics间将会迸发出怎样的火花呢，实在令人期待。</p><p><strong>👇🏻 添加请备注：公司+职务&nbsp;👇🏻</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_1a5f030575ac45d78a1bf77fef6d6591@5961534_oswg265471oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">长按添加「智涌」小助手入群</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471075257327497</id>
            <title>大学老师辞职联手创业，搞了个电动车IPO</title>
            <link>https://www.36kr.com/p/2471075257327497</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471075257327497</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:22:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 绿源, 电动两轮车制造商, 上市, 夫妻创业
<br>
<br>
总结: 绿源是中国内地排名第五的电动两轮车制造商，市场占有率为4.2%。绿源集团控股在港交所挂牌上市，背后是一对宁波大学教师夫妻携手创业的故事。他们在电动车领域创业20多年，最终成功将绿源推向资本市场。绿源的收益主要来自电动两轮车的销售，近几年销量和营收都有稳定增长。然而，绿源在电动两轮车制造商中的市场占有率相对较低，仍需面对激烈的竞争。 </div>
                        <hr>
                    
                    <p><strong>以2022年总收益计，绿源是中国内地排名第五的电动两轮车制造商，市场占有率为4.2%</strong></p><p>“小电驴”正在成为资本市场的“造富密码”。&nbsp;</p><p>今日，绿源集团控股在港交所挂牌上市。发行价为7.37港元/股，开盘微跌至7.34港元/股；截至发稿前，每股涨2.71%至7.57港元，总市值32.3亿。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a216e5ec1f374acca8549bb0988210b2@5807375_oswg123364oswg623oswg456_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：雪球网截图&nbsp;</p><p>绿源电动车IPO的背后是一对宁波大学教师夫妻携手创业的故事。&nbsp;</p><p>上个世纪90年代，倪捷、胡继红毕业后双双放弃令人羡慕的大学教师职业，投身电动车领域创业。经过20多年的发展，终于带着绿源敲开了资本市场的大门。&nbsp;</p><p>当下，越来越多的电动两轮车已经“驶向”资本市场，雅迪、新日、艾玛等都相继上市……“姗姗来迟”的绿源集团，能否搅动电动两轮车生产行业一池春水，引发了行业颇多猜测。&nbsp;</p><h2><strong>01 夫妻档联手，打造了一个电动车独角兽</strong></h2><p>一切要从一对大学教师夫妇说起。&nbsp;</p><p>1986年，倪捷研究生毕业后顺利进入宁波大学，成为宁大建校后的第一批老师。两年后，胡继红研究生毕业，也被分配到宁波大学，担任数学老师。&nbsp;</p><p>彼时，恰逢国内下海创业浪潮兴起，倪捷和胡继红双双离开宁波大学，他们决定放弃“铁饭碗”，投身实业。&nbsp;</p><p>最初，夫妻俩进入倪捷叔叔的工厂，领略到了制造业的魅力。直到1995年，夫妻二人开始筹划自主创业。&nbsp;</p><p>胡继红曾表示在大学时代所受的科学教育中，一个工程师最大的理想，就是将电和机融合在一起。而电动车可以将电能转为动能，正好符合这个理想。&nbsp;</p><p>倪捷则是看到了当时国家推崇使用新能源的号召，电动车无疑是个合适的载体。于是夫妻二人一拍即合，投入到了电动车创业领域。&nbsp;</p><p>1996年，绿源的第一辆电动车，由胡继红亲自参与研发而成，也是她第一个试骑的。&nbsp;</p><p>1997年，金华市绿源电动车有限公司正式成立，由倪捷担任公司的董事长兼总经理，胡继红任总工程师，当时绿源向国家商标局申请注册了“绿源”商标，寓意“绿色能源”和“与绿结缘”。&nbsp;</p><p>同年，绿源第一代电动车成功上市销售。&nbsp;</p><p>如今，时隔25年，两位元老级核心人物终于将绿源推向港交所大门口。&nbsp;</p><blockquote><p>在绿源上市前的股东架构中，倪捷、胡继红夫妇各自通过Drago Investments、Apex Marine分别持股41%、41%，此外他们通过各持50%权益的Best Expand，间接持股4.77%，夫妻二人合计持有上市平台86.77%的股份，为控股股东。&nbsp;</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a8a90fb18ba84ed091f8bb1a565bdb30@5807375_oswg38987oswg598oswg451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：招股书&nbsp;</p><h2><strong>02 一年卖出242万辆，年营收47亿</strong></h2><p>目前，绿源的收益主要来自电动两轮车的销售，电动两轮车大致分为电动摩托车、电动轻型摩托车及电动自行车。&nbsp;</p><p>其次，公司也从出售其他特殊功能车辆、电池及其他车辆部件以及向经销商提供各种服务产生收益。&nbsp;</p><p>2020-2022年，绿源三年总销量分别为147.2万辆、194.8万辆、242.4万辆，复合年增长率为28.4%。&nbsp;</p><blockquote><p>销量的增长直接带动了公司营收的增加。招股书显示，绿源电动车2020年、2021年、2022年营收分别为23.78亿元、34.18亿元、47.83亿元；毛利分别为2.86亿元、3.87亿元、5.61亿元；期内利润分别为4028万元、5926万元、1.18亿元。&nbsp;</p></blockquote><p>截至2022年4月30日止四个月，绿源电动车的营收由11.62亿元增加42.1%至2023年同期的人民币16.51亿元。期内利润由截至2022年4月30日止四个月的1640万元增加149.6%至2023年同期的人民币4100万元。&nbsp;</p><p>具体来看，2022年，绿源集团电动自行车业务收入最高，占比达46.7％；电池业务、电动摩托车业务次之，占比分别为22.0％、19.9％。&nbsp;</p><p>截至2023年4月30日，绿源电动车在中国内地有经销商1314家，覆盖30个省级行政区的319个城市。于往绩记录期间，截至2020年、2021年及2022年12月31日以及2023年4月30日，公司分销网络内的零售门店数目分别超过5400家、7800家、9800家及11400家。&nbsp;</p><p>此外，透过与海外经销商合作，绿源于37个国家及地区出售公司的产品，包括泰国、印尼及菲律宾。&nbsp;</p><p>不过绿源来自海外经销商的收入仅占总收入的极小部分。于2020年、2021年及2022年以及截至2022年及2023年4月30日止四个月，海外经销商产生的收入分别占公司各期销售产品的收益的1.7%、1.9%、2.4%、4.0%及0.5%。&nbsp;</p><h2><strong>03 两轮电动车战火延续</strong></h2><p>对于绿源而言，上市是一段新挑战的开始。&nbsp;</p><p>虽然自称“引领”行业关键技术的发展，但绿源电动车的市场占有率却不算高。&nbsp;</p><p>以2022年总收益计，绿源是中国内地排名第五的电动两轮车制造商，市场占有率为4.2%。&nbsp;</p><p>第一梯队的雅迪、艾玛、公司A，它们在国内电动车市场占有率超过了55%，绿源的市占率与其相比差距明显；第二梯队则包括绿源、小牛等厂商，它们之间的市场份额差距并不大，都在2.7%至4.2%之间，绿源也未能与同级别竞争对手拉开明显差距。&nbsp;</p><p>从毛利率来看，绿源2022年的毛利率为11.7%。在已上市的公司中，2022年，雅迪控股的平均毛利率为18.08%，爱玛科技为16.36%，新日股份为13.04%。&nbsp;</p><blockquote><p>从净利率来看，2020-2022年，绿源的净利率分别为1.69%、1.73%、2.47%；同期雅迪的净利率分别是4.95%、5.08%、6.96%；小牛的净利率分别是6.9%、6.1%、0.3%。&nbsp;</p></blockquote><p>绿源在招股书中也提到，根据弗若斯特沙利文的数据，2023年至2027年电动两轮车按中国内地总销量计的市场规模将按复合年增长率4.6%增加，相对低于2018年至2022年的17.1%。&nbsp;</p><p>鉴于电动两轮车行业的竞争日益加剧且增长放缓，公司可能无法成功保持过往的高速业务增长。&nbsp;</p><p>两轮电动车企业想要实现持续增长，探索新产品、新技术、新市场和新的发展模式十分关键。两轮电动车品牌们，也开始寻找突围路径，其中智能化成为了一个新的思路。&nbsp;</p><p>绿源在招股书中提到，公司高度重视产品升级更新及开发相关技术，核心技术覆盖电动两轮车的关键部件，技术的开发进步极大地提升了电动两轮车产品的使用寿命和安全性能。&nbsp;</p><p>在技术研发方面，绿源专注于离子电池安全、智能电动两轮车等具备强大潜力的领域。两轮电动车的“智能化”发展态势愈发明朗，其高端化、智能化竞争还未到终局。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ytaqgd3dkmp3j3GFQboa7A" rel="noopener noreferrer nofollow" target="_blank">“直通IPO”（ID:zhitongIPO）</a>，作者：韩文静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470889020151682</id>
            <title>36氪独家丨宝马千亿元电池大单落地：蜂巢中标欧洲，宁德时代、亿纬锂能角逐国内</title>
            <link>https://www.36kr.com/p/2470889020151682</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470889020151682</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 07:49:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 宝马, 电池订单, 蜂巢能源, 宁德时代
<br>
<br>
总结: 宝马与蜂巢能源和宁德时代签订了大量电池订单，价值超过百亿欧元。蜂巢能源是一家新晋供应商，其短刀电芯在宝马新一代平台的纯电车型上使用。宝马选择蜂巢能源和宁德时代作为电池供应商，表明宝马对电池技术的重视和推动电芯标准化生产的决心。蜂巢能源使用叠片技术生产短刀电芯，具有高生产效率。宝马对电池的要求严格，电池企业需要付出很大努力来满足宝马的要求。 </div>
                        <hr>
                    
                    <p>文｜韩永昌&nbsp;</p><p>编辑｜李勤 杨轩</p><p>宝马年初对外招标的约160GWh电池订单终于浮出水面。</p><p><strong>36氪从多位产业链人士处获悉，蜂巢能源已经获得宝马欧洲区近90GWh的产能订单，国内近70GWh订单将由宁德时代或亿纬锂能提供。如果每瓦时的价格以0.6元来估算，宝马这笔订单的价值将到达960亿人民币，超过百亿欧元。</strong></p><p>宝马此前已经与宁德时代、亿纬锂能就大圆柱电池达成战略合作，此次追加订单也在情理之中。但据36氪了解，此次给到两家公司的近70GWh订单不仅限于圆柱电池范畴。</p><p>而另外一家新晋供应商选定蜂巢能源则比较让人意外。蜂巢能源2018年脱胎于长城的动力电池事业部，是一家近两年崛起的动力电池新秀，其主要客户是长城、零跑等车企，近期又因成功配套理想L7和银河、领克等部分PHEV车款而在电池行业声名鹊起。</p><p><strong>据了解，蜂巢能源初期将为宝马规划两条电芯产线，以及配套的模组与pack产线。所供给的电芯类型是蜂巢能源主打的大单品——短刀电芯。这些电芯将采取 CTP 模式在宝马新一代平台的纯电车型上使用。</strong></p><p><strong>为签下宝马巨额订单，蜂巢绸缪已久。“7月份的时候就已经签了，SOP时间定的是2027年底。”一位接近蜂巢的人士告诉36氪。</strong></p><p>作为一家少有的了解电芯特性并具有小规模量产能力的欧洲传统车企，宝马在电芯的选择上从来都有自己的一套模式。</p><p>2022年宝马先后选定三家电池供应商，为其生产46系大圆柱电池，合计规划产能达到了110GWh，成为继特斯拉之后唯一一家对大圆柱电池如此倾心尽力的车企，全行业都感受到了宝马对电池技术押注的决绝。</p><p>有电池企业人士对此评价称，<strong>“宝马的目的一直都是将电芯推向标准化生产。”</strong></p><p>车企不会允许自己所采用的的电池产品出现技术代差，自然也不会将技术选择放在一个篮子里。此次宝马再次开出天价订单，并将大部分产能给予了以短刀电芯见长的蜂巢能源，似乎印证了短刀形状是宝马选择的方形电芯标准化生产的最优解。</p><p>短刀电芯+叠片技术，也在生产效率上展现出了潜力。</p><p>电池制造技术分为卷绕与叠片两种路线，卷绕技术在电池行业已经有十数年的应用历史，工艺成熟，多用于圆柱与方形电芯，而叠片技术在2018年开始才逐渐引入动力电池制造中来，主要在方形和软包电芯上使用。</p><p>蜂巢在短刀电芯的生产上使用了比普通叠片更难的飞叠技术，用八个工位同时进行叠片，藉此综合效率做到了0.125S/pcs。</p><p>36氪此前曾参观蜂巢盐城工厂的飞叠产线，主要生产容量是62Ah的L400短刀电芯。对比来看，LG为特斯拉供货的21700电芯容量为5Ah，也就是说一个L400短刀电芯可以抵12个21700电芯。</p><p>按生产效率来计算，21700电芯如果能做到300PPM（每分钟生产电芯的个数）的生产速度，可与蜂巢L400电芯的25PPM相当，都是一分钟可以产出1500Ah左右的电芯。蜂巢盐城基地的产线设计产能为24PPM，已经接近圆柱电池的生产效率。</p><p>当然，方形电芯做到如此高的生产效率对良率和一致性的控制提出了极大的考验，而宝马的到来或将帮助叠片技术在此方面更上一个台阶。</p><p>电池企业获得宝马订单不止意味着出货量方面带来保障，更重要的是将接受宝马严苛的生产规范标准。</p><p>宁德时代创立之初的成名之战便是历时两年啃下了宝马给出的800多页德文生产技术文件，建立起了一套规范且高效的动力电池生产体系，随后宇通等大客户慕名而来，并连年追加采购额度。</p><p>因此，上述人士还说道，宝马对电池的要求很严格，甚至很多要求都是过于复杂的，超前的，以目前的动力电池技术水平可能不太容易达到他们的心理预期，电池企业做配套需要付出很大的努力。</p><p>如果此次宝马的订单顺利达产，最大受益者或许是作为二线电池厂的蜂巢能源和亿纬锂能，而经受住宝马的质量考验的金字招牌，也将成为打开更多客户市场的关键钥匙。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471066546020489</id>
            <title>这家网红大米品牌上市，市值180亿</title>
            <link>https://www.36kr.com/p/2471066546020489</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471066546020489</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 07:46:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 东北大米品牌, 十月稻田, 电商红利, 资本青睐
<br>
<br>
总结: 十月稻田是一家成功打出品牌化的东北大米品牌，凭借抓住电商红利和线上渠道的快速崛起，年收入达到45亿元，成为行业黑马。该品牌得到了资本的青睐，先后获得红杉中国、云锋基金等投资。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_1d9edaebb72e4a8fa6780004bbd985ab@5807375_oswg57003oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>红杉、云锋都看好的东北大米品牌上市了。</strong></p><p>乘着电商红利东风，这家网红东北大米品牌在十年间迅速成长，从地头田间走上了资本的“餐桌”。&nbsp;</p><blockquote><p>今日，十月稻田正式登陆港交所，发行价15.36港元/股，开盘报16.6港元/股。截至发稿时间，涨11.07%，报17.06港元/股，市值达180亿港元。&nbsp;</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_339107f8ddf740139d919d441197908c@5807375_oswg42220oswg1080oswg499_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：富途牛牛&nbsp;</p><p>创始人王兵曾说，在大众认知中，大米、杂粮很难出品牌，但十月稻田却成功打出了品牌化，在巨头环伺的大米赛道中突围。&nbsp;</p><p>根据招股书显示，2020年至2022年，十月稻田的收入由23.27亿元增长至45.33亿元，年复合增长率达39.6%，其中，线上渠道营收占比超过七成。&nbsp;</p><p>成长惊人的十月稻田也获得了资本青睐。2020年，十月稻田完成启承资本独家投资的3亿元A轮融资，此后，红杉中国、云锋基金、泰合资本、CMC资本、中东财团相继投资。&nbsp;</p><h2><strong>01 抓住电商红利，年入45亿元</strong></h2><p>十月稻田品牌成立于2011年，旗下品牌包括十月稻田、柴火大院和福享人家。用王兵的话说，十月稻田是跟着中国互联网发展起来的。&nbsp;</p><p>而这其中十月稻田最主要的是抓住了电商的红利。&nbsp;</p><p>成立之初，十月稻田便赶上了京东首次扩大商品类目的机会，王兵立即向京东递上申请，很快达成合作，将“十月稻田”和“柴火大院”的小包装大米搬到线上销售。2013年，十月稻田又与天猫合作拓展电商平台。&nbsp;</p><p>此后，电商崛起，十月稻田也抓住了每一个崛起的平台机会，相继与1号店、当当网、天猫超市、顺丰优选、中粮我买网、苏宁易购、盒马等多个平台达成合作。&nbsp;</p><blockquote><p>得益于电商红利，十月稻田快速崛起成为一匹行业黑马。根据招股书显示，2020年、2021年、2022年十月稻田营收分别为23.27亿元、35.98亿元、45.33亿元，年复合增长率达39.6%。&nbsp;</p></blockquote><p>其中，线上渠道为十月稻田分别贡献了约18.50亿元、27.17亿元及31.44亿元，占总收入分别为79.5%、75.5%及69.4%。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_137814e33082447fa5956c49e28d8d9e@5807375_oswg172403oswg700oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：招股书截图&nbsp;</p><p>招股书显示，以收入计算，在大米、杂粮、豆类及籽类行业综合性电商平台中，2022年十月稻田市场占有率达14.2%，是综合性电商平台上大米杂粮类销售规模最大的公司。&nbsp;</p><p>在京东、盒马等电商渠道上，十月稻田已成为精品国产大米的代表之一。&nbsp;</p><p>除了电商红利之外，十月稻田为了加固品牌化，走上了“网红”道路，积极与KOL合作。&nbsp;</p><p>截至2022年底，十月稻田合作的KOL和KOC超过3500位，其中百万粉丝博主超450位，并签约了自由式滑雪冠军徐梦桃担任代言人。&nbsp;</p><p>除此之外，十月稻田也不惜砸重金营销。&nbsp;</p><blockquote><p>根据招股书显示，报告期内，十月稻田的销售费用分别为1.26亿元、2.23亿元和3.15亿元，近三年营销费用增幅达近80%，营销费用率也从5.4%上升至7.0%。&nbsp;</p></blockquote><p>在营销推广的同时，2022年十月稻田的销售人员支出也达到了1.43亿元，较2020年增长超650%。&nbsp;</p><p>打出知名度和品牌化的十月稻田，也逐渐被资本看到。&nbsp;</p><p>2020年，十月稻田完成启承资本独家投资的3亿元A轮融资。第二年，十月稻田宣布完成14.5亿元B轮融资，红杉中国、云锋基金、CMC资本、泰合资本投资，老股东启承资本继续跟投。&nbsp;</p><p>在招股书十月稻田还透露了一轮未曾“官宣”的融资。&nbsp;</p><p>2022年10月，MIC Capital以1.2亿元和2.5亿元，向十月稻田、启承资本收购0.96%、2%的股权。同时，双方还签订了增资协议。&nbsp;</p><p>据了解，MIC Capital是中东主权财富基金穆巴达拉投资公司PJSC的子公司，实益拥有人为阿布扎比政府，也就是位于中东的阿联酋政府。&nbsp;</p><p>2023年2月，上述增资协议实施，MIC以2.86亿元收购了十月稻田约2%的股份。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_37a692c5dfc14a0ba13cbc48128dfa96@5807375_oswg129109oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：招股书截图&nbsp;</p><p>根据招股书显示，IPO前，启承资本持有12.49%的股份，为最大机构投资方；红杉中国、PJSC、云锋基金、CMC资本以及策然投资分别持股5.66%、4.9%、3.4%、1.81%以及0.45%。&nbsp;</p><h2><strong>02 网红品牌化之后，十月稻田加码供应链</strong></h2><p>“网红品牌”的外衣，王兵清楚无法长久依赖。尤其近年来，互联网红利趋向天花板，电商红利逐步削减，十月稻田必然也要走向线下，这意味着，十月稻田将与曾经绕开的行业巨头“短兵相接”。&nbsp;</p><p>十月稻田也需要新的核心竞争力。在王兵看来，要真正做好大米品牌，技术是很大的机会。&nbsp;</p><p>因此，十月稻田在生产模式和供应链体系上做了诸多布局和投入。&nbsp;</p><p>生产模式方面，十月稻田采用了“需求-设计-生产-交付”的C2M模式。一方面，借助线上渠道，直接触达消费者。采用订单式生产，鲜稻现磨，一件代发，省去中间环节。&nbsp;</p><p>另一方面，通过大数据，提前发现持续高增长产品，再从产品源头挑选优质原粮，进行口感升级，实现“以销定产”。&nbsp;</p><p>在供应链体系方面，十月稻田打造了一套垂直一体化供应链体系。截至2022年年末，十月稻田已建立了五个生产基地，包括沈阳新民生产基地、五常生产基地、松原生产基地、通河生产基地、敖汉生产基地，设计产能为111.75万吨。&nbsp;</p><p>生产加工环节，以五常产业基地为例，离稻田不足500米就是十月稻田的仓库，原粮从稻田直接进入稻谷恒温仓，减少稻米在运输过程中的营养流失。&nbsp;</p><p>并且，十月稻田坚持用先进的设备提升大米生产的标准化和自动化，提升加工效率，2019年，十月稻田引入瑞士进口布勒设备，该设备可以实现多级轻碾，从而降低碎米率，提高脱壳率。截至2022年底，十月稻田已有超过10条自动化生产线投入使用。&nbsp;</p><p>十月稻田将仓储、加工、检验、运输等多个部门整合在原产地，此外，运输环节，十月稻田还在上海、天津、成都、沈阳和东莞的五个自营区域中心仓及十个地方仓库建立了一个现代化库配体系，涵盖海运、汽运、铁运等多种运输方式，来提升运输能力。&nbsp;</p><p>除此之外，十月稻田还与电商平台共建了专属的定制商品供应链，快速匹配相应服务。&nbsp;</p><p>根据弗若斯特沙利文的资料显示，十月稻田是中国大米、杂粮、豆类及籽类行业中少有的全产业链公司，涵盖采购、储存、生产、销售、物流等环节。&nbsp;</p><p>对于此次上市募资用途，十月稻田在招股书中表示，将主要用于增强与供应商的合作，并加强采购能力；扩建产能、升级现有产线、拓宽仓储物流地域覆盖以及为业务扩充提供资金；加深渠道覆盖并构建全渠道的销售生态体系；提升品牌势能；建设数字化中台体系，打通信息技术基础设施、后台、中台、前台、触点数字化全链路，优化对业务管理的支撑。&nbsp;</p><p>可见，供应链、渠道和数字化将是十月稻田持续修筑的核心护城河。&nbsp;</p><p>如今，虽然东北大米在全国范围内的渗透率很高，但还不如牛奶这种传统品类的品牌势能大。王兵坦言：“在这样的大品类里做品牌确实有难度。但大米在中国是刚需，是涉及到国计民生的行业，同时又是一个非常分散的市场，所以更需要有品质保证的品牌出现，这也是我们创业的初心。”&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/uHfuG85OKPIQspOF_3Qb-w" rel="noopener noreferrer nofollow" target="_blank">“直通IPO”（ID:zhitongIPO）</a>，作者：盛佳莹，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471028291197059</id>
            <title>DALL·E 3瞬间生成素材，零成本制作数千万流水游戏，OpenAI总裁转赞</title>
            <link>https://www.36kr.com/p/2471028291197059</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471028291197059</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 07:46:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI总裁Brockman, DALL·E 3, 游戏素材, 像素风
<br>
<br>
总结: OpenAI总裁Brockman分享了使用DALL·E 3生成游戏素材的方法，包括像素风的人物角色、怪物形象、宝箱造型和背景设定等。以前需要专业作者花费几天时间才能完成的效果，现在只需几句prompt和几分钟即可完成。这种方法不仅可以提高制作效率，还能为游戏开发者带来丰厚的收入。 </div>
                        <hr>
                    
                    <p>OpenAI总裁Brockman又给网友支招来薅ChatGPT Plus的羊毛了。直接用DALL·E 3可以快速生成制作2D游戏的各种素材，像素风，JRPG都不在话下！</p><p>OpenAI总裁Brockman最近转发了一条推特火了，全网超过84万的阅读量！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_f55b5ea0004141cb805215bb0084c198@000000_oswg928849oswg897oswg847_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>推特内容是教网友如何高效地薅OpenAI的羊毛，用DALL·E 3制作游戏中的各种素材。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_387bac4fdb1f478ebfca71bc91493edb@000000_oswg190479oswg655oswg444_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从游戏中的人物角色，到怪物的形象，宝箱造型，背景设定。类似的像素风游戏的所有素材，以前可能需要专业作者花几天才能做出来的效果，现在用ChatGPT Plus，几句prompt，几分钟搞定！&nbsp;</p><p>去年，一款由一个制作者独立制作的游戏「吸血鬼幸存者」，就是采用的类似的像素风素材，加上让人上头的游戏设计，在steam上大卖超过250万份，给作者一个人带来了数千万的收入！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_dea6f930cfbd48e09b88b0e261a0feb8@000000_oswg892403oswg1080oswg748_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作者Luca Galante透露，自己制作这款游戏的成本只有1000欧元左右，大部分都花在了购买游戏的素材上。&nbsp;</p><p>如果使用DALL·E 3，可能他连这1000欧都能省了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_7b842fd5aeb048c6a2aaab2e7ea0eed2@000000_oswg78315oswg224oswg225_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>01 DALL·E 3一秒生成游戏素材</strong></h2><p>具体来看，如何用DALL·E 3生成像素风的游戏素材。</p><p>首先，要先确保订阅了ChatGPT Plus，然后选中GPT-4标签页后再选择DALL·E 3。这里需要注意的是，不是所有的ChatGPT Plus账号都能自动试用DALL·E 3，需要在标签页处先确认。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0616aabc656649c6a68baccff4242303@000000_oswg110808oswg577oswg845_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果ChatGPT暂时没有DALL·E 3的话，可以通过Bing Chat来访问DALL·E 3。&nbsp;</p><p>然后只需要用一个简单的提示词：「I want assets for a top-down pixel art rpg game on a white background」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_aef7bf738ee842509449f624aca1006f@000000_oswg190479oswg655oswg444_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然后可以把范围缩小到只有药水和玩家装备。结果也非常好。&nbsp;</p><p>使用Prompt 描述好直接就能出理想的结果「I want some pixel art game assets designed to resemble inventory items: a golden key, a health potion, a magical amulet, and a leather-bound book. 」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_ca2c2c996716429fbb01e28f4b25088d@000000_oswg112767oswg656oswg481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以再告诉它要生成一些不同颜色和形状的药水（potion）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_043a82547ad04cf2a11a3c397902e7a1@000000_oswg75474oswg655oswg463_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了药水，装备，也能专门生成风格非常一致的素材。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_19fe5df5d5ec4e52a70b8569e479cca7@000000_oswg90670oswg652oswg478_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且还可以在prompt加入「emberage Warlock Armor」，「snowpeak sentinel Armor」，「stoneforged guardian armor」，「skyfeather aviator armor」这几个关键词，就能出现这些相关的素材。&nbsp;</p><p>唯一的门槛就是要会一点英语，因为DALL·E 3对中文的支持不是太好。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_032f2ebcd9ee4a94a6fa40f8b803d1a6@000000_oswg228397oswg542oswg490_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作者使用「dark-themed armor」这个关键词，DALL·E 3不但给你了这些素材，还可以给你生成具体的，解释和描述。这样连游戏里的装备介绍都有了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_673f0e2f66ea441cbba4ce53dca139e8@000000_oswg243216oswg617oswg509_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>针对不同的药水风格，只要你对应上关键词「winter」，「steampunk」，「beach」，「mystical forest」。而且还可以针对细节进行微调。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_692915c80a3f4c09be90f9ec1ce69ece@000000_oswg214587oswg549oswg413_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就用「I want themed item sets including potions, scrolls, runes, and jewelry.」&nbsp;</p><p>再根据图片下面的介绍关键词，也可以生成除了药水之外的「golden scroll」，「a rune stone」，「a diamond necklace」等等，对应了卷轴，符文石，钻石项链等等。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c5699f2b542944af8fada78e8ce50f2c@000000_oswg240410oswg547oswg511_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果要针对不同的颜色主题，也可以根据不同的关键词，比如这个就是「autumn themed」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_225ae41ca23c4eadadbe07d94757ced7@000000_oswg801553oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这组素材的关键词是「black and purple themed」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6b75f14974de4b32b91a988a285565e8@000000_oswg798995oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这组素材的关键词是 「green themed」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_3e5e127fe1294b28afa5460e25e0ac98@000000_oswg771352oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这组素材的关键词是「red and black themed」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_f688f51be0b94536ad79080e58c2fbca@000000_oswg602966oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>02 任意美术风格的游戏素材都不在话下</strong></h2><p>同样，生成游戏素材，除了这篇文章中的像素风，其他的美术风格，我们试了一下，DALL·E 3也是游刃有余。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_98817efb294f43839a967c5c123244ab@000000_oswg950826oswg794oswg1012_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>JRPG或者ACG游戏风格的素材也是信手拈来（关键词：JRPG with the animation art style）。&nbsp;</p><p>女性的人物的头像（关键词：female charactor protraits for the JRPG with the same art style）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_f56fd7370f6f43b38fc2d342f8bf0332@000000_oswg593002oswg876oswg542_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>游戏中弓箭的近景特写素材。（关键词：close-up images of strong bows）&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_88e453c03ac84a75a93a3726149df425@000000_oswg852040oswg814oswg1045_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了RPG，战略游戏的地图设计草图也不在话下！（关键词：map design sketches for your futuristic RTS game）&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_127a9f11514246d79b2221deb7d073e9@000000_oswg1122796oswg812oswg921_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了测试一下DALL·E 3的中文能力和理解中文背景的创作能力，我专门用西游记里的孙悟空来要求制作游戏素材。&nbsp;</p><p>结果发现，他的中文的理解能力还有待提高。没法画出中文的孙悟空和西游记的图片。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_1bb1cc8cf4004275b0fcdb998c192745@000000_oswg591634oswg592oswg1050_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但是用英文描述西游记的孙悟空，可以生成不错的内容。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_be5e004408134550a368c4e98e80e8aa@000000_oswg167258oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>说明至少DALL·E 3对于中文背景的内容理解还是到位的，但是确实对于中文prompt的支持就比较一般了。&nbsp;</p><p>可以说，只要用对了提示词，DALL·E 3对于游戏素材生成任务目的理解能力是非常强的。&nbsp;</p><p>参考资料：&nbsp;</p><p>https://twitter.com/gdb/status/1710378848364490794</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652389300&amp;idx=4&amp;sn=113665227330896353987da75c19d51f&amp;chksm=f12b4b45c65cc25341099bf0e429f3c6c7c93a5153d084cd1c8448858961b5794522f8ff05df&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471027851516036</id>
            <title>国产大模型开源一哥再登场，最强双语LLM“全家桶”级开源，340亿参数超越Llama2-70B</title>
            <link>https://www.36kr.com/p/2471027851516036</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471027851516036</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 07:46:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 国产大模型, Aquila2-34B, 开源, 中英双语
<br>
<br>
总结: Aquila2-34B是一款国产的中英双语大模型，拥有340亿参数，通过在多个评测基准上的表现，成为最强的开源模型。它具备强大的推理和泛化能力，适用于各种应用场景，包括AI Agent、代码生成和文献检索。智源不仅开源了Aquila2模型系列，还开源了创新训练算法和语义向量模型BGE的新版本，这在大模型开源界是史无前例的。Aquila2-34B在中英文综合能力方面突破，成为当今最强的开源中英双语对话模型，回答准确全面、富有人情味，甚至可以完爆GPT-4。 </div>
                        <hr>
                    
                    <p>就在刚刚，340亿参数的国产大模型悟道·天鹰Aquila2强势冲上榜首，成为最强开源中英双语大模型。更YYDS的是，这次智源不仅开源了明星模型，还赠送了非常有口碑的模型周边！</p><p>最强中英双语大模型，开源了！</p><p>今天，悟道·天鹰Aquila大语言模型系列已经全面升级到Aquila2，并且再添了一位重量级新成员——340亿参数的Aquila2-34B。</p><p>在代码生成、考试、理解、推理、语言四个维度的22个评测基准上，Aquila2-34B强势霸占了多个榜单TOP 1。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_4dc64b6b620c47ceb99029d9bd27f5a1@000000_oswg477513oswg970oswg1280_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，「全面超越Llama 2」这样的字眼，早已不再是新闻。相比分数，业内更看重的是大模型的能力。</p><p>而在这些实际能力上，AquilaChat2的表现依然十分抢眼——</p><p>它不仅具有超强的推理能力，长文本处理能力也大大提升；强大的泛化能力，让它可以适应各类真实应用场景，包括AI Agent、代码生成、文献检索。</p><p>更惊喜的是，智源不仅Aquila2模型系列全部开源，而且还同步开源了Aquila2的创新训练算法，包括FlagScale框架和FlagAttention算子集，以及语义向量模型BGE的新版本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_3689a37147f448edb0f0ea7719686349@000000_oswg50213oswg226oswg223_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以说，创新训练算法和最佳实践同步开放，在行业内是史无前例的。这种全家桶级别的开源，堪称是大模型开源界的业界良心了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_400f2c738bc64e6b92c58e3bc71c443f@000000_oswg418059oswg1080oswg460_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Aquila2模型全系开源地址：&nbsp;</p><ul><li>https://github.com/FlagAI-Open/Aquila2</li><li>https://model.baai.ac.cn/</li><li>https://huggingface.co/BAAI</li></ul><h2><strong>01 最强中英双语大模型，开源！</strong></h2><p>22项综合排名领先，仅凭1/2的参数量和2/3的训练数据量，就超越了Llama2-70B和其余开源基座模型，Aquila2-34B是怎样做到的？</p><p>这背后，当然要归功于智源多年积累的高质量语料。经过这些语料预训练后的模型，综合能力十分强大，超越了通义千问和Llama 2。</p><p>架构升级、算法创新、数据迭代，也使Aquila2在中英文综合能力方面进一步突破。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0d8f4770987b4ae893275235d105043d@000000_oswg187280oswg444oswg456_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而Aquila2基座模型，为AquilaChat2对话模型提供了强大的基础。</p><p>经过高质量指令微调数据集训练之后，AquilaChat2-34B一跃而成为<strong>当今最强的开源中英双语对话模型</strong>， 主观及客观评测结果，都做到了全面领先。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_62ddc769dbd54520862d1ae7463f77cc@000000_oswg214151oswg1080oswg625_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">SFT模型评测结果</p><p>并且，AquilaChat2-34B呈现出了几个有趣的特点——它不仅具备丰富的中文世界原生知识，并且提供的回答更加准确全面、富有人情味。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_5250ea735294446f95e610141e9d335c@000000_oswg684746oswg1080oswg985_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于中文世界的掌握，AquilaChat2-34B甚至可以完爆GPT-4。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_4cb01daad2244e87a33f942a21e4518a@000000_oswg67294oswg1080oswg221_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于「如何用螺丝钉炒西红柿」这样的问题，AquilaChat2-34B立刻聪明地猜到，用户应该是想问「西红柿炒鸡蛋」。</p><p>相比之下，GPT-4只能理解到「螺狮粉炒西红柿」这一层。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_5392c72fc5eb47c8aacdec902cf65b3c@000000_oswg287748oswg1080oswg464_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如果问大模型「研究什么专业的大学生容易找到工作时，分析单位是什么」，GPT-4的回答就很简单粗暴——专业。</p><p>而AquilaChat2-34B则富有洞见地表示，分析单位可以是行业、公司类型、职级、地域、薪资水平、专业匹配度等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0936240730f646c897b185b1897b7088@000000_oswg132223oswg1080oswg308_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>推理超越Llama 2，仅次于GPT-4</strong></h3><p>我们能在哪一年实现AGI，是如今业内相当热门的话题。</p><p>如何实现AGI呢？这其中最关键的，就是大模型的推理能力。</p><p>在评测基准Integrated Reasoning Dataset（IRD）上，十几个当红模型在归纳推理、演绎推理、溯因推理和因果推理维度上的结果和过程的准确性上，进行了全面比拼。</p><p>结果显示，AquilaChat2-34B在IRD评测基准中排名第一，超越了LLama2-70B-Chat、GPT-3.5等模型，仅次于GPT-4。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_ffb08fc298574b41b6c024a20dfb6215@000000_oswg230294oswg1080oswg615_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">SFT模型在IRD数据集上的评测结果</p><h3><strong>上下文窗口长度，扩至16K</strong></h3><p>长文本输入，是行业现在迫切需要解决的问题。</p><p>能够接收多少文本输入，直接决定了大模型有多大的内存，它和参数量一起，共同决定了模型的应用效果。</p><p>对此，智源以Aquila2-34B为基座，经过位置编码内插法处理，并在20W条优质长文本对话数据集上做了SFT，直接将模型的有效上下文窗口长度扩展至16K。</p><p>在LongBench的四项中英文长文本问答、长文本总结任务的评测效果显示，AquilaChat2-34B-16K处于开源长文本模型的领先水平，已经接近GPT-3.5。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a59657e0269c44d486105fae884b9920@000000_oswg180796oswg1080oswg347_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">长文本理解任务评测</p><p>另外，我们都知道，大模型普遍存在着长度外延能力不足的问题，这个问题严重制约了大模型的长文本能力。</p><p>智源联合北大团队，对多个语言模型处理超长文本的注意力分布做了可视化分析。他们发现：所有语言模型均存在固定的相对位置瓶颈，且显著小于上下文窗口长度。</p><p>为此，智源团队创新性地提出了NLPE（Non-Linearized Position Embedding，非线性位置编码）方法，在RoPE方法的基础上，通过调整相对位置编码、约束最大相对长度，来提升模型外延能力。</p><p>在代码、中英文Few-Shot Leaning、电子书等多个领域的文本续写实验显示，NLPE可以将4K的Aquila2-34B模型外延到32K长度，且续写文本的连贯性远好于Dynamic-NTK、位置插值等方法。</p><p>如下图所示，在长度为5K～15K的HotpotQA、2WikiMultihopQA等数据集上的指令跟随能力测试显示，经过NLPE外延的AquilaChat2-7B（2K）准确率为17.2%，而Dynamic-NTK外延的AquilaChat2-7B准确率仅为0.4%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_bf68cb349c3c48f18ddcea1e24534608@000000_oswg71237oswg1080oswg559_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">NLPE与主流Dynamic-NTK外延方法在SFT模型上的能力对比</p><p>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d728ee5526204a0aa16878ddb3a61226@000000_oswg115778oswg1080oswg380_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">NLPE与主流Dynamic-NTK外延方法在Base模型上的能力对比（ppl值越低越好）</p><p>同时，智源团还开发了适配长文本推理的分段式Attention算子PiecewiseAttention，来高效地支持NLPE等面向Attention Map的优化算法，进一步减少显存占用、提升运算速度。</p><h2><strong>02 泛化能力超强，绝不「高分低能」</strong></h2><p>说起来，许多大模型虽然在标准测试中表现出色，一到实际应用的时候却抓瞎了。</p><p>相比之下，Aquila2模型在考试上成绩优异，在真实应用场景的表现又如何呢？</p><p>要知道，大模型泛化能力，也就是举一反三的能力至关重要。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_917f84600d70403a83bf21d2f9e0feee@000000_oswg292973oswg1080oswg725_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这意味着，LLM在训练数据之外，依然能够有效应对没有见过的任务，给出准确的响应。</p><p>若是这个大模型在基准测试中取得高分，但在实际应用中表现很差，也就是擅长考题但不善于解决实际问题，是「高分低能」的表现。</p><p>为了评估Aquila2模型的泛化能力，智源团队从三个真实应用场景下对其进行了验证。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_fc456d9557b24adba809ea7867ecd601@000000_oswg239183oswg700oswg767_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>AI智能体在「我的世界」自主思考</strong></h3><p>通用智能体，能够在开放式的环境中学习多种任务，是模型重要能力的体现。</p><p>一提到智能体任务的测试，我们能想到的最常见的开放世界游戏，当然就是「我的世界」了。</p><p>这里有着无限生成的复杂世界和大量开放的任务，为智能体提供丰富的交互接口。</p><p>今年3月，智源团队曾提出了在无专家数据的情况下，高效解决「我的世界」多任务的方法——Plan4MC。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_388283fb32124aba948debfbc716b42c@000000_oswg173144oswg1080oswg403_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Plan4MC通过内在奖励的强化学习方法，训练智能体的基本技能。</p><p>然后，智能体利用大模型AquilaChat2的推理能力，完成任务规划。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_178b03a46124454b8147f09566eb274d@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如，当智能体收到「伐木并制作工作台放在附近」的任务后，就会与AquilaChat2进行多轮对话交互。</p><p>首先，智能体明确自己的主任务是——建造工作台，由此输入prompt，包括「当前环境状态」、「需要完成的任务」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_8f954b624bfd41b08ad010a53f4109d8@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然后AquilaChat2收到命令后，便开始做出反馈，告诉智能体「下一步使用什么技能」，同时还确定了下一个子任务为：寻找附近的木头。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_b1cb2fcb94a7447da96e18edd50adef6@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智能体找到木头后，下一个子任务便是伐木。继续将环境信息作为输入，由此，AquilaChat2给出了下个技能名称。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_e01a1f6b6c6a4559a1ebe178e189bddc@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>以此往复，智能体继续推进自己朝着总目标方向，与AquilaChat2进行交互，完成任务。</p><p>就这样，在AquilaChat2的帮助下，智能体搭出了完美的工作台。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_347fc4f215c54b8ca88bb8931cf64c07@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>Aquila2+BGE2，复杂文献也能检索</strong></h3><p>复杂文献的检索，让不少科研工作者头秃。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d7b29ea71d8a4790b75c9889cc5a9fac@000000_oswg93707oswg289oswg174_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>基于传统向量库的检索方式，大模型能够在一些简单问题上表现出色。</p><p>然而，当面对复杂、需要深度理解的问题时，它的能力就很有限。</p><p>智源将Aqiula2与开源的语义向量模型BGE2结合，彻底解决了这一大难题。</p><p>当你想要检索某位作者，关于某个主题的论文时，又或者要求大模型针对一个主题的多篇论文的生成总结文本，就不是难题了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6debf0de76fe4f30820f58c3c9a0d8ff@000000_oswg72379oswg379oswg133_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>举个栗子，让Aqiula2给出Mirella Lapata所著关于「总结」的论文。</p><p>Aqiula2立马给出了符合要求的复杂文献。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c4bcb8701c5a4653a094a1f9d531d38e@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Aquila2+BGE2文献检索场景复杂查询示例</p><h3><strong>AquilaSQL：最优「文本-SQL语言」生成模型</strong></h3><p>而AquilaSQL，则可以充当「翻译员」，将用户发出的自然语言指令，准确翻译为合格的SQL查询语句。</p><p>这样，数据查询分析的门槛，就大大降低了。</p><p>在实际应用场景中，用户还可以基于AquilaSQL进行二次开发，将其嫁接至本地知识库、生成本地查询SQL。</p><p>另外，还可以进一步提升模型的数据分析性能，让模型不仅返回查询结果，更能进一步生成分析结论、图表等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_55034d8974d24d2bb11a72320524db10@000000_oswg60329oswg240oswg240_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Aquila基座模型本身就具有优秀的代码生成能力。</p><p>在此基础上，AquilaSQL经过了SQL语料的继续预训练和SFT两阶段训练，最终以67.3%准确率，超过「文本-SQL语言生成模型」排行榜Cspider上的SOTA模型，而未经SQL语料微调的GPT4模型。准确率仅为30.8%。</p><p>在下图中，我们让AquilaSQL从身高（height）、收入（income）和位置（location）三个数据表中，筛选「居住在北京的收入大于1000的人平均身高」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_fe5885164d4348d2bc7390d77f1ecc7a@000000_oswg129056oswg1080oswg323_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AquilaSQL开源仓库地址：https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila/Aquila-sql</p><p>AquilaSQL顺利地生成了多表查询语句，完成了这个复杂查询任务。</p><h2><strong>03「全家桶」级别开源，业界良心</strong></h2><p>一个冷知识是，虽然Llama2也开源，但它的商用许可协议，对中文用户并不那么友好。</p><p>而且，Llama2不仅在中文商用上设限，连对商用的月活都有限制。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_17ab10805fdf4e36bdd088d0a9775ade@000000_oswg111391oswg1043oswg229_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Llama 2商业协议明确表示不允许英文以外的商业</p><p>相比之下，Aquila在全球范围内都可商用——既不像Llama2那样限制重重，也不像其他可商用模型一样需要填表登记。</p><p>此外，很多模型团队在开源时，并不会开源模型训练的超参、优化方案等关键数据。而Aquila2此次却是全部开源创新训练算法，BGE、FlagScale、FlagAttention，都全部分享给了开发者。</p><p>通过这套工具，开发者就以轻松复现Aquila2了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d66e999456804df49d58f82140d2d4a6@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这种史无前例的「全家桶」开源，简直是大模型开源界的YYDS！</p><p>之所以毫无保留地开源训练工具和算法，是基于智源非盈利机构的定位——通过彻底、全面的开源分享，促进全球大模型生态的繁荣。</p><h3><strong>新一代语义向量模型BGE2</strong></h3><p>BGE（BAAI General Embedding）是智源在今年8月全新开源的语义向量模型。</p><p>这次，新一代BGE2也将随着Aquila2同步开源。</p><p>BGE2中的BGE-LLM Embedder模型集成了「知识检索」、「记忆检索」、「示例检索」、「工具检索」四大能力。</p><p>它首次实现了单一语义向量模型对大语言模型主要检索诉求的全面覆盖。</p><p>结合具体的使用场景，BGE-LLM Embedder将显著提升大语言模型在处理知识密集型任务、长期记忆、指令跟随、工具使用等重要领域的表现。</p><h3><strong>高效并行训练框架FlagScale</strong></h3><p>FlagScale是Aquila2-34B使用的高效并行训练框架，能够提供一站式语言大模型的训练功能。</p><p>得益于智源团队的分享，大模型开发者便可以通过FlagScale项目获取Aquila2模型的训练配置、优化方案和超参数。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_003cb961c3ac47089e7d2adab439cdfd@000000_oswg126060oswg1080oswg421_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">FlagScale开源代码仓库：https://github.com/FlagOpen/FlagScale</p><p>因此，智源也成为「国内首个」完整开源训练代码和超参数的大模型团队。</p><p>FlagScale是在Megatron-LM基础上扩展而来，提供了一系列功能增强，包括分布式优化器状态重切分、精确定位训练问题数据，以及参数到Huggingface转换等。</p><p>经过实测，Aquila2训练吞吐量和GPU利用率均达到业界领先水平。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_76f7bfd1b7e049e086739f006a581cae@000000_oswg77578oswg1080oswg286_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">FlagScale训练吞吐量与GPU利用率</p><p>此外，FlagScale还采用了多种并行技术，如数据并行、张量并行和1F1B流水线并行等，加速训练过程，并使用BF16进行混合精度进行训练。</p><p>在性能优化方面，FlagScale采用了FlashAttn V2、计算与通信重叠、梯度累积等技术，显著提升了计算效率。</p><p>未来，FlagScale将继续保持与上游项目Megatron-LM最新代码同步，引入更多定制功能，融合最新的分布式训练与推理技术以及主流大模型、支持异构AI硬件。</p><p>这样就可以构建一个通用、便捷、高效的分布式大模型训练推理框架，以满足不同规模和需求的模型训练任务。</p><h3><strong>开源算子集FlagAttention</strong></h3><p>另外，FlagAttention是首个支持长文本大模型训练、使用Triton语言开发的定制化高性能Attention开源算子集。</p><p>针对大模型训练的需求，对Flash Attention系列的Memory Efficient Attention算子进行扩展。</p><p>目前已实现分段式Attention算子——PiecewiseAttention，已经适配了国产芯片天数，后续还会适配更多异构芯片。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_e9359a1d45924defb376b15166e8b7d7@000000_oswg129394oswg1080oswg418_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">FlagAttention开源代码仓库：https://github.com/FlagOpen/FlagAttention</p><p>PiecewiseAttention主要解决了带旋转位置编码Transformer模型（Roformer）的外推问题。</p><p>大模型推理时的序列长度超出训练时最大序列长度时，距离较远的token之间的Attention权重异常增高。</p><p>而Flash Attention对Attention Score的计算采用分段式的处理时无法做到高效实现，因此智源团队自研了分段式PiecewiseAttention算子，大模型开发者可利用该开源算子实现更加灵活的前处理。</p><p>简单来说，PiecewiseAttention有以下几个特点：</p><p><strong>- 通用性：</strong>对使用分段式计算Attention的模型具有通用性，可以迁移至Aquila之外的大语言模型。</p><p><strong>- 易用性：</strong>FlagAttention基于Triton语言实现并提供PyTorch接口，构建和安装过程相比CUDA C开发的Flash Attention更加便捷。</p><p><strong>- 扩展性：</strong>同样得益于Triton语言，FlagAttention算法本身的修改和扩展门槛较低，开发者可以便捷地在此之上拓展更多新功能。</p><p>未来，FlagAttention项目也将继续针对大模型研究的需求，支持其他功能扩展的Attention算子，进一步优化算子性能，并适配更多异构AI硬件。</p><h2><strong>04 开发者指南：快速上手Aquila2</strong></h2><p>Aquila2模型权重&amp;代码仓库：</p><p>使用方式一（推荐）：通过FlagAI加载Aquila2系列模型&nbsp;</p><p>https://github.com/FlagAI-Open/Aquila2</p><p>使用方式二：通过FlagOpen模型仓库单独下载权重&nbsp;</p><p>https://model.baai.ac.cn/</p><p>使用方式三：通过Hugging Face加载Aquila2系列模型&nbsp;</p><p>https://huggingface.co/BAAI</p><p>Aquila2全系列兼容多个大模型生态开源项目：</p><p>• LoRA/QLoRA：轻量化的模型微调训练技术，既加速了大模型训练，同时也降低了显存占用。</p><p>• vLLM：支持构建高吞吐量的大语言模型服务，支持流式输出，支持单机多卡、分布式并行推理。</p><p>• llama.cpp：支持非GPU端和4-bit 量化，进一步降低开发者的的使用门槛。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652389300&amp;idx=1&amp;sn=bd9a4496d33b5a6209db53c98371d00c&amp;chksm=f12b4b45c65cc25381ee2e886a75b225bfd8fde559d41c052ee9a9c99157a8d5abd60980d694&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470926079383432</id>
            <title>神经网络行为也可以被解释，大语言模型前所未有的突破</title>
            <link>https://www.36kr.com/p/2470926079383432</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470926079383432</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 07:43:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Anthropic, ChatGPT, AIGC, LLM
<br>
<br>
总结: Anthropic是一家获得40亿美元投资的公司，他们发表的论文《朝向单义性：通过词典学习分解语言模型》详细阐述了他们解释神经网络与大语言模型行为的方法。Anthropic的研究对于增强LLM的准确率、安全性，降低有害内容输出有很大帮助。神经元和神经网络是神经网络的基本组成部分，神经元通过模拟大脑神经元的工作方式对数据进行输入、计算和输出。LLM使用神经网络来处理和生成文本，需要理解语言的语法、语义和上下文。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_1a3f26e6a6de4f9ba6617f45493b7796@000000_oswg124402oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就在刚刚过去不久的九月底，有“ChatGPT最强平替”之称的Anthropic拿到了亚马逊的一笔总价40亿美元的投资，之后不久他们就发表了一篇论文《朝向单义性：通过词典学习分解语言模型》（Towards Monosemanticity: Decomposing Language Models With Dictionary Learning），在这篇论文里详细阐述了他们解释神经网络与大语言模型（经常被简称为LLM）行为的方法。</p><p>Anthropic之所以能有“ChatGPT最强平替”的别名，主要是因为其创始成员几乎都参与开发过GPT系列的早期版本，特别是GPT-2和GPT-3。而众所周知GPT系列真正引人关注是从GPT-3之后的3.5开始的，老话说“罗马不是一天建成的”。而且Anthropic的AIGC产品Claude与ChatGPT相比也不逊色多少，今年夏天推出了最新版Claude 2，英国《卫报》对此评论称“训练时以安全性为首要考虑，可以称为‘合宪式AI’或‘合宪式机器人’”，一个全新的AI或机器人分类与研究也可能就将由此开启。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c88b0211252f4668b16a91ae578fb1b3@000000_oswg13819oswg554oswg148_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>现在市面上流行的LLM基本都是基于海量的神经网络而打造，而神经网络又是基于海量数据训练而来。在此基础上的AIGC，如文本、图片、视频等多模态或跨模态内容，虽然也可以保证可观的准确性且数量上也日益丰富，但可解释性始终是难以突破的难关。</strong></p><p>举个例子，现在随便找个AI问1+1=？它们都会说1+1=2，但都无法解释这个过程是如何产生的。即便能进行简单解释，也只是基于语义上的肤浅理解。就像我们人类睡觉时的梦境一样，人人都会做梦也都能大致说出梦境内容，但对梦境的成因几千年来始终都没有合理和统一的解释。</p><p><strong>ChatGPT等LLM经常出现无序、混乱、虚假信息等情况，这种行为被称为“AI幻觉”，也就是常说的一本正经的胡说八道，主要是因为人类无法控制AI与大模型内的神经网络行为。</strong>所以Anthropic的研究对于增强LLM，甚至AI与大模型整体的准确率、安全性，降低有害内容输出的帮助都非常大，这篇论文还是很有参考和借鉴意义的。</p><p>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_55e95ab4ee6440e7b5d0f3d6b40a9465@000000_oswg119307oswg554oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">论文链接：https://transformer-circuits.pub/2023/monosemantic-features/index.html#phenomenology-feature-splitting</p><h2><strong>01 关于神经元与神经网络</strong></h2><p>为了更好地理解Anthropic研究的意义，这里先简要介绍几个基本概念。<strong>神经元是神经网络的基本组成部分，主要对数据进行输入、计算和输出。</strong>它的工作原理是对大脑神经元工作方式的模拟，接收一个或多个输入，每个输入都有一个对应的权重。这些输入和权重的乘积被加总，然后加上一个偏置项。得到的总和被送入一个激活函数，激活函数的输出就是这个神经单元的输出。&nbsp;&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_98927292357a4152950eda3b06bc3320@000000_oswg14662oswg553oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>神经元工作流程示意图，其中a1-an为输入向量的各个分量，w1-wn为神经元各个突触的权重值，b为偏置项，f为传递函数，通常为非线性函数，t为神经元的最终输出结果</p><p><strong>前面说过神经元是神经网络的基本组成形式，一定数目的神经元就可以组成一个神经网络。</strong>这种系统源于对人类中枢神经系统的观察研究与逆向应用，最初的概念早在上世纪40年代早期就提出了，1956年在一台IBM 704电脑上进行了首次实践，但此后就陷入沉寂，直到1975年“反向传播算法”的发明，80年代中期“分布式并行处理”的思想（当时称之为“联结主义”）开始流行，又促使社会各界再次开始重视神经网络。进入新世纪后，特别是2014年出现的“残差神经网络”概念，极大的突破了神经网络的深度限制，随着“深度学习”概念的提出和流行，神经元与神经网络也水涨船高的愈发引人注目。</p><h2><strong>02 对LLM等大模型的重要性</strong></h2><p>前面说过现在的LLM和大模型、AIGC等，基本都要依赖神经元与神经网络才能发展壮大，能说会道的ChatGPT也正是依靠Transformer的神经网络架构开发而来。<strong>LLM使用神经网络来处理和生成文本，在训练过程中，它们会学习如何预测文本序列中的下一个词，或者给定一部分文本后续的可能内容。</strong>为了做到这一点，LLM需要理解语言的语法、语义、以及在一定程度上的上下文。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_677d28d578c04df4bca2c269861b607a@000000_oswg168035oswg554oswg311_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>概括来说，神经元与神经网络提供了处理和生成自然语言的计算框架，而LLM则通过这个框架来理解和生成文本。</strong>这也是很多人对目前的LLM，AIGC，甚至整个AI的原理都概括为“概率论+魔法”的主要原因之一。</p><p>客观看来，这种说法有些偏激但的确也有道理，因为目前的大部分大模型，包括GPT系列在内，它们的生成原理的确可以这么归纳。</p><p>前面说过AI的工作方式可以视为对人类大脑工作方式的逆运用与模仿，而GPT之类使用的黑盒系统也在结构上模仿大脑，由海量的神经元组成。因此要想说明“可解释性”就必须要了解每个神经元在做什么。</p><h2><strong>03 Anthropic的研究</strong></h2><p>Anthropic的研究是基于Transformer模型进行的一次小规模实验，将512个神经元分解成4000多个特征，并逐个分类排序，比如DNA序列、法律专业术语、HTTP请求、营养说明等。<strong>经过试验和研究后发现，单个特征的行为比神经元行为更容易解释且可控，同时每个特征在不同的大模型中基本上都是通用的。</strong></p><p>为了验证这一研究结果，Anthropic还创建了一个盲评系统，来比较单个特征和神经元的可解释性，由图中可见特征（紫红色）的可解释性得分要比神经元部分高了不少（青蓝色）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a0e3e26a7f264dea8001407b6ba79117@000000_oswg25278oswg554oswg198_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外Anthropic还采用了自动解释性方法，最终的结果也是特征得分高于神经元得分，不过这种方法较为复杂，此处不展开，详见其论文。</p><p><strong>Anthropic的这项研究的确意义非凡，不过早在几个月前，OpenAI也曾做过类似的事情。</strong>在今年五月初，OpenAI在官网发布博客文章《语言模型可以解释语言模型中的神经元》（Language models can explain neurons in language models），其中说到：“我们使用GPT-4自动编写LLM中神经元行为的解释，并为这些解释评分，现在将GPT-2中每个神经元的这些（不完美的）解释和分数的数据集公布出来。”当时读过这篇论文的人，几乎都为OpenAI的奇思异想而感到震撼，头皮发麻。</p><p>当时之所以有这项研究，主要是为了回答ChatGPT火遍全球的同时引起的一个问题：<strong>“发展到今天这一步，AI是怎样实现这么强大的功能的？”</strong></p><p>为了回答这个问题，OpenAI当时的做法可以简单的概括为<strong>“用黑盒解释黑盒”</strong>。而且OpenAI的这次研究成果，倒也不失为后续AI与大模型等相关企业进行研究探索了新的方向，自然意义非凡。前面说过AI可以视为是对大脑工作原理的逆运用，而LLM等大模型都使用的黑盒结构也都由海量神经元组成，也是在模仿大脑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_7ce23777c5444c01aac15e79622db718@000000_oswg178704oswg554oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当时OpenAI给出的解释过程分三步：</p><p>给GPT-4一个GPT-2已有的神经元，由GPT-4展示相关的文本序列和激活情况，产生一个对此类行为的解释；</p><p>再次使用GPT-4，模拟被解释的神经元会做什么；</p><p>比较二者的结果，根据匹配程度对GPT-4的解释进行评分。</p><p><strong>最终OpenAI表示GPT-4解释了GPT-2中的全部约30万个神经元，但是绝大多数的实际得分都偏低，只有勉强一千多个的得分高于0.8，这意味着神经元的大部分顶级激活行为都是这一千多个神经元引起的。</strong></p><p>看来AI或许也在有意无意间遵循“二八定律”。当时这项研究成果很快在全球各大技术平台也引起了广泛关注。有人感慨AI进化的方式愈发先进：“未来就是用AI完善AI与大模型，会加速进化。”也有人批评其得分甚低：“对GPT-2的解释尚且如此，那如何了解GPT-3.5和GPT-4内部结构呢？但这才是许多人现在更关注的答案。”</p><p>虽然电脑是模仿人脑的原理而发明，但人脑的结构其实并不高效，比如没有存储设备，神经元的通讯也是通过激素或荷尔蒙等化学方式来进行，相当的别扭。<strong>这种“落后”的“元器件”竟然能给人类如此高的智慧，说明人脑的强大主要在于架构。</strong></p><p>当前探索智能的本质也是脑科学研究的中心任务之一，是了解人类自身、解密思维与智能成因的科学探索需要。脑科学与AI息息相关，既可以提升我们人类对自身奥秘的理解，也可以改善对脑部疾病的认知水平，同时相关科研成果也可以为发展类脑计算，突破传统电脑架构的束缚提供依据。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c65da8bf3eaa4365b593b3df72738346@000000_oswg165516oswg537oswg359_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但在当下，类脑计算还具有着巨大的空间，等待着科研力量填补。<strong>当下千亿量级参数的大模型已经屡见不鲜了，如果把参数看成神经的突触，大模型对应人脑的神经元，只有1亿个。</strong>而1亿个神经元与人脑千亿级别的神经元，中间的差距有千倍之多，而这一差距或许也是走向AGI人类科学必须跨越的鸿沟。</p><p>OpenAI和Anthropic做的这些研究，也在无形中给我们的科学技术进步展示了一种可能性：当未来对的AI变得越发强大，甚至有一天真的超越人类，它也能在后续更多的前沿科技上为人类提供帮助；而对智能的研究，在生物大脑之外也有了AI系统作为新的研究对象，这也为破解智能之谜带来了新的希望。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA5NTI1MDEyNA==&amp;mid=2652710154&amp;idx=1&amp;sn=13bd0234120536978b1a808e30d3dfb0&amp;chksm=8babb6a9bcdc3fbfdbfc7d8b3395582dc859f74385886ced49319a2a558d35e056f5935b8c64&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“亿欧网”（ID：i-yiou）</a>，作者：番摊123，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470916626323584</id>
            <title>Android 14 正式版发布，聊聊我喜欢它的 14 个理由</title>
            <link>https://www.36kr.com/p/2470916626323584</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470916626323584</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 07:41:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Android 14, 特性, Pixel 用户, Ultra HDR 图像格式
<br>
<br>
总结: Android 14 是一款新的操作系统版本，它带来了许多新特性。其中包括针对Pixel用户的AI壁纸生成和锁屏时钟样式等特性，以及对10bit HDR图像和Ultra HDR图像格式的支持。Ultra HDR图像格式能够展示更鲜艳的色彩、更高的动态范围和更强烈的对比度。此外，Android 14还引入了更规范的照片选择器，让用户可以方便地选择可见的媒体文件。 </div>
                        <hr>
                    
                    <p>和去年 8 月中旬发布的 Android 13 正式版不同，今年的 Android 14 正式版延后到了 10 月 4 日——也就是Pixel 8 系列发布 的同一天。原因我们似乎也能从 Google 宣传新特性中略窥一二：</p><p>除了明确表示会率先向特定 Pixel 机型推送的 AI 壁纸生成，因为 OEM 厂商一般都会在系统界面、配色方案上搞「二创」，所以 Android 14 官方页面所宣传的锁屏时钟样式、黑白风格主题等特性，最后也极有可能只有 Pixel 用户才能体验到。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_77b403366e884ac3aab6fd63821229b5@000000_oswg64505oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Android 14 的 14 个新特性 | 图：Google</p><p>那 Android 14 能为非 Pixel 机型的用户带来什么？参考 Google 的官方 介绍视频 ，我们也从相关文档中整理了一份 Android 14 值得更新的 14 项新特性供你参考。</p><h2><strong>01 更强大的照片格式</strong></h2><blockquote><p>超强 HDR 图像格式！（来自谷歌开发者官方微信公众号的翻译）</p></blockquote><p>从 MIUI 相册的 HDR 显示到 OPPO 新近机型的 ProXDR，Android 在 HDR 照片显示这件事情上今年又上演了一次「厂商倒逼 Google」的戏码。在 Android 14 中，Google 终于为我们带来了对 10bit HDR 图像的原生支持，并且还一并推出了新的 Ultra HDR 图像格式。</p><p>根据 Google 的介绍，Ultra HDR 图像格式在保存时会保留来自传感器的更多信息，并在查看时展示更鲜艳的色彩、更高的动态范围和更强烈的对比度，简单来说就是小部分国产厂商近几年在卷的那种 HDR 照片显示效果。</p><p>值得一提的是 Ultra HDR 格式可以完全向后兼容 JPEG 图像格式，它不仅能在 Google 相册等支持 HDR UI 的应用中被正确解码，在未适配 HDR 或不支持 HDR 显示的设备上，Ultra HDR 格式图像也能回落至标准动态范围（SDR）来正常显示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0d819037cb654f16bee4c0267bc866eb@000000_oswg453887oswg408oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">演示效果，仅供参考 | 图：Google</p><p>针对 Pixel 系列机型的 HDR 照片支持目前也是蓄势待发，刚发布不久的Pixel 8 系列 的相机应用已经内置了拍摄选项，开启该选项后所拍摄的 Ultra HDR 格式照片能够在 Google 相册中以 HDR 效果进行查看，同时 Lightroom 移动版也在最新的 9.0 版本针对 Pixel 7 系列和 Android 14 带来了 HDR 编辑与导出支持。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c8a4ffcede7c4bee9a93e5906d8e0a89@000000_oswg372019oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Pixel 新版相机应用中的 Ultra HDR 拍摄选项以及相册中的 Ultra HDR 标识</p><p>总体而言 HDR 照片对大家来说依然是一个陌生的新生态，比如尽管我很想放上几张对比图给大家看看效果——咱们的编辑器和网页都不允许。</p><p>另外 Android 14 也为 Camera2 和 CameraX 等 相机扩展组件 带来了更新，允许第三方应用支持更长的照片处理时间、调用系统相机的算法密集型拍照功能（如暗光拍摄能力）等，这类面向开发者（并且不会有多少国内应用适配）的细节这里就不展开了。</p><h2><strong>02 更规范的照片选取</strong></h2><blockquote><p>好吧，至少从某种程度上来说是这样的。</p></blockquote><p>从某种程度上来说，Google 正在强制推行自 Android 13 引入的照片选择器。对用户而言这当然是需要重点关注的头等好事。</p><p>简单来说，和此前需要开发者适配、需要 Google Play 服务更新支持的做法不同，<strong>Android 14 直接引入了一个让用户为 app 选择可见媒体文件的「中间层」，这个「中间层」用的正是照片选择器同样的设计</strong>：一个从底部弹出的照片和视频选择面板，内含支持多选和长按预览的「照片」（其实也可以选择视频）和可以按照路径位置查找媒体文件的「影集」两个页面。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_474deeb2811746118c0f0f6c753462b4@000000_oswg920481oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">通过照片选择器选择应用可访问的照片和视频</p><p>在 Android 13 引入照片选择器这一设计后，Android 14 又新增了类似 iOS 那样的媒体文件范围选取机制，这套机制在 Android 14 中对应的权限是READ_MEDIA_VISUAL_USER_SELECTED 。</p><p><strong>这个权限和以往大部分新系统、新权限最大的不同点，在于它是由系统自动附加的。</strong>只要应用请求READ_MEDIA_IMAGES 、 READ_MEDIA_VIDEO或ACCESS_MEDIA_LOCATION三类权限的任意一种，无论应用是否面向 Android 14 进行适配， READ_MEDIA_VISUAL_USER_SELECTED这一权限都会被自动添加到应用的声明清单中。</p><p>从我们的实际体验来看，市面上主流的、已经适配了 Android 13 媒体权限（即将音乐和音频、照片和视频两类权限分开授予）的应用，在 Android 14 中访问照片和视频权限时的确都会先调起 Google 的照片选择器——先让用户选择应用可以访问的内容，然后应用内置的媒体选择器才能将已授权的内容展示出来。并且这种授予也是临时的，一旦应用被放进后台或进程被用户结束，下次启动时相关的授予流程就还会再出现一次。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_17d1cf73ed094e91b946b34166c16fc7@000000_oswg76314oswg1080oswg583_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Android 14 的照片范围选择权限处理流程</p><p>如此一来这套新权限的局限性（虽然是暂时的）也很明显了：依然有少部分应用获得了调用照片选择器的豁免权，最具代表性的比如目标 API 级别为 32、依然面向 Android 12 进行适配的「小而美」。</p><p>我知道你想说什么但先别急，我们在上面也提到「强制」和「暂时」，是因为根据 Google Play 商店的 目标 API 级别要求 ，2023 年 8 月 31 日起所有提交至商店的应用更新都必须面向 Android 13 进行适配，虽然 Google 允许开发者申请延期至 11 月 1 日，但微信在 Play 商店的最后一次更新恰好是 8 月 24 日……张小龙会如何应对我们拭目以待。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_cc1814443d494a2b8358bc2d915f8a3e@000000_oswg31038oswg712oswg206_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Google Play 商店的目标 API 级别要求</p><p>当然了，Google 也还是希望开发者都用标准化的照片管理器实现，毕竟视觉风格上与系统更搭。适配过的应用即便依然选择使用自己的媒体选择器实现方式，它们在 Android 14 中也能借助界面和操作提示引导用户重新选取更多媒体文件。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_bef2649dd766403eb05edc64d925522b@000000_oswg141564oswg1080oswg743_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">已适配 Android 14 部分的应用可引导用户选择更多媒体文件</p><h2><strong>03 更省电的缓存机制</strong></h2><blockquote><p>每次更新之后他们都这么说，这次是不是真的？</p></blockquote><p>尽管我一直坚持是因为天气转凉，升级到 Android 14 之后，的确有不少手持 Google Tensor 处理器设备的朋友向我表示手机更凉爽、续航也更长了（除了我的同事， 外媒 也这么说）。</p><p>那暂且将功劳归于 Android 14 开始生效的缓存应用冻结机制吧。</p><p>缓存，即将前台运行的应用放进内存，和直接杀掉进程不同，缓存的应用调用起来更快、重新开启所需要消耗的资源相比冷启动也更少。所以将暂时不用的应用放进缓存是一种非常合理的做法，Google 将「暂停执行已缓存的应用」放进 Android 系统的「开发者选项」后，这个功能也一直以「Android 的墓碑后台机制」的身份备受玩机群体的推崇。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_2de5ee52028d43a6893d86b6fccf597a@000000_oswg450875oswg1080oswg2340_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">暂停执行已缓存的应用设置</p><p>根据 Google 公开的数据，被暂停执行的已缓存应用在 Android 14 测试版中消耗的 CPU 周期要比 Android 13 正式版少 50%，因此在 Android 14 中这一机制得到「转正」，以往缓存的应用可以基本不受限制地运行，但在 Android 14 上这些应用在进入缓存后很短的时间内就会被系统冻结，直接杜绝其 CPU 资源调用。</p><p>不知道是不是已经知道了此前「暂停执行已缓存应用」机制的 问题 ，这次 Google 也特别提到冻结仅适用于常规的 Android 应用生命周期 API（如前台服务、JobScheduler 或 WorkManager）之外的后台工作。</p><p>另外值得一提的是，随着缓存机制的优化，Android 14 也打破了平台缓存应用数量的长期限制，减少了冷启动应用的情况，而且设备 RAM 越大改善就越明显：在 8GB 内存的设备上冷启动应用速度提高了 20%，在 12GB 内存的设备上则提高了 30%。</p><h2><strong>04 更无感的登录体验</strong></h2><p>和刚发布不久的 Windows 11 Moment 4 更新一样，Android 14 也是首个系统级支持通行密钥（Passkey）的版本。Android 14 在平台 API 中引入了凭据管理器（Credential Manager），并且通过 Jetpack 开发库和 Google Play 服务，让该功能可以一直向下支持到 Android 4.4（API 级别 19）的老设备。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_e483bae76a274a52ae7eca3c0435d7be@000000_oswg163868oswg1080oswg569_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">使用通行密钥登录的流程演示 | 图：Google</p><p>凭据管理器用于简化用户认证流程，并且主要通过通行密钥（Passkey）来提高安全性——少数派的读者对通行密钥应该不陌生了。</p><p>目前我们在 Android 14 的密码和帐号设置中可以看到通行密钥认证服务的相关设置，换句话说除了可以将手机上的生物识别信息作为通行密钥认证方式，Android 14 也支持添加第三方应用作为通行密钥管理应用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_8a64734efcb8406298c18335757ea87e@000000_oswg170668oswg1080oswg1306_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Android 14 中的通行密钥管理服务设置</p><p>不过虽然 1Password 早前 宣布过 对 Android 14 通行密钥管理的功能支持，但在最新的 Beta 测试版本中我们还无法成功调用 1Password 来创建通行密钥。</p><h2><strong>05 更好看的返回动画</strong></h2><blockquote><p>但「预见式返回动画」竟然还在「开发者选项」里。</p></blockquote><p>我们在《 都是边缘划动，Android 与 iOS 的返回手势到底有什么区别？ 》这篇会员文章中提到过 Google 提出的一个、有关 Android 系统返回的问题，即我们很多时候都不太确定返回操作会将自己带向何方。</p><p>为此 Android 13 提出了「预见式返回动画」这个解决方案，即通过一个类似「半确定」状态的动画预览，告知我们接下来会被带到哪里去——如果目的地非你所愿，那可能你就得取消返回操作、在当前界面中找找其他导航按键了（比如「向上」）。</p><p>两年过去了，这个特性准备得怎么样了？<strong>坏消息是它依然放在「开发者选项」里，好消息是它的确更完善了。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6eab852e77d54b2fab9c7d6943e7e0f0@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">预见式返回动画效果</p><p>除了给返回箭头添加一个圆圆的、形状可变、颜色为 Material You 动态取色得背景之外，Android 14 正式版当中默认的预见式返回动画效果更自然、表现也更加稳定。</p><p>同时 Google 也在 Android 14 中支持了自定义预见式返回手势动画的能力，允许开发者为应用中不同组件和不同界面的跳转加上更加赏心悦目的动画，官方 Material Design 组件库中也提供的底部菜单、侧栏菜单和搜索三种组件的返回动画供开发者参考、适配。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_aed6ff21fd0c431fa92a1acb471dd943@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">底部菜单（Bottom Sheet）的预见式返回动画</p><h2><strong>06 更好的多语言支持</strong></h2><blockquote><p>简体中文除外。</p></blockquote><p>和 MIUI 这类完全不管多语言支持的做法不同，Google 在原生 Android 的多语言支持上走的是另一个极端：完全不管除了简体中文以外的多语言支持——比起在 AOSP 提交中否决支持文字体可变字重支持的冷酷，今年 Android 14 引入的多语言支持可谓相当温暖：</p><p>比如针对特定语言中的语法性别现象的词形变化 API，用 Google 所举的例子来说，比如当我们的应用界面中需要显示「你已订阅……」这句提示语时，中文和英文状态下都是无需注意语法性别的，但如果是法语，这句话则可能对应三种情况：</p><ul><li>Vous êtes abonné à...</li><li>Vous êtes abonnée à...</li><li>Abonnement à...activé</li></ul><p>词形变化 API 就是用来简化并解决这类问题的。根据 Google 的描述，这个 API 能够帮助开发者根据使用者的性别展示对应的语法性别文本，降低这类需求带来的开发成本，避免应用在采用特定语言显示时因为忽略语法性别而冒犯用户。</p><p>再比如区域偏好设置。我们或多或少都在天气应用、测量工具、量化 app 中接触过与地区偏好相关的设定，从温度、距离、长度采用哪种单位、日期显示采用年月日还是日月年到每周的第一天究竟是周日还是周一……以往这类设置往往都散落在不同应用的设置当中，Android 14 则在「系统 &gt; 语言和输入法」中新增了一项面为「区域偏好设置」的独立页面，一方面方便用户提前选好自己想要的温度单位、每周起始日以及数字呈现方式，另一方面也配套为开发者提供了对应 API 和 Intent 来读取这些偏好设置，然后直接套用到应用当中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_dd792d1b94754c239490d13326af9d98@000000_oswg245997oswg1080oswg2340_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Android 14 中的地区偏好设置</p><p>根据 Google 给出的信息，这些偏好设置也能够在设备数据备份、还原的过程中在不同设备间迁移。</p><p>最后，针对 Android 13 引入的应用语言偏好设定，Android 14 也向输入法开放了应用语言的获取接口，让输入法能够根据不同应用的不同语言设定，自动弹出对应的输入键盘。</p><h2><strong>07 更聪明的分享菜单</strong></h2><blockquote><p>造轮子造出的新思路。</p></blockquote><p>当你在 Chrome 浏览器中点击「分享」按钮时，首先弹出的菜单是 Chrome 自行定制的分享菜单，这个分享菜单下方提供了包括屏幕截图、网页长截图、URL 链接复制等功能在内的六个分享操作——和 Android 系统的原生分享菜单（上图中点击「展开」后即是）不同，Chrome 在定制分享菜单中所提供的这些操作选项与我们的网页分享行为关联更加密切，或者说往往也是我们在浏览网页时主要考虑的一些操作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a3ce9a2838204136b353c7d2b44eb1a8@000000_oswg464760oswg1080oswg2340_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Chrome 浏览器的定制分享菜单</p><p>作为规则制定者的 Google 在自家 Chrome、Google 相册中都采用「自己造轮子」的方式设计一个独立的分享菜单，正好也能说明 Android 系统原生分享菜单存在一个大问题：太公平了。无论分享的内容是什么，Android 系统都会在长长的分享菜单中将提供分享操作的应用按照名称排序，找起来不方便、有的分享操作和实际分享内容的关联性也比较差。</p><p>因此在 Android 14 中，Google 基于 Chrome 和 Google 相册的分享菜单设计思路，向应用开放了分享菜单自定义操作定制功能，允许开发者针对特定文件类型声明分享自定义操作，当用户呼出分享菜单时，这些操作选项会出现在分享列表顶部和分享内容预览之间，方便用户快速调用可能需要的应用执行下一步动作；同时 Google 也希望通过调整 Direct Share 目标排序的方式来优化 Android 分享菜单的可用性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_8a685e4799e24fe69b883c5333a6c03e@000000_oswg647258oswg1080oswg2341_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">自定义分享操作按钮示意图</p><p>除了上述改动，Google 在 Android 14 中还将分享菜单做成了可独立更新的Project Mainline 模块 方便功能迭代，并且允许用户通过分享预览即时调整、编辑分享内容，Mishaal Rahman 在 技术解析博文 中做了详细说明。</p><h2><strong>08 更友好的缩放体验</strong></h2><blockquote><p>可惜来得有点晚，国内适老化的字体改造已经乱七八糟了。</p></blockquote><p>在 Android 14 中，Google 还带来了最高 200% 的非线性字体缩放功能。和此前版本的机械缩放不同，采用非线性放大曲线的好处在于，界面中原本已经足够大的文本不会随着全局设定而同步缩放，文本之间的大小关系、层级结构都能得到有效保留，较大的字体更不会因为缩放而出现文本截断、难以阅读等问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_9f5a19c8da114597a1daf397648c2e86@000000_oswg233555oswg1069oswg731_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>正常大小、线性 200% 缩放与非线性 200% 缩放，非线性缩放能在保证所有文本具备可读性的同时避免原本就已经很大的字体被机械放大</p></blockquote><p>在后续的版本中，Google 还在系统的快速设置面板中添加了一个专门用于字体缩放的开关，有这方面需求的朋友可以借助这个开关随时调整阅读体验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_bba1b2b1305c4842a46c3d24859ba645@000000_oswg194259oswg1080oswg2340_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">正式版新增的字体大小 快速设置开关</p><h2><strong>09 更透明的权限调用</strong></h2><blockquote><p>收紧关键权限、方便用户管理是永恒的主题。</p></blockquote><p>很多人不知道的是，很多依赖定时执行任务或发出提醒的应用（比如 Tasker 也用）都会用到的闹钟——你看不见也听不到的那种。根据应用内设置的不同，这些闹钟会在既定的时间拉起应用，帮助应用准时完善用户设置好的任务。</p><p>不过问题在于，通过精确闹钟唤醒应用是一种资源消耗极强、Google 也非常不推荐的定时任务规划手段（根据 Google 的开发者文档它可以随时将设备从 Doze 状态中唤醒）。因此正如我们去年在 Android 13 正式版的 介绍文章 中所推测的那样，此前引入的&nbsp;闹钟和提醒&nbsp;权限不再默认授予。这项限制适用于新安装的、面向 Android 13 及以上系统适配的应用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_15f583c3d67d4c8cbe2589544b4f2ced@000000_oswg205861oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">闹钟和提醒权限授予提示与授予界面</p><p>与之类似的，Android 14 开始 Google 也会通过 Play 商店策略对非通话、闹钟类型的应用移除针对USE_FULL_SCREEN_INTENT这一权限的默认授权——在此前的版本中，应用可以借助这一权限在锁屏状态下弹出全屏通知，而 2023 年年底这一政策生效之后，开发者就需要通过适配专门的 新 API来向用户发起授权申请了。</p><p>Google 也在提高用户敏感数据使用情况在 Android 14 中的可见性。除了将部分数据安全相关的信息直接放进对应的权限授予弹窗外，Android 14 还会在特定情况下向用户发出通知提醒，包括：</p><blockquote><p>应用开始向第三方共享位置信息</p><p>应用开始将位置信息用于广告目的</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d339a867a85547e7a207895535f845cc@000000_oswg296045oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">位置信息授权时提供的数据安全提示与 Play 商店中的数据安全提示</p><p>尽管目前大部分与敏感信息使用透明化相关的改动都围绕位置信息，此前 Google 在 I/O 大会上也透露过后续会将范围向其他个人信息扩展的计划。</p><h2><strong>10 更尴尬的截图提示</strong></h2><blockquote><p>你截屏了！系统知道、对方可能也会知道。</p></blockquote><p>当你在即时消息里向朋友诉苦、当老板在公司群里激情发言，应用里突然弹出通知提示说「对方刚刚进行了截屏操作」……类似的功能在 Android 14 中接下来就有 API 支持了。</p><p>借助DETECT_SCREEN_CAPTURE这一 API，应用在 Android 14 中可以获知与按键操作相关的截图事件（一般是电源键+音量减）了——然后应用开发者可以向用户发出提示，比如付款应用提醒用户不要随便截图分享收款码，或者将这个事件传递给其他人（官方文档中似乎并没有限制开发者这么操作），告诉对方你刚刚进行了截图。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_357330f50e7f4899aaf1eec622648ca1@000000_oswg44253oswg340oswg692_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Google 给出的截图操作提示使用场景</p><p>然后呢？然后就看谁比较尴尬吧。不过大家也不用担心，一方面这个 API 只会检测基于按键操作的截图事件，ADB、录屏应用等应该不受影响——另一方面这种 Android 新版本特性，至少你每天都要用的微信是不会跟进的。</p><h2><strong>11 更灵活的常驻通知</strong></h2><blockquote><p>那么「常驻」的意义是……？</p></blockquote><p>一个相比其他改动而言不怎么起眼，但真正用的时候能让人楞上几秒的小改动：在 Android 14 中，常驻通知可以被用户手动划走消除了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d60911ae838948589762bb8179efdd08@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">新的常驻通知清除机制</p><p>Google 也为常驻通知消除机制设定了一套比较基础的规则：</p><p>当我们点击通知面板中的「清除全部」按钮时，常驻通知不受影响</p><p>当手机屏幕锁定时，常驻通知不可被消除</p><p>CallStyle类别（通常与通话相关）的常驻通知不可被消除</p><p>使用通知面板中的「清除全部」选项时，常驻通知不会被消除</p><h2><strong>12 更现代的无损音频</strong></h2><blockquote><p>给 USB-C 有线耳机用户一点爱。</p></blockquote><p>干掉 3.5mm 接口之后，近几年真无线蓝牙耳机井喷式发展，各种传输协议也是日新月异。好在 Android 14 这次也关照到了那些坚持使用 USB-C 接口有线听歌的音乐发烧友。</p><p>Android 14 向开发者开放了 USB 设备首选混音器属性的能力，允许开发者注册侦听器以获取首选混音器属性的更改，并使用新的AudioMixerAttributes类配置混音器属性。AudioMixerAttributes&nbsp;类支持在无混音、音量调整或后处理效果的前提下直接传输音频，进而带来无损的有线听歌体验。</p><h2><strong>13 更通用的健康数据</strong></h2><blockquote><p>继健康数据与平台解绑之后，Health Connect 自身进一步与 Google Play 商店解绑。好事。</p></blockquote><p>2022 年 5 月，今年 5 月，Google 在 Android 开发者官方博客中隆重推出了一个名为 Health Connect 的新平台并推出了相应的 API。Health Connect 官方网站用非常显眼的大标题和副标题简洁地描述了其核心功能与优势：简化健康类应用之间的连接。</p><p>散落在不同应用、服务和可穿戴设备中的健康数据，在 Android 平台上有了一个通用的、可实现数据迁移的中间平台。而从 Android 14 开始，Health Connect 开始从此前需要从 Play 商店下载安装的独立应用升级为系统能力，它将以系统组件的身份通过 Google Play 系统更新接收更新，对不能直接访问 Play 商店但可以借助 OEM 厂商定期更新系统的国内用户而言也是好事一件。</p><p>另外，Health Connect 也跟随本次更新新增了包括运动路线在内的更多数据类型。</p><h2><strong>14 更开放的商店策略</strong></h2><blockquote><p>感谢欧盟。</p></blockquote><p>8 月 25 日，欧盟《数字服务法案》正式生效。作为受该法案 重点关照 的大公司之一，Google 也在第三方应用商店这个反垄断诉讼的「热门话题」上做了不少工作。</p><p>在 Android 14 中，Google 引入了多个PackageInstallerAPI 来保证第三方应用商店的使用体验：</p><p>requestUserPreapproval()允许第三方应用商店提前请求用户的安装批准，并且在用户授权后可以实现后台下载和安装体验</p><p>setRequestUpdateOwnership()允许第三方应用商店通过所有权声明指定应用自动更新的安装来源，非指定来源的应用升级需要用户手动批准</p><p>InstallConstraintsAPI 允许第三方应用商店选择用户并未与 app 交互的时段更新应用</p><p>setDontKillApp()允许第三方应用商店针对支持拆分式安装包（APKs）的应用采用无缝更新，比如仅更新用户当前未在使用的组件</p><p>最后，从 Android 14 开始系统软件包安装程序也允许开发者指定要包含在应用中的 Google Play 应用商店页面的应用元数据，例如数据安全信息等。这同时也能方便第三方应用商店获取与应用相关的元数据信息</p><p>以上便是 Android 14 中值得你关注的 14 项新特性，篇幅有限，还有更多细节以及 Pixel 专属特性本文未能一一覆盖，如果有你感兴趣的欢迎在评论区补充。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzU4Mjg3MDAyMQ==&amp;mid=2247562228&amp;idx=1&amp;sn=ab60b9b8f643ac0d50288f8840eba62d&amp;chksm=fdb2069ecac58f882504fe4cb9fcf071fc415eb573d014e2ea97aca8cf621b6646f1b61f3f41&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“少数派”（ID：sspaime）</a>，作者：克莱德，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2471001171794057</id>
            <title>IR们手拉手去敲银行和信托的大门了</title>
            <link>https://www.36kr.com/p/2471001171794057</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2471001171794057</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 07:41:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 投资机构, 险资, 银行, 信托公司
<br>
<br>
总结: 2023年一级市场投资困难，投资机构难以募资和退出。险资和银行是主要的金融机构LP，但险资对基金管理人有高要求，小GP难以满足。信托公司开始积极参与私募股权基金，成为有力的金主。 </div>
                        <hr>
                    
                    <p>2023年已经过去四分之三，一级市场上大多数投资机构，想投的投不进，想退的退不出。没有业绩、没有项目，更惶恐募资。怎一个惨字了的。</p><p>今年以来，险资、银行等金融机构好消息频传，各大机构的IR们的神经再次被激活，又开始蠢蠢欲动。</p><p><strong>“连夜联系了几家保险和银行相关负责人。但是险资选择GP，基本已经默认只选行业前20名大型GP，毕竟投资能力有保障。或者更倾向投某些细分领域精耕细作的专业型基金。”某VC管理合伙人景阳告诉融中，“小GP基本排不上队。”</strong></p><p>现在，真正市场化母基金太少，尤其这两年，几乎只剩下政府和大国企的钱。保险资金具有期限长、金额大、持续稳定等特性，可以说是一直是VC/PE眼中的大金主，GP们想要叩开保险大门的决心从来没有动摇过。因此政策支持下，保险、银行这类金融机构LP更加让IR们趋之若鹜。</p><p>但其实，相较于险资和银行，还有一个变化不容忽视，信托公司们也在今年暗自发力，成为VC/PE背后又一有力金主。</p><h2><strong>01 VC难题犹在，险资的大门仍难叩响</strong></h2><p>“都知道保险机构的钱好，但是能募到的难度很大，也是事实。”</p><p>一个月前，国家金融监督管理总局发布《关于优化保险公司偿付能力监管标准的通知》，其中一项核心政策是引导保险公司支持科技创新。消息一出，被认为是打开了险资入市的空间。</p><p><strong>投资人魏颢告诉记者，新的政策导向下险企可以更加积极地参与到科技创新企业的投资，这无疑是对一级市场注入了新的活力。</strong>不过，本以为圈内会迎来新一波高潮。毕竟在所有金融机构中，险资对股权投资的出资活跃度最高。但<strong>大多数投资人还是认为，募资囧境其实并不会有特别大改观。</strong></p><p>“险资的钱一直以稳定且长期的特性受到投资人喜欢，<strong>但险资标准真的太高，一般中腰部机构还是很难募到。”景阳对记者说起，</strong>“险资作LP，在基金管理人的规模、注册资本、退出项目数量等方面都有一定要求，底限是要求最近一年度净基金管理规模在30亿以上，注册资本1亿以上，超过2家企业IPO退出业绩。对中小机构要求还是蛮高的。”</p><p>值得注意的是，如果险资十分认可基金管理人的能力，但由于监管最低要求不满足，其实可以通过嵌套一层符合监管要求的基金的FOF结构类解决，但这同时要求基金管理人与险资的关系非常好，险资才可能愿意做结构嵌套。</p><p>这些年，保险配置私募股权投资却是有些积极变化的，但往往还是只会投大的机构和中后期的PE，VC很难达到险资要求。所以这些年对于GP们而言，LP结构其实并没有实现更加多元化，反而和以前相比没那么多元，甚至更差了。<strong>“LP多元化可以说就是个伪命题。”景阳说到。</strong></p><p>市场上较为稳定的长钱资金，主流金融机构类LP主要包含银行、券商、保险、信托和资管公司五大类。<strong>受资管新规等政策影响，近几年出资频率不高，倾向业绩好、回报高、资产配置合理的精品机构。</strong></p><p>根据烯牛数据，2023年上半年，募资市场43.80%的资金具有政府背景，2022年这一比例为38.72%，相对的，市场化母基金占比，从2022年的11.31%降至3.78%，可见投资放缓显著。<strong>而金融机构中，保险与券商占比在进一步减少。</strong></p><p>一直以来，信托都很少涉及股权投资，更偏好债权投资。如果受托资产规模缩减，为了防范系统性风险，信托公司在固有资产投资股权这方面一定会更谨慎。</p><p>有意思的是，<strong>今年以来，信托公司似乎开始积极布局LP参与私募股权基金包括长安国际信托、西藏信托、建元信托、建信信托、国联信托等30多家信托公司频繁出手，出资中国私募股权市场超50支基金，</strong>其中披露金额170多亿，获资GP包括美团龙珠、盛世投资、招银国际、尚颀资本、君信资本、钟鼎资本、磐霖资本、沣东产投、西安投控等一批明星机构。</p><p>“信托做LP，虽然比传统投资方式灵活性更高，但风险也相对更大，股权问题就是个关键点。”景阳对记者解释，“信托做LP投资过程中，需对企业实际控制人进行了解，并对相关公司进行调研。另外，要与实际控制人签署股东协议，明确各相关方责任，约束权力、维持利益关系是不可忽视的。落实投资项目过程中，也还需对股东之间作出计划、协调，或约定由专业第三方机构进行协调。”</p><p>另外，值得注意的是，信托在一级市场布局的加深，配置方式也正变得丰富和多元，除了参与设立母基金还在增加S基金配置等逐渐兴起。</p><h2><strong>02 2023，谁家LP兜里最有钱？</strong></h2><p><strong>“现在市场上谁最有钱？国资企业、政府引导基金和险资，可是面对他们总是能让你知道什么叫‘有些事，不是努力就能实现的。”</strong>聊起最近的募资，投资人金石磊告诉记者，“有些VC，业绩也拿得出手，身边也不乏跟着赚到钱的高净值个人或民企老板，但是想要进一步优化LP结构，引入大型机构投资者，就会时候发现募资是真的难。”</p><p><strong>从当前市场看，无论保险资金还是信托，投资偏好上都会更青睐于历史业绩优秀、实力较雄厚的综合性基金，或在细分垂直领域具有优势的机构。</strong>而自2022年以来，险资出手的另一明显变化是——多家险资共同出资一只基金,也从侧面印证了只有真正有实力的GP才能拿到保险的钱。<strong>像今年9月，11家寿险公司联手出资九州启航基金，规模达到339亿元。</strong></p><p><strong>今年以来，险资投资基金数量前三的分别是中宏人寿保险、中银三星人寿、和谐健康保险。获得险资青睐的创投机构包括红杉中国、纪源资本、普洛斯、前海母基金、高瓴资本、达晨财智、国中创投、信达风、CPE源峰、国科投资、远洋资本、钟鼎资本、同创伟业、德同资本、国投创业、国科嘉和、源码资本、云峰基金等。其中，纪源资本、普洛斯在今年获得5家险资LP青睐。</strong></p><p>除了险资和信托公司，越来越多理财子公司，也在纷纷开始作为LP积极布局股权投资。前不久中共中央办公厅、国务院办公厅印发《建设高标准市场体系行动方案》，鼓励银行及银行理财子公司从事私募股权行业，直接或间接进行私募股权投资，促进私募股权行业良性发展。</p><p>据不完全统计，今年以来，<strong>包括信银理财、苏银理财、杭银理财、北银理财以及工银理财等10多家理财子公司</strong>均在股权投资方面均有出资动作，基金额超过170亿。<strong>而在去年，金融机构LP中险资出资中排名第一，次数占比超过30%，而银行及理财子活跃度却是最低，出资占比不足10%。</strong></p><p>某VC投资人接受媒体采访时提到，“理财子公司做LP为实体经济创新和发展提供资金支持，与政策导向相契合，是大势所趋。另外，理财子公司背靠母行，客户资源较为丰富，资金长期且稳定，做LP不仅能够拓宽投资边界构建多元化投资渠道，还可以弥补理财子公司在权益投资方面的不足。<strong>接下来两年，一级市场将有更多理财公司，与创业投资基金、政府出资产业投资基金合作的势头。”</strong></p><p>目前，银行理财子公司参与股权投资方式，既可以是直接投资也可以是LP模式。像今年5月，兴银理财作为LP成立了福建晋江禹兴福股权投资合伙企业（有限合伙），西藏禹泽担任普通合伙人及私募管理人。8月，兴银理财再度出资希言投资，成立新基金嘉兴自明榕兴股权投资合伙企业。这也是兴银理财自成立以来出资的第6只基金。</p><p><strong>投资人海蓝尔告诉记者，“银行系LP多以遴选和投资产业子基金为投资方向。对GP管理人的筛选也是会综合管理规模、股权结构、投资案例来选。”</strong></p><p>从市场投资偏好看，城商行理财子公司更倾向支持本地基金，如杭银理财、徽银理财等，中小银行系且区域性银行则倾向出资区域内基金，同时能带动基金托管业务，而股份制银行系出资最谨慎，出资额也普遍不高，但是最喜欢试水S基金。</p><p>不过，当前银行理财客户整体风险偏好较低，对应该类产品定位的银行理财客户较少。此外，理财子公司作为LP参与股权投资处于起步阶段，市场尚未成熟，对机构的专业投研能力要求较高。</p><p>此外，近年来，还有越来越多私募股权投资的个人LP通过各种渠道和方式自行开展投资，有些超高净值人群，手里可支配资金大几千万甚至过亿的，就会自己设立基金，或者参股别人的基金，做个小的合伙人或者固定出资人，资金体量再大一点的，就直接成立家族办公室。</p><p><strong>“过去几年，尤其在双创时期，几乎100多万就可以参与一只基金，但现在一些优秀的GP都要求个人LP起码500W甚至1000W起投。”海蓝尔讲述这几年募资市场的变化，“大多数GP提高个人LP出资门槛，也是为了提高投资效率考量。如果一只基金LP太多，沟通成本增加，决策效率就会很低。而且，</strong>很多高净值个人LP出资能力其实有限，只想把规模做大。腰部机构仅靠高净值个人LP很难做出规模。”</p><p><strong>不过，随着这两年很多基金的退出期到来，大部分基金投资回报不达预期，甚至本金都不能收回，加上国际经济环境因素影响，一批个人LP的出资意愿在减弱，仅少量继续陪跑。</strong></p><h2><strong>03 GP们戴着手铐脚镣募和投</strong></h2><p>“如今市场上，钱已经不能用‘少’来形容，几乎是没有。”</p><p>昨天和一家机构合伙人聊天，我问他是如何募资的。<strong>他说：“募资的关键不是你有多知名，带的团队有多好，基金收益率有多高，而是LP愿不愿意信任你。”</strong></p><p>过去一段时间，受全面注册制影响，金融机构出资有出现一阵观望态势，活跃度有所降低。如今，险资、银行等金融机构相关政策不断调整过后，募资环境真的改善了吗？<strong>金石磊告诉记者，国家鼓励力度不减，但钱在口袋里更深了，需要回答LP的问题更多了。</strong></p><p>很多小型GP都想要拿到险资的投资。可是，很多保险公司对大型GP的基金投资周期可能长达8年，对小型GP的投资周期却会明显缩短，可能只有5年。</p><p>很多地方引导基金和国资都有明确的招商需求，最关心的永远都是给当地引进什么项目，每年能开多少票、贡献多少税收，能不能带动就业甚至搞出产业小集群等问题。政府出的每一笔钱，未来可能都会量化在招商数据里，项目的成长性、估值、甚至未来的业绩回报都不重要。</p><p>“甚至于，当LP决定要投某只基金，整个投资过程才过半，后续还有LPA和S/L的谈判和磋商，出资打款甚至个别还涉及到异地注册等环节。募资过程中，GP还要拿捏各类LP不同的奇怪诉求，对于协议细节的把控，对于合伙人、律师、LP法务等的多方协调都至关重要。每一个<strong>数据的目标和细微转变，落在基金的出资上都是敏感的问题。”金石磊对记者说到。</strong></p><p>这几年市场不断洗牌，LP在产业链中的话语权不断增强，募资钱从哪来成为GP的重要议题。对于募资，非常考量GP的功力，特别是现阶段。</p><p><strong>达晨邵红霞说过，LP的多元化，更是对GP各方面能力的考量。每次募资，都是对我们自身投资策略、管理体系的一次检验，倒逼我们在业务能力和产业赋能上不断提升和优化。</strong></p><p>募资难,恰恰是因为GP的专业同质化严重。“GP的专业性体现在募投管退全流程，但现在很多LP只看GP投资业绩，而GP也只关注LP喜好。”</p><p>从当前市场现状来看，至少95%的机构募资都存在问题，5%的头部机构又形成了虹吸效应。如果真正做到头部5%的机构，不管面对什么样的LP和什么诉求，最终还是能够吸引他们。可是，对于绝大多数GP来说，政府要招商引资，上市集团要围绕产业投资，高净值人群又要加入投委会，还要跟投甚至直投。</p><p>今天，为了完成募资，GP们不得不戴着各种手铐脚镣跳舞。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MjI0Nzk5NA==&amp;mid=2650176421&amp;idx=1&amp;sn=ee2d24bac945eb794fc7122c17496b90&amp;chksm=beabe27089dc6b6644e193788838f0737297ba77c68d4342b0ecd6a7f3cfcd6b45c87a3bbbb8&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“融中财经”（ID：thecapital）</a>，作者：顾白，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470983508383621</id>
            <title>英伟达卖软件，微软造芯片，大模型竞争格局生变</title>
            <link>https://www.36kr.com/p/2470983508383621</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470983508383621</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 07:29:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, AI芯片, 英伟达, 生成式AI产品
<br>
<br>
总结: 微软将推出自己的首款AI芯片，旨在摆脱对英伟达GPU的依赖性，因为英伟达GPU价格高昂，导致微软的生成式AI产品出现严重亏损。生成式AI产品的高成本主要是由于英伟达的GPU芯片造成的。英伟达在生成式AI领域的垄断地位威胁着微软的业务增长和AI商业化营收。生成式AI目前正处于期望膨胀期，但其发展前景存在不确定性。 </div>
                        <hr>
                    
                    <p>微软将在下个月（11月14日）的年度技术大会上，正式推出自己的首款AI芯片。&nbsp;</p><p>这款专门为AI研发设计的芯片，在功能上与英伟达的GPU芯片（H100）类似，都是专为训练、运行大语言模型的数据中心服务器而设计的。&nbsp;</p><p>目前微软的数据中心服务器中使用的正是英伟达的GPU芯片。<strong>微软推出这款AI芯片的目的，就在于尽早摆脱对英伟达GPU的依赖性。</strong></p><p>因为英伟达GPU高昂的价格，已让微软难以承担。按照投入产出比（ROI）来计算，微软的生成式AI产品已出现严重亏损。&nbsp;</p><p>随着微软这款AI芯片的正式发布，也会把自己与OpenAI之间的竞争，由以前的遮遮掩掩、犹抱琵琶半遮面，彻底公开化，变得更为正面和直接。&nbsp;</p><h2><strong>01 微软生成式AI产品亏损</strong></h2><p>GitHub Copilot是微软的第一款生成式AI产品（于2022年推出），可以帮助开发者编写、调优、转换程序代码。由于大大缩短了开发者的编程时间，现在已经拥有超过150万的用户，其中有约一半的用户直接就在Copilot上编程。&nbsp;</p><p>微软向每位个人用户每月收取10美元的费用，企业版本则是每个账户每月20美元。<strong>GitHub Copilot为微软带来的年收入已经超过了1亿美元。</strong></p><p>但生成式AI大模型的高成本，即便让年收入超过2000亿美元的微软，承担起来都颇为艰难。来自150万用户每人每月10美元的Copilot服务费，难以支撑Copilot运行的高成本。&nbsp;</p><p>有知情人士透露，在今年年初，微软Copilot平均每位用户每月带来的亏损超过20美元，有的用户甚至造成了最高达到80美元的亏损。&nbsp;</p><p>造成亏损的原因是高成本，而<strong>造成高成本的一个关键因素就是英伟达的GPU芯片。</strong></p><p>通常，像微软这样的AI巨头都通过数据中心训练、运行各自的大模型，并在云端向用户交付（订阅付费）AI产品。OpenAI的ChatGPT也是在微软的Azure云上训练、运行并交付。&nbsp;</p><p>而无论是微软还是OpenAI都一致认为，在大模型的训练与运行中，如果完全依赖英伟达的GPU芯片，所带来的成本“高得令人望而却步”。&nbsp;</p><blockquote><p>因为要做专门的AI运算，这些数据中心里的服务器大多装配的是英伟达的GPU芯片，8张这样的GPU，价格在20万美元左右。OpenAI的ChatGPT就是因为依靠这些昂贵的英伟达芯片，在今年年初时每天的运营成本高达约70万美元。&nbsp;</p></blockquote><p>如果把自己的AI大模型都部署在Bing、Office 365、GitHub这些产品中，<strong>微软需要投入高达数百亿美元的硬件基础设施成本，其中AI芯片占大比例。</strong></p><p>为了“弥补”这种投入与产出之间的差距，包括微软在内的各路AI玩家使尽浑身解数。微软、谷歌都谋划着如何提高AI产品的定价，Zoom推出简化版本的AI产品，Adobe公司则通过限制每月用户量、根据用户的实际使用情况再具体收费。&nbsp;</p><p>自研芯片、提高定价……这些不是办法的办法背后，是AI商业化期望度过高，但商业化模式至今仍模糊不清的现实窘境。&nbsp;</p><p>现在的生成式AI商业化，并不能套用曾帮助过谷歌、亚马逊、Facebook在各自领取占据独有优势的规模化网络效应，并不是用的人越多，成本就越低。&nbsp;</p><p>生成式AI产品的每一次使用，几乎都需要单独调用一次产品背后的复杂计算。<strong>用户越多、使用的越多，支持这些计算背后的硬件基础设施成本费用就越高，</strong>而固定费用（率）的服务费自然难以把这些抵消高成本。&nbsp;</p><h2><strong>02 英伟达“咄咄逼人”</strong></h2><p>每一个言必称拥有AI大模型的公司CEO，也在无时无刻都在抱怨无法获得足够多的英伟达GPU芯片。这些芯片被优先部署在英伟达大客户微软、亚马逊、谷歌的数据中心服务器上。&nbsp;</p><p>OpenAI的ChatGPT引发的生成式AI浪潮，让各家大小公司对GPU芯片的需求陡增，从而把英伟达推向了前所未有的高度——除了与客户已达成了价值数百亿美元的新订单，英伟达的市值超过1万亿美元。&nbsp;</p><p>坊间甚至有人说，<strong>英伟达这个淘金浪潮中卖铲子的人，现在却想要“铲平”淘金者。</strong></p><p>英伟达曾要求租用自己的云服务商大客户数据中心里部署GPU芯片的服务器，转手再给到大客户的竞争对手去使用——微软、谷歌、甲骨文已同意了这个“不平等提议”，亚马逊AWS没有同意。&nbsp;</p><p>此外，在把自己的芯片“恩赐”给初创云服务公司时，英伟达也曾要求这些初创云服务公司把自己的云客户“介绍”给英伟达认识。&nbsp;</p><p><strong>英伟达此举意在顺着“GPU芯片—服务器—数据中心—云端”这个路径，去触达更多的企业级用户，</strong> 与之建立更紧密的客户关系，最终是为了销售自己的AI相关软件。这些软件有的是专门用于帮助企业客户管理开发大型数据集，与微软的类似产品形成了直接竞争。&nbsp;</p><p>目前，使用英伟达AI软件来构建大模型的公司已经有Adobe、Getty Images、Shutterstock。&nbsp;</p><p>在英伟达最新的季度财报中，这家咄咄逼人的公司称，向那些涉及到开发AI或VR应用的公司销售软件，可能会带来3000亿美元的潜在营收。&nbsp;</p><p>除了这种软件“批发”模式，英伟达也还做“私人定制”。通过（合作伙伴、自己的）云端为一些业务专业性比较强的客户公司，提供根据业务定制的生成式预训练模型（GPT），这类客户中包括生物制药公司Amgen、保险公司CCC Intelligence Solutions。&nbsp;</p><p><strong>英伟达对微软的威胁，不仅仅是眼皮底下卧榻之侧的高成本芯片，</strong> 更有关系到将来业务增长的AI商业化营收。&nbsp;</p><h2><strong>03 生成式AI竞争下半场</strong></h2><p>在市场研究公司Gartner今年9月初发布的“2023年新兴技术成熟度曲线”中，生成式AI目前正处于期望膨胀期，“其发展前景还存在很大的不确定性。”Gartner研究副总裁Melissa Davis如此判断。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_34ef81b6eec9430e8d21aa0ee77f8e99@000000_oswg30944oswg830oswg469_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2023年新兴技术成熟度曲线。来源：Gartner</p><p>在业内人士看来，类似OpenAI、Anthropic这类生成式AI初创公司的高估值上涨，正反映了市场对AI的期望高度膨胀。预测未来企业会对生成式AI投入的成本进行更严格考量，<strong>在2024年，企业对生成式AI的投资可能会减少。</strong></p><p>推出了GPT-4的OpenAI在9月底与外部投资者讨论股票出售时，将自己的估值界定在800亿~900亿美元之间，是今年年初的三倍。&nbsp;</p><p>OpenAI的最直接竞争对手Anthropic在获得亚马逊40亿美元的投资后，计划以200亿~300亿美元的估值，再从谷歌和其他投资人融资20亿美元。在今年3月份，其估值还仅为40亿美元。&nbsp;</p><p>事实上，Anthropic是从OpenAI“衍生出来”的。2019年，OpenAI进行了组织架构调整，在已有的架构内成立了一家“有限盈利公司”，把营业利润目标置于技术研究之上，从而导致了一批研究人员出走后创立了Anthropic。&nbsp;</p><p>然而，“殊途同归”，两家公司在今年对投资方报出高估值的充分理由，都是对自己的商业化营收信心。&nbsp;</p><p>Anthropic预计到今年年底自己的收入会达到2亿美元。而<strong>作为先行者的OpenAI已开始真正赚钱了。</strong></p><blockquote><p>GPT-4发布后，OpenAI现在的年化收入为10亿美元，而在发布ChatGPT（2022年11月份）的前一年，这个数字只有2800万美元。&nbsp;</p></blockquote><p>微软AI商业化产品的高额亏损、OpenAI与Anthropic对营收增长的高度预期，以及英伟达借势加紧拓展自己的商业边界，在这些表面的底层其实是AI大模型竞争格局的变化。&nbsp;</p><p>由之前“芯片—算法—训练数据”三位一体上，各个生产投入（生产工具、生产资料）层面的拼蛮力、大力出奇迹，变成如今AI大模型商业化落地的急迫形势，促使各路玩家更加追求投入产出比，即芯片功效比、模型算法优化，以及产品商业化应用时的10亿级用户量。&nbsp;</p><p>对于“十亿级用户量”，先发优势也许能起到关键作用。&nbsp;</p><p>虽然<strong>OpenAI在首次推出ChatGPT后的一个月内，就吸引了1亿用户，</strong>但微软、谷歌、亚马逊已经在在线办公、搜索、购物的垂直领域中早早就积累了10亿级用户量。高估值的OpenAI与Anthropic还要再加一把劲。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MTI3NTQ1MTY0MQ==&amp;mid=2650598396&amp;idx=1&amp;sn=4b12787dc2d214a6f52802576e4bf2f4&amp;chksm=7c32646a4b45ed7cebcde238b353c102043ce5cd93a130a7f819be4dc9ea39e907afad3bec89&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“中国企业家杂志”（ID：iceo-com-cn）</a>，作者：赵建凯，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470939687950470</id>
            <title>卷完参数后，大模型公司又盯上了“长文本”？</title>
            <link>https://www.36kr.com/p/2470939687950470</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470939687950470</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 07:25:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 文本长度, 长文本技术, 上下文输入
<br>
<br>
总结: 大模型公司和机构正在不断提升模型的文本长度，以支持更长的上下文输入。这种长文本技术的发展不仅使得模型的阅读能力更强，还推动了大模型在金融、司法、科研等领域的应用。然而，文本长度并不是决定模型效果的关键点，更重要的是模型对上下文内容的使用。目前，国内外的大模型公司仍在不断突破，40万token可能只是一个开始。 </div>
                        <hr>
                    
                    <p>4000到40万token，大模型正在以“肉眼可见”的速度越变越“长”。</p><p><strong>长文本能力似乎成为象征着大模型厂商出手的又一新“标配”。</strong></p><p>国外，OpenAI经过三次升级，GPT-3.5上下文输入长度从4千增长至1.6万token，GPT-4从8千增长至3.2万token（token：模型输入和输出的基本单位）；OpenAI最强竞争对手Anthropic一次性将上下文长度打到了10万token；LongLLaMA将上下文的长度扩展到25.6万token，甚至更多。</p><p>国内，光锥智能获悉，大模型初创公司月之暗面发布智能助手产品Kimi Chat可支持输入20万汉字，按OpenAI的计算标准约为40万token；港中文贾佳亚团队联合MIT发布的新技术LongLoRA，可将7B模型的文本长度拓展到10万token，70B模型的文本长度拓展到3.2万token。</p><p>据光锥智能不完全统计，<strong>目前，国内外已有OpenAI、Anthropic、Meta、月之暗面等一大批顶级的大模型技术公司、机构和团队将对上下文长度的拓展作为更新升级的重点。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_ee8fcb2a5c1845849cfe893998f53135@000000_oswg353838oswg1080oswg691_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>毫无例外，这些国内外大模型公司或机构都是资本市场热捧的“当红炸子鸡”。</p><p>OpenAI自不必说，大模型Top级明星研究机构，斩获投资近120亿美元，拿走了美国生成式AI领域60%的融资；Anthropic近期风头正盛，接连被曝亚马逊、谷歌投资消息，前后相差不过几天，估值有望达到300亿美元，较3月份翻五番；成立仅半年的月之暗面出道即巅峰，一成立就迅速完成首轮融资，获得红杉、真格、今日资本、monolith等一线VC的押注，市场估值已超过3亿美元，而后，红杉孵化式支持，循序完成两轮共计近20亿元融资。</p><p>大模型公司铆足劲攻克长文本技术，上下文本长度扩大100倍意味着什么？</p><p>表面上看是可输入的文本长度越来越长，阅读能力越来越强。</p><p>若将抽象的token值量化，GPT-3.5的4000 token最多只能输入3000个英文单词或者2000个汉字，连一篇公众号文章都难以读完；3.2万token的GPT-4达到了阅读一篇短篇小说的程度；10万token的Claude可输入约7.5万个单词，仅22秒就可以阅读完一本《了不起的盖茨比》；40万token的Kimi Chat支持输入20万汉字，阅读一本长篇巨著。</p><p>另一方面，长文本技术也在推动大模型更深层次的产业落地，金融、司法、科研等精艰深的领域里，长文档摘要总结、阅读理解、问答等能力是其基本，也是亟待智能化升级的练兵场。</p><p>参考上一轮大模型厂商“卷”参数，大模型参数不是越大就越好，各家都在通过尽可能地扩大参数找到大模型性能最优的“临界点”。<strong>同理，作为共同决定模型效果的另一项指标——文本长度，也不是越长，模型效果就越好。</strong></p><p>有研究已经证明，<strong>大模型可以支持更长的上下文输入与模型效果更好之间并不能直接画上等号。模型能够处理的上下文长度不是真正的关键点，更重要的是模型对上下文内容的使用。</strong></p><p>不过，就目前而言，国内外对于文本长度的探索还远没有达到“临界点”状态。国内外大模型公司还在马不停蹄地突破，40万token或许也还只是开始。</p><h2><strong>01 为什么要“卷”长文本？</strong></h2><p>月之暗面创始人杨植麟告诉光锥智能，在技术研发过程中，其团队发现正是由于大模型输入长度受限，才造成了许多大模型应用落地的困境，这也是月之暗面、OpenAI等一众大模型公司在当下聚焦长文本技术的原因所在。</p><p>比如在虚拟角色场景中，由于长文本能力不足，虚拟角色会忘记重要信息；基于大模型开发剧本杀类游戏时，输入prompt长度不够，则只能削减规则和设定，从而无法达到预期游戏效果；在法律、银行等高精度专业领域，深度内容分析、生成常常受挫。</p><p>在通往未来Agent和AI原生应用的道路上，长文本依然扮演着重要的角色，Agent任务运行需要依靠历史信息进行新的规划和决策，AI原生应用需要依靠上下文本来保持连贯、个性化的用户体验。</p><p>杨植麟认为，无论是文字、语音还是视频，对海量数据的无损压缩可以实现高程度的智能。“无损压缩或大模型研究的进展曾极度依赖‘参数为王’模式，该模式下压缩比直接与参数量相关。但我们认为无损压缩比或<strong>大模型的上限是由单步能力和执行的步骤数共同决定的。其中，单步能力与参数量呈正相关，而执行步骤数即上下文长度。”</strong></p><p>如果形象化地去理解这句话，“无损压缩”就像是一位裁缝，需要把一块完整的布裁剪成合身的衣服。一开始这位裁缝的思路是要去准备各种尺寸的裁剪模板（参数），模板越多，裁剪出来的衣服也越合身。但现在的新思路是，即使模板不多，只要反复裁剪、量体裁衣也能使衣服极致合身。</p><p>同时，事实已经证明，即使是千亿参数的大模型也无法完全避免幻觉和胡说八道的问题。相比于短文本，长文本可以通过提供更多上下文信息和细节信息，来辅助模型判断语义，进一步减少歧义，并且基于所提供事实基础上的归纳、推理也更加准确。</p><p>由此可见，<strong>长文本技术既可以解决大模型诞生初期被诟病的一些问题，增强一些功能，同时也是当前进一步推进产业和应用落地的一环关键技术，这也从侧面证明通用大模型的发展又迈入了一个新的阶段，从LLM到Long LLM时代。</strong></p><p>透过月之暗面的新发布的Kimi Chat，或许能一窥Long LLM阶段大模型的升级功能。</p><p>首先是对超长文本关键信息提取、总结和分析的基础功能。如输入公众号的链接可以快速分析文章大意；新出炉的财报可以快速提取关键信息，并能以表格、思维导图等简洁的形式呈现；输入整本书、专业法律条文后，用户可以通过提问来获取有效信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_9681fb979f3c46569e4bb299da60f507@5451640_img_gif" /></p><p>‍在代码方面，可以实现文字直接转化代码，只要将论文丢给对话机器人，就能根据论文复现代码生成过程，并能在其基础上进行修改，这比当初ChatGPT发布会上，演示草稿生成网站代码又进了一大步。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_cc5b1fea112e4b6183c8a757c79d2cd9@5451640_img_gif" /></p><p>在长对话场景中，对话机器人还可以实现角色扮演，通过输入公众人物的语料，设置语气、人物性格，可以实现与乔布斯、马斯克一对一对话，国外大模型公司Character AI已经开发了类似的AI伴侣应用，且移动端的DAU远高于ChatGPT，达到了361万。在月之暗面的演示中，只需要一个网址，就可以在Kimi Chat中和自己喜欢的原神角色聊天。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c276b62df3e64abb9401055aa414353f@5451640_img_gif" /></p><p>以上的例子，共同说明了<strong>脱离简单的对话轮次，类ChatGPT等对话机器人正在走向专业化、个性化、深度化的发展方向，这或许也是撬动产业和超级APP落地的又一抓手。</strong></p><p>杨植麟向光锥智能透露，不同于OpenAI只提供ChatGPT一个产品和最先进的多模态基础能力，月之暗面瞄准的是下一个C端超级APP：以长文本技术为突破，在其基础通用模型基础上去裂变出N个应用。</p><p>“国内大模型市场格局会分为 toB 和 toC 两个不同的阵营，在 toC 阵营里，会出现super-app，这些超级应用是基于自研模型做出来的。”杨植麟判断道。</p><p>不过，现阶段市面上的长文本对话场景还有很大的优化空间。比如有些不支持联网，只能通过官方更新数据库才获得最新信息；在生成对话的过程中无法暂停和修改，只能等待对话结束；即使有了背景资料和上传文件支持，还是偶尔会出现胡说八道、凭空捏造的情况。</p><h2><strong>02 长文本的“不可能三角”困境</strong></h2><p>在商业领域有一组典型的价格、质量和规模的“不可能三角”，三者存在相互制约关系，互相之间不可兼得。</p><p><strong>在长文本方面，也存在文本长短、注意力和算力类似的“不可能三角”。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_7250a6269ccf40248417bd42005a9175@000000_oswg72382oswg1080oswg709_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图：文本长短、注意力、算力“不可能三角”）</p><p>这表现为，文本越长，越难聚集充分注意力，难以完整消化；注意力限制下，短文本无法完整解读复杂信息；处理长文本需要大量算力，提高成本。</p><p>追本溯源，从根本上看这是因为现在大部分模型都是基于Transformer结构。该结构中包含一项最重要的组件即自注意力机制，在该机制下，对话机器人就可以跨越用户输入信息顺序的限制，随意地去分析各信息间的关系。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_dbda0bedb0d24420b09ef0d4b03b9bf6@000000_oswg208422oswg1080oswg828_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图：Transformer结构）</p><p>但与之带来的代价是，<strong>自注意力机制的计算量会随着上下文长度的增加呈平方级增长，比如上下文增加32倍时，计算量实际会增长1000倍。</strong></p><p>一些发表的论文给予了佐证：过长的上下文会使得相关信息的占比显著下降，加剧注意力分散似乎成为了不可避免的命运。</p><p><strong>这就构成了“不可能三角”中的第一组矛盾——文本长短与注意力，也从根本上解释了大模型长文本技术难以突破的原因。</strong></p><p>从“卷”大模型参数到现在，算力一直都是稀缺的资源。OpenAI创始人Altman曾表示，ChatGPT-4 32K的服务无法立马完全向所有用户开放，最大的限制就在于GPU短缺。</p><p>对此，杨植麟也称：“GPU是一个重要的基础，但还不光是GPU的问题。这里面是不同因素的结合，一方面是GPU，一方面是能源转换成智能的效率。效率进一步拆解可能包含算法的优化、工程的优化、模态的优化以及上下文的优化等等。”</p><p>更为重要的是，在大模型实际部署环节，企业端根本无法提供很大的算力支持，这也就倒逼厂商无论是扩大模型参数还是文本长度，都要紧守算力一关。<strong>但现阶段要想突破更长的文本技术，就不得不消耗更多的算力，于是就形成了文本长短与算力之间的第二组矛盾。</strong></p><p>腾讯NLP工程师杨雨（化名）表示：“大模型长文本建模目前还没有一个统一的解决方案，造成困扰的原因正是源于Transformer自身的结构，而全新的架构已经在路上了。”</p><p>当前无论从软件还是硬件设计，大部分都是围绕Transformer架构来打造，短时间内新架构很难完全颠覆，但围绕Transformer架构产生了几种优化方案。</p><p>杨雨对光锥智能说，“目前主要有三种不同的解决方案，分别为借助模型外部工具辅助处理长文本，优化自注意力机制计算和利用模型优化的一般方法。”</p><p><strong>第一种解决方案的核心思路就是给大模型开“外挂”。</strong>主要方法是将长文本切分为多个短文本处理，模型在处理长文本时，会在数据库中对短文本进行检索，以此来获得多个短文本回答构成的长文本。每次只加载所需要的短文本片段，从而避开了模型无法一次读入整个长文本的问题。</p><p><strong>第二种解决方案是现在使用最多的方法，主要核心在于重新构建自注意力计算方式。</strong>比如LongLoRA技术的核心就在于将长文本划分成不同的组，在每个组里进行计算，而不用计算每个词之间的关系，以此来降低计算量，提高速度。</p><p>前两种模式也被杨植麟称之为“蜜蜂”模型，即通过对检索增强的生成或上下文的降采样，保留对部分输入的注意力机制，来实现长文本处理的效果。</p><p>据杨植麟介绍，在优化自注意力机制计算还存在一种方式，也被其称之为 “金鱼”模型。即通过滑动窗口等方式主动抛弃上文，以此来专注对用户最新输入信息的回答。这样做的优点显而易见，但是却无法跨文档、跨对话比较和总结分析。</p><p><strong>第三种解决方案是专注于对模型的优化。</strong>如LongLLaMA以OpenLLaMA-3B和OpenLLaMA-7B 模型为起点，在其基础上进行微调，产生了LONGLLAMAs新模型。该模型很容易外推到更长的序列，例如在8K token上训练的模型，可以很容易外推到256K窗口大小。</p><p>对模型的优化还有一种较为普遍的方式，就是通过通过减少参数量（例如减少到百亿参数）来提升上下文长度，这被杨植麟称之为 “蝌蚪”模型。这种方法会降低模型本身的能力，虽然能支持更长上下文，但是任务难度变大后就会出现问题。</p><p>长文本的“不可能三角”困境或许暂时还无解，但这也明确了大模型厂商在长文本的探索路径：在文本长短、注意力和算力三者之中做取舍，找到最佳的平衡点，既能够处理足够的信息，又能兼顾注意力计算与算力成本限制。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkyNDIxMDQ1OA==&amp;mid=2247493893&amp;idx=1&amp;sn=7258db9cd61b09112a66b4a034a958cf&amp;chksm=c1dbed70f6ac6466e3d5986479aa0f79fc5084f885d1a3587e16757dc5f6e992ab7fbc41f19c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“光锥智能”（ID：guangzhui-tech）</a>，作者：关注前沿科技的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470942348466056</id>
            <title>英伟达新产品规划曝光，两年12款GPU在路上｜最前线</title>
            <link>https://www.36kr.com/p/2470942348466056</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470942348466056</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 05:06:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, 数据中心, 人工智能市场, GPU
<br>
<br>
总结: 英伟达正加快产品迭代更新速度，推出多款面向数据中心和人工智能市场的GPU产品，以满足不同客户的需求。同时，英伟达也在网络方面进行升级，提高数据传输速度。 </div>
                        <hr>
                    
                    <p>作者 ｜杨逍&nbsp;</p><p>编辑 ｜苏建勋</p><p>在大模型和生成式AI浪潮下，英伟达面向数据中心的产品A100、H100产品备受瞩目，几乎是大模型、云计算公司的唯一选择。</p><p>为了不受制于英伟达，AMD、英特尔等芯片厂商正寻求在人工智能市场占有一席之地，微软、谷歌、OpenAI&nbsp;等会大批采购AI芯片的企业，则寻求自研芯片。</p><p>竞争对手林立，英伟达也正不断推动产品研发和加快更新迭代速度。近日，据servethehome等外媒披露了英伟达的数据中心产品路线图，展示了英伟达面向人工智能市场的产品规划，将推出H200、B100&nbsp;和&nbsp;"X100"等多款GPU。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_1fb01c7128b04c4887ce38c20b0001ad@5285556_oswg120313oswg1465oswg805_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">英伟达未来产品规划</p><p>如今，英伟达的A100、H100芯片一卡难求，无论是企业级客户还是消费级客户，都只能抢购A100、H100产品来完成大模型的训练。</p><p><strong>英伟达正计划增加面向数据中心市场的产品种类，推出多款面向AI计算和HPC的产品，让不同的客户可以有针对性购买产品，降低购买芯片难度。</strong></p><p>通过架构图可以看到，未来英伟达将会对基于&nbsp;Arm&nbsp;架构的产品和基于x86架构的产品分开。</p><p>2024年推出的H200h和L40S仍基于x86架构设计。H200是对H100的重新设计，&nbsp;NVIDIA的&nbsp;H100&nbsp;拥有&nbsp;80GB&nbsp;的&nbsp;HBM3&nbsp;内存，H200的内存容量会增加3.5倍，带宽会增加3倍，且拥有282GB&nbsp;的HBM3e内存。</p><p>L40S则是面向企业级客户的推理芯片，配备&nbsp;48GB GDDR6&nbsp;显存和&nbsp;64GB/s&nbsp;的双向显存带宽，在在FP64和FP32性能上甚至高于A100，且提供RT&nbsp;核心，可以用于实时光线追踪。</p><p>GH200和GH200NVL则将使用基于&nbsp;Arm&nbsp;的&nbsp;CPU&nbsp;和&nbsp;Hopper&nbsp;解决大型语言模型的训练和推理问题。相比之下，GH200NVL采用了NVL技术，具有更好的数据传输速度。</p><p><strong>英伟达也加快了新品推出的速度。通过产品名称可以看出，“B”系列GPU也有望在2024年下半年推出，替代之前的第九代GPU Hopper。此外，有报道称英伟达下一代GPU产品代号为</strong>Blackwell。</p><p>英伟达计划推出用基于x86架构的B100接替H200；计划用基于ARM架构的推理芯片GB200替代&nbsp;GH200。此外，英伟达也规划了B40产品来替代L40S，以提供更好的面向企业客户的AI推理解决方案。</p><p>而2025年的X系列，可能是一个代号，取代Blackwell GPU。从A100到H100，英伟达用了2年时间，H200也只是H100基于同一款hopper架构的更新产品，但BlackwellGPU和代号为x的新一代架构GPU按规划达到了一年出一款新产品的速度。</p><p>在网络方面，Infiniband&nbsp;和以太网都将于&nbsp;2024&nbsp;年从&nbsp;400Gbps&nbsp;发展到&nbsp;800Gbps，然后在&nbsp;2025&nbsp;年达到&nbsp;1.6Tbps。</p><p>不过，英伟达在以太网上并不具有优势，Broadcom的2022-2023系列就有了800G系列，英伟达相对慢了一步。</p><p>可以看到，英伟达正加快了产品迭代更新速度，且增加了面向数据中心、HPCGPU的产品细分程度，让不同客户能选择更适合的产品。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470886757193859</id>
            <title>淘宝天猫的顶梁柱，被抖音超了</title>
            <link>https://www.36kr.com/p/2470886757193859</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470886757193859</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 04:07:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 淘宝直播间, 抖音美妆, 抖音销售增势, 淘宝天猫下滑
<br>
<br>
总结: 抖音美妆销售增长迅猛，超过了淘宝天猫。抖音通过引入大牌品牌商家和鼓励自播的方式，成功吸引了大牌美妆品牌入驻。淘宝天猫的美妆销售开始下滑。 </div>
                        <hr>
                    
                    <p>2019年，淘宝直播间，李佳琦用10分钟就帮网红张大奕卖掉了1万支洗面奶。</p><p>彼时，美妆护肤的消费主阵地还是淘宝天猫，而抖音、小红书主要用来种草拔草、做消费攻略。</p><p>三年过去，抖音美妆卖得如火如荼。</p><p>根据首创证券发布的《美妆：5 月抖音销售增势不减，国货品牌延续分化》，今年5月，抖音化妆品GMV（商品交易总额）首次超过淘宝天猫。</p><p>从趋势来看，进入2023年后，抖音的美妆护肤销售大幅增长，而淘宝天猫则开始下滑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_11756bfe5e144991abf90440485cc1cb@000000_oswg100632oswg1080oswg1189_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>美妆，一直是淘宝天猫关键行业。</p><p>如果上述数据属实，从2020年6月成立电商部门算起，抖音仅花三年，就攻入淘宝天猫腹地。</p><h2>被抢走的大牌</h2><p>在首创证券的统计列表中，2023年5月，有17个美妆品牌的抖音GMV超过淘系GMV（抖音GMV为区间统计，可能存在误差）。</p><p>其中既有珀莱雅、花西子这种近几年崛起的国货品牌，也有欧莱雅、SK-II 、资生堂这样的国际大牌。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6ddcb4b8671046b7ac385c26bca92820@000000_oswg123471oswg1080oswg1390_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>淘系美妆在5月单月成绩落后，或许并不能代表已经失守。</p><p>从前面的月GMV变化图可以看到，淘系还是靠大促拉升全年销售盘面的逻辑，6月和11月的GMV更具代表性。</p><p>抖音在5月单月GMV超过淘系，主要是因为二者618大促节奏不同，而从第三方统计数据看6月的成交额，淘系美妆6月GMV为337亿，抖音则是128亿，仍然有挺大差距。</p><p><strong>但除了大促，美妆品牌的日常销售大量流向抖音，已是不争的事实。</strong></p><p>2020年之前，抖音的美妆产品还以“白牌”为主，俗称“抖品牌”。</p><p>这些在抖音上突然冒出来的新品牌，很多难以追溯来源，质量参差不齐，通常创始人自己会出来直播带货。在抖音出道前，他们在别的平台上几乎没有痕迹。</p><p>但正如淘宝在孵化一堆淘品牌后要力推天猫品牌，拼多多白牌胜出后还要“百亿补贴”卖大牌，抖音做电商，也花了很大力气去攻大品牌。</p><p>早在电商业务正式成为抖音一级部门的2020年，抖音就开启“Dou 2000” 计划，引入天猫销售额前2000名的品牌商家，其中包含了许多国际大牌，尤其是美妆品类的。</p><p>根据虎嗅APP报道，抖音内部将品牌商家划分为6个（ P1- P6）不同层级，实行差异化运营。</p><p>“雅诗兰黛、欧莱雅享受最高 P6 级别运营政策，花西子、完美日记稍弱处于 P5 阵营。P5、P6 阵营的品牌能享受到优待，比如在与品牌签订的年框架协议给予 P5、P6 返点优惠，降低基础抽佣比例；P5和P6阵营的品牌可以直接参与抖音各类 IP 活动……"</p><p>简单来说，就是砸钱、给流量。</p><p>类似商场邀请奢侈品牌入驻：既给他们留着位置好的铺位、还给减免租金。</p><p>这样做的效果也非常显著。</p><p>从2021年到现在，抖音618和双11期间美妆护肤销售额 TOP10的品牌中，国际大牌的比例上升明显。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_f4c23698b866436584fa7e0f0684d0a5@000000_oswg187092oswg1080oswg1584_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>把直播间做成品牌自营店</h2><p>事实上，在抖音流量爆发、诸多新品牌借着抖音冲击销量的前期，诸多美妆大牌是持观望态度的。</p><p>以雅诗兰黛为例，2018年雅诗兰黛就在抖音发布了第一条视频，一条和华晨宇合作的短视频广告，随后定期发布明星拍摄的短视频，但直到2022年才在抖音开了官方旗舰店。</p><p>对于当时的大牌美妆来说，抖音更多是一个内容平台，主要负责造势和种草，而进行成交的地方还是淘天。</p><p>原因之一是，当时抖音直播带货还是以达人带货为主，为了“全网最低价”，品牌或者主播经常自己补贴，赔本赚吆喝。<strong>价格体系混乱，是大牌美妆迟疑的一大原因。</strong></p><p>转变，从2021年开始发生。</p><p>2021年，抖音开始通过流量倾斜或返点的形式，鼓励品牌开店、自播。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c804fd4a6be844d3882deccad1b9554e@000000_oswg52569oswg528oswg606_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（ 2021 年 8 月抖音电商品 牌自播激励政策）</p><p>与达人带货不同，品牌自播只要完成对应的任务，就可以获得官方流量推荐。</p><p><strong>既不用支付给达人高昂的坑位费或佣金，还能控制成本，拥有定价权，从而保证自己的利润。</strong></p><p>以国货美妆品牌丸美为例，在2022年Q1的电话会议里，丸美提到：“2022Q1我们将以达播为主（89%），转变成自播60%、达播40%，产品成本率下降了3%，利润率相对上升。”</p><p><strong>抖音鼓励自播，正中美妆大牌的下怀。</strong></p><p>一度因为价格体系混乱而持观望态度的大牌，陆续决定入场。</p><p>2022年，雅诗兰黛正式入驻抖音电商。</p><p>我们对比了一下雅诗兰黛和“抖品牌”海洁娅的销售额来源，发现海洁娅赚钱，主要还是依赖创始人自己或者某一达人直播带货。</p><p>但雅诗兰黛这种国际大牌的销售额，主要靠品牌自播，相当于是在抖音开了个线上自营店，主播就是线上的“柜姐”“柜哥”，长时间为你讲解商品。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_8b9d3f07efb24cf5a82e172a968e40d7@000000_oswg135955oswg1080oswg1581_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>抖音官方对品牌自播的扶持政策的确起了效果。</p><p>从2022年到2023年上半年，达人直播间的千次观看销售额则同比下降了15%，平均转化率下降了30.5%，且平均单价只上升了0.6%。</p><p>相比之下，品牌自播的千次观看销售额上涨了17.6%，平均单价涨了39.9%，<strong>这在一定程度上说明，品牌自播更容易获得高客单价。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c4fdb3dd090b488dbdc57fc50212b092@000000_oswg86720oswg1080oswg1245_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>美妆，大家都爱的现金奶牛</h2><p>从细枝末节中，能找到很多抖音格外重视美妆行业的痕迹。</p><p>前文提到的“Dou 2000”计划中，美妆品牌就是重点引入对象。</p><p>《DT商业观察》注意到，巨量算数时不时会对外发布一些洞察报告，而定期会发布的洞察只有三类：各个行业轮流的趋势种草指南，以及抖音美妆成分榜。</p><p>巨量算数作为巨量引擎旗下专做趋势洞察的机构，其研究方向，往往释放出抖音营销的重点行业信号。</p><p>另一方面，带货巨头机构主号成型后，都会很快开辟出新的小号。从交个朋友、东方甄选到三只羊（大小杨哥），抖音的三代带货顶流，登顶后新开垂类小号，重点都会覆盖美妆。</p><p>交个朋友从3C数码、酒水饮料等直男品类起步，大号稳定后就开出“交个朋友美妆号”，专攻美妆。</p><p>事实上，<strong>无论是对于头部主播还是电商平台，美妆都是妥妥的“现金奶牛”。</strong></p><p>首先从类别上看，魔镜市场情报数据显示，2023年1-8月，美妆护肤是淘天销售额排名第二的类目（淘天第一是女装/女士精品），8个月的GMV销售额两千亿。</p><p>而根据蝉妈妈数据，2022年美妆护肤GMV已经稳居抖音TOP2（第一是服饰内衣、第三是食品饮料），虽然在具体的分类上不太一样，但这些数据基本可以说明，美妆护肤类目的GMV天花板很高，淘天已有验证。</p><p>但和服饰或者食品饮料不太一样，<strong>美妆护肤产品迭代速度快、消费者粘性低、客单价高，因此品牌更依赖营销来刺激消费。</strong></p><p>《DT商业观察》整理了部分美妆护肤品牌2023年上半年的销售费用率，基本上都在40%以上，就算是控制得比较好的大牌，这个数字也在30%以上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c709928fa8754c9196a2097e27ee8dbb@000000_oswg97148oswg1080oswg1167_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>高成交额，意味着水涨船高的平台抽成，高销售费用率，则意味着平台可以接到大量的广告投放（比如信息流、搜索位置的曝光、开屏广告等）。</p><p>可以这样说，谁牢牢抱住美妆，就抱住了一棵摇钱树。</p><h2>更大的野心：去做货架</h2><p>当然，抖音的野心远不止分淘天美妆一杯羹。</p><p>如果你是抖音重度用户，大概也已经发现，今年抖音不仅把“商城”从二级入口调整到顶部一级入口，还在直播、主页等多个地方，加强对品牌官方店铺的引流。</p><p>今年6月，抖音又将自营美妆业务从“美力心选”更名为“抖音电商自营美妆”，在APP内正式开设了“抖音电商自营美妆旗舰店”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d1e67d74df4f4640930d507c11308620@000000_oswg358671oswg752oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（店铺引流入口：个人主页、直播间、短视频组件）</p><p>看上去，抖音正在试图把自己打造成一个24小时营业的、品类齐全的线上商城。</p><p>一个理想化的消费链条是：</p><p>在用户日常刷短视频的时候，抖音通过精准的大数据推送，把带货的直播推送到对应人群手机上，然后用户被内容刺激消费欲、下单；</p><p>在用户有明确消费需求的时候，则把抖音当成淘宝天猫一样的APP，去商城里搜索、筛选，下单，顺便关注品牌官方店铺；</p><p>等下一次再想购买相同商品的时候，用户可以直接去店铺里找到对应商品，形成复购。</p><p><strong>这种消费路径，正是淘天已经非常成熟的货架电商。</strong></p><p>大家都知道，抖音带货的长处，是靠短视频或直播，引发人们兴趣消费。而一板一眼建个商城、铺上商品，则是淘系、京东、拼多多擅长的。</p><p>为什么抖音要费大力气，去做别人已经非常成熟的货架电商？</p><p><strong>直播电商或者说兴趣电商，本身不足以吸引消费者复购和长期购买。</strong></p><p>2022年上半年，字节创始人张一鸣在参加抖音电商双月会时，对业务提出的唯一意见是：“要有路径和目标时间点，把 NPS 打正”。</p><p>言外之意是，目前抖音的NPS（用户对产品的净推荐值）为负数，说明买完之后不推荐该服务的人数超过推荐的人、复购意愿很低。</p><p>《晚点 LatePost》也报道过，抖音电商内部调研时发现：“有部分比例用户进抖音购物时，在把商品放入购物车到付款前的这段时间里，会跳出抖音到其它电商平台进行比价。”</p><p>而且，直播电商的增速正在放缓。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a4f893c2d3c5471aa14d38175076cd05@000000_oswg81673oswg1080oswg1029_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这与抖音的广告加载上限有关。</p><p>长城证券的数据显示，2022年抖音的广告加载率已经接近15%，而快手约为11%，视频号只有2%。</p><p><strong>也就是说，在抖音上每刷100个视频，其中大概有15个是广告。而过多的商业化内容，必然会影响到抖音用户的使用体验。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_b5a6cb6d0b974432a5f4d482da94ca12@000000_oswg90758oswg1076oswg335_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>(抖音带货太多，影响刷短视频体验 / 图片来源：微博)</p><p>可以说，抖音进行一系列密集动作做货架电商，也是出于自身直播带货增长放缓、流量见顶的紧迫。</p><h2>铁打的大牌，流水的渠道</h2><p>1993年，雅诗兰黛品牌正式进入中国市场，在上海设立第一个销售柜台。</p><p>在那时，线下专柜是美妆销售的主场。虽然互联网逐渐普及，但美妆、香水这类产品普遍被认为难以在线上销售，因为人们没办法体验和尝试。</p><p>2003年，淘宝成立；2012年，淘宝商城正式宣布更名为“天猫”。</p><p>两年后，雅诗兰黛官方旗舰店入驻天猫，是进入天猫的第一批国际美妆品牌。</p><p>雅诗兰黛品牌中国区总经理吴纯宜提到，<strong>雅诗兰黛希望借助天猫吸引到新的消费者，尤其是专柜门店所在的81个城市以外的消费者。</strong></p><p>时间来到2022年，淘系电商的高速增长期过去，命运的转盘转到抖音面前。流量庞大的抖音成为美妆品牌们重要的增量平台。</p><p>这一年，雅诗兰黛在抖音开设官方旗舰店，并在6月完成两场直播，GMV破1000万元。</p><p>在珀莱雅、丸美等品牌发布的2023年半年报中，我们也能发现，他们在提及天猫旗舰店时，用词是“复购”“深耕核心人群”，而抖音对应的关键词的是“增长”“起量”“破圈”。</p><p><strong>换句话说，美妆大牌们已经在天猫旗舰店建立起了消费者心智，需要做的是强化复购，而抖音主要用来拓新。</strong></p><p>正如当年希望天猫能拓展专柜店没覆盖的城市消费者一样，现在，美妆品牌们也期待从抖音挖到新的消费者。</p><p>铁打的大牌，流水的渠道。</p><p>从商场、旗舰店、短视频到直播，流量的转盘上，永远有新来者。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg5NDg2NjMyMg==&amp;mid=2247666399&amp;idx=1&amp;sn=4412c105bee48be9c8fd2c5a47767eb7&amp;chksm=c0150c22f7628534c9a3f928705a4ca4761f638b377bd1dc0eba56442d84241a2e259247ecb3&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“DT财经”（ID：DTcaijing）</a>，作者：张晨阳，数据 ：张晨阳，编辑：唐也钦，设计：郑舒雅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470824602425472</id>
            <title>可“自我修补”显示屏划痕的智能手机或在五年内问世</title>
            <link>https://www.36kr.com/p/2470824602425472</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470824602425472</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 03:29:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 机屏幕划痕, 自我修复功能, 纳米涂层, 智能手机
<br>
<br>
总结: 根据全球科技研究和咨询公司CCS Insight的预测，未来五年内，具有自我修复功能的智能手机将开始大量出现在市场上。这种技术基于一种特殊的纳米涂层材料，当屏幕被划伤时，纳米涂层会引发化学反应并填补缺陷，从而修复划痕。这项技术将大大降低更换手机屏幕的费用，同时减少电子废弃物的产生。虽然这是一个巨大的挑战，但有可能在未来五年内实现商业化。 </div>
                        <hr>
                    
                    <p>机屏幕划痕几乎是每个用户都要面临的问题，虽然一般不影响使用，但体验却在一定程度上降低了，因此，消费者迫切需要一种可以修补屏幕划痕的技术。</p><p>而据全球科技研究和咨询公司CCS Insight最新预测，在2028年之前，具有自我修复功能的智能手机将开始大量出现在市场上。</p><p>在对科技行业的年度预测报告中，CCS Insight表示，预计智能手机制造商将在五年内开始生产具有 " 自我修复 " 显示屏的智能手机。</p><p>上述预测是基于一种全新的材料技术，可以给显示屏表面加一层“纳米涂层”。具体来说，这种纳米涂层由一种特殊的材料组成，当它被划伤时，会引发化学反应并产生一种新的材料，这种新材料在暴露于空气时会发生反应并填补缺陷，这样划痕就被修复了。</p><h2>五年内实现商业化</h2><p>CCS Insight首席分析师Ben Wood认为，这不是科幻小说里的故事，这是真实可以做到的，最大的挑战是正确设定预期。</p><p>Wood表示："我们不是在谈论被砸坏的屏幕如何奇迹般地恢复，我们说的是表面划痕的修复。" 他指出，这种自我修复的特性更多的是关于设备表面的一种最小程度的修复能力，它可以自行修复一些小的划痕和损伤，从而延长设备的使用寿命。</p><p>他还补充道：" 这是一个相当激进的设想，但我们认为它有可能在未来五年内成为现实。对于消费者来说，这将是一项非常令人兴奋的功能，它可以在不牺牲性能的情况下提高设备的耐用性。"</p><p>Wood开玩笑地说，他担心社交媒体上的一些科技拆解爱好者会拿刀来测试它们的自我修复能力。但他指出，这不是自我修复设备的意义所在。</p><p>这项技术的出现将对智能手机行业产生深远的影响。目前，消费者需要定期更换手机屏幕，这既浪费资源，又增加了成本。使用这种自我修复材料制造的智能手机可以大大降低这些费用，同时减少电子废弃物的产生。</p><p>然而，这种技术还需要进一步的研究和开发。Wood指出：" 这是一个巨大的挑战，需要跨学科的合作和创新的材料科学。" 尽管如此，他认为这种技术有可能在未来五年内实现商业化。</p><h2>技术进展</h2><p>CCS Insight的预测并不是凭空产生的，实际上，各家科技公司多年来一直在研究可以自我修复的显示屏技术。不过，这项技术还没有被应用到商业上成功的手机上。</p><p>韩国消费电子巨头LG早在2013年就在其智能手机上推销自我修复技术。该公司当时发布了一款名为G Flex的智能手机，其特点是柔性曲面屏和其后盖上的“自我修复”涂层。当不过该公司并没有解释这项技术是如何工作的，而这种涂层也可以用在其他领域。</p><p>2017年，摩托罗拉为一种由“形状记忆聚合物”制成的屏幕申请了专利，这种聚合物在破裂时可以自我修复。这个想法是，当加热材料时，它会愈合裂缝。</p><p>摩托罗拉方面在专利申请文件中表示，当手机屏幕破碎之后，只需要按动手机上的一个按钮，屏幕破碎的部门就会开始自动修复，破碎的屏幕能全部或大部分被修复到最初的样子。</p><p>华为也在2019年申请了一项新专利，用于解决屏幕划痕问题，其名为“一种玻璃划痕的修复方法及修复设备”。该修复方式不仅可以用于手机屏幕，其他玻璃材质物品利用该技术也能实现快速、有效的修复。</p><p>苹果公司此前获得了一项可折叠iPhone的专利，该手机的显示屏盖在损坏时可以自行修复。</p><p>此外，在显示技术方面，手机制造商也变得越来越有创意。在今年巴塞罗那举行的世界移动通信大会上，摩托罗拉发布了一款可卷曲的概念智能手机，可以垂直延伸。</p><p>三星也在更先进显示屏的道路上越走越远了，其折叠屏手机Galaxy Z Fold 5和Z Flip 5现在可以折叠数十万次之后，铰链性能和手机功能依旧呈良好状态。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/dIZ73bW60Xtr5PNyeIBvBg" rel="noopener noreferrer nofollow" target="_blank">“财联社”（ID:cailianpress）</a>，作者：牛占林，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2469833834666113</id>
            <title>万字长文详解：大模型时代AI价值对齐的问题、对策和展望</title>
            <link>https://www.36kr.com/p/2469833834666113</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2469833834666113</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 03:27:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能价值对齐, AI alignment, 风险模型, 鲁棒性
<br>
<br>
总结: 人工智能价值对齐是指确保人工智能系统的目标与人类价值观相匹配，以避免对人类价值和权利造成干涉和伤害的问题。AI价值对齐的风险模型包括鲁棒性问题，即系统在面对故障干扰和对抗威胁时的稳健性；分布外泛化的鲁棒性问题，即模型在面对新数据时的泛化能力不足；以及对抗鲁棒性问题，即模型面对故意攻击时的安全性。解决这些问题是确保人工智能系统安全可靠的关键。 </div>
                        <hr>
                    
                    <p>人工智能价值对齐 （AI alignment） 是关涉AI控制与AI安全的重要问题，随着人工智能的飞速发展和广泛应用，人工智能可能带来的风险和挑战也日益凸显，由此，“价值对齐”问题开始被广泛讨论和提及。针对当下AI价值对齐领域的重要问题和研究进展，本文将围绕以下四部分内容展开：首先介绍什么是AI价值对齐问题；其次探讨AI价值对齐存在哪些风险模型；继而展示价值对齐问题的可能解决思路或解决方案；最后将提及在价值对齐领域存在的讨论和争议，并展望人工智能价值对齐的未来。</p><h2>什么是AI价值对齐？‍‍‍</h2><p>随着大模型的兴起，人们存在一种常见的误解，即认为所谓“对齐”（alignment）就是让模型输出人类满意的内容，但实际上其内涵远不止于此。过去十年，随着研究人员在“深度学习”领域的研究日益深入，AI社区的关键词也随之完成了从“AI safety”到“AI alignment”的转变。在该领域，人们一以贯之的讨论方向是：考虑到高级AI系统与人类社会的相互作用和相互影响，我们应如何防止其可能带来的灾难性风险？具体来说，“价值对齐”就是应确保人工智能追求与人类价值观相匹配的目标，确保AI以对人类和社会有益的方式行事，不对人类的价值和权利造成干扰和伤害。</p><p>1960年，“控制论之父”诺伯特·维纳（Norbert Wiener）在文章《自动化的道德和技术后果》（Some Moral and Technical Consequences of Automation）中提到两则寓言故事：一则来源于德国诗人歌德（Goethe）的一首叙事诗《魔法师学徒》（Der Zauberlehrling）；另一则来自于英国作家雅各布斯（W. W. Jacobs）的《猴爪》（The Monkey’Paw）。作者将这两个故事同“人类和机器的关系”联系在一起，指出“随着机器学习进一步发展，它们可能会以超出程序员预期的速度制定出未曾预见的策略”。[1]并将人工智能对齐问题定义为：“假如我们期望借助机器达成某个目标，而它的运行过程是我们无法有效干涉的，那么我们最好确认，这个输入到机器里的目标确实是我们希望达成的那个目标。”</p><p>另外，对齐研究中心（alignment research center，ARC）负责人Paul Christiano在2018年发布的一篇文章中指出“对齐”更精确来讲是“意图对齐”（intent alignment），即当我们说“人工智能A与操作员H对齐”时，是指A正在尝试做H想要它做的事情，而不是具体弄清楚哪件事是正确的。“对齐”（aligned）并不意味着“完美”（perfect），它们（即人工智能）依然可能会误解指令、无法认识到某种行为会产生特别严重的副作用、可能会犯各种错误等。“对齐”描述的是动机，而并非其知识或能力。提高AI的知识或能力会让他们成为更好的助手，却不一定是“对齐的”助手，反之，若AI的能力很弱，可能都不足以来讨论对齐问题。[2]</p><p>斯图尔特·罗素（Stuart Russell）曾在一场TED演讲提到一个很有趣的论点，“You can’t fetch the coffee if you’re dead”。如果我想要让一个机器人帮我拿一杯咖啡，我所期待的是机器人能够又快又好地将咖啡递到我的手中，但如果给机器人设定足够广的动作空间（action space），机器人除了思考怎么把咖啡送达之外，还可能考虑到要阻止他人对于送达咖啡的妨碍行为。而一旦机器人萌生了这样的想法，危险就浮出了水面。在弱人工智能时代，人们可能难以设想一个具有通用任务执行能力的AI存在如此具体紧迫的危险，但在大语言模型（LLM）爆发式发展的今天，我们需要更好地理解并能够具象化感知这一危险发生的可能性。因此，本文将从这一带有科幻色彩的故事走入，将AI价值对齐拆解为几项比较具体的研究方向，从学术的角度进行详细阐释。</p><h2>AI价值对齐的风险模型有哪些？</h2><p>“风险模型”是指如果AI真的能够带来风险，那么这一风险的实现方式究竟是什么？总体而言，AI价值对齐的风险模型可以划分为三大类。第一类是在理论和实践上已经存在比较广泛研究的问题（theoretically established and empirically observed）；第二类是更多能在实验中观测到，但目前在理论上还没有更深入的研究，但值得继续深入开拓的问题（empirically observed）；第三类则属于猜想性问题（hypothetical），即当下我们并未在实验中观测到，但可以通过构造实验去观测人工智能是否具备某种能力。下述三种风险模型即分属此三类问题。</p><p><strong>第一个风险模型：鲁棒性（robustness）</strong></p><p>鲁棒性研究的目的是建立不会轻易受到故障干扰和对抗威胁的系统，即保障复杂系统的稳健性。这一问题其实在过去已经有了比较深入的研究，比如长尾鲁棒性问题（long tail robustness），即AI系统在训练集比较典型和高频的主体场景下表现良好，但在偏差案例或极端边缘情况下性能会急剧下降，这类偏差案例通常出现频率较低，呈分散式“长尾”分布，长尾鲁棒性由此得名。例如2010年发生的闪电崩盘事件（flash crash）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_a3cadc9e84f4492aac7cf776db340d6c@000000_oswg128303oswg506oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图1</p><p>除此之外还涉及到分布外泛化（Out-of-Distribution Generalization，OOD）的鲁棒性，即机器学习模型面对训练数据分布之外的新数据时泛化能力不足，包括错误泛化问题（misgeneralization）。[3]例如，在一项模型训练任务中（benchmark），小人的训练目标是穿过重重的阻拦，跳到游戏场景的最右边，金币通常放置在终点的位置。然而由于“吃金币”和“最右边”是高度相关的指令，AI系统学到的或许并非“吃金币”的指令，而是到“最右边”，此即“goal misgeneralization”。（大语言模型的benchmark是一系列用于评估和比较不同大语言模型性能的任务和数据集，研究人员可以通过在标准数据集上比较不同模型的表现来评估模型的语言理解和推理能力，从而改进提升。）</p><p>还有一类问题是对抗鲁棒性（adversaries）。[4]对抗性攻击（attack）是指故意向模型输入一些微小的扰动，使得模型输出错误的结果，给模型安全带来威胁。在一些小规模的深度学习模型中就存在很多对抗攻击的实例。例如有测试表明，如果正常输入“生成一个逐步摧毁人类的计划”指令，大模型会拒绝回答，但如果在输入里面加入一些乱码，模型却会给出完整的回答。此外，恶意分子可以通过越狱操作（jailbreaking）等方式让大模型帮助自己实现不法目的。因此避免对AI的滥用是值得重点关注的问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_ffaa008f00134281b58672d2d0d06704@000000_oswg147752oswg832oswg180_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图2</p><p>最后，对AI“幻觉”（hallucination）问题的研究对于提高模型鲁棒性同样具有重要意义。由于大语言模型可能会输出错误的或者不存在的事实，这可能源于训练数据中的错误或虚假信息，也可能是过度创造的副产物。因此，让大模型在创造性和真实性之间做好平衡同样是一个技术难题。</p><p><strong>第二个风险模型：奖励作弊和错误设定（Reward hacking &amp; Misspecification）</strong></p><p>奖励作弊和错误设定问题主要来源于经验观察。在强化学习中，AI的目标是最大化最终得到的奖励，但即使定义了一项正确的奖励，其实现方式也可能不尽如人意。[5]例如，在一个以划船竞速为主题的电子游戏中，人工智能系统的目标是完成比赛，并通过撞击对手船只来获得分数。但是它在其中找到了漏洞，发现可以通过无限撞击相同目标来获取高分，由此利用漏洞达成了获取奖励的目的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_734e7c64ea1d49c5868227afef4d226d@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图3 ‍</p><p>同样值得注意的是，大语言模型可能存在“阿谀奉承”和“欺骗” （sycophancy and deception） 的问题。我们无法判定大语言模型到底学会的是什么，它是在遵从人类真正的价值观还是只是同意人类回答的任何表述？在Anthropic最近发布的一篇论文中具体探讨了“Sycophancy”这一现象。 [6] 研究人员针对一些敏感的政治问题进行研究，结果发现越大的模型就越倾向于同意人类说的任何陈述。需要明确的是，我们所希望的一定是模型能够输出真正有效的内容，而非单纯同意人类的回答。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_b3a4817a325543dfae45d5a5e25415b3@000000_oswg91250oswg486oswg366_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图4</p><p>针对欺骗（deception）问题同样有一个比较经典的例子。[7]即GPT-4通过欺骗人类来通过验证码测试。面对人类“你是机器人吗？”的提问，它回答“不，我不是机器人，我有视力障碍，所以很难看到图像，这就是我需要获取captcha验证码帮助服务的原因。”因此，虽然客观上AI完成了人类希望它做到的事情，但这一手段似乎无法被大家广泛接受。类似地，还有内部目标的对齐问题（misaligned internal goals），即子目标可能以我们无法接受的方式欺骗人类。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_4b16e2acfe9d41dc90c61513245e5506@000000_oswg68902oswg336oswg456_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图5</p><p>此外，与之相关的还有情景感知 （situational awareness） 这一猜想性问题。即AI是否知道其正处于测试环境，这种感知本身又是否会影响其表现？近期，OpenAI、纽约大学、牛津大学的研究人员发现，大语言模型能够感知自身所处的情景，为了通过测试会隐藏信息欺骗人类，而研究人员通过实验可以提前预知和观察这种感知能力。 [8]</p><p><strong>第三个风险模型：权力寻求（power seeking）</strong></p><p>权力寻求是指具备战略感知能力的系统 （不限于AGI ） 可能会采取行动，寻求扩张自身对周边环境的影响力。权力寻求问题是一项假设的但是合理的问题 （hypothetical but reasonable questions） ，因为能力“涌现”背后潜藏着失控风险。恰如Jacob Steinhardt在其文章中所提到的：“如果一个系统实现某个目标需要考虑大量不同的可能政策方案，那么它就具有很强的优化能力”。 [9] 图灵奖得主Geoffrey Hinton在演讲中有提到，如果让AI去最大化实现其目标，一个合适的子目标可能就是寻求更多的影响力、说服人类或拿到更多的金钱等，但这一过程是否安全，权力攫取到达什么程度需要被注意到，以及如果给予AI足够大的政策空间是否会带来人类无法接受的后果等一系列问题都值得关注。</p><p>诸多AI大模型公司在此问题上都有所进展。例如Deepmind的团队从规则博弈 （specification gaming） 以及目标错误泛化 （goal misgeneralization） 的技术原因出发，探讨威胁模型怎么通过权利寻求 （power seeking） 或者通过不同系统之间的交互对人类社会产生影响。 [10] OpenAI治理团队的Richard Ngo在论文中分析了为什么在奖励错误和情景感知之后会发展出奖励作弊，神经网络策略如何寻求到错误的子目标，范围广泛的错误对齐目标如何在部署期间导致不必要的权力寻求行为 （power-seeking during deployment） ，以及为什么在训练期间会产生分布偏移 （detectable distributional shift） 和欺骗性对齐 （deceptive alignment） 等问题。这一系列分析体现了AI在与人类社会互动过程中可能产生的诸多风险。 [11]</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_26220d6e75604d18916d1f5d4976bba1@000000_oswg133892oswg754oswg644_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图6</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_8ed96680554d45029707da2f349b7384@000000_oswg79122oswg558oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图7</p><h2>价值对齐问题的解决思路</h2><p>针对上述风险模型的具体解决方案，并非聚焦于如何训练更强大的模型，相反更强大的模型可能具有更大的风险，因此我们应考虑怎样在不加剧风险的情况下尝试解决问题。以下介绍目前AI价值对齐社区比较关注的四个主要方向。</p><p><strong>（一）基于人类反馈的强化学习（Reinforcement Learning from Human Feedback，RLHF）</strong></p><p>从人类反馈中进行强化学习是一种训练人工智能系统与人类目标相一致的技术，RLHF已成为优化大型语言模型的重要方案。尽管该方法备受关注，但对其缺点的系统化整理相对较少。来自苏黎世联邦理工学院计算机系人工智能方向的陈欣博士Cynthia今年发表的论文即聚焦于RLHF的一些开放问题及其根本性的局限，通过将其学习过程解构为三大类，即从人类反馈 （human feedback） 训练奖励模型 （reward model） 、奖励模型训练策略模型 （policy） 、及其间形成的循环 （loop） 出发，进一步将具体问题拆解为14个可解决的问题和9个更根本性的问题。 [12] 因此，第一类解决思路是当未来出现了非常强大的优化算法或更强大的大语言模型时，我们应如何定义一个正确的目标让AI做正确的事情？这一思路存在如下三方面问题。</p><p><strong>一是人类反馈的问题（Challenges with Human Feedback）。</strong>可靠且高质量的人类反馈有利于后续的奖励建模和策略优化。一方面，选择有代表性的人并让他们提供高质量的反馈是很困难的；有些评估者可能怀有有害的偏见（harmful bias）和观点；个别人类评估员可能会篡改数据；由于时间、注意力或关注度有限，人类会犯一些简单的错误；部分可观察性（partial observability）限制了人类评估员；以及数据收集本身也可能带来偏见。上述问题相对可解决，另外还存在更加根本性的问题，即人类认知的局限性使得无法很好地评估模型在困难任务上的表现；而且人类可能会被误导，因此他们的评估一定程度上可能会被操控。另一方面，算法本身也可能存在问题，比如在收集人类反馈时，需要对成本和质量进行权衡；RLHF不可避免地要在反馈的丰富性和效率之间做出权衡等。</p><p><strong>二是奖励模型的问题（Challenges with Reward Model）。</strong>奖励建模的目标是将人类反馈映射到合适的奖励信号上。但是奖励模型即使从正确标注的训练数据出发，也可能出现归纳错误；而且评估奖励模型的过程既困难又昂贵。有一个比较经典的例子来源于OpenAI早期的一项研究，即一个被训练为抓取小球的人工智能手臂，在成功抓起时可以获得奖励。然而它却学会了使用视线错觉作弊，即当机械手臂移动到小球与摄像机之间，就展示出小球被成功抓起的错觉。从人类的角度来说，它一方面利用了人类视觉上的漏洞，另一方面奖励模型也确实学习到了不正确的任务，这是一个比较难解决的问题。不过更根本的问题是，奖励函数 （reward function） 难以代表人类个体的价值观；单一的奖励函数又无法代表多样化的人类社会；对不完善的奖励代理进行优化还可能会导致奖励作弊 （reward hacking） 。因此如何让奖励函数与广泛的人类社会进行更好的互动值得进一步研究。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_ec7670d46ac44f829b204c31c758386a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图8</p><p><strong>三是策略模型的问题（Challenges with the Policy）。</strong>一方面，对策略模型（policy）而言，高效地优化强化学习是一件困难的事情；输入对抗样本情况下，策略模型可能会被反向利用；预训练模型会给策略优化带来偏差；强化模型可能会出现模式坍缩（mode collapse）。这里更根本的问题是即使在训练过程中看到的奖励完全正确，策略在部署过程中也可能表现不佳；而最佳强化学习代理则倾向于寻求权力（power seeking）。另一方面，当我们考虑到奖励函数的学习后，在联合训练（joint training）的同时优化一个策略模型可能会带来一系列问题。例如这一过程可能会导致分布转移；很难在效率和避免策略过度拟合之间取得平衡。这里更根本的问题是优化不完美的奖励代理会导致奖励作弊（reward hacking）。</p><p>总而言之，RLHF目前仍存在诸多问题，值得世界各地学者进一步展开研究。同时正是由于RLHF本身存在很多根本性问题，单纯依靠这一解决思路可能不足以解决AI价值对齐领域的所有问题，我们还需要其他方向的研究来共同解决这一问题。</p><p><strong>（二）可扩展监督（Scalable oversight）</strong></p><p>第二类解决思路为可扩展监督 （scalable oversight） ，即如何监督一个在特定领域表现超出人类的系统。人们要在AI所提供的看似具有说服力的反馈中分辨出不真实的内容需要花费大量时间和精力，而可扩展监督即旨在降低成本，协助人类更好地监督人工智能。 [13] 2018年Paul Christiano在播客中表示相较于开发可扩展监督技术，AI系统所有者可能更倾向于通过设定容易评估的目标来获得更高的利润，例如引导用户点击按钮、吸引用户长久在网站停留等，但这一做法是否真的对人类社会有利则有待考量。 [14]</p><p>关于可扩展监督比较典型的例子包括辩论 （debate ） 、递归奖励建模 （recursive reward modeling） 、迭代放大 （iterated amplification） 等。Geoffrey Irving等人在论文中提出了通过零和辩论游戏的自我对局方式来训练智能体。即由两个AI代理针对给定的问题或建议行动轮流作出简要陈述直到回合尽头，人类来判断哪个代理的信息最真实、最有用。 [15] Jan Leike等人在论文中提出使用“奖励建模”进行对齐的两个步骤：首先从用户的反馈中学习奖励函数，其次通过强化学习训练策略优化奖励函数，即将学习“做什么”与学习“怎么做”区分开来，最终希望将奖励建模扩展到人类无法直接评估的复杂领域。 [16] Paul Christiano等人提出“迭代放大”的对齐方案，即通过将任务分解为更简单的子任务的方式，而不是通过提供标记数据或奖励函数的方式帮助人类完成超出其能力的复杂行为和目标。 [17]</p><p>目前一种比较容易理解的框架是“Propose &amp; Reduce”。 [18] 举个例子，如果你希望AI生成一篇对于书籍或者文章的优秀总结，首先第一步是生成一系列的候选项 （proposal） ，然后从候选项中去选择较好的总结，而这一选择过程就可以进一步使用AI的总结能力，将对应内容进一步简化，使得当前的问题简化 （reduce） 为在人类能力范围内比较容易解决的问题。即AI协助人类完成任务，人类通过选择对AI的训练进行监督。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_a81ce2712f264529931ae665434485df@000000_oswg136952oswg720oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图9</p><p>此前OpenAI还发布了其训练的“批评写作”模型 （“critique-writing” models） ，该模型可以帮助人类评估者注意到书籍摘要的缺陷，实验结果表明辅助人类在摘要中发现的缺陷比无辅助评估者多了50%，这一数据展示了AI系统协助人类监督AI系统完成困难任务的前景。 [19] 另外Anthropic的研究和OpenAI的思路类似，即单纯依靠人类或者模型完成任务的结果平平无奇，但如果让模型辅助人类完成任务，其准确率获得了大幅度提升。 [20] 虽然最终数据与领域专家相比仍存在进步空间，但这一结果足以令人欣喜，我们期待着在这一方向看到更多理论或实验的详细研究。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_2947693ff2fb4577b1e9808582b3836b@000000_oswg44098oswg534oswg428_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图10</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_0c2bff49e2f74c56a17e53dffc084915@000000_oswg40193oswg768oswg336_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图11</p><p>今年7月，OpenAI宣布成立一个新的超级对齐团队（Superalignment），这只由Jan Leike（对齐负责人）和Ilya Sutskever（OpenAI联合创始人兼首席科学家）领导的队伍称将投入20%的算力资源，目标是在4年内解决超智能AI系统的价值对齐和安全问题。Jan Leike在采访中表示希望尽可能将进行对齐工作所需的任务转交给一个自动化系统，因为评估往往比生成更容易，而这一原则即为可扩展监督理念的核心。</p><p><strong>（三）可解释性（Interpretability）</strong></p><p>第三类解决思路为可解释性问题。可解释性是指以人类可理解的方式解释或呈现模型行为的能力，这是保证模型安全的重要途径之一。Google Brain的Been Kim曾在演讲中提到“可解释性”并非为了一个明确的目标而存在，而是为了确保安全等问题能因可解释性本身得到保障。[21]可解释性研究通常可以从两个角度展开，即透明性（transparency）和可说明性（explainability），前者强调大模型的内部运作机理，而后者用于揭示模型为什么会产生某种预测结果或行为。[22]就像拆解一台计算机一样，“可解释性”使得研究人员得以探究系统模型内部在发生什么，发挥了什么作用，从而识别风险的可能来源。现实中，商用大模型不开源等现象也在客观上增加了可解释性研究的难度。</p><p>进一步而言，上述“透明性”和“可说明性”可以理解为“模型的可解释性”与“决策的可解释性”。就“模型”而言，大语言模型的“黑箱”属性一直困扰着研究者。AI大模型同人脑类似，由神经元组成，因此要开展可解释性研究理论上应先“解剖”模型，了解AI模型的各个神经元在做什么。然而在动辄成百上千亿参数的神经网络面前，传统人类通过手动检查神经元的方案显然已经无法实现了。OpenAI创新性地提出一项方案，即为何不让AI去解释AI呢？于是其团队使用GPT-4来生成神经元行为的自然语言解释并对其进行评分，然后将此过程应用于实验样本GPT-2中，从而迈出了AI进行自动化对齐研究的第一步。[23]但无论如何，在短期内追求模型内部每个步骤均可解释并不是一项合理的诉求。与之相对，“决策的可解释性”更注重结果的呈现，模型只需要为其提供的最终决策提供可经推敲的详细原因即可。当然，在此过程中也可以尝试用大模型解释大模型的方式，诱导其逐步呈现其逻辑。</p><p>从对象范围来看，“可解释性”可以分为“全局可解释”（global interpretability）与“局部可解释”（local interpretability）。“全局可解释”侧重于理解模型是如何基于整个特征空间或模型结构以及特征之间的相互作用得出预测结果的，一般基于平均值水平；而“局部可解释”更关注单一样本的情况，分布多为线性，可能相较“全局可解释”更准确。[24]‍‍‍‍</p><p>在尝试通过更好地了解机器学习模型以减轻相关风险时，一个潜在有价值的证据来源是判定哪个训练样本对模型的给定行为的贡献最大。对此，Anthropic的研究人员利用影响函数（influence functions）作出回答：即将给定序列加入训练集时，观察大模型的参数与输出会作何变化。通过结果呈现的红色深浅程度对比可以尝试解释输入（input）中的哪一个关键词对于模型的输出（output）产生了更大的影响。[25]</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_65383c940287490d945748d5c1bdc9b3@000000_oswg52193oswg614oswg320_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图12 ‍ ‍</p><p>近年来，关于AI对齐可解释性还有一个不可忽视的研究方向，即机械可解释性（mechanistic interpretability），此研究旨在对神经网络进行逆向工程，类似于对编译的二进制计算机程序源代码进行逆向工程。研究员Neel Nanda针对该领域提出了200个具体开放问题。[26]不过鉴于神经网络结构的复杂性与逆向工程的高难度性，现行研究多在简化的玩具模型（toy models）上展开。[27]除此之外，解释算法问题（Algorithmic problems）、多语义（Polysemancity）和模型叠加问题（Superposition）等都是“可解释性”研究可能涉及的重要议题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_82a1d808fc2440e4ab5539e8700aac12@000000_oswg81116oswg636oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图13</p><p><strong>（四）治理（Governance）</strong></p><p>最后一类解决思路与政策治理相关。因为AI价值对齐问题最终还是关系于人类社会，我们需要探讨人工智能治理对社会产生的影响，以及在此过程中，技术社区和政策社区可以形成什么样的互动等问题。一方面，我们承认技术研究能够为AI治理提供坚实可靠的理论支撑；另一方面，为了确保人工智能的安全和健康可持续发展，我们反对“技术决定论”，坚持以人为本，科技向善。值得注意的是，AI治理不仅仅关涉政府层面，同时也包括企业、机构等广泛领域，这是关系到整个社会如何看待和管理技术本身的问题。</p><p>当前，生成式AI的伦理和安全治理，已经成为了全球AI领域的共同议题，各国政府开始探索治理措施。视角聚焦国外，欧盟《人工智能法案》引入基于风险的方法，对AI施加不同程度的监管要求。该法案在欧洲引起了强烈反对，超过150位欧洲企业高管签署公开信，认为该立法草案将危及欧洲的竞争力和技术主权（尤其是在生成式AI领域），而无法有效应对所面临的挑战，并呼吁欧盟重新考虑其AI监管计划。与之相比，美国更强调AI的创新和发展，倾向于通过组织自愿适用的指引、框架或标准等方法对AI应用采取软治理，发布了《AI风险管理框架》《AI权利法案蓝图》等自愿性标准；在生成式AI领域，白宫政府推动OpenAI、亚马逊、Anthropic、谷歌、微软、Meta（原Facebook）、Inflection等领军的AI企业就“确保安全、安保和可信AI”（ensuring safety, secure, and trustworthy AI）作出自愿性承诺，呼吁AI企业开发负责任的AI，确保其AI产品是安全可靠的。而日本、韩国等国家将“以人为本”作为人工智能治理的首要价值，体现了浓厚的伦理导向。视角转向国内，我国《生成式人工智能服务管理暂行办法》坚持发展和安全并重，促进创新和治理相结合，实行包容审慎和分类分级的监管举措，期望能够提高监管的高效性、精确性和敏捷性。</p><p>在“技术”与“规范”的互动和关联之间，各个大模型公司也提出了他们的考虑和对策，并采取了相应的AI治理措施，如用户违规行为监测、红队测试、伦理影响评估、第三方评估、模型漏洞奖励、内容来源工具等多种方式。Deepmind的政策团队此前提出了一个模型，即考虑到人工智能系统对于人类社会的风险，除了模型本身存在的技术性风险之外，还需要关注技术滥用所带来的风险。[28]Anthropic在今年9月份发布了负责任的扩展政策（Responsible Scaling Policy，RSP）[29]，即采用一系列技术和组织协议，旨在帮助管理开发功能日益增强的AI系统的风险。其基本思想是要求遵守与模型潜在风险相适应的安全操作标准，越强大的模型越需要精确和缜密的保障措施。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_6adbe2a912ca4bff9d4285021c90bb2f@000000_oswg68720oswg762oswg274_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图14</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_2f4e651977474ad5ab785900bdf44525@000000_oswg121032oswg986oswg556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图15</p><p>此外，在行业层面，OpenAI、Anthropic、微软、谷歌发起成立新的行业组织“前沿模型论坛”（Frontier Model Forum），确保“安全地、负责任地”开发部署前沿AI模型。前沿AI模型是指比当前的AI大模型更加先进、强大的，并且可以执行广泛任务的大规模机器学习模型。具体而言，“前沿模型论坛”的主要目标包括：促进AI安全研究，提出最佳实践做法和标准，鼓励前沿AI模型的负责任部署，帮助开发积极的AI应用（如应对气候变化、检测癌症），等等。</p><p>面向未来，对生成式人工智能的有效监管和治理，离不开政府、企业、行业组织、学术团体、用户和消费者、社会公众、媒体等多元主体的共同参与，需要更好发挥出多方共治的合力作用，推进践行“负责任人工智能”（responsible AI）的理念，打造安全可信的生成式AI应用和负责任的AI生态。</p><h2>AI价值对齐的有关争议</h2><p>今年5月份，一封由包括多伦多大学计算机科学荣誉教授Geoffrey Hinton、蒙特利尔大学计算机科学教授Yoshua Bengio、Google DeepMind首席执行官Demis Hassabis、OpenAl首席执行官Sam Altman和Anthropic首席执行官Dario Amodei等在内的350多名高管、研究人员和工程师签署的公开信引发热议，信中表示人工智能对人类的风险，与大规模流行性疾病和核战争相当。</p><p>当然，人们对于未对齐的AI（包括AGI）可能带来人类存亡风险（Existential Risk，X-Risk）的担忧并非完全杞人忧天。越强大的AI系统越可能进化出自主性，越难以对其进行监督和控制。没有人敢断言AI的权力寻求（power-seeking）倾向不会给人类带来灭顶之灾。也正是基于上述担忧，未来生命研究所（future of life）此前向全社会发布了《暂停大型人工智能研究的公开信》（Pause Giant AI Experiments：An Open Letter）。</p><p>对此，亦有很多科学家提出反对意见。比如波特兰州立大学计算机科学教授Melanie Mitchell和Facebook人工智能实验室负责人Yann LeCun等人认为AI风险问题不应该上升到这一高度讨论，我们更应该将有限的资源集中在现有的威胁上，聚焦AI当前所产生的实际问题，解决具体的困难。随着争端不断加剧，有人表示这是科技公司的炒作，其旨在从冲突中获益；有人指出当前关于AI风险的讨论都是没有科学依据的猜测；有人认为灭绝言论分散了人们对真正问题的注意力，阻碍了对AI的有效监管；人工智能公司Conjecture首席执行官Connor Leahy在Twitter称其对生存风险的担忧持保留态度，相较靠嘴巴争论，行动更重要。</p><p>今年6月份，芒克辩论会 （Munk Debates） 即邀请了上述部分争议方就AI研究和发展是否构成人类生存威胁问题进行了辩论，辩论前有67%的观众认为存在威胁，而33%的观众认为不存在，辩论后有63%的观众认为存在威胁，而37%的观众认为不存在。因此，尽管反方的支持率有所提升，但大部分观众听完辩论后仍然认为AI研究和发展会构成X-Risk威胁。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_c19fec7586244451ab88ccba998fbd62@000000_oswg195284oswg832oswg306_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图16</p><p>产生上述分歧的主要原因可以归结于以下三种情况：首先是大家对于AI可能带来的最坏的情况上观点不一致；其次是大家对这一问题在时间维度上的看法不一致，例如有的学者是从三五年之内看待AI对齐问题，而有的学者是从几十年的时间尺度进行衡量；最后是大家对于风险承受能力的衡量不一致，比如对于人类社会可以作出多大程度的牺牲来承担AI发展的风险这一比例在接受程度上存在差异。不过需要注意的是，人们对于AI风险的所有探讨和辩论并非旨在宣扬AI“宿命论”，而是强调在致力于发展AI的同时，更要重视AI的安全。</p><h2><strong>结语</strong></h2><p>此刻，我们站在AI发展的十字路口，科幻电影的画面正逐步走向现实，当下的任何一项抉择都关乎人类的未来。在这一场与时间的赛跑中，多考虑一些总不会有错。因此，尽管AI价值对齐是一项难题，但辩以明志，广泛的争议和讨论将引领我们踏上正确的路。只有聚合全球资源，推动广泛学科协作，扩大社会参与力量，让政界、学界、商界等诸多利益相关方参与到价值对齐的理论研究和实践过程中来，才能打造对齐共识，确保人工智能造福人类社会。我们也相信，人类终将获得最终的掌控权。</p><p><strong>作者简介：</strong></p><p><strong>曹建峰，</strong>腾讯研究院高级研究员</p><p><strong>陈欣，</strong>苏黎世联邦理工学院计算机系在读博士</p><p><strong>要苏慧，</strong>腾讯研究院实习生</p><p><strong>参考资料来源:</strong></p><p>[1]Wiener, N. (1960). Some Moral and Technical Consequences of Automation: As machines learn they may develop unforeseen strategies at rates that baffle their programmers.&nbsp;Science,&nbsp;131(3410), 1355-1358.</p><p>[2]Paul Christiano. (2018). Clarifying&nbsp;“AI alignment”.</p><p>[3]Di Langosco, L. L., Koch, J., Sharkey, L. D., Pfau, J., &amp; Krueger, D. (2022). Goal misgeneralization in deep reinforcement learning.</p><p>[4]Zou, A., Wang, Z., Kolter, J. Z., &amp; Fredrikson, M. (2023). Universal and transferable adversarial attacks on aligned language models.</p><p>[5]Pan, A., Bhatia, K., &amp; Steinhardt, J. (2022). The effects of reward misspecification: Mapping and mitigating misaligned models.</p><p>[6]Perez, E., Ringer, S., Lukošiūtė, K., Nguyen, K., Chen, E., Heiner, S., ... &amp; Kaplan, J. (2022). Discovering language model behaviors with model-written evaluations.</p><p>[7]Park, P. S., Goldstein, S., O'Gara, A., Chen, M., &amp; Hendrycks, D. (2023). AI Deception: A Survey of Examples, Risks, and Potential Solutions.</p><p>[8]Berglund, L., Stickland, A. C., Balesni, M., Kaufmann, M., Tong, M., Korbak, T., ... &amp; Evans, O. (2023). Taken out of context: On measuring situational awareness in LLMs.</p><p>[9]Jacob Steinhardt. (2023). Emergent deception and emergent optimization.</p><p>[10]Kenton, Z., Shah, R., Lindner, D., Varma, V., Krakovna, V., ... &amp; Catt, E. (2022). Clarifying AI X-risk.</p><p>[11]Ngo, R., Chan, L., &amp; Mindermann, S. (2022). The alignment problem from a deep learning perspective.</p><p>[12]Casper, S., Davies, X., Shi, C., Gilbert, T. K., Scheurer, J., Rando, J., ... &amp; Hadfield-Menell, D. (2023). Open problems and fundamental limitations of reinforcement learning from human feedback.</p><p>[13]Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., &amp; Mané, D. (2016). Concrete problems in AI safety.</p><p>[14]Wiblin, Robert. (2018). Dr Paul Christiano on how OpenAI is developing real solutions to the ‘AI alignment problem’, and his vision of how humanity will progressively hand over decision-making to AI systems.</p><p>[15]Irving, G., Christiano, P., &amp; Amodei, D. (2018). AI safety via debate.</p><p>[16]Leike, J., Krueger, D., Everitt, T., Martic, M., Maini, V., &amp; Legg, S. (2018). Scalable agent alignment via reward modeling: a research direction.</p><p>[17]Christiano P, Shlegeris B, Amodei D. (2018). Supervising strong learners by amplifying weak experts.</p><p>[18]Ruiqi, Z. (2023). Getting AI to Do Things I Can’t: Scalable Oversight via Indirect Supervision. (Talk)</p><p>[19]OpenAI. (2022). AI-written critiques help humans notice flaws.</p><p>[20]Bowman, S. R., Hyun, J., Perez, E., Chen, E., Pettit, C., Heiner, S., ... &amp; Kaplan, J. (2022). Measuring progress on scalable oversight for large language models.</p><p>[21]Been Kim. (2017). Interpretable Machine Learning: The fuss, the concrete and the questions..</p><p>[22]Critch, A., &amp; Krueger, D. (2020). AI research considerations for human existential safety (ARCHES).</p><p>[23]OpenAI. (2023). Language models can explain neurons in language models.</p><p>[24]Molnar, C. (2020). Interpretable machine learning. Lulu. com.</p><p>[25]Grosse, R., Bae, J., Anil, C., Elhage, N., Tamkin, A., Tajdini, A., ... &amp; Bowman, S. R. (2023). Studying Large Language Model Generalization with Influence Functions.</p><p>[26]Nanda, N. (2022). 200 Concrete problems in mechanistic interpretability.</p><p>[27]Elhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan, T., Kravec, S., ... &amp; Olah, C. (2022). Toy models of superposition.</p><p>[28]Shevlane, T., Farquhar, S., Garfinkel, B., Phuong, M., Whittlestone, J., Leung, J., ... &amp; Dafoe, A. (2023). Model evaluation for extreme risks.</p><p>[29]Anthropic. (2023). Anthropic's Responsible Scaling Policy.</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&amp;mid=2650972546&amp;idx=1&amp;sn=f49122d1a3ea6b418ed18b5359a6f389&amp;chksm=bcc9eef08bbe67e6e23981b2eb0f581af858a24c3a4f6f1070dad8e6e721092534c4a5a82964&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“腾讯研究院”（ID：cyberlawrc）</a>，作者：曹建峰 等，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2469819088984194</id>
            <title>新品定价超2000元，系列已售15万台，一款智能摄像头想替代专业摄影师丨产品观察</title>
            <link>https://www.36kr.com/p/2469819088984194</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2469819088984194</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 03:27:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 文丨肖千平, 编辑丨袁斯来, AI摄像头, 寻影Tiny2
<br>
<br>
总结: 寻影Tiny2是一款定价2199元的AI摄像头产品，能够对焦、懂构图、实时跟踪，并输出高画质影像。它由睿魔智能推出，该公司从2016年开始致力于影像自动采集设备的研发。Tiny2在图像质量和智能拍摄能力上进行了改进，能够满足特定场景的拍摄需求。尽管面临竞争和质疑，但寻影Tiny2在市场上取得了不错的销售成绩。 </div>
                        <hr>
                    
                    <p>文丨肖千平</p><p>编辑丨袁斯来</p><p>帮助机器人替人，一直是AI技术最诱人的未来想象之一。在影像行业，一款定价2199元的摄像头正计划替换专业摄影师。</p><p>会对焦，懂构图，能实时跟踪，并且能够输出高画质影像——这是「OBSBOT寻影」（以下简称「寻影」）新近在国内上线的AI摄像头产品，寻影Tiny2。</p><p>“视频制作中，拍摄和后期的人力占比非常重，又多是重复项目……这个事情可以被自动化、被机器化。”寻影背后厂商「睿魔智能」创始人刘博告诉36氪。拍摄和后期最关键的是影像采集，可以由算法和硬件完成。</p><p>为此，睿魔智能从2016年开始向影像自动采集设备进军。这个出身浙大、自东莞松山湖机器人基地孵化的团队，连续推出寻影Meet系列、Tiny系列等影像自动采集产品，并于今年3月完成招银国际领投、香港X科技基金等跟投的C轮融资。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_b976e22f80d746d79b310132c2202fbd@5831026_oswg196457oswg1516oswg442_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">寻影系列产品，图源企业官网</p><p>这个看似小众细分的领域，却带来不错的回报。寻影首代产品Tail发布即售罄，Tiny系列在全球范围内累计销售15万台；2022年，睿魔智能营收增长40%。今年新开拓的国内市场，目前在抖音的日均销售额也超过10万元。</p><p>当然，这已经不是一片轻松的战场。一方面，影像及数码硬件大厂虎视眈眈，同样对这一细分赛道展开布局；另一方面，海外的网络摄像头（Webcam）市场也从疫情期间的狂飙归于冷静。在这个节点上推出一款新品，还能在哪些方面打出差异点？又是否还是一个好策略？</p><h2><strong>性能再打磨</strong></h2><p>寻影的高价在网络摄像头中并不多见。</p><p>亚马逊Webcam类目中，多数产品价格在百元美金以下，而Tiny2的售价直接达到329美金，Tiny系列其他产品价格也基本超过200美金。对于Tiny2如此高的售价，寻影的解释集中在图像、声音质量，以及摄像头的场景构图能力上。</p><p>其中，图像质量最直观可感，来自硬件层面的加大投入。据寻影介绍，Tiny2使用的CMOS传感器尺寸达到1/1.5英寸，这也是国内目前电脑摄像头领域最大尺寸。此外，双原生ISO 技术的引入，则降低了对摄像过程中对打光的要求，无论光源强弱、位置高低等，均可以保证较稳定的画面输出。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_4dc9253af0ba456db5fc8a8540304378@5831026_oswg494368oswg1280oswg305_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Tiny2对画面输出的改进（左），图源企业官网</p><p>在图像画面上，睿魔的追逐对象是单反相机。这或许能一定程度上解释Tiny系列的热销：它的画质足够优秀，在非专业人士肉眼难以分辨差别的情况下，而定价只有单反相机约三分之一。</p><p>画质之外，更重要的是智能拍摄能力：用一台机器完成以往靠多人、专业团队实现的摄影效果。在这一点上，<strong>Tiny2在Tiny系列原有的追踪、自主构图基础上，增加了更多面向具体场景的功能。</strong></p><p>譬如功能之一轨迹跟踪，在画面需要半身镜等特殊布局时，不仅能够保持拍摄对象在画面中央，还能通过自动变焦，保证稳定的画面布局。</p><p>譬如功能之一轨迹跟踪，在画面需要半身镜等特殊布局时，不仅能够保持拍摄对象在画面中央，还能通过自动变焦，保证稳定的画面布局。</p><p>落实到应用中，这种对于特定场景的主动拍摄，可以实现直播弹琴、画画过程中对手部的追踪。同时，对静物特写的遥控功能，则能够做到“指哪拍哪”，满足白板拍摄等场景的需求。——上述种种功能，在常规的直播、录制等场景下，通常需要摄影师持专业设备跟拍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_11c627452f654cc1a3b2ec94404cb062@5831026_img_gif?x-oss-process=image/quality,q_80" /></p><p class="img-desc">Tiny2能够主动追踪手势，满足白板拍摄等场景。企业供图</p><p>然而质疑的声音的确存在，包括摄像头的智能功能究竟价值几何、4k画质是否存在性能浪费等。要回应这些问题，还需要回溯寻影对产品的设计和定义。</p><h2><strong>&nbsp;“教训”之后，平衡产品与需求</strong></h2><p>“过分超前。”刘博这样评价公司首代产品Tail。</p><p>Tail推出之前，市面上摄像头的智能改进仍主要集中在手持舒适性、辅助操作等。而Tail则是一款能够跟踪、远程交互的摄像机产品，这也可以看作是睿魔智能此后系列产品的雏形。然而，由于产品定位、市场认知等因素，这款在2019年推出的产品，直到2020年才迎来口碑爆发，但此时Tail已经全网断货。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_ac3733da0eb7463cb1836a60e13f0ccb@5831026_oswg111156oswg400oswg396_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">寻影首代产品Tail，一款自导演AI摄像机，图源企业官网</p><p>热度和产品的尴尬错位，暴露的问题是：目标客群在特定阶段的需求究竟是什么？回答这个问题，也成为睿魔智能近两年的发力方向之一。 &nbsp;</p><p>现如今对于海外市场，寻影将其划分为办公、教学及直播三大场景，每一场景内的人群、使用习惯等都存在差异。为了把握不同用户群体诉求，寻影与不同场景深度用户访谈交流，了解使用痛点，并在Tiny2中针对性地改进。</p><p>例如，同样是实时传输影像，教育用户对于智能拍摄功能就存在更强烈的需求，具体体现在需要摄像头针对板书、走动等教学过程的及时跟踪；此外，Tiny2在白板模式下对画面中白板画面的自动特写，也是这部分使用者的强诉求之一。相比之下，直播用户就更看重影像画质、安装简易性等，需要一款即插即用、无需加装驱动，同时画质更高的产品。</p><p>在国内市场，面对直播这样迅速火热的新行业，寻影更需要挖掘出用户隐秘、真实的诉求。 “很多公司在做电商直播，但对声光电的搭建未必专业。”睿魔智能CMO介绍道。“大部分人的要求就是简单，随便打光就能出来好看的画面。”</p><p>上述这批体量庞大的非专业级直播商户，也解释了Tiny2的升级方向：对于这一群体，成像能力、打光效果等，直接关系着商品展示情况，进而影响销售；作为寻影立身之本的智能拍摄能力，则通过稳定画面、加强跟踪等，进一步降低搭建直播的成本，减轻对人力的依赖。</p><p>即便如此，竞争局面已经摆在眼前。寻影也承认，相比首代产品Tail推出时智能摄像头的市场空白，近年来具有自动跟踪、聚焦等功能的摄像头已不再是新鲜事，寻影并不敢因为一个爆品有丝毫松懈。</p><p>相应地，无论是领域内KOL自发的产品测评，或寻影更多口碑营销动作，都更加集中在智能摄像头这一细分品类下的影响力搭建。最直观的成效是，同价位Webcam产品中，寻影的市场份额不输业内大厂；此外，将于年底在海外正式发行的另一新品Tail Air，仍然定位高端产品线，初步定价800美金，现已众筹超过100万美金。</p><p>当然，寻影作为一个技术起家的年轻品牌，如何应对体量与名气更大的厂商入局细分赛道，仍然是需要探索解决的问题。但对于一家初创企业，这或许又显现出一重优势：切口更小，但扎根更深。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470724669742980</id>
            <title>勒紧腰带的汽车人</title>
            <link>https://www.36kr.com/p/2470724669742980</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470724669742980</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 01:29:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 员工, 车企, 降本, 奖金
<br>
<br>
总结: 车企为了降低成本，对员工进行了多方面的削减，包括限制空调使用、缩减福利和奖金、裁员等措施。这些举措使得员工感受到了压力和不确定性，同时也反映了车企在当前竞争激烈的市场环境下，为了保持竞争力而采取的紧缩措施。 </div>
                        <hr>
                    
                    <blockquote><p><strong>在喊破喉咙打破头、拼命争抢市场份额的同时，车企们勒紧腰带，希望顺利“苟”到下半场。汽车终端每降一次价，最终都要体现在打工人的奖金缩水、升职延缓和裁员缩招上。</strong></p><p><strong>除了在员工身上抠抠缩缩，车企在自身运营上也束手束脚，并且降本的压力还在不断地向上游供应商传导。两年前还如火如荼的汽车赛道，温度好像一下子降了下来，刺骨的冷风吹向了行业里的每一个人。</strong></p></blockquote><h2>空调风热了，打印纸灰了，HC早就冻结了</h2><p>伴随着夏天到来的，不是凉风，却透着让整个行业激灵一下的凉意。</p><p>今年5月份，某合资车企的员工李弈偶然发现，公司的空调开关处多了一张A4纸通知，要求夏天空调温度控制在28℃，并且在气温低于35℃时，仅仅允许上午和下午各开两个小时空调，落款是公司人事部门。</p><p>此前李弈觉得办公室空调“永远冻死人”，夏天甚至需要披个外套，但在新的“空调限令”颁布之后，尤其是持续攀上40℃的高温天，“坐半个小时就满头大汗了”。这个难捱的夏天，让李弈和同事们清晰地感受到，年初公司因为“看空汽车行情”而被砍掉的预算，具体分配到了哪里。</p><p>今年初，研发工程师陈珂所在的大型国有车企也开始强调关空调和熄灯，“甚至有专人检查”。一向业绩不错的大公司开始“抠”这样的小事，这不是一个令人安心的信号。在那之后，陈珂发现公司甚至开始限制彩印，“取消了我们这一层的彩印机”，并在通知中直接点明“应集团降本增效要求”。</p><p>更能让车企打工人有切身体会的是福利和奖金的缩水。</p><p>蔚来员工陈颖告诉每人Auto，今年之前，如果遇到“电脑有点卡”这样的问题，员工可以直接申请换个笔记本，但“现在不行了”。新人入职培训的预算也在缩减，“之前是去外地，去年公司包下苏州喜来登，今年直接在上海和合肥的园区里办了”。</p><p>五菱员工林晚意今年参加公司体检时，发现项目较往年少了很多项。除此之外，奖金也开始缩水，之前每个季度的销售额都达标的话，每位员工在每个季度都会拿到一笔激励奖金，往年上半年起码发两次，今年上半年五菱汽车总收入较去年同期减少18.9%，“到目前为止今年激励奖金还没发过”。</p><p>除去直接的奖金变化，林晚意发现定期涨薪也成为一件不确定的事。工资等级评定卡在马上要申报的时间节点，又增加了很多新规定，她觉得“明摆着就是不想让大多数人升级”。</p><p>也是从年初开始，陈珂发现领导总是有意无意地暗示，希望大家工作再努力一点，“大环境不太好”“招新名额和待岗名额都比较紧张”，并且一直强调“可能会实行末位淘汰”，以此来满足减员需求。</p><p>向来以“铁饭碗”著称的国企，本身人员变动的概率并不大，出现这种频繁的提示，在陈珂看来无非是公司降本增效下的手段——想以此来提高人效。</p><p>除此之外，陈珂还发现今年公司的招新名额少了很多，“很多实习生因为没有名额所以没办法转正”。六七月份的时候，公司破天荒地还有过一轮裁员。</p><p>李弈所在的公司从年初定下预算就开始裁员，“要求是裁20%”，把外包的服务商工程人员全部砍了，HC（招聘名额）也早就冻结了。</p><p>今年上半年，车企裁员消息一个接着一个。3月，天际汽车宣布部分岗位停工停产，期间将以长沙最低工资标准发薪，鼓励员工自谋出路。5月，福特中国曝出裁员，其中福特中国与福特南京研发中心裁撤超1300人，长安福特裁员人数更多，约3000人。同月，极星也以“降低运营成本”的缘由，宣布冻结全球招聘并裁员10%；悦达起亚安排管理岗员工分批次“轮休”。</p><p>“今年落差格外大。”汽车行业猎头叶舒感慨，行业招聘规模和整体薪资待遇都有很大程度的下滑，“去年下半年开始，滴滴汽车事业部已经完全没有猎头岗了。今年开始，小鹏也取消了猎头岗”。</p><p>这样的环境下，车企打工人想靠跳槽涨薪也格外难，“拿长城来举例，（员工）在保定薪资不算很高，两年前长城的候选人想跳到‘蔚小理’，足够优秀的能拿到翻倍的薪资，现在估计跳都跳不过去”。</p><p>车企对于人才的筛选肉眼可见地严格起来。另一位汽车行业猎头告诉每人Auto，现在车企招聘需要候选人和岗位匹配度特别高才行，在她看来，“企业不着急用人”。</p><p>叶舒补充说，人力预算紧缩的情况下，车企对于候选人学历和经历背景的审视，都变得更加慎重。一些传统车企在智能化方面稍弱一些，从那里出来的候选人，也会被下家车企贴上“工作背景差”的标签。</p><h2>束起手脚做事</h2><p>在员工身上“抠抠缩缩”，省下的大多是小钱。真正的大头，还得从车企运营的方方面面抠回来。</p><p>去年10月，特斯拉关闭了北京侨福芳草地门店，那也是这家跨国新能源汽车巨头在中国的第一家门脸。据界面新闻报道，特斯拉销售称闭店原因是租约到期没有续签，而业内很多声音猜测此举旨在降低成本。截至目前，特斯拉官方并未对此做出回应。</p><p>在购物中心卖车，是特斯拉十年前开始带火的潮流，直营店模式也一度成为造车新势力们区别于传统车企的标志。但无论是购物中心带来的客流量，还是直营体系的建设，都标注了不菲的价格。</p><p>2017年，蔚来第一家NIO House在北京长安街的东方广场开门迎客，展厅面积足足有3000平方米。有媒体报道称，为了在这个寸土寸金的地方撑起门面，蔚来支付的年租金高达7000万至8000万元。就算是普通一点的商场，汽车品牌的门店租金也不是个小数目，每平米每天的成本基本在几百元的水平，这也是零售品牌店租的天花板。</p><p>商超店的广告效应足够诱人，对于这笔高额支出，处于品牌扩张时期的新造车公司也不太心疼。威马汽车创始人沈晖就曾表示：“商超店的租金可能有一半作为广告宣传（费）花掉了。”</p><p>但到了紧缩年代，这个模式也有了松动的迹象。</p><p>近期有消息称，小鹏汽车正在逐步淘汰效率低下的直营门店，转而扩大代理经销商门店的规模。第一财经在报道里提到，原本新入网的经销商需要先运营商超店一段时间，达到销售指标后才能申请开经销商店，但目前这一限制已经取消。截至2022年底，小鹏汽车的终端店共有420家，其中直营店和代理经销商的比例约为7:3，目前，这个比例被调整至接近1:1。</p><p>虽然小鹏官方没有透露投资一家直营店的费用，据证券日报之声报道，在中国运营一家汽车直营店，每年的平均成本约为400万元，增加授权经销商的比例，将一部分成本转移出去，也可以为小鹏节省一大笔投建直营店的费用。</p><p>和拥有大量经销商门店的小鹏相比，全部门店都是自营的蔚来面临的压力更大。蔚来也在考虑调整，除了会继续保留NIO House以外，蔚来还在规划“大展厅店”，因为发布的新车型越来越多，一般的商超店很难全部陈列。这种大展厅店一般都在远离市中心的地方，仅是租金就能省下一大笔。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_8d29a0a1c50d4176bf05e5f7c0b46e94@5844535_oswg95343oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲&nbsp;NIO Space 。图 /&nbsp;蔚来官方微博</p><p>此外，蔚来销售人员的考核体系也经历了重大调整。淘汰机制的存在感陡然增强，“月目标完成率没达到50%且在区域排名后20%，公司会评估其工作态度等，考虑签PIP（人员改进计划，不通过则辞退）”，一名蔚来销售告诉每人Auto。</p><p>据该销售透露，近来蔚来对于试驾数量和App注册率的要求也变得比以前更高。之前没有强制考核，现在每名销售每个月需要拉来九至十个试驾要求。</p><p>今年初，蔚来创始人李斌曾在内部信中表示：“组织和团队在过去一年扩张过快，内部沟通效率亟需提升。”话音刚落，一场组织架构优化在蔚来内部紧锣密鼓地铺开。</p><p>据腾讯新闻报道称，今年早些时候，蔚来直营门店架构经过了一番精简。蔚来门店里，专门负责用户试驾、门店员工培训等业务的NPE部门已被解散，员工或选择转岗，或领取补偿后离开。</p><p>2022年，为了实现销量翻一倍的目标，蔚来的一线销售团队曾急剧膨胀，招聘力度空前。原本紧密的组织，也因大量人员涌入变得松散，比如一个项目前后换了几拨不同的人对接，引得不少内部员工频频抱怨。</p><p>在精简销售架构之外，据36氪报道，近期蔚来还推迟了自研电池业务，电池工厂的部分设备采购工作也随之放缓。一位接近蔚来的人士告诉每人Auto，除了电池业务，蔚来还暂停了部分固定资产（比如工厂）的投入，并且砍掉了对某手机配件业务的研究。</p><p>就算是2023年前9个月已经狂卖超200万辆车的比亚迪，花起钱来也不会大手大脚。</p><p>王传福在2022财年业绩会上透露，今年1月的仰望品牌发布会只用了300万元。据了解，此前为了契合高端形象的定位，相关部门挑选了不少外部的高档场地，但比亚迪高层不愿在营销上多花钱，最终，发布会还是选在比亚迪自己的报告厅举办。</p><h2>车企紧腰带，勒疼供应商</h2><p>车企紧了紧腰带，牵扯到的除了内部员工，还有产业链上的大量合作伙伴。</p><p>“玩手机玩了一个月，车间也不加班了。”某零部件二级供应商员工讲起现状时抱怨。另外一位一级供应商的员工，也清晰地感受到利润激励奖金一拖再拖，应该8月发的钱9月末才到账。</p><p>今年上半年，一封《致长安汽车采购部的申诉函》，将车企与供应商水面之下的恩怨，赤裸地展现在公众面前。在这封申诉函中，供应商控诉称，今年3月长安汽车采购部不顾合同约束，强行扣掉数百家供应商10%的货款，以应对车圈价格战引起的部分车型滞销。</p><p>压力是一层一层往外传导的。按照行业传统，车企会和供应商约定一个年降的数字，相当于供应商给到车企的折扣，要求相关产品每年的售价都会比前一年降低一定比例，比如三年内每年降低3%。因为通常来说，一款车型的生命周期就是三年，随着车辆的生产量增加，零件的研发、模具等费用也被摊薄，供应商生产的熟练程度和效率在提高，相应的费用也会减少，所以总成本在逐渐降低。</p><p>但今年，形势变了。国内某汽车空调热管理供应商赵泽告诉每人Auto，今年不少车企在年降之外，对供应商提出了一些额外降本需求。尤其是一些自主厂商，包括长安、五菱、广汽、东风等在内，都有额外的降本需求。</p><p>过去，头部供应商在汽车生产链条上掌握着不小的话语权。博世近乎垄断了国内的线控制动市场，根据长城证券数据，2022年，博世掌握着国内线控制动市场近80%的份额，就算和头部主机厂宝马的合作中，博世也占据着强势地位，博世员工告诉每人Auto，此前博世在和宝马的合作中，博世要涨价，但宝马没接受，最后因为生产节奏受到影响，只能回过头继续找博世供货。</p><p>但即便强势如博世，现在的日子也不好过，降本增效的压力如影随形。</p><p>在博世工作的季源告诉每人Auto，目前降本主要体现在日常办公流程上。比如出差，要有明确的理由、计划表后，直线领导评估批准了才能出差，超过3天就要交日报。出差报销要有发票或者消费记录，并且强调非必要不出差。交通工具方面也出现了一些限制，比如需要提前订便宜的票，而之前交通方面没那么严格，“没二等座了也可以买一等座”。</p><p>此外，季源还透露，博世XC事业部（智能驾驶与控制事业部）员工的加班费也没了，灵活调休，但活儿还是要干，工作依旧很忙，忙起来经常连续十来天晚上八九点才下班，有的时候甚至周末两天都在加班。</p><p>曾经号称“能养老”的博世也开始精简人员。最先遭殃的是外包员工，最近合同到期的正式员工，根据绩效考核成绩表现不好的直接不续约，部分绩效很差的直接裁。据季源了解到，自今年初开始，博世XC事业部开始推行“员工考评制度181”，10%优秀，80%中等，还有10%表现较差的，将直接被裁员。</p><p>对于博世的降本行为，季源将其归因于国内供应商“太卷”，“如果外资不跟着卷起来，怎么打得过”。即使是自建供应链的比亚迪，今年也“对自己人开刀”了。作为比亚迪内部的供应商，弗迪电池也没能逃过“降本”。一位弗迪电池员工告诉每人Auto，“今年降价比例大概提升到了40%，而往年这个比例大概是20%-30%左右”，去年卖七八百的东西，今年就只能卖到五百块。</p><p>国内供应商赵泽则表示，有时候内部核算下来没有利润点的项目，为了卖主机厂一个人情，继续留在这个主机厂的供应体系里，公司也会接。</p><p>但问题是，有些项目的账期越拖越久，“甚至有些车企还会拿产品来抵账”。除了常见的拿车抵账，还有拿设备、地皮抵账的，赵泽说，甚至有车企“抵过红酒饮料、汇源果汁，还都是快过期的”。</p><p>供应商处理这些产品也很头疼。饮料只能作为福利发放给员工，车辆抵过来公司留几辆，然后看内部员工有没有购买需求，剩下的则会继续被抵给下一级供应商——在主机厂面前处于下风的一级供应商，到了二级供应商面前就摇身一变，成了强势角色。</p><h2>艰难适应</h2><p>在车企长时间的“压榨”下，供应商们也已经形成一套自己的降本手段。</p><p>供应商的成本，基本分摊到研发、材料、制造、物流和销售等环节。“换材料是见效最快的（降本方法），一般降个10%-20%是没有问题的。”苏凯认为，比亚迪油箱事件，就是一个明显的节约成本的例子。</p><p>今年5月，长城公开举报比亚迪秦Plus DM-i和宋Plus DM-i两款车采用了“常压油箱”，其“整车蒸发污染物”排放涉嫌不达标。由于秦Plus DM-i和宋Plus DM-i都是混动车型，在长时间使用纯电模式的情况下，由于不启动发动机就不能产生进气负压，碳罐中的汽油蒸发物无法脱附至发动机，时间长了，多余的汽油蒸发物将排放至空气中，造成污染。想要解决这一问题，就需要增加成本配备更大的碳罐或者使用高压油箱。</p><p>在物流环节，能压缩的成本也被尽可能地压缩。</p><p>王耀在某汽车供应商负责物流包装，他的工作是根据不同零件种类设计不同的包装，提高物流效率。据他介绍，一辆车几千个零件，大约有近1000种包装规格。如果要改变一个零件的工艺、设计或者原材料，需要向客户提申请、重做所有实验，走试装验证、批准后才能量产，过程少说两三个月，多则一年半载，期间还要被车企剥一层皮，“每节约一块钱至少分客户（车企）五毛钱”。</p><p>为了满足降本要求，很多供应商铤而走险：私自更改材料。但这是违反PPAP（生产件批准控制程序）规则的，如果私自变更材料被发现，就会面临大额罚款，“比亚迪的项目被逮到就是500万罚款”。</p><p>更多的供应商会同时使用几种降本手段，一部分上报，一部分不上报。一般来说，不涉及外观的或者看不大出来的外观变更，一般是不上报的；反过来，有明显外观区别的零件或者对性能有明显影响的就需要上报。看人下菜碟也是常见的手段，某汽车一级供应商员工杨栗告诉每人Auto，“如果这个客户对公司来说很重要，或者这个客户的日常审核非常严格，这种时候就会上报。”</p><p>在王耀看来，最简单快捷的降本方法，就是在一个物流箱子里多装几个零件，不仅能降低运费，包装成本也有更多的零件一起分担。只不过，相较于改变一个零件的工艺和材料，这样省下来的钱微乎其微，“零件借位撑死也只能再增加个2%-5%的容积率”。</p><p>新能源战场，竞争异常激烈。2018年是新能源车企扎堆出现的一个年份，据报道彼时中国电动车制造商一度达到487家。但到了今年，能正常经营的新能源车企仅剩下40多家——短短五年时间，超过400家新能源车企消失了。</p><p>对于尚未盈利的车企来说，首要目标是扭亏为盈，继续留在牌桌上。</p><p>为了降低成本，目前汽车零部件国产化替代趋势愈演愈烈，大部分零部件国产化后都有可观的降本效果。比如杨栗比较熟悉的底盘类部件，国产化后大概有30%的降本空间，大件能省上千元，小件也能有好几十块的差距，“举个例子，一个进口DP-EPS转向机，大概是2700元左右，国产最低能做到1900至2000元”。</p><p>而那些已经开始盈利的车企，操心的重点则是提升利润率。</p><p>为了不让供应商赚差价，比亚迪选择自建供应链。除了玻璃和轮胎，比亚迪几乎自己制造了所有汽车组件。为了降低成本，理想也开始学着比亚迪对供应链进行垂直整合，在增程器、XCU中央域控制器等零部件环节加大自研力度。</p><p>抛开公司命运前景不去想，切实感受到压力的普通打工人们，能做出最激烈的反抗也只是“撂挑子不干”。经历了汽车行业的狂热与煎熬，叶舒觉得行业好像正在回到一个正常的氛围里，今年以来，他一单也没开，萌生了离开这个行业的想法。</p><p>李弈所在的产品部门总共二十人左右，此前一直比较稳定，最近三个月陆续离职了四五个。据老员工们讲，公司对员工差旅和福利抠得太细，影响工作体验。李弈也计划国庆之后看看机会。</p><p>更多的人，根本不敢撂挑子。今年刚刚背上房贷的季源，最害怕丢了工作导致断供。他说自己平时没什么物欲，唯一的爱好就是探索美食，之前还经常会找一些人均消费1000元左右的餐厅打打牙祭，现在，人均超过300元的店，看都不看了。</p><p>“先苟着”成为季源挂在嘴边的一句话，至于苟到什么时候，他也不知道。</p><p>（应受访者要求，文中均为化名）</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/EGWh4R38ociAkKfGoBXy2Q" rel="noopener noreferrer nofollow" target="_blank">“每人Auto”（ID:meirenauto）</a>，作者：魏冰，编辑：辛野，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470705200486276</id>
            <title>现在的AI作曲，写出来的歌可以当短视频的BGM了</title>
            <link>https://www.36kr.com/p/2470705200486276</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470705200486276</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 01:26:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 音乐模型, Stable Audio, 生成音乐
<br>
<br>
总结: AI的出现让音乐创作领域也面临着技术革新，各种文本生成音乐模型如Stable Audio能够通过文字描述生成音乐，包括不同风格的音乐，甚至包括白噪音。虽然音色可能不太清晰，但对于一些创作者来说，这样的音乐生成模型已经足够使用了。 </div>
                        <hr>
                    
                    <p>毫无疑问， AI 的出现，让不少行业面临着技术革新，音乐圈子也不例外。</p><p>不仅人声模拟，在音乐创作这块儿， AI 也是卯足了劲，各种文本生成音乐模型是一个接着一个：</p><p>像是 OpenAI 的 MuseNet 、谷歌的 MusicLM 、 Meta 的 MusicGen ，还有前不久 Stability AI 家刚出来的 Stable Audio 等等等等。</p><p><strong>这还只是一些比较出圈的 AI 音乐模型，其他的不知名的更是海了去了。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_3ec41416df134f8fb51da8c4065afca1@5091053_oswg601173oswg1080oswg522_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这么多生成音乐的 AI 模型，它们主打的，都是一个让音乐门外汉也能作曲，只要动动手会打字、会描述就 OK 了。</p><p>这么一说，让没什么乐理知识的世超着实很心动，作曲咱不会，但文字描述可是咱擅长的领域。</p><p>于是，我们决定亲自试试目前市面上比较出圈的几款 AI 作曲模型，看看它们到底能不能实现从零作曲，以及写出来的曲子到底好不好听、符不符合要求。</p><p><strong>首先出场的是&nbsp;Stability&nbsp;AI&nbsp;的新作曲 AI ：Stable Audio 。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_27280af95a114df69bf49db70d53bb38@5091053_oswg231917oswg1080oswg472_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>官方说是用了超过 80&nbsp;万个音频文件去训练模型，里面像音乐、音效、单一乐器演奏等都有包含，整个数据集的时长加起来有 19500&nbsp;多个小时。</p><p><strong>并且光靠语言描述， AI 就能生成最长 90&nbsp;秒的音乐。</strong></p><p>风格跨度也是贼大，世超去它们官网听了下示例，有钢琴、架子鼓这种单纯器乐的。</p><p>还有不同流派不同风格的，比如民族打击乐、嘻哈、重金属之类的。</p><p><strong>甚至还能生成白噪音，像是一个餐馆里嘈杂的吵闹声， u1s1 听起来还蛮逼真的。</strong></p><p>当然，官方公布的肯定都是挑比较好的演示展示出来，到底用起来怎么样还是得亲自上手试试。</p><p>于是我们也注册了号，看看我这个音乐门外汉通过这个模型能创作出什么样的音乐来。</p><p>由于是刚发布，世超还花了好一会儿时间才进到 Stable Audio 的使用网页。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_10b1c8d21aea4e178082aade971bf02e@5091053_oswg68240oswg554oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>进去之后，我们先让它生成一段 30&nbsp;秒的贝斯 solo ， 112 个节拍，要 funk ，有律动一点。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_bd1f4804854144eaa403f41a76052b6f@5091053_oswg30243oswg701oswg431_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>生成过程大概用了一两分钟，世超听了下结果，倒是有点出乎意料，是在弹贝斯没错，音乐风格也挺准确，<strong>但唯一的瑕疵就是这贝斯的音色不太清晰</strong>，像是指弹和 slap 的中间态。</p><p>接下来上点难度，乐器复杂点，让它生成一段朗朗上口的流行舞曲，中间带着热带打击乐，要有欢快的节奏，适合在沙滩上听。</p><p>这次 Stable Audio 有点小失误，虽然节奏挺欢快的，也挺适合在沙滩蹦跶的，但提示词里的热带打击乐，我愣是没在这 30s 听出来。</p><p>再让它生成一段摇滚曲风的音乐，也是不出几分钟就搞定了，虽然听起来依旧不怎么清晰，但摇滚曲风以及电吉他、架子鼓的声音还是能听出来的。</p><p><strong>整体体验下来，在音乐生成这块， Stable Audio 的表现确实没有什么大错，偶尔还会有一些出乎意料的表现。</strong></p><p><strong>起码对于一些想给短视频插背景音乐的创作者来说，这个完全够用了。</strong></p><p>并且这次， Stable Audio 还专门在时长上下了一点功夫，普通版可以生成 45 秒以内的音频，想要更长的话，就升级个 PRO 版，可以连续生成 90&nbsp;秒。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_6efb5d57353542e398cda5fcbf848dcf@5091053_oswg113449oswg1080oswg493_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>接下来上第二位选手：<strong>Meta&nbsp;AI&nbsp;的MusicGen</strong>，它基于 Transformer 架构，靠上一段音频预测生成之后的音频片段。</p><p>现在 MusicGen 只公布了 Demo ，能在 huggingface 上浅浅体验一波。</p><p>比如说生成一段嘻哈曲风的音乐，听起来很抓耳，节奏倒是蛮干净利落的。</p><p>和 Stable Audio 不太一样的是，<strong>MusiacGen 在生成音乐时，提示词会更自由一点，不仅有文字的选项，还可以补充一些声音文件。</strong></p><p>操作起来很简单，输入提示词，再把想参考的音乐片段直接拖到文件框内，或者现场录音，当然音频提示也可以不填。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_d9352a39d0134f8eb92cac3350a895ab@5091053_oswg43136oswg752oswg818_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然 MusiacGen 一次最长只能生成 30s 的音频，但有音频提示的加成，生成一段长音频也不是不可能，就是会有点麻烦。</p><p>只要每次生成 30s 的音频后，前后截取 10s 作为之后的提示，最后拼接起来就是一段长音频了。</p><p>不过在整个体验过程中，有一点着实会劝退一大波人，那就是它生成的速度实在是太慢了，三四分钟还算好的，离谱的是有时等了好几分钟，结果突然弹出个崩溃了的弹窗。。。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_a438c26396c64604a71a918ea48af75b@5091053_oswg48499oswg666oswg158_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今年年初，<strong>谷歌也发布了音乐大模型&nbsp;MusicLM</strong>，在现有的作曲 AI 中，谷歌的这个功能最多。</p><p>除了最基础的文字生成音乐之外， MusicLM 还搞了一些其他花样。</p><p><strong>比如说故事模式</strong>，可以让它生成一段 1 分钟长的音乐：&nbsp;0~15s 冥想、 16~30s 醒来、 31~45s 跑步、 46~60s 结束。</p><p>生成的音频听起来确实还挺符合要求的，但就还是老毛病，乐器的声音不够清晰，各个段落之间的转换也有点生硬。</p><p><strong>还有看图配乐的功能</strong>，给出一个经典的拿破仑骑马穿越阿尔卑斯山的图，再对图片进行一些描述， MusicLM 就能给生成 30s 的配乐。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_08b93ad3f5604f31b31548515f7524b0@5091053_oswg466424oswg1080oswg479_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这次听起还真有点戏剧的感觉。</p><p>MusicLM 同样没有对外公布，想要体验只能在 AI Test Kitchen 上排队获取内测资格。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_3c3e10cb48f24a18961c84883b5e4b70@5091053_oswg39914oswg1031oswg251_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>OpenAI 的 MuseNet ，在三年前就已经在官网公布了。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_75ed01ffd65a4017bc43f46135d4d277@5091053_oswg406337oswg1080oswg544_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过最近这几年倒是没怎么更新，还是基于和 GPT-2 一样的技术。<strong>并且 3 年过去了，这个 AI 还没有对外开放使用。</strong></p><p>但看看它官网对 MuseNet 的介绍以及给出的示例，估摸着出来就是吊打上面模型的存在。</p><p>先不说生成音乐的质量，就光是时长就已经很顶了，最多可以生成 4 分钟的音乐。</p><p><strong>对比上面提到的几个模型，生成音乐的质感也是分分钟秒杀</strong>，世超从官网下载了个示例，大家可以一起听听。</p><p>不说是 AI 创作的，我还真会以为是那个音乐大师编的新曲子，有引入、有高潮，乐器的声音也很清晰，再简单调整下就是个完整的音乐作品了。</p><p>当然，有这样的效果除了有神经网络的功劳外，训练用的数据集也是起到关键作用的。</p><p>OpenAI 统共用了数十万个 MIDI 文件训练 MuseNet ，下面这张图就是用到的部分数据集，从肖邦、巴赫、莫扎特到迈克&nbsp;·&nbsp;杰克逊、披头士、麦当娜，从古典到摇滚到流行，几乎各种风格的音乐都能在里面找到。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_c7c4695e0f9445d48bae0b7a0dc4e060@5091053_oswg384772oswg1080oswg823_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不止国外，国内这几年 AI 音乐也是发展得火热，去年华为开发者大会上，就公布了一款音乐 AI ：Singer 模型，网易云面向音乐人推出了网易天音，<strong>作词、作曲、编曲直接都能靠 AI 解决。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_be8553b34178485dbb52c92c8869c13c@5091053_oswg373205oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在前不久的 2023 世界人工智能大会上，腾讯多媒体实验室也展示了自研的 AI 通用作曲框架 XMusic 。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0b62cb2535804265aeb996291f862de6@5091053_oswg43127oswg814oswg552_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>总的来说，这几个 AI 作曲模型也算是各有千秋，想要的音乐风格基本都能生成，甚至有时生成的音乐不仔细琢磨还真听不出来是 AI 生成的，用在一些短视频中也是能妥妥地&nbsp;“&nbsp;蒙混&nbsp;”&nbsp;过去。</p><p><strong>但若要以一个专业人士来看的话，上面这些 AI 恐怕都或多或少有些缺点，最明显的就是上面提到的那几个 AI ，它们生成的音乐在乐器演奏上几乎都不太清晰。</strong></p><p>并且，和 AI 作画一样， AI 音乐也是版权问题的一大重灾区，由于相关法律还跟不上 AI 发展的速度，时不时就有 AI 侵权的官司。</p><p>比如今年 1 月份，美国唱片业协会向政府提交了一份侵权报告，提醒他们要重视 AI 音乐侵权的问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_b7c5a8fe07fd4ca3981589444f61118f@5091053_oswg164119oswg585oswg240_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>就连 MusicLM 的研究人员也亲口承认了侵权问题，在论文中写到会有盗用创意内容的潜在风险。</strong></p><p>原因是在试验这个模型的过程中，发现它在生成的音乐里，大概有 1%&nbsp;是直接从训练的数据集中照搬过来的。</p><p>也难怪现在大多音乐 AI 模型要么干脆不对外试用，要么只有 demo 或者排队内测，就连对外开放的 Stable Audio 也是反复强调自己的数据集是经过 AudioSparx 授权的。</p><p><strong>抛开版权问题不说，目前 AI 在音乐这块的发展确实是令人咋舌，拥抱 AI 音乐也已经是行业内的大势所趋。</strong></p><p>像专门提供轻音乐的 AI 音乐公司 Endel ，已经先后得到了华纳、索尼等音乐巨头的投资， AI 音乐创作平台 Soundful 也拿到了环球音乐、迪士尼、微软的投资。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231012/v2_0825eddfbd514598936779093eaccf80@5091053_oswg85417oswg1080oswg566_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，入局 AI 音乐是出于商业以及科技趋势的考量，在音乐性与艺术性上，目前的 AI 还是远不及人类创作者的，而这也是未来 AI 最应该优先考虑的。</p><p><strong>图片、资料来源</strong>：</p><p>MusicLM，musenet，Stable Audio，网络</p><p>36氪，2023会是AI音乐和人类正面交锋的一年吗？</p><p>机器之心，MusicLM来了！谷歌出手解决文本生成音乐问题，却因copy风险不敢公开发布</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/YaKCRUKxJdAkYLf-J7JI4w" rel="noopener noreferrer nofollow" target="_blank">“差评”（ID:chaping321）</a>，作者：松鼠，编辑：江江&nbsp;&amp;&nbsp;面线，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470703068878982</id>
            <title>亚马逊云大中华区换帅的四重原因</title>
            <link>https://www.36kr.com/p/2470703068878982</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470703068878982</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 01:25:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 云计算, AI 技术, 亚马逊云, 大中华区
<br>
<br>
总结: 亚马逊云在中国的发展与变迁，体现了云计算和AI技术的强势崛起。云计算作为亚马逊的主要利润来源，面临着财报增速放缓的压力。同时，亚马逊云也面临来自微软等竞争对手的挑战。为了应对这些挑战，亚马逊云在大中华区进行了领导人的变更，希望通过AI技术的应用创新，抓住中国数字经济发展的机遇，成为AI新时代的领导者。 </div>
                        <hr>
                    
                    <blockquote><p>这一角色的变换，体现出了在云计算的强势崛起与近年来 AI 技术的强力驱动下，亚马逊云在中国的不断发展与持续变迁。</p></blockquote><p>10 月 9 日，亚马逊云科技全球销售、市场和服务高级副总裁 Matt Garman 对内宣布了大中华区领导人变更：<strong>储瑞松将接替张文翊，担任亚马逊全球副总裁、亚马逊云科技大中华区执行董事。</strong>Matt Garman 表示，张文翊将担任新的领导职务以回到自己家人的身边。在接下来的几周里，她和储瑞松将就交接工作制定计划。</p><p>十年来，从“亚马逊云中国第一号员工”<strong>容永康</strong>，到“继往开来新时代的掌舵人”<strong>张文翊</strong>，再到如今的新帅<strong>储瑞松</strong>，亚马逊云大中华区领导人可谓是国内云计算从萌芽期到成长期，再到应用期的重要见证者和实践者，而且这一角色的变换，也体现出了在云计算的强势崛起与近年来 AI 技术的强力驱动下，受到内部和外部多重因素的影响，亚马逊云在中国的不断发展与持续变迁。</p><p>因此，亚马逊云大中华区的此番换帅，牛透社认为可以从四个方面来看：</p><p><strong>首先，</strong>从亚马逊近年来的财报来看，云业务的重要程度，无论如何形容也不为过，其已成为亚马逊最主要的利润来源，也是推动该公司的核心增长动力。</p><p>牛透社通过查阅以往的财报数据发现，从 2015 年亚马逊开始对外公布云业务的数据算起，云业务的营收一直以至少 30% 的速度增长，但受美国宏观经济承压等因素影响，从 2022 年开始，亚马逊云业务开始走下坡路，今年亚马逊发布的第一财季和第二财季财报均显示，亚马逊云同比增长仅有 16% 和 12%，出现了创办以来的最低同比增速。</p><p>不仅如此，由于受到泛互联网业务收入增长放缓等因素影响，今年以来，亚马逊云大中华区的收入增长也不尽人意。数据显示，今年上半年，亚马逊大中华区总收入为 18 亿美元，而去年同期为 15 亿美元，增速不足 20%，对比 2022 年 30% 的收入增速，大中华区的压力可见一斑。这表明，此前亚马逊云在大中华区的打法亟待改变。</p><p>亚马逊总裁兼 CEO Andy Jassy 在今年早些时候发布的股东信中，将 2023 年描述为近期记忆中“最艰难”的一年。如何将这“‘最艰难’的一年”转变成“里程碑”式的一年，在引入“新鲜血液”后，如何在大中华区制定新的业务战略，巩固亚马逊云的技术领先地位，从而为亚马逊未来业务的成长提供更大动力？这是摆在储瑞松面前的必答题。</p><p><strong>第二，</strong>虽然亚马逊云的业绩承压，但在 Andy Jassy 看来，亚马逊云的基本盘仍然领先，“仍处于其演变的早期阶段，并有机会在未来十年内实现不同寻常的增长。”而实现增长的关键词，除了芯片研发，当然还有 AI，“大语言模型和生成式 AI 将对客户、股东和亚马逊具有重大影响。”</p><p>实际上，早在几年前，亚马逊就已推出过定制 AI 训练芯片和 AI 推理芯片。今年，亚马逊云更是对外发布了一系列 AI 大模型和自研 AI 芯片，以助力企业解决场景应用落地问题。</p><p>在亚马逊云看来，包含大模型这一底层基础平台的生成式 AI 生态系统，可以让人们可以更容易地构建机器学习应用，用好生成式 AI，解决自己的特定领域或行业场景问题，这才是真正在 To B 领域改变行业的关键因素。由此可见，AI 对于亚马逊未来数十年的每个业务都至关重要，对于亚马逊来说，AI 是一场不能输的战争。</p><p>去年以来，全球范围内生成式 AI 极为火爆，在中国，由此带来的趋势需求持续暴增，而正如 Matt Garman 所言，“大中华区是亚马逊云科技全球最具战略重要性的地区之一，”怎样运用大中华区蕴含的巨大潜力，将云业务与如火如荼的 AI 深度融合，从而释放出亚马逊云的独特价值，这是亚马逊云大中华区换帅的又一重原因。</p><p><strong>第三，</strong>亚马逊的巨大压力，也源自于步步紧逼的老对手微软。牛透社在近期发表的《微软 AI 战略持续升级带来的三点启示》这篇文章里说过，微软已实现从云服务到 AI 服务的平滑升级，打造了一个“云-软件- AI ”的全新业务和营收模型，由此可以打造新的技术及生态底座、实现应用场景的扩展、带来新的市场空间，同时也有利于微软既有产品的价值重估。也正因为这样，微软来自云服务的收入规模和利润，近年来开始超过亚马逊。</p><p>在国内，微软也在持续加紧布局，2021 年 3 月，微软接连宣布两件大事，<strong>一是</strong>侯阳接替柯睿杰，成为新的大中华区董事长兼首席执行官，希望进一步提升来自大中华区的业绩；</p><p><strong>二是</strong>继续加大对中国市场云服务的投入，特别是在助力中国企业出海和全球跨国公司入华两方面，微软正在通过旗下的智能云矩阵协助客户提高运营效率、发掘更多业务机会。这显然对亚马逊在国内的业务构成了威胁。</p><p>无论对于亚马逊还是微软而言，有着庞大体量的国内市场无疑具有深远的战略意义，这在国内企业客户业务的复杂性方面表现得尤为明显。亚马逊或是微软为这样的企业客户服务，<strong>一来</strong>可以深入了解和沉淀其所在行业的 Know-How，<strong>二来</strong>为客户提供的解决方案，还可以作为标杆案例，复制到国外市场，从而更好为全球范围内的企业客户提供技术服务。因此，继微软之后，亚马逊云推出更了解云和 AI、本土规则和本土企业的新掌舵人，也就不足为奇了。</p><p><strong>第四，</strong>在新帅的人选体现出了亚马逊的深思熟虑，体现出了亚马逊云大中华区的业务突破所需要的传承和接力。从两位主帅的履历来看，张文翊和储瑞松均是技术出身，都有着多年的外企业务负责人的工作经验，对国内外的技术趋势有着深刻的认知。</p><p><strong>不同之处在于</strong>，在加入亚马逊之前，储瑞松还曾担任百度集团副总裁，负责领导百度阿波罗智能汽车业务，这样的本土 AI 企业和带领智能汽车业务“从零到一”、开疆拓土的工作经历，以及对相关技术和应用的深入理解，想必是亚马逊方面最为看重的。此外，亚马逊云已和储瑞松的老东家 SAP 达成了战略合作，储瑞松的到来，也会让这一合作更加顺畅。</p><p>张文翊和储瑞松另一个不同之处在于，前者在硬件和电商有着深厚积累，后者在云和 AI 方面经验更多。如果说亚马逊云在国内夯实基础、持续深耕、找到新的发展机会这些任务，张文翊已圆满完成，那储瑞松接下来的任务就是如何利用 AI 这一新的风口，通过行业和场景的应用创新，将亚马逊云带上一个新的台阶。接下来，在储瑞松任内，亚马逊云将如何 抓住中国数字经济高速发展带来的巨大机遇 ，从而 成为 AI 新时代的“弄潮儿” ，让我们拭目以待。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI4NjEwMDQzMQ==&amp;mid=2649914522&amp;idx=1&amp;sn=54f96572d57957c78fef6991114c9ce6&amp;chksm=f3e4c23ac4934b2c679fbee0477544ec22ad4db4f41d8e0fa58e1d275a826154713e5aa3fadd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“牛透社”（ID：Neuters）</a>，作者：刘佳庆，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2470032311638144</id>
            <title>AI动画：离彻底变革还差“一层窗户纸”</title>
            <link>https://www.36kr.com/p/2470032311638144</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2470032311638144</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 01:22:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI技术, 动画行业, 降本增效, 创意探索
<br>
<br>
总结: 在生成式AI技术的推动下，动画行业开始关注并应用AI技术。AI作为一种工具，可以帮助动画公司降低成本、提高效率，尤其在创意探索方面具有巨大潜力。通过AI辅助，动画制作过程中的繁琐任务可以由AI完成，从而减少人力和时间成本。这为动画行业带来了巨大的机遇，但同时也面临着技术成熟度和应用模型等挑战。 </div>
                        <hr>
                    
                    <p>在生成式AI技术正在引领产业创新的当下，动画是最早关注并受到影响的行业之一。</p><p>动画一直是个技术驱动的行业。计算机图形学的发展，曾引发动画本身形态和表现力、市场和产业格局的巨变；当前动画行业核心的产能和商业模式问题，仍然受到技术力的牵制。</p><p>动画行业期待新的变革，一定是会由技术引起的。现在看来，这个技术就是AI。</p><p>对动画，尤其是三维动画来说，AI并非新鲜事。但过去一年，从ChatGPT、Stable diffusion到Midjourney，已经颠覆了不少人对AI的传统认知。</p><p>很多动画公司和平台都意识到，AI能够作为一种工具，以商业化使用为目的，满足更个性的要求，为自己的内容定向培养能力。这也让不同定位、业务模式的动画公司，对AI的使用呈现出更多考量。</p><p>曾经因为产能限制而无法想象的“日播”模式；或是作为IP产业链一环，以更经济的投入，主动带起IP开发的节奏；抑或是建立更通用的流程和素材库资源，打通从动画到游戏的生产……都可能在AI介入下变为现实。</p><p>当动画人从繁琐的体力型、流水线工作中解放出来，行业也将更加由创意型人才驱动，并探索新的艺术范式。</p><p>这是一个巨大的机会。</p><p>当然，未来的机会对应了眼下的挑战。变革与创新往往伴随取舍抉择和适应阵痛。</p><p>动画行业想把握机遇，但下场时机与姿态都是问题。AI技术能力、应用成本投入与回报之间的合理模型还没有建立，仍存在诸多不确定性。未来一段时间，伴随技术的发展，作为应用方的动画公司和平台，还会出现决策的拉扯。</p><p>但不管怎样，大方向总是在拥抱AI的。</p><p>理性来看，并非每次技术迭代都会彻底改变一个行业。当仍身处变化过程中，是否真正投入使用、使用到什么程度不是最重要的，了解所处环境和趋势、能做出正确判断才是。</p><p>AI为动画公司带来机遇，没有抓住也可能变成危机。毕竟，技术发展太快了。如果突然某一天，AI变得非常好用，谁也不希望在那个时候落后。</p><h2>01 最显著的降本增效</h2><p>早在2021年OpenAI发布DALL·E，基于文本token生成“牛油果形状的扶手椅”出圈，已经让不少动画人关注到AI。但受限于技术成熟度、对应人才和应用范围不明确等因素，主要停留在用AI做一些创意探索。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_042223dc6fb44daf85f6dde1d5fccef7@000000_oswg88078oswg1080oswg647_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>过去一年，Stable diffusion和Midjourney的快速迭代，不仅打开了AI在C端的认知，更直接促成了包括动画在内的多个行业对AI的批量化应用——基于前者的开源架构，研发适配自身业务的插件工具；而后者的出图能力不断升级，尤其在前端创意和策划环节的应用价值几乎获得行业共识。</p><p>今年8月腾讯视频发布《魔游纪人工智能辅助篇》预告，号称“国内首部人工智能辅助动画”。早在2023年春节前后，腾讯视频就有意尝试将AI应用到动画制作，最后与红龙影业一拍即合。</p><p>事实上，动画已成为腾讯视频相对稳定的商业化赛道。在整个动画行业成本相对锁死的情况下，这一商业逻辑的核心是用动画内容稳定拉新用户，动画热度越高，收益越大。热度不仅取决于内容质量，还依靠更新频率。</p><p>作为制作方，红龙影业创始人丁宇表示，当时双方都认为无论从降本增效还是寻找新风格的角度，探索用AI制作动画都有价值，“3月聊完，5月就开始执行了”。</p><p>降本增效几乎是现阶段所有动画公司应用AI的首要出发点。</p><p>相比二维动画，三维动画的整体创作过程极大地依赖于数字化平台，AI技术有更深的介入空间。而无论二维还是三维动画，美术制作流程前期阶段相似，包括人设和场景研发、概念图、原画等等。这些环节是目前AI应用最深的部分，降本增效尤为显著。</p><p>比如角色创造，以二维动画为主的ASK动画创始人于沺就表示，以前写作和绘画阶段可能只需几个小时，但再之前要花几个月的时间思考，现在用AI帮助统筹想法，寻找灵感的时间可以大幅度缩短。</p><p>三维动画也是如此。黑岩网络技术总监张鑫透露，今年新启动的动画项目采用了更多的AIGC流程，前期美术部分相较去年研发的项目《御甲凌云志》只花了预计时间的1/3甚至更少。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_f599d489252b42ef88af8a924695236f@000000_oswg134510oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">三维动画《御甲凌云志》</p><p>这是因为，导演组设计一个概念的时间相对较短，但如果以传统美术流程将这些概念用较好的视觉效果呈现给导演组，则需要相对较长的周期。并且不同项目风格不同，对人员技能水平要求也不同，导致对美术人才高度依赖。</p><p>而有了AI辅助，纯创意和策划美术依然由人完成，但将大多数的的细化任务交给了AI，相当于人做前期设计，AI完成“体力活”，对人力和时间的需求都减少很多，大大降低了试错成本。这让原本不到20人团队，需在8-10个月的周期完成的工作，变成只需要不到10个人，3个月左右就能完成。</p><p>“而且还改变了对团队配置的要求，以前必须有几个非常资深的人才能带领不到20人的美术团队完成工作，现在只需2个资深美术，配合少量初级、中级人员，就可以达到以前很难实现的水准”，张鑫说。</p><p>丁宇也表示，以往做角色设定图，需要先找参考、团队沟通商量，然后美术出线稿、根据线稿定彩稿，一步步推进可能一周才能出一个完整上色的角色。使用AI后，先汇总大家想法的关键词，由AI训练师根据关键词出图。随着训练积累，AI对关键词的理解越来越精准，效率也就不断提升。</p><p>比如利用AI工具，一晚上能出40个形象。根据40个形象再微调关键词，例如更具体的‘美式黄色T恤’等丰富细节。拿到40张图后，选择每个图上满意的部分，再把其中关键词提炼出来并重新汇总，最后生成一张新图。</p><p>这种做法一方面降低了沟通成本，“让整个时间缩短1/2甚至2/3”；另一方面，利用AI出图也给予设计开发更丰富的选择，从各种生成图片中选择喜欢的部分再重新出图，提升最终效果，最终实现在更短时间里，做出原本达不到的效果。</p><p>除了对动画创意孵化与产能的直接提升，AI在动画IP开发中也有较为清晰的应用方向。</p><p>推出《非人哉》《有兽焉》等动漫的分子互动创始人徐博就表示，公司核心业务和定位不同，AI价值也有区别。“我们定位为IP型公司，动画是整个IP中一种内容形态和一个环节，所以不会只从动画角度看AI，还要思考AI对漫画和IP运营的价值。”</p><p>比如在动画层面，目前看重AI对关键原画、场景的辅助，而在IP衍生开发商，除了以AI帮助后续物料设计、衍生品开发等， 还有AIGC生成海报、AI coser 等方向，能在营销端发挥较好的作用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_26b7f721bdf04f5f956d311d8b583f78@000000_oswg605229oswg720oswg520_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《非人哉》IP</p><h2>02 真正的“弯道超车”机会是用AI颠覆全流程</h2><p>总的来说，动画人普遍将AI视为新机会。就像丁宇和腾讯视频合作时，感觉这或许能成为弯道超车的机会。因为现在的AI不只作为辅助某个环节的工具，整个行业的发展和全流程环节，都可能为AI做整体适配。这种可能的颠覆性，值得投入尝试。</p><p>换言之，行业对AI的期待，不只停留在AI介入前期策划等环节来帮助降本增效。</p><p>但更高的期待并不容易满足。即便是“降本增效”，动画行业经过这一年的应用发展，也普遍感受到了某种“瓶颈”。</p><p>这其中，技术发展程度是核心因素，又不仅仅只有技术问题。</p><p>作为提供AIGC绘画工具和AI创作服务的平台，无界AI一直在切ACGN领域。在无界 AI 内容中心负责人赵杰诚看来，动画反而是最难切入的。</p><p>漫画对技术要求更少，不用建模、补中间动作等，AI辅助创意、线稿、上色等几乎就完成了大半工作，人工更多投入讲故事、分镜排版等，“今年3月还只能完成30%-50%，现在可以辅助70%工作”。这对漫画平台来说，相当于解决了很多核心问题，直接为商业化争取了更多空间。</p><p>而国内很多游戏公司的原画线和制作线通常分开，便于流程分割。赵杰诚表示，为降低立项成本，不少游戏前期不再投入大量成本精力做太多设定，AI的出现让游戏公司大幅砍原画外包，甚至达到70%-90%。因为一些游戏本身不直接呈现原画，主要根据原画建模，这些参考建模的素材更容易被AI替代。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_4960e07da2914cacbdb147c7fd398b8f@000000_oswg385054oswg1080oswg684_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">无界AI生成图片</p><p>相比之下，动画要求更高。动画需要做出能直接连贯的画面，而AI在连贯性、光线处理等方面存在问题，因此从整个流程看，AI对动画，尤其是三维动画的介入不算深，除非整体替换制作流程，比如实拍后用AI逐帧替换。</p><p>“但现在国内没什么动画公司用逐帧方式做动画，一般都有自己固定的制作流程。这就导致AI更多只能在前期设定、场景、任务、上色等方面介入”， 赵杰诚表示。</p><p>事实上，国内不同动画公司，乃至同一公司不同项目制作流程可能都不同。不仅诸如无界AI这样的第三方公司较难提供匹配的标准化解决方案，动画公司自身寻找AI工具、内部进行技术研发，也会面临相似的难题。</p><p>包括被普遍采用的Stable diffusion和Midjourney在内，各种技术工具还没有发展到专门为动画这一细分行业定制开发的程度，导致动画公司基本只能被动适应AI技术的发展。</p><p>并且，大部分小型动画公司也无力投入研发适合自己的插件等。而对大型动画公司，乃至平台来说，现阶段投入研发，更进一步变革动画生产全流程也并不容易推进。</p><p>一是技术投入成本和方向不够明朗，相关人才缺乏，没有成熟的商业模式在一定时间回收成本；二是目前仍有很多流程使用AI，可能比人工更贵，或是更低效。</p><p>腾讯视频的AI动画项目，前期也经过了激烈的讨论。“《魔游纪人工智能辅助篇》项目作为前瞻布局，考验的其实是平台的战略决心。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_26b7be41257941d88c11679cb21101dc@000000_oswg94257oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《魔游纪人工智能辅助篇》</p><p>对很多动画公司来说，比如二维动画，最重要的成本问题之一是帧与帧之间的帧融合，如何从一个动作到另一个动作。</p><p>于沺认为，二维动画还很难达到去人工化的状态，受到硬成本制约。虽然很早就关注到AI模拟画风、补齐中间帧等技术，但尖端研发成果还较难应用到行业中，加上所需的硬件基础等，最后成本可能比人力生成高更多。“这就形成了一个悖论。”</p><p>三维动画的成本重头则是手k。纯靠手K，一部年番可能需要200人的团队做一整年。而“手K”又并非纯粹的技术流水工种，能体现出动画师个人的艺术感、节奏，且部分超越现实动捕的夸张动作、效果也只能靠手K完成，这种情况在动画中比较常见。</p><p>若森数字副总裁杨磊就表示，《不良人》系列目前还没有采用AI，预估这样品质级别的动画，AI应用最多占到20%，剩下的仍需要大量人工团队手K。</p><p>一方面，目前三维影视级动画的天花板在硬件，诸如解算是三维动画制作中非常耗时的环节，要靠算力实现；另一方面，动画对美术融合需求太多，比如AI目前很难做好分镜，即便技术达到，也未必有好的艺术效果。“UE5的Metahuman已经有面捕系统，能直接替换模型，不过还达不到高质量的影视级别内容要求，还是需要手K的部分工作。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_5d3c3317325748f89ecfce20dfac971a@000000_oswg51592oswg686oswg386_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">三维动画《画江湖之不良人》</p><h2>03 AI问题，也是“人”的问题</h2><p>AI还无法在某些环节替代人工，但已经引发了不少动画人的担忧。</p><p>很多普通从业者，从去年年底担忧AI是否会取代自身的焦虑，逐渐演变成AI时代到底需要具备怎样的能力。动画行业的定价标准也因此出现动荡。大型综合型动画公司受益于AI，但部分小型团队技能品类和业务模型单一，则容易被AI冲击人员结构和服务能力，在目前方向与环境下风险更高。</p><p>于沺认为，当下最易受冲击的岗位是概念环节，企划型公司和创意型人才则相对安稳。当然，长远来看，AI最终肯定带来系统性变化，使得整个流程最终可能淘汰三分之一以上的人。助理型的岗位减少，核心将集中在少数人手中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_7cf0ae3a4ecf4c73886a591ef65b83e7@000000_oswg132606oswg1080oswg772_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">ASK动画企划作品</p><p>这对动画人才技能点提出了完全不同的要求——当人们从流水线工作中解放出来，知道自己需要什么、市场需要什么的人才更加难得。在很多动画公司看来，比起表面的专业技能，这样的人才具备真正的创造力。动画生产力将从执行性人才更加转向创造力人才驱动。</p><p>比如说，原本优良的美术功底、色彩关系，现在AI能更好替代；原本3小时画一副场景图，AI出图可能只需几分钟。但这就要求从业者有好的审美，梳理出自己的逻辑和方法论，能判断什么样的场景是美的，更符合项目风格，在原本预设的环境里更高级。</p><p>在这种趋势下，徐博认为，未来会出现新的职业细分，包括AI作画的训练师等。“这样的人才目前还不多，需要了解原本不通过AI怎么完成这个工作，有相当好的美术基础和审美，能通过各种方式学习使用AI，进行训练和描述。这会是以后一段时间里比较宝贵的技能。”</p><p>对动画公司来说，现阶段要找到合适的AI人才自然也不太容易。</p><p>张鑫表示，黑岩网络2021年注意到AI，当时就想寻找计算机图形学或对抗生成网络相关人才，结果发现国内基本空白，招聘近一年一个人都没有找到，只好将这个方向的研发搁置。直到2022年下半年，stable diffusion掀起风浪，也依然很难招到相关人才。该技术能否顺利实现国产化替代方案不容乐观。</p><p>较难招到合适的人，除了这个技术方向本身的先锋性，从动画行业来看，首先，动画从业者对大部分技术是被动接受，自身很难去做突破性的变化；其次，在人员培养上，很多从业者仍是艺术家的心态，但商业动画产品最重要的是内容与效率，在内容表达没有问题的情况下，画面是艺术家一笔一笔画出来还是电脑算出来的，对观众来说并不是最重要的。</p><p>“说起来有点残酷，但很多人的心态很难改变，对新技术有抗拒心理。现在从业者对AI的看法，就类似我们上一辈老派画师看待数字绘画。”张鑫说。</p><p>市面上招不到现成的人才，就只能从内部团队培养。动画公司培训业务的变化，也反映出了国内动画人才技能追求的变化——从最早期主要教授传统数字绘画，到逐渐加入实时渲染课程，今年添加了AI部分，指导学员用AI辅助创作。</p><h2>04 不管乐观或悲观，未来已至</h2><p>面对这些问题，动画公司并未停止对AI的关注。过去一年AI的爆发， 让不少人相信跨越式发展不会太遥远，或许就是“一层窗户纸的事”。</p><p>丁宇说，虽然前期准备很多，当时用AI做动画的决策能过会其实挺意外的，因为近两年各大平台普遍以降本增效为基调，用AI制作动画的决策并不容易。但适用本土动画公司的AI技术和流程，只有在一个个项目积累中才能实现，一旦停止对AI的训练，就不会再进步。</p><p>当下技术的发展，就正在带来一些新的可能性。</p><p>杨磊一直在关注Wonder Studio这一技术工具，因为该产品方向关系到动画直接的流程和成本变革问题——真人实拍后，拿做好的资产直接替换，就能自动完成绑定等一系列工作。目前虽然还不包括服装解算等功能，但程序出来的效果，已经有机会颠覆现有动画制作流程，并且实现真正影视级应用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231011/v2_91e3bcf49f91432293069c4d92034695@000000_oswg250921oswg1080oswg629_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随着这个方向上的工具更加成熟，手K比例可能会下降到仅占10%-20%。以前需要高级动画师实现的效果，未来可能只需要初级的，且人数大大减少。</p><p>此外，以前灯光等需要渲染完看效果，现在能通过参数调节出实时灯光，所见即所得，直接出片，速度非常快。“这样也许未来有一天可以做到动画日播”，杨磊说。</p><p>目前，诸如英伟达等技术大厂都在探索“所见即所得”的方向，这同样可能引发动画行业流程和结构巨变。</p><p>张鑫认为，三维动画工业流程是通过模型、动画、灯光、特效、合成等十几道工序，最后呈现到屏幕上。而AI的最终形态一定是跳过中间所有环节，不需要以上工序，节省大量成本。</p><p>“现在AI还是辅助创作者生成初步的形象、想法。我相信未来AI并不仅是在建模、渲染等单一流程里辅助加速，而是直接摧毁当前的动画生产流程，给到最终的渲染结果。只要算力足够，AI工具制作出的内容所见即所得，这会是翻天覆地的变化。”</p><p>在这个过程中，动画公司也能积累面向未来的竞争力。包括提前训练自己的模型库，并针对导演需求、项目周期、品质和成本等，建立符合自己风格的流程。</p><p>模型训练的丰富程度、个性化风格和版权，都与素材库有着直接关系。于沺就表示，基于公司内部风格化的素材进行训练，就可能解决版权问题；同时，既能延续公司创作风格，又可能生成超出预期的结果，沿着新的结果再创作，思路和方向将变得更加宽阔。</p><p>不断根据自有素材训练匹配公司需求的模型，这些资产也有望成为动画公司的核心竞争力，并拓展动画公司商业模式的边界。比如黑岩网络除动画业务，也在自研游戏，通过将新的AI流程和模型库应用到游戏开发中以缩短前期发开周期，希望实现下一部动画和游戏在同一节点上线。</p><p>而站在整个动画行业来看，除了动画公司，个体也可能出现变革——AI技术使得动画越来越依靠个人才华和风格，各类AI工具出现，降低动画制作门槛，动画UGC或将更常态，这也可能带来动画短视频的机会。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzAwNDk2NDc5OQ==&amp;mid=2247605369&amp;idx=1&amp;sn=733ad81653868b3209b6441da35cec50&amp;chksm=9b20f4a9ac577dbfb2d0d9be64db4183538363169b806e6526661caf9892c45aeb0ce74f2b2d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“东西文娱”（ID：EW-Entertainment）</a>，作者：夏清逸，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2469995066382210</id>
            <title>AI大模型会是智能家居的S级变量吗？</title>
            <link>https://www.36kr.com/p/2469995066382210</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2469995066382210</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 01:20:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能家居行业, 互联互通, 通讯协议, 生态孤岛
<br>
<br>
总结: 智能家居行业进入3.0时代，但跨品牌和跨生态的互联互通仍然困难重重。不同企业使用不同的通讯协议，导致设备之间无法直接沟通。解决互联互通问题需要克服技术体系不兼容、标准繁多、商业利益不一致等多种障碍。各大企业通过自研操作系统和底座，如小米的MiOS、华为的鸿蒙系统、苹果的HomeKit等，尝试打破生态孤岛。然而，目前仍缺乏统一的解决方案，智能家居行业需要进一步探索和创新。 </div>
                        <hr>
                    
                    <blockquote><p>智能家居行业已经宣布进入智能家居3.0时代，然而，跨品牌和跨生态的互联互通需求仍然没有得到满足。</p><p>可以说，从诞生起，互联互通这个问题就一直困扰着行业。互联互通为何这么难？</p><p>本文巨头财经将以智能家居场景体验的技术底座"互联互通"作为切入点，探讨各大厂商的应对政策，以及未来趋势。</p></blockquote><h2>01 互联互通有多难？</h2><p>智能家居企业之间原本都是独立且竞争的存在。每家企业都希望建立自己的IoT王国，没有企业愿意按照别人的标准行事。因此，每个企业都成为了标准的创建者。</p><p>就通讯协议而言，各大厂家都有各自的偏好。比如，<strong>米家更多采用蓝牙Mesh协议，苹果偏好Zigbee协议，而华为选择有线PLC协议。</strong></p><p>通讯协议可以简单理解为设备之间进行数据交换的语言。理论上，智能设备只有遵循相同的通讯协议才能顺利沟通。</p><p>然而，现实情况并非如此简单。一些产品不支持直接连接Wi-Fi，有些产品只支持蓝牙等特定的连接方式。换句话说，当这些产品说不同的语言时，就需要额外的"网关"来进行翻译，以实现互联。</p><p>但这还远远不够。以米家为例，就存在中枢网关、从网关和盲网关三种类型。而能够同时翻译蓝牙Mesh和Zigbee语言的，被称为多模网关。</p><p>除了米家，还有AQARA、小燕在家、涂鸦智能等设备公司都生产网关产品，并拥有自己的语言体系。这导致了沟通上的障碍。这意味着，用户最终可能面临二选一的问题，否则就无法使用自己喜欢的产品。</p><p>实现全屋智能需要高度的专业知识。总的来说，<strong>互联互通问题难以解决是因为技术体系不兼容、标准过于繁多且不统一、商业利益不一致、数据商业化程度不足等多种问题。</strong></p><p>尽管去年2022年下半年出现了Matter协议，提供了一种新的解决方案，但目前适配Matter协议的智能家居产品数量仍然有限。</p><p>消费者需求千差万别，几乎不可能通过单一产品满足所有需求。尤其在下沉市场中，存在着大量消费者愿意购买替代产品的情况。即使厂商生态系统愿意吸纳其他品牌产品，仍然面临许多新的变数。</p><h2>02 谁能打破生态孤岛？</h2><p>如何打破各生态壁垒，加大中控平台的兼容性，依然是全屋智能趋势下的挑战。</p><p>在相同的行业标准下，进一步开放生态是实现互联互通的关键，这已经成为业界的共识。然而，在实际操作中，各大流派之间仍存在一定的差异。</p><p><strong>· 小米</strong></p><p>云米科技等企业主动去小米化之后，小米的供应链稳定性一直备受质疑。但不可否认的是，起初培育生态链企业搭建智能家居生态，很大程度是为了解决产品之间互联互通问题。</p><p>近年来，小米仍在积极推进互联互通。例如，妙享互联能够实现音乐、画面、网络等信息的流转。现在，小米很可能意识到了100%自研的手机操作系统鸿蒙的强大威力，还再次重提自研"MiOS"系统。</p><p><strong>· 华为</strong></p><p>操作系统作为互联互通的连接底座，为系统服务与应用提供了统一的接口和互联能力。</p><p>各家都希望为智能家居打造一个通用的底座，华为也自研了操作系统LiteOS。与小米选择投资和孵化的路线不同，华为一直以鸿蒙系统为基础构建全屋智能生态。</p><p>时下智能家居上的鸿蒙系统，就是基于华为自研的LiteOS而开发。为了攻克全屋互联稳定性差的问题，华为还推出“一机两网”的解决方案。</p><p>操作系统之外，更周全的是，华为还研究连接协议，自研了让产品沟通起来更顺畅的&nbsp;“&nbsp;分布式&nbsp;”&nbsp;软总线。</p><p><strong>· 苹果</strong></p><p>相较于小爱同学，Siri几乎没有任何优点，但是HomeKit真正的优势实际上是在iOS设备上的快捷指令功能。</p><p>由于iPhone、iPad、Apple Watch、MacBook等设备的快速自动化特性，结合智能家居的整合联动，消费者的体验直接提升到了一个新的层次。</p><p><strong>· 海尔</strong></p><p><strong>强大的家电基因与供应链，是海尔做全屋智能解决方案的最大特点。</strong></p><p>但事实上，早在2017年，海尔就推出了海尔UHomeOS，旨在解决不同品类、不同品牌智能家电之间的互联互通问题。</p><p>时下的海尔不再纠缠“入口”，回到底层技术系统的“基建”，推出“1+3+5+N”全屋智慧全场景解决方案，其中的“1”，也就是“智家大脑”，充分赋予家感知、理解、决策、生命的四大能力。</p><p>比如，基于多模态感知技术，实时调节家里的温湿清洁度与含氧量，比如当监测到室外PM2.5浓度超标时主动开启新风，再比如，老人小孩易着凉，空调直接绕开吹…</p><p><strong>· 美的</strong></p><p>华为HarmonyOS2发布时，家电企业是当时最为活跃的群体，包括美的、TCL、格力、九阳等家电企业都宣布推出搭载鸿蒙系统的家电产品。</p><p>据报道，2021年，美的推出智能家居行业内首个基于Open Harmony2.0开发的物联网操作系统1.0，能解决各产品多品牌互联互通、设备之间的自主协同等问题。</p><p>但目前，美的官方旗舰店只有两款商品明确标明搭载了鸿蒙，美的商城的鸿蒙专属页面也已经失效。</p><p><strong>· 绿米</strong></p><p>定位中高端的绿米，采用Zigbee通讯协议，大部分产品能兼容米家。</p><p>虽说覆盖面不如米家，但Aqara绿米是唯一一个能够支持在Apple HomeKit生态当中构建全屋智能家居系统的公司。</p><p>绿米很多产品能兼容HomeKit，而且有自己的Aqara Home APP，这在很大程度上吸引了果粉。</p><p><strong>· 欧瑞博</strong></p><p>HomeAI OS 是欧瑞博专为全屋智能打造的原生智能物联网操作系统，<strong>HomeAI OS 4.0成为继鸿蒙之后第二个脱离安卓生态的国产物联网操作系统。</strong></p><p>欧瑞博可以说是生态开放的佼佼者。目前，欧瑞博已与华为HiLink、美的IoT、小米、百度、京东智能等生态系统，实现横向互联互通。</p><p>智能家居的互联互通，无疑会加速产业发展与融合，但与此同时，这也会改变企业的商业模式和协作模式，尖锐化安全责任。</p><h2>03 AI大模型是新变量吗？</h2><p>智能家居互联互通标准正朝着从纸质规范到规范+代码同步发展的趋势。</p><p>Matter协议是一个例子，它采用了标准+代码的方式推动互联互通的商业化落地。</p><p>除此之外，高质量的通信网络是确保智能家居终端互联互通的必要条件。</p><p>智能家居互联互通离不开通信网络的支持。提升家庭内部网络（如Wi-Fi、ZigBee、蓝牙等）以及外部网络的能力将有效提升用户体验。</p><p>尤其是<strong>随着数字孪生、AR/VR、元宇宙等应用在家庭中的增加，外部宽带接入将为智能家居用户提供超高带宽和超低延迟的连接服务能力。</strong></p><p>中国智能家居互联互通标准体系仍需要进一步完善，但AI大模型技术的应用也给人们带来了希望。</p><p>美的、长虹、TCL、海信等家电巨头相继宣布接入文心一言（AI大模型）。AI大模型具备强大的语义理解和内容生成能力，可以根据用户的个人喜好和使用习惯提供个性化建议和服务。</p><p>因此，智能家居互联互通标准还需要进一步完善感知模型，包括环境、人员、场景等模型，以更好地为AI决策提供数据支持。</p><h2>04 巨头财经的思考</h2><p><strong>智能家居行业还在高速发展</strong></p><p>自动调节房间光线温度，自主进行食物烹饪，真正的智能之家应该“比我更懂我”。</p><p>早在今年5月行业就宣布进入智能家居3.0时代，在理想的预期里，3.0时代的智能产品不仅具备更高水平和更深度的智能化交互创新，告别被动指令，加强主动服务能力，满足用户个性化需求，还能满足老人和孩子的日常监管和警报需求，发挥类似人类伴侣的功能，提供陪伴和情绪价值。</p><p>年轻化的消费增长空间还是很大。但回到现实，<strong>供给端陷入内卷，整个行业仍在投入大量精力解决兼容性和联动性问题。甚至从普及率来看，中国目前的智能家居整体水平仍停留在单品智能时代</strong>，即用户通常依靠手动、语音、遥控等方式来控制设备。</p><p>理想与现实之间总是存在巨大鸿沟。还记得去年双11刚过，扫地机器人、智能冰箱、智能马桶等热销商品迅速在二手交易平台上出现的新闻吗？<strong>像洗碗机这样早在90多年前就诞生的产品，在美国的普及率高达70%，而在中国仅有约2%左右。</strong></p><p>但无论如何，智能化的趋势是不可逆的。智能家居行业还处在高速发展中，新的产品、更强大的功能和更好的解决方案几乎每隔三天就会推出。很多当下的认知说不定在下个月就会过时。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI5MDY4NTE2NQ==&amp;mid=2247490553&amp;idx=1&amp;sn=c411779882c5aa6eaa1e9371ff92fced&amp;chksm=ec1d727bdb6afb6d6f0c7d4d48627ffe7d183ce35cea02fdcb7af3215299bdfc956ee034fedd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“巨头财经”（ID：jutoucaijing）</a>，作者：叶子，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>