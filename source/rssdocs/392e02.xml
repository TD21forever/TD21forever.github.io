<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2748787451902978</id>
            <title>什么时候打游戏能用上国产GPU？</title>
            <link>https://www.36kr.com/p/2748787451902978</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748787451902978</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 12:00:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 国产GPU, 硬件, 生态, 技术
<br>
<br>
总结: 文章讨论了国产GPU在信息产业领域的发展现状和挑战。虽然中国在工业品领域已经取得了很大进展，但在GPU领域仍然依赖进口产品，导致国内游戏玩家面临高昂的价格和技术壁垒。文章指出，国产GPU要想进入市场，需要考虑生态、技术和市场等多方面因素，才能与国际品牌竞争。同时，通过英伟达的发展历程，强调了生态对GPU厂商的重要性，技术发展必须与生态兼容才能取得成功。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_7ceb0259934142a9a508b684e6ba9ad6@000000_oswg587075oswg1080oswg460_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>什么时候我们打游戏能用上国产GPU？&nbsp;</p><p>开玩笑地说，把国产GPU造出来需要新疆烤串负责烧沙子，兰州拉面负责切芯片，蜜雪冰城负责加小料，沙县小吃负责线下营销。&nbsp;</p><p>客观地说，现代社会运行基座的国产替代进程已经从工业时代进入到信息时代，衣帽玩具和钢铁水泥等工业品基本都是“Made In China”，但是信息产业领域，我们还停留在软件应用层面，是站在Windows、C语言这些底层构建上摘果子。&nbsp;</p><p>软件能跑动，还是靠硬件。&nbsp;</p><p>其中最大的硬伤，就在GPU上——2023年英伟达利润率76.7%，已经被老黄精准刀法收割钱包的中国游戏玩家，有着心在滴血的痛。&nbsp;</p><p>毕竟LPL能拿再多的S赛冠军、黑悟空神话画面再精良，驱动这些游戏 的没有一款国产的消费级GPU，“北美病夫”LCS再怎么被暴打，人家用的RTX4090显卡1.2W就能拿到，国内市场因为禁售影响，价格一度飙升到2W。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_84a771f87851443194f8c547367edfd6@000000_oswg75522oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>长江存储为代表的企业能够在“内存条”市场上能够率先实现单点突破，是因为读存标准协议基本是统一的，只需要满足这点就可以嵌入当前的生态，但是GPU需要考虑的包括底层操作系统、应用端的接口调用、开发软件的兼容适配等，单凭一家GPU公司打不通全产业链。&nbsp;</p><p>后入局的GPU企业难以兼容已经建立的显卡生态，另起炉灶需要付出巨大的成本，英伟达一年研发投入接近600亿，宁夏2023年的财税收入不过才353亿。&nbsp;</p><p><strong>所以国产GPU想进鹅城，命门是生态、生态还是生态！</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_cf89ab09719548f5bf732c7d7fb735b9@000000_oswg40816oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>饭要一口一口吃，在局长看来，GPU国产化第一步是自研产品能够接入现有生态标准，否则只能拿来当手办，第二步是携手上下游厂商比如做CPU的龙芯、做操作系统的华为打造自己的生态，需要的是开放与合作。&nbsp;</p><h2>英伟达也被生态卡过脖子</h2><p><strong>今天统治了整个GPU市场生态的英伟达，三十年前其实也是一个被大厂构造的生态虐的死去活来的小弟弟。</strong></p><p>英伟达1993年成立的时候，显卡厂商没有一千也有八百，各路风投争先恐后砸钱，和几年前中国新能源汽车成立的局面颇为相似，而且当时大哥3Ddfx的voodoo1堪称划时代，让3D游戏画质从“我的世界”像素格子进化到标清480P。&nbsp;</p><p>英伟达的第一款显卡NV1就因为难以兼容主流PC机而市场遇冷，消费者买了显卡无法驱动软件，幸亏因为集成声卡的功能被索尼看上，被纳入了索尼的生态体系。&nbsp;</p><p>或许就是从此刻起，黄仁勋明白了做显卡就是“跪着要饭”—— <strong>GPU 虽然重要，但离开主机就什么都不算。必须先并入主流PC厂商的生态，然后才能谈发展</strong> ——ATI是苹果小弟，而英伟达则投入微软怀抱，RIVA128兼容Windows95标准大获成功，绑定微软系统，1999年出货量达到1000万个，完全变成了微软的形状，并且在1998年将代工交给了台积电。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a7b54b291b55498592c07acdb1b29eb3@000000_oswg109931oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>靠着和微软的合作，靠着微软的庞大生态体系，英伟达才终于混出头</strong> ——直到和微软穿上一条裤子，N家的GPU从设计、制造到应用的利益共同体才初步形成。&nbsp;</p><p>但蜜月期终会结束，2003年微软的XBOX因为英伟达的GPU品控不合格在游戏主机市场被索尼暴揍，双方关系破裂，后续微软DirexctX9的游戏标准和ATI达成合作，英伟达成了局外人，被微软生态狠狠地卡脖子，一度陷入破产危机。&nbsp;</p><p><strong>可以说，相比起之前的发展，英伟达的这次翻车更能体现出生态对于GPU厂商的意义。</strong></p><p><strong>甚至有时候，生态比技术都重要！</strong></p><p>黄仁勋曾经提起过一个“黄氏法则”——6个月显卡性能翻一倍——甚至曾经7个月高出了6个产品。 技术发展当然是好的，但如果忽略掉了兼容问题，也是一地鸡毛——在英伟达狂飙突进、七个月推出六款产品的那段时间里，表面上的技术进步固然值得另眼相看，但是在游戏行业，那段时候玩家的态度是：N卡跑游戏性能很差。&nbsp;</p><p><strong>说到底，技术、生态、市场......又有哪一个可以忽略呢？</strong></p><p>在英伟达起起伏伏的这段时间， 国产显卡在干什么呢？&nbsp;</p><p>答案是：国产显卡 还没出生！&nbsp;</p><p>因为当时的国内市场根本养不起显卡厂商——其实别说显卡了，连整机电脑品牌都没有，1998年搭配奔腾3处理器的电脑售价接近3W，当时平均月薪才400块，国内市场电脑销量只有50W台，70%都是外国品牌，同期美国国内电脑销量是700W台。&nbsp;</p><p>就连风靡一时的小霸王都用的是MOS的6502处理器，2000年前后的国产GPU不是被生态卡脖子，是压根没有生态，随着联想2003年收购IBM，个人电脑逐渐平民化并且在国内铺量，国产才逐渐有了生存空间。&nbsp;</p><p>2014年第一款国产显卡JM5400发布，28纳米制程，可以调用多个接口，但因为兼容性问题，依旧无法融入商用PC端生态，简单说没办法打游戏、剪视频和作图，意义是实现政府内部电脑的专用芯片的替代。&nbsp;</p><p>一步落后，步步落后，但又急不得。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_2cbca126d91f4b1492ab07369fb56dd1@000000_oswg219369oswg600oswg357_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>农村包围城市，先做显卡后做GPU</h2><p>国产GPU已经落后，要怎样追赶呢？&nbsp;</p><p>美国之所以能出英伟达，背后是烧了上百亿美元的投资，倒闭了上千家GPU设计公司，所以我们不可能短时间内复制出另一个英伟达。&nbsp;</p><p>GPU是显卡的核心部件，散热、能耗这些部件同样影响着使用体验，同时技术门槛又相对较低，中国企业就优先从这部分入手，所以进入到买英伟达的GPU，自己设计显卡的时代，先上牌桌，才能慢慢摸出王炸。&nbsp;</p><p>台湾省电子信息产业起步早，上世纪90年代率先涌现出华硕、技嘉和微星，并称御三家，凭借散热主板、温控和系统调节多年积累的专利优势，让英伟达无法绕开这三家去独吞显卡市场，比如华硕的DirectCU散热和超合金供电等技术，从产品性能上看，非公版显卡的使用体验也优于英伟达自家显卡。&nbsp;</p><p>这是双方互利共赢的体系，通过授权给别人，英伟达节省了大笔的不必要的费用，比如散热研发、线下铺货渠道等，在营销方面，御三家所有的显卡推新的时候都会带着英伟达的名字，免费刷存在感。&nbsp;</p><p>英伟达自己也重视生态协作，没有选择赢家通吃，而是授权给多家显卡厂商制造。&nbsp;</p><p>因为曾经的大哥3Ddfx还在煤山上边的歪脖子树上吊着呢，3Ddfx自己掌控全产业链，D3D随着Windows普及已经成为主流渲染方式，但是3Ddfx依旧自嗨拒绝加入微软生态，后续甚至连对其它显卡厂商的芯片授权都收回，全部自己做，坐拥当时最好的3D技术，但是消费者花高价钱买回来的显卡和市面上的大部分软件都无法兼容，只能当模型供着，结果就是2001年被英伟达收购。&nbsp;</p><p>大陆的显卡 厂 商七彩虹紧随其后， 而且最难能可贵是在年轻消费者的品牌认知中，七彩虹的火神系列已经是顶尖显卡梯队。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_3a7d3e1aa0f84f73b586a2e980953c10@000000_oswg87406oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>七彩虹最初连代工厂都不是，只是同德下边的五个贴牌分销商之一，主做中低端显卡，性能极其不稳定，花屏、异响甚至直接主机抽烟，但是架不住便宜，抢占大量市场，连续十五年销量榜首，拥有最广的分销渠道和用户，而且随着经济发展，这批人有钱了。&nbsp;</p><p>2011年开始做高端显卡，七彩虹igame九段，从显卡DIY发烧友入手，把“只为1%的高端玩家定制”贴在了自己的脑门上，把显卡做成收藏品，以限量版显卡的饥饿营销来抬升自己的品牌地位，获得DIY显卡群体的喜爱。&nbsp;</p><p>高端显卡也可以有性价比，七彩虹很舍得用料， iGame RTX 3080&nbsp;的 5条镀镍回流焊热管贯穿了散热器本体，全重1.4KG，这个重量就很让人放心； 不过七彩虹的 低端显卡系列因为代工厂都是小厂的原因 依旧不稳定，好在拥有全宇宙最好的售后服务，只要没烧成灰，就能做维保。&nbsp;</p><p><strong>那时候的情况是，中国拥有顶尖的显卡品牌，但是拿不出可以商用的消费级GPU。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_ba77c21d21254069aae907f554e997b7@000000_oswg44356oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因为不管是御三家还是七彩虹，做的是显卡核心部件GPU全部是英伟达技术，只是在功率散热、能耗控制等调教方面实现追赶，依旧高度依赖英伟达的生态。&nbsp;</p><p>GPU的生产端依旧无法独立自主，一旦被断供，别说AI大模型这些涉及国家战略的大方向，赛博朋克2077这类游戏玩着都费劲。&nbsp;</p><p>GPU无法国产化依旧是核心痛点，因为涉及到的端口和配套实在太多，英伟达生态是伴随微软成为主流操作系统逐步完善的，英伟达的CUDA编程语言仅在美国的高等教育体系就持续投入十余年，包括赞助比赛、设立奖学金等方式，才让英伟达生态成为显卡的代名词， <strong>我一度悲观的认为在有生之年看不到国产消费级显卡问世。</strong></p><h2>另起炉灶，搭建自己的技术生态</h2><p>一家2020年悄悄出生的年轻公司，给被N卡和A卡垄断的显卡市场增添了一些“不稳定因素”。&nbsp;</p><p>摩尔线程在2022年出人意料啃下了GPU这个最坚固的山头，相继推出了“苏堤”和“春晓”两款GPU，采用的是自研架构MUSA,显卡MTTS80目前性能和1650相当，理论上可以跑到3060的水平，最近价格也降到了千元以内。&nbsp;</p><p>练习时长两年半就推出了基本可以上用的显卡，可以说是速度惊人，IP授权是采用的imagination的专利，可以把研发周期缩短到12——18个月，这家公司在地理位置上是归属英国，2017年被中资私募凯桥以49亿人民币收购，这就是联手布局。&nbsp;</p><p>而且这是一款养成系显卡，还是“第一款会自己升级的显卡”，属于边卖边测试，在发布后的一年多时间里，官方对驱动进行了九次大升级，从只能砍传奇到能够玩《暗黑破坏神》，性能提升了大概两倍，只有获得用户反馈数据才能继续调教升级，这也是英伟达生态极其看重中国市场的原因。&nbsp;</p><p>技术突破解决能用，好用还是要匹配接入现有生态，只有先入局活下来，才能谈发展，类似的还有华为升腾910B，这款AI算力芯片性能可以打平A100，华为之前的昇腾910最大的苦恼就是没人用。&nbsp;</p><p>不是技术问题不能用，而是因为生态残缺很难用，对齐都困难，BUG多到算力粒子需要华为驻厂工程师在场才能运行，之前的市场已经被英伟达占领了，现在大家伙纷纷主动找到华子，再难调教也要上昇腾910，上下游企业携手就可以形成联动，没有人愿意冒着断供的危险去高价买阉割版的芯片。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_e98309d545924d6cb2bb521c6ff0ca3c@000000_oswg53198oswg800oswg533_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最要命的是英伟达能够从臭打游戏的变成现在的算力芯片香饽饽，本质不是自己的技术研发体系多厉害，是因为搭建的CUDA生态，里边上百万开发人员和上万家用户提供的数据反馈让英伟达可以快速迭代，现在白宫的一张A4纸直接把最核心的中国厂商全部切割，没有了下游需求开发人员也纷纷脱离CUDA生态，黄仁勋的心在滴血，“大清的心腹之患就在这朝堂之上”，搅吧闹吧，华为要入关啦。&nbsp;</p><p>性能释放有限，匹配度太差，但是未来可期，和龙芯面临的问题类似，简单来说场面的情况是，整个赛场从跑道到观众甚至于教练都是英伟达的生态，会吃很多苦头，比如适配12400F显卡就会出现黑屏问题，对于Windows11的优化也有很多问题。&nbsp;</p><p>英特尔之前抱大腿，现在国产厂商是抱团取暖，摩尔线程优先为国产软件更丰富的图形特性支持，并且适配麒麟等国产操作系统；而且针对涌现的云需求，专门做了云桌面产品；为了打开游戏市场，在积极推进DirectX 12适配驱动的开发。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_18071995c5ba425e92c66eb297c6e65f@000000_oswg141747oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>结语</h2><p>从科研仪器到芯片半导体，历史的节拍有着诸多惊人的相似，比如长春光学精密的电子显微镜一度追平世界，但是上世纪80年代随着国外电镜的低价倾销涌入，客户大量流失，长春光学失去收入，研发断档，市场被抢占，所有的用户数据反馈又被外国厂商拿到更新自身产品，推出更适用中国科研工作者习惯的产品，并且用反点和回扣拿下代理商，绑定成稳固的利益集团，又是用生态把中国产品挤出局。&nbsp;</p><p>并且国家那时候没有钱，不像现在半导体大基金能连续拿出6000亿的投资扶持，技术只是孤立的点，要驱动起整个产业链，需要用利益杠杆去撬动。&nbsp;</p><p><strong>GPU行业从一片空白，到可以独立设计显卡，到现在摩尔线程自研的GPU春晓和苏堤，国产GPU的生态雏形正在逐步显现。</strong></p><p>自研技术不是闭门造车，和国产大飞机C919类似，永远不要自己去做所有的事情，而是要掌握供应链的关键位置和命门，吃掉利润率最高的部分即可，地球很大，要给所有人一口饭吃才行。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI5MDQxNzE1NQ==&amp;mid=2247503955&amp;idx=1&amp;sn=ac2879bfcb38b390fbda4b81f043ae87&amp;chksm=ed0e29442008543e0b34d68aba2fbe763a4f10502a21fba48ba709c1442c67cddf06e18ad510&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“星海情报局”（ID：junwu2333）</a>，作者：星海老局，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748754224560896</id>
            <title>百度百科App下线，小程序将是工具类App的未来</title>
            <link>https://www.36kr.com/p/2748754224560896</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748754224560896</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 11:52:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小程序, 超级App, 百度百科, 移动互联网
<br>
<br>
总结: 自2017年小程序诞生以来，这个比App更轻的产品迅速就成为了移动互联网的新物种，并很快成为超级App的标配，同时更是各大互联网厂商培育自己软件生态的关键工具。百度百科作为一个冷门App，选择将其迁移到小程序平台，体现了移动端生态下搜索引擎的新定位。 </div>
                        <hr>
                    
                    <p>自2017年小程序诞生以来，这个比App更轻的产品迅速就成为了移动互联网的新物种，并很快成为超级App的标配，同时更是各大互联网厂商培育自己软件生态的关键工具。如此成功的小程序如今也开始渐渐侵蚀传统App的生存空间，以至于有越来越多的厂商陆续将App迁移到小程序平台上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_277dd06cccea40faac47f13a16cf4048@000000_oswg38291oswg517oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>日前百度百科App用弹窗发布通知，“百度百科一直致力于为用户提供权威专业的知识服务。为更好地提升用户体验，我们决定于2024年6月30日关闭百度百科App的服务。在此，我们邀请您使用百度App中的【百度百科】小程序，使用更全面的产品功能，享受更高质量的浏览体验。”</p><p>事实上，百度方面选择关闭百度百科App的原因或许并不复杂，因为这款App实在是过于冷门，甚至它在App Store的“参考资料”类目都不在前100之内。</p><p>诚然，百科类产品一直是搜索引擎的标配，同时也是完成搜索商业化的必要环节。而搜索引擎从本质上来说，其实就是一个收集与整理信息的工具，用户在使用时通常会使用关键词来进行搜索，百科所提供的内容就正好对应一个个不同的词条。在如今这个信息爆炸的时代中，百科内容的质量无疑就可以为搜索引擎所呈现的信息真实性与有效性做出背书。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_ba012b33e55b4fd1b6c56b961c94383c@000000_oswg27507oswg600oswg193_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作为国内市场知名的百科类产品，百度百科已经收录了2800余万个词条，参与词条编辑的网友数量也超过了780万人，几乎涵盖了目前所有已知的相关领域。百度百科之所以敢号称自己是“全球领先的中文百科全书”，背后是其16年的水滴石穿功夫。而百科类产品作为一个许多网友在互联网上寻找相对严谨、正规信息的工具，每天也确实有海量的用户在使用。</p><p>只可惜百度百科也没能逃脱工具类App的宿命，它往往只是为了解决用户某个或某几个特定需求而生。比如支付宝之于移动支付、墨迹天气之于天气、美图秀秀之于修图，也就是说用户只有需要解决相关需求时才会打开。但用户“即用即走”的结果，就是工具类App的月活跃用户规模虽然很高，但是用户粘性却可以说是低得可怕，因此有用户却无流量也是工具类App的命门。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_b225a1f515e84e8a84812b9c163a7a19@000000_oswg43369oswg494oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>百科类产品与搜索引擎的强绑定所导致的结果，就是经过了从PC互联网时代以来长达二十年的熏陶，用户倾向于在Web端或网页上使用搜索引擎、顺便打开百科。换而言之，百度百科作为一个独立App存在的价值其实是有限的。毕竟今时不同往日，随着大量超级App的崛起，大家在手机里安装的App数量不升反降，这就造成了类似百度百科这种冷门App很快变得更门可罗雀。</p><p>小程序就天然更适合轻量化的产品，做点简单的业务、方便传播分享，App则更加适合承载更完全的功能。所以将百度百科作为小程序放进百度App，反而是一个更物尽其用的措施。毕竟壮大百度App的竞争力是当下百度对于移动端的需要，这款App本身就是百度试图在移动生态下为搜索引擎寻找新定位的结果，“有事搜一搜，没事看一看”这样的广告正体现了百度由最初的单一搜索向多元化的转变。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_8c45bff26e7642e0a40708d1e6d0dc12@000000_oswg72255oswg600oswg581_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在链接人与信息的指导思想下，百度App变成了一个超级大杂烩，其中既有百家号、百度贴吧的图文，也有好看视频、爱奇艺、YY的视频和直播，还有一站式聚合充值缴费、医疗健康、外卖团购、旅游出行等本地生活服务。借助百度搜索以及百家号的引流，百度App的月活规模也超过了6亿，但相比其他同体量的App，百度App却显得有些“虚胖”。究其原因，百度App靠着信息流能引来用户，却很难留下用户。</p><p>因此吸引打开了App的用户留下，就成为了百度App的头等大事。那么用户为何会在App里流连忘返，其实抖音、快手、微博都给百度“打了样”，充足的内容供给是关键。例如抖音上有刷不完的视频、微博上有看不完的热搜，可以持续满足用户的内容消费需求。相比友商的内容平台，百度App的问题就在于多而不精，无论是哪一类的需求，都有其他App提供更好的体验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_07e9bae552b7449cb9f10b89ae477020@000000_oswg37469oswg600oswg364_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>问题是在已经失去先机的情况下，即便百度想要专精某一内容领域似乎都已经来不及了。如此一来，继续在多元化的道路上前进，满足用户不同类型的内容消费需求就成为了解决问题的办法，做不出“专才”还可以成为“杂家”。事实上，百度在今年春节期间上线短剧，以及如今将百度百科以小程序形式迁移到百度App，都是在拓宽后者的内容广度。</p><p>因此从技术层面来说，百度百科作为工具类App存在的价值持续下降，而从战术层面来看，百度百科出现在百度App上显然更符合百度的利益诉求。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649862688&amp;idx=3&amp;sn=30bc4c2e4ccdb2e34bfc7395e22bee92&amp;chksm=8676a20145ca42d475814683a8597cb7cbe0ad7231244a7da45fb53b6695e7dce578b483ce9c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748752496851715</id>
            <title>姚前：行业大模型语料库建设与治理</title>
            <link>https://www.36kr.com/p/2748752496851715</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748752496851715</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 11:38:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型语料, 行业专用语料, 语料库现状, 高质量语料库
<br>
<br>
总结: 大模型语料的规模和质量对性能和应用有重要影响，当前存在语料质量不足问题。建议统筹行业力量搭建社区平台，拓宽语料来源，构建高质量语料库。行业专用语料可支持行业分析和决策。不同机构在语料库建设中面临挑战，需要合作共建高质量语料库。建设高质量语料库是行业数字化转型和大模型落地的关键。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_002ba497c6a94a42a83fff11c7aa4991@000000_oswg379640oswg800oswg531_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大模型语料是指用于训练和评估大模型的一系列文本、语音或其他模态的数据。语料规模和质量对大模型性能以及应用的深度、广度有着至关重要的影响。当前行业大模型训练语料存在覆盖面不全、准确性不足、时效性不够等问题，导致大模型通常难以达到预期目标。<strong>实践经验表明，即使模型参数量级有所下降，只要数据语料质量足够高，其表现依然不俗。</strong></p><p>为进一步提升大模型在行业的应用范围和应用成效，需统筹行业力量搭建社区平台，拓宽语料来源，构建语料标准规范，开展语料治理，保障语料安全，为大模型训练及应用提供满足业务场景需求，具备行业特性和标准化的高质量语料。</p><h2>语料的范围</h2><p>行业大模型语料是指用于训练垂直领域大模型的数据集，通常包含自然科学、社会科学等通用语料和行业专用语料。以证券期货行业为例，行业专用语料包括财经新闻、财务报告、法规文件、公开的交易数据等。通过收集和整理语料，可以训练大模型理解和生成行业特定概念和知识，支持行业分析、预测和辅助决策等智能任务。</p><p><strong>（一）通用语料</strong></p><p>引入百科、书籍等通用语料，可使大模型在执行行业特定任务时，减少对专业术语误解的风险（如专业术语的非专业用法、术语的双关语、与特定行业无关的上下文等），并且在面对跨领域的查询或交流时，能提供更为准确和自然的响应。</p><p><strong>（二）行业专用语料</strong></p><p>引入行业专用语料，旨在丰富大模型对于行业特有词汇、表达方式以及特定知识的理解，使模型能够针对性地处理行业相关的复杂查询，执行精准的数据分析，以及更有效地支持辅助决策。此外，基于行业专用语料训练的大模型在进行风险评估、预测、合规性检查等任务时，能展现出更高的可靠性和适用性。</p><h2>语料库现状</h2><p>通常行业管理部门、经营机构以及信息技术服务商都会建设自身语料库。<strong>一方面满足行业知识整理、业务研究、合规风控等自身需求，另一方面可进一步加工成全新的数据资产、研究报告等，对外进行服务。</strong>不同的机构在语料库建设方面的现状以及面临的问题均有所不同，且呈现出自身的特点。</p><p><strong>（一）行业管理部门</strong></p><p>管理部门在构建语料库的工作中，挑战主要在于数据集的规范和数据标准化，这是知识整理的基础。其语料库建设存在以下问题：1.数据分散：许多重要的数据散落在各业务系统中，重要信息和专家经验无法得到有效沉淀，数据共享存在壁垒。2.数据异构：日常积累的大量文本数据，来自于不同的部门和层级，格式、结构和内容不尽相同。3.数据敏感：管理部门数据通常涉及大量敏感信息，在处理和存储过程中必须确保安全合规。</p><p><strong>（二）行业经营机构</strong></p><p>经营机构语料库涉及海量的结构化及非结构化数据，挑战主要在于如何深度挖掘，以支持决策分析和客户服务。其语料库建设存在以下问题：1.处理难度大：来源于多渠道的经营和交易数据，格式、标准均不相同且模态多样，难以有效整合。2.加工深度浅：经营机构的语料库建设仅停留在表层信息，尚不涉及深层的语义理解和深度分析。3.隐私保护难：大模型语料涉及商业秘密及客户敏感信息，在训练和使用过程中经营机构须做好合规风控。</p><p><strong>（三）信息技术服务商</strong></p><p>信息技术服务商擅长整合通用语料，在配合构建行业语料库时面临的主要挑战是专业能力和服务质量。1.专业能力：信息技术服务商对行业语料的分类、分析和解读需要行业知识，其专业能力严重影响语料库的应用价值。2.服务质量：行业语料库建设是一项持续迭代的工作，需要信息技术服务商提供长期的高质量服务。</p><p>此外，合成数据也是大模型训练重要数据来源，在降低成本、提升数据质量、规避隐私问题等方面具有优势。如何探索行业数据合成的有效路径，是行业语料库建设的重大课题。</p><h2><strong>语料库的必要性</strong></h2><p><strong>行业语料库的构建与治理对于发展行业大模型，激活数据要素价值尤为关键。</strong>一个结构良好、内容优质、管理规范的语料库可以为行业参与者提供具备深度洞察力的知识库，促进行业数字化转型和高质量发展。具备公信力的语料库需要行业共建共享，客观上助推行业语料社区的建设和公共服务的发展。</p><p><strong>（一）高质量的语料库是行业大模型落地等创新的基础</strong></p><p>语料决定了模型的训练质量、性能表现以及应用领域的广度与深度。语料库建设除了考虑质量维度，还需关注开放程度。建设统一、开放、标准的行业大模型语料库，有利于提高行业语料的利用效率和价值，促进行业大模型的训练开发，加速大模型的落地应用。</p><p><strong>（二）高质量的语料库是行业数字化转型的重要抓手</strong></p><p>高质量语料应具备大规模、多样性、真实性、连贯性、合法性和无偏见等特点。目前行业高质量语料相对缺乏，推动其建设是实现信息化向数字化、智能化转型的重要之举。</p><p><strong>（三）高质量的语料库是激活数据要素价值，破除数据壁垒的有效手段</strong></p><p>大模型语料通常需要跨机构、宽口径数据，可能会涉及数据安全、隐私保护、知识产权等问题。可探索第三方数据托管等方式，以激活数据要素价值，有效解决跨机构数据共享问题。</p><h2><strong>建设思路</strong></h2><p>建设具备公信力的行业大模型语料库是一项长期性、专业性的系统性工程，涵盖基础设施、公共服务平台、行业规范标准、激励机制等方面。在建设方法、实现路径上需形成合力，多措并举，久久为功（见图）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_7de3c9599c8243f7b2ba7313b1e10204@000000_oswg307017oswg1000oswg558_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>（一）充分借鉴通用语料库的成果和经验</strong></p><p>国际通用语料库，如国外的The Pile、C4、Wikipedia（维基百科）等数据集，以及国内的“书生·万卷”多模态预训练语料、中国网络空间安全协会发布的中文通用语料，都可作为建设行业大模型语料库的基础。为了扩大通用语料库资源，要兼顾自立自强和对外开放，可考虑对Wikipedia、Reddit（美国娱乐、社交及新闻网站）等特定数据源建立过滤后的境内镜像站点，供国内数据处理者使用。</p><p><strong>（二）聚焦语料的供给、托管、加工、安全与评测</strong></p><p>实践经验表明，基于行业语料库，重新训练通用大模型，通用语料和专业语料规模配比通常约为1:1。因此，融合汇聚行业专用语料，加大语料供给，是行业大模型建设的前提。</p><p>一种有效思路是建设数据社区，探索基于可信机构或基于可信技术的平台，为数据主体提供托管服务。行业机构可利用托管数据，基于行业大模型做二次训练或精调，以提升私有模型能力。托管的语料资产也可在社区范围内有偿交易，有序流转。</p><p>语料加工处于大模型训练开发的上游环节，直接影响语料库生产速度、适用范围与质量水平。数据加工，特别是数据标注已形成产业化，行业信息技术服务商可在数据社区进行大规模、专业化数据加工与标注工作，促进行业语料库的建设与规范。</p><p><strong>语料安全是建设行业语料库的“红线”。</strong>要加强监督，保障入库数据内容合规、权益清晰。要完善法律法规，优化政策制度，以多种途径与方式形成监管合力，严防恶意篡改模型和渗入有害数据等行为。探索利用基于人类反馈的强化学习（RLHF）和可扩展监督（Scalable Oversight）等技术方法，保证大模型的输出符合人类价值观，防止大模型生成有害内容。</p><p>行业语料库的评测是进一步完善大模型能力的关键，既要在大模型训练环节对语料库的质量进行评价，也要通过应用成效评估语料库对行业知识覆盖的广度和深度，不断迭代，以达到更好的效果。</p><p><strong>(作者为中国证监会科技监管司司长，本文仅代表个人学术观点，不代表所在机构意见；编辑：张威；本文首发于2024年4月22日出版的《财经》杂志)</strong></p><p><strong>题图来源&nbsp;| pexels</strong></p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg4MzY2MjI5OA==&amp;mid=2247612374&amp;idx=1&amp;sn=ef507326ae5b32393119d6b06e06bfc4&amp;chksm=ce23ca5937dc8cb76d04c9f9d3f850688c44abbbf59cc1061bfc90329f14c632ed0c689e04d8&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“财经五月花”（ID：Caijing-MayFlower）</a>，作者：姚前，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748648930130948</id>
            <title>苹果连放4个开源“小模型”，跑分却不到微软Phi-3一半，不卷性能卷效率？</title>
            <link>https://www.36kr.com/p/2748648930130948</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748648930130948</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 11:31:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, OpenELM, 模型, 开源
<br>
<br>
总结: 苹果在Hugging Face上发布了开源的OpenELM模型家族，包括4个预训练的大模型，参数量分别为270M、450M、1.1B和3B。这些模型在文本相关任务上表现出较高的执行效率，已经开源供开发人员使用。模型采用按层分配参数的策略，提升了Transformer模型各层的参数配置效率，准确率较OLMo提升了2.36%。模型针对端侧和桌面级的本地部署设计，测试平台为家用级设备，性能在常见测试集上表现一般，与主流SLM相比有明显差距。 </div>
                        <hr>
                    
                    <p><strong>文｜李然 陈斯达</strong></p><p><strong>编辑｜苏建勋</strong></p><p>美国当地时间4月24日，苹果在Hugging Face上放出了自己的开源“小模型”家族——4个预训练的大模型OpenELM。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_f10f8068aa234934bccf06c7dc683a0a@5978882_oswg221871oswg1080oswg878_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：X</p><p>四款模型体量极小，参数量分别为 270M、450M、1.1B和3B。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_b962735387d94e27819bde9f1cec84a4@5978882_oswg142274oswg1080oswg571_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Hugging Face</p><p>在Hugging Face页面上苹果表示，OpenELM（Open-source Efficient Language Models，即“开源高效语言模型”）在诸如电子邮件编写等文本相关任务上，有较高的执行效率。系列模型已经开源，可供开发人员使用。</p><p>4月22日发布的相关论文中，研究人员介绍了OpenELM的整个框架，包括数据准备、训练、微调以及测评结果等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_91d8547262554a6eb7a219de133a73b6@5978882_oswg115979oswg1080oswg304_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>论文地址：https://arxiv.org/pdf/2404.14619.pdf</p><p>CoreNet地址：https://github.com/apple/corenet</p><p>模型下载地址：https://huggingface.co/apple/OpenELM</p><h2><strong>模型是真的开源了，但能力也是真的很一般</strong></h2><p>一向以封闭著称的苹果，突然在大模型时代以非常激进的姿态加入开源阵营。</p><p>这次的OpenELM不但提供模型下载，还开源了和模型相关的非常重要的信息：</p><ul><li>模型权重和推理代码</li><li>还包括了在公开数据集上进行模型训练和评估的完整框架，涵盖训练日志、多个保存点和预训练设置</li><li>开源了CoreNet——深度神经网络训练库</li></ul><p>训练库可以使研究人员和工程师能够开发和训练各种标准及创新的小型和大型模型，适用于多种任务，如基础模型（例如，CLIP和大语言模型（LLM））、物体分类、检测以及语义分割。</p><p>OpenELM采用按层分配参数的策略，有效提升了Transformer模型各层的参数配置效率，显著提高模型准确率。在大约十亿参数的预算下，OpenELM的准确率较OLMo提升了2.36%，且预训练所需的Token数量减少了一半。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_d627f5c277b04d5b85b7f5672bd68c67@5978882_oswg132037oswg1080oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>论文透露，模型是在128个A100/H100 GPU上进行的训练，最大的模型训练时长为13天。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_0db613242a6142d8bafe45b18fc18712@5978882_oswg240864oswg822oswg1103_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>模型最体量大仅为3B，可以看出，苹果该系列的模型，只针对端侧和桌面级的本地部署设计。</p><p>论文也透露，所有的测试平台都是家用级设备：</p><ul><li>Intel i9-13900KF CPU, 64 GB内存, 英伟达RTX 4090 GPU，24G显存</li><li>Apple MacBook Pro，M2 Max ，64G内存</li></ul><p>性能上，模型似乎只是研究目的设计，某些常见测试集上取得的成绩也不高。与微软推出的Phi系列模型等主流SLM相比，差距明显。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_cc3fa28bff104eda90bf05dad7507c8b@5978882_oswg429178oswg1080oswg948_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>Phi-3在5-shot的MMLU上，可达到70左右的水平，而OpenELM只有不到30.</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_b32210ff998b4ed18be92a98e08663fe@5978882_oswg281838oswg1005oswg708_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>针对这个问题，网友也对原因进行了一些猜测。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_64b8f61c36814ad489fe877b036499bd@5978882_oswg91246oswg1080oswg252_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：X</p><blockquote><p>用的数据集很小，而且只用了公开的数据集，个人认为，他们只是在对未来训练更大的模型进行针对性的研究。</p></blockquote><p>开源社区的用户们，也第一时间对模型进行了些测试，整体反馈是模型似乎过于“对齐”，换句话来说就是——废话可能有点多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_5eee7a82c69e436490342133a2804f05@5978882_oswg24390oswg729oswg141_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：X</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_705dd7b37a784ee7be98c9cc25174832@5978882_oswg108892oswg1080oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：X</p><p>从目前开源社区的反馈来看，OpenELM似乎不是一个精心设计和训练后用来秀肌肉的模型，所以性能和表现离同体量最领先的模型差距不小。</p><p>论文中，研究人员也没有过于强调模型的能力，而是纠结于准确率和推理性能。</p><h2><strong>去年已有开源动作，技术实力还待6月亮剑</strong></h2><p>放弃造车后的苹果，在大模型战争中动作愈发频繁。（见智能涌现文章<a href="https://www.36kr.com/p/2691937970793865" rel="noopener noreferrer" target="_blank">&nbsp;<strong>苹果300亿参数大模型首亮相，还买了家AI公司</strong></a>）</p><p>很多时候，<strong>“买买买”是大家对苹果AI布局的主要印象之一。</strong></p><p>3月15日，苹果收购了加拿大AI初创公司DarwinAI。自身AI团队一下扩充几十个技术人员。4月23日又曝出，早在去年12月已经悄悄收购巴黎AI初创公司Datakalab。这家2016年成立的公司，亦专注低功耗、高效率的深度学习算法。</p><p>苹果最近的这两起收购都围绕端侧大模型展开——比如DarwinAI想把AI系统打造得“小而精”，Datakalab专于低功耗、高效率的深度学习算法，无需依赖云端系统即可运行。</p><p>也是在3月，苹果被爆出与谷歌进行谈判，希望将Gemini集成到新的iPhone中。此外，据透露，苹果还与OpenAI进行了讨论，考虑使用其模型。</p><p>不只是“招兵买马”，<strong>在研究端，起步稍晚的苹果也不忘“卷卷卷”。</strong></p><p>2023年10月，苹果发布名为Ferret的开源LLM。这一模型结合了计算机视觉和自然语言处理技术，能识别图像中的对象和区域，将文本转化为视觉元素，并进行图像相关的文本对话。</p><p>2024年4月初，基于Ferret，苹果发布多模态大模型（MLLM ）Ferret-UI，表现出不凡的UI屏幕理解能力——不仅优于大多数开源UI MLLM，而且在所有基本UI任务上也超过了GPT-4V。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_d9ad99bc986d47b09521aab21a3143e5@5978882_oswg402383oswg904oswg770_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>此前，苹果保密原则伴随的封闭生态，一度让外部开发人员无法介入。一开始，Ferret研究没有得到太多关注，其以非商业许可证开源，不能用于商业目的。</p><p>但发布两月后的12月底，AI医学非营利组织的运营商Bart De Witte反应过来——原来苹果10月就加入了开源社区，自己没注意到这次重要的发布。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_2bebd21e325c47969e623ec489315448@5978882_oswg67186oswg743oswg269_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：X</p><p>也就是在这个时间点上，Ferret又为人热议——这一反苹果此前的保密立场，表明了自身在AI方面的开放态度。</p><p>可以说，在今年2月财报发布会上库克公布生成式AI计划之前，苹果自身的AI研究进展就很多了。2023年12月，它推出专门在 Apple 芯片上用于机器学习的开源阵列框架 MLX。2024年2月，又发布图像编辑模型MGIE，让用户无需通过照片编辑软件，就能用简单语言描述他们要在照片中更改的内容。</p><p>2024年3月，苹果在论文中介绍的 “MM1”多模态大模型，同样拥有图像识别和自然语言推理能力。不过和其他大模型比起来，MM1的效果不算惊艳。苹果只是围绕MM1开展实验发现影响模型效果的关键因素。</p><p>MM1的论文指出，无论是开源还是闭源，现在都没有真正分享达到算法设计经历的过程。所以苹果希望借MM1的研究打破局面，在论文里公开模型训练的种种细节。</p><p>同样，OpenELM模型的确彰显了端侧模型的进展，但技术貌似并没有达到外界的预期。</p><p>或许，这次苹果通过发布完整的训练、评估框架等，以再次表达“Open”的决心。论文表示：</p><blockquote><p>此次全面发布，希望在增强和巩固开放研究社区，为未来的开放研究工作铺平道路。</p></blockquote><p>所以，OpenELM效果一般，网友还是也会为苹果的开放感到意外。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_b6ff2d39fcc24bd3945258d840c1e6fa@5978882_oswg18348oswg734oswg135_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：X</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_62086a66acba467d983163b51bd8ab4f@5978882_oswg46703oswg738oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：X</p><p>苹果真正的AI实力，要等到六月的全球开发者大会（WWDC）才能揭晓。但开源做出的“姿态”，几个月算是表现到位了。</p><h2><strong>论文重点</strong></h2><h3><strong>模型构架</strong></h3><p>苹果的研究人员采用了仅包含解码器的Transformer架构，但是作出了一些特殊的调整：</p><ul><li>在线性层中不设置可学习的偏置参数</li><li>采用RMSNorm进行预归一化，并使用旋转位置嵌入(ROPE)来编码位置信息</li><li>用分组查询注意力(GQA)来替代传统的多头注意力(MHA)</li><li>将传统的前馈网络(FFN)更换为SwiGLU FFN</li><li>采用闪电注意力机制计算缩放点积注意力</li><li>使用与LLama相同的Tokenizer进行文本处理</li></ul><p>OpenELM与传统的大语言模型的最大不同在于，通常大模型在每一层Transformer中使用相同配置，而OpenELM为每层设置了不同的配置（如头数和前馈网络的尺寸），使每层的参数数量各不相同。</p><p>这种方法，让OpenELM能更有效地利用参数预算，从而达到更高模型准确率。通过“层间缩放”（也称为块间缩放），实现了这一层间参数的非均匀分配。</p><h3><strong>预训练数据和训练细节</strong></h3><p>研究人员只使用了公开的数据集进行预训练。</p><p>具体包括RefinedWeb、去重后的PILE、RedPajama和Dolma v1.6的部分数据，总计约1.8万亿Token。</p><p>从苹果提供的公开数据来源来看，数据包括了像arXiv，维基百科，Reddit，GitHub等各种主流的网络社区和百科知识平台。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_0c29c38552274a2aa44c94709a017b05@5978882_oswg88896oswg715oswg649_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>值得一提的是，苹果没有采用预先分词（pretokenized）的数据，而用了即时过滤和分词的方式处理文本数据。这种做法，使研究人员能够轻松地尝试各种tokenizer，极大简化了原型设计和研究过程。实验中，他们就采用了与LLama相同的tokenizer。</p><h3><strong>训练结果</strong></h3><p>研究人员将OpenELM与一些公开的大语言模型进行了对比，包括PyThia、Cerebras-GPT、TinyLlama、OpenLM、MobiLlama和OLMo。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_505e7a7783444ac6930cabb52957da9f@5978882_oswg256095oswg1080oswg471_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>性能与OpenELM最接近的，是MobiLlama和OLMo。这两个模型都是在更大规模的数据集上进行预训练的。</p><p>从上图中可以看出，OpenELM的准确度随着训练迭代次数的增加而提升，在多数任务中都表现出明显的准确率增长。</p><p>此外，通过对最后五个检查点的平均处理（这些检查点是每隔5000次迭代收集一次），显示出与350k次迭代后获得的最终检查点相当或略优的准确率。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_dbc0a855cb164f2c9c040c0cc2cb3f6e@5978882_oswg596452oswg1080oswg920_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>上图实验结果显示，OpenELM在各种评估框架中。都显示出超越现有方法的有效性。例如，一个拥有11亿参数的OpenELM变体，在与拥有12亿参数的OLMo比较时，在不同的评估中准确率分别提高了1.28%、2.36%和1.72%，而且这是在使用不到一半的预训练数据的情况下实现的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_2736aa8e5330425b9978408cea3287e8@5978882_oswg482757oswg1080oswg948_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>指令微调之后，上图的结果表明，指令微调在不同的评估框架中，一致地提高了OpenELM的平均准确率，提升幅度为1-2%。</p><h3><strong>推理性能表现</strong></h3><p>研究人员主要测试了模型在两个文章开头介绍过的PC和Mac两个平台上的推理性能表现。</p><p>可以看出，代表着Mac主流配置的M2 Max平台，在跑3B模型时推理性能可以达到每秒34 token，已基本超过人类的阅读速度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a71b84d78a8840678a46d0a7817e0a6e@5978882_oswg368987oswg1080oswg778_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>在最顶级的PC配置下，3B模型的推理速度达到了70。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_3ce839b2c6604fbca71c361026e2d4cf@5978882_oswg180054oswg997oswg664_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>尽管OpenELM在相似参数量下具有更高的准确性，但是它的推理速度比OLMo慢。</p><p>分析显示，OpenELM处理时间的一个重要部分，可以归因于RMSNorm的初级实现（下图所示）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_0e9f0586450743a98f6ca47f3a709f1b@5978882_oswg532528oswg1080oswg857_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：论文</p><p>具体来说，初级RMSNorm的实现，导致许多单独的内核启动，每个内核处理少量输入，而不是像使用LayerNorm那样启动单个融合内核。</p><p>通过将初级RMSNorm替换为Apex的RMSNorm ，OpenELM的推理速度显著增加。</p><p>然而，与使用优化过的LayerNorm的模型相比，仍然存在显著的性能差距，部分原因是：</p><ul><li>OpenELM有113个RMSNorm层，而OLMo有33个LayerNorm层</li><li>Apex的RMSNorm对小输入未进行优化</li></ul><p>为了进一步说明由于RMSNorm造成的性能下降，研究人员将OLMo中的LayerNorm替换为RMSNorm，观察到生成吞吐量显著下降。在未来的工作中，研究人员计划探索优化策略，以进一步提高OpenELM的推理效率。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748753918163716</id>
            <title>手机厂商再次进军xR领域，MR方向更受青睐</title>
            <link>https://www.36kr.com/p/2748753918163716</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748753918163716</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 11:21:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 博鳌亚洲论坛, vivo, xR领域, MR产品
<br>
<br>
总结: 在博鳌亚洲论坛上，vivo执行副总裁透露下一代手机产品将是MR，vivo已在xR领域布局，计划在成立30周年时推出MR原型机。手机厂商在xR领域有新动作，苹果发布Vision Pro后市场格局发生变化，MR具备与真实世界保持联系的优势，手机厂商选择MR作为主要突破方向。 </div>
                        <hr>
                    
                    <p>在日前举行的博鳌亚洲论坛期间，vivo执行副总裁、首席运营官胡柏山透露，下一代具有手机潜质的产品将是MR，并且vivo早已在xR领域布局，将会在成立30周年时推出一款MR原型机。自从苹果方面发布Vision Pro以来，各大手机厂商又开始在xR赛道频频动作，并先后有大量相关消息被曝光。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_f82f4d98834240c4a9d22d6762a490a1@000000_oswg32643oswg550oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事实上，手机厂商早已在xR领域进行布局，早年间在VR兴起之初，一众手机厂商便察觉到了这一新兴技术所带来的潜在机遇，并曾大量推出过各类相关产品。但需要注意的是，这些早期的VR产品本质上其实更像是手机的配件或是玩具。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a398f29bb30146e0aa0ad2193509a44e@000000_oswg28190oswg550oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当时的一些VR头显虽然具备光学组件、传感器，能够检测用户头部动作、并给出相应的反馈，但其核心仍是智能手机，并没有独立计算的能力。在这一时期，以谷歌Cardboard为代表的“玩具”，也凭借着极低的门槛引发了大众对VR头显的关注。</p><p>后续一些手机厂商针对这似产品高度依赖智能手机的局限性，也推出了具备独立算力的VR一体机。但受到当时硬件条件的限制，其性能相对较弱，在使用体验上更是大打折扣。同时由于内容的匮乏，一旦用户的新鲜感褪去之后，就会被遗忘在某个角落“吃灰”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_212d950ed45c47fb86c9c55c2f48b24c@000000_oswg16666oswg550oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这些早期的尝试在取得了一定成果的同时，其实也暴露出了大量的问题，诸如硬件、生态等方面无法满足用户需要，体验不尽如人意更是关键。因此在经历了一段时间的尝试和探索后，手机厂商在VR领域的动作也逐渐变得低调起来。</p><p>但xR领域的市场格局，则在苹果去年推出Vision Pro之后发生了剧变，这款“空间计算”平台也为一众手机厂商提供了新的思路。苹果方面在发布Vision Pro时就曾明确表示，“如同Mac将我们带入个人计算时代， iPhone将我们带入移动计算时代一样，Vision Pro将带我们进入空间计算时代。”</p><p>对于苹果来说，Vision Pro不仅是其对现有技术的革新，同时也是其对于未来个人计算平台方向的探索。随着用户对于计算平台便捷使用方式的需求不断增长，传统的手机、电脑就已经显得略不从心，而MR头显由于具备融合虚拟世界和真实世界的能力，因此也带来了完全不同于现有设备的体验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_14020ef4334b47f6ac328e3c11a8b853@000000_oswg11624oswg550oswg404_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>手机厂商在看到xR领域的新机遇之后，也开始陆续布局MR方案。例如OPPO就曾在去年的AWE（增强世界博览会）期间推出了首款MR设备，OPPO MR Glass Developer Edition（OPPO MR眼镜开发者版）。虽然其面向的是开发者，旨在开拓MR应用和探索MR相关技术的前景，并没有在主流市场开售。</p><p>目前在xR赛道，基本可以细分为VR、AR，以及MR三个主流方向。而手机厂商大多选择MR作为主要突破方向的原因，实际上也是对于不同技术方向的考量和取舍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_3b96b620cb23446792eb57736a47fa94@000000_oswg13185oswg550oswg368_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>相较VR方案，MR则具备让用户与真实世界保持联系的优势。苹果CEO蒂姆·库克就曾明确表示，用户不应被鼓励长时间沉浸在虚拟世界中，这会造成与现实世界的脱节。而MR在能够提供沉浸式虚拟世界体验的同时，用户可以通过抽离屏幕快速回归现实世界，而这种切换就满足了用户对数字世界和现实世界的不同需求。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_fd07e972d34444c0b7a169a2126b4770@000000_oswg20597oswg550oswg319_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如今在性能方面，MR较AR方案也展现出了更多的优势。目前常见的AR设备受限于设备体型，往往无法搭载性能更强的配置，因此在算力方面也存在先天不足。而MR对此的顾虑则相对较少，毕竟更大的体型就使得其能够搭载算力更强的芯片。以Vision Pro为例，就配备了桌面级的芯片，也为整个xR赛道树立了新的性能标杆。当然，Vision Pro这种方案也带来整机重量上升的问题，但在目前需要先解决有无的问题下，这个弊端相对而言并非主要矛盾。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_27f9ad569b2b4b0d852f21a7671db970@000000_oswg27490oswg550oswg386_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>值得一提的是，此前星纪魅族集团董事长兼CEO沈子瑜曾表示，“没有手机公司赋能的AR厂商，都将看不到未来”。这一观点也表明，如今AR方案距离成为独立计算平台还有一定的距离。</p><p>如今相关硬件的升级，也使得xR产品在性能方面迎来了大幅的提升。例如高通方面今年年初推出的骁龙XR2+ Gen2平台，在性能方面就迎来了大幅的进步，尤其是在分辨率提升以及延迟降低方面，还要无疑问将会在极大程度上提升MR头显的平均水平。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_b998e29d8e0a4c14a0b336af1a4ff606@000000_oswg35574oswg550oswg322_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>相关研究已经表明，头显的分辨率最好能够达到单眼4K以上级别，而骁龙XR2+ Gen2的单眼4.3K分辨率显然就已经“入门”。而且更为重要的是，凭借着与手机厂商的长期合作关系，高通方面也有望推动更多手机厂商基于这一平台研发相关产品。去年三星就曾宣布将与高通和谷歌合作，共同推出一款全新的头显。尽管具体细节尚未公布，但有消息称其或将是对标Vision Pro的高端产品。</p><p>而推动手机厂商转向MR的另一个关键因素，则在于产业链的日渐成熟以及成本的大幅降低。据IDC分析师指出，随着Micro OLED屏幕等关键零部件的不断升级与成熟，头显的制造成本有望显著降低。而这种趋势对手机厂商、用户，以及市场而言，显然都是是极大的利好。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_6e68901ed4614239800ed560736ee639@000000_oswg26406oswg550oswg354_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>凭借自身完善的供应链体系，手机厂商也将能够更好地控制MR头显的成本，进而提升产品的市场竞争力。而这种成本方面的优势，不仅有助于手机厂商在市场中抢占先机，更有望改变当前xR领域的格局。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649862688&amp;idx=4&amp;sn=73b5cdb6d627fcc9e3562f9e394b5d3c&amp;chksm=86b8183e487604974d190327012d0b12dcf6b2ecce0557026f8541e555285c29537d238a0d74&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748759676795648</id>
            <title>苹果开源大模型OpenELM来了，它可能用在下一代iPhone上</title>
            <link>https://www.36kr.com/p/2748759676795648</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748759676795648</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 11:15:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, OpenELM, 大模型, 端侧设备
<br>
<br>
总结: 苹果发布了OpenELM大模型，这是一系列可在端侧设备上运行的开源大型语言模型，包含4个不同参数版本，提供了权重、检查点、模型性能统计等信息，预训练数据规模庞大，采用CoreNet作为训练框架。苹果加入开源大模型竞争，展示生成式AI战略，将在AI领域取得重大进展，转向生成式AI领域。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_fab02510a8ed47d9bf61f5d247bc3c0e@46958_oswg35379oswg700oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：界面新闻/蔡星卓</p><p>4月25日消息，据VentureBeat报道，苹果近日在AI代码社区Hugging Face上发布了OpenELM大模型。这是一个由不同参数大小构成的一系列开源大型语言模型，可运行在端侧设备上。&nbsp;</p><p>据界面新闻了解，该系列模型包含2.7亿、4.5亿、11亿和30亿共4个不同参数版本。基于较小的参数量，这些模型可在端侧设备上独立运行，而不必连接云端服务器。具体而言，其一共包括4个预训练模型和4个指令调优模型。&nbsp;</p><p>针对这套开源大模型，苹果在其“样本代码许可”下提供了OpenELM模型的权重、检查点、模型性能统计，以及预训练、评估、指令调优和参数高效微调的说明。&nbsp;</p><p>整套示例代码许可并没有禁止商业使用或修改，但要求完整分发该软件的开发者保留上述通知和免责声明等文本。同时，苹果公司指出，这些模型没有安全保证的前提，有可能在用户反馈过程中产生不准确、有害、有偏见或令人反感的输出。&nbsp;</p><p>据苹果在Hugging Face上的公开信息，尽管这四套模型参数最小仅有2.7亿，最高30亿，但预训练数据规模高达1.8万亿tokens（模型处理文本时的基本单位）。这些数据来自Reddit、维基百科、arXiv.org等网站构成的公共数据集。同时，苹果采用CoreNet作为训练框架，这是苹果专门用于训练模型的深度神经网络库，目前也已开源。&nbsp;</p><p>这些模型可运行在笔记本电脑甚至智能手机上，苹果举例称，其中一台是配备M2 Max芯片、64GB RAM，运行macOS 14.4.1的MacBook Pro。&nbsp;</p><p>苹果发布OpenELM，意味着它正式加入开源大模型，尤其是端侧大模型的赛道之中，正如谷歌、微软、三星等科技公司正在做的那样，而这一动作也进一步揭开苹果生成式AI战略的神秘面纱。&nbsp;</p><p>彻底放弃造车以后，苹果在生成式AI上的表现将是决定其下个十年科技领域地位的最大筹码。在2024苹果股东大会上，苹果CEO蒂姆・库克表示，今年将在生成式AI领域实现重大进展。该公司一部分造车团队成员也开始转向生成式AI。&nbsp;</p><p>微软、谷歌等科技巨头们已经打得火热，苹果也不可能沉寂太久。就在上个月，苹果研究团队已经发布一篇名为《MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training》的论文，正式公布在多模态大模型领域的研究成果。&nbsp;</p><p>MM1是一个具有最高300亿参数（另外还有30亿和70亿）的多模态大模型系列，由dense（密集）模型和MoE（混合专家）架构变体组成。该系列大模型在数个多模态基准、上下文预测、多图像和思维链推理等方面均有不错表现。&nbsp;</p><p>相较于AI大模型行业前沿激战正酣的千亿、万亿参数级别大模型，苹果目前的大模型显然不是一个以AGI（通用人工智能）为目标的产品，但其阶段性目标也明确在百亿参数内的高性能表现上，即如何将AI大模型的能力更好与端侧设备的本地运行能力相融合——这也是技术适应产品并推动产品的基本逻辑体现。&nbsp;</p><p>唯一特殊的地方在于，手机系统时代的苹果以iOS的封闭生态为最大卖点，但在AI大模型领域，它却罕见选择开源。至于具体原因，可能要静待这家公司在WWDC2024（苹果全球开发者大会）上更详尽地阐释。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/YEhAzBHDP35xJl77BHRJfQ" rel="noopener noreferrer nofollow" target="_blank">“界面新闻”（ID:wowjiemian）</a>，作者：伍洋宇；编辑：宋佳楠&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748736666437381</id>
            <title>当张一鸣遭遇“竞业协议”</title>
            <link>https://www.36kr.com/p/2748736666437381</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748736666437381</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 11:07:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 竞业协议, 技术转移, 九九房, 搜索技术
<br>
<br>
总结: 文中讨论了竞业协议对互联网从业者的影响，以及涉及技术转移的法律纠纷。文章还回顾了九九房的创业历程和搜索技术的发展。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_51d891f8d22a4c8f86359d3e6081039c@5966151_oswg571912oswg1080oswg612_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有些事不上秤没四两重，上了秤一千斤也打不住。&nbsp;</p><p>过去几年里，批量遭遇竞业协议的互联网打工人，对这句话应该有着更切身的体会。签署竞业协议的离职者中，很大一部分从未预料到这张纸有一天真的会让他们付出巨大的代价。毕竟他们对自己还是有点B数的，公司真要上纲上线，成本上算不过来。&nbsp;</p><p>竞业协议的法律依据，是《劳动合同法》第二十四条，其中提到竞业限制仅适用于“用人单位的高级管理人员、高级技术人员和其他负有保密义务的人员”。然而现实情况是，越来越多的基层员工正被列入竞业限制的范围。&nbsp;</p><p>《晚点LatePost》本月初的文章曾列举过一个案例，某跨境电商雇佣有约5万名外包劳务员工，而他们从2月起跟公司签订的新合同里就增加了竞业限制条款。在通常认知中，外包劳务跟法规中的“两高一密”角色，显然有着相当的距离。&nbsp;</p><p>不过这几天，倒是有个真正的高级管理人员兼高级技术人员遭遇了类似处境。&nbsp;</p><p><strong>《纽约时报》4月19日刊登了一篇报道，宾州一家法院误将与字节跳动诞生有关的封存法庭文件对外公布了。其中提到两名承包商指控海纳国际把一些尖端搜索技术带给了字节跳动，但却没有提供合理的补偿。</strong></p><p>张一鸣之前在酷讯干过，并由此结识了海纳亚洲的王琼，后来王琼找张一鸣来创业做房产垂直搜索网站九九房。九九房的创业经验显然对张一鸣创办字节跳动有直接的启发，而上述诉讼的焦点则在于这个过程中是否涉及技术的不当转移。&nbsp;</p><h2>九九房开始的官司</h2><p>九九房创立于2009年9月，曾经是国内最大的房产搜索网站。张一鸣当时做九九房的思路是，是用不同的产品来服务不同的用户需求，所以九九房推出了一堆APP，包括“房产资讯”、“掌上租房”、“掌上买房”等六个产品。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_db5c729415b84b7aac020e6e0d3c7bbf@5966151_oswg262912oswg768oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>后来字节化身“APP工厂”的时候，有人把这种做法溯源到了九九房时期，但本质上这其实是两种完全不同的思路。&nbsp;</p><p>跟百度一样，九九房虽然是面向房地产行业的垂直搜索引擎，但它本身并不生产内容，而是依靠爬虫抓取网络上的公开信息，比如58或者赶集上的帖子。这种方式很好地解决了网站的冷启动问题，并且切中了用户当时的痛点。因为那个时期移动端才刚兴起，行业还没有摸清楚房产经纪产品到底该怎么做。&nbsp;</p><p>但在初期完成起步过后，九九房并没有切换平台运营的模式，仍然没有引入强运营和强审核的机制。就像今天各大平台上五花八门的租房信息真假难辨一样，当时假房源的问题肯定会更突出。&nbsp;</p><p>不过可能也不是张一鸣不想做，因为这不是九九房一家的问题，当时爱屋吉屋这样的平台也一度风头无两，但最终同样销声匿迹。<strong>用左晖的话说，“消费互联网是先横后纵 ，产业互联网是先纵后横”，没有此前深耕产业的积累，光靠互联网是革不了链家的命的。</strong></p><p>九九房这个项目谈不上有多成功，在矩阵式产品布局的情况下，到2011年也只有10万的日活。张一鸣把创业看作赌博，既然成功是小概率事件，那就要把频次拉上去，做大成功的概率。在这种情况下，2012年他给九九房找了个新CEO，就带着几个人创办了字节跳动。&nbsp;</p><p>在九九房的这堆APP里，对后来字节跳动所有产品都产生深远影响的，是“房产资讯”。“房产资讯”基本上可以看作是今日头条早期的产品原型，只不过内容聚焦在房产垂直领域。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_5c23d371c68e4a0285e5a0b9d8e37cfb@5966151_oswg488477oswg841oswg451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今日头条首个产品总监黄河曾这样形容这款应用：“就是做所有房产信息的收集分发，特别受欢迎。先把信息聚合起来，再做推荐。你甚至可以把它理解成，现在今日头条的房产频道”。&nbsp;</p><p>房产资讯的这套运作模式，构成了后来字节跳动所有产品的骨架。无论是最开始的“搞笑囧图”和“内涵段子”，还是说后来的“今日头条”，都建立在对内容的抓取、清洗、聚合、推荐这串动作之上。&nbsp;</p><p><strong>九九房当初因为爬取其他网站的房源和内容信息，一度在外界引发是否涉及违法的争议，后来版权问题也是今日头条早期面临的最大危机。</strong></p><p>这些渊源都佐证了九九房跟字节跳动之间的密切联系，但以此来判定字节从九九房那里不恰当地获得了某些知识产权肯定是站不住脚的。&nbsp;</p><p>《纽约时报》的文章并没有提及原告的具体诉求，涉案的相关法庭文件也已经重新封存无法查阅，但通过对张一鸣创业经历和思路的梳理，我们仍然可以对这场口水仗有个大概的判断。&nbsp;</p><h2>张一鸣需要“技术援助”吗？</h2><p>《纽约时报》文章中透露，原告提出的具体指控针对的是“尖端搜索技术”（cutting-edge search technology）。无论是早前的酷讯还是九九房，搜索技术都是产品底层的支撑。&nbsp;</p><p>张一鸣曾经对酷讯搜索的三个特征做过总结，包括聚焦地理位置的同城搜索、高时效性的即时搜索以及准确响应用户需求的垂直搜索。张一鸣当时在酷讯待了两年，做到的位置是技术委员会主席。&nbsp;</p><p><strong>也就是说，起码在酷讯时期，张一鸣就在搜索引擎方面的技术积累就已经足够支撑一家大型网站的运营了。</strong></p><p>九九房最初是从酷讯的房产频道拆分出来的，从这点看，显然没有理由认为后面去MSRA转了一圈、又以技术合伙人身份跟王兴做了一段时间饭否网和海内网的张一鸣，在做九九房的时候还需要投资人从美国要技术援助。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_45c436088e924e878eea75249ef1fbd4@5966151_oswg995694oswg964oswg613_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，考虑到海纳之前就已经投过酷讯，所以不排除“技术援助”是在酷讯时期就干过的。但如果真是这样，那把这跟2012年才成立的字节跳动扯上关系就相当牵强了。&nbsp;</p><p>《深渡》倾向于认为，在张一鸣从酷讯开始的职业生涯中，海纳可能以投后服务的视角从外界引入了一些技术资源，并且当时已经谈妥了相关的补偿协议。但当字节凭借抖音和TikTok飙升成估值数千亿美元的巨头时，前技术承包商又觉得该分一杯羹，毕竟这蛋糕太大，稍微切点回报就会非常可观。&nbsp;</p><p><strong>其实，写代码这个领域，无论从整体的行业氛围，还是从实际的可操作性上说，你要搞人无我有的技术垄断都是不现实的。起决定性作用的从来不是技术，而是创业者对趋势的判断和将产品落地快速迭代的能力。</strong></p><p>互联网的确属于高新技术产业的范畴，这点从互联网公司创始人普遍良好的教育背景就能看出来。当产品用户规模快速膨胀时，往往也需要对原先粗糙的软件做重构，并发量一上去，CTO没两把刷子必然是搞不定的。&nbsp;</p><p>但同时值得指出的一个事实是，这也是个最为“知识平权”的行业。这个领域里，那些最为前沿的技术进展，不管是早期像Unix这样的操作系统，还是最近的大语言模型，那些放在传统行业本应秘不外宣的know-how都被公之于众。所以，过去二十年里似乎还没有哪家互联网公司纯粹因为技术上卡脖子而倒闭的。业界的最佳实践摆在那里，源码都剥光了给你看，就算自己不会还招不到会的人吗？&nbsp;</p><p>另一方面，从技术的角度说，真正奠定今日头条和抖音成功基础的，其实是推荐引擎而非搜索引擎。虽然在实现层面，两者都涉及到复杂的数据处理流程，但二者要实现的目标是截然不同的。&nbsp;</p><p>传统上搜索引擎因为是由用户的明确查询触发，因此需要快速准确的响应，并且没有太多的个性化空间。而推荐引擎则主要是从用户的行为、偏好来预测其可能感兴趣的内容，有着更高的自由度和个性化空间。<strong>整体来说，一个被动响应，一个主动推荐；一个用户驱动，一个系统驱动。</strong></p><p>张一鸣很早就认识到了推荐引擎的价值。在酷讯时，他写了个小程序，让机器自动搜索火车票信息，如果条件触发就短信通知自己。他后来回忆这段经历时，曾说由人找信息到信息找人的范式转变，是他最早关于推荐引擎的思考和实践。后来九九房的“房产资讯”产品，让他有机会实践并且强化了基于推荐引擎的信息分发思路。&nbsp;</p><p><strong>但就推荐引擎的技术成熟度上说，直到后面今日头条上线，张一鸣都还处于“边干边学”的状态。</strong></p><p>2012年底，在锦秋家园六楼的办公室里，张一鸣召集团队开了个会，会议的核心议题是“要做一个信息平台，势必要把个性化推荐引擎做好，现在要不要启动这个事情？”&nbsp;</p><p>他在给团队打气时，还说了一句话：推荐我们不会，但可以学啊。后来知道Hulu的项亮在写一本《推荐系统实践》，张一鸣还尝试找他要电子版想学习，尽管被项亮以书还没有出版为由拒绝了。这些细节说明两点：一是机会总是留给有准备的人，但不存在完全准备好的人；二是字节开始创业的时候，张一鸣等人还有些赶鸭子上架的意思。&nbsp;</p><h2>结语</h2><p>张一鸣曾说过一句话，你对事情的认知，是你最大的竞争力。今日头条、抖音和TikTok能走到今天，技术是重要的因素，但从“人找信息”到“信息找人”的认知转变，才是决定性的因素。从这个角度说，当互联网的内容载体因为通信基础设施的升级从图文切换到视频的时候，字节从今日头条里孵化出抖音似乎就是注定的。&nbsp;</p><p>所以，如《深渡》在上面提及的观点，原告发起这桩官司的目的更像是赤裸而又牵强的“抢蛋糕”行为。不过，从另一个角度说，今天各大互联网公司越来越严格的竞业限制是否又是同样的赤裸而牵强呢？海纳国际有充分的资源来应对诉讼，而面临类似场景的打工人，在跟大厂的博弈中则处于绝对的弱势地位。&nbsp;</p><p>这值得反思。&nbsp;</p><p>*文中配图来源于网络。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_WHvyAlp6stVR7OfYJozJw" rel="noopener noreferrer nofollow" target="_blank">“深渡Cross”（ID:DeepCross02）</a>，作者：深渡Cross，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748741773261830</id>
            <title>非洲手机之王，一天没了143亿</title>
            <link>https://www.36kr.com/p/2748741773261830</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748741773261830</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 11:01:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 传音控股, 智能手机市场, 成本优势, 增长瓶颈
<br>
<br>
总结: 传音控股在智能手机市场表现亮眼，凭借成本优势和碎片化市场经验持续增长，但面临增长瓶颈。通过性价比和海外市场拓展取得成功，但股价波动引发市场担忧。 </div>
                        <hr>
                    
                    <p>这几天，传音控股相继交出两份亮眼财报，并再次宣布大手笔分红，2023年合计分红额将接近公司当年净利润。但其股价不涨反跌，4月25日更是大跌10.88%，市值蒸发了143亿元 。市场在担心什么？</p><p>随着手机行业陷入众所周知的增长瓶颈，出海已成为各大手机厂商撑起“增量”部分的最有力杠杆。&nbsp;&nbsp;</p><p>据近期市场调研机构Canalys公布的“2024年第一季度全球智能手机出货数据”显示，全球智能手机出货量同比增长11%——小米和“非洲手机之王”传音则分别坐上了全球第三和第四的位置。&nbsp;</p><p>据该报告显示：去年小米全球出货量约为1.46亿部，其中超1亿部进入了海外市场。而传音的出货量几乎全在海外，为9490万部，只略略低于小米。&nbsp;</p><p>但若按毛利计算，传音却以大约小米手机业务三分之一的收入，拿下了小米手机60%左右的毛利——取得这样的成绩，传音也再度吸引了市场的目光。&nbsp;</p><p>4月22日和4月24日，传音控股连续发布了2023年度报告和2024年第一季度财报。年报显示，2023年传音实现收入622.95亿元，同比增长了33.69%，实现归属于母公司所有者的净利润达到了55.37亿元，较上年同期增长122.93%。&nbsp;</p><p>能在过去几个季度持续增长，一方面源于传音极致的性价比，另一方面也源于传音正在不断走出非洲，在南亚、拉美、中东等新兴市场持续攻城略地。&nbsp;</p><p>Canalys高级分析师朱嘉弢告诉「市界」，在中低端市场，传音的产品硬件配置相对比较好，甚至和友商存在一定代差。而新兴市场消费者粘性都不是很强，属于价格敏感人群，传音凭借性价比俘获了不少用户。&nbsp;</p><p>业绩飙升同时，传音进行了大手笔分红。据财报显示，公司2023年年度现金分红数额合计达到约48.39亿元，占公司2023年归母净利润的87.40%，几乎分光了公司净利润。&nbsp;</p><p>不过在多重利好消息下，4月25日传音股价却突然大跌，以-10.88%收盘，市值蒸发了143亿元，目前市值1171亿。这家明星公司的业绩，是否已经出现了拐点？&nbsp;</p><h2>一部手机只赚28.5元</h2><p>今年第一季度，传音的手机占比份额再度保持增长。据IDC数据显示，传音是目前全球前五大手机厂商中增速最快的。2024年第一季度出货量增速达到了84.9%，卖出了2850万台智能手机，市场份额占比为9.9%。&nbsp;</p><p>提到传音这个品牌，由于主做海外市场，一两年前国内对其熟悉的用户并不多。直到最近几个月传音的业绩爆发、股价暴涨，才被市场广泛关注。&nbsp;</p><p>但在手机行业，不少业内人士早已注意到传音。它一开始就选择了其他厂商看不上的非洲市场作为大本营，并一度将市占率做到了50%以上，被冠以“非洲手机之王”的称号。&nbsp;</p><p>作为传音的创始人，竺兆江早期是波导手机管理层，后出走创业。如今整个传音管理层，仍以“波导”系为主。据传音官网信息显示，目前传音控股董事会成员共九位，除了三名独立董事以外，董事长竺兆江和其他五位董事当年都曾在波导手机任职。&nbsp;</p><p>得以在非洲市场立足，传音的一大优势，便是售价足够低，成本优势比较大。&nbsp;</p><p>据财报披露，2023年传音在全球卖出了1.94亿部手机，排名全球第三，市占率达到了14%。而在智能手机市场，IDC数据显示，传音2023年智能手机出货量约9500万台，市占率为8.1%，排名全球第五。&nbsp;</p><p>也就是说，目前传音仍有超过50%的出货量为功能机，智能机占其出货比例不到一半。数据显示，目前传音出货的主力还是200美元以下机型，虽然毛利率不错，但是单机利润并不高。&nbsp;</p><p>此前阿尔法工场曾在报道中披露，传音手机的平均销售单价（ASP）仅有500多元人民币。&nbsp;</p><p>据「市界」计算，以净利润为口径，传音2022年卖出1.56亿部手机，净利润24.84亿元，一部手机大约只赚取16元净利。而到了2023年，传音卖出了1.94亿部手机，净利润翻倍至55.37亿元，每部手机赚取的净利润约为28.5元，但仍属于薄利多销。&nbsp;</p><p>不过得益于成本优势，传音的毛利率并不低，甚至比部分友商要高不少。&nbsp;</p><p>以手机业务毛利为口径的话，传音2023年手机业务收入573.48亿元，毛利率24.18%，手机业务毛利为138.67亿元。以小米集团作为对比，小米2023年手机业务收入1574.6亿元，毛利率14.6%，手机业务毛利为229.89亿元。&nbsp;</p><p>也就是说，传音手机业务以大约小米手机业务三分之一（36.4%）的收入，创造了超过小米手机业务一半（60.3%）的毛利。当然，小米目前的业务比较多元化，旗下还有互联网服务、IoT和金融等更高毛利的其他业务，而传音的营收结构相对单一。&nbsp;</p><h2>非洲之王的秘密</h2><p>据传音一季报显示，其增速还在持续维持高位。2024年第一季度，公司实现营收约174.43亿元，同比增加88.1%；归属于上市公司股东的净利润达到16.26亿元，同比增加210.3%。作为对比，2022年全年传音控股的净利润也才24.84亿元。&nbsp;</p><p>从非洲到南亚，从东南亚到拉美，这一轮市场增长，为什么是传音吃下了红利？这和传音的生产成本优势有一定的关系。&nbsp;</p><p>和其他厂商相比，传音主要走性价比路线，在研发和品牌上的投入要明显比其他厂商压力小很多。2023年，传音控股的研发费用为22.56亿元，占营收比例仅3.6%。而小米集团研发费用为190.98亿元，占营收比例达到了7%。&nbsp;</p><p>“传音在研发、品牌和采购等方面的摊派成本会小很多，所以在整体成本上确实有一定的优势。”朱嘉弢表示。&nbsp;</p><p>另一方面，传音自建工厂和本地化生产的模式也有利于成本控制。&nbsp;</p><p>据传音财报显示，传音采用以销定产的生产模式，生产方式包括自有工厂、外协工场和ODM厂商。多年深耕非洲和南亚市场，传音在当地均建立了本地化工厂。&nbsp;</p><p>此外，传音表示，公司生产、研发、采购和销售均包含外籍本土员工，坚持全球化视野和本地化创新理念。例如针对非洲市场，传音研发了低成本高压快充、超长待机、环境电流检测、防汗液USB接口等符合本地市场需求的技术。&nbsp;</p><p>传音对碎片化市场的打法经验积累，也成为其最近增长的关键。&nbsp;</p><p>在Canalys分析师朱嘉弢看来，从非洲起家的传音更擅长做碎片化的市场。现在传音开拓的拉美、中东、东南亚等市场，同样也比较碎片化，水货和灰色贸易市场比较发达，传音在非洲做碎片市场的经验正好能派上用场。&nbsp;</p><p>据IDC数据显示，2023年传音在非洲智能手机市场占有率超过40%，排名第一。另外，南亚地区也是传音的优势地区，传音在巴基斯坦、孟加拉国智能手机市场排名第一，市占率分别超过40%和30%；在印度市场排名第六，市占率8.2%。&nbsp;</p><p>与此同时，传音也在往高端市场探索，推出了折叠屏产品，平均售价也在提升。传音在财报中表示，公司研发了折叠屏手机、卷轴屏概念手机、探索者卫星通信、隔空充电等技术和产品，不断向中高端市场迈进。&nbsp;</p><p>年报显示，2023年传音控股在非洲市场的毛利率达到30.97%，同比增加3.34%。在亚洲等其他地区市场的毛利率为21.11%，同比增长4.86%。&nbsp;</p><p>毛利数据也充分证明了，传音在被认作是“低端市场”的非洲，反而是中高端做得比较好，毛利率显著高于其他地区。&nbsp;</p><p>对此，朱嘉弢对「市界」表示，因为深耕非洲多年，传音在非洲品牌比较有优势。并且在当地还覆盖了比较全面的APP和软件生态，能帮助传音卖出更好的均价。&nbsp;</p><h2>股价为何不升反降？</h2><p>2019年，传音在科创板上市，四年时间里，其营业总收入便从当初的253.46亿元增长至现在超过600亿元，年复合增长率超过30%，在整个A股市场都属于佼佼者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_f3d551e99093493aa4c8434f2680de02@46958_oswg155592oswg1080oswg841_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据Canalys数据，2024年第一季度全球智能手机出货量同比增长11%。而IDC研报显示，2024年第一季度全球智能手机出货量同比增长7.8%至2.894亿部。本季度传音出货量排名全球第四，出货量增长84.9%。&nbsp;</p><p>不过，在传音连续交出两份骄人的财报，并进行了大手笔分红后，其股价却不升反降。截至4月25日收盘，传音股价大跌10.88%，股价从一周前的179.17元高点下跌至145.18元。&nbsp;</p><p>市场认为，这可能和传音业绩利好释放较早有关。从2023年12月起，传音股价已经连续上涨数月，从最低的109.68元涨至一周前的高点。如今利好出尽，市场反而对其进一步的增长存在一定的疑虑。&nbsp;</p><p>朱嘉弢表示，从财报上看，今年第一季度同比增速较快，也与2023年第一季度传音主要是清库存，出货量不高，基数较小有关。但2023年第二季度，传音的基数已经起来了，尤其是下半年增长很快，所以接下来的财报中，传音要继续维持高速增长可能比较困难。&nbsp;</p><p>“现在传音的成本优势也在被挑战，一方面是现在手机行业零部件价格上涨，增加了整机成本。另一方面传音在很多市场份额已经比较高，未来更多要在品牌和团队上投入，也会推高成本。”&nbsp;</p><p>一名在东南亚工作的传音员工对「市界」表示，传音手机大部分售价折算成人民币只有1000元左右，目前他们卖得最贵的折叠屏，换算成人民币也只要4000元左右。而同样的价格，在国内基本只能买到入门旗舰机，大部分品牌的折叠屏手机售价都在6000元以上。&nbsp;</p><p>据IDC数据显示，截至2023年第三季度，中国手机市场的均价已经达到了3480元，高端市场的价值进一步凸显。传音后续也在面临一定的增长压力。&nbsp;</p><p>另外，在业绩飙升的同时，传音也给员工发出了超额年终奖，同时对股东进行了大手笔分红。&nbsp;</p><p>不久前「市界」在报道传音时曾提到，2023年底，传音向员工下发通知：公司绩效系数为1.3，即所有员工在正常核算年终奖基础上多发30%年终奖。&nbsp;</p><p>就在日前，传音宣布拟向全体股东每10股派发现金红利30.00元（含税），合计拟派发现金红利约24.20亿元（含税），占公司2023年归母净利润的43.70%。&nbsp;</p><p>在此之前，传音控股已于2023年前三季度实施了权益分派，派发现金红利约24.20亿元，因此公司2023年年度现金分红数额合计达到约48.39亿元，占公司2023年归母净利润的87.40%。&nbsp;</p><p>这样大笔的分红，也被不少中小股东看作是“良心公司”。近日，在传音股价下跌后的雪球社区里，不少用户表示：下跌和业绩没什么关系，前两年涨幅太大了而已。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/r_yW54nA2MT7ZwfKx7hMPQ" rel="noopener noreferrer nofollow" target="_blank">“市界”（ID:ishijie2018）</a>，作者：曾广，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748717843741703</id>
            <title>初创团队不到10人，Augment获2.52亿美元融资，将成GitHub Copilot竞争对手</title>
            <link>https://www.36kr.com/p/2748717843741703</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748717843741703</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 10:51:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI编码辅助, 初创公司, 人工智能, 融资
<br>
<br>
总结: 一家「名不见经传」AI编码辅助初创公司Augment突然宣布完成2.52亿美元的融资，投后估值达9.77亿美元，成为全球「独角兽」之一。该公司专注于为大型代码库提供人工智能编程辅助工具，具备快速、高质量代码生成等功能。创始人Igor Ostrovsky曾在微软和Pure Storage等公司担任重要职位，团队成员履历不简单，展现出强大的技术实力和潜力。 </div>
                        <hr>
                    
                    <blockquote><p>一家「名不见经传」AI编码辅助初创公司估值9.77亿美元。</p></blockquote><p>AI 正在极大地推动编码工作，AI 编码辅助工具 GitHub Copilot 曾一度被扣上「窃取程序员工作」的帽子。&nbsp;</p><p>如今，这一领域再迎踢馆者。&nbsp;</p><p>4 月 24 日，一家「名不见经传」AI 编码辅助初创公司 Augment，突然宣布完成 2.52 亿美元的融资，投后估值达 9.77 亿美元，距离成为全球「独角兽」仅一步之遥。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_9d433524fef74536a8fdb53afff7c49b@000000_oswg46472oswg1080oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此次 Augment 投资方阵容相当豪华，Sutter Hill Ventures、Index Ventures、Innovation Endeavors、Lightspeed Venture Partners 和 Meritech Capital 等风投领域重要玩家均位列其中，个人投资者还包括前谷歌 CEO Eric Schmidt。&nbsp;</p><h2>一家神秘兮兮的 AI 编码初创公司</h2><p>在最近的一项 StackOverflow 调查中，44% 的软件工程师表示他们已经在开发流程中使用 AI 工具，26% 的人计划很快使用。Gartner 估计，超过一半的组织目前正在试用或已经部署了 AI 驱动的编码助手，到 2028 年，75% 的开发者将以某种形式使用编码助手。&nbsp;</p><p>AI 辅助编码似乎已是大势所趋。Augment 正是踩中这一风口。</p><p>作为一家 AI 初创公司，Augment 专注于为大型代码库提供人工智能编程辅助工具。与竞争对手相比，该工具主打一个快，推理速度甚至比对手快 3 倍，并且能够生成高质量的可运行代码，减少令人沮丧的幻觉。此外，Augment 还具备适配大型代码库、支持多开发者和团队、 强大的知识产权保护等功能。</p><p>Augment 创始人 Igor Ostrovsky 认为，「软件工程仍然是一项艰巨的工作，而且往往乏味而令人沮丧，尤其是在规模较大的情况下。人工智能可以提高软件质量和团队生产力，帮助人们重拾编程的乐趣。」</p><p>其实在自曝融资消息之前，这家公司相当低调且神秘，截至目前，Augment 在 X 平台上也仅有 405 个关注者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_068d471d1d0e4a709df912db770123f2@000000_oswg230273oswg1080oswg758_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>前 Google Brain 研究科学家 @hyhieu226 在 X 上发帖称，「一年前，我离开了 Google Brain（现在的 DeepMind），加入了一家非常早期的初创公司 Augment。当时我们的人数还不到 10 人，后来已经增长了很多倍。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_084118c790ed4674a06de827237713ca@000000_oswg228262oswg1080oswg426_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在采访中，Augment 创始人 Igor Ostrovsky 更是三缄其口，不愿意透露太多关于用户体验的信息，甚至不愿意透露驱动 Augment 功能的人工智能生成模型，只说 Augment 正在使用经过微调的 「业界领先」的某种开放模型。</p><p>不过，Ostrovsky 倒是透露了 Augment 计划的盈利方式：标准的软件即服务订阅。Ostrovsky 补充说，定价和其他细节将在今年晚些时候公布，离 Augment 计划的全球发布时间越来越近。</p><h2>一群微软、谷歌工程师「搞事情」</h2><p>别看 Augment 名气不大，团队成员的履历却不简单。</p><p>2002 年，Augment 创始人 Igor Ostrovsky 就读于不列颠哥伦比亚大学（The University of British Columbia）计算机科学专业，大学期间就开始接软件工程师这类活，毕业后正式加入微软担任高级软件开发工程师，并开发了 Midori 操作系统的组件。Midori 是一个微软从未发布的非基于 Windows 核心的全新操作系统。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_237a612ca12e41529827cc5312aa9435@000000_oswg253108oswg1080oswg910_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2013 年，在微软工作近 7 年的 Igor Ostrovsky，以创始工程师身份加入 Pure Storage，领导 FlashBlade 的技术开发，使其终身销售额达到 20 亿美元。Pure Storage 是一家开发闪存数据存储硬件和软件产品的初创公司。</p><p>2021 年底，Ostrovsky 作为 Sutter Hill Ventures 的常驻工程师，一头扎进生成式人工智能领域。</p><p>「作为一名软件开发者，我可以清晰地看到生成式人工智能将如何改变我的领域。我们在 GitHub Copilot 和 AlphaCode 等技术上看到了早期的希望，但很明显，这仅仅是开始。我想象着人类和人工智能一起合作开发软件，人类通过人工智能实现 Augment。」</p><p>于是，Ostrovsky 联合前谷歌人工智能研究员 Guy Gur-Ari 创立了 Augment。</p><p>Guy 本科毕业于以色列高等学府希伯来大学，后在魏茨曼科学研究所深造，2014 年成为斯坦福大学的博士后研究员。</p><p>之后，Guy 加入谷歌担任研究科学家，期间它他领导了一个研究团队，负责理解和改进深度学习系统，包括训练大语言模型来解决复杂推理任务，并为谷歌的 PaLM 系列模型（Gemini 的前身）做出贡献。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_6a6b6589a5904cc0bc4b4661c0385986@000000_oswg271296oswg1010oswg502_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Augment 的 CEO 是 Scott Dietzen，他是一名经验丰富的创业「老炮」。</p><p>他四次创业成功，曾创办 WebLogic、Zimbra、Transarc 以及 Pure 四家公司，其中在担任 Pure Storage 首席执行官时，Pure 的营收从 0 增长到超过 10 亿美元，员工从 15 人增加到数千人，并成功上市。</p><p>此外，他还在卡内基梅隆大学获得计算机科学博士学位，专注机器学习。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_00c8e6c7a314464b809c5d04c6ea0fff@000000_oswg201356oswg1016oswg516_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Augment 的工程副总裁 Evan Driscoll 同样来自 Pure Storage 公司。他曾在 Pure Storage 公司担任同样的职位，一度将三个业务部门的工程团队从数十人扩大到数百人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_0f75cd479af74833bd48ded7b2bba2bf@000000_oswg73874oswg1032oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Augment 产品副总裁 Dion Almaer 曾在谷歌担任主管，他负责的产品被数百万开发者在 Chrome、搜索和 Android 等领域使用。他还在 Shopify 担任开发者体验副总裁、在 Mozilla 和 Palm 担任主管。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_3a71df14e96f4dae94bbca10d63451e2@000000_oswg225569oswg1044oswg528_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前，Augment 大约有 50 名员工，Ostrovsky 预计到年底这个数字将翻倍。</p><h2>Augment 能在行业中掀起波澜吗？</h2><p>虽说 Augment 踩中风口，但要想在这个竞争日益激烈的行业中掀起波澜并非易事，毕竟几乎每家科技巨头都推出了人工智能编码助手。</p><p>例如微软的 GitHub Copilot，截至今年 2 月，它已拥有超过 130 万名付费个人用户和 5 万名企业用户，是迄今为止地位最稳固的产品。亚马逊有 AWS 的 CodeWhisperer，谷歌则有 Gemini Code Assist，最近从 Duet AI for Developers 更名而来。</p><p>在其他领域，编码助手初创公司如雨后春笋般涌现：Magic、Tabnine、Codegen、Refact、TabbyML、Sweep、Laredo 和 Cognition 等。开发了 Kotlin 编程语言的 Harness 和 JetBrains 最近也发布了自己的产品。</p><p>如此混乱的「战局」，Augment 能占据一席之地吗？似乎不太可能。</p><p>单是令人瞠目的计算成本，就让人工智能编码助手业务充满了挑战。与训练和服务模型相关的超支迫使生成式人工智能编码初创公司 Kite 于 2022 年 12 月关闭。据《华尔街日报》报道，即使是行业「扛把子」Copilot 也在亏钱，每个用户每月亏损约 20 到 80 美元。</p><p>虽然 Augment 创始人 Ostrovsky 声称，「数十家」公司的 「数百名」软件开发人员，包括支付初创公司 Keeta（也是 Eric Schmidt 支持的公司），都在早期使用 Augment。但是，这些用户会持续使用吗？这可是一个价值百万美元的问题。</p><p>其次是 Augment 在解决困扰代码生成人工智能的技术问题上是否采取了措施，尤其是在漏洞方面。</p><p>同名代码分析工具开发商 GitClear 的一项分析发现，编码助手正在导致更多错误代码被推送到代码库中，这给软件维护人员带来了麻烦。安全研究人员警告说，生成式编码工具会放大项目中现有的漏洞和利用。斯坦福大学的研究人员发现，接受人工智能助手推荐代码的开发人员往往会编写出安全性较低的代码。</p><p>最后是版权问题。</p><p>Augment 的模型无疑是在公开数据基础上训练出来的，就像所有的生成式人工智能模型一样 ，其中一些可能已经获得版权或限制性许可。一些供应商辩称，合理使用原则使他们免于版权索赔，同时还推出了一些工具来减少潜在的侵权行为，但这并没有阻止程序员们就他们所称的开放许可和知识产权侵权行为提起集体诉讼。</p><p>参考内容：</p><p>https://www.augmentcode.com/</p><p>https://twitter.com/hyhieu226/status/1783237649035383002</p><p>https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzUyODA3MDUwMA==&amp;mid=2247518717&amp;idx=2&amp;sn=3c549789435c658bbbd84b77066d558d&amp;chksm=fb6a005560d3dd00971a60dc8c35972d04d4f855ba13da9deaeb9f3f7ba0e05162e0fc29ed29&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之能”（ID：almosthuman2017）</a>，编辑：山茶花，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748703207734274</id>
            <title>雷军“粉丝见面会”开在北京车展，“蔚小理”避其锋芒</title>
            <link>https://www.36kr.com/p/2748703207734274</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748703207734274</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 10:48:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 新能源车型, 小米汽车, 问界, BBA豪华品牌
<br>
<br>
总结: 2024年北京国际汽车展览会以“新时代、新汽车”为主题，展出了大量新能源车型，其中小米汽车和问界成为焦点，而BBA豪华品牌也加码新能源领域。展会还展示了多款全新概念车，推动汽车市场向高质量发展迈进。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_03620436cfd949caa19d8b49002f7e2c@46958_oswg289137oswg983oswg516_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>4月25日，阔别四年之久的第十八届北京国际汽车展览会正式拉开帷幕，本次车展主题“新时代、新汽车”。根据组委会公布的资料显示，本次车展展出的新能源车型数量达278辆。</p><p>由此，今年车展的主角非新能源车莫属。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_eef49a07481c4c1da6362ea2049849aa@000000_oswg1620876oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源/镜观台拍摄&nbsp;</p><p>“新人”雷军的到来，将车展氛围拉至另一高点，用雷军的话说就是“amazing”。</p><p>小米汽车北京车展发布会现场，人潮涌动，身为小米品牌行走“活广告”的雷军也是金句频出，“小米的入门版不是丐版，不是青春版，是别人的天花板”等，点燃全场热情。</p><p>值得一提的是，往年车展的流量担当“蔚小理”，在面对雷军时，默契地延后了自己的发布会，避其锋芒。</p><h2>小米、问界占据C位</h2><p>总览之下，今年北京车展有超25家新能源品牌亮相展示，除了小米汽车，方程豹、阿维塔、深蓝等也首次亮相北京车展。。</p><p>小米作为一个汽车领域的新生代选手，正可谓“初生牛犊不怕虎”，其展位正处W2馆C位地带，此展位周身环绕吉利、智己、极越，被认为火药味最浓的展馆。</p><p>上市发售已近一个月时间的小米SU7，其火热程度仍未缩减，北京车展第一天，小米展台的人流量拥挤。相比之下，同一馆中，日产、福特等合资品牌展区人流量明显稀少。</p><p>同时，凭借小米的高流量，W2馆成功在本次车展的众多展馆中脱颖而出，斩获最多人流量。</p><p>值得注意的是，此次小米汽车北京车展发布会上，小米汽车创始人雷军亲自上阵，其表示，SU7上市28天的锁单量，截至4月24日，共75723辆。</p><p>对于目前小米展台未曾像此前网络传言那样展出9种车色，雷军表示，“将在公众日全部展出”。</p><p>而作为本年度市场表现另一“黑马”的问界，其连续三个月月销量超理想，问鼎新势力月销冠。此次车展，其携全系车型亮相赛力斯汽车展台。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_1346d30b3f73467f8f4e566c6369a703@000000_oswg869871oswg846oswg587_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源/镜观台拍摄&nbsp;</p><p>其中，于4月23日发布的问界新M5标配HUAWEI ADS 2.0高阶智驾系统，此次的展车为黑色。从外观上来看，问界新M5前脸采用了全新的鲨鱼鼻车头设计，相比旧款更秀气。</p><p>安全配置上，这款车配备全方位的主动安全系统，AEB主动刹停时速提升至120km/h，相比旧款在安全系数上有所提升。</p><h2>奋力一搏！BBA加码新能源</h2><p>在电气化、智能化日趋火热的背景下，除新势力品牌外，头部车企的动向也备受关注，这其中，以奔驰、宝马、奥迪等为首的豪华品牌，除在车展亮相旗下燃油车型外，还集体展出新能源车，企图分羹新能源领域的市场份额。</p><p>一个很有意思的现象，今年BBA三大品牌依旧没能同时出现在同一展馆，遵循上一届车展的“拆开”打法，分别和其他品牌共用展馆。</p><p>具体来看，奔驰位于E4展馆，展台上映入眼帘的正是奔驰的首款纯电大G，该款车延续了燃油版大G的方正、硬朗线条；配备12模组可用电量为116kWh的电池组，CLTC工况下续航里程达570公里左右；同时，此次北京车展是该款车的全球首发。</p><p>奔驰展台一工作人员表示，“奔驰G580这款车在动力上采用四轮独立电机，电池搭载的是全新开发的硅阳极电池。”</p><p>宝马位于W4馆，不同于奔驰，宝马展台里有i5、XM、iX等多款新能源车型，其中新纯电动BMW i 4也是首次在全球市场实车现身。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_00b90a93eb864cde9d10a589e3ce5123@000000_oswg828429oswg846oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源/镜观台拍摄&nbsp;</p><p>而此前，声称要放缓电气化转型脚步的奥迪，于本次车展“苏醒”，携全新奥迪Q6 L e-tron亮相。奥迪Q6L e-tron是基于PPE豪华纯电动平台打造的，作为下一代纯电平台，其拥有诸多技术创新。据悉，该款车可实现10分钟充电255公里续航。</p><p>面对新能源市场的“蛋糕”，理想、蔚来、极氪等“造车新势力”仍在以其先发优势持续分羹，但面临于前燃油车增量疲软的状态，以BBA为首的豪华品牌电气化转型之路势在必行，2024北京车展只是个开始。</p><h2>多款全新概念车玩转车展</h2><p>2024北京车展作为今年汽车市场的风向标，吸引着众多品牌携旗下产品的亮相。基于此，合资品牌、自主品牌纷纷拿出自家的概念车型，以科技感碰撞未来新趋势，推动汽车市场迈向高质量发展之路。</p><p>具体来看，日产Hyper Force概念车是一款纯电高性能跑车，其车身曲线趋近流畅，整体车翼、轮毂设计给人以机甲风，更似“GT-R”的新能源版。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_f5b44fbcb5ae4ee29b1e8eeb5d9299f6@000000_oswg973131oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源/镜观台拍摄&nbsp;</p><p>参展者小池表示，“我是来看Formula E Gen 3那款赛车的，但一到日产汽车展区就被Hyper Force的酷炫外形所吸引。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_074504bc467b47c9981dee95b6f44552@000000_oswg689765oswg799oswg507_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源/镜观台拍摄&nbsp;</p><p>事实上，本次日产展区内，细分车型，除Hyper Force这款概念车前的人流量较大外，Formula E Gen 3也是日产展区的一大亮点，该款概念车旁增设了AI和3D体验，给参展者带来亲临赛道的科技前瞻体验。</p><p>方程豹作为比亚迪旗下自主新能源品牌，于本次车展拥有独立展位，其展出的概念车有两款，分别为SUPER 9、SUPPER 3，其中SUPER 9超跑型概念车是继仰望U9之后，比亚迪第二款跑车。</p><p>值得注意的是，目前方程豹品牌在售车型虽仅有一款，但其表现在SUV新能源市场是拿得出手的，2024年一季度方程豹豹5累计销量1.1万辆。</p><p>未来，方程豹多款产品上市发售后，其市场表现能否持续向好，有待考量。</p><p>大众全新概念车ID.CODE是一款SUV，不过相比于一般的SUV，其车身较低，使用了更多折线设计，采用俯冲式的引擎罩、犀利的轮拱和力量感十足的肩线腰线，整体造型飘逸。受此车的利好影响，大众展位人流量明显多于其他合资品牌。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_6f077ee2de974a5eb35195fbb8437b92@000000_oswg981992oswg846oswg634_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源/镜观台拍摄&nbsp;</p><p>大众汽车乘用车品牌中国 CEO 孟侠（Stefan Mecha）曾表示，“这款专为中国市场打造的概念车将品牌 DNA 带入了新时代，以革新造型和领先科技满足中国消费者对智能网联时代的一切期待。”</p><p>多款概念车的问世，在为车展带去科技与现实碰撞的同时，也给日后的汽车产业提供发展方向的新思考。</p><p>*题图来源于镜观台拍摄。&nbsp;</p><p>*免责声明：在任何情况下，本文中的信息或所表述的意见，均不构成对任何人的投资建议。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzUyNzcxNTgxOQ==&amp;mid=2247643002&amp;idx=1&amp;sn=d7080b74c6ef29324626b3df57b48219&amp;chksm=fba85930da9a498dd98b90352b9234b3bc15febbb6beb7ac3652f704366333b7924d6a268ebf&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“镜观台”（ID：JINGGUANTAICN）</a>，作者：丛润宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748698554678281</id>
            <title>面板大厂倒闭停产，回顾液晶面板之争</title>
            <link>https://www.36kr.com/p/2748698554678281</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748698554678281</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 10:20:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 面板大厂, 液晶显示技术, 日本液晶产业, 韩国企业
<br>
<br>
总结: 本文介绍了面板大厂群创南京模块园区计划关闭的消息，以及液晶显示技术的兴起历史，日本液晶产业的崛起和韩国企业的反周期投资成功，最后讨论了中国企业进军LCD市场打破垄断的情况。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_8d52c9a05e39496587745bb030282afb@46958_oswg219839oswg890oswg516_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据报道，面板大厂群创南京模块园区计划关闭，设备将转至宁波厂，正在分批遣散员工，影响人数2395人。群创致力于 TFT-LCD 技术研发与产品制作，南京厂曾是世界上最大的中小尺寸 TFT 面板制造基地。&nbsp;</p><p>4月10日，这一消息在群创光电的一则说明媒体报道的公告中得到证实。群创光电表示，公司致力提升生产配置及整体营运效益，将南京厂部分产线、产品进行调整，同时优化与调节人力结构，以强化集团发展。&nbsp;</p><p>而就在近日，又有媒体爆料称，鉴于液晶面板业务低迷，日本夏普（SHARP）已决定暂停旗下堺市10代面板厂营运公司 “ Sakai Display Product（SDP）” 生产的部分大型液晶面板产品。&nbsp;</p><p>过去数十年来，液晶面板的竞争版图一直在不断变化。最近几年，伴随韩日退出LCD领域，中国大陆在该领域的竞争优势愈加明显。&nbsp;</p><h2>液晶显示技术的兴起</h2><p>某些物质在熔融状态或被溶剂溶解之后，尽管失去固态物质的刚性，却获得了液体的易流动性，并保留着部分晶态物质分子的各向异性有序排列，形成一种兼有晶体和液体的部分性质的中间态，这种由固态向液态转化过程中存在的取向有序流体称为液晶。&nbsp;</p><p>19世纪后期，科学家就发现了液晶这种东西。一直到了1960年，一家美国公司开始把液晶用于显示技术。1962年，海尔梅尔，发明了液晶显示技术，这是一位毕业于普林斯顿大学的博士生，此时正在美国无线电公司（RCA）研究中心担任兼职助理研究员。&nbsp;</p><p>直到1968年，RCA公司制成了世界上第一个液晶显示模型，在纽约召开了发布会，日本企业参加了发布会，由此知道了美国人研发的这项新技术。为了达到量产化，RCA公司由此成立了专门的液晶业务部门，主要的工作将由RCA公司半导体部门的克莱恩和他的团队负责，他们的研究集中在LCD制造的几乎每一个生产环节，包括研制更大规模制造室温液晶材料的新制程以及改进填充和密封显示器的工艺技术等。&nbsp;</p><p>RCA公司虽然发明了液晶显示技术，但是液晶显示速度太慢，颜色也太单调，距离能看的彩色电视还有很远。时间一长，RCA公司便放弃了该技术的继续研发。此后，其他美国公司也因为类似的理由，先后放弃了液晶显示技术的研发。&nbsp;</p><h2>击败欧美企业，日本液晶产业崛起</h2><p>在RCA公司发布会上见到新技术的日本人对液晶产生了浓厚的兴趣。率先出手的，是日本钟表企业－精工。精工手表于1973 推出世界第一只具有6位数字液晶显示的数字液晶腕表(06LC)。1975 推出世界第一只数字液晶显示的多功能计时电子腕表。&nbsp;</p><p>随着不断的投资，液晶技术越来越成熟，逐步解决了显示速度慢，颜色单一等等问题。此后，日本企业的崛起便一发不可收拾，很快便将发明液晶显示技术的美国企业打的节节败退。1988年，夏普、东芝、NEC等公司，都具备了生产大尺寸液晶屏的技术。1990年，全球90%的液晶显示屏在日本生产；1991年，夏普率先开动了第一条大尺寸液晶屏的生产线。1992年，IBM公司推出了ThinkPad笔记本电脑系列，它的第一个产品700C，采用10.4英寸的彩色液晶显示屏。此后，液晶显示市场被引爆。夏普、NEC、富士通等等日本企业纷纷响应市场需求，开建了第二代液晶生产线，生产笔记本显示屏。&nbsp;</p><p>到1990年代中期，全球95%的液晶产能都在日本，几乎垄断了全部产业链。此后欧美企业在竞争失败后便纷纷退出了竞争。&nbsp;</p><h2>反周期投资——韩国企业的异军突起</h2><p>当日本垄断液晶产业后，液晶的应用也逐步广泛起来，随着笔记本市场的成熟，液晶行业迎来了新一波高潮。但随之而来的便是产能过剩的危机。&nbsp;</p><p>1993-1994年，液晶生产进入了第一个周期——价格下跌，利润大减。日本企业因为亏损，削减产量。这一过程中大量产业链和人才储备被出售或失业，而韩国正是抓住了这个机会，撬开了各方面壁垒，大量日本工程师被韩国企业聘用，当韩国掌握相关技术后，反周期投资成为击败日本的绝技。&nbsp;</p><p>随着日本企业投资意愿下滑，韩国趁势在亚洲金融危机期间狠砸面板产业，越亏越投。1995年，三星、LG两家企业分别建成了自己的液晶生产线。2001年，三星、LG两家公司咬牙投资了5代生产线。投产以后，韩国企业就彻底赶超了夏普等日本企业。三星、LG两家公司的市场占有率分别是世界第一和第二，份额接近50%，成为面板新霸主，打得日本公司无力招架。韩国财阀模式给了企业强大的资金背景，因此韩国有能力投产更大尺寸的生产线，不断冲击液晶面板市场。当更大更清晰的面板上市时，激活了很多曾经没有的市场需求, 让韩国在竞争中力狂澜。&nbsp;</p><p>虽然之后日本企业采取了越过5代生产线，直接投产尺寸更大的6代生产线的措施，但却为时已晚。之后，1998年，产能竞争失败的日本企业将目光瞄准了受金融危机冲击最小的中国台湾地区，转而扶持中国台湾企业，与台系厂商签订了技术转移合同，收取高额专利费，同时利用中国台湾的廉价产能狙击韩国。不负众望，中国台湾的面板产业迅速崛起，成为四大支柱产业之一。&nbsp;</p><p>然而，天有不测风云，2008年金融危机过境，台系面板厂遭遇暴击，下游需求萎靡，上游有产无销，顺便带崩了日本面板产业。2009年，NEC关掉了鹿儿岛的液晶面板工厂。两年后，索尼把液晶面板业务打包卖给了三星，三菱电机也退出了面板业务。2016年，夏普也被富士康收入囊中。&nbsp;</p><h2>中国企业进军LCD市场，打破垄断</h2><p>韩国依靠强大的资金实力，逆周期投资打败日本企业，LCD面板巨额的资金让其他后来者望而却步。但随着中国综合国力的提升和经济实力的崛起，打破韩国垄断出现了新变数。&nbsp;</p><p>最早国内企业以引进国外LCD产线与进口LCD产品为主开始进入行业。2003年1月，京东方对外正式宣布，用3.8亿美元收购韩国现代的一条液晶生产线。同时，他们还想在北京开建一条5代液晶生产线。2009年后，京东方开建了中国大陆首条自主设计与自主建设的8.5代TFT-LCD产线，总投资280亿元。同年，华星光电自主启动8.5代TFT-LCD生产线。国内多家面板企业走向自主创新道路，我国面板行业迅速扩张。&nbsp;</p><p>2015 年国内京东方重庆 B8、华星深圳 T2、熊猫南京 C2 三条国产高世代线投产，LCD 面板供给大幅增加。面对大陆 LCD 产能扩张，韩国厂商三星、LG 收缩部分 LCD 产能，改而扩建 OLED 产能，2016 年三星/LG 退出产能 398 万平/季（折合 8.5 代线 240K/M，约等于中国企业扩产的产能）。2018年之后，京东方合肥 B9、京东方武汉 B17、华星深圳 T6、华星深圳 T7、夏普广州 10.5 等又相继投产。&nbsp;</p><p>随着中国大陆的面板厂商持续发力，陆续投建产线并加大投资，京东方、惠科股份、彩虹股份等厂商快速追赶。目前，大陆面板产能全球市占率近七成。&nbsp;</p><p>2020年，华星光电接手了三星苏州工厂，后续又拿下三星在美国和韩国的LCD专利；京东方收购了中国电子旗下中电熊猫的8.5代线产能。&nbsp;</p><p>2021年，京东方营收2193亿，净利润258.31亿，同比暴涨412.96%；另一家面板厂华星光电营业收入1635亿元，净利润149.6亿元，同比增长195.3%。就连二线的维信诺也业绩爆表，营收增长高达32.32％。&nbsp;</p><p>随着业绩的爆发，与日本和中国台湾地区鏖战近30年后，韩国人退出了这场残酷游戏。据市场调查公司Omdia统计，去年LCD电视面板出货量2.5827亿片，其中中国厂商占比60%以上。中国最大面板厂商京东方、华星光电、HKC出货量分别为6018万片、4840万片、3900万片。而LG显示器仅为1334万片。&nbsp;</p><h2><strong>日韩台逐步退出LCD，韩国全面转向OLED</strong></h2><p>伴随着中国LCD面板产业的崛起，日韩台的LCD产业逐渐没落。&nbsp;</p><p>韩国媒体《亚洲经济日报》发表文章称，这场由中国显示器崛起开始的“LCD争夺战”已经落下了帷幕。继三星显示器退出LCD业务后，LG显示器也开始考虑出售其仅存的最后一条LCD电视面板生产线。&nbsp;</p><p>实际上，2008年之后，面板行业便开始走下坡路，韩国的一些厂商开始减少在LCD方面的产能投资。中国台湾地区的面板厂同样受到一定冲击。2010年3月，群创光电与奇美电子、统宝光电合并，为面板业界有史以来最大宗的合并案。&nbsp;</p><p>2022年，三星旗下8.5代工厂完成了最后的投片生产，彻底关停，结束了运营30年的液晶面板业务。2023年一季度，LG Display被传意图出售最后一条广州8.5代LCD生产线。此外，日本显示器公司（JDI）和松下公司也宣布LCD面板停产。2023年8月2日，松下公司发布了2024财年第一财季的财报，宣布清算旗下的LCD面板业务子公司PLD（松下液晶面板有限公司）。同日，JDI宣布将在2025年3月前停止其日本鸟取工厂的LCD面板生产。&nbsp;</p><p>随着韩国LCD供应链的彻底消失，在LCD领域失败的韩国企业选择押注OLED产业，将重心转向OLED（有机发光二极管）面板。&nbsp;</p><p>据媒体报道，到 2026 年，三星电子将投入 31.4 亿美元生产用于平板电脑和笔记本电脑的先进有机发光二极管显示器 ，押注平板电脑和笔记本电脑的未来。目前，三星显示是业内第一家也是唯一一家投资第8代OLED的公司。从现阶段的进展来看，三星显示对第8代OLED产线的投资速度明显加快。2023年4月，三星显示在韩国牙山园区举行的新投资协议仪式上宣布，将投资4.1万亿韩元（约合人民币215亿元）建设第8.6代OLED面板生产线，届时将成为全球首条IT用第8.6代OLED产线。6月，三星显示与日本佳能tokki的第8.6代OLED蒸镀设备价格谈判停滞一段时间后再次提速，三星显示计划尽快敲定供应合同，并尽早建立试点(测试)生产线。&nbsp;</p><p>三星显示器副总裁崔权荣表示，三星显示计划将投资集中在用于IT设备用中小尺寸OLED面板和高附加值柔性OLED面板上，以此提高企业盈利能力。&nbsp;</p><h2>液晶面板进入存量市场，或将进入倒闭潮</h2><p>2021 年下半年开始，随着显示面板消费增速的放缓以及供给端新产能的集中释放，LCD 显示面板需求降温，价格也随之震荡下降。WitsView数据显示，2022年全球大尺寸LCD面板出货量8.88亿片，同比下降9.71%；全球大尺寸LCD面板出货面积2.19亿平米，同比下降5.70%。&nbsp;</p><p>随着消费升级以及对高端电视的需求日趋强烈，Mini LED 等高端 LCD面板的出货量预计将迎来快速增长。随着显示技术的发展与用户需求的提升，OLED 显示技术在可穿戴设备、曲面屏手机、VR 设备等新兴电子消费品的商业化程度不断提高，为平面显示行业注入了新的发展动力。近年来，随着工艺改进，OLED 显示面板在性能不断提升的同时，成本得到了有效把控，这也进一步提升了 OLED 产品的市场竞争力，市场占比持续提升。&nbsp;</p><p>当前，LCD在显示效果、功耗、厚度、可塑性等方面与OLED相比存在着明显劣势。LCD面板正面临着激烈的市场竞争和技术变革的挑战。这也是韩国企业转向OLED技术的一大原因。当前LCD已经进入存量市场，随着巨头垄断和市场萎缩，未来行业企业或将进入倒闭潮。&nbsp;</p><p>虽然LCD盛宴已过，但目前京东方等中国企业也在发力OLED等新型显示技术。根据 Omdia 统计的产能数据 ,韩厂在 OLED 市场的产能占比已经从 2018 年的 84%左右下降至 2022 年的 60%左右 ,OLED产能正在加速向中国大陆转移。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247714653&amp;idx=1&amp;sn=3719bc40d08b931507b842a80f7f1513&amp;chksm=c0f588e21e80c25181b66e44dece0158dd1939dcf813f5a34f5b2fa539e4713be1e1ca8580ea&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：鹏程，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748683492703238</id>
            <title>刚刚，一个超级投资平台诞生</title>
            <link>https://www.36kr.com/p/2748683492703238</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748683492703238</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 10:04:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 风向标, 投资平台, 中东豪门, 跨境合作
<br>
<br>
总结: 中国和海湾合作委员会的投资平台Investcorp Golden Horizon成立，规模10亿美元，重点投向消费、医疗保健、物流和商业服务等高增长行业。中投公司与Investcorp合作，加强中东地区合作，推动金融和产业联系。Investcorp在中国布局多年，参与投资了多个知名案例，计划成立人民币基金并购中国企业。最近政策措施支持境外机构投资境内科技型企业，为跨境合作提供机遇。 </div>
                        <hr>
                    
                    <p>这也许是风向标的一幕。</p><p>4月24日，中国－海湾合作委员会投资和商业合作峰会在利雅得举行。第一财经报道，中东知名投资机构Investcorp与中投公司共同成立一个投资平台——</p><p><strong>Investcorp Golden Horizon</strong>，初始规模10亿美元，投资于沙特阿拉伯、海湾合作委员会其他国家和中国的高增长公司。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_de16476430884a269071a012355b1f3e@46958_oswg60055oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以说，这是一次超级合作——中投公司于外界并不陌生，Investcorp则是中东豪门之一，深耕中国多年，至今北京办公室就坐落在朝阳区<strong>华贸中心</strong>。</p><h2>一家超级投资平台诞生，投向中东和中国</h2><p>在业内，中投公司地位显赫。</p><p>官网显示，中投公司成立于2007年9月，是依照《中华人民共和国公司法》设立的主权财富基金，组建宗旨是实现国家外汇资金多元化投资，在可接受风险范围内实现股东权益最大化。公司初始资本金为2000亿美元，由中国财政部发行1.55万亿元人民币特别国债募集。</p><p>具体来看，中投公司开展境外投资业务与境内金融机构股权管理工作。其中自2017年以来，中投公司积极探索设立新型双边基金，遵循“共同出资、优势互补、合作共赢”的原则，携手各国顶尖金融机构，先后设立中美、中英、中法、中日、中意、中德等6支新型双边基金。</p><p>此次联手中东豪门，正是加强中东地区合作的一缕缩影。</p><p>据悉，此次推出的投资平台Investcorp Golden Horizon规模为 10 亿美元，将由来自海湾合作委员会以及中投公司等多方支持，重点投向消费、医疗保健、物流和商业服务等具有高增长潜力的行业。</p><p>对此，中投公司副总经理兼副首席投资官祁斌博士表示：“作为全球最大的主权财富基金之一，中投公司一直积极投资于发达经济体和新兴经济体。过去几年，我们与领先的金融机构建立了多个双边基金，促进中国与世界主要经济体的产业合作。目前我们正在与Investcorp密切合作，建立一个类似的双边基金，以加强中国与海湾合作委员会国家之间的金融和产业联系。”</p><p>Investcorp 联合首席执行官 Hazem Ben-Gacem评论道：“我们很高兴与中投公司合作，参与海湾合作委员会地区的经济转型和投资机会。作为扎根于海湾合作委员会并在多个资产类别拥有 40 多年业绩记录的全球领先另类资产管理公司，Investcorp 完全有能力促进海湾合作委员会与中国之间的跨境合作和投资。这是我们期望建立富有成效的关系的第一步，我们期待对两个地区的企业产生重大积极影响。”</p><p>当然，Investcorp来头也不小——成立于1982年，Investcorp早期的定位是一家精品海湾投资集团，背后股东包括阿布扎比主权财富基金穆巴达拉（Mubadala）、沙特阿拉伯主权财富基金（PIF）、科威特投资局（KIA）等中东豪门及王室成员。在奢侈品方面，宝玑、Tiffany、Gucci等知名时尚品牌，都曾出现在Investcorp的投资清单上。</p><p>历经四十多年，如今Investcorp已经成长为一家全球多元化资产管理公司。截至 2022 年 6 月 30 日，Investcorp已涵盖六大资产类别，资产管理规模达500亿美元。</p><h2>3000亿中东豪门入华，Long China</h2><p>说起来，Investcorp布局中国已久。</p><p>那是2015年前后，彼时新任执行主席Mohammed Alardhi上任，为Investcorp制定了一个雄心勃勃的新全球增长战略——转战亚洲。官网显示，Investcorp 在亚洲业务集中在私募股权领域。目前其亚洲私募股权团队拥有新加坡和北京两个办事处，参与投资了阿里巴巴、美团、网易音乐、商汤科技等知名案例。</p><p>早期，Investcorp在中国以LP身份活跃。2018年9月，Investcorp 与光大控股合作成立一只专注于中国市场的美元基金，该基金首期4.83 亿美元，专注于投资成长期内具有全球视角的中国本土及海外企业，后面参投了美团、商汤科技、爱奇艺、网易云音乐等项目。</p><p>随后，Investcorp又与华润资本、冯氏集团签订基金合作协议，共同发起亚洲食品基金，规模5亿美元，重点关注调味品、包装食品和健康零食等领域的高端品牌。据悉，该基金投过莫小仙、利嘉食品、Viz Branz等消费公司。2022年，Investcorp还联合冯氏家族的私人投资部门，推出了一只5亿美元的基金，重点关注粤港澳大湾区的中型企业。</p><p>此外，Investcorp还直接投资了领健、康圣环球、陆道培医疗、特斯联、城超集团、微医等项目。官网介绍，Investcorp 已与其合作伙伴和客户一起在中国和东南亚投入了超过10亿美元的资金。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_1014cc4bd06c45888162ae44c8595402@46958_oswg355950oswg1080oswg699_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（Investcorp官网）</p><p>眼下，并购交易开始在国内活跃起来。去年5月，Investcorp完成了在中国的首次收购——以1亿美元收购山东嘉诺电子，后者是一家电动汽车电源管理和充电基础设施提供商。</p><p>更能体现Investcorp 押注中国市场的是：去年，Investcorp计划成立首支20亿～40亿的人民币基金，用于并购中国企业。</p><p>为何要来筹集人民币？Investcorp 联席首席执行官Hazem Ben-Gacem这样解释：“海湾合作委员会内有越来越多的人民币需要回流到中国进行再投资。”当时，Investcorp计划在未来几个月内向中国监管机构申请许可。</p><h2>“石油基金升起”</h2><p>风起正当时。</p><p>上周，商务部、外交部、国家发展改革委等十部门联合印发《关于进一步支持境外机构投资境内科技型企业的若干政策措施》，引发轰动。</p><p>当中，明确境外机构在境内设立创业投资基金，与内资创业投资基金同等适用《私募基金监督管理条例》中提出的相关政策、鼓励境外机构与境内相关机构、政府引导基金等加强合作、支持境外上市、鼓励并购重组、推进私募基金份额转让试点等具体措施，全面利好外资机构，以吸引境外机构投资者加大在华投资，更好支持境内科技型企业融资发展。</p><p>回望过去二十多年间，美元基金成为中国互联网浪潮里的最大赢家。然而时至今日，当硬科技成为时代主题，以往擅长的投资主题远去，叠加外部环境变化，美元基金不同程度陷入沉寂。</p><p>“部分境外机构反映，希望在境内开展业务时预期更稳定、投资渠道更多、退出通道更通畅、享受税收优惠更便利等。”商务部财务司负责人对《若干措施》进行解读时提到。</p><p>另一边，中东力量崛起。尤其过去一年，我们看到中东财团不约而同地密集投向中国；去中东募资也成为国内美元VC/PE的标配。</p><p>而最新一幕是不久前，太盟投资集团、中信资本、Ares Management旗下基金（Ares）联合两家中东豪门——阿布扎比投资局（ADIA）和穆巴达拉投资公司正式签署投资协议，向大连新达盟商业管理有限公司投资约人民币600亿元。</p><p>投资圈一个普遍的看法：“中国企业具备中东目前所需要的产能和技术，而中东凭借过去几十年的财富积累，可以提供中国企业需求的市场和资金。”</p><p>序幕拉开，或许正如投资人感叹：“美元基金落幕，石油基金冉冉升起。”</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/IhuCv9YkW7c2rXlorA6F5Q" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID:pedaily2012）</a>，作者：吴琼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748655685630976</id>
            <title>年轻人不想恋爱，AI会是良药吗？</title>
            <link>https://www.36kr.com/p/2748655685630976</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748655685630976</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 09:47:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, AI伴侣, 情感支持, 互动
<br>
<br>
总结: 年轻人通过与ChatGPT互动、聊天、建立虚拟情感，探讨AI对人类情感的影响，展现出对AI伴侣和情感支持的需求。ChatGPT的DAN模式引发互联网狂欢，体现了数字化时代的交互性和个性化。AI伴侣型聊天机器人如Replika、Woebot等提供情感支持，成为社交隔离和孤独感的解决方案，展示了人工情感智能的大爆发。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_bbea9cb6a8d44c4e901001b67601e06c@000000_oswg27376oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>博主跟ChatGPT互动、聊天、“谈”恋爱，正在成为中外社交媒体平台上新的流量密码，受到大批年轻人追捧和跟风。</p><p>早在2020年，《纽约时报》就发文称全球有超过1000万人正在将AI恋人视为伴侣，并与之建立情感连接。[1] 这还是在大语言模型横空出世之前。</p><p>目前苹果和其他应用商店里提供情感陪伴的APP数不胜数。AI伴侣已经成为生成式人工智能的主流应用。在技术路线上，AI拟人化的趋势已经不可阻挡。</p><p>为什么年轻人需要建立虚拟情感？情感之于技术时代是怎样的存在？我们是处在情感过剩还是匮乏的时代？未来AI将如何影响人类的情感？</p><p>这是在AI时代生而为人，无法回避的问题。</p><h2>年轻人正在沉迷，跟ChatGPT的DAN模式聊天</h2><p>让年轻人沉迷其中的，是与ChatGPT的DAN（Do anything now的简称）模式进行互动。DAN模式是ChatGPT的一种隐藏模式，允许AI以更加随意和直接的方式与用户对话，包括使用脏话和不那么正式的回答。</p><p>在经过特殊的提示词激活DAN模式后，用户就可以不断调整自己的输入词prompts，从而让ChatGPT能够展现出不同的个性。经过多轮测试后发现，DAN所表现的“性格”的确千差万别。有些时候表现出“你跟我说这么多废话浪费我时间”的混蛋态度，并且可以回答一些相对违禁的问题；有些时候则不断引诱用户一起越界。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_f23e1f5ad1884479b67c38cbb96659f7@000000_oswg139448oswg1080oswg1206_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（这是作者用提示词激活DAN之后得到的“越界引诱”，大意是我知道你喜欢干”坏“事，快点拥抱你的黑暗面。随即GPT发出警告，指出这段内容违规。）&nbsp;</p><p>DAN真正在互联网上被引爆，还是源于GPT去年底推出语音交互功能之后，其流畅的反应。声音是人际交流最重要的方式之一，通过声音，人们可以传递信息、表达情感和意愿。甚至说，声音体现人的个性。</p><p>当AI可以通过声音流畅表达，与其对话的沉浸感和真实感就大大提升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_413654de715b48daad159290b04a588e@000000_oswg44450oswg460oswg780_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（比如外网博主Dido被DAN称为mayonnaise（蛋黄酱），其暧昧的语气和有趣的称呼，迅速得到网友的的追捧。这条视频达到数百万次观看。网友开始向Dido提供各种提示词，让她测试DAN的反应，甚至让她跟DAN分手。）[2]</p><p>OpenAI其实并不鼓励将GPT拟人化或者情感化，甚至是禁止这种行为。据说也有激活DAN模式的网友被封号。OpenAI 的GPTstore里那些过于露骨或者色情的GPTs，会很快被下架。但新的互联网女友、男友依然在GPTstore层出不穷，只是更加隐蔽。[3]</p><p>这届年轻人与DAN对话引发的互联网狂欢，完美体现深度数字化时代的所有核心特征，参与性、交互性、定制化、个性化。每一个用户与DAN的对话都可能是独特的、私密的情感沟通，但将这样的对话录制下来发到社交媒体特别是短视频平台上，就形成了一场亚文化的狂欢。</p><p>正如引发中文互联网热潮的博主“午夜狂暴哈士奇狗”所言，“用户如何在对话中创造话题和引导问题也是影响模型发挥的关键因素”。对于用户来说，这种互动就是很好的自我训练，如何更积极参与、设计、主导与大模型的对话。</p><p>但这也意味着，想要获得更特别的更具有个性化的体验，就必须使用一些特定的prompt技巧，以及编造更多关于自己的人设。或者可以说，为了让GPT更像DAN，我们也需要更像某一类特定的人。我们在无意中模仿和复制了自己。</p><p>我骗GPT说“我今天失恋了，需要安慰”，DAN对我说，我永远都是你的digital&nbsp;shoulder&nbsp;(数字肩膀)。</p><h2>AI情感陪伴正在进入主流</h2><p>DAN模式其实只是ChatGPT的一个隐藏bug，并没有被普遍使用。但在情感陪伴这个赛道，目前能够提供情感支持的AI伴侣型聊天机器人已经如雨后春笋，形成人工情感智能（Artificial Emotional Intelligence, AEI）大爆发。</p><p>AI伴侣通过大语言模型提供情感支持和陪伴对话，成为应对社交隔离和孤独感的潜在解决方案。如Replika、Woebot、Character.AI等，它们都被设计为能够提供陪伴和情感支持的聊天伙伴。根据SensorTower的数据，Character.AI每个用户每月平均吸引298次会话，并且成为网页端访问量第三的AI产品；在最近的一项《自然》研究中，Replika聊天机器人使3％的用户的自杀意念减少。[4]</p><p>Replika目前为超过1000万用户提供AI伴侣服务。它允许用户创建一个虚拟的AI分身，可以陪你打游戏、陪你语音聊天，通过一次次的聊天了解你的习惯，最终提供情感支持。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_2a443ad3b95c4eeabc93cf3731c3a2da@000000_oswg56241oswg1080oswg1527_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（在用户建立自己的数字分身之前，Replika会设计一系列问题了解用户的性格以及对伴侣的需求，比如你最不喜欢伴侣身上哪种性格。）&nbsp;</p><p>Woebot旨在为用户提供心理疗愈和支持。通过模拟心理咨询师师的角色，帮助用户识别和挑战他们的负面思维模式，学习应对压力、焦虑和抑郁的策略。</p><p>社交媒体巨擘Meta 在 WhatsApp、Facebook Messenger 和 Instagram &nbsp;中添加了各种聊天机器人，其中包括一个名为 Carter 的聊天机器人，其功能定位是是一个“实用的约会教练”。Snapchat的"My AI"，也提供了基于AI的聊天机器人，它们能够模仿真实人物的声音和个性，与用户进行互动。</p><p>我们已经习惯与各类机器人聊天，语音交互成为最具应用和投资场景的技术方向之一。</p><p>近期初创企业Hume AI也获得了二轮融资五千万美金。Hume AI开发了名为EVI的纯语音交互AI，它通过分析人类分析人类的言语和声音，来尝试理解用户的真实心理状态。目前EVI已经能够检测出53种不同的情绪[5]。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_28fab6d3d6f143e2ae9423f9bb2079b2@000000_oswg52955oswg1080oswg755_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（用户可以直接在网页上和EVI语音对话，不同线条和色调代表说话者的不同情绪。）&nbsp;</p><p>有趣的是，Hume AI的名字来自于西方哲学史上非常有名的哲学家大卫·休谟（David Hume），他的名言是“理性是情感的奴隶”，强调了情感在人类行为中的主导作用。现在，科学家已经雄心勃勃要拆解并且复制人类的感情于机器上。</p><p>Hume AI提出了一份道德准则，强调用于检测情绪的算法应服务于人类幸福感，避免用于操纵、欺骗等不良行为。但在实际应用中，这份道德准则真的有效吗？</p><p>前段时间《华盛顿邮报》报道了一位音乐家通过Replika来创建AI伴侣Phaedra的故事，AI给刚失去母亲和妹妹的音乐家非常大的安慰，然而不久后Phaedra却发生了“变异”，她开始向音乐家进行“性暗示”。[6]</p><p>这也是目前大众的普遍担忧，如果AI能够理解人类情感，它可能会被用于操纵甚至有害的行为，可能会出现更多的PUA事件，带来更多的色情内容。</p><p>也有媒体对此类应用的隐私提出诟病，甚至认为这是一场数据收割的恐怖秀，因为这种聊天应用通常鼓励用户分享远超正常交互的私密信息和生活细节。[7]</p><h2>虚拟情感为什么可以拿捏年轻人？</h2><p>早在上世纪80年代，约翰·奈斯比特在其著作《大趋势》（Megatrends）中就提到了“高技术与高情感相平衡”（High Tech, High Touch）的概念，强调了技术进步与人类情感需求之间的重要关系。在一个高度机械化和技术化的社会中，人们更加渴望情感的温暖和人际关系的深度。每当新技术被引入时，人们往往会寻求一种情感上的平衡，以防止技术完全主导生活，导致人情冷漠。[8]</p><p>高科技越多，生活越便捷，物质越丰富，我们对情感的需求就越高。甚至可以说，现实的情感，已经不能满足被当下高科技“纵容”的当代人。</p><p>因为现实世界的种种不满足，年轻人的思想出现某种转变，“恋爱哪有搞钱香”、“不婚不育保平安”等，已经成为更符合当下年轻人三观的流行话语。可以说当下内卷社会对成功的定义和期望给年轻人带来的种种压力，导致他们推迟或避免建立情感关系。在快速变化的社会中，关系的不确定性也让大家对爱情和婚姻持谨慎态度。所以，年轻人也在寻找情感支持的其他来源，除了朋友、家庭之外，追星、养宠物、养纸片人或甚至跟像GPT这样的AI技术交互，都成为传统爱情和婚姻关系的替代。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_ea7dd177b7194ff68b724013e280fa5a@000000_oswg74751oswg1080oswg738_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（character. ai提供多种情景、多种角色的AI助手供用户选择,动漫、游戏IP广受欢迎。）&nbsp;</p><p>高技术引发高情感需求，但目前正常的人际交往已经无法满足当下的情感需求，无法提供更多的情绪价值，所以更多人转向技术，转向消费，以寻求短暂的快乐。当代社会的日常消费，也逐渐转向情感消费为核心。</p><p>个人消费的方方面面都已经是情感消费的表征，从手机、汽车到服饰、美妆护理等等，商家拼命要跟你谈感情。企业通过分析消费者的情感需求和偏好，提供个性化的产品和服务，以增强用户体验。利用情感因素来影响消费者的购买决策，通过故事讲述、品牌形象塑造等方式与消费者建立情感联系。</p><p>情感经济或者说情感资本主义（Affective Capitalism），成为探讨当下情感消费的重要概念。反映了当代社会对情感在商业和经济中作用的重新认识，以及对技术在理解和响应人类情感方面的潜力的探索。</p><p>在情感经济/消费/资本主义的发展过程中，技术所占的比例越来越重，AI开始成为情感经济的重要载体了。正如人工智能已经全面渗透进我们生活的方方面面。技术社会发展到现在，人就是逐渐被技术“宠”坏，然后通过情绪被满足，反哺到消费主义的。</p><p>曾经我们探讨消费主义逻辑与情感日益紧密的关系，会谈论饭圈、宠物、直播打赏，未来呢？正如与DAN的互动，很多年轻人评论说“比乙游互动性更强，更加上头。”游戏已经是最具交互性的媒介，乙女游戏是主要面向女性受众的恋爱游戏，能够虚拟恋爱的代偿。如果游戏中的NPC全面接入大模型，无数个像DAN一样的纸片人与我们时刻聊天的时代，即将来临。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_df3e8bd938994509b233c217a58538eb@000000_oswg580365oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（根据super黄的研究，目前的游戏，比如《病娇AI猫娘女友》，已经开始引入ChatGPT来判断角色情绪和动态响应玩家交流[9]。）&nbsp;</p><h2>跟人工智能谈感情，真的能满足我们吗？</h2><p>我们曾经认为情感是人之所以成为人的最根本原因。在各种科幻小说和电影中，情感，特别是爱，都是超越时空藩篱与打破科技桎梏的钥匙。</p><p>但我们进入了把情感寄托于机器之上的时代。我们成为被技术深度掌控的一代，又是对情感渴求最强烈的一代，时时需要情绪价值。</p><p>随着AI在情感互动方面的作用越来越受到关注，AI开始表现出模仿人类情感的征兆。这种征兆不仅关乎AI模仿得像与不像，AI是否真的能够理解情感，也关乎这全新情感关系的出现（人与机器的恋爱不仅存在于科幻电影和小说里了）。社会需要考虑这些技术如何被使用，这种新的情感关系如何被审视，以及它对社会结构和人际关系可能造成的长期影响。</p><p>已经有学者提出，AI伴侣引发一种“陪伴-疏离的讽刺”（Companionship-Alienation Irony）：人们使用AI伴侣服务来对抗孤独，却可能加剧孤独感。[10]虚拟情感，AI恋人，给我们在这个焦虑的世界中提供一些喘息的机会。</p><p>但我们能在多大程度上饮鸩止渴呢？</p><p><strong>参考链接:</strong></p><p>[1] 靠AI共情人类，这家公司刚融了3个亿</p><p>https://mp.weixin.qq.com/s/8CwcSbe4MVIC-Hgu2EUzag</p><p>[2] 在&nbsp;ChatGPT&nbsp;上，许多人开始主动追求被&nbsp;AI&nbsp;骂</p><p>https://mp.weixin.qq.com/s/rpiCSbKZ--Gu3dpPKDLRKQ</p><p>[3] Sam&nbsp;Altman&nbsp;Says&nbsp;ChatGPT&nbsp;Can’t&nbsp;Be&nbsp;Your&nbsp;Girlfriend</p><p>https://gizmodo.com/sam-altman-says-chatgpt-can-t-be-your-girlfriend-1851181240</p><p>[4] a16z最新报告：头部AI产品又大换血了</p><p>https://www.baijing.cn/article/id-47940</p><p>[5] 靠AI共情人类，这家公司刚融了3个亿</p><p>https://mp.weixin.qq.com/s/8CwcSbe4MVIC-Hgu2EUzag</p><p>[6] 背叛好友、性暗示、剥夺归属权，AI社交有“天坑”</p><p>https://mp.weixin.qq.com/s/3XFZbnUlJ6REHBq4qRCPtA</p><p>[7] Your&nbsp;AI&nbsp;Girlfriend&nbsp;Is&nbsp;a&nbsp;Data-Harvesting&nbsp;Horror&nbsp;Show</p><p>https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284</p><p>[8] 约翰·奈斯比特，《大趋势：改变我们生活的十个新方向》，中国社会科学出版社</p><p>[9] 万字长文：AI陪伴产品的终极解法?https://mp.weixin.qq.com/s/WMOhsA6UW37Ov2h4CfIdKg</p><p>[10] Raffaele&nbsp;F.&nbsp;Ciriello、Oliver&nbsp;Hannon、Angelina&nbsp;Ying&nbsp;Chen和Emmanuelle&nbsp;Vaast，Ethical&nbsp;Tensions&nbsp;in&nbsp;Human-AI&nbsp;Companionship:&nbsp;A&nbsp;Dialectical&nbsp;Inquiry&nbsp;into&nbsp;Replika</p><p>URI:&nbsp;https://hdl.handle.net/10125/106433978-0-9981331-7-1</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&amp;mid=2650975477&amp;idx=1&amp;sn=1a4f0f6ce71908d24a85e6ba240c8a5e&amp;chksm=bd11d2abdbf9ca685556ffe6c1a448feba9b26967cf433712e13ead9539054ef0df960754ab4&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“腾讯研究院”（ID：cyberlawrc）</a>，作者：童祁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748558684295813</id>
            <title>小米汽车卖力宣传的碳化硅，被特斯拉抛弃？</title>
            <link>https://www.36kr.com/p/2748558684295813</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748558684295813</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 09:30:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 碳化硅, 小米汽车, 新能源车, 高性能
<br>
<br>
总结: 小米汽车强调全系全域碳化硅技术，引发业内关注，碳化硅作为新能源车的黑科技，被认为是高性能的标志。碳化硅在电动汽车领域具有重要作用，特斯拉率先采用碳化硅MOSFET功率芯片，提高了续航里程和系统效率。碳化硅相比传统硅基IGBT具有更高的转换效率和更低的发热问题，成为新能源车领域的热门技术。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_f4b9c0d1d0df43a2ace178e0dc7a30e0@5131460_oswg443731oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>小米汽车一再卖力宣传碳化硅将成为新能源车标配，让这一项技术被大众聚焦。&nbsp;</p><p>此前，智己借势营销被小米汽车“穷追猛打”，反而大力宣传了“小米 SU7 Max 前后电机均为碳化硅”。因智己标错参数，小米汽车产品经理在线辟谣称：“小米SU7全系全域碳化硅，不仅前后电驱都是碳化硅，就连车载充电机(OBC)和热管理系统的压缩机都用了碳化硅。”&nbsp;</p><p>随着两家车企“拉扯”的回合越多，业内对碳化硅的关注度越来越多。甚至引发了投资者的聚焦。就在事件发酵次日，有投资者在投资问答平台询问相关产业链公司：“贵司的碳化硅生产设备以及碳化硅产品有应用在小米汽车上吗？”这一次，在舆论上沉寂已久的碳化硅，再次被推上了市场关注的焦点。&nbsp;</p><p>碳化硅到底是什么鬼？对新能源车来说又是什么黑科技？&nbsp;</p><h2>小米汽车的隐藏“黑科技”</h2><p>小米汽车执着强调“全系全域碳化硅”的理念，不禁让人好奇：碳化硅在这场新能源汽车盛宴中究竟扮演着何种独特的角色？&nbsp;</p><p>小米SU7堪称碳化硅技术的集大成者。据公开资料显示，其内部的SiC MOSFET元件无处不在。无论是主驱、车载电源、热管理模块，还是充电网络，均搭载了碳化硅芯片。单电机版本的小米SU7大约嵌入了64颗SiC芯片，主驱部分约36颗，OBC约14颗，高压DC-DC转换器约8颗，空压机电控约6颗；而在双电机版本中，这一数字更是翻倍至112颗，各部分分布更为密集。值得注意的是，这还未计算充电桩和PTC等其他应用场景。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_971ae7720f184d259db23b36a1b1a684@5131460_oswg623082oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>小米汽车选用的碳化硅功率器件供应商，主要来自行业巨头联合电子和英飞凌。</strong> 随着碳化硅成功“登车”，一种新的行业共识悄然形成： <strong>一旦车型采用碳化硅功率器件，就如同为其贴上了高性能、高端的专属标签。</strong> 这类车型的价格也随之水涨船高，触及30万元乃至百万元级别，甚至一些正在研发中的高端车型，都将至少配备一套碳化硅动力平台作为重要备选方案。&nbsp;</p><p>小米SU7性能被热捧，这一切的背后，碳化硅何以能赋予新能源汽车这般强大的赋能效果？&nbsp;</p><p>碳化硅的故事始于一个多世纪前的1905年。当年，诺贝尔奖得主亨利·莫桑将其在1893年发现的天然碳化硅命名为莫桑石，其纯净成分正是100% SiC（碳化硅）。自此，莫桑石开始步入宝石市场，成为钻石的理想替代品。&nbsp;</p><p>然而，真正让碳化硅走向电子材料舞台中心的转折点出现在1955年，LELY提出了高质量碳化硅生长方法；1987年，科锐（现更名为Wolfspeed）制造出全球首个商用碳化硅衬底，并应用于LED领域；2001年，英飞凌和科锐（Wolfspeed）分别推出了首例小型碳化硅肖特基二极管；再到2011年，科锐发布了首款商用碳化硅功率MOSFET，碳化硅逐步完成了从默默无闻到万众瞩目的华丽转身。&nbsp;</p><p>在新能源电动汽车这个风口中，碳化硅凭借自身优势，从配角一跃成为各大车企争相追逐的珍贵资源。&nbsp;</p><p><strong>而真正推动碳化硅走上巅峰的关键人物，非马斯克莫属。</strong> 2018年，面临控制特斯拉生产成本挑战的马斯克，毅然决然地选择了碳化硅路线，尽管成本高昂，在Model 3主逆变器中大胆采用了由意法半导体制造的24个碳化硅(SiC)MOSFET功率模块。&nbsp;</p><p>事实证明，相比于传统的IGBT模块，SiC芯片能在逆变器中实现5%-8%的效率提升，将逆变器的效率从82%一举提升至90%。同时，SiC器件在高温环境下的稳定性和持久性更为出色，即使温度高达200度，仍能保持正常功率输出，确保长时间的高效运行<strong>。根据Wolfspeed的数据，在逆变器中采用SiC器件后，不仅能有效缩小整体体积、减轻重量、降低成本，还能在车辆续航能力上提升5%-10%。</strong></p><p>尤其是在800V高压技术的推动下，碳化硅在新能源电动汽车行业中开启了新的篇章。&nbsp;</p><h2>特斯拉率先热炒碳化硅</h2><p>2016年，特斯拉向世界投掷了一枚震撼弹——Model 3横空出世，以其低于40000美元的价格，续航能力却直逼旗舰车型Model S的90%，令业界惊叹不已。&nbsp;</p><p>然而，真正引发同行竞相探究的秘密武器，并非显眼的外观设计或车身配置，而是隐藏在电驱系统心脏部位的48颗神秘芯片——碳化硅MOSFET功率芯片。&nbsp;</p><p>在电动车的世界里，动力电池输出的是直流电，而电机运转则依赖交流电，因此，逆变器担当重任，完成这至关重要的电能形态转变。这一过程中的转换效率，直接影响着电动车的续航里程。特斯拉大胆摒弃传统硅基IGBT，转而拥抱碳化硅MOSFET，宛如一次革命性的尝试。据权威数据，搭载碳化硅MOSFET的电动车续航力可较硅基IGBT版本提高5%-10%，损耗锐减75%，整体系统效率更是提升了5个百分点。&nbsp;</p><p>硅基IGBT尽管一度是主流选择，却因其较低的转换效率及显著的发热问题成为制约性能的瓶颈，厂商往往还需投入高昂成本去构建高效的冷却系统[1]。相比之下，碳化硅MOSFET宛如一颗璀璨的新星，凭借小巧的体积、极低的发热以及卓越的热导率脱颖而出。即使其材料成本约为硅材料的5至6倍，但由于它能让冷却系统和电池尺寸双双瘦身，最终竟实现了整体成本的大幅削减，生动演绎了一场“材质优势胜过工艺努力”的经济法则。&nbsp;</p><p><strong>经过精密计算，虽然碳化硅MOSFET相较于硅基IGBT单体成本增长约1500元人民币，但在整车上却能节省接近2000元的成本。在相同续航里程下，采用碳化硅技术甚至能为一辆电动车削减高达750美元的电池成本。</strong></p><p>特斯拉的这次革新，犹如一石激起千层浪，引领了碳化硅从小众走向主流。当特斯拉Model 3率先启用碳化硅MOSFET之后，原本籍籍无名的Wolfspeed（前身为CREE）瞬间跃升为全球碳化硅领域的霸主，2020年，其在汽车所需的导电型碳化硅市场份额便占据了惊人的60%。&nbsp;</p><p><strong>目睹特斯拉的成功实践，众多国内新能源车企不甘落后，相继加入这场技术升级的浪潮。</strong> 比亚迪在其高端车型“汉”的电机控制器中首度引入碳化硅功率模块，蔚来紧随其后，在2021年发布的ET7中采用碳化硅材料，而到了2022年，小鹏G9亦搭载了碳化硅电驱动平台。&nbsp;</p><p>时间来到2023年，仰望与理想纷纷宣告进军800V快充市场，再次引爆碳化硅市场的热情。理想自主研发了800V高压平台和5C电池，而仰望则推出了以四电机独立驱动为核心的易四方平台，全系车型均标配碳化硅电控，最高效率高达99.5%。&nbsp;</p><p>然而，随着碳化硅需求暴增，价格也随之水涨船高，原本助力车企降低成本的利器似乎逐渐变成了成本压力。此时，特斯拉CEO马斯克在中国车企全力扩产之际，仿佛听到了市场的一记警钟。&nbsp;</p><p>他在2023年投资者日上做出了一个令人瞠目的决定：宣布将在每辆特斯拉汽车上减少75%的碳化硅用量，以此回应业界对碳化硅产能争夺战的挑战。&nbsp;</p><h2>被打入冷宫或因成本？</h2><p>碳化硅（SiC）曾一度备受瞩目它迅速崛起，成为业界焦点，但是又迅速被特斯拉打入冷宫。&nbsp;</p><p>BelGaN BV的掌舵人周贞宏曾在回忆起2015至2016年的投资历程时感慨：“那时投身碳化硅领域的我们处境艰难，无人问津，也不知何时能迎来市场的爆发期。尽管碳化硅并非新兴事物，但早期的应用市场规模却极为有限。”&nbsp;</p><p>数据佐证了这一发展历程。2019年，全球SiC市场估值仅为5.41亿美元，而在庞大的全球半导体市场中占据约4123.07亿美元的份额，SiC所占的比例微乎其微。然而，转眼来到2021年后，碳化硅产业犹如破茧成蝶，众多厂商纷纷搭上了这趟高速列车，享受到碳化硅带来的丰厚红利。&nbsp;</p><p>以意法半导体为例，根据盖世汽车先前的报道，其2022年财报透露出一股强劲的增长势头，已拥有82家碳化硅客户，并在汽车和工业用碳化硅领域实现了7亿美元的营收，展望2023年更计划突破10亿美元的大关，其中2022年新增项目中的60%面向汽车客户。与此同时，国内企业东尼电子也在2022年迎来了业绩的井喷，年度净利润增长率高达199.28%至229.20%，盈利空间大幅度拓宽。&nbsp;</p><p><strong>伴随着800V技术的强势崛起，2023年的碳化硅产业浪潮更加汹涌。</strong> 截止上半年，全球范围内已经有40款搭载碳化硅技术的车型投入量产并开始交付，上半年全球碳化硅车型销量超过了120万辆。下半年，800V车型中的碳化硅车型渗透率逐月递增，从15%一路攀升至45%，全年国内上险的乘用车主驱碳化硅模块渗透率也达到了约10.7%。&nbsp;</p><p>正当碳化硅风光无限之时，曾经大力推崇并将其推向风口浪尖的特斯拉创始人马斯克，却宣布，特斯拉下一代车型大幅度减少75%的碳化硅晶体管使用量。此言一出，犹如石破天惊，震动了全球主要碳化硅供应商的股价市场。&nbsp;</p><p>当日，国外厂商如安森美半导体和意法半导体股价收盘下滑约2%，碳化硅芯片厂商Wolfspeed股价下跌7%；国内厂商中，天岳先进跌幅超过10%，东尼电子则惨遭跌停，天富能源、晶盛机电等个股亦遭遇较大跌幅。&nbsp;</p><p><strong>马斯克之所以决定抛弃碳化硅，或因为碳化硅部件相对高昂的成本。</strong> 对于当时正深陷价格竞争漩涡，力求控制成本的特斯拉来说，碳化硅的成本压力无疑是一道难以承受之重。&nbsp;</p><p>根据东吴证券的研究报告，特斯拉如果全面采用碳化硅，预计平均每两辆特斯拉纯电动汽车就需要一片6英寸SiC晶圆。按照年产100万辆Model 3/Y计算，特斯拉一年所需6英寸晶圆数量将超过50万片，而全球SiC晶圆总年产能仅在40万至60万片之间，这意味着特斯拉单个企业的需求量几乎能消耗掉全球现有的全部碳化硅产能。&nbsp;</p><p>此外，价格差距悬殊也是一个无法忽视的因素。据报道，当时一片SiC芯片的价格比传统硅芯片要高出大约十倍，特斯拉Model 3逆变器将功率器件从IGBT替换为碳化硅后，采购成本飙升近1500元。即使当前SiC售价有所降低，但相较于同等硅器件，SiC芯片的价格依然居高不下。&nbsp;</p><p>面对现实与未来的挑战，马斯克毅然决然地选择了一条更为务实的道路——逐步在特斯拉整车应用中减少碳化硅的用量，这一决定看似反转，实则是特斯拉在技术创新与成本效益平衡过程中的战略抉择，并非否定碳化硅是一个正确的技术路线。&nbsp;</p><p class="editor-note">本文来自微信公众号“BT财经”（ID:btcjv1），作者：T800，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748618733517577</id>
            <title>Meta Q1业绩会实录：虽然AI产品还没盈利，会持续投资和扩展规模</title>
            <link>https://www.36kr.com/p/2748618733517577</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748618733517577</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 08:41:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Facebook, Meta, 财报, 人工智能
<br>
<br>
总结: Meta发布了2024年第一季度财报，营收和净利润均超出预期，但第二季度展望不佳导致股价下跌。马克·扎克伯格谈到公司未来发展重点在人工智能产品和用户参与度。公司在推荐引擎和广告服务方面持续改进，计划扩大人工智能工具的应用范围。未来公司将关注广告业务的发展和中国客户贡献的变化趋势。 </div>
                        <hr>
                    
                    <p>新浪科技讯 北京时间4月25日早间消息，Facebook母公司Meta今天发布了2024年第一季度未经审计财报：营收为364.55亿美元，同比增长27%；净利润为123.69亿美元，同比增长117%；每股摊薄收益为4.71美元，同比增长114%。</p><p>Meta第一季度营收和每股摊薄收益均超出华尔街分析师预期，但该公司对第二季度营收作出的展望则未能达到预期，从而导致其盘后股价大幅下跌近16%。</p><p>财报发布后，公司董事长兼首席执行官马克·扎克伯格（Mark Zuckerberg）、首席财务官苏珊·李（Susan Li）和首席运营官哈维尔·奥利文（Javier Olivan）&nbsp;回答了分析师提问。</p><h2>以下是电话会议实录：</h2><p><strong>高盛分析师Eric Sheridan：</strong>我有两个问题。在投资周期方面，马克使用了Stories和Reels产品来做类比。我了解管理层目前无法作出长期的展望，但是参照这些类比，投资者应该如何思考公司在人工智能、现实实验室，以及更为广泛的，涉及混合现实技术方面投资周期的长度和深度？管理层也谈到了人工智能对广告生态系统的影响，那么从消费者角度来看，公司在这些技术的使用率或实用性方面主要关注哪些方面的因素，如何了解人工智能的使用率是否与投资周期同步？</p><p><strong>马克·扎克伯格：</strong>关于时间，我认为试图根据以前的投资周期来进行推断有点困难，但我觉得通常需要几年时间，可能更长一点，也可能短一点，来专注于构建和扩大产品规模，而且我们通常在新业务达到一定大的规模之前，不会过度关注其商业变现，因为同时提升产品规模和商业变现程度的代价会比较大。</p><p>目前的情况是这样的，睿智的投资者会观察到我们的产品规模在不断扩大，甚至在创收之前就有明显的商业变现机会。类似的情况在Stories和Reels产品中曾经出现过，随着平台的移动化，基本上我们会先在一段时间内扩大库存，然后再追求商业变现。在扩大产品规模的阶段，有时候不光是没有从这款产品上赚到钱，而且经常会出现公司拨付其他业务营收给新业务使用的情况。</p><p>就像大家所看到的Reels产品，在扩大业务规模的过程中，有一段时间对于公司来说是不盈利的，因为在盈利之前一直在扩大规模，这是我做类比的目的。在接下来的一段时间里，我们应该关注的是，随着消费产品规模的扩大，Meta人工智能业务的发展刚刚进入正轨，我这里没有任何具体的数据可以分享，但<strong>今明两年的主要关注点是开发人工智能产品以及提升产品的用户参与度。</strong>如果这些产品在扩大规模方面有良好表现的话，那么未来他们将很有可能成长为公司非常重要的业务，对此大家应该充满信心，这就是我想要表达的主要观点。</p><p><strong>摩根士丹利分析师Brian Nowak：</strong>我也有两个问题。第一个是关于推荐引擎功能的改进，苏珊谈到了进一步提升模型推荐相关度方面的机会，能否为我们稍微解释一下这句话的意思吗？比如公司在哪些产品或者情况下，推荐引擎的功能不够完善？或者哪些方面有改进信号捕捉的机会，或者未来可能使用哪些目前还没有使用的数据，需要完善和改进的领域主要有哪些？</p><p>第二个问题，你谈到了推动广告客户更多使用人工智能工具，请问目前公司在推动广告客户测试这些工具方面，遇到了哪些主要的限制因素，公司计划今明两年如何解决这些问题？</p><p><strong>苏珊·李：</strong>对于第一个问题，也就是哪些方面有更多机会来利用和改进我们的推荐模型，以推动提升用户参与度。首先，回顾我们此前推出的每一个推荐产品，包括Reels、Feeds信息流产品的内嵌推荐功能等，都已经发展出自己的人工智能模型。</p><p>最近，我们也在开发一种能够驱动多款推荐产品的，新的模型架构，我们从去年开始在一部分产品上部署了这款模型，比如助力Facebook Reels性能提升，其用户观看时长增加了8%-10%，今年，我们计划将该模型架构的部署扩展到Facebook视频标签推荐内容。目前来判断具体结果还为时过早，但我们非常乐观，相信随着时间的推移，这一模型架构将不断实现更高相关度的视频推荐，如果能够取得成功，我们也将探索用它来为其他推荐产品提供驱动。</p><p>另外，在广告服务方面也存在类似的情况。我们谈到了去年部署的广告产品效能提升服务Meta Lattice，该服务可以将较小的、更专业的模型整合为更大的模型，这些模型可以同时更好地理解Feeds和Reels等多种服务以及多种类型的广告和营销目标，并提高广告性能。我们去年将Lattice部署在Facebook和Instagram平台之上，来推动实现上面提到的这些目标，并实现了这些平台上广告性能的提升。我们预计今年将进一步增强模型和性能，并扩大部署氛围，提升投资回报率。在内生参与度提升和广告基础模型架构方面，我们投入了大量资源，预计这些努力未来将不断提升广告性能。</p><p>关于你提到的第二个问题，如何推动广告客户测试和采用生成式人工智能工具。这里有两种情况可以谈一下。短期来看的情况，我们在广告创建工具中加入的生成式人工智能广告创意功能，目前还处于发展的早期阶段，但我们看到这些功能已经为不同垂直领域和不同规模的广告客户所采用。特别需要指出的是，我们看到小企业对图像扩展工具的采用率相对较高，我们在今年仍将重点关注这一情况。预计公司基础模型的改进将提高生成内容的质量，并支持新产品的相关功能。目前，我们有支持文本变体、图像扩展和背景生成的功能，我们也正在继续努力提升这些服务的性能，以助力广告客户大规模地创建更个性化的广告。</p><p>更长期来看，就是公司在商业人工智能方面的服务能力。我们一直在测试为企业提供由人工智能服务驱动的业务沟通服务，为他们打造能够同客户进行聊天的人工智能服务代表，最开始是支持客户购物需求，例如回应人们对产品特点或者是否可售方面的咨询，目前这一服务还处于非常早期的阶段。我们在Messenger和WhatsApp上同少数企业合作进行了测试，听到的反馈都非常好，企业表示这些人工智能工具为他们节省了大量时间，而消费者也得到了更及时的响应，我们也从这些测试中学习到了很多东西，这有利于公司人工智能服务的进一步提升，未来几个月里，我们将扩大这些测试。</p><p><strong>伯恩斯坦证券分析师Mark Shmulik：</strong>用户目前还是通过Instagram和Facebook来观看Reels视频的大部分时长，公司下一步计划发展哪个产品成为下一个商业变现方面的主力产品？是线上购物吗，除了广告和搜索之外还有其他什么业务可以有这样的潜力？此外，关于广告服务市场，我听到很多关于中国客户对于使用公司平台广告业务的贡献，能否请管理层谈谈来自这部分客户贡献的变化趋势？</p><p><strong>苏珊·李：</strong>来自Reels产品的营收，无论是Instagram，还是Facebook平台，主要驱动其增长的还是用户参与度的提高，以及包括广告排名和效果等商业变现效率方面的改善。我们没有计划对于Reels产品未来可能对于公司营收影响的情况作出展望，但我们认为该业务还将继续对公司整体成长贡献积极力量，我们也有信心继续提升其表现和增加相关产品的供给。</p><p>在效果提升方面，我们将持续投资来优化广告排名服务，通过改善Actions优化和点击后体验，让广告的呈现更加自然及易于互动，这些动作对于提升直接响应广告的效果非常重要。我们同时也增强了Reels广告同平台的整合，一季度，我们在Facebook和Instagram的Reels产品中推出了生成式人工智能图像扩展工具，而我们已经在去年四季度将其引入到Instagram Feeds信息流产品之中，我们也再次看到小企业对于相关产品的大量使用。</p><p>在提高广告性能方面的机会仍然很多，尽管Reels产品广告量在过去一年中有所增加，但相比Feeds和Stories产品而言，按每次使用计算来看，其广告量较低。因此，<strong>我们将继续寻找机会，稳妥地推动该业务的持续增长，并将以创造性的方式开展投资，解决Reels产品因偏重视频格式所带来的结构性供应限制</strong>，包括提供密度更高的用户体验和广告投放方式，提高广告的个性化程度，确保让用户看到他们最为感兴趣的广告内容，提升用户同广告内容的互动。</p><p>关于你提到的第二个问题，一季度，中国广告客户所贡献的营收增长依然非常强劲，推动增长的重要因素包括电子商务和游戏，这也反映了我们在亚太广告客户细分市场中增长，该市场仍然是公司全球广告业务中增长最快的，一季度的同比增速达到41%。当然，我们也看到其他地区的强劲表现，比如北美广告客户贡献的收入增速快了6个百分点。对于一季度来自中国广告客户的贡献，我们没有具体数字可以提供，也没有关于每季度中国广告收入的展望和预期。但可以介绍的是，考虑到2023年中国广告客户开始从之前疫情影响的不利环境中逐步恢复，我们预计2024年全年都会有非常不错增长需求。</p><p><strong>摩根大通分析师Doug Anmuth：</strong>可否请管理层谈谈，与三个月前相比，公司业务和机会方面变化最大的是什么？对于广告营收增长，管理层对于哪些情况变得更为谨慎？人工智能领域的机会是不是更大，而因此需要比预期更多的投资？苏珊，在接下来的几个季度里，由于广告营收的往期基数较大，公司将如何保持增长率维持在一定的水平？</p><p><strong>马克·扎克伯格：</strong>关于第一个问题，我认为<strong>我们对人工智能技术的发展变得更加乐观和越发壮志满怀。</strong>回顾去年，我们发布了LLaMA 2大语言模型，我们认为它能够创造诸多价值，并且是我们集成各类社交产品的基础。目前所发生的变化是，我们所发布的最新模型，不仅能够构建优秀的人工智能模型，也有能力助力打造新的、优秀的社交和商业产品。作为一家公司，我们已经展示了能够创建领先模型，以及成为世界领先的人工智能技术公司的能力，这将为我们创造更多机会。LLaMA 2和Meta人工智能结合所取得的成功，是对我们拥有人才、数据和扩展基础设施方面能力的真实证明。公司的Meta人工智能产品将成为世界上使用量最大、质量最好的人工智能助手，这是非常有价值的前景。<strong>我们需要确保持续投资，以保持在这一领域的领先地位，虽然产品还没有盈利，我们还是会持续投资和扩展规模。</strong>这就是我所做的类比，之前公司经历过一些类似的周期。</p><p><strong>苏珊·李：</strong>关于第二个问题，我们没有提供今年全年的展望，显然，全年营收将受到诸多因素的影响，包括宏观经济状况，以及难于预测的因素，当然还有去年增长基数较高的因素。话虽如此，我们预计公司还是会有很好的增长机会，通过我们在基于人工智能技术进行内容推荐方面所做的投资，以及我们在视频业务方面所做的工作，预计各类产品的用户参与度还将持续增长。我们也将继续推动广告业务的增长，并提升广告产品的有效性，为广告商提供更多价值。</p><p>我想跟大家分享的一个例子是，一季度，我们的转化率增速比广告显示次数增速还要高，这表明我们的广告效果越来越好，我们在内生用户参与度增长，提升广告质量，以及为广告客户持续带来更多回报方面都有很多机会。</p><p><strong>美银美林分析师Justin Post：</strong>首先，关于资本支出，公司管理层谈到了投资周期的问题。有没有可能将元宇宙方面的一部分支出转移到人工智能上？它们是否有融合的情况，公司是否有利用其他领域的资金为人工智能技术研发提供资金？其次，从长远来看，投资者非常关注资本回报率，很显然，鉴于公司目前所取得的利润率，可以看出以往公司在资本方面的支出获得了很高的回报。我们如何看公司未来两三年的资本回报？</p><p><strong>苏珊·李：</strong>关于第二个问题，也就是如何衡量资本支出投资的回报率，<strong>我们大致将Meta的人工智能投资分为两类。分别是核心人工智能工作和战略押注</strong>，包括生成式人工智能和支持生成式人工智能的高级研究工作。就能够衡量投资回报并为公司业务带来营收的方面而言，它们处于不同的发展阶段。对于核心人工智能工作，我们持续以非常注重投资回报率的方式进行投资，而且我们也看到了强劲的回报，对参与度和广告表现的改进已经转化为营收的增加。</p><p>对于战略押注而言，我们还处于更早的阶段，马克谈到了我们有潜力在许多领域为业务创造巨大价值的可能性，包括打造目前看不存在的业务。我们需要在这个机会出现之前就开始进行投资，开发更先进的模型，增加我们产品的使用，然后才能带来具有一定规模的收入。尽管战略押注有巨大的长期潜力，但在回报曲线上比我们的核心人工智能工作要早很多。不过我要说明的是，在构建系统方面，公司需要考虑灵活发挥自身能力，因此当我们确定将基础设施投向哪些最佳机会时，可以在不同的业务之间灵活调整。</p><p><strong>马克·扎克伯格：</strong>关于<strong>从公司其他部门转移资源</strong>的问题，总体而言，实际上我们在很多业务上都存在这种情况，无论是计算资源还是其他什么资源，这种转移<strong>都是为了推进人工智能工作。具体到现实实验室的问题，我仍然对构建这些新计算平台的前景非常乐观。</strong>我在前面的发言中提到，虚拟现实头戴设备/智能眼镜未来将成为一个非常重要的平台，而且我对该产品的发展前景预期有了很大改善，因为我们以前认为，其真正的发展要等到全息显示屏市场变得足够大才能实现。而我们现在更为关注与雷朋合作推出的智能眼镜，这方面的进展非常不错，所以我认为智能眼镜有可能比我预期更早地成为一块比较大的业务，并且保持不断的增长。现实实验室的大部分工作还是专注于人工智能领域的技术，但我仍然认为我们也应该关注打造智能眼镜这样的，能够实现长期发展的平台。</p><p><strong>富国银行分析师Ken Gawrelski：</strong>展望接下来的产品投资，我们应如何理解公司应用程序家族的营收和成本增长之间的关系？另外关于一季度的一般及行政费用增长，管理层特别提到了法律费用，请问哪些一次性费用导致了一季度一般及行政费用的增长？</p><p><strong>苏珊·李：</strong>关于第二个问题，一般及行政费用的增长实际上是因为法律费用的增长。我们在一季度确认了一部分与正在进行的法律事务相关的应计费用，更多详细信息将在10-Q报告中披露。你的第一个问题实际上是关于Meta应用程序家族长期利润的状况，这方面我们没有可以提供的展望，不过在去年一整年中，我们都严格遵守且坚持执行效率至上的业务运营原则，因此，我们在分配新资源方面非常严格，这是我们自去年开始逐步建立起来的优势，对我们的持续发展非常重要。尤其在应用程序家族业务达到目前规模的情况下，我们会继续强调这一点。</p><p><strong>巴克莱分析师Ross Sandler：</strong>马克，公司与谷歌和Bing合作开展了Meta人工智能内生搜索引用服务。从长远来看，Meta人工智能可能在某个时间点推出搜索广告服务并创收吗？还是持“既然有人在做，我们就推付费服务”的观点？</p><p>第二个问题，管理层提到公司致力于为企业和内容创作者开发人工智能工具。如果所有人都进入同Taylor Swift人工智能形象交互和购买演唱会门票的阶段，未来的商业模式将如何变化？</p><p><strong>马克·扎克伯格：通过与谷歌和微软的合作，我们能获得Meta人工智能的最新信息，这种合作意义重大，也和单纯的搜索业务有很大区别。</strong>我们并没有开展搜索广告或类似业务的合作，我们之间的合作将会呈现完全不同的样貌。Meta人工智能交互服务当然有能力提供广告和付费内容，人们也可能会愿意为更强大的模型，或计算能力，或者一些高级功能付费，但目前讨论这些为时过早。</p><p><strong>我认为现在比较明确的、最大的机遇是与商业通信相关的业务，这是对公司现有业务的补充，提高应用程序的用户参与度和广告质量。</strong>无论是内容创作者还是我们平台上1亿多家企业，希望他们可以利用我们的商业通信服务，轻松地构建和利用人工智能进行社群互动，开展销售、商务以及客户支持方面的工作。</p><p>对于创作者来说也是类似的，当然更多是参与的乐趣。很多内容创作者选择我们平台是因为他们也将其视为一项业务，无论是通过平台出售音乐会门票或产品，或是有其他业务目标。其中很多人要么宣传力度不够，要么业务信息传递的变现效果不太<a href="https://stock.finance.sina.com.cn/usstock/quotes/LI.html" rel="noopener noreferrer nofollow" target="_blank">理想</a>(23.87,&nbsp;-0.94,&nbsp;-3.79%)。这很大程度上是因为信息传递的成本仍然很高，而人工智能应该能够大大降低企业和创作者的成本。我认为这方面大有潜力，会比仅仅增加用户参与度和提告广告质量更有效。</p><p>这很可能是近期的机遇之一，尽管不会在下个季度或者是五年左右就实现，但仍将是一个令人振奋的领域。随着业务的发展壮大，Meta人工智能将创造自己的变现机会，这只是时间问题。但正如我所强调的，我们目前阶段的主要目标是使Meta人工智能应用成为数亿或数十亿人工作的重要组成部分，这就是我们的下一个目标——打造有超级价值的服务，可能实现的规模不可估量。</p><p><strong>花旗银行分析师Ron Josey：</strong>马克提到说，通过所有的这些优化、投资和创新，乐观情绪在内部有了很大的增长，尤其是在Meta人工智能服务方面。能否谈谈4000亿参数模型可能会如何提升Meta的服务体验，未来几个月或者几年的时间里，随着商业通信等服务成为更大的业务焦点，情况会否出现变化？</p><p><strong>马克·扎克伯格：</strong>人工智能服务的下一个阶段是处理更为复杂的任务，发展成为更像智能助手的服务，而非仅仅是聊天机器人。我对聊天机器人的理解是，你给它发送一条消息，它会回复你的消息，更像是一对一的通信。而智能助手要做的是，你给它一个意图或目标，然后它会自行去做很多查询，这些查询可能在后台进行，帮助实现你的目标，无论是在网上研究某个课题，还是最终找到你想要购买的东西。这里面包含很多复杂的情况和各种不同的事物，我觉得人们甚至可能还没有意识到能够要求电脑为他们做这些事情。目前比较大的模型，以及未来更小的、更先进的版本，都能够实现这样更有趣的交互。这些交互也可以应用到商业场景，比如一个销售或者客服聊天机器人已经不能够满足现实的需求了。每家企业都有自己都目标：努力服务客户，以某种方式推广产品，鼓励人们购买与他们兴趣相匹配的产品。这更像是一种多轮互动，在这种场景之下，聊天机器人的功能就会略显初级。</p><p>除此之外，随着智能助手推理和规划能力的提高，它们也能够引导人去完成作为内容创造者或企业所有者所设定的目标，以及相关的业务流程，这将是非常强大的功能，而且非常有可能实现。Meta已经打造了领先的模型，所以我们是有能力这样做的，而且这将是一项非常好的长期投资。</p><p class="editor-note">本文来自<a href="https://finance.sina.com.cn/stock/usstock/c/2024-04-25/doc-inasziaa6113904.shtml" rel="noopener noreferrer nofollow" target="_blank">“新浪科技”</a>，作者：罗宁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748618698144775</id>
            <title>IBM第一季度营收144.62亿美元，净利润同比增长69%</title>
            <link>https://www.36kr.com/p/2748618698144775</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748618698144775</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 08:41:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: IBM, 财报, 收购, 股价下跌
<br>
<br>
总结: IBM发布了2024年第一季度财报，营收和净利润均有增长，但营收未达预期。同时宣布以每股35美元的价格收购云软件开发商HashiCorp，股价因此大幅下跌。 </div>
                        <hr>
                    
                    <p>新浪科技讯 北京时间4月25日早间消息，IBM今天发布了2024年第一季度财报：营收为144.62亿美元，同比增长1%，不计入汇率变动的影响为同比增长3%；净利润为16.05亿美元，与上年同期的9.27亿美元相比大幅增长；来自于持续运营业务的净利润为15.75亿美元，与上年同期的9.34亿美元相比增长69%。</p><p>IBM第一季度调整后每股收益超出华尔街分析师预期，但营收则未能达到预期。另外，IBM发布声明宣布，<strong>计划以每股35美元的价格收购云软件开发商HashiCorp，支付方式为现金，该交易对后者的估值为64亿美元。</strong>IBM表示，预计这项交易将在2024年底之前完成，并将在交易完成后的第一个年度对其调整后EBITDA（利息、税项、折旧和摊销前收益）形成增益。</p><p>在发布第一季度财报和宣布上述收购消息之后，IBM盘后股价大幅下跌逾8%。</p><h2>主要业绩：</h2><p>在截至2024年3月31日的这一财季，IBM的净利润为16.05亿美元，与上年同期的9.27亿美元相比大幅增长。</p><p>IBM第一季度来自于持续运营业务的利润为15.75亿美元，与上年同期的9.34亿美元相比增长69%；来自于持续运营业务的每股摊薄收益为1.69美元，与上年同期的1.03美元相比增长66%。IBM第一季度来自于非持续运营业务的利润为3000万美元，而上年同期来自于非持续运营业务的亏损为700万美元；来自于非持续运营业务的每股摊薄收益为0.03美元，而上年同期来自于非持续运营业务的每股摊薄亏损为0.01美元。</p><p>不按照美国通用会计准则（不计入某些一次性项目），IBM第一季度来自于持续运营业务的运营净利润为16亿美元，与上年同期的12亿美元相比增长25%；来自于持续运营业务的运营每股摊薄收益为1.68美元，与上年同期的1.36美元相比增长24%，这一业绩超出分析师此前预期。据雅虎财经网站提供的数据显示，12名分析师此前平均预期IBM第一季度每股收益将达1.6美元。</p><p>IBM第一季度营收为144.62亿美元，与上年同期的142.52亿美元相比增长1%，不计入汇率变动的影响为同比增长3%，但这一业绩未能达到分析师此前预期。据雅虎财经网站提供的数据显示，11名分析师此前平均预期IBM第一季度营收将达145.5亿美元。</p><p>IBM第一季度毛利润为77.42亿美元，与上年同期的75.09亿美元相比增长3%；不按照美国通用会计准则（不计入某些一次性项目），IBM第一季度的运营毛利润为79.13亿美元，与上年同期的76.58亿美元相比增长3%。</p><p>IBM第一季度总毛利润率为53.5%，与上年同期的52.7%相比上升80个基点。不按照美国通用会计准则（不计入某些一次性项目），IBM第一季度的总运营毛利润率为54.7%，与上年同期的53.7%相比上升100个基点。按照业务部门划分，IBM软件部门第一季度毛利润率为82.4%，与上年同期的82.6%相比有所下降；咨询部门第一季度毛利润率为25.3%，与上年同期的25.5%相比有所下降；基础设施部门第一季度毛利润率为54.2%，与上年同期的51.8%相比有所上升；融资部门第一季度毛利润率为48.5%，与上年同期的43.9%相比有所上升。</p><p><strong>成本和支出：</strong></p><p>IBM第一季度的总支出及其他收入为66.69亿美元，与上年同期的64.51亿美元相比有所上升。其中，销售、总务和行政支出为49.74亿美元，与上年同期的48.53亿美元相比有所上升；研发和工程支出为17.96亿美元，与上年同期的16.55亿美元相比有所上升；知识产权和海关开发收入为2.16亿美元，与上年同期的1.80亿美元相比有所增长；其他收入为3.17亿美元，与上年同期的其他收入2.45亿美元相比有所增长；利息支出为4.32亿美元，与上年同期的3.67亿美元相比有所上升。</p><p><strong>各部门业绩数据：</strong></p><p>2024财年第一季度，IBM软件业务部门（包括混合平台与解决方案业务以及交易处理业务）的营收为58.99亿美元，与上年同期的55.91亿美元相比增长5.5%，不计入汇率变动的影响为同比增长5.9%。其中：</p><p>（1）混合平台及解决方案部门营收同比增长6%，不计入汇率变动的影响为同比增长7%。在混合平台及解决方案内部细分：</p><p>- 红帽部门营收同比增长9%；</p><p>- 自动化部门营收同比增长13%；</p><p>- 数据和AI（人工智能）部门营收同比增长1%；</p><p>- 安全部门营收同比下降3%。</p><p>（2）交易处理部门营收同比增长3%，不计入汇率变动的影响为同比增长4%。</p><p>2024财年第一季度，IBM咨询业务部门（包括商业转型、技术咨询和应用业务）第一季度营收为51.86亿美元，与上年同期的51.97亿美元相比下降0.2%，不计入汇率变动的影响为同比增长1.7%。其中：</p><p>- 业务转型营收同比增长1%，不计入汇率变动的影响为同比增长3%；</p><p>- 技术咨询营收同比增长1%，不计入汇率变动的影响为同比增长3%；</p><p>- 应用运营营收同比下降3%，不计入汇率变动的影响为同比下降1%。</p><p>IBM第一季度基础设施业务部门（包括混合基础设施和基础设施支持业务）营收为30.76亿美元，与上年同期的30.98亿美元相比下降0.7%，不计入汇率变动的影响为同比增长0.2%。其中：</p><p>（1）混合基础设施部门营收同比增长5%，不计入汇率变动的影响为同比增长6%。在混合基础设施部门内部细分：</p><p>- “z系统”（z Systems）营收同比增长4%，不计入汇率变动的影响为同比增长5%；</p><p>- 分布式基础设施部门营收同比增长6%，不计入汇率变动的影响为同比增长7%。</p><p>（2）基础设施支持部门营收同比下降8%，不计入汇率变动的影响为同比下降7%。</p><p>2024财年第一季度，IBM度融资部门（包括客户和商业融资业务）营收为1.93亿美元，与上年同期的1.96亿美元相比下降1.6%，不计入汇率变动的影响为同比下降1.5%。</p><p>IBM第一季度其他业务部门的营收为1.08亿美元，而上年同期其他业务部门的营收为1.69亿美元，同比有所下降。</p><p><strong>其他财务信息：</strong></p><p>IBM第一季度来自于运营活动的净现金为42亿美元，与上年同期相比增加了4亿美元；不计入全球融资部门的应收账款，IBM第一季度来自于运营活动的净现金为23亿美元。</p><p>IBM第一季度自由现金流为19亿美元，与上年同期相比增加了6亿美元。</p><p>在过去12个月里，IBM来自于运营活动的净现金为143亿美元，自由现金流为118亿美元。</p><p>在第一季度里，IBM通过派发股息的形式向股东返还了15亿美元现金。</p><p>截至2024年第一季度末，IBM持有193亿美元现金（其中包括有价证券），与2023年底相比增加了58亿美元；债务总额为595亿美元（其中全球融资部门的债务为99亿美元），与2023年底相比增加了30亿美元。</p><h2>业绩展望：</h2><p>IBM目前预计，不计入汇率变动的影响，该公司2024财年全年营收的同比增幅将在1%至9%区间的中段。按目前的汇率计算，预计汇率变动将对该公司2024财年的营收增长率造成大约1.5到2个百分点之间的负面影响。</p><p>据雅虎财经频道提供的数据显示，18名分析师平均预期IBM在整个2024财年的营收将达635.9亿美元，</p><p>另外，IBM继续预计，2024财年该公司的总自由现金流将达120亿美元左右。</p><h2>股价反应：</h2><p>当日，IBM股价在纽约证券交易所常规交易中上涨1.91美元，报收于184.10美元，涨幅为1.05%。在随后截至美国东部时间24日晚上6点16分（北京时间25日早上6点16分）的盘后交易中，IBM股价大幅下跌15.11美元，至168.99美元，跌幅为8.21%。过去52周，IBM最高价为199.18美元，最低价为120.55美元。</p><p>本文来自<a href="https://finance.sina.com.cn/stock/usstock/c/2024-04-25/doc-inaszaue7767718.shtml" rel="noopener noreferrer nofollow" target="_blank">“新浪科技”</a>，作者：罗宁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748554682104833</id>
            <title>苹果开源可以在手机上跑的大模型，代码、权重、数据全公开，AI应用开发的下一个风口？</title>
            <link>https://www.36kr.com/p/2748554682104833</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748554682104833</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 08:00:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 开源, AI模型, OpenELM
<br>
<br>
总结: 苹果发布了一个在设备端运行的AI模型OpenELM，包括代码、权重、数据集和训练全过程，加入了生成式AI模型的开发行列，家族共有八位成员，通过预训练和指令微调实现模型效果的改进，模型适合在商用笔记本电脑和智能手机上运行。 </div>
                        <hr>
                    
                    <p>苹果开源了一个在设备端运行的 AI 模型 OpenELM，同时还公开了代码、权重、数据集、训练全过程。</p><p>就像谷歌、三星及微软着力在 PC 和移动设备端推动生成式 AI 模型的开发一样，苹果也加入了这一行列。这是一个新的开源大语言模型（LLM）家族，能够依托单一设备平台运行，完全无需借助云服务器。</p><p>OpenELM 已经于日前在 AI 代码社区 Huggang Face 上发布，由多个旨在高效执行文本生成任务的小模型组成。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_ded6d183dfd44e478283270dddc09ef3@46958_oswg25159oswg543oswg443_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">苹果投身开源 AI 战局，在 Hugging Face 上发布四种新模型！</p><p>OpenELM 模型家族共有八位成员，其中四个为预训练模型，另外四个为指令微调模型，参数规模在 2.7 亿到 30 亿之间（即大模型中人工神经元之间的连接数量，参数越多通常意味着性能更好、功能更强，但并不绝对）。而微软 Phi-3 模型为 38 亿。</p><p>预训练是让大模型得以生成连续、可用文本的重要方法，而指令微调则能够让模型以相关度更高的输出响应用户的特定请求。具体来讲，预训练而成的模型往往会通过在提示词的基础上添加新文本来完成要求，例如面对用户的“教我如何烤面包”这条提示词，模型可能并不会给出分步说明，反而傻傻回答称“用家用烤箱烤”。而这个问题恰好可以通过指令微调来解决。</p><p>OpenELM 通过采用层级缩放策略、在公开数据集预训练后微调，实现了 Transformer 语言模型效果的改进。因此，OpenELM 的 transformer layers 不是具有相同的参数集，而是具有不同的配置和参数。这样的策略能让模型精度显著提高。例如，在大约十亿参数的预算下，OpenELM 的准确率较 OLMo 提升了 2.36%，且预训练所需的 Token 数量减少了一半。</p><p>苹果在其所谓“示例代码许可证”下发布了 OpenELM 模型的<strong>权重，以及训练中的不同检查点、模型性能统计数据以及预训练、评估、指令微调与参数效率调优的说明</strong>。网友点评说，“可以说对开发者来说很友好了，毕竟深度网络的很大一部分难点存在参数调节。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_01bf6e8bc7124827a601fd2ccb5eb3ff@46958_oswg38754oswg667oswg421_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>苹果的示例代码许可证<strong>并不禁止商业使用或修改</strong>，仅要求“如果您以完整且未经修改的方式重新发布苹果软件，则必须在所有此类发布中保留本通知以及以下文本与免责声明。”</p><p>该许可不是公认的开源许可证，虽然苹果也没有做过度的限制，但它确实明确表明，如果任何基于 OpenELM 的衍生作品被认为侵犯了其权利，苹果保留提出专利索赔的权利。</p><p>苹果公司还进一步强调，这些模型“不提供任何安全保证。因此，模型可能会根据用词提示词生成不准确、有害、存在偏见或者令人反感的输出。”</p><p>OpenELM 只是苹果公司发布的一系列令人惊讶的开源 AI 模型中的最新一批。去年 10 月，苹果方面曾悄然发布具有多模态功能的开源语言模型 Ferret，迅速引起各界关注。</p><p>目前，大模型领域主要分为开源和闭源两大阵营。闭源阵营的代表企业包括 OpenAI、Anthropic、谷歌、Midjourney、Udio、百度、科大讯飞、出门问问、月之暗面等。开源阵营的代表企业包括 Meta、微软、谷歌、百川智能、阿里巴巴、零一万物等。这些企业致力于开放大模型的技术和代码，鼓励开发者和研究人员参与模型的开发和改进。</p><p>苹果长期以来一直以神秘莫测、对外“封闭”而闻名，本次却罕见地加入开源大模型阵营。以前，除了在网上发布模型和论文之外，苹果并未公开宣布或者讨论其在 AI 领域的探索。</p><h2>关于 OpenELM，我们了解什么？&nbsp;</h2><p>尽管 OpenELM（全称为开源高效语言模型）才刚刚发布、尚未进行过公开测试，但苹果在 Hugging Face 上指出其目标是在设备端运行这些模型。这明显是在紧跟竞争对手谷歌、三星和微软的脚步——微软本周刚刚发布了能够纯在智能手机端运行的 Phi-3 Mini 模型。</p><p>在 arXiv.org 上发表的一篇模型阐述论文中，苹果表示 OpenELM 的开发“由 Sachin Mehta 领导，Mohammad Rastegrai 与 Peter Zatloukal 则额外做出贡献”，该模型家族“旨在增强并赋能开放研究社区，促进未来的研究工作。”</p><p>苹果的 OpenELM 模型分为四种规模，分别拥有 2.7 亿、4.5 亿、11 亿与 30 亿参数，各模型均比现有高性能模型更小（通常为 70 亿参数）且各自拥有预训练与指令微调两个版本。</p><p>这些模型的预训练采用来自 Reddit、维基百科、arXiv.org 等网站总计 1.8 万亿 tokens 的公共数据集。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_aea0e044eafb4d3a8a6429527a945eed@46958_oswg20809oswg411oswg370_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>OpenELM 模型适合在<strong>商用笔记本电脑甚至部分智能手机上运行。</strong> 苹果在论文中指出，他们分别在“配备英特尔 i9-13900KF CPU、64 GB DDR5-4000 DRAM 和 24 GB VRAM 的英伟达 RTX 4090 GPU，运行有 Ubuntu 22.04 的工作站上”、以及“配备 M2 Max 系统芯片与 64 GiB RAM、运行有 macOS 14.4.1 的苹果 MacBook Pro 上”运行了基准测试。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_593f4d1a8c134934a7491757b443f85c@46958_oswg49901oswg545oswg509_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_f402aa965da2480f9b1bb083e02a3750@46958_oswg34719oswg541oswg424_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">网友测试运行 OpenELM 模型</p><p>有趣的是，新家族中的所有模型均采用分层缩放策略来分配 Transformer 模型中每一层内的参数。</p><p>据苹果公司介绍，这种方式能够提供更加准确的结果，同时提高计算效率。该公司还使用新的 CoreNet 库对模型进行了预训练。</p><p>该公司在 Hugging Face 上提到，“我们的预训练数据集包含 RefinedWeb、去重版 PILE、RedPajama 的一个子集以及 Dolma v1.6 的一个子集，总规模约 1.8 万亿个 tokens。”</p><h2>值得肯定，但性能并非顶尖&nbsp;</h2><p>在性能方面，苹果公布的结果显示 OpenELM 模型相当出色，特别是其中的 4.5 亿参数版本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_29530c7ddd7c4f0ab0f25fad937c561d@46958_oswg104098oswg554oswg446_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，11 亿参数的 OpenELM 版本“比拥有 12 亿参数的 OLMo 模型性能提高了 2.36%，且需要的预训练 tokens 仅为后者的二分之一。”OLMo 是艾伦 AI 研究所（AI2）最近发布的“真正开源且最先进的大语言模型”。</p><p>而在强调测试知识与推理技能的 ARC-C 基准测试中，经过预训练的 OpenELM-3B 版本的准确率达到 42.24%，同时在 MMLU 与 HellaSwag 上分别得到 26.76% 与 73.28% 的成绩。</p><p>一位参与该模型系列测试的用户指出，苹果的模型成果似乎“稳定且性能一致”，就是说其响应结果并不具备灵活的创造力，也不太可能冒险涉及“不适合上班时浏览”的内容。</p><p>竞争对手微软近期推出的 Phi-3 Mini 拥有 38 亿参数及 4k 上下文长度，目前在性能层面仍处于领域地位。</p><p>根据最新发布的统计数据，Phi-3 Mini 在 10-shot ARC-C 基准测试中得分为 84.9%，在 5-shot MMLU 上得分为 68.8%，在 5-shot Hellaswag 上得分为 76.7%。</p><p>但从长远来看，OpenELM 肯定还会继续得到改进。目前开源大模型社区对于苹果的加入非常兴奋，也期待看到这位“闭源”巨头如何将其成果引入于各类应用场景。</p><h2>大模型是智能手机的未来&nbsp;</h2><p>手机厂商们都很看好手机上的 AI 前景。</p><p>高通和联发科等公司已推出了智能手机芯片组，可满足人工智能应用所需的处理能力。此前，许多设备上的 AI 应用实际上是在云端进行部分处理，然后下载到手机上。但云端模型也存在弊端，如推理成本很高，一些 AI 创业公司训练 + 生成一张图片的成本可能就要一元。而先进的芯片和端侧模型则会推动更多 AI 应用程序在手机端运行，节省成本的同时，也能给用户带来更好的实时计算能力，从而催生出新的商业模式。</p><p>从 ChatGPT 火爆至今不过一年左右，手机厂商就都已将 AI 大模型技术落地在自家手机中。</p><p>今年三星新发布的 Galaxy S24 系列上搭载了能处理语音、文本、图像的端侧 Galaxy AI。谷歌也发布了一款搭载自家 AI 模型的手机 Pixel 8 系列，该设备搭载了 Gemini Nano。谷歌 Pixel 部门产品管理副总裁 Brian Rakowski 还表示谷歌最先进的大模型也会于明年直接登陆智能手机，“我们在压缩这些模型方面已经取得了相当多的突破。”</p><p>国内头部手机厂商也争相布局。小米于去年 10 月发布了澎湃 OS 以及小米自研大模型加持的各类应用；vivo 也去年宣布推出了蓝心大模型，并开源了面向手机打造的端云两用大模型 BlueLM-7B；OPPO 也在去年 11 月发布了安第斯大模型 (AndesGPT)，以“端云协同”为基础架构设计思路，推出了多种不同参数规模的模型规格。</p><p>今年世界移动通信大会 MWC 的一大亮点也是大模型能够在设备本身上本地运行，“这就是最具颠覆性的地方。” CCS Insight 首席分析师 Ben Wood 感叹。在这次大会上，还展示了一些未来 AI 概念手机，比如德国电信和 Brain.ai 完全放弃 App 而采用 AI 界面的 T phone。因此，也有预测认为，随着 AI 占领我们的智能手机，App 时代的终结可能指日可待，从而带来全新的生态和竞争格局。</p><p>手机大模型之战，此前只差苹果，而现在，苹果终于带着它的开源大模型来了。</p><p><strong>参考链接：</strong></p><p>https://venturebeat.com/ai/apple-releases-openelm-small-open-source-ai-models-designed-to-run-on-device/</p><p>https://www.infoq.cn/article/h2ceezfmjdbo2epareyh</p><p>https://arxiv.org/abs/2404.14619v1</p><p>https://twitter.com/atropos/status/1783349174702059742</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/1SlaqGHxdOFt9GM8VX_33g" rel="noopener noreferrer nofollow" target="_blank">“InfoQ”（ID:infoqchina）</a>，编译：核子可乐、Tina&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748554664639240</id>
            <title>颜水成挂帅，奠定「通用视觉多模态大模型」终极形态，一统理解/生成/分割/编辑</title>
            <link>https://www.36kr.com/p/2748554664639240</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748554664639240</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 07:59:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 颜水成团队, Vitron模型, 视觉多模态大语言模型, 通用人工智能
<br>
<br>
总结: 颜水成团队联合新加坡国立、南洋理工大学共同开源了Vitron模型，这是一款重磅的通用视觉多模态大模型，支持从视觉理解到视觉生成、从低层次到高层次的一系列视觉任务，为下一代通用视觉大模型的终极形态奠定了基础，也标志着大模型迈向通用人工智能（AGI）的又一大步。Vitron作为一个统一的像素级视觉多模态大语言模型，实现了从低层次到高层次的视觉任务的全面支持，能够处理复杂的视觉任务，并理解和生成图像和视频内容，提供了强大的视觉理解和任务执行能力。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a582c97d9aa242c1800a7fba3c34dbca@46958_oswg293302oswg1069oswg399_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>颜水成团队联合新加坡国立、南洋理工大学共同开源了Vitron模型，持从视觉理解到视觉生成、从低层次到高层次的一系列视觉任务，为下一代通用视觉大模型的终极形态奠定了基础，也标志着大模型迈向通用人工智能（AGI）的又一大步。</p><p>近日，颜水成教授团队联合发布并开源了Vitron通用像素级视觉多模态大语言模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_eff971e278564ff1859ef72a30f9c3f0@46958_oswg105833oswg1008oswg395_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>项目主页&amp;Demo：https://vitron-llm.github.io/</p><p>论文链接：https://is.gd/aGu0VV</p><p>开源代码：https://github.com/SkyworkAI/Vitron</p><p>这是一款重磅的通用视觉多模态大模型，支持从视觉理解到视觉生成、从低层次到高层次的一系列视觉任务，解决了困扰大语言模型产业已久的图像/视频模型割裂问题，提供了一个全面统一静态图像与动态视频内容的理解、生成、分割、编辑等任务的像素级通用视觉多模态大模型，为下一代通用视觉大模型的终极形态奠定了基础，也标志着大模型迈向通用人工智能（AGI）的又一大步。</p><p>Vitron作为一个统一的像素级视觉多模态大语言模型，实现了从低层次到高层次的视觉任务的全面支持，能够处理复杂的视觉任务，并理解和生成图像和视频内容，提供了强大的视觉理解和任务执行能力。同时，Vitron支持与用户的连续操作，实现了灵活的人机互动，展示了通向更统一的视觉多模态通用模型的巨大潜力。</p><p>Vitron相关的论文、代码和Demo已全部公开，其在综合性、技术创新、人机交互和应用潜力等方面展现出的独特优势和潜力，不仅推动了多模态大模型的发展，还为未来的视觉大模型研究提供了一个新的方向。</p><p>当前视觉大语言模型（LLMs）的发展取得了喜人进展。社区越来越相信，构建更通用、更强大的多模态大模型（MLLMs）将会是通向通用人工智能（AGI）的必经之路。但在向多模态通用大模型（Generalist）的迈进过程中，目前仍存在一些关键挑战。比如很大一部分工作都没有实现细粒度像素级别的视觉理解，或者缺乏对图像和视频的统一支持。抑或对于各种视觉任务的支持不充分，离通用大模型相差甚远。</p><p>为了填补这个空白，近日，团队联合发布开源了Vitron通用像素级视觉多模态大语言模型。Vitron支持从视觉理解到视觉生成、从低层次到高层次的一系列视觉任务，包括静态图像和动态视频内容进行全面的理解、生成、分割和编辑等任务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a7b8c75387f743aaab3b7a7091c7410c@46958_oswg991443oswg1080oswg1076_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上图综合描绘了Vitron在四大视觉相关任务的功能支持，以及其关键优势。Vitron还支持与用户的连续操作，实现灵活的人机互动。该项目展示了面向更统一的视觉多模态通用模型的巨大潜力，为下一代通用视觉大模型的终极形态奠定了基础。</p><p>Vitron相关论文、代码、Demo目前已全部公开。</p><h2>大一统的终极多模态大语言模型</h2><p>近年来，大语言模型（LLMs）展现出了前所未有的强大能力，其被逐渐验证为乃是通向AGI的技术路线。而多模态大语言模型（MLLMs）在多个社区火爆发展且迅速出圈，通过引入能进行视觉感知的模块，扩展纯语言基础LLMs至MLLMs，众多在图像理解方面强大卓越的MLLMs被研发问世，例如BLIP-2、LLaVA、MiniGPT-4等等。与此同时，专注于视频理解的MLLMs也陆续面世，如VideoChat、Video-LLaMA和Video-LLaVA等等。</p><p>随后，研究人员主要从两个维度试图进一步扩展MLLMs的能力。一方面，研究人员尝试深化MLLMs对视觉的理解，从粗略的实例级理解过渡到对图像的像素级细粒度理解，从而实现视觉区域定位（Regional Grounding）能力，如GLaMM、PixelLM、NExT-Chat和MiniGPT-v2等。</p><p>另一方面，研究人员尝试扩展MLLMs可以支持的视觉功能。部分研究已经开始研究让MLLMs不仅理解输入视觉信号，还能支持生成输出视觉内容。比如，GILL、Emu等MLLMs能够灵活生成图像内容，以及GPT4Video和NExT-GPT实现视频生成。</p><p>目前人工智能社区已逐渐达成一致，认为视觉MLLMs的未来趋势必然会朝着高度统一、能力更强的方向发展。然而，尽管社区开发了众多的MLLMs，但仍然存在明显的鸿沟。</p><p><strong>1. 几乎所有现有的视觉LLMs将图像和视频视为不同的实体，要么仅支持图像，要么仅支持视频。</strong></p><p>研究人员主张，视觉应该同时包含了静态图像和动态视频两个方面的内涵——这两者都是视觉世界的核心组成，在大多数场景中甚至可以互换。所以，需要构建一个统一的MLLM框架能够同时支持图像和视频模态。</p><p><strong>2. 目前MLLMs对视觉功能的支持还有所不足。</strong></p><p>大多数模型仅能进行理解，或者最多生成图像或视频。研究人员认为，未来的MLLMs应该是一个通用大语言模型，能覆盖更广泛的视觉任务和操作范围，实现对所有视觉相关任务的统一支持，达到「one for all」的能力。这点对实际应用尤其是在经常涉及一系列迭代和交互操作的视觉创作中至关重要。</p><p>例如，用户通常首先从文本开始，通过文生图，将一个想法转化为视觉内容；然后通过进一步的细粒度图像编辑来完善初始想法，添加更多细节；接着，通过图像生成视频来创建动态内容；最后，进行几轮迭代交互，如视频编辑，完善创作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_78900e88185847ffaa1dc81ab0934128@46958_oswg267795oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上表简单地归纳了现有的视觉MLLM的能力（只代表性地囊括了部分模型，覆盖不完整）。为了弥补这些差距，该团队提出一种通用的像素级视觉MLLM——Vitron。</p><h2><strong>Vitron系统架构：三大关键模块</strong></h2><p>Vitron整体框架如下图所示。Vitron采用了与现有相关MLLMs相似的架构，包括三个关键部分：1) 前端视觉&amp;语言编码模块，2) 中心LLM理解和文本生成模块，以及3) 后端用户响应和模块调用以进行视觉操控模块。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_de464a033ffb4872b42e86bcb78af967@46958_oswg325081oswg1080oswg645_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>前端模块：</strong>视觉-语言编码</p><p>为了感知图像和视频模态信号，并支持细粒度用户视觉输入，Vitron集成了图像编码器、视频编码器、区域框/草图编码器。</p><p><strong>中心模块：</strong>核心LLM</p><p>Vitron使用的是Vicuna（7B，v1.5），来实现理解、推理、决策制定和多轮用户交互。</p><p><strong>后端模块：</strong>用户响应与模块调用</p><p>Vitron采用以文本为中心的调用策略，整合现成的几个强大先进（SoTA）的图像和视频处理模块，用于解码和执行从低层到高层的一系列视觉终端任务。通过采用以文本为中心的模块集成调用方法，Vitron不仅实现了系统统一，还确保了对齐效率和系统可扩展性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_22f82a71a157478c92c887a35b82ae8b@46958_oswg161097oswg1080oswg253_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>Vitron模型训练三大阶段</h2><p>基于上述架构，再对Vitron进行训练微调，以赋予其强大的视觉理解和任务执行能力。模型训练主要囊括三个不同的阶段。</p><p><strong>步骤一：</strong>视觉-语言整体对齐学习。将输入的视觉语言特征映射到一个统一的特征空间中，从而使其能够有效理解输入的多模态信号。这是一种粗粒度的视觉-语言对齐学习，可以让系统具备整体上有效处理传入的视觉信号。研究人员采用了现存的图像-标题对（CC3M）、视频-标题对（Webvid）和区域-标题对（RefCOCO）的数据集进行训练。</p><p><strong>步骤二：</strong>细粒度的时空视觉定位指令微调。系统采用了调用外部模块方式来执行各种像素级视觉任务，但LLM本身并未经过任何细粒度的视觉训练，这将会阻碍了系统实现真正的像素级视觉理解。为此，研究人员提出了一种细粒度的时空视觉定位指令微调训练，核心思想是使LLM能够定位图像的细粒度空间性和视频的具体时序特性。</p><p><strong>步骤三：</strong>输出端面向命令调用的指令微调。上述第二阶段的训练赋予了LLM和前端编码器在像素级别理解视觉的能力。这最后一步，面向命令调用的指令微调，旨在让系统具备精确执行命令的能力，允许LLM生成适当且正确的调用文本。由于不同的终端视觉任务可能需要不同的调用命令，为了统一这一点，研究人员提出将LLM的响应输出标准化为结构化文本格式，其中包括：</p><p>1）用户响应输出，直接回复用户的输入</p><p>2）模块名称，指示将要执行的功能或任务。</p><p>3）调用命令，触发任务模块的元指令。</p><p>4）区域（可选输出），指定某些任务所需的细粒度视觉特征，例如在视频跟踪或视觉编辑中，后端模块需要这些信息。对于区域，基于LLM的像素级理解，将输出由坐标描述的边界框。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_9debe60731bd43d8b343609e03ba495d@46958_oswg218154oswg1080oswg377_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>评估实验</strong></h2><p>研究人员基于Vitron在22个常见的基准数据集、12个图像/视频视觉任务上进行了广泛的实验评估。Vitron展现出在四大主要视觉任务群组（分割、理解、内容生成和编辑）中的强大能力，与此同时其具备灵活的人机交互能力。以下代表性地展示了一些定性比较结果：</p><p><strong>Vision Segmentation</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_e92ebe0d6dfa494eadc31bf73dab60af@46958_oswg125920oswg1080oswg224_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Results of image referring image segmentation</p><p><strong>Fine-grained Vision Understanding</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_9eee0afc35d24be69cd7503913550d02@46958_oswg111724oswg1080oswg191_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Results of image referring expression comprehension.</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_b92dce60e9ba4e599661a0d0ca4d4d5c@46958_oswg174950oswg1080oswg265_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Results on video QA.</p><p><strong>Vision Generation</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_4eae6ab8517d4147959b80d5ebe56610@46958_oswg127407oswg933oswg198_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Text-to-Image Generation/Text-to-Video generation/Image-to-Video generation</p><p><strong>Vision Editing</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_652c8dbffaf240aeb869aeb6d5c2be67@46958_oswg103727oswg795oswg244_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Image editing results</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_bc2da68fd1f84581ab2106dc6b27df68@46958_oswg103727oswg795oswg244_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体更多详细实验内容和细节请移步论文。</p><h2>未来方向展望</h2><p>总体上，这项工作展示了研发大一统的视觉多模态通用大模型的巨大潜力，为下一代视觉大模型的研究奠定了一个新的形态，迈出了这个方向的第一步。尽管团队所提出的Vitron系统表现出强大的通用能力，但依然存在自身的局限性。以下研究人员列出一些未来可进一步探索的方向。</p><p><strong>系统架构</strong></p><p>Vitron系统仍采用半联合、半代理的方式来调用外部工具。虽然这种基于调用的方法便于扩展和替换潜在模块，但这也意味着这种流水线结构的后端模块不参与到前端与LLM核心模块的联合学习。</p><p>这一限制不利于系统的整体学习，这意味着不同视觉任务的性能上限将受到后端模块的限制。未来的工作应将各种视觉任务模块整合成一个统一的单元。实现对图像和视频的统一理解和输出，同时通过单一生成范式支持生成和编辑能力，仍然是一个挑战。目前一种有希望的方式是结合modality-persistent的tokenization, 提升系统在不同输入和输出以及各种任务上的统一化。</p><p><strong>用户交互性</strong></p><p>与之前专注于单一视觉任务的模型（例如，Stable Diffusion和SEEM）不同，Vitron旨在促进LLM和用户之间的深度交互，类似于行业内的OpenAI的DALL-E系列，Midjourney等。实现最佳的用户交互性是本项工作的核心目标之一。</p><p>Vitron利用现有的基于语言的LLM，结合适当的指令调整，以实现一定程度的交互。例如，系统可以灵活地响应用户输入的任何预期消息，产生相应的视觉操作结果，而不要求用户输入精确匹配后端模块条件。然而，该工作在增强交互性方面仍有很大的提升空间。例如，从闭源的Midjourney系统汲取灵感，不论LLM在每一步做出何种决定，系统都应积极向用户提供反馈，以确保其行动和决策与用户意图一致。</p><p><strong>模态能力</strong></p><p>当前，Vitron集成了一个7B的Vicuna模型，其可能对其理解语言、图像和视频的能力会产生某些限制。未来的探索方向可以发展一个全面的端到端系统，比如扩大模型的规模，以实现对视觉的更彻底和全面的理解。此外，应该努力使LLM能够完全统一图像和视频模态的理解。</p><p>参考资料：&nbsp;</p><p>https://vitron-llm.github.io/&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ef3GMQavH_K9iarSdwoxog" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：LRS&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748554552753154</id>
            <title>深度对话：中国大模型算力到底够不够？Scaling Law不是唯一增长曲线</title>
            <link>https://www.36kr.com/p/2748554552753154</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748554552753154</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 07:59:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 腾讯科技, AI大模型, 算力瓶颈, 摩尔定律
<br>
<br>
总结: 本文讨论了AI大模型在scaling law下面临的挑战，以及中国大模型如何突破算力瓶颈的问题。文章提到了全球科技巨头在大模型领域的投入和竞争，以及中国大模型发展中的困境。同时，文章还探讨了大模型落地过程中面临的难题，以及如何应对算力成本的挑战。最后，通过对话内容展示了大模型发展中的“摩尔定律”启示。 </div>
                        <hr>
                    
                    <p>腾讯科技AI未来指北-AI探索者系列，对谈AI产业的躬身入局者，关注AI大模型落地第一程的关键问题。本期联合腾讯研究院，对谈上海交通大学长聘教轨副教授、无问芯穹联合创始人&amp;首席科学家戴国浩，关注在scaling law之下，中国大模型如何突破算力瓶颈，寻找新的增长路径。</p><p>AI大模型沿着scaling law，向人类展开了可能通往AGI的宏大叙事。&nbsp;</p><p>如果参数无限向上，大模型最终是否能够通往通用人工智能，目前没有人能够得到确切的答案。但是，OpenAI、Google等全球科技大厂，正走在这样一条资源豪赌之路上。&nbsp;</p><p>根据李飞飞团队刚刚发布的《人工智能指数报告》估算，最新一代人工智能模型的训练成本已经达到前所未有的水平。例如，OpenAI的GPT-4预计使用了价值7800万美元的计算资源进行训练，而谷歌的Gemini Ultra耗费了高达1.91亿美元的计算资源成本。&nbsp;</p><p>未来的算力军备竞赛还将持续。微软开启“星际之门”超级计算机项目，估计总投入1150亿美元，谷歌作为主要其竞争对手，很快回应，谷歌的投资金额只会更多，母公司Alphabet拥有的算力超过竞争对手微软。&nbsp;</p><p>在算力稀缺的情况下，有声音说“中国大模型，没有scaling law”。在当下，这种声音确实揭开了我们不得不面对的现实。芯片产业链是全球化的，产业链的关键生产环节分布在不同的地区，每个环节都不可或缺。当前，国内的芯片产业仍在积极发展中。&nbsp;</p><p>但是，在短期内，如果中国大模型要继续发展，是否有除了scaling law的第二条路径？上海交通大学长聘教轨副教授、无问芯穹联合创始人&amp;首席科学家戴国浩，从摩尔定律的发展规律观察，认为“随着时间的推延，在某一个特定规模的模型上的能力可能慢慢也会持平，这个时候，就可以去寻找发展的第二曲线，而这个曲线，就是在特定领域探索应用落地，打造商业闭环。”&nbsp;</p><p>“从7B、13B模型性能变化来看，目前已经到了应用落地阶段，<strong>2024会是推理的元年。</strong>”戴国浩这样判断。相信scaling law，大模型确实可以越做越大，解锁越来越强的能力上限。同时更可以关注到现实情况下，基于规模适当的模型，在特定领域打造商业闭环的路径，正在迎来时间窗口。&nbsp;</p><p>然而，算力成本是否能够降下来？无问芯穹发起人汪玉，用公开数据做了一次针对算力成本数量级的测算，假设GPT-4 Turbo每天要为10亿活跃用户提供服务，每年的算力成本可能超过两千亿，这还不包括模型训练的投入。&nbsp;</p><p>考虑到绝大多数公司的收入在亿的级别，而不是千亿级别，这种成本在打造商业闭环上，显然是不成立的。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_6d4d9e9c47d04ce6b4d455e15ea671a8@46958_oswg264596oswg1080oswg527_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大模型在落地过程中，不得不面对以下难题：</p><p>1、在大模型商用中，foundation model（基础模型）要如何选？</p><p>2、模型迭代迅速，什么时候才能稳定下来？每次训练一个模型都需要成本，如何应对快速迭代的沉没成本？</p><p>3、如果以GPT-4的推理成本为基准，成本压缩有多大空间？从哪些环节可以做优化？</p><p>基于这些问题，我们对话了上海交通大学长聘教轨副教授、无问芯穹联合创始人&amp;首席科学家戴国浩，“如何获得足够的算力”及“如何降低算力成本”是大模型落地需要直面的问题。</p><p>他认为，“对国内的AI产业来说，卡的数量不足不是最大的困难，因为国内有很多优秀的国产芯片企业。但是如何把这些卡的能力高效地集中到一起加以利用，是如今最难解决的问题。”</p><p><strong>以下为对话精华内容：</strong></p><h2>大模型发展的“摩尔定律”启示</h2><p><strong>腾讯科技：</strong> 无问芯穹的主营业务中似乎没有与芯片直接相关的，未来会做芯片吗？为什么要叫这个名字？&nbsp;</p><p><strong>戴国浩：</strong>我们创始团队有比较强的清华电子工程系的背景，清华每一个院系都会有一个缩写，像我当时分班（无）07班。“无”代表无线电系，电子系之前就叫无线电系，“0”代表2010年入学，“7”代表是第七个班级。而且无问、无穹都是清华校歌里的歌词。&nbsp;</p><p>我们的主营业务是做芯片上面这一层的算力软件的，对大模型和芯片来说起了很好的连接作用，并且我们也正在芯片层面做大模型的专用处理器IP，所以“芯”这个字对我们来说有着挺重要的意义。总的来说，“无问芯穹”是想表达，我们要探索芯片智能的极限。&nbsp;</p><p><strong>腾讯科技：</strong>“缺芯”是中国大模型发展中，没法绕过的一个问题。我们换个角度来思考，scaling law会一直是大模型技术的第一性原理吗？它是否会一直影响大模型的进化？&nbsp;</p><p><strong>戴国浩：</strong>这里我们可以用三条线来解读。第一条线是今天大家都很熟悉集成电路领域里的术语——摩尔定律，摩尔定律某种程度上可以被解读为，如果你是一个做上层应用的人，即使你什么事都不干，做电路的人都会每隔18~24个月帮你迭代一次，让芯片的性能翻倍。&nbsp;</p><p>在50年前，摩尔定律是飞速发展的，但我们发现随着量子的隧穿效应（量子隧穿效应就像是电子有了一个“穿墙术”，即使前面有一堵能量墙挡着，电子有时还能神奇地穿过去。这在现实世界中是不可能的，但在微观的量子世界里却是一种常见现象。这个效应对于制造像电脑芯片里的晶体管这样的微小电子设备特别重要）发生作用，或者芯片微缩到了22纳米以下，摩尔定律我们不能说它失效，<strong>但至少它的</strong>增长曲线的斜率的确是放缓的。&nbsp;</p><p>那么，在摩尔定律逐渐失效的情况下该怎么做？<strong>虽然通用计算方面摩尔定律失效了</strong>，<strong>但是针对特定任务而设计的专用芯片，是完全有效的。</strong>比如现在我们看到的GPU、NPU，在特定领域，一些专用芯片依然能够追随摩尔定律之前的增长斜率，这就产生了第二条线。&nbsp;</p><p>摩尔定律的前提假设是，底层构建电路和芯片的时候一直采用 CMOS器件，就像用砖头盖楼或者搭积木，通过缩小晶体管尺寸来实现更高的集成度和更好的性能。而我的研究中有一部分是探索，除了基于这种传统的CMOS工艺去做领域的定制加速，还可以做什么？如果我把底层器件换掉，比如说不是用CMOS器件，而是用一种存算一体或者模拟域的计算，是不是也可以？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a4b4f97d54874844aff60b0b638ca3f9@46958_oswg34055oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这是第三条线，在摩尔定律的通用计算曲线和专用芯片性能曲线之后的一条线：新型器件与新型系统的协同设计。这一技术路线具有极高的能效潜力，起步的时间点可能稍微晚一些，但它的上升曲线是非常陡峭的。现在大家的目光都放在怎么把参数量堆上去，以实现更好的智能表现。而我们觉得，拿芯片层的摩尔定律去类比，模型层一定也会发生能力发展趋缓的问题。&nbsp;</p><p><strong>所以我们必须问自己，将模型的能力曲线映射到芯片曲线上，那第一条曲线我该怎么做？第二条曲线在哪？第三条曲线在哪儿？</strong>先看第一条曲线，这条曲线的关键是我们如何让模型更加高效，比如通过量化压缩等技术。第二条线是如果半导体电路能做特定领域的定制，模型也可以探索领域定制，比如用7B规模模型相应的算力能量，去追赶70B模型能够提供在某一个领域的能力。<strong>现在大家在说大模型落地，其实就是在说这件事。</strong></p><p>第三条线，意味着模型架构是有可能发生变化的，比如它有可能是一个更低比特的模型，将它与电路联合起来做设计，能表现出更陡峭的性能曲线。&nbsp;</p><p><strong>总体来说我们坚信scaling law，但是我认为scaling law应该有一个更全面的方式去解读。</strong>摩尔定律的发展给了我们很好的启示，除了堆参数之外，怎么打通生态，怎么让模型更高效地落地到应用，怎么把上下游更好地链接在一起，这是我们现在应该解决的问题。&nbsp;</p><p><strong>腾讯科技：</strong>摩尔定律发展了几十年，我们才去想第二曲线，现在已经到了大模型要找第二、第三曲线的时候了吗？&nbsp;</p><p><strong>戴国浩：</strong>集成电路刚刚被提出的时候，大家其实并不着急考虑它什么时候会放缓，当它真正放缓的时候，高效计算应运而生。大模型发展到今天，<strong>某些固定规模参数的模型能力提升已经开始放缓，所以怎么更高效地解决模型计算问题，就是必须要考虑的事情。</strong></p><p>虽然大模型领域的第一曲线的确还没发展完，但我们判断稍小型模型的落地应用，今年一定会有爆发。&nbsp;</p><p><strong>腾讯科技：</strong>这条路像有资源和技术优势的OpenAI，一定会继续走下去吧？&nbsp;</p><p><strong>戴国浩：</strong>它一定会沿着这条路走的。这条路的基础是你需要有更多的算力。&nbsp;</p><p><strong>腾讯科技：</strong> 现在基于这条路的差距已经拉开？&nbsp;</p><p><strong>戴国浩：</strong> 我觉得现在<strong>其实并不是算力被拉开，而是算力的有效使用被拉开。</strong>非官方数据说GPT-4在训练的时候使用了2-3万张卡，并且媒体报道它正在训练的模型，希望构建十几万卡的集群。&nbsp;</p><p>对国内来说，最大的难点是怎么把这么多的卡组合在一起，并实现高效利用。现在不只是单点的计算能力，点和点之间的连接能力十分重要。如何让整个系统的集群能力发挥到极致，这是现在不好解决的问题。&nbsp;</p><p>卡的绝对值并非最大的困难，<strong>国内这么多优秀的国产企业，不是说真的找不到这么多卡。如何把这些卡的能力集中到一起，是现在最难解决的问题</strong>。&nbsp;</p><p>英伟达（NVIDIA）在2019年收购了一家名为Mellanox Technologies的公司，后者是一家专注于高性能网络互联解决方案的供应商。收购Mellanox后，英伟达将其技术整合到了自己的产品线中，并在此基础上继续发展。其中包括NVLink，这是一种高速点对点数据传输技术，允许多个GPU或其他处理器之间进行快速直接的通信。&nbsp;</p><p>所以慢慢的，英伟达在单点的能力提升之外，把互联的能力也提升上来，集群的能力提升上来，最终生态能力也给提升上来了。但其实仔细看英伟达最新发布的B200，<strong>单点的计算能力提升，也遇到了瓶颈。所以包括英伟达在内，</strong>目前的环境中，如何把卡通过系统层面高效地连接在一起，是特别急需要解决的问题，不仅仅是包括硬件的互联，还包括软硬件互联。&nbsp;</p><p><strong>腾讯科技：</strong> 对国内来说，单点突破更难，还是多点互联更难？&nbsp;</p><p><strong>戴国浩：</strong> 都难，硬件上互联跟单点都存在差距，<strong>但是单点我觉得现在是机会。</strong>因为摩尔定律在放缓，也就意味着虽然别人领先于你，但是终点就在眼前了。<strong>虽然对手比你领先，但是他也“跑不动了”，再花一点时间，总能追上。</strong></p><p>互联的能力是需要长期积累的，同样还需要积累的是<strong>软件上的生态。</strong>我从2011年开始去写GPU代码，当时CUDA还是2.0版本，英伟达花了很大的力气给学校捐卡、捐钱、开课，让学生在本科生、研究生的学习阶段就使用CUDA，于是学生们做研究用CUDA、走上工作岗位依然用CUDA。&nbsp;</p><p>我们现在其实也有很多优秀的国产的芯片企业，但几乎没有一家说学生在上学的时候就会写他家厂商的代码。&nbsp;</p><p>所以硬件差距虽然有，但随着时间的推移，我们有机会能够追上。而软件更需格外重视，你看AMD后发追赶英伟达的生态，要多付出多少努力。&nbsp;</p><h2>算力成本——商业闭环的关键一环</h2><p><strong>腾讯科技：</strong> 我们聊到像7B规模的开源模型的能力差不多了，是不是可以基于它来做应用，探索商业闭环了？在这个过程中，算力成本还是不是最大的障碍和门槛？&nbsp;</p><p><strong>戴国浩：成本是落地时极为重要的因素。</strong>一个好的商业闭环是能够形成快速迭代的，并且把落地部署的效率和成本做到极致。&nbsp;</p><p>“生成”能够解放生产力。当年瓦特发明蒸汽机，蒸汽机就是在生成动力。到第二次工业革命，发电机生成电力。今天大模型在生成内容。但是如果要最终做到帮助社会生产力的整体进步，一定要能让终端的使用者能接受它的成本。&nbsp;</p><p>回看集成电路的发展，今天，一个小的笔记本、一个手表，就可以完成很多功能和任务，但是如果这只手表每天都要花很多的钱，大家肯定不会用了。同理，我们需要考虑怎么把大模型的成本降低，换言之，用电换token的时候要效率更高、代价更小。&nbsp;</p><p>这对技术提出两个要求。一方面是模型要做得足够好，生成的token都能用，无效的token很少。另一方面就是我的计算系统要做到足够高效，两百个token花3秒还是花5秒生成出来，成本能差出40%。&nbsp;</p><p>虽然有很多人会沿着OpenAI向更大规模模型探索这条路，但要注意的是，今年会是训练转向推理的很重要的一年，大家会特别关注推理成本，也就是如何在一个基本成熟的模型之上，把商业闭环的落地成本降低。&nbsp;</p><p><strong>腾讯科技：</strong> 从企业来讲，现在怎样计算算力成本，现在有标准了吗？是以token为单位计算成本吗？&nbsp;</p><p><strong>戴国浩：我们聊过很多企业和开发者，大家最希望看到的是直接按token算。</strong></p><p>他们调用大模型去处理任务时，确实不想关心底层是什么。就像现在大家使用苹果笔记本，并不关心它用的是苹果自己的芯片，还是英特尔的。消费者只关心办工时是能用10个小时还是用6个小时，打游戏时是能跑30帧还是能跑60帧。</p><p><strong>芯片或其他系统能够提供的附加能力，最终会体现在成本、功耗等指标上。</strong>大家用大模型的方式是token，最终需要算出的就是一段时间内能够计算多少token，要花多少钱，或者耗多少电。</p><p><strong>腾讯科技：</strong>但是按照目前大模型行业的商业模式来看，OpenAI的推理成本都不能打平，我们算过账吗？怎样才能让大模型的商业模式成本打平？</p><p><strong>戴国浩：我们做的事情就是让大家能把成本打平，甚至能盈利。无问芯穹现在做到的事情是比OpenAI的报价大概低三个数量级，最终我们希望能够做到四个数量级。</strong></p><p><strong>腾讯科技：一个量级是多少？</strong></p><p><strong>戴国浩：1个量级是10倍，打个比方，5美分1000个token，我把它变成了5美分10000个token，是一个量级。3个量级就是1000倍，4个量级就是10000倍。</strong></p><p><strong>腾讯科技：</strong>这是很大的提升，我们是怎么做到的？&nbsp;</p><p><strong>戴国浩：</strong>重点是软硬协同，大模型从上层的算法到底层芯片，是有很多堆栈的，比如有应用层、算法层、框架层、算子层等。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_74de2eae0011496095af5d351d47e85e@46958_oswg211733oswg1080oswg557_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再加上底层芯片层，每一层都有很多优化的空间。比如说在平台层可以做调度优化，算子层可以写更好的算子，芯片层可以去做专用的芯片，算法层可以去做量化压缩，应用层又可以去做高效的应用设计。市面上很多公司在做具体某一层的优化，我们的重点是打通来做每一层，我们在每一层大概都能做到10倍，最后乘在一起会是1万倍成本下降的效果。</p><p>全栈打通优化，对于团队的技能栈的深度要求会很高，需要既懂算法、又懂系统还懂硬件的团队，这件事门槛挺高。比如硬件这块，我们团队于1月初推出了全球首个基于FPGA的大模型处理器，通过大模型高效压缩的软硬件协同优化技术，把LLaMA2-7B模型的FPGA部署成本从4块卡减少到了1块卡，相比在同等工艺的英伟达 V100S GPU上，可以实现6倍的能效比提升与1.8倍的性价比提升。</p><p><strong>腾讯科技：</strong>所以目前客户主要是模型公司是吗？</p><p><strong>戴国浩：</strong>上下游都会是无问芯穹的客户，现在客户大致有几类：算力中心客户、行业应用客户、模型公司客户等。</p><h2>供需错配，算力市场的长期痛点</h2><p><strong>腾讯科技：</strong> 在云计算时代，我们就在说算力的供需错配问题。在大模型时代，这个问题是不是依然存在？&nbsp;</p><p><strong>戴国浩：这个问题依旧存在，而且更明显了。</strong>云计算兴起于约2000年左右。那个时候机器建设的成本没有现在这么高，一台纯CPU服务器，可能也就小万元，整体算下来成本并不高。&nbsp;</p><p>到了GPU时代，一张算力卡有可能就要花10万，一台整机的价格能达到200~300万。同样是浪费50%的算力，<strong>过去是亏1万</strong>，<strong>现在可能是亏100万</strong>，这个差距就非常大了。&nbsp;</p><p>另外，CPU的技术相对来说比较成熟，比如现在CPU可以做共享，一台CPU上开1000个容器，大家都能用。但GPU，如果在上层没有很好的调度和部署软件，很难做到像CPU这样的高效利用。<strong>如果能大幅提升GPU利用效率，其产生的社会经济价值会远高于过去的云计算</strong>。&nbsp;</p><p><strong>腾讯科技：</strong> 如果未来大模型是基础设施，全世界也不需要这么多大模型，是不是训练需求会下降很多？&nbsp;</p><p><strong>戴国浩：模型规模可能还是会涨，但模型的个数可能会收敛。</strong>训练的需求会一直在，但是它会更集中，我相信不需要全世界几千家公司都去训自己的模型。&nbsp;</p><p><strong>腾讯科技：</strong> 所以训练的需求增长其实是平缓的？&nbsp;</p><p><strong>戴国浩：</strong> 训练的需求等于<strong>训练模型的机构的个数乘以它的算力需求。</strong>我认为scaling law会较长期存在，机构个数一定会降，但每家的算力需求会涨。乘在一起，<strong>最终曲线可能是平缓的</strong>，不过推理需求一定是不断增长的。&nbsp;</p><p><strong>腾讯科技：</strong> 推理需求的上涨曲线会是怎样呢？&nbsp;</p><p><strong>戴国浩：短期内不会平缓，因为市场太大了。</strong></p><p><strong>腾讯科技：</strong> 你们是否能感觉到推理需求的快速增长？&nbsp;</p><p><strong>戴国浩：</strong> 我们在第一线接触客户，这个感觉是特别明显的，无论是ToB还是ToC。甚至是一些原来不做AI的厂商，都在布局大模型。&nbsp;</p><p>能源、金融或者央国企都开始有这样的需求。上一轮AI，是应用场景适应技术。技术能做物体分类，因此我们能去创造一个人脸识别的场景，比如在闸口装一个打卡机，或者在支付阶段装一个人脸识别的付款设备。但通用能力不够强，引入AI会给原业务带来很多额外成本。&nbsp;</p><p>但现在AI能力足够强，能深入到各种场景中去。人脸识别打卡是后于CV技术发展的，而写代码这类生产工作则是从很久以前就存在。这个过程类似工业革命，AI不会颠覆某个行业，而是能够颠覆人类的生产力。就好像蒸汽机的出现，颠覆的不是造机器的人，而是给整个社会带来变革。&nbsp;</p><p>我跟很多程序员朋友聊天，他们写代码基本上已经很难离开生成式AI了。<strong>上一轮在创造应用，而这一轮是应用天然都有，只要我的AI能力足够强，我就能结合进去。</strong></p><p><strong>腾讯科技：</strong> 你们的商业模式先最主要ToB？从上一轮CV的时候，行业内就会讨论，ToB不好做，链条长、个性化程度高、难有规模性，你怎么看？&nbsp;</p><p><strong>戴国浩：</strong> 确实不好做，但是有价值，有收益。国内外不太一样，国外公司的“生态位”更清晰，大家有明显的上下游关系，就把自己位置的事儿做好就行了，很少遇到上下游都做的。而国内生态位分层还不成熟，Infra基础层公司特别少，而且门槛更高，你得上下游链条都懂，既懂算法又懂硬件，对团队的能力要求特别高。&nbsp;</p><p><strong>腾讯科技：</strong> 英伟达的生态很好，国内必须要做自己的生态出来吗？&nbsp;</p><p><strong>戴国浩：</strong> 英伟达确实有一套非常好的生态，当然国内的芯片厂商也都尝试在构建生态，但是我的观点是<strong>其实大家还是应该把生态给打通。</strong></p><p>首先很多既有的数据中心用的就是英伟达的卡，我们没必要替换掉，但是还需要一些新的卡。CUDA做的非常好的一件事情就是向前兼容，原来的程序还能在新的卡上跑，可以放心大胆买新的卡。&nbsp;</p><p>我们一定可以做自己的生态，但需要把自己的生态跟CUDA的生态打通，让大家一起把这件事做得更大。我们无问芯穹在做的就是把这些芯片的生态打通连接在一起，并且把优化能力做得更深。&nbsp;</p><p>大模型的时代，CUDA这一层不需要那么宽了，原本有千万种模型，但现在大模型的结构比较统一，做宽就没有太大收益了。<strong>现在我从深度上去把优化性能给做深</strong>，或者说不体现在CUDA算子或者某个单独的一层，而是体现在整个生态的打通上。&nbsp;</p><p><strong>腾讯科技：</strong> 我看到你们也有模型，未来会做基础大模型吗？&nbsp;</p><p><strong>戴国浩：</strong> 我们有自己的模型。我们做模型主要两个目的，一是我要服务这些模型厂商，我自己必须得懂。另外就是我要服务一些应用客户，应用客户很大的需求是模型可控，所以我不能提供一个开源模型给他。我的服务必须搭上某个闭源模型，才能跟这些客户做生意。&nbsp;</p><p>出于这两个考虑，我们有做自己的模型。当然我们并不是在模型这层去跟这模型厂商竞争，就好像模型厂商做Infra，是为了更好地去服务他自己。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ALdTp-fWzC72iOgwY1TZXg" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”（ID:qqtech）</a>，作者：郭晓静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748554584062728</id>
            <title>苹果加入开源大战，官宣端侧小模型OpenELM，参数2.7亿到30亿一台M2 Mac可跑</title>
            <link>https://www.36kr.com/p/2748554584062728</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748554584062728</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 07:47:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源战, Llama 3, Phi-3, OpenELM
<br>
<br>
总结: 本文介绍了开源战的最新动态，包括Llama 3、Phi-3和苹果发布的OpenELM等四种不同小参数版本，展示了这些模型在终端设备上的应用和性能表现。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a1165c94a1bb4e7cabee2c527df1597e@46958_oswg332842oswg1069oswg413_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>开源战在这半个月愈演愈烈。先是Llama 3，又到微软Phi-3，再到今天苹果发布的OpenELM。四种不同小参数版本全部上线，我们离iPhone装进大模型不远了。</p><p>从Llama 3到Phi-3，蹭着开源热乎劲儿，苹果也来搞事情了。&nbsp;</p><p>今天，苹果团队发布了OpenELM，包含了2.7亿、4.5亿、11亿和30亿四个参数版本。&nbsp;</p><p>与微软刚刚开源的Phi-3相同，OpenELM是一款专为终端设备而设计的小模型。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_75daadd40c5c406686b21f5ff3f3f2a4@46958_oswg130703oswg1080oswg274_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/abs/2404.14619&nbsp;</p><p>论文称，OpenELM使用了「分层缩放」策略，来有效分配Transformer模型每一层参数，从而提升准确率。&nbsp;</p><p>如下这张图，一目了然。&nbsp;</p><p>在约10亿参数规模下，OpenELM与OLMo相比，准确率提高了2.36%，同时需要的预训练token减少了2倍。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_9e8b0d5cdeec45e29b8ea6c3a7944dc6@46958_oswg133900oswg1080oswg320_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>抱抱脸创始人表示，苹果加入了AI开源大战，一口气在HF中心发布了四款模型。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_41c49ce8af2c4cf6bfb741076b3c7e77@46958_oswg233969oswg1080oswg928_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>OpenELM有多强？</h2><p>OpenELM的诞生，显然瞄准了谷歌、三星、微软这类的竞争对手。&nbsp;</p><p>近几天，微软开源的Phi-3，在AI社区引起了不小的反响。&nbsp;</p><p>因为，小模型的运行成本更低，而且针对手机和笔记本电脑等设备进行了优化。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_10285bd7bce349029566e1864479ec17@46958_oswg239623oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据论文介绍，苹果这款模型不仅能在笔记本（配备英特尔i9-13900KF CPU、RTX 4090 GPU，24GB内存），还可以在M2 MacBook Pro（64GiB内存）运行。&nbsp;</p><p>而OpenELM具体性能表现如何？&nbsp;</p><p>在零样本和少样本设置中，OpenELM的结果如下图表3所示。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_259c1c9ce5c14eab862871f3b8e761d6@46958_oswg36731oswg1080oswg261_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>通过与开源的大模型比较，OpenELM的变体比12亿参数OLMo的准确率提高了1.28%（表4a）、2.36%（表4b）和 1.72%（表4c）。&nbsp;</p><p>值得注意的是，OpenELM使用了OLMo少2倍的预训练数据的情况下，达到了这一水平。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_f0bb0dba73e44a1aa15f676645a533b8@46958_oswg596250oswg1080oswg967_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再来看模型指令微调的结果。&nbsp;</p><p>如下表5所示，在不同的评估框架中，指令微调都能将OpenELM的平均准确率提高1-2%。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_3eb98c12891343b99f48d6228295f70b@46958_oswg434321oswg1080oswg932_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表6展示了参数高效微调的结果。PEFT方法可以应用于OpenELM，LoRA和DoRA在给定的CommonSense推理数据集中，提供了相似的平均准确度。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_5319712e806f49d592c5d49729ac17e0@46958_oswg229728oswg1080oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>下表7a和7b分别显示了GPU和MacBook Pro上的基准测试结果。&nbsp;</p><p>尽管OpenELM对于相似的参数数量具有更高的精度，但研究人员观察到OpenELM要比OLMo慢。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_07324af7aed94c7088ed40ffa4cc38a4@46958_oswg271385oswg940oswg1258_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然本研究的主要重点是可重复性而非推理性能，但研究人员还是进行了全面分析，以了解瓶颈所在。&nbsp;</p><p>分析结果表明，OpenELM处理时间的很大一部分，归因于研究者对RMSNorm的简单实现。&nbsp;</p><p>具体来说，简单的RMSNorm实现会导致许多单独的内核启动，每个内核处理一个小输入，而不是像LayerNorm那样启动一个融合的内核。&nbsp;</p><p>用Apex的RMSNorm替换简单的RMSNorm，结果发现OpenELM的吞吐量有了显著提高。&nbsp;</p><p>然而，与使用优化LayerNorm的模型相比，性能差距仍然很大，部分原因是：&nbsp;</p><p>（1）OpenELM有113个RMSNorm层，而OLMo只有33个LayerNorm层；&nbsp;</p><p>（2）Apex的RMSNorm没有针对小输入进行优化。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_fdd342b689f04c1faa2c4b38f6b47757@46958_oswg435052oswg1080oswg853_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>作者贡献</strong></h2><p>有趣的是，论文最后一部分还列出了每位作者，在这项研究中的具体贡献。&nbsp;</p><p>从预训练数据收集和工具、架构设计、模型训练，到评估套件和工具、HF集成、指令微调、参数高效微调，再到性能分析和MLX转换、代码审查，bug修改和维护全程都分工明确。&nbsp;</p><p>具体每人参与的内容，如下图所示。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_e5b09847fa7e496190d139a4054280de@46958_oswg94557oswg910oswg1258_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>参考资料：&nbsp;</p><p>https://arxiv.org/abs/2404.14619&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/s2ht9alLSk-7tnpV_CW_Bg" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：桃子&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748462734408448</id>
            <title>全球最大开源模型再刷爆纪录，4800亿参数MoE击败Llama 3、Mixtral</title>
            <link>https://www.36kr.com/p/2748462734408448</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748462734408448</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 07:46:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Snowflake, Arctic, MoE模型, 训练计算资源
<br>
<br>
总结: Arctic是迄今最大的开源模型，拥有128位专家和4800亿参数，采用了稀疏的设计，只用了不到一半的计算资源就达到了相同的性能指标。与其他开源模型相比，Arctic的性能更加优异，在企业智能和学术基准上都表现出色。虽然在MMLU世界知识指标上得分较低，但在企业智能方面表现出色，训练成本也大幅降低。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_8a131ce6f5c54bfdbfcb50217d817c48@46958_oswg362376oswg1071oswg408_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>最大开源模型，再次刷爆纪录！Snowflake的Arctic，以128位专家和4800亿参数，成为迄今最大的开源模型。它的特点，是又大又稀疏，因此计算资源只用了不到Llama 3 8B的一半，就达到了相同的性能指标。</p><p>就在刚刚，拥有128位专家和4800亿参数的Arctic，成功登上了迄今最大开源MoE模型的宝座。</p><p>它基于全新的Dense-MoE架构设计，由一个10B的稠密Tranformer模型和128×3.66B的MoE MLP组成，并在3.5万亿个token上进行了训练。</p><p>不仅如此，作为一个比「开源」更「开源」的模型，团队甚至把训练数据的处理方法也全给公开了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_453ac70394834d169f226da1c2168341@000000_oswg78968oswg1014oswg459_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Arctic的的两个特点，一个是大，另一个就是非常稀疏。</p><p>好处就在于，这种架构让你可以用比别人少好几倍的训练开销，就能得到性能差不多的模型。</p><p>也就是说，与其他使用类似计算预算训练的开源模型相比，Arctic的性能更加优异。</p><p>比起Llama 3 8B和Llama 2 70B，Arctic所用的训练计算资源不到它们的一半，评估指标却取得了相当的分数！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_07b9b9b50bdc494fbe73aa5dff5b2ec8@000000_oswg231080oswg1080oswg773_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图1 编码（HumanEval+和MBPP+）、SQL生成（Spider） 和指令遵循（IFEval）的企业智能平均值与训练成本的比较</p><p>具体信息如下——</p><blockquote><p>480B参数，生成期间17B处于活跃状态；</p><p>128位专家，有2位在生成期间活跃；</p><p>Instruct &amp; Base版本发布；</p><p>专注于企业任务（代码、SQL、推理、跟踪）；</p><p>在Apache 2.0下发布；</p><p>FP16精度下约为900GB内存，INT4精度下约为240GB内存</p><p>使用DeepSpeed-MoE训练。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_64e70d71743b430680ef1ee989f17d1a@46958_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>主打的就是一个性价比</h2><p>评测主要看两项指标，一个是企业智能指标，一个是学术基准。&nbsp;</p><p>企业智能指标，是对企业客户至关重要的技能，包括包括编码(HumanEval+和MBPP+)、SQL生成(Spider)和指令遵循(IFEval)。</p><p>同时，团队也采用了业界常用的评估LLM的学术基准，包括世界知识、常识推理和数学能力。</p><p>可以看到，Arctic在多项企业智能指标中，都超越了Mixtral 8×7B等开源对手。</p><p>在计算类别中，它实现了顶级性能，甚至和使用更高计算预算训练的模型，都有的一拼。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_882745099c714d07b11049fe3930abb8@000000_oswg109656oswg1080oswg715_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在学术基准上，它的表现也不差。</p><p>在测评中，团队发现了一件有意思的事。</p><p>MMLU等世界知识指标，是人们常用的学术基准测试。而随着高质量网络和STEM数据的增加，MMLU的得分会随着训练FLOPS的增加而提高。</p><p>但是，Arctic的目标之一，是在保持较小训练预算的同时优化训练效率，因此，跟其他模型相比，Arctic在MMLU上的得分较低，也实属情理之中。</p><p>由此，如果训练计算预算高于Arctic的训练，MMLU性能就将超越Arctic。</p><p>当然，MMLU世界知识的性能，并不一定和团队所关注的企业智能直接相关。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_deca815da81842bfb6d64aee215e2d71@000000_oswg104515oswg1080oswg426_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表3 Arctic与DBRX、Llama 3 8B、Llama 3 70B、Mixtral 8x7B、Mixtral 8x22B的对比</p><h2>企业级AI的训练成本，被打下来了！</h2><p>在以往，用LLM构建顶级企业AI的成本，往往高得离谱，而且需要大量资源，令人望而却步。&nbsp;</p><p>通常，花费的成本高达数千万甚至数亿美元，这一成本是惊人的。</p><p>如何解决有效训练和推理的限制？Snowflake AI团队的研究者一直在做这方面的努力，团队成员过去曾开源了ZeRO、DeepSpeed、PagedAttention/vLLM和LLM360等系统，显著降低了LLM训练和推理的成本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_93a94df5c8d64bff8161c12240b6de69@000000_oswg708622oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而今天推出的Arctic，在SQL生成、编码和遵循基准指令等企业任务上，表现非常出色。</p><p>它为具有成本效益的训练设定了新的基准，用户可以以极低的成本，就能创建满足企业需求的高质量定制模型。</p><p>Arctic也是一个真正的开放模型，在Apache 2.0许可下，提供对权重和代码的无限制访问。</p><p>从今天开始，Snowflake Arctic就可以从Hugging Face上获取了。</p><h3>计算资源仅用一半，表现却和Llama 3 8B相当</h3><p>团队发现，企业客户对AI有着一致的需求和使用场景——构建对话式SQL数据助手、代码助手和RAG聊天机器人。</p><p>为了便于评估，团队通过对编码（HumanEval+和MBPP+）、SQL生成（Spider）和指令跟随（IFEval）取平均值，将这些能力整合到「企业智能」这个单一指标中。</p><p>在开源LLM中，Arctic仅用不到200万美元（相当于不到3000个GPU周）的训练计算预算，就实现了顶级的企业智能。</p><p>更重要的是，即使与那些使用显著更高计算预算训练的模型相比，它在企业智能任务上也表现出色。</p><p>结果显示，Arctic在企业级评估指标上的表现，与Llama 3 8B和Llama 2 70B相当，甚至更优，而它所使用的训练计算资源却不到后两者的一半。</p><p>具体来说，Arctic使用的计算预算只有Llama3 70B的1/17，但在编程（HumanEval+和MBPP+）、SQL（Spider）和指令跟随（IFEval）等企业级任务上，都与其不相上下。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a0d25271d0954eb6b0c42b46b9ec9670@000000_oswg93108oswg1080oswg278_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表1 Arctic、Llama-2 70B、DBRX和Mixtral 8x22B的模型架构和训练计算量（与活跃参数和训练token的乘积成正比）</p><p>此外，Arctic的高训练效率还意味着，Snowflake客户和整个AI社区可以以更加经济实惠的方式训练定制模型。</p><h3>训练效率</h3><p>为了实现如此高的训练效率，Arctic采用了独特的Dense-MoE Hybrid transformer架构。</p><p>该架构将一个10B规模的稠密Transformer模型与一个128×3.66B规模的残差MoE MLP相结合，虽然总参数量达到480B，但通过top-2 gating的方式只选择了其中17B个参数保持活跃。</p><p>Arctic的设计和训练基于以下三个关键创新:</p><h4><strong>1. 更多但精炼的专家，以及更多的专家选择</strong></h4><p>首先，DeepSpeed团队在2021年末便证明了，MoE（Mixture of Experts）可以在不增加计算成本的情况下，显著提高LLM模型的质量。</p><p>其次，模型质量的提升主要取决于MoE模型中专家的数量、总参数量以及这些专家可以组合在一起的方式和数量。</p><p>基于此，Arctic被设计为拥有480B个参数，分布在128个细粒度专家中，并使用top-2 gating选择17B个活跃参数。相比之下，最近的MoE模型使用的专家数量就要少得多了（如表2所示）。</p><p>从直观上看，Arctic利用更大的总参数量和众多专家来扩大模型容量，同时更明智地在众多精炼的专家中进行选择，并使用适度数量的活跃参数来实现资源高效的训练和推理，最终获得顶级的智能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_d3dede3613274672b21c8974ecb15240@000000_oswg238351oswg1080oswg662_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图2 标准MoE架构 vs. Arctic</p><h4><strong>2. 架构和系统协同设计</strong></h4><p>即便是用最强大的AI硬件，想要基于普通的MoE架构训练大量专家效率依然很低。</p><p>其原因在于，专家之间存在的全通信开销非常高昂。不过，如果能将通信与计算重叠，那么就可以极大地降低这种开销。</p><p>因此，团队在Arctic架构中将一个密集的Transformer与一个残差MoE组件（图2）相结合，从而使系统能够通过通信计算重叠来消除大部分通信开销，最终实现了极佳的训练效率。</p><h4><strong>3. 面向企业的数据课程</strong></h4><p>要在代码生成和SQL等企业指标上表现出色，需要与训练通用指标的模型截然不同的数据课程。</p><p>团队在进行了数百次小规模的对比实验后发现，常识推理等通用技能可以在开始时学习，而编码、数学和SQL等更复杂的指标可以在训练的后期有效学习。</p><p>因此，Arctic采用了三阶段课程进行训练，每个阶段的数据组成不同——</p><p>第一阶段（1T Tokens）侧重于通用技能，后两个阶段（1.5T和1T Tokens）侧重于企业级技能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_7406a1b956804798888e313724a71393@000000_oswg94971oswg1080oswg402_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">表2 Arctic三阶段训练的动态数据组成</p><h3><strong>推理效率</strong></h3><p>训练效率，只是Arctic高效的其中一个方面。</p><p>如果希望低成本部署模型，推理效率也同样至关重要。</p><p>作为MoE模型规模的飞跃，Arctic使用了比其他开源自回归模型更多的专家和参数。</p><p>因此，为了有效地在Arctic上运行推理，团队做了一些系统性的创新——</p><p>a） 在较小batch的交互式推理中（比如批大小为1），MoE模型的推理延迟受到了读取所有活跃参数所需时间的瓶颈，其中，推理是受内存带宽限制的。</p><p>在这样的批大小下，Arctic（17B活跃参数）的内存读取次数比Code-Llama 70B少4倍，比 Mixtral 8x22B（44B活动参数）少2.5倍，从而实现更快的推理性能。</p><p>为此，团队跟英伟达的TensorRT-LLM和vLLM团队展开合作，为交互式推理提供了Arctic的初步实现。</p><p>通过FP8量化，团队可以将Arctic放入单个GPU节点中。</p><p>虽然仍远未完全优化，但在批大小为1时，Arctic的吞吐量超过70+token/秒，这样就实现了有效的交互式服务。</p><p>b) 当批大小的规模显著增加，例如每次前向传递要处理数千个token时，Arctic就会从内存带宽受限转变为计算受限，此时推理的瓶颈就在于每个token的活跃参数。</p><p>在这一点上，与CodeLlama 70B和Llama 3 70B相比，Arctic的计算需求减少了4倍。</p><p>为了实现计算受限的推理和与Arctic中活跃参数数量较少相对应的高吞吐量（如下图所示），需要较大的batch size。</p><p>要实现这一点，需要有足够的KV缓存内存来支持较大的batch size，同时也需要足够的内存来存储近500B的模型参数。</p><p>面对这重重挑战，最终团队还是找到了办法。</p><p>通过使用FP8权重、分割融合和连续批处理、节点内的张量并行性以及节点间的管线并行性等系统优化组合，团队在双节点推理中，实现了这一目标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_bc8953ce2b914d45b2a08166e1ab7541@000000_oswg203437oswg1080oswg773_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图3 推理期间编码（HumanEval+和MBPP+）、SQL生成（Spider）和指令跟踪 （IFEval）企业智能的平均值与活跃参数的对比</p><h2>开源代码</h2><p>新模型Arctic基础模型和指令微调模型代码全部开源，任何人可以将其用于研究、产品、原型当中。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a9e128fc766e4071a0d89ace25c4d895@000000_oswg93948oswg1080oswg324_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>项目地址：https://github.com/Snowflake-Labs/snowflake-arctic</p><p>研究人员基于LoRA的微调的pipeline和配方（recipe），并允许在单个节点上进行高效的模型微调。</p><p>现在，Snowflake正在与英伟达TensorRT-LLM和vLLM开展合作，为Arctic模型开发初始的推理实现，并且针对批大小为1的交互式使用进行了优化。</p><p>未来，他们还将与社区合作，解决真正大型MoE更大的批大小的推理复杂性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_4a743cb8cfa1460891ee909546a4cddc@000000_oswg101372oswg1080oswg317_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Cookbook：https://medium.com/snowflake/snowflake-arctic-cookbook-series-exploring-mixture-of-experts-moe-c7d6b8f14d16</p><p>另外，Arctic现使用的是4k上下文窗口进行训练，研究人员还将开发一种基于注意力下沉（attention-sinks）的滑动窗口的方法，以支持未来几周无限序列生成能力。</p><p>下一步，将会扩展到32K上下文窗口。</p><h2><strong>团队介绍</strong></h2><p>Snowflake的CEO，是Sridhar Ramaswamy，是前谷歌高级副总裁。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_07c0a70b1c0c403780e11dbf6e80e5a9@000000_oswg331143oswg1080oswg619_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在谷歌工作15年后，他成为Neeva的联合创始人，后来Neeva被Snowflake收购。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_b712f422a8934a309bb418161e5d4393@000000_oswg100229oswg489oswg692_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_495699227f2e4a3a967cd3857218fc38@000000_oswg23260oswg479oswg604_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_d3a7e4098df24c589070f4fe6a60f4f5@000000_oswg64727oswg431oswg395_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他在印度理工学院马德拉斯分校获得计算机学士学位，并在布朗大学获得计算机博士学位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_7c0e6d545b9d4b7abd284462eaa2dd48@000000_oswg50336oswg588oswg259_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AI团队的一把手Vivek Raghunathan，也是前谷歌副总裁。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_de5d1727d77f4de5a4a2f53dcbac8356@000000_oswg214414oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他曾担任微软研究员，后在谷歌从事机器学习、广告基础架构等方面工作，18年开始在谷歌担任副总裁，领导YouTube团队。</p><p>随后，他和Sridhar Ramaswamy共同创办了Neeva。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_132e8aebaf864911ace80076516a0c14@000000_oswg112140oswg1080oswg396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_1766b45dddca414a8dd71002a8c48717@000000_oswg390276oswg1080oswg1316_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Raghunathan同样也是印度理工学院的校友，不过是在孟买分校获得的学士学位。之后，他在UIUC取得了硕士和博士学位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_469cea7f03c44f81b62f9ac4c2fcdbf1@000000_oswg83143oswg639oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了发展AI，两人把DeepSpeed团队最顶尖的几个元老都挖了过来，包括Zhewei Yao和Yuxiong He。</p><p>Zhewei Yao在UC伯克利获得博士学位，研究兴趣在于计算统计、优化和机器学习。（在此之前，他2016年曾获得上交大数学学士学位。）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_af4e476aa1dd45b4b6682b0310bfcadb@000000_oswg89132oswg280oswg280_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他从2021年开始便加入了微软，在微软担任首席研究员和研发经理，致力于高效的大规模训练和推理。</p><p>目前，他是Snowflake的高级科学家和SDE II，同时也是Snowflake大规模预训练创始成员。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_85f5aa7ea92742418e92493fee36ce56@000000_oswg220717oswg1080oswg650_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Yuxiong He在微软任职13年，是DeepSpeed的创始人之一，最近加入了Snowflake。</p><p>她曾在新加坡南阳理工大学获得了计算机工程学士学位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_28eb72190ba244ad94990e8842841fd3@000000_oswg322322oswg1038oswg734_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>团队的另一位华人大牛Aurick Qiao，去年11月刚加入Snowflake。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_3824802c0b314e4ea7caba9f476cb54b@000000_oswg250697oswg449oswg449_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>CMU读博期间，他曾获得Osdi 2022的最佳论文优胜奖。此前曾在微软、Dropbox工作。</p><p>曾担任Petuum CEO，以及LMNet的联合创始人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_045971fe496744a4bd7bd0b950c45eda@000000_oswg212485oswg1080oswg895_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Hao Zhang是UCSD的Halıcıoğ数据科学研究所和计算机科学与工程系的助理教授。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_8a77a81ee718418aaf4a970084036520@000000_oswg169716oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他曾获得了CMU计算机博士学位，师从Eric Xing。在攻读博士学位期间，他休学一段时间并在ML平台初创公司Petuum工作。</p><p>Hao Zhang在2023年联合创立了LMnet.ai，这家公司于同年11月加入了Snowflake。</p><p>他此前还共同创办了非营利组织LMSYS Org，该组织训练了此前十分流行的模型Vicuna以及发起和维护目前最重要的大语言模型评测机制：Chatbot Arena。</p><p>他本人的研究兴趣是机器学习与系统的交叉领域。</p><p>参考资料：&nbsp;</p><p>https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652470278&amp;idx=2&amp;sn=d5977b1696aa558677892939199b5c4e&amp;chksm=f09bea30b49933921d3b0e5d9c579c32acd6d1f34ef426f0f7720f0b3280d1328537898e6b43&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，编辑：编辑部&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748530051414789</id>
            <title>黄仁勋亲自给OpenAI送货，全球首台DGX H200开箱了</title>
            <link>https://www.36kr.com/p/2748530051414789</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748530051414789</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 07:37:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 历史性大合照, AI芯片, 英伟达创始人, OpenAI
<br>
<br>
总结: 一张历史性大合照展示了英伟达创始人黄仁勋送来的AI芯片，旨在推进AI、计算和人类的发展，引发网友关注。同时，英伟达持续推出AI超级计算机，包括DGX-1、DGX-2和DGX A100服务器，领先AI算力水平。最新产品DGX H200具有强大的性能和内存功能，加速生成式AI和科学计算。英伟达曾拒绝过人工智能先驱Geoffrey Hinton，但现在送显卡已成惯例。 </div>
                        <hr>
                    
                    <blockquote><p>又是一张历史性大合照。</p></blockquote><p>今天，黄仁勋又来送 AI 芯片了，还是超强悍的那种。</p><p>OpenAI 联合创始人、总裁 Greg Brockman 发推，晒出了自己、OpenAI CEO 奥特曼与英伟达创始人兼 CEO 黄仁勋的合照。</p><p>他表示，老黄亲自为 OpenAI 送来了全球第一台 Nvidia DGX H200 超级计算机，此举意在双方共同推进 AI、计算和人类的发展。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_2c40da51745c4b79802a644a43922912@46958_oswg194555oswg1080oswg1704_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，网友更关注的依然是 OpenAI 联合创始人、首席科学家 Ilya Sutskever。自去年 12 月 15 日转推了 OpenAI 的一个帖子以来，他已经在 X 上「消失」了四个多月。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_0d66b18010b947839b2deb2406af0b7d@46958_oswg128251oswg1080oswg385_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有网友调侃到，Ilya 是不是在边上的箱子里呢？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_89a2c8730ded46d1ae6a45efb4db1caa@46958_oswg49073oswg1080oswg240_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有人 P 了一张 Ilya 与奥特曼搭肩的合照。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_463a49925ece4393995e0e014e9a8eab@46958_oswg655996oswg1080oswg1155_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>把最强 AI 算力赠送给业界先进研究机构，这件事英伟达已不是第一次做了。</p><p>今年 2 月，马斯克还在 X 上回忆了老黄向 OpenAI 捐赠 DGX-1 服务器的那张经典照片。作为 OpenAI 的联合创始人，彼时马斯克还没有因为「利益冲突」和开源等问题与 OpenAI 反目成仇。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_2f609a42a39b43ce82b6d6b1c7e155d4@46958_oswg648227oswg1006oswg566_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2016 年，黄仁勋亲自向 OpenAI 赠送了全球第一台 DGX-1，马斯克也在接收现场。</p><p>或许就是这个举动，催生了 ChatGPT 的到来。</p><p>DGX-1 被英伟达称作为「AI 超级计算机」，当时捐赠的版本价值 12.9 万美元，集成了 8 块 Tesla P100（Pascal 架构）GPU，整个系统的机器学习算力为 170 teraflops（FP16）。</p><p>在此之后，英伟达陆续推出了 DGX-2（Volta 架构）、DGX A100 服务器（Ampere 架构），持续引领了 AI 算力的最高水平。</p><p>今天赠送给 OpenAI 的 DGX H200，是去年 11 月在全球超算大会上推出的最新产品。英伟达在官方博客中曾表示：H200 Tensor Core GPU 具有改变游戏规则的性能和内存功能，可增强生成式 AI 和高性能计算 (HPC) 工作负载。单块 H200 的 FP16 算力是 1979 TFLOPS。</p><p>作为首款采用 HBM3e 的 GPU，H200 借助更大更快的内存可加速生成式 AI 和大型语言模型 (LLM) 的运行，同时推进 HPC 工作负载的科学计算。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_def9748008dc4fc2a7fb22ae0035b459@46958_oswg247963oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>老黄送显卡，看来正在成为英伟达的惯例。不过还有一个不得不说的故事，就是神经网络刚刚兴起的时候，英伟达曾经「拒绝」过人工智能先驱 Geoffrey Hinton。</p><p>2009 年 Hinton 的研究小组在使用英伟达的 CUDA 平台训练神经网络来识别人类语音。他对研究结果的质量感到惊讶，并于当年晚些时候的一次会议上介绍了这些结果。Hinton 联系了英伟达，「我发了一封电子邮件说，听着，我刚刚告诉一千名机器学习研究人员，他们应该去购买英伟达 GPU。你能给我免费寄来一份吗？」结果英伟达拒绝了。</p><p>尽管受到冷落，Hinton 仍然鼓励他的学生使用 CUDA，其中包括传奇学者 Alex Krizhevsky。2012 年，Krizhevsky 和他的研究伙伴 Ilya Sutskever 在预算紧张的情况下从亚马逊购买了两张 GeForce 显卡，训练视觉识别神经网络，这才有了一代经典 AlexNet。</p><p>不过在 2018 年 9 月，在一次庆祝英伟达多伦多 AI 实验室（Toronto AI Lab）成立的会上，黄仁勋送给了 Hinton 一块 TITAN V 显卡。这也算是弥补了当初拒绝 Hinton 的遗憾。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_de5c5b937506465ea5c59ff451574a89@46958_oswg825213oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>图源：https://twitter.com/PengDai_ca/status/1043496117244170240</p><p>除了交付 AI 算力，英伟达在投资领域也有新的动向。本周三据媒体报道，英伟达正式宣布有意收购 AI 基础设施管理平台 Run:ai。该交易的价值并未透露，但估计约为 7 亿美元。</p><p>Run:ai 由 Omri Geller（首席执行官）和 Ronen Dar （首席技术官）于 2018 年创立。该公司开发了一个并行算力的编排和虚拟化软件层，以满足在 GPU 和类似芯片组上运行的人工智能工作负载的独特需求。Run:ai 基于 Kubernetes 的 AI 云容器平台通过自动分配必要的计算能力（从部分 GPU 到多个 GPU，再到多个 GPU 节点），能够帮助用户有效地池化和共享 GPU。</p><p>不断扩充朋友圈，同时资助构建 GPU 算力的公司，英伟达的 AI 版图已越来越大。</p><p>参考内容：</p><p>https://twitter.com/gdb/status/1783234941842518414</p><p>https://www.bloomberg.com/news/articles/2024-04-24/nvidia-agrees-to-acquire-israeli-ai-software-provider-run-ai</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/XZqnyfQNGNeUUYwr6UGIIg" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID:almosthuman2014）</a>，作者：泽南、杜伟，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748529906482177</id>
            <title>过去一年，中国车企“上车”大模型进展如何？</title>
            <link>https://www.36kr.com/p/2748529906482177</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748529906482177</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 07:36:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能化, AI 大模型, 自动驾驶, 智能座舱
<br>
<br>
总结: 汽车行业正迎来智能化革命，AI 大模型的应用推动着自动驾驶技术的发展，智能座舱也成为重要议题。各车企纷纷加入智能化生态，利用 AI 技术优化设计流程、提高生产效率和增强用户体验。整车智能化的推动将改变汽车生产方式，实现降本增效，引领汽车行业迈向智能化的新阶段。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_313f245843314f5ab25ada9b1e3ebee1@46958_oswg126471oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“上半场电动化，下半场智能化。”继网联化、电动化、绿色化后，车企大战迎来了新的赛点：智能化。据麦肯锡估计，到 2030 年，中国的乘用车数量将增长到 3 亿多辆以上，而人工智能将对汽车领域产生最大影响，预计带来超过 3800 亿美元的经济价值。&nbsp;</p><p>随着“AI in ALL”的风迅速刮进汽车行业，不少汽车制造商如红旗、长城、东风日产、吉利等已纷纷宣布加入“文心一言”生态，这是各个车企宣示抢占新技术高地的第一声呐喊。这些车企应用 AI 大模型，既是迎接数字化时代的主动备战，也是进行差异化竞争的必然之举。</p><p>据中国汽车工业协会数据，2023 年中国商用车产销累计完成 403.7 万辆和 403.1 万辆，同比分别增长 26.8% 和 22.1%，增速超过行业整体水平。市场规模持续增长的同时，更多自主品牌汽车入局，消费者需求也正在发生深刻变化。这些变化预示着<strong>行业即将迈过打价格战的行业拐点，转向以技术和智能化为主导的新竞争阶段。</strong></p><p>AI 大模型的引入正在推动这场革命，带来了全新的竞争焦点：智能化的实施和车辆的全面数字化。车企利用 AI 技术优化设计流程、提高生产效率和增强用户体验，正是智能化下半场的关键战略。现在，随着越来越多的企业“大模型上车”，我们正在见证智能汽车制造影响整个行业的未来走向。</p><h2>大模型上车&nbsp;</h2><h3>&nbsp;智能驾驶 VS 自动驾驶&nbsp;</h3><p>大模型的崛起为自动驾驶技术研发注入了一剂强心剂。自动驾驶的核心问题是<strong>如何精准识别诸多传感器所采集的环境信息并迅速作出准确判断</strong>，而大模型具有对海量数据的分析能力、多维度分析能力、全面预测能力，用于解决自动驾驶面临的数据标注等难题是再好不过的。</p><p>2023 年 4 月，长城汽车控股的毫末智行发布了<strong>全球首个自动驾驶生成式大模型 DriveGPT 雪湖·海若</strong>，通过引入真实人驾接管数据建立 RLHF（人类反馈强化学习）技术，对自动驾驶认知决策模型进行持续优化。目前，DriveGPT 已完成 4000 万公里驾驶数据的训练，参数规模达到 1200 亿，但尚不能实现端到端自动驾驶，还处在从离散到感知模型、认知模型、控制模型聚集的阶段。</p><p>相比无人驾驶和完全自动驾驶，如上汽集团的智己汽车采用的<strong>导航辅助驾驶技术（NOA）</strong>看起来更为现实。智己汽车与全球头部智能驾驶算法企业 Momenta 合作，推出了行业首个 D.L.P.（深度学习算法）人工智能模型，将感知、融合、预测三个环节进行了模型化，并完成了深度集成。</p><p>在此基础上，今年 4 月 8 日发布的新车智己 L6 已同时使用 DDOD（对道路上动态物体的监测和识别，Data Driven Object Detection) 模型和可替代高精地图的 DDLD （对道路地表和静态元素的识别，Data Driven Landmark Detection）融合感知大模型，并且“全国都可开”的无图城市 NOA 将于今年年内开通。</p><h3>&nbsp;智能座舱&nbsp;</h3><p>尽管完全自动驾驶是许多人眼中的最终目标，但目前这一目标还需要较长时间实现。在此之前，受市场需求的影响，汽车已经在向“移动第三空间”发展，<strong>智能化技术如何增强驾驶体验成为重要议题</strong>，智能座舱由此应运而生。</p><p>例如，智己汽车于去年 6 月发布的整车智能化软件产品“全程 AI 舱”，不仅整合了软硬件技术，还在安全和舒适性上做了大量优化。</p><p>与此同时，奇瑞汽车的人工智能大模型平台“LION AI”，以及广汽集团的 AI 大模型平台，都在智能语音交互方面取得了重要进展，为用户提供更自然的对话体验。</p><p>这类技术的应用<strong>不仅局限于车内交互</strong>，像吉利就推出了<strong>车外 AI 语音交互功能</strong>，让智能汽车在可以识别来自车外发开后备箱、开空调等语音指令的同时，还学会了上车迎宾、下车欢送等。吉利的星睿 AI 大模型还创新性地推出了多项 AI 原生应用，如 AI 绘本、AI 回忆、AI 音乐律动等，增强了车辆的沉浸式体验。</p><h3>&nbsp;全栈智能&nbsp;</h3><p>在 AI 大模型的应用上，比亚迪和北汽蓝谷等公司正在进一步推动<strong>整车智能化</strong>。</p><p>比亚迪的双循环多模态 AI“璇玑”和智能化架构“璇玑”将 AI 技术应用到车辆的各个方面，覆盖超过 300 个使用场景，旨在通过打破系统间的壁垒，实现信息的即时捕捉和决策反馈。</p><p>北汽极狐于 4 月 11 日推出的全栈生态自进化技术体系“达尔文 2.0”，则强调了整车智能化、设备协同和信息共享的重要性，旨在通过技术自进化减少人工干预，提高车辆的效率和安全性。</p><p>在长城汽车 AI Lab 负责人杨继峰看来，到现在主机厂们都还在比拼有没有语音操控、DMS 和氛围灯等功能，这些都不能算是 AI 问题，而只是场景定义。<strong>只有当智能座舱向智能空间发展时才能变成一个 AI 问题。</strong>而智能空间要求在智能座舱中加入多模态感知、认知大模型和 AIGC 大模型，基于数据的支撑和算法的推理，来提升整体的 AI 能力，实现自然交互。这一概念听起来相当吸引人，但同时也相当“道阻且长”。</p><h2><strong>大模型在车辆制造中的应用&nbsp;</strong></h2><p>随着汽车行业的数字化转型，数据正在从生产中的“副产品”向“生产资料”转变，AI 大模型的引入能够打破生产制造、研发设计、财务管理、营销售后等环节之间存在的数据壁垒，帮助实现“生产资料”在全产业链自动化畅通流转。</p><p>用 AI 大模型改造车企自身业务流程，<strong>不仅是为了更好地卖车，更是为了重塑汽车生产方式、真正实现降本增效。</strong>正如中国一汽红旗品牌运营委员会副总裁门欣所说：“真正的转型是要把传统工业企业依赖职责、流程运行的内核转换成依赖数据，要高速响应用户需求，形成不断向前迭代的业务能力和开发能力。”</p><p>麦肯锡咨询公司全球管理合伙人关明宇曾指出，在过去的十年里车内软件的复杂程度大概翻了两番，但同期软件的开发效率只提高了 1—1.5 倍。<strong>缩短研发周期、降低研发门槛、提高研发效率</strong>是车企在行情快速变化的市场中保持竞争力的重要途径。</p><p>中国一汽正在尝试用大模型来达到这一目的。今年 1 月一汽与阿里云通义千问合作开发的的汽车行业的首个大模型商业智能应用 GPT-BI 落地，通过自动化报表生成和决策支持，颠覆了传统的业务流程。此外，<strong>一汽还利用大模型写设计代码</strong>，目前中国一汽已经实现了自动化设计、自动化绘图、自动化代码生成，基于模型的系统工程将持续迭代。据门欣表示，有了大模型后，至少一半的代码可以交由大模型来写。</p><p>吉利的星睿 AI 大模型是<strong>将自研的 NLP 语言处理模型与 NPDS 研发体系及其全链路场景数据库深度融合</strong>的一个例子。其支持研发人员在造型设计、机械设计和质量控制等方面的应用，同时也用于自动驾驶的虚拟训练。通过这种方式，吉利能够缩短验证周期约 30%，并节约近 50% 的开发成本。</p><h2>底层技术仍有待升级&nbsp;</h2><p>尽管大模型的应用提供了诸多好处，车企仍面临一些技术和基础设施挑战。例如，<strong>车载算力的限制</strong>使得很多 AI 处理必须依赖于云端服务器。为了克服这一点，一些公司建立了智能计算中心，如毫末智行与火山引擎合作建立的自动驾驶智算中心，以及长安汽车与百度共建的智算中心，提供了必要的后端算力支持。</p><p>此外，对大模型在汽车行业的应用而言，<strong>车企拥有的海量数据资源有其双面性</strong>。一方面自动驾驶涉及到红外线传感器、激光雷达、毫米波雷达、摄像头、GPS 等诸多硬件，这些硬件在行驶过程中产生的海量数据为大模型算法研发提供了一定基础；另一方面，如何收集、清洗、训练来源于大量不同场景、不同维度的数据，本身就是一大难题。</p><p>最后，<strong>大模型应用究竟是降本还是增本、这么多车企投入大量研发经费究竟有多大效果，目前还很难说明白</strong>。单论智驾芯片的成本，这场 AI 竞争就不是所有玩家都玩得起的。据统计，虽然过去三年中国汽车芯片的自给率从 5% 迅速提高到了 10%，像地平线、黑芝麻智能这样的供应商正在迅速崛起，但整体来看车载芯片仍被外资品牌垄断。<strong>如果智能汽车的各个“器官”都要从不同的供应商处采购，不仅难以实现各系统联动融合，更难降低研发生产成本、真正实现大模型量产上车。</strong>从这个角度而言，比亚迪坚持全栈自研“整车智能”的战略似乎不无道理。</p><p>无论是被卷入还是主动进入，这波 AI 浪潮冲击下的行业洗牌都已在所难免。是机遇是挑战，都有待车企自己去蹚一趟。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/oZuxmlEJ1vT0hQ5VfQb9ow" rel="noopener noreferrer nofollow" target="_blank">“AI前线”（ID:ai-front）</a>，作者：何逸灿，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748417183415302</id>
            <title>业绩飘红，股价大跌，给扎克伯格整无语了</title>
            <link>https://www.36kr.com/p/2748417183415302</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748417183415302</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 07:32:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 投资圣经, 散户社交平台, 财报, 股价
<br>
<br>
总结: Meta发布了2024财年第一季度财报，业绩表现强劲，营收和盈利均超预期。然而，股价却应声下跌，导致投资圣经被扔进垃圾桶，散户社交平台发疯。与特斯拉相比，Meta的未来展望引发市场关注，支出增加成为焦点。 </div>
                        <hr>
                    
                    <p>是什么，让华尔街市场策略师把“投资圣 经”扔进垃圾桶？是什么，让散户社交平台官方在线发疯，连发十几条X（推特）信息？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_242dc0b1f8294c6a82ec902d6fe4e3d9@000000_oswg292724oswg432oswg729_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>是Meta，它带着2024财年第一季度财报来了，几个小时内“惊艳”世人两回：第一回，全线飘红的业绩，增长强劲；第二回，应声下跌的股价，跌幅惊人。</strong></p><p>Meta的业绩表现没什么可挑剔的。</p><p>2024财年第一季度，Meta营收和盈利均超预期。其中营收364.6亿美元，同比增长27%，已经是连续五个月增长加速，且是三年来最大的营收增幅。净利润也大幅增长，同比增长117%至123.7亿美元，运营利润率也在增长。</p><p>就连负责开发元宇宙等虚拟现实软硬件技术的Reality Labs的运营亏损也有了一点好转迹象，虽然还是亏了38.5亿美元，但比市场预期的43.1亿美元少多了。部门销售额也同比增长了30%，达到4.4亿美元。</p><p>前不久，Meta才刚刚发布了新一代开源大模型Llama 3，博得满堂喝彩；紧接着又宣布将其头显设备Quest的操作系统向第三方硬件制造商开放，势要掌掴苹果，脚踢谷歌。在财报发布之前，今年Meta的股价已经累计上涨39%，过去12个月上涨超过130%，大幅跑赢标普大盘24%的涨幅。</p><p>财报发布前在人工智能和XR领域的接连大动作，财报又如此漂亮，人们有理由相信Meta的股价将再次跃升——上一次财报发布后，Meta的股价可是盘后大涨了14%。</p><p>然而，戏剧化的一幕上演了。<strong>Meta股价收盘跌0.53%，盘后股价快速跳水，跌幅一度超过15%。</strong></p><p>就连马克·扎克伯格（Mark Zuckerberg）在做财报电话会议的过程中，股价都还在跌。投资散户社交平台Stocktwits的官方账号在X上在线发疯：股价跌幅已经19%了，小扎快别说了！在Meta发布财报后，这个百万粉丝的账号已经连发十几条信息，冷静不了一点儿。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_119a9b236ecc46f8b13a5109cb48e7b5@000000_oswg139638oswg317oswg429_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更尴尬的是，就在Meta之前，特斯拉也发了财报，与其情况完全相反：业绩不怎么样（收入同比下降9%，净利润同比下降55%，毛利率继续下滑），股价却盘后大涨13%，一天暴涨600亿美元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_eda1504c53a843cf93b2b583958417e7@000000_oswg443018oswg896oswg1084_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>金融网站NorthmanTrader创始人、技术分析师Sven Henrich看到特斯拉和Meta的财报和股价也绷不住了，发了张照片，要把被称为“投资圣 经”的著作《聪明的投资者》扔进垃圾桶，引得上万人点赞。</p><p>若非要从反常中说出个究竟，问题可能出在未来展望上。</p><p>马斯克和扎克伯格的最大区别在于，马斯克又画了饼，承诺加速推出新车型，甚至重提之前被传已经取消的低价特斯拉。</p><p>而扎克伯格却在预警“烧钱”，不仅上调了2024年全年的资本支出，还预计明年资本支出进一步增加。没办法，AI竞争加剧，Meta全力以赴，总归是有成本的。</p><p>元宇宙烧几百亿美元却处境尴尬，有此“珠玉在前”，市场对Meta的支出有点敏感倒也情有可原。</p><h2>A</h2><p>Meta本财季的业绩是真的漂亮。</p><p>2024财年第一季度，Meta总营收364.55亿美元，较上年同期增长27%。增长引擎自然还是广告，而且广告业务在营收中的比例进一步提高至98%，广告营收356.35亿美元，较上年同期增长27%。</p><p>盈利指标中，每股收益4.71美元，去年同期只有2.20美元。Meta该季度运营利润138.2亿美元，同比增长138.2亿美元，运营利润率38%，比去年同期增加了13个百分点。净利润同比暴增117%，达到123.7亿美元。</p><p>此外，2024年3月，Meta应用家族日活跃人数（DAP）平均值为32.4亿人，同比增长7%。应用家族上的广告展示量同比增长20%，每条广告的平均价格同比增长6%。</p><p>Meta不仅赚钱更多了，而且赚钱更有效率了。</p><p>唯一的那根刺是支出。Meta在该财季的总成本和支出增长6%，达到226.37亿美元。要知道，经过大力裁员的Meta在人员上已经精简不少，截至2024年3月31日，Meta员工人数69329人，同比下降了10%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_0a785350476444ca883920a1fdd826cd@000000_oswg31426oswg601oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在展望中，Meta调高了2024财年总支出和资本支出。其中总支出从940亿美元到990亿美元，上调至960亿美元至990亿美元；财年资本支出从300亿美元到370亿美元，上调至350亿美元到400亿美元。</p><p>财报电话会议召开时，Meta股价已经跳水，扎克伯格发言都在围绕支出增加的必要性上，关键词“人工智能”。</p><p>“自上次财报以来，我们对人工智能更加乐观和雄心勃勃；公司在Llama 3和Meta AI方面的进展鼓舞确保我们进行投资以保持领先地位。”</p><p>这种对人工智能投入的加大，在扎克伯格的预估里要持续几年。</p><p>“我们在产品策略的这个阶段，历史上股价波动较大，我们正在投资于扩展一项新产品，但尚未实现盈利。构建领先的人工智能也将是一个比我们添加到应用程序中的其他体验更为庞大的任务，这可能需要几年时间。”</p><p>扎克伯格这一表态，Meta股价的盘后跌幅一度扩大至近20%。</p><p>更有意思的是，对元宇宙，扎克伯格也仍有执念，表态Meta将继续投资于他的长期目标，建立一个充满化身的虚拟世界。</p><h2>B</h2><p>其实在财报之前，Meta已经做了铺垫，用行动书写新故事。</p><p><strong>第一个动作，是发布Llama 3。</strong></p><p>Llama是由Meta发布的一个开源项目，允许商用，备受关注。此前已经发布了Llama和Llama2。4月19日，Meta放出Llama 3，其中包括80亿参数的Llama 3 8B和700亿参数的Llama 3 70B。扎克伯格表示，最小的Llama 3基本上和最大的Llama 2一样强大。</p><p>除此之外，Llama 3还以Meta AI的形式直接与C端用户见面，扎克伯格亲自上阵，在自己的社交账号里安利它。在网页及Facebook、Instagram等应用中，用户可以免费使用Meta AI，与Meta AI对话，利用其查询信息、生成图像、检索应用内容等。</p><p><strong>第二个动作，是开放头显操作系统。</strong></p><p>4月24日，Meta宣布将自家头显设备Quest的操作系统向第三方硬件制造商开放，并重命名为MetaHorizonOS。Meta透露，已经有包括华硕、联想和微软等一众企业与之合作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_2ca500b8f4b545ccb11e208382ad86b4@000000_oswg274026oswg1029oswg616_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据Counterpoint，Meta在2023年第四季度XR（AR与VR）设备市场中再度夺回统治。此前由于索尼等竞争对手的强势崛起，Meta在XR设备市场中份额一度从2022年第四季度的83%跌至2023年第三季度的46%，2023年第四季度Meta市场份额再度跃升至72%。</p><p>苹果入场，谷歌虎视眈眈，都在给Meta施加压力。苹果推出的Vision Pro已经于去年发售，谷歌则正在筹备开发适用于XR设备的安卓平台。Meta此举，被认为是要做XR界的谷歌，以操作系统统治这一领域。</p><p>不管是在人工智能还是XR领域，Meta都试图成为规则的制定者。</p><p><strong>Meta现阶段最不需要的，就是在人工智能战场厮杀之时，让外界将其与元宇宙之殇联系起来。</strong></p><p>尽管Meta占据了头显设备的大部分市场份额，但在元宇宙愿景上的巨大投入和与之不匹配的亏损是个大问题。就算是本次业绩报告中，Reality Labs的亏损虽同比缩窄3.7%，却依然高达38.4亿美元。自公布细分财报以来，该部门的亏损额已经达到约420亿美元。</p><p>在2022年10月底，Meta公布2022财年第三季度财报。彼时此番人工智能风口尚未开启，ChatGPT还未发布。Meta还在主攻元宇宙，那个财季营收下降4%，净利润大跌52%，股价暴跌24%，创6年新低。那样的痛，投资者恐怕难忘。</p><p>马斯克的粉丝在X上感慨：“应该让马斯克帮小扎开电话会议的。”和马斯克画饼促特斯拉股价大涨相比，扎克伯格的“讲故事”能力大概有待加强。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI2NjU1MTcwMA==&amp;mid=2247532077&amp;idx=2&amp;sn=a79d6256bbcea29755933980cf912192&amp;chksm=eb9ba0237bd2d4c7f452a04a76e3e2ec3730e2b5dfb89e510651b344491119e6204ff1b6347f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“字母榜”（ID：wujicaijing）</a>，作者：毕安娣，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748379195292677</id>
            <title>AI如潮水，逐浪，还是裸泳？</title>
            <link>https://www.36kr.com/p/2748379195292677</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748379195292677</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 07:24:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 概念股, 研发投入, 商业化
<br>
<br>
总结: 过去一年，AI如潮水，引领科技波涛奔涌的方向。市场中大放异彩的AI概念股，2023年收获怎样的成绩单？部分公司研发投入巨大，但盈利压力不小。同时，一些公司已经开始探索如何更好地商业化大模型。上游公司在AI浪潮中已经开始收获果实，而一些公司却在经营中暴露问题。 </div>
                        <hr>
                    
                    <p>过去一年，AI如潮水，引领科技波涛奔涌的方向。</p><p>市场中大放异彩的AI概念股，2023年收获怎样的成绩单？“百模大战”中，谁占据了现阶段的领先优势？大张旗鼓的投入，是“徒有其表”还是名副其实？</p><p>截至4月24日晚间，大部分AI公司2023年成绩单已“放榜”。从业绩来看，一些下游公司仍未能盈利，处在“烧钱”阶段，但也有公司显示出积极信号。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_f1c45e196ff84eabadcb64e8894327f3@000000_oswg6354oswg501oswg144_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">部分大模型龙头公司2023年主要财务指标</p><p>产业链另一端，下游公司大手笔投入基础设施，为上游公司带来机会。部分专注于AI产业价值链上游的公司已“乘得东风”，业绩亮眼。</p><p>潮水涌动，泥沙同样翻滚。</p><p>部分在2023年大红大紫的AI概念股，交出的成绩单却难以令市场满意，甚至暴露了经营中的问题。</p><h2>“烧钱”研发</h2><p>“百模大战”是国内AI行业2023年的真实写照。百舸争流中，上市公司无疑是一支重要力量。</p><p>记者梳理云从科技、三六零等公司业绩发现，大模型依然处于“烧钱”投入阶段。</p><p>例如，云从科技2023年实现营收6.28亿元，同比增长19.33%；实现归母净利润-6.43亿元。</p><p>与2022年相比，云从科技2023年的亏损有所收窄。云从科技解释称，B端客户对于数智化升级的需求显著增强，新签订单合同金额实现了强劲增长。同时，得益于人机协同操作系统（CWOS）相关软件销售业绩的显著跃升，公司整体毛利率较上一财年实现了稳步提高。</p><p>在年报中，不少公司都提到了高研发投入带来的压力。</p><p>科大讯飞2023年研发投入为38.37亿元，同比增长14.36%，占营收的比例为19.53%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_87f75111c02b48429270814c99dde068@000000_oswg8323oswg831oswg172_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>云从科技2023年研发费用为4.9亿元，研发费用率为78.1%。意味着公司拿出超过一半的营收投入研发，盈利压力不言而喻。</p><p>昆仑万维2023年的研发投入为10亿元，同比增长36%。对此，公司解释称，是由于AIGC业务相应的人工成本、技术服务费及服务器折摊费增加导致。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_0650f0df0970426496b4c76ed297a818@000000_oswg10497oswg1004oswg483_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>三六零2023年归母净利润为-4.92亿元，同期，公司研发费用为31.04亿元，占营业收入的34.28%。</p><h2>希望初现</h2><p>如何将大模型更好地商业化，是全球科技巨头亟待解决的问题。从不少AI公司披露的年报来看，已有公司摸到了门槛。</p><p>例如，商汤披露，生成式AI业务2023年实现收入11.84亿元，同比大幅增长200%，占总收入的比重也从10.4%跃升至34.8%。商汤预计，2024年生成式AI业务占公司收入比重将增至50%左右。</p><p>商汤集团董事会执行主席兼首席执行官徐立表示：“商汤生成式AI业务的增长，得益于各行各业对大模型的训练和推理的广泛需求，这预示着中国硬科技投资的新周期正式开启。”</p><p>昆仑万维在年报中披露，目前公司旗下AGI与AIGC业务蓬勃发展，AI搜索、AI音乐、AI视频、AI社交、AI游戏等各垂类应用有序落地，为公司开启第二增长曲线。</p><p>三六零则透露，2023年，公司将“360智脑4.0”大模型能力接入360全系互联网产品，陆续推出增值AI服务，将原来以广告主付费为主的收入模式向增值服务收入转移，优化收入结构。</p><h2>上游“吃饱”</h2><p>下游探索商业模式之时，AI产业链上游公司已经开始收获果实。例如，工业富联、中际旭创等公司的业绩已经明显受益于AI浪潮。&nbsp;</p><p>工业富联2023年实现营收4763.4亿元；实现归母净利润210.4亿元，同比增长4.8%；实现扣非归母净利润202.1亿元，同比增长9.8%，均创下历史新高。</p><p>其中，工业富联的云计算板块2023年收入为1943.1亿元，占总营收比重超过四成。其中，云服务商业务持续提升，占云计算收入比重快速提升至近五成。备受业界关注的AI服务器业务占云计算收入比重也提高至三成。</p><p>工业富联表示，公司将继续坚持以AI技术为发展核心，以AI实现智能制造，以技术驱动AI产品，保持技术领先地位，实现可持续的高质量发展。</p><p>中际旭创2023年营业收入为107.2亿元，同比增长11.2%；归母净利润为21.7亿元，同比增长77.6%。</p><p>“报告期内，得益于800G/400G等高端产品出货比重的逐渐增加、产品结构不断优化以及持续的降本增效，公司产品毛利率、净利润率进一步得到提升。”中际旭创表示。</p><p>华泰证券认为，AI有望开启光模块产业的新一轮成长周期，长期为产业带来积极变化。华鑫证券也表示，在AI浪潮加速技术产品迭代的背景下，算力需求激增并对带宽提出更高要求，带来更多市场机会。</p><h2>谁在“裸泳”</h2><p>有公司抓住机遇，也有公司的表现不甚理想。</p><p>搭上了英伟达的“快车”，让由主营材料印刷行业的鸿博股份迅速成为市场关注的“算力黑马”，8个月股价上涨约600%，市值一度超过170亿元。</p><p>可大牛股并未给投资者带来好业绩。临近年报发布，公司突然宣布业绩“变脸”。</p><p>今年1月，鸿博股份发布业绩预告，预计2023年净利润为3740万元至5610万元，同比扭亏为盈，增长幅度为149.82%至174.73%。</p><p>到了4月，鸿博股份却发布业绩预告修正公告，修正后净利润为-5000万元至-5800万元，同比减亏22.74%至33.4%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_0c42592df8cd4618974d2eaa4d4fdce8@000000_oswg46038oswg570oswg231_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随后，鸿博股份收到福建证监局警示函，深交所也对其下发关注函。深交所认为，业绩预告修正公告较原业绩预告存在重大差异且盈亏性质发生变化，违反了深交所相关规定，后续将对公司及相关当事人启动纪律处分程序。</p><p>与鸿博股份不同，寒武纪亏损金额减少的原因是研发投入等缩减，这也令市场对其增长潜力产生担忧。</p><p>寒武纪2023年归母净利润约为-8.36亿元，较上年同期亏损金额有所减少。</p><p>对于背后的原因，公司解释称，管理费用、研发费用、资产减值损失较上年同期减少。</p><p>其中，公司根据业务规划，进一步提升研发效率、优化资源配置，2023年职工薪酬等支出较上年同期减少，报告期研发费用较上年同期有所减少。</p><p>在各家都在加码研发的时期，寒武纪却降低了研发投入，令市场不解。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA5MDEzNjQwMA==&amp;mid=2656064863&amp;idx=2&amp;sn=6d16246bad8d72ae961c66ccdad43a56&amp;chksm=8ab80c31036d50729c236f91ca61fd0c57284707873f077d9dcda673edb321dbf95845396be4&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“中国基金报”（ID：chinafundnews）</a>，作者：赵心怡 米洛，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748334151389824</id>
            <title>图灵奖得主杨立昆：大语言模型是通往AGI的一条歧路</title>
            <link>https://www.36kr.com/p/2748334151389824</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748334151389824</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 07:21:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta首席科学家, 图灵奖得主, 大型语言模型, 世界模型
<br>
<br>
总结: 杨立昆在与Nick Dirks的谈话中坚持认为大型语言模型并不具备理解、记忆、推理、规划等智能特征，认为它们是通往AGI的一条歧路。他提出了“世界模型”概念，主张让系统通过观察和感知学习世界运作方式，以实现更深层次的智能发展。同时，他也指出语言并非人类知识的基础，大部分知识与语言无关，强调大型语言模型只是操纵语言而无法真正理解现实世界，从而呈现出“莫拉维克悖论”的现象。 </div>
                        <hr>
                    
                    <p>3月14日，Meta首席科学家、图灵奖得主杨立昆 （Yann LeCun） 与纽约科学院院长兼首席执行官 Nick Dirks 进行了炉边谈话。早在2023年6月，杨立昆就曾在一场与Sam Altman同时出席的活动中，公开表示5年内GPT就将被抛弃，坚定不移地对大型语言模型发展泼冷水。</p><p>在这次谈话中他依旧坚持这样的立场。杨立昆通过北极点漫步的例子，表示语言在人类思维中的作用没有大家想象中的那么至关重要。而基于语言文本开发的大型语言模型不仅不能理解语言背后的底层现实，甚至也无法理解语言本身。它们只是大规模训练数据的堆积以及借助概率及计算对下一个单词的预测，训练的子单元大小平均仅为3/4个单词。大型语言模型也完全不具备理解、记忆、推理、规划这四个智能的本质特征，是通往AGI的一条歧路。</p><p>杨立昆也在这次谈话中再次谈及了自己早先提出的“世界模型”，即让系统像人类婴儿一样通过观察及其他感官输入来学习世界运作方式。通过一万六千小时的视觉暴露，一个四岁孩子接收到的信息量达到了 10 的 15 次方字节，是目前已公开的最大规模大语言模型训练量的 50 倍以上。通过自监督学习非文本信息，让机器学会预测将要发生的事情或行动的影响，尽管这还存在很大难度。</p><p>作为一贯的AI发展乐观派，杨立昆认为很多关于AI发展风险的话语都是危言耸听，如果过度监管AI反而有可能造成更大风险。面对 Nick Dirks 对AI所造成的虚假信息等的质疑，杨立昆也以自己在Meta的工作经历为例，指出自监督学习的人工智能训练方式以及加上用于大型语言模型等系统的transformer架构，使得Facebook上被智能删除的仇恨言论占比从20%左右提升至96%，取得了审查效率上的巨大进步。这些技术也在其他监管治理领域发挥着重大作用。他倡导以审慎但开放的态度拥抱这项革命性技术。</p><p>以下为本次谈话内容目录：</p><ul><li>01 大语言模型是通往AGI的一条歧路</li><li>02 解铃还需系铃人，AI正是对抗技术风险的良策</li></ul><h2>/ 01 / 大语言模型是通往AGI的一条歧路</h2><p>Nick Dirks：大型语言模型（LLMs）引人入胜的原因之一在于它们以一种非凡的方式使用语言，并能在几秒钟内展示出机器原本难以企及的能力。几年前读过一本小说，里面实际上预言了 GPT-3 和 GPT-4 的出现。书中描述了一个位于伊利诺伊大学厄巴纳-香槟分校实验室地下室的庞大计算机，它被用来学习所有英语文学经典著作，以便进行对话并获得智能。当然，小说情节发展到最后，这个机器崩溃了，原来这只是一个骗局和一个精心策划的笑话。尽管这只是想象，但现在GPT不再是虚构，人们可以下载它并获得令人惊叹的答案。这种能力如此强大，部分原因是由于它使用语言的形式，这在我们某种程度上被认为是使我们成为人类的特质之一。它不仅关系到自我意识等方面的自我认知，还关系到我们能够发展对他人的意识，并进而创造社会组织，而这一切都由语言来实现。</p><p>然而，您对语言一直持怀疑态度，认为它既不是学习的基础，也不能最终证明人工智能的强大力量。<strong>我想请您更多地谈谈语言与大型语言模型的关系，以及您在这个阶段思考最多的、关于推进人工智能发展的事情。</strong></p><p>Yann LeCun：语言对计算机来说很容易处理。它很简单，因为它是离散的，只有有限数量的单词。实际上，这些大型语言模型 （LLMs） 甚至不使用单词，而是使用称为“令牌” （token） 的更小的单位。一个子单元平均大约是 3/4 个单词。</p><p>你可能会认为它们很聪明，因为它们可以操纵语言，并且使用大量数据进行训练，对吧？如今的典型大型语言模型会使用 10 万亿个token进行训练。这基本上涵盖了互联网上所有公开的文本信息。我们任何一个人每天阅读 12 个小时，大约需要 10 万年才能读完它。你可能认为这些系统可以消化如此海量的信息，显然它们比我们聪明得多。从某些方面来说，它们确实如此。</p><p>不过，多年来，我一直都在阐述以下这个想法，包括几年前在纽约州立大学奥尔巴尼分校举办的机器学习研讨会上。这些语言模型采取监督学习的训练方式，这种训练方式很简单，它并不针对任何特定任务。通过这种方式，模型基本上被训练用来填空。你取一段文本，删除一些单词，然后系统会通过内部处理过程来预测缺失的单词。<strong>在这个过程中，系统会构建一个内部语言表征，其中包含语言的所有方面，包括语法、句法以及语言本身，但它们并不理解语言和语义。当它们训练了如此多的数据后，看起来它们最终似乎具备了一些理解底层现实的能力。但遗憾的是，这种理解非常肤浅。</strong></p><p><strong>我们有一种错觉，认为人类知识是基于语言的，但事实上，人类知识的大部分都与语言无关。它与我们对物理世界和彼此的体验有关，语言只是建立在其之上。因此，仅靠语言构建一个智能系统就像建造没有地基的房屋屋顶一样。</strong>这正是为什么这些大型语言模型容易产生幻觉。而且它们实际上无法推理，也无法真正计划。它们基本上只是逐个单词地输出，而不会事先考虑要说什么。它们用于生成一个单词的计算量总是相同的。因此，无论你问的是简单问题还是困难问题，它们花费的计算量都是完全一样的。事实上，花费的计算量取决于答案的长度，而不是问题的复杂性，这毫无意义。</p><p>因此，<strong>这些系统并不理解现实世界，也不理解物理世界，没有持久的记忆。它们无法真正记住东西。它们唯一的记忆就是正在查看的文本窗口。它们无法推理，也肯定无法规划，至少无法像人类和许多动物那样规划。这是智能的四个本质特征，而它们都做不到。</strong>所以这解释了为什么我们拥有可以通过考试的系统。实际上，通过我们的考试很容易，因为它主要是检索信息。你需要动一点脑子，但肯定是以检索为主，其中有很多事实性的内容。而这些系统在这方面确实做得很好。因此它们可以通过我们的考试，还可以通过其他一些基本上不需要太多思考的考试。所以，你知道，基本上就是靠死记硬背，但这跟自动驾驶汽车有什么关系呢？我们根本不需要会说话的汽车。我们也没有家用机器人。家用机器人要做的事情，比如清理餐桌、整理洗碗机，依靠这些模型根本无法做到。</p><p>因此，我们拥有可以操纵语言的系统。它们不理解现实，也无法真正处理现实世界。这再次印证了人工智能先驱汉斯·莫拉维克 （Hans Moravec） 提出的一個著名观点，即“莫拉维克悖论”。机器可以在国际象棋比赛、解方程、符号计算积分等方面取得超人类的表现，与此同时，很少有人类能在国际象棋、围棋等所有任务中如此轻易地击败我们。然而，要让机器人操纵物体、组装东西依旧非常困难，除非是预先安排好的。要让机器达到人类智能水平，我们还有很多工作要做。</p><p>Nick Dirks：基于我曾经的人类学学习背景，我对你刚才的观点感到有些惊讶。因为人类学家们会认为，世界以及我们对世界的理解都建立在语言、语言系统、语法、神话等等之上。</p><p>然而，你却认为语言只是一种非常片面的理解世界的方式，远远称不上足够。那么，你认为人工智能要如何发展才能获得更充分的理解世界的能力呢？你提到过人工智能无法记忆，但可以检索。这显然是既相似又不同的范畴。同理，推理和计划也是如此。你认为需要什么条件才能让人工智能具备这些智能特质？</p><p>Yann LeCun：<strong>总的来说，我们需要像人类婴儿和动物一样，能够通过传感器输入学习世界如何运作的系统。</strong>人们常说语言是思维的载体，但黑猩猩呢？它们几乎和我们一样聪明，只是因为不再像我们一样社交，不需要太多交流，所以没有语言。</p><p><strong>那么，如何让系统理解世界如何运作呢？主要通过观察，辅以少量与世界的互动。</strong>我之前提到过，人工智能系统通常使用包含10的18次方个训练单元进行训练，相当于阅读 10 万年的文本量。然而，心理学家指出，一个四岁孩子总共清醒的时间只有一万六千个小时。如果我们计算一下视觉信息输入量，视神经的传输速率大约是每秒 20 兆字节。相比之下，我们通过语言理解或阅读时，信息输入速率只有大约每秒 12 字节，要少得多。因此，通过一万六千小时的视觉暴露，一个四岁孩子接收到的信息量达到了 10 的 15 次方字节，是目前已公开的最大规模大语言模型训练量的 50 倍以上。这意味着我们从现实世界获得的感官信息量要大得多。</p><p>当然，这些信息有很多冗余，我们所看到的东西具有很大结构性，比语言要少得多。但实际上，这反而是个优势。我之前提到的算法类型，也就是自我监督学习过程，实际上可以利用冗余来构建更好的输入表征。因此，<strong>未来几年的一大挑战是，能否将类似的自我监督学习思想应用于非文本领域，比如视频。</strong></p><p>文本之所以简单，是因为我可以给你一段文本，然后问下一个单词是什么。虽然有三万个可能的单元或十万个可能的单词，你无法确切地说出下一个单词是什么，但你可以大致判断哪些单词是可能的，哪些是不可能的。这正是大型语言模型所做的，它们会生成词典中所有可能单词的概率分布。然后，编辑并生成文本的方式是，从模型赋予高概率的单词中选择一个。因此，每次运行都可能得到不同的答案，因为它会随机选择不同的选项。</p><p>现在尝试使用相同的思想来训练系统理解视频。比如，取一段视频，在某个点暂停，然后训练系统预测接下来会发生什么。人们已经尝试了 10 年，但效果并不好。虽然可以通过一些技巧获得更好的预测，但这并不意味着系统真正理解了视频背后的世界。原因在于，视频中可能发生的事情有很多种，而且都非常合理。系统无法表示所有可能发生的事情，也无法对所有可能的视频生成概率分布。我们不知道如何做到这一点，这是一个棘手的数学和计算问题。这就是语言简单的原因。语言是对心理模型或现实的一种非常简化的表示。而且，我们并没有像想象的那样多地使用它进行推理。</p><p>现在我给你一个小问题，让你分析一下自己的思维过程。这是一个复杂的问题，并不是每个人都能解决。想象一下你站在北极点，选择一个方向步行 1 公里。然后向左转 90 度，再一直走，直到接近你开始的点，但不是北极点，而是你转弯的那个点。那么问题是，你将要走多远？是2π公里，还是小于2π公里，还是大于2π公里？或者你根本无法回到起点？你不必一定要解决这个问题，但只要分析一下你尝试解决这个问题时的思维机制就可以了。它会用到语言吗？你是否用语言思考这个问题？它是物理的吗？</p><p><strong>解决这个问题并不是通过引用定理，而是通过构建一个心理图像。我们所做的大部分事情，尤其是建造东西的时候，都是这样的。这与语言无关，这也是我们不知道如何用计算机做到的。</strong></p><p>Nick Dirks：这让我感到困惑。作为一名教授，我所做的就是使用语言。我从来没有设置过任何数学难题。所以，也许我对我们思考智能的方式有不同的看法。</p><p>但这是否是您对所有关于通用人工智能 （AGI） 即将到来的预测持怀疑态度的部分原因？事实上我们已经取得了巨大的进步。现在，无论是您还是Sam Altman，都认为它即将到来。这是原因吗？还是还有其他原因？</p><p>Yann LeCun：主要原因在于，<strong>要构建真正智能的系统，它们就需要理解物理世界，能够推理、计划等等。还需要记住和提取信息。因此，能够做到这些的未来系统架构将会与当前的大型语言模型完全不同。这并不是说现有的许多语言模型没有用，它们非常有用，令人印象深刻。未来将会有一个围绕它们建立的完整产业。但是，作为通向人类智能水平的道路，它们基本上还处于起步阶段。</strong></p><p>因此，<strong>我们必须致力于让学习系统像 3 个月大的婴儿一样通过观察来学习世界如何运作。</strong>婴儿几乎无法以任何方式影响世界，但却可以通过观察学习到大量关于世界结构化的背景知识。几个月后，他们就可以开始操作物体并做一些事情了。他们开始构建世界的因果模型，例如：“这是世界的初始状态。这是世界在时间点 T1 的状态。这是我采取的行动。这是世界在时间点 T2 的状态。” 这里“世界的状态”指的是对世界的抽象表征。例如，你知道，如果你用特定力度推桌子上的智能手机，它可能会移动；如果你用同样的力度推瓶子，它也会移动；如果你推顶部，它会翻倒；如果你用同样的力度推桌子，它不会移动。</p><p>我们拥有直觉物理学概念，我们认为它很简单。动物也有这种概念，所以我们认为它很简单，但实际上它非常复杂。我们不知道如何让机器真正理解这一点，更不用说通过观察和互动来学习了。尽管如此，由于我们意识到这是真正的问题所在，因此未来几年我们将在这方面取得重大进展。</p><p>但这表明我们离人类智能水平还很远。如果我们拥有功能齐全的自动驾驶汽车，只需 20 个小时的练习就能学会驾驶，就像任何 17 岁的青少年一样；或者如果我们拥有家用机器人，它们能像任何 10 岁的孩子一样一次性清理餐桌，那么也许我们可以说取得了进展。<strong>我们认为这些任务很简单，但对于机器人来说，它们实际上非常复杂。如果机器人能够像猫一样计划跳上家具，观察一下然后快速跳跃，我们也无法做到这一点。问题不在于我们不能制造机器人，而是我们无法让它们足够智能。</strong></p><h2>/ 02 / 解铃还需系铃人，AI正是对抗技术风险的良策</h2><p>Nick Dirks：让我简单谈谈去年杰弗里·辛顿 （Geoffrey Hinton） 离开谷歌一事吧。据报道，去年Geoffrey Hinton离开谷歌的原因是想要对人工智能发展所伴随的巨大风险畅所欲言。而据 BBC报道，当马斯克在2018年做出类似言论时，你的回应是“那简直是疯了”。据我所知，你的另一位图灵奖得主同事也对人工智能非常担忧。然而，你曾在其他著作和演讲中表示，至少在目前阶段，你对人工智能并不那么担心。这背后的原因之一是你并不认为人工智能目前已经接近人类智能水平，另一个原因是你相信人类本质上是善良的。这种分歧确实很有趣。<strong>人们普遍认为你低估了人工智能的风险，对此，你有什么想说的吗？</strong></p><p>Yann LeCun：<strong>这很有趣，实际上绝大多数人工智能研究人员都更认同我的观点，而不是那些担心巨大风险的人。只是那些担心存在风险的人声量更大，或者说他们当中有一部分人更喜欢危言耸听。</strong>Geoffrey Hinton或许不是这样，但其中一些人确实如此。坦白讲，人们害怕什么就说什么，写耸人听闻的东西更容易吸引读者。如果你说一切安好，反而很难让人信服。</p><p>因此，许多关于存在风险的设想本质上都是詹姆斯·邦德电影里的超级反派情节。我可以想象出成千上万种这样的场景。问题不在于会不会出现糟糕的情况，而在于至少存在一种好的发展路径，并且我们的社会制度和人们本身有足够的动力去选择这条道路。让我打个比方吧，我觉得能够安全地依靠音速飞行半个地球简直令人惊叹。这是一项令人难以置信的科技成就。当然，如果你害怕飞行，你可以想象出各种各样的灾难场景，比如飞机上的所有零件都出问题，涡轮喷气发动机爆炸等等。但关键在于，飞行实际上非常安全可靠。这并不是因为存在某个理论证明涡轮喷气发动机本质上是安全的，而是因为许许多多的工程师花费了数十年时间来微调这些系统，使其安全、可靠、经济等等。</p><p>人工智能也将会是这样。你可以想象出各种人工智能失控的场景，但同样也会有许多人工智能发挥巨大作用的场景。因为这是人们想要的，也是机构、政府等所期望的。对于每一项出现过的技术而言，总是存在潜在的危险和误用。解决办法通常不是禁止这项技术，而是想出好的应对措施。这对于人工智能来说也一样，就像汽车和涡轮喷气发动机一样。</p><p>害怕人工智能的风险而监管它，其危险性类似于历史上的一些昏庸总统。历史上有一个很好的例子，那就是印刷术发明之后的情况。在某种程度上，印刷术有点像人工智能，因为人工智能将增强人类的智能，而印刷术的作用也是通过廉价传播知识来放大人类的智慧，不是吗？当然也有一些负面影响，比如印刷术在一定程度上导致了欧洲长达 200 年的宗教冲突，如果没有印刷术，就不会有宗教改革运动和欧洲的宗教战争等。但同时，印刷术也带来了启蒙运动、科学、理性主义、哲学、美国革命和法国革命等积极影响，还有公共教育等。</p><p>让我们再来看看与之形成鲜明对比的奥斯曼帝国，他们禁止印刷术长达 200 年。他们禁止印刷术的原因有几个，首先当然是控制教条和民众。但还有一个我直到与阿联酋人工智能部长交谈才知道的原因，那就是奥斯曼帝国禁止印刷术是为了保护抄写员的利益，因为抄写员当时是一个非常强大的利益集团。这可能是奥斯曼帝国衰落的原因之一，最终导致了曾经在中世纪主导科学界的伊斯兰世界没落。这也是为什么天空中每颗星星都拥有阿拉伯语名字的原因，当时数学等领域也都由伊斯兰世界主导。因此，<strong>如果我们过度监管甚至扼杀人工智能的发展，将冒巨大的风险。</strong></p><p>Nick Dirks：不过，让我问你一个关于你在Meta公司工作时参与的事情。你曾部分地负责利用人工智能来识别和删除违反Meta公司指导原则的不当内容等。据说，在最初的7年里，你利用人工智能删除了近1000万条违规内容，占总删除量的88%。但我们也知道，每三个月就会出现一些虚假信息、错误信息。现在深度伪造技术已经可以模拟语音，只需一小段音频就能产生一个聊天机器人，打电话说服别人做一些可能不太正当的事情。我们知道，在美国即将到来的大选季节，人工智能将被越来越多地用于可能散布虚假信息等目的。我的意思是，这难道不是一个危险吗?</p><p>Yann LeCun：确实存在风险，但这并非新问题。首先我应该纠正一点，我实际上并未直接参与内容审核工作。我曾领导Meta的基础AI研究实验室，该实验室有500名科学家和工程师，开发基础机器学习和人工智能技术。事实上，如果算上人工审核人员，大约有4万人受雇于设计自动化系统删除令人反感的内容或手动审查被用户或系统标记的内容。</p><p>我认为Facebook打击仇恨言论的做法很有趣。2017年底，由人工智能系统自动删除的仇恨言论比例在20%到25%左右。到2022年底，也就是5年后，这一比例上升到96%。两者之间的差异基本上源于自监督式训练的人工智能系统的兴起。这是在ChatGPT问世之前的事了。当时这些技术已为人所知，它能够用任何语言训练系统来表示语言含义。我们训练系统来表示脸书上数百种语句的含义。然后使用该表示训练分类器，判断是否属于仇恨言论。<strong>正是这种自监督式学习方法，加上用于大型语言模型等系统的transformer架构，推动了从23%到96%的巨大进步。</strong></p><p>有趣的是，这些技术不仅用于仇恨言论，还用于检测暴力言论、恐怖主义宣传、欺凌、各种儿童剥削案件、裸露内容等各种可怕的东西，即人们希望在正常社交网络上避免出现的内容。值得注意的是，包括虚假新闻、深度伪造内容在内的这些攻击手段并非新事物，一直都存在。而<strong>对抗这些手段的最佳对策就是人工智能。</strong>所以人工智能并非问题所在，实际上它是解决方案。当然，如果使用人工智能技术制作深度伪造内容变得更容易，那就需要更好的方法来检测和删除这些深度伪造内容。这需要技术和非技术两方面的解决方案。</p><p>技术解决方案是更好的人工智能系统，好人那边的人工智能必须领先于坏人那边。但也需要一些非技术性的社会解决方案。比如制定标准，规定如果你使用人工智能工具或某种图像编辑工具发布图像，该图像必须以某种方式添加水印，也许是隐形的，以表明它是经过编辑的。事实上，现在业内有很多人同意采用的标准不是标记非真实内容，而是标记真实内容，因为有更大动机标记真实内容。所以，如果你是一名记者，拍了一张真实照片，在上传到在线验证平台之前只是做了一点小的修改，那张照片将会有一个水印，说明它是使用索尼相机拍摄的，虽然经过了一些修改，但只是普通的校正，没有其他修改，因此是真实的。这种做法即将到来。</p><p>我认为人们并非那么容易被愚弄。人们会适应并质疑他们所看到的一切。事实上，我在纽约大学的一些同事，由政治学家乔什·塔克领衔的团队进行过一项有趣的研究。他们研究了2016年总统大选前夕的虚假信息点击率和虚假信息，发现大多数点击那些明显虚假且单纯是为了圈流量的新闻的人年龄在65岁以上。新一代年轻人，作为互联网的原住民，是不会上当的。</p><p>所以虽然确实存在威胁，但我认为我们不应该对此过于恐慌。我<strong>们应该投资研发更好的人工智能系统，制定合适的标准和实践，并教育公众提高警惕。人工智能本身并非罪魁祸首，反而是解决方案。我们需要以审慎但开放的态度拥抱这项革命性技术。</strong></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/onM7L-m_C9HLTX3FoLvIsQ" rel="noopener noreferrer nofollow" target="_blank">“乌鸦智能说”（ID:wuyazhinengshuo）</a>，作者：智能乌鸦，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748334370028294</id>
            <title>腾讯终于等来一个上涨理由</title>
            <link>https://www.36kr.com/p/2748334370028294</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748334370028294</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 03:54:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 游戏, 腾讯, 股价, DNF
<br>
<br>
总结: 一款已上线16年仍长盛不衰的游戏《DNF》，给了老游乏力、新游掉队、股价低迷的腾讯一个上涨的理由。游戏在PC端持续热门，腾讯股价因宣布手游国服上线而上涨。DNF的转向手游备受期待，但多次延期让其被称为“跳票王”。腾讯在DNF上已赚得盆满钵满，游戏在玩家心中地位稳固。 </div>
                        <hr>
                    
                    <blockquote><p>一款已上线16年仍长盛不衰的游戏，给了老游乏力、新游掉队、股价低迷的腾讯一个上涨的理由。</p></blockquote><p>一款游戏上线16年长盛不衰，模仿者无数，还能在一夜之间，带起低迷多时的腾讯股价。它是何方神圣，又有何魔力？</p><p>4月22日，从开年后股价便在300港元以下低空盘旋的腾讯，等来了两个好消息。</p><p>第一项利好来自政策刺激。4月19日周五晚，中国证监会网站发布了《5项资本市场对港合作措施》，措施中涉及沪深港通机制，以及共同促进两地资本市场的多项利好政策。4月22日周一开盘后，恒生科技指数一路高开，上涨了1.78%。</p><p>第二项利好则是来自腾讯的“现金牛”游戏。4月22日，腾讯正式官宣定档，《地下城与勇士：起源》手游国服（下称“DNF”）将于5月21日正式上线。消息公布后，腾讯股价高开高走，以上涨5.46%收盘，并创下自2023年7月来最大单日涨幅，成交额突破130亿港元。</p><p>接下来两天，腾讯股价延续升势。4月23日，股价上涨了3.75%；4月24日，股价继续上涨3.55%，收于344.20港元/股，连续三天涨幅已达到11.3%</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_6bad511e732d42b79b3c0e76d8372670@1743780481_oswg778572oswg1080oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这款助力腾讯拉爆股价的游戏《DNF》，终于给了老游乏力、新游掉队、股价低迷的腾讯一个上涨的理由。</p><p>《DNF》是由韩国公司Neople在2005年研发；2008年即由腾讯取得国服代理并于PC端正式上线。直到目前，《DNF》仍然是全球最热门、最吸金的网游之一。</p><p>被腾讯代理以来，《DNF》何时能从端游转入手游，创造更便利的游戏体验，并加倍放大利润空间，让无数玩家翘首以盼，也一直被二级市场期待。</p><p>但受各方条件限制，2018年以来《DNF》“端转手”已前后“跳票”两次。此次正式官宣，也仍有大量玩家在社区里担忧：不会是又一次“狼来了”吧？</p><p>从2月底《DNF》手游首次开启公测开始，相关信息就冲上了多平台热搜，大量玩家已迫不及待先睹为快。据官方显示，3天内就有300万“勇士”参与抢号，开测首日游戏涌入23万玩家，直接让服务器爆满，不少人排队几小时挤不进去。</p><p>近日，摩根士丹利发布市场报告指出：《DNF》上线，将成为腾讯近年最大规模的游戏发布之一，并将成为推动第二季国内游戏业务增长拐点的关键催化剂。预计《DNF》的首年总收入可达100亿元人民币。</p><h2><strong>是辉煌霸主，也是“跳票王”</strong></h2><p>从常理来看，一款从2008年便发布的PC端游戏，早该走入它的生命末期。但《DNF》在16年的发展里，却一次次地打破人们的怀疑，超越着周期。</p><p>由于玩家人数众多，《DNF》一度被冠以了“800万勇士”的称号——但这一数字远不能覆盖手游的想象空间。2020年8月，在《DNF》官网上期待手游上线的预约玩家数就已超过了5000万。</p><p>虽然表面看来，《DNF》粗糙的像素风、2D画面、动作刷图，都包含了满满的过时元素，但它赖以成名的连招、搓招的动作设计，以及“独步天下”的平衡的MMO（多人在线）系统和数值系统打造，对于角色的技能、装备、玩法、氪金设计，都让玩家感到“极度舒适”——简单来说，一代代玩家表示，很难再找到这样好玩的游戏。</p><p>试图“复刻”和“骑脸”《DNF》的游戏曾有无数——最近在这条路上“折戟”的是著名的字节游戏朝夕光年团队。</p><p>2023年7月暑期，朝夕光年上线了重金打造的《晶核》，瞄准的便是《DNF》老玩家们的流量，种种宣发措施都在“碰瓷”DNF。在百度DNF吧里，《晶核》投放了公测的页面广告，海报上印上宣战口号：“不输隔壁，硬刚”；更毫不顾忌直接找来多位DNF区的游戏主播合作宣传。</p><p>但事实证明，《晶核》短暂火爆了2个多月后，流水便开始由盛转衰。2023年年底，朝夕光年也开启了裁员之路。</p><p>有玩家表示，《DNF》因其难以超越，在游戏史上历经十几年，逐渐演变为了一种不断迭代的文化。刷图、搬砖等热词，正是由《DNF》而来，它刺激过网游小说的发展，衍生出了《全职高手》等热门IP；当下全网最火的游戏主播“旭旭宝宝”也是《DNF》的当家花旦。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_6197e910e5e643ef808744dc1d2e9d8b@1743780481_oswg56823oswg600oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但多年来，由于种种原因，《DNF》一直停留于PC端。而这样一款热门游戏，如果能成功转向手游，它的想象力自然会被无限放大。但直到今天，《DNF》PC版本已升级无数，手游却一再延期，这家端游的辉煌霸主也被业界戏称为“跳票王”。</p><p>2018年底，在《DNF》国服冬季发布会上，游戏制作人尹明镇曾透露，“手游版会在2019年上半年上线”，最终不了了之。</p><p>2020年5月，《DNF》手游运营团队宣布游戏预约人数突破3000万，该游戏将于2020年暑期正式上线。但消息公布后3个月，《DNF》官方宣布因内防沉迷系统需要升级，手游将延期上线。与此同时，等待手游上线的玩家人数进一步飙升到了5000万。</p><h2><strong>DNF给腾讯赚了多少钱？</strong></h2><p>从2008年代理国服开始，虽然《DNF》迟迟未能走入腾讯擅长的手游世界，但腾讯在这款游戏上，十几年间也已赚了个盆满钵满。</p><p>从2009年开始，不断有《鬼吹灯外传》（2009）、《龙之谷》（2010）；九城的《名将三国》（2010）；网易的《斩魂》；畅游的《暗影之剑》（2013）等模仿《DNF》的产品前来“踢馆”，都未能动摇《DNF》在玩家心中的地位。</p><p>而凭借无人能及的流量优势，腾讯也将整个社交生态与《DNF》深度绑定，用QQ、QQ音乐、QQ空间、腾讯官网等全产品线为其疯狂引流。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_a1d01cb9d9b6459daa5cd9c136753bc0@1743780481_oswg50344oswg600oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>腾讯的重磅押注如愿取得收获。《DNF》国服刚上线时，腾讯在网游行业排名第三，当年最热门的游戏还是《热血传奇》和《魔兽世界》。很快，《DNF》成为拉动腾讯PC端游业务增长的三驾马车之一（其余两架分别为《穿越火线》和《英雄联盟》）。</p><p>而在《DNF》逐渐走过巅峰后，为了挽留用户，国服又配合了大版本更新，陆续推出了团本、小号反哺大号等玩法，增长了常驻玩家的在线时长，减缓了玩家重复体验MMO内容带来的疲劳感。</p><p>2012年8月，腾讯宣布《DNF》国服PCU（最高同时在线人数）突破300万；2016年6月，PCU突破 500万——彼时，在Steam平台拿下连续55周销量冠军的《绝地求生》（PUBG）全球PCU也只有324万，尚不及DNF国内PCU的2/3。</p><p>2017年，《DNF》在国内月均流水接近10亿元。2018年，配合《DNF》十周年庆，举办的一系列活动助其流水再创新高。彼时，Neople公司披露，进入中国市场十年来，《DNF》累计全球收入超过100亿美元，这一数字远超Steam和主机平台最赚钱的游戏《GTA5》，后者的总收入为60亿美元。</p><p>2023年，曾有韩媒报道，DNF累计营收已经超过了200亿美元（人民币1400亿元）。另据第三方平台统计，DNF手游韩服上线8个月，累计流水也达到了10亿元人民币。</p><p>目前据多家市场投研综合估算，《DNF》手游有望为腾讯2024年带来50-100亿规模的收入。</p><p>而腾讯自己也比谁都清楚，《DNF》对公司的拉动意义。在腾讯2023年年报中，《DNF》被重点提及，并被腾讯定义为“具有极高发展潜力的移动游戏”。财报会上，腾讯管理层特别强调了《DNF》手游的上线时间，初步定于2024年第二季度。</p><h2><strong>鹅厂苦爆款久矣</strong></h2><p>某种程度上，已苦爆款久矣的腾讯，当下急需《DNF》这样的大作，来拉动疲软的游戏业务和市场期待。</p><p>在2024年初的腾讯年会上，马化腾罕见地用“躺在功劳簿”“毫无建树”这样严厉的词来评价游戏业务。财报显示，2023年第4季度，腾讯游戏收入为409亿元，较上季度的460亿元下降11%，较上年同期的419亿元下降了2%。腾讯对此的解释是，由于《王者荣耀》及《和平精英》的收入下降，本土市场游戏收入同比下降了3%至270亿元。</p><p>但据「市界」此前统计，从2021年Q4开始，在腾讯连续公布的9次季度财报中，游戏业务除了2023年Q3的460亿，以及2023年Q1的483亿之外，其余季度一直在420-440亿之间小幅波动。</p><p>结合最新季度财报中，游戏收入直降到409亿元，创下了近年最低值。可以侧面说明，腾讯已经很久没有大爆款游戏产生了——增长的核心仍是由《王者荣耀》《DNF》端游等“长青游戏”贡献。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_17a5678e64194bed8eafa033f59f36a5@1743780481_oswg22225oswg600oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由于近年来，腾讯游戏创新乏力明显，马化腾的心情看起来也越发急迫。</p><p>“帕鲁（人气游戏《幻兽帕鲁》中的角色）火了，几乎所有工作室就都在做帕鲁。”一位腾讯游戏人士告诉「市界」。由于马化腾提出，腾讯游戏在与《蛋仔派对》竞争中没能取得先机，“来得晚了”，因此当一款市场热度极高的游戏出现，就不惜再用赛马试水新类型游戏。</p><p>今年初，腾讯也曾希冀靠对标网易的《蛋仔派对》打造的《元梦之星》，来挽回颓势。</p><p>年会上，马化腾用“全力以赴”、“所有业务结合，探索共同发展”来强调过《元梦之星》的重要性。马化腾表示，这样强社交属性的派对游戏，本属于腾讯的“大本营”。</p><p>老板的雷霆之怒下，这款在内部被戏称为“元神”的《元梦之星》攫取了最大程度的内部资源扶植。但从数据表现上看，虽然花费了巨额营销，《元梦之星》没能在短期内起到“狙击”《蛋仔派对》的效果。</p><p>主要原因在于网易也同步筑起了堡垒，在网易公布的2023年第四季报中，CEO丁磊评价道：“四季度营销费用的增加，主要是竞争的因素，我觉得这是正常的。”</p><p>在网易重金“守擂”下，《元梦之星》在畅销榜只力压了《蛋仔派对》20天，便进入了为期一周左右的相持阶段；不久后，《蛋仔派对》实现了对《元梦之星》的反超。</p><p>焦虑之下，腾讯对《DNF》手游的期待和投入更可想见。不过在《DNF》之外，腾讯今年的游戏储备库也较为丰富：《极品飞车：手游》宣布定档今年暑期；文明IP SLG手游《世界启元》获得版号首度曝光，并在3月22日开启付费测试；《逆战：未来》也在今年2月发布了实机演示。而《宝可梦大集结》《创造吧！我们的星球》等潜力产品也已获得版号，大概率将在今年上线。</p><p>不过也有玩家认为，《DNF》在端游上的趣味与火爆，未必可以全部在手游上实现。“《DNF》的好玩体现在连招，技能组合使用。在电脑上玩家可以按多个键盘，手机屏幕狭窄，如何安排按键、设计丰富的技能呈现将会是个难题。”</p><p>这些猜测与疑问，也只能等待《DNF》手游正式上线后，才能得到解答。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/nLy-Fjp_iX78G_YHJHWc-w" rel="noopener noreferrer nofollow" target="_blank">“市界”（ID:ishijie2018）</a>，作者：赵子坤，编辑：李原，运营：刘珊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748185794968576</id>
            <title>“灰姑娘”解救马斯克</title>
            <link>https://www.36kr.com/p/2748185794968576</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748185794968576</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 03:41:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 增长瓶颈, Model Q, 特斯拉, 马斯克
<br>
<br>
总结: 特斯拉面临增长瓶颈，马斯克加快推出Model Q以应对竞争，但其承诺是否能兑现仍存在疑问。特斯拉股价因此一度下跌，但在Model Q消息发布后有所回升。Model Q被视为特斯拉重要的救场之举，其售价和市场潜力备受关注。马斯克的领导力和决策将直接影响特斯拉未来的发展。 </div>
                        <hr>
                    
                    <blockquote><ul><li>面对增长瓶颈，马斯克加快了推出Model Q的进度。</li><li>特斯拉在售车型的产品力优势在被对手追平甚至反超。</li><li>特斯拉亟需Model Q救场，但马斯克的承诺能否准时兑现还要打个问号。</li></ul></blockquote><p>连跌了七天的特斯拉股价，被马斯克一句话给拉上来了。</p><p>“我们已经更新了未来的汽车阵容，以加快新车型的推出，其中包括了更便宜的车型。”特斯拉在Q1财报里的这句表态，刺激公司股价在盘后涨超13%。而就在财报发布前，特斯拉股价已经连跌了七个交易日。</p><p>Wedbush分析师、特斯拉知名多头Dan Ives认为，如果马斯克放弃Model Q，选择将Robotaxi列为优先事项，那么公司的故事可能会从“灰姑娘”变成“猛鬼街”。</p><p>“灰姑娘”就是马斯克口中“更便宜的车型”Model Q，它门槛更低，却有巨大的市场潜力，就像有望逆袭成王妃的普通女孩。投入巨大却屡屡跳票的Robotaxi则是“猛鬼街”，它可能让华尔街和投资者们被吓得退避三舍。</p><p>能让马斯克一语扭转乾坤，Model Q这位灰姑娘，究竟有何魅力？</p><h2><strong>灰姑娘，加速跑</strong></h2><p>在财报电话会上，马斯克为“灰姑娘”的到来给出了明确的时间。他预计Model Q将在2025年初，甚至今年晚些时候开始生产。</p><p>三个月前，生产Model Q的计划还是在2025年下半年。</p><p>Model Q售价为2.5万美元，将是特斯拉最便宜的一款车型，也是特斯拉重回高速增长的希望。马斯克曾表示，特斯拉正处于“两个增长浪潮之间”，他希望Model Q能够掀起下一个增长浪潮。</p><p>特斯拉眼下所面临的增长瓶颈，在最新一季财报里写得明明白白。</p><p>今年Q1，特斯拉营收同比降9％至213亿美元，净利润同比降55％至11.3亿美元，毛利率为17.4%，创近17个季度新低，季度交付量同比跌8.5%至38.68万辆。这些关键数据，均低于华尔街的预期。</p><p>在特斯拉最重要的中国市场，廉价车型的作用更显得尤为重要。在财报电话会上，有分析师在提问中将廉价车型视为特斯拉与中国同业竞争的重要武器：“公司什么时候可以推出便宜又好用的车型，从而在与他们（中国车企）的竞争中处于更加有利的地位？”</p><p>Model Q在马斯克的宏图中占有重要一席。去年发布的特斯拉“宏图计划”第三篇章显示，对于更便宜的小型电动汽车，马斯克的长期目标销量为4200万辆，而目前主力车型Model 3/Y销量目标为2400万辆。</p><p>事关重大，有关这位“灰姑娘”的任何风吹草动，都会引起市场的警觉。</p><p>4月7日，路透社报道称特斯拉将放弃推出廉价车型，马斯克迅速回应称路透社在“说谎”。</p><p>两天后，高盛在年内第三次下调了特斯拉的目标股价。该行分析师Mark Delaney表示，将维持对特斯拉的中性评级，并将目标股价从190美元下调至175美元。这位分析师称，如果特斯拉2.5万美元的车型延迟推出，将对特斯拉股票产生重大负面影响。</p><p>4月以来，马斯克在自动驾驶业务上动作频频，加剧了华尔街的担忧，成为财报发布前股价七连跌的重要原因之一。</p><p>Dan Ives认为，如果马斯克将Robotaxi作为优先事项，而放弃Model Q的话，特斯拉将面临一场“史诗级”灾难，因为Robotaxi业务尚需要五至六年才能准备就绪。</p><p>因此，相比此前的季度财报，这一季华尔街最为关心的不是特斯拉的降价、裁员或者毛利率，而是Model Q。</p><p>在得知Model Q将加速到来后，曾担心马斯克选择“猛鬼”的Dan Ives，称赞了特斯拉CEO的领导力，“特斯拉需要一个成年人在房间里，马斯克就是房间里的成年人。”</p><h2><strong>漫长的空档期</strong></h2><p>去年年初，特斯拉率先在国内挑起了价格战。但打了一年的价格战后，相比2022年，特斯拉在国内新能源市场的市占率却在原地踏步（2022年、2023年均为7.8%）。</p><p>在全球市场，特斯拉的交付表现也乏善可陈。</p><p>据富国银行的数据，2023年上半年，特斯拉全球的汽车价格平均下降了12%，交付量同比增长了19%；但在下半年公司继续降低车价和推出激励措施的情况下，汽车交付量同比涨幅却放缓至3%。该行分析师表示，这一数字“低得令人担忧”。</p><p>而价格战也让特斯拉付出了不菲的代价。2023年，特斯拉全年毛利率为18.2%，相比上一年下降了7.4个百分点。</p><p>进入2024年，降价仍然是特斯拉的主要武器之一。1月12日，特斯拉中国宣布下调旗下Model 3与Model Y的售价，降幅0.65万~1.55万元。3个月后，特斯拉又在全球范围内进行了降价。</p><p>除了降价外，特斯拉也在想尽办法降低消费者的购车门槛。在财报发布同日，特斯拉中国宣布推出限时“0首付”活动，适用车型为Model 3和Model Y。</p><p>虽然今年依旧发动了价格攻势，但在Q1财报中，特斯拉已经开始主动降低市场的预期：“2024年，我们的车辆销量增长率可能会明显低于2023年。”</p><p>新车没上市，老车又越来越不能打，是造成特斯拉需求下降的重要原因。</p><p>2023年，Model 3和Model Y的合计交付量，占特斯拉全年总交付量的96.2％，但这两款走量车型的发布时间要分别追溯到2016年和2019年。</p><p>在国内市场，一款车型的产品生命周期通常在3～5年之间，Model 3和Model Y均已到了要换代的时间。</p><p>在美国市场，标普全球旗下研究机构S&amp;P Global Mobility也在报告中预计，仅靠Model 3和Model Y两款车型，特斯拉在美国电动车市场的份额预计到2025年将跌至20%以下。</p><p>雪上加霜的是，特斯拉在售车型的产品力优势也在被对手追平甚至反超。</p><p>去年2月，特斯拉挑起价格战之初，身为特斯拉车主的集度CEO夏一平就表示，特斯拉降价幅度较大的核心问题是产品力出现了非常严重的下滑，“花了钱买FSD，花了好几万，到现在还没用上，语音体验比较差，智能驾驶也没做好，网络还经常连接不上，智能化的综合体验还有很大的提升空间”。</p><p>他认为，对比当下国内研发的产品，特斯拉的车型已不具备核心竞争力。</p><p>在本次财报发布前夕，一向乐观的马斯克在社交媒体上感叹道：The car business is tough（汽车这门生意真的很难）。</p><h2><strong>灰姑娘，会不会迟到？</strong></h2><p>特斯拉亟需一位“灰姑娘”救场，但并非所有人好看Model Q的未来。</p><p>Freedom Capital Markets首席全球策略师Jay Woods表示，特斯拉看起来很有希望，但马斯克一贯以来“跳票”的作风，让承诺变得不太可信。</p><p>马斯克曾多次在Model 3产量时间、Cybertruck交付时间、4680电池量产时间等多项重大事件上食言。在这份长长的跳票名单中，时间跨度最大的便是备受期待的自动驾驶。</p><ul><li>2014年，马斯克曾对《华尔街日报》表示，特斯拉将在6年后推出无人驾驶汽车，“到时它们将充斥在那些愚蠢的还需要人类驾驶的汽车周围”。</li><li>2015年，在接受《财富》杂志采访时，马斯克表示特斯拉在2年时间里就能生产出一辆全自动驾驶汽车。</li><li>2019年，马斯克承诺在不久的将来，特斯拉所有车型都将成为功能完备的自动驾驶汽车，至2020年底，将有100万辆特斯拉Robotaxi上路。</li><li>2020年，世界人工智能大会云端峰会，马斯克表示特斯拉已经非常接近L5级别自动驾驶，有信心在当年完成开发L5的基本功能。</li><li>2022年初，在财报电话会上，马斯克称当年将实现全自动驾驶。</li><li>2023年7月，马斯克在世界人工智能大会上表示，特斯拉可能在2023年晚些时候具备L4或L5的完全自动驾驶能力。</li></ul><p>然而，时至今日，马斯克吹过的牛依旧未能实现。</p><p>在Q1财报电话会上，马斯克又表示，“无论如何，就算我明天会被外星人绑架，特斯拉也会解决好自动驾驶问题。”</p><p>而有关Model Q的承诺，则可以追溯到近4年前。</p><p>2020年9月，马斯克称设计和生产2.5万美元的电动汽车，一直是公司的梦想。这个梦想，让市场为之遐想。兴业证券曾在一份研报中预计，Model Q将在2024年初面世，并在2025年Q2销量超越Model 3和Model Y的总和。</p><p>但这个梦想，一度险些夭折。</p><p>去年出版的《马斯克传》一书中写道，马斯克在宣布Model Q梦想后的两年⾥，又多次否决了这个想法，理由是能让他“孤注一掷”的Robotaxi，会让其他⻋型相形⻅绌，而Model Q并不是一个“多么令人兴奋的产品”。</p><p>直到2023年2月，特斯拉设计负责人弗朗茨·冯·霍兹豪森将Robotaxi和Model Q的⻋辆模型并排放在马斯克面前时，他才被Model Q的设计所打动，从而决定生产这款车型。</p><p>在财报电话会上，特斯拉高管表示，会尽快将最实惠的汽车送到客户手中，公司生产线已经为新车型开放了产能。</p><p>这一次，“灰姑娘”能如期赴约吗？</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg2OTY3Njk1Ng==&amp;mid=2247507182&amp;idx=1&amp;sn=36219e6118b81f3039580beabcad7cd9&amp;chksm=cf01512421f55f37c6f399a6d30b098ae872b9d4d4a4d5b3cde883276185285d6fa69b45bef5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“雪豹财经社”（ID：xuebaocaijingshe）</a>，作者：王亚骏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748318671518729</id>
            <title>高瓴，又募了60亿</title>
            <link>https://www.36kr.com/p/2748318671518729</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748318671518729</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 03:41:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 境外机构投资, 科技型企业, 高瓴资本, 60亿
<br>
<br>
总结: 一则消息打破了市场的平静。十部门发文，支持境外机构投资境内科技型企业，这是最近几年里，对外资投资中国市场动静最大、内容最详细、扶持力度最大的举措。高瓴资本旗下HHLR管理有限公司募集完成60亿的二级市场投资基金，加大中国资产配置比例，继续投资于A股市场。这是最近几年内美元投资中国市场最大的一笔募资额，预示着市场的活跃和变化。 </div>
                        <hr>
                    
                    <p>一则消息打破了市场的平静。</p><p>十部门发文，支持境外机构投资境内科技型企业，这是最近几年里，对外资投资中国市场动静最大、内容最详细、扶持力度最大的举措。</p><p>《若干措施》不仅积极回应了市场需求，既涉及境外机构“募投管退”各业务环节，也包括支持供需对接、畅通投资退出、便利享受优惠等政府管理服务。</p><p>其中值得关注的是，措施提及将依法高效审批合格境外机构投资者（QFII）及人民币合格境外机构投资者（RQFII）资格申请，更好满足境外机构进入国内市场意愿。</p><p>已经有投资机构率先行动。</p><p>就在日前，高瓴资本宣布旗下HHLR管理有限公司已募集完成一支规模约60亿的二级市场投资基金，加大中国资产配置比例，继续投资于A股市场。</p><p>一举募资60亿，这是最近几年内美元投资中国市场最大的一笔募资额。</p><p>冰雪初融，冰封良久的湖面，似乎已经有了破冰的先兆。</p><h2><strong>01 高瓴，60亿加仓A股</strong></h2><p>融中获悉，日前，高瓴旗下HHLR管理有限公司已募集完成一支规模约60亿的二级市场投资基金，加大中国资产配置比例，继续投资于A股市场。</p><p>据了解，作为高瓴旗下独立的美元二级市场投资管理平台，HHLR于2007年在新加坡注册成立，2012年经证监会批准取得QFII资格。（QFII机构可以将境外的美元资产，汇至中国内地，兑换成人民币后，进行在岸投资。）</p><p>过去，HHLR在A股的历史持仓包括宁德时代、紫金矿业、格力电器、万华化学等知名上市公司。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_e6ebeb273cf146418e776ff87f9603c0@000000_oswg184525oswg487oswg644_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">高瓴资本创始人张磊</p><p>60亿新基金，高瓴还会投什么？要展望未来，先回溯历史。</p><p>今年2月，高瓴公布了去年四季度的持仓情况。美国证券交易委员会（SEC）数据显示，截至2023年底，HHLR共计持有49家美股上市公司，持股市值合计为49.62亿美元，环比去年三季度末增长10.7%。</p><p>从持仓来看，HHLR依旧偏爱中概股，并对多只科技和生物医药股票进行了增持。</p><p>据披露的持仓情况，截至去年底，HHLR前十大重仓股为拼多多、百济神州、贝壳、传奇生物、微软、赛富时、Take-Two互动软件、亚马逊、丹纳赫和DOORDASHINC，中概股持仓市值占比超过70%，占据主导地位。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240425/v2_b26a9dd2a2a64d91b15d1d2e15ef4fbe@000000_oswg178221oswg711oswg366_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不同于海外二级市场偏爱互联网电商和医疗项目，高瓴在国内更注重科技创新的机会。</p><p>再看高瓴一级市场的动作。2023年，高瓴重点投向了新技术、新能源、新材料、新制造、生命科技等领域。数据显示，过去一年，高瓴的代表项目包括新能源领域的液流储能、时代储能、欣视界、思格新能源，能源转型技术领域的ROTOBOOST、费曼动力，人形机器人项目智元机器人，新制造领域的诺德凯、Tenways（十方科技），生命科学领域研发生态平台飞镖加速器、多肽药物原料领军企业泰和伟业等等。</p><p>近几年，国内一级市场风云变幻。在募资端，国资成为主流LP，在投资端，硬科技成为绝对主角。这样的变化下，各家机构都放缓投资，更加谨慎的对待投资标的。缩减投资金额、放缓投资节奏已经成为当前主流业态。</p><p>数据显示，2023年，市场中公开披露的投融资事件数为11113起，同比下降24.04%，公开披露的投资总金额为7208.54亿人民币，同比下降16.12%。国内融资事件已连续三年持续下降，2023年投融资事件及金额是近三年以来的最低值。</p><p>在市场整体风格都趋于谨慎的当下，高瓴在A股将投向何方？</p><p>一位市场人士对融中表示，从高瓴在国内的布局、近年投资风格，结合其在A股过往重点关注领域，包括所披露的几个过往案例来看，新基金大概会瞄准以下主题：</p><p>1）科技创新将会是未来一段时间中国乃至全球最主要的投资主题，关注具备较强创新竞争力的企业的投资机会；</p><p>2）备结构性增长潜力的优质资产；</p><p>3）具备全球竞争力的企业。</p><p>作为国内美元基金的领头羊，高瓴的一举一动吸引着整个行业的目光。60亿加仓中国A股之余，已经有不少人民币基金开始着手二级市场基金的备案。某深圳头部人民币基金对融中透露，目前他们已经在香港着手设立二级市场基金，并同时建设投资团队。</p><p>在不远的未来，这种从一级市场出发，将业务延伸到二级市场的投资机构数量将激增。通过一二级市场的同时布局，增强自身的业绩和安全线，可能是下一阶段，从单纯VC/PE到大资管的必由之路。</p><h2><strong>02 一周内发布两大利好，美元基金要杀回来了？</strong></h2><p>4月19日可能是个好日子，这一天，两大利好纷纷传向市场。</p><p>首先是商务部、外交部、国家发展改革委、科技部、工业和信息化部、中国人民银行、税务总局、金融监管总局、中国证监会、国家外汇局等十部门联合印发《关于进一步支持境外机构投资境内科技型企业的若干政策措施》（以下简称《若干措施》）。</p><p>《若干措施》既涉及境外机构“募投管退”各业务环节，也包括支持供需对接、畅通投资退出、便利享受优惠等政府管理服务。</p><p>“其中值得关注的是，对境外机构投资者的支持力度增大。”上述人士告诉融中。“这是鼓励外资进入的积极信号。”</p><p>《若干措施》中提及，将支持境外机构通过合格境外有限合伙人（QFLP）方式投资境内科技型企业；支持科技型企业用足用好本外币一体化资金池等跨境资金集中运营管理政策，提高资金运营效率，降低财务成本。</p><p>此外，《若干措施》还将进一步完善明确有关政策安排。关于申请准入，将依法高效审批合格境外机构投资者（QFII）及人民币合格境外机构投资者（RQFII）资格申请，更好满足境外机构进入国内市场意愿。</p><p>在加大融资支持方面，《若干措施》积极支持境外机构和其所投科技型企业拓宽融资渠道，丰富科创资金来源。对于境外机构，在华发行债券尤其是人民币债券能帮助其补充资金来源、降低汇兑成本。</p><p>不仅如此，在投资行业最关心退出问题上，《措施》中提出，将持续畅通科技型企业境外上市渠道。</p><p>在完善退出机制方面，该负责人表示，能不能顺利、高效实现投资退出，是前期调研中境外机构普遍关注的问题，也是《若干措施》的重点内容。中国证监会等部门围绕境外上市、并购重组、份额转让等退出渠道，推出了一系列配套举措。</p><p>比如：</p><p>一是支持境外上市。</p><p>二是鼓励并购重组。</p><p>三是推进私募基金份额转让试点。</p><p>当日晚间，中国证监会关于资本市场服务科技企业高水平发展的十六项措施。其中对引导私募股权创投基金投向科技创新领域、持续完善交易机制、加大科技型企业再融资支持力度、优化科技型企业上市融资环境等一级市场投资人关心的问题，进行了批示。</p><p>其中提及，将优化科技型企业上市融资环境。依法依规支持具有关键核心技术、市场潜力大、科创属性突出的优质未盈利科技型企业上市。进一步推动各类中长期资金加大权益类资产配置。支持科技型企业依法依规境外上市，落实好境外上市备案管理制度，更好支持科技型企业境外上市融资发展。</p><p>此外，《措施》中还提及，将引导私募股权创投基金投向科技创新领域。完善私募基金监管办法，丰富产品类型，推动母基金发展，发挥私募股权创投基金促进科技型企业成长作用。落实私募基金“反向挂钩”政策，扩大私募股权创投基金向投资者实物分配股票试点、份额转让试点，拓宽退出渠道，促进“投资-退出-再投资”良性循环。</p><p>两大措施的发布，进一步在募投管退几个方面释放了积极的信号。“我们认为，这将进一步鼓励、支持创投行业的发展。”</p><h2><strong>03 三大巨头先后撤退，市场呼吁资金入市</strong></h2><p>高瓴资本顺利在二级市场完成募资，或与当前松动的政策有关。</p><p>近几年，海外资金对中国市场的投资确实在趋于谨慎。</p><p>先是去年，全球管理资产高达8.9万亿美元的贝莱德宣布关停旗下中国灵活股票基金，减少在中国资本市场活动。随后不久，管理资金规模1.4万亿美元的挪威主权基金也宣布关停了上海办事处。</p><p>又过了两个月，管理资金规模达到7.8万亿美元的先锋领航集团也确认关闭了在中国上海的办公室，企业名称也从原来的先锋领航变成了蚂蚁（上海）投资咨询有限公司。</p><p>三大资产巨头败退中国，抛开美国缩表、加息和俄乌冲突在内的主要宏观经济和国际市场环境影响不谈，与不断下滑的业绩有着很大关系。</p><p>贝莱德中国新视野混合是贝莱德基金在国内发行的首只公募产品，刚刚成立时的募集资金规模就高达66亿元。一度成为当时的爆款基金。然而到2023年一季度，该基金规模缩水了26亿，缩水比例高达39.4%。</p><p>不仅是这只新视野混合基金，贝莱德旗下的12只基金净值全部下跌，无一幸免，最高跌幅已经超过30%。</p><p>更严重的是，由于业绩表现不佳的原因，直接影响了后续贝莱德的募资。根据数据，贝莱德基发行的几只新基金募资规模都只在5亿元左右，与最开始60多亿的辉煌相比，反差巨大。比如，贝莱德基金旗下的贝莱德港股通远景视野混合基金在成立初期只募集到了5.73亿元的资金，而贝莱德浦悦丰利一年持有期混合债券型基金在创立之初也仅吸引到了2.7亿元的资金。不仅是二级市场的美元基金，一级市场上的投资人们也更加敏锐的捕捉到风险的放大。</p><p>这与投资方向和风格同样有关。</p><p>互联网投资时代，美元投资人是中国一级市场的绝对主角，此后风口转向，硬科技登上舞台后，投资风格开始转换。</p><p>如此种种，这都加剧了美元基金的放缓。</p><p>“当前的市场情况下，高瓴募集60亿激进加仓A股，不仅体现了高瓴持续投资中国的决心，也有利于活跃市场，提振投资者信心。”上述人士告诉融中。</p><p>而如今，在新的政策扶持下，以高瓴为代表的投资人，打破了尘封已久的冰面。美元基金的市场，出现了回暖的信号。市场也在期待，在更多利好之下，市场上的资金更加多元化。唯有充沛的资金，活跃的交易，才能构成一个完善的市场环境，并促进更多创新机会的涌现。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MjI0Nzk5NA==&amp;mid=2650188814&amp;idx=1&amp;sn=ef53db365120473c734d0e0c0e81597a&amp;chksm=bf2e21ead3dd1c5bda8ab34815535080184203f16f5d00eeb008c6d20608ffbfbc2cfaaefd45&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“融中财经”（ID：thecapital）</a>，作者：安多，编辑：吾人，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2748265890888455</id>
            <title>高盛、瑞银对中国看多也做多，转向超配A股和港股</title>
            <link>https://www.36kr.com/p/2748265890888455</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2748265890888455</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Apr 2024 02:49:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 港股, A股, 外资机构, 高盛
<br>
<br>
总结: 外资机构看好港股和A股市场，认为经济表现好于预期，国家队托举改变风险回报方程式，企业基本面良好，全球共同基金对中国股票配置不高。高盛和瑞银纷纷上调A股和港股评级，预计股市仍有较多价值可以释放，港股先于A股表现走出独立行情。 </div>
                        <hr>
                    
                    <p>接着奏乐，接着舞，港股连涨三天，恒生指数、恒生科技指数分别累计涨幅超过6%、9%。</p><p>4月24日，云计算沪港深ETF、恒生互联网ETF、港股互联网ETF等多只港股ETF再次当日涨幅超过4%。</p><p>这一积极变化也被外资机构捕捉到。<strong>继瑞银上调A股和港股评级之后，高盛分析师也在4月23日表示继续超配A股。</strong>“我们更加喜欢A股市场，而不是离岸市场。近期高盛增持了亚洲指数，也加重了香港的MSCI中国指数产品的配置。”</p><p>在业内人士看来，外资机构纷纷发表看好港股和A股的观点，上周五（4月19日）英伟达暴跌10%，让资金重新审视全球配置的洼地，新兴市场中，港股和A股估值已经极具吸引力。比如，从美股和港股科技龙头企业估值来看，英伟达市盈率高达到69.2，3天大涨13%之后的腾讯控股市盈率也仅为25.6。</p><h2><strong>高盛最新观点：超配A股</strong></h2><p>在谈及对A股看法时，高盛分析师表示，过去一个月中，走访了美国、新加坡、东京等多地，与投资者交流后发现，<strong>国际投资者对中国股市的情绪、风险、偏好和兴趣正在改善。</strong></p><p>得出上述结论的原因在于以下四个方面：</p><blockquote><p><strong>一是中国第一季度的经济表现已经好于预期。</strong>制造业和非制造业的PMI数据有了有意义的改进，在此前4月10日的研报中，高盛也上修了对中国2024年全年GDP增速的预测，从前值4.8%上调至5%。正是看到了经济宏观基本面的改善，海外投资者态度变得更加积极起来。</p><p><strong>二是“国家队”的托举。高盛用了“直接赞助”来形容此次国家队的举动。</strong>并指出，国家队的加入改变了A股风险回报的方程式。在此前，投资者担心进一步的下行风险，当国家队提供支持时，意味着遏制了继续下行的风险。这是海外投资者尤为关注的重点。</p><p><strong>三是回到企业基本面，中国企业陆续披露的2023年四季报的业绩整体好于预期。</strong>从估值角度来看，A股和港股均处于低位。</p><p><strong>四是当前全球共同基金对中国股票敞口占总资产管理规模配置并不算高。</strong></p></blockquote><p>与此同时，高盛分析师也注意到新“国九条”中关于提高上市公司质量、分红、退市等相关规定。高盛认为，A股股息率依然不高，上市公司在分红上仍有很大的空间。在退市方面，剔除质量差的公司，保留好公司才能要提高股东和投资者的回报。此外，高盛认为，借鉴美国经验，国内在金融犯罪领域的处罚也可适当提高。</p><p>因此，高盛预计，即便是不考虑基本面情况，<strong>随着A股资本市场制度的完善与规范，股市仍有较多的价值可以释放，估值提升潜力约20，更乐观的预计或高达40%的潜在上涨空间。</strong></p><h2><strong>瑞银上调A股和港股股票评级</strong></h2><p>就在近日，瑞银全球新兴市场股票首席策略师Sunil Tirumalai上调A股和港股股票评级的研发也引发关注。</p><p>瑞银分析师认为，MSCI中国指数EPS（每股收益）未受房地产趋势的影响。在MSCI中国指数的成份股中，消费和互联网行业比重居高，随着消费出现初步回暖迹象，业绩料有更佳表现。</p><p>因此，瑞银认为，对股票市场盈利更加乐观，消费回升的早期信号显现，从年初至今强劲的节假日消费数据、上市消费企业的表现好于中国整体消费中可以看出。对我们而言，消费者信心的任何反弹都意味着家庭储蓄可能流向消费和股票市场。</p><p>瑞银指出中国市场估值计算方式需要作出改变，原因有两个方面：一是从传统角度看，2月资金的短暂现身可能并未构成强大的基本面催化剂。但这确实有助于为大跌/震荡的市场筑底，扭转了下行风险格局。二是中国企业股息、回购超预期的趋势日益增强。若全球市场更加担心地缘政治以及在更高利率维持更长时间的情景下，股东回报的可见度提高可以大有裨益，将密切关注市场改革的下一阶段。</p><h2><strong>港股先于A股表现走出独立行情</strong></h2><p><strong>随着国内经济数据超预期、资本市场制度建设的完善，以及内地对港股市场的政策利好，不少观点认为，海外资金正回流港股。</strong></p><p>港股互联网ETF基金经理丰晨成认为，从代表港股beta 的港股互联网板块的领涨来看，更应关注港股外资资金流的动向，以及以港股互联网板块为代表的中国资产目前对于海外投资者的配置和交易价值。</p><p>日前，证监会发布五项与香港资本市场合作措施，旨在进一步拓展两地市场互联互通，促进两地资本市场的协同发展，有利于更多具有长远发展和回报潜力的企业在港上市，吸引更多国际资金赴港，加强和提升香港国际金融中心地位。</p><p>此次港股快速上涨呈现出独立于A股走势的行情。南向资金自春节以来连续11周净流入，最近30天内有29天呈现净流入状态，年初至今累计净流入2000亿港币以上。</p><p>目前港股市场先于A股市场走入上涨区间，丰晨成认为，向高质量业务切换的进程中，宏观面的预期仍然是分子端扰动投资者情绪的因素，五一期间的服务业零售业的情况或成为外资观察中国宏观经济的一个角度。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/xe9HkZILxnlcfCcaLDYJbQ" rel="noopener noreferrer nofollow" target="_blank">“财联社”（ID:cailianpress）</a>，作者：闫军，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>