<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2685091220263561</id>
            <title>假定降佣10%：以苹果营收7‰，解国内开发者困局</title>
            <link>https://www.36kr.com/p/2685091220263561</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2685091220263561</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 12:06:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 欧盟罚款, 开放性调整, 苹果税
<br>
<br>
总结: 苹果长达16年之久的“围墙花园”被欧盟罚款，苹果在流媒体音乐业务中存在垄断行为，被迫做出开放性调整，降低“苹果税”抽佣比例，但国内市场仍受限制，开发者深受“苹果税”困扰。苹果对开放犹疑，担心“苹果税”收入降低，但降佣可能带来巨大损失。国内开发者呼吁苹果公平对待，降佣、开放侧载等措施有望提升苹果生态创新与活力。 </div>
                        <hr>
                    
                    <p><strong>苹果长达16年之久的“围墙花园”，被轰开了一角。</strong></p><p>3月4日，苹果被欧盟罚款18.4亿欧元（约合142亿元），理由是认定苹果在流媒体音乐业务中存在垄断行为，如对开发者征收30%佣金、阻止开发者接入第三方支付等。</p><p><strong>欧盟大锤落下，苹果也终于一改往日傲慢，在3月6日发布的iOS 17.4正式版中，针对欧盟地区，做出一系列开放性调整，力度史无前例</strong>：</p><p>开放侧载，允许用户从App Store以外的第三方渠道安装应用；</p><p>允许开发者接入第三方支付，不再强制使用苹果支付；</p><p>下调”苹果税“抽佣比例，从原本的30%、15%（针对年收入100万美元以下的小型开发者）两档分别下调至17%、10%（一年以上订阅或小型开发者），降幅在5%～13%。</p><p><strong>苹果“镰刀”后撤，欧盟开发者和用户受益，持续了长达16年的”苹果税“就此大幅降低</strong>——自2008年上线以来，App Store便对应用内的虚拟物品交易收取30%的“过路费”，且强制使用苹果支付，如购买会员、给作者打赏等。</p><p><strong>不过，这样的反垄断红利，国内市场却只能远观</strong>——除欧盟外，此前，苹果对美国、荷兰、韩国等市场开发者，都曾有不同程度的开放或让步，但作为苹果全球第二大营收来源国、第三大营收来源地区，中国用户和开发者仍深受苹果限制，所缴纳的“苹果税”费率，依然是全球最高通用标准——30%、15%。</p><p>站在苹果的角度，其一直对开放讳莫如深，无非担心生态安全和收益受损，但开放所激发的正反馈与短期损失相比，究竟孰高孰低？</p><p><strong>这笔账，值得苹果好好算一算，而不是固执的握紧“钱袋子”。</strong></p><h2>被“特殊对待”的国内开发者</h2><p>如欧盟委员会所言，苹果的封闭，侵犯了用户和开发者的利益。</p><p><strong>在监管压力和开发者抗议之下，过去两三年间，苹果被迫走上开放、减税之路。</strong></p><p>2022年，苹果允许韩国开发者使用第三方支付，对应的抽佣比例降为26%；同年，荷兰约会类应用被允许开放第三方支付，对应的抽佣比例为27%；今年初，苹果允许美国开发者使用第三方支付，对应的抽佣比例为27%、12%（针对一年以上订阅或小型开发者）。</p><p>可见，全球开发者对此有着共性诉求。</p><p><strong>国内市场也是如此，开发者深受”苹果税“的高成本困扰，也曾尝试抗争过，但始终未能撞开苹果铁幕，不得不继续承担全球负担最重的“苹果税”。</strong></p><p>比如知名游戏开发商米哈游，其王牌游戏《原神》便对“苹果税”贡献不菲。</p><p>据data.ai今年2月估算的数据，自2020年9月上线以来，《原神》国内iOS端营收约为15亿美元，按30%的抽佣比例，《原神》仅国内市场大概贡献了4.5亿美元的“苹果税”。</p><p>为降低成本，去年下半年，米哈游尝试引导玩家绕开苹果支付，跳转到自建的网页充值中心，或支付宝“米哈游支付中心”小程序上充值，但这两种方式随后均被苹果停用，不少用户因此吐槽“苹果真麻烦啊”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_331b009eac054c818b47bd5c9ca2a692@46958_oswg70377oswg1080oswg965_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">支付宝安卓端搜索截图</p><p>去年3月，抖音也下架了iOS端的知识付费类课程及生活娱乐充值类商品，但安卓端不受影响，不少用户猜测这与“苹果税”有关。</p><p><strong>苹果逼迫开发者被迫“绕路”，不仅大幅降低iOS用户体验，也让开发者收入受损，长期其实也减少了“苹果税”收入，“伤敌一千，自损八百”。</strong></p><p>也有一部分开发者选择使用苹果支付，但为缓解抽佣成本，会提高iOS端服务定价，甚至高于安卓端三四成。</p><p>不少iOS用户为此在社交平台吐槽，“买得起iPhone，用不起服务”。</p><p><strong>无论是绕路iOS端功能，还是提高定价“转嫁”成本，亦或“照章”承受高佣金，于用户和开发者，都非善举，是国内APP生态低迷的原因之一。</strong></p><p>工信部数据显示，2018年-2023年7月底，国内市场的活跃APP数量从449万款下跌到261万款，四年多减少了42%，接近腰斩。</p><p>此外，截止去年7月底，国内移动应用开发者总数为83万，其中安卓开发者为25万，苹果开发者为58万。</p><p>如果苹果能为这近60万的开发者“减负”，国内移动生态尤其苹果生态的创新与活力便有望提升，这既关乎国内开发者的收益，也关乎苹果自身的生态收益。</p><p><strong>同时，作为苹果重要的销售市场，国内开发者也有权得到苹果的公平对待——开放侧载与第三方支付，适当降低佣金比例等。</strong></p><h2>帮苹果算笔开放经济账</h2><p><strong>苹果对开放的犹疑，大概率是担心“苹果税”收入降低。</strong></p><p>虽然苹果从未公布“苹果税”数据，但不难粗略估算。</p><p>参考Sensor Tower数据，2023年App Store和Google Play全球用户消费支出达1300亿美元，按照App Store历年60%左右的占比估算可得，其2023年的全球消费支出约为780亿美元，按照15%、30%的抽成比例，“苹果税”收入预计为117亿美元到234亿美元，这大约是同期苹果总营收的3%～6.1%。</p><p><strong>同时，“苹果税”毛利率很高，在财报中，包含“苹果税”在内的服务业务毛利率基本稳定在70%以上，远高于硬件40%左右的水平，可谓“躺赚”。</strong></p><p>假设苹果接下来对国内开发者降低抽佣比例，到底会带来多大损失呢？</p><p>我们以苹果降佣10%为例，可粗略估算佣金损失（存在一定误差）。</p><p>据Analysis Group报告，2022年中国市场在App Store产生的数字交易金额为210亿美元，如果以2023年中国社会消费品零售总额7.2%的同比增速，作为年复合增长率估算，可得出，2024年中国市场在App Store产生的数字交易金额预计为241.32亿美元（约合1713亿元），2026年预计为277.33亿美元（约合1969亿元）。</p><p>假如降佣10%，可得出，2024年苹果的佣金损失预计为171亿元人民币，2026年预计为197亿元人民币。</p><p><strong>参考苹果2023全年3857亿美元（约合27385亿元）的总收入看，这近200亿元的潜在损失，相当于其年营收的7‰，实属九牛一毛。</strong></p><p>收入减少苹果可以承受，同时开放、减税还能给苹果带来其他增量价值。</p><p>眼下，苹果在中国市场的日子不算好过。</p><p><strong>一来，iOS正在遭遇鸿蒙的强势赶超。</strong></p><p>IDC数据显示，去年前三季度，在中国智能手机操作系统市场份额中，安卓、iOS、鸿蒙的占比分别为71.8%、16.4%、11.8%。而据TechInsights预测，从2024年起，鸿蒙有望超过iOS，跃升为国内第二大智能手机操作系统；</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_0ed53ff1cc724b078e9259b94cb446e0@46958_oswg399863oswg1080oswg584_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>二来，苹果产品在国内的销售情况也不乐观。</strong>去年Q4,苹果大中华区营收同比下降13%，是唯一出现下滑的区域，也是自2020年第一季度以来的最弱季度表现；另据Counterpoint Research报告，今年前六周，苹果智能手机销量同比大跌24%位居第四，远高于大盘7%的下跌，华为则同比大涨64%升至第二。</p><p><strong>可以看到，苹果在中国的竞争力显著下滑，假如苹果能让利这7‰的营收损失，或许有机会激活应用生态，“以小博大”，以应用生态的长板去击打鸿蒙应用生态的短板，扭转颓势。</strong></p><p>原因在于，一方面，苹果降佣10%后，其最高20%的佣金比例，相比国内OV华米等应用商店具备竞争力，能吸引开发者积极拥抱App Store，反哺苹果生态繁荣。</p><p><strong>当然，国内其他应用商店可能也会跟风降佣，共同为开发者和用户减负，但未必能承担如此大的佣金损失。</strong></p><p>参照Statista Market Insights数据，在全球、欧洲、北美市场，其他应用商店的数字交易份额一般是苹果的2/3，若国内也参照该比例，意味着，在同样降佣10%时，国内其他应用商店的佣金损失约为苹果的2/3，即2024年损失预计为114亿元，2026年为131亿元。</p><p>另一方面，苹果降佣，以及开放侧载与第三方支付后，开发者成本大幅下降，iOS端定价更高的槽点减少，用户体验也有望改善。</p><p><strong>最终，来自用户和开发者的双边收益，或可助力苹果在中国扭转当下的颓势。</strong></p><h2>国内需要主管部门介入</h2><p>在欧盟高压下，苹果的被迫开放，其实也不情不愿，“附赠”了不少限制。</p><p><strong>其中，有些是为了保护用户体验，规避开放带来的安全风险。</strong></p><p>比如，苹果强调其依然会把控应用分发，审查所有应用程序。目标是，确保第三方应用商店分发的应用没有病毒、恶意软件或其他安全威胁，不会让用户遭受严重欺诈。</p><p>保护用户利益的审慎自然可取。</p><p><strong>但需要强调的是，苹果如果一味以此为借口，在国内拒绝开放，并不合理。</strong></p><p>毕竟，从本次苹果对欧盟市场的调整不难看出，苹果有能力在安全前提下开放侧载。</p><p>事实上，苹果先前已经在PC端允许用户从开发者官网下载应用，表明开放侧载在技术上可以实现，且不会产生显著的安全顾虑。</p><p><strong>反观苹果“附赠”的其他新规，则不太让人信服——其变相增加了开发者的费用或门槛。</strong></p><p>其一，针对使用苹果支付的应用，苹果将收取3%的支付服务费。</p><p>其二，苹果对上线第三方应用商店的开发者资质有要求，要么，每年都提交一份由A级金融机构出具的100万欧元（约合770多万元人民币）的信用证；要么，连续两年及以上成为Apple开发者计划的合格会员，且在上一日历年中拥有在欧盟iOS上首次安装量超过一百万次的应用。</p><p><strong>如此一来，那些不具备此般资金或产品实力的中小开发者，便无法享受侧载开放，只能继续被禁锢在App Store的牢笼中。</strong></p><p>其三，针对每年安装量超过100万次的应用，100万次之后的每次安装，开发者均需支付0.50欧元，苹果称为技术使用费。</p><p>也就是说，假设应用每年下载超过200万次，那么，开发者每年至少需额外支付50万欧元（约合380多万元人民币），越受欢迎的应用，费用越高。</p><p>虽然苹果声称，只有1%的开发者可能涉及这部分费用，但据投行机构摩根大通在投资备忘录中表示，收取该部分费用基本能抵消苹果的抽成损失，App Store在欧盟市场的收入将不会受到太大影响。</p><p><strong>综上，苹果前述“附赠门槛”，导致其新规开放性和减负力度大打折扣，结果很可能是“小开发者没资质使用第三方分发，大开发者则需缴纳高额技术使用费”，而只有部分开发者因此受益。</strong></p><p>申万宏源以国内出海游戏为例分析，假设游戏应用继续使用App Store但不使用苹果支付，那么，中高ARPPU（平均每个付费用户创造的收入）/用户规模小的产品或在新规后更受益，如《和平精英》《万国觉醒》《原神》等游戏在欧盟地区的费用预计减少30%以上；而低ARPPU/用户规模大的产品，如《UNO！》《龙珠大冒险》等，由于安装量大，核心技术使用费可能提升较多，导致总费用增加。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_f257b2cd61ca45e59f4423e69dcbbd36@46958_oswg78394oswg748oswg466_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：申万宏源研报</p><p><strong>总之，苹果意图明显，希望保持现状，让开发者尽可能留在App Store高达30%的围墙花园之中。</strong></p><p>为此，苹果还在3月6日“贴心”地为欧盟开发者提供了“反悔”的后路——只要开发者尚未使用第三方分发或第三方支付，可拥有一次切换回原有条款的机会，以避免新规下的新增潜在费用。</p><p>Epic&nbsp;Games和Spotify对此提出强烈批评，后者认为这是苹果应对法规的“伪装”策略，偏离了应有之义；微软Xbox总裁Sarah Bond也认为新规是“误入歧途”。</p><p><strong>对国内市场来说，之后在推动苹果开放时，也当引以为鉴，拒绝掺了水分的开放和减负。</strong></p><p>为此，国内市场不仅要口头抗争，更需要主管部门的介入。</p><p>此前，其他国家开发者能争取到一定让步，皆源于相关主管部门的一锤定音。</p><p>除欧盟之外，美国联邦法院已经通过判决，确认苹果必须放开第三方支付，荷兰竞争执法部门的调查也对苹果做出同样的决定，苹果需要为此分别少收取3%的佣金。韩国在《电子通信事业法》中明确要求苹果、谷歌必须开放第三方支付，一旦违反，可能面临在韩营收3%的罚款；日本有望在2024年出台《数字反垄断法》，要求苹果、谷歌等公司开放侧载及第三方支付，罚款金额最高为企业收入的6%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_703cf69bfb7f4c72bba2b137247346fc@46958_oswg60182oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>对下之下，国内的执法进程应当加速。</strong></p><p>接下来，苹果和欧盟的交涉或还有变数，苹果表示不服欧盟罚款，会提起上诉，欧盟委员会则表示，在3月法规正式生效之时，假如苹果的“建议解决方案不尽如人意”，将会采取激烈行动。</p><p><strong>以欧盟为镜，可知推动开放不易，但国内总要先迈出第一步。</strong></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/HFEjzpSeBLZiJ9burva9Rw" rel="noopener noreferrer nofollow" target="_blank">“财经故事荟”（ID:cjgshui）</a>，作者：王舒然，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2685054229926536</id>
            <title>7B大模型测试成绩超GPT-4，微软新研究解决工具调用难题</title>
            <link>https://www.36kr.com/p/2685054229926536</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2685054229926536</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 12:04:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, 模拟试错法, 大语言模型, 工具学习能力
<br>
<br>
总结: 近日微软和俄亥俄州立大学的研究人员提出了一种受到生物启发的模拟试错法，通过模拟想象和记忆来增强大语言模型的工具学习能力，实现了大幅性能提升，超越了GPT-4。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_881503e14dc74c8cb3ecbd1306b85f9e@453363432_oswg148079oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智东西3月11日消息，近日微软和俄亥俄州立大学的研究人员发布论文，提出了一种受到生物启发的可以增强大语言模型使用工具能力的方法，即模拟试错（STE）法，并将其开源。</p><p>该方法协调了试错、想象和记忆三个关键机制。具体而言，STE通过大模型的“想象力”来模拟使用工具的一些合理场景，从而尝试适配不同的大模型，随后从新的反馈中，获得反馈不断优化。</p><p>ToolBench实验结果显示，STE在上下文学习和微调设置下显著提高了大语言模型的工具学习能力，让Mistral-Instruct-7B实现了46.7%的性能提升，使其成绩超过了GPT-4。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_1663b328692b4f10832a37766d275fbc@453363432_oswg301932oswg1000oswg547_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲论文封面</p><p>论文PDF：https://arxiv.org/pdf/2403.04746.pdf</p><h2>一、无法兼顾准确性和灵活性，大语言模型调用工具遭遇两大难题</h2><p>寻找合适的工具一直以来都是训练大语言模型中关键一环。目前有关大语言模型的工具研究，主要集中在两个方面：为大语言模型增加一些新的工具，以及能够让大语言模型访问多个工具。</p><p>这些研究方向一般采用两种常见的设置：1）上下文学习（ICL），通过给预训练模型展示一些API规范以及输入-输出工具使用的示例，从而训练大语言模型在对应场景下的能力。2）大语言模型对工具使用示例进行微调。一般来说，微调可以更有效且更高效地引导大语言模型的行为。</p><p>但这两种设置在研究人员看来都有不足之处。上下文学习的方法确实能够保证大语言模型使用工具的灵活性，但是其精度却难以达到生产力水平。而微调的方法能够为大语言模型提供更高的准确性，但无法优化大语言模型本身使用工具能力。此外，如果想要优化大语言模型本身使用工具能力，还需要更高的精度，以面对法律、金融等特殊场景的需求。</p><p>同时，研究人员发现，哪怕是已经为了工具进行微调的GPT-4和开源大语言模型，在实际使用工具的过程中，也只有30%至60%的正确率。</p><p>在此背景下，研究团队探索如何让大语言模型能够提升使用已训练过工具的能力。他们从生物系统中获取灵感，设立了一个新的模拟试错法（STE），从而改善大语言模型使用工具学习的能力。</p><h2>二、模拟大语言模型使用工具的过程，设记忆机制反思结果</h2><p>研究团队对STE的研究分为了两个阶段：探索阶段和开发阶段。</p><p>在探索阶段中，研究团队做了一系列测试性实验：合理设想了一个用户查询相关API信息的提问；尝试实现与API交互进行查询；反馈实验结果。在训练的过程中，研究人员通过设计记忆机制来提高记忆的质量。其中，STE的短期记忆以及长期记忆将分别用于提高大语言模型使用工具学习能力的深度和广度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_579797934ac146d4bd37bd871b21bfbe@453363432_oswg136541oswg1000oswg478_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲STE训练示意图</p><p>如示意图所示，当大语言模型想要提升调用天气预报软件的API能力时，大语言模型会先想一些和设想一些有关天气的问题，然后和工具交互以完成用户查询，最后对结果进行自我反思试验。大语言模型将会利用这些短期实验记忆，不断优化相关信息的精确性，并探索API的应用范围，并且逐步形成长期记忆。最后，短期和长期的记忆都将帮助大语言模型提升使用工具的能力。</p><h2>三、大语言模型使用工具能力大幅提升，Mistral-Instruct-7B性能超越GPT-4</h2><p>在经过一系列实验、验证之后，研究团队总结道：STE方法对ICL和微调两种设置都有效。</p><p>研究团队先测试了在没有采用STE方法前，不同参数规模的Llama、GPT、Mistral大语言模型使用API的能力。这时，80亿的GPT-4效果最好，其API适配达到78.1%，正确率能达到60.8%。</p><p>随后，研究团队又测试了通过STE方法后，不同参数规模的大语言模型使用API的能力。在该阶段，几乎不同参数规模的大语言模型均较之前有所提升。通过微调，Mistral-Instruct-7B实现了46.7%的性能提升，其API的匹配能力，以及正确使用工具的能力均超过了GPT-4。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_22dc63e7b3b04239bc625bfeff2ffe5d@453363432_oswg167366oswg1000oswg470_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲在STE训练方法下，大模型使用工具能力的成果表现</p><p>目前，研究团队已经从ToolBench显示成果中验证了该方法的有效性。并且，通过调整训练重点，大语言模型在使用工具的过程中，可以有所侧重的优化使用方法。</p><h2>结语：促进应用生态，降低大模型适配成本</h2><p>随着AI爆发时代的到来，越来越多的大语言模型将面临如何更好地接入不同应用的问题。我们看到微软正在通过一种测试方法，帮助工具更好的和不同的大模型适配。</p><p>同时，我们也能够看见现阶段对大语言模型的研究更加细分化，各界正在共同推动大语言模型的应用落地，为人们提供高效、精确的生产力工具。</p><p>本文来自微信公众号“智东西”（ID：zhidxcom），作者：徐珊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2685020175699841</id>
            <title>大模型2024：先把价格打下去</title>
            <link>https://www.36kr.com/p/2685020175699841</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2685020175699841</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 12:03:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT-4, Mistral AI, 合作协议
<br>
<br>
总结: AI新星OpenAI最近面临竞争对手Mistral AI的挑战，后者推出了性能和价格都有竞争力的大模型Mistral Large，并与微软达成合作协议，成为GPT-4的有力竞争者。Mistral Large在多语言能力和性能方面表现优异，价格更具竞争力，有望在大模型领域掀起一场价格战。Mistral AI的训练成本和推出时间都比OpenAI低，被称为欧洲版OpenAI，吸引了顶级VC和企业的投资青睐。 </div>
                        <hr>
                    
                    <p>AI新星OpenAI最近有点头疼，不仅公司和CEO被马斯克起诉，其拳头产品GPT-4在性能和价格上均面临竞争对手的冲击。</p><p>近期，成立不到一年的法国人工智能创企Mistral AI发布了最新大模型Mistral Large，并推出了首个聊天机器人产品Le Chat，直接对标ChatGPT。据了解，Mistral Large在目前所有能通过API访问的大模型中评分第二，仅次于GPT-4。</p><p>更值得关注的是，Mistral AI还与微软达成了更加深入的合作协议，微软将投资入股Mistral AI，并为其提供算力和云服务，而Mistral AI的大模型资源也将在微软的Azure云平台中售卖。要知道，上一个有此待遇的AI创业公司还是OpenAI。</p><p>除此之外，更低廉的API接口价格也让Mistral Large成为了GPT-4的有力竞争者，并有望在当前的大模型军备竞赛中掀起一场价格战。</p><h2>比GPT-4更具性价比？</h2><p>作为一款诞生于欧洲的大模型，Mistral Large支持英语、法语、西班牙语、德语和意大利语，可深度理解语法和文化背景。另外，Mistral Large的上下文窗口为32K，可从约2.4万个英文单词的大型文档中精准提取信息；具备精确的指令跟随能力，便于开发者定制审核策略；支持原生函数调用和限定输出模式，助力应用开发规模化和技术栈现代化。</p><p><strong>性能方面，虽然Mistral AI并未公布Mistral Large的参数量，但其关键性能已达到业界前三。</strong></p><p>具体来看，Mistral Large在MMLU基准测试中的常识和推理得分为81.2%，仅次于GPT-4的86.4%。Mistral Large达到了顶级的推理能力，可用于复杂的多语言推理任务，包括文本理解、转换和代码生成。其推理准确性优于Anthropic的Claude 2、谷歌的Gemini 1.0 Pro、OpenAI的GPT-3.5，推理速度甚至超过了GPT-4和Gemini Pro，显示了其在处理复杂任务时的高效能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_04d43d7ac5094ba09bb2665cb090d0eb@46958_oswg89753oswg1080oswg682_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>多语言能力测试中，Mistral Large在法语、德语、西班牙语和意大利语的Arc Challenge、HellaSwag、MMLU等基准测试中的表现均远超目前公认最强的开源大模型——Meta的LLaMA 2 70B。</p><p>数学和编程能力方面，Mistral Large同样表现不俗：其在MBPP基准测试中的编程得分高于LLaMA 2 70B，在Math maj@4基准测试中的数学得分也领先于GPT-3.5、Gemini Pro 1.0等模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_12da1f7cc95d4a29b9344c99a8a0391e@46958_oswg26642oswg936oswg438_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>作为Mistral AI商用系列中的旗舰模型，Mistral Large与GPT-4一样并未开源。</strong>用户可通过三种方式访问与使用Mistral模型：其中，在欧洲的Mistral Al基础设施上安全托管的La Plateforme是开发者访问Mistral Al所有模型的首选方式，开发者可通过点击创建自己的应用程序和服务；Mistral Al的开源模型目前可通过GCP、AWS、Azure、NVIDIA等云服务商获得，而Mistral Large目前仅通过Azure云平台提供服务，包括Azure AI Studio和Azure Machine Learning。</p><p>此外，开发者还可以通过虚拟云或on-prem自行部署使用Mistral模型，这种方式提供了更高级的自定义和控制，自有数据将保留在公司内部。</p><p>价格方面，目前上下文窗口为128k的GPT-4 Turbo的输入价格为0.01美元/1000 token，输出价格为0.03美元/1000 token。相比之下，Mistral Large的输入、输出价格均为前者的80%。</p><p><strong>体验方面，有AI创业者指出，Mistral Large的使用体验碾压曾经的第三名Claude 2。</strong>截至2023年11月，OpenAI的开发者规模达200万，其中包含92%的世界500强企业。而Mistral Large直逼GPT-4的性能和更低的售价有望为需求量巨大的企业用户节省一大笔开支，从被OpenAI垄断的MaaS（模型即服务）市场撕开一个口子。</p><h2>MoE架构立大功</h2><p>Mistral Large把价格打下来的底气是更低的训练成本。OpenAI CEO Sam Altman曾表示，GPT-4的模型训练成本“远远超过了”5000万至1亿美元。而据Mistral AI创始人Arthur Mensch透露，<strong>Mistral Large的训练成本不到2200万美元，约为GPT-4的五分之一。</strong></p><p>除了真金白银的训练成本，后来者居上的Mistral Large的时间成本也更具优势。OpenAI从成立到推出GPT-4，足足用了8年，而Mistral AI推出仅次于GPT-4的Mistral Large只用了9个月。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_51e90d2e2525480ea047373776375561@46958_oswg64991oswg940oswg645_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Mistral AI号称欧洲版OpenAI，创始团队由Meta和Deepmind的前科学家们组成。成立后的半年多时间里，Mistral AI接连完成1.05亿欧元种子轮融资和后续的4.15亿欧元融资，得到美国光速、a16z等顶级VC以及英伟达、赛富时、法巴银行的青睐。</p><p>同期，Mistral AI先后推出号称当时“最强的70亿参数开源模型”Mistral 7B、首个开源MoE大模型Mistral 8x7B。其中，Mistral 8x7B更是以一条简单粗暴的磁力链接引领了大模型发布的新范式，给业界带来震撼。</p><p><strong>凭借巨额融资叠加新品发布，Mistral AI的估值也曾一夜之间飙升至20亿美元，成为大模型领域的新晋独角兽。</strong>而Mistral AI更引人关注的是，从初期只有6人的小团队成长至今，Mistral AI一直是MoE路线的忠实信徒。</p><p>MoE即“混合专家模型”，这种模型设计策略通过将大模型分解为多个子模块，提高模型的容量、处理能力和效率。MoE架构主要由“专家”和门控机制两部分构成。每个“专家”相当于一个小型的Transformer模型，专门处理特定类型的输入数据，多个“专家”的结合则使模型具备了更好的性能。而门控机制则用于判定输入样本需由哪些“专家”接管处理。</p><p>大模型的大规模应用与其算力成本紧密相关。对于模型厂商而言，目前主要的算力成本包括预训练成本和推理成本。除去GPU每秒运算次数和显卡的租用成本这两个常量后，<strong>大模型的预训练成本与模型参数量和训练数据的token量正相关，推理成本与模型参数量正相关。</strong>而大模型的性能通常与其参数量相关联，而越高的参数量意味着越高的算力成本。因此，如何在同样的算力成本下提升大模型的参数量成了破局的关键。</p><p>而MoE的解题思路是引入稀疏性，即模型训练过程中，各有所长的“专家”们独立训练、各司其职，在过滤重复信息、减少数据干扰的同时大幅提升模型的学习速度与泛化能力；在推理过程中，每次推理只按需调用部分“专家”，激活其对应的部分参数，如此便有效降低了相同参数下大模型的算力成本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_91d637f40d9c4628866051063357d968@46958_oswg70602oswg1000oswg683_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有意思的是，OpenAI在去年成为“当红炸子鸡”成功得到众多重度用户的续费后，被曝采用MOE重新设计了GPT-4构架，导致性能受到影响。<strong>尽管OpenAI官方并未对此进行正面回应，但利用MOE架构降低训练成本，已经被认为是一个无比自然的发展方向。</strong></p><p>Mistral AI同样未公布大模型的具体参数与训练数据Token数，但此前谷歌应用MoE开发出的GLaM模型参数量达12000亿、训练数据16000亿token，分别是GPT-3.5的6.8倍和5.3倍，其实际的训练成本却只有GPT-3.5的三分之一也印证了MoE框架的高效。</p><p>延续着MoE的路线，<strong>如果说此前发布的开源模型Mistral 7B、Mistral 8x7B实现了对LLaMA等大参数开源模型的逆袭，此次发布的Mistral Large则是Mistral AI对可持续商业模式的探索，试图以闭源模型搭建可盈利的产品线。</strong></p><h2>大模型进入成本战</h2><p>顶着对华芯片禁售的压力，芯片巨头英伟达以一份耀眼的四季报打消了市场顾虑：在数据中心与游戏业务双核驱动下，英伟达2023年四季度营收、净利润大幅超出预期，毛利率再创历史新高。业绩加持下，英伟达业绩已突破2万亿美元，更接连超越亚马逊、沙特阿美，成为仅次于微软和苹果的全球第三大公司。</p><p><strong>数据、算力和算法构成了大模型的基石。</strong>在当下这波如火如荼的大模型淘金热中，从学界到初创企业再到巨头纷纷下场，而无论其技术路线是开源或闭源，应用场景是通用或垂直，AI芯片作为大模型大脑，始终是模型预训练和推理必不可少的工具。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_8a6106fcc40e4b75ba9daf88adfd383f@46958_oswg221936oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>身为高端GPU市场中唯一的提供方，“军火商”英伟达是这场大模型军备竞赛中永远的赢家——以A100为例，若要通过训练达到ChatGPT级别的性能，至少消耗一万张A100加速卡，巨头们囤货的单位也以万张起，怎能不赚得盆满钵满？</p><p>但换个角度来看，在GPU供应短缺的背景下，一张A100显卡售价约10000美元甚至更高，对于大模型厂商来说，在应用落地和商业化前景仍不明朗的情况下，动辄上亿美元真金白银的投入必然肉疼。在算力、数据、人力等资源成本高企的情况下，如何用相对低的成本训练出一个想要的大模型，并以一个用户可接受的成本让大模型跑起来是大模型行业在2024年的当务之急。</p><p><strong>在保证同等效果前提下，提高硬件利用率，缩短算力使用时长；优化工具链以提高训练、推理效率；适配低价GPU是当前国内大模型厂商降本的主流方法论。</strong></p><p>例如，面向大模型训练，腾讯升级了自研机器学习框架Angel，针对预训练、模型精调和强化学习等全流程进行了加速和优化，提升了内存的利用率。借此，大模型训练效率可提升至主流开源框架的2.6倍，用该框架训练千亿级大模型可节省50%算力成本，大模型推理速度提高了1.3倍。</p><p>京东云推出vGPU池化方案，提供一站式GPU算力池化能力，结合算力的任意切分和按需分配，在同等GPU数量的前提下，实现了数倍业务量扩展和资源共享，降低了硬件采购成本，使用更少的AI芯片支撑了更多的训练和推理任务，GPU利用率最高提升70%，大幅降低大模型推理成本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_b005aac05a714eed8a558c2ebe57ede9@46958_oswg56338oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>阿里云通义大模型则聚焦于规模定理，基于小模型数据分布、规则和配比，研究大规模参数下如何提升模型能力，并通过对底层集群的优化，将模型训练效率提升了30%，训练稳定性提升了15%。</p><p>百度升级了异构计算平台“百舸”，将训练和推理场景的吞吐量提高了30%-60%，意味着原先需要用100天的训练才能达成的效果，现在只需40-70天，节约时间等于间接省钱。同时，在英伟达之外，百度的“千帆”大模型平台还兼容昆仑芯、昇腾、海光DCU、英特尔等国内外其他主流AI芯片，通过组合选项完成低成本的算力适配。</p><p>正所谓“早买早享受，晚买有折扣。”当前，Mistral AI以性价比暂时领先，但也有不少开发者还在等待OpenAI大模型产品的升级降价。毕竟，正是OpenAI自己在GPT-4发布后不到8个月就推出了更强也更便宜的GPT-4 Turbo。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/YCFoe4fVLWrm8oOmu33jRg" rel="noopener noreferrer nofollow" target="_blank">“惊蛰研究所”（ID:jingzheyanjiusuo）</a>，作者：觉，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2685074606637190</id>
            <title>超声波指纹或迎来普及，但生物识别并非手机的决定性因素</title>
            <link>https://www.36kr.com/p/2685074606637190</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2685074606637190</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 11:54:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米15, 超声波指纹识别, 生物识别技术, 指纹识别
<br>
<br>
总结: 文中介绍了小米15手机将采用超声波指纹识别技术，相比光学方案具有更高的安全性和识别率。同时探讨了安卓和iPhone在生物识别技术上的差异，以及不同指纹识别技术的优劣。文章强调了生物识别技术在提升用户数据安全和信息保护方面的重要性，以及对更高识别率、便捷性和低成本的追求。 </div>
                        <hr>
                    
                    <p>日前有消息称，小米15、小米15 Pro不仅会按惯例用上高通新款旗舰平台骁龙8 Gen4，还在测试汇顶的单点超声波指纹识别方案。据了解，相比目前主流的光学指纹识别，超声波方案的优势更为明显，其穿透性强，抗水渍、污渍干扰能力强，识别率更高、安全性也更强。</p><p>事实上，去年就曾有消息源透露，小米方面正在测试单点超声波方案，但当时并不确定是否会落地。因此有观点认为，2024年或将是超声波指纹识别方案“遍地开花”的节点。同时也有观点认为，高端机型理应用上成本更高的所有元器件，其中就包括生物识别方面。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_573bcb3127ed4ae3ae90b2cb28df0986@000000_oswg27529oswg550oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如今智能手机已普遍采用指纹识别、面部识别等生物识别技术，为用户带来更安全、便捷的身份验证体验。在具体的方向上，目前安卓阵营基本以指纹识别为主，苹果旗下主流iPhone机型则全面采用的是3D人脸识别。</p><p>安卓机型受制于成本等方面的考量，将指纹识别作为生物识别技术的主要方向，已经成为了其与iPhone体验差异化的重要组成部分之一。而作为一项历史悠久、且应用最为广泛的生物识别技术，指纹识别技术现阶段大致可分为电容式、光学式，以及超声波三种。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_0e135a08b2a743f0b411db7a959d1d2f@000000_oswg18429oswg550oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中，光学式指纹识别技术在安卓阵营中已经有着更大的市场份额，其是借助光线在指纹表面的反射和散射来生成图像，然后进行识别。这种方案的优点在于可以轻松集成到屏幕下方，能够更好地适应如今的全面屏设计，甚至还进一步细分为超薄屏下指纹（光学透射式）、短焦屏下指纹（光学投射式）两个分支。前者虽然对机身体型的影响不大、但成本相对更高，后者成本较低，但对机身内部空间有着更高的要求，目前大多被应用在中低端机型上。</p><p>超声波指纹识别则是利用超声波脉冲感应指纹特有的孔和脊，并形成3D深度数据，相比光学方案，由于能够识别指纹的三维形貌，因此也具备更高的安全性。而且即便是湿手或有污渍的情况下，在识别率、灵敏度等方面受到影响的概率也相对更低。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_0b89803ce4ed42d2b4d8da6f3fd61114@000000_oswg19654oswg550oswg352_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此前，高通是超声波指纹识别方案的主要推动者之一。在历经数次迭代后，其相关方案也升级到了超声波3D广域指纹识别，具备更大识别的区域，在部分机型上甚至可以提供半屏和双指识别。不过由于成本方面的限制，目前超声波指纹识别仅在各品牌的高端机型上采用。</p><p>针对这一局限性，相关厂商就通过简化结构，推出了单点超声波指纹识别方案。其只能在相对较小的区域内进行识别，虽然与广域指纹识别在技术细节上有所差异，但有相关消息显示，识别速度和识别率均不会受到影响。而且更为重要的是，虽然由汇顶提供的单点屏下超声波指纹识别方案具体成本并未公开，但较现有的成熟方案必然会更低。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_88d5e3b114be4d499221c7c76dbddbed@000000_oswg21578oswg550oswg395_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而电容式指纹识别技术的历史则更为“悠久”，这种方案是通过实体电容传感器来获取获取指纹信息，优势在于技术成熟、识别速度快、识别率高，但由于传感器会占据一定的空间，所以在全面屏设计这一潮流下也逐渐被边缘化。不过目前也有厂商在部分机型上采取了与电源键合二为一的设计，以扬长避短的方式实现了这一方案存在的价值。</p><p>自2017年苹果在iPhone X上换用FaceID后，“无感解锁”、“无感支付”的体验就成为了主流iPhone机型的标志性功能，其在安全性和便利性方面也毫不逊色于指纹识别。此前就曾有大量传言称，由于苹果还为屏下FaceID投入了大量资源，并已有一定成果，因此未来其极有可能还会继续在这一方向上发展。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_d8e8bdd8291a479088ebed834c7186d5@000000_oswg19125oswg550oswg353_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>值得一提的是，从本质上来说，无论安卓阵营现阶段主要采用的指纹识别、还是iPhone的面部识别技术，其实只是技术路线的差异，并没有高低优劣之分，两者同样都可以提供金融级的安全防护标准。</p><p>从本质上来说，在智能手机上应用生物识别技术的目的，就是为了提升用户的数据和信息安全保护能力。特别是随着移动支付的普及和数字化生活的深入，手机中的个人信息和资产价值也变得越来越重要，因此通过指纹识别、面部识别等技术手段来保护个人隐私和信息安全也具有了更多的现实意义。</p><p>此外，推动生物识别技术进步的背后，实际上也是对于更高识别率、便捷性，以及更低成本的追求。毕竟识别率的提高就意味着能更准确地识别出用户生物特征、减少误识和拒识的情况，便利性的提升则意味着用户体验更好，而成本的降低则有助于其应用越来越广泛。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_6166ab1c6989419a84d5d8e87b01166c@000000_oswg26919oswg550oswg373_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于手机厂商来说，在为旗下产品选择生物识别方案时，显然就需要综合考虑设计、体验、成本，以及市场等多方面的因素，并不能通过简单的“堆料”来解决。例如光学指纹识别技术中的超薄屏下指纹就充分利用了OLED屏的特性，仅从屏幕特性来说，其就无法用到配备LCD屏的机型中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_38dc6346bec845da9642a16176bc2e33@000000_oswg18148oswg550oswg375_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外在一些折叠屏机型中，也使用了侧置式指纹识别与电源键合二为一的设计，原因就在于其他方案将占用更多宝贵的机身内部空间，同时成本也会进一步提高。在这样的情况下，就不如将成本投入到可以提升产品力的元器件上，以满足用户的需求，例如性能、影像等方面。</p><p>当然，认为高端机型只有采用成本更高的生物识别方案才符合其定位的观点，其实也并无不妥，毕竟也符合用户对于新技术应用的期待。当前超声波指纹识别在高端机型上的普及，以及进一步下探极有可能会成为趋势，但在现有的技术条件下，厂商同样需要根据产品的实际情况有所取舍，确保在整体使用体验上达到最优。而这种平衡和选择，实际上就是每一个厂商能力在打造一款产品时都需要面临的事情。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649859652&amp;idx=4&amp;sn=613cd8331c2ab7654f4f745015f0f337&amp;chksm=86a1ac2af15a966375d428d65a3e524bb6de8b6e47aa9ebb492d7cbecaa1d10f4a2b9d19ed03&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2685066106371075</id>
            <title>HomePod剧变，苹果跑步入场AI硬件</title>
            <link>https://www.36kr.com/p/2685066106371075</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2685066106371075</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 11:50:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: HomePod, 带屏音箱, iPad, 苹果
<br>
<br>
总结: 苹果的HomePod产品线虽然不成功，但可能会推出带屏音箱，结合HomePod和iPad的优势，挑战在于价格、使用场景和基本功能。 </div>
                        <hr>
                    
                    <p>苹果旗下的各类产品中，HomePod估计是最不成功的（如果暂不考虑刚开售的Vision Pro)。初代HomePod 2018年发布，三年后停产，直到2023年苹果才推出了第二代产品。&nbsp;</p><p>让人大跌眼镜的是，HomePod 2相比五年前的旧款，在配置上反而全面缩水了。当然，HomePod 2的价格也降低了，这意味着苹果认为堆料提升音质的产品路线已经走不通。不过，这并不意味着苹果会放弃Home Pod产品线。<strong>前阵子，彭博社再次曝光带屏版HomePod。针对这条表现平平的产品线，苹果似乎要启动Plan B了。</strong></p><h2>小标题苹果要将HomePod与iPad合起来？</h2><p>带屏音箱并非什么新鲜事物，安卓阵营的小度率先推出了这一形态的产品，随后天猫精灵等纷纷跟进。 <strong>虽然带屏音箱这个名字听着有些古怪，但却因为更能满足用户进而受到热捧，成为增长最快的智能音箱细分品类。</strong></p><p><strong>有一说一，纯语音交互很难满足大部分人的大部分需求，因为人是视觉的动物，90%的信息获取来自于眼球。正因为此，小雷也并不看好Rabbit r1、AI Pin这两款AI硬件新物种，因为它们都依赖语音交互，视觉呈现前者没有后者孱弱（靠投影）。</strong></p><p>目前最常见的带屏音箱，基本可看作是音箱+平板的结合体。相比常规智能音箱，它多了块屏幕，具备了图形化交互和视频播放能力；相比一般的平板，它的外放和拾音能力更强，无论是播放效果，还是远距离唤醒语音助理，都更有优势。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_678a257f6f514792a57a9a1fac57c96a@000000_oswg65218oswg1080oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：Google）&nbsp;</p><p>如果苹果要做带屏音箱，那么很自然的猜想就是HomePod+iPad的形式。毕竟，苹果当前的智能音箱只有HomePod，大屏触屏设备只有iPad。&nbsp;</p><p>如果iPad集成了硬件更强劲的音频设备，那么音质和Siri方面的体验能够获得大幅度提升。而HomePod有了屏幕，也能够在交互体验和使用场景上实现升级。&nbsp;</p><p><strong>无论在音频还是平板，苹果均有技术积累和产品经验。</strong> 虽然HomePod系列商业层面上并不算成功，但仍然展现出了很多差异化的特点，比如强劲的硬件配置+计算音频带来的出色音质，音频方面的表现远超大量竞品。平板方面，iPad毫无疑问仍然是平板市场上实力最强的产品，无论硬件还是软件生态均领先于行业。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_4be17f5c75944b5e88436279974e21e5@000000_oswg1038646oswg1080oswg707_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技摄制）&nbsp;</p><p>这样来看，苹果带屏音箱或许是HomePod和iPad的强强联合，将各自的优势结合到一起，从而强势杀入带屏音箱市场中。 <strong>然而做好带屏音箱却并不是一道简单的“加法”题，就像iPhone：虽然形式上是手持电话、手持PDA、数码相机、MP3、地图导航仪等设备的“多合一”，但实际上却不是简单地做加法，而是在全新的形态上进行了软硬件、应用与内容生态乃至商业模式的重构。苹果如何通过“带屏音箱”重构智能音箱？</strong></p><h2>做带屏音箱，苹果要面临多少挑战？</h2><p><strong>首先，最现实的问题是价格。</strong> 市面上主流的带屏音箱，价格普遍在千元以内。如果苹果带屏音箱将现有HomePod和iPad结合，那么成本和定价恐怕很难低于千元。&nbsp;</p><p>苹果在售的最便宜的智能音箱HomePod mini 749元、最便宜的入门iPad 2599元。当然，苹果可选择压缩硬件成本，比如使用老款的库存芯片、规格较低的屏幕面板等，但整体成本仍然会高于竞品，至于定价，苹果一直都很重视利润且确实配得上品牌溢价，这样看，苹果的带屏音箱恐怕要大几千元，这让其损失了竞争力。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_84f2e28e14a84a23afb2767eac279e42@000000_oswg269307oswg1080oswg681_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：苹果）&nbsp;</p><p><strong>其次，得考虑使用场景。</strong></p><p>表面上看，带屏音箱兼顾了音箱和平板的功能，场景比单一产品更加丰富。只是，大部分带屏音箱都是家庭等固定场景下使用，充当智能助理和控制中枢的角色，移动便携性其实比平板要更弱。苹果需要用充足的理由来说服用户愿意为之买单。&nbsp;</p><p><strong>最后，基本功能不能过关？</strong></p><p>苹果HomePod系列，在产品策略上和市面上其他智能音箱有明显的区别，即更加注重音质，但智能性方面显然有所欠缺。对大部分用户来说，HomePod上的智能场景主要就是Siri。尽管Siri曾是语音助理的先行者，但语音交互能力已远远落后于竞争对手们，原因不难理解：在AI技术特别是生成式AI技术上，苹果已彻底落伍。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_da66f146b4fe437fa5bdd1b08694c17f@000000_oswg980247oswg950oswg733_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：雷科技摄制）&nbsp;</p><p>各大科技巨头都在大力推进大模型、生成式AI技术，其中微软（投资OpenAI）、Meta、Google以及中国的百度、华为、阿里等巨头均有强大的基础大模型，其他科技巨头如OPPO、荣耀、vivo、三星、魅族们则在生成式AI与硬件的结合（即AI硬件）上急行军，将苹果远远甩在了后面。&nbsp;</p><p>苹果已经意识到AI硬件的全面落后，并加速追赶，前段时间宣布终止造车项目，加码AI大模型，日前赶紧发布第一款自称是“最强消费级AI笔记本”的MacBook Air入局AI PC，可谓是亡羊补牢。&nbsp;</p><h2>带屏智能音箱是苹果AI硬件的一张牌</h2><p>HomePod不是苹果AI硬件的王牌，但至少也算一张牌。&nbsp;</p><p>初代HomePod发布后停更了5年，足以说明用堆硬件来提升音质的产品策略，市场并不买账。2023年，摇摆一阵子后，苹果又复活了这条产品线。&nbsp;</p><p>HomePod 2配置缩水，但重音质、弱AI这一基本产品思路没变。初代产品折戟沉沙并未让苹果痛定思痛、另起炉灶，而是用一种近乎凑合的方式来更新二代产品。&nbsp;</p><p>现在苹果带屏音箱的消息再次传出时，不仅让人好奇，对于智能音箱类产品，苹果还在打着什么算盘。答案可能是：AI硬件。&nbsp;</p><p>智能音箱是AI硬件的先行者——虽然前些年底层是深度学习而不是大模型技术，但在生成式AI加持下，智能音箱将升级成AI音箱，智能助理会更强大，因此苹果HomePod算是其在AI硬件中的一项基础业务，苹果只会更加重视。&nbsp;</p><p>从各大硬件和互联网品牌近年的动向来看，AI将是未来的竞争焦点，正如理想CEO李想说的那样：&nbsp;</p><blockquote><p>人工智能会成为所有设备、服务、应用、交易的最顶层入口，苹果的必争之战。&nbsp;</p></blockquote><p><strong>硬件是AI的黄金落地场景，AI硬件风起云涌，这对存量市场规模告急的硬件厂商（手机、家电、智能硬件、可穿戴、XR等）来说，无疑是雪中送炭。</strong></p><p>实际上，前几年智能音箱雨后春笋般出现的浪潮，就是因为各大品牌都把它当作了AI技术（深度学习）的试验田。因此，即便硬件上无法获利，这些厂商也不留余力地发布和更新智能音箱产品。如今，AGI（通用型人工智能）可以让诸多硬件再次被重做一遍，机会来了，苹果再度加码智能音箱就不让人意外了。&nbsp;</p><p>前面我们提到，苹果旗下设备的AI能力，相较于整个行业显得有些落后，至少在大模型、生成式AI这些热点项目上是缺位的。 <strong>但这并不意味着苹果对于竞争对手们纷纷All in AI的举动无动于衷，日前M3版MacBook Air发布时，苹果在官方新闻稿中就用到了“用于AI的全球最佳消费级笔记本电脑”这种描述。</strong> 而且，有消息称今年6月的WWDC上，苹果将会带来覆盖全平台的新AI功能，以及生成式AI驱动的iOS 18。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_0d242892989a499996cc97d80c598c51@000000_oswg548187oswg1080oswg667_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图源：苹果）&nbsp;</p><p><strong>据雷科技观察，无屏智能音箱的交互方式比较单一，比较适合作为语音相关技术的试验田；而带屏音箱由于多了触控屏幕这项重要的输入输出设备，能大幅拓展AI技术的应用场景，基于大模型和生成式AI带来全新的多模态交互体验。</strong></p><p>还有，智能家居也是苹果正在下注的重要项目。作为近年流行的概念，智能家居系统背后是海量设备的泛智能化和空间智能化。要控制这个庞大的系统，苹果最关键的切入点就是控制中枢产品，交互方式更丰富、即是音箱又是中控屏的带屏HomePod，自然可扮演好这个角色。&nbsp;</p><h2>写在最后</h2><p>正如雷科技此前所说： 2024是AI硬件元年。 在AI手机、AI PC后，AI正在加速与音箱、可穿戴、XR、家电、家居、智能清洁设备、机器人等硬件的结合。 在AI大模型落伍的苹果正跑步入场AI硬件浪潮，HomePod是苹果AI硬件的一张牌，其未来的更新值得期待，专注于AI硬科技的雷科技也将持续追踪关注。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzU4NjEwNDU5MQ==&amp;mid=2247541498&amp;idx=1&amp;sn=dfb61d8dc8a454455a75e0c50c6f60a1&amp;chksm=fc8c4a58a91983707cdd332b0ecd3379612c4de94c16b53608d0d0feab6a71987131bc3efa69&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“价值研究所”（ID：jiazhiyanjiusuo）</a>，作者：重嘉，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2685027813227525</id>
            <title>TikTok 凭什么敢对 1.7 亿美国用户弹窗</title>
            <link>https://www.36kr.com/p/2685027813227525</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2685027813227525</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 11:45:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: TikTok, 美国政府, 剥离法案, 用户弹窗
<br>
<br>
总结: TikTok在面对美国政府的剥离法案时，通过向1.7亿美国用户弹窗推送通知，号召他们给国会议员打电话，表达反对立场。这一举动与过去的耐心解释和沟通方式大相径庭，显示出TikTok的紧急态度。 </div>
                        <hr>
                    
                    <p>相对于 TikTok 过去几年面对美国政府打压的耐心解释和沟通，最近 TikTok 却做出了与以往风格大相径庭的的行动——美东时间 3 月 7 日，TikTok 在应用程序中向美国地区共计 1.7 亿用户弹窗推送通知，号召他们给所在地区的国会议员打电话，撤销针对 TikTok 的剥离法案。&nbsp;</p><p>TikTok 全屏弹窗用户的内容为：现在是需要发声的时刻，「在政府剥夺 1.7 亿美国人宪法赋予的言论自由之前」，「该（法案）将将剥夺 1.7 亿美国人的宪法自由言论权，损害数以百万计的企业，摧毁全国各地无数创作者的生计，剥夺艺术家的观众」，「让国会知道 TikTok 对你意味着什么，并让他们投出反对票。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_71c9bd61710c4aff954ce17f6e900723@000000_oswg90576oswg688oswg1282_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Stop a TikTok shutdown｜图片来源：TikTok&nbsp;</p><p>根据极客公园调查了解到的一些信息，TikTok 此举出自美国本土团队的决策，因为此次情况更为紧急，并已经退无可退。&nbsp;</p><p>相比 2020 年时任总统特朗普签署行政令，要求字节跳动在 90 天内剥离 TikTok 在美国的业务，否则将面临禁令，这次的《保护美国人免受外国对手控制应用程序侵害法》（Protecting Americans from Foreign Adversary Controlled Applications Act）显得更为紧迫和直接。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_c202e8d7826541f1a90533fb64dfdc8c@000000_oswg164891oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Protecting Americans from Foreign Adversary Controlled Applications Act｜图片来源：美国国会官网&nbsp;</p><p>在 TikTok 弹窗向用户求助后不到一天，美国众议院能源和商务委员会就一致通过了字节跳动旗下 TikTok 的剥离法案——以 50:0 的投票结果。该法案的下一个流程将在 3 月 11 日进行，届时众议院将对这项提案进行快速投票表决。&nbsp;</p><p>该法案于 3 月 5 日由美国众议院 19 名议员提交。该法案要求字节跳动在 165 天内剥离对旗下短视频应用 TikTok 的控制权，否则 TikTok 将面临从所有美国应用商店下架的命运。这份 12 页的立法提案草稿中有且仅有 ByteDance 和 TikTok 两家公司的名字。&nbsp;</p><p>另外，此次剥离 TikTok 的法案只有众议院在推进，参议院没有推进，流程被进一步加速。当地时间 3 月 8 日下午，美国总统拜登在接受外媒采访时表示「如果他们通过了，我就签字。」&nbsp;</p><h2>TikTok 在美国：频遭发难，退无可退</h2><p>2019 年 11 月，美国政府对 TikTok 母公司字节跳动收购 Musical.ly 进行了国家安全审查，关注点在于用户数据的处理和存储。「刁难」开始了。&nbsp;</p><p>在 2019 年 11 月至 2020 年 7 月期间，美国参议院针对中国的应用 TikTok 举行了一系列的听证会，目的是推动相关立法，以禁止 TikTok 在美国的使用。&nbsp;</p><p>这一过程中，参议院国土安全和政府事务委员会在 2020 年 7 月通过了一项法案，该法案旨在禁止联邦政府雇员在政府设备上使用 TikTok。随后在 8 月，时任美国总统的特朗普签署了两项行政命令。这些命令旨在限制 TikTok 在美国的下载、更新和运营，并要求 TikTok 的母公司字节跳动在 90 天内将其在美国的业务剥离。&nbsp;</p><p>该禁令并未立即实施，但美国外国投资委员会（CFIUS）随后启动了对 TikTok 的国家安全审查程序。&nbsp;</p><p>到了 2021 年 6 月 9 日，拜登政府发布了新的行政命令，撤销了特朗普时期的针对 TikTok 和微信的禁令。然而，这并不意味着对这些应用的监管有所放松。&nbsp;</p><p>实际上，拜登政府维持了美国外国投资委员会（CFIUS）对这些应用的审查，并提出了一系列针对「外国对手」开发的软件应用的限制措施。这些措施的打击力度甚至超过了特朗普政府时期。&nbsp;</p><p>TikTok 过往尝试了多种努力试图解决问题。2020 年 3 月，Tiktok 公布了透明化建设的两项重要举措，向外展示公司的安全可信赖：建立「透明度和问责中心」，允许外部外部访客查看 TikTok 内容审核后台系统，包括部分应用代码和数据管理操作，同时，TikTok 还发布了透明度报告，以公开其运营和数据处理的相关信息；成立了一个内容顾问委员会，该委员会由独立学者和行业专家组成，他们为 TikTok 在美国的运营团队提供关于内容管理、技术伦理和数据安全等方面的建议，并进行监督。&nbsp;</p><p>此外，TikTok 还成立了一个专门的美国数据安全公司（USDS），负责管理美国用户的数据。同时，TikTok 实施了名为「Clover」的数据隔离工程和「Texas」的数据安全工程，这两项计划的年度运营成本均达到了大约 10 亿美元。&nbsp;</p><p>2020 年 5 月，TikTok 聘请了具有美国背景的高管，如前迪斯尼高管 Kevin Mayer（凯文·梅耶尔）担任字节跳动首席运营官（COO）兼 TikTok 全球 CEO。&nbsp;</p><p>2020 年 8 月，TikTok 向美国加利福尼亚州中区联邦地区法院递交起诉书，正式控告美国政府 8 月 6 日发布的与该公司及其母公司字节跳动有关的行政令违法。&nbsp;</p><p>2020 年 9 月，字节跳动与甲骨文（Oracle）达成协议，甲骨文将成为 TikTok 在美国的「可信技术提供商」，根据协议，甲骨文有权对 TikTok 美国的源代码进行安全检查。&nbsp;</p><p>为了适应美国市场和法规要求，可以看到 TikTok 采取了一系列数据本土化和透明度提升的行动，不断努力消除质疑。&nbsp;</p><p>甚至在这些行动之外，TikTok 在美国的电商运营也在走本土化路线。TikTok 身为一个国际化公司，首先并没有根据赚钱效率，首先为跃跃欲试的中国跨境电商在美国市场提供通道。实际上对中国卖家而言，TikTok 电商的准入条件和门槛并不低：&nbsp;</p><p>首先是需要<strong>定向邀约入驻</strong>：TikTok Shop 美国站点向跨境商家开启了定向邀约的入驻通道。这包括国内主体和中国法人的美国主体，合作方式是「商家自运营」模式。&nbsp;</p><p>其次在<strong>入驻要求上，</strong>中国卖家需要拥有美国营业执照（中国人占股超过 25%）以及 EIN 税号，支持美国本土发货，以及在其他跨境头部平台单店铺年 GMV 超过 200 万美金等。&nbsp;</p><p>TikTok 主要发力支持和促进美国本地的商业生态发展，这样的做法在一段时间内甚至引发了一些国内公司的不满。但这一选择背后正是 TikTok 电商选择更专注更本土化地落地于美国市场的考量，其目标是成为一家真正的国际化公司，支持好每一个地区的商业生态发展，而不是一家孵化自中国并旨在帮助中国商业全球扩张的公司。&nbsp;</p><p>TikTok 过去所做的一切其实都是希望其能够像一个本土公司一样发展——数据本土化，团队本土化，商业生态也本土化。&nbsp;</p><p>但即便 TikTok 努力构建了本土系统支持运转，从结果来看，只要 TikToK 母公司是中国公司的血统存在，这些都没能改变美国 政治环境对 TikTok 完全无视事实和公正的打压。&nbsp;</p><h2>让用户知情：Fight like a local company</h2><p>弹窗以号召用户给议员打电话撤销法案，在中国观众眼里这是很激进的做法，毕竟看起来这类行动可能会引发关于企业影响力影响政治的「质疑」。&nbsp;</p><p>但实际上，这只是 TikTok 在面对美国政府的挑战时，采取了一种类似美国本土公司的抗争策略。因为在美国，过往也有多家公司在面临法律挑战或政策变动时，曾号召过用户采取行动。&nbsp;</p><p>2012 年，在 SOPA（禁止网络盗版法案）和 PIPA（防止网络对经济创新和知识产权盗窃法案）讨论期间，Reddit 联合其他网站进行了一次大规模的抗议活动，包括暂时关闭网站，号召用户联系议员来反对这些法案。&nbsp;</p><p>同年，Twitter 用户发起了一场名为「Twitter Blackout」的活动，以抗议 SOPA 和 PIPA 法案。Twitter 鼓励用户参与，通过社交媒体平台发声。&nbsp;</p><p>2015 年，Uber 曾通过发送电子邮件等方式收集签名，动员用户和司机向当地政府和立法机构表达反对禁令的立场。&nbsp;</p><p>2016 年，当 Airbnb 在纽约面临严格的短租法规时，该公司通过其平台，鼓励用户联系当地议员，反对可能限制其服务的法律。&nbsp;</p><p>这些公司的行动通常是为了保护其商业模式、用户利益或反对可能影响其运营的法律或政策。通过动员用户，它们试图影响立法过程，以维护其在市场中的地位。&nbsp;</p><p>在这些抗争中，企业的逻辑都是「这些不合理的法令和决策会侵害用户的权益，我们需要让用户需要知情，并有权行动起来保护自己的权益」。&nbsp;</p><p>这完全不等同于企业利用影响力来干预政治，这只是商业领域合法的争取公平和公正的抗争，并且符合美国的政治体系（至少是法理上）——政治应该为选民的利益负责。&nbsp;</p><p>当然，此前没有任何公司发动过 TikTok 规模这么大的在全国范围内号召用户进行电话抗议的活动。&nbsp;</p><p>根据极客公园了解到的消息，这次行动的决策是由 TikTok 的本土团队做出的，很可能的原因是此次剥离法案的提出以及飞速进展表明，TikTok 此前的其他形式的抗争或者妥协都已宣告无效。即便是在去年 3 月那场以「国家安全和数据隐私」为主题的美国国会听证会后。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_0643f2719e914f1990af2eace8cc25bd@000000_oswg110447oswg1024oswg683_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2023 年 3 月，美国华盛顿，抖音首席执行官周受资在众议院能源和商务委员会听证会上作证｜图片来源：视觉中国&nbsp;</p><p>在这场听证会上，问询主要围绕「窃取隐私」以及「数据安全」等展开，TikTok 的首席执行官周受资经历了来自美众议院能源和商业委员会的时长 5 个多小时超 200 个问题的问询，而他本人仅有开场 6 分钟时间来完整阐述自己的立场，其余时间的回应都在 20 秒之内被打断。&nbsp;</p><p>问询中充斥一些荒谬的问题，例如有议员发问：TikTok 是否可以访问家庭 WiFi 网络？周受资回答：它将不得不访问网络才能连接到互联网。&nbsp;</p><p>这场透露出太多不专业内容的听证会让更多关心 TikTok 的美国用户加强了对 TikTok 的理解，同时也将美国法院关于 TikTok 的无端猜测和推演的荒谬性揭露在大众面前。&nbsp;</p><p>今年 2 月初的一场关于儿童安全的听证会上，荒谬再度重演。听证会进行到一半的时候，参议员 Tom CoTikTokon (R-AR) 反复让 TikTok 首席执行官周受资回答与当天听证会主题完全无关的问题——他的身份归属问题。&nbsp;</p><p>如今，不利局面再度出现——不仅威胁到了其正常运营和合法权利，更是对其用户群体产生切实不利的影响。&nbsp;</p><p>TikTok 决定「让用户知情，并鼓励用户保护自己的权益」的最合理时间点，可能就是现在。&nbsp;</p><p>一方面是过去两场听证会已经让其用户充分理解了 TiKTok 所面对的不公正质疑之荒谬；同时目前也是 TikTok 以在美国法律框架内进行合法的抗争的关键时刻。因为一旦该法案在参议院获得通过，它将正式成为符合美国法律的合法议案，届时局势将更难以扭转。&nbsp;</p><p>在这一天到临之前，在美国的法律体系里还有这么些许抗争空间之时，看似激进的行动，也是必要的自卫手段，因为相对于 TikTok 是中国公司还是美国公司这样的问题，它属于 1.7 亿美国用户是更好的回答。&nbsp;</p><p>毕竟，当一家公司退无可退，TikTok 已经没有什么可失去的，最差的结果不会比既定法案里将要通向的分拆这个结果更差了。&nbsp;</p><p>可以说，TikTok 团队已经在本地化上去做到了一切可以做的，甚至是像本土公司一样发动了用户力量来做合法抗争。&nbsp;</p><p>但在今天的美国 政治环境里，这个动作的直接效果也不能抱有太高的预期。但这也不是最后的时刻，可以预料，后续 TikTok 将会动用其完全本土化的律师团队，继续在美国的政治和法律体系里，用最本土化的方式进行持续的抗辩。&nbsp;</p><p>很多时候，抗争也未必收获最好的结果，但抗争也是为了给世界留下痕迹。毫无疑问，TikTok 背负了一个时代的压力，它也在努力给时代一个有意义的答案。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653035833&amp;idx=1&amp;sn=a583dcb8a964b2038c7d164dab3b5b64&amp;chksm=7f2cf99b094999608189f972639af84bcc346813835960480a410d7acb6c1f0973de7e7f49d1&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：连冉，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2685075343440900</id>
            <title>苹果在欧盟降低佣金的政策，也应当惠及中国开发者</title>
            <link>https://www.36kr.com/p/2685075343440900</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2685075343440900</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 11:40:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果税, 第三方应用商店, 佣金率, 应用侧载
<br>
<br>
总结: 苹果在欧盟地区宣布遵循数字市场法案，降低了苹果税和佣金率，开放第三方应用商店和第三方支付处理系统，允许应用侧载。这一举措对欧盟用户和开发者具有重大意义，也对全球数字经济反垄断立法产生影响。然而，这些变化对中国用户无效，苹果在中国区仍然保持高佣金率和封闭生态。对于中国开发者而言，苹果的政策限制了他们的发展空间，也引发了对苹果佣金率是否合理的讨论。 </div>
                        <hr>
                    
                    <p>今年1月25日，苹果正式宣布遵循欧盟《数字市场法案》(DMA)的规定，在欧盟地区对iOS、Safari浏览器和App Store进行更改。从今年3月开始，欧盟27个国家的用户及开发者将通过iOS 17.4 Beta版，开始享受新规定带来的好处。具体而言：&nbsp;</p><p>App Store将下调在欧盟范围内的数字商品和服务的佣金率（俗称“苹果税”），标准费率从30%大幅降低至17%；上述数字不包含支付处理费和核心技术使用费。</p><p>苹果将对欧盟用户开放第三方应用商店，通过苹果生态之外的网站安装应用（“应用侧载”），允许用户将第三方浏览器设置为默认浏览器。</p><p>苹果支付之外的第三方支付处理系统也被放开了。若开发者愿意继续使用苹果支付，则需另行承担3%的手续费，这是可以自由选择的。</p><p>毫不夸张地说，苹果在欧盟地区做出的让步是划时代的。此前，在美国、日本等国出现过多起针对苹果的反垄断诉讼，诉讼发起者包括Epic Games等著名应用开发商，它们的诉求大同小异：降低“苹果税”比例、开放第三方应用商店。很可惜，迄今为止，绝大部分诉讼并未产生实质性效果。苹果自我辩护的主要依据是“花园围墙”(Walled Garden)理论：与安卓那样的开源系统不同，苹果对其软件生态拥有绝对的掌控，从而确保了用户安全，还有助于将低质量的应用拒之门外。当然，苹果也做出了一些有限的让步，例如从2020年开始推出中小开发者计划，年收入（扣除佣金）低于100万美元的开发者可以享受较低的佣金率；在日本，阅读器类型的APP允许外部链接跳转。但是上述让步的影响非常有限，不足以让广大开发者满意。&nbsp;</p><p>这一次，苹果在欧盟做出的让步，与以前完全不同：苹果用户第一次可以光明正大的使用第三方应用市场了，应用开发者也可以在苹果软件生态之外光明正大地进行销售和促销活动了。对于欧盟乃至全世界而言，这是一个具备里程碑意义的数字经济反垄断立法。从今往后，苹果对欧盟范围内的App Store收入仅抽取17%的佣金，对中小开发者则仅抽取10%的佣金——降幅如此之大，显然是为了更好地与第三方应用市场竞争。不过，俗话说“羊毛出在羊身上”，佣金率降低的最大受益者还是普通用户。&nbsp;</p><p>而且，苹果在欧盟范围内“拆墙”的后续效果，对其他国家和地区的监管者具备深远的借鉴意义。因为过去多年，苹果拒绝“拆墙”的一个重要论据就是“封闭生态更有利于用户隐私和数据安全”。现在，iOS17.4 Beta版在欧盟的上线，提供了一次绝佳的实践机会：如果事实证明，苹果更改规定没有对用户安全造成显著的不利影响，那就证明苹果此前的自我辩护有夸大其次的嫌疑。可以想象，苹果在世界其他主要市场将面临越来越大的监管压力，甚至不排除会主动做出让步。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_2153f100c7a84748942c6cc095269275@000000_oswg75727oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>遗憾的是，苹果在欧盟做出的让步，对中国用户是无效的。作为苹果在全球的第二大收入来源国（仅次于美国），中国用户和开发者从未享受到苹果提供的任何“优待”。通过分析数据，我们可以看到，无论是与其他国家和地区横向对比，还是与国内安卓应用市场对比，苹果中国区的应用收入佣金率都显得过高：&nbsp;</p><p>苹果中国区App Store一直采取“全球通用佣金率”，即标准30%、中小开发者15%。没有对个别品类的优待，也没有使用第三方支付以降低费率的选项（请注意，通过苹果支付绑定微信支付和支付宝账户不属于“第三方支付”）。</p><p>苹果中国区严格禁止一切第三方应用商店，无法以任何方式进行应用侧载；虽然允许第三方浏览器，但是无法将其设置为默认浏览器。例如，国内著名游戏社区TapTap就因为被苹果认定带有“应用市场”属性，在iOS端举步维艰。</p><p>国内安卓手机厂商一般不对非游戏类应用收入抽成，对游戏则以联运的形式抽取30-50%。但是近年来，游戏厂商官服取代安卓渠道服成为主流。对于从官网或买量渠道下载的安装包，安卓手机厂商的控制力越来越弱，逐渐采取放任自流的态度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_77e88360b40e4e108964f98966261cf3@000000_oswg79475oswg1080oswg510_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>直至今日，中国开发者从苹果那里享受的唯一优待，就是中小开发者的15%佣金率，那是全球通用的标准。至于年收入超过100万美元（不含佣金）的开发者，无论应用性质、应用品类，都没有任何优待可言。禁止一切“应用侧载”，不仅让开发者背上了沉重的渠道成本，还造成了许多无法以金钱衡量的影响。例如，游戏厂商只能通过苹果TestFlight发布内测产品，从而导致对苹果用户内测的难度远远高于对安卓用户。应用开发商也不能在自身官方或第三方渠道向苹果用户提供差异化定价和折扣（至少不能公开宣传），其定价体系和促销能力受到了严重的制约。至于此前，苹果与一些社交媒体应用围绕“用户打赏需不需要缴纳苹果税”展开的争议，更是毋庸赘述——虽然苹果在这个问题上做出了让步，但它相对于应用开发商仍然居于绝对的强势地位。&nbsp;</p><p>不可否认，苹果应用生态为用户带来了诸多好处，使他们在享受多种多样的应用程序的同时，能够最大限度地免除不必要的风险和打扰。对于开发者而言，苹果用户平均收入较高、消费意愿较强，单用户价值一般而言高于安卓；苹果的手机硬件体系简洁明了，应用开发环境发达，为技术人员省去了很多麻烦，这就是大批应用开发商仍然要把苹果作为主要目标市场的原因。问题在于，上面的诸多好处是否足以支撑高昂的佣金率，以及对第三方应用市场“一刀切”的政策？尤其是对于中国这样一个发展中国家而言，考虑到宏观环境和互联网行业的现状，维持全球最高的佣金率谈得上合理吗？&nbsp;</p><p>无论从道义角度还是经济角度讲，最佳的选择当然是仿效“欧盟模式”，要求苹果中国区全面开放第三方应用市场及第三方支付渠道。在市场经济的规律下，只要广大用户具备了完全的选择权，苹果自然会主动降低佣金、增强对中小开发者的扶持（就像它已经在欧盟做过的一样），与第三方应用市场在竞争中达到平衡。但是，这样步子迈得太大，用户在短期内不一定能适应，肯定也会引发苹果方面的激烈反对。&nbsp;</p><p>另一种更可行的选择，则是降低苹果中国区的佣金率。既可以是全方位的降低，也可以是面向某些类型、某些赛道应用的降低；既可以是渐进式的降低，也可以是一步到位的降低。即便中国区的“苹果税”不能在短期内降低到欧盟区的水平（标准17%、中小开发者10%），哪怕向这个目标靠近一步，也足以让数以万计的开发者受益匪浅，并且向整个互联网行业传递积极信号。这是苹果能够做到、也应该做到的。&nbsp;</p><p>当然，促进用户自由、给开发者减负，不能以牺牲安全为代价。反欺诈、反黑产、保护用户隐私，这些需求是刚性的，也是数亿中国用户选择苹果的重要原因。我相信，中国的主管部门肯定也在密切关注苹果在欧盟区“拆墙”的经验，评估由此产生的风险以及如何应对这些风险。对于当前的中国而言，无论在技术角度还是立法、执法经验角度，找到用户自由、开发者减负和保护安全的平衡点，应该完全是可以做到的。&nbsp;</p><p>那么，这一切什么时候能开始呢？让我们拭目以待，希望不要等待太久。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzIxMDgyMTM0NQ==&amp;mid=2247497690&amp;idx=1&amp;sn=1506e92f4d57d400b2c73035c60b6af5&amp;chksm=96933261fee24e4a46895d2154a9a328889a72068b9b2e562eb7bcccdac8c863d9a3fbf48462&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“互联网怪盗团”（ID：TMTphantom）</a>，作者：怪盗团团长裴培，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2685013236940932</id>
            <title>奔赴大模型战场一周年，它们的市值涨了多少？</title>
            <link>https://www.36kr.com/p/2685013236940932</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2685013236940932</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 11:32:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 大模型, 市值, 企业
<br>
<br>
总结: 越来越多企业发布了2023年的财报，AI或者大模型带来的营收成为财报焦点。不同类型的企业在大模型领域的表现不尽相同，市值涨跌情况各异。平台派企业在大模型领域的布局和影响力备受关注，而垂直派企业则在生成式AI的垂直赛道上有所突破。企业在大模型领域的表现直接影响市值的波动，市场对于企业的AI布局和发展策略持续关注。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_4685f050634d4e6ab9de658fafcc8c26@000000_oswg704801oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>越来越多企业发布了 2023 年的财报，和往年最大的不同，AI或者大模型带来的营收，开始成为财报中的焦点。</p><p>这也为我们提供了一个新视角：<strong>不少企业的大模型已经开放了近一年时间，到底为市值带来了多大贡献呢？</strong></p><p>我们大致将国内的AI企业分为三类，分别是平台派、垂直派和创业派，一起回顾下过去一年里市值的涨跌情况。</p><h2>01 平台派</h2><p>平台派以互联网云厂商为主，ChatGPT出现后，他们的反应也最为迅速。不仅在模型层面高举高打，在平台服务上冲锋在前，还主动担当了市场教育和应用孵化的任务，俨然是一场不能输的“生死之战”，对市值的影响也最为直接。</p><p>鉴于阿里巴巴的业务布局过于广泛，腾讯在大模型赛道慢了半拍，字节跳动等巨头的动作比较低调，百度无疑是当前最佳的观察对象。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_188ee269de3b4e1da7b61abc39ca6297@000000_oswg231576oswg1080oswg724_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>时间回到2023年3月16日，百度顶住压力，正式推出了文心一言。可能是因为发布会现场没有实时演示，且未全面开放体验，舆论上出现了大量失望的声音，导致百度股价的跌幅一度超过 10%。</p><p>好在外部的失望情绪并未持续太久，百度股价在文心一言内测后开始止跌回涨。3月27日，百度推出了文心千帆大模型平台，涵盖百度全套文心大模型，和相应的开发工具链，百度的市值随即冲上过去一年的最高点。</p><p>但在接下来的两个月里，百度的股价呈现出了明显的下滑态势。直到5月份，其他厂商的对话式AI产品陆续内测，文心一言在国内有了明确的比较对象，再加上百度智能云在To B市场的一系列合作，股价才走出低谷，重新回到上升的势头。</p><p>2023年8月31日，文心一言在邀测五个多月后全面开放，百度市值出现短暂飙升，而后却陷入了近两个月的暴跌期。10月17日的百度世界大会上，文心一言4.0发布，笼罩在百度股价上的迷雾才逐渐消散。</p><p>整体来看，过去一年百度市值的跌幅超过 30%，文心一言以及百度在大模型、社区、开发者生态等方面的布局，并未对市值产生太大的拉升作用，甚至成了股价下跌的负面因素。比如在2024年1月15日，只因国内某研究实验室在百度文心大模型上测试AI系统，让投资者担心未来百度有可能被列入美国的制裁名单中，致使百度股价重挫超过10%。</p><p>其他平台派的市值表现也不太乐观。</p><p>阿里巴巴一年内的市值下跌超过20%，大模型带来的正面影响几乎可以忽略；腾讯市值下滑20%以上，外界关注最多的仍然是游戏和社交，而非混元代表的大模型技术。科大讯飞成了为数不多市值上涨的企业，星火大模型1.5版本发布后，科大讯飞的市值达到高峰，之后也没能逃过持续下滑的命运。</p><p>其中的原因有很多，比如文心一言等常常被拿去和ChatGPT等国外产品对比，对于“先天体弱”的国产大模型而言，显然不是什么好事情。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_d52d59e9f2c1465da03756f294578729@000000_oswg189047oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再比如市场倾向于为大模型的能力投票，而平台派的玩家们往往有着更宏大的战略布局。</p><p>参考IDC对百度AI布局的总结，形成了“模型+工具平台+生态”的三级协同结构，大模型作为底座，将大模型的能力打包成产品和API服务，赋能给开发者开发各种各样的功能，然后通过获取到的行为数据，不断反哺大模型的研发，有助于业务的良性循环， 也更容易形成竞争壁垒。</p><p>这样的布局有着典型的互联网思维，在继续互联网大厂赖以生存的平台模式。也许市场逐步认识到平台模式的价值后，会在股价上给出合理的价格，但在目前这些都还是一个未知数，平台派需要在能力上证明自己。</p><h2>02 垂直派</h2><p>区别于平台派难以掩盖的野心，一些中等规模的互联网企业瞄准了生成式AI的垂直赛道，基于原有的产品和场景，顺势踏进了大模型的河流。因为离实际的生产力更近，垂直派的价值也更容易被验证。</p><p>单从股价上看，美图可能是其中的一个异类，至少在2024年以前，美图似乎尝尽了AIGC时代的红利。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_dd4b826166f040299eec3f16a2fa9f8c@000000_oswg196861oswg1080oswg684_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2023年6月19日的第二届影像节上，美图一口气拿出了7款AI产品，涵盖了AI绘图、AI海报、AI 商品图、AI写真等多个AIGC场景。产品发布当天，美图的股价暴涨21.28%，呈现出了一条夸张的上抛线。</p><p>而在此前三个月，外界对美图的态度还是——“生死未卜”：在AI生图的时代，美图这样的企业是否还有生存空间？相应的，美图的股价从2023年3月份开始下滑，一直持续到了6月中旬的发布会前后。</p><p>美图股价的第二次高光时刻，源于2023年8月28日的中期业绩，营收增长了29.8%，净利润增长了3倍多。二级市场迅速投出了肯定票，美图的股价大幅回升，彻底告别了生死存亡的至暗时刻。</p><p>让百度们“嫉妒”的是，美图每一次公布和AI相关的新动作，市场都会给出积极回应，譬如美图自研AI视觉大模型MiracleVision(奇想智能)3.0版本和4.0版本的发布，在股价上都有直观的体现。</p><p>2024年1月22日发布2023年财报预告后，美图的股价再次蒙上了一层阴影，即使是收购站酷网这样的重磅决策，也未能挽回股价下跌的趋势。和去年同期相比，美图的股价兜兜转转又回到了起点。</p><p>同属于垂直派，网易有道和金山办公的股价表现，则要比美图“悲惨”的多。</p><p>2023年初，网易有道被曝开始推进AIGC在在教育场景的落地，并且已经在AI口语老师、中文作文批改等细分学习场景中尝试应用。折射到股价上，网易有道终于止住了2021年以来的颓势，重新回到上涨轨道。</p><p>可惜外部环境的红利，在2023年4月“嘎然而止”，网易有道随后陆续推出了教育大模型子曰、新一代学习机和翻译笔、虚拟人口语私教Echo等产品，但股价在过去一年中依旧下跌了50%以上。</p><p>金山办公的股价也相当魔幻。</p><p>可能是身处距离AI最近的办公场景，也可能是因为微软的示范，从2023年2月份开始，金山办公的股价一路上涨，直至6月20日突破历史最高点，把市值带上了2500亿的规模。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_e73c781eb63f4127b1803376831b9caa@000000_oswg181407oswg1080oswg674_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2023世界人工智能大会期间，金山办公旗下的的智能办公助手WPS AI正式亮相，成为国内协同办公赛道首个类ChatGPT式应用。恰恰是因为概念变成了事实，金山办公的AI故事迅速失去了吸引力，股价进入下行通道，2024年2月初一度下跌到210元以下，比历史最高点跌去了60%。</p><p>不管是美图、网易有道、金山办公，还是万兴科技等前面未曾提到的企业，他们的命运或多或少都在被风口裹挟，股价无不经历了过山车式的起伏。摆在他们面前的选择并不多，不去蹭AI的风口，大概率会被资本市场抛弃；选择蹭AI的风口，终归还是要回到产品体验上，回归基本面和成长性。</p><h2>03 创业派</h2><p>生成式AI照进来的曙光，让沉寂已久的创投圈迎来了新的兴奋点。按照奇绩创坛创始人陆奇的说法：这一次AI技术和商业结合的进化速度，自己只在1996至1997年的互联网产业中感受到过。</p><p>陆奇的判断并非空穴来风。</p><p>奇绩创坛2023春季路演日收到了7954家创业公司申请，最终有60个项目参与路演，创业者的平均年龄只有29岁，且超过一半的项目和大模型相关；奇绩创坛的秋季路演中，AI方向上有51家和大模型相关、34家与Agent 相关。</p><p>科技大厂们争相下场的2023年，也成了大模型创业的“元年”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_50307d07e61a4902aa4381bcabac5be0@000000_oswg256482oswg1080oswg543_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2023年10月，智谱AI宣布年内已累计融资超过25亿元，估值高达100亿元。仅仅是在7月到9月之间，智谱 AI 就完成了5轮融资，成为名副其实的独角兽。同期即有传闻称，智谱AI正以200亿元的估值进行新一轮融资。</p><p>同样是2023年10月，前搜狗公司CEO王小川创立的百川智能，宣布完成A1轮战略融资，金额为3亿美元，算上天使轮的5000万美元，百川智能的融资总额达到3.5亿美元。从创立到独角兽，腾讯花了6年时间，百川智能只用了6个月。</p><p>2023年11月，李开复创办的AI大模型创业公司“零一万物”，被传拿到了阿里云领投的新一轮融资，估值已超10亿美元，跻身独角兽的时间，比百川智能还要快一个月。而在2023年底时，零一万物被曝正在筹集最多2亿美元的新资金。</p><p>2024年2月，月之暗面被媒体报道称已完成新一轮超10亿美金融资，估值约25亿美金，创造了国内AI大模型公司的单轮最大金额融资。</p><p>如果只看以上信息，大模型创业的黄金时代已经到来，即将开启下一个遍地神话的创业浪潮。可在硬币的另一面，目前估值达到10亿美元的大模型创业公司，除了上面提到的4家，似乎只剩下不久前拿到6亿美元融资的Minimax。</p><p>所谓的“大模型五虎”，无不有着过硬的背景，或是李开复、王小川这样的商业领袖，或是自带光环的学术大牛，他们拿走了大模型领域40%以上的融资。<strong>其他上百家大模型创业公司，只有两成不到拿到了融资，且基本是种子轮或天使轮，大模型创业的第一个年头，就显现出了典型的二八定律。</strong></p><p>一个更加残酷的事实在于，截止到2023年11月，国内已经有200多个大模型，几乎每天都会有新的大模型诞生。除去科技大厂和学术机构，不少大模型出自新成立的创业团队，而大模型偏偏是资本高度密集，人才高度密集的赛道，那些没有拿到巨额融资的团队，结局可想而知。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_1b32f713077f486e81c3b22bf3ffe93b@000000_oswg325089oswg708oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>李彦宏、王小川等人，曾不只一次高呼：创业者不应该去做大模型，而是做出一个好的AI原生应用。观察了大半年的投资者也纷纷坦言，后面将主要关注大模型应用层项目。<strong>可惜目前应用层项目的估值大多在1亿美元以下，远不如大模型企业耀眼。</strong></p><p>比起平台派和垂直派，能否在一级市场拿到可观的估值，直接关系着创业者生与死。而从大模型技术的进程来看，当下还只是在起步阶段，需要经历一次次的过滤分层，注定是一条艰难的创业之路。目前还没有机构去统计大模型创业的死亡名单，但有理由相信，这个名单会很长很长。</p><h2>04 最后的话</h2><p>单单从市值或估值衡量一家公司的价值，显然不是一个严谨的选择，却是一个无法回避的现实问题。</p><p>股价起起伏伏的背后，反映了市场信心的增减，至少现阶段已经证明：不同于以往技术创新的漂浮感，普通人只能雾里看花般地旁观，生成式AI为普罗大众打开了通往未来的大门，也就意味着，想要用大模型概念提振股价，必须要在体验上直面用户，耐心应对一次次用脚投票。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MjQwNTgwOQ==&amp;mid=2649709281&amp;idx=1&amp;sn=7c60575fa6227ee66d1a0d5205cefece&amp;chksm=86c3f1b6a60172b41d91b3c4ad70ecbbe624d890d2b4608e192166f05e851b394b6c28f44137&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“Alter聊科技”（ID：spnews）</a>，作者：顾青云，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2685013898150021</id>
            <title>多了AI功能，中国用户就会买三星的账？</title>
            <link>https://www.36kr.com/p/2685013898150021</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2685013898150021</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 11:17:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI手机, 三星Galaxy S24系列, 中国市场, 本地化合作
<br>
<br>
总结: 三星Galaxy S24系列以AI手机为卖点，在中国市场推出并进行本地化合作，希望借此夺回市场份额。然而，高昂的价格、竞争激烈以及用户对AI手机认知不足等因素可能影响其在中国市场的表现。 </div>
                        <hr>
                    
                    <p>凭借全球首款 AI手机的概念，三星Galaxy S24系列创下了新的销售记录。2月28日，三星公布的数据显示，其最新发布的Galaxy S24系列在韩国开售仅28天销量便突破100万部，刷新了S系列销量最快破百万纪录。可见，AI手机已经成为了三星在2024年最重要的一张王牌。&nbsp;</p><p>在中国举办的一场产品沟通会上，三星详细介绍了Galaxy S24系列的AI功能，主要包含三大方向：翻译、搜索和影像。其中翻译功能被强调得最多，包括通话实时翻译、同传等翻译应用，主要应对商务和出国等场景，搜索主打“即圈即搜”，即使用时无需进入某个特定应用，可随时圈点图标进行搜索，而影像的特点在于智能“填充”图片，可提升日常拍摄的“成功率”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_17f3561ea36241c3858a0f7b2514d280@000000_oswg321923oswg1080oswg661_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：三星官网</p><p>AI手机被三星寄予厚望，在此前的三星Galaxy Unpacked 2024新品全球发布会上，三星电子移动通信部门总裁卢泰文称，三星Galaxy S24系列为未来十年移动设备的创新指明了方向。Galaxy AI（三星自研AI技术）基于用户使用习惯打造，我们期待通过Galaxy AI帮助世界各地的三星用户发现更多可能性。</p><p>即便三星Galaxy S24系列增加了AI功能，但中国用户会为此买单吗？</p><h2>01.三星打响AI手机第一枪</h2><p>2024年1月18日，三星正式发布了Galaxy S24系列手机，与往年卷芯片、卷屏幕、卷影像等不同，今年AI功能成为了三星新的发力方向。</p><p>借助三星自研的Gauss Language（高斯语言）、Gauss Code（高斯代码）和Gauss Image（高斯图像）模型，Galaxy S24系列实现多项AI功能，以“即圈即搜”功能为例，该功能借助云端AI智能获取海量信息，将移动互联网上的信息变成用户唾手可得的内容库，无论用户面对的是文本、图片还是视频，长按home键唤醒后，通过圈选手势，即可快速获取搜索结果，无需退出当前应用，也不用思考搜索关键词，“即圈即搜”打破了单个应用程序的信息孤岛，通过AI盘活了移动互联网时代的数据信息。</p><p>AI手机的作用不止于此，其最直接的价值，是全面提升手机的性能和使用体验。</p><p>当AI与手机进行结合之后，一方面能增强手机处理图像、语音、自然语言处理等任务的能力，显著增强手机性能和可用性；另一方面能更灵活地响应用户需求，提升使用体验，且随着AI算法的进化，手机将对用户进行更为全面和深入的了解，从而预测用户的行为并提前进行反应，变得更智能。</p><p>与此同时，AI融入手机也能为三星提供额外的收入，毕竟会员费是AI大模型目前的核心收入来源，市面上最火的ChatGPT Plus会员要收取19.9美元/月，谷歌Gemini Pro是每千个字符0.00025美元，每张图片0.0025美元，输出每千个字符0.0005美元。根据三星官网披露的信息，三星目前的计划是2025年底之前，在受支持的设备上免费提供Galaxy AI功能，后续将对AI功能收费。</p><p>过去几年，智能手机行业陷入疲软，用户换新率不断下降，很大程度上是因为产品缺乏革命性的创新，而AI手机的出现，或将成为开启行业上行周期的机遇。</p><p>卢泰文表示：“我们正在准备采取措施，加强所有领域的竞争力，以重新夺回市场份额。与上一代产品相比，我们预计Galaxy S24系列的销量将实现两位数的增长，相信人工智能手机从零开始就能击败苹果。”</p><p>三星Galaxy S24系列上市之前，有媒体曝光了三星对于Galaxy S24系列的出货量预计：三星Galaxy S24系列的总计出货量预计将达到3500万台，其中高端机型S24 Ultra的出货量预计将达到1600万台，基础版S24的出货量预计为1350万台，而S24+的出货量则预计为580万台。</p><p>尽管三星打响AI手机第一枪，但三星能否借助AI手机夺回在中国市场的失地，仍是一个未知数。</p><h2>02.急需在中国市场翻盘</h2><p>借助搭载了Galaxy AI的Galaxy S24系列，三星试图收复一些在中国市场的失地，并为此进行了本地化探索，比如三星宣布Galaxy AI中国本土化合作方为百度、WPS、美图等公司。其中百度智能云成为三星在中国市场的Galaxy AI生态战略合作伙伴，美图基于自研AI视觉大模型MiracleVision与三星相册进行合作，WPS的AI能力将用于帮助用户生成文档。</p><p>本地化探索的背后，显现出三星急于在中国市场翻盘的决心。2023年，苹果手机出货量2.346亿台，同比增长3.7%，市场份额为20.1%，而三星手机出货量为2.266亿台，同比下滑13.6%，市场份额为19.4%。蝉联全球手机出货量第一名多年的三星，被苹果一朝夺走了宝座。</p><p>三星想要扭转颓势，中国市场是必争之地。根据分析网站StatCounter的数据，2024年1月，三星在中国市场的占有率仅为1.3%，相比排在第一名且占有率高达16.5%的小米，反映出了三星在中国市场的表现较为疲软。</p><p>三星寄希望于Galaxy S24系列能够改变现状，但不容忽视的是，即便加入了AI功能，中国用户或仍难以为此买单。</p><p>首先是性价比的问题，三星Galaxy S24系列共有三款机型，分别是S24、S24+和S24 Ultra，起售价分别为5999元、7499元和10199元，其中S24 Ultra最贵的版本达到了13199元。然而三星手机价格相对高昂，性价比不足，尤其是在二手手机市场上，跌价幅度较大，这使得用户在购买时可能更倾向于选择性价比更高的国产手机，而且国产手机在产品设计和功能设计上更符合中国用户的需求。</p><p>此外，还有一点不容忽视，即目前AI手机还处于初步发展期，用户对于AI手机普遍感知不深，比如在微博、小红书等社交平台上，不少用户对于AI手机仍颇为疑惑，诸如“手机里加个大模型就能叫AI手机了？”“AI功能实际上就是手机厂商卖高价的噱头”等言论比比皆是。</p><p>其次是三星手机在中国市场正面临着激烈的竞争，尤其是AI功能“登机”，在国内手机市场已然成为主流发展趋势，比如vivo自研的“AI蓝心大模型”已在自家中端机落地；OPPO发布了首个端侧应用70亿参数大语言模型手机Find X7；荣耀发布了MagicOS 8.0操作系统以及自研的70亿参数端侧AI大模型“魔法大模型”；星纪魅族宣布停止传统“智能手机”新项目，全力投入明日设备AI For New Generations；苹果CEO蒂姆・库克也在年度股东大会上表示，苹果将在2024年在生成式人工智能领域“开辟新天地”。</p><p>目前，国产手机品牌以及苹果在中国市场的竞争趋于白热化，其凭借对中国市场的深入了解和强大的供应链优势，不断推出具有创新性和竞争力的产品，从而吸引了大量用户，相比之下，占有率常年维持在1%左右的三星几乎毫无还手能力。</p><p>尽管三星Galaxy S24系列在韩国市场销售火爆，但三星想要重夺失去的中国市场份额，仍面临着不小的难度。</p><h2>03.留给三星的时间不多了</h2><p>AI手机有望加速行业换机潮的到来。</p><p>国泰君安表示，全球巨头加速布局AI手机，刺激新一轮换机潮；国金证券指出，AI手机热潮来袭，继续看好AI及需求转好产业链；中航证券认为，AI仍将成为未来高端智能手机最大的亮点。</p><p>AI手机的想象空间巨大。根据IDC的预测，在2024年起，新一代AI手机销量将会大幅度增长，并带动新一轮换机潮，2027年AI手机出货量将达到1.5亿台，市场份额超过50%。Canalys也预测，2024年全球AI手机将占智能手机出货量的5%，到2027年这一比例将上升至45%。</p><p>Counterpoint Research称，2024年AI手机出货量初估将超过1亿部、2027年预估达5.22亿部，期间的平均复合年增率达83%。同时Canalys也在中国AI市场趋势洞察报告中提到，防守市场份额并开发新的功能已经成为行业重点，而AI恰好是这一战略转变中的关键因素。</p><p>不过，这场换机潮的得利者，或许并不是三星。随着OPPO、vivo、小米、华为、荣耀等手机厂商的AI手机崛起，三星的先发优势势必会逐渐被削弱，毕竟从2017年至今，三星在中国市场始终一蹶不振，无论销量，还是市场份额均不见起色。</p><p>一位智能手机行业人士向DoNews表示，无论智能手机还是AI手机，最核心的竞争力还是对用户的洞察。谁对用户最理解，谁真正地懂产品，谁就能在竞争中保持差异化并突出重围，而三星的本地化程度始终一言难尽，售价也不亲民，售后问题频出，这意味着三星想要夺回中国市场的失地，实际上是心有余而力不足，难以重现往日荣光。</p><p>“目前看来，AI手机的噱头大于实质，AI在影像、翻译、识别等方面的应用，并不是杀手级应用，AI手机的本质是让手机变成一个拥有智慧的超级平台，显然三星未来还有很大的发展空间。”该行业人士表示。</p><p>不可否认的是，AI手机确实能帮助三星夺得一些市场份额，但想要挽回中国用户，仅靠AI手机远远不够，其还需要在渠道、营销、产品力、售后等方面下足苦功夫。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkwMDUwNzEwNA==&amp;mid=2247602994&amp;idx=1&amp;sn=9741fb3c05df8e36f31391d49953a8f9&amp;chksm=c1d44bf933ab98105fc9b35a08b15fb45b85416b54cf6c829d9a41ce6fac70ce8a297ea560fb&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“DoNews”（ID：ilovedonews）</a>，作者：张宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684982958428041</id>
            <title>让马斯克嫉妒的男人，OpenAI“第一投资人”：AI硬件是“伪命题”</title>
            <link>https://www.36kr.com/p/2684982958428041</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684982958428041</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 11:03:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克, OpenAI, Vinod Khosla, AI
<br>
<br>
总结: 马斯克对OpenAI提起诉讼，Vinod Khosla认为马斯克是吃不到葡萄就说葡萄酸。Khosla投资眼光犀利，对AI充满信心，认为AI将彻底改变世界。他投资了Rabbit这样的AI硬件公司，认为人机交互将通过语音界面实现，软件将适应人类。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_01e5320a93af485d8a6cf99771a687e4@5238864_oswg60316oswg1080oswg611_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>引言</h2><p>最近，马斯克怒写46页诉状，将OpenAI及 Sam Altman 告上法庭，并要求OpenAI恢复开源状态。对此，OpenAI“第一投资人”，被称为全球科技“投资之王”的Vinod Khosla表示，马斯克是典型吃不到葡萄就说葡萄酸。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_5d3ca62cff7241ebb15db46bf92317b0@5238864_oswg369066oswg830oswg451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然Vinod Khosla有句名言：“一个方案有90%的机率失败不是问题，只要还有10%的机会获得100倍的收益”。</p><p>然而，他本人的投资眼光却可谓毒辣。1990年代，Khosla投资了瞻博网络，并建议其开发一种“互联网路由器，而不是当时更常见的普通路由器”。据《华尔街日报》报道，Kleiner Perkins对瞻博网络的300万美元投资为他带来了70亿美元的收益。</p><p>2019年，当OpenAI从一家非营利研究组织转变为“有盈利上限”公司，Khosla大胆地迈出了第一步，其创立的投资机构Khosla Ventures在种子轮向OpenAI投出高达5000万美元。该金额是Khosla Ventures成立十五年来任何一笔投资规模的两倍。</p><p>至少从10年前开始，Khosla就坚信，AI将彻底改变世界。他认为：未来20年，AI有可能在80%的人类角色中承担80%的工作量，并创造巨大的经济价值。</p><p>上周，Khosla分享了自己对AI 交互与革命的最新洞察《How AI Will Change Our Relationship With Computers》（The Information）。<strong>这位科技“投资之王”表示：“AI硬件” （AI hardware） 和“小工具”（gadgets）等术语更像是一种“误用”。</strong>不妨抛开“设备”的局限，讨论在人机交互变革的大背景下，将会发生哪些根本性变化？适道在不影响原意的情况下，对文章进行了简译和补充改写。</p><h2>01 语音主导界面，软件将学习人类</h2><p><strong>第一个根本性变化——低延迟语音将成为人机交互的主导界面。</strong></p><p>想象一下，比起用手指戳半天屏幕，延迟在半秒内的语音显然更加便利。与此同时，“无声语音”技术也在迎面走来。当你在公共场合中，无需发出声音就能和设备进行互动，不干扰他人，也能保护隐私。</p><p><strong>第二个根本性变化——软件将适应人类，而不是人类学习软件。</strong></p><p>到目前为止，我们总是在自适应软件——学习APP的复杂设计，记住层次化的菜单，并以此与机器交互。未来，我们不再需要像学习使用 Uber 或SAP、Oracle 这样的复杂系统一样，去学习如何使用这些APP。</p><p><strong>综上，新一代硬件将结合二者特征——实现语音互动、能够学习人类语言和人类本身。</strong>虽然处理某些视觉任务可能仍然需要屏幕，但核心交互将转向语音——无论是无声的还是有声的。</p><p>Khosla指出：前苹果首席设计官Jony Ive和Sam Altman讨论过一个AI硬件项目，甚至在ChatGPT出现之前，大家就预言会出现这种界面。虽然早期热度很快消退了，但他们的方向是正确的。问题出在，他们没有充分关注AI所带来的全新用户体验。</p><h2>02 延迟不低的Rabbit何以得到Khosla青睐？</h2><p>前段时间，初创公司Rabbit在CES 2024上发布了其手持式AI硬件产品——R1，售价199美元，上线5日就卖了5万台，近1000万美元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_e197479f8244401dbc8f65f4be2dba45@5238864_oswg341645oswg830oswg553_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>和此前出圈的Ai Pin类似，Rabbit R1也采用紧凑小巧的设计，并标配了麦克风、摄像头，不需要连接手机，没有内置 App。不同的是，Ai Pin没有屏幕，选择“投影”显示，看起来更酷炫；Rabbit R1则是搭载了一块 2.88 英寸的触摸屏，更为稳妥。</p><p>Rabbit R1的定位为AI Agent，用户在不需要手机的情况下能够完成很多任务：叫车、放歌、订餐、订酒店，甚至在Midjourney 上生成图片。CEO吕骋（Jesse Lyu）在实测操作中，只需说一句“Play Feel Good Inc”，这首歌就能直接播放；对着屏幕中Discord论坛，问一句“大家都讨论什么”，Rabbit R1就可以对“看”到的内容进行总结。</p><p>Khosla本人正是Rabbit的早期投资人，投资金额高达千万美元。<strong>在文章中，Khosla给出了投资Rabbit的理由：“Rabbit是人机交互在强大AI世界中的早期尝试——设备通过自然语言，用语音与计算机（或称为“代理”）进行交流。”</strong></p><p>Khosla举了个自己的例子，当他徒步时，会使用“Picture This”APP识别自己遇到的植物，但这个过程很麻烦：停下来，暂停有声读物，打开应用，拍照，等待答案加载，关闭应用，将手机放回口袋。有了新设备，Khosla只需将设备指向植物并问：“这是什么植物？”就会得到答案，然后继续听正在播放的有声读物。</p><p>不过，Khosla可能要“等上一阵”。外媒爆料，有拿到真机的网友发现，Rabbit R1会在收到问题后说一句“让我看看”，接着就是20秒的无事发生，这延迟显然不符合Khosla定义的“半秒内”。</p><p>但根据CEO吕骋在访谈中的回应：Rabbit OS并非像ChatGPT一样的大语言模型LLM，而是基于大动作模型（Large Action Model）开发。LAM能够使AI学会人类操作各种APP的方式，并通过与LLM结合，从而实现“用户发指令——AI执行”的效果。因此，Rabbit OS更像一个通用的APP控制器。</p><p>如果用户仅使用LAM涉及的功能。例如，播放一首歌；询问“橙子和橘子的区别”等任何不需要搜索最新信息的任务，Rabbit响应速度会非常快，几乎在0.5秒以内。但如果涉及使用OpenAI，例如搜索最新信息，速度就会变慢，一般在7——8秒，涉及视觉则会更慢。不过，吕骋表示，这已经是目前行业内最快的速度。</p><p>Khosla本人似乎对Rabbit的目前的“延迟”不太在意，他更在意的是“让AI代替人与APP交互”，并对Rabbit OS 基于LAM“跨APP工作”能力大为赞赏：<strong>这代表传统范式将完全颠覆，意味着最终我们不必与软件交互，因为AI 将替我们这样做。</strong></p><p>但新的问题来了，Rabbit为何不以一种“APP”的形式出现在手机中？就像智商更高的Siri？</p><p>吕骋从创业者的角度给出了答案：首先，虽然Rabbit可以成为一款APP，但如果Rabbit只是个APP，就意味着苹果公司能接触到代码，无异于分享了公司的知识产权。其次，团队不得不同时为iOS和Android开发维护这款APP，这还需要大量的持续资金投入。最重要的是，当Rabbit会被放在和其他APP一样的平台上，会给自己带来了不安：如果明天出现了一个更好的应用怎么办？用户忠诚度几乎为零。</p><p>那么，如果Siri自己变成高智商呢，还需要Rabbit R1吗？吕骋表示：问题不在于技术，而在于商业模式，因为iPhone不可能一夜之间没有AppStore。而Rabbit R1可没有内置 App。</p><p>对于Rabbit R1的定位，吕骋给出了一个靠谱的描述：AI时代的iPod。</p><p>试想，在非智能手机时代，你会一个裤兜装手机，另一个裤兜装iPod。未来，或许会一个裤兜装iPhone，另一个裤兜装AI Agent。</p><p>但正如吕骋恐惧“下一个更好的应用”，如果下一款更快的AI Agent出现呢？毕竟，199美元的售价像是买了个付费的“AI app”。用户或许也可以花不高的价格买到下一款更好用的“AI app”，如此一来，建立在Rabbit R1上的拓展业务也将不再存在——“人们教Rabbit来做他们自己的事情，本质上是在创造Rabbit，而不是使用APP，当用户销售他们自己的Rabbit时，Rabbit OS将会从中抽成。”</p><h2>03 AI Agent会是下一个iPhone吗？</h2><p>结合文章，适道发现一个新角度——AI时代的社交媒体将走向何方。</p><p>吕骋表示：还有很多事情我宁愿去手机上查看，至少目前是这样。首先是重要的社交功能；另一部分是专业的群聊。</p><p>Khosla则指出：手机现在的设计是为了分散我们的注意力。如果我在徒步旅行时拿出手机，我会看到我的电子邮件、短信和其他通知；我会被拉到某个社交平台上，看到广告，甚至可能陷入一个兔子洞，无意冒犯。</p><p><strong>而这些新设计，比如Rabbit旨在节省时间和减少干扰。你告诉它要做什么，它就只做那些，没有多余的。</strong></p><p>Gartner最新预测，到2025年，50%消费者将“放弃或大幅限制与社交媒体的互动”。在 Gartner去年夏天的一项调查中，53%的消费者表示，社交媒体在前一年或过去五年中变得更糟。</p><p>有趣的是，根据传播学中的“媒介即讯息”，随着AI时代的到来，新一代AI Agent是否会摧毁iPhone所创造的社交媒体时代？“一个与真人分享的社交空间”是否将会终结？如果能，那么，人类当前由“社交媒体”承载的“娱乐时间”又将投向何方？这其中又将蕴含哪些新“钱景”？</p><p class="editor-note">本文来自微信公众号“适道”（ID:survivalbiz），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684945488362500</id>
            <title>芯片行业，没电了</title>
            <link>https://www.36kr.com/p/2684945488362500</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684945488362500</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 10:33:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 芯片, 能源消耗, 可持续发展
<br>
<br>
总结: 近年来，人工智能行业的快速发展引发了对芯片和电力供应的关注。芯片制造过程中的高耗电量问题日益凸显，对电力供应和碳排放造成挑战。特别是台积电等大型厂商的耗电量庞大，对电力供应的稳定性提出了严峻考验。为了应对这一问题，芯片行业需要加大对可再生能源的应用，提高能源效率，以实现更加可持续的发展。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_4c050adfafc34df0b9147240de74bb53@46958_oswg287229oswg889oswg513_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>近年来，人工智能行业迅速发展，芯片作为其核心组件，一直备受关注。然而，在博世互联世界2024大会上，特斯拉CEO埃隆·马斯克提出了一个观点：到了2025年，困扰AI行业的可能不再是芯片的短缺，而是电力供应的紧张。与此同时，多家媒体报道芯片代工大厂台积电也迎来电费难题。据报道，中国台湾考虑将台积电电价上调至多30%。&nbsp;</p><p>芯片制造是一个高度复杂和能源消耗巨大的过程。从熔化硅开始，到使用大功率激光进行光刻，再到创造和维护真空状态，以及持续清洁工作，每一个环节都需要大量的电力支持。据统计，半导体制造厂每小时的耗电量高达100兆瓦时，相当于8万多户北美家庭的用电量。这意味着，随着人工智能行业对芯片需求的不断增长，电力供应压力也将日益增大。&nbsp;</p><p>随着人工智能的快速发展以及应用，针对它的耗能问题也产生了诸多讨论。人工智能有多耗电？每生成9张照片消耗的能量，就可以充满一部手机。&nbsp;</p><p>人工智能开发商Hugging Face和卡内基梅隆大学研究人员组成的团队，利用一款名为Code Carbon的自研工具，对HuggingFace Hub上16个最受欢迎的开源模型进行了能量消耗和碳排放数据的比较。数据显示生成式AI每生成1000次图像所消耗的电量在0.06至2.9千瓦时（kWh）之间，中位数接近1.35千瓦时。相比之下，为普通智能手机充电所需的能量仅为0.012千瓦时。这意味着，生成大约九张（中位数）人工智能图像所消耗的能量，便相当于为一部充满电的手机提供能量。如果用户使用效率最低的图像生成模型，那么每生成一张图片所消耗的能量便足以充满一次普通智能手机，最糟糕的情况下甚至能充满两次。&nbsp;</p><p>高耗电量背后意味着碳排放的升高。&nbsp;</p><p>随着模型规模的扩大和生成图像质量的提高，所需的能耗和碳排放量也将进一步增加。耗电量背后关系到的是碳排放问题，每张图像生成过程中产生的二氧化碳排放量在0.1至0.5克之间，异常值甚至可能达到2克二氧化碳。这意味着，生成1000张图片所产生的排放量相当于一辆普通汽车行驶6.5公里所产生的排放量。&nbsp;</p><p>人工智能在图像生成方面的能耗和碳排放问题不容忽视。&nbsp;</p><h2>台积电消耗全岛7%电力</h2><p>让我们进一步看看芯片行业的耗电问题。&nbsp;</p><p>2020年，台积电EUV光刻机用电量就达100亿度，占台积电总用电量的50%以上。台积电不断扩充先进制程，就要一直增设光刻机，造成用电需求年年增长。&nbsp;</p><p>台积电2020年用电量为160亿度，约占台电售电量的5.9%；2021年用电量快速成长至191.9亿度，占台电售电量的7.2%，用电成长率高达20%，用电量超过了拥有270多万人口的台北市。据德勤预计到2025年，仅台积电一家公司就将占中国台湾整体能源消耗的12.5%。&nbsp;</p><p>此外，晶圆制造需要超净的生产环境，整个超净间需要制冷和恒温将稳度控制在22℃左右，每天超净间的正常运作都将消耗大量的电能；为了要热处理设备和离子设备来处理芯片生产过程中产生的高温，这部分涉及到的功耗也极其惊人。据德勤估计，到2028年，台积电占据中国台湾的电量消耗可能达到惊人的15%。&nbsp;</p><p>随着全球气候变化和能源转型的推进，电力供应的稳定性已经成为一个全球性的问题。面对如此巨大的耗电量，对于芯片行业来说最大的问题是，供电不稳将直接影响工厂产量。尤其是在发展中国家，电力供应不足和不稳定的问题尤为突出。此前，英特尔曾搁置越南投资计划的原因就是“对越南电力供应稳定程度感到担忧”。&nbsp;</p><p>在这样的背景下，如果人工智能行业继续以当前的能源消耗速度发展，那么电力供应紧张的问题很可能会成为制约其发展的瓶颈。此外，电力供应紧张还可能对人工智能行业的可持续发展带来挑战。随着人们对环保和可持续发展的日益关注，越来越多的企业和国家开始将绿色能源作为发展的重点。然而，如果人工智能行业的能源消耗持续增长，那么其对于绿色能源的需求也将不断增加。这可能会使得绿色能源的供应变得更为紧张，从而影响整个行业的可持续发展。&nbsp;</p><h2>没有电，就没有芯片</h2><p>回到台积电的耗电量，仅台积电在中国台湾的工厂消耗就如此之大，可想而知全球晶圆厂的耗电量的规模。晶圆厂的高耗电量原因有许多，当然最直接的一点就是没有电就造不出芯片。&nbsp;</p><p>更具体地去看，芯片行业对用电的要求是略微苛刻的。&nbsp;</p><p>在用电特性部分，台积电需要24小时连续制程，属全时段用电，年负载率高达80%~90%。其中，在先进制程产能部分，大概率处于满载状态，生产工厂的日用电曲线分布，应该是全日都维持用电尖峰。同时，随着制程的更新，以及产量扩大，台积电的用电量还会增加。&nbsp;</p><p>为了确保台积电供电稳定，台电在竹科、中科及南科都有配套供电措施，竹科是有通宵电厂、离岸光电来支援；中科是台中电厂加上离岸风电，南部没有离岸风电，南科是以台电兴达电厂为主要电力来源。这个概念是台电电厂直接对台积电有关的科学园区，为了保证台积电的生产，有关部门提供了双保险，通过用双回路来防范断电意外发生，确保台积电连续生产过程不受干扰。即使有意外发生，台积电自己也有备用的发电设备。&nbsp;</p><p>如此高的用电量，对于芯片企业来说，其背后的低碳需求日益增长。芯片行业为了更绿色也尝试了各种探索。芯片行业可采取的措施包括提升除当前芯片制造工艺外其他工艺流程的能源效率和速度：例如，LEED认证建筑，该行业十年来一直使用该技术来提高可持续发展能力。美国LEED体系是一个国际性绿色建筑认证系统。&nbsp;</p><p>当然其中最为重要的依旧是绿色电力的应用。据德勤数据电可再生能源可使该行业晶圆厂的能源消耗强度（瓦时/美元）从2020年的近240降至2022年的 219，预计2024年将降至206。此外，可再生能源使用比例预计将以高于能源消耗强度降幅的速度上升：预计到2024年，可再生能源将占能源构成的28%，是2020年的两倍。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_4497ed2e6f784c2b891e692ba07ed9aa@000000_oswg220783oswg722oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>说到底，电力问题、能源问题都是环保议题。越来越多的企业将自己的环保“KPI”提上台面。英特尔于2022年4月宣布致力于实现温室气体净零排放。（温室气体）排放；到2030年，将供应链温室气体排放量与无投资及行动情况下的排放量相比减少30%；同时提高能源效率，降低我们产品和平台的碳足迹。台积电在CSR(永续)报告中表示，未来非生产性的用电，到2030年要100%的绿电，但是生产性的用电只能使用25%绿电。&nbsp;</p><h2>环保，不仅仅是省电费</h2><p>随着科技的不断进步和全球电子市场的持续扩大，半导体产业正以前所未有的速度发展。对于半导体企业来说，提高可持续性不仅是一种社会责任，更是一种商业回报。在未来的发展中，半导体企业需要不断加强在环保和可持续发展方面的投入和创新，以适应日益严峻的环境挑战和市场需求。在当今这个日益关注环保和可持续发展的时代，半导体企业面临着前所未有的挑战和机遇。随着全球对绿色能源和环保意识的日益增强，半导体企业在生产过程中对绿电的成分和比例受到了越来越多的关注。对于半导体公司而言，环保意识不仅仅是一种社会责任，更是一种商业回报。提高可持续性不仅有助于企业的长期发展，还能带来诸多实际利益。&nbsp;</p><p>为了实现这一目标，半导体企业可以采取一系列措施。首先，加强技术研发和创新，推动绿色生产技术的研发和应用。通过研发更加环保、高效的生产技术，可以进一步降低能源消耗和减少环境污染。其次，建立完善的绿色供应链管理体系，确保供应链中的每一个环节都符合环保和可持续发展的要求。此外，加强员工培训和意识提升，培养一支具备环保意识和可持续发展理念的团队，也是至关重要的。&nbsp;</p><p>通过降低能源消耗和减少废物排放，企业可以显著降低生产成本。其次，随着社会对环保意识的提高，提高可持续性有助于半导体公司吸引和留住人才，同时也能赢得更多消费者的信任和支持。此外，提高可持续性还有助于降低半导体供应链的脆弱性，确保供应链的稳定和安全。&nbsp;</p><p>在半导体产业的人才竞争中，环保同样占据重要地位。半导体行业正面临与其他多个行业的技术型人才争夺，因此保持优良的环保记录显得尤为重要。特别是在吸引年轻员工方面，具备良好可持续发展记录的公司更具吸引力。根据德勤2023年对Z世代和千禧一代的调研结果显示，有六分之一的受访者已经因气候问题更换工作或行业，而另有四分之一的受访者计划在未来这样做。这一趋势表明，环保和可持续发展在半导体产业人才招聘中的重要性不容忽视。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247704266&amp;idx=1&amp;sn=dee2845fa65f1624ecb7947971c50291&amp;chksm=c0506b2a865e65d6f33343840593dda145fe1145592a494519291b0bef7ee06d33d53cb6a42e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：六千，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684877349257345</id>
            <title>拿初心说事儿，马斯克给奥特曼和Open AI上压力</title>
            <link>https://www.36kr.com/p/2684877349257345</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684877349257345</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 10:03:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 马斯克, 诉讼, AGI
<br>
<br>
总结: 马斯克对OpenAI提起诉讼，指控其违背初衷，涉及AGI风险、公司结构变化等问题。OpenAI回应驳斥指控，表示致力于开发安全有益的AGI。马斯克与OpenAI之间的冲突源于对公司发展方向的分歧，马斯克希望控制权并将其并入特斯拉。马斯克的诉讼行为与其过往商业策略相符，展现出其追求利益最大化的一贯风格。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_3a83b6d5bd354948b359ff24f6bdd89a@000000_oswg459995oswg800oswg411_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>“天下熙熙，皆为利来，天下攘攘，皆为利往。”——《史记》</strong></p><p>事物的发展总是曲折向前的，科技的发展总是伴随着是是是非非，前有OpenAI CEO兼联合创始人Sam Altman上演现代宫斗大戏争权夺位，今有特斯拉的马斯克公堂喊话别忘初心。</p><h2>01 事件始末</h2><p>美国时间3月1日，马斯克在旧金山高等法院提起诉讼，将OpenAI CEO兼联合创始人Sam Altman、Greg Brockman以及整个OpenAI公司告上法庭，用46页的诉讼文件控诉OpenAI违背了创立时非盈利的初衷，自己是怎么被OpenAI欺骗，要求赔钱、恢复开源。其控诉主要围绕以下几点:</p><p>1.AGI的风险</p><p>2.OpenAI，Inc. 的创始协议</p><p>3.2023 年违反创始协议</p><p>4.马斯克担忧AGI落入坏人之手</p><p>5.马斯克在让OpenAI起步方面发挥关键作用</p><p>6.Altman和Brockman一再重申创始协议</p><p>7.OpenAI的公司结构不断变化</p><p>8.OpenAI技术的发展——从AI到AGI</p><p><strong>表面上看，马斯克是在讲Open AI违背初衷的过程，但是诉讼文件中有句话很直接：“然而，事实上，OpenAI 公司已经变成了世界上最大的科技公司——微软的一个封闭式子公司。</strong>在新董事会的领导下，微软不仅在开发 AGI，而且实际上正在改进 AGI，以使微软的利润最大化，而不是为了人类的利益。”司马昭之心路人皆知。</p><p>针对马斯克长篇累牍的控诉，Open AI选择了“硬刚”，美国时间3月6日，OpenAI正式作出回应，并附上了几封与马斯克通信的电子邮件。回应要点如下：</p><p>1.OpenAI 致力于开发安全有益的 AGI 并推动其利益广泛分配。</p><p>2.OpenAI 计划驳回马斯克的所有指控，并分享与马斯克关系的真实情况。</p><p>3.开发 AGI 所需的资源远超预期，马斯克曾建议宣布 10 亿美元的初始资金承诺，但实际向OpenAI 提供的资金不足 4500 万美元，其他捐助者提供了超过 9000 万美元。</p><p>4.OpenAI 意识到为实现 AGI 需要巨额资金，每年可能达数十亿美元。</p><p>5.马斯克提出与特斯拉合并或完全控制 OpenAI，但最终选择离开并支持 OpenAI 自行筹资。</p><p>6.OpenAI 创建了盈利性实体以继续使命，马斯克希望拥有多数股权和控制权，但双方未能达成一致。</p><p>7.OpenAI 的使命不要求开源 AGI，马斯克理解并同意这一点。</p><p>8.OpenAI 对马斯克提起诉讼表示遗憾，尽管他曾激励团队设定高目标，但现在却成为竞争者并提起诉讼。</p><p>9.OpenAI 专注于推进其使命，期待部署系统以赋能每个人。</p><p>基本上OpenAI将马斯克的诉讼要点一一驳回，但事件到此并未结束，也暂未有新的进展，估计Open AI的实锤让马斯克焦头烂额，马斯克正在想着怎么回应。</p><h2>02 缘起与冲突</h2><p>马斯克与Sam Altman的相遇始于2015年。Sam Altman时任投资机构Y Combinator总裁，牵线马斯克与就职于谷歌的科学家Ilya Sutskever会面。当时，马斯克正在宣扬自己的“AI威胁论”，认为需要尽快成立一个公益组织预防AI的灾难性影响，而Ilya所就职的谷歌在AI上强大而保守，可能控制垄断AI而受到争议。</p><p>马斯克的主张对于技术理想主义者具有相当的吸引力，于是马斯克与Sam Altman一拍即合。2015年底，马斯克、Sam Altman及其他投资者共同出资创立了OpenAI。</p><p>成立之初的那几年，Open AI似乎还没有摸到发展的火门，研发OpenAI Five在《Dota2》中虐人类选手、刷新游戏纪录；做公益，研究防止恶意使用AI；搞小众赛道，使用古早时代的单向语言模型做预训练，这样的小打小闹就别说拳打谷歌、脚踢Facebook了。</p><p>Open AI当时的状况与马斯克的预期差得太远，2017年末，马斯克和其他人一致认为，需要创建一个盈利性实体，以盈利支撑Open AI建立AGI需要的海量计算资源。此时，马斯克借机表示希望拥有多数股权、初始董事会控制权，担任Open AI的CEO，主张将OpenAI和特斯拉合并，但Sam Altman和其他联合创始人并不接受此建议。于是在2018年2月，马斯克被Open AI董事会投票出局，但马斯克宣称还会继续提供资金资助和指导。</p><p>2019年3月，Open AI成立了一个营利性部门OpenAI LP，用于筹集外部投资，并具备了科技初创公司的属性，而公司则意味着需要有盈利。但微软也是通过这个部门向OpenAI 投资了约130亿美元。</p><p>根据Open AI公布的邮件显示，马斯克在邮件中建议宣布起步资金承诺为10亿美元，自己将补足其他人未能提供的部分。但马斯克在任期间仅为Open AI捐赠了4400万美元。</p><h2>03 马斯克的一贯策略</h2><p>马斯克其实是最想快速盈利的商人，在Open AI成立之初那几年，投入了4400万美元后见未能快速起效，就打算获得Open AI控制权，并着手将Open AI并入特斯拉，用于特斯拉的生产。<strong>而马斯克现在的诉讼却在控诉OpenAI违背了创立时非盈利的初衷，实属有些不符合常理。</strong></p><p><strong>可是纵观马斯克以前打过的官司，似乎这一切又是清晰的：</strong></p><p>1、早年马斯克创业特斯拉的时候，对汽车界设计大师菲斯克的设计非常倾心，专门上门拜访，并送去了一辆布加迪威龙作为礼物，诚邀菲斯克为特斯拉设计“白星”。二人一拍即合，马斯克对菲斯克有求必应，但是菲斯克在获取了特斯拉的诸多技术细节后，自己成立公司迅速推出了“卡玛”车型。</p><p>马斯克在2008年将菲斯克告上法庭，但由于马斯克未签订排他协议，仲裁听证认定马斯克对菲斯克的指控是毫无根据的恶意毁谤，马斯克败诉。</p><p>2、马斯克造火箭是人尽皆知的业务，但从2013年开始，亚马逊创始人贝佐斯和马斯克都想要打造可重复使用的火箭。2014年，贝佐斯旗下公司申请了注册了火箭回收的专利，马斯克得知后立即诉讼，贝佐斯同意撤销专利。</p><p>3、马斯克在商业上最大的手笔就是收购Twitter，当时马斯克在收购时提出要求，必须降低10%收购价格，而Twitter给出的方案仅愿意降低4%价格，收购推进艰难。期间，Twitter的高管和董事会一致坚持不管如何谈判，都必须保护他们未来免遭马斯克的诉讼。马斯克利用这一点，宣称要起诉Twitter，认为Twitter董事会和管理层在机器人账户上撒谎。但最终马斯克在律师的说服下放弃起诉，按原价收购。最后，马斯克接管了推特，他达到了收购目的，而推特前首席执行官等一众人马被离职。</p><p>纵观马斯克提起的诉讼，有输有赢，但始终遵循一个原则，就是在自己处于不利局面的时候，通过法律的方式，达到遏制竞争对手，心理威慑对手等目的。<strong>诉讼不是一定要赢，而是要高调表达自己的明确态度。</strong></p><p>此次马斯克起诉OpenAI，其核心逻辑也是一样。先下手为强，高调表达自己的态度，不求赢但主打一个就是恶心你一把，可是Open AI不吃那一套，“硬刚”回应，邮件记录实锤。</p><h2>04 马斯克到底是不是“渣男”？</h2><p>通过对此次马斯克诉讼OpenAI整个事件的梳理以及对马斯克过往的诉讼的判断，<strong>笔者得出了一个形象的比喻：马斯克的行径很难称得上是坦荡的君子。</strong></p><p>马斯克与奥特曼的相遇，两人惺惺相惜，一拍即合，就像两小年轻看对眼了，然后坠入爱河，一起许下了革命誓言，成立Open AI，要一起对抗这世界的不公（谷歌）。</p><p>两口子一起创业打天下，创业的过程中，奥特曼几经盘算，要对抗这世界的不公需要花不少的钱财，于是提出要想办法挣点钱，马斯克嘴上同意给钱，心里想的却是怎么将现有的创业成果攥手里，最后当然是闹掰分手了。分手时，马斯克还不忘唱一句：“只要你过得比我好，过得比我好，什么事都难不倒”。</p><p>分手后奥特曼找了新对象——财大气粗的微软，还对奥特曼言听计从，奥特曼事业蒸蒸日上，的的确确过得越来越好。</p><p>这下马斯克看不下去了，转头就来责问奥特曼，说好的当初要一起对抗世界的不公，你忘了最初的梦想了吗？</p><p>奥特曼通过以前的邮件记录回应，似乎也表明了一种态度——“你别说话，你就是个渣男。”</p><h2>结 语</h2><p>笔者认为，诉讼是商业竞争中实现竞争目的，维护自身利益的途径之一，但是不能成为表达个人态度的工具，这其实本身是违背了法律的严肃性。</p><p>就此次诉讼事件中暴露的问题，笔者的结论是不论Open AI如何发展，最终都会走上盈利的道路。因为Open AI发展需要的海量计算资源是需要巨量的资本来支撑的，而资本本身就是逐利的。至于OpenAI的盈利之路是否能走通，ChatGPT的月活超过1亿，用户超过1.8亿，且日益增长的数据已经告诉了我们答案。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzIwOTQwMDEyMA==&amp;mid=2247501643&amp;idx=1&amp;sn=546ecc2abfb61777b01eb36a3ac8a839&amp;chksm=96231b94c7dcb16de89929f229ee72bba57a2e9c92fad74b1ebcadfa2ee9e6851c6ac605f1b6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“来咖智库”（ID：laikazk）</a>，作者：三寿，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684858940592004</id>
            <title>荷兰的“造芯”帝国</title>
            <link>https://www.36kr.com/p/2684858940592004</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684858940592004</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 10:01:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 荷兰, 光刻机, ASML, 技术
<br>
<br>
总结: 本文介绍了荷兰ASML公司在光刻机领域的重要性和影响力。光刻机是芯片制造的关键设备，ASML公司垄断了高端光刻机市场，特别是极紫外（EUV）光刻机。文章还探讨了ASML公司的历史起源和发展过程，以及全球光刻机市场的格局变化。通过介绍ASML公司的故事，展示了技术创新和市场竞争对科技产业发展的重要性。 </div>
                        <hr>
                    
                    <h2>【前言】</h2><p>荷兰的风车缓缓转动，切割着时间的流沙，仿佛在诉说着历史的恒久。</p><p>在这些古老风车的守望之下，时代正以不可逆转的步伐向前迈进。新技术在这片土地上萌芽，科技的浪潮悄然涌动，世界唯一的不变就是变化。</p><p>我们渴望与世界同行，渴望推开那扇窗，让外界的光影和气息涌入我们的心房。在这扇窗的外面，我们看到全球产业的风云变幻，如同一部精彩的史诗。那些先行者的智慧、宝贵的经验，都是可以汲取的鲜活力量。</p><p>当全世界都把目光投向美国这个芯片产业的巨头，更确切地说，是投向英伟达那永远在攀高峰的股票；我想带大家走进荷兰这个欧洲小国，探秘它的“造芯”帝国，揭开ASML——全球光刻机制造巨头的神秘面纱。</p><p>虽然这些精密的芯片制造过程似乎与我们的日常生活有些遥远，但它们却在无形中编织着时代的脉络，影响着我们每一个人的未来。</p><p><strong>正如站在那些风车之下，我们仰望着风向的每一次微妙转变，期待着每一次变革带来的新希望。</strong></p><p>希望我们能一起，在这个变化的世界中，寻找能引领我们前行的力量。</p><h2>【开篇】</h2><p>光刻机，用半佛仙人老师评价瑞幸的经典话术来讲，乃是&nbsp;“芯片产业的开山鼻祖 ▪ 半导体世界的造梦者 ▪ 纳米工艺的奠基石 ▪ 高科技制造业的皇冠明珠 ▪ AI时代的幕后功臣 ▪ 让人疯狂的印钞机”&nbsp;。</p><p>没有光刻机，就没有芯片；没有芯片，就没有风靡全球的AI热潮。</p><p><strong>全球最顶配的光刻机，来自荷兰，来自它的企业ASML（阿斯麦）。</strong></p><p>为什么研发出最顶配光刻机的，不是芯片巨头美国，也不是早在90年代消费电子产业就颇为发达的日本？今天我们来聊聊~</p><h2>01、什么是光刻机？</h2><p>光刻机，可以理解为一台超级精确的“光的打印机”。<strong>它需要在一片指甲盖大小的硅片上，刻画出极其细小的电路图案。</strong>其精细程度，可能只有头发丝的几百分之一。</p><p>我们一般听得比较多的是技术名词是：<strong>纳米制程</strong>。比如5纳米制程、7纳米制程、14纳米制程、28纳米制程。<strong>数值越小，芯片性能越高。</strong></p><p><strong>如果没有光刻机，就没有芯片的诞生。</strong></p><p>如果没有光刻机，硅片只是硅片，一块平平无奇的化学材料，不会拥有惊人的计算力量，也不会拥有驱动手机、电脑、汽车等智能设备的能力。就像铜如果不铸成导线，就只是一块柔软的金属；铁如果不锻造成机械，也只是一堆沉重的矿石。</p><p><strong>光刻机的体积，相当庞大。</strong></p><p>目前全球最新、科技含量最高、今年1月初刚刚到达英特尔俄勒冈州一家工厂的ASML光刻机——ASML Holding NV，<strong>重达15万公斤，相当于两架空客A320飞机，</strong>整个系统的安装过程需要250个板条箱、250名工程师和六个月时间才能完成；预估组装完成后有3层楼那么高，需要英特尔新建一座更高的晶圆厂来容纳它。</p><p><strong>光刻机的价格，比黄金还贵。</strong></p><p>一台光刻机多少钱？我们要用的计量单位是亿，货币单位是美元。</p><p>2018年，中芯国际下单了一台ASML的EUV（极紫外线）光刻机，售价高达1.2亿美元（折合人民币7.7亿元），几乎耗尽了中芯国际2017年的净利润。然而，因为众所周知的原因，这台设备至今还没有交付。</p><p><strong>没有最贵，只有更贵。</strong></p><p>新款光刻机不仅在纳米级别突飞猛进，在售价上的增速也快得让人瞠目结舌。</p><p>刚刚提到的英特尔拿下的最新款ASML光刻机，价值3.5亿欧元（3.8亿美元）。按照目前的人民币汇率算，大概接近27亿人民币。</p><p>这对于卖光刻机的大厂——ASML来说，这台“光的打印机”，就像永不停歇的印钞机，带来源源不断的丰厚回报。</p><p><strong>制造光刻机的大厂那么多，为什么全球科技巨头都在买ASML（阿斯麦）？</strong></p><h2>02、市场格局的改变</h2><p>全球的光刻机销售市场，被三家企业占据了90%以上的份额：<strong>荷兰的ASML，日本的尼康，日本的佳能。</strong></p><ul><li>这三家企业具体来看，如果仅从销售量来看，荷兰的ASML占据63%，日本的佳能占据30%，日本的尼康占据7%；</li><li>但如果从销售额来看，荷兰的ASML更是一家独大，占据91%；日本的佳能占据6%，日本的尼康仅占据3%。</li></ul><p>因为荷兰的ASML，<strong>牢牢占据了高端光刻机的市场。</strong></p><p><strong>ASML垄断了最高端的极紫外（EUV）光刻机市场，拥有100%市场份额。</strong></p><p>这个极紫外（EUV）光刻机，<strong>能够适配7nm到5nm制程芯片的设计制造，目前全球只有ASML能够生产这种设备。</strong></p><p>而在其他高端光刻机领域，如ArFi、ArF和KrF技术（不理解没关系），ASML也分别占据了95%、87%和72%的市场份额。</p><p><strong>事实上，ASML不是一开始就这么强的，起步晚，早有对手跑在前方。</strong></p><p>但在高科技领域有一个神奇的规律——</p><p><strong>起跑的先后顺序，并非决定胜负的关键。</strong></p><p>ASML的前身只是飞利浦公司里的一个实验室小组。没错，就是那个卖电动剃须刀的飞利浦，它也是一家荷兰的企业。所谓实验室小组，就是试水创新型项目，成功了起飞，不出业绩的随时拜拜。</p><p>光刻机是未来之光，这谁都懂。可20世纪80年代初，飞利浦的财务状况陷入困境，这个光刻机小组只能成为弃儿。</p><p>1984年，飞利浦与一家已经在美国上市的荷兰本土半导体企业ASM共同出资成立了ASML，正式把光刻机小组独立出去。</p><p><strong>1984年，ASML成立的这个时间点，比行业巨头晚了大约20年。</strong></p><blockquote><p>美国和日本的巨头早在上世纪60年代就开始了光刻机的研发：</p><p>美国的GCA公司，在1961年推出了第一台接触式光刻机；</p><p>日本的尼康和佳能，也早已开始研发光刻机，更何况他们俩是光学领域的强者，各种专业级相机设备畅销全球。而光刻机的核心部分之一就是光学系统，它需要精确地将电路图案投影到硅片上。因此，日本的尼康和佳能在光刻机领域也相当有优势。</p></blockquote><p>不过，美国的GCA公司没敌过1984-1986年的经济衰退；日本的尼康和佳能也输在了“干式光刻技术”和“浸没式光刻技术”的选择上。</p><p><strong>2000年代初，全球半导体行业遇到了一个困难——从193纳米波长到157纳米波长，无法突破。</strong></p><p>也就是说，现有的光刻机技术，无法刻画出更精细的芯片。</p><p>如果把光源比作笔，把硅片比作画纸，你需要用笔在画纸上描绘越来越精细的线条。此时，笔尖已经很细了，线条也已经很细了。但是当你想画更细的线条，笔尖又没法变得更细，这该怎么办？</p><p>于是，台积电的林本坚博士提出，用<strong>“浸没式光刻技术”</strong>替代当时很流行的<strong>“干式光刻技术”</strong>——即在“笔”和“画纸”之间增加一层水，用水替代空气，利用水的折射作用，缩短光的波长，从而让“这支笔”画出更精细的图案。</p><p>林博士有了想法，需要找公司帮忙研发。</p><p><strong>但同行们纷纷拒绝，比如日本的尼康和佳能。</strong>他们在“干式光刻技术”已经投入巨大，不想再轻易转换一种前景不明的新技术路径。这也跟日本当时大部分企业的心态一样——经历了失去的10年，不再愿意加大投资，所有决策都偏向于保守。</p><p><strong>而当时的荷兰小厂ASML选择了尝试——</strong></p><p>他们与台积电共同合作，研发并推出了第一台浸没式光刻机。</p><p><strong>ASML凭借浸没式光刻机，快速蚕食光刻机的市场份额。</strong></p><ul><li>2007年，ASML配合台积电的技术方向，发布了首个采用193nm光源的浸没式光刻系统TWINSCAN XT:1900i，一举垄断市场。</li><li>2010年，ASML的光刻机销量占全球销量比例已经上升到了68.9%。</li></ul><p><strong>而ASML与台积电，也由此成为了一对好兄弟。</strong>ASML向台积电供应光刻机，台积电量产先进芯片，完美双赢。如今，台积电也持股着ASML，并且获得ASML的EUV光刻机的优先购买权。</p><p><strong>事实证明，起步晚并不是那么重要。</strong></p><p>因为在高科技领域，后发选手随时有可能开辟出一条全新的赛道。当然，这需要时间与技术的积累。如果能研发出下一代颠覆性产品，一切为时未晚。</p><h2>03、高攀不起的尖子生</h2><p>在这场无声的科技竞赛中，ASML（阿斯麦）就像一位遥不可及的学霸，吸引了全球科技巨头们纷纷为它氪金，只希望能在AI这场角逐中跑赢其他的选手。</p><p><strong>ASML被誉为“摩尔定律的忠实守护者”——</strong>它把不可能变成可能，不断推动着“造芯”技术的极限。</p><blockquote><p>摩尔定律是指，芯片上的微小部件（晶体管）的数量每18个月~24个月翻一倍。也就是说，我们的电脑、手机或其它电子设备大约每2年可以翻一倍性能，成本也会降低。</p></blockquote><p>芯片的面积是有限的，可以容纳的晶体管也是有物理极限的。</p><p><strong>但是，ASML再次奉上了奇迹，让摩尔定律的故事可以继续讲下去——</strong></p><p>ASML在与台积电联手研发了“浸没式光刻技术”之后，<strong>又推动了“EUV光刻技术”的发展，成为目前全球唯一能够量产EUV光刻机的厂商，牢牢抓住了光刻机的高端市场。</strong></p><p><strong>EUV光刻机，就像一位精通微雕艺术的大师。</strong></p><p>原本，科技巨头们造芯片，采用的是深紫外光源（DUV）。而这一次，ASML采用了极紫外光源（EUV），波长仅为13.5纳米，比传统的深紫外光源更短，更能够在硅片上雕琢出精细的电路图案。</p><p>好比我们原本已经有一支极为精细的画笔，能够在纸上画出非常细小的图案。但是现在人们想要画出的图案越来越精细，普通的画笔已经无能为力。因此，ASML选择了一支特殊的笔，这支笔采用了特殊的墨水，拥有更高的凝聚性，不易扩散，从而可以画出前所未有的精细图案。</p><p><strong>EUV光刻机的问世，让ASML在业内拥有了无可撼动的领导地位。</strong></p><p><strong>ASML彻底把光刻机高端市场抢过来了，占据了EUV光刻机市场100%的市场份额。</strong></p><p>这款顶尖新品，限量发行，供不应求，而且价格昂贵，不仅为ASML贡献了超过一半的销售额，而且也让ASML的全品类市场份额扩大到了91%。</p><p><strong>全世界都形成了共识——要想造最好的芯片，就买ASML的光刻机。</strong></p><p>ASML的光刻机，也不是你想买就能买，每年交付的EUV光刻机数量仅有两位数。</p><p>想买EUV光刻机，那还得排着队，即使愿意花上亿美元，也要排期到几年后。</p><p>从飞利浦的弃儿，到如今的光刻机霸主，ASML用实力诠释了，什么是“今天你对我爱答不理，明天我让你高攀不起”。</p><h2>04、全球资本的暗流涌动</h2><p>光刻机的霸主之位易主，如同世界洋流的转向，时刻发生着变化，在潜移默化间重塑了全球芯片产业链的版图。</p><p>旧的格局被打破，新的联盟在激流澎湃中孕育而生，每个身处其中的玩家都只有在新的不确定性中找到自己的位置。</p><p><strong>在20世纪80-90年代，日本的尼康和佳能在半导体领域有着显著的影响力。</strong></p><p>那时，全球光刻机产业链的资源自发地向日本流动，日本的设备企业为全球提供了大约37%的半导体设备。</p><p>日本的半导体设备企业在多个关键领域几乎处于垄断地位，包括电子束描画设备、涂布/显影设备、清洗设备、氧化炉、减压CVD设备等重要前端设备，以及以划片机为代表的重要后道封装设备和以探针器为代表的重要测试设备。</p><p><strong>当ASML崛起之后，全球芯片产业链的格局也在悄然改变。</strong></p><ul><li><strong>EUV光源技术，</strong>由美国的Cymer（已被ASML收购）提供；</li><li><strong>光学镜头，</strong>由德国的卡尔蔡司提供；</li><li><strong>电子束检测设备，</strong>由美国的HMI（已被ASML收购）提供；</li><li><strong>工业精密机床技术，</strong>由瑞典的Enskog等公司提供。</li></ul><p><strong>全球光刻机产业链经历了一场地理转移，从以往的日本为中心逐渐转向欧美地区。</strong></p><p><strong>产业链的迁移，也在无声中推动着世界秩序的演变。</strong></p><p>ASML依赖于多种关键技术和组件，比如最高端的EUV光刻机，其光源技术来源于美国的Cymer（现为ASML的子公司）。此外，光刻机的其他关键部件，如先进的光学镜头、精密机械部件和计量设备，也可能依赖于美国或其他国家的供应商。</p><p>只要产品中包含美国技术或组件，那么在出口时就要遵守美国的出口限制。</p><p>尽管Cymer已经是ASML的子公司，但它在美国的法律地位和运营仍然受到美国法律的约束。美国出口管制法规适用于所有在美国境内运营的公司，无论其所有权结构如何。</p><p>海明威在《老人与海》中写道，「海洋深处，大鱼游动，它们在水面下形成了暗流，而老人知道，这场斗争才刚刚开始。」</p><h2>【写在最后】</h2><p>就在前天（3月7日）有多家媒体报道，ASML计划从荷兰迁往其他国家或向海外大举扩张。</p><p>想要离开的原因是，荷兰潜在的反移民政策。ASML在荷兰的总计2.3万名员工中，非荷兰籍员工占比约40%，其中留在荷兰就业的海外留学生是公司主要劳动力来源之一。如果未来的政策风向是限制移民，ASML可能会撤出荷兰，去往法国或其他国家。</p><p><strong>ASML想要走，荷兰政府抖一抖。</strong></p><p>毕竟ASML作为全球最大的光刻机制造商、半导体产业“皇冠上的明珠”、7nm及以下芯片所需EUV光刻机的全球唯一供应商，给荷兰带来的经济效益是巨大的。</p><p>ASML是走是留，对全球科技行业的影响都是巨大的。</p><p>世界如同一片汪洋，我们都是在其中航行的船只，有时风平浪静，有时波涛汹涌，永远不知道下一刻会遇见什么。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ePQz_nhla5TgkVlnisR9RA" rel="noopener noreferrer nofollow" target="_blank">“叁言梁语”（ID:Whispering22）</a>，作者：VinkyLiang，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684985807322120</id>
            <title>大摩看涨叠加AI利好，「宁王」股价爆拉超14%｜市场要闻</title>
            <link>https://www.36kr.com/p/2684985807322120</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684985807322120</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 10:00:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 作者, 编辑, 宁德时代, 股价
<br>
<br>
总结: 3月11日，宁德时代股价大涨，创业板指数也上涨。摩根士丹利将宁德时代评级上调至“超配”，预计股价还有上涨空间。宁德时代准备通过新一代生产线提高成本效率，摩根士丹利认为宁德时代是行业首选股。外资唱多，宁德时代利好不断，基本面过硬。2023年度业绩预告显示净利润增长，全球动力电池市场份额提升。 </div>
                        <hr>
                    
                    <p>作者丨耿宸斐</p><p>编辑丨宋婉心</p><p>3月11日，动力电池龙头宁德时代股价大举上攻，盘中涨幅一度达14.97%，报181.65元/股。截至收盘，宁德时代报180.85元/股，涨14.46%，市值达到7956亿元。</p><p>统计数据显示，这是自2021年1月4日后，宁德时代首次涨超10%。宁德时代成交额更是在午后突破100亿元，为2023年6月15日以来首次。</p><p>在宁德时代股价暴涨的带动下，创业板指今日一路飙升，收涨4.6%。</p><p>此前一日，摩根士丹利发布报告，将中国电池巨头宁德时代（CATL）的评级上调至“超配”，并设定目标价为210元。但截至3月8日收盘，宁德时代报158元/股，由此看，宁德时代股价距离目标价还有超过30%的上涨空间。</p><p>摩根士丹利分析师Jack Lu团队认为，美国《通胀削减法案》对宁德时代造成的不利因素似乎已被消化。随着价格战接近尾声，宁德时代准备通过新一代大规模生产线提高成本效率，这有望扩大其在净资产回报率方面的优势。该团队表示，他们看到宁德时代的基本面出现多个拐点，选择其作为行业首选股。</p><p><strong>“随着成本效率的提高和资本支出周期的放缓，我们将宁德时代视为价值股和提款机，其自由现金流收益率将从2024年的6%增至2026年的10%。”摩根士丹利在报告中称。</strong></p><p>尽管投资者担心中国消费需求疲软，但摩根士丹利预计，对宁德时代电池的需求将保持良好，使用宁德时代电池的电动汽车在未来一年的销售前景强劲，新车型或将增加订单。</p><p><strong>在摩根士丹利看来，宁德时代可能是“长期的摇钱树”。</strong>其分析师团队预计宁德时代2024年的利润率可能好于市场预期，在2024年第一季度增速放缓之后，该公司将在未来几个季度恢复同比息税前利润增长。</p><p>惠誉此前曾评论，对研发的高投入以及对其他终端市场的多元化将使宁德时代保持其技术领先地位，并增强其相对于本地和海外同行的竞争优势，预计宁德时代将在2024年至2026年保持两位数的收入复合年增长率。</p><p><strong>除却外资唱多的因素影响，宁德时代近期利好不断。</strong></p><p>其一，人工智能芯片制造商英伟达创始人兼首席执行官黄仁勋和OpenAI创始人山姆·奥特曼对光伏和储能板块的关注引发市场广泛关注。</p><p>据北极星储能网，黄仁勋在此前一次公开演讲中指出，人工智能（AI）的未来发展和状态与储能紧密相连。“AI的尽头是光伏和储能！我们不能只想着算力，如果只考虑计算机，我们需要烧掉14个地球的能源。”</p><p>在这一点上，山姆·奥特曼与黄仁勋不谋而合。他认为，未来AI技术的发展将高度依赖于能源，特别是光伏和储能技术的进步。</p><p>其二则是宁德时代北京电池工厂的最新进展。上周五晚间，北汽蓝谷发布公告称，宁德时代、北汽海蓝芯、京能科技、小米汽车四方将设立合资公司，在北京投资建设电芯工厂。宁德时代将在合资公司中持股51%，北汽海蓝芯持股39%，京能科技和小米汽车各自持股5%。</p><p><strong>诸多利好刺激固然成为宁德时代本轮上涨的重要原因，但“宁王”自身基本面过硬则更是关键性因素。</strong></p><p>宁德时代2023年度业绩预告显示，其归母净利润为425亿元—455亿元，比上年同期增长38.31%至48.07%；扣非净利润为385亿元至415亿元，比上年同期增长36.46%至47.09%。</p><p>此外，SNE Research的数据显示，2024年1月，全球动力电池装车量为51.5GWh，同比增长60.6%，环比上涨71.7%。宁德时代电池装车量为20.5GWh，与去年同期10.9GWh相比，增长88.1%，保持全球第一。1月，宁德时代的动力电池市场份额达到39.7%，与去年同期相比提升5.8%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_4dbf293cfb1645d8a45c8697cd065af1@5892437_oswg166482oswg901oswg518_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">关注获取更多资讯</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684851886521353</id>
            <title>目标3-6个月赶超Sora，「爱诗科技」获达晨亿级A1轮融资 | 36氪首发</title>
            <link>https://www.36kr.com/p/2684851886521353</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684851886521353</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 09:59:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 爱诗科技, 视频大模型, 王长虎, Sora
<br>
<br>
总结: 本文介绍了视频大模型公司"爱诗科技"的创始人王长虎以及公司的发展历程，以及他们在AI视频生成领域的技术路线和产品应用。王长虎认为当前市场上的视频大模型还有很大的发展空间，而公司也在不断努力追赶和超越行业领先者Sora。通过介绍公司的产品PixVerse和其在国内外市场的运营情况，展示了爱诗科技在视频生成领域的创新和发展。 </div>
                        <hr>
                    
                    <p>文｜武静静</p><p>编辑｜邓咏仪</p><p>36氪获悉，视频大模型公司「爱诗科技」近日已完成亿级A1轮融资，本轮融资由达晨财智独家投资。光源资本担任独家财务顾问。公司称，资金将主要用于底层视频大模型的技术研发及团队搭建等方面。</p><p>2024年2月，OpenAI发布Sora之后，在视频大模型行业掀起了新的风浪，爱诗科技也因此受到广泛关注。</p><p>爱诗科技由字节跳动前视觉技术负责人王长虎创办于2023年4月，专注于打造全球顶尖的AI视频生成模型及应用，并服务于营销、广告、游戏等内容创作行业。</p><p>王长虎是人工智能领域的专家，也有丰富的产品经验。他博士毕业于中国科学技术大学，2009年毕业后，担任过微软亚洲研究院主管研究员，曾在新加坡国立大学担任研究工程师。2017年初，王长虎加入字节跳动，任人工智能实验室总监、集团视觉技术负责人，搭建了视觉技术团队和视觉算法平台和业务中台，并支撑了抖音和TikTok等产品从0到1的建设和发展。</p><p>这是王长虎第一次创业，他告诉36氪：“我一直有一个创业的情结，想要尝试从0开始，孵化技术和产品，用人工智能影响和帮助尽可能多的企业和用户。UGC向AIGC转变过程中存在大量的机会，我们想抓住这个机会。”</p><p>眼下，整个视频行业被Sora的惊艳亮相炒的风风火火，有人把Sora的出现形容为视频生成领域的ChatGPT时刻，OpenAI和其他公司的差距正在进一步拉大，创业公司很难出头。</p><p>王长虎持有相反的观点，他认为，<strong>目前Sora的技术发展相当于在GPT2和GPT3之间，还没到GPT-4的水平，留给市场的空间很大</strong>。</p><p>在他看来，视频模型的生成能力好坏体现在三个维度：第一，准确性，即判断生成的视频内容是否和输入的prompt或图片匹配，符合用户预期；第二，一致性，即生成的视频中的主体、背景和运动是否有连贯性，是否符合真实世界的物理规律；第三，信息丰富度，即在一段时间内生成的视频是否能够呈现足够的故事性。</p><p>王长虎提到，Sora的生成视频效果确实比现在市面上的视频大模型要好，对于整个行业和爱诗科技而言，是挑战也是机会。“一方面，Sora采用了DiT（Diffusion Transformer）的技术路线，验证了该架构，其次，Sora出现之后整个AI视频生成行业会迎来新的爆发性机会，爱诗作为最早入局的公司之一，更有机会去追上并赶超Sora，在这个赛道取得一席之地。”</p><p>技术上，DiT（Diffusion Transformer）被认为是Sora采用的一种技术架构，该技术路线架构灵活度更高，且显著提升视频的生成质量。爱诗科技在创立之初就选择了这条路线。</p><p>目前，海外市场，爱诗科技国际版AI视频生成产品PixVerse已经正式运营，用户可以通过网页端，或者加入Discord-PixVerse服务器进行体验。今年3月，面向国内用户的爱诗大模型也已通过备案，现已开放内测，内测链接为https://aishiai.com/waitlist。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_3696de231ba34a71ba2be9a77e74c8e1@5261678_oswg862727oswg1080oswg530_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△国际版PixVerse网页端产品界面</p><p>产品方面，PixVerse主要支持文生视频、图生视频等主功能，在2023年10月，爱诗就把生成的视频内容做到了4K的分辨率。</p><p>以文生视频功能为例，PixVerse产品界面有Prompt 、Style、Aspect-ratio、Negative-prompt四个功能参数，其中Prompt 指的是需要输入的一段句子或关键词语；Style 决定了视频画面的风格;Aspect-ratio决定了视频的画幅比例；Negative-prompt 帮助规避视频中用户不想呈现的内容，用文字表达即可。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_d9f4d5253975447eb3836a72c83cad0f@5261678_oswg235294oswg564oswg924_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△PixVerse网页端视频生成界面</p><p>比如，输入Prompt：a little girl with bun hair wear flight attendant blue uniform stand in the plane cabin. she smile to the passanger，就可以得到下面这段4秒的视频。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_d45a6803db5c4f3da7ed0660afd8a492@5261678_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">PixVerse生成的视频</p><p>也有很多海外用户借助PixVerse和其他AI创作工具制作微电影、广告、动漫等，形成了新一代的AI工具流。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_bef05ee13af845638f5d63671fc2dd0d@5261678_oswg294003oswg582oswg777_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△截图自社交平台X</p><p>下面这则广告短片就是作者Michael Heina用Midjourney结合PixVerse生成的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_60da468ebd0548339f1fdb1f757158e6@5261678_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">作者Michael Heina用Midjourney结合PixVerse生成的一则香水广告片</p><p>商业化发展层面，爱诗的思路是聚焦C端，通过技术平台，构建AI视频生成全价值链，提升内容生成、审核、分发及商业化各环节的效率，并最终实现AI Native视频产品应用闭环，满足各个行业和用户的需求。王长虎认为，OpenAI的商业节奏在初期会和之前GPT-4的路线一样，更注重完善整个大的技术体系，在模型侧发力，开放API，让用户和开发者自己进行产品开发同时，爱诗的发展也将不仅仅局限于技术，还会关注更多应用产品侧的机会。</p><p>根据海外流量检测网站similarweb.com，目前爱诗海外产品PixVerse月访问量增长迅猛，已经超过百万，用户群里中有影视、游戏、广告主、艺术创作者等各行各业的人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_ff16ba4e83ea400db39080abdeaa3c11@5261678_oswg39352oswg1080oswg531_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△数据来自海外流量检测网站similarweb.com</p><p>眼下，创立已有一年的爱诗目前在团队扩张方面也相对谨慎，目前，爱诗公司团队有20多人，相比去年只多了十个人。</p><p>王长虎认为，团队是爱诗最核心的竞争力之一。爱诗目前的团队成员大部分都在早期就支撑了抖音、TikTok从0-1阶段，曾把AI视频技术广泛应用到了今日头条、抖音等字节跳动全线产品中，在视频技术领域有丰富的经验。“比如在技术层面，数据清洗、自动标注、模型加速等工程化问题，都是此前在字节做产品期间就面临过的难题，当时单我们团队就操盘了数万块GPU。”王长虎告诉36氪。</p><p>在他看来，这些能力都可以复用在爱诗的产品建设过程中，帮助公司在资源有限的情况下，更好产生ROI更高的算法和生成能力。此外，过去一年，团队已经在视频大模型的技术产品有一定的积累，也有助于公司在竞争中持续保持优势。</p><p>关于未来发展，王长虎透露，接下来 3——6 个月，爱诗最重要的目标是，<strong>技术上能够追平甚至赶超Sora</strong>，做出更好的产品，同时也会持续推进国内和海外产品的更新迭代，在2024年底做到大规模的C端应用落地。</p><p>王长虎认为：“未来，提供视频大模型的技术公司一定是少数，爱诗希望持续打磨技术层和产品层能力，做出国民级的AI原生视频产品应用，服务广大的C端用户。”</p><p>达晨财智谈到，此次投资爱诗主要看中团队的几个层面：</p><p>首先，创始人王长虎此前曾在微软亚洲研究院任职，发表过上百篇的顶会期刊论文，对计算机视频的前沿技术具有非常高的敏感度，且团队从0到1搭建字节的计算机视频底层算法模型，在模型、数据、算力上都经历过大规模的工程化检验，在视频大模型上的创业上有其他团队不具备的天然背景优势；</p><p>其次，团队执行力极强，公司模型按周迭代，同时有诸多的分叉版本在同时优化，公司很早就尝试用Transfomer替代Diffusion Model中的Unet的技术路线，模型效果也在逐步提升；</p><p>第三，团队是工程师文化的典型，管理扁平，每个人对技术都有追求和信仰。接下来，期待爱诗能打造出下一代端到端Super AI-Native的视频平台、产品、应用。成为国内最头部的多模态AI企业。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_b51b92b9c9a24e0eb5a14c032d4c232c@5261678_oswg61549oswg900oswg335_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">欢迎来聊～</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684904501317508</id>
            <title>特斯拉、英伟达投身其中，人形机器人能借AI风口起飞吗？</title>
            <link>https://www.36kr.com/p/2684904501317508</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684904501317508</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 09:46:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人形机器人, AI大模型, 商业化, 创新发展
<br>
<br>
总结: 人形机器人在AI大模型的赋能下，商业化发展迅速，各公司获得巨额融资，产业正处于爆发拐点。AI助推了人形机器人的发展，大模型让机器人具备自主决策能力，多模态能力使其全流程处理信息。国内也在加大人形机器人研究力度，未来发展前景广阔。 </div>
                        <hr>
                    
                    <p>2024年初，人形机器人热度持续高涨。业界普遍认为，在AI大模型赋能下，人形机器人商业化落地速度进一步提升。</p><p>不久前，特斯拉公司在社交媒体上发布一段人形机器人Optimus的最新视频，展示了更为流畅的步行能力，相比几周前的视频，Optimus在持续升级迭代中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_c947ced64a4b458a986bd24f47c8d136@813924438_oswg297499oswg691oswg386_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，人形机器人公司Figure A也获得6.75亿美元融资。这是一家由英伟达、OpenAI、微软、英特尔、亚马逊所支持的初创科技企业，公司旗下机器人Figure01因会冲咖啡而火出圈。本轮融资前的估值已达到约20亿美元。</p><p>有业内人士分析，随着产业化、商业化应用加速，人形机器人产业发展正处于天时、地利、人和的爆发拐点。那么，借助AI的风口机器人能起飞吗?</p><h2>AI助推机器人发展</h2><p>AI软件和机器人硬件的结合，仿佛是当下科技界风口的真实写照。</p><p>人形机器人产业因大模型的出现而升温。GhatGPT的横空出世点燃了全球范围的“百模大战”，而具身智能被认为是“人工智能发展的下一个浪潮”，一个能理解、推理并与物理世界互动的智能系统需要一具“肉身”，人形机器人无疑是最佳载体。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_a21d52452bd645a2bef1a2b69f881491@813924438_oswg173551oswg691oswg363_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>需要了解的是，不同于传统工业机器人只为完成特定任务而存在，人形机器人自诞生便背负起了智能化期待——像人一样感受世界、作出决策并执行任务。1973年，日本早稻田大学推出了世界上第一台全尺寸仿人机器人WABOT-1，它能够用日语与人交流，测量方向与距离，缓慢行走并抓取物体，相当于一岁半儿童的智力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_7cabce86a9b148eca0d9c833675fd90a@813924438_oswg293294oswg692oswg452_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>众所周知，人形机器人要实现与物理世界交互，就要具备感知和理解能力，这些更离不开AI的发展。我们认为，如果说深度学习让人工智能对世界有了感知，当下爆火的大模型则让人工智能有了自主生成的决策能力。</p><p>随着AI大模型的出现，让人形机器人拥有了更强大的工具链，理论上，只要让机器人学习足够多的数据，就能拥有类人智能，从而脱离预设规划，进行自主决策。与此同时，“多模态”能力的建立可以让机器人多线程处理信息，实现感知-决策-执行的全流程。</p><p>这也解释了为什么在AI大模型爆发之际，人形机器人被大家热议，因为，AI赋予了这轮人形机器人热潮的想象空间，即走向通用的可能性。</p><p>事实上也的确如此，安装智能大脑后的人形机器人正在飞速进化。谷歌实验室中，基于“视觉-语言-动作”模型“RT-2”的机器人已经能完成“捡起灭绝动物”的指令，在放着恐龙、鲸鱼、狮子三个塑料玩具的桌面上，机器人准确拿起了恐龙。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_68cc5fcacc16433fbead22181f4e8ea0@813924438_oswg281252oswg673oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由此推算，只要有足够的数据、算法和算力，机器人将能胜任更多复杂场景。今年年初，谷歌DeepMind连发三项新进展，均基于RT-2模型，用于提升机器人的速度、数据收集以及泛化能力。</p><p>目前来看，人形机器人的风头始终被海外公司和研究机构占据。美国波士顿动力、日本本田、意大利RobotCub Consortium等公司都在“人形机器人”项目上不遗余力地砸钱。</p><p>相比之下，国内主要以项目研究为导向。直至2000年，国防科技大学才研制出国内第一台仿人机器人“先行者”，到2015年北京钢铁侠科技成立，国内“双足大仿人机器人”逐渐走出实验室，试水商业。</p><h2>我国人形机器人发展契机</h2><p>随着，我国对于科技领域大力支持，机器人行业也迎来了新的发展契机。</p><p>2023年10月20日，工信部印发《人形机器人创新发展指导意见》，指出人形机器人集成人工智能、高端制造、新材料等先进技术，将深刻变革人类生产生活方式，重塑全球产业发展格局。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_b491c924f8da49edba3192f132d1f165@813924438_oswg93443oswg689oswg293_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>工信部《人形机器人创新发展指导意见》提出，到2025年，我国人形机器人创新体系初步建立;到2027年，人形机器人技术创新能力显著提升，综合实力达到世界先进水平。</p><p>继工信部印发《人形机器人创新发展指导意见》后，北京、深圳、上海先后发布产业支持政策。北京设立了100亿元规模的机器人产业基金，上海计划打造具有全球影响力的人形机器人产业高地，建设“大模型+人形机器人”协同创新平台，深圳则是借助《深圳市加快推动人工智能高质量发展高水平应用行动方案(2023—2024年)》，提出发挥粤港澳大湾区制造业优势，开展人形机器人规模化应用。</p><p>不过，由于我国人形机器人研究起步较晚，在场景创新和应用推广等方面，产业还存在共性关键技术有待提升、产品成本高限制商业化应用推广、商业化落地场景缺乏阻碍产业化进程等问题。我们也有一些发展的建议：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_7eba11cec4db484bbb18c9b03ceb219e@813924438_oswg236995oswg691oswg424_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>首先是聚焦产业共性关键技术，加大技术创新力度。依托现有或新组建的国家级技术创新平台，围绕智慧“大脑”、“小脑”、“肢体”和“感官”四个方向，开展产学研用协同创新，突破人形机器人专用操作系统、智能控制器、高效驱动关节、仿真孪生平台、集成开发环境、类人智能算法等基础理论与共性关键技术，组建场景驱动的人形机器人技术中试基地，加快产业共性关键技术的落地转化。</p><p>其次是基于现有产业基础，加快整合人形机器人产业链“供给侧”优势资源，强化协同供给能力。各地以划拨或政府投资等方式提供统一的人形机器人算力中心，建设超强算力的人形机器人“智慧大脑”。依托现有的机器人产业链，构建与完善人形机器人产业链供给能力，通过规模化生产来降低人形机器人的整机成本。</p><p>最后是强化政策导向，构建人形机器人场景应用创新生态，支持人形机器人企业创新成果在未定型阶段与应用方建立合作，首试首用。支持相关研发机构、企业开放人形机器人产品应用功能。</p><p>元宇宙新声认为，在人形机器人这条赛道上，国内软硬件技术仍在快速发展，不过，目前产品不成熟，技术路线还需要继续钻研，产业真正要思考的是，能为人形机器人买单的客户到底是谁?</p><h2>机器人全面赋能各行业</h2><p>“我觉得这个需求也许会达到100亿台，这是一个令人疯狂的数字。”特斯拉股东大会上，公司首席执行官埃隆·马斯克表示，预计未来人形机器人的需求量将远远超过电动车。</p><p>人形机器人具备类人形态，能够适配人类工作环境，在养老助残、环境清洁、医疗康养、家政服务等领域具备巨大应用潜力。据国际投行高盛预测，到2035年，人形机器人市场规模有望达到1540亿美元，为缓解老年护理劳动力短缺问题、减轻家庭和社会负担提供新的解决思路。</p><p>乐聚(深圳)机器人技术有限公司研发副总裁吴雨璁认为，将机器人设计成人形是更好地适配人类社会的工作场景，可以满足特定环境的工作需求。“举一个例子，如果仅仅给机器人安装轮子，但不能像人一样行走，那么所有的工作场景都要改造成平地或是配备电梯。”</p><p>在小米集团高级副总裁曾学忠的设想里，未来的智能制造体系中，70%的工作由自动化设备来完成;20%应当由仿真机器人来完成，核心目的是实现柔性制造与跨系统的协同，主要覆盖高、复杂度高，柔性场景的需求的场景;剩下的10%需要人来完成。</p><p>小米公司带来了机器人“铁大”。未来，“铁大”会应用到小米自己的智能制造工厂中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_ccc9ef3dc4314040aaa37407e63692ef@813924438_oswg244719oswg691oswg385_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在医疗、快递等服务行业，人形机器人也有很大发展空间。深圳市优必选科技股份有限公司创始人、董事长兼CEO周剑表示，公司自主研发的大型人形机器人Walker已实现稳定量产交付，在迪拜世博会中国馆长期服务，这也是首个大型仿人服务机器人真正商业化落地。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_b6b7faaac5fb4fbd873acabb6cce0cc6@813924438_oswg201927oswg692oswg387_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2月27日，软通动力称，公司联合某大型通讯设备企业共同推出了昇腾一体机AI机器人，据悉，该机器人是软硬件一体化的自主创新信创解决方案，基于昇腾AI基础硬件平台，嵌入盘古大模型，同时整合天鹤OS操作系统、ISS虚拟化平台等组件，支持一站式AI开发，深入客户业务场景开发业务模型，加速行业智能化。</p><p>截至目前，AI机器人已成功赋能国央企、制造、金融、教育等领域企业智能自动化应用场景150余个，覆盖押品登记自动化、智能巡检、票据助手、智能合同管理等。通过AI机器人应用，帮助客户解决了数据处理量大、规则重复操作、易操作差错等痛点，助力客户提升了工作效率，实现高自动化率和低差错的经营效果。</p><p>元宇宙新声认为，我国是人形机器人最大的潜在市场之一，我国新一代年轻人在技术革新中不断受益，更愿意接受和拥抱前沿技术，这无形中减弱了人形机器人的商业化阻力，将加速迭代优化，造就强大的顶端优势。</p><h2>写在最后</h2><p>目前，整个AI技术发展很快，通用人形机器人目前在技术层面已经迈过了鸿沟，如果未来几年能在工程方面追赶上去，人形机器人就可以发挥很大的生产价值，而且会是颠覆性的。</p><p>当下，随着人口增长放缓、老龄化比例的上升，机器人帮助人解决关键问题的发展趋势已不可阻挡。也许在未来某个时刻，机器人与人类的比例可能超过1：1，机器人的数量将超过人类。元宇宙新声认为，人形机器人的商业化需要场景、技术和资本的共同催化，此刻的人类世界或许正处于深远的变革期之中。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/T1ISzSYbBxQ-JBMp91HhQQ" rel="noopener noreferrer nofollow" target="_blank">“元宇宙新声”（ID:NFTMall）</a>，作者：贾桂鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684797858927234</id>
            <title>读懂马斯克下云，就读懂私有云为什么崛起？</title>
            <link>https://www.36kr.com/p/2684797858927234</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684797858927234</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 09:03:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 云计算, 公有云, 私有云, 金融与央国企
<br>
<br>
总结: 云计算领域的公有云和私有云之争一直备受关注。尽管公有云市场份额领先，但随着一些大型企业选择私有云，私有云市场也在崛起。金融行业和央国企对私有云的需求增长迅速，私有云在金融行业和央国企中得到广泛应用。私有云的安全性和可控性成为其吸引金融行业和央国企的关键因素。在云计算市场的发展中，私有云与金融行业和央国企的深度契合是私有云快速增长的关键。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_c1c5aaaed2f8413492fbe25bc0dd4759@5070940_oswg33251oswg698oswg353_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在云计算领域，姓“公”还是姓“私”，一直是业界关注的焦点。时至今日，既有声音说公有云乃是云计算的大势所趋，也有声音笃定认为私有云至少占据云计算的半边天。</p><p>虽然两种观点并存于市场已经很多年，但从市场份额上看，公有云已领先数年：根据中国信通院2020年5月的数据，2019年我国云计算整体市场规模达1334亿元，增速38.6%。其中，公有云市场规模达到689亿元，相比2018年增长57.6%，当年市场规模首次超过私有云，并保持至今。</p><p>不过，随着推特（现在的X）下云，云计算的“公私之争”又掀起了一波高潮，只不过这一次，私有云明显占据了上风。</p><p>在马斯克收购推特（现在的X）一周年的去年10月27日，推特（现在的X）的工程技术团队发布了一条帖子，其中“下云”（CloudExit）这个词的出现引起了云市场热议，直白点说就是：推特（现在的X）不跟公有云厂商玩了。</p><p>推特的帖子还披露了工程团队在优化了 X 平台，开始在本地环境运行更多工作后的对比效果：月度云成本降低了 60%；将所有媒体/ blob工件移出云环境后，云数据存储大小降低了 60%；通过技术手段将云数据处理成本降低了 75%。</p><p>最尴尬的就要数推特（现在的X）的供应商亚马逊了，手里的大客户丢了不说，反过头来还被数据打脸，吃瓜人士纷纷表示：云计算巨头亚马逊的产品都不好用了，那还有好用的公有云吗？</p><p>不过，业内其实更关注另一个事实：推特（现在的X）并没有放弃云计算，而是采用了类私有云的形式继续运转公司的业务，并取得了超过公有云部署的工作效果。</p><p>说到这里，真正的问题才浮出水面：私有云为什么崛起？</p><h2>01 私有云崛起的动力来自金融与央国企</h2><p><strong>一个不容忽视的事实是：私有云崛起，动力来自于金融行业与央国企。</strong></p><p>先看体量。据财政部数据，2022年全国国有及国有控股企业营业总收入达82.6万亿元,作为国民经济的重要支柱,国资央企和以国资比例极高的金融行业发挥着重大作用,而在云计算应用层面，国务院国资委于2020年8月印发《关于加快推进国有企业数字化转型工作的通知》，将国有企业定位为深度上云用云的排头兵，在这其中，国有金融单位对云计算的需求极为强烈。因此，私有云需求迅速增长，自然也带来私有云市场规模扩大。</p><p>再看驱动因素。私有云崛起的两大动力中，金融行业上云可谓各有节奏：因为我国金融机构数量众多、发展规模和服务水平各不相同，各个机构对上云这件事的认知理解不一：有大型商业银行积极完成金融云业务场景全覆盖建设，进而探索基于私有云架构下的业务数据融合创新；同时也有大量中小银行尚未进入私有云和信创云建设，云计算需求尚未释放。</p><p>但无论处于什么阶段，私有云在金融行业未来前景都值得期待。根据艾瑞数据，2021年中国金融云市场规模为394亿元，未来四年的复合增长率28.6%，预计在2025年，我国金融云市场规模将突破千亿。</p><p><strong>在这片广阔的云计算市场中，与金融行业深度契合，是私有云快速增长的关键一步。</strong>“金融行业面临着快速变化的市场和技术环境，要求云平台支持快速开发和部署，支撑金融机构完成迅速响应，对数据隐私和安全有着严格的要求，同时也需要对基础设施的完全控制权，而私有云的主要优势在于其高度的安全性和可控性，确保数据安全和合规。此外，对于需要大量数据处理和存储的金融企业，私有云在长期使用中更经济高效。”第一新声采访博云科技首席运营官崔骥时，得到了以上私有云契合金融业务的观点。</p><p>再看央国企。相比于金融行业，央国企上私有云已经是进行时。据统计，国内大型国企已经开始广泛使用私有云：银行业的国内20家系统重要性银行（国有商业银行6家，股份制商业银行9家，城市商业银行5家）已超过80%使用私有云产品。证券业的交易所和十多家券商，南北两大电网公司，80%的航空公司也都是私有云厂商的客户。</p><p>实际上，如此多的央国企选择私有云的出发点，逻辑很简单：就是稳定经营，进而完成社会责任。易捷行云EasyStack的COO王瑞琳接受采访时认为从政策层面来看，安全性更高的私有云必然是央国企的首选，其次，云是要跟着数据走的，央国企数据的重要以及数据要素的业务价值决定了不会上公有云“为了实现对社会的责任，尤其是在信创热潮下，央国企对云平台技术、数据的控制要求极高，在百年未有大变局下，我们要实现民族的伟大复兴，企业数字化的独立自主需求已经放到了时代高度，央国企是这样，大型民营企业也这样，私有云在这一核心需求上是顺应潮流的。”</p><h2>02 金融/央国企的业务支撑，需要更具创新性的数字底座</h2><p>云计算的数字作用正在被市场、客户认可，那么适合金融/央国企的数字底座到底是什么样的呢？这就要从当下的市场来分析了。</p><p>据《财经十一人》报道，一位头部数字化企业高管总结当前中国云计算市场的打法就表示：集成、硬件、定制是政企市场敲门砖，“要先争取机会进场，再想办法通过二期、三期项目盈利”。</p><p>实际上，云计算行业的这一打法描述稍显笼统。一位从业超过十五年的行业老兵曾经向第一新声完整回忆过中国云计算市场所经历四个阶段的不同打法，总结起来可谓是：一路走路，全是教训。</p><p><strong>第一阶段：项目定制打法。</strong>后来厂商发现版本碎片化、维护成本高持续赔钱不说，也沉淀不出产品，于客户而言僵死的版本没法升级，远远跟不上业务需求和新技术引入的需要；</p><p><strong>第二阶段：硬件厂商兴起的投资建设运营云打法。</strong>主要集中在政务云领域，几年后发现也是客户和厂商双输的结果，厂商没赚到钱，客户业务得不到满足；</p><p><strong>第三阶段：互联网背景的云公司造势兴起的“全栈”“大集成”打法</strong>，并借此做大营收，进而捆绑用户，结果是交付结果大跌眼镜，客户也只能打掉牙往肚子里咽，互联网思维入侵云计算行业最终大溃败；</p><p><strong>第四阶段：抛弃集成，专注自有产品销售打法。</strong>这一过程始于去年开始，国内云公司集体达成的“共识”—拒绝项目制，坚持产品化交付。这才是产品型公司回归商业本质的正确姿势，也是产业开始走向成熟的标志。</p><p>那既然产业走向成熟了，我们还要探讨另一个需要直面的问题：为什么过往很长时间里，私有云服务没有很好的适应市场？答案很简单：私有云发展中留下了沉重的技术债务。</p><p>来看看都有什么技术债务吧：新技术导致底座割裂，进而形成虚拟化、超融合、IaaS、容器等各种功能孤岛；技术兼容贯通能力不足，最直观的就是系统组考虑不了网络SDN的需求和未来演进，更考虑不了开发测试组的容器需求；一味强调个性化定制吸引客户，却脱离了厂商产品主线，技术覆盖能力跟不上，后续的投入巨大不说，每次升级都是做小白鼠，苦了自己也苦了客户；运维能力制约顶层设计，说白了就是有心干，后勤跟不上，只能选择了保守过时的虚拟化或者超融合路线，走不到私有云路线，更支撑不了大规模部署；布局超过自身技术能力，总希望借助大厂商产品技术兜底，结果架构过重、成本过高不说，被全栈方案牢牢绑定。</p><p>实际上，金融及央国企客户的私有云扮演数字底座的角色，随着对云的深入使用和客户的技术能力提升，对私有云关注点的一定会从产品功能，转移到更关注架构技术路线、产品设计理念上来；从短期需求满足，转移到新技术、大规模场景兼容的未来扩展路径上来。整个业界的认知达到了这一高度，解决技术债务的方向也就出现了—系统设计和先进架构。</p><p>当然，架构要求的满足并不是一朝一夕可以实现的，但总有玩家可以走到趋势前沿。<strong>“拉长时间周期，从业务深度用云、放大建设规模的视角下，金融及央国企用户对选择私有云的关注点会很容易有共识：</strong></p><p><strong>1、开放的技术路线。</strong>避免被单一技术和单一厂商绑定，需要云平台具备接入开放生态的能力；</p><p><strong>2、可进化的产品架构。</strong>在新技术和新需求引入或者大版本升级时，确保平滑升级，业务不影响、数据不迁移；</p><p><strong>3、均衡的基础设施平台能力。</strong>产品可以实现虚拟化、超融合、分布式存储、云网络、容器、裸机等不同资源管理，兼顾X86和信创热潮下的国产架构，支持通用算力和GPU智算等不同硬件的能力；</p><p><strong>4、轻量级和灵活性。</strong>能够从3节点平滑扩展到上千节点，部署和使用简单，轻运维；满足客户从小规模试点到大规模演进的周期，兼顾传统业务和新技术，兼顾投资与收益等经营维度。”王瑞琳认为技术架构的搭建，越底层做起，越能解决客户面临的实际问题。</p><p>对于架构的的趋势，青云科技产品方案及服务部高级技术总监傅帅给出了自己的观察：“我们观察，多元异构算力已成为行业大势，为了满足金融客户的需求，我们研发产品的关键词定位成了‘开放’与‘融合’：通过统一平台架构，做到向下兼容和对接不同的硬件、不同的 CPU、不同的 GPU，向上支撑各类应用，尤其是当下火爆的大模型，当前的私有云厂商在架构设计上都留有兼容余地。”</p><p><strong>那解决私有云行业化场景化的问题后，能给客户带来什么价值呢？最主要的两个层面：降本增效和服务业务创新。</strong></p><p>降本增效比较好理解。据王瑞琳介绍，过去金融/央国企客户部署云计算，“每当有新技术、新硬件想要加入原架构的时候，头都大了。因为好多云厂商为了增加壁垒，就不支持这些新东西。客户想要用这些，只能推倒从来。造成了资源浪费、成本浪费，很可能还要中断业务，效率极差。”</p><p>服务业务创新，最明显的还是大模型嵌入云计算。这里还要把大模型分成两部分：通用大模型和垂直大模型。从AI大模型的发展看，当下普遍认为垂直大模型的商业落地更具可行性，而公有云上发展的更多的是通用大模型，垂直大模型更多的在私有云进行实践。</p><p>大模型对客户业务的加成在哪里？一位百度智能云技术人士曾表示，大模型出现前，AI技术通用性差，定制化交付烦琐，只能变成项目制，毛利非常低。<strong>AI最被诟病、落地最难的是，实际产业环境场景碎片化。大模型出现后，客户只需要关注大模型平台。</strong>上层的软件平台有更强的通用、泛化能力。底层技术细节差异被屏蔽、封装了。AI落地时无需太多精调数据、训练轮数。时间成本、交付难度都大幅度降低。</p><h2>03 数字底座安全，数据才安全</h2><p><strong>另一个不容忽视的问题是安全性。</strong>那公有云和私有云的安全性谁更好？先说观点：<strong>普遍认为是私有云更好。</strong></p><p>安全性事件能造成多大的影响，不妨看看阿里云。据媒体统计，近6年来阿里云先后发生4次大事故：</p><p>1、2018年6月，阿里云出现持续近半小时的重大技术故障，导致部分客户访问阿里云官网控制台和使用部分产品功能出现问题。</p><p>2、2019年3月3日凌晨，阿里云疑似出现了宕机事故。不少华北地区的互联网公司受到波及，APP和网站全部瘫痪。阿里云根据SLA协议（服务合同），进行处理赔偿。</p><p>3、2022年12月18日，阿里云爆发香港Region可用区C大规模服务中断事件，导致多个香港及澳门站点受到影响。是阿里云运营十多年来持续时间最长的一次大规模故障。</p><p>4、2023年11月12日晚间，阿里巴巴旗下淘宝、闲鱼、阿里云盘、饿了么、钉钉在内的多款产品均出现故障，公司的B端客户也受到影响。有媒体指出，故障更波及包括中国内地、香港，以及印度、美国、英国、韩日等多个国家和地区。</p><p>连阿里云这样巨头都有各种问题出现，公有云安全性屡受质疑也就符合逻辑了。实际上，长期以来公有云安全主要集中在数据泄露、访问安全、接口安全、数据劫持、监控不足、网络攻击、数据丢失等层面。尽管厂商从各种途径都在努力解决问题，但要注意到这些问题几乎都广泛存在于公域网络中，而公有云就是架设在公域网络，这成为一个结构性问题。</p><p>除了结构性问题，云计算平台还有一个自主可控的合规性问题。2024年1月16日，习总书记在省部级主要领导干部推动金融高质量发展专题研讨班开班式上发表重要讲话，强调要建立健全自主可控安全高效的金融基础设施体系。云计算平台自然是金融基础设施中的重中之重。</p><p>所以，<strong>安全合规在当下的云计算市场中，是客户搭建部署之前的红线。有了这条红线，在产品选型的时候，基本上就会率先选择私有云。</strong></p><p>为什么呢？首先，作为私有云是放在私有环境中的，比如企业、政府、组织等等自己在机房中建立的，或者是运营商建设好，但是整体租售给某一组织的。企业、组织、政府等之外的用户无法访问或无法使用；其次，私有云服务安全性高，服务稳定，管理方便。</p><p>以上特点，对于金融/央国企来说，非常有吸引力。私有云满足客户更高的数据安全性和隐私保护，确保客户敏感数据不会被泄露，机构核心数据不会被截取。“比如说，我们服务过的证券客户，它如果提供信息查询类功能，那放在公有云上就没问题，但是它还有高频交易业务，对速度和安全性的要求都非常高，恨不得在两大交易所旁边就摆上服务器加强服务和监管，这就不可能放在公有云。所以，什么样的业务就决定了使用什么样的云，金融行业和央国企，数据具有极大价值，尤其对运营商、央企、政府来说，这种数据只能私有云来保存。”王瑞琳在从业经历中，十分了解客户对安全性迫切需求。</p><p><strong>都说数据产生价值，其实应该还可以加以限定：安全的数据才有价值。</strong>这个价值在哪？别急，马上就有。12月15日，据国家发改委消息，国家发改委发布关于向社会公开征求《“数据要素×”三年行动计划（2024—2026年）（征求意见稿）》意见的公告。意见提出，到2026年底，数据要素应用场景广度和深度大幅拓展，在经济发展领域数据要素乘数效应得到显现，打造300个以上示范性强、显示度高、带动性广的典型应用场景，产品和服务质量效益实现明显提升，涌现出一批成效明显的数据要素应用示范地区。从安全角度理解这个意见稿，可以读出一句话：为业务深度融合创新保驾护航。</p><p>说了这么多，其实也从马斯克下云这件事延伸出来，下云肯定不是云计算的终点，读懂它其实也就读懂了未来私有云的发展路径，这比当吃瓜群主有意义多了。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/09QsSttlH1yMyhAv2MbtUA" rel="noopener noreferrer nofollow" target="_blank">“第一新声”（ID:thefirstnewvoice）</a>，作者：潇维，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684929903378563</id>
            <title>李彦宏“程序员将不再存在”言论被周鸿祎驳斥，网友怒怼：先把百度程序员都开除了</title>
            <link>https://www.36kr.com/p/2684929903378563</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684929903378563</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 09:01:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 程序员, 人工智能, 未来, AI
<br>
<br>
总结: 李彦宏和其他技术专家认为，未来人人都会具备程序员的能力，AI技术的发展将导致程序员职业的消失，人类程序员将被取代。程序员需要演变成AI程序的“老师”，产品经理和代码评审人员将是未来软件开发团队中的关键角色。未来程序员需要与AI共生，强化自己的能力以适应AI时代的发展。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_9c72eb1083014877b1d025156eb9d229@46958_oswg28880oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>李彦宏：未来将不再存在“程序员” 这一职业&nbsp;</h2><p>在 3 月 9 日央视的《对话》·开年说节目上，百度创始人、董事长兼 CEO 李彦宏表示，<strong>基本上以后不会存在“程序员”这种职业了，因为只要会说话，人人都会具备程序员的能力。</strong>“未来的编程语言只会剩下两种，一种叫做英文，一种叫做中文，这也是目前世界上人工智能技术最领先的两个语言。”</p><p>对于李彦宏的这一观点，有网友表示赞同，认为这是未来的趋势，未来的发展方向还得是智能化。“以后编程，写代码的难度肯定会不断降低”，“现在大模型的出现已经降低了程序员门槛，后面门槛肯定会越来越低”，“程序员这个职业会进化的更高级”。</p><p>也有网友表达了不一样的观点：“低端程序员会消失，有创造力的程序员会做大”，“编程仍是基础，是必须要学的，程序都看不懂，再有创造力也没用”。有网友调侃道，“先把百度的程序员都开除了吧”。有网友更是悲观地表示，“程序员还需要 AI 淘汰? 一到 35 岁你就找不到工作啦。”</p><p>3 月 10 日，周鸿祎发表微博驳斥称：“大模型将替代程序员？未来不用学编程了么？我认为，<strong>程序员热十年内不会减弱</strong>。尽管未来人人都会用电脑，所谓人人都是程序员，但不同的人用电脑创造的产品完全不一样，AI 时代更需要计算机专家和程序员，他们可能是各行各业最有发言权的。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_290ba2ae50b940e4847e1af55a2a6f9e@46958_oswg1043207oswg690oswg2353_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在节目中，李彦宏还提到了人工智能发展速度，并表示“我觉得人工智能发展比我想象中更慢。人工智能已经被提出快 70 年了，可能每过 10 年左右，就有一群人说，我们终于要实现通用人工智能了。但其实情况比想象中要复杂。”</p><p>谈到未来大模型会给人类的生活或者是生产带来什么改变时，李彦宏认为，大模型对于人类生产生活的改变会是非常根本性的。互联网改变了我们的很多生活，但是这一波人工智能的改变，会更加的彻底、更加的深刻。</p><h2>Stability AI CEO：未来五年内，人类程序员将彻底消失&nbsp;</h2><p>和李彦宏有同样观点的技术专家并不在少数。</p><p>Fixie 联合创始人兼 CEO、前谷歌 Chrome 移动团队工程总监 Matt Welsh 曾表示，“程序员这个工作或许在三五年内不复存在，甚至编程这个学科都会被终结。” 据悉，Welsh 曾在谷歌和苹果公司担任高级工程职位，他曾在 2023 年 1 月出版的《ACM 通讯》杂志上就这一话题写了一篇文章。此外，Welsh 还成立了一家初创公司来证明他的理论。</p><p>Welsh 认为，由于 ChatGPT 和 Copilot 等技术的出现，编程正处于从人类工作转变为机器人工作的转折点。在他看来，程序员需要演变成 AI 程序的“老师”——或者产品经理，或者代码评审人员。他认为这两个人类角色相对来说不那么受机器人的影响。“不要指望你的程序员职业生涯会一直持续下去，因为机器正在取代这个角色。”Welsh 说道。</p><p>Stability AI 创始人兼 CEO Emad Mostaque 也曾在某技术播客节目预言：“五年内，人类程序员将彻底消失。” Stability AI 是全球最受欢迎的开源图像生成器 Stable Diffusion 背后的开发商，该公司还涉及蛋白质折叠结构预测、DNA 分析与化学反应模型、语言模型乃至视听数据处理等多个领域的广泛项目。</p><p>Mostaque 总结道，对于人类程序员来说，未来前景着实不太光明，而且已经有不少证据能够支撑他的观点。来自 GitHub 的统计数据显示，“目前所有代码中已经有 41% 是由 AI 生成。Mostaque 进一步补充称，更有趣的是，“我们的项目在短短三个月内就超越了 GitHub 上的比特币和以太坊，迅速掀起一波新的潮流”，这证明 AI 相对于加密货币有着更积极的群众认同基础。</p><p>展望不久的未来，Mostaque 相信人类的信息获取与沟通方式将迎来突破性变化。他解释道，“到 2024 年年底，我相信大家就会把 ChatGPT 安装在自己的手机上，而且可以脱机运行、不再依赖联网。”而随着 AI 模型全面驻留在手机端，“我们的对话交互体验也将发生根本性的转变。”</p><h2>在未来，程序员将会走向何方？&nbsp;</h2><p>虽然技术大佬们对于程序员职业的未来发展抱有不同的观点，但都认为这波 AI 浪潮会给其带来翻天覆地的改变。</p><p>Welsh 甚至对未来的软件开发团队做了一些有趣的预测：当程序员开始被淘汰时，只有两个角色可以保留：产品经理和代码评审人员。</p><p>在 Welsh 看来，产品经理的角色不会有太大变化。“人类产品经理仍然能够写出告诉软件应该做哪些事情的英文描述——也就是产品需求文档（PRD）。这是产品经理已经在做的事情，对吧？”不同的是，在不久的将来，我们不再需要把 PRD 交给工程团队，然后等上六周左右，等他们把需求实现完毕，Welsh 说：“你只需要把 PRD 交给 AI，AI 在几秒钟内就可以吐出代码。”</p><p>具有编程能力的人类将承担“评审和阅读 AI 生成的代码，并确保它们能够正常运行以及做正确的事情”的任务。至于程序员，以及那些即将加入这一领域的人，他们将需要成为 AI 的老师，而不是程序员本身。Welsh 说：“这是关于如何教会 AI 写代码，而不是自己写。”</p><p>腾讯 Tech Lead 茹炳晟认为，工程师需要关注业务理解、需求拆分、架构设计、设计取舍，并在此基础上通过 prompt 学会与 AI 合作，从而实现“工程师 + LLM”形成 1+1 &gt;2 的效果。这就是共生。未来程序员要想更好地与 AI 共生，需要从以下三个方面来强化自己的能力：</p><p>需求理解、需求分析、需求拆解的能力。</p><p>架构设计、架构分析、设计取舍的能力，并推动设计的文档化和规范化。</p><p>理解问题本质，而不是单纯学习应用（授人以鱼不如授人以渔）。</p><p>参考链接：</p><p>https://mp.weixin.qq.com/s/fF7kqaAGfucYi-UI_GlKyw</p><p>https://decrypt.co/147191/no-human-programmers-five-years-ai-stability-ceo</p><p>https://thenewstack.io/coding-sucks-anyway-matt-welsh-on-the-end-of-programming/</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/JP2fE9TS9Dbjp8f3mfm3kA" rel="noopener noreferrer nofollow" target="_blank">“AI前线”（ID:ai-front）</a>，整理：凌敏、核子可乐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684858534674561</id>
            <title>用Vision Pro实时训练机器狗，MIT博士生开源项目火了</title>
            <link>https://www.36kr.com/p/2684858534674561</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684858534674561</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 09:00:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Vision Pro, 手部追踪功能, 机器狗, 具身智能
<br>
<br>
总结: Vision Pro利用手部追踪功能成功实现对机器狗的实时控制，引发了具身智能研究人员的兴趣，被认为是未来与机器互动的方式。作者已在GitHub上开源相关项目，App可在Vision Pro的App Store下载。同时，作者开发的Tracking Steamer应用利用Vision Pro追踪人类动作并传输至其他机器人设备，依靠ARKit库实现动作追踪，使用gRPC作为网络通信协议。 </div>
                        <hr>
                    
                    <p>Vision Pro又现火爆新玩法，这回还和具身智能联动了~</p><p>就像这样，MIT小哥利用Vision Pro的手部追踪功能，成功实现了对机器狗的实时控制。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_4c052e76b44d498b88529256c15fde3c@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不仅开门这样的动作能精准get：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_42e8ec1e258e4ecd958bea31b089828d@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也几乎没什么延时。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_00563ef612a1483ab3d841e913a01f7b@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Demo一出，不仅网友们大赞鹅妹子嘤，各路具身智能研究人员也嗨了。</p><p>比如这位准清华叉院博士生：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_2a18d044eff7494ba71b797e36db39ff@46958_oswg86800oswg942oswg246_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有人大胆预测：这就是我们与下一代机器互动的方式。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_b499232c916a4b748d37cd6ab5c7b50d@46958_oswg42993oswg936oswg150_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>项目如何实现，作者小哥<strong>朴英孝</strong>（Younghyo Park）已经在GitHub上<strong>开源</strong>。相关App可以直接在Vision Pro的App Store上下载。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_68e574b182364dd7a7775c2b2454f0bb@46958_oswg320007oswg1080oswg854_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>用Vision Pro训练机器狗</h2><p>具体来看看作者小哥开发的App——<strong>Tracking Steamer</strong>。</p><p>顾名思义，这个应用程序旨在利用Vision Pro追踪人类动作，并将这些动作数据实时传输到同一WiFi下的其他机器人设备上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_cc870dc5b92c4503a63127fe1d7b8df7@46958_oswg123861oswg960oswg348_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>动作追踪的部分，主要依靠苹果的ARKit库来实现。</p><p>其中头部追踪调用的是queryDeviceAnchor。用户可以通过长按数字表冠来重置头部框架到当前位置。</p><p>手腕和手指追踪则通过HandTrackingProvider实现。它能够追踪左右手腕相对于地面框架的位置和方向，以及每只手25个手指关节相对于手腕框架的姿态。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_1be781dd11ff4e8dba02f21da7a82b59@46958_oswg427361oswg1080oswg374_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>网络通信方面，这个App使用gRPC作为网络通信协议来流式传输数据。这使得数据能被更多设备订阅，包括Linux、Mac和Windows设备。</p><p>另外，为了方便数据传输，作者小哥还准备了一个Python API，让开发者能够通过编程方式订阅和接收从Vision Pro流式传输的追踪数据。</p><p>API返回的数据是字典形式，包含头部、手腕、手指的SE(3)姿态信息，即三维位置和方向。开发者可以直接在Python中处理这些数据，用于对机器人的进一步分析和控制。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_c7bdfa808c404ac9ae4712f0a5911af6@46958_oswg213342oswg1080oswg598_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就像不少专业人士所指出的那样，别看机器狗的动作还是由人类控制，事实上，相比于“操控”本身，结合模仿学习算法，人类在这个过程中，更像是机器人的教练。</p><p>而Vision Pro通过追踪用户的动作，提供了一种直观、简单的交互方式，使得非专业人员也能够为机器人提供精准的训练数据。</p><p>作者本人也在论文中写道：</p><blockquote><p>在不久的将来，人们可能会像日常戴眼镜一样佩戴Vision Pro这样的设备，想象一下我们可以从这个过程中收集多少数据！</p><p>这是一个充满前景的数据源，机器人可以从中学习到，人类是如何与现实世界交互的。</p></blockquote><p>最后，提醒一下，如果你想上手试一试这个开源项目，那么除了必备一台Vision Pro之外，还需要准备：</p><p>苹果开发者账户</p><p>Vision Pro开发者配件（Developer Strap，售价299美元）</p><p>安装了Xcode的Mac电脑</p><p>嗯，看样子还是得先让苹果赚一笔了（doge）。</p><p>项目链接：https://github.com/Improbable-AI/VisionProTeleop?tab=readme-ov-file</p><p>参考链接：https://twitter.com/younghyo_park/status/1766274298422161830</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Zq7xxhJk14hFQ_OSTZre1g" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：鱼羊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684858493877256</id>
            <title>华人CV宗师黄煦涛高徒离职特斯拉，加入OpenAI，专攻多模态模型研究</title>
            <link>https://www.36kr.com/p/2684858493877256</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684858493877256</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 08:49:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华人科学家, OpenAI, 多模态模型, Thomas Huang
<br>
<br>
总结: 华人科学家程博文即将加入OpenAI，参与多模态模型研究，他是著名华人计算机泰斗Thomas Huang的学生。程博文曾在特斯拉从事全自动驾驶系统开发工作，也在UIUC获得电气与计算机工程博士学位，期间受到Alexander Schwing和Thomas Huang教授的指导。他在多家知名研究机构实习过，个人研究兴趣涵盖计算机视觉和机器学习。在特斯拉，程博文是一位全栈研究员，参与全自动驾驶技术产品化进程的各个环节。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_76f69c8d15214e73afcd6563f673d025@46958_oswg184799oswg1045oswg407_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>华人科学家程博文官宣即将入职OpenAI，加入后训练团队参与多模态模型研究。值得一提的是，他还是著名华人计算机泰斗Thomas Huang的学生。</p><p>OpenAI又迎来一位AI大将。&nbsp;</p><p>最近，华人科学家程博文官宣离职特斯拉，即将加入OpenAI专攻多模态模型的研究。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_75dde943a20743d597f8f126980e1b94@46958_oswg158886oswg1080oswg374_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>今天是我在特斯拉自动驾驶部门的最后一天，这一年半的经历真的很棒：有机会与才华横溢的同事们共事，学习了如何开发出色的产品等等。但我向通用人工智能（AGI）进发的脚步不会因此而停歇，不久后，我将加入OpenAI的后训练（post-training）团队，参与构建多模态模型的工作。&nbsp;</p></blockquote><p>值得一提的是，程博文博士毕业于伊利诺伊大学厄巴纳-香槟分校（UIUC），导师就是大名鼎鼎的计算机科学家Thomas Huang。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_4ff48863c6354a099bd1d30c852ba857@46958_oswg129490oswg636oswg451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">黄煦涛于2020年4月逝世&nbsp;</p><p>OpenAI视频生成科学家Will Depue、技术人员Farzad Khorasani等人纷纷对他表示欢迎。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_e17c51534fa64852a236ee50b12244b3@46958_oswg39534oswg1080oswg100_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_124b5fee3c5d463b88476424666d5841@46958_oswg54509oswg1080oswg96_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>程博文是谁？</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_b0656abca048461a8e65271026ca5f21@46958_oswg1522330oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2022年，程博文正式入职特斯拉，成为自动驾驶团队的一位资深研究科学家。&nbsp;</p><p>在此期间，他的主要工作重心——开发全自动驾驶（FSD）系统，包括特斯拉最新的FSD v12。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_81a416127c3e43f1a3a06f9999b55bbd@46958_oswg104701oswg1080oswg272_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>程博文曾在UIUC获得了电气与计算机工程（ECE）的博士学位，期间由Alexander Schwing教授和Thomas Huang教授指导（2017-2020年）。&nbsp;</p><p>在攻读研究生学位之前，他于2017年在UIUC完成了电气与计算机工程的学士学位学习。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_dab62acb96c9447ca2c3efc6bfad7e32@46958_oswg144745oswg1080oswg492_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>程博文还曾在Facebook AI Research、谷歌研究院、微软研究院和微软亚洲研究院实习。&nbsp;</p><p>个人主页中，他提到了自己的研究兴趣，覆盖了计算机视觉和机器学习。&nbsp;</p><p>在特斯拉，程博文将自己视为一位「全栈研究员」，不仅将最新研究成果应用于全自动驾驶技术的产品化进程中，还参与了产品开发的全周期工作，包括数据引擎、模型设计与训练、模型集成等方面。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_6ae62c46b8784aaeb676ea4c2e540a08@46958_oswg181038oswg1080oswg534_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最近，他正致力于开发自动驾驶的端到端规划网络。&nbsp;</p><p>作为一位专注于计算机视觉和机器学习的研究者，程博文对多模态嵌入式智能体很感兴趣。&nbsp;</p><p>具体来说，他希望打造出能够（1）理解人类以任何形式发出的命令；（2）根据内置知识或利用工具以期望的方式执行任务并生成结果；（3）通过吸取常识知识和人类反馈进行学习的AI助手，如自动驾驶汽车、聊天机器人等。&nbsp;</p><h2>过往项目：重点在「分割」</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_b901957caa22426f83aff9cacf0857e4@46958_oswg231578oswg1080oswg647_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>程博文获得CVPR 2022 Oral的一篇论文提出了基于点的实例级注释——是实例分割的一种新的弱监督形式。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_81427ab69b5748a891373cb917573623@46958_oswg14812oswg810oswg212_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/abs/2104.06404&nbsp;</p><p>它将标准边界框注释与每个边界框内均匀采样的标记点相结合。&nbsp;</p><p>研究表明，为完全掩码监督而开发的现有实例分割模型（如Mask R-CNN），可以在不做任何重大修改的情况下，通过基于点的注释进行无缝训练。&nbsp;</p><p>实验中，在COCO、PASCAL VOC、Cityscapes和LVIS上训练的Mask R-CNN模型，在每个对象只有10个注释点的情况下，其完全监督性能达到了94%-98%的水平。&nbsp;</p><p>与比对象掩码相比，这种基于点的注释收集速度快约5倍，让高质量的实例分割更容易用于新数据。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_d485c9f7e6b84ad8bd0605726f48f2d3@46958_oswg1051270oswg1080oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，受新注释形式的启发，研究人员还对PointRend实例分割模块提出了修改建议。&nbsp;</p><p>对于每个对象，被称为Implicit PointRend的新架构会为一个函数生成参数，该函数会进行最终的点级掩码预测。&nbsp;</p><p>Implicit PointRend更为简单明了，只需使用一个点级掩码损失。&nbsp;</p><p>实验表明，新模块更适合基于点的监督方式。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_bd6083811dfa4f0ba7d24812bf45d2a2@46958_oswg164342oswg1080oswg545_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>CVPR 2022上另一篇录用论文，也是关于图像分割的研究。&nbsp;</p><p>是Maskformer算法的进阶。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_05cfd2e5343d45e6b4f51d4c04b6f9cb@46958_oswg106769oswg1080oswg209_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/abs/2112.01527&nbsp;</p><p>论文中，他提出的Mask2Former在图像分割，包括语义分割、实例分割、视频语义分割、视频实例分割等领域中逐渐变成了一个基础模型。&nbsp;</p><p>Mask2Former的关键组件包括掩码注意力，通过限制预测掩码区域内的交叉注意力来提取局部特征。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_e420c96927b44f07a8e95c846162c042@46958_oswg163314oswg1080oswg736_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了将研究工作量减少至少3倍外，它在四个流行数据集上的表现还大大优于最佳专业架构。&nbsp;</p><p>最值得注意的是，Mask2Former在全景分割（COCO上为57.8 PQ）、实例分割（COCO上为50.1 AP）和语义分割（ADE20K上为57.7 mIoU）方面都刷新了SOTA。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_d1b65a6bc5e645c7b5d70398207e5949@46958_oswg213990oswg1080oswg693_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而下面这篇就是Mask2Former的前身MaskFormer，被NeurIPS 2021 Spotlight录用。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_e2bc9b16fe924cfaa618b54c4f4ade81@46958_oswg42339oswg1080oswg369_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/abs/2107.06278&nbsp;</p><p>在作者看来，传统的逐像素分类的方法不足以通用。&nbsp;</p><p>为此全新提出的MaskFormer，是一种简单的掩码分类模型，可预测一组二进制掩码，每个掩码都与单个全局类标签预测相关联。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_2f28776f33824819abd9929511242ea6@46958_oswg122853oswg1080oswg246_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他们所提出的基于掩码分类的方法，简化了语义和全景分割任务的有效方法。&nbsp;</p><p>特别是，研究人员观察到，当类别数量较多时，MaskFormer的表现优于按像素分类的基准方法。&nbsp;</p><p>具体来说，MaskFormer基于掩码分类的方法优于最先进的语义分割模型（在ADE20K上为55.6 mIoU）和全景分割模型（在COCO上为52.7 PQ）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_8ad4015d400146a88840ad5543ed3268@46958_oswg126603oswg1080oswg327_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>程博文在CVPR 2020上，拿下的两篇论文，都得到了黄煦涛的指导。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_51d1ad3e6d38441aaf92b2e4073acdb2@46958_oswg38883oswg1080oswg278_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/abs/1911.10194&nbsp;</p><p>这篇论文介绍了Panoptic-DeepLab——一个简单、强大、快速的全景分割系统。&nbsp;</p><p>旨在为自下而上的方法建立一个坚实的基线，在获得快速推理速度的同时，实现与两阶段方法相当的性能。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_a455b31e09cc4c87a4d6533d1659f3c9@46958_oswg211721oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有一篇提出了HigherHRNet，一种全新的自下而上的人体姿势估计方法，用于使用高分辨率特征金字塔学习尺度感知表示。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_836c2ff7affe401f9186aefa7618b367@46958_oswg37646oswg1080oswg252_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/abs/1908.10357&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_e301ed7c419348938e2fe4d36a395e11@46958_oswg89309oswg1080oswg566_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>参考资料：&nbsp;</p><p>https://twitter.com/bowenc0221/status/1766339742818533636&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/YAQ9NKCzJyUjSde2uIB-WA" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：桃子 好困&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684831855444096</id>
            <title>傅盛打入“晋级赛”</title>
            <link>https://www.36kr.com/p/2684831855444096</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684831855444096</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 08:45:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 傅盛, AI大模型, 猎户星空, 互联网转战AI
<br>
<br>
总结: 傅盛从互联网转战AI，投资猎户星空推出AI大模型产品，希望改变传统编程方式，猎户星空成为活跃的AI企业。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_6808f16b59fc49fa9a4395698e9252e7@000000_oswg17722oswg544oswg298_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>傅盛再度押注AI大模型。&nbsp;</p><p>3月6日，一款名为“猎户星空AI代码加速器”的划时代的产品正式推出市场。董事长兼CEO、猎户星空董事长傅盛通过个人社交媒体宣布，猎户星空即将推出一款名为“猎户星空AI代码生成器”的新产品。&nbsp;</p><p>“这款产品基于大语言模型的代码生成器，预计将彻底改变传统的编程方式，人人都会写代码的时代到来！”&nbsp;</p><p><strong>从服务机器人到大模型大模型，傅盛的猎豹正在成为近几年非常活跃的AI企业。</strong> 只不过，AI重投入、低回报的现状，能否帮助傅盛和猎豹扳回一局？&nbsp;</p><h2>1、傅盛从互联网转战AI</h2><p>傅盛成名于互联网，而如今正在大量布局AI。&nbsp;</p><p>今年1月份，猎户星空发布预训练多语言大语言模型Orion-14B，据了解，该大模型拥有140亿参数，成功实现了类似千亿参数大模型所能达到的效果。&nbsp;</p><p>更早之前，2023年大模型热潮猎豹也率先发布了基于大模型技术的企业级深度应用“聚言”，将“聚言+机器人”作为新的增长点。&nbsp;</p><p>据时代周报统计，猎户星空基于语音交互、图像识别、视觉导航等人工智能技术，发布了豹小秘、招财豹、豹小递Max、豹小递Sky、豹小秘mini、豹小贩、智咖大师、消毒豹等机器人产品，并建立了猎户机器人开放平台OrionOS。&nbsp;</p><p><strong>猎户星空是傅盛的第二场创业。</strong> 2016年，猎豹移动董事长兼CEO傅盛"All in AI"，成立了以 AI 技术研发为核心的服务机器人新公司“猎户星空”。&nbsp;</p><p>今年初，猎豹再次对猎户星空增资，总增资额约合3.69亿元，其中包括1亿元可转换贷款权利。&nbsp;</p><p>据悉，本轮投资方包括猎豹移动、北京金山网络、九江市工业产业投资引导基金、深圳市中科招商股权投资管理。本轮增资完成后，猎豹移动将直接和间接持有猎户星空73.95%的股权。&nbsp;</p><p>傅盛成名于互联网时代。&nbsp;</p><p>江西景德镇走出的傅盛，曾是标准的草根——高考失利，考入山东工商学院。但他不甘平庸，毕业后勇敢追梦，南下厦门，又北漂北京，在IT界摸爬滚打。&nbsp;</p><p>直到遇见周鸿祎之后，他的人生轨迹发生了翻天覆地的变化。&nbsp;</p><p>在周鸿祎的提携下，傅盛可谓一路坦途，成为360安全卫士的研发者，策划了一系列颠覆性产品功能，为奇虎360的在互联网安全领域的崛起立下赫赫战功。&nbsp;</p><p>但就在奇虎360如日中天之际，傅盛与周鸿祎这对曾经的黄金搭档却分道扬镳，关系恶化到公开互撕。那场科技圈的“宫斗”一度让各路吃瓜群众印象深刻。&nbsp;</p><p>离开360的傅盛并未消沉，反而选择了创业，成立可牛影像，向杀毒市场发起挑战。两年后，他携手雷军，将可牛杀毒与金山安全合并，创建金山网络，自己出任CEO。这一次，他决定与老东家一较高下。&nbsp;</p><p>2010年11月10日，金山安全与可牛正式合并成立独立公司，傅盛出任金山网络金山网络 CEO。2014年3月25日，金山网络更名猎豹移动公司猎豹移动公司 ，傅盛出任猎豹移动公司CEO。&nbsp;</p><p>2014年，猎豹移动在美国纽交所风光上市，市值一度飙升。&nbsp;</p><h2>二、错失Musically</h2><p>好景不长，随着市场竞争加剧和内部矛盾的激化，猎豹移动开始走下坡路。&nbsp;</p><p>2月20日，猎豹移动收到谷歌总部与其终止广告合作的邮件通知。通知称，谷歌将终止猎豹移动旗下App的Admob及Ad Manager账户。随即，猎豹移动45款应用和游戏被谷歌从Google Play应用商店下架，甚至包括了猎豹所投资公司的一些App。&nbsp;</p><p>不可否认，猎豹曾经风光一时。鼎盛时候的猎豹移动如同一只迅猛的猎豹，驰骋在工具应用的广阔原野上。2014年5月8日，它荣耀地在纽交所敲响了上市的钟声，市值一路飙升，成为了众人瞩目的焦点。&nbsp;</p><p>猎豹的成功，离不开自身独特的三级火箭模式：免费的工具软件吸引用户，通过广告实现盈利，再借助用户影响力推广其他软件。这一模式在海外市场大放异彩，短短18个月，猎豹的全球用户就突破了8亿，收入也节节攀升。然而，这种过度依赖广告平台的模式，也为猎豹的未来埋下了巨大的隐患。&nbsp;</p><p>所谓“成也萧何败也萧何”，猎豹过度依赖广告平台的模式为其埋下了巨大的隐患。当Face Book和Google两大巨头相继调整策略，猎豹的收入被大幅分流，陷入了前所未有的困境。&nbsp;</p><p>2016年，Face Book调整了算法逻辑，开放了广告平台，猎豹的竞争对手如雨后春笋般涌现，收入被大幅分流。而更大的打击还在后头。2018年，猎豹被指控存在广告欺诈行为，随后Face Book宣布终止合作。2020年，Google也毫无征兆地下架了猎豹旗下的45款应用。这两大巨头的相继“抛弃”，让猎豹陷入了前所未有的困境。&nbsp;</p><p>猎豹本有机会打造自己的“护城河”，避免当时的尴尬境地。在市值高达四五十亿美元、利润十多亿的辉煌时期，猎豹完全有能力重点布局自己的生态体系。可惜的是，它并没有这样做，而是继续围绕工具类应用做矩阵产品。&nbsp;</p><p>正如傅盛所言：“<strong>我们之前是天天坐在石油上，根本没想过矿井会这么快枯竭。</strong>”当平台不再青睐你时，企业只能陷入被动局面。&nbsp;</p><p>为了缓解公司困境，傅盛开始寻找新的增长点，并将希望寄托在游戏和内容上。猎豹在游戏领域确实取得了不俗的成绩，推出了多款经典游戏产品。然而，在游戏业务如火如荼之际，猎豹却再次错失了短视频这一风口。&nbsp;</p><p>2015年，猎豹就投资了短视频社交软件Musically，并一度看到了希望的曙光。然而，由于内部认知差异和战略决策失误，猎豹并没有全力以赴去做内容。最终，Musically被字节跳动收购并整合进TikTok，成为了海外短视频市场的霸主。而猎豹则只能眼睁睁地看着自己曾经的投资如今风光无限，与自己却再无瓜葛。&nbsp;</p><h2><strong>三、AI能让傅盛翻身吗？</strong></h2><p>2016年，猎豹宣告“All in AI”的战略转型。&nbsp;</p><p>2016年，猎豹移动以投资猎户星空为契机，开始进入人工智能和机器人业务。随后，猎豹移动陆续推出了接待机器人、零售机器人、儿童陪伴机器人等产品，试图在AI领域寻找新的增长点。然而，AI业务投入巨大，且短期内难以实现盈利，猎豹移动的财务状况开始恶化。&nbsp;</p><p>后来，猎豹机器人开始悄然走进人们的生活。有数据显示，截至2020年10月底，已有超15000名猎户星空智能服务机器人走进大众视野，在35个城市的1000余家商场中忙碌穿梭。&nbsp;</p><p>然而，这些被猎豹寄予厚望、旨在构建“机器人互动营销网络‘AiM目标营销’体系”的智能使者们，却时常在人来人往的商场中显得形单影只，反应不够灵敏，功能也略显尴尬，有人戏谑地称它们为“行走的平板”。&nbsp;</p><p>据锌财经报道，猎豹疫情期间在全国商场投放的5000个多机器人，是以半卖半送的形式进入的。至于广告收入方面，以这样的体量尚不能形成规模效益，也寻找不到大客户、卖不出去高客单价。有前员提到，猎豹做机器人依然有工具思维的影子，就像一个线下的“工具”——也就是说，卖广告依旧会是机器人的重要收入来源。猎豹的本质都更像是一个广告公司，所有的工具和产品，最终是为了卖广告。&nbsp;</p><p><strong>尽管AI领域是目前互联网发展的大势所趋，但猎豹移动在短期内仍面临诸多挑战。</strong></p><p>2024年，科技圈掀起了一场“世纪大和解”的风波。周鸿祎与傅盛，这两位科技大佬在沉寂多年后，因一场对话再次成为焦点。而这场对话的背后，隐藏着两家公司对AI浪潮的野心与布局。&nbsp;</p><p>但AI产业的投入之大、周期之长，对于缺乏AI基因的企业来说，无疑是一场豪赌。猎豹移动也不例外。尽管公司在2016年就成立了人工智能公司猎户星空，并专注于机器人研发与应用，但多年来，人工智能业务并未给猎豹移动带来可观的收益。反而因为持续的高额投入，导致公司财务状况堪忧。&nbsp;</p><p>不过，大模型的应用场景与落地问题仍是摆在猎豹移动面前的一大难题。尽管机器人在商场优惠券等领域取得了一定的成功，但随着市场竞争的加剧和客户需求的变化，机器人业务也面临着巨大的挑战。如何拓展更多的应用场景，如何让大模型与机器人更好地结合，将成为猎豹移动未来发展的关键。&nbsp;</p><p>但持续的高额投入已经让公司的财务状况堪忧，而AI产业的投入又是一个长期的过程。因此，猎豹移动需要在保持研发投入的同时，积极寻求更多的盈利模式，以实现可持续发展。&nbsp;</p><p>财报数据显示，2021年和2022年猎豹的营收分别为6.54亿元和6.97亿元，和2017和2018年将近50亿元的年营收比大幅减少。&nbsp;</p><p>目前，猎豹的市值仅为不到8000万美金，和其最高时将近50亿美金相差甚远。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI4NDEyNDAyOA==&amp;mid=2648675108&amp;idx=1&amp;sn=b0a643bf9e42ea721e94f7a04becb88e&amp;chksm=f259376f89184fa650f59b79e1537311c94aa39a4834582579da95f30af0ef8f4a5a6c3386fd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“牛刀财经”（ID：niudaocaijing）</a>，作者：王海龙，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684920918080517</id>
            <title>出海只到第一步，智能宠物硬件却已掀起低价竞争｜小家电</title>
            <link>https://www.36kr.com/p/2684920918080517</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684920918080517</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 08:43:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 作者｜张子怡, 编辑｜彭孝秋, 智能宠物硬件, 中国宠物市场
<br>
<br>
总结: 中国宠物市场在智能宠物硬件领域发生了巨大变化，中国企业以价格竞争改变了产业格局。智能宠物硬件产品如智能猫砂盆和智能饮水机受到热捧，但面临价格竞争和同质化困扰。随着市场竞争白热化，一些企业选择出海拓展新市场。出海是当下的必然选择，尤其是美国市场具有巨大潜力。 </div>
                        <hr>
                    
                    <p>作者｜张子怡</p><p>编辑｜彭孝秋</p><p>一个有趣的宠物市场变化。</p><p>5年前，智能猫砂盆还是个鲜少听闻的品类，国内市场也主要由一款售价超5000元的美国品牌占据。高客单价让不少人望而却步。</p><p>5年后，一位智能宠物硬件领域的创业者告诉硬氪：“现在美国那款产品在国内已经卖不动了，主流的智能猫砂盆都变成了国产品牌，单价在2000元以上。”</p><p>这背后是<strong>擅长以充分价格竞争改变产业格局的中国企业，在继续发挥着“聪明才智”。</strong></p><p>事实上在中国，猫狗宠物已超过1亿只，中华田园猫是宠物猫中的主流担当，狗则是宠物类的主流担当。90后宠物主占比达到46.3%，七成宠物主都因为“喜欢宠物”而饲养宠物。（数据均截止于2021年）。</p><p>互联网上，“云吸猫、云吸狗”的人不在少数，由宠物衍生的表情包源源不断，宠物在家庭中的地位，已从“看家护院、捕捉老鼠”的实用性存在变身为家庭成员。由此，宠物产业市场规模年复一年的增加，到2021年已超过2000亿元，相关上市公司也有数家。</p><p>随着养宠理念的改变，除了常规宠物用品之外，智能宠物硬件品类作为细分赛道悄悄跑出，甚至从中国跑向海外。</p><p>智能猫砂盆和智能饮水机，是当下最受欢迎的智能宠物硬件产品。在智能宠物硬件领域，上述两款单品也备受价格竞争和产品同质化严重的困扰。</p><p>时至今日，中国养宠渗透仅在20%左右，智能宠物用品的渗透率则更低。然而，参与竞争的企业却愈发多，除了CATLINK、霍曼科技、小佩宠物等专门生产智能宠物硬件产品的创业公司，小米、美的、京东等大公司也在直接或间接参与其中。</p><p>国内竞争白热化后，不少公司选择出海作为新战场。智能宠物硬件产品不同于普通的电子消费品：产品稳定与功能迭代、国内外质量标准不统一甚至空白等等这些问题，都让出海的智能宠物硬件公司们面临着新困扰。</p><h3><strong>01 躲不过的低价竞争</strong></h3><p>硬氪访谈过的数位智能宠物硬件业内人士都认为，<strong>自动饮水机是目前渗透率最高的智能宠物用品，渗透率大概在20%以上。</strong></p><p>“‘猫咪要饮用活水，不然容易得肾结石’这类育宠理念，市场教育做得很好，基本深入人心。从2016年开始，初代智能饮水机产品在国内普及，在海外也很流行。而且这类单品价格低，对宠物主而言而好入手”「小壹科技」创始人Park告诉硬氪。</p><p>智能饮水机市场教育推行完善的同时，产品同质化非常严重。很多智能饮水机都有储水和清洁方面的问题，而行业还未攻克这类难题，导致很难有某一家的单品脱颖而出，以至于在价格战上打得十分激烈。</p><p>智能喂食器也有同样问题，多数都是从定时定量、宠粮保鲜、远程监控等角度入手，甚至在造型上也并无较大区别。</p><p>CATLINK CMO王敏君告诉硬氪：“智能饮水机的参与者特别多。因为饮水机本身结构比较简单，且开模起步只需数十万元。但智能猫砂盆开模要百万元起步，很多工厂资金有限，所以都会先从饮水机开始做。”</p><p>淘宝搜索智能饮水机，数十元到近千元的产品都有，功能本质大同小异。便宜的具备基本活水功能，昂贵的则是从猫咪健康、联网警报等细分功能做差异化。</p><p>代工类工厂的竞争能力不容小觑。硬氪报道过的「小壹科技」，是国内较早一批专门从事宠物用品OEM/ODM的供应商企业，公司客户主要为亚马逊、eBay和沃尔玛等线上线下渠道的卖家。赛维、有颗树等大卖也曾是其客户。截至目前，其已为上千家企业代工，自研产品销往全球20多个国家和地区，进入山姆、开市客等大型商超，销售额年均增长速度达400%。</p><p>产品研发方面，Park表示，「小壹科技」在3-4个月，可实现智能饮水类产品从定义到开模量产；喂食器和理毛机等功能稍显复杂的智能产品大约需要6个月，智能猫砂盆则需8个月。此外，能借助数十条自动化生产线，使出货速度比同行提升约50%，生产成本下降约15%。</p><p>在工厂型商家强大的生产能力面前，产品功能的差异化成为品牌类企业的求生法则之一。</p><p>例如，以智能猫砂盆为核心产品的CATLINK，其首款产品具备多猫识别、健康监测、一键铲屎等功能，高配版能供单只猫咪使用15天不铲屎，方便用户外出。自推出后，其便一直是CATLINK最为畅销的产品，截至目前全球累计销售超30万台。</p><p>此外，与自动化产品不同的是，CATLINK的智能猫砂盆、喂食器等产品都能与手机连接，在APP中显示猫咪体重、进食量、如厕信息等个性化数据，并形成不同猫咪的健康报告。当猫咪排便出现异常时，其会发出健康预警。</p><p>霍曼科技亦是如此。公司创始人兼CEO刘坤告诉硬氪，以智能喂食机为例，霍曼团队专门针对自动喂食器普遍的“卡粮”问题做优化，经内部大半年多次测试，都未出现卡食情况；其内置干电池，可以续航6个月，在断电情况下仍能续航 30 天，防止主人外出时停电让宠物断粮。</p><p>再比如智能饮水机，噪音是多数饮水机普遍具有的问题，不少家庭会选择拔掉饮水机插头，第二天再插回去的方式使用。“霍曼第一代饮水机的音量低于 20 分贝，不会影响人休息，同时满足主人和宠物的需求。第二代饮水解决了漏电的问题，我们将无线供电技术引入到水泵中，让水泵能够直接从饮水机拿出来，更加安全。”刘坤解释称。</p><p>这些细分的创新功能，让品牌类型的智能宠物硬件企业塑造品牌同时，避免持续卷入低价竞争的战况中。</p><p>刘坤认为，智能宠物硬件产品跟家电类产品相同，<strong>没有绝对的技术壁垒，只能在方案上做不断的创新，加入独特的细分功能。</strong>更重要的是，多数人都仍在使用传统方式养育宠物，行业仍处在非常初级的阶段。</p><h3><strong>02 出海是当下的必然选择</strong></h3><p>“国内竞争相当内卷”也是不少从业人士的共识，仅是智能猫砂盆，功能就有不少迭代。在美国品牌十年如一日的功能不变情况下，国内有不少品牌已经迭代到“自动加砂”、“自动打包”程度。</p><p>技术上的快速迭代以及价格优势使得不少企业都选择出海。</p><p>小佩宠物可能是当下跑得最远、最快的企业，相关数据显示，小佩的宠物智能科技产品已经覆盖全球三十多个国家，其中核心受众地区是美国，占比35%；其次是中国，占比23%。从社交媒体平台中可以看出，小佩的影响力从起初的北美，现已延伸到欧洲、俄罗斯、日本、泰国、越南等地。</p><p>美国也拥有着全球最大的宠物消费市场，根据咨询机构SkyQuest最新数据显示，2021 年全球宠物科技市场价值52亿美元，预计到2028年将达到175.7亿美元，复合年增长率为19%。超过52%的美国成年人为他们宠物购买了智能设备，在欧洲这个数字为67%。</p><p>事实上，对于智能宠物硬件企业而言，能够把业务布局到美国并不是易事，更多的是先在东南亚和日韩等临近国家发展。</p><p>由于智能宠物硬件产品是十分新兴的品类，全球基本没有针对这些产品的固定标准。绝大多数产品的使用标准需要从业者自己把控、调试、制定。因为使用对象的特殊性，所以对产品安全性、稳定性有极高要求。</p><p>宠物智能硬件的安全问题在全球都不时发生，全球网络安全公司卡巴斯基实验室调查显示，23%的被调查宠物主人，为他们宠物购买了智能设备，这之中的39%称自己宠物技术出现了某种故障（包括失灵和损坏）。</p><p>王敏君坦言称，CATLINK在发展初期布局于东南亚即是考虑到产品的稳定性问题，“产品离得近，发出去有问题可以及时寄回反馈，如果发货到欧美，来回四五十天，资金链压力太大。我们在确保产品稳定性足够后，才决定发展欧美市场。”</p><p>2023年，CATLINK在亚马逊美国站已上线5款智能产品及其配套用品，在黑五期间拿下了猫砂盆类目第一，实现年营收增长150%。</p><p>霍曼科技目前倾向于做日韩、中国台湾等东亚市场，则是考虑到目标群体育宠习惯问题。公司的核心产品是智能烘干箱。</p><p>在刘坤看来，欧美市场倾向于自然养宠，宠物洗澡频率极低；而日本对于宠物清洁度要求较高。此外，中国和日本居住习惯类似，家居整体面积较小，人宠生活动线结合紧密，人宠共居的矛盾会被放大，对宠物清洁度要求更高。如果进入欧美市场，需要针对当地的需求调整产品特点。</p><p>更重要的是，在育宠理念逐步改变的当下，宠物智能硬件安全问题一直是宠物主最关注问题。比如自动饮水机和智能项圈漏电、智能玩具导致宠物骨折、智能宠物窝闷死猫等事件频频爆出。如果不能有效规避此类安全问题，大多数宠物主仍将处于观望态度。</p><p>低价竞争也好，出海发展也罢，产品安全绝对是影响整个行业向前向后的问题。</p><p>在使用智能猫砂盆和自动喂食器半年后，拥有三只猫咪的谢临感慨：“猫猫自己养活自己，智慧养猫真方便”。但如果谢临出门在外，他仍然会关掉智能猫砂盆的自动铲屎等功能，并且通过摄像头远程监控，在猫咪不在猫砂盆的时候使用远程铲屎功能。“毕竟之前还是听过有猫猫被夹死的事情啊。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684874298653697</id>
            <title>Meta 首席科学家 Yann LeCun：AI 毁灭人类的概率为零</title>
            <link>https://www.36kr.com/p/2684874298653697</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684874298653697</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 08:20:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 未知恐惧, Meta, Yann LeCun
<br>
<br>
总结: 生成式 AI 的兴起带来了未知恐惧，Meta 首席科学家 Yann LeCun 的深度采访揭示了对 AI 的新视角。 </div>
                        <hr>
                    
                    <p>生成式 AI 的兴起惊艳了世界，如同所有新生事物一样，它的出现也伴随着人们对未知的恐惧和对新科技的不解。&nbsp;</p><p>尽管 AI 展现出了令人敬畏的能力，但其未来的轨迹和应用的广度，终究仍取决于我们如何设计和使用它。&nbsp;</p><p>近日， Meta 首席科学家、图灵奖得主 Yann LeCun 接受了科技博主 Lex Fridman 的深度采访。&nbsp;</p><p>从探讨 LLM 的局限性、到揭示大模型幻觉、再到讨论 AGI 的挑战、以及对 AI 末日论的批判，这场近三个小时的采访不仅干货满满，也为我们认识和理解 AI 提供了新的视角。&nbsp;</p><p><strong>原视频直达：https://www.youtube.com/watch?v=5t1vTLU7s40</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_05791ec7b6e34eaa9ee1a93e582d5bce@46958_oswg501275oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>金句如下：</strong></p><ul><li>通过感官输入，我们看到的信息比我们通过语言看到的要多得多，尽管我们的直觉是相反的，我们学到的大部分知识和我们的知识大多是通过我们对现实世界的观察和互动，而不是通过语言。</li><li>自回归预测，每产生一个标记或单词时，都有一定概率会使你偏离合理答案的集合。</li><li>我不讨厌强化学习，而且我认为它不应该被完全放弃，但我认为它应该被最小化使用，因为它在样本方面的效率极其低下</li><li>有可能制造一个没有偏见的 AI 系统吗？答案是，绝对不可能。这不仅仅是因为技术上的挑战，而是因为偏见存在于观察者的眼中。</li><li>未来已经到来，我们每个人与数字世界的互动都将由 AI 系统，AI 助手将起到中介的作用。</li><li>从计算能力的角度来看，我们离匹配人脑所需的计算能力还有很远的距离。</li><li>AI 末日论者想象了各种灾难性的情景，他们认为人工智能可能会失控或操纵，进而导致人类灭亡，这一观点基于大多是错误的假设。</li><li>我认为人类本质上是善良的。事实上，很多末日论者之所以成为末日论者，是因为他们认为人类本质上不善良，他们要么不信任人，要么不信任机构会做正确的事情。</li></ul><p>我们也摘取了部分原文（有删改）：&nbsp;</p><h2>LLM 的局限性&nbsp;</h2><p><strong>Lex Fridman</strong> 在你的职业生涯中，你实际上对人工智能的未来发表了一些强烈的技术性声明，但最近你说，像 GPT-4 这样的自回归 LLM（大型语言模型），以及即将到来的 LLaMA 3 等，并不是我们通往超人智能的正确途径。这些模型是如何工作的？为什么它们不能带我们走完全程？&nbsp;</p><p><strong>Yann LeCun</strong> 有很多原因。首先，智能行为有一些特性。例如，理解世界的能力，理解物理世界，记忆和检索事物的能力，持久的记忆，推理能力和规划能力。&nbsp;</p><p>这些是智能系统或实体的四个基本特征。LLMs 无法做到这些，或者它们只能以非常原始的方式做到，它们并不真正理解物理世界。它们没有持久的记忆。它们真的不能推理，当然也不能规划。&nbsp;</p><p>因此，如果你期望系统在没有做这些事情的可能性的情况下变得智能，那你就错了。这并不是说自回归 LLM 没有用。它们当然有用，它们很有趣，我们不能围绕它们构建一个完整的应用生态系统。 <strong>当然我们可以，但作为通往人类水平智能的途径，它们缺少了基本的组成部分。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_50996eb92b5b419db59ec4a56c2cbe3f@46958_oswg527937oswg1080oswg473_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然后还有另一个有趣的事实。这些 LLMs 是在海量的文本上训练的，包括互联网上所有公开可用的文本，对吧？这通常是 10 的 13 次方个标记。每个标记通常是两个字节，所以这是 2 乘以 10 的 13 次方字节的训练数据。&nbsp;</p><p>你我或许需要 170000 年才能读完这些，每天读 8 小时。所以看起来这些系统可以积累大量的知识，但然后你意识到这真的不是很多数据。如果你和发育心理学家交谈，他们会告诉你一个四岁的孩子在他或她的生活中醒着的时间是 16000 小时，这个孩子四年内到达视觉皮层的信息量大约是 10 到 15 字节。&nbsp;</p><p>你可以通过估计视神经每秒大约携带 20 兆字节来计算这个，所以对于一个四岁的孩子来说是 10 到 15 字节，相比之下，170000 年的阅读量是 2 乘以 10 的 13 次方字节。&nbsp;</p><p>这告诉你的是， <strong>通过感官输入，我们看到的信息比我们通过语言看到的要多得多，尽管我们的直觉是相反的，我们学到的大部分知识和我们的知识大多是通过我们对现实世界的观察和互动，而不是通过语言。</strong>我们在生命的前几年学到的一切，以及动物学到的一切，都与语言无关。&nbsp;</p><h2>LLM 能否构建世界模型&nbsp;</h2><p><strong>Lex Fridman</strong> 大型语言模型能否构建一个世界模型，知道如何开车，知道如何装载洗碗机，但目前不知道如何处理视觉数据，所以它可以在概念空间中操作？&nbsp;</p><p><strong>Yann LeCun</strong> 是的，很多人都在致力于这方面的工作。所以，简短的答案是：目前还不能。更复杂的答案是你可以使用各种技巧让 LLM 基本上消化图像或视频或音频的视觉表示。&nbsp;</p><p>一个经典的方法是以某种方式训练一个视觉系统，我们有多种训练视觉系统的方法，无论是监督的、半监督的、自监督的，各种各样的不同方法，可以将任何图像转化为高级表示。基本上是一个标记列表，与典型 LLM 接受的输入非常相似。&nbsp;</p><p>然后你就把那个喂给 LLM，除了文本之外，你希望 LLM 在训练期间能够使用这些表示来帮助做决策。我的意思是，这方面的工作已经进行了很长时间，现在，你看到了这些系统。&nbsp;</p><p>我的意思是，有一些视觉扩展的 LLM，但它们基本上是「黑客」，因为这些东西没有被训练来真正理解世界。它们没有被视频训练，例如。它们真的不理解直观的物理，至少目前还不理解。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_fcf2dc5097e941b69a70775253561356@46958_oswg657935oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Lex Fridman</strong> 所以你认为直观物理，关于物理空间的常识推理，关于物理现实。对你来说，这是一个巨大的飞跃，LLM 就是做不到？&nbsp;</p><p><strong>Yann LeCun</strong> 我们今天正在研究的这种 LLM 无法实现这一点。有多种原因，但主要原因是LLM的训练方式：你取一段文本，从中删除一些词，用黑色标记替换它们，然后训练一个神经网络来预测缺失的词。&nbsp;</p><p>如果你以一种特定的方式构建这个神经网络，使其只能查看左侧的词或它试图预测的词，那么你就有了一个系统，基本上是试图预测文本中的下一个词。然后你可以给系统一个文本，一个提示，你可以要求它预测下一个词。但这个系统永远无法精确预测下一个单词。&nbsp;</p><p>所以它会做的是产生一个字典中所有可能的词的概率分布。实际上，它不预测词。它预测的是类似于字典中可能的词的子词单元，所以处理预测中的不确定性很容易，因为字典中可能的词的数量是有限的，你可以简单地计算它们的分布。然后系统会从这个分布中选择一个词。&nbsp;</p><p>当然，选择概率更高的词的机会更大。所以从这个分布中抽样以实际产生一个词，然后将这个词移入输入，这样系统就不必预测第二个词了，一旦你这样做了，就将它移入输入，等等。&nbsp;</p><h2><strong>视频生成&nbsp;</strong></h2><p><strong>Yann LeCun</strong> 所以一个生成模型在视频上受过训练，我们已经尝试了10年，你给系统展示一段视频，然后让你预测视频的其余部分，基本上是预测接下来会发生什么。&nbsp;</p><p><strong>Lex Fridman</strong> 一帧一帧地发生。这也类似于自回归语言模型（LLM）的工作方式，但这是针对视频的。&nbsp;</p><p><strong>Yann LeCun</strong> 对。要么一帧接一帧——&nbsp;</p><p><strong>Yann LeCun</strong> ……这个想法已经流传了很长时间，我和我在 FAIR 的一些同事已经尝试了大约 10 年，但依旧不能像 LLMs 那样做同样的技巧。&nbsp;</p><p>因为我说过，你不能准确预测接下来会是哪个词，但你可以预测词的分布。现在，如果你去视频，你将不得不预测视频中所有可能帧的分布，我们真的不知道如何正确地做到这一点。&nbsp;</p><p>我们不知道如何在有用的方式来表示高维、连续空间的分布。这就是主要问题所在，我们之所以能做到这一点，是因为世界在信息方面比文本复杂和丰富得多。文本是离散的，视频是高维和连续的。这里面有很多细节。&nbsp;</p><p>所以如果我拿一个这个房间的视频，视频是相机在四处移动，我无法预测当我四处移动时房间里会有什么东西。系统无法预测当相机移动时房间里会有什么。也许它会预测这是一个有灯和墙的房间之类的。它无法预测墙上的画看起来像什么，或者沙发的质地看起来像什么。当然不是地毯的质地。所以无法预测所有这些细节。&nbsp;</p><p>至于可能处理这个问题的一种方式，我们已经工作了很长时间，是有一个所谓的潜变量的模型。潜变量被输入到神经网络中，它应该代表所有你尚未感知到的世界信息，你需要增强系统以便在预测像素方面做得很好，包括地毯和沙发的细腻质地以及墙上的画作。&nbsp;</p><p>这基本上是完全失败的。我们尝试了很多方法。我们尝试了直接神经网络，我们尝试了 GANs，我们尝试了 VAEs，各种正则化的自编码器。我们尝试了很多方法。我们还尝试了这些方法来学习图像或视频的良好表示，然后可以用作，例如，图像分类系统的输入。那基本上也失败了。&nbsp;</p><p>所有试图从损坏的版本中预测图像或视频的缺失部分的系统，基本上，所以拿一个图像或视频，损坏它或以某种方式转换它，然后尝试从损坏的版本重建完整的视频或图像，然后希望系统内部会发展出良好的图像表示，你可以用它进行对象识别、分割等。这基本上是完全失败的，而且对文本来说效果很好。这就是 LLMs 使用的原理，对吧？&nbsp;</p><p><strong>Lex Fridman</strong> 那么失败到底在哪里？是因为很难形成一个良好的图像表示，比如图像中所有重要信息的良好嵌入？还是图像到图像，图像到图像的一致性，形成了视频？如果我们做一个所有失败方式的高光剪辑，那会是什么样子？&nbsp;</p><p><strong>Yann LeCun</strong> 好的，所以这个不起作用的原因是，首先，我必须告诉你什么不起作用，因为还有其他东西是起作用的。所以不起作用的是训练系统通过从损坏的版本中重建良好的图像来学习图像的表示，好吗？这就是不起作用的。我们有很多这种技术的变体，这是我 FAIR 的一些同事开发的去噪自编码器，叫做 MAE，掩蔽自编码器。&nbsp;</p><p>所以基本上就像 LLMs 或类似的东西，你通过损坏文本来训练系统，除了你损坏图像，你从中移除补丁，然后你训练一个巨大的神经网络来重建。你得到的特征不好，你知道它们不好，因为如果你现在训练相同的架构，但你用标签数据来监督训练，用图像的文本描述等，你会得到良好的表示，而且识别任务的性能比自监督重建要好得多。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_fed0c809a20049f3a22944fe98a0cf35@46958_oswg411585oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>JEPA 与 LLM 的区别&nbsp;</h2><p><strong>Lex Fridman</strong> 我明白了。好吧，我们可能会继续争论。太好了。你喜欢 AMI，因为你喜欢法语，ami 在法语中是朋友，AMI 代表先进的机器智能。但无论如何，JEPA 能带我们走向那个先进的机器智能吗？&nbsp;</p><p><strong>Yann LeCun</strong> 嗯，这是第一步。首先，像 LLM 这样的生成架构有什么不同？LLM 或通过重建训练的视觉系统生成输入。它们生成未损坏、未转换的原始输入，所以你必须预测所有像素，系统中有大量的资源用于实际预测所有这些像素、所有细节。在 JEPA 中，你不是试图预测所有像素，你只是试图预测输入的抽象表示。在很多方面，这要容易得多。&nbsp;</p><p>所以 JEPA 系统在训练时试图做的是从输入中提取尽可能多的信息，但只提取相对容易预测的信息。世界上有很多事情我们无法预测。例如，如果你有一辆自动驾驶汽车在街上或道路上行驶，周围可能有树木，而且可能是刮风的日子。&nbsp;</p><p>所以树上的叶子以一种你无法预测的半混沌、随机的方式移动，你不在乎，你不想去预测。所以你想要的是你的编码器基本上消除所有这些细节。&nbsp;</p><p>它会告诉你有移动的叶子，但它不会给出每片叶子究竟发生了什么的详细信息。所以当你在表示空间中进行预测时，你不必预测每片叶子的每一个像素。&nbsp;</p><p>这不仅简单得多，而且允许系统基本上学习世界的抽象表示，其中可以建模和预测的内容被保留，其余的被视为噪声并被编码器消除。&nbsp;</p><p>所以它提高了表示的抽象层次。如果你考虑这个，这是我们一直在做的事情。每当我们描述一个现象时，我们都是在一个特定的抽象层次上描述它。我们并不总是用量子场理论来描述每一个自然现象。那是不可能的。所以我们有多个抽象层次来描述世界上发生的事情，从量子场理论到原子理论和分子和化学，材料，一直到现实世界中的具体物体等等。我们不能只在最低层次上建模一切。&nbsp;</p><p>这就是 JEPA 的想法，以自监督的方式学习抽象表示，你也可以分层地做到这一点。所以我认为，这是智能系统的一个重要组成部分。在语言中，我们可以不做这个，因为语言在某种程度上已经是抽象的，并且已经消除了很多不可预测的信息。所以我们可以直接预测单词，而不需要进行联合嵌入，不需要提高抽象层次。&nbsp;</p><p><strong>Lex Fridman</strong> 所以联合嵌入，它仍然是生成的，但它是在这种抽象表示空间中生成的？&nbsp;</p><p><strong>Yann LeCun</strong> 是的。&nbsp;</p><p><strong>Lex Fridman</strong> 你指出，在语言方面，我们很懒，因为我们已经得到了抽象表示，现在我们必须放大视野，实际上，对于通用智能系统，我们必须处理现实世界的全部物理现实。你确实必须经历这样一个步骤：从丰富、详细的真实世界跳转到那个世界的抽象表示，基于这个表示，你然后可以进行推理等操作。&nbsp;</p><p>Yann LeCun 对。而且问题是，那些通过预测学习的自监督算法，即使在表示空间中，如果输入数据更冗余，它们学到的概念就越多。数据中的冗余越多，它们就越能捕捉到它的一些内部结构。&nbsp;</p><p>所以在感知输入、视觉输入的结构中，冗余比文本要多得多，文本远没有那么冗余。这回到了你几分钟前问的问题。语言可能真的代表了更多的信息，因为它已经被压缩了。你说得对，但这意味着它也不够冗余，所以自监督，你不会做得那么好。&nbsp;</p><h2><strong>大模型幻觉&nbsp;</strong></h2><p><strong>Lex Fridman</strong> 我认为在你的一张幻灯片中有一个漂亮的图表，这是你展示 LLMs 局限性的方式之一。我想知道你能否从你的角度谈论一下幻觉，为什么大型语言模型会产生幻觉，以及为什么在某种程度上这是大型语言模型的根本缺陷？&nbsp;</p><p><strong>Yann LeCun</strong> 对， <strong>因为自回归预测，每产生一个标记或单词时，都有一定概率会使你偏离合理答案的集合。</strong>如果你假设，这是一个非常强烈的假设，这种错误的概率是独立于正在产生的一系列标记的，那意味着每当你生成一个标记时，你保持在正确答案集合内的概率就会降低，并且这个概率是指数级减少的。&nbsp;</p><p><strong>Lex Fridman</strong> 所以有一个强烈的假设，正如你所说，如果有犯错的非零概率，那么就会有某种漂移。&nbsp;</p><p><strong>Yann LeCun</strong> 是的，这种漂移是指数级的。就像错误会累积。答案变得毫无意义的概率随着标记数量的增加而指数级增加。&nbsp;</p><p><strong>Lex Fridman</strong> 让系统为人们可能提出的问题产生答案。而且人是人，所以他们有很多问题都非常相似，你可以通过收集数据，然后微调系统以产生所有这些问题的好答案，可能能够覆盖 80% 或任何人们会问的问题，而且它可能能够学会，因为它有很多学习的能力。&nbsp;</p><p>但然后是巨大的提示集合，你在训练期间没有涵盖，这个集合是巨大的，就像在所有可能的提示中，用于训练的提示的比例绝对是微小的，是所有可能提示的非常非常小的子集。&nbsp;</p><p><strong>Yann LeCun</strong> 所以系统将在已经训练、预训练或微调的提示上表现正常，但然后有一个巨大的空间，它不可能在训练中涵盖，因为数量是巨大的。&nbsp;</p><p>所以无论你对系统进行了多少训练以产生适当的答案，你都可以通过找到一个它未训练过的提示，或者类似的提示，来打破它，然后它就会完全胡说八道。&nbsp;</p><h2><strong>强化学习&nbsp;</strong></h2><p><strong>Lex Fridman</strong> 你提到了 RLHF，带有人类反馈的强化学习，为什么你仍然讨厌强化学习？&nbsp;</p><p><strong>Yann LeCun我不讨厌强化学习，而且我认为它不应该被完全放弃，但我认为它应该被最小化使用，因为它在样本方面的效率极其低下。</strong></p><p>因此，正确训练一个系统的方法是首先让它主要通过观察学习到好的世界表示和世界模型，可能稍加一些交互。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_9031cd6640f145d38752186b6ede87de@46958_oswg202591oswg1080oswg921_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Lex Fridman</strong> 为什么你认为 RLHF 工作得非常好？这种带有人类反馈的强化学习，为什么它对大型语言模型产生了如此变革性的影响，比以前更好？&nbsp;</p><p><strong>Yann LeCun</strong> 产生变革性影响的是人工反馈，有很多使用它的方式，其中一些纯粹是监督式的，实际上并不是真正的强化学习。&nbsp;</p><p><strong>Lex Fridman</strong> 所以这是 HF？&nbsp;</p><p><strong>Yann LeCun</strong> 是 HF，然后有各种使用人类反馈的方式，对吧？所以你可以要求人类写出答案，明天产生的多个答案。然后你做的是训练一个目标函数来预测那个评分。然后你可以使用这个目标函数来预测一个答案是否好，你可以反向传播梯度到这个系统，以便它只使用高度评级的答案。&nbsp;</p><p>这是一种方式，所以在 RL 中，这意味着训练所谓的奖励模型，基本上是一个小神经网络，估计答案有多好。这与我之前讨论的规划目标非常相似，只是现在它不是用来规划的，而是用来微调你的系统。我认为用它来规划会更有效，但目前，它被用来微调系统的参数。&nbsp;</p><p>有几种方法可以做到这一点，其中一些是监督的，你只是问一个人，这个答案好吗？然后你就输入答案。这些系统正在被调整的方式有很多。&nbsp;</p><h2><strong>AI 「觉醒」&nbsp;</strong></h2><p><strong>Lex Fridman</strong> 现在，很多人对最近发布的谷歌的 Gemini 1.5 表示了强烈批评，本质上，用我的话来说，可以说是非常「觉醒」（woke）。&nbsp;</p><p>它做了一些几乎荒谬可笑的事情，比如修改历史，生成一个黑人乔治·华盛顿的图像，每个人都开始询问设计这些 LLMs 的过程是什么？审查的角色是什么？等等。所以你在 Twitter 上评论说，开源是答案。&nbsp;</p><p><strong>Yann LeCun</strong> 是的。&nbsp;</p><p><strong>Lex Fridman</strong> 你能解释一下吗？&nbsp;</p><p>Yann LeCun 我实际上在我能参与的每一个社交网络上都发表了这个评论，我在各种论坛上多次提出这个观点。这是我的观点，人们可以抱怨 AI 系统有偏见，它们通常是由它们所训练的数据分布所反映的偏见，这在社会上是有偏见的，这可能对某些人有冒犯性，或者可能不是。一些去偏见的技术因为历史错误等问题而变得对某些人有冒犯性。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_ccc8e81f06aa4d4c8067d63427b1dc2c@46958_oswg302489oswg887oswg499_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以你可以问两个问题，第一个问题是， <strong>有可能制造一个没有偏见的 AI 系统吗？答案是，绝对不可能。这不仅仅是因为技术上的挑战，尽管这是一个技术上的挑战，而是因为偏见存在于观察者的眼中。</strong></p><p>不同的人可能对构成偏见的事物有不同的看法，有很多事实是无可争议的，但有很多观点或可以以不同的方式表达的事物。所以你不能有一个没有偏见的系统，这只是一种不可能。&nbsp;</p><p><strong>未来已经到来，我们每个人与数字世界的互动都将由 AI 系统，AI 助手将起到中介的作用。</strong>我们将拥有智能眼镜，你已经可以从 Meta 购买 Ray-Ban Meta，你可以与它们交谈，它们与 LLM 连接，你可以对任何问题得到答案。&nbsp;</p><p>或者你可以看着一个纪念碑，眼镜里有一个摄像头，你可以问它，你能告诉我关于这座建筑或这个纪念碑的什么？&nbsp;</p><p>你可以看着一个外语菜单，我认为我们会为你翻译它，或者如果我们说不同的语言，我们可以进行实时翻译。所以不久的将来，我们与数字世界的许多互动都将由这些系统来作为中介。&nbsp;</p><p><strong>我们将来使用的搜索引擎将不再是搜索引擎，而是成为对话系统，我们只需问一个问题，它就会回答，然后可能会指向适当的参考资料。</strong></p><p>但问题是，我们不能让这些系统由来自美国西海岸的少数公司控制，因为这些系统将构成所有人类知识的仓库，我们不能让少数人控制这些系统。&nbsp;</p><p>它必须是多样化的，同样的原因，新闻界必须是多样化的，那么我们如何获得多样化的 AI 助手？这非常昂贵和困难，目前，训练一个基础模型，一个基础 LLM，在未来可能会有所不同，但目前，那是一个 LLM。所以只有少数公司能够正确地做到这一点。&nbsp;</p><p>如果其中一些顶级系统是开源的，任何人都可以使用它们，任何人都可以微调它们。如果我们建立一些系统，允许任何一群人，无论是个人公民，公民团体，政府组织，非政府组织，公司，等等，利用这些开源 AI 系统并在他们自己的数据上为他们的自己的目的进行微调，那么我们将有非常多样化的不同 AI 系统，专门用于所有这些事情。&nbsp;</p><p>...&nbsp;</p><p>因此，要建立 AI 产业，要让 AI 系统不带有独特偏见，唯一的方式就是拥有开源平台，任何团体都可以在这些平台上构建专门的系统。所以， <strong>历史的必然方向是，绝大多数 AI 系统都将建立在开源平台之上。</strong></p><p><strong>Lex Fridman</strong> 这是一个美好的愿景。所以像 Meta 或 Google 这样的公司，在构建基础预训练模型之后，应该只进行尽可能少的微调步骤。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_5335b23149214a10ba34d8e28c98f84a@46958_oswg255017oswg850oswg478_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>LlaMA 3&nbsp;</strong></h2><p><strong>Lex Fridman</strong> Mark 宣布 LLaMA 3 最终会发布。我认为目前还没有具体的发布日期，但你对于已经发布的 LLaMA 2 以及未来的 LLaMA 3、4、5、6、10，或者更广泛地说，对 Meta 下的开源产品的未来有什么期待呢？&nbsp;</p><p><strong>Yann LeCun</strong> 有很多值得期待的事情。首先，会有各种版本的 LLaMA，这些都是对之前版本的改进，更大、更好的多模型等。在未来的版本中，系统将具备规划能力，真正理解世界是如何运作的，可能通过视频进行训练。因此，它们将拥有某种世界模型，也许具备我之前提到的那种推理和规划能力。&nbsp;</p><p>这需要多长时间？朝着那个方向的研究何时会进入 LLaMA 的产品线？我不知道。我不能告诉你。我们必须经历一些突破，才能到达那里，但你可以监控我们的进展，因为我们发表了我们的研究。所以上周我们发表了 V-JEPA 的工作，这是训练系统进行视频处理的第一步。&nbsp;</p><p>接下来的步骤将是建立基于这种思想的世界模型，从视频中进行训练。DeepMind 也有类似的工作正在进行，以及加州大学伯克利分校在世界模型和视频方面也有工作。很多人正在研究这个。我认为很多好的想法正在出现。我打赌这些系统将是轻量级的 JEPA，它们不会是生成模型，我们将看看未来会告诉我们什么。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_de08ef99e0a141348bd10f5b1c84f908@46958_oswg61908oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有一位名叫 Daniel Jar Hafner 的先生，他不在 DeepMind 工作，但他研究过这种类型的模型，这些模型学习表示，然后用于规划或学习任务通过强化运行。在 Berkeley，Peters 和其他很多人也在做这类工作。&nbsp;</p><p>实际上，我在纽约大学的背景下，通过一些资助与他们合作，同时也通过 Meta 进行合作，因为 Berkeley 的实验室在某种程度上与 Meta 有关联。所以，我认为这非常令人兴奋。我自从 10 年前 FAIRway 成立以来，就没有对机器学习和 AI 的方向这么激动过了。&nbsp;</p><p>在那之前，35 年前，我们正在研究组合网络和神经网络的早期。所以我非常兴奋，因为我看到了一条通往可能的人类水平智能的路径，系统可以理解世界，记忆，规划。有一些想法可以在那里取得进展，可能有机会奏效，我对此非常兴奋。&nbsp;</p><p>有些想法可能会让我们在这方面取得进展。我真的对此充满期待。我希望的是，我们能在我的大脑变得迟钝或我需要退休之前，找到一个好的方向并取得成功。&nbsp;</p><p><strong>Lex Fridman</strong> 是的。你也对这些庞大的 GPU 感到兴奋吗？整个训练过程都需要这么多计算能力，真是令人惊叹。想象一下，人类共同构建了这些计算设备，并能够训练出这样一个「大脑」。然后我们还会开源，就像给这个经过巨大计算系统训练的「大脑」赋予了生命。&nbsp;</p><p>这其中涉及到的训练细节、构建基础设施和硬件、冷却等等，都是令人关注的。你大部分的兴奋点是否仍然集中在理论方面，或者说是软件方面？&nbsp;</p><p>...&nbsp;</p><p><strong>Yann LeCun</strong> 确实， <strong>规模是必要的，但绝对不是充分的。因此，我们确实需要计算能力。从计算能力的角度来看，我们离匹配人脑所需的计算能力还有很远的距离。</strong>这可能在未来几十年内发生，但我们还有很长的路要走。在能源效率方面，我们更是远远落后。因此，硬件方面还有很多进步要做。&nbsp;</p><p>目前，很多进步并不完全来自硅技术，而是来自架构创新和更高效的实现流行架构的方式，比如变压器和协约的组合。所以，在我们达到饱和之前，还有很长的路要走。我们可能需要提出新的原则、新的制造技术、新的基本组件，这些可能基于不同于传统数字原理的新原理。&nbsp;</p><p><strong>Lex Fridman</strong> 有趣。所以你觉得为了构建 AMI，我们可能也需要一些硬件创新吗？&nbsp;</p><p><strong>Yann LeCun</strong> 是的，如果我们想让它无处不在，那确实需要硬件创新。因为我们将必须降低计算功耗。今天的 GPU 在 0.5 千瓦到 1 千瓦之间。人脑的功耗大约是 25 瓦，而 GPU 的功率远低于人脑，我们可能需要10万到100万个GPU。所以，我们在这方面还有很大的差距。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_7d4969a2fcc94ce1859f07d681a1f24a@46958_oswg405451oswg602oswg602_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>AGI&nbsp;</strong></h2><p><strong>Lex Fridman</strong> 你经常说 AGI（通用人工智能）不会很快到来，不是今年，也不是接下来的几年，可能更遥远。你背后的基本直觉是什么？&nbsp;</p><p><strong>Yann LeCun</strong> 首先，AGI 的出现不会是一个事件，对吧？科幻和好莱坞电影中的想法是，有人会突然发现 AGI 或人类水平的 AI 或 AMI 的秘密，然后开启一台机器，我们就有了 AGI。&nbsp;</p><p>但这不会发生， <strong>它不会是一个事件，而是一个渐进的过程</strong>。我们会有能够从视频中学习世界如何运作并学习良好表示的系统吗？&nbsp;</p><p>是的。在我们达到人类观察到的规模和性能之前，这将需要相当长的时间。这不会在一夜之间发生。我们得到能够拥有大量关联记忆的系统，以便他们能够记住事物吗？&nbsp;</p><p>是的，但同样，这不会在明天发生。我指的是，还有一些基本的技术需要开发。我们有很多这样的技术，但要让它们与整个系统协同工作，那就是另一回事了。&nbsp;</p><p>我们会有能够推理和规划的系统吗？也许沿着我之前描述的目标驱动 AI 架构的路线？是的，但在我们让这些正常工作之前，这将需要一段时间。&nbsp;</p><p>在我们让所有这些东西一起工作之前，然后在这之上，拥有能够学习层次化规划、层次化表示的系统，能够为手头的许多不同情况配置的系统，就像人脑一样，所有这些都将至少需要十年，可能更长时间。&nbsp;</p><p>因为我们现在没有遇到的问题还有很多，我们不知道在这个框架内是否有简单的解决方案。所以它并不只是拐角处。 过去 12、15 年里，我一直听到人们声称 AGI 就在眼前，但他们一直在犯错。当他们这么说的时候，我就知道他们是错的。我称之为他们的夸大其词。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_f809f1cf503c464590d5c250644db0d1@46958_oswg571354oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Lex Fridman</strong> 首先，从人工智能这个术语诞生以来，就有一种永恒的乐观主义，这可能与其他技术不同。这是莫拉维克悖论解释为什么人们对 AGI 如此乐观的原因吗？&nbsp;</p><p><strong>Yann LeCun</strong> 我不认为这只是莫拉维克悖论。莫拉维克悖论是意识到世界并不像我们想象的那么容易的后果。首先，智能不是你可以用一个尺度或一个单一数字来衡量的线性事物。你能说人类比猩猩聪明吗？在某些方面，是的，但在某些方面，猩猩在许多允许他们在森林中生存的领域比人类更聪明。&nbsp;</p><p><strong>Lex Fridman</strong> 所以智商是一个非常有限的智力衡量标准。人类智力比智商，所衡量的要大得多。&nbsp;</p><p><strong>Yann LeCun</strong> 嗯，智商可以大致衡量人类，因为人类形态相对统一，对吧？&nbsp;</p><p><strong>Lex Fridman</strong> 是的。&nbsp;</p><p><strong>Yann LeCun</strong> 但它只衡量一种能力，这种能力可能对某些任务相关，对其他任务则不然。但如果你谈论其他智能实体，对他们来说容易的基本事物非常不同，那么它就没有意义了。所以智能是一系列技能和有效获取新技能的能力。&nbsp;</p><p>特定智能实体拥有或能够快速学习的技能集合，与另一个实体的技能集合不同。因为它是多维的，技能集合是一个高维空间，你不能衡量，你不能比较两个事物，哪一个更聪明。它是多维的。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_0cb2e072be8149789330a544cdedfc8f@46958_oswg248137oswg640oswg360_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>AI 末日论&nbsp;</strong></h2><p><strong>Lex Fridman</strong> 所以你经常反驳所谓的 AI 末日论者。你能解释一下他们的观点以及为什么你认为他们错了吗？&nbsp;</p><p><strong>Yann LeCun</strong> 好的，AI 末日论者想象了各种灾难性的情景，他们认为 AI 可能会失控或操纵，进而导致人类灭亡，这一观点基于大多是错误的假设。&nbsp;</p><p>首先，他们假设超级智能的出现将会成真，某个时候我们会弄清这个秘密，然后打开一台超级智能的机器，它将接管世界并杀死我们所有人。但这是错误的。&nbsp;</p><p>它不会是一个事件。我们将拥有像猫一样聪明的系统，具有人类水平智能的所有特征，但它们的智能水平将像猫或鹦鹉或类似的东西。然后我们将努力使这些系统更智能。&nbsp;</p><p>当我们使它们更智能时，我们还将为它们设置一些安全措施，并学会如何设置这些安全措施，使它们行为得当。&nbsp;</p><p>这不会是单一的努力，会有很多人做这个工作，其中一些人将成功制造出可控、安全并具有正确安全措施的智能系统。如果有些系统变得失控，我们可以使用好的系统对抗失控的系统。&nbsp;</p><p><strong>所以这将是我的智能 AI 警察对抗你的失控 AI。所以不会像我们会被一个失控的 AI 暴露出来杀死我们所有人那样。那是不可能发生的。</strong></p><p><strong>人形机器人&nbsp;</strong></p><p><strong>Lex Fridman</strong> 好吧，至少会非常「喜剧化」。好的。既然我们谈到了物理现实，我很想了解你对机器人在这个物理现实中的未来愿景。你谈到的许多智能类型将使机器人成为我们人类的更有效的合作伙伴。&nbsp;</p><p>所以特斯拉的 Optimus 团队向我们展示了一些人形机器人的进展，我认为这确实重新激活了整个行业，我认为波士顿动力公司已经领导了很长时间。现在有很多公司，比如 Figure AI，显然还有波士顿动力。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_e278a19b013d436cac6b26ca8a2068e2@46958_oswg243381oswg594oswg396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Yann LeCun</strong> Unitree。&nbsp;</p><p><strong>Lex Fridman</strong> Unitree，但还有很多。&nbsp;</p><p><strong>Yann LeCun</strong> 有一些。&nbsp;</p><p><strong>Lex Fridman</strong> 这很棒，所以你认为不久将会有数百万人形机器人四处走动吗？&nbsp;</p><p><strong>Yann LeCun</strong> 暂时不会，但未来这会发生。我认为下一个十年对机器人来说将会非常有趣，机器人工业的出现已经等待了 10 到 20 年，除了预先编程的行为之类的东西，实际上并没有真正出现。&nbsp;</p><p>主要问题又是莫拉维克悖论，我们如何让这些系统理解世界如何运作并规划行动？所以我们可以为非常专业的任务做到这一点。&nbsp;</p><p>波士顿动力公司的方法基本上是通过大量手工制作的动态模型和提前仔细规划，这是非常经典的机器人技术，有很多创新。&nbsp;</p><h2><strong>展望未来&nbsp;</strong></h2><p><strong>Lex Fridman</strong> 当你展望未来 10年、20年、50年、100 年时，你对人类有什么希望？我们谈论了这么多令人兴奋的技术，这么多令人兴奋的可能性。在这一切中，有什么给你希望？&nbsp;</p><p><strong>Yann LeCun</strong> 我喜欢这个问题。我们可以用 AI 让人类变得更聪明。AI基本上会放大人类智能。就好像我们每个人都有一个聪明的 AI 助手团队。他们可能比我们更聪明。他们会按照我们的意愿行事，可能会以比我们自己做得更好的方式执行任务，因为他们比我们更聪明。 ... 现在，今天的 AI 的类比是什么？我们通过禁止 AI 保护谁？谁是要求监管 AI 以保护他们的工作的人？当然，这是一个真正的问题，即像 AI 这样的技术转型将对就业市场和劳动力市场产生什么影响？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_cd8247c447cd4a0cb10cda61273c9fed@46958_oswg328761oswg750oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有很多比我更专业的经济学家，但当我和他们交谈时，他们告诉我们，我们不会失业。这不会导致大规模失业。这只是不同职业的渐进转变。&nbsp;</p><p>未来 10 或 15 年将会热门的职业，我们今天无法想象它们会是什么。同样，如果你回到 20 年前，谁会想到 20 年前最热门的工作，即使是 5、10 年前，会是移动应用开发者？智能手机还没有发明。&nbsp;</p><p><strong>Lex Fridman</strong> 未来的大部分工作可能在元宇宙中。&nbsp;</p><p><strong>Yann LeCun</strong> 嗯，可能是这样的。&nbsp;</p><p><strong>Lex Fridman</strong> 关键是你无法预测。但你是对的。你提出了很多有力的观点。我相信人类从根本上说是善良的。所以如果 AI，特别是开源 AI，能让他们变得更聪明，它只会赋予了人类善良的力量。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_c1f96e347b724bcabf6f7b5ade518cf8@46958_oswg553886oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Yann LeCun我认为人类本质上是善良的。事实上，很多末日论者之所以成为末日论者，是因为他们认为人类本质上不善良，他们要么不信任人，要么不信任机构会做正确的事情。</strong></p><p><strong>Lex Fridman</strong> 我相信我们俩都信任人类。我想我的想法代表了许多人，感谢你们推动了开源技术的发展，推动了人工智能的开源研究，使人们能够使用，并且使这些模型本身也开源化。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ny6awp7BMvnRCZbn4lLTsA" rel="noopener noreferrer nofollow" target="_blank">“APPSO”（ID:appsolution）</a>，作者：用&nbsp;AI&nbsp;发电的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684858384956425</id>
            <title>不依赖token，字节级模型来了，直接处理二进制数据</title>
            <link>https://www.36kr.com/p/2684858384956425</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684858384956425</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 08:17:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT, bGPT, 字节, 模拟器
<br>
<br>
总结: 最新的GPT模型不再预测token，微软亚研院发布了bGPT，该模型基于Transformer，预测下一个字节。bGPT通过处理原生二进制数据，将所有输入内容视为字节序列，能够模拟CPU行为和MIDI音乐格式。研究团队认为字节是数字世界的基石，bGPT展示了处理原生二进制数据的强大能力和可扩展性。这一模型还展示了在处理传统媒体文件和非传统应用方面的潜力，同时提供了解决传统模型处理字节级数据挑战的解决方案。虽然bGPT展现出巨大潜力，但仍存在处理大规模数据序列的容量限制。 </div>
                        <hr>
                    
                    <p>最新GPT，不预测token了。</p><p>微软亚研院等发布bGPT，仍旧基于Transformer，但是模型预测的是<strong>下一个字节（byte）</strong>。</p><p>通过直接处理原生二进制数据，bGPT将所有输入内容都视为字节序列，从而可以不受限于任何特定的格式或任务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_6ffb5bd0107341cc86fb177d6c30473e@46958_oswg108568oswg1080oswg287_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>能预测CPU行为，准确率<strong>超过99.99%</strong>；还能直接模拟MIDI——一种音乐传输和存储的标准格式。</p><p>研究团队认为，传统的深度学习往往忽视了<strong>字节</strong>——数字世界的构建基石。</p><p>不论是信息的形式还是操作，都是通过二进制格式编码和处理的。字节构成了所有数据、设备和软件的基础，从计算机处理器到我们日常使用的电子产品中的操作系统。</p><p>这篇论文的标题清晰地指出了其目标：</p><blockquote><p>超越语言模型：将字节模型作为数字世界的模拟器。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_994e1e7f910c432aadc48233731dfa43@46958_oswg60373oswg1080oswg223_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>模拟CPU行为准确率超99.99%</h2><p>bGPT通过字节级处理，不仅能够应用于常规的AI生成和理解任务，还能处理<strong>更多非传统应用</strong>。</p><p>例如，它能够直接模拟MIDI——一种音乐传输和存储的标准格式，之前的研究由于MIDI的二进制本质而避免了直接对这类数据的建模。</p><p>但bGPT天生适合此类任务。它能够准确模拟符号音乐数据转换算法，在将ABC记谱法转换为MIDI格式时，达到极低的错误率（0.0011 BPB）。</p><p>在<strong>模拟CPU行为</strong>方面，bGPT展现出<strong>超过99.99%</strong>的准确率。这些实验显示了bGPT在处理原生二进制数据方面的强大能力和可扩展性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_fbf9ff568d0d499ea3734159d27d6d18@46958_oswg48598oswg904oswg804_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>bGPT还展示了在处理诸如文本、图像和音频传统媒体文件的生成/分类任务上的潜力，而且<strong>不需要任何针对特定模态的定制</strong>。</p><p>研究团队训练了一个大约有<strong>100M参数</strong>的bGPT，根据论文中的实验结果，bGPT可以与同样规模的文本模型（GPT-2）、视觉模型（ViT）和音频模型（AST）在各自的模态下有着可比的性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_3c9df7b0c6cb4c108e9ac9cfec308fed@46958_oswg78843oswg1080oswg387_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>字节到块策略：拓展序列建模长度</h2><p>在处理数字数据时，bGPT代表了一次重要的进步。</p><p>因为字节的粒度非常细，处理的字节序列通常较长，这对基于Transformer的传统模型来说是一个挑战。由于自注意机制的复杂度是二次方的，处理长序列的效率和可扩展性受到了限制。</p><p>bGPT的研发团队此前在音乐AI领域推出了CLaMP项目，并因此在ISMIR 2023上获得了最佳学生论文奖。</p><p>基于这项成果，bGPT采取了一种“<strong>字节到块（patch）</strong>”的转化方法。这个方法不仅极大提升了数据处理效率，还让长序列数据的处理和扩展变得更加简便。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_0eca4c5b87ec49e1a782dda274825bc7@46958_oswg103329oswg882oswg534_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>bGPT包含三个关键组成部分：</p><p><strong>线性投影层</strong>：通过线性投影将每个字节块转化为密集向量表示，既保留了关键信息，又降低了维度。</p><p><strong>块级解码器</strong>：顺序处理块的embeddings以预测下一个块的特征，使用自回归机制学习字节序列的整体结构。</p><p><strong>字节级解码器</strong>：根据块级解码器的预测特征来预测每个块内的字节序列，这一过程独立于每个块进行，依据当前块的特征表示。</p><p>bGPT提供了一种有前景的解决方案来应对传统模型在处理字节级数据时面临的挑战，显著提高了处理大规模数字数据序列的效率和可扩展性。</p><h2>拓宽边界：bGPT与未来数字世界的无限潜力</h2><p>尽管bGPT展现出巨大的潜力，但其也存在一定的局限性和改进空间。</p><p>目前，bGPT只能处理不超过8KB的数据序列，对于需要生成大量数据的现代应用来说，这一容量显然不够。这一局限主要由于训练和部署这类模型需要巨大的计算资源需求。</p><p>为了推进bGPT的实用性和适用范围，未来的研究将专注于开发更高效的算法和利用硬件进步以降低计算成本，使bGPT能够更加经济高效地处理更大规模的数据序列，从而拓宽其应用前景。</p><p>在探讨字节模型未来的话题中，来自世界各地的网友们已经提出了一系列脑洞。</p><p>他们探讨了<strong>在裸机上运行纯粹的神经网络</strong>，以取代操作系统执行命令的前景，或者利用网络修剪和自我学习来优化连接，使得超大规模网络具备自我重构的能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_6cd8f822a0a941dfbd90cfeaa56f7f01@46958_oswg255744oswg590oswg1280_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然实现这些目标需要时间，但bGPT有望实现将所有数据以字节形式输入，通过超大规模自我重构网络处理后再以字节形式输出的终极目标。</p><p>或许，在探索bGPT能力的边界时，想象力才是唯一的限制。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_66f5d2c7b47e487286f1c3350142813d@46958_oswg262931oswg1080oswg469_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>长期来看，bGPT展示的字节模型在推动人工智能进步方面展现了两大巨大潜能。</p><p>首先，它有望实现一个统一模型，将计算机中的所有数据整合起来，为实现真正的通用人工智能（AGI）迈出关键一步。</p><p>其次，bGPT推动了将AI作为操作系统（LLM OS）的概念，即利用这种字节模型作为核心，直接与文件、软件及底层硬件数据进行深度交互。</p><p>这不仅与Andrej Karpathy的AI愿景不谋而合，更重要的是，它开启了使用AI模拟数字世界各种层面的可能性——从精确模拟CPU操作到系统级软件的行为模拟，bGPT的能力远超传统界限。通过这种方式，bGPT有望成为数字世界的全面模拟器，探索和理解从基础硬件到复杂系统级软件操作的每一个角落。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_90630a55ff5542179cf4c8c51856c153@46958_oswg262931oswg1080oswg469_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>单凭对计算机文本数据的深入建模，我们已经见证了ChatGPT如何引发社会的广泛关注。</p><p>然而，文本数据在数字世界中海量数据的宏观图景里，不过只是冰山一角而已。想象一下，如果我们能够利用计算机中存储的所有形式的数据——无论是文本、图像、音频，还包括更复杂的二进制数据，乃至软件、操作系统和硬件本身的信息——来训练模型，能否创造出一个更加深入理解和精确模拟数字世界各个层面的模型？</p><p>bGPT的代码和模型已开源，如果你对探索字节级模型感兴趣，可以尝试在自己的数据集上使用bGPT进行训练，大胆探索它的潜能。</p><p>论文：https://arxiv.org/abs/2402.19155</p><p>代码：https://github.com/sanderwood/bgpt</p><p>模型：https://huggingface.co/sander-wood/bgpt</p><p>项目主页：https://byte-gpt.github.io</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/BLUTwhAlbXMPKYAgIoB_0Q" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：数字游民&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684880189800581</id>
            <title>对话：理解Sora，复现Sora</title>
            <link>https://www.36kr.com/p/2684880189800581</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684880189800581</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 08:16:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, OpenAI, ChatGPT, 技术架构
<br>
<br>
总结: 通过对Sora的研究和理解，AI从业者们对OpenAI的态度发生微妙转变，围绕Sora的技术架构、与ChatGPT的联系、开源可能性等问题展开讨论。李志飞作为主人公，致力于解密Sora的原理，对Sora和ChatGPT的冲击进行比较，同时探讨Sora的开放使用可能面临的挑战和合规问题。对于国内公司而言，追赶ChatGPT和Sora的难度各有不同，Sora的技术细节公开程度成为关键因素。 </div>
                        <hr>
                    
                    <p>经过1个月的发酵，国内AI从业者们对Sora的态度正发生着微妙的转变，从最初的震撼，到被未知裹挟的好奇、质疑，再到最近开始隐约出现“复现Sora”的潮流。</p><p>1份技术报告，32篇引用论文，一些画面堪比电影镜头的demo和1个故作高深的“世界模拟器”概念就是OpenAI给出的全部，没有技术论文，也没有可公开体验的产品入口。</p><p>OpenAI给全世界出了一系列谜题——Sora的技术架构到底是什么？和ChatGPT有什么联系？训练Sora是否会烧掉更多资金和算力？开源有机会反超Sora吗？OpenAI口中的“世界模拟器”到底是什么......？</p><p>本次对话的主人公李志飞，便是冲在一线破解谜题的人。</p><p>李志飞，出门问问创始人、CEO，美国约翰霍普金斯大学计算机系博士，前Google总部科学家，自然语言处理及人工智能专家，创业10年主导开发过语音助手、智能硬件，以及多个AIGC产品，如魔音工坊、奇妙元。</p><p>2022年底，感受到ChatGPT带来的心智冲击后，李志飞直接飞到美国，在距离OpenAI最近的地方寻找答案；但今年，李志飞没跟任何人聊，在他看来，“OpenAI很狡猾，他们试图隐藏一些东西”，而目前国内外社交媒体上对Sora激情评论的人基本“都是瞎猜”。</p><p>“过多的猜测只会浪费时间，既然找不到答案，还不如自己研究。”近一个月，李志飞一门心思研究Sora的原理，他几乎看遍了OpenAI列出的32篇论文。现在，他已经拼出了一幅完整的Sora技术架构图。</p><p>一年前，几乎是相同的时间，「甲子光年」曾与李志飞围绕ChatGPT的“炼丹大会”有过一次对话；一年后，甲小姐再次对话李志飞，主题转变为“理解Sora，复现Sora”。</p><h2>1.谈感受：“理解是没有终点的，我们只能无限逼近真相”</h2><blockquote><p>“我不觉得他们能有比我更深的认知，都是瞎猜。 既然找不到真正的答案，我还不如自己研究。”</p></blockquote><p><strong>甲小姐：</strong>到今天为止，你对Sora理解到什么程度？</p><p><strong>李志飞：</strong>我基本读完了所有Sora相关的论文，对Sora的理解更深了。但理解Sora不是封闭的数学题，<strong>现在我们对Sora的理解可能逻辑起点都是错的，是否在某个地方做了隐性假设都不知道。理解是没有终点的，我们只能无限逼近真相。</strong></p><p><strong>甲小姐：</strong>Sora跟ChatGPT相比，谁给你的震撼更大？</p><p><strong>李志飞：</strong>从原理突破来说，肯定是ChatGPT，或者说是它背后的GPT。今天，很多人都看过GPT许多相关论文，但还是很难理解大语言模型为啥有思维链（CoT）以及上下文学习（ICL）的能力，这是心智上的冲击。而Sora真正的冲击不在原理突破，因为ChatGPT出现后我们都能预见到AI生成高质量视频是必然的，<strong>只是没料到会这么快</strong>。Sora的冲击是它生成视频的时长、高质量以及一致性。</p><p><strong>甲小姐：</strong>Sora在业内引起的反响跟ChatGPT相比，哪个势能更大？</p><p><strong>李志飞：</strong>ChatGPT在2022年11月底发布，国内23年1月底才开始大规模讨论，2月左右出现创业潮，大概有三四个月的时间大家都非常兴奋，觉都睡不着，Sora肯定没到这种程度。一个重要原因是ChatGPT能直接体验。Sora的下一次高峰可能是OpenAI开放体验的时候，<strong>现在降火速度非常快</strong>。</p><p><strong>甲小姐：</strong>有人把Sora类比为GPT-3.5时刻，你认同吗？</p><p><strong>李志飞：</strong>这完全不对，如果一定要类比，<strong>Sora应该是GPT-2到GPT-3的过渡。</strong>因为GPT-2跟GPT-3原理上没什么区别，但<strong>GPT-3证明了Scaling law（规模法则）在文本数据上work，Sora进一步证明了Transformer和Scaling law在视频上同样能work。</strong></p><p><strong>甲小姐：</strong>OpenAI没有把Sora开放给大众使用，有没有一种可能是，现在的demo是他们精心筛选的结果，Sora的真实能力远不及此？</p><p><strong>李志飞：</strong>有可能。除非Meta的LLaMA-3也立马搞一个开源模型，能复现类似Sora的效果，以此证明Transformer和Scaling law确实能在视频生成领域规模化work。</p><p><strong>甲小姐：</strong>OpenAI可能会在什么时候开放Sora的使用？</p><p><strong>李志飞：</strong>具体何时不知道，OpenAI的Sora团队已在最新访谈中<strong>明确表示不会很快发布</strong>。如果Sora要商业可用，除了解决渲染速度、时间、成本等问题外，<strong>版权问题也是一个难点。</strong></p><p>文本的版权已经被搜索引擎重塑了一遍。2005-2010年，纽约时报等传统媒体不断诉讼谷歌搬运他们的原创内容。经过十几年的博弈，各方对文字内容版权基本形成共识。视频还没有经过这样的洗牌，大家的版权保护意识非常强。<strong>Sora要真正开放使用，可能要面临比ChatGPT更大的合规问题。</strong></p><p>我猜测OpenAI或许已经用了一些电影、电视剧、游戏以及YouTube的数据。如果只用社会媒体的UGC数据，Sora的生成效果可能根本达不到这个质量。</p><p>当然，Sora现在只是学术研究的demo，无法证明OpenAI到底有没有侵权。<strong>这也是OpenAI相对于谷歌的优势——他们在合规方面可以更加“野蛮”。</strong></p><p><strong>甲小姐：</strong>对于国内公司而言，ChatGPT和Sora哪个追赶难度更大？</p><p><strong>李志飞：</strong>去年和今年情况不太一样。去年国内对大语言模型原理的理解不到位，基础设施也比较差，导致最初的训练效率很低，GPU的利用率也很低。但好处在于，ChatGPT的原理有公开论文，你只要努力看懂就行。</p><p>今天我们在基础训练设施方面更成熟，可能只需要去年1/2甚至更少的GPU就能训练出同样的模型。但不好的地方是，Sora的技术细节并未公布，比如它用的编解码器到底是啥？60s的视频是一次成功生成的还是多次调整prompt的结果？60s是一个token sequence还是拆成了多个15s的token sequences？这些细节决定到底能不能复现。</p><p><strong>甲小姐：</strong>在你眼中，谁有可能最先做出“中国的Sora”？</p><p><strong>李志飞：</strong>我不知道。这次我没跟任何人聊，就是自己看论文，跟我们的工程师讨论，甚至连硅谷的人都很少聊。<strong>我不觉得他们能有比我们更深的认知，大家都是处于同一起跑线瞎猜。</strong>X上面那些人的认知、理解跟我们比也没有多大差别。去年ChatGPT出现后，我和业内的高频互动从结果看也对我作用不大。<strong>既然找不到真正的答案，我还不如自己研究。</strong></p><p><strong>甲小姐：</strong>你可以直接找OpenAI的人聊。</p><p><strong>李志飞：</strong>我懒得找，估计也找不着，OpenAI可能也就10个人做这个项目，再加上保密限制估计也聊不出啥。另外，我们要去实现Sora，并不一定要跟它一模一样，达到类似的效果就可以，那我肯定要有自己的一套理解去做。</p><p><strong>甲小姐：</strong>你为什么对Sora有如此大的兴趣？</p><p><strong>李志飞：</strong>一是个人爱好，去年读了不少多模态的论文，但大部分都是小打小闹的demo，各说各的，没啥让人信服的效果，但Sora的效果让我特别好奇到底是怎么做到的。二是我认为出门问问过去做的AIGC产品的终局就是视频生成。比如魔音工坊是为短视频生成配音，奇妙元是生成数字人视频。虽然这些产品现在的用户量和商业化都不错，但如果Sora这种端到端的技术路线成为主流，我们这些产品没有跟上就不会有竞争力了，所以我们必须理解并跟上。</p><h2>2.谈原理：“如果我是OpenAI，就做纯粹的GPT”</h2><blockquote><p>“GPT像人类的‘工笔画’，一笔一笔地画，后一笔依赖于前一笔；Diffusion很像人类的‘泼墨画’，‘一泼即成’，之后在初稿上一遍遍细化，直到最终呈现出一幅高清图像。”</p></blockquote><p><strong>甲小姐：</strong>OpenAI发布的Sora技术报告，你最关注哪个部分？</p><p><strong>李志飞：</strong>最让我困惑的是“时空编码器”，也就是OpenAI<strong>怎么把视频数据转成patch。</strong></p><p>刚开始我一头雾水，好奇每一步是怎么做的。OpenAI技术报告里也没怎么写，我就把编码器、解码器相关论文都看了一遍，发现其实<strong>没那么复杂。</strong></p><p>这里的patch就是大家常说的token，数据处理的原子性单位。就像人学知识一样，在一片汪洋大海中，你可能没有头绪，不知道怎么学，但把它分成块，每一块单独突破，肯定简单很多。</p><p><strong>甲小姐：</strong>概括一下patch的来龙去脉？</p><p><strong>李志飞：</strong>2021年6月，谷歌推出ViT（Vision Transformer），即用Transformer来做一个图片分类模型，<strong>这篇论文最早提出“patch”的概念，每一个patch可以当作一个token，用Transformer把图片转换成tokens。</strong>以前做图片分类不是基于token，都是用CNN提取图片feature（特征）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_c3838d8b13704637b61b21c45e12161f@46958_oswg78663oswg747oswg373_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：ViT论文&nbsp;</p><p>2021年11月，谷歌推出ViViT（Video Vision Transformer，视频ViT）。把ViT从图片拓展到视频，把视频也转换成了tokens。视频增加了时间的维度，这篇论文提出，要从时间和空间的维度同时切块，即<strong>时空patch</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_ddcaa882f66b491c95b24495614e38f8@46958_oswg231176oswg529oswg883_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：ViViT论文&nbsp;</p><p>2023年7月，谷歌提出NaViT（Native Resolution ViT），可以处理不同分辨率、纵横比的视频数据。</p><p>2023年10月，谷歌又推出MAGViT V2（Masked Generative Video Transformer），解决图片和视频联合训练的问题。</p><p><strong>强调图片和视频联合训练的原因有二：</strong>第一，视频跟文本对齐的数据很少，但图片跟文本对齐的数据很多。第二，图片有很多高分辨率的数据，但视频没有。所以图片跟视频最好在同一空间、同一vocabulary（词汇）中联合训练。</p><p>OpenAI可能还大量使用了模型再生数据。Sora技术报告明确说，他们将<strong>所有的训练视频与文本对齐，由专门的Dalle-3为之生成相应的captions（说明文字）。</strong></p><p><strong>甲小姐：</strong>视频数据token化后，在接下来的处理上和文本有什么本质区别？</p><p><strong>李志飞：照常理说，时空切片出来了，相当于视频数据已经token化，如果用GPT，那一切都简单了。但大家都猜测OpenAI没有用GPT，而是用了DiT（Diffusion Transformer）或其变体。</strong></p><p>类比来看，GPT的核心架构有三大块：编码器（tokenizer）、解码器（De-Tokenizer）和转换器（Transformer）。GPT的过程可抽象为：编码器将数据token化，通过转换器做上下文依赖关系的建模，再由解码器转换为人们熟知的形式。我猜测<strong>Sora核心也是这个框架，只是转换器换成了Diffusion。</strong></p><p><strong>甲小姐：</strong>到底什么是token？</p><p><strong>李志飞：</strong>Token是模型处理数据的基本单元，有两个方面，一是切分成块，二是分块后把对应的token值量化。</p><p><strong>很多人认为token一定是离散的，这是很大的误解。</strong>Token的值不一定离散，也可以是连续的。对Transformer来说也是如此，只要分块就可以了，它既可以处理连续值也可以处理离散值的分块。</p><p>文本模型通常使用离散表示，因为文本是天然离散的（文本是由字符或词构成的字符串），OpenAI用的<strong>DiT不需要将token值离散化，模型学的是不同连续值之间的关系。</strong>所以他们用的编解码器引用了VAE（Variational Autoencoder，变分自编码器），而不是VQ-VAE（Vector Quantization，向量量化）。</p><p><strong>Token值的离散和连续关系到模型学习的颗粒度，Tokenize都是为了找到最合适的、最能表示原始数据的学习颗粒度。</strong>假设token值的范围是0-100，如果token量化后以1为单位，就只有101个整数值（vocabulary的大小），但如果token值是连续的，那这个值就有无穷种可能。</p><p><strong>甲小姐：</strong>从思想上看，GPT和DiT的核心区别是什么？</p><p><strong>李志飞：GPT像人类的“工笔画”</strong>，一笔一笔地画，后一笔依赖于前一笔；<strong>Diffusion很像人类的“泼墨画”</strong>，“一泼即成”，之后在初稿上一遍遍细化，直到最终呈现出一幅高清图像。</p><p><strong>甲小姐：</strong>既然都可以“画画”，为什么不用GPT而用Diffusion？</p><p><strong>李志飞：说实话，如果我是OpenAI，就做纯粹的GPT，</strong>因为GPT擅长捕捉各种依赖关系，包括对长视频一致性很重要的远距离依赖关系。</p><p>我认为GPT的成功在于next token prediction，<strong>模拟人的思考方式。</strong>我觉得GPT也能模拟扩散的生成过程。具体来说，GPT生成一版粗糙的token sequence后，把它放在上下文窗口中再次生成下一版更精细的token sequence，如此反复，GPT也能完成扩散模型的“从粗到细”过程，这其实更像人类作画的方式。</p><p>但这对模型的上下文窗口要求很高。比如MAGViT生成2.125秒、帧率为每秒8帧、分辨率为128*128的视频需要1280个token，生成1分钟视频需要3万多个token；实际场景中分辨率和帧率都会更高，生成一分钟视频动不动就要几十万的token。</p><p><strong>以前不用GPT是因为模型支持处理的上下文窗口不够长，但这个问题现在已经解决了。</strong>如果一切模态的数据都转成token sequence，用Transformer学习它们之间的关系，那就很通用了。大家的注意力可以放在各种模态的Tokenizer以及数据收集上。</p><p><strong>甲小姐：</strong>既然如此，为什么过去文生图一般选择用Diffusion？</p><p><strong>李志飞：我猜测大家选择Diffusion，一是为了降低模型每一次学习的复杂度，二是为了找到正确的模型学习颗粒度。</strong>Diffusion把整个生成过程拆分为很多版本，不断加噪、降噪，完成从粗到细的过程，从而生成高分辨率的图片或视频。</p><p><strong>加噪、降噪本质是一种模拟人类作画的过程。</strong>模型难以学会一次性生成最终版图片，最好有不同清晰度的图片数据用来训练模型，比如第一版用粗略的轮廓图，第二版加入细节线条，第三版加颜色，第四版调整对比度，以此类推。<strong>但这些数据很匮乏，于是人为对一张图片加噪，制造不同清晰度的图片数据用于模型训练。</strong>降噪的过程则是把文本prompt作为条件，让模型学习不同版本图片之间的关系，进而学会把模糊的图片还原输出最终的高清图。</p><p><strong>甲小姐：</strong>DiT路线会成为文生视频领域的“大一统范式”吗？</p><p><strong>李志飞：</strong>之前文生视频有不同路线，有的是U-Net，代表包括SD、Gen-2、Pika等；也有把U-Net换成Transformer的，即DiT（Diffusion Transformer），Sora就是这条路。</p><p>我认为把U-Net换成Transformer应该是共识。Transformer更加scalable，最终可能会遵循Scaling law；而且，大家花了大量精力和金钱优化Transformer的工具链，各种论文也特别多，现在研究U-Net的人少了。</p><p><strong>但是否一定要用Diffusion？我认为不一定。我个人觉得用GPT把语言和视觉等模态统一处理更好。</strong></p><p>目前还处于技术早期、没有收敛，各种视频相关模型的分类或讲法比较混乱。我一直说OpenAI“狡猾”，他们的技术报告只是很笼统地引用了几篇谷歌的文章，但没说到底用了什么，怎么用的，以及做了哪些创新，<strong>感觉OpenAI在隐藏一些东西，你不知道他到底用了什么。</strong></p><p><strong>甲小姐：</strong>OpenAI的技术报告中强调了模型处理可变时长、分辨率、宽高比数据的能力，这些问题为什么重要？有多难？</p><p><strong>李志飞：</strong>自然界能收集到的图像数据有各种格式，比如不同分辨率，不同纵横比、不同时长。但以前学术研究为了简单，一般先把各种格式转换成一个固定格式。这相当于模型还没开始训练，在数据处理环节就丢失了很多信息。</p><p><strong>处理各种格式并不难，只是在学术界看来都是脏活累活，他们可能不愿意干</strong>。但如果要做一款面向公众的产品，用户的数据和需求一定是多格式、五花八门的，就必须解决这个问题。</p><p><strong>甲小姐：</strong>Sora用的很多技术路径都来自谷歌，你认为OpenAI真正的贡献是什么？</p><p><strong>李志飞：OpenAI真正的原创贡献是对Scaling law（规模法则）的信仰和实践。</strong>另外，他们<strong>把产品目标定义得非常好</strong>，比如说，别人都是生成几秒视频，他们敢于一开始把目标定为生成一分钟视频。如果这个目标实现很好的效果，就能对人产生很大的冲击；也<strong>正因为目标定义足够清晰，所以他们能够拆解一系列细分问题，并在文献中找到答案，而不需要每一个地方都自己做研究。</strong></p><h2>3.谈猜想：“视频生成的任务复杂度不见得比语言模型更大”</h2><blockquote><p>“跨模态的知识迁移超级重要。如果语言模型和视频模型能够深度融合，最终可能会实现技术路线的‘大一统’。”</p></blockquote><p><strong>甲小姐：</strong>视频生成的算力需求比文本更高吗？</p><p><strong>李志飞：</strong>我也没有答案。但如果视频模型一定比语言模型的算力需求还多，那我们就不用努力了，因为已经没什么意义了。我之所以努力看论文、想复现，是因为<strong>我觉得视频不像大家说的那样需要比文本多很多倍的算力。</strong></p><p><strong>甲小姐：</strong>Sora的模型规模多大？</p><p><strong>李志飞：</strong>大家猜测Sora可能只有30亿参数，我也觉得是百亿级别的参数，跟语言模型差了几个数量级。但是，这让我们很困惑：如果要让视频符合物理规律，那模型得有大量的世界知识，但模型又不大，这些知识从哪来呢？</p><p>现在大致有两种方法：一种是将语言模型的知识迁移到下游模态中，让视频继承语言模型里海量的常识，这会大大降低对视频数据质量和数量的需求，也会大大降低模型学习的难度；另一种是，只拿文本跟视频的匹配对去训练，这种匹配对含有的文本量很少，与几百万小时的视频相对齐的文本可能只有几百亿token，跟训练语言模型的万亿级别文本差距比较大。</p><p><strong>甲小姐：</strong>Sora是否是跟ChatGPT结合的模型？</p><p><strong>李志飞：</strong>我们之前分析得出，<strong>Sora跟语言模型没有深度融合，语言模型的世界知识没有有效迁移过来。</strong>如果只靠文本跟视频对齐的数据来训练模型，文本数量是非常少的，那么凭什么这个模型能够很好地学到世界知识，同时生成符合世界知识的视频？</p><p>我有个猜想：<strong>当我们用视频和文本联合训练模型，我们就有可能用比纯语言模型小很多的文本量，学出很好的世界模型。</strong>在这个前提下，<strong>视频生成的任务复杂度不见得比语言模型更大。</strong></p><p>我总结一下，一种方式是纯文本的模型去学世界知识；另外一种是用文本跟视频的对齐去联合学习世界知识。虽然文本数量远小于以前的全文本数据量，但还有大量视频tokenize后的tokens，另外视频模型的参数可能比语言模型小，此消彼长，最后视频模型和纯语言模型的算力需求可能相当。</p><p><strong>甲小姐：</strong>这个猜想很有意思，有点像小孩子成长的过程，要么死读书，要么一边读书一边在外面实践。</p><p><strong>李志飞：</strong>核心是grounding（抽象概念和实际的联结）。视频、图片是对文本抽象概念的一种grounding，哪怕你在文本里已经知道物理定义，但如果你没见过图片或视频，你脑海里还是没有特别具象的理解。</p><p><strong>甲小姐：</strong>OpenAI内部已经开始做知识迁移了吗？</p><p><strong>李志飞：</strong>我不知道，真的不知道，我再一次说OpenAI很狡猾。</p><p>我认为现在视频和文本是比较解耦的关系，GPT和Sora可能还是两个单独的模型，GPT生成文本的embedding（嵌入）只是作为视频生成的一个条件，用来指导视频的生成。</p><p>而Google的Gemini和RT-2反而是先把语言模型训练得很大，基于语言模型再加视频、图片和文字的对应关系，再接着往下训练，这样文本知识自然就迁移到下游的多模态任务里——这就是我一直强调的<strong>跨模态知识迁移</strong>。</p><p>比如，如果我们生成一只杯子掉在地板上的视频。今天的大语言模型本身就含有玻璃会碎、水会溅出等常识。如果不继承这些常识，视频生成模型还需要大量类似玻璃掉地的视频数据来训练。此外，语言模型还包含了对其它物理规律（比如声光电、碰撞等）的各种描述，这些知识都可以迁移到下游其它模态模型里。</p><p><strong>跨模态的知识迁移超级重要。</strong>如果我是OpenAI的工程师，我一定会重点做知识迁移。<strong>如果语言模型和视频模型能够深度融合，最终可能会实现技术路线的“大一统”。</strong></p><h2>4.谈争议：“大家不能对世界模拟器太认真”</h2><blockquote><p>“世界模拟器往深了研究是研究物理，然后你可能会变成研究神学。”</p></blockquote><p><strong>甲小姐：</strong>Sora发布后你写了一篇文章《为什么说Sora是世界的模拟器？》，现在你对世界模拟器有新思考吗？</p><p><strong>李志飞：</strong>当时我还没有系统性看论文，还不知道原理，现在我觉得<strong>大家不能对世界模拟器太认真。</strong>现在大家对世界模拟器想太多了。<strong>世界模拟器往深了研究是研究物理，然后你可能会变成研究神学。</strong>（笑）</p><p><strong>甲小姐：</strong>工程师就是有“造物”情结。</p><p><strong>李志飞：</strong>如果一直往下思考，你会进入一个很难具象的讨论，每个人都有自己的理解。上次有个活动在讨论Sora到底是不是世界模拟器，各说各的，没有一个具象的讨论基础，听得我都快睡着了。<strong>我现在一门心思只想知道Sora到底是怎么做到的，以及我该怎么复现Sora。</strong></p><p><strong>甲小姐：</strong>如果一定要回答，那你觉得Sora是否学会了世界模型？</p><p><strong>李志飞：</strong>如果你期望Sora学会了很多物理现象背后精准的数学公式（所谓解析解），比如说F = ma，V_t = V_0 + a*t，那Sora大概率没有学会世界模型，甚至永远都没法靠数据驱动学会。</p><p>如果你接受Sora学会很多物理现象展示的输入和输出的近似关系（所谓数值解），而且参数的数量远超精准数学公式里的参数个数，那么Sora大概率学会了世界模型，就算现在还没有“学会”，很快随着模型的scale up也能学会。</p><p>这就像ChatGPT可能学会了词性，但它学会的词性个数和颗粒度跟语言学家定义的可能很不一致。某种程度，我认为ChatGPT的词性定义可能更合理、更符合语言的规律。</p><p><strong>甲小姐：</strong>你到底相信哪一种？</p><p><strong>李志飞：</strong>相信第一种的“没学会”和第二种的“学会”本质不冲突，就看你是否抱着一种开放的心态，<strong>是否接受AI可以有跟人类不一样的世界观。</strong>如果你自负地认为人类总结的物理规律就是“伟光正”，那当我没说。</p><p>而且，就算Sora学会了世界的数值解，也只是人类观察到的世界，这个世界是“真”的吗？是不是模拟出来的？那什么是“真实”世界？你看，我们进入了讨论神学的境界。（笑）</p><p><strong>甲小姐：</strong>大家对世界模拟器的期待或许并不在于它理解所有因果关系，而是好奇沿着暴力美学的路径，能否实现用AI将整个物理世界数字化，继而演绎真实世界的可能性，这样人类可以从中选取最优解。例如工业界能够降低试错成本，科学界可以通过暴力美学发现未知的科学现象。</p><p><strong>李志飞：</strong>我们要定义清楚什么是世界模拟。如果从人的视角看，科学、工业都是人占主导，自然界只是配合，只要是人工的，由于我相信AGI会大概率超越人类，所以我相信AI能模拟和预测世界。<strong>如果从上帝视角看，世界还有很多事情是自然占主导，人类只是配角。</strong>比如灾难、风雨电雷以及各种未知的自然现象，人对这些问题无能为力，这个世界的90%，我们人类可能都没见过，我们凭什么去模拟它？除非上帝的规则很简单。</p><p><strong>甲小姐：</strong>要做世界模拟器要解决幻觉问题，60秒的视频里面任何一帧违反了力学或者光学定律就会不真实。假设幻觉问题始终解决不了，Sora的应用范围是不是就被锁在“文艺工作者”这个角色里了？</p><p><strong>李志飞：</strong>我认为终局不是两极分化的。<strong>幻觉问题百分之百不能彻底解决的。联结主义的核心就是“打碎重来”，一定会产生幻觉，这是它的feature，是它的基因。不像符号主义，只组合，不“打碎”，所以不会产生太多幻觉。</strong></p><p>ChatGPT和Sora虽然不能生成没有任何差错的世界，但并不代表它不能对世界模拟做出很多贡献。比如自动驾驶，我们可以用Sora生成很多以前根本搞不定的corner case，帮自动驾驶收集数据。</p><p><strong>甲小姐：</strong>现在我给Sora提出同样的问题，它给我的答案“可重现”吗？</p><p><strong>李志飞：</strong>训练模型的过程在采样、加噪、降噪、预测环节都有很多随机变量，如果要复现一模一样的视频，你只能把第一次采样的随机变量记下来，重现时不要再随机产生。但<strong>重现本身没有意义，模型不是这么玩的，你重现这个视频的生成还不如直接copy原来的视频。</strong></p><h2>5.谈竞争：“人才密度太高对大公司反而是问题”</h2><blockquote><p>“OpenAI一周就搞定的事情，他们可能两个月都搞不定。”</p></blockquote><p><strong>甲小姐：</strong>为什么很多人在谷歌没有做出ChatGPT、Sora这样惊艳的产品，到了OpenAI就能做到？</p><p><strong>李志飞：</strong>OpenAI使用的很多技术是谷歌之前做出来的工作，但很多都是学术论文，不是完整的工程系统，更别说产品了，只是个半吊子。</p><p>我之前也很困惑，我每次都觉得谷歌应该能跟得上，至少不会被OpenAI碾压，但这次在视频模型上又被OpenAI打得完全找不到牙。很多人把OpenAI的成功归因于它有很多天才，哪有那么多天才？你看一看谷歌团队的简历，哪个比OpenAI差？</p><p>但<strong>谷歌内部组织的复杂性和政治正确的文化，让他们很难做出好的生成式产品。</strong></p><p>写论文或做算法是小规模协作，可能顶多10个人，大家志同道合，就能做出一个原型系统，对组织力要求不高。但如果要面向公众发布一款生成式AI产品就非常难。<strong>生成式AI产品本身就有很大争议性</strong>，比如Deepfake（人工智能深伪技术）等隐患对大众追求的确定性有很大的冲击。</p><p><strong>谷歌作为公众公司，从算法原型到产品上线有难以跨越的鸿沟。</strong>具体来说，Google的算法团队Google Research和DeepMind都没有自己直接掌控的产品。如果要做新产品，谷歌CEO又不强势，二十多万人的公司，<strong>谁来own视频生成这类全新产品就成了巨大的难题。</strong>产品要上线就更难了，研发、PR、市场、 合规等各部门都有自己的考虑。大公司确实应该考虑这些，但这会让内部消耗很大。<strong>OpenAI一周就搞定的事情，他们可能两个月都搞不定。</strong></p><p><strong>甲小姐：</strong>这是否是所有公众公司都面临的问题？</p><p><strong>李志飞：</strong>美国大公司都存在这些问题，谷歌尤其典型。</p><p>因为谷歌人才密度太高，同一个研究方向有很多算法研究员和工程师，他们也会相互抢项目。你看过去几个月谷歌已经发布了好几个视频相关的模型，比如Gemini、VideoPoet、Lumiere等。这会让产品团队很困惑自己到底该用哪个模型。同一个方向，由于人才太多，他们算法团队可能有五六个，产品团队也有五六个，你可以算一下能产生多少交叉组合。</p><p>另外，工程师文化很理性，想抢到项目就要<strong>证明“我的模型比你好”——这本身就是一件巨复杂、巨耗时间的事情。</strong></p><p>我听说谷歌有团队去年本来做了视频生成模型，差不多就要集成到YouTube，但另外一个视频生成模型的团队负责人听到消息，就去和YouTube说应该用他们的模型。产品部门一方面迫于大佬的压力，另一方面也想看看到底谁更好，就开始评估。大家都说自己好，用自己的数据、benchmark跑一通，谁也说服不了谁，最后只能请外部团队来评估，又要搞一堆事，几个月又过去了。</p><p><strong>坦白讲，很多时候模型之间不会有太大差别，可能我今天比你差一点，我改一改，效果又跟你差不多了，就跟国内to B企业去竞标一样。</strong>很多最后都是靠关系或者低价取胜，而不是靠技术。To B项目竞标折腾下来要大几个月，谷歌内部产品可能也类似。到最后大家看产品上线无望，干脆离开，人才可能都被挖走了。</p><p>由于谷歌人才密度太高，我一直认为谷歌应该把算法团队拆成“开源模型、内部产品模型、前沿研究模型”三大块，各自有所侧重——开源更多面向开发者，要做得更通用、更轻量级，有更多工具链；内部产品模型团队则面向用户，相对to C，主要指标就是用户体验；前沿研究团队可以多花精力研究新算法。在人才等资源充分情况下，分开或许反而使每个项目都有ownership（主人翁意识），也有清晰的方向，不会一片混沌。</p><h2>6.谈应用：“模型应用的最终形态一定是视频生成”</h2><blockquote><p>“很多人老说开源‘套壳’，那都是不懂的人在瞎掰——你为什么要花大量时间、金钱和精力重新造个轮子，还不如别人的好？”</p></blockquote><p><strong>甲小姐：</strong>去年你曾说王慧文官宣的动作是想“吓退”其他人，但今年大家好像都没有被“吓退”，反而对复现Sora都很有信心。</p><p><strong>李志飞：</strong>作为初创公司，更多是从融资方面被“吓退”。比如说做语言模型，很多人的投入可能是我们的10倍甚至50倍，我们也没融资。一年下来，我们除了少烧几个亿外，语言模型的认知或实践也不见得就比同行差。我有种感觉，<strong>受限的资源更能做出创新。</strong></p><p><strong>甲小姐：</strong>对于复现Sora，你已经有信心了吗？</p><p><strong>李志飞：</strong>理论上是的，但真正要复现还需要很多细节，可能一个超参数就决定了能否生成高质量视频。这更多是我们工程师要干的活，他们要做各种实验，我只是抓住大的方向。</p><p>我给内部团队打气，说我们是少有的既懂语言模型、又有视频应用用户和数据的公司，所以我们有潜力做出好的视频模型。</p><p>但是，从公司投入上看，我们百分之百不可能像OpenAI那样做，因为我们没法那样烧钱，也不想那么做。就像去年2月追赶ChatGPT一样，我跟人说复现ChatGPT可能有“乞丐版”搞法。后来开源的LLaMA出来后，确实成就了很多“乞丐版”的ChatGPT。</p><p><strong>很多人老说开源“套壳”，那都是不懂的人在瞎掰——你为什么要花大量时间、金钱和精力重新造个轮子，还不如别人的好？我觉得核心是弄懂开源背后的细节，能在它基础上做创新。</strong></p><p><strong>甲小姐：</strong>谁最可能做出“乞丐版”Sora？</p><p><strong>李志飞：</strong>如果我是Meta的LLaMA开源团队，我必须搞。因为即使是做语言模型，要达到所谓的AGI水平，必须要有视频的模态。<strong>某种意义上，能解决视频的“生成”，“理解”自然就解决了。</strong></p><p><strong>甲小姐：</strong>为什么生成解决了，理解就解决了？</p><p><strong>李志飞：</strong>以语言为例，以前文本的理解是专门训练模型做情感分类、画语法树、做词性分析，都是单独做理解任务。但ChatGPT基于prompt的接口方式，一个生成模型把所有的理解任务都cover了。从原理上看，我相信只要你能回答出针对性的问题，就算是理解了，就像考试会出很多题目考我们对知识的理解一样。</p><p><strong>甲小姐：</strong>我认可<strong>生成是证明理解最好的方式。</strong>某种意义上，我们对于“理解”的定义本来就很模糊，但“生成”清晰得多。“<strong>理解”是内化，“生成”是外化。</strong></p><p><strong>李志飞：</strong>没错。而且，生成是用户能直接感受到的，更容易商业化。比如，语音识别是理解，很难商业化；但语音生成的商业化就更容易，我们的魔音工坊商业化就比较成功，因为用户能感知到。</p><p><strong>甲小姐：</strong>你对要做的产品有定义了吗？</p><p><strong>李志飞：</strong>我还没有考虑到视频的产品形态那一层，更多是先解决技术疑问。感觉Sora现在还不是产品，它没有应用场景。我们只是在尽量让我们的视频生成模型接近Sora的效果。视频生成有很多路径，Sora实现了最彻底的端到端生成，而且很通用。&nbsp;</p><p>从产品角度来说，<strong>我们做模型的终局就是视频生成，而且我们更关注短视频。</strong>但以前我也下不了决心，很难想象有一天能够端到端生成高质量的视频，但Sora让我们看到了希望。以前我也看过相关论文，但没有系统研究过他们之间的关系。Sora的技术报告把32篇论文串联在一起，我只用努力把这32篇论文理解清楚就有了个大概思路。</p><h2>7.谈终局：“我们正在接近大一统，接近智能的本质”</h2><blockquote><p>“从应用角度，视频是终局，语言不是最重要的，而且光有语言也意义不大。”</p></blockquote><p><strong>甲小姐：</strong>2024年有哪些看点？</p><p><strong>李志飞：第一，大家什么时候能用上Sora；第二，谁能复现Sora，最好是以开源的形式；第三，谷歌能不能在视频生成产品层面有不一样的表现。</strong>对谷歌我现在比较悲观，觉得他们可能又会发个论文，说可以生成5分钟的长视频，在一些榜单上比Sora表现得更好，但可能就是没有一个真正能打的产品。</p><p><strong>甲小姐：</strong>国内已经有团队说自己复现了Sora。</p><p><strong>李志飞：</strong>这种挺没意思的，有篇文章写清华一个团队说他们做的比DiT早。<strong>首先我根本不在意DiT，难点根本不在于把U-Net换成Transformer，而在于怎么在工程上真正做到scale up，提升生成质量，以及怎么从图片拓展到视频的时空建模。</strong></p><p>从实验的角度来说， DiT的数据规模很小，国内好像对DiT比较在意，网上都在说DiT，很少有人仔细分析Sora的内部原理。我认为DiT没那么重要。从复现角度来说，它可能是最容易理解、也最容易被复现的部分。</p><p><strong>甲小姐：</strong>每一位AI从业者此时可能都站在一个十字路口，下一步是去做文生视频、具身智能、Agent还是其他……爆点层出不穷，哪条道路是“主路”，你有建议吗？</p><p><strong>李志飞：</strong>不同角度肯定有不一样的思考。我永远都是用最简单的“技术-产品-商业化”三个层面思考。我认为<strong>从产品和应用角度来看，视频是终局，语言模型不是最重要的，或者说光有语言是远远不够的。</strong></p><p><strong>甲小姐：</strong>有人认为“语言就是一切”，LLM以文本的单模态就能实现AGI。</p><p><strong>李志飞：</strong>从纯技术角度我认同语言模型的重要性，语言是认知，图片、视觉、动作是感知，认知模型最难，机器学会了认知，再学感知就容易多了。但AI很大的价值就是代替人类的繁琐工作，而<strong>社会上绝大多数人不靠语言代表的认知赚钱，而是靠感知。你</strong>不能说环卫工人主要是靠认知赚钱，认知是这个工种的基础，但能赚钱的还是“扫地”这个感知的技能<strong>。</strong></p><p><strong>所以，语言代表的认知是基础和起点，声音、图片、视频、动作代表的感知才是应用的闭环。从最终的产品形态来看，只有语言认知意义不大。</strong></p><p>对模型层来说，确实要想视频怎么做，和语言模型有什么关系；对产品端来说，以前视频生成更多基于模板，现在Sora实现端到端生成，以前的产品也许就会被淘汰——原来的技术路线不升级，产品就没有竞争力，可能就是“死路一条”。这也是我为啥这么关心Sora的原因之一，我担心我们现有产品会死。当然，淘汰的过程不会太快，还有成本、版权等问题。<strong>Sora完全淘汰上一代视频生成产品，可能至少还要一两年。</strong></p><p><strong>甲小姐：</strong>2024年还会是OpenAI一家独大吗？</p><p><strong>李志飞：</strong>我没法直接给你答案，还得看Sora开放体验后，产品能否真正达到demo的效果。如果Sora的demo就是真正的产品能力，那我真的不知道谷歌什么时候能跟上，肯定比追ChatGPT更难。</p><p><strong>甲小姐：</strong>目前你已经拼出完整的Sora原理版图了吗？</p><p><strong>李志飞：</strong>我的结论只是基于论文，其实真正理解Sora的是一线工程师，因为我没有看源代码。<strong>最终的本质是代码，就像要理解这个世界就得拿到上帝的源代码。</strong>如果工程师除了看源代码外还具备抽象思维，比如想清数据和算法代码之间的关系，他们就是最理解Sora原理的人。但很多一线工程师对抽象问题没兴趣，更多是拿着别人的东西改代码，不愿真正理解背后的思想。</p><p><strong>甲小姐：</strong>OpenAI内部做AGI也会有团队分工，有点像盲人摸象，每人做一块，很难有人真正上升维度在抽象意义层面思考全局。</p><p><strong>李志飞：以前这个人是Ilya（Ilya Sutskever，OpenAI 联合创始人兼首席科学家），现在他可能被边缘化了。</strong></p><p><strong>甲小姐：</strong>现在AGI真正的源代码或许还分散在各位一线工程师的脑子里？如果有一位产品经理从上帝视角抽象出整个原理版图，现在我们对AI的理解或许会更深刻。</p><p><strong>李志飞：很多时候工程师没精力思考抽象问题，他们忙于调参数搞数据。</strong>但你要相信，<strong>和10年前相比，我们已经越来越接近智能的真相了。</strong>以前视觉、图片、声音、语言，都是完全不同工种的人通过不同方式在做，现在我们越来越接近大一统，接近智能的本质。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/u1GC8w8dmkN2XNhVy7M58g" rel="noopener noreferrer nofollow" target="_blank">“甲子光年”（ID:jazzyear）</a>，作者：甲小姐&nbsp;刘杨楠，36氪经授权发布。（原标题：《甲小姐对话李志飞：理解Sora，复现Sora》）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684713133588609</id>
            <title>奥特曼老黄齐预测：AGI五年内降临，代替95%工作，但马斯克断言AGI将被电力卡脖子</title>
            <link>https://www.36kr.com/p/2684713133588609</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684713133588609</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 07:35:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AGI, Altman, GPT-5, 人类智能水平
<br>
<br>
总结: AGI已经成为了一个新的「5年内实现」的未来技术，Altman和黄仁勋等人表示，达到人类智能水平的AI将很快到来，GPT-5等新技术的出现让人们感觉离AGI越来越近，但是AGI的实现还需要耐心等待，同时AGI的发展也面临能源短缺等挑战。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_cfafff39edd34939b6453ba8d44ac5c6@46958_oswg192990oswg797oswg453_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>突然间，AGI已经成为了一个新的「5年内实现」的未来技术。从Altman到老黄，都在不同场合表示，达到人类智能水平的AI将很快到来。而技术路径和未来可能出现的能源短缺，可能是达到AGI过程中的最大变数。</p><p>Claude 3、Sora、Gemini 1.5 Pro的纷纷出现，以及或许今年内就会被放出的GPT-5，让所有人都不约而同地隐隐感觉：我们似乎离AGI似乎越来越近了。</p><p>OpenAI CEO Sam Altman坚定地认为，AGI将在5年内实现。</p><p>不过，还需要我们耐心地等待。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_36d678803c5247338fb8f2be4d9bc5b4@000000_oswg47819oswg1080oswg169_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>英伟达CEO黄仁勋的观点与Altman不谋而合：如果我们对「像人类一样思考的计算机」的定义是通过人体测试能力，那么AGI在五年内就会到来。</p><p>谷歌机器人工程师Alex Irpan，在LLM出现后，修正了自己原先对AGI出现时间的预测：4年前，他认为AGI在2035年出现的几率是10%；现在，AGI在2025年，就有10%的几率出现。</p><p>更惊人的是，预测大神Jimmy Apples曾在去年爆料：AGI其实已经在内部实现了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_e17f0635c3c54354ba04c172bf41de99@000000_oswg88020oswg1080oswg234_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>初创公司Runway CEO兼AI投资人Siqi Chen也曾在去年表示，GPT-5预计在2023年底完成训练，OpenAI期待它达到AGI水平。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_21cf074c5976401fbf4cb854b60dfed2@000000_oswg286149oswg1044oswg676_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如此说来，马斯克的横插一脚，让AGI进程的加快损失重大……</p><p>离职OpenAI员工Logan.GPT表示，接下来的十年，将是人类历史上最重要的十年。</p><p>在这十年里，我们必定会拥有超人AI！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_4d4bd9009feb4e689cac11e8d3994484@000000_oswg176961oswg671oswg1186_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过细思恐极的一个问题是，AI实在是太耗水耗电了！</p><p>最近，ChatGPT耗电量惊人的话题，就上了微博热搜。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_79726cade3b54116aa428bff34e15162@000000_oswg102206oswg1080oswg179_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>前几天流传的PDF曝出，OpenAI新模型Q*的参数很可能达到了125万亿。让我们算一算，如果AGI真的出现，一天要耗费多少电能？</p><p>此外，马斯克在最近一个公开采访中表示，芯片短缺缓解，限制AI发展的将是电力和降压变压器的短缺。</p><p>而获取高效清洁能源的方法，会直接影响AGI的到来。</p><h2>Altman：AGI五年内实现</h2><p>Sam Altman在一本讨论AI未来发展方向的书「Our AI Journey」中说到，AI将能完成 「营销人员、策略规划人员和创意专业人员95%的工作」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_dec071bf963742c99f3c58a5755069a7@000000_oswg626165oswg1080oswg970_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（这本书采用订阅模式。新章节完成后就会发布）</p><p>他还说，AGI将在 「5 年内成为现实」。</p><p>这本书收录了两位商业创新者Adam Brotman和Andy Sack对包括Altman在内的顶级人工智能领导者的深度访谈。</p><p>Brotman是Forum3的联合创始人和联合首席执行官，此前曾担任星巴克首任首席数字官。Sack也是Forum3的联合创始人和联合首席执行官，曾任微软首席执行官Satya Nadella的顾问。</p><p>他们之前的背景表明他们不是那种只会说空话的人。</p><p>Altman讲述的内容总是能刷新读者认识的上限。</p><p>Altman认为，「当AI能够独立完成创新的科学突破时，它就能被称为AGI了」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_7955e32df51144f7bf7b542f00ddba26@000000_oswg577733oswg689oswg690_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>两位作者想知道AGI将如何影响他们的工作：市场营销。</p><p>于是他们问Altman，AGI对那些想要通过创作广告活动来建立消费品牌的市场营销人员意味着什么？</p><p>这时，Altman抛出了他的第一个知识炸弹：</p><blockquote><p>意味着营销人员今天使用代理公司、策略规划师和创意专业人员所做的95%的工作都将由人工智能轻松、近乎即时、几乎无成本地处理。</p><p>这一切内容都能做到免费、即时完成和近几乎完美可用。图片、视频、活动创意方案都没有问题。</p><p>而且AI很可能能够根据真实或合成的目标客户来测试创意，以预测结果并进行优化。</p></blockquote><h3>Altman称AGI即将到来</h3><p>两位作者再继续追问Altman，你认为 AGI 将在何时成为现实？</p><p>Altman回答到：</p><blockquote><p>5 年左右，也许会稍长一些——没有人能说出一个确切的时间，也没有人知道它对社会的影响到底是什么。</p></blockquote><p>这本书的作者Roetzer说，就算现在AGI还没有出现，人类就已经能看到经济、劳动力、教育和社会的大规模变革正在产生了。</p><p>就前不久，大型支付公司Klarna刚刚透露，它的AI助理现在已经能胜任700名员工的工作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_f4cd9153f0a941caaeffb7d8aef7c378@000000_oswg56161oswg1080oswg590_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个AI客服由OpenAI提供支持，处理客户的各种咨询，支持多语言，能够直接处理退款和退货的请求。</p><p>Klarna表示，在短短一个月内，AI助手就完成了700名全职客服的工作。</p><p>到目前为止，它已经进行了230万次对话，占公司所有客户服务对话的三分之二。</p><p>它的客户满意度得分与人工客服「不相上下」。</p><p>而且，它在解决客户请求方面更准确、更快速。解决请求的平均时间从11分钟降至2分钟。</p><p>Klarna的CEO暗示社会需要为先进的人工智能做好准备：</p><blockquote><p>这凸显了人工智能将对社会产生的深远影响。</p><p>我们希望社会和政界人士对AI带来的影响有慎重考虑，并相信全面、透明的管理对于我们社会应对这场变革至关重要。</p></blockquote><h2>老黄：AI会在五年内通过人类测试，未来10年算力将再提高100万倍</h2><p>老黄也同意这个观点，认为AGI将很快到来。</p><p>最近，英伟达CEO黄仁勋表示：AI会在五年内通过人类测试，AGI将很快到来！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_915c4f3ac9114815bde3c03a04fb698d@000000_oswg1011769oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在斯坦福大学举行的一个经济论坛上，黄仁勋回答了这个问题：人类何时能创造像人类一样思考的计算机？这也是硅谷的长期目标之一。</p><p>老黄是这样回答的：答案很大程度上取决于我们如何定义这个目标。</p><p>如果我们对「像人类一样思考的计算机」的定义，是通过人体测试能力，那么AGI很快就会到来。</p><h3><strong>五年后，AI将通过人类测试</strong></h3><p>老黄认为，如果我们把能想象到的每一个测试都列出一个清单，把它放在计算机科学行业面前，让AI去完成，那么不出五年，AI会把每个测试都做得很好。</p><p>截至目前，AI可以通过律师考试等测试，但是在胃肠病学等专业医疗测试中，它依然举步维艰。</p><p>但在老黄看来，五年后，它应该能通过这些测试中的任何一个。</p><p>不过他也承认，如果根据其他定义，AGI可能还很遥远，因为目前专家们对于描述人类思维如何运作方面，仍然存在分歧。</p><p>因此，如果从工程师的角度，实现AGI是比较难的，因为工程师需要明确的目标。</p><p>另外，黄仁勋还回答了另外一个重要问题——我们还需要多少晶圆厂，来支持AI产业的扩张。</p><p>最近，OpenAI CEO Sam Altman的七万亿计划震惊了全世界，他认为，我们还需要更多的晶圆厂。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_fa1545da0d114467995298d4738d22d4@000000_oswg52485oswg1080oswg235_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在黄仁勋看来，我们的确需要更多芯片，但随着时间推移，每块芯片的性能就会变得更强，这也就限制了我们所需芯片的数量。</p><p>他表示：「我们将需要更多的晶圆厂。但是，请记住，随着时间的推移，我们也在极大地改进AI的算法和处理。」</p><p>计算效率的提高，需求并不会像今天这么大。</p><p>「我会在10年内，将计算能力提高了一百万倍。」</p><h3>马库斯泼冷水：GPT-5在2024年不会出现</h3><p>一直唱反调的马库斯也做出了截止2024年底全新的预测——</p><p>我们可能会见证：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_3c9c5036dafc4e458071e4e26cf457ea@000000_oswg176486oswg1080oswg561_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>- 大约7到10款与GPT-4相当的模型问世&nbsp;</p><p>- 在技术上不会有革命性的突破（没有推出GPT-5，或者GPT-5并未达到预期）&nbsp;</p><p>- 市场上将出现激烈的价格竞争&nbsp;</p><p>- 几乎没有公司能够形成明显的护城河&nbsp;</p><p>- 尚无有效的方法来解决AI产生的幻觉&nbsp;</p><p>- 企业对这些技术的采纳将保持在一个适度的水平&nbsp;</p><p>- 利润相对适中，将在这7到10家公司之间分配</p></blockquote><p>网友表示，还有11个月就能见证这个结果了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_678b97685c9346d88f6e8c5f4513ba0f@000000_oswg52396oswg1080oswg174_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了证明自己的预测绝对影响力，马库斯还抛出了自己曾在2001年预测的模型幻觉问题。</p><p>以及两年前，2022年3月10日，曾发表了一篇「深度学习正在碰壁」的观点文章。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_9f35677ab0044a79b4ba10c57c36bd64@000000_oswg158035oswg1080oswg783_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>文章发表一个月后DALL·E问世，Sam Altman发文嘲讽，「请给我一个平庸的深度学习怀疑论者般的自信...」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_5f832c9c57fc427a98a6c32b213f2008@000000_oswg1775289oswg1080oswg1324_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在今天，马库斯再次表示「即便过了2年，深度学习依旧面临同样的根本性挑战」！</p><p>也就是说，人类靠深度学习到达AGI，遥不可及。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_04993a6af52e423580c0dae5f74984ed@000000_oswg78816oswg1080oswg283_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>https://garymarcus.substack.com/p/two-years-later-deep-learning-is?r=8tdk6&amp;utm_campaign=post&amp;utm_medium=web&amp;triedRedirect=true</p><p>文中他列举了多个例证，来说明这些观点至今依旧成立：</p><p>- 深度学习从根本上说是一种识别模式的技术，当我们需要的只是粗略的结果时，深度学习就能发挥出最大的作用。</p><p>- 目前的深度学习系统经常会出现愚蠢的错误。</p><p>- 扩大参数规模的争论——那些已经扩大参数规模的研究，并没真正改进LLM迫切需要的东西——「理解力」。Kaplan等OpenAI团队所提出的衡量标准——关于预测下一个单词，并不同于AI就实现深度理解。</p><p>- 「scaling laws」仅是观察到的现象，就像摩尔定律一样，可能不会永远有效。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_7e0157a986b242649429ded37de09b9d@000000_oswg60267oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/pdf/2001.08361.pdf</p><p>当然，马库斯最后表示，AGI并非不可以实现，而是人类需要一次范式转变。越来越多的结果说明，LLM本身不是通向AGI的终点答案。</p><p>与此同时，图灵巨头LeCun在最近的博客采访中，也谈到——AGI离我们还很远。</p><p>在这个访谈中，LeCun还提到了，「婴儿只有在已经了解了物质世界如何运作的基础知识之后，才能习得语言。很多物理知识都是内化的，无法用语言来描述，因此LLM也无法理解」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_f37f3d715dd8429ba9207df4e344dbab@000000_oswg152972oswg1080oswg323_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>吴恩达也参与了AGI的讨论，并表示AGI只会慢慢到来，而非一夜之间。</p><p>斯坦福团队凭借「大模型涌现能力是海市蜃楼」获得NeurIPS杰出论文奖，论文中提到大模型涌现能力的出现是因为研究人员度量选择，而不是因为模型行为，随着参数规模变化而发现根本变化。</p><p>当许多人突然意识到一项技术（也许是发展已久的技术）时，公众的感知就会出现断崖式的变化，从而会纷纷感到惊讶。</p><p>但人工智能能力的增长，比人们想象的要持续得多。这就是为什么我预计通往AGI的道路将包括许多前进的步骤，进而让系统的智能化程度逐步提高。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_0db5d184e2be43e0815b7e2796294212@000000_oswg500204oswg1080oswg1001_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>ChatGPT耗电量惊人，人类撑得住AGI吗？</h2><p>虽然AI模型已经在飞速发展，但最近的一个大问题已经让人揪心：它们实在太耗电了！</p><p>人工智能是能源的无底洞，AI未来将会被能源卡脖子。</p><p>包括Sam Altman在内的越来越多的AI行业大佬表示，AI的第一性原理，最重要的部分就是能源和智能的转化率的问题。</p><p>因为Transformer本质上不是一个能效很高算法，所以在未来，能源将会是困扰AI发展的一个大问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_6304e0925dee4b3f93d6a39359af970e@000000_oswg395000oswg840oswg560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>马斯克最近在一个公开采访中表示：</p><blockquote><p>AI是有史以来最大的技术革命，我从未见过任何技术进步比现在的AI更快。</p><p>芯片短缺的情况可能已经过去，但人工智能和电动汽车正在以如此迅猛的速度扩张，以至于明年世界将面临电力和变压器的供应紧缩。</p><p>现在AI对算力的需求差不多每半年就会增加10倍。显然，这种情况不可能永远以如此高的速度持续下去，否则会超过宇宙的质量。</p><p>AI计算的瓶颈是可以预见的……一年前，短缺的是芯片。</p><p>然后下一个短缺将是电力。当芯片短缺缓解之后，明年可能就会出现电力将不不足以运转这些芯片。</p><p>然后，很容易预测下一个短缺将是降压变压器。</p><p>如果电网输出100-300千伏的电压，然后必须一路降压至6伏，那么降压幅度就很大。</p><p>这有一个不是那么好笑的笑话，未来运行Transformer的变压器（Transformer）将出现短缺。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_35997df2133a45a3921da0fba17330e5@000000_oswg569238oswg700oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>Hinton：有1/10概率，AI会杀死人类</strong></h2><p>AGI真正实现那天，终结者中那一幕也在迫近。</p><p>「数字智能会取代生物智能吗」？</p><p>「几乎可以肯定，会的」！</p><p>「我们人类应该尽最大努力存活下来」。</p><p>AI教父Hinton近日在牛津大学发表了最新演讲，给出了惊人言论——在5-20年内，每个人都有1/10的概率被AI被杀死。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_195bef753fb54f128623d5246b5cd37e@000000_oswg257977oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>图灵奖得主Bengio也持有同样的观点，即有1/5的可能性，我们会被杀死。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_3ef83b40006d484fbeecbe9095b03d0e@000000_oswg144403oswg1080oswg335_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Hinton意识到，日益强大的AI模型可以像「蜂巢思维」一样，相互分享所学知识，从而相对于人类更具优势。它们可能是一种更好的智能形式。</p><p>就比如，GPT-4可以学习语言，会推理、讽刺，还会展现出极高的同理心。</p><p>他在演讲中说，「我要做出一个非常有力的声明，这些模型确实能理解」。</p><blockquote><p>这些模型也可能以危险的方式「进化」，形成一种控制的意向性。如果我为政府提供建议，我会说这些AI有10%的可能性会在未来20年内消灭人类。我认为这将是一个合理的数字。</p></blockquote><p>不仅如此，AI界大佬在「关于人工智能杀死所有人的可能性有多大」的问题时，认为有25-49%概率的人最多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_7694497afd0b48439be97ac940c5339f@000000_oswg258802oswg960oswg912_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不同的人/组织对AI灭世的概率预测。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_a2fd6662a53f4ee4aa7083fb9005d024@000000_oswg113934oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AI真的会杀死人类吗，你怎么看？</p><p>参考资料：&nbsp;</p><p>https://www.marketingaiinstitute.com/blog/sam-altman-ai-agi-marketing&nbsp;</p><p>https://twitter.com/garymarcus/status/1766871625075409381?s=46&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652453563&amp;idx=1&amp;sn=4d564520990fd6a74fb546517f31fdc5&amp;chksm=f03cdc3028b1bc10e574e96f204f597dbfc657f99563c84136fe487997034bbc626817cd5770&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，编辑：编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684701550246913</id>
            <title>互联网巨头该害怕了，「无 App」手机已经出现</title>
            <link>https://www.36kr.com/p/2684701550246913</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684701550246913</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 07:19:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI Pin, 激光投影, 量产消费品, 智能手机
<br>
<br>
总结: AI Pin 是一款完全 AI native 的产品，虽然具有激光投影和手势操作等创新功能，但在显示效果和用户体验上仍有不足，售价较高且缺乏本地化应用。与之相比，T-Phone 则是一款没有 App 的手机，通过 AI 辅助用户完成任务，如购物和订机票，展示了未来 AI 手机的潜力。其核心概念是通过 AI 预测生成界面，让用户成为技术的中心，摆脱对应用程序的依赖。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_d99f4644f4064601abbb46c25499a69a@000000_oswg507580oswg1080oswg801_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AI 初创公司 Humane 的 AI Pin，应该算是 MWC（世界移动通信大会）上最吸引人注意的明星产品。作为一个完全 AI native 的产品，AI Pin 满足了人们长久以来对硬件创新的期待，Open AI 的技术内嵌、激光投影、手势操作让 AI Pin 看起来是一款非常酷的产品。但是如果拿量产消费品的标准对待它的话，AI Pin 显然还算不上一个合格的产品。&nbsp;</p><p>例如，激光投影是 Humaine「去屏幕化」产品理念的体现，但是显示效果近似于卡西欧电子手表，远远比不上成熟的 OLED 屏幕；&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_2fba0dd37e7d4fce9c71f39b48975c47@000000_oswg279225oswg1080oswg664_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">AI Pin 激光投影｜图片来源：Humane&nbsp;</p><p>没有本地化应用，极度依赖网络。从现场的演示视频来看，任何 AI 回答都需要花去几秒钟的等待时间；&nbsp;</p><p>售价高达 699 美元（约合 5023 元人民币），此外还有每月 24 美元（约合 172 元人民币）的订阅费用；&nbsp;</p><p>抛开这些不谈，最关键的是，AI Pin 很难回应一个问题：<strong>既然我已经有一台智能手机了，为什么还需要 AI Pin</strong>？&nbsp;</p><p>同样的问题，一样适用此前在 CES 上出尽风头，几天卖出 5 万台的 rabbit r1。&nbsp;</p><p>另一些人的步子迈得没有那么大。同样是在 MWC 上，德国运营商 Deustche Telekom 联合 AI 初创公司 Brain.ai，展示了一款 AI 概念手机 T-Phone。&nbsp;</p><p>他们号称，这是一款没有 App 的手机——T-Phone 会不会是未来 AI 手机的雏形？&nbsp;</p><h2>「没有 App」的手机</h2><p>单从配置上来看，T-Mobile 可以说是标准的廉价手机：内存仅为 2GB，骁龙 625 是发布于 2016 年的 14 纳米处理器，前后双摄像头分别为 1500 万和 1300 万像素。&nbsp;</p><p>它的核心概念是这样：抛弃以往围绕 App 设计的手机，而是通过 AI，使用上下文预测来生成界面，帮助用户完成任务。因此，<strong>当你点亮屏幕，首先出现的是一个 AI 助手界面</strong>。在手机侧面也有一个实体的 AI 按钮，可以随时唤醒 AI 助手。&nbsp;</p><p>一个典型的场景是购物。当你向它询问：「我应该为我卧病在床的奶奶买些什么？」时，T-Phone 就会根据你的需求推荐相关的产品，从「床上小桌板」到「支撑颈部的 U 型枕」。&nbsp;</p><p>如果对这个产品感兴趣，点击之后，AI 会继续生成产品的详细信息，包括文字、图片以及视频。选中中意的商品之后，点击图片就会添加到第三方电商平台的购物车里。&nbsp;</p><p>Brain.ai 的创始人兼 CEO 乐圣（Jerry Yue）说，该系统在正式推出时将会吸引大约 7000 个电商网站。&nbsp;</p><p><strong>在这个例子中，T-Phone 的作用是一个电子商务聚合平台</strong>。&nbsp;</p><p>另一个乐圣展示的例子是购买机票。他告诉 AI 助理预订两张 3 月 12 日，从巴塞罗那飞往洛杉矶的头等舱机票手机停顿了一会，然后生成了一个航班列表。一旦乐圣找到合适的航班，他就可以使用他选择的移动支付系统进行支付，而无需切换到其他应用程序或服务。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_52bc860a442b442e8f8976335465afb4@000000_oswg392367oswg1024oswg683_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">使用 T-Phone 购买机票｜图片来源：CNET&nbsp;</p><p>不仅是购物，用户可以要求 AI 执行各种操作，例如建议旅行目的地、使用照片创建幻灯片、发布到社交媒体、起草文档等等。&nbsp;</p><p>T-Phone 的 AI 功能基于云和端的结合。<strong>对于高耗能的任务由云端 AI 处理，降低手机的功耗</strong>；对于一些低功耗的任务可以由本地的 AI 直接处理，以解决数据传输带来的延迟。&nbsp;</p><p>Brain.ai 认为，由于缺乏人类建立的这些连接的背景，今天的 App 无法实时动态地调整或适应人类的需求，也无法从过去的连接中学习，以适应新的需求。另一个 App 的缺点是他们通常在构建时的目的就是让用户沉迷其中。&nbsp;</p><p>「我们希望利用人工智能来做完全相反的事情——让人类成为技术的中心。你不去应用程序，应用程序来找你。我们想把权力交还给人们。」乐圣说。&nbsp;</p><p>德国电信和 Brain.ai 预计，十年后，你将再也不会记得应用程序。你只需与人工智能交谈，人工智能就会为你完成所有工作。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_2bf780820f9049b5ab09ad99a8f340ea@000000_oswg588205oswg943oswg530_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">乐圣在 MWC 上展示 T-Phone｜图片来源：androidpolice&nbsp;</p><p>听起来很美好，但是目前尚不清楚该如何设置送还信息、付款等信息；以及一旦出现售后问题，需要真人客户介入时，AI 助手又会如何帮助用户。&nbsp;</p><p>Brain.ai 曾在 2021 年推出过一款跟 T-Phone 概念高度类似的 AI 助理 App——Natural，尽管评分高达 4.7 星，但是很多也提到了没有售后、航班票价更贵等问题。&nbsp;</p><p>另外，如果用户只是想用微信聊天或者浏览邮箱该怎么办？这些场景下 AI 助手的加入并不会让效率变得更高。&nbsp;</p><h2>作为超级入口的 AI</h2><p>很明显 T-Phone 还处于早期阶段，这也是它是「概念手机」的原因。目前官方只展示了少量的使用场景，并且都算不上高频。试图用这样一款手机来代替传统智能手机显然是很困难的。&nbsp;</p><p><strong>实际上 T-Phone 并不是一台完完全全的 AI 手机，将主屏幕向上滑动，就可以进入传统的Android界面</strong>。本质上来说，T-Phone 是在传统 Android 手机的基础上外置了一层 AI 的壳。&nbsp;</p><p>这可能是 T-Phone 在产品理念上最聪明的一步，因为它并没有试图颠覆现有的智能手机，将 AI 助手作为了手机的第一入口。&nbsp;</p><p>入口为什么重要？因为它是所有功能展开的第一步。<strong>每一个经过入口的人，都是潜在的客户，都有可能交一笔过路费</strong>。&nbsp;</p><p>在个人电脑刚兴起的时候，微软把握住了操作系统这个入口。软件构建了用户场景，硬件才有意义，这个时候所有 PC 厂商就都是微软的用户。&nbsp;</p><p>互联网时代，微软又把握住了浏览器这个入口，凭借垄断地位进一步巩固了 Windows 操作系统。&nbsp;</p><p>早期的网民有一个习惯，就是把网址写在纸上，访问时需要一个一个字母键入。于是雅虎这样的门户网站应运而生。&nbsp;</p><p>再之后，网站数量爆炸式增长，在门户网站上翻页检索效率很低，就又诞生了谷歌这样的搜索引擎，并构建出了网络广告的商业模式。到今天，网络广告都是 Meta、百度、字节跳动最主要的收入来源。&nbsp;</p><p><strong>和 T-Phone 概念类似的&nbsp;rabbit&nbsp;r1、AI Pin 假设了一个场景，也就是所有人都翘首以待准备好进入 AI 时代</strong>。这可能是 AI 创造的幻觉，还没有人做好这样的准备。&nbsp;</p><p>iPhone 的诞生并非凭空而来。Apple 有了制造 iPod 等低功耗设备的经验；闪存需要以可承受的价格点变得可行；三星需要制造足够好的处理器；3G 网络需要推出；iTunes 音乐商店需要为 App Store 提供基础。&nbsp;</p><p>一切都在 2007 年发生了，于是移动时代爆发了。&nbsp;</p><p>技术的迭代往往是渐进的，从新技术的出现到实现终局，中间有漫长的迭代时间。新技术得发展到足够好；人们与旧技术的矛盾得足够激烈才会有勇气作切割。&nbsp;</p><p>从这个角度来说，T-Phone 不是一款不需要 App 的手机。相反，它是一台严重依赖现有 App 生态的手机，这也正是它更有可能成功的原因——人们也许没有准备好进入一个没有 App 的世界，但很多人应该乐于减少一些手机上的 App。&nbsp;</p><p>*头图来源：Humane&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653035812&amp;idx=1&amp;sn=9497c5f49c47f2bf09f3c574e32a0aed&amp;chksm=7f91976c3f9c331a182d5c8111f5beafb22839d50aad896ea7a1c70d4310a522d1e89bce8015&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：汤一涛，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684669640360065</id>
            <title>如何打造一个「电子茅台」，聊聊富士的产品策略及市场博弈</title>
            <link>https://www.36kr.com/p/2684669640360065</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684669640360065</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 07:16:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 富士 X100 VI, 京东抽奖, 相机品牌, 电子茅台
<br>
<br>
总结: 通过讨论富士 X100 VI相机的发布和销售过程，以及相机品牌在市场中的表现，探讨了相机行业的发展趋势和未来走向。 </div>
                        <hr>
                    
                    <h2>从新入手的 X100 VI 谈起</h2><p>富士 X100 VI（Fujifilm X100 VI）的发布和发售其实是有一个星期的间隔的，但是在这短短的一个星期里，我已经见到了几十上百个自媒体发布了关于这台机器的上手评测——这是只有大佬才有的待遇。我和各位一样，去京东上参与了一百多万人的联合抽奖，然后并未中选。&nbsp;</p><p>最后靠着和熟识的经销商达成了一个「当面开封、注册，且承诺持有半年不转卖」的君子协定之后，才最终拿到了这台 X100 VI。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_1f24c715173143f48388f2adbac36040@000000_oswg57285oswg1080oswg380_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>想来，京东这一百多万人里真是为了用才买的恐怕百不存一，更多的是看中了富士相机的理财属性，电子茅台实锤了。&nbsp;</p><p>笔者是 2018 年末「灭门」尼康入的富士。彼时富士还是一个靠着花拳绣腿耍狗驼子混日子的品牌，终端销量十分惨淡，也没有所谓的「经销商控价」政策——和现在的尼康索尼一样，拿货价加个一二百运费，不赔钱就能卖。&nbsp;</p><p>所以当你在京东上见到「富士 X-A10 16-50mm 套机+拍立得打印机 SP2+一盒相纸的礼盒」只要 2099 元还可以白条分期免息这么离谱的优惠的时候，你一定不要惊讶，这就是富士当时的基本操作。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_913c6eaa9b7149c0813c401f1b9f83c2@000000_oswg113147oswg1045oswg382_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">那时候就是这样&nbsp;</p><p>从清仓挥泪大甩卖的惨淡到如今的百万人抢购的盛况，这六年富士经历了什么？相机品牌那么多，为什么只有富士能担得起电子茅台这个称号？一定会有人说是小红书等平台炒作，是新媒体平台救活了富士。但是看过我之前那篇关于 CCD 的文章的朋友都知道，笔者并不认同光靠炒作营销就能实现销量的暴增，所以这其中一定还有其它的原因。&nbsp;</p><h2>从过去找答案</h2><p>2018 年，对于相机行业是一个具有划时代意义的一年，其重要程度不亚于 1959 年尼康推出大 F。自此，单反在专业相机舞台上彻底取代了旁轴。1985 年，美能达推出第一款自动对焦单反，使得佳能下定决心断臂求生换卡口，也明确了相机电子化的方向。2009 年的 5D2 发布，开启了用相机拍视频的时代。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_c7340265e05f446d96caaaeef2aea15f@000000_oswg90804oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">成就了历史经典的尼康大 F，图片来自维基百科&nbsp;</p><p>在 2018 年，首先是索尼发布了 A7R3（2017 年底）和 A7M3，在更换了新电池、采用了双卡槽设计之后，彻底打破了微单（无反）不能「干活」的固有印象。索尼的这一动作引发了婚庆摄影领域的一次装备革新，毕竟谁都想要更小，更轻，性能更好的机器，而婚庆摄影一直是专业（干活）摄影的标杆，索尼在这个领域站稳脚跟，也就有了未来称霸的底气。&nbsp;</p><p>同年发布的尼康的 D850 是尼康对自己 100 年生日的献礼，是当时最好的数码单反相机，但因为有 A7R3 的存在，销量远远不及预期，颇有些既生瑜何生亮的意味。而佳能也发现他们的新相机 5D4 不好卖了，「出佳为尼」的情况开始越来越多。&nbsp;</p><p>这一些列的现象都预示着一个「不好」的结果——索尼要做大了。所谓穷则思变，在业绩上的惨淡导致了尼康佳能做出了一个「违背祖训」的决定，他们开始进军无反领域。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_d2c26060e7cd4b7ca3a60151f80d9f11@000000_oswg226731oswg1080oswg331_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>尼康和佳能进入无反领域在当时都是爆炸性新闻&nbsp;</p><p>就在同时，M43 的一直的不温不火也使得松下开始考虑和奥林巴斯的关系以及今后的发展路线了。于是松下和徕卡适马眉来眼去，在同年组成了 L 卡口联盟。随着这些品牌的加入，也宣布相机的无反时代正式到来。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_e5f8f5f64cfa42b193425642461ba461@000000_oswg643602oswg1080oswg974_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>剩下的几个难兄难弟也组成了 L 卡口联盟，迎接无反时代的到来&nbsp;</p><p><strong>2018 年，我愿成为无反相机元年。</strong></p><p>而根据当时的市场表现来看，几乎所有人都会有一个共识，那就是：未来是属于全画幅的。&nbsp;</p><p>虽然索尼 E 卡口起步也是从 α NEX 3 开始，同样也是个半画幅，但是没过几年索尼就推出了全画幅 A7。尽管当时 A7 的性能比较拉胯，经常被人嘲笑，和当时主流的全画幅单反相比也不占优势，但莫欺少年穷，五年之后的故事大家也都看到了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_6614be1b59c54c91beec79166161f090@000000_oswg87014oswg1080oswg789_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">索尼 NEX-3，图片来自 DPReview&nbsp;</p><p>我们的主角富士在无反相机领域也是耕耘许久，早在 2012 年就推出了第一个可换镜头的无反相机 X-Pro 一代，如果要算上不可更换镜头的 X100，时间还要再提前两年，和索尼 E 系统算同年生。但至始至终富士从来就没打算出过全画幅相机，无论外接怎么呼喊，富士依旧不为所动。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_1a6ab85ddaf24a9f9c03edef05b9a8c5@000000_oswg125204oswg1080oswg750_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">初代 X100，图片来自 DPReview&nbsp;</p><p>当然富士也知道「底大一级压死人」这个道理，APS-C 画幅的 X-Trans 传感器再怎么优秀，也有其物理极限，它的上限也就那样，所以并不是富士不想做更好的相机，而是富士不愿意为了全画幅而妥协现在的优势——大不了就新开一条产品线嘛。&nbsp;</p><p>——2016 年 9 月，富士中画幅相机 GFX50S 横空出世。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_f73187a036a841bbb6db908d33109ba4@000000_oswg46949oswg1080oswg594_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">富士 GFX50S，图片来自富士&nbsp;</p><p>中画幅的成功我们按下不表，那是另一个故事。说回 X 系统，到 2018 年上半年，富士的三代 X-Trans 传感器机型刚好到了该更新换代的节点。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_f46e03a3e0a94275b0e6e01634248b2f@000000_oswg107152oswg1080oswg338_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">富士各代际传感器及对应机型&nbsp;</p><p>富士先是推出了带防抖的三代机 X-H1 准备最后再捞一笔，随后又给 X-T2 来了一个「史诗级」大 buff，大幅提升了 X-T2 的性能。但由于 X-H1 高得离谱的售价（13000+）以及并不怎么样的性能导致直接销量扑街，渠道商迫于资金链压力开始私自降价销售，富士在这个阶段的利润和口碑也跟着齐跌，「价高质次样子货」的固有印象深入人心。隔壁索尼都能干活挣钱了，富士还只能玩玩。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_9b129e8992574988a29db328ab4f5822@000000_oswg76542oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">富士 X-H1，图片来自 DPReview&nbsp;</p><p>如果放到其他厂家，在经历过这么大的挫折之后，就应该考虑改变赛道，果断推出全画幅相机去搞生产力来改变口碑，而富士却仍然不为所动。要知道，即便是在胶片时代，富士在 135 画幅的赛道上也没占什么便宜，唯一能拿出来说的也不过是和哈苏合作的 TX（XPAN)系列，剩下的一水的都是中画幅的 GW、GS 等等。我们之所以对富士这个品牌耳熟能详，并不是因为它相机做得多出彩，而是他的胶卷很流行。另一个胶卷巨头品牌是柯达也是如此。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_bfca2fe5c9c94359901d5edc6cfefc20@000000_oswg48124oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">富士 TX-1，图片来自 FUJILOVE MAGAZINE&nbsp;</p><p>正因为在胶片相机时代就留下了这个剑走偏锋的传统，所以富士在数码相机市场上遇到了一点挫折之后也没有改变初心，而是坚持自己的道路。&nbsp;</p><p>2018 年下半年，富士推出了第一款四代旗舰机型 XT3，由于是在苏州富士工厂生产的，成本比在日本本土生产下降了一大截，售价也是前所未有的低，比上一代旗舰 XT2 还要便宜，这在电子产品市场是极其少见的。而且，XT3 并没有因为价格低而放弃使用体验，你在当时能想象到的所有功能——只要富士能做——统统都加了进去。加之当时富士对渠道商的管控还没有这么严格，线下渠道商可以再优惠 1000 块，只要不到 9000 块就能买到。不仅如此，齐全的接口、丰富的扩展配件使得它即便去搞生产力也完全不虚。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_f882e0067a2948fb8071c774efe71fa2@000000_oswg103461oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">X-T3，图片来自 Amazon&nbsp;</p><p>「这是一台能让人有欲望拿出去拍照的机器。」时任 DPW 编辑的胡子哥在 2018 年底的总结视频中如此评价。&nbsp;</p><p>随后发布四代的机型也都是基于 XT3 的基础上增减功能，但都使用了同样的处理器和传感器，在性能上没有太大差异，并且有了 XT3 的价格锚定，在定位上不如它的机器，价格也会低上不少，而这些机器也就成了日后被炒起来的爆款机型。&nbsp;</p><p><strong>总的来说，富士的决策层在运营遇到困难的时候，没有像松下那样激进直接进军全画幅，也没像宾得奥巴一样摆烂，而是坚持自己的初心，专一地做 APS-C。厚积薄发，以提升产品力为主要目标，这也为日后的辉煌打下了基础。</strong></p><h2>打造一台「电子茅台」</h2><p>时间再次拨回到 2018 年夏天，尼康推出了 Z6 和 Z7，其中 Z6 官方售价为一万六左右，虽然不便宜，但是也收到许多全款预定的订单。尼康约定的交付时间是 2018 年的十月末，而这些尼康铁粉在十月末拿到首批 Z6 的时候，他们却一点也笑不出来，因为当时线下的价格已经崩盘，不要赠品可以做到一万一。也就是说，他们的新相机还没开封就已经折价了三分之一。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_aa89924e2ab74fa0acb64bf341d9c72f@000000_oswg135344oswg1080oswg296_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">尼康 Z6 上市时的新闻&nbsp;</p><p>电子产品的价格随着时间推移越来越便宜这是规律，电子产品的残值越来越低也是正常现象，相机首发售价一般都水分很大，等渠道商一铺开，迫于资金压力，就会有人开始甩货。最快两个月，最晚半年，相机的价格水分就被挤得差不多了，此时相机虽然也会随着时间推移慢慢降价，但是速率明显放缓，已经接近于正常折旧的速度，这时候就是出手买新机的最好时机。&nbsp;</p><p>由于卖相机不赚钱，渠道商更倾向于忽悠客户买套餐。但是随着网络媒体发达，大家都知道渠道商的套餐都是一些烂货，久而久之也就都忽悠不动了。相机这个东西，卖一台佳能赚 100，卖一台尼康也是赚 100，卖一台索尼同样赚 100——顾客买哪个都行，何必费力气吆喝。&nbsp;</p><p>正因为有尼康的前车之鉴，富士在 2019 年以后开始着手对渠道商进行整治，在淘宝、京东等电商平台，不再允许以低于官方指导价的价格进行售卖，否者将会进行处罚。&nbsp;</p><p>最著名的例子就是在 2019 年 5 月，一个来自于山东淄博的电商在拼多多上申请了百亿补贴的活动，售卖 XT30 套机，原本官方售价 6600+ 的套机在这里只要 5549 元，虽然只有限量 50 台，但买到就是赚到。&nbsp;</p><p>笔者也凑了一波热闹买了一套。后来与店家熟络了才知道，店家因为这个事，被富士扣了六位数的分红以及断供了两个月。&nbsp;</p><p>无独有偶，在同年十月，另一家据说是南京的商家也以 5499 元的价格售卖过 XT30 的套机，同样地，这个店家也受到了富士的处罚。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_1dbea58f2be84aa1b8ea0159d3f27e02@000000_oswg102884oswg1080oswg1182_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">当时的订单截图&nbsp;</p><p>不要妄想还有类似的机会——这两个拼多多店家都是马甲号，干完这一票之后陆续都关了。&nbsp;</p><p>整治渠道这一招有两个好处。一方面是防止由于快速降价导致消费者对品牌的不信任，在这一点上腾龙就是一个典型反面案例。2017 年年底，腾龙的 SP 35mm 和 45mm 第一方降价直接让海鲜市场的二手价格倒挂，而且这样的骚操作腾龙不只搞过一次。2022 年，腾龙的 17-70mm（富士卡口）降价同样让二手价格倒挂，梅开二度。以至于用户现在看腾龙镜头都有点 PTSD 了，生怕再给背刺一下。好在腾龙售后的 5+1 不看发票只看序列号，比较给力，才勉强保住口碑。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_7d97f6cb4436444ebca80c63d4e7b3a1@000000_oswg99192oswg1080oswg1272_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">刚上市时的腾龙和降价后的腾龙&nbsp;</p><p>第二个好处就是给渠道商留有充足的利润和操作空间，提升了渠道商的积极性，使得渠道商更愿意推荐用户去买富士的产品。就好比你去药房买感冒药，店员给你推荐的一定不是最好用的一款，一定是他们利润最高的一款。&nbsp;</p><p>但是单单整治渠道并不能完全杜绝渠道商低价出货，某些人仍然可以低于官方售价从渠道商拿到富士相机。只要你不说，我不说，富士上哪知道到底卖了多少钱？不过这种毕竟是少数，只能熟人操作，碰到一个钓鱼的，这半年可能就白干了。&nbsp;</p><p><strong>但是整治渠道的效果也是实打实的，二手富士相机因此可以挂得更高，和富士新机的价格并没有太明显的差距，保值率的明显提高也间接促进了富士新机的销售。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_d73100097e71479592e76482c7e4ff4c@000000_oswg627123oswg883oswg969_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">X100V 在二手市场上的价格比当初的零售价还高&nbsp;</p><p>富士用以上两点成功地挽回了在相机圈子里的口碑。此时，距离它爆火，其实就只差一个爆款的产品了。&nbsp;</p><p>这款产品就是 X-S10。&nbsp;</p><p>富士为了这款爆火的产品也是铺垫了好久，其中一个就是在 X-Pro 3 上新增加的经典负片（NC）滤镜。不过 X-Pro 3 并没有因此得到更多的关注，反而是富士目前为数不多不溢价的产品。最主要的原因还是价格太高——就多了个一个光电混合取景器，凭什么就要比 X-T3 贵上两三千？区区钛合金不要也罢，凭什么又要贵一千？NC 滤镜是很好，但是你让我花一万二去买，我的钱也不是大风刮来的，不能这么败家。&nbsp;</p><p>再后来大家知道通过修改 RAW 文件也能在后期软件上套用 NC 滤镜之后，X-Pro 3 就更无人问津了。随后富士发布的 X100V 和 X-T4 也都带 NC 滤镜，同样是因为价格较高，并没有在市场上产生多大的水花，别看这俩机器现在火，其实都是在近两年才炒起来的，发布之初没那么大的热度。&nbsp;</p><p>2020 年的全画幅市场可谓是热闹非凡，佳能炒作了大半年的能录 8K RAW 视频的 EOS R5 终于发布了，但随即被曝出过热问题，紧接着索尼拿出不过热但是像素只有 1200 万的视频机 A7S3，随后，尼康Z6 II、Z7II、松下 S5 纷纷亮相，你方唱罢我登场，晋西北已经乱成了一锅粥。&nbsp;</p><p>但是谁也没想到，2020 年的全场最佳居然是一款半画幅相机——富士 X-S10。&nbsp;</p><p>从性能上来说，X-S10 就是 X-T4 的简配版，没有使用复古的外观。因为有 X-T4 的价格锚定，外界普遍认为 X-S10 不会低于 8000 元。&nbsp;</p><p>等到发布当天，富士来了一波大的，直接定价 6999 元。&nbsp;</p><p>这还不是最上头的，因为临近双十一，借着这个机会还能再减 500，首发 6499 元，还送一堆赠品。&nbsp;</p><p>就这价格，谁来谁都迷糊。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_c4f703a5e2f14b0f98ce1346c71badd6@000000_oswg401979oswg1080oswg870_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">当时的每个人几乎都是类似的心理状态&nbsp;</p><p>彼时大家都没觉得富士是个理财产品，只是觉得 X-S10 是个好机器，6499 元的价格很香。但是也有人寻思：明年 618 背不住就 5999 元了呢？所以都想再等等看。这就跟很多人一直以来的想法一样：早买早享受，晚买有折扣。&nbsp;</p><p>但富士又一次用行动告诉了我们什么叫「犹豫就会白给」。&nbsp;</p><p>2020 年的双十二，富士在京东再次放货售卖 X-S10，而此时的价格是原价 6999 元，一分不降。再加上之前对渠道商的整治初见成效，所有的渠道商都只能跟进 6999 元进行售卖。许多首发用户一觉醒来，发现自己的相机玩了一个月，二手卖了居然还能赚 200 块？&nbsp;</p><p>还有这种好事？&nbsp;</p><p>如果你是 X-S10 的首发用户，你会对富士接下来的产品怎么看？是不是会觉得还得买首发？&nbsp;</p><p>当然，这不是最离谱的，离谱的在后面。随着 2021 年疫情的加重，佳能宣布减产和涨价，率先打响了相机涨价的第一枪。要知道佳能用户群和富士是有相当大的重叠的，随着佳能的涨价，原本佳能的潜在客户开始把目光投向富士，这泼天的富贵就让富士接着了。&nbsp;</p><p>然后富士也学着……涨价了。没错，X-S10 涨价了，理由竟然也是什么供应链产能不足之类，和佳能简直一毛一样。&nbsp;</p><p>按理说，涨价应该影响销量的，但是 X-S10 即便从首发的 6499 元涨价到 7499 元却仍然供不应求，只因为其他厂家都在一万多两万的全画幅市场杀红了眼，压根就没看万元以下的市场。大家都被所谓的「专业」给坑了。&nbsp;</p><p><strong>摄影嘛，就是个爱好，赚钱往后靠，开心才最重要。</strong></p><p>一万以下的消费级市场你们不要，那我富士可就就全吃下了。2021 年富士接连发布 X-T30 II 和 X-E4，把产品线更加细分，价格也都在 7000 块以内，同时停产了 X-A7 和 X-T200，毕竟相机市场已经萎靡成这样，已经不需要入门机型来走量了。&nbsp;</p><p>在 2021 年，你问我 17000 块钱能买什么相机，我能给你列出一大堆。但是你问我预算就7000 块，那我就只能给你推荐富士了。&nbsp;</p><p>佳能首先意识到了消费者大多还是集中在万元以下市场的，于是欣然发布了针对性明显的 EOS R7，8999 元的售价正好插在 X-S10（7499）和 X-T4（11390）的价格空档上。性能也是非常讨巧，乍一看性价比极高。但是佳能显然还是高估了自己的产能，R7 缺货比富士还严重，完全就成了 PPT 产品，压根买不到。&nbsp;</p><p>随着疫情的放开，渠道商不控价的弊端开始凸显，线下终端的价格及其不稳定，比较明显的就是佳能 R8，因为性能不错，价格也适中，所以刚发布的时候供不应求，一度加价售卖。但是水货客出去溜达一圈，发现东南亚的 R8 要比国内便宜好几千，于是开始往回背，直接把价格就打下来了。这时候加价购买的用户也只能用早买早享受来安慰自己了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_49da4cd5508a4625a242e0901e5a789b@000000_oswg366988oswg1080oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_f9c6688b518f4e6facf06f57a09a1662@000000_oswg135875oswg1080oswg536_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">价格被水货市场倒逼的佳能&nbsp;</p><p>富士对相机渠道的严格管控，并不是只针对于国内渠道，所以水货并没有比国行有多大的价格优势，最多也就是差了一些汇率，甚至于比国行还贵，自然就没有市场。没了水货的乱价，为富士的保值又增加了一个筹码。&nbsp;</p><p>性能好、外观漂亮、胶片滤镜讨喜、二手保值率高，同时满足这四点要求的相机，它就不可能不火，于是从 2021 年开始，小红书等平台关于富士的讨论量开始直线上升。&nbsp;</p><p>2022 年，富士开始更新五代的旗舰机型，其实可以预见到并不会有太大波澜，因为太贵了，X-H2S 要价 16700 元，就算是富士铁粉也觉得不值，于是销量扑街。X-H2 要价13000+，虽然有 8K 视频录制，但是外观一点也不富士，大部分人还是觉得不值。直到 X-T5 出现，富士的五代机才有那么一点热度。其实大家都明白，大家都在等那个性价比的爆款——X-S20。&nbsp;</p><p>所以你看，买富士的人其实很理智，一点也不盲从，X-Pro 3 二手常年不到 9000 元，XH2S 的二手也就 12000 元出头，要不是富士的新机有控价政策可能还会低，说白了，<strong>海鲜市场的价格才是这个相机应有的定价。</strong>而 X-S20 如今仍然溢价 500 块，就说明它就应该值这个价。&nbsp;</p><p>还有人会认为这一切是因为富士饥饿营销导致的。但是诸如尼康 ZF 和佳能 R7，即便是饥饿营销了，也没有达到如此的热度。从渠道商得到的消息来看，他们每个月每个季度分到的富士相机数量很稳定，并没有太大波动，但是咨询量却多了几倍不止，由此导致了供需关系的改变。在此基础上，全球经济下行，买富士这种稳赚不亏的投资有自然就会让人趋之若鹜。方方面面的原因一叠加，就让富士就变得越来越火，一发不可收拾，如同我们的茅台。&nbsp;</p><h2>尾声</h2><p>未来，富士热度是否还会延续？&nbsp;</p><p>笔者的推断是，在其他厂商没有拿出足够诚意之前，富士的热度还会持续相当一段时间。而要说诚意，谈何容易？要么这些相机厂家投入一个全新的生产线，专门生产性能强、外观美并且不缺货的相机，抢富士的市场份额，要么放弃全画幅专业领域的厮杀，回头专攻入门级产品。&nbsp;</p><p>前者新开生产线的投资巨大，按照相机市场目前这个萎靡程度，恐怕要很久才能收回成本，于是乎这个提案在他们的董事会的论证阶段估计就不可能通过。后者相当于推倒了从 2018 年开始制定的品牌发展路线，也就意味着企业六年走了弯路，不开几个高管恐怕没法向董事会交代。综合下来，各品牌只能维持现状，一条道走到黑。&nbsp;</p><p>所以，富士的热度恐怕还得维持相当长一段时间。而这样的富士，你愿意埋单么？&nbsp;</p><p>原文链接：&nbsp;</p><p>https://sspai.com/post/87038?utm_source=wechat&amp;utm_medium=social&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzU4Mjg3MDAyMQ==&amp;mid=2247570462&amp;idx=1&amp;sn=34f1b3fcd0cb19593d4c314bd611b3b7&amp;chksm=fcae401ee6a611076e3f2ea2b754d97baa602611392ac794c8f88560c765c9b158ca9b1c9cd5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“少数派”（ID：sspaime）</a>，作者：食肉库玛老师傅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684663004053639</id>
            <title>前端不存在了？盲测64%的人更喜欢GPT-4V的设计，杨笛一等团队新作</title>
            <link>https://www.36kr.com/p/2684663004053639</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684663004053639</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 07:14:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 前端工程师, 自动化, 多模态技术, Design2Code
<br>
<br>
总结: 百度创始人李彦宏指出未来不会存在程序员这种职业，人人都会具备程序员能力，编程语言将只剩下英文和中文。自动化技术越来越普及，尤其在软件开发领域。多模态技术的发展为前端工程师带来了新的解决方案，如通过视觉设计生成代码。研究团队评估了多模态模型在自动生成前端工程方面的表现，提出了Design2Code任务，为此构建了真实世界基准。当前商用模型表现最佳，但缺乏透明度，团队也贡献了一个开源的已微调模型。 </div>
                        <hr>
                    
                    <blockquote><p>前端工程师是不是开始慌了？&nbsp;</p></blockquote><p>3 月 9 日央视的一档节目上，百度创始人、董事长兼 CEO 李彦宏指出，以后不会存在「程序员」这种职业了，因为只要会说话，人人都会具备程序员的能力。「未来的编程语言只会剩下两种，一种叫做英文，一种叫做中文。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_5976c1f9c55b470cbb6b3c599c99d1c7@000000_oswg652655oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>自大模型技术突破以来，越来越多的行业拥有了自动化的趋势，这其中进度最快的领域似乎是软件开发本身。</p><p>根据你的自然语言指令，ChatGPT 这样的工具可以和你边聊边生成代码，结果逐渐靠谱且速度很快。在最近多模态技术进步以后，甚至截个图让 AI 自行领会意图也能生成你想要的设计：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_79de67823d5f4d12869c0e60b4eb2d24@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这种方法是装装样子还是来真的？AI 距离「替代程序员」还有多远？有研究告诉我们：已经很可怕了。</p><h2>‍我们离自动化前端工程还有多远？</h2><p>将视觉设计实现成执行功能的代码是一项颇具挑战性的任务，因为这需要理解视觉元素和它们的布局，然后将它们翻译成结构化的代码。</p><p>这个过程需要复杂的技能，也因此让很多普通人无法构建自己的网络应用，即便他们已经有了非常具体的构建或设计思路。不仅如此，由于这个过程需要不同领域的专业知识，因此往往需要具备不同技能的人互相合作，这就会让整个网页构建过程更加复杂，甚至可能导致目标设计与实际实现之间出现偏差。</p><p>如果能基于视觉设计有效地自动生成功能性代码，那么势必有望实现前端网页应用开发的大众化，也就是让非专家人士也能轻松快捷地构建应用。</p><p>近些年，基于自然语言的代码生成领域发展迅速，但少有人研究基于用户界面（UI）设计来自动生成代码实现，原因包括用户界面存在多样化的视觉和文本信号、结果代码的搜索空间巨大等。</p><p>最近，多模态 LLM 进入了新的发展时代，大规模预训练模型可以针对多种基于视觉的任务通过处理视觉和文本输入来生成文本输出，其中代表性的模型包括 Flamingo、GPT-4V 和 Gemini。</p><p>这样的进展为上述任务带来了全新的解决方案范式：取一张用户网站设计的截图并将其提供给系统，就能得到完整的代码实现，然后这些代码又可以被渲染成用户想要的网页。整个过程是完全端到端式的。</p><p>近日，斯坦福大学、佐治亚理工学院等机构的一个联合团队评估了当前的多模态模型在这一任务上的表现。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_325ffae46acb4b6c9ab1fbde766f4712@000000_oswg136043oswg1080oswg484_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文标题：Design2Code: How Far Are We From Automating Front-End Engineering?</p><p>论文地址：https://arxiv.org/pdf/2403.03163.pdf</p><p>项目主页：https://salt-nlp.github.io/Design2Code/</p><p>他们将这个任务称为 Design2Code。通过一系列的基准评测，我们可以从这些结果中了解自动化前端工程已经发展到哪一步了。</p><p>为了实现系统化和严格的基准评测，该团队为 Design2Code 任务构建了首个真实世界基准。表 1 给出了一些示例。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_253212380b75430e993fd2847ee51003@000000_oswg337383oswg1080oswg841_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了最好地反映真实用例，他们使用了真实世界的网页，而非用生成方法得到合成网页。他们收集了 C4 验证集中的网页，并对所有样本进行了仔细的人工调整，最终得到了 484 个高质量、高难度和多样化的网页。它们可代表不同复杂度的多种真实世界用例。他们执行了定性和定量分析，证明这个基准数据集覆盖了广泛的 HTML 标签用法、领域和复杂度。</p><p>此外，为了促进高效的评估和模型开发，该团队还为这个任务开发了一些评估指标 —— 可自动比较生成网页的截图与给定的截图输入。这些新指标考虑的维度很全面，包括边界框匹配、文本内容、位置和所有已匹配视觉元素的颜色。</p><p>然后，该团队调查了 GPT-4V 和 Gemini 等当前的多模态 LLM 在这一任务上的表现。为了让这些模型能展现出自己的最优能力，该团队使用了一些不同的 prompt 设计方案，包括文本增强式 prompt 设计和自我修正式 prompt 设计。其中文本增强式 prompt 设计是为视觉输入提供文本元素作为补充，从而可以降低光学字符识别（OCR）的任务负载；自我修正式 prompt 设计则是让模型比较之前的生成结果与输入的网页截图，让其自我改进。</p><p>研究者发现，在 GPT-4V 和 Gemini Pro 上，相比于使用直接 prompt 设计法，文本增强式 prompt 设计都能带来提升，但自我修正式方法只能为 GPT-4V 带来积极影响。</p><p>尽管这些商用模型的表现是当前最佳的，但它们都是缺乏透明度的黑箱。因此，该团队还为这一任务贡献了一个开源的 18B 参数的已微调模型：Design2Code-18B。</p><p>具体来说，该模型基于当前最佳的开源模型 CogAgent 构建，并使用合成的 Design2Code 数据进行了微调。令人惊讶的是，在新提出的基准上，尽管合成的训练数据与真实的测试数据之间存在差异，但这个「小型」开源模型的表现依然颇具竞争力 —— 足以媲美 Gemini Pro Vision。这说明专用型的「小型」开放模型是有发展潜力的，并且模型也可以从合成数据中学习获取技能。</p><h2>Design2Code 基准</h2><p>为了得到基准数据，该团队首先收集了 C4 验证集中的所有网站链接。然后他们将所有 CSS 代码嵌入到了 HTML 文件中，从而让每个网页都只有一个代码实现文件。这样得到了共计 12.79 万个网页。然后他们又执行了进一步的过滤和处理，包括自动调整和人工调节。最终他们得到了包含 484 个测试样本的基准。下表 1 比较了新提出的 Design2Code 与 Huggingface 的 WebSight 数据集。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_1799bdfbf96b481d98d4447657030433@000000_oswg249658oswg1080oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图 2 总结了 Design2Code 的主要主题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_c13663fb9b214d219b025603e8acf16f@000000_oswg61138oswg543oswg581_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>至于评估指标，该团队提出了一种高层级的视觉相似度指标，即比较参考网页和生成网页的相似度。另外他们还使用了一组低层级的元素匹配指标，包括块元素、位置、文本和颜色等的匹配程度。</p><h2>结果自动评估和人类评估</h2><h3>自动评估</h3><p>表 2 和图 3 给出了自动评估的结果。请注意，这里的比较并不是公平的，因为不同模型有不同的模型大小和训练数据。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_f6fef87cfd194ff3a8ef14cf55989240@000000_oswg341970oswg1080oswg623_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_bfc4f16629af42c9a76b1e873875c069@000000_oswg100168oswg568oswg564_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以观察到：</p><p>GPT-4V 在颜色之外的所有维度上都表现最好，而在颜色维度上领先的是 WebSight VLM-8B。</p><p>对于 GPT-4V 和 Gemini Pro Vision，文本增强式 prompt 设计均可以成功提升块元素匹配分数和文本相似度分数，这说明提供提取出的文本元素是有用的。</p><p>对 GPT-4V 而言，自我修正式 prompt 设计可以为块元素匹配和位置相似度带来少量提升，但对 Gemini Pro Vision 来说却并无提升。可能的原因是：在没有外部反馈的前提下，LLM 执行内部自我校正的能力有限。</p><p>通过比较 Design2Code-18B 和基础版本的 CogAgent-18B，可以看出微调能为所有维度带来显著提升。</p><p>相比于 WebSight VLM-8B，该团队微调得到的 Design2Code-18B 在块元素匹配和文本相似度指标上表现更好，但在位置相似度和颜色相似度指标上表现更差。</p><p>该团队表示，前两个观察可以归因于更强更大的基础模型，而后两个则可归功于更大量的微调数据。</p><h3>人类评估</h3><p>该团队也进行了人类评估。下面是主要的评估协议和结果。每一个问题都由 5 位人类标注者给出评估意见，最终结果遵从多数意见。</p><p>成对模型比较：也就是让标注者给一对生成的网页排名（一个来自基线方法，另一个来自受测方法），以决定哪一个与参考网页更相似。这里的基线是对 Gemini Pro Vision 采用直接 prompt 设计，收集的数据是其它七种方法与这种基线方法的胜 / 平 / 负的比例。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_20118da325c24d29b7cee0a436d6f5f6@000000_oswg281559oswg1080oswg634_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>结果见图 4，可以看出：</p><p>GPT-4V 显著优于其它基线，而且文本增强式 prompt 设计和自我修正式 prompt 设计能在直接 prompt 设计的基础上进一步提升。</p><p>文本增强式 prompt 设计可以少量提升 Gemini，但进一步增加自我修正方法却没有帮助。</p><p>WebSight VLM-8B 优于 Gemini 直接 prompt 设计方法（54% 的胜率和 35% 的败率），这说明在大量数据上进行微调可以在特定领域比肩商用模型。</p><p>新模型 Design2Code-18B 的表现与 Gemini Pro Vision 直接 prompt 设计方法相当（38% 的胜率和 37% 的败率）。</p><p>直接评估：尽管有这些比较，但读者可能还是会问：「我们离自动化前端工程还有多远？」</p><p>为了得到一个更直观的答案，该团队进一步让人类标注者比较了参考网页与最佳的 AI 生成网页（使用了 GPT-4V 自我修正式 prompt 设计）。他们从两个方面进行了直接评估：</p><p>1.AI 生成的网页能否替代原始网页？</p><p>人类标注者认为：AI 生成的网页中，49% 可与参考网页互换。</p><p>2. 参考网页和 AI 生成的网页哪个更好？</p><p>结果有点出人意料：在 64% 的案例中，人类标注者更偏爱 GPT-4V 生成的网页，也就是说他们认为 AI 生成的网页比原始参考图像的设计更好！</p><h3>自动评估 vs 人类评估</h3><p>该团队也研究了自动指标与人类配对偏好之间的相关性。结果发现，人类通常更关注高层级的视觉效果和布局，而不是细节内容，这说明人类的思考方式是自上而下的。</p><p>不过，针对论文给出的结果，有人提出了不同意见，认为前端的工作流程远比表面看上去复杂，因此真正实现「自动化前端工程」还需要一段时间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_40745178f7864d1f8d2bb99b9495e42e@000000_oswg320342oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_56f725b391be413992959b6ab15854b6@000000_oswg94961oswg1080oswg275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于这个问题，你怎么看？</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650910318&amp;idx=1&amp;sn=79915af15817ce7b9c5ccbf45d6e662f&amp;chksm=85d78063f246f6dd34d6190a0807c8a4c2d81cfc81eb6276408cc5be7cdee10a045ea9727189&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，编辑：Panda，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2684623047442568</id>
            <title>顶级美元VC在港交所排队“喝奶茶”</title>
            <link>https://www.36kr.com/p/2684623047442568</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2684623047442568</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 04:09:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 2021年, 奈雪的茶, 港交所, 新茶饮第一股
<br>
<br>
总结: 2021年，奈雪的茶成功登陆港交所成为新茶饮行业的第一股，引领了新茶饮行业的发展趋势。 </div>
                        <hr>
                    
                    <p>2021年，奈雪的茶登陆港交所成为新茶饮第一股；至今，“新茶饮第二股”的位置还是空的。</p><p>2024年刚过，蜜雪冰城、沪上阿姨、古茗股份、茶百道纷纷提交了港股上市申请书，茶百道从2023年6月第一次融资到现在也才半年有余，而蜜雪冰城更是在2022年尝试深交所上市未果后转战港股。</p><p>作为新茶饮上市“大前辈”的奈雪的茶在二级市场的表现并不算优秀。2023年下半年奈雪的茶的股价整体呈现下跌趋势，截至发稿前总市值为50.08亿港元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_9763bee96aa14e0895ccdf76577828e5@000000_oswg218718oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：老虎财经</p><p>2023年线下经济复苏后新茶饮行业的增速创下又一个新高，所以即使“老大”的表现差强人意“准老二”们也跃跃欲试敲响资本化的大门。</p><p>不过随着2024年新茶饮市场增速逐渐回到正常水平，以及靠着加盟商赚钱的新茶饮们逐渐触及的天花板的到来，港交所到底还有多少空间“喝”下这些奶茶呢？</p><h2><strong>01 2024，茶饮大年</strong></h2><p>2024年刚来，茶饮就已经“杀疯了”。</p><p>前脚蜜雪冰城和古茗控股在同一天提交了港交所上市申请书，后脚茶百道紧随其后也提交了最新的港交所申请书。其中蜜雪冰城更是从A股转战港股。</p><p>作为茶饮界的三巨头，蜜雪冰城、古茗控股和茶百道不只提交招股书的时间相近，就连主要的营收方式都非常相似。</p><p><strong>简单来说，都靠加盟商“活着”。</strong></p><p><strong>不过主要营收并不是来自加盟费而是卖给加盟商的各种材料。</strong></p><p>蜜雪冰城招股书中就表示他们仅有2%的收入来自加盟费和相关服务费，绝大部分收入来自向加盟门店销售商品及设备，加盟商的饮品食材、包材及设备100%从品牌方采购；同样古茗的招股书中，从古茗收入结构来看，销售商品及设备的收入在2021年、2022年及2023年前九个月都占到了总收入的八成，当中销售商品的收入占比又达到了75%以上。招股书解释，商品销售收入主要来自销售饮品的原材料，如新鲜水果、果汁、茶叶、乳制品及包装材料等。设备销售收入主要包括向加盟店销售泡茶机、制冰机、冷冻柜、冷藏柜及 其他电子设备；茶百道亦是如此，大概95%的收入来自向加盟店销售货品和设备，包括乳制品、茶叶及水果等制作茶饮的材料及配料，以及吸管、杯子等包装材料及门店设备。</p><p>不同的是，三家茶饮店的门店渗透率和盈利能力有所不同。</p><p>蜜雪冰城从门店数量来说无疑是老大，早早进入万店俱乐部的蜜雪冰城截至2023年9月30日，通过加盟模式发展的门店网络已经拥有超过36000家门店，覆盖中国及海外11个国家。2023年前九个月，其门店网络共实现出杯量约58亿杯，这是真“可以绕地球一圈”的销量。相较之下，古茗和茶百道德还没有跨过万店大关，截至2023年的最后一天，古茗全国门店数量为9001家、茶百道则为7801家。</p><p><strong>在城市的选择上，三位也不约而同地看中下沉市场。</strong></p><p>蜜雪冰城截至2023年前三季度在三线以及以下城市的门店数量18297家，占总门店数的56.9%，这个数据在2021年和2022年也高达58.7%和57.2%，占比接近六成；古茗在二线以及以下城市的门店数占比达到79%，2023年二线以及以下城市门店产生的GMV达到了147亿元，占比古茗约22%的市场规模；茶百道亦是如此，在二线、三线城市门店占比分别为20.9%、19.4%；一线城市门店最少，占比仅为10.6%。</p><p>遥想2017年，“新茶饮”这个概念还是当时还在坚持在一线城市自营的喜茶带火的。为了保证品质并没有开放加盟的喜茶火遍了北京、上海、广州这些超一线城市，一杯奶茶的价格甚至可以和星巴克媲美。新茶饮赛道一时火爆异常。</p><p>不过由于自营扩张的速度总是赶不上加盟的，各种下沉市场的“喜茶”们涌现而出，当时以10元左右的价格抢占二、三线城市的蜜雪冰城、茶百道和古茗都是其中一员。</p><p>但是做下沉也有做下沉的难处。</p><p>从产品属性上来说，新茶饮的概念可以在一线城市充满社交属性，比如和各个IP联名，或者设计当季的特饮、杯子外观设计等，让一线城市Z世代的消费者在各种社交渠道上“晒”这些饮品。但是到了下沉城市，“新茶饮”脱去漂亮的外衣赤裸裸剩下“奶茶”这个旧称号，说到底还只是个“小朋友爱喝的饮料”，由于消费群体和习惯的不同，新茶饮们的社交属性在下沉市场不容易被挖掘，愿意花钱来买联名和季节性设计的消费者绝大部分也不在这些地方。</p><p>所以，新茶饮到了下沉市场就得开始卷价格。价格卷多了影响的还是企业的盈利。而从门店扩张来说，加盟形式确实扩张迅速也能带来营收，但是加盟门店的数量也是有天花板的，当一个品牌在一个地区的加盟店过于密集，就会削弱每个加盟店的单店营收，对于品牌来说他们还是能赚到卖给加盟商产品的钱，但是加盟商的加盟意愿也会降低，最终影响的还是品牌的营收增速。</p><h2><strong>02 奶茶还能喝出几个IPO？</strong></h2><p>新茶饮，到底还能出几个IPO？</p><p>2021年6月，奈雪的茶在港股上市，成为第一个上市的新茶饮品牌。彼时市场以为这是新茶饮上市的序章。</p><p>2020和2021年喜茶完成了C轮和D轮的融资，包括LVMH旗下的投资机构L Catterton、红杉中国、高瓴资本等头部美元基金都在喜茶的投资人列表中；2021年蜜雪冰城也跟着完成了A轮融资，高瓴和美团龙珠为领投机构；而红杉中国和美团龙珠也在2020年参与了古茗的融资。可见当时顶级美元机构对于新茶饮的态度十分积极，接连做出密集的布局。</p><p>谁也没有想到，成功登陆港股的奈雪竟然不是新茶饮的“序章”，反而成了“绝唱”。</p><p>喜茶上市的消息从2021年传到现在也没有下一步的动静。2022年9月蜜雪冰城曾经向深交所提交IPO申请，计划募资64.96亿元，用于生产建设类项目、仓储物流配套类项目、其他综合配套类项目、补充流动资金，其中用于补流资金约19亿元，这件事情迟迟没有下文后蜜雪冰城也选择在今年转战港股...</p><p><strong>新茶饮上市难或许有几个因素。</strong></p><p><strong>宏观来看，整体IPO尤其是消费赛道的IPO在这两年的形势就不容乐观。</strong></p><p>根据德勤中国资本市场服务部发布的2023年中国内地与香港新股市场的表现回顾及2024年展望，2023年A股约有310只新股上市，融资约3551亿元人民币，与2022年424只新股、5868亿元融资额相比，分别下降27%和40%；港股方面，面对美联储加息、经济增速放缓等宏观因素影响，港股市场估值下降且流动性也受到了限制。受此影响，2023年预计港交所全年有65只新股上市，融资金额约458亿港元，而根据港交所2022年年报，新上市公司90个，首次公开招股集资额为1046亿元，今年新股上市同比下跌27.78%，融资金额同比下跌56.2%。</p><p>尤其在消费赛道上，虽然有百果园、日日煮、锅圈的成功上市，但是也有众多消费企业上市之路频频受阻。</p><p><strong>从行业来看，新茶饮整个行业的增速在2022年面临极大放缓，从2018-2021年超过20%的年复合增速降至2022年的3.5%，</strong>市场增速的放缓会稀释投资者们的信息也许也是2022年到现在没有新茶饮第二股成功上市的原因。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240311/v2_28381ab5d43f482d8cb1e00a4e6da334@000000_oswg153065oswg1080oswg621_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：行业研究报告</p><p>不过到了2023年，线下经济不断复苏，新茶饮市场的增速反弹也非常强烈，尤其在前两季度有暑假的加持下，最终在全年实现了超过44%的增速。或许这也是为什么新茶饮们纷纷重拾信心争先在2024年再次冲刺上市的原因。</p><p>线下经济复苏带来的新茶饮的增速并不是能长久持续的，外加新茶饮企业营收模式趋同且都重度依赖加盟商，早晚还是要面对增速天花板的问题。</p><h2><strong>03 怎么突破天花板？</strong></h2><p>面对近在眼前的增速天花板，各家新茶饮也纷纷拿出自己的办法。</p><p><strong>出海是其中一个。</strong>2023年喜茶在澳大利亚墨尔本和加拿大本拿比的门店陆续开业；主攻下沉市场的甜啦啦在印尼雅加达开出6家门店；茶百道的韩国首店也在10月31日落地首尔。更早进入东南亚市场的则是蜜雪冰城，早在2018年蜜雪冰城就在越南开设了第一家海外门店，到现在已经拥有接近4000家海外门店了，印度尼西亚、越南等多个东南亚国家都被拉满性价比的蜜雪冰城吸引。之后，蜜雪冰城还在京东高端商区表参道开出首店并计划在2023年底在日本开设20家门店。而去年在国内爆火的霸王茶姬其实也在2019年就开了马来西亚首店，之后也逐渐进入了泰国和新加坡市场，目前霸王茶姬在东南亚的门店已经达到了近70家。</p><p>实际上，饮品品牌靠出海扩张也不是什么新鲜事，成功登陆港股的海伦司，有“午夜星巴克”的称号，也是现在国内下沉市场完成扩张，靠“社交酒吧”的调性主打小一百元的奶啤或者调酒这种酒精度数较低的“小甜水”来吸引年轻的消费者。也是在这两年，海伦司开始进入东南亚市场，首站就是新加坡，开业当天就有博主探店并反映生意相当火爆。</p><p>新茶饮出海东南亚抓住的是近年来东南亚旅游的热潮以及东南亚本身的消费文化和中国市场十分相近的特征。当然成功的出海也需要足够的本土化，这也会带来相应的营销和人力成本的上升。</p><p><strong>如果说新茶饮出海是在业务上扩宽边界，那么新茶饮做VC就是在资本版图上尝试突破了。</strong></p><p>2021年拿到5亿美元融资后，喜茶开始“买买买”。2021年7月喜茶领投精品咖啡品牌Seesaw的A+轮融资，之后喜茶又分别参与了柠檬茶品牌王柠、燕麦奶品牌野生植物YePlant”、新茶饮品牌“和気桃桃”、新国潮预调酒品牌“WAT”以及“分子果汁”首创品牌野萃山的投资。2022年喜茶创始人聂云宸和财务负责人邱咏贤共同成立的一家投资合伙企业，完成了对新茶饮品牌“苏阁鲜茶”的投资，持股15.4%。之后喜茶再次加注，入股少数派咖啡，持股12%，而这也算喜茶的“二次投资”。少数派咖啡和野生植物YePlant都是吴凌波所创立的品牌。此外，聂云宸以个人出资形式投资了两个咖啡品牌——乌鸦咖啡和KUDDO咖啡。</p><p>同样是2021年完成上市的奈雪的茶第一笔投资落给了茶饮供应链田野股份，之后又投资了新茶饮品牌茶乙己、咖啡品牌澳咖AOKKA、烘焙品牌“鹤所”和咖啡连锁品牌“怪物困了”等。之后奈雪的茶旗下的深圳美好自有力量投资公司在2022年注册成立，据企查查信息，美好自有力量参与了“低糖、零蔗糖、低热量、低甜度”的网红糕点象飞田餐饮的天使轮融资、主打鲜肉汉堡的沙朗阿甘的天使轮融资、茶乙己的战略融资以及瑞鑫咖啡品牌怪物困了的天使轮融资。</p><p>之后美好自有力量55%控股成立了初芽创投，目前初芽创投发起了一笔对外投资，给做精品速冻咖啡的嗨罐咖啡。</p><p>新茶饮的投资版图十分清晰地聚焦在新锐咖啡、茶饮、新中式创新餐饮以及茶饮的供应链上。这背后的逻辑不言而喻，最近新茶饮在产品创新上纷纷对准“0糖”标签或者做出结合咖啡的茶咖，在这个赛道上的布局既有可能促成产品创新也是对于关联赛道的提前布局。</p><p>不用从市场的角度还是从资本的角度，新茶饮们都在试图扩宽自己的路径。但眼下新茶饮品牌们在产品创新、盈利模式上的趋同、整个市场增速又将要面临的放缓以及对加盟商的重度依赖仍是没有解决的问题。</p><p>所以，到底谁能拿到这个新茶饮第二股，拭目以待。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MjI0Nzk5NA==&amp;mid=2650185710&amp;idx=2&amp;sn=299c534a4da097b71a55fa9030212ef8&amp;chksm=bfd89048f9a3127be891718476b71124212f41084b14964da71705ab35f76cf552d6a074ea44&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“融中财经”（ID：thecapital）</a>，作者：吕敬之，编辑：吾人，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>