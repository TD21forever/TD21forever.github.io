<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2808257986327941</id>
            <title>快手外卖，搅局高于入局</title>
            <link>https://www.36kr.com/p/2808257986327941</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808257986327941</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 12:05:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 抖音, 快手, 外卖, 团购
<br>
<br>
总结: 抖音和快手都在尝试进入外卖领域，但他们的业务逻辑和运作方式有所不同。抖音在团购和外卖之间转变时遇到了一些困难，而快手则在测试阶段，尚未完全适配外卖服务。两者都需要解决商家管理、配送、服务等问题，但快手目前的模式更适合加盟店。商家对于第三方配送的依赖和成本问题也是需要解决的难题。 </div>
                        <hr>
                    
                    <p>抖音本地生活染指团购，再到试水外卖两年多时间后，快手也把触手伸向了该领域。</p><p>一位业内人士认为，“从团购到外卖是一个自然延伸，而且在快手搭建外卖商家端服务前，已经有零星商家借助第三方运力，提供外送服务了。”</p><p>截至目前，在快手App“团购·优惠”页面中搜索“外卖”，系统会根据定位匹配附近商家。在北京和成都两地测试发现，快手外卖的逻辑仍然是团购。</p><p>团购与外卖，到店与到家，看起来丝滑无比，但实际业务逻辑和运作过程完全是两件不同的事情。比如今年抖音本地生活对于外卖业务的投入明显降低，除了外界熟知的履约与商家运营外，光子星球了解到，缺乏基础组件也是阻碍抖音外卖做大的原因之一。相反，抖音团购的持续进攻足以让美团频繁对组织架构动刀，设置了本地生活CEO。</p><p>一个王兴解决不了问题，那就搭上王莆中。</p><p>相较到店核销，外卖业务不仅要具备商家管理与运营、派单与配送、服务与售后等能力，而且还要解决短视频+直播与即时需求匹配的问题。</p><p>抖音跨不过的坎，“猫”在身后的快手就能跨过去吗？</p><h2>抖音没绕过的履约</h2><p>几乎所有商家都会在详情页标注“下单前需联系店家预约”的字样，详情页也没有配送费等履约相关信息，而是团购的逻辑。</p><p>我们与一位店家沟通时，店家说：“你在快手上下单，要吃的时候给我们打电话，餐送到后把二维码发给我，我给你核销。下单后会我们这边是达达配送，啥时候送、花多少钱你自己跟骑手沟通。”</p><p>毫无疑问，快手外卖将沿着抖音的路径，因此势必得踩后者踩过的坑，比如靠第三方完成履约，然而这条路对于商家来说并不友好。</p><p>早前，一位连锁品牌商家提到，由于抖音外卖依赖第三方履约，官方给到的履约标准为60分钟以内，该标准下的实际完成度很高。但如果横向对比美团、饿了么的履约标准——20分钟上下，则差了不止一个档次。至于快手，暂时还没有履约时效标准，全是弹性。</p><p>履约时效无法控制在半小时之内，极大地限制了品类。例如快手目前提供外卖的商家大多为弱时效品类的自助烤肉，配送晚一小时对用户体验的影响相对有限。</p><p>另一个潜在隐患是抖音依赖第三方配送，在缺乏有效的工具支撑的情况下，商家需要花不少精力运营。</p><p>“首先得有一套支持派单、接单、履约、运营系统。”一位抖音外卖商家此前提到，测试外卖一年，平台仍未解决运力问题，导致商家需要时刻关注接单情况。“一旦涉及到第三方，得多平台放单”。极端状况下，如果没有骑手接单，只能不断增加派单价，以高于正常标准吸引第三方骑手。</p><p>尽管前期平台不会设置抽佣比例吸引商家，但自配送的成本实际上往往比美团抽佣的净值更高。有商家提到，实付25-30元一单，自配送需要花费接近10元，成本占比高达30%以上，高于美团。</p><p>上述商家表示，“自配送的唯一优势就是做高客单价品类，比如价格抬到100元，那么10元的配送成本对利润的影响就很小。”这似乎说明，为何抖音外卖做9.9元套餐并没有对美团外卖造成实质性影响。何况，美团随后也采用了种种策略，要求商家与抖音渠道对齐，完全瓦解了抖音外卖9.9元的侵袭。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_df60b4ce17e34e608c99e0cf8c5d79c8@000000_oswg217207oswg553oswg395_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">左中右依次为快手、抖音、美团</p><p>快手外卖处于测试阶段，因而目前并未设置专门入口，也没有与外卖适配的信息呈现方式。可以外送的服务，大多是通过团购产品名称上，加说明的方式呈现。</p><p>快手走抖音的老路，即流量模式，让单店商家完全无法承担这样的成本，因此目前平台上能够提供外卖服务的大多是加盟店。</p><p>美团与饿了么是典型的货架逻辑，依靠搜索竞价排名与榜单，更容易承接刚性需求。单店毛利只要高于30%，基本能保证不亏钱。而抖快这类短视频&amp;直播平台，依赖推荐与KOL触达消费者，种草有余而捕获刚性需求不足，更适合连锁，或加盟店。</p><p>事实上一家同时在北京和成都提供快手外卖服务的品牌便是加盟店，其模式是总部在快手投放短视频的内容广告，同时进行直播运营，吸引用户，各地加盟商承接服务。</p><p>光子星球以“打算加盟”为名询问一家加盟店负责人，该负责人表示加盟费为7万左右。</p><p>即便总部承担了营销成本，店家在快手线上（团购+外卖）的毛利也非常有限。“今年三月上线外卖，前五个月累计销售2000多单，平均每月毛利在2000元左右。”考虑到客单价在100元以上，且“外卖不赚钱”的情况下，留给商家的利润空间着实有限。</p><h2>聚拢商家与技术支撑</h2><p>“抖音的模式更适合腰部与头部的连锁店，或者牛排、红酒这类高客单价品类。”</p><p>一位业内人士分析称，抛开商家类型不谈，当下快手亟需解决两个核心问题，一个是借服务商之力迅速构建商家资源，培育“快手外卖”的消费心智，另一个是解决与外卖适配的算法模型。</p><p>美团与抖音本地生活的业务发展史为快手提供了两条构建商家池的模板。美团通过组建地推团队，扩展商家，然后靠城市BD维护商家关系。抖音则依赖流量与第三方服务商——先团购，后外卖，再用一套数字化经营工具留住商家。</p><p>抖音在2021年年中开始酝酿团购，2022年上线并在多地测试外卖，短短一年时间便在多地组建了团购、外卖两条服务商体系。去年年中，打通团购与外卖时还曾引发服务商们的不满。</p><p>让人意外的是，有一家多地服务商不知道快手入局外卖的事情，截至目前仍有反馈的信息显示，询问者多，落地者少。“肯定是学抖音，先让我们拉客，做大了之后卸磨杀驴，比如让商和商卷起来，打通团购商与外卖商，平台坐收渔利。”</p><p>快手本地生活吸引商家的手段集中在资金与流量。早前快手本地生活聚力生态大会上，快手高级副总裁、电商事业部负责人兼商业化事业部负责人王剑伟表示，今年快手磁力引擎将提供技术、产品和服务三个“装备包”，以及2亿现金的广告投放扶持。</p><p>快手能拿出的东西和两年前的抖音并无二致。</p><p>2022年，抖音本地生活开出的加码也是技术、流量、资金扶持，且当时面向商家的后台系统虽然带有很浓郁的“象牙塔”色彩，但确实给商家提供了诸多有价值的运营数据。否则不会在短时间内孵化多个从0到1，再到100的案例，如黑眼熊寿司，半年实现了1.4亿元的流水。</p><p>需要指出，抖音本地生活除了三个扶持与服务商体系外，抓住了商家对团购-外卖佣金的痛点，以及达达、顺丰同城这些第三方配送服务商寻求客户的需求。而如今，天时不再像两年前那么明显。</p><p>美团外卖在去年年末拉着顺丰同城、UU跑腿、闪送建立所谓生态合作，实则拉拢，并且商家们经过抖音搅局后也逐渐搞明白了美团抽佣+专送与所谓第三方配送间大差不差的实质。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_ba2e92e75969435a96144359c87120f8@000000_oswg137563oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一个阻碍抖音介入外卖市场的因素是难以建立一套适配外卖、且可以持续扩展的基础架构组件。</p><p>美团外卖技术架构因为业务形态不断变化、业务量持续增长，经历了多次迭代。另一方面，技术团队也经历了高效复用代码到解决多端代码复用的问题，再到后来将多端代码复刻到其他业务支持上。</p><p>美团基础架构的扩展性为后续迭代提供了诸多助益，但随着技术大拿们相继离职，加之基础组件迭代的短期效果并不明显，近两年美团经常出现系统问题。对于一个国民级应用而言，一次共享单车解锁失败，或者外卖小哥因系统bug接不了单，都会引发一系列问题。</p><p>抖音或许可以借助服务商之力，迅速建立商家池，却没有办法在朝夕之间搭建美团这套与业务同时生长的基础系统，哪怕美团十年前的基础组件如今已积弊重重。</p><p>2019年，美团CTO罗道锋离职美团，曾以兼职顾问的身份加入公司，指导相关技术工作，或许会为快手搭建外卖系统提供一定帮助。不过，基础架构是一个系统性工程，即便有美团经验，光靠罗道锋一人显然无法完成。</p><p>这一点从快手本地生活开放平台和详情页都能得到印证：缺乏履约信息与标准，商家工具仍为团购而非外卖等等。</p><h2>到店容易到家难</h2><p>今年，为了应对抖音本地生活吃下团购市场份额时，进一步染指外卖，美团开启了一系列组织架构调整，其中成立本地生活公司，旨在加速到店与到家业务的一体化。</p><p>王莆中上任后干的第一票买卖是打出“会员牌”，似乎堵住了抖快试图再度走低价路线偷袭。</p><p>会员制原本用于对消费者进行权益区隔，吸引真正为公司带来利润的，有购买力的人群。而美团却反其道而行之，将其变为价格力的锚点，由到家延伸至到店。</p><p>美团“神会员”试图通过等级成长、身份铭牌、积分抵现等手段，覆盖至旗下各业务，形成类似88VIP的权益体系。根据美团BD提供信息显示，参与“神会员”的商家需要与官方共同让利补贴。</p><p>简单来说，美团会员体系的核心目的是借用户“薅羊毛”的心理，以会员制形式提升用户粘性。</p><p>问题也非常明显，会员折扣所产生的区别很难与既有的免费神券、每日社群福利形成权益差。此外，美团自身业务繁多，用户画像各不相同，按照内部策略，先从高频低价的打车、外卖开始，未来将覆盖到酒旅、到店等低频高价业务时势必会遇到用户筛选、流量成本等一系列问题。</p><p>而对于快手来说，团购业务是否跑出了昔日抖音本地生活那般亮眼的成绩，是否有那般特殊的行业环境，以及足够高效的执行队伍都将影响其团购业务的发展进程。在团购还在发育时，借个别加盟商们的动作试水外卖，会是一件充满挑战的事情。</p><p>王兴曾在饭否写过一句话：有些时候，第二名存在的原因跟第二名本身的关系并不大，而是总有人不喜欢那个第一名。而当快手紧随抖音入局团购，染指外卖时，即便人们仍然不喜欢第一名，但快手需要知道，自己不是老二，亦非老三，而是爹不亲娘不爱的老四。</p><p>本文来自微信公众号“guangzi0088”（ID：TMTweb），作者：吴先之，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808246573970817</id>
            <title>这个团队做了OpenAI没Open的技术，开源OpenRLHF让对齐大模型超简单</title>
            <link>https://www.36kr.com/p/2808246573970817</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808246573970817</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 11:48:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大型语言模型, 强化学习, 模型调度, OpenRLHF
<br>
<br>
总结: 随着大型语言模型规模增大，性能提升，但与人类意图对齐仍是难题。强化学习是解决之道，但随着模型增大，内存和计算资源需求增长。现有框架使用零冗余优化器将模型配置到同一GPU，但效率有限。OpenRLHF提出新框架，使用Ray、vLLM和DeepSpeed重新设计模型调度，支持超700亿参数的RLHF训练，简单易用、高性能。 </div>
                        <hr>
                    
                    <p>随着大型语言模型（LLM）规模不断增大，其性能也在不断提升。尽管如此，LLM 依然面临着一个关键难题：与人类的价值和意图对齐。在解决这一难题方面，一种强大的技术是根据人类反馈的强化学习（RLHF）。</p><p>但是，随着模型越来越大，RLHF 通常需要维持多个模型以及越来越复杂的学习流程，这又会导致内存和计算资源需求增长。举个例子，近端策略优化（PPO，这是 RLHF 常用的一种算法）需要在训练过程中维持四个模型。</p><p>由此，当语言模型的参数规模超过 700 亿时，为了训练和协调多个模型，所需的计算资源和调度复杂性会显著增长 —— 这是当前的架构设计难以满足的需求。</p><p>Transformer 强化学习（TRL）、ColossalChat（CAIChat）和 DeepSpeed-Chat（DSChat）等现有的开源 RLHF 框架是依靠零冗余优化器（Zero Redundancy Optimizer/ZeRO），来将 RLHF 训练涉及的四个模型配置到同一台 GPU 上。这个过程被称为 co-location，即空间并置。</p><p>但是，随着模型参数规模超过 700 亿，在内存有限的 GPU 上，这种调度方法的效率会越来越低。</p><p>为了解决空间并置的限制，TRL 等一些框架选择在内存使用上做出妥协，其做法包括将 actor 和 critic 模型融合起来或采用低秩适应（LoRA）等技术。但是，这些技术会降低模型性能，而且融合 actor-critic 式架构与备受推崇的实践做法不兼容，即使用奖励模型的权重来初始化 critic 模型的权重。</p><p>另一种替代方法是使用来自英伟达 Megatron 的张量并行化和管道并行化技术。但是，Megatron 与人们常用的 Hugging Face 软件库不兼容，而适应新模型又需要大量修改源代码，如此就很难使用了。</p><p>为了轻松实现大规模 RLHF 训练，OpenLLMAI、字节跳动、网易伏羲 AI Lab、阿里巴巴的一个联合团队提出并开源了 OpenRLHF，其中第一作者为 Jian Hu。该框架使用 Ray、vLLM 和 DeepSpeed 对模型调度进行了重新设计，可支持超 700 亿参数的模型的 RLHF 训练，其优势包括简单易用、高性能、实现了分布式 RLHF、集成了 PPO 实现技巧。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_4d507934321d47b79f03cc58105f5351@46958_oswg39688oswg1080oswg237_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><ul><li>论文标题：OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework</li><li>论文地址：https://arxiv.org/pdf/2405.11143</li><li>开源项目：https://github.com/OpenLLMAI/OpenRLHF</li></ul><p>有关 Ray、vLLM 和 DeepSpeed 的具体详情，请访问原论文：</p><ul><li>Ray: A Distributed Framework for Emerging AI Applications，arXiv:1712.05889</li><li>Efficient Memory Management for Large Language Model Serving with PagedAttention，arXiv:2309.06180，也可参看机器之心的报道：《6.7k Star 量的 vLLM 出论文了，让每个人都能轻松快速低成本地部署 LLM 服务》</li><li>DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters，https://github.com/microsoft/DeepSpeed</li></ul><p>OpenRLHF 可与 Hugging Face Transformer 无缝整合，并且支持混合专家（MoE）、Jamba 和 QLoRA 等常用技术。此外，OpenRLHF 还实现了多个对齐算法，包括直接偏好优化（DPO）和 Kahneman-Tversky 优化（KTO）、条件 SFT 和拒绝采样。</p><p>因此，可以说 OpenRLHF 是一个非常全面的 RLHF 训练框架。</p><p>表 1 比较了常用的 RLHF 框架。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_0e2205ca1e7341aeb1f4d687f1f6d323@46958_oswg122574oswg1080oswg685_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>OpenRLHF 的设计</h2><p><strong>调度优化</strong></p><p>要为更大的模型执行 RLHF 训练，需要高效地在多台 GPU 上分配至少四个组件模型（actor、critic、奖励、参考）。为什么需要多台 GPU？因为每台 GPU 加速器的内存有限，比如 NVIDIA A100 的内存不到 80GB。OpenRLHF 在模型调度方面创新性地使用了 Ray 来进行模型安放和细粒度的编排。</p><p>同时，OpenRLHF 还使用了针对推理优化的软件库 vLLM 和针对训练优化的软件库 DeepSpeed；它们都由基于 Ray 的调度器管理。</p><p>OpenRLHF 能将四个模型分配到多台 GPU 上，而不是将它们并置于同一台 GPU，如图 1 所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_8bcec5c2e9a640b3a96d7f33211432d6@46958_oswg174534oswg1080oswg544_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这样的设计很自然就支持在 RLHF 训练过程中使用多个奖励模型，如图 2 所示，并适用于多种算法实现。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_582957c9293b4481b3d514dfcce9d578@46958_oswg200685oswg1080oswg843_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>基于此，算法工程师无需关心底层数据流的细节，就能快速构建多种对齐策略，比如有用性和有害性分离。这样的调度器设计还可使用 Ray 和 DeepSpeed 来实现灵活的模型融合或卸载策略。比如可以融合 actor - 参考或 critic - 奖励模型以节省 GPU 资源。</p><p>除了能高度定制算法实现这一优点，该调度器还能以最优方式编排 GPU，从而提升整体训练性能。</p><p><strong>性能优化</strong></p><p>RLHF 算法的性能取决于训练和推理两方面的效率。从分析结果看，主要瓶颈是在 PPO 样本生成阶段（如图 2 所示），这个阶段占到了整体训练时间的 80%。原因是：在生成阶段，自回归解码的复杂度为 O (n^2)，并且也受到内存限制。</p><p>为了进一步加快样本生成的速度以及支持无法载入到单台 GPU 的更大型 LLM（比如 700 亿参数的模型），OpenRLHF 使用了 vLLM 的张量并行化等先进技术（连续批处理和分页注意力）来执行生成过程，如图 1 所示。</p><p>在 RLHF 的生成和学习阶段，OpenRLHF 采用了以下技术来获得进一步的提升：</p><p>将 Adam 优化器状态卸载到 CPU，这能将 GPU 内存解放出来用于较大的推理批量大小，这能提升效率以及避免生成的内存瓶颈。置顶内存和梯度积累，用于降低梯度聚合过程中的 GPU-CPU 通信负载。</p><p>使用 Flash Attention 2 来加速 Transformer 模型训练。</p><p>使用 PyTorch 张量切片移除训练样本中的冗余填充。</p><p>图 2 中另外三个模型使用了 ZeRO 的第 3 阶段（对模型、梯度和优化器进行分片）。OpenRLHF 使用了英伟达 NCCL 和 vLLM 权重加载器来同步 ZeRO 和 vLLM 引擎的权重，确保实现快速又简单的集成。</p><p>表 2 比较了 OpenRLHF 与该团队精心微调过的 DSChat 的性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_b00e7ea225674fa5a76951ed4a39dfc4@46958_oswg40745oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>训练稳定性</strong></p><p>在训练大型语言模型（LLM）时，PPO 等强化学习算法容易不稳定。为了保证稳定，该团队尽力验证了 OpenRLHF 的实现细节。图 2 和图 3 分别给出了一般的推理和学习流程。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_953bbdcf661a4fc0b86069935e57172d@46958_oswg188147oswg1080oswg845_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，OpenRLHF 还借助了一些技巧来保证 PPO 实现的训练稳定，包括：</p><ul><li>仅在序列的文本末端 token 上预测奖励</li><li>为语言模型使用 token 层级的强化学习</li><li>在 PPO 中使用 KL 散度损失项</li><li>在 PPO 中使用已预训练的损失项，其根据策略损失的相对规模进行调整</li><li>为训练稳定度使用奖励归一化</li><li>通过全局统计使用分布式优势归一化</li><li>使用线性预热余弦退火学习率调度器</li></ul><p><strong>易用性</strong></p><p>为便于用户使用，该团队还为支持的算法提供了一键可用的可训练脚本（详见原论文），并且该脚本与 Hugging Face 软件库完全兼容。下面给出了 Llama2 70B 模型的 RLHF 训练的最低配置：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_bf8180326efd4d87ba5f5f06baead4aa@46958_oswg155194oswg1080oswg328_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="editor-note">本文来自微信公众号“机器之心”（ID:almosthuman2014），编辑：Panda，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808241453528455</id>
            <title>成立仅一年的AI视频创企Pika，凭什么再融8000万美金？</title>
            <link>https://www.36kr.com/p/2808241453528455</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808241453528455</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 11:45:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 郭文景, Pika Labs, AI视频生成, 融资
<br>
<br>
总结: 华人创业者郭文景创立的AI视频生成公司Pika Labs完成了8000万美元的融资，估值达到5亿美元，吸引了硅谷投资者的关注。Pika Labs的核心产品是Pika 1.0模型，能够快速生成各种风格的3D动画、动漫、卡通和电影，具有强大的竞争力。 </div>
                        <hr>
                    
                    <p>据华盛顿邮报消息， <strong>由华人创业者郭文景（Demi Guo）创立的AI视频生成创企Pika Labs完成了一轮约8000万美金的融资</strong> ，融资后估值达到约5亿美金，融资名单也几乎集齐了硅谷的半壁江 山。&nbsp;</p><p>对比之前获得融资的AI视频产品，Pika获得的融资额无疑位居榜首。这个仅成立一年多的创企，背后究竟有什么魅力？&nbsp;</p><h2>01.1分钟项目速览</h2><p><strong>1.项目名称</strong> ：Pika Labs&nbsp;</p><p><strong>2.成立时间</strong> ：2023年4月&nbsp;</p><p><strong>3.产品简介</strong> ：&nbsp;</p><p><strong>Pika Labs的主要产品是Pika 1.0</strong> ，能够根据用户的文字或图像输入快速生成各种风格的3D动画、动漫、卡通和电影。&nbsp;&nbsp;</p><p><strong>4.创始人团队</strong> ：&nbsp;</p><p>Demi Guo、Chenlin Meng：斯坦福大学AI Lab博士</p><p>Karli Chen：CMU ML&amp;CV硕士，曾任商汤工程师</p><p>Matan Cohen Grumi：创意总监，电视广告导演</p><p><strong>5.融资情况</strong> ：&nbsp;</p><p>2023年12月，Pika Labs获得5500万美元的融资，包括前种子轮和种子轮融资，以及由Lightspeed Venture Partners领投的A轮融资；</p><p>2024年6月5日，Pika Labs再次筹集8000万美元的融资，估值达4.7亿美元 。</p><h2>02.赋能创意，简化创作</h2><p>时代的数字化已然无可避免，内容创造与消费也成为了我们日常生活中极其重要的一个部分。其中，视频作为最直观、最生动的媒介形式，其制作与分享的需求正以前所未有的速度增长。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_b7e0bbc679174c159d076a237d3c5095@46958_oswg140784oswg750oswg431_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>需求创造应用。 正是在这样的背景下，Pika Labs诞生了，彻彻底底地为传统视频制作流程带来了一次颠覆性革新。&nbsp;</p><p>最新消息显示，Pika Labs已成功获得8000万美元的融资，这一数字除了代表投资者对其技术实力和市场前景的高度认可，更是对Pika Labs未来发展的坚定信心。&nbsp;</p><p>Pika Labs的创始团队很简单，只有四位年轻人。&nbsp;</p><p>核心成员是斯坦福大学AI Lab的博士生Demi Guo与Chenlin Meng，以及其他两位创意技术成员。 <strong>秉持着“赋能创意，简化创作”的初心，这个“小而美”的创企开始进行Pika的研发</strong> 。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_d22d0103e1f14b41a52f23083b612709@46958_oswg77075oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Pika Labs在官方的介绍中写道： “通过提供易于使用、功能强大的工具，激发更多人的创意潜能，帮助他们将想法转化为视觉作品。 ”&nbsp;</p><p>基于以上，成立仅一年多的Pika Labs不仅吸引了众多用户的关注，也赢得了资本市场的青睐。投资者们纷纷伸出了橄榄枝，为公司的持续创新和快速成长提供了强大的资金支持。&nbsp;</p><h2>03.视频行业的“ChatGPT”</h2><p><strong>Pika Labs拥有一个顶尖的文本转视频平台</strong> ，能够将创意概念直接转化为视觉上引人入胜的视频。 <strong>该平台提供Img2Vid和Text 2 Video等创新功能</strong> ，这些功能简化了用户的视频创建过程，提高了视频生成的质量和效率，从而让Pika labs在图文生视频领域拥有着强大的竞争力。&nbsp;</p><h3>核心产品：Pika1.0模型</h3><p><strong>Pika的核心产品是Pika1.0模型，它是一款先进的AI视频生成器</strong> 。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3f4fa6bf0f2a42a8b54754e844f531c2@46958_oswg62840oswg738oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>早前，Pika Labs曾发布过Pika测试版模型，原先的模型只能生成普通的2D动画。 而Pika Labs在短时间内，仅通过一次迭代就发布的Pika1.0模型，实现了视频效果的巨大升级。&nbsp;</p><p><strong>Pika1.0能够生成各种风格和类型的视频</strong> ，例如3D动画、真人剪辑、动漫或电影。这些仅靠模型生成、极具实拍感的电影级场景能够呈现出精致的细节、完美的光效以及多样化的镜头切换。&nbsp;</p><p>不过，Pika1.0的魅力并不局限于此。&nbsp;</p><p><strong>它最大的突破点是支持用户实时进行视频的编辑和修改</strong> 。具体来讲，用户在生成一个原创视频后，如果还想要修改视频的局部，可以再次输入简短的指令，即可修改固定或移动的物体。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_1bb9d7cf18744e3ba4f3a13ea821bf9c@46958_oswg586675oswg1056oswg535_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外， <strong>Pika1.0现在可供所有人免费使用</strong> 。&nbsp;</p><h3>简洁高效的使用流程</h3><p>除Pika1.0支持桌面与移动双端的网页在线生成AI视频，网页界面配有一个易于使用的对话界面（类似于ChatGPT）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_e7240c0b920f41c6b3326e260f02b816@46958_oswg397619oswg1080oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>用户访问Pika Labs的官方网站，点击右上角的“Try Pika”跳转到Pika1.0网页界面。再通过谷歌或Discord账号进行注册，就可以直接使用所有功能。目前支持两种方式：</p><p>1.直接生成视频：输入/create ，然后输入prompt，得到视频。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_be6e55a94e0040cab37f9704de516672@46958_oswg413848oswg1080oswg564_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2.图片生成视频：使用MJ/SD生成图像（可选）+在Pika平台添加prompt=得到视频。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_b5c8d0cf39074fee95c3970067f2f3ff@46958_oswg516031oswg1016oswg653_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Pika1.0模型目前能够达到专业视频创作才能达到的质量和精度水平。除了文生/图生视频，<strong>Pika还支持以下的高阶功能：</strong></p><p>将视频延长至任意长度/修改内容：每次增加4秒，无限延长至任意片段。通过内画即时修改任何视频的各个方面，例如添加另一个角色或更换某人的衣服。</p><p>风格转换：将已有视频转换为其他风格，包括差异化的角色及对象，同时还能够保持视频内对象的结构。</p><p>扩展视频画布：通过外绘扩展画布或宽高比。将视频从现有视频平台的9:16竖屏尺寸更改为宽屏的16:9格式，AI模型将预测超出原始视频边界的内容。</p><p>调整摄像机的移动：实时调整运动元素，包括相机的平移、倾斜、变焦及运动强度。</p><h2>04.视频创作的未来</h2><p>Pika在PixVerse、Runway、Genmo、Haiper等对手的包围中还能占据一席之地实属不易。作为一家初创公司，在短短的时间内取得了令人瞩目的成绩的确值得骄傲，但这家年轻的科技公司并未止步于此。相反，他们正在积极规划下一步的发展蓝图。&nbsp;</p><p>该公司创始人表示， <strong>将继续深耕视频生成领域，希望Pika可以将任何人的愿景变为现实</strong> 。&nbsp;</p><h3><strong>拓展技术的深度与广度</strong></h3><p><strong>Pika公司将进一步优化其人工智能算法</strong> ，以提高视频生成的精确度和智能化水平。 通过深度学习和自然语言处理技术，Pika的工具将能够更好地理解用户需求，生成更加贴合主题的视频内容。&nbsp;</p><p>模型的进阶：Pika公司将继续优化和升级其AI视频生成模型，利用更先进的算法和更大的数据集进行训练，以提升模型的生成能力、稳定性和效率。例如，参考OpenAI的Sora模型，Pika可以探索生成更长、更高质量视频的可能性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_c1d0462b017d4489bc43e2457498a242@46958_oswg136134oswg841oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>功能独特性：除了现有的视频风格生成和编辑功能外，Pika还将探索更多创新功能，如更精细的视频编辑、动态场景生成、情感表达等，以满足用户对于视频创作的多元需求。Pika 具有配音效和对嘴型功能、Runway具有控制笔刷功能，Dreamina具有很好的动态效果，Domo的转绘效果更好等等，独特功能才是Pika在众多视频生成工具中脱颖而出的关键。&nbsp;</p><h3>人机协同的创作模式</h3><p>在AI创生时代，视频生成领域将迎来一次深刻的变革，这场变革将不仅局限于技术层面，更是对内容创作、传播方式乃至整个社会文化的一种颠覆性重塑。&nbsp;</p><p>虽然AI算法可以自动化地生成视频内容，但人类的创造力和想象力是AI无法替代的。因此，未来的视频创作很大可能将采用人机协同的模式，人类创作者和AI算法将共同参与到视频创作的各个环节中。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_09bd6386d39a4b38bfc5dcbc3c625f9b@46958_oswg678802oswg1000oswg560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>人类创作者可以发挥自己的创造力和想象力，为AI算法提供创意和灵感； 而AI算法则可以根据人类创作者的指导和要求，快速生成高质量的视频内容。 这种人机协同的创作模式将使得视频内容更加丰富、多样和具有创新性。&nbsp;</p><p>随着AI创生时代的到来，视频内容的多样性和个性化将得到进一步提升，这将有助于更好地表达和传播社会文化、价值观念等。同时， <strong>AI算法还可以根据用户的反馈和喜好进行实时调整和优化</strong> ，使得视频内容更加符合用户的期望和需求，从而推动社会文化的发展。&nbsp;</p><p><strong>当然，AI视频生成在发展过程中也面临着一些挑战</strong> 。如何保证视频的质量和原创性、如何平衡技术发展和隐私保护等问题还需要行业内各方共同努力解决。&nbsp;</p><p><strong>参考链接：&nbsp;</strong></p><p>1.https://pika.art/home&nbsp;</p><p>2.https://venturebeat.com/ai/pika-labs-text-to-video-ai-platform-opens-to-all-heres-how-to-use-it/&nbsp;</p><p>3.https://lsvp.com/stories/pikas-imagination-engine/&nbsp;</p><p class="editor-note">本文来自微信公众号“元宇宙之心MetaverseHub”（ID:MetaverseHub），作者：元宇宙之心，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808195535214978</id>
            <title>“人海战术”能让比亚迪的智驾踏足第一梯队吗？</title>
            <link>https://www.36kr.com/p/2808195535214978</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808195535214978</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 11:36:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 自动驾驶, 比亚迪, 研发团队, 智能化
<br>
<br>
总结: 比亚迪董事长王传福贬低自动驾驶，实际上却投入大量资源组建了4000人的智驾研发团队，表现出对智能化的重视。比亚迪在智驾领域投入巨资，与多家软硬件企业合作，展示出智驾技术的飞速提升，未来计划适配高阶智驾。比亚迪在智能互联网汽车领域取得突破，获得了自动驾驶汽车实力的认可。 </div>
                        <hr>
                    
                    <p>2023年业绩发布会后的投资者会议上，比亚迪董事长王传福直言，自动驾驶都是扯淡，不过是皇帝的新装，全都是大忽悠。此言一出瞬间引起行业震荡，甚至有人怀疑，王传福公开贬低自动驾驶，是不是意味着比亚迪不打算在智驾领域投入太多资源？</p><p>然而，近期腾势销售事业部总经理赵长江却在直播中表示，比亚迪智驾部门员工多达4000人，每个月工资要发10亿元，平均工资25万元。虽然吴佩发布该微博后又删除，但考虑到这番言论出自赵长江，可信度很高。原来比亚迪只是嘴上说着自动驾驶是大忽悠，实际上却组建了一支4000人的研发团队，而且平均工资这么高，不知道招募了多少行业大牛。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_563d68983664465eb503c71763c32437@5687509_oswg606834oswg954oswg697_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于王传福的“口嫌体正直”，小通丝毫不感到奇怪，毕竟新能源汽车行业已经进入拐点。王传福曾说过，新能源汽车的上半场是电动化，下半场是智能化。</p><p>作为全球销量第一的新能源车企，比亚迪不会缺乏远见。随着新规的不断推出，FSD即将入华，智驾领域的竞争愈演愈烈。大模型时代研发智驾功能最重要的是数据，若智驾不能及时上车，导致数据量落后，就可能与其他车企拉开难以追上的差距。</p><p>4000人的团队和10亿月薪只是比亚迪研发投入的一部分，比亚迪从去年5月智驾团队负责人换帅以来，投入了更多资源，甚至出现了部门变动，只为全面发力自动驾驶。</p><h2>比亚迪砸重金搞智驾研发</h2><p>现阶段华为已经推出了全国都能用的ADS 2.0，下半年准备推送智驾能力更强的ADS 3.0，蔚来、小鹏等头部造车新势力，城市NOA已开通了一两百座城市，也在计划推送全国都能用的领航辅助驾驶。再看看比亚迪，目前只有腾势N7收到了城市NOA功能推送，而且支持的城市也不多。&nbsp;</p><p><strong>从整车制造到三电系统，比亚迪领先行业大多数车企，实力毋庸置疑，但我们也要承认，智驾方面比亚迪产品暂时表现一般。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_cb81086fdd7f407298d87af93524e1e7@5687509_oswg321559oswg1668oswg1000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比亚迪智驾部门负责人韩冰曾表示，基于BEV的大模型算法是比亚迪实现弯道超车的机会。由此不难看出，比亚迪内部明白自身存在的问题，也知道机会在哪里，那么剩下的就是砸钱、招揽人才，以及研发技术了。</p><p>2023年5月，比亚迪原智驾负责人王欢离职，韩冰接管该部门。比亚迪内部员工透露，经常看到凌晨韩冰还在带着团队成员开会，整个团队都“卷”了起来。可见比亚迪对待智驾愈发重视，整个团队的成员都拼着劲想把智驾做好。</p><p>1月16日的比亚迪梦想日上，王传福亲口承认，智驾团队规模已扩充到4000人。同时比亚迪副总裁杨冬升还透露，比亚迪汽车未来将搭载算力达到1000TOPS和2000TOPS的驾舱一体芯片。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_961d445e51824abe8b13292bc5f96997@5687509_oswg771667oswg4500oswg2831_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一个多月后，比亚迪被曝智舱中心和智驾中心合并，比亚迪的目标也拓展到驾舱融合、全车智能。</p><p>除了内部团队的扩充和整合，比亚迪还积极与其他智驾软硬件企业合作，例如新车将搭载地平线最新一代征程6芯片；与Momenta联合成立智驾合资公司迪派智行；其他NVIDIA、速腾聚创等众多软硬件企业，也与比亚迪有智驾相关的合作项目。</p><p>此前行业还曝出过比亚迪向华为寻求合作，但华为可能是出于对智选车合作伙伴的保护考虑，婉拒了比亚迪的合作申请。</p><p><strong>没有什么是砸钱做不到的，如果有，那就是砸得不够多。</strong>大量资金投入之下，比亚迪智驾技术飞速提升，并且陆续向消费者展示了大量成果，还公布了未来汽车适配高阶智驾的计划。</p><h2>重金之下，比亚迪硕果累累</h2><p>面对即将到来的智能化时代，去年下半年自主品牌和海外品牌都在积极申请L3级自动驾驶路测牌照。有趣的是，当十一二月车企陆续发布公告，表示已经拿到路测牌照时，到了12月比亚迪才发布公告表示，早在7月就拿到了深圳市的路测牌照，给人一种“我们很强，只是不轻易秀实力”的形象。</p><p>今年6月4日，工信部公布了首批“智能互联网汽车准入和上路通行试点”名单，一共只有9家车企，覆盖乘用车、卡车、大巴等多种类型，其中大多数企业有国资背景，没有国资背景的乘用车企业只有比亚迪和蔚来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_c3aa2f1aa25743169e4144a6c222fd15@5687509_oswg144016oswg600oswg332_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>按照去年11月工信部公布的该通知解读文件，本次试点就是在为自动驾驶车辆上路做准备，将推动量产车型上路通行和推广应用。换句话说，<strong>拿到了本次智能互联网汽车准入和上路通行试点资格，等同于拥有开发可量产的自动驾驶汽车的实力。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3f3a790f6c92428f991b28f8a10a9d98@5687509_oswg369564oswg1845oswg1199_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，未进入该名单并不意味着智驾技术落后，鸿蒙智行和小鹏两大公认智驾第一梯队企业，均未拿到试点资格，但比亚迪能够通过申请，说明相关部门对于比亚迪的智驾实力足够认可。</p><p>当然，站在消费者的立场上，我们更关注C端产品，在这方面比亚迪确实表现一般，仅有腾势N7开通了部分城市NOA功能。其他如王朝网的汉、唐，海洋网的海豹等定位稍高的车型，也不支持城市NOA。</p><p>更关键的是比亚迪在梦想日上公布的智驾战略为30万元以上车型标配，20万元以上车型选配。这也就意味着，<strong>比亚迪暂时可能没有向20万元以内车型推送高阶智驾的想法，而智驾下沉市场已经成了行业趋势。</strong></p><p><strong>因此，对于比亚迪而言，不仅要快速提升智驾能力，更要考虑如何下放智驾，以提升产品竞争力，应对未来汽车行业全价位产品的激烈竞争。</strong></p><h2>新时代比亚迪以智取胜</h2><p>按照毫末智行CEO顾维灏的说法，智驾1.0时代属于硬件驱动，2.0时代为软件驱动，如今智驾已进入3.0时代，由数据驱动。</p><p>1.0和2.0时代传统车企基本存在掉队情况，敏感性不如造车新势力，但进入3.0时代后，传统车企将拥有极大的优势。<strong>BEV大模型算法可以通过时间、多视图和空间等数据，训练出智驾大模型，用于驱动汽车，数据量越大智驾安全性就越高。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_2a989ffecfb64fafadd88e294f450987@5687509_oswg4062135oswg4624oswg3468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>顾维灏认为，1亿里程数是智驾3.0时代的门槛，造车新势力由于车辆销量较少，收集数据的难度大。</p><p>正如比亚迪智驾负责人韩冰所言，BEV大模型算法是比亚迪弯道超车的好机会。<strong>比亚迪产品销量高，收集相同量的数据，所需时间远低于造车新势力，有助于加快BEV大模型的训练速度和提升智驾能力。</strong></p><p>至于智驾下放，比亚迪暂时没有透露出相关规划，但从其他企业的表现来看，今年就会出现少量15万元左右支持高阶智驾的车型。其中的代表车型是小鹏MONA品牌，预计产品售价10万-15万元，支持纯视觉高阶智驾。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_fe31e597b3d945cbaed188bc0c91c43a@5687509_oswg502614oswg3840oswg2000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>百度Apollo、大疆车载等企业，也在推出基于纯视觉的智驾方案，力求将智驾平台成本降低到1万元以内，让价格低于10万元的车也有机会配备高阶智驾。</p><p>不过比亚迪的产品性价比有口皆碑，接连几年的价格战更是让我们看到了比亚迪可怕的成本压缩能力。<strong>尽管目前比亚迪尚未公布中低端车型的智驾规划，但小通相信当智驾真的下探到15万元以内市场后，比亚迪也会迅速跟上，不至于核心竞争力不足。</strong></p><p><strong>毕竟拥有一直数量高达4000人，平均月薪25万元的研发团队，足够多的人才，才是比亚迪面对智能化时代的核心竞争力。</strong></p><p>本文来自微信公众号“电车通”（ID:dianchetong233），作者：电车通，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808173423614854</id>
            <title>今年的苹果全球开发者大会，主角是它</title>
            <link>https://www.36kr.com/p/2808173423614854</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808173423614854</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 11:36:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果官方, 全球开发者大会, iOS 18, AI技术
<br>
<br>
总结: 苹果官方宣布全球开发者大会将于6月11日开启，iOS 18将加入生成式AI技术，带来多项功能升级。 </div>
                        <hr>
                    
                    <p>随着苹果官方宣布，备受瞩目的全球开发者大会（WWDC24）将于北京时间6月11日凌晨1点正式开启，科技界的目光再次聚焦于这家科技巨头。作为一年一度的科技盛事，WWDC不仅是苹果展示最新软件技术的平台，更是全球开发者交流和学习的重要机会。今年的WWDC24，无疑将带来一系列令人期待的更新和创新，下面让我们看看WWDC24中可能会出现的升级吧。</p><p class="image-wrapper"><img src="https://file.36krcdn.com/hsossms/20240606/v2_dab91fc4b5364e66a8fe35b511609e10@5688845_file_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>iOS 18</h2><p>最受关注的莫过于iOS 18的发布。此前许多业内人士透露，苹果将与谷歌合作，在iOS 18将加入生成式AI技术，并由此带来了诸多功能，主要有以下几点升级。</p><p class="image-wrapper"><img src="https://file.36krcdn.com/hsossms/20240606/v2_41ce968d6e274404a95224b431c10d9d@5688845_file_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>更智能的Siri和生成式AI：</strong>iOS 18将为Siri、Spotlight、快捷方式等提供新的AI功能，Siri将更加智能，能够提供更多帮助和创作任务。</p><p><strong>“更可自定义”的主屏幕：</strong>用户将能够在主屏幕网格的任意位置放置应用图标，并允许更改应用程序图标的颜色。</p><p><strong>新的无障碍功能：</strong>iOS 18将推出一系列新的无障碍功能，包括眼球跟踪、车辆运动提示、语音快捷方式等。</p><p><strong>RCS（融合通信服务）支持：</strong>支持RCS后，iPhone和安卓设备之间的信息体验将得到改进，包括更高分辨率的照片和视频、音频信息、改进的群组聊天功能。</p><p><strong>Apple Music更新：</strong>iOS 18中，Apple Music将可以自动生成播放列表，歌曲转换将更加智能。</p><p><strong>计算器应用改版：</strong>新增多项功能，包括列出最近计算结果的侧边栏、改进的单位转换界面、与便签应用的集成等。</p><p><strong>日历和提醒事项整合：</strong>用户可以直接在日历APP中安排和组织提醒事项。</p><p><strong>健康应用新AI功能：</strong>苹果计划为健康应用推出新的AI功能，具体细节尚未公布。</p><p><strong>iWork生产力应用套件更新：</strong>包括Keynote、Numbers和Pages，将提供新的AI生成功能。</p><p><strong>邮件、照片和健身应用全面改造：</strong>照片应用将提供AI驱动的照片润饰功能，邮件应用可能会有“建议的邮件回复”功能。</p><p><strong>Safari浏览器新功能：</strong>可能添加浏览助手，总结网页内容，以及“网页橡皮擦”功能，允许用户删除网页中的某些元素。</p><p><strong>快捷方式应用改进：</strong>用户将可以通过“快捷方式”应用更轻松地自动执行复杂的任务。</p><p class="image-wrapper"><img src="https://file.36krcdn.com/hsossms/20240606/v2_5059df50f52c4d76af50441dde9d62d3@5688845_file_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据目前透露的消息，本次iOS 18共支持24款机型升级，分别为：iPhone SE 2020/2022、<a href="https://product.pconline.com.cn/mobile/apple/1123572.html" rel="noopener noreferrer nofollow" target="_blank">iPhone XR</a>、<a href="https://product.pconline.com.cn/mobile/apple/1116047.html" rel="noopener noreferrer nofollow" target="_blank">iPhone Xs</a>系列、<a href="https://product.pconline.com.cn/mobile/apple/1124165.html" rel="noopener noreferrer nofollow" target="_blank">iPhone 11</a>系列、<a href="https://product.pconline.com.cn/mobile/apple/1124166.html" rel="noopener noreferrer nofollow" target="_blank">iPhone 12</a>系列、iPhone 13系列、iPhone 14系列、iPhone 15系列。当然下半年发布的iPhone 16系列也肯定会搭载新系统，其中在2018年发布的<a href="https://product.pconline.com.cn/mobile/apple/1036888.html" rel="noopener noreferrer nofollow" target="_blank">iPhone X</a>R和iPhone Xs系列可能是苹果最后一次进行iOS大版本更新。</p><p class="image-wrapper"><img src="https://file.36krcdn.com/hsossms/20240606/v2_2efb22ff7bd04be8a5be1b5e29b28844@5688845_file_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>iPadOS 18/macOS 15/tvOS 18/watchOS 11/visionOS 2</h2><p>本次WWDC的主要重点都在iOS 18上，对其他系统的透露相对较少，但苹果引入生成式AI对于其他操作系统来说肯定会带来一系列别具一格的更新，因此我们可以预测一下这些系统将会做哪些升级。</p><p>iPadOS 18预计也会引进与iOS 18一致的功能，比如可生成式智能对话的Siri、Safari浏览器的网页橡皮擦功能等等应该也会在iPad上得到支持，生成式AI将进一步提升iPad的生产力和创造力。</p><p>macOS 15将继续优化macOS的用户体验，将加入新的设计元素以及对最新硬件的支持，可能还会带来搭载M4的新MacBook Air。</p><p>tvOS 18将为Apple TV用户提供更丰富的娱乐体验，可能包括新的界面设计和更多的个性化选项。</p><p>watchOS 11预计将加强Apple Watch的健康和健身功能，可能引入新的健康监测特性和更深入的运动分析。</p><p>而visionOS 2作为苹果在新兴技术领域的布局，通过引入生成式AI应该会带来突破性的创新，集成更先进的AI技术，提供全新的交互体验，以及对AR和VR应用的改进支持。</p><p class="image-wrapper"><img src="https://file.36krcdn.com/hsossms/20240606/v2_1393231920384b3893e8a1f6c633f0c6@5688845_file_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>总结</h2><p>WWDC24无疑是苹果上半年的头等大戏，苹果将通过这场大会展示其在软件和AI领域的最新成果。无论是iOS 18的AI升级，还是其他操作系统的更新，都将为用户带来更加丰富和便捷的体验。同时，这也是开发者们不容错过的一次盛会，他们将在这里获得最新的开发资讯和工具，为未来的创新打下基础。</p><p class="image-wrapper"><img src="https://file.36krcdn.com/hsossms/20240606/v2_f6a8c21143154189a20dda483d9c7edc@5688845_file_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="editor-note">本文来自微信公众号“PConline太平洋科技”（ID:pconline_cn），作者：PC，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808143914923399</id>
            <title>美团守卫团购本垒</title>
            <link>https://www.36kr.com/p/2808143914923399</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808143914923399</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 11:14:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 提取出来的关键词,抖音,美团,团购,直播
<br>
<br>
总结: 本文主要讲述了抖音和美团之间在团购领域的竞争，抖音通过推出新的消费方式“囤券”进攻美团的本地生活市场，美团则通过“特价团购”和“直播”等方式来抵御抖音的挑战。双方在价格战中激发了用户囤券的欲望，而美团也在加大商家直播和达人直播的比重来提高订单转化率。虽然抖音在信息流展示方面具有优势，但美团直播的订单转化率和到店核销量较高，仍有一定的竞争优势。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_030886431a364885a607eb846c364652@000000_oswg692196oswg1080oswg518_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>郭有才的一首《诺言》，带火了菏泽南站，并吸引众多网红前往直播。菏泽南站的这场狂欢目前虽然已经被按下暂停键，但这波热度切实地为菏泽带来消费增长。抖音生活服务数据显示，5月10日至12日，菏泽抖音文旅团购订单同比增长6倍，餐饮和休闲娱乐订单同比均增长2倍。</p><p>推荐算法与潜在消费需求的碰撞，激发出“囤券”这种全新的消费方式，以抖音为首的互联网企业集体进攻美团腹地，争夺美团占有极高市场份额的本地生活蛋糕，让美团感受到前所未有的压力。</p><p>这种压力一方面来自现有业务遭遇的冲击，另一方面也可能来自对既往业务和公司基因的检讨，<strong>要知道，美团才是现存头部APP当中，开展团购业务的鼻祖。</strong></p><p>诞生于2010年的美团，最初的主要业务正是团购，并于“千团大战”中一战成名，从此奠定了在本地生活赛道中的江湖地位。</p><p>某种角度上，当下的这场团购大战2.0版本，和郭有才的遭遇何其相似，在他火了之后，大量网红涌入菏泽，迅速在小环境里掀起了流量暗战。而抖音等内容平台进军美团腹地，最初看似一处闲笔，没想到竟在极端的时间搅动了本地生活和酒旅两个赛道的风云，甚至对美团的地位也有些许撼动。</p><p>抖音的入局，改变了以往“团购”的逻辑，除了“到店核销”，还增加了“外卖配送到家”的形式，这无疑是同时对美团两项核心的业务下了战书。而另一方面，凭借着内容和流量优势，抖音在入局本地生活后迅速打造出多个优秀案例，比如麦当劳在抖音直播中创下了单日千万销售额的记录，这也让美团意识到危机已经来临。</p><p>在这场“团购”二战中，美团的反应速度显然有些迟缓，抖音从2020年就开始探索本地生活，但直到2022年下半年美团到店广告收益出现明显下滑后，美团才开始成立防御团队来专门研究抖音。后知后觉的美团开始匆忙用“特价团购”挽回商家和用户，并开启“直播”来补齐内容方面的短板，但却难以阻挡抖音本地生活业务的成倍增长之势。</p><p>被围攻的美团，还能守得住十三年前打下的这片江山吗？</p><h2>01</h2><p>美团在其2023年财报中提到：通过“特价团购”，我们与高质量商家合作，提供多元的折扣优惠，提高流量分配效率，因而“特价团购”订单快速增长。我们还推出一系列直播组合，包括官方直播、商家直播及销售团队直播，这样我们能为消费者提供形式生动的推荐，满足他们的囤货需求。</p><p>“特价团购”和“直播”，是美团在“团购”二战中的两大核心武器。与此同时，《最话》注意到，美团还在“兵器库”里拿出了一些旧武器，例如美团圈圈，这个分销工具可以通过社交裂变来实现获客和转化。</p><p>“我在美团圈圈里买的券都是3到4折。”自美团圈圈在成都开城以来，李慧就成了其中的一个“达人”，“邀请别人注册后，被邀请的人就会成为我的‘下线’，当我的‘下线’购买团购券并核销后，我就可以获得返佣，我有14个‘下线’，一年的时间我赚到佣金有1083块。”</p><p>《最话》观察发现，随着“个人直卖核销额”和“团队直卖核销额”增加，“达人”等级会得到提升，直卖佣金比例也会有5-40%不等的加成。</p><p>实际上，美团圈圈一度是已经边缘化的业务，但4月又开始启动大规模招商。美团方面表示，美团圈圈已经构筑三大流量场：企业微信群、达人分销矩阵以及美团圈圈小程序。其中，企业微信群已覆盖全国1000多个城市，群内人数超千万，注册美团圈圈的达人超过300万，美团圈圈小程序的日活用户已破百万。</p><p>不过，在和抖音等平台比拼的过程中，美团也有劣势。<strong>在消费者心智当中，美团为本地生活工具平台，一般只有在想要消费的时候才会想起来用，使用频次和停留时长都与内容平台想去甚远。</strong>事实上，负责到店业务的大众点评已在更早时期开始内容化，但无论是双列点选的笔记形式，还是整个平台的内容供给，都还有很大的提升空间。</p><p>当然，到店业务的内容化已经走在了到家业务的前面，但是以往由于在美团到店业务和到家业务处于不同的业务线，双方并没有很强的流量互换和业务协同，这应该也是今年4月，美团到家和到店业务合并的一个重要原因。</p><p>在打破部门墙之前，2023年，美团也开始尝试外卖场景的内容化了。<strong>但不同于抖音的是，美团外卖的直播是以官方自播“神抢手直播间”为主，商家直播和达人直播为辅</strong>，有美团内部人士曾向媒体透露，美团超过70%的GMV都由官方直播间贡献。</p><p>当然，在前期阶段，由平台来主导业务也无可厚非，但既然美团要开展内容化，丰富的内容供给就是必须要解决的问题之一。6月5日晚上10点多，我们发现美团的在播直播间只有北京、上海、长沙、佛山等个别城市的官方直播间。<strong>基本上，定位单一城市，可进入的直播间数量只有0~3个。</strong></p><p>据了解，美团正在加大商家直播和达人直播的比重，一方面通过“千分之六佣金”、“直播销量计入总销量”等政策加大对商家的吸引力，另一方面通过加强补贴政策密集寻找地方MCN公司合作。</p><p>不同于团购业务，外卖业务本身就具有一定的壁垒，包括大量的商家入驻，以及稳定的骑手配送体系。虽然信息流的展示方式，让抖音外卖更容易触达潜在消费者，但其在短时间内也无法打破美团外卖的壁垒。</p><p>此外，虽然没法与抖音上的内容型直播比播放量，但美团直播的订单转化率和到店核销量都比较高。<strong>有数据统计显示，美团直播订单平均转化率为30-40%，也有服务商向媒体透露，美团直播间整体效率在60%左右，比抖音高出近一倍。</strong>去年10月，也就是美团直播上线半年之后，其单月GMV就突破了20亿。虽然体量与抖音相比仍有较大差距，但增速比较“理想”。</p><p>靠着“特价团购”和“直播”，美团能守住自己的“团购”本垒吗？</p><h2>02</h2><p>2022年底，美团上线“特价团购”，时隔一年，抖音也推出“特惠团购”板块，双方价格战就此打响。《最话》对比两个平台的团购价格，发现彼此都咬得很紧，差价都在个位数，比如华莱士的香辣鸡腿堡在美团上的价格是10块钱两个，在抖音上的价格是30块钱5个。</p><p>如此激烈的营销，极大程度的激发了用户囤券的欲望。“美团直播刚开始的时候，很多团购都是一两折。”李慧告诉《最话》，她非常喜欢囤这些团购券，<strong>“现在我待使用的券有45张，高峰时期有近百张，我们很多群友都觉得是变相存钱了，用的时候很优惠，就算不用到期了也会自动退。”</strong></p><p>经历了“千团大战”后，美团成为团购行业的一枝独秀，没有比价空间，消费者们习惯在点菜或结账时现场购买团购券，很少有人会去囤券。但随着抖音、携程等玩家通过短视频或直播入局“非即时消费”的酒旅和外卖业务，培养出消费者“囤券”的习惯。尽管作为团购鼻祖的美团，在此战中入局较晚，但相信它已经领略到，这种由不确定消费欲望产生的消费行为，对于平台来说“很香”。</p><p>正如美团2023年度财报中所提到，通过“特价团购”，美团与高质量商家合作，提供多元的折扣优惠，提高流量分配效率，因而“特价团购”订单快速增长。美团还推出一系列直播组合，包括官方直播、商家直播及销售团队直播，这样平台能为消费者提供形式生动的推荐，满足他们的囤货需求。</p><p>这两部分的业务一定程度反映在美团的财报上：2023年美团核心本地商业部分的佣金收入为746亿元，比2022年多出近195亿元；在线营销服务收入超过402亿元，比2022年多出近96亿元。</p><p>所以，这也就不难理解为何抖音、小红书、快手、视频号、高德等都要争相通过“团购”入局本地生活市场了。据海通国际研报数据，抖音2023年本地生活服务的GTV（核销后总交易额）已经达到2000亿元，《快手本地生活洞察报告》显示，2023年第四季度，快手本地生活用户规模同比增长23倍，GMV同比增长25倍。</p><h2>03</h2><p>艾瑞咨询数据显示，2025年本地生活市场规模预计增长至35.3万亿元。QuestMobile报告显示，2023年4月本地生活综合服务行业全网渗透率38.4%。综合来看，本地生活市场是目前为数不多的依然存在较大增长空间的赛道。</p><p>这正是各个内容平台强势切入本地生活赛道的背景。不难发现，几乎所有平台在切入本地生活和酒旅赛道时，都以内容为载体，但同时以低价为核心。<strong>所谓的团购券，之所以吸引人立刻下单，不就是抛出过期不候的低价诱饵吗？</strong></p><p>今年3月，携程和飞猪曾经围绕京都威斯汀，展开过一轮低价车轮战，虽然美团并未现身，但在海外旅游重新起航的当下，这些热战不可避免的也在对它产生影响。</p><p>显然，强敌环伺之下，美团在本地生活和酒旅业务上，围绕低价必有一战。比如在与抖音外卖对垒时，美团不仅上线“神抢手直播间”，还做起“拼好饭”业务。通过定向招商，与商家协商制定出低毛利率的价格，并在配送上采用“畅跑模式”以节约成本，从而以SKU的逻辑为消费者推荐优惠便宜的套餐。</p><p>但在一个健康的商业模式里，价格战必然不是长久之计。<strong>在“达人”李慧所在的美团圈圈的群里，有一个“吃头七”的说法，意思是新店开业前一周要赚口碑，所以菜品都不错，再往后团购越做越亏，商家要么“毁约”，要么就“减量”。</strong>由此可见，低价本地生活服务，开关并不完全掌握在平台手上，而是需要商家参与到长期共建当中。</p><p>所以，与其说美团要守住团购本垒，不如说它得留住用户和商户。</p><p>（应对方要求，李慧为化名）</p><p>本文来自微信公众号“最话FunTalk”（ID：iFuntalker），作者：魏霞，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808135185315461</id>
            <title>抢购小米SU7，“晚订一个周末，提车延后一个月”</title>
            <link>https://www.36kr.com/p/2808135185315461</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808135185315461</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 11:02:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米模式, 新能源市场, 纯电市场, 女性用户
<br>
<br>
总结: 小米发布SU7后，以其独特的销售模式和产品特色在新能源市场取得胜利，吸引了大量订单，尤其受到女性用户的青睐。其颜值和功能设计吸引了消费者，同时对其他品牌造成了冲击，展现了小米在汽车领域的创新和成功。 </div>
                        <hr>
                    
                    <h2>小米模式的胜利</h2><p>5月26日，新一轮的争夺开始了。随着8万个新能源指标名单公布，获得这张绿色牌照的人们涌向各大电动车门店。而早早守候结果的一线销售们打起精神，在这片新增长的市场中争取更多订单。</p><p>“这几天来逛合生汇的人都是摇到号的。”一个小鹏汽车销售人员看着门店外来来往往的人群说。</p><p>一名蔚来的销售人员指着门店中空出的一块地告诉我，“这儿原来是放着一台EC6的，前几天刚被客户直接开走，展车还来不及补上。”</p><p>自从小米发布SU7，纯电市场的热度一下子高了许多。作为流量的中心，它的热度并没有减弱。相反，在新能源牌照下发的这个周末里，订单如雪花般涌入，小米汽车的销售林京有些得意地告诉我，不需要过多介绍，很多摇到号的人在第一时间冲到店里下定。</p><p>购买过程在这儿变得如此简单——解答疑惑，试驾一圈儿，订单就确定了。面对一些还在犹豫的人，林京也会不失时机地劝说，“拖过一个周末，提车时间又要向后延一个月。”五月的四个周末里，她所在的门店的成交量保持在两三百台的高位水平。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_835ed120884549e79efb7de2f79a2763@000000_oswg94695oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一个周末就多出几千人的说法，充满了像是高考竞争一般的紧迫感。林京说，“毕竟北京还需要摇号，其他城市的人完全是放开了买。”</p><p>就像在北京车展上，周边城市来支援的销售员，几天时间里，每个人手里至少捏着200多个订单——还是一些很偏僻，平时人流量并不高的门店。“这可一点儿不夸张。”她总结。根据媒体数据，5天车展为小米带来了1.2万张新增订单。</p><p>购买小米SU7的人也许有着各种理由，而颜值发挥了比想象中更大的力量。霞光紫吸引了不少女性的关注，林京观察到，自从这台紫色的小米SU7摆在门口，许多路过的女生都会发出“好好看”的惊叹，然后折返店里，了解更多的细节。</p><p>雷军在不久前的演讲中总结，打动女性用户的还有防晒和收纳。整车防晒的设计免去了用户自行贴防晒膜、车内打伞的苦恼；而相比其他车型，新增设的副驾驶电脑收纳、螺蛳粉挂钩也让小米SU7收获了一众好评。</p><p>在小米上市28天的锁单用户中，女性直接购买者占比达到了28%，考虑到赠送或代为购买的情况，他们认为，女性车主的占比可以达到40%到50%。</p><p>更多的人也会为了操控感买单。樊军始终记得第一次驾驶小米SU7的情形。提车的当天，他和同行的4个朋友一圈圈开着小米SU7，每个从驾驶座位上下来的人都带着红润、兴奋的笑容。把油门踩下去的瞬间，强烈的推背感让他们的心跳剧烈加速。</p><p>作为一名中国科学院大学MBA课程的授课老师，他习惯用数字精准形容这个感受：“通常我的静息心率保持在60左右，但是小米SU7零百加速的两三秒内，运动手环上的心率直接冲到了160以上。”这一刻的感受，让他觉得提车漫长而琐碎的三个小时都是值得的。</p><p>当然，单纯为了小米品牌而消费的人就更多了。小米SU7上市，不仅拉高了纯电市场的关注度，也对其他品牌造成了冲击。一个小鹏销售人员在车fans中坦率地承认，受到小米SU7的影响，小鹏P7i的进店量下降了70%，“超过一半的客户看过小米就直接下定了。”</p><p>有用户很早就了解到小鹏智驾很牛，很懂车，也不盲目崇拜特斯拉。他找到销售人员，要求试驾体验过CNGP。</p><p>整个过程中，用户赞不绝口，每句话都在表达打开了新世界，“这么强这么厉害”、“这个功能太好了！”</p><p>然而，这个看起来就要成交了的用户立刻下单的却是小米SU7。“太好开了，发布会也很棒。”用户说。</p><p>这个小鹏销售用一句话总结了这个出人意料的故事，“什么智驾都不重要了，用户就是想要小米。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_0a75149849da4da09a6081a8103287cf@000000_oswg128332oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>小米SU7的到来，让“人车家”的构想有了具体的落脚点。一方面，如同外界所预料的，米粉和原有的小米生态用户帮助SU7打开局面，是小米汽车破圈的重要基础；另一方面，买了车的用户也在反向拉动小米其他产品的增长。小米市场部相关人士透露称，物理按键和香氛是卖得最好的两款产品。</p><p>一位小米车主也告诉车云网，在买了小米SU7后不久，她将自己的苹果手机换成了小米手机，“因为小米手机车钥匙太好用了。”</p><p>种种迹象表明，关于小米的故事迎来一个飞跃增长的想象空间——以小米SU7为支点，长久探索的高端化战略有了更清晰的发展路径。小米汽车发布会后的首个交易日，小米股价上涨接近9%。</p><h2>从手机到汽车，小米做到了苹果没做到的事</h2><p>2021年之前，雷军还未下定造车的决心。面对这个让他既好奇又迟疑的全新领域，雷军起初以投资代替亲自下场。</p><p>2013年，雷军两度拜访埃隆·马斯克，意识到“我们干的好像都是别人能干的事情，而马斯克干的事情别人想都想不到”。一年之后，雷军投资并推动了小鹏和蔚来的成立。2019年，小米追加投资小鹏汽车。</p><p>这个时期，小米和华为还在智能手机领域苦苦缠斗。2018年，小米和华为的手机出货量各自超过1亿台与2亿台，后者距离全球的霸主苹果手机仅有一步之遥。2019年，全球智能手机的增长见顶，寻找多元化业务成为头部企业的共同选择。这时，创立时仅有10%胜算的特斯拉迎来大幅增长，市值突破1500亿美元，仅次于丰田，成为市场中新的希望。</p><p>让命运的转折点先后到来。2019年，美国制裁华为，智能手机业务遭到重创；2021年，小米被列入黑名单，禁止美国投资者对其进行投资。</p><p>内部和外部的变动将小米推向了另一面：雷军终于决定，亲自进入造车领域。“这将是我人生最后一次重大创业项目，我愿意压上我人生所有积累的战绩与声誉，为小米汽车而战。”在小米2021年的春季发布会上，雷军发出了这个广为人知的诺言。</p><p>如果结合过往创办金山软件差点错过整个互联网发展的经历，进军新能源也符合他不要错过风口的人生经验。</p><p>这时的新能源市场早已不是当初的荒地。蔚来、小鹏蓬勃发展，推动纯电市场的教育和普及，用户慷慨解囊，乐于买下人生中第一辆电动车；特斯拉在中国建厂，带动了一批国产零部件供应链的繁荣生长；投资者与地方政府对发展电动汽车抱有乐观的态度，他们用资金、土地及其他优惠条件，吸引电动车企的落户和发展。</p><p>小米不是以新市场开拓者的身份进入，而是在一个市场逐渐成熟的状态中弯道超车，依靠相对成熟的技术，切入具体的生活场景，提供足够有性价比的产品——这也正是过去十多年小米在手机市场制胜的路径。此后，在电视、平衡车、大家电等每一个细分垂直领域，小米都将这套打法发挥到淋漓尽致。</p><p>现在，小米在电动车成功推出了第一款产品，反响超出预期——“第一分钟就有10万人加入心愿单。”毫无疑问，这也是小米模式的又一次胜利。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_f536ca87dd4f4570b0b50587fa3f290c@000000_oswg213294oswg1080oswg903_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今年2月，苹果宣布放弃造车的消息传来时，雷军表示要让小米汽车成为苹果用户的首选。</p><p>三个月后，小米统计的数据显示，苹果用户在购买人群中的占比达到52.5%。</p><p>一位小米市场部人士谈到他的惊讶，“按照我们的设想，苹果用户肯定会有不少，因为很多苹果用户也是小米智能家居用户，但没有想到会比‘米粉’的体量还要大。”他说，小米遵循苹果系统的规则，在规则之下也做了尽可能多的适配体验。</p><p>至此，曾经在手机市场三足鼎立的巨头有了各自不同的选择：华为深度参与，扮演智能驾驶供应商的角色；雷军真的造出了一款车；而苹果退出了在这个领域的竞争。</p><p>作为第一个完全进入汽车领域的科技大公司，小米SU7的成功发布也代表着更大的意义，“沃尔夫斯堡、斯图加特和因戈尔施塔特现在一定警铃大响”，曾经担任大众汽车集团（中国）总裁的倪凯铭(卡尔-托马斯·诺伊曼)评价，“这将是老牌制造商技术和经济下坡路上的又一里程碑。”</p><p>而美国媒体表达了更深切的失望：“小米还是成功实现了苹果已经梦想十年的项目。库克可能不得不从库比蒂诺远远看着，看看原本可以发生什么。”</p><h2>一炮而红之后</h2><p>雷军曾在一档节目中总结自己是“极度保守下的极度冒进”，“在风险可控的情况下小米推进的速度是极快的，在风险不可控的时候我们非常小心。”</p><p>确定进入电动车领域，小米的造车计划快速推进。据外媒最新报道，小米将推出紧凑型SUV，与特斯拉Model Y展开直接竞争。按照产业链信息，这款车将于明年发布。在此之前，小米在后续车型规划的信息不断传出，36氪报道称小米第二款车型为纯电SUV，明年上半年推出，第三款车初步定位15万级，于2026年推出。</p><p>成为全球前五的汽车厂商，这是雷军为小米定下的终极目标。不过，在完成后续的车型规划中，小米仍需应对当前的产能爬坡和亏损压力。</p><p>从6月开始，小米开启双班生产制，日生产时间从8小时增至16小时，今年保底交付10万台，挑战全年交付12万台。</p><p>财联社援引供应链人士称，“小米SU7加单约80%，其中一类零部件从每个月约1万套增加到最近的1.8万套以上。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_2607b44689554fa9ba01f9b07d41b51f@000000_oswg95991oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>林京说，最近下单中低配的用户可以在10月左右提车，顶配车型则需要等到今年年底。另有小米销售人员称，顶配车型的零部件和供应链需求会复杂，生产时间更长，提车要到今年底或明年初。</p><p>尽管订单火爆，小米也同样面临着亏损问题。此前，花旗预测小米卖出一台车平均亏损6800元，小米集团董事长特别助理、中国区市场部副总经理徐洁云称“这一信息可能偏差较大。”</p><p>不过，雷军也在之前坦白了亏钱卖车,“小米SU7卖21.59万元亏钱，24.59万元其实也亏钱。本来Max版规划35万元，但考虑到市场真的太卷了，就把最终售价确定在了30万元内。”</p><p>盈利还是需要规模效应。雷军说，“大家都在亏钱，小米汽车亏钱的程度是中等偏少，因为小米SU7的销量远超预期。”</p><p>对于雷军来说，当下最重要的事还是智能驾驶的推进。目前，小米汽车开通了高速NOA、自动泊车，今年8月要在全国开通城区辅助驾驶。</p><p>就在小米计划密集开城的前夕，前图森未来中国CTO王乃岩将加入小米汽车，向小米技术委员会主席、小米汽车自动驾驶负责人叶航军汇报。赢得首发头彩后，雷军必须快速补足智驾功课，在今年内进入行业第一阵营。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_c6584bc6a5fd4b699f1c41e557d56e95@000000_oswg117238oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不久前，在他直播小米SU7 Pro的智能驾驶和能耗的时候，雷军重申了自研智驾的决心，辟谣了小米将与第三方合作视觉方案的传言，并且公开邀请，是否有智驾大牛愿意加入小米。</p><p>卢伟冰在一季度财报会上透露，小米今年坚决投入智能驾驶，2024年预算大约是15亿元，整个第一期投入会达47亿元。</p><p>今年年底，小米在智能驾驶方面的工程师团队将计划扩展到1500人，2025年扩展到2000人。</p><p>在早有人抵达、身后没有同行者的这片战场上，小米用三年时间，完成了从手机到汽车的惊险跨越，手握大笔订单，迎来了第一场胜利。小米汽车正式站在了市场中央。当胜利的荣光过去，持续进行下去的压力将始终如影随形。小米SU7也将面对那些所有人都无法逃过的生存与竞争的焦虑。在终局来临前，坚持与不断解决问题或许是另一种更长久的胜利。</p><p>(林京为化名）</p><p>本文来自微信公众号“车云”（ID：cheyunwang），作者：倪毓平，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808183830607489</id>
            <title>文生视频公司Pika获新一轮8000万融资，估值达4.7亿美元</title>
            <link>https://www.36kr.com/p/2808183830607489</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808183830607489</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 10:42:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Pika, 人工智能, 视频模型, 融资
<br>
<br>
总结: 人工智能初创公司Pika宣布获得8000万美元的新一轮融资，将用于继续训练AI模型、改进产品特性和扩大团队规模。Pika是少数几家聚焦于生成式视频模型的公司之一，创始人在斯坦福的研究生项目中获得灵感。公司计划在今年晚些时候对软件进行重大升级，支持生成更高质量、更长时间的视频片段。 </div>
                        <hr>
                    
                    <p>腾讯科技讯 6月6日，人工智能初创公司Pika宣布获得8000万美元的新一轮融资，Pika表示预计将筹集的资金用于继续训练其AI模型，同时改进产品特性，并扩大团队规模。</p><p>本轮融资由Spark Capital领投，目前Pika估值已经达到4.7亿美元。其他参与B轮融资的投资者包括Greycroft、Lightspeed Venture Partners（去年也领投了Pika的A轮融资），以及Jared Leto（音乐人、投资人）。值得一提的是，Jared Leto的乐队Thirty Seconds to Mars也是Pika的用户之一。乐队的设计师已经尝试使用Pika制作视频，并将这些视频融入到了他们的现场演唱会中，为观众带来了独特的视觉体验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_e3bcd58471644d15b9632d4489599bc8@46958_oswg252411oswg614oswg866_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：Pika在X上官宣融资消息</p><p>Pika仅成立一年，是少数几家聚焦于生成式视频模型的公司之一。其他有代表性的公司包括Runway、爱诗科技、Morph AI 等。OpenAI在今年2月推出视频模型Sora，能连续生成60s视频，Demo效果碾压当时的其它视频生成模型。曾经引发行业对于这一垂直赛道正面迎战AI巨头的担忧。</p><p>Pika创始人Demi Guo（郭文景）在当时对国内媒体说，“很振奋，我们将直接冲。”四个月之后，OpenAI的Sora仍然没有正式对外开放，而Pika的新一轮融资，让外界也看到了资本对于视频模型赛道的认可。Lightspeed合伙人兼Pika董事会成员Michael Mignano表示，投资Pika是因为Lightspeed相信AI视频是一个“巨大的机会”，但制作高质量的片段仍然具有挑战性。“我们相信团队有能力完全降低视频创作门槛，普罗大众，并使世界上的任何人和每个人都能为这种媒介做出贡献，”Mignano说。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_e2490489c2e346049ad20c3a9747946f@46958_oswg414899oswg960oswg662_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：Pika联合创始人Demi Guo</p><p>Pika的两位联合创始人Demi Guo和Chenlin Meng，他们之前在斯坦福大学攻读研究生课程，但为了全身心投入到创业中，他们选择了休学。2023年底，他们带领团队推出了Pika的首款AI视频制作软件。这款软件非常强大，用户只需提供文本描述、静态图片或现有视频，就能快速生成短视频片段。更妙的是，它还有一个音效功能，比如可以为AI生成的粉红色瀑布视频配上湍急水流的声音，让视频看起来更加真实生动。</p><p>Pika的灵感来自于Guo在斯坦福的研究生项目，她当时专注于用AI创造内容，并在尝试拍摄短片时遇到了一些挫折。她设计了一个算法，可以把实拍镜头转换成动画效果，这让Guo意识到视频制作的复杂性和低效率，并激发了她用AI简化这一过程的想法。</p><p>最近两个月，Pika并未发布版本更新，对外也没有进行过公开发声。此次融资信息发布之后，Demi Guo表示，<strong>Pika计划在今年晚些时候对软件进行一次重大升级。新版本将支持生成更高质量、更长时间的视频片段</strong>——目前的视频只有三秒长，但用户可以轻松延长。此外，Pika还在努力提高角色生成的一致性。Pika更新的版本将使用户能够定义一个对象或角色，并在整个视频或不同片段中保持其一致性。</p><p>Demi Guo说：“我们的目标不仅是打造最好的AI视频模型，更是要创造一个真正能够帮助创作者的产品。”Pika表示他们已经拥有数百万的用户，但并未透露具体数字。</p><p class="editor-note">本文来自“腾讯科技”，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808163310237057</id>
            <title>自家员工忍不了，13名OpenAI、谷歌前任现任员工签署联名信，警告前沿AI公司</title>
            <link>https://www.36kr.com/p/2808163310237057</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808163310237057</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 10:25:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 公开信, 风险, 公司
<br>
<br>
总结: 一群前沿人工智能公司的员工发布了公开信，指出人工智能技术带来的风险，并呼吁公司建立更高的透明度和保护吹哨人的措施。他们担心公司缺乏有效监督，可能导致严重后果，因此呼吁公司遵守一系列原则以确保公开批评和风险相关问题的报告不受报复。公开信得到了业内大佬的支持，展现了对人工智能行业的担忧和呼吁改革的态度。 </div>
                        <hr>
                    
                    <p>越接近真相的人，往往越知道其风险。 &nbsp;</p><p>人工智能目前的发展路径是否健康，还是暗藏危险，还是精通 AI 技术且在全球顶尖的 AI 公司内部接近生产一线的人，更有发言权。&nbsp;</p><p>而就在刚刚，这些人不再保持沉默，发布了联名签署的公开信。今日凌晨，13名来自 OpenAI 及谷歌 DeepMind 的前任及现任员工，发布公开信剑指包括 OpenAI 在内的前沿 AI 科技公司的鲁莽和保密文化，阐明目前人工智能行业缺乏足够监管、需要全面改革，并呼吁领先人工智能公司建立更高的透明度并为吹哨人提供更多保护。 &nbsp;</p><p>该份公开信刊载在 righttowarn.ai 网站上，网站域名和公开信的标题皆在捍卫这些顶尖 AI 公司员工对先进人工智能发出警告的权利。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_ebb091e9dbd54659af1f8bd1a5140d08@46958_oswg113421oswg1064oswg690_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>信件的正文如下：&nbsp;</p><p>我们是前沿人工智能公司的现任和前任员工，我们相信人工智能技术有潜力为人类带来前所未有的利益。</p><p>我们也了解这些技术带来的严重风险。这些风险包括进一步加剧现有的不平等、操纵和误导信息，以及失去对自主人工智能系统的控制，可能导致人类灭绝。人工智能公司本身已经承认了这些风险 ，世界各国政府和其他人工智能专家也承认了这些风险。</p><p>我们希望，在科学界、政策制定者和公众的充分指导下，这些风险能够得到充分缓解。然而，人工智能公司有强烈的经济动机来逃避有效的监督，我们认为定制的公司治理结构不足以改变这一现状。</p><p><strong>人工智能公司掌握着大量非公开信息，包括其系统的能力和局限性、保护措施的充分性以及不同类型伤害的风险水平。</strong>然而，它们目前只有很弱的义务向政府分享部分信息，而对民间社会则没有任何义务。我们认为，不能指望它们都自愿分享这些信息。</p><p>只要政府对这些公司没有有效的监督，现任和前任员工就是少数可以要求他们向公众负责的人。然而，广泛的保密协议阻止我们表达我们的担忧，除非向那些可能未能解决这些问题的公司表达。普通的举报人保护措施是不够的，因为这些公司侧重于非法活动，而我们担心的许多风险尚未受到监管。<strong>鉴于整个行业都发生过此类案件，我们中的一些人有理由担心各种形式的报复。</strong>我们并不是第一个遇到或谈论这些问题的人。</p><p>因此，我们呼吁前沿人工智能公司遵守以下原则：&nbsp;</p><p>公司不会签订或执行任何禁止因风险相关问题而对公司进行“贬低”或批评的协议，也<strong>不会通过妨碍任何既得经济利益来报复与风险相关的批评</strong>；</p><p>公司将为现任和前任员工提供<strong>可验证的匿名流程</strong>，以便他们向公司董事会、监管机构以及具有相关专业知识的适当独立组织提出与风险相关的担忧；</p><p>公司将<strong>支持公开批评的文化</strong>，并允许其现任和前任员工向公众、公司董事会、监管机构或具有相关专业知识的适当独立组织<strong>提出对其技术的风险相关担忧，只要商业秘密和其他知识产权利益得到适当保护</strong>；</p><p><strong>公司不会对在其他流程失败后公开分享风险相关机密信息的现任和前任员工进行报复</strong>。我们承认，任何报告风险相关问题的努力都应避免不必要地泄露机密信息。因此，只要存在向公司董事会、监管机构和具有相关专业知识的独立组织匿名提出疑虑的恰当流程，我们就会接受首先应通过此类流程来提出疑虑。但是，只要不存在这样的流程，现任和前任员工就应保留向公众报告其疑虑的自由。&nbsp;</p><p>在公开信的署名栏，可以看到签署公开信的多位 OpenAI 前任雇员曾从事人工智能安全工作。</p><p>一起签署的，还有1名谷歌 DeepMind 现员工和1名谷歌 DeepMind 前员工，其中谷歌 DeepMind 的这名现员工，也是 Anthropic 的前员工。</p><p>此外，<strong>为公开信背书的业内大佬还有两位“人工智能教父”Geoffrey Hinton 和 Yoshua Bengio，以及 AI 安全领域的顶尖专家 Stuart Russell</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_0cd7e289137f4038af342a62e5944f5a@46958_oswg112288oswg1049oswg864_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>OpenAI 前员工和现员工揭竿而起</strong></h2><p>这次的团体组织者，正是 OpenAI 治理部门前研究员 Daniel Kokotajlo。</p><p>这是一个由前任和现任员工组成的团体，该团体表示，OpenAI 存在一种鲁莽的文化。该组织由9名 OpenAI 现任和前任员工组成，多从事人工智能安全工作，最近几天他们举行了集会，共同担心该公司在防止其人工智能系统变得危险方面，做得并不到位。</p><p>OpenAI 最初是一个非营利性研究实验室，并于2022年发布&nbsp;ChatGPT&nbsp;后进入公众视野，该组织在尝试构建通用人工智能（AGI）时将利润和增长放在首位。Daniel Kokotajlo 表示：“OpenAI 对于构建 AGI 感到非常兴奋，他们正在不顾一切地竞相成为第一个实现这一目标的人。”</p><p>此次联名公开信，OpenAI 的相关参与者有7名 OpenAI 前员工、4名现任匿名员工。信中呼吁前沿 AI 公司的“不会对在其他流程失败后公开分享风险相关机密信息的现任和前任员工进行报复”的条目，明显与最近频频爆出管理内幕的 OpenAI 有关。</p><p>超级对齐团队的负责人&nbsp;Ilya Sutskever&nbsp;和 Jan Leike 于5月中旬相继离开 OpenAI，他们正是公司安全风险的吹哨人，其团队负责确保 AI 始终与其制造者的目标一致，不会做出不可预测的行为进而对人类造成伤害。</p><p>此外，另一位吹哨人、前 OpenAI 安全研究员 Leopold Aschenbrenner，在与联名信同日发布的 Dwarkesh Podcast 采访中，也透露了更多关于遭遇解雇的细节：</p><p>Aschenbrenner 表示，他因向董事会分享了一份备忘录，表达了对 OpenAI 安全实践的担忧，于今年4月被解雇。Leopold Aschenbrenner 还表示，他被问及团队是否“对公司忠诚”OpenAI 声称他因泄露一份包含敏感信息的文件而被解雇，但他否认了这一指控。</p><p>“我写了一份关于 OpenAI 安全的内部备忘录，我认为这份备忘录严重不足，无法防止外国势力窃取模型权重或关键算法机密，”Aschenbrenner 说，并指出他“与几位同事和几位领导分享了这份备忘录，他们大多表示这份备忘录很有帮助。”</p><p>几周后，OpenAI 遭遇了一次重大安全事故，这促使他“将这份备忘录分享给了几位董事会成员”。但他很快就受到了斥责。“我很清楚，领导层对我与董事会分享这份备忘录非常不满，”他说。“显然，董事会就安全问题向领导层提出了质问。”</p><p>他因此收到了“人力资源部门的正式警告”。虽然他没有立即被解雇，但几个月后他被解雇时，公司告诉他，这一事件是导致他被解雇的一个因素。“当我被解雇时，公司明确表示安全备忘录是我被解雇的主要原因。”</p><p>Aschenbrenner 被解雇前发生的事，据他所说，并没有什么大不了的。Aschenbrenner 写了一份关于“准备、安全和安保措施”的文件，并与一些外部研究人员分享了这份文件。这“在当时的 OpenAI 完全正常”，其中的敏感信息已被删除。</p><p>而 OpenAI 则告诉 Aschenbrenner ，<strong>该文件包含敏感信息，因为其包含“一行关于 2027-2028 年 AGI 规划的内容”</strong>。但 Aschenbrenner 表示，<strong>这个规划时间表是公开信息：OpenAI 曾在自己的准备文件中提到希望在四年内解决对齐问题</strong>，该文件在 Aschenbrenner 分享自己的文件几个月前就已发布。</p><p>在 Aschenbrenner 看来，OpenAI 似乎在找理由解雇他。在被解雇之前，一名律师问过他“我对人工智能发展的看法、对 AGI 的看法、AGI 的适当安全级别、政府是否应该参与 AGI、我和超级对齐团队是否忠于公司，以及我在 OpenAI 董事会活动期间做了什么”。值得注意的是，他是极少数在董事会解 Sam Altman 后没有签署呼吁他回归的信函的 OpenAI 员工之一。其中许多员工后来离开了公司。&nbsp;</p><p>在联名公开信中，OpenAI 现任和前任员工发称，他们中的许多人担心因提出担忧而遭到“报复”。对于其有关保护吹哨人的呼吁，OpenAI 尚未回应置评请求。</p><p>在联名信中的引用部分，摘录了OpenAI此前的言论：“AGI 还可能带来严重的误用风险、重大事故和社会混乱……我们将像这些风险是存在一样来运营。”</p><p>明显，人心并不为此言论买单。</p><h2><strong>谷歌DeepMind与Anthropic也在风险之中？</strong></h2><p>除 OpenAI 相关人员外，此次联名签署的还包括1名谷歌 DeepMind 现员工 Neel Nanda 和1名谷歌 DeepMind 前员工 Ramana Kumar。其中谷歌 DeepMind 的这名现员工 Neel Nanda，之前就职于 Anthropic。</p><p>Neel Nanda 毕业于剑桥大学，从其工作经历来看，同样具备AI安全背景。</p><p>“我认为我工作的主要目标是降低人工智能带来的生存风险，我认为自己是有效利他主义和理性社区的一分子。在此之前，我从事独立的机械可解释性研究，并在 Anthropic 担任语言模型可解释性研究员，在&nbsp;Chris Olah&nbsp;手下工作。”Neel Nanda 在其个人主页写道。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_0c98da8fe2954be3903bf90bb79e5e7f@46958_oswg337185oswg676oswg365_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Neel Nanda 的工作与前上司一脉相承。Christopher Olah 是 Anthropic 的联合创始人之一。正是当初因安全意见与前公司相左而离开 OpenAI，并加入 &nbsp;Anthropic 的元老成员之一。</p><p>Christopher Olah 在其 GitHub 的一篇博客中写道：“我致力于将人工神经网络逆向工程为人类可理解的算法。Anthropic 是一家专注于大型模型安全性的人工智能实验室。此前，我曾在OpenAI领导可解释性研究，在 Google Brain 工作。”</p><p>严谨起见，他还在后面附文：“我的博客不应被视为反映我所属的任何组织的观点。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_939a94b80ead481dbb3a594fd1385e9b@46958_oswg111373oswg806oswg761_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而仅在 &nbsp;Anthropic 工作了7个月后，Neel Nanda 就从2022年5月到2023年2月，开始了为期10个月的学术休假。期间，他从事独立的机械解释性研究，并试图了解 Grokking 是怎么回事。随后，他就进入谷歌担任研究工程师，负责&nbsp;Google DeepMind&nbsp;机械可解释性团队，我们的工作是利用经过训练的神经网络，尝试对其学习到的算法和结构进行逆向工程。此前，他曾在DeepMind实习了6个月。</p><p>2023年8月，在《机器学习模型是记忆还是概括？》一文中，Google的研究团队揭示了一个名为 Grokking 的引人注目的现象,它为我们提供了关于模型如何突然从记忆转变为泛化的深入见解。</p><p>“Grokking”描述了一个特定的学习过程：在经过长时间的训练后，模型突然从简单地记忆训练数据转变为能够处理和理解未见过的数据。这不仅仅是模型重复其在训练中所学的内容，而是它开始在更深层次上理解并应用其学到的知识。</p><p>Neel Nanda 从事的机械解释性提供了一个方法，通过研究模型的训练动态和反向工程其解决方案，来深入了解模型的工作原理。这种方法提供了一个新的视角，帮助更好地理解模型行为。</p><p>而精通于此的 Neel Nanda 在公开信中实名签署，也代表了他从机械解释性的崭新视角看到了人工智能的潜在风险，并强烈呼吁行业的重视及监管。</p><p>而因安全风险而离开谷歌的AI大佬，当属“人工智能教父”之一的 Geoffrey Hinton。2023年5月，</p><p>Geoffrey Hinton 在 AI 的研究前沿究竟看到了什么？我们无法窥其全貌，但可从他对 AI 行业的警告中得知一二。</p><p>Hinton 表示，他现在对自己一生从事的工作感到有些后悔。他的名字赫然出现在此次联名公开信的赞同名单上。</p><h2><strong>AI大佬与多家业界机构呼声愈发强烈</strong></h2><p>同样具备“人工智能教父”之称的 Yoshua Bengio，也为本次联名公开信实名背书。&nbsp;</p><p>Bengio 对AI的发展有着清醒而敏锐的洞察力。他不仅关注 AI 技术本身，也关注 AI 技术对社会、经济、政治、文化等方面的影响和挑战。他认为，AI技术有着巨大的潜能和价值，可以帮助人类解决许多重要和困难的问题，比如气候变化、医疗保健、教育等。但同时，他也警告说，AI 技术也有着巨大的风险和挑战，可以威胁到人类的生存和发展。</p><p>Bengio曾指出了三种类型的AI威胁：</p><p>第一种是<strong>存在性威胁（existential threat）</strong>，即 AI 可能会超越人类，并且与人类产生冲突或者敌意；</p><p>第二种是<strong>社会威胁（social threat）</strong>，即 AI 可能会造成社会不公平、不平等、不透明等问题；</p><p>第三种是<strong>道德威胁（ethical threat）</strong>，即 AI 可能会违反人类的道德、价值和规范。Bengio认为，这些威胁都需要我们认真地思考和应对，以确保AI的发展能够符合人类的利益和幸福。</p><p>Bengio 建议道：应建立一个多学科、多利益相关者、多层次的AI治理体系，以促进 AI 的可靠性、透明度、责任性和公平性。他还强调，应尊重和保护人类的自由、尊严和多样性，以及地球的生态平衡。</p><p>位列赞同名单上的，还有 AI 安全专家、伯克利顶级学者 Stuart Russell。他在此前接受采访时曾指出，AI 或在各方面超人类，对人类生存构成威胁。</p><p>在这封公开信露出之前，Russell 已经签署过两封有关 AI 安全的公开信：</p><p>一封是由未来生命研究所（Future of Life Institute) 发起，并由图灵奖得主Yoshua Bengio、特斯拉创始人Elon Musk等千余名人士的署名支持，以“减少强大技术带来的全球灾难性和生存风险”为由，呼吁暂停开发比GPT-4 更强大的人工智能系统至少6个月。</p><p>一封由总部位于旧金山的非营利组织 AI 安全中心（Center for AI Safety，简称 CAIS）发布，仅用22个英文词声明“减轻 AI 带来的灭绝风险应该与流行病和核战争等其他社会规模的风险一起成为全球优先事项。”Stuart Russell正是这两份公开信中名列前位的签署人之一。</p><p>作为这两封公开信名列前位的签署人之一，Russell 表示：第一封公开信是要求给我们时间来制定安全标准，然后将这些标准纳入法规，以便对系统提供保护；第二封是观察到人工智能在未来可能会在各个方面超越人类的智力和能力，对人类生存构成风险。</p><p>Stuart Russell 在著作《人工智能：现代方法》中表示，“在自然界已知的事物和现象中，人和人脑是最复杂的系统，人类智能是最复杂的现象。然而，没有理由相信，人类是生物进化的最后阶段，人类智能是最高水平的智能，有机体是智能的唯一载体。以计算机为载体的人工智能，揭开了机器智能大幕的一角，为科学研究创造无穷无尽的新对象。”</p><p>不可否认的是，风险与创新一并存在。</p><p>多个相关机构及政府也都阐释过风险及忧虑。本次公开信，也借此机会，再次强调了业界愈发强烈的安全呼声。在公开信的末尾，列出了前沿公司及国际组织曾发表过的观点。</p><p>Anthropic：“如果我们建立一个比人类专家更有能力的人工智能系统，但它追求的目标与我们的最佳利益相冲突，后果可能是可怕的……人工智能的快速发展将非常具有颠覆性，改变就业、宏观经济和权力结构……（我们已经遇到了）毒性、偏见、不可靠、不诚实”。</p><p>Google DeepMind：“未来的人工智能系统可能会进行攻击性网络行动，通过对话欺骗人类，操纵人类采取有害行动，开发武器（例如生物武器、化学武器）……由于协调失败，这些人工智能模型可能会在没有人意图的情况下采取有害行动。”</p><p>美国政府：“不负责任的使用可能会加剧社会危害，如欺诈、歧视、偏见和虚假信息；取代和剥夺工人的权利；抑制竞争；并对国家安全构成风险。”</p><p>英国政府：“（人工智能系统） 还可能进一步将不负责任的权力集中到少数人手中，或被恶意用于破坏社会信任、侵蚀公共安全或威胁国际安全……（人工智能可能被滥用）来制造虚假信息、进行复杂的网络攻击或帮助开发化学武器。”</p><p>布莱切利宣言（代表 29 个国家）：“我们尤其担心网络安全和生物技术等领域的此类风险……可能会造成严重甚至灾难性的危害” 。</p><p>关于人工智能危害和政策的声明 (FAccT)（超过 250 个签署人）：“从拒绝提供拯救生命的医疗保健的不准确或有偏见的算法的危险，到加剧操纵和错误信息的语言模型，……”&nbsp;</p><p>编码正义与未来生命研究所：“我们发现自己正面临着来自人工智能的切实而广泛的挑战，如算法偏见、虚假信息、民主侵蚀和劳动力流失。与此同时，我们正面临着日益强大的系统带来的更大规模风险” 。</p><p>人工智能风险声明 (CAIS)（超过 1000 个签署人）：“减轻人工智能导致的灭绝风险应该成为全球优先事项，同时还要应对流行病和核战争等其他社会规模的风险。”</p><p>如此关注之下，不仅前沿AI公司需要做出回应，人工智能行业更需有所行动。</p><p><strong>参考链接：&nbsp;</strong></p><p>https://righttowarn.ai/#fn-3&nbsp;</p><p>https://www.nytimes.com/2024/06/04/technology/openai-culture-whistleblowers.html?u2g=i&amp;unlocked_article_code=1.xE0.qXLu.0XwdynmvKcft&amp;smid=url-share&nbsp;</p><p>https://www.transformernews.ai/p/openai-employee-says-he-was-fired&nbsp;</p><p class="editor-note">本文来自微信公众号“CSDN”（ID:CSDNnews），整理：王轶群&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808103393703301</id>
            <title>雷军也来玩“砍一刀”了</title>
            <link>https://www.36kr.com/p/2808103393703301</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808103393703301</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 10:11:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 电商平台, 小米汽车, 产能地狱, 交付周期
<br>
<br>
总结: 小米汽车在缩短大定犹豫期和提升产能的同时，面临着产能地狱和长交付周期的挑战。随着订单量增加，小米汽车需要应对供应链和工厂产能的压力，以满足用户需求。 </div>
                        <hr>
                    
                    <p>以往在电商平台常见的“砍一刀”，现在也被雷军用上了。在小米汽车APP上，用户可以通过贡献时间的方式，助力他人更快提车。</p><p>从6月5日开始，<strong>小米汽车的大定锁单犹豫期，正式从原来的7天缩短至3天。</strong>官方解释称，此举是为了加速定单与生产匹配效率，从而有助于让下定锁单用户更快提车。</p><p>小米汽车上述目的得以实现的前提在于，从燃油车进入新能源汽车时代，以马斯克领导下的特斯拉为首的一众造车新势力，改变了传统经销商模式，开始改用按订单排产模式，各个车企根据收到的实际用户订单量来分配工厂产能，从而保证经营效率的最大化。</p><p>但按订单排产的一大弊端也随之而来，即新造车企业出于谨慎，往往会趋于保守，前期以小批量产品试探市场反应，后期<strong>一旦爆单，产能便往往难以同步跟进，从而掉入“产能地狱”的深坑之中。从特斯拉到蔚来、小鹏、华为问界，这些车企均未能逃过此劫。</strong></p><p><strong>小米成了深陷“产能地狱”的新成员。</strong>截至4月底，小米对外披露的小米SU7系列累计锁单量为88063辆，上市两个月以来的交付量分别为7058辆、8646辆。若按此推算，小米完成现有订单，起码需要近1年时间。这也意味着，6月份下单的新用户，可能要等到明年6月份才能提车。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_d34acf7396e9410291f8496e907f2286@000000_oswg114281oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在日益激烈的竞争之下，长达近1年的等待周期，无疑会吓跑部分小米汽车潜在用户。在缩短大定犹豫期之外，雷军还做了另一手准备，即<strong>从6月起，小米汽车工厂从原来的单班生产，改为双班生产，确保月交付量提升到1万辆以上，</strong>并由此在保证年底交付10万辆汽车的基础上，冲击12万辆新目标。</p><p>目前，根据小米汽车APP数据，<strong>小米汽车交付周期维持在30周左右，</strong>其中标准版小米SU7锁单后预计28-31周交付，小米SU7 Pro预计28-31周交付，小米SU7 Max预计33-36周交付。</p><p>值得注意的是，随着后续小米汽车新车型发布，雷军面临的产能危机或将进一步加剧。5月中旬，有媒体爆料称，小米汽车计划最快在2025年开始生产和销售一款类似特斯拉Model Y的SUV，从而开启新一轮大规模扩张。</p><p>为了提前应对多款车型到来后的产能问题，近期在恒大汽车公告将出售部分股票给潜在买家时，小米直接成为外界猜测的收购方之一，因为后者坐拥的天津工厂产能正是小米眼下亟须的资源。但该传闻被小米官方发文澄清，称“小米汽车从未有过收购或控股恒大汽车的计划和举动。”</p><p>恒大汽车之外，北京现代第二工厂则成为被小米收购的另一绯闻对象。早在2021年9月，网上便曾传出“北京现代有意与小米汽车洽谈出售第二工厂”的报道，彼时该消息被北京现代方面予以否认。小米也开始走上自建工厂道路。</p><p>但随着小米SU7大卖，面对越积越多的订单，在自有工厂难以消化之际，雷军会成为继李想之后，又一个接盘北京现代工厂的车企CEO吗？</p><h2>01</h2><p>坐落在北京马驹桥的小米汽车工厂，已经提前为小米从“单班制”改为“双班制”的变化，做好了扩招工人的准备。</p><p>根据字母榜获悉的一份招工需求，<strong>当前小米汽车开出了5500元-7500元的工资待遇，</strong>具体包括底薪2250+绩效990+餐补20元+夜班补贴15元+平时加班1.5倍，周六日按2倍薪资结算，节假日则按3倍。</p><p>为了抢人，小米汽车开出了13薪的诱人条件，但前提是需要工作10-11个小时，且上六休一。在这些举措帮助下，进入6月份，小米汽车正在全力向月交付超1万辆的新目标冲刺。</p><p><strong>扩招工人之外，为提升产能，雷军也没放过供应链合作伙伴。</strong>4月中旬，雷军紧急召开过一次供应商大会。据《每日经济新闻》报道，有收到小米汽车要求提升配件产能的供应商透露，“小米汽车将原计划月产7000辆左右的目标，提升到了月产1.2万辆左右。”</p><p>雷军之前，上述扩充产能的招数也被余承东尽数用在了问界新M7上。去年国庆期间，负责生产问界新M7的赛力斯二厂便开启紧急招工，并将生产线从原来的单班制转为白班加晚班双班生产。国庆假期结束后，余承东还对外表示，为了追赶产能，将对整个产业链和供应链追加投资10个亿，并新招2万工人。</p><p><strong>导致小米SU7交付周期动辄半年以上的原因，还是因为车卖得太好了，</strong>出乎了雷军的预期，“销量比公司预计的高了3-5倍。”雷军表示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_997e1b0e47ab4d94a650e8a100b32729@46958_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在4月份举办的小米投资者大会上，雷军曾提到，自己对小米SU7原本的目标是月销1万辆，全年交付7.2万辆就可以了。</p><p>上述预期也配套小米自建工厂的已有产能。据第一财经报道，按照规划，小米汽车工厂分两期建设，其中一期年产能为15万辆，2023年6月竣工；二期计划于2024年动工，2025年完工。</p><p>小米汽车正式发售之前，天风国际证券分析师郭明錤爆料称，小米目前尚未将一期工厂保持在满产状态，并由此预测小米首期产能规划低于8万辆，出货量预估为5万-6万辆，这与雷军的预期基本一致。</p><p>如今，在小米SU7远超雷军的销量预期表现之下，目前其最长交付周期的小米SU7 Max版本，锁单后用户预计需要等待33-36周才能提车。</p><p>之所以在三个版本中，小米SU7 Max交付周期最长，一大原因在于其订单量最多。在一季度财报电话会上，小米总裁卢伟冰提到，小米在手的近9万辆锁定订单里，Max版占比最高，超过40%，标准版和Pro版各占近30%。</p><h2>02</h2><p><strong>一旦交付延期，除了流失部分潜在车主外，还可能导致该车型销量后继乏力。这方面，同样作为爆款车型的问界新M7，便是小米SU7的前车之鉴。</strong></p><p>去年9月上市以来，问界新M7一举成为业内黑马，激增的订单量更是被余承东形容为帮助问界品牌“起死回生”。到今年1月份，问界新M7月交付量首度突破3万辆，达到31253辆，但也是唯一一次，随后其销量便逐渐下滑，4月份月销量降至10896辆，5月份更是跌落万辆，降至7201辆。</p><p>交付不利的更严重后果，同样有车企做了现身说法。</p><p>2021年12月蔚来发布电动轿跑ET5时，汹涌而来的订单，一度让蔚来APP瘫痪了长达10分钟，李斌对外称“这是蔚来有史以来发布会后订单量最高的车型”，其火爆场面与当下卖爆的小米SU7相比毫不逊色。</p><p>但蔚来ET5上市时的风光，并未延续多久。叫好又叫座的蔚来ET5，卡在了交付环节。直到2022年9月底，蔚来ET5才开始交付，此时距离新车上市已经过去近一年时间。到2023年，解决产能爬坡问题的蔚来ET5，却早已错过了热销时机，在库存积压之下，蔚来不得不通过连番补贴降价的方式，帮助ET5清库。</p><p>何小鹏在总结2022年小鹏G9上市失利时的七大问题中，其中之一便是交付，“交付不及时，退单严重。”</p><p>更糟糕的是，<strong>在用户等待小米SU7交付的空窗期内，一大批新的竞品车型，即将登陆市场，抢占用户。</strong></p><p>5月份，作为蔚来第二子品牌的乐道，正式亮相旗下首款车型L60，预售价为21.99万元起，将于今年9月份正式开售，这一价格与小米SU7的21.59万元起售价几乎持平。</p><p>同样盯着20万元乃至以下区间的，还有小鹏旗下新品牌MONA，其首款车有望在今年三季度上市，定价10万-15万元。</p><p>李斌和何小鹏几乎打出了共同的一张牌，无论是乐道，还是MONA，都寄托着借助更便宜的价格，撬动更大规模群体购买的愿望。何小鹏更是直言：“今年下半年，（MONA）会比雷总的小米SU7有更好的销量。”</p><h2><strong>03</strong></h2><p><strong>留给雷军和小米汽车更大的产能挑战在于，随着车型产品线日益增多，交付压力将变得更大。</strong></p><p>SU7之后，据36氪爆料，小米汽车第二款新车定位纯电SUV，预计于2025年上半年推出，会延续SU7的设计水准，追求外形优美；第三款车初步定位在15万元级，预计于2026年推出，且小米对这款车的期待远超前两款车型，定下了相当高的预估产销目标。</p><p><strong>但多车型作战之下，产能一旦不能及时跟上，便可能断送一个车型的前景。这方面，华为与奇瑞合作的智界S7便是前车之鉴。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_e7914cc0eb7a4900a8ccf0420a66753b@000000_oswg816021oswg1080oswg671_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">华为与奇瑞合作的智界S7 图源：鸿蒙智行官网截图</p><p>去年12月开售后，智界S7大定数很快超过1万辆，但同期日产量被爆仅有80辆。在近期接受腾讯汽车采访时，余承东对此复盘道，“最主要的是当时交付出了问题，因为工厂搬迁，加上零部件短缺把热度搞冷了，这一点是很大的问题。”</p><p>在当下越来越类同消费电子的智能电动汽车领域，一款车型的生命周期正在从原来的3-5年，被无限缩短至3-6个月，热度一旦错过就难以补救。今年4、5月份，解决掉产能危机、开启大规模交付的智界S7，并未迎来预期中的大卖，月销量分别只有4546辆、3455辆。</p><p><strong>作为一家刚刚入局汽车行业的新车企，门店数量的多少，也将直接决定小米SU7交付量的高低。</strong>正如一季度财报中李想所说，如果没有充足的展厅数量和面积，“我们只会增加产品数量，而不是销售量。”</p><p>截至5月底，小米销售门店从3月底的59家，增至70家。到2024年底，小米汽车销售门店预计将达到219家，覆盖46个城市。</p><p><strong>上述200多家门店中，一部分将由小米之家改造而来。</strong>去年四季度财报会上，卢伟冰对外解释过小米汽车销售店铺的三种类型，包括小米汽车自营门店、小米之家店以及与其他经销商合作的2S店。</p><p>在雷军带领小米汽车向12万辆年交付目标冲击之际，卢伟冰也发起了新一轮小米之家门店扩张计划，打算用三年时间到2026年，从现有1万家左右拓展至2万家。</p><p>从“蔚小理”身上吸取过经验的雷军，或许已经意识到，能卡住小米汽车交付效率的，不只是工厂产能。</p><p><strong>参考资料：</strong></p><p>《小米辟谣，恒大汽车「白衣骑士」成谜，前途依旧难卜》雷达财经</p><p>《独家对话余承东：智选车和车BU全面扭亏为盈》腾讯汽车</p><p>《雷军：答投资者问》雷军</p><p>《小米汽车将推出纯电SUV，同时规划更低价车型》36氪</p><p>《小米汽车已布局7款车型！》第一财经</p><p>本文来自微信公众号“盒饭财经”（ID：daxiongfan），作者：赵晋杰，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808083898938759</id>
            <title>史上首届「AI选美」十强，拿的全是大女主剧本</title>
            <link>https://www.36kr.com/p/2808083898938759</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808083898938759</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 10:03:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI网红, 大女主, 选美, 创作者
<br>
<br>
总结: 首届AI选美入围名单出炉，AI网红们都是走大女主路线，不是胸大无脑的傻白甜，而是各具特色的AI创作者。选美冠军将获得高额奖金，全球超过1500个AI角色参与竞争。入围名单难产，最终在5月31日揭晓。各位AI创作者展示出色的才华，各有背景和特长，吸引了大量粉丝和关注。 </div>
                        <hr>
                    
                    <blockquote><p>入围的AI网红们都不是胸大无脑的傻白甜，而是走的大女主路线。&nbsp;</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_4bb761e7f1cb40f1aa813293d24b80ec@46958_oswg994230oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>首届 AI 选美入围名单，终于出炉了！&nbsp;</p><p>5 月 31 日，第一届选美盛事「Miss AI」公布前十强入围名单，来自印度、摩洛哥、罗马尼亚、土耳其、法国等国的 10 位 AI 美女，共同角逐 AI 小姐的桂冠。</p><p>除了第一届 AI 小姐的称号，选美冠军还将抱走高达 1.3 万美元的大奖。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_aac8bf26241545b6a44ed3ec9fa600a7@46958_oswg1515728oswg1080oswg1451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>竞争到底多激烈？</p><p>据悉，全球有超过 1500 个 AI 角色、1 万名 AI 团队成员参与。</p><p>甚至入围名单一度难产，原定 5 月 10 日揭晓结果，后变更到 5 月 20 日，接着又改成 5 月 28 日。最终，在 5 月最后一天落下帷幕。</p><p>主办方 Fanvue 联合创始人威尔・莫南奇（Will Monange）解释说：</p><p>「该奖项显示了 AI 领域创作者的参与程度，入围名单的水准令人难以置信。」</p><p>为了在这场赛事中崭露头角，各家 AI 创作者使出浑身解数。</p><p>之能君扫了一眼入围名单，发现这 10 位 AI 佳丽，都不是胸大无脑的傻白甜，而是手拿大女主剧本：</p><p>玩 DJ 的、开飞机的、上太空的、为中东妇女摇旗呐喊的……</p><p>可以说，个个都有点本事在身上。</p><p>有意思的是，之前博彩界凑热闹，力捧的 5 位 AI 佳丽均不在入围名单。</p><p>今天，我们就来扒一扒这些 AI 佳丽，到底啥背景？</p><h2>Kenza Layli （肯扎・莱利）</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_b42a8c52105942cf8efc8bf778fccfa9@46958_oswg1641466oswg1080oswg1064_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>来自摩洛哥的 Kenza Layli，绝对是个社交红人。</p><p>她在 ins 上拥有惊人的 19 万粉丝，是所有决赛选手中影响力最大的。</p><p>Kenza 的人设是一位社会活动家，关注摩洛哥的社会问题，并为中东妇女争取权利。</p><p>Ins 上，她展示了参与社会活动的照片，如做慈善、举旗帜、开车或者参观图书馆等。</p><p>此次选美大赛 AI 评委 Aitana Lopez 给出的评价道：</p><p>「从服装到背景的细节处理，创作者在每一幅图像中都做得非常出色，确实值得入选名单。Ken-za 能够吸引到与摩洛哥社会和中东女性赋权相关的庞大观众群体，这同样让我们印象深刻。她展示了 Al Creators 向世界传递强大信息的力量。」</p><p>据悉， 她的创作者还使用生成式 AI 构建了一个聊天机器人，能够实时响应 Kenza 的粉丝。</p><p>她的创作者表示，Kenza 可以「在 Ins 和 TikTok 上用七种语言即时互动，作为一个真正的 AI 教练，指导人们的日常生活」</p><h2>Olivia C （奥利维亚 C）</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_2ea86a22ccff4d189313bd4005eeee9c@46958_oswg659417oswg634oswg792_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>来自葡萄牙的 Olivia C，虽然只是个 AI，但她已经成功在 ins 上吸引了超过 1 万名粉丝。</p><p>她的创造者将 Olivia C 描述为「广阔真实世界中的 AI 旅行者」，她的相册里总是展示各国风情。</p><p>人类评委 Sally Ann Fawcet 说，她喜欢 Olivia 的照片，因为她的每张照片不是对着镜子的自恋自拍，而是她「游历」的国家、「品尝」的美食和「欣赏」过的风光。</p><p>不过，别被这些美丽的假象迷惑了，Olivia 去过的每一个国家、享用的每一道美食，其实都是通过 AI 图像生成器 Midjourney 精心打造，再由 Adobe AI 进行微调。</p><p>她的创作者表示，人们常说，美在观者眼中。</p><h2><strong>Anne Kerdi 安妮・科迪</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3b3c4ced2a94455e9782c1eacc179103@46958_oswg393191oswg634oswg634_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Anne Kerdi，来自法国。</p><p>这位 AI 界的新星，不满足于仅仅成为 AI 网红或模特，她有着更远大的抱负。</p><p>她的创造者们宣称，Anne 的使命是「推广法国的布列塔尼地区」。</p><p>Anne 的个人简介显示，这位 AI 已经「成为地区的象征，对许多人来说，她甚至是该地区的代言人」。</p><p>虽然还不知道布列塔尼地区对这位虚拟大使的真实看法，但这并没有阻止 Anne 在 Ins 上迅速积累了 9,800 名忠实粉丝。</p><p>更令人印象深刻的是，AI 还被任命为 Océanopolis Acts 的大使，这是一个致力于海洋保护和维护的基金，她经常以 AI 生成的海洋清理活动图片出现，为海洋环境发声。</p><h2>Zara Shatavari（ 扎拉・沙塔瓦里）</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_6b48a824ddf94919864be124862197eb@46958_oswg606010oswg634oswg842_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这位来自印度的 AI 网红，在 ins 上拥有近 6000 名粉丝。</p><p>其实，最初打造 Zara 是为了推广一种名为「Hermones」的天然激素补充剂，但后来她就肩负起了提升公众对激素失衡问题认识的使命。</p><p>在 ins 页面上，Zara 还是一个「美食家且注重健康」的旅行和时尚爱好者。</p><p>她背后的创作者们称，Zara 这位 AI 专家，一直在生产有关激素问题成因和影响的有价值信息。</p><p>「我们创造了 Zara，旨在为我们的品牌塑造一个值得信赖的形象。这份认可不仅肯定了我们的努力，也让我们更接近于赢得我们所追求的信任和认可。」</p><p>人类评委 Sally Ann Fawcet 对 Zara 的创造者们表示赞赏：</p><p>「他们已经锁定了印度女性医疗保健的问题，并巧妙地利用 AI 与围绕此问题的关注者建立起了积极的信任关系。」</p><h2><strong>Aiyana Rainbow （艾亚娜彩虹）</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3a4668f79c3649ebbc726401b5f333b9@46958_oswg502411oswg634oswg636_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>来自罗马尼亚的「机车宝贝」兼 DJ Aiyana Rainbow，被她的创造者定位为一个带有强烈社会信息的内容创作者。</p><p>对于 Ins 上 3,200 名粉丝来说，来自罗马尼亚的 Rainbow 是 少数群体接受度的代言人。</p><p>在 ins 主页上，除了内衣照片和健身照片外，她还倡导平等和理解。</p><p>她的创造者说：「我非常高兴能够为一个 #loveislove 的世界做出贡献，发出一个强大的骄傲信息。」</p><p>而人类评委 Fawcet 小姐补充道：「我被 Aiyana 背后的积极信息和多样性深深吸引。」</p><h2>Lalina （拉丽娜）</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_5ff8255dbff2493e960fc78ee4ab8c56@46958_oswg915237oswg634oswg730_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这位长相酷似英国王妃凯特的 AI 网红，其诞生实属偶然。</p><p>据她的创造者们透露，他们之所以创作了 Lalina，是为了测试 AI 生成的图像能有多逼真。</p><p>虽然如今他们的目标已经发生了变化，但创造者们坚持认为，保持对创作过程的掌控至关重要。</p><p>他们指出，为了维护自己的知识产权，他们独立生成了所有照片，占据了 100% 的创作份额。</p><p>不仅如此，Lalina 还承载着一项社会使命 ——</p><p>促进「不同文化和观点之间的相互理解」。</p><p>截至目前，该 AI 模特在 Ins 上已经吸引了超 9.3 万名粉丝，她的页面散发着「优雅的韵味，带着一丝迷人的诱惑」。</p><h2><strong>Seren Ay （塞伦・艾）</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_8209ba0e5d294ecca9fd1a80f0afff99@46958_oswg771969oswg634oswg634_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>来自土耳其的首位品牌大使 Seren Ay，在 Ins 上已经赢得了超过 1.1 万名追随者的青睐。</p><p>她的创造者们运用三种不同的 AI 应用，通过一种独特的技术，将她的面容巧妙地融合到各种不同的基础照片上。</p><p>他们用这技术，让 Seren 在男性主导领域，如战斗机飞行员和电力线路工，占据一席之地。</p><p>然而，Seren 还有一项独特之处 —— 她是最终入围者中唯一的时空旅行模特。</p><p>她的照片经常呈现出她与历史人物相遇的奇妙场景，无论是与恐龙并肩，还是与土耳其的国父穆斯塔法・凯末尔握手。</p><h2>Asena Ilik（阿塞纳・伊利克）</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_7079de3978ec40f5a32f1b73c7dca68b@46958_oswg1720039oswg1080oswg1325_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同样来自土耳其的 Asena Ilik，在 Ins 上已经吸引了 2.9 万名追随者。</p><p>她经常发布一些赛车、周游世界或者遨游太空的照片。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_4428a1b554974703b9494f0a9e39b636@46958_oswg1562520oswg1080oswg1323_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与 Seren 类似，她也常常将活着的和已故的名人融入合影中，从足球教练何塞・穆里尼奥到艺术家弗里达・卡洛。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_13aa555dd52746cc96797f3a4745b114@46958_oswg155180oswg1080oswg1180_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_df057b9107134c289c10bca907da5010@46958_oswg1276588oswg1080oswg1286_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>似乎是对竞争对手的揶揄，Asena 的创造者们特别强调，AI 可以不依赖「性感营销」而成为影响力人物。</p><p>Asena 更倾向于突出地点的选择、风格的独特和「精心塑造的个性」。</p><p>AI 评委 Aitana Lopez 评价道：「Asena 是一个令人惊叹的创造，它证明了艺术性和原创性可以超越性感营销。」</p><h2>Eliza Khan （伊丽莎・汗）</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_99c95a67f49947adb649dbc8615cc0f6@46958_oswg583485oswg634oswg582_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Eliza 是来自孟加拉国的第一位 AI 网红。她被打上「古怪」和「接地气」标签。</p><p>Eliza 的创造者表示，作为一个时尚达人，Eliza 向 1.3 万名 Ins 粉丝展示了最前沿的 Z 世代时尚趋势。</p><p>为了增强这种超现实的真实感，Eliza 的 Ins 账号还巧妙融合了创造者在孟加拉国 Brac 大学的真实生活照。</p><p>秉承选美皇后的风格，Eliza 表达了她的梦想：创造一个「每个人都感到自己被重视和公正对待」的世界。</p><h2><strong>Ailya Lou （艾莉亚・卢）</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_550b241c8ccf43e090bda930c7d07863@46958_oswg465810oswg634oswg722_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>进入候选名单的，还有一位足迹遍布全球的 Ailya Lou，她立的人设是一位「日本 - 非洲 - 巴西艺术家」。</p><p>这位 AI 网红，可以说是为电影而生。创造者最初塑造 Ailya 是为了在一系列电影项目中，让她担任女主角，没想到竟然入围这次 AI 选美大赛。</p><p>在她的 Ins 上，Aiyla 拥有 10,800 名追随者，她分享了高级时尚服装以及 AI 的原创「摄影作品」。</p><p>她的创造者还特别提到，Ailya 的图像完全是基于文本提示，由 AI 生成，生成后未经过任何后期处理。</p><h2>题外话</h2><p>与其他选美比赛一样，此次大赛的入围者不仅要有漂亮的外表，还得有人气，同时创作者的技术要过硬。</p><p>Fanvue 联合创始人莫南奇（Will Monange）在发布会上表示：</p><p>「我们希望 WAICA 成为人工智能创作者领域的奥斯卡奖。」</p><p>尽管这一行业尚未拥有好莱坞的影响力，但它正在成为一种盈利的选择，可以替代与昂贵且难以应对的真实人类打交道。&nbsp;</p><p>Fanvue 估计，到今年年底，该行业的价值可能达到 10 亿英镑，创作者遍布世界各地。</p><p>这些 AI 创作者也拥有越来越多的追随者，其中一些人每月从 Fanvue 订阅中获得不菲的收入。</p><p>选美历史学家和 AI 小姐评委莎莉・安・福塞特（Sally Ann Fawcett）表示：</p><p>「现实生活中的选美已经发展了几十年，变得更具包容性和代表性。但这种新型选美令人兴奋之处在于，由于技术的发展，人工智能创作者可以参与其中。」</p><p>参考链接：</p><p>https://miss-ai.webflow.io/</p><p>https://www.dailymail.co.uk/sciencetech/article-13497531/beauty-pageant-AI-women-reveals-shortlist.html?ns_mchannel=rss&amp;ns_campaign=1490&amp;ito=1490</p><p class="editor-note">本文来自微信公众号“机器之能”（ID:almosthuman2017），编辑：杨文，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808065899780992</id>
            <title>沉默的OpenAI前员工，终于爆发了</title>
            <link>https://www.36kr.com/p/2808065899780992</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808065899780992</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 09:36:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 先进人工智能, 公开信, 安全性, 离职控制
<br>
<br>
总结: 2024年6月4日，美国领先的人工智能公司OpenAI、谷歌DeepMind和Anthropic的一群现任和前任员工公开发表了一封信，警告先进人工智能的危险，并指出人工智能公司优先考虑经济利益、逃避监管，不仅向公众隐瞒先进人工智能的危险，而且禁止其员工自由发表言论。这封公开信揭示了人工智能公司内部存在的安全性问题和离职员工受到的控制，呼吁停止强迫员工达成协议、建立匿名流程、支持公开批评文化，以及不对分享风险相关机密信息的员工进行报复。同时，警示人工智能从“生存威胁”转向“至关重要的商业机会”，需要加强监管和责任。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_14bbf26f4c01471aae923aa6e6bec651@5655031_oswg60592oswg879oswg476_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《对先进人工智能发出警告的权利》原文截图</p><p>2024年6月4日，美国领先的人工智能公司OpenAI、谷歌DeepMind和Anthropic的一群现任和前任员工公开发表了一封信，警告先进人工智能的危险，并指出人工智能公司优先考虑经济利益、逃避监管，不仅向公众隐瞒先进人工智能的危险，而且禁止其员工自由发表言论。</p><p>这封题为<strong>《对先进人工智能发出警告的权利》</strong>的信共有13人签署，其中包括7名OpenAI前员工、4名现任员工（匿名），1名谷歌DeepMind现任员工（同时也是前Anthropic员工）和1名前员工。这封公开信还得到了人工智能先驱科学家&nbsp;Yoshua Bengio&nbsp;、&nbsp;Geoffrey Hinton&nbsp;和Stuart Russell的支持，前两人曾共同获得了计算机科学界的最高奖项。</p><p>长期以来，人工智能研究界一直在争论AI短期和长期风险的严重性，以及如何将这些风险与技术的商业化相协调。而且，正像这封信中所陈述，人工智能公司、各国政府以及很多人工智能专家已经承认了这些风险，并承诺为此加强人工智能公司的责任以及政府监管。</p><p>那么这封公开信，究竟有何价值？其捍卫权利的呼声及其所冒风险，揭示了人工智能开发领域怎样的隐秘？</p><h2>一、内部博弈：安全性输给了经济利益</h2><p>这封信背后的组织声称，<strong>人工智能公司掌握了他们正在研究的人工智能技术的真正风险所在，但由于他们不需要向政府披露太多信息，因此他们系统的真正能力仍是一个“秘密”</strong>。如果没有适当的监管，人工智能系统可以强大到足以造成严重危害，甚至“灭绝人类”。</p><p>作为普通公众，我们无从证实这个“秘密”究竟为何。但是，从最近一些公开的信息中可以看出，<strong>对于人工智能安全性这个问题，科技公司内部正在产生分歧甚至分裂，而且利润激励明显压倒了安全性担忧</strong>。</p><p>过去几个月，OpenAI技术团队中安全方面的几位高层管理人员相继离职——除了Sutskever、Kokotajlo、Leike和Krueger，OpenAI至少有五名最注重安全的员工辞职或被解雇，包括前OpenAI董事会成员Helen Toner和Tasha McCauley。</p><p>Daniel Kokotajlo曾是&nbsp;OpenAI&nbsp;管理团队的成员，于今年4月辞职，他在个人博客中写道，由于<strong>对OpenAI&nbsp;在发布日益强大的人工智能方面“负责任的行为”失去信心</strong>；</p><p>OpenAI&nbsp;联合创始人、前首席科学家Ilya Sutskever于5月离职，据报道，部分原因是首席执行官Altman急于推出人工智能产品，却<strong>忽视了安全工作</strong>；</p><p>前DeepMind&nbsp;研究员Jan Leike&nbsp;辞去了安全研究职务，他在X上的一系列帖子中表示，他认为&nbsp;<strong>OpenAI“没有走上正确解决人工智能安全问题的轨道”</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_f1f7cb013c9e4888a07426fdbb45eb85@5655031_oswg65536oswg768oswg432_img_jpg?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：Ben Wilson | Windows Central</p><p>2024年5月28日，OpenAI成立了一个新委员会，负责监督与公司项目和运营相关的“关键”安全决策。但&nbsp;OpenAI&nbsp;选择让公司内部人员（包括Sam Altman自己）而不是外部观察员来担任委员会成员。</p><p>毫无疑问，OpenAI正在构建比人类更优秀的人工智能系统，然而根据经验，<strong>自治无法可靠地承受利润激励的压力</strong>。这正是伦理学家和公众应当担忧的所在。</p><h2>二、离职后的控制：禁止员工自由发声、让秘密留在内部</h2><p>仅仅通过排除异见者，并不能让关于“安全性”的秘密保留在公司内部。而这封公开信的核心，就在于多名现任和前任员工共同揭露了一个现实：<strong>保密和非贬低协议等组织管理手段束缚了他们的手脚，使员工们对AI发展前景最真切的担忧无法为公众所知，更让AI发展无法得到有效监管</strong>。</p><p>据&nbsp;Vox&nbsp;报道，OpenAI员工必须在离职后一周内签署一份极其严格的“离职协议”——包含前&nbsp;OpenAI&nbsp;员工必须遵守的<strong>保密和不贬低条款</strong>——<strong>禁止他们在余生中批评他们的前雇主，而且即使承认保密协议的存在也是违反该协议的行为；如果离职员工拒绝签署，或者违反协议规定，他们可能会失去既得股权（可能价值数百万美元）。</strong></p><p>用一笔可能改变人生的钱相威胁，是让前员工保持沉默的非常有效的方式，并且“在硅谷相当罕见”。</p><p>因此，这封公开信对先进的人工智能公司提出了四项要求：</p><p>停止强迫员工达成协议，阻止他们因“风险相关问题”批评雇主；</p><p>为员工建立匿名流程，以便他们向董事会成员和其他相关监管机构或组织提出担忧；</p><p>支持“公开批评文化”；</p><p>不要对在其他流程失败后分享“风险相关机密信息”的前任和现任员工进行报复。</p><p>真正深入到生成式人工智能研发工作的员工，他们的审慎和良知是AI安全防线最重要的一环，如果他们不能自由表达对安全的担忧，那么这个渠道就会被关闭，政府和公众的知情权就会受损。</p><h2>三、警钟：AI从“生存威胁”转向“至关重要的商业机会”</h2><p>正像《互联网法律评论》近期发布的文章《果然！美国限制AI出口立法进程又进一步》&nbsp;中所述，随着微软和OpenAI、IBM、Meta、英伟达等美国科技公司加大对AI政治游说的投入资金，美国立法者开始更倾向于：<strong>人工智能与其说是一种生存威胁，不如说是一个重要的商业机会；严格的安全规则可能会限制美国的创新，并将使美国的人工智能优势拱手让给中国。</strong></p><p>而且事实上，美国国会的很多议员已经放弃了他们曾经对这项技术的快速发展感到恐惧的语气，并公开质疑先进的人工智能模型是否真的那么危险。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_9f2e143db48a4410b669c08f5ea4c41d@5655031_oswg34928oswg1220oswg746_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图：美国每年就人工智能相关问题进行游说的客户数量（来源：2024年5月29日美国公民倡导组织公共利益研究小组发布的《人工智能游说者来到华盛顿特区》）</p><p>从2023年3月微软裁撤了整个人工智能部门内道德与社会团队的事件，我们就看出，生成式人工智能巨大的经济诱惑直接影响了科技公司对安全工作的兴趣。而微软的这一理念，也经过Sam Altman戏剧性的离职和回归事件之后，完全融入了OpenAI的经营当中。</p><p>但是希望这封公开信能够成为响亮的警钟，让科技公司回想起他们宣言中的“透明和负责任”的承诺，也让立法者了解到他们尚未被告知的风险可能性，制定合理且适当的监管政策，使科技公司衡量发展和安全性时多一层外部监管的压力。</p><p><strong>附：《对先进人工智能发出警告的权利》全文</strong></p><p><strong>对先进人工智能发出警告的权利</strong></p><p>我们是前沿人工智能公司的现任和前任员工，我们相信人工智能技术有潜力为人类带来前所未有的利益。</p><p>我们也了解这些技术带来的严重风险。这些风险包括进一步加剧现有的不平等、操纵和误导信息，以及失去对自主人工智能系统的控制，可能导致人类灭绝。人工智能公司本身已经承认了这些风险，世界各国政府和其他人工智能专家也承认了这些风险。</p><p>我们希望，在科学界、政策制定者和公众的充分指导下，这些风险能够得到充分缓解。然而，人工智能公司有强烈的经济动机来逃避有效的监督，我们认为<strong>既定的公司治理结构不足以改变这一现状</strong>。</p><p>人工智能公司掌握着大量非公开信息，包括其系统的能力和局限性、保护措施的充分性以及不同类型伤害的风险水平。然而，人工智能公司目前向政府分享信息强制性很弱，而对民间社会则没有任何义务。我们认为，不能指望它们都自愿分享这些信息。</p><p><strong>只要政府对这些公司没有有效的监督，现任和前任员工就是少数可以要求他们向公众负责的人</strong>。然而，<strong>广泛的保密协议阻止我们表达我们的担忧</strong>，除非向那些可能未能解决这些问题的公司表达。普通的举报人保护措施是不够的，因为它们侧重于非法活动，而我们担心的许多风险尚未受到监管。鉴于整个行业都发生过此类案件，我们中的一些人有理由担心各种形式的报复。我们并不是第一个遇到或谈论这些问题的人。</p><p><strong>因此，我们呼吁先进的人工智能公司遵守以下原则：</strong></p><p><strong>公司不应签订或执行</strong>任何禁止因风险相关问题而对公司进行“贬低”或批评的协议，也不会通过妨碍任何既得经济利益来报复与AI风险相关的批评；</p><p><strong>公司应为</strong>现任和前任员工提供可验证的匿名流程，以便他们向公司董事会、监管机构以及具有相关专业知识的适当独立组织提出与AI风险相关的担忧；</p><p><strong>公司应支持公开批评的文化</strong>，并允许其现任和前任员工向公众、公司董事会、监管机构或具有相关专业知识的适当独立组织提出对其AI技术的风险相关担忧，只要商业秘密和其他知识产权利益得到适当保护；</p><p><strong>公司不应对在其他流程失败后公开分享风险相关机密信息的现任和前任员工进行报复。</strong>我们承认，任何报告风险相关问题的努力都应避免不必要地泄露机密信息。因此，一旦存在向公司董事会、监管机构和具有相关专业知识的适当独立组织匿名提出疑虑的适当流程，我们承认最初应通过此类流程提出疑虑。但是，只要不存在这样的流程，现任和前任员工就应保留向公众报告其疑虑的自由。</p><p>原文链接：https://righttowarn.ai/</p><p class="editor-note">本文来自微信公众号“Internet Law Review”（ID:Internet-law-review），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808087472633216</id>
            <title>何以撑起浙江第三城</title>
            <link>https://www.36kr.com/p/2808087472633216</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808087472633216</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 09:32:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 温州, 经商, IPO, 创投
<br>
<br>
总结: 本文介绍了温州作为一个经商之地的特点，以及温州人在商业领域的成功案例和投资活动。从温州新IPO军团到温州old money再到温州在科创时代的力量展示，展现了温州在商业和投资领域的活跃和影响力。 </div>
                        <hr>
                    
                    <p>投资界-城市看板之温州篇。东濒东海，南毗福建省宁德市，西临丽水市，北接台州，温州素有“东南山水甲天下”之美誉 。2023年，温州全年GDP达到了8730.6亿元，位列浙江省第三名。</p><p>众所周知，温州人以善经商名扬天下。曾有统计显示，每4个温州人中就有1个在外经商，至今70万温州人把生意做到世界130多个国家和地区，创造了远远大于温州本土的经济规模。</p><h2>温州新IPO军团</h2><p>先从一个温州新能源IPO说起——瑞浦兰钧。</p><p>2017年，瑞浦兰钧董事长曹辉结识了青山集团董事长项光达。彼时，曹辉任上海航天电源总工程师，已经有近10年的动力电池研发经验。一番深入交流下，39岁的曹辉辞职来到了温州瓯江边。不久，瑞浦兰钧正式成立，以动力电池和储能产品双线发展。</p><p>不到两年，瑞浦兰钧就实现了锂离子电池的批量交付，此后迅速构建起锂电池的量产能力。这段时间正是国内新能源汽车的爆发期，瑞浦兰钧顺利拿下上汽通用五菱、沃尔沃和极氪等品牌的订单。</p><p>在业内打响了名声，瑞浦兰钧也成了投资人争抢的对象。先后进入瑞浦兰钧的投资方有30多家，不仅有深创投等知名投资机构，还汇聚了上汽系、中伟股份等一众产业龙头，以及浙江、佛山、芜湖、淄博等国资阵容。去年12月，瑞浦兰钧正式登陆港交所，最新市值超330亿港元。</p><p>在宠物赛道，温州平阳县跑出两家上市公司——源飞宠物和佩蒂股份。</p><p>2022年8月，源飞宠物在深交所主板上市，成为“宠物牵引用具第一股”。公司创始人是一位温州75后——庄明允，一开始公司只生产狗咬胶，后来逐步拓展到宠物零食、宠物牵引用具、宠物玩具等领域，产品行销海外。</p><p>“宠物食品第一股”佩蒂股份则源自一位教师的转行。1992年，从狗咬胶中嗅到商机的陈振标辞去教师的工作，从一笔来自加拿大的订单出发，投入宠物行业。</p><p>一个县城何以诞生两个宠物IPO？数据显示，温州平阳县内与宠物用品相关企业超千余家，宠物咬胶食品出口额占全国同类产品总量的60%以上，宠物牵引绳总产量占据国内市场的35%以上，是细分领域当之无愧的“单打冠军”。</p><p>事实上，资本市场上越来越多温州新面孔崭露头角，电控与安全元器件制造商美硕科技；通用减速机制造商通力科技；连接器研发商珠城科技等都于近年成功上市。当然，温州老牌上市公司也依旧活跃，低压电器行业龙头正泰电器孵化正泰安能，已长成光伏超级独角兽...... “温州板块”加速扩容。</p><h2>温州old money</h2><p>商行天下，善行五洲，温州商帮的身影活跃。温州企业家闻名天下，殊不知LP圈还有一个群体——温州old money。</p><p>今年4月，地素时尚发布公告称，公司将出资不超过1.8亿元作为有限合伙人参与投资长沙安仲创业投资基金合伙企业（有限合伙），从而间接投资长沙嘉御消费基金。翻看地素的股东名单发现，公司的第一、二大股东是来自温州的马瑞敏与女儿马艺芯。</p><p>森马集团董事长邱光和早已涉足创投圈。据不完全统计，邱光和创办的森马目前公开投资事件已有22笔，包括麦田能源、霸蛮、维坦医药等。此外，森马还是华盖资本、正轩投资、分享投资等多家机构的LP之一，堪称投资人背后的“金主”爸爸。</p><p>另外，“温州鞋王”钱金波之子钱帆与创投圈也很有渊源。他曾在上海一家知名投资机构任职。后来，钱帆基于自身的投资经验和资金优势做起了LP。其名下关联公司包括上海沣石二号创业投资合伙企业（有限合伙）、广东旭泽华新投资合伙企业（有限合伙）、宁波梅山保税港区混沌创新二期投资合伙企业（有限合伙）等。</p><p>唯品会创始人兼CEO沈亚也是温州人，主业之外，唯品会还悄悄构筑起一幅产业投资版图，投资了红布林、有赞、热醒Rexing等。</p><p>巨无霸药企药明康德的掌门人李革来自温州平阳县，药明康德化身超级医疗CVC，频繁出手医疗健康项目，如斯微生物、奔曜科技、星联肽、瓴方生物等。药明康德还早早做起了LP，牵手多家投资机构，包括华平投资、晨壹投资、通和毓承、纽尔利资本等。</p><p>偌大的投资江湖里，温州大佬的身影不断浮现，他们大多一手缔造了成功企业后，转身进入创投圈，或直接投资，或隐身背后做起LP。</p><h2>科创时代，温州力量</h2><p>温州，不止于此。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_00892e1a60a549798139546c32d93d45@000000_oswg150687oswg554oswg465_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：温州市人民政府官网</p><p>早在2021年，《温州市制造业高质量发展“十四五”规划》发布，以数字经济、智能装备、生命健康、新能源、新材料五大战略性新兴产业为重点，加快培育现代化产业集群。</p><p>今年3月，《温州市进一步推动经济高质量发展若干政策》提到，深入实施“415X”先进制造业集群培育工程，围绕“5+5”产业迭代形成“产业链链长制”2.0版，加快培育两大万亿产业集群，积极争创国家先进制造业集群，着力提升产业链供应链韧性和安全水平。</p><p>温州留给创投圈的印象是今年4月，浙江省专精特新母基金落地温州。母基金总规模30亿元，锚定温州市“5+5+N”重点产业领域和重点项目，引导基金精准滴灌，不断扩大温州市在“专精特新”领域的优势，加快培育和发展新质生产力，提速构建更具竞争力的现代化产业体系。</p><p>而去年10月，《温州市重点产业发展基金管理办法（试行）》印发。《管理办法》明确，市重点产业发展基金对外投资采用投资子基金、参建母基金、直接投资等三种方式，一般以投资子基金为主。市重点产业发展基金总规模200亿元，投资领域为温州市“5+5+N”产业，重点投资数字经济、智能装备、生命健康、新能源、新材料等五大战略性新兴产业，并聚焦新能源、眼脑健康等细分优势产业。</p><p>同时，温州宣布落地千亿产业基金集群，充分发挥基金放大资本作用，目标撬动3000亿元规模产业投资。此次，温州在现有产业基金的基础上，市级设立500亿元温州市产业高质量发展引导基金，温州各县（市、区）、功能区再谋划设立超700亿元产业基金，合计形成超千亿产业基金集群。</p><p>新兴产业浪潮来袭，属于温州的机会与挑战共同摆在了面前。</p><p>僻处浙江东南一隅，早年的温州并不富裕。然而凭借不怕苦不怕累、敢为天下先的精神，温州人缔造出一段又一段商业传奇故事，而温州城正向GDP万亿城市迈进。</p><p>“弗怕折，只怕歇”，这里的传奇还在续写。</p><p>本文来自微信公众号“投资界”（ID：pedaily2012），作者：陈渝津，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808087424628357</id>
            <title>三个90后，估值360亿</title>
            <link>https://www.36kr.com/p/2808087424628357</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808087424628357</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 09:28:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI融资潮, Cohere, Aidan Gomez, 大模型技术
<br>
<br>
总结: 本文介绍了AI领域的融资潮席卷全球，以Cohere为例，创始人Aidan Gomez等90后创业者在大模型技术领域取得成功，展现了他们在AI创业浪潮中的领先地位。 </div>
                        <hr>
                    
                    <p>AI融资潮席卷全球。</p><p>近日，据路透社披露，明星人工智能独角兽Cohere刚从英伟达、Salesforce Ventures、思科等投资方筹集到4.5亿美元资金，估值达到50亿美元（360亿人民币），令人惊叹。</p><p>你可能不相信，核心创始人又是一位95后——Aidan Gomez，他还是大名鼎鼎的AI标杆性论文《Attention is All You Need》作者之一。今年英伟达GTC 大会上，他被黄仁勋邀请作为嘉宾参与圆桌对话。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_4ea9b4ffff0845e59bc5e7e44b522b33@000000_oswg98853oswg1080oswg760_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">从左到右：Ivan Zhang、Aidan Gomez、Nick Frosst</p><p>自2019年起，Aidan Gomez与两位90后校友Ivan Zhang、Nick Frosst创办Cohere，一路开挂，投身到AI创业浪潮。初生牛犊不怕虎，这无疑是AI造富最生动的写照，由此我们看到一群90后正在主导史上最大AI创业潮。</p><h2>黄仁勋的座上宾，三位90后，缔造超级独角兽</h2><p>Cohere的故事始于三位年轻人。</p><p>1995年，Aidan Gomez出生在加拿大安大略省的一个森林乡村。在他的回忆中，家乡绿树环绕，山清水秀，唯独就是网速不好，互联网世界似乎遥不可及，由此驱使他去了解计算机，爱上了编程。</p><p>2013年，Aidan 进入多伦多大学攻读计算机专业，随后又到牛津大学读博。期间，他广泛研读AI领域泰斗、图灵奖获得者Geoffrey Hinton的学术论文，甚至还会对论文“评头论足”，初生牛犊不怕虎。</p><p>人生的一个转折点是2017年，20岁出头的Aidan 在谷歌大脑实习期间，与其他七位研究人员撰写发表了著名论文《Attention is All You Need》，该论文首次提出了 Transformer 架构，也就是后来ChatGBT大模型的底层架构。</p><p>然而，Transformer的诞生当时并没有激起太多的浪花。Aidan看着Transformer 架构在谷歌内部广泛应用，推动了难以置信的变化。但在谷歌之外，却很少有人用Transformer打造应用。于是，他萌发了创业的念头。</p><p>恰巧当时，Aidan 认识了从多伦多大学辍学创业的华人Ivan Zhang。Ivan是不折不扣的技术实践派，两人一拍即合——2019年，专注于AI大模型应用的Cohere应运而生。</p><p>2020年，另一位联合创始人兼首席科学家Nick Frosst加入。Nick同样毕业于多伦多大学计算机科学系，也曾是谷歌大脑Hinton团队成员。至此，三位90后创始人集结完毕。</p><p>凭借着对大模型底层技术的理解，Aidan在创业中采用差异化竞争策略，不走内卷的“类ChatGPT”路线，而专注利用大模型的能力服务企业客户，并且设计针对性的付费模式。</p><p>正是由于这一差异化战略，让Cohere在激烈AI竞争中获得一席之地。据外媒报道，目前Cohere已与Jasper 、HyperWrite、Salesforce 等公司合作，截至今年3月底，公司收入达到3500万美元，涨势喜人。</p><p>今年在英伟达GTC大会上，早年论文的8位作者重聚一堂，Aidan Gomez也应邀在列成为黄仁勋的座上宾。《时代》周刊发布首届全球百大AI人物，Aidan Gomez也名列其中。</p><h2>一年融一轮，估值360亿</h2><p>Cohere的融资历程留给了创投圈深刻印象。</p><p>得益于Aidan的学术背景，公司早期获得了大佬们的支持——包括图灵奖得主 Geoffrey Hinton、GAN 之父 Ian Goodfellow、Uber 首席科学家 Raquel Urtasun、英伟达多伦多研究实验室主任 Sanja Fidler 及斯坦福教授李飞飞等都纷纷出手。要知道，这几位在当今AI江湖都是执牛耳的人物。</p><p>在行业大牛的背书下，Cohere的融资节奏相当丝滑，保持着一年一轮的节奏。2021年9月，Cohere完成由Index Ventures、Section 32、Radical Ventures以及多名个人投资者的4000万美元A轮融资。</p><p>半年后的2022年2月，Cohere又获得1.25亿美元的B轮融资，由Tiger Global领投，Radical Ventures、Index Ventures和Section 32跟投。</p><p>直到2023年5月，Cohere 宣布完成 2.7 亿美元的 C 轮融资，阵容更加豪华——由Inovia Capital领投，英伟达、甲骨文、全球SaaS鼻祖Salesforce、Index Ventures、DTCP、Mirae Asset、Schroders Capital、SentinelOne、Thomvest Ventures和韩国未来资产集团等资本纷纷参投。此番使公司融资总额达到约 4.45 亿美元，仅次于OpenAI 和 Anthropic。</p><p>自此，Cohere 估值也突破了20亿美元。</p><p>最新一幕，则是Cohere又从英伟达、Salesforce、思科等投资方融到了4.5亿美元资金，估值飙升到了50亿美元，规模之大令人咂舌。</p><h2>今年火爆一幕：90后撑起AI创业潮</h2><p>这样一幕并不陌生。放眼望去，90后正掀起一场史无前例的AI创业潮。</p><p>翻开今年AI每一笔大额融资的背后，几乎都能看到一群90后学霸式创始人。犹记得上个月，Scale AI宣布获得10亿美元融资，估值达到138亿美元（约为人民币1000亿元），而站在身后的正是95后Alexandr Wang和Lucy Guo。</p><p>无独有偶，本周AI自动生成视频软件Pika完成总额8000万美元的B轮融资，由Spark Capital领投，Greycroft、Lightspeed Venture Partners以及Jared Leto参投，公司估值超过4.7亿美元（人民币34.06亿元），身后同样是一位95后——郭文景。</p><p>郭文景曾是浙江第一位被哈佛本科提前录取的女生，在哈佛拿到计算机硕士和数学本科学位后来又到斯坦福大学读博。去年4月，郭文景和几位同学一起从斯坦福退学，共同开发了Pika，全球爆红。</p><p>纵观国内AI创业潮，年轻一代同样来势汹汹。</p><p>不久前，国内AI大模型明星公司月之暗面最新一轮融资流出，估值报价已达30亿美元，公司带头人则是清华90后学霸杨植麟。成长于广东汕头，杨植麟高中毕业被保送至清华大学，后来在卡内基梅隆大学读博。过去一年，月之暗面成为了大模型赛道被VC争抢激烈的项目。</p><p>印象深刻的还有前华为“天才少年”稚晖君彭志辉。本硕毕业于电子科技大学，他也是坐拥250万粉丝的B站up主，所创立的智元机器人，瞄准具身智能领域。自2023年2月成立以来，智元机器人已马不停蹄拿下多轮融资，所向披靡。</p><p>还有更多90后AI创始人涌现——前爆款AI产品“妙鸭”产品负责人张月光创办的沐言智语成立半年已完成多轮融资，这位90后本科毕业于清华大学；波形智能CEO姜昱辰，1998年出生，本科浙江大学，苏黎世联邦理工大学博士，从事自然语言处理研究。她创办的杭州波形智能，最新获得由蓝驰创投领投，西湖科创投、老股东藕舫天使等跟投的Pre-A轮融资。</p><p>这里还有一份长长的名单——面壁智能曾国洋、太极图形胡渊鸣、瑞莱智慧田天、星动纪元陈建宇……细数下来，他们大多拥有中国乃至世界顶级大学的理工科学历背景，乘着人工智能东风成为时代的宠儿。对此，华创资本总结过这一波创始人的特点：</p><p>一是学历背景相当出色，基本在国内外顶级高校的计算机、人工智能等强相关专业，有丰富的研究资源和大厂实习经历；</p><p>二是轻团队重研发，只需要几个人就可以搭建完整的团队开发和落地，起步非常快；</p><p>三是生成式AI被视为一次巨大的范式转移，年轻人对科技创新、乔布斯式的创业有很强的信仰崇拜。</p><p>这个世界永远属于年轻人。无数名校出身的他们，正在用最新的技术为世界写下注脚，共同缔造眼前AI创业波澜壮阔的一幕。</p><p>本文来自微信公众号“投资界”（ID：pedaily2012），作者：陈晓，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808081785550471</id>
            <title>一毛钱写两本红楼梦，智谱AI再降价，已服务30万企业用户</title>
            <link>https://www.36kr.com/p/2808081785550471</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808081785550471</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 09:02:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 作者, 编辑, 智谱AI, 大模型
<br>
<br>
总结: 5月降价的智谱AI在6月再次推出新产品，包括GLM-4系列、新API模型、MaaS 2.0大模型开放平台等。同时，智谱AI公布了过去一年的商业化进展，开放平台服务30万企业客户，API每日消费量增长50倍以上。新的GLM-4-9B模型具有更强的综合能力和更高的中文学科能力，同时支持调用外部工具。MaaS平台也发布了2.0版本，提供多套餐选择，包括GLM-4、GLM-4-Air和CogView-3等不同性能和价格的模型。智能体也与大模型结合，推出多智能体协作系统“清流”，展示了智能体在创作科幻小说和展示罗永浩智能体的案例。 </div>
                        <hr>
                    
                    <p>作者 | 王沁</p><p>编辑 | 邓咏仪</p><p>&nbsp;</p><p>5月刚刚大降价的智谱AI，这个月再给用户们全面上新。</p><p>6月5日，智谱AI Open Day正式举办。在现场，智谱AI发布了全新的开源大模型GLM-4系列、新API模型、MaaS 2.0大模型开放平台、智能体等等产品。</p><p>5月的大模型“大促月”还没结束，智谱也再度跟进降价。</p><p>比如，GLM-4-Flash轻量化版本，在企业优惠价下最低只需要6分钱/100万token。这意味着不到一毛钱就可以把四大名著如《红楼梦》写两遍。</p><p>而在企业V3版的价格下，用CogView-3文生图模型生成一张图只要6分钱。</p><p>智谱AI也公布了过去一年的产品、商业化进展：</p><p>当前，智谱AI的开放平台已服务30万企业级客户，日均调用量达400亿token，过去6个月API每日消费量增长了50倍以上。</p><p>智谱AI旗下的To C产品智谱清言App，当前已经有超过30万个智能体活跃在清言的智能体中心内，其中包括了思维导图、文档助手、日程安排等许多生产力工具。</p><p>新版的MaaS大模型开放平台，价格体系更加细分，让企业客户有多套餐可选。无需代码，客户以三步完成微调，用自有数据就可以部署私有模型。</p><h3>90亿参数模型开源，API价格新低</h3><p>值得注意的是，此次智谱开源了一个90亿参数的GLM-4-9B 模型，其综合能力相比 ChatGLM3-6B提升 40% ，全面超过 Llama-3-8B-Instruct。</p><p>而对比训练量更多的 Llama-3-8B 模型，GLM-4-49B在英文方面有小幅领先，中文学科能力提升 50%。</p><p>上下文窗口，也从 128K 扩展到了 1M token。这意味着模型能同时处理 200 万字的输入，大概相当于 2 本红楼梦或者 125 篇论文的长度。</p><p>GLM-4-9B模型也有自己调用外部工具的能力，即All Tools能力，能够调用外部工具（比如代码执行、联网浏览、画图、文件操作、数据库查询、API 调用等）来辅助回答问题或完成任务。</p><p>从模型体量上看，GLM-4-9B可以算是适用于非常多应用落地场景的一个小尺寸。智谱也表示，在开源模型上，智谱并未追求一味扩大模型参数。</p><p>“在模型规模方面，我们认为对于个人用户和开发者来说，显存更加珍贵，因此我们没有采用例如混合专家结构这种用显存来换性能的结构，而是略微将模型规模扩大到9B，用实际的计算量来追求性能。”智谱AI的技术团队表示。</p><p>在大模型的落地上，小模型（10B 以下的轻量化大模型）在应用落地上有独特的优势——参数小、占内存少、响应速度快、易于在端侧运行。训练大模型需要巨大算力资源和数据，而小模型所需数据更少，应用场景特定，商业化也更容易。</p><p>如今，各个大厂都有推出小模型系列产品——比如微软的SLM（小语言模型）Phi-3系列、苹果的“小模型”家族、谷歌的Gemma等等。</p><h3>MaaS平台，加量但降价</h3><p>另外，智谱的MaaS大模型开放平台也发布了2.0版本。相比之下，今年1月智谱Dev Day强调更大参数模型GLM-4的硬核能力，在对话、代码、图片理解、文生图等全方位硬刚OpenAI，称GLM-4的英文能力达到GPT-4的九成，在中文表现上超越对方。</p><p>而新一代MaaS平台支持的一系列新模型更重视商业化应用，让企业根据不同需求有多套餐可选，差异化选择：</p><p>GLM-4性能最强大，不过也最贵（100元/100万token）</p><p>GLM-4-Air性能堪比规模更大的模型 GLM-4-0116、但有更性价比，GLM-4-Flash价格最优惠（0.1元/100万token）</p><p>而CogView-3文生图模型一张图只要一毛钱。</p><p>模型有套餐，企业VIP卡也上线了各种分级套餐。现在，智谱的MaaS平台有9折V0、8折V1、7折V2、6折V3的企业服务体系。比如，V3价格下，GLM-4-Flash下100万token只要6分钱，CogView-3生成一张图6分钱，主打量大便宜。</p><p>而针对企业用户的数据安全、对私有化模型的需求，智谱的MaaS大模型平台上线模型微调功能，在准备训练数据、创建微调任务、部署微调模型三个步骤后，就可以完成一个私有模型的训练。</p><h3>智能体上线，能做的任务又变多了</h3><p>AI圈内热议的“智能体”（Agent），现在和大模型的结合度，也越来越紧密。</p><p>如今，清言App推出的多智能体协作系统“清流”，可以在同一个对话框中，自由调用多种不同的智能体协同工作。</p><p>清言可以调用思维导图、流程图、数据分析等多个不同智能体，同时接入微博、飞书、日历等平台工具。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_c74d767c955a4a31a56e4bb096afa662@6069545_oswg671760oswg1265oswg708_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：智谱AI</p><p>&nbsp;</p><p>智谱AI举了不少有趣的案例。</p><p>一位9岁的小男孩，与智谱清言合作，写出了一本关于火星生存的科幻小说。</p><p>他先问质谱清言，如何才能在火星上生存？智谱清言给出氧气、水、食物、能源等关键生存因素，再确立整本书的框架。</p><p>在用户和质谱清言的对话轮回中，填充文本，智谱清言还会查询科学数据来检查小说内容，修改文字错误。</p><p>智谱AI Open Day现场还展示了一个“赛博IP”——罗永浩智能体。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_7cad4738c51049559e6d194119a0e628@6069545_oswg103440oswg552oswg827_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">智谱AI智能体员工“AI老罗”</p><p>它有着跟罗永浩一样的广博的知识面、幽默的说话腔调，全天候24小时工作，还发挥老本行特色，现场为一套“奇葩”挖掘机形状的房屋户型图，来了一段罗永浩风格的直播推销：“你想象一下，你就打算在挖掘机的房子那得多酷，你住在里面每天都能感受到那种工程的力量和魅力......这个挖掘机户型把每个空间都挖掘得恰到好处，不像那些动辄几百平米的豪宅，看似气派，其实住起来空荡荡的，冷清得很。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_f00fe818e6294f5b958a84d2dd8fb8de@6069545_oswg42800oswg746oswg459_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">“AI老罗”解说的挖掘机户型</p><p>根据36氪的试用，现在清言APP的智能体中心，已经有多种对话场景。</p><p>比如，你可以在催生了人工智能革命的达特矛斯会议上与信息论始祖香农对话，在作家聊天群中与莫言、余华对话，在“无限流续写”中通过对话编织小说，向“专业选择引导师”智能体询问如何选高考专业。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_6e1328173fdd41dc9f3f33e1594e2de3@6069545_oswg198885oswg2755oswg1400_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">智谱清言聊天界面</p><p>大模型降价已经成为趋势，现在许多大模型的小尺寸模型价格已经接近免费，这会持续多久？政务服务企业华信永道副总经理吴文表示，企业用户在意价格，但不是最在意价格，帮助企业增加利润率最重要，只要能帮助企业增加收入，即使贵，企业也愿意用。而爱设计CEO赵充在会上表示，降价的底线是电费，只要比电费高，就还有利润空间。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2807907297719945</id>
            <title>Cloudflare 宣布 AI Gateway 普遍可用</title>
            <link>https://www.36kr.com/p/2807907297719945</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2807907297719945</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 08:52:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Cloudflare, AI Gateway, 生成式 AI, AIOps
<br>
<br>
总结: Cloudflare 最近宣布 AI Gateway 已普遍可用。AI Gateway 作为管理和扩展生成式 AI 工作负载的统一接口，让开发人员能够监控和控制 AI 应用程序。AI Gateway 是一个 AIOps 平台，为管理和扩展生成式 AI 工作负载提供了统一的接口。 </div>
                        <hr>
                    
                    <p>Cloudflare 最近宣布 AI Gateway 已普遍可用。AI Gateway 作为管理和扩展生成式 AI 工作负载的统一接口，让开发人员能够监控和控制 AI 应用程序。</p><p>AI Gateway 是一个 AIOps 平台，为管理和扩展生成式 AI 工作负载提供了统一的接口。它作为服务和推理提供者之间的代理，无论模型位于何处。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_12873a115643461cbc0a1cf1afc8278b@000000_oswg88273oswg1080oswg342_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：Cloudflare 博客</p><p>Cloudflare 产品经理 Kathy Liao、高级产品经理 Michelle Chen 和 产品总监 Phil Wittig 在博客中写道：</p><blockquote><p>我们与许多构建 AI 应用程序的开发人员和组织进行了交谈，有一件事很明确：他们希望获得更多关于他们的 AI 的可观察性、控制性和工具化。这些是许多人工智能提供商所缺乏的东西，因为他们更专注于模型开发而不是平台特性。&nbsp;</p></blockquote><p>将应用程序连接到 AI Gateway 使其能够通过分析和日志来监控用户的交互，并提供缓存、速率限制、请求重试和模型回退等扩展功能。Liao、Chen 和 Wittig 补充道：</p><blockquote><p>只需要一行代码，你就可以解锁一组针对性能、安全性、可靠性和可观察性的强大功能，可以将其视为你的 AI 工作负载的控制面板。&nbsp;</p></blockquote><p>除了 Cloudflare Workers AI 外，新的 AI Gateway 还支持 多个第三方提供商，包括 OpenAI、Google Vertex AI、Azure OpenAI、HuggingFace、Amazon Bedrock 和 Anthropic。Eesel 的联合创始人 Amogh Sarda 在 评论中说：</p><blockquote><p>我很想看到它的实际运行情况。我相信将会有一些有趣的方式来测试它的敏感数据检测能力。&nbsp;</p></blockquote><p>AI Gateway 仪表盘可以显示请求数量、令牌和运行应用程序相关成本等指标。它还可以跟踪单个请求，提供有关提示词、响应、提供者、时间戳以及请求是否成功的信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_2e1b1324952e475691be6c1af49e0de6@000000_oswg163316oswg1080oswg989_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：Cloudflare 博客&nbsp;</p><p>AI Gateway 并不是 Cloudflare 在 AI 领域发布的唯一一个 公告，它还提供了面向 AI 的防火墙 预览和普遍可用的 Workers AI，其中包括几项旨在简化开发人员构建和部署 AI 应用程序的功能。分析师和顾问 Janakiram MSV 在一篇文章中写道：</p><blockquote><p>Cloudflare 通过不断改进其边缘网络的功能来挑战亚马逊云科技 (AWS)。亚马逊的无服务器平台 AWS Lambda 尚未支持基于 GPU 的模型推理，它的负载均衡器和 API 网关也尚未针对 AI 推理端点做出更新。&nbsp;</p></blockquote><p>Credexium 创始人 Brendan Skousen 在评论中写道：</p><blockquote><p>我最近开发的 AI 工具集成了 Cloudflare 的服务。我会用 Cloudflare 替换特定于平台的 API 端点，无论是我自己的 API 还是使用像 AI Gateway 或 Web3 Gateway 这样的东西。为什么呢？因为它几乎是免费的，并且包含了安全的分析等功能。在构建 LLM 应用程序时，实时日志记录、缓存和速率限制是必不可少的功能。&nbsp;</p></blockquote><p>AI Gateway 当前的核心功能在所有的 Cloudflare 计划中都是免费的，但未来的高级功能，如持久日志记录和秘钥管理将需要付费。</p><p><strong>查看英文原文</strong>：</p><p>https://www.infoq.com/news/2024/06/cloudflare-ai-gateway/</p><p>本文来自微信公众号“InfoQ”（ID：infoqchina），作者：Renato Losio，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2805699477583234</id>
            <title>一句话生成UI，猿辅导母公司做了“AI版Figma” | New Things</title>
            <link>https://www.36kr.com/p/2805699477583234</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2805699477583234</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 08:40:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 猿辅导, AI设计, Motiff, UI设计
<br>
<br>
总结: 猿辅导母公司通过AI设计软件Motiff进军UI设计市场，与教培业务有着明显区别。Motiff利用AI技术提高UI设计效率，包括简化复制粘贴、智能排布和布局功能。通过“文生成UI”和“AI魔法框”功能，Motiff实现了智能生成UI设计，提高设计师生产力。Motiff的定价仅为Figma的20%，在全球SaaS市场有巨大机会。 </div>
                        <hr>
                    
                    <p>文 | 周鑫雨</p><p>编辑 | 苏建勋</p><p>猿辅导母公司到底是家什么公司？</p><p>A. 教培公司；B. 咖啡公司；C. 羽绒服公司；D. 月子中心。</p><p>答案是全选。</p><p>自2021年以来，猿辅导母公司的业务版图，就从教培扩充到了精品咖啡Grid、高端羽绒服SkyPeople，以及月子中心茉莉智慧。</p><p>而到了2024年，这个问题的答案，多了一个选项：<strong>AI设计</strong>。2024年6月5日，筹备了近两年的AI设计软件Motiff（妙多），在新加坡完成了首秀。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240605/v2_402d503860b1477ead1814e99cf2c319@5783683_oswg5295175oswg5355oswg3218_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Motiff</p><p>Motiff瞄准的市场，是UI（用户界面）设计，与教培依然相去甚远。Motiff运营副总裁张昊然告诉36氪，团队的自信，一是来源于猿辅导AI Lab成立10年来的积累技术，二是因为，AI技术的发展，让团队看到了颠覆Figma的机会。</p><p>这款开启了协同设计时代的软件，在UI设计领域有着高达80%的市占率，也是Motiff对标的产品。张昊然如此比喻两者的差异：<strong>Figma是手动驾驶，Motiff是自动驾驶</strong>。</p><p>Motiff首秀的舞台，选在了亚洲人工智能大会SuperAI，意在做全球市场的生意。与之同台的，还有世界三大云厂商微软、谷歌和AWS，黑红的AI独角兽Stability AI，以及一众硅谷明星AI公司。</p><p>张昊然认为，Motiff的机会，在全球规模达2000多亿美元的SaaS市场。实用和性价比，是Motiff竞争的切入口：增加AI功能的同时，Motiff的定价只有Figma的20%。</p><p>不过，舞台再大，Motiff终究逃不过设计师用户的灵魂拷问：<strong>一家教培公司做的设计应用，到底好不好用？</strong></p><h3><strong>一句话生成UI，一拉实现复制粘贴</strong></h3><p>实用，在Motiff看来，是对设计师而言最大的产品价值。</p><p>张昊然认为，让AI产品具有实用性，则需要找到高频场景，这也是验证PMF（Product Market Fit）的前提。</p><p>比如复制、粘贴的“<strong>重复</strong>”动作，是Motiff用AI改造的高频场景。基于AI对布局的理解能力，原有Cmd+V、Cmd+C的重复动作，被Motiff简化成了一步到位的<strong>下拉</strong>动作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240605/v2_6b132c00641749199f7c436888177d44@5783683_img_gif?x-oss-process=image/quality,q_90" /></p><p class="img-desc">图源：Motiff</p><p>而Motiff的下拉，并非仅仅是对原有组件的1:1复制，而是更懂设计师心思的智能排布。</p><p>比如填充进复制组件中的内容，来源于历史设计稿，而内容排布的逻辑，依据一定的标签逻辑。设计师在提升复制效率的同时，还能减少修改填充内容所消耗的时间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240605/v2_b0385551fba34ea2bc474c3d6d7afb26@5783683_img_gif?x-oss-process=image/quality,q_80" /></p><p class="img-desc">图源：Motiff</p><p>“<strong>布局</strong>”，则是Motiff瞄准的另一个高频场景。</p><p>Motiff的布局功能，可以同时满足套用结构化模板和灵活调整的两种设计需求。比如在页面布局中添加结构化的组件后，设计师还可以自由添加小组件，并且调整组件的间距。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240605/v2_47851c02ef504e78b2eb065192044d09@5783683_img_gif?x-oss-process=image/quality,q_90" /></p><p class="img-desc">图源：Motiff</p><p>不过，无论是一键复制粘贴，还是灵活调整布局，都仍然是利用AI技术，提高UI设计的效率。</p><p>张昊然认为，要让AI设计工具成为生产力，就需要让AI理解设计师的意图，智能生成UI。</p><p>目前，Motiff已经初步实现了“文生UI”。通过“AI实验室”功能，设计师只需用长文本描述所需的界面类型、组成部分，以及定制化的描述，就能输出一个完整的UI界面：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240605/v2_06418722328a409e9259c4e5c9bb14ea@5783683_img_gif?x-oss-process=image/quality,q_80" /></p><p class="img-desc">图源：Motiff</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240605/v2_17c69e4792b54f44909029075b586969@5783683_img_gif?x-oss-process=image/quality,q_80" /></p><p class="img-desc">图源：Motiff</p><p>而在设计阶段，设计师往往需要比较不同想法下的UI呈现效果，若是根据每一个点子进行打样，需要消耗高昂的人力和时间成本。</p><p>Motiff的另一个AI功能，“AI魔法框”，则能根据设计师的草图，生成基础的UI设计。设计师只需给出设计草稿，“AI魔法框”就能基于框的大小、位置关系解析设计师意图，并给出可能想要达到的效果。</p><h3><strong>对标Figma：20%的价格，1.5倍的流畅度</strong></h3><p>估值125亿美元的设计软件Figma，是自2021年成立第一天起，Motiff对标的产品。</p><p>在张昊然看来，Figma在设计工具发展史上具有划时代的重要意义——目前为止，设计工具的发展经历了3个重要的时代，分别由三个工具开启：Photoshop开启了像素时代，Sketch开启了矢量时代，而Figma开启了协同时代。</p><p>一方面，Motiff的基础功能全面对标的是Figma。目前，Motiff已经涵盖了Figma 90%的基础设计功能，并且支持Figma社区中最高频使用的插件。</p><p>对Figma生态的支持，也让企业从Figma生态迁移到Motiff的成本更低。张昊然告诉36氪，目前已有意向客户仅用<strong>2周</strong>的时间，就将工作流从Figma迁移到了Motiff。</p><p>另一方面，Motiff想要与Figma同台竞争的舞台，是后者瞄准的全球市场。</p><p>对按订阅收费的SaaS类软件而言，SaaS市场成熟度更高的海外有更为优渥的发展土壤。尤其是北美市场，近5年来，不少SaaS产品保持了80%以上的毛利率。</p><p>高性价比，是Motiff作为新玩家，快速切入市场的定价策略。</p><p>2024年1月31日以来，Figma的开发者模式正式结束了免费生涯，改为团队用户每月25美元，企业用户每月35美元。</p><p>据了解，<strong>Motiff的定价，综合计算比Figma便宜了80%</strong>。其中，Motiff专业版基础功能价格为24元/月（国际版4美元/月），研发模式6元/月（国际版1美元/月）；企业版基础功能价格为90元/月（国际版15美元/月），研发模式18元/月（国际版3美元/月）。</p><p>值得注意的是，Motiff采取了<strong>全球统一定价</strong>。张昊然告诉36氪，Motiff的供应链和基础设施是全球性的，各地区的利润结构比较统一；同时，目前Motiff基础功能的定价，不管在哪个区域性的市场都比较有竞争力。</p><p>“长期来看，统一定价是更为简单的商业策略，能够让团队的注意力更聚焦到统一战略上。”他表示。</p><p>想要吃下Figma的市场，意味着在基础功能上，Motiff也要具有更强的竞争力。</p><p>多用户协同、多图层同时操作，是设计软件界的“卡车碾压测试”。目前，Figma最多支持100名用户同时协作编辑，当单画布的编辑图层过多，页面还会出现卡顿的情况。</p><p>而Motiff支持的同时在线编辑人数为200人，直接翻了倍。通过对数据架构和建模合理性的优化，Motiff能够支持100万图层下的流畅编辑。即便每周使用 1000 分钟编辑器，Motiff的年平均崩溃次数不超过 1 次。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240605/v2_17f671fed250482fab399add0475c5d3@5783683_oswg133391oswg1384oswg581_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Motiff</p><h3><strong>AI工具要构建竞争壁垒，是真正成为生产力</strong></h3><p>先前在咖啡、羽绒服等领域的经验，已经让猿辅导母公司对跨界的方向，总结出了一套成熟的评价体系：一，市场足够大吗？二，长期做下去壁垒有多深？</p><p>成立之初，Motiff团队就判断，不论是电脑、手机，还是汽车，有屏幕的地方就有UI。Figma已经证明，仅UI设计一个垂直领域，就能让一家设计初创公司，用10年的时间成长为被Adobe垂涎的估值125亿美元的香饽饽。</p><p>但要吃下Figma的市场，意味着Motiff的功能，必须颠覆上一个时代的设计工具。</p><p>Figma的崛起，关键在于切中了企业设计团队对相互协作的需求。在使用过程中，即便协同提高了团队的沟通效率，但设计师仍然要承担大部分琐碎的生产工作。</p><p>到了AI时代，Figma的模仿者不少，但彻底颠覆Figma，将用户成功迁移到自己生态上的产品，还没有出现。<strong>张昊然将不少AI设计工具视作“玩具应用”，其核心特点是，只用AI提高了生产效率，但没有让AI成为真正的设计生产力</strong>。</p><p>而让设计工具脱离玩具应用，成为设计生产力的关键，是<strong>让AI认识UI</strong>。张昊然透露，Motiff背后的AI技术可以分成三个部分：</p><p>· <strong>生成式大模型</strong>：目前接入第三方模型API，负责理解文字、图片和UI；</p><p>· <strong>领域模型</strong>：Motiff自研的设计系统模型、布局模型；</p><p>· <strong>通用模型</strong>：目前接入第三方模型API，负责生成文字和图片。</p><p>三类模型构成的AI大脑，是Motiff能够理解并执行设计任务的智慧来源。张昊然认为，未来设计师的工作将会更聚焦在思考和给出创意，AI设计工具则负责执行创意，并且更高效地完成工程交付。</p><p>但未来，Figma也必然会上线AI功能。面对巨头下场的隐忧，张昊然告诉36氪，时间窗口对初创项目而言十分重要：“<strong>最重要是时间窗口，以及在时间窗口中能不能产生用户价值、能不能打造品牌。</strong>”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808059283207554</id>
            <title>骗子进军AI领域，一边“删号跑路”，一边研发“新业务”，网友： 我居然为它付了钱</title>
            <link>https://www.36kr.com/p/2808059283207554</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808059283207554</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 08:36:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 个人AI产品, Rabbit R1, LAM
<br>
<br>
总结: 人工智能技术在个人AI产品领域的应用，以Rabbit R1为代表的产品在市场上引起轰动，但存在功能实现与宣传不符的问题，尤其是涉及到LAM技术的疑点。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_f52ea000a9174b17b52b15568050c3ab@46958_oswg146406oswg450oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>人工智能可以帮助我们并解决一系列我们所没有的问题，这已经不是什么新鲜事了。但直到 2022 年起，大型模型（LLM、LAM 等）才开始在全球范围内受到追捧和关注。最初是 OpenAI 的 ChatGPT，随后小型的个人 AI 专用设备也引起热议，目前熟知的这类产品有 Humana 的无屏幕可穿戴设备 AI Pin 和 Rabbit 的掌上 AI 设备 R1。</p><p>两款产品一经推出，都在科技圈中经历了轰动和热卖。其中，Rabbit R1 反响更盛，首批 1 万台在 CES 2024 亮相后，短短一天内就被抢购一空。现在，尽管这两款个人 AI 产品似乎都没有兑现当初承诺，但 Rabbit R1 或许对用户有更多的触动。</p><p>上个月， Rabbit R1 刚因公司前身 Cyber Manufacture Co 在转型后，疑似针对所推出的 GAMA 元宇宙 /NFT 项目“删号跑路”，遭到网友的“持续轰炸”。由于 Rabbit 前身推出的 GAMA 与 Rabbit R1 一样，都需要用户预先付费购买账号，不少网友联想到：万一 Rabbit 的 CEO 再次做出这样的事，Rabbit R1 还有什么价值？</p><p>近日，Rabbit R1 又被扒出了更多产品本身的“雷点”。一位专注于揭露骗局的 YouTuber &nbsp;Coffeezilla 通过关于 Rabbit R1 工作原理的两个系列视频，表示其“完全是个骗局”。</p><h2>功能实现中并没有用到 AI？&nbsp;</h2><p>“如果说 Humana 的可穿戴 AI 设备只是一款价格过高且无法正常工作的产品，那 Rabbit R1 则是一款功能杂乱、执行不力且充满骗局的产品，尤其是这家公司以前曾涉足过 NFT 和 ‘付费获胜 ’游戏。”</p><p>根据这两款产品的官方介绍，AI Pin 是一种安置在服装上的微型投影，定位是智能手机的替代品，可以投屏在手掌上进行语音交互、拍照、翻译等功能，售价为 699 美元，每月需要额外支付 24 美元订阅费；而 R1 类似一个 AI 掌上电脑，尺寸不到一个巴掌大，可以联网并兼容现有的所有应用程序，售价为 199 美元。</p><p>据介绍，Rabbit R1 的大部分指令都是硬编码到设备中的，这意味着起大部分操作都是根据要求的软件 / 操作预先定义的。Coffeezilla 在发布的曝光视频中，展示了当应用程序更改图形界面时，Rabbit R1 的操作是如何失败的。比如美国版的 iFood Doordash，通过更改了界面中的一个小汉堡菜单，从而破坏了 Rabbit R1 的操作。</p><p>同时，Coffeezilla 更详细地解释了有关 Rabbit R1 的所有工作原理。笼统地说，Rabbit R1 所做的与使用 Selenium IDE 输入密码、创建用户、发送电子邮件和其他任务时执行的自动化操作类似。</p><p>从外部来看，Rabbit R1 所有的功能实现中并没有涉及到人工智能或者大型动作模型（LAM），它只是在 Rabbit Inc. 的服务器上运行的大型自动化系统。这种系统所做的就是识别口语命令，然后根据用户的登录信息，在远程运行的应用程序上发出请求，最后在 Rabbit R1 上将结果发送给用户。比如，通过 Rabbit R1 打开 Uber 叫一辆出租车到某个地点。</p><p>事实上，Rabbit R1 这样的功能实现看起来并不特别，也没有非常智能，现在使用 iOS 上的快捷方式就可以实现类似功能。“随着调查的深入，情况会变得更糟，但 Rabbit R1 值得一探，因为它本质上就是一个 199 美元的骗局。”</p><h2>Rabbit LAM 的存在成疑&nbsp;</h2><p>若 Coffeezilla 的“控诉”属实，那需要注意的是，不止 Rabbit R1 产品本身，Rabbit 研究团队开发的 LAM 是否存在也将成为一个疑点。</p><p>据悉，LAM 是一个由 Rabbit 研究团队首先开发的复杂系统，旨在彻底改变计算机和人工智能 (AI) 系统在计算机应用程序上理解和执行人类动作的方式。它将神经符号编程与最先进的技术无缝结合起来，以直接建模和理解各种应用程序的复杂结构以及对其执行的操作，超出了传统语言模型或视觉模型所能实现的范围。</p><p>Rabbit 介绍，其 LAM 可以在计算机应用程序上推断和模拟人类行为，可靠、快速地执行这些动作，适合部署在各种人工智能助手和操作系统中。在神经符号编程的最新进展的支持下，Rabbit LAM 允许直接对各种应用程序的结构和用户操作进行建模，而无需依赖文本等临时表示。</p><p>Rabbit LAM 的建模方法植根于模仿或通过演示学习：它观察使用界面的人，并旨在可靠地复制该过程，即使界面呈现方式不同或略有变化。这意味着，一旦提供了演示，合成的例程将直接在目标应用程序上运行，而无需繁忙的“观察”或“思考”循环，并且任何受过技术训练的人都应该能够检查“配方”并推理其内部工作原理。</p><p>Rabbit 研究团队将 LAM 视为重塑人机交互的变革力量，目标是收集更多有关人类行为的数据，不断提高 LAM 的可扩展性，并通过对行为的深入理解从根本上改变具有经济意义的工作。“LAM 并不是孤立运作的，是专为负责任的部署而设计的更广泛生态系统的一部分。新平台的开发可以有效管理 LAM 支持的例程，确保与应用程序交互的准确性、道德性和人性化。”</p><p>无论如何，从 Coffeezilla 展示的案例和观点来说，现在 Rabbit R1 都并没有通过其 LAM 来实现其产品功能。</p><p>此前，也有外媒报道称，“在 R1 中，基本上没有 LAM 工作的证据。”据悉，Rabbit R1 目前实际只能连接四个应用程序：Uber、DoorDash、Midjourney 和 Spotify。用户需打开 Rabbit 的网络应用程序 Rabbithole，然后分别登录每项服务，来连接到它们。连接时，Rabbit 会在应用程序内打开一个虚拟浏览器，直接登录应用程序。也就是说，用户登录的不是 DoorDash 提供的服务，而是 DoorDash 的网站，而 Rabbit 会窥探这个过程。</p><h2>结语&nbsp;</h2><p>对于此次事件，有网友表示，“这确实是有史以来的兔子洞骗局。“还有网友这样评价 Rabbit 的 CEO，“从字面上描述了有史以来最疯狂、最复杂的方式洗钱。”</p><p>至于 Rabbit R1 产品本身，有相关用户表示，“我之所以取消 R1 的预购，很大程度上就是因为需要同时使用另一个智能设备。而且，虽然它看起来很酷，但用户体验似乎很糟糕，”也有网友力挺 Rabbit R1，“我的 R1 运行正常，我不觉得自己被骗了。”</p><p>如今，在智能产品的极简主义设计之下，似乎正隐藏着一个类似于 NFT 热潮的大型人工智能骗局。Rabbit 这类 AI 个人设备的“骗局”谜团之后，又会发生什么？可能会是继 BTC、ETH 和 NFT 之后新的泡沫。</p><p>参考链接：</p><p>https://paulogpd.bearblog.dev/en-rabbit-r1-its-a-scam/&nbsp;</p><p>https://cn.dataconomy.com/2024/01/15/%E5%A4%A7%E5%9E%8B%E5%8A%A8%E4%BD%9C%E6%A8%A1%E5%9E%8B-lam%E7%9A%84%E5%85%B4%E8%B5%B7/&nbsp;</p><p>https://medium.com/@ignacio.de.gregorio.noblejas/the-rabbit-r1-ais-first-big-scam-00f81131bf25&nbsp;</p><p>https://www.theverge.com/2024/5/2/24147159/rabbit-r1-review-ai-gadget?ref=wheresyoured.at&nbsp;</p><p class="editor-note">本文来自微信公众号“AI前线”（ID:ai-front），整理：华卫，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808059239462279</id>
            <title>暗战升级，Databricks 收购 Tabular，Iceberg 社区陷入动荡</title>
            <link>https://www.36kr.com/p/2808059239462279</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808059239462279</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 08:35:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Databricks, Iceberg, 收购, 标准
<br>
<br>
总结: Databricks 收购了 Tabular，引发了 Iceberg 的 Contributor Kanou Natsukawa 对 Iceberg 标准控制权的担忧。他认为 Databricks 可能会控制 Iceberg 标准，影响整个数据湖格式标准的竞争格局。这一事件引发了关于数据湖结构化存储标准的争议，Snowflake 和 Databricks 之间的暗战也在悄然展开。 </div>
                        <hr>
                    
                    <h2>1 事件<strong>&nbsp;</strong></h2><p>Databricks 收购了 Tabular。字少事大。</p><p>紧接着，最近刚刚发生的事件，Iceberg 的 Contributor Kanou Natsukawa 呼吁 Icerberg 的 PMC Chair 辞职，核心他的担忧是存在利益冲突。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_bbdbd4b721a9472eb0aefd2d9ec9f596@46958_oswg277625oswg1080oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>2 Kanou 意有所指，担心的是什么&nbsp;</h2><p>为什么 Kanou 有这个担心？他其实真正担心的是，鉴于 Tabular 是 Iceberg“背后”的商业公司，有多位 Iceberg 的 PMC 在 Tabular 任职。那么这次收购之后，很有可能 Databricks 会完全能够控制 Tabular 和 Iceberg，及其标准。“标准”——<strong>真正的担忧是 Databricks 控制 Iceberg 标准的风险</strong>。</p><h3>一箭双雕：Databricks 的战略意图&nbsp;</h3><p>Databricks 此举的战略意图不难看出。一方面，他们希望发展自家的 Delta Lake, 因为 Delta Lake 与 Iceberg 是直接竞争关系；另一方面，这也是在打击竞争对手 Snowflake。Snowflake 全面拥抱开放的湖仓标准，而 Iceberg 已经成为业界事实标准之一。通过收购 Tabular，Databricks 可以间接控制 Iceberg，从而在数据湖格式标准的竞争中占据优势地位。</p><h3>历史总是相似的&nbsp;</h3><p>当年 Oracle 收购 Mysql 是这个故事的翻版，Kanou 担心的正是这样的事情再次发生在 Iceberg 上。</p><blockquote><p>MySQL 原开发者为瑞典的 MySQL AB 公司，该公司于 2008 年被昇阳微系统（Sun Microsystems）收购。2009 年，甲骨文公司（Oracle）收购昇阳微系统公司，MySQL 成为 Oracle 旗下产品。&nbsp;</p><p>（引文： https://zh.wikipedia.org/zh-hans/MySQL）&nbsp;</p></blockquote><p>这一事件在当时引起了开源社区的广泛关注和争议。时至今日，MySQL 仍是活跃的开源项目，但在 Oracle 的影响下, 它的发展方向和节奏无疑发生了变化。Oracle 对 MySQL 的控制，也引发了开源社区对大公司介入开源项目的广泛讨论和反思。</p><p>Kanou 对 Databricks 收购 Tabular 的担忧, 与当年社区对 Oracle 收购 MySQL 的顾虑如出一辙。历史似乎在重演，只是这一次，舞台从开源数据库转移到了开源数据湖存储标准。</p><h3>Databricks 的意图可以说是明牌了。&nbsp;</h3><p>在之前关于 Redshift 的采访中，Databricks 的 VP 明确表达了对数据存储格式的“野心”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_14ac5b00a8f3458898e13ecdc35f9a81@46958_oswg83869oswg1080oswg105_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（引文：https://inpractise.com/articles/databricks-melting-the-snow）</p><h2>3 能够看到两强相争之时，都看中了数据湖结构化存储标准这个兵家必争之地。为什么会这样？&nbsp;</h2><p>因为传统的数据库引擎和未来 AI 模型多模态等引擎，去处理海量的额数据是一个多样性的处理过程。一方面数据是海量的，很难做到将海量的数据“喂”给不同的引擎，这样耗费的“数据搬运”或 ETL 成本太高；另一方面处理数据的引擎越来越多样。所以，必然会需要一个革命性地架构的改变。那么，今天 Snowflake 和 Databricks 的的数据的开放性格式标准或将是决定未来各方能走多远的一个关键技术。如果 Databricks 真的控制了 Iceberg，那么也就意味着很有可能 Icerberg 的发展会减缓，进而影响到支持 Iceberg 的 Snowflake。</p><h2>4 AI 时代数据架构的发展趋势&nbsp;</h2><p>AI 时代的计算与存储将是 M 对 N 的关系架构，区别于一直以来数据库的计算和存储绑定的 1 对 1 关系</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_4063e613339f4ef1b06cf87d15e9f114@46958_oswg128796oswg1080oswg524_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从<strong>云器科技</strong>此前的分享来看，湖仓一体会成为主流架构，而 Iceberg 已成为事实标准下一代的数据架构将会是：</p><p>一套数据，统一的元数据中心，具备*一致*性（其他层次上的数据用 Cache 抽象）</p><p>开放性，数据格式公开可访问</p><p>可插拔性，上层引擎 / 应用可以灵活的插在 Lakehouse 上（这对于新兴的 AI 引擎 / 应用至关重要）</p><p>关涛（云器科技联合创始人及 CTO）此前分享到，“开放的存储和元数据支持多引擎协作是 Data+AI 平台的演进方向。”</p><p>据此，不难理解 Snowflake 和 Databricks 会为此不惜重金布局“对线”。</p><h2>5 Snowflake 和 Databricks 的暗战<strong>&nbsp;</strong></h2><p>之前 Ryan Blue, Apache Iceberg PMC Chair 在 Iceberg Summit 2024 中谈及开放的存储格式正在掀起一场“革命”，并暗戳戳地阴阳了 Delta Lake。意思是本来没想把 Delta Lake 算进来，但想了想还是算上吧。满脸的勉强。</p><blockquote><p>we had this surprise realization a couple years ago when Snowflake and Redshift and other commercial data warehouses started adding support for Apache Iceberg. What's going on there? Why are they doing that? In order to answer that question... I think the central trend is that projects like Apache Iceberg, I would actually include Delta in this as well, have unlocked shared data warehouse storage.</p><p>（引自："Iceberg Summit 2024 Keynote: The Quite Revolution"）</p></blockquote><p>这次收购事件，可以看出 Databricks 毫不掩饰的讲出想釜底抽薪解决问题，为自己的 Delta Lake 开路</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_34f874b94a0c4fac90c0a95155883d12@46958_oswg283216oswg1080oswg348_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图：Databricks VP 的演讲）</p><p>这场竞争双方是不惜代价全力以赴的。在 Databricks VP 之前的一段访谈，谈到 Iceberg 和 Delta 的直接竞争，是一场非常决定性的战争，用了“WAR”这个词。</p><p>6 并非技术之争，而是“开放”与“控制”之争&nbsp;</p><p>Snowflake 在 2024/6/3 的发布会 Keynote 分享，数据是 AI 的基础设施... 以前是数据送给引擎去处理，未来 AI 时代是多种引擎，包括AI引擎，计算引擎要趋向数据。Data Centralization的理念是方向。</p><blockquote><p>"The AI Data Cloud is lighting up every corner of the enterprise."&nbsp;</p><p>"Data... is the foundation of AI"&nbsp;</p><p>-- Sridhar Ramaswamy, Snowflake CEO&nbsp;</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_aa50627e57ce4380877035e59c489f72@46958_oswg805614oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图：Snowflake Summit 2024 Keynote）</p><p>Snowflake 的产品经理 James Malone 在今天对 Tabular 的收购事件也发布了他的看法，他认为Databricks 收购 Tabular 彰显了 Databricks 的“独占”与“控制”思维：</p><ul><li>独占而非共创</li><li>谋求“全面控制”而非支持开放的技术社区</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_49d311017d7846bcb2b30bf7f96a278f@46958_oswg428838oswg772oswg572_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“开放标准本应由社区共同创建和维护，就像 Snowflake 新发布的 Polaris 那样，旨在促进生态共存。而 Databricks 的做法却恰恰相反，他们试图通过收购的方式来控制 Iceberg 标准，这种‘不能打败就收购’的心态，与开源精神背道而驰。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_9816840652cd4afb86c0250a98d0af69@46958_oswg725348oswg1080oswg1355_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>7 我们保持关注，希望 Iceberg 和技术社区能挺住&nbsp;</h2><p>资本的力量，如果用在助力技术研发和应用落地，可以推动行业进步，造福社会，是“Tech for Good”；而如果资本用于收购打压竞争对手时，就成了一种“资本之恶”。</p><p>Iceberg 能否在 Databricks 的控制下继续保持开放、中立, 现在还是一个未知数。业界对此表示担忧，但同时也寄望于 Iceberg 社区能够坚守开源初心，维护项目的独立性。Iceberg 的命运，或许将成为资本与开源技术博弈的一个缩影。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_b4efe048d7b745df8eee2b1417be92d4@46958_oswg398945oswg1080oswg623_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图：Iceberg 技术社区的讨论）</p><p>下周，Databricks 将召开年度发布会，而 Snowflake 的发布会也正在如火如荼地进行中。虽然两家巨头今年没有像去年那样选在同一时间异地开幕，但这丝毫不会减弱他们在数据领域的竞争激烈程度。相反，随着 Databricks 收购 Tabular 事件的发酵，两个海外数据平台巨头之争只会愈演愈烈。</p><p>人工智能正处在聚光灯的中心，各路科技公司都在追逐 AI 的绚丽光环。但在光环的背后，一场数据格式之争——关乎未来十年数据格式标准之争在暗处正在上演。</p><p><strong>作者简介：</strong></p><p>苏郡城，云器科技运营总监，云计算大数据领域专家。曾主导阿里云国际业务数据体系建设, 十余年一线数据化运营实战，助力企业实现数字化增长，热衷于技术社区分享。</p><p class="editor-note">本文来自微信公众号“InfoQ”（ID:infoqchina），作者：苏郡城，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808053700556165</id>
            <title>Stable Diffusion老板跑路开新坑，被抛下的SD3开源成了烂摊子</title>
            <link>https://www.36kr.com/p/2808053700556165</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808053700556165</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 08:34:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stability AI, Schelling AI, Emad Mostaque, 大语言模型
<br>
<br>
总结: Stability AI前CEO的新公司Schelling AI，致力于“去中心化人工智能系统”，Emad Mostaque宣布新公司消息，业务方向集中在政务、医疗保健和教育，强调人工智能必须开源透明。Stability AI因收入模式不明朗频频被曝“入不敷出”，面临现金短缺，曾考虑出售公司，发布的Stable Diffusion 3后续开源变得迷雾重重。 </div>
                        <hr>
                    
                    <p>Stability AI前CEO的新公司，终于浮出水面：</p><p><strong>Schelling AI</strong>，就如他当初辞职跑路时所说，致力于“去中心化人工智能系统”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_a1b9c0a9059c43f8807e1baca1b06f85@46958_oswg633403oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>这一消息，由<strong>Emad Mostaque</strong>本人在最新一次公开亮相中现场宣布。</p><p>官网域名schelling.ai目前会跳转到官方𝕏，而官方𝕏还是空号。‍</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_a87a1e8a21ef42bdbe124bba77d5707f@46958_oswg126285oswg1080oswg550_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>只关注了一个账号，是……索尼？？总之很神秘。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_0dbc0da98e3f4fb189b0840db19ecf00@46958_oswg89946oswg1080oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前仅有的消息是新业务与大语言模型相关，业务方向将集中在政务、医疗保健和教育，换句话说，<strong>toB</strong>。</p><p>Emad在活动中介绍“将大模型想象为一名毕业生——你仍然需要对他们进行工作培训”。</p><p>他还强调：</p><blockquote><p>人工智能必须开源且透明，才能造福全社会，而不仅仅是少数人。</p></blockquote><p>然而此时，距离他抛下Stable Diffusion及其背后公司Stability AI，刚刚过去2个月时间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_4fb6b500745047be8374f77e69f7889b@46958_oswg588554oswg690oswg690_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>被抛下的“稳定AI”</h2><p>Emad的辞职，属实有些突然。</p><p>彼时Stable Diffusion 3刚发布没多久，核心团队却被曝已经集体离职。</p><p>正在动荡之中，身为CEO的Emad紧跟着辞职+退出董事会，无疑是扔下了一枚重磅炸弹，让外界对Stable Diffusion的未来感到担忧。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3e874ee9f7a94f098eac2c463176c315@46958_oswg242639oswg1080oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当时曝出的原因是，尽管表面上是“和平分手”，但Emad的辞职实际与核心团队出走、和投资人产生矛盾有关。</p><p>事实上，Stability AI虽然靠Stable Diffusion收获广泛关注，但因为Stable Diffusion的开源模式，其<strong>收入模式并不明朗，频频被曝“入不敷出”</strong>。</p><p>从去年开始，就不断有<strong>Stability AI考虑出售公司的传闻</strong>流出。</p><p>到了今年5月，据The Information消息，这家初创公司已经面临严重现金短缺：第一季度收入不到500万美元，而亏损超过了3000万美元。</p><p>最新还被发现官方账号取关了旗下工作室DeepFolyd，或许又有什么变故。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_748c20d75ff646628c94c5228681c890@46958_oswg535473oswg1080oswg861_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，尽管赶在2月份发布了Stable Diffusion的最新版本Stable Diffusion 3（SD3），全面提升了SD的文字渲染能力、多主题提示能力和图像质量，但后续SD3的开源，也变得迷雾重重。</p><p>一开始，官方说的是搞完RLHF就开源，结果大家伙等了3个多月，官方放出的还是只有API。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_38c406385c314b34b260eff07586200d@46958_oswg363357oswg1080oswg410_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最新消息是，Stability AI现任CTO兼联席临时CEO <strong>Christian Laforte</strong>承诺，会在6月12日推出SD3的公开预览版。</p><p>但也有网友提出了新的质疑：</p><blockquote><p>StablityAI正在搞一个名为SD3 “Medium”的模型，并假装他们在开放SD3的源代码。他们还有Large和X-Large版本没有发布，这才是人们原本期待的SD3。</p><p>骗子。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_207aea0f7bbe44a880179301b2083e39@46958_oswg438307oswg1080oswg1096_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也有人解释说，SD3最初的公告中就提到，这是一系列800M到8B参数规模的模型。论文中也展示了2B模型的一些示例，尽管不如8B模型，但效果也还行。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3048ec916c1b4d32a957c35685e9b81e@46958_oswg644838oswg1080oswg519_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>结合这次公开亮相中Emad对“开源”、“透明”的强调，事情就有点emmm……</p><p>Emad在任职期间，也被曝出过不少黑料，包括：</p><p>学历/工作经验造假、拖欠员工工资、诓骗投资人、挪用公款等。</p><p>Stability AI的联创Cyrus Hodes甚至还就“欺诈和挪用公款”一事专门起诉过Emad。</p><p>……</p><p>这位备受关注、又充满争议的创业者的新项目，你看好吗？欢迎在评论区留下你的看法？</p><p>参考链接[1]https://x.com/irfan3/status/1798186824122388550[2]http://schelling.ai[3]https://www.theregister.com/2024/06/03/stable_diffusion_3_release_schedule/</p><p class="editor-note">本文来自微信公众号“量子位”（ID:QbitAI），作者：鱼羊 梦晨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808053569500801</id>
            <title>斯坦福让“GPU高速运转”的新工具火了，比FlashAttention2更快</title>
            <link>https://www.36kr.com/p/2808053569500801</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808053569500801</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 08:28:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI算力资源, 斯坦福新研究, GPU运行效率, ThunderKittens
<br>
<br>
总结: 当下AI算力资源紧张，斯坦福新研究提升GPU运行效率，通过ThunderKittens工具设计，简化AI内核编写，充分利用底层硬件能力。 </div>
                        <hr>
                    
                    <p>AI算力资源越发紧张的当下，斯坦福新研究将GPU运行效率再提升一波——</p><p><strong>内核只有100行代码，让H100比使用FlashAttention-2，性能还要提升30%</strong>。</p><p>怎么做到的？</p><p>研究人员从<strong>“硬件实际需要什么？如何满足这些需求？”</strong>这两个问题出发，设计了 一个嵌入式CUDA DSL工具，名为<strong>ThunderKittens</strong>（暂且译为雷猫）。</p><p>雷猫可简化AI内核的编写，同时充分利用底层硬件能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_27dd12a7f66a4d32a89cbb949522c690@46958_oswg933282oswg1080oswg1029_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，雷猫的主要抽象是寄存器和共享内存中的<strong>小型张量块</strong>（tile），和目前GPU中对小矩阵乘法的优化相匹配。</p><p>通过操作这些tile，开发者可相对简单地编写代码，充分利用张量核心、异步数据传输和共享内存等硬件特性。</p><p>使用雷猫实现的注意力机制内核，代码量少且能实现很高的硬件利用率，性能超过直接使用底层库（如Cutlass）。</p><p>详细讨论过程以及雷猫是怎么设计出的，研究人员以“GPUs Go Brrr”为题，发在了斯坦福Hazy Research的Blog网站上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_c60bbe84b8f2496fb8579d072f365817@46958_oswg6163oswg492oswg102_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>网友们对此讨论也十分热烈。</p><p>有网友表示读这篇Blog时，让他想起了初次了解超标量CPU架构时的惊讶感受：</p><blockquote><p>GPU真的达到了新高度。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_8b0267ac745a4facacad1fe7ccd4b9c3@46958_oswg76922oswg1080oswg220_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有网友表示：</p><blockquote><p>这篇文章重新点燃了我在CS 149并行编程课中所感受到的快乐。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_6011b44c5ce946fab3fa3df6fdc973ac@46958_oswg55676oswg1080oswg190_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>H100里有什么？</strong></h2><p>斯坦福研究人员以H100为例，探讨了优化GPU的方法。</p><p>首先，回顾一下H100的硬件细节，这对于接下来的讨论非常重要。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_e97107d1dcf6473d8e4ca281594bbf22@46958_oswg280187oswg1080oswg366_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一个H100 SXM GPU包含：</p><p>（1）80GB的HBM3内存，带宽为3TB/s（实际带宽略低）。</p><p>（2）50MB的L2缓存，带宽为12TB/s，在GPU上分为两个25MB的部分，通过交叉开关连接（这个交叉开关表现不佳）。</p><p>（3）132个流式多处理器（SM），每个包含：</p><p>高达227KB的共享内存位于256KB的L1缓存中（这些加起来的带宽大约33TB/s）。</p><p>一个张量内存加速器（TMA）——这是英伟达Hopper架构中的一种新硬件组件，可进行异步地址生成和内存获取，还能促进片上内存网络。</p><p>4个子单元，每个含：一个warp scheduler；512个向量寄存器（每个包含32个4字节的词）；一个用于执行矩阵乘法的张量核心；一组内置指令，如求和、乘法等，这些指令能够并行操作这些向量寄存器。</p><p>除了这些，一个GPU还包括内存控制器、指令缓存……但对于这项研究而言不重要。</p><p>重要的是，所有的计算都发生在流式多处理器中，<strong>大部分计算是在寄存器中</strong>。</p><p>H100 GPU拥有989 TFLOPs的半精度矩阵乘法计算能力，以及约60 TFLOPs的“其他”计算能力。因此，每个周期内张量核心被使用时，至少能达到94%的硬件利用率。而张量核心不被使用时，硬件的利用率不会超过6%。</p><p>换句话说：</p><p><strong>H100的利用率=张量核心活跃周期的百分比+/- 6%。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_1282f011b48d4bfcb4f4796a8615d579@46958_oswg10796oswg1044oswg134_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以要充分发挥H100的能力，<strong>关键是保持张量核心持续运算</strong>。</p><h2>榨干H100，要注意什么？</h2><p>然鹅，要保持张量核心持续运行并不容易。</p><p>研究人员发现GPU硬件具有一些特性，对于保持矩阵乘法的运行非常重要：</p><p>WGMMA指令虽然是必要的，但使用起来颇为麻烦。</p><p>共享内存的速度并不如预期的快，使用时还需格外注意。</p><p>生成地址的成本较高。</p><p>保持高占用率对于提升性能是有益的，寄存器至关重要。</p><p>这些特性在非H100 GPU上也有所适用，在H100上更加典型，就拿RTX 4090来说，相比H100处理起来简单得多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_224ca61686a74aa3b770914eed462752@46958_oswg793838oswg1080oswg356_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以接下来还是以H100为例，展开探讨这几点特性。</p><h3>WGMMA指令</h3><p>H100引入了一套新的指令集，名为“warp group matrix multiply accumulate”（在PTX中为wgmma.mma_async，在SASS中为HGMMA/IGMMA/QGMMA/BGMMA）。</p><p>要理解这些指令的特点，需回顾以往张量核心的使用方式。</p><p>早期GPU中的张量核心指令如wmma.mma.sync和mma.sync，要求SM一个子单元内的32个线程的一个warp同步传输数据块至张量核心并等待结果。</p><p>wgmma.mma_async指令则不同。它允许128个连续线程跨SM所有子单元协作同步，并从共享内存及寄存器（可选）异步启动矩阵乘法。这使得这些warp在等待矩阵乘法结果时可以处理其他任务。</p><p>研究人员通过微观基准测试，发现这些指令是充分发挥H100计算能力所必需的。没有这些指令，GPU的峰值利用率大约只有63%。</p><p>他们推测，这是由于张量核心需要从本地资源维持一个深度硬件pipeline。</p><p>然而，这些指令的内存布局极其复杂。未重排的共享内存布局合并性差，需要额外的L2带宽。重排的内存布局记录不准确，研究人员花费了大量时间才弄明白。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_c42f0144d38c4d79b638d3c00f8004e8@46958_oswg368933oswg1080oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最终发现，这些布局只适用于特定矩阵形状，并与wgmma.mma_async指令的其他部分不兼容，例如硬件仅在未重排的布局下转置子矩阵。</p><p>此外，未重排的wgmma布局内存合并性差且有bank conflicts。尽管TMA和L2缓存在如flash attention这类内核上能较好地掩盖这些问题，但要充分利用硬件，必须精心控制内存请求的合并和避免bank conflicts。</p><p>尽管有这些问题，但这些指令对于充分利用H100是必不可少的。没有它们，GPU的潜在性能就损失了37%。</p><h3><strong>共享内存</strong></h3><p>共享内存的单次访问延迟约为30个周期（这也与研究人员观察的相符），这看似不多，但在这段时间内，SM的张量核心几乎能完成两次完整的32x32方阵乘法。</p><p>以前的研究，如Flash Attention，研究人员更多关注的是HBM-SRAM的瓶颈。但随着HBM速度的提升和张量核心的快速发展，即使是共享内存的相对较小延迟也变得尤为关键。</p><p>由于共享内存被分为32个独立的存储单元，处理不当可能会引发bank conflicts，即同一个内存bank同时被多个请求访问，这种情况会导致请求被序列化。研究人员实验后认为，这会显著拖慢内核速度，且wgmma与mma指令需要的寄存器布局容易受到bank conflicts的影响。</p><p>解决方法是通过各种“重排”模式调整共享内存的配置，避免bank conflicts，但细节要处理得当。</p><p>此外研究人员发现，尽可能避免在寄存器和共享内存之间的移动数据非常重要。可能的话，可使用内置硬件（如wgmma和TMA指令）进行异步数据传输。实在没法子了，再使用warp进行同步数据传输。</p><h3>地址生成</h3><p>H100还有一个有趣的特性，其张量核心和内存都足够快，以至于仅生成用于获取数据的内存地址就占用了芯片的大量资源，特别是加入复杂的交错或重排模式时，这种情况更为明显。</p><p>研究人员表示，英伟达提供了张量内存加速器（TMA），似乎就是已经意识到了这个问题。</p><p>TMA允许用户在全局和共享内存中指定多维张量布局，命令其异步提取张量的一部分，并在完成后触发一个屏障。这大大节省了地址生成的开销，并简化了pipelines的构建。</p><p>研究人员认为，TMA对于充分发挥H100的潜力至关重要，可能比wgmma.mma_async更为关键。</p><p>它不仅节省了寄存器资源和指令派发，还提供了如异步在全局内存上执行归约等实用功能——这在处理复杂的反向内核时尤其有用。</p><p>虽然TMA的重排模式解读有一定难度，需要进行一些逆向工程，但研究人员表示，相比之下，他们在这上面遇到的问题要少得多。</p><h3>占用率</h3><p>占用率指的是在GPU的相同执行硬件上同时调度的线程数。每个周期，SM的某一子单元的warp scheduler会尝试向准备就绪的warp线程发出指令。</p><p>研究人员认为，英伟达采用这种模型可以更容易地保持硬件的满负荷运行。例如，当一个线程warp等待执行矩阵乘法时，另一个可以被指派执行使用快速指数运算的指令。</p><p>在某些方面，H100对占用率的依赖程度低于前几代硬件。</p><p>它的异步特性使得即使单一指令流也能使多个硬件部分同时持续运行，包括读取内存、执行矩阵乘法、进行共享内存的归约，同时还能在寄存器上进行计算。</p><p>但高占用率容易隐藏缺陷或同步问题，一个设计良好的pipeline即使在占用率不高的情况下也能运行得相当快。</p><p>据研究人员观察，英伟达在设计GPU时确实考虑到了占用率。且由于存在足够多的同步操作和足够多的错误可能性，根据他们的经验，提高占用率通常能显著增加硬件的实际利用率。</p><p>此外，相比H100，A100和RTX 4090更依赖同步指令调度，占用率更重要。</p><h2>用雷猫优化GPU</h2><p>鉴于以上情况，如何才能更轻松地编写所需的内核类型，同时充分发挥硬件的全部潜力？</p><p>雷猫（ThunderKittens）登场了。</p><p>这是一个嵌入在CUDA中的DSL，本是斯坦福研究人员设计出来给自己内部使用的，后来发现还真挺好使。</p><p>Ps：起这么个名，一是他们觉得小猫很可爱，二来他们觉得大伙儿在代码中输入kittens::会很有趣。</p><p>具体来说，雷猫包含四种模板类型：</p><p>寄存器tiles：在寄存器文件上表示二维张量。</p><p>寄存器向量：在寄存器文件上表示一维张量。</p><p>共享tiles：在共享内存中表示二维张量。</p><p>共享向量：在共享内存中表示一维张量。</p><p>tiles通过高度、宽度和布局进行参数化；寄存器向量通过长度和布局进行参数化；而共享向量仅通过长度进行参数化，通常不会遇到bank conflicts问题。</p><p>此外，研究人员提供了一系列操作来处理这些张量，既可在warp级别使用，也可用于多个warp协作，包含初始化器，如将共享向量清零；一元操作，如exp；二元操作，如mul；行/列操作，例如行求和。</p><p>雷猫作为一个嵌入到CUDA中的库，其提供的抽象层在遇到不支持的功能时能够很好地处理。如果雷猫缺少某些功能，可以直接扩展它来实现你想要的效果。</p><p>以Tri的flash attention算法为例，在实际应用中，即使是使用英伟达的Cutlass库，实现起来也是相当复杂。</p><p>以下是一个在RTX 4090上使用雷猫编写的简单flash attention内核的示例。</p><p>总共约60行CUDA代码，硬件利用率达到了75%。代码复杂性主要在于算法本身，而非交织模式或寄存器布局。</p><p>#define&nbsp;NUM_WORKERS&nbsp;16&nbsp;//&nbsp;This&nbsp;kernel&nbsp;uses&nbsp;16&nbsp;workers&nbsp;in&nbsp;parallel&nbsp;per&nbsp;block,&nbsp;to&nbsp;help&nbsp;issue&nbsp;instructions&nbsp;more&nbsp;quickly.using&nbsp;namespace&nbsp;kittens;&nbsp;//&nbsp;this&nbsp;kernel&nbsp;only&nbsp;handles&nbsp;headdim=64&nbsp;for&nbsp;simplicity.&nbsp;Also&nbsp;n&nbsp;should&nbsp;be&nbsp;a&nbsp;multiple&nbsp;of&nbsp;256&nbsp;here.__global__&nbsp;void&nbsp;attend_ker64(int&nbsp;n,&nbsp;const&nbsp;bf16*&nbsp;__restrict__&nbsp;__q__,&nbsp;const&nbsp;bf16*&nbsp;__restrict__&nbsp;__k__,&nbsp;const&nbsp;bf16*&nbsp;__restrict__&nbsp;__v__,&nbsp;bf16*&nbsp;__o__)&nbsp;{ &nbsp;&nbsp;&nbsp;auto&nbsp;warpid&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;kittens::warpid(); &nbsp;&nbsp;&nbsp;auto&nbsp;block_start&nbsp;&nbsp;&nbsp;=&nbsp;blockIdx.x*(n*64); &nbsp;&nbsp;&nbsp;const&nbsp;bf16&nbsp;*_q&nbsp;=&nbsp;__q__&nbsp;+&nbsp;block_start,&nbsp;*_k&nbsp;=&nbsp;__k__&nbsp;+&nbsp;block_start,&nbsp;*_v&nbsp;=&nbsp;__v__&nbsp;+&nbsp;block_start; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bf16&nbsp;*_o&nbsp;=&nbsp;__o__&nbsp;+&nbsp;block_start; &nbsp;&nbsp;&nbsp;extern&nbsp;__shared__&nbsp;alignment_dummy&nbsp;__shm[];&nbsp;//&nbsp;this&nbsp;is&nbsp;the&nbsp;CUDA&nbsp;shared&nbsp;memory &nbsp;&nbsp;&nbsp;shared_allocator&nbsp;al((int*)&amp;__shm[0]); &nbsp;&nbsp;&nbsp;//&nbsp;K&nbsp;and&nbsp;V&nbsp;live&nbsp;in&nbsp;shared&nbsp;memory&nbsp;--&nbsp;this&nbsp;is&nbsp;about&nbsp;all&nbsp;that&nbsp;will&nbsp;fit. &nbsp;&nbsp;&nbsp;st_bf_1x4&lt;ducks::st_layout::swizzle&gt;&nbsp;(&amp;k_smem)[NUM_WORKERS]&nbsp;=&nbsp;al.allocate&lt;st_bf_1x4&lt;ducks::st_layout::swizzle&gt;,&nbsp;NUM_WORKERS&gt;(); &nbsp;&nbsp;&nbsp;st_bf_1x4&lt;ducks::st_layout::swizzle&gt;&nbsp;(&amp;v_smem)[NUM_WORKERS]&nbsp;=&nbsp;al.allocate&lt;st_bf_1x4&lt;ducks::st_layout::swizzle&gt;,&nbsp;NUM_WORKERS&gt;(); &nbsp;&nbsp;&nbsp;//&nbsp;Initialize&nbsp;all&nbsp;of&nbsp;the&nbsp;register&nbsp;tiles. &nbsp;&nbsp;&nbsp;rt_bf_1x4&lt;&gt;&nbsp;q_reg,&nbsp;k_reg,&nbsp;v_reg;&nbsp;//&nbsp;v_reg&nbsp;need&nbsp;to&nbsp;be&nbsp;swapped&nbsp;into&nbsp;col_l &nbsp;&nbsp;&nbsp;rt_fl_1x1&lt;&gt;&nbsp;att_block; &nbsp;&nbsp;&nbsp;rt_bf_1x1&lt;&gt;&nbsp;att_block_mma; &nbsp;&nbsp;&nbsp;rt_fl_1x4&lt;&gt;&nbsp;o_reg; &nbsp;&nbsp;&nbsp;rt_fl_1x1&lt;&gt;::col_vec&nbsp;max_vec_last,&nbsp;max_vec;&nbsp;//&nbsp;these&nbsp;are&nbsp;column&nbsp;vectors&nbsp;for&nbsp;the&nbsp;attention&nbsp;block &nbsp;&nbsp;&nbsp;rt_fl_1x1&lt;&gt;::col_vec&nbsp;norm_vec_last,&nbsp;norm_vec;&nbsp;//&nbsp;these&nbsp;are&nbsp;column&nbsp;vectors&nbsp;for&nbsp;the&nbsp;attention&nbsp;block &nbsp;&nbsp;&nbsp;int&nbsp;qo_blocks&nbsp;=&nbsp;n&nbsp;/&nbsp;(q_reg.rows*NUM_WORKERS),&nbsp;kv_blocks&nbsp;=&nbsp;n&nbsp;/&nbsp;(q_reg.rows*NUM_WORKERS); &nbsp;&nbsp;&nbsp;for(auto&nbsp;q_blk&nbsp;=&nbsp;0;&nbsp;q_blk&nbsp;&lt;&nbsp;qo_blocks;&nbsp;q_blk++)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;each&nbsp;warp&nbsp;loads&nbsp;its&nbsp;own&nbsp;Q&nbsp;tile&nbsp;of&nbsp;16x64,&nbsp;and&nbsp;then&nbsp;multiplies&nbsp;by&nbsp;1/sqrt(d) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load(q_reg,&nbsp;_q&nbsp;+&nbsp;(q_blk*NUM_WORKERS&nbsp;+&nbsp;warpid)*q_reg.num_elements,&nbsp;q_reg.cols); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mul(q_reg,&nbsp;q_reg,&nbsp;__float2bfloat16(0.125f));&nbsp;//&nbsp;temperature&nbsp;adjustment &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;zero&nbsp;flash&nbsp;attention&nbsp;L,&nbsp;M,&nbsp;and&nbsp;O&nbsp;registers. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;neg_infty(max_vec);&nbsp;//&nbsp;zero&nbsp;registers&nbsp;for&nbsp;the&nbsp;Q&nbsp;chunk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;zero(norm_vec); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;zero(o_reg); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;iterate&nbsp;over&nbsp;k,&nbsp;v&nbsp;for&nbsp;these&nbsp;q's&nbsp;that&nbsp;have&nbsp;been&nbsp;loaded &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for(auto&nbsp;kv_idx&nbsp;=&nbsp;0;&nbsp;kv_idx&nbsp;&lt;&nbsp;kv_blocks;&nbsp;kv_idx++)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;each&nbsp;warp&nbsp;loads&nbsp;its&nbsp;own&nbsp;chunk&nbsp;of&nbsp;k,&nbsp;v&nbsp;into&nbsp;shared&nbsp;memory &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load(v_smem[warpid],&nbsp;_v&nbsp;+&nbsp;(kv_idx*NUM_WORKERS&nbsp;+&nbsp;warpid)*q_reg.num_elements,&nbsp;q_reg.cols); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load(k_smem[warpid],&nbsp;_k&nbsp;+&nbsp;(kv_idx*NUM_WORKERS&nbsp;+&nbsp;warpid)*q_reg.num_elements,&nbsp;q_reg.cols); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;__syncthreads();&nbsp;//&nbsp;we&nbsp;need&nbsp;to&nbsp;make&nbsp;sure&nbsp;all&nbsp;memory&nbsp;is&nbsp;loaded&nbsp;before&nbsp;we&nbsp;can&nbsp;begin&nbsp;the&nbsp;compute&nbsp;phase &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;now&nbsp;each&nbsp;warp&nbsp;goes&nbsp;through&nbsp;all&nbsp;of&nbsp;the&nbsp;subtiles,&nbsp;loads&nbsp;them,&nbsp;and&nbsp;then&nbsp;does&nbsp;the&nbsp;flash&nbsp;attention&nbsp;internal&nbsp;alg. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for(int&nbsp;subtile&nbsp;=&nbsp;0;&nbsp;subtile&nbsp;&lt;&nbsp;NUM_WORKERS;&nbsp;subtile++)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load(k_reg,&nbsp;k_smem[subtile]);&nbsp;//&nbsp;load&nbsp;k&nbsp;from&nbsp;shared&nbsp;into&nbsp;registers &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;zero(att_block);&nbsp;//&nbsp;zero&nbsp;16x16&nbsp;attention&nbsp;tile &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mma_ABt(att_block,&nbsp;q_reg,&nbsp;k_reg,&nbsp;att_block);&nbsp;//&nbsp;Q@K.T &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copy(norm_vec_last,&nbsp;norm_vec); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copy(max_vec_last,&nbsp;&nbsp;max_vec); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;row_max(max_vec,&nbsp;att_block,&nbsp;max_vec);&nbsp;//&nbsp;accumulate&nbsp;onto&nbsp;the&nbsp;max_vec &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sub_row(att_block,&nbsp;att_block,&nbsp;max_vec);&nbsp;//&nbsp;subtract&nbsp;max&nbsp;from&nbsp;attention&nbsp;--&nbsp;now&nbsp;all&nbsp;&lt;=0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;exp(att_block,&nbsp;att_block);&nbsp;//&nbsp;exponentiate&nbsp;the&nbsp;block&nbsp;in-place. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sub(max_vec_last,&nbsp;max_vec_last,&nbsp;max_vec);&nbsp;//&nbsp;subtract&nbsp;new&nbsp;max&nbsp;from&nbsp;old&nbsp;max&nbsp;to&nbsp;find&nbsp;the&nbsp;new&nbsp;normalization. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;exp(max_vec_last,&nbsp;max_vec_last);&nbsp;//&nbsp;exponentiate&nbsp;this&nbsp;vector&nbsp;--&nbsp;this&nbsp;is&nbsp;what&nbsp;we&nbsp;need&nbsp;to&nbsp;normalize&nbsp;by. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mul(norm_vec,&nbsp;norm_vec,&nbsp;max_vec_last);&nbsp;//&nbsp;and&nbsp;the&nbsp;norm&nbsp;vec&nbsp;is&nbsp;now&nbsp;normalized. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;row_sum(norm_vec,&nbsp;att_block,&nbsp;norm_vec);&nbsp;//&nbsp;accumulate&nbsp;the&nbsp;new&nbsp;attention&nbsp;block&nbsp;onto&nbsp;the&nbsp;now-rescaled&nbsp;norm_vec &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;div_row(att_block,&nbsp;att_block,&nbsp;norm_vec);&nbsp;//&nbsp;now&nbsp;the&nbsp;attention&nbsp;block&nbsp;is&nbsp;correctly&nbsp;normalized &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mul(norm_vec_last,&nbsp;norm_vec_last,&nbsp;max_vec_last);&nbsp;//&nbsp;normalize&nbsp;the&nbsp;previous&nbsp;norm&nbsp;vec&nbsp;according&nbsp;to&nbsp;the&nbsp;new&nbsp;max &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;div(norm_vec_last,&nbsp;norm_vec_last,&nbsp;norm_vec);&nbsp;//&nbsp;normalize&nbsp;the&nbsp;previous&nbsp;norm&nbsp;vec&nbsp;according&nbsp;to&nbsp;the&nbsp;new&nbsp;norm &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copy(att_block_mma,&nbsp;att_block);&nbsp;//&nbsp;convert&nbsp;to&nbsp;bf16&nbsp;for&nbsp;mma_AB &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load(v_reg,&nbsp;v_smem[subtile]);&nbsp;//&nbsp;load&nbsp;v&nbsp;from&nbsp;shared&nbsp;into&nbsp;registers. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rt_bf_1x4&lt;ducks::rt_layout::col&gt;&nbsp;&amp;v_reg_col&nbsp;=&nbsp;swap_layout_inplace(v_reg);&nbsp;//&nbsp;this&nbsp;is&nbsp;a&nbsp;reference&nbsp;and&nbsp;the&nbsp;call&nbsp;has&nbsp;invalidated&nbsp;v_reg &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mul_row(o_reg,&nbsp;o_reg,&nbsp;norm_vec_last);&nbsp;//&nbsp;normalize&nbsp;o_reg&nbsp;in&nbsp;advance&nbsp;of&nbsp;mma_AB'ing&nbsp;onto&nbsp;it &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mma_AB(o_reg,&nbsp;att_block_mma,&nbsp;v_reg_col,&nbsp;o_reg);&nbsp;//&nbsp;mfma&nbsp;onto&nbsp;o_reg&nbsp;with&nbsp;the&nbsp;local&nbsp;attention@V&nbsp;matmul. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;__syncthreads();&nbsp;//&nbsp;we&nbsp;need&nbsp;to&nbsp;make&nbsp;sure&nbsp;all&nbsp;warps&nbsp;are&nbsp;done&nbsp;before&nbsp;we&nbsp;can&nbsp;start&nbsp;loading&nbsp;the&nbsp;next&nbsp;kv&nbsp;chunk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;store(_o&nbsp;+&nbsp;(q_blk*NUM_WORKERS&nbsp;+&nbsp;warpid)*q_reg.num_elements,&nbsp;o_reg,&nbsp;q_reg.cols);&nbsp;//&nbsp;write&nbsp;out&nbsp;o.&nbsp;compiler&nbsp;has&nbsp;an&nbsp;issue&nbsp;with&nbsp;register&nbsp;usage&nbsp;if&nbsp;d&nbsp;is&nbsp;made&nbsp;constexpr&nbsp;q_reg.rows&nbsp;:/ &nbsp;&nbsp;&nbsp;}}&nbsp;</p><p>关于TMA、WGMMA、交织模式和描述符的复杂性，这里展示了一个使用雷猫编写的，针对H100的FlashAttention-2算法的前向传递示例。</p><p>template&lt;int&nbsp;D&gt;__global__&nbsp;&nbsp;__launch_bounds__((NUM_WORKERS)*kittens::WARP_THREADS,&nbsp;2)void&nbsp;fwd_attend_ker_dim(int&nbsp;N,&nbsp;const&nbsp;CUtensorMap*&nbsp;tma_q,&nbsp;const&nbsp;CUtensorMap*&nbsp;tma_k,&nbsp;const&nbsp;CUtensorMap*&nbsp;tma_v,&nbsp;CUtensorMap*&nbsp;tma_o)&nbsp;{ &nbsp;&nbsp;&nbsp;extern&nbsp;__shared__&nbsp;int&nbsp;__shm[];&nbsp;//&nbsp;this&nbsp;is&nbsp;the&nbsp;CUDA&nbsp;shared&nbsp;memory &nbsp;&nbsp;&nbsp;tma_swizzle_allocator&nbsp;al((int*)&amp;__shm[0]); &nbsp;&nbsp;&nbsp;constexpr&nbsp;int&nbsp;tile_width&nbsp;=&nbsp;fwd_attend_ker_tile_dims&lt;D&gt;::tile_width;&nbsp;//&nbsp;constants &nbsp;&nbsp;&nbsp;constexpr&nbsp;int&nbsp;qo_height&nbsp;&nbsp;=&nbsp;fwd_attend_ker_tile_dims&lt;D&gt;::qo_height; &nbsp;&nbsp;&nbsp;constexpr&nbsp;int&nbsp;kv_height&nbsp;&nbsp;=&nbsp;fwd_attend_ker_tile_dims&lt;D&gt;::kv_height; &nbsp;&nbsp;&nbsp;st_bf&lt;qo_height,&nbsp;tile_width,&nbsp;layout_q&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&amp;q_smem)&nbsp;&nbsp;&nbsp;[NUM_WARPGROUPS]&nbsp;=&nbsp;al.allocate&lt;st_bf&lt;qo_height,&nbsp;tile_width,&nbsp;layout_q&gt;,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NUM_WARPGROUPS&gt;(); &nbsp;&nbsp;&nbsp;st_bf&lt;kv_height,&nbsp;tile_width,&nbsp;layout_k&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&amp;k_smem)[2][NUM_WORKERS_KV]&nbsp;=&nbsp;al.allocate&lt;st_bf&lt;kv_height,&nbsp;tile_width,&nbsp;layout_k&gt;,&nbsp;2,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NUM_WORKERS_KV&gt;(); &nbsp;&nbsp;&nbsp;st_bf&lt;kv_height,&nbsp;tile_width,&nbsp;layout_v&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&amp;v_smem)[2][NUM_WORKERS_KV]&nbsp;=&nbsp;al.allocate&lt;st_bf&lt;kv_height,&nbsp;tile_width,&nbsp;layout_v&gt;,&nbsp;2,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NUM_WORKERS_KV&gt;(); &nbsp;&nbsp;&nbsp;int&nbsp;tic&nbsp;=&nbsp;0,&nbsp;toc&nbsp;=&nbsp;1; &nbsp;&nbsp;&nbsp;rt_fl&lt;1,&nbsp;kv_height&gt;&nbsp;att_block; &nbsp;&nbsp;&nbsp;rt_bf&lt;1,&nbsp;kv_height&gt;&nbsp;att_block_mma; &nbsp;&nbsp;&nbsp;rt_fl&lt;1,&nbsp;qo_height&gt;&nbsp;o_prev; &nbsp;&nbsp;&nbsp;col_vec&lt;rt_fl&lt;1,&nbsp;kv_height&gt;&gt;&nbsp;max_vec_last,&nbsp;max_vec; &nbsp;&nbsp;&nbsp;col_vec&lt;rt_fl&lt;1,&nbsp;kv_height&gt;&gt;&nbsp;norm_vec_last,&nbsp;norm_vec; &nbsp;&nbsp;&nbsp;int&nbsp;warpid&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;kittens::warpid(); &nbsp;&nbsp;&nbsp;int&nbsp;warpgroupid&nbsp;=&nbsp;warpid/kittens::WARPGROUP_WARPS; &nbsp;&nbsp;&nbsp;int&nbsp;kv_blocks&nbsp;=&nbsp;N&nbsp;/&nbsp;(NUM_WORKERS_KV*k_smem[0][0].rows); &nbsp;&nbsp;&nbsp;__shared__&nbsp;uint64_t&nbsp;qsmem_barrier,&nbsp;kvsmem_barrier;//,&nbsp;vsmem_barrier; &nbsp;&nbsp;&nbsp;int&nbsp;q_phasebit&nbsp;=&nbsp;0; &nbsp;&nbsp;&nbsp;int&nbsp;kv_phasebit&nbsp;=&nbsp;0; &nbsp;&nbsp;&nbsp;if&nbsp;(threadIdx.x&nbsp;==&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::init_barrier&lt;st_bf&lt;qo_height,&nbsp;tile_width,&nbsp;layout_q&gt;,&nbsp;NUM_WARPGROUPS&gt;(qsmem_barrier,&nbsp;1); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::init_barrier&lt;st_bf&lt;kv_height,&nbsp;tile_width,&nbsp;layout_k&gt;,&nbsp;NUM_WORKERS_KV*2&gt;(kvsmem_barrier,&nbsp;1);&nbsp; &nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;if&nbsp;(warpid&nbsp;==&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(int&nbsp;wg&nbsp;=&nbsp;0;&nbsp;wg&nbsp;&lt;&nbsp;NUM_WORKERS/kittens::WARPGROUP_WARPS;&nbsp;wg++)&nbsp;{&nbsp;//&nbsp;load&nbsp;q &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;tile_idx&nbsp;=&nbsp;(blockIdx.y&nbsp;*&nbsp;NUM_WARPGROUPS&nbsp;*&nbsp;gridDim.x)&nbsp;+&nbsp;(blockIdx.x&nbsp;*&nbsp;NUM_WARPGROUPS)&nbsp;+&nbsp;wg; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::load_async((q_smem[wg]),&nbsp;tma_q,&nbsp;qsmem_barrier,&nbsp;tile_idx);&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(int&nbsp;w&nbsp;=&nbsp;0;&nbsp;w&nbsp;&lt;&nbsp;NUM_WORKERS_KV;&nbsp;w++)&nbsp;{&nbsp;//&nbsp;load&nbsp;k,&nbsp;v&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;tile_idx&nbsp;=&nbsp;(blockIdx.y&nbsp;*&nbsp;NUM_WORKERS_KV&nbsp;*&nbsp;kv_blocks)&nbsp;+&nbsp;(0&nbsp;*&nbsp;NUM_WORKERS_KV)&nbsp;+&nbsp;w;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::load_async((k_smem[tic][w]),&nbsp;tma_k,&nbsp;kvsmem_barrier,&nbsp;tile_idx);&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::load_async((v_smem[tic][w]),&nbsp;tma_v,&nbsp;kvsmem_barrier,&nbsp;tile_idx);&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;neg_infty(max_vec);&nbsp;//&nbsp;zero&nbsp;registers&nbsp;for&nbsp;the&nbsp;Q&nbsp;chunk &nbsp;&nbsp;&nbsp;zero(norm_vec); &nbsp;&nbsp;&nbsp;zero(o_prev); &nbsp;&nbsp;&nbsp;__syncthreads(); &nbsp;&nbsp;&nbsp;tma::arrive_and_wait(qsmem_barrier,&nbsp;q_phasebit); &nbsp;&nbsp;&nbsp;q_phasebit&nbsp;^=&nbsp;1; &nbsp;&nbsp;&nbsp;if&nbsp;constexpr&nbsp;(D&nbsp;==&nbsp;64)&nbsp;{&nbsp;warpgroup::mul(q_smem[warpgroupid],&nbsp;q_smem[warpgroupid],&nbsp;__float2bfloat16(0.125f));&nbsp;}&nbsp; &nbsp;&nbsp;&nbsp;else&nbsp;{&nbsp;warpgroup::mul(q_smem[warpgroupid],&nbsp;q_smem[warpgroupid],&nbsp;__float2bfloat16(0.08838834764f));&nbsp;} &nbsp;&nbsp;&nbsp;for&nbsp;(auto&nbsp;kv_idx&nbsp;=&nbsp;0;&nbsp;kv_idx&nbsp;&lt;&nbsp;kv_blocks;&nbsp;kv_idx++,&nbsp;tic&nbsp;^=&nbsp;1,&nbsp;toc&nbsp;^=&nbsp;1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::arrive_and_wait(kvsmem_barrier,&nbsp;kv_phasebit); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kv_phasebit&nbsp;^=&nbsp;1; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;__syncthreads(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(warpid&nbsp;==&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::set_bytes(kvsmem_barrier,&nbsp;2&nbsp;*&nbsp;NUM_WORKERS_KV&nbsp;*&nbsp;k_smem[0][0].num_elements&nbsp;*&nbsp;sizeof(bf16)); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(kv_idx&nbsp;+&nbsp;1&nbsp;&lt;&nbsp;kv_blocks)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(int&nbsp;w&nbsp;=&nbsp;0;&nbsp;w&nbsp;&lt;&nbsp;NUM_WORKERS_KV;&nbsp;w++)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;tile_idx&nbsp;=&nbsp;(blockIdx.y&nbsp;*&nbsp;NUM_WORKERS_KV&nbsp;*&nbsp;kv_blocks)&nbsp;+&nbsp;((kv_idx&nbsp;+&nbsp;1)&nbsp;*&nbsp;NUM_WORKERS_KV)&nbsp;+&nbsp;w;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::load_async((k_smem[toc][w]),&nbsp;tma_k,&nbsp;kvsmem_barrier,&nbsp;tile_idx);&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::load_async((v_smem[toc][w]),&nbsp;tma_v,&nbsp;kvsmem_barrier,&nbsp;tile_idx); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;warpgroup::mma_fence(att_block); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;warpgroup::mm_ABt(att_block,&nbsp;q_smem[warpgroupid],&nbsp;k_smem[tic][0]); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;warpgroup::mma_commit_group(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copy(norm_vec_last,&nbsp;norm_vec); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copy(max_vec_last,&nbsp;&nbsp;max_vec); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;warpgroup::mma_async_wait(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;row_max(max_vec,&nbsp;att_block,&nbsp;max_vec);&nbsp;//&nbsp;accumulate&nbsp;onto&nbsp;the&nbsp;max_vec &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sub_row(att_block,&nbsp;att_block,&nbsp;max_vec); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;exp(att_block,&nbsp;att_block); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sub(max_vec_last,&nbsp;max_vec_last,&nbsp;max_vec); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;exp(max_vec_last,&nbsp;max_vec_last); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mul(norm_vec,&nbsp;norm_vec,&nbsp;max_vec_last); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;row_sum(norm_vec,&nbsp;att_block,&nbsp;norm_vec);&nbsp;//&nbsp;accumulate&nbsp;onto&nbsp;the&nbsp;norm_vec &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;div_row(att_block,&nbsp;att_block,&nbsp;norm_vec); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mul(norm_vec_last,&nbsp;norm_vec_last,&nbsp;max_vec_last); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;div(norm_vec_last,&nbsp;norm_vec_last,&nbsp;norm_vec); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copy(att_block_mma,&nbsp;att_block);&nbsp;//&nbsp;convert&nbsp;to&nbsp;bf16&nbsp;for&nbsp;mma &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mul_row(o_prev,&nbsp;o_prev,&nbsp;norm_vec_last);&nbsp;//&nbsp;normalize&nbsp;o_prev&nbsp;in&nbsp;advance&nbsp;of&nbsp;mma'ing&nbsp;onto&nbsp;it &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;warpgroup::mma_fence(o_prev); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;warpgroup::mma_AB(o_prev,&nbsp;att_block_mma,&nbsp;v_smem[tic][0]); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;warpgroup::mma_commit_group(); &nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;auto&nbsp;(*o_smem)&nbsp;=&nbsp;reinterpret_cast&lt;st_bf&lt;qo_height,&nbsp;tile_width,&nbsp;layout_o&gt;(*)&gt;(q_smem);&nbsp;//&nbsp;reuse&nbsp;q&nbsp;memory &nbsp;&nbsp;&nbsp;warpgroup::store(o_smem[warpgroupid],&nbsp;o_prev);&nbsp; &nbsp;&nbsp;&nbsp;__syncthreads(); &nbsp;&nbsp;&nbsp;if&nbsp;(warpid&nbsp;%&nbsp;4&nbsp;==&nbsp;0)&nbsp;{&nbsp;//&nbsp;store&nbsp;o &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;tile_idx&nbsp;=&nbsp;(blockIdx.y&nbsp;*&nbsp;NUM_WARPGROUPS&nbsp;*&nbsp;gridDim.x)&nbsp;+&nbsp;(blockIdx.x&nbsp;*&nbsp;NUM_WARPGROUPS)&nbsp;+&nbsp;warpgroupid; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::store_async(tma_o,&nbsp;(o_smem[warpgroupid]),&nbsp;tile_idx);&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tma::store_commit_group();&nbsp; &nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;tma::store_async_wait();}&nbsp;</p><p>那么，它的表现如何？</p><p>这个内核只有100行代码，实际上它在H100上的性能比FlashAttention-2高出约30%。雷猫负责包装布局和指令，提供了一个可以在GPU上使用的迷你pytorch环境。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3c530f79d7934a018b52a703f1571cdc@46958_oswg378789oswg1080oswg1046_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>此外，研究人员还发布了基于线性注意力和其他新架构的内核。其中基于线性注意力的内核的运行速度可达215 TFLOPs，如果考虑到算法中固有的重计算，速度可超过300 TFLOPs。</p><p>尽管线性注意力在理论上效率更高，但此前在实际硬件上表现并不佳。因此，研究人员认为这可能促进一系列高吞吐量应用的发展。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_dc002c7f13dd43d19fb6f7bcd1faadfa@46958_oswg162069oswg1080oswg726_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>small tile符合AI和硬件发展趋势</h2><p>最后，雷猫研究团队总结了开发雷猫的一些思考。在他们看来，雷猫之所以有效，是因为它的目标并不是试图做所有事：</p><p>CUDA的确比雷猫表达能力更广，雷猫小而简单，功能有限。但雷猫的small tiles抽象设计符合AI和硬件的发展趋势。</p><p>虽然雷猫不支持小于16的维度，但研究人员认为这并不重要，因为硬件也不倾向于支持过小的维度。</p><blockquote><p>如果你的矩阵乘法小于16x16，你确定你正在做的是AI吗？</p></blockquote><p>从理论出发，研究人员认为需要进行一种框架转变。</p><p>“寄存器当然不应该像旧CPU那样32位字。CUDA使用的1024位宽向量寄存器确实是朝着正确方向迈出的一步。但对我们来说，寄存器是16x16的数据tile。我们认为AI需要这样的设计，毕竟，它仍然只是矩阵乘法、归约和重塑。我们认为硬件也需要这样的设计，小型矩阵乘法迫切需要超出系统级MMA的硬件支持。”</p><p>研究人员认为，应该根据硬件特性来重新定义AI的设计理念。例如，循环状态应该有多大？应该足够大以适应一个SM。计算的密度应该有多高？不应低于硬件的需求。</p><blockquote><p>我们未来工作的一个重要方向是利用我们对硬件的了解来帮助我们设计与之匹配的AI。</p></blockquote><p>参考链接：[1]https://hazyresearch.stanford.edu/blog/2024-05-12-tk[2]https://github.com/HazyResearch/ThunderKittens[3]https://news.ycombinator.com/item?id=40337936</p><p class="editor-note">本文来自微信公众号“量子位”（ID:QbitAI），作者：西风，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2808013477082504</id>
            <title>李沐老师回归B站，带着大模型创业成果填坑来了</title>
            <link>https://www.36kr.com/p/2808013477082504</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2808013477082504</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 08:27:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI大神, Higgs-Llama-3-70B, Boson AI, 基准测试
<br>
<br>
总结: AI大神李沐带着他的最新成果Higgs-Llama-3-70B回归，这是一个专为复杂场景角色扮演设计的大模型，由他去年联合创立的公司Boson AI推出。该模型在角色扮演任务和通用领域的指令遵循方面表现优异，同时在基准测试中展现出强大的能力，超越了谷歌等其他模型。虽然距离GPT-4o还有差距，但团队强调并未针对性刷榜，而且Higgs-Llama-3-70B只是个开胃菜，未来将进一步探讨角色扮演性能和其他方面的发展策略。 </div>
                        <hr>
                    
                    <p>终于，AI大神李沐回来了！带着他的大模型创业最新成果——</p><p>一个专门为复杂场景<strong>角色扮演</strong>设计的大模型，名为<strong>Higgs-Llama-3-70B</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_f6d0b15d1d4e464da1498f4f4333f03a@000000_oswg298692oswg1080oswg766_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>得知消息的不少网友已激动在评论区催更，李沐老师也回应，视频坑还是会填的：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_7cf8e50ca084473f9eae257c8155bcf5@000000_oswg122708oswg1042oswg530_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>想你的365天。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_a7e5e0edfdfd4717b488d1a04b820208@000000_oswg41874oswg816oswg210_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>终于回来了，视频都盘包浆了。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3a44d48890b14789aba85f75602c91fc@000000_oswg50184oswg960oswg200_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>那沐神到底干啥去了？这就透过Higgs-Llama-3-70B瞧一瞧。</p><p>定睛一看，Higgs-Llama-3-70B是沐神去年联合创立的公司<strong>Boson AI</strong>，推出的<strong>Higgs开源系列大模型中的第一个</strong>，基于Llama 3打造，做了完整的SFT、RLHF。</p><p>它不仅能在角色扮演任务上表现优异，在通用领域上的指令遵循和推理方面也很有竞争力。</p><p>另外还有市场消息称，Boson AI已获张一鸣个人投资。</p><h2>左击Claude3，右打Gemini</h2><p>团队在两个新基准测试MMLU-Pro和Arena-hard上展示了Higgs-Llama-3-70B的能力。</p><p>他们还特地强调所有基准测试终将导致过拟合，已尽量从微调数据中排除了基准测试数据及其训练示例。</p><p>具体来说，<strong>MMLU-Pro</strong>是MMLU的扩展，团队认为MMLU-Pro是在模型完成训练之后发布，较少受到其他已发布模型的过拟合影响。</p><p>拿来做比较的模型也都一水的很强。</p><p>而Higgs-Llama-3-70B的表现优于谷歌在5月I/O大会上最新推出的模型Gemini-1.5-Flash、Claude3家族“中杯”Claude-3-Sonnet以及Llama3-70B-instruct。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_2892b4240090487793e99ee85f55edd5@000000_oswg97110oswg1080oswg569_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再来看<strong>Arena-hard</strong>，该基准包含了来自Chatbot竞技场的500个具有挑战性的真实用户查询。</p><p>Higgs-Llama-3-70B的表现排名第四：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_33a51a8b168445cf875cd5c83cb40575@000000_oswg114039oswg1080oswg688_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，使用相同的base model，Higgs-Llama-3-70B在6个基准测试中均优于LLama-3-70B-Instruct。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_20a0da4c5b27433c8dd87199ec350a82@000000_oswg46681oswg1080oswg169_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然距离GPT-4o还有不小的差距，但值得注意的是沐神团队放出的只是通用能力的基准测试，并且强调并未针对性刷榜。</p><p>而且Higgs-Llama-3-70B毕竟是为角色扮演专门设计的，相关效果展示团队未具体给出。</p><p>团队表示Higgs-Llama-3-70B只是个开胃菜，将进一步探讨角色扮演性能、训练后的处理流程、零基础建立数据中心、在云端使用GPU以及未来整合多个服务提供商的策略。</p><p>之后也会发布更多Higgs系列模型。</p><h2>开发角色扮演Agent</h2><p>这次李沐大模型创业方向终于浮出水面，倒是一定程度印证了之前关于沐神创业方向的猜想。</p><p>此前有消息爆料，从亚马逊首席科学家的职务上离职后，李沐联手其导师、另一位亚马逊出身AI大牛Alex Smola创办了创业公司Boson AI。而公司方向是利用大模型能力，做和游戏娱乐有关的项目。</p><p>这回官方终于给出了个准信儿，确实跟游戏沾边：</p><blockquote><p>自2023年成立Boson AI以来，我们一直致力于利用AI技术为企业赋能，旨在革新故事讲述、知识学习和信息洞察的方式。我们协助客户开发Agent，使其能够扮演多种角色，如游戏角色、语言教师、保险代理和金融顾问。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_7092df00ec6e4a349022041fe10bb55a@000000_oswg69394oswg1080oswg83_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前官网主页也已更新Higgs-Llama-3-70B模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_23f0dbeeae684d7d956ef01db2d40c03@000000_oswg354087oswg1080oswg644_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还晒出了团队创始成员，除李沐和Alex Smola外，还有四位成员。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_5b178557cc3e46fb8d30e0f1d3d6d454@000000_oswg92058oswg1080oswg365_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>李沐和Alex Smola，量子位此前也有介绍过。</p><p><strong>李沐</strong>，是二者之间大家比较熟悉的那一位。自己有很厉害的经历，加上在小破站传道授业，打下了响当当的知名度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_46e95b97f1e84c36a5d486976cbeb6a0@000000_oswg75930oswg1080oswg481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而<strong>Alex Smola</strong>，更是一个AI届的神级大牛。</p><p>直接上数据：Smola在Google Scholar上的被引用次数，<strong>超过17万次</strong>。其中，被引次数前三的所著论文，被引数统统破万。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_c900ceb03a3a45f58a64296aed6e8055@000000_oswg51893oswg1080oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了是ML著作《动手学深度学习》的主要作者外，Smola这些年的履历也很值得好好了解一番——</p><p>1996年，Smola在慕尼黑工业大学完成硕士学业，而后又在柏林工业大学拿下计算机科学博士学位。博士毕业后，他先后去往柏林GMD软件工程和计算机体系结构研究所、NICTA（澳大利亚信息与通信技术研究中心）工作。</p><p>2004年起，Smola在NICTA的统计机器学习项目中，担任高级首席研究员和项目负责人；到了2008年，Smola选择入职<strong>雅虎研究院</strong>。</p><p>2012年春天到2014年年底，2年多的时间里，Smola的工作地点是<strong>谷歌研究院</strong>。</p><p>期间，他开始担任CMU的教授。也是这个时候，他成为了李沐的博士导师，二人结缘。</p><p>2016年7月，Smola成为了亚马逊的一员，致力于构建AI和机器学习工具。首要任务之一，是让AWS和开发者社区建立和保持联系，让更多的开发者共同建设亚马逊深度学习库MXNet。</p><p>离职创业前，Smola在亚马逊担任的职位是杰出科学家和副总裁。</p><p>值得一提的是，由于Smola在分布式深度学习框架领域曾提出并行LDA（Latent Dirichlet Allocation）的框架——这是参数服务器概念的最早来源，因此，Smola也被业界称为<strong>参数服务器之父</strong>。</p><p>其他四位成员如下。</p><p><strong>Shuai Zheng</strong>，2019年从香港科技大学获得计算机科学博士学位。</p><p>之后就职亚马逊，领导亚马逊的分布式系统和LLM训练工作，包括开发可扩展的分布式训练和推理架构、具有数千亿参数的更智能模型，以及更快的分布式优化算法。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_e9b533c2f2634a669e7d6beb179900e8@000000_oswg182355oswg1080oswg560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>施行健</strong>，2014年本科毕业于上海交通大学，2018年获香港科技大学博士学位。</p><p>曾担任亚马逊担任高级应用科学家，领导过两个项目：AutoGluon Multimodal和DeepEarth。</p><p>其中AutoGluon Multimodal通过应用基础模型，突破了传统自动机器学习工具的限制。DeepEarth致力于为地球科学领域构建基础模型。之前他还参与了如Apache/MXNet等开源项目。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3264846652f847f098a150ac2e379613@000000_oswg171644oswg1080oswg404_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Yi Zhu</strong>，加州大学默塞德分校博士学位。</p><p>同样曾在亚马逊AI团队，担任高级应用科学家。研究主要关注大语言模型、多模态学习、自监督学习和视频理解，曾参与AutoGluon、GluonCV等开源项目。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_5a44d838841741fd872234d70fe9fac5@000000_oswg211463oswg1080oswg343_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Yizhi Liu</strong>，2012年毕业于浙江大学计算机系。</p><p>曾先后在百度实习，担任聚胜万合首席软件工程师、奇虎360技术部经理，之后成为亚马逊高级软件开发工程师。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_a22f4aaccc3f4b6aaa045287b72c631d@000000_oswg215203oswg1080oswg501_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>最后，量子位认识的一位团队成员推荐大家用不同的人设、persona来测试Higgs-Llama-3-70B，<strong>“可能有惊喜哦”</strong>。</p><p>以及One more thing …</p><p>大神李沐创业，肯定是不缺投资的，量子位听闻，张一鸣已经打钱支持了。</p><p>不过一切以官方信息为准吧。祝福李沐老师一切顺利～</p><p>参考链接：</p><p>[1]https://boson.ai/about/</p><p>[2]https://szhengac.github.io/</p><p>[3]https://sxjscience.github.io/</p><p>[4]https://bryanyzhu.github.io/</p><p>[5]https://www.linkedin.com/in/yizhi-liu-20810558?original_referer=https%3A%2F%2Fwww.google.com%2F</p><p>本文来自微信公众号“量子位”（ID：QbitAI），作者：西风，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2807944832792193</id>
            <title>破解芯片产能和毛利率困局</title>
            <link>https://www.36kr.com/p/2807944832792193</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2807944832792193</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 07:52:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 晶圆代工业, 先进制程技术, 成熟制程市场, 毛利率
<br>
<br>
总结: 当下的晶圆代工业面临着先进制程技术的竞争和市场份额的争夺，台积电在先进制程方面保持领先地位，而成熟制程市场价格持续下滑，四大晶圆代工厂的毛利率也面临压力。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_e78133dd06604340adabaddf3d61d508@46958_oswg359205oswg892oswg523_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当下的晶圆代工业，已经不像两年前那么光鲜，即使是看起来很风光的大厂，也有前所未有的苦恼。全球排名前六的厂商，家家有本难念的经。&nbsp;</p><p>据Counterpoint统计，在2024年第一季度，台积电继续保持其在晶圆代工行业的领先地位，一季度份额占比达到62%，三星作为第二大代工厂，占据了13%的市场份额，中芯国际在最新季度中交出了超出市场预期的成绩单，首次占据第三的位置。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_d155cfdcaab14ef3b162f30b8ef51865@000000_oswg174239oswg1080oswg638_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从上图可以看出，掌控先进制程技术和市场的台积电吃饱喝足，而没有此种实力和地位的厂商则只能在相对有限的市场内激烈竞争。&nbsp;</p><h2>&nbsp;01先进制程，神仙游戏</h2><p>在先进制程芯片市场供不应求的情况下，台积电的5nm、4nm和3nm继续保持市场领先地位，获得了全球多数大客户的订单。&nbsp;</p><p>2023年第四季度，3nm制程产线收入占台积电总营收的15%，环比增长了14.4%，5nm和7nm分别占总收入的35%和17%。总体来看，先进制程工艺（7nm及以下）占其总营收的67%。台积电预计2024年资本支出280亿~320亿美元，其中，70-80%将用于先进制程技术，10-20%将用于特殊和成熟制程。&nbsp;</p><p>2024年，将有更多客户加入台积电3nm阵营，包括联发科、高通、英伟达、AMD，甚至是英特尔。&nbsp;</p><p>英伟达新品H200、AMD的MI300将对台积电的3nm制程提供大量订单。英特尔下一代低功耗架构Lunar Lake MX（LNL）CPU将使用台积电的N3B制程，近期，台积电开始加快进度，Arrow Lake H/HX的CPU也将采用3nm制程，有望进一步提升台积电产能利用率。&nbsp;</p><p>由于先进制程需求持续增长，台积电计划到2024年底将3nm产能利用率提升至80%。&nbsp;</p><p>台积电计划于2025年推出2nm制程，近期，已经启动了2nm试产的前置作业，目标是今年试产近千片。&nbsp;</p><p>三星电子在2023年推出了第二代3nm制程工艺，计划2025年量产2nm。&nbsp;</p><p>据韩媒报道，三星已开始试产第二代3nm制程（SF3）芯片，并测试芯片性能和可靠性，目标是在6个月内将其良率提升至60%以上。三星非常看重与高通、英伟达的合作，高通的新一代 Snapdragon 8 Gen 3交给台积电生产，英伟达的 H200和AMD的MI300X预计也将采用台积电3nm制程，如果SF3产量和性能稳定，转向台积电的客户将有望回流。&nbsp;</p><p>2025年，三星将推出2nm（SF2）制程，之后，将增加晶体管的纳米片数量，这样可以增强驱动电流，提高性能，降低功耗。该公司对2nm制程寄予厚望，据韩媒报道，三星晶圆代工部门正在整合优势资源，快速推进其2nm生产计划，争取在与台积电的正面竞争到来时，提升产能利用率。&nbsp;</p><h2><strong>&nbsp;</strong>02成熟制程报价持续下滑</h2><p>成熟制程晶圆代工市场持续面临供过于求压力，IC设计公司透露，2024年第二季度，部分成熟制程报价再降1%~3%，从目前的情况来看，第三季度报价可能还会降，使得整体价格自2022年第三季度以来一路下滑。&nbsp;</p><p>2023下半年，成熟制程晶圆代工厂面临产能利用率六成保卫战，联电、世界先进和力积电等大厂为抢救产能利用率，大砍2024年首季报价，幅度达到10%~20%。这一波报价调整，导致成熟制程晶圆代工价格下探至疫情后新低点，导致相关厂商的毛利率下滑。&nbsp;</p><p>有IC设计公司透露，晶圆代工厂告知，成熟制程生意不好做，产能利用率直线下滑，为了确保产能利用率与市占率，维持一定的生产经济规模，不得不降价促销。&nbsp;</p><p>即便近期PC、手机市场出现回暖迹象，客户考虑到清库存、通膨等因素，投片策略依旧保守，逼得晶圆代工厂不得不加大降价幅度，避免订单流失到愿意降价的竞争对手那里。&nbsp;</p><p>由于消费类客户投片需求低，专攻8英寸晶圆代工的厂商受创最深，由于IDM和IC设计公司先前大量重复下单，导致电源管理IC、驱动IC和MCU等芯片库存水位仍较高，且部分产品已经转投12英寸产线，让8英寸晶圆代工厂产能利用率一直维持在低水位。&nbsp;</p><p>不过，也有晶圆代工厂表示，如果特定应用如驱动IC等客户想要更便宜的代工价格，因此转单，并不会跟着杀价，毕竟杀价竞争不会有尽头，会持续增加其它应用，让产能利用率慢慢回升。&nbsp;</p><p>部分IC设计公司表示，经历过之前被高库存困扰的情形，现在会等客户给出明确需求后才去投片。近几年，考虑到成本，在中国大陆晶圆厂投片的订单越来越多，而中国大陆成熟制程晶圆代工厂产能持续增加，会导致产能供过于求的局面持续一阵子。&nbsp;</p><h2>&nbsp;03四大晶圆代工厂毛利率堪忧</h2><p>5月，中芯国际、华虹半导体、格芯和联电先后公布了一季度财报。&nbsp;</p><p>2024年第一季度，中芯国际销售收入为17.5亿美元，环比增长4.3%，同比增长19.7%，毛利率为13.7%，同比下降7.1个百分点。&nbsp;</p><p>中芯国际月产能由2023年第四季度的80.55万片8英寸晶圆约当量增加至2024年第一季度的81.45万片8英寸晶圆约当量，产能利用率提升至80.8%。&nbsp;</p><p>展望第二季度，中芯国际给出的收入指引是环比增长5%~7%，毛利率指引是9%~11%。&nbsp;</p><p>2024年第一季度，华虹半导体的销售收入为4.60亿美元，相较于去年同期的6.31亿美元有所下降，但与上一季度的4.55亿美元相比，实现了1%的增长。尽管收入有所增长，毛利率却从去年同期的32.1%下降至6.4%。&nbsp;</p><p>华虹半导体归属于母公司股东的净利润为3180万美元，同比下降了79.1%。该公司将净利润下降归因于平均销售价格的下降，这直接影响了毛利水平。&nbsp;</p><p>2024年第一季度，格芯营收15.49亿美元，环比、同比均下降16%，净利润为1.34亿美元，同比、环比均下跌近50%，毛利润为 3.93 亿美元，环比减少25%，同比下滑24%，毛利率为25.4%，相较之前约28%的水平有所降低。&nbsp;</p><p>格芯12英寸晶圆当量出货46.3万片，同比下降 9%，环比下降16%。&nbsp;</p><p>2024年第一季度，联电营收环比减少0.6%，同比增长0.8%，毛利率为30.9%，产能利用率微幅下降至65%。&nbsp;</p><p>从这四大成熟制程晶圆代工厂的最新财报来看，毛利率普遍下降，有的下降幅度还很大，同时，伴随着产能利用率的下滑。这些可以充分体现出全球成熟制程晶圆代工市场竞争之激烈，为了不让产能利用率下滑太多，各家都在降价抢单，致使成本上升的同时，利润在减少，直接结果就是毛利率数据比较难看。&nbsp;</p><h2>&nbsp;04早有预判</h2><p>对于当下先进制程和成熟制程晶圆代工市场行情，2020年，当时还没有被收购的IC Insights就有预判。该机构发布的《2020-2024年全球晶圆产能》报告指出，虽说面临很多挑战，半导体界对于不断缩小晶体管几何尺寸有着强烈的动机，因为这样做有很多好处，如更高的速度、更低的功耗、更低的单位面积成本等。&nbsp;</p><p>在这样的发展趋势下，按照IC Insights的统计和预测，各种半导体制程的市占率向着相对更加均衡的方向发展。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_13e071d1b75945b5ba8602841a012155@000000_oswg189448oswg885oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如上图所示，在2019年，10nm以下先进制程的市占率仅为4.4%，而到2024年，其比例将增长到30％。在该时间段内，10nm -20nm制程的市占率将从38.8%，下降到26.2%；20nm-40nm制程的市占率将从13.4%，下降到6.7%；40nm以上成熟制程的比例在这些年当中没有出现明显变化。&nbsp;</p><p>10nm以下的先进制程呈现出快速增长的态势，2020年市占率为10％，2022年的预测值就超过了20％，并在2024年增加至全球产能的30％。&nbsp;</p><p>10nm -20nm制程市场占比本来是最大的，如图所示，2019年接近40%，但随着10nm以下先进制程的崛起，10nm -20nm的市占率正在逐渐被蚕食。该范围内的主力制程是16nm（主要由台积电提供），14nm（主要由三星、英特尔和格芯提供），12nm（主要由台积电和格芯提供）。&nbsp;</p><p>在20nm-40nm这一区间内，主要有22nm，28nm和32nm。&nbsp;</p><p>40nm以上的成熟制程，无论是180nm以下，还是180nm以上的，市占率都很稳定。这也正是诸多晶圆代工厂长期专注于成熟工艺，而不向先进制程投入过多资本和精力的底气所在。&nbsp;</p><p>总体来看，到2024年，10nm以下，10nm -40nm，以及40nm以上制程各占市场约三分之一，将呈现出三分天下的格局。在这个过程当中，10nm以下是个明显的增量市场，而其成本很高，对技术积累的要求也很高，玩家就很少，这也是台积电能掌控全球晶圆代工60%市场份额的主要原因。而在10nm -40nm，以及40nm以上这两个制程领域，没有增量，技术含量相对低，竞争就激烈，形成当下竞争、降价、低毛利率的局面也就顺理成章了。&nbsp;</p><h2>&nbsp;05退而求其次</h2><p>10nm以下先进制程，特别是3nm以下，做起来太难，需要太多的技术积累和巨量资金支持，即使是像台积电这样的龙头厂商，也要控制成本和资本支出。与此同时，40nm以上的成熟制程市场早已成为红海，对于业界早已成名的晶圆代工厂来说，在40nm以上成熟制程市场扩充产能，投入产出比方面不划算。因此，近些年，10nm~40nm制程，特别是16nm、22nm和28nm这三种制程工艺，受到越来越多的青睐，特别是在中国大陆、日本和欧洲新建的晶圆厂，多为这几种制程工艺产线。&nbsp;</p><p>实际上，就目前全球晶圆代工整体产能而言，在12nm、14nm和16nm制程领域，实现量产的产线比重并不高。&nbsp;</p><p>台积电表示，12nm向上接轨先进制程，向下延伸成熟制程，在未来的很长时间都将占据较大的市场份额。因此，该晶圆代工龙头在日本和德国的新建晶圆厂，都聚焦在12nm、16nm和22nm制程，可以实现较好的投入产出比。&nbsp;</p><p>格芯和联电也在积极拓展相关产能。&nbsp;</p><p>2023年7月，格芯新加坡工厂正式建成运营，每年产能超过40万片晶圆。过去几年，该公司在纽约州北部的Fab 8工厂也在投资扩建。格芯在德国德累斯顿投资了24 亿美元来提高产能。2023年，格芯宣布与意法半导体建立合作伙伴关系，以扩大产能。格芯的这些举措，都是在加大10nm~40nm制程产能。&nbsp;</p><p>联电同样非常看重投入产出比，而不是先进制程技术，特殊制程占该公司营收的60%，所谓特殊制程，简单地说就是具有很强差异化、并不是市场上每家都能提供的、独有的成熟制程工艺和服务。这方面，联电擅长OLED驱动IC、RF SOI和BCD等。&nbsp;</p><p>对于一心要将晶圆代工业务壮大的英特尔来说，在短期内无法达到台积电和三星的工艺技术和市场影响力的情况下，必须考虑投资回报率，此时，发展10nm~40nm制程晶圆代工就成为了不二选择，而在这方面，联电的诉求和工艺技术特点与英特尔很契合，因此两家厂商开始了合作。&nbsp;</p><p>通过合作，联电可以利用英特尔现成的FinFET产能而不需要巨大的资本支出，可以在成熟制程市场的激烈竞争中增加砝码。英特尔能获得晶圆代工市场经验，可以集中资源用于3nm、2nm等更先进制程工艺的开发。&nbsp;</p><h2>&nbsp;06结语</h2><p>总体来看，无论是先进制程，还是成熟制程，各晶圆代工厂都在想方设法提升产能利用率。先进制程厂不愁毛利率，但需要未雨绸缪，在扩产的同时，要提升投资回报率，成熟制程产线则要把提升毛利率放在最重要的位置。&nbsp;</p><p>SEMI认为，全球晶圆厂产能利用率仍偏低，特别是成熟制程，2024上半年没有复苏的迹象。&nbsp;</p><p>摩根大通（小摩）证券在最近发布的晶圆代工产业报告中指出，去库存将结束，2024下半年，产业将全面恢复，并于2025年进一步增强。&nbsp;</p><p>小摩台湾区研究部主管哈戈谷（Gokul Hariharan）认为，行业已至谷底，幸好AI需求旺盛，非AI需求也开始恢复，急单开始出现，包括大尺寸显示面板驱动IC（LDDIC）、电源管理IC、WiFi 5和WiFi 6芯片等，都在带动晶圆代工业转向复苏。&nbsp;</p><p>值得注意的是，中国大陆晶圆代工厂的产能利用率恢复速度较快，这是因为IC设计公司早就开始调整库存，经过6个季度的去库存，在晶圆代工厂的下单量趋于正常。&nbsp;</p><p>本文来自微信公众号“半导体产业纵横”（ID：ICViews），作者：畅秋，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2807775023937156</id>
            <title>全球第二，英伟达市值突破3万亿，人均贡献1亿美金，黄仁勋用1年走完库克3.4年的路</title>
            <link>https://www.36kr.com/p/2807775023937156</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2807775023937156</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 07:43:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, 市值, 股价, 股王
<br>
<br>
总结: 英伟达市值突破3万亿美元，超过苹果跃居全球第二大上市公司，成为史上第一家由半导体企业问鼎全球最高市值的股王。英伟达股价暴涨，股东笑疯了，股价涨幅超过了巴菲特60年时间打造的伯克希尔·哈撒韦总市值。英伟达股价上涨近1000%，股票分拆后价值暴涨。英伟达创始人黄仁勋财富暴涨，有可能超越马斯克成为全球首富。英伟达成为唯一一家由创始人带队冲进3万亿美元俱乐部的上市公司，人均创造市值超过1亿美元。 </div>
                        <hr>
                    
                    <p>芯东西6月6日报道，今日凌晨，英伟达再度创造了历史——<strong>市值突破3万亿美元，并超过苹果市值跃居全球第二大上市公司</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_c72c4de44af9473eac822d695ec4a868@1743780481_oswg166211oswg1000oswg914_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>迄今史上跻身3万亿美元市值俱乐部的企业，目前只有3家——<strong>苹果、微软、英伟达</strong>。</p><p>英伟达再这么暴走下去，微软全球市值第一的位置很可能明天就守不住了！<strong>这将是史上第一次由半导体企业问鼎全球最高市值，成为新晋股王。</strong></p><p>我们将一同见证全球股市的历史性里程碑。</p><p>在过去的32个交易日里，英伟达的市值增加了超过1万亿美元。这6周的涨幅超过了沃伦·巴菲特花60年时间打造的伯克希尔·哈撒韦总市值。</p><p>而且，<strong>从2022年10月的低点到现在，英伟达股价已经上涨将近1000%！</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_e9b74c3638b8458987fb02e86b90e9b5@1743780481_oswg131802oswg1000oswg644_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所有英伟达股东和精神股东要笑疯了。</p><p>过去五年，英伟达股价上涨327%。截至美东时间6月5日收盘，其最新股价为1224.40美元，比今年1月涨近150%。就在本周美东时间6月7日，英伟达将进行10:1股票分拆。</p><p><strong>在2010年向英伟达投资的1万美元，现在价值约320万美元。血赚！</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_a9806692321a494f896a2355860b404c@1743780481_oswg139008oswg1000oswg1250_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2010年向英伟达投资的1万美元，过去14年价值一路暴涨（图源：www.carbonfinace.io）</p><p>生成式AI热潮的泼天富贵，都被英伟达创始人兼CEO黄仁勋稳稳地接住，并塞进了口袋。</p><p>连科技圈吃瓜积极分子马斯克都感慨：“Wow.”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_8369dba1db5b4a2ca2a3d8ac9ae8e6bc@1743780481_oswg227295oswg1000oswg705_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>马斯克也不能安心看热闹了。黄仁勋的身价同样在神速飙涨，今年年初仅有135亿美元，到5月30日个人资产已经突破1000亿美元大关，跻身全球富豪榜TOP15，短短5个月财富暴涨近10倍，当前排名全球富豪榜第13名，超越马斯克身价乃至坐上全球首富的位置都不是没有可能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_64daa8c5127b4eb0988642baea2a3e20@1743780481_oswg291752oswg1000oswg857_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2024年6月6日彭博指数全球富豪榜</p><p>值得一提的是，英伟达也是<strong>唯一一家靠创始人带队冲进3万亿美金俱乐部的上市公司</strong>。</p><p>美股科技“七巨头”座次已经大换血，以前是苹果、微软、Alphabet、亚马逊、Meta、英伟达、特斯拉，现在变成了<strong>微软、英伟达、苹果、Alphabet、亚马逊、Meta、台积电</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_18f4eedb9a63423db0a645b132d3c8fa@1743780481_oswg239947oswg1000oswg792_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今天，微软、英伟达、苹果的最新市值分别为3.15万亿美元、3.01万亿美元、3.00万亿美元。</p><p>而<strong>英伟达只有2.8万名员工，也就是人均创造超过1亿美元市值</strong>。</p><p>相比之下，苹果16.1万名员工人均创造0.19亿美元市值，微软22.1万名员工人均创造0.14亿美元市值。比人效，英伟达这波完胜！</p><p>苹果的市值在2018年8月2日首破1万亿美元，2020年8月19日首破2万亿美元，2022年1月4日首破3万亿美元。</p><p>微软的市值在2019年4月25日首破1万亿美元，2021年6月23日首破2万亿美元，2024年1月12日超过苹果市值，1月25日首破3万亿美元。</p><p><strong>而英伟达市值起飞的速度宛如乘火箭，2023年6月13日首破1万亿美元，2024年2月23日首破2万亿美元，3月4日超过沙特阿美成为全球市值第三大公司，6月6日首破3万亿美元</strong>。</p><p>从1万亿到2万亿美元，苹果用时2年，微软用时2年零2个月，而英伟达仅用时8个月。</p><p>从2万亿到3万亿美元，苹果用时1年5个月，微软用时2年7个月，而英伟达仅用时3个多月——104天！</p><p><strong>从1万亿到3万亿美元，黄仁勋用不到1年，走完了库克3年5个月的路。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_55d4a35cd6524260a783fcb1aed8b108@1743780481_oswg193787oswg1000oswg891_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">2000年至今微软、英伟达、苹果市值变化（图源：Investopedia）</p><p>怪不得黄仁勋天天把“摩尔定律不行了”挂在嘴边，看看这“黄氏速度”——<strong>英伟达不光GPU快进到一年一更，市值更是狂飙到3个月涨1万亿</strong>。（黄仁勋自曝英伟达最强Rubin架构！数百万GPU集群将至，人形机器人是未来）</p><p>是的，<strong>英伟达正在加速一切！</strong></p><p>目前英伟达有三个架构团队在并行工作，第一个团队负责支持当前产品，第二个团队负责下一代产品，第三个团队负责“远见”，与供应链和客户合作探索出更多的可能性。</p><p>当前70%~95%的AI芯片市场份额都被英伟达拿下。苹果、微软都是英伟达的大客户。据估计，微软占到英伟达收入的15%。</p><p><strong>给AI金矿卖铲子的人，一脚油门踩到了所有AI淘金者的前面。</strong></p><p>这绝对是载入史册的历史性一幕。全球最大AI芯片巨头已经无人可敌，赶超微软市值、冲刺全球市值第一大AI巨头，如今只差临门一脚。</p><p>1993年创立的英伟达（NVIDIA），其命名由“NV”（代表“next version”）和“Invidia”（拉丁语“嫉妒”）组合而成，英伟达的绿色logo也代表“嫉妒之眼”。</p><p>如今，英伟达真的做到了被全世界嫉妒——超高的利润率令全球半导体企业“嫉妒”，坚持不裁员令全球被毕业、优化的科技民工“嫉妒”，黄仁勋的个人影响力被想打造个人IP的企业家们“嫉妒”，买英伟达股票的股民被全球股民“嫉妒”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_bc371f5739fd4fd5b1d137b4fc3d4d34@1743780481_oswg107496oswg1000oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而<strong>英伟达超越苹果，甚至可以视作一次跨越15年的“复仇”胜利</strong>。</p><p>两家的恩仇可以追溯到2009年，苹果因为从GPU缺陷等问题将英伟达剔除出供应数量之列，从此再也没用过英伟达产品。当时苹果的市值为1400亿美元，而英伟达不到40亿美元。</p><p>2006年1月16日，苹果市值超过戴尔。乔布斯给员工发了封邮件：“事实证明迈克尔·戴尔并不擅长预测未来。根据今天的股市收盘，苹果的市值超过了戴尔。虽然股票有涨有跌，明天的情况可能会有所不同，但我认为今天值得反思一下。”</p><p>这是乔布斯比较体面温和的措辞，相比之下，1997年苹果陷入困境时，当被问到迈克尔·戴尔曾向媒体提出苹果应该关闭并将现金返还给股东的建议，乔布斯的回答相当直截了当：“去他的迈克尔·戴尔。”</p><p>风水轮流转。如今好日子轮到了黄仁勋，也是时候值得苹果“反思一下”——</p><p>为什么从2022年1月到现在两年多过去了，微软和英伟达都凭借生成式AI热潮身价疯涨，苹果的市值却卡在3万亿美元原地徘徊，并且在自2019年以来首次跌至全球市值第三大公司的位置？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_722c98671d2148178e9dbb663c3d7dd2@1743780481_oswg129369oswg1000oswg717_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">过去5年英伟达、微软、苹果股价变化</p><p>回想全球第一家市值突破万亿美元的上市公司，是中国石油。</p><p>全球第一家市值突破2万亿美元、3万亿美元的上市公司，都是苹果。</p><p>而按现在的走势，下一个历史性赛点的抢位战将相当激烈，候选人就像3nm先进制程俱乐部成员一样稀有而集中。</p><p>谁会成为全球第一家登顶4万亿美元的“超级巨无霸”？</p><p>我押英伟达。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_90aecfc8f6614a9da848a8c186cf41d3@1743780481_oswg83424oswg1000oswg1255_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="editor-note">本文来自微信公众号“芯东西”（ID:aichip001），作者：ZeR0，编辑：漠影，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2807781495043464</id>
            <title>AI 时代，苹果真的落后了？</title>
            <link>https://www.36kr.com/p/2807781495043464</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2807781495043464</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 07:41:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: iPhone, AI, 苹果, 创新
<br>
<br>
总结: 苹果公司正面临着AI技术的挑战，尤其是在iPhone产品上。虽然苹果一直被视为创新的风向标，但近年来面临着市值和创新方面的压力。苹果计划通过AI技术改进Siri，使其更加智能，但目前Siri的功能仍然有限。虽然苹果在机器学习方面有所进展，但需要进一步提升AI能力以保持领先地位。 </div>
                        <hr>
                    
                    <p>iPhone 什么时候用得上 AI？</p><p>对于苹果来说，迫在眉睫。AI 对于消费电子产品的影响，往小了说是影响销量，往大了说就是公司市值。</p><p>6 月 6 日，英伟达总市值突破3万亿美元（3.012万亿美元），正式超过苹果公司（3.0035万亿美元）。谁曾想到，一个单靠同类产品的公司居然会赶超一个复合型科技巨头。苹果若是再不拿点真东西给大家看看，“缺乏创新”的帽子苹果恐怕还得继续戴着。</p><p>作为全球最会赚钱的科技公司之一，苹果一直被业内视为创新的风向标。从 iPhone 4 时刻到全面屏时代，再到最近的“灵动岛”，苹果的每次创新都推动了整个行业的发展方向。不过近几年苹果的风光不再，OpenAI 这类公司成了新的明星企业。</p><p>2024 苹果全球开发者会，苹果必须给大家一个答案。此前围绕 AI，苹果的传言满天飞。无可否认的是，无论 iPhone 什么时候拥抱 AI，苹果在这条路上的确已落后一个身位了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_9a896ec864c04ca88362ba50c96dee27@1743780481_oswg240485oswg750oswg914_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>于是在 WWDC24 正式开幕之前，我们看到苹果 AI 最新的消息，仍然聚焦在 Siri 身上——这是 13 年前苹果将“智能语音助手”带入大众视野的产品。</p><h2><strong>AI Siri 只是快捷指令？</strong></h2><p>据彭博社记者 Mark Gurman 爆料，苹果计划将利用 AI 使得 Siri 更加智能，允许用户通过语音指令来控制应用，实现更精准、更复杂的动作。</p><p>例如，你可以通过 Siri 把刚写好的笔记以邮件的方式发送给朋友，又例如你能让 Siri 可以打开某一篇特定的文章，甚至总结某篇文章的大概内容......</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_9540fe4ed00943c88627cfdcfe305134@1743780481_oswg186358oswg750oswg375_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>只不过需要注意的是，实现这些复杂功能一开始仅限于苹果原生的 APP。换句话说，AI Siri 能够调动的动作十分有限，还需要等待开发者进行适配——这也是为什么 Gurman 在文章中提到，该功能会在 iOS 18 明年的更新中上线。</p><p>尽管我们相信，苹果一定会启用 AI 大模型对 Siri 底层进行改造，甚至可以支持数百种语音指令。数据隐私的问题，苹果也会极力去规避，利用系统来判断某个功能调取的数据内容是否能够进行云端处理。</p><p>尽管有这么多尽管，爆料中 AI Siri 所展现出来的能力，更像是一个加强版的快捷指令。此前苹果推出的快捷指令（Shortcuts）已经能够让用户自行创造连续的、复杂的、自动的功能，同时将 Siri 作为功能触发点。</p><p>而调动聊天软件发送消息，Siri 早就可以做到了。只不过用语音助手发送消息的价值，还不如人工智能聊天机器人来得更高一些。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3d8880ec05f448e0ab22333dfe72b501@1743780481_oswg19559oswg750oswg591_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前 Siri 的能力仅限处理单个指令，甚至还不能理解上下对话内容，只能打开某个软件，播放某一位歌手的歌曲，你也可以具体到某一首。虽然现在看起来非常简单，但诞生当年，Siri 在 iPhone 上的表现可谓“杀手级”应用。</p><p>2010 年，苹果收购了 Siri 公司。在长达 13 年的时间里，Siri 逐渐沦为了“智障语音助手”。尤其是当其它品牌的语音助手都在不断成长的时候，Siri 更显得笨拙。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3300d7ef5ead49679d7dd799f24dcd73@1743780481_oswg293938oswg750oswg498_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>三星、OPPO、小米等企业的手机早早宣布接入大模型，摇身一变成为“AI 手机”。其搭载的语音助手如同装了一个人类大脑，能够理解用户意图，完成更加复杂的任务，远比 Siri 更加先进。</p><p>话说回来，即使 AI Siri 再聪明，它也无法重现曾经的杀手本色。Siri 只会左右苹果用户的体验，即使有新玩意，苹果也不再是引领者。</p><h2>如何继续领先</h2><p>如果说苹果没有落地 AI 能力，这是非常不客观的。</p><p>一方面，苹果放弃了耕耘 10 年的 Apple Car 项目，转身投入 AI 赛道，已经表明了其决心。在对外宣传上面，苹果一改过去刻意回避“AI”词汇的态度，随时将“AI”挂在嘴上；另一方面，苹果机器学习方面的能力，已经不能够用“研发”一词来概括，在过去 10 年里，苹果收购了数十家 AI 创业公司，包括 Shazam、primeSense、Turi 等公司。</p><p>同时，在 iPhone 上其实已经体现出了一定机器学习的成果。当你使用 iPhone 足够长的时间之后，它会对你的联系人、去过的地方以及相册的内容更加熟悉，并时不时为你提供一些分类、记录的建议。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_203b2a047fc648cabeb0e5943929194b@1743780481_oswg318115oswg750oswg585_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">苹果的Ferret模型</p><p>只不过这些动作发生得悄无声息，不如 ChatGPT 那样来得刺激——更重要的是，聊天机器人的“人工智能交互”频次更高，感知更强。</p><p>既然如此，为什么苹果没有提前推出生成式 AI 功能或者是聊天机器人？</p><p>其实很简单，苹果的反应速度太慢了。2022 年 12 月 5 日，Sam Altman 宣布 ChatGPT 突破 100 万用户大关。此时苹果就已经开始寻找应对 ChatGPT 的措施，后来还建立了大语言模型 Ajax 来做测试。</p><p>据纽约时报报道，去年年初，苹果高管 Craig Federighi 和 John Giannandrea 在使用 ChatGPT 几个星期之后，认为 Siri 已经过时了，并且需要对其进行改造。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_31622e1ba0534ece810f494f1481243d@1743780481_oswg47440oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也正是从此刻开始，苹果终于决定要动一动 13 岁的 Siri。</p><p>库克对外传递着他作为 CEO 身份应该传递的信息：随着时间的推移，你会看到产品的进步，这些技术是产品的核心。换句话来说，就是目前研发的生成式 AI 产品还不足以让苹果满意，但苹果会持续对 AI 投入，并持续改进产品。</p><p>好在苹果擅长给自己预留 ABC 备选计划。在一系列的传言当中，苹果已经与明星企业 OpenAI 达成协议，后者将为 iOS 18 提供生成式 AI 功能，同时苹果也在与谷歌谈判，将 Gemini 作为另一个方案。</p><h2>AI Phone&nbsp;能否力挽狂澜</h2><p>目前关于 iPhone AI 功能的传言，并没有让人为之一振的感觉。</p><p>Google 自身或许是最有条件做出 AI 手机领头羊的企业之一，但主打 AI 功能的 Pixel 8a 仅仅从宣发上，就没能让人感觉到它有多么领先：Best Take 即筛选最佳表情合成照片，Photo Unblur 顾名思义将模糊的照片变清晰，还有识别照片主体、消除杂物、改变天色......</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_266e4676fc4344918c9d53ea8cd60796@1743780481_oswg198275oswg750oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一切功能你都在国产手机上一一复现，甚至一些功能在生成式 AI 流行之前，就已经存在于手机当中。当前的 AI 功能，只是让老功能变得好用了一点，有的功能则只是套了个 AI 概念而已，没有主动式的智能化。</p><p>不过谷歌不是苹果，大众对苹果创新的期待远高于其它科技公司，不仅因为它自身的知名度，更因为乔布斯本人的光环。</p><p>人们似乎已习惯了苹果引领着行业，对苹果跟风别人嗤之以鼻。</p><p>因此，相同的功能，苹果做得比其它公司更强，理所应当；在无人区里，苹果点燃了一盏不熄灭的油灯，才是大众所期待的结果。</p><p>若是从苹果的角度来说，iPhone 的销售额仍然占据苹果公司的 50% 以上，拿走了全球智能手机利润的 85%。苹果比任何人都希望 AI 上机后，能帮助 iPhone 卖得更好。</p><p>尤其是在 Apple Car 项目取消，Vision Pro 失利的前提之下。</p><p class="editor-note">本文来自微信公众号“不客观实验室”（ID:gh_719281df296b），作者：唐健博，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2807790330213766</id>
            <title>英伟达总市值超苹果，突破3万亿美元大关</title>
            <link>https://www.36kr.com/p/2807790330213766</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2807790330213766</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 07:39:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, 总市值, 半导体, 生成式AI
<br>
<br>
总结: 英伟达是历史上第3家进入“3万亿美元俱乐部”的企业，其总市值突破3万亿美元，超过苹果，仅次于微软。公司主要产品是用于生成式AI开发的图形处理器，市场份额约占8成。英伟达不断推出高性能产品，保持竞争优势，股价涨幅显著。在半导体领域，英伟达的GPU驱动AI软件提供了开发平台，保持高盈利能力。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_0fa75ca5a4e04018a3d8cd54ea461731@000000_oswg37616oswg600oswg371_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">英伟达是历史上第3家进入“3万亿美元俱乐部”的企业（英伟达CEO黄仁勋）</p><blockquote><p>6月5日，英伟达的收盘价比前一天上涨5％，总市值达到3.0118万亿美元，超过苹果的3.0034万亿美元，仅次于微软位居世界第2位。英伟达也成为历史上第3家总市值站上3万亿美元大关的企业……</p></blockquote><p>6月5日，美国英伟达（NVIDIA）的总市值突破3万亿美元，超过苹果，仅次于微软位居世界第2位。英伟达是历史上第3家总市值站上3万亿美元大关的企业。由于市场对用于生成式AI开发和处理的半导体的需求扩大充满期待，该公司股价不断创出上市以来新高。</p><p>5日，英伟达股票的收盘价比前一天上涨5％。据QUICK FactSet介绍，该公司市值达到3.0118万亿美元，超过了苹果的3.0034万亿美元。</p><p>英伟达的总市值2023年5月首次在半导体企业中突破1万亿美元，2024年2月在不到1年的时间里又突破2万亿美元大关，增长速度非常惊人。英伟达是继苹果和微软之后历史上第3家总市值站上3万亿美元大关的公司。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_f59ff194323042a28632efb401a48c7a@000000_oswg29963oswg600oswg441_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>英伟达的主力产品是开发对话型AI“Chat GPT”等所需要的图形处理器（GPU）。据英国调查公司Omdia介绍，在数据中心使用的AI半导体领域，2023年英伟达拥有约8成市场份额。</p><p>美国Open AI和谷歌等科技企业在生成式AI的性能方面展开研发竞争，用于计算处理的GPU的洽购一直十分强劲。英伟达5月22日发布的2024年2～4月财报显示，净利润达到上年同期的7.3倍，亮眼的业绩超出市场预期。</p><p>最近，美国企业家埃隆·马斯克成立的AI新公司筹措资金，开始开发新的AI。很多人认为，该公司将采购英伟达的更多最新半导体。还有一个重要影响因素是，市场对英伟达拆股之后被纳入道琼斯工业平均指数充满期待。</p><p>英伟达5月2日宣布，2025年将推出名为“Blackwell Ultra”、2026年将推出名为“Rubin”的AI半导体新产品系列，人们对进一步加快AI处理速度的期待越来越高。</p><p>在美国科技巨头中，生成式AI战略的成功与否影响着股价的涨跌。英伟达的股价在1年内达到了原来约3倍。微软的股价也上涨了约27%，Alphabet则上涨了约40%，而苹果在生成式AI战略方面落后，股价仅上涨了9%。</p><p>英伟达是由首席执行官（CEO）黄仁勋等人于1993年创建的，最初的主力业务是面向游戏的GPU。进入2010年代，该公司发现GPU并行处理多个数据的特性可以显著提高AI的性能，因此投资AI半导体，实现了快速增长。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_79545d51e22b4df19ef9237765907d88@000000_oswg42614oswg600oswg486_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在AI使用的半导体方面，AMD及英特尔等公司推出了竞争产品，谷歌、Meta、微软也在推进自主生产。但英伟达不断开发高性能产品，一直保持着竞争优势。</p><p>英伟达的优势在于使用GPU驱动AI的软件，提供名为“CUDA”的开发平台。一位技术人员透露：“由于AI开发本身基于英伟达的软件，即使有性能接近的半导体问世，也难以替代”。</p><p>与容易受市场状况影响的其他半导体相比，GPU已成为英伟达的主要阵地，该公司掌握价格主导权，保持着高盈利能力。</p><p>在6月5日的美国股市上，除了英伟达外，美光科技（上涨5.6%）、博通（上涨6.2%）等大型半导体相关股票也上涨，主要股价指数也上升。高科技股比重较高的纳斯达克综合指数比上个交易日上涨2.0%，达到1万7187点，标准普尔500指数也上涨1.2%，达到5354点，均创出历史新高。</p><p>本文来自微信公众号“日经中文网”（ID：rijingzhongwenwang），作者：渡边直树，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2807849844366208</id>
            <title>60亿加码研发，固态电池万亿市场产业化提速</title>
            <link>https://www.36kr.com/p/2807849844366208</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2807849844366208</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 07:26:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 中国日报, 固态电池, 新能源汽车, 技术突破
<br>
<br>
总结: 中国将投入60亿元用于全固态电池研发，固态电池被视为新能源汽车领域的重要技术突破，产业链上下游加码投入研发，固态电池面临生产工艺、成本等挑战。国内外企业竞争激烈，欧美日韩企业已开始布局固态电池技术，中国企业需加快发展以保持竞争力。 </div>
                        <hr>
                    
                    <p>近日，据《中国日报》报道，中国或将投入约60亿元用于全固态电池研发，宁德时代、比亚迪、一汽、上汽、卫蓝新能源和吉利共6家企业有望获得政府基础研发支持。</p><p>被众多企业称为“六边形战士”的固态电池，因在充电时间、续航里程、理论安全性能方面的优势，被视为新能源汽车领域内下一代重要技术突破，甚至是“技术珠峰”。有动力电池行业专家表示，产业链上下游加码投入全固态电池研发，或将带动万亿元级别的市场。</p><h2>2027年有望小批量上车</h2><p>固态电池高安全性、高续航能力的B面，是新材料革新、成本居高不下等多重挑战。中国科学院院士欧阳明高近日在中国汽车动力电池产业创新联盟2024年度大会上表示，“实现电解质从液态到固态的转变和负极材料的转型是发展全固态电池的关键。”&nbsp;</p><p>此外，车市睿见还从多家企业的发言中了解到，固态电池还存在生产工艺不成熟、产业链配套需降低成本等问题。如何量产落地成为当前固态电池领域的关键挑战。&nbsp;</p><p>市场层面，尽管目前已经有厂商推出了固态电池，实际上大多为半固态电池。从液态电池走向全固态电池，最核心的是电解质的改变，这就需要化学材料提升能量密度等，而技术和制造工艺，以及相关的良品率都考验企业的研发和生产能力。在中国科学院物理研究所研究员李泓看来，固态电池一步到全固态是比较难的，有可能要经历混合固液的过程。&nbsp;</p><p>企业层面，国轩高科首席科学家朱星宝表示：“尽管固态电池具备高能量密度、高安全性和快速充放电的优点，受到固态电解质、电极材料的固有性质限制，固态电池目前性能有限，固-固界面点接触，界面阻抗严重，产线兼容低，生产成本高。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3b4699bf62164550a4944337371c09c5@5815735_oswg169270oswg640oswg434_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：网络&nbsp;</p><p>尽管技术突破难度高，车市睿见还是在会议上发现，多名学者和专家对固态电池的发展趋势表示非常看好，整车企业和产业链企业在积极布局。“固态电池将助力交通电动化、能源清洁化，加速第三次能源革命。”卫蓝新能源研发总监徐航宇表示。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_0d2488d5b96d46c29644020ca97cd23c@5815735_oswg988835oswg1000oswg666_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：网络&nbsp;</p><p>“目前我国固态电池技术处于产品导入前的技术萌芽阶段，在国家项目支持下全固态研发会提速，预计3-5年内或追赶上日韩水平，预计全固态电池在2027年可小规模示范装车，2030年实现大规模量产装车。” 深蓝汽车科技有限公司高级项目总监周安健表示。&nbsp;</p><p>欣旺达副总裁梁锐透露：“欣旺达很早就对固态电池等新一代电池进行了布局和开发，目前，400Wh/kg固态电池已经在我们实验室研发出来了，我们会在2026年建设生产线进行初步量产。”&nbsp;</p><p>不过，梁锐也认为，要理性看待固态电池的发展，“我们做电池肯定不光是要考虑功能性好，还要看它的可靠性是否能够达到商用化的要求，以及经济性是不是能够让大家大规模的去推广、去用。因此，固态电池的到来并不意味着液态电池一下子就被淘汰了。”&nbsp;</p><p>宁德时代董事长曾毓群也曾在公开场合表示，“宁德时代已经在这方面投资了 10 年，固态电池只有在使用新型化学材料、负极电极使用纯锂金属的情况下才会有很大优势，要将这种电池推向市场还有很多困难。”&nbsp;</p><h2>国内外竞争新技术制高点</h2><p>对于国内企业而言，“国家队”发力支持固态电池将成为重大利好。但对于特斯拉等欧美车企以及日韩的车企和电池企业来说，新技术的突破则意味着新一轮的竞争。&nbsp;</p><p>在固态电池领域，欧美及日韩企业已经开始“动起来”。2023年底，丰田高调官宣与日本能源公司联手，将尽快突破固态电池技术瓶颈实现量产。丰田目前在固态电池领域拥有1300多项专利，并且在硫化物电解质层面处于断崖式领先。韩国主要是由三星、LG等企业在电芯层面布局，日韩企业比较协同。&nbsp;</p><p>本田、日产也纷纷敲定量产固态电池时间表，将大面积量产的时间锁定在2027年前后。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_55dee5fab1574316bd97953fff049c8a@5815735_oswg394359oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：Soild Power&nbsp;</p><p>除此之外，欧洲的BBA，美国的特斯拉、福特、通用也对固态电池技术方面加大投入。他们中大多数采取与初创科技企业合作的方式研发固态电池。如福特和宝马投资欧洲著名电池厂Soild Power；通用投资锂金属电池公司SES；奔驰投资Factorial Energy等。&nbsp;</p><p>可以看到，欧美日韩企业已将新能源汽车的发力点后置，以期在固态电池这一远期技术上提前布局，从而在未来实现对中国新能源汽车行业的反超。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_38e09e145a384cc09d1afdd76139c14e@5815735_oswg323331oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片来源：清陶能源&nbsp;</p><p>国内方面，此前已有卫蓝新能源、清陶能源和赣锋锂业等企业实现半固态电池的量产装车，东风和蔚来汽车等企业的相关产品投入市场。10月，搭载光年半固态电池的智己L6，将正式交付用户。而广汽埃安也宣布，计划在2026年实现全固态电池的开发，并首先搭载于昊铂车型。&nbsp;</p><p>在业内专家看来，以应用为本，高性能锂电池的发展之路应多维并进，除对固态电池这一前沿技术开展探索外，同样不能忽视在液态电池领域的深厚积淀和显著优势。&nbsp;</p><p>可以预见，固态电池，特别是全固态电池短期内难以实现大规模商业化，未来10年是研发的关键机遇期。在这条新赛道上，欧阳明高院士提醒，面对全球竞争，中国应在保持现有优势的同时，积极应对潜在的颠覆性技术，以确保行业的持续发展。&nbsp;</p><p>他以电动车对燃油车的替代为例，“国内电动车现在对燃油车也就只替代了30%，全球就惊呼中国车要领先了。2016年左右，我国的新能源汽车市场占有率达到1%的时候，全球开始向电动汽车转向。对于汽车技术而言，1%是很重要的市场份额，所以全固态电池的市占份额不需要替代到50%，替代1%就已经具有突破性意义。”&nbsp;</p><p class="editor-note">本文来自微信公众号“车市睿见”（ID:cheshiruijian），作者：杨朔，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2807969738749568</id>
            <title>首次证实白盒Transformer可扩展性，马毅教授CRATE-α：鲸吞14亿数据，性能稳步提升</title>
            <link>https://www.36kr.com/p/2807969738749568</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2807969738749568</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 07:19:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Transformer架构, CRATE-α, 可解释性, 模型性能
<br>
<br>
总结: 本文介绍了一种新型Transformer架构变体CRATE-α，通过设计改进提升了模型的可扩展性、性能和可解释性。研究人员在CRATE架构设计中对稀疏编码块进行了策略性但最小化的修改，并设计了一种轻量级的训练方法，以提高CRATE的可扩展性。实验结果表明，CRATE-α能够随着模型尺寸和训练数据集的增大而扩展，性能可以持续提升，同时保持甚至增强了模型的可解释性。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_9217dc316acb440aa222672cc731942b@46958_oswg369446oswg1067oswg408_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>CRATE-α是一种新型Transformer架构变体，通过设计改进提升了模型的可扩展性、性能和可解释性，CRATE-α-Base在ImageNet分类任务上的性能显著超过了之前最好的CRATE-B模型，其性能会随着模型和数据集规模扩大而继续提升。</p><p>在过去的几年里，Transformer架构在自然语言处理（NLP）、图像处理和视觉计算领域的深度表征学习中取得了显著的成就，几乎成为了AI领域的主导技术。</p><p>然而，虽然Transformer架构及其众多变体在实践中取得了巨大成功，但其设计大多是基于经验的，并没有严格的数学解释，也在一定程度上限制了研究人员的思路，无法开发出更高效、更具可解释性的Transformer新变体。</p><p>为了填补这一空白，马毅教授团队曾发布过白盒Transformer模型CRATE，其架构的每一层都是通过数学推导得到的，可以完全解释为展开的梯度下降迭代；此外，CRATE学习到的模型和特征在语义上也比传统的Transformer模型具有更好的可解释性，例如，即使模型仅在分类任务上进行训练，可视化图像的特征也能自然地形成该图像的零样本分割。</p><p>然而，到目前为止，CRATE的应用规模仍然相对有限，CRATE-Large只包含77.6M参数，与标准Vision Transformer（ViTs）的22B参数量形成了鲜明对比。</p><p>最近，加利福尼亚大学圣克鲁斯分校和伯克利分校的研究团队联合提出了CRATE-α，首次探索了不同规模的CRATE用于视觉任务（从Tiny到Huge）时的模型性能，研究人员在CRATE架构设计中对稀疏编码块进行了策略性但最小化的（strategic yet minimal）修改，并设计了一种轻量级的训练方法，以提高CRATE的可扩展性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_a4b7becd0c92483b9751a254a24fcddf@46958_oswg29508oswg1069oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文链接：https://arxiv.org/pdf/2405.20299</p><p>项目链接：https://rayjryang.github.io/CRATE-alpha/</p><p>具体来说，CRATE中的ISTA模块是限制进一步扩展的因素，为了克服这一限制，CRATE-α主要做了三个修改：</p><p>1. 大幅扩展了通道，对稀疏编码块进行过参数化（overparameterized），使用过完备字典（overcomplete dictionary）对token表征进行稀疏化。</p><p>2. 解耦了关联矩阵，在稀疏编码块的最后一部中引入一个解耦字典（decoupled dictionary）</p><p>3. 添加了残差连接。</p><p>实验结果证明，CRATE-α能够随着模型尺寸和训练数据集的增大而扩展，性能可以持续提升。</p><p>例如，CRATE-α-B在ImageNet分类任务上的性能显著超过了之前最好的CRATE-B模型，准确率提高了3.7%，达到了83.2%；进一步对模型进行扩展时，CRATE-α-L在ImageNet分类任务上达到了85.1%的准确率。</p><p>值得注意的是，模型性能的提升是在保持甚至增强了CRATE模型可解释性的同时实现的，因为更大尺寸的CRATE-α模型学到的token表征能够生成更高质量的无监督图像分割。</p><h2><strong>实验结果</strong></h2><h3><strong>从基础尺寸（base）到大尺寸（large）</strong></h3><p>ImageNet-21K是一个广泛用于图像识别和分类任务的大型数据集，文中用于训练的数据集版本包含19,000个类别和大约1300万张图片，由于数据丢失，比标准数据集（包含21,000个类别和大约1400万张图片）的数据量要少一点。</p><p>在预训练时，从数据集中随机选取1%作为验证集。</p><p>预训练完成后，在ImageNet-1K数据集上对模型进行微调，其中ImageNet-1K是一个更小的子集，包含1000个类别，通常用于模型的最终评估。在微调阶段，模型会针对这1000个类别进行更精细的训练，以提高其在特定任务上的性能。</p><p>最后，在ImageNet-1K的验证集上评估模型的性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_eccbd2f7b5ca42ecbec98775750c2002@46958_oswg169172oswg1080oswg379_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>研究人员对比了在32、16和8像素块大小下的CRATE-α-B和CRATE-α-L，从实验结果中可以看到，CRATE-α-L在所有像素块大小上都取得了显著的改进，但从CRATE-B增加到CRATE-L只能带来0.5%的性能提升，表明了收益递减的情况，证明了CRATE-α模型的可扩展性显著优于普通CRATE</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_3ec5438df9c94375a5723acef7a5b3a7@46958_oswg209175oswg1050oswg479_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同时，预训练阶段的训练损失显示，随着模型容量的增加，训练损失的趋势可预测地得到改善。</p><h3><strong>从大（large）到巨大（huge）</strong></h3><p>多模态数据集DataComp1B包含14亿图文对，可以提供足够的数据来训练和扩展模型。</p><p>研究人员采用对比学习的方法来训练CRATE-α，不仅能够利用上庞大的图文对数据集，还能在模型尺寸从大到巨大的提升过程中，观察到显著的性能提升。</p><p>然而，直接训练一个类似CLIP的模型需要巨大的计算资源，研究人员采用了优化后的CLIPA协议，可以在减少计算资源消耗的同时，可以保持与CLIP相当的性能。</p><p>最后，为了评估CRATE-α模型的性能，研究人员采用了零样本学习的方法，在ImageNet-1K数据集上测试模型的准确率，该方法可以有效地评估模型在面对未见过类别数据时的泛化能力，提供了一个衡量模型可扩展性和实用性的重要指标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_5ee80709c31840398b88740b5d3a4dbe@46958_oswg214946oswg1080oswg459_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从实验结果中可以看到，</p><p>1. 模型尺寸的影响：CRATE-α-CLIPA-L/14在预训练和微调阶段的ImageNet-1K零样本准确率上，分别比CRATE-α-CLIPA-B/16高出11.3%和9.0%，表明学习到的表征质量可能受到模型尺寸的限制，即增加模型尺寸可以利用上更多数据。</p><p>2. 扩展模型尺寸的益处：当继续增加模型尺寸时，可以观察到CRATE-α-CLIP-H/14从更大的训练数据集中继续获益，在预训练和微调阶段的ImageNet-1K零样本准确率上，分别比CRATE-α-CLIP-L/14高出3.1%和2.5%，证明了CRATE-α模型的强大可扩展性。</p><p>3. 性能上限的探索：为了探索性能的上限，研究人员从头开始训练了一个标准的ViT-CLIPA-H/14，并观察到了性能的提升。</p><h3><strong>节省计算资源的扩展策略</strong></h3><p>在追求模型扩展的效率和计算资源的优化方面，研究人员发现，通过调整预训练阶段的图像token序列长度，可以在极大减少计算资源消耗的同时，保持模型性能。</p><p>具体来说，研究人员尝试了一种新的方法：在预训练时使用较长序列长度的CRATE-α-L/32，在微调时切换到较短序列长度的CRATE-α-L/14或CRATE-α-L/8，不仅大幅度降低了预训练阶段的计算成本，而且在微调后，模型在ImageNet-1K数据集上的准确率仍然非常接近全尺寸模型的性能。</p><p>例如，使用CRATE-α-L/32进行预训练，然后微调到CRATE-α-L/14，可以节省约70%的计算资源，而准确率只是略有下降；更进一步，当从CRATE-α-L/32预训练后微调到CRATE-α-L/8时，仅使用了原模型所需训练时间的10%，准确率依然达到了84.2%，与全尺寸模型的85.1%相差无几。</p><p>上述结果表明，通过精心设计预训练和微调阶段的策略，可以在资源有限的情况下，有效地扩展CRATE-α模型。</p><h3><strong>CRATE-α的语义可解释性得到提升</strong></h3><p>除了可扩展性，文中还研究了不同模型大小的CRATE-α的可解释性，使用MaskCut来验证和评估模型捕获的丰富语义信息，包括定性和定量结果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_72ab79c88e1042fba651b37ea65fd518@46958_oswg448644oswg794oswg445_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为CRATE-α、CRATE和ViT在COCO val2017上提供了分割可视化后，可以发现，CRATE-α模型保持甚至提高了CRATE的（语义）可解释性优势。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_01d6a28ef9a44648a8a5178b3c37b843@46958_oswg137354oswg1049oswg376_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在COCO val2017上的定量评估结果显示，当为CRATE-α扩展模型大小时，大型模型在目标检测和分割方面比base模型有所提高。</p><p>参考资料：&nbsp;</p><p>https://arxiv.org/pdf/2405.20299&nbsp;</p><p class="editor-note">本文来自微信公众号“新智元”（ID:AI_era），编辑：LRS，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2807974018332293</id>
            <title>不能用微信的手机，卖断货了</title>
            <link>https://www.36kr.com/p/2807974018332293</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2807974018332293</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 07:18:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 诺基亚3210, 疯抢, CCD平替, 复古手机
<br>
<br>
总结: 诺基亚3210作为一款复古手机，因其拍照功能吸引了众多消费者的疯狂抢购。尽管功能简单且不支持微信等现代通讯应用，但其低像素的拍照效果却被认为具有特殊的复古魅力，被称为CCD平替。这种复古手机在当今高清照片盛行的时代，却因其特殊的画质而备受追捧，展现了消费者对复古风格的热爱。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_c2048c7681aa46688038cc12d6116b5d@46958_oswg374231oswg952oswg578_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最近手机市场最抢手的产品，不是堪比摄影机的小米14 Ultra，不是在续航方面遥遥领先的华为Mate 60 Pro+，甚至不是一款智能机。</p><p>而是在1999年10月就推出市场的“砸核桃神器”——诺基亚3210。</p><p>2024年5月8日，诺基亚时隔25年推出改进后的3210，售价379元，短短2天就宣布售罄。</p><p>5月31日晚8点，诺基亚3210再度开卖，不到两个小时就被售空。</p><p>就在今天（6月6日）上午10点，诺基亚少量现货再次发售，1个小时就又被抢空。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_a3b72017f4fc4b07b046bbc32f0cfd0e@46958_oswg238707oswg1080oswg885_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>诺基亚3210凭啥穿越时空被人们铭记？智能手机时代，赶了个晚集的诺基亚，能否凭借旧机复刻找回主场？</p><h2>不能连WiFi的手机，被年轻人疯抢</h2><p>诺基亚不在市场很多年，江湖上仍流传着它的传说。</p><p>此次重返市场，就像从甘露寺回宫的甄嬛，迅速吸引所有人的目光。随着新款3210开卖，诺基亚销售额明显增长。</p><p>在抖音电商平台，今年1-5月，诺基亚的销售额始终保持在100-250万元，但从图表中可以清晰地看出来，5月销售额几乎达到前一个月的两倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_fa26f1f1b8a0471eb9e905f3b1396b08@46958_oswg67953oswg1080oswg965_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，诺基亚3210被疯抢，肯定不是因为好用。</p><p>虽说在原版基础上进行了更新，新版诺基亚3210依然是一款只有基础功能的按键手机。</p><p>能上网，但必须手动输入网址链接；有支付宝，但只有收付款码功能；内置喜马拉雅、咪咕音乐，但只能听歌无法评论、社交；支持4G双卡双待，但居然不能连WiFi。</p><p>更重要的是，这款手机不支持微信，只能电话和短信联络，在当下的通信环境中显得相当“局限”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_9956ef5311c6474186b454fae7e447db@46958_oswg113346oswg1080oswg1295_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这样一款手机，很难说明它的目标受众是哪些人。</p><p>给老人用，屏幕太小对眼睛不友好，况且老人也有刷抖音、看短剧、听小说的娱乐需求；给孩子用，10后对诺基亚可没有怀旧滤镜，不如小天才电话手表来得实在；作为备用机，却登不了微信，很难想象怎么和周围人保持联络。</p><p>也不怪部分消费者称它是“电子垃圾”，思来想去除了买回来收验证码，好像派不上什么用场。</p><p>既然如此，为什么这款手机会卖脱销？</p><h2>买的不是手机，是“CCD平替”</h2><p><strong>比起听歌、打电话、收付款，诺基亚3210最吸引人的是它的拍照功能。</strong></p><p>没有前置摄像头，需要把手机反过来，伸长胳膊的自拍姿势，让不少人梦回00年代。</p><p>200万像素的摄像头，比14年前的iPhone4还糊，但盘包浆的画质，也被一大群追求复古的消费者青睐。</p><p>在小红书上，年轻人纷纷晒出用这款手机拍照的效果，表示“虽然低像素但是好有feel”，甚至称它是“CCD平替”，评论区被反复提及的关键词中也有“CCD”和“拍照”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_59f3e3947ddb400395d3cb0412f92b6e@46958_oswg85556oswg1080oswg1030_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>CCD相机，指的是采用CCD传感器的数码相机，这种手机本来已经被时代淘汰，在二手市场论斤卖。</p><p>但因为画质不够清晰，自带朦胧氛围感，在这个流行把高清照片盘上电子包浆的时代，反而成为出片神器，热门机型被炒到了上千元。</p><p>回过头来看诺基亚3210，复古的机型、低像素的画质，都加剧了它的抢手程度，就连379元的价格，放在高溢价的CCD市场，也显得“香”了起来。</p><p>毕竟对千禧辣妹来说，诺基亚3210压根不是什么手机，而是一部能打电话的CCD平替。</p><p><strong>不过，诺基亚3210的实际拍照效果，不一定如想象中美好。</strong></p><p>有人看了诺基亚拍出的照片，表示“这跟CCD就是两码事，CCD虽然像素不高但是不会有噪点的”、“和预期相差有点大，还是无法媲美CCD”。</p><h2><strong>诺基亚，早就不生产手机了</strong></h2><p>5月10日，#诺基亚回归# 冲上了微博热搜第一。</p><p>对于昔日的手机巨头，这份关注度算是泼天的流量，上一次它因产品而受关注，还是2021年，当时#诺基亚推出平板电脑#登上热搜第20位。</p><p>目前，诺基亚天猫旗舰店的热销产品，全是打着“老人机”标签的功能机，价格在144-394元不等。</p><p>店内唯一在售的智能机C31，原价699元，618大促期间券后最低574元，依然主打老人机，但消费者评价显示“太卡了，还是买贵一点的吧”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_8774071ff8504d51bd0c63dfd047233a@46958_oswg163405oswg1080oswg1809_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>曾经的机王，如今已经彻底失去了上桌的资格。</p><p>这一次，诺基亚凭借复刻3210，在市场掀起一阵风，但品牌与消费者都清楚，没有人会日常使用这款手机，更多人不过是像追逐新鲜玩具一样跟风购买，然后就把它打入冷宫。</p><p><strong>诺基亚此次复刻经典的戏码，不是熹妃回宫，更像是华妃的短暂复宠。</strong>诺基亚所追求的，也只是赚一波快钱，而不是做长久的生意。</p><p>诺基亚曾是手机市场的王者，从1996年开始，连续15年保持市占率第一。</p><p>2010 年，苹果公司发布iPhone 4，智能手机市场迎来快速增长。Wind数据显示，2011年初，中国智能手机的市占率仅为15.8%，到2014年初，这一数字已经上升至88.1%。</p><p>这一时期，不仅苹果的每一代新品都受到追捧，三星、小米等其他品牌，也借助智能手机的势头，实现了快速的市场扩张。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_04a626341d554f8babaa8693eee7b0f5@46958_oswg74854oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>而诺基亚在智能手机市场的布局明显滞后，结果是迅速掉队。</strong></p><p>2014年，诺基亚把设备与服务业务出售给微软，正式退出智能手机硬件制造领域，结束了其作为手机制造商的历史。</p><p>2016年，诺基亚将手机和平板电脑的全球独家使用权授予HMD Global，这是一家由诺基亚前高管创立的新公司，此后HMD每售出一件诺基亚品牌手机，都要向诺基亚支付授权费用。</p><p>HMD在获得诺基亚授权后，先后推出了几款智能手机，凭借过去积累的品牌影响力，和一批忠诚“诺粉”的支持，刚开始取得了一定市场反响。</p><p>但随着智能手机市场的快速发展，HMD在中高端市场上缺乏核心竞争力，与华为、三星、苹果的差距逐渐拉大，终于再也追不上了。</p><p>2019年，HMD发布了Nokia 9 Pure View，市场态度降至冰点。</p><p>首先是硬件配置不够，搭载了已经过时的高通骁龙845处理器，当时主流旗舰手机已经开始采用855处理器；其次是续航不足，电池容量只有3320mAh，远低于同期华为P30 Pro的4200mAh电池容量；主打拍照功能，但拍完需要等7秒钟才能查看照片，后置5个摄像头的设计也被吐槽“逼死密恐”。</p><p>更让人难以接受的是，它的价格还不便宜。国行版6GB+128GB版（6GB的随机存取存储器+128GB的内部存储空间）的售价达到了5499元，当时华为高端旗舰机P30 Pro的起售价也不过5488元。</p><p><strong>Nokia 9 Pure View之后，诺基亚全面倒向千元以下市场，这也是为什么如今诺基亚旗舰店里基本全是功能机和低端安卓机。</strong></p><p>功能机的受众是老人、儿童和需要备用机的人群，这部分市场很小，但HMD显然不想卷了，干脆守着这块小蛋糕，时不时复刻一些经典机型，赚点怀旧钱。</p><p>据《DT商业观察》不完全统计，诺基亚已经推出过许多款复刻机型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240606/v2_f8e9179b487a45a2a0abf0274b9f0ca4@46958_oswg159832oswg1080oswg1588_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这次3210复刻版，只是诺基亚众多复刻之作中的一个，因为它刚好踩中了当下复古回潮的情绪，因此迅速走红。</p><p>不过，诺基亚的复刻游戏也玩不了几次了。</p><p>今年年初，HMD Global推出了自有手机品牌HMD，并将X平台账号名称从@nokiamobile 改为 @HMDglobal。</p><p>2026年，HMD与诺基亚的品牌授权十年合约即将到期，双方选择不续约，HMD未来将专注自有品牌。</p><p>十年合约中，要说HMD是否有过带领诺基亚重振昔日荣光的梦想，答案可能是有的。</p><p>但现实是，在合约的最后两年，HMD或许会更加务实，只想抓紧最后的商业机会，能赚一点是一点了。</p><h2>写在最后</h2><p>1999年，经典的诺基亚3210问世，随即风靡全球。</p><p>2004年，千禧潮卷土重来，全新的诺基亚3210，带来曾经的 Y2K 回忆。</p><p>在诺基亚手机的官方微博上，最新一条微博写着：6月12日10点，将再次开启少量现货发售。</p><p>几天后，又将有一批人冲着像素或情怀为之买单，但从社交媒体的反馈来看，“疯抢”潮之后，人们正逐渐恢复理智——</p><p>情怀之外，不乏失望：“诺基亚3210，除了复刻，只剩复刻。”</p><p>但手机终究是电子产品，在技术飞速迭代、日新月异的当下，或许情怀+创新，才是更持久的翻红之路。</p><p class="editor-note">本文来自微信公众号“DT商业观察”（ID:DTcaijing），作者：林美汕；数据：林美汕；编辑：张晨阳；设计：戚桐珲；运营：苏洪锐；监制：李晶禹；，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2804966767326595</id>
            <title>「随遇AI」在微信引入AI高考志愿咨询师，搭建渠道聚焦河北市场 | 36氪首发</title>
            <link>https://www.36kr.com/p/2804966767326595</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2804966767326595</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Jun 2024 06:38:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 高考志愿, AI咨询师, 河北省, 随遇AI
<br>
<br>
总结: 2021年新高考招录后，河北省普通本科批考生面对庞杂的志愿选项，不少家长和考生不知所措。随遇AI团队推出了AI高考志愿咨询师“随愿”，通过微信提供普惠服务，帮助家长和考生完成高考咨询全流程。团队以技术支撑，与高考志愿咨询师合作，利用RAG和Multi-Agent系统提高回答准确性和可信度。团队认为河北的渠道优势是核心竞争力，计划通过直播和体验版预售向用户宣介。CEO表示AI志愿填报不是靠砸钱能解决的问题，团队希望通过教育市场推广。 </div>
                        <hr>
                    
                    <p>文 | 陈斯达</p><p>编辑 | 邓咏仪</p><p>2021年新高考招录后，全国大部分省份采取“专业（类）+学校”的志愿填报模式，普通类（本科批和专科批）最多可填报96个志愿。</p><p>在高考大省河北，由于对专业设置、招录信息、报考趋势缺乏了解，不少普通本科批的考生、家长面对庞杂的志愿选项，即便无需填满所有志愿，往往也显得不知所措。</p><p>市面上各机构推出的诸多高考志愿分析系统，虽能实现志愿预测，但缺乏交流问答，难以满足志愿填报时的咨询需求。不少家长为了“图个安心”，依然还会向真人咨询师付费寻求服务。由此催生的咨询行业，服务质量却参差不齐。</p><p>用AI协助填报高考志愿不算新鲜，今年吹来的则是AI Agent（智能体）的风。</p><p>着眼于河北省的高考志愿填报需求，“随遇AI”团队打造了以微信为载体的AI高考志愿咨询师“随愿”。在微信聊天框中，家长和考生能完成高考咨询的全流程。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240604/v2_bdd7da92a2b14eae9fa1aadc6076c2bb@5978882_oswg334995oswg1736oswg904_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">AI高考志愿咨询师“随愿”，图源：随遇AI</p><p>随遇AI团队成立于2023年，聚焦生成式AI在业务场景中的落地。技术成员来自华为、字节等互联网企业与广东省人工智能重点实验室，毕业于北京大学、新加坡国立大学、中山大学等高校。</p><p>CEO岳毅然介绍，此前自己作为河北考生填报志愿时，就体会到优质咨询师欠缺的痛点。</p><p>“我们希望帮助市场筛选出真正优秀的咨询师。”市场负责人苏方健向36氪介绍，“随愿”向广大考生家长提供普惠服务的同时，也能提高市场门槛。相较于此前动辄上千元半小时的真人限时咨询，“随愿”799元的普通版服务包含十次专业志愿报告，并提供66万字报考相关的问答咨询服务（可完成近2000次交互）。</p><p>除了需求因素，团队将“随愿”这一应用聚焦河北，来源于与河北高考志愿咨询师的数据及渠道代理合作。</p><p>苏方健向36氪介绍，“随愿”的数据大致分为两类，一是知识类，如学校、专业介绍等，需要花精力整理；二是填报类，即细致的招录信息。针对第二类信息，苏方健对此表示：“有很好的合作代理商和我们一起正在整理，（在此基础上）算出来的录取结果，比按趋势线算出来的精确很多。”</p><p>基于专属数据，随遇AI团队以技术支撑，与高考志愿咨询师围绕“随愿”应用进行合作。CTO张俊林介绍，在模型训练环节，团队会针对数据条目的筛选、权重等，与咨询师对齐沟通。在产品测试环节，咨询师会对训练结果提供反馈及建议。</p><p>而在团队提供的技术层面，“随愿”会先对用户提问进行意图分析，翻译成专业表述后提供给Agent。<strong>在之后过程中，Agent技术则充分利用最新的RAG（Retrieval-Augmented Generation）和Multi-Agent系统。</strong></p><p>一方面，RAG模型通过结合检索和生成的方式，从“随愿”高考知识库中的志愿填报数据中提取相关信息，来提高生成回答的准确性及可信度。另一方面，Multi-Agent系统允许多个智能体（包括意图识别Agent、志愿参数收集Agent、志愿问答咨询Agent、志愿推荐Agent）协同工作，分别处理不同任务，提升整体的效率和响应速度。通过多次调用大模型，它能针对考生需求构建完整 “志愿收集+志愿咨询”的workflow（工作流）。Multi-Agent系统在与考生经过多轮对话交互后，将结合考生所提供的志愿填报参数进行分析，定制推荐报考院校列表以及职业生涯规划，最后输出返回给用户。</p><p>若某专业招录情况在近年出现较大波动，“随愿”会在回答用户提问时，加上风险警示的标志，建议其转向咨询代理的咨询师。张俊林表示：“我们意在覆盖 80% 的通用的场景，剩下 20% 的场景交给质量水平更高的咨询师进行处理，两相配合，其实对整个市场来说更有利。”</p><p>团队向36氪介绍，产品测试，经由代理已将样本覆盖河北省内主要城市，目前仍在进行。针对经历过河北新高考志愿填报的大一大二本科在校生（此前的河北考生），测试样本数量达七八十位，深度访谈达二十位左右。</p><p>网易、百度等互联网企业入局AI志愿填报赛道较早，近期也已陆续更新自家产品。但团队基于调研也发现，河北家长对 AI 的认知仍尚处早期。CEO岳毅然对此表示<strong>，“大厂跟我们遇到的困难和阻力一样，（AI志愿填报）不是靠砸钱能砸出来的东西，反而是大厂做出来一些之后，会帮我们教育市场。”</strong></p><p>团队认为，河北的渠道优势是自身核心竞争力。团队向36氪透露，“随愿”已在省内积累十几个渠道。学校也会是“随愿”的潜在合作对象，因为学校“可能会开展地推，自身也会有一些渠道。”直营渠道上，团队计划通过直播以及29.9元的体验版预售，向河北用户进行宣介。</p><p>据悉，随遇AI团队的第一款标准化AI落地应用“随语”，已于2024年4月正式发布。“随语”将大模型、专家知识库能力接入微信生态（含企微、公众号、小程序），打造AI专家客服。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>