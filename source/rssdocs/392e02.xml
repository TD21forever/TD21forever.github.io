<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3033263896129540</id>
            <title>纷纷涨价的国产旗舰机，不愿错失久违的换机潮</title>
            <link>https://www.36kr.com/p/3033263896129540</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033263896129540</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 12:31:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能手机, 涨价, 高端市场, 竞争  
<br><br>  
总结: 2024年秋季智能手机发布季已接近尾声，各大品牌如小米、OPPO、vivo等纷纷推出旗舰新品，普遍选择涨价以应对成本上升和抢占高端市场。涨价背后是芯片和内存等核心元器件成本的上涨，导致厂商在定价上不得不做出调整。消费者对高端手机的需求回暖，市场出货量同比增长，安卓厂商们积极对标苹果，试图在高端市场分一杯羹。各品牌通过差异化的功能宣传来吸引用户，尤其是在AI功能的应用上。 </div>
                        <hr>
                    
                    <p>在半个月的喧嚣之后，11月初2024年秋季的智能手机发新季步入了尾声。</p>
  <p>除了华为Mate系列新品尚未亮出真容，小米、OPPO、vivo等各大主流品牌的2024旗舰新品，都已列队集齐。</p>
  <p>而纵观市场，涨价的动作几乎成了所有智能手机厂商的共同选择。这一操作背后，既是厂商们对成本上浮的“被动”回应，也是诸位玩家不愿放弃新一轮用户换机窗口、想要抢占高端市场的主动选择。</p>
  <p>亚马逊创始人贝佐斯曾说过：“（竞争对手的）利润就是我的机会。”</p>
  <p>将中低价格段智能手机市场红利分食殆尽后，每个安卓阵营的局中人都想要在苹果所代表的更高价位段中，找一条出路。</p>
  <h2><strong>抢芯片首发、造营销概念，为涨价铺垫</strong></h2>
  <p>紧随高通、联发科两家移动处理器龙头企业公布新一代旗舰平台后发布新品，向来是智能手机市场的传统节目。</p>
  <p>今年，联发科新品天玑9400首发花落10月14日发布的vivo X200及Pro系列；10月24日发布的OPPO Find X8及Pro系列手机同样搭载天玑9400。</p>
  <p>高通阵营则在10月22日骁龙8至尊版发布会后，开启了密集的新品亮相节奏。</p>
  <p>仅仅相隔一星期后的10月29日，小米15及Pro官宣首发搭载骁龙8至尊版亮相。在随后的6天之内，iQOO、荣耀、一加、真我轮番登场。</p>
  <p>其中除了iQOO，涨价的情节不约而同发生在了所有品牌身上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_3fd566811c2c456eb26b4e8029c2e0c8@46958_oswg295709oswg1080oswg903_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>采用联发科新品的vivo X200及Pro全系起售价相比上代上浮了300元；OPPO Find X8起售价也上浮了200元，Pro则与上代持平。</p>
  <p>而高通芯片阵营中，小米15相比前代起售价上涨最高，直涨500元，来到4499元；小米15 Pro则涨了300元。</p>
  <p>其他搭载高通芯片的厂商也各有不等涨幅，如荣耀Magic 7相比前代起售价上浮了100元，但Pro系列维持了原定价。一加13相较前代涨了200元。真我则跳过了GT6 Pro序列，直接发布了3599元起售的真我GT7 Pro，相较GT 5 Pro也涨了200元。</p>
  <p>主流厂商最新机型均已来到5000元级价格。在售价调涨的氛围之中，各家也在为抢夺用户心智各出奇招。</p>
  <p>为了迎接历史最大涨幅的小米15，小米已经进行了为期一年的预告——早在去年同期的新机发布会上，小米创始人雷军就曾预告15系列的涨价计划，称“小米14将是最后一代3999元起售的数字旗舰”“希望能做出更好的手机，后续将不再卡这个价位段”。</p>
  <p>作为行业领袖，雷军的发言引起了足够的关注，也给了消费者足够长的心理缓冲期。</p>
  <p>其余企业同样在着力宣传各自在高端化功能上的差异化创新，如vivo X200主打影像效果，号称“专业影像旗舰”；荣耀Magic主打AI功能，号称“开启手机自动驾驶时代”；一加打出了“不分杯型”“样样超Pro”的宣传点……诸如此类。</p>
  <h2><strong>涨价的芯片，趋大的内存</strong></h2>
  <p>整齐划一的涨价动作，与供应链成本上浮带来的压力脱不开关系。</p>
  <p>本轮发新季，不止一家手机厂商提及了SoC、存储器件等核心零部件涨价对产品定价造成的影响。</p>
  <p>比如雷军称“小米15确实需要涨价”，原因是今年元器件成本上涨非常多，小米的研发投入也非常大。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_de0ee7c0fda64e32a2796ff9468bf186@46958_oswg312739oswg1068oswg1004_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>联发科阵营情况同样如是，vivo产品副总裁黄韬曾在X200发布会后的专访中对媒体表示，今年SoC等核心元器件成本上涨幅度非常大，且短期内难以缓解，因此vivo需要在成本控制和产品竞争力之间寻求平衡。</p>
  <p>无论骁龙8至尊版还是天玑9400，都是由台积电3nm工艺代工制造，后者定价昂贵，让处理器成本也水涨船高。如数码博主“数码闲聊站”透露的：““N3E（台积电第二代3nm）工艺挺贵的，这代旗舰芯的成本暴涨20%+，D9400采购成本约155刀，S8750采购约190刀。这代旗舰SoC的成本已经和一台中端机的价格差不多了。”</p>
  <p>而迈进“大模型落地商用元年”的2024，将大模型支持的AI功能“塞进”手机，同样是市场逃不开的命题。</p>
  <p>以外媒The Verge援引的数据为例，想要将微软参数量3.8亿的AI模型Phi-3-mini部署到智能手机，需要占用后者1.8GB的运行内存。因此，无论哪家厂商，想要在引入AI功能的同时保证丝滑体验，都需要选用更大的内存配置。</p>
  <p>比如最新发布的小米15系列直接全系取消了8GB内存版本，从12GB起跳。另据苹果爆料网站MacRumors报道称，iPhone 16全系配备了8GB的运行内存，而去年的iPhone 15和iPhone 15 Plus机型运行内存只有6GB。</p>
  <p>而作为手机RAM核心处理器的NAND Flash等存储芯片，同样在2024年步入上涨周期，也将涨价传导至整机环节。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_bab4a3e0c34f49bf913eb9e25b8befa6@46958_oswg20333oswg548oswg152_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>据TrendForce集邦咨询数据，2024年第二季DRAM合约价涨幅上修至13～18%；NAND Flash 合约价涨幅上修至约15～20%。</p>
  <p>红米品牌总经理王腾也曾公开指出这一点，称除了处理器芯片涨价，另一方面是内存经过持续一年的涨价已经达到了高点，所以大内存版本的手机涨幅会更大。</p>
  <h2><strong>冲刺高端，围剿苹果</strong></h2>
  <p>各大安卓厂商积极造势、轮番登台的核心原因，是用户对高端手机的消费需求明显反弹，为市场玩家提供了不容错过的宝贵窗口期。</p>
  <p>据IDC报告显示，2024年第三季度，中国智能手机市场出货量约6878万台，同比增长3.2%，连续四个季度保持同比增长。</p>
  <p>这种趋势也有望在第四季度持续。IDC中国研究经理郭天翔对此分析称，自去年四季度以来，中国智能手机市场表现稳步回升，过去三年积压的换机需求逐步释放，许多用户已到了不得不换手机的时候，经济环境因素并未明显抑制换机需求。这也为手机厂商们提供了不容错过的增长窗口。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_2eca9779af3b4167b3dacaa3a8beb7ae@46958_oswg62406oswg974oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>另一方面，IDC数据显示，消费者对高端手机的消费意愿也在稳步上涨，第三季度中国600美元以上高端手机市场份额达到29.3%，相比去年同期增长3.7个百分点。</p>
  <p>而传统高端手机市场的两大玩家中，苹果新品上市首销以后，市场需求并无明显改变，iOS市场出货量同比下降0.3%；华为在2023年8月底Mate系列回归之后，占据4000-8000元市场份额第一，但仍面临新品较少、供应量低的困境。</p>
  <p>特别是在中国市场，苹果Apple Intelligence短时间内无缘国行版本，而国产厂商在大热的AI功能落地方面更占据先机。</p>
  <p>凡此种种，让几乎所有安卓厂商一致对标苹果，试图从5000元以上价位段市场分一杯羹。</p>
  <p>对高端定位的强调，也体现在每个玩家对旗舰新品的宣传之上。</p>
  <p>如小米15号称可全面支持苹果生态，支持与Macbook、iPad、iPhone互传文件、与Macbook镜像投屏、支持苹果办公套件等，同时在外观上也对齐了苹果的冷雕玻璃背板工艺。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_25d33963b62d46d0a82fe0c1b99ff315@46958_oswg680924oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>荣耀Magic则着力宣传AI体验，CEO赵明称“智慧化体验上，所有的厂商都没办法和荣耀进行对比和竞争，在这个方面我们甩开了所有的厂家”，并认为现阶段iPhone 16在中国市场几乎没有太多AI体验、难以与荣耀并肩。</p>
  <p>OPPO Find X8更是直接挑明了野心，OPPO首席产品官刘作虎直言：“我们就是想转化苹果用户，说得直白一点，让苹果的用户有另外一种选择。”</p>
  <p>当久违的换季潮出现，没有人舍得错过这个机会。而在接下来的11月，华为Mate系列新品的亮相，还将为这个群雄环伺的市场带来新的变化。</p>
  <p>唯一确定的是，对安卓阵营玩家而言，在智能手机的红海市场背景下如何向高端要增长，将是一场长期的实践。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/FnO8pt-wgaPnbKvRjEZlsA" rel="noopener noreferrer nofollow" target="_blank">“电厂”</a>，作者：董温淑，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033339740549122</id>
            <title>OpenAI重金购得新域名，但这门生意早就没了前途</title>
            <link>https://www.36kr.com/p/3033339740549122</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033339740549122</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 12:28:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, OpenAI, 域名交易, 移动互联网  
<br><br>  
总结: 2022年秋季，ChatGPT的推出使OpenAI成为热门科技企业，其成功在于提供自然对话能力。OpenAI收购了chat.com域名，反映出域名交易的高价值。然而，随着移动互联网的兴起，用户更倾向于使用App而非浏览器，导致域名的“入口价值”下降。如今，域名交易市场出现两极分化，优质域名仍有价值，但大多数普通域名则难以盈利。持有域名的成本也在增加，使得域名交易的吸引力减弱。 </div>
                        <hr>
                    
                    <p>2022年秋季聊天机器人ChatGPT的横空出世，不仅让AI行业一扫颓势，更是使得其开发商OpenAI成为了当下炙手可热的科技企业。其实ChatGPT的成功方式相当简单，因为它提供了与人类无异的自然对话能力。而为了强化“聊天”这个概念，OpenAI方面最近更是斥巨资购买了一个新域名。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e2d9d0615d6c4d4e90d544455b2358db@000000_oswg8718oswg600oswg183_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>近日，OpenAI CEO萨姆・阿尔特曼在社交平台发布了一则推文，但内容相当的简单、只有一个网址chat.com，点开后就跳转到了ChatGPT。据海外科技媒体TechCrunch透露，OpenAI已收购这一域名。事实上，这个域名此前是被HubSpot创始人Dharmesh Shah在2023年年初购得，当时的价格为1000万美元。</p>
  <p>紧接着在2023年3月28日，Dharmesh Shah以1550万美元的价格将其卖给了一位匿名买家。所以很显然，此次OpenAI买到这个域名的价格只会更高。看到这里或许有的朋友会认为域名交易还大有可为，属于是能一夜暴富的机会。但如果真的这样想可就大错特错了，毕竟都快2025年了，还指望靠买卖域名赚钱已经不现实。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a8292beae4954397a7fa632d603911c9@000000_oswg13560oswg600oswg264_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>域名是由一串用点分隔的名字、组成的Internet上某一台计算机或计算机组的名称，用于在数据传输时对计算机的定位标识，它采用了易于记忆的字符串形式来代替复杂的IP地址。作为互联网上的“门牌号”，域名在网络中的作用其实就与现实中的房地产业类似，所以自然也就出现了炒域名的现象，并且域名交易也是互联网中经典的“小而美”生意。&nbsp;</p>
  <p>过去二十余年以来，通过域名交易一夜暴富的案例并不少见。例如在2011年4月，新浪花了800万元人民币购买了与微博全拼相同的域名“weibo.com”；随后在2014年，中国商人徐俊花340万美元从孩之宝公司手中买下game.com域名，然后在2016年以1亿元人民币的天价卖给了游戏矩阵CEO徐乐。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_fbc11439b1514b64b5662ca865aa1933@000000_oswg33887oswg324oswg437_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>那么为什么在2024年，已经很难再靠买卖域名赚钱了呢？只因时代变了。且不提当年小米花费360万美元购入mi.com，以及前文中提到的一系列卖出天价的域名，其实都是非典型案例。目前在域名交易网站上，绝大多数域名的成交价格都在几百上千美元这个范围，赚的则是传统企业数字化的钱。早在十余年前，全球都掀起了一股传统企业数字化转型的浪潮，大量传统企业由此也产生建设网站的需求，但想要搭建一个网站、域名就是前提。&nbsp;</p>
  <p>如此一来，庞大的需求造就了一片广阔的蓝海，无论是通过出色的眼光发现风口、还是倒买倒卖，域名生意在十多年前也曾红红火火过。如果后来没有移动互联网的到来、没有App的出现，域名生意大概还会长盛不衰。尽管域名作为互联网关键基础资源这一事实没变，但在移动互联网出现后，用户虽然依旧需要用域名解析来访问互联网，但变化的是我们已经再看不到域名了。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e91d4573300c4f289b57ecbea4862ec6@000000_oswg36749oswg600oswg378_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>事实上，域名是基于web生态的，并且与浏览器强关联，可大家如今在智能手机上用的是App、是小程序，反而手机浏览器的用户群体一直在萎缩。即便有相当多的App都只是web套壳，即用原生WebView+HTML5网页内容的形式来构成App，可用户直接体验的UI却是App的范式，而App几乎不会有网址栏。这一现实所导致的结果，就是成长在移动互联网时代的网民，可能压根就不知道域名为何物。&nbsp;</p>
  <p>在移动互联网时代，入口从浏览器变成了App，用户只需要在应用商店下载需要的App即可，根本就不需要通过浏览器来参与上网冲浪，大家自然也就不再需要记域名了。如今甚至就连搜索引擎都遭遇了“水逆”，遑论更古早的域名。当下即便有企业想要拥抱数字化，第一选择也是开发App、小程序，毕竟现在智能手机已经是人手一部、可电脑并非人手一台。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_032a1514e1284129b280a800ade37ecd@000000_oswg19151oswg600oswg248_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>以往企业购买域名是为了起到宣传作用，因为用户每一次键入域名都会加深对它的认知。但如今没有输入域名就访问网站，也就意味着域名失去了“入口价值”，其估值逻辑必然会被重构。即便类似chat.com这样有含义家喻户晓的顶级域名不受影响，但其他意义不明的域名则会变得不再有价值，所以如今两极分化就是域名交易市场的主旋律。&nbsp;</p>
  <p>显然对于大多数人来说，往往缺乏财力来玩转优质的域名资源。不仅如此，维护一个域名在互联网世界的存续也是要花钱的，因为域名存在持有成本，虽然单个域名每年几十元人民币看似不多，可要是多个域名累加起来就不是笔小钱了。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_52c89c5b40894ac69628c82895a67190@000000_oswg33272oswg600oswg328_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>所以普通产品不值钱、且不好卖，持有还需要持续花钱的生意，真的还是一门好生意吗？&nbsp;</p>
  <p>【本文图片来自网络】&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649874811&amp;idx=3&amp;sn=b90ce12b594c5d747b4fa3af053c4628&amp;chksm=8684112c17b533b8796e86b0079c1abf6baed3dabd725f40a48b7acde1b5b74e82c1f8f3fc9b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033214419940231</id>
            <title>INMO Air 2：消费级AR，一个弥足珍贵的“失败”案例</title>
            <link>https://www.36kr.com/p/3033214419940231</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033214419940231</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 12:09:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AR眼镜, INMO, 微显示屏, AI技术  
<br><br>  
总结: 本文讨论了AR眼镜市场的现状，特别是INMO作为“AR四小龙”中的一员，其在技术尚未成熟的情况下推出消费级AR眼镜的努力。INMO Air 2采用了独特的硅基OLED和阵列光波导方案，尽管面临亮度和分辨率的挑战，但其全彩显示和高透光率的设计仍然引人注目。同时，文章分析了AR眼镜在微显示屏和光传输组件方面的技术难题，指出了消费级AR眼镜在实现高性能、低成本和良好用户体验之间的矛盾。最后，AI与AR的结合被视为未来发展的重要方向，但实现这一目标仍需克服诸多技术障碍。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5216a28e52524f8ba3e4910eccd0ebd5@5900414_oswg87737oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Meta不计成本作出了Orion这一接近消费级AR眼镜之后，彭博社爆料苹果启动Atla“智能眼镜”项目，OpenAI招募了前Meta公司Orion增强现实眼镜项目的前负责人Caitlin Kalinowski，也在酝酿在AI硬件的动作。</p>
  <p>因为LLM的突破，这一波狼来了，对于AR眼镜来说，可能从根本上已经不同以往。在谈这一波AI+AR眼镜热潮前，有一家在国内甚少被讨论的AR眼镜公司，INMO，它的“失败”案例值得被研究。</p>
  <h2><strong>01 特立独行背后</strong></h2>
  <p>曾经有一个「AR四小龙」概念 ，将INMO 排第四。&nbsp;</p>
  <p>国内消费级AR创业圈子，INMO名气不大，却有一股子莽劲。这家公司在基础技术远未成熟的情况下，十分“严肃”地做出了一台设计正统、功能完整的消费级AR眼镜，而且上市发售了。&nbsp;</p>
  <p>亚洲四小龙、AI 四小龙、再到AR四小龙，是形容它们活力满满，它日必成龙成凤。 2022年开始，国内AR创业圈子里诞生了一个由XREAL、雷鸟创新、Rokid、INMO影目组成的「AR四小龙」行业概念，它们代表着中国消费级AR的希望之星。 但排行老四的 INMO 不似小龙，更像是中世纪的古典骑士，那种正经、严肃、笨拙、悲情的堂吉柯德式骑士。&nbsp;</p>
  <p>INMO 存在感相当弱，特别是与其他“三小龙”对比。XREAL号称全球消费级AR市场份额领先，关键的BirdBath光学模组、微机电、整机ID确实强一些，多个早期BirdBath方案眼镜在国外被大量引用讨论；雷鸟创新脱胎于TCL创新实验室，在近眼显示光学设计上积累know-how，还敢在光引擎上尝试RGB全彩的Micro LED方案；Rokid累计融资金额最多，B端C端双拳出击，创始人祝铭明的创业团队阵容豪华，有教育、数字文化、娱乐、旅游、地方机构的“朋友圈生态”，而且硬件供应链资源属于独一档。相比之下，INMO影目科技，似乎找不到一些足够差异化足够印象深刻的特征，能精准描述。</p>
  <p>如果要给 INMO贴个标签，产品路线特立独行，「顽固又硬核」。&nbsp;</p>
  <p>相比Hololens和Magic Leap 这种「AR头盔」，集成了大量传感器、电池、专属算力芯片的工业级AR眼镜，INMO AIr2 更接近真正的消费级AR眼镜，无论它一眼看上去的体积，产品原理还是实际功能，完整又「极简」。&nbsp;</p>
  <p>INMO Air 2不同于XREAL、雷鸟、Rokid 三家Air系列消费级AR眼镜，在空间中虚拟一块固定尺寸的「大屏幕」主打观影和游戏，强调空间显示功能，INMO Air 2有号称最为轻量级的SLAM，有基本的虚实交互，透光率更高。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a67d0bac0a674a9293c4cebaa324f5f1@5900414_oswg39104oswg686oswg386_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>也不同于OPPO Air、李未可眼镜以信息提示、翻译场景为主，产品多用单绿色Micro LED配合衍射光波导，INMO Air 2 在光波导方案上，实现了全彩色显示而非仅仅显示绿色。而类似OPPO、李未可的信息提示光波导AR眼镜，在使用场景、刚需程度、使用频率、出货量上，可能还比不上雷鸟、XREAL、Rokid三家BirdBath原理的观影眼镜。&nbsp;</p>
  <p>INMO特立独行在于，它在基础技术还未成熟的情况下，硬要做出一套有基础AR功能、针对消费级可正常穿戴的日常眼镜，一体式而非分体式，计算、传感、电池、显示都高度集成在眼镜本体，形态接近下一代消费电子。2022年10月底发布，2023年4月才正式上市的INMO Air 2，采用了截然不同，或者说极为罕见、独一无二的硅基OLED+阵列光波导产品方案。&nbsp;</p>
  <h2><strong>02 消费级AR的不可能三角</strong></h2>
  <p>AR眼镜的产品原理，说起来很简单：</p>
  <p><strong>首先，将微显示屏的光学图像，以微型投影仪的方式发射出去。实现组件就是所谓的光引擎或者眼镜的“光机”</strong></p>
  <p><strong>其次，让图像显示的数字内容跟现实的光线“混合”在一起，以某种设计好的方式传输进入眼睛。这涉及的过程就是光传输，实现组件就是光学模组，比如BirdBath透镜组合、自由曲面透镜、衍射或者阵列光波导。</strong></p>
  <p>微显示屏是第一道巨坑，而且是绕不开的成本大头。目前三种的主流微显示屏，硅基液晶（LCoS）、硅基OLED(Micro OLED）、Micro LED，它们都是硅基板而非玻璃基板，在很小的显示面积上实现极高的像素密度，类似芯片的方式“种植”微显示器，制造过程同时涉及半导体和先进显示。</p>
  <p>硅基液晶目前在分辨率、全彩显示方面性能优异。但问题在于，它并不属于自发光的直接显示，发光器件经过液晶层的相位变化光线调制和极化，会有层内的各种反射、散射损失。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_79de307830f64164b818bc974b87551a@5900414_oswg326241oswg800oswg531_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>如今的LCoS光引擎先以R、G、B三色panel 以半透半反分光，再以PBS棱镜的方式“聚合”在一起，光引擎结构复杂体积难以大幅压缩，而且出射图像亮度不够，经过传输后入眼亮度低，这是AR眼镜最关键和最致命的问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_dbdd42ca23054612aab31692d15c2179@5900414_oswg23648oswg603oswg297_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>硅基OLED作为目前的主流方案，OLED自发光组件，结构简单、体积小、色彩表现良好。但问题是采用先进制程压缩单像素面积、进一步提升分辨率的时候，良率低，成本高，高分辨率面板价格非常昂贵。&nbsp;</p>
  <p>微显示屏作为新兴显示产业，终端品牌都需要从供应链厂商采购，Apple Vision Pro使用了2块索尼4K分辨率的硅基OLED微显示屏作为内屏。之前媒体流传的BOM清单显示，售价3499美元的Apple Vision Pro硬件物料成本约 1509 美元，其中索尼供应的两片4K分辨率OLED内屏一片350美元，合计 700 美元，几乎占据了物料成本的一半，为成本最高的零组件。相比之下，台积电代工的M2 处理器仅需 120 美元。&nbsp;</p>
  <p>天价Apple Vision Pro如今销量惨淡到被传停产，索尼的4K分辨率微显示屏可谓“功不可没”。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6d6f9eded48743ceb52e4ed8ab1d165d@5900414_oswg71527oswg1080oswg644_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>硅基OLED的另一个致命问题，是亮度依然不够高，覆盖不了白天日光环境，特别是跟只有1%光效率衍射波导组合在一起使用的时候。</p>
  <p>Micro LED是最终极最理想的微显示屏，无机材料寿命长，也是自发光原理，超高亮度远超硅基液晶和硅基OLED，色彩饱和度和对比度也是最佳。但受限于基础技术的问题，没有办法在单片微显示屏面板上实现RGB三色像素集成，换句话说，它连彩色显示都很难做到，只能采取工程化的办法，而且高分辨率微显示面板生产制造非常难，同样巨贵无比。&nbsp;</p>
  <p>Micro LED要实现彩色显示，要么通过三块R、G、B小面板「合光」，三个控制板加合光棱镜，即JBD的x-cube棱镜方案，要么是还在实验室里的堆叠像素方案。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_98c87b7e887c42399d484013c57923a9@5900414_oswg50798oswg1080oswg682_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Micro LED目前的R、G、B三种面板的无机发光材料底层物理过程迥异，亮度一致性差异很大，而要将Micro LED分辨率提升到2K、4K，面临一系列基础物理、大规模生产制造良品率问题，理想的高分辨率Micro&nbsp;LED，成本也是天价。&nbsp;</p>
  <p>一句话总结，硅基液晶亮度不够且光引擎组件很难小型化；硅基OLED亮度勉强，分辨率高但是成本也高；Micro LED最理想但不成熟，连彩色显示都困难，只有单绿色光引擎可以达标。&nbsp;</p>
  <p>说了这么多，这还是微显示屏的第一个坑。第二个坑，光传输组件，同样困难无比。</p>
  <p>AR眼镜能够正常看清外界，要求它能像普通的眼镜一样高透光，与此同时，光引擎出射的数字内容和外界的真实光线，也需要“混合”一起进入眼睛。</p>
  <p>BirdBath和自由曲面方案是一组透镜组合，将眼镜顶部光引擎发出的图像光线，经过反射、折射、对焦等设计好的光路，传导到眼睛，这个方案不可避免在眼睛前方设计一个透光率不高的半透射半反射镜片。BirdBath和自由曲面眼镜，像XREAL、雷鸟、Rokid的Air系列眼镜，目前只有20%左右的透光率，只能是「墨镜」，最佳使用场景是观影。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_f9fea91bd248417bbb47c806ab0debfb@5900414_oswg21604oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>而像Apple Vision Pro这样的VR眼镜，干脆直接把“屏幕”放在眼前，设计一个非常复杂的折反射光学镜片组合，把图像光传输到眼睛。VR挡住所有前方的自然光线，依靠摄像头才能看清外界，这就是常说的依靠摄像头“透视”的VST方案。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c5826a70d7da4c409a9fa2ff393a19d6@5900414_oswg54857oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>摄像头传输画面的延迟、画面刷新率、图像畸变导致的眩晕，以及难以规避的VAC视觉辐辏冲突，你只能盯着一定焦距的画面，眼睛会快速疲劳，还有沉重的头盔设计，种种难以改进的佩戴体验。VR已经被市场反复验证了十几年，几乎注定了不会成为C端消费电子的主流，VST原理的眼镜即使是苹果，10年磨一剑的Vision Pro，也避免不了成为吃灰的摆设。&nbsp;</p>
  <p>AR眼镜像普通眼镜一样能做到光学透视OST，无限景深，还有一个方案，就是光波导。&nbsp;</p>
  <p>波导技术并不是什么新发明，我们熟悉的光通信系统中，用来传输信号的光纤组成了无数条连接大洋彼岸的海底光缆，就是波导的一种，只不过传输的是我们看不见的红外波段的光。在AR眼镜中，要想光在传输的过程中无损失无泄漏，“全反射”是关键，即光在波导中像只游蛇一样通过来回反射前进而并不会透射出来。&nbsp;</p>
  <p>光波导总体上可以分为几何光波导（Geometric Waveguide）和衍射光波导（Diffractive Waveguide）两种，几何光波导就是所谓的阵列光波导，也就是文章最开始INMO Air 2使用的那种。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_648f63a707384ed698b3987620d6cf1c@5900414_oswg95921oswg1080oswg1059_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>阵列光波导里，耦合的图像光进入波导的一般是一个反射面或者棱镜。 在多轮全反射后光到达眼镜前方时，会遇到一个“半透半反”镜面阵列，耦合图像光再耦出波导，进入眼睛。（图a所示）&nbsp;</p>
  <p>“几何光波导”的概念最先由以色列公司Lumus提出并一直致力于优化迭代，至今差不多快二十年了。它的制造良率问题一直没有根本性的进展。&nbsp;</p>
  <p>阵列光波导的问题就出在多个“半透半反”(确切说是“部分透部分反”)的镜面。它们是嵌入到玻璃基底里面并且与传输光线形成一个特定角度的表面，每一个镜面会将部分光线反射出波导进入人眼，剩下的光线透射过去继续在波导中前进。&nbsp;</p>
  <p>阵列光波导，图像质量包括颜色和对比度可以达到很高的水准，而且光传输效率最高可以达到10%左右，比衍射光波导只有1%光效率，优势明显。 但问题在于，阵列光波导工艺流程比较繁冗，特别是“半透半反”镜面阵列的镀膜工艺。&nbsp;</p>
  <p>由于光在经过多个半透半反镜面阵列传播过程中会越来越少，阵列中五六个镜面的每一个都需要不同的反射透射比(R/T)，以保证整个动眼框范围内的出光量是均匀的。 并且由于几何波导传播的光通常是偏振光，导致每个镜面的镀膜层数可能达到十几甚至几十层。&nbsp;</p>
  <p>另外，这些镜面是镀膜后层层摞在一起并用特殊的胶水粘合，然后按照一个角度切割出波导的形状，这个过程中镜面之间的平行度和切割的角度都会影响到成像质量。因此，即使每一步工艺都可以达到高良率，这几十步结合起来的总良率却是一个挑战。每一步工艺的失败都可能导致成像出现瑕疵，常见的有背景黑色条纹、出光亮度不均匀、鬼影等。&nbsp;</p>
  <p>因为阵列光波导难以解决的生产良率问题，以及多个半透半反镜面外观上影响美观的条纹，另一个方向的衍射光波导成为了包括Hololens、Magic Leap 实际应用的主流。而衍射光波导同样也有一堆问题，不同波长可见光衍射角度不一致，彩虹纹、光传输效率低、眼镜前向漏光影响正常的“视觉交流”。&nbsp;</p>
  <p>除了光引擎和光传输组件的种种技术困难，难有完美的解决方案，更大的FoV（虚拟图像显示视野），更大的EyeBox（适应绝大多数人的双眼瞳距），更高的入眼亮度，对于AR眼镜实际体验也至关重要。行业里，一直围绕着不同微显示屏光引擎设计、光波导基底材料、衍射和阵列光波导在持续改进和努力突破。</p>
  <p><strong>总结来说，性能全面没有短板的微显示屏，OST光学透视原理的高质量图像传输，完整的虚实结合和先进人机交互。这是一体式消费级AR眼镜的的不可能三角。</strong></p>
  <p>回过头来，这也是INMO Air 2的奇葩之处：INMO Air2搭载的珑璟LCE2210V 模组，在光机方面采用Mirco-OLED屏幕，光传输采用阵列光波导全彩双目方案。亮度勉强、分辨率一般但全彩显示效果优秀的硅基OLED屏幕，制造困难但光传输效率更高的阵列光波导，这样的方案，几乎是独此一家。INMO执着于做成一副轻量化+彩色显示+高透光的光波导眼镜。&nbsp;</p>
  <h2><strong>03&nbsp;后话，AI眼镜必然是彩色显示的光波导眼镜</strong></h2>
  <p>从2012年Google Glass 正式推出开始，满打满算已超过第十二个年头。消费级AR眼镜有潜力取代智能手机，成为下一代消费电子的「主力」，基本上还停留在痴人说梦的阶段。</p>
  <p>虽然AR眼镜这十多年来一系列新技术层出不穷。</p>
  <p>从深层次创新的角度来说，国外像Hololens引入了v-SLAM、衍射光波导、窄光谱的激光显示；Magic Leap演示了更加轻量化的AR一体机，紧凑强大的LCoS光引擎，大FoV、高分辨率、显示效果出色且能全局和分区调光；国内，Xreal带来了BirdBath光学透镜组合，在硬件成本和显示效果之间达到了较好的平衡，雷鸟尝试更终极的全彩显示MicroLED和光波导组合方案，Rokid则在BirdBath模组上实现了难度较高的SLAM锚定和交互，眼镜与主机和外设一起，意图实现移动办公和移动娱乐。</p>
  <p>还有最近的重磅，Meta Orion眼镜将轻量化、高性能、更好的OST光学显示方案和先进人机交互统统满足，但是以不计成本的方式。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_3bd09d39109548e186c99159417d3bef@5900414_oswg61114oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Meta Orion极为罕见地将碳化硅晶圆取代玻璃做衍射光波导基底，碳化硅超过2.0的材料折射率将FOV虚像视野提升到70度，可谓前所未有。Meta Orion在一副100克左右的眼镜上集成了来自JBD合色方案的Micro LED全彩显示的光引擎、复杂的多片衍射波导、电池、无线高速数据传输、高精度的眼球追踪、视觉SLAM等完备且先进的AR人机交互手段，还有融合了Meta强大的端侧小模型。</p>
  <p>相比INMO Air 2，Meta Orion也是一款能做到彩色显示的光波导AR眼镜。它满足日常佩戴使用的轻量化设计，高透光、彩色显示，上手体验极佳的AR人机交互，相比INMO Air 2有极大提升，也是AI眼镜目前最好的标杆。但没法大规模量产，成本是惊人的10000美金。</p>
  <p>在基础技术极为原始和粗糙的阶段，在产品可靠性、易用性、大规模生产成本和良率都十分有限的情况下，如何找到PMF，是消费级AR眼镜、通用人形机器人这些下一个10年最具想象力的产品，所普遍面临的困境。</p>
  <p>螺丝壳里造一个道场，角落里的技术高潮解决不了创业公司长期生存问题。当新技术出现，与原有产品产生「核子反应」，内爆出一个一定体量的市场，衍生出能够被验证的使用场景，这样的机遇非常罕见。</p>
  <p>如今，这样的机会恰好出现在AR眼镜上。因为LLM的爆发，生成式AI、多模态端侧模型，AI+AR的结合，是大模型被一致看好的“落地”方式。但是AI眼镜的硬件进展，在大规模高良率生产、成本可控、体验完整且优秀方面，路依然很长，很难。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/9SSYvbLmKi8OHuiGhyAnZw" rel="noopener noreferrer nofollow" target="_blank">“X研究媛”</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033227308397446</id>
            <title>流量卡，野蛮生长背后的灰色秘密</title>
            <link>https://www.36kr.com/p/3033227308397446</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033227308397446</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 12:03:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <流量卡, 产业链, 电信运营商, 代理商>
<br>
<br>
总结: 文章探讨了流量卡产业链的快速发展，涉及电信运营商、电商平台、快递公司和UP主等多个环节。随着移动互联网应用的普及，用户对流量的需求激增，而电信运营商的高价套餐使得许多用户转向低价流量卡。尽管流量卡市场蓬勃发展，但也伴随着诸多问题，如虚假宣传、个人信息泄露和代理模式的风险等。整体来看，流量卡产业的灰色地带反映了用户需求与产业发展之间的矛盾。 </div>
                        <hr>
                    
                    <p>你的第二张手机卡，正在成为一个养活百万人的新产业链。</p>
  <p>这条产业链的从业者涉及电信运营商、电商平台、快递公司、流量卡代理商、UP主等多个环节。</p>
  <p>他们围绕流量卡形成了新的蛋糕。</p>
  <p>对于运营商，流量卡已经成为了实现用户增长的新手段；在京东和天猫等平台上，搜索“流量卡”，不仅会出现许多第三方商家，也成为了官方自营的一项业务；在物流环节，顺丰和京东快递已经专门的流量卡激活小哥,带着设备和卡片满城跑，"每天根本忙不过来！”；在哔哩哔哩等视频网站里，推广流量卡的UP主时常出现在首页黄金位置。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e3faf9be20da4921be033be0e9149234@5457197_oswg166552oswg828oswg1139_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>一块小小的流量卡能形成如此大的生态体系，即有移动互联网生态的催动，也有电信运营商运营政策”倒逼“的原因。</p>
  <p>不过在这个行业高速增长的同时，伴生着的还有野蛮生长的杂草。</p>
  <h2><strong>01 被逼出来的第二张卡</strong></h2>
  <p>以短视频、直播、音乐等为代表的移动互联网应用的流行，给用户带来了巨大的流量需求。</p>
  <p>工信部数据显示，2024年5月，国内手机用户户均移动互联网接入流量DOU（平均每户每月上网流量）达到18.54GB/户/月，某些省区的DOU已接近30GB/户/月。</p>
  <p>然而，与用户对于流量需求形成鲜明对比的是电信运营商在流量方面"扣扣索索“。</p>
  <p>新商业派发现，以江苏地区中国移动、联通、电信官方APP中的长期大流量套餐为例，这些套餐均费用不菲。</p>
  <p>其中中国移动 40G流量套餐，办理价格为 128 元/月，中国联通30G流量+500分钟通话套餐，办理价格为129元/月；中国电信30G流量+500分钟通话套餐，原价129元，打折后也高达89元/月。</p>
  <p>高昂的套餐费用，用户们显然吃不消。</p>
  <p>于是在几年前，许多人开始将目光转向了一种新的事物——电商平台上出现的物联网卡，据了解，这些卡本身三大运营商提供给共享单车、指纹解锁等物联网设备使用，有商家解释，“和普通的流量卡不同，只能用流量不能打电话，所以价格相当便宜。“</p>
  <p>由于价格便宜，在一段时间内，物联网卡在电商平台上非常热销。</p>
  <p>不过运营商们也很快发现了这种现象，开始逐步打击这种“钻漏洞”的行为，检测到之后会直接停卡。</p>
  <p>不过，物联卡这件事儿也带了一个新的结果，让运营商们意识到了新的商机。</p>
  <p>毕竟随着手机完成普及，一人一张卡的情况下运营商的业务早已经没有了增长空间。</p>
  <p>唯一的办法就是向友商要增长，于是纷纷针对新用户推出特惠套餐，一时间“老用户不如狗”的呼声四起，携号转网也一度登上热搜。</p>
  <p>不过彼长此消的零和游戏显然不是长久之计，所以便宜大碗的大流量卡也开始逐步推出，常见的套餐内流量从80G到188G不等，但月租价格仅在19-29元之间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_64405a98a6a04773815d9ecb58fc6c99@5457197_oswg123026oswg1024oswg954_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>但为了防止用户放弃原来的高价套餐，全面奔向大流量卡，运营商们也是绞尽了脑汁。</p>
  <p>首先，这些大流量卡只能通过线上办理，如果去线下的营业厅和网点询问，得到的答案是通通不存在。</p>
  <p>其次，大流量卡的销售只通过第三方进行，比如电商平台和代理商，不会在官方的APP里找到。</p>
  <p>再次，大流量的优惠大部分都很短，通常优惠价格只有1-2年，让用户无法长期使用，只能作为备用卡。</p>
  <p>通过这样的设计，确保了流量卡的定期更换，即带来用户的增长，还最大程度避免冲击基本盘。</p>
  <p>所以和传统套餐里运营商一家通吃不同，围绕着大流量卡形成了代理商+电商平台+快递公司的业务生态，每个链条都能分到一杯羹，但也因为这样的设计，让一些灰色的产物应运而生。</p>
  <h2><strong>02 低价流量卡背后的套路</strong></h2>
  <p>如果你去抖音和淘宝上搜索流量卡，得到的结果可能会刷新你的认知——在这里，免费使用一整年的大流量卡、9元月租200多G的流量卡，激活就送20块钱的大流量卡……比比皆是，主播们在直播间信誓旦旦唾沫横飞。</p>
  <p>但如果此刻已经心潮澎湃的你能够打开一下这些店铺的评论，就会发现真相没那么简单。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_2d8dc3763d0542398790398da8ef4aac@5457197_oswg305653oswg828oswg1075_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_9eb209aff5104026a4e51c35ea02fcc2@5457197_oswg191359oswg828oswg737_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>按照一些了解内幕的人士透露，目前电商平台上很多所谓的大流量卡都有很多套路：</p>
  <p>第一种是货不对板。比如商家用一种很便宜的流量卡吸引用户下单，但隔天就会告之“审核失败”推销其他的卡，这种情况下，商家店铺的销量起来了，但消费者白白浪费了时间。</p>
  <p>第二种是骗取消费者的个人信息。用户下单的同时需要填写个人姓名和身份证，而商家并没有发货对应的商品（实际上也没有），而是用这些信息给消费者申请了其他的产品。这些产品费用更贵，而且都有合约期，一旦被激活，想退就有高昂违约金。</p>
  <p>第三种是返费陷阱。很多产品商家承诺每个月会补贴10元或者20元花费，但实际上这些补贴需要用户每个月主动去问店铺，如果这个月消费者忘了就补不了了。甚至有些店铺补了几个月就不补了，后续消费者退也退不了，只能自认倒霉。</p>
  <p>第三种是虚假宣传陷阱。澎湃新闻曾报道，有消费者在淘宝、拼多多等电商平台购买的所谓流量上网手机卡，实为“物联卡”。按卖家提供的教程激活并预充购买套餐后，遭遇商家跑路，充值费用打水漂的情况。</p>
  <p>江苏公安厅也曾经发布一个案例，消费者陈某在某音上购买了“月付19元得185G流量”的流量卡，该流量卡被激活后发现所谓的“月付19元”是个幌子，套餐包含流量和费用都不对，结果致电10086询问是否可以销户，被告知该流量卡归属地是浙江宁波，需本人携带身份证去当地营业厅办理，而且该流量卡有12个月协议期，协议期内取消需承担违约金。陈某想找商家维权，却发现该某音店铺已经关闭。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_656840d173cc40849258c565f2b04eb7@5457197_oswg429466oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>03 “灰色地带”的流量卡代理产业链</strong></h2>
  <p>由于运营商借助代理模式大力发展流量卡业务，因此流量卡代理产业也得到了迅速的发展，比如有平台宣称注册的代理商已经超过了一百万人。</p>
  <p>但是由于缺乏公开监管，这个行业也出现了很多多的乱象。</p>
  <p>在网上搜索，可以发现目前有多个不同名称的流量卡代理平台,这些代理平台以非常诱人的条件来吸引普通人加盟。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c2cc2c0ca97a42abb3252b2afd048ee5@5457197_oswg44677oswg1056oswg261_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>然而，诱人收益的背后，或许藏着难以防备的骗局。</p>
  <p><strong>首先，虽然代理平台名目繁多，但是真假难辨。</strong></p>
  <p>在网络上搜索同一个平台的名字，结果会出现很多的网站，这些网站网址各不相同，网站也非常粗糙，联系人往往是个人手机号，不知道谁是“李逵”谁是“李鬼”。这种信息的模糊，为各种不法行为提供了空间。</p>
  <p><strong>其次，流量卡代理野蛮增长，但也骗局丛生。</strong></p>
  <p>“通信行业可以说现在是一个“群雄争霸”的状态，各路“妖魔鬼怪”齐聚通信平台分一杯羹！”有行业人士表示，目前</p>
  <p>行业存在很多的骗局，常见的比如高佣政策骗局、偷单骗局、虚假宣传骗局、跑路骗局等。</p>
  <p>以高佣骗局为例，有些团队或者个人随便买个分销系统，随意调佣金价格，以高佣为诱惑吸引小白入行，等到结算佣金的时候，就会10单结7单的形式结算，如果单量大偶遇没有后台的数据，而且很难被发现，最终这些团队吃掉中间的利润。</p>
  <p>而偷单骗局则是将下级代理的单子偷偷算成自己的，“客户下单成功，就会操作后台更改，让下级代理以为申请失败，然后在偷给客户发卡，佣金当然算成自己的”。</p>
  <p>跑路骗局则更加恶劣，“有些不良商家忽悠刚入行的代理拉客户，把佣金调的很高。等到结算的时候直接系统关闭，佣金全部归自己。”</p>
  <p><strong>第三，在模式上流量卡代理模式存在着“传销”的风险。</strong></p>
  <p>据观察，由于佣金和层级挂钩，而且上级还能从下级的佣金中获得提成，许多号卡代理体系中存在着超过三层以上的组织体系。</p>
  <p>比如某平台的代理商分为金钻代理、黑钻代理、一级代理、二级代理、普通代理等五个层级，已经远远超过了两个曾经的合法边界。</p>
  <p>根据2013年两高一部《关于办理组织领导传销活动刑事案件适用法律若干问题的意见》“关于传销组织层级及人数的认定问题”中表示，组织内部参与传销活动人员在三十人以上且层级在三级以上的，应当对组织者、领导者追究刑事责任。”</p>
  <p>而这些问题的背后，流量卡始终是一个“灰色”的地带。</p>
  <p>出于利益的考虑，无论是运营商还是代理平台都不愿意公开宣传这项业务，有从业者表示，“有些代理拿着招牌去营业厅附近推广手机卡，影响了营业厅的正常业绩，从而导致平台被运营商处罚。”</p>
  <p>而从更大的视角来看，流量卡灰色业务也是现阶段用户需求与产业发展不匹配的畸形产物，但产业会向前发展，或许有一天消费者再也不会为获得一张流量卡而烦恼。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/V7Q09t6_tBCrkuPm8g3Rew" rel="noopener noreferrer nofollow" target="_blank">“新商业派”</a>，作者：我是小旋风，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033239567527940</id>
            <title>Robotaxi爆发前夜，国内自动驾驶急着IPO</title>
            <link>https://www.36kr.com/p/3033239567527940</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033239567527940</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 11:53:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Robotaxi, 自动驾驶, 上市, 商业化  
<br><br>  
总结: 2024年被视为Robotaxi元年，自动驾驶行业迎来上市潮，企业如地平线和文远知行相继上市，吸引了外界关注。Robotaxi作为L4级自动驾驶的主要应用领域，面临着高投入和长回报周期的挑战，许多企业仍在亏损中挣扎。尽管融资环境趋于理性，IPO被视为解决资金压力的关键，但成功上市后仍需面对市场波动。各家企业在Robotaxi业务上进展不一，小马智行在技术和市场上相对领先。未来，提升规模化水平和服务质量将是自动驾驶企业的核心竞争力。 </div>
                        <hr>
                    
                    <p>多年后回望今朝，可能会把2024年作为Robotaxi元年。</p>
  <p>最近，自动驾驶公司地平线和文远知行先后上市，再度引起了外界对自动驾驶行业的关注。</p>
  <p>前有激光雷达企业速腾聚创和自动驾驶芯片公司黑芝麻作为先行者，之后还有小马智行、Momenta、纵目科技、佑驾创新等企业正在冲刺上市。</p>
  <p>今年以来，自动驾驶领域热度非凡。上半年，百度旗下的萝卜快跑在网络上出圈，让Robotaxi成功进入普通人的视野。10月份，特斯拉发布无人家车Robotaxi，在全球范围内掀起了热烈讨论。</p>
  <p>Robotaxi是L4级自动驾驶前景最广阔的应用领域。多年发展以来，自动驾驶企业们，也终于迎来了商业化落地的新阶段。</p>
  <p>不过，前期投入大、回报周期长、技术难度高等客观困难，各家企业仍困于亏损的泥潭。</p>
  <p>集中冲刺IPO的背后，既是对资金的渴求，也是进一步加速商业化的必然要求。“流血上市”不是终点，而是新阶段的起点。</p>
  <h2><strong>时不我待</strong></h2>
  <p>今年以来，Robotaxi引起了前所未有的热度，或许是自动驾驶企业最好的上市时间点。</p>
  <p>L4级别自动驾驶虽有无人驾驶货车、负责派送的无人小车、无人驾驶公交车等诸多场景，但考虑市场需求与前景，Robotaxi是L4级别自动驾驶商业化落地的最好选择。当下的观点认为，2026年将是Robotaxi规模化量产的元年。</p>
  <p>彼岸的曙光在呼唤，专注于L4技术的自动驾驶企业们，已然闷头狂奔了七八年，如今进入冲刺阶段，谁都想取得头筹，上市则意味着率先获得更多资金与关注。</p>
  <p>2013年禾赛科技、知行汽车科技上市之后，今年又有数家自动驾驶企业陆续开启上市进程。这期间，速腾聚创、如琪出行、黑芝麻智能、地平线、文远知行等企业已然成功IPO，其后还有诸如小马智行、纵目科技、蘑菇车联等知名企业等待时机。</p>
  <p><strong>火热上市潮的背后，透着一种时不我待的紧迫感——自动驾驶行业发展七八年，再不上市就晚了。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_48521b064b234c4a8b078d0bad08b93a@000000_oswg91380oswg1080oswg857_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>自动驾驶经历了先热后冷的融资历程，如今一级市场融资遇冷，热钱涌入减少，国内独角兽们已然到了商业化落地、寻求资本化的关键节点。</p>
  <p>天眼查APP显示，从融资数额和频次来看，自动驾驶商业化回报短期内难以实现，融资变得越来越困难，资本对自动驾驶的态度更加理性，落地前景不明朗的项目很难吸引资本了。多数自动驾驶企业上一波的密集融资，还停留在2021年至2022年。</p>
  <p>2015年-2022年，纵目科技完成了10轮融资，最近一次融资停留在了2022年3月；已成功上市的黑芝麻智能，在2016年-2022年完成9轮融资，最近一次是在2022年12月；文远知行和小马智行，都在今年完成了新融资，但恐怕也是沾了即将上市的光。</p>
  <p>IPO正是解决上述问题的钥匙——只要能成功上市，投资方成功获益退出，创业公司也解除了高额回购股份的压力，同时获得新的发展资金。</p>
  <p>不过，即使成功IPO，也要做好破发的心理准备，看一看这两年登陆资本市场的前辈们表现就知道了。</p>
  <p>今年8月，黑芝麻智能以未盈利“特专科技”公司身份登陆港股，开盘后一度暴跌32.9%。截至11月12日，黑芝麻智能的市值为145亿港元，低于之前170亿港元的估值；禾赛科技在上市后股价一路下滑，如今为4.5美元/股，低于发行价。</p>
  <p>显然，IPO是上一个发展阶段的结束，也是新征程的开始，走出一条什么样的曲线，归根到底需要凭商业化实力说话。</p>
  <h2><strong>同一赛道，亦有差异</strong></h2>
  <p>投入很大，收益很小，负重前行是当前自动驾驶企业的共同写照。</p>
  <p>2021年至2024年上半年，文远知行的收入分别为1.38亿、5.28亿、4.02亿和1.50亿元人民币，相应的净亏损分别为10.07亿、12.98亿、19.82亿和8.82亿元人民币，三年半累计亏损超过50亿元。</p>
  <p>可以看出，其营收在2022年达到顶点后一路下滑，今年上半年的降低幅度尤其明显；净亏损一直扩大，今年上半年也没能收窄。</p>
  <p>小马智行同样承受着盈利压力，招股书显示，其近两年半调整前净亏损分别为1.48亿美元、1.25亿美元和5178万美元，累计亏损达到3.25亿美元，约合23.07亿元人民币。</p>
  <p>还有备受关注的智驾芯片科技公司地平线，2021年以来的三年半时间里，累计亏损超过220亿元人民币。</p>
  <p><strong>从自动驾驶技术到芯片，再到RoboTaxi落地运营，亏损前行是整个产业链的主旋律，原因在于自动驾驶行业前期投入大，回报周期长。</strong></p>
  <p>例如文远知行，2021年至2023年，累计研发支出为22.6亿元，是营收的两倍还多。其在招股书中预计，随着公司自动驾驶技术的测试、试验和商业化，研发支出后续预计还会增加。也就是说，如果收入不发生大幅增长，亏损还会持续扩大。</p>
  <p><strong>而在普遍的负重前行背后，各家处境亦有不同之处。</strong></p>
  <p>文远知行主要依赖两类业务：其一重销售，主要涉及L4级别自动驾驶汽车，包括机器人巴士、机器人出租车及各类机器人车辆、传感器套件的销售；其二重服务，提供L4自动驾驶及高级驾驶辅助系统服务，包括运营、技术支持及ADAS研发等全方位服务。</p>
  <p>小马智行的主营业务包括自动驾驶出行服务、自动驾驶卡车和技术授权与应用服务三大板块。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_82bf42fc8bcc4112a67a45f96dd2283a@000000_oswg317560oswg540oswg360_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>两家企业业务都覆盖了Robotaxi，但也都无法将其作为营收主力，主要受到落地场景复杂，技术有待提升等客观条件的限制。</p>
  <p>在2022年和2023年，小马智行技术授权与应用服务分别占到总营收的54.2%和54.5%，其次是自动驾驶卡车业务，占比也都超过32%。到了今年上半年，营收大头已然变为自动驾驶卡车（Robotruck）业务，营收占比高达73%。</p>
  <p>而Robotaxi业务，在2022年占比最高，达到13.1%，今年上半年已经降到了4.7%。文远知行的Robotaxi收入被收录在服务类别，没有详细披露。</p>
  <p><strong>自动驾驶企业的目标是Robotaxi，开放场景，想象空间大，现实却是Robotruck，封闭场景，增长空间有限，L4级自动驾驶的故事，在短期内变得不那么性感了。</strong></p>
  <p>业务的差异，也让“谁才配得上Robotaxi第一股”，至今仍有争论，目前来看，小马智行比文远知行更聚焦于Robotaxi，当前进度也更快。</p>
  <p>小马智行Robotaxi车辆已超过250辆，累积超3350万公里自动驾驶路测里程，其中包括390万公里无人驾驶路测里程，每辆车的日均订单量已超过15单。作为对比，火热全网的萝卜快跑每辆车日均峰值在20单出头。</p>
  <p>而文远知行在Robotaxi业务上的进展并无突出亮点，披露的信息不多，并且由于自动驾驶出租车、无人驾驶小巴的销量不尽如人意，其运营重心由产品销售转向服务，也就是。这也是被外界质疑“Robotaxi第一股”含金量的关键所在。</p>
  <p>无论如何，小马智行、文远知行、萝卜快跑等企业都在朝着Robotaxi的长远目标砥砺前行，谁能率先取得质的突破，还要经过技术、产品、运营等多方面的考验。</p>
  <h2><strong>规模化关键</strong></h2>
  <p>谁都知晓Robotaxi前景广阔，但如何跨越彼岸，是一道难题。</p>
  <p>弗若斯特沙利文预测，中国有望成为最大的Robotaxi市场，其市场规模预计在2025年和2030年达到2亿美元和390亿美元，占2030年全球自动驾驶出行服务市场的约58.5%。</p>
  <p>但在小马智行CTO楼天城看来，当下离设想中L4普及的状态还很远：“今天的高阶智能驾驶，即便采用了端到端技术，上限也只能做到L2.99，难以抵达L4。”</p>
  <p>对于自动驾驶企业来说，既要仰望天空，也要脚踏实地，翻译过来就是，赚大钱是以后的事，当下最重要的是活下去。因此，各家纷纷在L2领域开展合作“赚钱养家”。</p>
  <p>2023年1月，小马智行正式宣布乘用车智能驾驶业务产品线，之后与极石汽车达成合作，通过与主机厂共同开发智驾方案的形式，实现量产车智能驾驶；发家于智能芯片业务的黑芝麻智能从2022年开始给乘用车提供智驾方案；正在冲刺上市的Momenta在今年2024年6月宣布与广汽丰田达成合作，布局智驾方案业务。</p>
  <p>不过，自动驾驶企业和整车厂之间，是亦敌亦友的关系，有合作也有竞争。</p>
  <p>不论是造车新势力如蔚小理，还是头部传统车企，都拥有自己的智驾团队，甚至还涉足自研芯片。毕竟，没有哪家厂商愿意把“灵魂”交到别人手里。</p>
  <p>而且从技术上看，自动驾驶企业并没有明显领先。</p>
  <p>10月份，华为智能汽车解决方案BU董事长余承东表示：华为ADS 4.0计划于明年推出，届时将带来高速L3级自动驾驶的商用体验及城区L3级自动驾驶的试点项目。</p>
  <p>前景更广阔的Robotaxi，也是合作与竞争相互交织。</p>
  <p>广汽旗下的如祺出行和小马智行及文远知行都有合作；上汽旗下的享道Robotaxi，则基于魔门塔的自动驾驶技术；新能源汽车巨头比亚迪也与东潮科技出行公司达成了合作，将在深圳部署Robotaxi。</p>
  <p>自动驾驶公司和网约车平台从车企采购车辆，车企可以结合两者的运营能力和自动驾驶技术，共同打造Robotaxi，形成了一套互惠互利的合作模式。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_783e118f93c441d988dfb857bb0827bc@000000_oswg98407oswg1080oswg895_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>对于自动驾驶企业来说，要想在各种竞争中崭露头角，当下最重要的是提升规模化水平。</strong></p>
  <p>一方面，提升运营车辆的数量，尽快实现规模经济，有望早日实现盈亏平衡。车辆的采购成本、维修成本、运营管理成本等会随着规模的扩大而降低，这对于业务的可持续发展至关重要。</p>
  <p>另一方面，规模化也有利于提升服务质量。Robotaxi有赖于大量数据训练，更多的车辆和更长的运营总时长，意味着更多的数据来源，有利于提高自动驾驶的智能化水平，并且优化调度算法，进一步提高运营效率。</p>
  <p>业内已经出现了佼佼者。今年第二季度，萝卜快跑提供了约89.9万次出行服务，同比增长了26%。百度自动驾驶业务部总经理陈卓称表示，到今年底，萝卜快跑有望在武汉实现收支平衡，并于明年全面进入盈利期。</p>
  <p>时不我待，IPO能够缓解自动驾驶企业的资金压力，但真正的竞争或许才刚开始。而在竞争与合作中，各方企业共同推动Robotaxi的规模化普及，让自动驾驶真正改变人们的出行方式，则是更加深远的意义。</p>
  <h2><strong>结语</strong></h2>
  <p>筚路蓝缕七八年，自动驾驶产业上下游摸着石头过河，终于集中站在了IPO的舞台上。</p>
  <p>伴随着AI技术的迅猛迭代，自动驾驶相关产业也日臻成熟，包括政府机构、芯片制造商、汽车制造商和科技公司在内的参与者，共同推动着自动驾驶技术的规模化应用。</p>
  <p>如今，自动驾驶已经成为全球性的产业竞赛，Robotaxi作为前景广阔的商业落地场景，国内自动驾驶企业们志在必得。</p>
  <p>将成熟的商业化变现模式与长期主义相结合，逐一解决技术的成熟度、政策的健全度和商业模式的清晰度，自动驾驶产业的真正拐点就在不远的未来。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzUxNDcwNjIwNQ==&amp;mid=2247550454&amp;idx=1&amp;sn=e8897f7c5716744fe66ed297d0cbbc5a&amp;chksm=f86e79664548bbd17614c74290556678f4b9a143ae2ee600c826a08c1ccc41d8c9a78069aae6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“一点财经”（ID：yidiancaijing）</a>，作者：一点.大科技组，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033261860565001</id>
            <title>iPhone 16，引起一场手机壳的割据混战</title>
            <link>https://www.36kr.com/p/3033261860565001</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033261860565001</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 11:43:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <iPhone 16, 相机控制按键, 手机壳, 市场需求>
<br>
<br>
总结: 本文讨论了iPhone 16的相机控制按键及其对手机壳设计的影响。相机控制按键由蓝宝石玻璃和压力感应器组成，给手机壳制造了挑战。市场上出现了多种手机壳设计，但由于按键的特殊性，许多第三方壳子未能有效满足用户需求。用户对按键的使用体验产生分歧，有人选择不带按键的手机壳，而另一些人则坚持保留按键。最终，按键贴膜成为了新的解决方案，满足了用户对保护和操作的双重需求。 </div>
                        <hr>
                    
                    <p><strong>保护我？ 没那么简单&nbsp;</strong></p>
  <p>转眼，iPhone 16 已经推出了两个月。&nbsp;</p>
  <p>本来以为在这一代 iPhone 上，Apple Intelligence 会是最大看点，但落地遥遥无期的 AI 和各种「剑走偏锋」的偷渡方法，早已消磨了大家的热情。&nbsp;</p>
  <p>此时我才发现，原来 iPhone 16 上真正的主角，还是那颗相机控制按键。&nbsp;</p>
  <p>别误会，我的意思并非是它多好用，而是为了保护这个小东西，着实闹出了不小的动静。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_21ea9a366f7c49ba9232f8b2e4208328@000000_oswg50654oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>一颗按键，复杂集成&nbsp;</strong></h2>
  <p>就像家里的电视遥控器，再不济也要套一个袋子一样，不少人拿到新手机的第一件事，大概都是准备一套手机壳与贴膜。&nbsp;</p>
  <p>但在 iPhone 16 上，这颗按键给手机壳制造了不小的麻烦。&nbsp;</p>
  <p>先回顾一下相机控制按键是个什么东西：这颗按键由一块蓝宝石玻璃、一个压力感应器与一个机械结构组成，支持手指的滑动、按压与点击操作。&nbsp;</p>
  <p>我们可以将这颗按键的交互方案分成两套结构： <strong>一套是通过机械结构实现点按激发，另一套则是通过用于屏幕上的电容感应与压力传感器来实现触摸与按压激发。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5c0b5997d41242feaa29d18849526eb8@000000_oswg347805oswg1080oswg559_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>机械结构好解决，从电源键到音量键都是通过这种最基础的方式来交互，无论是开孔设计、硅胶覆盖，甚至是金属与硅胶结合以营造金属触感，市场上早已有成熟的方案来应对了。&nbsp;</p>
  <p><strong>但电容与压感明显是个新东西。</strong></p>
  <p>电容触摸的工作原理是通过人体导电性来检测触摸位置，它在表面覆盖了一层透明的导电材料（通常是氧化铟锡），形成一个稳定的电场。&nbsp;</p>
  <p>当你用手指触碰到材料表面时，人体会吸收一部分电流，这一触摸点的电容值就发生了变化。屏幕内部的传感器能够快速感知这种正在发生的电容变化，并将其传送至处理芯片，计算出触摸的精确坐标位置。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_f27a70e5f39c48c790c4ddd5002d3922@000000_oswg131345oswg820oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>也就是说，想要隔着手机壳用好这颗按键，满足传统的机械结构还不够，还必须有可以传导手指生物电讯号的介质。&nbsp;</p>
  <p>有需求，就有市场，不过这一次， <strong>商家想挣这份钱，可谓是忙坏了。</strong></p>
  <h2><strong>需求无限多，方案不完美&nbsp;</strong></h2>
  <p>在 iPhone 16 才推出时，大家想要带相机控制按键的手机壳，因为官方的手机壳也配备了相机控制按键，跟着原厂的做法肯定没错。&nbsp;</p>
  <p>那我们看看原厂是怎么做的：与 iPhone 16 上的相机控制按键一样，官方 MagSafe 硅胶保护壳上有一片蓝宝石玻璃，并配备有传导层，能够将手指的动作传递给手机的相机控制按钮。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_25acd40a93574c74bb604441bb7841e8@000000_oswg39921oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>之所以选用蓝宝石玻璃，是因为它能达到约为 2000HV 的硬度——这是矿物玻璃的两倍，不锈钢的十倍，只有少数材料能够划伤这个硬度的蓝宝石玻璃，比如 4500 至 10000HV 的真钻石。&nbsp;</p>
  <p>目前官方网站出售的 Beats 保护壳也采用了同样的方案。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_187670e559274595919916a2ba67ef38@000000_oswg25660oswg1024oswg523_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>与硬度相对应，蓝宝石玻璃的成本也相当高，虽然苹果从未透露过相机控制按键的蓝宝石玻璃成本，但是我们可以通过另一个使用蓝宝石玻璃的设备揣测——Apple watch。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_9e68eb9a4a594628b43219f5532ba7f1@000000_oswg44251oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">YouTube 博主 @Unbox Therapy 测试 Apple Watch 的蓝宝石屏幕硬度&nbsp;</p>
  <p>知名的市场调研和数据分析公司 IHS Markit 通过对 Apple Watch 拆解分析，得出了一份提及蓝宝石玻璃屏幕成本的报告：&nbsp;</p>
  <p><strong>Apple Watch 上使用的蓝宝石玻璃屏幕的总成本约为 27.41 美元，其中 7.86 美元为材料成本，其他部分包括研发、劳工和制造费用。</strong></p>
  <p>综合考虑材料成本和加工工艺，iPhone 16 系列的相机控制按键蓝宝石成本合理估计在 8 至 15 美元范围内。&nbsp;</p>
  <p>这种成本对于第三方制造商来说毫无疑问非常高，随之而来的就是风险，用户也更喜欢物廉价美的东西，想要继续维持低价多销，就需要想别的办法——用其他材料覆盖这颗按键。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a630fefdb5ac4644b767fb0f1cfa6127@000000_oswg43152oswg1024oswg682_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这种办法的效果不算好，大多数材料的导电性能有限，隔着一层材料操作这颗按键一点也不丝滑，大家想要的是既能保护按键，又不影响操作的手机壳。&nbsp;</p>
  <p>于是整个十月，市场的需求开始 <strong>出现分歧。</strong></p>
  <p>一部分人在发现带相机按键的手机壳并没有那么好用以后， <strong>干脆不要这颗按键了</strong>——反正也不好用，AI 又没落地，我要它干嘛？不如包起来。&nbsp;</p>
  <p>于是有的商家推出了类似于 iPhone 15 系列的手机壳，直接忽略掉这颗相机控制按键。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c93df9903c054323b8a8de55bcec188b@000000_oswg42079oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>而另一部分人则不愿意放弃，原因也很简单—— <strong>我为这颗按键花了钱，不管用不用得上它都要在那儿。</strong></p>
  <p>执着有时候会带来新发现。&nbsp;</p>
  <p>厂家继续生产额外做了相机控制按键的手机壳（后称电容手机壳），这些壳子绝大多数都遵循苹果官方手机壳设计——用玻璃材质作为表面材料，保证手指操作的顺滑度，再设计一个导电层，将电信号变化传导到手机上的相机控制按键，达成精准操作。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_dd2b1aa2348b4cb88490f0dfe7da6406@000000_oswg36391oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>但是结果也不乐观，由于控制成本，第三方的电容手机壳也出现各种翻车，比如玻璃材料脱落、按键整体脱落。&nbsp;</p>
  <p>不过这些还算小问题，一个避雷贴的出现，彻底把这类壳子打入冷宫：如果手机壳内部有灰，时间一长，iPhone 机身上的按键就会被弄出印子。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a3d0d270636e438496279d88773e1c5d@000000_oswg66531oswg1080oswg463_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>安了手机壳还留印？这简直不可接受，市场的呼声又又又变了：&nbsp;</p>
  <h2><strong>不要带按键的手机壳！</strong></h2>
  <p>这下商家是真的麻了，赶忙又将发布前提前设计的开孔壳库存拿出来卖。&nbsp;</p>
  <p>此时，又一个新鲜的东西进入了大家的视线：按键贴膜。&nbsp;</p>
  <p>没错，继屏幕贴膜、镜头贴膜之后，按键贴膜也出现了。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_18a259e305db4e0cbdb5fa445d2396c9@000000_oswg27548oswg800oswg533_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>人民群众的智慧是无穷的，经过反复折腾以后，大家实在是对于这颗矜贵的按键失去耐心了，索性就用最实用的方法吧——开孔手机+按键贴膜。&nbsp;</p>
  <p>甚至，广大用户还为其总结了非常全面的经验：为了防止这颗按键出现任何意外，不管用开孔壳还是全包壳，最好都贴上按键贴膜。&nbsp;</p>
  <p>手机壳厂家打得不可开交，按键贴膜商家却成为了最大的赢家。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&amp;mid=2652379886&amp;idx=1&amp;sn=b8d9a658a7bc3e44cdcafc5fa3dfcb2d&amp;chksm=9ad8682bc5b5f656db133c85e9fd8f13fdfcfaf314eda84ef088db0cab4e59d819cd497352de&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“爱范儿”（ID：ifanr）</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033056645967875</id>
            <title>开源版SearchGPT来了，两张3090就可复现，超越Perplexity付费版</title>
            <link>https://www.36kr.com/p/3033056645967875</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033056645967875</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 11:30:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Vision Search Assistant, 视觉语言模型, 多模态研究, 开放集问答  
<br>
<br>
总结: OpenAI推出的Vision Search Assistant（VSA）基于视觉语言模型（VLM），能够实时更新知识并处理未见过的图像和新概念。VSA通过“搜索链”算法，结合视觉描述和Web知识，提升了对图像和文本的理解能力。实验结果显示，VSA在开放集问答中表现优于其他模型，提供更准确、相关和有支持的答案。其潜力不仅限于图像处理，还可扩展到视频、3D模型和声音等领域，推动多模态研究的发展。 </div>
                        <hr>
                    
                    <p>OpenAI推出SearchGPT没几天，开源版本也来了。</p>
  <p>港中文MMLab、上海AI Lab、腾讯团队简易实现了<strong>Vision Search Assistant</strong>，模型设计简单，只要<strong>两张RTX3090</strong>就可复现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_108a05fed05b40f1b7671db36ac121a1@46958_oswg697547oswg1080oswg682_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Vision Search Assistant（VSA）以视觉语言模型（VLM）为基础，巧妙地将Web搜索能力融入其中，让VLM内部的知识得到实时更新，使其更加灵活和智能。</p>
  <p>目前，VSA已经针对通用图像进行了实验，可视化和量化结果良好。但不同类别的图像各具特色，还可以针对不同种类的图像（比如表格、医学等）构建出更为特定的VSA应用。</p>
  <p>更令人振奋的是，VSA的潜力并不仅限于图像处理。还有更广阔的可探索空间，比如视频、3D模型和声音等领域，期待能将多模态研究推向新的高度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_be6a08c3e2a14aa48fda4ba42ac085d6@46958_oswg90033oswg1080oswg213_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>让VLM处理未见过的图像和新概念</strong></h2>
  <p>大型语言模型（LLM）的出现让人类可以利用模型的强大零样本问答能力来获取陌生知识。</p>
  <p>在此基础上，检索增强生成（RAG）等技术进一步提高了LLM在知识密集型、开放域问答任务中的表现。然而，VLM在面对未见过的图像和新概念时，它们往往不能利用好来自互联网的最新多模态知识。</p>
  <p>现有的 Web Agent主要依赖于对用户问题的检索，并总结检索返回的HTML文本内容，因此它们在处理涉及图像或其他视觉内容的任务时存在明显的局限性，即视觉信息被忽视或处理不充分。</p>
  <p>为了解决这一问题，团队提出了Vision Search Assistant。Vision Search Assistant以VLM模型为基础，能够回答有关未见过的图像或新概念的问题，其行为类似人类在互联网上进行搜索并解决问题的过程，包括：</p>
  <ul>
   <li>理解查询</li>
   <li>决定应该关注图像中的哪些对象并推断对象之间的相关性</li>
   <li>逐对象生成查询文本</li>
   <li>根据查询文本和推断出的相关性分析搜索引擎返回的内容</li>
   <li>判断获得的视觉和文本信息是否足以生成答案，或者它应该迭代和改进上述过程</li>
   <li>结合检索结果，回答用户的问题</li>
  </ul>
  <h4><strong>视觉内容描述</strong></h4>
  <p>视觉内容描述模块被用来提取图像中对象级的描述和对象之间的相关性，其流程如下图所示。</p>
  <p>首先利用开放域的检测模型来获取值得关注的图像区域。紧接着对每一个检测到的区域，使用VLM获取对象级的文本描述。</p>
  <p>最后，为了更全面地表达视觉内容，利用VLM进一步关联不同的视觉区域以获得不同对象的更精确描述。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e7eb7f94c0e74c7b8dbc1980be568c68@46958_oswg171211oswg1080oswg201_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>具体地，令用户输入图片为 ，用户的问题为 。可通过一个开放域的检测模型 获取 个感兴趣的区域：</p>
  <p>然后利用预训练的VLM模型 分别描述这 个区域的视觉内容：</p>
  <p>为了让不同区域的信息关联起来，提高描述的精度，可将区域 与其它区域 的描述拼接，让VLM对区域 的描述进行矫正：</p>
  <p>至此，从用户输入获得了与之高度相关的 个视觉区域的精确描述 。</p>
  <h4><strong>Web知识搜索：“搜索链”</strong></h4>
  <p>Web知识搜索的核心是名为“搜索链”的迭代算法，旨在获取相关视觉描述的综合性的Web知识，其流程如下图所示。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_23e20a37ca624c06b518ea0c03521120@46958_oswg138430oswg1080oswg201_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在Vision Search Assistant中利用LLM来生成与答案相关的子问题，这一LLM被称为“Planing Agent”。搜索引擎返回的页面会被同样的LLM分析、选择和总结，被称为“Searching Agent”。通过这种方式，可以获得与视觉内容相关的Web知识。</p>
  <p>具体地，由于搜索是对每个区域的视觉内容描述分别进行的，因此以区域 为例，并省略这个上标，即 。该模块中使用同一个LLM模型 构建决策智能体（Planning Agent）和搜索智能体（Searching Agent）。决策智能体控制整个搜索链的流程，搜索智能体与搜索引擎交互，筛选、总结网页信息。</p>
  <p>以第一轮迭代为例，决策智能体将问题 拆分成 个搜索子问题 并交由搜索智能体处理。搜索智能体会将每一个 交付搜索引擎，得到页面集合 。搜索引擎会阅读页面摘要并选择与问题最相关的页面集合（下标集为 ），具体方法如下：</p>
  <p>对于这些被选中的页面，搜索智能体会详细阅读其内容，并进行总结：</p>
  <p>最终，所有 个子问题的总结输送给决策智能体，决策智能体总结得到第一轮迭代后的Web知识：</p>
  <p>重复进行上述迭代过程 次，或是决策智能体认为当前的Web知识已足矣回应原问题时，搜索链停止，得到最终的Web知识 。</p>
  <h4><strong>协同生成</strong></h4>
  <p>最终基于原始图像 、视觉描述 、Web知识 ，利用VLM回答用户的问题 ，其流程如下图所示。具体而言，最终的回答 为：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_020b325cd53b4bb99f25b87532e44b26@46958_oswg153191oswg1080oswg198_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>实验结果</strong></h2>
  <h4><strong>开放集问答可视化对比</strong></h4>
  <p>下图中比较了新事件（前两行）和新图像（后两行）的开放集问答结果。</p>
  <p>将Vision Search Assistant和Qwen2-VL-72B以及InternVL2-76B进行了比较，不难发现，Vision Search Assistant 擅长生成更新、更准确、更详细的结果。</p>
  <p>例如，在第一个样例中，Vision Search Assistant对2024年Tesla公司的情况进行了总结，而Qwen2-VL局限于2023年的信息，InternVL2明确表示无法提供该公司的实时情况。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a85e7a0bcfa14afc82c32ada394b7139@46958_oswg842095oswg1080oswg727_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h4><strong>开放集问答评估</strong></h4>
  <p>在开放集问答评估中，总共通过10位人类专家进行了比较评估，评估内容涉及7月15日至9月25日期间从新闻中收集的100个图文对，涵盖新颖图像和事件的所有领域。</p>
  <p>人类专家从真实性、相关性和支持性三个关键维度进行了评估。</p>
  <p>如下图所示，与Perplexity.ai Pro和GPT-4-Web相比，Vision Search Assistant在所有三个维度上都表现出色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_cf8f4a82a87347ff845dffa0c871e1f3@46958_oswg128053oswg1080oswg307_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>事实性：</strong>Vision Search Assistant得分为68%，优于Perplexity.ai Pro（14%）和 GPT-4-Web（18%）。这一显著领先表明，Vision Search Assistant 始终提供更准确、更基于事实的答案。</p>
  <p><strong>相关性：</strong>Vision Search Assistant 的相关性得分为80%，在提供高度相关的答案方面表现出显著优势。相比之下，Perplexity.ai Pro和GPT-4-Web分别达到11%和9%，显示出在保持网络搜索时效性方面存在显著差距。</p>
  <p><strong>支持性：</strong>Vision Search Assistant在为其响应提供充分证据和理由方面也优于其他模型，支持性得分为63%。Perplexity.ai Pro和GPT-4-Web分别以19%和24%的得分落后。这些结果凸显了Vision Search Assistant 在开放集任务中的卓越表现，特别是在提供全面、相关且得到良好支持的答案方面，使其成为处理新图像和事件的有效方法。</p>
  <h4><strong>封闭集问答评估</strong></h4>
  <p>在LLaVA W基准进行闭集评估，其中包含60个问题，涉及VLM在野外的对话、细节和推理能力。</p>
  <p>使用GPT-4o(0806)模型进行评估，使用LLaVA-1.6-7B作为基线模型，该模型在两种模式下进行了评估：标准模式和使用简单Google图片搜索组件的“朴素搜索”模式。</p>
  <p>此外还评估了LLaVA-1.6-7B的增强版本，该版本配备搜索链模块。</p>
  <p>如下表所示，Vision Search Assistant在所有类别中均表现出最强的性能。具体而言，它在对话类别中获得了73.3%的得分，与LLaVA模型相比略有提升，提升幅度为+0.4%。在细节类别中，Vision Search Assistant以79.3%的得分脱颖而出，比表现最好的LLaVA变体高出 +2.8%。</p>
  <p>在推理方面，VSA方法比表现最佳的LLaVA模型高出+10.8%。这表明Vision Search Assistant对视觉和文本搜索的高级集成极大地增强了其推理能力。</p>
  <p>Vision Search Assistant的整体性能为84.9%，比基线模型提高+6.4%。这表明Vision Search Assistant在对话和推理任务中都表现出色，使其在野外问答能力方面具有明显优势。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d050549acc8042bc934a23854d85140b@46958_oswg125644oswg1080oswg227_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文：https://arxiv.org/abs/2410.21220主页：https://cnzzx.github.io/VSA/代码：https://github.com/cnzzx/VSA</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/xa0oS-LPnZAQqEyUozf_eg" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：VSA团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033284180537603</id>
            <title>特斯拉股价4天涨40%，马斯克坐稳世界首富宝座</title>
            <link>https://www.36kr.com/p/3033284180537603</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033284180537603</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 11:26:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 特斯拉, 股价, 自动驾驶, 人工智能  
<br><br>  
总结: 特斯拉股价在特朗普赢得美国总统大选后迅速上涨，创下近三年来的新高，涨幅约40%。分析师认为，特朗普的胜利将减轻对自动驾驶的监管，有利于特斯拉未来的发展。特斯拉的第三季度财报显示业绩向好，营收和净利润均有所增长，且公司计划推出低成本车型和自动驾驶出租车。马斯克希望借助特朗普政府的影响力推动自动驾驶的审批程序，未来特斯拉将从汽车制造商转型为AI科技公司，Optimus机器人也将成为其多元化业绩的重要支撑。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_3c5efeea9bf84dc584fc687b8cd87434@46958_oswg62165oswg1024oswg683_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>美东时间11月11日收盘，特斯拉（NASDAQ: TSLA）股价站稳350美元，创下近三年以来的新高。自11月5日特朗普赢得美国总统大选后，特斯拉股价持续上涨，从251.44美元涨到350美元，4天里上涨了大约40%。作为本次美国总统候选人唐纳德·特朗普（Donald Trump）的支持者，特斯拉创始人埃隆·马斯克（Elon Musk）在大选后收到了积极回报。&nbsp;</p>
  <p>此轮上涨并非仅仅是对“特朗普概念股”的追捧，而是看好特斯拉在新美国总统任期内的发展势头。尽管特朗普不是电动车的支持者，但对人工智能等持积极态度。美国证券公司威布证券（Wedbush）分析师丹·艾夫斯（Dan Ives）认为，特朗普的胜利，将成为特斯拉和马斯克未来数年自动驾驶和人工智能故事的转折点。过去几年美国联邦政府对自动驾驶的高压监管，会在新总统任期内显著减轻，上述关键项目将会得到顺利推进。这些利好让马斯克的总资产在11月11日增长了162亿美元（约1171.94亿人民币），总资产达到3202亿美元（约2.32万亿人民币），坐稳全球首富的宝座。</p>
  <h2><strong>01&nbsp;&nbsp; 股价高歌猛进，空头损失惨重</strong></h2>
  <p>尽管市场上不乏对特斯拉上周股价快速上涨的担忧，但是现实交易中投资者正不断买入特斯拉股票。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_3b1b3b618d1544b9a9936a18784eb305@46958_oswg89377oswg876oswg764_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">特斯拉股价</p>
  <p>自美东时间11月5日至今，特斯拉股价上涨约40%，创造了近3200亿美元（约2.31万亿元人民币）的市值，股价更是创造了2022年4月以来的52周收盘价新高。美东时间11月11日，特斯拉成为当日美股市场内成交额最高的股票，当日成交723.2亿美元（约5231.6亿人民币）。 <strong>从涨幅来看，特斯拉股价5日涨幅达44.13%，这是自2020年3月25日后，表现最佳的5日涨幅；而年初至今，特斯拉股价涨幅为40.68%。</strong> 由此特斯拉总市值达1.12万亿美元（约8.1万亿人民币），超越台积电（NASDAQ::TSM）成为美股市值第七大的公司。市值前六名分别为英伟达、苹果、微软、Alphabet（谷歌母公司）、亚马逊和Meta Platforms。就在2024年4月，特斯拉股价一度跌至138.80美元的低点，勉强保住美国市值前十大公司的地位。有媒体一度表示，该公司已经退出了美国最强大、增长最快的公司之列。一场美国总统大选改变了一切，特朗普赢得美国总统大选后，据媒体报道， 自上次选举以来，马斯克几乎每天都会出现在海湖庄园，对特朗普第二任期的人事决策和战略产生直接影响。&nbsp;</p>
  <p>美国券商公司盈透证券（Interactive Brockers）首席策略分析师史蒂夫·索斯尼克（Steve Sosnick）认为，马斯克将赌注压在了特朗普胜利上，因此市场会把特斯拉作为受益者。连日的上涨让做空者备受打击。11月11日，据数据分析公司S3 Partners数据显示，11月5日到11月8日收盘，做空特斯拉的对冲基金账面上账面损失至少达到52亿美元。此外，11月11日特斯拉期权总成交量达401.18万张，其中看涨期权占65.5%。多空对决之际，市场也不乏冷静之声，美国投资研究机构晨星公司分析师赛斯·格德斯坦（Seth Goldstein）表示，特斯拉股价被高估了，尽管选举带来了一定好处。&nbsp;</p>
  <p>美国银行分析师近日也表示，很难判断马斯克与特朗普日益密切的公开关系将如何使特斯拉受益。截至美东时间11月11日，特斯拉股价距离历史高点最高点仍有15%的距离。</p>
  <h2><strong>02 &nbsp; 电动车是现实，AI才是未来业绩</strong></h2>
  <p>特斯拉的股价上涨并非完全得益于美国大选，在其公布2024年第三季度财务报告后，因为业绩处于上升通道，此时特斯拉股价已启动上涨。</p>
  <p>美东时间10月23日发布的财报显示，特斯拉第三季度总营收为251.8亿美元（约1821.4亿人民币），略低于分析师预期的253.7亿美元（约1835.1亿人民币），尽管如此，相比于去年同期增长了8%。季度非GAAP净利润为25亿美元（约180.8亿人民币），同比增长8%；毛利率上升至19.8%。特斯拉报告的每股收益为0.72美元（约5.2人民币），超过了分析师预期的0.58美元（约4.2人民币）。</p>
  <p>公司现金流创下新纪录，特斯拉第三季度的运营现金流为63亿美元（约455.7亿人民币），自由现金流（FCF）为27亿美元（约195.3亿人民币）。公司现金及投资增加至336亿美元（约2430.4亿人民币）。产品表现上，特斯拉第三季度总共生产了46.98万辆汽车，交付了46.29万辆汽车，其中电动皮卡Cybertruck成为美国第三季度最畅销的全电动车辆之一，仅次于Model 3和Model Y。</p>
  <p>每辆车的成本降至历史最低，大约为35100美元（约25.39万人民币）。此外，特斯拉第三季度部署了6.9 GWh的能源存储产品。多项关键指标超过分析师预期，使得特斯拉在财报发布后的第一个交易日中股价上涨了17%。对于未来发展，马斯克也给出了自己的规划—— <strong>低成本车型+自动驾驶普及，预计能在2025年实现20%-30%的销量增长。</strong> 马斯克表态，特斯拉计划在2025年开始生产成本低于3万美元的汽车，同时，强调了公司对自动驾驶技术的重视，并暗示这可能是一款自动驾驶出租车（robotaxi）。目前特斯拉推广自动驾驶出租车的阻力之一来自政府监管。</p>
  <p>拜登政府时期，特斯拉一直面临严格审查，美国国家公路交通安全管理局对特斯拉自动驾驶系统的车祸展开多项调查。同时，长期以来，美国国家公路交通安全管理局只允许汽车制造商在获得豁免的情况下每年部署2500台自动驾驶汽车。</p>
  <p><strong>随着特朗普的上台，马斯克希望利用其在特朗普政府中的影响力，推动建立“自动驾驶汽车的联邦审批程序”。</strong> 此外，马斯克预计特斯拉将在未来一年内获得美国得克萨斯州和加利福尼亚州的监管批准，向公众推出自动驾驶出租车的叫车服务。自动驾驶出租车的部署，预示着特斯拉的商业模式和收入变得多元，真正从汽车制造商向AI科技公司转变。另外，特斯拉另一大王牌——Optimus机器人也成为未来多元业绩支撑。近期特斯拉发布的第二代人形机器人（Optimus Gen 2）的视频，展示了其更接近人类的手部动作、更轻的重量以及改进的平衡和控制能力。它还能处理精细的操作，如操纵鸡蛋而不破裂。</p>
  <p>特斯拉相关高管称，几台Optimus机器人现在已被部署在工厂中，进行日常工作测试和改进。这些机器人已经掌握了在办公环境中长时间导航而不发生事故的能力，但仍需提高工作速度。马斯克此前已多次表达了对Optimus机器人的高度信心。他说，这款机器人预估价格在2万-3万美元之间，无论是陪伴散步的宠物犬、照看活泼的孩子，还是在社交聚会上穿梭递送饮品，将成为辅助日常生活的得力伙伴。中信证券认为，Optimus机器人具有良好的自主性展现，机器人初步具备工厂应用的可能性，2025年将是人形机器人的量产之年。自动驾驶和人工智能的两大机会，将成为未来特斯拉商业版图扩展的重要支柱，一旦监管政策调整，特斯拉会迎来扩张阶段。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_VTq1YH5t5FJUsSYxGSxdQ" rel="noopener noreferrer nofollow" target="_blank">“财经汽车”</a>，作者：陈亮，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033234653573125</id>
            <title>国产手机，买不起了</title>
            <link>https://www.36kr.com/p/3033234653573125</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033234653573125</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 11:23:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <国产手机, 涨价, AI功能, 消费者选择>
<br>
<br>
总结: 近年来，国产手机厂商纷纷涨价，旗舰机型价格突破5000元，消费者对这一变化感到困惑和不满。尽管厂商解释涨价原因主要是由于元器件成本上升和AI功能的研发投入，但消费者更关注的是最终售价。过去以性价比著称的国产手机逐渐失去优势，用户对高价手机的接受度下降。未来，国产手机的定价可能仍会继续上涨，消费者与厂商之间的需求差异显著。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_bc0082ed0b8f4533a557029c523e34e6@000000_oswg57983oswg1080oswg459_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>如果有一天，小米和苹果卖同一个价格，你会选谁？</p>
  <p>从今年上半年开始，国产手机厂商都纷纷面露难色地透露过成本涨价的情况，甚提前为用户打好了新机涨价的预防针。</p>
  <p>到了最近集中发售新机的秋季新品季，小米、vivo、OPPO、荣耀、一加不出意料地不同程度上涨了售价。国产手机旗舰机型集体突破5000元大关，在卷高端、卷AI的这条路上，它们与苹果的距离还远吗？</p>
  <p>有人说，“高通芯片年年涨，从几百到一千，你让厂家怎么办？”也有人说，“手机一年不到就发一次新款，说是花高价搞研发，但对普通用户来说真实的涨价比虚无的AI功能更容易感受到。”</p>
  <p>国产手机十几年磨一剑，终于在AI时代等到了弯道超车的机会。但眼前这波涨价潮，似乎正在让“以前没钱买国产，现在没钱买国产”这句话的含金量继续上升。</p>
  <h2><strong>“以前没钱买国产，现在没钱买国产”</strong></h2>
  <p>小米15pro，5299元起；</p>
  <p>OPPO Find X8 Pro，5299元起；</p>
  <p>vivo X200 Pro，5299元起；</p>
  <p>荣耀 Magic7 Pro，5699元起。</p>
  <p>集中在秋季发布的新一批国产手机品牌旗舰机型，默契地集体涨价，跃上5000元大关，属于国产手机的低价内卷时代或许一去不复返了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_9f33938c9d7043c5a99cafc9f75ece7e@000000_oswg52248oswg772oswg499_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">雷军此前对小米15定价的回应</p>
  <p>然而，这会是国产手机定价的天花板吗？肯定不是，此前各大厂商关于涨价的解释可以见得。</p>
  <p>从小米14系列开始，雷军就向“米粉”透露，这将是最后一次定价在3999元。“今年3nm工艺升级，同时供应链RAM和ROM成本涨幅很大，我们在研发上的投入也非常大，小米15确实需要涨价。”</p>
  <p>vivo产品副总裁黄韬也说，“目前手机元器件涨价很多，包括Soc、屏幕、内存等等，目前新机的定价已经是vivo能做到的极限”。</p>
  <p>消费者不会共情资本给出的理由，相比听起来距离用户更远的手机元器件涨价，手机的最终定价才是更能够被感知到的变化。</p>
  <p>并且对于大多数选购手机只在乎品牌、系统与价格的用户来说，<strong>将成本压力转嫁到消费者头上的品牌，则会得到用脚投票的结果。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_2bfa6697dbf24329a801863f9b1f3710@000000_oswg514352oswg1045oswg881_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">网友对国产手机涨价的态度</p>
  <p>“现在的手机太贵了，叠加一大堆复杂的功能就开始一步步涨价，但实际上绝大多数功能的实用性并不高，很多人甚至到最后换手机的时候都不见得会用。”秦为选手机通常都会直接选择国产品牌的新款旗舰机型，在他看来，过去的国产手机香就香在“便宜又大碗”。</p>
  <p>但从这两年开始，国产手机品牌的性价比正在渐渐减弱，“一家比一家的广告做得精美，请的代言人流量大，各种花里胡哨的功能也变得越来越多，能够真正提升手机体验感的功能不见得有多少，但它们一定会成为涨价的原因。”秦为对锌刻度谈到。</p>
  <p>如果诟病国产手机品牌旗舰机型涨价有些苛刻，那么再来看看平价机型。</p>
  <p>“2016年买的OPPO R9，4+64G，2500元，2019年买的一加7Pro，8+256G，4499元，今年准备买一加13，12+512G，4899元。从我个人的感受来看，每次换手机在内存上的投入都越来越大，但这又是无法取舍的配置，因为内存小的国产手机很快就会卡得不行，2、3000元左右就能拿下的国产手机，性价比已经越来越低了。”正在为妈妈挑选手机的“栗子”感慨道如今想选个有性价比的手机实在太难。</p>
  <p>逛了一圈国产手机线下店之后，“栗子”总结道：“便宜的手机也有，但一看配置，基本上都下不去手，毕竟如果用两年就坏了或者卡了，到时候换手机又是一笔费用。但是稍微配置看得过去的，就是中高端机型，价格也就没什么优势了。”</p>
  <p>“栗子”还表示，其实哪怕是老年人，现在对手机的需求也不再停留在基础功能上。“栗子”的妈妈在老年大学上摄影班，想要换一台稍微摄影功能好一些的手机，国产手机品牌往往只有旗舰机型才主打强大的影像功能，但旗舰机对于“栗子”妈妈这样的老年人来说实际上存在着功能冗余的情况，甚至可以说为了一个功能付了双倍的价钱。“我好像突然懂了为什么国产旗舰机全部都爱卷影像了。”</p>
  <p><strong>国产手机的涨价进程如同“温水煮青蛙”，只有恍然回头才能发现，国产手机早已不是当初的模样了。</strong></p>
  <h2><strong>AI功能真的就这么值钱？</strong></h2>
  <p>谁还记得2011年8月16日，雷军穿着黑色T恤和深蓝色牛仔裤，站在北京798艺术中心的舞台中央，带来了1999元的小米1？</p>
  <p>自那以后，小米一炮而红，抢到一台手机堪称被幸运女神眷顾。如今也能从一些论坛的旧帖中瞥见当时主打低价的小米究竟有多炙手可热。</p>
  <p>“抛开不靠谱的网络因素不提，在中午12点开放购买时能否拥有足够快的手速也是能否成功购买的因素之一。”小米社区里的大神会在小米手机开售前提供抢购手机的注意事项和抢购攻略。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_10a103ed395e4775aeb4d53821e5fdcc@000000_oswg96421oswg855oswg684_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">小米手机曾靠低价杀出重围</p>
  <p>那时候的小米，抢到就是赚到。</p>
  <p>同样是在2011年，余承东正式接手了华为手机业务，开启大刀阔斧的改革，全面放弃给运营商做贴牌手机的ODM业务，转头开创华为自主品牌；</p>
  <p>2011的OPPO正式推出了首款安卓智能手机OPPO X903，正式进军智能手机领域；</p>
  <p>2011年的vivo，艰难完成清库存之转型任务后，终于推出了旗下第一款安卓机 vivo V1。</p>
  <p>这一年的国产手机打通“任督二脉”，和乔布斯的最后一部手机一起站上了同一个赛道。</p>
  <p>13年过去，AI手机元年悄然而至，主流厂商集体跟进“All in AI”的策略，过去的影像竞争退潮，AI成为征服市场的核心战略，也是导致涨价的根本原因。</p>
  <p><strong>国产手机厂商在AI领域的研发投入还会持续增加，目前的定价也还没触及到天花板</strong>。据了解，小米今年的预计研发投入将超过240亿元，并计划在2025年将这一数字提升至300亿元，这些投资将主要用于AI、操作系统（OS）和芯片等底层技术的持续研发与创新。</p>
  <p>OPPO、vivo、荣耀企业近年来在AI方面的投入也普遍超过百亿元。各大厂商抢滩AI手机，为了尽早掌握移动AI时代的入口。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_40fdd57b54634bcfbe2f674510e4acf2@000000_oswg56713oswg861oswg201_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>不过为了在现阶段控制成本，平衡价格与配置，今年秋季的集体上新已经开始呈现出一个趋势，那就是影响硬件较去年基本没有提升，甚至有部分产品还存在倒退情况，而AI端侧模型，即智能体，则开始带来更多落地场景，让用户能在花了真金白银之后感受到钱用在了哪里。</p>
  <p>尽管不少用户依旧感受不到AI手机的魅力何在，看不见手机背后供应链涨价带来的影响，但国产手机涨价的趋势已经难以阻挡，至于未来成本的变化和整体市场的供应情况是否会导致手机定价产生动态波动，仍然是个长期命题。</p>
  <p>只是也有消费者直言，“不管是AI还是拍照像素，卷的方向都是非必要。谁能把价格降下来才是真的契合大部分人的需要。”关于这一点，厂商和消费者之间或许存在着分歧。</p>
  <p>诚然，一切的教育都需要时间，也需要代价，但涨价的国产手机，还会是你的选择吗？</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkyNzMwMTc1OA==&amp;mid=2247516278&amp;idx=1&amp;sn=3414e538abb7de5e4de9e620324b29f8&amp;chksm=c379db7c80a6cbf7130a364e2c7f46f544e3f85da476ed5f941a5198b94cfa1d6b206d8ad663&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“锌刻度”（ID：znkedu）</a>，作者：李觐麟，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033212109467906</id>
            <title>具身智能，究竟还缺什么？</title>
            <link>https://www.36kr.com/p/3033212109467906</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033212109467906</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 10:57:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 具身智能, 人形机器人, 供应链, 空间智能  
<br><br>  
总结: 本文探讨了具身智能的发展现状及其面临的挑战，强调了物理实体与智能之间的结合。具身智能系统能够在真实环境中学习和操作，但尚未广泛应用的原因包括技术突破的缺乏和供应链的复杂性。文章提到波士顿动力、特斯拉等公司在机器人领域的努力，以及中国在这一领域的潜力。空间智能的概念被引入，强调了多维感官与行动能力的重要性。最后，指出市场需求与技术创新之间的相互促进关系，呼吁多方合作以推动具身智能的进步。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_acfacba4596843028cec9e9df07bbddf@000000_oswg51166oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>本期AGI路线图中关键节点：Figure 02、Optimus Gen-2、宇树G1、傅利叶GR-2、众擎SE01、BVS、WonderWorld、ReKep、DrEureka、DeepMind足球机器人、腾讯「小五」、达芬奇AI机器人、Project GR00T、LeRobot。</p>
  <p>具身智能（Embodied AI）指的是拥有物理形态的人工智能系统，这些系统能够在真实的物理环境中进行学习和操作，与周围世界实现动态交互。</p>
  <p>不同于传统基于数字环境的AI，具身智能具备感知、行动，并对外界物理刺激作出反应的能力。</p>
  <p>长期以来，这些系统希望通过集成的传感器和执行器，模仿人类或动物的感知和行为，逐步弥合智能计算与物理行为之间的差距。</p>
  <p>同时，它们的复杂性还取决于其处理感官与行为数据的能力，当下大模型的出现让相关能力呈现规模级增长，正在革新其交互方式。</p>
  <p>然而，为何具身智能尚未像其他智能应用一样广泛融入我们的日常生活？究竟还缺乏哪些关键技术突破？通过回顾近期的技术进展，我们一起来探讨这个问题。</p>
  <h2><strong>物理智能：更强大更便宜的物理实体，让“身体”追上“大脑”的发育</strong></h2>
  <p>进入大模型时代，人工智能的发展超出了许多人的预期。<strong>有人甚至设想，只要将最先进的大模型装入机器人，就能立刻实现具身智能。然而，事实并非如此，物理实体或面临更大的挑战。</strong></p>
  <p>大家熟知的机器人行业明星公司波士顿动力（Boston Dynamics），已经为“具身”工程问题“死磕”了二十余年。该公司成立于1992年，最初因其先进的机器人研究而获得认可，许多项目被视为全球标杆，包括人形机器人Atlas和四足机器人Spot等。然而，在众多引人注目的演示视频背后，实际上，这些机器人在过去很长一段时间内并未达到“可用”的状态。</p>
  <p>不久前波士顿动力公布了一条催人泪下的短片，宣布大家熟悉的液压动力人形机器人Atlas正式退役！在最后一段告别视频中，我们可以看到这位明星机器人的真实状态：不断尝试奔跑、跳跃、后空翻，失手已成为家常便饭，甚至膝盖喷出了液压油，运动时皮带断裂而摔倒。<strong>这些公众平时看不到的画面，正是传统机器人多年来难以实现商业化的重要原因。</strong></p>
  <p>当屏幕前的几十万观众为Atlas的一次次摔倒而跟着喊疼时，波士顿动力随即宣布将推出下一代产品：专为实际应用而设计的全电动Atlas。然而，很遗憾，这一次的产品更新并非引领性创新，因为在波士顿动力死磕液压技术的这两年间，已经出现了不少新的竞争对手。</p>
  <p>特斯拉便是其中的佼佼者。早在2021年8月的特斯拉AI日上，特斯拉首次提出了推进机器人全电动化的概念。经过近两年的努力，今年5月，Tesla官方发布了其二代人形机器人Optimus最新的演示视频，展示其在特斯拉电池工厂学习分装电池。视频中，最值得关注的并不是AI的能力，而是马斯克让我们窥见了人类帮助机器人进行数据收集的真实场景，这也是Optimus最大的优势。一方面，Optimus的手是世界上顶级的五指灵巧型机器人手之一，具备触觉感知，拥有11个自由度（DOF），并称今年晚些时候将达到22个自由度（DOF）。另一方面，视频中展示了人类操作员戴着VR眼镜和手套指挥机器人进行操作，以精确的复刻动作，这背后是一个超低时延的全身控制器与硬件组合，强大的运动控制有助于训练的数据迭代。这样的能力，我们还在特斯拉10月11日举办的“Robotaxi Day”上看到。虽然过程中发生了一段小插曲，网友称其中的Tesla Bot与人类互动太流畅，背后应该是人类操作员而并非由AI独立完成，称其作假。真相无从考究，也许特斯拉确实还未能全面的接入AI，实现机器人的完全自主。但实际上此时的AI只是锦上添花，我们更希望看到“具身”工程的重大突破。&nbsp;&nbsp; &nbsp;</p>
  <p>与此同时，竞争对手们也不甘示弱。8月初OpenAI投资的Figure AI发布了第二代人形机器人Figure 02，进行了全面的硬件和软件升级，增强了AI、视觉处理、电池续航和传感器性能。在最新的视频中5台机器人已经可以进入到宝马车间进行了“实训”，尽管，它们的动作依然较为迟缓。仅仅三天后，波士顿动力的全新电动Atlas机器人也展示了能连续做8个俯卧撑的能力，采用非线性模型预测控制方法来优化动作，取得很大的进步。尽管，新款电动Atlas的手部设计仍未包含手指，在技术和实用性方面受到了挑战。</p>
  <p>Optimus Gen-2、Figure 02以及电动Atlas均是当前人形机器人的顶流，希望通过全面的电动化，能够更精确地将智能控制指令转化为物理行动，这一转化类似于电动车的兴起如何促进自动驾驶技术的发展。然而，要实现真正可用甚至好用的水平，仍需更多时间与技术进步。</p>
  <p>另外，<strong>人形机器人除了本体运动控制，高自由度灵巧手，还有触觉传感器、肌肉骨骼技术、表情模仿控制等等，均在不断发展中，虽不完美，但年内也有不少试点项目陆续取得了进展。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_db5bf884132246ef8ce130c04c17917d@000000_oswg365437oswg1080oswg1040_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">腾研AGI路线图图谱截选： Optimus、Figure 02&nbsp;</p>
  <p><strong>中国产业链或成全村的希望？</strong></p>
  <p><strong>人形机器人行业尚难以实现大规模量产，主要原因之一是供应链成熟度不足，导致制作成本居高不下。</strong>在电动化之前，波士顿动力的传统液压动力Atlas各个部分的零部件均为定制生产，单台制作成本高达200万美元（约合1447万元人民币），且后期维护费用高昂。电动化之后，虽然机器人的制作成本将有所下降，但仍面临复杂的供应链挑战。马斯克擅长通过第一性原理实现成本极限压缩，但其Optimus Gen2硬件的成本依然远未达到预期。根据摩根士丹利近期发布的分析报告《Humanoids: Optimus Prime》，Optimus Gen2目前的成本已达到6万美元甚至更高，而马斯克理想中的Optimus人型机器人的定价目标仅为2万美元。</p>
  <p>自2021年决定生产Optimus以来，马斯克的社交媒体账号上频繁出现一个关键词：supply chain（供应链）。在一次公开视频中，他无奈地表示，“尽管世界上有很多电机供应商，但没有一种电机适用于人形机器人，也没有一种齿轮箱符合我们的尺寸需求。”</p>
  <p>但这并非完全看不到希望，摩根士丹利分析报告中提到了一个积极的预测："随着规模扩大、研发周期缩短和中国零部件价格降低，成本可能会降至马斯克设定的2万美元目标。”<strong>类似于新能源汽车，中国产业链或许能够再开辟出一片天地？目前国内确实有众多出色的人形机器人“卷王”，几乎每月均有重大的更新，</strong>不仅是在技术上，在量产与售价上似乎更有竞争力。&nbsp;&nbsp; &nbsp;</p>
  <p>8月中，宇树推出的人形机器人G1量产版，起售价为9.9万元，展示出高级的动作控制和环境适应能力。G1具备出色的下肢运动能力，包括单腿跳跃和原地360度转身，能够处理复杂地形如高台阶和碎石地面。该机器人采用端到端的深度强化学习和仿真训练，具备高度自由度和强大的视觉及深度感知能力，支持2小时续航并可快速拆卸电源模块。</p>
  <p>9月底，傅利叶智能发布了第二代人形机器人GR-2，决定在已有的供应链条件下优先“落地交付”，已交付超过一百台。傅利叶的新一代FSA执行器已搭载在GR-2的踝关节和髋关节，最大关节扭矩超过380牛·米（N·m），并为机器人的灵巧手内置了6个触觉传感器，提升了机器人的精密操作能力。尽管售价相对较高，傅利叶仍决心通过落地交付来推动研发。</p>
  <p>10月底，深圳一家名叫众擎机器人（EngineAI）的机器人公司，推出了一款直立行走、姿势酷似人类的的机器人SE01，为了克服大部分双足机器人的弯腿、跺脚、小碎步，甚至是原地踏步的病态步伐，SE01采用的是自主研发的高性能谐波力控关节模组，使得膝关节最大扭矩能达到 186N·m，动力关节力控精度可达 0.2N·m。整体售价计划控制在2-3 万美元。</p>
  <p>相较于国外大厂，“活蹦乱跳”的国内机器人商业公司毫不示弱甚至更“卷”，尤其是<strong>在人形机器人形态的多样化发展方向，我们有理由相信摩根士丹利的预测，中国零部件价格降低，或将推动全球人形机器人的供应链的完善，</strong>加快实现更强大、更便宜的人形机器人大规模量产。&nbsp;&nbsp; &nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_b3178c39021a44a5871453cce8e72ab5@000000_oswg432138oswg1080oswg1051_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">腾研AGI路线图图谱截选： 宇树G1、傅利叶GR-2、众擎SE01&nbsp;</p>
  <h2><strong>空间智能：多维感官与行动能力</strong></h2>
  <p><strong>空间智能是什么，为什么重要</strong></p>
  <p>决定具身智能复杂性的感官与行为数据及其相关算法，是软件层面制约机器人的量产与泛化能力的另一个重要因素。多维度数据远没有文本、图像等丰富，难以有效支持大规模的空间训练。</p>
  <p><strong>关于李飞飞提出的空间智能，至今没有给出明确定义，但我们可以从她多年来与之相关的一系列工作中，具象化“空间智能”这一概念，并理解它对具身智能的重要性。</strong></p>
  <p>同样是在TED的讲台上，九年前李飞飞带来了影响深远的“ImageNet数据集”。在那个神经网络算法、图形处理器（GPU）和大数据首次结合的时期，图像数据非常紧缺。她的实验室开发的ImageNet启用了一个包含数百万张高质量照片的数据库，用以训练计算机视觉。除了数据库的标注与收集外，实验室还开发了识别图像中的对象并预测它们之间关系的算法。虽然实验室的工作并未独立商业化，但影响甚广，当时的学生还包括后来的AI大神Andrej Karpathy。&nbsp;&nbsp; &nbsp;</p>
  <p>目前，<strong>AI在3D领域的发展远不如其他领域迅速，一个重要原因就是基础数据的获取难度较大。</strong>优势的3D资产往往存在于建模、影视、游戏、自动驾驶公司的私有数据中，难以共享或交易。</p>
  <p>如今，空间智能要做的，其实可以简单理解为，就是3D版本的ImageNet数据集及相关算法。</p>
  <p>今年年中，李飞飞推动的“空间智能”概念，通过吴佳俊（同为斯坦福教员，目前在李飞飞创业公司World Labs中担任顾问）团队的BVS（BEHAVIOR Vision Suite）得到了新的发展。该套件为计算机视觉模型提供了一套强大的基础工具与资源集，帮助三维数据的合成与评估。</p>
  <p>并在10月进行了重要迭代。1、提出“数字表亲”概念，不再追求与真实物体一比一的复制，降低成本，增强模型的泛化能力。数字表亲通过简单拍照即可创建，用于机器人训练，提供变化且相似的训练场景。通过ACDC（Automatic Creation of Digital Cousins）方法自动创建数字表亲，实现从虚拟到真实的零样本迁移，表现优于数字孪生模型。2、推出WonderWorld系统，实现了交互式3D生成速度的重要突破。系统通过FLAGS（Fast LAyered Gaussian Surfels）方法在10秒内生成3D场景，速度比现有技术快100倍，并解决了多场景衔接的几何裂缝问题，无需训练预设模型，可跨多种场景类型生成连贯的3D世界。</p>
  <p><strong>相关研究正在加速空间模型的数据积累，训练与应用，使大模型的智能涌现正在从文本、图像、视频向3D场景过渡。</strong>当然，光有数据库还不够。正如上述所提及的，类似ImageNet需要“识别图像中的对象并预测它们之间关系”一样，空间智能还需要理解三维物件之间的关系。相对于数字环境的AI，这项能力对于需要与物理世界亲密接触的具身智能来说显得更为重要。</p>
  <p>因此，团队还提出了ReKep框架，提出了关系关键点约束方法（ReKep/Relational Keypoint Constraints），来优化机器人与环境的复杂交互。ReKep能够与GPT-4等多模态大模型整合，实现多阶段任务的分解和优化。通过约束优化问题定义机器人操作任务，增强执行策略的泛化能力。可以简单理解为，该方法将某项复杂任务表现为一连串的关系序列，通过与大型语言模型（LLMs）解决序列问题的强项结合，希望更加有效的提升机器人训练的效率与泛化能力。</p>
  <p>总体来说，与九年前的ImageNet一样，<strong>“神秘”的空间智能的创业内容其实并不难理解，甚至很简单、直接，就是把之前0-1的成功经验与优势，增加一个维度，再做一遍。</strong>而这对于接下来具身智能对世界的理解与交互来说，是非常重要的基础工作。&nbsp;&nbsp; &nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_959bc4376ae94f6d8b6209482d624959@000000_oswg450334oswg1080oswg1046_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">腾研AGI路线图图谱截选： BVS、WonderWorld、ReKep</p>
  <p><strong>从感官到行动，弥合虚拟与现实</strong></p>
  <p>在我们生活中，或许经常会遇到这样的情况：一件事情明明已经想好怎么做，但当真正动手时，却会发现自己笨手笨脚，不能完全将想象中的动作执行出来。</p>
  <p>具体智能的实现也面临着同样的问题，<strong>主要的挑战就是弥合模拟与现实之间的差距。这是一项涉及多方面的复杂系统工程。</strong>可喜的是，我们目前已经看到了一系列积极的变化。</p>
  <p><strong>首先是物理环境的适应。</strong>虚拟环境与现实环境的颗粒度是不同的，现实世界的变量更加复杂多变。传统上，让机器人学会在现实世界中执行任务，需要研究人员通过手动方式设置各类模型环境的参数与奖励函数等，这一过程非常繁琐且难以穷尽。得益于大型语言模型的泛文本与代码能力，这一过程有望得到简化。今年5月初，由宾夕法尼亚大学、英伟达等携手推出的突破性研究项目DrEureka验证了这一路径的可行性。在该研究中，一只四足机器人在瑜伽球上稳稳行走，无论是研究人员故意干扰，还是球体表面气压的变化，都无法让它失去平衡。这样的类似科幻电影的画面非常让人惊讶，这主要得益于DrEureka创新设计，它通过AI自动生成的奖励函数和域随机化技术，利用大算力来穷尽物理环境的参数，以更大程度的模拟现实。&nbsp;&nbsp; &nbsp;</p>
  <p><strong>其次是动作与策略规划。</strong>与单一任务机器人等不同，AI和机器人专家的长远目标，是创造出具有通用智能的机器人代理，使其能够像人类或动物一样自我学习与进步，应用于千变万化的现实环境。而当前基于编程的运动控制算法，显然难以满足这一目标，无论我们已经努力编程了N个任务，当机器人遇到第N+1项任务时，可能就会随时宕机。这时，我们也许会再次想到大型语言模型的泛化能力，但是，由于涉及到复杂的动作训练与策略规划，对推理的要求更高，强化学习将是更好的尝试。类似于围棋领域的AlphaGo Zero，人类只需要提供最基础的围棋规则，人工智能便能通过自我博弈的方式学会千变万化的棋艺，并碾压人类。4月初，AlphaGo Zero的开发者谷歌的DeepMind便打造了一款足球机器人，登上了《Science Robotics》封面。这简单来说就是足球机器人界的AlphaGo Zero，通过最基础的目标设置，机器人就可以学会行走、转身、踢腿等一系列动作，并根据目标（如射门）去连贯执行。该项目的核心是训练能够自我进化的通用机器人，而不是仅仅训练它们执行特定任务。</p>
  <p><strong>最后是控制策略的泛化。</strong>如果说上述两种方法都已经很惊艳，但如果我们的机器人不是DrEureka这样的四足机器人，或者像DeepMind这样的足球机器人，那相关的数据与控制指令是不是都要重新做一遍呢？显然，最好不要。控制策略的泛化对于具身智能的广泛普及具有重要意义。今年10月底，英伟达推出了一个具有150万参数的极小模型HOVER，主要用于人形机器人的多功能全身神经通用控制。HOVER控制器在单一模型内整合多种任务需求，适应各类人形机器人动作（行走、操作等），实现多模式切换，提升了机器人仿人应用的效率和灵活性。它不仅在输出端进行控制，还可以支持不同输入设备，简化数据收集。实际上，各类人形机器人在平时走路、保持平衡、控制手脚等看似简单的动作背后，其实涉及大量的潜意识处理，HOVER相当于把这种潜意识编码到了一个统一的模型里，同时，支持反向编译。&nbsp;&nbsp; &nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_fd1454d9698945b684c4e5e3f9d30bc1@000000_oswg339788oswg1080oswg1054_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">腾研AGI路线图图谱截选：DrEureka、足球机器人</p>
  <h2><strong>应用场景：市场与技术的良性循环</strong></h2>
  <p><strong>技术再强，也要找到用武之地</strong></p>
  <p>市场和技术之间一直都存在着一种相互促进、相互影响的辩证关系。市场需求往往是推动技术创新的关键动力，而技术进步反过来又影响市场结构。甚至在很多行业中，市场比技术显得更为重要。例如，<strong>增程式电动车虽然在多种技术方案中并不算领先，却占据了当前电动车销量的市场；苹果公司虽然大量采用非自研技术，但依然多年来稳居智能终端的领头羊；等等。</strong></p>
  <p>尤其是在各类要素高速流动的今天，工程实现事实上并不存在足够高的护城河，核心技术人员一旦出走，就有可能重新创办一家新公司。把握市场机会，甚至比技术本身更为重要。在机器人领域同样如此，除了观察技术本身，更应该看到机器人落地的的一些关键的价值方向：</p>
  <p><strong>第一类看预期规模。</strong>比如老年陪护机器人。据统计，2030年老龄化比例将达到约17%，2050年将进一步达到约24%。人口老龄化以及老年人的抚养和陪护问题，已成为摆在社会面前的重要议题之一。通过技术发展来惠及社会，关爱人类，是机器人规模化发展的一个刚性需求和核心方向。9月底，腾讯Robotics X实验室发布了新机器人「小五」，这是实验室开发的第五代机器人，具备四腿轮足复合设计、多指灵巧手、大面积触觉皮肤、安全人机物理交互等技术,可以提高机器人在人居环境中的实用性和交互性。其设计理念来自于实验室A2G理念的B（Body，机器人本体）、G（Guardian Angel，守护天使），通过探索不同形态的本体，去让人类的生活更美好。这个市场空间是非常巨大的，足以支持技术的迭代。类似的案例还有5月份，马里兰团队打造的辅助喂食机器人，可用于老年人进食和儿童保育，等等。&nbsp;&nbsp; &nbsp;</p>
  <p><strong>第二类看数据反馈。</strong>比如当下人形机器人的“进厂潮”。5月份，特斯拉Optimus人形机器人开始进入工厂，参与电池分装；7月份，Figure AI与宝马达成合作，将人形通用机器人引入汽车生产线以执行多样化任务；10月份，波士顿动力的Atlas机器人在工厂环境中成功完成全自动任务，展示了搬运汽车发动机零件的能力。当前顶尖机器人进入工厂的现象，几乎成为了行业标配。难道相对于传统的工业机器人，人形机器人真的能更好的适应厂里的工作吗？事实上并非如此。当下人形机器人上能够独立完成的具体工作，其实并不多，且并不足够稳定，成本上也不具备规模落地的优势。机器人纷纷进厂，或许更多为的不是规模化落地，而是通过任务执行，获取更多的数据反馈，并在实际环境中验证软硬件的操作表现。</p>
  <p><strong>第三类看比较优势。</strong>已经具备成熟的物理实体，数据较为完备的优势场景应用或更快得到应用。其中一个最典型的就是手术机器人。8月份，斯坦福团队开发的达芬奇机器人通过模仿学习独立完成外科手术基本任务，如缝合、针头处理和提起组织等；实验中，达芬奇机器人展示了精细操作能力，成功应用相对动作公式克服了系统本体感知的不准确性。通过大规模模仿学习，达芬奇机器人能够在没有进一步运动学矫正的情况下，有效学习并执行复杂手术任务。同样，Perceptive公司开发的AI机器人牙医也于近期首次完成了一例漂亮的人类牙科手术，速度是人类医生的8倍，能够精确处理患者头部移动。在国外或一些乡村社区，医生人数不足，或者没有太多牙医愿意在偏远、落后的社区工作，手术机器人将会是一个不错的主意。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_0237f4b02de1440fb668f58746a8a3bd@000000_oswg343158oswg1080oswg1062_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">腾研AGI路线图图谱截选：腾讯「小五」、达芬奇AI机器人</p>
  <p><strong>不管闭源或开源，推动多方合作</strong></p>
  <p><strong>具身智能涉及众多学科的融合，包括传统机器人领域的机械工程、自动化、嵌入式系统、控制优化等，与计算机领域的机器学习、模式识别，以及认知科学、神经科学等等。</strong>它是各个领域发展到一定成熟后才能涌现出的能力，这也决定了，闭门造车将会导致效率低下。要想加速具身智能的规模发展与量产应用，可能需要从更广的范围内去聚合社会和产业各方的资源。</p>
  <p><strong>核心在于全产业链条的打通，可以通过闭源平台，也可以通过开源社区的方式。</strong></p>
  <p>在闭源平台方面，3月中，英伟达推出了通用机器人模型Project GR00T，提出与人形机器人专家共同打造平台的设想。该平台涵盖了几乎所有著名的人形机器人制造商，包括1X Technologies、Agility Robotics、Apptronik、Boston Dynamics、Figure AI、Fourier Intelligence、Sanctuary AI、Unitree Robotics和XPENG Robotics等。该项目主要包括两个部分：1、提供机器人专用的基础模型，GR00T代表“通用机器人00技术”，旨在使人形机器人能够通过观察人类行为来理解自然语言并模仿动作，从而快速学习协调性、灵活性等技能；2、提供英伟达的Isaac平台，包括Isaac Lab（用于强化学习）和Jetson Thor（高性能计算平台），将英伟达的加速计算能力复用到机器人领域的开发中。目前，该项目并非一个开源项目，更像是通过产业联盟的方式推进相关工作。&nbsp;&nbsp; &nbsp;</p>
  <p>开源社区方面，同期，以构建大型开源社区而闻名的 AI 初创公司Hugging Face，挖来了前特斯拉科学家 Remi Cadene，他是特斯拉 Autopilot 和 Optimus 机器人研究项目的团队成员，有着丰富的实践经验。这次开源的LeRobot机器人工具包，堪称机器人领域的「Transformers」。LeRobot 提供了一个多功能的平台，支持大规模机器人数据集、预训练模型访问，以及物理模拟器集成，同时，还可以支持从简单机械臂到复杂类人机器人的多种硬件。Cadene 表示 LeRobot 项目的发展愿景是“从多样化社区中构建软件和硬件，以在现实世界中开发下一代智能机器人”。聚集于应用场景，加强技术的共享与创新交流，开源项目通常吸引大量开发者参与，这种集体智慧能够有效解决复杂问题。通过共同努力，开发者可以在更短的时间内找到解决方案，从而推动技术的进步与应用。</p>
  <p>闭源与开源的争论是一个复杂的话题。<strong>开源模式强调技术的共享、协作和快速迭代，而闭源模式则侧重于保护商业利益、确保数据安全和技术支持。不管哪种方式，对于具身智能这项复杂工程，都是有益且必要的。</strong>随着技术的发展和市场的变化，开源与闭源之间的界限也在逐渐变得模糊，未来可能会出现更多结合两者优点的混合模式，共同解决具身智能这一多学科难题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_78ade2f92c1a4ede9b83c48430675262@000000_oswg490106oswg1080oswg1056_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">腾研AGI路线图图谱截选：Project GR00T、LeRobot</p>
  <p>总的来说，要实现具身智能，还需要做大量的工作。<strong>“没有灵魂的躯体是一具行尸走肉，没有躯体的灵魂是一缕虚无幽灵。”</strong>在具身智能的发展过程中，具身和智能缺一不可，且需要达到高度的有机结合。<strong>弥合虚拟与现实的鸿沟也从来不是一件易事，不管是从现实到虚拟的元宇宙，还是虚拟到现实的具身智能。</strong>可喜的是，当下全世界的AI与机器人专家正在各自的专业领域为此狂奔，<strong>长远来看，具身智能一定会走进千家万户，只是，还需要给它多一些时间。</strong></p>
  <p>（感谢腾讯研究院曹士圯、袁晓辉在本文撰写中提供的帮助。）</p>
  <p><strong>参考资料：</strong>腾讯研究院AGI图谱数据库、#腾讯研究院AI速递、#AI每周关键词Top50</p>
  <p><strong>李瑞龙：</strong>腾讯研究院</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&amp;mid=2650979634&amp;idx=1&amp;sn=c6556a802207a47923e1b9cd9528e143&amp;chksm=bd565420e155b2a604ca446830cbfb43348293326193f517822d45a71427d182ad0f344ef9de&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“腾讯研究院”（ID：cyberlawrc）</a>，作者：李瑞龙，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033133072249094</id>
            <title>为避免海外“相残”，这些中企正在行动起来</title>
            <link>https://www.36kr.com/p/3033133072249094</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033133072249094</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 10:49:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <中国企业, 国际标准, 专利纠纷, 竞争力>
<br>
<br>
总结: 中国企业在海外市场面临内卷和专利纠纷，损害了国际形象并影响出海步伐。现行国际标准多由发达国家制定，中国企业在国际标准制定中话语权不足，仅占2%。随着中国制造业的崛起，国际标准缺失和不匹配导致企业间竞争加剧，损失显著。为提升国际竞争力，中国企业需加强科技创新，积极参与国际标准制定，并通过政企合作将“中国标准”转化为“国际标准”。 </div>
                        <hr>
                    
                    <blockquote>
   <p>中国企业在海外内卷、内讧甚至正面冲突的事例，这两年频繁发生，不仅造成严重的不必要的内耗，还损害了中企的国际形象，拖累了中企出海的步伐。如果对这种现象追根溯源，不得不说到各行各业的现行国际标准，绝大多数都是欧美、日韩等发达国家及其巨头公司制定的，他们从一开始就为永葆自己的优势位置，让后来者难以逾越做了精心安排。技术总是在不断发展和扩散，标准也需要与时俱进。在5G技术、自动驾驶、互联网电商等新兴领域，得益于我国相关产业发展成果在国际上产生的强大影响力，有些相关国际标准制定开始由中国主导。</p>
   <p>但在更多存量领域，中国企业便属于“后来者”。根据2024年初统计数据，全行业由中国主导制定的国际标准，占比仅为2%左右，这与中国在科技创新、市场产销规模等方面的实力远远无法匹配。中国正在向国际标准制定这个关键问题发起攻坚，一些有实力、有抱负的中国企业开始行动起来。</p>
  </blockquote>
  <p>随着中国制造在全球市场份额不断增加，由于国际标准部分缺位或中国在国际标准体系话语权与其科创、市场产销实力不匹配，对相关企业造成的损失越来越不容忽视。</p>
  <p>不久前，联想向英格兰和威尔士高等法院（EWHC）起诉中兴通讯专利侵权事件，引发全网热议。目前事件结果尚无定论，但可以想见的是，两家中企在海外爆发正面冲突，对双方而言都是一种损失。</p>
  <p>今年8月，追觅与石头两家扫地机器人头部企业，同样因专利权纠纷在德国法庭大打出手，最终结果引发全行业反思和警惕。</p>
  <p>该案件最终因石头一方缺席德国法庭现场，被判相关产品禁止在德国的销售、使用、进口等。且石头科技的库存，需要交给杜塞尔多夫地方法院警察执行做销毁处理，相关费用由石头科技承担。石头科技还需要以书面形式向其直接客户告知召回所售产品，费用都由石头科技来承担。</p>
  <p>在行业看来，类似的商业纠纷看似源自对应领域内国际标准缺失，导致每个地区都有不同准则，当竞争进入白热化，找准机会给对手下点“猛药”的行为虽然不地道，但在相关行业内颇为普遍。</p>
  <p>从更深层次来看，造成国际标准缺失或新市场与旧标准不匹配的现状，使中企在出海过程中“自相残杀”，何尝不是旧有国际标准话语权掌控者所出的一记阳谋。</p>
  <p>可以说，中企出海过程中遭遇的因标准不一造成巨额损失的事件，早已屡见不鲜。</p>
  <p>中国电子技术标准化研究院（下称“电子标准院”）数字技术研究中心副主任董桂官向观察者网分析认为，企业之间因专利导致的互相诉讼是商场常事，欧美国家类似的专利诉讼也不在少数。但透过特定事件，更多的需要看到，如何寻求产业合力强化整体国际竞争力。</p>
  <p>比如上文石头与追觅诉讼案例，两家企业完全可以积极通过国际标准的国内归口，寻求推动扫地机器人国际标准研制，借此求同存异，降低企业之间产生分歧、矛盾的可能性，在标准规定的技术指标上追求更高的技术实现，在标准未规定的技术指标上追求差异化技术优势，整体提升中企的全球竞争力。</p>
  <h2><strong>困境：话语权与科技、产销实力不匹配</strong></h2>
  <p>10月14日是第55个世界标准日。今年世界标准日的主题为“美好世界的共同愿景”，中国主题为“强化标准引领，促进高质量发展”。这一主题口号中，既包含了国际标准对发展的引领作用，也不难看出中国对于参与和主导世界标准体系的决心。</p>
  <p>事实上，几乎所有行业对此都早有认知，随着我国经济进入转型发展时期，强化标准引领，对于发展新质生产力，构建新发展格局，推动高质量发展具有重要意义。</p>
  <p>不过在国际标准制定过程中，话语权的大小不是简单地根据国家或企业间产能、销量、营收、知识产权数目等一连串确定的数字进行同比分配。每一场标准会议都如同一场“技术外交会”，背后是国家间、产业间的技术和利益博弈，更需要高质量的创新和长期坚守。</p>
  <p>尤其是中企在科技与市场产销方面后来居上的部分领域，想要在国际标准话语权上打破原有壁垒，更加困难重重。</p>
  <p>以扫地机器人领域为例，根据IDC统计数据，2023全球智能扫地机器人市场出货1852万台，中美两国最高，分别约占全球市场份额的1/4。</p>
  <p>但在国际标准话语权体系中，两国头部企业却不可同日而语。目前，美国厂商iRobot 作为行业的领先者，已参与并主导了多项与扫地机器人相关的国际标准的制定。</p>
  <p>例如iRobot 参与制定的《家用和类似用途擦（拖）地机器人》团体标准，适用于具有拖地功能的独立式拖地机器人，以及宣称具有拖地功能的二合一扫地机器人。至今，这个标准都对整个行业的规范和指导作用影响深远。</p>
  <p>相比之下，与美国企业所占全球市场份额相当的中国企业如科沃斯、石头、追觅、小米、美的等，在参与相关国际标准制定的过程中阻碍重重，至今几乎没有话语权。</p>
  <p>“由于在机器人领域起步较晚，而且国内企业竞争激烈，头部企业在近几年大规模进军国际市场受阻之后，才意识到国际标准话语权不足带来的危害，也导致中国企业本身在ISO、IEC等国际标准上的布局晚了一步。”科沃斯国际标准研专家尚云告诉观察者网，目前国内仅有科沃斯、石头、美的三家企业进入IEC家用清洁服务机器人工作组，全组约30个人，分别代表全球相关产业不同地区，但目前工作组仍以德国、韩国、美国和英国人为主，组长更是一名韩国庆熙大学教授，该教授背后目前甚至没有任何的相关产业支撑。“三家中国企业明明已经足以代表扫地机器人领域发展的最高水平，所提交的相关提案却因各种因素屡屡被否决。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_7e02221627274b9bb90b9a9a15e73740@000000_oswg55865oswg551oswg219_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>事实上这样的情形在整个国际标准体系中十分常见。</p>
  <p>根据三大国际组织官方网站及其最新的年度报告，以及美国大西洋理理事会研究报告中的数据，对比中美在三大组织的国际标准化活动情况，不难看出，中美在三大国际标准化组织中的参与度在全球均处于前列，相较而言，中国参加的技术委员会数量更多，更加积极参与各个领域的标准制定工作，但参与度高并不一定能转化为影响力，真正能反映成员参与和分配标准化资源能力的是秘书处和主席职位，这两项数据中国都弱于美国。</p>
  <p>且在众多国际标准原有的话语权体系中，德、英、法等欧洲传统工业强国，加上日本、韩国本身影响力不弱于美国，联合起来形成的壁垒对于中国企业而言，压力可想而知。</p>
  <p>中国电子技术标准化研究院（下称“电子标准院”）数字技术研究中心副主任董桂官向观察者网分析指出，如今随着国际市场竞争加剧，中企出海受到来自国际标准方面的影响更加明显。</p>
  <p>首先是国际标准中对应产品的标准缺失。国际标准包括安规方面的基础标准，也有不少具体的产品标准和技术标准；整体来看，安规等基础标准是比较完备的，一般配合法令、政策、规定执行，具备强制性；国际标准以技术标准为主，产品标准相对较少；因为国际标准研制周期比较长（一般3-5年及以上），很多新兴的产品长期缺乏对应的产品标准。企业因为产品标准的缺失，很多产品面临无产品标准可依据的情况；这样的情况下，加之贸易保护主义和单边主义盛行，中企出海就可能面临更大的市场风险，不仅在海外与本土企业竞争中天然处于劣势，而且可能平白增加许多不必要的资源消耗。</p>
  <p>其次是国外标准的符合性风险较大。区域性国家集体制定的标准，其标准配合相应国家和地区的法令、政策、规定要求，在对应区域内，其效力基本等同于国际标准，需要做好识别并做好应对；由技术组织制定的联盟标准、协会标准，不同技术组织对标准及相关商标、专利的许可机制不同，当产品涉及相关技术组织标准、知识产权时，要做好重点识别；由技术持有公司制定的私有标准，更需要注意好合规问题，此类涉及知识产权侵权问题时，往往伴随着诉讼、罚款等追加措施，企业面临的成本极高。</p>
  <p>此外，还需要留意一些特殊情况，包括特定国家发起的针对我国特定产品、技术的贸易调查等问题，海外布展涉及的相关备案问题，销售平台针对特定产品、技术的规定等等。</p>
  <h2><strong>遵循规则、参与规则、主导规则</strong></h2>
  <p>“尽管国际标准的研制周期长、投入大，且回报不是立竿见影的，但长远来看，其价值是难以估量的。”在董桂官看来，对于参与全球竞争的企业而言，国际标准化领域竞争激烈，在自己的核心产品领域，如果国际标准研制无法参与，后续的执行中只能作为标准的执行者，在关键技术指标方面只能被动遵守，最终反映在市场端就会处处受制于人。</p>
  <p>一个非常典型案例是DVD产业。1995年飞利浦、索尼公司的多媒体光盘系统MMCD和东芝等公司的超密度光盘系统SD在IBM等计算机公司的大力推动下将两种标准规格进行了统一，经国际官方组织DVD论坛认可，形成了第一代DVD标准规格，DVD开始大规模产业化。</p>
  <p>彼时，为了尽快实现工业化，中国迅速成为DVD的最大生产国和出口国，也迅速涌现出如步步高、先科、爱多、万利达、新科、TCL等众多耳熟能详的DVD品牌。</p>
  <p>据统计，2001年我国DVD产品出口总量达到了1050万台，2002年中国DVD产量已占世界产量的90％。</p>
  <p>但产销量巨大背后存在的严重问题是，DVD的核心专利和技术标准全部为国外企业掌握，DVD的核心元器件都是从国外进口，在国内只是简单的组装，我国企业基本没有自己的知识产权，渐渐变成了3C专利联盟（飞利浦、索尼、先锋）和6C专利联盟（东芝、三菱、日立、松下、JVC、时代华纳）等国外品牌的“专利提款机”。</p>
  <p>痛定思痛，中国在多个新兴领域组建联盟组织，如3C产业的闪联等，通过共同制定有中国自己知识产权的技术标准，提升中国企业的话语权，应对国外竞争。</p>
  <p>各领域头部企业也在崛起过程中，不断加强自身标准化制定专业能力以及对国际标准方面的参与度。如家用清洁机器人领域的头部企业科沃斯，早在2009年便由董事长钱东奇亲自带队成立标准化研究工作组，参与到国际标准制定的工作中。</p>
  <p>家电巨头美的集团，同样成立了以董事长方洪波为主任委员的集团标准化管理委员会，建立集团-事业部两级标准管理体系，并成立专职秘书处推进集团技术标准工作，同时发布集团标准化战略。</p>
  <p>然而中企凭借强的供应链体系，加强科技创新能力的同时，在产销方面做大做强相对容易，但要将自身技术和方案上升为国际标准却要困难得多，尤其是在西方发达国家早已建立了坚固的国际标准话语权壁垒的领域。</p>
  <p>强如美的集团，近5年研发投入接近600亿元，累计参与制修订2000余项外部标准，几乎覆盖所有家电制造领域，其中也仅有70多项属于国际标准，且绝大多数由西方发达国家主导。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_efdd1bbe11c8404bba01ba0fa3187771@000000_oswg7282oswg910oswg583_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>“除了少数新兴产业之外，任何一个领域的‘后来者’想要做大做强，都需要经历从遵循既定规则，到参与规则制定，再到牵头规则的过程，美的也是如此。”美的中央研究院科技与标准总监李猛向观察者网指出，一家企业如果不能参与国家标准或国际标准的制修订，那就只能被动接受；当企业能够参与到标准制修订过程中时，意味着企业的技术创新水平已经达到一定高度，并能转化成具有市场优势的引领产品；当企业可以牵头一些标准的制修订，则往往意味着企业的技术创新能力高于行业平均水平，可以推进行业的技术进步，为行业发展做出更多贡献，这也是包括美的在内所有头部企业努力的方向。</p>
  <h2><strong>“农村”包围“城市”，增量冲击存量</strong></h2>
  <p>那么，面对固有的国际话语权壁垒，中企该如何完成从标准的“遵循者”向“参与者”，再到“制定者”这一身份的跃迁呢？</p>
  <p>李猛认为，首先是打铁还需自身硬，回归自主科技创新本身，这是企业提升话语权的基础。</p>
  <p>譬如空调冷媒领域，美的集团创新研发的R290冷媒空调在环保方面远超此前由日企主导研发的R32冷媒，形成了打破原有壁垒的基础，因此美的有了牵头制定IEC国际标准中关于R290环保冷媒相关安全要求的基础。</p>
  <p>其次，从市场角度来看，面对欧美先发企业在众多领域组建的话语权壁垒，中企通过国家“一带一路”战略，先打开东南亚、中东、非洲及南美等发展中和欠发达地区增量市场，以新的增量市场来撬动发达地区存量市场，最终获得国际社会认可同样不失为一条可行性路径。且这一过程中，也必然伴随着更多新技术、新标准的诞生，用增量技术冲击存量技术壁垒的过程。</p>
  <p>在这方面，移动通信领域的成功无疑是一个典型案例，我国在2G、3G、4G、5G的技术标准研制中的标准必要知识产权占比不断增高，也促进了我国移动通信产业的快速发展，实现了3G跟跑，4G并跑，5G局部领跑的跨越式增长，华为、中兴等一大批全球通信巨头快速成长。</p>
  <p>有中国新能源汽车企业从业人员向观察者网分析认为，中国新能源汽车以及围绕于此的智能驾驶、电池、换电等服务，能在短短十余年间从起步之初不被看好，到如今称霸全球。有人说这是占了新赛道、填补市场空白的便宜，但根本上，汽车还是汽车，我们何尝不是从欧美日韩等传统燃油车霸主手中虎口夺食？</p>
  <p>比亚迪、蔚小理等新兴车企的发展路径，是先从中国市场站稳脚跟，然后扩张到东南亚、中东，而在扩大增量市场的过程，也是企业重新建立国际标准的过程。最终当增量市场足够大，足以撼动发达地区原有的存量市场时，这些新能源车企所建立的标准便顺理成章成为新的国际标准。</p>
  <p>在他看来，特斯拉的成功也是同理。2018年之前，马斯克在美国本土通用、福特等传统巨头以及欧洲、日本燃油车企的夹击下，得不到产业链支撑，只能在“产能地狱”苦苦挣扎，直到被中国政府引进，从中国这一增量市场打开局面，并由此一飞冲天。</p>
  <p>另一个通过增量市场冲击存量市场、增量技术冲击存量技术壁垒，从而在国际话语权体系占据一席之地的经典领域是中国家电。</p>
  <p>李猛举例称，美的今年上半年联合马来西亚当地政府发布了一项关于冰箱净味的标准，填补了该领域的空白。美的冰箱在深耕马来西亚市场时发现，当地市场的一个典型特征是家庭人口众多，对冰箱的要求就是容积和存储量大，冰箱存放物品种类多，因此对冰箱净味的需求就比发达地区更多。“通过对这一市场特征的洞察，加上美的冰箱在净味方面的技术优势，就促成了美的与马来西亚政府的合作，最终联合发布了这一标准，未来还将向其他有需求的国家地区推广应用。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_4ee41b00f2b44a05b24fd5c31941f2f9@000000_oswg146108oswg1063oswg709_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">美的主导的马来西亚冰箱净味标准发布仪式</p>
  <p>此外，中企亦不妨寻求建立新的全球性技术组织。董桂官表示，当前主要的全球性技术组织主要集中在欧美国家，我国具备产业基础、规模优势的领域，应该积极推动全球性技术组织的建立，进一步寻求产业合力。</p>
  <p>目前，国内已经建立了世界超高清视频产业联盟UWA等全球性技术组织，推动了HDR Vivid等创新技术标准研制和产业化应用，取得了不错的经济社会效益。</p>
  <h2><strong>政企合作，将“中国标准”变成“国际标准”</strong></h2>
  <p>值得注意的是，在更多行业人士看来，单凭企业自身力量去打破这一壁垒所需花费的时间、资金成本巨大，且各自为战。</p>
  <p>为此，企业和政府需要相向而行，形成合力，更多时候需要通过国家机构牵头，企业积极参与，先将科技研发成果转化为国家标准，再与国际相关组织融合，逐步将“中国标准”转化为“国际标准”，从而使全行业收益。</p>
  <p>以全国音频、视频及多媒体系统与设备标准化技术委员会为例，董桂官向观察者网介绍称，作为国内微型扬声器领域归口单位，该标委会一直以来致力于支持中国技术团队主导制定相关国际标准，如2020年6月发布的IEC 63034，是我国声学领域首个自主提出、具有技术主导性的声学国际标准，该标准重新定义了微型扬声器的关键技术指标，包含但并不限于阻抗特性、位移、幅频响应、失真和功率等，同时提高了国家标准、行业标准与国际标准的一致性，使积极参与其中的AAC（瑞声科技）、歌尔股份等中国微型扬声器头部企业率先受益。</p>
  <p>如今，已有越来越多行业头部企业积极参与其中。今年9月，科沃斯和中国家用电器研究院获批共同主导中国首个商用清洁机器人国家标准制定工作。该标准包含安全、性能等在内的整个产品评估体系的评估方法和限值要求，目的是建立商用清洁机器人产品门槛，规范行业内部竞争，并为国家相关部门抽查提供有利依据。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_90a60d30e1d3411a8c19441fcc5930ad@000000_oswg371602oswg640oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">科沃斯主导的《商用清洁机器人》国家标准制定启动会</p>
  <p>同时，科沃斯研发的机器人大模型算法通过国家网信办深度合成服务算法备案，成为国内首个家用机器人领域通过备案的大模型算法。</p>
  <p>在科沃斯看来，随着国家整体实力的不断提升，以及相关机构建立国际与国内标准项目同步发展，提升国际国内标准一致性水平方面的大幅改善，优先配合国内归口单位参与和主导相关标准体系的制修订，也是企业标准工作组的主要工作之一。</p>
  <p>事实上，早在2021年10月中共中央、国务院印发的《国家标准化发展纲要》中，就提出要“国家标准与国际标准关键技术指标的一致性程度大幅提升，国际标准转化率达到85%以上”；今年3月，国家市场监督管理总局等十八部门联合印发《贯彻实施〈国家标准化发展纲要〉行动计划（2024—2025年）》，再次提出“持续开展国际标准跟踪研究，加快转化先进适用国际标准，实现国际标准转化率达到85%以上”的具体工作要求。</p>
  <p>据国家市场监督管理总局标准创新司副司长柳成洋介绍，近年来，我国参与国际标准化活动的程度持续增强，国际影响力不断上升，国际标准组织技术机构国内技术对口单位发挥着重要作用。</p>
  <p>2024年，国家市场监管总局国家标准委以国际标准化工作的最新趋势和要求为导向设置18项指标，面向26个行业领域的353个对口单位开展考核，34个国内技术对口单位考核结果为一级。</p>
  <p>历史的车轮滚滚向前，不可阻挡。随着技术的不断进步和行业的快速发展，以及全球制造业格局重塑，中国企业通过引进、消化、吸收，慢慢进入再创新的阶段，已在不少领域后来居上，甚至在产销等占比方面拥有一定的主导地位，也开始逐渐冲击原有标准中无法适应当前市场需求的部分。</p>
  <p>注：围绕标准主题，首先要界定一下标准分类。第一类是国际标准，指的是ISO（国际标准化组织）、IEC（国际电工委员会）、ITU（国际电信联盟）三大国际标准化组织制定的标准；第二类是国外标准，指的是区域性国家集体制定的标准，和产品/技术组织制定的联盟标准、协会标准，前者比如欧盟的EN标准，后者比如IEEE标准、3GPP标准、USB标准、MPEG标准等；第三类是私有标准，指的是由技术持有公司制定的标准，比如杜比公司制定的标准等等。为了便于讨论，本文“国际标准”特指狭义的“国际标准”。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NjIxNjkxNw==&amp;mid=2247530976&amp;idx=1&amp;sn=311499248fbb34192cfff2073ba4a7b5&amp;chksm=c280032fce06abef9d28dbf74f51182db5ff6889eb9362c2d6cb874d2954af78787884652760&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“观网财经”（ID：tiequanhe）</a>，作者：张志峰，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033039607722245</id>
            <title>Ilya认错，Scaling Law崩了？自曝SSI秘密技术路线取代OpenAI</title>
            <link>https://www.36kr.com/p/3033039607722245</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033039607722245</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 10:11:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <Scaling, AI模型, Ilya Sutskever, 推理模型>
<br>
<br>
总结: Ilya Sutskever承认传统的Scaling Law已遇瓶颈，强调应关注扩展的对象而非单纯追求模型规模。当前AI实验室面临高昂的训练成本和复杂系统崩溃的问题，许多新模型未能显著提升性能。OpenAI和其他公司正在探索新的方法，如“测试时计算”，以提高模型推理能力并减少对数据和电力的依赖。随着Scaling Law的消退，推理模型的性能提升可能代表了一种新的Scaling Law，未来AI硬件市场格局也可能因此改变。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5bd6ea8fde4d49d5bf6f021446d37018@46958_oswg325185oswg1071oswg415_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>【导读】</strong>Ilya终于承认，自己关于Scaling的说法错了！现在训练模型已经不是「越大越好」，而是找出Scaling的对象究竟应该是什么。他自曝，SSI在用全新方法扩展预训练。而各方巨头改变训练范式后，英伟达GPU的垄断地位或许也要打破了。</p>
  <p>昨天，The Information爆料，传统的大模型Scaling Law已经撞墙，OpenAI下一代旗舰Orion遭遇瓶颈。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_833786bd19a84fc6b44708c885edf6ef@46958_oswg171952oswg1080oswg323_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>就在刚刚，路透社也发文表示，由于当前方法受到限制，OpenAI和其他公司正在寻求通向更智能AI的新途径。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_2d39b17776964089bc19ed066b91b259@46958_oswg61953oswg1080oswg198_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>有趣的是，昨天拱火的The Information，今天又急忙发出一篇文章来灭火。&nbsp;</p>
  <p>他们强调，昨天的文章只是在说改进大模型必须找到新方法，并不是说Scaling Law已经终结。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_78e76783ced742ee8c6c1b135ec49c8e@46958_oswg42970oswg1080oswg141_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>但一个不争的事实就是：硅谷几大主要AI实验室正在陷入困境。训练这些大规模的LLM动辄需要花费数千美元，但复杂系统还经常崩溃。往往需要数月时间，才知道模型能否按预期工作。&nbsp;</p>
  <p>比起GPT-4o，Orion几乎没有任何改进；谷歌的Gemini 2.0，被曝也存在同样问题；Anthropic据传也已暂停Opus 3.5模型的工作。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_2cb95ee644be43c485b87a26e27fbc2b@46958_oswg121235oswg465oswg279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>据悉，谷歌正准备在12月推测出最新的Gemini 2.0，它可能无法实现DeepMind创始人Demis Hassabis团队预期的显著性能改进，但会有引入一些有趣的新功能&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_f0ac5769fe9e427a97f1855412cda986@46958_oswg546049oswg1080oswg698_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Anthropic首席执行官Dario Amodei 表示，「我们的目标是改变曲线，然后在某个时候成为Opus 3.5」&nbsp;</p>
  <p>而离职创业的OpenAI元老则Ilya Sutskever则表示，现在重要的是「扩大正确的规模」。&nbsp;</p>
  <p>「2010年代是scaling的时代，现在，我们再次回到了奇迹和发现的时代。每个人都在寻找下一个奇迹。」&nbsp;</p>
  <p>对经营着自己的AI实验室SSI的Ilya来说，这是一个很大的改变。&nbsp;</p>
  <p>曾经在推动OpenAI的GPT模型时，他的准则是「越大越好」。但在SSI的最近一轮融资中，Ilya开始希望尝试一种与OpenAI不同的Scaling方法。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_9ad8407b183f4f5c9872257512278f8f@46958_oswg136305oswg720oswg1200_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Scaling Law大家都说得够多了。但有一个问题，却被每个人都忽略了——我们说scaling的时候，究竟在scaling什么？&nbsp;</p>
  <p>如今，Ilya抛出了这个振聋发聩的疑问。&nbsp;</p>
  <h2><strong>Scaling正确的东西，比以往任何时候都更重要</strong></h2>
  <p>毕竟，超大规模语言模型的ROI实在太低了。&nbsp;</p>
  <p>虽然在GPT-4发布后，各大AI实验室的研究人员都竞相追赶，发布了超过GPT-4的大模型，但他们更多的感觉是失望。&nbsp;</p>
  <p>因为要同时运行数百个芯片，这种超大参数模型的训练可能要花费数千万美元，系统太复杂还可能会出现硬件故障。但只有经过数月，等到运行结束后，研究人员才能知道模型的最终性能。&nbsp;</p>
  <p>另一个问题，就是LLM吞噬了大量数据，而世界上易于获取的数据，几乎已经被耗尽了！&nbsp;</p>
  <p>同时，由于过程中需要大量能源，电力短缺也成为训练AI的严重阻碍。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a754340ca4bf489192d6b69bb70dcc78@46958_oswg78029oswg850oswg449_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文题目：「The Unseen AI Disruptions for Power Grids: LLM-Induced Transients」&nbsp;</p>
  <h3><strong>替代Scaling的新方法，Ilya已经有了？</strong></h3>
  <p>面对这种种现状，Ilya最近在路透社的采访中表示，扩展训练的结果，已经趋于平稳。&nbsp;</p>
  <p>也就是说，用大量未标记数据来理解语言模式和结构的训练阶段到头了。&nbsp;</p>
  <p>以前，Ilya是暴力scaling的早期倡导者之一，那时有一种想法广泛认为，通过预训练中使用更多的数据和算力，能让AI模型的性能暴涨。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_397939dd2bed47ff9f1be741ebd746a2@46958_oswg233664oswg1080oswg448_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>OpenAI团队2020年提交的arXiv论文中最先提出这一概念：LLM性能与计算量、参数量、数据量三者呈现幂律关系&nbsp;</p>
  <p>的确，沿着这条路线，最终ChatGPT诞生了。&nbsp;</p>
  <p>ChatGPT发布后，从AI热潮中受益颇多的科技公司都公开声称，这种通过增加数据和算力来「scale up」的方法，能显著改善模型性能。&nbsp;</p>
  <p>可是现在，Scaling Law已经碰壁了！越来越多的AI科学家，对于这种「越大越好」（bigger is better）的哲学产生了质疑。&nbsp;</p>
  <p>2010年代属于Scaling，但大模型要继续发展下去，需要一个新的奇迹。&nbsp;</p>
  <p>Ilya的SSI团队是否找到了呢？&nbsp;</p>
  <p>对此，Ilya拒绝透露，只是表示，SSI正在研究一种全新的替代方法，来扩展预训练。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a714402b2ea648de8bc1f3b12f5e3735@46958_oswg929880oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>再领先三步？OpenAI破局新方法：测试时计算</strong></h3>
  <p>同时，OpenAI仿佛也找到了新方法——通过开发使用更类人思维的算法训练技术，或许就能克服在追求更大规模LLM过程中遇到的意外延迟和挑战。&nbsp;</p>
  <p>已经有十几位AI科学家、研究人员和投资者告诉路透社，他们认为正是这些技术，推动了OpenAI最近发布的o1模型。&nbsp;</p>
  <p>而它们，可能会重塑AI竞赛的格局，让AI公司们不再对能源和芯片资源产生无限制的需求。&nbsp;</p>
  <p>有没有这么一种新方法，让AI模型既能摆脱对数据的依赖，又不再需要动辄吞噬整个国家乃至全球的电力？&nbsp;</p>
  <p>为了克服这些挑战，研究人员正在探索一项「测试时计算」的技术。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_97e5bf744873472fb553770e2e6c90ed@46958_oswg114879oswg1080oswg596_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>上图即是OpenAI解释o1的博文，x轴标记为「训练时计算」和「测试时计算」。&nbsp;</p>
  <p>左图是OpenAI发现的Scaling Law，意味着在模型上投入更多训练时间（GPU周期）时，我们可以获得更好的结果。&nbsp;</p>
  <p>右图则暗示了我们尚未触及的一套全新的Scaling Law。「测试时计算」意味着，给模型更多的「思考时间」（GPU周期）时，它会思考出更好的结果。&nbsp;</p>
  <p>测试时计算技术，能在推理阶段（模型被使用时）就将模型增强，比如，模型可以实时生成和评估多种可能性，而不是理解选择单一答案。最终，模型就可以选择出最佳路径。&nbsp;</p>
  <p>这种方法可以允许模型将更多的处理能力，用于数学、编码问题等具有挑战性的任务，或者需要类人推理和决策的复杂操作。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_3addbff2666145c0ab13bc4aaeea252c@46958_oswg255288oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>传统的Scaling Law，专注于用更长时间训练大模型，但如今o1系列模型scaling有了两个维度——训练时间和测试（推理）时间&nbsp;</p>
  <p>早在上个月的旧金山TED AI会议上，曾参与o1开发的OpenAI研究员Noam Brown就提出——&nbsp;</p>
  <blockquote>
   <p>事实证明，让一个机器人在一局扑克中思考仅20秒，其性能提升与将模型规模扩大10万倍并训练10万倍时间相同。&nbsp;</p>
  </blockquote>
  <p>o1模型以前曾被称为「Q*」和「Strawberry」。现在，它能够以多步骤方法思考问题，类似于人类推理。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_4caeec21db0a46929d5b6680f10f6c09@46958_oswg165588oswg897oswg249_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>现在，模型不再受限于预训练阶段，还可以通过增加推理计算资源，来提升表现&nbsp;</p>
  <p>而且，它还涉及了来自博士和行业专家策划的数据和反馈。&nbsp;</p>
  <p>o1系列的秘密武器，是在GPT-4等基础模型上进行的另一套训练，OpenAI还计划，将这种技术应用于更多更大的基础模型。&nbsp;</p>
  <p>OpenAI的首席产品官Kevin Well在十月的一次科技会议表示——&nbsp;</p>
  <blockquote>
   <p>我们看到很多可以快速改进这些模型的机会，而且非常简单。到人们赶上来的时候，我们会尝试再领先三步。&nbsp;</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_f64d61209f574bcf81ad8cb612915f9a@46958_oswg395283oswg1080oswg1086_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>通过思维链提示，o1模型可以经过训练生成长长的输出，并通过答案进行推理&nbsp;</p>
  <h3><strong>全球顶尖AI实验室开卷，英伟达垄断地位有望打破？</strong></h3>
  <p>OpenAI说要领先三步，其他顶尖AI实验室岂甘落后？&nbsp;</p>
  <p>据知情人士透露，来自Anthropic、xAI和谷歌DeepMind的研究人员，也已经奋力开卷了！&nbsp;</p>
  <p>比如Meta最近提出了「思维偏好优化」TPO，这种方法旨在教会LLM在回答一般任务（而不仅仅是数学或逻辑问题）之前「思考」，而不需要特殊的训练数据。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_212a84c3731746e0b86f1cc35ce01556@46958_oswg69897oswg882oswg328_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文地址：https://arxiv.org/pdf/2410.10630&nbsp;</p>
  <p>而谷歌也在开发一种新模型，同样使用CoT方法解决多步骤问题、生成多个答案，评估后选择最佳答案。&nbsp;</p>
  <p>这个过程同样可以通过在推理中使用更多算力来增强，而非仅仅增加训练数据和算力，这就为扩展AI模型开辟了一条新道路。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_9005f0ba8c1b470aae1ac9b65e37d994@46958_oswg122720oswg1080oswg239_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文地址：https://arxiv.org/pdf/2408.03314&nbsp;</p>
  <p>这会导致什么后果？&nbsp;</p>
  <p>很有可能，对英伟达GPU巨大需求主导的AI硬件竞争格局，将从此改变。&nbsp;</p>
  <p>这是因为，通过增加训练时间和测试（推理）时间，可能会获得更好的结果，模型就不再需要那么大的参数。&nbsp;</p>
  <p>而训练和运行较小模型会更便宜，因此，在给定固定计算量的情况下，我们可能会突然从小模型中获得更多收益。&nbsp;</p>
  <p>突然之间，模型参数、训练时间和测试时间计算之间的关系变得复杂了，也就让我们看到了下一代GPU的可能。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5a587e463eab488a87f148f00185057d@46958_oswg219606oswg599oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>比如Groq这样的公司，恰巧就在为这类任务制造专门的芯片。&nbsp;</p>
  <p>今年2月登场的世界最快大模型Groq，每秒500 token直接破了纪录，自研的LPU在LLM任务上比英伟达GPU性能快了10倍。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_95a719d68e3746b5ae7fd81590eeedc6@46958_oswg756148oswg965oswg543_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>红杉资本和A16z在内的著名风投机构，如今已经投入了数十亿美元，资助OpenAI、xAI等多家AI实验室的开发。&nbsp;</p>
  <p>他们不可能不注意到最近圈内盛传的Scaling Law碰壁事件，而重新考虑自己的昂贵投资是否会打水漂。&nbsp;</p>
  <p>红杉资本合伙人Sonya Huang表示，这种转变，将使我们从大规模预训练集群转向推理云，即分布式的、基于云的推理服务器。&nbsp;</p>
  <p>大模型热以来，对英伟达尖端AI芯片的需求，已经让它崛起为全球最有价值的公司，并且市值超越了苹果。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d10ece1c611d492698537e5b1ea82203@46958_oswg86896oswg1080oswg420_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>今年以来，英伟达股价了约186%，而苹果仅上涨了17%&nbsp;</p>
  <p>虽然在训练芯片的市场，英伟达已经占据主导地位，但它在推理市场，可能还会面临更多竞争。&nbsp;</p>
  <p>而o1模型背后技术，意味着对推理芯片的需求也会随着增加。&nbsp;</p>
  <p>「我们现在发现了第二个Scaling Law，这是在推理阶段的Scaling Law……所有这些因素导致对Blackwell的需求非常高。」&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_303402a028e54a53a6d3848f0bc014d6@46958_oswg1190556oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在英伟达GTC大会上，黄仁勋也讲到，如果要训练一个1.8万亿参数量的GPT模型，需要8000张H100 GPU，消耗15兆瓦的电力，连续跑上90天&nbsp;</p>
  <p>随着Scaling Law碰壁，各大公司纷纷开启新路线，英伟达是否还会继续坐火箭般的辉煌呢？&nbsp;</p>
  <h2><strong>再见，GPT。你好，推理「o」</strong></h2>
  <p>The Information今天的解释文章，标题意味深长：《再见，GPT。你好，推理「o」》。&nbsp;</p>
  <p>文章内容是这样的。&nbsp;</p>
  <p>月初，一位Reddit用户曾在QA种问道，OpenAI的下一代旗舰大语言模型何时发布。&nbsp;</p>
  <p>对此，Altman回答说：「今年晚些时候，我们会发布一些非常不错的产品，但并不会叫做GPT-5。」随后他又补充道，有限的计算资源意味着很难同时推出过多的项目。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d312a921a74c4f679979392ca230b6c1@46958_oswg112659oswg816oswg614_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>当时我们并未多想。&nbsp;</p>
  <p>但如今，我们更能理解Altman的评论了——以及他为何专注于推出o系列推理模型而非另一版本的GPT 。&nbsp;</p>
  <p>所谓GPT，即生成式预训练Transformer模型，是ChatGPT和大多数其他生成式人工智能产品的基石。&nbsp;</p>
  <p>原因正如之前报道的那样，GPT的改进速度正在放缓。&nbsp;</p>
  <p>2023年初登场的上一代旗舰级模型GPT-4，凭借着巨大的性能提升在科技行业引发了轰动。&nbsp;</p>
  <p>Orion比GPT-4更好，但其质量提升与GPT-3和GPT-4之间的差距相比略显逊色。甚至，可能会让OpenAI放弃自2018年推出GPT-1起使用的「GPT」命名惯例。&nbsp;</p>
  <p>因此，当Altman写道「o1及其后续版本」时，可能意味着Orion将与推理融合并被命名为「o2」。&nbsp;</p>
  <h3><strong>随着一种Scaling Law的消退，另一种定律取而代之</strong></h3>
  <p>让我们回到GPT发展放缓这个问题上。&nbsp;</p>
  <p>传统的Scaling Law不仅仅意味着在大语言模型训练过程中需要更多的数据和计算能力才能获得更好的结果。OpenAI的研究人员还做了各种其他有趣的事情，才使得GPT-4比GPT-3有了大幅提升。比如，引入被称为模型稀疏性的概念。&nbsp;</p>
  <p>随着推理范式的出现，预训练改进的放缓变可以得到弥补——从本质上讲，它可能代表了一种新的Scaling Law。&nbsp;</p>
  <p>OpenAI一再表示，推理模型的性能在回答问题前有更多时间思考时会变得更好，这被称为对数线性计算扩展。&nbsp;</p>
  <p>那么，这些变化是否意味着OpenAI的1000亿美元超级计算集群的梦想正在消退呢？对于这个问题，可以肯定的是，所有主流的AI开发者都在全速推进极其昂贵的集群建设。&nbsp;</p>
  <p>一方面是，大型集群上可以更好地在预训练后改进这些模型、在后训练阶段处理强化学习以及更新或微调模型。&nbsp;</p>
  <p>另一方面是，即便预训练模型的改进速度放缓，但只要自己能训出比竞争对手略好的模型，就值得增加的数据中心投入。毕竟，LLM越好，将推理模型融入模型后获得的结果就越好。&nbsp;</p>
  <p>最后，如果GPT的发展没有加速，是不是就意味着末日论者错了——AI不会进入所谓的递归自我改进循环，在这个循环中，AI会一次又一次地找出如何制造下一个更好版本的自己（然后也许会征服我们所有人）？&nbsp;</p>
  <p>对此，Marc Andreessen认为，这种明显的平台期意味着这样的恐惧目前看来是没有根据的。&nbsp;</p>
  <p>参考资料：&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/EbO4lhGH1kwQstDSBoTHww" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：Aeneas 好困&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033113812611334</id>
            <title>“一听别人说‘清华系’，我就感觉压力山大”</title>
            <link>https://www.36kr.com/p/3033113812611334</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033113812611334</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 09:56:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 母校光环, 高校创业, 投资人特质, 孵化器价值  
<br><br>  
总结: 本文探讨了“母校光环”对投资工作的影响，尤其是在“硬”时代背景下，高校创业的兴起与投资人特质的关系。清华系的创业者和投资人被认为具有理性、踏实和长线思维的特质。张煜分享了自己在清华和微软的经历，强调了孵化器在创业过程中的重要性，尤其是在人工智能领域。文章还讨论了创业者在孵化器中成长的路径，以及如何在市场中保持竞争力和应对压力。 </div>
                        <hr>
                    
                    <p>“母校光环”的存在又能给投资这份工作带来一些什么样的具体影响呢？</p>
  <p>自从创投周期进入所谓的“硬”时代，“高校创业”逐渐成为了一个热门关键词。热度上升背后的基本逻辑是，模式创新带来的增长已经趋近于饱和，新的增长曲线需要新的技术来带动，而高校作为教研资源最集中的地方，理应在这个时代扮演更高的权重。</p>
  <p>也正因为如此，我们开始频繁在标题里看到“清华系”“科大系”“浙大系”“港大系”。通常这类报道的主线不是描述创业者的教育背景，而是借用创业者的教育背景，去切入某高校在某专业领域的发展状况，试着对未来可能潜在的发展进行一个阶段性的前瞻。</p>
  <p>不过如果我们把问题反过来，创业者可以用“XX系”来概括，投资人也可以用“XX系”来概括吗？在投资领域里，不同高校背景出身的投资人会有明显的性格特质差异吗？“母校光环”的存在又能给投资这份工作带来一些什么样的具体影响呢？</p>
  <p>这些问题很关键，也很难回答，但我遇到了一个非常合适的对谈者，他就是清智资本的创始合伙人张煜。张煜清华出身，学习工科，却在读书期间成为了传奇电子产品“文曲星”的区域销冠；毕业后他先后任职华为、微软，主导微软全球“创新杯”大赛，推动微软第一所创新加速器的诞生；他现在专注于人工智能初创团队的孵化与投资，我第一次遇到他的时候，他正在和团队一次确定加速器新区域的装修方案。</p>
  <p>在这样的故事线里，我们应该能找到一些相对明确的答案。</p>
  <h2><strong>1998年之前，同学们还不知道什么叫Startup</strong></h2>
  <p><strong>蒲凡：</strong>您身上有两个我特别感兴趣的“标签”。一个是清华——这个咱们今天的主题，可以放在后面详细展开——另一个是微软，尤其是您在微软期间，推动了微软创新加速器的建立。我个人对创业孵化这件事情特别感兴趣，这几天来北京出差，也安排了一个下午专门来参观清智在清华科技园的孵化器。</p>
  <p>所以开场阶段，我想首先问这样两个问题。第一，您当年为什么会主导推动这件事？第二，当年您是如何理解加速器、孵化器的？</p>
  <p><strong>张煜：</strong>我对于科技创新与孵化，特别是创业这件事情，其实很早以前就有了萌芽。但我在清华读书的时候，大家还不习惯今天现代意义上讲的创业逻辑。那个时候大家想的还是“下海做生意”，同学们都在做各种各样的生意。</p>
  <p><strong>蒲凡：</strong>90年代？</p>
  <p><strong>张煜：</strong>对，90年代。包括我也是，我在1995年开始代理一款电子产品叫“文曲星”。大家今天可能已经不太熟悉这款产品，但是那个时候其实“文曲星电子词典”是非常流行，在同类产品中排名第一，远远超过好译通、快译通。</p>
  <p>我是文曲星的第一个高校代理，也是从那个时候开始接触到商业社会，发现商业社会和我们大学象牙塔，其实遵循着两个完全不一样的逻辑。我也在这个过程中，发现自己在这商业方面有一定的灵感和天赋，因为那个时候我的业绩非常好，光是在高校里面做代理，能够在所有大省代理中排名前5，赚到了一小桶金。</p>
  <p>到<strong>1998年，清华举办了中国历史上的第一次的创业大赛。</strong>那届创业大赛，我们邀请了很多在硅谷打拼的老学长们回来参加，比如张朝阳。但那个时候，同学们还不知道什么叫Startup，什么叫entrepreneurship，我们都搞不清楚这两个单词是什么含义。而我作为学生会的学生干部和校报记者得到了参与机会，主要负责相关的一些宣传工作，我那个时候也是校报的记者。</p>
  <p>现在来看，清华创业大赛也确实成为了很多明星项目的起点，例如有一届的创业大赛冠军叫“视美乐”，是一家做投影的企业。还有百合网。也包括某个头部互联网公司的创始人——在我印象里，那时候他也在创业大赛的团队里负责宣传工作。<strong>所以后来大家有人调侃说，他的企业之所以地推能力很强，都是那个时候创业大赛带着同学们刷海报刷出来的</strong>。</p>
  <p>清华（在创投氛围）其实挺好的。如果说北大总是能在思想意识走在社会前沿，那么清华往往能够在产业创新方面走在前沿，这是两个学校非常鲜明的特征。而创业大赛也成为了很多人创业的启蒙。我记得那段时间央媒、中央人民广播电台、各级电视媒体都进行了持续报道，给整个中国社会带来了巨大的触动。“创业文化”也从那时候开始迅速在中国大地各个高校、各个社会层面上迸发出巨大的活力。</p>
  <h2><strong>华清嘉园的“价值”，不仅仅是“离清华近”</strong></h2>
  <p><strong>蒲凡：</strong>所以您的创业情怀，包括您的孵化情怀就是从这一段经历来的？</p>
  <p><strong>张煜：</strong>是的。我通过做代理，发现外部的世界与校园世界拥有巨大的差异，这让我产生了很大的一个好奇心。<strong>我也因为参与了创业大赛，发现未来的世界竟然如此令人期待，是一个新的世界</strong>。而且我们那个时候还处在包分配和自由择业的一个转折的时期。绝大多数学生毕业以后，从哪来，就要回哪去，都是固定的，所以我们对未来没有太多畅想。</p>
  <p><strong>是创业给了我们一个新的种子，告诉我们可以选择自己的人生，去开创自己的人生</strong>，看到了硅谷创新火花。那个时候，比尔·盖茨成为了我们的英雄。韦尔奇让大象跳舞，这个被我们当做教材的故事，没想到已经离我这么近，我们也可以参与到其中。这些都给当时的年轻人带来了巨大的触动。</p>
  <p><strong>蒲凡：</strong>我忽然特别理解“华清嘉园”，这个五道口附近的居民小区，为什么拥有如此重要的地位。</p>
  <p>我之前一直在想为什么只有清华和华清嘉园形成了这样一组原始的“高校创业载体”的关系，很难在其他高校附近找到一所类似的居民小区进行类比。您的经历告诉我，它的出现是一个必然的结果，是一次文化带动。第一批感受到创投魅力的年轻人，显然会非常渴望延续这样的氛围。</p>
  <p>换句话说，<strong>华清嘉园相当于一个小型的、原始的、自由选择的、粗放式的孵化器</strong>。</p>
  <p><strong>张煜：</strong>是的，这也是五道口后来被称为“宇宙中心”的原因。</p>
  <p><strong>蒲凡：</strong>您当年逛过华清嘉园吗？</p>
  <p><strong>张煜：</strong>我逛过，很破。华清嘉园刚刚盖好的时候，北京四环刚刚修好了，五环才开始建设，清华的位置还相对偏僻，大概是这样的一个时期，几千块钱一平都卖不出去，很多人买了之后也很后悔，只能把它租出去。可以说，那时候的配套环境很差，远不如今天这么完善，到处都是流动的小摊小贩。</p>
  <p><strong>蒲凡：</strong>所以您有考虑过当时在华清嘉园创业吗？</p>
  <p><strong>张煜：</strong>那时候我还没想好要不要创业，只是觉得自己愿意去推动这件事，愿意参与到其中。</p>
  <h2><strong>微软遍及全球的创新加速器，起点在中国</strong></h2>
  <p><strong>蒲凡</strong>：咱们把话题收回来，您在微软推动加速器成立，当时是什么样的情景，让您觉得有必要推动这样的一件事情？</p>
  <p><strong>张煜：</strong>我在微软待了15年，几乎所有的岗位都做过一遍，其中最开始的工作叫UR，也就是University Relations，高校关系部。“高校关系部”在英文的职位通常会被翻译成evangelist，直译过来是“<strong>布道者</strong>”，类似于教会当中的神父。那个时候，国内刚刚出现“创业创新”的萌芽，而微软是最早把一批把这些创业创新萌芽交付实践的企业。并且微软还尝试激活高校领域里的创新，引导大家看世界，我觉得非常了不起。</p>
  <p>具体到工作中，那个时候我们和很多高校进行合作，建立了很多高校俱乐部，推动同学们在技术上进行创新。例如在应用软件层面，如何去开发更好的应用。或者在创业层面，怎么样去管理公司，怎么样去开发市场，包括创业者自己如何进行时间管理、项目管理、团队管理。这一套在微软，其实有一个成体系的培训方案，最繁荣的时候我们一共在各大高校建立了30多家俱乐部。</p>
  <p>那段时期，微软也搞了一个大赛，叫Imagine Cup，<strong>微软全球创新杯</strong>。我们会从中国各个高校里面去挑选一些团队去参加微软的全球大赛，我负责带队参赛。在这个过程里，我看到了很多不错的创新项目。比如有一个特别有名的浏览器，海豚浏览器。</p>
  <p>海豚浏览器曾经是安卓平台上的三大浏览器之一，它的研发就是来自华中科技大学的一支团队，是我带去参加Imagine Cup最终成功获奖的团队。也就是说，当时已经有很多的创新在高校里孕育了。于是微软总部就鼓励我们继续做下去，最好能够向产业方面去发展，而不是仅仅搞一些学生的活动。我们就开始思考，是不是需要成立一只创投基金、成立一个真正的加速器。</p>
  <p>再加上那时候IDG在中国的创投已经做得很好了，我在我和张亚勤院长（微软亚洲研究院）商量、得到他的全力支持后，就用总部的品牌，推动成立了“微软创新加速器”。</p>
  <p>当然加速器成立之后，我就调到微软中国去做业务了。加速器方面的工作，交给了我们微软工程院当时商务经理高欣欣继续做。她非常有创新精神，也是一个国际化、全能型的人才，很快就把这个加速器撑了起来，也让总部看到我们中国区做的加速器涌现了很多创新，对微软自身研发体系起到了很好的反馈作用。后来微软总部也因此决定将这种加速器模式，扩展到其它的国家——<strong>也就是说，微软在全球有六个加速器，但是第一个加速器是从微软中国开始的。</strong></p>
  <p><strong>蒲凡：</strong>听起来就是一个一脉相承的故事。没有清华的创业氛围，你不会对高校创新有这样的热情，也不太会有机会在微软高校关系部扮演一个布道者的角色。不过我很好奇，现在您在清智做孵化器，也延续了微软当年的思路吗？</p>
  <p><strong>张煜：</strong>是的，我们院叫清华大学智能产业研究院。这个院有几个特点，第一，我们是一个“创新院”，希望能够面向产业去推动产研融合和创新，而不是一个纯粹的理论研究、科研型的单位；第二，我们里面大多数招聘的员工都来自产业界，大概超过80%是来自产业界，寻求在产业界当中做创新。</p>
  <p>这80%里，有超过一半的人是从微软系来的。有的原来在微软工作过，有的在微软做过实习，有的是微软学者。所以从我们的经历来看，<strong>微软号称“AI界的黄埔军校”确实也是实至名归</strong>。</p>
  <p>当然其中也有一大部分也是清华系的，只不过清华系与微软系又有很多交集。比如说唐杰老师，他既是原来微软的学者，也是清华大学的老师。这样的例子比比皆是。所以也有人管我们清华大学智能产业研究院叫MSRA2.0——MSRA就是微软亚洲研究院——以前的MSRA是只为微软服务，现在是2.0，为整个社会服务。</p>
  <h2><strong>可对于现在的创业者来说，“孵化器”还有价值吗？</strong></h2>
  <p><strong>蒲凡：</strong>咱们都说创业路径其实有两条，高校创业里尤其明显。一种是学生直接出去创业，拉团队、做产品、对接风险投资，然后成为一个企业家。另一种就是像您现在正在做的事业一样，深入到学校的产投研的条线中，先进入学校的孵化器，通过这个孵化器慢慢成长起来。</p>
  <p>您认为哪一种方式现在更适合现在的创业者？</p>
  <p>另外我之前也做过很多关于创业孵化的内容，其中有一条对于加速器模式的指责让我印象深刻。评论者说，孵化器这种模式替创业者解决了很多烦心事情，比如提供了共享运营能力、共享财务能力，在精力分配上允许他只聚焦在业务层面，<strong>但是也推迟了创业者独自面对市场风险的时间</strong>，导致当他进入企业家角色的时候，往往会出现能力不健全的状况。</p>
  <p><strong>张煜：</strong>同意。</p>
  <p><strong>蒲凡：</strong>所以您是怎么看这个批评的？再结合前面的问题，您觉得对于当代高校创业来说，是加速器更合适，还是我自己出去创业更合适呢？</p>
  <p><strong>张煜：</strong>应该说两者都有道理，需要从几个方面来讲。</p>
  <p>第一，我觉得最牛的创业者和团队不需要加速器或者孵化器，出来之后他就是牛，自己就能干起来。而且这些创业者往往还有感染别人的能力，能够充分地调动周围的资源来服务自己，不必非得寻找一个加速器去弥补自己的一些不足。</p>
  <p>只是这样的创业者少之又少，这个社会还是靠大多数中坚阶层的企业来推动。那么对于大多数创业者来讲，在起步阶段有很多事情，是自己过去经验所没有经历过的，那么孵化器和加速器就很好去弥补这一块，缩短创业起步的过程，也是很好的方案。</p>
  <p>第二，从发展阶段来讲，过去大多数加速器和孵化器，更多是提供一些空间服务，降低创业成本、提供一些财税服务。这些很辅助的功能，在过去一个阶段大家会觉得可有可无，因为它不是创业孵化的核心，起不到比较重要的作用。</p>
  <p>但现在不一样，因为目前创业比较集中的领域，尤其是我们目前所在的人工智能领域，它需要的要素很多也很复杂，要求创业者必须要成为一个全能型的六边形战士，面临的情况比以前要复杂得多。在这种情况下，财税、空间这些同属于创业者素质的部分，变得更烦心更微不足道了，因此把这些事情都交给孵化器，我觉得也是有道理。</p>
  <p>不过我们清智孵化器给自己的定义是“<strong>人工智能领域的产业孵化器</strong>”，财税辅助和空间不是我们所强调。我们更多强调是对他们产业赋能和科研上的互补性，解决他们在行业上的一些痛点。比如算力，我们的孵化器免费提供算力。提供类似的人工智能领域比较关键的要素支持，我觉得这更符合我心中一个真正孵化器的概念。</p>
  <p><strong>蒲凡：</strong>您这个回答提前说出了我想追问的问题，您在孵化中的角色是不是已经变了？以前可能是一个导师、老师、领队，现在更像是一个产业投资人，帮他们弥合产业链里面？</p>
  <p><strong>张煜</strong>：对，这是工作中很大的一部分。</p>
  <p><strong>蒲凡：</strong>您觉得这个工作是更复杂了还是更简单了一些？因为从产业出发其实更能发挥你的价值，虽然更累，但是我觉得爽感会多一些。</p>
  <p><strong>张煜：</strong>对，而且我们希望创业者自己的素质一定要足够强，孵化器的入驻和基金的投资，都需要评审和尽调，要求都很高。这些要求除了一些传统的标准外，我们还明确地将“<strong>资源组织能力</strong>”放到我们的尽调评审中去。<strong>因为今天的创业，特别是人工智能领域的创业，并不是光拍拍脑袋靠一个创意、一个很好的应用或者是一个很好的算法框架就可以做好的</strong>。</p>
  <p>当我们发明了一个很好的算法，想验证它、想优化它；当我们开发了一套生成式模型，要调优，做很多结构升级和优化的工作，这时候就对数据有大量的需求。那你怎么能获得优质的数据呢？比方做智慧交通要对接交通部门，比如做医疗数据对接医院，作为一个小的创业公司，这些资源方别人为什么要和你合作呢？这都不是钱能解决的问题，需要你的情商、智商、组织能力、领导能力、沟通能力、情绪控制能力。</p>
  <p>所以我刚才提到了“六边形战士”，其实仅仅“六个边”还不够。</p>
  <h2><strong>优秀的人工智能团队，从哪里来？</strong></h2>
  <p><strong>蒲凡：</strong>这好像再次印证我们之前很多人的观点，Open AI的出现它不是一个巨大的科研胜利，而是一个巨大的工程胜利。</p>
  <p><strong>张煜：</strong>是的，它是一个工程能力的体现。</p>
  <p><strong>蒲凡：</strong>那这些符合您要求的项目从哪里来？</p>
  <p><strong>张煜：</strong>大概有这样几部分。一部分是我们团队自己sourcing。既然做一个孵化器，还是人工智能领域的孵化器，那你就要去跟各个高校、科研单位去沟通、去了解。</p>
  <p>并且我们本身也是一个平台，有很多的博士生、博士后、年轻的教授、研究员，他们做各种各样的研究，我们跟他们关系很好，交流过程中会出现很多创新的火花，也是我们项目很重要的来源。我们邀请他们到我们的孵化器来，我们懂产业，他们懂科研，看看能不能结合一块把变成一个实际的项目落地，孵化出来之后未来我们还有投资，就变成一个真正实际的项目。</p>
  <p>第二，因为我们团队有很多成员是从微软系出来的，所以微软系肯定是特别庞大的一个的来源。我们有一个组织叫微软院友会，简称“<strong>希玛会</strong>”，因为这个组织是在知春路的希格玛大厦成立。“希玛会”有很多特别牛的人，每年这里面有大量创新的项目诞生。</p>
  <p>我们的基金清智资本，也会称自己是微软系的family fund，微软系创业我们都愿意优先去支持。当然这也是因为微软系创业本身它的质量非常好。</p>
  <p>第三就是清华系，清华的理工科创业创新已经形成了一个传统，每年的挑战杯、每年的三创大赛，到现在仍然有不错的影响力。近几年生成式AI、大模型的发展，清华之所以能占到很重要的地位，也是多年积累的一个结果。</p>
  <p>另外因为我们在业界做了很多工作，也有一些创业创新的团队看到我们的能力，主动找到我们这边来的也越来越多。基本上是在这几个方面。</p>
  <h2><strong>做投资人，比在华为工作还要忙</strong></h2>
  <p><strong>蒲凡：</strong>刚才听下来这一套逻辑都特别顺，那么迄今为止，在你的工作中有没有什么难点？</p>
  <p><strong>张煜：</strong>讲困难的话就太多了。首先我们发展时间还是很短，第二由于我们发展的时间不长，也意味着经验还不足。</p>
  <p><strong>我从2000年左右参加工作，到现在已经20多年一直都很忙，大家也都知道在华为、微软这些业界顶级公司，都会很辛苦。但是我认为我最忙的阶段可能就是最近这两年</strong>。我大概从去年开始，到今年以来，没有休过任何一个完整的周末，每个周末都在工作当中，未来的一两个月的周末甚至都已经排满了，这是我从来没有遇到过的一些挑战。</p>
  <p>当然也是因为现在整体上有一定的压力，你需要兼顾的事情很多，本身自己的团队建设也需要提高，你只有到达一个高水平阶段才有能力去指导别人。</p>
  <p>其次现在社会发展很快，特别是人工智能领域发展得更快，你不仅需要通过学习提升自身能力，还需要跟上整个知识图谱的发展，同时还要应对市场竞争的有压力。这几个压力放在一块，就变成了很多现实问题需要面对。</p>
  <p>相对而言我们还有一些限制条件，比如无论是孵化器还是基金，我们资金都是社会化、市场化的，都是以商业的方式去运营。大家也知道五道口既然叫宇宙中心，那也是寸土寸金，我们的成本压力也是非常大的。</p>
  <p><strong>最重要的是你能不能找到最好的创业者？把他吸引进来之后，能不能很好地去支持他？</strong>对于创业者的赋能这方面其实压力也很大，因为每个创业团队它的需求都是不一样的。你想把它做好，就需要更深入地往前走一步，深入到产业领域，是扶上马还要送一程，而不是简单的联系，这件事情也是比较难的。</p>
  <p>另外我们成立的时间短，不管是创投还是做孵化，一个新品牌需要争取社会的认可，大家还是抱着怀疑的态度来审视你，这样也增加了很多沟通的压力。比如说我们认为YC是硅谷比较成功的孵化器案例，那我们将自己的目标锁定为“做成中国的YC”，这就会遇到有很多人质疑，说你们现在刚刚起步，你们能比得上YC吗？</p>
  <p>但是创新是觉得不会停止，我们要坚持在正确的方向上，坚定地往前走，<strong>因为困难永远都会存在，但机会也永远是存在的。</strong></p>
  <h2><strong>做孵化要避免自己成为co-founder</strong></h2>
  <p><strong>蒲凡：</strong>这里延伸出来好几个小问题，比如您提到了YC，您觉得YC的精神内核是什么？</p>
  <p><strong>张煜：</strong>我之前也拜访过YC，大概是在2015年左右。总体上来讲，YC给我的一个直观的印象有两点，第一是说希望做有创新性的产品和服务，然后第二要坚持做正确的事。</p>
  <p><strong>蒲凡：</strong>第二个问题是，您刚才提到外界对于您现在的产业形态有怀疑、有误解，那么您觉得到底是哪一个环节出了问题？</p>
  <p><strong>张煜：</strong>其实我也有一段孵化器里创业的经历，大概两三年时间，做的是一个消费推荐产品，通过人工智能去做消费推荐，确实不是那么愉快。因为我们认为孵化器应该是对于整个创业创新，对于团队成长是有推动作用，但是后来发现可能只是简单的财税相关的辅助和空间费用的减免，但远远没有达到我们的预期。</p>
  <p>所以我们一直强调，自己做的是人工智能领域的产业孵化器，一定是要做产业赋能，提供人工智能领域的一些基础要素，比如之前提到过的免费的算力，也提供人工智能领域的一些基础的知识支持，背靠智能产业研究院，拥有很多专家进行指导。</p>
  <p><strong>还有一点就是我们寻求在孵化器里形成生态</strong>，比方我们有一家公司是做自动驾驶数据服务的，我们就帮它对接了一些孵化器自己的企业做数据的一些服务，那么它们自己就形成了一个生态。还有一些做智能体的，我们有一些做行业模型和做智能体很好地自己结合起来，做一些创新性的产品。</p>
  <p>现在在我们的孵化器里有几十家的企业，包括我们投资的一些企业，它们正在自己形成了一个生态，我觉得这个是挺有趣的一件事。</p>
  <p><strong>蒲凡：</strong>第三个问题其实是连着，您有没有觉得您现在的角色是一个co-funder？入驻团队的co-funder？你觉得一个孵化器主理人或者产业方的投资人，需要偏向co-founder这个角色？</p>
  <p><strong>张煜：</strong>我们其实是尽量避免成为co-founder，而且我们自己也有一些经验教训。我们在起步那几年就发现，如果你过多把自己的观点和意识与创业团队结合，就会出现一些不太和谐的碰撞。</p>
  <p>最常见的情形有两种，一种情况是说人家创业团队本来是这样想的，你是那样想的，大家就不一致，最后导致双方不愉快，又很难说清谁对谁错，因为都是在发展当中确实谈不上对错问题。第二种情况是，你确实很有经验，他确实经验不足，他应该是听你的，然后他也觉得自己经验不足，就逐渐靠到你的身上，最后发现你不仅是co-founder，你还变成一个founder了。</p>
  <p><strong>蒲凡：</strong>变成leader。</p>
  <p><strong>张煜：</strong>对。毕竟我们不是为一个企业服务，我们应该是一个支持方，所以这样的话是的反而创业团队失去了自己独立的创新思维，失去自己独立的执行能力，我觉得这也不行。</p>
  <p>所以经过一些摸索，我们自我总结要避免成为co-funder，在你决策了之后提供一些支持、一些辅助，决策还是你自己要做，<strong>而且告诉你这有一个阶段，到了这个阶段你必须要出去面对市场</strong>，这也是我们一贯的理念。</p>
  <p><strong>蒲凡：</strong>您不觉得聊下来这才是最难的难点。如何与项目保持一个若即若离的距离，如何找到这个中间点，我觉得太难了。</p>
  <h2><strong>“清华系”这个标签，可以用来概括投资人吗？</strong></h2>
  <p><strong>蒲凡：</strong>您看刚才咱们对话的过程中，都默认“清华系”一般是指代清华出身的创业者，您介意别人说您是“清华系”的投资人吗？</p>
  <p><strong>张煜：</strong>对，创业者按学校分系由来已久的，清华系有清华系的特征，北大有北大的特征，人大有人大的特征，科大有科大的特征，斯坦福有斯坦福的特征。但是投资人“分系”，这个概念是近几年才产生，确实也是比较有意思的现象</p>
  <p>我觉得我不介意这样去形容自己，但不必要过度解读。实际上不管是哪个系的投资团队，其实它投的项目是广泛，不会只投自己这个系派的项目，因为投资人有LP，都是要投资回报，你肯定要找投资回报最高的，而不是从哪出来，这不是我们考量的要素。</p>
  <p>但是为什么还是有这个系呢？可能因为创业者分的系，最后导致行业的一体两面，投资人现在也有了这个标记或者烙印。</p>
  <p><strong>蒲凡：</strong>我也认同这种原因。包括您的经历也是，大量的投资人都曾经是一名企业家，所以带着这个标签完成转型，自然而然就形成了一个清华系。</p>
  <p><strong>张煜：</strong>是的。</p>
  <p><strong>蒲凡：</strong>不过刚才我们说的是教育背景出身上的系，有没有精神特质上的“系”？清华系的投资人他们集体的性格会有哪些跟其它学校，譬如说北大、科大、港大不太一样的地方呢？</p>
  <p><strong>张煜：</strong>我也没有了解其它学校出来的投资人到底是什么样的一个风格，但从我自身的投资角度来讲，可能清华系的投资人总体上的特质就是理性、踏实、讲逻辑。</p>
  <p>我们其实是比较符合“清华系”的投资的逻辑和标准。更早一些溯源的话，我觉得北极光邓锋师兄应该是一个比较好的例子。“清华系”投资人具体有什么样的特质，第一是“<strong>亲力亲为</strong>”，就像你问我为什么还要看看装修方案什么的。“清华系”习惯一切都要看到事实然后才去做判断，更多愿意去亲力亲为而不是道听途说。</p>
  <p>但是这一点也有缺陷，比如可能会错过创意创新项目，就像“头条”这样的项目。从逻辑上来讲不会投，那如果让我投也许我也不会投，这确实也是有遗憾的地方。</p>
  <p>第二是比较“<strong>长线</strong>”。我们的基金就是长线基金，8+2，一共10年。我们愿意以一个更长远、更趋势的方式去看待投资创业的过程，而不是一个短期的获利。</p>
  <p>第三特别看中人的<strong>落地能力、执行能力。</strong>创业因为有很多种方式，比方说罗永浩创业也是一种执行能力的体现。但研发出芯片来、研究出一个算法框架来，研究出一个具体的产品和服务，是符合我们的标的。那种从思想意识形态方面建立的一些产品和服务，未必很符合我们的要求。当然这也是一个缺陷。</p>
  <p><strong>蒲凡：</strong>我想起一本书里的一句话，这本书叫《创新中的资本主义》。它说“在理想的状况下，所谓的前沿创新的基金，它的领导者应该是一名逆向的投资人”。所以您刚才描述的清华系投资人的精神特质，似乎很呼应这句话，这三个关键词背后似乎隐含了两个关键词，一个是冷静，一个是克制。</p>
  <h2><strong>“清华系”+“投资人”，注定背负太多外界期待</strong></h2>
  <p><strong>蒲凡：</strong>但是这里又引发出一个新的问题。</p>
  <p>一旦提到清华，在大多数人的印象里就会很快联想到“天之骄子”，全国最好的高校，默认我们把很多的教育资源、社会资源倾向于它，所以又自然而然对它的期待是高于所有其它同类学校的。所以当我用“清华系”这一个title去形容您、形容邓锋、形容英诺的时候，其实我对他们饱有期待的，期待他们应该和市场上其它的“妖艳货色”画风不同。</p>
  <p>第二，“投资人”也是一个备受期待的标签。跟欧美那种成熟的资本市场观念完全不同的是，在欧美大家会“投资人”，认为这就是一份职业，默认他的工作就是做金融游戏、玩虚拟经济。但是我们不一样，我们大部分老百姓的观点认为，投资人代表着你是高知、占有信息差，并且更靠近舞台中央的一群人，你需要背负更多的社会责任。</p>
  <p>包括很多投资人群体其实也接受这个观点。我以前采访过一位资深的消费投资人，他曾经向我强调，他要求每一位员工都必须意识到自己正在进行的是一个社会经济工作，所以你做出来的每一个决策都要背负到社会责任</p>
  <p>这些观点的存在，代表了大部分人的社会预期。于是“清华系”和“投资人”，这两个title加起来，更是无形的压力和社会预期的累加。我不知道您怎么处理这种压力？</p>
  <p><strong>张煜</strong>：所以刚才咱们俩的对话过程当中，我也是小心翼翼。你一说“清华系”，搞得我压力很大。</p>
  <p>说实话，我的清华系标签还是比较重，我觉得我是一个比较标准的清华学生。但另一方面，<strong>其实我在微软又做了很长时间的销售，当了四五年的top sales，还因为销售得好，用了很多创新的方法进行销售，拿了比尔·盖茨奖。</strong></p>
  <p><strong>蒲凡：</strong>这个故事很传奇，一个工科男进微软然后做销售还拿了销冠。</p>
  <p><strong>张煜：</strong>而且在我的推动下，通过我们本地销售的配合，拿下应该说是微软中国历史上最大、超10亿的订单。所以也不是说完全冷静理性，我们还是有很多销售需要的社交能力，有你对于市场的战略判断，有你对于整个国家政策的认知的理解。当然今天我们不讲销售的故事，那也是非常传奇的故事，很有趣。</p>
  <p><strong>蒲凡：</strong>我今天在这里预约下一次对谈了，销售的故事。</p>
  <p><strong>张煜：</strong>对，也包括我在大学里面卖文曲星的经历也同样。我发现，人就是有自己的基本出发点，但是如果你想改变一点自己的人生，希望有更高的一个目标，想跨越一步跳出自己的舒适圈，首先要有思维的转变。<strong>所以今天取得了一些成绩的人，在我看来大多数其实都思维分裂一些。</strong></p>
  <p>所以对于刚才的问题，社会对清华有一个定调，你作为清华人，又自然地背负上了清华的光环以及清华本身社会对它定位的约束，这个我觉得是正常的。只是相对来讲大家要更宽容一些，哪个学校都有自己的优秀毕业生，哪个学校也都会有失败者。我们更多是从结果上，会看到某个群体整体出来的成绩多一些，我们认可的是学校的一套培养体系是优秀的，值得学习。</p>
  <p>当然从我自己的角度来讲，“清华系”也有一些限制。再先进的思维也要包容并蓄，还是要吸收各方面的优点。<strong>所以我们的孵化器和创投有一个不太成文的规则，就是我们的孵化和投资的项目，清华系比例尽量不要超过一半</strong>。</p>
  <p>能不能都投清华系呢？肯定可以投，本来投资清华系的成功比例高，但这是一种偷懒的做法，而且对于长期的创投发展和创业发展肯定都没有好处，我们更希望找社会上的一些优秀项目，这个可能会更难，但是也必须这样做，这样的话才能促进整个社会的生态创新。特别是对我们资本和孵化器来讲，本来就应该是一个相互交流、碰撞的平台，在太固化的一个体系当中，不管这个体系有多先进、多优秀肯定都有自己的局限性。</p>
  <h2><strong>“危机感”或许才是“清华系”真正的底色？</strong></h2>
  <p><strong>蒲凡：</strong>听起来感觉你们危机感很重？</p>
  <p><strong>张煜：</strong>对，我们天天生活在危机当中。</p>
  <p><strong>蒲凡：</strong>甚至有一点，用现在年轻人比较流行的话来说叫……</p>
  <p><strong>张煜：</strong>自虐。</p>
  <p><strong>蒲凡：</strong>没苦硬吃。</p>
  <p><strong>张煜：</strong>对的，没苦硬吃。关于未来的发展，我们经常跟同事们一块讨论，我的一个观点是世界已经向两极化发展，你要么成功，要么就……</p>
  <p><strong>蒲凡：</strong>一事无成？</p>
  <p><strong>张煜：</strong>不是一事无成，是要么就不存在生存的理由。换句话说，你想生存下来你就必须是成功的，要么的话就生存不下来。</p>
  <p><strong>蒲凡：</strong>你这个比我的“一事无成”还极端一些。</p>
  <p><strong>张煜：</strong>确实极端，但实际上就是这样的。我们的孵化器不是体量最大的，我们不是受资金支持最多的，也不是政府关注的，你就是市场当中的沧海一粟。创投也是一样，我们也不是历史最悠久，也不是背景最强，也不是基因最好的，也不是资金最多，那你凭什么能够占据一定的地位还能够生存下来？为什么行业里要有你的地位？就是你必须要做到最好，你做不到最好就生存不下来。</p>
  <p><strong>蒲凡：</strong>这是刚才您总结清华精神特质没有提到的一点，这个“危机感”是您的个人气质还是可以归纳到清华系投资人整体气质？</p>
  <p><strong>张煜：</strong>我认为这个应该是清华和“华为系”的气质。</p>
  <p><strong>蒲凡：</strong>又多了一个“华为系”。</p>
  <p><strong>张煜：</strong>对，虽然我只在华为工作了一年，但是它给我带来的烙印应该说是一生的。在华为一定要做到极致，一定要做到最好。不能只追求行业的前三名，一定要做到第一——华为有几个特质这里稍微提一下，第一就是做最好，第二是要坚持做好，第三就是团队高于一切，团队的成功高于一切。所以华为可能没有特别牛的科学家，但是华为的产品都是业界最优秀。</p>
  <p><strong>蒲凡：</strong>这么说的话，微软反而是在你整个投资性格成型过程中，起到一个柔化的作用。</p>
  <p><strong>张煜：</strong>也不是，大多数人没有同时在华为和微软工作的经历，潜意识里会认为华为里是一个最严苛，纪律最严格的一个公司，而微软代表硅谷文化，牛仔裤文化、车库文化，貌似是一个世界上最宽松、最自由的、最开放的这样的公司。</p>
  <p>但是我认为，它们两个公司外表是迥然不同，但是精神内核是高度一致的。我从华为到微软，后来在微软的时候我又跟华为合作，我觉得非常顺畅，就两个公司思想理念是完全一致的，高度一致。</p>
  <p><strong>蒲凡：</strong>所以另一位互联网头部企业的创始人，为什么在微软晃了一年就走了，他身上也没有那么浓重的微软气质。我记得在一些采访中，他表示自己是去微软学习，学习一些工程管理、项目管理能力。因为他当时刚从酷讯到房讯网，几段创业经历不是特别成功，他觉得可能需要某种能力，于是他去了微软，但是似乎没有找到自己想要的东西。</p>
  <p><strong>张煜：</strong>对，我觉得他可能有失有得、微软肯定是牛人特别多，在微软跟在清华的体感可能会有点类似，就感觉周围全是大牛，都是既比我聪明又比我勤奋的一群人，自己好像每天都处在绝望当中。</p>
  <p>我在清华上学的时候每天都处在绝望当中，你再怎么努力都总有一些牛人，他牛得一塌糊涂，真的是智商超常，你完全不懂的一些逻辑理论、四大力学什么的，他看一遍就懂了。这些人真的很让自己绝望。微软也是这样的，一帮世界上最聪明的人在一起，也是一件压力很大的事。</p>
  <p>但从他自己的访谈里面，可以看到他首先在微软待得少，待得少就不受微软的限制——<strong>“微软的限制”就是每个人都想像微软一样做出改变世界的产品来，有几亿人在用</strong>——这个目标过于宏大，所以导致很多微软系的员工出来创业，过于把自己的目标定得理想化和过高了，反而就不容易成功。</p>
  <p>当然现在的大模型来了，因为微软号称“AI的黄埔军校”AI的能力就是很强，基础也很强，所以这边创业的人成功比例也很高。我在想，他未来也可能受到微软理念，至少是微软AI和技术理念的一些影响，进而成为未来影响他发展的一个重要要素。</p>
  <p>但总体而言，<strong>他在微软待过，但待得时间短，可能是他成功很重要的一个因素</strong>。</p>
  <p><strong>蒲凡：</strong>所以特别适合董师傅经常念叨的一句话来收尾，这句话是黑格尔说的，“未来不是知识的对象，未来是希望和恐惧的对象。”</p>
  <p>您刚才说的一系列故事，很能诠释这句话。您现在一切的一切，都不是某个理性推导出来的结果，而是里面包含很强烈的情绪冲动。而您正是在这个情绪冲动下，逐渐慢慢规划出了自己的1、2、3、4。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI4MjYxMTYyNA==&amp;mid=2247512471&amp;idx=1&amp;sn=5f829f167d6d5769cefa48b275fb4501&amp;chksm=ea0b9dc135a38a7b66eaf2618e388555f8816cc28e52c16877001264163ce4e87e44c917341f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“东四十条资本”（ID：DsstCapital）</a>，作者：蒲凡，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033056733736969</id>
            <title>o1不是唯一路径，MIT新研究：在测试时训练，模型推理能力最高升至5.8倍</title>
            <link>https://www.36kr.com/p/3033056733736969</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033056733736969</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 09:36:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型推理, 测试时训练, 准确率提升, 数据增强  
<br><br>  
总结: MIT的新研究表明，测试时对大模型进行训练（TTT）可以显著提升推理能力，尤其在ARC任务中，准确率最高可提升至原来的5.83倍。TTT方法不同于传统的训练模式，它在部署阶段通过快速训练调整模型参数，以适应新的测试样本。研究显示，使用TTT后，GPT-3模型在ARC数据集上的准确率从18.3%提升至47.1%。此外，TTT与BARC方法结合后，取得了61.9%的SOTA成绩，超越了人类的平均水平。该研究展示了TTT在提升大模型推理能力方面的潜力。 </div>
                        <hr>
                    
                    <p>o1不是通向大模型推理的唯一路径！</p>
  <p>MIT的新研究发现，<strong>在测试时对大模型进行训练</strong>，可以让推理水平大幅提升。</p>
  <p>在挑战超难的ARC任务时，准确率最高可提升至原来的5.83倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_413f12cf128f4713b1b368208e7f0e9a@46958_oswg27412oswg380oswg266_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这样的表现不仅优于GPT-4和Claude，如果与其他推理方法相结合，还能超越人类的平均水准。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_1854723db74d4e748b8c93d748ed52cb@46958_oswg8801oswg724oswg434_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>OpenAI o1团队成员<strong>Noam Brown</strong>表示，o1的大规模计算可能不是最好的方法，很高兴看到有学者在提高推理能力上探索新的方法。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e984de2fe94f42c39ead553bc90f485d@46958_oswg135980oswg1080oswg308_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>在测试中训练模型</strong></h2>
  <p>不同于传统的先训练后测试模式，测试时训练（Test-Time Training，TTT）在部署阶段面对新的测试样本时，<strong>不直接用训练好的模型去推理</strong>。</p>
  <p>在推理之前，<strong>测试样本自身携带的信息</strong>，会通过快速的训练过程被用于调整模型参数。</p>
  <p>总体来说，TTT过程中一共有三个关键阶段——<strong>训练数据生成、模型适应范式设计以及推理阶段的策略</strong>。</p>
  <p><strong>数据生成</strong>的核心是将测试任务中蕴含的输入输出对关系，通过数据增强的方式最大限度地利用，可具体分为两个步骤。</p>
  <p>首先是基于leave-one-out构造新的任务。</p>
  <p>对于包含K个输入输出对的测试任务，依次将每个样本留出作为测试样本，其余K-1个作为训练样本,由此构造出K个新的TTT训练任务。</p>
  <p>这样就可以从一个测试任务出发，构造出K个结构一致但内容互补的新任务，从而扩充了TTT训练数据。</p>
  <p>在此基础上，作者还进行了数据增强，主要包括对输入输出施加各类几何变换，以及打乱训练样本对的顺序。</p>
  <p>经过这一步，TTT训练集的规模可以得到显著扩大。</p>
  <p>整个TTT数据构造过程可高度自动化，不依赖人工标注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_8a6f67da96b14b938095c7fa457bde10@46958_oswg114922oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>利用构造好的TTT数据集，就可以对预训练好的语言模型进行测试时训练。</p>
  <p>考虑到测试时的资源限制，作者采用了参数高效的LoRA，为每个测试任务学习一组独立的adapter参数，附加在预训练模型的每一层之上，通过一个低秩矩阵与原始权重相乘起到调节作用。</p>
  <p>过程中还额外加入了对所有前缀序列的预测，目的是通过在各种长度的演示样本上都计算损失，鼓励模型尽早地从少量信息中总结出抽象规律，从而提高鲁棒性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c3825ed3a2b24e0d91e74338dd82d34a@46958_oswg25670oswg1004oswg194_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>最后，为了实现TTT效果的最大化，作者在推理阶段应用了数据增强和集成学习策略。</p>
  <p>推理过程中，先利用一系列预定义的几何变换算子（如旋转、翻转等）扩充原始输入，生成若干等价视角下的输入变体。</p>
  <p>之后将每个变体输入并行地送入LoRA-tuned模型，独立完成预测，然后再对齐和还原到原始输入空间，由此得到一组成对的预测。</p>
  <p>在成对预测的基础上，通过分两层投票的方式完成集成融合：</p>
  <p>第一层在每种变换内部进行投票，选出置信度最高的Top-3个预测;</p>
  <p>第二层在不同变换的Top-3预测之间进行全局投票，选出最终的Top-2作为输出。</p>
  <p>这一推理策略，既通过数据增强引入了输入的多样性，又用分层投票的方式对不同来源的预测进行了结构化的组合，进一步提升了TTT方法的效果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_fce66fa6073f42d79fc5ba844ed491be@46958_oswg76283oswg1060oswg492_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>ARC任务准确率最高升至6倍</strong></h2>
  <p>为了评估TTT方法的效果，研究团队以8B参数的GPT-3作为基础模型进行了测试。</p>
  <p>如果不使用TTT仅进行微调，模型在ARC数据集上的准确率只有18.3%，加入TTT后提升到47.1%，增长率达到了157%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_271f915767a541f49a10cd00680a4f3d@46958_oswg70251oswg1080oswg144_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>另外，作者还从ARC数据集中随机选择了80个任务作为子集进行了测试。</p>
  <p>测试发现，TTT方法对于1B模型的提升效果更加明显，调整后模型的准确率接近调整前的6倍。</p>
  <p>并且在调整前后，1B和8B两个规模的模型之间的相对差距也在缩小。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_73ff4b8edc584ec6891104b61e75ebad@46958_oswg35611oswg512oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>进一步地，作者还将TTT方法与之前在ARC任务上取得优异成绩的<strong>BARC</strong>（Bootstrapping Approach for Reward model Construction）方法进行了比较和结合。</p>
  <p>具体来说，作者首先独立运行这两个系统，得到它们在每个测试任务上的输出。</p>
  <p>如果两者输出完全一致，则直接认为推理结果是正确的；</p>
  <p>如果输出不一致，则看BARC是否能够生成确定的、唯一覆盖所有测试样本的解题程序，若是则认为BARC的输出更可靠；</p>
  <p>反之，如果BARC生成了多个候选程序但无法确定最优解，或者干脆无法生成任何满足约束的程序，则认为TTT的输出更可靠。</p>
  <p>两种方式配合使用后，取得了61.9%的SOTA成绩，已经<strong>超过了人类的平均水平</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_711be494f37c401581cb3375700260f7@46958_oswg30686oswg934oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>One More Thing</strong></h2>
  <p>根据作者在推文中的介绍，在这篇论文发布前，一个叫做MindsAI的团队已经发现使用了相同的技术。</p>
  <p>利用TTT技术，该团队已经用58%的正确率取得了ARC挑战的第一名。</p>
  <p>作者的论文发布之后，MindsAI团队领导者Jack Cole也发文进行了祝贺：</p>
  <blockquote>
   <p>很高兴，我们掀起了这场对TTT的兴趣风暴。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_4b314c194cec40fb9667bad52ebe9d66@46958_oswg71686oswg1080oswg359_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>同时，Jack还推荐了另一名研究TTT的学者——斯坦福大学华人博士后<strong>Yu Sun</strong>，表示他的研究值得被关注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_3ff4e7e1486c4590a900d8f6789c6d03@46958_oswg235853oswg1080oswg649_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Sun的个人主页显示，他针对测试时训练进行了大量研究，相关成果入选过ICML、NeurIPS、ICLR等多个顶级会议。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_dabf15d87fa441aa8c7b49fa7e434efd@46958_oswg156905oswg1080oswg517_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文地址：https://ekinakyurek.github.io/papers/ttt.pdf</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/sRv-BswlDOn-CFtR-rRqDQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：克雷西&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033174848057607</id>
            <title>是时候重新认识To B圈的「双11」了</title>
            <link>https://www.36kr.com/p/3033174848057607</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033174848057607</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 09:31:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <阿里云, 双11, 中小企业, 云计算>
<br>
<br>
总结: 阿里云在2023年双11期间实现了显著的销售增长，尤其是在中小企业市场。此次活动不仅是传统的消费购物节，更是针对B端市场的云计算推广。阿里云通过降低产品价格和提供技术支持，帮助中小企业更好地进行数字化转型。随着云计算技术的普及，越来越多的中小企业开始优化IT采购流程，借助双11的优惠政策实现成本控制。阿里云的合作伙伴在这一过程中发挥了重要作用，推动了区域市场的数字化发展。整体来看，双11已成为云计算行业的重要里程碑，促进了技术的普惠化和市场的多元化。 </div>
                        <hr>
                    
                    <p>11月11日，时针指向23点59分，杭州阿里巴巴云谷园区灯火通明。阿里云双11“作战指挥室”数据监控大屏上，销售额以秒级频率滚动刷新着。</p>
  <p>截至11月11日24时，阿里云分销合作伙伴“双11”销售额同比2023年“双11”实现两位数增长。11月前11天，AI大模型产品新用户数比10月增长了135%；无影云电脑的销售额，更是惊人地达到了2025财年前7个月（自然年2024年4月~10月）总和的3倍之多。</p>
  <p>监控大屏密密麻麻的指标里，有一条尤为引人注目：阿里云分销合作伙伴“双11”超过一半的销售额，来自除北京、上海、广州、深圳、杭州之外的广袤市场。</p>
  <p>这场“双11”，并不是消费者们熟悉的to C 购物大促，而是一场由阿里云牵起的，独属于to B 行业的“双11”云计算嘉年华。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_264238499d9147e6b04bd1f59d4963fb@11416942_oswg104912oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：阿里云和合作伙伴在杭州云谷的双11“作战室”里</p>
  <h2><strong>01. To B圈也有自己的“双11”</strong></h2>
  <p>很少有人意识到，“双11”这个节日，与阿里云几乎诞生于同一时间。</p>
  <p>2009年，淘宝商城首次举办“双11”网络促销活动，自此掀起了一场影响全民线上购物习惯的网络嘉年华。同样在2009年，国内第一朵“云”阿里云成立，成为此后十五年间中国云计算产业腾飞的起点。</p>
  <p><strong>阿里云从成立第一天起，就坚定服务中小企业。</strong>彼时愿意拥抱云计算的，大多数是互联网创业者，他们业务规模还不大，对于数字化投入有限，迫切需要便捷高效的数字化能力，以匹配业务的快速扩张。阿里云的信念，正是渴望通过云计算产品，让中小企业、互联网创业者与大企业站在同一起跑线上，开拓属于他们的业务版图。</p>
  <p>而阿里云在To B圈开启“双11”的历程，最早可以追溯到9年前。</p>
  <p>2015年，阿里云联合合作伙伴，将多款云计算产品投入“双11”大促，致力于让彼时还是“贵族消费”的云计算技术快速普惠，成为“多快好省”的公共科技服务。</p>
  <p>此后9年间，云计算技术高速发展、前沿技术日新月异，阿里云与12000家合作伙伴也持续在to B市场通过让利等方式，推动云计算服务普惠化。</p>
  <p>今年“双11”，阿里云将多款产品降到了全网全年低价，还为每位新用户提供“开通‘百炼’服务，即免费赠送超5000万 Tokens 大模型调用量（单模型100万 Tokens）”的福利。这让无数对大模型“心痒难耐”、却又因为种种原因选择谨慎观望的中小企业，能够以更低的门槛、更快的速度落地模型应用。</p>
  <p>时至今日，“双11”改变的不仅是to C的零售业，已经有越来越多的中小企业借助“双11”改变、优化IT采购节奏和流程，将精力专注于核心业务创新。</p>
  <p>“我们除了向中小企业推荐好用的方案之外，也会推荐省钱的方案——怎么利用‘双11’优惠最大节省技术成本。<strong>现在很多客户也知道，每年‘双11’采购成本相对低，就会主动把续费采购周期调到11月。”</strong>广东创云科技CEO陈文俊告诉36氪，“比如创云服务的广州某集团，早几年采购节奏比较分散，每个月都会续一批云服务器，每个月要走一遍繁琐的内部采购流程。我们结合客户情况推荐了‘双11’的优化采购方案后，经过一两年的时间，该集团已经调整为平均每年两次续费，不仅减轻了日常工作量，也降低了采购成本。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_26259031ab2a43cf9c6bfb9206cfc6d2@11416942_oswg876963oswg1080oswg677_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：阿里云业务团队与合作伙伴乘云至达在其珍藏的历年“双11战袍”前合照留念</p>
  <p>阿里云因中小企业而改变，“双11”也因合作伙伴而不同。今年“双11”期间，阿里云更是首次在杭州云谷园区设置了多个“合作伙伴作战室”。分销合作伙伴和阿里云公共云团队、产品技术团队齐聚一堂，通过集中办公、技术支持和面对面的高效沟通，共同投入到这场轰轰烈烈的双11“战役”中。</p>
  <p>山东云管家总经理苏春告诉36氪，“双11”所在的十一月，是阿里云的合作伙伴们全年最为重要、业绩最高的月份，往往能占到合作伙伴全年业绩的七分之一甚至五分之一。在今年的市场活动、优惠政策加持下，截至目前云管家“双11”业绩规模已同比增长超150%。</p>
  <p>北京乘云至达CEO郝凯深有同感。<strong>“‘双11’是个见证奇迹的时刻，就像奥运会、世界杯一样。你想达到一个业务目标，那就能实现。”</strong></p>
  <h2><strong>02. 到更广阔的市场中去</strong></h2>
  <p>今年“双11”期间，阿里云在重庆、青岛、武汉、福州、郑州五座城市投放了户外广告，携手乘云至达、快快网络、凌云创想、奇奇科技、完美网络、云管家、中科九洲等25家合作伙伴，共同致敬客户，进一步表达了深耕区域、要将数字化与智能化战火燃到中国每座城市的决心。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5cc79e983b3a44a484821005773de751@11416942_oswg160176oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：2024年11月，阿里云在重庆2号线轻轨投放“双11”广告</p>
  <p>事实上，在整个阿里云的生态体系中，“区域”与“下沉”这两个关键词，扮演了两个重要角色。</p>
  <p>中国信通院在《云计算白皮书（2024）》曾提出“用云量”指标，反映各地区上云用云的程度，并指出“用云量”已成各省数字经济发展晴雨表和数字经济发展活力的指标。</p>
  <p>从地域分布看，用云量第一梯队主要集中在京津冀、长三角、珠三角等地，东南地区用云量明显高于中西部地区，各区域在用云广度、深度、活跃度和创新度方面，都呈现出独特的区域差异化发展特色。</p>
  <p><strong>对于分布全国各地的中小企业而言，其行业特性、区域特性、技术能力、上云需求、用云需求均不相同，区域内技术合作伙伴的“在地”支持与保障尤为重要。</strong></p>
  <p>根据Gartner数据，2023年阿里云成为了亚太地区IaaS市场份额第一的云厂商，上文提到的山东云管家正是阿里云最“老牌”的合作伙伴之一，九年间深耕山东区域，业务遍及济南、青岛等多个城市，销售额从零起步做到了上亿规模。</p>
  <p>山东云管家总经理苏春告诉36氪，一线城市的企业客户往往更聚焦于科技创新、国际化视野以及其他多样化需求，行业主要集中在金融、电商、互联网等，对于前沿技术的接受程度更高，预算相对充裕；相较而言，山东区域的客户则主要集中在制造业、农业等传统行业，企业往往更关注生产效率提升，侧重于供应链优化、智慧农业等解决方案，对于驻场运维服务的关注度比较高。</p>
  <p>而二者相同之处在于，无论什么城市的企业，都重点关注数字化转型的成本控制、安全性。因此，作为区域服务商，云管家一直在结合山东当地产业特点，为企业提供更定制化的数字化解决方案，并配置了较高比例的技术服务和驻场运维团队，要求技术团队全员通过阿里云售前架构师和架构专家认证，以“更贴地的姿态”助力中小企业客户实现高效发展。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_435e50b3a4e94550ba18bf0a9df8943c@11416942_oswg118386oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：2024年11月，阿里云在重庆、青岛、武汉、福州、郑州等地携手伙伴致敬客户</p>
  <p>如果把视角转向以广州、深圳为首的华南区域，这片富集了国内智能制造、智能家电、AIoT等产业带的区域又有着差异化需求。</p>
  <p>深耕华南市场的深圳云帆长扬CEO何伟告诉36氪，在服务某智能门锁企业时，他了解到该企业的需求不仅仅是完成IoT终端设备网络搭建，更希望进一步探索阿里云的AI与大模型能力，并在内部孵化新业务线，进行业务拓展。</p>
  <p>云帆长扬与阿里云团队除了为该企业匹配大模型算法能力、大模型产品外，还引入了智能编码助手通义灵码、智能客服解决方案通义晓蜜，帮助企业提升代码研发效率、优化客服体验。</p>
  <p>“我们跟客户交流时关注到两点：<strong>第一，我们的技术应用跟客户的业务是同时增长的，云的使用量和使用深度都随着客户业务的发展而发展。第二，云和AI大模型等新技术的确能帮助企业业务更好地升级。”</strong>何伟告诉36氪。</p>
  <p>广阔的海外市场则是“流着蜜糖的下一个应许之地”。</p>
  <p>制造业重镇重庆，拥有汽车、电子、装备等全部31个制造业大类的行业，大量制造业企业正在从这座不靠海的城市“出海”，走向广阔的全球化市场。</p>
  <p>重庆星环云智能创始人黄山向36氪透露，重庆某制造企业的三轮车在夜市摆摊、短途货运等场景广泛应用，并通过网络直播等方式，将三轮车销往东南亚和非洲等海外市场。但因为时差问题和语言隔阂，国内的客服团队很难及时、准确地解答海外用户问题。</p>
  <p>在星环云的帮助下，该企业将通义晓蜜应用于海外销售平台，有效提升了客服效率、应答准确率，实现了与跨境客户的无障碍、无时差沟通。</p>
  <p>从阿里云双11业绩表现来看，北京、上海、广州、深圳、杭州之外的城市贡献了分销伙伴“双11”超一半的营收，有力印证了中长尾市场的增长潜力。</p>
  <p>阿里云研究院曾发布《2023云栖指数报告》，基于阿里云平台上用户对云产品和服务的购买及应用情况编制计算得出“云栖指数”。该指数Top100城市覆盖全国25个省，并涵盖越来越多的中西部城市。阿里云与合作伙伴正不断帮助中西部地区改善“云上数字鸿沟”，缩小与东南沿海的数字经济差距，同时打开一片潜力十足的发展市场。</p>
  <h2><strong>03. 当云计算超越云计算</strong></h2>
  <p>经过了20余年发展，今天的云计算早已超越云计算诞生时的IaaS+PaaS+SaaS这一狭义范畴，逐步成为影响企业核心业务效率的生产要素。</p>
  <p>双11前夕，一份IDC报告引起了业界广泛关注——根据IDC《中国公有云服务市场跟踪 2024H1&amp;Q2》报告数据，2024年上半年，中国IaaS+PaaS市场同比增长12.2%，其中PaaS市场表现尤为突出，其同比增速高达21.9%。</p>
  <p>行业内一般将计算、存储、网络、安全等云产品归入IaaS（Infrastructure as a Service, 基础设施即服务）；PaaS（Platform as a Service, 平台即服务）则包含了开发工具、数据库、数据分析等，是企业IT架构的核心支撑层，PaaS市场增长往往意味着企业对敏捷开发和数据处理需求在快速增长。</p>
  <p>这组数据深刻反映了<strong>当下中国大中小企业逐步迈入数字化转型的深水区。全栈上云逐渐成为主流，大量技术创新、业务升级、数据管理优化、运行效率提升都诞生在云上。</strong></p>
  <p>对于拥有大型技术团队的大企业而言，用好PaaS产品并非难事；但对于中小企业而言，想要用好PaaS，势必需要获得像乘云至达、云管家、云帆长扬、创云这样的企业提供从销售到服务全链路的帮助，从而方便地享受PaaS产品的超高灵活性、扩展性和性价比，支撑快速发展的业务创新。</p>
  <p>AI时代，大模型应用成为推动中小企业创新与提效的最有想象力的工具，与此同时，“AI焦虑”扑面而来，如何应用、如何部署也成为中小企业的巨大困惑。阿里云合作伙伴们帮助中小企业分析业务需求，定位关键场景，结合通义灵码、通义晓蜜、通义听悟等大模型产品能力，大幅降低开发应用门槛。</p>
  <p>反观阿里云，其商业模式决定了需将分销合作伙伴作为核心组成部分。作为一家云计算及人工智能科技公司，<strong>阿里云自身坚持产品技术的突破，必然需要合作伙伴成为阿里云销售、服务能力的延伸，</strong>组成商业化的关键一环。</p>
  <p>阿里云相关负责人向36氪透露，为帮助合作伙伴提升能力，2025财年上半年（自然年2024年4月-2024年9月）已为分销伙伴开设了200余门课程，向15000名伙伴员工提供了产品技术、渠道销售、技术服务等方向的专业培训，合作伙伴认证证书数量同比增长超20%。根据阿里云提供的数据，跟随阿里云赋能计划积极建设技术服务能力、提升客户服务体验的伙伴业绩增速显著高于伙伴平均增速，“双11”更成为合作伙伴渠道销售能力、技术服务能力的绝佳“练兵场”，也成为凝结士气的一次大型“团建”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6793beda13954c6f85c009b59c75d836@11416942_oswg782335oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：阿里云合作伙伴在杭州云谷的双11“作战室”里</p>
  <p>这些上阵有武器、打仗有底气的合作伙伴活跃在广阔的中国市场上，和阿里云一起推动着中小企业从信息化到数字化、智能化的每一次浪潮，见证着中小企业为业务效率提速的每次努力，创造着中小企业丝滑的用云体验，并协力将AI推入现实世界。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_cbdee14e3d0e4347b62bfa6840096da1@11416942_oswg1185441oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：2024年11月，阿里云在重庆、青岛、武汉、福州、郑州等地携手伙伴致敬客户</p>
  <p><strong>像“星环云协助三轮车制造企业用通义晓蜜出海”、“云帆长扬为智能门锁企业引入智能编码助手”这样的故事每天都在发生。随着技术普惠，这些曾被视为技术应用典范的案例，已成为遍布大江南北的“习以为常”。</strong></p>
  <p>“双11”曾是一场商业与技术的伟力创造的“奇观”。对于to B 圈而言，云的前沿技术创新曾在每年“双11”被集中验证，各行各业商家基于云计算的极致弹性攀上业务巅峰，每寸数据价值在这一天被充分挖掘，新的消费体验在“双11”被一一实现。</p>
  <p>但对于一家在全球已拥有29个公共云地域、87个可用区，服务全球数百万付费客户、并将“计算，为了无法计算的价值”奉为圭臬的云计算企业而言，无需刻意“出鞘”，“亮剑”也不再必然，只有当双11被习以为常，下一个奇迹才会诞生。</p>
  <p>就在这个2024“双11”的夜晚，作战室监控大屏上涌动的数字仿佛被赋予了生命，它们如同一股洪流，向中国的每一个城市奔涌而去。而下一个奇迹，正孕育在阿里云和它的朋友们席卷而来的新一轮智能化浪潮之中。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033153250291972</id>
            <title>连OpenAI都推不动Scaling Law了？MIT把「测试时训练」系统研究了一遍，发现还有路</title>
            <link>https://www.36kr.com/p/3033153250291972</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033153250291972</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 09:23:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, OpenAI, 测试时训练, 抽象推理  
<br><br>  
总结: 文章讨论了OpenAI下一代模型的质量提升面临挑战，主要由于高质量数据的减少和经济可行性问题。尽管Scaling Law的放缓令人担忧，但也有乐观观点认为推理的Scaling Law尚未被充分挖掘。测试时计算（TTC）和测试时训练（TTT）被提出为提升模型性能的新方法，TTT通过在测试阶段更新模型来提高抽象推理能力。研究表明，TTT可以显著提升语言模型在抽象推理任务上的表现，甚至超越许多传统方法，挑战了对符号逻辑的依赖。 </div>
                        <hr>
                    
                    <p>昨天，The Information 的一篇文章让 AI 社区炸了锅。&nbsp;</p>
  <p>这篇文章透露，OpenAI 下一代旗舰模型的质量提升幅度不及前两款旗舰模型之间的质量提升，因为高质量文本和其他数据的供应量正在减少，原本的 Scaling Law（用更多的数据训练更大的模型）可能无以为继。此外，OpenAI 研究者 Noam Brown 指出，更先进的模型可能在经济上也不具有可行性，因为花费数千亿甚至数万亿美元训练出的模型会很难盈利。&nbsp;</p>
  <p>这篇文章引发了业界对于未来 AI 迭代方向的讨论 —— 虽然 Scaling Law 放缓这一说法令人担忧，但其中也不乏乐观的声音。有人认为，虽然从预训练来看，Scaling Law 可能会放缓；但有关推理的 Scaling Law 还未被充分挖掘，OpenAI o1 的发布就证明了这一点。它从后训练阶段入手，借助强化学习、原生的思维链和更长的推理时间，把大模型的能力又往前推了一步。这种范式被称为「测试时计算」，相关方法包括思维链提示、多数投票采样（self-consistency）、代码执行和搜索等。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_4b374ea17876443d8d634af8b8bed5ca@46958_oswg427004oswg876oswg797_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其实，除了测试时计算，还有另外一个近来非常受关注的概念 —— 测试时训练（ Test-Time Training ，TTT），二者都试图在测试（推理）阶段通过不同的手段来提升模型的性能，但 TTT 会根据测试时输入，通过显式的梯度步骤更新模型。这种方法不同于标准的微调，因为它是在一个数据量极低的环境中运行的 —— 通常是通过单个输入的无监督目标，或应用于一个或两个 in-context 标注示例的有监督目标。&nbsp;</p>
  <p>不过，TTT 方法的设计空间很大。目前，对于哪些设计选择对 LM（特别是对新任务学习）最有效，人们的了解还很有限。&nbsp;</p>
  <p>在一篇新论文中，来自 MIT 的研究者系统地研究了各种 TTT 设计选择的影响，以及它与预训练和采样方案之间的相互作用。看起来，TTT 的效果非常好，至少从论文标题上看，它的抽象推理能力惊人（surprising）。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_1e80f379c32f4fbea9c945229241f384@46958_oswg563891oswg1080oswg1333_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文标题：The Surprising Effectiveness of Test-Time Training for Abstract Reasoning</p>
  <p>论文链接：https://ekinakyurek.github.io/papers/ttt.pdf</p>
  <p>具体来说，作者确定了将 TTT 有效应用于 few-shot 学习的几个关键要素：&nbsp;</p>
  <p>在与测试时类似的合成任务上进行初始微调；</p>
  <p>用于构建测试时数据集的增强型 leave-1-out 任务生成策略；</p>
  <p>训练适用于每个实例的适应器；</p>
  <p>可逆变换下的自我一致性（self-consistency）方法。</p>
  <p>实验环节，研究者在抽象与推理语料库（ARC）中对这些方法进行了评估。ARC 语料库收集了很多极具挑战性的 few-shot 视觉推理问题，被认为是测试 LM 泛化极限的理想基准。目前的大多语言模型在 ARC 上均表现不佳。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_367d628ab26c4c3a851adfd36b4f4c93@46958_oswg125646oswg1080oswg404_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>ARC 推理任务示例。可以看到，这是一组类似于智力测试的问题，模型需要找到图形变换的规则，以推导最后的输出结果。&nbsp;</p>
  <p>通过对这些部分的精心选择，TTT 可以显著提高 LM 在 ARC 上的性能 —— 在 1B 模型上将准确率提高到原来的 6 倍，使用 8B 模型时也超过其它已发布的 SOTA 纯神经模型方法。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a0f6ce9dd8db409abe86eebb2675a6dc@46958_oswg524171oswg1080oswg1223_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>事实上，他们的研究结果表明，当配备测试时训练时，普通的语言模型可以在 ARC 任务上达到或超过许多神经 - 符号方法的性能。&nbsp;</p>
  <p>这些结果挑战了这样一个假设：解决这类复杂任务必须严格依赖符号组件。相反，它们表明解决新推理问题的关键因素可能是在测试时分配适当的计算资源，也许与这些资源是通过符号还是神经机制部署无关。&nbsp;</p>
  <p>数据科学家 Yam Peleg 高度评价了这项研究：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_7b9a4e11ceaf4221939acdfeb868bec2@46958_oswg284344oswg1080oswg888_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>美国 Jackson 实验室基因组学部教授 Derya Unutmaz 则表示这是一项「令人震惊的研究」，因为如果 TTT 与 LLM 相结合足以实现抽象推理，我们就有可能消除对显式、老式符号逻辑的需求，并找到实现 AGI 的可行途径。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c3bde302a52843f5b63953dbf6db308e@46958_oswg368383oswg1080oswg734_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>不过，过完一关还有一关：Epoch AI 与 60 多位顶尖数学家合作打造的 FrontierMath，已经成为评估人工智能高级数学推理能力的新基准，恐怕接下来各位 AI 研究者有的忙了。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_7a3e4c24d0c24b25803a1a54b0f0999f@46958_oswg49961oswg1080oswg157_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>论文概览</strong></h2>
  <p>作者研究了现有的测试时训练理念：根据测试输入构建辅助数据集，并在预测前更新模型。但目前还不清楚的是，应该在哪些任务上进行训练、进行哪种推理以及从哪个基础模型开始？&nbsp;</p>
  <p>他们为 ARC 挑战赛提供了一组广泛的消融数据。具体来说，他们进行了三项分析，以回答如何进行 TTT，以及 TTT 之前和之后要做什么。&nbsp;</p>
  <p><strong>TTT 需要什么数据？&nbsp;&nbsp;</strong></p>
  <p>作者尝试了两种不同的 TTT 数据生成方式：一是 in-context learning（ICL）格式；另一种是端到端格式。在 ICL 中，作者从给定的测试演示中创建 leave-1-out 任务。在 E2E 中，他们将每个 i/o 对视为一个单独的任务。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_77efd6c138044a3f816d673dbaffd2b6@46958_oswg206693oswg1080oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>他们还应用了一些几何变换来扩充数据；请看上图中 ICL 任务是如何生成的。他们使用这些生成的任务，用 LoRA 更新他们的模型。他们发现，ICL 优于 e2e 任务，数据增强至关重要。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_78dec9a3c5904d9a859638d31bd05fe3@46958_oswg197014oswg1080oswg1310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>他们用 LoRA 更新了模型。但问题是，应该为每个测试任务训练一个新的 LoRA，还是使用从所有测试任务生成的数据集训练一个共享的 LoRA？他们发现，为每个任务训练 LoRA 要好得多 (FT + TTT vs Shared-TTT）。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_30906590cdff4549822319c076d7059d@46958_oswg162402oswg1080oswg791_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>TTT 之后的推理</strong></p>
  <p>ARC 中没有 CoT，因此无法通过多数投票来改进推理。研究者对此的做法与 TTT 相同：创建少量任务，然后用可逆函数对其进行变换。于是有了一堆经过变换的原始任务输入。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5ba7af82306b4271981e1590457756f7@46958_oswg177335oswg1080oswg507_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>研究者输入变换后的输入，然后将输出反转回来。现在，他们可以从多数表决中获益更多。他们将其命名为「可逆变换下的 self-consistency」。它比任何单一变换的预测效果都要好，分层投票的优势更大。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_51a464405fdc4d5dbd0df9a3543f98c5@46958_oswg134524oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>TTT 前的微调</strong></p>
  <p>你需要微调一个基础 LM，但不需要太多新数据。根据训练任务的重现 + 少量几何变换对模型进行微调，就能获得不错的得分。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6db69635fe5a47049378a632dac1608d@46958_oswg136724oswg1080oswg912_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>研究者尝试了大量基于 LM 的合成数据，但意外地发现，这些数据并没有什么帮助。有趣的是，TTT 缩小了不同级别模型之间的差距。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_abfa36ca5eac4de8a1b17549bc798d19@46958_oswg107799oswg1080oswg936_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>以 ARC 来检验</strong></h2>
  <p>抽象推理语料库（ARC）旨在通过语言模型解决视觉谜题的能力来评估其抽象推理能力。如图 1 (b) 所示，每个谜题（以下简称任务）都是由输入 - 输出对组成的二维网格（最大尺寸为 30 × 30），其中包含最多 10 种不同颜色的形状或图案。通过应用直观、共享的变换规则或函数 y = f (x)，可以获得每对网格的输出。在实践中，这些变换具有高度多样性和复合性，既有简单的概念，如反射和计数，也有更复杂的概念，如施加引力和路径查找。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_542e30ba69fe41ebb6ec736aceb9f4e4@46958_oswg219030oswg1080oswg388_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>ARC 中的每项任务都由训练和测试两部分组成。给定训练样本集，目标是通过推理潜在变换，预测测试输入 x^test 的测试输出 y^test。&nbsp;</p>
  <p>研究者用&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_1534492d7e524d2cbd73535bc78e209c@46958_oswg5568oswg730oswg96_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>表示一个任务，其中&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d9037d20f3a84e8b838fe4e9f16d86bc@46958_oswg5756oswg464oswg120_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>，即 ARC 任务的集合。ARC 数据集的原始训练集和验证集各由 400 个任务组成。成功标准要求对所有测试输出结果进行精确匹配（如果没有给出部分分数）。&nbsp;</p>
  <p>大多数 ARC 方法可分为两大类：程序合成和 fully neural（全神经网络方法）。程序合成试图首先找到变换函数 f，然后将其应用于测试样本。另一方面，全神经方法试图直接预测输出 y 测试，只是隐含地推理底层变换。在这项工作中，研究者采用了全神经网络方法，使用 LM 来预测测试输出。&nbsp;</p>
  <p>研究者首先使用了在文本数据（没有视觉编码器）上预训练过的 LM。为了向这些模型提供 ARC 样本作为输入，需要一个格式化函数（用 str 表示），将二维网格转换为文本表示。以前的一些工作将样本表示为一串数字或 color word，或标有形状和位置的连接组件列表。给定任务的任何此类字符串表示，都可以将其呈现给 LM，并通过简短提示进行预测。&nbsp;</p>
  <h2><strong>实验结果</strong></h2>
  <p>最终，在对 80 项任务进行开发实验之后，研究者展示了 ARC 全部公共评估集的综合结果，并将本文系统与现有方法进行了比较。分析主要集中在三个方面：本文 TTT 方法的影响、本文方法与现有方法相结合的益处、全神经方法与程序合成方法之间的差异。&nbsp;</p>
  <p>测试时训练的影响。研究者将测试时训练和推理过程应用于本文的基础微调模型（没有任何 LM 数据的微调 8B 模型）。TTT 将准确率从 39.3% 提高到 47.1%，超过了现有端到端神经模型的结果。&nbsp;</p>
  <p>与现有方法的整合。最近的一项工作引入了 BARC，通过结合神经和程序合成方法实现了 54.4% 的准确率，这是此前公开发表的最高结果。虽然这里的全神经方法与本文系统有相似之处，但本文 TTT 和推理 pipeline 有几个额外的组件可以提高性能。特别是，本文的测试时训练包括每个任务的 LoRA 和更大的增强集，而预测 pipeline 包括可逆变换下的增强推理和分层 self-consistency 投票方案。为了验证这种改进，研究者将本文的 TTT pipeline 应用于 BARC 的全神经模型，准确率达到了 53%，比最初的 TTT 方法提高了 35%。&nbsp;</p>
  <p>在这些结果的基础上，研究者探索了本文方法与 BARC 组件的各种组合：&nbsp;</p>
  <p>将本文的 TTT pipeline 与神经模型与 BARC 合成器相结合，准确率提高到 58.5%。</p>
  <p>将本文的 TTT pipeline 与 BARC 神经模型和合成器相结合，准确率提高到 61.9%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_40385c8f87104329a47fbd4057825fbd@46958_oswg259757oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这一最终配置在 ARC 公共评估集上实现了新的 SOTA 水平，与 60.2% 的人类平均性能相当。当然，这是一次重大进步，但与人类 97.8% 的最佳表现仍有很大差距，表明仍有进一步提高的空间。&nbsp;</p>
  <p>程序生成和端到端建模的对比。程序合成和用于 ARC 的全神经预测器具有很强的互补性，即使在相同的任务上进行训练也是如此。此前的端到端神经模型只能解决程序合成模型所解决任务的 42.2%。然而研究者发现，当配备本文的 TTT pipeline 时，BARC 的微调全神经模型可以解决程序合成模型所解决任务的 73.5%。这表明，本文的 TTT pipeline 大大提高了神经模型学习系统推理模式的能力，与程序合成模型所捕捉到的推理模式类似。&nbsp;</p>
  <p>更多研究细节，可参考原论文。&nbsp;</p>
  <p>参考链接：https://x.com/akyurekekin/status/1855680791784600013 &nbsp;</p>
  <p>©&nbsp;THE END &nbsp;</p>
  <p>转载请联系本公众号获得授权&nbsp;</p>
  <p>投稿或寻求报道：liyazhou@jiqizhixin.com&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/tfrG21mfteVAkjqYx5mDsQ" rel="noopener noreferrer nofollow" target="_blank">“机器之心”</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033153056764161</id>
            <title>特斯拉10万员工薪酬曝光：低薪背后的股票诱惑</title>
            <link>https://www.36kr.com/p/3033153056764161</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033153056764161</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 09:21:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 特斯拉, 薪酬策略, 股票奖励, 招聘流程  
<br><br>  
总结: 特斯拉的薪酬策略以较低的基本工资和丰厚的股票奖励为特点，吸引了大量求职者。尽管基本薪资低于同行业公司，特斯拉通过股票激励员工，尤其是高薪员工也需押注公司未来。特斯拉的招聘流程严格，旨在筛选出对公司有强烈认同感的“硬核”员工。公司文化强调员工的使命感和对工作的热情，尽管面临裁员和薪资竞争压力，特斯拉依然吸引人才。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_953bf409896e4c68bad17b2a29f0cc41@46958_oswg173590oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>北京时间11月12日，每一年，特斯拉都能够吸引数以百万计的求职者。少数被录用的人通常会做出一个精心计算的冒险决定：先接受较低的基本工资，以换取未来可能获得的丰厚股票回报。</p>
  <p>美国《商业内幕》杂志获取了特斯拉内部薪酬数据库，该数据库涵盖了截至2021年12月的近10万名员工的薪酬数据。这些数据结合公开文件和《商业内幕》对前特斯拉员工的采访，揭示了特斯拉的薪酬策略。特斯拉的基本薪资低于其科技和汽车行业的同行，但提供了丰厚的股票奖励。</p>
  <p>借助特斯拉的内部薪酬数据库，《商业内幕》研究了特斯拉内部工作类别中大约1.3万名美国全职受薪员工的基本工资中位数。特斯拉使用这些工作类别来划分业务单元中的员工，例如工程、制造或数据管理。这一研究不包括小时工的工资，因为他们中的许多人在制造业工作，无法能根据时薪准确计算出他们的年收入中位数。</p>
  <p>研究显示，<strong>即使是特斯拉的高薪员工也必须押注公司。</strong>这种高风险、高回报的薪酬系统与一个严格的招聘流程相结合。过去，特斯拉的每一次招聘甚至都需要埃隆·马斯克(Elon Musk)的签字批准。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d3020b2562914e77955c6c13a6ca5b8b@46958_oswg37307oswg1080oswg499_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜特斯拉基本工资中位数落后于其他公司&nbsp;</p>
  <p>《商业内幕》还进一步细分数据，按照职称查看了基本薪资的中位数，分析了至少有五名美国全职受薪员工的薪资。根据数据，<strong>这些有职称职位的基本薪资介于大约3.5万美元到32.4万美元，其中包括工程总监、负责修理车辆的特斯拉服务中心经理。</strong></p>
  <h2><strong>最硬核员工</strong></h2>
  <p>九名现任和前任员工表示，自2021年12月以来，特斯拉的薪酬结构基本上保持不变，属于马斯克只雇佣“最硬核”员工计划的一部分。</p>
  <p><strong>“整个系统的设计是为了找到那些狂热的特斯拉粉丝。虽然他们可以在其他地方获得更高的薪水，但我们想要的是那些死心塌地支持特斯拉的人。”</strong>一位了解特斯拉招聘流程的现任员工表示。</p>
  <p>一位在2024年离职的特斯拉前招聘人员表示，特斯拉对工程师的面试过程(通常需要至少9轮，耗费几个月的时间)以及公司的薪酬结构，旨在淘汰那些只想“打卡下班”的员工。</p>
  <p><strong>“这是文化问题，”</strong>这位前招聘人员说，<strong>“这甚至与你有多聪明或你的知识储备无关。他们要找的是愿意学习、愿意加班的人。”</strong></p>
  <h2><strong>基本工资倒数</strong></h2>
  <p>2023年12月，特斯拉在提交给美国证券交易委员会(SEC)的一份监管文件中，该公司在全球拥有逾14万名员工。今年4月，特斯拉通知员工，<strong>计划裁员10%以上。</strong>根据CNBC在今年6月份的估计，特斯拉现在的员工总数刚刚超过12万人。</p>
  <p>《商业内幕》利用SEC提供的独立数据，将特斯拉的基本工资中位数与传统汽车制造商和六大科技巨头(按市值)进行了比较。除亚马逊外，特斯拉落后于所有这些公司。虽然有各种各样的因素会影响一家公司的工资中位数，例如亚马逊庞大的仓库工人队伍或苹果庞大的零售员工队伍，但薪资数据与四位现任和前任特斯拉员工所说的一致：特斯拉的基本工资普遍低于竞争对手。</p>
  <p>《商业内幕》称，根据2021年的SEC文件，<strong>特斯拉员工的薪酬中位数约为4万美元，这与之前的报道基本一致。</strong>数据平台MyLogIQ在今年6月的统计显示，2023年特斯拉员工的薪酬中位数为4.6万美元，只高于亚马逊的3.6万美元。相比之下，脸书母公司Meta的员工薪酬中位数高达37.9万美元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_54a6049cff91486ea0d4b06e386882c2@46958_oswg231965oswg1080oswg1217_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜MyLogIQ统计的美国科技七巨头工资中位数&nbsp;</p>
  <p>英伟达、福特汽车、Meta和亚马逊拒绝就其员工薪酬方案发表评论。苹果、微软和谷歌母公司Alphabet没有回应置评请求。通用汽车表示，在过去六个月时间里，该公司在硅谷的员工人数增加了一倍，提供的工资福利具备了行业竞争力，可以从科技公司那里挖掘人才。</p>
  <h2><strong>要的是股票</strong></h2>
  <p>九名在特斯拉工程和销售部门工作的现任和前任员工表示，特斯拉的股票奖励让他们更容易接受较低的基本工资。特斯拉股票可以让他们变得富有，哪怕只是纸面上的。今年11月8日，在特朗普再次当选美国总统后，特斯拉的股价飙升了8%，市值达到1万亿美元。</p>
  <p>一些特斯拉员工可以获得价值数百万美元的股票。特斯拉薪资数据库显示，<strong>2020年和2021年，44名美国员工获得了价值超过100万美元的股票。</strong></p>
  <p>为了了解哪些员工更有可能获得大额股票奖励，《商业内幕》根据职位类别对股票奖励进行了分类。数据显示，大多数工程部门的员工获得的股票奖励超过了2.5万美元。这些股票的价值取决于特斯拉授予员工时的股价，但会根据特斯拉股价的变化而波动。</p>
  <p>根据《商业内幕》对美国全职员工的分析，在特斯拉股票奖励中，大约75%是限制性股票单位(RSU)，21%是非法定股票期权(NQSO，不受税法约束)，主要作为基于业绩的补偿发放。仅有4%的员工(包括许多高管和其他高级员工)以激励性股票期权(ISO)的形式获得了这些股票。</p>
  <p>科技行业薪酬研究公司Levels.fyi的联合创始人泽赫尔·泽赫尔(Zaheer Mohiuddin)表示，限制性股票单位在科技行业很常见，而激励性股票期权通常为资深高层员工保留，常见于非上市公司。<strong>限制性股票单位一般是标准薪酬方案的一部分，而非法定股票期权和激励性股票期权则常作为额外的激励措施。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e9d08d362b57473495f732f78e959b20@46958_oswg95649oswg1080oswg1015_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜特斯拉各岗位的股票奖励中位数&nbsp;</p>
  <p>薪资数据库显示，在特斯拉高管中，除了有一位没有列出股票金额外，其余高管的股票奖励金额在95万美元到2000万美元之间。该数据库显示了截至2021年12月每位员工的最新股票奖励金额，除了一名高管外，其他高管获得都是激励性股票期权。</p>
  <p><strong>特斯拉并不是首个通过股票奖励提升基本薪酬的公司。</strong>Meta、谷歌和亚马逊等公司也以提供丰厚的股票奖励著称。根据Levels.fyi的2024年员工调查数据，特斯拉美国软件工程师的总薪酬(基本薪资中位数加股票奖励)，略低于Meta、亚马逊、苹果、Netflix和Alphabet的美国软件工程师。</p>
  <h2><strong>特斯拉股价暴涨</strong></h2>
  <p>过去五年，特斯拉的股价飙升了逾1000%，这种表现使其股票奖励变得非常具有吸引力。</p>
  <p>猎头公司Stanton Chase的董事总经理格雷格·塞尔克(Greg Selker)指出，虽然其他大型科技公司可能会提供更高的基本工资和股票奖励组合，但特斯拉的优势还在于它的形象。</p>
  <p><strong>“特斯拉有一种使命感，员工们在努力实现地球的去碳化，这让它能够支付更低的薪酬。”</strong>塞尔克表示。</p>
  <p>马斯克之前曾描述过股票期权对员工的影响。“我们给每个人发放股票期权。我们让很多仅仅是在生产线工作的员工(他们甚至不知道什么是股票)都成了百万富翁，”他在去年表示。</p>
  <p>《商业内幕》研究了特斯拉股票奖励的中位数和每个工作类别获得奖励的员工百分比，发现几乎每个类别的大多数员工都获得了某种类型的股票奖励。</p>
  <h2><strong>“金手铐”</strong></h2>
  <p>汽车行业和劳工领域专家哈利·谢肯(Harley Shaiken)称，特斯拉的薪酬策略逾谷歌、Meta等其他硅谷公司更为相似，但与传统汽车制造商差异较大。“像通用或福特这样的传统汽车制造商依赖较高的基本工资，而特斯拉等过去五年股票回报较高的公司则可以通过股票奖励来吸引人才。”他表示。</p>
  <p>谢肯指出，<strong>科技行业员工寻找的是能够大赚一笔的机会，而不是缓慢的涨薪。</strong></p>
  <p>一位特斯拉前销售经理表示，最初吸引他加入特斯拉的就是股票奖励，但他也将股票比作“金手铐”。“股票是主要诱饵。你可能对自己的岗位感到不满，但你会告诉自己，低调一点，再忍耐几个月，直到我的股票兑现。”他表示。</p>
  <p>特斯拉的股票奖励让一些员工获得了丰厚的回报。特斯拉前动力总成与能源工程高级副总裁德鲁·巴格利诺(Drew Baglino)和前首席财务官扎卡里·柯克霍恩(Zachary Kirkhorn)各自获得了2000万美元的股票奖励。</p>
  <p>薪资数据库显示，<strong>其他特斯拉高管也收到了1000万美元的股票奖励，包括马斯克的得力助手奥梅德·阿夫沙尔(Omead Afshar)。</strong></p>
  <p>“这就是冒险加入特斯拉公司的部分好处。你可能得忍受创业公司带来的痛苦：长时间的工作、一些不确定性，但最终也有可能获得丰厚的回报。”一位在2015年加入特斯拉的工程师表示。</p>
  <p>艾伦·格林斯潘(Aaron Greenspan)是马斯克的公开批评者，也是PlainSite的创始人。PlainSite是一个提供法律文件访问和倡导法律透明度的组织。他提起了一项诉讼，将马斯克、特斯拉等列为被告，指控他们犯下诽谤等罪名，并在这桩诉讼中首次提到了阿夫沙尔的股票奖励。马斯克和特斯拉的律师称，格林斯潘提出了“基本上是莫名其妙的指控”。目前，诉讼仍在进行中。</p>
  <p>根据特斯拉薪酬数据库以及《商业内幕》对四名现任员工的采访，特斯拉会基于公司业绩在晋升和年度考核时授予股票奖励。据四名员工透露，特斯拉在去年削减了对员工的绩效股票奖励。今年6月，马斯克告诉员工，他计划为“表现卓越”的员工额外发放股票奖励。两位知情人士说，在今年7月的年度绩效考核中，管理人员被要求推荐不超过20%的团队成员获得额外奖励。数据显示，特斯拉通常会向员工发放为期四年的限制性股票单位。</p>
  <p>猎头公司Stanton Chase的董事总经理塞尔克表示，从历史上看，特斯拉员工能够指望他们的股票继续增长。“这是一场他们必须下的赌注。到目前为止，股票奖励证明比口袋里的现金更有价值。”他说，</p>
  <p>不过，塞尔克也警告称，如果股票变得不稳定或腰斩，那么特斯拉将不得不改变策略。特斯拉股价在今年经历了大幅波动，4月中旬时较年初下跌了44%。在特朗普再次当选美国总统后，特斯拉股价大涨，今年为止累计上涨了近30%。</p>
  <p><strong>至少有一位特斯拉老员工为新员工的如意算盘感到担忧。</strong></p>
  <p>“我觉得我很幸运，在特斯拉早期就加入了公司(获得了股票回报)，但我看到很多年轻工程师期望获得同样的回报。我不确定他们能否如愿。”他表示。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/IeLZRC-kfRUf1AcMKM22-A" rel="noopener noreferrer nofollow" target="_blank">“凤凰网科技”</a>，作者：箫雨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3032913400148864</id>
            <title>雷军余承东们出手，“非洲手机之王”危险了？</title>
            <link>https://www.36kr.com/p/3032913400148864</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3032913400148864</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 09:20:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <非洲手机市场, 传音, 小米, 竞争>
<br>
<br>
总结: 非洲手机市场正在经历变化，传音的净利润和市场份额出现下滑，而小米和OPPO的出货量却大幅增长。传音在非洲市场的成功源于低价策略、本土化创新、广告与渠道的结合以及相对较小的竞争环境。然而，随着小米、OPPO等中国品牌的进入，传音面临着更激烈的竞争。尽管传音在非洲的市场地位短期内难以撼动，但其防御能力将受到挑战。传音已建立了互联网和硬件生态，形成护城河，但其他品牌的崛起可能会影响其市场份额。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_f0a1e27f7dbe479da685623f142bf2c3@5952539_oswg1126620oswg768oswg768_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>稳固多年的非洲手机市场终于迎来了松动。</p>
  <p>第三季度，被誉为“非洲手机之王”的传音净利润暴跌41%，营收也同比下跌7%。不仅如此，今年二季度，传音在非洲的市场份额已开始下降。</p>
  <p>与传音净利润暴跌、市场份额下降相反的是：小米、OPPO在非洲的出货量增长100%和259%。</p>
  <p>这是一个极其重要的信号。</p>
  <p>要知道，传音在非洲已经布局近20年。2006年，当大部分人还没有手机，诺基亚还是全球手机市场的老大，传音的竺兆江已开始在非洲做调研。后来诺基亚手机退出市场，三星在非洲屈居第二，传音手机凭借非洲市场的放量，成为全球第四大手机厂商。</p>
  <p>去年，传音手机的出货量和净利润分别同比上涨30%和123%。为什么情况会急转直下？最近一年非洲手机市场又经历了哪些变化？</p>
  <h2><strong>一、广告靠刷墙、待机一个月，在非洲，传音遥遥领先</strong></h2>
  <p>竺兆江是传音创始人，他很低调，鲜少接受采访也很少在公开场合露面，传音手机的发展也很低调。</p>
  <p>2006年，竺兆江还是波导手机副总裁，中国放开国外手机厂商拿手机牌照后，国内手机厂商面临前所未有的竞争压力，于是竺兆江从波导辞职，创立传音，远赴非洲开拓市场。</p>
  <p>21世纪初，小灵通的出现让手机成为大众消费品，各大手机厂纷纷加入市场抢夺用户，当时非洲是诺基亚的天下。因为非洲人均GDP只有几百美元，大部分人还用不起手机，手机渗透率只有20%，而发达国家渗透率已超过90%。</p>
  <p>传音的第一款手机Tecno T780是一款双卡双待手机，因为当地人习惯随身携带多张SIM卡（非洲运营商比较多跨运营商信号会变差而且资费较贵），这样两张卡可以自由切换，省去了换卡的麻烦。此款手机非常受当地人欢迎，传音逐渐在非洲站稳了脚跟。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_78f1d70652d54104a2eccf9becb49eb3@5952539_oswg514617oswg700oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>紧接着，传音推出了首款安卓智能机Tecno T1，2013年，传音又推出了高端手机品牌Infinix与苹果、三星展开正面竞争。</p>
  <p>2016年，传音凭借着功能机的超高占有率，超越诺基亚和三星成为非洲市占率最高的手机厂商，2018年，传音手机在非洲的市场份额占比超过50%，过半的市占率一直保持到当下。</p>
  <p>传音手机能够打败国际巨头，统治非洲手机市场主要有以下四个原因：</p>
  <p><strong>第一，传音的低价策略。</strong></p>
  <p>无论功能机还是智能手机，传音的手机价格比诺基亚和三星便宜，传音采取农村包围城市的策略，主打三四线城市和农村，诺基亚三星则主要布局大城市，低线市场扎稳脚跟后，传音又推出高端品牌进入一线城市。</p>
  <p><strong>第二，进行本土化创新。</strong></p>
  <p>双卡双待手机之后，传音又推出了四卡四待手机，以及长续航电池，甚至一个月不用充电，还有针对非洲人喜欢载歌载舞，传音手机具有大音量播放音乐的功能。</p>
  <p>此外，也开发了适合黑人的手机拍照功能，其他厂商拍的照片，不仅照片里的脸比现实还黑，而且晚上拍照只能看到两颗牙，完全看不到脸，传音的手机可以做到把脸拍成巧克力色，晚上也不用担心看不到脸。还根据当地天热人手容易出汗，增加了防掉落、耐腐蚀，指纹解锁成功率高等个性化创新。</p>
  <p><strong>第三，“广告+渠道”，打造文化认同。</strong></p>
  <p>传音采取最基本的刷墙广告，同时非洲人热爱足球，传音与英超曼城、莱斯特城等球队签约成为官方合作伙伴，还有当地热门歌手，以及传音复制了OPPO、VIVO的打法，有很发达的线下分销体系。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_017ff974b8454e65aa4889f3b4444a76@5952539_oswg767727oswg1010oswg543_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>第四，传音选择的非洲市场，竞争比较小。</strong></p>
  <p>传音手机虽然卖的价格比小米要低，但是整体毛利率高于小米，比如2023年传音毛利率和净利率，分别是24.5%和9%，小米的分别只有21.5%和6.5%（手机业务毛利率更低）。在同价位配置上比不上红米，但是在非洲通过本土化创新在深耕多年，消费者愿意为其特色功能买单，所以毛利率高于小米。</p>
  <h2><strong>二、小米华为们扎堆非洲，翻倍式增长成常态</strong></h2>
  <p>然而在今年，传音稳固的市场正在被中国对手们蚕食。</p>
  <p>IDC数据，今年一季度，非洲智能手机出货量2020万台，同比增长17.9%，同期功能机出货量跌至1880万台，同比下跌15.9%，智能手机出货量首次超越功能机。</p>
  <p><strong>在非洲，智能机时代悄然到来。</strong></p>
  <p>2023年，传音在非洲卖了3450万部手机，份额占比54%，排名第一，从2024年第二季度起，传音的市场份额已降至51%，虽然仍然排第一，但传音的市场份额正在被蚕食。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_17744ad5773d4d2c97cdbcb768b74eec@5952539_oswg332764oswg1080oswg683_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>今年二季度，小米的智能手机市场份额从去年的11%增长至12%，2022年，小米份额还只有6%。<strong>去年，在非洲最大手机市场尼日利亚，小米份额已达19%，成为仅次于传音的第二大手机品牌。</strong>今年二季度，OPPO在非洲的市场份额也达5%，OPPO子品牌Realme的出货量增长137%。</p>
  <p>华为手机虽然没有进入前五，但Canalys数据显示，去年四季度华为手机销量大幅增长371%。</p>
  <p><strong>小米、OPPO等手机厂商大举进入非洲，用的也是低价策略，主攻中低端市场。</strong>Canalys高级研究员表示：“今年上半年，100 美元以下的细分市场增长率达到42%。”</p>
  <p>小米更注重技术发烧和性价比，以热卖的红米10A和红米12C为例，其售价仅为75美元和95美元，价格均低于100美元，还有大容量电池。</p>
  <p>OPPO也是主打的性价比，以其拍照性能见长。</p>
  <p>相比于传音、小米、OPPO，三星则更加重视中高端市场，在中国手机厂商的围剿下，三星份额出现下降。今年二季度，Canalys统计，三星在非洲的市场份额跌至19%，甚至手机出货量较去年同期下跌25%。</p>
  <p>此外，VIVO也已宣布进入非洲市场，荣耀手机也计划于近期进军非洲市场。巨头们进入非洲市场后，非洲手机市场竞争将会更激烈。</p>
  <h2><strong>三、传音生态遍布非洲，城池不会失守，但防御会更难</strong></h2>
  <p>不可否认，传音正面临着中国企业更激烈的竞争，但在非洲的市场地位，短期内仍然难以撼动。</p>
  <p>在非洲，传音的布局不止是手机。</p>
  <p><strong>传音凭借在非洲的手机占有量，已经早早地布局互联网软硬件生态，建立护城河。</strong>比如，互联网生态方面，传音围绕基于安卓系统的HiOS、itelOS和XOS三大系统8000万活跃用户，开发了应用商店、游戏中心、广告分发平台和手机管家等流量渠道。</p>
  <p>基于庞大的手机用户群，传音开发出了7款月活超千万的App，比如浏览器Phoenix月活用户达1.2亿；音乐播放软件Boomplay（“非洲版的网易云”），月活用户数达6800万；还有“非洲版今日头条”Scooper，月活用户数2700万；“非洲版抖音”Vskit，月活用户数3000万等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_b93091827f1d4a0a879c2962b5a849a9@5952539_oswg206466oswg1080oswg917_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>此外还有非洲版支付宝，网文、游戏市场传音也有涉及。</p>
  <p>硬件生态方面，传音有3C产品配件品牌Oraimo、中高端家电品牌Syinix和入门级家电品牌itel。Oraimo旗下产品包括智能音箱、智能手环、移动电源、蓝牙耳机等，Syinix旗下有电视、空调、冰箱、洗衣机、音响、微波炉、榨汁机，基本涵盖了常用电器与小家电产品。</p>
  <p>3C产品配件产品卖得最好的是蓝牙耳机，2023年，Oraimo蓝牙耳机的整体销量在非洲所有品牌中排名第一，市占率超过30%。</p>
  <p><strong>传音建立的护城河，短期看或许很难被撼动，但是国内手机厂商，比如小米手机销量的不断提升，小米生态也正在进入非洲。</strong></p>
  <p>只要大厂们愿意发力，传音守住非洲市场的难度也会越来越大。</p>
  <p class="editor-note">本文来自微信公众号“增长工场”，作者：武占国，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033039269802248</id>
            <title>深度揭秘CoT，普林斯顿耶鲁发布最新报告：大模型既有记忆推理、也有概率推理</title>
            <link>https://www.36kr.com/p/3033039269802248</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033039269802248</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 09:10:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大型语言模型, 思维链, 移位密码, 概率推理  
<br><br>  
总结: 研究人员通过案例研究，探讨了大型语言模型（LLMs）在解码移位密码任务中使用思维链（CoT）提示的表现。尽管CoT提示提升了模型的推理能力，但这种能力并非单纯的符号推理，而是结合了记忆和概率推理的复杂过程。研究分析了影响CoT性能的三个因素：任务的预期输出、模型在预训练期间隐式学习的内容以及数量推理中的中间操作。实验结果表明，CoT提示的性能提升反映了模型在推理过程中记忆和真实推理的概率因素。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_8e19b400666940538c96fa32cdc3f546@46958_oswg286382oswg1074oswg425_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>【导读】</strong>研究人员通过案例研究，利用大型语言模型（LLMs）如GPT-4、Claude 3和Llama 3.1，探索了思维链（CoT）提示在解码移位密码任务中的表现；CoT提示虽然提升了模型的推理能力，但这种能力并非纯粹的符号推理，而是结合了记忆和概率推理的复杂过程。</p>
  <p>「推理」是非常能展现「人类智能」的一项能力，需要结合现有证据和过去的经验，以逻辑和系统的方式思考某件事情，进而做出决策。</p>
  <p>大型语言模型（LLMs）以其通用性，在多项任务上都取得了出色的性能，虽然思维链（CoT）提示已经证明了大模型具备多步推理能力，但这种能力到底来自于「抽象泛化」（abstract generalization）还是「浅层启发式」（shallow heuristics），仍然没有定论。</p>
  <p>为了深入理解影响 CoT 推理的因素，普林斯顿大学、耶鲁大学的研究人员最近发布了一项案例研究，使用三个大模型（GPT-4、Claude 3 和 Llama 3.1）利用CoT提示来执行解码移位密码（decoding shift ciphers）的符号推理任务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_4e173ccf3a2c4f25a37a3bca39bd436b@46958_oswg192694oswg1080oswg349_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文地址：https://arxiv.org/abs/2407.01687</p>
  <p>文中只关注这一个简单的任务，能够系统地分析出影响 CoT 性能的三个因素：任务的预期输出（概率）、模型在预训练期间隐式学习的内容（记忆），以及数量推理中涉及的中间操作（噪声推理）。</p>
  <p>实验结果显示，这些因素可以极大地影响模型的准确率，并且可以得出结论，CoT提示带来的性能提升，既反映了模型在推理过程中有记忆的因素，也有真实推理的概率因素。</p>
  <h2><strong>研究方法</strong></h2>
  <p>以往的方法在研究模型推理能力时，往往在一系列复杂的推理任务上进行评估，其中任务的多样性和复杂性可能会掩盖CoT推理背后的影响因素，所以这篇论文只关注一个相对简单的任务：使用移位密码编码的文本进行破译（deciphering text encoded with a shift cipher）。</p>
  <p>使用移位密码（shift cipher）来编码消息的过程为，将每个字母替换为在字母表中向前移动一定数量位置（shift_level）的另一个字母；解码则为相反的操作，即向后移动。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_83869f39efcd41258b2e5ccadd44e3d0@46958_oswg523529oswg1080oswg865_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这种密码也可以称为旋转密码（rotation ciphers），过程等价于将字母表向前旋转一定数量的步rot-k，其中k对应于shift_level</p>
  <p>例如，给定测试词「FDW」并使用rot-3加密（shift_level = 3），解码需要将每个字母向后移动3步，即F → C，D → A，W → T，最后获得解码输出「CAT」。</p>
  <p>在实验设计时，研究人员给大模型输入一个使用移位密码编码的单词，并要求模型对文本进行解码以恢复原始单词。</p>
  <h3><strong>任务动机</strong></h3>
  <p>研究人员使用移位密码任务的主要出发点在于「任务复杂性」和「任务频率」之间存在明显的分离。</p>
  <p>解密任务的复杂性也可以动态变化，移位级别（shift level）更高的密码，需要更多中间步骤，也更复杂；不同的移位级别在互联网文本中的频率也不同，在大型语言模型的训练数据中也是如此。</p>
  <p>比如rot-13在互联网论坛中广泛用于隐藏文本，如谜题解答和剧透，而rot-3和rot-1通常用在解密教程中（rot-3也被称为凯撒密码）。</p>
  <p>此外，移位密码有助于研究概率的影响，因为正确答案可以是任意字符串，可以很容易地调节字符串的概率，并且生成样本和正确性验证也很容易。</p>
  <p>最重要的是，解码信息时，每个字母都是一个独立的步骤，更容易分析。</p>
  <h3><strong>CoT在移位密码上的影响</strong></h3>
  <h4><strong>数据</strong></h4>
  <p>研究人员构建了一个数据集，每个单词包含7个字母（从词表中组合3个字母和4个字母的单词），用GPT-4分词器后为2个token，以控制与分词器无关的因素。</p>
  <p>使用GPT-2计算对数概率，用句子「The word is "WORD"」的对数概率减去「The word is」的对数概率，然后把单词按其对数概率评分，并按降序排列。</p>
  <p>通过选择等距的对数概率值作为中心，形成了五个区间，其中区间1具有最高的概率，区间5具有最低的概率，再手动检查了数据集中的单词，并进行了筛选，以确保没有使用不恰当的单词，其中每个区间包含150个单词。</p>
  <p>数据集中总共包含150个样本，划分为两个子集：1）包含100个单词以评估GPT-4；2）包含50个单词，用于评估拟合到GPT-4在100个单词子集上表现的逻辑回归模型。</p>
  <p>最后在1-25移位级别上生成来自5个概率区间的单词的移位密码编码版本，作为模型的输入；评估只运行一次，基于100个样本报告准确率。</p>
  <h4><strong>评估提示</strong></h4>
  <p>研究人员使用多种不同的提示对数据集的性能进行了评估：</p>
  <p><strong>1. 标准（standard）提示</strong>，只有任务描述和演示但没有推理步骤的提示；</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_483686bf567745199be780fe7fd8bf58@46958_oswg50933oswg750oswg270_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>2.&nbsp;文本思维链（Text-CoT）</strong>，使模型逐个字母解码消息。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_fdf8ecbad7804d6593dc1dca4abb17ef@46958_oswg78125oswg710oswg444_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>要想正确得到推理步骤，模型必须在预训练期间学会字母表。</p>
  <p><strong>3.&nbsp;数学思维链（Math-CoT）</strong>，模型需要将每个字母转换为数字，然后通过数字应用算术来执行移位，再将结果转换回字母；提示中还指定了字母和位置之间的映射。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_87123e4628664746a1fad02594033862@46958_oswg125395oswg752oswg694_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>4.&nbsp;数字序列思维链（Number-CoT）</strong>，该任务基于数字域（即输入和输出是数字序列），与移位密码同构；推理需要对数字序列中的输入元素应用算术运算以获得相应的输出序列。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6f84502b742e40b988adf7caf617de2c@46958_oswg107073oswg755oswg559_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>实验结果</strong></h2>
  <p>研究人员使用了开源和闭源模型进行实验：GPT-4（gpt-4-0613），Claude 3（claude-3-opus-20240229），以及Llama-3.1-405B-Instruct，其中温度设置为0，并将max_new_tokens设置为200。</p>
  <p>在使用标准提示时，GPT-4在大多数移位级别上的准确率为零，但当使用文本CoT时，其准确率大幅提升（平均准确率达到32%），跟以前的研究结果相同，即CoT对移位密码很有帮助，但仍然远非完美；但在使用数字CoT时，GPT-4的表现结果几乎达到了完美。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d96443f31b844ec28112039746a81847@46958_oswg110370oswg910oswg434_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>上述结果显示，如果CoT提示中用到的是符号推理，那GPT-4的推理能力就会很完美；而事实上没有得到完美分数，也表明了CoT推理并非纯粹的符号推理。</p>
  <p>尽管如此，CoT也很明显优于标准提示，所以CoT推理不太可能仅仅是简单的记忆。</p>
  <p>如果CoT推理既不是简单的记忆也不是纯粹的符号推理，那会是什么？</p>
  <h3><strong>推理过程分解</strong></h3>
  <p>研究人员考虑了大型语言模型（LLMs）可能采用的四种推理过程：</p>
  <p><strong>1. 符号推理（Symbolic reasoning）</strong>是使用离散的、确定性的推理规则。移位密码可以通过简单的符号算法完美解码，因此一个使用完全系统化推理的系统应该达到100%的准确率。</p>
  <p><strong>2. 噪声推理（Noisy reasoning）</strong>类似于符号推理，但增加了噪声，导致推理过程中每个中间操作出错的可能性。如果系统使用噪声推理，那应该看到随着需要执行的操作数量的增加，准确率会下降；移位密码可以测试出这种可能性：通过改变移位级别，可以调节每个推理步骤中需要执行的操作数量，并观察准确率是否相应变化。</p>
  <p><strong>3. 记忆（Memorization）</strong>策略，模型可以记住在预训练中遇到的任务，但无法泛化到新任务。如果LLMs所做的只是记忆，应该看到在预训练中经常遇到的情况比那些不经常遇到的任务表现更好。</p>
  <p>之前有研究表明，13是自然语料库中最常见的移位级别，在一些网络社区中很常见。</p>
  <p><strong>4.&nbsp;概率推理（Probabilistic reasoning）</strong>将任务框架为选择给定输入下最可能的输出，推理会受到输出的先验概率的影响，概率推理器应该随着正确答案的先验概率增加，准确率也会有所提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_ccd1e5d96c364785a2afaa8986b34add@46958_oswg176832oswg731oswg715_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>对比假设准确率，研究人员发现，随着移位级别的增加，准确率通常会下降，代表LLM在执行噪声推理，并且是双向噪声推理，模型可以对字母进行向前或向后的移位来解码消息，例如，向后移动25个字母和向前移动1个字母相同，但后者的中间步骤更少；双向性质的具体表现为，当移位级别从20变为25时，准确率会增加。</p>
  <p>其次，模型进行概率推理的证据是，准确率在最高概率区间（区间1）远高于最低概率区间（区间5），其中「高概率」大多为常见的单词，如{'mariner', 'shrines', 'paywall', ...}，而「低概率」的情况大多是无意义的字母序列，如{'xcbrouw', 'jsxrouw', 'levjspx', ...}。</p>
  <p>最后，虽然移位级别13比其他移位级别需要更多的推理步骤，但移位级别13上的准确率存在一个峰值，代表模型执行了记忆（13是自然语料库中最常见的移位级别）。</p>
  <p>参考资料：&nbsp;</p>
  <p>https://arxiv.org/abs/2407.01687&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/PtuCL1WBRvrFr7nkJaKgrQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：LRS&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3032933080642434</id>
            <title>月之暗面杨植麟：天才少年难躲资本局？</title>
            <link>https://www.36kr.com/p/3032933080642434</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3032933080642434</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 09:10:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <月之暗面, 杨植麟, AI创业, 资本争议>
<br>
<br>
总结: 本文讨论了AI创业公司“月之暗面”的创始人杨植麟与前投资方之间的仲裁争议，起因是他在未获同意的情况下离职创业。文章指出，杨植麟在大模型市场的敏锐洞察力使他迅速融资并创立新公司，尽管面临法律和资本的压力。月之暗面在产品推广上采取了激进策略，吸引了大量用户，但也引发了市场对其商业模式和资本关系的质疑。最终，文章强调了在AI领域，创业者面临的机遇与风险，以及资本在其中的复杂角色。 </div>
                        <hr>
                    
                    <p>双11当天，这场电商的节日反倒静悄悄，AI领域却爆出了大新闻。</p>
  <p>大模型独角兽企业『月之暗面』创始人被前司投资人提起仲裁，消息阅读量很快突破10W+。 据《暗涌》具体报道，月之暗面创始人杨植麟、联合创始人兼CTO张宇韬，近日被循环智能时期投资方金沙江创投、靖亚资本、博裕资本、华山资本和万物资本，在香港提起仲裁。&nbsp;</p>
  <p>事件的起因是杨植麟和张宇韬此前是循环智能的联合创始人，2023年看到大模型热时，没经过循环智能的投资方同意离职创业，就私下启动融资并创立新公司月之暗面。&nbsp;</p>
  <p>据鲸哥了解，这件事并不是杨植麟天真到不了解『竞业协议』，不知道离职前需要给投资你的资本，一个清楚地交代。&nbsp;</p>
  <p><strong>而是与一个人有很大关系，这个人就是前金沙江创投管理合伙人张予彤。这位被小红书创始人最感谢的3个人之一的女将，也是站在杨植麟背后的天使投资人、清华校友，此前一度被传会加入月之暗面。</strong> 而这两件投资案例中，都涉及到朱啸虎、张予彤看事情的立场是否统一的问题。&nbsp;</p>
  <p>据鲸哥获悉，大模型6小虎中只有2家，是存在价格不高的天使轮投资机会， 诸如零一万物第一轮融资时，就宣布估值达到了独角兽级别。而月之暗面创立之初估值并不高，循环智能的CEO还给股东发出了情况说明邮件，让 循环智能的老股东知晓补偿方案后，放2位联创去创业，但当时全部股东并未谈妥。&nbsp;</p>
  <p>随后月之暗面做了一轮轮融资，让月之暗面的估值迅速攀升，率先超过了30亿美金估值，张予彤功不可没。而对于杨植麟而言，当初就没有拿到同意创业豁免书，今天演变成了巨大的商誉争议。&nbsp;</p>
  <p>所以现在看围绕月之暗面的一系列迷之操作：<strong>创始人早早套现一波、kimi急切商业化、部分融资拿阿里云『代金券』，这些动作也就不难理解，这是因为月之暗面始终隐藏着公司层面的大雷，能否用狂奔甩掉。</strong></p>
  <p>而围绕朱啸虎等资本大佬，<strong>对『新生儿』月之暗面是支持梦想，还是始终报以多要股份、多获益的心态</strong>，也成为市场舆论争议的焦点。&nbsp;</p>
  <h2><strong>1 冒险也要争取的创业窗口期</strong></h2>
  <p>在2023年的大模型市场，大家都知道有一位技术天才，他只要创业就会获得众多资本的支持。&nbsp;</p>
  <p>他就是月之暗面的创始人杨植麟，2023年6月份，硅谷科技媒体The Information列出了其认为有可能成为“中国OpenAI”的五个候选，里面有4家公司，第5位就是杨植麟个人。&nbsp;</p>
  <p>这意味着，他随时创业都可以做成一家国产OpenAI，这是很高的殊荣。&nbsp;</p>
  <p>所以即便当时没有谈妥，没有拿到前司投资人的同意豁免书，循环智能的两位联合创始人杨植麟和张宇韬，也在2023年4月17日正式创办了月之暗面。&nbsp;</p>
  <p>这里有个杨植麟采访透露出来的时间交叉，『我们2023年2月开始集中做第一轮融资。如果delay（延迟）到4月，基本没机会了』，也即在成立新公司前的4月份，杨植麟就开始了融资。这是他敏锐意识到，新公司获得投资的窗口期，其实就那一个月的时间。&nbsp;</p>
  <p>这期间金沙江等创投机构，是否知道月之暗面已成雏形，正在吸纳新资本就很关键。从红杉资本和真格基金等循环智能老股东参投进月之暗面看，同为老股东的金沙江等机构应该也知道这件事，但可能不是最早的2月份，而是知会邮件的3月份，双方对新公司留多少股份给老股东也有分歧。&nbsp;</p>
  <p><strong>2023年8月，月之暗面推出了他们的核心产品Kimi。这里不得不说，杨植麟确实是一位天才。</strong></p>
  <p>Kimi早期最具竞争的核心能力，在于它能够支持200万字的无损上下文输入，kimi的文本解析、长本文处理等方面都做得十分成功，使得很多白领在知识处理等领域，对kimi十分认可。&nbsp;</p>
  <p>Kimi间接促成了长本文大战，3月22日，通义千问升级，向所有人免费开放 1000 万字的长文档处理功能；360的智脑则内测 500 万字长文本处理功能；文心一言随之宣布将于4月升级，届时长文本能力预计将在200万-500万。&nbsp;</p>
  <p>2024年10月11日，月之暗面又上线具备AI自主搜索能力的Kimi探索版，搜索量是普通版的10倍，一次搜索可以精读500个页面。这是在OpenAI草莓大模型上线后，杨植麟的慢思考带来的产品化落地。&nbsp;</p>
  <p>其实从底层基础上看，月之暗面的大模型更新速度不太快。所以你在很多榜单前几名，很难看到kimi大模型，或者排名比较靠后。有行业人表示，kimi不是很重视大模型的训练，甚至SFT（监督微调）也做得不够多。&nbsp;</p>
  <p>但是在产品层面，kimi的用户口碑又不错，就是因为月之暗面对大模型推理侧调教的能力，以及功能上对市场需求的精准把控。这些能力让kimi看起来很强，但不一定是基础能力的体现。&nbsp;</p>
  <p>“o1的推理流程是LLM控制的，而不是predefined（预定义）』一位行业人士表示，真正大模型的能力强者是OpenAI的草莓大模型，很多大模型可能走了捷径。&nbsp;</p>
  <p>没有经常迭代大模型，这让月之暗面在企业服务和生态建设上也不急不忙。&nbsp;</p>
  <p>2024年8月，月之暗面方面正式宣布推出企业级API，月之暗面方才在B端市场开启了尝试。据透露，Kimi API专为企业级模型推理服务而设计，为行业提供定制化的AI解决方案。&nbsp;</p>
  <p>但实际上Kimi更侧重个人独立开发者，对企业不太在乎。在Questmobile报告中，相比豆包和通义都是成千上万个智能体，<strong>kimi仅有18个，原因是kimi还没有大规模开放用户创建。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_67d866558f644b7bbda22a843a41f1f8@6030424_oswg99761oswg960oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>月之暗面并不急于向生态展示实力，但是希望用户使用后获得效果，这是其当下的策略。</p>
  <h2><strong>2 激进战略惊到李彦宏</strong></h2>
  <p>『AGI是个长期探索的事情，“文小言”的推广没必要像豆包、Kimi那样激进』，这是百度创始人李彦宏，在百度2024年第三季度总监会上的发言。&nbsp;</p>
  <p>一家创立一年的公司，获得了BAT创始人的关注，并对其打法保持了警惕，这本身是件少有的事。&nbsp;</p>
  <p>实际上，坐落于在北京海淀的量子芯座大厦上，仅有200多人的月之暗面，确实还是个初创公司模样。但其对kimi的推广投放之凶猛，一点也不像初创公司。&nbsp;</p>
  <p>一位朋友曾和鲸哥讲述，他在2023年决定从大厂离职，因为自己受不了平淡的螺丝钉生活。&nbsp;</p>
  <p>他决定去做个周游四海的旅游博主，家人都劝他不要去，毕竟旅游博主竞争大，不赚钱花销还大。做了大半年，李朝确实感受到家长的良苦用心，一分钱没赚，机票酒店门票花了不少钱。&nbsp;</p>
  <p>好在最近做出了一个百万爆款视频，也意外让他获得一笔商单。<strong>谁都没想到的是，这笔商单尽然来自于一家大模型企业，不是更契合他账号定位的消费品公司。</strong></p>
  <p>这家公司就是月之暗面，通过腾讯互选广告平台找来，3000块一个视频。对于李朝来说，给钱就可以，尽管他还没用过月之暗面旗下的产品—Kimi。马上做个视频软植入下，用他话说“不懂就研究，这年头谁会和钱过不去啊。”&nbsp;</p>
  <p>这是月之暗面今年大规模投放的缩影，为了获取更多用户。kimi在字节的穿山甲、B站以及腾讯疯狂投放，科普博主投，旅游博主也投，甚至医学博主也投，拉爆Kimi 的下载量和用户活跃量。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e974fdf237a94fceb63e079c8d98dc60@6030424_oswg365314oswg1008oswg784_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>在市场疯传的三张表上，Kimi 在第三季度的投放金额高达1.5亿，尽管很多行业人士认为这张表的数据不一定准确，</strong> 但反映了一定的内在趋势。kimi 和豆包确实很舍得花钱。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e84849266be2423d81a9ce4ac67c257c@6030424_oswg187166oswg952oswg1108_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>另一方面，Kimi对产品也采取了一种极其激进的行业化策略：完全免费、不限次数使用。对比百度将文小言的文心4.0和4.0 turbo都收费，仅让文心3.5大模型免费的做法，很多人认为kimi十分敞亮。&nbsp;</p>
  <p>Kimi 仅在今年5月份首次试水商业化，采用打赏模式，付费入口有两个：一是在提示很忙时，二是用户可在网页端输入“我要打赏”，即可进入打赏界面。具体金额为5.2元/4天，9.99元/8天，28.8元/23天，49.9元/40天，99元/93天，399元/365天。&nbsp;&nbsp;</p>
  <p>以上这些火热的运营方式，配合密集的品牌曝光，根据QuestMobile数据显示，截止到2024年9月,kimi月活数达到1024.8万。这个数字虽然与超级App的过亿月活相差还很远，但作为一家AI创业公司，这样的增长速度已经相当惊人。&nbsp;</p>
  <p>几乎是同一时间，月之暗面也在市场上急招多模态（语音、文生视频）人才，不过月之暗面在多模态方面的投入已经持续了数月，今年5月OpenAI发布GPT-4o之际，杨植麟已在回复媒体时表态，“这个也是我们持续重点投入的方向，所以接下来也希望有更多的成果和大家分享。”&nbsp;</p>
  <p>据媒体报道，月之暗面还在美国市场推出两款产品：Ohai以及 Noisee，目前这两款产品已经暂停更新，出海战略按下暂停键。据月之暗面回复晚点财经称，做这两款产品只是尝试，并未正式立项，所以很快做出了调整。&nbsp;</p>
  <p>实话讲，豆包依托字节的流量体系，可以低成本投放推广和广泛布局AIGC产品，但对于kimi来讲，一家创业公司激进做法，让百度等老牌大厂也跟不起，这对于大家来说，是一件困惑的事情。如今看来，kimi更需要的是当下的成绩。</p>
  <h2><strong>3 资本支持梦想还是只想获益</strong></h2>
  <p>实际上，月之暗面仲裁的事情，已经在国内上演过一次，就是罗永浩和其投资人郑刚之间的恩怨。&nbsp;</p>
  <p>当时锤子科技难以为继，郑刚抵押了房子帮其借款1500万。但是罗永浩在决定卖掉锤子科技，再次创业细红线公司时，没有给郑刚等人足够的预留股份。郑刚认为，自己虽穷却是雪中送炭，新公司只预留约0.69%的股权，就要放弃在锤子科技十几亿的投资回购条款。而阿里吴妈是大富翁，不用他说，罗永浩都给留了很多股份，这不公平。&nbsp;</p>
  <p>因此依据提前的投资条款，提出了回购诉讼。月之暗面和金沙江等资本的事，还涉及不到这么多爱恨情仇，更多是资本利益的关系。&nbsp;</p>
  <p><strong>据第一财经报道，2024年3月份，月之暗面的估值水涨船高之际，循环智能投资人便提出希望获得月之暗面创始团队约50%的股权。</strong> 如此之高的股份索要，没有获得创始团队的同意。当然，这一消息并没有获得一方认可。</p>
  <p>最新消息是，月之暗面对仲裁提出回应：&nbsp;</p>
  <blockquote>
   <p>铭德律师事务所资深合伙人David Morrison律师表示&nbsp;本所已接受杨植麟先生、张宇韬先生委托，关注到相关仲裁事项。我们认为该事项既缺乏法律依据，也不具备事实基础，本所将依法提出抗辩。&nbsp;</p>
  </blockquote>
  <p>事情的演变，已经将水面下的争议抬到众人眼前。据暗涌报道，这其中不少资本一直在其中斡旋，很多重要投资方负责人甚至因此受到波及。&nbsp;</p>
  <p>在今年5月的财报中，阿里披露在2024财年向月之暗面投资合共约8亿美元，约购入36%股权。而这8亿美元并非全是现金，其中部分是以阿里云提供的算力来结算，实际出资金额不到6亿美元。&nbsp;</p>
  <p>当然，在阿里成为大股东之后，月之暗面也开始做了AB股权设计，这样确保杨植麟等人能够继续掌控公司的发展。<strong>据传月之暗面正在做新一轮的融资，老股东此时发难，也有着影响下一轮融资的谈判筹码，对创业公司来说，也是下了一招重棋。</strong></p>
  <p>现在看来，月之暗面这场豪赌本身伴随着巨大风险。如果无法在现金耗尽前获得新的资金支持，或发展多年后未能找到合适的并购方，过度透支的现金流可能会让这个雄心勃勃的创业项目陷入困境。&nbsp;</p>
  <p>随着2024年AI领域竞争的进一步加剧，月之暗面这样的创业公司将面临更大的压力和挑战。BAT等巨头在完善自身产品的同时，也在积极寻找可能的并购标的。在这场没有硝烟的战争中，月之暗面还需要处理本身产品、技术和市场之外的麻烦事，这对于技术天才杨植麟来说，可能并不擅长。&nbsp;</p>
  <p>但无论结局如何，月之暗面的故事都将成为中国AI创业浪潮中一个独特的注脚。它展现了创业者在面对巨大机遇与风险时的决断与魄力，也折射出资本在技术变革大潮中的躁动与彷徨。&nbsp;</p>
  <p>正如一位业内人士所说："在AI这个领域，或许真的只有两种结局：要么成为头部，要么被淘汰。月之暗面选择了一条最激进的路径，这是他们的豪赌，也是他们的宿命。"&nbsp;</p>
  <p>而眼下，资本正成为这场豪赌的不利筹码。&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/xZ9J_0zmX0hikYWukvGy6A" rel="noopener noreferrer nofollow" target="_blank">“AI鲸选社”</a>，作者：杨晓鹤，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033085285003522</id>
            <title>IPO失败，一位创始人体面退出</title>
            <link>https://www.36kr.com/p/3033085285003522</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033085285003522</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 08:59:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 并购, 兆易创新, 苏州赛芯, 清华校友  
<br><br>  
总结: 兆易创新拟以现金方式收购苏州赛芯70%的股份，交易总额为5.81亿元，吸引了创投圈的关注。此次并购的溢价率接近3倍，反映出市场对该交易的认可。苏州赛芯在经历了两年的IPO筹备后选择出售，给创业公司带来启示。兆易创新的收购将增强其模拟芯片团队实力，提升技术储备和产品线丰富度。并购市场在政策支持下逐渐活跃，但仍面临创始人对高估值的期待与实际市场情况的矛盾。随着市场环境变化，越来越多的创始人开始接受合理估值，推动并购交易的进行。 </div>
                        <hr>
                    
                    <p>一笔印象深刻的并购案浮出水面。</p>
  <p>近日，存储芯片设计领域上市龙头兆易创新宣布，拟于石溪资本、合肥国投、合肥产投共同以现金方式收购苏州赛芯70%的股份，交易总额高达5.81亿元。</p>
  <p>这笔交易迅速吸引创投圈的目光：一方面，买方兆易创新是市值超600亿元的芯片龙头，卖方也在模拟芯片赛道颇具知名度，双方掌门人还都是清华校友；另一方面，这笔并购溢价率接近3倍，在如今盛行打折并购的背景下，格外令人羡慕。</p>
  <p>此外，当中还有一个细节：苏州赛芯此前有过一段长达两年的IPO筹备之路，直至去年4月宣布终止。如今选择“卖身”，此番经历或许能给创业公司带来一丝启示。</p>
  <h2><strong>清华校友联手，缔造一笔半导体并购</strong></h2>
  <p>公告披露更多细节——</p>
  <p>根据专业机构对苏州赛芯100%股权截至基准日的价值评估，评估值为83,119.47万元；参考评估值，苏州赛芯70%股权的交易价格确定为58,100.00万元；其中，兆易创新以现金3.16 亿元收购苏州赛芯约 38.07%股份，石溪资本以现金 1 亿元收购苏州赛芯约 12.05%股份，合肥国投以现金1.5亿元收购苏州赛芯约18.07%股份，合肥产投以现金1,500万元收购苏州赛芯约1.81%股份。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_96cfc2d303b84ac09d557f847524bad4@000000_oswg29956oswg897oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>毫无疑问，兆易创新是此次收购的主力军。值得注意的是，兆易创新的董事李红、监事胡静，均在石溪资本任职；两家合肥国资此前也与兆易创新渊源深厚。此次收购中，石溪资本将其所持有的苏州赛芯股份的表决权委托给兆易创新行使，合肥国投和合肥产投也与兆易创新签署了《一致行动协议》。</p>
  <p>交易完成后，兆易创新将成为苏州赛芯的控股股东，苏州赛芯将成为兆易创新的控股子公司，纳入公司合并报表范围。同时，兆易创新还将拟向苏州赛芯提供1.3亿元借款，专项用于苏州赛芯归还贷款，使得银行解除对苏州赛芯所拥有苏州大楼的抵押。</p>
  <p>对于兆易创新，我们并不陌生——创始人朱一明，1989年考入清华大学物理系，并在硕士毕业后赴美深造。读书时，他参与过多家国际知名网络公司的项目开发，回国后敏锐捕捉到国内芯片设计的落后空白， 2005年在一众清华校友的帮助下成立兆易创新。2016年，兆易创新登陆上交所，如今市值超600亿元。</p>
  <p>对于此次收购，兆易创新资金颇为充沛。截至今年前三季度，兆易创新账面上的货币资金余额高达92.66亿元，而流动负债总额仅为19.69亿元。与此同时，公司第三季度营收达到56.5亿元，同比增长28.56%，盈利能力恢复，扣除非经常性损益后的净利润更是同比增长了128.31%。</p>
  <p>手握现金，兆易创新此次看上的也是一位清华校友——苏州赛芯创始人谭健，本科毕业于清华自动化系，同样曾赴美读博，直到2009年创立苏州赛芯。</p>
  <p>兆易创新在公告中表示，此次收购苏州赛芯是推动公司模拟芯片战略的重要举措。通过本次交易，兆易创新将能够进一步增强其模拟团队实力，提升技术储备和产品线丰富度，同时加强与联合收购方在技术、市场、产业链等方面的协同效应。这不仅有助于支撑兆易创新模拟业务在销售规模、产品深度和广度等方面的长远发展，还将显著提升公司的整体竞争力。</p>
  <h2><strong>IPO失败后，创始人体面卖掉公司</strong></h2>
  <p>被收购的苏州赛芯有何来头？</p>
  <p>公开资料显示，苏州赛芯主要从事模拟芯片的研发、设计与销售，主要产品包括锂电池保护芯片、电源管理芯片等产品，主要应用于移动电源、智能穿戴及其他通用领域，已在众多知名终端客户中得到使用，包括了小米、OPPO、vivo、荣耀、漫步者、 魅族、JBL、Anker、Belkin、麦克韦尔、南孚电池等知名品牌。</p>
  <p>这为苏州赛芯带来良好的业绩表现：2023年及今年上半年，公司分别实现营收2.51亿元和1.34亿元，实现净利润3494.58万元和3492.1万元。而此次交易也对其设定了业绩承诺：苏州赛芯在2024年度、2025年度和2026年度经审计的扣非归母净利润分别不低于6000万元、7000万元、8000万元。</p>
  <p>此前，公司早早踏上IPO之路：苏州赛芯2020年便进行IPO辅导备案，并在2022年初完成一笔2.15亿元的Pre-IPO轮融资，由国家集成电路产业投资基金二期领投，星睿投资、歌尔股份、国联集团跟投，用于主营产品锂电池保护芯片技术的研发以及新品的开发。当年6月，苏州赛芯IPO申请获科创板受理，不到一个月便进入问询阶段，十分迅速。</p>
  <p>彼时招股书显示，2020年8月，公司股东赛芯企管曾与王明旺、毕方一号签订股权转让协议，将其所持有的公司0.84%的股权作价800万元转让给王明旺，将1.05%股权作价1000万元转让给毕方一号。其中，王明旺正是锂电池龙头欣旺达的实际控制人之一。</p>
  <p>2020年9月，欣旺达子公司前海弘盛以及“元禾系”基金元禾璞华、元禾知产，以16.68元/股的价格，分别认购公司59.94万股、179.81万股、23.97万股。</p>
  <p>如若成功上市，以上股东将获得一笔可观收益。然而戏剧性的是，自2022年末首轮问询后，苏州赛芯IPO便进入停滞状态，直到去年4月宣布撤回申请，终止了在二级市场的上市计划。</p>
  <p>直到此次交易，一众投资方终于得以退出——</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_05426c554a384a9db5ca37f69dac10bc@000000_oswg33158oswg517oswg667_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>根据公告，被收购前，苏州赛芯在评估基准日的股东全部权益账面价值约为2.13亿元，而评估价值则高达8.31亿元，增值额达到6.18亿元——也就是说，这笔收购足足溢价289.48%。正如公告中表示，这一评估结果不仅验证兆易创新对苏州赛芯价值的认可，也为其未来的业绩增长提供了坚实的保障。</p>
  <p>更重要的是，这为身后投资人们带来十分可观的回报：根据所披露数据，此次交易完成后，苏州赛芯原实控人谭健将转让股份25.57%，拟转让出资额约1477.67万元，交易对价则为1.64亿元，获得约10倍回报。</p>
  <p>同时，元禾系的两只基金分别拟转让出资额179.81万元、23.97万元，交易对价金额分别为4355.26万元、580.34万元；欣旺达系基金及其实控人王明旺分别拟转让出资额59.94万元、59.94万元及47.95万元，交易对价金额分别为1468.93万元、1451.75万元和1175.39万元，顺利落袋为安。</p>
  <p>另外，如果在业绩承诺期内，苏州赛芯实际净利润累计数达到或超过承诺净利润累计数的70%，兆易创新将于完成苏州赛芯2026年专项审计后（最迟不晚于2027年6月30日），启动对除受让方外其余全部股东所持剩余30%股权的收购。</p>
  <h2><strong>珍惜被并购的机会</strong></h2>
  <p>所有人都期待着一场真正的并购潮。</p>
  <p>从“新国九条”提出支持上市公司并购重组、产业链整合；到“科创板八条”提高并购重组估值包容性；“创投17条”提出拓宽并购重组退出渠道；再到扶持力度空前的“并购六条”发布……短短几个月，并购市场肉眼可见地活跃起来。</p>
  <p>以半导体行业为例，今年已有约40家A股半导体产业链企业披露重大重组事件或进展。就在兆易创新宣布收购的前一天，科创板公司希荻微也发布公告，拟以发行股份及支付现金的方式买下芯片公司诚芯微100%股权。往前看，芯联集成、晶华微、东芯股份、富乐德等数家A股半导体公司，都找到了心仪的标的，推进或完成了重大资产重组事宜。</p>
  <p>清科研究数据显示，目前存量的PE基金里面，处于延长期和退出期的规模约合19万亿——在一级市场IPO节奏收紧的大背景下，迫切退出的企业和投资机构们涌入并购之路，似乎愈加理所当然。</p>
  <p>此前信宸资本合伙人王冉旭便表示，并购行业走到今天有它内在的增长逻辑，即在经济增速放缓情况下，市场上新的机会变少，将更多转向存量市场的博弈。</p>
  <p>并购时代还有多远？一位北京投资人表示，在一个上百人的并购讨论群里，中介发布的买卖方信息满天飞，从业绩要求到预期对价事无巨细，氛围火热。</p>
  <p>然而现实一面是，并购“井喷”一幕迟迟没有到来。清科研究中心数据显示，2024年前三季度，中国股权投资市场共发生1219笔退出案例，同比下降63%；其中并购类交易数量129笔，同比下降26.7%，交易活跃度反而呈现下滑趋势。</p>
  <p>究其原因之一，许多创始人和投资人仍期待着企业IPO后的高额回报，一时间难以接受降价卖身的结局。即使交易前期交谈融洽，但由于标的此前估值被抬得太高，仍然容易因双方估值预期差异太大而无法成交。</p>
  <p>但变化正在发生。随着IPO、融资情况愈加严峻，越来越多的创始人已经开始转变态度，在买方市场中谈到了合适的估值。一位北京VC分享，与买卖双方年初在价格上的难以调和不同，他认识的一些创始人正在主动降估值，拉低姿态，诚意十足。</p>
  <p>当并购被视作寒冬里难得的出路，那些还能坐上谈判桌的企业，已经十分幸运。</p>
  <p>另一方面，市场上量变带来质变，标杆性案例不断涌现，市场服务于并购交易的熟练度得到提升。例如此前思瑞浦发行可转债及支付现金购买创芯微100%股权，采取差异化作价和评估值方案的新思路，使各方投资人平衡收益、圆满退场，让并购市场看到仍有各方多赢的可能性和创新操作的空间。</p>
  <p>正如清科研究中心报告指出，我国并购投资步入行业整合阶段，由“机会型”交易向“系统性”交易转变，并购市场发展进入历史拐点。</p>
  <p>这一幕令人期待。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247666704&amp;idx=1&amp;sn=2150c630b4fed8659a8292d8d2cb724a&amp;chksm=edbe6900d1601f424bad6fcf1e8f3b9a28fcbf424cd1aa1fb19c6431faa0976ceb7e0398a372&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：岳笑笑，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3032871277031433</id>
            <title>应用突破还是炫技噱头：大模型能否真正驱动行业升级？</title>
            <link>https://www.36kr.com/p/3032871277031433</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3032871277031433</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 08:47:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 行业升级, 数据隐私, 医疗应用  
<br><br>  
总结: 本文探讨了大模型技术在各行业，尤其是医疗领域的应用与影响。大模型与代码的结合能够提升团队的工作效率，并通过私有化部署解决数据隐私问题。医疗领域的需求复杂，临床辅助决策系统的病历生成是重要应用场景。通过推理模型，医疗诊断过程可以更高效地进行。多模态大模型在处理医疗影像时，通过多轮交互提高了诊断准确性。此外，模型的评估应由专业医生进行，而非单纯依赖榜单排名。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_ab8f09eb44ef496e87f0eeac28257937@000000_oswg52856oswg720oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>大模型如何驱动行业升级？</p>
  <p>近日 InfoQ《极客有约》X AICon 直播栏目特别邀请了商汤科技大模型技术总监张涛担任主持人，与百度灵医大模型底座技术负责人夏源和京东零售 AIGC 技术专家，在 AICon 全球人工智能开发与应用大会 2024 北京站即将召开之际，深入探讨大模型技术在垂直行业落地的见解。</p>
  <p>部分精彩观点如下：</p>
  <ul>
   <li>代码和大模型的结合能够为团队提供更广泛的支持。</li>
   <li>私有化部署的策略可以有效地解决数据隐私问题。</li>
   <li>由专业医生进行的真实评估，比榜单排名更能反映模型的实际效果。</li>
  </ul>
  <p><strong>以下内容基于直播速记整理，经 InfoQ 删减。</strong></p>
  <p><strong>张涛：各位最近主要关注大模型的哪些话题，有没有可以分享的观察或体会？</strong></p>
  <p><strong>张涛：</strong> 我个人主要关注大模型和生产力工具结合方面，特别关注 Claude 大模型，尤其是针对代码能力的增强。最近，Claude 发布了一个名为“computer use”的产品 Demo，展示了大模型如何接入操作系统桌面并生成操作键盘和鼠标的代码，它展示了大模型在生成代码操作电脑方面的潜力。但是，我对大模型在操作电脑时使用视觉分析屏幕的方式有所担忧。这种方式实际上消耗了很多不必要的资源，因为计算机的很多元素本身就是代码形成的，理论上可以直接定位并操作，我认为这背后有很大的提效空间。</p>
  <p><strong>夏源：</strong> 最近我特别关注 Claude Sonnet 3.5 新模型和它的 computer use 功能；另外还有 OpenAI 的 o1 大模型，推理能力的巨大提升让我思考如何将这些技术应用于医疗领域。</p>
  <p>我们一直在思考如何利用推理技术提升诊断效果。从抽象层面来看，基于推理模型给患者看病的过程类比于在棋盘上下棋，类似于 AlphaGo，模型预测棋子在棋盘的落地空间分布概率和最终输赢的概率分布，而在疾病诊断，我们通过问诊（症状空间预测），不断排除和逐步缩小可能疾病诊断空间，最终得到一个最优的诊断结果分布。最近关于 OpenAI o1 的相关论文解释中提到的推理模型的 Scaling Law，它在推理阶段采样不同的推理路径和思维链，通过过程奖励逐步提升每一步思维的效果，最终提升整体推理能力。<strong>这与我们的诊断思路相似，我们也是通过采样成百上千条问诊路径，并通过逐步的过程奖励来提升每一步问诊的逻辑，最终得到更优质的问诊路径</strong>，然后通过强化学习进行大模型调优训练。</p>
  <p><strong>张涛：大模型技术已经渗透在各个行业，你们认为大模型带来了哪些最显著的变化？</strong></p>
  <p><strong>夏源：</strong> 医疗领域对大模型的需求复杂多变，通过和业务方沟通我们发现，临床辅助决策系统的病历生成是更符合医院需求的应用落地场景。病历生成虽然看似简单，实际上涉及大量文档处理和医生书写工作，大模型能简化这一过程，极大提升医生的工作效率，减轻他们的负担。</p>
  <p>另一方面，在比如病案质控相关问题，我们也遇到了难题，这需要模型有细致发现病历潜在的缺陷问题。尽管尝试了规则和小模型，但效果有限，单纯大模型在这方面的能力也有所不足。因此，我们正在考虑使用 agent 方式来进一步探索解决方案。</p>
  <p><strong>张涛：</strong> 去年年初，我们已经开始着手开发代码小浣熊。最初，我们的目标是将生成式能力融入代码中，以帮助编程工作。随着项目深入，我们逐渐发现代码的能力不仅仅局限于编程，当代码能力提升到一定程度，其编译运行的概率增大后，我们有能力将其与虚拟环境联合训练，使其成为一个代码 agent。这样的 agent 能够实现更大的能力，比如与其他工具的调用和集成。</p>
  <p>现在，我们的团队不仅仅局限于开发人员，运维人员在进行问题筛查、运营人员在处理数据、产品经理在进行产品头脑风暴或编写产品需求文档时，都会利用大模型来生成更好的内容。这表明，代码和大模型的结合不仅能够提升开发效率，还能够扩展到其他工作领域，为团队成员提供更广泛的支持。</p>
  <p><strong>张涛：数据隐私和合规性是包括医疗在内的各企业应用中无法回避的挑战，应如何看待大模型和编程助手在确保数据安全性和合规性方面的作用？</strong></p>
  <p><strong>夏源：</strong> 医疗领域主要关注两个方面：模型训练和实际应用情况。模型训练方面，我们需要大量的医疗数据，这些数据主要来自 C 端和 B 端。C 端数据相对容易处理，包括百度健康平台的 UGC 内容和医生审核的精编内容等，这些高质量的数据可用于预训练。B 端数据则涉及与一些权威数据库合作，用于预训练和内容挖掘。实际应用阶段，在医院数据层面，我们面临的问题较大，因为并非所有医院都愿意分享数据，尤其是涉及隐私问题，尽管数据都会进行严格脱敏。为了解决这个问题，我们采取了 <strong>模型私有化部署的策略</strong>，这是 B 端尤其是医疗大模型非常重要的一环。</p>
  <p>为了适应医院的需求，我们将大模型容量进行蒸馏，将其精简到百亿参数级别甚至更小，以实现病历生成和智能诊断等功能。同时，我们也支持国产芯片，如华为的昇腾 NPU、海光的 DCU 以及百度的昆仑芯片，以实现私有化部署。对于没有能力采购 GPU 的医院，我们提供了 CPU 版本的大模型，并与芯片厂商合作，针对特定模型架构进行专有适配，提升推理效率，确保模型能够私有化部署。通过私有化部署，我们可以有效地解决数据隐私问题，因为所有数据都保留在医院内部，不会外泄，从而消除客户的疑虑。</p>
  <p><strong>张涛：</strong> 我观察到 Claude 新发布的模型 Demo，以及像 cursor 这样的项目，它们已经开始引入多模态技术。这些技术能够处理如将图片输入后直接复刻网页或 APP 布局的任务。在我的理解中，这种素材生成技术在零售领域可能会有应用。在医疗领域，传统的 AI 或者说 AI 1.0 时代，主要依赖计算机视觉技术来分析病理图片、CT 图像等，进行问题检查。而现在，随着新大模型的出现，医疗领域也拥有了更多前沿的能力。</p>
  <p><strong>夏源：</strong> 我们没有追求开发一个通用模型来处理所有类型的医疗影像，如肺炎、CT、X 光等，尽管这些在研究领域和学术论文中非常常见。相反，我们结合了百度健康上的用户数据，发现皮肤病相关的图片查询是一个比较高频的场景。因此，我们专门针对皮肤病开发了一个多模态大模型。</p>
  <p>传统的计算机视觉方法可能在用户上传图片后立即给出诊断，但这种方法缺乏多轮交互，可能导致信息缺失，影响准确率。而我们的多模态大模型通过询问一些患者信息，结合图片信息，最终给出诊断。这种方法在皮肤病领域会优于单轮仅用视觉模型的图片诊断效果。</p>
  <p>此外，我们也在探索中医领域的应用。虽然中医大模型可能没有受到广泛关注，但许多机构和厂商对此有需求。我们之前已经为一家企业开发了中医大模型，同时并在 C 端推出了基于中医的多模态大模型，包括面诊、手诊等模型，通过统一架构以实现这些功能。这些是我们在医疗领域一些更偏向实际应用的探索。</p>
  <p><strong>提问：</strong> 这个模型是在百度本身的文心一言基础上构建的吗？如果是的话，团队主要的工作是在模型预训练时还是在后续微调中进行的呢？benchmark 有对标吗？</p>
  <p><strong>夏源：</strong> 我们的工作主要集中在两个方面：预训练和指令微调。预训练阶段，我们依托于百度的文心一言这一基础模型，它已经经过了大量的通用数据语料训练。我们没有必要从头开始训练一个通用大模型，因为文心一言已经为我们提供了一个坚实的基础。在此基础上，我们结合了百度健康上的 C 端数据、权威书籍、B 端的权威数据，以及药企咨询数据等这些数据经过脱敏和处理后。利用这些数据，在文心一言的基础上进行了后预训练，得到了一个干净的医疗基础模型。接下来，我们在这一基础模型之上进行特定应用的 SFT，包括病历生成、辅助诊断、智能问诊、医疗问答、医疗分析以及治疗推荐等业务相关的指令，共同构建起业界首个企业级的医疗大模型。</p>
  <p>针对 benchmark，我们刚开始有去对标一些医疗 benchmark。然而，随着时间的推移，我们发现许多医院和企业不再那么关注排行榜，大家逐渐认识到单纯追求榜单排名并不是必要的。我们转变了策略，开始与三甲医院的医生合作，让他们帮助我们评估模型的性能，并为模型的诊断能力提供背书。我们认为，这种由专业医生进行的真实评估，比单纯的榜单排名更能反映模型的实际效果。</p>
  <p><strong>张涛：</strong> 编程领域现在有一种趋势，即通过识别图像来复刻产品，这已经被许多公司和创业团队作为一种酷炫的演示展示出来。然而，在实际应用中，目前的模型还没有达到在不同维度的数据空间内有效关联信息的水平。<strong>对于这些令人印象深刻的演示，我持怀疑态度，我认为可能 80% 都需要在上层进行工程化处理。</strong> 我并不是否认它们的通用性有问题，而是觉得这些演示在 AI 能力真正发挥作用的成分上可能并没有大家想象的那么大。它们可能只是恰好发挥了能力，解决了之前大家束手无策的问题。</p>
  <p>目前，我们也在探索如何处理多模态数据，例如处理 PDF 文档，其中可能包含扫描文档和图像。我们希望像办公小浣熊这样的工具能够准确地提取这些信息，并将其作为处理的输入，以便根据用户的需求完成任务。</p>
  <p><strong>张涛：我们已经看到大模型在各个领域的应用不断深化。未来大模型技术在哪些方面会有突破性进展？是否有尚未被广泛讨论的潜在应用领域？</strong></p>
  <p>夏源：我简单分享一下我在业内技术层面上的一些观察。我注意到，像 Hinton 这样的学者认为 AGI 非常危险，因为他们认为在某种程度大模型已经达到了所谓的 AGI。然而，另一派，比如 CNN 的发明者 Yann LeCun，也是图灵奖得主之一，他认为大模型并不是通向世界模型的最终之路，仅靠 next token 预测是远远不够的，他们认为可能还需要考虑物理因素交互等，才可能真正构建一个世界模型。最近，李飞飞也组建了一个团队，旨在开发感知、生成 3D 世界，并与之进行交互的大世界模型（Large World Models）。各位学界大佬自都有其各自道理，我们可能需要在未来，比如 20 年或 50 年后，回过头来看他们的观点究竟如何。</p>
  <p>目前，简单来说，我认为像 Transformer 这样的模型，如果你拆开它的代码，其实就是一系列简单的矩阵计算的组合。<strong>这样的最本质的矩阵计算能否实现通用人工智能，说实话，我并不知道，不过可能世界就是“大道至简”的，越是简单的东西可能才是真正通往 AGI 的方式。</strong> 可能很多年后，真的有人会揭开这个谜团。比如我们现在说神经网络是黑盒模型，它背后的物理或数学意义可能就蕴含在这些简单的公式之间，但我们目前还不清楚。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247627022&amp;idx=2&amp;sn=14d1d2e04ba4f8e1f1a45ff7109c4262&amp;chksm=fa8bba130c865fd667682752a54e3cf6c3845f6be83190878523ed88b511fc4159cde1154f85&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“AI前线”（ID：ai-front）</a>，作者：罗燕珊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033022349373700</id>
            <title>谷歌推出教育AI产品“Learn About”，步步引导，多模态呈现</title>
            <link>https://www.36kr.com/p/3033022349373700</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033022349373700</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 08:37:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 教育产品, AI工具, 学习方式, 谷歌  
<br>
<br>
总结: 谷歌推出的“Learn About”是一款基于LearnLM AI模型的教育工具，旨在通过对话帮助用户掌握新主题并加深理解。该工具结合高质量内容、学习科学和聊天体验，提供多模态的回复，包括文字、图片和视频，采用教科书式的风格进行引导。它的设计理念是将信息转化为理解，适合中小学教师备课和学生自学。尽管目前仍处于实验阶段，但“Learn About”展示了教育AI产品的创新潜力，强调逐步引导和激发学习兴趣的重要性。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6657ce595cb6495ca60f05d9041cca90@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <blockquote>
   <p><strong>单从教育产品的角度来说，这已经是一个创新。</strong></p>
  </blockquote>
  <p>11月11日，谷歌推出了一款名为“Learn About” 的实验性的新 AI 工具，它不同于此前的聊天机器人，如 Gemini 和 ChatGPT。它是基于谷歌今年春天推出的LearnLM AI 模型构建，并称其“以教育研究为基础，并根据人们的学习方式量身定制”。它提供的答案具有更多视觉和交互元素，并采用教科书式的风格。</p>
  <p>谷歌官方表示，“Learn About” 是对话学习伴侣，通过对话可以掌握新的主题，加深理解，适应用户独特的好奇心和学习目标。</p>
  <p><strong>“Learn About” 主要是探索信息如何转化为“理解”，将高质量内容、学习科学和聊天体验结合在一起。</strong>问一个问题，它会通过图片、视频、网页和活动引导用户以自己的节奏了解任何主题。</p>
  <p>“Learn About” 底层是基于LearnLM模型，这是基于谷歌大型语言模型Gemini的一系列 AI 模型，旨在成为各个学科的专家，以不同的方式找到展示例子（如照片或视频），在学习过程中辅导学生，并激发学习的兴趣。</p>
  <p>多知体验“Learn About” 观察到，“Learn About” 是一个专门针对教育的产品，目前或仅支持英语提问，其回复方式很像老师，步步引导，且从易到难层层递进，回复格式像教科书，还有背景知识的关联。<strong>“Learn About”有的回答还做了“停下来思考”的效果，先引导用户想一下，然后用户点击翻转才能查看答案。可以说，用户不管是在理论知识还是动手实验都能带来启发，这款产品非常适合中小学学校老师用来备课，或者学生自学。</strong></p>
  <p>“Learn About” 是谷歌在教育领域的一个新尝试，背后包含了Google DeepMind和Google Research等团队的共同努力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_8f74b848b95f44ef8788cb80464de315@000000_oswg407430oswg1080oswg712_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>01</strong></h2>
  <p>&nbsp;步步引导，回复格式带有教科书的风格</p>
  <p>进入主页，“Learn About” 的slogan是“今天你想学什么？”，<strong>其官方给出的提示问题涵盖历史、艺术、地理、天文、科技等领域，还包括生活的小技巧。</strong></p>
  <p>“Learn About” 支持文字和图片输入，在多知体验中，提出了谷歌官方提示问题“是什么导致有些海洋生物可以发光？”，“Learn About” 很快给出了答案，一些海洋生物发光的能力被称为生物发光。当生物体内的化学反应产生光时，就会发生这种现象。这就像一个内置的手电筒！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a42868db86c54de1886a5fe684afe2f8@000000_oswg314737oswg1080oswg656_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（关于“是什么导致有些海洋生物可以发光？”问题）</p>
  <p>除了文字回复之外，“Learn About” 还给出了图片和讲解的视频，点击视频就会跳转到YouTube，视频来自专业机构“国家地理儿童版”的科普视频。</p>
  <p>进而，“Learn About” 还提到：“你知道吗，生物发光在海洋中比在陆地上更常见？这是因为大部分海洋都是黑暗的，所以生物才进化出这种惊人的生存能力。”</p>
  <p>值得注意的是，由于是实验版，“Learn About” 初次使用还会给出提示：回复的答案有可能会遇到不准确或误导性的信息，所以请再次检查回复，并通过在结果上提供反馈来帮助改进“Learn About”。<strong>可以看到，跟大多数生成式AI产品一样，“Learn About”每次输出的答案并不一致。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_7c65fbfe102a4376b89c2380f7251b14@000000_oswg101084oswg740oswg180_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>总体来说，“Learn About”的回复是多模态的，既有文字，还有图片和视频。<strong>“Learn About”文字回复风格很像一个老师，给出的讲解生动形象，还会进一步引导用户思考，视频内容则来自专业的机构，所有内容都有很强的学习性，不是简单的提供事实和定义。</strong></p>
  <p>除此之外，在左侧，还添加了相关的学习主题提示，如果点击可以进一步学习。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_291148ed87aa44eb81f6feadfb186198@000000_oswg67815oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（左图为“Learn About” 原图，右图为翻译成中文的图片）</p>
  <p>如果进一步了解，有的专业术语还会给出发音，还会像“教科书”的格式一样给出背景信息，如需了解详情可以点击官方链接的专业教育网站。</p>
  <p><strong>可以看到，“Learn About” 这种方式对于有探索欲望的用户来说，可以一步步了解到自己感兴趣的全部知识，从点到面均有涉及。如此一来，也可以帮助用户构建相关知识体系。</strong></p>
  <p>多知又提问了一个科学实验的问题“八岁小孩想做“磁悬浮实验”，怎么做？”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_dfe7420551cb4d7ea78756d0ec3d2524@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（多知提问“八岁小孩想做‘磁悬浮实验’，怎么做？”）</p>
  <p>“Learn About” 给出了图文并茂的实验步骤，包括材料准备、工作原理解释，还给出了“磁悬浮”词汇解释，底部探索相关内容还链接了有关视频，左侧还有磁悬浮的相关知识点，点击可以进一步了解。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_1a00b6dec0574ca6b72f1b462166d7ad@000000_oswg280805oswg1080oswg847_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（多知提问“八岁小孩想做‘磁悬浮实验’，怎么做？”）</p>
  <p><strong>最重要的是，“Learn About” 所有步骤都是引导式的，甚至还有“停下来思考”的引导。</strong>先让用户想一下“您能想到任何使用磁悬浮的实际应用吗？”然后用户点击翻转才能查看答案，“一个突出的例子就是磁悬浮列车！它们使用强大的磁铁将列车稍微抬高到轨道上方，从而实现超快速和平稳的运行。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_537b13b3a4e148818e86bc9b822a4073@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>从引导方式来看，将实验引导到生活实际应用，符合教育的目的。</strong></p>
  <h2><strong>02</strong></h2>
  <p>“搜索+AI”将成为主战场？</p>
  <p>“Learn About” 底层是基于LearnLM 模型，但从“Learn About” 的整体思路来看，其核心是“搜索+AI”，目前很多搜索工具已经有类似的方式，比如perplexity.ai、秘塔搜索等。</p>
  <p>多知用第一个测试问题体验了Perplexity.ai、秘塔搜索，可以看到与“Learn About” 有一些不同。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d2f1ab8324344f9481531c65d7855c3b@000000_oswg328331oswg1080oswg502_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（perplexity.ai）</p>
  <p>Perplexity.ai支持中文，亦会给出多模态的回复，主要是文字，右侧有图片和视频，但是其答案像学术论文一样，是非常专业的方式。如果继续了解，最后相关问题的提示。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d73c6dd22e7b41a5ac0254d993c7fcca@000000_oswg322157oswg1080oswg811_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（秘塔搜索）</p>
  <p>秘塔搜索亦是可以给出多模态的回复，图文并茂，右侧还可以生成脑图、大纲和演示文稿，没有视频，如果想进一步了解，底部有相关事件、相关人物的索引。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_01462b62768c45a0b1c1f8c4037afc03@000000_oswg409321oswg1080oswg1485_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>总体来看，“Learn About” 更集中在教育内容，且回复方式是从易到难层层深入，引导用户思考，让用户最终“理解”。此外，回复内容从词汇到纵深的知识均有覆盖，点面结合。而Perplexity.ai和秘塔搜索更偏向直接给出最终结果。</p>
  <p><strong>可以说，“Learn About” 更像一个学习产品，学校各科老师都可以利用它进行备课，学生也可以自学。</strong></p>
  <p>值得注意的是，市面上的搜索AI产品虽然火爆，也会面临版权纷争。</p>
  <p>美国新闻集团旗下的道琼斯公司（《华尔街日报》的出版商）和《纽约邮报》在今年10月都对Perplexity提起诉讼，指控Perplexity对其受版权保护的作品进行了“大量非法复制”。</p>
  <p>而早在今年8月，秘塔科技收到《中国学术期刊（光盘版）》电子杂志社有限公司（即“知网”）长达28页的侵权告知函。</p>
  <p>“Learn About” 引用的也是教育专业网站、出版机构以及YouTube上的内容，其中一大优势是YouTube是谷歌的，其他内容是否会有版权问题尚没有答案。</p>
  <p><strong>谷歌“Learn About” 还处于实验阶段，未来有望在各方面进一步完善。单从教育产品的角度来说，这已经是一个创新。从趋势来看，教育AI产品均不会像通用大模型那样直接给答案，而是步步引导，激发兴趣，引发思考，从而达到教育的目的。</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU1Mjc4NjM4Mg==&amp;mid=2247572148&amp;idx=1&amp;sn=1369a2e70eec7eb47d5d776db9e49437&amp;chksm=fa4e89444dc3667a810fda97d9e889abdd469ea3440b79268d03a6764d60fbbeef30d1999355&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“多知网”（ID：duozhiwang）</a>，作者：王上，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033056826913033</id>
            <title>马斯克招人策略曝光：9轮面试，底薪低于同行，只招“铁杆特斯拉人”</title>
            <link>https://www.36kr.com/p/3033056826913033</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033056826913033</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 08:30:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 特斯拉, 薪酬, 股票奖励, 招聘策略  
<br><br>  
总结: 特斯拉采用低底薪加股票奖励的薪酬策略，旨在吸引对公司有强烈认同感的员工。尽管特斯拉的底薪普遍低于同行业公司，但员工愿意接受这一点，主要是因为股票奖励的潜在高回报。特斯拉的招聘流程严格，通常需要多轮面试，以确保招聘到真正热爱公司的员工。虽然只有少数员工能获得高额股票奖励，但特斯拉的公司形象和使命感也吸引了许多求职者。 </div>
                        <hr>
                    
                    <p>要想进入特斯拉，先得接受低底薪才行？！</p>
  <p>事情是这样的。</p>
  <p>Business Insider最近获得了特斯拉内部薪酬数据库（截至2021年12月）的访问权限，里面有<strong>10万名</strong>员工的薪酬数据。</p>
  <p>然后他们发现了有关特斯拉薪酬的<strong>一系列猛料</strong>：</p>
  <p>面试9轮只为招聘特斯拉铁粉；</p>
  <p>采用低底薪+股票奖励策略，打出“高风险、高回报”口号；</p>
  <p>特斯拉底薪低于同行，不及苹果、谷歌、英伟达、Meta、福特等科技公司和传统汽车制造商；</p>
  <p>工程师更有可能获得股票奖励；</p>
  <p>仅有4%的员工通过激励股票期权（ISOs） 获得股票，且通常授予高管；</p>
  <p>……</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d7bacd030e3d4d1697af70ad314f6997@46958_oswg109788oswg297oswg223_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>更多爆料细节如下——</p>
  <h2><strong>马斯克招人策略：低底薪+股票奖励</strong></h2>
  <p>透过这份曝光的内部薪酬文件，我们看到特斯拉向员工喊出的是“高风险、高回报”这一口号。</p>
  <p>why？？</p>
  <p>一切的一切，还是归于特斯拉想要招聘自身铁粉。据一位了解招聘的内部员工透露：</p>
  <blockquote>
   <p>他们可能在别处得到更好的报酬，但我们想要的是铁杆的特斯拉人。</p>
  </blockquote>
  <p>而为了实现这一目标，特斯拉主要靠<strong>“低底薪+股票奖励”</strong>这一策略以及<strong>配套的招聘系统</strong>。</p>
  <p>对于前者，一位特斯拉前销售经理将其比喻为“金手铐”：</p>
  <blockquote>
   <p>股票是主要的钩子……我要低下头再等几个月，直到我获得股权。</p>
  </blockquote>
  <p>至于后者，一位特斯拉前招聘人员表示，前司的招聘流程极为严格，通常需要几个月时间来考察面试候选人。</p>
  <p>比如面试一位工程师，通常至少包括<strong>九次面试</strong>，可能需要<strong>数月时间</strong>。</p>
  <blockquote>
   <p>这是一件文化上的事情，一切都是为了排除掉只想“打卡上下班”的员工。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_0a2c70ead9424ee4a5d38ea857ac862a@46958_oswg59238oswg1080oswg952_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>那么，特斯拉到底给员工们开了多少薪酬呢？</p>
  <p>这里需要补充一个员工人数数据。在这份文件里，我们可以看到10万名员工的薪酬情况，而据CNBC报道，截至今年6月，特斯拉雇佣了大约12万名员工（包括正式员工和临时工）。</p>
  <p>下面具体来看。</p>
  <p>第一，先从公司内部来看。</p>
  <p>首先，Business Insider分析了大约<strong>13,000名全职、有薪、美国本土员工</strong>的平均基本工资（年薪），这些员工分属特斯拉的各个业务部门（如工程、制造或数据管理），而且排除了无法准确计算平均年薪的小时工。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_63946a5854274dbd9a0249044089bc50@46958_oswg221507oswg1080oswg723_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>可以看出，这些员工的基本工资中位数（年薪）大多在10万美元和15万美元之间。</p>
  <p>接下来，Business Insider进一步将数据细分，并查看特斯拉管理岗（全职、美国本土员工、有薪且手下至少有五名员工）的基本工资情况。</p>
  <p>结果显示，包括工程总监和在特斯拉服务中心维修车辆的经理在内，这些人的基本工资中位数（年薪）从大约35,000美元到324,000美元不等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_4e0274bdc87e4a93b4e312dae61f73b2@46958_oswg278042oswg1080oswg1120_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>而且据9位现任和前员工透露，自2021年12月以来，<strong>特斯拉的薪酬结构基本保持不变</strong>。</p>
  <p>换句话说，虽然上述数据看起来老旧，但特斯拉目前仍在延续这些薪酬方案。</p>
  <p>不过，只看内部情况，我们可能无法直观感受特斯拉的“低底薪”。</p>
  <p>别急，Business Insider还另外使用了来自证券交易委员会的数据，将特斯拉的基本工资与传统汽车制造商以及市值最大的六家科技公司进行了比较。</p>
  <p>可以看出，除了亚马逊，特斯拉均处于落后地位。</p>
  <p>而且我们知道，像亚马逊和苹果这样的公司，它们还拥有庞大的仓库劳动力和零售劳动力，这些因素也会影响公司的平均工资。</p>
  <p>因此，一个基本情况浮出水面：</p>
  <blockquote>
   <p>特斯拉的基本工资通常低于竞争对手</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a30860fc2b0847dfa126708ff674df1f@46958_oswg126702oswg1080oswg539_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>那么，接下来的问题是：员工为什么愿意接受低底薪呢？</p>
  <p>最大原因还是在于<strong>股票</strong>。</p>
  <p>9位现任和前工程师及销售人员表示，特斯拉的股票授予计划使得他们更容易接受较低的底薪。</p>
  <p>据悉，过去5年，特斯拉的股价飙升超过1000%；而今年，虽然特斯拉股价经历了显著波动（4月中旬跌至年初价格的44%），但在川普成功竞选后，特斯拉收获重大利好，其股价至今累计上涨近30%。</p>
  <p>so，又有多少员工能享受到特斯拉的股票奖励呢？</p>
  <p>据内部文件显示，2020年和2021年，有<strong>44名</strong>美国本土员工获得了价值<strong>超过100万美元</strong>的股票。</p>
  <p>为了了解哪些员工更有可能获得股票奖励，Business Insider根据<strong>职位类别</strong>对股票奖励进行了拆分。</p>
  <p>结果显示，大多数<strong>工程师</strong>收到的股票奖励超过25,000美元。（股票的价值基于授予时的股价，但会根据特斯拉的股价变动而变化）</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6db16fa18ecc40a4a9cef6887eb171c1@46958_oswg157008oswg1080oswg909_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>不过需要注意的是，特斯拉将限制性股票单位（RSUs）作为薪酬结构中的主要组成部分，约占薪资发放的75%。</p>
  <p>解释一下，RSUs指授予时并不立即转化为实际的股票，而是在一定时间锁定期后，以公司股票的形式提供给员工。</p>
  <p>换句话说，员工在满足特定条件（如服务年限或公司业绩目标）后才能获得RSUs股票。</p>
  <p>同时，特斯拉将非合格股票期权（NQSOs） 作为基于业绩的薪酬的一部分，占薪资发放的21%。</p>
  <p>最终，<strong>仅有4%的员工</strong>通过激励股票期权（ISOs） 获得股票，且通常授予高管和其他高级员工。</p>
  <p>而对于这一部分，内部文件显示，特斯拉高管中，除一名未列出持股数量的员工外，其余人收到的股票价值在95万美元至2000万美元之间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_de6f568b751d4aa88b4677a4990e1287@46958_oswg49752oswg1024oswg896_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>除了股票，另一大原因在于<strong>特斯拉的公司形象</strong>。</p>
  <p>按照招聘公司Stanton Chase一位总监的说法：</p>
  <blockquote>
   <p>它包含一个以使命为导向的元素……这些人正在努力实现地球的脱碳。</p>
  </blockquote>
  <p>更不必说，还有CEO马斯克这位顶流的卖力宣传（doge）：</p>
  <blockquote>
   <p>我们给每个人股票期权，我们让许多只是在工作一线的人——甚至不知道股票是什么的人——变成了百万富翁。</p>
  </blockquote>
  <h2><strong>马斯克560亿美元天价薪酬案将于年底见分晓</strong></h2>
  <p>那么，老马本人在特斯拉的薪酬水平如何呢？</p>
  <p>事实上，<strong>“马斯克560亿美元天价薪酬案”</strong>一直引人关注：</p>
  <p>2018年，特斯拉为马斯克制定了一项为期10年的激励计划，方案核心是通过股票期权的方式，将马斯克的个人利益与公司的市值和业绩紧密绑定。</p>
  <p>简单说，一旦老马能完成KPI，他将累计获得特斯拉12%的股票期权作为奖励，总价值约为560亿美元，这一方案也被外媒认为是美国有史以来规模最大的高管薪酬方案。</p>
  <p>当然了，当时来看公司定的KPI非常难，结果没想到后来特斯拉一路起飞，市值大涨（目前已来到1.12万亿美元）。</p>
  <p>这下就有股东跳出来，觉得不公平了。</p>
  <p>2022年，特斯拉的部分股东将马斯克告上法庭，称他将大部分精力花在SpaceX等其他公司上，同时利用其对公司及董事会的控制敲定了长期薪酬计划，因此希望废除该方案。</p>
  <p>紧接着，特拉华州的法官便以“对股东不公平”为由，宣布马斯克的长期薪酬方案无效。</p>
  <p>面对这一判决，老马一怒之下宣称将特斯拉的注册地从特拉华州迁至得克萨斯州。（后来确实迁了）</p>
  <p>并进行了上诉。</p>
  <p>而最终结果，将在<strong>今年年底前</strong>得到裁决。</p>
  <p>就在上周四，负责审理此案的特拉华州衡平法院大法官凯瑟琳・麦考密克（Kathaleen McCormick）表示，她将在 2024年年底前作出最终决定。</p>
  <p>不过，尽管之前的法院判决不利于老马，但特斯拉股东在2024年6月13日的年度股东大会上，已经以较大优势批准了这一薪酬方案。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_72406bc5b59a4fc890b0be599564dcc0@46958_oswg197345oswg490oswg490_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>参考链接：https://x.com/BusinessInsider/status/1855915725153595824</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/JCGC27mVfemdbLLA2vUHPA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：一水，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033040283857796</id>
            <title>AMD新核显性能媲美4070，APU将成AI PC主流方案？</title>
            <link>https://www.36kr.com/p/3033040283857796</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033040283857796</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 08:30:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 核显, AMD, AI PC, 性能提升  
<br><br>  
总结: 本文讨论了AMD新一代核显的性能提升，指出其将与高端独立显卡竞争，尤其是Radeon 8060S的CU单元数量显著增加，可能接近RTX 4070的性能。AMD通过chiplet分离式设计和集成HBM3内存，解决了显存带宽问题，提升了核显性能。随着AI技术的发展，核显的用途也在转变，成为AI算力的重要组成部分。APU的设计使其在移动办公和小型PC中更具优势，未来将成为AI PC的主流方案。英特尔、AMD和英伟达在核显市场的竞争将影响未来AI PC的发展方向。 </div>
                        <hr>
                    
                    <p>很长一段时间里，人们对于CPU核显的性能，都还停留在「能用」的阶段， 不过苹果的M系列芯片核显却颠覆这一认知，让大家意识到核显的性能其实也有很大的进步空间。</p>
  <p>在核显领域，强大的并不只有苹果，在独显市场被英伟达打得满地找牙的AMD，<strong>前段时间就曝光了目前最强的x86架构核显，并将会搭载于未来发布的Radeon 8000S系列上。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_93c712972478473ea0c95edf78fb939b@1547419282_oswg156151oswg600oswg326_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：推特</p>
  <p><strong>作为x86生态的一员，AMD的核显在泛用性上无疑是远远超越苹果的，而且从目前曝光的信息来看，其性能更是一个大“惊喜”。</strong></p>
  <h2><strong>AMD核显大战独显，底气何在？</strong></h2>
  <p>近日曝光的AMD新核显，其芯片代号已经基本确定，并非沿用此前的Radeon 800M/900M，而是直接更名为Radeon 8060S和Radeon 8050S。新的命名方式与AMD积极发布的下一代RX独立显卡保持一致，换言之所采用的核心与AMD的独显大概率是同款。</p>
  <p>虽然此前AMD也尝试过将独显核心部署到CPU里，但是受限于工艺制程，并没有取得很好的效果，所以后续还是单开一个序列，只是沿用了独显的同款GPU架构。不过，即使并非同款核心，出色架构设计带来的性能提升也让AMD的APU（AMD对拥有高性能核显单元的CPU的称呼）成为x86最强。</p>
  <p>而在台积电的3nm制程成熟后，加上DDR5内存的成熟以及CAMM2内存标准的正式确定，AMD也终于找到了进一步提升核显性能的机会。<strong>从曝光的信息来看，Radeon 8060S/8050S将分别拥有40/32个CU单元，其中Radeon 8060S的单元数与苹果的M4 Max一致，其实际性能或将接近移动版的RTX 4070。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_2372356846a0461abc4421b52f1cdf20@1547419282_oswg78189oswg600oswg315_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：微博</p>
  <p>如果曝光信息无误，那么这将会是核显性能首次能够与高端独立显卡角力，要知道上一代核显的实际性能只是刚好超过GTX 1650的水平（英伟达在2019年发布的入门级独显），而RTX 4070则是英伟达2023年发布的高端显卡，如果按综合测试的基准成绩来算，RTX 4070的性能约等于GTX 1650的3.8倍。</p>
  <p>如此大的提升是怎么做到的？很简单，看看CU单元数量就知道了，<strong>Radeon 890M的CU单元数量只有16个，而Radeon 8060S则是40个，是前者的2.5倍</strong>，即使其他参数不做调整，性能也将是前者的两倍以上。</p>
  <p>而且，搭载Radeon 8060S的锐龙AI MAX 300系列将会采用chiplet分离式设计，简单来说将GPU芯片与CPU芯片分开封装并彼此独立。因此可以在CPU里塞进超大规模的GPU核心，甚至从曝光的内部设计图来看，GPU核心的面积要明显大于CPU核心。</p>
  <p>另外，chiplet分离式设计还可以让AMD将HBM3内存集成到芯片内，作为GPU核心的独立显存使用，解决主板内存带宽和速度无法满足GPU性能释放的问题。正是因为有望解决了GPU核心以及显存带宽问题，才让新一代核显在性能上出现了惊人的突破。</p>
  <p><strong>核显性能媲美高端独显，或许真的不只是说说而已了。</strong></p>
  <h2><strong>AI时代，核显成芯片巨头必争之地</strong></h2>
  <p>为什么AMD要执着于将高性能的GPU塞进CPU里？以前主要是为了押注入门娱乐PC的赛道，只需要购买一个比同规格CPU贵一点的APU，你就可以得到一个高性能CPU+入门级独显性能的核显，能够满足网游及部分单机游戏的娱乐需求，而且因为不需要考虑显卡的安装，可以做成盒子大小的迷你主机，便于部署和摆放。</p>
  <p>但是随着AI大模型的出现，APU的用途就悄然发生了变化，核显的用途不再是视频编解码加速和游戏，而是成为AI算力的一部分。虽然现在的CPU大多将NPU作为主要的AI算力来源，但是GPU在并行计算和高计算量任务方面的优势是无可替代的。</p>
  <p>举个例子，AI大模型中非常热门的文生图功能，在部分AI PC上已经实现了端侧运行，但是实际效果并不好，往往只能生成构图简单且小尺寸的图像。<strong>这是因为NPU虽然在AI运算上非常高效，但是却不具备GPU的超强并行计算性能，难以进行复杂的非线性操作和深层次的模型计算。</strong></p>
  <p>实际上，NPU和GPU在文生图等功能上是可以互补的，利用NPU的高效推理分析和理解用户需求，同时生成简单的图像框架，再用GPU来执行更深层次的优化并丰富画面，最大程度地利用各计算模块的优势，就可以提供更高效的AI服务。</p>
  <p>未来的AI功能想要在图像分析、生成、修改等方面进行更深层次的功能探索，那么GPU就是必需的，因为其本身的性能特点是无可替代的。而且，不要觉得这些功能离你还很遥远，就以我们常用的Adobe Photoshop来说，新版本已经支持大量AI功能，并且提供本地端侧的AI功能支持。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6391c7f3a1c243528bd6e5baef631189@1547419282_oswg79640oswg1024oswg385_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：Adobe</p>
  <p>而在实际测试中，虽然没有独立显卡的PC也可以运行端侧AI功能，但是却有大量功能被限制，即使是可用的功能效率也大打折扣。所以，Adobe建议用户搭配至少拥有4GB显存的GPU，以此来保证端侧AI功能的基础功能都可以启用。</p>
  <p>随着Adobe在旗下软件中普及AI功能，轻薄本的核显性能已经无法满足需求，除非你只打算使用Adobe套件的基础功能，否则一个性能过得去的GPU就是必需的，不管它是独显还是核显。</p>
  <p><strong>Adobe只是整个AI生态的其中一部分，未来的AI PC显然不会止步于此。</strong></p>
  <h2><strong>AI PC爆发，APU核显将成为主流方案？</strong></h2>
  <p>那么问题来了，为什么一定要核显？CPU+独显的组合难道不行吗？并非如此，APU和CPU+独显都是未来AI PC的方向，但是侧重点却有所不同。CPU+独立显卡，也就是现在的高性能笔记本电脑，虽然性能强大但是因为需要应付两个热源，所以对散热系统要求更高，无法做到真正的轻薄设计。</p>
  <p>但是APU不同，因为CPU、GPU等都被封装到一个芯片里，可以通过均热板等技术更好地优化散热系统，在保持散热系统轻量化的同时满足散热需求，更好地满足移动办公需求。</p>
  <p>换言之，<strong>APU能够满足AI PC的移动化和随时部署要求</strong>，虽然在性能峰值等方面肯定无法与CPU+独显的组合相比，但是却可以更好地部署在小型PC、移动PC里。当然，一个高性能的APU本身功耗肯定不会低，届时就只能看CPU厂商如何进行取舍了。</p>
  <p>此外，APU可以利用统一内存等技术，让CPU、GPU共用高速内存，虽然成本会显著上升，但是也可以提供更高的性能，并且满足大型AI模型的运行要求。比如苹果的Mac就利用超大统一内存的优势，能够流畅运行RTX 4090都无法流畅运行的AI模型，不管是AI开发还是AI应用，都有着更显著的优势。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_cbd90bd9957f4c4894aadb9985d2a719@1547419282_oswg273806oswg1254oswg702_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：极客湾</p>
  <p>实际上，CPU+GPU的组合芯片已经被多个半导体巨头盯上，除了前面提到的苹果和AMD外，英特尔、英伟达也在探索这个市场，英特尔的Xe-LPG就采用了独显同等核心，只是性能与AMD还有很大差距，仅相当于780M的水平。至于英伟达，则是更激进一些，选择直接将CPU内置到GPU里，反其道而行之。</p>
  <p>其实英伟达的思路也是可以理解的，既然自家的优势在于GPU而非CPU，那么将GPU打包为主要卖点，CPU作为附赠功能来销售就可以更好地发挥出英伟达的技术优势，只是对于PC市场来说这样的组合确实很新鲜。</p>
  <p><strong>核显赛道以前是英特尔独秀，后来AMD加入战场，现在则是进入三国争霸的阶段，英特尔、AMD、英伟达都想在这个市场上取得优势，因为这将关系到未来的AI PC市场走向。</strong>苹果呢？作为四大主流芯片平台里唯一的封闭式生态，苹果虽然并不直接参与竞争，但是却已经成为其余三家无法忽视的对手。</p>
  <p>未来，随着苹果逐渐完善自己的系统生态，Mac设备的市场份额会不可阻挡的上升，虽然因为价格等问题并不会直接威胁到x86 PC的核心地位，但是却会蚕食掉相当一部分移动PC和AI PC市场。</p>
  <p>谁能想到，曾经毫不起眼，被视为CPU附赠品的核显，会有一天成为兵家必争之地。</p>
  <p>本文来自“雷科技”，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033051886908295</id>
            <title>LCD党狂喜，史上最小5G手机来了：“小而美”的品牌也能活？</title>
            <link>https://www.36kr.com/p/3033051886908295</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033051886908295</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 08:09:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小屏手机, Unihertz, LCD屏, 市场需求  
<br><br>  
总结: 今年手机市场出现了小屏旗舰手机的趋势，主流品牌如vivo、小米和OPPO纷纷推出小屏手机，但Unihertz的Jelly Max以5.05英寸LCD屏幕和较高的定价在市场中显得独特。尽管其配置不算顶尖，但在小屏手机中仍具备一定的性能和影像能力。Unihertz专注于小众市场，推出了多款小屏和三防手机，成功捕捉了特定用户需求。未来，智能手机市场可能会更加细分，满足多样化的用户需求，但Unihertz Jelly Max的极致小屏设计可能仍不适合大众消费者。 </div>
                        <hr>
                    
                    <p>今年的手机市场可以说是彻底和小屏杠上了，vivo、小米、OPPO等主流品牌纷纷推出了小屏旗舰手机，这些手机无论是性能还是影像，表现都相当出众。但这时候咱们LCD党就有些怨言了：为什么没有厂商推出一台LCD屏的小屏旗舰呢？</p>
  <p>你别说，还真有。</p>
  <p><strong>一家名为Unihertz的手机厂商近期推出了旗下新款旗舰手机——Unihertz Jelly Max，该机配备5.05英寸LCD面板，配备天玑7300移动平台。</strong>与此同时，Unihertz Jelly Max也是目前全球机身尺寸最紧凑的5G智慧型手机。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_bf575ee9f3874225bfd0d0412cb7892b@1547419282_oswg534510oswg1600oswg900_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：Unihertz）</p>
  <p>不得不说，敢在2024年推出5英寸小尺寸屏幕，还是LCD面板的手机，Unihertz勇气可嘉。<strong>但LCD党们也别着急心动，这款新机国行定价2199元起，</strong>已经和大多数子系性能旗舰售价相当，比如Redmi Turbo 3，如今渠道价也不到1500元了。</p>
  <p>虽然定价和配置都不算太顶尖，但Unihertz Jelly Max在海外初亮相时可引起了不小的轰动。而Unihertz选择在国内正式上架这款新机，它能打得过这一众小屏旗舰吗？</p>
  <h2><strong>搭载LCD屏，这款小屏“旗舰”成另类&nbsp;</strong></h2>
  <p>很多人估计看到Unihertz Jelly Max这个型号时都会感觉有点迷惑，为何明明只有5.05英寸，却要用“Max”为后缀呢？这其实是与此前的Unihertz Jelly Star相呼应，毕竟Star只有3英寸，也算是小屏手机里的异类了。</p>
  <p>当然，之所以能称其小屏旗舰，自然也是与旗下其他小屏手机相比之下得出的结论。</p>
  <p>Unihertz Jelly Max搭载天玑7300移动平台，采用台积电4nm制程工艺。这颗芯片由4颗2.5GHz的A78大核与4颗A55核心组成，GPU为Mail-G615 MC2。这颗芯片可以视作是天玑7050的升级版，安兔兔跑分大约在75万分，和骁龙778G相差不大。</p>
  <p>为了满足这颗芯片的性能需求，Unihertz也十分慷慨地为Jelly Max配上了12GB内存+256GB存储空间的组合，规格也是用上了LPDDR5+UFS 3.1。虽说与现在的主流旗舰仍有差距，但确保日常的流畅使用肯定是不成问题了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5b83b453524d4c7f860077c4de9cac31@1547419282_oswg153551oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：Unihertz）</p>
  <p>续航上，Unihertz Jelly Max配备了一颗4000毫安时容量电池，支持66W有线快充，不支持无线充电。考虑到Unihertz Jelly Max的三围尺寸只有62.7x128.7x16.3mm，小雷认为这样的电池容量还算是比较合理的。值得注意的是，Unihertz Jelly Max的重量大约为179g，在这个机身尺寸下，似乎控制得不是太好。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_2b370a18eff24385a8f9a9d85461c895@1547419282_oswg376683oswg900oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：Unihertz）</p>
  <p>既然聊到“旗舰”，自然是无法避免要谈及影像。Unihertz Jelly Max搭载了双摄方案，主摄为1亿像素，副摄是800万像素的3.4倍直立式长焦。虽说这套方案在2024年的旗舰手机中肯定是没法排上号的，但Unihertz选择长焦而非超广角镜头，这一点的确让人感到意外。</p>
  <p>整体配置看下来，Unihertz Jelly Max与我们所了解的小屏旗舰不太一样，它并没有可能称得上顶级的硬件水平，但确实是主打一个均衡，性能、影像、快充，在可控的尺寸里都算是能给的都给了。<strong>问题在于，Unihertz Jelly Max的定价来到2199元，这已经超出很多消费者对这种硬件配置的心理预期了，外加它的三围尺寸控制得也不是很好，正面的超大黑边比曾经的iPhone 12 mini糟糕得多。</strong></p>
  <p>在没有任何情怀的加持下，Unihertz Jelly Max似乎很难吸引到消费者。</p>
  <p>不过，Unihertz在海外市场可是炙手可热的明星品牌，曾多次被海外媒体夸赞其创新能力，比如在MWC 2023上，连Nothing的创始人都在Unihertz的展位上打卡留念。足以见得，在没有极度内卷的海外市场，给足了Unihertz创新的空间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_62b7ce90683746c3a33a0abbbe2387e8@1547419282_oswg181996oswg1092oswg1050_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：X）</p>
  <h2><strong>风靡海外市场，Unihertz的小众棋下活了？</strong></h2>
  <p>Unihertz是一家来自中国上海的手机制造商，与我们熟知的从中国走出去的这些手机厂商，如传音、真我、Redmi等不同，Unihertz主打差异化，不走寻常路。Unihertz主攻三防、小屏手机，甚至还曾推出过自带灯带的手机和配备实体键盘的手机，收获了不少忠实粉丝。</p>
  <p>数据显示，Unihertz在2017年首次登陆Kickstarter众筹平台时，就以35天筹获125万美元刷新记录。据了解，截至目前，Unihertz的总销售额已经破亿，这在手机市场这片红海里，算是不俗的成绩。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_1dc4160a1a374b4e8651b1ab988f375b@1547419282_oswg275308oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：Unihertz）</p>
  <p>Unihertz目前主打的系列分为四个：主打三防小巧的Atom系列、配备全键盘的实用型手机Titan系列、双屏时钟设计的TicTock系列，以及我们前面介绍过的Jelly系列。这四个系列都属于手机市场里最不被看好的赛道，三防、小屏、全键盘、双屏，只能说是只有小众爱好者会比较关注。</p>
  <p>但Unihertz之所以能成功，其实还是与其“极致”的心态有关。</p>
  <p>2020年，Unihertz推出了迄今为止最小巧的4G智能手机Jelly 2，它仅配备了3英寸的LCD屏幕，机身尺寸为95×49.4×16.5毫米，重量也只有110克。<strong>但就是在这样小巧的机身里，Unihertz还是为其配备了双卡双待、NFC、GPS、蓝牙4.2，甚至指纹识别、3.5mm耳机孔、USB-C接口也一应俱全。</strong></p>
  <p>Unihertz在2021年推出的Titan Pocket也相当经典，全键盘设计，支持IP67等级防护，还塞入了4000毫安时容量的大电池。这种设计对于户外运动爱好者而言，是相当友好的设计。</p>
  <p>不难看出，其实Unihertz手机的流行源于对小众市场需求的精准捕捉。当前智能手机市场以大屏、极致的性能表现等为主流趋势，而Unihertz反其道而行之，推出了一系列小屏幕、实体键盘和三防功能的手机。这些独特的设计不仅满足了对轻便、坚固、实用性有需求的用户，也让它在竞争激烈的智能手机市场中找到了独有的定位。</p>
  <h2><strong>小而美的路线，注定不适合主流厂商</strong></h2>
  <p>事实上，Unihertz的成功之道在于其聚焦特定需求的精准定位。主流市场在追求大屏、高性能的路上快速发展时，忽略了部分用户对便携性、单手操作和设备耐用性的需求。Unihertz推出的Jelly系列、Atom系列和Titan系列恰好弥补了这部分市场空白。</p>
  <p>但相较之下，Unihertz的竞争力与主流手机品牌之间还有很大的差距，例如销售额，Unihertz成立至今也仅突破一亿大关，但这对于主流手机厂商而言很有可能只是某一款手机1分钟的销售额。的确，我们无法忽视小米、vivo和OPPO等品牌纷纷推出小屏旗舰，对细分市场需求的响应。但小米15、vivo X200 Pro mini和OPPO Find X8等小屏手机没有Unihertz那般极端的小巧和功能差异化，它们的屏幕尺寸约在6.3到6.5英寸之间，重新优化了手感和便携性，这使其变得更加均衡，也收获更多大众消费者的喜爱。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_f552297e1cf947d2876a77ec5bfa1d6c@1547419282_oswg562729oswg1200oswg675_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：Unihertz）</p>
  <p>微博智慧芯片案内人此前透露，X200 Pro mini对于vivo而言是个意外之喜，估计要继续加单；OPPO Find X8的首销也比前代高出2.8倍。这恰好说明，手机市场正在回到当初那个百花齐放的时代，小屏旗舰、大屏旗舰，接下来要登场的电竞手机，各自都有坚实的受众群体。此外，像是努比亚坚持的无孔全面屏，在不断优化下，也越来越受消费者的认可。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_374c189f0d154bc98d634eff12fe48c1@1547419282_oswg158700oswg1206oswg509_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：微博）</p>
  <p>未来，智能手机市场可能会朝着更加精细化的方向发展。Unihertz的成功为其他厂商提供了范例，而小米、vivo和OPPO等品牌的参与，也将进一步推动细分市场的发展。小屏旗舰手机的趋势提醒我们，市场需求是多层次的，用户的生活方式和使用场景各不相同。无论是小屏旗舰、户外三防手机、或是高奢手机等，每一款产品都在满足某一类特定需求。</p>
  <p>因此，未来的智能手机品牌可能会更加关注细分市场，通过推出不同尺寸、功能的设备，来满足多元化的用户需求。这种策略不仅能够增强品牌在不同市场中的竞争力，还能为用户带来更多选择。但就目前而言，Unihertz Jelly Max这种极致小屏手机，可能还是不太适合大众消费者。</p>
  <p>本文来自“雷科技”，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033039401808133</id>
            <title>扩散模型失宠？端侧非自回归图像生成基础模型Meissonic登场，超越SDXL</title>
            <link>https://www.36kr.com/p/3033039401808133</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033039401808133</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 08:09:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meissonic, 图像生成, 非自回归, 掩码图像建模  
<br><br>  
总结: Meissonic是一款新发布的非自回归掩码图像建模模型，旨在高效生成高分辨率图像，标志着图像生成技术进入端侧时代。该模型通过创新的架构和优化的训练流程，克服了现有MIM方法在分辨率和性能上的限制，能够生成1024×1024分辨率的图像，并在生成质量和效率上与领先的扩散模型相媲美。Meissonic的训练依赖于高质量数据集，并引入了动态采样条件和特征压缩层，显著提升了图像的保真度与生成效率。该模型的推出反映了移动设备上文本到图像应用的日益趋势，具有广泛的应用潜力。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_626130ef2f09448b9d76af1488bf9a4b@46958_oswg313614oswg1073oswg416_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>【导读】</strong>刚刚，一款专为消费级显卡设计的全新非自回归掩码图像建模的文本到图像生成模型——Meissonic发布，标志着图像生成即将进入「端侧时代」。</p>
  <p>最近，YouTube和Reddit上出现了一个引起广泛讨论的图像生成模型，来自日本、韩国、美国、印度、中东和英国的网友们纷纷参与讨论。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_ac469af512394ec49b57ba2c478e1804@46958_oswg180618oswg975oswg252_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_181b476a955847c29f66d2d60597a739@46958_oswg218248oswg975oswg247_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">Youtube热烈讨论</p>
  <p>那么，这到底是怎么回事呢？<strong>让我们一起来看看吧。 &nbsp;&nbsp;</strong></p>
  <p>近年来，大语言模型在自然语言处理领域取得了巨大的突破，以LLaMA和Qwen等为代表的模型展现了强大的语言理解和生成能力。&nbsp;</p>
  <p>但是，图像生成技术的突破主要得益于扩散模型，如Stable Diffusion XL在图像质量、细节和概念一致性方面设立了事实标准。&nbsp;</p>
  <p>然而，这些扩散模型与自回归语言模型的工作原理和架构显著不同，导致在视觉和语言任务上实现统一生成方法面临挑战。这种差异不仅使这些模态的整合变得复杂，还凸显了需要创新的方法来弥合它们之间的差距。&nbsp;</p>
  <p>自回归文本到图像模型（如LlamaGen）通过预测下一个token生成图像，但由于生成的图像token数量庞大，自回归模型在效率和分辨率上也面临瓶颈，难以应用到实际场景。于是，一些Masked Image Modeling（MIM）技术，例如MaskGIT和MUSE被提出。这些方法展现了高效图像生成的潜力。&nbsp;</p>
  <p>尽管MIM方法具有一定的前景，它们仍面临两个关键限制：&nbsp;</p>
  <p><strong>1.&nbsp;分辨率限制</strong></p>
  <p>当前的MIM方法只能生成最大分辨率为512×512像素的图像。这一限制阻碍了它们的广泛应用和进一步发展，尤其是在文本生成图像的社区中，1024×1024分辨率逐渐成为标准。&nbsp;</p>
  <p><strong>2. 性能差距</strong></p>
  <p>现有的MIM技术尚未达到领先扩散模型如SDXL所表现的性能水平，特别是在图像质量、复杂细节和概念表达等关键领域表现不佳，而这些对实际应用至关重要。&nbsp;</p>
  <p>这些挑战需要探索新的创新方法，Meissonic的目标是使MIM能够高效生成高分辨率图像（如1024×1024），同时缩小与顶级扩散模型的差距，并确保其计算效率适合消费级硬件。&nbsp;</p>
  <p>Meissonic模型提出了全新的解决方案，基于非自回归的掩码图像建模（MIM），为高效、高分辨率的T2I生成设定了新标准。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_cc96147edffd40ec923509e95821ce6c@46958_oswg71612oswg980oswg336_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文链接: https://arxiv.org/abs/2410.08261</p>
  <p>GitHub Code: https://github.com/viiika/Meissonic</p>
  <p>Huggingface Model: https://huggingface.co/MeissonFlow/Meissonic</p>
  <p>通过架构创新、先进的位置编码策略和优化的采样方法，Meissonic不仅在生成质量和效率上与领先的扩散模型（如SDXL）相媲美，甚至在某些场景中超越了它们。</p>
  <p>此外，Meissonic利用高质量的数据集，并通过基于人类偏好评分的微观条件进行训练，同时引入特征压缩层，显著提升了图像的保真度与分辨率。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_b4edc45d06a14fdc86b3009377b817fe@46958_oswg1398001oswg727oswg1022_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>以下是Meissonic在方法上的几项重要技术改进：</p>
  <p><strong>1. 增强型Transformer架构</strong></p>
  <p>Meissonic结合了多模态与单模态的Transformer层，旨在捕捉语言与视觉之间的互动信息。从未池化的文本表示中提取有用信号，构建两者之间的桥梁；单模态Transformer层则进一步细化视觉表示，提升生成图像的质量与稳定性。研究表明，这种结构按1:2比例能够实现最佳性能。</p>
  <p><strong>2. 先进的位置编码与动态采样条件</strong></p>
  <p>为保持高分辨率图像中的细节，Meissonic引入了旋转位置编码（RoPE），为queries和keys编码位置信息。RoPE有效解决了随着token数量增加，传统位置编码方法导致的上下文关联丢失问题，尤其在生成512×512及更高分辨率图像时。</p>
  <p>此外，Meissonic通过引入掩码率作为动态采样条件，使模型自适应不同阶段的采样过程，进一步提升图像细节和整体质量。</p>
  <p><strong>3. 高质量训练数据与微观条件</strong></p>
  <p>Meissonic的训练依赖于经过精心筛选的高质量数据集。为提升图像生成效果，Meissonic在训练中加入了图像分辨率、裁剪坐标及人类偏好评分等微观条件，显著增强了模型在高分辨率生成时的稳定性。</p>
  <p><strong>4. 特征压缩层</strong></p>
  <p>为了在保持高分辨率的同时提升生成效率，Meissonic引入了特征压缩层，使其在生成1024×1024分辨率图像时可以有效降低计算成本。</p>
  <p>那么，Meissonic到底有多强大呢？让我们来看看它的表现：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c3bb7ff49ef04eec9b41f2d89641f615@46958_oswg385119oswg975oswg730_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在HPS V2.0基准测试中，Meissonic以平均0.56分的优势超越了SDXL。</p>
  <p>在图像编辑能力评测数据集Emu-Edit上，Meissonic的Zero-shot图像编辑性能甚至超越了经过图像编辑指令微调后的模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_72ffe61850744911a9802c7ea0c743de@46958_oswg122216oswg970oswg442_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d369da1765af475395ae522fea7e5eab@46958_oswg1087647oswg975oswg577_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在风格多样性生成方面，Meissonic展现出超越SDXL的表现。</p>
  <p>而这一切，都只需SDXL 1/3的推理时间和1/2的显存占用。值得注意的是，Meissonic可以在8GB显存下运行，让中低端显卡的用户也能受益。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c9f1ef14c77d4a82972f37b0cb2b8f27@46958_oswg162273oswg975oswg374_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>此外，Meissonic还展现了超强的zero-shot图像编辑能力，无需微调即可灵活编辑有mask和无mask的场景，提供了更多创作可能性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_164f9eba70a146df9fcbc384e87d1302@46958_oswg917087oswg961oswg787_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_2e04f14088114f6b87b61bf491820547@46958_oswg602533oswg975oswg640_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>高效推理与训练的结合</strong></h2>
  <p>在文本到图像合成领域，Meissonic模型凭借卓越的效率脱颖而出。该模型不仅在推理过程中实现了高效性，同时在训练阶段也显著提升了效率。Meissonic采用了一套精心设计的四阶段训练流程，逐步提升生成效果。</p>
  <p><strong>阶段一：理解图像基础概念</strong></p>
  <p>研究表明，原始LAION数据集的文本描述无法充分满足文本到图像模型的训练需求，通常需要多模态大型语言模型（MLLM）进行优化，但这消耗大量计算资源。</p>
  <p>为此，Meissonic在初始阶段采用了更加平衡的策略，利用经过筛选的高质量LAION数据学习基础概念，通过降分辨率的方法提高效率，最终保留约2亿张高质量图像，并将初始训练分辨率设定为256×256。</p>
  <p><strong>阶段二：实现文本与图像对齐</strong></p>
  <p>第二阶段的重点在于提升模型对长文本描述的理解能力。团队筛选了审美分数高于8的图像，构建了120万对优化后的合成图文对及600万对内部高质量图文对。此阶段，训练分辨率提升至512×512，配对数据总量达到约1000万对，从而显著提升了Meissonic在处理复杂提示（如多样风格和虚拟角色）以及抽象概念方面的能力。</p>
  <p><strong>阶段三：实现高分辨率图像生成</strong></p>
  <p>在Masked Image Modeling（MIM）领域，生成高分辨率图像仍然是一个挑战。Meissonic通过特征压缩技术高效实现了1024×1024分辨率的图像生成。引入特征压缩层后，模型能够在较低计算成本下实现从512×512到1024×1024的平滑过渡，此阶段的数据集经过进一步筛选，仅保留约600万对高分辨率、高质量的图文配对，以1024分辨率进行训练。</p>
  <p><strong>阶段四：精细化美学细节生成</strong></p>
  <p>在最后阶段，Meissonic通过低学习率微调模型和文本编码器，并引入人类偏好评分作为训练条件，进一步提升了生成图像的质量和多样性。这一阶段的训练数据与第三阶段保持一致，但更加注重对高分辨率图像生成的美学细节的打磨。</p>
  <p>通过上述四个阶段的训练，Meissonic在训练数据和计算成本上实现了显著降低。具体而言，在训练过程中，Meissonic仅使用210万张图像，相较于其他主流模型（如SD-1.5和Dall-E 2），训练数据的使用量显著减少。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_46076cb8ca7a4d82b0c112d6aff23500@46958_oswg140077oswg598oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在使用8个A100 GPU进行训练的情况下，Meissonic的训练时间仅需19天，显著低于Würstchen、SD-2.1等模型的训练时间。</p>
  <h2><strong>广泛影响</strong></h2>
  <p>最近，移动设备上的端侧文本到图像应用如谷歌Pixel 9的Pixel Studio和苹果iPhone 16的Image Playground相继推出，反映出提升用户体验和保护隐私的日益趋势。作为一种资源高效的文本到图像基座模型，Meissonic在这一领域代表了重要的进展。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_28df7dd209b843bdbde22ab00a163403@46958_oswg382018oswg975oswg566_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>此外，来自斯坦福大学的创业团队Collov Labs在一周内就成功复现出同样架构的Monetico，生成效果可以与Meissonic相媲美，推理效率更加高效，并荣登huggingface趋势榜第一名。这也显示出Meissonic架构在资源高效上的巨大潜力和应用价值。</p>
  <p>参考资料：&nbsp;</p>
  <p>https://arxiv.org/abs/2410.08261&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/pYZxK3OFV8CH4VQET4_rLg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：LRST&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3032904678289669</id>
            <title>最强开源CodeLLM模型深夜来袭，320亿参数，Qwen2.5-Coder新模型超越GPT-4o</title>
            <link>https://www.36kr.com/p/3032904678289669</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3032904678289669</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 07:13:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源编程模型, Qwen2.5-Coder-32B, AI编程, 代码生成  
<br>
<br>
总结: Qwen2.5-Coder-32B的发布标志着开源编程模型的重大突破，成功超越了多个闭源模型，包括GPT-4o。该模型在12个主流基准测试中取得9项胜利，展现出强大的代码生成、修复和推理能力。Qwen2.5-Coder支持多达92种编程语言，且其易用性使得编程小白也能轻松上手。此次发布的全系列模型采用宽松的Apache 2.0许可，进一步推动了开源社区的发展。Qwen系列的成功反映了开源模型在全球开发者中的广泛认可和应用潜力。 </div>
                        <hr>
                    
                    <p>一夜之间，AI编程模型的开源王座易主了！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6d1654e40dd94ec2ad4e7ed4fe42abe3@000000_oswg420900oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Qwen2.5-Coder-32B正式发布，<strong>霸气拿下多个主流基准测试SOTA</strong>，彻底登上全球最强开源编程模型宝座。</p>
  <p>更重要的是，在代码能力的12个主流基准上，Qwen2.5-Coder-32B与GPT-4o对决，<strong>斩获9胜</strong>，一举掀翻闭源编程模型的绝对统治。</p>
  <p>不用一行代码，只要输入最直接、够详细的自然语言prompt，它就能给你整全套：</p>
  <p>比如，做个简单的模拟三体运动的HTML网页吧！</p>
  <p>生成个game of life的小游戏，也是手拿把掐：</p>
  <p>哪怕是完全不懂编程的小白，也能轻松上手。比如我们体验了一把用一句大白话生成计算器：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_72535567d3aa4992a6a472e605bd75bb@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>很快就搞定了，计算器可以直接使用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5791718dc3c64385bf9641246478f24b@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>还有更多好玩又实用的应用，比如不到20秒生成一个音乐播放器。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6a255c74a661426b97b23144fd0de59a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>做简历也易如反掌：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_a1459647006c4bc297a2e3f11823aef6@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>怪不得开发者们都说，太恐怖了，<strong>超越了4o，与Sonnet、o1都能掰手腕</strong>！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_3d52b1f876bb45f6bb731acd68a91f97@000000_oswg639664oswg1080oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e3a6b6c3df004dfb92a1dee6947a667a@000000_oswg298315oswg1080oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_8c25a6eb230741d7a3cf906a2a8a9f4e@000000_oswg385933oswg1080oswg568_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c0f4c677b00748afba8590c678e31dcb@000000_oswg174349oswg1024oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>更让人惊喜的是，这次Qwen2.5-Coder上新，<strong>共开源0.5B/1.5B/3B/7B/14B/32B共6个尺寸的全系列模型</strong>，每种尺寸都取得同规模下<strong>SOTA</strong>。</p>
  <p>而且大部分版本都是采用非常宽松的<strong>Apache 2.0许可</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_9cc2fe8c4a8e43d6b7834716e580db30@000000_oswg58600oswg1080oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>要知道，自从CodeQwen1.5推出以来，该系列模型就成为开发者社区最关注的开源编程模型之一。</p>
  <p>9月发布的Qwen2.5-Coder-7B版本，更是一骑绝尘，不少人表示它足以替代GPT-4和Sonnet 3.5成为日常主力工具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_18f990583da048e2b831bbee3487a939@000000_oswg195249oswg1080oswg355_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>当时还预告了32B的发布，从此，网友一直催更。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_979b2d971e9d49948d24013de3d90df8@000000_oswg293550oswg1080oswg461_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>这次，32B和更多尺寸的全系列Qwen2.5-Coder如约而至，这个看起来能用code生万物的最强开源代码模型，到底厉害在哪儿呢？</p>
  <h2><strong>超越GPT-4o，人人都能用</strong></h2>
  <p>首先，我们为什么关注编程模型？因为代码能力对大模型的推理很重要，<strong>大模型对代码的理解通常被认为是其逻辑能力的基础来源之一</strong>。</p>
  <p>代码思维链(program-of-thought)&nbsp;将复杂问题分解为可执行的代码片段，并且利用代码执行器逐步解决子问题，可以较大程度提升基于大型语言模型的推理能力。</p>
  <p>DeepMind斯坦福UC伯克利联手发表的一项研究中提到，使用代码链（Chain of Code），不仅可以提升模型基于代码的推理能力，也给模型自然语言任务、数学计算方面带来积极影响。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_393d65fa72da4ce29ed5b541effc39ea@000000_oswg119301oswg1080oswg330_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>Qwen2.5-Coder也采用了类似原理。它基于Qwen2.5基础大模型进行初始化，使用源代码、文本代码混合数据、合成数据等5.5T tokens的数据持续训练，实现了代码生成、代码推理、代码修复等核心任务性能的显著提升。</p>
  <p>最新发布中，<strong>Qwen2.5-Coder全系列共开源6个尺寸模型</strong>，每个规模包含base和Instruct两个版本。</p>
  <p>Base模型为开发者可以自行微调的基座模型，Instruct模型是可以直接聊天的官方对齐模型。</p>
  <p>团队评估了不同尺寸Qwen2.5-Coder在所有数据集上的表现，不但均取得同等规模下最佳性能（无论开闭源），并且还验证了Scaling Law依旧奏效。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_47eccf76d3c8486daae67aa17679e2b3@000000_oswg19492oswg1080oswg271_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其中，<strong>Qwen2.5-Coder-32B-Instruct是本次开源的旗舰模型</strong>。</p>
  <p>在编程大模型主要关注的5个方面上，它都实现了对GPT-4o的超越：</p>
  <ul>
   <li>代码生成</li>
   <li>代码修复</li>
   <li>代码推理</li>
   <li>多编程语言</li>
   <li>人类偏好对齐</li>
  </ul>
  <p>首先来看编程模型最核心的能力——<strong>代码生成</strong>。</p>
  <p>Qwen2.5-Coder-32B-Instruct在多个流行的代码生成基准上都取得了开源SOTA。</p>
  <p>而且在HumanEval、McEval、Spider、EvalPlus、BigCodeBench等基准上，都超越了闭源的GPT-4o和Claude 3.5 Sonnet。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_878fe170339744b4bf713bafcc9eb7cf@000000_oswg188953oswg1080oswg538_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其次，<strong>代码修复</strong>方面，在主流基准Aider上，Qwen2.5-Coder-32B-Instruct略胜GPT-4o。</p>
  <p>第三，<strong>代码推理</strong>方面，在CRUXEval基准上，32B版本较7B版本有了明显提升，甚至达到了和GPT-4o、Claude 3 Opus相当的水平。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_0894f9601ed540828d9ca1ad3f311b4c@000000_oswg88042oswg1080oswg514_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>第四，在对多编程语言的掌握上，Qwen2.5-Coder支持<strong>92种</strong>编程语言。Qwen2.5-Coder-32B-Instruct在其中40多种语言上表现出色。</p>
  <p>在Haskell、Racket等语言上表现格外突出，<strong>打败4o等闭源模型同时取得了超高分数</strong>。</p>
  <p>通过在预训练阶段进行独特数据清洗和配比，它在McEval上取得65.9分，</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_6615326812184d1eba090a8493adce1d@000000_oswg164984oswg720oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在多编程语言的代码修复基准MdEval上，同样表现突出，取得75.2分，位列所有开源模型第一。</p>
  <p>最后，为了检验Qwen2.5-Coder-32B-Instruct在<strong>人类偏好上的对齐表现</strong>。通义千问团队还构建了一个来自内部标注的代码偏好评估基准Code Arena，可以理解为编程大模型竞技场。</p>
  <p>这一部分，Qwen2.5-Coder-32B-Instruct和闭源模型正面PK，通过让两个模型在同样问题下PK，计算最终胜负比，以此来评判模型表现。</p>
  <p>实验结果显示，Claude 3.5 Sonnet战绩最好，Qwen2.5-Coder-32B-Instruct和GPT-4o水平相当，胜率为68.9%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5954d4f6efea49d3ad0374165bc97257@000000_oswg125084oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>总的来看，Qwen2.5-Coder-32B-Instruct毫无疑问是开源最佳，并且真正拉平甚至部分超出了有最强代码能力的闭源模型。</p>
  <p>在实际应用上，通义千问团队演示了基于Qwen2.5-Coder打造的智能代码助手，并上线了一个<strong>Artifacts应用</strong>。</p>
  <p>目前智能代码助手领域主要以闭源模型为主，Qwen2.5-Coder为开发者提供了开源选择。</p>
  <p>它在几个可以评估模型辅助编程的基准上（CrossCodeEval、CrossCodeEval、CrossCodeLongEval、RepoEval、SAFIM）都取得了SOTA。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_69f237497e4d4de8aa58ae18bc454927@000000_oswg85627oswg1080oswg402_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>新的Qwen2.5-Coder，对编程小白也很友好，一句话就能开发小应用/游戏。</p>
  <p>比如现场自动做一个2048小游戏，几十秒搞定，立刻就能玩。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_1cb95778a03e4678be90bed258591a1d@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>或者是生成一个图文并茂的英语单词卡页面，速度都非常快。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_3689d33d55374f1b919baaa6b3f076b6@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>被全球开发者追捧的中国开源模型</strong></h2>
  <p>Qwen2.5-Coder-32B的快速推出可以说是众望所归。</p>
  <p>就在前段时间，Reddit还有帖子提问，怎么32B版本还不来？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_385df13ff1d8486ebda51b4754f20564@000000_oswg348162oswg1080oswg587_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>毕竟，不少人都基于9月开源的Qwen2.5-Coder-1.5B和7B版本，打造出了热度颇高的应用。</p>
  <p>比如<strong>Qwen Code Interpreter</strong>。这是一个类似于ChatGPT的代码解释器，可完全在本地/浏览器上运行，基于Qwen2.5-Coder-1.5B打造。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_b7235ca8ba6f4a90b2baff5fe1057e0a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>只用小模型还实现了非常好的效果，这立刻引发不少网友的关注，一个随手推荐帖就有近千人点赞。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_e6c9a13584b14ff5802ccac56f659059@000000_oswg392953oswg720oswg869_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c0a5ffc8b95a4d9aaa21b32ae7a167df@000000_oswg404849oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>还有人基于Qwen2.5-Coder打造了<strong>专门用于rust语言的编程助手</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_b6a3dc11b6ad45f5939f769135d5945b@000000_oswg464908oswg720oswg939_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>说Qwen2.5-Coder是最受欢迎的开源编程大模型绝不为过，事实上，每一代Qwen编程模型，都代表了开源的最高水平，PK的永远是当时最厉害的闭源模型。</p>
  <p>今年4月，CodeQwen1.5-7B发布，在基础代码生成能力上，它表现出超过更大尺寸模型的潜力，拉近了开源模型和GPT-4之间的编程能力差距。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_70b7b06c7dd9490e92b6296faa3dda74@000000_oswg150830oswg931oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>之后在云栖大会上，Qwen2.5-Coder-1.5B/7B发布。作为Qwen2.5家族的一员，Qwen2.5-Coder-7B打败了当时比它尺寸更大的DeepSeek-Coder-V2-Lite和Codestral-20B，成为最强基础编程模型之一。</p>
  <p>在此基础上，Qwen2.5-Coder-32B的推出，将规模提升一个数量级达到百亿参数，能力也进一步涌现，水平超越GPT-4o，逐渐逼近闭源模型王者Claude 3.5 Sonnet。</p>
  <p>闭源模型山头几个月一换，而开源的Qwen却从来没有停下攀登的脚步，也进一步验证，开源模型和闭源模型之间的差距正在缩短，开源模型完全有机会、有能力取代闭源模型，为全球广大开发者用户提供更加低门槛、开放的AI能力。</p>
  <p>随着AI应用趋势不断演进，越来越多领域和行业加入，对AI模型的性能、开发成本以及上手门槛都会提出更高要求。反之，易用的开源模型将成为推动这股趋势的重要动力。</p>
  <p>Qwen系列的爆火就是这种正向循环最好的证明之一。截至9月底，全球基于Qwen系列二次开发的衍生模型数量9月底突破7.43万，超越Llama系列衍生模型的7.28万。</p>
  <p>通义千问Qwen已成为全球最大的生成式语言模型族群。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_f8de36894e824c8da119eb11d3ab1ea7@000000_oswg120723oswg1000oswg512_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>而背靠阿里——全球云计算和AI的第一梯队玩家，一方面，深厚技术和资源支持为Qwen系列的持续开源、不断升级提供更可靠保障，另一方面，阿里自身业务及发展上的需要也构成了Qwen继续攀登高峰的内在闭环。</p>
  <p>不过开源模型最大价值还是要回归开发者。</p>
  <p>AI的到来，让天下没有难开发的应用。</p>
  <p>Qwen作为中国开源大模型领军者，为全球开发者提供更丰富的选择，也代表中国创新力量在全球大模型竞技中登台亮相，并且正在得到更多人的认可。</p>
  <p>嗯…比如前段时间Mistral发布的端侧模型没有和Qwen2.5做对比，还被小小吐槽了下（doge）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c98aaf6d7de44a0882df5493e777d867@000000_oswg61044oswg998oswg316_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_28e7efc3859e4af6a1c1a628d6dc974c@000000_oswg427082oswg1080oswg614_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>值得一提的是，据透露<strong>Qwen3</strong>已经在路上，预计在几个月内和大家见面。可以期待一下~</p>
  <p>关于Qwen2.5-Coder的更多信息，可直接通过下方链接了解。</p>
  <p>GitHub地址：https://github.com/QwenLM/Qwen2.5-Coder技术报告：https://arxiv.org/abs/2409.12186</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247757769&amp;=1&amp;sn=729479112761021887b03be76cc8faf5&amp;chksm=e9636a84ca9cabf88a53999b68874d2e229cd12629ae6623cf22fc5042c8dd11c49a852db906&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID：QbitAI）</a>，作者：小明，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3033039426859273</id>
            <title>AlphaFold3重磅开源，诺奖级AI颠覆世界，GitHub斩获1.8k星，本地即可部署</title>
            <link>https://www.36kr.com/p/3033039426859273</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3033039426859273</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 07:09:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源, AlphaFold3, 蛋白质结构, 科学创新  
<br><br>  
总结: AlphaFold3在经过六个月的争议后终于开源，旨在推动生化医药领域的科学创新。该AI工具的开源使得科学家能够在本地部署，从而加速新药和疫苗的研发进程。尽管开源后只有学术背景的科学家可以申请访问训练权重，但其代码在GitHub上已获得广泛关注。AlphaFold3的开源也激发了其他公司开发类似模型，显示出开源在科学研究中的重要性。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_2a6eac0fdc5b4bfdbae45df787b90dce@46958_oswg170513oswg1070oswg417_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>【导读】</strong>六个月的争议后，诺奖级AI AlphaFold3开源了。这个在蛋白质结构预测领域掀起波澜的AI——期待它的开源推动更多科学家的大量创新。文后附有安装和运行步骤详解哦！</p>
  <p>AlphaFold3源码终于开放了！</p>
  <p>六个月前，AlphaFold3横空出世震撼了整个学术界。AlphaFold的开发人也凭借它在上个月赢得了诺贝尔化学奖。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_856a6861f61e4bc3b96dfe71e3388639@46958_oswg1062258oswg1080oswg598_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>然而，这个诺奖级AI的「不开源」一直引起学界的不满。谷歌DeepMind只推出了一个免费研究平台「AlphaFold Server」，而且该服务有每日的次数限制。相比于开源的AlphaFold2来说，这种使用方式缺失了很多自由度。</p>
  <p>好在它现在终于开源了！开源后，生化医药的科学家们可以在本地部署AlphaFold3，极大地缩短了新药、疫苗等研发进程。</p>
  <p>现在，任何人都可以下载AlphaFold3软件代码并进行非商业使用，但目前只有学术背景的科学家可申请访问训练权重。</p>
  <p>GitHub上的AlphaFold3开源项目代码目前已斩获1.8k星。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5a1214950bc643f8b01dfbe73e541a5f@46958_oswg119803oswg1080oswg430_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>开源项目：https://github.com/google-deepmind/alphafold3</p>
  <h2><strong>AlphaFold3的「效仿者」们</strong></h2>
  <p>在过去的几个月中，不少公司都依靠AlphaFold3论文中的伪代码，争相发布了各自受到AlphaFold3启发的类似模型。</p>
  <p>比如，获得OpenAI投资的AI生物初创Chai Discovery，就在9月发布了用于分子结构预测的新型多模态基础模型Chai-1，并附带了一份技术报告，比较了Chai-1与AlphaFold等模型的性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_d3ba5b8daf0d4423ae29f44d63dc7d8b@46958_oswg117398oswg1080oswg513_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>官网地址：https://www.chaidiscovery.com/</p>
  <p>另一家位于美国旧金山的公司Ligo Biosciences则发布了一个无使用限制的AlphaFold3版本。但它尚未具备完整的功能，比如模拟药物和蛋白质以外分子的能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_c69fdbc1afce48b0aafc18d97cbb20b5@46958_oswg112617oswg1080oswg424_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>项目地址：https://github.com/Ligo-Biosciences/AlphaFold3</p>
  <p>其他团队也正在开发没有使用限制的AlphaFold3版本：AlQuraishi希望在年底前推出一个名为OpenFold3的完全开源模型。这将使制药公司能够使用专有数据（例如结合不同药物的蛋白质结构）重新训练模型，从而有可能提高性能。</p>
  <h2><strong>开源的重要性</strong></h2>
  <p>过去一年里，许多公司发布了新的生物AI模型，这些公司对开放性采取了不同的态度。</p>
  <p>威斯康星大学麦迪逊分校的计算生物学家Anthony Gitter对盈利性公司加入他的领域没有异议——只要他们在期刊和预印本服务器上分享工作时遵循科学界的标准。</p>
  <p>「我和其他人希望盈利性公司们也分享关于如何进行预测的信息，并以我们可以审查的方式发布AI模型和代码，」Gitter补充道，「我的团队不会基于无法审查的工具进行构建和使用。」</p>
  <p>DeepMind科学AI负责人Pushmeet Kohli表示，几种AlphaFold3复制品的出现表明，即使没有开源代码，该模型也是可复现的。</p>
  <p>他补充说，未来他希望看到更多关于出版规范的讨论，因为这一领域越来越多地由学术界和企业研究人员共同参与。</p>
  <p>此前，AlphaFold2的开源推动了其他科学家的大量创新。</p>
  <p>例如，最近一次蛋白质设计竞赛的获胜者使用该AI工具设计出能够结合癌症靶标的新蛋白质。</p>
  <p>AlphaFold项目的负责人Jumper最喜欢的一个AlphaFold2创新，是一个团队使用该工具识别出一种帮助精子附着在卵细胞上的关键蛋白。</p>
  <p>Jumper迫不及待地想看到在分享AlphaFold3后出现这样的惊喜。</p>
  <h2><strong>安装和运行</strong></h2>
  <p>安装AlphaFold3需要一台运行Linux的机器；AlphaFold3不支持其他操作系统。&nbsp;</p>
  <p>完整安装需要多达1TB的磁盘空间来存储基因数据库（建议使用SSD存储）以及一块具有计算能力8.0或更高的 NVIDIA GPU（具有更多内存的GPU可以预测更大的蛋白质结构）。</p>
  <p>经过验证，单个NVIDIA A100 80 GB或NVIDIA H100 80 GB可以适配最多5120个token的输入。在NVIDIA A100和H100 GPU上的数值准确性也已被验证。</p>
  <p>尤其是对于较长的目标，基因搜索阶段可能会消耗大量RAM——建议至少使用64GB的RAM运行。</p>
  <p>配置步骤：&nbsp;</p>
  <p>1. 在GCP上配置机器&nbsp;</p>
  <p>2. 安装Docker&nbsp;</p>
  <p>3. 为A100安装NVIDIA驱动程序&nbsp;</p>
  <p>4. 获取基因数据库&nbsp;</p>
  <p>5. 获取模型参数&nbsp;</p>
  <p>6. 构建AlphaFold3 Docker容器或Singularity镜像</p>
  <h3><strong>获取AlphaFold3源代码</strong></h3>
  <p>通过git下载AlphaFold3的代码库：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_34745438da7c4ea495dce1eb935437ab@46958_oswg11807oswg698oswg72_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>获取基因数据库</strong></h3>
  <p>此步骤需要「curl」和「zstd」。</p>
  <p>AlphaFold3需要多个基因（序列）蛋白质和RNA数据库来运行：&nbsp;</p>
  <p>- BFD small&nbsp;</p>
  <p>- MGnify&nbsp;</p>
  <p>- PDB（mmCIF格式的结构）&nbsp;</p>
  <p>- PDB seqres&nbsp;</p>
  <p>- UniProt&nbsp;</p>
  <p>- UniRef90&nbsp;</p>
  <p>- NT&nbsp;</p>
  <p>- RFam&nbsp;</p>
  <p>- RNACentral</p>
  <p>Python程序「fetch_databases.py」可以用来下载和设置所有这些数据库。</p>
  <p>建议在「screen」或「tmux」会话中运行以下命令，因为下载和解压数据库需要一些时间。完整数据库的总下载大小约为252GB，解压后的总大小为630GB。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_0209929ca2be4fad840d5cb67c53e943@46958_oswg28415oswg697oswg104_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>该脚本从托管在GCS上的镜像下载数据库，所有版本与AlphaFold3论文中使用的相同。&nbsp;</p>
  <p>脚本完成后，应该有以下目录结构：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_83521fea6b2d4a7ab11a4889d03c7158@46958_oswg68279oswg701oswg289_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>获取模型参数</strong></h3>
  <p>访问AlphaFold3模型参数需要向Google DeepMind申请并获得授权。</p>
  <h3><strong>数据管线</strong></h3>
  <p>数据管线的运行时间（即基因序列搜索和模板搜索）可能会因输入的大小、找到的同源序列数量以及可用的硬件（磁盘速度尤其会影响基因搜索的速度）而显著变化。</p>
  <p>如果想提高性能，建议提高磁盘速度（例如通过利用基于RAM的文件系统），或增加可用的CPU核心并增加并行处理。</p>
  <p>此外，请注意，对于具有深度MSA的序列，Jackhmmer或Nhmmer可能需要超出推荐的64 GB RAM的大量内存。</p>
  <h3><strong>模型推理</strong></h3>
  <p>AlphaFold3论文的补充信息中的表8提供了在配置为运行在16个NVIDIA A100上时的AlphaFold3的无需编译的推理时间，每个设备具有40GB的内存。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_5f676af0ffb44920b9220ff6a8f6f2df@46958_oswg81293oswg1068oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>相比之下，该存储库支持在单个NVIDIA A100上运行AlphaFold3，具有80GB内存，并在配置上进行了优化以最大化吞吐量。</p>
  <p>下表中使用GPU秒（即使用16个A100时乘以16）比较了这两种设置的无需编译的推理时间。该存储库中的设置在所有token大小上效率更高（提高至少2倍），表明其适合高吞吐量应用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_7115fdf01f2a442c9dc78406f0044566@46958_oswg79155oswg1080oswg377_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>硬件要求</strong></h3>
  <p>AlphaFold3正式支持以下配置，并已对其进行了广泛的数值准确性和吞吐量效率测试：&nbsp;</p>
  <p>- 1 NVIDIA A100（80GB）&nbsp;</p>
  <p>- 1 NVIDIA H100（80GB）</p>
  <p>通过以下配置更改，AlphaFold3可以在单个NVIDIA A100 (40GB) 上运行：&nbsp;</p>
  <p>1. 启用统一内存。&nbsp;</p>
  <p>2. 调整model_config.py中的pair_transition_shard_spec：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241112/v2_8a82730ae8614429a84569f50f815fc8@46958_oswg22098oswg698oswg181_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>虽然数值上准确，但由于可用内存较少，因此与NVIDIA A100 (80GB) 的设置相比，该配置的吞吐量会较低。&nbsp;</p>
  <p>虽然也可以在单个NVIDIA V100上使用run_alphafold.py中的--flash_attention_implementation=xla来运行长度最多为1280 token的AlphaFold3，但此配置尚未经过数值准确性或吞吐量效率的测试，因此请谨慎操作。</p>
  <p>参考资料：&nbsp;</p>
  <p>https://www.nature.com/articles/d41586-024-03708-4&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/rUqJMp80sR8dkaSuFyorCg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：静音&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3031722478888453</id>
            <title>对话镁伽科技： AI for Science发展，亟需智能化新基建 | 36氪专访</title>
            <link>https://www.36kr.com/p/3031722478888453</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3031722478888453</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Nov 2024 06:35:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI for Science, 生命科学, 数据工厂, 自动化实验室  
<br><br>  
总结: 文章讨论了“AI for Science”作为一种新兴的科学研究范式，强调其在诺贝尔化学奖中的重要性。镁伽科技通过建立镁伽鲲鹏实验室，旨在解决生命科学领域中数据稀缺和生产力落后的矛盾。该实验室结合机器人、自动化和人工智能技术，能够提供高质量的实验数据，促进AI模型的训练和迭代。镁伽科技的商业模式从单一设备销售转向提供综合技术服务，未来将致力于成为新一代药物研发服务提供商。 </div>
                        <hr>
                    
                    <p>文 | 王方玉</p>
  <p>编辑 | 苏建勋</p>
  <p>2024年诺贝尔化学奖揭晓后，“AI for Science”这一科学研究的新范式来到聚光灯下，受到了广泛关注。</p>
  <p>AI for Science（AI4S），即人工智能驱动的科学研究，诺贝尔化学奖的决定，很大程度上肯定了这一研究范式、乃至整个赛道的长期价值。科大讯飞董事长刘庆峰甚至在近期的发布会上直言，AI for Science决定了中国科技发展的速度。</p>
  <p>AI4S不仅是AI模型，其能够创造“奇迹”得益于从数据收集到模型构建，从实验设计到过程控制的全过程。其背后存在一个巨大的可发展的创业体系和商业空间。</p>
  <p>尤其是数据，成规模和精确的数据仍然是稀缺资源。然而现状是，当前国内生命科学实验室的设备和耗材，绝大多数仍是为手工操作而设计，并没有大规模积累数据的能力。</p>
  <p>这成为了国内生命科学领域AI4S发展的一大堵点。镁伽科技创始人兼CEO黄瑜清，将上述问题形容为“科学家们对于数据日益增长的需求和相对落后的生产力之间的矛盾。”</p>
  <p>抓住这一趋势，镁伽科技自2019年开始举公司之力打造了镁伽鲲鹏实验室，并于2021年开始投入使用。</p>
  <p>镁伽鲲鹏实验室融合了机器人、自动化、人工智能等技术，既可以为生命科学实验提供自动化的工具，也为AI for Science提供数据积累。镁伽科技将其定义为“生命科学行业的数据工厂”。</p>
  <p>今年9月，镁伽鲲鹏实验室3.0正式发布，专注于细胞基因编辑、高通量药物筛选、类器官自动化、中医药研究发现、合成生物学等领域的研究。</p>
  <p>近日，镁伽科技创始人兼首席执行官黄瑜清、联合创始人兼首席运营官张琰，以及首席科学家方攀峰博士与36氪等多家媒体进行了交流，阐释了镁伽科技在生命科学领域的布局和行业趋势的思考。</p>
  <p>以下为36氪与镁伽科技的交流实录（经摘编）：</p>
  <p><strong>媒体：镁伽科技为什么要打造镁伽鲲鹏实验室，背后看到了什么样的趋势？</strong></p>
  <p>黄瑜清：2017年创业时，我们有一个很朴素的想法是做一个方便部署的、快捷使用的机器人，可以部署到全世界上百万个生命科学实验室里。但很快我们就撞到了南墙，我们发现生命科学这个行业，负责研发的科学家们需要的不是单个机器人，而是一整个解决方案。</p>
  <p>所以从2019年开始，我们就下决心转型，开始打造超级实验室，过去几年我们在技术研发上花费了超过12亿元人民币。到今天这个实验室已经迭代了三轮。</p>
  <p><strong>媒体：镁伽鲲鹏实验室和AI for Science的关系是什么？</strong></p>
  <p>张琰：生命科学的AI研究所需要的数据是海量的。要获取海量的数据，首先要保证实验的质量，培养和测序等整个流程要是一致性的、可控的，然后数据要经过串联、治理、分类、归集，然后变成可供训练模型的数据。</p>
  <p>但此前业内的做法就是科学家手动做实验，实验的一致性和质量都很难保障，另外，数据的收集还依赖Excel等初级工具。可以说，生命科学行业现在面临的一个大趋势和最主要的矛盾，就是科学家们对于数据日益增长的需求和相对落后的生产力之间的矛盾。</p>
  <p>镁伽鲲鹏实验室的价值在于，它能通过设计实验、实施实验、测试结果，并根据结果调整模型形成干湿闭环，加速模型迭代，帮助人类在生命科学领域做出更为精准的预测。所以我们把镁伽鲲鹏实验室形容成“生命科学行业的数据工厂”。</p>
  <p><strong>媒体：镁伽科技如何保证数据的高质量和有效性？</strong></p>
  <p>方攀峰：机器自动提取，必然是一个趋势。不然一旦涉及到高通量大队列的情况，靠人的话其实是完成不了的。</p>
  <p>黄瑜清：生命科学实验室设备通常来自不同品牌，接口也不一样，所以数据格式本身就存在大量的噪音。这些原始数据无法喂给模型，甚至不同设备之间数据的相关性也是问题。所以镁伽打造了一个Megalnfomics数智化平台，它包含了中央调度软件、数据集成软件、信息化管理软件、生信分析软件等，这些软件保证了数据的有效收集、结构化、分析和追溯。</p>
  <p>张琰：镁伽鲲鹏实验室这一代的实验通量相比于前一代可以提升40倍，数据生成的能力提升100倍，数据处理能力提升了1000倍。</p>
  <p><strong>媒体：镁伽科技从卖单体设备到打造镁伽鲲鹏实验室，商业模式有没有什么变化？</strong></p>
  <p>黄瑜清：镁伽鲲鹏实验室是一个技术服务的商业模式，客户提出实验要求，镁伽鲲鹏实验室输出最终实验结果给客户。可以理解成AI和自动化升级版本的CRO（合同研究组织）。我们既卖商品，也卖服务，我相信未来服务的占比会越来越高。</p>
  <p>对于镁伽未来的定位，除了为客户提供自动化设备外，我们希望能够成为一个 AI 和自动化赋能的新一代药物研发服务提供商，成为新一代的 CRO 和CDMO。</p>
  <p><strong>媒体：AI制药公司晶泰科技这两年也在布局自动化，从软件到硬件；而镁伽科技是从硬件到布局软件。生命科学领域的自动化是不是有点殊途同归？</strong></p>
  <p>黄瑜清：最后大概率可能会是殊途同归，这是由客户的需求来决定的。</p>
  <p>举个例子，在构建模型的过程中，一定需要大量的数据。为了获取这些数据，就必然要使用相应的工具。我们的策略是先自主开发工具，而在开发工具的过程中，我们自然而然地积累了大量的数据。</p>
  <p>随后，许多客户向我们反馈，认为我们的工具非常出色，并且拥有丰富的数据资源。他们进一步询问我们，是否能帮助他们更好地处理和加工这些数据。确实，在数据加工的过程中，软件与硬件的紧密结合是至关重要的。因此，我们也非常乐意为客户提供这样的软件平台，以帮助他们解决数据加工的问题。</p>
  <p>基于这样的观察和实践，我认为，在这个行业中，顶尖的公司最终都将走向软硬件结合的道路。</p>
  <p><strong>媒体：镁伽科技推出镁伽鲲鹏实验室3.0之后，在市场拓展方面有什么样的规划？</strong></p>
  <p>黄瑜清：我认为在任何经济环境下，都有快速增长的细分市场，关键在于谁能敏锐地抓住这些机遇。镁伽的定位是提供先进生产力工具，服务于众多行业，因此我们的增长必然源自于客户的增长。我们必须时刻保持对市场的敏锐洞察力，准确判断哪些行业正在经历增长，并且评估自身是否具备抓住这些增长机遇的能力。通过实践，已经证明了我们的模式和战略是有效的。</p>
  <p>在科研或者说生命科学这个行业，总体来说的支付能力是比较强的，预算也相对充足。目前行业内整体也在提倡国产替代。所以对于镁伽来说，一方面得益于从手工设备向高度自动化的无人实验室升级的趋势；另一方面，镁伽鲲鹏实验室在数据方面的能力比传统的设备更强。在多重的市场趋势下，我们只需要顺着趋势往下走就可以了。</p>
  <p><strong>媒体：AI 加自动化，是不是未来国内生命科学自动化企业的发展方向？</strong></p>
  <p>黄瑜清：是的，就像是电动汽车的自动驾驶一样，要让AI for Science潜力充分发挥，底层的设备，包括自动化设备都是要重构的，未来的科学仪器、设备，一定是要为这样一个趋势去设计和开发的。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>