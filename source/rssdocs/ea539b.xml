<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>OpenAI / @OpenAI</title>
        <link>https://nitter.cz/OpenAI</link>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1736809614019375230#m</id>
            <title>R to @OpenAI: We encourage you to read the full Preparedness Framework (Beta) here for more detail. This is a living document, and we expect to regularly update it as we learn more. https://cdn.openai.com/openai-preparedness-framework-beta.pdf</title>
            <link>https://nitter.cz/OpenAI/status/1736809614019375230#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1736809614019375230#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 18:04:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>We encourage you to read the full Preparedness Framework (Beta) here for more detail. This is a living document, and we expect to regularly update it as we learn more. <a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf">cdn.openai.com/openai-prepar…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1736809611473432903#m</id>
            <title>R to @OpenAI: In our safety baselines, only models with a post-mitigation score of medium or below can be deployed, and only models with a post-mitigation score of high or below can be developed further. We also increase security protections commensurate with model risk.</title>
            <link>https://nitter.cz/OpenAI/status/1736809611473432903#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1736809611473432903#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 18:04:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>In our safety baselines, only models with a post-mitigation score of medium or below can be deployed, and only models with a post-mitigation score of high or below can be developed further. We also increase security protections commensurate with model risk.</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JwaXNCRGJzQUlwcC1SLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1736809608994599326#m</id>
            <title>R to @OpenAI: Our new safety baselines and governance process will turn these technical findings into safety decisions for model development and deployment. This involves establishing a cross-functional Safety Advisory Group to make safety recommendations.</title>
            <link>https://nitter.cz/OpenAI/status/1736809608994599326#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1736809608994599326#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 18:04:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Our new safety baselines and governance process will turn these technical findings into safety decisions for model development and deployment. This involves establishing a cross-functional Safety Advisory Group to make safety recommendations.</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JwaW1wemJzQUVLLTJqLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1736809604892569861#m</id>
            <title>R to @OpenAI: Our Preparedness Team will drive technical work, pushing the limits of our cutting edge models to run evaluations and closely monitor risks, including during training runs. Results will be synthesized in scorecards that track model risk.</title>
            <link>https://nitter.cz/OpenAI/status/1736809604892569861#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1736809604892569861#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 18:04:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Our Preparedness Team will drive technical work, pushing the limits of our cutting edge models to run evaluations and closely monitor risks, including during training runs. Results will be synthesized in scorecards that track model risk.</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JwaWh1cWJjQUFOazlOLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1736809603311280489#m</id>
            <title>We are systemizing our safety thinking with our Preparedness Framework, a living document (currently in beta) which details the technical and operational investments we are adopting to guide the safety of our frontier model development.
https://openai.com/safety/preparedness</title>
            <link>https://nitter.cz/OpenAI/status/1736809603311280489#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1736809603311280489#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 18:04:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>We are systemizing our safety thinking with our Preparedness Framework, a living document (currently in beta) which details the technical and operational investments we are adopting to guide the safety of our frontier model development.<br />
<a href="https://openai.com/safety/preparedness">openai.com/safety/preparedne…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDQzODgyOTcyODA5NjI1Ny9iWlA1YVhoMD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1735390088929202673#m</id>
            <title>Our new research white paper identifies seven practices for keeping increasingly agentic AI systems safe and accountable as they become more common and more capable.

We are providing research grants for work on a range of open questions. https://openai.com/research/practices-for-governing-agentic-ai-systems</title>
            <link>https://nitter.cz/OpenAI/status/1735390088929202673#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1735390088929202673#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 20:03:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Our new research white paper identifies seven practices for keeping increasingly agentic AI systems safe and accountable as they become more common and more capable.<br />
<br />
We are providing research grants for work on a range of open questions. <a href="https://openai.com/research/practices-for-governing-agentic-ai-systems">openai.com/research/practice…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTM4ODkxMTI5NDIwMTg1Ni9JX2JRUFduYz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1735349723295564020#m</id>
            <title>R to @OpenAI: There is lots of low-hanging fruit and many promising directions for future work. We think this is an exciting opportunity for the ML research community.

To kickstart more research, we're launching $10M in grants: https://x.com/OpenAI/status/1735347884718211562?s=20</title>
            <link>https://nitter.cz/OpenAI/status/1735349723295564020#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1735349723295564020#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:23:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>There is lots of low-hanging fruit and many promising directions for future work. We think this is an exciting opportunity for the ML research community.<br />
<br />
To kickstart more research, we're launching $10M in grants: <a href="https://x.com/OpenAI/status/1735347884718211562?s=20">x.com/OpenAI/status/17353478…</a></p>
<p><a href="https://nitter.cz/OpenAI/status/1735347884718211562#m">nitter.cz/OpenAI/status/1735347884718211562#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1735349722020495665#m</id>
            <title>R to @OpenAI: Naive weak supervision isn't enough—current techniques, like RLHF, won't be sufficient for future superhuman models.

But we also show that it's feasible to drastically improve weak-to-strong generalization—making iterative empirical progress on a core challenge of superalignment</title>
            <link>https://nitter.cz/OpenAI/status/1735349722020495665#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1735349722020495665#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:23:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Naive weak supervision isn't enough—current techniques, like RLHF, won't be sufficient for future superhuman models.<br />
<br />
But we also show that it's feasible to drastically improve weak-to-strong generalization—making iterative empirical progress on a core challenge of superalignment</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1735349720435048751#m</id>
            <title>R to @OpenAI: Large pretrained models have excellent raw capabilities—but can we elicit these fully with only weak supervision?

GPT-4 supervised by ~GPT-2 recovers performance close to GPT-3.5 supervised by humans—generalizing to solve even hard problems where the weak supervisor failed!</title>
            <link>https://nitter.cz/OpenAI/status/1735349720435048751#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1735349720435048751#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:23:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Large pretrained models have excellent raw capabilities—but can we elicit these fully with only weak supervision?<br />
<br />
GPT-4 supervised by ~GPT-2 recovers performance close to GPT-3.5 supervised by humans—generalizing to solve even hard problems where the weak supervisor failed!</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JVeVVzT2F3QU1SZHg2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1735349718765715913#m</id>
            <title>In the future, humans will need to supervise AI systems much smarter than them.

We study an analogy: small models supervising large models.

Read the Superalignment team's first paper showing progress on a new approach, weak-to-strong generalization: https://openai.com/research/weak-to-strong-generalization</title>
            <link>https://nitter.cz/OpenAI/status/1735349718765715913#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1735349718765715913#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:23:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>In the future, humans will need to supervise AI systems much smarter than them.<br />
<br />
We study an analogy: small models supervising large models.<br />
<br />
Read the Superalignment team's first paper showing progress on a new approach, weak-to-strong generalization: <a href="https://openai.com/research/weak-to-strong-generalization">openai.com/research/weak-to-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JVeUo5QmF3QUVhNWlmLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1735347885955584352#m</id>
            <title>R to @OpenAI: Figuring out how to ensure future superhuman AI systems are aligned and safe is one of the most important unsolved technical problems in the world. But we think it is a solvable problem.

There is lots of low-hanging fruit, and new researchers can make enormous contributions!</title>
            <link>https://nitter.cz/OpenAI/status/1735347885955584352#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1735347885955584352#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:15:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Figuring out how to ensure future superhuman AI systems are aligned and safe is one of the most important unsolved technical problems in the world. But we think it is a solvable problem.<br />
<br />
There is lots of low-hanging fruit, and new researchers can make enormous contributions!</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1735347884718211562#m</id>
            <title>We're announcing, together with @ericschmidt: Superalignment Fast Grants.

$10M in grants for technical research on aligning superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.

Apply by Feb 18! https://openai.com/blog/superalignment-fast-grants</title>
            <link>https://nitter.cz/OpenAI/status/1735347884718211562#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1735347884718211562#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:15:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>We're announcing, together with <a href="https://nitter.cz/ericschmidt" title="Eric Schmidt">@ericschmidt</a>: Superalignment Fast Grants.<br />
<br />
$10M in grants for technical research on aligning superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.<br />
<br />
Apply by Feb 18! <a href="https://openai.com/blog/superalignment-fast-grants">openai.com/blog/superalignme…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTM0NzAzMDU5MDE0NDUxMi8wMlo2QkY1Sj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1734940445824937993#m</id>
            <title>We have formed a new global partnership with @AxelSpringer and its news products.

Real-time information from @politico, @BusinessInsider, European properties @BILD and @welt, and other publications will soon be available to ChatGPT users.

ChatGPT’s answers to user queries will include attribution and links to full articles for transparency and further information. http://www.openai.com/blog/axel-springer-partnership</title>
            <link>https://nitter.cz/OpenAI/status/1734940445824937993#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1734940445824937993#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 14:16:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>We have formed a new global partnership with <a href="https://nitter.cz/AxelSpringer" title="Axel Springer SE">@AxelSpringer</a> and its news products.<br />
<br />
Real-time information from <a href="https://nitter.cz/politico" title="POLITICO">@politico</a>, <a href="https://nitter.cz/BusinessInsider" title="Business Insider">@BusinessInsider</a>, European properties <a href="https://nitter.cz/BILD" title="BILD">@BILD</a> and <a href="https://nitter.cz/welt" title="WELT">@welt</a>, and other publications will soon be available to ChatGPT users.<br />
<br />
ChatGPT’s answers to user queries will include attribution and links to full articles for transparency and further information. <a href="http://www.openai.com/blog/axel-springer-partnership">openai.com/blog/axel-springe…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1732103075144532197#m</id>
            <title>Our Safety Systems team is on the frontlines of ensuring the safety and reliability of our AI models in the real world today.

Learn about the team’s vision, challenges, and structure and see how you can be part of making AI safer and more beneficial for society. https://openai.com/safety/safety-systems</title>
            <link>https://nitter.cz/OpenAI/status/1732103075144532197#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1732103075144532197#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 18:22:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Our Safety Systems team is on the frontlines of ensuring the safety and reliability of our AI models in the real world today.<br />
<br />
Learn about the team’s vision, challenges, and structure and see how you can be part of making AI safer and more beneficial for society. <a href="https://openai.com/safety/safety-systems">openai.com/safety/safety-sys…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1730272610586599845#m</id>
            <title>ChatGPT is turning 1! 🥳🎂

Today we’re celebrating our users around the world who are doing amazing things.</title>
            <link>https://nitter.cz/OpenAI/status/1730272610586599845#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1730272610586599845#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 17:08:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT is turning 1! 🥳🎂<br />
<br />
Today we’re celebrating our users around the world who are doing amazing things.</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FNb2V4ZmE4QUlPbzM4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1730030975931846939#m</id>
            <title>Sam Altman is back as CEO, Mira Murati as CTO and Greg Brockman as President. OpenAI has a new initial board. Messages from @sama and board chair @btaylor https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board</title>
            <link>https://nitter.cz/OpenAI/status/1730030975931846939#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1730030975931846939#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 01:08:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam Altman is back as CEO, Mira Murati as CTO and Greg Brockman as President. OpenAI has a new initial board. Messages from <a href="https://nitter.cz/sama" title="Sam Altman">@sama</a> and board chair <a href="https://nitter.cz/btaylor" title="Bret Taylor">@btaylor</a> <a href="https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board">openai.com/blog/sam-altman-r…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMzI3MjI3ODQzNDIyMjA4MC80ZWdDUmJJQj9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1727236805182026159#m</id>
            <title>OpenAI is nothing without its people</title>
            <link>https://nitter.cz/OpenAI/status/1727236805182026159#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1727236805182026159#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 08:05:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI is nothing without its people</p>
<p><a href="https://nitter.cz/gdb/status/1727230819226583113#m">nitter.cz/gdb/status/1727230819226583113#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1727210837868437901#m</id>
            <title>❤️</title>
            <link>https://nitter.cz/OpenAI/status/1727210837868437901#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1727210837868437901#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 06:22:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>❤️</p>
<p><a href="https://nitter.cz/sama/status/1727207458324848883#m">nitter.cz/sama/status/1727207458324848883#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1727210687502651417#m</id>
            <title>❤️</title>
            <link>https://nitter.cz/OpenAI/status/1727210687502651417#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1727210687502651417#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 06:21:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>❤️</p>
<p><a href="https://nitter.cz/gdb/status/1727208843137179915#m">nitter.cz/gdb/status/1727208843137179915#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OpenAI/status/1727206187077370115#m</id>
            <title>We have reached an agreement in principle for Sam Altman to return to OpenAI as CEO with a new initial board of Bret Taylor (Chair), Larry Summers, and Adam D'Angelo.

We are collaborating to figure out the details. Thank you so much for your patience through this.</title>
            <link>https://nitter.cz/OpenAI/status/1727206187077370115#m</link>
            <guid isPermaLink="false">https://nitter.cz/OpenAI/status/1727206187077370115#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 06:03:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>We have reached an agreement in principle for Sam Altman to return to OpenAI as CEO with a new initial board of Bret Taylor (Chair), Larry Summers, and Adam D'Angelo.<br />
<br />
We are collaborating to figure out the details. Thank you so much for your patience through this.</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>