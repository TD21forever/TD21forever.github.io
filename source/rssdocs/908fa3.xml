<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/2575928949384579</id>
            <title>成立2年融资近9亿，AI NPC引爆游戏行业巨变，微软等大厂已经入局</title>
            <link>https://www.36kr.com/p/2575928949384579</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2575928949384579</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 09:19:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 游戏行业, 大语言模型, AI NPC体验, 微软与inworld合作
<br>
<br>
总结: 游戏行业正在加速拥抱大语言模型等AI技术，微软与inworld合作开发Xbox工具，让游戏开发者能够创建由AI驱动的角色、故事和任务。这将为游戏行业带来全新的AI NPC体验。 </div>
                        <hr>
                    
                    <p><strong>【导读】</strong>游戏行业真在加速拥抱大语言模型等AI技术，不论是大厂还是独立游戏制作人，都开始依靠LLM的技术创立全新的AI NPC体验。</p><p>在聊天机器人之外，如何让大语言模型完成产品化落地，一直是一个世界性的难题。</p><p>因为大语言模型本身可解释性低，内容受到幻觉影响，很多专业度很高的行业，要真正用上大模型的能力，也许还有一段距离。</p><p>而游戏行业，已经成为了第一批全面拥抱大模型的行业！</p><p>最近，微软宣布与AI初创公司inworld达成合作，一同开发Xbox工具，让游戏开发者能够创建由AI驱动的角色、故事和任务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_863c52c3e7654d118215577a6955273d@46958_oswg115063oswg640oswg427_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>微软与inworld签订了一个持续多年的合作伙伴关系，将包括共同开发一个「AI 设计副驾驶」系统，Xbox开发人员可以使用该系统创建详细的脚本、对话树、任务线等。</p><p>根据微软官方的说法，nworld在使用生成式AI模型进行角色开发方面的专业知识、微软尖端的基于云的 AI 解决方案（包括 Azure OpenAI 服务）、微软研究院对未来游戏的技术见解，以及Team Xbox的游戏制作和发行方面的经验，为所有开发人员提供负责任的创建者工具。</p><p>合作目标是共同提供一个易于使用的多平台人工智能工具集，以协助和授权创作者进行对话、故事和任务设计。该工具集将包括：</p><p>AI游戏设计Copilot，可协助游戏设计师探索更多创意，将提示转化为详细的脚本、对话树、任务等。</p><p>集成到游戏客户端中的AI角色引擎，通过动态生成的故事、任务和对话来实现全新的故事和剧情，供玩家体验。</p><p>inworld作为一家由前谷歌员工成立的初创公司，已经为很多大型游戏公司提供了AI生成的NPC和故事线的解决方案。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_476ded56062a438bab82dd07aad954fa@46958_oswg32522oswg1080oswg192_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>公司成立两年多的时间，融资超过一亿两千万美元，已经和网易，迪士尼等游戏和动画行业的大厂完成了合作。</p><p>由NetEase旗下的工作室推出的Cygnus Enterprises, 就利用了inworld推出的AI NPC的功能，创制出来的AI伴侣不仅可以为玩家提供一个有趣的角色，让他们在收集资源时与之交谈，还可以在玩家通过语音命令要求 AI 同伴收集资源时，指示他们为玩家收集资源。</p><h2><strong>被谷歌收购的连续创业者再次创业</strong></h2><p>Inworld创始人Ilya Gelfenbeyn，Michael Ermolenko之前创立了API.AI。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_9ee1b530b17248f3937754060d8cb6ab@46958_oswg211458oswg540oswg303_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>API.AI被Google收购后更名为Dialogflow，集成进了Google Cloud之中，成为了市场上最受欢迎的对话式AI平台。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_37f45ce4233f44e3a7c9769c61d32e8d@46958_oswg271316oswg1080oswg706_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>之后于2021年，他们再次创业，成立了Inworld。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_8801945a04de4593bb8930c133c6fb26@46958_oswg104189oswg1080oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在2022年底推出了一款利用GPT-3来生成游戏NPC对话内容的工具，成为了OpenAI的官方宣传案例。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_ece7dc1cfc5f42a8b0ff17d722ffd4d6@46958_oswg202842oswg1080oswg700_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随后，Inworld推出了名为「角色引擎」的产品，专门帮助游戏开发人员创立个性化的AI NPC。</p><p>AI NPC 可以学习和适应，利用情商处理关系，具有记忆力和回忆能力，并且能够自主启动目标、执行行动并遵循自己的动机。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_9813e4c48b6341c68b770869185e45dc@46958_oswg572139oswg994oswg557_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>使用定义的触发器、意图识别和动机来触发角色对玩家行为的反应并驱动游戏中的交互。「角色引擎」的目标和行动功能让用户驱动NPC行为，以动态和自定义的方式响应玩家的输入。</p><p>玩家认为，就像游戏动画引擎一样，角色引擎可能会改变未来3A大作的体验方式。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_05c2fa98b5604bc8a968784f1168a2a7@46958_oswg23858oswg1011oswg78_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>角色通过从闪存和长期记忆中检索信息，以类似人类的记忆功能进行操作，从而创造出玩家返回的引人入胜的体验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_4b2d5bc2f45f4450a4cc004b29cc835c@46958_oswg184928oswg1019oswg573_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Inworld通过编排30多个机器学习模型来支持多模式角色表达，这些模型旨在模仿全方位的人类交流，包括语音变化和语调、面部表情和肢体语言等非语言线索。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_1374766b2bf94c84839982c136a61e9d@46958_oswg208757oswg1019oswg573_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>世界中的角色能够根据与用户的互动来表达情感。情绪可以映射到动画、目标和触发器之上，呈现出性格丰富而真实的NPC。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_f2e1f024f2954c2e975f9ff7a52ed1e4@46958_oswg248391oswg1019oswg539_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「角色引擎」可以使用内置语音设置以最小化延迟，并配置角色的性别、年龄、音调和说话速度。或者，使用类似像「ElevenLabs」这样的第三方服务来创建自定义和复刻声音。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_18115544e9d44f958dd7fcf64bfde31e@46958_oswg85373oswg1014oswg586_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>在自己的电脑上实现本地AI NPC的框架</strong></h2><p>而大部分像「角色引擎」这种使用生成式AI提供AI NPC功能的工具，都可以使用几乎免费或者开源的技术替代。</p><p>这给了很多独立游戏制作者在这个领域赶上大厂的希望。</p><p>我们曾经就介绍过一个「上古卷轴」的AI NPC mod。</p><p>最近，开发者Joe Gibbs，分享了自己在自己的电脑上自己通过开源大模型搭建智能NPC的本地框架：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_9a0dcda1c48647f7b9603f55bbbed309@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，Joe Gibbs使用llama.cpp和Mistral7b来创造对话内容，并利用StyleTTS2来生成语音，同时使用Unreal Engine 5来进行场景渲染。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_57c4599fdf254eb1bb71dc5f0c38e894@46958_oswg109385oswg1080oswg297_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>项目地址：https://github.com/joe-gibbs/local-llms-ue5</p><p>起初，他将llama.cpp作为动态链接库（DLL）集成到了Unreal中，但过程并不顺利。于是，他转而构建了一个用Node.js脚本实现的解决方案。</p><p>至于语音部分，则使用mrfakename提供的StyleTTS2演示版Docker容器镜像，并通过Gradio的API接口与之进行交互。理想情况下，如果不必依赖Docker容器会更好，但我没能在我自己的电脑上直接运行 StyleTTS2 模型。</p><p>实现配置如下：</p><p>系统：Windows 11</p><p>硬盘：三星980 PRO M.2 1TB</p><p>CPU：英特尔Core i5 12600KF</p><p>内存：64GB DDR5</p><p>GPU：英伟达GeForce RTX 4070 12GB</p><h3><strong>工作原理</strong></h3><p>在Unreal中，通过调用FInteractiveProcess类来执行Node脚本。这个脚本将先前的对话历史作为命令行参数传入，然后逐句输出NPC的对话内容。为了提升性能，可以不等整个对话生成完毕，边播放当前句子边生成并发声下一句。</p><p>输出一个JSON对象，包含字幕所需的文本和相应音频文件的位置信息，Unreal会解析成结构体后进行播放。</p><h3><strong>性能表现</strong></h3><p>性能方面意外地出色。生成新句子时会略微卡顿，但影响不大。StyleTTS2需要使用14GB的RAM，而Llama服务器需要3GB，因此运行它需要较大的内存空间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_3b50c7a602104ecba0d648b495ceb994@46958_oswg245936oswg1080oswg583_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>至于帧率，正如视频所展示的，系统能轻松保持流畅的60 FPS。</p><p>生成新句子大约需要2-3秒。或许可以在生成句子期间播放一些动画，以减少等待时的不适感，但现状已经相当不错了。</p><p>如果搭配使用Whisper，可以在生成回应时稍微延迟玩家语音转录显示在屏幕上的速度，这种体验用户在使用Siri等服务时已经比较熟悉了。</p><h3><strong>缺陷</strong></h3><p>尽管速度更快，但Mistral模型与GPT-3.5相比，主要的缺点在于其连贯性较差。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_dae174df30f34693bbd17506cc3ddb8b@46958_oswg36733oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>容易跑题，而且还是会有幻觉问题的存在。例如，在一个测试中，它指引玩家前往几英里外的村庄，尽管玩家实际上已经处于那个村庄之中。</p><p>同样地，在视频中可以看到，它知道玩家名为John，这个信息实际上并未在对话中被提及，它还提到了Angers这个要在数百年之后才出现的地名。</p><p>此外，它对于游戏世界里可能发生和不可能发生的事情也缺乏现实感。比如，在演示视频中展示的训练村民的任务，实际上是不可能完成的，因为游戏内根本没有相关的机制支持。</p><p>StyleTTS2的语音合成效果也不够自然，仍然带有些许机械感。对于它不熟悉的单词，它的发音也不太准确，或者会根据上下文错误地发音。</p><h3><strong>未来的改进方向</strong></h3><p>目前，这只是一个初步的概念实验框架，如果要在本地良好的运行这个框架，还有许多方面可以进行优化。</p><p>- 首先，可以尝试将llama.cpp 作为动态链接库 (DLL) 集成到Unreal引擎中。这样可以避免使用Node.js脚本，从而大大简化游戏的分发流程。</p><p>- Mistral有时会跑题，因此最好针对游戏的背景进行调整。比如，目前似乎无法通过设定来完全避免它产生不符合时代背景的表述，当一个设定在12世纪的角色突然能解释如何使用AWS时，这会让玩家感到很出戏。</p><p>- 此外，调整算法这样能在文本输出中标注情感也是一个可能的选项。通过使用StyleTTS2，可以传入语音克隆的片段，这样只需让配音演员用不同的情感朗读一个句子，就可以根据这个特定的样本来生成语音。</p><p>- 还有一些其他的方法值得探索，比如StyleTTS2能与Unreal引擎更紧密地结合。如果能摆脱对特定Python版本和特定Python包的依赖，那将大有裨益。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231225/v2_af245dbffa3643a88a44d4c588af0962@46958_oswg72501oswg828oswg552_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>- 集成Whisper也许就能让玩家自然地与NPC对话并得到回答。</p><p>在技术展示的其他方面，还有一些间接相关的改进措施。例如，NPC在对话时嘴唇不会动。可以使用类似于audio2face的技术来解决这个问题，而且不会对游戏性能产生太大的影响。</p><p>此外，还可以让大语言模型（LLM）通过返回包含动画指令的JSON数据，来控制 NPC的肢体动作，从而使得对话更加生动。</p><h3><strong>对未来的一些思考</strong></h3><p>作者设想了一个随着玩家开始对话而更新的数据库方案。</p><p>该数据库将储存关于玩家、NPC（包括他们的背景故事和目标）、世界等方面的信息，以此作为对话的基础。</p><p>系统会创建一个详尽的文件，记录玩家的所有任务历史（NPC 所知道的部分）、玩家身上的装备、当前天气、NPC 与其他 NPC 的互动、以及与玩家的聊天记录（包括日期、时间等，方便推测玩家提到的是过去的某个事件），接着在提交给大语言模型 (LLM) 前，对这份文件进行自然语言的查询分析。</p><p>当然，最理想的情况还是由人工精心设计任务。</p><p>目前来看，让大语言模型自行设计完整任务还暂时做不到 。</p><p>可能会导致像《上古卷轴》中那样重复的任务，简单的重复「去某地做某事」是很难被游戏玩家接受的。</p><p>行业还需要精确训练的大语言模型，专注于其擅长的领域，并拒绝执行超出能力范围的任务。可以给它设定一个能力列表（如给予物品、取走物品、开始任务等），并让它拒绝执行列表之外的操作。</p><p>不过这篇分享的重点是展示如何在本地完整运行一个AI NPC角色框架，现在来看实现这目标并不复杂。</p><p>参考资料：</p><p>https://www.cnbc.com/2023/12/23/the-first-minds-controlled-by-gen-ai-will-live-inside-video-games.html</p><p>https://jgibbs.dev/blogs/local-llm-npcs-in-unreal-engine</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Ms46OU1xbxOwSrterHLWZw" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：润&nbsp;好困，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>