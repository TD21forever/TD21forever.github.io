<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/2999283499710598</id>
            <title>向现实低头，苹果或要做更便宜的Vision头显</title>
            <link>https://www.36kr.com/p/2999283499710598</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2999283499710598</guid>
            <pubDate></pubDate>
            <updated>Sun, 20 Oct 2024 02:30:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <苹果, Vision Pro, Meta, 应用开发>
<br>
<br>
总结: 苹果的Vision Pro设备在市场表现不佳，与Meta的VR头显形成鲜明对比。为了应对这一局面，苹果计划在2025年推出一款更便宜的Vision头显，预计价格约为2000美元。尽管苹果声称已有2500款专为Vision Pro开发的应用，但实际应用数量和开发者参与度却显著低于预期。开发者对MR应用的开发成本和风险感到担忧，导致他们不愿意投入。苹果面临的挑战是如何吸引开发者和消费者，可能需要采取激励措施来促进应用生态的繁荣。 </div>
                        <hr>
                    
                    <p>承载着苹果下一个十年野望的空间计算设备Vision Pro叫好不叫座，几乎已经是毋庸置疑的事情。可偏偏隔壁Meta的VR头显和智能眼镜都取得了空前的市场成绩，以至于近日有消息称，苹果Vision Pro团队可能正在努力开发更具吸引力的设备，以应对Meta在智能眼镜领域的成功。</p>
  <p>根据彭博社的报道显示，苹果方面或计划于2025年推出一款价格约为2000美元的Vision头显，与现款的Vision Pro相比，前者将采用更便宜的材料和性能更低的芯片，并且不支持EyeSight功能。从现阶段Vision Pro的市场表现来看，苹果下一款空间计算设备价格更亲民，应该是必然的事情。</p>
  <p>此前《华尔街日报》追踪了自今年2月2日在美国上市以来，Vision Pro每月新发布的应用，他们发现在吸引主要软件开发商为其开发应用方面似乎遇到了困难。自预售以来，Vision Pro平台每月发布的新应用数量正逐月减少。</p>
  <p>移动应用分析公司Appfigures公布的相关数据也显示，Vision Pro的应用商店在9月仅推出了10款应用程序，远远低于该设备推出前两个月数百款的新应用数量。截至9月，App Store中约有1770个Vision Pro的应用程序，其中只有34%是为其定制的。</p>
  <p>值得一提的是，此前苹果方面在8月曾宣称专为Vision Pro开发的应用数量已超过2500款。对于其中的差异，Appfigures的说法是可能是因为某些应用的使用率不够高，无法在排行榜中被追踪，所以导致他们很难发现这些应用。然而即使是2500款应用的说法，Vision Pro这样的表现显然也不太尽如意。</p>
  <p>比如App Store在2008年发布时推出了大约500款App，仅仅一年后就已经增加至5万个。Apple Watch在2015年4月上市时的应用数量大约为3000个，等到iPhone 6s在同年9月9日发布时，Apple Watch的App数量就已经突破1万个。</p>
  <p>对于这一现象，曾经在苹果负责过Vision Pro研发的Bertrand neveu就表示，“这是一个先有鸡，还是先有蛋的问题。”</p>
  <p>苹果方面希望开发者为Vision Pro带来更多的专属应用，并期待从中诞生一款杀手级应用来吸引消费者，一如当年的iPhone与《愤怒的小鸟》。而开发者则想要等到Vision Pro成熟再下场，不愿重蹈当年Windows Phone开发者的覆辙。所以这也是为什么苹果又是搞Vision Pro开发者实验室，又是联手Unity打造创作者工具，可至今开发者的反应还比较冷淡。</p>
  <p>不同于智能手机和智能手表，MR（混合现实）应用已经不再是二维、而是三维，空间概念的引入会大幅提升开发者为Vision Pro打造专属应用的难度。并且Vision Pro与市面上绝大多数VR头显不同的交互设计，也增加了现有VR应用的适配难度，眼球追踪和手势操作固然很“高大上”，但也与目前常用的VR手柄有所差异，以至于以往用手柄为操控设备的VR游戏无法直接就移植。</p>
  <p>简而言之，相比于已经很成熟的智能手机App开发体系，MR应用的开发成本更高。同时由于Vision Pro的用户规模有限，也导致为其开发应用的风险过高。想要解决这个问题，目前苹果面前有两条路，第一个选项是学习华为的解决方案，为了繁荣鸿蒙生态，他们推出了鸿蒙原生应用的开发者激励，开发者年前上架鸿蒙原生应用最高就可以拿到10万元。</p>
  <p>就好比互联网厂商推广产品时会拿出真金白银来补贴用户，砸钱来吸引开发者显然也是可行。只不过苹果过去从未有过类似的操作，所以他们是否有魄力打破常规是一个问题。如果不能用钱来砸，那么就只有满足开发者诉求这一条路了。</p>
  <p>到目前为止，在一众AR、VR、MR硬件中最为成功的产品非Meta Quest 2莫属，而其能够在全球卖出超过1500万台，靠的就是发布时仅为299.99美元的超低价格。对于消费者而言，Meta Quest 2、苹果Vision Pro都是以尝鲜为主，它们现阶段都还无法代替智能手机。可如果是从“玩具”的角度出发，那么自然就是越便宜越好。</p>
  <p>诚然，苹果可能会在2025年推出的Vision头显卖2000美元左右也不便宜，但这已经只有Vision Pro现在价格的三分之二，1500美元即便是对于大多数美国消费者来说，都不是一个能忽视的小数字。而更便宜的Vision头显才有成为大众消费品的潜力，或许才可以给予开发者打造相关应用的理由。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649873177&amp;idx=2&amp;sn=2e12e4c769385d7696f329f365692011&amp;chksm=860af249a6e26465ebe6f43292d8a460f884f0502c3465872788f9bc928cc5e2f9f3a1f97470&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2998717634655363</id>
            <title>字节跳动实习生投毒自家大模型细节曝光，影响到底有多大？</title>
            <link>https://www.36kr.com/p/2998717634655363</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2998717634655363</guid>
            <pubDate></pubDate>
            <updated>Sat, 19 Oct 2024 05:30:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 字节跳动, 实习生, 模型训练, 内部攻击  
<br><br>  
总结: 字节跳动在今年6月遭遇了一名实习生的内部技术攻击，该实习生因对资源分配不满，利用Huggingface平台的漏洞破坏了团队的模型训练任务。事件导致模型训练效果不稳定，影响了近30位员工的工作。虽然该实习生试图推卸责任，但证据显示其在长达两个月的时间内进行了恶意攻击。字节跳动已对其辞退，并通报相关行业和学校，但目前该实习生未受到其他处罚。事件引发了对实习生权限管理的担忧。 </div>
                        <hr>
                    
                    <p class="image-wrapper">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/T7a2wzKvdoOgauhMK7K0yQ" rel="noopener noreferrer nofollow">“凤凰网科技”</a>，作者：董雨晴，36氪经授权发布。</p>
  <p><strong>作者｜董雨晴</strong></p>
  <p>10月19日，字节跳动大模型训练遭实习生攻击一事引发广泛关注。据多位知情人士透露，字节跳动某技术团队在今年6月遭遇了一起内部技术袭击事件，一名实习生因对团队资源分配不满，使用攻击代码破坏了团队的模型训练任务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241019/v2_02aa47677a89437c8005fc81f6e2ac1f@1883322323_oswg80953oswg640oswg516_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc" label="图片描述">图｜来源于网络&nbsp;</p>
  <p>据悉，该事件的主要涉事者为一名田姓实习生所为，他利用了Huggingface（HF）平台的漏洞，在公司的共享模型中写入了破坏代码，导致模型训练效果忽高忽低，无法产生预期的训练成果。</p>
  <p>一位前字节技术员工表示，“字节AI Lab的实习生权限和正职员工差异不大，也使得此次事件有了发生的机会”，其也对此次事件带来的恶性影响表达了担忧，“这件事之后肯定会极大地收缩实习生的权限”。</p>
  <p>在消息曝出后，该名涉事实习生试图在社交平台上辟谣，将责任推给他人，不过很快便遭到了接近字节跳动人士的否认。</p>
  <p>据相关知情人士在Gitbub上表述，<strong>“你（指田某）在长达2个月的时间里对集群代码进行恶意攻击，对公司近30位各级员工造成巨大伤害，让你的同事近一个季度的工作白费。所有的记录和审查都证明这是不容狡辩的事实！”</strong></p>
  <p>该名人士还分享了一则调查人员对田姓实习生 (TianKeyu)的询问录音，录音中的对话还原其攻击的过程：田某最先输入的code本来是被用于影响通讯和随机性的，“最开始的时候它并不是以攻击为目的，它是为了debug，但这确实会涉及到程序的一些运行情况。但是后面它经过一些文件，就是那些upload文件，code也会被update，code就变成了攻击code。它大概的作用就是去修改code，然后就会造成一些后果。”</p>
  <p>录音中疑似田某本人的回应承认了其通过update使得code带有了攻击性。其也对问询人员明确表示，“就是因为某些原因导致了我们都非常不满”。</p>
  <p><strong>另据传闻称此次损失可能超过千万美元，但内部人士表示实际损失并没有传闻中那么严重。</strong></p>
  <p>据了解，该事件发生于今年6月底，<strong>目前字节跳动已对田姓实习生采取了辞退处理，并将此事通报给相关行业联盟和该实习生所在的学校。</strong></p>
  <p>不过前述相关知情人士表示，<strong>除了被字节辞退，田某目前未受到任何处罚。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241019/v2_9f72ab6b2d95458eae6b039c58ab7cc8@1883322323_oswg97553oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>多方消息显示，田姓实习生为国内某高校在读博士生，于2021年9月起在字节AI Lab实习，其所在的团队刚在今年4月与北大王立威团队提出了VAR研究，在图像生成质量、推理速度、数据效率和可拓展性等方面均超过了DiT。此外，VAR的推理速度比传统自回归模型快了约20倍。</p>
  <p>截至发稿，字节跳动方面仍未对此事进行公开回应。</p>
  <p>注：本文部分图片来源于网络，如有侵权，可联系我们删除。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>