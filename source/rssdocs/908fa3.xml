<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/3000755413711233</id>
            <title>特斯拉Robotaxi上路，产业寡头化进程被提速？</title>
            <link>https://www.36kr.com/p/3000755413711233</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3000755413711233</guid>
            <pubDate></pubDate>
            <updated>Mon, 21 Oct 2024 01:00:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Robotaxi, 特斯拉, 自动驾驶, 商业化  
<br><br>  
总结: 特斯拉于2024年10月发布了名为Cybercab的Robotaxi，预计于2026年开始生产，成本低于3万美元。特斯拉的Robotaxi构想与其智能电动车上市几乎同步，旨在通过共享经济让车主获利。随着自动驾驶技术的成熟，Robotaxi有潜力颠覆汽车产业。尽管特斯拉的Robotaxi业务多次跳票，但其FSD技术的进步为业务落地提供了支持。全球Robotaxi市场竞争激烈，特斯拉、谷歌和百度等企业处于领先地位。未来，Robotaxi的成功与否将取决于技术成熟度和制造成本的降低。 </div>
                        <hr>
                    
                    <p>2024年10月11日，特斯拉召开主题为“We,Robot”的Robotaxi演示活动，发布了名为Cybercab的Robotaxi。据了解，Cybercab仅有两座，采用蝶翼式车门，没有方向盘、油门和刹车板，完全依赖特斯拉的FSD。</p>
  <p>特斯拉CEO马斯克介绍称，CyberCab的成本将低于3万美元，交通成本约为0.2美元/英里，预计于2026年开始生产。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_3da9ea63067b4d59ba8094b8b3e5cff7@000000_oswg7456oswg534oswg146_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：特斯拉</p>
  <p>粗看起来，作为一家车企，特斯拉推出CyberCab有些不务正业，但事实上，特斯拉的Robotaxi构想几乎与自家的智能电动车上市相同步，称得上是公司的“第二条曲线”。早在2016年7月，特斯拉就在“宏图第二篇章”中阐述了Robotaxi理念，“让车辆闲置的时候，通过分享帮车主赚钱”。</p>
  <p>事实上，结合行业发展趋势来看，随着自动驾驶技术逐步成熟，Robotaxi确实有可能颠覆汽车产业。</p>
  <p>Frost&amp;Sullivan预测，2030年中国L4及以上自动驾驶渗透率有望达9.5%，Robotaxi市场规模将达4888亿元。加拿大皇家银行资本市场分析师Tom Narayan在研报中表示，随着Robotaxi技术逐步成熟，消费者将不会再购买私家车。在此背景下，特斯拉确实有必要提前布局Robotaxi。</p>
  <p>因Robotaxi极具想象力，目前不止特斯拉，谷歌、百度、如祺出行等企业也在布局相关业务。比如，2024年6月，百度的萝卜快跑在武汉提供全无人驾驶叫车服务，引发网友热议。小鹏汽车CEO何小鹏也宣称，计划于2026年推出Robotaxi。</p>
  <p>尽管特斯拉此前的Robotaxi发布会颇为无聊，对投资者也没有太强的吸引力，但此番特斯拉切入Robotaxi赛道，还是清晰无误昭示出，马斯克对自家的FSD技术足够自信。随着FSD入华以及Cybercab量产，一众中国Robotaxi玩家，或将直面特斯拉这个凶悍的“拦路虎”。</p>
  <h2><strong>1 马斯克虚晃一枪，FSD极具威慑力</strong></h2>
  <p>尽管早已明确提出Robotaxi构想，并且马斯克也屡屡宣传Robotaxi概念，但特斯拉的Robotaxi业务却屡屡跳票。</p>
  <p>早在2019年，马斯克就宣称，2020年某个时间，特斯拉将拥有100万辆自动驾驶出租车。不过如我们所见，2020年时，特斯拉的Robotaxi业务并未落地。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_fd5319ea1bd14f16ad7bdef6d1f486f9@000000_oswg486916oswg1080oswg749_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：特斯拉</p>
  <p>2022年，马斯克将特斯拉Robotaxi的量产时间推迟至2024年，并宣称将“扔掉方向盘或踏板”。终于，2024年4月，特斯拉官宣，将于8月8日推出Robotaxi。不过，特斯拉的Robotaxi又延期2个月，最终于10月11日正式问世。</p>
  <p>复盘特斯拉Robotaxi业务的发展史可以发现，2024年后，其Robotaxi产品落地速度明显加快。这或许是因为特斯拉的FSD技术逐步成熟。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_f467ad041e994bcfbe07b37106d2e143@000000_oswg865672oswg1080oswg591_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：何小鹏</p>
  <p>2024年3月，FSD Beta测试计划结束，“FSD Beta”更名为“FSD （Supervised）”。与此同时，基于“端到端”技术的FSD V12在北美大规模推送，好评如潮。何小鹏体验完FSD V12.3.6后在社交媒体平台表示，“FSD在硅谷和高速表现极好，可以达到很高的分数。”</p>
  <p>考虑到特斯拉的Cybercab取消了方向盘、油门和刹车板，其显然高度依赖自动驾驶技术。而FSD V12高度成熟，无疑是特斯拉Robotaxi业务落地的关键推手。</p>
  <p>即便两年后才会生产，但Cybercab在此时发布，也从侧面说明，特斯拉的自动驾驶技术，已经达到了一定高度，这或许会给竞争对手带来较强的威慑力。</p>
  <p>与大部分车企采购开放供应链的智驾方案，并且需要激光雷达作为安全冗余不同，特斯拉拥有自研智驾芯片，并且采用纯视觉方案，技术和成本优势都更为明显。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_099fa6d886084a35819e8960fca79b13@000000_oswg148594oswg1080oswg423_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：信达证券</p>
  <p>比如，最新款的特斯拉车型搭载了HW4.0自动驾驶硬件，拥有第二代FSD芯片，CPU内核从12个增加至20个，算力从144 TOPS提升到720 TOPS。对比而言，其他车企的旗舰车型大多采用双英伟达Orin芯片，算力仅为568 TOPS。</p>
  <p>自研芯片不止可以带来更高的算力，还决定了特斯拉自动驾驶技术的硬件和软件算法高度契合。在此基础上，特斯拉发力更具竞争力的端到端自动驾驶技术，充分挖掘出了HW4.0自动驾驶硬件的潜在价值。</p>
  <p>接受采访时，英伟达CEO黄仁勋对外表示，“特斯拉在自动驾驶方面遥遥领先。特斯拉第12版全自动驾驶汽车真正具有革命性的一点是，它是一个端到端的生成模型。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_ebc90c0c85684bc3853672eb6675dd4b@000000_oswg236238oswg1080oswg365_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：信达证券</p>
  <p>据了解，早在2022年末，特斯拉就开始布局端到端自动驾驶技术。马斯克曾表示，“FSD V12端到端模型迭代主要受到云端算力资源掣肘。”目前，特斯拉正重金堆算力，计划于2024年底前，对DOJO超算中心投资超10亿美元，将算力提升至10万PFLOPS。对比而言，其他车企算力中心的算力仅为1000 PFLOPS左右。</p>
  <p>当然了，Cybercab之所以可以落地，不止受自动驾驶技术成熟与否影响，也与成本高低息息相关。即便现阶段有了革命性的自动驾驶成本，但整车成本居高不下，Robotaxi也难以大规模推广。</p>
  <p>马斯克曾宣称，“与其他汽车公司相比，特斯拉的特点就是实现了‘不可思议’的垂直整合”。过去几年，特斯拉将触手伸向上游产业链，布局自研芯片、电池、电机等核心零部件，再叠加数以百万出货量带来的规模效应，特斯拉汽车拥有极强的成本优势。此外，特斯拉汽车采用纯视觉方案，不搭载成本高昂的激光雷达，成本还可以进一步下探。</p>
  <p>马斯克宣称，CyberCab的成本将低于3万美元，约为人民币21万元。而沙利文披露的《2024年中国Robotaxi行业深度研究报告》显示，目前中国Robotaxi的单车产品投入约为30万元左右，显著高于特斯拉的CyberCab。</p>
  <h2><strong>2 Robotaxi混战多年，“三强多弱”格局初显</strong></h2>
  <p>尽管特斯拉带火了Robotaxi概念，但事实上，过去几年，Robotaxi产业一直在蓬勃发展，目前行业已经涌现诸多玩家，并且已有成熟的产品上路。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_4d831af25f1845c3ba0fddf1459a2251@000000_oswg364641oswg1080oswg521_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：中金点睛</p>
  <p>中金点睛研报显示，“目前中美两国在Robotaxi商业化探索方面处于全球领先地位”。其中美国明星Robotaxi企业包括特斯拉、谷歌、Cruise等，中国知名企业则包括百度、小马智行、文远知行、如祺出行等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_a893af63c1a7480b9145d679c35016f4@000000_oswg376905oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：谷歌</p>
  <p>在美国市场，2024年以来，谷歌Waymo的Robotaxi不断扩大服务区域，6月在旧金山面向全域用户开放无人驾驶出行服务。2024年8月20日，Waymo宣布，在美国每周无人车付费出行次数突破10万次，相较5月份的5万次翻倍。</p>
  <p>无独有偶，2024年5月，Cruise也宣布重启Robotaxi业务运营，在亚利桑那州测试有安全员的Robotaxi。</p>
  <p>在中国市场，2023年以来，百度的萝卜快跑也开始加速落地，目前已于全国11个城市开放载人测试运营服务，实现超一线城市全覆盖。财报显示，截至2024年7月28日，萝卜快跑在全国累计提供超700万次的乘车服务；2024年Q2，萝卜快跑提供约89.9万次乘车服务，同比增长26%。</p>
  <p>尽管目前Cruise、小马智行、文远知行、如祺出行等企业也在积极布局Robotaxi，但这些企业的Robotaxi车队还不成气候，均处于追赶梯队。</p>
  <p>简言之，目前全球Robotaxi行业呈现“三强多弱”的局面，其中特斯拉的Robotaxi产品虽然尚未上线，但由于具备出众的自动驾驶技术以及成本控制能力，想象力非凡，而谷歌和百度也依托海量的订单，跻身Robotaxi强队。</p>
  <p>虽然目前全球Robotaxi行业竞争格局已逐渐清晰，但由于自动驾驶技术尚处发展起步期，各个企业Robotaxi产品的技术路径并不一致。</p>
  <p>整体而言，由于缺少海量量产汽车提供数据助力技术迭代，Waymo、百度等科技公司走“跨越式”路线，试图一步到位，实现L4级+自动驾驶；而以特斯拉为主的车企，由于拥有海量的数据，可以不断结合数据迭代，因而走“渐进式”路线，先从L2/L3级辅助驾驶起步，一步步实现L4/L5级自动驾驶。</p>
  <p>事实上，不同的技术方案，也决定了不同科技公司自动驾驶技术有不同的可靠性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_061fd6ccc93548659fba3851f7a19fbd@000000_oswg193152oswg879oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：Guidehouse Insights</p>
  <p>2023年初，Guidehouse Insights披露的全球自动驾驶技术公司分析报告显示，Waymo、百度、Cruise等走“跨越式”路线的公司自动驾驶技术得分均超80，排名靠前，位列“领导者”梯队。反观特斯拉自动驾驶技术仅有28分，位列“跟随者”梯队。</p>
  <p>将上述分析报告和目前已经推出Robotaxi服务的企业交叉对比可以发现，目前已经推出Robotaxi服务的企业，大部分为位列“领导者”梯队的科技公司。即便特斯拉的FSD V12已实现跨越式进步，其Robotaxi服务依然需要等到2026年才会正式上线。</p>
  <p>凡此种种，从侧面说明，现阶段“跨越式”路线更适合Robotaxi，而“渐进式”路线需要进一步提升安全性以及可靠性，才能支撑起Robotaxi业务。</p>
  <h2><strong>3 商业化拐点临近，萝卜快跑们还需加速</strong></h2>
  <p>其实从Robotaxi运营的角度出发，“跨越式”路线和“渐进式”路线的目标高度趋同，都致力于给消费者提供完全自动驾驶、高安全性等体验。</p>
  <p>之所以目前“跨越式”路线走得更远，主要是因为其依赖高精度地图，并且可在单一场景实现车路协同，显著提升了无人车在复杂路况下的应对能力。这也解释了，为什么目前大部分走“跨越式”路线的Robotaxi都仅在少数城市上线，并未全面铺开。</p>
  <p>不过，随着有关部门逐渐意识到Robotaxi的商业价值，诸多地方政府均开始出台自动驾驶试点示范政策。据不完全统计，目前中国北京、上海、广州、深圳等51个城市已开展无驾驶人车辆公开道路试点示范。这预示着，基于“跨越式”路线的Robotaxi有大规模落地的可能。</p>
  <p>与此同时，随着端到端技术逐渐成熟，目前诸多走“渐进式”路线的造车新势力也迈入了高阶智驾时代，支持城市无图NOA。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_1a6b009975f5465196592d5983d28c22@000000_oswg1268175oswg1080oswg803_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：理想汽车</p>
  <p>比如，2024年7月15日，理想汽车正式全量推送无图NOA，不依赖高精地图等先验信息，即可在全国范围内可导航的城市道路使用智驾功能。对此，理想汽车产品部高级副总裁范皓宇表示，“新一代产品将进入有监督自动驾驶的新阶段。”</p>
  <p>可以说，目前无论是依托于“跨越式”路线还是“渐进式”路线的Robotaxi产品，都已经来到了大规模商业化的临界点。接下来，哪种技术路线能完美实现完全自动驾驶以及高安全性，并且同时可以压低无人车的制造成本，哪种Robotaxi产品就将席卷市场。</p>
  <p>由于已来到大规模商业化的临界点，目前中国Robotaxi市场已经异常喧嚣，百度、小马智行、文远知行、如祺出行等企业都正加紧布局相关业务。其中百度的萝卜快跑作为先行者，已经拥有一定的行业知名度，小马智行、文远知行、如祺出行等企业则刚刚起跑。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_717f25b54b384f6fad901e728bc230f1@000000_oswg802999oswg1080oswg682_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：百度</p>
  <p>过去几年，萝卜快跑除了不断精进自动驾驶技术，更重要的举措，就是致力于压低车辆的制造成本。禾赛科技透露，第六代百度Apollo无人车将于2024年投放，搭载第六代智能化系统解决方案，整车成本相较上代降低60%，售价为20.46万元，几乎和特斯拉的Cybercab一致。</p>
  <p>目前，萝卜快跑在全国共投放2000台左右Robotaxi，预计在2024-2026年，车队规模将提升至2万台左右，覆盖65座城市。萝卜快跑六代车队投运后，有望首次实现盈亏平衡，盈亏平衡点的收费标准大约为0.6元/km。</p>
  <p>与百度即将跑通Robotaxi的商业闭环不同，小马智行、文远知行、如祺出行等企业的Robotaxi业务还看不到盈利的希望。</p>
  <p>以如祺出行为例，其虽然被誉为“Robotaxi第一股”，但招股书显示，截至2023年底，其仅网联281辆Robotaxi车辆，Robotaxi服务仅累计运营2万小时，覆盖545个站点，完成超45万公里安全试运营里程。</p>
  <p>或许是因为Robotaxi业务进展缓慢，2024年上半年，如祺出行并未披露详细的Robotaxi运营数据，而是重点展示网约车相关业务的营收数据。这也从侧面说明，现阶段Robotaxi对于如祺出行来说，还是个遥不可及的“故事”。</p>
  <p>无独有偶，尽管宣称自己是全球领先的自动驾驶科技公司，但招股书显示，过去三年，文远知行仅售出19台自动驾驶出租车、147辆自动驾驶巴士，持续亏损。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_fdd18fe5abd14c1dbd82037c00e97a8a@000000_oswg171913oswg1048oswg211_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：文远知行招股书</p>
  <p>耐人寻味的是，因L4自动驾驶汽车产品价格异常昂贵，近年来，文远知行不再侧重发展产品业务，而是不断加码服务相关业务，为第三方车企提供智驾相关技术。2024年上半年，文远知行来自服务业务的营收为1.29亿元，营收占比高达86%。</p>
  <p>由此来看，目前文远知行正逐渐远离Robotaxi服务商的身份，接下来或许很难在Robotaxi领域和百度一较高下。</p>
  <p>总而言之，特斯拉选择在2024年10月这个时间节点推出Robotaxi，很大程度上昭示出，依托于端到端的自动驾驶技术极具想象力，即将实现高阶自动驾驶。</p>
  <p>与此同时，随着越来越多的地方政府出台自动驾驶试点示范政策，走“跨越式”路线的Robotaxi也有了大规模落地的可能。百度、谷歌的Robotaxi产品都已蓄势待发。</p>
  <p>当然，Robotaxi能否大规模落地，不光与自动驾驶技术成熟与否息息相关，也离不开整车成本下探。目前，以特斯拉为代表的车企可凭借垂直整合，压低整车制造成本，而与百度为代表的科技公司也通过不断迭代，尽可能压低车辆的成本。</p>
  <p>反观文远知行等创业公司由于缺乏必要的资金以及供应链资源，迟迟难以压低Robotaxi产品的成本，目前已明显落后一程。</p>
  <p>由此来看，接下来Robotaxi市场，将呈现寡头争斗的局面。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzAxMDE2NTgzMw==&amp;mid=2650431967&amp;idx=1&amp;sn=11df70df2e115a57544d120d918cd3c8&amp;chksm=82c68630efb899d8af370d82cef24c02b68be69fde6cd51140c72bc88f740537607b6c096d69&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“师天浩观察”（ID：shitianhao01）</a>，作者：麟山，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3001357661075590</id>
            <title>苹果一篇论文得罪大模型圈？Transformer不会推理，只是高级模式匹配器，所有LLM都判死刑</title>
            <link>https://www.36kr.com/p/3001357661075590</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3001357661075590</guid>
            <pubDate></pubDate>
            <updated>Mon, 21 Oct 2024 00:58:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: LLM, 推理能力, 模式匹配, 数学能力  
<br><br>  
总结: 最近的研究质疑大语言模型（LLM）是否具备真正的推理能力，认为其所谓的推理能力实际上只是复杂的模式匹配。苹果的研究者们开发了新的数据集，发现无论是开源还是闭源的模型，在面对经过修改的数学题时，准确率普遍下降，表明模型并未真正理解数学概念。即使在面对更复杂的问题时，模型的表现也显得不稳定，无法有效处理无关信息。最终，研究者得出结论，LLM更像是复杂的模式匹配器，而非具备逻辑推理能力的系统。 </div>
                        <hr>
                    
                    <p>LLM真的会推理吗？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_18d23ce6d1964d8e8c99875fba7cd936@5091053_oswg245502oswg942oswg932_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>最近，苹果研究员发文质疑道：LLM根本没有不会推理，所谓的推理能力只是复杂的模式匹配罢了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_f919acf4916d4e21be7641ce30a21cdb@5091053_oswg113587oswg1080oswg389_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文地址：https://arxiv.org/abs/2410.05229</p>
  <p>这项研究也在AI社区引起了广泛讨论。</p>
  <p>谷歌DeepMind科学家Denny Zhou表示，自己ICML 2023的一片论文中，也发现了类似现象。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_46aeaf315341476880ccef55678eea9a@5091053_oswg169340oswg961oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>Meta AI研究者田渊栋表示，梯度下降可能无法学习到这样的权重。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_2bf77e6ec32146ce855a6705d89a261a@5091053_oswg219874oswg919oswg1010_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>巧的是，AI2等机构在23年的一篇研究也被翻出，证实模型根本没有学会数学推理，只是在「照背」答案而已。</p>
  <p>网友们搜罗了越来越多的学术证据，一致证明：LLM可能根本不会推理！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_e4d4f3058b2549c586717c6c2512c711@5091053_oswg380426oswg865oswg679_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>图灵三巨头之一的LeCun，也在最近的万字演讲表示，Meta现在已经完全放弃纯语言模型，因为仅靠文本训练，它永远不可能达到接近人类水平的智能！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_0a9d85558dee483ca130503ca712e915@5091053_oswg438706oswg1080oswg563_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>目前Transformer架构的大语言模型，难道真的是一条弯路？</p>
  <h2><strong>换个马甲，大模型的数学能力就滑坡了！</strong></h2>
  <p>这次，苹果的研究者们仔细研究了GPT-4o和o1系列闭源模型，以及Llama、Phi、Gemma、Mistral等开源模型的数学能力。</p>
  <p>此前，业界用来评价大模型数学能力的数据集是2021年发布的GSM8K，该数据集包含8000可小学水平的数学应用题，例如下面的例子：</p>
  <blockquote>
   <p>当索菲照顾她侄子时，她会为他拿出各种各样的玩具。积木袋里有31块积木。毛绒动物桶里有8个毛绒动物。堆叠环塔上有9个五彩缤纷的环。索菲最近买了一管弹性球，这使她为侄子准备的玩具总数达到了62个。管子里有多少个弹性球？</p>
  </blockquote>
  <p>此时距OpenAI发布GSM8K已经三年了，模型性能也从GPT-3的35%，提升到了30亿参数模型的85%以上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_2a2fc6bc3efd4d6d816cf4b74d0da503@5091053_oswg261807oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>不过，这真的能证明LLM的推理能力确实提高了吗？</p>
  <p>要知道，由于是21年发布的数据集，如今的主流大模型可能抓取的训练数据无意间涵盖了GSM8K的题目。</p>
  <p>虽然大部分模型没有公开训练数据的信息，但存在数据污染的可能，这就会导致大模型能够靠背题答对GSM8K中题目。</p>
  <p>因此，用这个数据集去评判LLM的数学能力，并不准确。</p>
  <p>于是，为了客观评价LLM的数学能力极限，苹果的研究者们开发了一个名为GSM-Symbolic的数据集。</p>
  <p>GSM-Symbolic将GSM8K的题目进行了修改，例如改变了索菲这个名字，侄子这个家人的称谓，以及各种玩具的多少（数字）。</p>
  <p>这样一来，就可以产生出很多个看起来全新，但实际上却是具有相同内核的题目。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_243437d5ef1145058a5dcc5526e348de@5091053_oswg451764oswg1080oswg890_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>另外，除了GSM-Symbolic，这项研究还提出了GSM-NoOp数据集，GSM-NoOp 向题目中添加看似相关但实际上无关的数据，来判断大模型在执行逻辑推理任务时是否会受到无关数据的影响。</p>
  <h3><strong>不管开源闭源，都会因题目换皮表现更差</strong></h3>
  <p>实验结果很有趣：就跟人类一样，数学题干一换，很多LLM就不会了！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_ce7a6a5a5428447c911ad6aa652a0836@5091053_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>苹果的研究者们对比了GSM8k和GSM-Symbolic在多种模型上的性能差异，结果发现——</p>
  <p>无论是主流的开源模型还是闭源的GPT系列模型，甚至专门为数理推断专门优化的o1模型，当面对GSM-Symbolic的换皮题目时，准确率都会下降。</p>
  <p>大多数模型在GSM-Symbolic上的平均性能，都低于在GSM8K上的平均性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_19508f1ac3cc4835b0cabe61b0eb8335@5091053_oswg365726oswg1080oswg734_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_ef90aaf390da4babbdc112e4c51cb881@5091053_oswg165930oswg1080oswg570_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">GSM8k和GSM-Symbolic和模型性能对比</p>
  <p><strong>即使只更改了题目中的名称，大模型的表现也会有存在差异，当只改变了题目中的专有名词时，性能下降在1%-2%之间，当实验者更改数字或结合两类更改时，差异则更为显著。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_6642f6f58cca4d94ab1100c9951e7878@5091053_oswg327322oswg1080oswg670_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">对比只修改题目中的专有名词，题目中数字和都修改时的准确度</p>
  <p>从图2中可看出，几乎所有模型都明显出现了分布均值从右向左的逐渐移动（准确度变低），以及方差增加。</p>
  <p>仅仅是更改一下专有名词，就会存在如此大的差异，这种现象实在是令人担忧：看来，LLM的确没有真正理解数学概念。</p>
  <p>即使理解了数学题目的小学生，都不会因为题目换汤不换药，就不会做了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_9181f9f03a114ebdb3c1334361f15e27@5091053_oswg71428oswg241oswg209_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>随后，苹果的研究者继续给这些LLM上难度。</p>
  <p>他们引入了GSM-Symbolic的三个新变体：删除一个分句（GSM-M1），增加一个分句（GSM-P1）或增加两个分句（GSM-P2）。</p>
  <p>果然，当模型面对的题目变难时，例如题目从「打电话每分钟10分钱，打60分钟多少钱？」变为「打电话前10分钟每分钟10分钱，之后每分钟8分钱，如此打60分钟电话费多钱？」，大模型回答的准确性降低，方差变大，这就意味着，LLM的性能极不稳定，可靠性越来越差。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_44f6e7ff80f946ed8aa92d0285be2850@5091053_oswg582517oswg1080oswg1071_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>最后，当模型面对增加了和题目无关的论述的题目（GSM-NoOP），性能的下降更是惨不忍睹。</p>
  <p>所有模型的性能下降都更加明显，其中Phi-3-mini 模型下降了超过 65%，甚至像o1-preview这样的预期表现更好的模型也显示出显著的下降（17.5%）。</p>
  <p><strong>这是由于模型会将无关的论述当成需要操作的步骤，从而画蛇添足地回答错误。</strong></p>
  <p>也就是说，当今性能最强大的模型，也依然无法真正理解数学问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_509433a6f97344bd8575484a76bd452d@5091053_oswg378976oswg1080oswg825_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">GSM-NoOP数据集相比GSM8k数据集的性能下降</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_73aa469f6ea140f78de407cfdb902ed8@5091053_oswg293821oswg1080oswg733_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">o1系列模型，依然无法避免这些问题</p>
  <p>从这项研究的结果来看，<strong>大模型在执行真正的数学推理方面的重大局限性。</strong></p>
  <p>大模型在不同版本的同一问题上的表现高度差异，随着难度轻微增加而表现大幅下降，以及对无关信息的敏感度表明，<strong>大模型进行的推理及运算是脆弱的。</strong></p>
  <p>最终，苹果研究者给出这样的结论——<strong>它们可能更像是复杂的模式匹配，而不是真正的逻辑推理。</strong></p>
  <p>也就是说，即使我们继续堆数据、参数和计算量，或者用更好的训练数据，也只能得到「更好的模式匹配器」，而非「更好的推理器」。</p>
  <h2><strong>大模型实际不是解数学题，还是在进行模式匹配</strong></h2>
  <p>无独有偶，23年的一项研究《信仰与命运：Transformer作为模糊模式匹配器》也证实——</p>
  <p>大模型并没有真正的理解数学概念，而只是根据模糊模式匹配来从训练数据的题库中寻找答案。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_c709808499a44019a052a43182c7f41f@5091053_oswg118005oswg1054oswg470_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文地址：https://arxiv.org/abs/2305.18654</p>
  <p>研究者们很疑惑，为什么Claude或GPT-4这样的模型输出时，听起来非常像一个人在推理，而且问题也都是需要推理才能解决的。</p>
  <p>它们仿佛已经在超人类智能的边缘，但在处理一些简单的事情上却有很蠢。</p>
  <p>比如，人类在学习基本计算规则后，可以解决三位数乘三位数的乘法算术。但在23年底，ChatGPT-3.5和GPT-4在此任务上的准确率分别只有55%和59%。</p>
  <p>到底发生了什么？</p>
  <p>在《信仰与命运》这篇论文中，Allen AI、华盛顿大学等的学者对LLM的这种表现提出了一种解释——「线性化子图匹配」。</p>
  <h3><strong>线性子图匹配</strong></h3>
  <p>他们猜测，大模型解决问题的方式是这样的。</p>
  <blockquote>
   <p>1. 任何任务的解决问题都可以表示为一个有向图，该图将任务描述为一系列步骤，这些步骤会被分别解决，然后将结果组合在一起。</p>
   <p>2. 如果整个任务的解决方案过程可以用一个图来描述，那么其中的子任务就是该图中的子图。图的结构描述了哪些步骤依赖于其他步骤，而这种依赖顺序限制了子图如何被展平成线性序列。</p>
   <p>3. GPT类的模型，通常就是通过近似匹配来“解决”上述子图的。给定一个可以用子图描述的问题，大模型就会通过大致将其与训练数据中相似的子图相匹配，来进行预测。</p>
  </blockquote>
  <p>为了证明这项猜测，研究者测试了三个任务——</p>
  <p>乘法、爱因斯坦逻辑谜题和动态规划问题。</p>
  <p>拿乘法举例。</p>
  <p>如果LLM真的能通过足够的数据学会东西，或者能通过系统化的推理解决复杂的多步骤问题，那它应该能通过足够的例子或对算法的充分解释来学习乘法。</p>
  <p>而乘法问题可以被分解为更小的问题，因此模型应该能通过逐步推理来做出来。</p>
  <p>LLM可以完成吗？</p>
  <p>为了检验多位数乘法任务，研究者定义了一组大量的乘法问题。从计算两位数和两位数的乘积到五位数和五位数的乘积。</p>
  <p>首先，他们会要求模型解决如下问题：</p>
  <blockquote>
   <p>问题：35 乘以 90 等于多少？答案：3150。</p>
  </blockquote>
  <p>其次，他们向模型提供了思维链示例，将其分解为更小的任务，使用学校教授的标准乘法算法。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_eaf30cb60bb842ed88c1e7d0f55d1384@5091053_oswg566406oswg1080oswg862_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">提示模型执行任务的程序</p>
  <p>但如何衡量一项任务比另一项更难呢？如何追踪模型在哪些地方失败，如何失败？</p>
  <p>研究者将乘法算法描述为一个包含加法和乘法等基本操作的定向图。</p>
  <p>比如下面是7乘以49所涉及的运算的图表示：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_25a96995326b4f06a8d604fc7f23a448@5091053_oswg236132oswg1080oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其中包含7乘以4的子任务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_dd1bbc5422ce48478d0f1278f57bd86e@5091053_oswg243572oswg1080oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">子程序是图中的子图</p>
  <p>研究者在评估中发现，即使经过微调，模型也无法从训练集中看到的小乘法问题，推广到更大的乘法问题。</p>
  <p>在左侧图中，蓝色的单元格表示模型是在这样的乘积上训练的，得分相当不错。</p>
  <p>原因在于，模型在预测与训练数据规模相同的问题时就表现良好。</p>
  <p>然而在橙色的单元格，如三位数与三位数或更高位数的乘积，得分就要差得多了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_825e2bcfb42d4225a3243e694c629032@5091053_oswg169764oswg1080oswg514_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">GPT-3准确率与规模对比</p>
  <p>在操作图中可以看出，当任务变得更加复杂时，准确度会急剧下降。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_cc98e74e27ba4cec88e397f32e354a8b@5091053_oswg271623oswg1080oswg391_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>宽度衡量需要同时维护多少个中间结果，而深度衡量需要组合多长的步骤序列才能达到结果</p>
  <p>由此，研究者总结出一些真正有趣的东西。</p>
  <h3><strong>错误告诉我们，LLM中真正发生的事</strong></h3>
  <p>首先，研究者观察到：<strong>LLM是否能成功解决问题，取决于模型之前是否见过相关的子问题。</strong></p>
  <p>换句话说——</p>
  <blockquote>
   <p>1. LLM无法解决大型问题，因为它们只能解决大型问题中的部分子问题。</p>
   <p>2. 如果它们在解决训练数据中频率更高或更精确的子问题上成功了，这表明它们只是记住了答案，通过回忆解决。</p>
  </blockquote>
  <p>这就是为什么7乘以49会失败，但7乘以4却取得一些进展，因为LL没记住了「7乘以4的呢关于28」这个子问题。</p>
  <p>更大的意义在于：与其将模型视为以一般和系统的方式处理问题的各个部分，不如将其视为搜索引擎，它会先召回与特定问题部分大致匹配的例子，然后将这些近似回忆拼接起来。</p>
  <p>也就是说LLM通过仅完成整体问题的一部分而取得部分成功。</p>
  <p>它是以自己反直觉、更肤浅、更实际的方式分解问题，更关注文本的「表面」，而非系统地思考给定的乘法算法。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_dd8640b715fc46118ff458154f244e84@5091053_oswg363552oswg1080oswg610_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">高信息增益，甚至能预测意外的部分解决方案</p>
  <h3><strong>一些问题</strong></h3>
  <p>作者提出，子图匹配的想法，更多的是一个起点，而非对现状的精确完整描绘。</p>
  <p>后续的实证研究，又削弱了这一解释的普遍性。</p>
  <p>比如McLeish 等人（2024 年）表明，通过「算盘嵌入」的架构修改，可以显著提高Transformer在算术上的性能。</p>
  <p>LLM能够解决比训练数据中更大的多位数加法问题，但未体现乘法性能的同等提升。</p>
  <p>如果线性子图匹配是Transformer的一般性限制，那么加法为何会如此容易受到特定修复的影响，而非乘法呢？</p>
  <p>这又引出了新的问题：什么样的文本表示将使模型更容易处理多步问题——比如推理链问题？</p>
  <p>那些从外部看起来像是在推理的系统，即使我们知道其内部并未在逻辑蕴涵空间中执行搜索，它们的实际限制在哪里？</p>
  <p>这些都留待未来解决。</p>
  <h2><strong>马库斯：我早说过了</strong></h2>
  <p>对于苹果的研究，马库斯也专门写了一篇博客进行论述。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_50b430c1bb8945dda5e4e50d9173fe92@5091053_oswg59210oswg1080oswg242_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>他表示，LLM的这种「在受到干扰材料的影响下推理失败」的缺陷，并非新现象。</p>
  <p>在2017年，斯坦福大学的Robin Jia和Percy Liang就进行过类似研究，得出了相似的结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_67d644bcd0c340448be0669680805d7d@5091053_oswg103545oswg935oswg638_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在问答系统中，即使只是改变一两个无关紧要的词或添加一些无关信息，也可能得到完全不同的答案</p>
  <p>另一个体现LLMs缺乏足够抽象、形式化推理能力的证据是，当问题变得更大时，其性能往往会崩溃。</p>
  <p>这源于Subbarao Kambhapati团队近期对GPT o1的分析：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_5e880b412c5c4f9d8cbe5f54f4f826d4@5091053_oswg136539oswg888oswg532_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">性能在小问题上尚可，但很快就会下降</p>
  <p>&nbsp;</p>
  <p>在整数算术中，我们也可以看到相同现象。</p>
  <p>在越来越大的乘法问题中，这种下降趋势在旧模型和新模型中都被反复观察到。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_b23473c1c2fc498bad6569674fd2edc2@5091053_oswg48069oswg1080oswg356_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>即使 o1 也受到这个问题的影响：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_d16004a4d9274e3d8edf260cbe9c9b19@5091053_oswg188506oswg1080oswg895_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>LLM不遵守棋类规则，是其形式推理持续失败的另一个例子：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_9c0a7eaa33b74875b61260490e21e186@5091053_oswg133840oswg1080oswg1083_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>马斯克提出，甚至马斯克的Robotaxi也会受到类似困扰：它们可能在最常见的情况下安全运行，但在某些情况下可能难以足够抽象地推理。</p>
  <p>马库斯指出：LLM爱好者总是为它们的个别错误开脱，然而最近的苹果研究及其他相关研究和现象，都太过广泛和系统化，让我们无法视而不见了。</p>
  <p>他表示，自1998和2001年以来，标准神经网络架构无法可靠地外推和进行形式化推理，一直是自己工作的核心主题。</p>
  <p>最后，他再次引用了自己在2001年的《代数心智》一书中的观点——</p>
  <blockquote>
   <p>符号操作，即某些知识通过变量及其上的操作以真正抽象的方式表示，就像我们在代数和传统计算机编程中看到的一样，必须成为AI发展的组成部分。</p>
   <p>神经符号AI——将这种机制与神经网络结合起来——很可能是未来前进的必要条件。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_b94ed584bb1d454e9cd0ba79d862ac55@5091053_oswg97529oswg685oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>总的来看，无论是将乘法拆解为有向图，还是一旦面对应用题中称谓和数字变换就答错，这都反映了大模型在逻辑推理上的本质缺陷。</p>
  <p>总之，LLM在背题这件事，算是「人赃俱获」了。</p>
  <p>这两项研究也警示我们：正如Meta的AI科学家田渊栋所说，只要大模型还是依赖梯度下降，那么就不要期待它变得不那么愚蠢。</p>
  <p><strong>参考资料：</strong></p>
  <p>https://www.reddit.com/r/MachineLearning/comments/1g3cumr/d_will_scale_be_enough_to_get_llms_to_reason/</p>
  <p>https://garymarcus.substack.com/p/llms-dont-do-formal-reasoning-and?r=17uk7&amp;triedRedirect=true</p>
  <p>https://www.answer.ai/posts/2024-07-25-transformers-as-matchers.html</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ecv-c7rlVZGhcSW_MLf1sQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，编辑：peter东 Aeneas，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3001497474759045</id>
            <title>百度做AI，为何硬不起来？</title>
            <link>https://www.36kr.com/p/3001497474759045</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3001497474759045</guid>
            <pubDate></pubDate>
            <updated>Mon, 21 Oct 2024 00:46:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <智能硬件, 百度, AI技术, 市场竞争>
<br>
<br>
总结: 文章探讨了百度在AI硬件领域的布局与挑战。尽管百度早期进入该市场并推出多款智能硬件产品，但其在市场表现上仍显平平，缺乏引领性产品。百度的硬件战略多依赖于AI技术，而非将硬件视为核心业务，导致其产品在设计和用户体验上缺乏差异化。与其他竞争对手相比，百度的硬件生态系统不够完整，用户体验不一致，影响了市场吸引力。文章指出，百度需要在硬件设计创新、营销和生态系统建设上更加聚焦，以提升市场竞争力。 </div>
                        <hr>
                    
                    <p>智能硬件在2024年貌似又行了？</p>
  <p>忽略市场表现，从抢跑者动作看，确实是这样的。</p>
  <p>亿欧网统计，<strong>从2023年至今，在大约一年半时间里，至少有25位大厂高管已投身AI硬件赛道。从出身上看，多数来自于BAT、TMD等互联网大厂。</strong></p>
  <p>在大模型潮涌中，<strong>在AI加持下，AI手机、AI PC、AI眼镜、AI耳机、AI玩具好不热闹。</strong></p>
  <p>有意思的是，在众多互联网大厂中，百度的表现值得观察。</p>
  <p>百度作为第一批进军硬件的老牌互联网巨头，至今依然“还在牌桌上”。从时间跨度和百度布局硬件方向调整上，我们能窥探到整个智能硬件产业的变迁。</p>
  <p>目前，承担百度在AI硬件领域布局的主要业务线是小度科技，但在2020年前，小度科技在百度业务体系中地位并不明显。</p>
  <p>实际上，在过往十年时间里，百度的业务体系经历了数次调整，2013年前，百度主要分为销售体系、商业运营体系、用户产品与技术体系、商业产品与技术体系等四大业务线；2013年，则调整为了移动服务事业群组、新兴事业群组、搜索业务群组、金融服务事业群组等四大事业群。</p>
  <p>2020年是百度转型以来组织架构调整最大的一年，当年百度设立了内部事业群组、外部并购企业体系，以及内部孵化或通过投资获得控制权体系等三大业务体系，彼时，小度也被划进了后者业务体系中。</p>
  <p>百度此举意图明显，目的就是为了突出“人工智能”的战略地位。不过遗憾的是，哪怕自2020年起百度就已战略性All in人工智能，但现实是，当前，在众多热门AI硬件细分领域，百度的表现依然难言如意。</p>
  <p>不得不让人猜测，<strong>是否是硬件定位与战略重心的摇摆不定，才导致一直未出现“亮眼”产品</strong>。</p>
  <p>多年来，百度的核心战略一直聚焦在AI技术研发和软件服务上，而不是在硬件生产本身。<strong>百度往往将硬件产品视为AI技术的载体，而不是独立的商业化核心</strong>。相较于苹果、华为等将硬件视作业务核心的企业，<strong>百度在硬件产品上投入的资源和战略重视度可能相对不足</strong>。</p>
  <p><strong>从外部观察，百度更倾向通过其AI平台与第三方硬件厂商合作，而不是自己主导硬件研发和生产。</strong>尽管开放性包容度多受上下游好评，但也一定程度上导致<strong>百度的硬件产品更多是作为“配件”来展示其AI能力，而非直接通过硬件获取市场份额和用户黏性</strong>。</p>
  <p>其次，很明显与智能硬件巨头相比，尽管产品不少，但是缺乏完整的硬件生态。硬件领域竞争激烈，消费者往往选择那些具备生态粘性，日常常用性产品多的生态品牌，比如小米、苹果、华为等等。</p>
  <h2><strong>百度AI硬件产品，横跨数十个领域</strong></h2>
  <p>或许外界对百度的印象还停留在互联网大厂、做搜索的、卖广告的等刻板印象中，但实际上，一个让人惊讶的事实是，百度进军AI硬件市场非常早，经过近十年积累，目前已悄悄推出了一大批智能硬件。</p>
  <p>在百度业务体系中，承担AI硬件业务的部门主要是小度科技，专门研发AI硬件产品。此前不久，百度副总裁、小度CEO李莹曾介绍小度科技，称其战略定位就是“AI+硬件”。</p>
  <p>在AI硬件领域，小度已经探索了多年，早在2017年，就已推出了小度助手1.0版。根据最新披露，今年4月，小度刚发布了DuerOS X系统，小度称其成为全球首个AI原生操作系统。</p>
  <p>目前，在AI硬件方面，小度已推出十余个细分领域的智能硬件产品，覆盖智能家居、智慧教育、影视娱乐、智能机器人等多个方向。</p>
  <p>根据公开信息，亿欧网整理出了百度已推出的AI硬件产品（见下图），为便于观察，亿欧网将这些硬件产品，划分成了功能类、学习类、家居类三大类别。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_0128c84cf51f4a58b60301079bbe5f53@000000_oswg376161oswg1080oswg1022_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>从上图不难看出，百度在AI硬件领域的布局相当广泛，尤其是在智能家居领域，几乎覆盖了家居生活的各个方面，产品包括智能照明灯、智能插座、智能门锁、智能温湿度计、智能遥控器、智能电视等等。</p>
  <p>除家居类智能硬件以外，百度还先后推出了学习机、学习平板、词典笔等学习类智能硬件，以及智能耳机、智能音箱、智能健身镜等功能类硬件产品。</p>
  <p>但不得不提，面向C端的产品，除了性能，在创新设计上的突出也尤为重要。<strong>百度的硬件产品在设计和用户体验上缺乏明显的差异化</strong>。百度主要集中在将DuerOS等AI技术嵌入硬件，但<strong>在外观设计和创新体验上相对保守</strong>，没有为消费者带来明显的“惊喜”感。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241021/v2_7601a684c77e4177a64c968867fccdca@000000_oswg236877oswg567oswg334_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>像小度智能音箱这样的产品，虽然依靠百度的AI能力有一定竞争力，但在创新性上与市面上其他类似产品并没有本质差异，用户很容易选择性价比更高的小米等成熟产品。</p>
  <h2><strong>一直在跟随，从来没引领</strong></h2>
  <p>把时间线拉长来看，百度在AI硬件领域已经探索近十年，无论是自研产品，还是投资并购或者与外部合作，百度在AI硬件产品方面都投入消耗了大量人力、时间、资金，不可否认，的确有些产品获得了市场的认可，例如智能健身镜、智能学习机等产品具有一定的市场份额。</p>
  <p>尽管产品足够多，但在不同设备间往往缺乏一致的用户体验。由于其生态中的产品来源多样，部分来自自研，部分来自并购或合作，<strong>百度难以为用户提供一个完全统一、流畅的跨设备体验</strong>。</p>
  <p>这种体验上的不一致也让用户在切换设备时，难以保持一致性和连贯性，导致生态的吸引力减弱，市场声音也趋于微弱。</p>
  <p>其实从AI硬件产品布局来看，也难言如意，甚至可以说表现平平。一个不争的事实是，当前最受关注的AI眼镜、AI耳机、AI头显、AI可穿戴设备等产品，<strong>百度几乎都缺席了</strong>。</p>
  <p>此前，百度曾一度设立了新兴事业群组，但如今来看，截至目前，百度或许依然没有抓住新兴的AI硬件风口。甚至可以说，此前推出的硬件产品，有很多产品都是“一直在跟随，从来没引领”。</p>
  <p>整体来看，这些年百度推出了大量的AI硬件，覆盖领域的确很广。但实际上，在与对手比拼时，百度缺乏能“一剑封喉”的AI产品，没有真正能“打”的产品，恰恰因此，外界对百度的刻板印象依然是“百度在AI硬件赛道正在掉队”。</p>
  <p>其实，对于AI硬件企业来说，无论是大厂、还是小企业，在产品布局上，“多而全，不如少而精”。等到具备强大的竞争力，获得一定市场地位时，再布局其他领域也未尝不可。</p>
  <p>业界已有共识，今年是“AI硬件元年”，AI眼镜、AI耳机等产品如火如荼。前不久，扎克伯格刚发布了号称“地表最强的AI眼镜”，可以预见，未来一段时间，AI硬件将是大厂们追逐的重点领域，届时市场竞争也会更激烈。</p>
  <p>百度的核心竞争力在AI算法和平台，而硬件则是一个需要不同技术和资源的领域。要成功推出AI硬件产品，需要在硬件与软件之间找到合适的融合点，若百度希望在硬件领域取得显著突破，可能<strong>要更加聚焦于硬件设计创新、营销和生态系统建设，进一步提升其硬件产品在市场上的竞争力</strong>。</p>
  <p>留给百度的时间不多了。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA5NTI1MDEyNA==&amp;mid=2652717374&amp;idx=1&amp;sn=b63af9d4003c0b551c54f0b618774fc1&amp;chksm=8a4b1ac288e8871a01358dcf44972e6e2548f12feb7e1bc385acf565043266ceac956ddd86a5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“亿欧网”（ID：i-yiou）</a>，作者：王圆磊，编辑：刘欢，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3000677266766213</id>
            <title>当绊脚石被搬开后，微软要再次发力云游戏了</title>
            <link>https://www.36kr.com/p/3000677266766213</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3000677266766213</guid>
            <pubDate></pubDate>
            <updated>Mon, 21 Oct 2024 00:08:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Google Play, 云游戏, 微软, 垄断  
<br><br>  
总结: 美国法院裁定Google Play存在“非法垄断”行为，要求谷歌在未来三年内向竞争对手开放应用商店。微软宣布将允许用户在安卓端Xbox App购买游戏时不再通过Google Play支付，从而避免抽成。云游戏自2009年诞生以来，虽然经历了波折，但随着网络基础设施的改善和算力投资的增加，微软重新恢复了对云游戏的信心。云游戏的优势在于降低玩家的硬件门槛，但内容的独占性仍是关键。微软的Xbox Cloud Gaming将不再仅限于XGP内容库，满足玩家对云游戏的需求。 </div>
                        <hr>
                    
                    <p>随着美国法院日前裁定Google Play存在“非法垄断” 行为，要求谷歌在未来三年内向竞争对手开放这一应用商店之后。不仅是Epic Games旋即就表示要做安卓应用商店，微软也顺势宣布拟于11月开始允许用户在安卓端Xbox App购买游戏时、不再需要通过Google Play进行支付，从而避免开发者向谷歌支付抽成。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_be6b29a94245492b9cb1edf79879e612@000000_oswg35318oswg600oswg358_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>紧接着微软Xbox部门总裁Sarah Bond趁热打铁，宣布自11月开始将扩大云游戏库，未来玩家可以在云端体验Xbox Game Pass内容库以外的游戏。如此看来，在此前经历了2022年云游戏行业的低潮期后，微软方面在两年后的今天重新恢复了对云游戏的信心。</p>
  <p>事实上，云游戏这个概念早在2009年就已经诞生，但真正的“云游戏元年”应该是2019年，在这一年的游戏开发者大会上，作为圈外人的谷歌推出了自家的云游戏服务Stadia。自谷歌振臂一呼之后，一众厂商云集景从，诸如亚马逊Luna、微软Xbox Cloud Gaming、英伟达GeForce Now、腾讯START如同雨后春笋般冒了出来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_9711d52d4911426183cf117d9315f3bc@000000_oswg37641oswg600oswg336_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>相比于传统的游戏形式，云游戏的优势非常显著，这也是其能够得到游戏厂商、乃至互联网巨头青睐的关键。云游戏技术是通过将本地存储和计算迁移到数据中心，在将桌面虚拟化后，以云计算和串流的方式通过网络传输到用户的终端上，让消费者无需购买独立显卡、高性能CPU和大容量硬盘，设备只需支持视频的解码解压即可。</p>
  <p>在2019年的那一轮云游戏浪潮中，游戏厂商和互联网公司的策略其实是有明显差异的，因此也导致了在云游戏的落地遭遇挫折时，互联网公司往往干净利落地壮士断腕，而游戏厂商则是默默坚持。在以谷歌、Meta为代表的互联网厂商看来，云游戏和YouTube、Spotify没什么区别，都是流媒体技术在不同领域的应用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_8f7f895dd44b41038d53b5d1bbdc7d50@000000_oswg28113oswg600oswg351_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>故而谷歌、Meta都是以技术驱动自家的云游戏业务，来提供云游戏算力和服务解决方案。但遗憾的是，游戏作为一个在互联网诞生之前就存在的行业，它的内容属性极为突出。纵观整个游戏行业的发展史，其实从来就没有哪一个平台能够在缺乏独占内容的情况下站稳脚跟，云游戏自然也一样。</p>
  <p>当时，谷歌选择了与EA、育碧、R星、CDPR等知名游戏厂商合作，在Stadia发售之初为其带来了一套拥有《刺客信条：奥德赛》、《幽灵行动：断点》的豪华游戏阵容。可谷歌当时只是提供了一个空壳子，玩家想要在Stadia上体验云游戏，除了需要为Stadia本身的云游戏服务付费之外，还要再额外购买相关游戏的Stadia版本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_0562bddf457548bc8edc94b0a18061bf@000000_oswg24214oswg594oswg362_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>云游戏本身是为了降低玩家体验游戏的门槛，可在谷歌的这番操作下，Stadia反而变得却更贵了。其实不仅是谷歌，Meta和亚马逊也都是一个样。可反观微软，Xbox平台的游戏内容之丰富显然无需多言，但由于众所周知的原因，游戏大厂通常对于XGP不太感兴趣，诸多非微软第一方的大作也并未出现在XGP内容库里。</p>
  <p>现在微软承诺Xbox Cloud Gaming不再仅限于云端游玩XGP内容库，无疑就给了许多玩家体验云游戏的动力。那么问题就来了，微软为什么要等到现在才再次发力云游戏？事实上，除了苹果和谷歌如今都允许Xbox App登陆自家应用商店之外，云游戏固有的两大顽疾在过去两年间，也得到了一定程度的缓解。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_adb7111f338d48959fe14776788f3f3c@000000_oswg23282oswg600oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>云游戏对网络带宽要求高，并且本身的成本不菲，这已经是业界公认的事实。体验过云游戏的玩家都知道，网速越快、波动越小，云游戏的体验才会越接近传统的本地游戏体验，反之如果带宽不足，那么云游戏就完全是空中楼阁。</p>
  <p>除此之外，云游戏还是集中式计算的典型，所有的计算、渲染都是由服务器来完成。更何况不同于内容源统一的视频/音频流媒体，只需要一定数量的CDN就可以实现全球分发，云游戏本质上则相当于是每位用户都在看独一无二的实时直播画面，这就使得其成本可以说是相当之高。</p>
  <p>但在过去两年的时间里，云游戏的这两大缺陷得到了弥补。此前在2023年，美国通过了一项名为“BEAD”的计划，这项投资超过420亿美元的基础设施投资计划旨在让每个美国家庭都能实现高速上网，也就意味着美国距离“村村网通”只有一步之遥了。同时美国无线通信和互联网协会透露，到2023年年底，全美40%的无线连接为5G。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241020/v2_be4c0c4d0a1e44c9a8d07d01211c67c6@000000_oswg16926oswg600oswg327_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>中美、欧洲、日韩等主流市场的宽带和移动网络建设，显然与2019年已经有了天壤之别，这或许就给了微软一些信心。至于说云游戏所需要的庞大算力，其实也在过去两年AI大模型带动的算力投资中得到了解决。随着全球科技巨头几乎都将AI视作未来，一场有关算力的军备竞赛早已跑步进入了白热化的状态，仅仅微软一家就预计将把上千亿美元的预算分配给了算力。</p>
  <p>如此庞大的算力投资，Xbox云游戏自然也能分到一杯羹。如此一来，无论从任何角度来看，微软现在发力云游戏的障碍都已经消失，所以他们不做云游戏反而会有些奇怪。更为重要的是，大量玩家对于摆脱硬件的束缚、随时随地玩游戏的需求，早已是客观存在的事实。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649873178&amp;idx=2&amp;sn=44bdadd90a3e7c5f4a6b13dfc5f8db1e&amp;chksm=86fa7ac4ca1cb5aee2a268d72d8c9b2fb0107bf2ff0f664db2f46b490e8ba8129dcfa6438402&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>