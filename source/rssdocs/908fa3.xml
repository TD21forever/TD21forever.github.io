<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/2690772037283457</id>
            <title>苹果首次披露多模态大模型，AI 大招什么时候上 iPhone</title>
            <link>https://www.36kr.com/p/2690772037283457</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690772037283457</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 12:05:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 生成式 AI, 多模态 LLM, MM1-30B-Chat
<br>
<br>
总结: 苹果在生成式 AI 领域取得突破，发布了多模态 LLM 系列，其中包括了具有高达30B参数规模的MM1-30B-Chat。这一模型不仅能准确识别图片内容，还具有出色的推理和信息提取能力。通过研究论文，苹果详细披露了多模态大模型的研发过程，探讨了模型架构和预训练数据选择的重要性。 </div>
                        <hr>
                    
                    <p>一直在大模型浪潮有点克制的苹果，终于不再低调了。 在今年的 苹果股东大会上，库克罕见地谈及了生成式 AI。&nbsp;</p><p><strong>苹果 2024 年将在生成式 AI 领域「开辟新天地」。&nbsp;</strong></p><p>今天，苹果首次揭晓了在多模态大型语言模型（LLM）研究领域的最新突破。&nbsp;</p><p>这是一篇题为《MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training》的学术论文，里面详细介绍了具有高达 30B 参数规模的系列多模态 LLM。&nbsp;</p><h2>不只是数苹果！超大杯自带火眼金睛&nbsp;</h2><p>直入主题，先来看看「超大杯」 MM1-30B-Chat 的能力。&nbsp;</p><p>MM1-30B-Chat 不仅准确无误地数出图片中苹果、橙子的数量，而且面对一连串数字的识别，也能轻松应对。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b320bbca6b2444c5bd149494c7b2652b@46958_oswg61850oswg1080oswg378_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>难度也进一步升级，研究人员设置了个陷阱问题，询问 MM1-30B-Chat 能看到图片中的红球吗？&nbsp;</p><p>并未中招的它能够明确地回应道：「图片中并无红球，我所见到的是一只猫正坐在沙发的枕头上，除此之外，别无他物。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_33f4dee95aa14f9597e56c7da09dacd1@46958_oswg21034oswg534oswg294_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>我们时常在朋友圈上看到飞机上随手一拍的风景图，那 MM1-30B-Chat 会怎么解读这些风景图呢？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d59bb762239a4520a26f0a7383cf8186@46958_oswg43290oswg599oswg332_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>目睹这幅图像，人们会体验到敬畏、好奇和宁静等多种情感。飞机窗户外展现的景色令人叹为观止：飞机的机翼下，是一片广阔而雪白的山脉，给人一种宁静和自然之美的深刻感受。&nbsp;山脉宏伟、层次分明的排列，以及其雪峰与明亮的蓝天形成的对比，让人不禁对自然世界充满惊奇和赞赏。&nbsp;这种视角还提供了一个日常生活中难以体验的独特世界，激发出人们的好奇心和兴奋感。此外，图中未被触及、原始的风景，还能带来平静与安宁之感。&nbsp;</strong></p><p>它提取信息的能力也是一流，光靠一张图，就能滔滔不绝地给你讲清楚地解释清楚蒸发和蒸散发的区别。&nbsp;</p><p>推理能力是大模型的必备的核心竞争力之一，这种能力使得模型能够从有限的信息中提炼出深层次的见解和关联。MM1-30B-Chat 仅凭照片，就能推理出下面这些信息：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_448128497f904d7c9a62860510cd60c4@46958_oswg36663oswg581oswg282_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>海滩上的伞图片显示温度在 25-30 摄氏度。伞已撑开，人们在海滩上，看来是个温暖而阳光灿烂的日子。&nbsp;</p><p>飞机飞越雪地的图片显示温度在 -20 至 -30 摄氏度。飞机正飞越一片雪地，地面上有车辆，显然是一个寒冷的冬日。&nbsp;</p><p>动物在田野上吃草的图片显示温度在 15-20 摄氏度。动物正在吃草，这通常发生在温和的天气中。草地的绿色进一步显示出温和的气候特征。&nbsp;</p><h2>MM1 是怎么做到的？&nbsp;</h2><p>苹果发布的论文里详细披露了背后的研究过程。&nbsp;</p><p>得益于大规模图像-文本数据的丰富性和大规模计算能力的普及，多模态大模型已经成为众多顶尖模型的标配。&nbsp;</p><p>现有的多语言大型语言模型（MLLMs）主要分为封闭和开放两类。封闭模型的信息有限，而开放模型提供详细的参数、数据和训练配置，便于进一步研究。不过，大多数研究缺乏关于算法设计选择的透明度，特别是在多模态预训练方面。&nbsp;</p><p>因此，苹果撰写的这篇论文详细记录了多语言大型语言模型（MLLM）的开发过程，并尝试归纳出宝贵的设计经验。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b115ec6fb5874fc0b8966bf66223435a@46958_oswg53218oswg644oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，研究团队在模型架构决策和预训练数据选择进行了小规模的消融实验，探讨了模型架构决策和预训练数据选择，并观察到了几个有趣的趋势：&nbsp;</p><p>在模型设计方面，研究人员发现图像分辨率、视觉编码器的损失和容量、以及视觉编码器的预训练数据是至关重要的考量点。但出乎意料的是，几乎没有发现有力证据支持视觉数据输入到大型语言模型（LLM）的架构设计对性能有显著影响。&nbsp;</p><p>此外，研究人员探索了三种不同的预训练数据类型：图像字幕、交错的图像文本数据以及纯文本数据。&nbsp;</p><p>他们发现，对于少样本学习和纯文本任务的性能来说，交错的图像-文本数据和纯文本数据极为关键，而对于零样本学习的性能而言，图像-标题对数据最为重要。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a9631089f6bc4dad8ab83ffc100536ec@46958_oswg57986oswg651oswg307_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>经过监督微调（SFT）阶段后，研究人员证实了这些趋势的持续性，无论是在预训练阶段的评估中，还是在后续的基准测试中。这一发现表明，模型在预训练阶段所展现的能力以及所做出的建模决策，在经过微调之后依然保持其有效性。&nbsp;</p><p>在研究的最终阶段，研究团队通过扩展至更大规模的大型语言模型（LLMs），包括3B、7B 至 30B 参数级别的模型，以及探索混合专家（MoE）模型的不同配置——从拥有 64 个专家的 3B MoE 到拥有 32 个专家的 7B MoE——来进一步增强模型的性能。&nbsp;</p><p>预训练模型 MM1 在少样本学习设置中，无论是在小型还是大型规模上，都在标题生成和视觉问答（VQA）任务上超越了 Emu2、Flamingo 和 IDEFICS 等众多先进模型。经过监督微调（SFT）后的最终模型，在 12 个公认的多模态基准测试中展现了竞争力十足的性能。&nbsp;</p><p>得益于广泛的大规模多模态预训练，MM1 展现出了一系列引人注目的能力，包括上下文预测、多图像处理和连贯性推理等。&nbsp;</p><p>此外，经过指令调优的 MM1 还表现出了卓越的少样本学习能力。这些显著的成果证明了研究团队提出的构建多语言大型语言模型（MLLM）的方法能够有效地将设计原则转化为实际中具有竞争力的规模化模型。&nbsp;</p><p><strong>构建 MM1 的秘诀&nbsp;</strong></p><p>构建高性能多模态大型语言模型（MLLMs）是一项极其依赖经验的工作。虽然高层次的架构设计和训练流程是明确的，但实际形式和执行方式却不明确。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_15022905f4474c62bd67943d1d0d9605@46958_oswg34679oswg697oswg246_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>研究人员详细记录了为了构建高性能模型所进行的一系列消融实验。主要是三个设计决策维度：&nbsp;</p><p>架构：研究人员研究了不同的预训练图像编码器，并探索了将这些编码器与大型语言模型（LLMs）如何连接。&nbsp;</p><p>数据：研究人员考虑了不同类型的数据及其混合比例。&nbsp;</p><p>训练流程：研究人员探索了如何训练多模态大型语言模型，包括超参数以及在不同阶段训练模型的哪些部分。&nbsp;</p><p>鉴于训练大型多模态语言模型（MLLMs）可能涉及庞大的资源消耗，研究人员采取了一种精简的实验设置来进行消融实验。&nbsp;</p><p><strong>模型架构消融</strong></p><p>实验过程中，研究者分析了使大型语言模型（LLM）有效处理视觉数据的关键组件。他们专注于两个主要问题：最佳预训练视觉编码器的方法，以及如何将视觉特征与 LLM 内部空间有效结合。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_de371745deba43b5b8fcd67e37aaf59f@46958_oswg44096oswg640oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>图像编码器的预训练：多数多模态大型语言模型（MLLMs）使用 CLIP 预训练的图像编码器，也有研究探索使用 DINOv2 等仅视觉的自监督模型。研究显示，预训练图像编码器的选择对下游任务性能有显著影响，重点关注图像分辨率和预训练目标的重要性。在此过程中，研究人员使用了 2.9B 的 LLM 以充分挖掘大型图像编码器的潜力。&nbsp;</p><p>对比损失与重建损失：大规模图像-文本数据集训练的模型展现出强大的语义理解能力，这得益于数据的丰富性和视觉编码器的语义知识。然而，CLIP 风格的模型在密集预测任务上表现不佳，因此研究者考虑使用重建损失来提升图像理解的详细程度。&nbsp;</p><p>编码器课程的影响：研究发现，图像分辨率的提升对性能影响最大，其次是模型大小和训练数据组成。提高图像分辨率、增加模型参数和引入合成字幕数据集均能带来性能的小幅提升。&nbsp;</p><p>模型类型的选择：对比方法通常优于重建方法，特别是 ViT-L 编码器在性能上小幅超越同等尺寸的 AIM。&nbsp;</p><p><strong>预训练数据消融</strong></p><p>在追求高性能模型的训练过程中，获取大量且与任务相关的数据是至关重要的。通常，模型的训练被分为两个关键阶段：预训练和指令调优。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_22963645b8ef48abbe4f785ab1b0e018@46958_oswg28814oswg667oswg160_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>预训练阶段涉及使用广泛的网络数据，旨在为模型提供一个全面的学习基础。随后的指令调优阶段则利用针对特定任务精心挑选和策划的数据，以进一步提升模型在该任务上的表现。&nbsp;</p><p>而研究人员则集中讨论预训练阶段，并详细阐释他们在数据选择上的策略和考量。&nbsp;</p><p><strong>最终模型与训练方法</strong></p><p>研究人员选用了 378x378 像素分辨率的 ViT-H 模型，并在 DFN-5B 数据集上以 CLIP 目标进行预训练。&nbsp;</p><p>研究显示视觉标记的数量至关重要，因此他们采用了包含 144 个标记的连接器，选择了 C-Abstractor 作为连接器架构。&nbsp;</p><p>为了保持模型在零样本和少样本场景下的性能，研究人员使用了 45% 交错图像-文本、45% 图像-文本对和 10% 纯文本的数据组合。&nbsp;</p><p>他们也将大型语言模型（LLM）的参数规模扩展至 3B、7B 和 30B，并在相同文本数据集上进行训练。利用预训练的LLM和视觉编码器初始化 MM1，并在混合数据上进行了 200 万步的多模态预训练。&nbsp;</p><p>所有模型都在 AXLearn 框架下，以不冻结状态、4096 的序列长度、每序列最多 16张图像、378×378 分辨率和 512 序列的批次大小进行训练。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_72e205e1f766459fb7f764b220069d8d@46958_oswg7965oswg299oswg174_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>鉴于在这样规模下进行精确的超参数搜索是不现实的。研究人员依据 LLM 的扩展规律，在小规模上进行了学习率的网格搜索，并确定了最佳学习率，随后将其应用于更大规模的模型中。&nbsp;</p><p><strong>监督微调</strong></p><p>研究人员还阐述了基于预训练模型所进行的监督微调（SFT）实验细节。&nbsp;</p><p>它们遵循了 LLaVA-1.5 和 LLaVA-NeXT 的方法，并从一系列多样化的数据集中收集了大约 100 万个 SFT 示例，包括：&nbsp;</p><p>由 GPT-4 和 GPT-4V 生成的指令-响应对，LLaVA-Conv 和 LLaVA-Complex 用于对话和复杂推理，以及 ShareGPT-4V 用于详细图像描述。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_53788d6b7cfa45c3819cadce3c753a0f@46958_oswg93338oswg650oswg486_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>针对学术任务的视频-语言（VL）数据集，涵盖了自然图像的 VQAv2、GQA、OKVQA、A-OKVQA 和 COCO Captions；文本丰富的图像数据集 OCRVQA 和 TextCaps；以及文档和图表理解的 DVQA、ChartQA、AI2D、DocVQA、InfoVQA 和 Synthdog-En。&nbsp;</p><p>此外，研究人员使用了类似于ShareGPT 的内部数据集，以保持模型对仅文本指令的遵循能力。&nbsp;</p><p><strong>论文结论</strong></p><p>研究团队致力于探索构建高效能的多模态大型语言模型（MLLMs）的策略。通过精心设计的消融实验，研究人员对建模和数据选择进行深入分析，从而归纳出一系列关键的经验教训。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1fd3b86869a54a768648b5f72adaf89b@46958_oswg29223oswg690oswg239_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这些经验成功培养出一个预训练模型，在各种少样本评估中取得了业界领先的成绩。经过监督微调（SFT）的过程，这一模型系列在多个基准测试中展现出卓越的性能，不仅能够处理多图像推理任务，还能适应少样本提示的挑战。&nbsp;</p><p>更多研究细节，请查阅论文地址：https://arxiv.org/pdf/2403.09611.pdf&nbsp;</p><p>另外，据彭博社报道，苹果在今年早些时候还悄然收购了加拿大 AI 初创公司 DarwinAI。而该公司掌握的核心技术之一是利用 AI 来理解深度神经网络算法，并据此定制生成一系列经过高度优化、满足特定需求的神经网络。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a3cb9131e1e34790818535426a56cb81@46958_oswg385858oswg1074oswg517_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>报道还指出，这项技术对苹果公司来说可能极具战略价值，因为它完美契合苹果致力于在设备上直接运行 AI 功能的长远规划，而非单纯依赖云端计算。&nbsp;</p><p>无论是发表学术论文，还是战略性收购，这一连串举措都清晰表明了苹果即将在 AI 领域大展拳脚。&nbsp;</p><p>如今距离 WWDC24 仅剩不到三个月的时间，现在，让我们备好爆米花，屏息以待，准备迎接库克所描述的「开辟新天地」。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/oBBUOU5RnfKcCR2YvlP_CQ" rel="noopener noreferrer nofollow" target="_blank">“APPSO”（ID:appsolution）</a>，作者：莫崇宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690737120554627</id>
            <title>苹果拿下第33家AI公司，自研300亿参数大模型首次亮相</title>
            <link>https://www.36kr.com/p/2690737120554627</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690737120554627</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:46:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果公司, DarwinAI, AI技术, 多模态大模型
<br>
<br>
总结: 苹果公司收购了加拿大AI创企DarwinAI，DarwinAI的AI技术主要应用于工业制造领域，特点是小型化且处理速度快。苹果一直致力于在设备上本地运行AI，而不是云端，DarwinAI的技术优势对苹果有帮助。苹果还发布了多模态大模型系列MM1，支持增强的上下文学习和多图像推理。苹果在AI领域的动作越来越多，收购AI企业数量超过谷歌和微软。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_6a8d040f99d1435aaf42b234da8d1e45@000000_oswg294023oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智东西3月15日消息，根据彭博社报道，苹果公司在今年年初收购了一家加拿大AI创企DarwinAI，这家创企的数十名员工已经加入了苹果的AI部门。这也是苹果已知收购的第33家AI公司。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5e96815c719e4a6fb274df42707ad7cf@000000_oswg114137oswg1080oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲2022年12月，DarwinAI团队成员合影，来源：Communitech</p><p>DarwinAI开发的AI技术主要用于工业制造过程中的印刷电路板（PCB）视觉检测领域，他们的核心技术优势主要是把AI系统做的更小型化，同时兼顾较高的处理速度。&nbsp;</p><p>这其实刚好正中苹果下怀，彭博社报道认为，苹果一直致力于做的就是在设备上本地运行AI，而不是放在云端，因此DarwinAI的技术优势对苹果来说可能很有帮助。&nbsp;</p><p>作为收购的一部分，DarwinAI的联合创始人兼首席科学家、加拿大滑铁卢大学首席AI研究员Alexander Wong也加入了苹果，并在苹果的AI部门中担任着一个领导岗位。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ee9448ff766f47e6a72f4e65e6fbec53@000000_oswg13805oswg326oswg275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Alexander Wong，来源：滑铁卢大学</p><p>昨日，苹果公司研发团队成员还发布了一篇论文，首次公布了苹果多模态大模型系列MM1，该系列模型支持增强的上下文学习和多图像推理，在一些多模态基准测试中有较好表现，最高参数量为300亿。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_6515b3d589e5419aa24e830674178634@000000_oswg165928oswg1080oswg1006_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲相关论文</p><p>论文地址： https://arxiv.org/pdf/2403.09611.pdf&nbsp;</p><p>可以看到，苹果在AI领域的动作，正越来越多。&nbsp;</p><h2>01.五年融资超1亿人民币，收购AI创企难救苹果股价</h2><p>DarwinAI成立于2017年，截至2022年12月，其员工人数约为30人，计划在2023年扩张到45-60人。&nbsp;</p><p>市研机构CB Insight曾将DarwinAI列入2021年和2020年的AI 100强排行榜中。&nbsp;</p><p>根据加拿大创业社区Communitech数据，截至2022年年底，DarwinAI的融资额已经超过了1550万美元（约合人民币1.1亿元）。DarwinAI的客户中有洛克希德·马丁公司和英特尔。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_9db8220aeb7c425fb5a81e6c831c33f7@000000_oswg97939oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲2020年3月团队成员合影，来源：英特尔</p><p>至于收购相关细节，彭博社向苹果询问了有关交易的问题，苹果公司在回答中提到，苹果时不时收购规模较小的科技公司是很正常的。但苹果并没有具体回答相关收购计划。&nbsp;</p><p>收购消息传出后，苹果股价曾短暂上涨超1%，但目前苹果股价年内跌幅已经达到了10%左右。&nbsp;</p><h2>02.收购AI企业数量超过谷歌微软，苹果的生成式AI大招何时来？</h2><p>最近，业内对苹果AI相关进展的关注度颇高，这一定程度上也是因为苹果在这波基于大模型的生成式AI热潮中几乎一直保持“沉默”，三星以及中国智能手机厂商们早已将大模型以及生成式AI相关技术应用在了智能手机产品中。&nbsp;</p><p>在AI热潮中，作为底层芯片算力巨头的英伟达，其股价持续飞涨，如今市值已经达到了2.2万亿美元，相比之下苹果股价却在美股上涨大潮中逆势下跌，有不少业内人士预计，英伟达市值超过苹果只是时间问题。&nbsp;</p><p>其实在过去的十几年里，苹果收购的AI公司数量超过了大多数竞争对手，比如谷歌和微软。&nbsp;</p><p>据市场调研机构Stocklytics最新报告，到2023年，苹果总共收购了32家AI公司，是科技公司中收购数量最多的，谷歌母公司Alphabet收购了21家，Meta收购了18家，微软收购了17家。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8fcb56c1498d4acd9fcd74cc1cb8f138@000000_oswg166558oswg1080oswg1005_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲到2023年，主要科技巨头收购AI公司数量统计，来源：Stocklytics</p><p>统计数据显示，自2017年以来，苹果在AI技术的股权和附加投资方面远远领先于竞争对手，约为21%，而微软则占12%，Alphabet占8%。&nbsp;</p><p>虽然收购了不少AI公司，但苹果在生成式AI领域的声量显然远低于微软、OpenAI、谷歌、Meta等公司。&nbsp;</p><p>当然，苹果也在抓紧跟上大部队。&nbsp;</p><p>据彭博社报道，苹果正在为iOS 18添加各类基于生成式AI的新功能，苹果公司CEO蒂姆·库克（Tim Cook）也在今年的股东大会上明确提到，苹果今年将在AI领域“开创新局面（break new ground）”。苹果大概率将在今年6月的WWDC24上公布相关消息。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_bfa8a3873f524cf7a0db33abf548f558@000000_oswg37466oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来看，苹果会将生成式AI技术整合到业务当中，比如在软件中增加自动创建PPT、自动生成文本的功能，此外苹果也在开发Xcode编程软件的新版本，新版可能会加入更多的AI功能帮助开发人员编写代码。&nbsp;</p><p>在人员方面，苹果此前也将造车团队近2000人都转移至了AI部门。&nbsp;</p><p>就在最近，苹果公司研发团队成员发布了一篇名为《MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training》的论文，并正式亮出了自己的300亿参数多模态大模型（MLLMs）。&nbsp;</p><p>研究中，研发团队聚焦于如何构建高性能多模态大模型，重点研究了各种架构组件和数据选择的重要性，通过对图像编码器、视觉语言连接器以及各种预训练数据选择进行仔细而全面的剥离，团队总结出了一些关键的设计经验。&nbsp;</p><p>研发团队构建了一个多模态模型系列MM1，其中模型最高参数量为300亿，据称这些模型在预训练指标中是“最先进的”，并且在一系列已建立的多模态基准测试中，经过监督微调后实现了“有竞争力的”性能。&nbsp;</p><p>MM1可以支持增强的上下文学习和多图像推理，使得少数样本的思维链提示成为可能。&nbsp;</p><h2>03.结语：从收购创企到大模型发布，苹果生成式AI提速</h2><p>收购AI创企属于苹果的“常规操作”，但此次事件发生的节点，恰好是苹果“掉队”AIGC颇受关注之时，也是苹果股价连连下跌的时点。&nbsp;</p><p>根据目前各路外媒爆料，苹果在生成式AI领域必然在紧锣密鼓地推进技术落地，从软件操作系统的新功能升级，到自研大模型陆续浮出水面。6月的开发者大会将成为一个关键节点，苹果是否会憋个大招，后来居上，我们拭目以待。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652768441&amp;idx=4&amp;sn=80995ad4710cc455d7f3de0014d5f9c2&amp;chksm=852f261bc78bf37e232da053a779c4f55567a2445fb029b7905b6e54ba6ae6c159725be1cba5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：云鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690745217494404</id>
            <title>外媒：字节跳动投资国产存储芯片公司昕原半导体，成第三大股东</title>
            <link>https://www.36kr.com/p/2690745217494404</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690745217494404</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:32:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 字节跳动, 昕原半导体, 虚拟现实, 存储芯片
<br>
<br>
总结: 字节跳动成为昕原半导体第三大股东，投资用于推进虚拟现实头显设备的开发，计划在Pico虚拟现实头显中使用昕原半导体的存储芯片。 </div>
                        <hr>
                    
                    <p><strong>划重点：</strong></p><ul><li>1字节跳动成为昕原半导体第三大股东，持股比例为9.5%。</li><li>2字节跳动投资昕原半导体，是为帮助推进该公司虚拟现实头显设备的开发。</li><li>3字节跳动表示，该公司将在Pico虚拟现实头显中使用昕原半导体的存储芯片。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1632f0a9f25f4a3db0e683d97f866d27@46958_oswg145150oswg658oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>腾讯科技讯&nbsp;据国外媒体报道，最新的企业记录显示，字节跳动已悄然对总部位于上海的存储芯片公司昕原半导体进行投资，成为该公司的第三大股东。</p><p>外媒报道称，字节跳动发言人证实了这一此前未经报道的投资，并表示这是为了帮助推进该公司虚拟现实头显设备的开发。</p><p>上周更新的中国企业记录显示，一家在新加坡注册的字节跳动所有的实体已成为昕原半导体的股东。记录显示，字节跳动已通过间接持股成为昕原半导体的第三大股东，持股比例为9.5%。</p><p>昕原半导体官网信息显示，该公司成立于2019年，专注于ReRAM新型存储技术及相关芯片产品的研发，涵盖高性能工控/车规SoC/ASIC芯片、存算一体IP及芯片、系统级存储芯片三大应用领域。作为国内ReRAM商业化领军企业，昕原半导体掌握一体化闭环技术能力，覆盖器件材料、工艺制程、芯片设计、IP设计和中试量产等诸多环节。由昕原自主建设的中国大陆首条先进制程ReRAM&nbsp;12寸中试后道生产线已顺利通线。</p><p>据知情人士对外媒透露，昕原半导体的最大股东是一家在香港注册的实体Memris&nbsp;Asia&nbsp;Pacific&nbsp;Ltd.。该香港实体持有昕原半导体约29%的股份，但由多名投资者持有。</p><p>外媒引述字节跳动发言人的话表示，“我们投资昕原半导体是希望在Pico虚拟现实头显中使用该公司生产的存储芯片。”去年12月曾有媒体报道称，字节跳动子公司Pico已经取消了下一代VR头显的计划，转而专注于一个长期项目，最终目标是开发一款使用更先进技术的高端头显。</p><p>昕原半导体并不是字节跳动支持的唯一一家中国芯片公司。根据记录，2021年，字节跳动投资了总部位于北京的图形处理器开发商摩尔线程。摩尔线程的其他支持者包括国有企业和风险投资公司红杉中国。</p><p>阿里巴巴集团等其他中国科技巨头也投资了本土芯片初创公司。</p><p>本文来自<a href="https://new.qq.com/rain/a/20240312A09V3300" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，编译：无忌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690730843614855</id>
            <title>苹果加入战局，携 300 亿参数的 AI 大模型 MM1 “炸场”</title>
            <link>https://www.36kr.com/p/2690730843614855</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690730843614855</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:25:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 造车, AI, 苹果, MM1
<br>
<br>
总结: 苹果取消了电动车项目，转而在生成式人工智能领域开辟新天地。他们收购了AI初创公司DarwinAI，发布了多模态大模型MM1，旨在分享建立这样模型的方法。MM1拥有300亿参数，具有优秀的图像识别和推理能力，可以统计对象、执行OCR识别、展示常识和文字知识，具有少量学习能力。 </div>
                        <hr>
                    
                    <p>在「造车」与「AI」两条截然不同的赛道上，苹果在今年毅然决定取消搞了十多年的电动车项目，而宣布：公司将于 2024 年在生成式人工智能领域“开辟新天地”。</p><p>果不其然，在战略方向定下之后，他们的动作很快。</p><p>一方面，据彭博社最新报道，苹果收购了一家来自加拿大专门研究基于视觉技术的 AI 初创公司 DarwinAI。虽然苹果及 DarwinAI 尚未宣布这笔交易，但是根据 LinkedIn 部分专家资料显示，这家初创公司团队的几名成员于 1 月份已经加入了苹果的机器学习团队。</p><p>另一方面，在 3 月 14 日，也有不少网友发现苹果在 30 位研究员的加持下，带着一款名为&nbsp;<strong>MM1 的多模态大模型</strong>强势入场。</p><p>苹果的取名也一如既往地简单好记：M1 是自家的芯片，那 MM1 就是自己的大模型。</p><p>此外，苹果更是一上来便说明，自己走了和现在开源、闭源大模型不同的分享路线，正如其论文名称所示，其直接在论文中分享了关于 MM1 多模态大语言模型的预训练方法、分析和启示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_207596fa25594f8b9b996f071fadeef4@46958_oswg135594oswg1080oswg816_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/pdf/2403.09611.pdf</p><h2>因业界的“不透明性”，苹果发布多模态大模型——MM1</h2><p>所谓多模态，是指在各种格式（如图像文件、视频文件和音频文件以及纯文本数据）上训练的大规模语言模型。</p><p>之所以发布 MM1，苹果研究团队在论文中指出，主要原因是因为现在很多 AI 公司在 AI 模型的学习方法上有着“不透明性”。</p><p>行业中现有的 MLLM（Multimodal Large Language Model，多模态大型语言模型）主要分为两类：闭源模型和开放模型。</p><p>闭源模型往往虽然可用，但外界对其数据模型、模型架构和训练细节所知甚少。</p><p>至于开放模型，很多公司会将模型参数连同数据模型和训练配置的详细说明一起发布，从而使社区能够在此基础上更进一步微调。</p><p>但是在苹果团队看来，无论是开放式的还是封闭式的，大多数的模型对于他们所使用的算法设计选择的过程几乎什么都没有公开，特别是关于多模态预训练。</p><p>为了在这一领域进一步研究，苹果研究团队认为，当务之急是分享如何建立这样模型的方法。</p><p>所以，一不做二不休，苹果发表了这篇论文，不仅带来了 MM1，还在论文中直接记录了 MLLM 的构建过程，也试图尽可能地去分享制定设计的经验教训。</p><h2>300 亿参数的 MM1 可以用来干些什么？</h2><p>研究人员在论文中解释道，通过在<strong>模型架构决策</strong>和<strong>预训练数据选择上</strong>执行小规模消融实验，以及通过对图像编码器、视觉语言连接器和各种预训练数据选择进行细致全面的分析，他们发现了一些关键的设计经验。</p><p>苹果研究团队证明了在大规模多模态预训练中，与其他已发布的预训练结果相比，使用图像字幕、交错图像文本和纯文本数据的组合对于在多个基准测试中实现最先进（SOTA）的少量测试结果至关重要。</p><p>此外，图像编码器、图像分辨率和图像标记数量具有重大影响，而视觉语言连接器设计的重要性则相对较小。</p><p>详细来看，在建模方面，研究人员发现设计的重要性按照以下顺序来：<strong>图像分辨率、视觉编码器的损耗和容量，以及视觉编码器的预训练数据。</strong></p><p>此外，研究人员使用三种不同类型的预训练数据：<strong>图像字幕、交错图像文本和纯文本数据。</strong>由此看到，当涉及到少样本和纯文本性能时，交错和纯文本训练数据是至关重要的，而对于零样本性能，字幕数据最为重要。</p><p>在监督微调（SFT）后，无论是在预训练中使用的评估上，还是在更多基准上，这些趋势都保持不变。这表明，在预训练中发现的能力和建模决策在微调后得以保留。</p><p>最后，通过使用更大的 LLM（从 3B、7B 到 30B）以及探索混合专家模型（MoE）（从使用 64 位专家的 3B MoE，到使用 32 位专家的 7B MoE）来扩展苹果的模型，从而建立了&nbsp;MM1，这是一个多模态模型系列，<strong>参数多达 300 亿。</strong></p><p>由于进行了大规模的多模态预训练，MM1 有不错的图像识别和推理能力。更具体地说，Apple MM1 非常擅长在用户输入的图像和文本中寻找“规则”。</p><p>就如下图所示，当用户给出排列的图像，并注明每张上传的图像有关的“对象”和“对象编号”的文本：</p><p>第一张照片：1 只泰迪熊，1 个智能手机。</p><p>第二张照片：2 只猫的图像。</p><p>第三张照片：3 本书、1 个花瓶和 1 个玻璃杯。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8fb88e1f440940908ba2017df6842b7a@46958_oswg368446oswg793oswg586_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，MM1 还具有：</p><p>(a) 统计对象并遵循自定义格式，输出文本</p><p>(b) 参照图像的某些部分并执行 OCR 识别</p><p>(c) 展示有关日常物品的常识和文字知识</p><p>(d) 执行基本的数学功能。</p><p>经过指令调整后，MM1 还具有很强的少量学习能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e8fd0ad3911540ab88b75ae0eaadb9b6@46958_oswg92989oswg866oswg453_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如说下图，上传一张照片，MM1 可以给出具体的数量、识别图片的数值、动物种类等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_25765fd908d4400bb1d104b1020b8c2f@46958_oswg423271oswg680oswg809_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同时，还能输入多张图片。比如下图：</p><p>Q：“识别图片中是什么数字显示在蛋糕上。然后算出总和。”</p><p>MM1-30B-Chat：第一个图像显示的是一个蛋糕上的数字 3，第二个图像显示的是一个蛋糕上的数字 4。和为 7。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b08cc0a33659496d83bebb45287ed5a8@46958_oswg213252oswg673oswg410_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Q：我向你展示一幅图像，你需要预测当图像旋转 180 度时显示的字母或数字。</p><p>MM1-30B-Chat：W，9</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_34fae4421f6e4fd49b5cffcf48d1b83a@46958_oswg33803oswg316oswg438_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Q：我给你看几张图，你的任务是回答我的问题。估计每张图像的温度(以摄氏度为单位)。也提供理由。</p><p>MM1-30B-Chat：</p><p>海滩上带伞的图像：25-30摄氏度。伞撑起来了，人们都在海滩上，暗示着一个温暖、阳光灿烂的日子。</p><p>飞机飞越雪地的图像：-20至-30摄氏度。飞机正飞越一片白雪覆盖的地区，地面上有车辆，说明冬天天气寒冷。</p><p>草地上的动物吃草的图像：15-20摄氏度。动物在吃草，这通常发生在较温和的天气条件下。草是绿色的，进一步表明温带气候。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1c789766950d42d08b9ba1ea2f4b648c@46958_oswg510334oswg869oswg706_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从示例看来，整体效果还是不错的。据苹果研究员透露，MM1 这些模型的性能优于大多数相关研究。特别是，预训练模型 MM1 是 SOTA，在少样本设置下的字幕和视觉问题解答（VQA）任务中，无论是小尺寸还是大尺寸，其性能都优于 Emu2、Flamingo 和 IDEFICS。经过 SFT 处理后，最终模型在 12 个既定的多模态基准测试中取得了具有竞争力的性能。</p><h2>MM1 是如何构建出来的？</h2><p>那么，MM1 究竟是怎么“造”出来的？苹果研究员首先从三个维度展开了分享：</p><p>架构：研究员研究了不同的预训练图像编码器，并探索了将 LLM 与这些编码器连接起来的各种方法。</p><p>数据：他们还考虑了不同类型的数据及其相对混合权重。</p><p>训练程序：探讨了如何训练 MLLM，包括超参数以及在哪个阶段训练模型的哪些部分。</p><p>起步阶段，由于训练一个大型 MLLM 需要大量的资源，研究员采用了一种简化的消融设置。</p><p>具体来看，研究员使用一个较小的模型基础配置，并在此基础上进行删减。每次修改一个组件，无论是架构模块还是数据源，然后评估设计选择对每个组件的影响。这样，研究员就能得出最终的模型-数据配置，并在模型参数和训练时间方面进行扩展。</p><p>消融的基本配置如下：</p><p>图像编码器：在 DFN-5B 和 VeCap-300M 上使用 CLIP loss 的 ViT-L/14 模型；图像大小为 336×336。</p><p>视觉语言连接器：C-Abstractor，含 144 个图像标记。</p><p>预训练数据：混合字幕图像（45%）、交错图像文本文档（45%）和纯文本数据（10%）。</p><p>语言模型：1.2B Transformer 解码器语言模型。</p><p>为了评估不同的设计决策，研究者在各种 VQA 和字幕任务中使用了零样本和少样本（4 个样本和 8 个样本）性能：COCO Cap tioning、NoCaps、TextCaps、VQAv2、TextVQA、VizWiz、GQA和 OK-VQA。</p><p><strong>模型架构消融</strong></p><p>在这项工作中，研究员分析了使 LLM 能够处理视觉数据的组件，分析如何用最佳方式预训练视觉编码器，以及如何将视觉特征连接到 LLM 的空间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_346637a191d1459d94f8f46e43b9f479@46958_oswg145015oswg886oswg386_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>过去，大多数 MLLM 都使用 CLIP 预训练图像编码器，而最近的研究也开始探索使用纯视觉自监督模型（如 DINOv2）作为图像编码器。在这里，苹果研究员主要消除了图像分辨率和图像编码器预训练目标的重要性。他们使用的是 2.9B LLM（而不是 1.2 B），以确保有足够的容量来使用一些较大的图像编码器。</p><p>在实验过程中，研究人员发现，将图像分辨率从 224 提高到 336，所有架构的所有指标都提高了约 3%。将模型大小从 ViT-L 增加到 ViT-H，参数增加了一倍，但性能提升不大，通常不到 1%。最后，加入 VeCap-300M （一个合成字幕数据集）后，在少量拍摄的情况下，性能提升超过 1%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8af0ff4377b743689d623db766896d1e@46958_oswg38321oswg833oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在 VL 连接器维度，研究人员发现视觉标记数和图像分辨率最重要，而 VL 连接器的类型影响不大。下图显示的结果表明，随着视觉标记数量或图像分辨率的增加，零样本和少样本的性能都会提高。</p><p>这一点，与之前很多专家发现的情况有所不同，即不同的架构设计似乎并不能最终产生更强的模型。经过指令调整后，所有三种架构在 336px 和 114 token 设置下都取得了非常相似的结果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_56ddbdbbd1e243b8acf89a729d64ee8d@46958_oswg87355oswg847oswg277_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大规模和适合任务的数据对训练高性能模型至关重要。通常，模型的训练分为两个阶段：预训练和指令调整。前一阶段使用网络规模的数据，而后一阶段则使用特定任务策划的数据。</p><p>有两类数据通常用于训练 MLLM：由图像和成对文本描述组成的字幕数据；以及来自网络的交错图像-文本文档。需要注意的是，字幕数据往往包含相对较短的文本，与图像的相关性较高。</p><p>相反，交错数据中的文本篇幅更长、种类更多，但与周围图像的相关性平均较低。最后，苹果研究人员还采用了包括纯文本数据，以帮助保留底层 LLM 的语言理解能力。以下是所有数据集：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3329792e222940f29a953e7eba4c55ec@46958_oswg55662oswg790oswg228_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>预训练数据消融</strong></p><p>在预训练数据消融环节，研究员使用了与消融模型相同的模型设置，唯一不同的是，在这里训练了 200k 步，以充分利用大规模数据训练。</p><p>最终，研究员总结出以下经验：</p><p>数据经验 1：交错数据有助于提高少样本和纯文本性能，而字幕数据则能提高零样本性能。</p><p>数据经验 2：纯文本数据有助于实现少样本和纯文本性能</p><p>数据经验 3：精心混合图像和文本数据可获得最佳的多模态性能，并保留较强的文本性能。</p><p>数据经验 4：合成数据有助于少量学习</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e4b2ea5778c647ffb3c566f252301fae@46958_oswg177836oswg804oswg823_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据以上，苹果研究员最终确定了 MM1 多模态预训练的最终方法：</p><p>图像编码器：使用了分辨率为 378x378px 的 ViT-H 模型，并在 DFN-5B 上使用 CLIP 目标进行了预训练。</p><p>视觉语言连接器：由于视觉标记的数量最为重要，因此研究员使用了具有 144 个 token 的 VL 连接器。实际架构似乎不太重要，其选择了 C-Abstractor。</p><p>数据：为了保持零样本和少样本的性能，研究员采用了 45% 交错图像-文本文档、45% 图像-文本对文档和 10% 纯文本文档这样的组合数据。</p><p>为了提高模型性能，研究员将 LLM 的大小扩展到 3B、7B 和 30B 个参数。</p><p>底层 LLM 在同一纯文本数据集上进行内部训练。由于 LLM 和视觉编码器都经过了预训练，研究员将它们作为 MM1 的初始化，并在上述数据组合上进行了 200k 步（约 100B 标记）的多模态预训练。</p><p>所有模型都是在序列长度为 4096、每个序列最多 16 幅图像（分辨率为 378×378）、批量大小为 512 个序列的情况下完全不冻结地进行预训练的。所有模型均使用 AXLearn 框架进行训练。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4870e9e26ba448ee838e4e6a530fb69c@46958_oswg29131oswg340oswg290_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最终，研究员通过适当的提示对字幕和 VQA 任务中的预训练模型进行了评估。得到如下结果：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4ba493ee56ae41479b9d57e4c35d58ac@46958_oswg181603oswg717oswg774_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>请注意，研究员只将其模型与较大的模型进行比较，例如，将 MM1 的 30B 模型与两个 80B 模型进行比较。</p><p>说到“少量”性能，MM1 优于所有已发表的预训练 MLLM。在字幕基准和 VizWiz-QA 基准中，我们看到了 30B 的卓越性能。在 VQAv2、TextVQA 和 OKVQA 上，我们的性能可与 Emu2 相媲美。在零样本性能方面&nbsp;，即使不进行指令微调，MM1 模型在所有模型规模的 TextCaps 上都表现良好，在大多数基准的小规模上与 Flamingo-3B 不相上下。</p><h2>监督微调实验</h2><p>除了以上，研究员还进行了监督微调（SFT，Supervised Fine-Tuning）实验。</p><p>根据下图结果显示，MM1-3B-Chat 和 MM1-7B-Chat 优于所有已列出的同尺寸模型包括 Google 的 Gemini Nano。</p><p>同时，在 VQAv2、TextVQA、ScienceQA、MMBench 以及最近的基准测试（MMMU 和 MathVista）中，MM1-3B-Chat&nbsp;和 MM1-7B-Chat 的表现都不错。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e1f429d2c43d49309f784e1b40df947d@46958_oswg222648oswg704oswg680_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其次，研究员还分析了两种 MoE 模型：3B-MoE（64 位专家）和 6B-MoE（32 位专家）。在几乎所有基准测试中，苹果的 MoE 模型比密集型模型取得了更好的性能。</p><p>再者，对于 30B 大小的模型，MM1-30B-Chat 在 TextVQA、SEED 和 MMMU 上的表现优于 Emu2-Chat37B 和 CogVLM-30B。不过，LLaVA-NeXT 不支持多图像推理，也不支持少量提示，因为每幅图像都表示为 2,880 个发送到 LLM 的标记，而苹果的标记总数只有 720 个。这就限制了某些涉及多图像的应用。</p><p>另外，苹果研究团队还研究了图像分辨率和预训练对 SFT 性能的影响，其结果如下。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c0d7708afdcb444fbb0fd439905f49c7@46958_oswg94879oswg724oswg326_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>MM1 尚未公开以什么样的形式对外</h2><p>值得注意的是，苹果发布的这篇论文中，并没有提及 MM1 是否会发布。</p><p>然而，正如文章伊始所提及的，苹果已经停止了开发电动汽车，并收购了 DarwinAI。</p><p>此外，iPhone 的 Siri 首席执行官 Dag Kittlaus 已宣布，“Siri 将在 2024 年做一些很酷的新事情。然后加速并成为人工智能领域的真正力量。Apple 具有独特的优势，可以实现新的、有用的和意想不到的 LLM 用例。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d1ddf098e1fe4e6f8c11d6ed4fbdad03@46958_oswg28599oswg468oswg159_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>MM1 如今只是苹果正式对外的 AI 布局第一步，我们也期待它的进一步。</p><p>更多技术细节可详见论文报告：https://arxiv.org/pdf/2403.09611.pdf</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/jWeWnyInazGUzLGTyIFgZw" rel="noopener noreferrer nofollow" target="_blank">“CSDN”（ID:CSDNnews）</a>，整理：屠敏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>