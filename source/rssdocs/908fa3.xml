<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/3031501636085253</id>
            <title>苹果的悲剧，不是从iPhone降价参加双十一开始的</title>
            <link>https://www.36kr.com/p/3031501636085253</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3031501636085253</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 08:19:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 创新, 收税, 市场竞争  
<br><br>  
总结: 苹果在经历了巨大的财务成功后，逐渐失去了其创新的本质，变成了一个以收税为主的企业。随着规模的不断膨胀，苹果的优势逐渐转变为对创新的禁锢，导致其在VR、汽车和大模型等领域的落后。尽管苹果的营收和利润大幅增长，但其曾经引领行业的地位和创新精神却日渐消失。苹果的“苹果税”政策也引发了广泛的争议，成为限制新兴竞争和创新的障碍。最终，苹果从一个颠覆者变成了一个维护自身利益的巨头，反映出硅谷创新精神的衰退。 </div>
                        <hr>
                    
                    <p><strong>苹果正在走下神坛。</strong></p>
  <p>这是苹果第一年官方参加双十一。在最新机型iPhone16仅1个月后，该系列随即迎来全系官方渠道大降价。</p>
  <p>而与降价一同冲上热搜的，则是iPhone 16系列的重启问题。在外网Reddit、MacRumors论坛和Apple Support Communities等平台，关于iPhone 16随机重启的投诉，数次登上论坛头条。</p>
  <p>汽车迟迟不见踪影、VR雷声大雨点小、大模型更是远远落后于一众竞争对手……</p>
  <p><strong>此时此刻，拿走全球智能手机产业90%利润的苹果，正前所未有的成功。但也离那个2007年1月9日旧金山马士孔尼会展中心Macworld大会上，那个乔布斯拿着初代iPhone，高呼“今天，苹果将重新发明手机”的苹果越来越远：</strong></p>
  <p>苹果的CEO，不再是那个统一了全球科技创业者着装风格的偶像。</p>
  <p>苹果的手机新功能，不再是各大手机品牌争相模仿的对象。</p>
  <h2><strong>是什么时候，我们觉得苹果不再像苹果了？</strong></h2>
  <p>或许不是从发布史上最丑的iPhone 16开始的，也不是乔布斯的去世开始的。</p>
  <p><strong>而是伴随着规模的不断膨胀，曾经的优势变成禁锢，苹果从软硬一体创新的风向标，变身生态围墙的铜墙铁壁维护者的时候。</strong></p>
  <p><strong>苹果什么时候不再像苹果了</strong></p>
  <p>无论你是否承认，如今的苹果已经不再像苹果，反而像极了那个曾与苹果闹翻了无数次，又合作了无数次的全球CPU霸主——英特尔。</p>
  <p><strong>它们都曾是开启一个时代的存在。</strong></p>
  <p>英特尔是全世界最早规模化生产芯片的产业奠基人，摩尔规律的奠定者，电脑pc时代的开创者。甚至，迄今为止，如今的英特尔，也依然是全世界唯三可以生产7nm芯片的企业；唯二可以规模量产CPU的企业；以及半导体营收前三的巨无霸。</p>
  <p>然而历史的荣光，早随着乔伊斯、戈登摩尔这样一代宗师的逝去，被属于台积电、英伟达、AMD的新故事所替代。在资本市场，高通、博通在计划收购英特尔；英伟达值三十个英特尔，台积电值九个英特尔，就连市占率远低于英特尔的AMD也可以买下三个英特尔……</p>
  <p><strong>比市场上的落后更悲哀的，是一个科技企业无可避免地走入暮年，成为曾锐意颠覆的模样。</strong></p>
  <p><strong>而苹果变老的痕迹，VR、汽车，甚至大模型，都比手机企业提早感知到。</strong></p>
  <p>在等待苹果VR这件事情上，全球的科技企业，花了足足十年。直到2023年6月6日苹果一年一度的苹果全球开发者大会上，首款MR混合现实产品Apple Vision Pro真正面世。</p>
  <p>没有想象中的更高灵活度，没有更轻的重量，甚至也没有苹果一贯擅长的流畅体验与工业设计迭代，有的只是3499美元起步的高级玩具。</p>
  <p>而在等待苹果的过程中，苹果在中国最忠诚的供应链企业歌尔，都一度靠着多年的技术积累，成为如今VR领域销量最高的Meta旗下oculus的代工厂，旗下孵化的自研VR品牌Pico也被字节收购，成为国内首屈一指的VR头部玩家。</p>
  <p>汽车更不必说，为了十多年前就已经立项的苹果“泰坦自动驾驶计划”，苹果一度拒绝了想把特斯拉卖给苹果的马斯克，将中国大陆、中国台湾、乃至韩国的一众汽车代工厂溜了一圈。然而，富士康自研的汽车都已经发布了两款，苹果泰坦迄今为止的进度，还依然是一个不愿公开承认存在的自动驾驶汽车项目。</p>
  <p>到了大模型产业，当国产的小米OV，都已经推出自研大模型之际，全世界翘首以盼的果粉，等来了发布会上苹果与OpenAI合作官宣，未来ChatGPT将整合到包括新一代iOS、iPadOS以及macOS中，成为苹果的Intelligence来源。</p>
  <p><strong>所有人都在等待苹果的十年磨一剑，却无人想到，苹果十年磨的全是剑鞘。</strong></p>
  <p><strong>但苹果是一个失败的企业吗？答案是否定的。</strong></p>
  <p><strong>与“失望”并列出现的，是苹果财务侧史无前例的“成功”：</strong></p>
  <p>乔布斯去世后，十二年间，苹果的营收从1082亿美金增长到了3833亿美金，增幅三倍；利润则从259亿美金，增长到了970亿美金，增幅近四倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_164770d6c98d4b619c78d558d2e16217@000000_oswg146357oswg750oswg393_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p><strong>毫无疑问，苹果正变成一个越来越庞大、越来越赚钱的帝国。财务的扩张，伴随用户的忠诚，足以让它有无数次推出最丑iPhone却依旧被信任的机会，也足以支撑它在VR、汽车、大模型，输了一次又一次。</strong></p>
  <p><strong>因为，躺在iPhone的金山上，这座帝国活成了所有企业梦寐以求的样子——收税。</strong></p>
  <p>所谓苹果税，指的是，苹果生态内，开发者必须通过苹果的官方支付渠道进行交易，而苹果则对交易金额抽成30%。</p>
  <p>一开始，这一条款包括用户在苹果App Store的买断费用，但2016年后，苹果对条款的适用范围进一步扩张：苹果生态内软件，除了拼多多或者淘宝这种购物网站，一切的用户订阅、打赏、充值等支付行为，苹果全部抽成30%。</p>
  <p>也是因此，同样的游戏道具，苹果用户的价格会高于安卓；同样的直播打赏金额，主播在苹果生态内收到的金额低于安卓。</p>
  <p>据统计，仅去年一年，苹果在中国市场的软件收入，就高达400亿收入；甚至，强如谷歌，为了能成为苹果的内置浏览器应用，也要每年纳税200亿美金。</p>
  <p>尽管，为了这30%的暴利，苹果仅仅提供的，只有App Store的日常维护，不过，所有的app开发者早已习以为常。</p>
  <p><strong>但，本该如此吗？</strong></p>
  <p><strong>或许，关于苹果，真正“变老”的节点，其实正是创新起家的公司，最后变成了收税阻碍创新，却借此在商业上无比成功的那一刻。</strong></p>
  <p><strong>这又是一个屠龙少年终成恶龙的历史故事循环。</strong></p>
  <h2><strong>当屠龙少年成为恶龙</strong></h2>
  <p><strong>2021年，一向以招牌的“厨子式微笑”出现在公众眼前的库克，罕见地坐在被告席上。</strong></p>
  <p>站在起诉方的，则是全球鼎鼎有名的美国游戏开发引擎epic。作为近十年来最负盛名的游戏制作团队之一，epic的引擎一度被用在《战争机器》系列、《子弹风暴》各大热门游戏的开发中，技术之领先，一度引来NASA一同合作开发VR火星模拟器。</p>
  <p>2020年8月，Epic Games仅仅因为《堡垒之夜》绕开App Store，选择让玩家在游戏中直接付费，不到半天，就被苹果在应用商店下架，下架仅一个小时，Epic一纸诉状，将苹果送上了法庭。</p>
  <p>然而，面对epic对苹果滥用地位收税的指控，库克的反驳罕见的疾言厉色，陈词概括如下：</p>
  <p>1、从来没有垄断，苹果面临着大量的竞争。</p>
  <p><strong>尽管，苹果一家占据了全球智能机利润的90%+</strong></p>
  <p>2、苹果收税是必要的，从应用程序开发者那里收取的佣金有助于为App Store提供更好的安全性。</p>
  <p><strong>尽管，各个国家，对民间借贷利率的司法保护与高利贷的划分，也仅在20%上下</strong></p>
  <p>3、APP开发者自己要反思，想要什么和消费者想要什么之间存在冲突；苹果无罪且有功，苹果已经为许多开发者降低了应用商店的费用。</p>
  <p><strong>尽管，30%，已经是那个时间节点下，几乎最高的抽成比例</strong></p>
  <p>然后，一番慷慨陈词，苹果赢了。</p>
  <p><strong>同一时间，同一理由被epic送上审判席的谷歌，因为在搜索引擎中的更高市场占比，被判败诉。</strong></p>
  <p><strong>苹果的胜诉，随机在全世界范围内引起了更高声浪的控诉。</strong>除了音乐流媒体Spotify等应用持续不断的反对，早在2019年，美国司法部也开启了对苹果的调查，并持续迄今；并在上半年，联合15个州和哥伦比亚特区的总检察长，对苹果公司提起反垄断诉。</p>
  <p>美国之外，日本、韩国、荷兰也先后起草了关于降低“苹果税”的法案，法律的硬性规定下，苹果在韩国的费用从30%下调至26%，在荷兰约会类应用费用下调至27%，并先后开放第三方支付。</p>
  <p><strong>唯一的例外是中国。</strong></p>
  <p>不久前，据报道，今年6月前后，苹果正施压腾讯、字节这两家国内流量规模最大的互联网公司，要求其配合封堵微信、抖音中小程序中绕过苹果进行支付的行为。如不配合，未来将拒绝微信与抖音的重要更新。</p>
  <p>更直白一点来说，苹果在用拒绝更新，要挟微信与抖音的小程序付费。</p>
  <p>市场则对这场围堵进行了更加精准的估值：字节跳动，此前曾测算，仅仅小游戏，今年的市场规模将达到600亿，并且这一市场还在持续的高速增长；相应的，<strong>一旦对此收税，苹果的营收将再多180亿。</strong></p>
  <p><strong>进一步换算，这约等于小米2023年，一整年的净利润。</strong></p>
  <h2><strong>不断瓦解的铜墙铁壁</strong></h2>
  <p>不同于epic的激烈抗争无果，以及美国司法部的雷声大雨点小，<strong>微信与字节的回应，是罕见的沉默。</strong></p>
  <p><strong>而在这背后，则是一场全球范围内，关于移动互联网基础设施交接的无声变革。</strong></p>
  <p><strong>回顾全球的互联网发展史，一定程度上，收税角色变化的本质，是一场又一场的用户入口争夺战。</strong></p>
  <p>90年代，互联网最大的甚至唯一的入口是Windows，与之相伴随的，则是微软成为全球顶尖科技水平的代名词，比尔·盖茨登顶全球首富。</p>
  <p>此后，伴随搜索引擎技术成熟，即使所有的应用仍在部署在操作系统，但越来越多的功能在网页端上线，搜索引擎成为距离用户最近的入口，谷歌、百度随之崛起，成为中美两国在2005年前后最具权力地位的科技巨头。</p>
  <p>伴随着2010年之后的移动端浪潮，搜索引擎开始被垂直的电商、外卖、新闻资讯平台分流，继而成就了阿里、美团、字节一大批智能手机时代的生态帝国。</p>
  <p>与此同期，手机取代电脑，全球的通信运营商，以及苹果、华为、小米等手机企业粉墨登场，凭借着对用户流量入口的把握，一度靠着应用商店，在软件层面赚得盆满钵满。</p>
  <p>直到最近几年，不同手机品牌之间的差距越来越小，微信、字节等超级APP不断膨胀，成为直接接触用户最久、功能绑定最多的平台，<strong>相应的新生态也在超级APP中成长，小程序就是代表。</strong></p>
  <p>这种权力结构的变迁中，每一代“入口”的老去，伴随的，往往是用户的增长，统治地位的不断加深；但与此同时，在此基础之上，新的平台不断成长，越来越多的创新与用户使用时长，被转移到新的平台之上，原本的入口，与用户的距离，与越来越长。</p>
  <p>当原本的入口，已经不再能为新的小程序与游戏们带来增量，却依旧靠着垄断的地位，维持着30%的高税收，博弈的天平也就开始向新生事物一侧倾斜：</p>
  <p>对于苹果的精准打击，美国司法部一针见血“苹果正在摧毁创新”，即苹果的App Store的政策，是<strong>苹果不断财务扩张的生态长城、是苹果可以一次次错过的最大底气；但却也限制了下一代的竞争和创新，成为无数创新难以逾越的铜墙铁壁。</strong></p>
  <h2><strong>一代地球人失落的硅谷梦</strong></h2>
  <p>事实上，没有人会想到，雁过拔毛30%的苹果，也一度是创新与生态活力的代名词。</p>
  <p>在苹果之前，全球的游戏和移动应用的分销，往往由运营商直接控制。而由于运营商对渠道流量的绝对把控，能够进入运营商的分销渠道，就往往意味着销量的保底。也是因此，绝大多数情况下，运营商对游戏收入的抽成，往往高达 90%。</p>
  <p>而伴随着苹果的崛起，与App Store对传统短信订阅下载的取代，开发者发布应用变得更容易，开发的流程也伴随着苹果提供的标准开发工具，而变得大幅简化，但收税标准却从过往的90%，降到了 30%。</p>
  <p>只是时移世易：</p>
  <p>不断变化配色的iPhone不再是全球手机的风向标；</p>
  <p>越来越膨胀的营收与曾经“改变一切”的勇气越来越远；</p>
  <p>收税的苹果不再是创新的代名词……</p>
  <p>而伴随着流量入口的话语权转移，30%成为新的税收天花板，苹果也从曾经的屠龙少年变身恶龙。</p>
  <p><strong>但，苹果从来不是个例。</strong></p>
  <p>以苹果的成功与失败一体两面为切口，映射出的，是这些年来，硅谷越来越高的房价，创业者们越来越少的极客精神，算法越来越多以无数人血肉之躯对最佳工作效率的试验。</p>
  <p>……</p>
  <p><strong>于是，越来越多的人、越来越多的企业离开“硅谷”，越来越多的创新，被扼杀在大企业用流量编织起的铜墙铁壁。</strong></p>
  <p><strong>那是一代地球人失落的硅谷梦。</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzUyNjA0Mjg3Ng==&amp;mid=2247492626&amp;idx=1&amp;sn=04dc1051560b9cf78ab7b4076255c724&amp;chksm=fb89d44127c61b03e518ef78e9b0d564743f9baa5f96ff9e18453cb676fe1d8d313e4ca9d91c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“边码故事”（ID：tech-kk）</a>，作者：刘老师，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3031615136572678</id>
            <title>专家模型不要专家并行，微软开源MoE新路径</title>
            <link>https://www.36kr.com/p/3031615136572678</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3031615136572678</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 07:00:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: MoE大模型, GRIN MoE, SparseMixer, 训练方法  
<br><br>  
总结: 微软研究人员开源了新的混合专家大模型GRIN MoE，采用新一代SparseMixer方法来精确估计专家路由的梯度，解决了传统方案中的问题。GRIN MoE在参数量和推理时激活的参数上表现优异，尤其在编码和数学测试中得分高于同类模型。该模型通过数据、pipeline和张量并行的方式进行训练，避免了传统方法中丢弃token的问题，显著提升了训练效率。GRIN MoE的设计和训练方法展示了其在计算扩展潜力上的优势。 </div>
                        <hr>
                    
                    <p><strong>【导读】</strong>近日，来自微软的研究人员开源了使用全新方法训练的MoE大模型，不走寻常路，且编码和数学表现出色。</p>
  <p>继Phi家族之后，微软又开源了新的混合专家大模型——GRIN MoE。</p>
  <p>与Phi-3.5同样的个头（16 * 3.8B），却采用了截然不同的训练方法。</p>
  <p>这个「不走寻常路」如果写个太长不看版，那就是两句话：</p>
  <blockquote>
   <p>1. 使用新一代SparseMixer来精确估计专家路由的梯度，解决传统方案中利用门控梯度代替路由梯度的问题。</p>
   <p>2. 专家并行不要了，训练中改用数据、pipeline和张量并行，避免了传统方法丢弃token的问题。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_128f0cfbb71548cdab4b7a2a40ab613c@46958_oswg89694oswg1077oswg449_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文地址：https://arxiv.org/abs/2409.12136</p>
  <p>当然了，上面两句话是小编说的，多少有点糙，文中细节，还请诸君继续阅读~</p>
  <p>这年头，新来一个LLM，当然要先刷分了——</p>
  <p>参数要少，效果要好，所以要在左上角：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_a634bb79970349c782ce3de35d3eb7b6@46958_oswg94266oswg765oswg799_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>GRIN作为MoE架构，总参数量约42B，推理时激活的参数为6.6B，打同级别（7B）的非MoE模型是手拿把攥，甚至比14B的Phi-3还要略胜一筹。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_80322e31ea444b5e9698a179e0e3b076@46958_oswg386717oswg1080oswg807_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在上面的这份成绩单中，GRIN MoE表现优异，尤其是在编码和数学测试中。</p>
  <p>比如，在衡量数学问题解决能力的GSM-8K中，GRIN MoE得分为90.4，而在编码任务基准HumanEval上拿到了74.4分。</p>
  <p>在MMLU（大规模多任务语言理解）基准测试中GRIN得分为79.4，超过了同为MoE架构的Mixtral（70.5分），以及自家的Phi-3.5（78.9分）。</p>
  <p>如果对比流行的商用模型，GPT-3.5表示感受到时代的力量，默默退出群聊。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_d6bcfa4251464eaa86f97dd82ce36f64@46958_oswg248251oswg967oswg535_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>开放权重：https://huggingface.co/microsoft/GRIN-MoE&nbsp;</p>
  <p>demo：https://github.com/microsoft/GRIN-MoE</p>
  <h2><strong>MoE全新训练路径</strong></h2>
  <p>GRIN MoE由常规的Transformer块构成，采用分组查询注意力（GQA）和滑动窗口注意力来提高计算效率。&nbsp;</p>
  <p>采用RoPE进行位置编码，以便在预训练后实现长上下文能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_57d4954ca9424e1799e06342bc5b9383@46958_oswg96383oswg429oswg737_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>在MoE架构中，模型通过路由网络为每个输入token挑选适合的专家模块。对于有n个专家的网络，一个用于推理的MoE模块的输出为：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_5bfd836fb8864dd08e71fdde007660a3@46958_oswg9806oswg571oswg81_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其中z = Router（x，r），本文中Router采用线性网络，Gating是门控函数（通常为softmax），Expert是FNN层。</p>
  <p>MoE通过TopK函数进行专家分配，这个专家路由的过程是不可微的，所以反向传播的时候没法求导。</p>
  <p>对此，传统的MoE训练将TopK视为常数，仅通过Gating来反向传播计算路由权重梯度，相当于用门控的梯度代替了路由的梯度。</p>
  <p>这多少有点糙。</p>
  <h3><strong>不可导怎么办</strong></h3>
  <p>恰好，本文一作之前有一篇工作（SparseMixer）：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_22b593023e584a8fa88363c1fbdc5df6@46958_oswg63783oswg1021oswg327_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>论文地址：https://arxiv.org/pdf/2310.00811</p>
  <p>受到直通梯度估计器的启发，作者扩展了前作，提出了SparseMixer-v2。</p>
  <p>作者首先将TopK函数替换为模型训练中离散变量的随机采样，然后应用heun’s third order method来近似专家路由梯度，并构建一个改进的反向传播，为专家路由给出数学上合理的梯度估计。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_aeeb438b3a5d497981903b51f1e2544a@46958_oswg244631oswg913oswg533_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>前作中，SparseMixer的有效性在神经机器翻译任务和ELECTRA语言模型训练中得到了证明。</p>
  <p>而在GRIN MoE的开发过程中，SparseMixer-v2终于有机会大规模应用于自回归语言模型训练。</p>
  <p>作者用2.5T token训练了两个16×0.9B MoE。其中一个遵循GRIN MoE中使用的相同方案，另一个用传统的GShard方法替换 SparseMixer-v2。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_0a9d5a906df849b3866ce8ae4892101c@46958_oswg63253oswg865oswg473_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>如上图所示，将SparseMixer-v2的性能提升推广到16×0.9B尺度的自回归语言模型训练。</p>
  <p>在前0.5T token上GShard表现更好，但SparseMixer-v2在训练后期取得了更强的性能。</p>
  <h3><strong>专家模型不要专家并行</strong></h3>
  <p>传统的MoE训练采用专家并行，简单理解就是把不同的专家分配到不同的显卡上。</p>
  <p>一个明显的问题是负载不均衡，有的专家会分到更多的token，有的专家却很闲。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_2d4d85ea701c4245889f970a7ec140c8@46958_oswg164174oswg973oswg403_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>之前的做法是设定一个阈值，比如1000个token分给4个专家，每人应该是250，这时候每张卡就最多只算250个token，超过后直接丢弃（送到下一层）。</p>
  <p>而在本文中，作者利用数据并行、pipeline并行和张量并行来训练GRIN MoE。</p>
  <p>此外，对于没有专家并行性的MoE计算，作者发现Megablocks包非常有用，它的grouped_GEMM内核和包装器的性能更好。</p>
  <p>应用这些新的工程化方法避免了专家并行，也就不用丢弃token了。</p>
  <p>最终，与具有相同激活参数的密集模型相比，本文的方法实现了超过80%的训练效率提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_2e55868ddf90445285b0a6ac5417034d@46958_oswg87322oswg1080oswg226_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>上表中，作者将两种不同大小的MoE模型与具有相同激活参数量的密集模型进行了比较，使用相同的硬件测量了它们的训练吞吐量。</p>
  <p>尽管MoE总的参数量是密集模型的六倍多，但在实验中达到了超过80%的相对吞吐量，证实了使用GRIN MoE方法的模型具有显著的计算扩展潜力。</p>
  <p>（PS：密集模型的吞吐量是在与MoE模型相同的并行度设置下测量的，这里的比较是为了研究密集激活网络（非MoE）和稀疏激活网络（MoE）的GPU内核效率）</p>
  <p>此外，在扩大模型大小时，密集模型和MoE模型显示出相似的减速模式，比如6.6B密集模型的训练吞吐量大约比1.6B密集模型的训练吞吐量慢4.19倍（后者的参数少4倍）。同样，42B MoE模型的训练吞吐量比10B MoE 模型的训练吞吐量慢约3.96倍（对应参数少4.2倍）。</p>
  <h2><strong>并行实验</strong></h2>
  <p>在只使用pipeline并行的情况下，通过在GPU之间进一步划分不同层，可以将最大专家数量从16个扩展到32个。但是，如果再增加专家数量，则会导致单个层的参数过多，一个GPU就放不下了。</p>
  <p>所以下一个维度采用张量并行。</p>
  <p>专家并行在前向和后向计算中有两个all-to-all通信开销，而张量并行在前向和后向计算中有两个all-reduce通信开销。</p>
  <p>相比之下all-reduce操作的延迟更高一点，但可以通过精心排布前向和反向的计算来overlap掉一部分开销。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_5e8cfc0235344640a25fc0b00413d042@46958_oswg139417oswg1080oswg580_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>如上图所示，通过结合pipeline并行和张量并行，系统支持的最大专家数量扩展到52个（总共132B参数）。</p>
  <p>这个数量是因为实验只用了64个GPU，最多能将模型划分为64个阶段，如果有更多的GPU，那么还能继续向上扩展。</p>
  <p>不过作者也表示，使用更复杂的并行通常会导致计算吞吐量降低。</p>
  <h2><strong>负载均衡</strong></h2>
  <p>如前所述，本文没有采用专家并行，但是负载不均衡的事实依然存在。</p>
  <p>作者在这里通过调整负载均衡损失来调节全局的负载均衡。常见的负载均衡损失定义为：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_7c0743d409f84cf6846c062ba1db0640@46958_oswg7049oswg377oswg89_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>其中α是超参数，n是专家数量，fi是调度给专家的token比例。</p>
  <p>传统方法在本地不同的GPU上计算fi，因此负载均衡损失将调节本地专家负载均衡并缓解token丢弃。</p>
  <p>在本文中，作者通过计算全局的fi（比如数据并行过程中组内的all-reduce）来修改负载均衡损失，调节专家负载以达到全局平衡。</p>
  <p>尽管这种调整会产生额外的通信开销，但类似于张量并行，这些通信也可以与计算overlap，从而在很大程度上减少额外的延迟。</p>
  <p>最后，放一个测试结果来show一下GRIN MoE的数学推理能力：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_5904356359b041d897ccbed3f0481383@46958_oswg47750oswg1079oswg581_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <blockquote>
   <p>作者注：我们对新发布的GAOKAO（即全国普通大学和学院入学统一考试）的数学问题进行案例研究，这是中国一年一度的全国本科入学考试。</p>
   <p>该考试以其严格的安全协议而闻名，是评估AI模型回答数学问题的能力的理想测试平台。请注意，GRIN MoE的训练于太平洋标准时间6月3日结束，2024年GAOKAO于中国标准时间6月7日开始。</p>
  </blockquote>
  <p>参考资料：&nbsp;</p>
  <p>https://venturebeat.com/ai/microsofts-grin-moe-ai-model-takes-on-coding-and-math-beating-competitors-in-key-benchmarks/&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/pt-AlH_z4e3PNiKC9Iyz7A" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：alan&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3014413166372354</id>
            <title>700亿低空独角兽破产，腾讯40亿投资打水漂了</title>
            <link>https://www.36kr.com/p/3014413166372354</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3014413166372354</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 06:59:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 飞行汽车, Lilium, 破产, 低空经济  
<br><br>  
总结: Lilium公司作为飞行汽车行业的领头羊，因无法筹集到足够资金而宣布破产，令人震惊。尽管其在技术上取得了一定突破，但缺乏政府支持和持续亏损使其面临困境。Lilium的破产反映了低空经济行业的挑战，尤其是在融资和技术创新方面。与Lilium形成对比的是，其他低空经济企业如Joby获得了强有力的资金支持。文章指出，低空经济仍需大量资金投入，且商业化进程缓慢，行业参与者需吸取教训，注重技术与商业化的结合。 </div>
                        <hr>
                    
                    <p>一家200亿的独角兽，破产了。</p>
  <p>作为未来交通领域的先驱，飞行汽车一直承载着公众对未来出行方式的无限遐想。然而，现实中的进展并不总是如人所愿。在这一领域中，曾经被看作是行业领头羊的Lilium公司，最近遭遇了重大挫折。</p>
  <p>最近，这家被誉为飞行汽车行业的“特斯拉”的公司宣布，由于无法筹集到足够的资金维持运营，已经向德国拜仁州的法院提交了破产申请。</p>
  <p>令人意外的是，就在宣布破产的前几天，Lilium还对外宣称实现了一项重大突破：成功启动了全电动的Lilium Jet原型机。这一破产消息的传出，迅速在国际科技界引起了广泛关注。毕竟，这是一家有着九年历史、众多知名投资者支持、累计融资超过百亿人民币的行业巨头，其突然的崩溃无疑令人感到惊讶和遗憾。</p>
  <p>自成立以来，Lilium已经筹集了约14.5亿美元（约合103亿元人民币）的资金，其中腾讯是其主要的投资方之一。在Lilium过去的十多轮融资中，腾讯参与了至少七轮，并且在由腾讯领投的三轮融资中，为Lilium筹集了约5.7亿美元（约合40亿元人民币）。</p>
  <p>2020年，Lilium通过SPAC方式成功上市，市值一度高达100亿美元（约合713亿元人民币）。然而，随着破产的宣布，其股价暴跌超过60%，市值缩水至不足1亿美元，这一转变令人唏嘘不已。</p>
  <h2><strong>9年的超级独角兽宣告破产</strong></h2>
  <p>自2015年成立以来，Lilium在低空经济领域尚未形成热潮之时，便已经开始布局。</p>
  <p>凭借其创新的“故事”和“概念”，Lilium迅速吸引了资本市场的目光，并成功获得了欧洲知名投资机构Freigeist Capital的首轮种子资金。紧接着，在次年，Lilium又迅速完成了1070万美元的A轮融资。这两轮融资为Lilium的技术发展提供了坚实的资金基础。2017年4月，Lilium宣布其飞行器原型Lilium Jet成功完成了首次测试飞行。</p>
  <p>随着低空经济概念的全面爆发，资本纷纷涌入这一领域，而作为行业的先行者和领导者，Lilium自然也获得了更多的资金支持。</p>
  <p>同年9月，Lilium完成了9000万美元的B轮融资，该轮融资由腾讯领投。据悉，腾讯至少参与了Lilium的7轮融资，其中至少3轮是由腾讯领投，总投资额高达约5.7亿美元（约40亿元人民币）。</p>
  <p>资金的注入使得Lilium的产品得以提前问世。2019年，Lilium宣布成功制造并试飞了世界上第一架全电动喷气式五座飞机原型机。同年，Lilium又完成了超过2.4亿美元的融资，估值达到10亿美元，正式迈入独角兽企业的行列。</p>
  <p>Lilium的融资步伐并未就此停止。2021年，Lilium通过反向收购在纳斯达克成功上市，估值达到33亿美元（投资人累计提供14.5亿美元），成为继亿航和Joby之后第三家在美国上市的电动航空企业，也被誉为“飞行汽车领域的一股”。</p>
  <p>尽管获得了如此多的投资，Lilium的创始人Daniel却似乎陷入了贾跃亭式的困境，一直表示存在许多“挑战”，需要更多资金来克服。因此，在2022年和2023年，Lilium又分别获得了1.19亿美元和2.92亿美元的融资。</p>
  <p>时间一年年过去，资金一轮轮投入，但Daniel仍然声称，只要再有一些资金支持，就能在2024年下半年实现首次载人飞行的目标。然而，资本市场的耐心是有限的，已经没有机构愿意相信Daniel Wiegand所描绘的宏伟蓝图。</p>
  <p>今年，Lilium试图从德国复兴信贷银行获得约1亿欧元的贷款，但由于德国联邦政府拒绝提供担保，这一努力宣告失败。随后，Lilium表示其子公司将根据德国法律申请破产。子公司的破产申请可能会导致Lilium最终从纳斯达克全球精选市场退市，或被停牌。</p>
  <p>实际上，Lilium的困境在之前公布的中期财报中已有迹象。</p>
  <p>今年上半年，Lilium的研发费用、一般和管理费用以及销售费用分别为1.31亿欧元（约10亿元人民币），0.49亿欧元（约3.8亿元人民币），以及0.06亿欧元（约0.48亿元人民币），与去年同期相比分别增长了55%，22.7%以及49%。由于缺乏商业化成果，Lilium没有收入，主要依靠股东融资和贷款来维持运营。因此，Lilium整体亏损，今年上半年净亏损了8694.9万欧元（约6.7亿元人民币），上市后累计亏损近20亿欧元（约153亿元人民币），融资所得的现金几乎已经耗尽。</p>
  <p>今年上半年，Lilium的经营活动现金流减少了1.59亿欧元（约12.2亿元人民币），而投资和融资活动产生的现金流分别增加了0.81亿欧元（约6.2亿元人民币）和1.05亿欧元（约6.24亿元人民币）。</p>
  <p>截至今年上半年末，Lilium的现金及现金等价物仅剩下1.09亿欧元（约8.4亿元人民币），现金储备已经到了危险的边缘。</p>
  <p>公司高层透露，Lilium的未来运营能力在很大程度上取决于能否成功获得政府的可转换贷款支持。自公司成立以来，Lilium一直面临着持续的亏损和负的运营现金流，且预计这种状况在未来一段时间内仍将持续。</p>
  <p>基于当前的融资策略，Lilium迫切需要额外的资金注入以保持业务的连续性。然而，如果德国联邦政府未能及时批准政府可转换贷款的担保，公司管理层可能不得不采取极端措施，包括大幅度削减成本、缩减业务规模，甚至可能面临破产的风险。遗憾的是，这种最不希望看到的情况已经成为现实。由于联邦政府的拒绝担保，原本有望成为公司“生命线”的1亿欧元贷款未能到位。</p>
  <p>在10月24日的公告中，Lilium指出，公司目前所面临的困境，主要归咎于缺乏政府层面的有力支持。与此同时，其竞争对手在包括美国、法国、中国、巴西和英国在内的多个国家都获得了资助和贷款，而德国的Volocopter和Lilium却未能享受到同等的政府支持。</p>
  <p>对于创始人Daniel Wiegand而言，他所有的感慨最终凝聚为一句话：如果能够重新选择，他不会选择在德国创业。</p>
  <h2><strong>对低空经济行业敲响警钟</strong></h2>
  <p>低空经济，这个概念指的是在1000米以下空域内，依托各类载人或无人航空器进行的低空飞行及相关服务和技术所构成的经济体系。</p>
  <p>这一体系涵盖了无人机、直升机、电动垂直起降飞行器（eVTOL，即飞行汽车）、热气球等多种航空器，并在物流、农业、环保、城市建设、影视制作、应急救援等多个领域有着广泛的应用。比如，一场使用无人机进行的航拍婚礼、无人机配送的外卖、或是无人机在农林植保中的低空作业，都是低空经济的生动实例。</p>
  <p>尽管目前对于低空经济还没有一个统一的定义，但可以肯定的是，这一领域距离实现大规模商业化还有很长的路要走。至今还没有哪个国家能够完全实现这一目标，整个行业目前正处于技术不断革新和升级的阶段。简而言之，整个产业目前还处在一个需要大量资金投入的阶段，这对参与者的融资能力是一个巨大的考验。</p>
  <p>Lilium的失败，对于低空经济领域的参与者来说，无疑是一个警钟。</p>
  <p>中国低空经济联盟的执行理事长罗军曾指出，eVTOL的发展需要强大的技术支持和时间的积累，尤其是需要获得民航部门的全面认证，并且还要经受市场的考验。</p>
  <p>Lilium的破产，外部原因是没有得到足够的当地支持，内部原因则是技术方面的不足。例如，Lilium使用的小型管道风扇在提供升力和推力时，能源效率较低，所需的功率大约是使用较大倾斜转子的类似设计重量的两倍。简而言之，就是在起飞和降落阶段，飞行器会消耗大量能源，严重影响电池的续航能力，续航里程和测试时间也都相对有限。2020年，Lilium的一架原型机在维修时起火，最终无法修复，飞行测试因此推迟，且至今未公布起火原因。至今未能完成载人飞行测试，也是一个问题。</p>
  <p>然而，与Lilium的破产形成鲜明对比的是，低空经济领域的其他企业却呈现出不同的融资状态。</p>
  <p>以空中出租车公司Joby为例，尽管同样面临巨额亏损，其在2024年上半年的运营亏损高达2.9亿美元，净亏损为2.18亿美元，而上年同期的净亏损为4亿美元。与Lilium不同的是，Joby得到了强有力的支持。不久前，丰田汽车和Joby宣布，丰田将额外投资5亿美元以支持Joby电动空中出租车的认证和商业生产，以实现两家公司的空中交通愿景。</p>
  <p>在国内，今年6月，吉利旗下的沃飞长空宣布完成了数亿元的B轮融资，由策源资本领投，中科创星、华控资本等原股东继续追投，创下了近两年国内eVTOL行业单笔融资的最高纪录。8月，电池巨头宁德时代也投资了峰飞航空数亿美元，计划共同研发eVTOL航空电池。</p>
  <p>在过去五年中，全国低空经济产业企业共获得了728次创投融资，公开融资金额的事件占比达到了35.58%。</p>
  <p>破产的破产，融资的融资。“冰火两重天”的低空经济正让玩家们意识到，这似乎不仅仅是一个有钱就能玩的游戏。</p>
  <p>诚然，站在风口下，猪都能起飞。但是，“猪”也有飞到一半重重摔下的可能。</p>
  <h2><strong>国家队支持低空经济发展</strong></h2>
  <p>当前的低空经济领域与当年的新能源汽车产业颇为相似，两者都是需要巨额资金投入且盈利模式尚不明确的行业。</p>
  <p>回顾过去，国内的新能源汽车制造商蔚来在2019年遭遇了严重的财务危机，一度濒临崩溃，甚至有媒体将蔚来创始人李斌评为“2019年最不幸的人”。</p>
  <p>据早期报道，2020年初，蔚来汽车因融资困难，股价在美股市场一度跌至1美元的退市警戒线，公司面临严峻的生存挑战。</p>
  <p>幸运的是，合肥市及时对蔚来进行救助，由多家合肥市国有企业组成的战略投资者团队向蔚来中国注资112.6亿元人民币，换取了蔚来中国24.1%的股份。得益于合肥市的资本注入，蔚来随后实现了业绩和股价的强劲反弹。</p>
  <p>相比之下，Lilium似乎就是那个没有得到类似合肥式救援的蔚来。</p>
  <p>在10月24日的公告中，Lilium指出，公司目前困境的主要原因是“缺乏政府的有力支持”。</p>
  <p>与Lilium的处境不同，随着国内对低空空域管理政策的逐渐放宽，以及产业链的日趋成熟，国内的企业获得了更广阔的发展空间。</p>
  <p>2024年的《政府工作报告》将低空经济定位为经济增长的新动力，为低空经济的发展注入了信心。因此，2024年被视为低空经济的起步之年。在这一年中，政策的频繁出台、各类低空飞行器的接连发布以及多地航线的开通，使得低空领域呈现出一派繁荣景象。</p>
  <p>在政策的推动下，低空经济已成为投资者眼中的热门赛道。其中，响应政策号召的地方政府引导基金成为这一赛道中最活跃的投资力量。</p>
  <p>截至目前，安徽、广州、武汉、北京等多个省市已经启动了低空经济产业基金的设立，基金规模从10亿元到200亿元不等，贵阳、武汉和苏州等地更是以基金集群的方式设立了低空经济产业基金。</p>
  <p>以广州为例，据调查，目前该市开发区、黄埔区已聚集了50多家涉及低空经济的企业，覆盖了产业链的各个环节，包括研发设计、原材料、零部件制造、集成、应用与服务等，年产值/营收规模约为130亿元。此外，广州还率先推出了“低空10条”产业扶持政策，发布了低空经济应用场景的典型案例和应用场景清单。</p>
  <p>处在投资圈的人都明白，国资LP的出资无疑就是风向标。</p>
  <p>在国资大举押注低空经济赛道的前提下，已经有大批投资人也开始将目光放到了该赛道内。今年以来，组团看低空经济项目的投资人越来越多，过去专注于医疗、消费、半导体等其他赛道的投资人也将目光转移到了低空经济上。</p>
  <p>受此影响，今年以来低空经济的融资事件显著增长，在2024年前6月，国内低空经济领域已发生融资事件26起，其中超70%投融资项目投向无人机企业，包括无人机整机、系统及零部件制造商各个环节。</p>
  <p>沃兰特航空、小鹏汇天、沃飞长空、峰飞航空、星逻智能、鸿鹏航空、特金智能、时的科技、卓翼智能等多家企业都是在今年收到融资的低空经济企业。</p>
  <p>另外，今年沃兰特的A++++轮融资由北京机器人产业基金领投，京国瑞基金、首程资本、燕创集团参与投资。零重力飞机公司在今年完成的近亿元A轮融资中，合肥高新区国有创投机构合肥高投作为领投方，科大硅谷引导基金、国华投资、蕴盛资本、紫峰资本跟投。这些案例都是由政府产业投资基金、政府引导基金的主导的低空经济投资事件。有专业投资人表示，低空经济强调的是整个低空空域开发和利用所带来的综合经济效益，目前对领域内创业企业来说是难得的机遇，在国家政策的支持下，这一领域正成为热点风口，其应用场景广泛，市场潜力大，技术创新不断等等优点，未来仍将具有光明前景。</p>
  <p>总而言之，对于国内外低空经济玩家们而言，都应该吸取Lilium破产的经验教训，更加注重技术创新与商业化落地的结合。一家公司的倒下，或许充满了无奈，但也为后来者提供了宝贵经验。中国的eVTOL要想飞得更远，那在起飞时就要保持冷静。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/yFodSfNFGNTExHUvf5z16A" rel="noopener noreferrer nofollow" target="_blank">“融中财经”</a>，作者：王涛，编辑：吾人，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3031427336529414</id>
            <title>谷歌苹果曝出LLM惊人内幕，自主识别错误却装糊涂，AI幻觉背后藏着更大秘密</title>
            <link>https://www.36kr.com/p/3031427336529414</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3031427336529414</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 03:48:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 幻觉, 错误检测, 真实性编码  
<br><br>  
总结: 研究发现，大模型（LLM）内部编码了比其输出更多的正确答案，但仍会生成错误内容，这种现象被称为“幻觉”。研究团队通过分析特定的token，揭示了大模型内部表征与外部行为之间的差异，并指出内部表征可以预测模型可能犯的错误类型。尽管现有的错误检测方法主要集中在最后生成的token，但研究表明，精确答案token的选择能显著提高错误检测的性能。最终，研究结果为未来设计更好的幻觉检测系统提供了基础，但也指出了技术的局限性，尤其是在对开源模型的适用性方面。 </div>
                        <hr>
                    
                    <blockquote>
   <p>大模型幻觉，究竟是怎么来的？谷歌、苹果等机构研究人员发现，大模型知道的远比表现的要多。它们能够在内部编码正确答案，却依旧输出了错误内容。</p>
  </blockquote>
  <p>到现在为止，我们仍旧对大模型「幻觉」如何、为何产生，知之甚少。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_bc4debe96faf4f6a8ff1b6970fd61187@1743780481_oswg926221oswg906oswg1186_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>最近，来自Technion、谷歌和苹果的研究人员发现，LLM「真实性」的信息集中在特定的token，而且并得均匀分布。</p>
  <p>正如论文标题所示，「LLM知道的往往要比表现出来的更多」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_591e911579304186bd3754b6d86c4d1c@1743780481_oswg40682oswg1080oswg273_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文地址：https://arxiv.org/pdf/2410.02707</p>
  <p>不仅如此，他们还发现，内部表征可以用来预测LLM可能会犯错的错误类型。</p>
  <p>它的优势在于，未来有助于开发出针对性的解决方案。</p>
  <p>最后，研究团队还解释了，大模型内部编码和外部行为之间存在的差异：</p>
  <blockquote>
   <p>它们可能在内部编码了正确答案，却持续生成错误答案。</p>
  </blockquote>
  <h2><strong>幻觉，如何定义？</strong></h2>
  <p>事实错误、偏见，以及推理失误，这些统称为「幻觉」。</p>
  <p>以往，大多数关于幻觉的研究，都集中在分析大模型的外部行为，并检查用户如何感知这些错误。</p>
  <p>然而，这些方法对模型本身如何编码、处理错误提供了有限的见解。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_b6fc9efc00ec4bf7920508679d5fbf7e@1743780481_oswg340327oswg640oswg479_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>近期另有一些研究表明，LLM内部状态其实「知道」那些输出可能是错误的，而且这种「知识」被编码在模型内部状态中。</p>
  <p>这一发现可以帮助提高错误检测的性能，并进一步缓解这些问题。</p>
  <p>不过其中一个缺陷是，这些研究主要集中了检验模型生成最后一个token、或提示符中最后一个token。</p>
  <p>由于LLM通常会生成长篇的相应，因此这一做法可能会错过关键细节。</p>
  <p>在最新研究中，研究团队采取了不同的方法：</p>
  <blockquote>
   <p>不只是看最终的输出，而是分析「确切的答案token」，如若修改，将会改变答案的正确性的相应token。</p>
  </blockquote>
  <p>最终证明了，LLM内部表征所包含的真实性信息，比以往要多得多。</p>
  <p>但这种错误检测器难以在不同数据集之间泛化，这说明真实性编码并非统一的，而是多方面的。</p>
  <h2><strong>更好的错误检测</strong></h2>
  <p>给定一个大模型M，输入提示p、模型生成的响应ŷ，任务预测ŷ是正确还是错误的。</p>
  <p>假设可以访问LLM内部状态（即白盒设置），但不能访问任何外部资源（如搜索引擎或其他LLM）。</p>
  <p>数据集使用的是</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_53d3a1ad5a844048b7b04db9a55ea6f3@1743780481_oswg8100oswg600oswg116_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>，包含N个问题-标签对，</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_1e363ed5e8894268a6354b9e05873ac2@1743780481_oswg3320oswg206oswg110_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>代表着一系列问题，</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_84f76a412fec42ddadf6f2e95eccb0a5@1743780481_oswg6011oswg378oswg146_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>代表着对应的真实答案。</p>
  <p>对于每个问题q_i，作者让模型M生成响应y_i，得到预测答案集</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_7a861048d975406bb56d711061586900@1743780481_oswg5848oswg354oswg128_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>。</p>
  <p>接下来， 研究人员构建了错误检测数据集，通过将每个生成的响应ŷ_i与真实标签y_i比较，以评估其正确性。</p>
  <p>比较结果会产生出一个正确的标签z_i ∈ {0, 1}（1表示正确，0表示错误）。</p>
  <p>这种比较可以通过自动启发式方法，在指令型LLM的协助下完成。</p>
  <p>最终的错误检测数据集为</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_40ddfce158254eb6903374b649535307@1743780481_oswg11798oswg736oswg158_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>。其排除了LLM拒绝回答的情况，因为这些可以轻易地被分类为错误。</p>
  <p>接下来，研究人员在Mistral 7B和Llama 2模型的四个变体上进行了实验。</p>
  <p>这些模型跨越了十个数据集，涵盖了各种任务。</p>
  <p>其中包括问答、自然语言推理、数学问题解决、情感分析。</p>
  <p>他们允许模型生成不受限制的响应，来模拟真实世界的使用情况。</p>
  <p>这里，一共用到了三种错误检测方法：Aggregated probabilities / logits、P(True)、Probing。</p>
  <h3><strong>精确答案token</strong></h3>
  <p>现有的方法经常忽略一个关键的细微差别：用于错误检测的token选择，通常关注最后生成的token或取平均值。</p>
  <p>然而，由于大模型通常会生成长篇回复，这种做法可能会错过关键细节。</p>
  <p>还有一些方法使用提示最后的一个token，但本质上是不正确的，因为大模型的单向性，未能考虑生成响应和丢失的情况，其中同一模型的不同采样答案在不同情况下，有所不同正确性。</p>
  <p>对此，研究人员检查了以往未经检查的token位置：确切的答案token，代表生成响应中最有意义的部分。</p>
  <p>他们将精确答案token定义为那些修改会改变答案的正确性token，而忽略了后续生成的内容。</p>
  <p>如下图图1，说明了不同的token位置。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_3e952ab5a2854436b4d0cc5a13cf5f16@1743780481_oswg178558oswg1080oswg495_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h3><strong>实验结果</strong></h3>
  <p><strong>真实性编码模式</strong></p>
  <p>研究人员首先专注于探索分类器，以了解LLM的内部表征。</p>
  <p>具体来说，广泛分析了层和token选择对这些分类器激活提取的影响。这是通过系统地探测模型的所有层来完成的，从最后一个问题token开始，一直到最终生成的token。</p>
  <p>下图2显示了Mistral-7b-Instruct各个层和token中经过训练的探测器的AUC指标。</p>
  <p>虽然，某些数据似乎更容易进行错误预测，但所有数据集都表现出一致的真实性编码模式。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_e215be1eb0134b15a0534c18a2dc3d57@1743780481_oswg165371oswg1080oswg518_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>对于token来说，提示后立即出现了强烈的真实性信号，表明这种表征编码了有关模型正确回答问题的一般能力的信息。</p>
  <p>对着文本生成的进行，该信号会减弱，但在确切的答案token处，再次达到峰值。</p>
  <p>再生成过程即将结束时，信号强度再次上升，表明了该表征编码了整个生成过程的特征，尽管它仍弱于确切答案token。</p>
  <p><strong>错误检测结果</strong></p>
  <p>接下来，研究人员通过比较使用、不使用精确答案token的性能，来评估各种错误检测方法。</p>
  <p>表1比较了三个代表性数据集的AUC。</p>
  <p>在这里，他们展示了最后一个精确答案token的结果，它的性能优于第一个精确答案token及其前面的token，而最后一个精确答案token之后的token性能类似。</p>
  <p>合并精确答案token，有助于改进几乎所有数据集中的不同错误检测方法。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_71aed9a009c340e79408a46483c80445@1743780481_oswg106763oswg1080oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>任务之间的泛化</strong></h2>
  <p>以上，探测分类器在检测错误方面有效性，表明了大模型对其输出的真实性进行了编码。</p>
  <p>但目前仍不清楚的是，它们跨任务的通用性。</p>
  <p>然而，理解这一点对于实际应用至关重要，因为错误检测器可能会遇到与训练时完全不同的示例。</p>
  <p>因此，研究人员探讨在一个数据集上训练的探测器，是否可以检测其他数据集的错误。</p>
  <p>如下图3显示了Mistral-7b-Instruct的泛化结果。在这种情况下，高于0.5的值表明泛化成功。</p>
  <p>乍一看，结果似乎与之前的研究一致：大多数热图值超过0.5，这意味着跨任务具有一定程度的泛化性。</p>
  <p>然而，再仔细检查，发现大部分性能可以通过基于logit的真实性检测来实现，该检测仅观察输出logits。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_770a0accd42c48afb23d323935c63247@1743780481_oswg315149oswg1080oswg611_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>图3b显示了从最强的基于Logit的基线（Logit-min-exact）中减去结果后的相同热图。</p>
  <p>这张 调整后的热图揭示了探测器的泛化能力很少超过单独检查 logits所能达到的效果。</p>
  <p>这意味着明显的概括并非源于真实性的普遍内部编码，而是反映了已经可以通过逻 辑等外部特征获取的信息。</p>
  <h2><strong>调查错误类型</strong></h2>
  <p>在确定了错误检测的局限性后，研究人员转向错误分析。</p>
  <p><strong>错误分类</strong></p>
  <p>图4说明了，三种代表性的错误类型。</p>
  <p>在其中一个（图4a）中，模型通常会给出正确的答案，但偶尔会出错，这意味着存在正确的信息，但采样可能会导致错误。</p>
  <p>在第二种类型中（图4b），模型经常做出错误的响应，尽管它能够提供正确的答案，这表明尽管不断犯同样的错误，但仍然保留了一些知识。</p>
  <p>在第三种类型中（图4c），模型生成了大多数答案都是错误的，反映出对任何生成的答案的信心较低。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_c8fe473f137c4e49ae1dfa4ec16e032d@1743780481_oswg195876oswg1080oswg415_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>研究人员通过记录每个示例的三个特定特征来对错误进行分类：（a）生成的不同答案的数量；(b) 正确答案的频率；(c) 最常见的错误答案的频率。</p>
  <p><strong>预测错误类型</strong></p>
  <p>表2列出了所有模型的测试集结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_b593949a7f914c5489d70e2578af23e8@1743780481_oswg65548oswg1080oswg325_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <h2><strong>检测正确答案</strong></h2>
  <p>最后，在确定模型编码各种与真实性相关的信息后，作者又研究了这种内部真实性，如何在响应生成过程中，与外部行为保持一致。</p>
  <p>为此，他们使用了探测器（5个经过错误检测训练），从针对同一问题生成的30个响应中，选择一个答案。</p>
  <p>然后，根据所选答案来衡量模型的准确性。</p>
  <p>Mistral-7b-instruct的结果如下图5所示，总体而言，使用探测器选择答案可以提高大模型在所有检查任务中的准确性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241111/v2_34775977a06a42f1ba76ceb0aa20a8b9@1743780481_oswg184148oswg1080oswg724_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p>
  <p>总之，这项研究的发现，可以帮助未来研究人员去设计更好的幻觉环节系统。</p>
  <p>遗憾的是，它使用的技术需要访问内部LLM表征，这也主要适用于开源模型的使用。</p>
  <h3>参考资料</h3>
  <p>https://venturebeat.com/ai/study-finds-llms-can-identify-their-own-mistakes/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/u_h6qwmHdXI74_9feKNeEw" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：桃子，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>