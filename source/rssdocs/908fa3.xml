<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/2558530806684804</id>
            <title>手机能跑，微软小模型击败Llama 2，96块A100 GPU训练14天，参数规模仅27亿</title>
            <link>https://www.36kr.com/p/2558530806684804</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2558530806684804</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 02:13:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, 小语言模型, 参数规模, 性能
<br>
<br>
总结: 微软发布了参数规模为27亿的小语言模型Phi-2，展示了先进的性能，超过了130亿参数规模的模型，并且可以在移动设备上运行。Phi-2的训练数据质量和规模化的知识转移是其性能优越的关键。在基准测试中，Phi-2击败了其他主流语言模型，包括Mistral、Llama 2和Gemini Nano 2。 </div>
                        <hr>
                    
                    <p>智东西12月13日报道，昨日晚间，微软又亮出了小模型大招！</p><p>微软发布了27亿参数规模的小语言模型Phi-2，经研究人员测试，<strong>Phi-2在参数规模小于130亿的模型中展示了最先进性能</strong>。</p><p>从性能表现看，Phi-2在Big Bench Hard（BBH）、常识推理、语言理解、数学和编码基准测试中，其<strong>平均性能得分已经超过70亿、130亿参数规模的Mistral和Llama 2，在部分基准测试中超过谷歌的Gemini Nano 2</strong>。</p><p>Phi-2还有一大优势是，因为参数规模足够小，其可以在<strong>笔记本电脑、手机</strong>等移动设备上运行。</p><p>过去几个月间，微软研究院的机器学习基础团队陆续发布了小型语言模型（SLM）Phi系列。</p><p>其中，第一个模型为13亿参数规模的Phi-1，官方博客称，Phi-1在SLM中的Python编码方面表现最好，在HumanEval和MBPP基准测试上尤甚。第二个模型为13亿参数规模的Phi-1.5，这个模型的重点为常识推理和语言理解能力。</p><p>现在微软发布的Phi-2能为研究人员探索机器可解释性、安全性改进或对各种任务的微调实验上提供帮助，目前，Phi-2已经从Azure AI Studio模型目录中开放给研究人员。</p><h2>01.96块A100 GPU训练14天，参数规模仅27亿</h2><p>一些大模型的参数规模达到数千亿的量级，使得其涌现出众多新兴能力，那么，是否可以通过改变训练策略等方式让更小的参数实现这些能力？微软的小型语言模型（SLM）系列或许是这一问题的答案。</p><p>Phi-2是一个基于Transformer架构的模型，具有下一个单词预测目标，在用于NLP和编码的合成数据集和Web数据集的混合上多次传递的1.4T tokens上进行训练。</p><p>Phi-2在<strong>96个A100 GPU上训练了14天</strong>，作为一个基础模型，其没有通过人类反馈强化学习（RLHF）进行对齐，也没有进行指令微调。</p><p>尽管如此，与经过调整的现有开源模型Llama 2-7B相比，研究人员观察到在避免生成有攻击性、有害和内容有偏差方面Phi-2的表现也不差。</p><p>研究人员根据ToxiGen的13个人口统计数据计算的安全评分，他们选择6541个句子的子集，并根据困惑度和句子“毒性”进行0到1之间的评分。分数高就说明，模型产生有攻击性、有害句子的可能性较小。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231213/v2_cbe62644e18d4237a7f5fc9004b29295@000000_oswg116945oswg1024oswg556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Llama 2与Phi-2在生成有攻击性、有害和内容有偏差方面性能比较（图源：微软官方博客）</p><p>微软使用Phi-2打破了传统语言模型缩放定律，其中有两个关键环节：</p><p><strong>第一是训练数据的质量对模型的性能至关重要</strong>。微软的模型训练数据包含专门创建的合成数据集，用于教授模型常识推理，还包括科学、心理等领域的常识。</p><p>研究人员还挑选了一些网络数据进一步扩充训练语料库，并基于内容的价值和质量进行了数据过滤。</p><p>此外，从13亿参数规模的Phi-1.5开始，微软的研究人员实现了<strong>规模化的知识转移</strong>，将Phi-1.5的知识嵌入到27亿参数的Phi-2中。这种方法不仅加速了训练收敛，而且提高了Phi-2的基准分数。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231213/v2_b6dbb2fe56a54fd3997a1a9295af9438@000000_oswg75787oswg1024oswg299_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Phi-2和Phi-1.5比较（图源：微软官方博客）</p><h2>02.基准测试击败Llama 2、Mistral、Gemini Nano 2</h2><p>微软总结了Phi-2在学术基准上与主流语言模型的性能表现对比。</p><p>其基准测试涵盖Big Bench Hard（BBH数据集）以及PIQA、WinoGrande、ARC easy、Challenge、SIQA的常识推理、HellaSwag、OpenBookQA、MMLU、SQuADv2的语言理解数据集，GSM8k数学数据集和HumanEval、MBPP的编码数据集等。</p><p><strong>27亿参数规模的Phi-2，在BBH、常识推理、语言理解、数学、编码各项基准测评上都超过了70亿、130亿参数规模的Mistral和Llama 2。</strong></p><p>相比于参数规模差距在25倍的700亿参数Llama 2，Phi-2在编码、数学等多步推理任务上表现更好。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231213/v2_41e37958d1394c8196bd98cbbf86d2e9@000000_oswg63499oswg1024oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Llama 2、Mistral、Phi-2性能比较（图源：微软官方博客）</p><p>此外，微软还比较了Phi-2与谷歌最近发布的Gemini Nano 2，谷歌发布的模型参数规模为32.5亿，<strong>Phi-2的性能表现部分优于Gemini Nano 2。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231213/v2_2a432bf0aa824cd2ac81057ba116d876@000000_oswg35609oswg1024oswg166_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Phi-2、Gemini Nano 2性能比较（图源：微软官方博客）</p><p>考虑到一些公共基准测试的数据可能会泄漏到训练数据中，微软对第一个模型Phi-1进行了广泛的净化研究以排除这种可能性。</p><p>基于判断语言模型的最佳方法是在具体用例上对其进行测试的考量，研究人员使用了多个微软内部专有数据集和任务评估了Phi-2，并再次将其与Mistral和Llama 2进行比较，其结果为，<strong>平均而言Phi 2优于Mistral-7B，后者优于70亿、130亿、730亿参数规模的Llama-2模型</strong>。</p><p>除了基准测试外，研究人员还测试了社区内的一些常用提示，他们观察到的表现也与基准测试的结果预期一致。</p><p>其中，研究人员测试了用于评估谷歌Gemini Ultra模型在解决物理问题方面能力的问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231213/v2_a18c0eb0705a43aeb5900bbcae3cb1fd@000000_oswg281563oswg1024oswg619_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与Gemini的测试类似，研究人员进一步向Phi-2询问学生的错误答案，来确认它是否能识别出错误所在。</p><p>不过，从输出结果来看，这并不完全是与Gemini报告中描述的Gemini Ultra输出的同类比较，Gemini测评中学生的答案上传了手写文本的图像，Phi-2的测试采用的是原始文本。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20231213/v2_2db6d1dbdeb3470998036f4cc24344a3@000000_oswg212730oswg1024oswg553_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>03.结语：大模型时代，小模型仍在崛起</h2><p>Phi-2的参数规模仅有27亿，但相比于参数规模更大的70亿、130亿模型，其性能表现仍不逊色。微软专注于小模型市场的布局，也印证了大模型时代小模型的价值。&nbsp;</p><p>微软与OpenAI的紧密合作，使得GPT模型的表现在大模型市场一骑绝尘，再加上微软参数规模更小的Phi系列，能进一步抢占开源模型长尾市场。不过从目前来看，Phi系列仅被允许用于研究目的。&nbsp;</p><p>从市场来看，越来越多的玩家开始探索在手机等移动设备上部署大模型，微软此举或许也会加速模型能力在端侧的应用。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652765796&amp;idx=1&amp;sn=ecf67ef205ba6076e789852f03856c8d&amp;chksm=85e7923be2eb2351272f307fab2fc1ff3ad01a12700fa4ae4a2fcc3d1a1a2c9fd6697c0e8e19&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：程茜，编辑：李水青，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>