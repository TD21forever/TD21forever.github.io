<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/2639431440367872</id>
            <title>芯片级拆机：35颗苹果Vision Pro芯片型号供应商首次解密，显微镜看索尼屏</title>
            <link>https://www.36kr.com/p/2639431440367872</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2639431440367872</guid>
            <pubDate></pubDate>
            <updated>Thu, 08 Feb 2024 09:20:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果Vision Pro核心35颗芯片型号、供应商, 索尼Miciro OLED显微镜, Vision Pro海量传感器, 华强北三方镜片
<br>
<br>
总结: 苹果Vision Pro是一款具有改变世界潜力的产品，通过苹果多年来严谨的深入布局和技术创新，集成了35颗核心芯片、索尼Miciro OLED显微镜和海量传感器。它的设计细节包括了供应商、像素排列和镜片等方面的创新，同时通过一个小妙招断了所有“华强北”三方镜片的后路。这款产品是苹果多个产品系列多年积累的结晶，具有高度的可修复性。 </div>
                        <hr>
                    
                    <p><strong>苹果Vision Pro核心35颗芯片型号、供应商首次曝光！</strong>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_276fd2c6765f4d55974bfe3738853ab8@000000_oswg68844oswg1080oswg508_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Vision Pro主板正面</p><p><strong>索尼Miciro OLED显微镜下的像素排列首次被看到，人体红细胞大小的像素原来长这样！</strong>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_f287869b84144b74a2007270e24bfd64@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Vision Pro海量传感器背后竟藏着苹果秘密布局多年的宏大野心！跟苹果所有产品几乎都相关。</strong>&nbsp;</p><p><strong>苹果如何通过一个小妙招断了所有“华强北”三方镜片的后路？</strong>&nbsp;</p><p>智东西2月8日报道，上周日专业机构iFixit的苹果Vision Pro全球首拆一时间引爆了整个科技圈，苹果藏的最深的N多细节，被全盘爆出（Vision Pro全球首拆，36小时火速出炉！N多细节曝光，苹果又一个工业奇迹）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_117c8f88c8d44de5a6d54f6031d19c06@000000_oswg61711oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Vision Pro首拆全家福</p><p>今天，iFixit再次放出了超深入的拆解第二弹，<strong>深入到“每一颗像素”，深入到每一颗芯片的型号、供应商，以及传感器、镜片、电池等部分的设计细节。</strong>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_731ad5abb0af4a34b68a2bdab41b5e08@000000_oswg39730oswg1080oswg437_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>iFixit这次的无死角深度拆解，极具产业价值。&nbsp;</p><p><strong>苹果到底是如何进行技术创新的，Vision Pro这个具有改变世界潜力的产品，究竟是如何通过苹果多年来严谨到令人吃惊、一环扣一环的深入布局最终实现的？</strong>&nbsp;</p><p>一切，都能找到答案了！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_f386c89458fb40d9a6fea5db20bf3fc5@000000_oswg600698oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>毫不夸张地说，<strong>苹果Vision Pro，是iPhone、Apple Watch、AirPods、iPad等一系列产品多年积累的结晶。</strong>&nbsp;</p><p>作为彩蛋，上次iFixit发了一个Vision Pro的X光360度全身照，这次Creative Electron直接搞出了一个360度CT扫描的动画，简直更加科幻和炫酷！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_d1e7a138ecbd4472bcb7169f396fe092@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从外壳到内部，抽丝剥茧，最终各种零部件在3D空间内以正确位置进行呈现，效果炸裂！或许Vision Pro的3D拼装模型很快就会有了，拼起来应该相当有挑战性。&nbsp;</p><p>哦对了，按照惯例，iFixit都会给拆完的产品来个“可修复性”评分，<strong>这次Vision Pro最终可修复性评分为4分，满分10分，你觉得这评分高了还是低了？</strong>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_cae5d9eadfd445e19298542d0a226f28@000000_oswg416835oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>话不多说，我们直接来看深入拆解。&nbsp;</p><h2><strong>1.Vision Pro芯片方案终极曝光！中国大陆兆易创新上榜</strong>&nbsp;</h2><p>在上次的拆解中，我们只是看到了主板长什么样，大概看到了R1芯片和M2芯片，而这次，iFixit给主板来了更清晰的大特写照，并深入分析了主板上的各类芯片和器件。&nbsp;</p><p>这里我们直接做了一张表格，方便大家查阅：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_e436b716b21e48bb8bb70bee26cec990@000000_oswg787629oswg961oswg1761_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>下面是文字版：</strong>&nbsp;</p><p><strong>1、主板正面芯片：</strong>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_4f53afe9d5fa4cbb9aae822ff92fcf43@000000_oswg58186oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>苹果M2芯片&nbsp;</p><p>美光8GB LPDDR5内存&nbsp;</p><p>苹果R1芯片&nbsp;</p><p>铠侠256GB闪存芯片&nbsp;</p><p>苹果电源管理芯片x4&nbsp;</p><p>德州仪器时钟缓冲器&nbsp;</p><p>ADI（Analog Devices）双通道同步降压转换器&nbsp;</p><p>德州仪器300毫安降压转换器&nbsp;</p><p>德州仪器可调式升压转换器&nbsp;</p><p>安森美（onsemi）电流限制开关&nbsp;</p><p>德州仪器150毫安/3.6伏LDO稳压器&nbsp;</p><p>USI蓝牙WiFi模组&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_ae746b9797324d139508979b909485c5@000000_oswg39701oswg1080oswg481_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>2、主板背面芯片：</strong>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_0ec1277fd3e741b2a459f46fb8df02bb@000000_oswg65250oswg1080oswg538_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ADI（Analog Devices）双二相步进电动机驱动器&nbsp;</p><p>莱迪思半导体（Lattice Semiconductor）iCE40 Ultra FPGA芯片&nbsp;</p><p>（可能）Cirrus Logic音频编解码芯片&nbsp;</p><p>Diodes Incorporated 2:1多路复用器/分路器&nbsp;</p><p>德州仪器四路SPDT模拟开关&nbsp;</p><p>德州仪器双路SPDT模拟开关&nbsp;</p><p>德州仪器4安降压转换器&nbsp;</p><p>德州仪器比较器W/集成reference&nbsp;</p><p>安森美（onsemi）电流限制开关&nbsp;</p><p><strong>3、电池主板芯片：</strong>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_c8f1b838b4594e809b5c8af51a6c95c5@000000_oswg68572oswg1080oswg636_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>意法半导体Arm Cortex-M4微控器&nbsp;</p><p>兆易创新1MB NOR闪存芯片&nbsp;</p><p>德州仪器USB-C控制器&nbsp;</p><p>德州仪器USB-C接口保护器&nbsp;</p><p>德州仪器6安同步降压转换器&nbsp;</p><p>德州仪器1安降压转换器&nbsp;</p><p>安森美（onsemi）电流限制开关&nbsp;</p><p>博世（Bosch Sensortec）加速度计&nbsp;</p><p>瑞萨电子升压式电池充电器&nbsp;</p><p>瑞萨电子双向升压稳压器&nbsp;</p><p>德州仪器温度传感器x2&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_4c62a9e0c7c841a08afb11a5683bb23a@000000_oswg82941oswg1080oswg786_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>4、扬声器主板：</strong>&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_d695c0106f314ed99d2a536c42ab6542@000000_oswg53370oswg1080oswg505_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>（可能）Cirrus Logic音频编解码芯片&nbsp;</p><p>德州仪器音频放大器&nbsp;</p><p>德州仪器4A降压转换器&nbsp;</p><p>可以看到，苹果在核心的芯片部分几乎全部采用美国供应商，另外有少量日本、欧洲供应商，从iFixit的拆解来看，仅有一家中国台湾供应商，日月光旗下的环旭电子，以及一家中国大陆供应商兆易创新，兆易创新仅参与了Vision Pro外接电池的部分闪存芯片供应，并未参与到头显产品主体芯片供应之中。&nbsp;</p><p>最核心的计算芯片均为苹果自研。&nbsp;</p><h2><strong>2.红细胞大小的像素到底长啥样？苹果这块屏幕里藏了N多秘密</strong></h2><p>上次拆解，我们只是看到了索尼这块据传2024年限量100万片、单片成本350美元、单片1150万像素的Micro OLED屏幕的外观长啥样，但总体上还是“黑乎乎”一片，看不到更多细节。&nbsp;</p><p>这次iFixit直接对这块屏幕进行了“像素级”深入研究。&nbsp;</p><p>用一句形象地描述来说：在一个iPhone 15 Pro Max的屏幕像素中，你可以直接塞入54个Vision Pro的像素！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_1456890a1d3445e0bcdb51dbd3fb2967@000000_oswg1204925oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>苹果Vision Pro屏幕单像素宽度仅有7.5微米，仅相当于一个红细胞的大小！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_33b0be4d816f481e8bc7de2465960c86@000000_oswg63695oswg1080oswg583_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Vision Pro单像素</p><p>说是“工业奇迹”真的不为过，因为iPhone 15 Pro Max这块三星AMOLED屏的像素密度已经达到了460 PPI。&nbsp;</p><p>为了深入研究这块屏幕，iFixit直接把光学模组、屏幕还有固定它们的框架结构进行了彻底分离式拆解。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_f3376b9ea40a4a0eacd68b3d372b730b@000000_oswg29403oswg1080oswg474_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，Vision Pro采用的的确是三片式Pancake光学方案，并且三个镜片是紧密贴合在一起的，与苹果在发布会上演示的一致。&nbsp;</p><p>此外，镜头模组中还放置了一个眼球追踪摄像头，这也是Vision Pro眼动追踪交互实现的关键，当然，镜头模组的最后一个重要组成部分就是索尼Micro OLED屏幕本身。&nbsp;</p><p>iFixit使用电子显微镜测量了红细胞大小的屏幕像素，同时屏幕实际发光部分的横向宽度约为27.5毫米，纵向高度约为24毫米，面积约为660平方毫米，1英寸的面积大约是645平方毫米，所以这块屏幕实际发光的区域略超过1英寸。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_307ec1896dee4c35bb25ac75477f111f@000000_oswg28424oswg1080oswg665_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来看每颗像素的结构，红色和绿色子像素纵向上下放置在一起，而蓝色子像素‍的长度大约是红色和绿色子像素的两倍，位于红绿子像素的边上。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_d7601577ac2c423ba5fb356b79601461@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲像素变化</p><p>不过根据显微镜画面，蓝色子像素呈“长条状”，红绿子像素呈“圆点状”，三者形态并不相同。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_fd58eb0ed38847f98dd74dd02b5d386f@000000_oswg37734oswg1080oswg560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲蓝色子像素</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_5119f8cca7d54952bb18f9aa3d46beea@000000_oswg61279oswg1080oswg587_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲红色绿色子像素</p><p>值得一提的是，iFixit实际拍摄的像素排列，与苹果在官方视频中曾经放出的屏幕像素排列方式完全一致。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_89412c3208d345caae82299ede6ca536@000000_oswg71049oswg1080oswg552_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲官方视频展示的像素排列</p><p>经过实际测量，屏幕发光区域总共有横向3660个像素、纵向3200个像素，这相当于把12078000个像素塞到0.98英寸的面积中。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_0d691e847c8c4347b034c2457a07097a@000000_oswg920324oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为什么是0.98英寸？实际上，这块屏幕并不是标准的长方形，而是四个角被“切掉”的不规则八边形！并且四个角并不是被对称切掉的，每个角被切掉的面积都不一样！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_2450a28c3f4444a4be85431b4692d835@000000_oswg79596oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>四个角被切掉的面积分别为6.95平方毫米、11.52平方毫米、9.9平方毫米和10.15平方毫米，被切掉的部分不发光，占660平方毫米总面积的5.3%，剩余发光部分的像素数为11437866个。&nbsp;</p><p>苹果官方宣称的像素数为单块屏幕1150万，与iFixit的实际测量值惊人的一致，其中差别更多是测量误差，毕竟，这可是在测量“细胞大小”的像素啊！&nbsp;</p><p>按照PPI的方式来计算，苹果Vision Pro实际测量的像素密度达到了惊人的3386 PPI，是iPhone 15 Pro Max的7.3倍！是12.9英寸iPad Pro的12.8倍！&nbsp;</p><p>与头显类产品相比，HTC Vive Pro的PPI约为950，不到Vision Pro的三分之一。Meta Quest 3的PPI约为1218，同样差距显著。&nbsp;</p><p>苹果Vision Pro在屏幕像素密度上可以说是“遥遥领先”了。&nbsp;</p><p>值得一提的是，标准4K UHD分辨率是3840*2160个像素点，也就是8294400个像素，苹果这块屏幕，像素数显然超过了标准4K分辨率，但横向像素数3660却小于3840，所以从技术标准上来讲，这并非是一块标准的“4K屏”，但确实是一块超高像素屏幕。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_e261dda0cccc4bed80ef13f82fbf3c63@000000_oswg102634oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以苹果也并没有简单地宣称Vision Pro采用了4K屏幕，而是准确告知了屏幕的像素数，苹果在说法上还是非常严谨的。&nbsp;</p><p>iFixit说，这是他们见过的像素密度最高的屏幕，没有之一。&nbsp;</p><p>你可以把54个Vision Pro的像素放入一个iPhone 15 Pro Max的像素中。&nbsp;</p><p>你还可以把2500个Vision Pro的像素放入一个65英寸4K电视的像素中。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_4ea731ca482c45a5abbda09493ae4bfb@000000_oswg924346oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>说到这里，有个关于像素的问题要先弄清楚。不论是2K、4K还是几K，这些分辨率对于人眼来说到底意味着什么？&nbsp;</p><p>比如手机屏是2K的，电视屏是4K的，但是电视机离近了你可以看到像素，手机却不会。&nbsp;</p><p>这里就要说到两种测量像素密度的方式了，一种是测量每英寸像素数，Pixels per inch，也就是我们常说的PPI，这种方式是在测量屏幕给定区域内的像素数，这是一种基于设备物理特性的“绝对值”测量。&nbsp;</p><p>第二种方式是每度像素数，Pixels per degree，PPD，也被称为“角分辨率”，这种测量方式更容易体现距离带来的影响，你的眼睛离屏幕越近，每一度中包含的像素就越少，你就越容易分辨出单个像素，屏幕就越容易观感“模糊”。&nbsp;</p><p>这就是为什么电影院里的大屏幕即使只有2K，你也会觉得比较清晰，因为你距离很远，眼睛看过去，每一度视角中包含的像素可能并不少。&nbsp;</p><p>所以说到这里，得出一个结论就是，高像素密度并不能保证高每度像素数，屏幕分辨率高，并不一定就会很清晰，跟你的观看距离密切相关。&nbsp;</p><p>一台4K大电视，PPI只有可怜的68，但是你看着依然很清晰，为啥？因为你坐在距离电视很远的地方看，这样所有像素就被缩到了一个很小的视角范围内，每度像素数就会很高。&nbsp;</p><p>在VR领域，工程师们通常喜欢用PPD来衡量屏幕的清晰度，也就是每个视角度中的水平方向像素数。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_9803e13dfbb4433c81a49859e3fe73ad@000000_oswg348718oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但在Vision Pro的实际PPD测量中，情况要复杂很多，主要是三方面：&nbsp;</p><p>第一，从屏幕边缘到中心，PPD是在变化的，并不是恒定的。&nbsp;</p><p>第二，镜片会导致画面扭曲畸变，影响PPD数值。&nbsp;</p><p>第三，立体视觉会影响人眼看到的像素数量，进而影响PPD计算。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_39da7a91d52f431ea58212de07ba5276@000000_oswg84663oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此，iFixit对于Vision Pro屏幕的PPD计算只是“粗略”测量，在100度的FOV（视场角）内，他们测量的PPD预估值为34。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_7a7cea8c3963438ab0773b39c58a8274@000000_oswg534331oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>相比之下，在2米左右（6.5英尺）的距离观看一个65英寸4K电视，PPD约为95，在30厘米（1英尺）的距离看一个iPhone 15 Pro Max，PPD约为94。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_01cc96f63ae844d6aeba57aca1aade7a@000000_oswg36266oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以结论就是，虽然Vision Pro有着“逆天”的屏幕像素密度，但实际观看中，由于屏幕距离眼睛非常近，因此它的每度像素数并不高。&nbsp;</p><p>所以这就带来一个问题，实际上，用Vision Pro替代高端显示器、电视是不现实的，比如用Vision Pro显示MacBook Pro的屏幕时，实际上虚拟屏幕只占用了Vision Pro可用像素的一小部分，剩下的像素都用来显示你周围的房间了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_7b38dd76e6654ba1b371a740ccf351b5@000000_oswg62605oswg1080oswg653_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>实际上这块悬在空中的虚拟屏幕的PPD是非常低的，iFixit的朋友Karl Guttag说，他这么用的时候，可以清晰地看到“单个像素”，这距离标准的“桌面显示体验”相去甚远。&nbsp;</p><p>所以当我们真正办公的时候，一块真正的4K或者5K屏幕带来的体验肯定要好的多。&nbsp;</p><p>这里iFixit还不忘皮一下，他们说，如果考虑便携性，即使算上200美元的专用背包，Vision Pro的重量也要比Apple Studio Display轻得多。&nbsp;</p><h2><strong>3.iPhone“同款”Face ID暗藏玄机苹果到底是怎么把传感器用出花来？</strong>&nbsp;</h2><p>除了强大的芯片、出色的屏幕和光学系统，Vision Pro的另一大优势就在于大量高素质传感器。&nbsp;</p><p>当然，苹果拼的并不是塞入传感器的数量，苹果的秘密武器在于：经过多年的经验分析、场景理解并融合了复杂传感器数据、进行了多次迭代的传感器设计。&nbsp;</p><p>苹果哪来的经验？苹果不是第一次做头显吗？是的，头显是第一次，传感器可是积累了四年！&nbsp;</p><p>还记得苹果在2020年将激光雷达首次加入iPhone 12 Pro和iPad Pro之中吗？苹果早就开始下一盘大棋了！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_1dde7db2525542598226f273fbcab563@000000_oswg45422oswg1018oswg1237_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲2020年iPad Pro加入激光雷达模组</p><p>激光雷达的加入，可以让设备在弱光环境下获得更好的拍照以及距离测量能力，在iFixit看来，苹果可能还有另外一个动机，iPad Pro的激光雷达传感器可以让苹果在一个极低风险的环境中测试AR功能。&nbsp;</p><p>iPad Pro已经大规模量产，苹果可以获得宝贵的专业知识和用户反馈。&nbsp;</p><p>回到Vision Pro，苹果在传感器领域经验积累的应用，最典型的就是Vision Pro正面的Face ID深度摄像头，这跟iPhone上的那一套原理是相同的，只是器件规格有所不同。&nbsp;</p><p>Vision Pro上的这套Face ID系统同样包括一个激光点阵投射器，将红外线点阵投射到你的脸上，同时另一个接收器负责接收，从而绘制一个你的3D人脸模型。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_1e41e3a1ecab46abb3dcf3683a679bc0@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲前置传感器在红外摄像机下的工作状态</p><p>当然，这套系统配合激光雷达，还可以很好的完成房间的空间测绘，而且完全不需要任何物理围栏设备。&nbsp;</p><p>这项功能其实在AirPods上苹果已经用过了，利用Face ID扫描你的耳朵，生成耳朵的模型，从而提供“定制化”的空间音频体验。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_b758a26f6d2249b1ae1185ab5ad4fec0@000000_oswg81816oswg991oswg1962_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>发现了吗，苹果做的一切，都是相互关联，成体系的！&nbsp;</p><p>苹果在传感器领域的另一项重要优势就是加速度计的应用和对应数据分析能力。&nbsp;</p><p>iPhone、Apple Watch的跌倒检测、HomePod的移动检测、HomePod的房间监听及音频校准功能、AirPods加速度计检测敲击指令……&nbsp;</p><p>所有这些功能的实现，都需要先进的传感器数据分析技术，而苹果在这一领域已经深耕了多年。&nbsp;</p><p>硬件并不是苹果最深的壁垒，如何将这些先进硬件用好，才是苹果最大的致胜法码。&nbsp;</p><p><strong>04</strong> <strong>.</strong>&nbsp;</p><p><strong>苹果用一招彻底绝了“山寨版”镜片的路</strong>&nbsp;</p><p>说完了最最核心的屏幕显示，我们来看看镜片。目前中国近视人群比例逐年提高，各类头显能否很好地照顾近视人群也是大家非常关心的，尤其是苹果Vision Pro不支持戴眼镜佩戴。&nbsp;</p><p>看起来，我们在用的时候就是简单把镜片“吸附”上去，但实际上，在装配之前，用户还需要进行“扫码配对”，没错，你没听错，每副镜片都有不同的配对代码。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_7eb295e1381a468382598c7e85396b13@000000_oswg45179oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为什么要这么做？因为每副镜片都有不同的度数，Vision Pro需要预先读取这些参数，从而进行相应的校准，让你获得正确的视觉体验。所以，如果你的镜片要借给朋友用，别忘了先让他扫码配对。&nbsp;</p><p>这也意味着，蔡司对镜片的供应有了“垄断地位”，任何“华强北版”可能都无法使用了，因为，你没有配对代码，“盗版镜片”无法让Vision Pro正确进行校准！&nbsp;</p><p>一个好消息是，Vision Pro可以支持各类近视镜片，甚至连散光都可以加进去，并且Vision Pro还支持老花镜片，包括双光镜和渐进多焦镜，不过棱镜矫正镜片并不支持。&nbsp;</p><p>简单总结就是，只要通过官方渠道，量身定做一副适合你的镜片是很容易的。&nbsp;</p><h2><strong>5.Vision Pro外接电池“缩水”？非也！苹果有意为之</strong>&nbsp;</h2><p>在上期拆解中，iFixit只展示了Vision Pro外接电池拆解后的样子，并没有说是如何拆解的，这次，真相大白，好家伙，他们直接上了锤子和凿子！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_4ae927418ee04f5787bb382122ead4df@000000_oswg32835oswg1080oswg456_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>简单来说就是贼难撬开，压根就没有缝隙，边缘还布满了胶，总结就是：苹果压根就不想让你拆开它！&nbsp;</p><p>电池内部大家都不陌生了，上次都已经见过，三块电池串联在一起，堆叠放置，每块电池的大小跟iPhone 15 Plus的电池大小差不多。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_b83a698ec43e40f3b6f35371dc0b07c8@000000_oswg483014oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一个小细节是，每块电池的电量为15.36瓦时，总电量按理说应为46.08瓦时，但实际电池外壳上写的额定电量为35.9瓦时（3166毫安时），实际电量为理论总量的80%。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_e8c37cd5e0084397b48169022f69b702@000000_oswg23416oswg1080oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>值得一提的是，此前苹果在iPhone 15 Pro上也发布了新的电池健康管理功能，用户可以将充电上限设置为80%，这有利于电池寿命的延长。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_898e5458cae54055b944dc57778c8def@000000_oswg81965oswg1080oswg556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此苹果对Vision Pro电池的操作，可能算是“未雨绸缪”了。&nbsp;</p><p>在这样一块电池里，苹果还放入了温度传感器和加速度计，只要你拿起电池，它就会显示剩余电量指示灯，你什么时候佩戴它也能检测到。&nbsp;</p><p>还有一个细节，这块电池为了满足Vision Pro的处理要求，可以输出非USB标准的13伏电压，这也是为什么苹果要定制“大号Lightning”接口的原因之一，这样你就不会不小心把这个接口插到别的设备里然后烧坏这些东西。&nbsp;</p><p>所以总体而言，对于这个电池的设计苹果是花了不少心思的，苹果很认真地思考了佩戴电池的风险，比如发热、重量、安全、寿命、更换便捷性等等。苹果没有尽可能地增大电池容量，而是更侧重易于更换，使用安全。&nbsp;</p><p>最后iFixit还搞了个小“彩蛋”，他们设计了一个“iFixit”版的Vision Pro外接电池包，体积大得多，续航是官方版本的两倍，不过这个只是个原型机，还没有开始售卖。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_6be065e47e824fdabeadd20ff44402fa@000000_oswg421199oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲iFixit自制Vision Pro外接电池包</p><h2><strong>6.可修复性：模块设计加分超难拆的外屏玻璃减分</strong></h2><p>在深入拆解的最后，iFixit再次提到了Vision Pro的“可修复性”。&nbsp;</p><p>在上周日Vision Pro全球首拆发布后，国内不少媒体都进行了拆机直播，在直播过程中，“翻车”成了家常便饭，一个外屏保护玻璃拆了20分钟“纹丝不动”也称为常态，有些拆机团队甚至不惜动用锤子将其击碎取下。&nbsp;</p><p>Vision Pro的“究极难拆”，已经是有目共睹。&nbsp;</p><p>不过iFixit上来还是先说了点好的，比如电池模块化的设计易于更换，头带的模块化设计同理，镜片的磁吸式设计也提高了更换的便捷性。&nbsp;</p><p>iFixit提到，好在光学元器件、显示屏和可移动的部件基本都在眼睛那一侧，不需要大开超级难拆的外屏，所以这一定程度上降低了修复难度。&nbsp;</p><p>但另一方面，任何需要拆下外屏的维修都会变得异常艰难，这块外屏需要“巨大工作量”才能完好取下，一不留神弄碎了，背后的传感器就会失效，因为碎玻璃会阻挡光线穿透。&nbsp;</p><p>最后，iFixit对比了Meta Quest 2、Quest 3与Vision Pro的可修复性，因为前两款产品占据了全球XR市场70%的出货份额。&nbsp;</p><p>当然，iFixit对三者的修复细节进行了一些对比，比如内置电池和外置电池的区别，感兴趣的也可以去看看，在这里我们不做赘述。&nbsp;</p><p>总体来看，最终iFixit给Vision Pro的可修复性评分为4分，满分10分。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_6cd5efa0471d40ce90dc9e8ee9bceea9@000000_oswg28636oswg400oswg535_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>7.结语：工业奇迹背后是多到令人惊叹的深厚技术积累</strong>&nbsp;</h2><p>不论是单像素红细胞大小的屏幕、异常精密的复杂组装、极为精密的内部结构，还是各种高规格的传感器、先进芯片的应用，苹果Vision Pro毫无疑问可以用“工业奇迹”来评价。&nbsp;</p><p>人们常常感叹苹果的创新来的往往很“慢”，但通过对Vision Pro的深度拆解分析，我们看到的事实就是，量变到质变是需要过程的，苹果的长期深入布局，细节多到令人惊叹，Vision Pro对VR/AR领域的颠覆，不仅仅是一些供应链前沿技术的整合应用，而更多是苹果长期深耕沉淀技术的集中体现。&nbsp;</p><p>质变一刻背后，是漫长的量变积累。&nbsp;</p><p>或许每个人对苹果Vision Pro都有不同的看法，作为初代产品，它可能有诸多的不足，比如亟待提升的EyeSight功能、比iPad Pro还重的重量。&nbsp;</p><p>但不可否认的是，苹果让我们有了一次瞥见未来的机会，这个未来，可能将改变无数行业和你我的生活方式。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652766975&amp;idx=1&amp;sn=701f225aded553e2b8868767d1b9f2ee&amp;chksm=85bc427dc262c6ccacc5051a2662047a722405db7a8cd46c8433031e570314bc664ad9c3e274&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：云鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2639318072688897</id>
            <title>阿里再回购，250亿美金能换来信心吗？｜焦点分析</title>
            <link>https://www.36kr.com/p/2639318072688897</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2639318072688897</guid>
            <pubDate></pubDate>
            <updated>Thu, 08 Feb 2024 08:42:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 阿里, 财报, 营收, 亏损
<br>
<br>
总结: 阿里发布了Q4财报，营收和净利润低于市场预期，其中亏损主要来自实体零售业务。尽管国际商业表现良好，但核心业务淘天和云营收增长乏力。阿里计划通过回购和剥离非核心资产来改善业绩。 </div>
                        <hr>
                    
                    <p>文｜彭倩</p><p>编辑｜乔芊</p><p>阿里交出了一份没有惊喜的季度报。</p><p>财报显示，Q4 （自然年，美股为 2024 财年 Q3）阿里营收净利润均低于市场预期。Q4 营收 2603.5 亿元，同比增长 5%，低于市场预期的 2612.47 亿元。利润方面，公告称由于高鑫零售等投资减值，阿里经营利润为 225 亿，同比下降 36%。剔除这部分影响，当季EBITDA约为595.7亿元，同比微增2%。</p><p>即使宣布了将股票回购计划规模扩大至 250 亿美元（至此，回归规模从2019年5月到2027年3月底共计650亿美金），由于业绩较为低迷，阿里的股价仍经历了盘前先跌后涨再跌的起伏。今日恒指开盘跌 0.58%，阿里跌也超 4%。</p><p>阿里已连续多年开展股份回购并数次提升回购额度，显示了其对公司未来发展的坚定信心。不久前，阿里创始人马云、蔡崇信也大幅增持阿里股票。但市场更为关注的仍是，在经历近一年的动荡调整后，各个业务集团业绩是否能够真正迎来反弹。</p><p>据 Q4 披露的各业务集团财务数据，改革的成效目前还未能直接在核心业务上显现出来。</p><p>最核心的两大块业务淘天和云营收依然涨不动，增速分别为 2%和 3%，和前两个季度差别不大。仔细翻阅财报可知，淘天集团的客户管理收入持平去年，变现率下滑；若不计来自阿里并表业务，阿里云Q4 营收实际是负增长。</p><p>不过，国际商业、菜鸟和大文娱等子集团都保持了不错的增速。尤其是国际商业，Q4营收增长了44%，由于跨境物流履约解决方案的收入增长的贡献，菜鸟营收增长了24%；因为线下演出收入的强劲增长，大文娱也增长了18%。</p><h3>淘天增长乏力，国际商业成最大亮点</h3><p>尽管 Q4 有“双11”，但淘天的增长依然乏力。</p><p>财报会上，集团 CEO、淘天 CEO 吴泳铭强调：“在全球竞争最激烈的中国电商市场，淘天集团 GMV 继续保持第一位”。吴泳铭还立下军令状，2024 年有信心让淘天重回增长轨道。</p><p>目前淘天的确成功拉动中小淘宝商家的回归。例如，平台商家数继续录得同比双位数增长，并在过去 4 个季度连续保持双位数增速的趋势，这里面绝大部分是中小商家。</p><p>财报显示，“淘宝和天猫的线上GMV实现了同比健康增长”，但客户管理收入却没有增长。这是因为淘宝相比天猫贡献了更多的销售额，但由于淘宝的变现率更低，因此拉低了整体收入水平。</p><p>财报会上，分析师也对此提出疑问：“相比同业，淘天的变现率偏低，怎么实现这个财务指标稳定增长？”吴泳铭则称将针对这类中小商家，制定出新的商家与平台商业模式。</p><p>也不是完全没有好消息。Q4 国际商业仍然维持了高增长，营收增速达到 44%，整体订单增速为 24%，其中国际零售商业的营收增速高达 56%，这主要归功于速卖通。该季度速卖通也首次披露了数据，其订单增速高达 60%。</p><p>国际零售商业持续的高增长，也让国际商业成为仅次于淘天的第二大业务。财报显示，国际商业整体营收为 285.16 亿元，超过了云业务的 280.66 亿元。</p><p>速卖通 Choice（即全托管模式）无疑是国际零售商业营收高速的大功臣。该模式极大的提升了国际商业零售订单的增速，继而成为国际商业零售营收增长的最大动力。截至2024年1月，Choice 的订单数量已经占据了速卖通的一半。</p><p>基于全托管的良好表现，速卖通也在近期上线了半托管模式，进一步放大其在供应链和物流履约上的优势。这也是基于商家们的诉求，例如，为了完全掌握自主定价权，许多大的三方商家（即 POP 商家）并不想做全托管，但仅凭自己又无法解决物流时效的问题。</p><p>不过全托管和半托管业务前期投入较大，加上 Q4 是大促旺季，这导致阿里国际商业的亏损有所增加。Q4 阿里国际商业整体经营利润的亏损了31亿元，较去年同期扩大了近4倍，亏损率为11%。不过，财报会上，高管们强调，阿里会对国际商业持续投入，并且不再考虑融资。</p><p>但国际商业仍在持续降本增效。去年12月，Lazada 也开展了被收购以来较大的一次组织调整，为让业务决策更集中和高效，Lazada 东南亚六国的用户产品和商家策略团队集中到总部，地方多个部分被裁撤，今后将由总部中台来支持地方的运营。</p><p>对于国际商业是否要收缩对东南亚市场的投入，蒋凡在财报会上称，将在可控的规模上进行投入。</p><h3>继续瘦身：清点资产、减员</h3><p>相比于营收增长的持续乏力，Q4财报透露的一个更不妙的信息则是多项投资业务已经对阿里的利润表现产生了较大的负累。</p><p>对海外等业务的投入的确造成了一些亏损，但这些亏损是为了换取增长，阿里更介意的还是多项实体零售业务的亏损。</p><p>在阿里的收入板块中，名为“其他”的板块里囊括了高鑫零售、盒马、阿里健康、银泰、灵犀互娱、智能信息、飞猪、钉钉等。这里面包含了所有的实体零售资产，该板块 Q4 收入为 470 亿元，同比下滑 7%，亏损扩大了 87%，达到了 32 亿元，以九个月计，这部分收入下滑了 2%，亏损则达到了 63 亿元。</p><p>对这一板块的表现不佳，阿里在财报中给出了解释，主要是由于高鑫零售业务规模尤其是供应链业务（包括天猫共享库存及淘菜菜业务）收缩。</p><p>就在上周，国内外多家媒体曾报道，阿里方面考虑出售银泰、盒马、高鑫零售等多个实体零售业务。此次财报会上，阿里集团董事长蔡崇信也首次给出了正面回应：“阿里已成立相关公司，研究如何进行相关上市公司的股票出售，目前资产负债表上仍有许多传统的实体零售业务，这些并非核心业务，若退出也是合理做法，但考虑到当前有挑战的市场情况，尚需时间实现。”</p><p>实际上，在2024财年至今的九个月内，阿里已退出17亿美元的非核心资产。但正如蔡崇信所言，在当前的市场环境下，线下实体零售能否成功出售还具有很高的不确定性。</p><p>在过去10年里，为了做新零售和导流，阿里曾花费数百亿资金收购线下资产，但如今消费环境巨变，新零售战略遇挫，也到了该抛售的时间节点。银泰、高鑫零售值钱的资产在于其此前购买的大量商业地产，每天产生的人员工资和经营成本，属于潜在负债，这意味着，越早出售越能及时止损。</p><p>除了考虑出售表现不佳的实体零售业务，阿里在过去两年里也通过减员4万人进行瘦身，而接下来，随着部分业务整合、出售，其减员举措或仍将持续。</p><p>经历了接近一年的分拆后，各个子集团未来的方向也较为明确，目前云已回归集团，国际商业、大文娱集团、本地生活集团继续独立运营，而在财报会上，针对部分子集团是否还将推进上市，阿里CFO徐宏给出说法是：盒马、菜鸟IPO交易是否推进、如何推进都取决于市场条件,当前的市场条件没有办法真正反映这些业务的内在价值。</p><p>在如今诸多不利因素下，阿里的创始人们也频繁出手，以挽救市场对这家公司的信心。</p><p>无论是马云和蔡崇信增持股票、一再加码的回购规模、还是马云在内网提及的“阿里会改，阿里会变”，或是积极剥离非核心资产的举动，都在试图对外释放更多积极的信号。</p><p>随着吴泳铭迅速接管淘天和云、对分拆收尾，2024年，正如其所言，阿里将聚焦核心业务，投入激烈的行业竞争之中。</p><p>阿里正陷入其创业20多年来最大的危机和动荡之中，但它能否走出低谷？这或许仍需要时间。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2639419105819784</id>
            <title>苹果Vision Pro的5个关键问题，我们问了专业开发者</title>
            <link>https://www.36kr.com/p/2639419105819784</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2639419105819784</guid>
            <pubDate></pubDate>
            <updated>Thu, 08 Feb 2024 07:54:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果 Vision Pro, VR、AR 设备, 空间计算, 应用开发
<br>
<br>
总结: 苹果 Vision Pro 是一款引人注目的 VR、AR 设备，其空间计算功能带来了突破性的体验。使用 Vision Pro 上手简单，手眼交互易用，无需抬手即可完成交互操作。用户体验良好，连续使用7个小时眼睛不会感到疲劳。Vision Pro 的透视功能达到了基本可用的程度，消除了水波纹效果，让人可以正常生活。对于开发者来说，Vision Pro 提供了广阔的应用开发空间。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_c8c6dba84bc14b0c95b9fa15e7a8ea49@000000_oswg91821oswg1080oswg711_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2 月 2 日，苹果 Vision Pro 在美发售，吸引了全球的目光。</p><p>Vision Pro 实际试戴体验如何？与过去的那么多款 VR、AR 设备有什么不同？</p><p>空间计算是一个噱头吗？库克宣布 All-in Vision Pro，那么开发者现在是不是也该 All-in？</p><p>关于这些大家关心的话题，极客公园邀请了两位在 XR 领域有多年经验的从业者，也是早早用上了 Vision Pro 的尝鲜者，聊聊他们使用 Vision Pro 的真实体验，以及基于这样的体验，他们会不会选择现在投入 Vision Pro 的应用开发中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_2691d499109444db9dc022c14fd5e6cb@000000_oswg312279oswg864oswg884_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>两位嘉宾之一是刘天一，从 2015 年开始接触 AR 行业，有多年 XR 行业解决方案和 C 端产品设计的经验。曾任职于国内 AR 公司亮亮视野多年，目前是独立开发者。</p><p>另一位是 Allen Xiang，虚实之间网络科技的创始人。Allen 2016 年就接触了 XR 行业，曾在多家互联网大厂任职，包括腾讯的 XR 部门。目前，Allen 接受了美元基金的投资，正在进行 XR 应用开发的创业。</p><p>极客公园与两位在 XR 领域有着多年从业经验的创业者进行了两个小时的对话。在对话中，两位创业者指出了 Vision Pro 的体验突破性的关键，苹果在推进 Vision Pro 的发展中将出现哪些优势和劣势，中国厂商有没有可能追上 Vision Pro，以及他们认为，未来哪些应用或将成为爆款。</p><p><strong>以下是极客公园与刘天一、Allen Xiang 的对话节选，由极客公园整理。</strong></p><h2><strong>1.体验：连玩 7 小时，不累，透视功能强大</strong></h2><p><strong>极客公园：两位都已经上手了这款产品，先简单讲讲拿到 Vision Pro 使用的第一印象吧？</strong>&nbsp;</p><p><strong>刘天一：</strong>我是在北京商场里的「空间计算网吧」，Vision Pro 的租赁体验店里体验到的，玩了大概两个小时左右。&nbsp;</p><p>接触到 Vision Pro 的第一印象是，整体感觉非常苹果。无论是包装，还是各种设计风格，融合了 iPhone、Airpods Max 以及 Apple Watch 上面的各种设计元素，拿到手的第一感觉是很熟悉。&nbsp;</p><p>使用后印象最深的，是它上手非常简单。很多人都体验过不同种类的 XR 设备，上手的难度其实是 XR 设备中的一大痛点。通常情况下，旁边要有一个人告诉你说，「你看见那个点了吗？你按这个键，去点一下那个点。」非常麻烦。&nbsp;</p><p>而 Vision Pro，我<strong>从戴上，开机，到被引导着使用数字表冠，再到被引导注册我的手和眼，全套流程大概也就是 2 分钟就完成了</strong>，而且过程中没有什么我要去学习的东西，上手难度非常低，这一点让我印象很深。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_6e9097d5175a4e93a4e4fb8935a592c8@000000_oswg68458oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">苹果专卖店里消费者无需引导自己试用 Vision Pro | 图片来源：视觉中国&nbsp;</p><p>Vision Pro 手眼交互的易用性也很强。过去的 XR 设备，我们如果用手来交互，都需要把手抬起来，放在面前去点击和捏合。苹果这一次把向下的摄像头做的非常好。&nbsp;</p><p>这是我用了这么多设备，第一个能让我非常慵懒地躺在沙发上，然后手都不用从腿上抬起来，简单地捏合一下我的食指和拇指，看哪里点哪里，就能完成交互的设备。&nbsp;</p><p><strong>Allen：</strong>我的 Vision Pro 是刚好有朋友从美国飞回来带回给我的。我刚刚拿到，从中午拿到到刚刚我们连线的晚上七点左右一直没有摘过。&nbsp;</p><p>我体验了多个场景，包括带着它下楼，去便利店买东西吃，晚上去到商场里，和同事一起吃快餐。我也带着它使用透视的功能，使用我的 Windows 电脑进行办公了一段时间。&nbsp;</p><p>我在仔细调整完角度后，觉得佩戴上没有任何体验上的问题。<strong>7 个小时下来眼睛不会酸也不会累</strong>。&nbsp;</p><p>我体验过的朋友中，大家普遍评价都非常高。我认为 Vision Pro 带来了一个转折点，是它的透视（Video See-Through, VST）达到了一种基本可用的程度。&nbsp;</p><p>因为视觉透视功能中，需要算力对现实世界的物体在 XR 头显中实时进行 3D 重建，你看到的景象都是实时生成的，如果算的不够快的话，就会出现水波纹。&nbsp;</p><p>水波纹的效果指的是，如果你拿一个近场的物体，比如拿手在面前挥一挥，然后远景的物体就会产生一种波纹的感觉，像你在扰动水面一样。那种感觉像是你是魔法师，你的手一动就会扰动这个世界。而在 Vision Pro 上，这种感觉被完全干掉了，让人真的觉得带着它干什么都可以，可以戴着它正常生活了。&nbsp;</p><p>槽点的话是，整个 OS 交互完全限制了用户移动中使用，系统级窗口不是自认为中心跟随的，移动超过 1.5 米，独占的 MR 应用也会消失，想要把用户局限在一个固定的场景来使用 Vision Pro，还是缺失了很多想象空间的。&nbsp;</p><p>另外还有一些比较细的技术难点，可能苹果都很难跨越：比如说如果你在走路的话，每次落足时的撞动会带来运动模糊，我在便利店买饮料时，感觉每次踏一下步，画面会糊一下。&nbsp;</p><p>再比如你要定睛看某些字的时候，比如看手机，手机还是得保持完全不动。手机保持稳定的情况下回微信，刷淘宝都可以，但是要是一边走路一边看手机就不行。&nbsp;</p><p><strong>极客公园：Vision Pro 有六百多克，也看到许多外媒报道，Vision Pro 设计的前坠感比较明显，长时间佩戴可能不舒服。连续戴 7 个小时没有不舒服，是幸存者偏差吗？</strong>&nbsp;</p><p><strong>Allen：</strong>真的不是。因为我是 XR 行业的从业者，我的朋友圈里面有非常多去美国购买 Vision Pro 的人，一些朋友从坐美国飞回中国，很长的旅程中也能一直戴着，两个电池换着充电。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_506e8a5c8e8148cd9c5d3dc565c7f91d@000000_oswg369560oswg1080oswg640_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">华尔街日报记者挑战 24 小时佩戴 Vision Pro ｜图片来源：YouTube 频道 The Wall Street Journal&nbsp;</p><p>目前我们看到的网上所有关于重量的差评，基本上都是说它会挤压眼睛下方颧骨的位置。这个位置一旦感觉到挤压，超过 10 分钟可能就觉得很不舒服。这可能是因为 Solo 的绑带没有绑紧，或者是没有换上双环的绑带。一定要进行细微调整，让头显的上方更多地去贴合面部。&nbsp;</p><p>我自己体感，唯一有点感觉脖子酸的场景是你完全坐直，脖子有一点点前倾的时候，眼眶那个位置会感觉到重量，有点往下沉的感觉。&nbsp;</p><p>但是能有这样的感觉，前提是要脖子保持长时间不动。比如在你全神贯注地用一个姿势看电影，或者是你去投屏 Mac 的电脑办公在 Vision Pro 里办公的时候。只要不要坐的非常直，身体有一个低一点或者抬一点的角度，其实都可以很舒服地看完两个小时的电影。&nbsp;</p><p>这样的不舒服其实不是重量带来的，而是由于力矩分布不均匀带来的。因为本身 Vision Pro 的设计也有一些前坠的感觉，如果在后面挂一个一两百克的小电池，均衡一下前后配重，重量就完全不是问题。&nbsp;</p><p><strong>刘天一：</strong>如果说看电影两个小时的话，我觉得半躺或者全躺在沙发上，应该是没有任何问题的。&nbsp;</p><p>这个设备确实有一些明显的前坠感，但戴在头上绝对没有那种不舒适的感觉，我戴了一个小时，用下来感觉没有什么疲劳感。&nbsp;</p><h2><strong>2.空间计算，XR 的另一种叫法</strong></h2><p><strong>极客公园：两位也都是体验过很多款 XR 设备的人，Vision Pro 的区别在哪？</strong>&nbsp;</p><p><strong>刘天一：</strong>我感觉 Vision Pro 应该是我第一款能够带着到各个场景里面去走动的一个产品。&nbsp;</p><p>在此之前，只有芬兰公司的 Varjo 产品的视觉透视效果让我感受到有点接近于肉眼看世界的效果，但 Varjo 产品并不是一款无线的产品。而且它是纯针对 B 端的产品，为飞行员、汽车建模等等专业用户设计的，在国内一套买下来要 5-8 万左右，比苹果的产品还贵。&nbsp;</p><p>Vision Pro 的视觉透视效果上，它的色彩，面对大光比光源不会出现某些区域的严重的过曝或者死黑，以及弱光下没有明显的噪点，没有很强的水波纹和拼接，都做到了非常好。&nbsp;</p><p>苹果在方便用户走起来以及考虑用户安全性方面，也做了很多的细节的处理。我记得苹果最早这款设备设计的充电线是磁吸的，而我体验的时候，它是变成旋转卡紧的卡扣式的了。我想这也是考虑了行走中，万一线被突然碰掉，眼前一片黑有危险的。移动的时候，人眼前的弹窗也会淡出消失，停下来才会重新回到视野中心。&nbsp;</p><p>此外，<strong>苹果相对于 Meta（Quest）这样的设备的一个最大的差别，在于算力。它具有桌面级的算力，市场上没有第二个产品有这样的性能</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_f9e8307b51504301a32abd0482f02df3@000000_oswg279876oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Vision Pro 使用了双芯片 其中 M2 芯片之前被用在苹果笔记本电脑上 ｜图片来源：苹果官网&nbsp;</p><p>举个例子，如果我们使用 Vision Pro 直播，它的算力足够我们每个人做出一个数字分身，实时生成我们的动态，而之前 Meta 公司的设备做这些就很难，它只能用一些抽象的卡通形象去完成。Vision Pro 的算力跑分到达了 Quest 设备的四五倍、五六倍，这是非常高的一个水平。&nbsp;</p><p><strong>Allen：</strong>我可以把 Vision Pro 与 Quest 头显做一个对比。Quest 头显是欧美非常主流的一款产品。&nbsp;</p><p>Quest 设备也有视频透视功能。Pico 等产品使用单目画面做扭曲重建，而 Quest3 的视频透视功能采用了双目立体建模和点云重建，扭曲感和深度的感觉已经很不错。但是它的视频透视功能，出来的效果仍然有水波纹。而 Vision Pro 做出来的效果已经达到了 80 分，是一个普通消费者不需要再去关注的属性了。&nbsp;</p><p>清晰度方面是硬参数，苹果也没有办法突破物理学。Quest 实际上的入眼像素只有 400 多万，然后再加上 FOV 的话，折算可能就 260 万左右。<strong>Vision Pro 入眼像素大概 600 多万，从噪点上，能感受到 Vision Pro 的清晰度提升了大概 60% 左右</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_f34e2f1726bb4afdaa9cc571f8ead060@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">「你会感觉现实有一点糊，但你不会感觉它就不是现实了。」｜图片来源：影视飓风&nbsp;</p><p>延迟方面，人眼的反应的灵敏度大概就在 20 毫秒上下。普通消费者在 60 毫秒以下，已经感知不到很明显的区别。Vision Pro 大概 12 毫秒延迟，Quest 实测 50 毫秒左右。这个东西可能有点因人而异，敏感一点的人或许能感觉到流畅性的差别。&nbsp;</p><p>佩戴体验上，Vision Pro 跟 Quest3 的体验是相近的，但面罩更硬一点，所以我觉得改第三方面罩和头戴配件，来提升体验对这两种设备来说都是必要的。&nbsp;</p><p>而且由于 Vision Pro 的纵向 FOV 要比 Quest3 小很多，透视的潜望镜效应会更明显，或许未来会有很多用户会改成类似 Quest Pro 那样的开放式面罩来获得更沉浸的透视体验。&nbsp;</p><p>我觉得 Vision Pro 属于已经达到了一个大家已经挑不出刺的水平。而 Quest 头显则是普通戴着，玩游戏和一些 MR 应用没什么问题，但是视频透视，则能感受到很明显的水波纹等等问题。体验上可能是 60 分到 80 分的区别。&nbsp;</p><p>Vision Pro 和 Quest 3 从价格上来说，一个两万多，一个三千多。<strong>Vision Pro 的定位偏观影和办公，它没有很好的游戏生态，开发者没办法那么好地从 Unity 的生态迁移过来</strong>。Quest 头显就是游戏机。我也尝试着戴着它办公过，确实没办法骗自己，我觉得那个是大多数人都无法接受的一个状态。&nbsp;</p><p><strong>极客公园：这次苹果很努力地提「空间计算」这个概念，而不是 XR。从你们的感觉，空间计算和 XR，有很大的不同吗？</strong>&nbsp;</p><p><strong>刘天一：我觉得本质上是同一个东西，但是苹果作为一个厂商，想要使用一个不同的品牌，在一个自己创造的品牌里，有一个领导者的地位</strong>。&nbsp;</p><p>其实大家可以回忆一下，在 Vision Pro 前，苹果一直讲的是 AR，但是现在主提空间计算，其实无外乎是因为在 VR 也好、AR 也好、元宇宙也好，这几个专属名词的赛道上，苹果都不能算是先行者，或者是之前最耀眼的那个公司。&nbsp;</p><p>那么如果提出一个朗朗上口，易于传播并且契合自己理念的名字，未来它可能想用空间计算来去取代掉过去的这些名词。&nbsp;</p><p>目前我们看到苹果的很多应用，仍然是 2D 的。对于 iOS，Mac 的开发者来说，其实是能够很轻易的在 Vision Pro 上去完成新应用的构建，甚至把 iPad 之类的应用移植过来都很方便，<strong>所以在可预见的将来，它会是 XR 行业里面应用生态成长最快的一个平台</strong>。但我其实 2D 应用不算代表了空间计算。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_af8b88af080d441c80939e819edf9944@000000_oswg562835oswg1080oswg615_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">苹果宣传片中也是 2D 应用居多 ｜图片来源：苹果 Vision Pro 宣传片&nbsp;</p><p>前面提到苹果的芯片算力非常强，3-6 个月后，应该会有一些真正的 3D 应用做出来，能够突破我们所熟悉的物理的限制和束缚。这时候苹果应该会进一步去给大家洗脑，强化大家认知，说这个才叫空间计算，你们以前玩的都是垃圾，我觉得可能会这样发展。&nbsp;</p><p><strong>Allen：</strong>对，我也觉得<strong>现在 Vision Pro 首发的这些应用，还完全没有办法代表苹果想打出的这个空间计算的愿景</strong>。&nbsp;</p><p>基于 SwiftUI 或者是原生的 ARKit 的开发者并不多。因为之前使用这些工具去开发的，都是为手机开发 AR 场景，拿手机扫一扫出来一些特效，是一个很小众的场景。&nbsp;</p><p>而使用 VisionOS 原生的 RealityKit 去做 3D 的包装，你又会发现它的整个组装能力没有那么的丰富，跟 Unity、Unreal 这样成熟的 3D 引擎比起来还差得远。&nbsp;</p><p>而 Unity 改过来兼容移植过来的应用，Unity 又卡了一手——你要开 Pro 版，你要交会员费，你才能去用这个功能，否则只有一个月的免费的试用期，一个月的试用期可能是移植不完的。&nbsp;</p><p>所以很多大的 VR 厂商，如果没有去跟苹果谈一些二方合作的话，不会那么急着去做制作兼容、移植。&nbsp;</p><p>这造成现在原生的 3D 应用不多。但并不是说 Vision Pro 未来只有这些 2D 的应用，或者苹果只想要做这样的东西。&nbsp;</p><h2><strong>3.「Android 版」空间计算会跟上吗？</strong></h2><p><strong>极客公园：聊到生态，未来一两年会不会出现 Vision Pro 这边有一个苹果的空间计算的生态，而另一边会有像一个&nbsp;Android&nbsp;这样的生态出现？</strong>&nbsp;</p><p><strong>刘天一：</strong>我个人觉得短时间内还是有难度的，长时间是有机会的。这一次苹果在 Vision Pro 上甩其他厂商甩的比当年 iOS 甩 Android 要远很多，<strong>我比较悲观，我觉得可能在 5 年左右才会出现这样的机会</strong>。&nbsp;</p><p>比如，首先苹果在潜心去研发 M 系列芯片的时候。英特尔、高通的芯片并没有在低功耗无风扇化的这条路上走的那么激进。所以其实到苹果真正把这个算力堆出一个满足及格线的产品的时候，我们在市场上找不到任何一款可以和它媲美的芯片，更不用说里面的 R1（Vision Pro 里处理视觉追踪数据的芯片）。&nbsp;</p><p>硬件的层面甩了其他家很多，就意味着在相当长的一段时间内，苹果这个平台上能够看到的内容的质量，在其他的平台上我们是很难看到的。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_de88d1f8e767459893d9e7ed783a6e8d@000000_oswg198042oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">苹果公司总部对面的苹果商店开始售卖 Vision Pro ｜图片来源：视觉中国&nbsp;</p><p><strong>整套系统的延迟优化，眼动手势交互，文字和图形渲染的优化，都需要追赶</strong>。&nbsp;</p><p>举个例子，我们在 PC 电脑上和手机上看到文字是经过渲染优化的，让我们看起来没有明显的锯齿。但是这个基于静态屏幕做的这种文字栅格填充和次像素渲染的算法，如果拿到 XR 上就不适用了，因为在 XR 中，人们可能倾斜着对着屏幕，有可能远，有可能近，因此使用原先的那一套字体渲染的方法就不适用了。&nbsp;</p><p>Meta 追赶的是不错，但是就 Android 系统本身来说，系统层面这方面应该没有看到有什么动作。我们如果想解决它的延迟问题，解决渲染的清晰度问题，一些预设的手势、眼动的交互的问题，还是要交给厂商自己来做，这个代价就会非常大。&nbsp;</p><p>如果想要<strong>做一个复杂度接近 Vision Pro 可能 60%、 70% 的产品，一个小几百号人的团队其实是非常捉襟见肘的</strong>，因为 Android 在底层没有提供这方面能力，大家不太好做。&nbsp;</p><p>但是如果时间再久一点，尤其是我觉得可能在两年以后，苹果的应用生态和内容生态得到一个大发展的时候，市场也会希望有苹果的替代品，更便宜的、更轻的，或者其他功能更适合我自己，它市场的需求摆在这了，相应的 Android 的生态也会跟到位，但是下一代平台，是不是还属于 Android？&nbsp;</p><p><strong>我其实认为很多厂商的机会是比较平等的，除了&nbsp;Android，国内的系统，包括其他的第三方系统我觉得也不是不可期待的</strong>。&nbsp;</p><p><strong>Allen：</strong>我的感受是追 VST 这个形态没有那么的难，难的可能是在于生态上面。&nbsp;</p><p>我们把它拆成三层，一层是硬件本身，另外一层 OS 的基建，然后再上面一层才是生态和开发者的这些东西。&nbsp;</p><p>如果我们单纯说硬件的话，硬件比手机复杂，主要在透视和光学上面。这是手机行业没有接触过的领域。手机拍照镜头跟我们去做这种放大的这种镜头，它其实不属于同一种光学领域，所以这些对应的人才都是要重新培养的。&nbsp;</p><p>但因为 XR 头显本身比较大，大其实代表着冗余。这里面有非常多硬件可以取舍的地方。苹果确实有优势，苹果的结构件做的特别特别复杂，但是它的复杂来自于为了做到极致。如果不做到那么极致，可能成本会掉的非常快。<strong>用一些现成的解决方案，你还是能攒出来一个感觉上有苹果 80% 硬件实力的东西的</strong>。&nbsp;</p><p>华米 OV 里面一个做手表的团队可能都有一两千人，所以团队方面，完全是看厂商认不认可这是一个未来市场，BG 的老大感没感受到压力。<strong>纯硬件角度的差距可能就是一年半、两年左右的一个时间，而且就在当下的每一个切片，可能都能拿出来一个苹果 80% 的一个体验的一个硬件出来</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_443c5c1109db4a37902a55a30e79bf6c@000000_oswg306984oswg1080oswg612_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">为了极致而复杂的 Vision Pro ｜图片来源：苹果官网&nbsp;</p><p>然后至于中间层，其实今天 OS 层开发的研发人才海内外都很多，已经不是当年全球都找不出来多少做 OS 开发的情况，我觉得 OS 今天可能难在一些，像天一说的这种文字的次像素渲染这种很细的问题，它不是说特别难，但很刁钻，要做很多很多小细节的优化，可能是要花人力去堆的一个状态。但这里的窗口期拉的时间长一点，<strong>OS 层的这个底层优化我觉得是没有任何问题的，感觉也是两年左右的差距</strong>。&nbsp;</p><p>难可能难在生态上面。因为过去 Meta 有在游戏行业的生态号召力，然后 iOS 有帮助到很多的开发者赚钱。然后两家各拥抱了一个生态，Meta 选择拥抱 Unity，然后苹果也拥抱，但是还没有那么彻底，要推自己那套原生的开发的架构。&nbsp;</p><p>对应的 Android 阵营，我感觉 OpenXR（XR 领域的开源标准）还没有那么成熟，至少两三年内我看不到作为 MR 应用的开发者，大家很想要去拥抱 OpenXR 那套生态体系。比如说国内的厂商，想要基于 OpenXR 去推这个东西可能就很难了，里面优化的坑特别特别多。基于不同的底层架构，优化移植的成本很高。&nbsp;</p><p>听起来 OpenXR 和 Meta 的设备感觉还挺兼容的，<strong>但我们自己去尝试做架构的兼容移植，会发现这里的坑可能好像比当年&nbsp;Android&nbsp;去适应不同的机型的难度要大 10 倍以上</strong>。开发者就会考量，花这个时间值不值得，如果出货量很小，那为什么要做兼容移植呢？我感觉这里面有非常长的路要追。&nbsp;</p><h2><strong>4.应用：空间图片和轻娱乐</strong></h2><p><strong>极客公园：Vision Pro 目前也有一些原生应用，比如空间视频和空间照片。它的体验感如何？</strong>&nbsp;</p><p><strong>刘天一：</strong>Vision Pro 给我体验留下印象最深的应该就是它的照片和视频的部分。我的感受是已经非常接近你在实际场景中去看眼前这个人的感觉。&nbsp;</p><p>2D 照片和视频中，严格意义上来说人的鼻尖和脸颊其实是在一个深度上，只能是通过图片上的光影，用大脑的脑补出它的深度。&nbsp;</p><p>但是在空间视频和空间照片中，我们是可以这样轻轻地移动自己的头部和身体去环绕这个场景进行观察的，非常有真实场景的感觉。&nbsp;</p><p>我也和很多行业内的其他朋友交流过，他们说<strong>如果有这样一个设备，可以帮你显示那些不在你身边的亲朋好友，或者甚至说的再激进一点，已经不在人世的这些亲朋好友，能够去给你还原这个瞬间，那么你愿意花多少钱，多少的时间去使用这样的一个设备</strong>？这件事会让很多人的意向瞬间变得更强烈。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_bd5e13653eed4f55804761b9a0cb519b@000000_oswg375275oswg912oswg854_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">使用 iPhone 15 Pro 就能制作空间视频 ｜图片来源：苹果&nbsp;</p><p>我当时使用的时候，看到了一张巴黎的照片。我之前去巴黎的时候，也在那个位置拍过照，当时感觉一下子就回到那个现场了，临场感特别强。&nbsp;</p><p>它的照片不是简单的这样平铺在我的眼前，而是透过一个大概一米六几，一米七左右的这样的一个窗口向外去观察。当我这样站起来或者低下去的时候，我能看到这画面的边缘以外，其实是还有画面的，好像是透过一个窗口向外看巴黎的这个城市。&nbsp;</p><p>这种临场感，我在其他的 XR 设备上确实还没有体验到这么好的感觉。&nbsp;</p><p>不过我个人感觉，空间视频和空间照片的清晰度可能还有点低，所以看起来也没有想象中的那么好。我觉得苹果在将来应该还会在这个拍照上继续去迭代，把这方面的体验去完善。&nbsp;</p><p><strong>Allen：</strong>过去 180 3D 的内容其实很少，因为之前能够生产 180 3D 的设备就不是很多。播放端和生产端之间，因为参数的各种不一致，还会导致不匹配，纵深感会很弱，3D 感会很弱。&nbsp;</p><p>所以之前，其实我们是没有办法接触到很多日常场景的 180 度 3D 的优质内容的。即使是从业者也接触不到很多。&nbsp;</p><p>苹果其实没有创造一种真正很新颖的格式，但是它的景深，还有光圈比例等等，都调的很接近人眼，可能只是清晰度差一点。&nbsp;</p><p>我们也录了一些相关的视频，发现大家熟悉了之后，已经不会在使用中一直歪头去看它的 3D 效果了。所以，在一个固定的位置下，你的双目的纵深感和它给你呈现的畸变角度的还原，有没有很像真实世界，这个感觉才是最重要的。&nbsp;</p><p><strong>不是说苹果有什么特殊的黑科技，而是苹果定义了这个行业规范</strong>。&nbsp;</p><h2><strong>5.空间计算，真正的创业机会</strong></h2><p><strong>极客公园：作为开发者，你们会考虑为 Vision Pro 开发内容吗？</strong>&nbsp;</p><p><strong>刘天一：</strong>我不太可能会把它当做一个主要的工作方向，但可能会闲暇时间去尝试做一些应用。&nbsp;</p><p>因为它目前还没有很大的出货量，很多的开发者把它买回去，或者是评测人士、行业内的人买它回去进行一个测试。我觉得可能还要再看两三批的出货，来看看它的表现如何，再进一步的决定。现在可能不适合把它作为一个公司的创业方向来去做。&nbsp;</p><p>但是个人闲暇时间如果有一些好玩的、小的应用或者想法是可以写一写，上去试一试的。前两天看群里有人就是相当于抢这个先机，因为这个平台它刚刚发布的时候，上边没多少应用，自己马上发一个，可能随便一卖几十万美元也到手了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_02238a4ec8774172bd9b7d5c6e3d9de1@000000_oswg469895oswg990oswg664_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">使用 Vision Pro 换眼睛显示效果的小应用效果图 实际开发者无权限开发类似应用｜图片来源：X 平台 RAP MAIS&nbsp;</p><p><strong>不过我觉得 Vision Pro 的互动空间网吧，类似于院线的这种模式，可能会有一定的商机</strong>。&nbsp;</p><p>消费者花一定的钱去租赁它的设备，包括后面有更多数字内容跟上的话，为了新鲜体验，消费者会愿意去购买。甚至是再往后有可能赚的钱都不定来自消费者，也有可能来自推广。&nbsp;</p><p>另一个我觉得比较好的模式，是 VR 的大空间互动，比如前段时间的《消失的法老》，我觉得做得很成功。我觉得这个模式在 Vision Pro 上是可能复制的。&nbsp;</p><p>在 Vision Pro 之前，其他的这些 XR 设备没有一个能够把视觉、听觉等等各方面的感官体验每一条都拉到一个及格线。&nbsp;</p><p>它在这方面体验上及格了之后，再配合上比如说嗅觉、触觉、味觉，包括现场的装置，去做一些互动的话，一次体验卖个几百的门票，我觉得不难。&nbsp;</p><p>Vision Pro 再往后发展个几代之后，我认为这很适合一些电影行业的人参与进来去做，可以观察一下。&nbsp;</p><p><strong>Allen：</strong>我们目前在 Quest 平台上开发 MR 社交应用和 MR+AI 的一些互动游戏的体验的娱乐的应用。&nbsp;</p><p>如果要为 Vision Pro 开发的话，我现在自己的观察到的是，<strong>现在的用户很需要的，其实就是一些轻娱乐和更游戏化的场景</strong>。&nbsp;</p><p>尤其是我自己一直觉得桌游这个品类，会是非常非常适合 MR 的一个品类。或者墙上会跳出来那种有节奏的音符、歌词，一些垂直的一些小玩法，节奏音游类游戏的 MR 版本，都有很大可以挖掘的空间。&nbsp;</p><p><strong>极客公园：为没有 Vision Pro 适配应用做第三方应用，是一个好生意吗？</strong>&nbsp;</p><p><strong>刘天一：</strong>这就是我刚才所说的，短暂满足某一类群体需求，然后赚一些很小的快钱，它大概是这样的一个定位。&nbsp;</p><p>其实我觉得，那些没推出原生应用的大厂和大的品牌，反而是值得关注的。现阶段急着抢一个第一，其实做出来的往往就是很粗暴的把 iPad 上的应用给移植过去了。&nbsp;</p><p>真的能把这个三维空间的这种深度，包括这种直观的手眼交互给融入到下一代更高效的人机交互里面，应该怎么样去做？我觉得现在大家应该都还在探索。&nbsp;</p><p><strong>极客公园：看到一个概念图，在 Vision Pro 里做 DeepFake，实时换脸，甚至走向黑镜里犯罪后别人在眼镜里看到的他是一个完全的马赛克，这个是可以实现的吗？</strong>&nbsp;</p><p><strong>Allen：</strong>这个看苹果给不给权限了，给不给开发者实时的摄像头的视频的数据。&nbsp;</p><p>技术上是没有难度的，之前我看日本的一个大学已经做到了，对车辆实时抠图，让路过你身边的车辆都显示为外星飞船，应该是 2021 年，2022 年的事情了。&nbsp;</p><p>对应的包括现在的实时的视频处理技术已经非常非常成熟。今天在手机上，其实已经有一些没有上架的应用可以做到这样的功能了，包括一些违反伦理的 AI 一键脱衣等应用都已经出来了。&nbsp;</p><p>XR 平台上这样的事情只会更可怕。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240208/v2_0765b9fbcd0b4c7b9e87dd1b64bff547@000000_oswg335135oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">在 Vision Pro 里看对方的虚拟分身 ｜图片来源：YouTube 频道 Marques Brownlee&nbsp;</p><p>这就会回到应用生态，它想不想让你这种类型的产品上架，会不会开放这些权限。<strong>苹果不给做的话，那对应的&nbsp;Android&nbsp;厂商有没有某家厂商敢冒大不韪去做这样的事情</strong>。也有可能 20 年、 30 年，我们永远都不会走到这一天。&nbsp;</p><p>因为苹果它也做了很多的特殊的处理，它会给开发者点云深度的各种的信息，但它会做加密和处理，比如它会抹掉你的材质，他不会告诉你的开发者，这个用户的家里的桌子是木质的还是大理石制的，我只能知道有个桌子在这。&nbsp;</p><p>开发者生态，用户隐私以及平台的诉求，这三者之间会互相博弈，最后达到一个和谐共存的点，然后开发者只能在这个状态下，去探索出来各种有意思的应用。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653032864&amp;idx=1&amp;sn=3df4c9b39d16684cb7d29b8a88fcd495&amp;chksm=7fe41c9c09d01dd98988f9989273fd78c0b8e266e979bbd05c9a14b8fb4303357cf3a2f90d5c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：Li Yuan，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>