<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/3061185955718528</id>
            <title>加州对特斯拉和SpaceX说不，公报私仇触怒马斯克</title>
            <link>https://www.36kr.com/p/3061185955718528</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3061185955718528</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Dec 2024 04:12:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 特斯拉, 马斯克, 加州, 电动车激励  
<br><br>  
总结: 马斯克在社交媒体上对加州州长纽森即将出台的电动车激励新政表示愤怒，认为这是针对特斯拉的排挤。尽管他支持特朗普政府取消电动车购置补贴，但与纽森的关系因政治立场的变化而恶化。马斯克在特朗普当选后成为美国最具权势的商业领袖，影响力显著提升。然而，加州政府计划重启电动车购置激励政策，却将特斯拉排除在外，导致特斯拉在加州市场面临销量下滑的困境。加州的电动车市场前景迷茫，消费者对电动车的兴趣降低，未来电动车的普及速度可能减缓。 </div>
                        <hr>
                    
                    <p>“特斯拉可是唯一一家在加州组装电动车的公司。(纽森)真是疯了。”马斯克在他的X平台(此前的推特)上愤怒炮轰加利福尼亚州州长纽森即将出台的电动车激励新政。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_e86122df86cc452ba707324fc9deb599@1743780481_oswg74485oswg1080oswg334_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>尽管马斯克支持特朗普政府取消所有电动车购置补贴，但面对加州州长纽森刻意针对他，试图将特斯拉排挤出加州市场的举动，马斯克还是感到异常愤怒。这对曾经密切合作的多年政商好友，现在已经彻底翻脸，甚至公报私仇。</p>
  <h2><strong>豪赌成功的全球首富</strong></h2>
  <p>现在的马斯克，无疑处在自己的人生巅峰。他刚刚赢下了一场几乎没有退路的政治豪赌。随着特朗普再度当选美国总统，他背后的最大金主马斯克成为了美国横跨政商两界、最具权势的商业领袖。</p>
  <p>现在的马斯克是美国当选总统身边的大红人。他不仅天天呆在特朗普的海湖庄园，随着特朗普一道和外国元首通话，更邀请当选总统去看自己的火箭试射。两人的关系前所未有的紧密，马斯克甚至被外界戏称为美国“第一兄弟”。</p>
  <p>马斯克在这场大选中投入了近两亿美元巨资，在决定美国总统大选结果的七大摇摆州投放广告、百万美元抽奖以及线下拉票，最终帮助特朗普以绝对优势赢下了所有摇摆州，为再度入主白宫奠定了坚实基础。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_54a7ee21010d4eddb946f7bf809ff6a4@1743780481_oswg704497oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>同样不可否认的是，马斯克在2022年斥资440亿美元收购的社交媒体巨头推特(已改名为X)更是发挥了巨大的作用，马斯克将这个原本明显倾向自由派的社交媒体平台进行了大刀阔斧的改革，成为了助选特朗普以及保守派的舆论平台。</p>
  <p>现在的马斯克，已经不仅仅是科技创新领袖，他甚至成为100多年前约翰-皮尔庞特-摩根(John Pierpont Morgan，摩根银行创始人)之后美国最具政治影响力的的商业领袖，甚至可以直接影响到美国经济外交政策的制定。这是他梦寐以求的权力地位。</p>
  <p>特朗普当选之后，履行承诺“册封”马斯克领导政府效率部(DoGE)。尽管这只是个没有实权的顾问部门，但却负责向总统提供建议，精简美国各大政府机构的预算与人员。马斯克相当于拿着一柄“尚方宝剑”，凌驾于诸多联邦政府部门之上。</p>
  <p>美国司法部、国际贸易委员会(FTC)、证券交易委员会(SEC)、美国高速公路安全管理局(NHTSA)、五角大楼、美国国家航空航天局(NASA)，这些与特斯拉和SpaceX直接相关的监管部门和业务部门，未来都会受到马斯克“提升政府效率”的直接影响。</p>
  <p>值得一提的是，这些监管机构此前至少已经对马斯克旗下公司展开了20多次调查甚至诉讼，未来是否还能有效监管特斯拉，将成为一个巨大的疑问。而特斯拉自动驾驶业务的监管难题，在特朗普政府时期也将迎来光明前景。</p>
  <p>资本市场已经对马斯克的特殊地位给出了回应。美国大选结果公布后，特斯拉股价累计上涨了40%，市值再度突破了1.1万亿美元关口。与此同时，SpaceX估值也超过了2500亿美元，xAI估值突破了500亿美元，马斯克的个人资产也因此突破了3000亿美元，成为第一位达到3000亿美元关口的超级富翁。</p>
  <h2><strong>美国电动车前景迷茫</strong></h2>
  <p>然而，就在马斯克风头无二之际，他却在民主党旗帜加州遭到了加州州长纽森的直接打压。马斯克最重要的企业特斯拉，很有可能遭到加州政府的针对和排挤，未来会在这个美国最重要的电动车市场持续下滑。</p>
  <p>加州州长纽森上周宣布了加州的电动车激励计划。这是加州民主党政府针对特朗普上台未来政策进行的预防性措施。在特朗普当选之后，纽森宣布紧急召集加州议会成员讨论如何采取对策，应对特朗普即将宣布的诸多政策。</p>
  <p>特朗普早就宣布自己当选之后，会撤销拜登政府的所有新能源发展计划，尤其是电动车产业激励计划，包括购置电动车的联邦退税，以及投资兴建充电网络计划。这无疑会给美国电动车的发展带来沉重打击。</p>
  <p>美国电动车市场正处在一个前景迷茫的阶段。通胀严重已经打击了消费者购车意愿，而电动车价格高昂，公共充电设施匮乏，二手电动车贬值严重，更是让消费者不愿购买电动车。</p>
  <p>美国消费者对电动车的兴趣并不高。麦肯锡今年夏天的一项调查显示，超过半数(51%)的特斯拉美国车主再次购车时，重新选择了内燃机汽车，10%的车主选择了混动车，6%选择了插电混动，只有不到三分之一(32%)的车主选择继续买电动车。</p>
  <p>可以预见的是，如果特朗普撤销所有电动车激励计划，加大开采石油推动油价下滑，美国电动车的普及速度只会更慢。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_9f7604b1ee654743a1c1ecd0920d9ef4@1743780481_oswg326687oswg1080oswg1035_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>虽然特斯拉早期享受了美国政府和加州政府的大量补贴，但马斯克却表示自己支持特朗普取消所有电车行业补贴。</p>
  <p>分析人士指出，在其他车企造电动车大量亏损的同时，特斯拉已经实现了盈利，更拥有美国最完善的充电网络，特朗普取消联邦购车补贴和充电网络建设显然影响不到特斯拉，只会打击其他电动车企。</p>
  <h2><strong>加州对特斯拉说不</strong></h2>
  <p>鉴于特朗普即将取消电动车扶持计划，加州政府决定重启自己的加州电动车购置激励计划，即重新启动2023年结束的加州清洁车辆回扣计划(Clean Vehicle Rebate Program，CVRP)，鼓励加州居民继续购买更多的电动车。</p>
  <p>但令马斯克意外的是，纽森政府计划在加州新版电动车激励政策中单独排除特斯拉，即购买特斯拉不能享受退税补贴。</p>
  <p>纽森办公室的官方解释是为了刺激更多车企推出电动车，促进电动车市场竞争，因此激励补助政策需要倾向那些市场份额较低的车企。作为加州电动车市场占据一半份额的龙头老大，特斯拉已经无需政府继续补助支持了。</p>
  <p>这一消息公布之后，特斯拉股价一度下跌了4%。因为加州不仅是美国最富裕的州，更占据了美国电动车市场的超过三分之一。加州今年第三季度电动车的渗透率已经达到了26.4%，几乎是美国整体市场的三倍。</p>
  <p>虽然特斯拉依然是加州电动车市场的领头羊，但却遭遇了销量下滑的困境。根据加州新车经销商协会的数据，今年前三个季度，特斯拉在加州共交付了15.9万辆新车，同比下滑了13%，是主要电动车企里面唯一销量下滑的。同期，特斯拉在加州电动车市场份额从63%下降至54.5%。而排名第二的现代和宝马，在加州电动车市场的份额仅为5.6%和5%。</p>
  <h2><strong>特斯拉享受多年补贴</strong></h2>
  <p>加州是特斯拉无法放弃的电动车市场。马斯克虽然支持特朗普取消所有电动车购置退税补助，但却对加州可能拒绝给特斯拉提供退税补助异常愤怒。在他看来，这是加州州长纽森故意针对自己，通过政府政策来公报私仇。</p>
  <p>纽森曾经是马斯克的好友，也是特斯拉的忠实用户。特斯拉在发展前期，从加州政府得到了数以亿计的政策扶持和补助，帮助当时财务困难的特斯拉度过了难关。</p>
  <p>一方面，加州政府人为抬高油价(加州油价比美国其他州都要高出近三分之一)，提供新能源补贴。购买电动车，安装太阳能面板都能得到政府的补贴。</p>
  <p>另一方面，加州还通过碳排放交易体系，逼迫燃油车企销售新能源车，或者花钱向特斯拉这样的电动车企购买排放指标，给起步阶段的特斯拉带来了数以十亿计的纯利润。</p>
  <p>过去十多年时间，纽森作为加州副州长和州长，直接负责新能源行业政策，更多次为特斯拉和马斯克站台。据前特斯拉高管帕特尔(Rohan Patel)回忆，纽森政府团队对特斯拉一直帮助有加。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_2f5bf90c7d154235bbe007040e60a8e5@1743780481_oswg719577oswg960oswg639_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>纽森自己也曾是特斯拉的忠实用户，购买了Roadster和Model S，家里还装了特斯拉的太阳能面板和储能设施。纽森并不需要公款购置这些，他在从政之前是个成功商人，在加州葡萄酒之乡纳帕拥有酒庄生意，个人资产超过2000万美元。</p>
  <h2><strong>政商好友反目成仇</strong></h2>
  <p>然而，在马斯克政治立场完全倒向共和党之后，他与纽森曾经良好的政商关系也在过去几年逐渐恶化，乃至彻底破裂。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_17ab4fba59504b0ab8839084336022f2@1743780481_oswg796827oswg1080oswg853_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在新冠疫情爆发之后，马斯克因为对加州政府的疫情政策(特斯拉工厂被迫停工)非常不满，与加州民主党人爆发了严重矛盾。从2021年开始，马斯克卖光了加州的七座豪宅，并且把特斯拉总部也搬到了德州。</p>
  <p>不过，特斯拉只是将行政总部搬到了德州超级工厂，研发工程团队依然留在硅谷总部，因为这里才是全球科技人才的聚集地。去年特斯拉更将其命名为“全球工程总部”。加州民主党议员因此嘲讽马斯克只是“假装搬迁”。</p>
  <p>马斯克与纽森关系彻底破裂，则是今年加州通过法律保护跨性别学生隐私，即禁止学校告诉家长他们孩子的性别认同与取向。本就因为孩子变性而痛恨“左派觉悟思想”(Woke Culture)的马斯克异常愤怒，再次公开炮轰加州政府，并公开宣布将X和SpaceX总部搬到德州。</p>
  <p>在马斯克这次挑衅之后，纽森终于开始回击。他在X平台上贴出了特朗普曾经对马斯克“差点下跪”的羞辱，嘲讽马斯克已经对特朗普卑躬屈膝，而马斯克则回击纽森“从来就没有站起来过”。在美国大选期间，纽森和马斯克又多次在X平台隔空叫阵，为自己支持的候选人抨击另一派。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_8ef2cb4d2d064950abe2b8fe0d0ab4a7@1743780481_oswg662676oswg1080oswg809_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最近加州州长纽森耐人寻味地公开称赞了加州的另外一家电动车企Rivian。“我想为Rivian所做的卓越工作鼓掌和表示感谢。特斯拉已经不再是这个领域的唯一企业。你们正在看到电动车行业竞争格局的显著变化。这完全是之前预料的情况，也是我们一直在推动的市场竞争。”</p>
  <p>虽然纽森没有把话说的太明显，但他的意思非常明确：加州消费者有很多的电动车可以选择，Rivian就是其中之一，并不是只买特斯拉。加州电动车市场的实际销量数据说明了一切。</p>
  <p>这番话或许可以解释为什么纽森政府计划在未来推出电动车购置补贴时，将特斯拉单独排除在外。不过，纽森政府的产业计划还需要得到加州议会的批准，最终版本或许还可能有变化。</p>
  <h2><strong>加州对抗特朗普政府</strong></h2>
  <p>可以肯定的是，在未来四年，特朗普政府和加州政府会在环保、移民等诸多问题上持续对抗。而马斯克可能会因为过于强烈的政治站队，越来越多地遭到加州政府的针对。</p>
  <p>加州在2022年通过立法规定，2030年新能源汽车销售比例达到三分之二，而在2035年全面禁售燃油新车。而特朗普则明确表示，上台计划就迫使加州放弃这一计划。双方势必将为此进行一场诉讼大战，最终交由最高法院定夺。</p>
  <p>加州民主党政府对于马斯克的抵触情绪已经越来越明显。上个月加州政府海岸委员会否决了SpaceX的增加火箭发射计划，拒绝SpaceX增加从加州空军基地发射火箭的数量。</p>
  <p>为了SpaceX，加州政府甚至还和五角大楼产生了争执。尽管美国军方表示在空军基地发射导弹是联邦政府行为，并不需要加州批准，但加州却官员认为SpaceX大部分火箭发射是用于他们公司的商业行为，因此必须得到加州批准。</p>
  <p>尽管美国军方表示会尽力帮助SpaceX化解环保问题(音爆问题会影响周边100英里范围)，但海岸委员会在否决SpaceX火箭发射计划的时候，却提到了马斯克明显右倾的政治立场、散播大选阴谋论和他对劳工工会的抵制态度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_3f46939ae0ca4739816692d6908a83bd@1743780481_oswg675595oswg1080oswg688_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>或许，遭受加州政府的排挤，就是马斯克倾力帮助特朗普赢下美国大选，获得巨大政治影响力的代价。或许，马斯克未来还会将更多业务撤出加州，搬到监管有利于自己的德州。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/NAQKpHfl7TGdrSkHN_SiNg" rel="noopener noreferrer nofollow" target="_blank">“新浪科技”</a>，作者：郑峻，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3061104970753413</id>
            <title>微软发明全新「LLM语言」，AI智能体交互效率翻倍</title>
            <link>https://www.36kr.com/p/3061104970753413</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3061104970753413</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Dec 2024 03:32:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: LLM, Droidspeak, 通信效率, 缓存复用  
<br><br>  
总结: 研究人员提出了一种名为"Droidspeak"的通信方式，旨在提高AI智能体之间的交流效率。通过直接传递模型中间的计算结果，而非转换为人类可理解的自然语言，Droidspeak使得模型的通信速度提高了2.78倍，同时保持了性能不变。该方法利用了智能体系统中不同模型间的相似性，允许在不损失精度的情况下复用缓存。最终，Droidspeak在预填充延迟和生成质量之间实现了良好的平衡，展示了其在智能体系统中的应用潜力。 </div>
                        <hr>
                    
                    <blockquote>
   <p>对于LLM来说，人类语言可能不是最好的交流媒介，正如《星战》中的机器人有自己的一套语言，近日，来自微软的研究人员改进了智能体间的交互方式，使模型的通信速度翻倍且不损失精度。</p>
  </blockquote>
  <p>在《星球大战》中，机器人R2-D2和其他机器人使用特殊的语言进行交流。</p>
  <p>这种语言主要由蜂鸣声和口哨声组成，被称为「二进制语」（Binary）或「机器人语」（Droidspeak）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_2417c71196c54157a265707aad1c3357@1743780481_oswg748006oswg971oswg539_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Droidspeak是专门为机器人之间的交流设计的，只有机器人能够完全理解其精确含义。</p>
  <p>电影中，C-3PO是唯一能够完全理解R2-D2语言的角色，而天行者等人类则是通过长期与R2-D2相处，逐渐能够猜测出它所表达的意思。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_b0fba159115745ac8f562de8ced314f8@1743780481_oswg798927oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>机器人之间的「专用」通信显然更加高效，那对于LLM来说，是否也应该如此？</p>
  <p>近日，来自微软、芝加哥大学的研究人员推出了「Droidspeak」，让AI智能体之间可以用自己的语言进行交流：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_874a9b5252bd490fa5061b497ec02367@1743780481_oswg67384oswg1055oswg305_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文地址：https://arxiv.org/pdf/2411.02820</p>
  <p>结果表明，在不损失性能的情况下，Droidspeak使模型的通信速度提高了2.78倍。</p>
  <p>所以，尽管人类用自然语言训练出了LLM，但用自然语言输出和交流，只是AI对于人类的一种「迁就」。</p>
  <h2><strong>Droidspeak</strong></h2>
  <p>下面是喜闻乐见的读论文环节。</p>
  <p>事先甩个锅，说「发明全新LLM语言」或有标题党之嫌，概括文章的思想，四个字足矣：缓存复用。</p>
  <p>再具体一些：在很多智能体系统中，不同的Agents其实是同源的，大家从同一个base model微调而来，参数的差距并不大。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_03e05bfe80554c8d9d5c1db762d0233a@1743780481_oswg42549oswg567oswg467_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>那么，相同的输入（经过差不多的weight）产生的计算结果也应该差不多。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_bee2299f28484060bbf5580d560edcb2@1743780481_oswg56056oswg943oswg297_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在智能体系统中，前一个Agent（sender）的输出，会作为后一个Agent（receiver）输入的一部分。</p>
  <p>而这部分需要prefill的计算，在之前其实已经做过了，那对于receiver来说，是不是能直接把sender的计算结果拿过来？</p>
  <p>——直接传递模型中间的计算结果（缓存），而不需要转换成人类能够理解的自然语言，这就是「Droidspeak」的含义。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_7ca48c8b5100411dacb249891fec8635@1743780481_oswg401110oswg763oswg499_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果您是相关领域研究者，看到这里基本就可以退出了，节约了您宝贵的时间。</p>
  <p>（但是小编走不了，毕竟稿费是按字数算的......）</p>
  <h3><strong>智能体面临的挑战</strong></h3>
  <p>高端的食材往往只需要最朴素的烹饪方式，而简单的idea往往得来并不简单。</p>
  <p>根据小学二年级学过的知识，LLM的推理可分为预填充（prefill）和解码（decode）两个阶段：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_3ab36c22c360451783eef8fc7cb0848f@1743780481_oswg33960oswg647oswg248_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>prefill是LLM拿你提出的问题（词向量序列），一股脑放进模型计算，填充所有层的kv cache；</p>
  <p>而decode是用最后一个词作为query，开始一个一个词往外蹦。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_1f677cf4447642bd84f48cc91330f6db@1743780481_oswg139891oswg743oswg517_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从计算的角度来看，预填充阶段是矩阵乘矩阵，为计算密集型；解码阶段是向量乘矩阵，相对来说访存变多。</p>
  <p>当我们长时间运行上下文密集的对话时，prefill的占比会越来越高，包括计算和通信的开销。</p>
  <p>所以在需要频繁交互的智能体系统中，prefill会成为瓶颈。</p>
  <p>比如，在HotpotQA数据集中，Llama-3-70B-Instruct的平均预填充延迟为2.16秒，而解码时间只有0.21秒；</p>
  <p>在MapCoder这种级联智能体系统中，前一个Agent的输出最多可达到38,000个token，从而导致极高的预填充延迟。</p>
  <h3><strong>亲子关系</strong></h3>
  <p>之前有工作探究过，利用kv cache来减少同一个模型的预填充延迟，这件事在智能体系统中貌似也能成立。</p>
  <p>先测试一下亲子之间的相似度。</p>
  <p>实验使用base model作为发送方，微调版本作为接收方，选择了下面四组模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_63c6dfab23984bec9f0bb53886a17545@1743780481_oswg94720oswg591oswg529_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>单从模型参数来看，绝对是亲生的，相似度差别都是小数点后三位的水平：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_2e7a66d6e5fa4d4b8df720b7659be087@1743780481_oswg23708oswg525oswg317_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>那么对于相同输入，中间的计算结果有多大差别？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_0002432898af4d12beabd5f89c3f73e6@1743780481_oswg47335oswg591oswg407_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这里的E cache指的是每层的输入，即E通过投影矩阵计算出QKV。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_20a545c9bd044641950e05309137628a@1743780481_oswg23133oswg545oswg297_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>相比于权重，每对模型的E cache和KV cache差别大了一点点，但也还好，那能不能直接复用呢？</p>
  <h3><strong>方法探索</strong></h3>
  <p>在最初的实验构建中，要求微调版本在测试基准上的表现比基础模型好得多，以便测试出复用缓存带来的影响。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_c53f2608ae7046b8a0d4b3abeff74562@1743780481_oswg185938oswg1080oswg386_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在此基础上，如果只是简单的复用全部的kv cache，效果稍显惨不忍睹，Fine-tuned Model的性能直接被打回原形：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_2a1acc5c5e5549a2a862d3e0b4345b4e@1743780481_oswg46543oswg589oswg295_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>看上去需要更加细致的操作，所以逐层分析一下E cache和KV cache的差别（注意是与base model的差别）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_1e75e07aa58c4cdfae6f288a60dd3785@1743780481_oswg63179oswg593oswg365_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>因为缓存的差异因层而异，所以优化的应用也要按层来，这里首先考虑重用KV cache的连续层（直到最后一层）。</p>
  <p>下图表明了重用KV cache带来的精度影响，效果很不错，但优化的自由度很低。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_123ac2a8b507490ebc502bd4c46865a0@1743780481_oswg67778oswg585oswg455_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>小编推测，这个「自由度低」的意思是：复用KV cache时，本层的输入（E cache）就不需要了，没有输入就没法算Q，就没法算下一层，所以后面也只能复用KV cache（直到最后一层）。</p>
  <p>所以，作者接下来就测试复用E cache的情况，因为有输入可以继续往下算，所以复用E cache时可以选择任意的起点和终点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_79b9791116d947f0b839f9daab2bddaa@1743780481_oswg212750oswg765oswg735_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如下图所示，每个点代表在一定程度的预填充延迟下的最佳精度。</p>
  <p>我们可以看到，重用E cache在保持生成质量的同时，将预填充延迟降低了1.8倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_25d8d779834a44779ba7500fc543b4fa@1743780481_oswg64367oswg583oswg423_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>最终方案</strong></h3>
  <p>作者表示，尽管重用 E cache在层方面提供了极大的灵活性，但它会在GPU内存、传输和计算方面产生开销。</p>
  <p>考虑发送方和接收方放置在两个GPU节点上，并通过Infiniband链路互连：</p>
  <p>在发送方，E cache需要先存储在GPU内存中（内存开销），发送E cache到接收方会产生额外的传输延迟；</p>
  <p>在接收端，还需要额外的QKV投影操作，将E cache转换为KV cache，这会导致额外的计算延迟。这三种类型的delay随着重用层的数量呈线性增长，如图12所示。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_63ca327c179c4b29ac92dafa5c869378@1743780481_oswg90795oswg1080oswg244_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与之相对，重用KV cache没啥额外开销，只是缺乏灵活性。</p>
  <p>所以，两种方法合体。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_46c4a46a19bc410e930c1aa06819f8e3@1743780481_oswg147405oswg1080oswg322_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>图13在预填充延迟和准确性权衡方面，比较了单独重用E cache与重用KV+E cache。</p>
  <p>对于实验的三对模型，重用KV+E cache在延迟和准确性方面效果良好，且不会增加发送方的GPU内存开销或接收方的计算开销。</p>
  <p>最后是端到端的整体架构：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_5d6a11e1a99e4a91af55c4fc6a56d79a@1743780481_oswg49544oswg539oswg411_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如图14所示，离线阶段，DroidSpeak首先在示例分析数据集上分析每对要重用的层（复用配置）；</p>
  <p>在线阶段，当发送方与接收方LLM通信时，会根据复用配置将KV和E缓存发送给接收方。</p>
  <p>然后，接收方会为那些不重用KV缓存的层重新计算新的KV缓存。</p>
  <p>下图展示了DroidSpeak相对于baseline的改进：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20241202/v2_dd65c42503c746b3873c2c06a8fe4d8d@1743780481_oswg141730oswg1080oswg246_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>我们可以看到，与完全预填充相比，DroidSpeak的预填充延迟减少了1.69到2.77倍，而不会影响生成质量（重用所有E缓存或KV缓存时，生成质量会大大降低）。</p>
  <p>水平虚线表示基础模型的生成质量，DroidSpeak的质量损失与基础模型和微调模型之间的差异相比微不足道。</p>
  <h3>参考资料：</h3>
  <p>https://singularityhub.com/2024/11/21/droidspeak-ai-agents-now-have-their-own-language-thanks-to-microsoft/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/suIXm71AoVXgLWtFX3wJwA" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：alan，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>