<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/2691937970793865</id>
            <title>苹果300亿参数大模型首亮相，还买了家AI公司｜焦点分析</title>
            <link>https://www.36kr.com/p/2691937970793865</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2691937970793865</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Mar 2024 09:29:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 大模型, AI, DarwinAI
<br>
<br>
总结: 苹果加速入局大模型战争，收购加拿大AI初创公司DarwinAI，扩充AI团队实力，发布多模态大模型领域的最新成果MM1，探索MoE架构，提高模型处理多模态数据的能力。苹果通过公开模型训练细节，打破大模型构建的不透明局面。 </div>
                        <hr>
                    
                    <p>文｜武静静</p><p>编辑｜邓咏仪</p><p>放弃造车后的苹果，正在加速入局大模型战争。</p><p>当地时间3月15日，苹果就披露了两个关键大模型动作。</p><p>其中一个值得关注的是苹果的收购事件。彭博社报道称，苹果已经收购了一家加拿大AI初创公司DarwinAI。</p><p>苹果的AI团队一下子扩充了几十个技术人员——作为收购交易的一部分，DarwinAI的几十名员工都被纳入苹果麾下，DarwinAI联合创始人、加拿大滑铁卢大学系统设计工程系教授Alexander Wong加盟苹果，担任AI团队的主管。</p><p>此前，DarwinAI的技术主要在视觉模型方向，他们此前主要给制造业提供零部件视觉检测的AI技术，致力于把AI系统打造得更小型和更快速。这符合此前苹果一直对外说的要打造更小的端侧大模型方向。</p><p><strong>“买买买”是苹果布局AI的思路之一</strong>，此前苹果已经陆续收购了Voysis、Curious AI、 AI Music、WaveOne等初创AI公司，来不断扩充自身的AI实力。</p><p>践行收购战略的同时，苹果也在不断加大自研技术的力度。被披露收购DarwinAI的同一时间，苹果低调的在arxiv.org网站上发布论文，<strong>官宣了在多模态大模型领域的最新成果。</strong></p><p>在论文《MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training》（MM1: 多模式LLM预训练的方法、分析和见解）中可以看到，MM1是一个图文的多模态大模型，参数规模有30亿、70亿、300亿三种大小，有图像识别和自然语言推理能力。</p><p>其中，参与该论文的作者有30人，一半以上都是华人。</p><h2><strong>MM1测试效果不如Gemini和GPT4V</strong></h2><p>和市面上其他大模型相比，<strong>MM1亮点并不在惊艳的效果上，也没有提出特别的技术路线，而是通过控制各种变量，做实验，找出影响模型效果中关键因素。</strong></p><p>在测试中，MM1-30B-Chat在TextVQA、SEED和MMMU上的表现优于Emu2-Chat37B和CogVLM-30B，<strong>但是表现不如谷歌的Gemini和OpenAI的GPT4V。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240316/v2_5d1b3bd2f4ac4ae790fa85972800265c@5261678_oswg241925oswg1080oswg1041_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">MM1测试效果</p><p>苹果做了各种变量实验，通过修改数据源、修改图像分辨率等，来看各种因素对模型效果的影响。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240316/v2_db05869c51444ef598273186bcf506a1@5261678_oswg61748oswg942oswg529_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△摘自苹果发布的论文《MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training》</p><p>目前，苹果发现让多模态大模型变得更聪明、效果更好的主要因素有：</p><ul><li><strong>图像分辨率和图像标记数量</strong>对模型性能影响较大，比如更高清的图像，标注的细节越多，模型的效果就更好。</li><li><strong>视觉语言连接器对模型的影响较小</strong>，视觉语言连接器指的是可以将图像和文本结合起来，进行信息融合的一种技术。论文中也提到，虽然影响不大，但仍然需要选择合适的视觉语言连接器。</li><li><strong>不同类型的预训练数据</strong>对模型的性能有不同的影响。交错的图像文本数据和文本数据对于提高模型的少样本（few-shot）和零样本（zero-shot）性能至关重要，类似在训练时，需要使用“多样化的教材”可以帮助大模型更好地适应不同类型的问题。</li><li><strong>模型的架构和训练过程</strong>，包括模型大小和训练超参数的选择，对于模型性能很重要，可以理解为在“建造大模型大楼”的过程中，需要选择“合适的建筑材料”和“施工方法”。</li></ul><p>模型架构上，使用了<strong>混合专家（Mixture of Experts, MoE）架构是MM1的亮点之一</strong>，苹果探索发现，在模型的前馈网络层中使用MoE架构，可以有效地扩展模型的容量而不牺牲推理速度。</p><p>我们可以将MoE架构理解为一个<strong>大型的客服中心</strong>，其中有许多专门处理不同问题的专家——有的专家专门处理技术问题，有的专家处理账单查询，还有的专家负责解答产品使用问题。在大模型训练过程中，当数据进入模型中后，大模型会像“客服中心”一样，根据问题的性质被分配给最合适的专家来解决。</p><p>在实验过程中，苹果采用了一种<strong>名为Top-2 Gating的方法，来做“调度员”</strong>，根据图像的内容和文本语义等数据特点，来决定输入数据应该被送往哪些专家处理。在处理数据过程中，苹果还采用了一种<strong>叫“稀疏激活”的方式</strong>，只选择一部分“专家”进行计算，其余处于“休眠”状态，来提高模型训练的效率。</p><p>此外，在训练大模型过程中，苹果还在3B参数的MoE模型中使用了64个专家，在7B参数的MoE模型中使用了32个专家。这些专家被分布在模型的不同层中，来提高模型处理多模态数据的能力。</p><p><strong>为什么苹果要发布这样一篇实验性的技术论文？</strong></p><p>目前，语言模型主要有闭源和开源两种路线，闭源模型中，人们对数据、模型架构、训练细节知之甚少。开源模型虽然会发布数据、模型、训练的细节，但是也不会发布任何模型算法设计以及工程化的细节信息。</p><p>苹果想打破这种局面，提出让大模型构建的过程变得“更透明”的路线，这是苹果为什么将各种模型训练的细节公开，发布这篇论文的原因。</p><h2><strong>苹果的大模型步调：更谨慎，落后于竞争对手</strong></h2><p>宣布停止造车后，接下来，苹果的重心都在加速大模型进程上，来追赶谷歌、微软、亚马逊。</p><p>目前，整体大模型进展，苹果对外的信息较少，看上去已经落后其竞争对手一大截。</p><p>在年初的苹果季度财报电话会议上，蒂姆·库克表示，苹果正在投入大量时间和精力将人工智能集成到其软件平台中。这些功能将在2024年晚些时候向客户提供。</p><p>库克对于透露苹果大模型细节非常谨慎，他觉得苹果<strong>工作模式是先做再说</strong>，“我认为苹果在生成式人工智能和人工智能方面存在着巨大的机会，而无需透露更多细节或超出自己的范围。”</p><p>据The Information2023年9月的一次报道，苹果每天在人工智能上投资数百万美元，正在多个团队开发多种人工智能模型。苹果构建对话式人工智能的部门被称为“基础模型”，有大约16名成员，由Apple人工智能主管John Giannandrea掌舵。</p><p>对于大众期待的大模型与苹果手机结合的业务进展，目前公开的信息也非常有限。去年8月，苹果在加州、西雅图、巴黎、北京等部门已经释放了数十个岗位，招聘大模型技术人才，<strong>其中尤其是端侧大型模型是重点</strong>。招聘信息显示，苹果希望将大型机型压缩到终端中，以便未来iPhone/iPad等核心产品可以直接运行在AIGC技术上。</p><p>The Information报道称，苹果的大语言模型内部代号是Ajax GPT，其参数规模超过2000亿，在2023年9月时，已经比OpenAI的GPT-3.5更强大。</p><p>苹果也正在试验Siri增强功能、生成视频和图像的软件，以及处理图像、视频和文本的多模式人工智能技术。此前，由于苹果一直比竞争对手更加谨慎，将隐私置于功能之上，导致Siri落后于Alexa、Google Assistan。接下来，苹果希望通过大语言模型让Siri自动执行多步骤任务。</p><p>目前，苹果正在与其AppleCare支持员工一起测试ChatGPT式的生成式AI工具“Ask”，旨在生成对技术问题的答复。此外，苹果内部也有“Apple GPT”是苹果内部的聊天机器人，但该产品仅供苹果员工使用，不会在消费产品中使用。</p><p>The Information和海通证券分析师Jeff Pu均表示，苹果将在2024年末左右在iPhone和iPad上提供某种生成式AI功能。也有人预测时间会提前，彭博社报道称，苹果将在今年6月的全球开发者大会上发布iOS 18更新。</p><p>这是一份有挑战的试卷，眼下，苹果必须加大马力，驶入这场大模型战局中。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240316/v2_1717980e304141238d0905a1fb7a6edd@5261678_oswg61549oswg900oswg335_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">欢迎来聊～</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>