<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1743193413615521829#m</id>
            <title>AI资讯日报，1月5日：https://gorden-sun.notion.site/1-5-AI-f6124b24c6644328bbd1a3b854065401?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1743193413615521829#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1743193413615521829#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 08:51:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，1月5日：<a href="https://gorden-sun.notion.site/1-5-AI-f6124b24c6644328bbd1a3b854065401?pvs=4">gorden-sun.notion.site/1-5-A…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RFUktTS2JrQUFWX1EwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1743191888574947632#m</id>
            <title>大模型降本增效综述：这篇论文总结了降低LLM资源消耗、提升LLM效率的相关方法。
（这论文也太好写了吧）
论文：https://arxiv.org/abs/2401.00625
提到的论文列表：https://github.com/tiingweii-shii/Awesome-Resource-Efficient-LLM-Papers</title>
            <link>https://nitter.cz/Gorden_Sun/status/1743191888574947632#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1743191888574947632#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 08:45:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大模型降本增效综述：这篇论文总结了降低LLM资源消耗、提升LLM效率的相关方法。<br />
（这论文也太好写了吧）<br />
论文：<a href="https://arxiv.org/abs/2401.00625">arxiv.org/abs/2401.00625</a><br />
提到的论文列表：<a href="https://github.com/tiingweii-shii/Awesome-Resource-Efficient-LLM-Papers">github.com/tiingweii-shii/Aw…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RFUGFjSWFvQUFGeE1HLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1743189732329439598#m</id>
            <title>WizardCoder发布V1.1版本，33B大小，能力接近ChatGPT-3.5，超过Gemini Pro，是目前最好的开源代码模型。
Github：https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder
模型：https://huggingface.co/WizardLM/WizardCoder-33B-V1.1</title>
            <link>https://nitter.cz/Gorden_Sun/status/1743189732329439598#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1743189732329439598#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 08:36:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WizardCoder发布V1.1版本，33B大小，能力接近ChatGPT-3.5，超过Gemini Pro，是目前最好的开源代码模型。<br />
Github：<a href="https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder">github.com/nlpxucan/WizardLM…</a><br />
模型：<a href="https://huggingface.co/WizardLM/WizardCoder-33B-V1.1">huggingface.co/WizardLM/Wiza…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RFTmhWWmEwQUE5bXgyLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1743182774813835442#m</id>
            <title>VideoDB：适用于LLM的视频基础设施
提供的是API服务，只需要上传视频，VideoDB来处理视频，提供LLM可使用的信息，例如查询什么位置有日出。没有公开实现方法。
官网：https://videodb.io/
Github：https://github.com/video-db/videodb-python</title>
            <link>https://nitter.cz/Gorden_Sun/status/1743182774813835442#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1743182774813835442#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 08:08:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>VideoDB：适用于LLM的视频基础设施<br />
提供的是API服务，只需要上传视频，VideoDB来处理视频，提供LLM可使用的信息，例如查询什么位置有日出。没有公开实现方法。<br />
官网：<a href="https://videodb.io/">videodb.io/</a><br />
Github：<a href="https://github.com/video-db/videodb-python">github.com/video-db/videodb-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RFSGVfb2JJQUFlbGhGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1743148719959429131#m</id>
            <title>我对AI伴侣/虚拟人/助手的期待，想法不复杂，实现也不难，为什么还没出现类似的APP？</title>
            <link>https://nitter.cz/Gorden_Sun/status/1743148719959429131#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1743148719959429131#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 05:53:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我对AI伴侣/虚拟人/助手的期待，想法不复杂，实现也不难，为什么还没出现类似的APP？</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REb1VjRmJBQUFrLWRULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mranti/status/1743098940554408314#m</id>
            <title>RT by @Gorden_Sun: 我觉得中国小家电行业的人都得看这个视频，这就是未来，5年之内，就应该有家政机器人出现了。</title>
            <link>https://nitter.cz/mranti/status/1743098940554408314#m</link>
            <guid isPermaLink="false">https://nitter.cz/mranti/status/1743098940554408314#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 02:35:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我觉得中国小家电行业的人都得看这个视频，这就是未来，5年之内，就应该有家政机器人出现了。</p>
<p><a href="https://nitter.cz/zipengfu/status/1742973258528612724#m">nitter.cz/zipengfu/status/1742973258528612724#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/ZHOZHO672070/status/1742884117191004644#m</id>
            <title>RT by @Gorden_Sun: 🔥ComfyUI ArtGallery 1.0正式版 来啦！
🤣Prompt Visualization 提示词可视化：对于很多不熟悉艺术的小伙伴来说，面对众多陌生的的选项时，没有参考和预览是一件是非头疼的事，并且还只能等生成之后才能做出判断
🌟现在只需选择喜欢的图像，滑动选择权重，节点会自动输出提示词，助你自由探索艺术世界</title>
            <link>https://nitter.cz/ZHOZHO672070/status/1742884117191004644#m</link>
            <guid isPermaLink="false">https://nitter.cz/ZHOZHO672070/status/1742884117191004644#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 12:22:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔥ComfyUI ArtGallery 1.0正式版 来啦！<br />
🤣Prompt Visualization 提示词可视化：对于很多不熟悉艺术的小伙伴来说，面对众多陌生的的选项时，没有参考和预览是一件是非头疼的事，并且还只能等生成之后才能做出判断<br />
🌟现在只需选择喜欢的图像，滑动选择权重，节点会自动输出提示词，助你自由探索艺术世界</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI4ODM4MTEwNDAzNjY1OTMvcHUvaW1nL0JnLWc0VThORGcyRXNZZmguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742904738281320698#m</id>
            <title>ComfyUI工作流的下载链接：https://drive.google.com/file/d/1ysc1C5E4qdNvtKKEDAbHyUYLc7SnbPUX/view?pli=1</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742904738281320698#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742904738281320698#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 13:44:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI工作流的下载链接：<a href="https://drive.google.com/file/d/1ysc1C5E4qdNvtKKEDAbHyUYLc7SnbPUX/view?pli=1">drive.google.com/file/d/1ysc…</a></p>
<p><a href="https://nitter.cz/op7418/status/1742891365485494444#m">nitter.cz/op7418/status/1742891365485494444#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742873702621126924#m</id>
            <title>RT by @Gorden_Sun: SD A1111 Controlnet 更新了手部修复的预处理器depth_hand_refiner，现在可以在 Web UI 里面对出问题的手进行修复了。

如何使用：
在图生图 Tab 选择inpaint，然后给需要修复的手部涂上蒙版，然后在 Contorlnet 选择depth_hand_refiner 预处理器，点击生成就可以了。</title>
            <link>https://nitter.cz/op7418/status/1742873702621126924#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742873702621126924#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 11:40:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SD A1111 Controlnet 更新了手部修复的预处理器depth_hand_refiner，现在可以在 Web UI 里面对出问题的手进行修复了。<br />
<br />
如何使用：<br />
在图生图 Tab 选择inpaint，然后给需要修复的手部涂上蒙版，然后在 Contorlnet 选择depth_hand_refiner 预处理器，点击生成就可以了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfdUVnb2FJQUFQaC1sLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfdVVhWGFBQUFNcUVGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742859637467255213#m</id>
            <title>微软这是要把键盘左侧的Windows键换成Copilot键？</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742859637467255213#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742859637467255213#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 10:44:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软这是要把键盘左侧的Windows键换成Copilot键？</p>
<p><a href="https://nitter.cz/yusuf_i_mehdi/status/1742819477681582198#m">nitter.cz/yusuf_i_mehdi/status/1742819477681582198#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742840316485566730#m</id>
            <title>AI资讯日报，1月4日：https://gorden-sun.notion.site/1-4-AI-b95e3dbd45ff4091ac10d211395e1cb2?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742840316485566730#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742840316485566730#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:28:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，1月4日：<a href="https://gorden-sun.notion.site/1-4-AI-b95e3dbd45ff4091ac10d211395e1cb2?pvs=4">gorden-sun.notion.site/1-4-A…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfUUJUN2F3QUFfa0M1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742833536368029842#m</id>
            <title>Self-Extend：无需训练和微调，仅通过几行代码，即可提升LLM context的有效长度
不是提升LLM的上下文长度，是减少了上下文长度的退化。方法看起来异常的简单，只是后移了token的位置（在更远的地方建索引）
论文：https://arxiv.org/abs/2401.01325</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742833536368029842#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742833536368029842#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:01:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Self-Extend：无需训练和微调，仅通过几行代码，即可提升LLM context的有效长度<br />
不是提升LLM的上下文长度，是减少了上下文长度的退化。方法看起来异常的简单，只是后移了token的位置（在更远的地方建索引）<br />
论文：<a href="https://arxiv.org/abs/2401.01325">arxiv.org/abs/2401.01325</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfSnk0emJjQUFtQmpBLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfSjJaY2JvQUFzMkZuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742821932695990288#m</id>
            <title>这篇论文总结了减少LLM幻觉的32种方法，包括RAG、微调模型，提示词工程等。
论文：https://arxiv.org/abs/2401.01313</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742821932695990288#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742821932695990288#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 08:15:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这篇论文总结了减少LLM幻觉的32种方法，包括RAG、微调模型，提示词工程等。<br />
论文：<a href="https://arxiv.org/abs/2401.01313">arxiv.org/abs/2401.01313</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MtX0hxaWFnQUFULV9OLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742819283477139946#m</id>
            <title>E5-mistral-7b-instruct：使用合成数据训练的Embedding模型
亮点是仅使用LLM生成的数据即可实现不错的效果，使用合成数据+标记数据训练可以实现SOTA。
大小比其他模型大10倍，性能也仅是微弱提升。更大的意义是实践了合成数据的作用。
论文：https://arxiv.org/abs/2401.00368
模型：https://huggingface.co/intfloat/e5-mistral-7b-instruct</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742819283477139946#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742819283477139946#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 08:04:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>E5-mistral-7b-instruct：使用合成数据训练的Embedding模型<br />
亮点是仅使用LLM生成的数据即可实现不错的效果，使用合成数据+标记数据训练可以实现SOTA。<br />
大小比其他模型大10倍，性能也仅是微弱提升。更大的意义是实践了合成数据的作用。<br />
论文：<a href="https://arxiv.org/abs/2401.00368">arxiv.org/abs/2401.00368</a><br />
模型：<a href="https://huggingface.co/intfloat/e5-mistral-7b-instruct">huggingface.co/intfloat/e5-m…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MtODVDWWEwQUFpdWdwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742813091170308211#m</id>
            <title>之前的辐射渲染，可以合成高质量的图片和3D场景，但是训练成本高，渲染时间长。
新兴的高斯泼溅，可以实时渲染，但是存在图片模糊的情况。
Deblurring-3D-Gaussian-Splatting提出了新的实时去模糊框架，可以实现高质量实时渲染。
项目地址：https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/
论文：https://arxiv.org/abs/2401.00834</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742813091170308211#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742813091170308211#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 07:39:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前的辐射渲染，可以合成高质量的图片和3D场景，但是训练成本高，渲染时间长。<br />
新兴的高斯泼溅，可以实时渲染，但是存在图片模糊的情况。<br />
Deblurring-3D-Gaussian-Splatting提出了新的实时去模糊框架，可以实现高质量实时渲染。<br />
项目地址：<a href="https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/">benhenryl.github.io/Deblurri…</a><br />
论文：<a href="https://arxiv.org/abs/2401.00834">arxiv.org/abs/2401.00834</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI4MTMwNjU3NTcwMzY1NDQvcHUvaW1nL051M2VLU3FSUDQtYjNiQVcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/tonyzzhao/status/1742603121682153852#m</id>
            <title>RT by @Gorden_Sun: Introducing 𝐌𝐨𝐛𝐢𝐥𝐞 𝐀𝐋𝐎𝐇𝐀🏄 -- Hardware!
A low-cost, open-source, mobile manipulator.

One of the most high-effort projects in my past 5yrs! Not possible without co-lead @zipengfu and @chelseabfinn.

At the end, what's better than cooking yourself a meal with the 🤖🧑‍🍳</title>
            <link>https://nitter.cz/tonyzzhao/status/1742603121682153852#m</link>
            <guid isPermaLink="false">https://nitter.cz/tonyzzhao/status/1742603121682153852#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 17:45:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Introducing 𝐌𝐨𝐛𝐢𝐥𝐞 𝐀𝐋𝐎𝐇𝐀🏄 -- Hardware!<br />
A low-cost, open-source, mobile manipulator.<br />
<br />
One of the most high-effort projects in my past 5yrs! Not possible without co-lead <a href="https://nitter.cz/zipengfu" title="Zipeng Fu">@zipengfu</a> and <a href="https://nitter.cz/chelseabfinn" title="Chelsea Finn">@chelseabfinn</a>.<br />
<br />
At the end, what's better than cooking yourself a meal with the 🤖🧑‍🍳</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI1OTQzNzA4MjQ3NTMxNTMvcHUvaW1nL2d3X0JnTG4tZzhNMlk3WkguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742484602193920101#m</id>
            <title>AI资讯日报，1月3日：https://gorden-sun.notion.site/1-3-AI-c2a34f21403543ee8b7e15507df3d1e1?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742484602193920101#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742484602193920101#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 09:54:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，1月3日：<a href="https://gorden-sun.notion.site/1-3-AI-c2a34f21403543ee8b7e15507df3d1e1?pvs=4">gorden-sun.notion.site/1-3-A…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M2TWdETWF3QUFPVndWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742479464452563229#m</id>
            <title>DiffusionLight：检测图片中的光源
使用ControlNet的Depth模型，通过在图片中画一个反光金属球，实现了目前效果最好的光源检测。
应用场景：可以根据光源，把物体插入到图片中，遵循相同的光影效果。
项目地址：https://diffusionlight.github.io/
Github：https://github.com/DiffusionLight/DiffusionLight</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742479464452563229#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742479464452563229#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 09:34:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DiffusionLight：检测图片中的光源<br />
使用ControlNet的Depth模型，通过在图片中画一个反光金属球，实现了目前效果最好的光源检测。<br />
应用场景：可以根据光源，把物体插入到图片中，遵循相同的光影效果。<br />
项目地址：<a href="https://diffusionlight.github.io/">diffusionlight.github.io/</a><br />
Github：<a href="https://github.com/DiffusionLight/DiffusionLight">github.com/DiffusionLight/Di…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI0Nzk0MDk1OTkzOTM3OTIvcHUvaW1nLzNZTDJfLVdiVkw0ZkJ3S3cuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742475555885474203#m</id>
            <title>通过文本、图片、音频、视频都能生成音乐，听起来很厉害，实际对于seq2seq来说是“基操勿六”。
seq2seq是信息的万物互连，没有中介。例如英文语音翻译成中文语音，人脑里至少要经过英文语音->中文文字->中文语音的过程，但对于seq2seq来说，只需要英文语音->中文语音。
seq2seq应该叫anything2anything</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742475555885474203#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742475555885474203#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 09:18:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>通过文本、图片、音频、视频都能生成音乐，听起来很厉害，实际对于seq2seq来说是“基操勿六”。<br />
seq2seq是信息的万物互连，没有中介。例如英文语音翻译成中文语音，人脑里至少要经过英文语音-&gt;中文文字-&gt;中文语音的过程，但对于seq2seq来说，只需要英文语音-&gt;中文语音。<br />
seq2seq应该叫anything2anything</p>
<p><a href="https://nitter.cz/_akhaliq/status/1742209475283423556#m">nitter.cz/_akhaliq/status/1742209475283423556#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742472101100224720#m</id>
            <title>MathPile：用于提升LLM数学能力的语料库
包含10亿token的语料，包括教科书、arXiv、维基百科等多种来源的数学内容，目标是提升LLM的数学推理能力。
项目地址：https://gair-nlp.github.io/MathPile/
Github：https://github.com/GAIR-NLP/MathPile/
语料库：https://huggingface.co/datasets/GAIR/MathPile</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742472101100224720#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742472101100224720#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 09:04:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MathPile：用于提升LLM数学能力的语料库<br />
包含10亿token的语料，包括教科书、arXiv、维基百科等多种来源的数学内容，目标是提升LLM的数学推理能力。<br />
项目地址：<a href="https://gair-nlp.github.io/MathPile/">gair-nlp.github.io/MathPile/</a><br />
Github：<a href="https://github.com/GAIR-NLP/MathPile/">github.com/GAIR-NLP/MathPile…</a><br />
语料库：<a href="https://huggingface.co/datasets/GAIR/MathPile">huggingface.co/datasets/GAIR…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M2QklZV2JVQUFyX2cxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>