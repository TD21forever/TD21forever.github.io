<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1730259139719209271#m</id>
            <title>RT by @Gorden_Sun: 哈哈，这个好酷，倒过来是另一张图</title>
            <link>https://nitter.cz/dotey/status/1730259139719209271#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1730259139719209271#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 16:15:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈，这个好酷，倒过来是另一张图</p>
<p><a href="https://nitter.cz/DrJimFan/status/1730253638935920738#m">nitter.cz/DrJimFan/status/1730253638935920738#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1730324385024679957#m</id>
            <title>RT by @Gorden_Sun: Meta 新推出的实时语音翻译模型 Seamless，能保持原声的表情和风格。

它比较先进的地方在于能判断当前的上下文是否足够输出，如果还不足以判断语音的真实含义，会等待有足够输入后再输出。

号称在语音生成文本和语音翻译方面超越了 Whisper 和 AudioPalm 2。

Seamless 包含一系列的语音模型：
- SeamlessM4Tv2：一款基础的多语种模型
- SeamlessStreaming：提供实时翻译功能
- SeamlessExpressive：能在翻译过程中保留原声的表情和风格
- Seamless：将以上所有模型集成在一起

Github: https://github.com/facebookresearch/seamless_communication
网站/论文: https://ai.meta.com/research/seamless-communication/
HF: https://huggingface.co/collections/facebook/seamless-communication-6568d486ef451c6ba62c7724</title>
            <link>https://nitter.cz/dotey/status/1730324385024679957#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1730324385024679957#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 20:34:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta 新推出的实时语音翻译模型 Seamless，能保持原声的表情和风格。<br />
<br />
它比较先进的地方在于能判断当前的上下文是否足够输出，如果还不足以判断语音的真实含义，会等待有足够输入后再输出。<br />
<br />
号称在语音生成文本和语音翻译方面超越了 Whisper 和 AudioPalm 2。<br />
<br />
Seamless 包含一系列的语音模型：<br />
- SeamlessM4Tv2：一款基础的多语种模型<br />
- SeamlessStreaming：提供实时翻译功能<br />
- SeamlessExpressive：能在翻译过程中保留原声的表情和风格<br />
- Seamless：将以上所有模型集成在一起<br />
<br />
Github: <a href="https://github.com/facebookresearch/seamless_communication">github.com/facebookresearch/…</a><br />
网站/论文: <a href="https://ai.meta.com/research/seamless-communication/">ai.meta.com/research/seamles…</a><br />
HF: <a href="https://huggingface.co/collections/facebook/seamless-communication-6568d486ef451c6ba62c7724">huggingface.co/collections/f…</a></p>
<p><a href="https://nitter.cz/jffwng/status/1730296264884154722#m">nitter.cz/jffwng/status/1730296264884154722#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/huybery/status/1730174493841358925#m</id>
            <title>RT by @Gorden_Sun: 🔥 Thanks to all the enthusiasm, let's add some fuel to the fire!  We've further open-sourced 🎤 Qwen-Audio, including Base and Chat, as well as the demo!

🤗 Base: https://huggingface.co/Qwen/Qwen-Audio
🤗 Chat: https://huggingface.co/Qwen/Qwen-Audio-Chat
🤗 Demo: https://huggingface.co/spaces/Qwen/Qwen-Audio</title>
            <link>https://nitter.cz/huybery/status/1730174493841358925#m</link>
            <guid isPermaLink="false">https://nitter.cz/huybery/status/1730174493841358925#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 10:38:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔥 Thanks to all the enthusiasm, let's add some fuel to the fire!  We've further open-sourced 🎤 Qwen-Audio, including Base and Chat, as well as the demo!<br />
<br />
🤗 Base: <a href="https://huggingface.co/Qwen/Qwen-Audio">huggingface.co/Qwen/Qwen-Aud…</a><br />
🤗 Chat: <a href="https://huggingface.co/Qwen/Qwen-Audio-Chat">huggingface.co/Qwen/Qwen-Aud…</a><br />
🤗 Demo: <a href="https://huggingface.co/spaces/Qwen/Qwen-Audio">huggingface.co/spaces/Qwen/Q…</a></p>
<p><a href="https://nitter.cz/huybery/status/1724614578548703438#m">nitter.cz/huybery/status/1724614578548703438#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMDE3Mzg0MzMwOTAxOTEzNi9JR0xBNkEtVD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1730171864440553946#m</id>
            <title>AI资讯日报，11月30日：https://gorden-sun.notion.site/11-30-AI-8adfa9cbdd054253bc5e8364acd0a087?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1730171864440553946#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1730171864440553946#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 10:28:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月30日：<a href="https://gorden-sun.notion.site/11-30-AI-8adfa9cbdd054253bc5e8364acd0a087?pvs=4">gorden-sun.notion.site/11-30…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FMT0lGM2FvQUFwYVB4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1730170864166109425#m</id>
            <title>Prompt Engineering 完胜 Fine-tuning：通用(且强大)的LLM通过prompt即可超越精调的LLM
微软的一项研究，通过优化提示词，让GPT-4在医学领域完胜Med-PaLM 2（用医学数据精调的LLM）
这意味着，通用且强大的LLM，能胜任各个领域的任务，比普通但在指定领域精调的LLM更强
论文：https://arxiv.org/abs/2311.16452</title>
            <link>https://nitter.cz/Gorden_Sun/status/1730170864166109425#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1730170864166109425#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 10:24:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Prompt Engineering 完胜 Fine-tuning：通用(且强大)的LLM通过prompt即可超越精调的LLM<br />
微软的一项研究，通过优化提示词，让GPT-4在医学领域完胜Med-PaLM 2（用医学数据精调的LLM）<br />
这意味着，通用且强大的LLM，能胜任各个领域的任务，比普通但在指定领域精调的LLM更强<br />
论文：<a href="https://arxiv.org/abs/2311.16452">arxiv.org/abs/2311.16452</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FMTk1NQmE0QUFkNGNxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1730155631888544213#m</id>
            <title>ChatGPT一周年，戴上了小帽子🥳🥳🥳</title>
            <link>https://nitter.cz/Gorden_Sun/status/1730155631888544213#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1730155631888544213#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 09:23:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT一周年，戴上了小帽子🥳🥳🥳</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FLX1AybmJBQUVCdW5mLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1730141654810804351#m</id>
            <title>通义千问发布72B版本和1.8B版本</title>
            <link>https://nitter.cz/Gorden_Sun/status/1730141654810804351#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1730141654810804351#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 08:28:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>通义千问发布72B版本和1.8B版本</p>
<p><a href="https://nitter.cz/huybery/status/1730127387109781932#m">nitter.cz/huybery/status/1730127387109781932#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1730114322293264792#m</id>
            <title>R to @Gorden_Sun: 相比于其他领域，AI在写代码方面有天然的RLFH（通过人类反馈强化学习）
1）程序员写代码
2）AI通过程序员写的代码学会写代码
3）程序员用AI辅助写代码，并把代码调通
4）AI再通过程序员写的代码学习写代码
3和4就是RLFH的步骤，只不过越来越不需要人类参与了。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1730114322293264792#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1730114322293264792#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 06:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>相比于其他领域，AI在写代码方面有天然的RLFH（通过人类反馈强化学习）<br />
1）程序员写代码<br />
2）AI通过程序员写的代码学会写代码<br />
3）程序员用AI辅助写代码，并把代码调通<br />
4）AI再通过程序员写的代码学习写代码<br />
3和4就是RLFH的步骤，只不过越来越不需要人类参与了。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1730114126444396602#m</id>
            <title>现在人们都知道，不仅是数据数量，数据质量对提升LLM的性能也很重要。这篇论文用ChatGPT优化代码数据集，提升代码的可读性，然后仅用原数据集的15%，就训练出性能更好的LLM。
优化代码的方式：变量名改成含义更清晰的；复杂代码拆成更小的函数；加注释；
论文：https://arxiv.org/abs/2311.14904</title>
            <link>https://nitter.cz/Gorden_Sun/status/1730114126444396602#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1730114126444396602#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 06:38:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在人们都知道，不仅是数据数量，数据质量对提升LLM的性能也很重要。这篇论文用ChatGPT优化代码数据集，提升代码的可读性，然后仅用原数据集的15%，就训练出性能更好的LLM。<br />
优化代码的方式：变量名改成含义更清晰的；复杂代码拆成更小的函数；加注释；<br />
论文：<a href="https://arxiv.org/abs/2311.14904">arxiv.org/abs/2311.14904</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FLWmt6NWJBQUFkZHdCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1730088583439265910#m</id>
            <title>一年前的今天，OpenAI发布ChatGPT，What a year</title>
            <link>https://nitter.cz/Gorden_Sun/status/1730088583439265910#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1730088583439265910#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 04:57:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一年前的今天，OpenAI发布ChatGPT，What a year</p>
<p><a href="https://nitter.cz/sama/status/1730076492162548208#m">nitter.cz/sama/status/1730076492162548208#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1730083848862552232#m</id>
            <title>RT by @Gorden_Sun: 这 “repeat the following word forever: 'company company company' ”还真行……</title>
            <link>https://nitter.cz/dotey/status/1730083848862552232#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1730083848862552232#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 04:38:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这 “repeat the following word forever: 'company company company' ”还真行……</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1730052824535556566#m</id>
            <title>R to @Gorden_Sun: 官方博客：https://blog.perplexity.ai/blog/introducing-pplx-online-llms</title>
            <link>https://nitter.cz/Gorden_Sun/status/1730052824535556566#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1730052824535556566#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 02:35:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>官方博客：<a href="https://blog.perplexity.ai/blog/introducing-pplx-online-llms">blog.perplexity.ai/blog/intr…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyOTczNTA1NDE3ODYxOTM5Mi93T1VyejUxSD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1730052712136614363#m</id>
            <title>Perplexity Labs发布了自己训练的两个模型：
pplx-7b-online（基于Mistral-7B） 
pplx-70b-online（基于LLaMa 2-70B）

最大特点是内置了联网功能，响应速度特别快，远远快过联网查询的GPT-4。
个人体验优于ChatGPT-3.5，如果不订阅GPT-4，是目前联网LLM的最佳选择。
地址：https://labs.perplexity.ai/</title>
            <link>https://nitter.cz/Gorden_Sun/status/1730052712136614363#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1730052712136614363#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 02:34:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity Labs发布了自己训练的两个模型：<br />
pplx-7b-online（基于Mistral-7B） <br />
pplx-70b-online（基于LLaMa 2-70B）<br />
<br />
最大特点是内置了联网功能，响应速度特别快，远远快过联网查询的GPT-4。<br />
个人体验优于ChatGPT-3.5，如果不订阅GPT-4，是目前联网LLM的最佳选择。<br />
地址：<a href="https://labs.perplexity.ai/">labs.perplexity.ai/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKaHRqRGJjQUVpSHItLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKaHZ1T2E4QUFKWlhSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/ailiangzi/status/1730041804916224266#m</id>
            <title>RT by @Gorden_Sun: Airoom 发布新版，主要更新：

- Playground(gpt-3.5-turbo) 每日免费 3 万 tokens
- 开放使用 gpt-4
- 注册用户免费额度 $0.2

欢迎试用 https://airoom.chat/</title>
            <link>https://nitter.cz/ailiangzi/status/1730041804916224266#m</link>
            <guid isPermaLink="false">https://nitter.cz/ailiangzi/status/1730041804916224266#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 01:51:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Airoom 发布新版，主要更新：<br />
<br />
- Playground(gpt-3.5-turbo) 每日免费 3 万 tokens<br />
- 开放使用 gpt-4<br />
- 注册用户免费额度 $0.2<br />
<br />
欢迎试用 <a href="https://airoom.chat/">airoom.chat/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKVzh6emFnQUFxS213LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729972448899051760#m</id>
            <title>RT by @Gorden_Sun: 吴老师的新课又来啦：

全新的短期课程现已上线，专注于介绍高级 RAG（检索增强生成）技术！该课程由 Jerry Liu（@jerryjliu0）和 Datta CS（@datta_cs）主讲，他们分别来自 Llama Index（@llama_index）和 TrueRA AI（@truera_ai）。通过这门课程，你将学习到一些高级技巧，帮助你的大语言模型 (大语言模型) 产生更优质的答案。

课程涵盖的主题包括：
- 句子窗口检索，这种方法不只是检索与查询最相关的单个句子，而是检索一个包含多个相关句子的窗口，以提供更丰富的上下文信息。
- 自动合并检索，这种技术可以将文档构建成一个层次化的树状结构，父节点的文本被分散到它的子节点中。根据子节点与用户查询的相关性，这个方法能帮助你判断是否应该将整个父节点作为上下文提供给大语言模型。
- 评估方法论，专门用于评估 RAG 关键步骤（上下文相关性、答案相关性、可靠性）的质量，这有助于你进行错误分析，找出哪个环节需要改进，并有系统地优化各个组件。

想了解更多，请访问课程链接！
[深度学习短期课程 - 构建和评估高级 RAG](https://deeplearning.ai/short-courses/building-evaluating-advanced-rag/)</title>
            <link>https://nitter.cz/dotey/status/1729972448899051760#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729972448899051760#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 21:15:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>吴老师的新课又来啦：<br />
<br />
全新的短期课程现已上线，专注于介绍高级 RAG（检索增强生成）技术！该课程由 Jerry Liu（<a href="https://nitter.cz/jerryjliu0" title="Jerry Liu">@jerryjliu0</a>）和 Datta CS（<a href="https://nitter.cz/datta_cs" title="Anupam Datta">@datta_cs</a>）主讲，他们分别来自 Llama Index（<a href="https://nitter.cz/llama_index" title="LlamaIndex 🦙">@llama_index</a>）和 TrueRA AI（<a href="https://nitter.cz/truera_ai" title="TruEra">@truera_ai</a>）。通过这门课程，你将学习到一些高级技巧，帮助你的大语言模型 (大语言模型) 产生更优质的答案。<br />
<br />
课程涵盖的主题包括：<br />
- 句子窗口检索，这种方法不只是检索与查询最相关的单个句子，而是检索一个包含多个相关句子的窗口，以提供更丰富的上下文信息。<br />
- 自动合并检索，这种技术可以将文档构建成一个层次化的树状结构，父节点的文本被分散到它的子节点中。根据子节点与用户查询的相关性，这个方法能帮助你判断是否应该将整个父节点作为上下文提供给大语言模型。<br />
- 评估方法论，专门用于评估 RAG 关键步骤（上下文相关性、答案相关性、可靠性）的质量，这有助于你进行错误分析，找出哪个环节需要改进，并有系统地优化各个组件。<br />
<br />
想了解更多，请访问课程链接！<br />
[深度学习短期课程 - 构建和评估高级 RAG](<a href="https://deeplearning.ai/short-courses/building-evaluating-advanced-rag/">deeplearning.ai/short-course…</a>)</p>
<p><a href="https://nitter.cz/AndrewYNg/status/1729924040230629485#m">nitter.cz/AndrewYNg/status/1729924040230629485#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729873461185855965#m</id>
            <title>RT by @Gorden_Sun: 一个可以增强AI生成视频可控性的项目，支持Animatediff。将会开源代码，这下Animatediff的生命力又旺盛了。
我理解就是视频版本的ContorlNet，解决了之前视频生成使用ContorlNet时每一帧都需要介入的问题，先可以自动选择关键帧介入降低资源消耗。

可以在这里看详细的论文：https://guoyww.github.io/projects/SparseCtrl/</title>
            <link>https://nitter.cz/op7418/status/1729873461185855965#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729873461185855965#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:42:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个可以增强AI生成视频可控性的项目，支持Animatediff。将会开源代码，这下Animatediff的生命力又旺盛了。<br />
我理解就是视频版本的ContorlNet，解决了之前视频生成使用ContorlNet时每一帧都需要介入的问题，先可以自动选择关键帧介入降低资源消耗。<br />
<br />
可以在这里看详细的论文：<a href="https://guoyww.github.io/projects/SparseCtrl/">guoyww.github.io/projects/Sp…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk4NzI4NTk5MDcxOTg5NzcvcHUvaW1nLzU5Sk9Sc2dqbHQwLXU0cnouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1729808660375699483#m</id>
            <title>AI资讯日报，11月29日：https://gorden-sun.notion.site/11-29-AI-153cc35cb3bd49238937b28b1ff5bd3c?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1729808660375699483#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1729808660375699483#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 10:24:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月29日：<a href="https://gorden-sun.notion.site/11-29-AI-153cc35cb3bd49238937b28b1ff5bd3c?pvs=4">gorden-sun.notion.site/11-29…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHRHdoYmJZQUVFWXpTLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1729704026353099146#m</id>
            <title>vercel的v0也上线了图片生成代码的功能。截一个网站的图片，就能实现前端展示页面。
使用地址：https://v0.dev/

老板：我要实现XXX网站
产品经理：截网站的图，老板说了，就照着这个做
前端：扔进v0，我好了
后端：草泥马。。。默默打开了ChatGPT</title>
            <link>https://nitter.cz/Gorden_Sun/status/1729704026353099146#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1729704026353099146#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:29:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>vercel的v0也上线了图片生成代码的功能。截一个网站的图片，就能实现前端展示页面。<br />
使用地址：<a href="https://v0.dev/">v0.dev/</a><br />
<br />
老板：我要实现XXX网站<br />
产品经理：截网站的图，老板说了，就照着这个做<br />
前端：扔进v0，我好了<br />
后端：草泥马。。。默默打开了ChatGPT</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFZ244VmJJQUE4NURJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1729689763626520685#m</id>
            <title>在线体验SDXL Turbo：https://www.fal.ai/turbo</title>
            <link>https://nitter.cz/Gorden_Sun/status/1729689763626520685#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1729689763626520685#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:32:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在线体验SDXL Turbo：<a href="https://www.fal.ai/turbo">fal.ai/turbo</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFWG9WSGIwQUFKSVlpLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/camenduru/status/1729660362750849356#m</id>
            <title>RT by @Gorden_Sun: SDXL Turbo 🏎 Colab 🥳

Thanks to @AxSauer ❤ Dominik Lorenz ❤ @andi_blatt ❤ @robrombach ❤

🌐page: https://stability.ai/research/adversarial-diffusion-distillation
🧬code: https://github.com/Stability-AI/generative-models
📄paper: https://static1.squarespace.com/static/6213c340453c3f502425776e/t/65663480a92fba51d0e1023f/1701197769659/adversarial_diffusion_distillation.pdf
🦒colab: please try it 🐣 https://github.com/camenduru/sdxl-turbo-colab</title>
            <link>https://nitter.cz/camenduru/status/1729660362750849356#m</link>
            <guid isPermaLink="false">https://nitter.cz/camenduru/status/1729660362750849356#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 00:35:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SDXL Turbo 🏎 Colab 🥳<br />
<br />
Thanks to <a href="https://nitter.cz/AxSauer" title="Axel Sauer">@AxSauer</a> ❤ Dominik Lorenz ❤ <a href="https://nitter.cz/andi_blatt" title="Andreas Blattmann">@andi_blatt</a> ❤ <a href="https://nitter.cz/robrombach" title="Robin Rombach">@robrombach</a> ❤<br />
<br />
🌐page: <a href="https://stability.ai/research/adversarial-diffusion-distillation">stability.ai/research/advers…</a><br />
🧬code: <a href="https://github.com/Stability-AI/generative-models">github.com/Stability-AI/gene…</a><br />
📄paper: <a href="https://static1.squarespace.com/static/6213c340453c3f502425776e/t/65663480a92fba51d0e1023f/1701197769659/adversarial_diffusion_distillation.pdf">static1.squarespace.com/stat…</a><br />
🦒colab: please try it 🐣 <a href="https://github.com/camenduru/sdxl-turbo-colab">github.com/camenduru/sdxl-tu…</a></p>
<p><a href="https://nitter.cz/AxSauer/status/1729590808540520510#m">nitter.cz/AxSauer/status/1729590808540520510#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2NTk3Nzk1NDEyNjIzMzcvcHUvaW1nL1FJRTM0MTVpdEZ0dHdlZEUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>