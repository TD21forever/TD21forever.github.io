<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1722629707123093546#m</id>
            <title>RT by @Gorden_Sun: @huggingface 的开源LLM排行榜增加了三个新的指标，他们把网站上的2000多个LLM都跑了一遍测试，重新计算了排名。花了大概一年多的GPU时间。
值得注意的是@kaifulee零一智能的Yi-34B模型在所有模型中排第一，有点离谱的。</title>
            <link>https://nitter.cz/op7418/status/1722629707123093546#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1722629707123093546#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 14:58:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/huggingface" title="Hugging Face">@huggingface</a> 的开源LLM排行榜增加了三个新的指标，他们把网站上的2000多个LLM都跑了一遍测试，重新计算了排名。花了大概一年多的GPU时间。<br />
值得注意的是<a href="https://nitter.cz/kaifulee" title="Kai-Fu Lee">@kaifulee</a>零一智能的Yi-34B模型在所有模型中排第一，有点离谱的。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1nQ0JXSGFNQUFVTU9YLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722558023548412377#m</id>
            <title>AI资讯日报，11月9日：https://gorden-sun.notion.site/11-9-AI-5815778524f042d58ce149d6089fc966?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722558023548412377#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722558023548412377#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 10:13:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月9日：<a href="https://gorden-sun.notion.site/11-9-AI-5815778524f042d58ce149d6089fc966?pvs=4">gorden-sun.notion.site/11-9-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1mQlZ5VGIwQUFGMXFoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722554889119875322#m</id>
            <title>这个项目是真快，已经用上了刚刚发布的XTTS v2</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722554889119875322#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722554889119875322#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 10:01:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个项目是真快，已经用上了刚刚发布的XTTS v2</p>
<p><a href="https://nitter.cz/dotey/status/1722543725459452211#m">nitter.cz/dotey/status/1722543725459452211#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722539360464351384#m</id>
            <title>MusicGen可以生成立体声音乐了，双声道（左右耳朵声音不一样），很带感。效果见视频。

推荐在线colab：https://colab.research.google.com/drive/1ECmNEoXk8kvnLEMBMF2LY82E7XmIG4yu?usp=sharing
最长2分钟，我的参数是musicgen-stereo-medium+MultiBand Diffusion(更占显存)，24秒音频

抱抱脸(只能15秒)：https://huggingface.co/spaces/facebook/MusicGen
Github：https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722539360464351384#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722539360464351384#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 08:59:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MusicGen可以生成立体声音乐了，双声道（左右耳朵声音不一样），很带感。效果见视频。<br />
<br />
推荐在线colab：<a href="https://colab.research.google.com/drive/1ECmNEoXk8kvnLEMBMF2LY82E7XmIG4yu?usp=sharing">colab.research.google.com/dr…</a><br />
最长2分钟，我的参数是musicgen-stereo-medium+MultiBand Diffusion(更占显存)，24秒音频<br />
<br />
抱抱脸(只能15秒)：<a href="https://huggingface.co/spaces/facebook/MusicGen">huggingface.co/spaces/facebo…</a><br />
Github：<a href="https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md">github.com/facebookresearch/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI1Mzg2MzcwNDc1MTMwODgvcHUvaW1nL3dsM2N3Y2FsWTF3blZ3SHguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/goldengrape/status/1722518486675788118#m</id>
            <title>RT by @Gorden_Sun: 教程来了：
用GPTs建立一个autoGPT
https://quail.ink/goldengrape/p/how-to-setup-an-autogpt-with-gpts</title>
            <link>https://nitter.cz/goldengrape/status/1722518486675788118#m</link>
            <guid isPermaLink="false">https://nitter.cz/goldengrape/status/1722518486675788118#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:36:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>教程来了：<br />
用GPTs建立一个autoGPT<br />
<a href="https://quail.ink/goldengrape/p/how-to-setup-an-autogpt-with-gpts">quail.ink/goldengrape/p/how-…</a></p>
<p><a href="https://nitter.cz/goldengrape/status/1722504369764225322#m">nitter.cz/goldengrape/status/1722504369764225322#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMjUxODQ5NDU0MDE1MjgzMi9hbzdCSThkZj9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1722484822101078390#m</id>
            <title>RT by @Gorden_Sun: 赞，在你的GPT中可以直接调用WePilot的接口，拥有WebPilot的网络获取能力👍🏻</title>
            <link>https://nitter.cz/dotey/status/1722484822101078390#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1722484822101078390#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 05:22:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>赞，在你的GPT中可以直接调用WePilot的接口，拥有WebPilot的网络获取能力👍🏻</p>
<p><a href="https://nitter.cz/CocoSgt_twt/status/1722482821053477121#m">nitter.cz/CocoSgt_twt/status/1722482821053477121#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722439866112463163#m</id>
            <title>HeyGen实现流程中的语音克隆，现在有最佳开源方案了：XTTS v2，单样本即可克隆语音，效果见视频。
现在已经能实现：让一个明星的采访视频，变成他讲述任意小故事（内容可以GPT编）的视频，声音是他的声音，嘴型也能对上。
XTTS v2在线体验：https://huggingface.co/spaces/coqui/xtts
Github：https://github.com/coqui-ai/tts</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722439866112463163#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722439866112463163#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 02:24:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HeyGen实现流程中的语音克隆，现在有最佳开源方案了：XTTS v2，单样本即可克隆语音，效果见视频。<br />
现在已经能实现：让一个明星的采访视频，变成他讲述任意小故事（内容可以GPT编）的视频，声音是他的声音，嘴型也能对上。<br />
XTTS v2在线体验：<a href="https://huggingface.co/spaces/coqui/xtts">huggingface.co/spaces/coqui/…</a><br />
Github：<a href="https://github.com/coqui-ai/tts">github.com/coqui-ai/tts</a></p>
<p><a href="https://nitter.cz/Gorden_Sun/status/1716075577117929841#m">nitter.cz/Gorden_Sun/status/1716075577117929841#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI0Mzk2NTM4NjgxMDk4MjQvcHUvaW1nL293aDJtcDRVd29VajcxRXYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/goldengrape/status/1722406261805940753#m</id>
            <title>RT by @Gorden_Sun: 如何建立一个专利专家GPT
https://quail.ink/goldengrape/p/how-to-build-a-patent-gpt
一步一步讲解了如何把插件纳入到自定义GPTs里面</title>
            <link>https://nitter.cz/goldengrape/status/1722406261805940753#m</link>
            <guid isPermaLink="false">https://nitter.cz/goldengrape/status/1722406261805940753#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 00:10:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如何建立一个专利专家GPT<br />
<a href="https://quail.ink/goldengrape/p/how-to-build-a-patent-gpt">quail.ink/goldengrape/p/how-…</a><br />
一步一步讲解了如何把插件纳入到自定义GPTs里面</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMjQwNTgyNDE3MjM3NjA2NC8yV2QyVUJwVT9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1722401600038424936#m</id>
            <title>RT by @Gorden_Sun: GPT-4-Turbo 128K上下文当全部用上，就有Lost in Middle的问题了。

上下文低于64K 没有遗忘问题，这倒是已经干掉了目前所有模型。

所以目前不建议使用其处理超过64K的文本。

顺便一提，128K一次就是一点几美金，也用不起。</title>
            <link>https://nitter.cz/9hills/status/1722401600038424936#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1722401600038424936#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 23:51:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT-4-Turbo 128K上下文当全部用上，就有Lost in Middle的问题了。<br />
<br />
上下文低于64K 没有遗忘问题，这倒是已经干掉了目前所有模型。<br />
<br />
所以目前不建议使用其处理超过64K的文本。<br />
<br />
顺便一提，128K一次就是一点几美金，也用不起。</p>
<p><a href="https://nitter.cz/GregKamradt/status/1722386725635580292#m">nitter.cz/GregKamradt/status/1722386725635580292#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/ruanyf/status/1722219566926037224#m</id>
            <title>RT by @Gorden_Sun: 昨天的 OpenAI 开发者大会，正式推出了“图生文”的 GPT-4 Vision 模型。

我有点好奇，找了一张中文图片，让 GPT-4 跟 @JinaAI_ 的  SceneXplain（图一）比较一下，看看谁的文字描述比较准。https://scenex.jina.ai/a/NEW

GPT-4 的结果（图二）不算很理想，似乎中文处理不太行，把“佳节”看成了“家乐福” ，还编造了一段。相比之下，SceneXplain 的中文理解（图三）就好很多。

我以前就在用 SceneXplain，这里推一下。它经过中文强化，更适合中文用户，可以生成图像描述、视频摘要、故事脚本等（图四），可用于电商图片生成文案、社交媒体的图片分析、无障碍读屏等场合。

它对开发者也很友好，提供 API 调用，结果以 JSON 格式输出，方便加工后放入自己的项目。</title>
            <link>https://nitter.cz/ruanyf/status/1722219566926037224#m</link>
            <guid isPermaLink="false">https://nitter.cz/ruanyf/status/1722219566926037224#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 11:48:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天的 OpenAI 开发者大会，正式推出了“图生文”的 GPT-4 Vision 模型。<br />
<br />
我有点好奇，找了一张中文图片，让 GPT-4 跟 <a href="https://nitter.cz/JinaAI_" title="Jina AI">@JinaAI_</a> 的  SceneXplain（图一）比较一下，看看谁的文字描述比较准。<a href="https://scenex.jina.ai/a/NEW">scenex.jina.ai/a/NEW</a><br />
<br />
GPT-4 的结果（图二）不算很理想，似乎中文处理不太行，把“佳节”看成了“家乐福” ，还编造了一段。相比之下，SceneXplain 的中文理解（图三）就好很多。<br />
<br />
我以前就在用 SceneXplain，这里推一下。它经过中文强化，更适合中文用户，可以生成图像描述、视频摘要、故事脚本等（图四），可用于电商图片生成文案、社交媒体的图片分析、无障碍读屏等场合。<br />
<br />
它对开发者也很友好，提供 API 调用，结果以 JSON 格式输出，方便加工后放入自己的项目。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1hTUxibGE4QUVOM3ZqLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1hTU1FV2F3QUFWMHBLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1hTU9QWGFZQUVPaGhoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1hTVEzNmEwQUFOTGdVLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/iamairyland/status/1722041853451669644#m</id>
            <title>RT by @Gorden_Sun: 快速用 AI 糊了个简陋无设计的 GPTs 发现和分享网站：http://www.GPTsHunter.com  它会对 Twitter 公开动态中的 GPT 进行自动收录。

欢迎 Up Vote：
https://www.producthunt.com/posts/gptshunter</title>
            <link>https://nitter.cz/iamairyland/status/1722041853451669644#m</link>
            <guid isPermaLink="false">https://nitter.cz/iamairyland/status/1722041853451669644#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 00:02:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>快速用 AI 糊了个简陋无设计的 GPTs 发现和分享网站：<a href="http://www.GPTsHunter.com">GPTsHunter.com</a>  它会对 Twitter 公开动态中的 GPT 进行自动收录。<br />
<br />
欢迎 Up Vote：<br />
<a href="https://www.producthunt.com/posts/gptshunter">producthunt.com/posts/gptshu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1YcU5VdFd3QUEwWWFnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722196691645018537#m</id>
            <title>AI资讯日报，11月8日：https://gorden-sun.notion.site/11-8-AI-970d7e25c78b4d73b17721a39ec42829?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722196691645018537#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722196691645018537#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 10:17:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月8日：<a href="https://gorden-sun.notion.site/11-8-AI-970d7e25c78b4d73b17721a39ec42829?pvs=4">gorden-sun.notion.site/11-8-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1aNHdDWmJZQUEwekR1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722140904365101484#m</id>
            <title>Figma推出Figma AI，输入文字可以生成流程图、原型、计划表，选中内容可以进行整理和总结

在线体验地址：https://www.figma.com/file/krMbt5UqgmjTaHGIAzWScY/FigJam-AI-playground-(Community)?type=whiteboard</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722140904365101484#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722140904365101484#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 06:36:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Figma推出Figma AI，输入文字可以生成流程图、原型、计划表，选中内容可以进行整理和总结<br />
<br />
在线体验地址：<a href="https://www.figma.com/file/krMbt5UqgmjTaHGIAzWScY/FigJam-AI-playground-(Community)?type=whiteboard">figma.com/file/krMbt5UqgmjTa…</a></p>
<p><a href="https://nitter.cz/figma/status/1721936196996350387#m">nitter.cz/figma/status/1721936196996350387#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMjE0MDkwNTk3OTk4MTgyNC9lX3Y5aFFGYT9mb3JtYXQ9cG5nJm5hbWU9MTIwMHg2Mjc=" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722075640990716082#m</id>
            <title>https://huggingface.co/spaces/hf-audio/whisper-large-v3
这个空间可以体验OpenAI最新发布的Whisper v3，支持多语言混合识别。识别下面的音频，日语的爱识别成了中文的爱，阿姨洗铁路没识别成正确的梗。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722075640990716082#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722075640990716082#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 02:16:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://huggingface.co/spaces/hf-audio/whisper-large-v3">huggingface.co/spaces/hf-aud…</a><br />
这个空间可以体验OpenAI最新发布的Whisper v3，支持多语言混合识别。识别下面的音频，日语的爱识别成了中文的爱，阿姨洗铁路没识别成正确的梗。</p>
<p><a href="https://nitter.cz/Gorden_Sun/status/1721890997133877583#m">nitter.cz/Gorden_Sun/status/1721890997133877583#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1ZS28tamJjQUEtamNNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1721986978978087190#m</id>
            <title>RT by @Gorden_Sun: 推荐阅读：Developing Advanced Reasoning and Planning Algorithms with LLMs

大多数人都听说过思考链（Chain of Thought），把复杂问题拆分成一步步来处理提升准确率。

但是对于有些更复杂的问题，在某个步骤出错后，希望能回到上一个正确的节点重试，而不是重头开始，那么就需要借助“思维树”（Tree-of-Thoughts）。但思维树相对复杂，不容易调试和展示，所以作者开发了一款工具叫Branches，将大语言模型推理和规划的算法用图形化的方式展示出来。可以直观的用树形结构，还可以查看每一个节点的推理过程。

原文链接：https://blog.normalcomputing.ai/posts/2023-11-05-search-based-reasoning/search-based-reasoning.html

中文翻译：利用大语言模型开发先进的推理与规划算法 [译]
https://baoyu.io/blog/translations/search-based-reasoning</title>
            <link>https://nitter.cz/dotey/status/1721986978978087190#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1721986978978087190#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Nov 2023 20:24:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：Developing Advanced Reasoning and Planning Algorithms with LLMs<br />
<br />
大多数人都听说过思考链（Chain of Thought），把复杂问题拆分成一步步来处理提升准确率。<br />
<br />
但是对于有些更复杂的问题，在某个步骤出错后，希望能回到上一个正确的节点重试，而不是重头开始，那么就需要借助“思维树”（Tree-of-Thoughts）。但思维树相对复杂，不容易调试和展示，所以作者开发了一款工具叫Branches，将大语言模型推理和规划的算法用图形化的方式展示出来。可以直观的用树形结构，还可以查看每一个节点的推理过程。<br />
<br />
原文链接：<a href="https://blog.normalcomputing.ai/posts/2023-11-05-search-based-reasoning/search-based-reasoning.html">blog.normalcomputing.ai/post…</a><br />
<br />
中文翻译：利用大语言模型开发先进的推理与规划算法 [译]<br />
<a href="https://baoyu.io/blog/translations/search-based-reasoning">baoyu.io/blog/translations/s…</a></p>
<p><a href="https://nitter.cz/ArunPatro/status/1721762402641813535#m">nitter.cz/ArunPatro/status/1721762402641813535#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1721915726951305500#m</id>
            <title>RT by @Gorden_Sun: 好人呐，OpenAIDocGPT</title>
            <link>https://nitter.cz/dotey/status/1721915726951305500#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1721915726951305500#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Nov 2023 15:41:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>好人呐，OpenAIDocGPT</p>
<p><a href="https://nitter.cz/CocoSgt_twt/status/1721914300288454782#m">nitter.cz/CocoSgt_twt/status/1721914300288454782#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1721893393868128623#m</id>
            <title>AI资讯日报，11月7日：https://gorden-sun.notion.site/11-7-AI-0771acd36fbc4874862a08ddfd278d18?pvs=4

虽迟但到，OpenAI开发者大会的总结，还是要自己梳理一份。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1721893393868128623#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1721893393868128623#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Nov 2023 14:12:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月7日：<a href="https://gorden-sun.notion.site/11-7-AI-0771acd36fbc4874862a08ddfd278d18?pvs=4">gorden-sun.notion.site/11-7-…</a><br />
<br />
虽迟但到，OpenAI开发者大会的总结，还是要自己梳理一份。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1Wa3piWmFzQUE1bDB3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1721890997133877583#m</id>
            <title>最牛逼的是支持多语言混合输入，一段掺杂了多种语言的文本，可以完美地说出来，是传统的TTS实现不了的。
听我的视频里的效果，3种语言同时说，毫无违和感。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1721890997133877583#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1721890997133877583#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Nov 2023 14:02:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最牛逼的是支持多语言混合输入，一段掺杂了多种语言的文本，可以完美地说出来，是传统的TTS实现不了的。<br />
听我的视频里的效果，3种语言同时说，毫无违和感。</p>
<p><a href="https://nitter.cz/finedtune/status/1721760389581709778#m">nitter.cz/finedtune/status/1721760389581709778#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjE4OTA4MDY3NzExMDk4ODgvcHUvaW1nL0k0LWp2ZjJFSXV6NDdOMGwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1721698031765000607#m</id>
            <title>RT by @Gorden_Sun: 为了让大家看到第一手的OpenAI DevDay的信息，对直播的视频的字幕进行了校对和翻译，这里是第一部分。

早上好，感谢你们今天的参与。欢迎 Sam Altman 登台。早上好，欢迎来到我们首次举办的 OpenAI 开发者日。我们很高兴你们能来，这种活力真棒。欢迎来到旧金山。旧金山从一开始就是我们的家。这个城市对我们和整个科技行业都很重要。我们期待在这里继续发展。

今天，我们有一些重要的事情要宣布。但首先，我想花一分钟时间谈谈我们在过去一年里做的一些事情。大约一年前，11 月 30 日，我们以研究预览的方式低调地发布了 ChatGPT。效果还不错。在三月，我们接着发布了 GPT-4。这仍然是世界上最强大的模型。在过去的几个月里，我们推出了语音和视觉功能，使 ChatGPT 现在可以看、听、说。

最近的...有很多，你们不必每次都鼓掌。最近，我们推出了 DALL-E3，世界上最先进的图像模型。当然，你可以在 ChatGPT 中使用它。对于我们的企业客户，我们推出了 ChatGPT Enterprise，它提供企业级的安全和隐私，更高速度的 GPT-4 访问，更长的上下文窗口，等等。

今天，我们有大约 200 万开发者在我们的 API 上进行各种用途的开发，做了很多令人惊叹的事情，超过 92% 的财富 500 强公司在我们的产品上进行开发，现在我们在 ChatGPT 上有大约 1 亿的每周活跃用户。令人难以置信的是，我们完全通过口口相传达到了这个地步。人们发现它很有用，就告诉他们的朋友。OpenAI 现在是世界上最先进、使用最广泛的 AI 平台。

但是，数字永远不能完全描绘出这样的事情。真正重要的是人们如何使用产品，人们如何使用 AI。所以，我想给你们看一个简短的视频。我实际上想用塔加洛语给我爸爸写点什么。我想以一种非浪漫的方式告诉我的父亲我爱他，我也想告诉他他可以依赖我，但是以一种仍然保持孩子对父母的尊重的方式，这是你在菲律宾文化和塔加洛语语法中应该有的。

它被翻译成塔加洛语，我深深地爱你，无论道路通向何处，我都会和你在一起。我看到一些可能性，我就像，哇，有时我对一些东西不确定。我觉得我实际上在聊天时就像，嘿，这就是我在想的，所以你有点给它更多的信心。第一件让我震惊的事情是它与你平等对待。这是很多人都在努力做的事情。这启发了我，只要有一个倾听者相助，每位创意工作者都能释放出无限的可能。

这是一种标志性的 'neemaglobbin'，你是用 ChatGPT 建造的吗？ChatGPT 和我一起建造的。我开始用它进行日常活动，比如，嘿，这是我冰箱的照片，你

能告诉我我缺什么吗？因为我要去超市，而我非常需要遵循我的素食饮食来准备食谱。我们获得了代码解释器的访问权限。我当时就想，哇，这东西太棒了。它可以建立电子表格，它可以做任何事情。

我在我的 100 岁生日那天发现了 chatty。Chatty 非常友好，非常有耐心，知识非常渊博，而且反应非常快。这真是一件美妙的事情。尽管我是个 GPA 4.0 的优等生，同时也是四个孩子的妈妈。我在使用 ChatGPT 后很快发现，无论我有什么问题，它都能提供答案并且附带详细解释，让我不再那么依赖家教。它让我重获新生，让我有了更多陪伴家人和自己的时间。

我身体的左半边因为神经损伤而长期遭受着慢性疼痛。经历过脊椎和大脑手术之后，我的左手的功能受到了一定的限制。如今，语音输入技术的应用，以及最新的可进行双向对话的功能，为我提供了一个前所未有的最佳交互界面。这一切现在都变为现实。所以我们很喜欢听到人们如何使用这项技术的故事。这正是我们工作的真正动力。

好了，让我们来看看一些新鲜出炉的东西，我们有很多东西要分享。首先，我们会介绍我们所做的一些改进，然后再分享我们的下一步计划。

在过去的一年里，去年一整年，我们与全球的开发者们进行了深入的交流。他们的反馈极大地影响了我们今天要展示给大家的内容。今天，我们即将发布一个新的模型——GPT-4 Turbo。这个新模型将解决你们提出的许多问题。

接下来，我们来看看有哪些新特性。对于这一部分，我们有六大主题需要讨论。

首先是上下文长度。很多人在处理工作时，常常需要处理比较长的文字。尽管 GPT-4 支持最多 8K 个 token，有时候甚至能处理 32K 个 token，我们明白这对很多用户来说还远远不够。现在，GPT-4 Turbo 可以处理长达 128K 个 token 的文本，这相当于一本标准书籍的 300 页，比我们的 8K 上下文长 16 倍。除此之外，你还会发现，在处理这么长的文本时，模型的准确性也大大提升了。

其次，是对模型更强的控制能力。开发者们强烈希望能更精细地控制模型的响应和结果，我们也做出了相应的改进。其中包括一项新功能——JSON 模式，它能确保模型的响应是有效的 JSON 格式，这一直是开发者的强烈需求。这大大简化了 API 的调用过程。模型在函数调用方面也有所改进。能够一次性调用多个函数，并且它会更好地遵循一般的指示。我们还新增了一个特性——可复现输出。你可以传递一个 seed 参数，它会使模型返回一致的输出。这无疑增强了对模型行为的控制力。这项新功能从今天开始进入 beta 测试阶段。

在接下来的几周内，我们还会推出一个新功能，使得开发者能在 API 中查看 log probs。

好的，接下来是第三点，更好的知识储备。你希望这些模型能够获取更多更新的知识，我们也是。因此，我们正在平台上推出检索功能，允许用户将外部文档或数据库的信息融入到他们正在开发的项目中。同时，我们也在不断更新模型的知识库，让它保持最新。我们和你们一样，对 GPT-4 的知识停留在 2021 年这件事感到十分困扰，可能我们还更甚。我们会尽力不再让它过时。GPT-4 Turbo 已经包含了截至 2023 年 4 月的世界知识，并且我们会不断对此进行更新。

第四，我们引入了新的模态功能。毫不意外，DALL-E v3，具备视觉功能的 GPT-4 Turbo，以及全新的文本到语音模型都会加入到我们的 API 服务中。我们已有几位客户开始使用 DALL-E v3 来创作图像和设计作品。今天 Coca 就推出了一个活动，使用 DALL-E v3 创作 DIWALI 节日卡片。当然了，我们也提供了安全系统，帮助开发者防止他们的应用程序被滥用。这些工具都可以通过 API 获得。GPT-4 Turbo 现在可以通过 API 接受图像作为输入，可以生成标题，分类和分析。例如，Be My Eyes 使用这项技术帮助盲人或视力不佳的人完成他们的日常任务，比如识别他们面前的产品。而我们的新文本转语音模型，能让你通过 API 将文本转化为听起来极其自然的音频，有六种预设的声音供你选择。我会播放一个例子。你知道吗，伟大的发明家亚历山大·格雷厄姆·贝尔对声音的世界充满了迷恋？他的一项天才发明——留声机，能将声音刻录在蜡上，让它们跨越时空低语。这种效果比我们之前听到的任何音频都要自然。语音功能使应用程序的交互变得更加自然和便捷。它还开启了许多应用场景，比如语言学习和语音助手。说到新的模态，我们今天还发布了最新版的开源语音识别模型 Whisper V3。不久后，它将集成进我们的 API。该版本在多种语言上的表现都有显著提升，我们认为你会非常喜欢它。

好的。第五，定制。自从几个月前我们推出 GPT 3.5 以来，模型微调功能表现出色。从今天起，我们会将此功能扩展至模型的 16K 版本。也从今天开始，同时，我们也欢迎那些活跃的微调用户申请加入 GPT-4 微调的实验性接入项目。微调 API 能够让我们的模型通过较少的数据量就适应各种应用场景，并取得更佳表现。但或许你希望模型能学习全新的知识领域，或是处理大量专有数据。因此，我们推出了一项名为“自定义模型”的新服务。有了自定义模型，通过这项服务，我们的研究团队将与企业紧密协作，利用我们的工具为他们的特定用例打造专属的高质量模型。这涉及修改模型训练流程的每一个环节，包括特定领域的预训练和针对该领域定制的强化学习后期训练过程等。我们一开始不会与太多公司合作，因为这需要大量的工作，而且至少在初期，成本也不会低。但如果你愿意与我们一起把事情推向极致，请联系我们，我们相信能创造出令人惊喜的成果。

接下来是第六点，提高速率限制。我们将把所有现有 GPT-4 客户的每分钟 Token 数翻倍，使你能够更加轻松地扩展使用。现在，您可以在 API 账户设置中直接申请调整速率限制和配额。在制定这些限制的同时，我们还致力于提高用户在我们平台上构建新产品的成功率。

为此，我们推出了 "版权保护盾" 服务。版权保护盾的引入，意味着如果您在版权侵权问题上面临法律诉讼，我们将介入并承担相关法律费用，这项服务适用于 ChatGPT 企业版和 API 用户。在此我要明确指出，我们绝不会用 API 或 ChatGPT 企业版的数据来进行我们的训练工作。

此外，开发者们对另一个问题的需求甚至超过了以上所有问题，所以我想现在谈谈这个。那就是产品定价。GPT-4 Turbo 作为行业领先的模型，不仅带来了刚才提到的多项改进，而且比 GPT-4 更为智能。我们听到很多开发者反馈，他们有很多想要实现的项目，但 GPT-4 的成本过高。他们告诉我们，如果我们能将成本降低 20% 到 25%，那将是一个巨大的进步。

我非常激动地宣布，我们经过了大量努力，GPT-4 Turbo，一个更优秀的模型，比 GPT-4 的价格要低得多。对于输入的 Token 价格，便宜了 3 倍。对于输出的 Token 价格，从今天开始，便宜了 2 倍。所以新的定价是，每千个输入 Token 0.01 美元，每千个输出 Token 0.03 美元。对于大多数客户来说，这意味着使用 GPT-4 Turbo 的成本将比 GPT-4 低 2.75 倍以上。

我们为此付出了巨大的努力，希望你们能和我们一样对此感到兴奋。我们不得不在价格和速度之间做出选择，而我们选择了先着手于价格问题。但提速的工作也在我们的计划之中，速度的提升同样关键。你很快就会发现 GPT-4 Turbo 的速度有了显著提升。

我们也在降低 GPT 3.5 Turbo 16K 的成本。此外，现在输入 tokens 的费用减少了 3 倍，输出 tokens 的费用减少了 2 倍。这意味着 GPT 3.5 16K 现在比之前的 GPT 3.5 4K 模型更便宜。运行一个微调的 GPT 3.5 Turbo 16K 版本，其成本甚至比旧的 4K 版本还要低。

好的，我们刚刚详细介绍了这个模型本身。我们希望这些改进能够满足你们的反馈。我们非常兴奋能够立即将所有这些改进带给大家。</title>
            <link>https://nitter.cz/dotey/status/1721698031765000607#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1721698031765000607#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Nov 2023 01:16:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>为了让大家看到第一手的OpenAI DevDay的信息，对直播的视频的字幕进行了校对和翻译，这里是第一部分。<br />
<br />
早上好，感谢你们今天的参与。欢迎 Sam Altman 登台。早上好，欢迎来到我们首次举办的 OpenAI 开发者日。我们很高兴你们能来，这种活力真棒。欢迎来到旧金山。旧金山从一开始就是我们的家。这个城市对我们和整个科技行业都很重要。我们期待在这里继续发展。<br />
<br />
今天，我们有一些重要的事情要宣布。但首先，我想花一分钟时间谈谈我们在过去一年里做的一些事情。大约一年前，11 月 30 日，我们以研究预览的方式低调地发布了 ChatGPT。效果还不错。在三月，我们接着发布了 GPT-4。这仍然是世界上最强大的模型。在过去的几个月里，我们推出了语音和视觉功能，使 ChatGPT 现在可以看、听、说。<br />
<br />
最近的...有很多，你们不必每次都鼓掌。最近，我们推出了 DALL-E3，世界上最先进的图像模型。当然，你可以在 ChatGPT 中使用它。对于我们的企业客户，我们推出了 ChatGPT Enterprise，它提供企业级的安全和隐私，更高速度的 GPT-4 访问，更长的上下文窗口，等等。<br />
<br />
今天，我们有大约 200 万开发者在我们的 API 上进行各种用途的开发，做了很多令人惊叹的事情，超过 92% 的财富 500 强公司在我们的产品上进行开发，现在我们在 ChatGPT 上有大约 1 亿的每周活跃用户。令人难以置信的是，我们完全通过口口相传达到了这个地步。人们发现它很有用，就告诉他们的朋友。OpenAI 现在是世界上最先进、使用最广泛的 AI 平台。<br />
<br />
但是，数字永远不能完全描绘出这样的事情。真正重要的是人们如何使用产品，人们如何使用 AI。所以，我想给你们看一个简短的视频。我实际上想用塔加洛语给我爸爸写点什么。我想以一种非浪漫的方式告诉我的父亲我爱他，我也想告诉他他可以依赖我，但是以一种仍然保持孩子对父母的尊重的方式，这是你在菲律宾文化和塔加洛语语法中应该有的。<br />
<br />
它被翻译成塔加洛语，我深深地爱你，无论道路通向何处，我都会和你在一起。我看到一些可能性，我就像，哇，有时我对一些东西不确定。我觉得我实际上在聊天时就像，嘿，这就是我在想的，所以你有点给它更多的信心。第一件让我震惊的事情是它与你平等对待。这是很多人都在努力做的事情。这启发了我，只要有一个倾听者相助，每位创意工作者都能释放出无限的可能。<br />
<br />
这是一种标志性的 'neemaglobbin'，你是用 ChatGPT 建造的吗？ChatGPT 和我一起建造的。我开始用它进行日常活动，比如，嘿，这是我冰箱的照片，你<br />
<br />
能告诉我我缺什么吗？因为我要去超市，而我非常需要遵循我的素食饮食来准备食谱。我们获得了代码解释器的访问权限。我当时就想，哇，这东西太棒了。它可以建立电子表格，它可以做任何事情。<br />
<br />
我在我的 100 岁生日那天发现了 chatty。Chatty 非常友好，非常有耐心，知识非常渊博，而且反应非常快。这真是一件美妙的事情。尽管我是个 GPA 4.0 的优等生，同时也是四个孩子的妈妈。我在使用 ChatGPT 后很快发现，无论我有什么问题，它都能提供答案并且附带详细解释，让我不再那么依赖家教。它让我重获新生，让我有了更多陪伴家人和自己的时间。<br />
<br />
我身体的左半边因为神经损伤而长期遭受着慢性疼痛。经历过脊椎和大脑手术之后，我的左手的功能受到了一定的限制。如今，语音输入技术的应用，以及最新的可进行双向对话的功能，为我提供了一个前所未有的最佳交互界面。这一切现在都变为现实。所以我们很喜欢听到人们如何使用这项技术的故事。这正是我们工作的真正动力。<br />
<br />
好了，让我们来看看一些新鲜出炉的东西，我们有很多东西要分享。首先，我们会介绍我们所做的一些改进，然后再分享我们的下一步计划。<br />
<br />
在过去的一年里，去年一整年，我们与全球的开发者们进行了深入的交流。他们的反馈极大地影响了我们今天要展示给大家的内容。今天，我们即将发布一个新的模型——GPT-4 Turbo。这个新模型将解决你们提出的许多问题。<br />
<br />
接下来，我们来看看有哪些新特性。对于这一部分，我们有六大主题需要讨论。<br />
<br />
首先是上下文长度。很多人在处理工作时，常常需要处理比较长的文字。尽管 GPT-4 支持最多 8K 个 token，有时候甚至能处理 32K 个 token，我们明白这对很多用户来说还远远不够。现在，GPT-4 Turbo 可以处理长达 128K 个 token 的文本，这相当于一本标准书籍的 300 页，比我们的 8K 上下文长 16 倍。除此之外，你还会发现，在处理这么长的文本时，模型的准确性也大大提升了。<br />
<br />
其次，是对模型更强的控制能力。开发者们强烈希望能更精细地控制模型的响应和结果，我们也做出了相应的改进。其中包括一项新功能——JSON 模式，它能确保模型的响应是有效的 JSON 格式，这一直是开发者的强烈需求。这大大简化了 API 的调用过程。模型在函数调用方面也有所改进。能够一次性调用多个函数，并且它会更好地遵循一般的指示。我们还新增了一个特性——可复现输出。你可以传递一个 seed 参数，它会使模型返回一致的输出。这无疑增强了对模型行为的控制力。这项新功能从今天开始进入 beta 测试阶段。<br />
<br />
在接下来的几周内，我们还会推出一个新功能，使得开发者能在 API 中查看 log probs。<br />
<br />
好的，接下来是第三点，更好的知识储备。你希望这些模型能够获取更多更新的知识，我们也是。因此，我们正在平台上推出检索功能，允许用户将外部文档或数据库的信息融入到他们正在开发的项目中。同时，我们也在不断更新模型的知识库，让它保持最新。我们和你们一样，对 GPT-4 的知识停留在 2021 年这件事感到十分困扰，可能我们还更甚。我们会尽力不再让它过时。GPT-4 Turbo 已经包含了截至 2023 年 4 月的世界知识，并且我们会不断对此进行更新。<br />
<br />
第四，我们引入了新的模态功能。毫不意外，DALL-E v3，具备视觉功能的 GPT-4 Turbo，以及全新的文本到语音模型都会加入到我们的 API 服务中。我们已有几位客户开始使用 DALL-E v3 来创作图像和设计作品。今天 Coca 就推出了一个活动，使用 DALL-E v3 创作 DIWALI 节日卡片。当然了，我们也提供了安全系统，帮助开发者防止他们的应用程序被滥用。这些工具都可以通过 API 获得。GPT-4 Turbo 现在可以通过 API 接受图像作为输入，可以生成标题，分类和分析。例如，Be My Eyes 使用这项技术帮助盲人或视力不佳的人完成他们的日常任务，比如识别他们面前的产品。而我们的新文本转语音模型，能让你通过 API 将文本转化为听起来极其自然的音频，有六种预设的声音供你选择。我会播放一个例子。你知道吗，伟大的发明家亚历山大·格雷厄姆·贝尔对声音的世界充满了迷恋？他的一项天才发明——留声机，能将声音刻录在蜡上，让它们跨越时空低语。这种效果比我们之前听到的任何音频都要自然。语音功能使应用程序的交互变得更加自然和便捷。它还开启了许多应用场景，比如语言学习和语音助手。说到新的模态，我们今天还发布了最新版的开源语音识别模型 Whisper V3。不久后，它将集成进我们的 API。该版本在多种语言上的表现都有显著提升，我们认为你会非常喜欢它。<br />
<br />
好的。第五，定制。自从几个月前我们推出 GPT 3.5 以来，模型微调功能表现出色。从今天起，我们会将此功能扩展至模型的 16K 版本。也从今天开始，同时，我们也欢迎那些活跃的微调用户申请加入 GPT-4 微调的实验性接入项目。微调 API 能够让我们的模型通过较少的数据量就适应各种应用场景，并取得更佳表现。但或许你希望模型能学习全新的知识领域，或是处理大量专有数据。因此，我们推出了一项名为“自定义模型”的新服务。有了自定义模型，通过这项服务，我们的研究团队将与企业紧密协作，利用我们的工具为他们的特定用例打造专属的高质量模型。这涉及修改模型训练流程的每一个环节，包括特定领域的预训练和针对该领域定制的强化学习后期训练过程等。我们一开始不会与太多公司合作，因为这需要大量的工作，而且至少在初期，成本也不会低。但如果你愿意与我们一起把事情推向极致，请联系我们，我们相信能创造出令人惊喜的成果。<br />
<br />
接下来是第六点，提高速率限制。我们将把所有现有 GPT-4 客户的每分钟 Token 数翻倍，使你能够更加轻松地扩展使用。现在，您可以在 API 账户设置中直接申请调整速率限制和配额。在制定这些限制的同时，我们还致力于提高用户在我们平台上构建新产品的成功率。<br />
<br />
为此，我们推出了 "版权保护盾" 服务。版权保护盾的引入，意味着如果您在版权侵权问题上面临法律诉讼，我们将介入并承担相关法律费用，这项服务适用于 ChatGPT 企业版和 API 用户。在此我要明确指出，我们绝不会用 API 或 ChatGPT 企业版的数据来进行我们的训练工作。<br />
<br />
此外，开发者们对另一个问题的需求甚至超过了以上所有问题，所以我想现在谈谈这个。那就是产品定价。GPT-4 Turbo 作为行业领先的模型，不仅带来了刚才提到的多项改进，而且比 GPT-4 更为智能。我们听到很多开发者反馈，他们有很多想要实现的项目，但 GPT-4 的成本过高。他们告诉我们，如果我们能将成本降低 20% 到 25%，那将是一个巨大的进步。<br />
<br />
我非常激动地宣布，我们经过了大量努力，GPT-4 Turbo，一个更优秀的模型，比 GPT-4 的价格要低得多。对于输入的 Token 价格，便宜了 3 倍。对于输出的 Token 价格，从今天开始，便宜了 2 倍。所以新的定价是，每千个输入 Token 0.01 美元，每千个输出 Token 0.03 美元。对于大多数客户来说，这意味着使用 GPT-4 Turbo 的成本将比 GPT-4 低 2.75 倍以上。<br />
<br />
我们为此付出了巨大的努力，希望你们能和我们一样对此感到兴奋。我们不得不在价格和速度之间做出选择，而我们选择了先着手于价格问题。但提速的工作也在我们的计划之中，速度的提升同样关键。你很快就会发现 GPT-4 Turbo 的速度有了显著提升。<br />
<br />
我们也在降低 GPT 3.5 Turbo 16K 的成本。此外，现在输入 tokens 的费用减少了 3 倍，输出 tokens 的费用减少了 2 倍。这意味着 GPT 3.5 16K 现在比之前的 GPT 3.5 4K 模型更便宜。运行一个微调的 GPT 3.5 Turbo 16K 版本，其成本甚至比旧的 4K 版本还要低。<br />
<br />
好的，我们刚刚详细介绍了这个模型本身。我们希望这些改进能够满足你们的反馈。我们非常兴奋能够立即将所有这些改进带给大家。</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzIxNjk2MjY0MzUyMzMzODI0L2ltZy8xVkhzYmYtSUZTdDJqTUJRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1721736444237221927#m</id>
            <title>R to @Gorden_Sun: 之前做的有声绘本的视频：</title>
            <link>https://nitter.cz/Gorden_Sun/status/1721736444237221927#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1721736444237221927#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Nov 2023 03:48:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前做的有声绘本的视频：</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjE3MzU1MDAxNzA3Mzk3MTIvcHUvaW1nL2NaMTh4M1RfbXdIdExRRE0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>