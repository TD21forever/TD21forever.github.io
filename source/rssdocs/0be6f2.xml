<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735223017079456019#m</id>
            <title>Solar 10.7B：新的开源最佳模型
评分超过Mistral 7B，不过也就超过了一点点，Mistral如果有10B的版本，两者的水平差不多。
基座模型：https://huggingface.co/upstage/SOLAR-10.7B-v1.0
指令微调：https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735223017079456019#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735223017079456019#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 08:59:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Solar 10.7B：新的开源最佳模型<br />
评分超过Mistral 7B，不过也就超过了一点点，Mistral如果有10B的版本，两者的水平差不多。<br />
基座模型：<a href="https://huggingface.co/upstage/SOLAR-10.7B-v1.0">huggingface.co/upstage/SOLAR…</a><br />
指令微调：<a href="https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0">huggingface.co/upstage/SOLAR…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTXzR6cGJVQUFCTE44LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735220263065976947#m</id>
            <title>Coffee：AI辅助前端开发（怎么老是前端）
适用于React项目，支持大多数UI组件，能写简洁易维护的代码。
Github：https://github.com/Coframe/coffee</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735220263065976947#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735220263065976947#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 08:48:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Coffee：AI辅助前端开发（怎么老是前端）<br />
适用于React项目，支持大多数UI组件，能写简洁易维护的代码。<br />
Github：<a href="https://github.com/Coframe/coffee">github.com/Coframe/coffee</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUyMjAwMjMyMDIwNDE4NTYvcHUvaW1nL1hoTkVrQ3JobUhoV0FoWjYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735064009974431884#m</id>
            <title>RT by @Gorden_Sun: 今天 Google 的 Gemini Pro 通过 Gemini API 上线，并且提供了 API 访问，同时还有一个开发者的利好：目前 Gemini Pro 可免费使用！

Gemini API 地址：http://ai.google.dev https://ai.google.dev

有关 Gemini Pro 的一些细节：

- 在专业的基准测试中，Gemini Pro 的表现超越了其他同类模型。
- 当前版本配备了 32K 文本上下文窗口，未来将推出拥有更广阔上下文窗口的版本。
- 目前，Gemini Pro 可免费使用（存在一定使用限制），并且其定价将十分 有竞争力。
- 它具备丰富的功能，包括函数调用、数据嵌入、语义检索、自定义知识嵌入以及聊天功能。
- 它支持 全球超过 180 个国家和地区 的 38 种语言。
- 在今日发布的版本中，Gemini Pro 可处理文本输入并生成文本输出。我们还推出了一个专门的 Gemini Pro 视觉多模态终端，能够处理图像和文本输入，输出文本。
- Gemini Pro 提供了多种 SDK，以便开发者在不同平台上构建应用，包括 Python、Android (Kotlin)、Node.js、Swift 和 JavaScript。

Gemini Pro 提供了易于使用的 SDK，助力开发者在任何平台上快速构建应用。

另外 Google 还提供了一个免费的在线开发工具 Google AI Studio，你可以用它快速构建 Gemini 应用。

Google AI Studio ：https://makersuite.google.com/

最后是 Gemini Pro 定价策略，

Gemini Pro

INPUT
$0.00025 / 1K characters
$0.0025 / image

OUTPUT
$0.0005 / 1K characters

对比一下 GPT-3.5 价格：
gpt-3.5-turbo-1106
INPUT
$0.0010 / 1K tokens
OUTPUT
$0.0020 / 1K tokens

但两者的计算单位不一样， Google 是按字符，OpenAI 是按 Token，如果是中文那 Google 便宜不少，如果是英文两者价格差不多。

更多详细内容可以参考其官方博客：https://blog.google/technology/ai/gemini-api-developers-cloud/
如果你更喜欢中文版本可以参考我的翻译：https://baoyu.io/translations/google/gemini-api-developers-cloud</title>
            <link>https://nitter.cz/dotey/status/1735064009974431884#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735064009974431884#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 22:27:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天 Google 的 Gemini Pro 通过 Gemini API 上线，并且提供了 API 访问，同时还有一个开发者的利好：目前 Gemini Pro 可免费使用！<br />
<br />
Gemini API 地址：<a href="http://ai.google.dev">ai.google.dev</a> <a href="https://ai.google.dev">ai.google.dev</a><br />
<br />
有关 Gemini Pro 的一些细节：<br />
<br />
- 在专业的基准测试中，Gemini Pro 的表现超越了其他同类模型。<br />
- 当前版本配备了 32K 文本上下文窗口，未来将推出拥有更广阔上下文窗口的版本。<br />
- 目前，Gemini Pro 可免费使用（存在一定使用限制），并且其定价将十分 有竞争力。<br />
- 它具备丰富的功能，包括函数调用、数据嵌入、语义检索、自定义知识嵌入以及聊天功能。<br />
- 它支持 全球超过 180 个国家和地区 的 38 种语言。<br />
- 在今日发布的版本中，Gemini Pro 可处理文本输入并生成文本输出。我们还推出了一个专门的 Gemini Pro 视觉多模态终端，能够处理图像和文本输入，输出文本。<br />
- Gemini Pro 提供了多种 SDK，以便开发者在不同平台上构建应用，包括 Python、Android (Kotlin)、Node.js、Swift 和 JavaScript。<br />
<br />
Gemini Pro 提供了易于使用的 SDK，助力开发者在任何平台上快速构建应用。<br />
<br />
另外 Google 还提供了一个免费的在线开发工具 Google AI Studio，你可以用它快速构建 Gemini 应用。<br />
<br />
Google AI Studio ：<a href="https://makersuite.google.com/">makersuite.google.com/</a><br />
<br />
最后是 Gemini Pro 定价策略，<br />
<br />
Gemini Pro<br />
<br />
INPUT<br />
$0.00025 / 1K characters<br />
$0.0025 / image<br />
<br />
OUTPUT<br />
$0.0005 / 1K characters<br />
<br />
对比一下 GPT-3.5 价格：<br />
gpt-3.5-turbo-1106<br />
INPUT<br />
$0.0010 / 1K tokens<br />
OUTPUT<br />
$0.0020 / 1K tokens<br />
<br />
但两者的计算单位不一样， Google 是按字符，OpenAI 是按 Token，如果是中文那 Google 便宜不少，如果是英文两者价格差不多。<br />
<br />
更多详细内容可以参考其官方博客：<a href="https://blog.google/technology/ai/gemini-api-developers-cloud/">blog.google/technology/ai/ge…</a><br />
如果你更喜欢中文版本可以参考我的翻译：<a href="https://baoyu.io/translations/google/gemini-api-developers-cloud">baoyu.io/translations/google…</a></p>
<p><a href="https://nitter.cz/sundarpichai/status/1734952757722001626#m">nitter.cz/sundarpichai/status/1734952757722001626#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JRbzJiMVhzQUFRcUh2LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735062406554874210#m</id>
            <title>RT by @Gorden_Sun: 微软在 HuggingFace 上发布了 Phi-2 的模型</title>
            <link>https://nitter.cz/dotey/status/1735062406554874210#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735062406554874210#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 22:21:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软在 HuggingFace 上发布了 Phi-2 的模型</p>
<p><a href="https://nitter.cz/_akhaliq/status/1735051609581793768#m">nitter.cz/_akhaliq/status/1735051609581793768#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735059338488697012#m</id>
            <title>RT by @Gorden_Sun: 现在已经可以在 iPhone 或 iPad 上本机离线运行开源的 Mistral-7B 大语言模型了！

需要借助 LLMFarm（http://llmfarm.site https://llmfarm.site/ ），一个支持 Apple Silicon 技术的开源客户端。对于设备的要求是：
- 一台至少配备M1 + 8GB RAM 的 iPad 或 iPhone
- 至少 8GB 的可用本地存储空间

在本机运行大语言模型有几个好处：
1. 无需联网
2. 不用担心隐私泄露

缺点就是能力要弱一些，机器配置不够高速度也不会太快。但多一些选择总是好的！

如果你想看详细的安装教程，可以看这个链接：https://www.linkedin.com/pulse/using-llms-locally-ipad-iphone-maciek-j%C4%99drzejczyk-cd0zf/

中文翻译：https://baoyu.io/translations/llm/using-llms-locally-ipad-iphone</title>
            <link>https://nitter.cz/dotey/status/1735059338488697012#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735059338488697012#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 22:09:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在已经可以在 iPhone 或 iPad 上本机离线运行开源的 Mistral-7B 大语言模型了！<br />
<br />
需要借助 LLMFarm（<a href="http://llmfarm.site">llmfarm.site</a> <a href="https://llmfarm.site/">llmfarm.site/</a> ），一个支持 Apple Silicon 技术的开源客户端。对于设备的要求是：<br />
- 一台至少配备M1 + 8GB RAM 的 iPad 或 iPhone<br />
- 至少 8GB 的可用本地存储空间<br />
<br />
在本机运行大语言模型有几个好处：<br />
1. 无需联网<br />
2. 不用担心隐私泄露<br />
<br />
缺点就是能力要弱一些，机器配置不够高速度也不会太快。但多一些选择总是好的！<br />
<br />
如果你想看详细的安装教程，可以看这个链接：<a href="https://www.linkedin.com/pulse/using-llms-locally-ipad-iphone-maciek-j%C4%99drzejczyk-cd0zf/">linkedin.com/pulse/using-llm…</a><br />
<br />
中文翻译：<a href="https://baoyu.io/translations/llm/using-llms-locally-ipad-iphone">baoyu.io/translations/llm/us…</a></p>
<p><a href="https://nitter.cz/emollick/status/1734931042211934543#m">nitter.cz/emollick/status/1734931042211934543#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/StabilityAI/status/1735009826814513342#m</id>
            <title>RT by @Gorden_Sun: Introducing Stable Zero123: Quality 3D object generation from single images.

Stable Zero123, a new in-house generative AI model is capable of creating 3D objects from any input image.

Due to improved training datasets and elevation conditioning, the model demonstrates 3D understanding of the object’s appearance from various angles with notably improved quality over Zero1-to-3 or Zero123-XL

Learn more here: https://bit.ly/48a5crq</title>
            <link>https://nitter.cz/StabilityAI/status/1735009826814513342#m</link>
            <guid isPermaLink="false">https://nitter.cz/StabilityAI/status/1735009826814513342#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 18:52:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Introducing Stable Zero123: Quality 3D object generation from single images.<br />
<br />
Stable Zero123, a new in-house generative AI model is capable of creating 3D objects from any input image.<br />
<br />
Due to improved training datasets and elevation conditioning, the model demonstrates 3D understanding of the object’s appearance from various angles with notably improved quality over Zero1-to-3 or Zero123-XL<br />
<br />
Learn more here: <a href="https://bit.ly/48a5crq">bit.ly/48a5crq</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0JQNnpscFdzQUFFSXQzLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dCUDZ6bHBXc0FBRUl0My5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734880198406091261#m</id>
            <title>AI资讯日报，12月13日：https://gorden-sun.notion.site/12-13-AI-01b51c85f79c495485bf7ef5531c0ded?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734880198406091261#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734880198406091261#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 10:17:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月13日：<a href="https://gorden-sun.notion.site/12-13-AI-01b51c85f79c495485bf7ef5531c0ded?pvs=4">gorden-sun.notion.site/12-13…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JPSVZPN2JZQUFoYkhGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734869378724950074#m</id>
            <title>RT by @Gorden_Sun: Krea现在开始向所有人开放，不需要邀请了，没有资格的可以试试了。</title>
            <link>https://nitter.cz/op7418/status/1734869378724950074#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734869378724950074#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 09:34:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Krea现在开始向所有人开放，不需要邀请了，没有资格的可以试试了。</p>
<p><a href="https://nitter.cz/krea_ai/status/1734866368489722035#m">nitter.cz/krea_ai/status/1734866368489722035#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1734612479106543703#m</id>
            <title>RT by @Gorden_Sun: 接着上次LLM inference 的选择，整理了一个repo。

包括了推理框架、推理后端以及性能评测（吞吐、QPS和首token延迟）。

目前评测只更新了2个，会尽快完成全部测试。

https://github.com/ninehills/llm-inference-benchmark</title>
            <link>https://nitter.cz/9hills/status/1734612479106543703#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1734612479106543703#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:33:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>接着上次LLM inference 的选择，整理了一个repo。<br />
<br />
包括了推理框架、推理后端以及性能评测（吞吐、QPS和首token延迟）。<br />
<br />
目前评测只更新了2个，会尽快完成全部测试。<br />
<br />
<a href="https://github.com/ninehills/llm-inference-benchmark">github.com/ninehills/llm-inf…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDYxMjEzMjcxOTkxNTAwOC9fODhDRmNMVj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734742684353380484#m</id>
            <title>RT by @Gorden_Sun: 作者声称在这个 21 分钟的新闻剪辑中，所有的主播乃至其中很多其他内容，都是由 AI 生成的！

AI 主播的报道，既丰富有料，又感人至深，还不至于太乏味，还不用担心负面新闻。

如果真的这么强，未来新闻主播职业会受到影响吗？</title>
            <link>https://nitter.cz/dotey/status/1734742684353380484#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734742684353380484#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 01:11:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者声称在这个 21 分钟的新闻剪辑中，所有的主播乃至其中很多其他内容，都是由 AI 生成的！<br />
<br />
AI 主播的报道，既丰富有料，又感人至深，还不至于太乏味，还不用担心负面新闻。<br />
<br />
如果真的这么强，未来新闻主播职业会受到影响吗？</p>
<p><a href="https://nitter.cz/channel1_ai/status/1734591810033373231#m">nitter.cz/channel1_ai/status/1734591810033373231#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/MSFTResearch/status/1734609807770898674#m</id>
            <title>RT by @Gorden_Sun: Today, we share our teams’ latest contributions, Phi-2 and promptbase.  

Phi-2 outperforms other existing small language models, yet it’s small enough to run on a laptop or mobile device. https://msft.it/6040ipYH6</title>
            <link>https://nitter.cz/MSFTResearch/status/1734609807770898674#m</link>
            <guid isPermaLink="false">https://nitter.cz/MSFTResearch/status/1734609807770898674#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:23:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Today, we share our teams’ latest contributions, Phi-2 and promptbase.  <br />
<br />
Phi-2 outperforms other existing small language models, yet it’s small enough to run on a laptop or mobile device. <a href="https://msft.it/6040ipYH6">msft.it/6040ipYH6</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDU4OTE3MzQ4OTY4NDQ4MC9wN0lIbEhPcz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734509504618983528#m</id>
            <title>AI资讯日报，12月12日：https://gorden-sun.notion.site/12-12-AI-faeb7be46e4a4e889b3ca3a1f24b3431?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734509504618983528#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734509504618983528#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 09:44:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月12日：<a href="https://gorden-sun.notion.site/12-12-AI-faeb7be46e4a4e889b3ca3a1f24b3431?pvs=4">gorden-sun.notion.site/12-12…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JJM0xfMmFBQUF0ak9VLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734508261007937869#m</id>
            <title>AnimateZero：对标AnimateDiff的项目
北大、腾讯、香港科技大学联合推出的项目，基于Stable Diffusion，支持文字生成视频、文字编辑视频，各个方面都跟AnimateDiff很像。
不过AnimateDiff已经有开源社区贡献的很多改进，想要超越有点难。
项目地址：https://vvictoryuki.github.io/animatezero.github.io/</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734508261007937869#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734508261007937869#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 09:39:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AnimateZero：对标AnimateDiff的项目<br />
北大、腾讯、香港科技大学联合推出的项目，基于Stable Diffusion，支持文字生成视频、文字编辑视频，各个方面都跟AnimateDiff很像。<br />
不过AnimateDiff已经有开源社区贡献的很多改进，想要超越有点难。<br />
项目地址：<a href="https://vvictoryuki.github.io/animatezero.github.io/">vvictoryuki.github.io/animat…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ1MDgxNDkwMTk5Njc0ODgvcHUvaW1nL01oN3F0X25iaHdyMDllMjIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734495786208272824#m</id>
            <title>Upscale-A-Video：AI提升视频画质
演示视频选的好哇。
项目地址：https://shangchenzhou.com/projects/upscale-a-video/
Github（代码暂未发布）：https://github.com/sczhou/Upscale-A-Video</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734495786208272824#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734495786208272824#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 08:49:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Upscale-A-Video：AI提升视频画质<br />
演示视频选的好哇。<br />
项目地址：<a href="https://shangchenzhou.com/projects/upscale-a-video/">shangchenzhou.com/projects/u…</a><br />
Github（代码暂未发布）：<a href="https://github.com/sczhou/Upscale-A-Video">github.com/sczhou/Upscale-A-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ0OTU2ODY1MTM4NzI4OTYvcHUvaW1nL05BYUl5RkxMLWt0QzJqN2guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734231321864818727#m</id>
            <title>R to @Gorden_Sun: Mixtral-8x7B-v0.1也正式在抱抱脸发布了：https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734231321864818727#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734231321864818727#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 15:19:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mixtral-8x7B-v0.1也正式在抱抱脸发布了：<a href="https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1">huggingface.co/mistralai/Mix…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDE1OTEwMDcwMjAyNzc3Ni9Nb251enNDYj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734229565114114552#m</id>
            <title>MistralAI太强了，正式宣布了他们的AI平台La Plateforme，提供3个模型：
Mistral Tiny，即之前的最强7B LLM
Mistral Small，即最近发布的混合专家模型Mixtral 7B×8，竟然只称为small!
Mistral Medium，尚未公开发布，能力显著优于ChatGPT 3.5
显然至少还有Large模型
官方新闻：https://mistral.ai/news/la-plateforme/</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734229565114114552#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734229565114114552#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 15:12:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MistralAI太强了，正式宣布了他们的AI平台La Plateforme，提供3个模型：<br />
Mistral Tiny，即之前的最强7B LLM<br />
Mistral Small，即最近发布的混合专家模型Mixtral 7B×8，竟然只称为small!<br />
Mistral Medium，尚未公开发布，能力显著优于ChatGPT 3.5<br />
显然至少还有Large模型<br />
官方新闻：<a href="https://mistral.ai/news/la-plateforme/">mistral.ai/news/la-plateform…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JFNGwxQmFRQUFQd2VKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734138085032780065#m</id>
            <title>AI资讯日报，12月10日：https://gorden-sun.notion.site/12-11-AI-31f9fa4e269248b88f4dfeb2abcef716?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734138085032780065#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734138085032780065#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 09:08:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月10日：<a href="https://gorden-sun.notion.site/12-11-AI-31f9fa4e269248b88f4dfeb2abcef716?pvs=4">gorden-sun.notion.site/12-11…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JEbFlYbGF3QUFNNmdWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734128575861944527#m</id>
            <title>MistralAI发布了关于混合专家模型Mixtral 8x7B的介绍。
核心信息：
· 32K上下文
· 支持英语、法语、意大利语、德语、西班牙语
· 整体能力超过LLaMa 2，且推理速度快6倍
· 能力与ChatGPT 3.5接近
· 有45B参数，但是每个token只使用12B的参数，所以推理速度与12B模型相同
https://mistral.ai/news/mixtral-of-experts/</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734128575861944527#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734128575861944527#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 08:30:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MistralAI发布了关于混合专家模型Mixtral 8x7B的介绍。<br />
核心信息：<br />
· 32K上下文<br />
· 支持英语、法语、意大利语、德语、西班牙语<br />
· 整体能力超过LLaMa 2，且推理速度快6倍<br />
· 能力与ChatGPT 3.5接近<br />
· 有45B参数，但是每个token只使用12B的参数，所以推理速度与12B模型相同<br />
<a href="https://mistral.ai/news/mixtral-of-experts/">mistral.ai/news/mixtral-of-e…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JEY3BFVGJNQUFPcVU4LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734093582913708368#m</id>
            <title>RT by @Gorden_Sun: AIGC Weekly 50期一周年了，第一期也是这个时候发布的，也是刚过完生日，那个时候想的就是随便写写，反正平时也要看，没想到一个周刊会让我发生这样的改变，我是一个很没有长性的人，几乎没有规律性坚持任何事情，这是唯一坚持的事情。感觉最重要的就是各位的支持，持续不断的正反馈才让我坚持这么久。

50 期地址：https://quail.ink/op7418/p/aigc-weekly-50</title>
            <link>https://nitter.cz/op7418/status/1734093582913708368#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734093582913708368#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 06:11:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AIGC Weekly 50期一周年了，第一期也是这个时候发布的，也是刚过完生日，那个时候想的就是随便写写，反正平时也要看，没想到一个周刊会让我发生这样的改变，我是一个很没有长性的人，几乎没有规律性坚持任何事情，这是唯一坚持的事情。感觉最重要的就是各位的支持，持续不断的正反馈才让我坚持这么久。<br />
<br />
50 期地址：<a href="https://quail.ink/op7418/p/aigc-weekly-50">quail.ink/op7418/p/aigc-week…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JDOG91ZmFJQUE2Q0tGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1733636113883885626#m</id>
            <title>RT by @Gorden_Sun: 推荐阅读：在 RAG 流程中提高检索效果：融合传统关键词与现代向量搜索的混合式搜索技术 [译]

这篇文章探讨了如何结合传统关键词搜索与现代向量搜索来获得更相关的搜索结果。

原文：Improving Retrieval Performance in RAG Pipelines with Hybrid Search
https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5

翻译：https://baoyu.io/translations/rag/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search</title>
            <link>https://nitter.cz/dotey/status/1733636113883885626#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1733636113883885626#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 23:53:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：在 RAG 流程中提高检索效果：融合传统关键词与现代向量搜索的混合式搜索技术 [译]<br />
<br />
这篇文章探讨了如何结合传统关键词搜索与现代向量搜索来获得更相关的搜索结果。<br />
<br />
原文：Improving Retrieval Performance in RAG Pipelines with Hybrid Search<br />
<a href="https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5">towardsdatascience.com/impro…</a><br />
<br />
翻译：<a href="https://baoyu.io/translations/rag/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search">baoyu.io/translations/rag/im…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDU5MDQ4MTgxNDczNjg5Ni9WandHcXlkRD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>