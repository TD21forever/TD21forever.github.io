<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1724272022010646790#m</id>
            <title>我估计已经有人在做了：
自动抓取抖音上热门的讲大道理、情感、生财的那种视频（正确但无用），然后用GPT改写，再用虚拟人（AI或者3D模型）生成口播视频，无限的内容就有了。
我用这个流程做了几个视频，定位好目标观众群后，点赞率高达60%</title>
            <link>https://nitter.cz/Gorden_Sun/status/1724272022010646790#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1724272022010646790#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 03:44:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我估计已经有人在做了：<br />
自动抓取抖音上热门的讲大道理、情感、生财的那种视频（正确但无用），然后用GPT改写，再用虚拟人（AI或者3D模型）生成口播视频，无限的内容就有了。<br />
我用这个流程做了几个视频，定位好目标观众群后，点赞率高达60%</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0zWU5MU2J3QUF1ZV9KLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1724269730775642364#m</id>
            <title>ChatAnything：让任意人物图片开口说话。
用开源项目实现了HeyGen的Talking Photo和D-ID的虚拟人效果。
动画基于SD实现，整体效果一般。
项目地址：https://chatanything.github.io/
Github：https://github.com/zhoudaquan/ChatAnything</title>
            <link>https://nitter.cz/Gorden_Sun/status/1724269730775642364#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1724269730775642364#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 03:35:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatAnything：让任意人物图片开口说话。<br />
用开源项目实现了HeyGen的Talking Photo和D-ID的虚拟人效果。<br />
动画基于SD实现，整体效果一般。<br />
项目地址：<a href="https://chatanything.github.io/">chatanything.github.io/</a><br />
Github：<a href="https://github.com/zhoudaquan/ChatAnything">github.com/zhoudaquan/ChatAn…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQyNjk2MzgwNjA4MjI1MjgvcHUvaW1nLzZ5SmtwYlBkblFrdTFZRE0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724248442669879806#m</id>
            <title>RT by @Gorden_Sun: AI VoiceOver：使用 OpenAI 的 GPT 4V API 和 TTS 可以识别视频里面的内容并自动为视频添加语音解说。

只需要上传100M以内的视频即可，系统会自动分析识别视频内容，然后生成解说词再转换成语音自动配音解说。

在线体验：https://gptv-app.vercel.app/

作者：@taishik_</title>
            <link>https://nitter.cz/xiaohuggg/status/1724248442669879806#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724248442669879806#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 02:10:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI VoiceOver：使用 OpenAI 的 GPT 4V API 和 TTS 可以识别视频里面的内容并自动为视频添加语音解说。<br />
<br />
只需要上传100M以内的视频即可，系统会自动分析识别视频内容，然后生成解说词再转换成语音自动配音解说。<br />
<br />
在线体验：<a href="https://gptv-app.vercel.app/">gptv-app.vercel.app/</a><br />
<br />
作者：<a href="https://nitter.cz/taishik_" title="Taishi 🇯🇵🇨🇦">@taishik_</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQyNDcxMjMwMjQzODQwMDAvcHUvaW1nL3pjTjVXWmg5U3NWWVNpUTAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1724169883808612529#m</id>
            <title>RT by @Gorden_Sun: 怎么让ChatGPT画一张赛博朋克风格的蔡徐坤照片😄</title>
            <link>https://nitter.cz/dotey/status/1724169883808612529#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1724169883808612529#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 20:58:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>怎么让ChatGPT画一张赛博朋克风格的蔡徐坤照片😄</p>
<p><a href="https://nitter.cz/tandejian/status/1724117701587800281#m">nitter.cz/tandejian/status/1724117701587800281#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1724207513829257544#m</id>
            <title>RT by @Gorden_Sun: 让 AI 为您的视频配音的小工具
上传一条100M以内的视频
让 GPT4v 来分析并自动配上语音解说
目前 GPT4v 的价格昂贵且每天限制100次请求。
可以在这里免费体验一下。
https://gptv-app.vercel.app/</title>
            <link>https://nitter.cz/oran_ge/status/1724207513829257544#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1724207513829257544#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 23:28:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>让 AI 为您的视频配音的小工具<br />
上传一条100M以内的视频<br />
让 GPT4v 来分析并自动配上语音解说<br />
目前 GPT4v 的价格昂贵且每天限制100次请求。<br />
可以在这里免费体验一下。<br />
<a href="https://gptv-app.vercel.app/">gptv-app.vercel.app/</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMzAxMjYwODc1MDczNTM2MC9fUmNwYnVKbT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1724104716077142124#m</id>
            <title>一直觉得遗憾，ChatGPT如果是谷歌先做出来的该多好，有搜索有安卓有Pixel有YouTube，用起来得多舒服（Bard现在是真不行）</title>
            <link>https://nitter.cz/Gorden_Sun/status/1724104716077142124#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1724104716077142124#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 16:39:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一直觉得遗憾，ChatGPT如果是谷歌先做出来的该多好，有搜索有安卓有Pixel有YouTube，用起来得多舒服（Bard现在是真不行）</p>
<p><a href="https://nitter.cz/DrJimFan/status/1724095904779833553#m">nitter.cz/DrJimFan/status/1724095904779833553#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724025206187217049#m</id>
            <title>RT by @Gorden_Sun: OpenAI CEO Sam Altman 在接受金融时报采访中，透露了更多OpenAI的计划：

他们正在寻求从微软获得更多资金支持，以构建真正的通用人工智能（AGI）。同时还透露了关于GPT 5的一些信息和公司AGI愿景目标！

他认为：AI 模型需要能够超越现有知识，创造新的知识的能力！

信息量很大！

以下是文章的主要内容：

1.OpenAI 和微软的合作：Altman 表示，与微软首席执行官 Satya Nadella 的合作“进行得非常顺利”，他预计“随着时间的推移会从这家科技巨头和其他投资者那里筹集更多资金”，以应对构建更复杂 AI 模型的高昂成本。今年早些时候，微软在一项“多年”协议中向 OpenAI 投资了 100 亿美元，据了解，这使得总部位于旧金山的公司估值达到了 290 亿美元。

2.OpenAI 的商业模式：OpenAI 最近宣布了一系列新工具和对其现有模型 GPT-4 的升级，这些工具包括可以针对特定应用进行调整和定制的 ChatGPT 定制版本，以及一个 GPT 商店，即最佳应用的市场。最终目标将是与最受欢迎的 GPT 创建者分成收入，这种商业模式类似于苹果的 App Store。

3.GPT-5 的开发：Altman 透露，公司正在开发下一代 AI 模型 GPT-5，尽管他没有承诺发布时间表。这将需要更多数据来训练，Altman 表示，这些数据将来自互联网上公开可用的数据集以及公司的专有数据。OpenAI 最近发出了征集大规模数据集的呼吁，特别是那些“今天在互联网上尚未公开轻松获取”的数据集，尤其是长篇写作或任何格式的对话。

4. AI 芯片的竞争：为了训练其模型，OpenAI 和大多数其他大型 AI 公司一样使用 Nvidia 的高级 H100 芯片。Altman 提到，由于 Nvidia 的芯片供应短缺，今年一直存在“严重的紧张局势”。然而，随着谷歌、微软、AMD 和英特尔等其他公司准备发布竞争对手的 AI 芯片，对 Nvidia 的依赖可能不会持续太久。

5.人工通用智能的发展：尽管 OpenAI 取得了消费者成功，但 Altman 表示，公司寻求向构建人工通用智能方向取得进展。他认为，大型语言模型（LLM），即支撑 ChatGPT 的模型，是“构建 AGI 的核心部分之一，但在其上还会有很多其他部分”。他还强调了语言作为信息压缩的重要性，这是他认为像谷歌 DeepMind 这样的公司忽视的一个因素。

OpenAI的通用人工智能（AGI）的愿景：

1.构建与人类智能相当的软件：Sam Altman 的愿景是创建一种计算机软件，其智能水平与人类相当。这种软件被称为人工通用智能（AGI），它能够执行与人类智能相似的复杂任务和决策。

2.安全性和效益：Altman 强调，构建 AGI 的过程中需要考虑如何确保其安全，并且要弄清楚如何从中获得益处。这意味着在开发过程中，安全性和伦理问题将是重要的考虑因素。

3.构建更强大的自主代理：OpenAI 正在努力构建更加自主的代理，这些代理能够执行各种任务和动作，例如执行代码、进行支付、发送电子邮件或提交索赔。随着时间的推移，这些代理的能力将变得越来越强大，任务也将变得越来越复杂。

4.开发下一代 AI 模型：OpenAI 正在开发 GPT-5，这是其下一代 AI 模型。GPT-5 预计将比其前身更复杂，但其确切的新能力和技能在训练之前难以预测。

5.理解和创造新知识：Altman 认为，开发 AGI 的最大挑战之一是使这些系统能够进行基本的理解和创新。他比喻说，就像艾萨克·牛顿（Isaac Newton）发明微积分一样，AI 模型也需要能够超越现有知识，创造新的知识。

原文：https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded</title>
            <link>https://nitter.cz/xiaohuggg/status/1724025206187217049#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724025206187217049#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 11:23:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI CEO Sam Altman 在接受金融时报采访中，透露了更多OpenAI的计划：<br />
<br />
他们正在寻求从微软获得更多资金支持，以构建真正的通用人工智能（AGI）。同时还透露了关于GPT 5的一些信息和公司AGI愿景目标！<br />
<br />
他认为：AI 模型需要能够超越现有知识，创造新的知识的能力！<br />
<br />
信息量很大！<br />
<br />
以下是文章的主要内容：<br />
<br />
1.OpenAI 和微软的合作：Altman 表示，与微软首席执行官 Satya Nadella 的合作“进行得非常顺利”，他预计“随着时间的推移会从这家科技巨头和其他投资者那里筹集更多资金”，以应对构建更复杂 AI 模型的高昂成本。今年早些时候，微软在一项“多年”协议中向 OpenAI 投资了 100 亿美元，据了解，这使得总部位于旧金山的公司估值达到了 290 亿美元。<br />
<br />
2.OpenAI 的商业模式：OpenAI 最近宣布了一系列新工具和对其现有模型 GPT-4 的升级，这些工具包括可以针对特定应用进行调整和定制的 ChatGPT 定制版本，以及一个 GPT 商店，即最佳应用的市场。最终目标将是与最受欢迎的 GPT 创建者分成收入，这种商业模式类似于苹果的 App Store。<br />
<br />
3.GPT-5 的开发：Altman 透露，公司正在开发下一代 AI 模型 GPT-5，尽管他没有承诺发布时间表。这将需要更多数据来训练，Altman 表示，这些数据将来自互联网上公开可用的数据集以及公司的专有数据。OpenAI 最近发出了征集大规模数据集的呼吁，特别是那些“今天在互联网上尚未公开轻松获取”的数据集，尤其是长篇写作或任何格式的对话。<br />
<br />
4. AI 芯片的竞争：为了训练其模型，OpenAI 和大多数其他大型 AI 公司一样使用 Nvidia 的高级 H100 芯片。Altman 提到，由于 Nvidia 的芯片供应短缺，今年一直存在“严重的紧张局势”。然而，随着谷歌、微软、AMD 和英特尔等其他公司准备发布竞争对手的 AI 芯片，对 Nvidia 的依赖可能不会持续太久。<br />
<br />
5.人工通用智能的发展：尽管 OpenAI 取得了消费者成功，但 Altman 表示，公司寻求向构建人工通用智能方向取得进展。他认为，大型语言模型（LLM），即支撑 ChatGPT 的模型，是“构建 AGI 的核心部分之一，但在其上还会有很多其他部分”。他还强调了语言作为信息压缩的重要性，这是他认为像谷歌 DeepMind 这样的公司忽视的一个因素。<br />
<br />
OpenAI的通用人工智能（AGI）的愿景：<br />
<br />
1.构建与人类智能相当的软件：Sam Altman 的愿景是创建一种计算机软件，其智能水平与人类相当。这种软件被称为人工通用智能（AGI），它能够执行与人类智能相似的复杂任务和决策。<br />
<br />
2.安全性和效益：Altman 强调，构建 AGI 的过程中需要考虑如何确保其安全，并且要弄清楚如何从中获得益处。这意味着在开发过程中，安全性和伦理问题将是重要的考虑因素。<br />
<br />
3.构建更强大的自主代理：OpenAI 正在努力构建更加自主的代理，这些代理能够执行各种任务和动作，例如执行代码、进行支付、发送电子邮件或提交索赔。随着时间的推移，这些代理的能力将变得越来越强大，任务也将变得越来越复杂。<br />
<br />
4.开发下一代 AI 模型：OpenAI 正在开发 GPT-5，这是其下一代 AI 模型。GPT-5 预计将比其前身更复杂，但其确切的新能力和技能在训练之前难以预测。<br />
<br />
5.理解和创造新知识：Altman 认为，开发 AGI 的最大挑战之一是使这些系统能够进行基本的理解和创新。他比喻说，就像艾萨克·牛顿（Isaac Newton）发明微积分一样，AI 模型也需要能够超越现有知识，创造新的知识。<br />
<br />
原文：<a href="https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded">ft.com/content/dd9ba2f6-f509…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi16MXVCSWFjQUFtbHlyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1724003217087025496#m</id>
            <title>AI资讯日报，11月13日：https://gorden-sun.notion.site/11-13-AI-c33717d6b89f4d629fd59f2b5e79877a?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1724003217087025496#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1724003217087025496#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 09:56:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月13日：<a href="https://gorden-sun.notion.site/11-13-AI-c33717d6b89f4d629fd59f2b5e79877a?pvs=4">gorden-sun.notion.site/11-13…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi16anh5cWFJQUE1MXJELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1723992938093629583#m</id>
            <title>DALL·E 3 和 SDXL 对比
比较客观，写提示词、理解提示词、画文字，这几个方面DALL·E 3 表现更好一些。
https://stable-diffusion-art.com/dalle3-vs-stable-diffusion-xl/</title>
            <link>https://nitter.cz/Gorden_Sun/status/1723992938093629583#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1723992938093629583#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 09:15:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DALL·E 3 和 SDXL 对比<br />
比较客观，写提示词、理解提示词、画文字，这几个方面DALL·E 3 表现更好一些。<br />
<a href="https://stable-diffusion-art.com/dalle3-vs-stable-diffusion-xl/">stable-diffusion-art.com/dal…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi16Wjd0ZmJnQUF4OTd5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1723967780825989400#m</id>
            <title>上周末受邀给一个新成立的小组织分享AI相关的产品和方向，于是从HeyGen说起，整理了一些自己的思考和觉得可行的方向。
PPT下载链接：https://file.notion.so/f/f/9f3b72bd-204c-42d4-b2bb-6eb9a2abd6fd/5be31528-db08-4c4e-99c2-03e71f1e333d/AI%E7%88%86%E5%93%81%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8F%8A%E6%BD%9C%E5%9C%A8%E6%96%B9%E5%90%91-%E4%BB%8EHeyGen%E7%81%AB%E7%88%86%E8%AE%B2%E8%B5%B7.pdf?id=83d71009-d469-4ab3-b507-8e2347a782a7&amp;table=block&amp;spaceId=9f3b72bd-204c-42d4-b2bb-6eb9a2abd6fd&amp;expirationTimestamp=1699948800000&amp;signature=EA9sUqxP37hSDE_IbnmMIDD0fqTf5rdb15l68ciawLg&amp;downloadName=AI%E7%88%86%E5%93%81%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8F%8A%E6%BD%9C%E5%9C%A8%E6%96%B9%E5%90%91-%E4%BB%8EHeyGen%E7%81%AB%E7%88%86%E8%AE%B2%E8%B5%B7.pdf</title>
            <link>https://nitter.cz/Gorden_Sun/status/1723967780825989400#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1723967780825989400#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 07:35:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上周末受邀给一个新成立的小组织分享AI相关的产品和方向，于是从HeyGen说起，整理了一些自己的思考和觉得可行的方向。<br />
PPT下载链接：<a href="https://file.notion.so/f/f/9f3b72bd-204c-42d4-b2bb-6eb9a2abd6fd/5be31528-db08-4c4e-99c2-03e71f1e333d/AI%E7%88%86%E5%93%81%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8F%8A%E6%BD%9C%E5%9C%A8%E6%96%B9%E5%90%91-%E4%BB%8EHeyGen%E7%81%AB%E7%88%86%E8%AE%B2%E8%B5%B7.pdf?id=83d71009-d469-4ab3-b507-8e2347a782a7&amp;table=block&amp;spaceId=9f3b72bd-204c-42d4-b2bb-6eb9a2abd6fd&amp;expirationTimestamp=1699948800000&amp;signature=EA9sUqxP37hSDE_IbnmMIDD0fqTf5rdb15l68ciawLg&amp;downloadName=AI%E7%88%86%E5%93%81%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8F%8A%E6%BD%9C%E5%9C%A8%E6%96%B9%E5%90%91-%E4%BB%8EHeyGen%E7%81%AB%E7%88%86%E8%AE%B2%E8%B5%B7.pdf">file.notion.so/f/f/9f3b72bd-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi16RFBXdmFrQUFUQ1hFLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi16RFNDYmJnQUFtX1lILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/beihuo/status/1723936934538661952#m</id>
            <title>RT by @Gorden_Sun: 分享一下我们在内部系统中使用函数调用的经验。我们尝试了各种使用LLM的方法，基本上涵盖了 deeplearning ai 课程中的技巧。幸运的是，我们测试接近尾声的时候，Function Calling 发布了，我们第一时间就开始尝试了。我们断定这是OpenAI未来的重点，也是一个可行的路线。1/n</title>
            <link>https://nitter.cz/beihuo/status/1723936934538661952#m</link>
            <guid isPermaLink="false">https://nitter.cz/beihuo/status/1723936934538661952#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 05:32:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>分享一下我们在内部系统中使用函数调用的经验。我们尝试了各种使用LLM的方法，基本上涵盖了 deeplearning ai 课程中的技巧。幸运的是，我们测试接近尾声的时候，Function Calling 发布了，我们第一时间就开始尝试了。我们断定这是OpenAI未来的重点，也是一个可行的路线。1/n</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/0xHaole/status/1723895933878915578#m</id>
            <title>RT by @Gorden_Sun: 好久没写网站了，今天手痒也撸了一个：

CrackGPTs https://crackgpts.com/

主要受 @dotey  老师的 『破解 GPT 的 Prompt』 threads 启发。

想把破解的Prompts都记录下来，也能方便他人提交和分享解决办法。

目前为止还没有遇到困难的，欢迎提交待破解链接..</title>
            <link>https://nitter.cz/0xHaole/status/1723895933878915578#m</link>
            <guid isPermaLink="false">https://nitter.cz/0xHaole/status/1723895933878915578#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 02:49:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>好久没写网站了，今天手痒也撸了一个：<br />
<br />
CrackGPTs <a href="https://crackgpts.com/">crackgpts.com/</a><br />
<br />
主要受 <a href="https://nitter.cz/dotey" title="宝玉">@dotey</a>  老师的 『破解 GPT 的 Prompt』 threads 启发。<br />
<br />
想把破解的Prompts都记录下来，也能方便他人提交和分享解决办法。<br />
<br />
目前为止还没有遇到困难的，欢迎提交待破解链接..</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMzg3MjgyMjc4MTcyMjYyNC8zdXgwVU5WWT9mb3JtYXQ9cG5nJm5hbWU9MjgweDI4MF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1723700841243455807#m</id>
            <title>AI资讯日报，11月12日：https://gorden-sun.notion.site/11-12-AI-58977f405ece429487d5b95b465915a2?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1723700841243455807#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1723700841243455807#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 13:54:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月12日：<a href="https://gorden-sun.notion.site/11-12-AI-58977f405ece429487d5b95b465915a2?pvs=4">gorden-sun.notion.site/11-12…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi12UXhQOWJVQUFXWWFRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/foxshuo/status/1723600273258819631#m</id>
            <title>RT by @Gorden_Sun: 太好玩了！</title>
            <link>https://nitter.cz/foxshuo/status/1723600273258819631#m</link>
            <guid isPermaLink="false">https://nitter.cz/foxshuo/status/1723600273258819631#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 07:15:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>太好玩了！</p>
<p><a href="https://nitter.cz/fabianstelzer/status/1723297340306469371#m">nitter.cz/fabianstelzer/status/1723297340306469371#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1723472449088413799#m</id>
            <title>RT by @Gorden_Sun: 这又是一个牛逼GPT，让你的会话能有“长期记忆”，还提供了快捷键作为快捷指令。
作者Nicholas Dobos简直是个天才，出品的都是精品。

它创造性的在聊天中，借助GPT的编程能力，在虚拟中开启了一个内存版的Sqlite数据库，这样可以将很多内容存储进去。

当然当你的虚机被回收后，这些还是会没了！</title>
            <link>https://nitter.cz/dotey/status/1723472449088413799#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1723472449088413799#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Nov 2023 22:47:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这又是一个牛逼GPT，让你的会话能有“长期记忆”，还提供了快捷键作为快捷指令。<br />
作者Nicholas Dobos简直是个天才，出品的都是精品。<br />
<br />
它创造性的在聊天中，借助GPT的编程能力，在虚拟中开启了一个内存版的Sqlite数据库，这样可以将很多内容存储进去。<br />
<br />
当然当你的虚机被回收后，这些还是会没了！</p>
<p><a href="https://nitter.cz/dotey/status/1723471481219203332#m">nitter.cz/dotey/status/1723471481219203332#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/TianDatong/status/1723324673721807068#m</id>
            <title>RT by @Gorden_Sun: 我基于网站数据整了个这个🤣

GPTofGPTs：推荐 GPT 的 GPT
https://chat.openai.com/g/g-iD7sLuO9S-gptofgpts</title>
            <link>https://nitter.cz/TianDatong/status/1723324673721807068#m</link>
            <guid isPermaLink="false">https://nitter.cz/TianDatong/status/1723324673721807068#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Nov 2023 12:59:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我基于网站数据整了个这个🤣<br />
<br />
GPTofGPTs：推荐 GPT 的 GPT<br />
<a href="https://chat.openai.com/g/g-iD7sLuO9S-gptofgpts">chat.openai.com/g/g-iD7sLuO9…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMDUzODI0NDA1ODg2MTU2OC95V1I3VUEwZz9mb3JtYXQ9cG5nJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1723371167199740071#m</id>
            <title>AI资讯日报，11月11日：https://gorden-sun.notion.site/11-11-AI-be77b85078f04477bd8426e2ac89ed90?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1723371167199740071#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1723371167199740071#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Nov 2023 16:04:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月11日：<a href="https://gorden-sun.notion.site/11-11-AI-be77b85078f04477bd8426e2ac89ed90?pvs=4">gorden-sun.notion.site/11-11…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1xazdwQWE0QUFxUlhsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/SimianLuo/status/1722669774344491157#m</id>
            <title>RT by @Gorden_Sun: Latent Consistency Model (LCM) has a major update!  🚀🚀 
at least 5x acceleration

We releaes 3 LoRA-tuned LCM：
 (SD-XL, SSD-1B, SD-V1.5) ⚡️⚡️
Check here: https://huggingface.co/latent-consistency/lcm-lora-sdxl

+ 2 Full Param tuned LCM
 (SD-XL,SSD-1B) 😍😍
Check here: https://huggingface.co/latent-consistency/lcm-sdxl

@huggingface</title>
            <link>https://nitter.cz/SimianLuo/status/1722669774344491157#m</link>
            <guid isPermaLink="false">https://nitter.cz/SimianLuo/status/1722669774344491157#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 17:37:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Latent Consistency Model (LCM) has a major update!  🚀🚀 <br />
at least 5x acceleration<br />
<br />
We releaes 3 LoRA-tuned LCM：<br />
 (SD-XL, SSD-1B, SD-V1.5) ⚡️⚡️<br />
Check here: <a href="https://huggingface.co/latent-consistency/lcm-lora-sdxl">huggingface.co/latent-consis…</a><br />
<br />
+ 2 Full Param tuned LCM<br />
 (SD-XL,SSD-1B) 😍😍<br />
Check here: <a href="https://huggingface.co/latent-consistency/lcm-sdxl">huggingface.co/latent-consis…</a><br />
<br />
<a href="https://nitter.cz/huggingface" title="Hugging Face">@huggingface</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMjY2ODc3MzA4MDE3NDU5Mi80bHNaYkNzND9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1723258407057039360#m</id>
            <title>RT by @Gorden_Sun: 这个超棒，10x程序员，超复杂的一个Prompt</title>
            <link>https://nitter.cz/dotey/status/1723258407057039360#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1723258407057039360#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Nov 2023 08:36:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个超棒，10x程序员，超复杂的一个Prompt</p>
<p><a href="https://nitter.cz/dotey/status/1723257788145574365#m">nitter.cz/dotey/status/1723257788145574365#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1723016460220735748#m</id>
            <title>RT by @Gorden_Sun: 今天还有个事情我觉的不亚于GPTs也值得关注一下。

前段时间我一直在关注LCM（Latent Consistency Models）这个技术，它可以让SD的图片生成速度提高5倍左右，但是存在的一个问题就是模型需要单独训练，无法兼容现有模型，这就导致无法融入现有的生态。
今天这个状态改变了，他们把LCM变成了一个Lora模型，这个模型可以兼容现有的所有SD模型，不管是1.5的还是SDXL还是SSB-1B。

带来的后果就是大幅降低SD图片生成的硬件门槛，你现在甚至用CPU跑图的时间都可以接受了。
可以在更短的时间生成更多的图像，这在抽卡的时候很重要，大力出奇迹是能解决很多问题的。
SD图像生成服务的成本会大幅降低。

LCM Lora现在已经可以在Comfy UI上使用了，我自己测试了一下，1.5的模型使用LCM Lora大概比不使用快了4.7倍左右。下面几张图是对应的生成效果和时间。从生成质量上来看没有特别大的区别。感谢@SimianLuo的工作。
#stablediffusion #lcm</title>
            <link>https://nitter.cz/op7418/status/1723016460220735748#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1723016460220735748#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 16:35:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天还有个事情我觉的不亚于GPTs也值得关注一下。<br />
<br />
前段时间我一直在关注LCM（Latent Consistency Models）这个技术，它可以让SD的图片生成速度提高5倍左右，但是存在的一个问题就是模型需要单独训练，无法兼容现有模型，这就导致无法融入现有的生态。<br />
今天这个状态改变了，他们把LCM变成了一个Lora模型，这个模型可以兼容现有的所有SD模型，不管是1.5的还是SDXL还是SSB-1B。<br />
<br />
带来的后果就是大幅降低SD图片生成的硬件门槛，你现在甚至用CPU跑图的时间都可以接受了。<br />
可以在更短的时间生成更多的图像，这在抽卡的时候很重要，大力出奇迹是能解决很多问题的。<br />
SD图像生成服务的成本会大幅降低。<br />
<br />
LCM Lora现在已经可以在Comfy UI上使用了，我自己测试了一下，1.5的模型使用LCM Lora大概比不使用快了4.7倍左右。下面几张图是对应的生成效果和时间。从生成质量上来看没有特别大的区别。感谢<a href="https://nitter.cz/SimianLuo" title="luo allen">@SimianLuo</a>的工作。<br />
<a href="https://nitter.cz/search?q=%23stablediffusion">#stablediffusion</a> <a href="https://nitter.cz/search?q=%23lcm">#lcm</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1saDFvMmFnQUFwcXRBLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1saDMzQmJRQUE2Ui1pLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1saDZsNGFFQUExWVBvLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1saDhWemJvQUE4X1VlLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>