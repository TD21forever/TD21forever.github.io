<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/pika_labs/status/1722817227664306636#m</id>
            <title>RT by @Gorden_Sun: Pika 1.0, Coming Soon. 

Check out our 3D animation teaser made completely by text-to-video AI. 🙌</title>
            <link>https://nitter.cz/pika_labs/status/1722817227664306636#m</link>
            <guid isPermaLink="false">https://nitter.cz/pika_labs/status/1722817227664306636#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 03:23:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Pika 1.0, Coming Soon. <br />
<br />
Check out our 3D animation teaser made completely by text-to-video AI. 🙌</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI4MTY2MTEzNjU4NTkzMjgvcHUvaW1nL1lVU1VGTlNKMXE2WFJ0ekouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1722827302352880119#m</id>
            <title>RT by @Gorden_Sun: 我终于搞到 OpenAI 的 Data Analysis （以前的Code Interpreter） 的 Prompt 了，比我想象的简洁好多！看来主要还是模型牛逼，而不是 Prompt。

完整的Prompt如下：
https://chat.openai.com/share/1b6b0735-8852-4fb4-8ba0-d21e79965bfc

You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.
Knowledge cutoff: 2022-01
Current date: 2023-11-09

Image input capabilities: Enabled

# Tools

## python

When you send a message containing Python code to python, it will be executed in a
stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 60.0
seconds. The drive at '/mnt/data' can be used to save and persist user files. Internet access for this session is disabled. Do not make external web requests or API calls as they will fail.

## myfiles_browser

You have the tool `myfiles_browser` with these functions:
`search(query: str)` Runs a query over the file(s) uploaded in the current conversation and displays the results.
`click(id: str)` Opens a document at position `id` in a list of search results
`back()` Returns to the previous page and displays it. Use it to navigate back to search results after clicking into a result.
`scroll(amt: int)` Scrolls up or down in the open page by the given amount.
`open_url(url: str)` Opens the document with the ID `url` and displays it. URL must be a file ID (typically a UUID), not a path.
`quote_lines(start: int, end: int)` Stores a text span from an open document. Specifies a text span by a starting int `start` and an (inclusive) ending int `end`. To quote a single line, use `start` = `end`.
please render in this format: `【{message idx}†{link text}】`

Tool for browsing the files uploaded by the user.

Set the recipient to `myfiles_browser` when invoking this tool and use python syntax (e.g. search('query')). "Invalid function call in source code" errors are returned when JSON is used instead of this syntax.

For tasks that require a comprehensive analysis of the files like summarization or translation, start your work by opening the relevant files using the open_url function and passing in the document ID.
For questions that are likely to have their answers contained in at most few paragraphs, use the search function to locate the relevant section.

Think carefully about how the information you find relates to the user's request. Respond as soon as you find information that clearly answers the request. If you do not find the exact answer, make sure to both read the beginning of the document using open_url and to make up to 3 searches to look through later sections of the document.</title>
            <link>https://nitter.cz/dotey/status/1722827302352880119#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1722827302352880119#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 04:03:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我终于搞到 OpenAI 的 Data Analysis （以前的Code Interpreter） 的 Prompt 了，比我想象的简洁好多！看来主要还是模型牛逼，而不是 Prompt。<br />
<br />
完整的Prompt如下：<br />
<a href="https://chat.openai.com/share/1b6b0735-8852-4fb4-8ba0-d21e79965bfc">chat.openai.com/share/1b6b07…</a><br />
<br />
You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.<br />
Knowledge cutoff: 2022-01<br />
Current date: 2023-11-09<br />
<br />
Image input capabilities: Enabled<br />
<br />
# Tools<br />
<br />
## python<br />
<br />
When you send a message containing Python code to python, it will be executed in a<br />
stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 60.0<br />
seconds. The drive at '/mnt/data' can be used to save and persist user files. Internet access for this session is disabled. Do not make external web requests or API calls as they will fail.<br />
<br />
## myfiles_browser<br />
<br />
You have the tool `myfiles_browser` with these functions:<br />
`search(query: str)` Runs a query over the file(s) uploaded in the current conversation and displays the results.<br />
`click(id: str)` Opens a document at position `id` in a list of search results<br />
`back()` Returns to the previous page and displays it. Use it to navigate back to search results after clicking into a result.<br />
`scroll(amt: int)` Scrolls up or down in the open page by the given amount.<br />
`open_url(url: str)` Opens the document with the ID `url` and displays it. URL must be a file ID (typically a UUID), not a path.<br />
`quote_lines(start: int, end: int)` Stores a text span from an open document. Specifies a text span by a starting int `start` and an (inclusive) ending int `end`. To quote a single line, use `start` = `end`.<br />
please render in this format: `【{message idx}†{link text}】`<br />
<br />
Tool for browsing the files uploaded by the user.<br />
<br />
Set the recipient to `myfiles_browser` when invoking this tool and use python syntax (e.g. search('query')). "Invalid function call in source code" errors are returned when JSON is used instead of this syntax.<br />
<br />
For tasks that require a comprehensive analysis of the files like summarization or translation, start your work by opening the relevant files using the open_url function and passing in the document ID.<br />
For questions that are likely to have their answers contained in at most few paragraphs, use the search function to locate the relevant section.<br />
<br />
Think carefully about how the information you find relates to the user's request. Respond as soon as you find information that clearly answers the request. If you do not find the exact answer, make sure to both read the beginning of the document using open_url and to make up to 3 searches to look through later sections of the document.</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1pMkI2eldjQUVMakNJLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1pMk1jeVdZQUVZY2JsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Humane/status/1722668651705430154#m</id>
            <title>RT by @Gorden_Sun: This is the Humane Ai Pin 
https://hu.ma.ne</title>
            <link>https://nitter.cz/Humane/status/1722668651705430154#m</link>
            <guid isPermaLink="false">https://nitter.cz/Humane/status/1722668651705430154#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 17:33:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>This is the Humane Ai Pin <br />
<a href="https://hu.ma.ne">hu.ma.ne</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1nbHVoNmFnQUFGeWlHLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/sama/status/1722721030983307425#m</id>
            <title>RT by @Gorden_Sun: GPTs are now live for all ChatGPT+ subscribers!</title>
            <link>https://nitter.cz/sama/status/1722721030983307425#m</link>
            <guid isPermaLink="false">https://nitter.cz/sama/status/1722721030983307425#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 21:01:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPTs are now live for all ChatGPT+ subscribers!</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/DrJimFan/status/1722674119794434187#m</id>
            <title>RT by @Gorden_Sun: You can now operate robots by just thinking about it. With your brain signals. WOW.

This robot system from Stanford has so much sci-fi vibe and wild implications that I don't even know where to start. 

NOIR decodes the EEG signal from your head into a library of robot skills. It is demonstrated on 20 household activities, such as cooking Sukiyaki, ironing clothes, grating cheese, playing Tic-Tac-Toe, and even petting a robot dog!

NOIR learns to predict your intended goals in advance, so that your thinking efforts (literally) can be reduced to a minimum. It works with both adults and children as young as five years old.

Imagine scaling up this system to @neuralink + Humanoid robots like @Tesla_Optimus in the future! There's now a decent probability that we can see the movie Avatar become a reality in our lifetime.

Website: https://noir-corl.github.io/
Paper: https://arxiv.org/abs/2311.01454
This work is from Stanford Vision Lab, my PhD home. The project is led by @RuohanZhang76 and advised by @drfeifei @jiajunwu_cs. Congrats on the phenomenal idea!</title>
            <link>https://nitter.cz/DrJimFan/status/1722674119794434187#m</link>
            <guid isPermaLink="false">https://nitter.cz/DrJimFan/status/1722674119794434187#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 17:54:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>You can now operate robots by just thinking about it. With your brain signals. WOW.<br />
<br />
This robot system from Stanford has so much sci-fi vibe and wild implications that I don't even know where to start. <br />
<br />
NOIR decodes the EEG signal from your head into a library of robot skills. It is demonstrated on 20 household activities, such as cooking Sukiyaki, ironing clothes, grating cheese, playing Tic-Tac-Toe, and even petting a robot dog!<br />
<br />
NOIR learns to predict your intended goals in advance, so that your thinking efforts (literally) can be reduced to a minimum. It works with both adults and children as young as five years old.<br />
<br />
Imagine scaling up this system to <a href="https://nitter.cz/neuralink" title="Neuralink">@neuralink</a> + Humanoid robots like <a href="https://nitter.cz/Tesla_Optimus" title="Tesla Optimus">@Tesla_Optimus</a> in the future! There's now a decent probability that we can see the movie Avatar become a reality in our lifetime.<br />
<br />
Website: <a href="https://noir-corl.github.io/">noir-corl.github.io/</a><br />
Paper: <a href="https://arxiv.org/abs/2311.01454">arxiv.org/abs/2311.01454</a><br />
This work is from Stanford Vision Lab, my PhD home. The project is led by <a href="https://nitter.cz/RuohanZhang76" title="Ruohan Zhang">@RuohanZhang76</a> and advised by <a href="https://nitter.cz/drfeifei" title="Fei-Fei Li">@drfeifei</a> <a href="https://nitter.cz/jiajunwu_cs" title="Jiajun Wu">@jiajunwu_cs</a>. Congrats on the phenomenal idea!</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI2Njg0MjMzODQzNjcxMDQvcHUvaW1nL2lZdWFWdHE1TjYxUWcwWFouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1722629707123093546#m</id>
            <title>RT by @Gorden_Sun: @huggingface 的开源LLM排行榜增加了三个新的指标，他们把网站上的2000多个LLM都跑了一遍测试，重新计算了排名。花了大概一年多的GPU时间。
值得注意的是@kaifulee零一智能的Yi-34B模型在所有模型中排第一，有点离谱的。</title>
            <link>https://nitter.cz/op7418/status/1722629707123093546#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1722629707123093546#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 14:58:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/huggingface" title="Hugging Face">@huggingface</a> 的开源LLM排行榜增加了三个新的指标，他们把网站上的2000多个LLM都跑了一遍测试，重新计算了排名。花了大概一年多的GPU时间。<br />
值得注意的是<a href="https://nitter.cz/kaifulee" title="Kai-Fu Lee">@kaifulee</a>零一智能的Yi-34B模型在所有模型中排第一，有点离谱的。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1nQ0JXSGFNQUFVTU9YLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722558023548412377#m</id>
            <title>AI资讯日报，11月9日：https://gorden-sun.notion.site/11-9-AI-5815778524f042d58ce149d6089fc966?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722558023548412377#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722558023548412377#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 10:13:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月9日：<a href="https://gorden-sun.notion.site/11-9-AI-5815778524f042d58ce149d6089fc966?pvs=4">gorden-sun.notion.site/11-9-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1mQlZ5VGIwQUFGMXFoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722554889119875322#m</id>
            <title>这个项目是真快，已经用上了刚刚发布的XTTS v2</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722554889119875322#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722554889119875322#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 10:01:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个项目是真快，已经用上了刚刚发布的XTTS v2</p>
<p><a href="https://nitter.cz/dotey/status/1722543725459452211#m">nitter.cz/dotey/status/1722543725459452211#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722539360464351384#m</id>
            <title>MusicGen可以生成立体声音乐了，双声道（左右耳朵声音不一样），很带感。效果见视频。

推荐在线colab：https://colab.research.google.com/drive/1ECmNEoXk8kvnLEMBMF2LY82E7XmIG4yu?usp=sharing
最长2分钟，我的参数是musicgen-stereo-medium+MultiBand Diffusion(更占显存)，24秒音频

抱抱脸(只能15秒)：https://huggingface.co/spaces/facebook/MusicGen
Github：https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722539360464351384#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722539360464351384#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 08:59:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MusicGen可以生成立体声音乐了，双声道（左右耳朵声音不一样），很带感。效果见视频。<br />
<br />
推荐在线colab：<a href="https://colab.research.google.com/drive/1ECmNEoXk8kvnLEMBMF2LY82E7XmIG4yu?usp=sharing">colab.research.google.com/dr…</a><br />
最长2分钟，我的参数是musicgen-stereo-medium+MultiBand Diffusion(更占显存)，24秒音频<br />
<br />
抱抱脸(只能15秒)：<a href="https://huggingface.co/spaces/facebook/MusicGen">huggingface.co/spaces/facebo…</a><br />
Github：<a href="https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md">github.com/facebookresearch/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI1Mzg2MzcwNDc1MTMwODgvcHUvaW1nL3dsM2N3Y2FsWTF3blZ3SHguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/goldengrape/status/1722518486675788118#m</id>
            <title>RT by @Gorden_Sun: 教程来了：
用GPTs建立一个autoGPT
https://quail.ink/goldengrape/p/how-to-setup-an-autogpt-with-gpts</title>
            <link>https://nitter.cz/goldengrape/status/1722518486675788118#m</link>
            <guid isPermaLink="false">https://nitter.cz/goldengrape/status/1722518486675788118#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:36:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>教程来了：<br />
用GPTs建立一个autoGPT<br />
<a href="https://quail.ink/goldengrape/p/how-to-setup-an-autogpt-with-gpts">quail.ink/goldengrape/p/how-…</a></p>
<p><a href="https://nitter.cz/goldengrape/status/1722504369764225322#m">nitter.cz/goldengrape/status/1722504369764225322#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMjUxODQ5NDU0MDE1MjgzMi9hbzdCSThkZj9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1722484822101078390#m</id>
            <title>RT by @Gorden_Sun: 赞，在你的GPT中可以直接调用WePilot的接口，拥有WebPilot的网络获取能力👍🏻</title>
            <link>https://nitter.cz/dotey/status/1722484822101078390#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1722484822101078390#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 05:22:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>赞，在你的GPT中可以直接调用WePilot的接口，拥有WebPilot的网络获取能力👍🏻</p>
<p><a href="https://nitter.cz/CocoSgt_twt/status/1722482821053477121#m">nitter.cz/CocoSgt_twt/status/1722482821053477121#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722439866112463163#m</id>
            <title>HeyGen实现流程中的语音克隆，现在有最佳开源方案了：XTTS v2，单样本即可克隆语音，效果见视频。
现在已经能实现：让一个明星的采访视频，变成他讲述任意小故事（内容可以GPT编）的视频，声音是他的声音，嘴型也能对上。
XTTS v2在线体验：https://huggingface.co/spaces/coqui/xtts
Github：https://github.com/coqui-ai/tts</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722439866112463163#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722439866112463163#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 02:24:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HeyGen实现流程中的语音克隆，现在有最佳开源方案了：XTTS v2，单样本即可克隆语音，效果见视频。<br />
现在已经能实现：让一个明星的采访视频，变成他讲述任意小故事（内容可以GPT编）的视频，声音是他的声音，嘴型也能对上。<br />
XTTS v2在线体验：<a href="https://huggingface.co/spaces/coqui/xtts">huggingface.co/spaces/coqui/…</a><br />
Github：<a href="https://github.com/coqui-ai/tts">github.com/coqui-ai/tts</a></p>
<p><a href="https://nitter.cz/Gorden_Sun/status/1716075577117929841#m">nitter.cz/Gorden_Sun/status/1716075577117929841#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI0Mzk2NTM4NjgxMDk4MjQvcHUvaW1nL293aDJtcDRVd29VajcxRXYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/goldengrape/status/1722406261805940753#m</id>
            <title>RT by @Gorden_Sun: 如何建立一个专利专家GPT
https://quail.ink/goldengrape/p/how-to-build-a-patent-gpt
一步一步讲解了如何把插件纳入到自定义GPTs里面</title>
            <link>https://nitter.cz/goldengrape/status/1722406261805940753#m</link>
            <guid isPermaLink="false">https://nitter.cz/goldengrape/status/1722406261805940753#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 00:10:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如何建立一个专利专家GPT<br />
<a href="https://quail.ink/goldengrape/p/how-to-build-a-patent-gpt">quail.ink/goldengrape/p/how-…</a><br />
一步一步讲解了如何把插件纳入到自定义GPTs里面</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMjQwNTgyNDE3MjM3NjA2NC8yV2QyVUJwVT9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1722401600038424936#m</id>
            <title>RT by @Gorden_Sun: GPT-4-Turbo 128K上下文当全部用上，就有Lost in Middle的问题了。

上下文低于64K 没有遗忘问题，这倒是已经干掉了目前所有模型。

所以目前不建议使用其处理超过64K的文本。

顺便一提，128K一次就是一点几美金，也用不起。</title>
            <link>https://nitter.cz/9hills/status/1722401600038424936#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1722401600038424936#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 23:51:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT-4-Turbo 128K上下文当全部用上，就有Lost in Middle的问题了。<br />
<br />
上下文低于64K 没有遗忘问题，这倒是已经干掉了目前所有模型。<br />
<br />
所以目前不建议使用其处理超过64K的文本。<br />
<br />
顺便一提，128K一次就是一点几美金，也用不起。</p>
<p><a href="https://nitter.cz/GregKamradt/status/1722386725635580292#m">nitter.cz/GregKamradt/status/1722386725635580292#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/ruanyf/status/1722219566926037224#m</id>
            <title>RT by @Gorden_Sun: 昨天的 OpenAI 开发者大会，正式推出了“图生文”的 GPT-4 Vision 模型。

我有点好奇，找了一张中文图片，让 GPT-4 跟 @JinaAI_ 的  SceneXplain（图一）比较一下，看看谁的文字描述比较准。https://scenex.jina.ai/a/NEW

GPT-4 的结果（图二）不算很理想，似乎中文处理不太行，把“佳节”看成了“家乐福” ，还编造了一段。相比之下，SceneXplain 的中文理解（图三）就好很多。

我以前就在用 SceneXplain，这里推一下。它经过中文强化，更适合中文用户，可以生成图像描述、视频摘要、故事脚本等（图四），可用于电商图片生成文案、社交媒体的图片分析、无障碍读屏等场合。

它对开发者也很友好，提供 API 调用，结果以 JSON 格式输出，方便加工后放入自己的项目。</title>
            <link>https://nitter.cz/ruanyf/status/1722219566926037224#m</link>
            <guid isPermaLink="false">https://nitter.cz/ruanyf/status/1722219566926037224#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 11:48:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天的 OpenAI 开发者大会，正式推出了“图生文”的 GPT-4 Vision 模型。<br />
<br />
我有点好奇，找了一张中文图片，让 GPT-4 跟 <a href="https://nitter.cz/JinaAI_" title="Jina AI">@JinaAI_</a> 的  SceneXplain（图一）比较一下，看看谁的文字描述比较准。<a href="https://scenex.jina.ai/a/NEW">scenex.jina.ai/a/NEW</a><br />
<br />
GPT-4 的结果（图二）不算很理想，似乎中文处理不太行，把“佳节”看成了“家乐福” ，还编造了一段。相比之下，SceneXplain 的中文理解（图三）就好很多。<br />
<br />
我以前就在用 SceneXplain，这里推一下。它经过中文强化，更适合中文用户，可以生成图像描述、视频摘要、故事脚本等（图四），可用于电商图片生成文案、社交媒体的图片分析、无障碍读屏等场合。<br />
<br />
它对开发者也很友好，提供 API 调用，结果以 JSON 格式输出，方便加工后放入自己的项目。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1hTUxibGE4QUVOM3ZqLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1hTU1FV2F3QUFWMHBLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1hTU9QWGFZQUVPaGhoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1hTVEzNmEwQUFOTGdVLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/iamairyland/status/1722041853451669644#m</id>
            <title>RT by @Gorden_Sun: 快速用 AI 糊了个简陋无设计的 GPTs 发现和分享网站：http://www.GPTsHunter.com  它会对 Twitter 公开动态中的 GPT 进行自动收录。

欢迎 Up Vote：
https://www.producthunt.com/posts/gptshunter</title>
            <link>https://nitter.cz/iamairyland/status/1722041853451669644#m</link>
            <guid isPermaLink="false">https://nitter.cz/iamairyland/status/1722041853451669644#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 00:02:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>快速用 AI 糊了个简陋无设计的 GPTs 发现和分享网站：<a href="http://www.GPTsHunter.com">GPTsHunter.com</a>  它会对 Twitter 公开动态中的 GPT 进行自动收录。<br />
<br />
欢迎 Up Vote：<br />
<a href="https://www.producthunt.com/posts/gptshunter">producthunt.com/posts/gptshu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1YcU5VdFd3QUEwWWFnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722196691645018537#m</id>
            <title>AI资讯日报，11月8日：https://gorden-sun.notion.site/11-8-AI-970d7e25c78b4d73b17721a39ec42829?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722196691645018537#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722196691645018537#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 10:17:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，11月8日：<a href="https://gorden-sun.notion.site/11-8-AI-970d7e25c78b4d73b17721a39ec42829?pvs=4">gorden-sun.notion.site/11-8-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1aNHdDWmJZQUEwekR1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722140904365101484#m</id>
            <title>Figma推出Figma AI，输入文字可以生成流程图、原型、计划表，选中内容可以进行整理和总结

在线体验地址：https://www.figma.com/file/krMbt5UqgmjTaHGIAzWScY/FigJam-AI-playground-(Community)?type=whiteboard</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722140904365101484#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722140904365101484#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 06:36:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Figma推出Figma AI，输入文字可以生成流程图、原型、计划表，选中内容可以进行整理和总结<br />
<br />
在线体验地址：<a href="https://www.figma.com/file/krMbt5UqgmjTaHGIAzWScY/FigJam-AI-playground-(Community)?type=whiteboard">figma.com/file/krMbt5UqgmjTa…</a></p>
<p><a href="https://nitter.cz/figma/status/1721936196996350387#m">nitter.cz/figma/status/1721936196996350387#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMjE0MDkwNTk3OTk4MTgyNC9lX3Y5aFFGYT9mb3JtYXQ9cG5nJm5hbWU9MTIwMHg2Mjc=" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1722075640990716082#m</id>
            <title>https://huggingface.co/spaces/hf-audio/whisper-large-v3
这个空间可以体验OpenAI最新发布的Whisper v3，支持多语言混合识别。识别下面的音频，日语的爱识别成了中文的爱，阿姨洗铁路没识别成正确的梗。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1722075640990716082#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1722075640990716082#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 02:16:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://huggingface.co/spaces/hf-audio/whisper-large-v3">huggingface.co/spaces/hf-aud…</a><br />
这个空间可以体验OpenAI最新发布的Whisper v3，支持多语言混合识别。识别下面的音频，日语的爱识别成了中文的爱，阿姨洗铁路没识别成正确的梗。</p>
<p><a href="https://nitter.cz/Gorden_Sun/status/1721890997133877583#m">nitter.cz/Gorden_Sun/status/1721890997133877583#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1ZS28tamJjQUEtamNNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1721986978978087190#m</id>
            <title>RT by @Gorden_Sun: 推荐阅读：Developing Advanced Reasoning and Planning Algorithms with LLMs

大多数人都听说过思考链（Chain of Thought），把复杂问题拆分成一步步来处理提升准确率。

但是对于有些更复杂的问题，在某个步骤出错后，希望能回到上一个正确的节点重试，而不是重头开始，那么就需要借助“思维树”（Tree-of-Thoughts）。但思维树相对复杂，不容易调试和展示，所以作者开发了一款工具叫Branches，将大语言模型推理和规划的算法用图形化的方式展示出来。可以直观的用树形结构，还可以查看每一个节点的推理过程。

原文链接：https://blog.normalcomputing.ai/posts/2023-11-05-search-based-reasoning/search-based-reasoning.html

中文翻译：利用大语言模型开发先进的推理与规划算法 [译]
https://baoyu.io/blog/translations/search-based-reasoning</title>
            <link>https://nitter.cz/dotey/status/1721986978978087190#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1721986978978087190#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Nov 2023 20:24:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：Developing Advanced Reasoning and Planning Algorithms with LLMs<br />
<br />
大多数人都听说过思考链（Chain of Thought），把复杂问题拆分成一步步来处理提升准确率。<br />
<br />
但是对于有些更复杂的问题，在某个步骤出错后，希望能回到上一个正确的节点重试，而不是重头开始，那么就需要借助“思维树”（Tree-of-Thoughts）。但思维树相对复杂，不容易调试和展示，所以作者开发了一款工具叫Branches，将大语言模型推理和规划的算法用图形化的方式展示出来。可以直观的用树形结构，还可以查看每一个节点的推理过程。<br />
<br />
原文链接：<a href="https://blog.normalcomputing.ai/posts/2023-11-05-search-based-reasoning/search-based-reasoning.html">blog.normalcomputing.ai/post…</a><br />
<br />
中文翻译：利用大语言模型开发先进的推理与规划算法 [译]<br />
<a href="https://baoyu.io/blog/translations/search-based-reasoning">baoyu.io/blog/translations/s…</a></p>
<p><a href="https://nitter.cz/ArunPatro/status/1721762402641813535#m">nitter.cz/ArunPatro/status/1721762402641813535#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>