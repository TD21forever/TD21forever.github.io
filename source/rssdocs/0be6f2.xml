<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733481745318924441#m</id>
            <title>AI资讯日报，12月9日：https://gorden-sun.notion.site/12-9-AI-0d305d675a554c60b7c874ecd044e56c?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733481745318924441#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733481745318924441#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 13:40:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月9日：<a href="https://gorden-sun.notion.site/12-9-AI-0d305d675a554c60b7c874ecd044e56c?pvs=4">gorden-sun.notion.site/12-9-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E2UWJfbWFJQUFCZ2FLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733128533030195504#m</id>
            <title>AI资讯日报，12月8日：https://gorden-sun.notion.site/12-8-AI-02fe68987f6d4ab0b4d11c98f93a0a64?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733128533030195504#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733128533030195504#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 14:16:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月8日：<a href="https://gorden-sun.notion.site/12-8-AI-02fe68987f6d4ab0b4d11c98f93a0a64?pvs=4">gorden-sun.notion.site/12-8-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ExUExtVWFnQUEwRmtTLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xicilion/status/1732869795299860718#m</id>
            <title>RT by @Gorden_Sun: LLM 在学习上下文时会优先记住与前文关联的内容。这就导致越长的上下文，信息丢失越严重。

图一二分别时 Baichuan2-7b 和 ChatGLM3-6b 不同尺寸上下文召回效果统计图。

解决办法是在上下文之前要求它记住【问题】相关内容。

图三是这样提问后 Baichuan2-7b 的召回效果(少一列是因为增加提示超长了)</title>
            <link>https://nitter.cz/xicilion/status/1732869795299860718#m</link>
            <guid isPermaLink="false">https://nitter.cz/xicilion/status/1732869795299860718#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 21:08:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLM 在学习上下文时会优先记住与前文关联的内容。这就导致越长的上下文，信息丢失越严重。<br />
<br />
图一二分别时 Baichuan2-7b 和 ChatGLM3-6b 不同尺寸上下文召回效果统计图。<br />
<br />
解决办法是在上下文之前要求它记住【问题】相关内容。<br />
<br />
图三是这样提问后 Baichuan2-7b 的召回效果(少一列是因为增加提示超长了)</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F4ajRjVGJNQUEzTzdULmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F4ajRjWmFZQUF4LTBULmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F4ajRjVWFFQUFaMUU5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732928134591520823#m</id>
            <title>聊天机器人Pi推出安卓APP（ChatGPT能语音聊天后，还有人用Pi吗？）</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732928134591520823#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732928134591520823#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 01:00:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>聊天机器人Pi推出安卓APP（ChatGPT能语音聊天后，还有人用Pi吗？）</p>
<p><a href="https://nitter.cz/heypi_ai/status/1732807478922871147#m">nitter.cz/heypi_ai/status/1732807478922871147#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732731944432230542#m</id>
            <title>RT by @Gorden_Sun: ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。

他们野心很大，未来会支持更多方便的功能：
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。

这里下载插件：https://github.com/11cafe/comfyui-workspace-manager</title>
            <link>https://nitter.cz/op7418/status/1732731944432230542#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732731944432230542#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 12:01:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。<br />
<br />
他们野心很大，未来会支持更多方便的功能：<br />
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。<br />
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。<br />
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。<br />
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。<br />
<br />
这里下载插件：<a href="https://github.com/11cafe/comfyui-workspace-manager">github.com/11cafe/comfyui-wo…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0F2bVFzSmFFQUFuY3RyLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBdm1Rc0phRUFBbmN0ci5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732709985577230822#m</id>
            <title>AI资讯日报，12月7日：https://gorden-sun.notion.site/12-7-AI-108fbe9be6114579976d5d79744a848e?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732709985577230822#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732709985577230822#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:33:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月7日：<a href="https://gorden-sun.notion.site/12-7-AI-108fbe9be6114579976d5d79744a848e?pvs=4">gorden-sun.notion.site/12-7-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F2U2lFaWJZQUFJVnFhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732709601207111860#m</id>
            <title>MotionCtrl：控制AI生成视频中物体的运动路径
腾讯发布的项目，除了常规的镜头控制外，支持手绘轨迹来控制视频中物体的运动路径，支持AnimateDiff。代码暂未发布。
项目地址：https://wzhouxiff.github.io/projects/MotionCtrl/
论文：https://arxiv.org/abs/2312.03641</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732709601207111860#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732709601207111860#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:32:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MotionCtrl：控制AI生成视频中物体的运动路径<br />
腾讯发布的项目，除了常规的镜头控制外，支持手绘轨迹来控制视频中物体的运动路径，支持AnimateDiff。代码暂未发布。<br />
项目地址：<a href="https://wzhouxiff.github.io/projects/MotionCtrl/">wzhouxiff.github.io/projects…</a><br />
论文：<a href="https://arxiv.org/abs/2312.03641">arxiv.org/abs/2312.03641</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI3MDk1NDE3MTA4NTIwOTYvcHUvaW1nL3JmTGZRR3VOc1pab2FZdFMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732706357051375935#m</id>
            <title>OneLLM：把所有模态的模型与语言模型对齐
不依赖特定模态的解码器，一个框架把八种（详见下图）模式与语言对齐。
Github：https://github.com/csuhan/OneLLM
论文：https://arxiv.org/abs/2312.03700
在线体验：https://huggingface.co/spaces/csuhan/OneLLM</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732706357051375935#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732706357051375935#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:19:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OneLLM：把所有模态的模型与语言模型对齐<br />
不依赖特定模态的解码器，一个框架把八种（详见下图）模式与语言对齐。<br />
Github：<a href="https://github.com/csuhan/OneLLM">github.com/csuhan/OneLLM</a><br />
论文：<a href="https://arxiv.org/abs/2312.03700">arxiv.org/abs/2312.03700</a><br />
在线体验：<a href="https://huggingface.co/spaces/csuhan/OneLLM">huggingface.co/spaces/csuhan…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F2TzRZa2JZQUEyZ1VRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732703907686826049#m</id>
            <title>谷歌宣称的超越GPT-4，是基于CoT@32的测试方法（用Chain of Thought提示方法，32次内回答正确的比例），对比的也是GPT4的API。在普通的5-shot测试上，还是低于GPT-4。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732703907686826049#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732703907686826049#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:09:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌宣称的超越GPT-4，是基于CoT@32的测试方法（用Chain of Thought提示方法，32次内回答正确的比例），对比的也是GPT4的API。在普通的5-shot测试上，还是低于GPT-4。</p>
<p><a href="https://nitter.cz/bindureddy/status/1732505292011917494#m">nitter.cz/bindureddy/status/1732505292011917494#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732652458160394653#m</id>
            <title>Gemini Pro 的水平大概是能联网的ChatGPT 3.5：
英国IP时，图标是PaML2，回答如图1；
切换到美国IP后，图标是动态双子星，回答如图2（但profile的链接压根不是我）；
之前也没有经常用Bard，也不好说具体提升有多少。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732652458160394653#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732652458160394653#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 06:45:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini Pro 的水平大概是能联网的ChatGPT 3.5：<br />
英国IP时，图标是PaML2，回答如图1；<br />
切换到美国IP后，图标是动态双子星，回答如图2（但profile的链接压根不是我）；<br />
之前也没有经常用Bard，也不好说具体提升有多少。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1Y1J3V2FNQUFDRzJ0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1Y3lOQWFNQUFQMjF3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/tvytlx/status/1732535383752343624#m</id>
            <title>RT by @Gorden_Sun: 看到大家玩的蛮开心，之前的功能我决定全部免费开放，不用再问我要License了。

同时，DrawingPics发布正式版了，License购买作为了可选项，这次更新带来的两个新模型，作为License激活用户的特权。

这次更新的效果是，不需要什么机器代价的情况下，你们可以画的更准，和图像质量更高。直观展示请看视频。

关于这两个模型具体细节：
1 精准画图模型：
类似controlnet，这个模型下你画的线条它都会去感知到。另外它只需要额外多下载300M。运行时内存也有优化。

2更高质量的模型：
这个是SDXL的社区改良版，比SDXL体积更小速度更快，适合我们这种场景跑。SDXL主要特色是具有照片真实感，景深比较强。它也同样拥有这个优点。但低分辨率下跑不出来效果。缺点是它要多下载4-6GB，而且占用内存比较高。

3一开始的画图模型，没有动它：
我发现了它的优点，就是图生图的理解能力蛮强的，只要写简单的prompt就能懂，虽然没有SDXL那么“高质量”真实感，但是似乎更“聪明”“灵活”，而且快。

这就是目前三个主要的画图模式，都在最新的 DrawingPics1.0.1 版本中发了，只需要下载安装，就可以在你自己的电脑上无限出图了！</title>
            <link>https://nitter.cz/tvytlx/status/1732535383752343624#m</link>
            <guid isPermaLink="false">https://nitter.cz/tvytlx/status/1732535383752343624#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 22:59:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看到大家玩的蛮开心，之前的功能我决定全部免费开放，不用再问我要License了。<br />
<br />
同时，DrawingPics发布正式版了，License购买作为了可选项，这次更新带来的两个新模型，作为License激活用户的特权。<br />
<br />
这次更新的效果是，不需要什么机器代价的情况下，你们可以画的更准，和图像质量更高。直观展示请看视频。<br />
<br />
关于这两个模型具体细节：<br />
1 精准画图模型：<br />
类似controlnet，这个模型下你画的线条它都会去感知到。另外它只需要额外多下载300M。运行时内存也有优化。<br />
<br />
2更高质量的模型：<br />
这个是SDXL的社区改良版，比SDXL体积更小速度更快，适合我们这种场景跑。SDXL主要特色是具有照片真实感，景深比较强。它也同样拥有这个优点。但低分辨率下跑不出来效果。缺点是它要多下载4-6GB，而且占用内存比较高。<br />
<br />
3一开始的画图模型，没有动它：<br />
我发现了它的优点，就是图生图的理解能力蛮强的，只要写简单的prompt就能懂，虽然没有SDXL那么“高质量”真实感，但是似乎更“聪明”“灵活”，而且快。<br />
<br />
这就是目前三个主要的画图模式，都在最新的 DrawingPics1.0.1 版本中发了，只需要下载安装，就可以在你自己的电脑上无限出图了！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI1MzQ0MzI1MzQ1ODk0NDAvcHUvaW1nL2hPTWtJMVBGV1J4SFI0TlouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732598975184896403#m</id>
            <title>小红书的AI绘画平台“奇域”可以使用了，用跟Dall E相同提示词画了2张图，风格显然是微调和限定了，适合国风（画风总有脏脏的感觉）
网址：http://qiyuai.net</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732598975184896403#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732598975184896403#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 03:12:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>小红书的AI绘画平台“奇域”可以使用了，用跟Dall E相同提示词画了2张图，风格显然是微调和限定了，适合国风（画风总有脏脏的感觉）<br />
网址：<a href="http://qiyuai.net">qiyuai.net</a></p>
<p><a href="https://nitter.cz/Gorden_Sun/status/1710947441409675620#m">nitter.cz/Gorden_Sun/status/1710947441409675620#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F0dGt1RGJNQUFkLW9pLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F0dGt1RGFZQUFpU3I2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732399220970426858#m</id>
            <title>RT by @Gorden_Sun: MagicAnimate刚发布的时候只能使用它自带的动作，现在使用Vid2Densepose可以将任何视频的人物动作转成Densepose格式自定义MagicAnimate动画生成的动作。</title>
            <link>https://nitter.cz/op7418/status/1732399220970426858#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732399220970426858#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 13:58:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MagicAnimate刚发布的时候只能使用它自带的动作，现在使用Vid2Densepose可以将任何视频的人物动作转成Densepose格式自定义MagicAnimate动画生成的动作。</p>
<p><a href="https://nitter.cz/nacho_gorriti_/status/1732106540474126381#m">nitter.cz/nacho_gorriti_/status/1732106540474126381#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732430397785706567#m</id>
            <title>谷歌的Gemini大模型发布了！</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732430397785706567#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732430397785706567#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 16:02:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌的Gemini大模型发布了！</p>
<p><a href="https://nitter.cz/sundarpichai/status/1732414873139589372#m">nitter.cz/sundarpichai/status/1732414873139589372#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732403081932165607#m</id>
            <title>AI资讯日报，12月6日：https://gorden-sun.notion.site/12-6-AI-99ecf19685e54899a1154e450fcf0698?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732403081932165607#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732403081932165607#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 14:14:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月6日：<a href="https://gorden-sun.notion.site/12-6-AI-99ecf19685e54899a1154e450fcf0698?pvs=4">gorden-sun.notion.site/12-6-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FxN2FBY2JzQUE0eEszLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732402413817262505#m</id>
            <title>TaskWeaver：微软发布的代码优先的Agent框架。
主要用于数据分析领域。将用户需求转换为可执行代码，协调各种插件（以函数形式）来执行数据分析任务。支持丰富的数据结构、自定义算法、上下文记忆等。
Github：https://github.com/microsoft/TaskWeaver
论文：https://arxiv.org/abs/2311.17541</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732402413817262505#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732402413817262505#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 14:11:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>TaskWeaver：微软发布的代码优先的Agent框架。<br />
主要用于数据分析领域。将用户需求转换为可执行代码，协调各种插件（以函数形式）来执行数据分析任务。支持丰富的数据结构、自定义算法、上下文记忆等。<br />
Github：<a href="https://github.com/microsoft/TaskWeaver">github.com/microsoft/TaskWea…</a><br />
论文：<a href="https://arxiv.org/abs/2311.17541">arxiv.org/abs/2311.17541</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FxNndLc2J3QUFwTVY0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732397314877342111#m</id>
            <title>PlaygroundAI 发布了自己训练的绘图模型：Playground v2。
试了一下，效果不错（官方宣称比SDXL更受欢迎），可以免费在线使用。也支持使用 SD 1.5 和 SDXL。
使用地址：https://playground.com/create
模型地址：https://huggingface.co/playgroundai/playground-v2-1024px-aesthetic</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732397314877342111#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732397314877342111#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 13:51:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>PlaygroundAI 发布了自己训练的绘图模型：Playground v2。<br />
试了一下，效果不错（官方宣称比SDXL更受欢迎），可以免费在线使用。也支持使用 SD 1.5 和 SDXL。<br />
使用地址：<a href="https://playground.com/create">playground.com/create</a><br />
模型地址：<a href="https://huggingface.co/playgroundai/playground-v2-1024px-aesthetic">huggingface.co/playgroundai/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FxMWZyNmFRQUE1a0lYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732035425836159458#m</id>
            <title>不是前几天发ARR新闻的时候就出了么？还特意试了，没办法用别人的视频做虚拟人，因为最后要上传本人的授权录像。
会不会有一天HeyGen的talking photo生成的视频，能骗过系统和人工，用作授权录像？</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732035425836159458#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732035425836159458#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 13:53:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>不是前几天发ARR新闻的时候就出了么？还特意试了，没办法用别人的视频做虚拟人，因为最后要上传本人的授权录像。<br />
会不会有一天HeyGen的talking photo生成的视频，能骗过系统和人工，用作授权录像？</p>
<p><a href="https://nitter.cz/HeyGen_Official/status/1731965543920349488#m">nitter.cz/HeyGen_Official/status/1731965543920349488#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1731984367042412875#m</id>
            <title>AI资讯日报，12月5日：https://gorden-sun.notion.site/12-5-AI-c06bfe70032e4cf0ac246e60dcb444fc?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1731984367042412875#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1731984367042412875#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 10:30:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月5日：<a href="https://gorden-sun.notion.site/12-5-AI-c06bfe70032e4cf0ac246e60dcb444fc?pvs=4">gorden-sun.notion.site/12-5-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FrLWxxTGE0QUEyZG0wLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1731974352546017722#m</id>
            <title>太有趣啦（脸部实际没还原，不过角色一致+动作还原就很好了）</title>
            <link>https://nitter.cz/Gorden_Sun/status/1731974352546017722#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1731974352546017722#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 09:50:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>太有趣啦（脸部实际没还原，不过角色一致+动作还原就很好了）</p>
<p><a href="https://nitter.cz/_akhaliq/status/1731754853238501522#m">nitter.cz/_akhaliq/status/1731754853238501522#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzE5NzQyOTk4OTkzNDY5NDQvcHUvaW1nLzExYXBEUXJROEN5bklRN1guanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>