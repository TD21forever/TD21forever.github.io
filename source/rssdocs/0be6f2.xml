<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734138085032780065#m</id>
            <title>AI资讯日报，12月10日：https://gorden-sun.notion.site/12-11-AI-31f9fa4e269248b88f4dfeb2abcef716?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734138085032780065#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734138085032780065#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 09:08:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月10日：<a href="https://gorden-sun.notion.site/12-11-AI-31f9fa4e269248b88f4dfeb2abcef716?pvs=4">gorden-sun.notion.site/12-11…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JEbFlYbGF3QUFNNmdWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734128575861944527#m</id>
            <title>MistralAI发布了关于混合专家模型Mixtral 8x7B的介绍。
核心信息：
· 32K上下文
· 支持英语、法语、意大利语、德语、西班牙语
· 整体能力超过LLaMa 2，且推理速度快6倍
· 能力与ChatGPT 3.5接近
· 有45B参数，但是每个token只使用12B的参数，所以推理速度与12B模型相同
https://mistral.ai/news/mixtral-of-experts/</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734128575861944527#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734128575861944527#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 08:30:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MistralAI发布了关于混合专家模型Mixtral 8x7B的介绍。<br />
核心信息：<br />
· 32K上下文<br />
· 支持英语、法语、意大利语、德语、西班牙语<br />
· 整体能力超过LLaMa 2，且推理速度快6倍<br />
· 能力与ChatGPT 3.5接近<br />
· 有45B参数，但是每个token只使用12B的参数，所以推理速度与12B模型相同<br />
<a href="https://mistral.ai/news/mixtral-of-experts/">mistral.ai/news/mixtral-of-e…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JEY3BFVGJNQUFPcVU4LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734093582913708368#m</id>
            <title>RT by @Gorden_Sun: AIGC Weekly 50期一周年了，第一期也是这个时候发布的，也是刚过完生日，那个时候想的就是随便写写，反正平时也要看，没想到一个周刊会让我发生这样的改变，我是一个很没有长性的人，几乎没有规律性坚持任何事情，这是唯一坚持的事情。感觉最重要的就是各位的支持，持续不断的正反馈才让我坚持这么久。

50 期地址：https://quail.ink/op7418/p/aigc-weekly-50</title>
            <link>https://nitter.cz/op7418/status/1734093582913708368#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734093582913708368#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 06:11:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AIGC Weekly 50期一周年了，第一期也是这个时候发布的，也是刚过完生日，那个时候想的就是随便写写，反正平时也要看，没想到一个周刊会让我发生这样的改变，我是一个很没有长性的人，几乎没有规律性坚持任何事情，这是唯一坚持的事情。感觉最重要的就是各位的支持，持续不断的正反馈才让我坚持这么久。<br />
<br />
50 期地址：<a href="https://quail.ink/op7418/p/aigc-weekly-50">quail.ink/op7418/p/aigc-week…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JDOG91ZmFJQUE2Q0tGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1733636113883885626#m</id>
            <title>RT by @Gorden_Sun: 推荐阅读：在 RAG 流程中提高检索效果：融合传统关键词与现代向量搜索的混合式搜索技术 [译]

这篇文章探讨了如何结合传统关键词搜索与现代向量搜索来获得更相关的搜索结果。

原文：Improving Retrieval Performance in RAG Pipelines with Hybrid Search
https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5

翻译：https://baoyu.io/translations/rag/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search</title>
            <link>https://nitter.cz/dotey/status/1733636113883885626#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1733636113883885626#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 23:53:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：在 RAG 流程中提高检索效果：融合传统关键词与现代向量搜索的混合式搜索技术 [译]<br />
<br />
这篇文章探讨了如何结合传统关键词搜索与现代向量搜索来获得更相关的搜索结果。<br />
<br />
原文：Improving Retrieval Performance in RAG Pipelines with Hybrid Search<br />
<a href="https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5">towardsdatascience.com/impro…</a><br />
<br />
翻译：<a href="https://baoyu.io/translations/rag/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search">baoyu.io/translations/rag/im…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMjA1MzcwMjA3MDg5NDU5Mi9RN25lNXRhZj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/WaytoAGI/status/1733793320940552476#m</id>
            <title>RT by @Gorden_Sun: 《Claude官方文档提示词工程最佳实践》来自未来力场中英文编译。这个 PPT 是 Anthropic 上个月更新进自己官网的，未来力场（可搜同名公众号）把它编译成了中文，内容翻译的很用心，推荐给大家：

https://waytoagi.feishu.cn/record/SRegrOta4ecqcXcSRuYcwXG9n7c</title>
            <link>https://nitter.cz/WaytoAGI/status/1733793320940552476#m</link>
            <guid isPermaLink="false">https://nitter.cz/WaytoAGI/status/1733793320940552476#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 10:18:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《Claude官方文档提示词工程最佳实践》来自未来力场中英文编译。这个 PPT 是 Anthropic 上个月更新进自己官网的，未来力场（可搜同名公众号）把它编译成了中文，内容翻译的很用心，推荐给大家：<br />
<br />
<a href="https://waytoagi.feishu.cn/record/SRegrOta4ecqcXcSRuYcwXG9n7c">waytoagi.feishu.cn/record/SR…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EtclZxc2F3QUFOdjhPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/tzwm/status/1733835200302596144#m</id>
            <title>RT by @Gorden_Sun: 写了个 comfyui 插件来管理和收藏图片视频和 workflow。可以通过 git 来远程同步更新。将来会支持加载他人的公开 workflows repository。欢迎使用和反馈</title>
            <link>https://nitter.cz/tzwm/status/1733835200302596144#m</link>
            <guid isPermaLink="false">https://nitter.cz/tzwm/status/1733835200302596144#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 13:04:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>写了个 comfyui 插件来管理和收藏图片视频和 workflow。可以通过 git 来远程同步更新。将来会支持加载他人的公开 workflows repository。欢迎使用和反馈</p>
<p><a href="https://nitter.cz/tzwm/status/1733833507984838799#m">nitter.cz/tzwm/status/1733833507984838799#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FfUjVIQ2E0QUE3Tmo1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FfUjVIRWFNQUFrUGFuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733817645798232402#m</id>
            <title>AI资讯日报，12月10日：https://gorden-sun.notion.site/12-10-AI-0b6cd1120efd426e9361d32b80531ac6?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733817645798232402#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733817645798232402#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 11:55:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月10日：<a href="https://gorden-sun.notion.site/12-10-AI-0b6cd1120efd426e9361d32b80531ac6?pvs=4">gorden-sun.notion.site/12-10…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FfQmcxZ2FVQUFWNXhpLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733812588646212089#m</id>
            <title>R to @Gorden_Sun: 训练代码：https://github.com/NousResearch/StripedHyenaTrainer
在线使用：https://api.together.xyz/playground/chat/togethercomputer/StripedHyena-Nous-7B</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733812588646212089#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733812588646212089#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 11:35:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>训练代码：<a href="https://github.com/NousResearch/StripedHyenaTrainer">github.com/NousResearch/Stri…</a><br />
在线使用：<a href="https://api.together.xyz/playground/chat/togethercomputer/StripedHyena-Nous-7B">api.together.xyz/playground/…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMzIyODY5MDIzNjk2NDg2NS9CRlpOcVVWUz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733812583654952972#m</id>
            <title>StripedHyena：Transformer的替代品
现在基本所有LLM都基于Transformer，TogetherAI推出了StripedHyena，可以替代LLM训练和推理过程中的Transformer，而且在长上下文的情况下速度更快。
同时推出了对应的LLM：StripedHyena-Nous-7B
官方新闻：https://www.together.ai/blog/stripedhyena-7b
模型：https://huggingface.co/togethercomputer/StripedHyena-Nous-7B</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733812583654952972#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733812583654952972#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 11:35:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>StripedHyena：Transformer的替代品<br />
现在基本所有LLM都基于Transformer，TogetherAI推出了StripedHyena，可以替代LLM训练和推理过程中的Transformer，而且在长上下文的情况下速度更快。<br />
同时推出了对应的LLM：StripedHyena-Nous-7B<br />
官方新闻：<a href="https://www.together.ai/blog/stripedhyena-7b">together.ai/blog/stripedhyen…</a><br />
模型：<a href="https://huggingface.co/togethercomputer/StripedHyena-Nous-7B">huggingface.co/togethercompu…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMzIyNDgwMjgwMTA3ODI3Mi9aMmFiZThvSD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733481745318924441#m</id>
            <title>AI资讯日报，12月9日：https://gorden-sun.notion.site/12-9-AI-0d305d675a554c60b7c874ecd044e56c?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733481745318924441#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733481745318924441#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 13:40:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月9日：<a href="https://gorden-sun.notion.site/12-9-AI-0d305d675a554c60b7c874ecd044e56c?pvs=4">gorden-sun.notion.site/12-9-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E2UWJfbWFJQUFCZ2FLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733128533030195504#m</id>
            <title>AI资讯日报，12月8日：https://gorden-sun.notion.site/12-8-AI-02fe68987f6d4ab0b4d11c98f93a0a64?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733128533030195504#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733128533030195504#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 14:16:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月8日：<a href="https://gorden-sun.notion.site/12-8-AI-02fe68987f6d4ab0b4d11c98f93a0a64?pvs=4">gorden-sun.notion.site/12-8-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ExUExtVWFnQUEwRmtTLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xicilion/status/1732869795299860718#m</id>
            <title>RT by @Gorden_Sun: LLM 在学习上下文时会优先记住与前文关联的内容。这就导致越长的上下文，信息丢失越严重。

图一二分别时 Baichuan2-7b 和 ChatGLM3-6b 不同尺寸上下文召回效果统计图。

解决办法是在上下文之前要求它记住【问题】相关内容。

图三是这样提问后 Baichuan2-7b 的召回效果(少一列是因为增加提示超长了)</title>
            <link>https://nitter.cz/xicilion/status/1732869795299860718#m</link>
            <guid isPermaLink="false">https://nitter.cz/xicilion/status/1732869795299860718#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 21:08:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLM 在学习上下文时会优先记住与前文关联的内容。这就导致越长的上下文，信息丢失越严重。<br />
<br />
图一二分别时 Baichuan2-7b 和 ChatGLM3-6b 不同尺寸上下文召回效果统计图。<br />
<br />
解决办法是在上下文之前要求它记住【问题】相关内容。<br />
<br />
图三是这样提问后 Baichuan2-7b 的召回效果(少一列是因为增加提示超长了)</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F4ajRjVGJNQUEzTzdULmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F4ajRjWmFZQUF4LTBULmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F4ajRjVWFFQUFaMUU5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732928134591520823#m</id>
            <title>聊天机器人Pi推出安卓APP（ChatGPT能语音聊天后，还有人用Pi吗？）</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732928134591520823#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732928134591520823#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 01:00:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>聊天机器人Pi推出安卓APP（ChatGPT能语音聊天后，还有人用Pi吗？）</p>
<p><a href="https://nitter.cz/heypi_ai/status/1732807478922871147#m">nitter.cz/heypi_ai/status/1732807478922871147#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732731944432230542#m</id>
            <title>RT by @Gorden_Sun: ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。

他们野心很大，未来会支持更多方便的功能：
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。

这里下载插件：https://github.com/11cafe/comfyui-workspace-manager</title>
            <link>https://nitter.cz/op7418/status/1732731944432230542#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732731944432230542#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 12:01:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。<br />
<br />
他们野心很大，未来会支持更多方便的功能：<br />
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。<br />
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。<br />
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。<br />
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。<br />
<br />
这里下载插件：<a href="https://github.com/11cafe/comfyui-workspace-manager">github.com/11cafe/comfyui-wo…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0F2bVFzSmFFQUFuY3RyLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBdm1Rc0phRUFBbmN0ci5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732709985577230822#m</id>
            <title>AI资讯日报，12月7日：https://gorden-sun.notion.site/12-7-AI-108fbe9be6114579976d5d79744a848e?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732709985577230822#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732709985577230822#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:33:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月7日：<a href="https://gorden-sun.notion.site/12-7-AI-108fbe9be6114579976d5d79744a848e?pvs=4">gorden-sun.notion.site/12-7-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F2U2lFaWJZQUFJVnFhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732709601207111860#m</id>
            <title>MotionCtrl：控制AI生成视频中物体的运动路径
腾讯发布的项目，除了常规的镜头控制外，支持手绘轨迹来控制视频中物体的运动路径，支持AnimateDiff。代码暂未发布。
项目地址：https://wzhouxiff.github.io/projects/MotionCtrl/
论文：https://arxiv.org/abs/2312.03641</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732709601207111860#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732709601207111860#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:32:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MotionCtrl：控制AI生成视频中物体的运动路径<br />
腾讯发布的项目，除了常规的镜头控制外，支持手绘轨迹来控制视频中物体的运动路径，支持AnimateDiff。代码暂未发布。<br />
项目地址：<a href="https://wzhouxiff.github.io/projects/MotionCtrl/">wzhouxiff.github.io/projects…</a><br />
论文：<a href="https://arxiv.org/abs/2312.03641">arxiv.org/abs/2312.03641</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI3MDk1NDE3MTA4NTIwOTYvcHUvaW1nL3JmTGZRR3VOc1pab2FZdFMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732706357051375935#m</id>
            <title>OneLLM：把所有模态的模型与语言模型对齐
不依赖特定模态的解码器，一个框架把八种（详见下图）模式与语言对齐。
Github：https://github.com/csuhan/OneLLM
论文：https://arxiv.org/abs/2312.03700
在线体验：https://huggingface.co/spaces/csuhan/OneLLM</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732706357051375935#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732706357051375935#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:19:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OneLLM：把所有模态的模型与语言模型对齐<br />
不依赖特定模态的解码器，一个框架把八种（详见下图）模式与语言对齐。<br />
Github：<a href="https://github.com/csuhan/OneLLM">github.com/csuhan/OneLLM</a><br />
论文：<a href="https://arxiv.org/abs/2312.03700">arxiv.org/abs/2312.03700</a><br />
在线体验：<a href="https://huggingface.co/spaces/csuhan/OneLLM">huggingface.co/spaces/csuhan…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F2TzRZa2JZQUEyZ1VRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732703907686826049#m</id>
            <title>谷歌宣称的超越GPT-4，是基于CoT@32的测试方法（用Chain of Thought提示方法，32次内回答正确的比例），对比的也是GPT4的API。在普通的5-shot测试上，还是低于GPT-4。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732703907686826049#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732703907686826049#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:09:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌宣称的超越GPT-4，是基于CoT@32的测试方法（用Chain of Thought提示方法，32次内回答正确的比例），对比的也是GPT4的API。在普通的5-shot测试上，还是低于GPT-4。</p>
<p><a href="https://nitter.cz/bindureddy/status/1732505292011917494#m">nitter.cz/bindureddy/status/1732505292011917494#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732652458160394653#m</id>
            <title>Gemini Pro 的水平大概是能联网的ChatGPT 3.5：
英国IP时，图标是PaML2，回答如图1；
切换到美国IP后，图标是动态双子星，回答如图2（但profile的链接压根不是我）；
之前也没有经常用Bard，也不好说具体提升有多少。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732652458160394653#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732652458160394653#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 06:45:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini Pro 的水平大概是能联网的ChatGPT 3.5：<br />
英国IP时，图标是PaML2，回答如图1；<br />
切换到美国IP后，图标是动态双子星，回答如图2（但profile的链接压根不是我）；<br />
之前也没有经常用Bard，也不好说具体提升有多少。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1Y1J3V2FNQUFDRzJ0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1Y3lOQWFNQUFQMjF3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/tvytlx/status/1732535383752343624#m</id>
            <title>RT by @Gorden_Sun: 看到大家玩的蛮开心，之前的功能我决定全部免费开放，不用再问我要License了。

同时，DrawingPics发布正式版了，License购买作为了可选项，这次更新带来的两个新模型，作为License激活用户的特权。

这次更新的效果是，不需要什么机器代价的情况下，你们可以画的更准，和图像质量更高。直观展示请看视频。

关于这两个模型具体细节：
1 精准画图模型：
类似controlnet，这个模型下你画的线条它都会去感知到。另外它只需要额外多下载300M。运行时内存也有优化。

2更高质量的模型：
这个是SDXL的社区改良版，比SDXL体积更小速度更快，适合我们这种场景跑。SDXL主要特色是具有照片真实感，景深比较强。它也同样拥有这个优点。但低分辨率下跑不出来效果。缺点是它要多下载4-6GB，而且占用内存比较高。

3一开始的画图模型，没有动它：
我发现了它的优点，就是图生图的理解能力蛮强的，只要写简单的prompt就能懂，虽然没有SDXL那么“高质量”真实感，但是似乎更“聪明”“灵活”，而且快。

这就是目前三个主要的画图模式，都在最新的 DrawingPics1.0.1 版本中发了，只需要下载安装，就可以在你自己的电脑上无限出图了！</title>
            <link>https://nitter.cz/tvytlx/status/1732535383752343624#m</link>
            <guid isPermaLink="false">https://nitter.cz/tvytlx/status/1732535383752343624#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 22:59:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看到大家玩的蛮开心，之前的功能我决定全部免费开放，不用再问我要License了。<br />
<br />
同时，DrawingPics发布正式版了，License购买作为了可选项，这次更新带来的两个新模型，作为License激活用户的特权。<br />
<br />
这次更新的效果是，不需要什么机器代价的情况下，你们可以画的更准，和图像质量更高。直观展示请看视频。<br />
<br />
关于这两个模型具体细节：<br />
1 精准画图模型：<br />
类似controlnet，这个模型下你画的线条它都会去感知到。另外它只需要额外多下载300M。运行时内存也有优化。<br />
<br />
2更高质量的模型：<br />
这个是SDXL的社区改良版，比SDXL体积更小速度更快，适合我们这种场景跑。SDXL主要特色是具有照片真实感，景深比较强。它也同样拥有这个优点。但低分辨率下跑不出来效果。缺点是它要多下载4-6GB，而且占用内存比较高。<br />
<br />
3一开始的画图模型，没有动它：<br />
我发现了它的优点，就是图生图的理解能力蛮强的，只要写简单的prompt就能懂，虽然没有SDXL那么“高质量”真实感，但是似乎更“聪明”“灵活”，而且快。<br />
<br />
这就是目前三个主要的画图模式，都在最新的 DrawingPics1.0.1 版本中发了，只需要下载安装，就可以在你自己的电脑上无限出图了！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI1MzQ0MzI1MzQ1ODk0NDAvcHUvaW1nL2hPTWtJMVBGV1J4SFI0TlouanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>