<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/WaytoAGI/status/1733793320940552476#m</id>
            <title>RT by @Gorden_Sun: 《Claude官方文档提示词工程最佳实践》来自未来力场中英文编译。这个 PPT 是 Anthropic 上个月更新进自己官网的，未来力场（可搜同名公众号）把它编译成了中文，内容翻译的很用心，推荐给大家：

https://waytoagi.feishu.cn/record/SRegrOta4ecqcXcSRuYcwXG9n7c</title>
            <link>https://nitter.cz/WaytoAGI/status/1733793320940552476#m</link>
            <guid isPermaLink="false">https://nitter.cz/WaytoAGI/status/1733793320940552476#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 10:18:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《Claude官方文档提示词工程最佳实践》来自未来力场中英文编译。这个 PPT 是 Anthropic 上个月更新进自己官网的，未来力场（可搜同名公众号）把它编译成了中文，内容翻译的很用心，推荐给大家：<br />
<br />
<a href="https://waytoagi.feishu.cn/record/SRegrOta4ecqcXcSRuYcwXG9n7c">waytoagi.feishu.cn/record/SR…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EtclZxc2F3QUFOdjhPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/tzwm/status/1733835200302596144#m</id>
            <title>RT by @Gorden_Sun: 写了个 comfyui 插件来管理和收藏图片视频和 workflow。可以通过 git 来远程同步更新。将来会支持加载他人的公开 workflows repository。欢迎使用和反馈</title>
            <link>https://nitter.cz/tzwm/status/1733835200302596144#m</link>
            <guid isPermaLink="false">https://nitter.cz/tzwm/status/1733835200302596144#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 13:04:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>写了个 comfyui 插件来管理和收藏图片视频和 workflow。可以通过 git 来远程同步更新。将来会支持加载他人的公开 workflows repository。欢迎使用和反馈</p>
<p><a href="https://nitter.cz/tzwm/status/1733833507984838799#m">nitter.cz/tzwm/status/1733833507984838799#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FfUjVIQ2E0QUE3Tmo1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FfUjVIRWFNQUFrUGFuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733817645798232402#m</id>
            <title>AI资讯日报，12月10日：https://gorden-sun.notion.site/12-10-AI-0b6cd1120efd426e9361d32b80531ac6?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733817645798232402#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733817645798232402#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 11:55:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月10日：<a href="https://gorden-sun.notion.site/12-10-AI-0b6cd1120efd426e9361d32b80531ac6?pvs=4">gorden-sun.notion.site/12-10…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FfQmcxZ2FVQUFWNXhpLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733812588646212089#m</id>
            <title>R to @Gorden_Sun: 训练代码：https://github.com/NousResearch/StripedHyenaTrainer
在线使用：https://api.together.xyz/playground/chat/togethercomputer/StripedHyena-Nous-7B</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733812588646212089#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733812588646212089#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 11:35:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>训练代码：<a href="https://github.com/NousResearch/StripedHyenaTrainer">github.com/NousResearch/Stri…</a><br />
在线使用：<a href="https://api.together.xyz/playground/chat/togethercomputer/StripedHyena-Nous-7B">api.together.xyz/playground/…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMzIyODY5MDIzNjk2NDg2NS9CRlpOcVVWUz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733812583654952972#m</id>
            <title>StripedHyena：Transformer的替代品
现在基本所有LLM都基于Transformer，TogetherAI推出了StripedHyena，可以替代LLM训练和推理过程中的Transformer，而且在长上下文的情况下速度更快。
同时推出了对应的LLM：StripedHyena-Nous-7B
官方新闻：https://www.together.ai/blog/stripedhyena-7b
模型：https://huggingface.co/togethercomputer/StripedHyena-Nous-7B</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733812583654952972#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733812583654952972#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 11:35:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>StripedHyena：Transformer的替代品<br />
现在基本所有LLM都基于Transformer，TogetherAI推出了StripedHyena，可以替代LLM训练和推理过程中的Transformer，而且在长上下文的情况下速度更快。<br />
同时推出了对应的LLM：StripedHyena-Nous-7B<br />
官方新闻：<a href="https://www.together.ai/blog/stripedhyena-7b">together.ai/blog/stripedhyen…</a><br />
模型：<a href="https://huggingface.co/togethercomputer/StripedHyena-Nous-7B">huggingface.co/togethercompu…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMzIyNDgwMjgwMTA3ODI3Mi9aMmFiZThvSD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733481745318924441#m</id>
            <title>AI资讯日报，12月9日：https://gorden-sun.notion.site/12-9-AI-0d305d675a554c60b7c874ecd044e56c?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733481745318924441#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733481745318924441#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 13:40:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月9日：<a href="https://gorden-sun.notion.site/12-9-AI-0d305d675a554c60b7c874ecd044e56c?pvs=4">gorden-sun.notion.site/12-9-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E2UWJfbWFJQUFCZ2FLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1733128533030195504#m</id>
            <title>AI资讯日报，12月8日：https://gorden-sun.notion.site/12-8-AI-02fe68987f6d4ab0b4d11c98f93a0a64?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1733128533030195504#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1733128533030195504#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 14:16:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月8日：<a href="https://gorden-sun.notion.site/12-8-AI-02fe68987f6d4ab0b4d11c98f93a0a64?pvs=4">gorden-sun.notion.site/12-8-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ExUExtVWFnQUEwRmtTLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xicilion/status/1732869795299860718#m</id>
            <title>RT by @Gorden_Sun: LLM 在学习上下文时会优先记住与前文关联的内容。这就导致越长的上下文，信息丢失越严重。

图一二分别时 Baichuan2-7b 和 ChatGLM3-6b 不同尺寸上下文召回效果统计图。

解决办法是在上下文之前要求它记住【问题】相关内容。

图三是这样提问后 Baichuan2-7b 的召回效果(少一列是因为增加提示超长了)</title>
            <link>https://nitter.cz/xicilion/status/1732869795299860718#m</link>
            <guid isPermaLink="false">https://nitter.cz/xicilion/status/1732869795299860718#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 21:08:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLM 在学习上下文时会优先记住与前文关联的内容。这就导致越长的上下文，信息丢失越严重。<br />
<br />
图一二分别时 Baichuan2-7b 和 ChatGLM3-6b 不同尺寸上下文召回效果统计图。<br />
<br />
解决办法是在上下文之前要求它记住【问题】相关内容。<br />
<br />
图三是这样提问后 Baichuan2-7b 的召回效果(少一列是因为增加提示超长了)</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F4ajRjVGJNQUEzTzdULmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F4ajRjWmFZQUF4LTBULmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F4ajRjVWFFQUFaMUU5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732928134591520823#m</id>
            <title>聊天机器人Pi推出安卓APP（ChatGPT能语音聊天后，还有人用Pi吗？）</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732928134591520823#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732928134591520823#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 01:00:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>聊天机器人Pi推出安卓APP（ChatGPT能语音聊天后，还有人用Pi吗？）</p>
<p><a href="https://nitter.cz/heypi_ai/status/1732807478922871147#m">nitter.cz/heypi_ai/status/1732807478922871147#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732731944432230542#m</id>
            <title>RT by @Gorden_Sun: ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。

他们野心很大，未来会支持更多方便的功能：
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。

这里下载插件：https://github.com/11cafe/comfyui-workspace-manager</title>
            <link>https://nitter.cz/op7418/status/1732731944432230542#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732731944432230542#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 12:01:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。<br />
<br />
他们野心很大，未来会支持更多方便的功能：<br />
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。<br />
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。<br />
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。<br />
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。<br />
<br />
这里下载插件：<a href="https://github.com/11cafe/comfyui-workspace-manager">github.com/11cafe/comfyui-wo…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0F2bVFzSmFFQUFuY3RyLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBdm1Rc0phRUFBbmN0ci5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732709985577230822#m</id>
            <title>AI资讯日报，12月7日：https://gorden-sun.notion.site/12-7-AI-108fbe9be6114579976d5d79744a848e?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732709985577230822#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732709985577230822#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:33:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月7日：<a href="https://gorden-sun.notion.site/12-7-AI-108fbe9be6114579976d5d79744a848e?pvs=4">gorden-sun.notion.site/12-7-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F2U2lFaWJZQUFJVnFhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732709601207111860#m</id>
            <title>MotionCtrl：控制AI生成视频中物体的运动路径
腾讯发布的项目，除了常规的镜头控制外，支持手绘轨迹来控制视频中物体的运动路径，支持AnimateDiff。代码暂未发布。
项目地址：https://wzhouxiff.github.io/projects/MotionCtrl/
论文：https://arxiv.org/abs/2312.03641</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732709601207111860#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732709601207111860#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:32:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MotionCtrl：控制AI生成视频中物体的运动路径<br />
腾讯发布的项目，除了常规的镜头控制外，支持手绘轨迹来控制视频中物体的运动路径，支持AnimateDiff。代码暂未发布。<br />
项目地址：<a href="https://wzhouxiff.github.io/projects/MotionCtrl/">wzhouxiff.github.io/projects…</a><br />
论文：<a href="https://arxiv.org/abs/2312.03641">arxiv.org/abs/2312.03641</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI3MDk1NDE3MTA4NTIwOTYvcHUvaW1nL3JmTGZRR3VOc1pab2FZdFMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732706357051375935#m</id>
            <title>OneLLM：把所有模态的模型与语言模型对齐
不依赖特定模态的解码器，一个框架把八种（详见下图）模式与语言对齐。
Github：https://github.com/csuhan/OneLLM
论文：https://arxiv.org/abs/2312.03700
在线体验：https://huggingface.co/spaces/csuhan/OneLLM</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732706357051375935#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732706357051375935#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:19:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OneLLM：把所有模态的模型与语言模型对齐<br />
不依赖特定模态的解码器，一个框架把八种（详见下图）模式与语言对齐。<br />
Github：<a href="https://github.com/csuhan/OneLLM">github.com/csuhan/OneLLM</a><br />
论文：<a href="https://arxiv.org/abs/2312.03700">arxiv.org/abs/2312.03700</a><br />
在线体验：<a href="https://huggingface.co/spaces/csuhan/OneLLM">huggingface.co/spaces/csuhan…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F2TzRZa2JZQUEyZ1VRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732703907686826049#m</id>
            <title>谷歌宣称的超越GPT-4，是基于CoT@32的测试方法（用Chain of Thought提示方法，32次内回答正确的比例），对比的也是GPT4的API。在普通的5-shot测试上，还是低于GPT-4。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732703907686826049#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732703907686826049#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 10:09:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌宣称的超越GPT-4，是基于CoT@32的测试方法（用Chain of Thought提示方法，32次内回答正确的比例），对比的也是GPT4的API。在普通的5-shot测试上，还是低于GPT-4。</p>
<p><a href="https://nitter.cz/bindureddy/status/1732505292011917494#m">nitter.cz/bindureddy/status/1732505292011917494#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732652458160394653#m</id>
            <title>Gemini Pro 的水平大概是能联网的ChatGPT 3.5：
英国IP时，图标是PaML2，回答如图1；
切换到美国IP后，图标是动态双子星，回答如图2（但profile的链接压根不是我）；
之前也没有经常用Bard，也不好说具体提升有多少。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732652458160394653#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732652458160394653#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 06:45:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini Pro 的水平大概是能联网的ChatGPT 3.5：<br />
英国IP时，图标是PaML2，回答如图1；<br />
切换到美国IP后，图标是动态双子星，回答如图2（但profile的链接压根不是我）；<br />
之前也没有经常用Bard，也不好说具体提升有多少。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1Y1J3V2FNQUFDRzJ0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1Y3lOQWFNQUFQMjF3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/tvytlx/status/1732535383752343624#m</id>
            <title>RT by @Gorden_Sun: 看到大家玩的蛮开心，之前的功能我决定全部免费开放，不用再问我要License了。

同时，DrawingPics发布正式版了，License购买作为了可选项，这次更新带来的两个新模型，作为License激活用户的特权。

这次更新的效果是，不需要什么机器代价的情况下，你们可以画的更准，和图像质量更高。直观展示请看视频。

关于这两个模型具体细节：
1 精准画图模型：
类似controlnet，这个模型下你画的线条它都会去感知到。另外它只需要额外多下载300M。运行时内存也有优化。

2更高质量的模型：
这个是SDXL的社区改良版，比SDXL体积更小速度更快，适合我们这种场景跑。SDXL主要特色是具有照片真实感，景深比较强。它也同样拥有这个优点。但低分辨率下跑不出来效果。缺点是它要多下载4-6GB，而且占用内存比较高。

3一开始的画图模型，没有动它：
我发现了它的优点，就是图生图的理解能力蛮强的，只要写简单的prompt就能懂，虽然没有SDXL那么“高质量”真实感，但是似乎更“聪明”“灵活”，而且快。

这就是目前三个主要的画图模式，都在最新的 DrawingPics1.0.1 版本中发了，只需要下载安装，就可以在你自己的电脑上无限出图了！</title>
            <link>https://nitter.cz/tvytlx/status/1732535383752343624#m</link>
            <guid isPermaLink="false">https://nitter.cz/tvytlx/status/1732535383752343624#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 22:59:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看到大家玩的蛮开心，之前的功能我决定全部免费开放，不用再问我要License了。<br />
<br />
同时，DrawingPics发布正式版了，License购买作为了可选项，这次更新带来的两个新模型，作为License激活用户的特权。<br />
<br />
这次更新的效果是，不需要什么机器代价的情况下，你们可以画的更准，和图像质量更高。直观展示请看视频。<br />
<br />
关于这两个模型具体细节：<br />
1 精准画图模型：<br />
类似controlnet，这个模型下你画的线条它都会去感知到。另外它只需要额外多下载300M。运行时内存也有优化。<br />
<br />
2更高质量的模型：<br />
这个是SDXL的社区改良版，比SDXL体积更小速度更快，适合我们这种场景跑。SDXL主要特色是具有照片真实感，景深比较强。它也同样拥有这个优点。但低分辨率下跑不出来效果。缺点是它要多下载4-6GB，而且占用内存比较高。<br />
<br />
3一开始的画图模型，没有动它：<br />
我发现了它的优点，就是图生图的理解能力蛮强的，只要写简单的prompt就能懂，虽然没有SDXL那么“高质量”真实感，但是似乎更“聪明”“灵活”，而且快。<br />
<br />
这就是目前三个主要的画图模式，都在最新的 DrawingPics1.0.1 版本中发了，只需要下载安装，就可以在你自己的电脑上无限出图了！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI1MzQ0MzI1MzQ1ODk0NDAvcHUvaW1nL2hPTWtJMVBGV1J4SFI0TlouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732598975184896403#m</id>
            <title>小红书的AI绘画平台“奇域”可以使用了，用跟Dall E相同提示词画了2张图，风格显然是微调和限定了，适合国风（画风总有脏脏的感觉）
网址：http://qiyuai.net</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732598975184896403#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732598975184896403#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 03:12:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>小红书的AI绘画平台“奇域”可以使用了，用跟Dall E相同提示词画了2张图，风格显然是微调和限定了，适合国风（画风总有脏脏的感觉）<br />
网址：<a href="http://qiyuai.net">qiyuai.net</a></p>
<p><a href="https://nitter.cz/Gorden_Sun/status/1710947441409675620#m">nitter.cz/Gorden_Sun/status/1710947441409675620#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F0dGt1RGJNQUFkLW9pLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F0dGt1RGFZQUFpU3I2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732399220970426858#m</id>
            <title>RT by @Gorden_Sun: MagicAnimate刚发布的时候只能使用它自带的动作，现在使用Vid2Densepose可以将任何视频的人物动作转成Densepose格式自定义MagicAnimate动画生成的动作。</title>
            <link>https://nitter.cz/op7418/status/1732399220970426858#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732399220970426858#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 13:58:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MagicAnimate刚发布的时候只能使用它自带的动作，现在使用Vid2Densepose可以将任何视频的人物动作转成Densepose格式自定义MagicAnimate动画生成的动作。</p>
<p><a href="https://nitter.cz/nacho_gorriti_/status/1732106540474126381#m">nitter.cz/nacho_gorriti_/status/1732106540474126381#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732430397785706567#m</id>
            <title>谷歌的Gemini大模型发布了！</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732430397785706567#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732430397785706567#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 16:02:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌的Gemini大模型发布了！</p>
<p><a href="https://nitter.cz/sundarpichai/status/1732414873139589372#m">nitter.cz/sundarpichai/status/1732414873139589372#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1732403081932165607#m</id>
            <title>AI资讯日报，12月6日：https://gorden-sun.notion.site/12-6-AI-99ecf19685e54899a1154e450fcf0698?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1732403081932165607#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1732403081932165607#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 14:14:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月6日：<a href="https://gorden-sun.notion.site/12-6-AI-99ecf19685e54899a1154e450fcf0698?pvs=4">gorden-sun.notion.site/12-6-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FxN2FBY2JzQUE0eEszLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>