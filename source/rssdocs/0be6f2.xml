<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736657917867327586#m</id>
            <title>获得了Mistral-medium的API资格，试了下确实比GPT-3.5强，安全限制也很弱，可惜对中文的支持不太好。

关于Mistral-medium的介绍：https://mistral.ai/news/la-plateforme/</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736657917867327586#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736657917867327586#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 08:01:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>获得了Mistral-medium的API资格，试了下确实比GPT-3.5强，安全限制也很弱，可惜对中文的支持不太好。<br />
<br />
关于Mistral-medium的介绍：<a href="https://mistral.ai/news/la-plateforme/">mistral.ai/news/la-plateform…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JuWkFXZWJVQUFQRDgyLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JuWkRhYmJnQUFRdGhqLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JuWklrZmJnQUFpTFFXLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736561583957180619#m</id>
            <title>MLC Chat：在iPhone上离线运行7B最强LLM Mistral
中文不太行，速度很快，手机会发热
APP下载：https://apps.apple.com/gb/app/mlc-chat/id6448482937
Github：https://github.com/mlc-ai/mlc-llm</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736561583957180619#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736561583957180619#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 01:38:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MLC Chat：在iPhone上离线运行7B最强LLM Mistral<br />
中文不太行，速度很快，手机会发热<br />
APP下载：<a href="https://apps.apple.com/gb/app/mlc-chat/id6448482937">apps.apple.com/gb/app/mlc-ch…</a><br />
Github：<a href="https://github.com/mlc-ai/mlc-llm">github.com/mlc-ai/mlc-llm</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY1NjE0ODc5Mjg1MjQ4MDAvcHUvaW1nL282WFAyWFpRTmZGVGpubFUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1736476171385069941#m</id>
            <title>RT by @Gorden_Sun: 新翻译了：OpenAI 生产环境最佳实践官方指南

这份指南全面介绍了如何将产品原型发布到生产环境的最佳实践。不论你是资深的机器学习工程师还是刚入门的技术爱好者，这份指南都能为你提供在实际生产环境中成功应用该平台所需的各种工具和知识。内容涵盖从如何保护 API 访问安全到如何构建能应对高流量的架构。参考这份指南，可以帮助你更顺畅、高效地部署应用程序到生产环境。

请求补全（Completion）的延迟主要受两个因素的影响：使用的模型和生成的 Token 数量。在这个过程中，大部分延迟通常源自 Token 生成步骤。在调用补全时，提示词（Prompt）的 Token 造成的延迟非常小。但生成这些补全用的 Token 要花费更多时间，因为它们是一个接一个产生的。生成长度越长，由于每个 Token 的生成，所累积的延迟也越多。

在考虑降低成本时，一个实用的方法是把成本看作是 Token 数量和每个 Token 成本的函数。 按照这个方法，您可以从两方面着手降低成本：一是通过使用更小的模型来降低每个 Token 的成本，二是尝试减少所需的 Token 数量。您可以通过使用更简短的提示、模型微调或缓存用户的常见查询来实现这一点，从而避免重复处理。

原始地址：https://platform.openai.com/docs/guides/production-best-practices
翻译：https://baoyu.io/translations/openai/guides-production-best-practices</title>
            <link>https://nitter.cz/dotey/status/1736476171385069941#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1736476171385069941#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 19:59:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>新翻译了：OpenAI 生产环境最佳实践官方指南<br />
<br />
这份指南全面介绍了如何将产品原型发布到生产环境的最佳实践。不论你是资深的机器学习工程师还是刚入门的技术爱好者，这份指南都能为你提供在实际生产环境中成功应用该平台所需的各种工具和知识。内容涵盖从如何保护 API 访问安全到如何构建能应对高流量的架构。参考这份指南，可以帮助你更顺畅、高效地部署应用程序到生产环境。<br />
<br />
请求补全（Completion）的延迟主要受两个因素的影响：使用的模型和生成的 Token 数量。在这个过程中，大部分延迟通常源自 Token 生成步骤。在调用补全时，提示词（Prompt）的 Token 造成的延迟非常小。但生成这些补全用的 Token 要花费更多时间，因为它们是一个接一个产生的。生成长度越长，由于每个 Token 的生成，所累积的延迟也越多。<br />
<br />
在考虑降低成本时，一个实用的方法是把成本看作是 Token 数量和每个 Token 成本的函数。 按照这个方法，您可以从两方面着手降低成本：一是通过使用更小的模型来降低每个 Token 的成本，二是尝试减少所需的 Token 数量。您可以通过使用更简短的提示、模型微调或缓存用户的常见查询来实现这一点，从而避免重复处理。<br />
<br />
原始地址：<a href="https://platform.openai.com/docs/guides/production-best-practices">platform.openai.com/docs/gui…</a><br />
翻译：<a href="https://baoyu.io/translations/openai/guides-production-best-practices">baoyu.io/translations/openai…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736386289371615352#m</id>
            <title>计算机很擅长处理计算问题，你可以很轻松地用各种软件做出对称、翻转的图，但是AI却画不出稍微复杂一点的完美的对称的图。仿佛计算机学会了人类，却忘记了自己。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736386289371615352#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736386289371615352#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 14:02:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>计算机很擅长处理计算问题，你可以很轻松地用各种软件做出对称、翻转的图，但是AI却画不出稍微复杂一点的完美的对称的图。仿佛计算机学会了人类，却忘记了自己。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736357627276476512#m</id>
            <title>AI资讯日报，12月17日：https://gorden-sun.notion.site/12-17-AI-58b3d5c40c584ffc8091a598d8156607?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736357627276476512#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736357627276476512#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 12:08:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月17日：<a href="https://gorden-sun.notion.site/12-17-AI-58b3d5c40c584ffc8091a598d8156607?pvs=4">gorden-sun.notion.site/12-17…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JqSUMwWmE0QUFNQzhuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736344262042898845#m</id>
            <title>DomoAI效果不错，很稳定了。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736344262042898845#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736344262042898845#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 11:15:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DomoAI效果不错，很稳定了。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzYzNDQwMjk3MTYyNTQ3MjAvcHUvaW1nL3I1eGpFZ3VPSGQ2ZkpPcnguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1736304093621047351#m</id>
            <title>RT by @Gorden_Sun: 今天花了点时间翻译了一下 OpenAI 发布的提示工程指南，这份指南分享了如何更有效地利用像如 GPT-4 这样的大语言模型（有时候也叫 GPT 模型）来获得更好的结果。介绍的方法可以相互结合，以发挥更大的作用。希望你也可以从中学习到适合你的技巧。

另外，这份指南的示例主要针对 GPT-4 模型，但理论上来说也适用其他模型。

其中主要有六个策略，每个策略下再有具体的技巧。

策略一：撰写清晰的指令

这些模型并不会读心术，无法猜到你的想法。如果模型的输出内容过长，你可以要求它简短回答。如果模型输出内容过于简单，你可以要求使用更专业的水平写作。如果你对输出格式不满意，可以直接展示你期望的格式。最好就是让模型不需要去猜你想要什么，这样你最有可能获得想要的结果。

技巧：
- 在查询中添加详细信息，以获得更准确的答案
- 请求模型扮演特定角色
- 使用分隔符来清晰区分输入的不同部分
- 明确指出完成任务需要的步骤
- 提供实例作为参考
- 明确指定希望输出的长度

策略二：提供参考文本

语言模型可能会自信地编造出虚假答案，特别是当回应一些深奥主题或被要求提供引文和 URLs 时。就像学生在考试中借助笔记能够帮助其取得更好的成绩一样，为这类模型提供参考文本也可减少其制造虚假信息的情况。

技巧：
- 引导模型根据参考文本回答问题
- 引导模型根据参考文本中的引用信息回答问题

策略三：把复杂的任务拆分成简单的子任务

就像在软件工程中，我们会习惯于把复杂的系统分解成一套模块化的组件，对于提交给语言模型的任务也是同样的道理。相较于简单的任务，复杂任务的错误率往往会更高。而更进一步，我们常常可以把这些复杂任务重新设定为一系列的工作流程，每一个流程就是一个更简单的任务，而且这些任务之间是相互联系的，前一个任务的输出会作为后一个任务的输入。

技巧：

- 利用意图分类识别用户查询中最相关的指令
- 对于需要长时间对话的对话应用，总结或筛选先前的对话内容
- 分步总结长文档，并递归地构建完整的总结

策略四：给模型更多时间“思考”

如果被要求计算 17 乘以 28，我们可能不能立即给出答案，但可以花一些时间逐步计算出结果。同样，在 AI 模型试图立刻回答问题时，往往比理性思考后再做出回答更容易出错。所以，在模型给出答案之前，要求其展示一下"思考过程"，有助于模型更可靠地推导出正确的答案。

技巧：
- 在仓促做出结论前，指导模型自己寻找解决方法
- 通过内心独白或连串问题来掩盖模型的思考过程
- 问模型在之前的步骤中是否有遗漏

策略五：运用外部工具

为了弥补模型的不足，我们可以利用其他工具的输出作为输入。例如，文本检索系统（有时被称为 RAG 或检索增强生成系统）可以向模型提供相关文档的信息。像 OpenAI 的代码执行引擎这样的工具，可以帮助模型进行数学运算和代码执行。如果某项任务通过工具来完成能比通过语言模型更可靠或更高效，那么就把任务交给这个工具处理，这样就能结合两者长处，达到最佳效果。

技巧：
- 运用基于嵌入的搜索来高效实现知识检索
- 利用代码执行进行更精确的计算或调用外部 API
- 使模型能够访问特定功能

策略六：系统地对变更进行测试

如果能对性能进行量化，那么就能更好地提高性能。有时，对提示词的修改在少数特定例子上可能表现更佳，但在更具普遍性的样本集上可能会导致整体性能下降。因此，为了确保改动对总体性能产生积极的影响，可能需要设计一份全方位的测试（也被称为"评估"）。

技巧：
- 根据标准答案的参考评估模型输出效果

对于上面提到的每一种技巧，都有非常详细的参考示例。

官网链接：https://platform.openai.com/docs/guides/prompt-engineering
中文翻译：https://baoyu.io/translations/openai/openai-prompt-engineering-guides</title>
            <link>https://nitter.cz/dotey/status/1736304093621047351#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1736304093621047351#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 08:35:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天花了点时间翻译了一下 OpenAI 发布的提示工程指南，这份指南分享了如何更有效地利用像如 GPT-4 这样的大语言模型（有时候也叫 GPT 模型）来获得更好的结果。介绍的方法可以相互结合，以发挥更大的作用。希望你也可以从中学习到适合你的技巧。<br />
<br />
另外，这份指南的示例主要针对 GPT-4 模型，但理论上来说也适用其他模型。<br />
<br />
其中主要有六个策略，每个策略下再有具体的技巧。<br />
<br />
策略一：撰写清晰的指令<br />
<br />
这些模型并不会读心术，无法猜到你的想法。如果模型的输出内容过长，你可以要求它简短回答。如果模型输出内容过于简单，你可以要求使用更专业的水平写作。如果你对输出格式不满意，可以直接展示你期望的格式。最好就是让模型不需要去猜你想要什么，这样你最有可能获得想要的结果。<br />
<br />
技巧：<br />
- 在查询中添加详细信息，以获得更准确的答案<br />
- 请求模型扮演特定角色<br />
- 使用分隔符来清晰区分输入的不同部分<br />
- 明确指出完成任务需要的步骤<br />
- 提供实例作为参考<br />
- 明确指定希望输出的长度<br />
<br />
策略二：提供参考文本<br />
<br />
语言模型可能会自信地编造出虚假答案，特别是当回应一些深奥主题或被要求提供引文和 URLs 时。就像学生在考试中借助笔记能够帮助其取得更好的成绩一样，为这类模型提供参考文本也可减少其制造虚假信息的情况。<br />
<br />
技巧：<br />
- 引导模型根据参考文本回答问题<br />
- 引导模型根据参考文本中的引用信息回答问题<br />
<br />
策略三：把复杂的任务拆分成简单的子任务<br />
<br />
就像在软件工程中，我们会习惯于把复杂的系统分解成一套模块化的组件，对于提交给语言模型的任务也是同样的道理。相较于简单的任务，复杂任务的错误率往往会更高。而更进一步，我们常常可以把这些复杂任务重新设定为一系列的工作流程，每一个流程就是一个更简单的任务，而且这些任务之间是相互联系的，前一个任务的输出会作为后一个任务的输入。<br />
<br />
技巧：<br />
<br />
- 利用意图分类识别用户查询中最相关的指令<br />
- 对于需要长时间对话的对话应用，总结或筛选先前的对话内容<br />
- 分步总结长文档，并递归地构建完整的总结<br />
<br />
策略四：给模型更多时间“思考”<br />
<br />
如果被要求计算 17 乘以 28，我们可能不能立即给出答案，但可以花一些时间逐步计算出结果。同样，在 AI 模型试图立刻回答问题时，往往比理性思考后再做出回答更容易出错。所以，在模型给出答案之前，要求其展示一下"思考过程"，有助于模型更可靠地推导出正确的答案。<br />
<br />
技巧：<br />
- 在仓促做出结论前，指导模型自己寻找解决方法<br />
- 通过内心独白或连串问题来掩盖模型的思考过程<br />
- 问模型在之前的步骤中是否有遗漏<br />
<br />
策略五：运用外部工具<br />
<br />
为了弥补模型的不足，我们可以利用其他工具的输出作为输入。例如，文本检索系统（有时被称为 RAG 或检索增强生成系统）可以向模型提供相关文档的信息。像 OpenAI 的代码执行引擎这样的工具，可以帮助模型进行数学运算和代码执行。如果某项任务通过工具来完成能比通过语言模型更可靠或更高效，那么就把任务交给这个工具处理，这样就能结合两者长处，达到最佳效果。<br />
<br />
技巧：<br />
- 运用基于嵌入的搜索来高效实现知识检索<br />
- 利用代码执行进行更精确的计算或调用外部 API<br />
- 使模型能够访问特定功能<br />
<br />
策略六：系统地对变更进行测试<br />
<br />
如果能对性能进行量化，那么就能更好地提高性能。有时，对提示词的修改在少数特定例子上可能表现更佳，但在更具普遍性的样本集上可能会导致整体性能下降。因此，为了确保改动对总体性能产生积极的影响，可能需要设计一份全方位的测试（也被称为"评估"）。<br />
<br />
技巧：<br />
- 根据标准答案的参考评估模型输出效果<br />
<br />
对于上面提到的每一种技巧，都有非常详细的参考示例。<br />
<br />
官网链接：<a href="https://platform.openai.com/docs/guides/prompt-engineering">platform.openai.com/docs/gui…</a><br />
中文翻译：<a href="https://baoyu.io/translations/openai/openai-prompt-engineering-guides">baoyu.io/translations/openai…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JpWFZDNVhFQUFBZGVJLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736025684613660752#m</id>
            <title>大多数人画画都是先画个框架，再逐步完善细节，Stable Diffusion生成图片的过程大致也这样，这很符合直觉。
大多数人写文章的过程也类似，但LLM Transformer的过程却不是这样的，Transformer执行的是续写，在写出内容前它也不知道会写出什么主题。是不是因为它最早只为解决翻译问题，并不是为AI诞生？</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736025684613660752#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736025684613660752#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 14:09:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大多数人画画都是先画个框架，再逐步完善细节，Stable Diffusion生成图片的过程大致也这样，这很符合直觉。<br />
大多数人写文章的过程也类似，但LLM Transformer的过程却不是这样的，Transformer执行的是续写，在写出内容前它也不知道会写出什么主题。是不是因为它最早只为解决翻译问题，并不是为AI诞生？</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735997979935555986#m</id>
            <title>AI资讯日报，12月16日：https://gorden-sun.notion.site/12-16-AI-fe853e8c37254d2aa93e6ff428dfb60b?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735997979935555986#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735997979935555986#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 12:19:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月16日：<a href="https://gorden-sun.notion.site/12-16-AI-fe853e8c37254d2aa93e6ff428dfb60b?pvs=4">gorden-sun.notion.site/12-16…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JlQThjdGFjQUFjTEtLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735857768480063941#m</id>
            <title>PC互联网刚兴起的时候，开始有了网络春晚，现在AI兴起了，搞个AI春晚怎么样。
主持人文案由GPT写，口播由AI生成，节目有AI孙燕姿、郭德纲讲英文相声、sunoAI唱歌、video2video舞蹈之类的。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735857768480063941#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735857768480063941#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 03:01:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>PC互联网刚兴起的时候，开始有了网络春晚，现在AI兴起了，搞个AI春晚怎么样。<br />
主持人文案由GPT写，口播由AI生成，节目有AI孙燕姿、郭德纲讲英文相声、sunoAI唱歌、video2video舞蹈之类的。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/tzwm/status/1735654103165067422#m</id>
            <title>RT by @Gorden_Sun: 更新了一版插件。现在可以订阅大佬们的工作流仓库方便抄作业了。我先预置了 @hylarucoder 和 ComfyUI 官方的两个推荐源。欢迎使用和贡献更多工作流仓库：https://github.com/tzwm/comfyui-browser</title>
            <link>https://nitter.cz/tzwm/status/1735654103165067422#m</link>
            <guid isPermaLink="false">https://nitter.cz/tzwm/status/1735654103165067422#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 13:32:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>更新了一版插件。现在可以订阅大佬们的工作流仓库方便抄作业了。我先预置了 <a href="https://nitter.cz/hylarucoder" title="HylaruCoder">@hylarucoder</a> 和 ComfyUI 官方的两个推荐源。欢迎使用和贡献更多工作流仓库：<a href="https://github.com/tzwm/comfyui-browser">github.com/tzwm/comfyui-brow…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2NTM1NjUwMzE2NDUxODQvcHUvaW1nL3ZRcWdKZ1lpQ1YyR25WT1QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735670437412065571#m</id>
            <title>AnimateDiff v3发布了，新增支持控制视频生成的过程（有点类似ControlNet，但是还没那么强，目前只支持线稿和RGB图片）</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735670437412065571#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735670437412065571#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 14:37:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AnimateDiff v3发布了，新增支持控制视频生成的过程（有点类似ControlNet，但是还没那么强，目前只支持线稿和RGB图片）</p>
<p><a href="https://nitter.cz/CeyuanY/status/1735657553504477517#m">nitter.cz/CeyuanY/status/1735657553504477517#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735585835859476732#m</id>
            <title>AI资讯日报，12月15日：https://gorden-sun.notion.site/12-15-AI-2bb3a797f62348449be2a64fb5db8c56?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735585835859476732#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735585835859476732#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 09:01:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月15日：<a href="https://gorden-sun.notion.site/12-15-AI-2bb3a797f62348449be2a64fb5db8c56?pvs=4">gorden-sun.notion.site/12-15…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JZS0dzR2FRQUFIV0NULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735417480133095501#m</id>
            <title>RT by @Gorden_Sun: 免费薅 GPT-4 羊毛的机会来了！不花钱也能体验GPTs。

据 @henuwangkai 说 Coze 是字节弄的可以免费试用GPT-4，并且可以创建自己的GPT机器人。

我测试了一下确实可以，估计随着用户增多会增加使用限制。要体验趁早。

https://www.coze.com/</title>
            <link>https://nitter.cz/dotey/status/1735417480133095501#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735417480133095501#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 21:52:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>免费薅 GPT-4 羊毛的机会来了！不花钱也能体验GPTs。<br />
<br />
据 <a href="https://nitter.cz/henuwangkai" title="henu王凯">@henuwangkai</a> 说 Coze 是字节弄的可以免费试用GPT-4，并且可以创建自己的GPT机器人。<br />
<br />
我测试了一下确实可以，估计随着用户增多会增加使用限制。要体验趁早。<br />
<br />
<a href="https://www.coze.com/">coze.com/</a></p>
<p><a href="https://nitter.cz/henuwangkai/status/1735257617231192113#m">nitter.cz/henuwangkai/status/1735257617231192113#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JWdzBXcVdrQUFJWVZXLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735568937327501560#m</id>
            <title>R to @Gorden_Sun: 效果演示：https://www.youtube.com/watch?v=3eiSohroGwU&amp;t=3s&amp;ab_channel=JulianParker</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735568937327501560#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735568937327501560#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:54:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>效果演示：<a href="https://www.youtube.com/watch?v=3eiSohroGwU&amp;t=3s&amp;ab_channel=JulianParker">youtube.com/watch?v=3eiSohro…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTU2ODE5NzcwODA1MDQzMi9JYVF4b3JiTD9mb3JtYXQ9anBnJm5hbWU9ODAweDMyMF8x" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735568864614953216#m</id>
            <title>StemGen：先听音乐再生成
这个音乐模型有点意思。之前的音乐模型是，用户输入文字，AI生成整段的音乐。StemGen则是参考用户输入的音乐，先生成一小段音乐，然后再把输入音乐+生成的音乐作为新的输入，继续生成，类似Transformer的过程。
项目：https://julian-parker.github.io/stemgen/
论文：https://arxiv.org/abs/2312.08723</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735568864614953216#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735568864614953216#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:53:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>StemGen：先听音乐再生成<br />
这个音乐模型有点意思。之前的音乐模型是，用户输入文字，AI生成整段的音乐。StemGen则是参考用户输入的音乐，先生成一小段音乐，然后再把输入音乐+生成的音乐作为新的输入，继续生成，类似Transformer的过程。<br />
项目：<a href="https://julian-parker.github.io/stemgen/">julian-parker.github.io/stem…</a><br />
论文：<a href="https://arxiv.org/abs/2312.08723">arxiv.org/abs/2312.08723</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTM3NzMwNDg0MTMwNjExMi9pN0xmVGg3Mj9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735432352489246741#m</id>
            <title>RT by @Gorden_Sun: 写了一个搜索 arXiv 论文的GPT，可以显示标题和你输入语言的摘要，使用的是 arXiv 官方的搜索 API。

https://chat.openai.com/g/g-QlTT7Mi2m-ar-x-iv-assistant</title>
            <link>https://nitter.cz/dotey/status/1735432352489246741#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735432352489246741#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 22:51:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>写了一个搜索 arXiv 论文的GPT，可以显示标题和你输入语言的摘要，使用的是 arXiv 官方的搜索 API。<br />
<br />
<a href="https://chat.openai.com/g/g-QlTT7Mi2m-ar-x-iv-assistant">chat.openai.com/g/g-QlTT7Mi2…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JWLUNBSlhJQUFaNWJDLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JWLWMyVFc0QUE4bDhILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735227363368259626#m</id>
            <title>AI资讯日报，12月14日：https://gorden-sun.notion.site/12-14-AI-cc1310c000114ba3a454395597f30b36?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735227363368259626#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735227363368259626#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 09:16:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月14日：<a href="https://gorden-sun.notion.site/12-14-AI-cc1310c000114ba3a454395597f30b36?pvs=4">gorden-sun.notion.site/12-14…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JURUViaGE4QUFfNHRWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735223017079456019#m</id>
            <title>Solar 10.7B：新的开源最佳模型
评分超过Mistral 7B，不过也就超过了一点点，Mistral如果有10B的版本，两者的水平差不多。
基座模型：https://huggingface.co/upstage/SOLAR-10.7B-v1.0
指令微调：https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735223017079456019#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735223017079456019#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 08:59:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Solar 10.7B：新的开源最佳模型<br />
评分超过Mistral 7B，不过也就超过了一点点，Mistral如果有10B的版本，两者的水平差不多。<br />
基座模型：<a href="https://huggingface.co/upstage/SOLAR-10.7B-v1.0">huggingface.co/upstage/SOLAR…</a><br />
指令微调：<a href="https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0">huggingface.co/upstage/SOLAR…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTXzR6cGJVQUFCTE44LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735220263065976947#m</id>
            <title>Coffee：AI辅助前端开发（怎么老是前端）
适用于React项目，支持大多数UI组件，能写简洁易维护的代码。
Github：https://github.com/Coframe/coffee</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735220263065976947#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735220263065976947#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 08:48:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Coffee：AI辅助前端开发（怎么老是前端）<br />
适用于React项目，支持大多数UI组件，能写简洁易维护的代码。<br />
Github：<a href="https://github.com/Coframe/coffee">github.com/Coframe/coffee</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUyMjAwMjMyMDIwNDE4NTYvcHUvaW1nL1hoTkVrQ3JobUhoV0FoWjYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>