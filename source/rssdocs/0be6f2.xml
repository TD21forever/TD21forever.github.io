<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736386289371615352#m</id>
            <title>计算机很擅长处理计算问题，你可以很轻松地用各种软件做出对称、翻转的图，但是AI却画不出稍微复杂一点的完美的对称的图。仿佛计算机学会了人类，却忘记了自己。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736386289371615352#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736386289371615352#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 14:02:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>计算机很擅长处理计算问题，你可以很轻松地用各种软件做出对称、翻转的图，但是AI却画不出稍微复杂一点的完美的对称的图。仿佛计算机学会了人类，却忘记了自己。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736357627276476512#m</id>
            <title>AI资讯日报，12月17日：https://gorden-sun.notion.site/12-17-AI-58b3d5c40c584ffc8091a598d8156607?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736357627276476512#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736357627276476512#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 12:08:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月17日：<a href="https://gorden-sun.notion.site/12-17-AI-58b3d5c40c584ffc8091a598d8156607?pvs=4">gorden-sun.notion.site/12-17…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JqSUMwWmE0QUFNQzhuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736344262042898845#m</id>
            <title>DomoAI效果不错，很稳定了。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736344262042898845#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736344262042898845#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 11:15:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DomoAI效果不错，很稳定了。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzYzNDQwMjk3MTYyNTQ3MjAvcHUvaW1nL3I1eGpFZ3VPSGQ2ZkpPcnguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1736304093621047351#m</id>
            <title>RT by @Gorden_Sun: 今天花了点时间翻译了一下 OpenAI 发布的提示工程指南，这份指南分享了如何更有效地利用像如 GPT-4 这样的大语言模型（有时候也叫 GPT 模型）来获得更好的结果。介绍的方法可以相互结合，以发挥更大的作用。希望你也可以从中学习到适合你的技巧。

另外，这份指南的示例主要针对 GPT-4 模型，但理论上来说也适用其他模型。

其中主要有六个策略，每个策略下再有具体的技巧。

策略一：撰写清晰的指令

这些模型并不会读心术，无法猜到你的想法。如果模型的输出内容过长，你可以要求它简短回答。如果模型输出内容过于简单，你可以要求使用更专业的水平写作。如果你对输出格式不满意，可以直接展示你期望的格式。最好就是让模型不需要去猜你想要什么，这样你最有可能获得想要的结果。

技巧：
- 在查询中添加详细信息，以获得更准确的答案
- 请求模型扮演特定角色
- 使用分隔符来清晰区分输入的不同部分
- 明确指出完成任务需要的步骤
- 提供实例作为参考
- 明确指定希望输出的长度

策略二：提供参考文本

语言模型可能会自信地编造出虚假答案，特别是当回应一些深奥主题或被要求提供引文和 URLs 时。就像学生在考试中借助笔记能够帮助其取得更好的成绩一样，为这类模型提供参考文本也可减少其制造虚假信息的情况。

技巧：
- 引导模型根据参考文本回答问题
- 引导模型根据参考文本中的引用信息回答问题

策略三：把复杂的任务拆分成简单的子任务

就像在软件工程中，我们会习惯于把复杂的系统分解成一套模块化的组件，对于提交给语言模型的任务也是同样的道理。相较于简单的任务，复杂任务的错误率往往会更高。而更进一步，我们常常可以把这些复杂任务重新设定为一系列的工作流程，每一个流程就是一个更简单的任务，而且这些任务之间是相互联系的，前一个任务的输出会作为后一个任务的输入。

技巧：

- 利用意图分类识别用户查询中最相关的指令
- 对于需要长时间对话的对话应用，总结或筛选先前的对话内容
- 分步总结长文档，并递归地构建完整的总结

策略四：给模型更多时间“思考”

如果被要求计算 17 乘以 28，我们可能不能立即给出答案，但可以花一些时间逐步计算出结果。同样，在 AI 模型试图立刻回答问题时，往往比理性思考后再做出回答更容易出错。所以，在模型给出答案之前，要求其展示一下"思考过程"，有助于模型更可靠地推导出正确的答案。

技巧：
- 在仓促做出结论前，指导模型自己寻找解决方法
- 通过内心独白或连串问题来掩盖模型的思考过程
- 问模型在之前的步骤中是否有遗漏

策略五：运用外部工具

为了弥补模型的不足，我们可以利用其他工具的输出作为输入。例如，文本检索系统（有时被称为 RAG 或检索增强生成系统）可以向模型提供相关文档的信息。像 OpenAI 的代码执行引擎这样的工具，可以帮助模型进行数学运算和代码执行。如果某项任务通过工具来完成能比通过语言模型更可靠或更高效，那么就把任务交给这个工具处理，这样就能结合两者长处，达到最佳效果。

技巧：
- 运用基于嵌入的搜索来高效实现知识检索
- 利用代码执行进行更精确的计算或调用外部 API
- 使模型能够访问特定功能

策略六：系统地对变更进行测试

如果能对性能进行量化，那么就能更好地提高性能。有时，对提示词的修改在少数特定例子上可能表现更佳，但在更具普遍性的样本集上可能会导致整体性能下降。因此，为了确保改动对总体性能产生积极的影响，可能需要设计一份全方位的测试（也被称为"评估"）。

技巧：
- 根据标准答案的参考评估模型输出效果

对于上面提到的每一种技巧，都有非常详细的参考示例。

官网链接：https://platform.openai.com/docs/guides/prompt-engineering
中文翻译：https://baoyu.io/translations/openai/openai-prompt-engineering-guides</title>
            <link>https://nitter.cz/dotey/status/1736304093621047351#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1736304093621047351#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 08:35:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天花了点时间翻译了一下 OpenAI 发布的提示工程指南，这份指南分享了如何更有效地利用像如 GPT-4 这样的大语言模型（有时候也叫 GPT 模型）来获得更好的结果。介绍的方法可以相互结合，以发挥更大的作用。希望你也可以从中学习到适合你的技巧。<br />
<br />
另外，这份指南的示例主要针对 GPT-4 模型，但理论上来说也适用其他模型。<br />
<br />
其中主要有六个策略，每个策略下再有具体的技巧。<br />
<br />
策略一：撰写清晰的指令<br />
<br />
这些模型并不会读心术，无法猜到你的想法。如果模型的输出内容过长，你可以要求它简短回答。如果模型输出内容过于简单，你可以要求使用更专业的水平写作。如果你对输出格式不满意，可以直接展示你期望的格式。最好就是让模型不需要去猜你想要什么，这样你最有可能获得想要的结果。<br />
<br />
技巧：<br />
- 在查询中添加详细信息，以获得更准确的答案<br />
- 请求模型扮演特定角色<br />
- 使用分隔符来清晰区分输入的不同部分<br />
- 明确指出完成任务需要的步骤<br />
- 提供实例作为参考<br />
- 明确指定希望输出的长度<br />
<br />
策略二：提供参考文本<br />
<br />
语言模型可能会自信地编造出虚假答案，特别是当回应一些深奥主题或被要求提供引文和 URLs 时。就像学生在考试中借助笔记能够帮助其取得更好的成绩一样，为这类模型提供参考文本也可减少其制造虚假信息的情况。<br />
<br />
技巧：<br />
- 引导模型根据参考文本回答问题<br />
- 引导模型根据参考文本中的引用信息回答问题<br />
<br />
策略三：把复杂的任务拆分成简单的子任务<br />
<br />
就像在软件工程中，我们会习惯于把复杂的系统分解成一套模块化的组件，对于提交给语言模型的任务也是同样的道理。相较于简单的任务，复杂任务的错误率往往会更高。而更进一步，我们常常可以把这些复杂任务重新设定为一系列的工作流程，每一个流程就是一个更简单的任务，而且这些任务之间是相互联系的，前一个任务的输出会作为后一个任务的输入。<br />
<br />
技巧：<br />
<br />
- 利用意图分类识别用户查询中最相关的指令<br />
- 对于需要长时间对话的对话应用，总结或筛选先前的对话内容<br />
- 分步总结长文档，并递归地构建完整的总结<br />
<br />
策略四：给模型更多时间“思考”<br />
<br />
如果被要求计算 17 乘以 28，我们可能不能立即给出答案，但可以花一些时间逐步计算出结果。同样，在 AI 模型试图立刻回答问题时，往往比理性思考后再做出回答更容易出错。所以，在模型给出答案之前，要求其展示一下"思考过程"，有助于模型更可靠地推导出正确的答案。<br />
<br />
技巧：<br />
- 在仓促做出结论前，指导模型自己寻找解决方法<br />
- 通过内心独白或连串问题来掩盖模型的思考过程<br />
- 问模型在之前的步骤中是否有遗漏<br />
<br />
策略五：运用外部工具<br />
<br />
为了弥补模型的不足，我们可以利用其他工具的输出作为输入。例如，文本检索系统（有时被称为 RAG 或检索增强生成系统）可以向模型提供相关文档的信息。像 OpenAI 的代码执行引擎这样的工具，可以帮助模型进行数学运算和代码执行。如果某项任务通过工具来完成能比通过语言模型更可靠或更高效，那么就把任务交给这个工具处理，这样就能结合两者长处，达到最佳效果。<br />
<br />
技巧：<br />
- 运用基于嵌入的搜索来高效实现知识检索<br />
- 利用代码执行进行更精确的计算或调用外部 API<br />
- 使模型能够访问特定功能<br />
<br />
策略六：系统地对变更进行测试<br />
<br />
如果能对性能进行量化，那么就能更好地提高性能。有时，对提示词的修改在少数特定例子上可能表现更佳，但在更具普遍性的样本集上可能会导致整体性能下降。因此，为了确保改动对总体性能产生积极的影响，可能需要设计一份全方位的测试（也被称为"评估"）。<br />
<br />
技巧：<br />
- 根据标准答案的参考评估模型输出效果<br />
<br />
对于上面提到的每一种技巧，都有非常详细的参考示例。<br />
<br />
官网链接：<a href="https://platform.openai.com/docs/guides/prompt-engineering">platform.openai.com/docs/gui…</a><br />
中文翻译：<a href="https://baoyu.io/translations/openai/openai-prompt-engineering-guides">baoyu.io/translations/openai…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JpWFZDNVhFQUFBZGVJLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1736025684613660752#m</id>
            <title>大多数人画画都是先画个框架，再逐步完善细节，Stable Diffusion生成图片的过程大致也这样，这很符合直觉。
大多数人写文章的过程也类似，但LLM Transformer的过程却不是这样的，Transformer执行的是续写，在写出内容前它也不知道会写出什么主题。是不是因为它最早只为解决翻译问题，并不是为AI诞生？</title>
            <link>https://nitter.cz/Gorden_Sun/status/1736025684613660752#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1736025684613660752#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 14:09:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大多数人画画都是先画个框架，再逐步完善细节，Stable Diffusion生成图片的过程大致也这样，这很符合直觉。<br />
大多数人写文章的过程也类似，但LLM Transformer的过程却不是这样的，Transformer执行的是续写，在写出内容前它也不知道会写出什么主题。是不是因为它最早只为解决翻译问题，并不是为AI诞生？</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735997979935555986#m</id>
            <title>AI资讯日报，12月16日：https://gorden-sun.notion.site/12-16-AI-fe853e8c37254d2aa93e6ff428dfb60b?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735997979935555986#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735997979935555986#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 12:19:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月16日：<a href="https://gorden-sun.notion.site/12-16-AI-fe853e8c37254d2aa93e6ff428dfb60b?pvs=4">gorden-sun.notion.site/12-16…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JlQThjdGFjQUFjTEtLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735857768480063941#m</id>
            <title>PC互联网刚兴起的时候，开始有了网络春晚，现在AI兴起了，搞个AI春晚怎么样。
主持人文案由GPT写，口播由AI生成，节目有AI孙燕姿、郭德纲讲英文相声、sunoAI唱歌、video2video舞蹈之类的。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735857768480063941#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735857768480063941#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 03:01:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>PC互联网刚兴起的时候，开始有了网络春晚，现在AI兴起了，搞个AI春晚怎么样。<br />
主持人文案由GPT写，口播由AI生成，节目有AI孙燕姿、郭德纲讲英文相声、sunoAI唱歌、video2video舞蹈之类的。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/tzwm/status/1735654103165067422#m</id>
            <title>RT by @Gorden_Sun: 更新了一版插件。现在可以订阅大佬们的工作流仓库方便抄作业了。我先预置了 @hylarucoder 和 ComfyUI 官方的两个推荐源。欢迎使用和贡献更多工作流仓库：https://github.com/tzwm/comfyui-browser</title>
            <link>https://nitter.cz/tzwm/status/1735654103165067422#m</link>
            <guid isPermaLink="false">https://nitter.cz/tzwm/status/1735654103165067422#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 13:32:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>更新了一版插件。现在可以订阅大佬们的工作流仓库方便抄作业了。我先预置了 <a href="https://nitter.cz/hylarucoder" title="HylaruCoder">@hylarucoder</a> 和 ComfyUI 官方的两个推荐源。欢迎使用和贡献更多工作流仓库：<a href="https://github.com/tzwm/comfyui-browser">github.com/tzwm/comfyui-brow…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2NTM1NjUwMzE2NDUxODQvcHUvaW1nL3ZRcWdKZ1lpQ1YyR25WT1QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735670437412065571#m</id>
            <title>AnimateDiff v3发布了，新增支持控制视频生成的过程（有点类似ControlNet，但是还没那么强，目前只支持线稿和RGB图片）</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735670437412065571#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735670437412065571#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 14:37:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AnimateDiff v3发布了，新增支持控制视频生成的过程（有点类似ControlNet，但是还没那么强，目前只支持线稿和RGB图片）</p>
<p><a href="https://nitter.cz/CeyuanY/status/1735657553504477517#m">nitter.cz/CeyuanY/status/1735657553504477517#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735585835859476732#m</id>
            <title>AI资讯日报，12月15日：https://gorden-sun.notion.site/12-15-AI-2bb3a797f62348449be2a64fb5db8c56?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735585835859476732#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735585835859476732#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 09:01:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月15日：<a href="https://gorden-sun.notion.site/12-15-AI-2bb3a797f62348449be2a64fb5db8c56?pvs=4">gorden-sun.notion.site/12-15…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JZS0dzR2FRQUFIV0NULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735417480133095501#m</id>
            <title>RT by @Gorden_Sun: 免费薅 GPT-4 羊毛的机会来了！不花钱也能体验GPTs。

据 @henuwangkai 说 Coze 是字节弄的可以免费试用GPT-4，并且可以创建自己的GPT机器人。

我测试了一下确实可以，估计随着用户增多会增加使用限制。要体验趁早。

https://www.coze.com/</title>
            <link>https://nitter.cz/dotey/status/1735417480133095501#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735417480133095501#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 21:52:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>免费薅 GPT-4 羊毛的机会来了！不花钱也能体验GPTs。<br />
<br />
据 <a href="https://nitter.cz/henuwangkai" title="henu王凯">@henuwangkai</a> 说 Coze 是字节弄的可以免费试用GPT-4，并且可以创建自己的GPT机器人。<br />
<br />
我测试了一下确实可以，估计随着用户增多会增加使用限制。要体验趁早。<br />
<br />
<a href="https://www.coze.com/">coze.com/</a></p>
<p><a href="https://nitter.cz/henuwangkai/status/1735257617231192113#m">nitter.cz/henuwangkai/status/1735257617231192113#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JWdzBXcVdrQUFJWVZXLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735568937327501560#m</id>
            <title>R to @Gorden_Sun: 效果演示：https://www.youtube.com/watch?v=3eiSohroGwU&amp;t=3s&amp;ab_channel=JulianParker</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735568937327501560#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735568937327501560#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:54:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>效果演示：<a href="https://www.youtube.com/watch?v=3eiSohroGwU&amp;t=3s&amp;ab_channel=JulianParker">youtube.com/watch?v=3eiSohro…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTU2ODE5NzcwODA1MDQzMi9JYVF4b3JiTD9mb3JtYXQ9anBnJm5hbWU9ODAweDMyMF8x" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735568864614953216#m</id>
            <title>StemGen：先听音乐再生成
这个音乐模型有点意思。之前的音乐模型是，用户输入文字，AI生成整段的音乐。StemGen则是参考用户输入的音乐，先生成一小段音乐，然后再把输入音乐+生成的音乐作为新的输入，继续生成，类似Transformer的过程。
项目：https://julian-parker.github.io/stemgen/
论文：https://arxiv.org/abs/2312.08723</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735568864614953216#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735568864614953216#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:53:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>StemGen：先听音乐再生成<br />
这个音乐模型有点意思。之前的音乐模型是，用户输入文字，AI生成整段的音乐。StemGen则是参考用户输入的音乐，先生成一小段音乐，然后再把输入音乐+生成的音乐作为新的输入，继续生成，类似Transformer的过程。<br />
项目：<a href="https://julian-parker.github.io/stemgen/">julian-parker.github.io/stem…</a><br />
论文：<a href="https://arxiv.org/abs/2312.08723">arxiv.org/abs/2312.08723</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTM3NzMwNDg0MTMwNjExMi9pN0xmVGg3Mj9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735432352489246741#m</id>
            <title>RT by @Gorden_Sun: 写了一个搜索 arXiv 论文的GPT，可以显示标题和你输入语言的摘要，使用的是 arXiv 官方的搜索 API。

https://chat.openai.com/g/g-QlTT7Mi2m-ar-x-iv-assistant</title>
            <link>https://nitter.cz/dotey/status/1735432352489246741#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735432352489246741#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 22:51:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>写了一个搜索 arXiv 论文的GPT，可以显示标题和你输入语言的摘要，使用的是 arXiv 官方的搜索 API。<br />
<br />
<a href="https://chat.openai.com/g/g-QlTT7Mi2m-ar-x-iv-assistant">chat.openai.com/g/g-QlTT7Mi2…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JWLUNBSlhJQUFaNWJDLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JWLWMyVFc0QUE4bDhILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735227363368259626#m</id>
            <title>AI资讯日报，12月14日：https://gorden-sun.notion.site/12-14-AI-cc1310c000114ba3a454395597f30b36?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735227363368259626#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735227363368259626#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 09:16:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月14日：<a href="https://gorden-sun.notion.site/12-14-AI-cc1310c000114ba3a454395597f30b36?pvs=4">gorden-sun.notion.site/12-14…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JURUViaGE4QUFfNHRWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735223017079456019#m</id>
            <title>Solar 10.7B：新的开源最佳模型
评分超过Mistral 7B，不过也就超过了一点点，Mistral如果有10B的版本，两者的水平差不多。
基座模型：https://huggingface.co/upstage/SOLAR-10.7B-v1.0
指令微调：https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735223017079456019#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735223017079456019#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 08:59:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Solar 10.7B：新的开源最佳模型<br />
评分超过Mistral 7B，不过也就超过了一点点，Mistral如果有10B的版本，两者的水平差不多。<br />
基座模型：<a href="https://huggingface.co/upstage/SOLAR-10.7B-v1.0">huggingface.co/upstage/SOLAR…</a><br />
指令微调：<a href="https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0">huggingface.co/upstage/SOLAR…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTXzR6cGJVQUFCTE44LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1735220263065976947#m</id>
            <title>Coffee：AI辅助前端开发（怎么老是前端）
适用于React项目，支持大多数UI组件，能写简洁易维护的代码。
Github：https://github.com/Coframe/coffee</title>
            <link>https://nitter.cz/Gorden_Sun/status/1735220263065976947#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1735220263065976947#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 08:48:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Coffee：AI辅助前端开发（怎么老是前端）<br />
适用于React项目，支持大多数UI组件，能写简洁易维护的代码。<br />
Github：<a href="https://github.com/Coframe/coffee">github.com/Coframe/coffee</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUyMjAwMjMyMDIwNDE4NTYvcHUvaW1nL1hoTkVrQ3JobUhoV0FoWjYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735064009974431884#m</id>
            <title>RT by @Gorden_Sun: 今天 Google 的 Gemini Pro 通过 Gemini API 上线，并且提供了 API 访问，同时还有一个开发者的利好：目前 Gemini Pro 可免费使用！

Gemini API 地址：http://ai.google.dev https://ai.google.dev

有关 Gemini Pro 的一些细节：

- 在专业的基准测试中，Gemini Pro 的表现超越了其他同类模型。
- 当前版本配备了 32K 文本上下文窗口，未来将推出拥有更广阔上下文窗口的版本。
- 目前，Gemini Pro 可免费使用（存在一定使用限制），并且其定价将十分 有竞争力。
- 它具备丰富的功能，包括函数调用、数据嵌入、语义检索、自定义知识嵌入以及聊天功能。
- 它支持 全球超过 180 个国家和地区 的 38 种语言。
- 在今日发布的版本中，Gemini Pro 可处理文本输入并生成文本输出。我们还推出了一个专门的 Gemini Pro 视觉多模态终端，能够处理图像和文本输入，输出文本。
- Gemini Pro 提供了多种 SDK，以便开发者在不同平台上构建应用，包括 Python、Android (Kotlin)、Node.js、Swift 和 JavaScript。

Gemini Pro 提供了易于使用的 SDK，助力开发者在任何平台上快速构建应用。

另外 Google 还提供了一个免费的在线开发工具 Google AI Studio，你可以用它快速构建 Gemini 应用。

Google AI Studio ：https://makersuite.google.com/

最后是 Gemini Pro 定价策略，

Gemini Pro

INPUT
$0.00025 / 1K characters
$0.0025 / image

OUTPUT
$0.0005 / 1K characters

对比一下 GPT-3.5 价格：
gpt-3.5-turbo-1106
INPUT
$0.0010 / 1K tokens
OUTPUT
$0.0020 / 1K tokens

但两者的计算单位不一样， Google 是按字符，OpenAI 是按 Token，如果是中文那 Google 便宜不少，如果是英文两者价格差不多。

更多详细内容可以参考其官方博客：https://blog.google/technology/ai/gemini-api-developers-cloud/
如果你更喜欢中文版本可以参考我的翻译：https://baoyu.io/translations/google/gemini-api-developers-cloud</title>
            <link>https://nitter.cz/dotey/status/1735064009974431884#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735064009974431884#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 22:27:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天 Google 的 Gemini Pro 通过 Gemini API 上线，并且提供了 API 访问，同时还有一个开发者的利好：目前 Gemini Pro 可免费使用！<br />
<br />
Gemini API 地址：<a href="http://ai.google.dev">ai.google.dev</a> <a href="https://ai.google.dev">ai.google.dev</a><br />
<br />
有关 Gemini Pro 的一些细节：<br />
<br />
- 在专业的基准测试中，Gemini Pro 的表现超越了其他同类模型。<br />
- 当前版本配备了 32K 文本上下文窗口，未来将推出拥有更广阔上下文窗口的版本。<br />
- 目前，Gemini Pro 可免费使用（存在一定使用限制），并且其定价将十分 有竞争力。<br />
- 它具备丰富的功能，包括函数调用、数据嵌入、语义检索、自定义知识嵌入以及聊天功能。<br />
- 它支持 全球超过 180 个国家和地区 的 38 种语言。<br />
- 在今日发布的版本中，Gemini Pro 可处理文本输入并生成文本输出。我们还推出了一个专门的 Gemini Pro 视觉多模态终端，能够处理图像和文本输入，输出文本。<br />
- Gemini Pro 提供了多种 SDK，以便开发者在不同平台上构建应用，包括 Python、Android (Kotlin)、Node.js、Swift 和 JavaScript。<br />
<br />
Gemini Pro 提供了易于使用的 SDK，助力开发者在任何平台上快速构建应用。<br />
<br />
另外 Google 还提供了一个免费的在线开发工具 Google AI Studio，你可以用它快速构建 Gemini 应用。<br />
<br />
Google AI Studio ：<a href="https://makersuite.google.com/">makersuite.google.com/</a><br />
<br />
最后是 Gemini Pro 定价策略，<br />
<br />
Gemini Pro<br />
<br />
INPUT<br />
$0.00025 / 1K characters<br />
$0.0025 / image<br />
<br />
OUTPUT<br />
$0.0005 / 1K characters<br />
<br />
对比一下 GPT-3.5 价格：<br />
gpt-3.5-turbo-1106<br />
INPUT<br />
$0.0010 / 1K tokens<br />
OUTPUT<br />
$0.0020 / 1K tokens<br />
<br />
但两者的计算单位不一样， Google 是按字符，OpenAI 是按 Token，如果是中文那 Google 便宜不少，如果是英文两者价格差不多。<br />
<br />
更多详细内容可以参考其官方博客：<a href="https://blog.google/technology/ai/gemini-api-developers-cloud/">blog.google/technology/ai/ge…</a><br />
如果你更喜欢中文版本可以参考我的翻译：<a href="https://baoyu.io/translations/google/gemini-api-developers-cloud">baoyu.io/translations/google…</a></p>
<p><a href="https://nitter.cz/sundarpichai/status/1734952757722001626#m">nitter.cz/sundarpichai/status/1734952757722001626#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JRbzJiMVhzQUFRcUh2LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735062406554874210#m</id>
            <title>RT by @Gorden_Sun: 微软在 HuggingFace 上发布了 Phi-2 的模型</title>
            <link>https://nitter.cz/dotey/status/1735062406554874210#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735062406554874210#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 22:21:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软在 HuggingFace 上发布了 Phi-2 的模型</p>
<p><a href="https://nitter.cz/_akhaliq/status/1735051609581793768#m">nitter.cz/_akhaliq/status/1735051609581793768#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735059338488697012#m</id>
            <title>RT by @Gorden_Sun: 现在已经可以在 iPhone 或 iPad 上本机离线运行开源的 Mistral-7B 大语言模型了！

需要借助 LLMFarm（http://llmfarm.site https://llmfarm.site/ ），一个支持 Apple Silicon 技术的开源客户端。对于设备的要求是：
- 一台至少配备M1 + 8GB RAM 的 iPad 或 iPhone
- 至少 8GB 的可用本地存储空间

在本机运行大语言模型有几个好处：
1. 无需联网
2. 不用担心隐私泄露

缺点就是能力要弱一些，机器配置不够高速度也不会太快。但多一些选择总是好的！

如果你想看详细的安装教程，可以看这个链接：https://www.linkedin.com/pulse/using-llms-locally-ipad-iphone-maciek-j%C4%99drzejczyk-cd0zf/

中文翻译：https://baoyu.io/translations/llm/using-llms-locally-ipad-iphone</title>
            <link>https://nitter.cz/dotey/status/1735059338488697012#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735059338488697012#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 22:09:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在已经可以在 iPhone 或 iPad 上本机离线运行开源的 Mistral-7B 大语言模型了！<br />
<br />
需要借助 LLMFarm（<a href="http://llmfarm.site">llmfarm.site</a> <a href="https://llmfarm.site/">llmfarm.site/</a> ），一个支持 Apple Silicon 技术的开源客户端。对于设备的要求是：<br />
- 一台至少配备M1 + 8GB RAM 的 iPad 或 iPhone<br />
- 至少 8GB 的可用本地存储空间<br />
<br />
在本机运行大语言模型有几个好处：<br />
1. 无需联网<br />
2. 不用担心隐私泄露<br />
<br />
缺点就是能力要弱一些，机器配置不够高速度也不会太快。但多一些选择总是好的！<br />
<br />
如果你想看详细的安装教程，可以看这个链接：<a href="https://www.linkedin.com/pulse/using-llms-locally-ipad-iphone-maciek-j%C4%99drzejczyk-cd0zf/">linkedin.com/pulse/using-llm…</a><br />
<br />
中文翻译：<a href="https://baoyu.io/translations/llm/using-llms-locally-ipad-iphone">baoyu.io/translations/llm/us…</a></p>
<p><a href="https://nitter.cz/emollick/status/1734931042211934543#m">nitter.cz/emollick/status/1734931042211934543#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>