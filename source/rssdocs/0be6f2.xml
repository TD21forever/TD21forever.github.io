<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Gorden Sun / @Gorden_Sun</title>
        <link>https://nitter.cz/Gorden_Sun</link>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1742092294948594002#m</id>
            <title>GPTs从简单到复杂可以划分为4种：
1）只通过文字限定角色和功能的GPTs
2）在1的基础上，附加知识库
3）调用标准OpenAPI的GPTs
4）调用自定义API的GPTs
GPTs的潜力非常大，用第4种GPTs甚至可以实现独立的小应用。
这篇教程完整介绍了每种GPTs的创建流程：https://mojju.com/blog/how-to-create-complex-gpts-with-api-actions-and-a-node-js-backend</title>
            <link>https://nitter.cz/Gorden_Sun/status/1742092294948594002#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1742092294948594002#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 07:55:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPTs从简单到复杂可以划分为4种：<br />
1）只通过文字限定角色和功能的GPTs<br />
2）在1的基础上，附加知识库<br />
3）调用标准OpenAPI的GPTs<br />
4）调用自定义API的GPTs<br />
GPTs的潜力非常大，用第4种GPTs甚至可以实现独立的小应用。<br />
这篇教程完整介绍了每种GPTs的创建流程：<a href="https://mojju.com/blog/how-to-create-complex-gpts-with-api-actions-and-a-node-js-backend">mojju.com/blog/how-to-create…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MwbmlVQ2JvQUFTZ1FOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1741985433649926332#m</id>
            <title>有没有这样的GPU平台：
我选好SD版本，设置好checkpoint模型和ControlNet模型，设置好默认填充的提示词和参数。其他用户来了开箱即用，并且根据使用量我能赚到收益。

这样一来，基于SD的应用都可以被取代，艺术字、二维码、换脸、上色等等。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1741985433649926332#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1741985433649926332#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 00:51:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有没有这样的GPU平台：<br />
我选好SD版本，设置好checkpoint模型和ControlNet模型，设置好默认填充的提示词和参数。其他用户来了开箱即用，并且根据使用量我能赚到收益。<br />
<br />
这样一来，基于SD的应用都可以被取代，艺术字、二维码、换脸、上色等等。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1741794568818053539#m</id>
            <title>AI资讯日报，1月1日：https://gorden-sun.notion.site/1-1-AI-4814d23b1304458eb4644a82ca8b9628?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1741794568818053539#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1741794568818053539#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 12:12:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，1月1日：<a href="https://gorden-sun.notion.site/1-1-AI-4814d23b1304458eb4644a82ca8b9628?pvs=4">gorden-sun.notion.site/1-1-A…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0N3WTZwT2JZQUFSWl9YLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1741793485106319657#m</id>
            <title>LLaVA-3b：基于 Dolphin 2.6 Phi（微软Phi的微调版本）的多模态模型，图片模型使用的是 SigLIP 400M。
模型地址：https://huggingface.co/visheratin/LLaVA-3b</title>
            <link>https://nitter.cz/Gorden_Sun/status/1741793485106319657#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1741793485106319657#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 12:08:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLaVA-3b：基于 Dolphin 2.6 Phi（微软Phi的微调版本）的多模态模型，图片模型使用的是 SigLIP 400M。<br />
模型地址：<a href="https://huggingface.co/visheratin/LLaVA-3b">huggingface.co/visheratin/LL…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MTU0MzI0ODAzNDY2NDQ0OS9fX3prYzdOTT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1741791400927326548#m</id>
            <title>FlowVid：Meta推出的一致性视频生成视频模型
保持主体一致，可以修改视频风格或替换视频主体。
项目地址：https://jeff-liangf.github.io/projects/flowvid/
Github（暂未发布代码）：https://github.com/Jeff-LiangF/FlowVid
论文：https://arxiv.org/abs/2312.17681</title>
            <link>https://nitter.cz/Gorden_Sun/status/1741791400927326548#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1741791400927326548#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 12:00:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>FlowVid：Meta推出的一致性视频生成视频模型<br />
保持主体一致，可以修改视频风格或替换视频主体。<br />
项目地址：<a href="https://jeff-liangf.github.io/projects/flowvid/">jeff-liangf.github.io/projec…</a><br />
Github（暂未发布代码）：<a href="https://github.com/Jeff-LiangF/FlowVid">github.com/Jeff-LiangF/FlowV…</a><br />
论文：<a href="https://arxiv.org/abs/2312.17681">arxiv.org/abs/2312.17681</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDE3OTA4MTI0NDk3MDU5ODQvcHUvaW1nL2lzRVo0U0daN01fRkhEM3guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1741788126165799330#m</id>
            <title>TinyLlama 发布1.0版本，1.1B 参数，基于3万亿 tokens 训练，与 LLaMa 2 完全相同的架构和分词器。
从他们的Github能看到完整的训练过程。
模型地址：https://huggingface.co/TinyLlama
Github：https://github.com/jzhang38/TinyLlama</title>
            <link>https://nitter.cz/Gorden_Sun/status/1741788126165799330#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1741788126165799330#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 11:47:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>TinyLlama 发布1.0版本，1.1B 参数，基于3万亿 tokens 训练，与 LLaMa 2 完全相同的架构和分词器。<br />
从他们的Github能看到完整的训练过程。<br />
模型地址：<a href="https://huggingface.co/TinyLlama">huggingface.co/TinyLlama</a><br />
Github：<a href="https://github.com/jzhang38/TinyLlama">github.com/jzhang38/TinyLlam…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MTc3MjMzNjI5NzM1NzMxMi9uM3puMVBVaD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1741419996994269542#m</id>
            <title>AI资讯日报，12月31日：https://gorden-sun.notion.site/12-31-AI-682e263f6f39467d997695cc721bee3e?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1741419996994269542#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1741419996994269542#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 11:24:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月31日：<a href="https://gorden-sun.notion.site/12-31-AI-682e263f6f39467d997695cc721bee3e?pvs=4">gorden-sun.notion.site/12-31…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NyRVBmSmF3QUFfZFlrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1741410171153486176#m</id>
            <title>HandRefiner：修复AI画的异常的手部
11月发布的论文，12月29号发布的代码。识别出图片中的手部，并局部重绘为正常的手部。
示例的使用方法是python命令行，估计ControlNet里引入模型也可以正常使用。
Github：https://github.com/wenquanlu/HandRefiner/
论文：https://arxiv.org/abs/2311.17957
模型：https://huggingface.co/hr16/ControlNet-HandRefiner-pruned/tree/main</title>
            <link>https://nitter.cz/Gorden_Sun/status/1741410171153486176#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1741410171153486176#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 10:45:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HandRefiner：修复AI画的异常的手部<br />
11月发布的论文，12月29号发布的代码。识别出图片中的手部，并局部重绘为正常的手部。<br />
示例的使用方法是python命令行，估计ControlNet里引入模型也可以正常使用。<br />
Github：<a href="https://github.com/wenquanlu/HandRefiner/">github.com/wenquanlu/HandRef…</a><br />
论文：<a href="https://arxiv.org/abs/2311.17957">arxiv.org/abs/2311.17957</a><br />
模型：<a href="https://huggingface.co/hr16/ControlNet-HandRefiner-pruned/tree/main">huggingface.co/hr16/ControlN…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NxN1N1NmJNQUFtZ3B0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1741087804975972811#m</id>
            <title>AI生成视频工具Assistive Video有免费试用了</title>
            <link>https://nitter.cz/Gorden_Sun/status/1741087804975972811#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1741087804975972811#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 13:24:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI生成视频工具Assistive Video有免费试用了</p>
<p><a href="https://nitter.cz/assistiveapp/status/1741086196917477587#m">nitter.cz/assistiveapp/status/1741086196917477587#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1741067085877485691#m</id>
            <title>AI资讯日报，12月30日：https://gorden-sun.notion.site/12-30-AI-f514ecc668b8488aae330c3da4a0ba0b?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1741067085877485691#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1741067085877485691#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 12:01:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月30日：<a href="https://gorden-sun.notion.site/12-30-AI-f514ecc668b8488aae330c3da4a0ba0b?pvs=4">gorden-sun.notion.site/12-30…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NtRFJxZWJJQUFad2txLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740930168393466246#m</id>
            <title>微软的Copilot出iOS版本了，基本跟之前的Bing Chat差不多，不买ChatGPT Plus的可以考虑用这个。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740930168393466246#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740930168393466246#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 02:57:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软的Copilot出iOS版本了，基本跟之前的Bing Chat差不多，不买ChatGPT Plus的可以考虑用这个。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrR3dWQmJNQUFMX29ILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrR3dVX2FrQUF4RFNpLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrR3dVX2FrQUUzTXJtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/ZHOZHO672070/status/1740811505413787708#m</id>
            <title>RT by @Gorden_Sun: 👀有小伙伴问除了聊天和生成提示词以外，ComfyUI中的Gemini模型还可以用来干嘛，其实用处有很多，相当于通过ComfyUI这个平台将LLM与图像/视频模型结合起来，实现一种“散装”的多模态
🤖具体来说，最直接最实用的一个用法就是将pro vision模型用于批量打标，关键是免费哈哈哈哈
🤣期待大家创造更多玩法</title>
            <link>https://nitter.cz/ZHOZHO672070/status/1740811505413787708#m</link>
            <guid isPermaLink="false">https://nitter.cz/ZHOZHO672070/status/1740811505413787708#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 19:06:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>👀有小伙伴问除了聊天和生成提示词以外，ComfyUI中的Gemini模型还可以用来干嘛，其实用处有很多，相当于通过ComfyUI这个平台将LLM与图像/视频模型结合起来，实现一种“散装”的多模态<br />
🤖具体来说，最直接最实用的一个用法就是将pro vision模型用于批量打标，关键是免费哈哈哈哈<br />
🤣期待大家创造更多玩法</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDA4MTEzMTI0MDg0NzM2MDAvcHUvaW1nL2p1eWg0aEZsYWRJQ2hwZFkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740668733180510345#m</id>
            <title>AI资讯日报，12月29日：https://gorden-sun.notion.site/12-29-AI-fac4f646715143afbbf8f3f150771e28?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740668733180510345#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740668733180510345#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 09:39:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月29日：<a href="https://gorden-sun.notion.site/12-29-AI-fac4f646715143afbbf8f3f150771e28?pvs=4">gorden-sun.notion.site/12-29…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NnWS1ZcWJZQUEyZEVBLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740665370988658868#m</id>
            <title>Deita：微调LLM的高质量数据和工具包
目前开源了6K和10K大小高质量数据，用10K数据微调的Mistral 7B模型，MT-Bench得分7.55，AlpacaEval得分90（超过openchat-3.5）
Github：https://github.com/hkust-nlp/deita
论文：https://arxiv.org/abs/2312.15685</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740665370988658868#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740665370988658868#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 09:25:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Deita：微调LLM的高质量数据和工具包<br />
目前开源了6K和10K大小高质量数据，用10K数据微调的Mistral 7B模型，MT-Bench得分7.55，AlpacaEval得分90（超过openchat-3.5）<br />
Github：<a href="https://github.com/hkust-nlp/deita">github.com/hkust-nlp/deita</a><br />
论文：<a href="https://arxiv.org/abs/2312.15685">arxiv.org/abs/2312.15685</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NnVjZTb2FVQUFoLVphLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740661879624872078#m</id>
            <title>阿里放出了DreaMoving的Demo，但是这个空间实在是拉胯，排队要几个小时，复制空间又报错😅</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740661879624872078#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740661879624872078#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 09:11:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里放出了DreaMoving的Demo，但是这个空间实在是拉胯，排队要几个小时，复制空间又报错😅</p>
<p><a href="https://nitter.cz/_akhaliq/status/1740380744726594003#m">nitter.cz/_akhaliq/status/1740380744726594003#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740651315066544251#m</id>
            <title>UForm：仅 1.5B 大小的多模态模型
能读图和聊天，由 llama-1.3B 和 ViT-B/16 组成。
Github：https://github.com/unum-cloud/uform</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740651315066544251#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740651315066544251#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 08:29:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>UForm：仅 1.5B 大小的多模态模型<br />
能读图和聊天，由 llama-1.3B 和 ViT-B/16 组成。<br />
Github：<a href="https://github.com/unum-cloud/uform">github.com/unum-cloud/uform</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MTIzNDkyODE0NTA1MTY0OC9nNTlfcER4Yj9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740646486302748961#m</id>
            <title>WhatOnEarth：搜索+ChatGPT
与Perplexity的区别是，直接把界面做成了搜索引擎的样式，而不是聊天的样式。支持中文输入，但只能英文回复。
地址：https://www.whatonearth.ai/</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740646486302748961#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740646486302748961#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 08:10:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WhatOnEarth：搜索+ChatGPT<br />
与Perplexity的区别是，直接把界面做成了搜索引擎的样式，而不是聊天的样式。支持中文输入，但只能英文回复。<br />
地址：<a href="https://www.whatonearth.ai/">whatonearth.ai/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NnRXVsd2JFQUFIaDNFLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740585793255862636#m</id>
            <title>今年4月份看到过一句关于AI发展现状的讨论：
Stuff happening faster than you can read up on what stuff is happening.

现在回头看，真是太形象了。看不完，完全看不完。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740585793255862636#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740585793255862636#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 04:09:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今年4月份看到过一句关于AI发展现状的讨论：<br />
Stuff happening faster than you can read up on what stuff is happening.<br />
<br />
现在回头看，真是太形象了。看不完，完全看不完。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740294394400612714#m</id>
            <title>AI资讯日报，12月28日：https://gorden-sun.notion.site/12-28-AI-7dfc0b792a7a4ce1ae7efe44c4a3ec24?pvs=4</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740294394400612714#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740294394400612714#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 08:51:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI资讯日报，12月28日：<a href="https://gorden-sun.notion.site/12-28-AI-7dfc0b792a7a4ce1ae7efe44c4a3ec24?pvs=4">gorden-sun.notion.site/12-28…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiRWhCeGFJQUVsbWFGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740236201754566987#m</id>
            <title>R to @Gorden_Sun: 10、Suno
输入歌词即可由AI生成歌曲，效果比较好，预计明年会有突破式进展。目前市面上甚至没有竞品。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740236201754566987#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740236201754566987#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 05:00:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>10、Suno<br />
输入歌词即可由AI生成歌曲，效果比较好，预计明年会有突破式进展。目前市面上甚至没有竞品。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDAyMzYxNjM3NDU4MTY1NzYvcHUvaW1nL2tYQS1MVFhNUmt1TXJ1QWwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>