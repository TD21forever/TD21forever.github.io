<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>少数派 -- 首页</title>
        <link>https://sspai.com</link>
        
        <item>
            <id>https://sspai.com/post/83533</id>
            <title>派早报：文石推出两款电子书新品、荣耀发布 Magic Vs2 折叠屏手机等</title>
            <link>https://sspai.com/post/83533</link>
            <guid isPermaLink="false">https://sspai.com/post/83533</guid>
            <pubDate></pubDate>
            <updated>Fri, 13 Oct 2023 01:01:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 文石, 电子书, Note X3, Tab 10C Pro
<br>
<br>
总结: 文石发布了两款新的电子书产品，分别是Note X3和Tab 10C Pro。Note X3采用了10.3英寸的屏幕，内置多种笔刷选择，配置高通处理器和大内存。Tab 10C Pro则是Tab 10C的升级版，采用了最新的彩墨屏技术，配备高通处理器和大容量存储空间。 </div>
                        <hr>
                    
                    <h2>你可能错过的新鲜事</h2><h3>文石推出两款电子书新品</h3><figure class="image ss-img-wrapper"><img alt="ONxgbrRm7oCOhBxKWnXcWHqbnwf" src="https://cdn.sspai.com/editor/u_/ckk9cftb34tcsa71k4ag?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>10 月 12 日，文石发布了 Note X3 电子书和 Tab 10C Pro 彩墨平板。其中，文石 BOOX Note X3 的尺寸为 10.3 英寸，227 PPI，使用更新款的导光板，其厚度更薄，前光均匀度更强，此举有效减少了文字与屏幕的距离感。其内置了多种笔刷选择，包括但不限于：毛笔、钢笔、铅笔、圆珠笔、马克笔等。配置方面，Note X3 装载了高通 8 核 2.4 GHz 处理器，配备 4 GB 内存和 64 GB 存储空间。系统采用的是 Android 12 开放系统，支持 AI 阅读助手、AI 手写识别和分屏模式。售价为 2599 元。</p><figure class="image ss-img-wrapper"><img alt="SiSJb5KAwoDHfuxc8tXc2oTrnUf" src="https://cdn.sspai.com/editor/u_/ckk9cg5b34tcsa71k4b0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>Tab 10C Pro 彩墨平板是 Tab 10C 的升级版，采用了最新的 Kaleido 3 面板，屏幕尺寸为 10.3 英寸，黑白像素密度为 300 ppi，彩色像素密度则为 150 ppi。该设备内含独立显示芯片，官方表示能极大提升应用的刷新速度。在配置上，配备了 8 核 2.8 GHz 的高通处理器，6 GB 内存和 128 GB 闪存，4600 mAh 的电池容量。新型 Tab 10C Pro 还装有 1600 万像素扫描摄像头，可支持 OCR 识别。同时，附带 Pen 2 手写笔，可实现 4096 级压感，磁力吸附，无需充电。产品售价是 4699 元。<a href="https://www.ithome.com/0/724/557.htm">来源</a></p><h3>荣耀发布 Magic Vs2 折叠屏手机</h3><p>荣耀于 10 月 12 日的发布会上正式发布了荣耀 Magic Vs2 折叠屏手机。SoC 方面采用了 3.0 GHz 的高通骁龙 8+ Gen 1 移动处理平台，并内置了独立的安全存储芯片。</p><figure class="image ss-img-wrapper"><img alt="LFVbbHIFQoIpO8xSnQ4c5bE8n1b" src="https://cdn.sspai.com/editor/u_/ckk9cgdb34tcs84s7ke0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>屏幕方面，荣耀 Magic Vs2 的外屏是 6.43 英寸、分辨率为 2376×1060 的 OLED 屏，而内屏则采用了 7.92 英寸、2272×1984 分辨率的 OLED 屏。铰链部分，官方表示采用了「鲁班钛金铰链」「榫卯式一体成型工艺」「自研的盾构钢材料」等，实现了自由悬停功能。</p><p>影像方面，Magic Vs2 的内外屏均装备了 16 MP 前置摄像头，后置则是 50 MP 主摄、12 MP 超广角和 20 MP 长焦镜头。其他方面，这款手机内置了 5000 mAh 电池，并支持 66 W 的快速充电功能。系统方面，基于安卓 13 版本的 MagicOS 7.2 操作系统。</p><p>荣耀还同步正式推出了荣耀手表 4 Pro，手表配备了紫光展锐 W117 穿戴芯片，并且拥有 64 MB 内存和 4 GB 存储空间。采用了一块 1.5 英寸 464×464 的圆形 OLED 屏幕，支持 LTPO 常亮显示。手表机身重大约为 50g，搭载了 480mAh 电池，并能通过 4.5 W 的无线充电技术进行充电。官方声称，这款手表的续航时间可以长达 10 天。此外，其还配备了八通道光学传感器，且支持 eSIM 独立通话功能。<a href="https://weibo.com/3206603957/NnyaBpnvh#comment">来源</a></p><h3>掌阅推出多款电子书新品</h3><p>掌阅于 10 月 12 日召开新品发布会，推出 Light 3/3 Turbo、Ocean3 Turbo 以及 Smart X3 多款新品。</p><figure class="image ss-img-wrapper"><img alt="XZHxbxkupor7EmxxvlbcMOcynqe" src="https://cdn.sspai.com/editor/u_/ckk9cglb34tcscgattqg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>iReader Light 3 和 Light 3 Turbo 均是入门级别的电子书产品，采用了 6 英寸 212 PPI 的 Carta 1200 面板，配有 28 级阅读灯。硬件方面，Light 3 装备了双核 2.0 GHz 处理器，1 GB 内存以及 32 GB 闪存；Light 3 Turbo 则配备了 4 核心墨水屏定制处理器，配有独立的显示芯片，支持 AI 动态刷新，配有 2 GB 内存以及 32 GB 闪存。Light 3 的首发价格为 689 元，Light 3 Turbo 则定价 799 元。</p><figure class="image ss-img-wrapper"><img alt="GJa7bwL88oquwwxOIGqcGwYKnDc" src="https://cdn.sspai.com/editor/u_/ckk9cgtb34tcsee9iccg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>Ocean 3 Turbo，作为 Ocean 3 的升级增强版，定位在中阶市场。Ocean 3 Turbo 采用了 7 英寸 300 ppi 的 E ink Carta 1200 面板，机身薄至 4 mm。屏幕采用了全新的贴合工艺，官方表示大幅度提高了透光度和清晰度，同时也支持了 Regal 图像刷新技术。</p><p>在硬件配置方面，设备搭载了四核墨水屏定制处理器，内存为 4 GB，存储空间为 64 GB。灯光方面，配置了 28 级 DC 调光阅读灯，可以显示 256 级的灰阶效果，Ocean 3 Turbo 也配备了实体翻书键。电池部分，设备搭载了 1800 mAh 的电池，阅读续航长达 72 小时。Ocean 3 Turbo 的售价为 1599 元。</p><figure class="image ss-img-wrapper"><img alt="MQHZblZJnoSWaAxexQ1cjWqUnT1" src="https://cdn.sspai.com/editor/u_/ckk9chdb34tcscgattr0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>iReader Smart X3 定位高阶，搭载了全新的 10.65 英寸 300 PPI 的 Carta 1300 面板。设备搭载了四核墨水屏定制处理器，4GB 的内存和 64GB 的储存空间，机身厚度薄至 5.6mm，重量为 365g，并且还支持 X-Pen3 电磁笔。官方表示阅读灯经过全新升级，使得阅读体验更为舒适。系统上，新加入的「深色模式」能使夜间阅读更适宜。还采用了 AI 动态高刷引擎和独立显示芯片以增强墨水屏的流畅度以及减少残影。售价为 3399 元。<a href="https://weibo.com/u/6146617735">来源</a></p><h3>声阔推出不入耳蓝牙耳机 AeroFit Pro</h3><p>声阔公司于 10 月 12 日推出了其首款不入耳蓝牙耳机 AeroFit Pro。这款耳机具有二合一的设计，可以在耳挂和后挂之间自由切换。</p><figure class="image ss-img-wrapper"><img alt="M3nBbnF4ModmUUxJD8CcZ70Bnmb" src="https://cdn.sspai.com/editor/u_/ckk9chlb34tcsee9icd0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>它配备了 16.2 mm 的动圈单元，软件方面提供 360°空间音频支持并具有 LDAC 编解码及 AirTurbo 气旋式气导功能。此外，这款耳机用 AI 算法和搭配 4 个麦克风共同降噪，并且单耳使用时的续航时间达到 14 小时，总续航时间可达 46 小时。官方表示仅需充电 10 分钟，就能享受 5.5 小时的播放时间。耳机的挂钩由 0.7 mm 超弹力的航天级钛合金制成，并外覆亲肤的 TPU 材质。它还配有可拆卸的编织纹路后挂，且拥有 IPX 5 级别的防汗功能。现在这款耳机已经在各大电商平台上架销售，首发价格为 1199 元。<a href="https://weibo.com/n/Soundcore%E5%A3%B0%E9%98%94">来源</a></p><h3>微软开始阻止 Windows 7/8 的激活密钥激活 Windows 11</h3><p>10 月 12 日，微软正式开始阻止 Windows 7/8 的激活密钥激活 Windows 11。</p><p>微软上月晚段时期表明，将在未来禁止使用 Windows 7/8 的激活密钥用以激活 Windows 11。然而在当时，Windows 7/8 的激活密钥仍然可以启动 Windows 11。而自本周起，微软已经确认 Windows 7 的密钥已经不能用于新安装 Windows 11 系统。</p><p>假如用户先前已经把一台机器从 Windows 7 或 Windows 8 升级至 Windows 11，或已经使用这些旧密钥直接激活了 Windows 11，那么激活状态不会发生变化，现有的数字许可证仍能继续使用。<a href="https://www.theverge.com/2023/10/11/23913107/microsoft-windows-11-block-windows-7-8-keys-upgrade-activation">来源</a></p><h3>RIAA 认为 AI 翻唱有版权侵权风险</h3><p>美国唱片行业协会（RIAA）认为 AI 翻唱有版权侵权风险，期待美国政府将其纳入盗版监察名单。</p><p>在向美国贸易代表办公室（USTR）的申请中，RIAA 建议政府在年度版权侵权活动报告《盗版与假冒市场调查》中，加入 AI 翻唱的类别。据悉《盗版与假冒市场调查》通常会列出版权侵权的公司和网站。</p><p>在申请信中，RIAA 提到，2023 年的 AI 翻唱服务的数量激增，这些服务不只侵犯了被克隆声音艺术家的权益，同样侵害了音轨原始录音所有者的权益。RIAA 亦强调，AI 翻唱已导致「未授权衍生作品」激增。<a href="https://www.theverge.com/2023/10/11/23913405/riaa-ai-voice-cloning-threat-copyright-ustr">来源</a></p><h3>Apple 修改国区 Apple Store 教育优惠政策</h3><p>近期，Apple 修改了国区 Apple Store 的教育优惠政策。教育优惠的认证方式由原先的 UNIDAYS 账号验证变为了支付宝验证，用户在桌面端需要扫码认证，移动端则会自动跳转支付宝认证。目前，Apple Music「大学生资格」的验证方式没有发生变化，仍需通过 UNIDAYS 账号验证。<a href="https://www.apple.com.cn/cn-edu/shop">来源</a></p><h3>QQ 浏览器推出 PDF 阅读助手</h3><p>QQ 浏览器今日发布了「PDF 阅读助手」并开始接受测试申请。支持一键将 PDF 文件转化为智能摘要，用户无须自行阅读原材料就可通过提问得到所需信息。还支持对先前问答的进一步提问，可直接点击跳转至相应的原始引用，方便比对阅读。用户只需在 QQ 浏览器中打开 PDF 文件，并点击右上角按钮即可启动「PDF 阅读助手」。这项功能是由腾讯混元大模型驱动，并且适用于手机和电脑版的 QQ 浏览器。<a href="https://tool.browser.qq.com/invitation/?code=0315iXkl2lAcbc4orNnl20VFRR15iXkC&amp;state=">来源</a></p><figure class="image ss-img-wrapper"><img alt="AzeWbPinBoDGixxvwdfcj8F7nhe" src="https://cdn.sspai.com/editor/u_/ckk9chtb34tcsee9icdg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><h2>看看就行的小道消息</h2><ul><li>根据国外科技媒体 MySmartPrice 报道，三星 Galaxy S24 Ultra 的相关测试数据现身 GeekBench 跑分库，其中美版 Galaxy S24 Ultra 测试结果显示，6.2.0 版本单核成绩 2234 分，多核成绩为 6807 分。配置上应该是采用高通骁龙 8 Gen 3 for Galaxy 芯片，采用 1+3+2+2 八核设计，配有 Adreno 750 GPU，运存为 8GB 并基于 One UI 6.0。同时采用三星 Exynos 2400 的欧版 Galaxy S24+ 的跑分数据也出现在 Geekbench 6，数据显示 Exynos 2400 采用了 1+2+3+4 十核设计，超大核频率达 3.21GHz。该机跑分单核 2067 分、多核 6520 分，比美版 Galaxy S24 Ultra 跑分略低。<a href="https://www.sammobile.com/news/galaxy-s24-ultra-snapdragon-performance-numbers-revealed/">来源</a></li></ul><h2>少数派的近期动态</h2><ul><li>国庆去了哪儿，留下了哪些回忆？用一张照片为夏天的尾巴做个「总结」！<a href="https://s.weibo.com/weibo?q=%23%E8%BF%99%E4%B8%AA%E5%A4%8F%E5%A4%A9%E6%88%91%E5%9C%A8%E8%BF%99%23">#这个夏天我在这#</a> 照片征集活动仍在进行，每周都有「出行礼包」送出。<a href="https://weibo.com/u/1914010467"><strong>微博参与</strong></a></li><li>《iOS 蓝皮书》已开启年度更新，内容适配 iOS 17，首发加入少数派会员。年度会员可<a href="https://sspai.com/series/277"><strong>直接畅读</strong></a></li><li>不能说走就走，但想去哪儿就去哪儿总是可以的！规划、路线、必备好物、心得经验、踩雷避坑……分享你的自驾游故事和心得。<a href="https://sspai.com/bullet/1695717562"><strong>参与讨论</strong></a></li></ul><h2>你可能错过的好文章</h2><ul><li>🤏 <a href="https://sspai.com/prime/story/apple-watch-a11y">呼风唤雨于指尖拳心：巧用辅助功能单手操作 Apple Watch</a></li><li>🎈 <a href="https://sspai.com/post/83516">大内密谈 | 口述深圳二十年少数派激荡浮沉录</a></li><li>🫧 <a href="https://sspai.com/post/83522">科普 | 高帧率、好画质的「光追」是如何实现的？</a></li></ul><p>&gt; 下载 <a href="https://sspai.com/page/client">少数派 2.0 客户端</a>、关注 <a href="https://sspai.com/s/J71e">少数派公众号</a>，解锁全新阅读体验 📰</p><p>&gt; 实用、好用的 <a href="https://sspai.com/mall">正版软件</a>，少数派为你呈现 🚀</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://sspai.com/post/83516</id>
            <title>大内密谈 | 口述深圳二十年少数派激荡浮沉录</title>
            <link>https://sspai.com/post/83516</link>
            <guid isPermaLink="false">https://sspai.com/post/83516</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 09:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 老麦, 创业故事, 商业思考, 内容平台
<br>
<br>
总结: 本期节目中，老麦在《大内密谈》中分享了自己的创业故事和对商业、创业及内容平台的思考。他从东北到广东闯荡，经历了起起落落，最终在深圳闯出了自己的天地，创办了少数派。节目中老麦分享了少数派十几年来的发展历程，给人们带来了正向的鼓励。 </div>
                        <hr>
                    
                    <p>本期节目中，老麦做客《<a href="https://podcasts.apple.com/cn/podcast/%E5%A4%A7%E5%86%85%E5%AF%86%E8%B0%88/id657765158">大内密谈</a>》，和相征老师分享了自己的创业故事，以及对商业、创业及内容平台的思考。</p><p>以下为节目原始简介：</p><blockquote><p>本期，故人重逢，划水怪 @相征 终于和老麦 @老麦煮机 约着录上了节目，聊一聊人生 20 多年的起落浮沉。毕业后，从东北到广东闯荡的老麦，还没出东北，在车站就被人骗去 30 块钱。当你以为这只是社会给你的小小考验时，只能说一句，还是太年轻。节目前半部分，堪称南漂打工防骗指南，年轻的老麦从一个坑出来又跳入了另一个坑。好在一个心态好又肯努力，最终在深圳闯出自己的天地，少数派也应运而生。节目中老麦分享了少数派十几年来的发展历程，同为创业者的划水怪也颇为感概。只不过，昨日之深渊，今日之浅谈。当下两人还是心态还是非常积极的，也希望这期能给大家带来一些正向的鼓励。</p></blockquote><p>📺 《少数派播客》已经登陆 YouTube 平台，YouTube 用户也能收听啦。<a href="https://www.youtube.com/channel/UC0R2CbQ5vpLE8LTCSt7dAKQ">点击这里</a>，即可订阅！</p><p>🎁 少数派会员全面焕新，定制内容持续更新，付费栏目全场畅读，年度最惠价格正在进行中，<a href="https://sspai.com/prime/explore">欢迎新老朋友加入</a>！</p><p>🥳 少数派出品、知名主播婉莹、甜食制作的播客入门教程《<a href="https://sspai.com/series/280">100 小时后请叫我播客主理人</a>》已经上线，用通俗易懂的语言带你入门播客制作，轻松完成你的「第〇期」播客节目。</p><h2>直接收听</h2><div class="ss-audioSource" id="109" src="https://v.typlog.com/sspai/8302908826_408734.mp3" title="口述深圳二十年少数派激荡浮沉录">Audio</div><h2>订阅《少数派播客》</h2><ul><li><a href="https://sspai.typlog.io/feed/audio.xml">节目 RSS 链接</a></li><li><a href="https://podcasts.apple.com/hk/podcast/%E4%B8%80%E6%B4%BE-podcast/id1483157529">Apple Podcasts</a></li><li><a href="https://www.xiaoyuzhoufm.com/podcast/5e280fb1418a84a0461fc567">小宇宙</a></li><li><a href="https://www.youtube.com/channel/UC0R2CbQ5vpLE8LTCSt7dAKQ">YouTube</a></li><li><a href="https://open.spotify.com/show/7pJ5EHWj7i5wQwqzY9kHr5">Spotify</a></li><li><a href="https://podcasts.google.com/feed/aHR0cHM6Ly9zc3BhaS50eXBsb2cuaW8vZmVlZC54bWw?hl=zh-TW">Google Podcasts</a></li><li><a href="https://pod.link/1483157529">其它平台</a></li></ul><h2>人物介绍</h2><ul><li>相征：人民群众熟悉和喜爱的《大内密谈》主播</li><li>老麦：少数派创始人</li></ul><p>有任何想对我们说的、听我们聊的，都欢迎写信至 nick@sspai.com。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://sspai.com/post/83522</id>
            <title>科普 | 高帧率、好画质的「光追」是如何实现的？</title>
            <link>https://sspai.com/post/83522</link>
            <guid isPermaLink="false">https://sspai.com/post/83522</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 08:37:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 赛博朋克 2077, 往日之影, 光追, DLSS
<br>
<br>
总结: 《赛博朋克 2077：往日之影》是一款与赛博朋克、公司殖民主义、边缘行者等概念紧密相关的游戏。除了这些概念外，游戏还通过光追和DLSS等技术在未来城市中打造了夜之城。光追、DLSS等技术的出现改变了游戏体验，提升了画面的真实感和细节表现。传统游戏的光照实现方式是通过光栅化来描绘光照结果，而不是还原光照过程。光栅化的优点是速度快，但缺点是不够真实。光追技术的应用使得游戏中的光照效果更加真实，投影也更接近真实。 </div>
                        <hr>
                    
                    <p>不知道上个月上线的《赛博朋克 2077：往日之影》DLC 大家剧情推到哪儿了？</p><p><strong>关联阅读：</strong><a href="https://sspai.com/post/83309">It's Okay To Cry——评《往日之影》及《赛博朋克 2077》</a></p><p>除了与赛博朋克、公司殖民主义、边缘行者等名词高度绑定，现在当我们提起《赛博朋克 2077》这款游戏，出现在很多人还脑海里的自然也有 CDPR 借助光线追踪、DLSS 等技术在其 RED 引擎中所打造的未来城市「夜之城」。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/69cef3864fb34f1346ca50bfdb8388b6.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>2.01 版本开启超速模式和光线重建后的效果，DLSS 设置为「均衡」</figcaption></figure><p>从一卡难求到如今支持最新技术的游戏作品井喷，「光追」也从早年少数游戏和玩家才能享受的前沿体验变成了 3A 大作不可或缺的「点睛之笔」。那光追、DLSS、帧生成等技术是如何提升游戏体验的？它的出现改变了什么，又解决了哪些问题？</p><p>注：本文为《<a href="https://sspai.com/post/63057">升级「真香」的 RTX 30 系显卡后，你能得到什么？</a>》一文的更新内容，原文部分信息已过时。</p><h2>传统游戏的光照如何实现</h2><p>我们所能看见的、五彩斑斓的世界，本质上是因为光在传播中遇到了组成这个世界的、不同材质的物体。光线在这些物体上反射、折射、漫反射、散射……经过不同的光学现象加工之后，特定的光线最终到达人眼，经视网膜感光细胞的处理，我们才得以看到不同颜色的物体。这种原理会带来一些很有意思的变化，比如不同材质的物体从相同角度来看观感不同，相同材质从不同角度看过去的感觉也不一样；在光线很暗的时候，我们自然也很难看清东西。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/9dc15e0f9801ff1505b6931aaaf47331?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>真实环境的光线远比游戏复杂 | 图片自 @unsplash</figcaption></figure><p>但同样的「观感」放在游戏世界，所采取的呈现方式则截然不同。在光线追踪技术出现之前，传统的游戏设计在重现光照效果时往往只能从「最终效果」出发，为玩家呈现不同光照环境下，游戏世界所呈现出来的最终效果。</p><p>具体的实现原理很好理解：</p><p>首先，现代 3D 模型实际上都是通过三角形构成的<sup class="ss-footnote" href="" title="在 3D 建模和图形渲染中，最小的单位就是一个三角面。 ,而在 3D 建模软件（Maya、3D Max）中，四边面模型非常常见，四边面模型在顶点分布更均匀，更符合实际物体的形状，而且在细分或者涉及到变形、动画操作时更加平滑和容易于控制。 ">1</sup>，三角形的面数决定了模型的精细程度，模型精度越高，三角形数目也就越多，性能开销也就越大。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/f06d2b9b3791702abc9b69d75e9276bf?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>由三角形构成的模型，越复杂的模型也越精细</figcaption></figure><p>这些三角形要显示在我们的电脑屏幕上，还需要经过「光栅化」，即先将三角形用<strong>近似连点描边</strong>的方式转化成屏幕上的像素<sup class="ss-footnote" href="" title="在这个过程中，因为三维坐标系可以是小数而屏幕二维坐标只能是整数，大家在游戏中看到的锯齿就出现了。">2</sup>，然后对三角形内部的像素进行上色，同时判断三角形哪些部分被前面其他三角形遮挡了，被遮挡的部分也无需上色，减少不必要的性能开销。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/626266e8040e68fe558d8c2d92cf928b?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>光栅化工作原理</figcaption></figure><p>游戏里的光照效果实现，也是在「光栅化」这个过程里完成的——只需要对三角形内部的像素进行额外的上色步骤即可：模型的三角形都有对应的固有颜色（皮肤有固有的肤色、头发有固有的发色），所以将模型转化到二维像素以后，可以通过每个三角形的颜色为每个屏幕上的像素分配一个初始颜色值。接下来要根据场景里的其他光源来进一步的像素处理来改变像素的颜色，最后还需要根据纹理（皮革有皮革的纹理，布料有不同的材质）对像素做最后的处理，进而生成应用于像素的最终颜色。</p><p><strong>所以基于光栅化的游戏光线处理，更像是一种对光照结果的「描绘」而非对光照过程的还原。你看到的画面可以被理解为在自行发光，而不是和生活中一样通过折射、反射等手段传递光线。这也就是我们在上面所说的以渲染「最终效果」为主要手段</strong>。</p><p>光栅化的优点在于可以足够快，程序员可以预先写好光线的程序来处理小面积的光线，还可以制作光照贴图，在需要的时候和环境再进行渲染呈现（静态光照效果）来减少处理压力；但是缺点也很明显：不够真实，比方说游戏中的物体投影大部分时候都是一整块颜色相同的区域（阴影贴图），但是我们仔细观察生活会发现由于光的复杂性实际上的投影由近到远是越来越浅的。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/49dfd213006d6463756bace330c702d5?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>投影和更接近真实的投影 图片来自 unreal 引擎官网</figcaption></figure><p>更多关于光栅化不够真实的更多例子可以看<a href="https://sspai.com/link?target=https%3A%2F%2Fdocs.unrealengine.com%2Fzh-CN%2FEngine%2FRendering%2FLightingAndShadows%2FRayTracedDistanceFieldShadowing%2Findex.html">这里</a>。</p><h2>光线追踪提供的逆向解法</h2><p>相比之下，实时光线追踪可以营造更加真实的光照效果，它通过逆向「追踪」与假想照相机镜头（也就是玩家的「眼睛」或者观察点位置）相交的光作为工作原理，来实现对光线的实时追踪。</p><p>之所以反其道而行之，除了光沿直线传播、入射角等于反射角等基本光学原理外，更重要的原因是逆向追踪比真实地模拟光线相互作用的效率要高很多——大部分的光经过多次反射会逐渐消失，最后也不会进入眼睛。减少不必要的模拟会让最后的计算压力小很多。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/33f5ee73830bbbbb2426a829cfcd828a?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>通过逆向追踪实现的实时光线追踪</figcaption></figure><p>实时光线追踪技术最终的产物，大家或多或少早在游戏内容外也都接触过了：电影院里的好莱坞大片在特效制作过程中经常会用到光线追踪技术来生成以假乱真的特效场景，这背后往往需要以亿为单位的庞大运算量，每一帧的画面都需要高性能计算机花费数小时的运算——而这还是在提前设计好了场景和环境光线的前提下，游戏的随机性更大，实时光线追踪的实现难度自然也更高。</p><p><strong>所以该如何把光线追踪引入到游戏中呢？</strong></p><p>2018 年，英伟达发布了第一张支持光线追踪技术 RTX 20 系列显卡，RTX 20 系列中搭载了几组专门的 RT Core 来加速逆向追踪光线的过程，比起 GTX 10 系列，RT Core 在实时光线追踪这件事情上拥有更好的性能，在游戏中开启实时光线追踪后平均帧数也更高。</p><p>而 RTX 显卡发展到今天，游戏中的光线追踪也经历了多种实现方式的变迁。其中玩家感受最直观的几种按实现难度来排序分别是：</p><ul><li>阴影</li><li>高级反射</li><li>全局光照</li><li>全景光线追踪</li></ul><h3>阴影</h3><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/124e8c86e5e8d609a5df5c6a9884ecb3?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>仅阴影</figcaption></figure><p>阴影的代表游戏就是《古墓丽影》，这也是实时光线追踪最简单的实现方式。<strong>只需要确定动态光源的数量和位置</strong>就可以给游戏带去动态阴影的效果，在任何的表面和环境下都能获得逼真自然的阴影效果。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/fa6e58881a70fdbf3edc93badf45a157?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>上：未开启光追；下：开启光追，人物有了更真实的投影</figcaption></figure><h3>高级反射</h3><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/ed4fa29fa9c29c5859284a75ab48d587?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>高级反射</figcaption></figure><p>高级反射的代表游戏是《战地 5》，<strong>光线需要实时追踪场景里的所有物体</strong>才能正确精准地表现出反射效果，所以很多时候会造成很大的计算压力，因此这里往往还会引入传统的反射处理方法：屏幕空间法，只要画面中你能看到的物件不出现、被遮挡或是不可见，就不会产生反射。这也是为什么有些游戏中镜子看不见背后的人的原因。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/bb06866598e1e6144a36f52b8e934bc1?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>上：开启光追；下：未开启光追，小汽车更融入环境里了</figcaption></figure><p>在高级反射中后续还引入了，光线可以在所有表面形成反射进一步增强真实感的<strong>光线追踪不透明反射</strong>，可以在透明表面实现不同亮度反射的<strong>光线追踪透明反射</strong>，独立光源照亮周围细节或是天空的照明照亮表面的<strong>光线追踪漫反射照明</strong>等一系列细节更新。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/f58190cf9fd7bff4565c3b769097f9b2.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/8f3db1817f9e1da65fd9035124c52699.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>上：未开启光线追踪透明反射；下：开启光线追踪透明反射，窗前的反射效果更加真实</figcaption></figure><h3>全局光照</h3><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/f6abaf6db165b242611ec5287871f10a?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>全局光照</figcaption></figure><p>最复杂的实时光线追踪方式则是实现全局光照，《地铁：离去》和《控制》都利用了实时光线追踪去实现全局光照。<strong>无论是光源、反射还是投影都是实时光线追踪计算得到的</strong>，这可以进一步提高光照的准确度，更好地烘托游戏场景和氛围。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/8d2dcd9b54fc870738c7da53248ef257?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>上：未开启光追，下：开启光追；房间内的光照更为准确，给人的感受更为真实</figcaption></figure><p>全局光照后续还改善了<strong>环境光遮蔽会生成的阴影</strong>，确保每个角落和裂缝都有正确的阴影投射，从而进一步改善图像质量和沉浸感。不过实现全局光照的压力真的是太大了：在没有 RT Core 的 GTX 系列的显卡上打开《地铁：离去》的实时光线追踪，1080Ti 的表现直接从「高刷模式」掉到了「电影级画质」，帧率从 149 掉到了 38。</p><h3>全景光线追踪</h3><p>不难发现，之前提到的阴影、高级反射又或是全局光照，三者在实现上都是针对特定区域或场景内的光源追踪方式。这些实现方式只追踪一部分光源，需要处理的数据相对较少，对应的计算需求自然更低。在过去显卡光追性能较弱的时候，也可以很好地平衡画面效果和显卡价格。</p><p>而在《赛博朋克：2077》这类五光十色的游戏世界中，大量使用这类部分光线追踪方式虽然可以塑造一个充满氛围感的赛博朋克世界，但仔细观察仍然能发现光影交错中视觉上不够真实的地方，比如较远距离的建筑投影闪烁、镜面和水面的投影模糊等等。显然，覆盖范围有限的光源追踪无法完全捕获场景中所有的光线轨迹，从远距离的角度观察也一定会遗漏一些微妙的光照变化和阴影效果。</p><p>所以随着显卡性能的提升，英伟达在今年也引入了一套新的全景光线追踪实现<sup class="ss-footnote" href="" title="注：也被称为路径追踪">3</sup>。</p><p>全景光线追踪可对几乎不限数量的自发光光源的光线特性进行建模，构造出物理意义上更加精准的阴影、反射和全局照明。所以无论场景中光源的数量、方向、或强度如何变化，全景光线追踪均能准确捕捉并在各物体上造成正确的阴影及照明效果，最终提供极其精美的画面质量。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/c87009270dff5122d40cb50b175f80a9.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>不管是远景还是近景都能带来更真实的光追效果</figcaption></figure><p>另外，得益于全景光线追踪，来自天空和大气间接光照效果也可以很好得融入到整个游戏画面中。而且相比于分模块实现，整体的光追反倒可以降低开发适配成本，整合多个光源追踪方式提高性能。所以只要游戏支持，比如 2077 中的「光线追踪：超速模式」，对玩家来说游戏画面的效果一定会更好。</p><p>至此，摆在游戏光线追踪面前的就只剩下了最后一个问题：性能。正如前面提到的电影工业里的实时光线追踪十分考验计算能力一样，即便有 RT Core 这样的计算核心进行加速，在原生分辨率下开启实时光线追踪也会带来非常严重的帧率下滑；受限于成本，英伟达也不可能无限制地堆砌 RT Core 数量（不然就真的没几个人买得起了）。</p><p>有没有什么办法在不降低分辨率的情况下仍能获得稳定的帧率呢？</p><h2>让高分、高帧率成为可能</h2><p>既然高分辨率不能达到稳定的帧率，那不如先降低分辨率渲染，再用算法提升到较高的分辨率，这样不就高分辨率和稳定帧率兼得了嘛。</p><p>这其实也是目前大部分游戏机的处理 4K 画面输出的办法。但是用什么算法提升分辨率呢？很多人会想到的第一个方法可能是插值。借助插值，我们可以很轻松地将 1080P 画面提升至 4K 分辨率，但简单插值效果并不好，对游戏这种特殊的渲染内容而言，还会带来额外的锯齿。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/b9578f88c42fd9d3d96c091d8235e790?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>图片来自知乎 @一疼 ETN</figcaption></figure><p>英伟达最终选择的方案是深度学习，用算法去计算画面，即我们接下来要展开的 DLSS 技术。DLSS 全称 Deep Learning Super Sampling（深度学习超采样），它主要通过 RTX 20 系列引入的 Tensor Core 硬件来加速深度学习，来对实时渲染的图片进行非常高质量的超分辨率。</p><h3>DLSS 2</h3><p>在 RTX 30 系列发布前上线的 DLSS 2.0 对比第一代 DLSS 进一步带来了如下改进：</p><p>4 倍的实时超采样</p><p>2 倍的处理速度</p><p>通用模型</p><p>媲美甚至超越原生分辨率的画面</p><p>其中，4 倍的实时超采样足以让我们在一个极低的渲染分辨率下获得一个高分辨率超采样结果，比如游戏只需要渲染一个 540P 的画面，即可生成一个 1080P 的最终画面，大幅度减少显卡压力。加上一点新算法的「调味」，我们最后获得甚至可以超越原生 1080P 的画面。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/fb56f55c6308af7bd8eaa30681a9a4de.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>图片来自知乎 @文刀秋二</figcaption></figure><p>处理速度方面的提升，主要体现在一段时间内可以处理的帧数会更多了，搭配 4 倍的实时超采样，最后的结果就是渲染性能的暴涨以及游戏帧率的直线上升。以《控制》为例，4K 分辨率下光追效果全开（全局光照），直接把 2060 的 8 FPS 提升到了 36 FPS，让 PPT 有了可玩性，堪称魔法。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/903c4623b9b6e1afea4df77e5e9a44ed?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>图片来自知乎 @文刀秋二</figcaption></figure><p><strong>而使用通用模型</strong>可以快速在多个完全不同的场景、引擎和风格的游戏中部署 DLSS，让所有的游戏利用同一个神经网络实现高质量的超采样。</p><p>本来在游戏图形领域，性能和画质绝对是成反比的，要想要更好的画质就一定要牺牲性能。而通过 DLSS 2.0 这种鱼和熊掌兼得的技术，原生分辨率渲染输出很快就变成了过去式。<strong>超采样的画面不仅不差，反而可能会更好</strong>。</p><figure class="image ss-img-wrapper image_resized" style="width: 664px;"><img src="https://cdn.sspai.com/2023/10/12/article/c09f183f413a030b6e36e81d29ec3293?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>左：未开启 DLSS 的原生 1080P，右：开启 DLSS 的 1080P</figcaption></figure><h3>DLSS 3：不仅要高分辨率也要高帧率</h3><p>虽然大多数的电影还是 24 帧，但在游戏这一场景下，更高的帧率和更稳定的帧速率自然更好。尤其是对一些快节奏的游戏来说，高帧率也能给我们更多的时间来反应并作出更准确的操作。</p><p>因此在全景光线追踪对显卡性能提出新要求的同一时间，主攻高帧率的 DLSS 3 多帧生成技术也应运而生。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/2ceae248e16804c48347f83b92c622db.gif" /><figcaption>帧采样、帧融合与光流法</figcaption></figure><p>传统意义上的多帧生成技术分为以下 3 种：</p><ul><li>帧融合(Frame Blending)：最为基础的插帧技术，其工作原理是通过对比两个连续帧之间像素的差异，生成一帧「过渡」图像，这也是很多智能手机、电视上 MEMC 补帧功能的实现方式。这种技术比较简单，适用于简单的场景，但对于复杂的运动和细节可能处理不太好，可能会出现「模糊」的新帧。</li><li>帧采样(Frame Sampling)：一种算法更为复杂的插帧技术，它首先通过一个方式<sup class="ss-footnote" href="" title="注：可以是随机，也可以是均匀选择，或是特别的一些算法。">4</sup>挑选出一部分帧，再从这些帧生成新的、需要被插入的帧，来提高帧率。这种方法可以处理复杂的运动变化，但依赖于原始画面的质量和内容。</li><li>光流法(Optical Flow)：目前算法最为复杂的插帧技术，通过估计每个像素点在图像序列中的运动，可以生成更精确的新帧。这种技术可以处理更复杂的运动变化，它基于对光的流动进行计算，可以更准确地插值新帧的位置。但这种方法计算复杂，对硬件要求较高，且有的时候也不能达到预期的效果。</li></ul><p>然而这 3 种技术在游戏中的应用效果都不一定好，帧融合容易头晕、帧采样可能丢失重要帧，而光流法最后生成的画面不可控。</p><p>既然在生成帧结束后再插帧效果都不好，那么为什么不在生成每一帧的时候就针对性地插帧呢？DLSS 3 的帧生成技术采用的正是这种方法：<strong>在渲染游戏画面时就生成额外的帧来补齐画面</strong>。从实现原理上来说，在对画面完成 DLSS 2 的超分辨率环节以后，DLSS 3 就要开始生成额外的帧了。想要生成额外的帧需要当前游戏帧、前一游戏帧、Ada 光流加速器生成的光流场，以及游戏引擎数据（例如运动矢量和深度）——这里我打算先举一个不算特别恰当的例子辅助大家进行理解。我们可以把 DLSS 3 的所做的事情想象成我们在走路，我们会不断地根据已经走过和看到的路，大概估计下一步脚下的地面会是什么情况。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/e10e2b68d407b895f8118de39cad62d4.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>通过分析前两帧画面，DLSS 3 知道画面中的像素的运动方式</figcaption></figure><p>DLSS 3 也是如此，它会分析当前游戏帧、前一游戏帧，就像我们走路时分析之前已经脚下的路和已经走过的路一样，进而理解像素从第一帧图像到第二帧图像中间发生了什么。</p><p>不过如果只看脚下的路，那么走路不是会掉坑里就是会走歪；反映在帧生成的环节里，DLSS 只使用之前的画面来生成帧可能会导致视觉效果异常。我们的大脑会通过已经走过的路面、当前的步伐和方向、我们看到的路的情况，来决定我们接下来一步会走到哪里——要不要避开前面的坑、是不是需要停下或者改变方向。比如前面有个坑，我们就知道要避开它；前面有个台阶，我们就知道要抬高脚步。这个过程，就是我们在根据已经观察到的信息，预测下一步要发生什么，以便做出正确的反应。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/454ee7b98002c79467356b55ff9d24cf.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>DLSS 3 知道阴影部分不能借助之前的画面，需要重新渲染</figcaption></figure><p>这里游戏引擎数据所扮演的角色就像是我们的大脑：除了提前告诉 DLSS 3 一些必要的数据，DLSS 3 也会自行决定如何用上之前的帧、游戏引擎数据、光流法算法，来有的放矢地预测到每个像素在下一帧中的位置，用尽可能少的资源算出更多的画面。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/d40898c428753e3f65ade3f64d11a584.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>实际实践中，很有可能 2 帧只需要渲染第一帧的部分画面即可。大幅度解放了 GPU 的渲染能力。</figcaption></figure><p>这种级别的图像和引擎数据分析，自然也少不了显卡计算能力的加持，英伟达表示第四代 Tensor Core 推理相比于上一代最高可以提升 4 倍，加上新的光流运算单元，这也使得 DLSS 3 目前只有 RTX 支持这项功能。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/c85a2dcd60e8abf4eef4dac54718b463.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>整个 DLSS 3 的实现流程</figcaption></figure><p>不过有利自然也有弊，虽然帧生成技术可以快速产生更多的帧，但这个过程仍然需要额外的时间。所以，帧生成技术可能会导致用户输入延迟增加。简单地讲，当你在游戏中执行一个动作，这个动作的结果（例如角色的移动、环境的变化等）需要在画面中表现出来，正常情况下显卡会立即计算并生成这个结果然后展示在你的屏幕上，这个过程通常是非常快速的；但在使用当使用帧生成技术时，假设用户在第 3 帧的时候按下了一个按钮，根据第 1、2 帧以及游戏引擎数据，在用户的操作输入抵达 GPU 时，可能画面已经预先渲染到了第 4 甚至 5 帧了，真的开始渲染至少要到第 6 帧，最后就多了 3 帧延迟。这对于我们来说最直观的感觉就是不跟手，而对于竞技游戏来说额外的延迟会更加致命。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/14c1dfdcfa67624ded72f9f2a7d592e8.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>Reflex 技术的工作流程</figcaption></figure><p>英伟达在这个问题上的解决思路则很简单：尽可能降低系统延迟，也就是使用 RTX Reflex 技术。这项功能于 2020 年正式发布，但放在 DLSS 3 的环节中，RTX Reflex 可以有效降低 DLSS 3 帧生成技术带来的延迟。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/0a633af03b9884ada4656ee93b2918b8.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/badc5aa529d66ae6396e87f4429518eb.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>未启用和启用 RTX Reflex 渲染上的区别</figcaption></figure><p>RTX Reflex 的实现原理一方面是减少队列深度，以为后续输入做准备；另一方面则是就是检测到输入时，及时将命令发送到 GPU。我们依然可以用走路来举例：如果我们走在繁忙的街道上，如果提前计划好下面几步的走法（不开启 RTX Reflex 时），那么遇到情况时，比如一个人突然从旁边的小巷走出来，那你即使反应过来了也很有可能撞上那个人，因为你的脚步（GPU 渲染好的画面）已经落后于你的大脑已经做出的决定（我们的输入）。</p><p>所以正常情况下，我们的每一走出一步都会有大脑参与，并且任何突发事件都能使我们的行动即刻响应大脑的决策，无需等待之前行动的完成。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/9ccf6fc4031d0274fa0f4c1d2a2a7410.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>未启用和启用 RTX Reflex 的延迟对比</figcaption></figure><p>RTX Reflex 开启时也是如此，它会尽可能得将用户操作优先传递给 GPU，来让 GPU 生成新的画面。这样既降低了延迟，又能享受帧生成带来的更多画面。</p><h3>DLSS 3.5：为光线追踪引入深度学习</h3><p>在 DLSS 3.5 得到应用之前，光线追踪的效果生成一般是放在材质和几何体载入完毕后进行的，此时的游戏世界就像一块没有上色的画布，光线追踪根据游戏内不同类型的模型、材质，计算并模拟反射光、散射光和全局光照在画布中不同位置的呈现效果。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/7672d3d59b5c338b8cacb2d1315f42b2.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>未进行光效追踪效果渲染的游戏世界看起来是这个样子 | 图：英伟达</figcaption></figure><p>但问题在于，戏内场景千变万化、不同材质对光线的传递效果也各不相同。即便是上面提到的全景光线追踪——因为其实现方式的特殊性（由结果逆推光源和路径）——也无法保证正确判断并渲染画面中的每一个细节。</p><p><strong>因此无论是游戏还是上面提到的特效电影，都会在光线追踪效果渲染之前引入一个人为设计的、用于效果优化的降噪器</strong>。</p><p>这些降噪器以往通常采用时域累积、空间插值两种方法，比如时域累积会选择多个连续帧中质量较高的像素点进行合成，此法能有效减噪并提高像素填充效果；空间插值则是在单一帧内，通过插值相邻像素点的灰度值，产生平滑的图像效果。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/be05f1c48550848f0c7d8838b06c93c5.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>人工设计的降噪器存在诸多问题，比如因为多帧信息合成导致的倒影画质降低 | 图：英伟达</figcaption></figure><p>但无论哪种降噪方案都有其弊端，时域积累会合成不正确的画面、空间插值则会影响全局光照和反射效果……人工设计的降噪器在设计和实际应用中也有诸多难以应对实际状况的地方。</p><p>要解决这些局部细节上的「不对劲」，担任调色板和笔刷角色的降噪器就必须更加高效且更加聪明，足以在瞬息万变的游戏环境中决定画面中每个细节应该如何修改和调整。于是便有了 DLSS 3.5 <strong>光线重建</strong>（Ray Reconstruction/RR）的引入。</p><p>前面提到 DLSS 的全称是 Deep Learning Super Sampling（深度学习的超采样），9 月上线的《赛博朋克 2077》 2.0 版本更新中所搭载的 DLSS 3.5，则将这项超采样能力扩展到了提高分辨率、帧率之外——让深度学习参与光线追踪最终呈现效果的生成环节。</p><p>光线重建的核心理念在于，将光线追踪光照处理流程中的人工设计组件，改为效率更高、由深度学习驱动的 AI 模型。在大量训练素材的积累下，光线重建就像经验丰富的画家，不仅有更优质的工具，对游戏内的环境和世界也有更独特、更专业的看法和理解；他知道如何融合不同的颜色、纹理和运动，他熟知如何尽可能保留细腻的光照效果，并能善用各种手法来呈现各种光照效果。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/d686052c6518c3c401f01c5c783268c4.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/a9d0a95f998aa643634589dd8bde30ba.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>同等设置下光线重建开启前（上）与开启后（下）的画质对比，注意路面积水中的倒影清晰度、以及远处桥梁顶部的阴影细节</figcaption></figure><p>最终，在《赛博朋克 2077》的世界中，原本就已经足够惊艳的夜之城在视觉上也更能经得起眼尖玩家的鉴赏了。在我们的实际测试中，远处建筑的阴影几乎没有以往频繁出现的闪烁、跳动问题，地面倒影中的霓虹灯广告牌细节清晰可见……无论是近景还是远眺，都几乎不会发现那些原本会打破游戏世界沉浸感的小问题了。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/58b93115e89870bf6664877968db5301.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>就连车灯在路面和马路牙子上的不同照射效果都更加真实了 | 图：英伟达</figcaption></figure><p>最后值得一提的是，RTX 40 系列用户可以将光线重建与帧生成相结合，而 RTX 20 和 30 系列用户则可以将光线重建与 DLSS 或 DLAA 一同开启，也算是充分照顾到了显卡型号没那么新的玩家。如果你阔别夜之城已久，我们也在此提醒显卡型号较老的玩家们——就算全景光线追踪打开后影响游玩帧数，CDPR 也贴心的在设置里准备了只针对拍照模式开启的全景光追选项，喜欢截图的朋友不要错过。</p><p><strong>参考链接：</strong></p><ul><li><a href="https://www.nvidia.cn/geforce/news/nvidia-dlss-3-5-ray-reconstruction/">NVIDIA DLSS 3.5：借助 AI 提升光线追踪；“心灵杀手 2 (Alan Wake 2)”、“赛博朋克 2077：往日之影 (Cyberpunk 2077: Phantom Liberty)”、“传送门 RTX 版 (Portal with RTX)”等游戏将于今年秋季支持 DLSS 3.5</a></li><li><a href="https://www.nvidia.cn/geforce/news/dlss-3-5-cyberpunk-2077-phantom-liberty-available-now/">“赛博朋克 2077：往日之影 (Cyberpunk 2077：Phantom Liberty)”现已支持 NVIDIA DLSS 3.5 和全景光线追踪技术</a></li><li><a href="https://sspai.com/post/63057">升级「真香」的 RTX 30 系显卡后，你能得到什么？</a></li></ul><p>&gt; 关注 <a href="https://sspai.com/s/J71e">少数派公众号</a>，解锁全新阅读体验 📰</p><p>&gt; 实用、好用的 <a href="https://sspai.com/mall">正版软件</a>，少数派为你呈现 🚀</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://sspai.com/post/69134</id>
            <title>呼风唤雨于指尖拳心：巧用辅助功能单手操作 Apple Watch</title>
            <link>https://sspai.com/post/69134</link>
            <guid isPermaLink="false">https://sspai.com/post/69134</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 03:52:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 辅助触控手势, 双指互点两下, Apple Watch Series 9, Ultra 2
<br>
<br>
总结: 本文介绍了Apple Watch的辅助触控手势功能以及新发布的双指互点两下功能。双指互点两下是对辅助触控手势的增强和精简版本，适用于Apple Watch Series 9和Ultra 2等型号。辅助触控手势可以通过设置实现类似双指互点两下的功能，适用于较旧型号的Apple Watch。同时，辅助触控手势还提供更大的灵活度，适合希望获得更多功能或需要完整触控替代操作方案的用户。 </div>
                        <hr>
                    
                    <p><strong>注：</strong>本文原发表于 2021 年，基于当时的 Apple Watch 型号和 watchOS 版本写作。2023 年 9 月，苹果宣布为新发布的 Apple Watch Series 9 和 Ultra 2 型号增加「双指互点两下」（Double Tap）功能，其与本文所述辅助功能的差异如下表所示：</p><figure class="table"><table><tbody><tr><td><strong>功能</strong></td><td><strong>辅助触控手势</strong></td><td><strong>双指互点两下</strong></td></tr><tr><td><strong>上线时间</strong></td><td>2021 年随 watchOS 8 推出</td><td>将于 2023 年 10 月随 watchOS 10.1 推出</td></tr><tr><td><strong>适用型号</strong></td><td>Apple Watch Series 4 或后续型号</td><td>仅 Apple Watch Series 9 和 Ultra 2 或后续型号</td></tr><tr><td><strong>操作手势</strong></td><td>双指互点一或两次、握拳一或两次、重力感应光标</td><td>双指互点两下</td></tr><tr><td><strong>手势功能</strong></td><td>可在设置中自定义；此外，可以将「双指互点两下」或「握拳两次」的手势设定为「快速操作」，在各界面下实现系统预设的特定功能</td><td>系统预设的特定功能（与旧型号「快速操作」对应的功能偶有不同）；可自定义项仅包括在播放控制和智能堆栈界面的行为</td></tr><tr><td><strong>灵敏度</strong></td><td>一般，有时不能准确识别</td><td>通过分析加速计和心率传感器的数据辅助识别，效果更好</td></tr></tbody></table></figure><p>因此，「双指互点两下」可以视为「辅助触控手势」经过新机能强化、但面向主流用户且更精简的版本。<strong>在该功能推出后，本文所述的「辅助触控手势」功能仍可用于下列场景：</strong></p><ul><li>较旧型号的 Apple Watch 可以通过设置「辅助触控手势」中的「快速操作」，获得接近（但灵敏度略逊）于新型号的「双指互点两下」手势功能；</li><li>希望获得比「双指互点两下」更多功能的用户，或者因行动不便需要完整的触控替代操作方案的用户，可以继续受益于「辅助功能设置」提供的更大灵活度。</li></ul><p>因此，我们将本文重新发出并设为免费阅读，供有需要的读者继续参考。</p><hr /><h2><strong>引言</strong></h2><p style="margin-left: 0px;">作为一部手腕上的计算设备，Apple Watch 能给我们的生活带来很多方便。遗憾的是，Apple Watch 本身的操作逻辑还有很大的改进空间。</p><p style="margin-left: 0px;">例如，从初代 Apple Watch 一路用上来，我始终困惑于为什么操作手表始终需要用到<strong>两只手</strong>：你必须把佩戴手表的手腕端正抬着，用另一只手在表盘的方寸江山上指点。</p><p style="margin-left: 0px;">即使是在双手空闲的情况下，这么操作也会显得窘迫，更不要提撑雨伞、提重物这种一只手被占据的情况了。（用鼻子或者下巴点过屏幕的读者请举手。）</p><p style="margin-left: 0px;">这个问题终于在今年得到了解决——尽管是通过一种「曲线救国」的方式。在 watchOS 8 中，Apple 将多种新的「辅助功能」带到了 Apple Watch 上，其中就包括 iOS 用户熟悉的「辅助触控」。</p><p style="margin-left: 0px;">在辅助触控的帮助下，用户可以<strong>用捏指、握拳等手势代替触控操作</strong>；换言之，用一只手就可以使用 Apple Watch 上的所有功能。</p><p style="margin-left: 0px;">先来看看 Apple 的官方介绍视频：</p> <p style="margin-left: 0px;">是不是颇有些「呼风唤雨」的魔术色彩？</p><p style="margin-left: 0px;">诚然，「辅助功能」的设计初衷是方便那些有肢体不便的用户，但这并不意味着普通用户不能从中受益；从某种意义上说，「一只手被占用」本身就是一种肢体不便的情形。本文中，我们就将介绍如何利用这一新增的辅助触控功能，单手掌控 Apple Watch。</p><p style="margin-left: 0px;"><strong>注：</strong> 请注意「辅助触控」功能仅适用于 2020 年起推出的型号，即 Apple Watch Series 6 或以上，以及 Apple Watch SE。[<strong>2021-12-09 更新：</strong>watchOS 8.3 版开始，辅助触控功能也将能用于 Apple Watch Series 4 和 5。]</p><h2><strong>开启手势和基本操作</strong></h2><p style="margin-left: 0px;">启用 Apple Watch 的辅助触控功能其实只需简单几步。在 iPhone 上打开 Watch App，进入「辅助功能」&gt;「辅助触控」，然后打开「辅助触控」开关。接着，点击「手势」，再打开其中的「手势」开关。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2021/10/07/fc7149466601c580d8d9a864fae909d0.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p style="margin-left: 0px;">现在抬起手腕看向 Apple Watch，可以发现伴随着一次细微的振动，界面上第一个可点击元素的周围显示出一个边框。这表明已经完成了启用。</p><figure class="image ss-img-wrapper image_resized" style="width: 500px;"><img src="https://cdn.sspai.com/2021/10/07/5c5b167f4b7b4cdb3e4218e21211879f.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>当前焦点所在元素的周围显示出一个边框</figcaption></figure><p style="margin-left: 0px;"><strong>注：</strong> 本文中的各项设置也可以直接 Apple Watch 上通过「设置」app 完成，但考虑到在 iPhone 宽大的屏幕上操作更为方便的，本文的步骤和配图仍以 iPhone 为例。</p><p style="margin-left: 0px;">这时，我们已经可以使用手势操作 Apple Watch 了。Apple Watch 可以识别两种动作：</p><ul><li><strong>捏指</strong>（pinch），即拇指和食指快速捏合并松开（实测用拇指和其他手指捏合也可以，如果你更习惯那样的话）；</li><li><strong>握拳</strong>（clench），即五指快速握紧并松开。</li></ul><p style="margin-left: 0px;">上述动作连做两次也可以被识别，这样一共得到四种可以关联到不同操作的手势，默认设置分别为：</p><ul><li><strong>捏指一次：</strong>选中下一个元素</li><li><strong>捏指两次：</strong>返回上一层</li><li><strong>握拳一次：</strong>点选当前选中的元素</li><li><strong>握拳两次：</strong>显示「操作菜单」</li></ul><p style="margin-left: 0px;">其中，「操作菜单」是辅助触控专属的界面，类似于在 iOS 上打开「辅助触控」后，点击「小圆点」弹出的半透明菜单。通过操作菜单可以模拟各种触控手势、物理按键操作，也可以快捷唤出通知中心、控制中心等界面。</p><figure class="image ss-img-wrapper image_resized" style="width: 500px;"><img src="https://cdn.sspai.com/2021/10/07/565be4abe71888421b0cdb55b73afc7b.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>操作菜单</figcaption></figure><p style="margin-left: 0px;">如果初次使用时对于这些手势比较陌生，可以点击「手势」开关下的「了解更多」，然后在手表上通过动画向导来尝试和学习。</p><figure class="image ss-img-wrapper image_resized" style="width: 250px;"><img src="https://cdn.sspai.com/2021/10/07/dfca80243e6c9fbccf347422c617a0c1.JPEG?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><h2><strong>让手势操作更好用的设置</strong></h2><p style="margin-left: 0px;">由于辅助触控功能的本意是让肢体不便的用户也能操作手表，因此其默认设置也是优先考虑这部分群体的需求，以便于操作、通用型强为导向，操作效率则不是首要目标。对于本文这类只需要用辅助功能补充（而非代替）普通触控的使用场景，默认设置就显得不太实用。</p><p style="margin-left: 0px;">好在 Apple 提供了丰富的自定义选项，只要稍花时间思考和调整，就能极大强化辅助触控的快捷程度。</p><p style="margin-left: 0px;">首先要调整的是四种手势的<strong>功能映射</strong>。在「手势」设置页中点击各个手势的名称，就能为其指定不同的功能，其中既包括上下高亮菜单项、点击、按下数字表冠这类模拟真实触控的功能，也包括打开通知中心、控制中心、程序坞（Dock）和唤出 Siri 等「一键直达」类功能。</p><p style="margin-left: 0px;">例如，我自己经过尝试，将「点选当前选中项」这常用操作，映射到了更便于完成的「捏指两次」手势上，而将「握拳一次」改为模拟按下数字表冠。这不仅方便快速回到表盘界面，在我看来也更易于记忆，因为「握拳」和按键都是需要用力、表示某种确定性的操作。至于「握拳两次」这个相对最「费力」的手势，我则保留了打开「操作菜单」的默认设置，这也与其相对较低的使用频率相称。</p><p style="margin-left: 0px;">除了自定义手势，「手势」设置页还有两个可以调整的选项：</p><ul><li><strong>启用手势：</strong>默认为「无」。如果启用，则每次抬腕后需要先做一次在此设置的手势，然后才能用其他手势操作手表。这某种程度上可以起到防止误操作的效果。但考虑到抬腕亮屏本身就是前置性的，再增加一层确认操作的意义不大，不建议开启。</li><li><strong>快速操作：</strong>是指在各类界面中允许通过「握拳两次」的手势直接点选一个常用选项，而无论该手势原本被设为什么操作。例如，在来电界面，握拳两次可以直接接听；在短信通知界面，握拳两次可以向下滚动预览等。这是一个比较方便的设计，建议开启。</li></ul><p style="margin-left: 0px;">回到上一级「辅助触控」设置页，这里可以对辅助触控的功能和外观做一进步调整。下面介绍一些比较实用的选项及其适用场景。</p><p style="margin-left: 0px;"><strong>自动滚动菜单项：</strong>辅助触控中，一般需要通过手势（例如默认的捏指一次）逐项滚动到所需的界面元素，然后通过确认手势点选。但在界面元素较多的情况下，逐个切换就会显得较为繁琐。这时，可以将「扫描样式」从默认的「手动」改为「自动」，这样屏幕中可用的操作会陆续自动高亮显示（滚动到最后一项时，则会调头从后往前自动选中）。</p><p style="margin-left: 0px;">遗憾的是，根据我的测试，在启用自动滚动时，手势操作似乎变得不那么灵敏；即使将滚动速度降到很低，也经常来不及在跳到下一项之前的间隙完成并识别点选手势。因此，我还是选择关闭了自动滚动。</p><p style="margin-left: 0px;"><strong>自定义功能菜单：</strong> 如上文介绍，功能菜单的选项非常丰富，但普通用户需要用到的只是其中少数，并且较为实用的控制中心、通知中心等选项还处于偏后位置，选择起来很麻烦。对此，可以进入「自定义功能菜单」页面，挑选至多三种常用操作作为「个人收藏」。这些操作将被固定在功能菜单的最前面，调用起来就快多了。</p><figure class="image ss-img-wrapper image_resized" style="width: 250px;"><img src="https://cdn.sspai.com/2021/10/07/bec148c0de77d00593b54a44d1701df1.PNG?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p style="margin-left: 0px;">此外，在这个设置页面还可以选择功能菜单的显示位置、尺寸和自动滚动速度（独立于上述「自动滚动菜单项」设置）。</p><p style="margin-left: 0px;"><strong>让高亮框更醒目：</strong>默认情况下，标识当前选中项的高亮框是比较「苗条」的，并且会自动适配所选元素的形状和颜色。例如，在彩色表盘上，高亮框会显示为与表盘底色相同的颜色。这是比较美观的，不会让高亮框过分突兀，但在户外走动等视线无法聚焦的场合，可能也会让高亮项目不太容易辨别。</p><p style="margin-left: 0px;">对此，可以打开「高对比度」选项，让高亮框的周围再包裹一层醒目的白框；并在「颜色」菜单中为其指定一个固定、不随所选项而变动的颜色。</p><p style="margin-left: 0px;"><strong>仅靠单手完成 Apple Pay 支付：</strong> 在 Apple Watch 上进行一些特殊操作，例如使用 Apple Pay 付款、在绑定的 Mac 上确认鉴权操作时，一般需要连按两次侧边按键来确认。考虑到这类操作的敏感性，辅助触控功能默认不能模拟这个操作。打开「通过辅助触控确认」选项就可以绕过这一限制。</p><h2><strong>用动作指针精准操作</strong></h2><p style="margin-left: 0px;">通过辅助触控手势，我们已经可以仅靠单手完成很多日常操作。不过，手势操作仍然存在一些限制：</p><ul><li><strong>手势数量是有限的。</strong>辅助触控只能设置 4 种不同手势，其他功能只能通过「操作菜单」来</li><li><strong>手势操作有时较为繁琐。</strong>对于那些部件数量很多的表盘、列表很长的 app 界面（例如「天气」app 的逐日预报），用手势逐项定位和操作就很浪费时间，在公众场合可能还有些尴尬。</li></ul><p style="margin-left: 0px;">要是有一个「鼠标」的功能，可以指哪打哪，就会方便得多了。</p><p style="margin-left: 0px;">好消息是，这样的「鼠标」还真的存在，它在 watchOS 中的名字叫「动作指针」。</p><p style="margin-left: 0px;">动作指针是辅助触控的一部分，但默认情况下藏得很深，需要在手表上唤出「操作菜单」，然后通过「交互」&gt;「动作指针」显示出来。</p><p style="margin-left: 0px;">但这显然太麻烦了。其实，动作指针可以通过晃动手腕开启，方法是进入「辅助触控」&gt;「动作指针」&gt;「停留控制」（Dwell Control），打开「停留控制」和「摇动以开始」两个开关，并将「计时器操作」选择为「轻点动作位置」。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2021/10/07/a35c80da114227a6cd048e822de6d3d6.JPEG?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p style="margin-left: 0px;">设置好之后，界面上会显示一个灰底的小圆球。熟悉 iPadOS 的朋友可能还记得这个形状——在 iPad 尚未正式支持光标操作的时代，很多用户正是通过「辅助触控」功能间接开启外接鼠标支持的，而当时显示的指针正是同样的形状。</p><figure class="image ss-img-wrapper image_resized" style="width: 500px;"><img src="https://cdn.sspai.com/2021/10/07/cf138419522351d7c803ba08e6824d63.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>动作指针</figcaption></figure><p style="margin-left: 0px;">动作指针的操作方式也颇有趣味：通过重力感应实现，手腕往哪个方向偏，指针就往哪个方向移动。如果停止活动手腕，指针外沿会出现一个进度圈；一旦转满，就会在当前位置模拟一次点击操作。（如果在之前启用步骤中，将动作指针的「计时器操作」选择「操作菜单」而非「轻点动作位置」，则每次进度圈转满后，将会弹出菜单要求选择模拟轻点还是滚动等操作；这对普通用户意义不大。）</p><p style="margin-left: 0px;">动作指针的功能也不限于定位和点击，还可以通过在边缘上悬停来触发特定功能——有点类似于 Mac 上的「触发角」，同样可以在「动作指针」设置页看到对应设置。</p><p style="margin-left: 0px;">默认情况下，上下左右四个触发边缘的功能是模拟向相应方向滚动屏幕。但如上所述，由于本文语境下的辅助功能只是为了方便操作，而不是完全代替触控，这里不妨将触发边缘替换为更为实用的功能。例如我的设置方式是：</p><ul><li>上边缘：通知中心</li><li>下边缘：控制中心</li><li>左边缘：打开「操作菜单」</li><li>右边缘：打开程序坞（Dock）</li></ul><p style="margin-left: 0px;">最后，「动作指针」设置界面还可以调节指针的灵敏度（即倾斜手腕时指针的移动幅度）和启用时间（即触发操作需要悬停的时间）。我尝试后感觉各自<strong>比默认设置调低 1—2 挡</strong>比较好用，谨供参考。</p><hr /><p style="margin-left: 0px;"><strong>延伸阅读</strong></p><ul><li>Apple Watch 官方使用说明：<a href="https://support.apple.com/zh-cn/guide/watch/apdec70bfd2d/watchos" target="_blank">在 Apple Watch 上使用辅助触控</a></li><li>Apple 新闻稿：<a href="https://www.apple.com.cn/newsroom/2021/05/apple-previews-powerful-software-updates-designed-for-people-with-disabilities/" target="_blank">Apple 展示为残障人士设计的强大软件更新</a></li></ul>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://sspai.com/post/83511</id>
            <title>派早报：高通公布骁龙 X 芯片、网页版 Illustrator 开放公测等</title>
            <link>https://sspai.com/post/83511</link>
            <guid isPermaLink="false">https://sspai.com/post/83511</guid>
            <pubDate></pubDate>
            <updated>Thu, 12 Oct 2023 00:44:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 高通公司, 骁龙 X 系列芯片, PC, AI
<br>
<br>
总结: 高通公司公布了面向 PC 的骁龙 X 系列芯片，该芯片利用了高通在 CPU、GPU 和 NPU 领域的经验，并且提供了针对生成式 AI 的加速功能。
 </div>
                        <hr>
                    
                    <h2>你可能错过的新鲜事</h2><h3>高通公布面向 PC 的骁龙 X 系列芯片</h3><p>10 月 10 日，高通公司公布了面向 PC 的骁龙 X 系列芯片。高通方面表示，骁龙 X 基于高通多年来在 CPU、GPU 和 NPU 领域的异构计算经验构建，并且利用了新一代高通 Oryon CPU 的卓越性能，骁龙 X 的 NPU 还将针对生成式 AI 提供加速。首款骁龙 X 芯片会 2023 骁龙峰会上正式发布，该活动将于 10月24 至 26 日在夏威夷举行。<a href="https://www.expreview.com/90443.html">来源</a></p><h3>网页版 Adobe Illustrator 开放公测</h3><p>10 月 10 日，Adobe 公司在 MAX 大会上宣布，网页端 Beta 版 Illustrator 正式开启公测，用户已经可以创建、编辑和分享 llustrator 云文档（.aic）。同时，Adobe 还上线了 Beta 版的 Text to Vector Graphic、Retype 和 Mockup 三项新功能。其中，Text to Vector Graphic 功能基于 Adobe Firefly，可以通过描述主题或视觉效果来生成相关的矢量图形和插图；Retype 可以识别 Adobe Fonts 上的相似字体，快速将导入 Illustrator 的静态光栅化文本或轮廓转换为可编辑文本；Mockup 则可以直接在 Illustrator 中快速轻松地预览图形的「真实」应用程序模型。<a href="https://helpx.adobe.com/illustrator/web/illustrator-on-the-web-overview.html">来源</a></p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/article/78a179891740eb3419f76fe0cc70d54f?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>产品特性概述，网页截取自 Adobe</figcaption></figure><h3>微软将结束多项服务支持</h3><h4>微软将在 Windows 中弃用 VBScript</h4><p>近日，微软公司<a href="https://learn.microsoft.com/en-us/windows/whats-new/deprecated-features">更新了 Windows 系统说明文档</a>，在「弃用功能」一章中表示，计划在未来的 Windows 版本中弃用 VBScript。微软将首先在 Internet Explorer 内移除 VBScript，之后将作为可选组件供有需要的用户安装。VBScript 曾被大量的系统管理员用于完成各种自动化任务，但这些工作目前可以通过 PowerShell 实现。此外，VBScript 日益严重的安全问题也可能是微软考虑弃用的重要原因。<a href="https://www.oschina.net/news/261322/microsoft-deprecated-vbscript-in-window">来源</a></p><h4>微软结束对于 Windows 11 21H2 版本的支持</h4><p>10 月 10 日，微软公司正式结束对首个 Windows 11（Windows 11 21H2）版本的支持，其中包括 Windows 11 家庭版、家庭中国版、专业版、专业工作站版和专业教育版，未来该版本将不会收到月度安全和质量更新。</p><p>不过，Windows 11 21H2 的企业版、企业教育版、IoT 企业版和企业多会话版将在 2024 年 10 月 8 日结束支持。用户可以尽快升级到 Windows 11 22H2 或者近期发布的 Windows 11 23H2 来保障系统继续获得服务支持。<a href="https://www.neowin.net/news/windows-11-version-21h2-is-no-longer-supported/">来源</a></p><h3>Valve 确认《反恐精英2》不支持 macOS</h3><p>近日，游戏开发商 Valve 推出了《反恐精英 2》（CS 2），但游戏仅提供了 Windows 和 Linux 版本，对此 Valve 在一份声明中表示，由于上一代游戏《CS:GO》的 macOS 玩家仅占全部玩家总数的 1%，因此他们决定《反恐精英2》不推出 macOS 版本。</p><p>目前 macOS 用户可以继续玩《CS:GO》，但对《CS:GO》的支持将于 2024 年 1 月 1 日结束。符合资格的 macOS 玩家可以申请 Prime Status Upgrade 退款。Valve 将在 12 月 1 日前允许玩家申请退款。<a href="https://www.solidot.org/story?sid=76299">来源</a></p><h3>《星露谷物语》将举办全球音乐会</h3><p>近日，知名游戏《星露谷物语》上线了<a href="https://www.stardewvalleyconcert.com/" target="_blank">「季节庆典」（Festival of Seasons）全球音乐会巡演页面</a>。据页面介绍，本次巡演将在美国、英国、加拿大、澳大利亚等地展开，演出从 2024 年 2 月正式开始，10 月起已可以预订门票。「季节庆典」将由交响乐团现场演奏《星露谷物语》中的经典配乐，让听众在现实世界中感受《星露谷物语》的四季。<a href="https://www.stardewvalleyconcert.com/" target="_blank">来源</a></p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/10/12/1811508c6d5299f2f86dfa0823a7100d.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>目前已公布的巡演目的地及开票时间，图片截取自网页</figcaption></figure><h2>少数派的近期动态</h2><ul><li>国庆去了哪儿，留下了哪些回忆？用一张照片为夏天的尾巴做个「总结」！<a href="https://s.weibo.com/weibo?q=%23%E8%BF%99%E4%B8%AA%E5%A4%8F%E5%A4%A9%E6%88%91%E5%9C%A8%E8%BF%99%23" target="_blank">#这个夏天我在这#</a> 照片征集活动仍在进行，每周都有「出行礼包」送出。<a href="https://weibo.com/u/1914010467" target="_blank"><strong>微博参与</strong></a></li><li>《iOS 蓝皮书》已开启年度更新，内容适配 iOS 17，首发加入少数派会员。年度会员可<a href="https://sspai.com/series/277"><strong>直接畅读</strong></a></li><li>不能说走就走，但想去哪儿就去哪儿总是可以的！规划、路线、必备好物、心得经验、踩雷避坑……分享你的自驾游故事和心得。<a href="https://sspai.com/bullet/1695717562"><strong>参与讨论</strong></a></li></ul><h2>你可能错过的好文章</h2><ul><li><a href="https://sspai.com/prime/story/zhuanglesha-231011">少数派健身类选题人气作者「举铁的马里奥」都装了啥？</a></li><li><a href="https://sspai.com/post/83501">具透 | 喜欢 Android 14 的 14 个理由（少数派版本）</a></li><li><a href="https://sspai.com/post/83488">返璞归真，又迎一春：小评《刺客信条：幻景》</a></li><li><a href="https://sspai.com/post/83487">用开源项目，你也能训练自己的 AI 语音模型</a></li></ul><p>&gt; 关注 <a href="https://sspai.com/s/J71e">少数派公众号</a>，解锁全新阅读体验 📰</p><p>&gt; 实用、好用的 <a href="https://sspai.com/mall">正版软件</a>，少数派为你呈现 🚀</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://sspai.com/post/83501</id>
            <title>具透 | 喜欢 Android 14 的 14 个理由（少数派版本）</title>
            <link>https://sspai.com/post/83501</link>
            <guid isPermaLink="false">https://sspai.com/post/83501</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 09:36:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Android 14, Pixel 8 系列发布, AI 壁纸生成, 锁屏时钟样式, 黑白风格主题
<br>
<br>
总结: Android 14 正式版于 Pixel 8 系列发布当天发布，其中包含了 AI 壁纸生成、锁屏时钟样式、黑白风格主题等特性。这些特性可能只有 Pixel 用户才能体验到。对于非 Pixel 机型的用户来说，Android 14 带来了更强大的照片格式，包括对 10bit HDR 图像的原生支持和新的 Ultra HDR 图像格式。此外，Android 14 还引入了更规范的照片选取机制，让用户可以方便地选择可见媒体文件。 </div>
                        <hr>
                    
                    <p>和去年 8 月中旬发布的 Android 13 正式版不同，今年的 Android 14 正式版延后到了 10 月 4 日——也就是 <a href="https://sspai.com/post/83366">Pixel 8 系列发布</a>的同一天。原因我们似乎也能从 Google 宣传新特性中略窥一二：</p><p>除了明确表示会率先向特定 Pixel 机型推送的 AI 壁纸生成，因为 OEM 厂商一般都会在系统界面、配色方案上搞「二创」，所以 Android 14 官方页面所宣传的锁屏时钟样式、黑白风格主题等特性，最后也极有可能只有 Pixel 用户才能体验到。</p><figure class="image ss-img-wrapper"><img alt="OzyubLuQ9oeTJFxmNavcS9R6nIg" src="https://cdn.sspai.com/editor/u_/ckj6ktlb34tcsee9i81g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>Android 14 的 14 个新特性 | 图：Google</figcaption></figure><p>那 Android 14 能为非 Pixel 机型的用户带来什么？参考 Google 的官方<a href="https://www.youtube.com/watch?v=wEVaHobjbPw">介绍视频</a>，我们也从相关文档中整理了一份 Android 14 值得更新的 14 项新特性供你参考。</p><p>注：本文较长，部分内容沿用往期具透，可能会有重复，请善用目录浏览。</p><h2>更强大的照片格式</h2><blockquote><p>超强 HDR 图像格式！（来自谷歌开发者官方微信公众号的翻译）</p></blockquote><p>从 MIUI 相册的 HDR 显示到 OPPO 新近机型的 ProXDR，Android 在 HDR 照片显示这件事情上今年又上演了一次「厂商倒逼 Google」的戏码。在 Android 14 中，Google 终于为我们带来了对 10bit HDR 图像的原生支持，并且还一并推出了新的 Ultra HDR 图像格式。</p><p>根据 Google 的介绍，Ultra HDR 图像格式在保存时会保留来自传感器的更多信息，并在查看时展示更鲜艳的色彩、更高的动态范围和更强烈的对比度，简单来说就是小部分国产厂商近几年在卷的那种 HDR 照片显示效果。值得一提的是 Ultra HDR 格式可以完全向后兼容 JPEG 图像格式，它不仅能在 Google 相册等支持 HDR UI 的应用中被正确解码，在未适配 HDR 或不支持 HDR 显示的设备上，Ultra HDR 格式图像也能回落至标准动态范围（SDR）来正常显示。</p><figure class="image ss-img-wrapper"><img alt="UjbpbXI53oZj2vx4JzFcVfctnNf" src="https://cdn.sspai.com/editor/u_/ckj6kttb34tcs84s7ghg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>演示效果，仅供参考 | 图：Google</figcaption></figure><p>针对 Pixel 系列机型的 HDR 照片支持目前也是蓄势待发，刚发布不久的 <a href="https://sspai.com/post/83366">Pixel 8 系列</a>的相机应用已经内置了拍摄选项，开启该选项后所拍摄的 Ultra HDR 格式照片能够在 Google 相册中以 HDR 效果进行查看，同时 Lightroom 移动版也在最新的 9.0 版本针对 Pixel 7 系列和 Android 14 带来了 HDR 编辑与导出支持。</p><figure class="image ss-img-wrapper"><img alt="IN9ObcQpIoyg4mxMM4yc0P0jnib" src="https://cdn.sspai.com/editor/u_/ckj6ku5b34tcsee9i820?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>Pixel 新版相机应用中的 Ultra HDR 拍摄选项以及相册中的 Ultra HDR 标识</figcaption></figure><p>总体而言 HDR 照片对大家来说依然是一个陌生的新生态，比如尽管我很想放上几张对比图给大家看看效果——咱们的编辑器和网页都不允许。</p><p>另外 Android 14 也为 Camera2 和 CameraX 等<a href="https://developer.android.com/training/camera/camera-extensions">相机扩展组件</a>带来了更新，允许第三方应用支持更长的照片处理时间、调用系统相机的算法密集型拍照功能（如暗光拍摄能力）等，这类面向开发者（并且不会有多少国内应用适配）的细节这里就不展开了。</p><h2>更规范的照片选取</h2><blockquote><p>好吧，至少从某种程度上来说是这样的。</p></blockquote><p>从某种程度上来说，Google 正在强制推行自 Android 13 引入的照片选择器。对用户而言这当然是需要重点关注的头等好事。</p><p>简单来说，和此前需要开发者适配、需要 Google Play 服务更新支持的做法不同，<strong>Android 14 直接引入了一个让用户为 app 选择可见媒体文件的「中间层」，这个「中间层」用的正是照片选择器同样的设计</strong>：一个从底部弹出的照片和视频选择面板，内含支持多选和长按预览的「照片」（其实也可以选择视频）和可以按照路径位置查找媒体文件的「影集」两个页面。</p><figure class="image ss-img-wrapper"><img alt="Dlz0bvOtnoCufRxy5E7cRSfgnGm" src="https://cdn.sspai.com/editor/u_/ckj6kutb34tcscgatpn0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>通过照片选择器选择应用可访问的照片和视频</figcaption></figure><p>在 Android 13 引入照片选择器这一设计后，Android 14 又新增了类似 iOS 那样的媒体文件范围选取机制，这套机制在 Android 14 中对应的权限是 <a href="https://developer.android.com/reference/android/Manifest.permission#READ_MEDIA_VISUAL_USER_SELECTED"><code>READ_MEDIA_VISUAL_USER_SELECTED</code></a>。</p><p><strong>这个权限和以往大部分新系统、新权限最大的不同点，在于它是由系统自动附加的。</strong>只要应用请求 <a href="https://developer.android.com/reference/android/Manifest.permission#READ_MEDIA_IMAGES"><code>READ_MEDIA_IMAGES</code></a>、<a href="https://developer.android.com/reference/android/Manifest.permission#READ_MEDIA_VIDEO"><code>READ_MEDIA_VIDEO</code></a> 或 <a href="https://developer.android.com/reference/android/Manifest.permission#ACCESS_MEDIA_LOCATION"><code>ACCESS_MEDIA_LOCATION</code></a> 三类权限的任意一种，无论应用是否面向 Android 14 进行适配，<a href="https://developer.android.com/reference/android/Manifest.permission#READ_MEDIA_VISUAL_USER_SELECTED"><code>READ_MEDIA_VISUAL_USER_SELECTED</code></a> 这一权限都会被自动添加到应用的声明清单中。</p><p>从我们的实际体验来看，市面上主流的、已经适配了 Android 13 媒体权限（即将<code>音乐和音频</code>、<code>照片和视频</code>两类权限分开授予）的应用，在 Android 14 中访问照片和视频权限时的确都会先调起 Google 的照片选择器——先让用户选择应用可以访问的内容，然后应用内置的媒体选择器才能将已授权的内容展示出来。并且这种授予也是临时的，一旦应用被放进后台或进程被用户结束，下次启动时相关的授予流程就还会再出现一次。</p><figure class="image ss-img-wrapper"><img alt="DKvdb6l9VoQknAxeUNWc477DnUf" src="https://cdn.sspai.com/editor/u_/ckj6kvtb34tcsee9i82g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>Android 14 的照片范围选择权限处理流程</figcaption></figure><p>如此一来这套新权限的局限性（虽然是暂时的）也很明显了：依然有少部分应用获得了调用照片选择器的豁免权，最具代表性的比如目标 API 级别为 32、依然面向 Android 12 进行适配的「小而美」。</p><p>我知道你想说什么但先别急，我们在上面也提到「强制」和「暂时」，是因为根据 Google Play 商店的<a href="https://support.google.com/googleplay/android-developer/answer/11926878?hl=zh-Hans">目标 API 级别要求</a>，2023 年 8 月 31 日起所有提交至商店的应用更新都必须面向 Android 13 进行适配，虽然 Google 允许开发者申请延期至 11 月 1 日，但微信在 Play 商店的最后一次更新恰好是 8 月 24 日……张小龙会如何应对我们拭目以待。</p><figure class="image ss-img-wrapper"><img alt="SHQpbGB3Ioj3lhxaAN6crPzwndf" src="https://cdn.sspai.com/editor/u_/ckj6kvtb34tcscgatpng?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>Google Play 商店的目标 API 级别要求</figcaption></figure><p>当然了，Google 也还是希望开发者都用标准化的照片管理器实现，毕竟视觉风格上与系统更搭。适配过的应用即便依然选择使用自己的媒体选择器实现方式，它们在 Android 14 中也能借助界面和操作提示引导用户重新选取更多媒体文件。</p><figure class="image ss-img-wrapper"><img alt="Cnccb6K7Oo8mhKxvCqVcxlnJnNc" src="https://cdn.sspai.com/editor/u_/ckj6l05b34tcsee9i830?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>已适配 Android 14 部分的应用可引导用户选择更多媒体文件</figcaption></figure><p><strong>扩展阅读：</strong><a href="https://sspai.com/prime/story/android-mediastore-explained">谁来管管 Android 的照片选择器 ｜ 少数派会员 π+Prime</a></p><h2>更省电的缓存机制</h2><blockquote><p>每次更新之后他们都这么说，这次是不是真的？</p></blockquote><p>尽管我一直坚持是因为天气转凉，升级到 Android 14 之后，的确有不少手持 Google Tensor 处理器设备的朋友向我表示手机更凉爽、续航也更长了（除了我的同事，<a href="https://www.androidpolice.com/android-14-fixes-heat-battery-issues-pixel-7-6-report/">外媒</a>也这么说）。</p><p>那暂且将功劳归于 Android 14 开始生效的缓存应用冻结机制吧。</p><p>缓存，即将前台运行的应用放进内存，和直接杀掉进程不同，缓存的应用调用起来更快、重新开启所需要消耗的资源相比冷启动也更少。所以将暂时不用的应用放进缓存是一种非常合理的做法，Google 将「暂停执行已缓存的应用」放进 Android 系统的「开发者选项」后，这个功能也一直以「Android 的墓碑后台机制」的身份备受玩机群体的推崇。</p><figure class="image ss-img-wrapper image_resized" style="width: 450px;"><img alt="EXaybAxJWowNK4xXzyRcQxTqnob" src="https://cdn.sspai.com/editor/u_/ckj6l0lb34tcsa71k0fg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>暂停执行已缓存的应用设置</figcaption></figure><p>根据 Google 公开的数据，被暂停执行的已缓存应用在 Android 14 测试版中消耗的 CPU 周期要比 Android 13 正式版少 50%，因此在 Android 14 中这一机制得到「转正」，以往缓存的应用可以基本不受限制地运行，但在 Android 14 上这些应用在进入缓存后很短的时间内就会被系统冻结，直接杜绝其 CPU 资源调用。</p><p>不知道是不是已经知道了此前「暂停执行已缓存应用」机制的<a href="https://blog.xzr.moe/archives/190/">问题</a>，这次 Google 也特别提到冻结仅适用于常规的 Android 应用生命周期 API（如前台服务、JobScheduler 或 WorkManager）之外的后台工作。</p><p>另外值得一提的是，随着缓存机制的优化，Android 14 也打破了平台缓存应用数量的长期限制，减少了冷启动应用的情况，而且设备 RAM 越大改善就越明显：在 8GB 内存的设备上冷启动应用速度提高了 20%，在 12GB 内存的设备上则提高了 30%。</p><h2>更无感的登录体验</h2><p>和刚发布不久的 Windows 11 Moment 4 更新一样，Android 14 也是首个系统级支持通行密钥（Passkey）的版本。Android 14 在平台 API 中引入了凭据管理器（Credential Manager），并且通过 Jetpack 开发库和 Google Play 服务，让该功能可以一直向下支持到 Android 4.4（API 级别 19）的老设备。</p><figure class="image ss-img-wrapper"><img alt="DFlYbSDmYo2kWHxFOTjcwwFznhf" src="https://cdn.sspai.com/editor/u_/ckj6l0tb34tcscgatpo0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>使用通行密钥登录的流程演示 | 图：Google</figcaption></figure><p>凭据管理器用于简化用户认证流程，并且主要通过通行密钥（Passkey）来提高安全性——少数派的读者对通行密钥应该不陌生了。</p><p><strong>关联阅读：</strong></p><ul><li><a href="https://sspai.com/post/77376">无密码、更安全的未来，你该如何登录？通行密钥上手体验</a></li><li><a href="https://sspai.com/post/73937">不用密码但不能代替密码：通行密钥如何让登录这件事更简单？</a></li></ul><p>目前我们在 Android 14 的密码和帐号设置中可以看到通行密钥认证服务的相关设置，换句话说除了可以将手机上的生物识别信息作为通行密钥认证方式，Android 14 也支持添加第三方应用作为通行密钥管理应用。</p><figure class="image ss-img-wrapper image_resized" style="width: 450px;"><img alt="AOblbCqLXo2VW1xVsu7c59BRn0b" src="https://cdn.sspai.com/editor/u_/ckj6l15b34tcsee9i83g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>Android 14 中的通行密钥管理服务设置</figcaption></figure><p>不过虽然 1Password 早前<a href="https://www.reddit.com/r/1Password/comments/13dzc7w/passkeys_are_coming_to_1password_for_android_soon/">宣布过</a>对 Android 14 通行密钥管理的功能支持，但在最新的 Beta 测试版本中我们还无法成功调用 1Password 来创建通行密钥。</p><h2>更好看的返回动画</h2><blockquote><p>但「预见式返回动画」竟然还在「开发者选项」里。</p></blockquote><p>我们在《<a href="https://sspai.com/prime/story/android-ios-back-gestures">都是边缘划动，Android 与 iOS 的返回手势到底有什么区别？</a>》这篇会员文章中提到过 Google 提出的一个、有关 Android 系统返回的问题，即我们很多时候都不太确定返回操作会将自己带向何方。</p><p>为此 Android 13 提出了「预见式返回动画」这个解决方案，即通过一个类似「半确定」状态的动画预览，告知我们接下来会被带到哪里去——如果目的地非你所愿，那可能你就得取消返回操作、在当前界面中找找其他导航按键了（比如「向上」）。</p><p>两年过去了，这个特性准备得怎么样了？<strong>坏消息是它依然放在「开发者选项」里，好消息是它的确更完善了</strong>。</p><figure class="image ss-img-wrapper"><img alt="T64nbPyiuolXpExxOyRcdQXEn6e" src="https://cdn.sspai.com/editor/u_/ckj6l1db34tcs84s7gi0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>预见式返回动画效果</figcaption></figure><p>除了给返回箭头添加一个圆圆的、形状可变、颜色为 Material You 动态取色得背景之外，Android 14 正式版当中默认的预见式返回动画效果更自然、表现也更加稳定。同时 Google 也在 Android 14 中支持了自定义预见式返回手势动画的能力，允许开发者为应用中不同组件和不同界面的跳转加上更加赏心悦目的动画，官方 Material Design 组件库中也提供的底部菜单、侧栏菜单和搜索三种组件的返回动画供开发者参考、适配。</p><figure class="image ss-img-wrapper image_resized" style="width: 645px;"><img alt="OlzsbT68hoSAExx3hurciawqnhf" src="https://cdn.sspai.com/editor/u_/ckj6l1tb34tcsa71k0g0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>底部菜单（Bottom Sheet）的预见式返回动画</figcaption></figure><p style="text-align: center;">&nbsp;</p><h2>更好的多语言支持</h2><blockquote><p>简体中文除外。</p></blockquote><p>和 MIUI 这类完全不管多语言支持的做法不同，Google 在原生 Android 的多语言支持上走的是另一个极端：完全不管除了简体中文以外的多语言支持——比起在 AOSP 提交中否决支持文字体可变字重支持的冷酷，今年 Android 14 引入的多语言支持可谓相当温暖：</p><p>比如针对特定语言中的语法性别现象的词形变化 API，用 Google 所举的例子来说，比如当我们的应用界面中需要显示「你已订阅……」这句提示语时，中文和英文状态下都是无需注意语法性别的，但如果是法语，这句话则可能对应三种情况：</p><ul><li>Vous êtes abonné à...</li><li>Vous êtes abonnée à...</li><li>Abonnement à...activé</li></ul><p>词形变化 API 就是用来简化并解决这类问题的。根据 Google 的描述，这个 API 能够帮助开发者根据使用者的性别展示对应的语法性别文本，降低这类需求带来的开发成本，避免应用在采用特定语言显示时因为忽略语法性别而冒犯用户。</p><p>再比如区域偏好设置。我们或多或少都在天气应用、测量工具、量化 app 中接触过与地区偏好相关的设定，从温度、距离、长度采用哪种单位、日期显示采用年月日还是日月年到每周的第一天究竟是周日还是周一……以往这类设置往往都散落在不同应用的设置当中，Android 14 则在「系统 &gt; 语言和输入法」中新增了一项面为「区域偏好设置」的独立页面，一方面方便用户提前选好自己想要的温度单位、每周起始日以及数字呈现方式，另一方面也配套为开发者提供了对应 API 和 Intent 来读取这些偏好设置，然后直接套用到应用当中。</p><figure class="image ss-img-wrapper image_resized" style="width: 450px;"><img alt="VLpYbKgLhogBOux2TIpctPzrnZj" src="https://cdn.sspai.com/editor/u_/ckj6l2db34tcscgatpog?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>Android 14 中的地区偏好设置</figcaption></figure><p>根据 Google 给出的信息，这些偏好设置也能够在设备数据备份、还原的过程中在不同设备间迁移。</p><p>最后，针对 Android 13 引入的应用语言偏好设定，Android 14 也向输入法开放了应用语言的获取接口，让输入法能够根据不同应用的不同语言设定，自动弹出对应的输入键盘。</p><h2>更聪明的分享菜单</h2><blockquote><p>造轮子造出的新思路。</p></blockquote><p>当你在 Chrome 浏览器中点击「分享」按钮时，首先弹出的菜单是 Chrome 自行定制的分享菜单，这个分享菜单下方提供了包括屏幕截图、网页长截图、URL 链接复制等功能在内的六个分享操作——和 Android 系统的原生分享菜单（上图中点击「展开」后即是）不同，Chrome 在定制分享菜单中所提供的这些操作选项与我们的网页分享行为关联更加密切，或者说往往也是我们在浏览网页时主要考虑的一些操作。</p><figure class="image ss-img-wrapper image_resized" style="width: 450px;"><img alt="Vr8Nbnmgco2s66xzdIncoYkjnsh" src="https://cdn.sspai.com/editor/u_/ckj6l2lb34tcsa71k0gg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>Chrome 浏览器的定制分享菜单</figcaption></figure><p>作为规则制定者的 Google 在自家 Chrome、Google 相册中都采用「自己造轮子」的方式设计一个独立的分享菜单，正好也能说明 Android 系统原生分享菜单存在一个大问题：太公平了。无论分享的内容是什么，Android 系统都会在长长的分享菜单中将提供分享操作的应用按照名称排序，找起来不方便、有的分享操作和实际分享内容的关联性也比较差。</p><p>因此在 Android 14 中，Google 基于 Chrome 和 Google 相册的分享菜单设计思路，向应用开放了分享菜单自定义操作定制功能，允许开发者针对特定文件类型声明分享自定义操作，当用户呼出分享菜单时，这些操作选项会出现在分享列表顶部和分享内容预览之间，方便用户快速调用可能需要的应用执行下一步动作；同时 Google 也希望通过调整 Direct Share 目标排序的方式来优化 Android 分享菜单的可用性。</p><figure class="image ss-img-wrapper image_resized" style="width: 450px;"><img alt="TcD5bO6D0oLsMvx3uAgcGdI6nph" src="https://cdn.sspai.com/editor/u_/ckj6l2tb34tcsa71k0h0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>自定义分享操作按钮示意图</figcaption></figure><p>除了上述改动，Google 在 Android 14 中还将分享菜单做成了可独立更新的 <a href="https://sspai.com/post/56167">Project Mainline 模块</a>方便功能迭代，并且允许用户通过分享预览即时调整、编辑分享内容，Mishaal Rahman 在<a href="https://sspai.com/link?target=https%3A%2F%2Fblog.esper.io%2Fandroid-14-share-sheet-improvements%2F">这篇技术解析博文</a>中做了详细说明，感兴趣的朋友可以前往阅读。</p><h2>更友好的缩放体验</h2><blockquote><p>可惜来得有点晚，国内适老化的字体改造已经乱七八糟了。</p></blockquote><p>在 Android 14 中，Google 还带来了最高 200% 的非线性字体缩放功能。和此前版本的机械缩放不同，采用非线性放大曲线的好处在于，界面中原本已经足够大的文本不会随着全局设定而同步缩放，文本之间的大小关系、层级结构都能得到有效保留，较大的字体更不会因为缩放而出现文本截断、难以阅读等问题。</p><figure class="image ss-img-wrapper"><img alt="My4UbTRAeoJo8pxyqONcz9VBnTe" src="https://cdn.sspai.com/editor/u_/ckj6l35b34tcsee9i840?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>正常大小、线性 200% 缩放与非线性 200% 缩放，非线性缩放能在保证所有文本具备可读性的同时避免原本就已经很大的字体被机械放大</figcaption></figure><p>在后续的版本中，Google 还在系统的快速设置面板中添加了一个专门用于字体缩放的开关，有这方面需求的朋友可以借助这个开关随时调整阅读体验。</p><figure class="image ss-img-wrapper image_resized" style="width: 450px;"><img alt="CBdGbEOqNoJJuSxGlmjc05RnnLe" src="https://cdn.sspai.com/editor/u_/ckj6l3db34tcsa71k0hg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>正式版新增的字体大小快速设置开关</figcaption></figure><h2>更透明的权限调用</h2><blockquote><p>收紧关键权限、方便用户管理是永恒的主题。</p></blockquote><p>很多人不知道的是，很多依赖定时执行任务或发出提醒的应用（比如 Tasker 也用）都会用到的闹钟——你看不见也听不到的那种。根据应用内设置的不同，这些闹钟会在既定的时间拉起应用，帮助应用准时完善用户设置好的任务。</p><p>不过问题在于，通过精确闹钟唤醒应用是一种资源消耗极强、Google 也非常不推荐的定时任务规划手段（根据 Google 的开发者文档它可以随时将设备从 Doze 状态中唤醒）。因此正如我们去年在 Android 13 正式版的<a href="https://sspai.com/post/75272">介绍文章</a>中所推测的那样，此前引入的 <code>闹钟和提醒</code> 权限不再默认授予。这项限制适用于新安装的、面向 Android 13 及以上系统适配的应用。</p><figure class="image ss-img-wrapper"><img alt="UwxBb8D1Uoltb3xGZDIcPIRDnbe" src="https://cdn.sspai.com/editor/u_/ckj6l3lb34tcsa71k0i0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>闹钟和提醒权限授予提示与授予界面</figcaption></figure><p>与之类似的，Android 14 开始 Google 也会通过 Play 商店策略对非通话、闹钟类型的应用移除针对 <a href="https://developer.android.com/reference/android/Manifest.permission#USE_FULL_SCREEN_INTENT"><code>USE_FULL_SCREEN_INTENT</code></a> 这一权限的默认授权——在此前的版本中，应用可以借助这一权限在锁屏状态下弹出全屏通知，而 2023 年年底这一政策生效之后，开发者就需要通过适配专门的<a href="https://developer.android.com/reference/android/provider/Settings#ACTION_MANAGE_APP_USE_FULL_SCREEN_INTENT">新 API</a> 来向用户发起授权申请了。</p><p>Google 也在提高用户敏感数据使用情况在 Android 14 中的可见性。除了将部分数据安全相关的信息直接放进对应的权限授予弹窗外，Android 14 还会在特定情况下向用户发出通知提醒，包括：</p><ul><li>应用开始向第三方共享位置信息</li><li>应用开始将位置信息用于广告目的</li></ul><figure class="image ss-img-wrapper"><img alt="PsUcbiJNroYGcwxkPaicvzkYn7e" src="https://cdn.sspai.com/editor/u_/ckj6l3tb34tcsee9i84g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>位置信息授权时提供的数据安全提示与 Play 商店中的数据安全提示</figcaption></figure><p>尽管目前大部分与敏感信息使用透明化相关的改动都围绕位置信息，此前 Google 在 I/O 大会上也透露过后续会将范围向其他个人信息扩展的计划。</p><h2>更尴尬的截图提示</h2><blockquote><p>你截屏了！系统知道、对方可能也会知道。</p></blockquote><p>当你在即时消息里向朋友诉苦、当老板在公司群里激情发言，应用里突然弹出通知提示说「对方刚刚进行了截屏操作」……类似的功能在 Android 14 中接下来就有 API 支持了。</p><p>借助 <a href="https://sspai.com/link?target=https%3A%2F%2Fdeveloper.android.google.cn%2Freference%2Fandroid%2FManifest.permission%23DETECT_SCREEN_CAPTURE"><code>DETECT_SCREEN_CAPTURE</code></a> 这一 API，应用在 Android 14 中可以获知与按键操作相关的截图事件（一般是电源键+音量减）了——然后应用开发者可以向用户发出提示，比如付款应用提醒用户不要随便截图分享收款码，或者将这个事件传递给其他人（官方文档中似乎并没有限制开发者这么操作），告诉对方你刚刚进行了截图。</p><figure class="image ss-img-wrapper"><img alt="TMyjbzSP6ouWhwxyR0dcs3CsnEe" src="https://cdn.sspai.com/editor/u_/ckj6l45b34tcs84s7gig?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>Google 给出的截图操作提示使用场景</figcaption></figure><p>然后呢？然后就看谁比较尴尬吧。不过大家也不用担心，一方面这个 API 只会检测基于按键操作的截图事件，ADB、录屏应用等应该不受影响——另一方面这种 Android 新版本特性，至少你每天都要用的微信是不会跟进的。</p><h2>更灵活的常驻通知</h2><blockquote><p>那么「常驻」的意义是……？</p></blockquote><p>一个相比其他改动而言不怎么起眼，但真正用的时候能让人楞上几秒的小改动：在 Android 14 中，常驻通知可以被用户手动划走消除了。</p><figure class="image ss-img-wrapper image_resized" style="width: 449px;"><img alt="MhuXbSGIGo4DMnxW5pZcogBVnOc" src="https://cdn.sspai.com/editor/u_/ckj6l4lb34tcsa71k0ig?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>新的常驻通知清除机制</figcaption></figure><p>Google 也为常驻通知消除机制设定了一套比较基础的规则：</p><ul><li>当我们点击通知面板中的「清除全部」按钮时，常驻通知不受影响</li><li>当手机屏幕锁定时，常驻通知不可被消除</li><li><a href="https://developer.android.com/reference/androidx/core/app/NotificationCompat.CallStyle"><code>CallStyle</code></a> 类别（通常与通话相关）的常驻通知不可被消除</li><li>使用通知面板中的「清除全部」选项时，常驻通知不会被消除</li></ul><h2>更现代的无损音频</h2><blockquote><p>给 USB-C 有线耳机用户一点爱。</p></blockquote><p>干掉 3.5mm 接口之后，近几年真无线蓝牙耳机井喷式发展，各种传输协议也是日新月异。好在 Android 14 这次也关照到了那些坚持使用 USB-C 接口有线听歌的音乐发烧友。</p><p>Android 14 向开发者开放了 USB 设备首选混音器属性的能力，允许开发者注册侦听器以获取首选混音器属性的更改，并使用新的 <a href="https://developer.android.google.cn/reference/android/media/AudioMixerAttributes"><code>AudioMixerAttributes</code></a> 类配置混音器属性。<code>AudioMixerAttributes</code> 类支持在无混音、音量调整或后处理效果的前提下直接传输音频，进而带来无损的有线听歌体验。</p><h2>更通用的健康数据</h2><blockquote><p>继健康数据与平台解绑之后，Health Connect 自身进一步与 Google Play 商店解绑。好事。</p></blockquote><p>2022 年 5 月，今年 5 月，Google 在 Android 开发者官方博客中隆重推出了一个名为 Health Connect 的新平台并推出了相应的 API。Health Connect 官方网站用非常显眼的大标题和副标题简洁地描述了其核心功能与优势：简化健康类应用之间的连接。</p><p>散落在不同应用、服务和可穿戴设备中的健康数据，在 Android 平台上有了一个通用的、可实现数据迁移的中间平台。而从 Android 14 开始，Health Connect 开始从此前需要从 Play 商店下载安装的独立应用升级为系统能力，它将以系统组件的身份通过 Google Play 系统更新接收更新，对不能直接访问 Play 商店但可以借助 OEM 厂商定期更新系统的国内用户而言也是好事一件。</p><p>另外，Health Connect 也跟随本次更新新增了包括运动路线在内的更多数据类型。</p><p>关联阅读：<a href="https://sspai.com/post/77024">App+1 | 你的下一款可穿戴设备，最好支持这个新特性：Health Connect</a></p><h2>更开放的商店策略</h2><blockquote><p>感谢欧盟。</p></blockquote><p>8 月 25 日，欧盟《数字服务法案》正式生效。作为受该法案<a href="https://finance.sina.com.cn/tech/internet/2023-04-25/doc-imyrrekr3857688.shtml">重点关照</a>的大公司之一，Google 也在第三方应用商店这个反垄断诉讼的「热门话题」上做了不少工作。</p><p>在 Android 14 中，Google 引入了多个 <a href="https://developer.android.com/reference/android/content/pm/PackageInstaller"><code>PackageInstaller</code></a> API 来保证第三方应用商店的使用体验：</p><ul><li><a href="https://developer.android.com/reference/android/content/pm/PackageInstaller.Session#requestUserPreapproval(android.content.pm.PackageInstaller.PreapprovalDetails,%20android.content.IntentSender)"><code>requestUserPreapproval()</code></a> 允许第三方应用商店提前请求用户的安装批准，并且在用户授权后可以实现后台下载和安装体验</li><li><a href="https://developer.android.com/reference/android/content/pm/PackageInstaller.SessionParams#setRequestUpdateOwnership(boolean)"><code>setRequestUpdateOwnership()</code></a> 允许第三方应用商店通过所有权声明指定应用自动更新的安装来源，非指定来源的应用升级需要用户手动批准</li><li><a href="https://developer.android.com/reference/android/content/pm/PackageInstaller.InstallConstraints"><code>InstallConstraints</code></a> API 允许第三方应用商店选择用户并未与 app 交互的时段更新应用</li><li><a href="https://developer.android.com/reference/android/content/pm/PackageInstaller.SessionParams#setDontKillApp(boolean)"><code>setDontKillApp()</code></a> 允许第三方应用商店针对支持拆分式安装包（APKs）的应用采用无缝更新，比如仅更新用户当前未在使用的组件</li><li>最后，从 Android 14 开始系统软件包安装程序也允许开发者指定要包含在应用中的 Google Play 应用商店页面的应用元数据，例如数据安全信息等。这同时也能方便第三方应用商店获取与应用相关的元数据信息</li></ul><hr /><p>以上便是 Android 14 中值得你关注的 14 项新特性，篇幅有限，还有更多细节以及 Pixel 专属特性本文未能一一覆盖，如果有你感兴趣的欢迎在评论区补充。</p><p style="margin-left: 0px;">&gt; 关注 <a href="https://sspai.com/s/J71e">少数派公众号</a>，解锁全新阅读体验 📰</p><p style="margin-left: 0px;">&gt; 实用、好用的 <a href="https://sspai.com/mall">正版软件</a>，少数派为你呈现 🚀</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://sspai.com/post/83491</id>
            <title>少数派健身类选题人气作者「举铁的马里奥」都装了啥？</title>
            <link>https://sspai.com/post/83491</link>
            <guid isPermaLink="false">https://sspai.com/post/83491</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 07:15:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    少数派健身类选题人气作者「举铁的马里奥」都装了啥？
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://sspai.com/post/83488</id>
            <title>返璞归真，又迎一春：小评《刺客信条：幻景》</title>
            <link>https://sspai.com/post/83488</link>
            <guid isPermaLink="false">https://sspai.com/post/83488</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 07:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 《刺客信条：幻景》，回归初心，潜入+暗杀，简化玩法
<br>
<br>
总结: 《刺客信条：幻景》作为系列十五周年的纪念之作，回归了系列最初的潜入+暗杀的核心玩法，并通过简化玩法系统，让玩家能够体验到最原汁原味的刺客体验。 </div>
                        <hr>
                    
                    <p>本文首发于 <a href="https://www.gcores.com/articles/171791" target="_blank">机核网</a> ，作者 <a href="https://www.gcores.com/users/62278/content" target="_blank">@雪豆</a>，少数派经授权转载，仅对文章格式略作调整。</p><hr /><p>《刺客信条：幻景》在今天已经正式发售，在一个月前我曾经前往上海育碧总部提前玩到了部分内容，感谢育碧的邀请，这次趁着十一长假，我完整体验到了本作的全部内容。</p><p>作为系列十五周年的纪念之作，去年就已经公布的《幻景》在宣传之时就定下了「回归初心」的基调 —— 虽说这种说辞在当下有种「陈腔滥调」的嫌疑，然而从整个系列的变迁来看，将「潜入+暗杀」这一主题能够再次完整地带给玩家，我还真觉得是系列新作的「当务之急」。&nbsp;</p><p>于是《幻景》做出了一个很好的「还原」：它去掉了更加复杂的成长机制，将玩法系统刻意地做出了简化，却传承了系列发展中总结出来的一些优秀特色 —— 你仍然可以体验到最原汁原味的计划、潜行、暗杀等情节，也可以将一切抛之脑后，欣赏黄金时代下的巴格达的美丽景色。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/d471ce164949879da09698b36f4de04d?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>事实上，我觉得《幻景》没有任何进步、也没有任何改变，说是一部看起来非常保守的作品也不为过。但它依然充满了系列最原始的那种扮演刺客的魅力，并让我沉浸数十个小时无法自拔。</p><p>通俗点说，那就是味儿对了。</p><h2>关于本次体验内容的一些注意事项</h2><ul><li>总游戏时间约 20 小时左右，出于时间的关系，除了主线剧情之外，我未能达成全收集以及全部支线任务的目标。</li><li>为了保证各位玩家的体验，本篇文章中将不包含讲述剧情相关的内容，请放心阅读。</li><li>本次所体验的平台版本为 Windows，使用 Xbox 手柄。在 RTX3080 显卡的加持下，游戏全程稳定在 60FPS，未出现明显的掉帧和拖慢现象。</li><li>我所体验的版本并未实装首日补丁，游戏的最终表现请以正式版为准。</li></ul><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/505ed4f5c1437ba397dabda4adba3a10?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><h2>去 RPG 化，好</h2><p>《幻景》给我的最直观的感受就是 —— 一切都变得简单了。</p><p>不知道还有多少玩家记得《起源》中的等级，以及《英灵殿》中纷繁复杂的技能加点。在《幻景》中这些都不复存在。主人公巴辛姆的血量和耐力的上限值并不会受到经验值的影响 —— 或许应该这么说 —— 本作中不存在经验值这个东西。</p><p>这让原本聚焦于角色本身的成长体系被分配到了武器和天赋树这两个部分上。虽说部分武器通过强化可以提升伤害，但武器与防具更多的则是强化「角色的某项技能效果」，例如「减少暗杀时的噪音」或是「击杀敌人时提供 X 秒的时间减缓」等等。甚至有些武器获得时就是满强化的效果，找到一套趁手的武器，然后全程用到通关也是没问题的。</p><p>而天赋树则简简单单地分为了三个分支：「幻影」侧重于暗杀与正面战斗时的辅助能力、「骗徒」则是可以增强暗杀时使用道具的效果、「猎手」则是提供猎鹰等侦查手段的花样。像是「连续暗杀多名敌人」这种非常便利的天赋我个人自然是推荐优先点出来的，而其余的则可以根据自己的喜好随意选择。更方便的是，这些天赋可以随时重置，就算是点到了自己不常用的天赋也不必担心。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/294ae68711748cf50079fcf43487cd31?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>这样的简化让游戏一下子变得「通俗易懂」了起来，不用费劲巴力地研究什么天赋流派，也不需要在探索的时候时刻注意敌人的等级以免被碾压。毕竟巴辛姆不是上一部的狂战士，不需要什么多姿多彩的战斗方式，灵巧的回避和各种辅助逃跑潜行的副武器才是他最拿手的技能。所以就算是一不小心暗杀失败暴露了自己，玩家也只要熟练掌握轻重攻击、回避和非常宽松的弹反，那就足以令他在巴格达游刃有余。</p><p>不过说没有任何的成长要素显然是不客观的：伴随着不断推进任务流程以及探索巴格达内隐藏的各种谜团，玩家可以提升巴辛姆的评价等级。但这个评价等级更像是一种引导，指导玩家在当前的阶段可以在哪个区推进任务，确认目前的游戏进度。实际上就算完全无视也不会对角色行动造成什么影响。另外评价等级还会解锁背后的挂饰，仅此而已。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/335c5ca46d2d2e8bc8bad71ff07a6241?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>这种去 RPG 化的设计我觉得就像是一种「育碧在绞尽了脑汁想要做出点什么新花样之后，突然某天夜里把电脑里的各种策划文档突然一删，然后把老祖宗藏在阁楼里的笔记本又翻出来」的一种表现 —— 我能在《幻景》中找到在其他系列游戏中所验证过的那些成功的机制，但这些机制又不会影响到《刺客信条》这一系列中最原始，也是最有意思的「暗杀」这一玩法。</p><p>更不如说，之所以要为了做出这些简化，它的目的，就是为了要让「刺客」的味道更加纯粹。</p><h2>简单的刺杀与战斗，很好</h2><p>回想初代操纵阿泰尔在乱军中取目标首级的游戏体验，以及二代艾奇奥那种经过强化后的，优雅而又神秘的「传统」玩法，《刺客信条》系列在之后的设计思路就开始往一种令我有点「接受不了」的方向开始发展 —— 就比如《黑旗》让各位玩家称道的航海与探险跟「刺客」八竿子打不着；《枭雄》里增加了各种街头破坏的内容让暗杀变得没啥存在的意义；《英灵殿》连主副手装备都给你做出了详细的区别，就是想让你往狂暴战那个方向直接转职。</p><p>我的意思并不是说这些作品中就没有「暗杀」这一选项，而是觉得在这些作品中，暗杀只是一种「选择」 。你暗杀也行，不暗杀一路进去叮咣五四一通乱砸也行。说真的，虽然这设计玩起来是自由度拉满，但也挺不「刺客信条」的。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/b9407347523a1c23b73e73fd1b15a507?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>尤其是当这种开发思路开始贯穿到之后的作品中，一次尝试我可以接受，两次尝试我可以理解，但它的名字叫《刺客信条》 —— 再加上后来《起源》中那种「装备跟等级绑定」类似的我非常不喜欢的设计，我曾经在很长一段时间还反思自己，是不是像真正的刺客那样「从黑影中来，在黑影中消失」的游戏体验已经跟不上时代潮流了？</p><p>然而《幻景》跳出来给了我一个大嘴巴子。正如它所宣传的那样，《刺客信条》的最新作变成了像初代那样的，着重「暗杀体验」的游戏模式。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/c7ce5d795f3dfeb34a1ce1b30484e6b7?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>当故事剧情带领玩家开启一轮新的刺杀任务时，玩家并不是像往常那样，直接被给予了暗杀的目标。系统将原本的一个个任务，设计成了一个看似体量非常庞大的「调查」面板。玩家先根据故事的提示，潜入各个区域去搜集相关信息，亦或是从一些小头目身上套取情报，从而如抽丝剥茧一般，最终确定你需要暗杀的目标。到底要先干什么后干什么，自己去面板里查就完事儿了。</p><p>获取情报的过程实际上是非常随意的 —— 比如说某个道具在NPC的手上，你可以跟他交易、直接杀掉目标抢夺、亦或是使用惯用的偷窃伎俩来获得；潜入某个地方时，你可以选择是花点货币让门口的雇佣兵捣乱从而趁机进入，亦或者用你的猎鹰“恩奇都”仔细探查周围，找到下水道或是墙上的裂缝进行一次传统的潜入。甚至连一些任务的推进顺序也是可以由玩家来自由决定的，先做A还是先做B，最终结果所导向的发展也都是一致的。毕竟少了等级的制约，玩家能去的地方也就更多了。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/373b94da818ff34ebb65280b81480031?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>在故事的开始我们可以得知，这次巴辛姆所要面对的敌人都是蒙着面，也不知道真实身份的神秘人物，而这些「大人物」都隐藏在守卫森严的特殊堡垒或是区域中。玩家要做的就是在各种敌人之中穿梭，在令人焦躁的等待中，找到出手的一刹那时机。</p><p>这让我不由得想起了隔壁后脑勺纹条形码的大哥 —— 对比过来二者都是强调「暗杀」的魅力，但前者可以各种花样杀陷阱杀甚至是栽赃嫁祸的狼人杀，《幻景》这次却变成了一件特别简单的事儿：无论从哪个地方，玩家所要做的就是潜行到敌人背后，给他/她来上一刀，然后在混乱之际攀爬跳跃跑酷再配上几颗烟雾弹逃出生天即可。</p><p>看起来特别质朴，可身为古代刺客的真实体验，就是这样简单而干脆。</p><p>可以说，本作的核心玩法全是构筑在了如此简单的暗杀玩法上。《幻景》将玩法的重点放在了「调查暗杀目标开始，找到各种蛛丝马迹，在确定暗杀目标身份之后制定暗杀计划」这样的过程上，并在体验过程中给了许多选项，让玩家自己选一条最合适自己游戏习惯的玩法即可。花样真没那么多，最多也就是爬进屋子看看有没有吊灯或者油瓶什么的，辅助击杀 BOSS 一下。</p><p>就连本作中为巴辛姆设计的大招「专注刺杀」也是基于「暗杀」这一系统上：玩家需要通过暗杀来积累专注值，再用专注值来一瞬间秒杀任何敌人。不管你是身高马大的重甲兵，还是身份显贵的重要人物，「专注刺杀」都可以轻松让玩家达成目标 —— 当然，想要发动这样的强力技能，也需要巴辛姆处于未被发现的状态才可以。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/edc6ef4a01d74571f947f5f1e1a056cc?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>当然，换个角度来看，这种设计也确实是显得太过于传统了。「眼前一亮」这种东西在《幻景》中可以说是非常少见 —— 因为游戏提供了一种「非常纯粹「的游戏体验。它纯粹到就算一不小心暗杀失败了要不得已处理大批大批敌人时，玩家除了逃跑，所能做的也就只有回避、格挡和攻击（还把轻重攻击做到了一个键位上）这几个简单的应对手段而已。除了需要留神的「无法格挡只能回避」的红光攻击以外，大部分情况下都可以通过判定非常宽松的格挡来轻松化解各种难题。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/38c0a9546a09d27518402dc8fc7197ff?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>不过《幻景》中加入了「体力条」这种限制玩家翻滚癌的设计，不难猜测是希望玩家尽量不要采用「硬碰硬」的玩法策略来体验本作。一些重甲敌人的红光攻击节奏也非常难抓，关键时候还是用烟雾弹保命更有效一些。</p><p>总的来说，这种战斗体验一下子就让我回到了初代的时候「一个格挡能杀一地图的敌人」这种简单而粗暴的战斗体验 —— 玩起来是没啥新鲜感，但话又说回来，《刺客信条》真的需要那么多花里胡哨的玩意儿吗？</p><p>一切的核心玩法都围绕着抽丝剥茧般的「暗杀」体验来展开，其他的作为「锦上添花」来增添找补。我觉得《幻景》终于理清楚了一件事儿，那就是「返璞归真」才是美。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/0eb8e11f831a8c17bfcb9fb50eda5519?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><h2>巴格达的魅力，太好了</h2><p>要说通过玩游戏来学知识的典型，我就佩服俩游戏：一个《三国无双》，一个《刺客信条》。</p><p>《刺客信条》系列中所包含的文化属性是一种完善到足以令人匪夷所思的程度 —— 什么「巴黎圣母院拿游戏来做重建参考」「上课直接作为课件进行实际演示」什么的新闻早已经是玩家之间口口相传的「好人好事」了。</p><p>就怎么来形容《刺客信条》这种事无巨细的文化关怀呢？哪怕是这游戏没有半点的可玩之处，它还能牢牢坚持着「旅游模拟器」这一最后的操守，成为各位一次次当着父母的面正大光明地打开游戏机说「学历史」的最好借口。</p><p>毫无疑问，《幻景》所带来的公元九世纪的阿拔斯王朝，又一次成为了我们学习阿拉伯历史的最好教材。这个时代离我们很遥远，所以体验《幻景》所带来的那种神秘却又朦胧的气质，成为了我漫步在这个灼热大地上的另外一个理由。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/caa0a1e31e889bfac9be9b46a5046054?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>「伊斯兰黄金时代」是一个穆斯林文化影响全世界的时代。除了我们所熟知的《一千零一夜》以外，世界上的艺术家、工程师、学者、诗人、哲学家、地理学家及商人，在巴格达的「智慧宫」里相互碰撞，带来了艺术、农业、经济、工业、法律、文学、航海、哲学、科学、社会学、科技各方面的飞速进步：原始的资本主义市场自那时涌现、阿拉伯农业革命引进了大量伊斯兰世界以外的农作物、巴格达建立了第一所天文台并创造了标准星盘、大型清真寺拔地而起使得伊斯兰建筑更具特色……</p><p>作为故事发生的舞台巴格达，正是这样一个庞大且由各种文化符号互相影响而形成的宏伟都市。立体的结构不但给巴辛姆提供了更加灵活自由的移动路线，更是让这些虚拟的游戏画面变成了我们回顾历史的真实途径。我曾经在前瞻文章中提到过，选定巴格达是很讨巧的一件事 —— 毕竟作为当时三大国际都市之一，它注定是可以提供充足的鸟瞰点、可以作为刺客据点的房屋、以及足够宏伟的历史建筑的。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/dbdb36cf8668e796e212d18c2967b67c?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>更让我觉得印象深刻的是，《幻景》中的巴格达作为港口，还融合了罗马、中国、印度、希腊等多个国家的文化元素。比如在街头就可以听到亲切的唐人行商叫卖的声音。《幻景》中那些大量的真实存在的历史文化遗迹，变成了一个个可以供玩家进行收集的「历史古迹」条目。光是那些详细的说明文字，就足以花上几个小时去细细品味。但感到遗憾的是《起源》和《英灵殿》中的教育模式「发现之旅」并没有在初期就实装到游戏中，希望在之后能再补充进来吧。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/58343d1c6df0868b5f601116dbb727ab?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>将文化的展现以电子游戏的形式展现给玩家这种事是育碧的拿手好戏，所以放一万个心，这次的《幻景》也绝对不可能在这方面失手。但话又说回来，不停地观光总有一天也会腻，《幻景》这种恰到好处的简单游戏体验会让那种早已习惯「罐头游戏」的各位玩家们会有一种「哎？青菜好像还挺好吃的来着？」这种很微妙的惊喜感。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/3f13f20bad38f21f02929e94c9482b26?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><h2>一些杂七杂八的想法，不够好</h2><p>得益于巴格达在当时历史上的地位，巴辛姆可以花费一些特殊硬币来雇佣来自各个国家的三教九流达成目标 —— 就比如可以雇佣外籍佣兵捣乱来吸引敌人的注意，亦或者贿赂当地的宣讲官来降低敌人的警觉度，但我很少用这个系统，一般都比较喜欢亲力亲为；</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/b5d755f2e107eb271a8fff7a36cb89cd?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>警觉度高了会被市民喊卫兵过来，满值了还会出现阿拉伯暴恐机动队来天诛你（没那么夸张），撕布告可以直接降低一个警戒度，也太过于有效了点儿……我曾经问过开发团队为啥这样设计，他们说就是不想让玩家太过于花精力在消除负面效果上，贴心。</p><p>硬币的获取大部分是通过本作中的「偷窃系统」获得的 —— 本质上是一个简单的 QTE。偷窃可以从其他 NPC 上获取金钱或道具，灵活使用偷窃系统，可以在一定程度上影响到玩家完成刺杀潜入的进程，另外觉得 QTE 很烦的玩家还可以开启菜单中的「必定成功」选项。对自已好一点，因为有些时候偷窃的判定真的太小了；</p><p>不知为啥，《幻景》的移动手感其实挺一般的，比如一些需要跑酷的情节里，方向的判断并不够灵敏，掉到河里或是爬错方向的情况比较常见，感觉有点祖传手感的味道；</p><p>游戏中的引导做的也不够明显，比如一些室内场景中的出口需要仔细观察才能发现，没有小地图只有方位显示真的挺折磨人；</p><p>另外我真的很讨厌“反锁的门”这样让你绕远的设计，《幻景》中多的也太过分了；</p><p>在之前试玩的时候我发现暗杀敌人的判定会比视觉的距离要远上一个身位左右，但在正式版中，我发现暗杀的动作会根据所处的位置不同而有所区别 —— 例如草丛中离敌人太远时触发暗杀就会让尸体停留在原地而不是拖进草丛，不是很严谨。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/988a2596decacfdcf6705080204b1f5a?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>敌人蠢到令人吃惊，蹲草丛里是真的可以靠口哨把整个巡逻队一个个骗进来杀掉而不被发现。都 2023 年了大哥！能不能学学《MGS 2》里面那种 CAUTION 状态下小队地毯式搜索的 AI 的表现啊。</p><p>本作的副武器在每一个阶段都可以进行三选一的性能强化，这种打造独一无二的设计思路我很喜欢，不过说回来我最常用的也就是飞刀、烟雾弹这两样。天赋中副武器上限可以不用着急点，反正敌人的营地里啥都有，摸一圈全回来了。</p><p>虽说不能剧透，但我觉得…… 剧情还是挺中规中矩的。偷的东西干的事儿，只要你想猜，没有你猜不到的。</p><p>Bug 确实有，但我遇到的也顶多是穿模的小事，卡关的情况没有发现过。</p><p>除去主线任务以外，流程中包含了若干名为「巴格达传奇」的支线任务。做不做都行，有一些货币奖励之类的，但挑战的内容都挺有意思，比如「不被发现」「无伤击败敌人」，不难做，调剂一下胃口很合适。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/b36d43cf9b4f02ad291dc3ac96739e7e?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>猎鹰的使用方式与《起源》类似，需要先解决掉弓箭手才能探明据点，基本上找任务目标全靠它了。</p><p>整体画面没有美到「惊艳」的程度，正常水平吧，拍拍照还是挺出图的。</p><p>买了豪华版的玩家记得领领给的特殊装备、马和鹰。主要是装备，挺好使。</p><p>另外如果在育碧自家平台购买的话，还可以用账号升级给的奖励币在平台菜单里免费换取阿泰尔和艾奇奥在《启示录》里的经典装扮。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/5c26f60e730d745dc6f559b51f6200b9?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><h2>结语</h2><p>《幻景》最终的感觉就是一款显得很「保守」的游戏。它没有那么多花里胡哨的新系统，反倒是把之前系列中那些不错的想法敛了一波，又融合了一下。所以如果你是本身对《刺客信条》系列不是很感兴趣的玩家，在本作中其实也挺难找到快乐的。因为本来的《刺客信条》它就是一个质朴的穷小子，没啥光鲜亮丽的地方，但就是有一种简单的真诚和美好。</p><figure class="image ss-img-wrapper"><img alt="图片" src="https://cdn.sspai.com/2023/10/11/article/9ffdbaba2ff308dae519216a47f80047?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>在《幻景》理同样可以大杀四方，也同样可以爬到楼顶啥都不做看看夕阳，它有着绝对是《刺客信条》最应该有也最完好保留下来的玩法体验，并且这次也没胡搞乱搞，稳稳当当的落地。虽说游戏也有小毛病，但骂归骂，玩还是要玩，并且我玩的还挺有像第一次在大学宿舍用 Xbox 玩《刺客信条 1》的时候那种感觉，似乎比初恋还值得回味。</p><p>而且最重要的是，《幻景》挺便宜的，我真的没啥理由不玩它。<br />&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://sspai.com/post/83487</id>
            <title>用开源项目，你也能训练自己的 AI 语音模型</title>
            <link>https://sspai.com/post/83487</link>
            <guid isPermaLink="false">https://sspai.com/post/83487</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 03:50:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stable Diffusion, AI绘图, AI翻唱歌曲, AI语音模型
<br>
<br>
总结: 作者通过自己的经历介绍了AI语音模型的应用场景和训练成果，包括训练自己的音色唱歌模型和女声模型，以及用混合模型生成近现代文学作品的音频。作者还提到了AI变声器的应用和潜在的更多应用场景，如自制广播剧、制作有声书短视频和文字游戏等。最后，作者提醒读者在发布分享之前要了解相关法律法规。 </div>
                        <hr>
                    
                    <h2>前言</h2><p>Stable Diffusion 比较火的时候玩过一阵子 AI 绘图，那个时候就感受到了人工智能的巨大潜力。后来刷 B 站的时候一直刷到各种 AI 模型的视频，其中就有许多 AI 翻唱歌曲的内容。出于好奇，去 Github 上搜了一下，发现了不少开源的 AI 语音模型项目，训练门槛也不高，就入坑玩了一阵子。初时只是出于好奇，实际体验过后却被其逼真的效果所震撼，于是把以前训练时的一些笔记整理了一下，和大家分享一下训练的心得体会。</p><h2>应用场景</h2><h3>个人应用</h3><p>先简单谈谈我自己的训练成果和应用场景。</p><p>训练过一个自己音色的唱歌模型，虽然高音还是唱不上去，但是起码在调上了，也算圆了自己的一个唱歌梦，不跑调就是胜利。还训练了几个女声模型，最后挑了两个融了个略带烟嗓的女声模型，效果相当的不错，一篇几千字的文章，最多出现一两处电音或变调，我个人完全可以接受。</p><p>目前比较喜欢用这个混合模型来生成一些近现代文学作品的音频，就是那种直接看可能看不下去，但是听的话还能投入进去的文章。以前上学的时候还挺喜欢看看出版书籍的，各种散文、名著都能耐下性子研读，现在变得比较浮躁，沉不下心，但是又想接受一下文学的熏陶，这种矛盾的心情不知道各位能不能理解。如果是普通 TTS 转换出来的朗读效果我个人不太能接受，完全不会有想听下去的欲望，所以特地花了一个礼拜调出了目前使用的音色，等哪一天听腻了就准备再花点时间换个口味，反正成本也不高，几晚上的电费而已。</p><p>为了用起来更方便一点，我特地看了一下音色推理部分的源码，临时写了一个脚本，可以一键把指定文件夹中的 txt 文件转为音频文件，还会同时生成 vtt 格式的字幕文件。因为我特意把微软 TTS 的语速调慢了 20%，所以一般 3000 字的文章转成音频后会有 15 分钟左右，对我来说刚刚好。</p><p>电脑上听的话我一般是用 PotPlayer，这个播放器可以自动加载同文件夹下的同名字幕文件，比较省心，播放的显示效果如下：</p><figure class="image ss-img-wrapper"><img alt="V7AMbk3suoQwrSxGiDTckSyrnjh" src="https://cdn.sspai.com/editor/u_/ckj0b7db34tdh3ari810?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>除此之外还训练过几个用来实时转换音色的模型，说简单点就是 AI 版的变声器。以男声变女声为例，以往的变声器除了需要打开变声功能外，还需要说话人用尖细的音调说话才能达到以假乱真的程度，但是 AI 变声器完全不需要，普通语气讲话即可。目前的 AI 变声器还存在两个不大的缺陷，第一是如果显卡不行的话延迟会比较高；第二是类似鼓掌、敲桌子之类行为发出的非人声也会被转换。游戏里用 AI 变声器开麦说话效果非常炸裂，偶尔玩玩还挺有意思。</p><h3>更多应用</h3><p>其实这些模型也可以接入我家的智能家居系统 HomeAssistant 里面，但是比较麻烦，因为我不想在 HomeAssistant 的虚拟机里安装过多的依赖，所以如果要接进去的话最好的办法就是封装一个 API 接口的 docker 容器，想想还是算了，等什么时候训练出来一个熟人的音色想整活的时候可以考虑写一个玩玩。</p><p>思维如果发散一下，应用场景其实非常丰富，如果稍微懂点编程就能玩出花来。简单点的，根据类似「甲：…… 乙：…… 旁白：……」这样格式的文本，写个脚本自动识别角色匹配不同的语音模型来批量化自制广播剧。复杂点的，搭配 Stable Diffusion 这样的 AI 绘图软件批量制作有声书短视频。难度再高点的话，可以配合 Ren'Py 这种简单的视觉小说引擎自制一个文字游戏，亦或是将跑团群中的文字跑团游戏可视化为影音游戏的形式留念。</p><p>当然，虽然我在这里列举了这么多的应用方式，但是并不建议大家轻易尝试，训练出来自己玩玩就好。如果你真的想<strong>发布分享</strong>的话，那么建议在行动之前看一下国家今年 7 月份开始公布施行的《<strong>生成式人工智能服务管理暂行办法</strong>》以及其他的一些相关法律，包括但不限于《中华人民共和国宪法》《刑法》《民法典》《合同法》。</p><blockquote><p>《民法典》</p><p>第一千零一十九条</p><p>任何组织或者个人不得以丑化、污损，或者利用信息技术手段伪造等方式侵害他人的肖像权。未经肖像权人同意，不得制作、使用、公开肖像权人的肖像，但是法律另有规定的除外。未经肖像权人同意，肖像作品权利人不得以发表、复制、发行、出租、展览等方式使用或者公开肖像权人的肖像。对自然人声音的保护，参照适用肖像权保护的有关规定。</p><p>第一千零二十四条</p><p>【名誉权】民事主体享有名誉权。任何组织或者个人不得以侮辱、诽谤等方式侵害他人的名誉权。</p><p>第一千零二十七条</p><p>【作品侵害名誉权】行为人发表的文学、艺术作品以真人真事或者特定人为描述对象，含有侮辱、诽谤内容，侵害他人名誉权的，受害人有权依法请求该行为人承担民事责任。行为人发表的文学、艺术作品不以特定人为描述对象，仅其中的情节与该特定人的情况相似的，不承担民事责任。</p></blockquote><h2>语音模型分类</h2><p>这里我就不说什么非常专业的名词了，我自己也不是专门做这个的，理解也算不上深刻。就我目前能找到的开源项目而言，主要分为两类。一是文字转语音，类似常见的 TTS 功能；一是语音转语音，就是进行音色上的转换。许多这类开源项目的初衷是希望让自己喜爱的虚拟角色唱自己喜欢的歌，所以一般主要功能都是唱歌，顺带也可以支持正常说话。</p><p>文字转语音的模型想要自己训练一般会比较困难，困难的点主要是数据集，因为要实现文字与语音之间的一一对应，数据集制作时不仅需要大量干声素材，还需要对每一条干声素材进行文本标注。虽然标注的过程可以借用别的 AI 模型进行简化，但是一条条地人工校验 AI 标注的结果也是一种折磨。当然，也可以选择不校验，但是最后训练出来的模型质量就无法保证了。</p><p>语音转语音的模型则要亲民许多，一般只要保证有足够时长的高质量干声素材即可，我个人主要训练的就是这种模型。想用这种模型实现 TTS 功能也是可以的，就是需要多一步转化。可以先使用微软免费的在线 TTS 服务将文本转换为语音，然后再通过训练出来的音色模型将其转化为目标音色。听上去比较复杂，其实上写个 Python 脚本调用 edge-tts 库即可轻松完成。</p><p>单从 TTS 的效果而言，效果比直接自己训练的文本转语音模型还要好。因为微软的 TTS 模型真的很强大，相信大家都在电影解说视频中听到过「这个男人叫小帅」的开场白，这个配音用的就是微软 TTS 服务中的「云希」。虽然现在「云希」各种泛滥，导致大家听到之后都有点厌烦，但不可否认，语音效果确实算是最强的一档。</p><h2>开源项目推荐</h2><p>AI 语音类的开源项目非常多，这里只推荐两个我自己用下来觉得训练方便、效果显著的。</p><h3>so-vits-svc</h3><p><a href="https://github.com/svc-develop-team/so-vits-svc/">SoftVC VITS Singing Voice Conversion</a> 是一个音色转换项目，之前网上比较流行的 AI 孙燕姿模型很多都是用这个项目训练出来的。除了唱歌，也可以用在正常说话的语音上，音色还原度以及咬字清晰度都是开源项目中的佼佼者。</p><p>唯一不好的地方是因为一些法律原因，之前这个项目删库重建过一次，之后项目组就不再发布官方训练底模了，想找个合适的底模比较麻烦。</p><h3>Retrieval-based-Voice-Conversion-WebUI</h3><p><a href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI">RVC-Project</a> 项目可以用更少的素材和训练步数达到一个不错的音色还原度，而且实时转换的效率也比较高，如果是想要作为变声器使用的话，更推荐使用这个项目。</p><h2>开源模型社区</h2><p>大家如果没法自己训练模型但是又想体验的话，其实有一个最简单的办法，就是部署好环境之后直接去开源模型社区下载现成的模型，这里推荐使用 <a href="https://huggingface.co/">Hugging Face</a>，基本所有的开源项目都能在这里找到相关模型，有些项目的底模找不到也可以在这里碰碰运气。</p><h2>本地训练门槛</h2><p>这里讲的是本地训练的门槛，对于租借云端显卡进行训练的方案就不讨论了。</p><h3>6 GB 显存的英伟达显卡</h3><p>训练大部分 AI 模型都需要用到高显存的 N 卡，语音模型算是里面比较亲民的，最低显存要求不算太高，一般的游戏显卡都能满足。</p><h3>充足且清晰的单人音频素材</h3><p>这里充足的概念是指符合目标项目中提到的最低音频时长要求，不同的 AI 项目想要达到目标效果所需的素材时长是不同的。相较于音频时长，其实更关键的是音频的<strong>质量</strong>，低质量的素材最后训练出来的模型也必然不会完美。我这里没有强调必须是干声素材，因为背景音大部分情况下都可以通过人声分离软件进行剔除，后面会有更详细的讲解。</p><h3>基础的 Python 编程知识</h3><p>并不是说不会 Python 就没法自己训练 AI 模型，毕竟网上有一大堆所谓的整合包，下载解压后一键就可以开始训练。但是没有这部分基础知识，训练过程中碰到问题就很被动。更关键的是，训练出来也无法自如应用到更多的场景。</p><p>举个稍微复杂点的例子，让服务器每天爬取当天的天气预报，如果出现下雨或极端天气就自动生成一段提醒文本，然后自动调用语音模型将其转换为音频，最后通过 DLNA 传输的方式让房间中的音箱播报这段音频。这种场景很美好，就是得靠一定编程知识才好搞定。</p><h2>语音模型项目本地部署</h2><p>我并不想针对单一的 AI 语音项目来出一个具体的教程，如今 AI 发展呈井喷之势，可能过一阵子就会因为一篇新算法的发表而出现更加优秀的训练项目。「授人以鱼不如授人以渔」，所以下面的内容更多的是分享一些解决问题的思路。</p><p>这里仅考虑使用 Windows 的情况。当然，如果实在不想折腾，也可以直接去 B 站上搜对应项目的整合包，一般都能找到，开箱即用。</p><h3>前期准备</h3><p>相比直接安装 Python，其实我个人更推荐使用集成工具 <a href="https://www.anaconda.com/">Anaconda</a>。它的优势是方便部署虚拟环境，可以很方便地为每个项目配置单独的运行环境，配置好环境后只需要将整个项目文件打包就可以放在任何其他电脑上运行，自己创建所谓的整合包。</p><p>Anaconda 安装起来非常简单，去官网下载最新的安装包，然后按照指引完成安装即可。如果对于安装过程存在疑惑的话，网上随便搜一个教程即可，我就不讲了。因为这些开源项目一般都是发布在 Github，下载太慢可以用 <a href="https://github.com/BeyondDimension/SteamTools">Watt Toolkit</a> 试试，或者用 <a href="https://doget.nocsdn.com/#/">Doget</a> 对下载链接转换后再下载。也可以在 <a href="https://gitee.com/">Gitee</a> 上新建仓库从 Github 上导入。</p><h3>项目部署</h3><h4>查看文档</h4><p>想要部署一个项目，最先要做的就是看一下项目根目录下的 readme.md。这个文件会默认显示在 Github 中该仓库的主页。</p><p>主要看哪些东西呢？</p><ul><li>项目实现的功能。确定项目符合自己的需求。</li><li>训练模型需要的硬件配置。如果文档中没有特别强调，一般 6 GB 显存的 N 卡也就够用了；如果电脑配置不满足却还是想要尝试，可以使用类似谷歌 Colab、百度飞桨等云计算平台。</li><li>支持的 Python 版本。目前开源的 AI 模型基本都是依托于 PyTorch 这一机器学习库编写的，如果文档中没有提及版本问题，可以使用较为稳妥的 3.8 版本。</li><li>训练用音频素材的要求。首先是音频格式及其采样率，大部分情况下是单声道 44K 采样率的 WAV 格式文件，虽然项目中可能有重采样的预处理程序，但是最好初始输入的音频就符合项目要求。另一个是音频素材的单个时长及总时长，单个时长一般 3~20 秒都是可以的，最好是控制在 5~15 秒，具体以项目文档为准；总时长个人经验并不是越长越好，正常两个小时左右就能达到不错的效果，部分特化的项目甚至只需要几分钟，不要太长的另一个原因主要是考虑到训练速度，如果素材总大小超过电脑内存上限的话，就无法一次将数据读取到内存中，训练速度会受到硬盘读取速度的限制，GPU 占用率会因为读盘的操作而经常下降。</li><li>训练的命令。大项目都会有比较详细的训练步骤介绍。</li></ul><h4>拉取项目</h4><p>接着自然是把项目文件拉取到本地，不管是用上面提到的哪种办法，只要能下载到本地即可。</p><h4>搭建环境</h4><p>进入项目根目录，在此处打开 CMD 窗口，确保 CMD 窗口中显示的路径为当前项目根目录，如果不是就用 cd 命令切换过来。注意这里<strong>一定不要用 PowerShell</strong>，不然会无法激活下面创建的虚拟环境。</p><p>然后使用 Anaconda 在当前目录创建虚拟环境：</p><pre class="language-"><code>conda create -p .\env python=3.8
</code></pre><p>命令中 Python 的版本可以根据需要自行更改。我比较喜欢指定环境安装位置在项目根目录，方便后期打包备份。如果不准备在其他电脑上运行也可以用 -n 参数创建一个命名环境，这个环境一般会保存在当前电脑用户的文件夹下。</p><figure class="image ss-img-wrapper"><img alt="D4zQbuixRoPnsmxTPsFcP9h0nBb" src="https://cdn.sspai.com/editor/u_/ckj0b7lb34tditeq6uag?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>创建好 Python 虚拟环境后需要在命令行中激活：</p><pre class="language-"><code>conda activate .\env
</code></pre><p>激活后命令行前面会有一个小括号包裹的环境路径，一定要确保激活环境后再进行后面的操作。</p><figure class="image ss-img-wrapper"><img alt="GTuMbfQ75oQjl0xORzDcQqkMnWZ" src="https://cdn.sspai.com/editor/u_/ckj0b7tb34tditeq6ub0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>接下来输入下面的命令查看自己电脑的 CUDA 版本：</p><pre class="language-"><code>nvidia-smi
</code></pre><figure class="image ss-img-wrapper"><img alt="BXuXbC0V1oK497xrxm5cjnRbnwb" src="https://cdn.sspai.com/editor/u_/ckj0b7tb34tdh3ari81g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>之后登录 PyTorch 的官网，官网上可以直接查看符合自己系统的安装命令，我一般直接选择 Pip 安装方式。在之前的命令窗中输入网页上的安装命令，等待下载安装完成。第一次安装可能会比较慢，后面如果创建别的虚拟环境就可以直接用系统内的缓存，安装速度会快很多。</p><figure class="image ss-img-wrapper"><img alt="KK8dbzfk4osdgzx6wcWc2OsbnSf" src="https://cdn.sspai.com/editor/u_/ckj0b85b34tdhbcubb8g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>这里可以看一下安装命令，不难发现安装了 torch、torchvision、torchaudio 这三个包，把它们的名字记一下，后面可能用到。</p><figure class="image ss-img-wrapper"><img alt="NWznb96cOoQWKGxHaSdclue5nbf" src="https://cdn.sspai.com/editor/u_/ckj0b8db34tdhbcubb90?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>除了安装 PyTorch 外，想要让项目正常运行，还需要安装 requirements.txt 文件中规定的所以库才行。正常支持 Windows 的项目会有一个额外的 requirements_win.txt 文件，有的话就用这个文件，没有就用 requirements.txt。在安装之前最好先打开这个文件，看看里面的库名是否包含之前安装过的那三个包，如果包含的话就先手动删去，避免重新安装到错误的版本。准备工作完成后运行如下命令：</p><pre class="language-"><code>pip install -r requirements_win.txt -i https://mirrors.aliyun.com/pypi/simple/
</code></pre><p>如果安装过程不报错那就皆大欢喜，但是报错了也不用慌，大部分都是包的版本问题，解决起来不算难，下面举几个例子作为参考。</p><h4>常见错误 1</h4><figure class="image ss-img-wrapper"><img alt="PReIbQkmloVHG6xsGSLcKWHPnVh" src="https://cdn.sspai.com/editor/u_/ckj0b8lb34tdivk90qug?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>这个错误是因为 gradio 没有符合要求的版本号，解决办法很简单，把 txt 文件中这个包的版本号删去，让包管理器自动寻找最新版本即可。</p><figure class="image ss-img-wrapper"><img alt="IPHebeG67oRJKoxJSEicmv4Dny5" src="https://cdn.sspai.com/editor/u_/ckj0b8tb34tdhbcubb9g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><h4>常见错误 2</h4><figure class="image ss-img-wrapper"><img alt="TvrMbTupToMM9nxXSRic15Uqnjb" src="https://cdn.sspai.com/editor/u_/ckj0b8tb34tdivk90qv0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>这个错误是因为多个不同的包对 numpy 版本的要求不同，包管理器无法找到符合所有包需求的 numpy 版本。解决方法其实报的错误信息里已经写了，就是删去这些库的版本号，可以逐个删除尝试，尽可能少的修改 txt 文件。</p><h4>常见错误 3</h4><figure class="image ss-img-wrapper"><img alt="QcjnbtLHmoAb2IxtZRicQdQTnDe" src="https://cdn.sspai.com/editor/u_/ckj0b95b34tdh3ari820?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>这个错误发生的原因很多，解决办法也相应比较多，可以按照错误提示中说的，试试看升级 Pip，或者是安装 Rust 编译器。除此之外还有一种解决办法就是限制一下对应包的版本号，比如我碰到的这个问题只需要将 transformers 的版本号限定在 3.4 即可。</p><figure class="image ss-img-wrapper"><img alt="GWZ6bH7laokCgoxfCrKcSJnHnzh" src="https://cdn.sspai.com/editor/u_/ckj0b9db34tdh3ari82g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>下面放一张<strong>安装成功</strong>的截图，希望各位都能一次成功。</p><figure class="image ss-img-wrapper"><img alt="Hjyhb0qdnoldmcxRem8cHzMBnSc" src="https://cdn.sspai.com/editor/u_/ckj0b9lb34tdh3ari830?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><h3>运行命令</h3><p>之前项目部署那里提到过部分内容，比方说激活虚拟环境的命令：</p><pre class="language-"><code>conda activate .\env
</code></pre><p>激活环境后就可以按照项目文档中写的训练命令来依次执行了，不过如果是简单的 Python 命令的话也可以不激活环境，直接写出解释器的路径也可以调用，比如：</p><pre class="language-"><code>.\env\python webUI.py
效果等同于
conda activate .\env

python webUI.py
</code></pre><p>有时候部分命令需要频繁使用，每次都打开 CMD 窗口输入命令未免过于麻烦，这时候我们可以编写一个 bat 后缀的文件来简化操作。</p><p>创建的方法也很简单，右击新建一个文本文档，也就是 txt 文件，然后将其重命名为 bat 拓展名的文件即可。双击这个文件就会自动在当前路径执行其中的命令。如果是想要修改其中的命令，右击文件后点击编辑即可。下面给出一个通用的模板：</p><pre class="language-shell"><code>@echo off
call conda activate .\env
python webUI.pypy

pause
</code></pre><p>简单解释一下各个语句的意思，第一行表示关闭命令行输出，第二行表示激活当前环境，第三行写上任意想要运行的命令，第四行表示运行完成后等待用户确认再关闭命令行窗口。</p><h2>数据集准备</h2><p>学会上面这一套基本所有的开源 AI 项目就都可以自行部署到本地了，可以说是实现了整合包自由，看上哪个项目直接上手玩就是了。本节则是分享一下我个人处理语音数据集的经验。</p><h3>基础知识</h3><p>整理数据集之前，请<strong>务必先搞清楚</strong>自己训练语音模型的<strong>用途</strong>，明确是唱歌用还是说话用，一个人唱歌和说话时的音色是有很大差别的。</p><p>唱歌用数据集的要求一般更高一些，除了时长的要求，音域也需要尽可能全覆盖，说简单点就是高音、低音最好都有，不然最后出来的模型就会在数据集缺失的音域产生哑音或音色失真之类的缺陷。</p><p>我本人五音不全，也曾经训练过自己音色的唱歌模型，结果只能说惨不忍睹，事实证明你本来唱不上去的调，换成 AI 还是唱不上去。唱歌数据集如果时长实在有限，可以适当添加一些音色相近的说话素材，但不能太多，质量大部分时候都比数量更重要。说话数据集就简单许多，尽量选用音色相近的正常语音素材即可。</p><h3>获取音频素材</h3><p>这里其实分几种情况，主要是根据训练模型的<strong>目的</strong>来划分。</p><p>第一种是只想要一个听着舒服的音色来进行 TTS 文本转语音，第二种是想先随便找点素材练练手看看效果。这两种需求最简单的素材获取方式就是去类似喜马拉雅、蜻蜓 FM 的音频网站上找一个主播，直接把他所有的音频下载下来，简单处理之后就可以开始训练。</p><p>第三种是想要训练自己或朋友的 AI 语音模型，这个有两种常见的处理手法，一种是用 Au 之类的录音软件专门录制干声，一种是使用 Voicemeeter 之类的虚拟声卡软件将平常微信或 QQ 电话的音频录制下来。当然，如果是训练朋友的模型，请务必取得他的同意。如果是想要训练唱歌用的模型，可以安装一些 K 歌类的软件，大多都可以将音频保存下来，平常没事的时候唱几首，时长够了也就可以开始动手训练了。</p><p>第四种是想训练某个明星或主播的模型，歌星的话直接用他歌曲的人声部分即可；主播的话麻烦一点，得找直播切片提取出音轨；影视明星更加麻烦，得慢慢找视频素材单独切出角色语音，不是真爱或者闲得蛋疼不推荐尝试。</p><h3>处理素材</h3><p>这里讲一些常用的素材处理技巧，可以极大地提高处理效率。</p><h4>人声分离</h4><p>很多素材都会有背景音乐，人工去除难度太大，此时需要借助一些专用软件。我这里只推荐使用 <a href="https://ultimatevocalremover.com/" target="_blank">UVR5</a>，目前市面上最强的免费声音分离软件。使用起来也非常简单，直接去官网下载安装好之后打开保持默认，勾选上 Vocals Only 选项，点击开始转换即可。</p><figure class="image ss-img-wrapper"><img alt="URI9bKEwJo4LGUxoRt6cQdgVnyc" src="https://cdn.sspai.com/editor/u_/ckj0b9tb34tdh3ari83g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>Vocals Only 选项就是只输出人声音轨，不输出伴奏音轨。图中的这套配置可以轻松去除纯音乐的背景音，不过如果 BGM 是带有人声的歌曲就无能为力了，歌曲中的人声也会被保留。我本人对这个软件也没啥深入的研究，更多需求大家自行研究一下。</p><h4>文件重命名</h4><p>这个步骤非常关键，主要是很多项目都不支持中文文件名，所以素材在切片之前最好先重命名一下。文件数量少的话手工改一下问题不大，数量太多的话就比较头疼了。目前市面上批量重命名的工具不少，大家各显神通即可。我本人比较习惯用 Python 脚本，这里简单分享一个，大家会用就用。</p><pre class="language-python"><code>import glob
import os

if __name__ == '__main__':
    index = 1
    for file in glob.glob("*.wav"):
        os.rename(file, "{:04d}.wav".format(index))

        index += 1
</code></pre><h4>批量切除部分片段</h4><p>有时候一些音频会有一个统一时长的开场白或结束语，手动切除就会很麻烦，这里同样给出一个 Python 脚本。</p><pre class="language-python"><code>import glob
import os

from pydub import AudioSegment


def cut_one(input, output):
    audio = AudioSegment.from_file(input, format="mp3")
    # 切除开头 8 秒
    audio = audio[8000:]
    audio.export(output, format="mp3")


if __name__ == '__main__':
    for file in glob.glob("*.mp3"):
        out = os.path.join("cutted", os.path.split(file)[-1])

        cut_one(file, out)
</code></pre><h4>合并短音频</h4><p>这个需求比较少见——比如有时候会用到一些游戏的角色语音来作为训练素材，但是这些素材可能单条都只有几秒钟时间，不太符合训练切片的时长要求。这时候可以使用 Au 这样的图形化软件手动拼接，也可以借用脚本，同样给出一个示例。</p><pre class="language-python"><code>import glob

from pydub import AudioSegment


if __name__ == '__main__':
    index = 1
    for file in glob.glob("dirname/*.ogg"):
        if index == 1:
            audio = AudioSegment.from_ogg(file)
        else:
            audio += AudioSegment.from_ogg(file)
        print(index)
        index += 1

    audio.export("merged.wav", format="wav")
</code></pre><h4>音量统一</h4><p>很多项目会有内置的脚本进行音量处理，如果没有就只能自己动手了，因为这个步骤是<strong>必不可少</strong>的，不然最终训练出来的模型也会出现类似的问题。想要达到最好的效果肯定是使用 Au 这样的专业软件进行调整，但是如果怕麻烦的话也可以使用脚本解决。</p><pre class="language-python"><code>import glob
import os

from pydub import AudioSegment

if __name__ == '__main__':
    # 统一化的音量大小，单位 dB
    target_db = -10
    os.makedirs("normalized", exist_ok=True)
    for file in glob.glob("dirpath/*.wav"):
        basename = os.path.basename(file)
        audio = AudioSegment.from_file(file)
        current_db = audio.dBFS
        db_diff = target_db - current_db
        normalized_audio = audio + db_diff
        normalized_audio.export(
            os.path.join("normalized", basename),
            format="wav"

        )
</code></pre><h4>批量切片</h4><p>切片是准备数据集必不可少的步骤，大部分项目对单条音频的时长都有限制，大多为 5~15 秒，手工切是肯定不可能的，毕竟几千条能把人累死，目前用的最多的是 <a href="https://github.com/flutydeer/audio-slicer">audio-slicer</a>，有带图形化界面的版本，使用的时候保持默认设置即可。</p><figure class="image ss-img-wrapper"><img alt="VjaobjlnKo9txYxfYwbcH4J0nfd" src="https://cdn.sspai.com/editor/u_/ckj0b9tb34tdivk90qvg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><h4>删去过长过短音频</h4><p>这个操作非常简单，为了处理过程的完整性简单提一下。将切片好的文件夹属性设置为常规文件，然后根据数据大小排序，依照顺序删去过长或过短的音频即可。</p><h4>需要标注文本的音频</h4><p>之前提过，训练文本转语音模型需要对音频进行文本标注。因为不同的项目对文本的标注格式会有些许差别，仔细看项目文档就是了，大部分项目会给出标注建议和相关工具，依照指示操作即可。</p><h2>训练进度查看</h2><p>对于很多新手朋友来说，训练模型时最大的疑惑可能就是怎么样算是训练完成了？如何判定训练进度是一件非常重要的事，不然闷头训练很容易浪费时间。要知道，<strong>模型并不是训练的时间越长效果越好</strong>。训练步数过多很有可能出现过拟合的情况，纸面参数好看结果却完全不如低步数时的效果。</p><p>目前大部分模型的训练代码中都会添加 tensorboard 的相关支持，借由 tensorboard 我们就可以在训练的过程中实时跟踪关键训练参数。判断一个项目是否支持 tensorboard 很简单，直接看之前搭建环境时提到的 requirements.txt 文件即可，里面如果有这个包的名称就是支持的。</p><p>怎么打开参数面板也很简单，首先找到模型训练时保存 checkpoints 和日志的文件夹，一般就叫 logs，在里面找到带有 <strong>events</strong> 打头文件的文件夹，这里要注意，这种文件只有在开始训练模型并在命令行产生输出后才会生成。</p><figure class="image ss-img-wrapper"><img alt="R9gzb99BTogiCjxcnMFcqT94n5g" src="https://cdn.sspai.com/editor/u_/ckj0ba5b34tdhbcubba0?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>找到后记下其所在文件夹的路径，无论是绝对路径还是相对路径皆可，然后再开一个命令行窗口激活虚拟环境后输入下面的命令：</p><pre class="language-"><code>tensorboard --logdir dirname
</code></pre><p>命令中的 dirname 自行替换，如果出现如下输出则代表运行成功：</p><figure class="image ss-img-wrapper"><img alt="MmotbwDCdo5DZ4xhuOCcq1cjnCD" src="https://cdn.sspai.com/editor/u_/ckj0badb34tdh3ari840?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>打开命令行中的本地链接后就可以看到监测面板：</p><figure class="image ss-img-wrapper"><img alt="HFTrbJhzXoaMAPxy9GUciLEbn7c" src="https://cdn.sspai.com/editor/u_/ckj0balb34tdhbcubbag?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>里面的数据根据不同的项目会有差别，有的详细，有的可能只有 loss 这一部分。看不懂没有关系，会看曲线就行。其实大部分情况只看一张 loss 的图就够用了，有些叫 total，有些叫 reference loss，简单理解就是总偏差，一般这张图的曲线趋于平稳之后就可以结束训练了。</p><p>训练结束后就是纯主观的听音环节了，如果面板上有 AUDIO 选项卡的话可以进入其中试听不同步数下的转换效果，框定一个大致的步数范围，然后可以挑选几个听下来不错的模型，找一些音频素材让其实际转换一下，再细品一下到底把哪个模型文件作为最终成品。很多时候并不是步数最高的模型效果最好，我就碰到过一个好玩的例子，特地训练了一个烟嗓的女声模型，结果训练到后面把烟嗓给训练没了，反倒是步数少的模型更加原汁原味。</p><h2>训练参数设置</h2><p>最后再提两个训练的小技巧，如果你的硬盘空间足够大的话，建议把训练参数中保留的 checkpoints 数量调大一点，像我一般直接调成 100，这样挂一晚上之后所有的记录点模型都在，不会出现训练过头导致真正效果好的模型被删除而只能从头再来的折磨。另一个技巧就是如果参数中支持将训练数据一次性全部加载到内存中的话，在内存容量足够的情况下请务必开启这一功能，可以大大提高训练速度。</p><figure class="image ss-img-wrapper"><img alt="LGy6bu90VoZ99DxNNzfcjFesnXc" src="https://cdn.sspai.com/editor/u_/ckj0balb34tdh3ari84g?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /></figure><p>还有一个注意点，如果不是特殊需求的话，最好训练单人模型，因为单人模型后期进行音色融合的话更加简单灵活。我自己现在常用的就是两个音色融合之后的模型。</p><h2>批量转换脚本</h2><p>我本人现在用的是 so-vits-svc-4.1-Stable，最开始的个人应用中提到的批量转换脚本如下，放在项目根目录就可以运行。因为是临时写的，也没有仔细优化过，代码写的比较乱，看不懂就只改最前面几个大写的参数。实在不会用就算了，用项目自带的网页工具手动转换也一样。</p><pre class="language-python"><code>import asyncio
import edge_tts
import glob
import librosa
import numpy as np
import os
import re
import soundfile

from inference import infer_tool
from inference.infer_tool import Svc

# 微软 TTS 参数
# 音色，云希虽然是男声，但是说话节奏是最好的，不建议修改
VOICE = "zh-CN-YunxiNeural"
# 说话速率，根据喜好来
RATE = "-20%"
# 音量增强，根据喜好来
VOLUME = "+50%"

# 模型参数
# 模型文件路径
MODEL = "trained/female_RuiQian/female_RuiQian.pth"
# 模型对应配置文件路径
CONFIG = "trained/female_RuiQian/config.json"
# 说话人名称
SPEAKER = "female_RuiQian"


async def generate_one(filepath) -&gt; None:
    # 读取 txt 文件内容
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read().replace("　", "").replace(" ", "").replace("\n", "").replace("\t", "").replace("\a", "")
    # 微软 TTS 生成语音和字幕的保存路径
    base_name = os.path.basename(filepath)
    name = os.path.splitext(base_name)[0]
    media = os.path.join("results", "raw_{}.mp3".format(name))
    subtitle = os.path.join("results", "{}.vtt".format(name))
    # 创建并保存微软 TTS 语音和字幕文件，需要联网，速度较慢
    communicate = edge_tts.Communicate(text=text, voice=VOICE, rate=RATE, volume=VOLUME)
    submaker = edge_tts.SubMaker()
    with open(media, "wb") as file:
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                file.write(chunk["data"])
            elif chunk["type"] == "WordBoundary":
                # 向字幕文件中加入标点符号
                chunk_text = chunk["text"].replace(" ", "")
                pattern = "^" + chunk_text.replace("", ".*?").rstrip(".*?") + r"""[，。”：；、？）》}】！,.'";:?)&gt;}\]]*"""
                chunk_text = re.match(pattern, text).group()
                print(chunk_text)
                text = text[len(chunk_text):]
                submaker.create_sub((chunk["offset"], chunk["duration"]), chunk_text)

    with open(subtitle, "w", encoding="utf-8") as file:
        file.write(submaker.generate_subs())

    # 音频数据预处理，将 TTS 生成的 mp3 文件转为 wav
    target_sr = 44100
    y, sr = librosa.load(media)
    resampled_y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)
    processed_audio = os.path.join("results", f"processed_{name}.wav")
    soundfile.write(processed_audio, resampled_y, target_sr, subtype="PCM_16")

    # 加载语音模型
    model = Svc(MODEL,
                CONFIG,
                device=None,
                cluster_model_path="",
                nsf_hifigan_enhance=False,
                diffusion_model_path="",
                diffusion_config_path="",
                shallow_diffusion=False,
                only_diffusion=False,
                spk_mix_enable=False,
                feature_retrieval=""
                )
    # 模型推理参数
    kwarg = {
        "raw_audio_path": processed_audio,
        "spk": SPEAKER,
        "tran": 0,
        "slice_db": -40,
        "cluster_infer_ratio": 0,
        "auto_predict_f0": True,
        "noice_scale": 0.4,
        "pad_seconds": 0.5,
        "clip_seconds": 0,
        "lg_num": 0,
        "lgr_num": 0.75,
        "f0_predictor": "rmvpe",
        "enhancer_adaptive_key": 0,
        "cr_threshold": 0.05,
        "k_step": 100,
        "use_spk_mix": False,
        "second_encoding": False,
        "loudness_envelope_adjustment": 1
    }
    # 音色转换推理
    audio = model.slice_inference(**kwarg)
    model.clear_empty()
    res_path = os.path.join("results", "{}.wav".format(name))
    # 保存最终音频
    soundfile.write(res_path, audio, model.target_sample)


async def generate():
    # 提前在根目录创建一个 text 文件夹，把要转换的 txt 文件放在里面
    for file in glob.glob("text/*.txt"):
        await generate_one(file)


if __name__ == "__main__":
    loop = asyncio.get_event_loop_policy().get_event_loop()
    try:
        loop.run_until_complete(generate())
    finally:

        loop.close()
</code></pre><h2>后记</h2><p>目前 AI 发展的势头非常迅猛，说是日新月异也不为过。之前就看到过有人被 AI 工具换脸变声后的视频通话骗取大量财物的新闻，有人可能觉得这样的诈骗成本很高，自己一个普通人不可能碰到，但是事实上，这样的诈骗效果使用目前市面上那些开源的项目就能基本实现。别的不说，单就声音而言，如果你依照文中的内容实际体验过训练过程的话就会知道，克隆一个人的声音并不困难。如果你看了本篇文章但是并不想训练语音模型，也请更加注重自身隐私数据的保护，提高防范意识。</p><p style="margin-left: 0px;">&gt; 下载 <a href="https://sspai.com/page/client">少数派 2.0 客户端</a>、关注 <a href="https://sspai.com/s/J71e">少数派公众号</a>，解锁全新阅读体验 📰</p><p style="margin-left: 0px;">&gt; 实用、好用的 <a href="https://sspai.com/mall">正版软件</a>，少数派为你呈现 🚀</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://sspai.com/post/83042</id>
            <title>3 年、4 个库目录、100 万字——也谈我的 Obsidian 笔记工作流</title>
            <link>https://sspai.com/post/83042</link>
            <guid isPermaLink="false">https://sspai.com/post/83042</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Sep 2023 07:26:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 748227, 102072, 68286, 66743
<br>
<br>
总结: 这篇文章讨论了信息处理的重要性和如何构建高效的信息处理管线。作者分享了自己在使用Obsidian进行笔记管理的体验，并介绍了Obsidian的多种用途，包括作为笔记板应用、浏览器书签存储处、文档和演示文稿编写之处、模板库和仪表板。作者选择Obsidian的原因是因为它能够满足他对信息处理的需求，并提供了便捷的功能和工具。 </div>
                        <hr>
                    
                    <p>748227、102072、68286、66743。这是我在写下这篇文章前，四个笔记库的字符数统计。算上这篇文章，我在 Obsidian 中写下的文字已经超过了一百万字。从有道笔记、OneNote、VNote 到 Obsidian，每一次对工具的权衡利弊与重新选择都是我对自己的笔记工作流，以及我的信息处理管线的重新审视与思考。</p><p>这篇文章不仅限于 Obsidian 这一个工具，也不会围绕着几乎是匠气大于能力的双链笔记法继续陈词滥调。关键的是内容，而非工具：探讨如何高效的处理爆炸的信息输入，实际上是对思维的一种优化。作为自己第一篇在少数派上同步发布的文章，我希望能和各位读者分享我的这些体会，也希望能从互动中汲取更多经验，在生产力体验上共同精进。</p><h2>信息——输入与输出</h2><p>信息是什么？<br />维基百科有言：“信息是反映（映射）事件的内容。”<br />信息的本质在于流动。静止的信息不具有意义：事件需要发生、内容需要理解、知识需要应用。每一位信息工作者实际上都是一个输入与输出的中介，而其工作的基础是一个缓存体系。如果载体是人脑，那么缓存就是记忆；如果载体是纸张、电子设备，那么缓存就是笔记和文件。信息只有在中介间不断流动才能产生价值。<br />因此，一个高效的信息处理管线可以简单的被归纳为如下的三个方面：</p><ul><li>输入：<ul><li>应当能够有效容纳几乎任何信息类型；</li><li>应当尽最大可能以最原始的信息形式暂存；</li><li>应当有适当的存储位置；</li></ul></li><li>缓存：<ul><li>应当有成体系的缓存层级：从即弃类信息（比如每天的新闻简报）、到需要短期存储（比如一个短期项目的素材）、再到需要长期甚至永久存储（比如知识与技能的佐证）；</li><li>应当能有效管理和蒸馏信息；</li><li>应当易于与思考配合；</li></ul></li><li>输出：<ul><li>应当有便捷的输出模式；</li><li>应当能以多样化的信息类型输出内容；</li><li>应当能持续稳定的输出优质内容，而不至于复制粘贴，不加思考；</li></ul></li></ul><p>下文中，我将从笔记（着重于 Obsidian）和其他方面介绍我对这一体系的理解。</p><h2>笔记</h2><h3>使用 Obsidian 做什么？</h3><p>Obsidian 可能比我电脑上任何非系统必须的进程打开的时间都要长。它一定是我每天开机自启动的应用，也一定是我每天关机前最后一个关闭的应用。<br />&nbsp;</p><figure class="image ss-img-wrapper image_resized" style="width: 311px;"><img src="https://cdn.sspai.com/2023/09/18/1c4c104451a845a4cc62daf6ffb517eb.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>笔记树</figcaption></figure><p><br />除了传统意义上的笔记之外，Obsidian 还是：</p><ul><li>我默认的笔记板（Notepad）应用；<br />这个称呼是刻意选择的。它被我定义为：任意一个能够便捷的输入文本并自然的对较长段文本进行编辑的应用。<br />笔记板应用相当的有用，它是大部分编辑的基础，除了暂存和编辑一般的文本之外，还有命令行指令与代码，尤其是在 Linux 这样一个重度依赖文本进行命令行操作的环境下。</li><li>我浏览器书签的存储处；<br />长久的在浏览器本身同步之后，我发现大部分浏览器的文件夹式/树状书签管理以及很多扩展所实现的书签页面都不是书签的最佳展示方式。它们大多不能一次性展示多层归类结构，对显示空间的利用率相当的低，并且并不像简单的剪贴板粘贴一样适用于多样化的分享。因此，我最终选择了把所有书签从浏览器中导出，并转换为了 Obsidian 中的无序层级列表。</li></ul><figure class="image ss-img-wrapper image_resized" style="width: 378px;"><img src="https://cdn.sspai.com/2023/09/19/e8911a2b82d98698bb99fb5404caa6cb.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>浏览器书签。一系列我推荐的个人博客。</figcaption></figure><ul><li>我大部分输出文档和演示文稿的编写之处；<br />除了 Markdown 和原生自带的导出之外，其 LaTeX 编辑功能配合 <code>pandoc</code> 也为我的学习提供了相当程度的便利。下文会提到这一点。</li><li>我日常工作所必备的模板库；<br />Obsidian 作为一个恒定打开的软件，存放了大量日常使用的文本段落和预编写的代码/脚本以便于我随时复制粘贴使用。</li><li>我许多工作与爱好的仪表板；<br />使用一点 HTML 与 iframe，笔记页面中就能展示许多有用的信息无论信息存储在何处，信息工作者都是促使信息流动的关键，他们确保信息能够在事件发生、内容理解和知识应用之间流通畅通，从而创造意义和价值。。相较于 Notion 等的精心拼凑、高级 Query，一个制作简单、使用暴力的仪表板反而会成为相当实用的利器。</li></ul><h3>为什么选择 Obsidian？</h3><p>在使用 Obsidian 之前的许多应用都只是我尚未形成信息处理流时的过度选择，这里暂且不表。但 Obsidian 前，我使用的最后一个应用，<a href="https://github.com/vnotex/vnote">VNote</a>，值得一提。<br />使用 VNote 时正是我信息管理意识的启蒙时期。当时的我尚且对笔记方法论一无所知，Markdown 都写不顺手，试遍了当时几乎所有小众笔记软件都未能感觉到记录信息的酣畅淋漓。在这种情况下，我遇到了 VNote，其所使用的 Markdown，以及其对 Markdown 和笔记的阐释。<br />至今，这些阐释依然保留在 VNote 的<a href="https://app.vnote.fun/zh_cn/#!docs/%E7%94%A8%E6%88%B7/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%20VNote.md">文档</a>中：</p><blockquote><p>Markdown 作为一种简单的标记语言，与富文本不同，与生俱来就带有<strong>编辑和阅读之间的鸿沟</strong>。处理该鸿沟的方法一般有三种：</p><ol><li>作为一个极端，一些编辑器只是将Markdown视为<strong>纯文本</strong>。用户可能会迷失在凌乱的黑色字符中，<strong>难于追踪</strong>笔记的信息脉络。</li><li>大多数Markdown编辑器使用两个并排面板以<strong>同时编辑和预览</strong>Markdown笔记。它使事情变得更加简单，因为用户可以在编辑文本的同时预览到一个美观的排版和布局。但是，两个面板可能占据整个屏幕，并且用户要不断左右移动视线，这使用户极其容易分心。</li><li>另一个极端是，一些编辑器在用户输入后马上转换Markdown元素，使得在使用Markdown时就像使用一些快捷方式在Word里编辑富文本文档一样。这可能与Markdown的设计目标相冲突。</li></ol><p>由于大多数编辑器选择第二种方式，因此很多用户一提起 Markdown 就会想起实时预览。这可能是一个对 Markdown 的<strong>误解</strong>。定位为简单的标记语言，Markdown 旨在帮助在编辑时方便跟踪文本信息，并在转换为 HTML 后进行阅读时提供漂亮的排版。</p></blockquote><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/09/19/1a748fe7fcb409f0c7537a1e54d1ddad.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>四种不同的编辑器，四种不同的呈现方式。</figcaption></figure><p>由此便演化出了我对 Markdown 的理解：</p><blockquote><p>Markdown 的语法设计目标实际上是允许不渲染的纯文本也能被没有预先了解的读者<strong>脑补排版</strong>。</p></blockquote><p>由此理解，Typora 显然并不达标：它只是一个用了 Markdown 语法作为快捷键的 “所见即所得”（WYSIWYG）编辑器，从某种意义上甚至比 Word 还差：编辑中随时识别格式并消除格式化文本的举措会形成巨大的<a href="https://web.dev/i18n/zh/optimize-cls/">布局偏移</a>，加重编辑时的眼动和操作压力。另一方面来说，虽然 Markdown 熟练者能够直接编辑纯文本撰写格式，但是能在编辑纯文本时有恰当的排版格式指引视觉动线更有利于有效的反馈式写作。<br />而当时，VNote 面临 3.0 版本大跨越的门槛，许多我习惯的设计逻辑都将作出改变，而这时 Obsidian 的出现完美的满足了我的要求。<br />对于许多文本编辑器，特别是代码编辑器来说，它们选择了相对保守的做法，在 Markdown 语法上添加高亮以做区分。而对于 VNote，以及 Obsidian 的“源码模式”来说，它们所作出的许多更进一步的操作（例如原地渲染标题、粗体/斜体，加载图片等）恰如其分的带来了 Markdown 应有的编辑体验。<br />也因此，Markdown 源文件也应当被当做一个部分排版的文件处理，需要考虑纯文本浏览时的美观性。例如，</p><ul><li>尽可能使用软换行；<br />虽然 Markdown 标准鼓励硬换行或者行尾两空格，少数派甚至有<a href="https://sspai.com/post/73957">编辑文章</a>专门谈使用硬换行的问题，但是软换行符合绝大多数人阅读的习惯以及纯文本处理管线的逻辑，对于文本多格式少的文件更加适当；</li><li>尽可能使用原生语法；<br />这个特例特别指 Obsidian。例如图片插入等语法虽然 Obsidian 有自己的语法替代，但是我还是推荐尽可能使用 Markdown 的原生语法。这可以改进文件的可迁移性，也符合 Obsidian 自身“离线存储，永不倒闭”的卖点。</li></ul><p>同时，也不要忘了 Markdown 格式的灵活性。数学语法，流程图甚至行内 HTML 等等使用方法，如果恰当也不要因为什么“Markdown 原教旨主义者”的言论而忌讳使用。不要忘记，<strong>关键的是内容，而非工具。</strong></p><h3>如何正确使用 Obsidian？</h3><p>Obsidian，与 Roam Research、Logseq 等等“生产力界的 EDC 文玩”都常常被与一种特定的笔记方法论绑定，例如原子笔记、例如 Zettelkasten、例如双链。但在我的笔记库中，含有链接的文件不过寥寥，小于千字的文件也是绝对少数。为什么我对这些方法论完全不感冒？</p><p>基于双链的原子笔记、卡片笔记最终会散落成一地无所适从、无从找起的卡片。双链，无论任何形式，链接的本身是不带属性的。为了理解一个链接所连起的信息原子的关系，两端的内容都需要互相引用，这本身就是记录上的浪费。同时，双链无法表示任何多次转移的逻辑关系，一条完整的逻辑链条被拆分成一个个需要逐步查看逻辑关系，甚至根本没有记录逻辑关系的论点，每次重新利用时都需要从头建立理解，对于构建所谓的“知识网络”没有任何帮助。更进一步的，双链需要时时维护，而维护的过程会无数次陷入“这一点内容是填入这张卡片还是那张卡片”的决定，累积起来的精神压力会使得笔记维护越来越称为一个精神负担，最终被放弃。</p><p>双链笔记宣扬一种“贴近人脑的思维模式”的概念，然而这完全是一个伪命题。资深 Obsidian 使用者 Eleanor Konik 在名为“Obsidian 是我的思考环境，不是我的第二大脑”的<a href="https://www.eleanorkonik.com/ite-not-second-brain/">文章</a>中有这样五个小标题，总结的尤为恰当：</p><blockquote><p>Obsidian doesn't do my thinking for me.<br />Our brains do more than record, reshuffle and regurgitate information.<br />If a computer isn't a second brain, nothing is.<br />None of my thinking is done by a tool.<br />My perfect auxiliary brain would not be a notetaking app.</p><p>Obsidian 不能代替我思考。<br />我们的大脑所做的比记录、重组、再输出信息多得多。<br />如果电脑不是第二大脑，那没有什么会是。<br />我的思考不是由工具所做的。<br />我最完美的辅助之脑不会是一个笔记软件。</p></blockquote><p>因此，我依然坚持一种近乎“传统”的笔记模式：分门别类树状归纳信息体系，几乎不使用双链，以大篇幅记录一个足够独立的信息集合体，如一篇 Wiki 一样。日积月累，我的笔记几乎发展成了一本覆盖面广泛的书籍，而书籍（特别是教科书）的优点正是信息清晰翔实、观点一致明了、便于理解记忆。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2023/09/19/3b8cd9839b59eb001def29a98a8aa9b7.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" /><figcaption>多样的笔记形式。请不要在意内容。</figcaption></figure><p>同时，不要忘记，人脑也是缓存中重要的组成部分。因此，记录笔记时，尝试着籍由选择归类这一点重新审视整篇笔记，并在大脑中直接对笔记的标题、大致内容和储存位置有所记忆。让大脑中的记忆成为笔记的第一索引，然后是模糊搜索，最后才是逐个文件夹翻找。不要把这部分大脑理解信息所必备的记忆偷懒的交给双链体系。之后，定期维护笔记库，尝试着一次又一次重写笔记，精简概念，蒸馏信息，提升笔记的思维质量同时强化记忆。灵感不能通过在双链体系中四处乱逛而产生，思想必须内化于记忆中才能产生创造力。</p><p>同样的，再次强调，<strong>关键的是内容，而非工具，</strong> 因此，一些花里胡哨的笔记制作方法，例如过度精细的可视化、在格式上纠结无尽但内容不存思考只有复制粘贴的思维导图、精心维护却不填内容的 Notion 页面等等，本质上来讲并不是提高生产力，最多只能算一种角度奇异的爱好。因此，我几乎不使用任何增强“编辑”这件事本身之外的插件，也极少折腾主题的自定义选项。</p><h2>文件</h2><p>不过，在电子设备上所接受的信息，除了文本之外还有许多其他类型，都多以文件的形式存在，或者能被转化为文件。“输入——缓存——输出”的模型套用在这里，我称其为“Inbox - Queue - Outbox”。</p><h3>Inbox</h3><p>这是信息输入的第一道防线：粗筛选。<br />无论这些文件来源为何，需要如何处理，首先全部收入 Inbox 文件夹，避免信息丢失。之后，依据信息的类型进行分类处理：</p><ul><li>如果是立刻就可以完成处理、或者没有必要进行任何处理的内容，例如需要转发分享的文件，那么就可以直接从 Inbox 中送往需要发送的地方；</li><li>如果是需要短期内合并保存的内容，例如为一个项目收集的素材，那么就在 Queue 中新建一个相关的子分类存放其中；</li><li>如果是需要长期保存的内容，例如书籍、文档、音乐、视频等，那么就从 Inbox 中送往对应的保存处；</li></ul><p>存在一个 Inbox 文件夹的好处有很多，例如：</p><ul><li>在收集信息时不需要被任何“这份信息我需要保留吗？丢失了会造成之后的生产力损失吗？”这样的问题所困扰，一份信息的重要性和去留问题可以留到之后循序渐进的解决；</li><li>Inbox 内容的大小直观反应信息的接收量，有效利用这个计量可以显著的控制数字焦虑；</li><li>今日事今日毕，清空 Inbox 能够稳定的实现一个“工作完成”的正向心理反馈，所产生的直观的成就感有利于提高工作效率；<ul><li>同样的，对于邮件等等，清空 Inbox 也是一个相当好的习惯；</li></ul></li></ul><h3>Queue</h3><p>需要短期缓存的内容进入 Queue 文件夹，分门别类（通常是时间上相关的内容），其相关联的事项就等同与排上了日程。Queue 中的信息要么进入笔记或者其他长期存储，要么随着事项的完成而被移除。正如其名所述，Queue 文件夹的管理最好遵循先进先出（First In First Out，FIFO）的规则，对信息也设置适当的截止期。这样的信息管理方式也能反哺日程管理，减少拖延症发作。</p><h3>Outbox</h3><p>信息蒸馏、内化与重组的结果就是产出。内容的产出要兼顾思维质量和易读性、美观性，才能与接受者产生共鸣。这才是纠结美轮美奂的呈现效果的时候。<br />虽然 Obsidian 自带的导出相当完善，也能最大程度的还原 Obsidian 中显示的效果，但是对于高级排版有要求的文档，我依然选择使用 <code>pandoc</code> 进行导出。</p><h2>结语</h2><p>本篇文章没有试图去介绍我具体如何使用 Obsidian 的技巧，而是尽可能的偏重于我对笔记方法论的感悟与个人体会。文章的逻辑可能有些沉重，希望看到最后的你能有所共鸣。<br />感谢阅读。</p><p>&nbsp;</p><p><i>题图 Photo by </i><a href="https://unsplash.com/@pedroaraujo74" target="_blank"><i>Pedro Araújo</i></a><i> on </i><a href="https://unsplash.com/photos/ZG4Tz-ivLb8" target="_blank"><i>Unsplash</i></a><i>.</i></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>