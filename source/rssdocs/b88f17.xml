<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738282594943275508#m</id>
            <title>推荐一下，Chatbot UI这个开源项目一直在持续更新，越做越好了

https://github.com/mckaywrigley/chatbot-ui</title>
            <link>https://nitter.cz/dotey/status/1738282594943275508#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738282594943275508#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 19:37:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一下，Chatbot UI这个开源项目一直在持续更新，越做越好了<br />
<br />
<a href="https://github.com/mckaywrigley/chatbot-ui">github.com/mckaywrigley/chat…</a></p>
<p><a href="https://nitter.cz/mckaywrigley/status/1738273242283151777#m">nitter.cz/mckaywrigley/status/1738273242283151777#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzQ4MzYzMDgwMzMyMDgzMi8tVlRZUThycz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738269094737293581#m</id>
            <title>RT by @dotey: 上海人工智能实验室又搞了一个即插即用的图像生成视频模型。
主要特点是根据不同的文本提示以动作进行动画处理，同时保留原始的独特风格和高保真度的细节。

项目简介：
我们提出了PIA，一种个性化图像动画生成器，它在与条件图像对齐、通过文本实现动作可控性以及与各种个性化T2I模型的兼容性方面表现出色，而无需特定调整。

为了实现这些目标，PIA基于一个经过良好训练的时间对齐层的基础T2I模型，允许将任何个性化T2I模型无缝转换为图像动画模型。

PIA的一个关键组成部分是引入条件模块，它利用条件帧和帧间关联作为输入，在潜在空间中通过关联提示来传输外观信息，以指导个别帧的合成。

 这种设计减轻了外观相关图像对齐的挑战，并允许更加专注于与运动相关的指导对齐。

项目地址：https://pi-animator.github.io/</title>
            <link>https://nitter.cz/op7418/status/1738269094737293581#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738269094737293581#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 18:43:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上海人工智能实验室又搞了一个即插即用的图像生成视频模型。<br />
主要特点是根据不同的文本提示以动作进行动画处理，同时保留原始的独特风格和高保真度的细节。<br />
<br />
项目简介：<br />
我们提出了PIA，一种个性化图像动画生成器，它在与条件图像对齐、通过文本实现动作可控性以及与各种个性化T2I模型的兼容性方面表现出色，而无需特定调整。<br />
<br />
为了实现这些目标，PIA基于一个经过良好训练的时间对齐层的基础T2I模型，允许将任何个性化T2I模型无缝转换为图像动画模型。<br />
<br />
PIA的一个关键组成部分是引入条件模块，它利用条件帧和帧间关联作为输入，在潜在空间中通过关联提示来传输外观信息，以指导个别帧的合成。<br />
<br />
 这种设计减轻了外观相关图像对齐的挑战，并允许更加专注于与运动相关的指导对齐。<br />
<br />
项目地址：<a href="https://pi-animator.github.io/">pi-animator.github.io/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzgyNjkwNTU0ODI3NjEyMTYvcHUvaW1nL3pWTWpQTUdiOXFsMzJKa0EuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738260817097953530#m</id>
            <title>RT by @dotey: 这个等不了阿里自己实现Animate Anyone单图生成动作视频的老哥进展很快啊。

已经发布了训练和推理代码，第一阶段训练已经完成，马上就会发布权重文件。

项目基于magic-animate和AnimateDiff构建。

https://github.com/guoqincode/AnimateAnyone-unofficial</title>
            <link>https://nitter.cz/op7418/status/1738260817097953530#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738260817097953530#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 18:10:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个等不了阿里自己实现Animate Anyone单图生成动作视频的老哥进展很快啊。<br />
<br />
已经发布了训练和推理代码，第一阶段训练已经完成，马上就会发布权重文件。<br />
<br />
项目基于magic-animate和AnimateDiff构建。<br />
<br />
<a href="https://github.com/guoqincode/AnimateAnyone-unofficial">github.com/guoqincode/Animat…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ItSy1pZmJNQUFBeG9rLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738124109991587845#m</id>
            <title>Midjourney 的创始人 David Holz 提出了一种新的提示方法。V6 对提示的敏感度大大提高。

建议避免使用“获奖、超现实、4k、8k”等表述，而应确保请求明确。如果你希望得到更直接、更中立且更现实的输出结果，最好将 --style raw 设置为默认。

（原文中直言不讳地将 4k、8k 等描述称为“无用”提示。"V6 对你的提示非常敏感。避免使用‘无用’的表述，如‘获奖、超现实、4k、8k’"）

https://baoyu.io/translations/ai-photos/midjourney-v6-elevating-prompt-structure-and-expression</title>
            <link>https://nitter.cz/dotey/status/1738124109991587845#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738124109991587845#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 09:07:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney 的创始人 David Holz 提出了一种新的提示方法。V6 对提示的敏感度大大提高。<br />
<br />
建议避免使用“获奖、超现实、4k、8k”等表述，而应确保请求明确。如果你希望得到更直接、更中立且更现实的输出结果，最好将 --style raw 设置为默认。<br />
<br />
（原文中直言不讳地将 4k、8k 等描述称为“无用”提示。"V6 对你的提示非常敏感。避免使用‘无用’的表述，如‘获奖、超现实、4k、8k’"）<br />
<br />
<a href="https://baoyu.io/translations/ai-photos/midjourney-v6-elevating-prompt-structure-and-expression">baoyu.io/translations/ai-pho…</a></p>
<p><a href="https://nitter.cz/ciguleva/status/1737206895738585483#m">nitter.cz/ciguleva/status/1737206895738585483#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I4T04xUFhvQUFxRFZQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738103359020622171#m</id>
            <title>R to @dotey: 中文翻译版本：《AppAgent: 像人类用户一样操作手机的多模态智能体 [译]》

https://baoyu.io/translations/ai-paper/2312.13771-appagent-multimodal-agents-as-smartphone-users</title>
            <link>https://nitter.cz/dotey/status/1738103359020622171#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738103359020622171#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 07:45:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>中文翻译版本：《AppAgent: 像人类用户一样操作手机的多模态智能体 [译]》<br />
<br />
<a href="https://baoyu.io/translations/ai-paper/2312.13771-appagent-multimodal-agents-as-smartphone-users">baoyu.io/translations/ai-pap…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738103315626340521#m</id>
            <title>腾讯新论文 AppAgent 的中文翻译版本：《AppAgent: 像人类用户一样操作手机的多模态智能体 [译]》

https://baoyu.io/translations/ai-paper/2312.13771-appagent-multimodal-agents-as-smartphone-users

摘要

大语言模型 (LLMs) 的最新进展催生了一类能够执行复杂任务的智能代理。本文提出了一种基于大语言模型的多模态代理框架，专为智能手机应用而设计。我们的框架允许智能体通过简化的动作范围，如点击和滑动，来操作智能手机应用，仿佛它是一个人类用户。这种创新方法免除了访问系统后端的需要，使其能够适用于多种不同的应用。我们的智能体采用了一种创新的学习方法：它可以通过自我探索或观察人类的操作来学习如何导航和使用新的应用程序。通过这个过程，它建立了一个知识库，用于在不同应用中执行复杂任务。为了证明我们智能体的实用性，我们在 10 个不同的应用中进行了 50 项任务的测试，涵盖了社交媒体、电子邮件、地图、购物和高级图像编辑等领域。测试结果证明了我们的智能体在处理多种高级任务方面的高效能。</title>
            <link>https://nitter.cz/dotey/status/1738103315626340521#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738103315626340521#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 07:44:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>腾讯新论文 AppAgent 的中文翻译版本：《AppAgent: 像人类用户一样操作手机的多模态智能体 [译]》<br />
<br />
<a href="https://baoyu.io/translations/ai-paper/2312.13771-appagent-multimodal-agents-as-smartphone-users">baoyu.io/translations/ai-pap…</a><br />
<br />
摘要<br />
<br />
大语言模型 (LLMs) 的最新进展催生了一类能够执行复杂任务的智能代理。本文提出了一种基于大语言模型的多模态代理框架，专为智能手机应用而设计。我们的框架允许智能体通过简化的动作范围，如点击和滑动，来操作智能手机应用，仿佛它是一个人类用户。这种创新方法免除了访问系统后端的需要，使其能够适用于多种不同的应用。我们的智能体采用了一种创新的学习方法：它可以通过自我探索或观察人类的操作来学习如何导航和使用新的应用程序。通过这个过程，它建立了一个知识库，用于在不同应用中执行复杂任务。为了证明我们智能体的实用性，我们在 10 个不同的应用中进行了 50 项任务的测试，涵盖了社交媒体、电子邮件、地图、购物和高级图像编辑等领域。测试结果证明了我们的智能体在处理多种高级任务方面的高效能。</p>
<p><a href="https://nitter.cz/dotey/status/1738069505220194639#m">nitter.cz/dotey/status/1738069505220194639#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I3N3FoS1hjQUFubzNULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738069505220194639#m</id>
            <title>腾讯推出的 AppAgent，是一个多模态智能体，通过识别当前手机的界面和用户指令直接操作手机界面，能像真实用户一样操作手机！比如它可以操作图片编辑软件编辑图片、打开地图应用导航，购物等等操作

项目首页：https://appagent-official.github.io/
论文链接：https://arxiv.org/abs/2312.13771

像真实智能手机用户一样操作手机的多模态智能体

论文摘要：

随着大语言模型（LLMs）的最新进展，人们创造出了能执行复杂任务的智能智能体。本文介绍了一个全新的、基于大语言模型的多模态智能体框架，专为操作智能手机应用而设计。我们的框架让智能体可以通过一个简化的操作空间来操控智能手机应用，这种方式仿佛是人类在进行点击和滑动操作。这种创新的方法避开了对系统后端的直接访问需求，使其能够适用于多种不同的应用程序。我们智能体功能的核心在于它的创新学习方式。智能体通过自我探索或者观察人类的示范来学习如何导航和使用新的应用程序。在这个过程中，它会构建起一个知识库，并依靠这个知识库来执行不同应用中的复杂任务。为了展示我们智能体的实用性，我们对它在 10 个不同应用中的 50 个任务进行了全面测试，这些应用包括社交媒体、电子邮件、地图、购物以及复杂的图像编辑工具。测试结果证明了我们的智能体在处理各种高级任务方面的高效能力。</title>
            <link>https://nitter.cz/dotey/status/1738069505220194639#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738069505220194639#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 05:30:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>腾讯推出的 AppAgent，是一个多模态智能体，通过识别当前手机的界面和用户指令直接操作手机界面，能像真实用户一样操作手机！比如它可以操作图片编辑软件编辑图片、打开地图应用导航，购物等等操作<br />
<br />
项目首页：<a href="https://appagent-official.github.io/">appagent-official.github.io/</a><br />
论文链接：<a href="https://arxiv.org/abs/2312.13771">arxiv.org/abs/2312.13771</a><br />
<br />
像真实智能手机用户一样操作手机的多模态智能体<br />
<br />
论文摘要：<br />
<br />
随着大语言模型（LLMs）的最新进展，人们创造出了能执行复杂任务的智能智能体。本文介绍了一个全新的、基于大语言模型的多模态智能体框架，专为操作智能手机应用而设计。我们的框架让智能体可以通过一个简化的操作空间来操控智能手机应用，这种方式仿佛是人类在进行点击和滑动操作。这种创新的方法避开了对系统后端的直接访问需求，使其能够适用于多种不同的应用程序。我们智能体功能的核心在于它的创新学习方式。智能体通过自我探索或者观察人类的示范来学习如何导航和使用新的应用程序。在这个过程中，它会构建起一个知识库，并依靠这个知识库来执行不同应用中的复杂任务。为了展示我们智能体的实用性，我们对它在 10 个不同应用中的 50 个任务进行了全面测试，这些应用包括社交媒体、电子邮件、地图、购物以及复杂的图像编辑工具。测试结果证明了我们的智能体在处理各种高级任务方面的高效能力。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzgwNjg1MzExMzkyMDMwNzIvcHUvaW1nL0RuZmFsWk92MW52YzRiSzIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738061130034266560#m</id>
            <title>RT by @dotey: 最近这个让照片说话的项目很多

这不，字节跳动又搞了个

DREAM-Talk ：能从单张图像生成逼真的、带有情感的、能说话的面部动画。

支持各种情感表达，如愤怒、快乐、悲伤、惊讶等。表情会根据音频中的情感变化

多语言支持：支持包括中文、日文、法语、德语等。

项目及演示：https://magic-research.github.io/dream-talk/</title>
            <link>https://nitter.cz/xiaohuggg/status/1738061130034266560#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738061130034266560#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 04:57:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近这个让照片说话的项目很多<br />
<br />
这不，字节跳动又搞了个<br />
<br />
DREAM-Talk ：能从单张图像生成逼真的、带有情感的、能说话的面部动画。<br />
<br />
支持各种情感表达，如愤怒、快乐、悲伤、惊讶等。表情会根据音频中的情感变化<br />
<br />
多语言支持：支持包括中文、日文、法语、德语等。<br />
<br />
项目及演示：<a href="https://magic-research.github.io/dream-talk/">magic-research.github.io/dre…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzgwNjA3NDQzOTczNDA2NzIvcHUvaW1nL3BYNHNhYjhmRGhSMm1feUYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738062235161825610#m</id>
            <title>32 K真不少呀，看起来中文支持也不错</title>
            <link>https://nitter.cz/dotey/status/1738062235161825610#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738062235161825610#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 05:01:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>32 K真不少呀，看起来中文支持也不错</p>
<p><a href="https://nitter.cz/balconychy/status/1738048162542346406#m">nitter.cz/balconychy/status/1738048162542346406#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738050714146894107#m</id>
            <title>这是多模态和 SAM（Segment Anything） 的一个非常好的应用场景👍🏻</title>
            <link>https://nitter.cz/dotey/status/1738050714146894107#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738050714146894107#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 04:15:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这是多模态和 SAM（Segment Anything） 的一个非常好的应用场景👍🏻</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1738046153877508458#m">nitter.cz/xiaohuggg/status/1738046153877508458#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OLLAMA/status/1738047032281940146#m</id>
            <title>RT by @dotey: .@llama_index and @seldo’s article now translated in Chinese. 👇</title>
            <link>https://nitter.cz/OLLAMA/status/1738047032281940146#m</link>
            <guid isPermaLink="false">https://nitter.cz/OLLAMA/status/1738047032281940146#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 04:01:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>.<a href="https://nitter.cz/llama_index" title="LlamaIndex 🦙">@llama_index</a> and <a href="https://nitter.cz/seldo" title="Laurie Voss">@seldo</a>’s article now translated in Chinese. 👇</p>
<p><a href="https://nitter.cz/dotey/status/1738046572049350903#m">nitter.cz/dotey/status/1738046572049350903#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738046572049350903#m</id>
            <title>这篇教程的中文版本：https://baoyu.io/translations/llm/running-mixtral-8x7-locally-with-llamaindex</title>
            <link>https://nitter.cz/dotey/status/1738046572049350903#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738046572049350903#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 03:59:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这篇教程的中文版本：<a href="https://baoyu.io/translations/llm/running-mixtral-8x7-locally-with-llamaindex">baoyu.io/translations/llm/ru…</a></p>
<p><a href="https://nitter.cz/OLLAMA/status/1738033711231185331#m">nitter.cz/OLLAMA/status/1738033711231185331#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczODA0NjU3MzMxNjA1NTA0MC95MnpnVUlZdD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738031978358681988#m</id>
            <title>#AI开源项目推荐：langgenius/dify

开源版本的 GPTs 实现，甚至于很多地方比 GPTs 功能更强大！

Dify 是一个 LLM 应用开发平台，已经有超过 10 万个应用基于 http://Dify.AI 构建。它融合了 Backend as Service 和 LLMOps 的理念，涵盖了构建生成式 AI 原生应用所需的核心技术栈，包括一个内置 RAG 引擎。使用 Dify，你可以基于任何模型自部署类似 Assistants API 和 GPTs 的能力。

特点

1. LLM支持：与 OpenAI 的 GPT 系列模型集成,或者与开源的 Llama2 系列模型集成。事实上，Dify支持主流的商业模型和开源模型(本地部署或基于 MaaS)。

2. Prompt IDE：和团队一起在 Dify 协作，通过可视化的 Prompt 和应用编排工具开发 AI 应用。 支持无缝切换多种大型语言模型。

3. RAG引擎：包括各种基于全文索引或向量数据库嵌入的 RAG 能力，允许直接上传 PDF、TXT 等各种文本格式。

4. Agent：基于函数调用的 Agent框架，允许用户自定义配置，所见即所得。Dify 提供了基本的插件能力，如谷歌搜索。

5. 持续运营：监控和分析应用日志和性能，使用生产数据持续改进 Prompt、数据集或模型。

项目地址：https://github.com/langgenius/dify</title>
            <link>https://nitter.cz/dotey/status/1738031978358681988#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738031978358681988#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 03:01:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：langgenius/dify<br />
<br />
开源版本的 GPTs 实现，甚至于很多地方比 GPTs 功能更强大！<br />
<br />
Dify 是一个 LLM 应用开发平台，已经有超过 10 万个应用基于 <a href="http://Dify.AI">Dify.AI</a> 构建。它融合了 Backend as Service 和 LLMOps 的理念，涵盖了构建生成式 AI 原生应用所需的核心技术栈，包括一个内置 RAG 引擎。使用 Dify，你可以基于任何模型自部署类似 Assistants API 和 GPTs 的能力。<br />
<br />
特点<br />
<br />
1. LLM支持：与 OpenAI 的 GPT 系列模型集成,或者与开源的 Llama2 系列模型集成。事实上，Dify支持主流的商业模型和开源模型(本地部署或基于 MaaS)。<br />
<br />
2. Prompt IDE：和团队一起在 Dify 协作，通过可视化的 Prompt 和应用编排工具开发 AI 应用。 支持无缝切换多种大型语言模型。<br />
<br />
3. RAG引擎：包括各种基于全文索引或向量数据库嵌入的 RAG 能力，允许直接上传 PDF、TXT 等各种文本格式。<br />
<br />
4. Agent：基于函数调用的 Agent框架，允许用户自定义配置，所见即所得。Dify 提供了基本的插件能力，如谷歌搜索。<br />
<br />
5. 持续运营：监控和分析应用日志和性能，使用生产数据持续改进 Prompt、数据集或模型。<br />
<br />
项目地址：<a href="https://github.com/langgenius/dify">github.com/langgenius/dify</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2NjBjTlc0QUE2R0RqLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2NjFxeldzQUFWcVFNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738030025859817929#m</id>
            <title>微软前几天发布的 MedPrompt 论文“Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine” 的中文翻译：

《通用型基础模型能否超越专用调整模型？医学领域的案例研究 [译]》

https://baoyu.io/translations/ai-paper/2311.16452-case-study-in-medicine</title>
            <link>https://nitter.cz/dotey/status/1738030025859817929#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738030025859817929#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 02:53:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软前几天发布的 MedPrompt 论文“Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine” 的中文翻译：<br />
<br />
《通用型基础模型能否超越专用调整模型？医学领域的案例研究 [译]》<br />
<br />
<a href="https://baoyu.io/translations/ai-paper/2311.16452-case-study-in-medicine">baoyu.io/translations/ai-pap…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2NUVRb1hrQUFpdGVXLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2NUY1MVdVQUFKQXdYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/monday_chen/status/1738008262287732758#m</id>
            <title>RT by @dotey: Sam Altman 最新博文的中文翻译 https://blog.samaltman.com/what-i-wish-someone-had-told-me
ChatGPT 直译+意译，我人工校对了一遍。</title>
            <link>https://nitter.cz/monday_chen/status/1738008262287732758#m</link>
            <guid isPermaLink="false">https://nitter.cz/monday_chen/status/1738008262287732758#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 01:27:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam Altman 最新博文的中文翻译 <a href="https://blog.samaltman.com/what-i-wish-someone-had-told-me">blog.samaltman.com/what-i-wi…</a><br />
ChatGPT 直译+意译，我人工校对了一遍。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2azlMUFhJQUFsNnJPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1737985249806889187#m</id>
            <title>RT by @dotey: Mistral-Medium在Poe上可以使用了，英文对话能力超过了ChatGPT-3.5</title>
            <link>https://nitter.cz/Gorden_Sun/status/1737985249806889187#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1737985249806889187#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 23:55:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mistral-Medium在Poe上可以使用了，英文对话能力超过了ChatGPT-3.5</p>
<p><a href="https://nitter.cz/poe_platform/status/1737956764308672948#m">nitter.cz/poe_platform/status/1737956764308672948#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737983047264346237#m</id>
            <title>推荐阅读：《The Future is Rusty —— LLMs Make Programming Language Learning Curves Shallower》

众所周知，Rust 的学习曲线很陡峭，但现在，得益于大语言模型（LLMs）的发展，这个陡峭学习曲线的问题已经变得容易解决了。 无论是 Rust、Haskell 还是其他任何语言，借助大语言模型的帮助，现在学习起来都更加容易。事实上，如果你在学习难懂的材料时没有利用大语言模型的帮助，那么你的学习方式可能不是最佳的。 

文章中提到了一个很有意思的概念叫 “The Intermediate Material Problem”，是指在学习某个技能或领域时，在初级和高级阶段之间存在的一种学习难点。具体来说，在编程语言学习中，这个问题特别明显，尤其是对于像 Rust 这样的复杂语言。

在初级阶段，学习者通过教程和基础课程获得基本的知识和技能。这些资源通常都是易于理解和遵循的，目的是帮助初学者快速入门。然而，当学习者试图从基础过渡到更复杂的应用和项目时，他们常常发现可用的学习材料突然变得稀少并且难度很高。例如，在 Rust 编程中，学习者可能已经掌握了基本的语法和概念，但在尝试开发更复杂的系统（如光线追踪器）时，他们需要理解更高级的概念，比如所有权规则和内存管理，这些通常不在初级教程中详细讲解。

这种情况造成了一个“中阶教材”缺口，学习者必须依靠自己的努力和探索来克服这个难关，这通常包括阅读高级文档、参与社区讨论，甚至通过试错来解决具体的编程难题。这个阶段通常伴随着挫折和困惑，因为学习者不再有清晰的指导和步骤可循，而是需要自己摸索前进。

这个问题并不限于编程或技术领域。在许多学习曲线陡峭的领域中，从初学者过渡到熟练者的过程中都可能遇到类似的“中阶教材问题”。

另外文章中还提到数学家陶哲轩都在借助 ChatGPT 辅助学习。如果我们这个时代最杰出的数学家都在用 ChatGPT 来帮助他进行证明，那么你也没有理由不尝试！

原文：https://earthly.dev/blog/future-is-rusty/
译文：https://baoyu.io/translations/software-engineering/future-is-rusty</title>
            <link>https://nitter.cz/dotey/status/1737983047264346237#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737983047264346237#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 23:47:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《The Future is Rusty —— LLMs Make Programming Language Learning Curves Shallower》<br />
<br />
众所周知，Rust 的学习曲线很陡峭，但现在，得益于大语言模型（LLMs）的发展，这个陡峭学习曲线的问题已经变得容易解决了。 无论是 Rust、Haskell 还是其他任何语言，借助大语言模型的帮助，现在学习起来都更加容易。事实上，如果你在学习难懂的材料时没有利用大语言模型的帮助，那么你的学习方式可能不是最佳的。 <br />
<br />
文章中提到了一个很有意思的概念叫 “The Intermediate Material Problem”，是指在学习某个技能或领域时，在初级和高级阶段之间存在的一种学习难点。具体来说，在编程语言学习中，这个问题特别明显，尤其是对于像 Rust 这样的复杂语言。<br />
<br />
在初级阶段，学习者通过教程和基础课程获得基本的知识和技能。这些资源通常都是易于理解和遵循的，目的是帮助初学者快速入门。然而，当学习者试图从基础过渡到更复杂的应用和项目时，他们常常发现可用的学习材料突然变得稀少并且难度很高。例如，在 Rust 编程中，学习者可能已经掌握了基本的语法和概念，但在尝试开发更复杂的系统（如光线追踪器）时，他们需要理解更高级的概念，比如所有权规则和内存管理，这些通常不在初级教程中详细讲解。<br />
<br />
这种情况造成了一个“中阶教材”缺口，学习者必须依靠自己的努力和探索来克服这个难关，这通常包括阅读高级文档、参与社区讨论，甚至通过试错来解决具体的编程难题。这个阶段通常伴随着挫折和困惑，因为学习者不再有清晰的指导和步骤可循，而是需要自己摸索前进。<br />
<br />
这个问题并不限于编程或技术领域。在许多学习曲线陡峭的领域中，从初学者过渡到熟练者的过程中都可能遇到类似的“中阶教材问题”。<br />
<br />
另外文章中还提到数学家陶哲轩都在借助 ChatGPT 辅助学习。如果我们这个时代最杰出的数学家都在用 ChatGPT 来帮助他进行证明，那么你也没有理由不尝试！<br />
<br />
原文：<a href="https://earthly.dev/blog/future-is-rusty/">earthly.dev/blog/future-is-r…</a><br />
译文：<a href="https://baoyu.io/translations/software-engineering/future-is-rusty">baoyu.io/translations/softwa…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2TkdsWlhNQUVTQjZCLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2TkgxT1hBQUFDN2x5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2Tkk4TFdFQU1pWTlwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2TktXZ1hnQUVUTXQzLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737930871531831412#m</id>
            <title>转译：《Nvidia CEO：我们对 AI 下了重注，而这一决策鲜为人知》

Nvidia 创始人兼 CEO Jensen Huang 最近在 SIGGRAPH 洛杉矶主题演讲中表示，公司在 2018 年做出了一项关键商业决策，这一决策在当时很少有人预见到它将如何重新定义 Nvidia 的未来，以及对整个不断发展的行业产生深远影响。当然，这一决策已经取得了巨大成功，但 Huang 认为，这只是以 Nvidia 硬件为主导的 AI 驱动未来的序幕。这是否是一个幸运的或明智的赌注？看起来，两者都是。

Huang 在演讲中回顾道，五年前的那个关键时刻是选择采用 AI 驱动的图像处理技术，即光线追踪（RTX）和智能升级（DLSS）。 (引用根据我的笔记整理，可能并非原话，详细内容可能会在核查记录后稍作调整。)

“我们意识到光栅化技术已接近极限，”他说。2018 年是 Nvidia 的一个关键时刻，公司需要彻底改革硬件、软件和算法。在我们用 AI 重塑计算机图形的同时，我们也在重塑 GPU，以适应 AI 的需求。”

尽管光线追踪和 DLSS 在消费者 GPU 和游戏领域仍处于渐进采纳阶段，但 Nvidia 创建的架构被证明是不断成长的机器学习开发社区的理想伙伴。

为了训练越来越庞大的生成模型，所需的大量计算能力并非仅能由传统数据中心和部分 GPU 提供，而是需要像 H100 这样从一开始就设计用于大规模运算的系统。可以说，AI 发展在某种程度上受限于这些计算资源的可用性。Nvidia 正在经历类似于 Beanie Baby 的热潮，并且销售了它能生产出的所有服务器和工作站。

但 Huang 强调，这只是个开始。新的模型不仅需要被训练，而且还需由数以百万计甚至数以亿计的用户定期实时运行。

他说：“未来，无论是在视觉效果、快速数字化的制造业市场、工厂设计，还是重工业领域，大语言模型 (LLM) 都将成为核心技术。‘人类’将成为新的编程语言。”黄博士预测，自然语言界面将在这些领域得到广泛应用。

他补充道：“整个工厂将通过软件定义和机器人化实现自动化。我们将要建造的汽车，甚至本身就是机器人。这可以说是机器人设计的机器人制造机器人。”

黄博士的这一观点虽然合理，但也非常符合英伟达 (Nvidia) 的利益。有些人可能不同意他的看法。

尽管大语言模型的依赖程度尚不明确，但几乎没有人认为它不会被采用。即使是保守的估计，也表明将来必须在新的计算资源上进行大量投资。

他认为，在上一代以 CPU 为核心的计算资源上投资数百万美元是不明智的。相比之下，像 GH200 这样的新推出的、专门用于数据中心的 AI 开发硬件，在成本和功耗方面都有显著优势，能以不到十分之一的代价完成相同的工作。

他兴奋地展示了一个视频，视频中展示了多个 Grace Hopper 计算单元如同乐高积木般组装成一个刀片，然后是一个机架，接着是一排 GH200。这些设备以极高的速度连接在一起，形成了“世界上最大的单一 GPU”，拥有一整个每秒一百万亿次的机器学习 (ML) 专用计算能力。

“顺便说一下，这是真实大小，”他站在可视化的中心，戏剧性地说道。“而且，它甚至可能运行《Crysis》游戏。”

他认为，这些设备将成为未来数字化、AI 主导的工业中的基本单元。

他笑着说：“我不知道谁是第一个说出这话的，但是……你买的越多，省的也就越多。如果你们从今天的演讲中只记住一件事，那就是这句话。”他的话在 SIGGRAPH 的游戏观众中引起了笑声。

他没有提及 AI 面临的诸多挑战、监管问题，或者 AI 概念的变化——就像去年已经发生过多次的那样。当然，这是一种乐观的世界观。但在淘金热中卖铲子和锄头的人，确实可以有这样的想法。

https://techcrunch.com/2023/08/08/nvidia-ceo-we-bet-the-farm-on-ai-and-no-one-knew-it/</title>
            <link>https://nitter.cz/dotey/status/1737930871531831412#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737930871531831412#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 20:19:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：《Nvidia CEO：我们对 AI 下了重注，而这一决策鲜为人知》<br />
<br />
Nvidia 创始人兼 CEO Jensen Huang 最近在 SIGGRAPH 洛杉矶主题演讲中表示，公司在 2018 年做出了一项关键商业决策，这一决策在当时很少有人预见到它将如何重新定义 Nvidia 的未来，以及对整个不断发展的行业产生深远影响。当然，这一决策已经取得了巨大成功，但 Huang 认为，这只是以 Nvidia 硬件为主导的 AI 驱动未来的序幕。这是否是一个幸运的或明智的赌注？看起来，两者都是。<br />
<br />
Huang 在演讲中回顾道，五年前的那个关键时刻是选择采用 AI 驱动的图像处理技术，即光线追踪（RTX）和智能升级（DLSS）。 (引用根据我的笔记整理，可能并非原话，详细内容可能会在核查记录后稍作调整。)<br />
<br />
“我们意识到光栅化技术已接近极限，”他说。2018 年是 Nvidia 的一个关键时刻，公司需要彻底改革硬件、软件和算法。在我们用 AI 重塑计算机图形的同时，我们也在重塑 GPU，以适应 AI 的需求。”<br />
<br />
尽管光线追踪和 DLSS 在消费者 GPU 和游戏领域仍处于渐进采纳阶段，但 Nvidia 创建的架构被证明是不断成长的机器学习开发社区的理想伙伴。<br />
<br />
为了训练越来越庞大的生成模型，所需的大量计算能力并非仅能由传统数据中心和部分 GPU 提供，而是需要像 H100 这样从一开始就设计用于大规模运算的系统。可以说，AI 发展在某种程度上受限于这些计算资源的可用性。Nvidia 正在经历类似于 Beanie Baby 的热潮，并且销售了它能生产出的所有服务器和工作站。<br />
<br />
但 Huang 强调，这只是个开始。新的模型不仅需要被训练，而且还需由数以百万计甚至数以亿计的用户定期实时运行。<br />
<br />
他说：“未来，无论是在视觉效果、快速数字化的制造业市场、工厂设计，还是重工业领域，大语言模型 (LLM) 都将成为核心技术。‘人类’将成为新的编程语言。”黄博士预测，自然语言界面将在这些领域得到广泛应用。<br />
<br />
他补充道：“整个工厂将通过软件定义和机器人化实现自动化。我们将要建造的汽车，甚至本身就是机器人。这可以说是机器人设计的机器人制造机器人。”<br />
<br />
黄博士的这一观点虽然合理，但也非常符合英伟达 (Nvidia) 的利益。有些人可能不同意他的看法。<br />
<br />
尽管大语言模型的依赖程度尚不明确，但几乎没有人认为它不会被采用。即使是保守的估计，也表明将来必须在新的计算资源上进行大量投资。<br />
<br />
他认为，在上一代以 CPU 为核心的计算资源上投资数百万美元是不明智的。相比之下，像 GH200 这样的新推出的、专门用于数据中心的 AI 开发硬件，在成本和功耗方面都有显著优势，能以不到十分之一的代价完成相同的工作。<br />
<br />
他兴奋地展示了一个视频，视频中展示了多个 Grace Hopper 计算单元如同乐高积木般组装成一个刀片，然后是一个机架，接着是一排 GH200。这些设备以极高的速度连接在一起，形成了“世界上最大的单一 GPU”，拥有一整个每秒一百万亿次的机器学习 (ML) 专用计算能力。<br />
<br />
“顺便说一下，这是真实大小，”他站在可视化的中心，戏剧性地说道。“而且，它甚至可能运行《Crysis》游戏。”<br />
<br />
他认为，这些设备将成为未来数字化、AI 主导的工业中的基本单元。<br />
<br />
他笑着说：“我不知道谁是第一个说出这话的，但是……你买的越多，省的也就越多。如果你们从今天的演讲中只记住一件事，那就是这句话。”他的话在 SIGGRAPH 的游戏观众中引起了笑声。<br />
<br />
他没有提及 AI 面临的诸多挑战、监管问题，或者 AI 概念的变化——就像去年已经发生过多次的那样。当然，这是一种乐观的世界观。但在淘金热中卖铲子和锄头的人，确实可以有这样的想法。<br />
<br />
<a href="https://techcrunch.com/2023/08/08/nvidia-ceo-we-bet-the-farm-on-ai-and-no-one-knew-it/">techcrunch.com/2023/08/08/nv…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I1ZXM1S1dZQUFIYjF4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I1ZXZFQ1dFQUFpczBLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737926846539235783#m</id>
            <title>#开源项目推荐：docusealco/docuseal

开源 DocuSign 替代方案。创建、填写和签署数字文档 ✍️

功能包括：
 - PDF 表单字段生成器（所见即所得）
 - 提供 11 种字段类型（签名、日期、文件、复选框等）
 - 每个文档有多个提交者
 - 通过 SMTP 自动发送电子邮件
 - 文件存储在磁盘或 AWS S3、谷歌存储、Azure 云上
- 自动 PDF 电子签名
 - PDF 签名验证
 - 用户管理
 - 移动优化
 - 集成 API 和 Webhooks
 - 几分钟内即可轻松部署

项目地址：https://github.com/docusealco/docuseal</title>
            <link>https://nitter.cz/dotey/status/1737926846539235783#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737926846539235783#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 20:03:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23开源项目推荐">#开源项目推荐</a>：docusealco/docuseal<br />
<br />
开源 DocuSign 替代方案。创建、填写和签署数字文档 ✍️<br />
<br />
功能包括：<br />
 - PDF 表单字段生成器（所见即所得）<br />
 - 提供 11 种字段类型（签名、日期、文件、复选框等）<br />
 - 每个文档有多个提交者<br />
 - 通过 SMTP 自动发送电子邮件<br />
 - 文件存储在磁盘或 AWS S3、谷歌存储、Azure 云上<br />
- 自动 PDF 电子签名<br />
 - PDF 签名验证<br />
 - 用户管理<br />
 - 移动优化<br />
 - 集成 API 和 Webhooks<br />
 - 几分钟内即可轻松部署<br />
<br />
项目地址：<a href="https://github.com/docusealco/docuseal">github.com/docusealco/docuse…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I1YlFKM1dNQUVoZ1hILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>