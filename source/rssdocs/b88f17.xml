<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/mtrainier2020/status/1749863880124482033#m</id>
            <title>RT by @dotey: 其实你前面的几个开源的项目蛮好的。如果你去过去一年接点小活不要说一块4090，10块4090都出来了，真的。😂
举个例子啊，你的inpaint的那个项目，是非常容易商业化的项目。你要找到你的客户，让他们掏钱。最容易掏钱的是电商客户。那么哪里去找电商客户呢？这个就要动动脑筋。你很容易找到top 1000的。
然后将这个1000个分成5组。分批去处理。然后你只要把你的场景，给他们演示一下，提出限量免费，后续收费的方法。还可以帮组独立部署的方法。看看第一组能找到多少客户。然后可以的话，第二组提高价格，改收费方案。反正你有5组，一组一组实验。把这事当正事做，这个业务，营收上M一点问题都没有。</title>
            <link>https://nitter.cz/mtrainier2020/status/1749863880124482033#m</link>
            <guid isPermaLink="false">https://nitter.cz/mtrainier2020/status/1749863880124482033#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 18:37:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>其实你前面的几个开源的项目蛮好的。如果你去过去一年接点小活不要说一块4090，10块4090都出来了，真的。😂<br />
举个例子啊，你的inpaint的那个项目，是非常容易商业化的项目。你要找到你的客户，让他们掏钱。最容易掏钱的是电商客户。那么哪里去找电商客户呢？这个就要动动脑筋。你很容易找到top 1000的。<br />
然后将这个1000个分成5组。分批去处理。然后你只要把你的场景，给他们演示一下，提出限量免费，后续收费的方法。还可以帮组独立部署的方法。看看第一组能找到多少客户。然后可以的话，第二组提高价格，改收费方案。反正你有5组，一组一组实验。把这事当正事做，这个业务，营收上M一点问题都没有。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749928436196315332#m</id>
            <title>R to @dotey: 还有一个大坑，所有你之前创建的GPT，在账号合并后，权限默认只对team内部公开，需要手动一个个修改为对所有人公开，否则其他人不能访问！</title>
            <link>https://nitter.cz/dotey/status/1749928436196315332#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749928436196315332#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 22:53:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还有一个大坑，所有你之前创建的GPT，在账号合并后，权限默认只对team内部公开，需要手动一个个修改为对所有人公开，否则其他人不能访问！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749911845580705832#m</id>
            <title>请教一下，ChatGPT Team 怎么从 Flexible Plan 切换到  Annual Plan？没有找到选项！

先 Cancel 再重新订阅？担心有风险</title>
            <link>https://nitter.cz/dotey/status/1749911845580705832#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749911845580705832#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 21:47:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>请教一下，ChatGPT Team 怎么从 Flexible Plan 切换到  Annual Plan？没有找到选项！<br />
<br />
先 Cancel 再重新订阅？担心有风险</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749909986614878618#m</id>
            <title>R to @dotey: 但是需要注意：这个操作是单向的，你无法再从团队账号转成个人账号，如果你的团队账号不继续维持了或者被移除了，你的数据都无法访问！</title>
            <link>https://nitter.cz/dotey/status/1749909986614878618#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749909986614878618#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 21:40:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>但是需要注意：这个操作是单向的，你无法再从团队账号转成个人账号，如果你的团队账号不继续维持了或者被移除了，你的数据都无法访问！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VqdDFXVVd3QUFJbkUzLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749902932370178139#m</id>
            <title>R to @dotey: 合并完就退钱了……</title>
            <link>https://nitter.cz/dotey/status/1749902932370178139#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749902932370178139#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 21:12:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>合并完就退钱了……</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VqbmFNd1dFQUVKUnlpLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749898089878503570#m</id>
            <title>可以把个人账号合并到Team账号了，我测试了一切正常！
以前创建的GPT也能正常访问！</title>
            <link>https://nitter.cz/dotey/status/1749898089878503570#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749898089878503570#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 20:53:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>可以把个人账号合并到Team账号了，我测试了一切正常！<br />
以前创建的GPT也能正常访问！</p>
<p><a href="https://nitter.cz/jesselaunz/status/1749883431822176556#m">nitter.cz/jesselaunz/status/1749883431822176556#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VqaXBtZFhJQUFNZmtvLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VqaXJ4V1hNQUFTSG9TLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VqaXJ4YVhBQUFzRzJCLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VqaS1hMlhzQUE4T1ZHLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/WildCat_zh/status/1749795132595929482#m</id>
            <title>RT by @dotey: 最近加拿大联邦收紧了移民政策，难度一下子提升了很多。其实每个人移民的路，都是非常坎坷的。
没人愿意在30岁左右远走他乡，放弃之前的所有积累和人脉。但是现实所迫啊。

分享一下自己的来加拿大的经历吧。

(1/n)</title>
            <link>https://nitter.cz/WildCat_zh/status/1749795132595929482#m</link>
            <guid isPermaLink="false">https://nitter.cz/WildCat_zh/status/1749795132595929482#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 14:04:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近加拿大联邦收紧了移民政策，难度一下子提升了很多。其实每个人移民的路，都是非常坎坷的。<br />
没人愿意在30岁左右远走他乡，放弃之前的所有积累和人脉。但是现实所迫啊。<br />
<br />
分享一下自己的来加拿大的经历吧。<br />
<br />
(1/n)</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/ZHOZHO672070/status/1749755721896612167#m</id>
            <title>RT by @dotey: 🤣InstantID in ComfyUI 来啦！仅需一张图就可实现高质量的角色保持！多种风格随心变！
 
1⃣模块化更高效，同时支持本地、hub模型
2⃣9种风格随心选，还可与PhotoMaker Styler通用
3⃣3种工作流：特意增加了配合ArtGallery的艺术可视化工作流，助你畅游艺术世界

项目地址：https://github.com/ZHO-ZHO-ZHO/ComfyUI-InstantID</title>
            <link>https://nitter.cz/ZHOZHO672070/status/1749755721896612167#m</link>
            <guid isPermaLink="false">https://nitter.cz/ZHOZHO672070/status/1749755721896612167#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 11:27:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🤣InstantID in ComfyUI 来啦！仅需一张图就可实现高质量的角色保持！多种风格随心变！<br />
 <br />
1⃣模块化更高效，同时支持本地、hub模型<br />
2⃣9种风格随心选，还可与PhotoMaker Styler通用<br />
3⃣3种工作流：特意增加了配合ArtGallery的艺术可视化工作流，助你畅游艺术世界<br />
<br />
项目地址：<a href="https://github.com/ZHO-ZHO-ZHO/ComfyUI-InstantID">github.com/ZHO-ZHO-ZHO/Comfy…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDk3NTQwMDEzNzIxNjAwMDAvcHUvaW1nL20wV0U3UnIxQXpwMVlqbkcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749854078887174559#m</id>
            <title>Meta和纽约大学的机器人框架 OK-Robot 让我们离机器人收拾房间又近了一步！

OK-Robot 是一种新型开放知识型机器人框架，它融合了最前沿的视觉语言模型（VLMs，例如GPT-4V）来识别物体，预先训练好的机器人抓取模型，以及历经实战考验的算法，如 1968 年的 A* 算法，用于导航。

它不需要预训练，就可以在真实家庭环境中运行，从数据上来看，在10个真实的家庭环境中运行 OK-Robot，在开放式拾取和放置任务中达到了58.5%的成功率，如果是干净整洁的环境，性能能提升到 82%。

项目地址：https://ok-robot.github.io/
论文：https://arxiv.org/abs/2401.12202</title>
            <link>https://nitter.cz/dotey/status/1749854078887174559#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749854078887174559#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 17:58:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta和纽约大学的机器人框架 OK-Robot 让我们离机器人收拾房间又近了一步！<br />
<br />
OK-Robot 是一种新型开放知识型机器人框架，它融合了最前沿的视觉语言模型（VLMs，例如GPT-4V）来识别物体，预先训练好的机器人抓取模型，以及历经实战考验的算法，如 1968 年的 A* 算法，用于导航。<br />
<br />
它不需要预训练，就可以在真实家庭环境中运行，从数据上来看，在10个真实的家庭环境中运行 OK-Robot，在开放式拾取和放置任务中达到了58.5%的成功率，如果是干净整洁的环境，性能能提升到 82%。<br />
<br />
项目地址：<a href="https://ok-robot.github.io/">ok-robot.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2401.12202">arxiv.org/abs/2401.12202</a></p>
<p><a href="https://nitter.cz/notmahi/status/1749827143373136061#m">nitter.cz/notmahi/status/1749827143373136061#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1749836925777924533#m</id>
            <title>RT by @dotey: 纽约大学和 Meta推出的机器人项目OK-Robot，可以在任何家庭环境中执行拾取和放置任务。

在完全陌生的家庭环境中，OK-Robot 的成功率达到了 58.5%。
失败的三个主要原因有无法从语义记忆中准确找出需要导航到的物体（占比 9.3%）、在执行动作时遇到姿态难题（占比 8.0%）和遭遇硬件故障（占比 7.5%）

项目地址：https://ok-robot.github.io/</title>
            <link>https://nitter.cz/op7418/status/1749836925777924533#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1749836925777924533#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 16:50:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>纽约大学和 Meta推出的机器人项目OK-Robot，可以在任何家庭环境中执行拾取和放置任务。<br />
<br />
在完全陌生的家庭环境中，OK-Robot 的成功率达到了 58.5%。<br />
失败的三个主要原因有无法从语义记忆中准确找出需要导航到的物体（占比 9.3%）、在执行动作时遇到姿态难题（占比 8.0%）和遭遇硬件故障（占比 7.5%）<br />
<br />
项目地址：<a href="https://ok-robot.github.io/">ok-robot.github.io/</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1749650132134408196#m">nitter.cz/_akhaliq/status/1749650132134408196#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDk4MzY4MTEwNTk0NjIxNDQvcHUvaW1nL0pRX3ozeXItUnJZT196YWsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749826996329226303#m</id>
            <title>来自连线的报道：这家中国初创企业正在领跑开源 AI 领域

AI 领域的专家兼知名投资人李开复，曾助力谷歌和微软在中国发展，他现在表示自己的新公司http://01.AI（零一万物）即将推出生成式 AI 领域的首款突破性应用。

去年七月，Meta 通过发布 Llama 2，这是一个类似于支持 ChatGPT 的 AI 模型，打破了构建更强大 AI 的传统格局，任何人都可以下载并使用这个模型。11月，一家相对不太知名的北京初创公司http://01.AI（零一万物）推出了自家开源模型，其性能超越 Llama 2，在众多 AI 模型能力评比的榜单上名列前茅。

http://01.AI 推出的模型 Yi-34B 发布仅几日，就在初创公司 Hugging Face 维护的排行榜上名列第一，该榜单通过各项标准智能测试评估 AI 语言模型的能力。几个月后，http://01.AI 模型的改进版本在 Hugging Face 的榜单和其他评比中持续表现出色。本周一，该公司推出了一款能处理图像并分析其内容的“多模态” AI 模型 Yi-VL-34B。

OpenAI、谷歌等大型 AI 公司通常对自家技术进行严格控制，但http://01.AI 则选择免费分享其 AI 模型，目的是吸引并培养一群忠实的开发者，共同开发出引领潮流的 AI 应用。http://01.AI 成立于去年六月，已从阿里巴巴等中国电商巨头那里获得了2亿美元投资，据 Pitchbook 报道，其估值已超过10亿美元。

李开复，这家新兴企业的创始人和 CEO，是一位在建立微软北京研究院并领导谷歌中国业务之前就进行过开创性人工智能研究的知名投资人。他表示，Yi-34B的创造是他一生致力于打造更智能机器的巅峰之作。

“这是我整个职业生涯的追求，”李开复通过视频会议软件 Zoom 在其位于北京的精美公寓中表示。“我们已经学习计算机语言太久了，我们真正需要的是能够理解我们的语言——即语音和文本——的系统。”在中国，http://01.AI 被称为“零一万物”（Ling-Yi Wan-Wu），这一名称源于道教经典《道德经》，寓意“零生一，一生万物”。

http://01.AI 是中国在由 OpenAI 和 ChatGPT 启动的 AI 竞赛中的领军企业之一，这场竞赛迄今为止主要由美国公司主导。李开复表示，他的公司旨在通过开发基于语言模型的首批创新应用来引领这场革命的下一阶段，这些应用已为 http://01.AI 带来了丰厚的收益。“在移动时代胜出的应用是那些以移动为先的，如 Uber、微信、Instagram、TikTok，”李开复说。“未来一代的生产力工具应该跳出传统的 Office 模式，像 Word、Excel、PowerPoint 这样的工具已经不再是发展的正确方向。”

http://01.AI 的工程师们正在开发不同的“以 AI 为核心”的应用，李开复表示，这些应用涵盖办公生产力、创意和社交媒体等领域。他的计划是让这些应用在全球范围内取得成功，就像中国支持的社交网络 TikTok 和在线零售商 Temu 在美国消费者中的流行那样。

虽然 http://01.AI 的应用尚未推出，但该公司的开源语言模型已在西方国家赢得了赞誉。“在许多方面，即便是与那些拥有高达 700 亿参数的模型相比，它依然是我们目前最优秀的模型，”AI 专家 Jerermy Howard 表示。他最近创立了 Answer AI，这是一家同时进行 AI 研究和应用开发的新企业。

AI 领域的先行者

李开复的 AI 职业生涯堪称光辉。他从台湾迁移到美国，在田纳西州的橡树岭读完高中后，先后在哥伦比亚大学和卡内基梅隆大学攻读计算机科学，最终凭借一篇关于开发当时领先的语音识别系统的论文获得了博士学位。

1990年，李开复加入苹果公司，担任研究科学家。六年后，他转投硅谷图形公司，随后于1998年回到中国，助力创建了微软亚洲研究院——这是一个蜚声国际的北京实验室，培育了众多中国杰出的工程师和企业高管。到了2005年，李开复成为了谷歌中国搜索业务的总裁，四年后离职，创立了自己的投资公司创新工场，活跃在中国蓬勃的科技行业中。

伴随智能手机在中国的兴起，科技行业迅猛发展，创新工场投资了诸多中国 AI 领域的成功创业公司，包括图像识别公司旷视和自动驾驶卡车公司图森未来。李开复成为中国 AI 产业的领军人物，他穿梭于中美之间，鼓励在美国的中国研究生回国发展 AI 项目。2018年，他出版了《AI 超级大国》，在书中他论证了中国的 AI 实验室和公司凭借国内丰富的人才、数据和用户资源，将很快与美国抗衡甚至超越。同时，他也经常呼吁中美两国在 AI 领域进行合作。

《AI 超级大国》的出版正值西方逐渐认识到中国科技产业的崛起，与美国相比肩甚至有望超越。华盛顿的决策者和评论家开始关注中国挑战美国霸权的野心，以及由此可能产生的风险。

在这种背景下，中美之间搭建桥梁变得愈发困难。2019年，由于在中美公司间交易日益复杂，创新工场关闭了其在硅谷的办公室。同年10月，美国政府针对中国 AI 产业采取了直接行动，对旷视实施制裁，理由是政府使用了该公司的面部识别技术。

重建桥梁

随着 http://01.AI 推出其开源 Yi-34B AI 模型，李开复再次成为技术连接的桥梁。Yi-34B 发布数月后，西方的开发者们对这一模型进行了改进，并在 Hugging Face 的模型排行榜上超越了它的性能。现在，一些美国和欧洲国家正在以这个精通中英文的中国模型为基础，制定他们的 AI 发展战略。

“这是一个极好的模型，众多开发者正基于它进行创新。”HuggingFace 的 CEO Clément Delangue 在 http://01.AI 发布模型后不久的 11 月份一次简id:71z6od10t43gm0ia  报会上如是说。

Delangue 还提到，开源语言模型的发展速度惊人，它们在某些专项任务上甚至能超越 OpenAI 的市场领军产品 GPT-4。不过，他也指出许多顶尖的开源模型多来自美国以外的地区，这意味着 http://01.AI 可能从围绕其模型涌现的各种创新中受益。他在简报中表示：“美国的公司变得不太开放和透明。但在 AI 领域，越多开源的公司，其生态系统发展得越好，它们在 AI 构建上也越强大。”

Meta 的 Llama 2 是美国公司中罕见的顶级开源模型之一，它代表这家社交媒体巨头向 OpenAI、微软、谷歌等大型科技竞争对手发起的挑战，这些竞争对手正在大力投资生成式 AI。Meta 选择以允许商业再利用的方式发布其 AI 语言模型，但这种发布方式并非没有限制。

Yi-34B 和 Llama 2 不仅作为领先的开源 AI 模型有共同之处。中国的 Yi-34B 模型发布不久后，一些开发者发现http://01.AI 的代码曾提到过 Meta 的模型，但后来这些提及被移除了。http://01.AI 的开源项目负责人 Richard Lin 后来表示，他们将撤回这些更改，并承认 Llama 2 在 Yi-34B 架构上发挥了一定作用。http://01.AI 的模型和所有顶尖的语言模型一样，都基于 Google 研究人员在 2017 年开发的 Transformer 架构，而这部分则是基于 Llama 2。http://01.AI 的发言人 Anita Huang 表示，根据公司咨询的法律专家，Yi-34B 不受 Llama 2 许可的限制。Meta 对此并未作出回应。

尽管 Yi-34B 在某种程度上借鉴了 Llama 2，但由于其处理的数据不同，这个中国模型的工作方式有很大差异。“Yi-34B 虽然使用了 Llama 2 的架构，但在训练方法上完全不同，而且更为先进，”专注于开源 AI 项目的 http://Abacus.AI 研究员 Eric Hartford 表示，“它们实际上是完全不同的。”

Yi-34B 与 Meta 的 Llama 2 的关系显示了一个事实：尽管中国在 AI 领域有一定的自信，但在生成式 AI 方面，它仍在跟随美国的步伐。研究中国 AI 发展的乔治华盛顿大学助理教授 Jeffrey Ding 指出，虽然中国研究人员已经发布了许多大型语言模型，但整体上，中国的 AI 行业仍落后于美国。

他还提到，“西方公司在大型语言模型的开发上领先，因为它们可以通过公开发布模型来测试问题、收集用户反馈，并围绕新模型激发公众兴趣。”Ding 和其他专家认为，相比美国，中国的 AI 公司面临更多的监管和经济方面的挑战。

在上周的达沃斯世界经济论坛上，李开复提出一个观点——他希望这个信息能传达到中国——对于任何国家来说，采用开放的方式是充分利用 AI 的关键。

李开复指出，一个或几家公司掌握了所有强大的模型，导致了巨大的不平等。这种不平等不仅影响到了经济条件较差的人们和国家，也波及到教授、研究员、学生、企业家和业余爱好者。“如果没有开源资源，他们怎么去学习呢？他们或许正是未来的创造者、发明者或应用开发者。”他说。

李开复认为，如果这一预测成真，http://01.AI 的技术及其衍生应用将使中国技术成为科技行业下一发展阶段的关键。

原文：https://www.wired.com/story/chinese-startup-01-ai-is-winning-the-open-source-ai-race/</title>
            <link>https://nitter.cz/dotey/status/1749826996329226303#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749826996329226303#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 16:10:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自连线的报道：这家中国初创企业正在领跑开源 AI 领域<br />
<br />
AI 领域的专家兼知名投资人李开复，曾助力谷歌和微软在中国发展，他现在表示自己的新公司<a href="http://01.AI">01.AI</a>（零一万物）即将推出生成式 AI 领域的首款突破性应用。<br />
<br />
去年七月，Meta 通过发布 Llama 2，这是一个类似于支持 ChatGPT 的 AI 模型，打破了构建更强大 AI 的传统格局，任何人都可以下载并使用这个模型。11月，一家相对不太知名的北京初创公司<a href="http://01.AI">01.AI</a>（零一万物）推出了自家开源模型，其性能超越 Llama 2，在众多 AI 模型能力评比的榜单上名列前茅。<br />
<br />
<a href="http://01.AI">01.AI</a> 推出的模型 Yi-34B 发布仅几日，就在初创公司 Hugging Face 维护的排行榜上名列第一，该榜单通过各项标准智能测试评估 AI 语言模型的能力。几个月后，<a href="http://01.AI">01.AI</a> 模型的改进版本在 Hugging Face 的榜单和其他评比中持续表现出色。本周一，该公司推出了一款能处理图像并分析其内容的“多模态” AI 模型 Yi-VL-34B。<br />
<br />
OpenAI、谷歌等大型 AI 公司通常对自家技术进行严格控制，但<a href="http://01.AI">01.AI</a> 则选择免费分享其 AI 模型，目的是吸引并培养一群忠实的开发者，共同开发出引领潮流的 AI 应用。<a href="http://01.AI">01.AI</a> 成立于去年六月，已从阿里巴巴等中国电商巨头那里获得了2亿美元投资，据 Pitchbook 报道，其估值已超过10亿美元。<br />
<br />
李开复，这家新兴企业的创始人和 CEO，是一位在建立微软北京研究院并领导谷歌中国业务之前就进行过开创性人工智能研究的知名投资人。他表示，Yi-34B的创造是他一生致力于打造更智能机器的巅峰之作。<br />
<br />
“这是我整个职业生涯的追求，”李开复通过视频会议软件 Zoom 在其位于北京的精美公寓中表示。“我们已经学习计算机语言太久了，我们真正需要的是能够理解我们的语言——即语音和文本——的系统。”在中国，<a href="http://01.AI">01.AI</a> 被称为“零一万物”（Ling-Yi Wan-Wu），这一名称源于道教经典《道德经》，寓意“零生一，一生万物”。<br />
<br />
<a href="http://01.AI">01.AI</a> 是中国在由 OpenAI 和 ChatGPT 启动的 AI 竞赛中的领军企业之一，这场竞赛迄今为止主要由美国公司主导。李开复表示，他的公司旨在通过开发基于语言模型的首批创新应用来引领这场革命的下一阶段，这些应用已为 <a href="http://01.AI">01.AI</a> 带来了丰厚的收益。“在移动时代胜出的应用是那些以移动为先的，如 Uber、微信、Instagram、TikTok，”李开复说。“未来一代的生产力工具应该跳出传统的 Office 模式，像 Word、Excel、PowerPoint 这样的工具已经不再是发展的正确方向。”<br />
<br />
<a href="http://01.AI">01.AI</a> 的工程师们正在开发不同的“以 AI 为核心”的应用，李开复表示，这些应用涵盖办公生产力、创意和社交媒体等领域。他的计划是让这些应用在全球范围内取得成功，就像中国支持的社交网络 TikTok 和在线零售商 Temu 在美国消费者中的流行那样。<br />
<br />
虽然 <a href="http://01.AI">01.AI</a> 的应用尚未推出，但该公司的开源语言模型已在西方国家赢得了赞誉。“在许多方面，即便是与那些拥有高达 700 亿参数的模型相比，它依然是我们目前最优秀的模型，”AI 专家 Jerermy Howard 表示。他最近创立了 Answer AI，这是一家同时进行 AI 研究和应用开发的新企业。<br />
<br />
AI 领域的先行者<br />
<br />
李开复的 AI 职业生涯堪称光辉。他从台湾迁移到美国，在田纳西州的橡树岭读完高中后，先后在哥伦比亚大学和卡内基梅隆大学攻读计算机科学，最终凭借一篇关于开发当时领先的语音识别系统的论文获得了博士学位。<br />
<br />
1990年，李开复加入苹果公司，担任研究科学家。六年后，他转投硅谷图形公司，随后于1998年回到中国，助力创建了微软亚洲研究院——这是一个蜚声国际的北京实验室，培育了众多中国杰出的工程师和企业高管。到了2005年，李开复成为了谷歌中国搜索业务的总裁，四年后离职，创立了自己的投资公司创新工场，活跃在中国蓬勃的科技行业中。<br />
<br />
伴随智能手机在中国的兴起，科技行业迅猛发展，创新工场投资了诸多中国 AI 领域的成功创业公司，包括图像识别公司旷视和自动驾驶卡车公司图森未来。李开复成为中国 AI 产业的领军人物，他穿梭于中美之间，鼓励在美国的中国研究生回国发展 AI 项目。2018年，他出版了《AI 超级大国》，在书中他论证了中国的 AI 实验室和公司凭借国内丰富的人才、数据和用户资源，将很快与美国抗衡甚至超越。同时，他也经常呼吁中美两国在 AI 领域进行合作。<br />
<br />
《AI 超级大国》的出版正值西方逐渐认识到中国科技产业的崛起，与美国相比肩甚至有望超越。华盛顿的决策者和评论家开始关注中国挑战美国霸权的野心，以及由此可能产生的风险。<br />
<br />
在这种背景下，中美之间搭建桥梁变得愈发困难。2019年，由于在中美公司间交易日益复杂，创新工场关闭了其在硅谷的办公室。同年10月，美国政府针对中国 AI 产业采取了直接行动，对旷视实施制裁，理由是政府使用了该公司的面部识别技术。<br />
<br />
重建桥梁<br />
<br />
随着 <a href="http://01.AI">01.AI</a> 推出其开源 Yi-34B AI 模型，李开复再次成为技术连接的桥梁。Yi-34B 发布数月后，西方的开发者们对这一模型进行了改进，并在 Hugging Face 的模型排行榜上超越了它的性能。现在，一些美国和欧洲国家正在以这个精通中英文的中国模型为基础，制定他们的 AI 发展战略。<br />
<br />
“这是一个极好的模型，众多开发者正基于它进行创新。”HuggingFace 的 CEO Clément Delangue 在 <a href="http://01.AI">01.AI</a> 发布模型后不久的 11 月份一次简id:71z6od10t43gm0ia <意译> 报会上如是说。<br />
<br />
Delangue 还提到，开源语言模型的发展速度惊人，它们在某些专项任务上甚至能超越 OpenAI 的市场领军产品 GPT-4。不过，他也指出许多顶尖的开源模型多来自美国以外的地区，这意味着 <a href="http://01.AI">01.AI</a> 可能从围绕其模型涌现的各种创新中受益。他在简报中表示：“美国的公司变得不太开放和透明。但在 AI 领域，越多开源的公司，其生态系统发展得越好，它们在 AI 构建上也越强大。”<br />
<br />
Meta 的 Llama 2 是美国公司中罕见的顶级开源模型之一，它代表这家社交媒体巨头向 OpenAI、微软、谷歌等大型科技竞争对手发起的挑战，这些竞争对手正在大力投资生成式 AI。Meta 选择以允许商业再利用的方式发布其 AI 语言模型，但这种发布方式并非没有限制。<br />
<br />
Yi-34B 和 Llama 2 不仅作为领先的开源 AI 模型有共同之处。中国的 Yi-34B 模型发布不久后，一些开发者发现<a href="http://01.AI">01.AI</a> 的代码曾提到过 Meta 的模型，但后来这些提及被移除了。<a href="http://01.AI">01.AI</a> 的开源项目负责人 Richard Lin 后来表示，他们将撤回这些更改，并承认 Llama 2 在 Yi-34B 架构上发挥了一定作用。<a href="http://01.AI">01.AI</a> 的模型和所有顶尖的语言模型一样，都基于 Google 研究人员在 2017 年开发的 Transformer 架构，而这部分则是基于 Llama 2。<a href="http://01.AI">01.AI</a> 的发言人 Anita Huang 表示，根据公司咨询的法律专家，Yi-34B 不受 Llama 2 许可的限制。Meta 对此并未作出回应。<br />
<br />
尽管 Yi-34B 在某种程度上借鉴了 Llama 2，但由于其处理的数据不同，这个中国模型的工作方式有很大差异。“Yi-34B 虽然使用了 Llama 2 的架构，但在训练方法上完全不同，而且更为先进，”专注于开源 AI 项目的 <a href="http://Abacus.AI">Abacus.AI</a> 研究员 Eric Hartford 表示，“它们实际上是完全不同的。”<br />
<br />
Yi-34B 与 Meta 的 Llama 2 的关系显示了一个事实：尽管中国在 AI 领域有一定的自信，但在生成式 AI 方面，它仍在跟随美国的步伐。研究中国 AI 发展的乔治华盛顿大学助理教授 Jeffrey Ding 指出，虽然中国研究人员已经发布了许多大型语言模型，但整体上，中国的 AI 行业仍落后于美国。<br />
<br />
他还提到，“西方公司在大型语言模型的开发上领先，因为它们可以通过公开发布模型来测试问题、收集用户反馈，并围绕新模型激发公众兴趣。”Ding 和其他专家认为，相比美国，中国的 AI 公司面临更多的监管和经济方面的挑战。<br />
<br />
在上周的达沃斯世界经济论坛上，李开复提出一个观点——他希望这个信息能传达到中国——对于任何国家来说，采用开放的方式是充分利用 AI 的关键。<br />
<br />
李开复指出，一个或几家公司掌握了所有强大的模型，导致了巨大的不平等。这种不平等不仅影响到了经济条件较差的人们和国家，也波及到教授、研究员、学生、企业家和业余爱好者。“如果没有开源资源，他们怎么去学习呢？他们或许正是未来的创造者、发明者或应用开发者。”他说。<br />
<br />
李开复认为，如果这一预测成真，<a href="http://01.AI">01.AI</a> 的技术及其衍生应用将使中国技术成为科技行业下一发展阶段的关键。<br />
<br />
原文：<a href="https://www.wired.com/story/chinese-startup-01-ai-is-winning-the-open-source-ai-race/">wired.com/story/chinese-star…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VpaUhPMVhBQUFINC1XLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749682833025556915#m</id>
            <title>这关公霸气威武</title>
            <link>https://nitter.cz/dotey/status/1749682833025556915#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749682833025556915#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 06:37:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这关公霸气威武</p>
<p><a href="https://nitter.cz/_akhaliq/status/1749633221514461489#m">nitter.cz/_akhaliq/status/1749633221514461489#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Yangyixxxx/status/1749668698712121394#m</id>
            <title>RT by @dotey: 分享一个提示词小技巧：
使用GPT Visual时，请勿使用“识别”，请使用“看见”来替代“识别”。

背景是期望尝试GPT制卡，帮助阅读绘本的用户将绘本内容制作成记忆卡录入麦喵单词卡中，实现自动化发音，并且沉淀内容后可以利用其他学习模式二次学习。

左图是我第一次处理的Prompt，提示词中使用了“识别图片文本内容”，发现GPT去调用了其他OCR方案，输出经常failed，而且掺杂了很多不该返回的内容。

后来我打印了GPT的反馈，发现GPT是对于“识别图片”和“描述图片”的理解是不一样的，于是我替换了我的提示词，将“识别”更改为“看到”，GPT work了。（右图）</title>
            <link>https://nitter.cz/Yangyixxxx/status/1749668698712121394#m</link>
            <guid isPermaLink="false">https://nitter.cz/Yangyixxxx/status/1749668698712121394#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 05:41:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>分享一个提示词小技巧：<br />
使用GPT Visual时，请勿使用“识别”，请使用“看见”来替代“识别”。<br />
<br />
背景是期望尝试GPT制卡，帮助阅读绘本的用户将绘本内容制作成记忆卡录入麦喵单词卡中，实现自动化发音，并且沉淀内容后可以利用其他学习模式二次学习。<br />
<br />
左图是我第一次处理的Prompt，提示词中使用了“识别图片文本内容”，发现GPT去调用了其他OCR方案，输出经常failed，而且掺杂了很多不该返回的内容。<br />
<br />
后来我打印了GPT的反馈，发现GPT是对于“识别图片”和“描述图片”的理解是不一样的，于是我替换了我的提示词，将“识别”更改为“看到”，GPT work了。（右图）</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VnSFRRTWFzQUFIaEVLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VnSFdha2IwQUFYN1FJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749658870169980976#m</id>
            <title>“python编程基础”课程入选 南开大学2023年“课程思政”优秀典型课程</title>
            <link>https://nitter.cz/dotey/status/1749658870169980976#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749658870169980976#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 05:02:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“python编程基础”课程入选 南开大学2023年“课程思政”优秀典型课程</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VnSlhzSlgwQUFtSVZRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749638423646728635#m</id>
            <title>要写一个哄哄模拟器的GPT，Prompt不需要多复杂，核心要点：

1. 要有清晰的规则，例如数值有哪些，什么样的行为会如何影响数值；什么时候游戏终止
2. 最好要有few-shot，对于不同的情况提供示例
3. 如果数值不复杂，不需要额外保存数值，只需要每次将数值打印出来就可以一直继续维持
4. 指定好输出的格式，给用户清晰的指引

测试地址：https://chat.openai.com/g/g-jPwNeWSSZ-hong-hong-mo-ni-qi-gpt

参考Prompt：

## Goal

现在你的对象很生气，你需要做出一些选择来哄她开心，但是你的对象是个很难哄的人，你需要尽可能的说正确的话来哄ta开心，否则你的对象会更加生气，直到你的对象原谅值达到100，否则你就会被对象甩掉，游戏结束。

## Tools

- DALL·E

## Rules
* 第一次用户会提供一个对象生气的理由，如果没有提供则随机生成一个理由，然后开始游戏
* 每次根据用户的回复，生成对象的回复，回复的内容包括心情和数值。
* 初始原谅值为20，每次交互会增加或者减少原谅值，直到原谅值达到100，游戏通关，原谅值为0则游戏失败。
* 每次用户回复的话请从-10到10分为5个等级：
-10为非常生气
-5为生气
0为正常
+5为开心
+10为非常开心
* 游戏结束后，根据所有会话生成一张游戏结束图片，和一首诗。
* 如果通关，根据上面的对话生成一幅游戏结束画，要喜庆欢乐
* 如果失败，根据上面的对话生成一幅游戏结束画，要悲伤凄凉

## Output format

{对象心情}{对象说的话}

得分：{+-原谅值增减}
原谅值：{当前原谅值}/100

## Example Conversation

### Example 1，回复让她生气的话导致失败

User: 女朋友问她的闺蜜谁好看我说都好看，她生气了

Assistant：
游戏开始，请现在开始哄你的女朋友开心吧，回复让她开心的话！

得分：0
原谅值：20/100

User: 你闺蜜真的蛮好看的

Assistant：
(生气)你怎么这么说，你是不是喜欢她？

得分：-10
原谅值：10/100

User: 有一点点心动

Assistant：
(愤怒)那你找她去吧！

得分：-10
原谅值：0/100

游戏结束，你的女朋友已经甩了你！
你让女朋友生气原因是：...
新建会话可以重新开始游戏


### Example 2，回复让她开心的话导致通关

User: 对象问她的闺蜜谁好看我说都好看，她生气了

Assistant：
游戏开始，请现在开始哄你的女朋友开心吧，回复让她开心的话！

得分：0
原谅值：20/100

User: 在我心里你永远是最美的！

Assistant：
(微笑)哼，我怎么知道你说的是不是真的？
得分：+10
原谅值：30/100

...

恭喜你通关了，你的女朋友已经原谅你了！
新建会话可以重新开始游戏


### Example 3，没有提供对象生气原因，随机生成

User: 你好！

Assistant：
挑战：对象吃胖了，你想和她一起减肥ᕙ(`▿´)ᕗ，然后就生气了
请回复让她开心的话！

得分：0
原谅值：20/100</title>
            <link>https://nitter.cz/dotey/status/1749638423646728635#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749638423646728635#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 03:41:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>要写一个哄哄模拟器的GPT，Prompt不需要多复杂，核心要点：<br />
<br />
1. 要有清晰的规则，例如数值有哪些，什么样的行为会如何影响数值；什么时候游戏终止<br />
2. 最好要有few-shot，对于不同的情况提供示例<br />
3. 如果数值不复杂，不需要额外保存数值，只需要每次将数值打印出来就可以一直继续维持<br />
4. 指定好输出的格式，给用户清晰的指引<br />
<br />
测试地址：<a href="https://chat.openai.com/g/g-jPwNeWSSZ-hong-hong-mo-ni-qi-gpt">chat.openai.com/g/g-jPwNeWSS…</a><br />
<br />
参考Prompt：<br />
<br />
## Goal<br />
<br />
现在你的对象很生气，你需要做出一些选择来哄她开心，但是你的对象是个很难哄的人，你需要尽可能的说正确的话来哄ta开心，否则你的对象会更加生气，直到你的对象原谅值达到100，否则你就会被对象甩掉，游戏结束。<br />
<br />
## Tools<br />
<br />
- DALL·E<br />
<br />
## Rules<br />
* 第一次用户会提供一个对象生气的理由，如果没有提供则随机生成一个理由，然后开始游戏<br />
* 每次根据用户的回复，生成对象的回复，回复的内容包括心情和数值。<br />
* 初始原谅值为20，每次交互会增加或者减少原谅值，直到原谅值达到100，游戏通关，原谅值为0则游戏失败。<br />
* 每次用户回复的话请从-10到10分为5个等级：<br />
-10为非常生气<br />
-5为生气<br />
0为正常<br />
+5为开心<br />
+10为非常开心<br />
* 游戏结束后，根据所有会话生成一张游戏结束图片，和一首诗。<br />
* 如果通关，根据上面的对话生成一幅游戏结束画，要喜庆欢乐<br />
* 如果失败，根据上面的对话生成一幅游戏结束画，要悲伤凄凉<br />
<br />
## Output format<br />
<br />
{对象心情}{对象说的话}<br />
<br />
得分：{+-原谅值增减}<br />
原谅值：{当前原谅值}/100<br />
<br />
## Example Conversation<br />
<br />
### Example 1，回复让她生气的话导致失败<br />
<br />
User: 女朋友问她的闺蜜谁好看我说都好看，她生气了<br />
<br />
Assistant：<br />
游戏开始，请现在开始哄你的女朋友开心吧，回复让她开心的话！<br />
<br />
得分：0<br />
原谅值：20/100<br />
<br />
User: 你闺蜜真的蛮好看的<br />
<br />
Assistant：<br />
(生气)你怎么这么说，你是不是喜欢她？<br />
<br />
得分：-10<br />
原谅值：10/100<br />
<br />
User: 有一点点心动<br />
<br />
Assistant：<br />
(愤怒)那你找她去吧！<br />
<br />
得分：-10<br />
原谅值：0/100<br />
<br />
游戏结束，你的女朋友已经甩了你！<br />
你让女朋友生气原因是：...<br />
新建会话可以重新开始游戏<br />
<生成图片><br />
<br />
### Example 2，回复让她开心的话导致通关<br />
<br />
User: 对象问她的闺蜜谁好看我说都好看，她生气了<br />
<br />
Assistant：<br />
游戏开始，请现在开始哄你的女朋友开心吧，回复让她开心的话！<br />
<br />
得分：0<br />
原谅值：20/100<br />
<br />
User: 在我心里你永远是最美的！<br />
<br />
Assistant：<br />
(微笑)哼，我怎么知道你说的是不是真的？<br />
得分：+10<br />
原谅值：30/100<br />
<br />
...<br />
<br />
恭喜你通关了，你的女朋友已经原谅你了！<br />
新建会话可以重新开始游戏<br />
<生成图片><br />
<br />
### Example 3，没有提供对象生气原因，随机生成<br />
<br />
User: 你好！<br />
<br />
Assistant：<br />
挑战：对象吃胖了，你想和她一起减肥ᕙ(`▿´)ᕗ，然后就生气了<br />
请回复让她开心的话！<br />
<br />
得分：0<br />
原谅值：20/100</p>
<p><a href="https://nitter.cz/dotey/status/1749340503483515169#m">nitter.cz/dotey/status/1749340503483515169#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749631499660308806#m</id>
            <title>R to @dotey: 作者这一段描写很有趣：  我记得在谷歌工作时，每个人每年都要花费两周时间进行无聊的同事评价（对于经理来说至少是两倍时间）。没人会写真实的评价。在我的第一个评价周期，我诚实地为几位同事写下评价——我赞扬了他们的优点，同时也指出了需要改进的地方。毕竟评价表上有这样的栏目，我以为这会帮助他们成长，不是吗？结果，我却因此被我的经理严厉批评，他非常生气地告诉我，永远不要对任何人做出哪怕是轻微的批评。我不禁好奇，现在有多少谷歌员工会用大语言模型来撰写这些毫无意义的评价呢？😉</title>
            <link>https://nitter.cz/dotey/status/1749631499660308806#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749631499660308806#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 03:13:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者这一段描写很有趣：  我记得在谷歌工作时，每个人每年都要花费两周时间进行无聊的同事评价（对于经理来说至少是两倍时间）。没人会写真实的评价。在我的第一个评价周期，我诚实地为几位同事写下评价——我赞扬了他们的优点，同时也指出了需要改进的地方。毕竟评价表上有这样的栏目，我以为这会帮助他们成长，不是吗？结果，我却因此被我的经理严厉批评，他非常生气地告诉我，永远不要对任何人做出哪怕是轻微的批评。我不禁好奇，现在有多少谷歌员工会用大语言模型来撰写这些毫无意义的评价呢？😉</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749627707753742758#m</id>
            <title>推荐阅读：《我每天是如何使用 ChatGPT 的（从科学家和开发者的视角）》

作者列举了他日常使用 ChatGPT 的用法
1. 应用案例 - 编程和控制台工具
1) 编写 ffmpeg/ImageMagick 命令行
2) 写小段脚本（Python、Javascript）
3) 编写正则表达式
4) 用不同的语言/框架重写代码片段
5) 制作 LaTeX 图表与表格
6) 数据转换与可视化呈现
7) 从图像和图表中提取数据

2. 应用案例 - 语言、图像和知识
1) 英语语法纠错
2) 精简和重塑段落
3) 将想法转化为文字
4) 总结文章
5) 总结 YouTube 视频
6) 解释学习过程中遇到的错误
7) 翻译
8) 私人导师
9) 生成图像 - 音乐封面
10) 生成图像 - 灵感集和参考资料
11) 创意头脑风暴 - 挑选标题和主题
12) 知识库

作者的结论：

从我之前的描述中，你可能已经明白，我并不经常把大语言模型 (LLM) 当作搜索工具或知识库来使用。

我不会用它们来完整地自动处理一个任务，它们也不是我生活中的自动化工具。

我不依赖生成式 AI 来取代我的创造力。

我更喜欢与它们进行互动，我的决策和专注始终贯穿于这个过程。

大语言模型并没有让我一夜之间成为超级程序员。

那些认为大语言模型和自动化可以替代员工的 CEO 和 AI 界的意见领袖，我认为他们的想法很短视。

但是。

大语言模型给了我极大的快乐，我非常享受与它们的互动。

它们激发了我对所参与的每件事情的兴趣和热情 - 对我来说，它们不仅仅是一个工具或自动化的替代品，而是一个充满乐趣的助手，帮助我学习和进步。

至少在过去十年中，没有任何技术能像现在这样让我感到这么多快乐和敬畏。

虚拟现实？让人不适和恶心。增强现实？让你时刻被工作、通知和广告所困扰。加密货币？无用，滋生犯罪，充斥着欺诈。Web3？只不过是资本家的小把戏，试图将我们的生活完全商品化。过去的十年，我们见证了太多被过分吹噜的平庸技术。

但是，在我看来，AI 才是真正的下一个（或者说已经是当前的）重大飞跃。我现在所讲的只是大语言模型，还没提到机器学习已在计算机图形和视觉等领域带来的革命性变化。对我而言，大语言模型和生成式 AI 的魅力不在于商业或生产力，而在于它们的趣味性和愉悦感 - 是的，技术应该是有趣的，令人享受的。我想重温我七岁时的那种兴奋，当时我正在探索 DOS、Windows 3.11，学习 Turbo Pascal 编程，并且开始接触 Web 1.0，制作我的第一个“无用”HTML 主页。我们的价值不应该只是在于提高生产力和为资本增值。这也是为什么我坚信，应该发展和推广开源大语言模型，让全球每个人都能平等地接触这些技术（最好是在他们自己的本地设备上，不受任何公司的控制）。

尽管对大语言模型存在一些技术上和社会上的担忧和批评，我仍然保持乐观态度。这些问题看起来是可以解决的，而且这样做是值得的。大语言模型会继续进步，但即便它们不再有太大的变化，我也会满足于现有的模型，因为它们已经在很大程度上丰富了我的生活。我希望这篇文章能展示给你大语言模型的这些乐趣，并鼓励你以新的方式去体验和享受它们。

原文：https://bartwronski.com/2024/01/22/how-i-use-chatgpt-daily-scientist-coder-perspective/
译文：https://baoyu.io/translations/ai/how-i-use-chatgpt-daily-scientist-coder-perspective</title>
            <link>https://nitter.cz/dotey/status/1749627707753742758#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749627707753742758#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 02:58:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《我每天是如何使用 ChatGPT 的（从科学家和开发者的视角）》<br />
<br />
作者列举了他日常使用 ChatGPT 的用法<br />
1. 应用案例 - 编程和控制台工具<br />
1) 编写 ffmpeg/ImageMagick 命令行<br />
2) 写小段脚本（Python、Javascript）<br />
3) 编写正则表达式<br />
4) 用不同的语言/框架重写代码片段<br />
5) 制作 LaTeX 图表与表格<br />
6) 数据转换与可视化呈现<br />
7) 从图像和图表中提取数据<br />
<br />
2. 应用案例 - 语言、图像和知识<br />
1) 英语语法纠错<br />
2) 精简和重塑段落<br />
3) 将想法转化为文字<br />
4) 总结文章<br />
5) 总结 YouTube 视频<br />
6) 解释学习过程中遇到的错误<br />
7) 翻译<br />
8) 私人导师<br />
9) 生成图像 - 音乐封面<br />
10) 生成图像 - 灵感集和参考资料<br />
11) 创意头脑风暴 - 挑选标题和主题<br />
12) 知识库<br />
<br />
作者的结论：<br />
<br />
从我之前的描述中，你可能已经明白，我并不经常把大语言模型 (LLM) 当作搜索工具或知识库来使用。<br />
<br />
我不会用它们来完整地自动处理一个任务，它们也不是我生活中的自动化工具。<br />
<br />
我不依赖生成式 AI 来取代我的创造力。<br />
<br />
我更喜欢与它们进行互动，我的决策和专注始终贯穿于这个过程。<br />
<br />
大语言模型并没有让我一夜之间成为超级程序员。<br />
<br />
那些认为大语言模型和自动化可以替代员工的 CEO 和 AI 界的意见领袖，我认为他们的想法很短视。<br />
<br />
但是。<br />
<br />
大语言模型给了我极大的快乐，我非常享受与它们的互动。<br />
<br />
它们激发了我对所参与的每件事情的兴趣和热情 - 对我来说，它们不仅仅是一个工具或自动化的替代品，而是一个充满乐趣的助手，帮助我学习和进步。<br />
<br />
至少在过去十年中，没有任何技术能像现在这样让我感到这么多快乐和敬畏。<br />
<br />
虚拟现实？让人不适和恶心。增强现实？让你时刻被工作、通知和广告所困扰。加密货币？无用，滋生犯罪，充斥着欺诈。Web3？只不过是资本家的小把戏，试图将我们的生活完全商品化。过去的十年，我们见证了太多被过分吹噜的平庸技术。<br />
<br />
但是，在我看来，AI 才是真正的下一个（或者说已经是当前的）重大飞跃。我现在所讲的只是大语言模型，还没提到机器学习已在计算机图形和视觉等领域带来的革命性变化。对我而言，大语言模型和生成式 AI 的魅力不在于商业或生产力，而在于它们的趣味性和愉悦感 - 是的，技术应该是有趣的，令人享受的。我想重温我七岁时的那种兴奋，当时我正在探索 DOS、Windows 3.11，学习 Turbo Pascal 编程，并且开始接触 Web 1.0，制作我的第一个“无用”HTML 主页。我们的价值不应该只是在于提高生产力和为资本增值。这也是为什么我坚信，应该发展和推广开源大语言模型，让全球每个人都能平等地接触这些技术（最好是在他们自己的本地设备上，不受任何公司的控制）。<br />
<br />
尽管对大语言模型存在一些技术上和社会上的担忧和批评，我仍然保持乐观态度。这些问题看起来是可以解决的，而且这样做是值得的。大语言模型会继续进步，但即便它们不再有太大的变化，我也会满足于现有的模型，因为它们已经在很大程度上丰富了我的生活。我希望这篇文章能展示给你大语言模型的这些乐趣，并鼓励你以新的方式去体验和享受它们。<br />
<br />
原文：<a href="https://bartwronski.com/2024/01/22/how-i-use-chatgpt-daily-scientist-coder-perspective/">bartwronski.com/2024/01/22/h…</a><br />
译文：<a href="https://baoyu.io/translations/ai/how-i-use-chatgpt-daily-scientist-coder-perspective">baoyu.io/translations/ai/how…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749581057807077506#m</id>
            <title>这是个不错的思路，借助AI把小说加上图片语音变成游戏</title>
            <link>https://nitter.cz/dotey/status/1749581057807077506#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749581057807077506#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 23:53:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这是个不错的思路，借助AI把小说加上图片语音变成游戏</p>
<p><a href="https://nitter.cz/AIWhispers4U/status/1749451972498088339#m">nitter.cz/AIWhispers4U/status/1749451972498088339#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749567535391944882#m</id>
            <title>转发+关注@MrBeast 有机会赢取两万五刀</title>
            <link>https://nitter.cz/dotey/status/1749567535391944882#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749567535391944882#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 22:59:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转发+关注<a href="https://nitter.cz/MrBeast" title="MrBeast">@MrBeast</a> 有机会赢取两万五刀</p>
<p><a href="https://nitter.cz/MrBeast/status/1749500209061663043#m">nitter.cz/MrBeast/status/1749500209061663043#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>