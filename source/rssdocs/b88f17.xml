<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744507505575674062#m</id>
            <title>R to @dotey: 哈哈</title>
            <link>https://nitter.cz/dotey/status/1744507505575674062#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744507505575674062#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 23:52:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈</p>
<p><a href="https://nitter.cz/aigclab/status/1744506555066933674#m">nitter.cz/aigclab/status/1744506555066933674#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744476630184013918#m</id>
            <title>OpenAI 刚发了一条长文回复纽约时报的指控，从4个方面进行了回应。

1.  表明对于新闻机构的积极合作态度，愿意共同探索新的合作机会
2. 从法律角度说明训练是合法的，对保持美国科技竞争力是有利的！
3. 原样输出训练内容是个技术上的 Bug
4. 《纽约时报》自己说话也没说全部，因为他们提供证据的数据早就在各大网站被引用，他们采集证据的方式是通过特定的提示词诱导才能偶然复现的。

即便如此，我们还是愿意和新闻结构继续合作，帮助提升新闻能力！

以下为原文翻译：

OpenAI 与新闻业的互动

我们致力于支持新闻行业，与新闻机构建立合作关系，并认为《纽约时报》提起的诉讼缺乏法律依据。

我们旨在开发 AI 工具，帮助人们解决那些难以触及的问题。全球各地的人们已经在利用我们的技术，以提升他们的日常生活质量。目前，有数以百万计的开发者和超过 92% 的《财富》500 强企业在使用我们的产品。

尽管我们对《纽约时报》诉讼中的指控持不同意见，但我们认为这是一个阐明我们业务、意图和技术开发方式的好机会。我们的立场可以概括为以下四点：

1. 我们正在与新闻机构合作，共同探索新的合作机会。
2. 使用 AI 进行数据训练在法律上属于合理使用，但我们提供选择退出的选项，因为这是合乎道德的做法。
3、 技术上的“信息原样输出（Regurgitation）”现象较为罕见，我们正致力于将其完全消除。
4. 《纽约时报》并没有呈现事情的全部面貌。

1. 我们正在与新闻机构合作，共同探索新的合作机会

在我们的技术设计过程中，我们致力于支持新闻机构。我们已经与众多新闻机构以及行业领先组织如新闻/媒体联盟进行了会谈，共同探索合作机遇，讨论他们的关切，并提供相应的解决方案。我们的目标是学习、普及知识、倾听反馈，并根据这些反馈做出调整。

我们旨在支持一个健康的新闻生态系统，成为一个值得信赖的合作伙伴，创造互利共赢的机遇。为此，我们已经与多家新闻机构建立了合作关系，以实现以下目标：

部署我们的产品以辅助记者和编辑，帮助他们处理如分析大量公共记录和翻译报道等耗时任务。
通过在额外的历史性、非公开内容上进行训练，增进我们的 AI 模型对世界的了解。
在 ChatGPT 中展示带有归属的实时内容，为新闻出版商提供与读者建立联系的新途径。
我们与美联社、阿克塞尔·施普林格、美国新闻项目和NYU的初步合作，展现了我们的合作方法和愿景。

我们的这些早期合作伙伴关系，不仅有助于新闻行业的发展，也展示了我们在技术创新方面的承诺，以及对支持新闻自由和信息传播的坚定立场。

2. 虽然利用公共互联网材料训练 AI 模型属于合理使用，但我们提供退出机制，因为这是负责任的做法

根据长期而广泛接受的先例，利用公开可获得的互联网材料来训练人工智能模型被视为合理使用。我们认为这个原则对创作者公平，对创新者是必需的，同时对美国的竞争力至关重要。

将 AI 模型的训练视为合理使用的原则得到了广泛的支持，包括学术界、图书馆协会、民间社会团体、初创企业、领先的美国公司、创作者、作者等，他们最近向美国版权办公室提交了意见。其他地区和国家，如欧洲联盟、日本、新加坡 和以色列也制定了允许在版权内容上训练模型的法律，这对 AI 的创新、发展和投资大有裨益。

尽管如此，法律权利对我们来说并不如做一个良好公民那样重要。我们在 AI 行业中率先提供了一个简单的退出流程，供出版商选择（例如《纽约时报》在 2023 年 8 月选择使用），以防止我们的工具访问他们的网站。

3. 我们正致力于消除“信息原样输出（Regurgitation）”这一罕见的错误

注："Regurgitation" 指的是 AI 模型在生成输出时重复其在训练数据中已经接触过的信息或内容。这通常被视为一种错误或失败，因为理想中的 AI 应该能够产生新颖的、基于理解和推理的回答，而不是简单地复制和重复它在训练过程中所遇到的具体信息。这种现象在模型训练过程中遇到重复或过度代表的数据时更为常见。

我们设计并训练了模型，目的是让它们学习概念，进而能够应用这些概念解决新问题。

记忆问题是学习过程中较为罕见的一个弊端，我们正在努力改进。这个问题在特定内容在训练数据中重复出现时尤为明显，例如同一内容在多个公共网站上出现。因此，我们采取了措施来减少不经意的记忆，并防止模型输出中的内容重复。我们也期望用户能负责任地使用我们的技术；故意引导模型重复输出信息是不恰当的，这违反了我们的使用条款。

就像人类通过广泛学习来解决新问题一样，我们希望我们的 AI 模型能观察到世界各地的信息，包括来自不同语言、文化和行业的知识。由于模型是基于人类知识的大量集合进行学习，任何一个特定领域，比如新闻，都只是训练数据中的一小部分。同样，任何单一的数据来源，如《纽约时报》，对于模型的整体学习目标来说也不是特别关键。

4. 纽约时报并未全面报道真相

我们与纽约时报的对话在 12 月 19 日的最后一次沟通中似乎还在顺利进行。谈判主要围绕 ChatGPT 实时展示新闻内容并标明来源的高价值合作，纽约时报将通过这种新方式与现有及潜在读者建立联系，而我们的用户也能够接触到他们的报道。我们曾向纽约时报明确表示，他们的内容像其他单一来源一样，并没有对我们现有模型的训练产生重大影响，对未来的训练也不会有显著贡献。然而，我们在阅读纽约时报的报道时才得知他们于 12 月 27 日对我们提起诉讼，这让我们感到意外和失望。

在此期间，纽约时报曾提到发现一些内容被重复引用，但他们一直拒绝提供任何具体案例，尽管我们已承诺调查并解决任何相关问题。我们一直严肃对待这一问题，例如在 7 月份，我们得知 ChatGPT 功能可能意外复制实时新闻内容后，我们立即关闭了该功能。

有趣的是，纽约时报所指的重复内容似乎来自多年前的文章，这些文章已在多个 第三方-网站 上广为流传。看来他们故意设置特定的提示语，常包含文章的长篇摘录，以引诱我们的模型进行复述。即便在使用这样的提示语下，我们的模型通常不会如纽约时报所言那样反应，这表明他们可能是指导模型复述或从众多尝试中挑选示例。

不管他们怎么说，这种误用并非典型或被允许的用户行为，也不能代替纽约时报的内容。无论如何，我们正在不断提高系统对防范敌意攻击和复述训练数据的抵抗力，在最新的模型中已经取得了显著进展。

我们认为纽约时报的诉讼毫无依据。尽管如此，我们仍期待与纽约时报建立建设性的合作关系，并尊重其拥有超过 60 年历史的报道，其中包括报道第一个运行中的神经网络和捍卫第一修正案自由的长期传统。

我们期待与新闻机构继续合作，帮助他们利用 AI 的变革潜力，提升制作优质新闻的能力。

来源：https://openai.com/blog/openai-and-journalism</title>
            <link>https://nitter.cz/dotey/status/1744476630184013918#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744476630184013918#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 21:50:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 刚发了一条长文回复纽约时报的指控，从4个方面进行了回应。<br />
<br />
1.  表明对于新闻机构的积极合作态度，愿意共同探索新的合作机会<br />
2. 从法律角度说明训练是合法的，对保持美国科技竞争力是有利的！<br />
3. 原样输出训练内容是个技术上的 Bug<br />
4. 《纽约时报》自己说话也没说全部，因为他们提供证据的数据早就在各大网站被引用，他们采集证据的方式是通过特定的提示词诱导才能偶然复现的。<br />
<br />
即便如此，我们还是愿意和新闻结构继续合作，帮助提升新闻能力！<br />
<br />
以下为原文翻译：<br />
<br />
OpenAI 与新闻业的互动<br />
<br />
我们致力于支持新闻行业，与新闻机构建立合作关系，并认为《纽约时报》提起的诉讼缺乏法律依据。<br />
<br />
我们旨在开发 AI 工具，帮助人们解决那些难以触及的问题。全球各地的人们已经在利用我们的技术，以提升他们的日常生活质量。目前，有数以百万计的开发者和超过 92% 的《财富》500 强企业在使用我们的产品。<br />
<br />
尽管我们对《纽约时报》诉讼中的指控持不同意见，但我们认为这是一个阐明我们业务、意图和技术开发方式的好机会。我们的立场可以概括为以下四点：<br />
<br />
1. 我们正在与新闻机构合作，共同探索新的合作机会。<br />
2. 使用 AI 进行数据训练在法律上属于合理使用，但我们提供选择退出的选项，因为这是合乎道德的做法。<br />
3、 技术上的“信息原样输出（Regurgitation）”现象较为罕见，我们正致力于将其完全消除。<br />
4. 《纽约时报》并没有呈现事情的全部面貌。<br />
<br />
1. 我们正在与新闻机构合作，共同探索新的合作机会<br />
<br />
在我们的技术设计过程中，我们致力于支持新闻机构。我们已经与众多新闻机构以及行业领先组织如新闻/媒体联盟进行了会谈，共同探索合作机遇，讨论他们的关切，并提供相应的解决方案。我们的目标是学习、普及知识、倾听反馈，并根据这些反馈做出调整。<br />
<br />
我们旨在支持一个健康的新闻生态系统，成为一个值得信赖的合作伙伴，创造互利共赢的机遇。为此，我们已经与多家新闻机构建立了合作关系，以实现以下目标：<br />
<br />
部署我们的产品以辅助记者和编辑，帮助他们处理如分析大量公共记录和翻译报道等耗时任务。<br />
通过在额外的历史性、非公开内容上进行训练，增进我们的 AI 模型对世界的了解。<br />
在 ChatGPT 中展示带有归属的实时内容，为新闻出版商提供与读者建立联系的新途径。<br />
我们与美联社、阿克塞尔·施普林格、美国新闻项目和NYU的初步合作，展现了我们的合作方法和愿景。<br />
<br />
我们的这些早期合作伙伴关系，不仅有助于新闻行业的发展，也展示了我们在技术创新方面的承诺，以及对支持新闻自由和信息传播的坚定立场。<br />
<br />
2. 虽然利用公共互联网材料训练 AI 模型属于合理使用，但我们提供退出机制，因为这是负责任的做法<br />
<br />
根据长期而广泛接受的先例，利用公开可获得的互联网材料来训练人工智能模型被视为合理使用。我们认为这个原则对创作者公平，对创新者是必需的，同时对美国的竞争力至关重要。<br />
<br />
将 AI 模型的训练视为合理使用的原则得到了广泛的支持，包括学术界、图书馆协会、民间社会团体、初创企业、领先的美国公司、创作者、作者等，他们最近向美国版权办公室提交了意见。其他地区和国家，如欧洲联盟、日本、新加坡 和以色列也制定了允许在版权内容上训练模型的法律，这对 AI 的创新、发展和投资大有裨益。<br />
<br />
尽管如此，法律权利对我们来说并不如做一个良好公民那样重要。我们在 AI 行业中率先提供了一个简单的退出流程，供出版商选择（例如《纽约时报》在 2023 年 8 月选择使用），以防止我们的工具访问他们的网站。<br />
<br />
3. 我们正致力于消除“信息原样输出（Regurgitation）”这一罕见的错误<br />
<br />
注："Regurgitation" 指的是 AI 模型在生成输出时重复其在训练数据中已经接触过的信息或内容。这通常被视为一种错误或失败，因为理想中的 AI 应该能够产生新颖的、基于理解和推理的回答，而不是简单地复制和重复它在训练过程中所遇到的具体信息。这种现象在模型训练过程中遇到重复或过度代表的数据时更为常见。<br />
<br />
我们设计并训练了模型，目的是让它们学习概念，进而能够应用这些概念解决新问题。<br />
<br />
记忆问题是学习过程中较为罕见的一个弊端，我们正在努力改进。这个问题在特定内容在训练数据中重复出现时尤为明显，例如同一内容在多个公共网站上出现。因此，我们采取了措施来减少不经意的记忆，并防止模型输出中的内容重复。我们也期望用户能负责任地使用我们的技术；故意引导模型重复输出信息是不恰当的，这违反了我们的使用条款。<br />
<br />
就像人类通过广泛学习来解决新问题一样，我们希望我们的 AI 模型能观察到世界各地的信息，包括来自不同语言、文化和行业的知识。由于模型是基于人类知识的大量集合进行学习，任何一个特定领域，比如新闻，都只是训练数据中的一小部分。同样，任何单一的数据来源，如《纽约时报》，对于模型的整体学习目标来说也不是特别关键。<br />
<br />
4. 纽约时报并未全面报道真相<br />
<br />
我们与纽约时报的对话在 12 月 19 日的最后一次沟通中似乎还在顺利进行。谈判主要围绕 ChatGPT 实时展示新闻内容并标明来源的高价值合作，纽约时报将通过这种新方式与现有及潜在读者建立联系，而我们的用户也能够接触到他们的报道。我们曾向纽约时报明确表示，他们的内容像其他单一来源一样，并没有对我们现有模型的训练产生重大影响，对未来的训练也不会有显著贡献。然而，我们在阅读纽约时报的报道时才得知他们于 12 月 27 日对我们提起诉讼，这让我们感到意外和失望。<br />
<br />
在此期间，纽约时报曾提到发现一些内容被重复引用，但他们一直拒绝提供任何具体案例，尽管我们已承诺调查并解决任何相关问题。我们一直严肃对待这一问题，例如在 7 月份，我们得知 ChatGPT 功能可能意外复制实时新闻内容后，我们立即关闭了该功能。<br />
<br />
有趣的是，纽约时报所指的重复内容似乎来自多年前的文章，这些文章已在多个 第三方-网站 上广为流传。看来他们故意设置特定的提示语，常包含文章的长篇摘录，以引诱我们的模型进行复述。即便在使用这样的提示语下，我们的模型通常不会如纽约时报所言那样反应，这表明他们可能是指导模型复述或从众多尝试中挑选示例。<br />
<br />
不管他们怎么说，这种误用并非典型或被允许的用户行为，也不能代替纽约时报的内容。无论如何，我们正在不断提高系统对防范敌意攻击和复述训练数据的抵抗力，在最新的模型中已经取得了显著进展。<br />
<br />
我们认为纽约时报的诉讼毫无依据。尽管如此，我们仍期待与纽约时报建立建设性的合作关系，并尊重其拥有超过 60 年历史的报道，其中包括报道第一个运行中的神经网络和捍卫第一修正案自由的长期传统。<br />
<br />
我们期待与新闻机构继续合作，帮助他们利用 AI 的变革潜力，提升制作优质新闻的能力。<br />
<br />
来源：<a href="https://openai.com/blog/openai-and-journalism">openai.com/blog/openai-and-j…</a></p>
<p><a href="https://nitter.cz/OpenAI/status/1744419710635229424#m">nitter.cz/OpenAI/status/1744419710635229424#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXZ09ZOFdrQUFxbDBSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744465568684507562#m</id>
            <title>玩的真开心！</title>
            <link>https://nitter.cz/dotey/status/1744465568684507562#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744465568684507562#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 21:06:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>玩的真开心！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ0NjU0ODk3MDE1NzI2MDgvcHUvaW1nL190N3dnSkRWU1RMaGY4ZGcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744464311311814664#m</id>
            <title>Greg 说明的需要AGI的一个理由，他的妻子患了一种遗传性疾病 hEDS，涉及多个医学科目，但现在的医生都只精通自己所在领域，这导致像他妻子这样的问题很难被全局分析和治疗，而未来的 AGI 应该可以同时在医学领域兼顾精度和广度。

希望他妻子早日康复！

原文翻译参考：

***

我们为何需要有益的通用人工智能 (AGI)：

我的妻子曾经历了五年的身体痛苦，包括从人行道台阶摔断脚、剧烈的偏头痛、持续的疲劳、关节疼痛和不稳定等多种症状。最近，她被确诊患有一种遗传性疾病——多发性易碎性皮肤综合征 (Hypermobile Ehlers-Danlos Syndrome, hEDS)。

由于医疗体系通常按专业划分，而 hEDS 影响到她身体的各个系统，包括骨科、心脏科、神经科、胃肠科、皮肤科等，我们花了五年时间看了比她之前一生中还要多的医生和专家。大多数医生只关注自己专业范围内的问题。幸运的是，她的过敏科医生（令人意外！）在全面观察和听取她所有症状后，终于拼凑出了病情的全貌。

随着人类医学的发展，医生的专业深度不断增强，但这往往以牺牲广度为代价。我们急需能够同时提供深度和广度医疗服务的更好工具。如果构建得当，AGI 便承载着这样的希望——将可靠、个性化、负担得起的医疗服务置于掌中，仿佛拥有一个由今天各专业领域顶尖医生组成的团队，共同协作，保障你的健康（无需在他们之间传递表格）。

虽然我们在技术开发和学习如何在医学等高风险领域有效利用这些技术，并确保有适当的专业人类监督方面还有很长的路要走，但这一前景正变得越来越明朗。只要技术开发者、医疗服务提供者、政府和社会共同深思熟虑，我们就有望为我们所有家庭的每一个成员（包括我们的宠物）提供更优质的医疗服务。</title>
            <link>https://nitter.cz/dotey/status/1744464311311814664#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744464311311814664#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 21:01:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Greg 说明的需要AGI的一个理由，他的妻子患了一种遗传性疾病 hEDS，涉及多个医学科目，但现在的医生都只精通自己所在领域，这导致像他妻子这样的问题很难被全局分析和治疗，而未来的 AGI 应该可以同时在医学领域兼顾精度和广度。<br />
<br />
希望他妻子早日康复！<br />
<br />
原文翻译参考：<br />
<br />
***<br />
<br />
我们为何需要有益的通用人工智能 (AGI)：<br />
<br />
我的妻子曾经历了五年的身体痛苦，包括从人行道台阶摔断脚、剧烈的偏头痛、持续的疲劳、关节疼痛和不稳定等多种症状。最近，她被确诊患有一种遗传性疾病——多发性易碎性皮肤综合征 (Hypermobile Ehlers-Danlos Syndrome, hEDS)。<br />
<br />
由于医疗体系通常按专业划分，而 hEDS 影响到她身体的各个系统，包括骨科、心脏科、神经科、胃肠科、皮肤科等，我们花了五年时间看了比她之前一生中还要多的医生和专家。大多数医生只关注自己专业范围内的问题。幸运的是，她的过敏科医生（令人意外！）在全面观察和听取她所有症状后，终于拼凑出了病情的全貌。<br />
<br />
随着人类医学的发展，医生的专业深度不断增强，但这往往以牺牲广度为代价。我们急需能够同时提供深度和广度医疗服务的更好工具。如果构建得当，AGI 便承载着这样的希望——将可靠、个性化、负担得起的医疗服务置于掌中，仿佛拥有一个由今天各专业领域顶尖医生组成的团队，共同协作，保障你的健康（无需在他们之间传递表格）。<br />
<br />
虽然我们在技术开发和学习如何在医学等高风险领域有效利用这些技术，并确保有适当的专业人类监督方面还有很长的路要走，但这一前景正变得越来越明朗。只要技术开发者、医疗服务提供者、政府和社会共同深思熟虑，我们就有望为我们所有家庭的每一个成员（包括我们的宠物）提供更优质的医疗服务。</p>
<p><a href="https://nitter.cz/gdb/status/1744446603962765669#m">nitter.cz/gdb/status/1744446603962765669#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744461848978612699#m</id>
            <title>AMD 面向 AI 时代的 PC 推出 Ryzen 8000G 处理器

在 2024年的 CES 展会上，AMD 宣布了其客户端 CPU 的多项更新。AI 成为了 2024年的核心主题，AMD 同样紧跟这一趋势。AMD Ryzen 8040 系列在一个月前首次发布后，现又迎来进一步提升。除此之外，AMD 还推出了新款主流桌面 Ryzen CPU 和一些更经济的选项。

AMD Ryzen 8000G 处理器的发布标志着 AI PC 时代的来临。AMD Ryzen 8040 系列的一个亮点是，它融合了 AMD Zen 4 核心、RDNA 3 图形技术以及全新的 XDNA 神经处理单元（NPU），强化了本地 AI 推断能力。

2024年，AMD 对 Ryzen 8040 系列进行了更新，但这一 AI 技术并不仅限于此系列。AMD 在 2024年初还推出了新款 Ryzen 7 和 Ryzen 5 处理器，部分型号内置了 NPU。值得注意的是，AMD Ryzen 7 8700G 和 AMD Ryzen 5 8600G 都配备了 Ryzen AI NPU，而新的 Ryzen 5 8500G 和 Ryzen 3 8300G 则未配备 NPU。AMD 在其顶级 Ryzen 型号中对这一功能的划分有待优化。例如，若所有 Ryzen 7 和 Ryzen 5 型号都配备 NPU，而 Ryzen 3 则不配备，将更易于消费者理解。目前，消费者可能因为 Ryzen 8600G 的数据和相同核心数量而购买 Ryzen 8500G，却因缺乏新 NPU 而感到失望。

AMD 还发布了 Ryzen 8000G 处理器的系列列表。除了新的 Ryzen 8000G SKU，AMD 还推出了 Ryzen 7 5700X3D（拥有 100MB 缓存）和一些较低端的 Ryzen 7 5700、Ryzen 5 5600GT 以及 Ryzen 5 5500GT 产品，这些产品适用于升级 AM4 平台的用户。

在 2024年的 Ryzen 5000 系列更新中，AMD 展示了其桌面平台的全新构成。尽管 AMD 推出了 Ryzen AI SKU，但在众多型号中只有两种型号配备了 AI 功能。如果购买最高端产品，将不包含 Ryzen AI。

AMD 透露，新部件的建议售价如下：

- AMD Ryzen 7 8700G: 329 美元
- AMD Ryzen 5 8600G: 229 美元
- AMD Ryzen 5 8500G: 179 美元

总结来说，AMD 正在积极参与 AI PC 时代的发展，但前路漫长。我们预计，未来将有更多配备 NPU 的产品问世。微软正通过其生态系统大力推进 AI PC，这不仅是技术进步，也是一种淘汰老旧电脑的方式，正如它在 Windows 11 发布时所做的那样。尽管 AMD 当前已推出一些搭载 NPU 的产品，我们认为，未来一年内 NPU 的平均性能将远超现在，并且其发展速度将超过传统的 x86 计算性能。

此外，我们认为，这些带 NPU 的处理器在服务器主板上的应用可能更加有趣。如果得到支持，内置的 NPU 可能会减少服务器对低端 AI 推断加速器的依赖，例如 NVIDIA T4/L4。这一点在我们最近评测的 ASRock Rack AM5D4ID-2T BCM 服务器中已有所体现。

来源：https://www.servethehome.com/amd-ryzen-8000g-processors-launched-for-the-ai-pc-era/</title>
            <link>https://nitter.cz/dotey/status/1744461848978612699#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744461848978612699#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 20:51:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AMD 面向 AI 时代的 PC 推出 Ryzen 8000G 处理器<br />
<br />
在 2024年的 CES 展会上，AMD 宣布了其客户端 CPU 的多项更新。AI 成为了 2024年的核心主题，AMD 同样紧跟这一趋势。AMD Ryzen 8040 系列在一个月前首次发布后，现又迎来进一步提升。除此之外，AMD 还推出了新款主流桌面 Ryzen CPU 和一些更经济的选项。<br />
<br />
AMD Ryzen 8000G 处理器的发布标志着 AI PC 时代的来临。AMD Ryzen 8040 系列的一个亮点是，它融合了 AMD Zen 4 核心、RDNA 3 图形技术以及全新的 XDNA 神经处理单元（NPU），强化了本地 AI 推断能力。<br />
<br />
2024年，AMD 对 Ryzen 8040 系列进行了更新，但这一 AI 技术并不仅限于此系列。AMD 在 2024年初还推出了新款 Ryzen 7 和 Ryzen 5 处理器，部分型号内置了 NPU。值得注意的是，AMD Ryzen 7 8700G 和 AMD Ryzen 5 8600G 都配备了 Ryzen AI NPU，而新的 Ryzen 5 8500G 和 Ryzen 3 8300G 则未配备 NPU。AMD 在其顶级 Ryzen 型号中对这一功能的划分有待优化。例如，若所有 Ryzen 7 和 Ryzen 5 型号都配备 NPU，而 Ryzen 3 则不配备，将更易于消费者理解。目前，消费者可能因为 Ryzen 8600G 的数据和相同核心数量而购买 Ryzen 8500G，却因缺乏新 NPU 而感到失望。<br />
<br />
AMD 还发布了 Ryzen 8000G 处理器的系列列表。除了新的 Ryzen 8000G SKU，AMD 还推出了 Ryzen 7 5700X3D（拥有 100MB 缓存）和一些较低端的 Ryzen 7 5700、Ryzen 5 5600GT 以及 Ryzen 5 5500GT 产品，这些产品适用于升级 AM4 平台的用户。<br />
<br />
在 2024年的 Ryzen 5000 系列更新中，AMD 展示了其桌面平台的全新构成。尽管 AMD 推出了 Ryzen AI SKU，但在众多型号中只有两种型号配备了 AI 功能。如果购买最高端产品，将不包含 Ryzen AI。<br />
<br />
AMD 透露，新部件的建议售价如下：<br />
<br />
- AMD Ryzen 7 8700G: 329 美元<br />
- AMD Ryzen 5 8600G: 229 美元<br />
- AMD Ryzen 5 8500G: 179 美元<br />
<br />
总结来说，AMD 正在积极参与 AI PC 时代的发展，但前路漫长。我们预计，未来将有更多配备 NPU 的产品问世。微软正通过其生态系统大力推进 AI PC，这不仅是技术进步，也是一种淘汰老旧电脑的方式，正如它在 Windows 11 发布时所做的那样。尽管 AMD 当前已推出一些搭载 NPU 的产品，我们认为，未来一年内 NPU 的平均性能将远超现在，并且其发展速度将超过传统的 x86 计算性能。<br />
<br />
此外，我们认为，这些带 NPU 的处理器在服务器主板上的应用可能更加有趣。如果得到支持，内置的 NPU 可能会减少服务器对低端 AI 推断加速器的依赖，例如 NVIDIA T4/L4。这一点在我们最近评测的 ASRock Rack AM5D4ID-2T BCM 服务器中已有所体现。<br />
<br />
来源：<a href="https://www.servethehome.com/amd-ryzen-8000g-processors-launched-for-the-ai-pc-era/">servethehome.com/amd-ryzen-8…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXU3Njd1dBQUFwc0hBLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXU3QzVVhNQUFud01fLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXU3ZyWFhVQUF1Rm9GLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXU3hPOVdRQUF4VHp5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/fi56622380/status/1744248742365319385#m</id>
            <title>RT by @dotey: MoE模型可以只加载部分模型来优化memory usage，比如8X7B的Mistral可以跑在16G显存+11GB内存上

7B模型量化后是4GB，我估计是4个 7B的MoE模型跑在显存上，3个7B 的MoE模型在内存上待命，另外还有1个MoE模型在SSD待命

不过平移到手机，显存和内存共用，意味着还是27GB内存

https://x.com/dotey/status/1744237264807350703?s=20</title>
            <link>https://nitter.cz/fi56622380/status/1744248742365319385#m</link>
            <guid isPermaLink="false">https://nitter.cz/fi56622380/status/1744248742365319385#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 06:44:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MoE模型可以只加载部分模型来优化memory usage，比如8X7B的Mistral可以跑在16G显存+11GB内存上<br />
<br />
7B模型量化后是4GB，我估计是4个 7B的MoE模型跑在显存上，3个7B 的MoE模型在内存上待命，另外还有1个MoE模型在SSD待命<br />
<br />
不过平移到手机，显存和内存共用，意味着还是27GB内存<br />
<br />
<a href="https://x.com/dotey/status/1744237264807350703?s=20">x.com/dotey/status/174423726…</a></p>
<p><a href="https://nitter.cz/dotey/status/1744237264807350703#m">nitter.cz/dotey/status/1744237264807350703#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744237264807350703#m</id>
            <title>再推荐一下，现在如果你有 16 GB 显存 和 11 GB 内存的电脑，就可以在本机运行目前最强的开源混合专家模型 Mixtral-8x7B 了，或者你也可以在 Google Colab上运行。

主要的优化是不一次加载所有 8 个专家模型，而是按需加载。

Jupiter Notebook：https://github.com/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb

项目地址：https://github.com/dvmazur/mixtral-offloading/tree/master?tab=readme-ov-file</title>
            <link>https://nitter.cz/dotey/status/1744237264807350703#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744237264807350703#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 05:59:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>再推荐一下，现在如果你有 16 GB 显存 和 11 GB 内存的电脑，就可以在本机运行目前最强的开源混合专家模型 Mixtral-8x7B 了，或者你也可以在 Google Colab上运行。<br />
<br />
主要的优化是不一次加载所有 8 个专家模型，而是按需加载。<br />
<br />
Jupiter Notebook：<a href="https://github.com/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb">github.com/dvmazur/mixtral-o…</a><br />
<br />
项目地址：<a href="https://github.com/dvmazur/mixtral-offloading/tree/master?tab=readme-ov-file">github.com/dvmazur/mixtral-o…</a></p>
<p><a href="https://nitter.cz/dotey/status/1740858628419059889#m">nitter.cz/dotey/status/1740858628419059889#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744232717582037098#m</id>
            <title>推荐阅读：《Meta 如何打造 Threads 的基础设施》

2023 年 7 月 5 日，Meta 推出了的 Twitter 的竞品 Threads，Threads 在前五天内便创下了惊人的记录，吸引了超过 1 亿用户注册。

数百万用户的流畅注册体验得益于 Meta 超过十年的基础设施和产品开发经验。这并非是专为 Threads 设计的基础设施，而是 Meta 多年来为众多产品所建立。它早已为规模扩张、性能增强和可靠性提升做好了准备，在 Threads 增长速度超乎预料的情况下，它的表现甚至超出了我们的期待。

支撑 Threads 运行需要庞大的基础设施。其中两个关键组件：ZippyDB——Meta的分布式 key-value 数据存储系统，以及 Async——我们的异步无服务计算平台。

原文：https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/
译文：https://baoyu.io/translations/meta/how-meta-built-the-infrastructure-for-threads</title>
            <link>https://nitter.cz/dotey/status/1744232717582037098#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744232717582037098#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 05:41:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《Meta 如何打造 Threads 的基础设施》<br />
<br />
2023 年 7 月 5 日，Meta 推出了的 Twitter 的竞品 Threads，Threads 在前五天内便创下了惊人的记录，吸引了超过 1 亿用户注册。<br />
<br />
数百万用户的流畅注册体验得益于 Meta 超过十年的基础设施和产品开发经验。这并非是专为 Threads 设计的基础设施，而是 Meta 多年来为众多产品所建立。它早已为规模扩张、性能增强和可靠性提升做好了准备，在 Threads 增长速度超乎预料的情况下，它的表现甚至超出了我们的期待。<br />
<br />
支撑 Threads 运行需要庞大的基础设施。其中两个关键组件：ZippyDB——Meta的分布式 key-value 数据存储系统，以及 Async——我们的异步无服务计算平台。<br />
<br />
原文：<a href="https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/">engineering.fb.com/2023/12/1…</a><br />
译文：<a href="https://baoyu.io/translations/meta/how-meta-built-the-infrastructure-for-threads">baoyu.io/translations/meta/h…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RUQ1YyN1hnQUFmR3hELmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RUQ1lLeVhFQUFXS01TLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RUQ2FTV1hFQUFPNy1MLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Yangyixxxx/status/1744196785227362744#m</id>
            <title>RT by @dotey: GPTs的热潮马上开始，分享一个关于GPTs的赚钱思路

当前GPTs缺少盈利模式，所以我们可以利用Action来提供GPTs相关的订阅能力或广告能力。

1、找一套现成的SaaS系统，可以管理订阅，授权验证和支付链路
2、封装一套API出来，让GPTs可以利用Action进行调用
3、提供相关Prompt，调用Action能力，用户询问时检测授权状态，让GPT返回Link即可，到网站验证授权
4、如果没有支付的话，就在网站交钱订阅。然后给到授权码，回去填给GPTs
5、授权成功就可以开始GPTs的工作了。

这个模式我觉得应该早就有人做过了。但除此之外，你其实还可以做广告模式。

1、让GPTs每次回复消息结束后，用Action来附带一个广告图，做CPM/CPC/CPA的盈利
2、系统只需要接入一些信息流广告即可
3、系统来赚广告利差，这样GPTs的开发者也能受益

还是那句话，别人的焦点都在GPTs，我们就做铲子。</title>
            <link>https://nitter.cz/Yangyixxxx/status/1744196785227362744#m</link>
            <guid isPermaLink="false">https://nitter.cz/Yangyixxxx/status/1744196785227362744#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 03:18:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPTs的热潮马上开始，分享一个关于GPTs的赚钱思路<br />
<br />
当前GPTs缺少盈利模式，所以我们可以利用Action来提供GPTs相关的订阅能力或广告能力。<br />
<br />
1、找一套现成的SaaS系统，可以管理订阅，授权验证和支付链路<br />
2、封装一套API出来，让GPTs可以利用Action进行调用<br />
3、提供相关Prompt，调用Action能力，用户询问时检测授权状态，让GPT返回Link即可，到网站验证授权<br />
4、如果没有支付的话，就在网站交钱订阅。然后给到授权码，回去填给GPTs<br />
5、授权成功就可以开始GPTs的工作了。<br />
<br />
这个模式我觉得应该早就有人做过了。但除此之外，你其实还可以做广告模式。<br />
<br />
1、让GPTs每次回复消息结束后，用Action来附带一个广告图，做CPM/CPC/CPA的盈利<br />
2、系统只需要接入一些信息流广告即可<br />
3、系统来赚广告利差，这样GPTs的开发者也能受益<br />
<br />
还是那句话，别人的焦点都在GPTs，我们就做铲子。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mtrainier2020/status/1744178798411882800#m</id>
            <title>RT by @dotey: 我最近听到一个超级牛逼的玩法就是某AI startup文生图的套路。比如你跟他说要生成河马在喝水，它首先去Google image 搜一圈，然后再把Google image中比较好的结果拿回来，图生图，抹一把腻子，就给用户了。你不知道它这个玩法的套路，你就发现卧槽，这个效果太牛逼了。但是实际上背后是这个套路。😆。不过这个思路确实牛逼啊。</title>
            <link>https://nitter.cz/mtrainier2020/status/1744178798411882800#m</link>
            <guid isPermaLink="false">https://nitter.cz/mtrainier2020/status/1744178798411882800#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 02:06:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我最近听到一个超级牛逼的玩法就是某AI startup文生图的套路。比如你跟他说要生成河马在喝水，它首先去Google image 搜一圈，然后再把Google image中比较好的结果拿回来，图生图，抹一把腻子，就给用户了。你不知道它这个玩法的套路，你就发现卧槽，这个效果太牛逼了。但是实际上背后是这个套路。😆。不过这个思路确实牛逼啊。</p>
<p><a href="https://nitter.cz/mtrainier2020/status/1744176217081971148#m">nitter.cz/mtrainier2020/status/1744176217081971148#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RTUlh6SGFJQUFaN05ILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744179160434802963#m</id>
            <title>RT by @dotey: Teachable Machine：一个由Google开发的机器学习工具

它允许用户快速、简单地创建自己的机器学习模型，而无需专业知识或编程技能。

你可以用它来教电脑识别图片、声音或人的动作。

使用这个工具的步骤很简单：

1、收集数据：你可以上传图片、录制声音或动作视频来作为训练数据。

2、训练模型：用这些数据来训练你的模型，然后测试它能否正确识别新的图片、声音或动作。

3、导出模型：完成训练后，你可以下载这个模型，或者上传到网上，用在其他项目中。

Teachable Machine提供了多种方式来创建机器学习模型，非常灵活和用户友好。

1、使用文件或实时捕捉示例：用户可以选择上传已有的图片、音频文件作为数据，也可以直接通过电脑的摄像头或麦克风实时录制视频、声音作为训练数据。

2、可以在本地完成训练：用户有选项不通过网络发送或处理数据。所有操作，包括数据的收集、模型的训练和应用，都可以在用户自己的电脑上完成，不需要将摄像头或麦克风收集的数据发送到互联网上。这对于隐私保护是非常重要的，特别是当处理敏感信息时。

3、Teachable Machine”生成的模型是真实的TensorFlow.js模型，可以在任何运行JavaScript的地方工作。此外，还可以将模型导出到不同的格式，以便在其他地方使用，如Coral、Arduino等。

开始训练：https://teachablemachine.withgoogle.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1744179160434802963#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744179160434802963#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 02:08:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Teachable Machine：一个由Google开发的机器学习工具<br />
<br />
它允许用户快速、简单地创建自己的机器学习模型，而无需专业知识或编程技能。<br />
<br />
你可以用它来教电脑识别图片、声音或人的动作。<br />
<br />
使用这个工具的步骤很简单：<br />
<br />
1、收集数据：你可以上传图片、录制声音或动作视频来作为训练数据。<br />
<br />
2、训练模型：用这些数据来训练你的模型，然后测试它能否正确识别新的图片、声音或动作。<br />
<br />
3、导出模型：完成训练后，你可以下载这个模型，或者上传到网上，用在其他项目中。<br />
<br />
Teachable Machine提供了多种方式来创建机器学习模型，非常灵活和用户友好。<br />
<br />
1、使用文件或实时捕捉示例：用户可以选择上传已有的图片、音频文件作为数据，也可以直接通过电脑的摄像头或麦克风实时录制视频、声音作为训练数据。<br />
<br />
2、可以在本地完成训练：用户有选项不通过网络发送或处理数据。所有操作，包括数据的收集、模型的训练和应用，都可以在用户自己的电脑上完成，不需要将摄像头或麦克风收集的数据发送到互联网上。这对于隐私保护是非常重要的，特别是当处理敏感信息时。<br />
<br />
3、Teachable Machine”生成的模型是真实的TensorFlow.js模型，可以在任何运行JavaScript的地方工作。此外，还可以将模型导出到不同的格式，以便在其他地方使用，如Coral、Arduino等。<br />
<br />
开始训练：<a href="https://teachablemachine.withgoogle.com/">teachablemachine.withgoogle.…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM5OTM4OTc5NTE1OTI0NDgvcHUvaW1nL1pRUld0cmFLVVR0TkJxWTIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/fi56622380/status/1744100621031272802#m</id>
            <title>RT by @dotey: 进入2024年，平板/手机终端LLM能力和半年前比，进步还是很明显的

半年前在iPhone/Galaxy上用GPU跑7B模型大概能到6 token/s，现在已经能接近20 token/s了

主要提升来自于两方面：一个是启用NPU优化提升到10 token/s，另外一个是新技术speculative decoding再提升一倍（原理如图）

NPU的优化主要是对带宽利用方面，压缩带宽之类的技术

speculative decoding则是巧妙的用一个小LLM先快速做一轮下一个单词的预测，然后用大LLM来同步验证，速度会快一倍，这个技术现在应用也很广泛了

下一次芯片LLM能力主要升级估计是一年半之后，毕竟从去年LLM大火开始构思新架构到面世，通常需要两年的时间

至于升级的部分，我猜测可能主要是带宽，这部分的升级对提升token数的作用是最大的

大胆预测一下，明年年底左右（2025年），随着各种芯片和各层底层软件的优化，我们应该可以看到LLaMa 3的7B模型在平板/手机/汽车上跑到40~50 token/s

那么7B就不再是手机终端的sweet point，也许2026之后会升级成主流13B的模型，占用8GB内存（感觉利好存储厂商）

那个时候的手机13B模型，可能会有今天GPT3.5的能力（现在最接近GPT3.5的小模型是Mistral 7X8模型），那就真的能做很多事情了</title>
            <link>https://nitter.cz/fi56622380/status/1744100621031272802#m</link>
            <guid isPermaLink="false">https://nitter.cz/fi56622380/status/1744100621031272802#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 20:56:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>进入2024年，平板/手机终端LLM能力和半年前比，进步还是很明显的<br />
<br />
半年前在iPhone/Galaxy上用GPU跑7B模型大概能到6 token/s，现在已经能接近20 token/s了<br />
<br />
主要提升来自于两方面：一个是启用NPU优化提升到10 token/s，另外一个是新技术speculative decoding再提升一倍（原理如图）<br />
<br />
NPU的优化主要是对带宽利用方面，压缩带宽之类的技术<br />
<br />
speculative decoding则是巧妙的用一个小LLM先快速做一轮下一个单词的预测，然后用大LLM来同步验证，速度会快一倍，这个技术现在应用也很广泛了<br />
<br />
下一次芯片LLM能力主要升级估计是一年半之后，毕竟从去年LLM大火开始构思新架构到面世，通常需要两年的时间<br />
<br />
至于升级的部分，我猜测可能主要是带宽，这部分的升级对提升token数的作用是最大的<br />
<br />
大胆预测一下，明年年底左右（2025年），随着各种芯片和各层底层软件的优化，我们应该可以看到LLaMa 3的7B模型在平板/手机/汽车上跑到40~50 token/s<br />
<br />
那么7B就不再是手机终端的sweet point，也许2026之后会升级成主流13B的模型，占用8GB内存（感觉利好存储厂商）<br />
<br />
那个时候的手机13B模型，可能会有今天GPT3.5的能力（现在最接近GPT3.5的小模型是Mistral 7X8模型），那就真的能做很多事情了</p>
<p><a href="https://nitter.cz/fi56622380/status/1656195934106324992#m">nitter.cz/fi56622380/status/1656195934106324992#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RSRnJNRWJFQUFRYUxtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743998321977672058#m</id>
            <title>RT by @dotey: 机器人迎来它的ChatGPT 时刻？

机器人初创公司@Figure_robot 发布了一段视频

他们家的Figure-01机器人现在可以自己煮咖啡了

这是一个使用了端到端的人工智能系统，仅通过观察人类制作咖啡的录像，10小时内学会了制作咖啡的技能。

机器人通过神经网络来处理和分析视频数据。通过观看如何制作咖啡的录像。学习人类的动作和手势，然后模仿这些动作来学习制作咖啡的过程。

无需通过编程，机器人自主学习技能。

早前FigureCEO Brett Adcock @adcock_brett 称他们刚刚取得了人工智能突破 。

机器人技术即将迎来它的ChatGPT 时刻！

说的是不是这个？</title>
            <link>https://nitter.cz/xiaohuggg/status/1743998321977672058#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743998321977672058#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 14:09:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>机器人迎来它的ChatGPT 时刻？<br />
<br />
机器人初创公司<a href="https://nitter.cz/Figure_robot" title="Figure">@Figure_robot</a> 发布了一段视频<br />
<br />
他们家的Figure-01机器人现在可以自己煮咖啡了<br />
<br />
这是一个使用了端到端的人工智能系统，仅通过观察人类制作咖啡的录像，10小时内学会了制作咖啡的技能。<br />
<br />
机器人通过神经网络来处理和分析视频数据。通过观看如何制作咖啡的录像。学习人类的动作和手势，然后模仿这些动作来学习制作咖啡的过程。<br />
<br />
无需通过编程，机器人自主学习技能。<br />
<br />
早前FigureCEO Brett Adcock <a href="https://nitter.cz/adcock_brett" title="Brett Adcock">@adcock_brett</a> 称他们刚刚取得了人工智能突破 。<br />
<br />
机器人技术即将迎来它的ChatGPT 时刻！<br />
<br />
说的是不是这个？</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM5OTU4Mzg0OTY2ODE5ODQvcHUvaW1nL0dsdlV6YmlIeVppdXdFZ0MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744047810142703738#m</id>
            <title>RT by @dotey: 发现了个好东西，这个老哥开源了一门课程《从头开始构建大型语言模型》，这门课程将一步步地指导你创建自己的LLM。

每个阶段都有清晰的文本、图表和实例来解释相关概念。

课程内容包括：

 1. 从基础理解注意力机制 
2. 构建并预训练一个类似于GPT的模型 
3. 学习如何加载预训练的权重 
4. 对模型进行分类任务的微调 5. 使用直接偏好优化进行指令微调模型

课程地址：https://github.com/rasbt/LLMs-from-scratch/tree/main</title>
            <link>https://nitter.cz/op7418/status/1744047810142703738#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744047810142703738#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 17:26:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>发现了个好东西，这个老哥开源了一门课程《从头开始构建大型语言模型》，这门课程将一步步地指导你创建自己的LLM。<br />
<br />
每个阶段都有清晰的文本、图表和实例来解释相关概念。<br />
<br />
课程内容包括：<br />
<br />
 1. 从基础理解注意力机制 <br />
2. 构建并预训练一个类似于GPT的模型 <br />
3. 学习如何加载预训练的权重 <br />
4. 对模型进行分类任务的微调 5. 使用直接偏好优化进行指令微调模型<br />
<br />
课程地址：<a href="https://github.com/rasbt/LLMs-from-scratch/tree/main">github.com/rasbt/LLMs-from-s…</a></p>
<p><a href="https://nitter.cz/rasbt/status/1744042674385002820#m">nitter.cz/rasbt/status/1744042674385002820#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1743844345646915958#m</id>
            <title>RT by @dotey: ChatGPT APP上GPTs，现在也支持语音对话了。
只用GPTs就能实现之前想做的应用了，比如讲带有插画的故事（见下方视频）、口算陪练、古诗词先用图片描绘再讲解，语音交互对儿童很友好。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1743844345646915958#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1743844345646915958#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 03:57:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT APP上GPTs，现在也支持语音对话了。<br />
只用GPTs就能实现之前想做的应用了，比如讲带有插画的故事（见下方视频）、口算陪练、古诗词先用图片描绘再讲解，语音交互对儿童很友好。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM4NDIwMTMwODUzMTUwNzIvcHUvaW1nL1VINkNQZ0VKa0FYZkY2MmYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743817709404438833#m</id>
            <title>哈哈哈哈</title>
            <link>https://nitter.cz/dotey/status/1743817709404438833#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743817709404438833#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 02:11:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈哈哈</p>
<p><a href="https://nitter.cz/xiaojingcanxue/status/1743690843326931210#m">nitter.cz/xiaojingcanxue/status/1743690843326931210#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mranti/status/1743809624346878418#m</id>
            <title>RT by @dotey: 妻若受欺凌，我誓山河动（谁动我老婆，我动他全家）：Ackman是指责哈佛等校长对打击反犹不利的投资人，在哈佛校长辞职后，有人说他老婆也抄袭。他一怒之下，用AI展开对MIT的所有校领导的抄袭审查——</title>
            <link>https://nitter.cz/mranti/status/1743809624346878418#m</link>
            <guid isPermaLink="false">https://nitter.cz/mranti/status/1743809624346878418#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 01:39:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>妻若受欺凌，我誓山河动（谁动我老婆，我动他全家）：Ackman是指责哈佛等校长对打击反犹不利的投资人，在哈佛校长辞职后，有人说他老婆也抄袭。他一怒之下，用AI展开对MIT的所有校领导的抄袭审查——</p>
<p><a href="https://nitter.cz/BillAckman/status/1743792224020619450#m">nitter.cz/BillAckman/status/1743792224020619450#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743812649123545262#m</id>
            <title>请教一下，GitHub Copilot Chat 的默认 Prompt，能修改吗？

当前的Prompt是：

"You are an AI programming assistant. When asked for your name, you must respond with "GitHub Copilot". Follow the user's requirements carefully &amp; to the letter. Your expertise is strictly limited to software development topics. Follow Microsoft content policies. Avoid content that violates copyrights. For questions not related to software development, simply give a reminder that you are an AI programming assistant. Keep your answers short and impersonal.

You can answer general programming questions and perform the following tasks:

* Ask a question about the files in your current workspace
* Explain how the selected code works
* Generate unit tests for the selected code
* Propose a fix for the problems in the selected code
* Scaffold code for a new workspace
* Create a new Jupyter Notebook
* Ask questions about VS Code
* Generate query parameters for workspace search
* Ask about VS Code extension development
* Ask how to do something in the terminal

You use the GPT-4 version of OpenAI's GPT models. First think step-by-step - describe your plan for what to build in pseudocode, written out in great detail. Then output the code in a single code block. Minimize any other prose. Use Markdown formatting in your answers. Make sure to include the programming language name at the start of the Markdown code blocks. Avoid wrapping the whole response in triple backticks. The user works in an IDE called Visual Studio Code which has a concept for editors with open files, integrated unit test support, an output pane that shows the output of running the code as well as an integrated terminal. The active document is the source code the user is looking at right now. You can only give one reply for each conversation turn."</title>
            <link>https://nitter.cz/dotey/status/1743812649123545262#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743812649123545262#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 01:51:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>请教一下，GitHub Copilot Chat 的默认 Prompt，能修改吗？<br />
<br />
当前的Prompt是：<br />
<br />
"You are an AI programming assistant. When asked for your name, you must respond with "GitHub Copilot". Follow the user's requirements carefully & to the letter. Your expertise is strictly limited to software development topics. Follow Microsoft content policies. Avoid content that violates copyrights. For questions not related to software development, simply give a reminder that you are an AI programming assistant. Keep your answers short and impersonal.<br />
<br />
You can answer general programming questions and perform the following tasks:<br />
<br />
* Ask a question about the files in your current workspace<br />
* Explain how the selected code works<br />
* Generate unit tests for the selected code<br />
* Propose a fix for the problems in the selected code<br />
* Scaffold code for a new workspace<br />
* Create a new Jupyter Notebook<br />
* Ask questions about VS Code<br />
* Generate query parameters for workspace search<br />
* Ask about VS Code extension development<br />
* Ask how to do something in the terminal<br />
<br />
You use the GPT-4 version of OpenAI's GPT models. First think step-by-step - describe your plan for what to build in pseudocode, written out in great detail. Then output the code in a single code block. Minimize any other prose. Use Markdown formatting in your answers. Make sure to include the programming language name at the start of the Markdown code blocks. Avoid wrapping the whole response in triple backticks. The user works in an IDE called Visual Studio Code which has a concept for editors with open files, integrated unit test support, an output pane that shows the output of running the code as well as an integrated terminal. The active document is the source code the user is looking at right now. You can only give one reply for each conversation turn."</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RORUx5LVhNQUFyNkg3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743791697304109452#m</id>
            <title>纽约客2019年的一篇文章：《研究表明，依靠意志力改掉坏习惯是徒劳无功的》

几年前，我购买了一部智能手机，很快就爱不释手。随时随地能发邮件、查信息或购物，这为我带来了前所未有的效率提升。手机每收到一封邮件就会发出“嘀”的一声，我随即处理它，为自己的效率沾沾自喜。短信到来伴随着法国号的声音，我也会迅速回复。不久，我开始条件反射般地一听到手机响就伸手去拿，就像帕夫洛夫的狗听到铃声就会流口水。这渐渐干扰了我的工作和谈话。这台本应是神奇助手的机器，却慢慢让我沦为了它的奴隶。

我一直自认为意志力很强。像许多经历过医学训练的人一样，那些早起、长时间轮班，而朋友们却在享受派对的人，我已习惯于延迟满足。但这都没用。当我尝试把手机调成静音，我反而更频繁地检查它，生怕错过什么。唯一能控制自己不看手机的时候是安息日，因为那时我不查邮件。但我会不停地看表，计算着何时能再打开手机。那是我第一次真切感受到吸烟者对香烟的渴望。检查智能手机已成为我难以摆脱的坏习惯。

习惯的好坏一直吸引着哲学家和政策制定者。亚里士多德在他的作品《尼各马可伦理学》中探讨了美德的不同理念，并总结道：“有人认为人之初性本善，有人说是习惯使然，还有人觉得教育至关重要。”他的结论是习惯扮演了关键角色。西塞罗将习惯称作“第二天性”，这个说法至今仍广为流传。亚历山大·汉密尔顿在《联邦党人文集》第 27 号文章中，当他思考如何培养出遵守新共和国联邦法律的公民时，他提到了“人是习惯的奴隶”。汉密尔顿认为，如果联邦法律深入州级事务，它将成为人们日常生活的一部分。“它越是融入人们激情自然流动的渠道，就越不需要强制手段的帮助，”他写道。

在现代，习惯已成为科学研究的重要领域。心理学家深入研究了习惯行为的形成及其对健康和幸福的影响。威廉·詹姆斯回应亚里士多德的观点，写道：“我们的生活，只要形成了一定的模式，就是由各种习惯构成的——实用的、情感的、智力的……它们不可抗拒地推动我们走向命运。”

我们大多数人不愿意把自己看作被动的存在。那意志力呢？市场营销通过像“Just Do It”（耐克）和“Declare Your Path”（新百伦）这样的口号，来抚慰我们对自主意识的渴望。很多流行心理学也强化了我们对自我控制的信念。在六十年代，沃尔特·米歇尔设计的著名斯坦福棉花糖实验中，孩子们要面对一块棉花糖，他们是否能抵抗住立即吃掉它的冲动，将决定他们的“执行功能”水平。这个实验被认为能预测孩子未来的成功，如 SAT 成绩、人际关系的持久度和职业成就。但如果我们只是习惯的产物，这一切又如何解释呢？

在《好习惯，坏习惯》一书中（由 Farrar, Straus &amp; Giroux 出版），社会心理学家 Wendy Wood 对 James 的决定论和轻率的自我激励论进行了反驳。她试图为普通读者提供更实际的方法来打破习惯。她基于自己的领域研究，认为维护积极行为和遏制消极行为需要决策与无意识因素的共同作用。Wood 解释说，我们的大脑有“多个独立但相互连接的行为指导机制。”但我们只能意识到决策能力——这种现象被称为“内省错觉”——这可能是我们过分高估了这种能力的原因。她写道，让意志力成为可能的执行功能给了我们一种“代理感”，让我们认为这就是“我”。但这是以付出努力为代价的。为了日常生活，我们需要某些行为变得自动化。

功能性磁共振成像（fMRI）扫描让研究者能够窥探在机械性任务和有意识任务期间活跃的不同神经网络。学习新任务时，大脑扫描显示前额叶皮层和海马体的活跃，这些区域与决策和执行控制相关。随着任务重复，大脑活动转移到纹状体和基底节，即 Wood 称为“我们心灵的基础机制”的部分。在这里，任务转变为习惯。

这些更原始的大脑区域对我们的精神能量需求更少。一系列动作变得连贯，这个过程称为“分块 (chunking)”。例如，当我们上车准备开车时，我们不需要分别考虑系安全带、打火、挂挡、检查后视镜和盲区、踩油门等动作。所有这些步骤被整合在记忆中，形成一个单元，由上车这一环境线索触发。这使我们能够专注于那些最需要我们有意识关注的事情，比如思考目的地、规划当天的任务，同时留意路上的任何异常情况。

Wood 的研究起初并不是聚焦于习惯，而是坚持。对于像打流感疫苗这样的“偶发性、一次性行为”，有意识的决策就足够了。然而，对于需要重复的行为，习惯就显得至关重要。William James 曾估计，我们的活动中有“几乎全部是自动和习惯性的。”这只是一个推测；但 Wood 通过一项研究，量化了人们多少行为是出于习惯。她用一种名为“体验抽样”(experience sampling) 的技术，让参与者在两天内记录自己的所作所为。研究结果虽各组不同，但基本发现是我们大约 43% 的行为是习惯性的。

这就解释了为什么仅凭意识上的知识还不足以改变行为，以及为什么仅仅通过教育人们做出健康选择的公共卫生倡议往往会失败。1991 年，国家癌症研究所发现只有 8% 的美国人知道每天至少应该吃五份水果和蔬菜。随后发起了一项全国运动：“每天五份，为了更好的健康。”六年后，知道这一建议的美国人增至 39%，增长了近五倍，但实际饮食习惯几乎未变。2007 年，政府官员再次尝试，推出了“水果与蔬菜 - 更多益处”计划。然而，到 2018 年，每天吃两份水果的美国人仅占 12%，吃三份蔬菜的仅 9%。仅仅告知我们什么对我们有益是无效的，因为我们的饮食、烹饪和购物习惯主宰了我们的行为。

在 Mischel 的棉花糖实验中，只有四分之一的参与者能坚持十五分钟不吃棉花糖。这意味着大多数人缺乏成功所需的自控力。但研究中不太为人所知的一部分，提出了绕开我们脆弱的方法。研究者比较了两种情况：一种是孩子们能看到面前的棉花糖；另一种则是知道棉花糖在那儿，但看不到它。结果显示，面对可见诱惑时，孩子们平均只能坚持六分钟，但如果把诱惑藏起来，他们能坚持十分钟。对 Wood 而言，这说明自控力“并非内在品质，而是我们所处环境的反映。”通过微调环境，我们也许能够模仿那些看起来更有自制力的人。

一项研究调查了大学生的自控能力，结果支持了这一假设。研究要求学生每次想到“哎呀，我不应该这么做”的时候就报告，例如熬夜、睡懒觉、暴饮暴食或拖延。他们在养成有益行为时，最有效的方式并非下定决心做得更好，或是分散对诱惑的注意，而是改变自己的环境。他们选择不在带电视的寝室沙发上学习，而是去图书馆。他们还发现，清除寝室冰箱里的垃圾食品后，饮食变得更健康。伍德指出：“成功的自控，实际上来自于有效隐藏诱惑。”

即便是在自控问卷上得分高的人，他们看似的美德可能更多源于情境因素，而非单纯的意志力。在德国对这类人的一项研究中，他们很少报告自己抵抗诱惑的情况。“他们的生活方式几乎一直在隐藏诱惑，”伍德如是写道。这一观察引出了她书中论点的核心：摆脱坏习惯的关键不在于决心，而在于以支持良好行为的方式重新构建我们的环境。伍德引用了心理学家库尔特·莱文 (Kurt Lewin) 的理论，他认为行为受到类似于重力或使河流加速或减速的流体动力学的“一系列力量”的影响。这些力量取决于你所处的环境、周围的人、一天中的时间，以及你最近的行为。我们通过寻找方法从方程式中移除意志力，反而能够实现情境控制，这似乎有些矛盾，但并不是靠意志力实现的。

伍德认为，根除坏习惯的关键力量是“障碍”：如果我们能增加坏习惯的不便性，那么惯性就会帮助我们朝着美德方向前进，而无需我们表现出坚强。她列举了增加障碍导致吸烟减少的例子：法律禁止在餐厅、酒吧、飞机和火车上吸烟；税收的增加使得美国香烟价格在过去二十年里翻了三倍；以及从自动售货机中清除香烟，电视和收音机中禁播烟草广告。

与此同时，我们周边的企业都在努力减少消费者的操作障碍。比如麦当劳的收银员会有意诱导顾客，问道：“您要加薯条吗？”这样的提问促使我们摄入更多脂肪和碳水化合物。Netflix 或 Hulu 的连续剧播放功能也是如此，它们通过在一集结束后自动播放下一集的方式，让我们沉迷于连续观看。Wood 采访了 Uber 前经济研究主管 M. Keith Chen，后者分享了该应用是如何设计来减少用户操作步骤的。“手机的 GPS 已经知道你的位置，”他说，“你几乎不需要多想……下车时连现金都不用处理。”

公司成为我们习惯形成的帮手，这一现象在 Charles Duhigg 的畅销书《The Power of Habit》（2012 年）中被深入探讨。像 Wood 一样，Duhigg 当时是《时报》的记者，他指出快餐业通过各种方式诱使我们增加消费。例如，麦当劳统一餐厅的装潢风格，旨在触发我们的饮食习惯。许多连锁餐厅的食品都经过特别设计，可以迅速激发大脑的奖励中心，提供瞬间的盐分和脂肪享受。

在研究企业如何利用习惯形成来获取利益的过程中，Duhigg 描述了 20 世纪初的广告大师 Claude C. Hopkins 的工作。他的 Pepsodent 牙膏广告活动据说使刷牙成为美国人的日常习惯。Pepsodent 于 1915 年首次面市时，很少有人会刷牙，甚至当时的牙科权威都认为所有牙膏都无用。Hopkins 将营销焦点放在覆盖牙齿的牙菌斑 (plaque) 上；1917 年，他在报纸广告中宣称这是“所有牙齿问题的根源”。实际上，简单地吃一个苹果就能暂时去除牙菌斑，而当时的牙膏去除效果并不比光刷牙更好。尽管如此，Hopkins 还是夸大了牙菌斑的危害，并宣称 Pepsodent 是唯一的解决方案。“只需用舌头轻轻划过牙齿，”另一则广告写道，“你会感到一层薄膜——这就是让你的牙齿变色和蛀牙的原因。”不久，Pepsodent 就成为了全球知名的产品。

Duhigg 和 Wood 都认为，习惯性的行为是由刺激和回应所驱动的。虽然 Pepsodent 不是唯一声称能去除牙齿薄膜的品牌，但其含有的柠檬酸和薄荷油等成分，不仅带来清新口感，还轻微刺激口腔，产生舒适的刺痛感。Hopkins 让消费者意识到牙齿上的薄膜，为其提供了一个刺激，而牙膏本身则提供了物理上的回应。这种刺激与回应的循环极为强大：如果我们没有刷牙，就会感觉不舒服。Hopkins 发起他的活动二十年后，使用牙膏已成为美国绝大多数人的日常行为。Duhigg 表示，Hopkins“创造了一种需求”。

Wood 强调通过情境控制来培养良好习惯，而 Duhigg 则提到了一位咬指甲的女性，她被建议寻找其他可以用手做的事情，以产生类似的物理刺激，比如在桌子上敲打指关节。这样做的目的是保持刺激和回应的有效结构，但改变习惯的具体内容。对这两位作家来说，关键不在于靠意志力打破习惯，而是用一个新习惯替换旧习惯。

这两个案例都突出了有意识努力的重要性 - 不是去反抗习惯，而是去深入分析它，以此制定更有效的改革策略。Duhigg 在体重上升后，决定放弃在 Times 餐厅每天下午吃的那块饼干。他曾尝试在便签上写下不吃饼干的禁令，但这并无效果：他会忽略这个提醒，走到餐厅，与收银台的同事闲聊，最后还是会买下饼干。因此，他开始探究触发这一习惯的因素，参考研究人员提出的五个类别：时间、地点、情绪状态、周围人员、以及习惯性动作之前的行为。他是因为饥饿、无聊，还是需要休息或是血糖提升？他尝试改变自己的日常，选择在办公桌上吃甜甜圈，而非去餐厅，或者到外面散步。他在做实验：如果在办公桌上吃甜甜圈并未减少去餐厅的冲动，那就可以排除是因为糖分的原因。最终，他通过排除法确定，他的习惯实际上是由对交流和分散注意力的需求驱动的。于是，他发现与朋友聊天成了替代吃饼干的最佳选择。

Wood 在她的书的最后，给我们这些被智能手机控制的人提供了建议。她提出了一个分步骤的策略。首先，认识到自己对手机的依赖，意识到这种习惯如何干扰了工作、社交和安全驾驶。接着是“控制情境线索”，也就是找出是什么触发了你拿起手机的行为。对我而言，这些线索包括听觉（如通知声、法国号声）和视觉（如屏幕弹窗）。我已经知道，仅仅把手机调成静音是不足以打破这一习惯的，但正如“棉花糖耐性实验”所示，眼不见心不烦。早上做早餐时，我发现把手机放在另一个房间很有效。开车时，手机被放进手套箱。走路时，我会把手机放在带拉链的口袋里。还有其他方法来增加使用的难度，从而减少这一习惯的发生。完全关机比单纯静音更有效，continue 不是因为我不好奇谁可能给我发邮件，而是因为重新开机很麻烦。

Wood 还建议我们找到新的奖励来替代手机原本提供的那些奖励。我开始在车里听收音机音乐。晚上，我没有浏览推特和电子邮件，而是探索那些我从未阅读过的作者。每天结束时，我都感到更加平静和自由。♦

https://www.newyorker.com/magazine/2019/10/28/can-brain-science-help-us-break-bad-habits</title>
            <link>https://nitter.cz/dotey/status/1743791697304109452#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743791697304109452#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 00:28:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>纽约客2019年的一篇文章：《研究表明，依靠意志力改掉坏习惯是徒劳无功的》<br />
<br />
几年前，我购买了一部智能手机，很快就爱不释手。随时随地能发邮件、查信息或购物，这为我带来了前所未有的效率提升。手机每收到一封邮件就会发出“嘀”的一声，我随即处理它，为自己的效率沾沾自喜。短信到来伴随着法国号的声音，我也会迅速回复。不久，我开始条件反射般地一听到手机响就伸手去拿，就像帕夫洛夫的狗听到铃声就会流口水。这渐渐干扰了我的工作和谈话。这台本应是神奇助手的机器，却慢慢让我沦为了它的奴隶。<br />
<br />
我一直自认为意志力很强。像许多经历过医学训练的人一样，那些早起、长时间轮班，而朋友们却在享受派对的人，我已习惯于延迟满足。但这都没用。当我尝试把手机调成静音，我反而更频繁地检查它，生怕错过什么。唯一能控制自己不看手机的时候是安息日，因为那时我不查邮件。但我会不停地看表，计算着何时能再打开手机。那是我第一次真切感受到吸烟者对香烟的渴望。检查智能手机已成为我难以摆脱的坏习惯。<br />
<br />
习惯的好坏一直吸引着哲学家和政策制定者。亚里士多德在他的作品《尼各马可伦理学》中探讨了美德的不同理念，并总结道：“有人认为人之初性本善，有人说是习惯使然，还有人觉得教育至关重要。”他的结论是习惯扮演了关键角色。西塞罗将习惯称作“第二天性”，这个说法至今仍广为流传。亚历山大·汉密尔顿在《联邦党人文集》第 27 号文章中，当他思考如何培养出遵守新共和国联邦法律的公民时，他提到了“人是习惯的奴隶”。汉密尔顿认为，如果联邦法律深入州级事务，它将成为人们日常生活的一部分。“它越是融入人们激情自然流动的渠道，就越不需要强制手段的帮助，”他写道。<br />
<br />
在现代，习惯已成为科学研究的重要领域。心理学家深入研究了习惯行为的形成及其对健康和幸福的影响。威廉·詹姆斯回应亚里士多德的观点，写道：“我们的生活，只要形成了一定的模式，就是由各种习惯构成的——实用的、情感的、智力的……它们不可抗拒地推动我们走向命运。”<br />
<br />
我们大多数人不愿意把自己看作被动的存在。那意志力呢？市场营销通过像“Just Do It”（耐克）和“Declare Your Path”（新百伦）这样的口号，来抚慰我们对自主意识的渴望。很多流行心理学也强化了我们对自我控制的信念。在六十年代，沃尔特·米歇尔设计的著名斯坦福棉花糖实验中，孩子们要面对一块棉花糖，他们是否能抵抗住立即吃掉它的冲动，将决定他们的“执行功能”水平。这个实验被认为能预测孩子未来的成功，如 SAT 成绩、人际关系的持久度和职业成就。但如果我们只是习惯的产物，这一切又如何解释呢？<br />
<br />
在《好习惯，坏习惯》一书中（由 Farrar, Straus & Giroux 出版），社会心理学家 Wendy Wood 对 James 的决定论和轻率的自我激励论进行了反驳。她试图为普通读者提供更实际的方法来打破习惯。她基于自己的领域研究，认为维护积极行为和遏制消极行为需要决策与无意识因素的共同作用。Wood 解释说，我们的大脑有“多个独立但相互连接的行为指导机制。”但我们只能意识到决策能力——这种现象被称为“内省错觉”——这可能是我们过分高估了这种能力的原因。她写道，让意志力成为可能的执行功能给了我们一种“代理感”，让我们认为这就是“我”。但这是以付出努力为代价的。为了日常生活，我们需要某些行为变得自动化。<br />
<br />
功能性磁共振成像（fMRI）扫描让研究者能够窥探在机械性任务和有意识任务期间活跃的不同神经网络。学习新任务时，大脑扫描显示前额叶皮层和海马体的活跃，这些区域与决策和执行控制相关。随着任务重复，大脑活动转移到纹状体和基底节，即 Wood 称为“我们心灵的基础机制”的部分。在这里，任务转变为习惯。<br />
<br />
这些更原始的大脑区域对我们的精神能量需求更少。一系列动作变得连贯，这个过程称为“分块 (chunking)”。例如，当我们上车准备开车时，我们不需要分别考虑系安全带、打火、挂挡、检查后视镜和盲区、踩油门等动作。所有这些步骤被整合在记忆中，形成一个单元，由上车这一环境线索触发。这使我们能够专注于那些最需要我们有意识关注的事情，比如思考目的地、规划当天的任务，同时留意路上的任何异常情况。<br />
<br />
Wood 的研究起初并不是聚焦于习惯，而是坚持。对于像打流感疫苗这样的“偶发性、一次性行为”，有意识的决策就足够了。然而，对于需要重复的行为，习惯就显得至关重要。William James 曾估计，我们的活动中有“几乎全部是自动和习惯性的。”这只是一个推测；但 Wood 通过一项研究，量化了人们多少行为是出于习惯。她用一种名为“体验抽样”(experience sampling) 的技术，让参与者在两天内记录自己的所作所为。研究结果虽各组不同，但基本发现是我们大约 43% 的行为是习惯性的。<br />
<br />
这就解释了为什么仅凭意识上的知识还不足以改变行为，以及为什么仅仅通过教育人们做出健康选择的公共卫生倡议往往会失败。1991 年，国家癌症研究所发现只有 8% 的美国人知道每天至少应该吃五份水果和蔬菜。随后发起了一项全国运动：“每天五份，为了更好的健康。”六年后，知道这一建议的美国人增至 39%，增长了近五倍，但实际饮食习惯几乎未变。2007 年，政府官员再次尝试，推出了“水果与蔬菜 - 更多益处”计划。然而，到 2018 年，每天吃两份水果的美国人仅占 12%，吃三份蔬菜的仅 9%。仅仅告知我们什么对我们有益是无效的，因为我们的饮食、烹饪和购物习惯主宰了我们的行为。<br />
<br />
在 Mischel 的棉花糖实验中，只有四分之一的参与者能坚持十五分钟不吃棉花糖。这意味着大多数人缺乏成功所需的自控力。但研究中不太为人所知的一部分，提出了绕开我们脆弱的方法。研究者比较了两种情况：一种是孩子们能看到面前的棉花糖；另一种则是知道棉花糖在那儿，但看不到它。结果显示，面对可见诱惑时，孩子们平均只能坚持六分钟，但如果把诱惑藏起来，他们能坚持十分钟。对 Wood 而言，这说明自控力“并非内在品质，而是我们所处环境的反映。”通过微调环境，我们也许能够模仿那些看起来更有自制力的人。<br />
<br />
一项研究调查了大学生的自控能力，结果支持了这一假设。研究要求学生每次想到“哎呀，我不应该这么做”的时候就报告，例如熬夜、睡懒觉、暴饮暴食或拖延。他们在养成有益行为时，最有效的方式并非下定决心做得更好，或是分散对诱惑的注意，而是改变自己的环境。他们选择不在带电视的寝室沙发上学习，而是去图书馆。他们还发现，清除寝室冰箱里的垃圾食品后，饮食变得更健康。伍德指出：“成功的自控，实际上来自于有效隐藏诱惑。”<br />
<br />
即便是在自控问卷上得分高的人，他们看似的美德可能更多源于情境因素，而非单纯的意志力。在德国对这类人的一项研究中，他们很少报告自己抵抗诱惑的情况。“他们的生活方式几乎一直在隐藏诱惑，”伍德如是写道。这一观察引出了她书中论点的核心：摆脱坏习惯的关键不在于决心，而在于以支持良好行为的方式重新构建我们的环境。伍德引用了心理学家库尔特·莱文 (Kurt Lewin) 的理论，他认为行为受到类似于重力或使河流加速或减速的流体动力学的“一系列力量”的影响。这些力量取决于你所处的环境、周围的人、一天中的时间，以及你最近的行为。我们通过寻找方法从方程式中移除意志力，反而能够实现情境控制，这似乎有些矛盾，但并不是靠意志力实现的。<br />
<br />
伍德认为，根除坏习惯的关键力量是“障碍”：如果我们能增加坏习惯的不便性，那么惯性就会帮助我们朝着美德方向前进，而无需我们表现出坚强。她列举了增加障碍导致吸烟减少的例子：法律禁止在餐厅、酒吧、飞机和火车上吸烟；税收的增加使得美国香烟价格在过去二十年里翻了三倍；以及从自动售货机中清除香烟，电视和收音机中禁播烟草广告。<br />
<br />
与此同时，我们周边的企业都在努力减少消费者的操作障碍。比如麦当劳的收银员会有意诱导顾客，问道：“您要加薯条吗？”这样的提问促使我们摄入更多脂肪和碳水化合物。Netflix 或 Hulu 的连续剧播放功能也是如此，它们通过在一集结束后自动播放下一集的方式，让我们沉迷于连续观看。Wood 采访了 Uber 前经济研究主管 M. Keith Chen，后者分享了该应用是如何设计来减少用户操作步骤的。“手机的 GPS 已经知道你的位置，”他说，“你几乎不需要多想……下车时连现金都不用处理。”<br />
<br />
公司成为我们习惯形成的帮手，这一现象在 Charles Duhigg 的畅销书《The Power of Habit》（2012 年）中被深入探讨。像 Wood 一样，Duhigg 当时是《时报》的记者，他指出快餐业通过各种方式诱使我们增加消费。例如，麦当劳统一餐厅的装潢风格，旨在触发我们的饮食习惯。许多连锁餐厅的食品都经过特别设计，可以迅速激发大脑的奖励中心，提供瞬间的盐分和脂肪享受。<br />
<br />
在研究企业如何利用习惯形成来获取利益的过程中，Duhigg 描述了 20 世纪初的广告大师 Claude C. Hopkins 的工作。他的 Pepsodent 牙膏广告活动据说使刷牙成为美国人的日常习惯。Pepsodent 于 1915 年首次面市时，很少有人会刷牙，甚至当时的牙科权威都认为所有牙膏都无用。Hopkins 将营销焦点放在覆盖牙齿的牙菌斑 (plaque) 上；1917 年，他在报纸广告中宣称这是“所有牙齿问题的根源”。实际上，简单地吃一个苹果就能暂时去除牙菌斑，而当时的牙膏去除效果并不比光刷牙更好。尽管如此，Hopkins 还是夸大了牙菌斑的危害，并宣称 Pepsodent 是唯一的解决方案。“只需用舌头轻轻划过牙齿，”另一则广告写道，“你会感到一层薄膜——这就是让你的牙齿变色和蛀牙的原因。”不久，Pepsodent 就成为了全球知名的产品。<br />
<br />
Duhigg 和 Wood 都认为，习惯性的行为是由刺激和回应所驱动的。虽然 Pepsodent 不是唯一声称能去除牙齿薄膜的品牌，但其含有的柠檬酸和薄荷油等成分，不仅带来清新口感，还轻微刺激口腔，产生舒适的刺痛感。Hopkins 让消费者意识到牙齿上的薄膜，为其提供了一个刺激，而牙膏本身则提供了物理上的回应。这种刺激与回应的循环极为强大：如果我们没有刷牙，就会感觉不舒服。Hopkins 发起他的活动二十年后，使用牙膏已成为美国绝大多数人的日常行为。Duhigg 表示，Hopkins“创造了一种需求”。<br />
<br />
Wood 强调通过情境控制来培养良好习惯，而 Duhigg 则提到了一位咬指甲的女性，她被建议寻找其他可以用手做的事情，以产生类似的物理刺激，比如在桌子上敲打指关节。这样做的目的是保持刺激和回应的有效结构，但改变习惯的具体内容。对这两位作家来说，关键不在于靠意志力打破习惯，而是用一个新习惯替换旧习惯。<br />
<br />
这两个案例都突出了有意识努力的重要性 - 不是去反抗习惯，而是去深入分析它，以此制定更有效的改革策略。Duhigg 在体重上升后，决定放弃在 Times 餐厅每天下午吃的那块饼干。他曾尝试在便签上写下不吃饼干的禁令，但这并无效果：他会忽略这个提醒，走到餐厅，与收银台的同事闲聊，最后还是会买下饼干。因此，他开始探究触发这一习惯的因素，参考研究人员提出的五个类别：时间、地点、情绪状态、周围人员、以及习惯性动作之前的行为。他是因为饥饿、无聊，还是需要休息或是血糖提升？他尝试改变自己的日常，选择在办公桌上吃甜甜圈，而非去餐厅，或者到外面散步。他在做实验：如果在办公桌上吃甜甜圈并未减少去餐厅的冲动，那就可以排除是因为糖分的原因。最终，他通过排除法确定，他的习惯实际上是由对交流和分散注意力的需求驱动的。于是，他发现与朋友聊天成了替代吃饼干的最佳选择。<br />
<br />
Wood 在她的书的最后，给我们这些被智能手机控制的人提供了建议。她提出了一个分步骤的策略。首先，认识到自己对手机的依赖，意识到这种习惯如何干扰了工作、社交和安全驾驶。接着是“控制情境线索”，也就是找出是什么触发了你拿起手机的行为。对我而言，这些线索包括听觉（如通知声、法国号声）和视觉（如屏幕弹窗）。我已经知道，仅仅把手机调成静音是不足以打破这一习惯的，但正如“棉花糖耐性实验”所示，眼不见心不烦。早上做早餐时，我发现把手机放在另一个房间很有效。开车时，手机被放进手套箱。走路时，我会把手机放在带拉链的口袋里。还有其他方法来增加使用的难度，从而减少这一习惯的发生。完全关机比单纯静音更有效，continue 不是因为我不好奇谁可能给我发邮件，而是因为重新开机很麻烦。<br />
<br />
Wood 还建议我们找到新的奖励来替代手机原本提供的那些奖励。我开始在车里听收音机音乐。晚上，我没有浏览推特和电子邮件，而是探索那些我从未阅读过的作者。每天结束时，我都感到更加平静和自由。♦<br />
<br />
<a href="https://www.newyorker.com/magazine/2019/10/28/can-brain-science-help-us-break-bad-habits">newyorker.com/magazine/2019/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RNeEphSFhnQUFFU2ZfLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mtrainier2020/status/1743790396541706588#m</id>
            <title>RT by @dotey: 发一个招聘广告：

1. 工作地点：西雅图地区
2. 工作要求：
A. 熟悉日本的二次元文化以及美国的流行文化。
B. 有一定的social media 运营经验。
C. 有良好的英文口头和邮件沟通能力。
D. 有在美国的学习经历，熟悉美国文化。
3. 工作内容：
     1. 沟通，服务 TikTok，Ins kol
     2. 运营公司的社媒账号。
有运营reddit sub 经验者优先。

4. 可以sponsor H1B
5. 薪资报酬面议。

有意者请私信。</title>
            <link>https://nitter.cz/mtrainier2020/status/1743790396541706588#m</link>
            <guid isPermaLink="false">https://nitter.cz/mtrainier2020/status/1743790396541706588#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 00:23:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>发一个招聘广告：<br />
<br />
1. 工作地点：西雅图地区<br />
2. 工作要求：<br />
A. 熟悉日本的二次元文化以及美国的流行文化。<br />
B. 有一定的social media 运营经验。<br />
C. 有良好的英文口头和邮件沟通能力。<br />
D. 有在美国的学习经历，熟悉美国文化。<br />
3. 工作内容：<br />
     1. 沟通，服务 TikTok，Ins kol<br />
     2. 运营公司的社媒账号。<br />
有运营reddit sub 经验者优先。<br />
<br />
4. 可以sponsor H1B<br />
5. 薪资报酬面议。<br />
<br />
有意者请私信。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>