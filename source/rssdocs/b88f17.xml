<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732508883137016304#m</id>
            <title>R to @dotey: 原文：https://blog.google/technology/ai/google-gemini-ai</title>
            <link>https://nitter.cz/dotey/status/1732508883137016304#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732508883137016304#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 21:14:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原文：<a href="https://blog.google/technology/ai/google-gemini-ai">blog.google/technology/ai/go…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMjQyMDYxOTIyNjk4ODU0NC9kaTAteldYUD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732508618333798734#m</id>
            <title>R to @dotey: 在与原版 AlphaCode 相同的平台上进行评估时，AlphaCode 2 展现了显著提升，解决问题数量几乎翻倍。我们估计其性能超过了 85% 的竞赛参与者，相较于 AlphaCode 的近 50% 有显著提高。当程序员与 AlphaCode 2 协作，为代码样本定义特定属性时，其表现更为出色。

我们期待程序员们越来越多地将这些高效能的 AI 模型作为协作工具，以帮助他们解决问题、设计代码，并协助实施，这将使他们能够更快地推出应用程序并设计更好的服务。

更多详情请参阅我们的 AlphaCode 2 技术报告。

更加可靠、可扩展和高效
我们利用 Google 自行设计的 张量处理单元（Tensor Processing Units）（TPUs）v4 和 v5e，在我们为 AI 优化的基础设施上对 Gemini 1.0 进行了大规模训练。Gemini 1.0 被打造成为我们最稳定、最易于扩展的训练模型，同时也是运行最高效的模型。

在 TPUs 上，Gemini 的运行速度远超过之前的较小且功能有限的模型。这些专为 AI 优化的加速器是 Google 众多 AI 驱动产品的核心，服务于全球数十亿用户，如 Google 搜索、YouTube、Gmail、Google 地图、Google Play 和 Android。这些加速器还使全球的公司能够高效、低成本地训练大型 AI 模型。

今天，我们宣布了迄今为止最强大、最高效、最具扩展性的 TPU 系统——Cloud TPU v5p，这是专门为训练前沿 AI 模型而设计的。这款新一代的 TPU 将加快 Gemini 的发展，并助力开发者与企业客户更快地训练大型生成式 AI 模型，让新产品和功能更快地惠及用户。

图一：Google 数据中心内排列着的 Cloud TPU v5p AI 加速超级计算机。

贯彻责任与安全的核心构建理念
在谷歌，我们全力以赴推动大胆、负责的人工智能发展。在谷歌的人工智能原则和我们产品中严格的安全政策的基础上，我们为 Gemini 的多模态能力增添了新的保护措施。在开发的每一步，我们都在仔细考虑潜在风险，并努力进行测试和减轻这些风险。

Gemini 在偏见和毒性方面进行了谷歌迄今最全面的安全评估。我们进行了针对潜在风险领域的开创性研究，如网络攻击、说服力和自主性，并采用了谷歌研究最先进的对抗测试技术，以便在 Gemini 部署前提前发现关键安全问题。

为了找出我们内部评估方法的盲点，我们与一群多元化的外部专家和合作伙伴合作，对我们的模型进行全方位的压力测试。

在 Gemini 的训练阶段，为了诊断内容安全问题并确保其输出符合我们的政策，我们使用了如Real Toxicity Prompts这样的基准测试，这是由 Allen 人工智能研究所的专家开发的，含有来自网络的 10 万个不同毒性级别的提示。更多相关工作的细节即将发布。

为了减少伤害，我们专门建立了安全分类器，用于识别、标记和过滤涉及暴力或负面刻板印象的内容。加上强效的过滤器，这种多层次的方法旨在让 Gemini 对每个人都更加安全、包容。此外，我们还在不断应对事实性、基础性、归属和证实等方面的模型挑战。

在我们的模型开发和部署过程中，责任感和安全性始终是核心要素。这是一项长期的承诺，需要与行业和更广泛的生态系统合作建设。因此，我们通过组织如 MLCommons、Frontier Model Forum 及其 AI Safety Fund，以及我们的 Secure AI Framework (SAIF) 等，与行业伙伴共同定义最佳实践，并设定安全性和安保标准。这些努力旨在帮助降低公共和私营部门 AI 系统的安全风险。我们将继续与全球研究人员、政府和民间团体合作，共同推进 Gemini 的发展。

使 Gemini 惠及全球
Gemini 1.0 正在广泛推向各种产品和平台：

Gemini Pro 集成于 Google 产品
我们正通过 Google 的产品将 Gemini 带给全球数十亿用户。

从今天开始，Bard 将采用 Gemini Pro 的优化版本，以实现更高级的推理、规划、理解等功能。这是 Bard 自推出以来的最重大升级。它将首先以英语面向超过 170 个国家和地区提供服务，我们计划在不久的将来支持更多模式、新语言和地区。

我们还在将 Gemini 引入 Pixel。Pixel 8 Pro 是首款搭载 Gemini Nano 的智能手机，为像记录器应用中的“概要功能”和 Gboard 的“智能回复”等新功能提供支持，首先支持 WhatsApp，明年将拓展至更多消息应用。

在接下来的几个月中，Gemini 将在我们更多的产品和服务中推出，如搜索、广告、Chrome 和 Duet AI。

我们已经开始在搜索功能中尝试使用 Gemini，它使我们的 搜索生成体验（SGE）对用户更加迅速，美国英语搜索的延迟降低了 40%，同时质量也有所提升。

利用 Gemini 打造创新
从 12 月 13 日起，开发者和企业用户可以通过 Google AI Studio 或 Google Cloud Vertex AI 的 Gemini API 访问 Gemini Pro。

Google AI Studio 是一个免费的、基于网页的开发工具，可以让开发者通过 API 密钥迅速构建原型并启动应用。当需要更高级的全托管 AI 平台时，Vertex AI 提供了对 Gemini 的个性化定制，拥有完整的数据控制，并且能从 Google Cloud 的其他特性中受益，例如企业安全、安全保护、隐私保护、数据治理和合规性等。

Android 开发者还能使用 AICore，在 Android 14 中利用 Gemini Nano 构建应用。Gemini Nano 是我们在设备上任务中最高效的模型，首先将在 Pixel 8 Pro 设备上提供。有兴趣的可以报名参加 AICore 的早期体验。

更强大的 Gemini Ultra 即将来临
我们正在为 Gemini Ultra 进行全面的信任和安全检测，这包括受信任外部团队的红队测试，以及在大规模推出前，通过细致调整和基于人类反馈的强化学习 (RLHF) 进一步完善模型。

作为这个过程的一部分，我们将让部分客户、开发者、合作伙伴以及安全和责任专家率先体验 Gemini Ultra，并提供反馈。明年初，我们计划将其向更广泛的开发者和企业用户推出。

明年初，我们还会推出 Bard Advanced，这是一种全新的先进 AI 体验，提供我们最佳模型和功能的使用权限，首先是 Gemini Ultra。

Gemini 时代：开启创新未来之门
这是 AI 发展的关键里程碑，也标志着我们 Google 迈入了一个全新时代。我们将继续快速创新，并负责任地提升我们的模型能力。

我们已经在 Gemini 上取得了重大进展，并正在努力进一步拓展其未来版本的能力，如在规划和记忆方面的提升，以及增加处理更多信息的上下文窗口，以便提供更佳的响应。

我们对 AI 负责任地赋能世界所带来的巨大潜力感到兴奋。这是一个充满创新的未来，它将激发创造力，拓展知识，推动科学发展，并改变全球数十亿人的生活和工作方式。</title>
            <link>https://nitter.cz/dotey/status/1732508618333798734#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732508618333798734#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 21:13:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在与原版 AlphaCode 相同的平台上进行评估时，AlphaCode 2 展现了显著提升，解决问题数量几乎翻倍。我们估计其性能超过了 85% 的竞赛参与者，相较于 AlphaCode 的近 50% 有显著提高。当程序员与 AlphaCode 2 协作，为代码样本定义特定属性时，其表现更为出色。<br />
<br />
我们期待程序员们越来越多地将这些高效能的 AI 模型作为协作工具，以帮助他们解决问题、设计代码，并协助实施，这将使他们能够更快地推出应用程序并设计更好的服务。<br />
<br />
更多详情请参阅我们的 AlphaCode 2 技术报告。<br />
<br />
更加可靠、可扩展和高效<br />
我们利用 Google 自行设计的 张量处理单元（Tensor Processing Units）（TPUs）v4 和 v5e，在我们为 AI 优化的基础设施上对 Gemini 1.0 进行了大规模训练。Gemini 1.0 被打造成为我们最稳定、最易于扩展的训练模型，同时也是运行最高效的模型。<br />
<br />
在 TPUs 上，Gemini 的运行速度远超过之前的较小且功能有限的模型。这些专为 AI 优化的加速器是 Google 众多 AI 驱动产品的核心，服务于全球数十亿用户，如 Google 搜索、YouTube、Gmail、Google 地图、Google Play 和 Android。这些加速器还使全球的公司能够高效、低成本地训练大型 AI 模型。<br />
<br />
今天，我们宣布了迄今为止最强大、最高效、最具扩展性的 TPU 系统——Cloud TPU v5p，这是专门为训练前沿 AI 模型而设计的。这款新一代的 TPU 将加快 Gemini 的发展，并助力开发者与企业客户更快地训练大型生成式 AI 模型，让新产品和功能更快地惠及用户。<br />
<br />
图一：Google 数据中心内排列着的 Cloud TPU v5p AI 加速超级计算机。<br />
<br />
贯彻责任与安全的核心构建理念<br />
在谷歌，我们全力以赴推动大胆、负责的人工智能发展。在谷歌的人工智能原则和我们产品中严格的安全政策的基础上，我们为 Gemini 的多模态能力增添了新的保护措施。在开发的每一步，我们都在仔细考虑潜在风险，并努力进行测试和减轻这些风险。<br />
<br />
Gemini 在偏见和毒性方面进行了谷歌迄今最全面的安全评估。我们进行了针对潜在风险领域的开创性研究，如网络攻击、说服力和自主性，并采用了谷歌研究最先进的对抗测试技术，以便在 Gemini 部署前提前发现关键安全问题。<br />
<br />
为了找出我们内部评估方法的盲点，我们与一群多元化的外部专家和合作伙伴合作，对我们的模型进行全方位的压力测试。<br />
<br />
在 Gemini 的训练阶段，为了诊断内容安全问题并确保其输出符合我们的政策，我们使用了如Real Toxicity Prompts这样的基准测试，这是由 Allen 人工智能研究所的专家开发的，含有来自网络的 10 万个不同毒性级别的提示。更多相关工作的细节即将发布。<br />
<br />
为了减少伤害，我们专门建立了安全分类器，用于识别、标记和过滤涉及暴力或负面刻板印象的内容。加上强效的过滤器，这种多层次的方法旨在让 Gemini 对每个人都更加安全、包容。此外，我们还在不断应对事实性、基础性、归属和证实等方面的模型挑战。<br />
<br />
在我们的模型开发和部署过程中，责任感和安全性始终是核心要素。这是一项长期的承诺，需要与行业和更广泛的生态系统合作建设。因此，我们通过组织如 MLCommons、Frontier Model Forum 及其 AI Safety Fund，以及我们的 Secure AI Framework (SAIF) 等，与行业伙伴共同定义最佳实践，并设定安全性和安保标准。这些努力旨在帮助降低公共和私营部门 AI 系统的安全风险。我们将继续与全球研究人员、政府和民间团体合作，共同推进 Gemini 的发展。<br />
<br />
使 Gemini 惠及全球<br />
Gemini 1.0 正在广泛推向各种产品和平台：<br />
<br />
Gemini Pro 集成于 Google 产品<br />
我们正通过 Google 的产品将 Gemini 带给全球数十亿用户。<br />
<br />
从今天开始，Bard 将采用 Gemini Pro 的优化版本，以实现更高级的推理、规划、理解等功能。这是 Bard 自推出以来的最重大升级。它将首先以英语面向超过 170 个国家和地区提供服务，我们计划在不久的将来支持更多模式、新语言和地区。<br />
<br />
我们还在将 Gemini 引入 Pixel。Pixel 8 Pro 是首款搭载 Gemini Nano 的智能手机，为像记录器应用中的“概要功能”和 Gboard 的“智能回复”等新功能提供支持，首先支持 WhatsApp，明年将拓展至更多消息应用。<br />
<br />
在接下来的几个月中，Gemini 将在我们更多的产品和服务中推出，如搜索、广告、Chrome 和 Duet AI。<br />
<br />
我们已经开始在搜索功能中尝试使用 Gemini，它使我们的 搜索生成体验（SGE）对用户更加迅速，美国英语搜索的延迟降低了 40%，同时质量也有所提升。<br />
<br />
利用 Gemini 打造创新<br />
从 12 月 13 日起，开发者和企业用户可以通过 Google AI Studio 或 Google Cloud Vertex AI 的 Gemini API 访问 Gemini Pro。<br />
<br />
Google AI Studio 是一个免费的、基于网页的开发工具，可以让开发者通过 API 密钥迅速构建原型并启动应用。当需要更高级的全托管 AI 平台时，Vertex AI 提供了对 Gemini 的个性化定制，拥有完整的数据控制，并且能从 Google Cloud 的其他特性中受益，例如企业安全、安全保护、隐私保护、数据治理和合规性等。<br />
<br />
Android 开发者还能使用 AICore，在 Android 14 中利用 Gemini Nano 构建应用。Gemini Nano 是我们在设备上任务中最高效的模型，首先将在 Pixel 8 Pro 设备上提供。有兴趣的可以报名参加 AICore 的早期体验。<br />
<br />
更强大的 Gemini Ultra 即将来临<br />
我们正在为 Gemini Ultra 进行全面的信任和安全检测，这包括受信任外部团队的红队测试，以及在大规模推出前，通过细致调整和基于人类反馈的强化学习 (RLHF) 进一步完善模型。<br />
<br />
作为这个过程的一部分，我们将让部分客户、开发者、合作伙伴以及安全和责任专家率先体验 Gemini Ultra，并提供反馈。明年初，我们计划将其向更广泛的开发者和企业用户推出。<br />
<br />
明年初，我们还会推出 Bard Advanced，这是一种全新的先进 AI 体验，提供我们最佳模型和功能的使用权限，首先是 Gemini Ultra。<br />
<br />
Gemini 时代：开启创新未来之门<br />
这是 AI 发展的关键里程碑，也标志着我们 Google 迈入了一个全新时代。我们将继续快速创新，并负责任地提升我们的模型能力。<br />
<br />
我们已经在 Gemini 上取得了重大进展，并正在努力进一步拓展其未来版本的能力，如在规划和记忆方面的提升，以及增加处理更多信息的上下文窗口，以便提供更佳的响应。<br />
<br />
我们对 AI 负责任地赋能世界所带来的巨大潜力感到兴奋。这是一个充满创新的未来，它将激发创造力，拓展知识，推动科学发展，并改变全球数十亿人的生活和工作方式。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FzYlZfUFdjQUFneFFjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732508421797167465#m</id>
            <title>R to @dotey: 高级编程

我们首个版本的 Gemini 能够理解、解释并生成世界上最受欢迎编程语言（例如 Python、Java、C++ 和 Go）的高质量代码。其跨语言操作能力和对复杂信息的处理使其成为全球领先的编程基础模型之一。

Gemini Ultra 在多个编程基准测试中表现卓越，其中包括 HumanEval —— 一个评估编程任务性能的重要行业标准，以及我们的内部数据集 Natural2Code，后者使用原创来源而非网络信息。

此外，Gemini 还可以作为更高级编程系统的核心。两年前，我们展示了 AlphaCode，这是首个在编程竞赛中达到竞争水平的人工智能代码生成系统。

我们利用 Gemini 的特殊版本创建了更先进的代码生成系统 AlphaCode 2，该系统擅长解决涉及复杂数学和理论计算机科学的竞赛编程问题。

视频：Gemini 在编码和竞赛编程方面表现出色</title>
            <link>https://nitter.cz/dotey/status/1732508421797167465#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732508421797167465#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 21:12:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>高级编程<br />
<br />
我们首个版本的 Gemini 能够理解、解释并生成世界上最受欢迎编程语言（例如 Python、Java、C++ 和 Go）的高质量代码。其跨语言操作能力和对复杂信息的处理使其成为全球领先的编程基础模型之一。<br />
<br />
Gemini Ultra 在多个编程基准测试中表现卓越，其中包括 HumanEval —— 一个评估编程任务性能的重要行业标准，以及我们的内部数据集 Natural2Code，后者使用原创来源而非网络信息。<br />
<br />
此外，Gemini 还可以作为更高级编程系统的核心。两年前，我们展示了 AlphaCode，这是首个在编程竞赛中达到竞争水平的人工智能代码生成系统。<br />
<br />
我们利用 Gemini 的特殊版本创建了更先进的代码生成系统 AlphaCode 2，该系统擅长解决涉及复杂数学和理论计算机科学的竞赛编程问题。<br />
<br />
视频：Gemini 在编码和竞赛编程方面表现出色</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI1MDgzMjAyNzgxMjY1OTMvcHUvaW1nL0FTNnZjd0VSMVJvaHN1VFAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732508211750592993#m</id>
            <title>R to @dotey: 理解文本、图像、音频等

Gemini 1.0 能够同时处理和理解文本、图像、音频等多种信息，这使它在理解复杂话题上更加细腻，能够回答那些涉及到复杂主题的问题。它在解释数学和物理等复杂科目的推理过程方面表现尤为出色。

视频：Gemini 在数学和物理学方面的解释能力</title>
            <link>https://nitter.cz/dotey/status/1732508211750592993#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732508211750592993#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 21:12:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>理解文本、图像、音频等<br />
<br />
Gemini 1.0 能够同时处理和理解文本、图像、音频等多种信息，这使它在理解复杂话题上更加细腻，能够回答那些涉及到复杂主题的问题。它在解释数学和物理等复杂科目的推理过程方面表现尤为出色。<br />
<br />
视频：Gemini 在数学和物理学方面的解释能力</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI1MDgxMjA0NDQ3ODg3MzYvcHUvaW1nL1oxMWQxUU11TDQwQloyTXIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732508019018129737#m</id>
            <title>R to @dotey: 下一代能力的飞跃

直到最近，多模态模型的建立通常是单独训练处理不同类型信息的组件，然后将它们组合起来，试图模拟某些功能。这些模型在某些任务上表现不错，比如描述图片，但在处理更加抽象和复杂的逻辑推理时就显得力不从心。

Gemini 的设计初衷就是让它从一开始就能处理不同类型的信息，我们先对它进行多模态的预训练，然后通过额外的多模态数据进行微调，以此来提高其效果。这使得 Gemini 能够从根本上无缝理解和推理各种类型的输入，其能力在几乎所有领域都达到了顶尖水平。

更多关于 Gemini 的能力和它的工作方式，欢迎了解。

高级推理能力

Gemini 1.0 的高级多模态推理能力能够帮助解读复杂的书面和视觉信息，这让它在从海量数据中挖掘难以察觉的知识方面具有独特优势。

它能够通过阅读、筛选和理解信息，从成千上万的文件中抽丝剥茧，提炼出关键洞见，这在从科学到金融等多个领域将带来数字化速度的新突破。

视频：Gemini 揭示新的科学见解</title>
            <link>https://nitter.cz/dotey/status/1732508019018129737#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732508019018129737#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 21:11:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>下一代能力的飞跃<br />
<br />
直到最近，多模态模型的建立通常是单独训练处理不同类型信息的组件，然后将它们组合起来，试图模拟某些功能。这些模型在某些任务上表现不错，比如描述图片，但在处理更加抽象和复杂的逻辑推理时就显得力不从心。<br />
<br />
Gemini 的设计初衷就是让它从一开始就能处理不同类型的信息，我们先对它进行多模态的预训练，然后通过额外的多模态数据进行微调，以此来提高其效果。这使得 Gemini 能够从根本上无缝理解和推理各种类型的输入，其能力在几乎所有领域都达到了顶尖水平。<br />
<br />
更多关于 Gemini 的能力和它的工作方式，欢迎了解。<br />
<br />
高级推理能力<br />
<br />
Gemini 1.0 的高级多模态推理能力能够帮助解读复杂的书面和视觉信息，这让它在从海量数据中挖掘难以察觉的知识方面具有独特优势。<br />
<br />
它能够通过阅读、筛选和理解信息，从成千上万的文件中抽丝剥茧，提炼出关键洞见，这在从科学到金融等多个领域将带来数字化速度的新突破。<br />
<br />
视频：Gemini 揭示新的科学见解</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI1MDc5MzAxOTk1NDc5MDQvcHUvaW1nL19yaGgtX2hFZWluU1VoMHAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732507688578228433#m</id>
            <title>R to @dotey: 一流的性能

我们对 Gemini 模型进行了严格的测试，并在多样化的任务上评估其性能。在从自然图像、音频和视频的理解到数学推理等多个领域，Gemini Ultra 的表现在 32 个广泛应用于大语言模型研究和开发的学术基准测试中，超越了现有尖端成果的 30 项。

在 MMLU（大规模多任务语言理解）评测中，Gemini Ultra 以 90.0% 的得分成为首个超越人类专家的模型。MMLU 综合了 57 个诸如数学、物理、历史、法律、医学和伦理学等主题，用以测试模型在全球知识和问题解决能力方面的表现。

我们针对 MMLU 的新基准方法使 Gemini 能在回答棘手问题前更加谨慎地运用其推理能力，相较于仅依赖初印象，这种方式带来了明显的提升。

图一：无论是文本还是编程基准测试，Gemini 都展现出超越现有技术的卓越性能。

在新的 MMMU 基准测试中，Gemini Ultra 也取得了 59.4% 的高分。该测试包含了多个领域的多模态任务，需要深入的推理能力。

在我们测试的图像基准方面，Gemini Ultra 无需物体字符识别 (OCR) 系统的辅助，就超越了之前的尖端模型。这些基准测试突显了 Gemini 的天生多模态能力，并预示了其更为复杂的推理能力。

更多细节请参阅我们的 Gemini 技术报告。https://goo.gle/GeminiPaper

图二：Gemini 在多模态基准测试方面也超越了现有的技术水平。</title>
            <link>https://nitter.cz/dotey/status/1732507688578228433#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732507688578228433#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 21:09:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一流的性能<br />
<br />
我们对 Gemini 模型进行了严格的测试，并在多样化的任务上评估其性能。在从自然图像、音频和视频的理解到数学推理等多个领域，Gemini Ultra 的表现在 32 个广泛应用于大语言模型研究和开发的学术基准测试中，超越了现有尖端成果的 30 项。<br />
<br />
在 MMLU（大规模多任务语言理解）评测中，Gemini Ultra 以 90.0% 的得分成为首个超越人类专家的模型。MMLU 综合了 57 个诸如数学、物理、历史、法律、医学和伦理学等主题，用以测试模型在全球知识和问题解决能力方面的表现。<br />
<br />
我们针对 MMLU 的新基准方法使 Gemini 能在回答棘手问题前更加谨慎地运用其推理能力，相较于仅依赖初印象，这种方式带来了明显的提升。<br />
<br />
图一：无论是文本还是编程基准测试，Gemini 都展现出超越现有技术的卓越性能。<br />
<br />
在新的 MMMU 基准测试中，Gemini Ultra 也取得了 59.4% 的高分。该测试包含了多个领域的多模态任务，需要深入的推理能力。<br />
<br />
在我们测试的图像基准方面，Gemini Ultra 无需物体字符识别 (OCR) 系统的辅助，就超越了之前的尖端模型。这些基准测试突显了 Gemini 的天生多模态能力，并预示了其更为复杂的推理能力。<br />
<br />
更多细节请参阅我们的 Gemini 技术报告。<a href="https://goo.gle/GeminiPaper">goo.gle/GeminiPaper</a><br />
<br />
图二：Gemini 在多模态基准测试方面也超越了现有的技术水平。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FzYWJSZFdZQUFZcjR1LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FzYWhvcFc4QUVGZW1aLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732507449943323032#m</id>
            <title>Gemini 介绍：我们的超级 AI 模型 [译]

2023 年 12 月 6 日

让 AI 更贴近每个人的生活

来自 Google 和 Alphabet 首席执行官 Sundar Pichai 的寄语：

每一次技术革新都是推动科学突破、加快人类前进的好机会，也是改善我们的生活的大好时机。我认为，我们现在见证的 AI 革命将是我们一生中最为深远的改变，这种影响甚至超过了手机和互联网的普及。AI 的潜力无限，它不仅能够改善我们的日常生活，还能在更高层面上创造出非凡的机会。AI 将引领创新与经济的新浪潮，并以前所未有的规模推动知识、学习、创造力和生产力的提升。

我最激动的是，有机会让 AI 成为全世界每个人的得力助手。

自从我们定位为一家以 AI 为核心的公司已经八年了，这期间我们的进步速度越来越快：如今，已经有数百万人在我们的产品中使用生成式 AI，做到了一年前难以想象的事情，比如解决更复杂的问题，或是使用全新工具进行协作和创造。同时，全球的开发者和企业都在利用我们的 AI 模型和基础设施开发新的应用，实现增长。

这种势头令人振奋，但我们仅仅是开始探索 AI 的无限可能。

我们对这项工作的态度是大胆且负责任的。这意味着我们在研究上充满野心，努力开发能够为人类和社会带来巨大益处的能力，同时也在建立安全机制，并与政府和专家合作，共同应对随着 AI 能力增强所带来的风险。我们持续投入于最优秀的工具、基础模型和基础设施，并将它们应用于我们的产品及其他产品，这一切都遵循我们的AI 原则。

现在，我们准备迈出旅程的下一步，推出 Gemini，这是我们迄今为止最强大、最全面的模型，它在众多顶尖的基准测试中表现卓越。我们的第一个版本 Gemini 1.0，有多种规格：Ultra、Pro 和 Nano。这些是我们迈入 Gemini 时代的首批模型，也是我们今年初成立 Google DeepMind 时愿景的初步实现。这一新时代的模型是我们公司迄今为止在科学和工程方面的最大努力。我对未来充满期待，也相信 Gemini 将为全球人民带来无限的新机遇。

– Sundar

介绍 Gemini
由谷歌 DeepMind 的首席执行官兼联合创始人 Demis Hassabis 代表 Gemini 团队撰写

AI 是我一生致力的工作重点，这对我许多研究同事来说也是一样。从我青少年时期开始为电脑游戏编写 AI，到作为神经科学研究者探索大脑的奥秘，我始终相信，如果能打造出更加智能的机器，我们就可以利用它们为人类带来前所未有的益处。

正是这个让 AI 负责任地赋能世界的愿景，持续驱动着我们在谷歌 DeepMind 的工作。我们长期以来一直梦想着构建新一代 AI 模型，它们的灵感来源于人类理解和与世界互动的方式。这样的 AI 不仅仅是一款智能软件，更像是一个有用且直观的专家助手或助理。

今天，我们在实现这个愿景上迈出了更大的一步。我们隆重介绍 Gemini，这是我们迄今为止开发的最强大、最通用的模型。

Gemini 是谷歌各团队大规模合作的成果，包括我们在谷歌研究部门的同事们。它是从零开始打造的多模态模型，这意味着它能够广泛地理解并流畅地处理和结合包括文本、代码、音频、图像和视频等多种类型的信息。

视频：介绍 Gemini：我们最大、最有能力的 AI 模型

Gemini 还是我们迄今为止最灵活的模型，它能够在从数据中心到移动设备的各种设备上高效运行。它的尖端技术能力将极大地改善开发者和企业用户使用 AI 构建和扩展应用的方式。

我们针对 Gemini 1.0 进行了优化，这是我们的首个版本，包括三个不同规模的型号：

Gemini Ultra — 我们最大型号、能力最强的模型，适用于极其复杂的任务。
Gemini Pro — 我们最佳模型，适合跨越广泛任务范围的扩展。
Gemini Nano — 我们最高效的模型，专为设备上的任务而设计。</title>
            <link>https://nitter.cz/dotey/status/1732507449943323032#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732507449943323032#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 21:08:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini 介绍：我们的超级 AI 模型 [译]<br />
<br />
2023 年 12 月 6 日<br />
<br />
让 AI 更贴近每个人的生活<br />
<br />
来自 Google 和 Alphabet 首席执行官 Sundar Pichai 的寄语：<br />
<br />
每一次技术革新都是推动科学突破、加快人类前进的好机会，也是改善我们的生活的大好时机。我认为，我们现在见证的 AI 革命将是我们一生中最为深远的改变，这种影响甚至超过了手机和互联网的普及。AI 的潜力无限，它不仅能够改善我们的日常生活，还能在更高层面上创造出非凡的机会。AI 将引领创新与经济的新浪潮，并以前所未有的规模推动知识、学习、创造力和生产力的提升。<br />
<br />
我最激动的是，有机会让 AI 成为全世界每个人的得力助手。<br />
<br />
自从我们定位为一家以 AI 为核心的公司已经八年了，这期间我们的进步速度越来越快：如今，已经有数百万人在我们的产品中使用生成式 AI，做到了一年前难以想象的事情，比如解决更复杂的问题，或是使用全新工具进行协作和创造。同时，全球的开发者和企业都在利用我们的 AI 模型和基础设施开发新的应用，实现增长。<br />
<br />
这种势头令人振奋，但我们仅仅是开始探索 AI 的无限可能。<br />
<br />
我们对这项工作的态度是大胆且负责任的。这意味着我们在研究上充满野心，努力开发能够为人类和社会带来巨大益处的能力，同时也在建立安全机制，并与政府和专家合作，共同应对随着 AI 能力增强所带来的风险。我们持续投入于最优秀的工具、基础模型和基础设施，并将它们应用于我们的产品及其他产品，这一切都遵循我们的AI 原则。<br />
<br />
现在，我们准备迈出旅程的下一步，推出 Gemini，这是我们迄今为止最强大、最全面的模型，它在众多顶尖的基准测试中表现卓越。我们的第一个版本 Gemini 1.0，有多种规格：Ultra、Pro 和 Nano。这些是我们迈入 Gemini 时代的首批模型，也是我们今年初成立 Google DeepMind 时愿景的初步实现。这一新时代的模型是我们公司迄今为止在科学和工程方面的最大努力。我对未来充满期待，也相信 Gemini 将为全球人民带来无限的新机遇。<br />
<br />
– Sundar<br />
<br />
介绍 Gemini<br />
由谷歌 DeepMind 的首席执行官兼联合创始人 Demis Hassabis 代表 Gemini 团队撰写<br />
<br />
AI 是我一生致力的工作重点，这对我许多研究同事来说也是一样。从我青少年时期开始为电脑游戏编写 AI，到作为神经科学研究者探索大脑的奥秘，我始终相信，如果能打造出更加智能的机器，我们就可以利用它们为人类带来前所未有的益处。<br />
<br />
正是这个让 AI 负责任地赋能世界的愿景，持续驱动着我们在谷歌 DeepMind 的工作。我们长期以来一直梦想着构建新一代 AI 模型，它们的灵感来源于人类理解和与世界互动的方式。这样的 AI 不仅仅是一款智能软件，更像是一个有用且直观的专家助手或助理。<br />
<br />
今天，我们在实现这个愿景上迈出了更大的一步。我们隆重介绍 Gemini，这是我们迄今为止开发的最强大、最通用的模型。<br />
<br />
Gemini 是谷歌各团队大规模合作的成果，包括我们在谷歌研究部门的同事们。它是从零开始打造的多模态模型，这意味着它能够广泛地理解并流畅地处理和结合包括文本、代码、音频、图像和视频等多种类型的信息。<br />
<br />
视频：介绍 Gemini：我们最大、最有能力的 AI 模型<br />
<br />
Gemini 还是我们迄今为止最灵活的模型，它能够在从数据中心到移动设备的各种设备上高效运行。它的尖端技术能力将极大地改善开发者和企业用户使用 AI 构建和扩展应用的方式。<br />
<br />
我们针对 Gemini 1.0 进行了优化，这是我们的首个版本，包括三个不同规模的型号：<br />
<br />
Gemini Ultra — 我们最大型号、能力最强的模型，适用于极其复杂的任务。<br />
Gemini Pro — 我们最佳模型，适合跨越广泛任务范围的扩展。<br />
Gemini Nano — 我们最高效的模型，专为设备上的任务而设计。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI1MDcwMDY3MTg2ODkyODAvcHUvaW1nL24ta21pODItME1sTDBKS18uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732451490361430230#m</id>
            <title>Pika 这效果还挺夸张的……</title>
            <link>https://nitter.cz/dotey/status/1732451490361430230#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732451490361430230#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 17:26:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Pika 这效果还挺夸张的……</p>
<p><a href="https://nitter.cz/pika_labs/status/1732438007603777539#m">nitter.cz/pika_labs/status/1732438007603777539#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732448002076185046#m</id>
            <title>R to @dotey: 谢谢各位指正，我上面对于 llama.cpp 的描述不正确，但无法编辑原文，请无视</title>
            <link>https://nitter.cz/dotey/status/1732448002076185046#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732448002076185046#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 17:12:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谢谢各位指正，我上面对于 llama.cpp 的描述不正确，但无法编辑原文，请无视</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732420600428425362#m</id>
            <title>RT by @dotey: Google终于发布了传言中的强大多模态LLM Gemini，他们说这是迄今为止最强大的AI模型。从描述来看确实非常强大。
Google CEO的介绍视频也翻译好了，下面模型是具体的介绍：

◆Gemini 是多模态的，意味着它可以理解、操作和结合不同类型的信息，包括文本、代码、音频、图像和视频。
◆它还非常灵活，能够高效地运行在从数据中心到移动设备上的各种环境中。Gemini 的第一个版本，Gemini 1.0，针对三种不同的大小进行了优化：Gemini Ultra 用于高度复杂的任务，Gemini Pro 适用于广泛的任务，Gemini Nano 用于设备上的任务。

◆Gemini Ultra 在 32 个广泛使用的学术基准测试中的 30 个上超越了当前的最新成果，这些基准测试用于大型语言模型的研究和开发。它是第一个在 MMLU（大规模多任务语言理解）上超越人类专家的模型，MMLU 测试了世界知识和在 57 个科目（如数学、物理、历史、法律、医学和伦理）中的解决问题能力。

◆Gemini 1.0 被训练用于同时识别和理解文本、图像、音频等，使其在解释数学和物理等复杂科目的推理方面表现出色。它还可以理解、解释和生成流行编程语言（如 Python、Java、C++ 和 Go）中的高质量代码。

◆Google 使用其针对 AI 优化的基础设施和自家设计的 Tensor Processing Units (TPUs) v4 和 v5e 来训练 Gemini 1.0。公司还宣布了迄今为止最强大、最高效、最可扩展的 TPU 系统——Cloud TPU v5p，专为训练尖端 AI 模型而设计。

◆Gemini 1.0 现在正在逐步应用于各种产品和平台。它将用于 Google 的产品，如 Bard 和 Pixel，开发者和企业客户可以从 12 月 13 日起通过 Google AI Studio 或 Google Cloud Vertex AI 中的 Gemini API 访问 Gemini Pro。安卓开发者也将能够通过 AICore，在安卓 14 上使用 Gemini Nano 开发，该功能将从 Pixel 8 Pro 设备开始提供。

了解详情：https://blog.google/technology/ai/google-gemini-ai/?utm_source=twitter&amp;utm_medium=social&amp;utm_campaign=GDMGemini#performance</title>
            <link>https://nitter.cz/op7418/status/1732420600428425362#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732420600428425362#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 15:23:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google终于发布了传言中的强大多模态LLM Gemini，他们说这是迄今为止最强大的AI模型。从描述来看确实非常强大。<br />
Google CEO的介绍视频也翻译好了，下面模型是具体的介绍：<br />
<br />
◆Gemini 是多模态的，意味着它可以理解、操作和结合不同类型的信息，包括文本、代码、音频、图像和视频。<br />
◆它还非常灵活，能够高效地运行在从数据中心到移动设备上的各种环境中。Gemini 的第一个版本，Gemini 1.0，针对三种不同的大小进行了优化：Gemini Ultra 用于高度复杂的任务，Gemini Pro 适用于广泛的任务，Gemini Nano 用于设备上的任务。<br />
<br />
◆Gemini Ultra 在 32 个广泛使用的学术基准测试中的 30 个上超越了当前的最新成果，这些基准测试用于大型语言模型的研究和开发。它是第一个在 MMLU（大规模多任务语言理解）上超越人类专家的模型，MMLU 测试了世界知识和在 57 个科目（如数学、物理、历史、法律、医学和伦理）中的解决问题能力。<br />
<br />
◆Gemini 1.0 被训练用于同时识别和理解文本、图像、音频等，使其在解释数学和物理等复杂科目的推理方面表现出色。它还可以理解、解释和生成流行编程语言（如 Python、Java、C++ 和 Go）中的高质量代码。<br />
<br />
◆Google 使用其针对 AI 优化的基础设施和自家设计的 Tensor Processing Units (TPUs) v4 和 v5e 来训练 Gemini 1.0。公司还宣布了迄今为止最强大、最高效、最可扩展的 TPU 系统——Cloud TPU v5p，专为训练尖端 AI 模型而设计。<br />
<br />
◆Gemini 1.0 现在正在逐步应用于各种产品和平台。它将用于 Google 的产品，如 Bard 和 Pixel，开发者和企业客户可以从 12 月 13 日起通过 Google AI Studio 或 Google Cloud Vertex AI 中的 Gemini API 访问 Gemini Pro。安卓开发者也将能够通过 AICore，在安卓 14 上使用 Gemini Nano 开发，该功能将从 Pixel 8 Pro 设备开始提供。<br />
<br />
了解详情：<a href="https://blog.google/technology/ai/google-gemini-ai/?utm_source=twitter&amp;utm_medium=social&amp;utm_campaign=GDMGemini#performance">blog.google/technology/ai/go…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI0MjAyOTg3NDg5NTY2NzIvcHUvaW1nL2J6cmJYYWNaVF91NG5sa1AuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732435176720908458#m</id>
            <title>厉害了👍</title>
            <link>https://nitter.cz/dotey/status/1732435176720908458#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732435176720908458#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 16:21:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>厉害了👍</p>
<p><a href="https://nitter.cz/op7418/status/1732377907795013749#m">nitter.cz/op7418/status/1732377907795013749#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/IlllIllllIIl_/status/1732387641784762615#m</id>
            <title>RT by @dotey: 官方的比whisper.cpp慢五倍。。。不愧是苹果</title>
            <link>https://nitter.cz/IlllIllllIIl_/status/1732387641784762615#m</link>
            <guid isPermaLink="false">https://nitter.cz/IlllIllllIIl_/status/1732387641784762615#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 13:12:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>官方的比whisper.cpp慢五倍。。。不愧是苹果</p>
<p><a href="https://nitter.cz/dotey/status/1732285963647254663#m">nitter.cz/dotey/status/1732285963647254663#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FxdFJxOGJzQUVNQ3BrLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FxdFNJbWFRQUFkOUMxLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/indigo11/status/1732303417878643068#m</id>
            <title>RT by @dotey: Stripe Press 把芒格的《穷查理宝典》做了一个超级酷的电子版，可看、可听、可动还全免费！https://www.stripe.press/poor-charlies-almanack

一家做支付 API 的公司，如何让自己显得有品位？那就是干出版 http://press.stripe.com 的选品相当不错📖 记得以前 Ping++ 总结过 Stripe 成功的五个基本条件：

1. 开发者作为支付服务采购者阶层；
2. 大量中长尾客群的存在；
3. 基于 Visa 和 MasterCard 营造的高利润支付生态；
4. 没有工程师红利的欧美社会；
5. 贸易文明主宰下的企业协同文化；</title>
            <link>https://nitter.cz/indigo11/status/1732303417878643068#m</link>
            <guid isPermaLink="false">https://nitter.cz/indigo11/status/1732303417878643068#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 07:38:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stripe Press 把芒格的《穷查理宝典》做了一个超级酷的电子版，可看、可听、可动还全免费！<a href="https://www.stripe.press/poor-charlies-almanack">stripe.press/poor-charlies-a…</a><br />
<br />
一家做支付 API 的公司，如何让自己显得有品位？那就是干出版 <a href="http://press.stripe.com">press.stripe.com</a> 的选品相当不错📖 记得以前 Ping++ 总结过 Stripe 成功的五个基本条件：<br />
<br />
1. 开发者作为支付服务采购者阶层；<br />
2. 大量中长尾客群的存在；<br />
3. 基于 Visa 和 MasterCard 营造的高利润支付生态；<br />
4. 没有工程师红利的欧美社会；<br />
5. 贸易文明主宰下的企业协同文化；</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzIzMDMzMjI5OTA5NTI0NDgvcHUvaW1nL0xiM204Zm1scWkzQ0ROTXUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732289154652791077#m</id>
            <title>这曹操还挺神似电视剧版的👍🏻</title>
            <link>https://nitter.cz/dotey/status/1732289154652791077#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732289154652791077#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 06:41:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这曹操还挺神似电视剧版的👍🏻</p>
<p><a href="https://nitter.cz/hanqing_me/status/1732265674624700693#m">nitter.cz/hanqing_me/status/1732265674624700693#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732288614157943151#m</id>
            <title>R to @dotey: 没有Swift版本吗？🥲</title>
            <link>https://nitter.cz/dotey/status/1732288614157943151#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732288614157943151#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 06:39:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>没有Swift版本吗？🥲</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732285963647254663#m</id>
            <title>#AI开源项目推荐：MLX

苹果刚刚发布了一个专门为苹果芯片定制的神经网络框架 MLX，类似于 PyTorch ，但是是针对苹果 M 系列芯片定制的。

MLX 的亮点在于设计了一个对于深度学习用户易于上手的API，并包含一些经典案例，比如 Llama、LoRa、Stable Diffusion 和 Whisper！

看来不需要再用 whisper.cpp、llama.cpp 这种靠 CPU 运行的框架了。

MLX 源代码：http://github.com/ml-explore/mlx</title>
            <link>https://nitter.cz/dotey/status/1732285963647254663#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732285963647254663#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 06:28:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：MLX<br />
<br />
苹果刚刚发布了一个专门为苹果芯片定制的神经网络框架 MLX，类似于 PyTorch ，但是是针对苹果 M 系列芯片定制的。<br />
<br />
MLX 的亮点在于设计了一个对于深度学习用户易于上手的API，并包含一些经典案例，比如 Llama、LoRa、Stable Diffusion 和 Whisper！<br />
<br />
看来不需要再用 whisper.cpp、llama.cpp 这种靠 CPU 运行的框架了。<br />
<br />
MLX 源代码：<a href="http://github.com/ml-explore/mlx">github.com/ml-explore/mlx</a></p>
<p><a href="https://nitter.cz/DrJimFan/status/1732261026815770912#m">nitter.cz/DrJimFan/status/1732261026815770912#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732247057237500130#m</id>
            <title>RT by @dotey: Generative Powers of Ten：基于文本的多尺度图像生成技术

是一种图像无限缩放技术，而且质量非常高清！

它能够根据文本描述（你想要看到的场景的文字说明）生成一系列在不同尺度上连贯一致的图像。

可以展示从非常远的景象（大到整个宇宙）到非常近的细节（小到一个细胞）。

该项目受到1977年原版《Powers of Ten 十次幂》电影的启发，该电影最初展示了这种连续缩放效果。研究团队的目标是使用生成模型自动创建类似的动画，并且能够从自己的照片中创建这些缩放视频。

这项技术的关键特点包括：

- 连续缩放视频： 通过一系列文本提示描述不同尺度的场景，该方法可以创建无缝缩放的视频。例如，可以从森林的广角景观视图缩放到树枝上一只昆虫的特写镜头。

- 多尺度生成： 它能够从大范围（如整个星系）到小范围（如单个细胞）的不同尺度生成图像。

- 文本驱动： 图像的生成是基于文本提示，这意味着用户可以通过文字描述来指导图像的生成过程。

- 内容一致性： 在不同的放大级别之间，生成的图像在视觉和内容上保持一致性，这是传统图像放大技术难以实现的。

- 实际图像的缩放： 该技术还可以引导一个缩放级别与输入图像匹配，从而实现可以对真实图像的缩放。

多样性： 通过改变种子（即生成过程的随机输入），即使是对于相同的一组输入提示，也可以获得不同的结果。

该项目基于一种联合采样算法：

联合采样算法的核心特点

并行扩散采样过程： 该算法使用一组分布在不同缩放级别的并行扩散采样过程。这意味着算法能够同时处理多个尺度的图像，从而在每个尺度上生成图像。

迭代频带合并： 为了保持不同尺度图像的一致性，这些采样过程通过一个迭代频带合并过程进行协调。这个过程确保在从一个尺度到另一个尺度的过渡中，图像内容保持连贯和一致。

优化所有尺度的内容： 不同于传统的通过增加图像分辨率来生成更高细节的图像（如超分辨率或图像外推技术），这种方法同时针对所有尺度的内容进行优化。这样做的好处是，它不仅在每个尺度上生成合理的图像，而且还保持了不同尺度之间内容的一致性。

它使用了以下几个关键步骤和技术：

1、文本提示驱动的图像生成： 用户提供一系列文本提示，描述他们想要在不同缩放级别上看到的场景。例如，从一个星系的远景到一个细胞的微观视图。

2、预训练的扩散模型： 该技术使用了一个预训练的扩散模型来同时去噪不同尺度上的多个图像。通过逐步去除噪声来生成图像，从而从随机噪声中逐步构建出清晰的图像。

3、多尺度联合采样： 在每个缩放级别上，噪声图像和相应的文本提示被同时输入到同一个预训练的扩散模型中，以估计相应的清晰图像。这些图像在它们共同观察的重叠区域可能会有不一致的估计。

4、多分辨率融合： 为了解决不同尺度图像在重叠区域的不一致性，该技术采用了多分辨率融合方法。这种方法将这些区域融合成一个一致的缩放堆栈，并从这个一致的表示中重新渲染不同的缩放级别。

5、连续缩放视频的生成： 通过这种方法，可以生成连续缩放的视频，这些视频在视觉上平滑且内容上连贯，从一个尺度平滑过渡到另一个尺度。

项目及演示：https://powers-of-10.github.io/
论文：https://arxiv.org/abs/2312.02149</title>
            <link>https://nitter.cz/xiaohuggg/status/1732247057237500130#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732247057237500130#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 03:54:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Generative Powers of Ten：基于文本的多尺度图像生成技术<br />
<br />
是一种图像无限缩放技术，而且质量非常高清！<br />
<br />
它能够根据文本描述（你想要看到的场景的文字说明）生成一系列在不同尺度上连贯一致的图像。<br />
<br />
可以展示从非常远的景象（大到整个宇宙）到非常近的细节（小到一个细胞）。<br />
<br />
该项目受到1977年原版《Powers of Ten 十次幂》电影的启发，该电影最初展示了这种连续缩放效果。研究团队的目标是使用生成模型自动创建类似的动画，并且能够从自己的照片中创建这些缩放视频。<br />
<br />
这项技术的关键特点包括：<br />
<br />
- 连续缩放视频： 通过一系列文本提示描述不同尺度的场景，该方法可以创建无缝缩放的视频。例如，可以从森林的广角景观视图缩放到树枝上一只昆虫的特写镜头。<br />
<br />
- 多尺度生成： 它能够从大范围（如整个星系）到小范围（如单个细胞）的不同尺度生成图像。<br />
<br />
- 文本驱动： 图像的生成是基于文本提示，这意味着用户可以通过文字描述来指导图像的生成过程。<br />
<br />
- 内容一致性： 在不同的放大级别之间，生成的图像在视觉和内容上保持一致性，这是传统图像放大技术难以实现的。<br />
<br />
- 实际图像的缩放： 该技术还可以引导一个缩放级别与输入图像匹配，从而实现可以对真实图像的缩放。<br />
<br />
多样性： 通过改变种子（即生成过程的随机输入），即使是对于相同的一组输入提示，也可以获得不同的结果。<br />
<br />
该项目基于一种联合采样算法：<br />
<br />
联合采样算法的核心特点<br />
<br />
并行扩散采样过程： 该算法使用一组分布在不同缩放级别的并行扩散采样过程。这意味着算法能够同时处理多个尺度的图像，从而在每个尺度上生成图像。<br />
<br />
迭代频带合并： 为了保持不同尺度图像的一致性，这些采样过程通过一个迭代频带合并过程进行协调。这个过程确保在从一个尺度到另一个尺度的过渡中，图像内容保持连贯和一致。<br />
<br />
优化所有尺度的内容： 不同于传统的通过增加图像分辨率来生成更高细节的图像（如超分辨率或图像外推技术），这种方法同时针对所有尺度的内容进行优化。这样做的好处是，它不仅在每个尺度上生成合理的图像，而且还保持了不同尺度之间内容的一致性。<br />
<br />
它使用了以下几个关键步骤和技术：<br />
<br />
1、文本提示驱动的图像生成： 用户提供一系列文本提示，描述他们想要在不同缩放级别上看到的场景。例如，从一个星系的远景到一个细胞的微观视图。<br />
<br />
2、预训练的扩散模型： 该技术使用了一个预训练的扩散模型来同时去噪不同尺度上的多个图像。通过逐步去除噪声来生成图像，从而从随机噪声中逐步构建出清晰的图像。<br />
<br />
3、多尺度联合采样： 在每个缩放级别上，噪声图像和相应的文本提示被同时输入到同一个预训练的扩散模型中，以估计相应的清晰图像。这些图像在它们共同观察的重叠区域可能会有不一致的估计。<br />
<br />
4、多分辨率融合： 为了解决不同尺度图像在重叠区域的不一致性，该技术采用了多分辨率融合方法。这种方法将这些区域融合成一个一致的缩放堆栈，并从这个一致的表示中重新渲染不同的缩放级别。<br />
<br />
5、连续缩放视频的生成： 通过这种方法，可以生成连续缩放的视频，这些视频在视觉上平滑且内容上连贯，从一个尺度平滑过渡到另一个尺度。<br />
<br />
项目及演示：<a href="https://powers-of-10.github.io/">powers-of-10.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2312.02149">arxiv.org/abs/2312.02149</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzIyNDMyNzc2NDUzMzY1NzYvcHUvaW1nL2ZwZ2pVYmN2Zkd2OV9WWFEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Barret_China/status/1732247223499641077#m</id>
            <title>RT by @dotey: 复旦大学张奇教授团队写了一本在线免费的电子书，《大规模语言模型：从理论到实践》，https://intro-llm.github.io，大概有 300 页篇幅，将大模型从理论到实战的每个阶段都描述的较为清楚。

全文在线阅读地址：https://intro-llm.github.io/chapter/LLM-TAP.pdf</title>
            <link>https://nitter.cz/Barret_China/status/1732247223499641077#m</link>
            <guid isPermaLink="false">https://nitter.cz/Barret_China/status/1732247223499641077#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 03:54:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>复旦大学张奇教授团队写了一本在线免费的电子书，《大规模语言模型：从理论到实践》，<a href="https://intro-llm.github.io">intro-llm.github.io</a>，大概有 300 页篇幅，将大模型从理论到实战的每个阶段都描述的较为清楚。<br />
<br />
全文在线阅读地址：<a href="https://intro-llm.github.io/chapter/LLM-TAP.pdf">intro-llm.github.io/chapter/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FvczhYdGFJQUF0YVo0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FvdG1DX2FrQUF4NXRsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/0xthefool/status/1731896006608838834#m</id>
            <title>RT by @dotey: 不得不承认O Reilly是技术书籍出版的大哥大，已经整理出来了一本 《用GPT-4与ChatGPT完成应用开发》的书籍，Amazon上面可以几十刀买一份实体书或者电子书，也可以在下面官网上注册账号免费读10天。

https://www.oreilly.com/library/view/developing-apps-with/9781098152475/</title>
            <link>https://nitter.cz/0xthefool/status/1731896006608838834#m</link>
            <guid isPermaLink="false">https://nitter.cz/0xthefool/status/1731896006608838834#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 04:39:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>不得不承认O Reilly是技术书籍出版的大哥大，已经整理出来了一本 《用GPT-4与ChatGPT完成应用开发》的书籍，Amazon上面可以几十刀买一份实体书或者电子书，也可以在下面官网上注册账号免费读10天。<br />
<br />
<a href="https://www.oreilly.com/library/view/developing-apps-with/9781098152475/">oreilly.com/library/view/dev…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FqdUNSMGE0QUE4WU1WLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732219459526340887#m</id>
            <title>高斯头像 (GaussianAvatars)，可以高逼真还原演员表情、姿势到3D虚拟人头像上的技术

相关论文：高斯头像 (GaussianAvatars): 用 3D 高斯技术打造的逼真头部虚拟形象

摘要
我们推出了一种名为高斯头像 (GaussianAvatars) 的创新技术，用以制作不仅逼真而且可以完全操控表情、姿势和观看角度的头部虚拟形象。这一技术的核心在于一个基于 3D 高斯点的动态三维表示法，这些高斯点被配置在一个可参数化、可塑形的面部模型上。这种结合不仅实现了逼真的渲染效果，而且通过底层的参数化模型，实现了精确的动画控制。例如，可以通过从视频序列中传递表情或手动调整可塑形模型的参数来控制动画。我们利用三角形的局部坐标系对每个高斯点进行参数设置，并通过优化明确的位移偏移来实现更精准的几何表达。在头像重建过程中，我们采用端到端的方式同时优化可塑形模型参数和高斯点参数。我们还展示了这种逼真头像在多个具有挑战性的场景中的动画表现力。例如，在驱动视频的重现场景中，我们的方法相比现有技术有了显著的提升。

项目首页：https://shenhanqian.github.io/gaussian-avatars
论文：http://arxiv.org/abs/2312.02069</title>
            <link>https://nitter.cz/dotey/status/1732219459526340887#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732219459526340887#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 02:04:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>高斯头像 (GaussianAvatars)，可以高逼真还原演员表情、姿势到3D虚拟人头像上的技术<br />
<br />
相关论文：高斯头像 (GaussianAvatars): 用 3D 高斯技术打造的逼真头部虚拟形象<br />
<br />
摘要<br />
我们推出了一种名为高斯头像 (GaussianAvatars) 的创新技术，用以制作不仅逼真而且可以完全操控表情、姿势和观看角度的头部虚拟形象。这一技术的核心在于一个基于 3D 高斯点的动态三维表示法，这些高斯点被配置在一个可参数化、可塑形的面部模型上。这种结合不仅实现了逼真的渲染效果，而且通过底层的参数化模型，实现了精确的动画控制。例如，可以通过从视频序列中传递表情或手动调整可塑形模型的参数来控制动画。我们利用三角形的局部坐标系对每个高斯点进行参数设置，并通过优化明确的位移偏移来实现更精准的几何表达。在头像重建过程中，我们采用端到端的方式同时优化可塑形模型参数和高斯点参数。我们还展示了这种逼真头像在多个具有挑战性的场景中的动画表现力。例如，在驱动视频的重现场景中，我们的方法相比现有技术有了显著的提升。<br />
<br />
项目首页：<a href="https://shenhanqian.github.io/gaussian-avatars">shenhanqian.github.io/gaussi…</a><br />
论文：<a href="http://arxiv.org/abs/2312.02069">arxiv.org/abs/2312.02069</a></p>
<p><a href="https://nitter.cz/MattNiessner/status/1731799570177228975#m">nitter.cz/MattNiessner/status/1731799570177228975#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>