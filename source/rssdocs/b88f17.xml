<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1739180460331155513#m</id>
            <title>翻译了最近很火的论文：《Autonomous chemical research with large language models | 大语言模型在自主化学研究中的应用 [译]》

中文版：https://baoyu.io/translations/ai-paper/s41586-023-06792-0
原始论文：https://www.nature.com/articles/s41586-023-06792-0
pdf：https://www.nature.com/articles/s41586-023-06792-0.pdf

本研究重点介绍了一种基于多个大语言模型的智能助手（我们称之为 Coscientist），它能独立设计、规划并执行复杂的科学实验。

Coscientist 由匹兹堡的 Coscientist 大学和卡内基梅隆大学的 Wilton E. Scott 能源创新研究所共同研发。这个智能助手可以通过互联网搜索相关资料，使用机器人实验的应用程序接口 (API)，并借助其他大语言模型来完成多样化的任务。Coscientist 的研发是独立进行的，与其他自主智能体的研究同步展开，化学领域的 ChemCrow 也是一个相关的例子。

我们在论文中展示了 Coscientist 在六大任务方面的灵活性和高效能力，包括：
（1）利用公开数据规划已知化合物的化学合成；
（2）高效搜索和浏览大量硬件文档；
（3）利用文档在云实验室执行高阶指令；
（4）通过低阶指令精准控制液体处理设备；
（5）处理需要多个硬件模块协同和多数据源整合的复杂科学任务；
（6）解决分析既往实验数据的优化问题。</title>
            <link>https://nitter.cz/dotey/status/1739180460331155513#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1739180460331155513#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 07:05:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>翻译了最近很火的论文：《Autonomous chemical research with large language models | 大语言模型在自主化学研究中的应用 [译]》<br />
<br />
中文版：<a href="https://baoyu.io/translations/ai-paper/s41586-023-06792-0">baoyu.io/translations/ai-pap…</a><br />
原始论文：<a href="https://www.nature.com/articles/s41586-023-06792-0">nature.com/articles/s41586-0…</a><br />
pdf：<a href="https://www.nature.com/articles/s41586-023-06792-0.pdf">nature.com/articles/s41586-0…</a><br />
<br />
本研究重点介绍了一种基于多个大语言模型的智能助手（我们称之为 Coscientist），它能独立设计、规划并执行复杂的科学实验。<br />
<br />
Coscientist 由匹兹堡的 Coscientist 大学和卡内基梅隆大学的 Wilton E. Scott 能源创新研究所共同研发。这个智能助手可以通过互联网搜索相关资料，使用机器人实验的应用程序接口 (API)，并借助其他大语言模型来完成多样化的任务。Coscientist 的研发是独立进行的，与其他自主智能体的研究同步展开，化学领域的 ChemCrow 也是一个相关的例子。<br />
<br />
我们在论文中展示了 Coscientist 在六大任务方面的灵活性和高效能力，包括：<br />
（1）利用公开数据规划已知化合物的化学合成；<br />
（2）高效搜索和浏览大量硬件文档；<br />
（3）利用文档在云实验室执行高阶指令；<br />
（4）通过低阶指令精准控制液体处理设备；<br />
（5）处理需要多个硬件模块协同和多数据源整合的复杂科学任务；<br />
（6）解决分析既往实验数据的优化问题。</p>
<p><a href="https://nitter.cz/dotey/status/1739123470322016718#m">nitter.cz/dotey/status/1739123470322016718#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NMTzk2ZVhnQUFNMThnLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NMUEJjc1hBQUF6cEZjLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NMUEhEVldRQUFmblZwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NMUElxa1hJQUF5NGlCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1739123470322016718#m</id>
            <title>推荐阅读：《多个 AI 智能体共同解决化学难题 [译]》

尽管人工智能技术飞速发展，但 AI 目前还无法完全替代人类从事科学研究。然而，这并不意味着 AI 不能在一些日常的科学实验工作中提供自动化的帮助。举个例子，就在几年前，研究人员就已经让 AI 控制自动化实验室设备，并成功让它全面记录所有可能发生的化学反应。

虽然这种方法很有效，但最初设立这个系统时仍需要研究人员大量的干预。现在，卡内基梅隆大学的一个团队已经探索出了一种方法，让 AI 系统能够自行学习如何进行化学操作。这个系统需要三个专门化的 AI 智能体，每个负责不同的任务。一旦设置完成并提供了所需原料，你只需告诉它你想进行的反应类型，它就能自行解决了。

研究人员并没有依赖单一的系统来完成化学领域的所有工作，而是设置了几个不同的模块，这些模块在工作分配上互相配合，共同构成了一个名为“Coscientist”的系统。

他们使用了以下三个模块：

1. 网络搜索器（Web searcher）： 这个模块有两项核心功能：一是利用 Google 的搜索 API 来寻找可能含有有用信息的网页；二是获取这些网页的内容并从中提取信息，这有点像 ChatGPT 在对话早期部分维持的上下文，帮助它更好地回答后续问题。研究者可以追踪这个模块花费时间的地方，发现它访问的页面中大约一半是维基百科。此外，它最常访问的网站前五名包括了美国化学学会和英国皇家化学学会发布的期刊。

2. 文档搜索器（Documentation searcher）： 可以把这个模块看作是用于“查阅手册”的 AI。它将控制各种实验室自动化设备，比如机器人流体处理器，这些设备通常是通过专门的命令或类似 Python 语言的接口来控制的。这个 AI 模块可以访问所有这些设备的使用手册，以便了解如何操作它们。

3. 规划器（Planner）： 规划器可以向其他两个 AI 模块发出指令并处理它们的回应。它能够在一个 Python 编程环境中执行代码，从而进行各种计算。它还能操作自动化实验室设备，亲自进行和分析实验。因此，规划器就像是一个化学家，它从文献中学习，并尝试使用实验设备来应用所学的知识。

规划器还能识别软件错误，无论是它的 Python 脚本还是操作自动化硬件时的错误，并据此进行修正。

原文：https://arstechnica.com/science/2023/12/large-language-models-can-figure-out-how-to-do-chemistry/
译文：https://baoyu.io/translations/ai/large-language-models-can-figure-out-how-to-do-chemistry</title>
            <link>https://nitter.cz/dotey/status/1739123470322016718#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1739123470322016718#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 03:18:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《多个 AI 智能体共同解决化学难题 [译]》<br />
<br />
尽管人工智能技术飞速发展，但 AI 目前还无法完全替代人类从事科学研究。然而，这并不意味着 AI 不能在一些日常的科学实验工作中提供自动化的帮助。举个例子，就在几年前，研究人员就已经让 AI 控制自动化实验室设备，并成功让它全面记录所有可能发生的化学反应。<br />
<br />
虽然这种方法很有效，但最初设立这个系统时仍需要研究人员大量的干预。现在，卡内基梅隆大学的一个团队已经探索出了一种方法，让 AI 系统能够自行学习如何进行化学操作。这个系统需要三个专门化的 AI 智能体，每个负责不同的任务。一旦设置完成并提供了所需原料，你只需告诉它你想进行的反应类型，它就能自行解决了。<br />
<br />
研究人员并没有依赖单一的系统来完成化学领域的所有工作，而是设置了几个不同的模块，这些模块在工作分配上互相配合，共同构成了一个名为“Coscientist”的系统。<br />
<br />
他们使用了以下三个模块：<br />
<br />
1. 网络搜索器（Web searcher）： 这个模块有两项核心功能：一是利用 Google 的搜索 API 来寻找可能含有有用信息的网页；二是获取这些网页的内容并从中提取信息，这有点像 ChatGPT 在对话早期部分维持的上下文，帮助它更好地回答后续问题。研究者可以追踪这个模块花费时间的地方，发现它访问的页面中大约一半是维基百科。此外，它最常访问的网站前五名包括了美国化学学会和英国皇家化学学会发布的期刊。<br />
<br />
2. 文档搜索器（Documentation searcher）： 可以把这个模块看作是用于“查阅手册”的 AI。它将控制各种实验室自动化设备，比如机器人流体处理器，这些设备通常是通过专门的命令或类似 Python 语言的接口来控制的。这个 AI 模块可以访问所有这些设备的使用手册，以便了解如何操作它们。<br />
<br />
3. 规划器（Planner）： 规划器可以向其他两个 AI 模块发出指令并处理它们的回应。它能够在一个 Python 编程环境中执行代码，从而进行各种计算。它还能操作自动化实验室设备，亲自进行和分析实验。因此，规划器就像是一个化学家，它从文献中学习，并尝试使用实验设备来应用所学的知识。<br />
<br />
规划器还能识别软件错误，无论是它的 Python 脚本还是操作自动化硬件时的错误，并据此进行修正。<br />
<br />
原文：<a href="https://arstechnica.com/science/2023/12/large-language-models-can-figure-out-how-to-do-chemistry/">arstechnica.com/science/2023…</a><br />
译文：<a href="https://baoyu.io/translations/ai/large-language-models-can-figure-out-how-to-do-chemistry">baoyu.io/translations/ai/lar…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NLYmtxeVcwQUFDc2x4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738978659808022619#m</id>
            <title>“在我们继续之前，我想先重复一遍刚才的内容，以确认我已经完全理解了。”

在沟通中，最有效的策略之一就是用自己的话重述对方刚刚解释的内容。

推荐阅读：Let me repeat that back to you -- Two-phase commit for humans  https://roughlywritten.substack.com/p/let-me-repeat-that-back-to-you
译文：https://baoyu.io/translations/work/let-me-repeat-that-back-to-you</title>
            <link>https://nitter.cz/dotey/status/1738978659808022619#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738978659808022619#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 17:43:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“在我们继续之前，我想先重复一遍刚才的内容，以确认我已经完全理解了。”<br />
<br />
在沟通中，最有效的策略之一就是用自己的话重述对方刚刚解释的内容。<br />
<br />
推荐阅读：Let me repeat that back to you -- Two-phase commit for humans  <a href="https://roughlywritten.substack.com/p/let-me-repeat-that-back-to-you">roughlywritten.substack.com/…</a><br />
译文：<a href="https://baoyu.io/translations/work/let-me-repeat-that-back-to-you">baoyu.io/translations/work/l…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NJWHJ2ZVhrQUFnTnZtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738974173957935524#m</id>
            <title>#AI开源项目推荐：cumulo-autumn/StreamDiffusion

可以实时文生图或者图生图，RTX 4090 的 GPU，步数 1 的情况下每秒可以到106张。

论文：https://arxiv.org/abs/2312.12491
项目地址：https://github.com/cumulo-autumn/StreamDiffusion</title>
            <link>https://nitter.cz/dotey/status/1738974173957935524#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738974173957935524#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 17:25:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：cumulo-autumn/StreamDiffusion<br />
<br />
可以实时文生图或者图生图，RTX 4090 的 GPU，步数 1 的情况下每秒可以到106张。<br />
<br />
论文：<a href="https://arxiv.org/abs/2312.12491">arxiv.org/abs/2312.12491</a><br />
项目地址：<a href="https://github.com/cumulo-autumn/StreamDiffusion">github.com/cumulo-autumn/Str…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0NJUk1QOFc4QUVPa2RULmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dDSVJNUDhXOEFFT2tkVC5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738969745313927603#m</id>
            <title>有人尝试了借助开源大语言模型，无需联网在本机实现和游戏 NPC 自由对话，技术栈：
- Mistral7b，开源大语言模型
- StyleTTS2 文字转语音
- llama.cpp 用来运行大语言模型的库

生成一句新对话的时间大约为 2-3 秒。在生成新对话行时会稍微有点卡顿，但影响不大。StyleTTS2（文本转语音系统）需要占用约 14GB 的 RAM，而基于 llama.cpp 运行的服务器占用 3GB，因此运行这一系统需要较大的 RAM 容量。不过我相信 StyleTTS 还有进一步优化的空间。从视频中可以看出，对帧率影响不大，游戏画面依然能够保持流畅的 60 帧每秒。

缺点也很明显：

Mistral 在判断游戏世界中哪些事情可能发生哪些不可能方面也不是很准确。比如，在演示中出现的关于训练村民的任务，在游戏中实际上是无法实现的，因为游戏中根本没有相关机制。

尽管 Mistral 模型的处理速度更快，但一致性不如 GPT3.5。容易偏离主题，并且不太能坚持事实。

StyleTTS2 的语音合成效果也不够自然，还带有些许机械感。对于它不熟悉的词汇，它的发音不太准确，或者会根据上下文错误地发音（例如，Angers 这个城市的发音与动词“to anger”发音不同）。

不过还是相当有积极意义的一次尝试👍🏻

相关源码：https://github.com/joe-gibbs/local-llms-ue5

原文：https://jgibbs.dev/blogs/local-llm-npcs-in-unreal-engine
译文：https://baoyu.io/translations/llm/local-llm-npcs-in-unreal-engine</title>
            <link>https://nitter.cz/dotey/status/1738969745313927603#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738969745313927603#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 17:07:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有人尝试了借助开源大语言模型，无需联网在本机实现和游戏 NPC 自由对话，技术栈：<br />
- Mistral7b，开源大语言模型<br />
- StyleTTS2 文字转语音<br />
- llama.cpp 用来运行大语言模型的库<br />
<br />
生成一句新对话的时间大约为 2-3 秒。在生成新对话行时会稍微有点卡顿，但影响不大。StyleTTS2（文本转语音系统）需要占用约 14GB 的 RAM，而基于 llama.cpp 运行的服务器占用 3GB，因此运行这一系统需要较大的 RAM 容量。不过我相信 StyleTTS 还有进一步优化的空间。从视频中可以看出，对帧率影响不大，游戏画面依然能够保持流畅的 60 帧每秒。<br />
<br />
缺点也很明显：<br />
<br />
Mistral 在判断游戏世界中哪些事情可能发生哪些不可能方面也不是很准确。比如，在演示中出现的关于训练村民的任务，在游戏中实际上是无法实现的，因为游戏中根本没有相关机制。<br />
<br />
尽管 Mistral 模型的处理速度更快，但一致性不如 GPT3.5。容易偏离主题，并且不太能坚持事实。<br />
<br />
StyleTTS2 的语音合成效果也不够自然，还带有些许机械感。对于它不熟悉的词汇，它的发音不太准确，或者会根据上下文错误地发音（例如，Angers 这个城市的发音与动词“to anger”发音不同）。<br />
<br />
不过还是相当有积极意义的一次尝试👍🏻<br />
<br />
相关源码：<a href="https://github.com/joe-gibbs/local-llms-ue5">github.com/joe-gibbs/local-l…</a><br />
<br />
原文：<a href="https://jgibbs.dev/blogs/local-llm-npcs-in-unreal-engine">jgibbs.dev/blogs/local-llm-n…</a><br />
译文：<a href="https://baoyu.io/translations/llm/local-llm-npcs-in-unreal-engine">baoyu.io/translations/llm/lo…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg5Njg0MzUxNTYwMTcxNTIvcHUvaW1nL1NKSXJEZkJyNDg4WEpUQk4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738849725221343683#m</id>
            <title>RT by @dotey: 换脸工具Rope发布了Ruby版本，性能获得了大幅提升。有需要的可以更新一下试试，具体更新内容有：

◆几乎是之前 Rope 性能的两倍。
◆更快的 GFPGAN。
◆现在可以调整遮挡遮罩尺寸。
◆添加实验性功能以调整面部交换区域放置和面部比例。

项目地址：https://github.com/Hillobar/Rope?tab=readme-ov-file</title>
            <link>https://nitter.cz/op7418/status/1738849725221343683#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738849725221343683#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 09:10:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>换脸工具Rope发布了Ruby版本，性能获得了大幅提升。有需要的可以更新一下试试，具体更新内容有：<br />
<br />
◆几乎是之前 Rope 性能的两倍。<br />
◆更快的 GFPGAN。<br />
◆现在可以调整遮挡遮罩尺寸。<br />
◆添加实验性功能以调整面部交换区域放置和面部比例。<br />
<br />
项目地址：<a href="https://github.com/Hillobar/Rope?tab=readme-ov-file">github.com/Hillobar/Rope?tab…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg4NDk2NjMxODM0MTczNDQvcHUvaW1nL3JBWWtWRk9CQnkyV1Y0S1guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738779664150094270#m</id>
            <title>推荐阅读：如何加速大语言模型的运行

这是一篇综合性的调研文章，涵盖了多种提升大语言模型运行速度的方法，从改善硬件利用效率到巧妙的解码技巧应有尽有。虽然这篇文章并非面面俱到，也不是每个话题的深度解析，但你应该能从中找到一些有用的信息，并且作者也提供了相关论文和博客文章的链接。

原文：https://vgel.me/posts/faster-inference/
译文：https://baoyu.io/translations/llm/how-to-make-llms-go-fast</title>
            <link>https://nitter.cz/dotey/status/1738779664150094270#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738779664150094270#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 04:32:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：如何加速大语言模型的运行<br />
<br />
这是一篇综合性的调研文章，涵盖了多种提升大语言模型运行速度的方法，从改善硬件利用效率到巧妙的解码技巧应有尽有。虽然这篇文章并非面面俱到，也不是每个话题的深度解析，但你应该能从中找到一些有用的信息，并且作者也提供了相关论文和博客文章的链接。<br />
<br />
原文：<a href="https://vgel.me/posts/faster-inference/">vgel.me/posts/faster-inferen…</a><br />
译文：<a href="https://baoyu.io/translations/llm/how-to-make-llms-go-fast">baoyu.io/translations/llm/ho…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738778275629982135#m</id>
            <title>转译：《苹果公司于 10 月份悄然发布了一款开源多模态 LLM》

苹果公司在2023年10月低调发布了一款名为Ferret的开源多模态大语言模型，这是苹果与哥伦比亚大学研究人员的合作成果。当时，尽管发布包括了代码和权重（仅限研究用途，不包含商业许可），但并未引起太多关注。然而，随着近期 Mistral 的开源模型成为焦点，以及谷歌的Gemini模型即将在Pixel Pro上亮相，未来还将进入Android系统，人们开始更加关注本地LLMs在小型设备上的应用潜力。

最近，随着苹果宣布在iPhone上成功部署LLMs的重大突破，这方面的讨论更加热烈。苹果[发布了两篇新研究论文](https://x.com/dotey/status/1738767070022570250)，介绍了3D头像和高效语言模型推理的新技术，这些技术被认为有望提供更加沉浸式的视觉体验，并使复杂的AI系统能够在消费者设备如iPhone和iPad上运行。

AI社区中许多原本未注意到Ferret发布的成员，对苹果这一意外进入开源LLM领域的行动表示欢迎，尤其是鉴于苹果一向以其“封闭园区”的形象而闻名。

今晨，专注于医疗领域开源AI的欧洲非营利组织负责人Bart de Witte在X平台上分享了他的惊讶：“我之前竟然没发现这个。”他表示，“苹果在10月份加入了开源AI圈子。Ferret的推出展现了苹果对影响深远的AI研究的承诺，巩固了它在多模态AI领域的领先地位……另外，我很期待有一天Local Large Language Models (LLLMs)能作为重新设计的iOS的一部分，在我的iPhone上运行。”

德国AI音乐艺术家及顾问Tristan Behrens也表达了他的看法，他在领英上写道：“明天就是圣诞节，但你知道吗？苹果（没错，就是苹果！）近期发布了一个包含代码和权重的多模态大语言模型。”

科技博客作家兼VentureBeat撰稿人Ben Dickson在领英上的发言提到了这一惊喜：“2023年最让你意外的AI进展是什么？对我来说，是苹果发布了开源LLMs（虽然是非商业许可）。”他指出，苹果一直是封闭系统、封闭园区开发、保密、严格的保密协议、发布极少细节、并为其产品申请每一项小的专利的代表。

他继续说道：“但回过头来看，苹果（像Meta一样）推出开源LLM模型是合情合理的。要与ChatGPT这类模型竞争，你要么得是一个超级计算者，要么需要强大的合作伙伴。苹果虽然资源丰富，但其基础设施并不是为服务大规模LLMs而建的。另一种选择是依赖像微软或谷歌这样的云服务提供商（两大劲敌），或者像Meta那样开始发布自己的开源模型。”

值得注意的是，苹果开源及本地ML发展的消息传来之际，Anthropic和OpenAI据报道正在为他们的专有LLM开发工作进行大规模的新资金筹集。据路透社[本周三报道](http://seeking%20to%20raise%20$750%20mln%20in%20funding%20round%20led%20by%20menlo%20ventures/)，Anthropic正在与Menlo Ventures商谈筹集7.5亿美元的资金。而根据[彭博社昨天的报道](https://www.bloomberg.com/news/articles/2023-12-22/openai-in-talks-to-raise-new-funding-at-100-billion-valuation)，OpenAI正在进行初步讨论，计划以至少1000亿美元的估值筹集新一轮资金。

这一系列动态显示了AI领域的竞争格局正在发生变化。尽管苹果以往以其产品和技术的封闭性著称，但现在它通过发布开源LLM模型，正逐渐改变这一形象，展现出其在AI领域的活跃参与和创新精神。这不仅对苹果自身，也对整个AI领域来说，都是一个值得关注的重要发展方向。

来源：https://venturebeat.com/ai/apple-quietly-released-an-open-source-multimodal-llm-in-october/</title>
            <link>https://nitter.cz/dotey/status/1738778275629982135#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738778275629982135#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 04:27:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：《苹果公司于 10 月份悄然发布了一款开源多模态 LLM》<br />
<br />
苹果公司在2023年10月低调发布了一款名为Ferret的开源多模态大语言模型，这是苹果与哥伦比亚大学研究人员的合作成果。当时，尽管发布包括了代码和权重（仅限研究用途，不包含商业许可），但并未引起太多关注。然而，随着近期 Mistral 的开源模型成为焦点，以及谷歌的Gemini模型即将在Pixel Pro上亮相，未来还将进入Android系统，人们开始更加关注本地LLMs在小型设备上的应用潜力。<br />
<br />
最近，随着苹果宣布在iPhone上成功部署LLMs的重大突破，这方面的讨论更加热烈。苹果[发布了两篇新研究论文](<a href="https://x.com/dotey/status/1738767070022570250">x.com/dotey/status/173876707…</a>)，介绍了3D头像和高效语言模型推理的新技术，这些技术被认为有望提供更加沉浸式的视觉体验，并使复杂的AI系统能够在消费者设备如iPhone和iPad上运行。<br />
<br />
AI社区中许多原本未注意到Ferret发布的成员，对苹果这一意外进入开源LLM领域的行动表示欢迎，尤其是鉴于苹果一向以其“封闭园区”的形象而闻名。<br />
<br />
今晨，专注于医疗领域开源AI的欧洲非营利组织负责人Bart de Witte在X平台上分享了他的惊讶：“我之前竟然没发现这个。”他表示，“苹果在10月份加入了开源AI圈子。Ferret的推出展现了苹果对影响深远的AI研究的承诺，巩固了它在多模态AI领域的领先地位……另外，我很期待有一天Local Large Language Models (LLLMs)能作为重新设计的iOS的一部分，在我的iPhone上运行。”<br />
<br />
德国AI音乐艺术家及顾问Tristan Behrens也表达了他的看法，他在领英上写道：“明天就是圣诞节，但你知道吗？苹果（没错，就是苹果！）近期发布了一个包含代码和权重的多模态大语言模型。”<br />
<br />
科技博客作家兼VentureBeat撰稿人Ben Dickson在领英上的发言提到了这一惊喜：“2023年最让你意外的AI进展是什么？对我来说，是苹果发布了开源LLMs（虽然是非商业许可）。”他指出，苹果一直是封闭系统、封闭园区开发、保密、严格的保密协议、发布极少细节、并为其产品申请每一项小的专利的代表。<br />
<br />
他继续说道：“但回过头来看，苹果（像Meta一样）推出开源LLM模型是合情合理的。要与ChatGPT这类模型竞争，你要么得是一个超级计算者，要么需要强大的合作伙伴。苹果虽然资源丰富，但其基础设施并不是为服务大规模LLMs而建的。另一种选择是依赖像微软或谷歌这样的云服务提供商（两大劲敌），或者像Meta那样开始发布自己的开源模型。”<br />
<br />
值得注意的是，苹果开源及本地ML发展的消息传来之际，Anthropic和OpenAI据报道正在为他们的专有LLM开发工作进行大规模的新资金筹集。据路透社[本周三报道](http://seeking%20to%20raise%20$750%20mln%20in%20funding%20round%20led%20by%20menlo%20ventures/)，Anthropic正在与Menlo Ventures商谈筹集7.5亿美元的资金。而根据[彭博社昨天的报道](<a href="https://www.bloomberg.com/news/articles/2023-12-22/openai-in-talks-to-raise-new-funding-at-100-billion-valuation">bloomberg.com/news/articles/…</a>)，OpenAI正在进行初步讨论，计划以至少1000亿美元的估值筹集新一轮资金。<br />
<br />
这一系列动态显示了AI领域的竞争格局正在发生变化。尽管苹果以往以其产品和技术的封闭性著称，但现在它通过发布开源LLM模型，正逐渐改变这一形象，展现出其在AI领域的活跃参与和创新精神。这不仅对苹果自身，也对整个AI领域来说，都是一个值得关注的重要发展方向。<br />
<br />
来源：<a href="https://venturebeat.com/ai/apple-quietly-released-an-open-source-multimodal-llm-in-october/">venturebeat.com/ai/apple-qui…</a></p>
<p><a href="https://nitter.cz/dotey/status/1738767070022570250#m">nitter.cz/dotey/status/1738767070022570250#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NGaG00aVh3QUFUSGQ1LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738767070022570250#m</id>
            <title>转译：《苹果最新 AI 研究或将彻底革新你的 iPhone》

苹果这个几乎与技术创新划等号的公司，再次站在了 AI 革命的前沿。

这家总部位于加州库比蒂诺的公司最近公布了在人工智能研究领域的重要进展，推出了两篇新论文，分别介绍了用于 3D 头像和高效语言模型推断的新技术。这些创新有望为用户提供更沉浸式的视觉体验，并使复杂的 AI 系统能够在 iPhone 和 iPad 等消费者设备上运行。

在其[第一篇研究论文](https://arxiv.org/pdf/2311.17910.pdf)中，苹果的科学家们提出了一个名为 [HUGS](https://machinelearning.apple.com/research/hugs)（人类高斯喷溅，Human Gaussian Splats）的技术，用于从单镜头短视频中生成动态的 3D 人像。“我们的方法只需一段短单镜头视频（50-100 帧），就能自动学习分离静态场景和一个完全可动画化的人像，整个过程仅需 30 分钟，” 首席作者 Muhammed Kocabas 表示。

图一
该技术包括训练视频（左上），重建的标准人体头像（右上），重建的场景模型（左下），以及重新布局的动画人体与场景（右下）。 （图片来源：Apple）

HUGS 使用一种高效的渲染技术，即 3D 高斯喷溅，来同时展现人物和背景场景。人物模型以 [SMPL](https://smpl.is.tue.mpg.de/)（一种统计学身体形态模型）为基础构建。而 HUGS 通过允许高斯变形，能够捕捉到衣物和发型等细节。

一个创新的[神经形变模块](https://machinelearning.apple.com/research/neural-engine-transformers) 采用线性混合蒙皮技术（linear blend skinning），使得高斯以逼真的方式动态表现。这种协调的动作避免了在调整人像姿势时产生的视觉失真。Kocabas 指出，HUGS 能够实现对人物新姿势的合成以及对人物和场景的新视角合成。

相较于早期的头像生成方法，HUGS 在训练和渲染速度上高达100倍。研究者们在标准游戏GPU上仅用30分钟进行系统优化，就取得了逼真的效果。在 3D 重建质量方面，HUGS 也超过了如 [Vid2Avatar](https://github.com/MoyGcc/vid2avatar) 和 [NeuMan](https://machinelearning.apple.com/research/neural-human-radiance-field) 等最先进技术。

这项新技术使人们仅需一段包含人物和场景的视频，就能将不同的数字角色或“头像”置入新环境中。这个过程非常迅速，图像每秒更新60次，达到流畅且逼真的效果。

苹果研究团队的这一新 3D 建模成就非常引人注目。实时表现能力及利用实地视频创造头像的技术，很快就可能为虚拟试穿、远程互动及合成媒体领域开辟新天地。想象一下，如果你可以直接在 iPhone 相机上制作如此新颖的 3D 场景，会带来怎样的创新可能性！

## 在人工智能推断中弥合内存差距

在[第二篇论文](https://arxiv.org/pdf/2312.11514.pdf)中，苹果(Apple)的研究团队应对了一个挑战：如何将庞大的大语言模型 (LLMs)，比如参数众多的 GPT-4，部署到内存受限的设备上。这些先进的自然语言模型由于参数众多，让在普通消费级硬件上的推断变得耗费资源。

他们提出的系统旨在最大程度减少在推断过程中从闪存到有限的动态随机存取内存 (DRAM) 的数据传输量。“我们的方法是建立一个与闪存行为相协调的推断成本模型，从而在两个关键方面进行优化：一是减少从闪存到内存的数据传输量，二是以更大、更连续的数据块进行读取，”首席研究员 Keivan Alizadeh 详细说明了这一点。

研究中引入了两种主要技术：“窗口化”，即重复利用最近推断过程中的激活数据；以及“行列捆绑”，通过将数据的行和列存储在一起，实现读取更大的数据块。在苹果 M1 Max CPU 上运用这些技术，相比传统的简单数据加载方法，推断速度提高了 4-5 倍；而在 GPU 上，速度提升更是达到了 20-25 倍。

“这项技术突破对于在资源受限的环境中部署先进的大语言模型至关重要，这不仅扩大了这些模型的应用范围，也提高了它们的易用性，”共同作者 Mehrdad Farajtabar 表示。这些优化不久后可能使得复杂的 AI 助手和聊天机器人能够在 iPhone、iPad 和其他移动设备上流畅运行。

## 苹果的战略愿景

这两篇论文凸显了苹果在 AI 研究和应用领域的逐渐增强的领导力。尽管前景充满希望，专家们提醒，苹果在将这些技术整合到消费产品中时必须格外慎重，承担相应的责任。从保护隐私到预防技术滥用，都应全面考虑到[社会影响](https://venturebeat.com/ai/the-widening-web-of-effective-altruism-in-ai-security-the-ai-beat/)。

苹果可能会将这些创新技术融入其产品系列，不仅仅是为了提升设备性能，更是为了预见混合 AI 服务的未来需求。苹果允许更复杂的 AI 模型在内存有限的设备上运行，为新一代应用和服务的开发奠定基础，这些应用和服务将以前所未有的方式利用大语言模型（LLMs）的强大功能。

此外，苹果公开发布这些研究成果，对整个 AI 领域做出了贡献，这可能会促进该领域的进一步发展。这一行为反映了苹果对自身作为技术领先者地位的自信，以及不断探索新可能性的承诺。

苹果的最新创新如果得到恰当应用，有可能将人工智能提升至一个新高度。逼真的数字化虚拟形象和强大的 AI 助手原本只存在于遥远的未来设想中 — 但在苹果科学家的努力下，这一未来正迅速成为现实。

来源：https://venturebeat.com/ai/apples-latest-ai-research-could-completely-transform-your-iphone/</title>
            <link>https://nitter.cz/dotey/status/1738767070022570250#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738767070022570250#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 03:42:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：《苹果最新 AI 研究或将彻底革新你的 iPhone》<br />
<br />
苹果这个几乎与技术创新划等号的公司，再次站在了 AI 革命的前沿。<br />
<br />
这家总部位于加州库比蒂诺的公司最近公布了在人工智能研究领域的重要进展，推出了两篇新论文，分别介绍了用于 3D 头像和高效语言模型推断的新技术。这些创新有望为用户提供更沉浸式的视觉体验，并使复杂的 AI 系统能够在 iPhone 和 iPad 等消费者设备上运行。<br />
<br />
在其[第一篇研究论文](<a href="https://arxiv.org/pdf/2311.17910.pdf">arxiv.org/pdf/2311.17910.pdf</a>)中，苹果的科学家们提出了一个名为 [HUGS](<a href="https://machinelearning.apple.com/research/hugs">machinelearning.apple.com/re…</a>)（人类高斯喷溅，Human Gaussian Splats）的技术，用于从单镜头短视频中生成动态的 3D 人像。“我们的方法只需一段短单镜头视频（50-100 帧），就能自动学习分离静态场景和一个完全可动画化的人像，整个过程仅需 30 分钟，” 首席作者 Muhammed Kocabas 表示。<br />
<br />
图一<br />
该技术包括训练视频（左上），重建的标准人体头像（右上），重建的场景模型（左下），以及重新布局的动画人体与场景（右下）。 （图片来源：Apple）<br />
<br />
HUGS 使用一种高效的渲染技术，即 3D 高斯喷溅，来同时展现人物和背景场景。人物模型以 [SMPL](<a href="https://smpl.is.tue.mpg.de/">smpl.is.tue.mpg.de/</a>)（一种统计学身体形态模型）为基础构建。而 HUGS 通过允许高斯变形，能够捕捉到衣物和发型等细节。<br />
<br />
一个创新的[神经形变模块](<a href="https://machinelearning.apple.com/research/neural-engine-transformers">machinelearning.apple.com/re…</a>) 采用线性混合蒙皮技术（linear blend skinning），使得高斯以逼真的方式动态表现。这种协调的动作避免了在调整人像姿势时产生的视觉失真。Kocabas 指出，HUGS 能够实现对人物新姿势的合成以及对人物和场景的新视角合成。<br />
<br />
相较于早期的头像生成方法，HUGS 在训练和渲染速度上高达100倍。研究者们在标准游戏GPU上仅用30分钟进行系统优化，就取得了逼真的效果。在 3D 重建质量方面，HUGS 也超过了如 [Vid2Avatar](<a href="https://github.com/MoyGcc/vid2avatar">github.com/MoyGcc/vid2avatar</a>) 和 [NeuMan](<a href="https://machinelearning.apple.com/research/neural-human-radiance-field">machinelearning.apple.com/re…</a>) 等最先进技术。<br />
<br />
这项新技术使人们仅需一段包含人物和场景的视频，就能将不同的数字角色或“头像”置入新环境中。这个过程非常迅速，图像每秒更新60次，达到流畅且逼真的效果。<br />
<br />
苹果研究团队的这一新 3D 建模成就非常引人注目。实时表现能力及利用实地视频创造头像的技术，很快就可能为虚拟试穿、远程互动及合成媒体领域开辟新天地。想象一下，如果你可以直接在 iPhone 相机上制作如此新颖的 3D 场景，会带来怎样的创新可能性！<br />
<br />
## 在人工智能推断中弥合内存差距<br />
<br />
在[第二篇论文](<a href="https://arxiv.org/pdf/2312.11514.pdf">arxiv.org/pdf/2312.11514.pdf</a>)中，苹果(Apple)的研究团队应对了一个挑战：如何将庞大的大语言模型 (LLMs)，比如参数众多的 GPT-4，部署到内存受限的设备上。这些先进的自然语言模型由于参数众多，让在普通消费级硬件上的推断变得耗费资源。<br />
<br />
他们提出的系统旨在最大程度减少在推断过程中从闪存到有限的动态随机存取内存 (DRAM) 的数据传输量。“我们的方法是建立一个与闪存行为相协调的推断成本模型，从而在两个关键方面进行优化：一是减少从闪存到内存的数据传输量，二是以更大、更连续的数据块进行读取，”首席研究员 Keivan Alizadeh 详细说明了这一点。<br />
<br />
研究中引入了两种主要技术：“窗口化”，即重复利用最近推断过程中的激活数据；以及“行列捆绑”，通过将数据的行和列存储在一起，实现读取更大的数据块。在苹果 M1 Max CPU 上运用这些技术，相比传统的简单数据加载方法，推断速度提高了 4-5 倍；而在 GPU 上，速度提升更是达到了 20-25 倍。<br />
<br />
“这项技术突破对于在资源受限的环境中部署先进的大语言模型至关重要，这不仅扩大了这些模型的应用范围，也提高了它们的易用性，”共同作者 Mehrdad Farajtabar 表示。这些优化不久后可能使得复杂的 AI 助手和聊天机器人能够在 iPhone、iPad 和其他移动设备上流畅运行。<br />
<br />
## 苹果的战略愿景<br />
<br />
这两篇论文凸显了苹果在 AI 研究和应用领域的逐渐增强的领导力。尽管前景充满希望，专家们提醒，苹果在将这些技术整合到消费产品中时必须格外慎重，承担相应的责任。从保护隐私到预防技术滥用，都应全面考虑到[社会影响](<a href="https://venturebeat.com/ai/the-widening-web-of-effective-altruism-in-ai-security-the-ai-beat/">venturebeat.com/ai/the-widen…</a>)。<br />
<br />
苹果可能会将这些创新技术融入其产品系列，不仅仅是为了提升设备性能，更是为了预见混合 AI 服务的未来需求。苹果允许更复杂的 AI 模型在内存有限的设备上运行，为新一代应用和服务的开发奠定基础，这些应用和服务将以前所未有的方式利用大语言模型（LLMs）的强大功能。<br />
<br />
此外，苹果公开发布这些研究成果，对整个 AI 领域做出了贡献，这可能会促进该领域的进一步发展。这一行为反映了苹果对自身作为技术领先者地位的自信，以及不断探索新可能性的承诺。<br />
<br />
苹果的最新创新如果得到恰当应用，有可能将人工智能提升至一个新高度。逼真的数字化虚拟形象和强大的 AI 助手原本只存在于遥远的未来设想中 — 但在苹果科学家的努力下，这一未来正迅速成为现实。<br />
<br />
来源：<a href="https://venturebeat.com/ai/apples-latest-ai-research-could-completely-transform-your-iphone/">venturebeat.com/ai/apples-la…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg3NjY4NzkzMTE3NTczMTIvcHUvaW1nL19HMU94dE1xQjVjT0ttWnUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738614091349172544#m</id>
            <title>RT by @dotey: 卧槽，看了这个老哥用Midjourney V6生产3D素材，突发奇想，既然V6对中国传统元素的了解很详细，能不能也用来生产中国风3D素材贴图。

试了一下居然真可以，这效果也太好了。建模直接照着做就行，要求低可以直接用 https://3d. csm. ai/ 这种网站生成。

图像生成是现在视觉媒体生成的绝对上游，上游质量的突破绝对会帮助视频、3D等下游带来巨大突破。

提示词模板：
A highly detailed 3D render of [需要生成的物品] isolated on a white background as an RPG game asset, unreal engine, ray tracing --ar 3:2 --v 6.0</title>
            <link>https://nitter.cz/op7418/status/1738614091349172544#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738614091349172544#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 17:34:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，看了这个老哥用Midjourney V6生产3D素材，突发奇想，既然V6对中国传统元素的了解很详细，能不能也用来生产中国风3D素材贴图。<br />
<br />
试了一下居然真可以，这效果也太好了。建模直接照着做就行，要求低可以直接用 https://3d. csm. ai/ 这种网站生成。<br />
<br />
图像生成是现在视觉媒体生成的绝对上游，上游质量的突破绝对会帮助视频、3D等下游带来巨大突破。<br />
<br />
提示词模板：<br />
A highly detailed 3D render of [需要生成的物品] isolated on a white background as an RPG game asset, unreal engine, ray tracing --ar 3:2 --v 6.0</p>
<p><a href="https://nitter.cz/chaseleantj/status/1738511249107767788#m">nitter.cz/chaseleantj/status/1738511249107767788#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NETGl6RWJJQUF2VGJuLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NETF9LTGJFQUVGRzZPLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NETDZ2UmF3QUE3dWRMLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NETDJ2amIwQUFlN1ViLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lin_bob57617/status/1738486215178125640#m</id>
            <title>RT by @dotey: 大佬们可以考虑我这个项目: https://github.com/169/video-translation ，虽然目前还在施工中..  之前也看到 @dotey 宝玉老师的这个工具，UI也不错，但是缺点一是不能定制，二是不能集成到一个工作流里面，比较割裂(需要先出字幕，来这里编辑，最后用另外的工具生成带字幕的视频)，我这个项目昨天刚新加了一个基于streamlit的Web UI，把整个过程放到一个页面，另外主要用Python实现，定制性会很好，页面功能会越来越全 （这里有个视频: https://www.youtube.com/watch?v=45wv4HPBAQ4），现在支持:

1. 可以指定多个配置项，例如whisper模型（或者使用Openai API，我实际使用发现开源的whisper没有官方API效果好，尤其是翻译语言时），语言，视频文件类型，字幕样式等 
2. 支持根据视频生成字幕 
3. 支持字幕添加后的预览模式(我写了一个自定义的视频组件)
4. 支持字幕编辑，如果点"auto save"可以让修改实时生效 
5. 支持字幕文件下载 
6. 支持生成添加字幕的视频

之后计划添加的:

1. 时间轴编辑
2. 支持双语字幕
3. 中文自动适配时间轴</title>
            <link>https://nitter.cz/lin_bob57617/status/1738486215178125640#m</link>
            <guid isPermaLink="false">https://nitter.cz/lin_bob57617/status/1738486215178125640#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 09:06:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大佬们可以考虑我这个项目: <a href="https://github.com/169/video-translation">github.com/169/video-transla…</a> ，虽然目前还在施工中..  之前也看到 <a href="https://nitter.cz/dotey" title="宝玉">@dotey</a> 宝玉老师的这个工具，UI也不错，但是缺点一是不能定制，二是不能集成到一个工作流里面，比较割裂(需要先出字幕，来这里编辑，最后用另外的工具生成带字幕的视频)，我这个项目昨天刚新加了一个基于streamlit的Web UI，把整个过程放到一个页面，另外主要用Python实现，定制性会很好，页面功能会越来越全 （这里有个视频: <a href="https://www.youtube.com/watch?v=45wv4HPBAQ4">youtube.com/watch?v=45wv4HPB…</a>），现在支持:<br />
<br />
1. 可以指定多个配置项，例如whisper模型（或者使用Openai API，我实际使用发现开源的whisper没有官方API效果好，尤其是翻译语言时），语言，视频文件类型，字幕样式等 <br />
2. 支持根据视频生成字幕 <br />
3. 支持字幕添加后的预览模式(我写了一个自定义的视频组件)<br />
4. 支持字幕编辑，如果点"auto save"可以让修改实时生效 <br />
5. 支持字幕文件下载 <br />
6. 支持生成添加字幕的视频<br />
<br />
之后计划添加的:<br />
<br />
1. 时间轴编辑<br />
2. 支持双语字幕<br />
3. 中文自动适配时间轴</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NCWF9COGEwQUFwZHMtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738468015342076139#m</id>
            <title>R to @dotey: 一个问题和解释
https://x.com/goldengrape/status/1738462928532287768?s=20</title>
            <link>https://nitter.cz/dotey/status/1738468015342076139#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738468015342076139#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 07:54:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个问题和解释<br />
<a href="https://x.com/goldengrape/status/1738462928532287768?s=20">x.com/goldengrape/status/173…</a></p>
<p><a href="https://nitter.cz/goldengrape/status/1738462928532287768#m">nitter.cz/goldengrape/status/1738462928532287768#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738451824661627241#m</id>
            <title>#AI开源项目推荐：AI-Employe

又一款开源的基于GPT-4V的API操作浏览器的浏览器插件

https://github.com/vignshwarar/AI-Employe</title>
            <link>https://nitter.cz/dotey/status/1738451824661627241#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738451824661627241#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 06:49:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：AI-Employe<br />
<br />
又一款开源的基于GPT-4V的API操作浏览器的浏览器插件<br />
<br />
<a href="https://github.com/vignshwarar/AI-Employe">github.com/vignshwarar/AI-Em…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg0NTE2NTYxODQ4ODkzNDQvcHUvaW1nL082Zkk1anlmY0tKa2RLemYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738446618146336794#m</id>
            <title>就是普通的文档问答，基于Embedding做相似度搜索，把字幕向量化存向量数据，而且它没有用OpenAI的Embedding（用的Gegeral Text Embeddings (GTE) model），估计中文支持不会太好。

顺便说下，首页搜索框的自动完成是调用的YouTube的API所以看着还行</title>
            <link>https://nitter.cz/dotey/status/1738446618146336794#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738446618146336794#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 06:29:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>就是普通的文档问答，基于Embedding做相似度搜索，把字幕向量化存向量数据，而且它没有用OpenAI的Embedding（用的Gegeral Text Embeddings (GTE) model），估计中文支持不会太好。<br />
<br />
顺便说下，首页搜索框的自动完成是调用的YouTube的API所以看着还行</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1738435580516765958#m">nitter.cz/xiaohuggg/status/1738435580516765958#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738442390313029973#m</id>
            <title>一篇关于在扩散模型中生成文字的论文：TextDiffuser-2: Unleashing the Power of Language Models for Text Rendering

可以稳定在扩散模型中生成指定位置和风格的英文文本（中文测试过无法正常生成），它是借助的微调后的大语言模型来规划文本布局，以及编码文本的位置。

项目首页：https://jingyechen.github.io/textdiffuser2/
论文：https://arxiv.org/abs/2311.16465
在线测试地址：https://huggingface.co/spaces/JingyeChen22/TextDiffuser-2
代码：https://github.com/microsoft/unilm/tree/master/textdiffuser-2</title>
            <link>https://nitter.cz/dotey/status/1738442390313029973#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738442390313029973#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 06:12:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一篇关于在扩散模型中生成文字的论文：TextDiffuser-2: Unleashing the Power of Language Models for Text Rendering<br />
<br />
可以稳定在扩散模型中生成指定位置和风格的英文文本（中文测试过无法正常生成），它是借助的微调后的大语言模型来规划文本布局，以及编码文本的位置。<br />
<br />
项目首页：<a href="https://jingyechen.github.io/textdiffuser2/">jingyechen.github.io/textdif…</a><br />
论文：<a href="https://arxiv.org/abs/2311.16465">arxiv.org/abs/2311.16465</a><br />
在线测试地址：<a href="https://huggingface.co/spaces/JingyeChen22/TextDiffuser-2">huggingface.co/spaces/Jingye…</a><br />
代码：<a href="https://github.com/microsoft/unilm/tree/master/textdiffuser-2">github.com/microsoft/unilm/t…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBdUx2QldRQUFRdDA4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBdU1fQVdFQUFYSU1oLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBdVJ5R1hzQUFsMmZILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBdVN6U1dnQUFDSDY0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/iarrp/status/1738436868096868752#m</id>
            <title>RT by @dotey: 感谢宝玉老师的推荐 @dotey 🫰🏻

自 5 月份推出产品以来，Dify 帮助了相当多的国内外开发者和非技术小白用户低成本地验证自己充满创意的 idea，截止今天一共在上面搭建起了将近 10 万个 AI 应用。

同时我们也有相当一部分的企业级客户，通过私有化部署和二次开发，将 Dify 嵌入到企业原有的产品或者工作流中，快速完成产线的 AI 化升级。

在这个过程中，我们也收到了相当多的支持和反馈，我与许多喜爱我们产品的用户进行过沟通，得到最多的正面评价是“易用”和“克制”。

在今年三月份开始定义产品时，我们的整个构想建立在以下三点假设之上：

1. Democratization of AI，Prompt 工程 ，RAG 和 Fine-tune 对用户来说是复杂技术有待简化；

2. Cross-Functional Collaboration in AI，非技术人员需要参与到 AI 应用的定义过程之中；

3. Data-Driven Feedback，AI 应用的效果提升建立在生产数据的持续反馈。

这三点假设直至今天依旧成立。

在今年实现了帮助用户完成“从想法到应用的快速验证”这一小目标之后，明年我们的产品形态将从 “GPTs 平替” 回归到 “LLM 应用开发技术栈” 之上，为用户提供更深度，丰富，可定制的技术解决方案。

作为一个小团队用心做的一款开源产品，我们的产品迭代速度有时也显得“克制”。我们将在近期在社区开放产品的 Roadmap，联合开发者社区的力量帮助我们一起打造这款产品。

Dify -- Do It For You ❤️</title>
            <link>https://nitter.cz/iarrp/status/1738436868096868752#m</link>
            <guid isPermaLink="false">https://nitter.cz/iarrp/status/1738436868096868752#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 05:50:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>感谢宝玉老师的推荐 <a href="https://nitter.cz/dotey" title="宝玉">@dotey</a> 🫰🏻<br />
<br />
自 5 月份推出产品以来，Dify 帮助了相当多的国内外开发者和非技术小白用户低成本地验证自己充满创意的 idea，截止今天一共在上面搭建起了将近 10 万个 AI 应用。<br />
<br />
同时我们也有相当一部分的企业级客户，通过私有化部署和二次开发，将 Dify 嵌入到企业原有的产品或者工作流中，快速完成产线的 AI 化升级。<br />
<br />
在这个过程中，我们也收到了相当多的支持和反馈，我与许多喜爱我们产品的用户进行过沟通，得到最多的正面评价是“易用”和“克制”。<br />
<br />
在今年三月份开始定义产品时，我们的整个构想建立在以下三点假设之上：<br />
<br />
1. Democratization of AI，Prompt 工程 ，RAG 和 Fine-tune 对用户来说是复杂技术有待简化；<br />
<br />
2. Cross-Functional Collaboration in AI，非技术人员需要参与到 AI 应用的定义过程之中；<br />
<br />
3. Data-Driven Feedback，AI 应用的效果提升建立在生产数据的持续反馈。<br />
<br />
这三点假设直至今天依旧成立。<br />
<br />
在今年实现了帮助用户完成“从想法到应用的快速验证”这一小目标之后，明年我们的产品形态将从 “GPTs 平替” 回归到 “LLM 应用开发技术栈” 之上，为用户提供更深度，丰富，可定制的技术解决方案。<br />
<br />
作为一个小团队用心做的一款开源产品，我们的产品迭代速度有时也显得“克制”。我们将在近期在社区开放产品的 Roadmap，联合开发者社区的力量帮助我们一起打造这款产品。<br />
<br />
Dify -- Do It For You ❤️</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738412368437109019#m</id>
            <title>推荐阅读：《math team
and other horrible things you do to get into stanford | 数学队——及其他你为了进入斯坦福而做出的疯狂之举 [译]》

一个被普林斯顿拒绝、拒绝了MIT，去了斯坦福的学霸写的高中在数学队的经历。

美国的高中也挺卷的，为了上名校也都是各显神通，就像作者本人，在数学上有一点天赋，而加入数学对就是一条捷径，有更大机会上名校。

而对于高中数学队的教练来说，他的数学队经费依赖于学校，而学校的经费又取决于能否持续将学生送入顶尖大学。

像作者这样即使在数学上有天赋的孩子，学习数学对他来说也不是件快乐的事情，但是为了名校还是不得不拼命努力，最终所有这些努力最终只会被压缩成申请表上的几行字，然后被招生委员会在大约九十秒内匆匆审阅，之后就转向下一个成绩优异的申请者。

原文：https://benexdict.io/p/math-team
译文：https://baoyu.io/translations/life/math-team</title>
            <link>https://nitter.cz/dotey/status/1738412368437109019#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738412368437109019#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 04:13:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《math team<br />
and other horrible things you do to get into stanford | 数学队——及其他你为了进入斯坦福而做出的疯狂之举 [译]》<br />
<br />
一个被普林斯顿拒绝、拒绝了MIT，去了斯坦福的学霸写的高中在数学队的经历。<br />
<br />
美国的高中也挺卷的，为了上名校也都是各显神通，就像作者本人，在数学上有一点天赋，而加入数学对就是一条捷径，有更大机会上名校。<br />
<br />
而对于高中数学队的教练来说，他的数学队经费依赖于学校，而学校的经费又取决于能否持续将学生送入顶尖大学。<br />
<br />
像作者这样即使在数学上有天赋的孩子，学习数学对他来说也不是件快乐的事情，但是为了名校还是不得不拼命努力，最终所有这些努力最终只会被压缩成申请表上的几行字，然后被招生委员会在大约九十秒内匆匆审阅，之后就转向下一个成绩优异的申请者。<br />
<br />
原文：<a href="https://benexdict.io/p/math-team">benexdict.io/p/math-team</a><br />
译文：<a href="https://baoyu.io/translations/life/math-team">baoyu.io/translations/life/m…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBVTBIUlhFQUFkalZXLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738400607336120573#m</id>
            <title>年底最值得一读的 RAG 论文：
《Retrieval-Augmented Generation for Large Language Models: A Survey | 面向大语言模型的检索增强生成技术：调查 [译]》

摘要：

在这篇调查中，我们关注的是面向大语言模型的检索增强生成技术。这项技术通过结合检索机制，增强了大语言模型在处理复杂查询和生成更准确信息方面的能力。我们从同济大学和复旦大学的相关研究团队出发，综合分析了该领域的最新进展和未来趋势。

校对中难免有疏漏指出，有翻译错误请指出！

https://baoyu.io/translations/ai-paper/2312.10997-retrieval-augmented-generation-for-large-language-models-a-survey</title>
            <link>https://nitter.cz/dotey/status/1738400607336120573#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738400607336120573#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 03:26:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>年底最值得一读的 RAG 论文：<br />
《Retrieval-Augmented Generation for Large Language Models: A Survey | 面向大语言模型的检索增强生成技术：调查 [译]》<br />
<br />
摘要：<br />
<br />
在这篇调查中，我们关注的是面向大语言模型的检索增强生成技术。这项技术通过结合检索机制，增强了大语言模型在处理复杂查询和生成更准确信息方面的能力。我们从同济大学和复旦大学的相关研究团队出发，综合分析了该领域的最新进展和未来趋势。<br />
<br />
校对中难免有疏漏指出，有翻译错误请指出！<br />
<br />
<a href="https://baoyu.io/translations/ai-paper/2312.10997-retrieval-augmented-generation-for-large-language-models-a-survey">baoyu.io/translations/ai-pap…</a></p>
<p><a href="https://nitter.cz/9hills/status/1737451462077399071#m">nitter.cz/9hills/status/1737451462077399071#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBS0NrX1c4QUFnNlZ1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBS0ZhdVhzQVExSkc0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBS0ZheFgwQUF0VEs0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBS0Zhd1h3QUFUZURzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>