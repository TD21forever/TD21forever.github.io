<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/songma/status/1751482861981737441#m</id>
            <title>RT by @dotey: 马老师跟春丽切磋。

英国伦敦腔小粉红：DON’T TOUCH HER!!! U ARE NOT HER AGE!!!😭</title>
            <link>https://nitter.cz/songma/status/1751482861981737441#m</link>
            <guid isPermaLink="false">https://nitter.cz/songma/status/1751482861981737441#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 05:50:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>马老师跟春丽切磋。<br />
<br />
英国伦敦腔小粉红：DON’T TOUCH HER!!! U ARE NOT HER AGE!!!😭</p>
<p><a href="https://nitter.cz/xiaxiaoqiang/status/1751425708126097804#m">nitter.cz/xiaxiaoqiang/status/1751425708126097804#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751486058913481159#m</id>
            <title>Google 新的 OKRs

上周四，Google CEO Pichai 在备忘录中提到的公司级 OKRs（Objectives and Key Results，目标与关键成果）。目标如下：

1.⁠ ⁠打造全球最领先、最安全、最有社会责任感的人工智能（AI）。
2.⁠ ⁠提升知识水平、学习能力、创造力和工作效率。
3. 开发出最实用的个人计算平台和设备。
4.⁠ ⁠支持各组织和开发者在谷歌云平台上进行创新。
5. 提供全球最受信赖的产品和平台。
6. 建设一个对谷歌员工和全世界都极具价值的谷歌公司。
7.⁠ ⁠提升公司的运营速度、效率和生产力，并实现长期的成本节约。

来源：https://www.theverge.com/2024/1/18/24043547/inside-meta-ai-reorg-mark-zuckerberg</title>
            <link>https://nitter.cz/dotey/status/1751486058913481159#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751486058913481159#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 06:03:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google 新的 OKRs<br />
<br />
上周四，Google CEO Pichai 在备忘录中提到的公司级 OKRs（Objectives and Key Results，目标与关键成果）。目标如下：<br />
<br />
1.⁠ ⁠打造全球最领先、最安全、最有社会责任感的人工智能（AI）。<br />
2.⁠ ⁠提升知识水平、学习能力、创造力和工作效率。<br />
3. 开发出最实用的个人计算平台和设备。<br />
4.⁠ ⁠支持各组织和开发者在谷歌云平台上进行创新。<br />
5. 提供全球最受信赖的产品和平台。<br />
6. 建设一个对谷歌员工和全世界都极具价值的谷歌公司。<br />
7.⁠ ⁠提升公司的运营速度、效率和生产力，并实现长期的成本节约。<br />
<br />
来源：<a href="https://www.theverge.com/2024/1/18/24043547/inside-meta-ai-reorg-mark-zuckerberg">theverge.com/2024/1/18/24043…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U2QWJMcVhNQUFGSWN2LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751472529724620922#m</id>
            <title>R to @dotey: 普通贴纸，乐乐贴 http://skinat.com/
@zhengle

https://x.com/Yangyixxxx/status/1751471372503822828?s=20</title>
            <link>https://nitter.cz/dotey/status/1751472529724620922#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751472529724620922#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 05:09:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>普通贴纸，乐乐贴 <a href="http://skinat.com/">skinat.com/</a><br />
<a href="https://nitter.cz/zhengle" title="zhengle">@zhengle</a><br />
<br />
<a href="https://x.com/Yangyixxxx/status/1751471372503822828?s=20">x.com/Yangyixxxx/status/1751…</a></p>
<p><a href="https://nitter.cz/Yangyixxxx/status/1751471372503822828#m">nitter.cz/Yangyixxxx/status/1751471372503822828#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751470666522542431#m</id>
            <title>前面那个用多模态为图片重命名的应用 让我想起来两个月前给朋友做过一个GPT，专门帮助他给图片命名。

他是做贴纸的，需要给图片生成SEO友好的标题，以前是花钱买第三方的图片描述服务，流程是这样的：
1. 上传照片给一个第三服务，第三方服务给出详细的图片说明
2. 他把图片说明提供给ChatGPT，让GPT提供10个中英文名称
3. 它再让GPT基于这10个中英文名称，生成5个SEO标题

那会GPTs刚推出，我说你不用这么麻烦，做个GPT，上传照片给它就都搞定了，不需要你这么来回倒腾。

逻辑很简单：
1. 让GPT先对图片详细描述
2. 基于描述信息直接生成5个SEO友好的标题

而且这个逻辑在一个Prompt内就搞定了，只要一次交互！

这里面有个小技巧就是借助简单的CoT（思考链），先生成图片详细描述再生成标题，为标题提供充分的资料，这样可以保证生成标题的质量。

测试地址：https://chat.openai.com/g/g-102boyviu-image-captioning

Prompt：

If the user has not uploaded an image or the image is not in a standard format (e.g., JPEG, PNG), remind them to upload an image and wait for their upload. 

For the image provided by the user, follow these steps:
1. Write 1-3 detailed paragraphs describing the content of the image. Focus on elements like the main subject, background, colors, and mood.
2. Create 5 different style titles based on the description. Each title should be concise, within a single sentence, and SEO-friendly. Incorporate relevant keywords and be descriptive.
3. Output the results in the language used by the user. If English is used, provide only English titles; for other languages, offer bilingual titles (in English and the user's language).

This approach ensures clarity in instructions and improves user experience by providing detailed guidance on image descriptions and title creation, while also accommodating the user's language preferences.</title>
            <link>https://nitter.cz/dotey/status/1751470666522542431#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751470666522542431#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 05:02:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前面那个用多模态为图片重命名的应用 让我想起来两个月前给朋友做过一个GPT，专门帮助他给图片命名。<br />
<br />
他是做贴纸的，需要给图片生成SEO友好的标题，以前是花钱买第三方的图片描述服务，流程是这样的：<br />
1. 上传照片给一个第三服务，第三方服务给出详细的图片说明<br />
2. 他把图片说明提供给ChatGPT，让GPT提供10个中英文名称<br />
3. 它再让GPT基于这10个中英文名称，生成5个SEO标题<br />
<br />
那会GPTs刚推出，我说你不用这么麻烦，做个GPT，上传照片给它就都搞定了，不需要你这么来回倒腾。<br />
<br />
逻辑很简单：<br />
1. 让GPT先对图片详细描述<br />
2. 基于描述信息直接生成5个SEO友好的标题<br />
<br />
而且这个逻辑在一个Prompt内就搞定了，只要一次交互！<br />
<br />
这里面有个小技巧就是借助简单的CoT（思考链），先生成图片详细描述再生成标题，为标题提供充分的资料，这样可以保证生成标题的质量。<br />
<br />
测试地址：<a href="https://chat.openai.com/g/g-102boyviu-image-captioning">chat.openai.com/g/g-102boyvi…</a><br />
<br />
Prompt：<br />
<br />
If the user has not uploaded an image or the image is not in a standard format (e.g., JPEG, PNG), remind them to upload an image and wait for their upload. <br />
<br />
For the image provided by the user, follow these steps:<br />
1. Write 1-3 detailed paragraphs describing the content of the image. Focus on elements like the main subject, background, colors, and mood.<br />
2. Create 5 different style titles based on the description. Each title should be concise, within a single sentence, and SEO-friendly. Incorporate relevant keywords and be descriptive.<br />
3. Output the results in the language used by the user. If English is used, provide only English titles; for other languages, offer bilingual titles (in English and the user's language).<br />
<br />
This approach ensures clarity in instructions and improves user experience by providing detailed guidance on image descriptions and title creation, while also accommodating the user's language preferences.</p>
<p><a href="https://nitter.cz/dotey/status/1751436030903812569#m">nitter.cz/dotey/status/1751436030903812569#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U1NFJlT1dnQUFobGd2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751454896593809666#m</id>
            <title>R to @dotey: 这个案例也不错</title>
            <link>https://nitter.cz/dotey/status/1751454896593809666#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751454896593809666#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 03:59:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个案例也不错</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1751446948803178868#m">nitter.cz/xiaohuggg/status/1751446948803178868#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751442652388814956#m</id>
            <title>RT by @dotey: 兄弟们 这个厉害了...

StreamRAG：一个视频搜索和流媒体代理工具

他可以让你在2分钟内基于你的视频数据构建一个定制的个人GPT，然后你可以和你的视频进行对话。

它能够在数百小时的视频内容中找到你输符合你需求的相关视频时刻，并立即返回一个视频剪辑。

也就是说它能搜索视频内容的任意时刻。

它能够迅速浏览存储的大量视频资料，找到包含这些内容或主题的视频片段，并把这些片段展示给你，这样你就能直接观看到与你搜索内容相关的视频部分。

主要能力：

StreamRAG允许用户上传视频，创建视频集合，并在这些视频中进行搜索，以获得实时的视频回应或编辑。此外，用户还可以将他们的视频集合发布到ChatGPT商店，以便他人搜索和使用。

1、视频库创建： 上传多个视频以创建视频库或集合。

2、视频搜索与回应： 在这些视频中搜索，能立即获得实时的视频回应或编译结果。

3、GPTs发布： 在ChatGPT的GPT商店发布你的可搜索集合。

4、文本回答总结（RAG）： 接收总结性的文本回答。

5、视频关键洞察： 从特定视频中获得关键洞察，例如“第31集的要点”。

GitHub：https://github.com/video-db/StreamRAG
作者：@ashu_trv</title>
            <link>https://nitter.cz/xiaohuggg/status/1751442652388814956#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751442652388814956#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 03:10:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们 这个厉害了...<br />
<br />
StreamRAG：一个视频搜索和流媒体代理工具<br />
<br />
他可以让你在2分钟内基于你的视频数据构建一个定制的个人GPT，然后你可以和你的视频进行对话。<br />
<br />
它能够在数百小时的视频内容中找到你输符合你需求的相关视频时刻，并立即返回一个视频剪辑。<br />
<br />
也就是说它能搜索视频内容的任意时刻。<br />
<br />
它能够迅速浏览存储的大量视频资料，找到包含这些内容或主题的视频片段，并把这些片段展示给你，这样你就能直接观看到与你搜索内容相关的视频部分。<br />
<br />
主要能力：<br />
<br />
StreamRAG允许用户上传视频，创建视频集合，并在这些视频中进行搜索，以获得实时的视频回应或编辑。此外，用户还可以将他们的视频集合发布到ChatGPT商店，以便他人搜索和使用。<br />
<br />
1、视频库创建： 上传多个视频以创建视频库或集合。<br />
<br />
2、视频搜索与回应： 在这些视频中搜索，能立即获得实时的视频回应或编译结果。<br />
<br />
3、GPTs发布： 在ChatGPT的GPT商店发布你的可搜索集合。<br />
<br />
4、文本回答总结（RAG）： 接收总结性的文本回答。<br />
<br />
5、视频关键洞察： 从特定视频中获得关键洞察，例如“第31集的要点”。<br />
<br />
GitHub：<a href="https://github.com/video-db/StreamRAG">github.com/video-db/StreamRA…</a><br />
作者：<a href="https://nitter.cz/ashu_trv" title="Ashutosh">@ashu_trv</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTE0NDAzODE4Nzc5MTk3NDQvcHUvaW1nL0Y1eU9KUDhlU0FBbHppRm4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751443167784669417#m</id>
            <title>你们有希望伊大开源的吗？</title>
            <link>https://nitter.cz/dotey/status/1751443167784669417#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751443167784669417#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 03:12:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>你们有希望伊大开源的吗？</p>
<p><a href="https://nitter.cz/yihong0618/status/1751438381509476553#m">nitter.cz/yihong0618/status/1751438381509476553#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751436030903812569#m</id>
            <title>看到一个多模态的用法，给图片命名……
把识别出来的图片信息用向量保存下来，后续还可以用做图片搜索

有点杀鸡牛刀的感觉！</title>
            <link>https://nitter.cz/dotey/status/1751436030903812569#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751436030903812569#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 02:44:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看到一个多模态的用法，给图片命名……<br />
把识别出来的图片信息用向量保存下来，后续还可以用做图片搜索<br />
<br />
有点杀鸡牛刀的感觉！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U1WlBDTVdzQUFNUEtPLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U1WlFsUlhVQUF5c0MyLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751064514886594962#m</id>
            <title>RT by @dotey: 好文推荐：AI时代UX的高标准：Perplexity

Perplexity通过AI重塑了网络搜索的方式，获得了业界的关注和商业成功。

这篇文章通过以下几个方面来阐述Perplexity是如何成功应用 Jakob Nielson 在1994年提出的：“10个可用性启发式原则”来提升用户体验。

1、系统状态的可见性： 设计应始终让用户了解正在发生的事情，通过适当的反馈在合理的时间内。

2、使用用户的语言： 使用用户熟悉的词汇、短语和概念，而不是内部术语。

3、用户控制和自由度： 用户经常会误操作，他们需要一个明显的“紧急出口”来离开不想要的动作，而无需经历复杂的过程。

4、一致性和标准化： 用户不应该对不同的词语、情境或行为是否表示同一事物感到困惑。

5、错误预防： 良好的错误信息很重要，但最好的设计是事先预防问题的发生。

6、识别而非回忆： 尽量减少用户的记忆负担，使元素、动作和选项可见。

7、灵活性和使用效率： 隐藏对初学者不可见的快捷方式，可以加快专家用户的交互速度。

8、美观和简约设计： 界面中不应包含不相关或很少需要的信息。

9、帮助用户识别、诊断和从错误中恢复： 错误信息应该用简单的语言表达，准确指出问题，并提出建设性的解决方案。

10、帮助和文档： 最好的系统是不需要额外解释的，但有时可能需要提供文档帮助用户完成任务。

文章最后强调，Perplexity如何将这些原则成功地融入其产品设计中，使其成为AI产品中用户体验的典范。

对于2024年从事AI产品开发的人来说，可以从Perplexity的例子中学习，即怎样通过传统的用户体验原则来提升现代技术产品的易用性。

Perplexity展示了即便是最先进的技术，也需要以用户为中心，简化设计，并提供直观的用户界面来满足广泛的用户需求。

通过细致入微地考虑用户体验的各个方面，AI产品可以更好地被大众接受和使用。

图文完整内容：https://mttmr.com/2024/01/10/perplexitys-high-bar-for-ux-in-the-age-of-ai/</title>
            <link>https://nitter.cz/xiaohuggg/status/1751064514886594962#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751064514886594962#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 02:08:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>好文推荐：AI时代UX的高标准：Perplexity<br />
<br />
Perplexity通过AI重塑了网络搜索的方式，获得了业界的关注和商业成功。<br />
<br />
这篇文章通过以下几个方面来阐述Perplexity是如何成功应用 Jakob Nielson 在1994年提出的：“10个可用性启发式原则”来提升用户体验。<br />
<br />
1、系统状态的可见性： 设计应始终让用户了解正在发生的事情，通过适当的反馈在合理的时间内。<br />
<br />
2、使用用户的语言： 使用用户熟悉的词汇、短语和概念，而不是内部术语。<br />
<br />
3、用户控制和自由度： 用户经常会误操作，他们需要一个明显的“紧急出口”来离开不想要的动作，而无需经历复杂的过程。<br />
<br />
4、一致性和标准化： 用户不应该对不同的词语、情境或行为是否表示同一事物感到困惑。<br />
<br />
5、错误预防： 良好的错误信息很重要，但最好的设计是事先预防问题的发生。<br />
<br />
6、识别而非回忆： 尽量减少用户的记忆负担，使元素、动作和选项可见。<br />
<br />
7、灵活性和使用效率： 隐藏对初学者不可见的快捷方式，可以加快专家用户的交互速度。<br />
<br />
8、美观和简约设计： 界面中不应包含不相关或很少需要的信息。<br />
<br />
9、帮助用户识别、诊断和从错误中恢复： 错误信息应该用简单的语言表达，准确指出问题，并提出建设性的解决方案。<br />
<br />
10、帮助和文档： 最好的系统是不需要额外解释的，但有时可能需要提供文档帮助用户完成任务。<br />
<br />
文章最后强调，Perplexity如何将这些原则成功地融入其产品设计中，使其成为AI产品中用户体验的典范。<br />
<br />
对于2024年从事AI产品开发的人来说，可以从Perplexity的例子中学习，即怎样通过传统的用户体验原则来提升现代技术产品的易用性。<br />
<br />
Perplexity展示了即便是最先进的技术，也需要以用户为中心，简化设计，并提供直观的用户界面来满足广泛的用户需求。<br />
<br />
通过细致入微地考虑用户体验的各个方面，AI产品可以更好地被大众接受和使用。<br />
<br />
图文完整内容：<a href="https://mttmr.com/2024/01/10/perplexitys-high-bar-for-ux-in-the-age-of-ai/">mttmr.com/2024/01/10/perplex…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTA5MTAwMjE0OTQ2MDc4NzIvcHUvaW1nL0hiM2xxaDdQS2RnQmp6VWsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751403306973343808#m</id>
            <title>R to @dotey: 另外他们号称要开放源代码在：https://github.
com/MinorJerry/WebVoyager</title>
            <link>https://nitter.cz/dotey/status/1751403306973343808#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751403306973343808#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 00:34:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另外他们号称要开放源代码在：https://github.<br />
com/MinorJerry/WebVoyager</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751399058197946620#m</id>
            <title>推荐阅读：构建企业级 RAG 系统的高级指南 [译]

https://baoyu.io/translations/rag/mastering-rag-how-to-architect-an-enterprise-rag-system</title>
            <link>https://nitter.cz/dotey/status/1751399058197946620#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751399058197946620#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 00:17:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：构建企业级 RAG 系统的高级指南 [译]<br />
<br />
<a href="https://baoyu.io/translations/rag/mastering-rag-how-to-architect-an-enterprise-rag-system">baoyu.io/translations/rag/ma…</a></p>
<p><a href="https://nitter.cz/llama_index/status/1751291798843212111#m">nitter.cz/llama_index/status/1751291798843212111#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc1MTM5ODQ4MDAxNzUzNDk3Ni9FOXRJdjFPLT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751388813237141542#m</id>
            <title>来自浙江大学、腾讯 AI 实验室和西湖大学的新论文：《WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models》

这篇论文详细的讲解了如何借助 GPT-4V 这样的多模态模型，与开放网络中的网站交互，完成用户的各项指令。

如果你有做过类似的事情的话，会发现其实还是很有挑战的，因为让 AI 遵循指令操作网页，特定的网站相对容易，因为网页元素和路径比较固定，但是开放环境的话，每个网站都不一样，交互方式也千差万别，再加上浮动广告、弹出窗口和网页内容实时更新等等。

具体在实现层面，要先理解当前网页的内容，然后根据用户指令，在网页上选择正确的操作，根据操作的结果再继续下一步操作，直到完成任务。

举例来说，我们要去苹果官网查询，附近的哪个苹果店能买到特定型号的 iPad 保护壳（Smart Folio）。如果是人操作的话，要打开官网，找到配件页面，搜索关键字，找到配件查看详情，从详情页选择弹出位置搜索界面，输入邮编，找到最近的苹果店。但这系列操作对于 AI 来说还是很有挑战的。

那么 WebVoyager 是怎么来做的呢？

一、AI 如何浏览操作网页？

首先，WebVoyager 不是用的普通浏览器，而是基于 Selenium，这是一个自动化网页测试工具，可以方便的截图，可以自动化操作网页浏览器。

但是要让 GPT-4V 能识别和操作网页元素，还需要对网页上的可以操作的元素进行标记，WebVoyager 开发了一个叫 GPT-4-ACT4 的 JavaScript 工具，它能够根据网页元素的类型自动识别交互元素，并在这些元素上覆盖带有数字标记的黑色边框。

此外，GPT-4-ACT4 还能向智能体提供了一些辅助文本，如交互元素内的文字内容、元素类型以及 aria-label 属性中可能的注释文本，以简化观察过程。

如果你有些自动化测试代码的经验的话，可以知道我们可以用 JavaScript 或者 Python 脚本灵活的操作网页做任意操作，但是对于 AI 来说，如果让它直接写代码可能会出错率比较高，所以 WebVoyager 将常用的网页操作进行了归类，提供了有限的几种操作，例如：点击、输入、滚动、等待、返回上一页等等。

这样 AI 就不需要写代码，而是直接基于这几种操作给出清晰的指令，根据 AI 的指令，WebVoyager 将指令翻译成操作 Selenium 的代码操作网页。

这些为后面 GPT-4V 识别和提供后续指令提供了基础，否则 GPT-4V 无法清晰的描述出下一步要采取的操作。

二、如何让 AI 清晰的给出网页操作的指令？

然后就是 Prompt，Prompt 就是和 AI 交互的指令。要让 GPT-4V 帮助我们完成任务，光有截图还不够，还需要让 AI 能根据截图和任务，清晰的说明下一步如何操作，才能去相应的网站，借助外部工具进行交互。

WebVoyager 采用的是 ReAct 的 Prompt 框架，让 AI 能够根据目标任务和当前状态，推理出下一步的行动，每一步都采用：思考（Thought）、行动（Action）和观察（Observe）的结构，思考推理出行动，行动完成后观察行动后的结果，根据观察的结果进一步思考，思考推理出下一步的行动，这样一步步，直到完成任务。

举例来说要查询附近哪个苹果店可以买到特定型号的 iPad 保护壳，基于 ReAct 的框架是这样做的：

思考 1：我要找哪个苹果店可以买到特定型号的 iPad 保护壳，我需要打开苹果官网
行动 1：打开苹果官网
观察 1：苹果官网已经打开，上面有 Mac、iPhone、iPad、配件……导航

思考 2：iPad 保护壳属于配件，我已经打开配件页面
行动 2：点击打开配件页面
观察 2：配件页面打开，有导航，有推荐配件，有搜索框……

思考 3：我应该使用搜索框输入 Smart Folio 搜索
行动 3：在搜索框中输入 Smart Folio，点击搜索按钮
观察 3：列出了所有 Smart Folio 相关产品，第一项是 Smart Folio for iPad Pro 11，第二项是 Smart Folio for iPad……

思考 4：第一个搜索结果就是我想要的，我需要点击进入详情页面
行动 4：打开第一个 Smart Folio 详情页
观察 4：标题…介绍…图片…苹果商店……

思考 5：点击苹果商店链接查看有哪些商店
行动 5：点击苹果商店链接
观察 5：弹出对话框，有苹果商店列表 1,2,3,4…，有位置搜索框

思考 6：这些苹果商店离我太远，需要按照我的邮编寻找最近的
行动 6：输入邮编到位置输入框，搜索
观察 6：列出了新的苹果商店列表 1,2,3,4…

思考 7：第一个苹果商店就是离我最近的苹果店，任务完成

三、效果如何？

根据论文上的结果显示，WebVoyager 在任务成功率上达到了 55.7%。这个结果显然还达不到替代人类操作的效果，但是作为现阶段来说，已经算是个不错的成绩。未来随着 AI 能力的增强，成功率应该可以做到更高。

目前 WebVoyager 任务失败的原因主要有：

1. 导航失败
a) 如果智能体的搜索查询不够精确和明确，它会被海量无关搜索结果淹没。在这种情况下，智能体可能倾向于浏览这些不相关的结果，而不是纠正之前的错误；b) 当只有屏幕的一小部分可滚动时，智能体可能找不到正确的滚动区域，反复进行无效的滚动操作；c) 有时在网页中部，智能体难以决定是向上滚动还是向下滚动。
2. 视觉识别不足
a) 智能体无法正确理解一些不常见的模式，比如误将代表发音的字符或数学公式理解错了；b) 智能体没有识别出两次观察之间的微妙差异，误以为操作失败了；c) 由于元素之间位置接近，智能体有时会选错了操作对象。比如，它可能会将相邻的元素混淆，或者把日历上的数字误认为是数值标签。有时，文本信息对于区分密集的网页元素至关重要。
3. 幻觉
理解和遵循复杂的提示对智能体来说是一个重大挑战。此外，长时间的操作路径可能导致上下文过于冗长，从而妨碍了有效的指令执行。

总的来说，WebVoyager 是一个很不错的尝试，期待未来 AI 能真正的帮助我们操作网页，解放双手。

完整的论文翻译：https://baoyu.io/translations/ai-paper/2401.13919-webvoyager-building-an-end-to-end-web-agent-with-large-multimodal-models</title>
            <link>https://nitter.cz/dotey/status/1751388813237141542#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751388813237141542#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 23:36:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自浙江大学、腾讯 AI 实验室和西湖大学的新论文：《WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models》<br />
<br />
这篇论文详细的讲解了如何借助 GPT-4V 这样的多模态模型，与开放网络中的网站交互，完成用户的各项指令。<br />
<br />
如果你有做过类似的事情的话，会发现其实还是很有挑战的，因为让 AI 遵循指令操作网页，特定的网站相对容易，因为网页元素和路径比较固定，但是开放环境的话，每个网站都不一样，交互方式也千差万别，再加上浮动广告、弹出窗口和网页内容实时更新等等。<br />
<br />
具体在实现层面，要先理解当前网页的内容，然后根据用户指令，在网页上选择正确的操作，根据操作的结果再继续下一步操作，直到完成任务。<br />
<br />
举例来说，我们要去苹果官网查询，附近的哪个苹果店能买到特定型号的 iPad 保护壳（Smart Folio）。如果是人操作的话，要打开官网，找到配件页面，搜索关键字，找到配件查看详情，从详情页选择弹出位置搜索界面，输入邮编，找到最近的苹果店。但这系列操作对于 AI 来说还是很有挑战的。<br />
<br />
那么 WebVoyager 是怎么来做的呢？<br />
<br />
一、AI 如何浏览操作网页？<br />
<br />
首先，WebVoyager 不是用的普通浏览器，而是基于 Selenium，这是一个自动化网页测试工具，可以方便的截图，可以自动化操作网页浏览器。<br />
<br />
但是要让 GPT-4V 能识别和操作网页元素，还需要对网页上的可以操作的元素进行标记，WebVoyager 开发了一个叫 GPT-4-ACT4 的 JavaScript 工具，它能够根据网页元素的类型自动识别交互元素，并在这些元素上覆盖带有数字标记的黑色边框。<br />
<br />
此外，GPT-4-ACT4 还能向智能体提供了一些辅助文本，如交互元素内的文字内容、元素类型以及 aria-label 属性中可能的注释文本，以简化观察过程。<br />
<br />
如果你有些自动化测试代码的经验的话，可以知道我们可以用 JavaScript 或者 Python 脚本灵活的操作网页做任意操作，但是对于 AI 来说，如果让它直接写代码可能会出错率比较高，所以 WebVoyager 将常用的网页操作进行了归类，提供了有限的几种操作，例如：点击、输入、滚动、等待、返回上一页等等。<br />
<br />
这样 AI 就不需要写代码，而是直接基于这几种操作给出清晰的指令，根据 AI 的指令，WebVoyager 将指令翻译成操作 Selenium 的代码操作网页。<br />
<br />
这些为后面 GPT-4V 识别和提供后续指令提供了基础，否则 GPT-4V 无法清晰的描述出下一步要采取的操作。<br />
<br />
二、如何让 AI 清晰的给出网页操作的指令？<br />
<br />
然后就是 Prompt，Prompt 就是和 AI 交互的指令。要让 GPT-4V 帮助我们完成任务，光有截图还不够，还需要让 AI 能根据截图和任务，清晰的说明下一步如何操作，才能去相应的网站，借助外部工具进行交互。<br />
<br />
WebVoyager 采用的是 ReAct 的 Prompt 框架，让 AI 能够根据目标任务和当前状态，推理出下一步的行动，每一步都采用：思考（Thought）、行动（Action）和观察（Observe）的结构，思考推理出行动，行动完成后观察行动后的结果，根据观察的结果进一步思考，思考推理出下一步的行动，这样一步步，直到完成任务。<br />
<br />
举例来说要查询附近哪个苹果店可以买到特定型号的 iPad 保护壳，基于 ReAct 的框架是这样做的：<br />
<br />
思考 1：我要找哪个苹果店可以买到特定型号的 iPad 保护壳，我需要打开苹果官网<br />
行动 1：打开苹果官网<br />
观察 1：苹果官网已经打开，上面有 Mac、iPhone、iPad、配件……导航<br />
<br />
思考 2：iPad 保护壳属于配件，我已经打开配件页面<br />
行动 2：点击打开配件页面<br />
观察 2：配件页面打开，有导航，有推荐配件，有搜索框……<br />
<br />
思考 3：我应该使用搜索框输入 Smart Folio 搜索<br />
行动 3：在搜索框中输入 Smart Folio，点击搜索按钮<br />
观察 3：列出了所有 Smart Folio 相关产品，第一项是 Smart Folio for iPad Pro 11，第二项是 Smart Folio for iPad……<br />
<br />
思考 4：第一个搜索结果就是我想要的，我需要点击进入详情页面<br />
行动 4：打开第一个 Smart Folio 详情页<br />
观察 4：标题…介绍…图片…苹果商店……<br />
<br />
思考 5：点击苹果商店链接查看有哪些商店<br />
行动 5：点击苹果商店链接<br />
观察 5：弹出对话框，有苹果商店列表 1,2,3,4…，有位置搜索框<br />
<br />
思考 6：这些苹果商店离我太远，需要按照我的邮编寻找最近的<br />
行动 6：输入邮编到位置输入框，搜索<br />
观察 6：列出了新的苹果商店列表 1,2,3,4…<br />
<br />
思考 7：第一个苹果商店就是离我最近的苹果店，任务完成<br />
<br />
三、效果如何？<br />
<br />
根据论文上的结果显示，WebVoyager 在任务成功率上达到了 55.7%。这个结果显然还达不到替代人类操作的效果，但是作为现阶段来说，已经算是个不错的成绩。未来随着 AI 能力的增强，成功率应该可以做到更高。<br />
<br />
目前 WebVoyager 任务失败的原因主要有：<br />
<br />
1. 导航失败<br />
a) 如果智能体的搜索查询不够精确和明确，它会被海量无关搜索结果淹没。在这种情况下，智能体可能倾向于浏览这些不相关的结果，而不是纠正之前的错误；b) 当只有屏幕的一小部分可滚动时，智能体可能找不到正确的滚动区域，反复进行无效的滚动操作；c) 有时在网页中部，智能体难以决定是向上滚动还是向下滚动。<br />
2. 视觉识别不足<br />
a) 智能体无法正确理解一些不常见的模式，比如误将代表发音的字符或数学公式理解错了；b) 智能体没有识别出两次观察之间的微妙差异，误以为操作失败了；c) 由于元素之间位置接近，智能体有时会选错了操作对象。比如，它可能会将相邻的元素混淆，或者把日历上的数字误认为是数值标签。有时，文本信息对于区分密集的网页元素至关重要。<br />
3. 幻觉<br />
理解和遵循复杂的提示对智能体来说是一个重大挑战。此外，长时间的操作路径可能导致上下文过于冗长，从而妨碍了有效的指令执行。<br />
<br />
总的来说，WebVoyager 是一个很不错的尝试，期待未来 AI 能真正的帮助我们操作网页，解放双手。<br />
<br />
完整的论文翻译：<a href="https://baoyu.io/translations/ai-paper/2401.13919-webvoyager-building-an-end-to-end-web-agent-with-large-multimodal-models">baoyu.io/translations/ai-pap…</a></p>
<p><a href="https://nitter.cz/wyu_nd/status/1750743389287669940#m">nitter.cz/wyu_nd/status/1750743389287669940#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U0dVhsRVcwQUFfQnNXLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U0dWdpVVhJQUUxZkp1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U0dXNNTVcwQUFCTDVJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751310925020147848#m</id>
            <title>推荐下博主，分享质量非常高，值得关注</title>
            <link>https://nitter.cz/dotey/status/1751310925020147848#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751310925020147848#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 18:27:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐下博主，分享质量非常高，值得关注</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1751187683400105984#m</id>
            <title>RT by @dotey: 昨晚ChatGPT推出了通过在正常的聊天中@其他GPTs协同处理任务的能力，这个能力非常强大。

他让GPTs的可能性多了非常多，我没有被灰度到，Dan Shipper这个演示非常详细和完整。

他演示了如何将对话结果利用GPTs直接保存到Notion中，我顺便翻译了这个视频，如果你也没有被灰度到可以看看这个视频。</title>
            <link>https://nitter.cz/op7418/status/1751187683400105984#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1751187683400105984#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 10:17:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚ChatGPT推出了通过在正常的聊天中@其他GPTs协同处理任务的能力，这个能力非常强大。<br />
<br />
他让GPTs的可能性多了非常多，我没有被灰度到，Dan Shipper这个演示非常详细和完整。<br />
<br />
他演示了如何将对话结果利用GPTs直接保存到Notion中，我顺便翻译了这个视频，如果你也没有被灰度到可以看看这个视频。</p>
<p><a href="https://nitter.cz/danshipper/status/1751017376143794415#m">nitter.cz/danshipper/status/1751017376143794415#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTExODc1ODgxMDk3OTUzMjgvcHUvaW1nLzJGQkdTdjNtUnFSTjdJZEsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1751292333268893851#m</id>
            <title>RT by @dotey: 我刚才发现自己有了ChatGPT昨天发布的GPTs联动的功能，试了一下确实强大。

下面用一个例子看一下如何使用和具体能力，还有一个对简中用户比较重要的操作。

我自己看论文会先下载下来让ChatGPT总结，然后会用宝玉的科技文章翻译GPTs对总结的内容进行精细的翻译，以前完成这两步起码需要我切两个窗口，然后复制粘贴一次。

现在我只需要在总结完成后输入“@”找到需要的GPTs，输入要求就可以在一次对话中完成，甚至我还可以再搞一个自动发推的GPTs在ChatGPT直接将翻译内容发到推特上。

最后一个对简中用户不太友好的BUG：拉起GPTs选择的时候你输入的“@”符号需要在英文输入法下才能调用这个功能，中文输入法下面没办法拉起GPTs选择，OpenAI做产品是真的糙。</title>
            <link>https://nitter.cz/op7418/status/1751292333268893851#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1751292333268893851#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 17:13:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我刚才发现自己有了ChatGPT昨天发布的GPTs联动的功能，试了一下确实强大。<br />
<br />
下面用一个例子看一下如何使用和具体能力，还有一个对简中用户比较重要的操作。<br />
<br />
我自己看论文会先下载下来让ChatGPT总结，然后会用宝玉的科技文章翻译GPTs对总结的内容进行精细的翻译，以前完成这两步起码需要我切两个窗口，然后复制粘贴一次。<br />
<br />
现在我只需要在总结完成后输入“@”找到需要的GPTs，输入要求就可以在一次对话中完成，甚至我还可以再搞一个自动发推的GPTs在ChatGPT直接将翻译内容发到推特上。<br />
<br />
最后一个对简中用户不太友好的BUG：拉起GPTs选择的时候你输入的“@”符号需要在英文输入法下才能调用这个功能，中文输入法下面没办法拉起GPTs选择，OpenAI做产品是真的糙。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTEyOTIyNTcwODc2ODg3MDQvcHUvaW1nL0dFdHpDX2JJcWhsNmY3S3YuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751162830282248253#m</id>
            <title>R to @dotey: 来源：https://weibo.com/5648729445/NDpJjbh5G</title>
            <link>https://nitter.cz/dotey/status/1751162830282248253#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751162830282248253#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 08:38:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来源：<a href="https://weibo.com/5648729445/NDpJjbh5G">weibo.com/5648729445/NDpJjbh…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751162655908200838#m</id>
            <title>用无人机清理电线上的冰雪</title>
            <link>https://nitter.cz/dotey/status/1751162655908200838#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751162655908200838#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 08:38:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>用无人机清理电线上的冰雪</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTExNjI2MDk3ODc2OTUxMDQvcHUvaW1nL0tuT1VTRzRidkFDSm9rX0ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751160931055260028#m</id>
            <title>R to @dotey: AI工程师剪头发
https://www.youtube.com/watch?v=7zBrbdU_y0s</title>
            <link>https://nitter.cz/dotey/status/1751160931055260028#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751160931055260028#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 08:31:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI工程师剪头发<br />
<a href="https://www.youtube.com/watch?v=7zBrbdU_y0s">youtube.com/watch?v=7zBrbdU_…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0ODYyNDM3NzYxOTM3ODE3Ni9EQWI0ejVLQj9mb3JtYXQ9anBnJm5hbWU9ODAweDMyMF8x" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>