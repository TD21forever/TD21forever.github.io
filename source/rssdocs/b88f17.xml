<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744607895134622115#m</id>
            <title>《在AI优势的争夺中，中国和美国分别走出了各自的独特道路》

作者：Manya Koetse

北京曾设定在2030年成为全球AI领导者的目标，然而，这是在ChatGPT出现之前。

2023年，在中国社交媒体的在线讨论中，尤为引人关注的是ChatGPT的崛起。

美国OpenAI公司在2022年底官方发布的聊天机器人ChatGPT，直到2023年才因其极速增长在中国引起关注，此时，中国政府已经设定了在2030年成为全球AI领导者的目标。

在过去的十年里，AI在中国社会和数字文化中的重要性日益凸显。自从新冠病毒爆发以来，AI在学校、办公大楼和工厂中的应用更是快速推进。

AI面部识别技术在从公共安全到支付技术的各个领域都有所应用；智能眼镜和头盔使许多工人的工作变得更加容易；在购物中心、餐馆和银行，智能机器人已经成为常见的视线。

鹰与龙之间的科技竞赛的结果似乎毋庸置疑，但随后出现了ChatGPT的挑战。

中国花了数月时间来推出自己的类似产品，但这些产品在多方面都似乎落后于它们的西方对手。甚至科技部长也承认，中国的聊天机器人在与美国的竞争中遇到了困难，这让中国网民疑惑——在即将迈入AI纪元的前夜，中国是否能主导这个时代。

专家和博客作者对此有不同的看法：有人认为，中国科技公司聚焦于快速应用化而非长时间的研发，这就是中国没有率先推出类似ChatGPT产品的原因。还有人认为，由于中文的丰富性和复杂性，使得在中国训练语言模型更具挑战性。

然而，人们普遍认为，由于政治敏感性以及中国线上环境的严格管控和审查，中国开发类似ChatGPT的平台面临更大的挑战。

2023年夏，中国政府为生成式AI提出了法规，要求AI产生的内容，无论是图片或文本，都必须符合“社会主义核心价值观”，不能削弱国家权力，伤害民族团结，也不能传播虚假信息。同时还要求AI服务提供商必须防止用户过度依赖其服务。

至此，许多中国科技公司已经推出了自己的聊天机器人，但对于他们来说，在中国大陆接入ChatGPT——由于受到国家制定的许多限制而变得近乎不可能。比如试图向百度的Ernie聊天机器人询问关于中国领导层的一些简单问题，可能会导致对话立即终止。

在秋季，中国AI公司科大讯飞赴美上市后，由于其一款AI平板在帮助学生做作业时生成了含有对毛泽东的批评的文章，导致公司股票暴跌。这起事件给了科大讯飞的员工一记惩戒，也警告了互联网行业的其他参与者，他们的AI模型必须在中国严格管控的网络环境下，把所有操作都纳入规章制度之内。

然而，这些举动是否意味着中国的AI革命开始失去势头呢？并非如此。

不论是党派还是人民，不论是年轻人还是老年人，不论是城市还是农村，AI的进步都正在影响着全社会的方方面面。AI驱动的社交媒体、直播应用和电商平台在中国的数字经济中起着关键的作用。

借助新的AI技术，老板们现在可以购买他们自己的数字人，不分昼夜地为他们工作并销售商品，给小型中国企业家带来了前所未有的机会。这些深度假冒者在电商平台上的热度在2023年爆炸。

新的数字化员工不仅可以回答客户的问题，还可以感知他们是否在微笑，知道何时应该简短回答。一个这样的虚拟模型，被一家中国房地产开发商评为年度员工。

百度最近公布了其宏大的计划——通过帮助十万名中国农民通过虚拟直播销售他们的产品，从而推动农村经济发展。

与此同时，中国政府正在与大型科技公司合作，向各年龄段的中国人推广吸引人的共产党宣传。国家报纸《人民日报》引入了一位虚拟主播。

尽管ChatGPT取得了成功，但过去一年已经明确表明，可能已经是时候脱离对西方和中国之间所谓"AI竞赛"的关注，而更多的关注他们各自不同的方法了。

中国注重在经济增长和政治稳定之间取得平衡。由于中央政府对数字化发展的严格控制，使得关注点在于网络主权和集体支持，以及"国家和谐"和保留与党的权力。

相比之下，西方则更加关注那些倡导个人主义、个人自主、去中心化和全球化的AI应用，这自然引发了要如何在个人权利和广泛的社会利益之间取得平衡的辩论。

西方应用AI的方式并不一定适合中国市场，反之亦然。

ChatGPT的到来将鹰与龙的独特道路暴露在世人眼前，他们分别在不同的道路上展开自己的竞争。这并不意味着他们无法从对方那里学习东西——我们只需要超越竞争的思维，跳出地缘政治一点看这个问题。

https://www.theguardian.com/world/2024/jan/09/in-the-race-for-ai-supremacy-china-and-the-us-are-travelling-on-entirely-different-tracks</title>
            <link>https://nitter.cz/dotey/status/1744607895134622115#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744607895134622115#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 06:31:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《在AI优势的争夺中，中国和美国分别走出了各自的独特道路》<br />
<br />
作者：Manya Koetse<br />
<br />
北京曾设定在2030年成为全球AI领导者的目标，然而，这是在ChatGPT出现之前。<br />
<br />
2023年，在中国社交媒体的在线讨论中，尤为引人关注的是ChatGPT的崛起。<br />
<br />
美国OpenAI公司在2022年底官方发布的聊天机器人ChatGPT，直到2023年才因其极速增长在中国引起关注，此时，中国政府已经设定了在2030年成为全球AI领导者的目标。<br />
<br />
在过去的十年里，AI在中国社会和数字文化中的重要性日益凸显。自从新冠病毒爆发以来，AI在学校、办公大楼和工厂中的应用更是快速推进。<br />
<br />
AI面部识别技术在从公共安全到支付技术的各个领域都有所应用；智能眼镜和头盔使许多工人的工作变得更加容易；在购物中心、餐馆和银行，智能机器人已经成为常见的视线。<br />
<br />
鹰与龙之间的科技竞赛的结果似乎毋庸置疑，但随后出现了ChatGPT的挑战。<br />
<br />
中国花了数月时间来推出自己的类似产品，但这些产品在多方面都似乎落后于它们的西方对手。甚至科技部长也承认，中国的聊天机器人在与美国的竞争中遇到了困难，这让中国网民疑惑——在即将迈入AI纪元的前夜，中国是否能主导这个时代。<br />
<br />
专家和博客作者对此有不同的看法：有人认为，中国科技公司聚焦于快速应用化而非长时间的研发，这就是中国没有率先推出类似ChatGPT产品的原因。还有人认为，由于中文的丰富性和复杂性，使得在中国训练语言模型更具挑战性。<br />
<br />
然而，人们普遍认为，由于政治敏感性以及中国线上环境的严格管控和审查，中国开发类似ChatGPT的平台面临更大的挑战。<br />
<br />
2023年夏，中国政府为生成式AI提出了法规，要求AI产生的内容，无论是图片或文本，都必须符合“社会主义核心价值观”，不能削弱国家权力，伤害民族团结，也不能传播虚假信息。同时还要求AI服务提供商必须防止用户过度依赖其服务。<br />
<br />
至此，许多中国科技公司已经推出了自己的聊天机器人，但对于他们来说，在中国大陆接入ChatGPT——由于受到国家制定的许多限制而变得近乎不可能。比如试图向百度的Ernie聊天机器人询问关于中国领导层的一些简单问题，可能会导致对话立即终止。<br />
<br />
在秋季，中国AI公司科大讯飞赴美上市后，由于其一款AI平板在帮助学生做作业时生成了含有对毛泽东的批评的文章，导致公司股票暴跌。这起事件给了科大讯飞的员工一记惩戒，也警告了互联网行业的其他参与者，他们的AI模型必须在中国严格管控的网络环境下，把所有操作都纳入规章制度之内。<br />
<br />
然而，这些举动是否意味着中国的AI革命开始失去势头呢？并非如此。<br />
<br />
不论是党派还是人民，不论是年轻人还是老年人，不论是城市还是农村，AI的进步都正在影响着全社会的方方面面。AI驱动的社交媒体、直播应用和电商平台在中国的数字经济中起着关键的作用。<br />
<br />
借助新的AI技术，老板们现在可以购买他们自己的数字人，不分昼夜地为他们工作并销售商品，给小型中国企业家带来了前所未有的机会。这些深度假冒者在电商平台上的热度在2023年爆炸。<br />
<br />
新的数字化员工不仅可以回答客户的问题，还可以感知他们是否在微笑，知道何时应该简短回答。一个这样的虚拟模型，被一家中国房地产开发商评为年度员工。<br />
<br />
百度最近公布了其宏大的计划——通过帮助十万名中国农民通过虚拟直播销售他们的产品，从而推动农村经济发展。<br />
<br />
与此同时，中国政府正在与大型科技公司合作，向各年龄段的中国人推广吸引人的共产党宣传。国家报纸《人民日报》引入了一位虚拟主播。<br />
<br />
尽管ChatGPT取得了成功，但过去一年已经明确表明，可能已经是时候脱离对西方和中国之间所谓"AI竞赛"的关注，而更多的关注他们各自不同的方法了。<br />
<br />
中国注重在经济增长和政治稳定之间取得平衡。由于中央政府对数字化发展的严格控制，使得关注点在于网络主权和集体支持，以及"国家和谐"和保留与党的权力。<br />
<br />
相比之下，西方则更加关注那些倡导个人主义、个人自主、去中心化和全球化的AI应用，这自然引发了要如何在个人权利和广泛的社会利益之间取得平衡的辩论。<br />
<br />
西方应用AI的方式并不一定适合中国市场，反之亦然。<br />
<br />
ChatGPT的到来将鹰与龙的独特道路暴露在世人眼前，他们分别在不同的道路上展开自己的竞争。这并不意味着他们无法从对方那里学习东西——我们只需要超越竞争的思维，跳出地缘政治一点看这个问题。<br />
<br />
<a href="https://www.theguardian.com/world/2024/jan/09/in-the-race-for-ai-supremacy-china-and-the-us-are-travelling-on-entirely-different-tracks">theguardian.com/world/2024/j…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZV29MWVdnQUFJMzFHLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZV3FfMFdrQUE2OUxyLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744561781144490345#m</id>
            <title>Mixtral 8x7B 论文来了</title>
            <link>https://nitter.cz/dotey/status/1744561781144490345#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744561781144490345#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 03:28:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mixtral 8x7B 论文来了</p>
<p><a href="https://nitter.cz/dchaplot/status/1744547220983005478#m">nitter.cz/dchaplot/status/1744547220983005478#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744507505575674062#m</id>
            <title>R to @dotey: 哈哈</title>
            <link>https://nitter.cz/dotey/status/1744507505575674062#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744507505575674062#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 23:52:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈</p>
<p><a href="https://nitter.cz/aigclab/status/1744506555066933674#m">nitter.cz/aigclab/status/1744506555066933674#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744476630184013918#m</id>
            <title>OpenAI 刚发了一条长文回复纽约时报的指控，从4个方面进行了回应。

1.  表明对于新闻机构的积极合作态度，愿意共同探索新的合作机会
2. 从法律角度说明训练是合法的，对保持美国科技竞争力是有利的！
3. 原样输出训练内容是个技术上的 Bug
4. 《纽约时报》自己说话也没说全部，因为他们提供证据的数据早就在各大网站被引用，他们采集证据的方式是通过特定的提示词诱导才能偶然复现的。

即便如此，我们还是愿意和新闻结构继续合作，帮助提升新闻能力！

以下为原文翻译：

OpenAI 与新闻业的互动

我们致力于支持新闻行业，与新闻机构建立合作关系，并认为《纽约时报》提起的诉讼缺乏法律依据。

我们旨在开发 AI 工具，帮助人们解决那些难以触及的问题。全球各地的人们已经在利用我们的技术，以提升他们的日常生活质量。目前，有数以百万计的开发者和超过 92% 的《财富》500 强企业在使用我们的产品。

尽管我们对《纽约时报》诉讼中的指控持不同意见，但我们认为这是一个阐明我们业务、意图和技术开发方式的好机会。我们的立场可以概括为以下四点：

1. 我们正在与新闻机构合作，共同探索新的合作机会。
2. 使用 AI 进行数据训练在法律上属于合理使用，但我们提供选择退出的选项，因为这是合乎道德的做法。
3、 技术上的“信息原样输出（Regurgitation）”现象较为罕见，我们正致力于将其完全消除。
4. 《纽约时报》并没有呈现事情的全部面貌。

1. 我们正在与新闻机构合作，共同探索新的合作机会

在我们的技术设计过程中，我们致力于支持新闻机构。我们已经与众多新闻机构以及行业领先组织如新闻/媒体联盟进行了会谈，共同探索合作机遇，讨论他们的关切，并提供相应的解决方案。我们的目标是学习、普及知识、倾听反馈，并根据这些反馈做出调整。

我们旨在支持一个健康的新闻生态系统，成为一个值得信赖的合作伙伴，创造互利共赢的机遇。为此，我们已经与多家新闻机构建立了合作关系，以实现以下目标：

部署我们的产品以辅助记者和编辑，帮助他们处理如分析大量公共记录和翻译报道等耗时任务。
通过在额外的历史性、非公开内容上进行训练，增进我们的 AI 模型对世界的了解。
在 ChatGPT 中展示带有归属的实时内容，为新闻出版商提供与读者建立联系的新途径。
我们与美联社、阿克塞尔·施普林格、美国新闻项目和NYU的初步合作，展现了我们的合作方法和愿景。

我们的这些早期合作伙伴关系，不仅有助于新闻行业的发展，也展示了我们在技术创新方面的承诺，以及对支持新闻自由和信息传播的坚定立场。

2. 虽然利用公共互联网材料训练 AI 模型属于合理使用，但我们提供退出机制，因为这是负责任的做法

根据长期而广泛接受的先例，利用公开可获得的互联网材料来训练人工智能模型被视为合理使用。我们认为这个原则对创作者公平，对创新者是必需的，同时对美国的竞争力至关重要。

将 AI 模型的训练视为合理使用的原则得到了广泛的支持，包括学术界、图书馆协会、民间社会团体、初创企业、领先的美国公司、创作者、作者等，他们最近向美国版权办公室提交了意见。其他地区和国家，如欧洲联盟、日本、新加坡 和以色列也制定了允许在版权内容上训练模型的法律，这对 AI 的创新、发展和投资大有裨益。

尽管如此，法律权利对我们来说并不如做一个良好公民那样重要。我们在 AI 行业中率先提供了一个简单的退出流程，供出版商选择（例如《纽约时报》在 2023 年 8 月选择使用），以防止我们的工具访问他们的网站。

3. 我们正致力于消除“信息原样输出（Regurgitation）”这一罕见的错误

注："Regurgitation" 指的是 AI 模型在生成输出时重复其在训练数据中已经接触过的信息或内容。这通常被视为一种错误或失败，因为理想中的 AI 应该能够产生新颖的、基于理解和推理的回答，而不是简单地复制和重复它在训练过程中所遇到的具体信息。这种现象在模型训练过程中遇到重复或过度代表的数据时更为常见。

我们设计并训练了模型，目的是让它们学习概念，进而能够应用这些概念解决新问题。

记忆问题是学习过程中较为罕见的一个弊端，我们正在努力改进。这个问题在特定内容在训练数据中重复出现时尤为明显，例如同一内容在多个公共网站上出现。因此，我们采取了措施来减少不经意的记忆，并防止模型输出中的内容重复。我们也期望用户能负责任地使用我们的技术；故意引导模型重复输出信息是不恰当的，这违反了我们的使用条款。

就像人类通过广泛学习来解决新问题一样，我们希望我们的 AI 模型能观察到世界各地的信息，包括来自不同语言、文化和行业的知识。由于模型是基于人类知识的大量集合进行学习，任何一个特定领域，比如新闻，都只是训练数据中的一小部分。同样，任何单一的数据来源，如《纽约时报》，对于模型的整体学习目标来说也不是特别关键。

4. 纽约时报并未全面报道真相

我们与纽约时报的对话在 12 月 19 日的最后一次沟通中似乎还在顺利进行。谈判主要围绕 ChatGPT 实时展示新闻内容并标明来源的高价值合作，纽约时报将通过这种新方式与现有及潜在读者建立联系，而我们的用户也能够接触到他们的报道。我们曾向纽约时报明确表示，他们的内容像其他单一来源一样，并没有对我们现有模型的训练产生重大影响，对未来的训练也不会有显著贡献。然而，我们在阅读纽约时报的报道时才得知他们于 12 月 27 日对我们提起诉讼，这让我们感到意外和失望。

在此期间，纽约时报曾提到发现一些内容被重复引用，但他们一直拒绝提供任何具体案例，尽管我们已承诺调查并解决任何相关问题。我们一直严肃对待这一问题，例如在 7 月份，我们得知 ChatGPT 功能可能意外复制实时新闻内容后，我们立即关闭了该功能。

有趣的是，纽约时报所指的重复内容似乎来自多年前的文章，这些文章已在多个 第三方-网站 上广为流传。看来他们故意设置特定的提示语，常包含文章的长篇摘录，以引诱我们的模型进行复述。即便在使用这样的提示语下，我们的模型通常不会如纽约时报所言那样反应，这表明他们可能是指导模型复述或从众多尝试中挑选示例。

不管他们怎么说，这种误用并非典型或被允许的用户行为，也不能代替纽约时报的内容。无论如何，我们正在不断提高系统对防范敌意攻击和复述训练数据的抵抗力，在最新的模型中已经取得了显著进展。

我们认为纽约时报的诉讼毫无依据。尽管如此，我们仍期待与纽约时报建立建设性的合作关系，并尊重其拥有超过 60 年历史的报道，其中包括报道第一个运行中的神经网络和捍卫第一修正案自由的长期传统。

我们期待与新闻机构继续合作，帮助他们利用 AI 的变革潜力，提升制作优质新闻的能力。

来源：https://openai.com/blog/openai-and-journalism</title>
            <link>https://nitter.cz/dotey/status/1744476630184013918#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744476630184013918#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 21:50:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 刚发了一条长文回复纽约时报的指控，从4个方面进行了回应。<br />
<br />
1.  表明对于新闻机构的积极合作态度，愿意共同探索新的合作机会<br />
2. 从法律角度说明训练是合法的，对保持美国科技竞争力是有利的！<br />
3. 原样输出训练内容是个技术上的 Bug<br />
4. 《纽约时报》自己说话也没说全部，因为他们提供证据的数据早就在各大网站被引用，他们采集证据的方式是通过特定的提示词诱导才能偶然复现的。<br />
<br />
即便如此，我们还是愿意和新闻结构继续合作，帮助提升新闻能力！<br />
<br />
以下为原文翻译：<br />
<br />
OpenAI 与新闻业的互动<br />
<br />
我们致力于支持新闻行业，与新闻机构建立合作关系，并认为《纽约时报》提起的诉讼缺乏法律依据。<br />
<br />
我们旨在开发 AI 工具，帮助人们解决那些难以触及的问题。全球各地的人们已经在利用我们的技术，以提升他们的日常生活质量。目前，有数以百万计的开发者和超过 92% 的《财富》500 强企业在使用我们的产品。<br />
<br />
尽管我们对《纽约时报》诉讼中的指控持不同意见，但我们认为这是一个阐明我们业务、意图和技术开发方式的好机会。我们的立场可以概括为以下四点：<br />
<br />
1. 我们正在与新闻机构合作，共同探索新的合作机会。<br />
2. 使用 AI 进行数据训练在法律上属于合理使用，但我们提供选择退出的选项，因为这是合乎道德的做法。<br />
3、 技术上的“信息原样输出（Regurgitation）”现象较为罕见，我们正致力于将其完全消除。<br />
4. 《纽约时报》并没有呈现事情的全部面貌。<br />
<br />
1. 我们正在与新闻机构合作，共同探索新的合作机会<br />
<br />
在我们的技术设计过程中，我们致力于支持新闻机构。我们已经与众多新闻机构以及行业领先组织如新闻/媒体联盟进行了会谈，共同探索合作机遇，讨论他们的关切，并提供相应的解决方案。我们的目标是学习、普及知识、倾听反馈，并根据这些反馈做出调整。<br />
<br />
我们旨在支持一个健康的新闻生态系统，成为一个值得信赖的合作伙伴，创造互利共赢的机遇。为此，我们已经与多家新闻机构建立了合作关系，以实现以下目标：<br />
<br />
部署我们的产品以辅助记者和编辑，帮助他们处理如分析大量公共记录和翻译报道等耗时任务。<br />
通过在额外的历史性、非公开内容上进行训练，增进我们的 AI 模型对世界的了解。<br />
在 ChatGPT 中展示带有归属的实时内容，为新闻出版商提供与读者建立联系的新途径。<br />
我们与美联社、阿克塞尔·施普林格、美国新闻项目和NYU的初步合作，展现了我们的合作方法和愿景。<br />
<br />
我们的这些早期合作伙伴关系，不仅有助于新闻行业的发展，也展示了我们在技术创新方面的承诺，以及对支持新闻自由和信息传播的坚定立场。<br />
<br />
2. 虽然利用公共互联网材料训练 AI 模型属于合理使用，但我们提供退出机制，因为这是负责任的做法<br />
<br />
根据长期而广泛接受的先例，利用公开可获得的互联网材料来训练人工智能模型被视为合理使用。我们认为这个原则对创作者公平，对创新者是必需的，同时对美国的竞争力至关重要。<br />
<br />
将 AI 模型的训练视为合理使用的原则得到了广泛的支持，包括学术界、图书馆协会、民间社会团体、初创企业、领先的美国公司、创作者、作者等，他们最近向美国版权办公室提交了意见。其他地区和国家，如欧洲联盟、日本、新加坡 和以色列也制定了允许在版权内容上训练模型的法律，这对 AI 的创新、发展和投资大有裨益。<br />
<br />
尽管如此，法律权利对我们来说并不如做一个良好公民那样重要。我们在 AI 行业中率先提供了一个简单的退出流程，供出版商选择（例如《纽约时报》在 2023 年 8 月选择使用），以防止我们的工具访问他们的网站。<br />
<br />
3. 我们正致力于消除“信息原样输出（Regurgitation）”这一罕见的错误<br />
<br />
注："Regurgitation" 指的是 AI 模型在生成输出时重复其在训练数据中已经接触过的信息或内容。这通常被视为一种错误或失败，因为理想中的 AI 应该能够产生新颖的、基于理解和推理的回答，而不是简单地复制和重复它在训练过程中所遇到的具体信息。这种现象在模型训练过程中遇到重复或过度代表的数据时更为常见。<br />
<br />
我们设计并训练了模型，目的是让它们学习概念，进而能够应用这些概念解决新问题。<br />
<br />
记忆问题是学习过程中较为罕见的一个弊端，我们正在努力改进。这个问题在特定内容在训练数据中重复出现时尤为明显，例如同一内容在多个公共网站上出现。因此，我们采取了措施来减少不经意的记忆，并防止模型输出中的内容重复。我们也期望用户能负责任地使用我们的技术；故意引导模型重复输出信息是不恰当的，这违反了我们的使用条款。<br />
<br />
就像人类通过广泛学习来解决新问题一样，我们希望我们的 AI 模型能观察到世界各地的信息，包括来自不同语言、文化和行业的知识。由于模型是基于人类知识的大量集合进行学习，任何一个特定领域，比如新闻，都只是训练数据中的一小部分。同样，任何单一的数据来源，如《纽约时报》，对于模型的整体学习目标来说也不是特别关键。<br />
<br />
4. 纽约时报并未全面报道真相<br />
<br />
我们与纽约时报的对话在 12 月 19 日的最后一次沟通中似乎还在顺利进行。谈判主要围绕 ChatGPT 实时展示新闻内容并标明来源的高价值合作，纽约时报将通过这种新方式与现有及潜在读者建立联系，而我们的用户也能够接触到他们的报道。我们曾向纽约时报明确表示，他们的内容像其他单一来源一样，并没有对我们现有模型的训练产生重大影响，对未来的训练也不会有显著贡献。然而，我们在阅读纽约时报的报道时才得知他们于 12 月 27 日对我们提起诉讼，这让我们感到意外和失望。<br />
<br />
在此期间，纽约时报曾提到发现一些内容被重复引用，但他们一直拒绝提供任何具体案例，尽管我们已承诺调查并解决任何相关问题。我们一直严肃对待这一问题，例如在 7 月份，我们得知 ChatGPT 功能可能意外复制实时新闻内容后，我们立即关闭了该功能。<br />
<br />
有趣的是，纽约时报所指的重复内容似乎来自多年前的文章，这些文章已在多个 第三方-网站 上广为流传。看来他们故意设置特定的提示语，常包含文章的长篇摘录，以引诱我们的模型进行复述。即便在使用这样的提示语下，我们的模型通常不会如纽约时报所言那样反应，这表明他们可能是指导模型复述或从众多尝试中挑选示例。<br />
<br />
不管他们怎么说，这种误用并非典型或被允许的用户行为，也不能代替纽约时报的内容。无论如何，我们正在不断提高系统对防范敌意攻击和复述训练数据的抵抗力，在最新的模型中已经取得了显著进展。<br />
<br />
我们认为纽约时报的诉讼毫无依据。尽管如此，我们仍期待与纽约时报建立建设性的合作关系，并尊重其拥有超过 60 年历史的报道，其中包括报道第一个运行中的神经网络和捍卫第一修正案自由的长期传统。<br />
<br />
我们期待与新闻机构继续合作，帮助他们利用 AI 的变革潜力，提升制作优质新闻的能力。<br />
<br />
来源：<a href="https://openai.com/blog/openai-and-journalism">openai.com/blog/openai-and-j…</a></p>
<p><a href="https://nitter.cz/OpenAI/status/1744419710635229424#m">nitter.cz/OpenAI/status/1744419710635229424#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXZ09ZOFdrQUFxbDBSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744465568684507562#m</id>
            <title>玩的真开心！</title>
            <link>https://nitter.cz/dotey/status/1744465568684507562#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744465568684507562#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 21:06:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>玩的真开心！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ0NjU0ODk3MDE1NzI2MDgvcHUvaW1nL190N3dnSkRWU1RMaGY4ZGcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744464311311814664#m</id>
            <title>Greg 说明的需要AGI的一个理由，他的妻子患了一种遗传性疾病 hEDS，涉及多个医学科目，但现在的医生都只精通自己所在领域，这导致像他妻子这样的问题很难被全局分析和治疗，而未来的 AGI 应该可以同时在医学领域兼顾精度和广度。

希望他妻子早日康复！

原文翻译参考：

***

我们为何需要有益的通用人工智能 (AGI)：

我的妻子曾经历了五年的身体痛苦，包括从人行道台阶摔断脚、剧烈的偏头痛、持续的疲劳、关节疼痛和不稳定等多种症状。最近，她被确诊患有一种遗传性疾病——多发性易碎性皮肤综合征 (Hypermobile Ehlers-Danlos Syndrome, hEDS)。

由于医疗体系通常按专业划分，而 hEDS 影响到她身体的各个系统，包括骨科、心脏科、神经科、胃肠科、皮肤科等，我们花了五年时间看了比她之前一生中还要多的医生和专家。大多数医生只关注自己专业范围内的问题。幸运的是，她的过敏科医生（令人意外！）在全面观察和听取她所有症状后，终于拼凑出了病情的全貌。

随着人类医学的发展，医生的专业深度不断增强，但这往往以牺牲广度为代价。我们急需能够同时提供深度和广度医疗服务的更好工具。如果构建得当，AGI 便承载着这样的希望——将可靠、个性化、负担得起的医疗服务置于掌中，仿佛拥有一个由今天各专业领域顶尖医生组成的团队，共同协作，保障你的健康（无需在他们之间传递表格）。

虽然我们在技术开发和学习如何在医学等高风险领域有效利用这些技术，并确保有适当的专业人类监督方面还有很长的路要走，但这一前景正变得越来越明朗。只要技术开发者、医疗服务提供者、政府和社会共同深思熟虑，我们就有望为我们所有家庭的每一个成员（包括我们的宠物）提供更优质的医疗服务。</title>
            <link>https://nitter.cz/dotey/status/1744464311311814664#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744464311311814664#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 21:01:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Greg 说明的需要AGI的一个理由，他的妻子患了一种遗传性疾病 hEDS，涉及多个医学科目，但现在的医生都只精通自己所在领域，这导致像他妻子这样的问题很难被全局分析和治疗，而未来的 AGI 应该可以同时在医学领域兼顾精度和广度。<br />
<br />
希望他妻子早日康复！<br />
<br />
原文翻译参考：<br />
<br />
***<br />
<br />
我们为何需要有益的通用人工智能 (AGI)：<br />
<br />
我的妻子曾经历了五年的身体痛苦，包括从人行道台阶摔断脚、剧烈的偏头痛、持续的疲劳、关节疼痛和不稳定等多种症状。最近，她被确诊患有一种遗传性疾病——多发性易碎性皮肤综合征 (Hypermobile Ehlers-Danlos Syndrome, hEDS)。<br />
<br />
由于医疗体系通常按专业划分，而 hEDS 影响到她身体的各个系统，包括骨科、心脏科、神经科、胃肠科、皮肤科等，我们花了五年时间看了比她之前一生中还要多的医生和专家。大多数医生只关注自己专业范围内的问题。幸运的是，她的过敏科医生（令人意外！）在全面观察和听取她所有症状后，终于拼凑出了病情的全貌。<br />
<br />
随着人类医学的发展，医生的专业深度不断增强，但这往往以牺牲广度为代价。我们急需能够同时提供深度和广度医疗服务的更好工具。如果构建得当，AGI 便承载着这样的希望——将可靠、个性化、负担得起的医疗服务置于掌中，仿佛拥有一个由今天各专业领域顶尖医生组成的团队，共同协作，保障你的健康（无需在他们之间传递表格）。<br />
<br />
虽然我们在技术开发和学习如何在医学等高风险领域有效利用这些技术，并确保有适当的专业人类监督方面还有很长的路要走，但这一前景正变得越来越明朗。只要技术开发者、医疗服务提供者、政府和社会共同深思熟虑，我们就有望为我们所有家庭的每一个成员（包括我们的宠物）提供更优质的医疗服务。</p>
<p><a href="https://nitter.cz/gdb/status/1744446603962765669#m">nitter.cz/gdb/status/1744446603962765669#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744461848978612699#m</id>
            <title>AMD 面向 AI 时代的 PC 推出 Ryzen 8000G 处理器

在 2024年的 CES 展会上，AMD 宣布了其客户端 CPU 的多项更新。AI 成为了 2024年的核心主题，AMD 同样紧跟这一趋势。AMD Ryzen 8040 系列在一个月前首次发布后，现又迎来进一步提升。除此之外，AMD 还推出了新款主流桌面 Ryzen CPU 和一些更经济的选项。

AMD Ryzen 8000G 处理器的发布标志着 AI PC 时代的来临。AMD Ryzen 8040 系列的一个亮点是，它融合了 AMD Zen 4 核心、RDNA 3 图形技术以及全新的 XDNA 神经处理单元（NPU），强化了本地 AI 推断能力。

2024年，AMD 对 Ryzen 8040 系列进行了更新，但这一 AI 技术并不仅限于此系列。AMD 在 2024年初还推出了新款 Ryzen 7 和 Ryzen 5 处理器，部分型号内置了 NPU。值得注意的是，AMD Ryzen 7 8700G 和 AMD Ryzen 5 8600G 都配备了 Ryzen AI NPU，而新的 Ryzen 5 8500G 和 Ryzen 3 8300G 则未配备 NPU。AMD 在其顶级 Ryzen 型号中对这一功能的划分有待优化。例如，若所有 Ryzen 7 和 Ryzen 5 型号都配备 NPU，而 Ryzen 3 则不配备，将更易于消费者理解。目前，消费者可能因为 Ryzen 8600G 的数据和相同核心数量而购买 Ryzen 8500G，却因缺乏新 NPU 而感到失望。

AMD 还发布了 Ryzen 8000G 处理器的系列列表。除了新的 Ryzen 8000G SKU，AMD 还推出了 Ryzen 7 5700X3D（拥有 100MB 缓存）和一些较低端的 Ryzen 7 5700、Ryzen 5 5600GT 以及 Ryzen 5 5500GT 产品，这些产品适用于升级 AM4 平台的用户。

在 2024年的 Ryzen 5000 系列更新中，AMD 展示了其桌面平台的全新构成。尽管 AMD 推出了 Ryzen AI SKU，但在众多型号中只有两种型号配备了 AI 功能。如果购买最高端产品，将不包含 Ryzen AI。

AMD 透露，新部件的建议售价如下：

- AMD Ryzen 7 8700G: 329 美元
- AMD Ryzen 5 8600G: 229 美元
- AMD Ryzen 5 8500G: 179 美元

总结来说，AMD 正在积极参与 AI PC 时代的发展，但前路漫长。我们预计，未来将有更多配备 NPU 的产品问世。微软正通过其生态系统大力推进 AI PC，这不仅是技术进步，也是一种淘汰老旧电脑的方式，正如它在 Windows 11 发布时所做的那样。尽管 AMD 当前已推出一些搭载 NPU 的产品，我们认为，未来一年内 NPU 的平均性能将远超现在，并且其发展速度将超过传统的 x86 计算性能。

此外，我们认为，这些带 NPU 的处理器在服务器主板上的应用可能更加有趣。如果得到支持，内置的 NPU 可能会减少服务器对低端 AI 推断加速器的依赖，例如 NVIDIA T4/L4。这一点在我们最近评测的 ASRock Rack AM5D4ID-2T BCM 服务器中已有所体现。

来源：https://www.servethehome.com/amd-ryzen-8000g-processors-launched-for-the-ai-pc-era/</title>
            <link>https://nitter.cz/dotey/status/1744461848978612699#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744461848978612699#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 20:51:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AMD 面向 AI 时代的 PC 推出 Ryzen 8000G 处理器<br />
<br />
在 2024年的 CES 展会上，AMD 宣布了其客户端 CPU 的多项更新。AI 成为了 2024年的核心主题，AMD 同样紧跟这一趋势。AMD Ryzen 8040 系列在一个月前首次发布后，现又迎来进一步提升。除此之外，AMD 还推出了新款主流桌面 Ryzen CPU 和一些更经济的选项。<br />
<br />
AMD Ryzen 8000G 处理器的发布标志着 AI PC 时代的来临。AMD Ryzen 8040 系列的一个亮点是，它融合了 AMD Zen 4 核心、RDNA 3 图形技术以及全新的 XDNA 神经处理单元（NPU），强化了本地 AI 推断能力。<br />
<br />
2024年，AMD 对 Ryzen 8040 系列进行了更新，但这一 AI 技术并不仅限于此系列。AMD 在 2024年初还推出了新款 Ryzen 7 和 Ryzen 5 处理器，部分型号内置了 NPU。值得注意的是，AMD Ryzen 7 8700G 和 AMD Ryzen 5 8600G 都配备了 Ryzen AI NPU，而新的 Ryzen 5 8500G 和 Ryzen 3 8300G 则未配备 NPU。AMD 在其顶级 Ryzen 型号中对这一功能的划分有待优化。例如，若所有 Ryzen 7 和 Ryzen 5 型号都配备 NPU，而 Ryzen 3 则不配备，将更易于消费者理解。目前，消费者可能因为 Ryzen 8600G 的数据和相同核心数量而购买 Ryzen 8500G，却因缺乏新 NPU 而感到失望。<br />
<br />
AMD 还发布了 Ryzen 8000G 处理器的系列列表。除了新的 Ryzen 8000G SKU，AMD 还推出了 Ryzen 7 5700X3D（拥有 100MB 缓存）和一些较低端的 Ryzen 7 5700、Ryzen 5 5600GT 以及 Ryzen 5 5500GT 产品，这些产品适用于升级 AM4 平台的用户。<br />
<br />
在 2024年的 Ryzen 5000 系列更新中，AMD 展示了其桌面平台的全新构成。尽管 AMD 推出了 Ryzen AI SKU，但在众多型号中只有两种型号配备了 AI 功能。如果购买最高端产品，将不包含 Ryzen AI。<br />
<br />
AMD 透露，新部件的建议售价如下：<br />
<br />
- AMD Ryzen 7 8700G: 329 美元<br />
- AMD Ryzen 5 8600G: 229 美元<br />
- AMD Ryzen 5 8500G: 179 美元<br />
<br />
总结来说，AMD 正在积极参与 AI PC 时代的发展，但前路漫长。我们预计，未来将有更多配备 NPU 的产品问世。微软正通过其生态系统大力推进 AI PC，这不仅是技术进步，也是一种淘汰老旧电脑的方式，正如它在 Windows 11 发布时所做的那样。尽管 AMD 当前已推出一些搭载 NPU 的产品，我们认为，未来一年内 NPU 的平均性能将远超现在，并且其发展速度将超过传统的 x86 计算性能。<br />
<br />
此外，我们认为，这些带 NPU 的处理器在服务器主板上的应用可能更加有趣。如果得到支持，内置的 NPU 可能会减少服务器对低端 AI 推断加速器的依赖，例如 NVIDIA T4/L4。这一点在我们最近评测的 ASRock Rack AM5D4ID-2T BCM 服务器中已有所体现。<br />
<br />
来源：<a href="https://www.servethehome.com/amd-ryzen-8000g-processors-launched-for-the-ai-pc-era/">servethehome.com/amd-ryzen-8…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXU3Njd1dBQUFwc0hBLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXU3QzVVhNQUFud01fLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXU3ZyWFhVQUF1Rm9GLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RXU3hPOVdRQUF4VHp5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/fi56622380/status/1744248742365319385#m</id>
            <title>RT by @dotey: MoE模型可以只加载部分模型来优化memory usage，比如8X7B的Mistral可以跑在16G显存+11GB内存上

7B模型量化后是4GB，我估计是4个 7B的MoE模型跑在显存上，3个7B 的MoE模型在内存上待命，另外还有1个MoE模型在SSD待命

不过平移到手机，显存和内存共用，意味着还是27GB内存

https://x.com/dotey/status/1744237264807350703?s=20</title>
            <link>https://nitter.cz/fi56622380/status/1744248742365319385#m</link>
            <guid isPermaLink="false">https://nitter.cz/fi56622380/status/1744248742365319385#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 06:44:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MoE模型可以只加载部分模型来优化memory usage，比如8X7B的Mistral可以跑在16G显存+11GB内存上<br />
<br />
7B模型量化后是4GB，我估计是4个 7B的MoE模型跑在显存上，3个7B 的MoE模型在内存上待命，另外还有1个MoE模型在SSD待命<br />
<br />
不过平移到手机，显存和内存共用，意味着还是27GB内存<br />
<br />
<a href="https://x.com/dotey/status/1744237264807350703?s=20">x.com/dotey/status/174423726…</a></p>
<p><a href="https://nitter.cz/dotey/status/1744237264807350703#m">nitter.cz/dotey/status/1744237264807350703#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744237264807350703#m</id>
            <title>再推荐一下，现在如果你有 16 GB 显存 和 11 GB 内存的电脑，就可以在本机运行目前最强的开源混合专家模型 Mixtral-8x7B 了，或者你也可以在 Google Colab上运行。

主要的优化是不一次加载所有 8 个专家模型，而是按需加载。

Jupiter Notebook：https://github.com/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb

项目地址：https://github.com/dvmazur/mixtral-offloading/tree/master?tab=readme-ov-file</title>
            <link>https://nitter.cz/dotey/status/1744237264807350703#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744237264807350703#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 05:59:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>再推荐一下，现在如果你有 16 GB 显存 和 11 GB 内存的电脑，就可以在本机运行目前最强的开源混合专家模型 Mixtral-8x7B 了，或者你也可以在 Google Colab上运行。<br />
<br />
主要的优化是不一次加载所有 8 个专家模型，而是按需加载。<br />
<br />
Jupiter Notebook：<a href="https://github.com/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb">github.com/dvmazur/mixtral-o…</a><br />
<br />
项目地址：<a href="https://github.com/dvmazur/mixtral-offloading/tree/master?tab=readme-ov-file">github.com/dvmazur/mixtral-o…</a></p>
<p><a href="https://nitter.cz/dotey/status/1740858628419059889#m">nitter.cz/dotey/status/1740858628419059889#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744232717582037098#m</id>
            <title>推荐阅读：《Meta 如何打造 Threads 的基础设施》

2023 年 7 月 5 日，Meta 推出了的 Twitter 的竞品 Threads，Threads 在前五天内便创下了惊人的记录，吸引了超过 1 亿用户注册。

数百万用户的流畅注册体验得益于 Meta 超过十年的基础设施和产品开发经验。这并非是专为 Threads 设计的基础设施，而是 Meta 多年来为众多产品所建立。它早已为规模扩张、性能增强和可靠性提升做好了准备，在 Threads 增长速度超乎预料的情况下，它的表现甚至超出了我们的期待。

支撑 Threads 运行需要庞大的基础设施。其中两个关键组件：ZippyDB——Meta的分布式 key-value 数据存储系统，以及 Async——我们的异步无服务计算平台。

原文：https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/
译文：https://baoyu.io/translations/meta/how-meta-built-the-infrastructure-for-threads</title>
            <link>https://nitter.cz/dotey/status/1744232717582037098#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744232717582037098#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 05:41:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《Meta 如何打造 Threads 的基础设施》<br />
<br />
2023 年 7 月 5 日，Meta 推出了的 Twitter 的竞品 Threads，Threads 在前五天内便创下了惊人的记录，吸引了超过 1 亿用户注册。<br />
<br />
数百万用户的流畅注册体验得益于 Meta 超过十年的基础设施和产品开发经验。这并非是专为 Threads 设计的基础设施，而是 Meta 多年来为众多产品所建立。它早已为规模扩张、性能增强和可靠性提升做好了准备，在 Threads 增长速度超乎预料的情况下，它的表现甚至超出了我们的期待。<br />
<br />
支撑 Threads 运行需要庞大的基础设施。其中两个关键组件：ZippyDB——Meta的分布式 key-value 数据存储系统，以及 Async——我们的异步无服务计算平台。<br />
<br />
原文：<a href="https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/">engineering.fb.com/2023/12/1…</a><br />
译文：<a href="https://baoyu.io/translations/meta/how-meta-built-the-infrastructure-for-threads">baoyu.io/translations/meta/h…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RUQ1YyN1hnQUFmR3hELmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RUQ1lLeVhFQUFXS01TLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RUQ2FTV1hFQUFPNy1MLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Yangyixxxx/status/1744196785227362744#m</id>
            <title>RT by @dotey: GPTs的热潮马上开始，分享一个关于GPTs的赚钱思路

当前GPTs缺少盈利模式，所以我们可以利用Action来提供GPTs相关的订阅能力或广告能力。

1、找一套现成的SaaS系统，可以管理订阅，授权验证和支付链路
2、封装一套API出来，让GPTs可以利用Action进行调用
3、提供相关Prompt，调用Action能力，用户询问时检测授权状态，让GPT返回Link即可，到网站验证授权
4、如果没有支付的话，就在网站交钱订阅。然后给到授权码，回去填给GPTs
5、授权成功就可以开始GPTs的工作了。

这个模式我觉得应该早就有人做过了。但除此之外，你其实还可以做广告模式。

1、让GPTs每次回复消息结束后，用Action来附带一个广告图，做CPM/CPC/CPA的盈利
2、系统只需要接入一些信息流广告即可
3、系统来赚广告利差，这样GPTs的开发者也能受益

还是那句话，别人的焦点都在GPTs，我们就做铲子。</title>
            <link>https://nitter.cz/Yangyixxxx/status/1744196785227362744#m</link>
            <guid isPermaLink="false">https://nitter.cz/Yangyixxxx/status/1744196785227362744#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 03:18:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPTs的热潮马上开始，分享一个关于GPTs的赚钱思路<br />
<br />
当前GPTs缺少盈利模式，所以我们可以利用Action来提供GPTs相关的订阅能力或广告能力。<br />
<br />
1、找一套现成的SaaS系统，可以管理订阅，授权验证和支付链路<br />
2、封装一套API出来，让GPTs可以利用Action进行调用<br />
3、提供相关Prompt，调用Action能力，用户询问时检测授权状态，让GPT返回Link即可，到网站验证授权<br />
4、如果没有支付的话，就在网站交钱订阅。然后给到授权码，回去填给GPTs<br />
5、授权成功就可以开始GPTs的工作了。<br />
<br />
这个模式我觉得应该早就有人做过了。但除此之外，你其实还可以做广告模式。<br />
<br />
1、让GPTs每次回复消息结束后，用Action来附带一个广告图，做CPM/CPC/CPA的盈利<br />
2、系统只需要接入一些信息流广告即可<br />
3、系统来赚广告利差，这样GPTs的开发者也能受益<br />
<br />
还是那句话，别人的焦点都在GPTs，我们就做铲子。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mtrainier2020/status/1744178798411882800#m</id>
            <title>RT by @dotey: 我最近听到一个超级牛逼的玩法就是某AI startup文生图的套路。比如你跟他说要生成河马在喝水，它首先去Google image 搜一圈，然后再把Google image中比较好的结果拿回来，图生图，抹一把腻子，就给用户了。你不知道它这个玩法的套路，你就发现卧槽，这个效果太牛逼了。但是实际上背后是这个套路。😆。不过这个思路确实牛逼啊。</title>
            <link>https://nitter.cz/mtrainier2020/status/1744178798411882800#m</link>
            <guid isPermaLink="false">https://nitter.cz/mtrainier2020/status/1744178798411882800#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 02:06:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我最近听到一个超级牛逼的玩法就是某AI startup文生图的套路。比如你跟他说要生成河马在喝水，它首先去Google image 搜一圈，然后再把Google image中比较好的结果拿回来，图生图，抹一把腻子，就给用户了。你不知道它这个玩法的套路，你就发现卧槽，这个效果太牛逼了。但是实际上背后是这个套路。😆。不过这个思路确实牛逼啊。</p>
<p><a href="https://nitter.cz/mtrainier2020/status/1744176217081971148#m">nitter.cz/mtrainier2020/status/1744176217081971148#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RTUlh6SGFJQUFaN05ILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744179160434802963#m</id>
            <title>RT by @dotey: Teachable Machine：一个由Google开发的机器学习工具

它允许用户快速、简单地创建自己的机器学习模型，而无需专业知识或编程技能。

你可以用它来教电脑识别图片、声音或人的动作。

使用这个工具的步骤很简单：

1、收集数据：你可以上传图片、录制声音或动作视频来作为训练数据。

2、训练模型：用这些数据来训练你的模型，然后测试它能否正确识别新的图片、声音或动作。

3、导出模型：完成训练后，你可以下载这个模型，或者上传到网上，用在其他项目中。

Teachable Machine提供了多种方式来创建机器学习模型，非常灵活和用户友好。

1、使用文件或实时捕捉示例：用户可以选择上传已有的图片、音频文件作为数据，也可以直接通过电脑的摄像头或麦克风实时录制视频、声音作为训练数据。

2、可以在本地完成训练：用户有选项不通过网络发送或处理数据。所有操作，包括数据的收集、模型的训练和应用，都可以在用户自己的电脑上完成，不需要将摄像头或麦克风收集的数据发送到互联网上。这对于隐私保护是非常重要的，特别是当处理敏感信息时。

3、Teachable Machine”生成的模型是真实的TensorFlow.js模型，可以在任何运行JavaScript的地方工作。此外，还可以将模型导出到不同的格式，以便在其他地方使用，如Coral、Arduino等。

开始训练：https://teachablemachine.withgoogle.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1744179160434802963#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744179160434802963#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 02:08:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Teachable Machine：一个由Google开发的机器学习工具<br />
<br />
它允许用户快速、简单地创建自己的机器学习模型，而无需专业知识或编程技能。<br />
<br />
你可以用它来教电脑识别图片、声音或人的动作。<br />
<br />
使用这个工具的步骤很简单：<br />
<br />
1、收集数据：你可以上传图片、录制声音或动作视频来作为训练数据。<br />
<br />
2、训练模型：用这些数据来训练你的模型，然后测试它能否正确识别新的图片、声音或动作。<br />
<br />
3、导出模型：完成训练后，你可以下载这个模型，或者上传到网上，用在其他项目中。<br />
<br />
Teachable Machine提供了多种方式来创建机器学习模型，非常灵活和用户友好。<br />
<br />
1、使用文件或实时捕捉示例：用户可以选择上传已有的图片、音频文件作为数据，也可以直接通过电脑的摄像头或麦克风实时录制视频、声音作为训练数据。<br />
<br />
2、可以在本地完成训练：用户有选项不通过网络发送或处理数据。所有操作，包括数据的收集、模型的训练和应用，都可以在用户自己的电脑上完成，不需要将摄像头或麦克风收集的数据发送到互联网上。这对于隐私保护是非常重要的，特别是当处理敏感信息时。<br />
<br />
3、Teachable Machine”生成的模型是真实的TensorFlow.js模型，可以在任何运行JavaScript的地方工作。此外，还可以将模型导出到不同的格式，以便在其他地方使用，如Coral、Arduino等。<br />
<br />
开始训练：<a href="https://teachablemachine.withgoogle.com/">teachablemachine.withgoogle.…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM5OTM4OTc5NTE1OTI0NDgvcHUvaW1nL1pRUld0cmFLVVR0TkJxWTIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/fi56622380/status/1744100621031272802#m</id>
            <title>RT by @dotey: 进入2024年，平板/手机终端LLM能力和半年前比，进步还是很明显的

半年前在iPhone/Galaxy上用GPU跑7B模型大概能到6 token/s，现在已经能接近20 token/s了

主要提升来自于两方面：一个是启用NPU优化提升到10 token/s，另外一个是新技术speculative decoding再提升一倍（原理如图）

NPU的优化主要是对带宽利用方面，压缩带宽之类的技术

speculative decoding则是巧妙的用一个小LLM先快速做一轮下一个单词的预测，然后用大LLM来同步验证，速度会快一倍，这个技术现在应用也很广泛了

下一次芯片LLM能力主要升级估计是一年半之后，毕竟从去年LLM大火开始构思新架构到面世，通常需要两年的时间

至于升级的部分，我猜测可能主要是带宽，这部分的升级对提升token数的作用是最大的

大胆预测一下，明年年底左右（2025年），随着各种芯片和各层底层软件的优化，我们应该可以看到LLaMa 3的7B模型在平板/手机/汽车上跑到40~50 token/s

那么7B就不再是手机终端的sweet point，也许2026之后会升级成主流13B的模型，占用8GB内存（感觉利好存储厂商）

那个时候的手机13B模型，可能会有今天GPT3.5的能力（现在最接近GPT3.5的小模型是Mistral 7X8模型），那就真的能做很多事情了</title>
            <link>https://nitter.cz/fi56622380/status/1744100621031272802#m</link>
            <guid isPermaLink="false">https://nitter.cz/fi56622380/status/1744100621031272802#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 20:56:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>进入2024年，平板/手机终端LLM能力和半年前比，进步还是很明显的<br />
<br />
半年前在iPhone/Galaxy上用GPU跑7B模型大概能到6 token/s，现在已经能接近20 token/s了<br />
<br />
主要提升来自于两方面：一个是启用NPU优化提升到10 token/s，另外一个是新技术speculative decoding再提升一倍（原理如图）<br />
<br />
NPU的优化主要是对带宽利用方面，压缩带宽之类的技术<br />
<br />
speculative decoding则是巧妙的用一个小LLM先快速做一轮下一个单词的预测，然后用大LLM来同步验证，速度会快一倍，这个技术现在应用也很广泛了<br />
<br />
下一次芯片LLM能力主要升级估计是一年半之后，毕竟从去年LLM大火开始构思新架构到面世，通常需要两年的时间<br />
<br />
至于升级的部分，我猜测可能主要是带宽，这部分的升级对提升token数的作用是最大的<br />
<br />
大胆预测一下，明年年底左右（2025年），随着各种芯片和各层底层软件的优化，我们应该可以看到LLaMa 3的7B模型在平板/手机/汽车上跑到40~50 token/s<br />
<br />
那么7B就不再是手机终端的sweet point，也许2026之后会升级成主流13B的模型，占用8GB内存（感觉利好存储厂商）<br />
<br />
那个时候的手机13B模型，可能会有今天GPT3.5的能力（现在最接近GPT3.5的小模型是Mistral 7X8模型），那就真的能做很多事情了</p>
<p><a href="https://nitter.cz/fi56622380/status/1656195934106324992#m">nitter.cz/fi56622380/status/1656195934106324992#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RSRnJNRWJFQUFRYUxtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743998321977672058#m</id>
            <title>RT by @dotey: 机器人迎来它的ChatGPT 时刻？

机器人初创公司@Figure_robot 发布了一段视频

他们家的Figure-01机器人现在可以自己煮咖啡了

这是一个使用了端到端的人工智能系统，仅通过观察人类制作咖啡的录像，10小时内学会了制作咖啡的技能。

机器人通过神经网络来处理和分析视频数据。通过观看如何制作咖啡的录像。学习人类的动作和手势，然后模仿这些动作来学习制作咖啡的过程。

无需通过编程，机器人自主学习技能。

早前FigureCEO Brett Adcock @adcock_brett 称他们刚刚取得了人工智能突破 。

机器人技术即将迎来它的ChatGPT 时刻！

说的是不是这个？</title>
            <link>https://nitter.cz/xiaohuggg/status/1743998321977672058#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743998321977672058#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 14:09:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>机器人迎来它的ChatGPT 时刻？<br />
<br />
机器人初创公司<a href="https://nitter.cz/Figure_robot" title="Figure">@Figure_robot</a> 发布了一段视频<br />
<br />
他们家的Figure-01机器人现在可以自己煮咖啡了<br />
<br />
这是一个使用了端到端的人工智能系统，仅通过观察人类制作咖啡的录像，10小时内学会了制作咖啡的技能。<br />
<br />
机器人通过神经网络来处理和分析视频数据。通过观看如何制作咖啡的录像。学习人类的动作和手势，然后模仿这些动作来学习制作咖啡的过程。<br />
<br />
无需通过编程，机器人自主学习技能。<br />
<br />
早前FigureCEO Brett Adcock <a href="https://nitter.cz/adcock_brett" title="Brett Adcock">@adcock_brett</a> 称他们刚刚取得了人工智能突破 。<br />
<br />
机器人技术即将迎来它的ChatGPT 时刻！<br />
<br />
说的是不是这个？</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM5OTU4Mzg0OTY2ODE5ODQvcHUvaW1nL0dsdlV6YmlIeVppdXdFZ0MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744047810142703738#m</id>
            <title>RT by @dotey: 发现了个好东西，这个老哥开源了一门课程《从头开始构建大型语言模型》，这门课程将一步步地指导你创建自己的LLM。

每个阶段都有清晰的文本、图表和实例来解释相关概念。

课程内容包括：

 1. 从基础理解注意力机制 
2. 构建并预训练一个类似于GPT的模型 
3. 学习如何加载预训练的权重 
4. 对模型进行分类任务的微调 5. 使用直接偏好优化进行指令微调模型

课程地址：https://github.com/rasbt/LLMs-from-scratch/tree/main</title>
            <link>https://nitter.cz/op7418/status/1744047810142703738#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744047810142703738#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 17:26:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>发现了个好东西，这个老哥开源了一门课程《从头开始构建大型语言模型》，这门课程将一步步地指导你创建自己的LLM。<br />
<br />
每个阶段都有清晰的文本、图表和实例来解释相关概念。<br />
<br />
课程内容包括：<br />
<br />
 1. 从基础理解注意力机制 <br />
2. 构建并预训练一个类似于GPT的模型 <br />
3. 学习如何加载预训练的权重 <br />
4. 对模型进行分类任务的微调 5. 使用直接偏好优化进行指令微调模型<br />
<br />
课程地址：<a href="https://github.com/rasbt/LLMs-from-scratch/tree/main">github.com/rasbt/LLMs-from-s…</a></p>
<p><a href="https://nitter.cz/rasbt/status/1744042674385002820#m">nitter.cz/rasbt/status/1744042674385002820#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1743844345646915958#m</id>
            <title>RT by @dotey: ChatGPT APP上GPTs，现在也支持语音对话了。
只用GPTs就能实现之前想做的应用了，比如讲带有插画的故事（见下方视频）、口算陪练、古诗词先用图片描绘再讲解，语音交互对儿童很友好。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1743844345646915958#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1743844345646915958#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 03:57:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT APP上GPTs，现在也支持语音对话了。<br />
只用GPTs就能实现之前想做的应用了，比如讲带有插画的故事（见下方视频）、口算陪练、古诗词先用图片描绘再讲解，语音交互对儿童很友好。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM4NDIwMTMwODUzMTUwNzIvcHUvaW1nL1VINkNQZ0VKa0FYZkY2MmYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743817709404438833#m</id>
            <title>哈哈哈哈</title>
            <link>https://nitter.cz/dotey/status/1743817709404438833#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743817709404438833#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 02:11:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈哈哈</p>
<p><a href="https://nitter.cz/xiaojingcanxue/status/1743690843326931210#m">nitter.cz/xiaojingcanxue/status/1743690843326931210#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mranti/status/1743809624346878418#m</id>
            <title>RT by @dotey: 妻若受欺凌，我誓山河动（谁动我老婆，我动他全家）：Ackman是指责哈佛等校长对打击反犹不利的投资人，在哈佛校长辞职后，有人说他老婆也抄袭。他一怒之下，用AI展开对MIT的所有校领导的抄袭审查——</title>
            <link>https://nitter.cz/mranti/status/1743809624346878418#m</link>
            <guid isPermaLink="false">https://nitter.cz/mranti/status/1743809624346878418#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 01:39:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>妻若受欺凌，我誓山河动（谁动我老婆，我动他全家）：Ackman是指责哈佛等校长对打击反犹不利的投资人，在哈佛校长辞职后，有人说他老婆也抄袭。他一怒之下，用AI展开对MIT的所有校领导的抄袭审查——</p>
<p><a href="https://nitter.cz/BillAckman/status/1743792224020619450#m">nitter.cz/BillAckman/status/1743792224020619450#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>