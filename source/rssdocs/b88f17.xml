<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/Barret_China/status/1729339337182187704#m</id>
            <title>RT by @dotey: self-operating-computer，https://github.com/OthersideAI/self-operating-computer，这个项目演示了如何让 GPT-4V 来控制自己的电脑，你需要做的就是告诉它完成一个怎样的任务，例如，打开 Google Docs 写一篇文章，然后发布并分享给同事。

它的 Prompt 写的比较简单，定义了一个可以与机器交互的 DSL，主要包含三种动作：Click/Type/Search，分别对应 mouse_click/keyboard_type/mac_search 几个封装好的系统函数。

每次程序执行动作时，都会携带任务目标、上一步执行结果以及当前屏幕截图作为上下文，然后将信息传递给 ChatGPT，并让它给出下一步操作指示。

这个项目中 Prompt 的定制化程度偏高，说明完成复杂的工作还比较有挑战，如果参考之前提到的 Mutil-Agent 方案，https://twitter.com/Barret_China/status/1712408323851788505，做出来效果应该会更好一些。</title>
            <link>https://nitter.cz/Barret_China/status/1729339337182187704#m</link>
            <guid isPermaLink="false">https://nitter.cz/Barret_China/status/1729339337182187704#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 03:20:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>self-operating-computer，<a href="https://github.com/OthersideAI/self-operating-computer">github.com/OthersideAI/self-…</a>，这个项目演示了如何让 GPT-4V 来控制自己的电脑，你需要做的就是告诉它完成一个怎样的任务，例如，打开 Google Docs 写一篇文章，然后发布并分享给同事。<br />
<br />
它的 Prompt 写的比较简单，定义了一个可以与机器交互的 DSL，主要包含三种动作：Click/Type/Search，分别对应 mouse_click/keyboard_type/mac_search 几个封装好的系统函数。<br />
<br />
每次程序执行动作时，都会携带任务目标、上一步执行结果以及当前屏幕截图作为上下文，然后将信息传递给 ChatGPT，并让它给出下一步操作指示。<br />
<br />
这个项目中 Prompt 的定制化程度偏高，说明完成复杂的工作还比较有挑战，如果参考之前提到的 Mutil-Agent 方案，<a href="https://nitter.cz/Barret_China/status/1712408323851788505">nitter.cz/Barret_China/sta…</a>，做出来效果应该会更好一些。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9fVmhQWWFvQUFaSmtmLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729299645933728046#m</id>
            <title>Bill Gates 认为 ChatGPT 和其他生成式 AI 已经达到顶峰，OpenAI 的 GPT-5 不会有显著提升

https://www.firstpost.com/tech/news-analysis/chatgpt-generative-ai-have-peaked-openais-gpt-5-wont-be-much-better-says-bill-gates-13299212.html

微软前首席执行官和董事长比尔·盖茨认为，类似 OpenAI 的 ChatGPT 这种生成式 AI 的功能已经达到顶峰，现在只会进一步精炼，而不太可能再为诸如 GPT-5 这类大语言模型增加更多创新功能

Mehul Reuben Das, 2023年10月26日

微软前首席执行官和董事长比尔·盖茨认为，像 ChatGPT 这样的生成式 AI 功能已经达到顶峰，目前的重点将是对现有技术进行进一步的精炼，而不太可能在像 GPT-5 这样的大语言模型上增添新的重大功能。

过去一年中，生成式 AI 成为新闻头条的常客，众多公司在这一领域投入了巨资。这一趋势的关键时刻是在 2022 年 11 月 OpenAI 推出了 ChatGPT。

OpenAI 的 GPT 技术为各个行业的 AI 发展打下了坚实基础。尽管公众对 GPT 和生成式 AI 抱有极大热情，但微软创始人比尔·盖茨却表达了一定的保留意见，暗示这种技术可能已经到达了一个发展的高原期。

比尔·盖茨认为 ChatGPT 功能已达到顶峰
在接受德国商业报纸 Handelsblatt 采访时，这位 67 岁的科技巨擘分享了他对生成式 AI 发展趋势的担忧。他坦言，有充分的理由认为目前的 GPT 技术已经达到一个顶点。不过，盖茨也表示，他的这种判断可能并非绝对正确。
他对 GPT-5 的发展前景持有与 OpenAI 不同的看法，认为这一技术的发展可能有限，与 OpenAI 对未来的乐观预期相反。

盖茨认为，从 GPT-2 到 GPT-4 的飞跃进步是“难以置信的”。他还预测，在未来两到五年间，AI 软件的精准度将会大幅度提升，同时成本会降低。

他相信，这将为开发新颖且可靠的应用程序铺平道路。然而，盖茨预计，在最初阶段，特别是在 GPT-4 的发展上，可能会遇到技术瓶颈，GPT-5 也可能难以突破这一限制。

AI 将朝着更可靠的方向发展，而非增加更多功能
尽管如此，Gates 对 AI 短期内的发展前景仍持乐观态度。他预见，持续的研究会让 AI 变得更加可靠且易于理解。他特别强调，发展中国家将显著受益于 AI，例如通过智能手机获取健康咨询。

谈及 AI 的成本和可靠性，Gates 提到 Nvidia 的某些 AI 芯片价格高达每个约 30,000 美元，具有强大的计算能力和能源消耗。他指出，虽然训练大语言模型成本高昂，但实际使用成本已随时间降低。
Gates 还相信，AI 有潜力彻底改变医疗行业，尤其是在加速药物和疫苗研发方面，尽管对其可靠性仍存疑虑。

关于人工通用智能（AGI），未来充满不确定性
此外，Gates 探讨了 AI 的“黑盒”问题及其加密信息的机制，强调了许多个人和组织在解开这一谜团方面的努力。

在人工通用智能（AGI）这一议题上，Gates 认为 AGI 的到来尚无定论，这可能是人类历史上的重大转折。

最后，Gates 分析了 AI 在应对气候变化方面的重要角色。他强调气候模型不断进步，并大力支持那些能在高温环境中生长的新作物品种。
Gates 透露，他投资了近百家公司，致力于利用 AI 技术改善电网，展现了他面对全球挑战的决心。</title>
            <link>https://nitter.cz/dotey/status/1729299645933728046#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729299645933728046#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 00:42:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Bill Gates 认为 ChatGPT 和其他生成式 AI 已经达到顶峰，OpenAI 的 GPT-5 不会有显著提升<br />
<br />
<a href="https://www.firstpost.com/tech/news-analysis/chatgpt-generative-ai-have-peaked-openais-gpt-5-wont-be-much-better-says-bill-gates-13299212.html">firstpost.com/tech/news-anal…</a><br />
<br />
微软前首席执行官和董事长比尔·盖茨认为，类似 OpenAI 的 ChatGPT 这种生成式 AI 的功能已经达到顶峰，现在只会进一步精炼，而不太可能再为诸如 GPT-5 这类大语言模型增加更多创新功能<br />
<br />
Mehul Reuben Das, 2023年10月26日<br />
<br />
微软前首席执行官和董事长比尔·盖茨认为，像 ChatGPT 这样的生成式 AI 功能已经达到顶峰，目前的重点将是对现有技术进行进一步的精炼，而不太可能在像 GPT-5 这样的大语言模型上增添新的重大功能。<br />
<br />
过去一年中，生成式 AI 成为新闻头条的常客，众多公司在这一领域投入了巨资。这一趋势的关键时刻是在 2022 年 11 月 OpenAI 推出了 ChatGPT。<br />
<br />
OpenAI 的 GPT 技术为各个行业的 AI 发展打下了坚实基础。尽管公众对 GPT 和生成式 AI 抱有极大热情，但微软创始人比尔·盖茨却表达了一定的保留意见，暗示这种技术可能已经到达了一个发展的高原期。<br />
<br />
比尔·盖茨认为 ChatGPT 功能已达到顶峰<br />
在接受德国商业报纸 Handelsblatt 采访时，这位 67 岁的科技巨擘分享了他对生成式 AI 发展趋势的担忧。他坦言，有充分的理由认为目前的 GPT 技术已经达到一个顶点。不过，盖茨也表示，他的这种判断可能并非绝对正确。<br />
他对 GPT-5 的发展前景持有与 OpenAI 不同的看法，认为这一技术的发展可能有限，与 OpenAI 对未来的乐观预期相反。<br />
<br />
盖茨认为，从 GPT-2 到 GPT-4 的飞跃进步是“难以置信的”。他还预测，在未来两到五年间，AI 软件的精准度将会大幅度提升，同时成本会降低。<br />
<br />
他相信，这将为开发新颖且可靠的应用程序铺平道路。然而，盖茨预计，在最初阶段，特别是在 GPT-4 的发展上，可能会遇到技术瓶颈，GPT-5 也可能难以突破这一限制。<br />
<br />
AI 将朝着更可靠的方向发展，而非增加更多功能<br />
尽管如此，Gates 对 AI 短期内的发展前景仍持乐观态度。他预见，持续的研究会让 AI 变得更加可靠且易于理解。他特别强调，发展中国家将显著受益于 AI，例如通过智能手机获取健康咨询。<br />
<br />
谈及 AI 的成本和可靠性，Gates 提到 Nvidia 的某些 AI 芯片价格高达每个约 30,000 美元，具有强大的计算能力和能源消耗。他指出，虽然训练大语言模型成本高昂，但实际使用成本已随时间降低。<br />
Gates 还相信，AI 有潜力彻底改变医疗行业，尤其是在加速药物和疫苗研发方面，尽管对其可靠性仍存疑虑。<br />
<br />
关于人工通用智能（AGI），未来充满不确定性<br />
此外，Gates 探讨了 AI 的“黑盒”问题及其加密信息的机制，强调了许多个人和组织在解开这一谜团方面的努力。<br />
<br />
在人工通用智能（AGI）这一议题上，Gates 认为 AGI 的到来尚无定论，这可能是人类历史上的重大转折。<br />
<br />
最后，Gates 分析了 AI 在应对气候变化方面的重要角色。他强调气候模型不断进步，并大力支持那些能在高温环境中生长的新作物品种。<br />
Gates 透露，他投资了近百家公司，致力于利用 AI 技术改善电网，展现了他面对全球挑战的决心。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8tMDBndlc0QUFuQ3F4LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729277775205335321#m</id>
            <title>R to @dotey: **LLM Scaling Laws**

好的，现在我要转换话题，我们将讨论语言模型，它们是如何改进的，以及这些改进将带我们走向何方。首先要理解的关于大语言模型的重要概念是“规模化法则”。事实证明，这些大语言模型在预测下一个词的准确性方面的表现是一个非常平滑、规律性强，并且只有两个变量的预测函数。一个变量是 N，即网络中的参数数量；另一个变量是 D，即你用来训练的文本量。只要有了这两个数据，我们就能非常准确地预测你在下一词预测任务上能达到的准确度。令人惊奇的是，这些趋势看起来并没有出现停滞或达到极限的迹象。这意味着，如果你在更多文本上训练更大规模的模型，我们可以非常自信地预期下一词预测的表现将会提升。

因此，在算法上取得进步并非必要条件。算法进步当然是很好的加分项，但我们能够在不增加成本的情况下获得更强大的模型，因为我们只需要更强大的计算机。我们有理由相信这是可行的，并且我们可以在更长时间内训练一个更大的模型。我们非常有信心我们将得到更好的结果。当然，在实际操作中，我们并不是真的那么关心预测下一个词的准确度。但是，从经验上看，这种准确度与我们真正关心的许多评估指标是相关的。例如，你可以对这些大语言模型进行很多不同的测试。你会看到，如果你训练一个更大的模型更长的时间，例如，在 GPT 系列中从 3.5 提升到 4，所有这些测试的准确性都会提高。所以，当我们训练更大规模的模型和更多的数据时，我们自然而然地期待有性能的提升。这正是当前计算领域的一场淘金热的根本驱动力，每个人都在努力获取更强大的 GPU 集群，收集更多的数据，因为人们有很大的信心，通过这样做，可以获得更优秀的模型。算法的进步就像是额外的奖励，许多机构对此投入巨大。但从根本上说，扩大规模提供了一条通往成功的确定途径。

**Tool Use (Browser, Calculator, Interpreter, DALL-E)**

接下来，我想通过一些具体的例子来讲解这些语言模型的能力，以及它们是如何随着时间发展的。不是泛泛而谈，我会用一个具体的例子，逐步分析来说明。所以我打开 ChatGPT，给出了以下的查询。我说，收集关于 Scale AI 及其融资轮次的信息，包括发生的时间、日期、金额和估值，并将这些信息整理成一张表。根据我们收集的大量数据，ChatGPT 在微调学习阶段就已经理解，在这种类型的查询中，ChatGPT 不会仅仅依靠自己作为一个大语言模型来直接回答问题。相反，它学会了在需要时使用一些外部工具来帮助完成任务。在这个例子中，一个很合适的工具就是浏览器。

假设你和我遇到同样的问题，你可能会选择上网搜索，对吧？ChatGPT 做的正是这样的事情。它能够发出特定的词汇，我们可以通过这些词汇观察它是如何尝试进行搜索的。在这种情况下，我们可以拿着这个查询去 Bing 搜索，查看搜索结果。就像你我在浏览搜索结果一样，我们可以把搜索到的文本反馈给语言模型，让它基于这些文本生成回答。这个过程非常类似于我们使用浏览器进行研究的方式。然后，它会将这些信息整理成以下形式，并以此方式进行回应。

所以，它收集了信息，我们得到了一张表格，上面列出了 A、B、C、D 和 E 轮融资的具体日期、筹资金额和对应的估值。接着，它还提供了引用链接，你可以通过这些链接去核实这些信息的准确性。在底部，它表示，实际上我要道歉，我没有找到 A 轮和 B 轮的估值数据，只找到了筹集的金额。所以你可以看到表格中有一项标记为不可用。好的，我们现在可以继续这种互动。我提出，让我们尝试基于 C 轮、D 轮和 E 轮中看到的比例，来推测或估算 A 轮和 B 轮的估值。可以看到，在 C、D 和 E 轮中，筹资金额和估值之间存在一定的比例关系。那么，我们该如何解决这个问题呢？当我们尝试推算“不可用”的数据时，并不是仅凭脑海中的计算就能解决。你不可能只是试图在你的脑海中解决它。这样做相当复杂，因为我们在数学方面并不特别擅长。同样，ChatGPT 也不是通过单纯“思考”就能擅长数学运算。实际上，ChatGPT 知道它应该使用计算器来处理这类任务。因此，它会发出特定的指令，告诉程序它需要使用计算器来计算这个数值。它实际上做的是，首先计算所有的比率，然后根据这些比率来推算 A 轮和 B 轮的估值，可能是 7000 万或者 2.83 亿。所以，现在我们的目标是得到所有不同融资轮次的估值数据。接下来，我们将这些数据制作成一个二维图表：横轴表示日期，纵轴显示 Scale AI 的估值。为了更精确地展示，我们会在纵轴上使用对数刻度，并且加上网格线，使图表看起来既专业又美观。ChatGPT 实际上可以使用工具，这次是编写代码，使用 Python 语言中的 Matplotlib 库来绘制这些数据。它会进入一个 Python 解释器，输入所有数据，然后生成图表。这就是图。它清晰地展示了底部的数据，完全按照我们用自然语言提出的要求制作完成。

与 ChatGPT 交流就像与人交谈一样自然。现在我们看着这张图表，想要进行更多的分析。比如，我们现在想在这个图表上加一条线性趋势线，并尝试推算 Scale AI 到 2025 年底的估值。再比如，在图表上标出今天的日期，并基于趋势线来估算今天和 2025 年底的估值。ChatGPT 完成了所有编码工作，虽然这些代码没有展示出来，但它提供了详细的分析结果。在图表的底部，我们可以看到日期和估值的推算结果。根据这个趋势线的拟合结果，今天 Scale AI 的估值大约是 1500 亿美元。而到了 2025 年底，这个公司预计会成长为价值高达 2 万亿美元的科技巨头。所以，祝贺 Scale AI 团队。但这只是 ChatGPT 擅长的分析类型之一。我想通过这个例子展示的核心点是，语言模型在工具使用方面的能力以及它们的发展趋势。它们的功能不再局限于在大脑中处理信息和选择词汇。如今，它们开始利用各种工具和现有的计算基础设施，将一切紧密联系并用词汇交织在一起，如果这有意义的话。

因此，工具使用已成为这些模型日益增强能力的重要一环。它们能够编写大量代码、进行全面分析、从互联网上检索信息等等。再举一个例子。根据上述信息，试图生成一个代表 Scale AI 公司的图像。所以，基于上面的所有内容，依据大语言模型的上下文理解，它对 Scale AI 有深刻的了解。它可能还记得关于 Scale AI 的一些信息以及网络中储存的知识。然后它去使用另一个工具，在这种情况下这个工具是 DALL-E，这也是 OpenAI 开发的一种工具，可以根据自然语言描述生成图像。所以在这里 DALL-E 被用作生成图像的工具。希望这个演示能具体说明问题解决过程中大量使用工具的情况，这与人类解决很多问题的方式高度相关。我们在解决问题时不仅仅依赖思考，而是广泛运用各种工具，比如电脑就非常有用。对于大语言模型也是如此，利用工具正逐渐成为大语言模型发展的一个重要方向。</title>
            <link>https://nitter.cz/dotey/status/1729277775205335321#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729277775205335321#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 23:15:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>**LLM Scaling Laws**<br />
<br />
好的，现在我要转换话题，我们将讨论语言模型，它们是如何改进的，以及这些改进将带我们走向何方。首先要理解的关于大语言模型的重要概念是“规模化法则”。事实证明，这些大语言模型在预测下一个词的准确性方面的表现是一个非常平滑、规律性强，并且只有两个变量的预测函数。一个变量是 N，即网络中的参数数量；另一个变量是 D，即你用来训练的文本量。只要有了这两个数据，我们就能非常准确地预测你在下一词预测任务上能达到的准确度。令人惊奇的是，这些趋势看起来并没有出现停滞或达到极限的迹象。这意味着，如果你在更多文本上训练更大规模的模型，我们可以非常自信地预期下一词预测的表现将会提升。<br />
<br />
因此，在算法上取得进步并非必要条件。算法进步当然是很好的加分项，但我们能够在不增加成本的情况下获得更强大的模型，因为我们只需要更强大的计算机。我们有理由相信这是可行的，并且我们可以在更长时间内训练一个更大的模型。我们非常有信心我们将得到更好的结果。当然，在实际操作中，我们并不是真的那么关心预测下一个词的准确度。但是，从经验上看，这种准确度与我们真正关心的许多评估指标是相关的。例如，你可以对这些大语言模型进行很多不同的测试。你会看到，如果你训练一个更大的模型更长的时间，例如，在 GPT 系列中从 3.5 提升到 4，所有这些测试的准确性都会提高。所以，当我们训练更大规模的模型和更多的数据时，我们自然而然地期待有性能的提升。这正是当前计算领域的一场淘金热的根本驱动力，每个人都在努力获取更强大的 GPU 集群，收集更多的数据，因为人们有很大的信心，通过这样做，可以获得更优秀的模型。算法的进步就像是额外的奖励，许多机构对此投入巨大。但从根本上说，扩大规模提供了一条通往成功的确定途径。<br />
<br />
**Tool Use (Browser, Calculator, Interpreter, DALL-E)**<br />
<br />
接下来，我想通过一些具体的例子来讲解这些语言模型的能力，以及它们是如何随着时间发展的。不是泛泛而谈，我会用一个具体的例子，逐步分析来说明。所以我打开 ChatGPT，给出了以下的查询。我说，收集关于 Scale AI 及其融资轮次的信息，包括发生的时间、日期、金额和估值，并将这些信息整理成一张表。根据我们收集的大量数据，ChatGPT 在微调学习阶段就已经理解，在这种类型的查询中，ChatGPT 不会仅仅依靠自己作为一个大语言模型来直接回答问题。相反，它学会了在需要时使用一些外部工具来帮助完成任务。在这个例子中，一个很合适的工具就是浏览器。<br />
<br />
假设你和我遇到同样的问题，你可能会选择上网搜索，对吧？ChatGPT 做的正是这样的事情。它能够发出特定的词汇，我们可以通过这些词汇观察它是如何尝试进行搜索的。在这种情况下，我们可以拿着这个查询去 Bing 搜索，查看搜索结果。就像你我在浏览搜索结果一样，我们可以把搜索到的文本反馈给语言模型，让它基于这些文本生成回答。这个过程非常类似于我们使用浏览器进行研究的方式。然后，它会将这些信息整理成以下形式，并以此方式进行回应。<br />
<br />
所以，它收集了信息，我们得到了一张表格，上面列出了 A、B、C、D 和 E 轮融资的具体日期、筹资金额和对应的估值。接着，它还提供了引用链接，你可以通过这些链接去核实这些信息的准确性。在底部，它表示，实际上我要道歉，我没有找到 A 轮和 B 轮的估值数据，只找到了筹集的金额。所以你可以看到表格中有一项标记为不可用。好的，我们现在可以继续这种互动。我提出，让我们尝试基于 C 轮、D 轮和 E 轮中看到的比例，来推测或估算 A 轮和 B 轮的估值。可以看到，在 C、D 和 E 轮中，筹资金额和估值之间存在一定的比例关系。那么，我们该如何解决这个问题呢？当我们尝试推算“不可用”的数据时，并不是仅凭脑海中的计算就能解决。你不可能只是试图在你的脑海中解决它。这样做相当复杂，因为我们在数学方面并不特别擅长。同样，ChatGPT 也不是通过单纯“思考”就能擅长数学运算。实际上，ChatGPT 知道它应该使用计算器来处理这类任务。因此，它会发出特定的指令，告诉程序它需要使用计算器来计算这个数值。它实际上做的是，首先计算所有的比率，然后根据这些比率来推算 A 轮和 B 轮的估值，可能是 7000 万或者 2.83 亿。所以，现在我们的目标是得到所有不同融资轮次的估值数据。接下来，我们将这些数据制作成一个二维图表：横轴表示日期，纵轴显示 Scale AI 的估值。为了更精确地展示，我们会在纵轴上使用对数刻度，并且加上网格线，使图表看起来既专业又美观。ChatGPT 实际上可以使用工具，这次是编写代码，使用 Python 语言中的 Matplotlib 库来绘制这些数据。它会进入一个 Python 解释器，输入所有数据，然后生成图表。这就是图。它清晰地展示了底部的数据，完全按照我们用自然语言提出的要求制作完成。<br />
<br />
与 ChatGPT 交流就像与人交谈一样自然。现在我们看着这张图表，想要进行更多的分析。比如，我们现在想在这个图表上加一条线性趋势线，并尝试推算 Scale AI 到 2025 年底的估值。再比如，在图表上标出今天的日期，并基于趋势线来估算今天和 2025 年底的估值。ChatGPT 完成了所有编码工作，虽然这些代码没有展示出来，但它提供了详细的分析结果。在图表的底部，我们可以看到日期和估值的推算结果。根据这个趋势线的拟合结果，今天 Scale AI 的估值大约是 1500 亿美元。而到了 2025 年底，这个公司预计会成长为价值高达 2 万亿美元的科技巨头。所以，祝贺 Scale AI 团队。但这只是 ChatGPT 擅长的分析类型之一。我想通过这个例子展示的核心点是，语言模型在工具使用方面的能力以及它们的发展趋势。它们的功能不再局限于在大脑中处理信息和选择词汇。如今，它们开始利用各种工具和现有的计算基础设施，将一切紧密联系并用词汇交织在一起，如果这有意义的话。<br />
<br />
因此，工具使用已成为这些模型日益增强能力的重要一环。它们能够编写大量代码、进行全面分析、从互联网上检索信息等等。再举一个例子。根据上述信息，试图生成一个代表 Scale AI 公司的图像。所以，基于上面的所有内容，依据大语言模型的上下文理解，它对 Scale AI 有深刻的了解。它可能还记得关于 Scale AI 的一些信息以及网络中储存的知识。然后它去使用另一个工具，在这种情况下这个工具是 DALL-E，这也是 OpenAI 开发的一种工具，可以根据自然语言描述生成图像。所以在这里 DALL-E 被用作生成图像的工具。希望这个演示能具体说明问题解决过程中大量使用工具的情况，这与人类解决很多问题的方式高度相关。我们在解决问题时不仅仅依赖思考，而是广泛运用各种工具，比如电脑就非常有用。对于大语言模型也是如此，利用工具正逐渐成为大语言模型发展的一个重要方向。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjkyNzY3NjA4NTA1NjMwNzIvcHUvaW1nL1VRX0VWbDd5bVJoTWN1SnQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/goocarlos/status/1729210688017760324#m</id>
            <title>RT by @dotey: 这款名为 Coze 的产品是否看起来眼熟？由某裁员中的大厂“高 Level”团队创作。该产品的完成度其实做得不错，毕竟是重金投入。但社区中屡有朋友向我发来询问，因为实在和 Dify 太像了，连我们选择不恰当的那些英文术语都全盘搬走。简单的说下吧：

我们一直在做的就是持续创新、并坚持向社区交付高品质的产品。论资金密度我们是无法跟这个体量的大厂去拼的，但我们可以保持开放、中立、透明。Dify 为开发者的做的事可以归结为三项：
1. Democratization of AI，围绕 LLM 的 RAG 和 Fine-tune 等是复杂技术，有待简化；
2. Cross-Functional Collaboration in AI，我们相信 非技术人员需要参与到 AI 应用的定义过程之中；
3. Data-Driven Feedback，AI 应用的效果提升建立在来自生产数据的反馈，为全社会加速这个流程的运转。

如何应对？
1. 据我已知，Dify 有超过万计的私有部署实例，已经有许多开发者基于我们赚到了钱、融到了资以及少走了弯路（虽然我们没怎么收钱）。社区是我们最重要的力量和资产；
2. 我们会在近期开放产品的 Roadmap，并发布详细的贡献指南；
3. 大厂仿品有价值的特性，我们会做得更好，然后“贡献”给开源社区；
4. 与全生态合作伙伴加深合作，我们和国内所有的模型公司都有非常棒的沟通；
5. 将未来我们的收入分出来一部分给贡献者。

创业公司如何对待大厂？
在热门赛道，国内几乎所有的大厂都会以战投、交流、比赛等方式与创业者接触，然后把情报带回去注资研发。今年某些厂商狂搞黑客松就是现象之一，目的并不是简单的拉高声量。

大厂应该如何对待创业项目？
1. 出来好好交个朋友，不寒碜；
2. 向借鉴的开源项目公开致敬，即使没有直接使用源码；
3. 向开源社区做贡献。

就说这些，如果你想以任何形式参与 Dify 的产品，发邮件至 luyu@dify.ai，Do it for you.</title>
            <link>https://nitter.cz/goocarlos/status/1729210688017760324#m</link>
            <guid isPermaLink="false">https://nitter.cz/goocarlos/status/1729210688017760324#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 18:48:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这款名为 Coze 的产品是否看起来眼熟？由某裁员中的大厂“高 Level”团队创作。该产品的完成度其实做得不错，毕竟是重金投入。但社区中屡有朋友向我发来询问，因为实在和 Dify 太像了，连我们选择不恰当的那些英文术语都全盘搬走。简单的说下吧：<br />
<br />
我们一直在做的就是持续创新、并坚持向社区交付高品质的产品。论资金密度我们是无法跟这个体量的大厂去拼的，但我们可以保持开放、中立、透明。Dify 为开发者的做的事可以归结为三项：<br />
1. Democratization of AI，围绕 LLM 的 RAG 和 Fine-tune 等是复杂技术，有待简化；<br />
2. Cross-Functional Collaboration in AI，我们相信 非技术人员需要参与到 AI 应用的定义过程之中；<br />
3. Data-Driven Feedback，AI 应用的效果提升建立在来自生产数据的反馈，为全社会加速这个流程的运转。<br />
<br />
如何应对？<br />
1. 据我已知，Dify 有超过万计的私有部署实例，已经有许多开发者基于我们赚到了钱、融到了资以及少走了弯路（虽然我们没怎么收钱）。社区是我们最重要的力量和资产；<br />
2. 我们会在近期开放产品的 Roadmap，并发布详细的贡献指南；<br />
3. 大厂仿品有价值的特性，我们会做得更好，然后“贡献”给开源社区；<br />
4. 与全生态合作伙伴加深合作，我们和国内所有的模型公司都有非常棒的沟通；<br />
5. 将未来我们的收入分出来一部分给贡献者。<br />
<br />
创业公司如何对待大厂？<br />
在热门赛道，国内几乎所有的大厂都会以战投、交流、比赛等方式与创业者接触，然后把情报带回去注资研发。今年某些厂商狂搞黑客松就是现象之一，目的并不是简单的拉高声量。<br />
<br />
大厂应该如何对待创业项目？<br />
1. 出来好好交个朋友，不寒碜；<br />
2. 向借鉴的开源项目公开致敬，即使没有直接使用源码；<br />
3. 向开源社区做贡献。<br />
<br />
就说这些，如果你想以任何形式参与 Dify 的产品，发邮件至 luyu@dify.ai，Do it for you.</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85ZE16c2EwQUVBZ3ZoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85ZFB0MGJFQUFlS3RaLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85ZFB1QmFZQUFnSXFDLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85amM4SmJ3QUFVQUduLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729231976672977016#m</id>
            <title>推荐：《Reading List For Andrej Karpathy’s Intro to Large Language Models Video》 
Andrej Karpathy 大语言模型视频入门的精选阅读清单

作者针对Andrej Karpathy前几天的视频教程，把相关的参考文章、论文都分门别类整理出来了。

原文：https://blog.oxen.ai/reading-list-for-andrej-karpathys-intro-to-large-language-models-video/
译文：https://baoyu.io/translations/llm/reading-list-for-andrej-karpathys-intro-to-large-language-models-video</title>
            <link>https://nitter.cz/dotey/status/1729231976672977016#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729231976672977016#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 20:13:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐：《Reading List For Andrej Karpathy’s Intro to Large Language Models Video》 <br />
Andrej Karpathy 大语言模型视频入门的精选阅读清单<br />
<br />
作者针对Andrej Karpathy前几天的视频教程，把相关的参考文章、论文都分门别类整理出来了。<br />
<br />
原文：<a href="https://blog.oxen.ai/reading-list-for-andrej-karpathys-intro-to-large-language-models-video/">blog.oxen.ai/reading-list-fo…</a><br />
译文：<a href="https://baoyu.io/translations/llm/reading-list-for-andrej-karpathys-intro-to-large-language-models-video">baoyu.io/translations/llm/re…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85MnlJTVdVQUV1NXVFLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85M0hkblhjQUFfUE1wLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85M09xU1hvQUFWX1NoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85M1RzeVhZQUFaYjNrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729228859483054230#m</id>
            <title>黑的漂亮😂</title>
            <link>https://nitter.cz/dotey/status/1729228859483054230#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729228859483054230#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 20:01:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>黑的漂亮😂</p>
<p><a href="https://nitter.cz/milosvete/status/1729203769836212432#m">nitter.cz/milosvete/status/1729203769836212432#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mave99a/status/1729221316165906820#m</id>
            <title>RT by @dotey: 关键是要看什么东西可以 RL （Reinforcement learning） 却不需要 HF（human feedback）。 AI行业和区块链行业（或者整个IT行业）一样有喜欢造词来显得高大上的毛病。 其实RLHF，通俗来说就是给AI 点赞或点踩，这样它能反思提高。 目前语言问题在于需要人工参与这个过程，因此提高缓慢。</title>
            <link>https://nitter.cz/mave99a/status/1729221316165906820#m</link>
            <guid isPermaLink="false">https://nitter.cz/mave99a/status/1729221316165906820#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 19:31:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>关键是要看什么东西可以 RL （Reinforcement learning） 却不需要 HF（human feedback）。 AI行业和区块链行业（或者整个IT行业）一样有喜欢造词来显得高大上的毛病。 其实RLHF，通俗来说就是给AI 点赞或点踩，这样它能反思提高。 目前语言问题在于需要人工参与这个过程，因此提高缓慢。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729194209901736340#m</id>
            <title>作者把这个冒险游戏的GPT的Prompt开源了
https://gist.github.com/levelsio/5bc87fd1b1ffbf4a705047bebd9b4790</title>
            <link>https://nitter.cz/dotey/status/1729194209901736340#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729194209901736340#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 17:43:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者把这个冒险游戏的GPT的Prompt开源了<br />
<a href="https://gist.github.com/levelsio/5bc87fd1b1ffbf4a705047bebd9b4790">gist.github.com/levelsio/5bc…</a></p>
<p><a href="https://nitter.cz/levelsio/status/1728951317945868729#m">nitter.cz/levelsio/status/1728951317945868729#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyODMwOTI4NTAyODAyMDIyNC84MzFnbzNucD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729178839191081077#m</id>
            <title>核心就是得做中学</title>
            <link>https://nitter.cz/dotey/status/1729178839191081077#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729178839191081077#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:42:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>核心就是得做中学</p>
<p><a href="https://nitter.cz/gdb/status/1729162836499472734#m">nitter.cz/gdb/status/1729162836499472734#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729172682758054147#m</id>
            <title>RT by @dotey: Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。
将这种方法扩展是否能实现通用人工智能（AGI）？不会。
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</title>
            <link>https://nitter.cz/op7418/status/1729172682758054147#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729172682758054147#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:17:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：<br />
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。<br />
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。<br />
将这种方法扩展是否能实现通用人工智能（AGI）？不会。<br />
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。<br />
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</p>
<p><a href="https://nitter.cz/DrJimFan/status/1729162728072433876#m">nitter.cz/DrJimFan/status/1729162728072433876#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</id>
            <title>RT by @dotey: 建议和这篇《为什么你不该加入 Y Combinator》https://readit.vip/a/e0Bwj  一起阅读。

作者反对保罗这种只以增长为目标的做法。

1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</title>
            <link>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</link>
            <guid isPermaLink="false">https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 13:57:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>建议和这篇《为什么你不该加入 Y Combinator》<a href="https://readit.vip/a/e0Bwj">readit.vip/a/e0Bwj</a>  一起阅读。<br />
<br />
作者反对保罗这种只以增长为目标的做法。<br />
<br />
1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。<br />
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZXRtdmFrQUFMRFBtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZnFEcWJnQUFhMGJ2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Tisoga/status/1729017824092549247#m</id>
            <title>RT by @dotey: 这应该就是做产品最希望收到的评价吧。

另外 http://devv.ai 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。

欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</title>
            <link>https://nitter.cz/Tisoga/status/1729017824092549247#m</link>
            <guid isPermaLink="false">https://nitter.cz/Tisoga/status/1729017824092549247#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:02:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这应该就是做产品最希望收到的评价吧。<br />
<br />
另外 <a href="http://devv.ai">devv.ai</a> 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。<br />
<br />
欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82ejBRVmIwQUFYUDAzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729026599411225075#m</id>
            <title>R to @dotey: 谢谢</title>
            <link>https://nitter.cz/dotey/status/1729026599411225075#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729026599411225075#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:37:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谢谢</p>
<p><a href="https://nitter.cz/Nag1ovo/status/1729018702048493634#m">nitter.cz/Nag1ovo/status/1729018702048493634#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728998748272156761#m</id>
            <title>R to @dotey: 相应的GitHub项目：https://github.com/SurviveSJTU/SJTU-Application</title>
            <link>https://nitter.cz/dotey/status/1728998748272156761#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728998748272156761#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:46:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>相应的GitHub项目：<a href="https://github.com/SurviveSJTU/SJTU-Application">github.com/SurviveSJTU/SJTU-…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNzQ2NzQ2MzM3NjMwMjA4MC9uaEdRYmZRRD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728997603847675923#m</id>
            <title>推荐GitBook：
https://survivesjtu.gitbook.io/survivesjtumanual/

于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</title>
            <link>https://nitter.cz/dotey/status/1728997603847675923#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728997603847675923#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:42:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐GitBook：<上海交通大学生存手册><br />
<a href="https://survivesjtu.gitbook.io/survivesjtumanual/">survivesjtu.gitbook.io/survi…</a><br />
<br />
<上海交通大学生存手册>于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82aUl1SldRQUFwblExLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728976294195429627#m</id>
            <title>R to @dotey: ## Summary so far

构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。

Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。

## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard

在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。

关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选

部分形成最优答案，或者让模型帮助检查工作。

在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</title>
            <link>https://nitter.cz/dotey/status/1728976294195429627#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728976294195429627#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:17:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## Summary so far<br />
<br />
构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。<br />
<br />
Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。<br />
<br />
## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard<br />
<br />
在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。<br />
<br />
关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选<br />
<br />
部分形成最优答案，或者让模型帮助检查工作。<br />
<br />
在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzU3MzY0MTU5MzY1MTMvcHUvaW1nL29uOVlkdzV1WTdGdkx5V2MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728974703895711948#m</id>
            <title>R to @dotey: ## How do they work?

好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。

但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。

我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。

这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。

它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要

相应的复杂评估来处理这些模型，因为它们主要是基于经验的。

## Finetuning into an Assistant

现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。

获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”

接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。

所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。

这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</title>
            <link>https://nitter.cz/dotey/status/1728974703895711948#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728974703895711948#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:11:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## How do they work?<br />
<br />
好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。<br />
<br />
但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。<br />
<br />
我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。<br />
<br />
这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。<br />
<br />
它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要<br />
<br />
相应的复杂评估来处理这些模型，因为它们主要是基于经验的。<br />
<br />
## Finetuning into an Assistant<br />
<br />
现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。<br />
<br />
获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”<br />
<br />
接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。<br />
<br />
所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。<br />
<br />
这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzM4NzQ4MzY5NzE1MjAvcHUvaW1nL0wxZHl1ZFRFTDM5SFB2NmsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</id>
            <title>RT by @dotey: Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章

Loom基于GPT-3，采用了一种独特的树形结构来组织文本。

每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

举例解释：

假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。

1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。

2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。

3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。

4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。

6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。

通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。

Loom的主要特点和功能包括：

1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。

2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。

3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。

4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。

5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。

6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。

5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。

GitHub：https://github.com/socketteer/loom
实例：https://generative.ink/meta/block-multiverse/</title>
            <link>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728963473152045089#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章<br />
<br />
Loom基于GPT-3，采用了一种独特的树形结构来组织文本。<br />
<br />
每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
举例解释：<br />
<br />
假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。<br />
<br />
1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。<br />
<br />
2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。<br />
<br />
3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。<br />
<br />
4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。<br />
<br />
6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。<br />
<br />
通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。<br />
<br />
Loom的主要特点和功能包括：<br />
<br />
1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。<br />
<br />
2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。<br />
<br />
3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。<br />
<br />
4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。<br />
<br />
5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。<br />
<br />
6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。<br />
<br />
5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。<br />
<br />
GitHub：<a href="https://github.com/socketteer/loom">github.com/socketteer/loom</a><br />
实例：<a href="https://generative.ink/meta/block-multiverse/">generative.ink/meta/block-mu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRV2JjQUF6dFY4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRMmJjQUFtSzZILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhReWE0QUFKZ2NLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRd2FjQUFRa2t3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</id>
            <title>RT by @dotey: UIDraw：在手机上画草图，自动生成H5页面
一个SwiftUI项目，使用GPT-4V实现写HTML界面。
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。
Github：https://github.com/jordansinger/UIDraw</title>
            <link>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:25:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>UIDraw：在手机上画草图，自动生成H5页面<br />
一个SwiftUI项目，使用GPT-4V实现写HTML界面。<br />
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。<br />
Github：<a href="https://github.com/jordansinger/UIDraw">github.com/jordansinger/UIDr…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjMxMjg4ODM2MDU1MDQvcHUvaW1nLzRFbEx2WGJEeHlYYUtiUGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728962389830238296#m</id>
            <title>R to @dotey: ## LLM Training

但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。

因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。

你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。

但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。

这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。

那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。

你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个

词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。

所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。

我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。

## LLM Dreams

那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。

可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。

比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。

但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</title>
            <link>https://nitter.cz/dotey/status/1728962389830238296#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728962389830238296#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:22:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## LLM Training<br />
<br />
但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。<br />
<br />
因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。<br />
<br />
你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。<br />
<br />
但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。<br />
<br />
这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。<br />
<br />
那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。<br />
<br />
你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个<br />
<br />
词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。<br />
<br />
所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。<br />
<br />
我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。<br />
<br />
## LLM Dreams<br />
<br />
那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。<br />
<br />
可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。<br />
<br />
比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。<br />
<br />
但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjE4MTc2MjIyNDEyODEvcHUvaW1nL3pCck1GN1Vzenpnc0RNNm8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>