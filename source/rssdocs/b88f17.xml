<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729178839191081077#m</id>
            <title>核心就是得做中学</title>
            <link>https://nitter.cz/dotey/status/1729178839191081077#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729178839191081077#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:42:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>核心就是得做中学</p>
<p><a href="https://nitter.cz/gdb/status/1729162836499472734#m">nitter.cz/gdb/status/1729162836499472734#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729172682758054147#m</id>
            <title>RT by @dotey: Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。
将这种方法扩展是否能实现通用人工智能（AGI）？不会。
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</title>
            <link>https://nitter.cz/op7418/status/1729172682758054147#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729172682758054147#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:17:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：<br />
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。<br />
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。<br />
将这种方法扩展是否能实现通用人工智能（AGI）？不会。<br />
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。<br />
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</p>
<p><a href="https://nitter.cz/DrJimFan/status/1729162728072433876#m">nitter.cz/DrJimFan/status/1729162728072433876#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</id>
            <title>RT by @dotey: 建议和这篇《为什么你不该加入 Y Combinator》https://readit.vip/a/e0Bwj  一起阅读。

作者反对保罗这种只以增长为目标的做法。

1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</title>
            <link>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</link>
            <guid isPermaLink="false">https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 13:57:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>建议和这篇《为什么你不该加入 Y Combinator》<a href="https://readit.vip/a/e0Bwj">readit.vip/a/e0Bwj</a>  一起阅读。<br />
<br />
作者反对保罗这种只以增长为目标的做法。<br />
<br />
1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。<br />
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZXRtdmFrQUFMRFBtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZnFEcWJnQUFhMGJ2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Tisoga/status/1729017824092549247#m</id>
            <title>RT by @dotey: 这应该就是做产品最希望收到的评价吧。

另外 http://devv.ai 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。

欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</title>
            <link>https://nitter.cz/Tisoga/status/1729017824092549247#m</link>
            <guid isPermaLink="false">https://nitter.cz/Tisoga/status/1729017824092549247#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:02:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这应该就是做产品最希望收到的评价吧。<br />
<br />
另外 <a href="http://devv.ai">devv.ai</a> 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。<br />
<br />
欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82ejBRVmIwQUFYUDAzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729026599411225075#m</id>
            <title>R to @dotey: 谢谢</title>
            <link>https://nitter.cz/dotey/status/1729026599411225075#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729026599411225075#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:37:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谢谢</p>
<p><a href="https://nitter.cz/Nag1ovo/status/1729018702048493634#m">nitter.cz/Nag1ovo/status/1729018702048493634#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728998748272156761#m</id>
            <title>R to @dotey: 相应的GitHub项目：https://github.com/SurviveSJTU/SJTU-Application</title>
            <link>https://nitter.cz/dotey/status/1728998748272156761#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728998748272156761#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:46:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>相应的GitHub项目：<a href="https://github.com/SurviveSJTU/SJTU-Application">github.com/SurviveSJTU/SJTU-…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNzQ2NzQ2MzM3NjMwMjA4MC9uaEdRYmZRRD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728997603847675923#m</id>
            <title>推荐GitBook：
https://survivesjtu.gitbook.io/survivesjtumanual/

于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</title>
            <link>https://nitter.cz/dotey/status/1728997603847675923#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728997603847675923#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:42:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐GitBook：<上海交通大学生存手册><br />
<a href="https://survivesjtu.gitbook.io/survivesjtumanual/">survivesjtu.gitbook.io/survi…</a><br />
<br />
<上海交通大学生存手册>于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82aUl1SldRQUFwblExLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728976294195429627#m</id>
            <title>R to @dotey: ## Summary so far

构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。

Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。

## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard

在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。

关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选

部分形成最优答案，或者让模型帮助检查工作。

在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</title>
            <link>https://nitter.cz/dotey/status/1728976294195429627#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728976294195429627#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:17:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## Summary so far<br />
<br />
构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。<br />
<br />
Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。<br />
<br />
## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard<br />
<br />
在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。<br />
<br />
关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选<br />
<br />
部分形成最优答案，或者让模型帮助检查工作。<br />
<br />
在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzU3MzY0MTU5MzY1MTMvcHUvaW1nL29uOVlkdzV1WTdGdkx5V2MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728974703895711948#m</id>
            <title>R to @dotey: ## How do they work?

好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。

但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。

我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。

这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。

它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要

相应的复杂评估来处理这些模型，因为它们主要是基于经验的。

## Finetuning into an Assistant

现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。

获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”

接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。

所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。

这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</title>
            <link>https://nitter.cz/dotey/status/1728974703895711948#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728974703895711948#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:11:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## How do they work?<br />
<br />
好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。<br />
<br />
但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。<br />
<br />
我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。<br />
<br />
这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。<br />
<br />
它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要<br />
<br />
相应的复杂评估来处理这些模型，因为它们主要是基于经验的。<br />
<br />
## Finetuning into an Assistant<br />
<br />
现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。<br />
<br />
获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”<br />
<br />
接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。<br />
<br />
所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。<br />
<br />
这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzM4NzQ4MzY5NzE1MjAvcHUvaW1nL0wxZHl1ZFRFTDM5SFB2NmsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</id>
            <title>RT by @dotey: Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章

Loom基于GPT-3，采用了一种独特的树形结构来组织文本。

每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

举例解释：

假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。

1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。

2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。

3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。

4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。

6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。

通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。

Loom的主要特点和功能包括：

1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。

2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。

3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。

4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。

5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。

6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。

5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。

GitHub：https://github.com/socketteer/loom
实例：https://generative.ink/meta/block-multiverse/</title>
            <link>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728963473152045089#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章<br />
<br />
Loom基于GPT-3，采用了一种独特的树形结构来组织文本。<br />
<br />
每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
举例解释：<br />
<br />
假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。<br />
<br />
1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。<br />
<br />
2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。<br />
<br />
3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。<br />
<br />
4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。<br />
<br />
6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。<br />
<br />
通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。<br />
<br />
Loom的主要特点和功能包括：<br />
<br />
1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。<br />
<br />
2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。<br />
<br />
3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。<br />
<br />
4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。<br />
<br />
5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。<br />
<br />
6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。<br />
<br />
5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。<br />
<br />
GitHub：<a href="https://github.com/socketteer/loom">github.com/socketteer/loom</a><br />
实例：<a href="https://generative.ink/meta/block-multiverse/">generative.ink/meta/block-mu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRV2JjQUF6dFY4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRMmJjQUFtSzZILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhReWE0QUFKZ2NLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRd2FjQUFRa2t3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</id>
            <title>RT by @dotey: UIDraw：在手机上画草图，自动生成H5页面
一个SwiftUI项目，使用GPT-4V实现写HTML界面。
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。
Github：https://github.com/jordansinger/UIDraw</title>
            <link>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:25:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>UIDraw：在手机上画草图，自动生成H5页面<br />
一个SwiftUI项目，使用GPT-4V实现写HTML界面。<br />
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。<br />
Github：<a href="https://github.com/jordansinger/UIDraw">github.com/jordansinger/UIDr…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjMxMjg4ODM2MDU1MDQvcHUvaW1nLzRFbEx2WGJEeHlYYUtiUGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728962389830238296#m</id>
            <title>R to @dotey: ## LLM Training

但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。

因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。

你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。

但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。

这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。

那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。

你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个

词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。

所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。

我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。

## LLM Dreams

那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。

可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。

比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。

但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</title>
            <link>https://nitter.cz/dotey/status/1728962389830238296#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728962389830238296#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:22:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## LLM Training<br />
<br />
但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。<br />
<br />
因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。<br />
<br />
你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。<br />
<br />
但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。<br />
<br />
这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。<br />
<br />
那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。<br />
<br />
你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个<br />
<br />
词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。<br />
<br />
所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。<br />
<br />
我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。<br />
<br />
## LLM Dreams<br />
<br />
那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。<br />
<br />
可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。<br />
<br />
比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。<br />
<br />
但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjE4MTc2MjIyNDEyODEvcHUvaW1nL3pCck1GN1Vzenpnc0RNNm8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728959646138880026#m</id>
            <title>OpenAI 的大神 Andrej Karpathy 前几天在他的 YouTube 频道讲了一堂课，系统的介绍了大语言模型，内容深入浅出，非常赞，抽空将它翻译成了双语，由于内容较长，我将分批上传，以下是第一部分精校后的双语视频，字幕文稿如下：

Intro: Large Language Model (LLM) talk

大家好。最近，我进行了一场关于大语言模型的 30 分钟入门讲座。遗憾的是，这次讲座没有被录制下来，但许多人在讲座后找到我，他们告诉我非常喜欢那次讲座。因此，我决定重新录制并上传到 YouTube，那么，让我们开始吧，为大家带来“忙碌人士的大语言模型入门”系列，主讲人 Scott。好的，那我们开始吧。

LLM Inference

首先，什么是大语言模型 (Large Language Model) 呢？其实，一个大语言模型就是由两个文件组成的。在这个假设的目录中会有两个文件。

以 Llama 2 70B 模型为例，这是一个由 Meta AI 发布的大语言模型。这是 Llama 系列语言模型的第二代，也是该系列中参数最多的模型，达到了 700 亿。LAMA2 系列包括了多个不同规模的模型，70 亿，130 亿，340 亿，700 亿是最大的一个。

现在很多人喜欢这个模型，因为它可能是目前公开权重最强大的模型。Meta 发布了这款模型的权重、架构和相关论文，所以任何人都可以很轻松地使用这个模型。这与其他一些你可能熟悉的语言模型不同，例如，如果你正在使用 ChatGPT 或类似的东西，其架构并未公开，是 OpenAI 的产权，你只能通过网页界面使用，但你实际上没有访问那个模型的权限。

在这种情况下，Llama 2 70B 模型实际上就是你电脑上的两个文件：一个是存储参数的文件，另一个是运行这些参数的代码。这些参数是神经网络（即语言模型）的权重或参数。我们稍后会详细解释。因为这是一个拥有 700 亿参数的模型，每个参数占用两个字节，因此参数文件的大小为 140 GB，之所以是两个字节，是因为这是 float 16 类型的数据。

除了这些参数，还有一大堆神经网络的参数。你还需要一些能运行神经网络的代码，这些代码被包含在我们所说的运行文件中。这个运行文件可以是 C 语言或 Python，或任何其他编程语言编写的。它可以用任何语言编写，但 C 语言是一种非常简单的语言，只是举个例子。只需大约 500 行 C 语言代码，无需任何其他依赖，就能构建起神经网络架构，并且主要依靠一些参数来运行模型。所以只需要这两个文件。

你只需带上这两个文件和你的 MacBook，就拥有了一个完整的工具包。你不需要连接互联网或其他任何设备。你可以拿着这两个文件，编译你的 C 语言代码。你将得到一个可针对参数运行并与语言模型交互的二进制文件。

比如，你可以让它写一首关于 Scale AI 公司的诗，语言模型就会开始生成文本。在这种情况下，它会按照指示为你创作一首关于 Scale AI 的诗。之所以选用 Scale AI 作为例子，你会在整个演讲中看到，是因为我最初在 Scale AI 举办的活动上介绍过这个话题，所以演讲中会多次提到它，以便内容更具体。这就是我们如何运行模型的方式。只需要两个文件和一台 MacBook。

我在这里稍微有点作弊，因为这并不是在运行一个有 700 亿参数的模型，而是在运行一个有 70 亿参数的模型。一个有 700 亿参数的模型运行速度大约会慢 10 倍。但我想给你们展示一下文本生成的过程，让你们了解它是什么样子。所以运行模型并不需要很多东西。这是一个非常小的程序包，但是当我们需要获取那些参数时，计算的复杂性就真正显现出来了。

那么，这些参数从何而来，我们如何获得它们？因为无论 run.c 文件中的内容是什么，神经网络的架构和前向传播都是算法上明确且公开的。</title>
            <link>https://nitter.cz/dotey/status/1728959646138880026#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728959646138880026#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:11:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 的大神 Andrej Karpathy 前几天在他的 YouTube 频道讲了一堂课，系统的介绍了大语言模型，内容深入浅出，非常赞，抽空将它翻译成了双语，由于内容较长，我将分批上传，以下是第一部分精校后的双语视频，字幕文稿如下：<br />
<br />
Intro: Large Language Model (LLM) talk<br />
<br />
大家好。最近，我进行了一场关于大语言模型的 30 分钟入门讲座。遗憾的是，这次讲座没有被录制下来，但许多人在讲座后找到我，他们告诉我非常喜欢那次讲座。因此，我决定重新录制并上传到 YouTube，那么，让我们开始吧，为大家带来“忙碌人士的大语言模型入门”系列，主讲人 Scott。好的，那我们开始吧。<br />
<br />
LLM Inference<br />
<br />
首先，什么是大语言模型 (Large Language Model) 呢？其实，一个大语言模型就是由两个文件组成的。在这个假设的目录中会有两个文件。<br />
<br />
以 Llama 2 70B 模型为例，这是一个由 Meta AI 发布的大语言模型。这是 Llama 系列语言模型的第二代，也是该系列中参数最多的模型，达到了 700 亿。LAMA2 系列包括了多个不同规模的模型，70 亿，130 亿，340 亿，700 亿是最大的一个。<br />
<br />
现在很多人喜欢这个模型，因为它可能是目前公开权重最强大的模型。Meta 发布了这款模型的权重、架构和相关论文，所以任何人都可以很轻松地使用这个模型。这与其他一些你可能熟悉的语言模型不同，例如，如果你正在使用 ChatGPT 或类似的东西，其架构并未公开，是 OpenAI 的产权，你只能通过网页界面使用，但你实际上没有访问那个模型的权限。<br />
<br />
在这种情况下，Llama 2 70B 模型实际上就是你电脑上的两个文件：一个是存储参数的文件，另一个是运行这些参数的代码。这些参数是神经网络（即语言模型）的权重或参数。我们稍后会详细解释。因为这是一个拥有 700 亿参数的模型，每个参数占用两个字节，因此参数文件的大小为 140 GB，之所以是两个字节，是因为这是 float 16 类型的数据。<br />
<br />
除了这些参数，还有一大堆神经网络的参数。你还需要一些能运行神经网络的代码，这些代码被包含在我们所说的运行文件中。这个运行文件可以是 C 语言或 Python，或任何其他编程语言编写的。它可以用任何语言编写，但 C 语言是一种非常简单的语言，只是举个例子。只需大约 500 行 C 语言代码，无需任何其他依赖，就能构建起神经网络架构，并且主要依靠一些参数来运行模型。所以只需要这两个文件。<br />
<br />
你只需带上这两个文件和你的 MacBook，就拥有了一个完整的工具包。你不需要连接互联网或其他任何设备。你可以拿着这两个文件，编译你的 C 语言代码。你将得到一个可针对参数运行并与语言模型交互的二进制文件。<br />
<br />
比如，你可以让它写一首关于 Scale AI 公司的诗，语言模型就会开始生成文本。在这种情况下，它会按照指示为你创作一首关于 Scale AI 的诗。之所以选用 Scale AI 作为例子，你会在整个演讲中看到，是因为我最初在 Scale AI 举办的活动上介绍过这个话题，所以演讲中会多次提到它，以便内容更具体。这就是我们如何运行模型的方式。只需要两个文件和一台 MacBook。<br />
<br />
我在这里稍微有点作弊，因为这并不是在运行一个有 700 亿参数的模型，而是在运行一个有 70 亿参数的模型。一个有 700 亿参数的模型运行速度大约会慢 10 倍。但我想给你们展示一下文本生成的过程，让你们了解它是什么样子。所以运行模型并不需要很多东西。这是一个非常小的程序包，但是当我们需要获取那些参数时，计算的复杂性就真正显现出来了。<br />
<br />
那么，这些参数从何而来，我们如何获得它们？因为无论 run.c 文件中的内容是什么，神经网络的架构和前向传播都是算法上明确且公开的。</p>
<p><a href="https://nitter.cz/karpathy/status/1727731541781152035#m">nitter.cz/karpathy/status/1727731541781152035#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NTg2NTQ5Nzg2NjI0MDIvcHUvaW1nL096ak1ReDBBU0JqM29IUkYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728913073388368146#m</id>
            <title>转译：人工智能本身并非危险的根源，关键在于掌控它的人

by Kenan Malik

OpenAI 的混乱事件揭示了我们对待科技的矛盾心态

这起事件的发展有时让人联想到 Fawlty Towers，而不是 Succession，更像是一出劳莱和哈代的闹剧，而不是莎士比亚式的悲剧。OpenAI 凭借其知名产品 聊天机器人 ChatGPT 成为当下科技界的焦点。上周，关于 Sam Altman 被撤销 CEO 职位解雇及随后的重新聘用成为全球媒体热议的话题，引发了广泛的惊奇和困惑。

一些人认为这场闹剧反映了董事会的不称职；另一些人则看到了巨大自我间的冲突。更深层次地，这次动荡折射出科技行业的诸多内在矛盾：一方面是技术企业家自封的“颠覆者”形象，另一方面则是他们控制着影响我们每个人生活的价值数十亿美元的巨型产业。同样存在的还有人工智能作为改变人类生活的工具与其可能成为人类生存威胁的双重视角。

在这些矛盾中，几乎没有哪个组织比 OpenAI 更具代表性。Elon Musk、Peter Thiel 等硅谷知名人士于 2015 年创立了这个组织，他们既是人工智能的倡导者，也是对其潜在威胁发出警告的先锋。Elon Musk 曾沉重地宣称：“通过人工智能，我们似乎在召唤一只恶魔。”

科技界巨头们对自己作为未来的征服者的无限自尊，加上对他人和社会深深的悲观情绪，使得他们对世界末日即将降临的恐惧几乎成为了默认状态。其中许多人已经成为了“预备者”，为可能出现的疯狂麦克斯式世界做好了准备。Altman 在 OpenAI 刚成立时向《纽约客》透露：“我有枪械、黄金、碘化钾、抗生素、电池、水、以色列国防军的防毒面具，还有位于 Big Sur 的一大块可以飞去的土地。”他认为，最优秀的企业家，“极度偏执，常常面临生存危机”，当然，对 AI 的担忧也在所难免。

OpenAI 的初衷是作为一个非盈利的慈善组织，旨在开发人工通用智能（AGI），简而言之，就是能够完成或超越人类所有智力任务的机器。但它的目标是以一种道德的方式造福“全人类”。

然后，到了 2019 年，这个慈善机构成立了一个盈利子公司，以筹集更多投资，最终从 Microsoft 那里募集了超过 110 亿美元（约 87 亿英镑）。尽管如此，非盈利的母公司仍然保持着完全的控制权，这就形成了追求利润与对其产品可能带来的世界末日担忧之间的张力。ChatGPT 的巨大成功进一步加剧了这种紧张关系。

两年前，一些 OpenAI 的研究人员离开去创建了一个新机构 Anthropic，因为他们担心自己原公司 AI 的发展速度过快。其中一位后来对记者表示：“在未来十年内，一个失控的 AI 毁灭人类的可能性高达 20%”。似乎是这种同样的恐惧促成了对 Altman 的排挤以及过去一周的董事会混乱。

我们可能会好奇，为什么人类会持续研发可能威胁到人类生命的机器。但讽刺的是，尽管人们对 AI 的恐惧有些夸张，这种恐惧本身却带来了新的危险。对 AI 的过度警惕源于对其能力的高估。ChatGPT 在预测文字序列的下一个词方面表现得非常出色，以至于我们误以为它能像真人一样进行交流。然而，它并不能像人类那样真正理解这些词汇的含义，对现实世界的了解也微乎其微。我们距离实现“人工通用智能 (AGI)”的梦想还有很长的路要走。“AGI 不会在短期内出现”，IBM 软件工程首席科学家 Grady Booch 指出，即使是在我们的后代子孙的一生中也不太可能实现。

对于那些认为 AGI 即将成为现实的硅谷人士来说，他们认为应通过“对齐”来保护人类，即确保 AI 符合人类的价值观和意图。这看似是一种理性的方式，可以减轻 AI 可能带来的伤害。但当我们开始探讨“人类价值”究竟是什么、谁来定义它们，以及在价值观冲突时该如何应对时，问题就变得复杂了。

社会价值观总是众说纷纭，尤其是在当今这个社会共识标准瓦解、普遍不满情绪高涨的时代。我们与技术的关系本身就引发了热烈的讨论。对一些人来说，限制网络仇恨或保护人们免受网络伤害比维护言论自由或隐私权更为重要。这正是英国最新在线安全法案的出发点。这也是许多人对这项法律可能带来的后果感到担忧的原因。

接下来是虚假信息的问题。几乎没人会质疑虚假信息是一个日益严重的问题，它对民主和信任提出了挑战。但如何应对这一问题，依然存在很大争议。尤其是许多管理虚假信息的尝试，最终增强了科技公司监管公众的能力。

同时，算法偏见这一议题也揭示了对“价值对齐”观点的弱点。算法容易对少数群体产生偏见，原因正是它们过于贴合人类价值观。AI 程序是基于充满歧视的人类世界数据训练而成的。这些偏见也渗透到 AI 软件中，不论是在刑事司法系统、医疗保健、面部识别还是招聘等领域。

我们面临的问题并非机器将来可能对人类行使权力——这种看法基于目前的发展是无依据的猜测。真正的问题在于，我们生活在一个少数人利用权力损害多数人的社会，而技术成为了巩固这种权力的工具。对于掌握社会、政治和经济权力的人来说，将问题描绘为技术问题而非社会问题，把问题推到未来而非现在，似乎更合理。

几乎所有对人类有益的工具也可能造成伤害。但它们很少自行造成伤害，更多是因为被人类，尤其是那些掌权者，错误使用。这才是我们讨论 AI 时应当关注的起点，而非那些关于人类灭绝的虚构恐惧。

https://www.theguardian.com/commentisfree/2023/nov/26/artificial-intelligence-harm-worry-about-people-control-openai</title>
            <link>https://nitter.cz/dotey/status/1728913073388368146#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728913073388368146#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 23:06:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：人工智能本身并非危险的根源，关键在于掌控它的人<br />
<br />
by Kenan Malik<br />
<br />
OpenAI 的混乱事件揭示了我们对待科技的矛盾心态<br />
<br />
这起事件的发展有时让人联想到 Fawlty Towers，而不是 Succession，更像是一出劳莱和哈代的闹剧，而不是莎士比亚式的悲剧。OpenAI 凭借其知名产品 聊天机器人 ChatGPT 成为当下科技界的焦点。上周，关于 Sam Altman 被撤销 CEO 职位解雇及随后的重新聘用成为全球媒体热议的话题，引发了广泛的惊奇和困惑。<br />
<br />
一些人认为这场闹剧反映了董事会的不称职；另一些人则看到了巨大自我间的冲突。更深层次地，这次动荡折射出科技行业的诸多内在矛盾：一方面是技术企业家自封的“颠覆者”形象，另一方面则是他们控制着影响我们每个人生活的价值数十亿美元的巨型产业。同样存在的还有人工智能作为改变人类生活的工具与其可能成为人类生存威胁的双重视角。<br />
<br />
在这些矛盾中，几乎没有哪个组织比 OpenAI 更具代表性。Elon Musk、Peter Thiel 等硅谷知名人士于 2015 年创立了这个组织，他们既是人工智能的倡导者，也是对其潜在威胁发出警告的先锋。Elon Musk 曾沉重地宣称：“通过人工智能，我们似乎在召唤一只恶魔。”<br />
<br />
科技界巨头们对自己作为未来的征服者的无限自尊，加上对他人和社会深深的悲观情绪，使得他们对世界末日即将降临的恐惧几乎成为了默认状态。其中许多人已经成为了“预备者”，为可能出现的疯狂麦克斯式世界做好了准备。Altman 在 OpenAI 刚成立时向《纽约客》透露：“我有枪械、黄金、碘化钾、抗生素、电池、水、以色列国防军的防毒面具，还有位于 Big Sur 的一大块可以飞去的土地。”他认为，最优秀的企业家，“极度偏执，常常面临生存危机”，当然，对 AI 的担忧也在所难免。<br />
<br />
OpenAI 的初衷是作为一个非盈利的慈善组织，旨在开发人工通用智能（AGI），简而言之，就是能够完成或超越人类所有智力任务的机器。但它的目标是以一种道德的方式造福“全人类”。<br />
<br />
然后，到了 2019 年，这个慈善机构成立了一个盈利子公司，以筹集更多投资，最终从 Microsoft 那里募集了超过 110 亿美元（约 87 亿英镑）。尽管如此，非盈利的母公司仍然保持着完全的控制权，这就形成了追求利润与对其产品可能带来的世界末日担忧之间的张力。ChatGPT 的巨大成功进一步加剧了这种紧张关系。<br />
<br />
两年前，一些 OpenAI 的研究人员离开去创建了一个新机构 Anthropic，因为他们担心自己原公司 AI 的发展速度过快。其中一位后来对记者表示：“在未来十年内，一个失控的 AI 毁灭人类的可能性高达 20%”。似乎是这种同样的恐惧促成了对 Altman 的排挤以及过去一周的董事会混乱。<br />
<br />
我们可能会好奇，为什么人类会持续研发可能威胁到人类生命的机器。但讽刺的是，尽管人们对 AI 的恐惧有些夸张，这种恐惧本身却带来了新的危险。对 AI 的过度警惕源于对其能力的高估。ChatGPT 在预测文字序列的下一个词方面表现得非常出色，以至于我们误以为它能像真人一样进行交流。然而，它并不能像人类那样真正理解这些词汇的含义，对现实世界的了解也微乎其微。我们距离实现“人工通用智能 (AGI)”的梦想还有很长的路要走。“AGI 不会在短期内出现”，IBM 软件工程首席科学家 Grady Booch 指出，即使是在我们的后代子孙的一生中也不太可能实现。<br />
<br />
对于那些认为 AGI 即将成为现实的硅谷人士来说，他们认为应通过“对齐”来保护人类，即确保 AI 符合人类的价值观和意图。这看似是一种理性的方式，可以减轻 AI 可能带来的伤害。但当我们开始探讨“人类价值”究竟是什么、谁来定义它们，以及在价值观冲突时该如何应对时，问题就变得复杂了。<br />
<br />
社会价值观总是众说纷纭，尤其是在当今这个社会共识标准瓦解、普遍不满情绪高涨的时代。我们与技术的关系本身就引发了热烈的讨论。对一些人来说，限制网络仇恨或保护人们免受网络伤害比维护言论自由或隐私权更为重要。这正是英国最新在线安全法案的出发点。这也是许多人对这项法律可能带来的后果感到担忧的原因。<br />
<br />
接下来是虚假信息的问题。几乎没人会质疑虚假信息是一个日益严重的问题，它对民主和信任提出了挑战。但如何应对这一问题，依然存在很大争议。尤其是许多管理虚假信息的尝试，最终增强了科技公司监管公众的能力。<br />
<br />
同时，算法偏见这一议题也揭示了对“价值对齐”观点的弱点。算法容易对少数群体产生偏见，原因正是它们过于贴合人类价值观。AI 程序是基于充满歧视的人类世界数据训练而成的。这些偏见也渗透到 AI 软件中，不论是在刑事司法系统、医疗保健、面部识别还是招聘等领域。<br />
<br />
我们面临的问题并非机器将来可能对人类行使权力——这种看法基于目前的发展是无依据的猜测。真正的问题在于，我们生活在一个少数人利用权力损害多数人的社会，而技术成为了巩固这种权力的工具。对于掌握社会、政治和经济权力的人来说，将问题描绘为技术问题而非社会问题，把问题推到未来而非现在，似乎更合理。<br />
<br />
几乎所有对人类有益的工具也可能造成伤害。但它们很少自行造成伤害，更多是因为被人类，尤其是那些掌权者，错误使用。这才是我们讨论 AI 时应当关注的起点，而非那些关于人类灭绝的虚构恐惧。<br />
<br />
<a href="https://www.theguardian.com/commentisfree/2023/nov/26/artificial-intelligence-harm-worry-about-people-control-openai">theguardian.com/commentisfre…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl81Vk9pa1hFQUEtUGhSLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1728805500702105959#m</id>
            <title>RT by @dotey: 在测试 Yi-34B-Chat-4Bits，确实能力上秒杀了一众10B模型。

通过vLLM 可以在4090上提供33 tokens/s 生成速度，3 并发稳定生成速度100tokens/s。

从ceval 开发集中挑选最难的数学等，打乱答案顺序后评测。（肯定在训练集中，会高估）

Qwen-14B-4bits 34.5%，yi是 52.7%。</title>
            <link>https://nitter.cz/9hills/status/1728805500702105959#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1728805500702105959#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 15:58:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在测试 Yi-34B-Chat-4Bits，确实能力上秒杀了一众10B模型。<br />
<br />
通过vLLM 可以在4090上提供33 tokens/s 生成速度，3 并发稳定生成速度100tokens/s。<br />
<br />
从ceval 开发集中挑选最难的数学等，打乱答案顺序后评测。（肯定在训练集中，会高估）<br />
<br />
Qwen-14B-4bits 34.5%，yi是 52.7%。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728820432613052859#m</id>
            <title>杨立昆（Yann LeCun）在《AI: Grappling with a New Kind of Intelligence》上的精彩发言：

这里有一个关键问题。

毫无疑问，未来或许在几十年后，我们将拥有智能与人类媲美的人工智能（AI）系统。这些系统不仅在特定领域专业化，而且在人类擅长的所有领域都可能比人类更聪明。
你可能会担心，这样的系统会不会掌控世界。其实，智能与控制欲之间并无必然联系。以人类为例，虽然有些人有控制欲，但并非所有人都是如此，而且通常不是最聪明的人才有控制欲。国际政治舞台上的种种事件每天都在证明这一点。这背后可能有进化上的原因：不够聪明的人需要依赖他人，因此会试图影响他人；而聪明的人可以独立生存。

再来看第二个观点，我们其实已经习惯了与比自己聪明的人合作。就我个人经验，我曾领导一个研究实验室，而我只雇佣比我聪明的人。与比你更聪明的人共事其实是一种美妙的经历。想象一下未来10到20年，我们会有人工智能助手在日常生活中协助我们，他们可能比我们更聪明。但他们的存在是为了让我们变得更聪明，我们指导它们，它们服务于我们。智能本身并不意味着渴望控制。

这种控制欲其实源于我们作为社会性物种的本性。作为社会性物种，我们需要影响他人，这就产生了控制和服从的概念。我们像黑猩猩、狒狒、狼等其他社会性动物一样，有着等级制的社会组织。这是进化赋予我们的特征。而像猩猩这样的非社会性物种，即便智力接近人类，也没有控制他人的渴望。所以，智能与控制欲是两码事。我们完全可以设计一个极为智能但不具备控制欲的系统。

关于这些系统的设计，它们会非常聪明，也就是说，你给它们一个目标，它们可以帮你实现这个目标。但设定目标的是我们，人类。这些系统会制定子目标，但如何实现这一技术问题还未解决，这仍然是我们对未来的设想。

再想象一下，如果未来我们与数字世界和信息世界的所有互动都通过人工智能代理来完成，这些代理将成为所有人类知识的宝库，类似于一个能进行对话和推理的“超级维基百科”。这将成为一个像现在的互联网一样的公共平台，它必须是开放的，不能是专有的，因为掌握在少数公司手中的超级智能AI将是非常危险的。想象一下，如果少数几家公司控制着这些超级智能AI，他们可以左右每个人的观点、文化等等。或许美国政府会接受这种情况，但全世界的其他政府绝不会同意。他们不会希望自己的文化被美国文化所主导。因此，他们将不得不开发自己的大语言模型（LLM）。

唯一的解决方案是基于开源的基础架构。这就是 Meta 开源 La Maute 2的原因之一，因为它是基础设施的一部分。此前，Meta 还发布了用于构建人工智能系统的软件系统 PyTorch，而 ChatGPT 就是基于 PyTorch 构建的。因此，这些系统必须是开源的，并且它们的训练方式也必须是众包的，以确保它们成为所有人类知识的仓库。这意味着所有人都必须对其做出贡献，而不仅仅是贡献给 openAI、Meta 或其他公司的专有系统。无论这听起来有多危险，这是未来的必然走向。

完整视频：https://www.youtube.com/watch?v=EGDG3hgPNp8</title>
            <link>https://nitter.cz/dotey/status/1728820432613052859#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728820432613052859#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 16:58:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>杨立昆（Yann LeCun）在《AI: Grappling with a New Kind of Intelligence》上的精彩发言：<br />
<br />
这里有一个关键问题。<br />
<br />
毫无疑问，未来或许在几十年后，我们将拥有智能与人类媲美的人工智能（AI）系统。这些系统不仅在特定领域专业化，而且在人类擅长的所有领域都可能比人类更聪明。<br />
你可能会担心，这样的系统会不会掌控世界。其实，智能与控制欲之间并无必然联系。以人类为例，虽然有些人有控制欲，但并非所有人都是如此，而且通常不是最聪明的人才有控制欲。国际政治舞台上的种种事件每天都在证明这一点。这背后可能有进化上的原因：不够聪明的人需要依赖他人，因此会试图影响他人；而聪明的人可以独立生存。<br />
<br />
再来看第二个观点，我们其实已经习惯了与比自己聪明的人合作。就我个人经验，我曾领导一个研究实验室，而我只雇佣比我聪明的人。与比你更聪明的人共事其实是一种美妙的经历。想象一下未来10到20年，我们会有人工智能助手在日常生活中协助我们，他们可能比我们更聪明。但他们的存在是为了让我们变得更聪明，我们指导它们，它们服务于我们。智能本身并不意味着渴望控制。<br />
<br />
这种控制欲其实源于我们作为社会性物种的本性。作为社会性物种，我们需要影响他人，这就产生了控制和服从的概念。我们像黑猩猩、狒狒、狼等其他社会性动物一样，有着等级制的社会组织。这是进化赋予我们的特征。而像猩猩这样的非社会性物种，即便智力接近人类，也没有控制他人的渴望。所以，智能与控制欲是两码事。我们完全可以设计一个极为智能但不具备控制欲的系统。<br />
<br />
关于这些系统的设计，它们会非常聪明，也就是说，你给它们一个目标，它们可以帮你实现这个目标。但设定目标的是我们，人类。这些系统会制定子目标，但如何实现这一技术问题还未解决，这仍然是我们对未来的设想。<br />
<br />
再想象一下，如果未来我们与数字世界和信息世界的所有互动都通过人工智能代理来完成，这些代理将成为所有人类知识的宝库，类似于一个能进行对话和推理的“超级维基百科”。这将成为一个像现在的互联网一样的公共平台，它必须是开放的，不能是专有的，因为掌握在少数公司手中的超级智能AI将是非常危险的。想象一下，如果少数几家公司控制着这些超级智能AI，他们可以左右每个人的观点、文化等等。或许美国政府会接受这种情况，但全世界的其他政府绝不会同意。他们不会希望自己的文化被美国文化所主导。因此，他们将不得不开发自己的大语言模型（LLM）。<br />
<br />
唯一的解决方案是基于开源的基础架构。这就是 Meta 开源 La Maute 2的原因之一，因为它是基础设施的一部分。此前，Meta 还发布了用于构建人工智能系统的软件系统 PyTorch，而 ChatGPT 就是基于 PyTorch 构建的。因此，这些系统必须是开源的，并且它们的训练方式也必须是众包的，以确保它们成为所有人类知识的仓库。这意味着所有人都必须对其做出贡献，而不仅仅是贡献给 openAI、Meta 或其他公司的专有系统。无论这听起来有多危险，这是未来的必然走向。<br />
<br />
完整视频：<a href="https://www.youtube.com/watch?v=EGDG3hgPNp8">youtube.com/watch?v=EGDG3hgP…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg4MjAwMjExMDk5MzYxMjgvcHUvaW1nL0RQOHdLdXpfc29MWHhMbTcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728651529102533076#m</id>
            <title>推荐阅读：一个失败的 AI 女友产品，以及我的教训：来自一位中国开发者的总结

摘录部分内容：

“11Labs 官网会记录语音合成的文字内容，我看到，Dolores 的回复内容通常都是一些成人内容，而且均为女性角色，因此我推测 Dolores 的付费用户主要是男性，对成人角色扮演感兴趣。”

“8 月份，OpenAI 的审查升级了，我收到了检测 Dolores 生成 NSFW 内容的邮件警告：我被强制要求在 2 周内在生成内容前，加入他们（免费的）moderation API，以过滤 NSFW 内容。为了顺利过审，我只能使用 OpenAI 的免费审核 API 提前进行内容过滤，而这一变化让 Dolores 的日均访问量暴跌 70%，电子邮件和 Twitter 上的投诉也纷至沓来。”

“首先，这不是一个个人能开发的产品。我不认为 Dolores 在“意识”层面上比 http://Character.AI 弱，但他们拥有完善的数据埋点、A/B 测试，以及大量用户带来的数据飞轮。

其次，我意识到当前的 AI Friend 会不可避免地变成 AI Girlfriend/Boyfriend，因为你和手机里的角色不对等：她没办法在你摔伤的时候安慰你 (除非你告诉他)，她没办法主动向你表达情绪，而这一切，都是因为她没有外部视觉。所以我认为，即使是 http://Character.AI 这样体量的产品，如果未来不做硬件、角色们都在傻傻地等用户来，最终的结局也不会比 Dolores 好到哪里。

最后，我不反对审查，相反，不经审查的的产品是非常危险的。我不知道是否会有人用它来进行自杀诱导、发泄暴力工具，所以 OpenAI 的 moderation 可能在某种程度帮助了我，但成人性方面的对话也不应该被扼杀。”

https://mp.weixin.qq.com/s/uDUAhxi9AWxt3fSYUmVIzg</title>
            <link>https://nitter.cz/dotey/status/1728651529102533076#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728651529102533076#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 05:46:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：一个失败的 AI 女友产品，以及我的教训：来自一位中国开发者的总结<br />
<br />
摘录部分内容：<br />
<br />
“11Labs 官网会记录语音合成的文字内容，我看到，Dolores 的回复内容通常都是一些成人内容，而且均为女性角色，因此我推测 Dolores 的付费用户主要是男性，对成人角色扮演感兴趣。”<br />
<br />
“8 月份，OpenAI 的审查升级了，我收到了检测 Dolores 生成 NSFW 内容的邮件警告：我被强制要求在 2 周内在生成内容前，加入他们（免费的）moderation API，以过滤 NSFW 内容。为了顺利过审，我只能使用 OpenAI 的免费审核 API 提前进行内容过滤，而这一变化让 Dolores 的日均访问量暴跌 70%，电子邮件和 Twitter 上的投诉也纷至沓来。”<br />
<br />
“首先，这不是一个个人能开发的产品。我不认为 Dolores 在“意识”层面上比 <a href="http://Character.AI">Character.AI</a> 弱，但他们拥有完善的数据埋点、A/B 测试，以及大量用户带来的数据飞轮。<br />
<br />
其次，我意识到当前的 AI Friend 会不可避免地变成 AI Girlfriend/Boyfriend，因为你和手机里的角色不对等：她没办法在你摔伤的时候安慰你 (除非你告诉他)，她没办法主动向你表达情绪，而这一切，都是因为她没有外部视觉。所以我认为，即使是 <a href="http://Character.AI">Character.AI</a> 这样体量的产品，如果未来不做硬件、角色们都在傻傻地等用户来，最终的结局也不会比 Dolores 好到哪里。<br />
<br />
最后，我不反对审查，相反，不经审查的的产品是非常危险的。我不知道是否会有人用它来进行自杀诱导、发泄暴力工具，所以 OpenAI 的 moderation 可能在某种程度帮助了我，但成人性方面的对话也不应该被扼杀。”<br />
<br />
<a href="https://mp.weixin.qq.com/s/uDUAhxi9AWxt3fSYUmVIzg">mp.weixin.qq.com/s/uDUAhxi9A…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8xblpkaVhjQUFVNEJzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728632847999631610#m</id>
            <title>“在那个充满活力的周末结束时，Altman 决定在这家科技巨擘里设立一个新的 AI 部门，好继续与 Nadella 合作，并充分利用 Microsoft 强大的计算资源。不久，成百上千的研究人员准备加入 Altman，投身于一个与众不同、魅力十足的公司。为了支持这些工程师们的研究，Microsoft 准备了一应俱全的资源：LinkedIn 办公楼的一整层、充裕的云计算资源和苹果笔记本电脑。更令人意外的是，这家价值万亿的公司向未来的同事保证，他们甚至不需要使用 Microsoft 的团队沟通应用 Teams。”

能不用 Teams 都成了谈判筹码了😄

以上内容来自华尔街日报：

OpenAI 事件中的最大赢家

作者：Ben Cohen，华尔街日报，2023年11月25日

摘要：微软首席执行官 Satya Nadella 对全球最火爆的 AI 公司 OpenAI 进行了重大投资。尽管这场事件一度将他置于风口浪尖，但现在他与 OpenAI 的领导人 Sam Altman 建立了更加密切的联系。

Satya Nadella 心绪难平。

作为微软的首席执行官，他本应全力以赴，专注于在硅谷历史上最为混乱的周末之一中挽救其珍贵的资产。但他的思绪不断被板球这项运动所吸引。

他无法全神贯注于关注自己祖国印度在板球世界杯中对抗澳大利亚的比赛，因为他发现自己正卷入了另一场更加激烈、风险更高的“游戏”中。即便在紧张的谈判和灾难应对中，Nadella 仍不时检查比分，向对板球不那么狂热的同事报告他最爱运动的最新动态。尽管他的团队处境艰难，但他的公司仍有转机。

这场令他难以忘怀的周末始于上周五。就在 OpenAI 的董事会突然罢免其联合创始人兼首席执行官 Sam Altman 的消息传遍全球前几分钟，Nadella 得知了这一消息。这家推出 ChatGPT 的公司曾寻求达到900亿美元的估值。如此短时间内，很少有董事会的决策能对如此巨大的价值造成如此严重的威胁。

虽然微软已为 OpenAI 的49%股份支付了数十亿美元，并利用其技术开发了一系列新一代软件，微软承诺这些软件将彻底改变工作方式，但作为这家初创公司最大的投资者，微软并未在董事会中占有一席之地。Nadella 几乎与全世界同时得知，他的这一投资——该投资几乎将微软独自推向了人工智能革命的前沿——突然面临困境。

然而，当董事会对 Altman 采取行动时，Altman 立刻联系了 Nadella。在上周五董事会突变的数小时后，他们通过电话讨论了如何让 Altman 重返 OpenAI 或加入微软的方案。如果 Altman 不能重返 OpenAI 的首席执行官职位，这位曾经在 AI 领域最为瞩目的公司的前首席执行官将加盟微软。

在那个充满活力的周末结束时，Altman 决定在这家科技巨擘里设立一个新的 AI 部门，好继续与 Nadella 合作，并充分利用 Microsoft 强大的计算资源。不久，成百上千的研究人员准备加入 Altman，投身于一个与众不同、魅力十足的公司。为了支持这些工程师们的研究，Microsoft 准备了一应俱全的资源：LinkedIn 办公楼的一整层、充裕的云计算资源和苹果笔记本电脑。更令人意外的是，这家价值万亿的公司向未来的同事保证，他们甚至不需要使用 Microsoft 的团队沟通应用 Teams。

然而，对 Microsoft 而言，最理想的结局是让 Altman 回归 OpenAI 担任 CEO。据了解 Nadella 的人士透露，通过向 OpenAI 团队敞开大门，Nadella 增强了 Altman 重回 CEO 位置的筹码，尤其是在 OpenAI 董事会面临人员流失的背景下。Altman 终于在五天紧张的谈判后实现了自己的愿望，重返 CEO 职位。他在 X 平台发布的回归声明中，特别感谢了一个人：Satya Nadella。

Microsoft 如何在硅谷这家最炙手可热的初创企业陷入困境之时，反而成为意外的赢家？

这背后很大程度上得益于 Nadella 的管理和领导风格，以及他对首席技术官 Kevin Scott 的信任，后者是 Microsoft AI 策略的幕后推手。这两位领导人在确保 Altman 重新掌管 OpenAI、保护他们 130 亿美元的投资以及帮助 Microsoft 避免一场可能是自食其果的尴尬失败中发挥了关键作用。

Microsoft 和 OpenAI 之间的非常规合作有时显得有些尴尬。但 Nadella 的高明之举在于，他与 Altman 建立了深厚的联系，五年来一直培养这种关系，成为一个不安分的企业家的重要伙伴。OpenAI 能够继续存在，很大程度上要归功于 Microsoft，其股价本周达到了历史新高。

纳德拉，现年 56 岁，出生并成长于印度海得拉巴。在那里，这位学习成绩平平的他最大的梦想是进入一所小型学院，打板球，并在银行工作。但在印度顶尖大学的入学考试失败后，他选择了在 Manipal 技术学院主修电气工程。他在回忆录《刷新》（2017）中提到，自青少年时期编写第一行代码起，他就对计算机和软件充满了热情。

纳德拉原本并没有计划离开印度，也并不急于这样做。他甚至曾希望自己申请的美国研究生院会拒绝他。然而，事与愿违，他最终来到美国，在威斯康星大学密尔沃基分校攻读计算机科学硕士。在那里，严寒让他不得不戒烟——他简直无法忍受在户外多待一秒。

尽管冬天异常严苛，纳德拉却爱上了他在美国的新生活。他发现这里的环境非常友好，最终甚至成为了美国公民。他在书中写道：“我认为我的故事只有在这里才可能发生。”（他拒绝就本文发表评论。）

1990 年，纳德拉加入了太阳微系统公司，并搬到加利福尼亚。两年后，他接到了来自华盛顿州雷德蒙德的电话，这通电话彻底改变了他的生活轨迹——他即将加入微软。

纳德拉在书中回忆，他在微软的关键时刻之一发生在他成为微软员工之前。在面试过程中，他被问到一个看似简单的问题：如果你在街上看到一个哭泣的婴儿，你会怎么做？他的第一反应是打 911。

然而，面试官指出：“你需要一些同理心。如果一个婴儿躺在街上哭泣，你应该去抱起他。” 纳德拉深刻记住了这个教训。

他在微软的早期岁月中遇到了史蒂夫·鲍尔默，这位未来的 CEO 继任者以热情的高举手式庆祝他的到来。纳德拉在公司的初期，常常携带康柏电脑跨越全国拜访客户，而周末则飞往芝加哥大学攻读商学硕士。

在微软公司步步高升的过程中，他负责监管了公司众多业务部门，例如云计算平台 Azure 和搜索引擎 Bing。目前，Azure 已成为微软整体增长的动力：微软的股价随着 Azure 的业绩而波动。在他的任期内，标普 500 指数增长了 215%，而微软的增长超过了 1,100%。至于 Bing，尽管它仍是 Bing，但在上一财年也创造了 120 亿美元的广告收入，不容小觑。

2014 年 2 月，Nadella 成为微软史上第三位 CEO，与前两任 CEO 截然不同。比尔·盖茨以其火山般的脾气而闻名，而巴尔默则以公开大声发泄而著称。相比之下，Nadella 在商业交往中更为低调。

他在感恩节期间写了一份 10 页的备忘录，以回答董事会关于他对公司未来愿景的看法，并成功地通过了面试。Nadella 强调，他的首要任务是改善公司的内部文化。他在一次高管会议上表示，仅仅发布产品并不足为喜，微软应当根据产品是否受到用户喜爱来衡量成功。

“我们需要更深入地理解客户未被言明和未得到满足的需求，" 他在自己的书中写道。

Nadella 的家庭生活也帮助他培养了更深的同理心。他的第一个孩子 Zain 患有严重的脑瘫，需要特别的照顾。Zain 去年去世，享年 26 岁。“成为一个有特殊需求孩子的父亲，是我生命中的转折点，深刻影响了我今天的为人，" Nadella 曾这样说。他称赞 Zain 是“我们家庭的快乐之源，他的坚强和温暖激励我不断探索技术的可能性。”

在担任微软首席执行官近十年后，员工们已经对纳德拉的管理风格了如指掌。

他是一位清楚认识自身极限，并愿意信任并委派他人的领导者。作为经理，他通常和善，但在必要时会严厉无情。一位前高管透露，纳德拉曾威胁要解雇那些不进步的直接下属。另一位前高管回忆，他曾直截了当地让一个爱炫耀的员工“坐下”。他很少说脏话，但在一次与微软高层的会议上，他明确告诉他们，他们的任务不是抱怨。“作为这家公司的领导者，”他说，“你们的工作是在困境中寻找亮点。”

他通过不断努力来践行这一点。一次，一位员工与他一同前往中国，为了缓解时差，凌晨3点去酒店健身房锻炼，却发现纳德拉已经锻炼完毕，开始了新的一天。

纳德拉也不惧怕果断终止那些无望的项目。他曾取消了将必应搜索引擎引入苹果手表的计划，认为这是浪费时间。“纳德拉独有的才能在于，能将复杂问题简化为核心要点，并且不会让会议室内的任何人感到被忽视，”曾向纳德拉汇报工作的前微软高管黄学东（Xuedong Huang）表示。

而他与前任微软首席执行官最不同的地方不仅仅在于他的行事风格。盖茨以其技术天赋著称，而鲍尔默则以其对商业模式的深刻理解闻名。纳德拉虽是工程师出身，但他的首席执行官任期内更多标志着一系列大规模交易的进行。他花费260亿美元收购了领英（LinkedIn），接着又斥资750亿美元收购动视暴雪（Activision Blizzard）。与此同时，他比前任更倾向于建立合作伙伴关系。鲍尔默曾在一次活动中夸张地从员工手中夺过iPhone，并假装要踩碎它，而纳德拉则平息了这种竞争情绪，在他首次重大产品发布会上推出了iPad版的微软Office套件。

他后来还与亚马逊建立了合作关系，与谷歌达成了脆弱的和平，并向外界宣布微软愿意与包括OpenAI在内的初创公司开展合作。

在一个专为亿万富翁设计的夏令营中，Nadella 和 Altman 的友谊奇遇开始了。2018年，他们在爱达荷州 Sun Valley 的 Allen &amp; Co. 大会上的一次楼梯偶遇，为他们之间的关系拉开了序幕。

Nadella 对 Altman 充满好奇，而 Altman 也对 Nadella 十分钦佩。

离开山区后，Altman 坚信 Microsoft 是唯一能与他的初创公司合作的企业，因为它不仅资金充裕，计算能力强大，而且对人工智能有着深刻的理解。

尽管 Microsoft 投资了高达130亿美元，但在 OpenAI 的董事会中并未获得席位，也无法洞察其内部治理。这是因为 Microsoft 担心自己的过度影响力可能会引发监管机构的警觉。这样一来，Microsoft 就不得不面对 OpenAI 独特结构带来的风险。Altman 的公司作为一个非盈利机构成立，其董事会的首要职责不是为股东创造最大价值，而是开发能“造福全人类”的安全人工智能。因为没有在董事会中占有一席之地，Microsoft 对很多事情都一无所知。同时，Microsoft 还面临着 Altman 可能离开并创立新公司、带走员工的风险，或者在一种原本看似遥不可及、却突然成为现实的情况下，OpenAI 董事会未经最大投资者同意就解雇 Altman。

即便在 OpenAI 危机爆发之前，这笔交易也并非人人欢迎。据知情人士透露，Gates 曾对高管表示，如果不完全收购该公司，Microsoft 支持它是没有意义的。虽然他现在已经对这项投资持积极态度，但他的担忧并非没有根据。Microsoft 必须在保护其投资和确保其持股比例低于50%（以避免监管问题）之间找到微妙的平衡点。

即便 Altman 已经回归，且 OpenAI 实施了更传统的治理结构，Microsoft 的问题仍未解决。Larry Summers 获得了新董事会的席位，但 Microsoft 仍然没有。至于 Nadella 是否想要扮演某种正式角色以防止此类事件重演，目前仍然是个未知数。

但有一人对 Nadella 处理 OpenAI 混乱局面的方式表示赞赏——Nadella 的前任 CEO。

Ballmer 在一封电邮中表示：“作为一个 Microsoft 的股东，也是一个长期支持 Satya 的人，我为他的表现感到欣慰且不感到惊讶。”

要深入了解微软 (Microsoft) 对未来的大胆投资，首先需要了解其 CEO Nadella 的成长经历。

Nadella 的父母曾在他的卧室里挂上 Karl Marx 和印度财富与繁荣女神的海报，但他真正热爱的是板球，特别是海得拉巴的板球明星 M.L. Jaisimha。Nadella 对板球的热情如此深厚，以至于高中时，为了继续打板球，他选择留在国内，而不随父亲出国。甚至在申请微软的工作时，他的简历上也写着自己的板球经历。在微软，不同于其他高管喜欢用棒球作比喻，Nadella 更倾向于用板球来说明问题。

Nadella 认为，他在球场上的经历深刻影响了他的领导风格。他曾参加过一场与强队的比赛，对手的强大让 Nadella 和队友们不禁止步观望，但他们的教练鼓励他们去挑战：“不要只是远观，要勇于竞争！”这段经历让 Nadella 深信，尊重对手固然重要，但更关键的是勇敢面对竞争。

正是这种精神指导了 Nadella 的决策。自2019年起，微软向 OpenAI 投资了30亿美元。到了2022年末，OpenAI 推出了 ChatGPT，这款产品迅速成为技术界的爆款，Nadella 甚至用它来翻译诗歌。到了2023年初，Nadella 再次大举投资，斥资100亿美元，预计这将帮助微软在当年实现1万亿美元的市场价值增长。

但增长也伴随着挑战。AI 技术成本高昂，随着微软加大对计算基础设施的投资，其开支预计将大幅增加。目前还不确定这些前期投资何时能够通过新增收入得到回报。尽管市场上已有证据显示，个人和企业愿意为像 GitHub 的 Copilot 这类 AI 助手支付高价，但微软的其他 AI 工具，例如 Microsoft 365，仍处于初期阶段，且每月每人收费30美元。微软需要现有和新客户为这一投资买单，以实现其增长目标。

Nadella 坚信，OpenAI 的独立性将促进创新，不仅对人类有益，也能助力微软的发展。然而，近期的不确定性事件揭示了一个重要风险点：作为全球最有价值公司之一的微软，将未来的部分掌控权外包给了一个初创公司。

“我不会假装我们的关系完美无瑕，”Altman 上月这样说。但他把 Nadella 形容成朋友而非敌手，强调他们在最关键的 AI（人工智能）问题上有着“高度一致”的看法。本月早些时候，在 OpenAI 的首次开发者大会上，两人同台亮相，Nadella 在 Altman 热情的介绍下轻松走上了舞台。

“微软对这次合作有何看法？”他问。

“我们非常喜欢你们！”Nadella 回答道。

谁也没想到，接下来的两周事件将使他们的关系更加紧密。

至于与 OpenAI 动荡期同步发生的那场板球比赛呢？Nadella 的公司比他支持的印度队表现得更好：印度在本土比赛中败给了澳大利亚。他祝贺澳大利亚队获胜，随后便投身工作，寻求属于自己的胜利。

*本文得到了 Keach Hagey 的贡献。*

https://www.livemint.com/ai/artificial-intelligence/the-biggest-winner-in-the-openai-fiasco-11700902916013.html</title>
            <link>https://nitter.cz/dotey/status/1728632847999631610#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728632847999631610#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 04:32:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“在那个充满活力的周末结束时，Altman 决定在这家科技巨擘里设立一个新的 AI 部门，好继续与 Nadella 合作，并充分利用 Microsoft 强大的计算资源。不久，成百上千的研究人员准备加入 Altman，投身于一个与众不同、魅力十足的公司。为了支持这些工程师们的研究，Microsoft 准备了一应俱全的资源：LinkedIn 办公楼的一整层、充裕的云计算资源和苹果笔记本电脑。更令人意外的是，这家价值万亿的公司向未来的同事保证，他们甚至不需要使用 Microsoft 的团队沟通应用 Teams。”<br />
<br />
能不用 Teams 都成了谈判筹码了😄<br />
<br />
以上内容来自华尔街日报：<br />
<br />
OpenAI 事件中的最大赢家<br />
<br />
作者：Ben Cohen，华尔街日报，2023年11月25日<br />
<br />
摘要：微软首席执行官 Satya Nadella 对全球最火爆的 AI 公司 OpenAI 进行了重大投资。尽管这场事件一度将他置于风口浪尖，但现在他与 OpenAI 的领导人 Sam Altman 建立了更加密切的联系。<br />
<br />
Satya Nadella 心绪难平。<br />
<br />
作为微软的首席执行官，他本应全力以赴，专注于在硅谷历史上最为混乱的周末之一中挽救其珍贵的资产。但他的思绪不断被板球这项运动所吸引。<br />
<br />
他无法全神贯注于关注自己祖国印度在板球世界杯中对抗澳大利亚的比赛，因为他发现自己正卷入了另一场更加激烈、风险更高的“游戏”中。即便在紧张的谈判和灾难应对中，Nadella 仍不时检查比分，向对板球不那么狂热的同事报告他最爱运动的最新动态。尽管他的团队处境艰难，但他的公司仍有转机。<br />
<br />
这场令他难以忘怀的周末始于上周五。就在 OpenAI 的董事会突然罢免其联合创始人兼首席执行官 Sam Altman 的消息传遍全球前几分钟，Nadella 得知了这一消息。这家推出 ChatGPT 的公司曾寻求达到900亿美元的估值。如此短时间内，很少有董事会的决策能对如此巨大的价值造成如此严重的威胁。<br />
<br />
虽然微软已为 OpenAI 的49%股份支付了数十亿美元，并利用其技术开发了一系列新一代软件，微软承诺这些软件将彻底改变工作方式，但作为这家初创公司最大的投资者，微软并未在董事会中占有一席之地。Nadella 几乎与全世界同时得知，他的这一投资——该投资几乎将微软独自推向了人工智能革命的前沿——突然面临困境。<br />
<br />
然而，当董事会对 Altman 采取行动时，Altman 立刻联系了 Nadella。在上周五董事会突变的数小时后，他们通过电话讨论了如何让 Altman 重返 OpenAI 或加入微软的方案。如果 Altman 不能重返 OpenAI 的首席执行官职位，这位曾经在 AI 领域最为瞩目的公司的前首席执行官将加盟微软。<br />
<br />
在那个充满活力的周末结束时，Altman 决定在这家科技巨擘里设立一个新的 AI 部门，好继续与 Nadella 合作，并充分利用 Microsoft 强大的计算资源。不久，成百上千的研究人员准备加入 Altman，投身于一个与众不同、魅力十足的公司。为了支持这些工程师们的研究，Microsoft 准备了一应俱全的资源：LinkedIn 办公楼的一整层、充裕的云计算资源和苹果笔记本电脑。更令人意外的是，这家价值万亿的公司向未来的同事保证，他们甚至不需要使用 Microsoft 的团队沟通应用 Teams。<br />
<br />
然而，对 Microsoft 而言，最理想的结局是让 Altman 回归 OpenAI 担任 CEO。据了解 Nadella 的人士透露，通过向 OpenAI 团队敞开大门，Nadella 增强了 Altman 重回 CEO 位置的筹码，尤其是在 OpenAI 董事会面临人员流失的背景下。Altman 终于在五天紧张的谈判后实现了自己的愿望，重返 CEO 职位。他在 X 平台发布的回归声明中，特别感谢了一个人：Satya Nadella。<br />
<br />
Microsoft 如何在硅谷这家最炙手可热的初创企业陷入困境之时，反而成为意外的赢家？<br />
<br />
这背后很大程度上得益于 Nadella 的管理和领导风格，以及他对首席技术官 Kevin Scott 的信任，后者是 Microsoft AI 策略的幕后推手。这两位领导人在确保 Altman 重新掌管 OpenAI、保护他们 130 亿美元的投资以及帮助 Microsoft 避免一场可能是自食其果的尴尬失败中发挥了关键作用。<br />
<br />
Microsoft 和 OpenAI 之间的非常规合作有时显得有些尴尬。但 Nadella 的高明之举在于，他与 Altman 建立了深厚的联系，五年来一直培养这种关系，成为一个不安分的企业家的重要伙伴。OpenAI 能够继续存在，很大程度上要归功于 Microsoft，其股价本周达到了历史新高。<br />
<br />
纳德拉，现年 56 岁，出生并成长于印度海得拉巴。在那里，这位学习成绩平平的他最大的梦想是进入一所小型学院，打板球，并在银行工作。但在印度顶尖大学的入学考试失败后，他选择了在 Manipal 技术学院主修电气工程。他在回忆录《刷新》（2017）中提到，自青少年时期编写第一行代码起，他就对计算机和软件充满了热情。<br />
<br />
纳德拉原本并没有计划离开印度，也并不急于这样做。他甚至曾希望自己申请的美国研究生院会拒绝他。然而，事与愿违，他最终来到美国，在威斯康星大学密尔沃基分校攻读计算机科学硕士。在那里，严寒让他不得不戒烟——他简直无法忍受在户外多待一秒。<br />
<br />
尽管冬天异常严苛，纳德拉却爱上了他在美国的新生活。他发现这里的环境非常友好，最终甚至成为了美国公民。他在书中写道：“我认为我的故事只有在这里才可能发生。”（他拒绝就本文发表评论。）<br />
<br />
1990 年，纳德拉加入了太阳微系统公司，并搬到加利福尼亚。两年后，他接到了来自华盛顿州雷德蒙德的电话，这通电话彻底改变了他的生活轨迹——他即将加入微软。<br />
<br />
纳德拉在书中回忆，他在微软的关键时刻之一发生在他成为微软员工之前。在面试过程中，他被问到一个看似简单的问题：如果你在街上看到一个哭泣的婴儿，你会怎么做？他的第一反应是打 911。<br />
<br />
然而，面试官指出：“你需要一些同理心。如果一个婴儿躺在街上哭泣，你应该去抱起他。” 纳德拉深刻记住了这个教训。<br />
<br />
他在微软的早期岁月中遇到了史蒂夫·鲍尔默，这位未来的 CEO 继任者以热情的高举手式庆祝他的到来。纳德拉在公司的初期，常常携带康柏电脑跨越全国拜访客户，而周末则飞往芝加哥大学攻读商学硕士。<br />
<br />
在微软公司步步高升的过程中，他负责监管了公司众多业务部门，例如云计算平台 Azure 和搜索引擎 Bing。目前，Azure 已成为微软整体增长的动力：微软的股价随着 Azure 的业绩而波动。在他的任期内，标普 500 指数增长了 215%，而微软的增长超过了 1,100%。至于 Bing，尽管它仍是 Bing，但在上一财年也创造了 120 亿美元的广告收入，不容小觑。<br />
<br />
2014 年 2 月，Nadella 成为微软史上第三位 CEO，与前两任 CEO 截然不同。比尔·盖茨以其火山般的脾气而闻名，而巴尔默则以公开大声发泄而著称。相比之下，Nadella 在商业交往中更为低调。<br />
<br />
他在感恩节期间写了一份 10 页的备忘录，以回答董事会关于他对公司未来愿景的看法，并成功地通过了面试。Nadella 强调，他的首要任务是改善公司的内部文化。他在一次高管会议上表示，仅仅发布产品并不足为喜，微软应当根据产品是否受到用户喜爱来衡量成功。<br />
<br />
“我们需要更深入地理解客户未被言明和未得到满足的需求，" 他在自己的书中写道。<br />
<br />
Nadella 的家庭生活也帮助他培养了更深的同理心。他的第一个孩子 Zain 患有严重的脑瘫，需要特别的照顾。Zain 去年去世，享年 26 岁。“成为一个有特殊需求孩子的父亲，是我生命中的转折点，深刻影响了我今天的为人，" Nadella 曾这样说。他称赞 Zain 是“我们家庭的快乐之源，他的坚强和温暖激励我不断探索技术的可能性。”<br />
<br />
在担任微软首席执行官近十年后，员工们已经对纳德拉的管理风格了如指掌。<br />
<br />
他是一位清楚认识自身极限，并愿意信任并委派他人的领导者。作为经理，他通常和善，但在必要时会严厉无情。一位前高管透露，纳德拉曾威胁要解雇那些不进步的直接下属。另一位前高管回忆，他曾直截了当地让一个爱炫耀的员工“坐下”。他很少说脏话，但在一次与微软高层的会议上，他明确告诉他们，他们的任务不是抱怨。“作为这家公司的领导者，”他说，“你们的工作是在困境中寻找亮点。”<br />
<br />
他通过不断努力来践行这一点。一次，一位员工与他一同前往中国，为了缓解时差，凌晨3点去酒店健身房锻炼，却发现纳德拉已经锻炼完毕，开始了新的一天。<br />
<br />
纳德拉也不惧怕果断终止那些无望的项目。他曾取消了将必应搜索引擎引入苹果手表的计划，认为这是浪费时间。“纳德拉独有的才能在于，能将复杂问题简化为核心要点，并且不会让会议室内的任何人感到被忽视，”曾向纳德拉汇报工作的前微软高管黄学东（Xuedong Huang）表示。<br />
<br />
而他与前任微软首席执行官最不同的地方不仅仅在于他的行事风格。盖茨以其技术天赋著称，而鲍尔默则以其对商业模式的深刻理解闻名。纳德拉虽是工程师出身，但他的首席执行官任期内更多标志着一系列大规模交易的进行。他花费260亿美元收购了领英（LinkedIn），接着又斥资750亿美元收购动视暴雪（Activision Blizzard）。与此同时，他比前任更倾向于建立合作伙伴关系。鲍尔默曾在一次活动中夸张地从员工手中夺过iPhone，并假装要踩碎它，而纳德拉则平息了这种竞争情绪，在他首次重大产品发布会上推出了iPad版的微软Office套件。<br />
<br />
他后来还与亚马逊建立了合作关系，与谷歌达成了脆弱的和平，并向外界宣布微软愿意与包括OpenAI在内的初创公司开展合作。<br />
<br />
在一个专为亿万富翁设计的夏令营中，Nadella 和 Altman 的友谊奇遇开始了。2018年，他们在爱达荷州 Sun Valley 的 Allen & Co. 大会上的一次楼梯偶遇，为他们之间的关系拉开了序幕。<br />
<br />
Nadella 对 Altman 充满好奇，而 Altman 也对 Nadella 十分钦佩。<br />
<br />
离开山区后，Altman 坚信 Microsoft 是唯一能与他的初创公司合作的企业，因为它不仅资金充裕，计算能力强大，而且对人工智能有着深刻的理解。<br />
<br />
尽管 Microsoft 投资了高达130亿美元，但在 OpenAI 的董事会中并未获得席位，也无法洞察其内部治理。这是因为 Microsoft 担心自己的过度影响力可能会引发监管机构的警觉。这样一来，Microsoft 就不得不面对 OpenAI 独特结构带来的风险。Altman 的公司作为一个非盈利机构成立，其董事会的首要职责不是为股东创造最大价值，而是开发能“造福全人类”的安全人工智能。因为没有在董事会中占有一席之地，Microsoft 对很多事情都一无所知。同时，Microsoft 还面临着 Altman 可能离开并创立新公司、带走员工的风险，或者在一种原本看似遥不可及、却突然成为现实的情况下，OpenAI 董事会未经最大投资者同意就解雇 Altman。<br />
<br />
即便在 OpenAI 危机爆发之前，这笔交易也并非人人欢迎。据知情人士透露，Gates 曾对高管表示，如果不完全收购该公司，Microsoft 支持它是没有意义的。虽然他现在已经对这项投资持积极态度，但他的担忧并非没有根据。Microsoft 必须在保护其投资和确保其持股比例低于50%（以避免监管问题）之间找到微妙的平衡点。<br />
<br />
即便 Altman 已经回归，且 OpenAI 实施了更传统的治理结构，Microsoft 的问题仍未解决。Larry Summers 获得了新董事会的席位，但 Microsoft 仍然没有。至于 Nadella 是否想要扮演某种正式角色以防止此类事件重演，目前仍然是个未知数。<br />
<br />
但有一人对 Nadella 处理 OpenAI 混乱局面的方式表示赞赏——Nadella 的前任 CEO。<br />
<br />
Ballmer 在一封电邮中表示：“作为一个 Microsoft 的股东，也是一个长期支持 Satya 的人，我为他的表现感到欣慰且不感到惊讶。”<br />
<br />
要深入了解微软 (Microsoft) 对未来的大胆投资，首先需要了解其 CEO Nadella 的成长经历。<br />
<br />
Nadella 的父母曾在他的卧室里挂上 Karl Marx 和印度财富与繁荣女神的海报，但他真正热爱的是板球，特别是海得拉巴的板球明星 M.L. Jaisimha。Nadella 对板球的热情如此深厚，以至于高中时，为了继续打板球，他选择留在国内，而不随父亲出国。甚至在申请微软的工作时，他的简历上也写着自己的板球经历。在微软，不同于其他高管喜欢用棒球作比喻，Nadella 更倾向于用板球来说明问题。<br />
<br />
Nadella 认为，他在球场上的经历深刻影响了他的领导风格。他曾参加过一场与强队的比赛，对手的强大让 Nadella 和队友们不禁止步观望，但他们的教练鼓励他们去挑战：“不要只是远观，要勇于竞争！”这段经历让 Nadella 深信，尊重对手固然重要，但更关键的是勇敢面对竞争。<br />
<br />
正是这种精神指导了 Nadella 的决策。自2019年起，微软向 OpenAI 投资了30亿美元。到了2022年末，OpenAI 推出了 ChatGPT，这款产品迅速成为技术界的爆款，Nadella 甚至用它来翻译诗歌。到了2023年初，Nadella 再次大举投资，斥资100亿美元，预计这将帮助微软在当年实现1万亿美元的市场价值增长。<br />
<br />
但增长也伴随着挑战。AI 技术成本高昂，随着微软加大对计算基础设施的投资，其开支预计将大幅增加。目前还不确定这些前期投资何时能够通过新增收入得到回报。尽管市场上已有证据显示，个人和企业愿意为像 GitHub 的 Copilot 这类 AI 助手支付高价，但微软的其他 AI 工具，例如 Microsoft 365，仍处于初期阶段，且每月每人收费30美元。微软需要现有和新客户为这一投资买单，以实现其增长目标。<br />
<br />
Nadella 坚信，OpenAI 的独立性将促进创新，不仅对人类有益，也能助力微软的发展。然而，近期的不确定性事件揭示了一个重要风险点：作为全球最有价值公司之一的微软，将未来的部分掌控权外包给了一个初创公司。<br />
<br />
“我不会假装我们的关系完美无瑕，”Altman 上月这样说。但他把 Nadella 形容成朋友而非敌手，强调他们在最关键的 AI（人工智能）问题上有着“高度一致”的看法。本月早些时候，在 OpenAI 的首次开发者大会上，两人同台亮相，Nadella 在 Altman 热情的介绍下轻松走上了舞台。<br />
<br />
“微软对这次合作有何看法？”他问。<br />
<br />
“我们非常喜欢你们！”Nadella 回答道。<br />
<br />
谁也没想到，接下来的两周事件将使他们的关系更加紧密。<br />
<br />
至于与 OpenAI 动荡期同步发生的那场板球比赛呢？Nadella 的公司比他支持的印度队表现得更好：印度在本土比赛中败给了澳大利亚。他祝贺澳大利亚队获胜，随后便投身工作，寻求属于自己的胜利。<br />
<br />
*本文得到了 Keach Hagey 的贡献。*<br />
<br />
<a href="https://www.livemint.com/ai/artificial-intelligence/the-biggest-winner-in-the-openai-fiasco-11700902916013.html">livemint.com/ai/artificial-i…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8xV1Z0WlhnQUVIa1BGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/jesselaunz/status/1728560640082759716#m</id>
            <title>RT by @dotey: 整了一个新的GPT

Free Grammar Checker

用了几个不太直观，自己写一个：

1.支持emoji提示，错误和修改部分

2.最终修改版放code block里，方便拷贝

3.支持多语言

需者点击： https://chat.openai.com/g/g-FmpWpbNpd-free-grammar-checker

视频因X时间限制，只放了中英文版本，

等会做个油管，加上西班牙语和日语演示</title>
            <link>https://nitter.cz/jesselaunz/status/1728560640082759716#m</link>
            <guid isPermaLink="false">https://nitter.cz/jesselaunz/status/1728560640082759716#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 25 Nov 2023 23:45:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整了一个新的GPT<br />
<br />
Free Grammar Checker<br />
<br />
用了几个不太直观，自己写一个：<br />
<br />
1.支持emoji提示，错误和修改部分<br />
<br />
2.最终修改版放code block里，方便拷贝<br />
<br />
3.支持多语言<br />
<br />
需者点击： <a href="https://chat.openai.com/g/g-FmpWpbNpd-free-grammar-checker">chat.openai.com/g/g-FmpWpbNp…</a><br />
<br />
视频因X时间限制，只放了中英文版本，<br />
<br />
等会做个油管，加上西班牙语和日语演示</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg1NjAyOTU5MzU4Njg5MjgvcHUvaW1nL1VlcEF1cERRaTFaOU9feUQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>