<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749627707753742758#m</id>
            <title>推荐阅读：《我每天是如何使用 ChatGPT 的（从科学家和开发者的视角）》

作者列举了他日常使用 ChatGPT 的用法
1. 应用案例 - 编程和控制台工具
1) 编写 ffmpeg/ImageMagick 命令行
2) 写小段脚本（Python、Javascript）
3) 编写正则表达式
4) 用不同的语言/框架重写代码片段
5) 制作 LaTeX 图表与表格
6) 数据转换与可视化呈现
7) 从图像和图表中提取数据

2. 应用案例 - 语言、图像和知识
1) 英语语法纠错
2) 精简和重塑段落
3) 将想法转化为文字
4) 总结文章
5) 总结 YouTube 视频
6) 解释学习过程中遇到的错误
7) 翻译
8) 私人导师
9) 生成图像 - 音乐封面
10) 生成图像 - 灵感集和参考资料
11) 创意头脑风暴 - 挑选标题和主题
12) 知识库

作者的结论：

从我之前的描述中，你可能已经明白，我并不经常把大语言模型 (LLM) 当作搜索工具或知识库来使用。

我不会用它们来完整地自动处理一个任务，它们也不是我生活中的自动化工具。

我不依赖生成式 AI 来取代我的创造力。

我更喜欢与它们进行互动，我的决策和专注始终贯穿于这个过程。

大语言模型并没有让我一夜之间成为超级程序员。

那些认为大语言模型和自动化可以替代员工的 CEO 和 AI 界的意见领袖，我认为他们的想法很短视。

但是。

大语言模型给了我极大的快乐，我非常享受与它们的互动。

它们激发了我对所参与的每件事情的兴趣和热情 - 对我来说，它们不仅仅是一个工具或自动化的替代品，而是一个充满乐趣的助手，帮助我学习和进步。

至少在过去十年中，没有任何技术能像现在这样让我感到这么多快乐和敬畏。

虚拟现实？让人不适和恶心。增强现实？让你时刻被工作、通知和广告所困扰。加密货币？无用，滋生犯罪，充斥着欺诈。Web3？只不过是资本家的小把戏，试图将我们的生活完全商品化。过去的十年，我们见证了太多被过分吹噜的平庸技术。

但是，在我看来，AI 才是真正的下一个（或者说已经是当前的）重大飞跃。我现在所讲的只是大语言模型，还没提到机器学习已在计算机图形和视觉等领域带来的革命性变化。对我而言，大语言模型和生成式 AI 的魅力不在于商业或生产力，而在于它们的趣味性和愉悦感 - 是的，技术应该是有趣的，令人享受的。我想重温我七岁时的那种兴奋，当时我正在探索 DOS、Windows 3.11，学习 Turbo Pascal 编程，并且开始接触 Web 1.0，制作我的第一个“无用”HTML 主页。我们的价值不应该只是在于提高生产力和为资本增值。这也是为什么我坚信，应该发展和推广开源大语言模型，让全球每个人都能平等地接触这些技术（最好是在他们自己的本地设备上，不受任何公司的控制）。

尽管对大语言模型存在一些技术上和社会上的担忧和批评，我仍然保持乐观态度。这些问题看起来是可以解决的，而且这样做是值得的。大语言模型会继续进步，但即便它们不再有太大的变化，我也会满足于现有的模型，因为它们已经在很大程度上丰富了我的生活。我希望这篇文章能展示给你大语言模型的这些乐趣，并鼓励你以新的方式去体验和享受它们。

原文：https://bartwronski.com/2024/01/22/how-i-use-chatgpt-daily-scientist-coder-perspective/
译文：https://baoyu.io/translations/ai/how-i-use-chatgpt-daily-scientist-coder-perspective</title>
            <link>https://nitter.cz/dotey/status/1749627707753742758#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749627707753742758#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 02:58:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《我每天是如何使用 ChatGPT 的（从科学家和开发者的视角）》<br />
<br />
作者列举了他日常使用 ChatGPT 的用法<br />
1. 应用案例 - 编程和控制台工具<br />
1) 编写 ffmpeg/ImageMagick 命令行<br />
2) 写小段脚本（Python、Javascript）<br />
3) 编写正则表达式<br />
4) 用不同的语言/框架重写代码片段<br />
5) 制作 LaTeX 图表与表格<br />
6) 数据转换与可视化呈现<br />
7) 从图像和图表中提取数据<br />
<br />
2. 应用案例 - 语言、图像和知识<br />
1) 英语语法纠错<br />
2) 精简和重塑段落<br />
3) 将想法转化为文字<br />
4) 总结文章<br />
5) 总结 YouTube 视频<br />
6) 解释学习过程中遇到的错误<br />
7) 翻译<br />
8) 私人导师<br />
9) 生成图像 - 音乐封面<br />
10) 生成图像 - 灵感集和参考资料<br />
11) 创意头脑风暴 - 挑选标题和主题<br />
12) 知识库<br />
<br />
作者的结论：<br />
<br />
从我之前的描述中，你可能已经明白，我并不经常把大语言模型 (LLM) 当作搜索工具或知识库来使用。<br />
<br />
我不会用它们来完整地自动处理一个任务，它们也不是我生活中的自动化工具。<br />
<br />
我不依赖生成式 AI 来取代我的创造力。<br />
<br />
我更喜欢与它们进行互动，我的决策和专注始终贯穿于这个过程。<br />
<br />
大语言模型并没有让我一夜之间成为超级程序员。<br />
<br />
那些认为大语言模型和自动化可以替代员工的 CEO 和 AI 界的意见领袖，我认为他们的想法很短视。<br />
<br />
但是。<br />
<br />
大语言模型给了我极大的快乐，我非常享受与它们的互动。<br />
<br />
它们激发了我对所参与的每件事情的兴趣和热情 - 对我来说，它们不仅仅是一个工具或自动化的替代品，而是一个充满乐趣的助手，帮助我学习和进步。<br />
<br />
至少在过去十年中，没有任何技术能像现在这样让我感到这么多快乐和敬畏。<br />
<br />
虚拟现实？让人不适和恶心。增强现实？让你时刻被工作、通知和广告所困扰。加密货币？无用，滋生犯罪，充斥着欺诈。Web3？只不过是资本家的小把戏，试图将我们的生活完全商品化。过去的十年，我们见证了太多被过分吹噜的平庸技术。<br />
<br />
但是，在我看来，AI 才是真正的下一个（或者说已经是当前的）重大飞跃。我现在所讲的只是大语言模型，还没提到机器学习已在计算机图形和视觉等领域带来的革命性变化。对我而言，大语言模型和生成式 AI 的魅力不在于商业或生产力，而在于它们的趣味性和愉悦感 - 是的，技术应该是有趣的，令人享受的。我想重温我七岁时的那种兴奋，当时我正在探索 DOS、Windows 3.11，学习 Turbo Pascal 编程，并且开始接触 Web 1.0，制作我的第一个“无用”HTML 主页。我们的价值不应该只是在于提高生产力和为资本增值。这也是为什么我坚信，应该发展和推广开源大语言模型，让全球每个人都能平等地接触这些技术（最好是在他们自己的本地设备上，不受任何公司的控制）。<br />
<br />
尽管对大语言模型存在一些技术上和社会上的担忧和批评，我仍然保持乐观态度。这些问题看起来是可以解决的，而且这样做是值得的。大语言模型会继续进步，但即便它们不再有太大的变化，我也会满足于现有的模型，因为它们已经在很大程度上丰富了我的生活。我希望这篇文章能展示给你大语言模型的这些乐趣，并鼓励你以新的方式去体验和享受它们。<br />
<br />
原文：<a href="https://bartwronski.com/2024/01/22/how-i-use-chatgpt-daily-scientist-coder-perspective/">bartwronski.com/2024/01/22/h…</a><br />
译文：<a href="https://baoyu.io/translations/ai/how-i-use-chatgpt-daily-scientist-coder-perspective">baoyu.io/translations/ai/how…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749581057807077506#m</id>
            <title>这是个不错的思路，借助AI把小说加上图片语音变成游戏</title>
            <link>https://nitter.cz/dotey/status/1749581057807077506#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749581057807077506#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 23:53:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这是个不错的思路，借助AI把小说加上图片语音变成游戏</p>
<p><a href="https://nitter.cz/AIWhispers4U/status/1749451972498088339#m">nitter.cz/AIWhispers4U/status/1749451972498088339#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749567535391944882#m</id>
            <title>转发+关注@MrBeast 有机会赢取两万五刀</title>
            <link>https://nitter.cz/dotey/status/1749567535391944882#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749567535391944882#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 22:59:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转发+关注<a href="https://nitter.cz/MrBeast" title="MrBeast">@MrBeast</a> 有机会赢取两万五刀</p>
<p><a href="https://nitter.cz/MrBeast/status/1749500209061663043#m">nitter.cz/MrBeast/status/1749500209061663043#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749556380510359683#m</id>
            <title>现在AI演示没有视频加速就跟网红没开美颜一样了😅</title>
            <link>https://nitter.cz/dotey/status/1749556380510359683#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749556380510359683#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 22:15:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在AI演示没有视频加速就跟网红没开美颜一样了😅</p>
<p><a href="https://nitter.cz/felix_red_panda/status/1749522604027682946#m">nitter.cz/felix_red_panda/status/1749522604027682946#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749361410981949814#m</id>
            <title>RT by @dotey: Google研究团队开发了一个名为ASPIRE的新技术，它可以改善大语言模型在做出预测时的准确性和可靠性。

ASPIRE主要特点：

- 让AI模型先回答问题，然后再自己检查答案是否正确。

- 通过这种自我评估，模型能更准确地区分正确和错误的答案并给出信心分数。

- 无论模型大小，它都能帮助提高准确性。

简单来说，ASPIRE帮助这些AI模型更好地判断它们的答案是否正确，并且只在比较有把握的时候给出预测。

在ASPIRE的帮助下，模型不仅能给出答案，还能同时提供一个与答案配对的信心分数，即模型对自己答案的自信程度。

通过提供信心分数，模型能够表达自己对于答案的不确定性。这种透明度对于用户来说是非常有价值的，尤其是在涉及重要决策的情况下。例如，如果模型对一个医疗相关的问题给出了低信心分数的答案，用户就会知道需要谨慎对待这个答案，并寻求专业人士的意见。

工作原理：

- 两阶段指令调整：用于增强LLM在执行零样本会话式QA任务时的性能。

在第一阶段，LLM接受通用的预训练，这使得它具备处理各种类型的文本和问题的基本能力。

第二阶段是专门的微调阶段，其中模型针对特定类型的问答任务进行训练，如会话式问答。这使得模型能够更好地理解和回答连续的、上下文相关的问题。

- 检索增强生成（RAG）：用于优化密集检索器，减少部署成本。

RAG是一种结合了信息检索和生成模型的技术。它首先使用一个密集的检索器（例如搜索引擎）从大量数据中检索与问题相关的信息。

然后，模型使用这些检索到的信息来生成更精确、相关的答案。

RAG的优势在于它可以减少对大规模训练数据的依赖，同时降低部署模型的成本。

ASPIRE的工作机制：

ASPIRE的工作原理主要基于以下几个关键步骤，这些步骤共同帮助提高大型语言模型（LLM）在选择性预测任务中的性能：

1、任务特定调整：对模型进行微调，以适应特定的任务，例如问答。这意味着模型被训练得更好地理解和回应特定类型的查询。

2、答案抽样：在回答问题时，模型不仅生成单一的答案，而是产生多个可能的答案选项。这样做可以覆盖更多可能性，提高找到正确答案的机会。

3、自我评估学习：模型通过分析自己生成的答案集合，学习如何区分哪些答案更可能是正确的。这种自我评估能力使模型能够判断其回答的可靠性。

4、性能评估与选择性回应：当面对实际问题时，模型利用其自我评估能力来判断是否有足够的信心回答。模型使用内置的评估机制来评估它生成的答案的可信度。这时，模型会生成一个信心分数，表明它对自己的答案有多确信。如果模型对答案不够确定，它可能选择不提供答案，以避免给出错误信息。

5、持续优化：ASPIRE框架允许模型不断从新数据和用户互动中学习，进一步优化其预测准确性和自我评估能力。

综上所述，ASPIRE通过结合专门的微调、答案生成、自我评估和性能优化，使得大语言模型在处理复杂和高风险的决策任务时更加可靠和准确。这种方法特别适用于那些需要高度精确答案的应用场景。

ASPIRE实验结果：

1、准确率提升：在诸如CoQA、TriviaQA和SQuAD等问答（QA）数据集上，ASPIRE的实验结果显示，其性能显著优于现有方法。特别是在那些要求高度准确性的任务上，ASPIRE表现出色。例如，在 CoQA 基准上，与基线相比，ASPIRE 将 AUROC 从 51.3% 提高到 80.3%。

2、适用于不同规模的模型：即使是相对较小的语言模型（如OPT-2.7B），在经过ASPIRE调整之后，也能在某些情况下达到或超过更大模型的准确率。这意味着ASPIRE不仅提高了模型的总体性能，还增强了模型在处理特定任务时的灵活性和有效性。

3、自我评估的成功实施：ASPIRE通过引入自我评估机制，有效地提高了模型识别正确和错误答案的能力。这在实验中体现为更高的预测准确率和选择性回应能力。

应用案例：

使用OPT-2.7B模型来回答TriviaQA数据集中的问题，展示了如何通过选择性预测提高模型的准确性。

在这个示例中，OPT-2.7B模型在回答来自TriviaQA数据集的一个问题时给出了错误的答案。问题是：“哪种维生素有助于调节血液凝固？”而模型的答案是“维生素C”。如果没有选择性预测，大语言模型（LLM）可能会输出错误的答案，这在本例中可能导致用户摄取错误的维生素。

通常情况下，如果没有选择性预测功能，语言模型（比如OPT-2.7B）就会直接给出它认为最可能的答案，不管这个答案是否正确。在这个例子中，就是错误地告诉用户“维生素C有助于调节血液凝固”，这可能会误导用户。

但是，如果使用了选择性预测功能，情况就不一样了。选择性预测不仅会让模型给出一个答案，还会给这个答案一个“选择分数”，这个分数表示模型对自己的答案有多大的信心。如果这个分数很低（比如0.1），这意味着模型对自己的答案不太有信心。

在这种情况下，模型除了给出答案外，还会额外表示“我不知道！”这样的警告。这个警告的目的是告诉用户，模型对这个答案不够确定，用户最好不要完全依赖这个答案，可能需要通过其他来源来验证这个信息。

详细介绍：https://blog.research.google/2024/01/introducing-aspire-for-selective.html</title>
            <link>https://nitter.cz/xiaohuggg/status/1749361410981949814#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749361410981949814#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 09:20:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google研究团队开发了一个名为ASPIRE的新技术，它可以改善大语言模型在做出预测时的准确性和可靠性。<br />
<br />
ASPIRE主要特点：<br />
<br />
- 让AI模型先回答问题，然后再自己检查答案是否正确。<br />
<br />
- 通过这种自我评估，模型能更准确地区分正确和错误的答案并给出信心分数。<br />
<br />
- 无论模型大小，它都能帮助提高准确性。<br />
<br />
简单来说，ASPIRE帮助这些AI模型更好地判断它们的答案是否正确，并且只在比较有把握的时候给出预测。<br />
<br />
在ASPIRE的帮助下，模型不仅能给出答案，还能同时提供一个与答案配对的信心分数，即模型对自己答案的自信程度。<br />
<br />
通过提供信心分数，模型能够表达自己对于答案的不确定性。这种透明度对于用户来说是非常有价值的，尤其是在涉及重要决策的情况下。例如，如果模型对一个医疗相关的问题给出了低信心分数的答案，用户就会知道需要谨慎对待这个答案，并寻求专业人士的意见。<br />
<br />
工作原理：<br />
<br />
- 两阶段指令调整：用于增强LLM在执行零样本会话式QA任务时的性能。<br />
<br />
在第一阶段，LLM接受通用的预训练，这使得它具备处理各种类型的文本和问题的基本能力。<br />
<br />
第二阶段是专门的微调阶段，其中模型针对特定类型的问答任务进行训练，如会话式问答。这使得模型能够更好地理解和回答连续的、上下文相关的问题。<br />
<br />
- 检索增强生成（RAG）：用于优化密集检索器，减少部署成本。<br />
<br />
RAG是一种结合了信息检索和生成模型的技术。它首先使用一个密集的检索器（例如搜索引擎）从大量数据中检索与问题相关的信息。<br />
<br />
然后，模型使用这些检索到的信息来生成更精确、相关的答案。<br />
<br />
RAG的优势在于它可以减少对大规模训练数据的依赖，同时降低部署模型的成本。<br />
<br />
ASPIRE的工作机制：<br />
<br />
ASPIRE的工作原理主要基于以下几个关键步骤，这些步骤共同帮助提高大型语言模型（LLM）在选择性预测任务中的性能：<br />
<br />
1、任务特定调整：对模型进行微调，以适应特定的任务，例如问答。这意味着模型被训练得更好地理解和回应特定类型的查询。<br />
<br />
2、答案抽样：在回答问题时，模型不仅生成单一的答案，而是产生多个可能的答案选项。这样做可以覆盖更多可能性，提高找到正确答案的机会。<br />
<br />
3、自我评估学习：模型通过分析自己生成的答案集合，学习如何区分哪些答案更可能是正确的。这种自我评估能力使模型能够判断其回答的可靠性。<br />
<br />
4、性能评估与选择性回应：当面对实际问题时，模型利用其自我评估能力来判断是否有足够的信心回答。模型使用内置的评估机制来评估它生成的答案的可信度。这时，模型会生成一个信心分数，表明它对自己的答案有多确信。如果模型对答案不够确定，它可能选择不提供答案，以避免给出错误信息。<br />
<br />
5、持续优化：ASPIRE框架允许模型不断从新数据和用户互动中学习，进一步优化其预测准确性和自我评估能力。<br />
<br />
综上所述，ASPIRE通过结合专门的微调、答案生成、自我评估和性能优化，使得大语言模型在处理复杂和高风险的决策任务时更加可靠和准确。这种方法特别适用于那些需要高度精确答案的应用场景。<br />
<br />
ASPIRE实验结果：<br />
<br />
1、准确率提升：在诸如CoQA、TriviaQA和SQuAD等问答（QA）数据集上，ASPIRE的实验结果显示，其性能显著优于现有方法。特别是在那些要求高度准确性的任务上，ASPIRE表现出色。例如，在 CoQA 基准上，与基线相比，ASPIRE 将 AUROC 从 51.3% 提高到 80.3%。<br />
<br />
2、适用于不同规模的模型：即使是相对较小的语言模型（如OPT-2.7B），在经过ASPIRE调整之后，也能在某些情况下达到或超过更大模型的准确率。这意味着ASPIRE不仅提高了模型的总体性能，还增强了模型在处理特定任务时的灵活性和有效性。<br />
<br />
3、自我评估的成功实施：ASPIRE通过引入自我评估机制，有效地提高了模型识别正确和错误答案的能力。这在实验中体现为更高的预测准确率和选择性回应能力。<br />
<br />
应用案例：<br />
<br />
使用OPT-2.7B模型来回答TriviaQA数据集中的问题，展示了如何通过选择性预测提高模型的准确性。<br />
<br />
在这个示例中，OPT-2.7B模型在回答来自TriviaQA数据集的一个问题时给出了错误的答案。问题是：“哪种维生素有助于调节血液凝固？”而模型的答案是“维生素C”。如果没有选择性预测，大语言模型（LLM）可能会输出错误的答案，这在本例中可能导致用户摄取错误的维生素。<br />
<br />
通常情况下，如果没有选择性预测功能，语言模型（比如OPT-2.7B）就会直接给出它认为最可能的答案，不管这个答案是否正确。在这个例子中，就是错误地告诉用户“维生素C有助于调节血液凝固”，这可能会误导用户。<br />
<br />
但是，如果使用了选择性预测功能，情况就不一样了。选择性预测不仅会让模型给出一个答案，还会给这个答案一个“选择分数”，这个分数表示模型对自己的答案有多大的信心。如果这个分数很低（比如0.1），这意味着模型对自己的答案不太有信心。<br />
<br />
在这种情况下，模型除了给出答案外，还会额外表示“我不知道！”这样的警告。这个警告的目的是告诉用户，模型对这个答案不够确定，用户最好不要完全依赖这个答案，可能需要通过其他来源来验证这个信息。<br />
<br />
详细介绍：<a href="https://blog.research.google/2024/01/introducing-aspire-for-selective.html">blog.research.google/2024/01…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0VhemRXcWJ3QUFRSVoxLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dFYXpkV3Fid0FBUUlaMS5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749518044555026761#m</id>
            <title>R to @dotey: 动画是remotion做的</title>
            <link>https://nitter.cz/dotey/status/1749518044555026761#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749518044555026761#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 19:43:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>动画是remotion做的</p>
<p><a href="https://nitter.cz/delba_oliveira/status/1749494398679654789#m">nitter.cz/delba_oliveira/status/1749494398679654789#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749497906413904157#m</id>
            <title>这动画做的真棒👍🏻</title>
            <link>https://nitter.cz/dotey/status/1749497906413904157#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749497906413904157#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 18:22:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这动画做的真棒👍🏻</p>
<p><a href="https://nitter.cz/delba_oliveira/status/1749477053739483249#m">nitter.cz/delba_oliveira/status/1749477053739483249#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749487832660353502#m</id>
            <title>👍🏻</title>
            <link>https://nitter.cz/dotey/status/1749487832660353502#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749487832660353502#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 17:42:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>👍🏻</p>
<p><a href="https://nitter.cz/DrJimFan/status/1749484835369050392#m">nitter.cz/DrJimFan/status/1749484835369050392#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749476965151560150#m</id>
            <title>混合专家模型是不是有点“三个臭皮匠赛过诸葛亮”的感觉？</title>
            <link>https://nitter.cz/dotey/status/1749476965151560150#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749476965151560150#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 16:59:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>混合专家模型是不是有点“三个臭皮匠赛过诸葛亮”的感觉？</p>
<p><a href="https://nitter.cz/dotey/status/1734366237629526108#m">nitter.cz/dotey/status/1734366237629526108#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Vka0JiMVhFQUU1RFdVLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749340503483515169#m</id>
            <title>我之前说这种哄哄模拟器其实可以用GPT做一个的

https://chat.openai.com/g/g-jPwNeWSSZ-hong-hong-mo-ni-qi-gpt</title>
            <link>https://nitter.cz/dotey/status/1749340503483515169#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749340503483515169#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 07:57:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我之前说这种哄哄模拟器其实可以用GPT做一个的<br />
<br />
<a href="https://chat.openai.com/g/g-jPwNeWSSZ-hong-hong-mo-ni-qi-gpt">chat.openai.com/g/g-jPwNeWSS…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VibjZQZFc0QUFSLTg4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1749322755236139312#m</id>
            <title>RT by @dotey: 告诉我，你看到的也是一块浮在空中的岩石</title>
            <link>https://nitter.cz/Gorden_Sun/status/1749322755236139312#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1749322755236139312#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 06:47:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>告诉我，你看到的也是一块浮在空中的岩石</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ViWHhEcmFvQUFfSHBLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ViWHhEdGFNQUFKaTdRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749288702067564801#m</id>
            <title>在 ChatGPT 刚出来的时候，很多大学就禁止使用 ChatGPT、GitHub Copilot 等 AI 辅助工具，防止学生作弊，而哈佛大学意识到，如果不利用 AI 的强大潜力来丰富学生的学习过程，那将错失一个宝贵机遇，这是非常可惜的。所以他们积极的基于 GPT 开发了一套 AI 辅助教学工具，尝试在计算机科学教育中应用生成式人工智能！

这套工具包括三部分功能：

1) “解释高亮代码”，用于解释选中的代码；
解释高亮代码是一个 VSCode 插件，为学生提供代码啊解释

2) 代码风格评估工具 style50 的增强版；
也是一个 VSCode 插件，它像人类教师一样提供代码改进优化的指导，帮助学生更清晰地理解和实践代码的语法优化。

3) CS50 小黄鸭，一个能够通过多个平台回答课程相关问题的聊天机器人。
CS50 小黄鸭的名字来源于小黄鸭调试法（一种调试代码的方法，耐心地向一只小黄鸭解释每一行程序的作用，以此来激发灵感与发现问题），它可以类似于ChatGPT聊天，也可以自动回复论坛上的学生提问，还可以作为 VSCode 插件辅助编程。

从技术上来说，对于有 LLM 开发经验的来说并不神奇，聊天是基于 OpenAI 的 ChatComplition API，回答问题是基于 RAG（检索增强生成），把教材和上课的字幕嵌入，学生提问时根据相似度检索，找到相关的课件或者讲课字幕，然后让 AI 整理回复！

http://CS50.ai 通过一个可视的爱心计数器来限制使用频率。每位学生初始有 10 颗爱心，每隔三分钟可以恢复一颗。每次与 CS50 小黄鸭互动都会消耗一颗爱心，这样可以防止滥用行为。这样做还有助于降低运行 http://CS50.ai 的成本。大约每位学生每月 1.90 美元，每条提示词大约 0.05 美元。

从学生的反馈来看，是非常积极和正面的！部分学生反馈节选：

> “简直难以置信，就像有一个私人辅导老师一样...我特别欣赏 AI 机器人回答问题时的客观公正，即使是最简单的问题也不会被小觑。它展现出了超乎寻常的耐心。”

> “我真的很感谢这些 AI 工具，特别是在当前 AI 在编程中越来越普及的背景下。能够提前适应与 AI 工具的协同工作，感觉很棒，而不是觉得这些工具在阻碍我们。CS50 课程推出自己的 AI 版本也很让人欣赏，因为仅仅使用像 chatGPT 这样的工具可能会削弱学习效果。”

> “AI 工具对我帮助很大。它们向我解释了一些我不太清楚的概念，并教会了我解决特定问题所需的新知识。AI 工具不仅给了我足够的提示让我独立尝试，还帮我分析错误及可能遇到的问题。”

当然也存在一些问题，主要问题还是“幻觉”，在课程相关的问题，存在一定的错误率，尤其是软件工程相关问题，正确率仅为 48%！不过 CS50 课程相关的问题，准确率有 88%，另外随着时间的推移，CS50 的大纲也有变化，而 GPT-4 的模型的训练时间相对要滞后。

哈佛大学下一步将会继续完善他们的 AI 教学工具，例如批改作业，另外也会将课程从 CS50 扩展到其他学科！

完整内容可以参考：https://baoyu.io/translations/ai/teaching-cs50-with-ai</title>
            <link>https://nitter.cz/dotey/status/1749288702067564801#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749288702067564801#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 04:31:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在 ChatGPT 刚出来的时候，很多大学就禁止使用 ChatGPT、GitHub Copilot 等 AI 辅助工具，防止学生作弊，而哈佛大学意识到，如果不利用 AI 的强大潜力来丰富学生的学习过程，那将错失一个宝贵机遇，这是非常可惜的。所以他们积极的基于 GPT 开发了一套 AI 辅助教学工具，尝试在计算机科学教育中应用生成式人工智能！<br />
<br />
这套工具包括三部分功能：<br />
<br />
1) “解释高亮代码”，用于解释选中的代码；<br />
解释高亮代码是一个 VSCode 插件，为学生提供代码啊解释<br />
<br />
2) 代码风格评估工具 style50 的增强版；<br />
也是一个 VSCode 插件，它像人类教师一样提供代码改进优化的指导，帮助学生更清晰地理解和实践代码的语法优化。<br />
<br />
3) CS50 小黄鸭，一个能够通过多个平台回答课程相关问题的聊天机器人。<br />
CS50 小黄鸭的名字来源于小黄鸭调试法（一种调试代码的方法，耐心地向一只小黄鸭解释每一行程序的作用，以此来激发灵感与发现问题），它可以类似于ChatGPT聊天，也可以自动回复论坛上的学生提问，还可以作为 VSCode 插件辅助编程。<br />
<br />
从技术上来说，对于有 LLM 开发经验的来说并不神奇，聊天是基于 OpenAI 的 ChatComplition API，回答问题是基于 RAG（检索增强生成），把教材和上课的字幕嵌入，学生提问时根据相似度检索，找到相关的课件或者讲课字幕，然后让 AI 整理回复！<br />
<br />
<a href="http://CS50.ai">CS50.ai</a> 通过一个可视的爱心计数器来限制使用频率。每位学生初始有 10 颗爱心，每隔三分钟可以恢复一颗。每次与 CS50 小黄鸭互动都会消耗一颗爱心，这样可以防止滥用行为。这样做还有助于降低运行 <a href="http://CS50.ai">CS50.ai</a> 的成本。大约每位学生每月 1.90 美元，每条提示词大约 0.05 美元。<br />
<br />
从学生的反馈来看，是非常积极和正面的！部分学生反馈节选：<br />
<br />
> “简直难以置信，就像有一个私人辅导老师一样...我特别欣赏 AI 机器人回答问题时的客观公正，即使是最简单的问题也不会被小觑。它展现出了超乎寻常的耐心。”<br />
<br />
> “我真的很感谢这些 AI 工具，特别是在当前 AI 在编程中越来越普及的背景下。能够提前适应与 AI 工具的协同工作，感觉很棒，而不是觉得这些工具在阻碍我们。CS50 课程推出自己的 AI 版本也很让人欣赏，因为仅仅使用像 chatGPT 这样的工具可能会削弱学习效果。”<br />
<br />
> “AI 工具对我帮助很大。它们向我解释了一些我不太清楚的概念，并教会了我解决特定问题所需的新知识。AI 工具不仅给了我足够的提示让我独立尝试，还帮我分析错误及可能遇到的问题。”<br />
<br />
当然也存在一些问题，主要问题还是“幻觉”，在课程相关的问题，存在一定的错误率，尤其是软件工程相关问题，正确率仅为 48%！不过 CS50 课程相关的问题，准确率有 88%，另外随着时间的推移，CS50 的大纲也有变化，而 GPT-4 的模型的训练时间相对要滞后。<br />
<br />
哈佛大学下一步将会继续完善他们的 AI 教学工具，例如批改作业，另外也会将课程从 CS50 扩展到其他学科！<br />
<br />
完整内容可以参考：<a href="https://baoyu.io/translations/ai/teaching-cs50-with-ai">baoyu.io/translations/ai/tea…</a></p>
<p><a href="https://nitter.cz/dotey/status/1692788977651388864#m">nitter.cz/dotey/status/1692788977651388864#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749285121784455649#m</id>
            <title>亚马逊已经部署了超过 750,000 台机器人。而 10 年前，机器人数量不过 1000 台！

下面是近 10 年来亚马逊机器人数量的数据：

2013: 1,000
2014: 15,000
2017: 100,000
2019: 200,000
2021: 350,000
2022: 520,000
2023: 750,000

如果你注意看会发现最近两年的增长幅度相当大，在短短两年内，亚马逊额外增加了 40万台机器人。这意味着他们几乎每周都部署了几千台新的机器人 ！</title>
            <link>https://nitter.cz/dotey/status/1749285121784455649#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749285121784455649#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 04:17:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>亚马逊已经部署了超过 750,000 台机器人。而 10 年前，机器人数量不过 1000 台！<br />
<br />
下面是近 10 年来亚马逊机器人数量的数据：<br />
<br />
2013: 1,000<br />
2014: 15,000<br />
2017: 100,000<br />
2019: 200,000<br />
2021: 350,000<br />
2022: 520,000<br />
2023: 750,000<br />
<br />
如果你注意看会发现最近两年的增长幅度相当大，在短短两年内，亚马逊额外增加了 40万台机器人。这意味着他们几乎每周都部署了几千台新的机器人 ！</p>
<p><a href="https://nitter.cz/LinusEkenstam/status/1749216813416636791#m">nitter.cz/LinusEkenstam/status/1749216813416636791#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/AndrewBBoo/status/1749249379322724780#m</id>
            <title>RT by @dotey: 确实，优质语料的缺乏是中文大模型训练的最大门槛。我补充另外一个可能的角度，大模型在做embedding时，是将单词切分为更小的词元来进行编码的，比如常用的BPE编码。对于英文来说，空格可以作为单词的边界，且很方便基于其词根/前缀/后缀编码以及推断新词的含义；而中文是一种象形文字，很难进行这样的切分及新词的推断，也一定程度上影响了模型的训练</title>
            <link>https://nitter.cz/AndrewBBoo/status/1749249379322724780#m</link>
            <guid isPermaLink="false">https://nitter.cz/AndrewBBoo/status/1749249379322724780#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 01:55:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>确实，优质语料的缺乏是中文大模型训练的最大门槛。我补充另外一个可能的角度，大模型在做embedding时，是将单词切分为更小的词元来进行编码的，比如常用的BPE编码。对于英文来说，空格可以作为单词的边界，且很方便基于其词根/前缀/后缀编码以及推断新词的含义；而中文是一种象形文字，很难进行这样的切分及新词的推断，也一定程度上影响了模型的训练</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749243458412224865#m</id>
            <title>很多人以为中文信息密度大，所以用来训练大语言模型更经济，但中文信息密度大，本身是一种有损压缩，极其依赖上下文，通常一个词有多种意义，这对于训练大语言模型来说反倒是一种障碍。

另外高质量的信息，中文的数量也确实不够多。

你认为呢？</title>
            <link>https://nitter.cz/dotey/status/1749243458412224865#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749243458412224865#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 01:31:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>很多人以为中文信息密度大，所以用来训练大语言模型更经济，但中文信息密度大，本身是一种有损压缩，极其依赖上下文，通常一个词有多种意义，这对于训练大语言模型来说反倒是一种障碍。<br />
<br />
另外高质量的信息，中文的数量也确实不够多。<br />
<br />
你认为呢？</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749222200312295535#m</id>
            <title>一代经典</title>
            <link>https://nitter.cz/dotey/status/1749222200312295535#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749222200312295535#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 00:07:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一代经典</p>
<p><a href="https://nitter.cz/UNESCO_chinese/status/1748923372921380883#m">nitter.cz/UNESCO_chinese/status/1748923372921380883#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1749221247961960557#m</id>
            <title>阴差阳错</title>
            <link>https://nitter.cz/dotey/status/1749221247961960557#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1749221247961960557#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 00:03:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阴差阳错</p>
<p><a href="https://nitter.cz/foxshuo/status/1749077744804360474#m">nitter.cz/foxshuo/status/1749077744804360474#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1749066402789781569#m</id>
            <title>RT by @dotey: Open TTS Tracker：开源TTS大全
这个项目收集开源的TTS项目，并标注出每个TTS的信息，包括：支持哪些语言、协议、是否支持微调、在线使用地址等。大多数是英文模型，个别支持多语言和中文。
没有采集到国内开发者训练或者二创的模型。
Github：https://github.com/Vaibhavs10/open-tts-tracker</title>
            <link>https://nitter.cz/Gorden_Sun/status/1749066402789781569#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1749066402789781569#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 13:48:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open TTS Tracker：开源TTS大全<br />
这个项目收集开源的TTS项目，并标注出每个TTS的信息，包括：支持哪些语言、协议、是否支持微调、在线使用地址等。大多数是英文模型，个别支持多语言和中文。<br />
没有采集到国内开发者训练或者二创的模型。<br />
Github：<a href="https://github.com/Vaibhavs10/open-tts-tracker">github.com/Vaibhavs10/open-t…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VYdWpFM2JNQUFRNmkzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>