<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737350042439065963#m</id>
            <title>实至名归😄</title>
            <link>https://nitter.cz/dotey/status/1737350042439065963#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737350042439065963#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 05:51:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>实至名归😄</p>
<p><a href="https://nitter.cz/XxWrkb5TSyu8DlT/status/1737326829332303950#m">nitter.cz/XxWrkb5TSyu8DlT/status/1737326829332303950#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xicilion/status/1737317533878014293#m</id>
            <title>RT by @dotey: 一个思路和 airllm 很类似的优化推理引擎，利用清华的 ReLU-based sparse models 技术，对 llama.cpp 的 ggml 进行改造，最终达到在 4090 上相对原版 llama.cpp 11 倍的速度。

在 4090 上的速度仅比在 a100 （未介绍基于什么引擎）上慢 18%。

https://github.com/SJTU-IPADS/PowerInfer</title>
            <link>https://nitter.cz/xicilion/status/1737317533878014293#m</link>
            <guid isPermaLink="false">https://nitter.cz/xicilion/status/1737317533878014293#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 03:42:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个思路和 airllm 很类似的优化推理引擎，利用清华的 ReLU-based sparse models 技术，对 llama.cpp 的 ggml 进行改造，最终达到在 4090 上相对原版 llama.cpp 11 倍的速度。<br />
<br />
在 4090 上的速度仅比在 a100 （未介绍基于什么引擎）上慢 18%。<br />
<br />
<a href="https://github.com/SJTU-IPADS/PowerInfer">github.com/SJTU-IPADS/PowerI…</a></p>
<p><a href="https://nitter.cz/omarsar0/status/1737168751668187229#m">nitter.cz/omarsar0/status/1737168751668187229#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzE0NzAwMjUyMDAzOTQyNC9nOW50U0xIQj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737312698705092887#m</id>
            <title>建议关注 Google 新发布的 VideoPoet，它并非基于扩散模型，而是多模态大语言模型，基本上扩散模型能支持的功能它都能做，比如说：如文本到视频、图像到视频、视频到音频的转换，以及视频风格化、补画（inpainting）或延伸画（outpainting）处理。

并且它在保证视频一致性方面做的效果特别好，你可以看到它的一些演示动画都相当稳定。

我上传的这个视频是 Google 用 VideoPoet 制作的一个短片，展示了由多个由 VideoPoet 生成的短视频片段拼接而成的成果。在编写剧本时，他们使用 Bard 创作了一个关于旅行的浣熊的短故事，并提供了按场景划分的故事梗概和相应的视频提示。接着，根据这些提示制作了视频片段，并将它们拼接成为最终展示的视频。

对于长视频也很有大模型的 提示-补全（Prompt-Completion） 风格，VideoPoet 可以通过对视频最后一秒进行分析，预测接下来的一秒内容，从而生成更长的视频。这种方法可以连续应用，显示出模型不仅能够有效延长视频长度，还能在多次重复过程中保持视频中所有对象的连贯性和真实性。

也许像 VideoPoet 这样的多模态大模型才是视频生成的未来主流。

更多演示可以看项目网站：https://sites.research.google/videopoet/

更多详情可以看这篇博客：《VideoPoet: 能零样本生成视频的大语言模型 [译]》
https://baoyu.io/translations/google/videopoet-large-language-model-for-zero</title>
            <link>https://nitter.cz/dotey/status/1737312698705092887#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737312698705092887#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 03:23:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>建议关注 Google 新发布的 VideoPoet，它并非基于扩散模型，而是多模态大语言模型，基本上扩散模型能支持的功能它都能做，比如说：如文本到视频、图像到视频、视频到音频的转换，以及视频风格化、补画（inpainting）或延伸画（outpainting）处理。<br />
<br />
并且它在保证视频一致性方面做的效果特别好，你可以看到它的一些演示动画都相当稳定。<br />
<br />
我上传的这个视频是 Google 用 VideoPoet 制作的一个短片，展示了由多个由 VideoPoet 生成的短视频片段拼接而成的成果。在编写剧本时，他们使用 Bard 创作了一个关于旅行的浣熊的短故事，并提供了按场景划分的故事梗概和相应的视频提示。接着，根据这些提示制作了视频片段，并将它们拼接成为最终展示的视频。<br />
<br />
对于长视频也很有大模型的 提示-补全（Prompt-Completion） 风格，VideoPoet 可以通过对视频最后一秒进行分析，预测接下来的一秒内容，从而生成更长的视频。这种方法可以连续应用，显示出模型不仅能够有效延长视频长度，还能在多次重复过程中保持视频中所有对象的连贯性和真实性。<br />
<br />
也许像 VideoPoet 这样的多模态大模型才是视频生成的未来主流。<br />
<br />
更多演示可以看项目网站：<a href="https://sites.research.google/videopoet/">sites.research.google/videop…</a><br />
<br />
更多详情可以看这篇博客：《VideoPoet: 能零样本生成视频的大语言模型 [译]》<br />
<a href="https://baoyu.io/translations/google/videopoet-large-language-model-for-zero">baoyu.io/translations/google…</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1737253472808956293#m">nitter.cz/_akhaliq/status/1737253472808956293#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzczMTExMTQxNTE1NDY4ODEvcHUvaW1nL1lyaDVub0FjQjBvanhHRDYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/linyiLYi/status/1737241501334462765#m</id>
            <title>RT by @dotey: 苹果 mlx 机器学习库增加了对通义千问的支持，前几天 mixtral、phi-2 也都是一到三天的时间就支持了，这个库的维护力量超出预期。llama.cpp 要加油了。</title>
            <link>https://nitter.cz/linyiLYi/status/1737241501334462765#m</link>
            <guid isPermaLink="false">https://nitter.cz/linyiLYi/status/1737241501334462765#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 22:40:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>苹果 mlx 机器学习库增加了对通义千问的支持，前几天 mixtral、phi-2 也都是一到三天的时间就支持了，这个库的维护力量超出预期。llama.cpp 要加油了。</p>
<p><a href="https://nitter.cz/awnihannun/status/1737218185659908099#m">nitter.cz/awnihannun/status/1737218185659908099#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737240852336902344#m</id>
            <title>微软和人工智能音乐创作公司 Suno 达成合作，可以在 Copilot 直接用 Suno 作曲！

以下内容转译自微软博客：

用 Suno 在 Microsoft Copilot 上把你的想法变成歌曲

我们非常兴奋地宣布，我们已与 Suno 达成合作，Suno 是人工智能音乐创作的先锋，现在它的能力将融入 Microsoft Copilot。这项合作意味着，人们可以轻松地创作出有趣、巧妙且具有个性的歌曲，无论他们的音乐背景如何，只需一个简单的提示。Suno 作为 AI 音乐技术的领军企业，率先实现了从一句话生成完整歌曲——包括歌词、伴奏和人声。

即使你不会唱歌、演奏乐器或阅读乐谱，也能轻松将你的音乐想法变为现实。Microsoft Copilot 和 Suno 将完成所有复杂的工作，根据你的提示创作歌曲。想要开始创作音乐，只需遵循以下步骤：

1. 打开 Microsoft Edge 浏览器，访问 http://copilot.microsoft.com 并确保以你的 Microsoft 账户登录。
2. 启用 Suno 插件或点击标有 “用 Suno 制作音乐” 的 Suno 图标。
3. 请求 Copilot 为你创作一首歌曲，比如：“创作一首关于和家人冒险的流行歌曲”。
4. 随着你的新曲目一起享受音乐的乐趣。
5. 将它分享到社交媒体或与朋友和同事一起分享。

我们相信，这次合作将开启创意和乐趣的新篇章，使音乐创作变得简单易行。这种全新体验将从今天开始逐步向用户推出。我们期待着看到（和聆听）你的创作成果。

https://blogs.bing.com/cmsctx/pv/JandJ/culture/en-US/wg/d46f1dcb-1009-4263-8d42-15c762ec5019/h/e256ae63c417284cb35df9ddd14d1e9f807ad5053e5e825a1f9b2a4569ca6a13/-/cms/getdoc/c4d04949-3857-4608-afb3-bb10eb3ed45a/pv.aspx</title>
            <link>https://nitter.cz/dotey/status/1737240852336902344#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737240852336902344#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 22:37:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软和人工智能音乐创作公司 Suno 达成合作，可以在 Copilot 直接用 Suno 作曲！<br />
<br />
以下内容转译自微软博客：<br />
<br />
用 Suno 在 Microsoft Copilot 上把你的想法变成歌曲<br />
<br />
我们非常兴奋地宣布，我们已与 Suno 达成合作，Suno 是人工智能音乐创作的先锋，现在它的能力将融入 Microsoft Copilot。这项合作意味着，人们可以轻松地创作出有趣、巧妙且具有个性的歌曲，无论他们的音乐背景如何，只需一个简单的提示。Suno 作为 AI 音乐技术的领军企业，率先实现了从一句话生成完整歌曲——包括歌词、伴奏和人声。<br />
<br />
即使你不会唱歌、演奏乐器或阅读乐谱，也能轻松将你的音乐想法变为现实。Microsoft Copilot 和 Suno 将完成所有复杂的工作，根据你的提示创作歌曲。想要开始创作音乐，只需遵循以下步骤：<br />
<br />
1. 打开 Microsoft Edge 浏览器，访问 <a href="http://copilot.microsoft.com">copilot.microsoft.com</a> 并确保以你的 Microsoft 账户登录。<br />
2. 启用 Suno 插件或点击标有 “用 Suno 制作音乐” 的 Suno 图标。<br />
3. 请求 Copilot 为你创作一首歌曲，比如：“创作一首关于和家人冒险的流行歌曲”。<br />
4. 随着你的新曲目一起享受音乐的乐趣。<br />
5. 将它分享到社交媒体或与朋友和同事一起分享。<br />
<br />
我们相信，这次合作将开启创意和乐趣的新篇章，使音乐创作变得简单易行。这种全新体验将从今天开始逐步向用户推出。我们期待着看到（和聆听）你的创作成果。<br />
<br />
<a href="https://blogs.bing.com/cmsctx/pv/JandJ/culture/en-US/wg/d46f1dcb-1009-4263-8d42-15c762ec5019/h/e256ae63c417284cb35df9ddd14d1e9f807ad5053e5e825a1f9b2a4569ca6a13/-/cms/getdoc/c4d04949-3857-4608-afb3-bb10eb3ed45a/pv.aspx">blogs.bing.com/cmsctx/pv/Jan…</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1737144934933631127#m">nitter.cz/_akhaliq/status/1737144934933631127#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737088730706718817#m</id>
            <title>RT by @dotey: MIST：一个反AI工具，旨在帮助艺术家保护其艺术作品免受AI的模仿。

艺术家可以用MIST在他们的作品上加上一种特殊的水印，这种水印肉眼几乎看不见，但可以阻止AI程序正确地“理解”和复制这些作品。

当AI尝试学习或复制加了MIST水印的图片风格时，它会受到干扰，导致无法正确复制原作的风格和内容。

Mist应对各种AI-for-Art的应用均有效，包括LoRA，SDEdit，DreamBooth ，Scenario gg等。

MIST这个工具在保护艺术作品时非常强大和灵活。即使艺术作品的图片被数字处理或变化，MIST依然能有效地保护这些作品。

MIST项目在GitHub上开源，开发者希望在Discord上建立一个活跃的开发者和用户社区，共同提高MIST的性能，并欢迎用户反馈和技术贡献。

网站提供了一些艺术家作品在MIST保护下的效果示例，展示了MIST如何有效地保护这些作品不被AI模仿。

MIST兼容Linux和Windows操作系统，用户可以通过提供的链接下载MIST启动器并安装运行。

网站：https://mist-project.github.io/index.html
GitHub：https://github.com/mist-project/mist-v2</title>
            <link>https://nitter.cz/xiaohuggg/status/1737088730706718817#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737088730706718817#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 12:33:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MIST：一个反AI工具，旨在帮助艺术家保护其艺术作品免受AI的模仿。<br />
<br />
艺术家可以用MIST在他们的作品上加上一种特殊的水印，这种水印肉眼几乎看不见，但可以阻止AI程序正确地“理解”和复制这些作品。<br />
<br />
当AI尝试学习或复制加了MIST水印的图片风格时，它会受到干扰，导致无法正确复制原作的风格和内容。<br />
<br />
Mist应对各种AI-for-Art的应用均有效，包括LoRA，SDEdit，DreamBooth ，Scenario gg等。<br />
<br />
MIST这个工具在保护艺术作品时非常强大和灵活。即使艺术作品的图片被数字处理或变化，MIST依然能有效地保护这些作品。<br />
<br />
MIST项目在GitHub上开源，开发者希望在Discord上建立一个活跃的开发者和用户社区，共同提高MIST的性能，并欢迎用户反馈和技术贡献。<br />
<br />
网站提供了一些艺术家作品在MIST保护下的效果示例，展示了MIST如何有效地保护这些作品不被AI模仿。<br />
<br />
MIST兼容Linux和Windows操作系统，用户可以通过提供的链接下载MIST启动器并安装运行。<br />
<br />
网站：<a href="https://mist-project.github.io/index.html">mist-project.github.io/index…</a><br />
GitHub：<a href="https://github.com/mist-project/mist-v2">github.com/mist-project/mist…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J0Z2tmT2FVQUF0SzQ4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/geekbb/status/1737067974555759073#m</id>
            <title>RT by @dotey: 这简直是更新狂的必备！Latest 是一款免费开源的 Mac 程序，帮助检查你 Mac 所使用的应用程序是否都是最新版本，显示更新内容并提供更新的选项。
GitHub https://github.com/mangerlahn/latest
主页 https://max.codes/latest/</title>
            <link>https://nitter.cz/geekbb/status/1737067974555759073#m</link>
            <guid isPermaLink="false">https://nitter.cz/geekbb/status/1737067974555759073#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 11:10:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这简直是更新狂的必备！Latest 是一款免费开源的 Mac 程序，帮助检查你 Mac 所使用的应用程序是否都是最新版本，显示更新内容并提供更新的选项。<br />
GitHub <a href="https://github.com/mangerlahn/latest">github.com/mangerlahn/latest</a><br />
主页 <a href="https://max.codes/latest/">max.codes/latest/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J0S1UyQWJjQUF5bmJfLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737158211558326605#m</id>
            <title>如果你也有一个感觉永远完不成的个人项目或者永远写不完的文章、论文，不妨花几分钟时间看看这篇文章：《一个永无止境的个人项目带来的启示》，当然你也不用指望能改变什么，无非就是从中找到一点共鸣罢了——原来还有那么多人跟我一样😄

作者从三月份开始写一篇关于音乐的论文，写了 9 个月，快两万字，但是到现在还没完成。

通常给项目设立截止日期是非常有效的。有经验的人都知道，对于个人项目来说，就算你设置了截止日期，其实也很难遵守。

另外并非所有项目都适合加上期限，因为只有在没有期限的情况下，这些项目才能真正成长成为你所期望的样子。然而，没有期限你可能永远也无法完成它们！

如果你希望你的项目能被人看见，那么总要设定一个Deadline，停止对它的不断完善，并将它推出去。否则，你可能会永远在这个项目上耗费时间，却收获不了任何成果。

当然，技术产品和艺术作品又不一样，技术产品可以一直迭代升级，但是艺术作品发布就无法更改了，所以艺术家可能比我们更纠结😅

原文：https://siddhesh.substack.com/p/projects
翻译：https://baoyu.io/translations/software-engineering/finishing-a-personal-project-you-are-doing-just-for-yourself-is-impossible</title>
            <link>https://nitter.cz/dotey/status/1737158211558326605#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737158211558326605#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:09:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果你也有一个感觉永远完不成的个人项目或者永远写不完的文章、论文，不妨花几分钟时间看看这篇文章：《一个永无止境的个人项目带来的启示》，当然你也不用指望能改变什么，无非就是从中找到一点共鸣罢了——原来还有那么多人跟我一样😄<br />
<br />
作者从三月份开始写一篇关于音乐的论文，写了 9 个月，快两万字，但是到现在还没完成。<br />
<br />
通常给项目设立截止日期是非常有效的。有经验的人都知道，对于个人项目来说，就算你设置了截止日期，其实也很难遵守。<br />
<br />
另外并非所有项目都适合加上期限，因为只有在没有期限的情况下，这些项目才能真正成长成为你所期望的样子。然而，没有期限你可能永远也无法完成它们！<br />
<br />
如果你希望你的项目能被人看见，那么总要设定一个Deadline，停止对它的不断完善，并将它推出去。否则，你可能会永远在这个项目上耗费时间，却收获不了任何成果。<br />
<br />
当然，技术产品和艺术作品又不一样，技术产品可以一直迭代升级，但是艺术作品发布就无法更改了，所以艺术家可能比我们更纠结😅<br />
<br />
原文：<a href="https://siddhesh.substack.com/p/projects">siddhesh.substack.com/p/proj…</a><br />
翻译：<a href="https://baoyu.io/translations/software-engineering/finishing-a-personal-project-you-are-doing-just-for-yourself-is-impossible">baoyu.io/translations/softwa…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J1V2lYVFdjQUF0MDNzLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1737110963076395477#m</id>
            <title>RT by @dotey: Runway 的 TTS 正式上线了。
声音方面已经有好几家在卷了
11lab 的高价不可持续了</title>
            <link>https://nitter.cz/oran_ge/status/1737110963076395477#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1737110963076395477#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 14:01:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runway 的 TTS 正式上线了。<br />
声音方面已经有好几家在卷了<br />
11lab 的高价不可持续了</p>
<p><a href="https://nitter.cz/runwayml/status/1737110251999002768#m">nitter.cz/runwayml/status/1737110251999002768#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737116145554272341#m</id>
            <title>这个挺好用，借用的Mac自带的OCR能力识别率很高</title>
            <link>https://nitter.cz/dotey/status/1737116145554272341#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737116145554272341#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 14:22:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个挺好用，借用的Mac自带的OCR能力识别率很高</p>
<p><a href="https://nitter.cz/LuoSays/status/1736971294284140927#m">nitter.cz/LuoSays/status/1736971294284140927#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737017381321310709#m</id>
            <title>正好今天也看到一篇类似的文章：《用 RAGAs（检索增强生成评估）评估 RAG（检索增强型生成）应用》

它也是四个评估指标，但是略有不同：

1. 上下文精准度： 衡量检索出的上下文中有用信息与无用信息的比率。该指标通过分析 question 和 contexts 来计算。
2. 上下文召回率： 用来评估是否检索到了解答问题所需的全部相关信息。这一指标依据 ground_truth（此为框架中唯一基于人工标注的真实数据的指标）和 contexts 进行计算。
3. 真实性：用于衡量生成答案的事实准确度。它通过对比给定上下文中正确的陈述与生成答案中总陈述的数量来计算。这一指标结合了 question、contexts 和 answer。
4. 答案相关度： 评估生成答案与问题的关联程度。例如，对于问题“法国在哪里及其首都是什么？”，答案“法国位于西欧。”的答案相关度较低，因为它只回答了问题的一部分。

所有指标的评分范围在 [0, 1] 之间，分数越高表示性能越出色。

它在评估时，需要依赖以下几种信息：

- question：RAG 流程的输入，即用户的查询问题。
- answer：由 RAG 流程生成的答案，也就是输出结果。
- contexts：为解答 question 而从外部知识源检索到的相关上下文。
- ground_truths：question 的标准答案，这是唯一需要人工标注的信息。这个信息仅在评估 context_recall 这一指标时才必须（详见 评估指标）

它在评估数据集时，不必依赖人工标注的标准答案，而是通过底层的大语言模型 (LLM) 来进行评估。

具体参考：Evaluating RAG Applications with RAGAs
https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a
翻译：https://baoyu.io/translations/rag/evaluating-rag-applications-with-ragas</title>
            <link>https://nitter.cz/dotey/status/1737017381321310709#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737017381321310709#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 07:49:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>正好今天也看到一篇类似的文章：《用 RAGAs（检索增强生成评估）评估 RAG（检索增强型生成）应用》<br />
<br />
它也是四个评估指标，但是略有不同：<br />
<br />
1. 上下文精准度： 衡量检索出的上下文中有用信息与无用信息的比率。该指标通过分析 question 和 contexts 来计算。<br />
2. 上下文召回率： 用来评估是否检索到了解答问题所需的全部相关信息。这一指标依据 ground_truth（此为框架中唯一基于人工标注的真实数据的指标）和 contexts 进行计算。<br />
3. 真实性：用于衡量生成答案的事实准确度。它通过对比给定上下文中正确的陈述与生成答案中总陈述的数量来计算。这一指标结合了 question、contexts 和 answer。<br />
4. 答案相关度： 评估生成答案与问题的关联程度。例如，对于问题“法国在哪里及其首都是什么？”，答案“法国位于西欧。”的答案相关度较低，因为它只回答了问题的一部分。<br />
<br />
所有指标的评分范围在 [0, 1] 之间，分数越高表示性能越出色。<br />
<br />
它在评估时，需要依赖以下几种信息：<br />
<br />
- question：RAG 流程的输入，即用户的查询问题。<br />
- answer：由 RAG 流程生成的答案，也就是输出结果。<br />
- contexts：为解答 question 而从外部知识源检索到的相关上下文。<br />
- ground_truths：question 的标准答案，这是唯一需要人工标注的信息。这个信息仅在评估 context_recall 这一指标时才必须（详见 评估指标）<br />
<br />
它在评估数据集时，不必依赖人工标注的标准答案，而是通过底层的大语言模型 (LLM) 来进行评估。<br />
<br />
具体参考：Evaluating RAG Applications with RAGAs<br />
<a href="https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a">towardsdatascience.com/evalu…</a><br />
翻译：<a href="https://baoyu.io/translations/rag/evaluating-rag-applications-with-ragas">baoyu.io/translations/rag/ev…</a></p>
<p><a href="https://nitter.cz/Tisoga/status/1736544319199478175#m">nitter.cz/Tisoga/status/1736544319199478175#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737015537937314300#m</id>
            <title>Nvidia 推出一项新技术：GAvatar，这是一种能够生成可动画的 3D 高斯头像，并采用了隐式网格学习技术。

高斯分割技术作为一种先进的 3D 表现形式，它巧妙地结合了显式（即网格形式）和隐式（如神经辐射场，NeRF）的 3D 表示优点。

在这篇论文中，利用高斯分割技术，通过文本描述来创造出栩栩如生的可动画头像，这一过程克服了传统网格或基于 NeRF 表示的种种限制，如灵活性和效率不足。

然而，简单地应用高斯分割技术并不能制作出高质量的可动画头像，这种方法在学习过程中稳定性不足，难以捕捉细致的头像几何形状，常常导致身体部分形态不佳。为解决这些难题，Nvidia 提出了一种基于原始形状的 3D 高斯表示法，这种方法通过在姿势驱动的基础形状内定义高斯分布来便于动画制作。接着，为了稳定地并高效地学习数以百万计的高斯数据，Nvidia 采用神经隐式场预测高斯的各种属性（比如颜色）。

最后，为了更好地捕捉细致的头像几何结构并提取精细网格，Nvidia 提出了一种全新的、针对 3D 高斯的基于有向距离场（SDF）的隐式网格学习方法。这种方法不仅规范了几何结构，而且能够提取高度详细的纹理网格。我们的这种方法，GAvatar，使得仅用文本提示就可以生成大量多样化的可动画头像成为可能。

在外观和几何质量上，GAvatar 明显优于现有技术，并能在 1K 分辨率下达到令人印象深刻的渲染速度——每秒 100 帧。

项目首页：https://nvlabs.github.io/GAvatar/
论文：https://arxiv.org/abs/2312.11461</title>
            <link>https://nitter.cz/dotey/status/1737015537937314300#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737015537937314300#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 07:42:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nvidia 推出一项新技术：GAvatar，这是一种能够生成可动画的 3D 高斯头像，并采用了隐式网格学习技术。<br />
<br />
高斯分割技术作为一种先进的 3D 表现形式，它巧妙地结合了显式（即网格形式）和隐式（如神经辐射场，NeRF）的 3D 表示优点。<br />
<br />
在这篇论文中，利用高斯分割技术，通过文本描述来创造出栩栩如生的可动画头像，这一过程克服了传统网格或基于 NeRF 表示的种种限制，如灵活性和效率不足。<br />
<br />
然而，简单地应用高斯分割技术并不能制作出高质量的可动画头像，这种方法在学习过程中稳定性不足，难以捕捉细致的头像几何形状，常常导致身体部分形态不佳。为解决这些难题，Nvidia 提出了一种基于原始形状的 3D 高斯表示法，这种方法通过在姿势驱动的基础形状内定义高斯分布来便于动画制作。接着，为了稳定地并高效地学习数以百万计的高斯数据，Nvidia 采用神经隐式场预测高斯的各种属性（比如颜色）。<br />
<br />
最后，为了更好地捕捉细致的头像几何结构并提取精细网格，Nvidia 提出了一种全新的、针对 3D 高斯的基于有向距离场（SDF）的隐式网格学习方法。这种方法不仅规范了几何结构，而且能够提取高度详细的纹理网格。我们的这种方法，GAvatar，使得仅用文本提示就可以生成大量多样化的可动画头像成为可能。<br />
<br />
在外观和几何质量上，GAvatar 明显优于现有技术，并能在 1K 分辨率下达到令人印象深刻的渲染速度——每秒 100 帧。<br />
<br />
项目首页：<a href="https://nvlabs.github.io/GAvatar/">nvlabs.github.io/GAvatar/</a><br />
论文：<a href="https://arxiv.org/abs/2312.11461">arxiv.org/abs/2312.11461</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1736994634356691255#m">nitter.cz/_akhaliq/status/1736994634356691255#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/waylybaye/status/1737002026280870346#m</id>
            <title>RT by @dotey: 大家好，OpenCat 2.0 iOS/macOS 更新啦，部分 UI 进行了重新设计了。

Cloud 现在可以免费试用了。
支持了 Google Gemini。

https://opencat.app/</title>
            <link>https://nitter.cz/waylybaye/status/1737002026280870346#m</link>
            <guid isPermaLink="false">https://nitter.cz/waylybaye/status/1737002026280870346#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 06:48:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大家好，OpenCat 2.0 iOS/macOS 更新啦，部分 UI 进行了重新设计了。<br />
<br />
Cloud 现在可以免费试用了。<br />
支持了 Google Gemini。<br />
<br />
<a href="https://opencat.app/">opencat.app/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzUl91dWF3QUFXM2xiLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzU0JqeWJjQUEzV3FFLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzU0duemFNQUFUUnN2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzU0lPOWFzQUFJQm8wLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1736990848317812988#m</id>
            <title>推荐阅读：《在命令行中运行 Mistral 模型的多种方法》

作者介绍了若干方法在本地命令行窗口中运行 Mistral 模型：
- 通过 llama.cpp 和 llm-llama-cpp 来运行 Mistral 8x7B
- 通过 llm-llama-cpp、llm-gpt4all 或 llm-mlc 来运行 Mistral 7B
- 使用 Mistral API，包括新推出的 Mistral-medium
- 通过其他 API 服务商来接入 Mistral

如果你想要本地运行 Mistral 7B 或者 Mistral 8x7B 可以参考

原文：Many options for running Mistral models in your terminal using LLM
https://simonwillison.net/2023/Dec/18/mistral

翻译：https://baoyu.io/translations/llm/many-options-for-running-mistral-models-in-your-terminal-using-llm</title>
            <link>https://nitter.cz/dotey/status/1736990848317812988#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1736990848317812988#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 06:04:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《在命令行中运行 Mistral 模型的多种方法》<br />
<br />
作者介绍了若干方法在本地命令行窗口中运行 Mistral 模型：<br />
- 通过 llama.cpp 和 llm-llama-cpp 来运行 Mistral 8x7B<br />
- 通过 llm-llama-cpp、llm-gpt4all 或 llm-mlc 来运行 Mistral 7B<br />
- 使用 Mistral API，包括新推出的 Mistral-medium<br />
- 通过其他 API 服务商来接入 Mistral<br />
<br />
如果你想要本地运行 Mistral 7B 或者 Mistral 8x7B 可以参考<br />
<br />
原文：Many options for running Mistral models in your terminal using LLM<br />
<a href="https://simonwillison.net/2023/Dec/18/mistral">simonwillison.net/2023/Dec/1…</a><br />
<br />
翻译：<a href="https://baoyu.io/translations/llm/many-options-for-running-mistral-models-in-your-terminal-using-llm">baoyu.io/translations/llm/ma…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzSDluSVdJQUFYTko0LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1736982650965909806#m</id>
            <title>这个应用还有点意思，有点像 SwiftUI 版本的 V0，可以根据截图或者Prompt生成手机App，生成的代码是 SwiftUI。

测试地址：https://www.trace.zip/</title>
            <link>https://nitter.cz/dotey/status/1736982650965909806#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1736982650965909806#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 05:31:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个应用还有点意思，有点像 SwiftUI 版本的 V0，可以根据截图或者Prompt生成手机App，生成的代码是 SwiftUI。<br />
<br />
测试地址：<a href="https://www.trace.zip/">trace.zip/</a></p>
<p><a href="https://nitter.cz/trace_ai/status/1736862506642227675#m">nitter.cz/trace_ai/status/1736862506642227675#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1736980589117411788#m</id>
            <title>#开源项目推荐：Librum

Librum 是一个开源免费的电子书图书馆应用程序，包含电子阅读器，可以管理自己的电子书，支持多平台和多语言，还有 AI 功能，能对选中的文本解释和总结。

此外，Librum 还允许用户免费访问超过 70,000 本书籍，并提供个人阅读统计功能，且完全免费、开源。

目前，Librum 支持英语、德语、俄语和中文。

目前支持的平台包括：

- Windows
- GNU/Linux
- MacOS
- IOS（即将推出）
- Android（即将推出）

Librum 支持的格式包括：

- PDF
- EPUB
- CBZ（漫画书）
- XPS
- PS
- 所有纯文本格式
- 图片

功能包括：

- 现代化的电子阅读器
- 可个性化定制的图书馆
- 编辑书籍元数据
- 内置的超过 70,000 本书的免费书店
- 在所有设备间同步书籍
- 高亮显示
- 书签
- 文本搜索
- 无限制的个性化定制
- 笔记（即将推出）
- 文字转语音 (TTS)（即将推出）
- 个性化阅读统计（即将推出）
- 无需登录即可阅读书籍（即将推出）

https://github.com/Librum-Reader/Librum</title>
            <link>https://nitter.cz/dotey/status/1736980589117411788#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1736980589117411788#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 05:23:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23开源项目推荐">#开源项目推荐</a>：Librum<br />
<br />
Librum 是一个开源免费的电子书图书馆应用程序，包含电子阅读器，可以管理自己的电子书，支持多平台和多语言，还有 AI 功能，能对选中的文本解释和总结。<br />
<br />
此外，Librum 还允许用户免费访问超过 70,000 本书籍，并提供个人阅读统计功能，且完全免费、开源。<br />
<br />
目前，Librum 支持英语、德语、俄语和中文。<br />
<br />
目前支持的平台包括：<br />
<br />
- Windows<br />
- GNU/Linux<br />
- MacOS<br />
- IOS（即将推出）<br />
- Android（即将推出）<br />
<br />
Librum 支持的格式包括：<br />
<br />
- PDF<br />
- EPUB<br />
- CBZ（漫画书）<br />
- XPS<br />
- PS<br />
- 所有纯文本格式<br />
- 图片<br />
<br />
功能包括：<br />
<br />
- 现代化的电子阅读器<br />
- 可个性化定制的图书馆<br />
- 编辑书籍元数据<br />
- 内置的超过 70,000 本书的免费书店<br />
- 在所有设备间同步书籍<br />
- 高亮显示<br />
- 书签<br />
- 文本搜索<br />
- 无限制的个性化定制<br />
- 笔记（即将推出）<br />
- 文字转语音 (TTS)（即将推出）<br />
- 个性化阅读统计（即将推出）<br />
- 无需登录即可阅读书籍（即将推出）<br />
<br />
<a href="https://github.com/Librum-Reader/Librum">github.com/Librum-Reader/Lib…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY5ODAxNTk5MTAwMjcyNjQvcHUvaW1nLzY0b0JfZlVEcms3dkxJMXMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1736975803601059964#m</id>
            <title>#开源项目推荐：pacexy/flow

一个开源免费的完全基于浏览器的ePub 阅读器，不需要安装客户端，在浏览器中运行，所有数据都保存在本地的indexDB。

主要功能有：
书内搜索
图片预览
自定义排版
高亮、笔记
主题
通过链接分享、下载书籍
数据导出
云端存储

但似乎最近一段没有更新了。

项目地址：https://github.com/pacexy/flow</title>
            <link>https://nitter.cz/dotey/status/1736975803601059964#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1736975803601059964#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 05:04:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23开源项目推荐">#开源项目推荐</a>：pacexy/flow<br />
<br />
一个开源免费的完全基于浏览器的ePub 阅读器，不需要安装客户端，在浏览器中运行，所有数据都保存在本地的indexDB。<br />
<br />
主要功能有：<br />
书内搜索<br />
图片预览<br />
自定义排版<br />
高亮、笔记<br />
主题<br />
通过链接分享、下载书籍<br />
数据导出<br />
云端存储<br />
<br />
但似乎最近一段没有更新了。<br />
<br />
项目地址：<a href="https://github.com/pacexy/flow">github.com/pacexy/flow</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JyNTl0Q1c0QUV4YXA2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JyNkE0ZldzQUFJUHNuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>