<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726857269139091872#m</id>
            <title>OpenAI 员工对 Sam Altman 被解雇的原因感到怀疑和愤怒。

- 在一次员工大会上，OpenAI 的 Ilya Sustkever 揭露了 CEO Sam Altman 被解雇的两个原因。
- 这些原因与他向董事会提供的人事相关陈述有关。
- 大部分员工对这些理由表示怀疑，正准备离职。

OpenAI 目前的独立董事会列举了两个原因，认为这些是解雇联合创始人兼 CEO Sam Altman 的原因，此事使公司陷入混乱。

上周日晚间，Ilya Sutskever 向员工介绍了新任临时 CEO Emmett Shear，他是 Twitch 的前 CEO，接替了仅任职两天的 Mira Murati，后者上周五接替了 Altman。这次简短的会议在 OpenAI 旧金山的一个办公室举行，据了解情况的人士透露，只有少数员工参加了。其他员工则选择罢工。据 The Verge 报道，这次会议确实发生。

员工原本期待着听到 Altman 将重返 CEO 职位的消息。在周日晚上的大约 30 分钟内，他们先是被告知 Altman 将回归，随后又得知不会，然后又是 Shear 被任命。这一消息源自几位不愿透露姓名的内部人士，他们并未被授权公开公司内部事务，但他们的身份为 Business Insider 所知。

当员工得知 Shear 将接任时，大多数人对这个消息反应极为激烈。对于整个周末都处于焦虑中的员工而言，这是又一次打击。

Sutskever 作为首席科学家和联合创始人，是投票决定解雇 Altman 的人之一，也是通过 Google Meet 宣布解雇的人，他负责告知员工 Shear 的到来。会议上，Sutskever 显得情绪低落。

员工和科技行业观察家们此前一直在猜测 OpenAI 发表的一份严厉声明背后的原因，该声明指出 Altman 在与董事会的沟通中“并不始终诚实”。

据悉，Sustkever 向员工提供了董事会给出的两个解释。第一个解释是 Altman 曾让 OpenAI 的两位员工同时进行同一个项目。第二个则是 Altman 据称对董事会的两名成员在某个员工问题上表达了不同的观点。对于这些解释，OpenAI 的发言人并未回应置评请求。

员工对这些解释感到困惑，普遍不接受。他们内部普遍认为，这是董事会的一次直接“政变”。现在，董事会给出的任何理由在员工中几乎没有影响力。

会议结束几小时后，员工起草并在夜间传阅了一封公开信，由包括 Murati 和 Sutskever 在内的 OpenAI 领导层签署。信中抗议董事会未能让 Altman 返回。到周一中午，超过 90% 的员工签署了这封信。

信中，员工坚称，如果董事会现有成员不辞职、不任命新董事会成员、Altman 不返回公司，他们将集体辞职。

目前，据说 Altman 正在与 Microsoft 协商可能的回归，同时他在 Microsoft 担任着一个临时职位，这是由 CEO Satya Nadella 策划的。Microsoft 是 OpenAI 最大的投资者，投资额至少为 100 亿美元。

“员工极度愤怒，大规模辞职即将发生，”一位了解内情的人士表示。

公司目前的董事会由 Quora 首席执行官 Adam D'Angelo、科技创业家 Tasha McCauley、乔治城大学安全与新兴技术中心的 Helen Toner 和 Sutskever 组成。尽管 Sutskever 也签署了威胁离开公司的公开信，但据悉他目前仍是董事会成员。Altman 和 OpenAI 总裁 Greg Brockman 之前也在董事会中。

虽然 Murati 在 Altman 被解雇后不久成为许多员工的怨气对象，因为她是他的直接替代者，且据悉她在前一天就知道了他将被解雇，但这种情绪现在已经缓和。

据了解情况的人士称，她在周五之后一直在向 Sutskever 寻求指导。现在她决定如果 Altman 不返回，则与 Sutskever 一同离开公司，后者也公开表达了对参与董事会行动的“遗憾”。有人质疑，所有这些高层人物是否能继续在其他地方与 OpenAI 团队和领导层合作。然而，也有观点认为 Sutskever 不太可能被轻易原谅，并可能不会被邀请留下或加入 Microsoft 的新项目。

https://www.businessinsider.com/openais-employees-given-explanations-why-sam-altman-out-2023-11</title>
            <link>https://nitter.cz/dotey/status/1726857269139091872#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726857269139091872#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 06:57:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 员工对 Sam Altman 被解雇的原因感到怀疑和愤怒。<br />
<br />
- 在一次员工大会上，OpenAI 的 Ilya Sustkever 揭露了 CEO Sam Altman 被解雇的两个原因。<br />
- 这些原因与他向董事会提供的人事相关陈述有关。<br />
- 大部分员工对这些理由表示怀疑，正准备离职。<br />
<br />
OpenAI 目前的独立董事会列举了两个原因，认为这些是解雇联合创始人兼 CEO Sam Altman 的原因，此事使公司陷入混乱。<br />
<br />
上周日晚间，Ilya Sutskever 向员工介绍了新任临时 CEO Emmett Shear，他是 Twitch 的前 CEO，接替了仅任职两天的 Mira Murati，后者上周五接替了 Altman。这次简短的会议在 OpenAI 旧金山的一个办公室举行，据了解情况的人士透露，只有少数员工参加了。其他员工则选择罢工。据 The Verge 报道，这次会议确实发生。<br />
<br />
员工原本期待着听到 Altman 将重返 CEO 职位的消息。在周日晚上的大约 30 分钟内，他们先是被告知 Altman 将回归，随后又得知不会，然后又是 Shear 被任命。这一消息源自几位不愿透露姓名的内部人士，他们并未被授权公开公司内部事务，但他们的身份为 Business Insider 所知。<br />
<br />
当员工得知 Shear 将接任时，大多数人对这个消息反应极为激烈。对于整个周末都处于焦虑中的员工而言，这是又一次打击。<br />
<br />
Sutskever 作为首席科学家和联合创始人，是投票决定解雇 Altman 的人之一，也是通过 Google Meet 宣布解雇的人，他负责告知员工 Shear 的到来。会议上，Sutskever 显得情绪低落。<br />
<br />
员工和科技行业观察家们此前一直在猜测 OpenAI 发表的一份严厉声明背后的原因，该声明指出 Altman 在与董事会的沟通中“并不始终诚实”。<br />
<br />
据悉，Sustkever 向员工提供了董事会给出的两个解释。第一个解释是 Altman 曾让 OpenAI 的两位员工同时进行同一个项目。第二个则是 Altman 据称对董事会的两名成员在某个员工问题上表达了不同的观点。对于这些解释，OpenAI 的发言人并未回应置评请求。<br />
<br />
员工对这些解释感到困惑，普遍不接受。他们内部普遍认为，这是董事会的一次直接“政变”。现在，董事会给出的任何理由在员工中几乎没有影响力。<br />
<br />
会议结束几小时后，员工起草并在夜间传阅了一封公开信，由包括 Murati 和 Sutskever 在内的 OpenAI 领导层签署。信中抗议董事会未能让 Altman 返回。到周一中午，超过 90% 的员工签署了这封信。<br />
<br />
信中，员工坚称，如果董事会现有成员不辞职、不任命新董事会成员、Altman 不返回公司，他们将集体辞职。<br />
<br />
目前，据说 Altman 正在与 Microsoft 协商可能的回归，同时他在 Microsoft 担任着一个临时职位，这是由 CEO Satya Nadella 策划的。Microsoft 是 OpenAI 最大的投资者，投资额至少为 100 亿美元。<br />
<br />
“员工极度愤怒，大规模辞职即将发生，”一位了解内情的人士表示。<br />
<br />
公司目前的董事会由 Quora 首席执行官 Adam D'Angelo、科技创业家 Tasha McCauley、乔治城大学安全与新兴技术中心的 Helen Toner 和 Sutskever 组成。尽管 Sutskever 也签署了威胁离开公司的公开信，但据悉他目前仍是董事会成员。Altman 和 OpenAI 总裁 Greg Brockman 之前也在董事会中。<br />
<br />
虽然 Murati 在 Altman 被解雇后不久成为许多员工的怨气对象，因为她是他的直接替代者，且据悉她在前一天就知道了他将被解雇，但这种情绪现在已经缓和。<br />
<br />
据了解情况的人士称，她在周五之后一直在向 Sutskever 寻求指导。现在她决定如果 Altman 不返回，则与 Sutskever 一同离开公司，后者也公开表达了对参与董事会行动的“遗憾”。有人质疑，所有这些高层人物是否能继续在其他地方与 OpenAI 团队和领导层合作。然而，也有观点认为 Sutskever 不太可能被轻易原谅，并可能不会被邀请留下或加入 Microsoft 的新项目。<br />
<br />
<a href="https://www.businessinsider.com/openais-employees-given-explanations-why-sam-altman-out-2023-11">businessinsider.com/openais-…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726853628005118273#m</id>
            <title>#AI开源项目推荐#：Video-LLaVA

北京大学的多模态图像视频识别

论文摘要：
大型视觉-语言模型（LVLM）在视觉与语言理解的各种任务中表现出色。传统方法通常将图像和视频分别编码到不同的特征空间，再作为输入提供给大语言模型（LLM）。但由于图像和视频在投影前未能实现统一的词元化，导致大语言模型难以从多个较差的投影层中学习多模态交互。在本研究中，我们尝试将视觉信息融入语言特征空间，以推动基础大语言模型向更统一的大型视觉-语言模型发展。因此，我们创建了一个简单而强大的大型视觉-语言模型基线，名为 Video-LLaVA，它通过学习混合的图像和视频数据集来实现相互增强。Video-LLaVA 在包含 5 个图像问答数据集和 4 个图像基准工具包的 9 个主要图像基准测试中取得显著成效。另外，我们的 Video-LLaVA 在 MSRVTT、MSVD、TGIF 和 ActivityNet 四个基准测试中，分别比 Video-ChatGPT 高出 5.8%、9.9%、18.6% 和 10.1%。更重要的是，广泛的实验表明 Video-LLaVA 通过统一的视觉表示，促进了图像和视频的相互提升，其性能超越了专门针对图像或视频设计的模型。

在线测试地址：https://replicate.com/nateraw/video-llava
项目地址：http://github.com/PKU-YuanGroup/Video-LLaVA
论文：https://arxiv.org/pdf/2311.10122.pdf</title>
            <link>https://nitter.cz/dotey/status/1726853628005118273#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726853628005118273#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 06:42:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>#AI开源项目推荐#：Video-LLaVA<br />
<br />
北京大学的多模态图像视频识别<br />
<br />
论文摘要：<br />
大型视觉-语言模型（LVLM）在视觉与语言理解的各种任务中表现出色。传统方法通常将图像和视频分别编码到不同的特征空间，再作为输入提供给大语言模型（LLM）。但由于图像和视频在投影前未能实现统一的词元化，导致大语言模型难以从多个较差的投影层中学习多模态交互。在本研究中，我们尝试将视觉信息融入语言特征空间，以推动基础大语言模型向更统一的大型视觉-语言模型发展。因此，我们创建了一个简单而强大的大型视觉-语言模型基线，名为 Video-LLaVA，它通过学习混合的图像和视频数据集来实现相互增强。Video-LLaVA 在包含 5 个图像问答数据集和 4 个图像基准工具包的 9 个主要图像基准测试中取得显著成效。另外，我们的 Video-LLaVA 在 MSRVTT、MSVD、TGIF 和 ActivityNet 四个基准测试中，分别比 Video-ChatGPT 高出 5.8%、9.9%、18.6% 和 10.1%。更重要的是，广泛的实验表明 Video-LLaVA 通过统一的视觉表示，促进了图像和视频的相互提升，其性能超越了专门针对图像或视频设计的模型。<br />
<br />
在线测试地址：<a href="https://replicate.com/nateraw/video-llava">replicate.com/nateraw/video-…</a><br />
项目地址：<a href="http://github.com/PKU-YuanGroup/Video-LLaVA">github.com/PKU-YuanGroup/Vid…</a><br />
论文：<a href="https://arxiv.org/pdf/2311.10122.pdf">arxiv.org/pdf/2311.10122.pdf</a></p>
<p><a href="https://nitter.cz/jesselaunz/status/1726850138776453379#m">nitter.cz/jesselaunz/status/1726850138776453379#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/jesselaunz/status/1726850138776453379#m</id>
            <title>RT by @dotey: Video-LLaVA很cool

我上传了几个视频，几个视频都成功识别了

且速度也相当快。</title>
            <link>https://nitter.cz/jesselaunz/status/1726850138776453379#m</link>
            <guid isPermaLink="false">https://nitter.cz/jesselaunz/status/1726850138776453379#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 06:28:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Video-LLaVA很cool<br />
<br />
我上传了几个视频，几个视频都成功识别了<br />
<br />
且速度也相当快。</p>
<p><a href="https://nitter.cz/_nateraw/status/1726783481248977037#m">nitter.cz/_nateraw/status/1726783481248977037#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjY4NDk1MDc0ODc1NTk2ODAvcHUvaW1nL2twMUdEejI4TmszRGNKcncuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726846017407254754#m</id>
            <title>除了投资人不开心，应该大家都支持😅</title>
            <link>https://nitter.cz/dotey/status/1726846017407254754#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726846017407254754#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 06:12:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>除了投资人不开心，应该大家都支持😅</p>
<p><a href="https://nitter.cz/mtrainier2020/status/1726842782663495834#m">nitter.cz/mtrainier2020/status/1726842782663495834#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1726844221095842260#m</id>
            <title>RT by @dotey: Orca-2：教会小型LLM如何推理
微软推出的、基于LLaMa 2微调的、学会了多种推理方法的LLM，推理能力超过5-10倍大小的模型。
推理方法包括step-by-step, recall then generate, recall-reason-generate, direct answer 等。
论文：https://arxiv.org/abs/2311.11045
模型：https://huggingface.co/models?other=arxiv:2311.11045</title>
            <link>https://nitter.cz/Gorden_Sun/status/1726844221095842260#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1726844221095842260#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 06:05:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Orca-2：教会小型LLM如何推理<br />
微软推出的、基于LLaMa 2微调的、学会了多种推理方法的LLM，推理能力超过5-10倍大小的模型。<br />
推理方法包括step-by-step, recall then generate, recall-reason-generate, direct answer 等。<br />
论文：<a href="https://arxiv.org/abs/2311.11045">arxiv.org/abs/2311.11045</a><br />
模型：<a href="https://huggingface.co/models?other=arxiv:2311.11045">huggingface.co/models?other=…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9iN3BxWmJ3QUFaRU9tLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/jefflijun/status/1726825653625143551#m</id>
            <title>RT by @dotey: 有意思</title>
            <link>https://nitter.cz/jefflijun/status/1726825653625143551#m</link>
            <guid isPermaLink="false">https://nitter.cz/jefflijun/status/1726825653625143551#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 04:51:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有意思</p>
<p><a href="https://nitter.cz/FinanceYF5/status/1726773418790699245#m">nitter.cz/FinanceYF5/status/1726773418790699245#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726824524371415385#m</id>
            <title>OpenAI：周末大事记
2023 年 11 月 20 日，TheZvi 发布

大约在四个 GPT 和七年前，OpenAI 的创始人们在企业领域诞生了一个新实体。这个实体的构思是为了自由，承诺旨在让所有人在人工通用智能（AGI）问世时能够平等生活。

如今，我们正卷入一场激烈的企业战争之中，测试着这个实体，或者说任何这样构思和致力的实体，是否能够长期存续。

重要的不是理论，而是实践。在关键时刻会发生什么？

那么，发生了什么呢？是什么引发了这一系列事件？接下来将会发生什么？

在很大程度上，我们甚至比平时更加一无所知。我们不应该假装知道的比实际更多。

我不打算在这里尝试解释或用无休止的反应和引用轰炸大家，而是会尽力只列出关键事实。

（注：以下提到的所有时间均为东部标准时间。）

事实如何，女士？

我们能确定或至少几乎确定些什么？

这是 OpenAI 的企业结构，赋予其 501c3 组织的董事会有聘请和解雇 CEO 的权力。它明确致力于其非营利使命，优先于对任何次级实体股东的职责。投资者被告知，公司没有任何盈利的义务：

OpenAI 提供的 OpenAI 非常规结构的块状图。

图 1

图 2

以下是我们所知的最值得注意的事实，据我所知：

1. 周五下午 3:28，OpenAI 董事会解雇了 Sam Altman，立即任命 CTO Mira Murati 为临时 CEO。他们通过一个不包括时任董事长 Greg Brockman 的 Google Meet 进行了这一决定。

2. Greg Brockman，Altman 的老朋友和盟友，被撤销董事会主席职务，但董事会表示他将继续担任总裁。作为回应，他选择辞职。

3. 董事会几乎没有通知任何人。微软只得到了一分钟的预警。

4. 据我们所知，Mira Murati 是唯一被告知的人，这发生在周四晚上。

5. 董事会声明称：“Altman 先生的离职是董事会经过深思熟虑的审查过程后作出的决定，认为他在与董事会的沟通中并不始终如一，阻碍了董事会行使其职责的能力。董事会不再对他继续领导 OpenAI 的能力有信心。”

6. 董事会在一份声明中说：“OpenAI 是专门为了推进我们的使命而设立的：确保人工通用智能（AGI）造福全人类。董事会将继续全力支持这一使命。我们感谢 Sam 对 OpenAI 的创立和成长所做的诸多贡献。同时，我们认为在公司向前发展的过程中需要新的领导。作为公司研究、产品和安全功能的负责人，Mira 非常合适担任临时 CEO 的角色。我们对她在这个过渡期间领导 OpenAI 充满信心。”

7. 目前的 OpenAI 董事会成员包括：OpenAI 首席科学家 Ilya Sutskever、独立董事 Quora CEO Adam D’Angelo、技术企业家 Tasha McCauley 以及乔治敦安全与新兴技术中心的 Helen Toner。

8. 通常情况下，501c3 组织的董事会必须由非公司员工占多数。但 OpenAI 的董事会声称，由于 Sam Altman 没有任何股权，多数成员并没有公司利益。

9. 针对许多人称之为“董事会政变”的说法，Sutskever 表示：“你可以这么说，我理解你为什么选择这个词，但我不同意。这是董事会履行其非营利使命的职责，即确保 OpenAI 构建能造福全人类的 AGI。”当被问及“这些幕后的撤换是否是治理世界上最重要公司的好方法？”时，他回答说：“我同意这不理想。百分之百。”

10. 除此之外，董事会在公开场合未发表任何言论。我愿意直言不讳地说，无论最初的理由是什么，这次撤换尝试考虑不足，计划不周，且搞砸了。要么他们有充分的理由证明这些行动是合理的并需要分享这些理由，要么他们没有。

11. Altman 与董事会之间发生了各种冲突。我们不知道它们都是什么。我们确实知道董事会觉得 Altman 行动太快，对安全问题关注不足，过于专注于构建消费产品，同时还创立了其他公司。ChatGPT 是一个很棒的消费产品，但却加速了 AI 的发展，与 OpenAI 公开声明的非营利使命相悖。

12. OpenAI 此前计划进行一次高额认购的股票出售，估值达到 860 亿美元，预计几周后结束。

13. 董事会成员 Adam D’Angelo 在今年 1 月的《福布斯》中表示：“没有一种结果是这个组织成为五大科技公司之一。这是一件根本不同的事情，我希望我们能为世界做更多的好事，而不仅仅是成为另一家变得那么大的公司。”

14. Sam Altman 在 10 月 16 日说：“在 OpenAI 的历史中——最近一次是在过去几周内——我四次有幸在我们推开无知的面纱、向前推进发现的边界时在场。能够做到这一点是我一生职业的荣耀。”有人猜测，事件的驱动力全部或部分来自 OpenAI 内部的秘密能力提升，可能来自一个名为 Gobi 的系统，甚至可能与开玩笑的说法“AI 已在内部实现”有关，但我们没有具体证据。

15. Ilya Sutskever 共同领导了超对齐任务组，对我们获得 AGI 的时间线非常短，非常关心 AI 的存在风险。

16. Sam Altman 参与创立了多家新的重要科技公司。他正在寻求从沙特筹集数百亿美元来创办一家芯片公司。他还参与了其他有关 AI 硬件公司的讨论。

17. Sam Altman 一再声明，包括向国会表示，他非常重视来自 AI 的存在风险。他是 OpenAI 企业结构的创立者之一。他签署了 CAIS 信函。在发布 GPT-4 之前，OpenAI 花费了六个月时间进行安全工作。他明白其中的风险。人们可以质疑 OpenAI 在安全方面的记录，包括那些离开创立 Anthropic 的人。但这不是一个纯粹的“末日论者与加速主义者”的故事。

18. Sam Altman 在权力游戏方面非常擅长，例如争夺企业控制的斗争。多年来，他赢得了员工的忠诚，其中许多人步调一致地行动，使用强烈的战略模糊性。手段玩得很好。

19. 几乎所有的风险投资、科技、创始人、金融 Twitter 都一致谴责董事会解雇 Altman 以及他们的做法，许多员工也是如此，他们呼吁 Altman 返回公司或创立新公司并吸引所有人才。在线上普遍的观点是，无论其企业结构如何，解雇建立公司的 Altman 或危及 OpenAI 的价值都是不可接受的。员工、股东、合作伙伴和其他人联合起来夺回控制权是正确和必要的。

20. 那些圈子里的谈话认为，这将永远彻底败坏 EA 或“末日论者”或对 AI 安全的任何担忧。是的，他们每周都这么说，但这次声音更大、更可信。《纽约时报》却误解了这一点。无论如何，这是一场灾难。

21. 相比之下，那些关心存在风险的人和其他一些人指出，OpenAI 独特的企业结构正是为了这种情况而设计的。他们还大多指出，董事会在决策和沟通上处理得非常糟糕，但还有很多未知之数，试图避免草率下结论。

22. 因此，我们现在正在回答这个问题：法律是什么？我们有法律吗？权力最终在哪里？最终重要的是领袖的魅力吗？你雇佣的人和你的文化吗？企业结构能帮助我们吗，还是商业利益和利润动机最终占据主导地位？

23. 对董事会施加了巨大压力，要求他们恢复 Altman 的职位。他们在周六和周日被给予了两个太平洋时间下午 5 点的最后期限，要求辞职。微软及其 CEO Satya Nadella 的援助被征召。我们不知道微软在此事上使用了什么或没有使用什么杠杆。

24. Sam Altman 推文表示“我非常爱 openai 团队。”许多 OpenAI 的员工回应了心形表情，包括 Mira Murati。

25. 应员工包括 Mira Murati 和其他高管的邀请，Sam Altman 周日访问了 OpenAI 办公室。他推文“这是我第一次也是最后一次戴上这些”，并附上了他访客通行证的照片。

26. 董事会当时似乎不在大楼内。

27. 媒体报道称董事会原则上同意辞职，但在替代董事会成员选择上和是否需要发表声明免除 Altman 过错上遇到了障碍，这对他们来说可能在法律上具有危险性，鉴于他们最初的声明。

28. 彭博社周日晚上 11:16 报道，临时 CEO Mira Murati 计划重新聘请 Altman 和 Brockman，而董事会寻求另一位 CEO。

29. OpenAI 董事会聘请前 Twitch CEO Emmett Shear 担任新 CEO。他在这里发布了他的初始声明。我对他有所了解。如果董事会需要从外部聘请一位认真对待存在风险的新 CEO，他似乎是一个非常出色的选择，我想不出一个更好的选择。他面临的任务可能是不可能完成的，也可能不是。Shear 在他的笔记中的 PPS：PPS：“在我接受这份工作之前，我检查了更换的原因。董事会并不是因为在安全方面的任何具体分歧撤掉了 Sam，他们的理由完全不同。如果没有董事会对商业化我们出色模型的支持，我不会疯到接受这份工作。”

30. 新任 CEO Emmett Shear 在放慢 AI 发展方面发表了言论，尽管并不是停止。他的末日概率（p(doom)）在 5% 到 50% 之间。他说过“我的 AI 安全言论 100% 是‘你们正在构建一个外星神，当它达到临界阈值时将真正摧毁世界，但在此之前看起来无害。’”这里是一个带有更多内容的线索和视频链接，文字记录在这里或有字幕的剪辑。这是他几天前在推特上发布的 2×2 派系图。

31. 微软 CEO Satya Nadella 周一凌晨 2:53 发帖：我们仍然致力于与 OpenAI 的合作，对我们的产品路线图、我们在 Microsoft Ignite 上宣布的继续创新的能力以及继续支持我们的客户和合作伙伴有信心。我们期待着了解 Emmett Shear 和 OAI 的新领导团队，并与他们合作。我们非常兴奋地分享 Sam Altman 和 Greg Brockman 将与同事一起加入微软，领导一个新的先进 AI 研究团队的消息。我们期待迅速为他们提供成功所需的资源。

32. Sam Altman 转推上述内容，并称“使命继续。”Brockman 确认。其他领导包括 GPT-4 负责人 Jackub Pachocki、Szymon Sidor 和 Aleksander Madry。

33. Nadella 接着回复：“Sam，我非常兴奋地邀请你作为这个新团队的 CEO，为创新设定新的节奏。多年来，我们已经学会了如何给予创始人和创新者在微软内部建立独立身份和文化的空间，包括 GitHub、Mojang Studios 和 LinkedIn，我期待着你也能做到这一点。”

34. Ilya Sutskever 周一早上 8:15 发帖：“我深感遗憾参与了董事会的行动。我从未想伤害 OpenAI。我热爱我们一起建立的一切，我将竭尽所能重新团结公司。”Sam 用三个心形表情转推。超对齐团队的另一位负责人 Jan Leike 发推称，他在危机期间工作了整个周末，董事会应该辞职。

35. 微软股价在周五盘后下跌 -1%，但在周一早上和开盘时回到了大致原来的价值。一切都已计入价格。谷歌或标普也没有发生重大变动。

36. OpenAI 的 770 名员工中有 505 名，包括 Ilya Sutskever，签署了一封信，要求董事会辞职并恢复 Altman 和 Brockman 的职位（后来声称达到约 743 人），否则他们将转移到微软，在 Altman 领导下的新子公司工作，那里为每位 OpenAI 员工都有职位。信的全文如下：“致 OpenAI 董事会，OpenAI 是世界领先的 AI 公司。我们，OpenAI 的员工，开发了最佳模型，推动了该领域的新前沿。我们在 AI 安全和治理方面的工作塑造了全球规范。我们构建的产品被全世界数百万人使用。直到现在，我们所工作和珍视的公司从未处于如此强大的地位。你终止 Sam Altman 和撤换 Greg Brockman 从董事会的过程危及了所有这些工作，破坏了我们的使命和公司。你的行为清楚地表明，你没有能力监督 OpenAI。当我们都意外地了解到你的决定时，OpenAI 的领导团队迅速采取行动稳定公司。他们认真倾听了你的担忧，并尽力在各方面与你合作。尽管多次要求你提供具体事实的证据，你从未提供任何书面证据。他们也越来越意识到，你无法履行职责，且是在不诚信地谈判。领导团队建议，向前迈进的最稳定路径——最能服务我们的使命、公司、利益相关者、员工和公众——将是你辞职，并任命一个合格的董事会，以稳定地领导公司向前发展。领导层与你日以继夜地合作，寻找双方都能接受的结果。然而在你最初决定后的两天内，你再次更换了临时 CEO Mira Murati，违背了公司的最佳利益。你还告诉领导团队，允许公司被摧毁‘将符合使命’。你的行为已明显表明，你无法监督 OpenAI。我们无法为或与那些缺乏能力、判断力和对我们的使命及员工的关心的人一起工作。我们，以下签名者，可能会选择辞去 OpenAI 的职位，并加入 Sam Altman 和 Greg Brockman 领导的新宣布的微软子公司。微软已向我们保证，如果我们选择加入，这个新子公司将为所有 OpenAI 员工提供职位。除非所有现任董事会成员辞职，并且董事会任命两位新的首席独立董事，例如 Bret Taylor 和 Will Hurd，并恢复 Sam Altman 和 Greg Brockman 的职位，否则我们将立即采取这一步骤。”

37. 有人谈论 OpenAI 可能会完全解体，ChatGPT 可能在几天后就无法工作，等等。

38. 这件事远未结束，仍在发展中。

39. 我们仍然有很多不知道的。

40. 这个周末对每个人来说都非常紧张。我们大多数人，包括我在内，真诚地希望这一切都没有发生。根据我们所知，实际重要的故事中没有恶人。只有在高度紧张的情况下尽力而为的人，他们面临巨大的风险，拥有完全不同的信息和不同的世界模型以及什么将导致好结果。简而言之，对于那些在任何一方或试图处理这一情况的人，而不是吐槽：❤️。

稍后，当我们了解更多时，我将有许多其他事情要说，许多反应要引用和回应。但现在，请大家尽力保持理智，帮助世界尽可能好地度过这一切。

https://thezvi.wordpress.com/2023/11/20/openai-facts-from-a-weekend/</title>
            <link>https://nitter.cz/dotey/status/1726824524371415385#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726824524371415385#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 04:47:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI：周末大事记<br />
2023 年 11 月 20 日，TheZvi 发布<br />
<br />
大约在四个 GPT 和七年前，OpenAI 的创始人们在企业领域诞生了一个新实体。这个实体的构思是为了自由，承诺旨在让所有人在人工通用智能（AGI）问世时能够平等生活。<br />
<br />
如今，我们正卷入一场激烈的企业战争之中，测试着这个实体，或者说任何这样构思和致力的实体，是否能够长期存续。<br />
<br />
重要的不是理论，而是实践。在关键时刻会发生什么？<br />
<br />
那么，发生了什么呢？是什么引发了这一系列事件？接下来将会发生什么？<br />
<br />
在很大程度上，我们甚至比平时更加一无所知。我们不应该假装知道的比实际更多。<br />
<br />
我不打算在这里尝试解释或用无休止的反应和引用轰炸大家，而是会尽力只列出关键事实。<br />
<br />
（注：以下提到的所有时间均为东部标准时间。）<br />
<br />
事实如何，女士？<br />
<br />
我们能确定或至少几乎确定些什么？<br />
<br />
这是 OpenAI 的企业结构，赋予其 501c3 组织的董事会有聘请和解雇 CEO 的权力。它明确致力于其非营利使命，优先于对任何次级实体股东的职责。投资者被告知，公司没有任何盈利的义务：<br />
<br />
OpenAI 提供的 OpenAI 非常规结构的块状图。<br />
<br />
图 1<br />
<br />
图 2<br />
<br />
以下是我们所知的最值得注意的事实，据我所知：<br />
<br />
1. 周五下午 3:28，OpenAI 董事会解雇了 Sam Altman，立即任命 CTO Mira Murati 为临时 CEO。他们通过一个不包括时任董事长 Greg Brockman 的 Google Meet 进行了这一决定。<br />
<br />
2. Greg Brockman，Altman 的老朋友和盟友，被撤销董事会主席职务，但董事会表示他将继续担任总裁。作为回应，他选择辞职。<br />
<br />
3. 董事会几乎没有通知任何人。微软只得到了一分钟的预警。<br />
<br />
4. 据我们所知，Mira Murati 是唯一被告知的人，这发生在周四晚上。<br />
<br />
5. 董事会声明称：“Altman 先生的离职是董事会经过深思熟虑的审查过程后作出的决定，认为他在与董事会的沟通中并不始终如一，阻碍了董事会行使其职责的能力。董事会不再对他继续领导 OpenAI 的能力有信心。”<br />
<br />
6. 董事会在一份声明中说：“OpenAI 是专门为了推进我们的使命而设立的：确保人工通用智能（AGI）造福全人类。董事会将继续全力支持这一使命。我们感谢 Sam 对 OpenAI 的创立和成长所做的诸多贡献。同时，我们认为在公司向前发展的过程中需要新的领导。作为公司研究、产品和安全功能的负责人，Mira 非常合适担任临时 CEO 的角色。我们对她在这个过渡期间领导 OpenAI 充满信心。”<br />
<br />
7. 目前的 OpenAI 董事会成员包括：OpenAI 首席科学家 Ilya Sutskever、独立董事 Quora CEO Adam D’Angelo、技术企业家 Tasha McCauley 以及乔治敦安全与新兴技术中心的 Helen Toner。<br />
<br />
8. 通常情况下，501c3 组织的董事会必须由非公司员工占多数。但 OpenAI 的董事会声称，由于 Sam Altman 没有任何股权，多数成员并没有公司利益。<br />
<br />
9. 针对许多人称之为“董事会政变”的说法，Sutskever 表示：“你可以这么说，我理解你为什么选择这个词，但我不同意。这是董事会履行其非营利使命的职责，即确保 OpenAI 构建能造福全人类的 AGI。”当被问及“这些幕后的撤换是否是治理世界上最重要公司的好方法？”时，他回答说：“我同意这不理想。百分之百。”<br />
<br />
10. 除此之外，董事会在公开场合未发表任何言论。我愿意直言不讳地说，无论最初的理由是什么，这次撤换尝试考虑不足，计划不周，且搞砸了。要么他们有充分的理由证明这些行动是合理的并需要分享这些理由，要么他们没有。<br />
<br />
11. Altman 与董事会之间发生了各种冲突。我们不知道它们都是什么。我们确实知道董事会觉得 Altman 行动太快，对安全问题关注不足，过于专注于构建消费产品，同时还创立了其他公司。ChatGPT 是一个很棒的消费产品，但却加速了 AI 的发展，与 OpenAI 公开声明的非营利使命相悖。<br />
<br />
12. OpenAI 此前计划进行一次高额认购的股票出售，估值达到 860 亿美元，预计几周后结束。<br />
<br />
13. 董事会成员 Adam D’Angelo 在今年 1 月的《福布斯》中表示：“没有一种结果是这个组织成为五大科技公司之一。这是一件根本不同的事情，我希望我们能为世界做更多的好事，而不仅仅是成为另一家变得那么大的公司。”<br />
<br />
14. Sam Altman 在 10 月 16 日说：“在 OpenAI 的历史中——最近一次是在过去几周内——我四次有幸在我们推开无知的面纱、向前推进发现的边界时在场。能够做到这一点是我一生职业的荣耀。”有人猜测，事件的驱动力全部或部分来自 OpenAI 内部的秘密能力提升，可能来自一个名为 Gobi 的系统，甚至可能与开玩笑的说法“AI 已在内部实现”有关，但我们没有具体证据。<br />
<br />
15. Ilya Sutskever 共同领导了超对齐任务组，对我们获得 AGI 的时间线非常短，非常关心 AI 的存在风险。<br />
<br />
16. Sam Altman 参与创立了多家新的重要科技公司。他正在寻求从沙特筹集数百亿美元来创办一家芯片公司。他还参与了其他有关 AI 硬件公司的讨论。<br />
<br />
17. Sam Altman 一再声明，包括向国会表示，他非常重视来自 AI 的存在风险。他是 OpenAI 企业结构的创立者之一。他签署了 CAIS 信函。在发布 GPT-4 之前，OpenAI 花费了六个月时间进行安全工作。他明白其中的风险。人们可以质疑 OpenAI 在安全方面的记录，包括那些离开创立 Anthropic 的人。但这不是一个纯粹的“末日论者与加速主义者”的故事。<br />
<br />
18. Sam Altman 在权力游戏方面非常擅长，例如争夺企业控制的斗争。多年来，他赢得了员工的忠诚，其中许多人步调一致地行动，使用强烈的战略模糊性。手段玩得很好。<br />
<br />
19. 几乎所有的风险投资、科技、创始人、金融 Twitter 都一致谴责董事会解雇 Altman 以及他们的做法，许多员工也是如此，他们呼吁 Altman 返回公司或创立新公司并吸引所有人才。在线上普遍的观点是，无论其企业结构如何，解雇建立公司的 Altman 或危及 OpenAI 的价值都是不可接受的。员工、股东、合作伙伴和其他人联合起来夺回控制权是正确和必要的。<br />
<br />
20. 那些圈子里的谈话认为，这将永远彻底败坏 EA 或“末日论者”或对 AI 安全的任何担忧。是的，他们每周都这么说，但这次声音更大、更可信。《纽约时报》却误解了这一点。无论如何，这是一场灾难。<br />
<br />
21. 相比之下，那些关心存在风险的人和其他一些人指出，OpenAI 独特的企业结构正是为了这种情况而设计的。他们还大多指出，董事会在决策和沟通上处理得非常糟糕，但还有很多未知之数，试图避免草率下结论。<br />
<br />
22. 因此，我们现在正在回答这个问题：法律是什么？我们有法律吗？权力最终在哪里？最终重要的是领袖的魅力吗？你雇佣的人和你的文化吗？企业结构能帮助我们吗，还是商业利益和利润动机最终占据主导地位？<br />
<br />
23. 对董事会施加了巨大压力，要求他们恢复 Altman 的职位。他们在周六和周日被给予了两个太平洋时间下午 5 点的最后期限，要求辞职。微软及其 CEO Satya Nadella 的援助被征召。我们不知道微软在此事上使用了什么或没有使用什么杠杆。<br />
<br />
24. Sam Altman 推文表示“我非常爱 openai 团队。”许多 OpenAI 的员工回应了心形表情，包括 Mira Murati。<br />
<br />
25. 应员工包括 Mira Murati 和其他高管的邀请，Sam Altman 周日访问了 OpenAI 办公室。他推文“这是我第一次也是最后一次戴上这些”，并附上了他访客通行证的照片。<br />
<br />
26. 董事会当时似乎不在大楼内。<br />
<br />
27. 媒体报道称董事会原则上同意辞职，但在替代董事会成员选择上和是否需要发表声明免除 Altman 过错上遇到了障碍，这对他们来说可能在法律上具有危险性，鉴于他们最初的声明。<br />
<br />
28. 彭博社周日晚上 11:16 报道，临时 CEO Mira Murati 计划重新聘请 Altman 和 Brockman，而董事会寻求另一位 CEO。<br />
<br />
29. OpenAI 董事会聘请前 Twitch CEO Emmett Shear 担任新 CEO。他在这里发布了他的初始声明。我对他有所了解。如果董事会需要从外部聘请一位认真对待存在风险的新 CEO，他似乎是一个非常出色的选择，我想不出一个更好的选择。他面临的任务可能是不可能完成的，也可能不是。Shear 在他的笔记中的 PPS：PPS：“在我接受这份工作之前，我检查了更换的原因。董事会并不是因为在安全方面的任何具体分歧撤掉了 Sam，他们的理由完全不同。如果没有董事会对商业化我们出色模型的支持，我不会疯到接受这份工作。”<br />
<br />
30. 新任 CEO Emmett Shear 在放慢 AI 发展方面发表了言论，尽管并不是停止。他的末日概率（p(doom)）在 5% 到 50% 之间。他说过“我的 AI 安全言论 100% 是‘你们正在构建一个外星神，当它达到临界阈值时将真正摧毁世界，但在此之前看起来无害。’”这里是一个带有更多内容的线索和视频链接，文字记录在这里或有字幕的剪辑。这是他几天前在推特上发布的 2×2 派系图。<br />
<br />
31. 微软 CEO Satya Nadella 周一凌晨 2:53 发帖：我们仍然致力于与 OpenAI 的合作，对我们的产品路线图、我们在 Microsoft Ignite 上宣布的继续创新的能力以及继续支持我们的客户和合作伙伴有信心。我们期待着了解 Emmett Shear 和 OAI 的新领导团队，并与他们合作。我们非常兴奋地分享 Sam Altman 和 Greg Brockman 将与同事一起加入微软，领导一个新的先进 AI 研究团队的消息。我们期待迅速为他们提供成功所需的资源。<br />
<br />
32. Sam Altman 转推上述内容，并称“使命继续。”Brockman 确认。其他领导包括 GPT-4 负责人 Jackub Pachocki、Szymon Sidor 和 Aleksander Madry。<br />
<br />
33. Nadella 接着回复：“Sam，我非常兴奋地邀请你作为这个新团队的 CEO，为创新设定新的节奏。多年来，我们已经学会了如何给予创始人和创新者在微软内部建立独立身份和文化的空间，包括 GitHub、Mojang Studios 和 LinkedIn，我期待着你也能做到这一点。”<br />
<br />
34. Ilya Sutskever 周一早上 8:15 发帖：“我深感遗憾参与了董事会的行动。我从未想伤害 OpenAI。我热爱我们一起建立的一切，我将竭尽所能重新团结公司。”Sam 用三个心形表情转推。超对齐团队的另一位负责人 Jan Leike 发推称，他在危机期间工作了整个周末，董事会应该辞职。<br />
<br />
35. 微软股价在周五盘后下跌 -1%，但在周一早上和开盘时回到了大致原来的价值。一切都已计入价格。谷歌或标普也没有发生重大变动。<br />
<br />
36. OpenAI 的 770 名员工中有 505 名，包括 Ilya Sutskever，签署了一封信，要求董事会辞职并恢复 Altman 和 Brockman 的职位（后来声称达到约 743 人），否则他们将转移到微软，在 Altman 领导下的新子公司工作，那里为每位 OpenAI 员工都有职位。信的全文如下：“致 OpenAI 董事会，OpenAI 是世界领先的 AI 公司。我们，OpenAI 的员工，开发了最佳模型，推动了该领域的新前沿。我们在 AI 安全和治理方面的工作塑造了全球规范。我们构建的产品被全世界数百万人使用。直到现在，我们所工作和珍视的公司从未处于如此强大的地位。你终止 Sam Altman 和撤换 Greg Brockman 从董事会的过程危及了所有这些工作，破坏了我们的使命和公司。你的行为清楚地表明，你没有能力监督 OpenAI。当我们都意外地了解到你的决定时，OpenAI 的领导团队迅速采取行动稳定公司。他们认真倾听了你的担忧，并尽力在各方面与你合作。尽管多次要求你提供具体事实的证据，你从未提供任何书面证据。他们也越来越意识到，你无法履行职责，且是在不诚信地谈判。领导团队建议，向前迈进的最稳定路径——最能服务我们的使命、公司、利益相关者、员工和公众——将是你辞职，并任命一个合格的董事会，以稳定地领导公司向前发展。领导层与你日以继夜地合作，寻找双方都能接受的结果。然而在你最初决定后的两天内，你再次更换了临时 CEO Mira Murati，违背了公司的最佳利益。你还告诉领导团队，允许公司被摧毁‘将符合使命’。你的行为已明显表明，你无法监督 OpenAI。我们无法为或与那些缺乏能力、判断力和对我们的使命及员工的关心的人一起工作。我们，以下签名者，可能会选择辞去 OpenAI 的职位，并加入 Sam Altman 和 Greg Brockman 领导的新宣布的微软子公司。微软已向我们保证，如果我们选择加入，这个新子公司将为所有 OpenAI 员工提供职位。除非所有现任董事会成员辞职，并且董事会任命两位新的首席独立董事，例如 Bret Taylor 和 Will Hurd，并恢复 Sam Altman 和 Greg Brockman 的职位，否则我们将立即采取这一步骤。”<br />
<br />
37. 有人谈论 OpenAI 可能会完全解体，ChatGPT 可能在几天后就无法工作，等等。<br />
<br />
38. 这件事远未结束，仍在发展中。<br />
<br />
39. 我们仍然有很多不知道的。<br />
<br />
40. 这个周末对每个人来说都非常紧张。我们大多数人，包括我在内，真诚地希望这一切都没有发生。根据我们所知，实际重要的故事中没有恶人。只有在高度紧张的情况下尽力而为的人，他们面临巨大的风险，拥有完全不同的信息和不同的世界模型以及什么将导致好结果。简而言之，对于那些在任何一方或试图处理这一情况的人，而不是吐槽：❤️。<br />
<br />
稍后，当我们了解更多时，我将有许多其他事情要说，许多反应要引用和回应。但现在，请大家尽力保持理智，帮助世界尽可能好地度过这一切。<br />
<br />
<a href="https://thezvi.wordpress.com/2023/11/20/openai-facts-from-a-weekend/">thezvi.wordpress.com/2023/11…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9icHQ4SFhBQUEzd3F1LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9icHZzcldRQUFhVEl5LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726820663988461686#m</id>
            <title>发现 GPTs 到限额不能用了以后还能用 ChatGPT 4！

挺好，主要是 GPT 太好用都想不起来要用 ChatGPT</title>
            <link>https://nitter.cz/dotey/status/1726820663988461686#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726820663988461686#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 04:31:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>发现 GPTs 到限额不能用了以后还能用 ChatGPT 4！<br />
<br />
挺好，主要是 GPT 太好用都想不起来要用 ChatGPT</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726819577177268231#m</id>
            <title>更多人将幕后黑手指向了POE的CEO Adam：

因为有些人 *仍然* 不明白发生了什么，让我介绍一下董事会的“主要”成员 - Adam D'Angelo。

Adam 拥有一家叫 Poe 的公司，由于 OpenAI 在开发者日宣布的 GPTs 技术，Poe 公司显得过时了。

Adam 对于董事会没有提前通知他，使得他的竞争对手能够抢先一步，感到非常愤怒。

Adam 说服了董事会中的 EA（有效利他主义）人士，让他们相信存在一种严重的 AI 风险，同时暗示 Sam 故意隐瞒信息（他对 GPTs 的推出感到不满）。

Adam 的目标是敌意接管 OpenAI —— 这一切都是为了打倒他的头号竞争对手。

Adam 拒绝公开发表声明，因为他正在忙于处理法律事务。

可以说，Adam 是这一切背后的策划者。</title>
            <link>https://nitter.cz/dotey/status/1726819577177268231#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726819577177268231#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 04:27:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>更多人将幕后黑手指向了POE的CEO Adam：<br />
<br />
因为有些人 *仍然* 不明白发生了什么，让我介绍一下董事会的“主要”成员 - Adam D'Angelo。<br />
<br />
Adam 拥有一家叫 Poe 的公司，由于 OpenAI 在开发者日宣布的 GPTs 技术，Poe 公司显得过时了。<br />
<br />
Adam 对于董事会没有提前通知他，使得他的竞争对手能够抢先一步，感到非常愤怒。<br />
<br />
Adam 说服了董事会中的 EA（有效利他主义）人士，让他们相信存在一种严重的 AI 风险，同时暗示 Sam 故意隐瞒信息（他对 GPTs 的推出感到不满）。<br />
<br />
Adam 的目标是敌意接管 OpenAI —— 这一切都是为了打倒他的头号竞争对手。<br />
<br />
Adam 拒绝公开发表声明，因为他正在忙于处理法律事务。<br />
<br />
可以说，Adam 是这一切背后的策划者。</p>
<p><a href="https://nitter.cz/williamlegate/status/1726715671487156554#m">nitter.cz/williamlegate/status/1726715671487156554#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mranti/status/1726814901212230137#m</id>
            <title>RT by @dotey: 现在最近的动机解释是D'Angelo，唯一有利益冲突的OpenAI独董，突然发现新发布的GPTs直接杀死了自己的Poe，非常生气Sam对他保密，所以煽动其他独董和耳朵根子软的ILya投出了致命的四票。目前ILya道歉，另外2个独董锁推，D'Angelo在寻找律师，因为OpenAI的股东准备告他。实际上他早就没资格做独董了。</title>
            <link>https://nitter.cz/mranti/status/1726814901212230137#m</link>
            <guid isPermaLink="false">https://nitter.cz/mranti/status/1726814901212230137#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 04:08:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在最近的动机解释是D'Angelo，唯一有利益冲突的OpenAI独董，突然发现新发布的GPTs直接杀死了自己的Poe，非常生气Sam对他保密，所以煽动其他独董和耳朵根子软的ILya投出了致命的四票。目前ILya道歉，另外2个独董锁推，D'Angelo在寻找律师，因为OpenAI的股东准备告他。实际上他早就没资格做独董了。</p>
<p><a href="https://nitter.cz/williamlegate/status/1726715671487156554#m">nitter.cz/williamlegate/status/1726715671487156554#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726812249115746362#m</id>
            <title>很多人认为微软是最大赢家，这是一种不同的观点：

有人说，对于最近几天发生的事情，我的看法似乎与众不同，我想分享一下我的观点。

与 Kevin Roose 和其他人的观点相反，我认为 Microsoft 在最近围绕 #OpenAI 的事件中并没有占据上风。实际上，他们在上周五早上的情况比现在好多了。那时，Microsoft 已经投资了约 110 亿美元于 OpenAI，并且基本上把握了其大部分增值潜力，同时还保持了足够的距离，让他们可以对监管机构声称诸如“ChatGPT 比 Meta 的 Llama 更开放”这样的话。同时，任何尴尬的大语言模型 (LLM) 幻觉或其他问题都被视为 OpenAI 而非 Microsoft 的责任。

然而到了周日早上，情况跌至谷底。Microsoft 面临着可能失去他们全部约 110 亿美元投资的真实风险，且因缺乏有效的治理控制而在投资这么大的一笔款项上显得非常愚蠢。很多关注新闻的聪明人，包括一些持有 $MSFT 股票的大基金经理，都在向我询问这种情况是如何发生的。

尽管今天的情况比周日好一些，但仍远不及上周五。的确，Microsoft 可能会聘请不少 OpenAI 的团队成员。但这并没有为他们带来任何新的优势，反而带来了大量新的声誉风险（他们现在需要对任何不当行为负责）和执行风险（可以参考 Google 旗下的 DeepMind，即使是 AI 领域最顶尖的人才也可能被大公司的官僚体制所困）。

我认为，OpenAI 的高级人员在未来三年内留在 Microsoft 的可能性越来越小。OpenAI 的独立性和明确使命本是吸引这群卓越人才长期保持积极和一致的关键因素。然而，让 Office365 的电子表格变得稍微智能一点并不足以激发他们的团队士气。尽管他们可能会尝试保持一定的独立性，但在一个超过万亿美元的商业软件巨头的大机器中，很难不被卷入其中并最终被磨损。

这对 Microsoft 和 OpenAI 来说，都是糟糕的一周。我看不到任何明显的赢家（也许 Elon Musk 或 Marc Benioff（Salesforce 的 CEO）会间接受益？）。虽然情况本可更糟，但这对所有直接相关的人来说仍是一场灾难。这个故事还远未结束，但短期内 Microsoft 情况好转的可能性不大。甚至从长期来看，与上周五 Microsoft 和 OpenAI 的情况相比，也很难看到会有更好的转机。

换句话说，有时候，出于多种原因，拥有一项资产的期权比拥有资产本身更有利。上周，Microsoft 大致上拥有了 OpenAI 的一个期权。但现在，他们最多只是拥有了部分资产本身。</title>
            <link>https://nitter.cz/dotey/status/1726812249115746362#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726812249115746362#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 03:58:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>很多人认为微软是最大赢家，这是一种不同的观点：<br />
<br />
有人说，对于最近几天发生的事情，我的看法似乎与众不同，我想分享一下我的观点。<br />
<br />
与 Kevin Roose 和其他人的观点相反，我认为 Microsoft 在最近围绕 <a href="https://nitter.cz/search?q=%23OpenAI">#OpenAI</a> 的事件中并没有占据上风。实际上，他们在上周五早上的情况比现在好多了。那时，Microsoft 已经投资了约 110 亿美元于 OpenAI，并且基本上把握了其大部分增值潜力，同时还保持了足够的距离，让他们可以对监管机构声称诸如“ChatGPT 比 Meta 的 Llama 更开放”这样的话。同时，任何尴尬的大语言模型 (LLM) 幻觉或其他问题都被视为 OpenAI 而非 Microsoft 的责任。<br />
<br />
然而到了周日早上，情况跌至谷底。Microsoft 面临着可能失去他们全部约 110 亿美元投资的真实风险，且因缺乏有效的治理控制而在投资这么大的一笔款项上显得非常愚蠢。很多关注新闻的聪明人，包括一些持有 <a href="https://nitter.cz/search?q=%23MSFT">$MSFT</a> 股票的大基金经理，都在向我询问这种情况是如何发生的。<br />
<br />
尽管今天的情况比周日好一些，但仍远不及上周五。的确，Microsoft 可能会聘请不少 OpenAI 的团队成员。但这并没有为他们带来任何新的优势，反而带来了大量新的声誉风险（他们现在需要对任何不当行为负责）和执行风险（可以参考 Google 旗下的 DeepMind，即使是 AI 领域最顶尖的人才也可能被大公司的官僚体制所困）。<br />
<br />
我认为，OpenAI 的高级人员在未来三年内留在 Microsoft 的可能性越来越小。OpenAI 的独立性和明确使命本是吸引这群卓越人才长期保持积极和一致的关键因素。然而，让 Office365 的电子表格变得稍微智能一点并不足以激发他们的团队士气。尽管他们可能会尝试保持一定的独立性，但在一个超过万亿美元的商业软件巨头的大机器中，很难不被卷入其中并最终被磨损。<br />
<br />
这对 Microsoft 和 OpenAI 来说，都是糟糕的一周。我看不到任何明显的赢家（也许 Elon Musk 或 Marc Benioff（Salesforce 的 CEO）会间接受益？）。虽然情况本可更糟，但这对所有直接相关的人来说仍是一场灾难。这个故事还远未结束，但短期内 Microsoft 情况好转的可能性不大。甚至从长期来看，与上周五 Microsoft 和 OpenAI 的情况相比，也很难看到会有更好的转机。<br />
<br />
换句话说，有时候，出于多种原因，拥有一项资产的期权比拥有资产本身更有利。上周，Microsoft 大致上拥有了 OpenAI 的一个期权。但现在，他们最多只是拥有了部分资产本身。</p>
<p><a href="https://nitter.cz/eastdakota/status/1726735785188073726#m">nitter.cz/eastdakota/status/1726735785188073726#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726809515448840482#m</id>
            <title>通往 AGI (人工通用智能) 的激动人心、充满危险的旅程 | Ilya Sutskever | TED

在 OpenAI 的管理层巨变震动硅谷并引起国际关注的几周前，该公司联合创始人及首席科学家 Ilya Sutskever 深入探讨了人工通用智能 (AGI) 的革命性潜力。他详细阐述了 AGI 如何可能超越人类智能，从而彻底改变我们生活的方方面面。在这次演讲中，你将听到他对 AGI 所带来的巨大机遇与潜在风险的看法，以及他对于通过前所未有的合作来确保 AGI 安全、有益发展的乐观期望。（该演讲于 2023 年 10 月 17 日录制）</title>
            <link>https://nitter.cz/dotey/status/1726809515448840482#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726809515448840482#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 03:47:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>通往 AGI (人工通用智能) 的激动人心、充满危险的旅程 | Ilya Sutskever | TED<br />
<br />
在 OpenAI 的管理层巨变震动硅谷并引起国际关注的几周前，该公司联合创始人及首席科学家 Ilya Sutskever 深入探讨了人工通用智能 (AGI) 的革命性潜力。他详细阐述了 AGI 如何可能超越人类智能，从而彻底改变我们生活的方方面面。在这次演讲中，你将听到他对 AGI 所带来的巨大机遇与潜在风险的看法，以及他对于通过前所未有的合作来确保 AGI 安全、有益发展的乐观期望。（该演讲于 2023 年 10 月 17 日录制）</p>
<p><a href="https://nitter.cz/DrJimFan/status/1726763792556839253#m">nitter.cz/DrJimFan/status/1726763792556839253#m</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI2ODA3MDIyNjM5NzEwMjA4L2ltZy91R0YwNHhBajQ2dThzUlVsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/monday_chen/status/1726792034990821452#m</id>
            <title>RT by @dotey: 帮没有追硅谷年度大戏《OpenAI 之 Sam Altman王者归来》的朋友梳理一下到目前为止的剧情</title>
            <link>https://nitter.cz/monday_chen/status/1726792034990821452#m</link>
            <guid isPermaLink="false">https://nitter.cz/monday_chen/status/1726792034990821452#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 02:37:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>帮没有追硅谷年度大戏《OpenAI 之 Sam Altman王者归来》的朋友梳理一下到目前为止的剧情</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9iTU1fdVdBQUEyYTNILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/DrJimFan/status/1726763792556839253#m</id>
            <title>RT by @dotey: I was honored to share the TED AI stage with Ilya on Oct. 17. His speech video is out today (mine's still being edited). I think it provides relevant context tokens to the ongoing events. Transcript starting at ~10'20": 

As AI continues to progress, as technology advances, [...] What I claim will happen is that people will start to act in unprecedentedly collaborative ways out of their own self-interest. It's already happening right now. 

You see the leading AGI companies starting to collaborate, such as the Frontiers model forum. And we will expect that companies, even competitors, will share technical information to make their AI safe. We may even see governments do this.

As another example, at OpenAI, we really believed in how dramatic AGI is going to be. So, one of the ideas that we were operating by, and it's been written on our website for 5 years now, is that when technology gets such that we are very close to AGI, to computers smarter than humans, if some other company is far ahead of us, then rather than compete with them, we will help them out, join them, in a sense.

And why do that? Because we appreciate how incredibly dramatic AGI is going to be. And my claim is that with each generation of capability advancements, as AI gets better and as all of you experience what AI can do, as people who run AI efforts and AGI efforts, and people who work on them will experience it as well, this will change the way we see AI and AGI. And that will change collective behavior. And this is an important reason why I'm hopeful that, despite the great challenges posed by this technology, we will overcome them.

@TEDAI2023 https://www.youtube.com/watch?v=SEkGLj0bwAU</title>
            <link>https://nitter.cz/DrJimFan/status/1726763792556839253#m</link>
            <guid isPermaLink="false">https://nitter.cz/DrJimFan/status/1726763792556839253#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 00:45:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>I was honored to share the TED AI stage with Ilya on Oct. 17. His speech video is out today (mine's still being edited). I think it provides relevant context tokens to the ongoing events. Transcript starting at ~10'20": <br />
<br />
As AI continues to progress, as technology advances, [...] What I claim will happen is that people will start to act in unprecedentedly collaborative ways out of their own self-interest. It's already happening right now. <br />
<br />
You see the leading AGI companies starting to collaborate, such as the Frontiers model forum. And we will expect that companies, even competitors, will share technical information to make their AI safe. We may even see governments do this.<br />
<br />
As another example, at OpenAI, we really believed in how dramatic AGI is going to be. So, one of the ideas that we were operating by, and it's been written on our website for 5 years now, is that when technology gets such that we are very close to AGI, to computers smarter than humans, if some other company is far ahead of us, then rather than compete with them, we will help them out, join them, in a sense.<br />
<br />
And why do that? Because we appreciate how incredibly dramatic AGI is going to be. And my claim is that with each generation of capability advancements, as AI gets better and as all of you experience what AI can do, as people who run AI efforts and AGI efforts, and people who work on them will experience it as well, this will change the way we see AI and AGI. And that will change collective behavior. And this is an important reason why I'm hopeful that, despite the great challenges posed by this technology, we will overcome them.<br />
<br />
<a href="https://nitter.cz/TEDAI2023" title="TED AI">@TEDAI2023</a> <a href="https://www.youtube.com/watch?v=SEkGLj0bwAU">youtube.com/watch?v=SEkGLj0b…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI2NzYxNjMzNjYwNDk3OTIwL2ltZy94X0VYUWNqWUhQeHNtMFk1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726780803688861738#m</id>
            <title>R to @dotey: x.com/mranti/status/17267779…</title>
            <link>https://nitter.cz/dotey/status/1726780803688861738#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726780803688861738#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 01:53:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://x.com/mranti/status/1726777932016968045?s=20">x.com/mranti/status/17267779…</a></p>
<p><a href="https://nitter.cz/mranti/status/1726777932016968045#m">nitter.cz/mranti/status/1726777932016968045#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mranti/status/1726777932016968045#m</id>
            <title>RT by @dotey: 现在看来，真正的大BOSS就是目前在董事会的三个独立董事，一个是OpenAI的对手（Poe） @adamdangelo ，一个也是OpenAI地理业务子公司的董事@TashaMcCauley  ，一个和OpenAI无关 @hlntnr 。这三个没OpenAI股份、也不拿OpenAI工资的人，却一个晚上摧毁了这家伟大的企业，这说明这治理结构荒谬的可怕。</title>
            <link>https://nitter.cz/mranti/status/1726777932016968045#m</link>
            <guid isPermaLink="false">https://nitter.cz/mranti/status/1726777932016968045#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 01:41:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在看来，真正的大BOSS就是目前在董事会的三个独立董事，一个是OpenAI的对手（Poe） <a href="https://nitter.cz/adamdangelo" title="Adam D'Angelo">@adamdangelo</a> ，一个也是OpenAI地理业务子公司的董事<a href="https://nitter.cz/TashaMcCauley" title="Tasha McCauley">@TashaMcCauley</a>  ，一个和OpenAI无关 <a href="https://nitter.cz/hlntnr" title="Helen Toner">@hlntnr</a> 。这三个没OpenAI股份、也不拿OpenAI工资的人，却一个晚上摧毁了这家伟大的企业，这说明这治理结构荒谬的可怕。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726779854719168968#m</id>
            <title>整天想着怎么限制AI，结果没想到最应该限制的是董事会！

OpenAI 董事会主动与 Anthropic 探讨合并可能

据一位直接知情人士透露，OpenAI 的董事会主动联系了其竞争对手——大语言模型 (Large Language Model) 开发公司 Anthropic 的联合创始人兼 CEO Dario Amodei，探讨了两家公司合并的可能性。这一举动发生在 OpenAI 的董事会上周五解除了 Sam Altman 的 CEO 职务之后，目的是想说服 Amodei 接替 Altman 成为 OpenAI 的新 CEO。

目前还不清楚这个合并提案是否引发了深入讨论。由于 Amodei 在 Anthropic 的角色，他很快就拒绝了成为 CEO 的提议。这家成立两年的初创公司正在销售 Claude 聊天机器人，该产品与 OpenAI 的 ChatGPT 相竞争，Anthropic 正在与 OpenAI 展开激烈的争夺，试图吸引更多研究人员并赢得客户。</title>
            <link>https://nitter.cz/dotey/status/1726779854719168968#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726779854719168968#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 01:49:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整天想着怎么限制AI，结果没想到最应该限制的是董事会！<br />
<br />
OpenAI 董事会主动与 Anthropic 探讨合并可能<br />
<br />
据一位直接知情人士透露，OpenAI 的董事会主动联系了其竞争对手——大语言模型 (Large Language Model) 开发公司 Anthropic 的联合创始人兼 CEO Dario Amodei，探讨了两家公司合并的可能性。这一举动发生在 OpenAI 的董事会上周五解除了 Sam Altman 的 CEO 职务之后，目的是想说服 Amodei 接替 Altman 成为 OpenAI 的新 CEO。<br />
<br />
目前还不清楚这个合并提案是否引发了深入讨论。由于 Amodei 在 Anthropic 的角色，他很快就拒绝了成为 CEO 的提议。这家成立两年的初创公司正在销售 Claude 聊天机器人，该产品与 OpenAI 的 ChatGPT 相竞争，Anthropic 正在与 OpenAI 展开激烈的争夺，试图吸引更多研究人员并赢得客户。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726776018612920398#m</id>
            <title>一种观点认为是 Dustin Moskovitz 和 Sam Altman 之间的矛盾，Ilya 可能被卷入了这件事，而他本人可能并不知情（这或许能解释为何他后来改变了自己的立场）：

提升 alphanerd 这个引人入胜的深层评论到显眼位置：

> 我在其他地方也提到过，我觉得这是 Dustin Moskovitz 和 Sam Altman 之间的一场冲突。Ilya 可能被卷入了这件事，而他本人可能并不知情（这或许能解释为何他后来改变了自己的立场）。Dustin Moskovitz 不仅是 Facebook 的早期员工，还是 Asana 的创始人。他还和一些微软（Microsoft）的高管一起创建了一个名为 Open Philanthropy 的非盈利组织，这个组织是有效利他主义的早期支持者，并为 OpenAI 提供了 3000 万美元的资助。他还是人工智能公司 Anthropic 的早期投资者。

> 大部分 OpenAI 董事会成员都和 Dustin Moskovitz 有着千丝万缕的联系。

> - Adam D'Angelo 是 Asana 董事会的成员，同时也是 Moskovitz 和 Altman 的密友

> - Helen Toner 在 Open Philanthropy 为 Dustin Moskovitz 工作，负责管理他们对 OpenAI 的资助。她还曾是 AI 治理中心的成员，当时 McCauley 是该中心的董事会成员。Toner 离职后不久，AI 治理中心就从 Open Philanthropy 获得了 100 万美元的资助，而 McCauley 随后加入了 OpenAI 的董事会

> - Tasha McCauley 代表 AI 治理中心，这个中心通过 Open Philanthropy 获得了 Dustin Moskovitz 提供的 100 万美元资助，后来 McCauley 加入了 OpenAI 的董事会

> 在过去几个月里，Dustin Moskovitz 对人工智能安全问题的警告也越来越频繁。

> 总的来看，这似乎是 Sam Altman 和 Dustin Moskovitz 之间的一场分裂。</title>
            <link>https://nitter.cz/dotey/status/1726776018612920398#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726776018612920398#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 01:34:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一种观点认为是 Dustin Moskovitz 和 Sam Altman 之间的矛盾，Ilya 可能被卷入了这件事，而他本人可能并不知情（这或许能解释为何他后来改变了自己的立场）：<br />
<br />
提升 alphanerd 这个引人入胜的深层评论到显眼位置：<br />
<br />
> 我在其他地方也提到过，我觉得这是 Dustin Moskovitz 和 Sam Altman 之间的一场冲突。Ilya 可能被卷入了这件事，而他本人可能并不知情（这或许能解释为何他后来改变了自己的立场）。Dustin Moskovitz 不仅是 Facebook 的早期员工，还是 Asana 的创始人。他还和一些微软（Microsoft）的高管一起创建了一个名为 Open Philanthropy 的非盈利组织，这个组织是有效利他主义的早期支持者，并为 OpenAI 提供了 3000 万美元的资助。他还是人工智能公司 Anthropic 的早期投资者。<br />
<br />
> 大部分 OpenAI 董事会成员都和 Dustin Moskovitz 有着千丝万缕的联系。<br />
<br />
> - Adam D'Angelo 是 Asana 董事会的成员，同时也是 Moskovitz 和 Altman 的密友<br />
<br />
> - Helen Toner 在 Open Philanthropy 为 Dustin Moskovitz 工作，负责管理他们对 OpenAI 的资助。她还曾是 AI 治理中心的成员，当时 McCauley 是该中心的董事会成员。Toner 离职后不久，AI 治理中心就从 Open Philanthropy 获得了 100 万美元的资助，而 McCauley 随后加入了 OpenAI 的董事会<br />
<br />
> - Tasha McCauley 代表 AI 治理中心，这个中心通过 Open Philanthropy 获得了 Dustin Moskovitz 提供的 100 万美元资助，后来 McCauley 加入了 OpenAI 的董事会<br />
<br />
> 在过去几个月里，Dustin Moskovitz 对人工智能安全问题的警告也越来越频繁。<br />
<br />
> 总的来看，这似乎是 Sam Altman 和 Dustin Moskovitz 之间的一场分裂。</p>
<p><a href="https://nitter.cz/AdrianDittmann/status/1726766987714707932#m">nitter.cz/AdrianDittmann/status/1726766987714707932#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1726774460496200181#m</id>
            <title>来自Google DeepMind 的可扩展对齐项目主管的不同声音：

关于 OpenAI 董事会解雇 Sam 的细节我一无所知，我（Google DeepMind 的可扩展对齐项目主管）对此感到左右为难。但是，鉴于对我极具影响力的人，特别是 Helen Toner 和 Ilya Sutskever 面临的强烈指责，我觉得有必要表达我的看法。
首先，这些仅代表我个人的观点，并非我的雇主的立场。但是，由于潜在的利益冲突，这些观点需要持有一定的保留。
其次，我原本非常支持 Helen 和 Ilya（对另外两位不太了解）。Ilya 是一位杰出的机器学习（ML）研究者，我曾有幸近距离观察他两年的安全观念不断进步，据我所知，这种进步在我 2019 年离开后仍在继续。
Helen 是一位卓越的战略和综合研究员，思考极其缜密，自从我 2018 年认识她以来，我们的交流始终非常愉快。她接受董事会职位时持有保留态度......
......那时，我曾建议她不要接受，因为我认为治理结构存在问题，但她和其他我信任的人士认为董事会中增加更多独立成员很重要（回顾过去，我还不确定谁的决定是正确的）。
第三，经过两年在 OpenAI 为 Sam 工作的经历，我对他持有强烈的负面看法：

1. 他对我一直很友好。
2. 但他曾多次对我撒谎。
3. 他对其他人，包括我亲近的朋友们，表现出欺骗、操纵甚至更糟糕的行为（再次提及，他只对我友好，出于某些原因）。
“他对我一直很友好”这一点让我处于一个尴尬的境地：我所知道的大部分负面信息都与其他人有关，即便他对我撒谎，也总是试图利用这些谎言在人们之间制造隔阂。因此，我觉得单方面透露这些信息很不妥。
正如我所述，除了已公开的信息外，我对董事会采取行动的具体原因一无所知。对于上周五和周末发生的事情，我感到非常迷惑：从公开信息看，似乎发生了一些重大的战术和战略错误......
......但这与涉及人员的审慎思考似乎不符。目前，我的立场是在获取更多信息之前保持审慎的判断。我明白这对许多人来说可能显得不太合理，但这是我目前能提出的最佳建议。</title>
            <link>https://nitter.cz/dotey/status/1726774460496200181#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1726774460496200181#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 01:28:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自Google DeepMind 的可扩展对齐项目主管的不同声音：<br />
<br />
关于 OpenAI 董事会解雇 Sam 的细节我一无所知，我（Google DeepMind 的可扩展对齐项目主管）对此感到左右为难。但是，鉴于对我极具影响力的人，特别是 Helen Toner 和 Ilya Sutskever 面临的强烈指责，我觉得有必要表达我的看法。<br />
首先，这些仅代表我个人的观点，并非我的雇主的立场。但是，由于潜在的利益冲突，这些观点需要持有一定的保留。<br />
其次，我原本非常支持 Helen 和 Ilya（对另外两位不太了解）。Ilya 是一位杰出的机器学习（ML）研究者，我曾有幸近距离观察他两年的安全观念不断进步，据我所知，这种进步在我 2019 年离开后仍在继续。<br />
Helen 是一位卓越的战略和综合研究员，思考极其缜密，自从我 2018 年认识她以来，我们的交流始终非常愉快。她接受董事会职位时持有保留态度......<br />
......那时，我曾建议她不要接受，因为我认为治理结构存在问题，但她和其他我信任的人士认为董事会中增加更多独立成员很重要（回顾过去，我还不确定谁的决定是正确的）。<br />
第三，经过两年在 OpenAI 为 Sam 工作的经历，我对他持有强烈的负面看法：<br />
<br />
1. 他对我一直很友好。<br />
2. 但他曾多次对我撒谎。<br />
3. 他对其他人，包括我亲近的朋友们，表现出欺骗、操纵甚至更糟糕的行为（再次提及，他只对我友好，出于某些原因）。<br />
“他对我一直很友好”这一点让我处于一个尴尬的境地：我所知道的大部分负面信息都与其他人有关，即便他对我撒谎，也总是试图利用这些谎言在人们之间制造隔阂。因此，我觉得单方面透露这些信息很不妥。<br />
正如我所述，除了已公开的信息外，我对董事会采取行动的具体原因一无所知。对于上周五和周末发生的事情，我感到非常迷惑：从公开信息看，似乎发生了一些重大的战术和战略错误......<br />
......但这与涉及人员的审慎思考似乎不符。目前，我的立场是在获取更多信息之前保持审慎的判断。我明白这对许多人来说可能显得不太合理，但这是我目前能提出的最佳建议。</p>
<p><a href="https://nitter.cz/geoffreyirving/status/1726754270224023971#m">nitter.cz/geoffreyirving/status/1726754270224023971#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>