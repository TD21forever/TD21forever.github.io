<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/realrenmin/status/1735817231601135720#m</id>
            <title>RT by @dotey: 在闭源超大型模型盛行的时代背景下，微软选择了一条不同的道路，专注于开发“小而美”的oss模型，正如phi和Wizard。

昨天，微软放出开源2.7B的phi-2，效果媲美超过自己25倍参数规模的llama-2 70B。事实上，自phi-1和phi-1.5起，phi系列在过去半年中已迭代了三次。phi的卓越表现源于半年前发表的论文 Textbooks Are All You Need，该论文的核心观点是注重数据的质量。

在探索如何提升数据质量的过程中，作者采用了一种富有哲学意味的方法，即将语言模型训练的过程人性化。比如，在我们学习编程时，如果所用的学习材料缺乏清晰的结构大纲，示例代码频繁调用来源不明的外部模块，或者常量与变量的定义混乱且缺乏实际意义，那么学习效率自然会受到影响。

下图展示了高质量数据vs低质量数据。

当前语言模型在预训练阶段所使用的语料普遍存在一些问题，如高噪声、内容模糊不清以及话题分布的不均匀等。作者针对这些问题，有意识地选择并生成高质量数据，力求让数据集像教科书Textbook一样，具备清晰度、独立性、指导性以及话题上的平衡性。这种方法使得即便是小型模型，也能经过精细训练，在特定任务上达到大型模型的效果。

值得注意的是，phi的训练过程中未采用任何指令微调(instruction finetuning)或强化学习(RLHF)。这意味着phi更像是一个纯粹的文本补全模型。因此，在使用提示（prompt）引导phi时，它可能不会完全按照预期执行，例如不会按指令输出JSON格式。这种特性使得phi更适合作为专家模型，用于特定的下游任务。

在微软的另一条expert model路线，Wizard系列也非常出色。

Wizard模型的核心理念同样也蕴含了深刻的哲学思考，特别是它所引入的“Evol-Instruct”概念，这在很大程度上借鉴了演化论的思想。

具体来说，当人们学会基础的概念，比如“1+1=2”之后，随着时间的推移，他们的思维会经历一种深度（In-Depth）和广度（In-Breadth）的演化过程。例如，他们可能会开始思考“在什么情况下1+1不等于2？”或“在真空中光速是多少？”等更深入或更广泛的问题。这种思维的演化过程正是Wizard模型试图模拟的核心要素。

对于语言模型而言，这种深度（In-Depth）和广度（In-Breadth）的指令演化使得模型能够解放思想、与时俱进，并把握遵循事物发展的客观规律，做到了举一反三。这种能力使得模型能够在学习一个概念后应用到其他相关领域，从而能够遵循更加复杂和多样的指令，完成不同的任务。

基于Evol-Instruct理念，Wizard系列的oss模型在大模型任务的三大核心领域——instruction（WizardLM）、math（WizardMath）和code（WizardCoder），都表现出色。值得一提的是，Wizard系列模型都是通过instruction tuning得到的专家模型，所以，在遵循指令方面表现稳定。

此时，从phi和Wizard的发展来看，微软似乎并没有在闭源大型模型领域投入太多，而是在开源的专家（小型）模型上下了大量功夫。微软专注于从文本补全到推理、数学、编程等细分任务的“小而美”发展。这些工作对于我们构建自己的下游专家模型提供了重要的参考和启示。

Textbooks Are All You Need https://arxiv.org/abs/2306.11644
WizardLM、WizardMathWizardCoder
https://huggingface.co/WizardLM</title>
            <link>https://nitter.cz/realrenmin/status/1735817231601135720#m</link>
            <guid isPermaLink="false">https://nitter.cz/realrenmin/status/1735817231601135720#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 00:20:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在闭源超大型模型盛行的时代背景下，微软选择了一条不同的道路，专注于开发“小而美”的oss模型，正如phi和Wizard。<br />
<br />
昨天，微软放出开源2.7B的phi-2，效果媲美超过自己25倍参数规模的llama-2 70B。事实上，自phi-1和phi-1.5起，phi系列在过去半年中已迭代了三次。phi的卓越表现源于半年前发表的论文 Textbooks Are All You Need，该论文的核心观点是注重数据的质量。<br />
<br />
在探索如何提升数据质量的过程中，作者采用了一种富有哲学意味的方法，即将语言模型训练的过程人性化。比如，在我们学习编程时，如果所用的学习材料缺乏清晰的结构大纲，示例代码频繁调用来源不明的外部模块，或者常量与变量的定义混乱且缺乏实际意义，那么学习效率自然会受到影响。<br />
<br />
下图展示了高质量数据vs低质量数据。<br />
<br />
当前语言模型在预训练阶段所使用的语料普遍存在一些问题，如高噪声、内容模糊不清以及话题分布的不均匀等。作者针对这些问题，有意识地选择并生成高质量数据，力求让数据集像教科书Textbook一样，具备清晰度、独立性、指导性以及话题上的平衡性。这种方法使得即便是小型模型，也能经过精细训练，在特定任务上达到大型模型的效果。<br />
<br />
值得注意的是，phi的训练过程中未采用任何指令微调(instruction finetuning)或强化学习(RLHF)。这意味着phi更像是一个纯粹的文本补全模型。因此，在使用提示（prompt）引导phi时，它可能不会完全按照预期执行，例如不会按指令输出JSON格式。这种特性使得phi更适合作为专家模型，用于特定的下游任务。<br />
<br />
在微软的另一条expert model路线，Wizard系列也非常出色。<br />
<br />
Wizard模型的核心理念同样也蕴含了深刻的哲学思考，特别是它所引入的“Evol-Instruct”概念，这在很大程度上借鉴了演化论的思想。<br />
<br />
具体来说，当人们学会基础的概念，比如“1+1=2”之后，随着时间的推移，他们的思维会经历一种深度（In-Depth）和广度（In-Breadth）的演化过程。例如，他们可能会开始思考“在什么情况下1+1不等于2？”或“在真空中光速是多少？”等更深入或更广泛的问题。这种思维的演化过程正是Wizard模型试图模拟的核心要素。<br />
<br />
对于语言模型而言，这种深度（In-Depth）和广度（In-Breadth）的指令演化使得模型能够解放思想、与时俱进，并把握遵循事物发展的客观规律，做到了举一反三。这种能力使得模型能够在学习一个概念后应用到其他相关领域，从而能够遵循更加复杂和多样的指令，完成不同的任务。<br />
<br />
基于Evol-Instruct理念，Wizard系列的oss模型在大模型任务的三大核心领域——instruction（WizardLM）、math（WizardMath）和code（WizardCoder），都表现出色。值得一提的是，Wizard系列模型都是通过instruction tuning得到的专家模型，所以，在遵循指令方面表现稳定。<br />
<br />
此时，从phi和Wizard的发展来看，微软似乎并没有在闭源大型模型领域投入太多，而是在开源的专家（小型）模型上下了大量功夫。微软专注于从文本补全到推理、数学、编程等细分任务的“小而美”发展。这些工作对于我们构建自己的下游专家模型提供了重要的参考和启示。<br />
<br />
Textbooks Are All You Need <a href="https://arxiv.org/abs/2306.11644">arxiv.org/abs/2306.11644</a><br />
WizardLM、WizardMathWizardCoder<br />
<a href="https://huggingface.co/WizardLM">huggingface.co/WizardLM</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiUU9aMVdzQUE0RWQ5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiU1VHVldvQUFycC03LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiU2VLMVc0QUFTM1dTLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiWEZvUFc0QUFrNktQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/goldengrape/status/1735830881972170963#m</id>
            <title>RT by @dotey: 微软前几天提前给出过示例，用prompt+logprobs+n调出了一个高分医学模型
https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/</title>
            <link>https://nitter.cz/goldengrape/status/1735830881972170963#m</link>
            <guid isPermaLink="false">https://nitter.cz/goldengrape/status/1735830881972170963#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 01:15:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软前几天提前给出过示例，用prompt+logprobs+n调出了一个高分医学模型<br />
<a href="https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/">microsoft.com/en-us/research…</a></p>
<p><a href="https://nitter.cz/dotey/status/1735799522792546517#m">nitter.cz/dotey/status/1735799522792546517#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDc1NjI5NjgwNzg2NjM2OC8weGFhR0xaaj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735736967487459833#m</id>
            <title>RT by @dotey: 还能这样？在跟Chatgpt语音聊天的时候也可以调用DALL-E3</title>
            <link>https://nitter.cz/op7418/status/1735736967487459833#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735736967487459833#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 19:01:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还能这样？在跟Chatgpt语音聊天的时候也可以调用DALL-E3</p>
<p><a href="https://nitter.cz/gopatrik/status/1735479721134313934#m">nitter.cz/gopatrik/status/1735479721134313934#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735803702563291451#m</id>
            <title>R to @dotey: 补充个文档截图</title>
            <link>https://nitter.cz/dotey/status/1735803702563291451#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735803702563291451#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 23:27:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>补充个文档截图</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiUVE5Y1hnQUU4NFNGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735802907390284114#m</id>
            <title>R to @dotey: 还有两个变化也要注意：

functions 参数和 function_call 已经改名字了，分别对应的是 tools 参数和 tool_choice，参数结果似乎没明显变化。</title>
            <link>https://nitter.cz/dotey/status/1735802907390284114#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735802907390284114#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 23:23:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还有两个变化也要注意：<br />
<br />
functions 参数和 function_call 已经改名字了，分别对应的是 tools 参数和 tool_choice，参数结果似乎没明显变化。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiUGh0Vlc0QUVldVBBLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735802381240078497#m</id>
            <title>R to @dotey: 另外还有两个参数我以前没注意到，不确认是不是新增的：

n 参数，可以同时返回多个生成结果。比如有时候你可以一次性生成几个不同的结果，让用户选择一个他们觉得最好的结果。（参考图一）

还有一个就是上次开发者大会说到的 seed 参数，这个类似于用 Stable Diffusion 画图的时候用到的 seed 参数，当你每次传入相同的 seed 和其他相同参数时，每次返回的结果会尽可能的保持一致。</title>
            <link>https://nitter.cz/dotey/status/1735802381240078497#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735802381240078497#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 23:21:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另外还有两个参数我以前没注意到，不确认是不是新增的：<br />
<br />
n 参数，可以同时返回多个生成结果。比如有时候你可以一次性生成几个不同的结果，让用户选择一个他们觉得最好的结果。（参考图一）<br />
<br />
还有一个就是上次开发者大会说到的 seed 参数，这个类似于用 Stable Diffusion 画图的时候用到的 seed 参数，当你每次传入相同的 seed 和其他相同参数时，每次返回的结果会尽可能的保持一致。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiT1hlVVdNQUFIMlRNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735799522792546517#m</id>
            <title>OpenAI 的 Chat Completions API 新增了 logprobs，那么这个参数是做什么用的呢？

我们知道 LLM （大语言模型）是概率模型，会根据 Token 出现的概率来决定下一个 Token，但我们通常是无法知道 LLM 在生成的时候，各个 Token 的概率是什么样的，只能看到最终的结果，所以在调试 Prompt 的时候无法直观的看到 Prompt 和参数的设置对生成结果的影响。

新增的 logprobs 参数，默认是 false 的，如果你设置成 true，那么在返回的结果中，会多一个 logprobs 的项，里面会列出来每一个 Token 在生成时的概率。（参见图一）

但这个只是让你看到一种结果。如果你仔细看文档，还可以看到新增了一个 top_logprobs 参数，需要同时将 logprobs 设置为 true 才能生效，这个参数是一个0-5之间的数字，意味着在返回结果的时候，会同时其他显示在生成时，当时最有可能的候选 Token 有哪些，以及各自的概率是多少。

比如我将 top_logprobs 设置成 5，就可以看到在生成第一个词的时候，最有可能得 5 个 Token 是：“How”、“Hello”、“I”、“Great”和“Thank”。

当第一个词选定“How”后，生成第二个词是最有可能的 5 个词分别是：“ can”，“ may”， “ May”， “ Can”， “dy”。

注意前 4 个前面都有空格，而第 5 个没有空格，也就是每一次的 Token 既可能是个独立的单词也可能和前面的组成一个新的单词，比如第 5 个“dy”就可以和前面的“How”组成一个新词“Howdy”。

不过对于普通开发者来说，感觉并没有太大的用处，只有真正的 Prompt Engineer 才可能会用的上。

也欢迎评论补充：你觉得这两个参数可以有哪些实用的应用场景？</title>
            <link>https://nitter.cz/dotey/status/1735799522792546517#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735799522792546517#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 23:10:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 的 Chat Completions API 新增了 logprobs，那么这个参数是做什么用的呢？<br />
<br />
我们知道 LLM （大语言模型）是概率模型，会根据 Token 出现的概率来决定下一个 Token，但我们通常是无法知道 LLM 在生成的时候，各个 Token 的概率是什么样的，只能看到最终的结果，所以在调试 Prompt 的时候无法直观的看到 Prompt 和参数的设置对生成结果的影响。<br />
<br />
新增的 logprobs 参数，默认是 false 的，如果你设置成 true，那么在返回的结果中，会多一个 logprobs 的项，里面会列出来每一个 Token 在生成时的概率。（参见图一）<br />
<br />
但这个只是让你看到一种结果。如果你仔细看文档，还可以看到新增了一个 top_logprobs 参数，需要同时将 logprobs 设置为 true 才能生效，这个参数是一个0-5之间的数字，意味着在返回结果的时候，会同时其他显示在生成时，当时最有可能的候选 Token 有哪些，以及各自的概率是多少。<br />
<br />
比如我将 top_logprobs 设置成 5，就可以看到在生成第一个词的时候，最有可能得 5 个 Token 是：“How”、“Hello”、“I”、“Great”和“Thank”。<br />
<br />
当第一个词选定“How”后，生成第二个词是最有可能的 5 个词分别是：“ can”，“ may”， “ May”， “ Can”， “dy”。<br />
<br />
注意前 4 个前面都有空格，而第 5 个没有空格，也就是每一次的 Token 既可能是个独立的单词也可能和前面的组成一个新的单词，比如第 5 个“dy”就可以和前面的“How”组成一个新词“Howdy”。<br />
<br />
不过对于普通开发者来说，感觉并没有太大的用处，只有真正的 Prompt Engineer 才可能会用的上。<br />
<br />
也欢迎评论补充：你觉得这两个参数可以有哪些实用的应用场景？</p>
<p><a href="https://nitter.cz/OpenAIDevs/status/1735730662362189872#m">nitter.cz/OpenAIDevs/status/1735730662362189872#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiSXp5eVhVQUk1dUs2LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiS1B0VldRQUE2Sk5CLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735770125704335647#m</id>
            <title>FunSearch 是 Google DeepMind 最近利用大语言模型在数学领域的一个重大成果，甚至于你能从中看出前不久传闻中的 Q* 的影子，因为它本质上是实现了大语言模型自己提出解决数学问题的方案，并自己去验证解决方案。

它有一个前提条件，就是需要将数学问题描述成计算机代码“函数”，这就是 FunSearch 中“Fun”的由来，也就是“Function”。

图一很清楚的描述了 FunSearch 的工作原理。

FunSearch 主要由几个部分组成：
- 大语言模型：根据现有代码，提出创新性的解决方案，生成新的代码
- 评估器：防止错误或虚构的结果，评估生成的结果，选择最好的结果
- 程序池：保存已经生成好的并且评估器评选的最好的代码

FunSearch 是一个循环迭代的过程。在每一轮中：
1. 系统会从现有程序池选取若干程序，交由 LLM 加工。
2. LLM 在这些程序的基础上进行创新，生成新程序，并自动对它们进行评估。
3. 表现最佳的程序将被重新加入程序池，形成一个自我提升的循环。

借助代码和评估器，FunSearch 就类似于 Alpha Go 的训练那样，实现了一套自动训练优化的机制，让 LLM 提出新的解决方案，持续不断地优化解决方案，最终解决问题。

另外如果你记得 @DrJimFan 他们做过的 GPT-4 自动玩 Minecraft 的 Voyager https://twitter.com/DrJimFan/status/1662115266933972993 （图二），原理也是类似的：把 Minecraft 的操作转换成代码，GPT-4 生成技能代码，生成后去 Minecraft 中执行校验，优秀的技能代码最终保存到技能库。思路惊人的相似。

感觉这个（LLM - 代码 - 验证器）框架以后可以有越来越多的有创新的应用场景！

另外原始文章我翻译了一下：https://baoyu.io/translations/google/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models</title>
            <link>https://nitter.cz/dotey/status/1735770125704335647#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735770125704335647#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 21:13:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>FunSearch 是 Google DeepMind 最近利用大语言模型在数学领域的一个重大成果，甚至于你能从中看出前不久传闻中的 Q* 的影子，因为它本质上是实现了大语言模型自己提出解决数学问题的方案，并自己去验证解决方案。<br />
<br />
它有一个前提条件，就是需要将数学问题描述成计算机代码“函数”，这就是 FunSearch 中“Fun”的由来，也就是“Function”。<br />
<br />
图一很清楚的描述了 FunSearch 的工作原理。<br />
<br />
FunSearch 主要由几个部分组成：<br />
- 大语言模型：根据现有代码，提出创新性的解决方案，生成新的代码<br />
- 评估器：防止错误或虚构的结果，评估生成的结果，选择最好的结果<br />
- 程序池：保存已经生成好的并且评估器评选的最好的代码<br />
<br />
FunSearch 是一个循环迭代的过程。在每一轮中：<br />
1. 系统会从现有程序池选取若干程序，交由 LLM 加工。<br />
2. LLM 在这些程序的基础上进行创新，生成新程序，并自动对它们进行评估。<br />
3. 表现最佳的程序将被重新加入程序池，形成一个自我提升的循环。<br />
<br />
借助代码和评估器，FunSearch 就类似于 Alpha Go 的训练那样，实现了一套自动训练优化的机制，让 LLM 提出新的解决方案，持续不断地优化解决方案，最终解决问题。<br />
<br />
另外如果你记得 <a href="https://nitter.cz/DrJimFan" title="Jim Fan">@DrJimFan</a> 他们做过的 GPT-4 自动玩 Minecraft 的 Voyager <a href="https://nitter.cz/DrJimFan/status/1662115266933972993">nitter.cz/DrJimFan/status/…</a> （图二），原理也是类似的：把 Minecraft 的操作转换成代码，GPT-4 生成技能代码，生成后去 Minecraft 中执行校验，优秀的技能代码最终保存到技能库。思路惊人的相似。<br />
<br />
感觉这个（LLM - 代码 - 验证器）框架以后可以有越来越多的有创新的应用场景！<br />
<br />
另外原始文章我翻译了一下：<a href="https://baoyu.io/translations/google/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models">baoyu.io/translations/google…</a></p>
<p><a href="https://nitter.cz/GoogleDeepMind/status/1735332722208284797#m">nitter.cz/GoogleDeepMind/status/1735332722208284797#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JhczlqN1hNQUFPM1RfLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Jhd1hmY1dRQUVJRTVNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735712550212215061#m</id>
            <title>R to @dotey:</title>
            <link>https://nitter.cz/dotey/status/1735712550212215061#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735712550212215061#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 17:24:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<p><a href="https://nitter.cz/goocarlos/status/1729210688017760324#m">nitter.cz/goocarlos/status/1729210688017760324#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735705912008954024#m</id>
            <title>说的很实在，开会的时候发言顺序很重要👍</title>
            <link>https://nitter.cz/dotey/status/1735705912008954024#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735705912008954024#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 16:58:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>说的很实在，开会的时候发言顺序很重要👍</p>
<p><a href="https://nitter.cz/pirrer/status/1735701274866414016#m">nitter.cz/pirrer/status/1735701274866414016#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1735637926493786167#m</id>
            <title>RT by @dotey: mistral 还是厉害，现在lmsys elo 比较高的7B模型，包括openchat、starling、openhermes、zephyr 都是以 mistral 为基座模型。

而且实测用中文prompt 进行sft，也有良好的表现。

目前我们新的7B模型的base，已经全部切换为mistral。</title>
            <link>https://nitter.cz/9hills/status/1735637926493786167#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1735637926493786167#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 12:28:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>mistral 还是厉害，现在lmsys elo 比较高的7B模型，包括openchat、starling、openhermes、zephyr 都是以 mistral 为基座模型。<br />
<br />
而且实测用中文prompt 进行sft，也有良好的表现。<br />
<br />
目前我们新的7B模型的base，已经全部切换为mistral。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735558086297825478#m</id>
            <title>我把 a16z 这篇文章翻译了一下：《2024 年科技领域的重大创新思想 [译]》
https://baoyu.io/translations/ai/big-ideas-in-tech-2024</title>
            <link>https://nitter.cz/dotey/status/1735558086297825478#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735558086297825478#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:11:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我把 a16z 这篇文章翻译了一下：《2024 年科技领域的重大创新思想 [译]》<br />
<a href="https://baoyu.io/translations/ai/big-ideas-in-tech-2024">baoyu.io/translations/ai/big…</a></p>
<p><a href="https://nitter.cz/indigo11/status/1735216254993199204#m">nitter.cz/indigo11/status/1735216254993199204#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTU1ODA4ODI5NDMxMzk4NC9WRlNDekVZZD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1734562244422504844#m</id>
            <title>RT by @dotey: 老铁们 发现一个开源的界面非常漂亮的聊天机器人框架： Lobe Chat

支持TTS语音合成、GPT 4V多模态交互和可扩展的函数调用插件系统，可以联网、画图、爬虫等。

支持一键部署，可在1分钟内完成部署（亲测确实很快🙂），无需复杂的配置过程。一键搭建私人 ChatGPT/LLM 网页应用程序。

主要功能特点：

- 多模态支持：支持最新的GPT 4V模型，具备视觉识别能力。

- 语音会话：支持文字转语音（TTS）和语音转文字（STT）技术，提供清晰的语音输出

- 插件系统：Function Calling插件生态允许实时信息获取和处理，如自动获取最新新闻头条。

- 助手市场：内置多种精心设计的AI助手，用户可以贡献和分享个人开发的助手。

- 采用 PWA 技术：提供接近原生应用体验的网页应用。支持桌面和移动设备，提供优化的用户体验。

- 移动设备适配：针对移动设备进行了优化设计，提升移动体验。正在进行版本迭代，以实现更流畅和直观的交互。

-快速部署：使用 Vercel 平台或者 Docker 镜像，一键部署，可在 1 分钟内完成部署，无需复杂的配置过程。

- 更多特性：包括精致的 UI 设计、流畅的对话体验、数据本地化隐私安全和自定义域名等。

在线体验：https://chat-preview.lobehub.com/welcome
GitHub：https://github.com/lobehub/lobe-chat</title>
            <link>https://nitter.cz/xiaohuggg/status/1734562244422504844#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1734562244422504844#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 13:14:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>老铁们 发现一个开源的界面非常漂亮的聊天机器人框架： Lobe Chat<br />
<br />
支持TTS语音合成、GPT 4V多模态交互和可扩展的函数调用插件系统，可以联网、画图、爬虫等。<br />
<br />
支持一键部署，可在1分钟内完成部署（亲测确实很快🙂），无需复杂的配置过程。一键搭建私人 ChatGPT/LLM 网页应用程序。<br />
<br />
主要功能特点：<br />
<br />
- 多模态支持：支持最新的GPT 4V模型，具备视觉识别能力。<br />
<br />
- 语音会话：支持文字转语音（TTS）和语音转文字（STT）技术，提供清晰的语音输出<br />
<br />
- 插件系统：Function Calling插件生态允许实时信息获取和处理，如自动获取最新新闻头条。<br />
<br />
- 助手市场：内置多种精心设计的AI助手，用户可以贡献和分享个人开发的助手。<br />
<br />
- 采用 PWA 技术：提供接近原生应用体验的网页应用。支持桌面和移动设备，提供优化的用户体验。<br />
<br />
- 移动设备适配：针对移动设备进行了优化设计，提升移动体验。正在进行版本迭代，以实现更流畅和直观的交互。<br />
<br />
-快速部署：使用 Vercel 平台或者 Docker 镜像，一键部署，可在 1 分钟内完成部署，无需复杂的配置过程。<br />
<br />
- 更多特性：包括精致的 UI 设计、流畅的对话体验、数据本地化隐私安全和自定义域名等。<br />
<br />
在线体验：<a href="https://chat-preview.lobehub.com/welcome">chat-preview.lobehub.com/wel…</a><br />
GitHub：<a href="https://github.com/lobehub/lobe-chat">github.com/lobehub/lobe-chat</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ1NTc1MzMzNzE4NzEyMzIvcHUvaW1nL09qSmpoOXdURzZKTkpPbE4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735547248665035146#m</id>
            <title>R to @dotey: 刊误：</title>
            <link>https://nitter.cz/dotey/status/1735547248665035146#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735547248665035146#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:28:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刊误：</p>
<p><a href="https://nitter.cz/Miracle_XYZ/status/1735545849617535133#m">nitter.cz/Miracle_XYZ/status/1735545849617535133#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735539921039839429#m</id>
            <title>微软官方出的 Windows AI Studio，如果你需要：
- 本地测试Phi-2 小模型
- 测试 RAG
- 微调模型
- 针对 Windows 优化模型

并且你是Windows 系统 + NVIDIA 的显卡，可以试试用它 。

官方说明：
Windows AI Studio 通过集成 Azure AI Studio Catalog 和其他类似 Hugging Face 的AI 模型目录中的最新 AI 开发工具和模型，使得开发生成式 AI 应用程序变得更加简单。你可以浏览由 Azure ML 和 Hugging Face 提供动力的 AI 模型目录，下载它们到本地进行微调和测试，然后在你的 Windows 应用中使用它们。因为所有的计算都在你的设备上进行，所以要确保设备的性能能够担负起这个任务。

未来，我们还计划将 ORT/DML 集成进 Windows AI Studio 的工作流程中，这样开发者就能够在任何一款 Windows 设备上进行 AI 模型的运行了。</title>
            <link>https://nitter.cz/dotey/status/1735539921039839429#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735539921039839429#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 05:58:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软官方出的 Windows AI Studio，如果你需要：<br />
- 本地测试Phi-2 小模型<br />
- 测试 RAG<br />
- 微调模型<br />
- 针对 Windows 优化模型<br />
<br />
并且你是Windows 系统 + NVIDIA 的显卡，可以试试用它 。<br />
<br />
官方说明：<br />
Windows AI Studio 通过集成 Azure AI Studio Catalog 和其他类似 Hugging Face 的AI 模型目录中的最新 AI 开发工具和模型，使得开发生成式 AI 应用程序变得更加简单。你可以浏览由 Azure ML 和 Hugging Face 提供动力的 AI 模型目录，下载它们到本地进行微调和测试，然后在你的 Windows 应用中使用它们。因为所有的计算都在你的设备上进行，所以要确保设备的性能能够担负起这个任务。<br />
<br />
未来，我们还计划将 ORT/DML 集成进 Windows AI Studio 的工作流程中，这样开发者就能够在任何一款 Windows 设备上进行 AI 模型的运行了。</p>
<p><a href="https://nitter.cz/osanseviero/status/1735280610329993564#m">nitter.cz/osanseviero/status/1735280610329993564#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYZXR0alhVQUFDWWdaLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYZXZOOVdZQUFRaVNqLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735536489029586975#m</id>
            <title>HuggingFace Chat 也提供了 Mistral 8x7B 试用，还有几个其他开源大语言模型可以选择

https://huggingface.co/chat</title>
            <link>https://nitter.cz/dotey/status/1735536489029586975#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735536489029586975#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 05:45:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HuggingFace Chat 也提供了 Mistral 8x7B 试用，还有几个其他开源大语言模型可以选择<br />
<br />
<a href="https://huggingface.co/chat">huggingface.co/chat</a></p>
<p><a href="https://nitter.cz/mervenoyann/status/1735277253313921461#m">nitter.cz/mervenoyann/status/1735277253313921461#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYZEttMldnQUF2WmxoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735531881230213136#m</id>
            <title>如果有想在本机运行 Mixtral 8x7B 或者 Dolphin-mixtral 8x7B的，可以使用 Ollama 或者 LM Studio，只不过 Ollama 目前只支持 Mac，而 LM Studio 还支持 Windows 和 Linux。

LM Studio：https://lmstudio.ai/
Ollama：https://ollama.ai/library/dolphin-mixtral

至于机器要求，请查看网站上的说明</title>
            <link>https://nitter.cz/dotey/status/1735531881230213136#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735531881230213136#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 05:26:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果有想在本机运行 Mixtral 8x7B 或者 Dolphin-mixtral 8x7B的，可以使用 Ollama 或者 LM Studio，只不过 Ollama 目前只支持 Mac，而 LM Studio 还支持 Windows 和 Linux。<br />
<br />
LM Studio：<a href="https://lmstudio.ai/">lmstudio.ai/</a><br />
Ollama：<a href="https://ollama.ai/library/dolphin-mixtral">ollama.ai/library/dolphin-mi…</a><br />
<br />
至于机器要求，请查看网站上的说明</p>
<p><a href="https://nitter.cz/dotey/status/1735457201395814770#m">nitter.cz/dotey/status/1735457201395814770#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMzU5NzA2MzIyNzUyMzA3Mi94bk1mbk5zcT9mb3JtYXQ9cG5nJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735465277934956905#m</id>
            <title>R to @dotey: x.com/epochaudiocn/status/17…</title>
            <link>https://nitter.cz/dotey/status/1735465277934956905#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735465277934956905#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 01:02:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://x.com/epochaudiocn/status/1735463776718332070?s=20">x.com/epochaudiocn/status/17…</a></p>
<p><a href="https://nitter.cz/epochaudiocn/status/1735463776718332070#m">nitter.cz/epochaudiocn/status/1735463776718332070#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735465185681235995#m</id>
            <title>R to @dotey: 如果要自己部署可以用 http://ollama.ai

https://ollama.ai/library/dolphin-mixtral/tags</title>
            <link>https://nitter.cz/dotey/status/1735465185681235995#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735465185681235995#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 01:01:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果要自己部署可以用 <a href="http://ollama.ai">ollama.ai</a><br />
<br />
<a href="https://ollama.ai/library/dolphin-mixtral/tags">ollama.ai/library/dolphin-mi…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDQzMDgwNTI4NjY0MTY2NC9YWUd1WUt2UD9mb3JtYXQ9cG5nJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>