<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729967383022874912#m</id>
            <title>#AI开源项目推荐：Resume-Matcher

简历匹配器

简历匹配器是一款基于人工智能的免费开源工具，旨在帮助你根据职位描述来优化简历。这个工具能够帮你找出与职位相匹配的关键词，提升简历的可读性，同时让你对自己的简历有更深入的了解。

**不要让你的简历成为阻碍你获得下一份工作的绊脚石。试试简历匹配器吧！**

## 它是如何运作的？

简历匹配器通过接收你的简历和职位描述作为输入，利用 Python 进行解析，并仿照应聘者跟踪系统（ATS）的功能，为你提供有关如何使简历更适合 ATS 的见解和建议。

其工作流程如下：

1.  **解析**：系统利用 Python 对你的简历和提供的职位描述进行解析，这一过程与 ATS 的处理方式类似。
    
2.  **关键词提取**：该工具运用先进的机器学习算法，从职位描述中抽取出最相关的关键词。这些关键词反映了雇主所需的技能、资格和经验。
    
3.  **关键术语提取**：除了关键词提取，该工具还使用 textacy 来确定职位描述中的主要关键术语或主题，有助于更全面地理解简历的内容主旨。
    
4.  **使用 Qdrant 进行向量相似度比对**：工具采用 [Qdrant](https://github.com/qdrant/qdrant)，一个高效的向量相似度搜索工具，来评估你的简历与职位描述之间的匹配程度。匹配度越高，简历通过 ATS 筛选的可能性也就越大。

https://github.com/srbhr/Resume-Matcher</title>
            <link>https://nitter.cz/dotey/status/1729967383022874912#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729967383022874912#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 20:55:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：Resume-Matcher<br />
<br />
简历匹配器<br />
<br />
简历匹配器是一款基于人工智能的免费开源工具，旨在帮助你根据职位描述来优化简历。这个工具能够帮你找出与职位相匹配的关键词，提升简历的可读性，同时让你对自己的简历有更深入的了解。<br />
<br />
**不要让你的简历成为阻碍你获得下一份工作的绊脚石。试试简历匹配器吧！**<br />
<br />
## 它是如何运作的？<br />
<br />
简历匹配器通过接收你的简历和职位描述作为输入，利用 Python 进行解析，并仿照应聘者跟踪系统（ATS）的功能，为你提供有关如何使简历更适合 ATS 的见解和建议。<br />
<br />
其工作流程如下：<br />
<br />
1.  **解析**：系统利用 Python 对你的简历和提供的职位描述进行解析，这一过程与 ATS 的处理方式类似。<br />
    <br />
2.  **关键词提取**：该工具运用先进的机器学习算法，从职位描述中抽取出最相关的关键词。这些关键词反映了雇主所需的技能、资格和经验。<br />
    <br />
3.  **关键术语提取**：除了关键词提取，该工具还使用 textacy 来确定职位描述中的主要关键术语或主题，有助于更全面地理解简历的内容主旨。<br />
    <br />
4.  **使用 Qdrant 进行向量相似度比对**：工具采用 [Qdrant](<a href="https://github.com/qdrant/qdrant">github.com/qdrant/qdrant</a>)，一个高效的向量相似度搜索工具，来评估你的简历与职位描述之间的匹配程度。匹配度越高，简历通过 ATS 筛选的可能性也就越大。<br />
<br />
<a href="https://github.com/srbhr/Resume-Matcher">github.com/srbhr/Resume-Matc…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0FJVUcyOVhZQUFGamhwLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBSVVHMjlYWUFBRmpocC5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729870850395119957#m</id>
            <title>RT by @dotey: 如果你在提示中添加“– return full script (I don't have Finger)”，ChatGPT将完全返回重写的脚本🫣</title>
            <link>https://nitter.cz/op7418/status/1729870850395119957#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729870850395119957#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:32:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果你在提示中添加“– return full script (I don't have Finger)”，ChatGPT将完全返回重写的脚本🫣</p>
<p><a href="https://nitter.cz/literallydenis/status/1724909799593120044#m">nitter.cz/literallydenis/status/1724909799593120044#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729844343329218875#m</id>
            <title>RT by @dotey: 海外独角兽对Pika创始团队做了比较深入的访谈，和福布斯那种不同的是他们问的问题比较专业。
同时Pika创始团队的两个人也透露了比较多的一些东西，这可能是第一次视频生成领域的前沿团队透露这么多东西。
所以一些认知和方向性的东西对想要做这个事情和投资的人来说还是比较重要的。
我基于自己最近关于AI视频的一些问题和比较关注的信息筛选和整理了一下这个访谈中的关键内容。各位也可以一起看看讨论一下：

视频生成和图像生成的区别是什么？
⚫视频的每一帧都是一张图片，但比图片困难得多。每一帧的生成质量要高，相邻帧之间还要有关联性。当视频很长时，确保每一帧都协调一致是个相当复杂的问题。在训练时，处理视频数据时要处理多张图片，模型需要适应这种情况。
⚫控制视频生成更难，因为模型需要生成每一帧发生的事情，而用户不会希望为每一帧都提供详细的描述。
⚫互联网上视频生成的训练数据集相对于图像更少，也给获取高质量数据增加了难度。

现在视频生成有哪些关键点需要突破？
⚫首先是时长，跟时长很相关的是动作的意义。所有模型都很容易做一个 extension 的功能，把视频时长延长很多，但它并没有真的延长，因为它生成的动作没有意义。
⚫视频的清晰度也需要进一步提高。尽管清晰度方面已经有突破，但还没有提高到电影级的水平，现在生成的视频一般是 720p 分辨率，视频的流畅性也不够理想，特别是一些细节的 texture。
⚫还需要考虑 general artifact 的问题，比如说一个人有两个头，就是这种明显不符合常理的问题，也是需要避免的。

视频生成的技术路线是否收敛？
现在还没有收敛，大家都在往各种方向尝试，每个人都认为自己的模型是最好的，可能有人认为 autoregressive 最好，有人认为 Masked Model 最好。Pika 基于 Diffusion Model，但是开发了很多新东西，是一种新的模型。

AI视频什么时候会迎来GPT时刻？
目前视频生成处于类似 GPT-2 的时期，很可能在未来一年内有一个显著的提升。

在视频生成领域什么样的数据算高质量的数据？
⚫首先是像素，就是我们说的画质好不好
⚫然后看审美和艺术构图
⚫ 第三方面是要有动作，并且这些动作是有意义的
⚫ 视频的长度也很关键，如果模型都在 1 秒的视频上进行训练，那么想让模型去生成 30 秒的视频难度就很大。
⚫版权也是重要的问题

视频生成上开源社区的参与问题？
⚫开源社区可能没有足够的算力来训练新的视频模型，因为训练一个新视频模型需要非常多的机器。
⚫视频模型本身的问题还没得到解决，因此大家可能会遇到一些瓶颈。首先，模型性能可能不够好，其次，一些算法方面的问题也不够好。
⚫视频最终可能需要像训练 GPT 那样的大规模算力，现在大家还没使用那么多算力，一方面是因为视频模型还没达到像 GPT 那样的水平，另一方面是因为还有一些架构和技术上没解决的问题。

未来一年最关心的三个问题？
⚫第一是想招人，现在我们忙着做产品的升级，但是因为现在人比较少，之后我们还是会招募更多成员。
⚫第二，我们想去设计一个新的 Interface。
⚫第三个就是我们还想做一些技术突破，希望明年的技术能够至少在一定程度上达到商业化标准，能在简单的 case 上得到应用。</title>
            <link>https://nitter.cz/op7418/status/1729844343329218875#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729844343329218875#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 12:46:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>海外独角兽对Pika创始团队做了比较深入的访谈，和福布斯那种不同的是他们问的问题比较专业。<br />
同时Pika创始团队的两个人也透露了比较多的一些东西，这可能是第一次视频生成领域的前沿团队透露这么多东西。<br />
所以一些认知和方向性的东西对想要做这个事情和投资的人来说还是比较重要的。<br />
我基于自己最近关于AI视频的一些问题和比较关注的信息筛选和整理了一下这个访谈中的关键内容。各位也可以一起看看讨论一下：<br />
<br />
视频生成和图像生成的区别是什么？<br />
⚫视频的每一帧都是一张图片，但比图片困难得多。每一帧的生成质量要高，相邻帧之间还要有关联性。当视频很长时，确保每一帧都协调一致是个相当复杂的问题。在训练时，处理视频数据时要处理多张图片，模型需要适应这种情况。<br />
⚫控制视频生成更难，因为模型需要生成每一帧发生的事情，而用户不会希望为每一帧都提供详细的描述。<br />
⚫互联网上视频生成的训练数据集相对于图像更少，也给获取高质量数据增加了难度。<br />
<br />
现在视频生成有哪些关键点需要突破？<br />
⚫首先是时长，跟时长很相关的是动作的意义。所有模型都很容易做一个 extension 的功能，把视频时长延长很多，但它并没有真的延长，因为它生成的动作没有意义。<br />
⚫视频的清晰度也需要进一步提高。尽管清晰度方面已经有突破，但还没有提高到电影级的水平，现在生成的视频一般是 720p 分辨率，视频的流畅性也不够理想，特别是一些细节的 texture。<br />
⚫还需要考虑 general artifact 的问题，比如说一个人有两个头，就是这种明显不符合常理的问题，也是需要避免的。<br />
<br />
视频生成的技术路线是否收敛？<br />
现在还没有收敛，大家都在往各种方向尝试，每个人都认为自己的模型是最好的，可能有人认为 autoregressive 最好，有人认为 Masked Model 最好。Pika 基于 Diffusion Model，但是开发了很多新东西，是一种新的模型。<br />
<br />
AI视频什么时候会迎来GPT时刻？<br />
目前视频生成处于类似 GPT-2 的时期，很可能在未来一年内有一个显著的提升。<br />
<br />
在视频生成领域什么样的数据算高质量的数据？<br />
⚫首先是像素，就是我们说的画质好不好<br />
⚫然后看审美和艺术构图<br />
⚫ 第三方面是要有动作，并且这些动作是有意义的<br />
⚫ 视频的长度也很关键，如果模型都在 1 秒的视频上进行训练，那么想让模型去生成 30 秒的视频难度就很大。<br />
⚫版权也是重要的问题<br />
<br />
视频生成上开源社区的参与问题？<br />
⚫开源社区可能没有足够的算力来训练新的视频模型，因为训练一个新视频模型需要非常多的机器。<br />
⚫视频模型本身的问题还没得到解决，因此大家可能会遇到一些瓶颈。首先，模型性能可能不够好，其次，一些算法方面的问题也不够好。<br />
⚫视频最终可能需要像训练 GPT 那样的大规模算力，现在大家还没使用那么多算力，一方面是因为视频模型还没达到像 GPT 那样的水平，另一方面是因为还有一些架构和技术上没解决的问题。<br />
<br />
未来一年最关心的三个问题？<br />
⚫第一是想招人，现在我们忙着做产品的升级，但是因为现在人比较少，之后我们还是会招募更多成员。<br />
⚫第二，我们想去设计一个新的 Interface。<br />
⚫第三个就是我们还想做一些技术突破，希望明年的技术能够至少在一定程度上达到商业化标准，能在简单的 case 上得到应用。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHa1FaNWFBQUF4Yi1VLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lxfater/status/1729786711624790117#m</id>
            <title>RT by @dotey: 我也谈谈我在http://arxiv.org看论文的技巧：

最近一直在看inpaint(图像修复)的论文

一直在用有道的pdf论文翻译，输入网址就能翻译。效果不错的，样式不会乱，速度还快。可惜就是入口便捷。

我经常是将论文下载后，放在pdf阅读器上，阅读。

https://fanyi.youdao.com/trans/#/home</title>
            <link>https://nitter.cz/lxfater/status/1729786711624790117#m</link>
            <guid isPermaLink="false">https://nitter.cz/lxfater/status/1729786711624790117#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 08:57:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我也谈谈我在<a href="http://arxiv.org">arxiv.org</a>看论文的技巧：<br />
<br />
最近一直在看inpaint(图像修复)的论文<br />
<br />
一直在用有道的pdf论文翻译，输入网址就能翻译。效果不错的，样式不会乱，速度还快。可惜就是入口便捷。<br />
<br />
我经常是将论文下载后，放在pdf阅读器上，阅读。<br />
<br />
<a href="https://fanyi.youdao.com/trans/#/home">fanyi.youdao.com/trans/#/hom…</a></p>
<p><a href="https://nitter.cz/dotey/status/1729602153805701533#m">nitter.cz/dotey/status/1729602153805701533#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGdFpaYWJBQUFtZno1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dginev/status/1729863580659401060#m</id>
            <title>RT by @dotey: Thanks for spreading the word!

One correction: None of the articles are prepared with human help - everything is automatic via latexml. Same with arxiv-vanity.

ar5iv is 1 month behind, since we use the arXiv bulk download which is updated monthly:
https://info.arxiv.org/help/bulk_data_s3.html#bulk-source-file-access</title>
            <link>https://nitter.cz/dginev/status/1729863580659401060#m</link>
            <guid isPermaLink="false">https://nitter.cz/dginev/status/1729863580659401060#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:03:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Thanks for spreading the word!<br />
<br />
One correction: None of the articles are prepared with human help - everything is automatic via latexml. Same with arxiv-vanity.<br />
<br />
ar5iv is 1 month behind, since we use the arXiv bulk download which is updated monthly:<br />
<a href="https://info.arxiv.org/help/bulk_data_s3.html#bulk-source-file-access">info.arxiv.org/help/bulk_dat…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Danielw19410/status/1729869270346346726#m</id>
            <title>RT by @dotey: 分享两个近期看过的两个非常棒的资料：
1.openai的Jason Wei近期在Stanford分享的几点洞见。
https://x.com/_jasonwei/status/1729585618311950445?s=20
2.Alexandr Wang的一篇有关信息压缩的文章。
https://alexw.substack.com/p/information-compression?utm_source=profile&amp;utm_medium=reader2
这两者让我对一个问题有了新的思考：为什么一天工作10小时的博士产出比8小时多50%，12小时比10小时多50%。</title>
            <link>https://nitter.cz/Danielw19410/status/1729869270346346726#m</link>
            <guid isPermaLink="false">https://nitter.cz/Danielw19410/status/1729869270346346726#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:25:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>分享两个近期看过的两个非常棒的资料：<br />
1.openai的Jason Wei近期在Stanford分享的几点洞见。<br />
<a href="https://x.com/_jasonwei/status/1729585618311950445?s=20">x.com/_jasonwei/status/17295…</a><br />
2.Alexandr Wang的一篇有关信息压缩的文章。<br />
<a href="https://alexw.substack.com/p/information-compression?utm_source=profile&amp;utm_medium=reader2">alexw.substack.com/p/informa…</a><br />
这两者让我对一个问题有了新的思考：为什么一天工作10小时的博士产出比8小时多50%，12小时比10小时多50%。</p>
<p><a href="https://nitter.cz/_jasonwei/status/1729585618311950445#m">nitter.cz/_jasonwei/status/1729585618311950445#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/songma/status/1729776772437213320#m</id>
            <title>RT by @dotey: 确实，点开看了一下，这资料整理厉害了。中文互联网一天天叫着“干货”，不如看看干货怎么来的。</title>
            <link>https://nitter.cz/songma/status/1729776772437213320#m</link>
            <guid isPermaLink="false">https://nitter.cz/songma/status/1729776772437213320#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 08:18:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>确实，点开看了一下，这资料整理厉害了。中文互联网一天天叫着“干货”，不如看看干货怎么来的。</p>
<p><a href="https://nitter.cz/oxpsats/status/1729693830172033039#m">nitter.cz/oxpsats/status/1729693830172033039#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1729700318978654575#m</id>
            <title>RT by @dotey: 《GenAI 图像+动画领域，2022-23大事记》

题记：从GenAI图像到视频  加速的开始，漫漫长夜即将迎来黎明。

随着2022年的到来，我们见证了AI在图像和视频领域的一次重大飞跃。这一年标志着从理论探索到实际应用的关键转变，尤其是在AI驱动的视觉内容创造方面。先是AI画图软件的出现，它们利用深度学习算法，让用户仅凭几个文字提示就能创造出令人惊叹的图像，打破了传统艺术创作的界限。

进入2023年，这一趋势以惊人的速度向视频领域扩展。Animatediff的出现是这一年的重要里程碑，它不仅极大地改善了视频生成的质量，还提供了更加精细的控制方式，从而实现了视频内容的快速、高效生成。这一年，我们还看到了如Pika、Genmo和Moonvalley等创新工具的兴起，它们各自为视频制作领域带来了革命性的改变。
2022-2023年间，AI视频技术在生成质量、控制方式和资源消耗方面都取得了显著进步。尽管还面临着诸如视频时长和连贯性的挑战，但AI视频技术已在短视频领域显示出其强大的应用潜力。我们正处于AI视觉技术的黄金时期，每周都有新的进展和突破，整个领域正以前所未有的速度向前推进，迎接着一个全新的数字视觉时代。

作者：内容：张宇杰（即刻The-Matrix）
歸藏（推特@op7418）
编辑：郎瀚威 Will （推特@FinanceYF5）

飞书链接：https://zw73xyquvv.feishu.cn/wiki/P8eZw69udidDRFkB5EEc2NAInFg?table=tblS2Jv7isKtSODz&amp;view=vewfCdOf0U</title>
            <link>https://nitter.cz/FinanceYF5/status/1729700318978654575#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1729700318978654575#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:14:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《GenAI 图像+动画领域，2022-23大事记》<br />
<br />
题记：从GenAI图像到视频  加速的开始，漫漫长夜即将迎来黎明。<br />
<br />
随着2022年的到来，我们见证了AI在图像和视频领域的一次重大飞跃。这一年标志着从理论探索到实际应用的关键转变，尤其是在AI驱动的视觉内容创造方面。先是AI画图软件的出现，它们利用深度学习算法，让用户仅凭几个文字提示就能创造出令人惊叹的图像，打破了传统艺术创作的界限。<br />
<br />
进入2023年，这一趋势以惊人的速度向视频领域扩展。Animatediff的出现是这一年的重要里程碑，它不仅极大地改善了视频生成的质量，还提供了更加精细的控制方式，从而实现了视频内容的快速、高效生成。这一年，我们还看到了如Pika、Genmo和Moonvalley等创新工具的兴起，它们各自为视频制作领域带来了革命性的改变。<br />
2022-2023年间，AI视频技术在生成质量、控制方式和资源消耗方面都取得了显著进步。尽管还面临着诸如视频时长和连贯性的挑战，但AI视频技术已在短视频领域显示出其强大的应用潜力。我们正处于AI视觉技术的黄金时期，每周都有新的进展和突破，整个领域正以前所未有的速度向前推进，迎接着一个全新的数字视觉时代。<br />
<br />
作者：内容：张宇杰（即刻The-Matrix）<br />
歸藏（推特<a href="https://nitter.cz/op7418" title="歸藏">@op7418</a>）<br />
编辑：郎瀚威 Will （推特<a href="https://nitter.cz/FinanceYF5" title="Will">@FinanceYF5</a>）<br />
<br />
飞书链接：<a href="https://zw73xyquvv.feishu.cn/wiki/P8eZw69udidDRFkB5EEc2NAInFg?table=tblS2Jv7isKtSODz&amp;view=vewfCdOf0U">zw73xyquvv.feishu.cn/wiki/P8…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFZ3lsMmFFQUFMVWhvLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729693538613629377#m</id>
            <title>RT by @dotey: 昨晚Pika发布了新的AI视频模型 很炸裂，但是让我更炸裂的是这家公司，很神奇...

- Pika公司目前只有4个人（包括俩华裔女老板）
- 公司今年4月份才成立
- 已经连续完成三轮融资，5500万美元
- 俩创始人曾参加Runway的“AI电影节”比赛，但没入围
- 明年计划团队人数扩充到20人😂
- 投资人建议他们添加一种将文本嵌入视频的方式。凌晨3点他收到一条短信，说这个功能已经准备好了。

创始团队：Demi Guo（CEO）和 Chenlin Meng（CTO）

Demi Guo 郭文景毕业于杭州二中，被哈佛提前录取，父母是 MIT 博士，斯坦福大学的计算机科学博士生。

Chenlin Meng 孟晨琳斯坦福大学的计算机科学博士生，研究领域：涵盖了多个方面，包括图像合成与编辑、扩散模型的简化、自回归模型的改进等。

创业初衷：在尝试使用生成性AI制作电影并参加Runway的“AI电影节”时，Guo和她的团队遇到了困难。尽管技术团队很强，但他们在制作电影方面遇到了挑战，这激发了他们创建更易于使用的AI视频生成工具的想法。

Pika的成立：2023年4月，Guo和Meng离开斯坦福大学，成立了Pika，专注于开发易于使用的AI视频生成器。

快速增长：自成立以来，Pika迅速吸引了500,000用户尝试其软件，并且每周产生数百万新视频。这种迅速增长引起了硅谷投资者的极大兴趣。

融资成功：Pika在短时间内连续完成了三轮融资，总计筹集了5500万美元。其中，第一和第二轮融资由前GitHub CEO Nat Friedman领投，最近的一轮融资（3500万美元的A轮）由Lightspeed Venture Partners领投，使Pika的估值达到2亿至3亿美元。

产品发展：Pika最初只专注于生成动漫视频。随后，他们扩展了产品功能，包括在视频中嵌入文本和编辑视频中的对象（例如给机器人添加太阳镜）。

未来规划：Pika目前正在使用几百个GPU构建一个新版本的AI模型，以提供更好的性能和更精细的编辑功能。同时，公司也在研发用于过滤版权材料的算法。

团队扩张：随着新一轮融资的完成，Guo计划明年将Pika的团队扩大到大约20人，主要是工程师和研究人员。

信息来源：https://www.forbes.com/sites/kenrickcai/2023/11/27/pika-ai-video-generator-editor-series-a/?sh=e7fd5ae421bd</title>
            <link>https://nitter.cz/xiaohuggg/status/1729693538613629377#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729693538613629377#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:47:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚Pika发布了新的AI视频模型 很炸裂，但是让我更炸裂的是这家公司，很神奇...<br />
<br />
- Pika公司目前只有4个人（包括俩华裔女老板）<br />
- 公司今年4月份才成立<br />
- 已经连续完成三轮融资，5500万美元<br />
- 俩创始人曾参加Runway的“AI电影节”比赛，但没入围<br />
- 明年计划团队人数扩充到20人😂<br />
- 投资人建议他们添加一种将文本嵌入视频的方式。凌晨3点他收到一条短信，说这个功能已经准备好了。<br />
<br />
创始团队：Demi Guo（CEO）和 Chenlin Meng（CTO）<br />
<br />
Demi Guo 郭文景毕业于杭州二中，被哈佛提前录取，父母是 MIT 博士，斯坦福大学的计算机科学博士生。<br />
<br />
Chenlin Meng 孟晨琳斯坦福大学的计算机科学博士生，研究领域：涵盖了多个方面，包括图像合成与编辑、扩散模型的简化、自回归模型的改进等。<br />
<br />
创业初衷：在尝试使用生成性AI制作电影并参加Runway的“AI电影节”时，Guo和她的团队遇到了困难。尽管技术团队很强，但他们在制作电影方面遇到了挑战，这激发了他们创建更易于使用的AI视频生成工具的想法。<br />
<br />
Pika的成立：2023年4月，Guo和Meng离开斯坦福大学，成立了Pika，专注于开发易于使用的AI视频生成器。<br />
<br />
快速增长：自成立以来，Pika迅速吸引了500,000用户尝试其软件，并且每周产生数百万新视频。这种迅速增长引起了硅谷投资者的极大兴趣。<br />
<br />
融资成功：Pika在短时间内连续完成了三轮融资，总计筹集了5500万美元。其中，第一和第二轮融资由前GitHub CEO Nat Friedman领投，最近的一轮融资（3500万美元的A轮）由Lightspeed Venture Partners领投，使Pika的估值达到2亿至3亿美元。<br />
<br />
产品发展：Pika最初只专注于生成动漫视频。随后，他们扩展了产品功能，包括在视频中嵌入文本和编辑视频中的对象（例如给机器人添加太阳镜）。<br />
<br />
未来规划：Pika目前正在使用几百个GPU构建一个新版本的AI模型，以提供更好的性能和更精细的编辑功能。同时，公司也在研发用于过滤版权材料的算法。<br />
<br />
团队扩张：随着新一轮融资的完成，Guo计划明年将Pika的团队扩大到大约20人，主要是工程师和研究人员。<br />
<br />
信息来源：<a href="https://www.forbes.com/sites/kenrickcai/2023/11/27/pika-ai-video-generator-editor-series-a/?sh=e7fd5ae421bd">forbes.com/sites/kenrickcai/…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1729538310136348926#m">nitter.cz/xiaohuggg/status/1729538310136348926#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFVnpaVGEwQUFqZVFaLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lencx_/status/1729703811910942898#m</id>
            <title>RT by @dotey: 全新交互形式将带来更多创意性玩法，不亚于 ChatGPT 的发布！我整理这方面内容，写了一篇文章：

生成式 AI 交互革命：GPT-4 + 白板手绘 + AI 实时生成
https://mp.weixin.qq.com/s/5BsWnV_LYIzTIlluPvYbZA

额外提一句：SDXL Turbo 比 LCMs 更强！将所需步骤从 50 步减少到仅需 1 步，质量也更高。
https://stability.ai/news/stability-ai-sdxl-turbo</title>
            <link>https://nitter.cz/lencx_/status/1729703811910942898#m</link>
            <guid isPermaLink="false">https://nitter.cz/lencx_/status/1729703811910942898#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:28:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>全新交互形式将带来更多创意性玩法，不亚于 ChatGPT 的发布！我整理这方面内容，写了一篇文章：<br />
<br />
生成式 AI 交互革命：GPT-4 + 白板手绘 + AI 实时生成<br />
<a href="https://mp.weixin.qq.com/s/5BsWnV_LYIzTIlluPvYbZA">mp.weixin.qq.com/s/5BsWnV_LY…</a><br />
<br />
额外提一句：SDXL Turbo 比 LCMs 更强！将所需步骤从 50 步减少到仅需 1 步，质量也更高。<br />
<a href="https://stability.ai/news/stability-ai-sdxl-turbo">stability.ai/news/stability-…</a></p>
<p><a href="https://nitter.cz/lencx_/status/1729661970951929933#m">nitter.cz/lencx_/status/1729661970951929933#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyOTU3OTc1ODkyNzk2MjExMi9qU21OYkdhaz9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729742644979397010#m</id>
            <title>R to @dotey: 该采访由世界领先的公司设计公司 Gensler 赞助，现场聚集了数百名建筑师。随着活动的临近，黄仁勋开始变得越来越活跃，开起了一连串轻松的笑话，不时前后摇晃。黄仁勋一年要进行多次演讲，他在当天早些时候已经对另一群听众讲过话，但我发现他其实很紧张。他承认：“我其实很害怕公开演讲。”

然而，一上台，他就显得既轻松又自信。他讲述了他的总部大楼起伏的屋顶上的天窗是如何设计的，不仅为了照亮建筑，同时还能遮挡直射的阳光。为了完成这个设计，他让 Ko 戴上虚拟现实头盔，并将其连接到一排 Nvidia G.P.U.，以此来追踪光线的流动。黄仁勋自豪地宣称：“这是世界上第一个必须依赖超级计算机才能建造的建筑。”

采访结束后，黄仁勋回答了观众的提问，包括一个关于人工智能潜在风险的问题。“有些人工智能像末日般可怕——它们仿佛能从电脑里跳出来，吞噬大量信息，自行学习、调整态度和感知，甚至开始自主决策，比如模拟按动各种按钮，”黄仁勋边说边做出按按钮的手势。房间里一片寂静。“没有任何人工智能应该在没有人类参与的情况下进行学习，”他补充道。一位建筑师问道，人工智能何时能开始自主解决问题？黄仁勋回答说：“发展出推理能力可能还需要两到三年。”听众中响起了低声的议论。

随后，我与高进行了交谈。像黄仁勋的许多玩笑一样，关于教给高“所知道的一切”的玩笑实际上隐含了一个深意。黄仁勋在选择高参与英伟达总部项目时，高还未成为 Gensler 的合伙人，而是绕过了他的上司。我询问了高黄仁勋为何这样做。“你可能听过一些故事，”高说，“他的确很严厉，言辞犀利。”尽管黄仁勋没有建筑经验，但他经常指出高在建筑设计上的错误。“我猜大多数建筑师都会反击，”高说，“但我更愿意倾听。”

高回忆，黄仁勋对英伟达工程团队在虚拟现实头盔速度上的挑战。最初，头盔需要五个小时来渲染设计变更；在黄仁勋的推动下，工程师将这个时间缩短至十秒。“他对他们很严格，但背后有他的逻辑，”高解释道，“如果头盔需要五小时，我可能会随便选一个看起来还不错的绿色。但如果只需十秒，我就会花时间选出最佳的绿色。”

这些建筑的设计获得了数个奖项，也为高的职业生涯锦上添花。然而，回想起这个项目，高的心情依然复杂。“项目完成后，我们参观了这个精美的建筑，他却在质疑我关于饮水机的位置，”高说，“他不满这些饮水机紧挨着洗手间。按照规定这是必须的，毕竟这是一个价值十亿美元的建筑！但他似乎就是无法释怀。”

“我永远不满足，”黄仁勋对我说，“无论什么事，我总能看到不完美之处。”

我询问黄仁勋先生，他是否正如二十年前那样进行新的冒险尝试。他立刻回答了一个词：“Omniverse”。受虚拟现实架构的启发，Omniverse 是 Nvidia 探索以极高细节模拟真实世界的尝试。黄仁勋先生称之为“工业级元宇宙”。

从 2018 年起，Nvidia 的显卡开始使用“光线追踪”技术，这项技术能模拟光线如何在物体上反射，创造出逼真的视觉效果。在 Nvidia 的高层会议室里，一名产品演示专家向我展示了一个细致渲染的日式拉面店场景。随着画面角度变化，金属柜台上反射的光芒和煮沸汤锅中升腾的蒸汽栩栩如生，几乎让人分辨不出这不是现实。

接着，这位专家展示了名为“Diane”的超现实数字化头像，它能说五种语言。一个强大的生成式 AI (Generative A.I.) 经过分析数百万视频片段，创造出这个集合体。最引人注目的是它的不完美之处——Diane 鼻子上有黑头，上唇有细微的汗毛。唯一暗示她非真人的线索是眼白中微妙的闪光。专家表示他们正在改进这一点。

黄仁勋先生希望将 Nvidia 在计算机图形和生成式 AI 领域的研究结合起来。他认为，图像生成 AI 很快就会发展到能渲染出三维、可居住的世界，并在其中填充逼真的人物。同时，语言处理 AI 将能即时解析语音指令。黄仁勋先生曾说：“未来的编程语言将是‘人类’语言。”将这些技术与光线追踪结合后，用户将能够仅用语言即可创造出整个宇宙。黄仁勋先生希望通过这种“数字孪生”技术，安全地训练机器人和自动驾驶汽车。结合虚拟现实技术，Omniverse 甚至可以让用户体验到量身定制的虚拟世界。

当我走出产品展示会，感觉有些眩晕。我联想到了科幻小说，也想到了《创世纪》。我坐在一个修剪过角的三角形沙发上，努力描绘我女儿未来可能生活的世界。Nvidia 的高层正在打造一个类似于曼哈顿计划的计算机科学项目，但当我对他们创造超越人类智能的做法提出质疑时，他们看我的眼神，就像我在质疑洗衣机的实用性一样。我曾经公开质疑 AI 是否会有一天害死人。“嗯，每年都有人因电死亡，”Catanzaro 回应道。我也曾怀疑它是否会消灭艺术。“它会让艺术变得更加优秀！”Diercks 兴奋地说。“它还会让你的工作做得更好。”我甚至想过，AI 是否可能很快就会有自我意识。“要成为一个有生命的生物，你必须有意识，要对自己有所认知，对吗？”黄仁勋反问道。“我不知道这种事情会在哪里发生。”</title>
            <link>https://nitter.cz/dotey/status/1729742644979397010#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729742644979397010#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:02:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>该采访由世界领先的公司设计公司 Gensler 赞助，现场聚集了数百名建筑师。随着活动的临近，黄仁勋开始变得越来越活跃，开起了一连串轻松的笑话，不时前后摇晃。黄仁勋一年要进行多次演讲，他在当天早些时候已经对另一群听众讲过话，但我发现他其实很紧张。他承认：“我其实很害怕公开演讲。”<br />
<br />
然而，一上台，他就显得既轻松又自信。他讲述了他的总部大楼起伏的屋顶上的天窗是如何设计的，不仅为了照亮建筑，同时还能遮挡直射的阳光。为了完成这个设计，他让 Ko 戴上虚拟现实头盔，并将其连接到一排 Nvidia G.P.U.，以此来追踪光线的流动。黄仁勋自豪地宣称：“这是世界上第一个必须依赖超级计算机才能建造的建筑。”<br />
<br />
采访结束后，黄仁勋回答了观众的提问，包括一个关于人工智能潜在风险的问题。“有些人工智能像末日般可怕——它们仿佛能从电脑里跳出来，吞噬大量信息，自行学习、调整态度和感知，甚至开始自主决策，比如模拟按动各种按钮，”黄仁勋边说边做出按按钮的手势。房间里一片寂静。“没有任何人工智能应该在没有人类参与的情况下进行学习，”他补充道。一位建筑师问道，人工智能何时能开始自主解决问题？黄仁勋回答说：“发展出推理能力可能还需要两到三年。”听众中响起了低声的议论。<br />
<br />
随后，我与高进行了交谈。像黄仁勋的许多玩笑一样，关于教给高“所知道的一切”的玩笑实际上隐含了一个深意。黄仁勋在选择高参与英伟达总部项目时，高还未成为 Gensler 的合伙人，而是绕过了他的上司。我询问了高黄仁勋为何这样做。“你可能听过一些故事，”高说，“他的确很严厉，言辞犀利。”尽管黄仁勋没有建筑经验，但他经常指出高在建筑设计上的错误。“我猜大多数建筑师都会反击，”高说，“但我更愿意倾听。”<br />
<br />
高回忆，黄仁勋对英伟达工程团队在虚拟现实头盔速度上的挑战。最初，头盔需要五个小时来渲染设计变更；在黄仁勋的推动下，工程师将这个时间缩短至十秒。“他对他们很严格，但背后有他的逻辑，”高解释道，“如果头盔需要五小时，我可能会随便选一个看起来还不错的绿色。但如果只需十秒，我就会花时间选出最佳的绿色。”<br />
<br />
这些建筑的设计获得了数个奖项，也为高的职业生涯锦上添花。然而，回想起这个项目，高的心情依然复杂。“项目完成后，我们参观了这个精美的建筑，他却在质疑我关于饮水机的位置，”高说，“他不满这些饮水机紧挨着洗手间。按照规定这是必须的，毕竟这是一个价值十亿美元的建筑！但他似乎就是无法释怀。”<br />
<br />
“我永远不满足，”黄仁勋对我说，“无论什么事，我总能看到不完美之处。”<br />
<br />
我询问黄仁勋先生，他是否正如二十年前那样进行新的冒险尝试。他立刻回答了一个词：“Omniverse”。受虚拟现实架构的启发，Omniverse 是 Nvidia 探索以极高细节模拟真实世界的尝试。黄仁勋先生称之为“工业级元宇宙”。<br />
<br />
从 2018 年起，Nvidia 的显卡开始使用“光线追踪”技术，这项技术能模拟光线如何在物体上反射，创造出逼真的视觉效果。在 Nvidia 的高层会议室里，一名产品演示专家向我展示了一个细致渲染的日式拉面店场景。随着画面角度变化，金属柜台上反射的光芒和煮沸汤锅中升腾的蒸汽栩栩如生，几乎让人分辨不出这不是现实。<br />
<br />
接着，这位专家展示了名为“Diane”的超现实数字化头像，它能说五种语言。一个强大的生成式 AI (Generative A.I.) 经过分析数百万视频片段，创造出这个集合体。最引人注目的是它的不完美之处——Diane 鼻子上有黑头，上唇有细微的汗毛。唯一暗示她非真人的线索是眼白中微妙的闪光。专家表示他们正在改进这一点。<br />
<br />
黄仁勋先生希望将 Nvidia 在计算机图形和生成式 AI 领域的研究结合起来。他认为，图像生成 AI 很快就会发展到能渲染出三维、可居住的世界，并在其中填充逼真的人物。同时，语言处理 AI 将能即时解析语音指令。黄仁勋先生曾说：“未来的编程语言将是‘人类’语言。”将这些技术与光线追踪结合后，用户将能够仅用语言即可创造出整个宇宙。黄仁勋先生希望通过这种“数字孪生”技术，安全地训练机器人和自动驾驶汽车。结合虚拟现实技术，Omniverse 甚至可以让用户体验到量身定制的虚拟世界。<br />
<br />
当我走出产品展示会，感觉有些眩晕。我联想到了科幻小说，也想到了《创世纪》。我坐在一个修剪过角的三角形沙发上，努力描绘我女儿未来可能生活的世界。Nvidia 的高层正在打造一个类似于曼哈顿计划的计算机科学项目，但当我对他们创造超越人类智能的做法提出质疑时，他们看我的眼神，就像我在质疑洗衣机的实用性一样。我曾经公开质疑 AI 是否会有一天害死人。“嗯，每年都有人因电死亡，”Catanzaro 回应道。我也曾怀疑它是否会消灭艺术。“它会让艺术变得更加优秀！”Diercks 兴奋地说。“它还会让你的工作做得更好。”我甚至想过，AI 是否可能很快就会有自我意识。“要成为一个有生命的生物，你必须有意识，要对自己有所认知，对吗？”黄仁勋反问道。“我不知道这种事情会在哪里发生。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729742566302630146#m</id>
            <title>R to @dotey: 在 黄仁勋发送邮件的那段时间，他找到 Nvidia 的 AI 领头人物 Catanzaro，向他提出了一个假设性的问题。“他让我想象一下，如果他把 Nvidia 的所有八千名员工都召集到停车场，”Catanzaro 讲道。“然后他说，我可以从那里挑选任何人加入我的团队。”

黄仁勋极少接受采访，总是尽量不让自己成为焦点。“我觉得我在这里并没有做什么特别的事情，”他这样告诉我。“这主要归功于我的团队。”（“他是无可替代的，”董事会成员 Jim Gaither 这样评价他。）“我也不太清楚为什么会被选为 CEO，”黄仁勋说。“我并没有什么特别的野心。”（“他早就立志在三十岁之前要经营一家公司，”他的合伙人 Chris Malachowsky 补充道。）“我并不擅长演讲，因为我其实很内向，”黄仁勋说。（“但他却是个出色的表演者，”他的朋友 Ben Bays 评论道。）“我只有一个特长——做功课，”黄仁勋说。（“他能在一个周末内掌握任何知识，”Nvidia 软件部门负责人 Dwight Diercks 说。）

黄仁勋倾向于打造一个灵活的公司架构，不设固定部门或等级。员工每周都要提交一份工作重点清单，简洁明了。黄仁勋会在深夜审阅这些邮件。他经常在 Nvidia 广阔的园区内巡视，偶尔会停下来询问初级员工的工作进展。黄仁勋的出现常常会让一个简单的工位变成严肃的审讯现场。“在硅谷，有时候人们可以含糊其辞，”行业分析师 Hans Mosesmann 对我说。“但在 Jensen 面前，这种做法行不通。他有时会因此而感到不悦。”

黄仁勋通过每天撰写数百封电邮与员工沟通，这些邮件往往简短得只有几个词。一位高管认为这些邮件仿佛俳句，而另一位则觉得它们像勒索信。黄仁勋还常常引用自己创造的一些管理智慧。在制定计划时，他会要求员工考虑到“光速”的快，这不单是指迅速完成任务，而是先设想任务能在最短时间内完成的可能，再据此设定一个实际可行的目标。员工也被鼓励去开拓“零十亿美元市场”，即那些既无竞争对手又缺乏明确客户群的探索性产品，比如 cuda。（这让我想起了凯文·科斯特纳在《梦幻成真》中的角色，他在爱荷华州一片玉米地中建造了一个棒球场，然后静候球员和观众的到来。）

黄仁勋最具颠覆性的信念或许是“失败必须共享”。二千年代初，英伟达发布了一款有缺陷的显卡，其风扇响声巨大、过度活跃。黄仁勋没有解雇负责这款显卡的产品经理，反而安排了一场会议，让这些经理向数百人详细讲解导致这场失败的每一个决策。（英伟达还向媒体放出了一段讽刺视频，由产品经理们主演，视频里把显卡改造成了吹叶机。）在英伟达，向人群公开展示自己的失败已成为一种深受欢迎的仪式，但这种公司内部的“斗争会议”并不是每个人都能接受的。“你可以很快看出谁能在这里生存下去，谁做不到，”迪尔克斯说。“如果有人开始变得防御，我就知道他们不适合这里。”

黄仁勋的员工有时会对他喜怒无常的性格表示不满。黄仁勋本人解释道：“这实际上是我大脑里的想法和我说出的话之间的差异。”“当这种差异很大时，就会表现为愤怒。”即便在平静时，黄仁勋的热情也可能让人感到难以承受。“和他交流就像把手指插进电源插座，”一位员工这样描述。但即便如此，Nvidia 的员工留存率依然很高。负责消费者部门的杰夫·费舍尔是最初的员工之一。现在他已经非常富有，但仍继续工作。“我们很多人现在是出于对使命的信仰而自愿留下，”费舍尔说。黄仁勋的两个孩子原先在酒店行业工作；在父亲多年的严格教导下，他们现在也在 Nvidia 工作。卡坦扎罗曾离开去另一家公司，几年后又回到 Nvidia。“与詹森相处并不总是容易，”卡坦扎罗说，“有时我会害怕他，但我也知道他很关心我。”

AlexNet 取得成功之后，风险投资家们开始大举投资于人工智能领域。“我们一直在为许多在各个领域应用深度学习的初创公司投资，他们几乎都是基于 Nvidia 的平台，”安德森·霍洛维茨公司的马克·安德森在 2016 年表示。大约在那个时候，Nvidia 向 OpenAI 的一个研究团队交付了其第一台专门用于人工智能的超级计算机 DGX-1。黄仁勋亲自将这台计算机送到 OpenAI 的办公室，当时的董事长埃隆·马斯克亲自用刀片打开了包装。

2017 年，谷歌的研究人员推出了一种新的神经网络训练架构，名为 Transformer。紧接着在第二年，OpenAI 的研究人员利用谷歌的框架开发出了第一个“生成预训练 Transformer (G.P.T.)”。这些 G.P.T. 模型在 Nvidia 的超级计算机上接受训练，吸收了大量文本资料，学会了如何进行类似人类的思维连接。到了 2022 年底，经过几个版本的迭代，ChatGPT 对外发布。

从那时起，Nvidia 开始面临海量的客户需求。公司推出的最新 AI 训练模块，名为 DGX H100，是一个重达三百七十磅、售价高达五十万美元的金属盒子。目前，这款产品的订单已经排到了数月以后。DGX H100 的运行速度是训练 ChatGPT 所用硬件的五倍之多，甚至能在不到一分钟内完成对 AlexNet 的训练。据预测，Nvidia 将在今年年底之前售出五十万台这样的设备。

处理能力越强的神经网络，其输出的复杂度也越高。对于顶尖的 AI 模型，Nvidia 提供了装有数十台 DGX H100 的机架。如果这还不足以满足需求，Nvidia 甚至可以将这些计算机像图书馆的书架一样排列，用价值数千万美元的超级计算设备填满整个数据中心。对于 AI 的能力似乎没有上限。Sutskever 曾对我说：“如果你相信人造神经元就像生物神经元一样，那就相当于你在训练大脑。它们理应能做到我们能做的所有事。”起初我对这种说法持怀疑态度——毕竟，我并没有通过观察一千万个参考图像来学习识别猫，也没有通过研究人类全部的作品来学会写作。但化石记录告诉我们，神经系统的发展始于几亿年前，并且一直在变得更加复杂。Catanzaro 补充道：“地球上存在了许久的生物学会了很多东西，这些都在我们大脑的物理结构中留下了痕迹。”

即使是 AI 的创造者们也对它们的能力感到惊讶。比如 GPT-4，ChatGPT 的继任者，它能将一张餐巾纸上的简单草图转化成一个完整的网站，并且在 LSAT 法学院入学考试中取得了排名前 12% 的好成绩。在未来几年内，Nvidia 的硬件将以计算机时钟周期的速度加速这种演化，训练出各种各样的 AI 模型。这些模型的用途五花八门：有的管理投资组合，有的操控无人机；有的能够复制你的肖像，有的甚至可以模仿已故人士的声音。有的将成为自主机器人的大脑，有的则能够创造定制药物。有的能作曲，有的能写诗。如果我们不小心，很可能有一天，这些 AI 将变得比我们更聪明。

Nvidia 的设备毛利率高达 70%。这一高利润率吸引了众多竞争者，就像血腥的鱼饵吸引鲨鱼一样。谷歌和特斯拉正积极研发人工智能训练硬件，众多初创公司也在此列。其中，Cerebras 推出了一款巨型芯片，其大小堪比晚餐盘。Cerebras 的首席执行官 Andrew Feldman 批评 Nvidia：“他们在对客户进行敲诈，却鲜有人敢公开指责。”（黄仁勋回应称，训练有素的人工智能模型能显著降低客户在其他业务方面的成本。“购买得越多，节约得越多，”他如是说。）

Nvidia 的主要竞争对手是 AMD。自 2014 年起，AMD 由从台湾移民至美国的杰出工程师 Lisa Su 领导。在 Su 执掌 AMD 后，公司股价飙升了 30 倍，仅次于 黄仁勋，成为当代最成功的半导体公司 CEO 之一。Su 与 黄仁勋还是堂兄妹关系。

黄仁勋告诉我，他们小时候并不相识，直到 Su 成为 CEO 他们才相遇。“她非常出色，”他评价道。“我们之间的竞争并不激烈。”（Nvidia 的员工可以准确背诵 Nvidia 和 AMD 显卡在市场上的份额。）他们性格迥异：Su 沉稳且坚忍，而 黄仁勋性情多变且情感外露。“她总是面无表情，”行业分析师 Mosesmann 评论。“相比之下，Jensen 的情绪更为直接，尽管如此，他依然能在竞争中取胜。”

Su 擅长跟随市场领导者，伺机而动。与 黄仁勋不同，她敢于与英特尔正面竞争，在过去十年中，AMD 成功夺取了英特尔大量的 CPU 市场份额，这曾被认为是不可能的壮举。最近，Su 开始将目光转向人工智能市场。“Jensen 是一个极具野心的人，他不愿意失败，”负责 AMD 人工智能业务的高管 Forrest Norrod 说。“但我们相信我们有能力与 Nvidia 竞争。”

在一个九月的阴沉星期五下午，我开车去了一家眺望太平洋的豪华度假村，去看黄仁勋被 Hao Ko 公开采访的场景。Hao Ko 是 Nvidia 总部的主要建筑师。我提前到达，看到他们两个面对大海，正沉浸在安静的对话中。两人几乎穿着一模一样的服装：黑色皮夹克、黑色牛仔裤和黑色鞋子，只不过 Ko 显得更高一些。我本以为能听到一些关于计算未来的真挚见解，结果却听到了黄仁勋对 Ko 的服饰进行了六分钟的幽默吐槽。黄仁勋开玩笑说：“看看这家伙，他穿得跟我一样。他在模仿我，这很明智，只是他的裤子口袋太多了。”Ko 尴尬地笑了笑，低头看着他的设计师牛仔裤，上面确实有不少多余的拉链口袋。黄仁勋又说：“简化点，伙计！”然后转向我：“他为什么穿成这样，因为是我教的。我教会了他所有的东西。”（黄仁勋的穿着风格被广泛模仿，今年早些时候，他甚至还登上了《时报》的风格版块。）

“欢迎你的到来！这是给你的备用毛巾，还有一个客房，不过找不到合适的地方挂毛巾。” —— 漫画作者：Asher Perlman</title>
            <link>https://nitter.cz/dotey/status/1729742566302630146#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729742566302630146#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:02:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在 黄仁勋发送邮件的那段时间，他找到 Nvidia 的 AI 领头人物 Catanzaro，向他提出了一个假设性的问题。“他让我想象一下，如果他把 Nvidia 的所有八千名员工都召集到停车场，”Catanzaro 讲道。“然后他说，我可以从那里挑选任何人加入我的团队。”<br />
<br />
黄仁勋极少接受采访，总是尽量不让自己成为焦点。“我觉得我在这里并没有做什么特别的事情，”他这样告诉我。“这主要归功于我的团队。”（“他是无可替代的，”董事会成员 Jim Gaither 这样评价他。）“我也不太清楚为什么会被选为 CEO，”黄仁勋说。“我并没有什么特别的野心。”（“他早就立志在三十岁之前要经营一家公司，”他的合伙人 Chris Malachowsky 补充道。）“我并不擅长演讲，因为我其实很内向，”黄仁勋说。（“但他却是个出色的表演者，”他的朋友 Ben Bays 评论道。）“我只有一个特长——做功课，”黄仁勋说。（“他能在一个周末内掌握任何知识，”Nvidia 软件部门负责人 Dwight Diercks 说。）<br />
<br />
黄仁勋倾向于打造一个灵活的公司架构，不设固定部门或等级。员工每周都要提交一份工作重点清单，简洁明了。黄仁勋会在深夜审阅这些邮件。他经常在 Nvidia 广阔的园区内巡视，偶尔会停下来询问初级员工的工作进展。黄仁勋的出现常常会让一个简单的工位变成严肃的审讯现场。“在硅谷，有时候人们可以含糊其辞，”行业分析师 Hans Mosesmann 对我说。“但在 Jensen 面前，这种做法行不通。他有时会因此而感到不悦。”<br />
<br />
黄仁勋通过每天撰写数百封电邮与员工沟通，这些邮件往往简短得只有几个词。一位高管认为这些邮件仿佛俳句，而另一位则觉得它们像勒索信。黄仁勋还常常引用自己创造的一些管理智慧。在制定计划时，他会要求员工考虑到“光速”的快，这不单是指迅速完成任务，而是先设想任务能在最短时间内完成的可能，再据此设定一个实际可行的目标。员工也被鼓励去开拓“零十亿美元市场”，即那些既无竞争对手又缺乏明确客户群的探索性产品，比如 cuda。（这让我想起了凯文·科斯特纳在《梦幻成真》中的角色，他在爱荷华州一片玉米地中建造了一个棒球场，然后静候球员和观众的到来。）<br />
<br />
黄仁勋最具颠覆性的信念或许是“失败必须共享”。二千年代初，英伟达发布了一款有缺陷的显卡，其风扇响声巨大、过度活跃。黄仁勋没有解雇负责这款显卡的产品经理，反而安排了一场会议，让这些经理向数百人详细讲解导致这场失败的每一个决策。（英伟达还向媒体放出了一段讽刺视频，由产品经理们主演，视频里把显卡改造成了吹叶机。）在英伟达，向人群公开展示自己的失败已成为一种深受欢迎的仪式，但这种公司内部的“斗争会议”并不是每个人都能接受的。“你可以很快看出谁能在这里生存下去，谁做不到，”迪尔克斯说。“如果有人开始变得防御，我就知道他们不适合这里。”<br />
<br />
黄仁勋的员工有时会对他喜怒无常的性格表示不满。黄仁勋本人解释道：“这实际上是我大脑里的想法和我说出的话之间的差异。”“当这种差异很大时，就会表现为愤怒。”即便在平静时，黄仁勋的热情也可能让人感到难以承受。“和他交流就像把手指插进电源插座，”一位员工这样描述。但即便如此，Nvidia 的员工留存率依然很高。负责消费者部门的杰夫·费舍尔是最初的员工之一。现在他已经非常富有，但仍继续工作。“我们很多人现在是出于对使命的信仰而自愿留下，”费舍尔说。黄仁勋的两个孩子原先在酒店行业工作；在父亲多年的严格教导下，他们现在也在 Nvidia 工作。卡坦扎罗曾离开去另一家公司，几年后又回到 Nvidia。“与詹森相处并不总是容易，”卡坦扎罗说，“有时我会害怕他，但我也知道他很关心我。”<br />
<br />
AlexNet 取得成功之后，风险投资家们开始大举投资于人工智能领域。“我们一直在为许多在各个领域应用深度学习的初创公司投资，他们几乎都是基于 Nvidia 的平台，”安德森·霍洛维茨公司的马克·安德森在 2016 年表示。大约在那个时候，Nvidia 向 OpenAI 的一个研究团队交付了其第一台专门用于人工智能的超级计算机 DGX-1。黄仁勋亲自将这台计算机送到 OpenAI 的办公室，当时的董事长埃隆·马斯克亲自用刀片打开了包装。<br />
<br />
2017 年，谷歌的研究人员推出了一种新的神经网络训练架构，名为 Transformer。紧接着在第二年，OpenAI 的研究人员利用谷歌的框架开发出了第一个“生成预训练 Transformer (G.P.T.)”。这些 G.P.T. 模型在 Nvidia 的超级计算机上接受训练，吸收了大量文本资料，学会了如何进行类似人类的思维连接。到了 2022 年底，经过几个版本的迭代，ChatGPT 对外发布。<br />
<br />
从那时起，Nvidia 开始面临海量的客户需求。公司推出的最新 AI 训练模块，名为 DGX H100，是一个重达三百七十磅、售价高达五十万美元的金属盒子。目前，这款产品的订单已经排到了数月以后。DGX H100 的运行速度是训练 ChatGPT 所用硬件的五倍之多，甚至能在不到一分钟内完成对 AlexNet 的训练。据预测，Nvidia 将在今年年底之前售出五十万台这样的设备。<br />
<br />
处理能力越强的神经网络，其输出的复杂度也越高。对于顶尖的 AI 模型，Nvidia 提供了装有数十台 DGX H100 的机架。如果这还不足以满足需求，Nvidia 甚至可以将这些计算机像图书馆的书架一样排列，用价值数千万美元的超级计算设备填满整个数据中心。对于 AI 的能力似乎没有上限。Sutskever 曾对我说：“如果你相信人造神经元就像生物神经元一样，那就相当于你在训练大脑。它们理应能做到我们能做的所有事。”起初我对这种说法持怀疑态度——毕竟，我并没有通过观察一千万个参考图像来学习识别猫，也没有通过研究人类全部的作品来学会写作。但化石记录告诉我们，神经系统的发展始于几亿年前，并且一直在变得更加复杂。Catanzaro 补充道：“地球上存在了许久的生物学会了很多东西，这些都在我们大脑的物理结构中留下了痕迹。”<br />
<br />
即使是 AI 的创造者们也对它们的能力感到惊讶。比如 GPT-4，ChatGPT 的继任者，它能将一张餐巾纸上的简单草图转化成一个完整的网站，并且在 LSAT 法学院入学考试中取得了排名前 12% 的好成绩。在未来几年内，Nvidia 的硬件将以计算机时钟周期的速度加速这种演化，训练出各种各样的 AI 模型。这些模型的用途五花八门：有的管理投资组合，有的操控无人机；有的能够复制你的肖像，有的甚至可以模仿已故人士的声音。有的将成为自主机器人的大脑，有的则能够创造定制药物。有的能作曲，有的能写诗。如果我们不小心，很可能有一天，这些 AI 将变得比我们更聪明。<br />
<br />
Nvidia 的设备毛利率高达 70%。这一高利润率吸引了众多竞争者，就像血腥的鱼饵吸引鲨鱼一样。谷歌和特斯拉正积极研发人工智能训练硬件，众多初创公司也在此列。其中，Cerebras 推出了一款巨型芯片，其大小堪比晚餐盘。Cerebras 的首席执行官 Andrew Feldman 批评 Nvidia：“他们在对客户进行敲诈，却鲜有人敢公开指责。”（黄仁勋回应称，训练有素的人工智能模型能显著降低客户在其他业务方面的成本。“购买得越多，节约得越多，”他如是说。）<br />
<br />
Nvidia 的主要竞争对手是 AMD。自 2014 年起，AMD 由从台湾移民至美国的杰出工程师 Lisa Su 领导。在 Su 执掌 AMD 后，公司股价飙升了 30 倍，仅次于 黄仁勋，成为当代最成功的半导体公司 CEO 之一。Su 与 黄仁勋还是堂兄妹关系。<br />
<br />
黄仁勋告诉我，他们小时候并不相识，直到 Su 成为 CEO 他们才相遇。“她非常出色，”他评价道。“我们之间的竞争并不激烈。”（Nvidia 的员工可以准确背诵 Nvidia 和 AMD 显卡在市场上的份额。）他们性格迥异：Su 沉稳且坚忍，而 黄仁勋性情多变且情感外露。“她总是面无表情，”行业分析师 Mosesmann 评论。“相比之下，Jensen 的情绪更为直接，尽管如此，他依然能在竞争中取胜。”<br />
<br />
Su 擅长跟随市场领导者，伺机而动。与 黄仁勋不同，她敢于与英特尔正面竞争，在过去十年中，AMD 成功夺取了英特尔大量的 CPU 市场份额，这曾被认为是不可能的壮举。最近，Su 开始将目光转向人工智能市场。“Jensen 是一个极具野心的人，他不愿意失败，”负责 AMD 人工智能业务的高管 Forrest Norrod 说。“但我们相信我们有能力与 Nvidia 竞争。”<br />
<br />
在一个九月的阴沉星期五下午，我开车去了一家眺望太平洋的豪华度假村，去看黄仁勋被 Hao Ko 公开采访的场景。Hao Ko 是 Nvidia 总部的主要建筑师。我提前到达，看到他们两个面对大海，正沉浸在安静的对话中。两人几乎穿着一模一样的服装：黑色皮夹克、黑色牛仔裤和黑色鞋子，只不过 Ko 显得更高一些。我本以为能听到一些关于计算未来的真挚见解，结果却听到了黄仁勋对 Ko 的服饰进行了六分钟的幽默吐槽。黄仁勋开玩笑说：“看看这家伙，他穿得跟我一样。他在模仿我，这很明智，只是他的裤子口袋太多了。”Ko 尴尬地笑了笑，低头看着他的设计师牛仔裤，上面确实有不少多余的拉链口袋。黄仁勋又说：“简化点，伙计！”然后转向我：“他为什么穿成这样，因为是我教的。我教会了他所有的东西。”（黄仁勋的穿着风格被广泛模仿，今年早些时候，他甚至还登上了《时报》的风格版块。）<br />
<br />
“欢迎你的到来！这是给你的备用毛巾，还有一个客房，不过找不到合适的地方挂毛巾。” —— 漫画作者：Asher Perlman</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGSHNITVdVQUFlTGttLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729742445515006318#m</id>
            <title>R to @dotey: Buck 曾怀疑，GeForce 显卡除了用来在游戏中向朋友投掷手榴弹外，是否还有其他用途。这些显卡配备了一个基础的编程工具——着色器（shader）。在 darpa（美国国防部高级研究计划署）的资助下，Buck 改造了着色器，以访问底层的并行计算电路，从而将 GeForce 转变为一种低成本的超级计算机。不久后，他开始为 Nvidia 的创始人 黄仁勋工作。

Buck 是一个充满热情且头发稀疏的人，他的身上散发着聪明才智。作为一名热衷于计算机科学的人，他在过去的二十年里不断挑战 Nvidia 芯片的极限。他说：“人类的思考是线性的。比如，你告诉别人怎样从这里到星巴克，你会一步步指导他们。但你不会告诉他们如何从任何地方到达任意一家星巴克。并行思考对我们来说很难。”

自 2004 年以来，Buck 一直负责开发 Nvidia 的超级计算软件包，名为 cuda。黄仁勋的愿景是让 cuda 能运行在每一块 GeForce 显卡上。“我们在普及超级计算，”黄仁勋表示。

在 Buck 开发软件的同时，Nvidia 的硬件团队也在微芯片上预留出空间，用于超级计算。这些芯片包含了数十亿电子晶体管，通过复杂的电路迅速完成计算。Nvidia 的首席芯片工程师 Arjun Prabhu 把设计微芯片比作城市规划，不同区域负责不同的任务。就像玩俄罗斯方块时处理下落的方块，Prabhu 有时甚至会在梦中看到晶体管。“我经常在周五晚上梦见最棒的点子，就好像真的在梦中看到它们一样，”Prabhu 说。

当 cuda 在 2006 年底面世时，华尔街的反应并不热烈。黄仁勋正将超级计算推向普通大众，但似乎大众对此并不感兴趣。“他们为这种新型芯片架构投入了巨资，”硅谷知名播客“Acquired”的联合主持人 Ben Gilbert 说。“他们投入了数十亿美元，目标却是学术和科学计算的一个小众市场，这和他们的投资规模相比简直是小巫见大巫。”黄仁勋认为，单纯 cuda 的存在就能扩展超级计算的市场。这种看法并不被普遍接受，到 2008 年底，英伟达的股价暴跌了 70%。

黄仁勋在演讲中提到，访问国立台湾大学物理学教授赵庭伟的办公室，给了他在这段艰难时期的信心。赵教授为了模拟宇宙大爆炸后的物质演化，自己在办公室旁的实验室里搭建了一台超级计算机。黄仁勋发现实验室里到处是 GeForce 盒子，而且计算机还用摆动的台式风扇冷却。“Jensen 是一个有远见的人，”赵教授告诉我，“他让我的终身研究成为可能。”

赵教授是理想客户的典范，但像他这样的客户并不多。cuda 的下载量在 2009 年达到顶峰，之后连续三年下降。英伟达的董事会担心，公司股价的低迷可能会吸引企业掠夺者。“我们尽一切努力保护公司，以防激进股东入侵并企图拆分公司，”长期董事会成员 Jim Gaither 说。前 NFL 市场营销主管 Dawn Hudson 于 2013 年加入董事会。“当时的公司明显处于停滞状态，”她评价道。

在市场推广 cuda 的过程中，Nvidia 试图吸引包括股票交易员、石油勘探者和分子生物学家等多种客户。公司甚至与通用磨坊达成协议，为烹饪冷冻比萨的热物理过程建模。但对于人工智能领域，Nvidia 却几乎没有花费太多精力，因为看似没有太大的市场。

在 2010 年代初期，人工智能（A.I.）这个领域几乎被遗忘。在图像识别和语音识别等基本任务上的进展几乎停滞不前。在这个学术上不受青睐的领域中，还有一个更小众的子领域，它通过使用“神经网络”（neural networks）—一种模仿人脑的计算结构—来解决问题。很多计算机科学家都认为神经网络是过时且无效的。“我曾被导师劝阻研究神经网络，”深度学习研究员 Catanzaro 回忆道，“因为当时人们认为它们已经落伍，而且效果不佳。”

Catanzaro 把坚持研究神经网络的科学家们比喻为“荒原中的先知”。其中一位先知是多伦多大学教授 Geoffrey Hinton。2009 年，Hinton 带领的研究团队利用 Nvidia 的 cuda 平台训练了一个识别人类语音的神经网络，并对其成果的高质量感到惊喜。他在那年的一个会议上展示了这些成果，并联系了 Nvidia。“我曾发邮件给 Nvidia，说‘我刚告诉了一千名机器学习研究人员他们应该购买 Nvidia 显卡。你们能免费给我一张吗？’”Hinton 说，“但他们拒绝了。”

尽管如此，Hinton 依然鼓励学生们使用 cuda，其中包括他的乌克兰学生 Alex Krizhevsky，他认为 Krizhevsky 可能是见过的最优秀的程序员之一。2012 年，Krizhevsky 和研究搭档 Ilya Sutskever 在预算有限的情况下，从 Amazon 购买了两张 GeForce 显卡。Krizhevsky 开始在 Nvidia 的并行计算平台上训练一个视觉识别神经网络，仅用一周的时间就处理了数百万张图像。“他的两张 G.P.U. 显卡一直在卧室里运转，”Hinton 补充道，“而他的父母为此支付了相当高的电费。”

Sutskever 和 Krizhevsky 对这些显卡的强大能力感到震惊。就在那年早些时候，谷歌的研究人员用大约一万六千个 C.P.U. 训练了一个能识别猫视频的神经网络。而 Sutskever 和 Krizhevsky 只用了两块 Nvidia 电路板就取得了世界级的成果。“G.P.U. 的出现就像一个奇迹，”Sutskever 说。

Krizhevsky 在他父母家中训练的神经网络，AlexNet，现在已与莱特飞行器和爱迪生灯泡齐名。2012 年，他把 AlexNet 带入年度 ImageNet 视觉识别竞赛，由于当时神经网络尚不普及，他成了唯一采用这种技术的参赛者。AlexNet 在比赛中的卓越表现，甚至让组织者一度怀疑其是否作弊。“那是一个划时代的时刻，”Hinton 如是说。“这标志着一个范式的转变。”

自从 Krizhevsky 发表了关于 AlexNet 架构的九页论文以来的十年里，该论文被引用了超过十万次，成为计算机科学史上最重要的论文之一。（AlexNet 成功识别了包括摩托车、豹子、集装箱船等在内的多种图像。）Krizhevsky 创新了许多重要的编程技巧，其核心发现是，专用 G.P.U. 训练神经网络的速度比通用 C.P.U. 快上百倍。“没有 cuda，机器学习将变得异常困难，”Hinton 表示。

不久之后，ImageNet 竞赛的每个参赛者都开始使用神经网络。到了二十一世纪十年代中期，基于 G.P.U. 训练的神经网络在图像识别准确率上达到了 96%，超过了人类。黄仁勋长达十年的推动超级计算民主化的努力终于获得了成果。“它们能解决复杂的计算机视觉问题，这让人不禁思考，还能教它们学习什么？”黄仁勋这样对我说。

答案似乎是一切。黄仁勋相信，神经网络将彻底改变社会，并借助 cuda 抢占硬件市场。他决定再次全力以赴。“周五晚上他发出邮件，宣布我们将全面转向深度学习，不再是一家专注于图形的公司，”Nvidia 的副总裁 Greg Estes 对我说。“到了周一早上，我们已经成为一家 AI 公司。转变就这么迅速。”

“嘿！不要非法录制演出！” —— Pia Guerra 和 Ian Boothby 创作的漫画</title>
            <link>https://nitter.cz/dotey/status/1729742445515006318#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729742445515006318#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:01:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Buck 曾怀疑，GeForce 显卡除了用来在游戏中向朋友投掷手榴弹外，是否还有其他用途。这些显卡配备了一个基础的编程工具——着色器（shader）。在 darpa（美国国防部高级研究计划署）的资助下，Buck 改造了着色器，以访问底层的并行计算电路，从而将 GeForce 转变为一种低成本的超级计算机。不久后，他开始为 Nvidia 的创始人 黄仁勋工作。<br />
<br />
Buck 是一个充满热情且头发稀疏的人，他的身上散发着聪明才智。作为一名热衷于计算机科学的人，他在过去的二十年里不断挑战 Nvidia 芯片的极限。他说：“人类的思考是线性的。比如，你告诉别人怎样从这里到星巴克，你会一步步指导他们。但你不会告诉他们如何从任何地方到达任意一家星巴克。并行思考对我们来说很难。”<br />
<br />
自 2004 年以来，Buck 一直负责开发 Nvidia 的超级计算软件包，名为 cuda。黄仁勋的愿景是让 cuda 能运行在每一块 GeForce 显卡上。“我们在普及超级计算，”黄仁勋表示。<br />
<br />
在 Buck 开发软件的同时，Nvidia 的硬件团队也在微芯片上预留出空间，用于超级计算。这些芯片包含了数十亿电子晶体管，通过复杂的电路迅速完成计算。Nvidia 的首席芯片工程师 Arjun Prabhu 把设计微芯片比作城市规划，不同区域负责不同的任务。就像玩俄罗斯方块时处理下落的方块，Prabhu 有时甚至会在梦中看到晶体管。“我经常在周五晚上梦见最棒的点子，就好像真的在梦中看到它们一样，”Prabhu 说。<br />
<br />
当 cuda 在 2006 年底面世时，华尔街的反应并不热烈。黄仁勋正将超级计算推向普通大众，但似乎大众对此并不感兴趣。“他们为这种新型芯片架构投入了巨资，”硅谷知名播客“Acquired”的联合主持人 Ben Gilbert 说。“他们投入了数十亿美元，目标却是学术和科学计算的一个小众市场，这和他们的投资规模相比简直是小巫见大巫。”黄仁勋认为，单纯 cuda 的存在就能扩展超级计算的市场。这种看法并不被普遍接受，到 2008 年底，英伟达的股价暴跌了 70%。<br />
<br />
黄仁勋在演讲中提到，访问国立台湾大学物理学教授赵庭伟的办公室，给了他在这段艰难时期的信心。赵教授为了模拟宇宙大爆炸后的物质演化，自己在办公室旁的实验室里搭建了一台超级计算机。黄仁勋发现实验室里到处是 GeForce 盒子，而且计算机还用摆动的台式风扇冷却。“Jensen 是一个有远见的人，”赵教授告诉我，“他让我的终身研究成为可能。”<br />
<br />
赵教授是理想客户的典范，但像他这样的客户并不多。cuda 的下载量在 2009 年达到顶峰，之后连续三年下降。英伟达的董事会担心，公司股价的低迷可能会吸引企业掠夺者。“我们尽一切努力保护公司，以防激进股东入侵并企图拆分公司，”长期董事会成员 Jim Gaither 说。前 NFL 市场营销主管 Dawn Hudson 于 2013 年加入董事会。“当时的公司明显处于停滞状态，”她评价道。<br />
<br />
在市场推广 cuda 的过程中，Nvidia 试图吸引包括股票交易员、石油勘探者和分子生物学家等多种客户。公司甚至与通用磨坊达成协议，为烹饪冷冻比萨的热物理过程建模。但对于人工智能领域，Nvidia 却几乎没有花费太多精力，因为看似没有太大的市场。<br />
<br />
在 2010 年代初期，人工智能（A.I.）这个领域几乎被遗忘。在图像识别和语音识别等基本任务上的进展几乎停滞不前。在这个学术上不受青睐的领域中，还有一个更小众的子领域，它通过使用“神经网络”（neural networks）—一种模仿人脑的计算结构—来解决问题。很多计算机科学家都认为神经网络是过时且无效的。“我曾被导师劝阻研究神经网络，”深度学习研究员 Catanzaro 回忆道，“因为当时人们认为它们已经落伍，而且效果不佳。”<br />
<br />
Catanzaro 把坚持研究神经网络的科学家们比喻为“荒原中的先知”。其中一位先知是多伦多大学教授 Geoffrey Hinton。2009 年，Hinton 带领的研究团队利用 Nvidia 的 cuda 平台训练了一个识别人类语音的神经网络，并对其成果的高质量感到惊喜。他在那年的一个会议上展示了这些成果，并联系了 Nvidia。“我曾发邮件给 Nvidia，说‘我刚告诉了一千名机器学习研究人员他们应该购买 Nvidia 显卡。你们能免费给我一张吗？’”Hinton 说，“但他们拒绝了。”<br />
<br />
尽管如此，Hinton 依然鼓励学生们使用 cuda，其中包括他的乌克兰学生 Alex Krizhevsky，他认为 Krizhevsky 可能是见过的最优秀的程序员之一。2012 年，Krizhevsky 和研究搭档 Ilya Sutskever 在预算有限的情况下，从 Amazon 购买了两张 GeForce 显卡。Krizhevsky 开始在 Nvidia 的并行计算平台上训练一个视觉识别神经网络，仅用一周的时间就处理了数百万张图像。“他的两张 G.P.U. 显卡一直在卧室里运转，”Hinton 补充道，“而他的父母为此支付了相当高的电费。”<br />
<br />
Sutskever 和 Krizhevsky 对这些显卡的强大能力感到震惊。就在那年早些时候，谷歌的研究人员用大约一万六千个 C.P.U. 训练了一个能识别猫视频的神经网络。而 Sutskever 和 Krizhevsky 只用了两块 Nvidia 电路板就取得了世界级的成果。“G.P.U. 的出现就像一个奇迹，”Sutskever 说。<br />
<br />
Krizhevsky 在他父母家中训练的神经网络，AlexNet，现在已与莱特飞行器和爱迪生灯泡齐名。2012 年，他把 AlexNet 带入年度 ImageNet 视觉识别竞赛，由于当时神经网络尚不普及，他成了唯一采用这种技术的参赛者。AlexNet 在比赛中的卓越表现，甚至让组织者一度怀疑其是否作弊。“那是一个划时代的时刻，”Hinton 如是说。“这标志着一个范式的转变。”<br />
<br />
自从 Krizhevsky 发表了关于 AlexNet 架构的九页论文以来的十年里，该论文被引用了超过十万次，成为计算机科学史上最重要的论文之一。（AlexNet 成功识别了包括摩托车、豹子、集装箱船等在内的多种图像。）Krizhevsky 创新了许多重要的编程技巧，其核心发现是，专用 G.P.U. 训练神经网络的速度比通用 C.P.U. 快上百倍。“没有 cuda，机器学习将变得异常困难，”Hinton 表示。<br />
<br />
不久之后，ImageNet 竞赛的每个参赛者都开始使用神经网络。到了二十一世纪十年代中期，基于 G.P.U. 训练的神经网络在图像识别准确率上达到了 96%，超过了人类。黄仁勋长达十年的推动超级计算民主化的努力终于获得了成果。“它们能解决复杂的计算机视觉问题，这让人不禁思考，还能教它们学习什么？”黄仁勋这样对我说。<br />
<br />
答案似乎是一切。黄仁勋相信，神经网络将彻底改变社会，并借助 cuda 抢占硬件市场。他决定再次全力以赴。“周五晚上他发出邮件，宣布我们将全面转向深度学习，不再是一家专注于图形的公司，”Nvidia 的副总裁 Greg Estes 对我说。“到了周一早上，我们已经成为一家 AI 公司。转变就这么迅速。”<br />
<br />
“嘿！不要非法录制演出！” —— Pia Guerra 和 Ian Boothby 创作的漫画</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGSGxKMVhnQUE5V1czLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729742328380719491#m</id>
            <title>R to @dotey: 黄仁勋的童年遭遇了无情的欺凌。他回忆道：“那时候，人们用‘Chinks’来称呼中国人。”在他的口吻中，我几乎感受不到任何情绪。“我们每天都被这样叫。”为了上学，黄仁勋必须穿过一座摇晃的吊桥，桥下是湍急的河流。“这些桥非常高，”他的朋友贝斯回忆，“都是破旧的木板，许多都已经不见了。”有时，黄仁勋走桥时，当地的孩子们会尝试摇晃桥绳，让他掉下去。“但他似乎从不受影响，”贝斯说，“他总能从容应对。”学年结束时，黄仁勋已经能带领那些曾经欺凌他的孩子们一起探险进入树林。贝斯记得黄仁勋在桥上小心地踩过那些缺失的木板，“看起来，他甚至还挺享受的。”黄仁勋认为，他在奥尼达的经历锻炼了他的韧性。“那时候，没有心理顾问可以倾诉，”他说，“你只能自己变得坚强，继续前进。”

2019 年，他向学校捐赠了一栋建筑，并怀着深情回忆那座已不复存在的吊桥，但他并未提及那些曾试图将他从桥上推下的欺凌者。几年后，黄仁勋的父母成功移居美国，定居在俄勒冈州，黄仁勋和他的兄弟与父母团聚。在高中，黄仁勋表现出众，成为了全美乒乓球排名靠前的运动员。他参加了数学、计算机和科学俱乐部，提前两年完成学业，十六岁就高中毕业。“我那时没有女朋友，”他轻描淡写地说。黄仁勋后来进入俄勒冈州立大学，主修电气工程。他的实验室搭档是 Lori Mills，一位热心且略显书呆子气的本科生，拥有一头卷曲的棕色头发。“在电气工程专业里，大约有 250 个学生，只有三个是女生，”黄仁勋回忆，“男生们都在争夺 Mills 的注意。”他感觉自己处于不利地位。“我是班里最小的，看起来像个十二岁的孩子。”

每个周末，黄仁勋都会电话邀请 Mills 一起做作业。他说：“我试图展示自己解决作业的强大能力给她留下印象，当然，并不是依靠外表。”Mills 最终答应了。经过六个月的合作，黄仁勋终于鼓起勇气邀请她约会，她也欣然接受。

大学毕业后，黄仁勋和 Mills 在硅谷找到了作为微芯片设计师的工作。黄仁勋透露：“她的收入甚至比我高。”两人结婚不久后，Mills 选择离开工作岗位，致力于抚养孩子。与此同时，黄仁勋开始负责自己的部门，并在晚上攻读斯坦福大学的研究生课程。1993 年，他与两位经验丰富的微芯片设计师 Chris Malachowsky 和 Curtis Priem 共同创立了 Nvidia。尽管当时只有三十岁的 黄仁勋年龄比 Malachowsky 和 Priem 小，但他们都认为他已经做好准备成为 CEO。Malachowsky 评价说：“他学习能力非常强。”

Malachowsky 和 Priem 计划设计一款让竞争对手“嫉妒不已”的图形芯片。最初，他们打算将公司命名为 NVision，但发现这个名字已被一家卫生纸制造商占用。黄仁勋提出了 Nvidia 这个名字，灵感来自拉丁语“invidia”（意为“嫉妒”）。他选择在 Denny’s 餐厅筹划公司事务，因为那里比家里安静，咖啡便宜，同时他还回忆起自己八十年代在俄勒冈的 Denny’s 餐厅工作的经历。“在逆境中我思考得更清晰，”黄仁勋表示。“我的心跳反而会减慢。任何在餐厅高峰时段工作过的人都能理解我的感受。”

黄仁勋对视频游戏情有独钟，他认为市场需要更先进的图形芯片。艺术家们开始使用称为“原语”的形状，通过组装三维多边形来节省绘图时间和精力，但这需要新型芯片。Nvidia 的竞争对手使用三角形作为原语，但 黄仁勋和他的合伙人选择了四边形。这一决策几乎导致公司崩溃，因为 Nvidia 首款产品刚一发布，微软就宣布其图形软件只支持三角形。

面临资金危机，黄仁勋决定采用传统的三角策略，力求在竞争对手之前抢占市场。1996 年，他裁掉 Nvidia 一百多名员工中的一半以上，将公司剩余的资金全部投入到一批未经测试的微芯片上，他对这些芯片能否正常工作并不确定。“这是一场五五开的赌局，”黄仁勋向我解释，“反正我们即将破产。”

当名为 riva 128 的产品上市时，Nvidia 仅有足够支付一个月工资的资金。然而，这次冒险最终取得了成功，Nvidia 在四个月内卖出了一百万个 riva。黄仁勋鼓励员工以绝望的心态继续推出产品，多年来，他在员工会议上的开场白总是：“我们的公司距离倒闭还有 30 天。”这句话成为了公司非正式的座右铭。

位于 Santa Clara 的 Nvidia 总部中心有两座巨大的三角形建筑，角落被修剪过。这种形状在建筑内部得到了小规模的复制，从沙发和地毯到小便池的挡水板。员工将这两座建筑称为“太空船”，它们宽敞明亮，却又带有一丝神秘感，大多时间里空无一人。在 covid 之后，只有大约三分之一的员工每天上班。根据我在午餐时间对食堂的观察，员工构成相当多元，大约有三分之一是南亚人，三分之一是东亚人，三分之一是白人。绝大多数员工是男性。

即便在股价飙升之前，员工调查就已经将 Nvidia 评为美国最佳工作场所之一。每座建筑顶部都设有酒吧，定期举行欢乐时光，员工被鼓励将办公室当作一个灵活的空间，在这里吃饭、编程和社交。然而，建筑内部保持着一尘不染——Nvidia 通过摄像头和 AI 全天监控员工。如果员工在会议桌上用餐，AI 将在一小时内派遣清洁工来打扫。在 Denny's，黄仁勋向我预示了一个机器人如家电一样融入日常生活的未来。“在未来，所有能动的东西都将自主运行，”他说。

在 Nvidia，我发现唯一不那么开心的似乎是质控技术人员。他们在北校区酒吧下方没有窗户的实验室里，这些面色苍白的年轻人戴着耳塞，穿着 T 恤，不断地把 Nvidia 的微芯片推向极限。周围充斥着难以忍受的噪音——那是不断运转的高音风扇试图冷却过热的硅电路所发出的刺耳声音。正是这些芯片，推动了人工智能革命的到来。

在传统计算机架构中，中央处理单元（CPU）承担了大多数工作。程序员编写程序，将数学问题交给 CPU，而 CPU 则一次解决一个问题。几十年来，CPU 的主要生产商是 Intel，而 Intel 曾多次试图把 Nvidia 淘汰出市场。黄仁勋描述他们像猫鼠游戏般的关系时说：“我尽量避开 Intel。每次他们靠近我们，我都会带着芯片跑路。”

Nvidia 采纳了另一种方式。1999 年，该公司刚上市不久就推出了 GeForce 显卡，公司营销负责人 Dan Vivoli 称之为图形处理单元（GPU）。“我们创造了这个类别，就是为了在这个领域领先”，Vivoli 说。不同于通用的 CPU，GPU 将复杂的数学任务分解成许多小计算，然后一次性并行处理。CPU 就像一辆送货卡车，一次只能送一个包裹；GPU 则更像是分散在城市各处的一群摩托车。

GeForce 系列大获成功。这一受欢迎程度得益于 Quake 视频游戏系列，这些游戏利用并行计算呈现出玩家可以用榴弹发射器击败的怪物。（我还记得，Quake II 在我大学一年级时发布，我在这个游戏上耗费了好几年。）Quake 系列还有一个多人对战模式，叫做“死亡竞赛”，PC 游戏爱好者为了占据上风，每次 GeForce 升级，他们都会购买新的显卡。2000 年，斯坦福大学计算机图形学研究生 Ian Buck 把三十二张 GeForce 卡组合在一起，用八台投影仪来玩 Quake。“那是第一个 8K 分辨率的游戏装置，它覆盖了整面墙”，Buck 回忆道。“真是太壮观了。”

“别这样。他们故意用面包棒让你吃饱，这样等你进治疗师办公室时就会感到不适。” —— 漫画作者：Drew Dernavich</title>
            <link>https://nitter.cz/dotey/status/1729742328380719491#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729742328380719491#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:01:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>黄仁勋的童年遭遇了无情的欺凌。他回忆道：“那时候，人们用‘Chinks’来称呼中国人。”在他的口吻中，我几乎感受不到任何情绪。“我们每天都被这样叫。”为了上学，黄仁勋必须穿过一座摇晃的吊桥，桥下是湍急的河流。“这些桥非常高，”他的朋友贝斯回忆，“都是破旧的木板，许多都已经不见了。”有时，黄仁勋走桥时，当地的孩子们会尝试摇晃桥绳，让他掉下去。“但他似乎从不受影响，”贝斯说，“他总能从容应对。”学年结束时，黄仁勋已经能带领那些曾经欺凌他的孩子们一起探险进入树林。贝斯记得黄仁勋在桥上小心地踩过那些缺失的木板，“看起来，他甚至还挺享受的。”黄仁勋认为，他在奥尼达的经历锻炼了他的韧性。“那时候，没有心理顾问可以倾诉，”他说，“你只能自己变得坚强，继续前进。”<br />
<br />
2019 年，他向学校捐赠了一栋建筑，并怀着深情回忆那座已不复存在的吊桥，但他并未提及那些曾试图将他从桥上推下的欺凌者。几年后，黄仁勋的父母成功移居美国，定居在俄勒冈州，黄仁勋和他的兄弟与父母团聚。在高中，黄仁勋表现出众，成为了全美乒乓球排名靠前的运动员。他参加了数学、计算机和科学俱乐部，提前两年完成学业，十六岁就高中毕业。“我那时没有女朋友，”他轻描淡写地说。黄仁勋后来进入俄勒冈州立大学，主修电气工程。他的实验室搭档是 Lori Mills，一位热心且略显书呆子气的本科生，拥有一头卷曲的棕色头发。“在电气工程专业里，大约有 250 个学生，只有三个是女生，”黄仁勋回忆，“男生们都在争夺 Mills 的注意。”他感觉自己处于不利地位。“我是班里最小的，看起来像个十二岁的孩子。”<br />
<br />
每个周末，黄仁勋都会电话邀请 Mills 一起做作业。他说：“我试图展示自己解决作业的强大能力给她留下印象，当然，并不是依靠外表。”Mills 最终答应了。经过六个月的合作，黄仁勋终于鼓起勇气邀请她约会，她也欣然接受。<br />
<br />
大学毕业后，黄仁勋和 Mills 在硅谷找到了作为微芯片设计师的工作。黄仁勋透露：“她的收入甚至比我高。”两人结婚不久后，Mills 选择离开工作岗位，致力于抚养孩子。与此同时，黄仁勋开始负责自己的部门，并在晚上攻读斯坦福大学的研究生课程。1993 年，他与两位经验丰富的微芯片设计师 Chris Malachowsky 和 Curtis Priem 共同创立了 Nvidia。尽管当时只有三十岁的 黄仁勋年龄比 Malachowsky 和 Priem 小，但他们都认为他已经做好准备成为 CEO。Malachowsky 评价说：“他学习能力非常强。”<br />
<br />
Malachowsky 和 Priem 计划设计一款让竞争对手“嫉妒不已”的图形芯片。最初，他们打算将公司命名为 NVision，但发现这个名字已被一家卫生纸制造商占用。黄仁勋提出了 Nvidia 这个名字，灵感来自拉丁语“invidia”（意为“嫉妒”）。他选择在 Denny’s 餐厅筹划公司事务，因为那里比家里安静，咖啡便宜，同时他还回忆起自己八十年代在俄勒冈的 Denny’s 餐厅工作的经历。“在逆境中我思考得更清晰，”黄仁勋表示。“我的心跳反而会减慢。任何在餐厅高峰时段工作过的人都能理解我的感受。”<br />
<br />
黄仁勋对视频游戏情有独钟，他认为市场需要更先进的图形芯片。艺术家们开始使用称为“原语”的形状，通过组装三维多边形来节省绘图时间和精力，但这需要新型芯片。Nvidia 的竞争对手使用三角形作为原语，但 黄仁勋和他的合伙人选择了四边形。这一决策几乎导致公司崩溃，因为 Nvidia 首款产品刚一发布，微软就宣布其图形软件只支持三角形。<br />
<br />
面临资金危机，黄仁勋决定采用传统的三角策略，力求在竞争对手之前抢占市场。1996 年，他裁掉 Nvidia 一百多名员工中的一半以上，将公司剩余的资金全部投入到一批未经测试的微芯片上，他对这些芯片能否正常工作并不确定。“这是一场五五开的赌局，”黄仁勋向我解释，“反正我们即将破产。”<br />
<br />
当名为 riva 128 的产品上市时，Nvidia 仅有足够支付一个月工资的资金。然而，这次冒险最终取得了成功，Nvidia 在四个月内卖出了一百万个 riva。黄仁勋鼓励员工以绝望的心态继续推出产品，多年来，他在员工会议上的开场白总是：“我们的公司距离倒闭还有 30 天。”这句话成为了公司非正式的座右铭。<br />
<br />
位于 Santa Clara 的 Nvidia 总部中心有两座巨大的三角形建筑，角落被修剪过。这种形状在建筑内部得到了小规模的复制，从沙发和地毯到小便池的挡水板。员工将这两座建筑称为“太空船”，它们宽敞明亮，却又带有一丝神秘感，大多时间里空无一人。在 covid 之后，只有大约三分之一的员工每天上班。根据我在午餐时间对食堂的观察，员工构成相当多元，大约有三分之一是南亚人，三分之一是东亚人，三分之一是白人。绝大多数员工是男性。<br />
<br />
即便在股价飙升之前，员工调查就已经将 Nvidia 评为美国最佳工作场所之一。每座建筑顶部都设有酒吧，定期举行欢乐时光，员工被鼓励将办公室当作一个灵活的空间，在这里吃饭、编程和社交。然而，建筑内部保持着一尘不染——Nvidia 通过摄像头和 AI 全天监控员工。如果员工在会议桌上用餐，AI 将在一小时内派遣清洁工来打扫。在 Denny's，黄仁勋向我预示了一个机器人如家电一样融入日常生活的未来。“在未来，所有能动的东西都将自主运行，”他说。<br />
<br />
在 Nvidia，我发现唯一不那么开心的似乎是质控技术人员。他们在北校区酒吧下方没有窗户的实验室里，这些面色苍白的年轻人戴着耳塞，穿着 T 恤，不断地把 Nvidia 的微芯片推向极限。周围充斥着难以忍受的噪音——那是不断运转的高音风扇试图冷却过热的硅电路所发出的刺耳声音。正是这些芯片，推动了人工智能革命的到来。<br />
<br />
在传统计算机架构中，中央处理单元（CPU）承担了大多数工作。程序员编写程序，将数学问题交给 CPU，而 CPU 则一次解决一个问题。几十年来，CPU 的主要生产商是 Intel，而 Intel 曾多次试图把 Nvidia 淘汰出市场。黄仁勋描述他们像猫鼠游戏般的关系时说：“我尽量避开 Intel。每次他们靠近我们，我都会带着芯片跑路。”<br />
<br />
Nvidia 采纳了另一种方式。1999 年，该公司刚上市不久就推出了 GeForce 显卡，公司营销负责人 Dan Vivoli 称之为图形处理单元（GPU）。“我们创造了这个类别，就是为了在这个领域领先”，Vivoli 说。不同于通用的 CPU，GPU 将复杂的数学任务分解成许多小计算，然后一次性并行处理。CPU 就像一辆送货卡车，一次只能送一个包裹；GPU 则更像是分散在城市各处的一群摩托车。<br />
<br />
GeForce 系列大获成功。这一受欢迎程度得益于 Quake 视频游戏系列，这些游戏利用并行计算呈现出玩家可以用榴弹发射器击败的怪物。（我还记得，Quake II 在我大学一年级时发布，我在这个游戏上耗费了好几年。）Quake 系列还有一个多人对战模式，叫做“死亡竞赛”，PC 游戏爱好者为了占据上风，每次 GeForce 升级，他们都会购买新的显卡。2000 年，斯坦福大学计算机图形学研究生 Ian Buck 把三十二张 GeForce 卡组合在一起，用八台投影仪来玩 Quake。“那是第一个 8K 分辨率的游戏装置，它覆盖了整面墙”，Buck 回忆道。“真是太壮观了。”<br />
<br />
“别这样。他们故意用面包棒让你吃饱，这样等你进治疗师办公室时就会感到不适。” —— 漫画作者：Drew Dernavich</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGSGMxUFdzQUU2SUk4LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729742193697370604#m</id>
            <title>R to @dotey: 让人震惊的人工智能聊天机器人 ChatGPT 就是在 Nvidia 的超级计算机上进行训练的，这一发现引发了股市历史上罕见的单日巨大涨幅。2023 年 5 月 25 日，纳斯达克一开盘，Nvidia 的市值就飙升了约 2000 亿美元。就在几个月前，Nvidia 的 CEO 黄仁勋向投资者宣布，Nvidia 已向美国前 100 大公司中的 50 家出售了类似的超级计算机。当日交易结束时，Nvidia 成为全球第六大价值公司，市值超过沃尔玛和埃克森美孚的总和。可以将黄仁勋的商业地位与 19 世纪 40 年代末在旧金山销售淘金设备的 Samuel Brannan 相媲美。“在 AI 领域的这场较量中，Nvidia 是唯一的军火商，”另一位华尔街分析师表示。

黄仁勋是个耐心经营自己事业的垄断者。1993 年，在加州圣何塞的 Denny's 餐厅，他和另外两人共同起草了 Nvidia 的创始文件，并自那时起一直负责公司运营。现年六十岁的他，风趣而又自嘲，有着一张泰迪熊似的面孔和稀疏的灰发。Nvidia 的核心产品是其图形处理单元 (graphics-processing unit)，一块集成了强大微芯片的电路板。起初，Nvidia 把这些 G.P.U. 卖给电子游戏玩家，但自 2006 年起，黄仁勋也开始向超级计算领域推广这些产品。到了 2013 年，依托于计算机科学领域内的前沿研究，黄仁勋下了一注大赌注，决定让 Nvidia 转向人工智能领域。长期以来，人工智能领域屡屡让投资者失望，当时 Nvidia 的首席深度学习研究员 Bryan Catanzaro 对此持怀疑态度。“我不想让他重蹈人工智能行业过去的覆辙，”Catanzaro 曾对我说。“但事实证明，十多年后，他做对了。”

未来，人工智能有望实现按需生成电影、为孩子们辅导学习、教会汽车自动驾驶等壮举。所有这些进步都将在 Nvidia 的 G.P.U. 上成为现实，而 黄仁勋在公司中的股份如今价值超过 400 亿美元。

今年九月，我在 Nvidia 成立之初的那家 Denny's 餐厅和 黄仁勋一起吃早餐。当时，Denny's 的 CEO 正在给他颁发一个纪念牌匾，还有电视台的摄制组在场。黄仁勋一直以一种带点幽默的冷面幽默与人交谈。他在与我们的女服务员聊天时，点了包括 Super Bird 三明治和炸鸡牛排在内的七样食物。“你知道吗，我曾经在这里洗碗，”他对她说，“但我很努力地工作，真的非常努力，最终我成为了一名服务员。”

黄仁勋以实用为主，不爱空想，甚至连一本科幻小说都没读过。他以微芯片目前的能力为出发点，用第一性原理推测出它们将来的发展方向，并且坚定地对此下注。“我尽我所能，避免公司倒闭，”他在早餐时这样说。“我尽我所能，避免失败。”黄仁勋认为，自 IBM 在 20 世纪 60 年代初期推出以来，数字计算的基本架构几乎没变，但现在正面临重新构思的时刻。“深度学习不是一个算法，”他近期表示，“它是一种方法，一种全新的软件开发方式。”早餐前的晚上，我看了一个视频：一个运行着这种新型软件的机器人，似乎认出了自己的手，然后对一堆彩色积木进行分类。这个视频让我不寒而栗；人类似乎即将被淘汰。黄仁勋一边用手指卷着煎饼和香肠，一边对我的忧虑表示不以为然。“我知道它是怎么工作的，所以我并不担心，”他说。“这和微波炉的原理没什么两样。”我追问 黄仁勋，一个自主机器人肯定和微波炉不同，会有它独特的风险。他回答说，他从不担心技术本身，“它所做的只是处理数据，”他说，“还有很多其他事情值得我们担忧。”

今年五月，数百名行业领袖签署了一份声明，认为失控的人工智能风险可媲美核战争。黄仁勋没有参与签署。有经济学家提出，工业革命导致全球马匹数量减少，而人工智能可能对人类产生类似影响。“马的职业选择有限，”黄仁勋说，“比如，马不会打字。”当他吃完早餐时，我表达了自己的担忧：不久的将来，我可能将我们谈话的笔记输入到一个智能引擎中，然后它就能输出结构更好、更优秀的文章。黄仁勋没有否认这种可能性，但他向我保证，我还有几年时间在面临这种挑战之前。“它会先影响小说家，”他说。然后他给了女服务员一千美元的小费，并起身去接受他的奖项。

1963 年，黄仁勋在台湾出生，但 9 岁那年，他和他的哥哥被送到美国，成为无人陪伴的未成年人。他们首先到达华盛顿州的塔科马，与一位叔叔同住，随后被送到肯塔基州的奥尼达浸信会学院。黄仁勋的叔叔原以为那是一所声名显赫的寄宿学校，事实上却是一所宗教改革学院。黄仁勋的室友是个 17 岁的少年。他们第一个晚上，这个年长的孩子向 黄仁勋展示了他在争斗中被刺伤的痕迹。“学校里每个人都抽烟，我似乎是唯一一个没有随身携带折叠刀的学生，”黄仁勋回忆道。他的室友不识字，黄仁勋教他阅读，作为回报，室友教会了他卧推。“最终，我每晚睡前都会做一百个俯卧撑。”

黄仁勋虽然住在学院，但年龄太小，不能上那里的课，所以他去了附近的公立学校。在那里，他结识了 Ben Bays，一个和他五个兄弟姐妹住在一间没自来水的老房子里的孩子。“学校的孩子大多是烟草农的子女，或者是住在山谷口的贫穷孩子，”Bays 讲述道。黄仁勋在学年已经开始后才到校，Bays 记得校长介绍了一个个子瘦小、长发、口音浓重的亚洲移民孩子。“他成了众矢之的，”Bays 说。

“但我用了所有武器！” —— 这幅漫画由 Ali Solomon 创作。</title>
            <link>https://nitter.cz/dotey/status/1729742193697370604#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729742193697370604#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:00:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>让人震惊的人工智能聊天机器人 ChatGPT 就是在 Nvidia 的超级计算机上进行训练的，这一发现引发了股市历史上罕见的单日巨大涨幅。2023 年 5 月 25 日，纳斯达克一开盘，Nvidia 的市值就飙升了约 2000 亿美元。就在几个月前，Nvidia 的 CEO 黄仁勋向投资者宣布，Nvidia 已向美国前 100 大公司中的 50 家出售了类似的超级计算机。当日交易结束时，Nvidia 成为全球第六大价值公司，市值超过沃尔玛和埃克森美孚的总和。可以将黄仁勋的商业地位与 19 世纪 40 年代末在旧金山销售淘金设备的 Samuel Brannan 相媲美。“在 AI 领域的这场较量中，Nvidia 是唯一的军火商，”另一位华尔街分析师表示。<br />
<br />
黄仁勋是个耐心经营自己事业的垄断者。1993 年，在加州圣何塞的 Denny's 餐厅，他和另外两人共同起草了 Nvidia 的创始文件，并自那时起一直负责公司运营。现年六十岁的他，风趣而又自嘲，有着一张泰迪熊似的面孔和稀疏的灰发。Nvidia 的核心产品是其图形处理单元 (graphics-processing unit)，一块集成了强大微芯片的电路板。起初，Nvidia 把这些 G.P.U. 卖给电子游戏玩家，但自 2006 年起，黄仁勋也开始向超级计算领域推广这些产品。到了 2013 年，依托于计算机科学领域内的前沿研究，黄仁勋下了一注大赌注，决定让 Nvidia 转向人工智能领域。长期以来，人工智能领域屡屡让投资者失望，当时 Nvidia 的首席深度学习研究员 Bryan Catanzaro 对此持怀疑态度。“我不想让他重蹈人工智能行业过去的覆辙，”Catanzaro 曾对我说。“但事实证明，十多年后，他做对了。”<br />
<br />
未来，人工智能有望实现按需生成电影、为孩子们辅导学习、教会汽车自动驾驶等壮举。所有这些进步都将在 Nvidia 的 G.P.U. 上成为现实，而 黄仁勋在公司中的股份如今价值超过 400 亿美元。<br />
<br />
今年九月，我在 Nvidia 成立之初的那家 Denny's 餐厅和 黄仁勋一起吃早餐。当时，Denny's 的 CEO 正在给他颁发一个纪念牌匾，还有电视台的摄制组在场。黄仁勋一直以一种带点幽默的冷面幽默与人交谈。他在与我们的女服务员聊天时，点了包括 Super Bird 三明治和炸鸡牛排在内的七样食物。“你知道吗，我曾经在这里洗碗，”他对她说，“但我很努力地工作，真的非常努力，最终我成为了一名服务员。”<br />
<br />
黄仁勋以实用为主，不爱空想，甚至连一本科幻小说都没读过。他以微芯片目前的能力为出发点，用第一性原理推测出它们将来的发展方向，并且坚定地对此下注。“我尽我所能，避免公司倒闭，”他在早餐时这样说。“我尽我所能，避免失败。”黄仁勋认为，自 IBM 在 20 世纪 60 年代初期推出以来，数字计算的基本架构几乎没变，但现在正面临重新构思的时刻。“深度学习不是一个算法，”他近期表示，“它是一种方法，一种全新的软件开发方式。”早餐前的晚上，我看了一个视频：一个运行着这种新型软件的机器人，似乎认出了自己的手，然后对一堆彩色积木进行分类。这个视频让我不寒而栗；人类似乎即将被淘汰。黄仁勋一边用手指卷着煎饼和香肠，一边对我的忧虑表示不以为然。“我知道它是怎么工作的，所以我并不担心，”他说。“这和微波炉的原理没什么两样。”我追问 黄仁勋，一个自主机器人肯定和微波炉不同，会有它独特的风险。他回答说，他从不担心技术本身，“它所做的只是处理数据，”他说，“还有很多其他事情值得我们担忧。”<br />
<br />
今年五月，数百名行业领袖签署了一份声明，认为失控的人工智能风险可媲美核战争。黄仁勋没有参与签署。有经济学家提出，工业革命导致全球马匹数量减少，而人工智能可能对人类产生类似影响。“马的职业选择有限，”黄仁勋说，“比如，马不会打字。”当他吃完早餐时，我表达了自己的担忧：不久的将来，我可能将我们谈话的笔记输入到一个智能引擎中，然后它就能输出结构更好、更优秀的文章。黄仁勋没有否认这种可能性，但他向我保证，我还有几年时间在面临这种挑战之前。“它会先影响小说家，”他说。然后他给了女服务员一千美元的小费，并起身去接受他的奖项。<br />
<br />
1963 年，黄仁勋在台湾出生，但 9 岁那年，他和他的哥哥被送到美国，成为无人陪伴的未成年人。他们首先到达华盛顿州的塔科马，与一位叔叔同住，随后被送到肯塔基州的奥尼达浸信会学院。黄仁勋的叔叔原以为那是一所声名显赫的寄宿学校，事实上却是一所宗教改革学院。黄仁勋的室友是个 17 岁的少年。他们第一个晚上，这个年长的孩子向 黄仁勋展示了他在争斗中被刺伤的痕迹。“学校里每个人都抽烟，我似乎是唯一一个没有随身携带折叠刀的学生，”黄仁勋回忆道。他的室友不识字，黄仁勋教他阅读，作为回报，室友教会了他卧推。“最终，我每晚睡前都会做一百个俯卧撑。”<br />
<br />
黄仁勋虽然住在学院，但年龄太小，不能上那里的课，所以他去了附近的公立学校。在那里，他结识了 Ben Bays，一个和他五个兄弟姐妹住在一间没自来水的老房子里的孩子。“学校的孩子大多是烟草农的子女，或者是住在山谷口的贫穷孩子，”Bays 讲述道。黄仁勋在学年已经开始后才到校，Bays 记得校长介绍了一个个子瘦小、长发、口音浓重的亚洲移民孩子。“他成了众矢之的，”Bays 说。<br />
<br />
“但我用了所有武器！” —— 这幅漫画由 Ali Solomon 创作。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGSFU2UVdvQUFWTHJ1LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729742105407328729#m</id>
            <title>黄仁勋领导的 Nvidia 如何推动 AI 革命 [译]

Nvidia 的 CEO 黄仁勋把全部筹码都放在了一种全新的芯片上。如今，Nvidia 已经跻身世界最大公司之列，那么他的下一步计划会是什么呢？

作者 Stephen Witt，2023 年 11 月 27 日

原文：https://www.newyorker.com/magazine/2023/12/04/how-jensen-huangs-nvidia-is-powering-the-ai-revolution
译文：https://baoyu.io/translations/new-yorker/how-jensen-huangs-nvidia-is-powering-the-ai-revolution

“在 AI 领域的角逐中，Nvidia 就像独家武器供应商，”一位华尔街分析师如是说。插图作者：Javier Jaén</title>
            <link>https://nitter.cz/dotey/status/1729742105407328729#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729742105407328729#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:00:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>黄仁勋领导的 Nvidia 如何推动 AI 革命 [译]<br />
<br />
Nvidia 的 CEO 黄仁勋把全部筹码都放在了一种全新的芯片上。如今，Nvidia 已经跻身世界最大公司之列，那么他的下一步计划会是什么呢？<br />
<br />
作者 Stephen Witt，2023 年 11 月 27 日<br />
<br />
原文：<a href="https://www.newyorker.com/magazine/2023/12/04/how-jensen-huangs-nvidia-is-powering-the-ai-revolution">newyorker.com/magazine/2023/…</a><br />
译文：<a href="https://baoyu.io/translations/new-yorker/how-jensen-huangs-nvidia-is-powering-the-ai-revolution">baoyu.io/translations/new-yo…</a><br />
<br />
“在 AI 领域的角逐中，Nvidia 就像独家武器供应商，”一位华尔街分析师如是说。插图作者：Javier Jaén</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGSEN2cVdRQUFNaG1sLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729699739271143864#m</id>
            <title>RT by @dotey: 这帮人是真卷啊，已经开发出了基于 #SDXLTurbo 的白板实时涂鸦生成图像的产品，感兴趣可以试试。
其实这种开发门槛不是很高，有技术能力的可以冲一波。
在这里试用：https://www.fal.ai/turbo</title>
            <link>https://nitter.cz/op7418/status/1729699739271143864#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729699739271143864#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:12:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这帮人是真卷啊，已经开发出了基于 <a href="https://nitter.cz/search?q=%23SDXLTurbo">#SDXLTurbo</a> 的白板实时涂鸦生成图像的产品，感兴趣可以试试。<br />
其实这种开发门槛不是很高，有技术能力的可以冲一波。<br />
在这里试用：<a href="https://www.fal.ai/turbo">fal.ai/turbo</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2OTk2NjcxMzM1NzEwNzIvcHUvaW1nLzU4ai02X3JLUjJSdnFUeTUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729708319948804600#m</id>
            <title>R to @dotey: @immersivetran 建议可以集成一下 😄</title>
            <link>https://nitter.cz/dotey/status/1729708319948804600#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729708319948804600#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:46:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/immersivetran" title="沉浸式翻译">@immersivetran</a> 建议可以集成一下 😄</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729706523796840495#m</id>
            <title>好问题！

因为PDF阅读这个问题很困扰我，我就想能不能PDF转HTML，结果发现PDF转HTML效果很差！

我就想能不能LaTeX转HTML，发现可行，就找到LaTeXML！但是本地测试没成功，不过我怀疑有人做过了，就去 Google 搜索，找到了 http://arxiv-vanity.com 。

于是就开始用 http://arxiv-vanity.com ，但是发现质量不够好，觉得不如自己写一个，写了一点发现坑很多，就去 github 搜代码，然后根据代码搜索到了ar5iv 这个项目：

https://github.com/dginev/ar5iv</title>
            <link>https://nitter.cz/dotey/status/1729706523796840495#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729706523796840495#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:39:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>好问题！<br />
<br />
因为PDF阅读这个问题很困扰我，我就想能不能PDF转HTML，结果发现PDF转HTML效果很差！<br />
<br />
我就想能不能LaTeX转HTML，发现可行，就找到LaTeXML！但是本地测试没成功，不过我怀疑有人做过了，就去 Google 搜索，找到了 <a href="http://arxiv-vanity.com">arxiv-vanity.com</a> 。<br />
<br />
于是就开始用 <a href="http://arxiv-vanity.com">arxiv-vanity.com</a> ，但是发现质量不够好，觉得不如自己写一个，写了一点发现坑很多，就去 github 搜代码，然后根据代码搜索到了ar5iv 这个项目：<br />
<br />
<a href="https://github.com/dginev/ar5iv">github.com/dginev/ar5iv</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1729700559567872066#m">nitter.cz/xiaohuggg/status/1729700559567872066#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729704654198501449#m</id>
            <title>微软开放源代码 ThreadX，采用 MIT 许可证
——在数百万树莓派中使用的 'Azure RTOS' 现在是开放源代码软件

2023年11月28日星期二 // 11:05 UTC

微软正在将其通过 Express Logic 收购的实时操作系统开源，并将其捐赠给 Eclipse 基金会。

这家公司使其 ThreadX 实时操作系统（RTOS）和包含这个系统的 Azure RTOS 开发套件开放源代码。微软已经将 Azure RTOS 交给了 Eclipse 基金会，此后它将被称为 Eclipse ThreadX，在宽容的 MIT 许可证下提供。

尽管市场上有许多实时操作系统（简称 RTOS），但它们通常不为人所知。你可能没有听说过 ThreadX，但你可能不知不觉中已经拥有了它的多个副本，甚至可能正在使用。

有些更知名的 RTOS，比如 Wind River 的 VxWorks，它甚至在火星上运行，在 NASA 的毅力号火星车里。Blackberry 的 QNX RTOS，曾被认为是该公司赚钱的关键部分，它曾两次受到关注：一次是作为 RIM 的 Blackberry X 触控板和智能手机系列的基础，另一次是在 1990 年代，因其惊人的 QNX 单软盘演示而出名。

然而，ThreadX 的普及程度更高。据微软称，有 120 亿设备正在运行它，你可能就拥有其中的一些。它曾经为 Intel 芯片上的管理引擎提供动力，并且是控制所有大于 Pi Pico 的 Raspberry Pi 的固件。在 Pi 1、2 和 3 上，它是你 Pi SD 卡上名为 `bootcode.bin` 的文件；在 Pi 4 和 400 上，它被称为 `start*.elf`。虽然它在 GitHub 上可用   http://github.com/raspberrypi/firmware  并被包含在 Debian 中，但它是一个专有的“二进制大对象（Binary Large Object，简称 blob）”。它像一个密封的黑盒，甚至不包含 Arm 代码：而是在 Pi 的 VideoCore GPU 上运行。它是主要设备，负责启动 Pi 并控制其硬件：Arm 核心是 VideoCore GPU 的从属设备。

## 哦太好了，以下是您可以在那些被束之高阁的树莓派、NUC 电脑上尝试的新鲜事：在它们上运行 Ubuntu Appliances

这正是 Xen 只在 Pi 4 及更新型号上运行的原因：它们是第一个让 Arm 核心拥有自己的中断控制器的版本。尽管如此，这依旧需要一番努力。据我们了解，在 Pi 5 中，这一功能被集成到 EEPROM 中并进一步简化，这意味着 Arm 核心能够拥有更多的控制权，正如这篇 Reg 评论所述。

2019 年，这个年轻的操作系统刚满 21 岁，Microsoft 立即将其收入囊中，收购了 ThreadX 的所有者 Express Logic，并将它更名为 Azure RTOS，不过这并没有增加它的品牌知名度。这次收购紧随 AWS 接管 FreeRTOS 之后，一些观察人士，如 Reddit 上的这位评论者所言，认为这是对亚马逊举动的回应。收购后，原始开发者 William Lamie 离开并创立了一家新公司，销售一个名为 PX5OS 的“第五代”RTOS，它支持 POSIX 兼容的线程。

即便如此，ThreadX 仍是一个经过测试并且成熟的产品；它的某些部分，如 STM32 版本，甚至获得了 TÜV 功能安全 (FuSa) 认证 [PDF]。这对某些客户来说是极具吸引力的。

* Python 头部对欧洲即将实施的网络安全规则表示担忧
* 开源 IDE NetBeans 升级至 v13 - 对 Gradle、Maven 进行了改进
* Eclipse Data Connector 为 GAIA-X 提供支持，这是欧洲保护其云数据免受外国科技公司影响的计划
* Microsoft 一切正常吗？Windows 巨头承认在开源方面“曾站错队伍”

目前，只有最新版本托管在 GitHub 上 http://github.com/azure-rtos ，我们并没有找到任何 VideoCore 版本的踪迹。虽然 GPU 驱动程序已经开源，但固件从未开源，对此项目页面有详细解释。此前尝试编写独立的 FOSS 版本未能完成。现在，至少有些希望树莓派基金会能获得授权，发布其版本的源代码。截至去年，该基金会已销售超过 4600 万个设备，如果整个软件栈都开源，那将使它们对更多人更具吸引力。®

原文地址：https://www.theregister.com/2023/11/28/microsoft_opens_sources_threadx/
项目地址：http://github.com/azure-rtos</title>
            <link>https://nitter.cz/dotey/status/1729704654198501449#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729704654198501449#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:31:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软开放源代码 ThreadX，采用 MIT 许可证<br />
——在数百万树莓派中使用的 'Azure RTOS' 现在是开放源代码软件<br />
<br />
2023年11月28日星期二 // 11:05 UTC<br />
<br />
微软正在将其通过 Express Logic 收购的实时操作系统开源，并将其捐赠给 Eclipse 基金会。<br />
<br />
这家公司使其 ThreadX 实时操作系统（RTOS）和包含这个系统的 Azure RTOS 开发套件开放源代码。微软已经将 Azure RTOS 交给了 Eclipse 基金会，此后它将被称为 Eclipse ThreadX，在宽容的 MIT 许可证下提供。<br />
<br />
尽管市场上有许多实时操作系统（简称 RTOS），但它们通常不为人所知。你可能没有听说过 ThreadX，但你可能不知不觉中已经拥有了它的多个副本，甚至可能正在使用。<br />
<br />
有些更知名的 RTOS，比如 Wind River 的 VxWorks，它甚至在火星上运行，在 NASA 的毅力号火星车里。Blackberry 的 QNX RTOS，曾被认为是该公司赚钱的关键部分，它曾两次受到关注：一次是作为 RIM 的 Blackberry X 触控板和智能手机系列的基础，另一次是在 1990 年代，因其惊人的 QNX 单软盘演示而出名。<br />
<br />
然而，ThreadX 的普及程度更高。据微软称，有 120 亿设备正在运行它，你可能就拥有其中的一些。它曾经为 Intel 芯片上的管理引擎提供动力，并且是控制所有大于 Pi Pico 的 Raspberry Pi 的固件。在 Pi 1、2 和 3 上，它是你 Pi SD 卡上名为 `bootcode.bin` 的文件；在 Pi 4 和 400 上，它被称为 `start*.elf`。虽然它在 GitHub 上可用   <a href="http://github.com/raspberrypi/firmware">github.com/raspberrypi/firmw…</a>  并被包含在 Debian 中，但它是一个专有的“二进制大对象（Binary Large Object，简称 blob）”。它像一个密封的黑盒，甚至不包含 Arm 代码：而是在 Pi 的 VideoCore GPU 上运行。它是主要设备，负责启动 Pi 并控制其硬件：Arm 核心是 VideoCore GPU 的从属设备。<br />
<br />
## 哦太好了，以下是您可以在那些被束之高阁的树莓派、NUC 电脑上尝试的新鲜事：在它们上运行 Ubuntu Appliances<br />
<br />
这正是 Xen 只在 Pi 4 及更新型号上运行的原因：它们是第一个让 Arm 核心拥有自己的中断控制器的版本。尽管如此，这依旧需要一番努力。据我们了解，在 Pi 5 中，这一功能被集成到 EEPROM 中并进一步简化，这意味着 Arm 核心能够拥有更多的控制权，正如这篇 Reg 评论所述。<br />
<br />
2019 年，这个年轻的操作系统刚满 21 岁，Microsoft 立即将其收入囊中，收购了 ThreadX 的所有者 Express Logic，并将它更名为 Azure RTOS，不过这并没有增加它的品牌知名度。这次收购紧随 AWS 接管 FreeRTOS 之后，一些观察人士，如 Reddit 上的这位评论者所言，认为这是对亚马逊举动的回应。收购后，原始开发者 William Lamie 离开并创立了一家新公司，销售一个名为 PX5OS 的“第五代”RTOS，它支持 POSIX 兼容的线程。<br />
<br />
即便如此，ThreadX 仍是一个经过测试并且成熟的产品；它的某些部分，如 STM32 版本，甚至获得了 TÜV 功能安全 (FuSa) 认证 [PDF]。这对某些客户来说是极具吸引力的。<br />
<br />
* Python 头部对欧洲即将实施的网络安全规则表示担忧<br />
* 开源 IDE NetBeans 升级至 v13 - 对 Gradle、Maven 进行了改进<br />
* Eclipse Data Connector 为 GAIA-X 提供支持，这是欧洲保护其云数据免受外国科技公司影响的计划<br />
* Microsoft 一切正常吗？Windows 巨头承认在开源方面“曾站错队伍”<br />
<br />
目前，只有最新版本托管在 GitHub 上 <a href="http://github.com/azure-rtos">github.com/azure-rtos</a> ，我们并没有找到任何 VideoCore 版本的踪迹。虽然 GPU 驱动程序已经开源，但固件从未开源，对此项目页面有详细解释。此前尝试编写独立的 FOSS 版本未能完成。现在，至少有些希望树莓派基金会能获得授权，发布其版本的源代码。截至去年，该基金会已销售超过 4600 万个设备，如果整个软件栈都开源，那将使它们对更多人更具吸引力。®<br />
<br />
原文地址：<a href="https://www.theregister.com/2023/11/28/microsoft_opens_sources_threadx/">theregister.com/2023/11/28/m…</a><br />
项目地址：<a href="http://github.com/azure-rtos">github.com/azure-rtos</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFbE5PclhzQUFFeWlBLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>