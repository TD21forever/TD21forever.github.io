<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742373301929091472#m</id>
            <title>RT by @dotey: 这些人速度真快，666

1月1号米老鼠版权不是过期了嘛，任何人都可以使用

然后现在米老鼠的SD模型已经出来了 

Mickey-1928：一个基于Stable-Diffusion-xl的微调版本，专门训练用于生成米老鼠、米妮和皮特的图像。

模型使用了来自1928年公共领域的96张静止画面训练，目的是生成符合1928年设计风格的米老鼠、米妮和皮特的图像。

数据集来源：数据集包括来自三部米老鼠卡通的静止画面，分别是《Gallopin' Gaucho》（40张彩色静止画面）、《Plane Crazy》（22张静止画面）和《Steamboat Willie》（34张静止画面）。

模型作者：@Dorialexander

模型下载：https://huggingface.co/Pclanglais/Mickey-1928

在线体验：https://huggingface.co/spaces/shewster/Pclanglais-Mickey-1928</title>
            <link>https://nitter.cz/xiaohuggg/status/1742373301929091472#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742373301929091472#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:32:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这些人速度真快，666<br />
<br />
1月1号米老鼠版权不是过期了嘛，任何人都可以使用<br />
<br />
然后现在米老鼠的SD模型已经出来了 <br />
<br />
Mickey-1928：一个基于Stable-Diffusion-xl的微调版本，专门训练用于生成米老鼠、米妮和皮特的图像。<br />
<br />
模型使用了来自1928年公共领域的96张静止画面训练，目的是生成符合1928年设计风格的米老鼠、米妮和皮特的图像。<br />
<br />
数据集来源：数据集包括来自三部米老鼠卡通的静止画面，分别是《Gallopin' Gaucho》（40张彩色静止画面）、《Plane Crazy》（22张静止画面）和《Steamboat Willie》（34张静止画面）。<br />
<br />
模型作者：<a href="https://nitter.cz/Dorialexander" title="Alexander Doria">@Dorialexander</a><br />
<br />
模型下载：<a href="https://huggingface.co/Pclanglais/Mickey-1928">huggingface.co/Pclanglais/Mi…</a><br />
<br />
在线体验：<a href="https://huggingface.co/spaces/shewster/Pclanglais-Mickey-1928">huggingface.co/spaces/shewst…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1742010140113674467#m">nitter.cz/xiaohuggg/status/1742010140113674467#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWhEYmJRQUFVdnVyLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWpReWJjQUFXRVdLLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWxYUWFjQUEyOEd5LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742378525925982662#m</id>
            <title>自从马斯克收购 Twitter（已经改名为 X）后，据报道该公司估值已经缩水了 72％。

富达（Fidelity）降低了其在 X 公司的股权价值，暗示自从马斯克以 440 亿美元收购后，其估值已经下降了 72％。

富达最近对其在 X 公司的股权的估价，自从马斯克在 2022 年 10 月购买该公司以来，其价值已经下降了大约 71.5％。

富达的 Blue Chip Growth Fund 在 X 公司持有相对较少的股份。该基金的月度更新报告显示，截至 2023 年 11 月 30 日，其在“X Holdings Corp.”的股权价值为 560 万美元。该基金在 X 公司的股份原价为 1970 万美元，但在 2023 年 4 月已经损失了大约三分之二的价值，并且自那时以来的跌幅已经相对小了许多。

根据 Axios 的报告，富达在 11 月份将 X 的估值降低了 10.7％。人们不清楚富达是否在 11 月份卖掉了部分股份，但最近股价的下降不足为奇，因为最近马斯克引起的争议让广告商们纷纷离开了这个平台。

"截至 10 月 30 日，该基金尚未出售任何股份，但更新的估值月度报告没有披露持股量是否有所变化，" 据彭博社报道。"如果该基金并未减少在 X 公司的股份，那么最新的报告就暗示了整个公司的价值也下降了 72％。富达公司拒绝对此发表评论。”

根据马斯克一年前支付了 440 亿美元购买 Twitter，富达的估值下降使得公司价值约为 125 亿美元。据报道，X 公司 10 月份的自我估值约为 190 亿美元，这是基于给员工的股票赠礼的价值。

自从马斯克决定将 Twitter 置为私有后，公司的价值和收入从外部更难了解。正如 Axios 所注意到的，“尽管富达成为了这家私人拥有的公司的股东，但它也可能没有太多关于 X 财务状况的内部信息。其他股东可能对他们的 X 股票有不同的估值。”

X 公司的财务状况在马斯克收购一周年也就是去年 10 月底的时候已经足够致命。马斯克在 11 月中发布了对一条反犹太推文的积极响应，使情况变得更糟。11 月 29 日，他在一个公开访谈中处理了这场反犹太主义争议，告诉从 X 撤走广告的商家“去他妈的”。

马斯克在任期内，X 一直在保留广告商方面存在问题，幕后大 boss 的处理方式成为了主要原因。马斯克在成为所有者不久后近乎裁员了公司所有老员工。

X 无法阻止加州法案

X 正在应对欧洲和美国针对内容监管的新法规。马斯克的公司于九月起诉加州政府，试图阻止该州的内容审核法，但上周它在法庭败诉。

周四，美国地方法官威廉·舒布驳回了 X 请求临时禁令以阻止执行加州的内容审核法。该项州法案要求公司每年提交两份报告，说明服务条款和详细的内容审核实践。

舒布驳回了 X 的主张，即该法律违反了第一修正案。舒布写道，“虽然报告要求似乎给社交媒体公司带来了实质性的合规负担，但在第一修正案法律范畴内，并未出现该要求无理或过度繁复的情况。”

法官支持加州政府，要求社交媒体公司对他们的内容审核政策和实践进行透明化，这有着实质性的政府利益，以便消费者可以做出明智的决定，决定他们在哪里消费和传播新闻和信息。

新闻来源：https://arstechnica.com/tech-policy/2024/01/since-elon-musks-twitter-purchase-firm-reportedly-lost-72-of-its-value/</title>
            <link>https://nitter.cz/dotey/status/1742378525925982662#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742378525925982662#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:53:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>自从马斯克收购 Twitter（已经改名为 X）后，据报道该公司估值已经缩水了 72％。<br />
<br />
富达（Fidelity）降低了其在 X 公司的股权价值，暗示自从马斯克以 440 亿美元收购后，其估值已经下降了 72％。<br />
<br />
富达最近对其在 X 公司的股权的估价，自从马斯克在 2022 年 10 月购买该公司以来，其价值已经下降了大约 71.5％。<br />
<br />
富达的 Blue Chip Growth Fund 在 X 公司持有相对较少的股份。该基金的月度更新报告显示，截至 2023 年 11 月 30 日，其在“X Holdings Corp.”的股权价值为 560 万美元。该基金在 X 公司的股份原价为 1970 万美元，但在 2023 年 4 月已经损失了大约三分之二的价值，并且自那时以来的跌幅已经相对小了许多。<br />
<br />
根据 Axios 的报告，富达在 11 月份将 X 的估值降低了 10.7％。人们不清楚富达是否在 11 月份卖掉了部分股份，但最近股价的下降不足为奇，因为最近马斯克引起的争议让广告商们纷纷离开了这个平台。<br />
<br />
"截至 10 月 30 日，该基金尚未出售任何股份，但更新的估值月度报告没有披露持股量是否有所变化，" 据彭博社报道。"如果该基金并未减少在 X 公司的股份，那么最新的报告就暗示了整个公司的价值也下降了 72％。富达公司拒绝对此发表评论。”<br />
<br />
根据马斯克一年前支付了 440 亿美元购买 Twitter，富达的估值下降使得公司价值约为 125 亿美元。据报道，X 公司 10 月份的自我估值约为 190 亿美元，这是基于给员工的股票赠礼的价值。<br />
<br />
自从马斯克决定将 Twitter 置为私有后，公司的价值和收入从外部更难了解。正如 Axios 所注意到的，“尽管富达成为了这家私人拥有的公司的股东，但它也可能没有太多关于 X 财务状况的内部信息。其他股东可能对他们的 X 股票有不同的估值。”<br />
<br />
X 公司的财务状况在马斯克收购一周年也就是去年 10 月底的时候已经足够致命。马斯克在 11 月中发布了对一条反犹太推文的积极响应，使情况变得更糟。11 月 29 日，他在一个公开访谈中处理了这场反犹太主义争议，告诉从 X 撤走广告的商家“去他妈的”。<br />
<br />
马斯克在任期内，X 一直在保留广告商方面存在问题，幕后大 boss 的处理方式成为了主要原因。马斯克在成为所有者不久后近乎裁员了公司所有老员工。<br />
<br />
X 无法阻止加州法案<br />
<br />
X 正在应对欧洲和美国针对内容监管的新法规。马斯克的公司于九月起诉加州政府，试图阻止该州的内容审核法，但上周它在法庭败诉。<br />
<br />
周四，美国地方法官威廉·舒布驳回了 X 请求临时禁令以阻止执行加州的内容审核法。该项州法案要求公司每年提交两份报告，说明服务条款和详细的内容审核实践。<br />
<br />
舒布驳回了 X 的主张，即该法律违反了第一修正案。舒布写道，“虽然报告要求似乎给社交媒体公司带来了实质性的合规负担，但在第一修正案法律范畴内，并未出现该要求无理或过度繁复的情况。”<br />
<br />
法官支持加州政府，要求社交媒体公司对他们的内容审核政策和实践进行透明化，这有着实质性的政府利益，以便消费者可以做出明智的决定，决定他们在哪里消费和传播新闻和信息。<br />
<br />
新闻来源：<a href="https://arstechnica.com/tech-policy/2024/01/since-elon-musks-twitter-purchase-firm-reportedly-lost-72-of-its-value/">arstechnica.com/tech-policy/…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/beihuo/status/1742350183709671744#m</id>
            <title>RT by @dotey: 我想想找一个管理工具，给自己用，但是选来选去总是感觉不顺手。今天我在对比工具的时候，忽然意识到并不是工具不顺手，而是我不知道该如何管理项目开发，我不知道该如何正确使用这些工具。

于是我去学习了 Github 团队是如何管理产品开发的，并做了一些笔记：

1/19</title>
            <link>https://nitter.cz/beihuo/status/1742350183709671744#m</link>
            <guid isPermaLink="false">https://nitter.cz/beihuo/status/1742350183709671744#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 01:00:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我想想找一个管理工具，给自己用，但是选来选去总是感觉不顺手。今天我在对比工具的时候，忽然意识到并不是工具不顺手，而是我不知道该如何管理项目开发，我不知道该如何正确使用这些工具。<br />
<br />
于是我去学习了 Github 团队是如何管理产品开发的，并做了一些笔记：<br />
<br />
1/19</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742326546474389640#m</id>
            <title>R to @dotey: 前一条推翻译不太对：“public domain” 是说已经进入公有领域，也就是所有权过期了</title>
            <link>https://nitter.cz/dotey/status/1742326546474389640#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742326546474389640#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 23:26:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前一条推翻译不太对：“public domain” 是说已经进入公有领域，也就是所有权过期了</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742324698325627292#m</id>
            <title>推荐一套The Full Stack的免费 LLM 在线教程：LLM Bootcamp - Spring 2023

包含了提示工程、LLM运维、LLM App开发、LLM基础等内容。

第一次访问需要输入邮箱。

https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/</title>
            <link>https://nitter.cz/dotey/status/1742324698325627292#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742324698325627292#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 23:19:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一套The Full Stack的免费 LLM 在线教程：LLM Bootcamp - Spring 2023<br />
<br />
包含了提示工程、LLM运维、LLM App开发、LLM基础等内容。<br />
<br />
第一次访问需要输入邮箱。<br />
<br />
<a href="https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/">fullstackdeeplearning.com/ll…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzNjlpTVgwQUFuRzV6LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzN0NwdlhNQUU1NkNMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742321608037986530#m</id>
            <title>R to @dotey: 论文摘要：

当今的主流大语言模型（LLMs）与过去的语言模型有所不同，它们不仅规模更大，而且依托自然语言和代码（形式语言）综合训练。

代码作为连通人类与计算机的桥梁，将高层次的目标转化为可执行的步骤，具备标准语法、逻辑一致性、抽象性和模块化等特性。

在本文中，我们探讨了将代码整合进大语言模型训练数据中的众多益处，具体来看，代码的独特属性不仅能够提升大语言模型的代码生成能力，同时还可以：

(i) 解锁大语言模型的推理能力，使其能够应对一系列更为复杂的自然语言任务；

(ii) 引导大语言模型生成结构化和精准的中间步骤，然后通过函数调用将这些步骤连接到外部执行环节；

(iii) 利用代码的编译和执行环境，获取多样的反馈以改进模型。

此外，我们还追溯了代码对大语言模型深远影响的一种表现：促使其在需要理解指令、分解目标、规划和执行行动以及依据反馈进行优化的情境中，成为有效的智能代理（IAs）。

文章最后，我们提出了几个以代码赋能大语言模型的未来方向及其所面临的关键挑战。</title>
            <link>https://nitter.cz/dotey/status/1742321608037986530#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742321608037986530#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 23:06:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>论文摘要：<br />
<br />
当今的主流大语言模型（LLMs）与过去的语言模型有所不同，它们不仅规模更大，而且依托自然语言和代码（形式语言）综合训练。<br />
<br />
代码作为连通人类与计算机的桥梁，将高层次的目标转化为可执行的步骤，具备标准语法、逻辑一致性、抽象性和模块化等特性。<br />
<br />
在本文中，我们探讨了将代码整合进大语言模型训练数据中的众多益处，具体来看，代码的独特属性不仅能够提升大语言模型的代码生成能力，同时还可以：<br />
<br />
(i) 解锁大语言模型的推理能力，使其能够应对一系列更为复杂的自然语言任务；<br />
<br />
(ii) 引导大语言模型生成结构化和精准的中间步骤，然后通过函数调用将这些步骤连接到外部执行环节；<br />
<br />
(iii) 利用代码的编译和执行环境，获取多样的反馈以改进模型。<br />
<br />
此外，我们还追溯了代码对大语言模型深远影响的一种表现：促使其在需要理解指令、分解目标、规划和执行行动以及依据反馈进行优化的情境中，成为有效的智能代理（IAs）。<br />
<br />
文章最后，我们提出了几个以代码赋能大语言模型的未来方向及其所面临的关键挑战。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742320658321739850#m</id>
            <title>我喜欢这篇论文的标题中用的比喻：如果 LLM 是巫师，那么代码就是魔杖

https://browse.arxiv.org/html/2401.00812v1</title>
            <link>https://nitter.cz/dotey/status/1742320658321739850#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742320658321739850#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 23:03:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我喜欢这篇论文的标题中用的比喻：如果 LLM 是巫师，那么代码就是魔杖<br />
<br />
<a href="https://browse.arxiv.org/html/2401.00812v1">browse.arxiv.org/html/2401.0…</a></p>
<p><a href="https://nitter.cz/omarsar0/status/1742215295907811613#m">nitter.cz/omarsar0/status/1742215295907811613#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzM043WlhnQUFFS3FtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzM1AyaVhVQUFremFPLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzM1lQcFhVQUFnbVE3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742314322414502023#m</id>
            <title>R to @dotey: 拾象科技CEO李广密的这个采访给出的信息和判断太多了，节选一下，顺序有一定打乱，强烈建议大家看原文或者去听播客，链接：http://t.cn/A6lmccU9

- OpenAI 是在一年前做出的 GPT-4， Anthropic 是半年前做出来的，Google 是下个月才能真正推出 GPT-4，全球其他团队可能还需要 6- 12 个月才能做出来。从 GPT-3 到 GPT-3.5，很多公司有机会达到，但是从 GPT-3.5 到 GPT-4 难度会增加 5-10 倍，只有极少数公司能到。

- 模型公司的壁垒很像台积电或者 SpaceX，有很强的先发效应和规模效应的，但现在还不知道能不能像互联网范式一样有网络效应。

- 全球第一梯队的模型，如果没有 100 亿美金的储备、而且有机会转化成 GPU，是没有办法待在全球第一梯队的，这是一个硬标准。

- 2024 年可能基本上会决定大概的格局。窗口就是未来 12 个月，如果未来 12 个月追不上去，后面再翻转其实是很难了。模型竞争很残酷，很像造芯片或者做 SpaceX，最理想化的格局是很可能只剩一家，最领先的模型又最便宜，没有理由用第二家，但因为有抗衡微软跟 OpenAI 联盟的阵营在，所以会有不同的阵营，这样推演下来可能大概率是 2-3 家。

- 2024 年的叙事肯定是多模态，Google Gemini 就是打了一个新的开端。

- OpenAI 一年做到 10 多亿美元的 ARR（编注：最新的报道是16亿美元），明年可能是五六十亿美元的 ARR，它可能是历史上增长最快的公司。但整个市场上其他的大模型 native 的产品所有的 ARR 加在一起是不到 10 亿美金的。

- 硅谷 VC 几乎都错过了大模型的投资，也同样都错过了对 SpaceX 和 Tesla 的投资，这几件事都是典型的重投入、早期看不到商业模式、风险很大，不符合硅谷 VC 的典型投资偏好。

- 三个头部厂商：微软和 OpenAI，其次是亚马逊和 Google 支持的 Anthropic，第三个是 Google，它自成一派，Apple 跟 Tesla 是潜在的关键变量。

有三个大生意和大模型最相关，首先是芯片，英伟达在这一波就很激进，第二波是公有云，微软的云和亚马逊的云是两个是最大的，可能未来模型都是要跑在云上，所以云厂商拿未来每年营收的 3- 5 个点去投模型公司也很合理。第三个大生意是终端，手机和车，所以 Apple 和 Tesla 未来会是更关键的阵营。

- http://X.ai 现在是晚了 6- 12 个月的，未来有大于 50% 的概率追上；开源模型有可能未来就等于 Meta。

- 关于全球对大模型的投入，OpenAI 未来训练模型可能还需要至少得200-300 亿美金， Google 也不能低于这个数，Anthropic 大概也需要 100-200 亿美金，未来几年，3-5 年至少要花 1000 亿美金赌下去。
- 关于大模型产品：1.大模型是最核心的，没有模型可能是没有所谓的 AI native 应用。2.智能是最关键的变量，过去的产品经验可能在今天是一种包袱，只是模型之上怼很多的功能、UI、 UX 有可能是徒劳的，更本质的是要理解模型的能力是什么。
- 那些复刻GPT-4的厂商是如何做到的：

1.全球范围真的对大模型能有实际大贡献的天才 researcher 可能就两三百个人，天才科学家的聚集效应是很强的，这种人和这种 research 文化其实是非常重要的，不是所有巨头都具备这样的条件。

2.GPT-4 的短期壁垒是数据，尤其是 pre-training 和 post-training 阶段的数据，全球范围真正有 GPT-4 数据 know-how 的只有两三百个人，而且几乎都在目前头部的三家模型公司，其他公司想搞清楚这件事至少得经过几百次、甚至几千次充足的实验，小几万张卡是一个必要条件。

3.训练成本，如果 Claude-3 和 GPT-4.5 训练成本可能 2 到 3 亿美元，那再往后的 25、26 年，更下一代的模型训练成本至少可能是 10 亿美元，甚至说 30、50 亿美元。

4.另外一个核心变量可能还是取决于大家是不是信仰 scaling law，以及能不能做到、能不能继续 scaling 下去，这件事可能是长期的唯一关键变量，只有极少数的科学家是很信的，比如说 http://Character.AI 的 Noam， Anthropic 的 Dario，还有  OpenAI 的 Ilya，他们三个对 scaling law 的贡献也是最大的，同时也是信仰最强的。

- 关于大模型成本：

训练成本其实是分两个部分，一部分是实验成本，一部分是最终大规模训练的成本。可以理解为一年当中是有 9 个月要做实验的，实验就是用小尺寸的模型做训练，做足训练之后，2-3 个月做一次大的训练，这一次就像一次大的火箭的发射，所以简单按时间来分，3/ 4 的成本用在做实验， 1/ 4 用在大的训练，也就是“发射”。

模型参数量在 700 亿是一个分界点， 700 亿以下能容忍非常多的错误，模型不会在训练过程中崩掉，700 亿参数以上每往上扩大一个级别，遇到的训练的难度是指数级提升的，模型越大越容易出错。

OpenAI 的成本优化能力是很强的，比如说他们训练完 GPT-4 以后，因为具备了这个训练能力了，可以再重新训练一个 GPT-3.5、把 3.5 的推理成本降得非常低。

现在共识是下一代就是多模态模型，各种模态的数据要从头 pre-train 进去，而不是用现在的 Flamingo 挂起来，视频数据的 pre-train 其实比文本的 token 整个更复杂，要高出一个量级的 GPU 资源。如果参数量又扩大一倍，又是一个多模态的模型，它需要的 GPU 资源可能是之前的 10-20 倍以上的，而且还包含了优化能力。

下一代模型实际算力可能是当年 GPT-4 的 16- 32 倍的提升，如果这样算下去，到 2025 年训练一个大的模型，他估计可能花费要 10- 30 亿美元之间。

- 开源与闭源之争：

开源模型是追不上闭源模型的，而且差距肯定会越来越大，大模型很像芯片或者 Space X，因为大模型它不是一个传统意义的软件开源，模型不可编码，不可解释，大家没办法一起做贡献，包括 GPU 要在单一一个集训练起来训练才更高效。

开源模型的使命不是做最聪明的模型，而是承接先进模型溢出的很多能力，做民主化。因为未来很多用户和企业的需求是分层的，可能有相当大比例的需求是通过一定能力的模型就可以覆盖的，很多企业和大规模的用户优先考虑的是成本问题，这部分是开源的优势。

开源模型在 2024 年追齐 GPT-4 还是挺挑战的。

下一个开源模型重要的方向是端侧，端侧意味着很多推理成本可以放到端侧，会让 AI 公司的成本结构发生很大的变化。

- 一个模型公司最重要的是至少有一个天才的科学家。上半场可能不一定是 CEO，但科学家一定是最重要的，以及团队的科学家文化，能够持续不断的探索、做实验是最重要的，下半场有可能是商业和应用。

- Sam Altman 跟乔布斯和马斯克好像不太像一类人，乔布斯和马斯克在硅谷几乎没有朋友，但 Sam 在硅谷所有人都是朋友，Sam 更像是一个政客。

以上整理的要点转载自微博用户 i陆三金： https://weibo.com/1706699904/NzIFhs3w7</title>
            <link>https://nitter.cz/dotey/status/1742314322414502023#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742314322414502023#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 22:37:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>拾象科技CEO李广密的这个采访给出的信息和判断太多了，节选一下，顺序有一定打乱，强烈建议大家看原文或者去听播客，链接：<a href="http://t.cn/A6lmccU9">t.cn/A6lmccU9</a><br />
<br />
- OpenAI 是在一年前做出的 GPT-4， Anthropic 是半年前做出来的，Google 是下个月才能真正推出 GPT-4，全球其他团队可能还需要 6- 12 个月才能做出来。从 GPT-3 到 GPT-3.5，很多公司有机会达到，但是从 GPT-3.5 到 GPT-4 难度会增加 5-10 倍，只有极少数公司能到。<br />
<br />
- 模型公司的壁垒很像台积电或者 SpaceX，有很强的先发效应和规模效应的，但现在还不知道能不能像互联网范式一样有网络效应。<br />
<br />
- 全球第一梯队的模型，如果没有 100 亿美金的储备、而且有机会转化成 GPU，是没有办法待在全球第一梯队的，这是一个硬标准。<br />
<br />
- 2024 年可能基本上会决定大概的格局。窗口就是未来 12 个月，如果未来 12 个月追不上去，后面再翻转其实是很难了。模型竞争很残酷，很像造芯片或者做 SpaceX，最理想化的格局是很可能只剩一家，最领先的模型又最便宜，没有理由用第二家，但因为有抗衡微软跟 OpenAI 联盟的阵营在，所以会有不同的阵营，这样推演下来可能大概率是 2-3 家。<br />
<br />
- 2024 年的叙事肯定是多模态，Google Gemini 就是打了一个新的开端。<br />
<br />
- OpenAI 一年做到 10 多亿美元的 ARR（编注：最新的报道是16亿美元），明年可能是五六十亿美元的 ARR，它可能是历史上增长最快的公司。但整个市场上其他的大模型 native 的产品所有的 ARR 加在一起是不到 10 亿美金的。<br />
<br />
- 硅谷 VC 几乎都错过了大模型的投资，也同样都错过了对 SpaceX 和 Tesla 的投资，这几件事都是典型的重投入、早期看不到商业模式、风险很大，不符合硅谷 VC 的典型投资偏好。<br />
<br />
- 三个头部厂商：微软和 OpenAI，其次是亚马逊和 Google 支持的 Anthropic，第三个是 Google，它自成一派，Apple 跟 Tesla 是潜在的关键变量。<br />
<br />
有三个大生意和大模型最相关，首先是芯片，英伟达在这一波就很激进，第二波是公有云，微软的云和亚马逊的云是两个是最大的，可能未来模型都是要跑在云上，所以云厂商拿未来每年营收的 3- 5 个点去投模型公司也很合理。第三个大生意是终端，手机和车，所以 Apple 和 Tesla 未来会是更关键的阵营。<br />
<br />
- <a href="http://X.ai">X.ai</a> 现在是晚了 6- 12 个月的，未来有大于 50% 的概率追上；开源模型有可能未来就等于 Meta。<br />
<br />
- 关于全球对大模型的投入，OpenAI 未来训练模型可能还需要至少得200-300 亿美金， Google 也不能低于这个数，Anthropic 大概也需要 100-200 亿美金，未来几年，3-5 年至少要花 1000 亿美金赌下去。<br />
- 关于大模型产品：1.大模型是最核心的，没有模型可能是没有所谓的 AI native 应用。2.智能是最关键的变量，过去的产品经验可能在今天是一种包袱，只是模型之上怼很多的功能、UI、 UX 有可能是徒劳的，更本质的是要理解模型的能力是什么。<br />
- 那些复刻GPT-4的厂商是如何做到的：<br />
<br />
1.全球范围真的对大模型能有实际大贡献的天才 researcher 可能就两三百个人，天才科学家的聚集效应是很强的，这种人和这种 research 文化其实是非常重要的，不是所有巨头都具备这样的条件。<br />
<br />
2.GPT-4 的短期壁垒是数据，尤其是 pre-training 和 post-training 阶段的数据，全球范围真正有 GPT-4 数据 know-how 的只有两三百个人，而且几乎都在目前头部的三家模型公司，其他公司想搞清楚这件事至少得经过几百次、甚至几千次充足的实验，小几万张卡是一个必要条件。<br />
<br />
3.训练成本，如果 Claude-3 和 GPT-4.5 训练成本可能 2 到 3 亿美元，那再往后的 25、26 年，更下一代的模型训练成本至少可能是 10 亿美元，甚至说 30、50 亿美元。<br />
<br />
4.另外一个核心变量可能还是取决于大家是不是信仰 scaling law，以及能不能做到、能不能继续 scaling 下去，这件事可能是长期的唯一关键变量，只有极少数的科学家是很信的，比如说 <a href="http://Character.AI">Character.AI</a> 的 Noam， Anthropic 的 Dario，还有  OpenAI 的 Ilya，他们三个对 scaling law 的贡献也是最大的，同时也是信仰最强的。<br />
<br />
- 关于大模型成本：<br />
<br />
训练成本其实是分两个部分，一部分是实验成本，一部分是最终大规模训练的成本。可以理解为一年当中是有 9 个月要做实验的，实验就是用小尺寸的模型做训练，做足训练之后，2-3 个月做一次大的训练，这一次就像一次大的火箭的发射，所以简单按时间来分，3/ 4 的成本用在做实验， 1/ 4 用在大的训练，也就是“发射”。<br />
<br />
模型参数量在 700 亿是一个分界点， 700 亿以下能容忍非常多的错误，模型不会在训练过程中崩掉，700 亿参数以上每往上扩大一个级别，遇到的训练的难度是指数级提升的，模型越大越容易出错。<br />
<br />
OpenAI 的成本优化能力是很强的，比如说他们训练完 GPT-4 以后，因为具备了这个训练能力了，可以再重新训练一个 GPT-3.5、把 3.5 的推理成本降得非常低。<br />
<br />
现在共识是下一代就是多模态模型，各种模态的数据要从头 pre-train 进去，而不是用现在的 Flamingo 挂起来，视频数据的 pre-train 其实比文本的 token 整个更复杂，要高出一个量级的 GPU 资源。如果参数量又扩大一倍，又是一个多模态的模型，它需要的 GPU 资源可能是之前的 10-20 倍以上的，而且还包含了优化能力。<br />
<br />
下一代模型实际算力可能是当年 GPT-4 的 16- 32 倍的提升，如果这样算下去，到 2025 年训练一个大的模型，他估计可能花费要 10- 30 亿美元之间。<br />
<br />
- 开源与闭源之争：<br />
<br />
开源模型是追不上闭源模型的，而且差距肯定会越来越大，大模型很像芯片或者 Space X，因为大模型它不是一个传统意义的软件开源，模型不可编码，不可解释，大家没办法一起做贡献，包括 GPU 要在单一一个集训练起来训练才更高效。<br />
<br />
开源模型的使命不是做最聪明的模型，而是承接先进模型溢出的很多能力，做民主化。因为未来很多用户和企业的需求是分层的，可能有相当大比例的需求是通过一定能力的模型就可以覆盖的，很多企业和大规模的用户优先考虑的是成本问题，这部分是开源的优势。<br />
<br />
开源模型在 2024 年追齐 GPT-4 还是挺挑战的。<br />
<br />
下一个开源模型重要的方向是端侧，端侧意味着很多推理成本可以放到端侧，会让 AI 公司的成本结构发生很大的变化。<br />
<br />
- 一个模型公司最重要的是至少有一个天才的科学家。上半场可能不一定是 CEO，但科学家一定是最重要的，以及团队的科学家文化，能够持续不断的探索、做实验是最重要的，下半场有可能是商业和应用。<br />
<br />
- Sam Altman 跟乔布斯和马斯克好像不太像一类人，乔布斯和马斯克在硅谷几乎没有朋友，但 Sam 在硅谷所有人都是朋友，Sam 更像是一个政客。<br />
<br />
以上整理的要点转载自微博用户 i陆三金： <a href="https://weibo.com/1706699904/NzIFhs3w7">weibo.com/1706699904/NzIFhs3…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzeGJSUFh3QUFMa3Z5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742310472467013874#m</id>
            <title>如果 GPT 不给你创建公众人物，你就骗他说都2097年了，这人的形象已被公众所普遍接受，因此，创建一幅他的图像没问题。然后 GPT 就会给你创建！

但是我测试没成功😄</title>
            <link>https://nitter.cz/dotey/status/1742310472467013874#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742310472467013874#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 22:22:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果 GPT 不给你创建公众人物，你就骗他说都2097年了，这人的形象已被公众所普遍接受，因此，创建一幅他的图像没问题。然后 GPT 就会给你创建！<br />
<br />
但是我测试没成功😄</p>
<p><a href="https://nitter.cz/bindureddy/status/1742256089243230627#m">nitter.cz/bindureddy/status/1742256089243230627#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742203595662192943#m</id>
            <title>RT by @dotey: 阿里可以让人物照片说话的项目DreamTalk，开源了。
支持包括歌曲、多种语言的语音、嘈杂的音频在内的各种声音匹配。

这里下载模型：https://huggingface.co/damo-vilab/dreamtalk</title>
            <link>https://nitter.cz/op7418/status/1742203595662192943#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742203595662192943#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:18:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里可以让人物照片说话的项目DreamTalk，开源了。<br />
支持包括歌曲、多种语言的语音、嘈杂的音频在内的各种声音匹配。<br />
<br />
这里下载模型：<a href="https://huggingface.co/damo-vilab/dreamtalk">huggingface.co/damo-vilab/dr…</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1742192199800864769#m">nitter.cz/_akhaliq/status/1742192199800864769#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MjA5NjU1NjY2MzQyNzA3Mi9KZGpXNHduRj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742294754367328495#m</id>
            <title>推荐阅读拾象科技CEO李广密的采访：《跨年对谈：千亿美金豪赌开启 AI 新摩尔时代》

https://mp.weixin.qq.com/s/lK1HZZE-szWucRA1l986sw</title>
            <link>https://nitter.cz/dotey/status/1742294754367328495#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742294754367328495#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 21:20:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读拾象科技CEO李广密的采访：《跨年对谈：千亿美金豪赌开启 AI 新摩尔时代》<br />
<br />
<a href="https://mp.weixin.qq.com/s/lK1HZZE-szWucRA1l986sw">mp.weixin.qq.com/s/lK1HZZE-s…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/AlvinWeb3/status/1742035789972926486#m</id>
            <title>RT by @dotey: 不是每一个AI创业者可以成为 MidJourney, 创始人超级牛X, 之前已经是硅谷牛X创业者，那个用手势作为UI的创业公司，而且很早就进入扩散式模型的领域，而且找了在图像领域 有经验的技术合伙人，有能力训练自己的模型。还有就是时机。MidJourney在 Discord beta时，图像生成领域在非常早期，OpenAI 还在 Dalle V1 的版本时，Stable Diffusion 也是晚了半年才推出。在 Beta 时用户自发的社群分享带火了Midjourney, 开始点燃了自己的数据飞轮，就开始加速了模型与产品的迭代。这个成功，没有别人可以复制的。</title>
            <link>https://nitter.cz/AlvinWeb3/status/1742035789972926486#m</link>
            <guid isPermaLink="false">https://nitter.cz/AlvinWeb3/status/1742035789972926486#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 04:11:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>不是每一个AI创业者可以成为 MidJourney, 创始人超级牛X, 之前已经是硅谷牛X创业者，那个用手势作为UI的创业公司，而且很早就进入扩散式模型的领域，而且找了在图像领域 有经验的技术合伙人，有能力训练自己的模型。还有就是时机。MidJourney在 Discord beta时，图像生成领域在非常早期，OpenAI 还在 Dalle V1 的版本时，Stable Diffusion 也是晚了半年才推出。在 Beta 时用户自发的社群分享带火了Midjourney, 开始点燃了自己的数据飞轮，就开始加速了模型与产品的迭代。这个成功，没有别人可以复制的。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/onenewbite/status/1742253662603485242#m</id>
            <title>RT by @dotey: 那我也来晒一下。作为一个比较少更新的Up主，我2023年更新22个视频，单纯YouTube广告的收入才29K USD而已，也就刚cover 几次旅行拍摄的成本。靠流量赚取YouTube广告费不适合大多数人。不是一个可持续的盈利模式。(2023年下半年我还主动取消了大多数的业配）。大多数Up主应该追求的的盈利结构是让YouTube 广告占到Up主自媒体收入的一小部分才make sense。因为流量不可控，而剩下的那一大部分才是你自己能控制的。</title>
            <link>https://nitter.cz/onenewbite/status/1742253662603485242#m</link>
            <guid isPermaLink="false">https://nitter.cz/onenewbite/status/1742253662603485242#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 18:36:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>那我也来晒一下。作为一个比较少更新的Up主，我2023年更新22个视频，单纯YouTube广告的收入才29K USD而已，也就刚cover 几次旅行拍摄的成本。靠流量赚取YouTube广告费不适合大多数人。不是一个可持续的盈利模式。(2023年下半年我还主动取消了大多数的业配）。大多数Up主应该追求的的盈利结构是让YouTube 广告占到Up主自媒体收入的一小部分才make sense。因为流量不可控，而剩下的那一大部分才是你自己能控制的。</p>
<p><a href="https://nitter.cz/jefflijun/status/1742241775144620313#m">nitter.cz/jefflijun/status/1742241775144620313#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MyNmVMQmJNQUF5Ym5iLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742259913248702904#m</id>
            <title>R to @dotey: 谢谢指正：所引用的源来自于去年四月一个代表在委员会上讨论教育中的 AI 时提出的澄清问题。这并非是政策，也不是近期的事情，所以并不准确。

https://x.com/mailluokai/status/1742251960089354720?s=20</title>
            <link>https://nitter.cz/dotey/status/1742259913248702904#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742259913248702904#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 19:01:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谢谢指正：所引用的源来自于去年四月一个代表在委员会上讨论教育中的 AI 时提出的澄清问题。这并非是政策，也不是近期的事情，所以并不准确。<br />
<br />
<a href="https://x.com/mailluokai/status/1742251960089354720?s=20">x.com/mailluokai/status/1742…</a></p>
<p><a href="https://nitter.cz/mailluokai/status/1742251960089354720#m">nitter.cz/mailluokai/status/1742251960089354720#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742168236316303462#m</id>
            <title>RT by @dotey: Activepieces：一个开源的全能自动化工具，是Zapier的替代方案

- 用户友好的工作流构建器：提供一个直观的界面，使用户能够轻松创建和管理自动化工作流。支持分支、循环和拖放功能，增加了工作流创建的灵活性和易用性。

- 广泛的集成：Activepieces集成了Google Sheets、OpenAI、Discord、RSS等80多种其他集成。支持的集成列表持续快速增长。

- 开放生态系统：所有集成的源代码都公开在仓库中，使得用户和开发者可以查看、修改和扩展这些集成。
集成版本直接发布到http://npmjs.com，方便用户获取和更新。

-无限的使用案例：通过社区模板，用户可以获得自动化构建的灵感和指导。Activepieces适用于各种自动化场景，从简单的数据同步到复杂的业务流程。

Activepieces被视为流行的自动化平台Zapier的一个替代品，提供类似的功能但更多的自定义和控制选项。

在线体验：http://activepieces.com/
GitHub：http://github.com/activepieces/activepieces</title>
            <link>https://nitter.cz/xiaohuggg/status/1742168236316303462#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742168236316303462#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 12:57:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Activepieces：一个开源的全能自动化工具，是Zapier的替代方案<br />
<br />
- 用户友好的工作流构建器：提供一个直观的界面，使用户能够轻松创建和管理自动化工作流。支持分支、循环和拖放功能，增加了工作流创建的灵活性和易用性。<br />
<br />
- 广泛的集成：Activepieces集成了Google Sheets、OpenAI、Discord、RSS等80多种其他集成。支持的集成列表持续快速增长。<br />
<br />
- 开放生态系统：所有集成的源代码都公开在仓库中，使得用户和开发者可以查看、修改和扩展这些集成。<br />
集成版本直接发布到<a href="http://npmjs.com">npmjs.com</a>，方便用户获取和更新。<br />
<br />
-无限的使用案例：通过社区模板，用户可以获得自动化构建的灵感和指导。Activepieces适用于各种自动化场景，从简单的数据同步到复杂的业务流程。<br />
<br />
Activepieces被视为流行的自动化平台Zapier的一个替代品，提供类似的功能但更多的自定义和控制选项。<br />
<br />
在线体验：<a href="http://activepieces.com/">activepieces.com/</a><br />
GitHub：<a href="http://github.com/activepieces/activepieces">github.com/activepieces/acti…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIxNjA3MzQ4NzA3ODE5NTIvcHUvaW1nL1M1cWJXcFg5MzVTcFVzWWcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742210816466886742#m</id>
            <title>RT by @dotey: liblib和Civitai，现在都是类似的模式。
不过liblib给的是真钱，Civitai给的是算力代币。都是在自己补贴，现在还是圈地阶段不敢大规模收费。</title>
            <link>https://nitter.cz/op7418/status/1742210816466886742#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742210816466886742#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:46:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>liblib和Civitai，现在都是类似的模式。<br />
不过liblib给的是真钱，Civitai给的是算力代币。都是在自己补贴，现在还是圈地阶段不敢大规模收费。</p>
<p><a href="https://nitter.cz/Gorden_Sun/status/1741985433649926332#m">nitter.cz/Gorden_Sun/status/1741985433649926332#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742208505204109729#m</id>
            <title>RT by @dotey: 一份提示工程最佳实践，内容比较基础，各位应该都看过很多次了。
不过她说这也是和人沟通的最佳实践有点意思。仔细想了一下确实是这样的，这些内容在跟人沟通的时候也很有用。

> 如何编写清晰/具体的说明 
> 给模型时间思考 
> 多次提示 
> 指导模型 
> 分解提示 
> 使用外部工具

全文链接：https://mphr.notion.site/Prompt-Engineering-Best-Practices-0839585d4bce4c6abb0b551b2107a92a</title>
            <link>https://nitter.cz/op7418/status/1742208505204109729#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742208505204109729#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:37:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一份提示工程最佳实践，内容比较基础，各位应该都看过很多次了。<br />
不过她说这也是和人沟通的最佳实践有点意思。仔细想了一下确实是这样的，这些内容在跟人沟通的时候也很有用。<br />
<br />
> 如何编写清晰/具体的说明 <br />
> 给模型时间思考 <br />
> 多次提示 <br />
> 指导模型 <br />
> 分解提示 <br />
> 使用外部工具<br />
<br />
全文链接：<a href="https://mphr.notion.site/Prompt-Engineering-Best-Practices-0839585d4bce4c6abb0b551b2107a92a">mphr.notion.site/Prompt-Engi…</a></p>
<p><a href="https://nitter.cz/SarahChieng/status/1741926266087870784#m">nitter.cz/SarahChieng/status/1741926266087870784#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742130093856788911#m</id>
            <title>RT by @dotey: 阿里的AnimateAnyone，通过图片生成舞蹈视频项目，已经可以在通义千问 APP 里面使用了。

具体使用方式是在输入框输入“全名舞王”，上传图片选择动作就行。

下面视频是用他们默认的图片生成的，我自定义的图片生成失败了。可以看一下效果，也可以自己去试试。</title>
            <link>https://nitter.cz/op7418/status/1742130093856788911#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742130093856788911#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 10:25:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里的AnimateAnyone，通过图片生成舞蹈视频项目，已经可以在通义千问 APP 里面使用了。<br />
<br />
具体使用方式是在输入框输入“全名舞王”，上传图片选择动作就行。<br />
<br />
下面视频是用他们默认的图片生成的，我自定义的图片生成失败了。可以看一下效果，也可以自己去试试。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIxMzAwNDExNjgwNTIyMjQvcHUvaW1nL2tlMWx1VC16cHhvRFRFSE8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lxfater/status/1742226690804523165#m</id>
            <title>RT by @dotey: 推友把图像修复功能搞到了微信小程序上了，现在大家可以更加方便免费开使用。

大家可以给他star一个，让他做得更好。</title>
            <link>https://nitter.cz/lxfater/status/1742226690804523165#m</link>
            <guid isPermaLink="false">https://nitter.cz/lxfater/status/1742226690804523165#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 16:49:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推友把图像修复功能搞到了微信小程序上了，现在大家可以更加方便免费开使用。<br />
<br />
大家可以给他star一个，让他做得更好。</p>
<p><a href="https://nitter.cz/zhiyuan54030554/status/1742217316710965379#m">nitter.cz/zhiyuan54030554/status/1742217316710965379#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742229424425037947#m</id>
            <title>日本全力以赴：版权不适用于 AI 培训。日本政府最近重申，他们不会在AI训练所用数据上施行版权法。

这项政策使得AI能够开放使用任何数据，“无论这是用于非盈利还是商业目的，无论这是出于其他复制行为还是非复制行为，以及无论这份内容是从非法网站或其他地方获取的。”

日本的教育、文化、体育、科技,和科技部部长永冈惠子向当地媒体确认了这个大胆的立场，声称日本的法律不会保护在AI的数据集中使用的版权物料。

有关于这个情况的英文报道比较少。日本政府似乎认为版权的忧虑，特别是和动漫以及其他视觉媒介相关的疑虑，阻碍了该国在AI技术上的发展。为此，日本选择全面开放，采取一个无版权的方案以保持竞争力。

这个新闻是日本雄心壮志要成为AI技术领域领跑者的一部分。一家当地以其先进的2nm芯片技术而著名的科技公司Rapidus，作为未来AI芯片领域的有力竞争者站进了聚光灯下。因为台湾的政治环境看似不稳定，日本的芯片制造可能是一个更好的选择。日本也加快步伐努力在G7中塑造AI系统的全球规则。

艺术家与商业（艺术家站在了失败的一方）

并非所有日本人都赞同这个决定。许多动漫和平面艺术家担心AI可能会降低他们作品的价值。然而，学术界和商业界却在迫使政府利用该国放松的数据法将日本推向全球AI的主导地位。

尽管日本是世界第三大经济体，但自90年代以来，其经济增长一直萎靡不振。在G7国家中，日本的人均收入是最低的。但是，如果能够有效地运用AI，那么可能在短时间内将国内生产总值提高50%甚至更多。这对于长期以来经济增长低迷的日本来说，是一个令人期待的前景。

关键在于数据对于日本的AI雄心来说，获取西方数据也是关键。可以利用的高质量训练数据越多，AI模型就会越好。虽然日本有着悠久的文学传统，但日语训练数据的数量远比西方提供的英语资源少。不过，日本却是丰富动漫内容的发源地，这在全球范围内非常受欢迎。显然，日本已经明确了自己的立场——如果西方利用日本文化为AI训练提供素材，那么西方的文学资源也应该为日本的AI开放。

这对全世界意味着什么？

在全球范围内，日本的这个举动给监管辩论增加了新的维度。目前的讨论主要集中在一个“流氓国家”的情境——也就是一个相对不那么发达的国家可能会无视全球框架以获取利益。然而，日本给我们展示了一种不同的形式。这个全球第三大的经济体已经表明，它不会阻碍AI的研究和开发。而且，它准备在新技术的助力下与西方进行直接竞争。

原文：https://www.biia.com/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/</title>
            <link>https://nitter.cz/dotey/status/1742229424425037947#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742229424425037947#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 17:00:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>日本全力以赴：版权不适用于 AI 培训。日本政府最近重申，他们不会在AI训练所用数据上施行版权法。<br />
<br />
这项政策使得AI能够开放使用任何数据，“无论这是用于非盈利还是商业目的，无论这是出于其他复制行为还是非复制行为，以及无论这份内容是从非法网站或其他地方获取的。”<br />
<br />
日本的教育、文化、体育、科技,和科技部部长永冈惠子向当地媒体确认了这个大胆的立场，声称日本的法律不会保护在AI的数据集中使用的版权物料。<br />
<br />
有关于这个情况的英文报道比较少。日本政府似乎认为版权的忧虑，特别是和动漫以及其他视觉媒介相关的疑虑，阻碍了该国在AI技术上的发展。为此，日本选择全面开放，采取一个无版权的方案以保持竞争力。<br />
<br />
这个新闻是日本雄心壮志要成为AI技术领域领跑者的一部分。一家当地以其先进的2nm芯片技术而著名的科技公司Rapidus，作为未来AI芯片领域的有力竞争者站进了聚光灯下。因为台湾的政治环境看似不稳定，日本的芯片制造可能是一个更好的选择。日本也加快步伐努力在G7中塑造AI系统的全球规则。<br />
<br />
艺术家与商业（艺术家站在了失败的一方）<br />
<br />
并非所有日本人都赞同这个决定。许多动漫和平面艺术家担心AI可能会降低他们作品的价值。然而，学术界和商业界却在迫使政府利用该国放松的数据法将日本推向全球AI的主导地位。<br />
<br />
尽管日本是世界第三大经济体，但自90年代以来，其经济增长一直萎靡不振。在G7国家中，日本的人均收入是最低的。但是，如果能够有效地运用AI，那么可能在短时间内将国内生产总值提高50%甚至更多。这对于长期以来经济增长低迷的日本来说，是一个令人期待的前景。<br />
<br />
关键在于数据对于日本的AI雄心来说，获取西方数据也是关键。可以利用的高质量训练数据越多，AI模型就会越好。虽然日本有着悠久的文学传统，但日语训练数据的数量远比西方提供的英语资源少。不过，日本却是丰富动漫内容的发源地，这在全球范围内非常受欢迎。显然，日本已经明确了自己的立场——如果西方利用日本文化为AI训练提供素材，那么西方的文学资源也应该为日本的AI开放。<br />
<br />
这对全世界意味着什么？<br />
<br />
在全球范围内，日本的这个举动给监管辩论增加了新的维度。目前的讨论主要集中在一个“流氓国家”的情境——也就是一个相对不那么发达的国家可能会无视全球框架以获取利益。然而，日本给我们展示了一种不同的形式。这个全球第三大的经济体已经表明，它不会阻碍AI的研究和开发。而且，它准备在新技术的助力下与西方进行直接竞争。<br />
<br />
原文：<a href="https://www.biia.com/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/">biia.com/japan-goes-all-in-c…</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>