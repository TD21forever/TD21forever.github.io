<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737492846041530578#m</id>
            <title>RT by @dotey: 刚看到苹果发的这个论文《使用有限的内存实现更快的 LLM 推理》。通过将将模型参数保存在闪存里，根据需要移动到DRAM。

使得能够运行的模型大小是可用DRAM的两倍，与传统的CPU和GPU加载方法相比，推理速度分别提高了4-5倍和20-25倍。</title>
            <link>https://nitter.cz/op7418/status/1737492846041530578#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737492846041530578#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 15:19:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚看到苹果发的这个论文《使用有限的内存实现更快的 LLM 推理》。通过将将模型参数保存在闪存里，根据需要移动到DRAM。<br />
<br />
使得能够运行的模型大小是可用DRAM的两倍，与传统的CPU和GPU加载方法相比，推理速度分别提高了4-5倍和20-25倍。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1737300118070534468#m">nitter.cz/_akhaliq/status/1737300118070534468#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737460981331288421#m</id>
            <title>RT by @dotey: XHS-Downloader：小红书采集器 

✅ 采集小红书图文/视频作品信息
✅ 提取小红书图文/视频作品下载地址
✅ 下载小红书无水印图文/视频作品文件
✅ 自动跳过已下载的作品文件
✅ 作品文件完整性处理机制
✅ 持久化储存作品信息至文件

GitHub：https://github.com/JoeanAmier/XHS-Downloader</title>
            <link>https://nitter.cz/xiaohuggg/status/1737460981331288421#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737460981331288421#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 13:12:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>XHS-Downloader：小红书采集器 <br />
<br />
✅ 采集小红书图文/视频作品信息<br />
✅ 提取小红书图文/视频作品下载地址<br />
✅ 下载小红书无水印图文/视频作品文件<br />
✅ 自动跳过已下载的作品文件<br />
✅ 作品文件完整性处理机制<br />
✅ 持久化储存作品信息至文件<br />
<br />
GitHub：<a href="https://github.com/JoeanAmier/XHS-Downloader">github.com/JoeanAmier/XHS-Do…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J5elhIR2JVQUFjb2hQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737518777481535521#m</id>
            <title>RT by @dotey: ChatGPT聊天记录可以归档了，再也不用看着一堆没用碍眼的聊天记录了。

点击想归档的聊天记录右侧三个点，选择Archive Chat就可以了，已经归档的内容可以在设置中查看。</title>
            <link>https://nitter.cz/op7418/status/1737518777481535521#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737518777481535521#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 17:02:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT聊天记录可以归档了，再也不用看着一堆没用碍眼的聊天记录了。<br />
<br />
点击想归档的聊天记录右侧三个点，选择Archive Chat就可以了，已经归档的内容可以在设置中查看。</p>
<p><a href="https://nitter.cz/OpenAI/status/1737517702766633063#m">nitter.cz/OpenAI/status/1737517702766633063#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc1MTgzMzk3OTc0NTQ4NDgvcHUvaW1nL2Rjakt4NG80WnBUTzE1TlUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Barret_China/status/1737459317102747701#m</id>
            <title>RT by @dotey: 强烈推荐这本在线免费的电子书，《动手学深度学习》，https://zh.d2l.ai，上线一年多时间，已经更新到了第二版，光看作者阵容就已经十分强大了，这本书也被上百所名校列为教材或参考书，当前也出版了实体书。

本书的每个章节都是可以直接运行的 Jupyter 记事本，你可以在本地直接跑，也可以克隆到 Google Colab 在云端跑；讲解的时候，不仅结合文字、公式和图示来阐明深度学习里常用的模型和算法，还提供代码来演示如何从零开始实现它们，并使用真实数据来提供一个交互式的学习体验。

第二版的内容是 2023 年更新的，手把手教你搭建 Bert/Transformer，各种语言框架都有，包括 Pytorch/Tensorflow/JAX 等，而且还支持中英文对照，英文域名是 https://d2l.ai，它对于初学者和有经验的深度学习从业者都是一份宝贵的资源。</title>
            <link>https://nitter.cz/Barret_China/status/1737459317102747701#m</link>
            <guid isPermaLink="false">https://nitter.cz/Barret_China/status/1737459317102747701#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 13:05:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>强烈推荐这本在线免费的电子书，《动手学深度学习》，<a href="https://zh.d2l.ai">zh.d2l.ai</a>，上线一年多时间，已经更新到了第二版，光看作者阵容就已经十分强大了，这本书也被上百所名校列为教材或参考书，当前也出版了实体书。<br />
<br />
本书的每个章节都是可以直接运行的 Jupyter 记事本，你可以在本地直接跑，也可以克隆到 Google Colab 在云端跑；讲解的时候，不仅结合文字、公式和图示来阐明深度学习里常用的模型和算法，还提供代码来演示如何从零开始实现它们，并使用真实数据来提供一个交互式的学习体验。<br />
<br />
第二版的内容是 2023 年更新的，手把手教你搭建 Bert/Transformer，各种语言框架都有，包括 Pytorch/Tensorflow/JAX 等，而且还支持中英文对照，英文域名是 <a href="https://d2l.ai">d2l.ai</a>，它对于初学者和有经验的深度学习从业者都是一份宝贵的资源。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J5cnZOZ2F3QUFIblJwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737518177322475655#m</id>
            <title>推荐阅读：《深入了解大语言模型运维 (LLMOps) [译]》

这篇文章 5 月份的，但并没有过时，对于大语言模型的运维(LLMOps)讲的非常系统。

随着大语言模型的普及，未来的 Ops 肯定离不开 LLMOps ，甚至于需要专门的团队做 LLMOps。

文章中把 LLMOps 分成了几个关键步骤：

第 1 步：选择基础模型
是商业模型还是开源模型，亦或是混合使用

第 2 步：适应下游任务
LLM 的生成结果不像传统的服务，它的结果是不确定的，怎么让 LLM 生成你期望的结果？要不要微调？要不要使用 RAG？

第 3 步：评估
如何评估性能？由于 LLM 生成结果的不确定性，每次微调或者调整 Prompt 后，性能的变化需要可以量化的评估。

这部分可以配合《用 RAGAs（检索增强生成评估）评估 RAG（检索增强型生成）应用 [译]》 https://baoyu.io/translations/rag/evaluating-rag-applications-with-ragas 这篇一起看

第 4 步：部署和监控
和传统运维一样，对于 LLM 的线上的部署和监控也是必不可少的，但是又不太一样，外部 API 需要监控 API 可用性，故障了还要考虑能切换到其他 API。

以上就是主要的几个步骤，可以帮助你系统的了解 LLMOps，但是文章都没有深入展开，最好是配合 OpenAI 官方的 《OpenAI 生产环境最佳实践官方指南 [译]》https://baoyu.io/translations/openai/guides-production-best-practices 一起阅读。

LLMOps 还是个很新也是个很有前途的领域，我个人对这方面也不专业，如果你有相关经验欢迎分享，或者有好的文章视频也欢迎推荐。

原文：https://wandb.ai/site/articles/understanding-llmops-large-language-model-operations#Why%20the%20Rise%20of%20LLMOps
翻译：https://baoyu.io/translations/llm/understanding-llmops-large-language-model-operations</title>
            <link>https://nitter.cz/dotey/status/1737518177322475655#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737518177322475655#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 16:59:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《深入了解大语言模型运维 (LLMOps) [译]》<br />
<br />
这篇文章 5 月份的，但并没有过时，对于大语言模型的运维(LLMOps)讲的非常系统。<br />
<br />
随着大语言模型的普及，未来的 Ops 肯定离不开 LLMOps ，甚至于需要专门的团队做 LLMOps。<br />
<br />
文章中把 LLMOps 分成了几个关键步骤：<br />
<br />
第 1 步：选择基础模型<br />
是商业模型还是开源模型，亦或是混合使用<br />
<br />
第 2 步：适应下游任务<br />
LLM 的生成结果不像传统的服务，它的结果是不确定的，怎么让 LLM 生成你期望的结果？要不要微调？要不要使用 RAG？<br />
<br />
第 3 步：评估<br />
如何评估性能？由于 LLM 生成结果的不确定性，每次微调或者调整 Prompt 后，性能的变化需要可以量化的评估。<br />
<br />
这部分可以配合《用 RAGAs（检索增强生成评估）评估 RAG（检索增强型生成）应用 [译]》 <a href="https://baoyu.io/translations/rag/evaluating-rag-applications-with-ragas">baoyu.io/translations/rag/ev…</a> 这篇一起看<br />
<br />
第 4 步：部署和监控<br />
和传统运维一样，对于 LLM 的线上的部署和监控也是必不可少的，但是又不太一样，外部 API 需要监控 API 可用性，故障了还要考虑能切换到其他 API。<br />
<br />
以上就是主要的几个步骤，可以帮助你系统的了解 LLMOps，但是文章都没有深入展开，最好是配合 OpenAI 官方的 《OpenAI 生产环境最佳实践官方指南 [译]》<a href="https://baoyu.io/translations/openai/guides-production-best-practices">baoyu.io/translations/openai…</a> 一起阅读。<br />
<br />
LLMOps 还是个很新也是个很有前途的领域，我个人对这方面也不专业，如果你有相关经验欢迎分享，或者有好的文章视频也欢迎推荐。<br />
<br />
原文：<a href="https://wandb.ai/site/articles/understanding-llmops-large-language-model-operations#Why%20the%20Rise%20of%20LLMOps">wandb.ai/site/articles/under…</a><br />
翻译：<a href="https://baoyu.io/translations/llm/understanding-llmops-large-language-model-operations">baoyu.io/translations/llm/un…</a></p>
<p><a href="https://nitter.cz/dotey/status/1736476171385069941#m">nitter.cz/dotey/status/1736476171385069941#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J6ai1RdVdVQUExeDAyLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737512582057992391#m</id>
            <title>R to @dotey: PopAi 官网链接：https://bit.ly/3Ty8G2Z （官方抽3个注册用户送3个月的会员）
使用折扣码可以有 20% 优惠：BAOYU</title>
            <link>https://nitter.cz/dotey/status/1737512582057992391#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737512582057992391#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 16:37:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>PopAi 官网链接：<a href="https://bit.ly/3Ty8G2Z">bit.ly/3Ty8G2Z</a> （官方抽3个注册用户送3个月的会员）<br />
使用折扣码可以有 20% 优惠：BAOYU</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737512580690649455#m</id>
            <title>R to @dotey: 我拿我的翻译 Prompt （PopAi 中已经内置成了模板，并且支持多种语言翻译）实际测试后效果挺不错，这个产品免费的每天有条数限制，但 Unlimited 档的话可以无限使用 GPT-4，不用担心受 ChatGPT Plus 3 小时 40 条的限制了。</title>
            <link>https://nitter.cz/dotey/status/1737512580690649455#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737512580690649455#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 16:37:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我拿我的翻译 Prompt （PopAi 中已经内置成了模板，并且支持多种语言翻译）实际测试后效果挺不错，这个产品免费的每天有条数限制，但 Unlimited 档的话可以无限使用 GPT-4，不用担心受 ChatGPT Plus 3 小时 40 条的限制了。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737512577641390311#m</id>
            <title>之前我发翻译的 Prompt 的或者 GPTs 时候，很多同学无法注册 ChatGPT Plus 或无法获取到 GPT-4 的 API，没机会用上，所以这里推荐一个 ChatGPT 的替代产品 PopAi @popaiinone，内置有 GPT-4V 多模态模型，所以不仅是能用上高质量的翻译能力，还能支持图像识别，PDF 文档对话等能力。</title>
            <link>https://nitter.cz/dotey/status/1737512577641390311#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737512577641390311#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 16:37:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前我发翻译的 Prompt 的或者 GPTs 时候，很多同学无法注册 ChatGPT Plus 或无法获取到 GPT-4 的 API，没机会用上，所以这里推荐一个 ChatGPT 的替代产品 PopAi <a href="https://nitter.cz/popaiinone" title="PopAi">@popaiinone</a>，内置有 GPT-4V 多模态模型，所以不仅是能用上高质量的翻译能力，还能支持图像识别，PDF 文档对话等能力。</p>
<p><a href="https://nitter.cz/dotey/status/1707478347553395105#m">nitter.cz/dotey/status/1707478347553395105#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J6aVFBLVdvQjhENXR4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J6aVFBLVc4QUFreU1DLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J6aVFBX1dvQUFvdVlxLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J6aVRieVdvQVlob1RLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mtrainier2020/status/1737398651830276156#m</id>
            <title>RT by @dotey: 我初步读了一下论文，这篇论文的基本思路其实是利用了推理过程中的局部性。现在现在推理性能的一个瓶颈就是GPU的内存。它们的思路就是联合CPU和GPU做联合推理。尽可能把active的neuron 信息load到GPU中，充分利用局部性。这样大大提高了GPU推理的效率。
你不能拿单独的CPU推理或者单独的GPU推理来比。两者的指导思想都不一样。
这样的效果非常牛逼。

在推理速度上，在 4090 上是未经优化的llama.cpp 11 倍。相当于用一块4090（2000刀左右）在推理上取得了比a100 （2万刀左右）仅仅慢18%的成绩。

这个结果，更大的意义就是证明，充分考虑并利用推理的局部性有极大的潜力，CPU+GPU 联合推理有很强的优越性。
类似的，那么在训练当面是不是也可以采用这种思路呢？</title>
            <link>https://nitter.cz/mtrainier2020/status/1737398651830276156#m</link>
            <guid isPermaLink="false">https://nitter.cz/mtrainier2020/status/1737398651830276156#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 09:04:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我初步读了一下论文，这篇论文的基本思路其实是利用了推理过程中的局部性。现在现在推理性能的一个瓶颈就是GPU的内存。它们的思路就是联合CPU和GPU做联合推理。尽可能把active的neuron 信息load到GPU中，充分利用局部性。这样大大提高了GPU推理的效率。<br />
你不能拿单独的CPU推理或者单独的GPU推理来比。两者的指导思想都不一样。<br />
这样的效果非常牛逼。<br />
<br />
在推理速度上，在 4090 上是未经优化的llama.cpp 11 倍。相当于用一块4090（2000刀左右）在推理上取得了比a100 （2万刀左右）仅仅慢18%的成绩。<br />
<br />
这个结果，更大的意义就是证明，充分考虑并利用推理的局部性有极大的潜力，CPU+GPU 联合推理有很强的优越性。<br />
类似的，那么在训练当面是不是也可以采用这种思路呢？</p>
<p><a href="https://nitter.cz/engineer_bob_sz/status/1737297706736144476#m">nitter.cz/engineer_bob_sz/status/1737297706736144476#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4NjNKeVdJQUFDZlp5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4NjNKdlc0QUFGblJfLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4NjNKeFdrQUFNMEM5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737408280090280396#m</id>
            <title>RT by @dotey: 前几天发布的大幅提高视频生成流畅性的项目FreeInit，已经可以用了。

试了一下，真的离谱，Animatediff 的稳定性确实得到了大幅提高，但是同时变化幅度也有一定下降，不过这个是值得的。

下面是对比视频，可以用camenduru做的这个 Colab 链接部署测试：https://colab.research.google.com/github/camenduru/FreeInit-colab/blob/main/FreeInit_gradio_colab.ipynb</title>
            <link>https://nitter.cz/op7418/status/1737408280090280396#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737408280090280396#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 09:43:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天发布的大幅提高视频生成流畅性的项目FreeInit，已经可以用了。<br />
<br />
试了一下，真的离谱，Animatediff 的稳定性确实得到了大幅提高，但是同时变化幅度也有一定下降，不过这个是值得的。<br />
<br />
下面是对比视频，可以用camenduru做的这个 Colab 链接部署测试：<a href="https://colab.research.google.com/github/camenduru/FreeInit-colab/blob/main/FreeInit_gradio_colab.ipynb">colab.research.google.com/gi…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc0MDgwNjY4MzA5NzkwNzIvcHUvaW1nL19IdndIQ2FpQUJ0VGQwN1kuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737389024300429498#m</id>
            <title>🤣 React Server Component 没那么夸张吧
RSC 虐我千百遍，我待 RSC 如初恋！</title>
            <link>https://nitter.cz/dotey/status/1737389024300429498#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737389024300429498#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 08:26:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🤣 React Server Component 没那么夸张吧<br />
RSC 虐我千百遍，我待 RSC 如初恋！</p>
<p><a href="https://nitter.cz/sebastienlorber/status/1737380479383277636#m">nitter.cz/sebastienlorber/status/1737380479383277636#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737388243006480895#m</id>
            <title>推荐阅读：《2023 in Review: Recapping the Post-ChatGPT Era and What to Expect for 2024 | 2023 年回顾：聚焦 ChatGPT 时代之后的发展及 2024 年展望 [译]》

原文：https://towardsdatascience.com/2023-in-review-recapping-the-post-chatgpt-era-and-what-to-expect-for-2024-bb4357a4e827
译文：https://baoyu.io/translations/ai/2023-in-review-recapping-the-post-chatgpt-era-and-what-to-expect-for-2024</title>
            <link>https://nitter.cz/dotey/status/1737388243006480895#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737388243006480895#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 08:23:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《2023 in Review: Recapping the Post-ChatGPT Era and What to Expect for 2024 | 2023 年回顾：聚焦 ChatGPT 时代之后的发展及 2024 年展望 [译]》<br />
<br />
原文：<a href="https://towardsdatascience.com/2023-in-review-recapping-the-post-chatgpt-era-and-what-to-expect-for-2024-bb4357a4e827">towardsdatascience.com/2023-…</a><br />
译文：<a href="https://baoyu.io/translations/ai/2023-in-review-recapping-the-post-chatgpt-era-and-what-to-expect-for-2024">baoyu.io/translations/ai/202…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4eFpXdlhnQUE3SHhULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737372064187642211#m</id>
            <title>R to @dotey: iframe定时刷新的副作用就是如果打开音箱，能听到吧嗒吧嗒的刷新网页的声音……</title>
            <link>https://nitter.cz/dotey/status/1737372064187642211#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737372064187642211#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 07:19:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>iframe定时刷新的副作用就是如果打开音箱，能听到吧嗒吧嗒的刷新网页的声音……</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737371423142736066#m</id>
            <title>写过用iframe定时刷新更新消息的聊天室，那会连xmlhttp都没有</title>
            <link>https://nitter.cz/dotey/status/1737371423142736066#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737371423142736066#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 07:16:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>写过用iframe定时刷新更新消息的聊天室，那会连xmlhttp都没有</p>
<p><a href="https://nitter.cz/noworkforsixian/status/1737122354013360488#m">nitter.cz/noworkforsixian/status/1737122354013360488#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737365753198772373#m</id>
            <title>纽约客的文章：《The Year A.I. Ate the Internet | AI 改变互联网的一年 [译]》

2023 年，许多人开始学习如何与机器人沟通、创造、作弊，并进行合作。

就在一年多前，OpenAI 发布了 ChatGPT，这是一个让用户能够以极为人性化的方式与计算机对话的应用。发布仅五天，它就吸引了一百万用户；两个月后，月活跃用户数飙升至一亿，目前这一数字几乎翻了一番。可以说，2023 年是许多人开始用全新的方式与人工智能进行沟通、创造、作弊和合作的一年。

继 ChatGPT 之后，谷歌发布了其聊天机器人 Bard；微软将 OpenAI 的模型融入了它的必应搜索引擎；Meta 推出了 LLaMA；Anthropic 则带来了 Claude，一款可以应对各种规模任务的“下一代 AI 助手”。这一切让互联网仿佛注入了生命。尽管人工智能并非新鲜事物——我们的生活已经离不开它，无论是 Netflix 的推荐算法、信用卡公司侦测欺诈活动，还是亚马逊的 Alexa 播报早间新闻，人工智能无处不在，却鲜为人注意。

但是，尽管有些人工智能 (A.I.) 在幕后以一种脚本化且脆弱的方式工作，聊天机器人 (chatbot) 却展现出了反应灵敏和即兴创造的能力。它们的行为也充满不可预测性。当我们向它们寻求帮助，用我们所不了解的事物来提问或请求它们提供创意支持时，它们往往能创造出前所未有的东西，仿佛凭空而来。诗歌、文学评论、论文、研究报告、三幕剧本，这些作品都以清晰、纯正的人类语言呈现，宛如机器中的神被赋予了我们的形象。比如，如果你让 ChatGPT 用 Johnny Cash 的风格创作一首关于自动驾驶汽车的歌曲，你可能会得到这样的歌词：

Ridin’solo, but I’m never alone,（独自行驶，但从不孤单，）

Got my AI ridin’shotgun, steady as a stone.（我的 AI 同伴如岩石般稳固，）

On the endless road, under the sky so vast,（在无尽的路途下，天空广袤无垠，）

A ghost driver at the wheel, footprints of the past.（无形的驾驶者操控着，过去的足迹历历在目。）

而如果要求以 Giuseppe Verdi 的风格创作，ChatGPT 则构建了这样一个男高音歌唱的场景：

Ecco la carrozza senza cavallo! （看！无马的马车！）

Scivola nella notte, silenziosa come il fato. （它在夜晚悄无声息地滑行，宛如命运的寂静。）

L’ingegno dell’uomo, l’orgoglio del progresso, （人的智慧，进步的荣耀，）

In questa danza d’acciaio, tessiamo il nostro destino. （在这钢铁之舞中，我们编织着各自的命运。）

虽然至今尚未赢得多项奖项，但像 ChatGPT 这样的聊天机器人令我们的智能设备相形见绌。他们不仅精通各种语言，还精通编程语言；他们可以快速概括冗长的法律和财务文档；开始从事医疗疾病的诊断工作；甚至无需学习就能通过律师资格考试。不过，我们可能会误以为 AI 模型是真正的智慧，而不只是人工合成的——智能，还会误以为他们理解他们传递的内容的含义和后果。但实际上，他们不是。用语言学家 Emily Bender 和其三位合作者的话来说，他们更像是“概率性的复读机”。在 AI 被视为拥有智慧之前，人们不应忘记，AI 所拥有的一切都源于大量的人类知识。我们学会了如何与机器人协同工作，但在这之前，机器人必须首先被教会如何与我们协同工作。

要开始理解这些聊天机器人的工作原理，我们必须掌握新的词汇，从“大语言模型”(L.L.M.s)、"神经网络" 到“自然语言处理”(N.L.P.) 和“生成式 AI”。目前我们大致了解了基本情况：这些聊天机器人汲取了互联网上的内容，并通过一种模仿人脑的机器学习技术进行分析；它们根据统计学原理串联起词语，依据哪些词汇和短语通常会组合在一起。然而，人工智能的极致创新性仍然难以完全理解，正如我们在聊天机器人出现“幻觉”时所发现的那样。

以 Google 的 Bard 为例，它曾错误地创造了关于 James Webb 望远镜的信息。同样，Microsoft 的 Bing 误称歌手 Billie Eilish 在 2023 年超级碗中场秀中表演过。一位律师表示：“我之前没想到 ChatGPT 会编造案例”，他提交给联邦法院的简报中充满了 ChatGPT 提供的虚假引用和捏造的司法意见（因此被法院罚款五千美元）。ChatGPT 在细则中承认其可能不可靠：“ChatGPT 可能会犯错误。请考虑核实重要信息。”奇怪的是，最近的一项研究显示，在过去一年中，ChatGPT 在执行某些任务时的准确性反而下降了。研究人员推测这可能与其训练材料有关，但由于 OpenAI 未公开其用于训练大语言模型 (Large Language Model, L.L.M.) 的具体内容，这仅是推测。

尽管清楚知道聊天机器人可能出错，高中和大学生依然是其最热衷的早期使用者。他们利用聊天机器人来研究和撰写论文、完成题集、编写代码。（去年五月的期末考试周，我有个学生在图书馆里散步，发现几乎每个人的笔记本电脑上都开着 ChatGPT。）根据青少年成就组织最近的一项调查显示，超过一半的年轻人认为使用聊天机器人协助完成学业是作弊，但几乎一半的人表示他们可能会使用它。

学校管理层也感到左右为难。他们对于聊天机器人究竟是误导学生的工具还是促进学习的辅助手段，似乎难以做出明确判断。今年 1 月，纽约市学校校长 David Banks 宣布禁止使用 ChatGPT；一位发言人向华盛顿 Post 表示，聊天机器人“无助于培养学生的批判性思维和解决问题的能力，而这对于学术成就和终身成功来说至关重要。”然而四个月后，Banks 改变了主意，他称这一禁令是一种本能的、基于恐惧的反应，忽略了生成式 AI（生成式 AI）在帮助学生和老师方面的潜力，也没考虑到我们的学生正在成长于一个理解生成式 AI 至关重要的世界。此外，德州 A&amp;M 的一位教授尝试使用 ChatGPT 来识别使用该工具作弊的学生。当 ChatGPT 显示整个班级都有作弊行为时，教授威胁要让所有人挂科。问题在于，ChatGPT 的判断并不准确。（事实上，抓捕作弊者的 AI 程序是一个正在增长的领域。）从某种角度看，我们都像那位教授一样，在对其功能可能存在的高估、误解，或根本不理解的情况下，对这些产品进行初步测试。

人工智能已经开始被用于撰写财务报告、广告文案和体育新闻。3 月份，OpenAI 的联合创始人兼总裁 Greg Brockman 高兴地预测，在未来，聊天机器人还将协助编写电影剧本，甚至重写观众不喜欢的片段。两个月后，美国编剧工会举行了罢工，他们要求签订一份能够保护我们免受劣质 AI 制作电影的影响的合约。他们认为，任何能在多个人类领域创造可靠作品的 AI 平台，都可能对创造力本身构成实质性威胁。

去年九月，在编剧们结束了长达五个月的罢工之际——他们此前已经说服电影制片厂承诺不再使用 AI 编写的剧本——作家协会和一些知名小说家联合对 OpenAI 提起了集体诉讼。他们指责 OpenAI 在搜集网络内容时，未经授权或提供补偿就使用了他们的版权作品。虽然作家们无法完全确定自己的作品是否被公司使用，但由于 OpenAI 在分享其训练数据方面的政策并不透明，他们在诉讼中提到，ChatGPT 在早期对特定书籍的查询会给出字面上的引用，这“暗示该大语言模型 (LLM) 很可能已经包含了这些书籍的全部内容。”（现在这个聊天机器人已被重新训练，以回应“我无法提供版权文本的直接摘录。”）目前，一些企业通过销售特定提示来帮助用户模仿著名作家的风格。但是，如果一个作家能够轻而易举地被模仿，那么他们的作品可能就不会有太高的价值。

七月份，文学非营利组织 pen America 发布的一份报告指出，生成式 AI (Generative A.I.) 通过大幅增强虚假信息和网络滥用的传播，对自由表达构成了威胁。报告强调了一个可能的风险：“人们可能会对语言本身失去信任，进而互不信任。”这种危险如今已经超越了书面文字的范畴。OpenAI 推出了DALL-E 2，这是一个能够将文字转化为人工图像的引擎；几个月后，Stability AI 也发布了一个类似的工具，名为Stable Diffusion。根据艺术探究和报道中心的看法，AI 生成的艺术作品就像“吸血鬼”，它们吞噬了前人的艺术创作，甚至可以被视为“史上最大的艺术盗窃行为”。虽然用这种方式创造“艺术”既有趣又神奇，尤其是对于那些不擅长艺术的人来说，但那些栩栩如生地描绘了未曾发生的事件的场景，也对真实性构成了威胁。任何人都可以用 AI 炮制出塞票箱的男子或抗议者与警察对峙的图像（我亲自尝试过，效果出奇地逼真）。

尽管人们正在尝试对人工智能生成的图像加上水印，但是至今，研究人员 还没有找到一套能有效防御目前广泛使用的破解工具的水印系统；甚至，他们还可以将假水印添加到真实图片上。目前，OpenAI 仍允许用户自由地移除水印。

今年三月，包括 Elon Musk 和苹果公司联合创始人 Steve Wozniak 在内的超过一千名技术专家签署了一封公开信，呼吁 AI 公司暂停其最先进技术的研发六个月，为引入某种监管措施腾出时间。信件部分内容如下：

> 我们真的应该允许机器在我们的信息渠道中散播宣传和虚假信息吗？我们真的应该将所有工作自动化，即便是那些让人感到成就感的工作吗？我们真的应该开发出可能最终超越、比我们更聪明、甚至取代我们的非人类智能吗？我们真的应该冒着失去对我们文明控制的风险吗？这样重大的决策不应该由那些未经选举的技术领袖来做出。

这些担忧并非空穴来风。例如，IBM 的一个研究团队仅用五分钟就让 ChatGPT 制作出了极具欺骗性的网络钓鱼电邮。其他研究人员则利用生成式 AI（Generative A.I.）编写了能绕过安全协议的恶意软件，这使其成为网络犯罪分子的潜在工具。高盛甚至估计 AI 不久将取代三亿个全职岗位。

不出所料，这些问题并未得到暂停或有效监管。相反，10 月底，拜登政府发布了一份名为“安全、可靠和值得信赖的人工智能发展和使用的行政命令”，这份文件更像是一份愿景清单而非具体指令。这显示出行政部门在 AI 带来的风险和机遇之间努力寻找平衡。就在一周后，OpenAI 宣布推出一系列新产品，包括一个能读懂长达三百页书籍的 AI 模型；一个自制聊天机器人工具包；以及一个名为“版权保护盾”的产品，承诺为被控侵权的开发者支付法律费用。

利用这些新工具，我成功使用 ChatGPT 创建了两个聊天机器人：一个用来判断哪些药物不应同时服用，另一个则列出能够适应特定食物过敏和禁忌的特定地点的餐厅。虽然制作这些聊天机器人既直观又简单，但我对其背后的算法、它们的训练数据来源一无所知。我甚至不清楚这些聊天机器人提供的信息是否准确，也不了解我使用的计算能力有多大，或者我的环境影响有多严重。但毕竟，这些都是很酷的东西，是人们可能愿意为之付费的创新产品。

生成式 AI 的商业应用前景广阔，预计将持续蓬勃发展。AI 技术日益影响到各类复杂领域，包括放射学、药物发现、心理治疗、招聘以及大学录取等。众多公司正计划将 AI 集成进其下一代产品中。例如，三星计划在 1 月发布的新一代旗舰手机中融入生成式 AI。Sam Altman，作为 OpenAI 的联合创始人，他不久前被董事会罢免了首席执行官的职位，但后来又重返 CEO 岗位。据悉，他正在与 Apple 的知名设计师 Jony Ive 合作，共同打造类似于“人工智能领域的 iPhone”这样的产品。我们或许会怀念 2023 年，那是一个智能还没有被普遍商品化的时代。♦

原文链接：https://www.newyorker.com/culture/2023-in-review/the-year-ai-ate-the-internet
译文：https://baoyu.io/translations/ai/the-year-ai-ate-the-internet</title>
            <link>https://nitter.cz/dotey/status/1737365753198772373#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737365753198772373#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 06:54:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>纽约客的文章：《The Year A.I. Ate the Internet | AI 改变互联网的一年 [译]》<br />
<br />
2023 年，许多人开始学习如何与机器人沟通、创造、作弊，并进行合作。<br />
<br />
就在一年多前，OpenAI 发布了 ChatGPT，这是一个让用户能够以极为人性化的方式与计算机对话的应用。发布仅五天，它就吸引了一百万用户；两个月后，月活跃用户数飙升至一亿，目前这一数字几乎翻了一番。可以说，2023 年是许多人开始用全新的方式与人工智能进行沟通、创造、作弊和合作的一年。<br />
<br />
继 ChatGPT 之后，谷歌发布了其聊天机器人 Bard；微软将 OpenAI 的模型融入了它的必应搜索引擎；Meta 推出了 LLaMA；Anthropic 则带来了 Claude，一款可以应对各种规模任务的“下一代 AI 助手”。这一切让互联网仿佛注入了生命。尽管人工智能并非新鲜事物——我们的生活已经离不开它，无论是 Netflix 的推荐算法、信用卡公司侦测欺诈活动，还是亚马逊的 Alexa 播报早间新闻，人工智能无处不在，却鲜为人注意。<br />
<br />
但是，尽管有些人工智能 (A.I.) 在幕后以一种脚本化且脆弱的方式工作，聊天机器人 (chatbot) 却展现出了反应灵敏和即兴创造的能力。它们的行为也充满不可预测性。当我们向它们寻求帮助，用我们所不了解的事物来提问或请求它们提供创意支持时，它们往往能创造出前所未有的东西，仿佛凭空而来。诗歌、文学评论、论文、研究报告、三幕剧本，这些作品都以清晰、纯正的人类语言呈现，宛如机器中的神被赋予了我们的形象。比如，如果你让 ChatGPT 用 Johnny Cash 的风格创作一首关于自动驾驶汽车的歌曲，你可能会得到这样的歌词：<br />
<br />
Ridin’solo, but I’m never alone,（独自行驶，但从不孤单，）<br />
<br />
Got my AI ridin’shotgun, steady as a stone.（我的 AI 同伴如岩石般稳固，）<br />
<br />
On the endless road, under the sky so vast,（在无尽的路途下，天空广袤无垠，）<br />
<br />
A ghost driver at the wheel, footprints of the past.（无形的驾驶者操控着，过去的足迹历历在目。）<br />
<br />
而如果要求以 Giuseppe Verdi 的风格创作，ChatGPT 则构建了这样一个男高音歌唱的场景：<br />
<br />
Ecco la carrozza senza cavallo! （看！无马的马车！）<br />
<br />
Scivola nella notte, silenziosa come il fato. （它在夜晚悄无声息地滑行，宛如命运的寂静。）<br />
<br />
L’ingegno dell’uomo, l’orgoglio del progresso, （人的智慧，进步的荣耀，）<br />
<br />
In questa danza d’acciaio, tessiamo il nostro destino. （在这钢铁之舞中，我们编织着各自的命运。）<br />
<br />
虽然至今尚未赢得多项奖项，但像 ChatGPT 这样的聊天机器人令我们的智能设备相形见绌。他们不仅精通各种语言，还精通编程语言；他们可以快速概括冗长的法律和财务文档；开始从事医疗疾病的诊断工作；甚至无需学习就能通过律师资格考试。不过，我们可能会误以为 AI 模型是真正的智慧，而不只是人工合成的——智能，还会误以为他们理解他们传递的内容的含义和后果。但实际上，他们不是。用语言学家 Emily Bender 和其三位合作者的话来说，他们更像是“概率性的复读机”。在 AI 被视为拥有智慧之前，人们不应忘记，AI 所拥有的一切都源于大量的人类知识。我们学会了如何与机器人协同工作，但在这之前，机器人必须首先被教会如何与我们协同工作。<br />
<br />
要开始理解这些聊天机器人的工作原理，我们必须掌握新的词汇，从“大语言模型”(L.L.M.s)、"神经网络" 到“自然语言处理”(N.L.P.) 和“生成式 AI”。目前我们大致了解了基本情况：这些聊天机器人汲取了互联网上的内容，并通过一种模仿人脑的机器学习技术进行分析；它们根据统计学原理串联起词语，依据哪些词汇和短语通常会组合在一起。然而，人工智能的极致创新性仍然难以完全理解，正如我们在聊天机器人出现“幻觉”时所发现的那样。<br />
<br />
以 Google 的 Bard 为例，它曾错误地创造了关于 James Webb 望远镜的信息。同样，Microsoft 的 Bing 误称歌手 Billie Eilish 在 2023 年超级碗中场秀中表演过。一位律师表示：“我之前没想到 ChatGPT 会编造案例”，他提交给联邦法院的简报中充满了 ChatGPT 提供的虚假引用和捏造的司法意见（因此被法院罚款五千美元）。ChatGPT 在细则中承认其可能不可靠：“ChatGPT 可能会犯错误。请考虑核实重要信息。”奇怪的是，最近的一项研究显示，在过去一年中，ChatGPT 在执行某些任务时的准确性反而下降了。研究人员推测这可能与其训练材料有关，但由于 OpenAI 未公开其用于训练大语言模型 (Large Language Model, L.L.M.) 的具体内容，这仅是推测。<br />
<br />
尽管清楚知道聊天机器人可能出错，高中和大学生依然是其最热衷的早期使用者。他们利用聊天机器人来研究和撰写论文、完成题集、编写代码。（去年五月的期末考试周，我有个学生在图书馆里散步，发现几乎每个人的笔记本电脑上都开着 ChatGPT。）根据青少年成就组织最近的一项调查显示，超过一半的年轻人认为使用聊天机器人协助完成学业是作弊，但几乎一半的人表示他们可能会使用它。<br />
<br />
学校管理层也感到左右为难。他们对于聊天机器人究竟是误导学生的工具还是促进学习的辅助手段，似乎难以做出明确判断。今年 1 月，纽约市学校校长 David Banks 宣布禁止使用 ChatGPT；一位发言人向华盛顿 Post 表示，聊天机器人“无助于培养学生的批判性思维和解决问题的能力，而这对于学术成就和终身成功来说至关重要。”然而四个月后，Banks 改变了主意，他称这一禁令是一种本能的、基于恐惧的反应，忽略了生成式 AI（生成式 AI）在帮助学生和老师方面的潜力，也没考虑到我们的学生正在成长于一个理解生成式 AI 至关重要的世界。此外，德州 A&amp;M 的一位教授尝试使用 ChatGPT 来识别使用该工具作弊的学生。当 ChatGPT 显示整个班级都有作弊行为时，教授威胁要让所有人挂科。问题在于，ChatGPT 的判断并不准确。（事实上，抓捕作弊者的 AI 程序是一个正在增长的领域。）从某种角度看，我们都像那位教授一样，在对其功能可能存在的高估、误解，或根本不理解的情况下，对这些产品进行初步测试。<br />
<br />
人工智能已经开始被用于撰写财务报告、广告文案和体育新闻。3 月份，OpenAI 的联合创始人兼总裁 Greg Brockman 高兴地预测，在未来，聊天机器人还将协助编写电影剧本，甚至重写观众不喜欢的片段。两个月后，美国编剧工会举行了罢工，他们要求签订一份能够保护我们免受劣质 AI 制作电影的影响的合约。他们认为，任何能在多个人类领域创造可靠作品的 AI 平台，都可能对创造力本身构成实质性威胁。<br />
<br />
去年九月，在编剧们结束了长达五个月的罢工之际——他们此前已经说服电影制片厂承诺不再使用 AI 编写的剧本——作家协会和一些知名小说家联合对 OpenAI 提起了集体诉讼。他们指责 OpenAI 在搜集网络内容时，未经授权或提供补偿就使用了他们的版权作品。虽然作家们无法完全确定自己的作品是否被公司使用，但由于 OpenAI 在分享其训练数据方面的政策并不透明，他们在诉讼中提到，ChatGPT 在早期对特定书籍的查询会给出字面上的引用，这“暗示该大语言模型 (LLM) 很可能已经包含了这些书籍的全部内容。”（现在这个聊天机器人已被重新训练，以回应“我无法提供版权文本的直接摘录。”）目前，一些企业通过销售特定提示来帮助用户模仿著名作家的风格。但是，如果一个作家能够轻而易举地被模仿，那么他们的作品可能就不会有太高的价值。<br />
<br />
七月份，文学非营利组织 pen America 发布的一份报告指出，生成式 AI (Generative A.I.) 通过大幅增强虚假信息和网络滥用的传播，对自由表达构成了威胁。报告强调了一个可能的风险：“人们可能会对语言本身失去信任，进而互不信任。”这种危险如今已经超越了书面文字的范畴。OpenAI 推出了DALL-E 2，这是一个能够将文字转化为人工图像的引擎；几个月后，Stability AI 也发布了一个类似的工具，名为Stable Diffusion。根据艺术探究和报道中心的看法，AI 生成的艺术作品就像“吸血鬼”，它们吞噬了前人的艺术创作，甚至可以被视为“史上最大的艺术盗窃行为”。虽然用这种方式创造“艺术”既有趣又神奇，尤其是对于那些不擅长艺术的人来说，但那些栩栩如生地描绘了未曾发生的事件的场景，也对真实性构成了威胁。任何人都可以用 AI 炮制出塞票箱的男子或抗议者与警察对峙的图像（我亲自尝试过，效果出奇地逼真）。<br />
<br />
尽管人们正在尝试对人工智能生成的图像加上水印，但是至今，研究人员 还没有找到一套能有效防御目前广泛使用的破解工具的水印系统；甚至，他们还可以将假水印添加到真实图片上。目前，OpenAI 仍允许用户自由地移除水印。<br />
<br />
今年三月，包括 Elon Musk 和苹果公司联合创始人 Steve Wozniak 在内的超过一千名技术专家签署了一封公开信，呼吁 AI 公司暂停其最先进技术的研发六个月，为引入某种监管措施腾出时间。信件部分内容如下：<br />
<br />
> 我们真的应该允许机器在我们的信息渠道中散播宣传和虚假信息吗？我们真的应该将所有工作自动化，即便是那些让人感到成就感的工作吗？我们真的应该开发出可能最终超越、比我们更聪明、甚至取代我们的非人类智能吗？我们真的应该冒着失去对我们文明控制的风险吗？这样重大的决策不应该由那些未经选举的技术领袖来做出。<br />
<br />
这些担忧并非空穴来风。例如，IBM 的一个研究团队仅用五分钟就让 ChatGPT 制作出了极具欺骗性的网络钓鱼电邮。其他研究人员则利用生成式 AI（Generative A.I.）编写了能绕过安全协议的恶意软件，这使其成为网络犯罪分子的潜在工具。高盛甚至估计 AI 不久将取代三亿个全职岗位。<br />
<br />
不出所料，这些问题并未得到暂停或有效监管。相反，10 月底，拜登政府发布了一份名为“安全、可靠和值得信赖的人工智能发展和使用的行政命令”，这份文件更像是一份愿景清单而非具体指令。这显示出行政部门在 AI 带来的风险和机遇之间努力寻找平衡。就在一周后，OpenAI 宣布推出一系列新产品，包括一个能读懂长达三百页书籍的 AI 模型；一个自制聊天机器人工具包；以及一个名为“版权保护盾”的产品，承诺为被控侵权的开发者支付法律费用。<br />
<br />
利用这些新工具，我成功使用 ChatGPT 创建了两个聊天机器人：一个用来判断哪些药物不应同时服用，另一个则列出能够适应特定食物过敏和禁忌的特定地点的餐厅。虽然制作这些聊天机器人既直观又简单，但我对其背后的算法、它们的训练数据来源一无所知。我甚至不清楚这些聊天机器人提供的信息是否准确，也不了解我使用的计算能力有多大，或者我的环境影响有多严重。但毕竟，这些都是很酷的东西，是人们可能愿意为之付费的创新产品。<br />
<br />
生成式 AI 的商业应用前景广阔，预计将持续蓬勃发展。AI 技术日益影响到各类复杂领域，包括放射学、药物发现、心理治疗、招聘以及大学录取等。众多公司正计划将 AI 集成进其下一代产品中。例如，三星计划在 1 月发布的新一代旗舰手机中融入生成式 AI。Sam Altman，作为 OpenAI 的联合创始人，他不久前被董事会罢免了首席执行官的职位，但后来又重返 CEO 岗位。据悉，他正在与 Apple 的知名设计师 Jony Ive 合作，共同打造类似于“人工智能领域的 iPhone”这样的产品。我们或许会怀念 2023 年，那是一个智能还没有被普遍商品化的时代。♦<br />
<br />
原文链接：<a href="https://www.newyorker.com/culture/2023-in-review/the-year-ai-ate-the-internet">newyorker.com/culture/2023-i…</a><br />
译文：<a href="https://baoyu.io/translations/ai/the-year-ai-ate-the-internet">baoyu.io/translations/ai/the…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4YzdfWVhZQUFpV1owLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737350042439065963#m</id>
            <title>实至名归😄</title>
            <link>https://nitter.cz/dotey/status/1737350042439065963#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737350042439065963#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 05:51:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>实至名归😄</p>
<p><a href="https://nitter.cz/XxWrkb5TSyu8DlT/status/1737326829332303950#m">nitter.cz/XxWrkb5TSyu8DlT/status/1737326829332303950#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xicilion/status/1737317533878014293#m</id>
            <title>RT by @dotey: 一个思路和 airllm 很类似的优化推理引擎，利用清华的 ReLU-based sparse models 技术，对 llama.cpp 的 ggml 进行改造，最终达到在 4090 上相对原版 llama.cpp 11 倍的速度。

在 4090 上的速度仅比在 a100 （未介绍基于什么引擎）上慢 18%。

https://github.com/SJTU-IPADS/PowerInfer</title>
            <link>https://nitter.cz/xicilion/status/1737317533878014293#m</link>
            <guid isPermaLink="false">https://nitter.cz/xicilion/status/1737317533878014293#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 03:42:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个思路和 airllm 很类似的优化推理引擎，利用清华的 ReLU-based sparse models 技术，对 llama.cpp 的 ggml 进行改造，最终达到在 4090 上相对原版 llama.cpp 11 倍的速度。<br />
<br />
在 4090 上的速度仅比在 a100 （未介绍基于什么引擎）上慢 18%。<br />
<br />
<a href="https://github.com/SJTU-IPADS/PowerInfer">github.com/SJTU-IPADS/PowerI…</a></p>
<p><a href="https://nitter.cz/omarsar0/status/1737168751668187229#m">nitter.cz/omarsar0/status/1737168751668187229#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzE0NzAwMjUyMDAzOTQyNC9nOW50U0xIQj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737312698705092887#m</id>
            <title>建议关注 Google 新发布的 VideoPoet，它并非基于扩散模型，而是多模态大语言模型，基本上扩散模型能支持的功能它都能做，比如说：如文本到视频、图像到视频、视频到音频的转换，以及视频风格化、补画（inpainting）或延伸画（outpainting）处理。

并且它在保证视频一致性方面做的效果特别好，你可以看到它的一些演示动画都相当稳定。

我上传的这个视频是 Google 用 VideoPoet 制作的一个短片，展示了由多个由 VideoPoet 生成的短视频片段拼接而成的成果。在编写剧本时，他们使用 Bard 创作了一个关于旅行的浣熊的短故事，并提供了按场景划分的故事梗概和相应的视频提示。接着，根据这些提示制作了视频片段，并将它们拼接成为最终展示的视频。

对于长视频也很有大模型的 提示-补全（Prompt-Completion） 风格，VideoPoet 可以通过对视频最后一秒进行分析，预测接下来的一秒内容，从而生成更长的视频。这种方法可以连续应用，显示出模型不仅能够有效延长视频长度，还能在多次重复过程中保持视频中所有对象的连贯性和真实性。

也许像 VideoPoet 这样的多模态大模型才是视频生成的未来主流。

更多演示可以看项目网站：https://sites.research.google/videopoet/

更多详情可以看这篇博客：《VideoPoet: 能零样本生成视频的大语言模型 [译]》
https://baoyu.io/translations/google/videopoet-large-language-model-for-zero</title>
            <link>https://nitter.cz/dotey/status/1737312698705092887#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737312698705092887#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 03:23:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>建议关注 Google 新发布的 VideoPoet，它并非基于扩散模型，而是多模态大语言模型，基本上扩散模型能支持的功能它都能做，比如说：如文本到视频、图像到视频、视频到音频的转换，以及视频风格化、补画（inpainting）或延伸画（outpainting）处理。<br />
<br />
并且它在保证视频一致性方面做的效果特别好，你可以看到它的一些演示动画都相当稳定。<br />
<br />
我上传的这个视频是 Google 用 VideoPoet 制作的一个短片，展示了由多个由 VideoPoet 生成的短视频片段拼接而成的成果。在编写剧本时，他们使用 Bard 创作了一个关于旅行的浣熊的短故事，并提供了按场景划分的故事梗概和相应的视频提示。接着，根据这些提示制作了视频片段，并将它们拼接成为最终展示的视频。<br />
<br />
对于长视频也很有大模型的 提示-补全（Prompt-Completion） 风格，VideoPoet 可以通过对视频最后一秒进行分析，预测接下来的一秒内容，从而生成更长的视频。这种方法可以连续应用，显示出模型不仅能够有效延长视频长度，还能在多次重复过程中保持视频中所有对象的连贯性和真实性。<br />
<br />
也许像 VideoPoet 这样的多模态大模型才是视频生成的未来主流。<br />
<br />
更多演示可以看项目网站：<a href="https://sites.research.google/videopoet/">sites.research.google/videop…</a><br />
<br />
更多详情可以看这篇博客：《VideoPoet: 能零样本生成视频的大语言模型 [译]》<br />
<a href="https://baoyu.io/translations/google/videopoet-large-language-model-for-zero">baoyu.io/translations/google…</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1737253472808956293#m">nitter.cz/_akhaliq/status/1737253472808956293#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzczMTExMTQxNTE1NDY4ODEvcHUvaW1nL1lyaDVub0FjQjBvanhHRDYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/linyiLYi/status/1737241501334462765#m</id>
            <title>RT by @dotey: 苹果 mlx 机器学习库增加了对通义千问的支持，前几天 mixtral、phi-2 也都是一到三天的时间就支持了，这个库的维护力量超出预期。llama.cpp 要加油了。</title>
            <link>https://nitter.cz/linyiLYi/status/1737241501334462765#m</link>
            <guid isPermaLink="false">https://nitter.cz/linyiLYi/status/1737241501334462765#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 22:40:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>苹果 mlx 机器学习库增加了对通义千问的支持，前几天 mixtral、phi-2 也都是一到三天的时间就支持了，这个库的维护力量超出预期。llama.cpp 要加油了。</p>
<p><a href="https://nitter.cz/awnihannun/status/1737218185659908099#m">nitter.cz/awnihannun/status/1737218185659908099#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>