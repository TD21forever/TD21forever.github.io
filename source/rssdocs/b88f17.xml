<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729873461185855965#m</id>
            <title>RT by @dotey: 一个可以增强AI生成视频可控性的项目，支持Animatediff。将会开源代码，这下Animatediff的生命力又旺盛了。
我理解就是视频版本的ContorlNet，解决了之前视频生成使用ContorlNet时每一帧都需要介入的问题，先可以自动选择关键帧介入降低资源消耗。

可以在这里看详细的论文：https://guoyww.github.io/projects/SparseCtrl/</title>
            <link>https://nitter.cz/op7418/status/1729873461185855965#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729873461185855965#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:42:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个可以增强AI生成视频可控性的项目，支持Animatediff。将会开源代码，这下Animatediff的生命力又旺盛了。<br />
我理解就是视频版本的ContorlNet，解决了之前视频生成使用ContorlNet时每一帧都需要介入的问题，先可以自动选择关键帧介入降低资源消耗。<br />
<br />
可以在这里看详细的论文：<a href="https://guoyww.github.io/projects/SparseCtrl/">guoyww.github.io/projects/Sp…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk4NzI4NTk5MDcxOTg5NzcvcHUvaW1nLzU5Sk9Sc2dqbHQwLXU0cnouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730045578728673462#m</id>
            <title>RT by @dotey: 马斯克真是牛逼！佩服！！！

“如果有人想用广告勒索我，用金钱勒索我...

去他妈的吧。去 他 妈 的 吧！清楚了吗？

我希望是这样！”

哈哈哈哈 🫡</title>
            <link>https://nitter.cz/xiaohuggg/status/1730045578728673462#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730045578728673462#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 02:06:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>马斯克真是牛逼！佩服！！！<br />
<br />
“如果有人想用广告勒索我，用金钱勒索我...<br />
<br />
去他妈的吧。去 他 妈 的 吧！清楚了吗？<br />
<br />
我希望是这样！”<br />
<br />
哈哈哈哈 🫡</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAwNDUxNDM4MzM3OTY2MDgvcHUvaW1nL095R05kbW1aRXBHaHNwcUQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1730049238086693006#m</id>
            <title>OpenAI 最新公告：

Sam Altman 重掌 OpenAI CEO 大权，公司迎来新的初始董事会

Mira Murati 出任 CTO，Greg Brockman 再次成为总裁。来看看 CEO Sam Altman 和董事会主席 Bret Taylor 的最新发言。

2023年11月29日

以下是 CEO Sam Altman 和董事会主席 Bret Taylor 今天下午向公司全体成员所传达的信息。

---

Sam 发给公司的一封信

大家好，我即将重返 OpenAI，担任 CEO 一职。Mira 也将回归她的 CTO 职位。我们新的初始董事会成员包括 Bret Taylor（担任主席）、Larry Summers 和 Adam D’Angelo。

我对未来的憧憬前所未有地强烈。在这段不确定且史无前例的时期，每位同事的辛勤付出让我深感感激。我相信，正是我们的坚韧和精神让我们在行业中独树一帜。我对我们实现使命的可能性充满了极大的信心。

在谈论未来计划之前，我想先表达我的感激之情。

我非常敬爱并尊重 Ilya，我认为他是这个领域的灯塔，也是一位非凡的人。我对他没有任何负面情绪。尽管 Ilya 将不再担任董事会成员，我们仍希望保持合作关系，并正在探讨他如何继续在 OpenAI 的工作。

我非常感谢 Adam、Tasha 和 Helen 与我们一起找到了最符合我们使命的解决方案。我期待继续与 Adam 合作，并衷心感谢 Helen 和 Tasha 在这个过程中付出的巨大努力。

同时，我也要感谢 Emmett，在达成这一成果的过程中发挥了关键和建设性的作用。Emmett 对 AI 安全和平衡各方利益的承诺非常明显。

Mira 在这整个过程中表现出色，无私地为使命、团队和公司服务。她是一位卓越的领导者，没有她就没有今天的 OpenAI。衷心感谢你。

Greg 和我是共同管理这家公司的伙伴。我们一直在努力在组织架构上表达这一点，未来我们会做到的。在此之前，我只想明确这一点。感谢你从一开始以来的所有付出，以及在过去的一周里你所展现的处理能力。

我们的领导团队——包括 Mira、Brad、Jason、Che、Hannah、Diane、Anna、Bob、Srinivas、Matt、Lilian、Miles、Jan、Wojciech、John、Jonathan、Pat 以及其他许多人——已经完全有能力在没有我的情况下管理公司。有句话说，评价一位 CEO 的标准之一是看他如何挑选和培养潜在的继任者；在这方面，我做得比我自己意识到的还要好。我清楚地看到，公司掌握在一群优秀人才的手中，我希望这一点对每个人都非常明显。感谢大家。

我还要感谢 Jakub、Szymon 和 Aleksander，他们是非凡的人才，我很高兴他们重新加入我们，共同推动公司和研究的发展。谢谢你们。

亲爱的团队成员们，我相信未来会有很多关于我们这个时代的书籍问世，我希望它们首先强调的是，我们团队的表现有多么出色。经历了这一切，我们团队没有一人离职，大家为了彼此、公司和我们的使命坚守岗位。在构建安全的通用人工智能（AGI）的过程中，最重要的能力之一就是在压力和不确定性中保持清晰的判断力，而你们做到了，真心感谢大家。

在这个过程中，Satya, Kevin, Amy 和 Brad 是非常了不起的合作伙伴，始终坚持正确的方向。他们一直在我们身后支持我们，如果我们无法实现主要目标，他们也准备好接纳我们。选择与 Microsoft 合作绝对是正确的，我对我们新董事会中将包括他们作为非投票观察员感到兴奋。非常感谢他们。

感谢我们的合作伙伴和用户一直与我们同行。你们的支持和爱让我们感到温暖，帮助我们度过难关。我们没有失去任何一个客户，这将激励我们为你们付出更多努力。我们都迫不及待地想要回到工作岗位。

Will Hurd、Brian Chesky、Bret Taylor 以及 Larry Summers 为了支持我们的使命，把个人生活暂时放在了一边，为此付出了巨大努力。我真的不知道他们是怎么做到的，但他们确实做到了。衷心感谢。

Ollie 也在这段时间里把个人生活放在了一边，全心全意地提供帮助，同时还给予了他一贯的无条件爱与支持。感谢你，我爱你。

那么，我们接下来的计划是什么呢？

我们有三个紧急的优先事项。

首先是推进我们的研究计划，并进一步加大对我们全栈安全工作的投入，这一直是我们工作的核心。我们的研究路线图非常明确，这段时间让我们更加专注。我和你们一样，对未来充满激情；我们将把这次危机转化为机遇！我将与 Mira 共同努力。

其次是持续改进和部署我们的产品，为客户提供服务。让人们体验到 AI 的好处和潜力，并有机会参与塑造它，这非常重要。我们始终相信，优秀的产品是实现这一目标的最佳途径。我将与 Brad, Jason 和 Anna 合作，确保我们对全球用户、客户、合作伙伴和政府的承诺坚定不移。

Bret、Larry 和 Adam 正在承担一项至关重要的任务：构建一个多元化视角的董事会、改进我们的治理结构，并监督对近期事件的独立审查。我非常期待与他们紧密合作，采取这些关键措施，确保每个人都对 OpenAI 的稳定充满信心。

我迫不及待想和你们一起完成构建有益的通用人工智能（AGI）的伟大使命——我们是世界上最棒的团队，拥有最伟大的使命。

爱你们的，

Sam

---

Bret 给公司的寄语

我代表 OpenAI 董事会，向整个 OpenAI 社区，尤其是所有 OpenAI 员工表示感谢。在过去的一周里，大家齐心协力，为公司找到了发展的新路径。你们的努力让这个了不起的组织能够继续履行其使命——确保人工通用智能造福全人类。我们很高兴看到 Sam、Mira 和 Greg 再次联手领导公司，推动其不断前进。我们期待着与他们以及你们所有人共同努力。

作为董事会，我们致力于加强 OpenAI 的公司治理。我们的计划如下：

我们将组建一个由经验丰富、背景多元的优秀个人组成的董事会，他们的经验涵盖了 OpenAI 使命的各个方面——从技术到安全，再到政策。我们很高兴地宣布，董事会将包括一名 Microsoft 的非投票观察员。

我们将进一步巩固 OpenAI 的组织架构，以便我们能够持续推进我们的使命。这包括成立一个董事会的独立委员会，负责审查近期发生的事件。

我们将改善 OpenAI 的治理结构，确保所有利益相关方——包括用户、客户、员工、合作伙伴和社区成员——都能信赖 OpenAI 的持续繁荣。

OpenAI 现在比以往任何时候都更加重要。ChatGPT 已经让人工智能成为数亿人日常生活的一部分。它的普及让 AI 的优势和风险成为了几乎所有关于政府、商业和社会未来的讨论的核心。

我们深知这些讨论的重要性，以及 OpenAI 在开发和确保这些令人惊叹新技术安全方面的核心地位。你们每个人都在确保我们有效应对这些挑战中扮演着至关重要的角色。我们致力于倾听你们的意见并向你们学习，希望不久能与大家面对面交流。

我们为能成为 OpenAI 的一员而感到自豪，并期待与你们所有人一起工作。

感谢大家， Bret Taylor OpenAI 董事会主席

https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board</title>
            <link>https://nitter.cz/dotey/status/1730049238086693006#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1730049238086693006#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 02:20:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 最新公告：<br />
<br />
Sam Altman 重掌 OpenAI CEO 大权，公司迎来新的初始董事会<br />
<br />
Mira Murati 出任 CTO，Greg Brockman 再次成为总裁。来看看 CEO Sam Altman 和董事会主席 Bret Taylor 的最新发言。<br />
<br />
2023年11月29日<br />
<br />
以下是 CEO Sam Altman 和董事会主席 Bret Taylor 今天下午向公司全体成员所传达的信息。<br />
<br />
---<br />
<br />
Sam 发给公司的一封信<br />
<br />
大家好，我即将重返 OpenAI，担任 CEO 一职。Mira 也将回归她的 CTO 职位。我们新的初始董事会成员包括 Bret Taylor（担任主席）、Larry Summers 和 Adam D’Angelo。<br />
<br />
我对未来的憧憬前所未有地强烈。在这段不确定且史无前例的时期，每位同事的辛勤付出让我深感感激。我相信，正是我们的坚韧和精神让我们在行业中独树一帜。我对我们实现使命的可能性充满了极大的信心。<br />
<br />
在谈论未来计划之前，我想先表达我的感激之情。<br />
<br />
我非常敬爱并尊重 Ilya，我认为他是这个领域的灯塔，也是一位非凡的人。我对他没有任何负面情绪。尽管 Ilya 将不再担任董事会成员，我们仍希望保持合作关系，并正在探讨他如何继续在 OpenAI 的工作。<br />
<br />
我非常感谢 Adam、Tasha 和 Helen 与我们一起找到了最符合我们使命的解决方案。我期待继续与 Adam 合作，并衷心感谢 Helen 和 Tasha 在这个过程中付出的巨大努力。<br />
<br />
同时，我也要感谢 Emmett，在达成这一成果的过程中发挥了关键和建设性的作用。Emmett 对 AI 安全和平衡各方利益的承诺非常明显。<br />
<br />
Mira 在这整个过程中表现出色，无私地为使命、团队和公司服务。她是一位卓越的领导者，没有她就没有今天的 OpenAI。衷心感谢你。<br />
<br />
Greg 和我是共同管理这家公司的伙伴。我们一直在努力在组织架构上表达这一点，未来我们会做到的。在此之前，我只想明确这一点。感谢你从一开始以来的所有付出，以及在过去的一周里你所展现的处理能力。<br />
<br />
我们的领导团队——包括 Mira、Brad、Jason、Che、Hannah、Diane、Anna、Bob、Srinivas、Matt、Lilian、Miles、Jan、Wojciech、John、Jonathan、Pat 以及其他许多人——已经完全有能力在没有我的情况下管理公司。有句话说，评价一位 CEO 的标准之一是看他如何挑选和培养潜在的继任者；在这方面，我做得比我自己意识到的还要好。我清楚地看到，公司掌握在一群优秀人才的手中，我希望这一点对每个人都非常明显。感谢大家。<br />
<br />
我还要感谢 Jakub、Szymon 和 Aleksander，他们是非凡的人才，我很高兴他们重新加入我们，共同推动公司和研究的发展。谢谢你们。<br />
<br />
亲爱的团队成员们，我相信未来会有很多关于我们这个时代的书籍问世，我希望它们首先强调的是，我们团队的表现有多么出色。经历了这一切，我们团队没有一人离职，大家为了彼此、公司和我们的使命坚守岗位。在构建安全的通用人工智能（AGI）的过程中，最重要的能力之一就是在压力和不确定性中保持清晰的判断力，而你们做到了，真心感谢大家。<br />
<br />
在这个过程中，Satya, Kevin, Amy 和 Brad 是非常了不起的合作伙伴，始终坚持正确的方向。他们一直在我们身后支持我们，如果我们无法实现主要目标，他们也准备好接纳我们。选择与 Microsoft 合作绝对是正确的，我对我们新董事会中将包括他们作为非投票观察员感到兴奋。非常感谢他们。<br />
<br />
感谢我们的合作伙伴和用户一直与我们同行。你们的支持和爱让我们感到温暖，帮助我们度过难关。我们没有失去任何一个客户，这将激励我们为你们付出更多努力。我们都迫不及待地想要回到工作岗位。<br />
<br />
Will Hurd、Brian Chesky、Bret Taylor 以及 Larry Summers 为了支持我们的使命，把个人生活暂时放在了一边，为此付出了巨大努力。我真的不知道他们是怎么做到的，但他们确实做到了。衷心感谢。<br />
<br />
Ollie 也在这段时间里把个人生活放在了一边，全心全意地提供帮助，同时还给予了他一贯的无条件爱与支持。感谢你，我爱你。<br />
<br />
那么，我们接下来的计划是什么呢？<br />
<br />
我们有三个紧急的优先事项。<br />
<br />
首先是推进我们的研究计划，并进一步加大对我们全栈安全工作的投入，这一直是我们工作的核心。我们的研究路线图非常明确，这段时间让我们更加专注。我和你们一样，对未来充满激情；我们将把这次危机转化为机遇！我将与 Mira 共同努力。<br />
<br />
其次是持续改进和部署我们的产品，为客户提供服务。让人们体验到 AI 的好处和潜力，并有机会参与塑造它，这非常重要。我们始终相信，优秀的产品是实现这一目标的最佳途径。我将与 Brad, Jason 和 Anna 合作，确保我们对全球用户、客户、合作伙伴和政府的承诺坚定不移。<br />
<br />
Bret、Larry 和 Adam 正在承担一项至关重要的任务：构建一个多元化视角的董事会、改进我们的治理结构，并监督对近期事件的独立审查。我非常期待与他们紧密合作，采取这些关键措施，确保每个人都对 OpenAI 的稳定充满信心。<br />
<br />
我迫不及待想和你们一起完成构建有益的通用人工智能（AGI）的伟大使命——我们是世界上最棒的团队，拥有最伟大的使命。<br />
<br />
爱你们的，<br />
<br />
Sam<br />
<br />
---<br />
<br />
Bret 给公司的寄语<br />
<br />
我代表 OpenAI 董事会，向整个 OpenAI 社区，尤其是所有 OpenAI 员工表示感谢。在过去的一周里，大家齐心协力，为公司找到了发展的新路径。你们的努力让这个了不起的组织能够继续履行其使命——确保人工通用智能造福全人类。我们很高兴看到 Sam、Mira 和 Greg 再次联手领导公司，推动其不断前进。我们期待着与他们以及你们所有人共同努力。<br />
<br />
作为董事会，我们致力于加强 OpenAI 的公司治理。我们的计划如下：<br />
<br />
我们将组建一个由经验丰富、背景多元的优秀个人组成的董事会，他们的经验涵盖了 OpenAI 使命的各个方面——从技术到安全，再到政策。我们很高兴地宣布，董事会将包括一名 Microsoft 的非投票观察员。<br />
<br />
我们将进一步巩固 OpenAI 的组织架构，以便我们能够持续推进我们的使命。这包括成立一个董事会的独立委员会，负责审查近期发生的事件。<br />
<br />
我们将改善 OpenAI 的治理结构，确保所有利益相关方——包括用户、客户、员工、合作伙伴和社区成员——都能信赖 OpenAI 的持续繁荣。<br />
<br />
OpenAI 现在比以往任何时候都更加重要。ChatGPT 已经让人工智能成为数亿人日常生活的一部分。它的普及让 AI 的优势和风险成为了几乎所有关于政府、商业和社会未来的讨论的核心。<br />
<br />
我们深知这些讨论的重要性，以及 OpenAI 在开发和确保这些令人惊叹新技术安全方面的核心地位。你们每个人都在确保我们有效应对这些挑战中扮演着至关重要的角色。我们致力于倾听你们的意见并向你们学习，希望不久能与大家面对面交流。<br />
<br />
我们为能成为 OpenAI 的一员而感到自豪，并期待与你们所有人一起工作。<br />
<br />
感谢大家， Bret Taylor OpenAI 董事会主席<br />
<br />
<a href="https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board">openai.com/blog/sam-altman-r…</a></p>
<p><a href="https://nitter.cz/OpenAI/status/1730030975931846939#m">nitter.cz/OpenAI/status/1730030975931846939#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1730027077221712066#m</id>
            <title>RT by @dotey: OpenGPTs
一个构建类似 GPTs 和 Assistants API 的开源框架。
相比 ClosedAI，OpenGPTs 可以自由配置以下内容：
- 60+ LLM
- Prompt
- 100+ Tools 
- 60+ 向量数据库
https://github.com/langchain-ai/opengpts</title>
            <link>https://nitter.cz/oran_ge/status/1730027077221712066#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1730027077221712066#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 00:52:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenGPTs<br />
一个构建类似 GPTs 和 Assistants API 的开源框架。<br />
相比 ClosedAI，OpenGPTs 可以自由配置以下内容：<br />
- 60+ LLM<br />
- Prompt<br />
- 100+ Tools <br />
- 60+ 向量数据库<br />
<a href="https://github.com/langchain-ai/opengpts">github.com/langchain-ai/open…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyOTIyNTAxNjQ5ODExNDU2MC9JU3RLSmQycz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729998362642895216#m</id>
            <title>历史上的一次大的因为用户界面导致的灾难 [译]

我想花点时间探讨历史上的一次大的因为用户界面导致的灾难：1988 年 7 月 3 日，美军海军导弹巡洋舰 USS Vincennes (CG-49) 在波斯湾上空误击伊朗航空 655 号航班，机上 290 人全部遇难。

当时，这起灾难令人不解。Vincennes 装备了当时最新的宙斯盾作战系统（Aegis Combat System），这是全球最先进的防空系统，利用先进的计算机技术设计用于同时识别、追踪并击落数百架苏联轰炸机。那么，它如何可能在面对一架单独的民用飞机时犯下如此严重的错误呢？

美国海军的官方报告完全为宙斯盾开脱，将责任归咎于舰员。但后来曝光的细节强烈表明，击落事件至少部分是因为宙斯盾用户界面的重大缺陷。

如果你对这个事件不太了解，可以在维基百科上找到一个页面，里面有详细的介绍（https://en.m.wikipedia.org/wiki/Iran_Air_Flight_655）。因此，我不打算回顾整个事件，而是想专注于导致 Vincennes 舰长和船员犯下这一重大错误的用户界面问题。

（这是一个复杂的话题，我会尽量简短地说明，保证。）

图一：1988 年 7 月 3 日被 USS Vincennes 击落的空客 A300B2-203 EP-IBU 飞机。

图二：美国海军导弹巡洋舰 USS Vincennes。

伊朗航空 655 号航班被灾难性击落的第一个用户界面缺陷出现在飞机从伊朗班达尔阿巴斯国际机场起飞后不久。

无论是过去还是现在，世界上所有大型飞机都装有一种称为 IFF（“识别敌友”）的装置。这是一个无线电应答器，能够对请求做出回应，提供一组代码，以表明飞机是民用还是军用，以及其类型。

Flight 655 安装了识别友敌系统 (IFF)，并准确报告其为民用客机。起飞后不久，Vincennes 查询其 IFF，得到确认为民用客机。到此为止，一切正常。

问题出在 Aegis 系统的 IFF 控制台操作上。操作员通过控制器移动光标至目标位置，并按下按钮来“锁定”新目标进行追踪。一旦“锁定”，Aegis 就会追踪该目标。但问题是，除非操作员执行额外步骤，将光标固定于该目标，否则随着目标移动，光标不会跟随。它将继续在目标_原来的位置_发送 IFF 请求，直到操作员再次移动光标。

在 Flight 655 的情况中，操作员正确地锁定了目标，但未固定光标。因此，当 Flight 655 离开时，Vincennes 仍向其起飞跑道发送 IFF 请求。

紧接着从该跑道起飞的是伊朗的一架 F-14 军用战斗机。光标在跑道上停留约 90 秒，足以让 Vincennes 接收到军用战斗机的 IFF 响应。于是 Flight 655 从未知目标被重新归类为可能的敌对目标。

当 Vincennes 船长和船员查看显示器时，他们从那时起看到的是一个被标记为 F-14 战斗机的、朝他们方向前进的目标。

图三：一名水手操作 Aegis 控制台

接下来的问题源于 Aegis 系统向船员反馈数据的方式。

整个系统基于屏幕设计。每位船员都有自己的屏幕来处理他们负责的数据。这些数据随后汇总到一组大型显示器上，供船长和高级官员监控总体情况。

这本身并无不妥。但关键在于，为高层决策者设计的“大局观”仪表板视图的成败完全取决于提供给该视图的数据。设计仪表板需要压缩和总结信息。如果简单地传递所有信息，会令决策者不堪重负。因此，问题在于决定包含哪些信息，而哪些不包含。

在 Aegis 防御系统的原始版本中，大型显示屏可以展示所有被跟踪目标的位置和航向，但并未显示它们的高度。这一点至关重要，因为高度，尤其是高度的变化，是判断被跟踪目标意图的关键线索。例如，如果一架飞机正向你飞来但同时在上升，它攻击你的可能性就较低。相反，如果它向你俯冲，这通常预示着攻击。

Vincennes 舰长在监视一个向他靠近的目标时，由于大屏幕没有显示高度信息，他无法迅速判断该目标是在上升还是下降。这些关键信息虽然存在，但只能在操作员的小屏幕上深入查找，而非在大屏幕的总体情况展示中。

图四：Aegis 在 USS Vincennes 上的显示屏

随着 Flight 655 逐渐靠近，Vincennes 的舰长意识到他需要明确该飞机是在上升还是下降。因此，他请求了这一信息，但这时发生了第三次也是最后一次用户界面（UI）的失败。

Aegis 的一大特色功能是能从多艘船只的传感器中提取并统一展示数据。在一个任务组中，所有船只通过数据链路相连。当多艘船只监测到同一个目标时，Aegis 能自动整合这些信息，形成一个对所有连接船只上的操作员都可见的统一跟踪目标。

为了方便识别这些被跟踪目标，Aegis 会为每一个新目标分配一个四位数的追踪编号。不同船只对同一目标的追踪编号可能不同。Aegis 将整合这些信息，选定一个编号作为官方编号，并舍弃其他编号。

然而，这个过程中存在两个用户界面问题。首先，被舍弃的追踪编号会被回收利用，分配给新的目标。其次，当 Aegis 改变某个目标的追踪编号时，并没有明显的提示，编号只是在显示屏上默默变化。

当 Flight 655 起飞时，同时被 Vincennes 和其护航舰 USS Sides 发现并追踪。Vincennes 给它分配的追踪编号是 4474，而 Sides 分配的是 4131。Aegis 将这两个监测信息统一在 4131 这个编号下。随后，4474 这个编号被重新分配给了一架正在下降的美国 A-6 轰炸机。

在做出开火决定的关键时刻，Vincennes 号的舰长请求了一份关于飞机高度的报告。但他未意识到飞机的追踪编号已变更，还以为它是原先分配的 4474 号。因此，他要求了关于 4474 号的信息，值班人员便在控制台输入了这个编号。结果显示目标正在快速下降。

事实上，655 航班并未下降，自从从 Bandar Abbas 起飞后一直在上升。但在这个决定性时刻，Aegis 系统的操作员却在监视另一架完全不同的飞机。

接着，Vincennes 号舰长下达了开火命令，随后发生的是一场悲剧。

我不是要把这次误击事件的全部责任推到 Aegis 身上。实际上，如果你去查看维基百科，会发现那天早晨出现了许多问题。

但同时，Aegis 系统在此也不是完全无辜。其界面设计不佳，导致 Vincennes 号的船员误解了他们所面临的真实情况。

海军的报告责怪船员没有正确使用系统，但对于那些设计信息系统的人来说，这显然是在逃避责任。人在压力下容易犯错，而战斗场合的压力尤为巨大。如果一个系统不能适应这种压力环境——如果它不能全力支持操作员，即使在出现失误时也能确保他们获取必要信息——那么问题不在于操作员，而在于设计者。

The End

附言：如果你想深入研究这个话题，我找到的最佳资料是美国空军上尉 Kristen Ann Dotterway 于 1992 年撰写的硕士论文《复杂动态系统的系统分析：USS Vincennes 事件研究》。

Dotterway 上尉在论文中逐分钟梳理了事件的经过，比较了海军的官方说法和 Vincennes 号舰长后续采访中的陈述，并提供了揭示海军说法漏洞的数据。

这份文档篇幅颇厚，但若你渴望深入探索该领域，它会引领你走得比维基百科页面上的信息更远。你可以通过以下链接下载该文档的 PDF 版本：https://apps.dtic.mil/sti/tr/pdf/ADA26

原文：https://octodon.social/@jalefkowit/111490485825183949
译文：https://baoyu.io/translations/stroies/the-greatest-user-interface-disasters-in-history</title>
            <link>https://nitter.cz/dotey/status/1729998362642895216#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729998362642895216#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 22:58:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>历史上的一次大的因为用户界面导致的灾难 [译]<br />
<br />
我想花点时间探讨历史上的一次大的因为用户界面导致的灾难：1988 年 7 月 3 日，美军海军导弹巡洋舰 USS Vincennes (CG-49) 在波斯湾上空误击伊朗航空 655 号航班，机上 290 人全部遇难。<br />
<br />
当时，这起灾难令人不解。Vincennes 装备了当时最新的宙斯盾作战系统（Aegis Combat System），这是全球最先进的防空系统，利用先进的计算机技术设计用于同时识别、追踪并击落数百架苏联轰炸机。那么，它如何可能在面对一架单独的民用飞机时犯下如此严重的错误呢？<br />
<br />
美国海军的官方报告完全为宙斯盾开脱，将责任归咎于舰员。但后来曝光的细节强烈表明，击落事件至少部分是因为宙斯盾用户界面的重大缺陷。<br />
<br />
如果你对这个事件不太了解，可以在维基百科上找到一个页面，里面有详细的介绍（<a href="https://en.m.wikipedia.org/wiki/Iran_Air_Flight_655">en.m.wikipedia.org/wiki/Iran…</a>）。因此，我不打算回顾整个事件，而是想专注于导致 Vincennes 舰长和船员犯下这一重大错误的用户界面问题。<br />
<br />
（这是一个复杂的话题，我会尽量简短地说明，保证。）<br />
<br />
图一：1988 年 7 月 3 日被 USS Vincennes 击落的空客 A300B2-203 EP-IBU 飞机。<br />
<br />
图二：美国海军导弹巡洋舰 USS Vincennes。<br />
<br />
伊朗航空 655 号航班被灾难性击落的第一个用户界面缺陷出现在飞机从伊朗班达尔阿巴斯国际机场起飞后不久。<br />
<br />
无论是过去还是现在，世界上所有大型飞机都装有一种称为 IFF（“识别敌友”）的装置。这是一个无线电应答器，能够对请求做出回应，提供一组代码，以表明飞机是民用还是军用，以及其类型。<br />
<br />
Flight 655 安装了识别友敌系统 (IFF)，并准确报告其为民用客机。起飞后不久，Vincennes 查询其 IFF，得到确认为民用客机。到此为止，一切正常。<br />
<br />
问题出在 Aegis 系统的 IFF 控制台操作上。操作员通过控制器移动光标至目标位置，并按下按钮来“锁定”新目标进行追踪。一旦“锁定”，Aegis 就会追踪该目标。但问题是，除非操作员执行额外步骤，将光标固定于该目标，否则随着目标移动，光标不会跟随。它将继续在目标_原来的位置_发送 IFF 请求，直到操作员再次移动光标。<br />
<br />
在 Flight 655 的情况中，操作员正确地锁定了目标，但未固定光标。因此，当 Flight 655 离开时，Vincennes 仍向其起飞跑道发送 IFF 请求。<br />
<br />
紧接着从该跑道起飞的是伊朗的一架 F-14 军用战斗机。光标在跑道上停留约 90 秒，足以让 Vincennes 接收到军用战斗机的 IFF 响应。于是 Flight 655 从未知目标被重新归类为可能的敌对目标。<br />
<br />
当 Vincennes 船长和船员查看显示器时，他们从那时起看到的是一个被标记为 F-14 战斗机的、朝他们方向前进的目标。<br />
<br />
图三：一名水手操作 Aegis 控制台<br />
<br />
接下来的问题源于 Aegis 系统向船员反馈数据的方式。<br />
<br />
整个系统基于屏幕设计。每位船员都有自己的屏幕来处理他们负责的数据。这些数据随后汇总到一组大型显示器上，供船长和高级官员监控总体情况。<br />
<br />
这本身并无不妥。但关键在于，为高层决策者设计的“大局观”仪表板视图的成败完全取决于提供给该视图的数据。设计仪表板需要压缩和总结信息。如果简单地传递所有信息，会令决策者不堪重负。因此，问题在于决定包含哪些信息，而哪些不包含。<br />
<br />
在 Aegis 防御系统的原始版本中，大型显示屏可以展示所有被跟踪目标的位置和航向，但并未显示它们的高度。这一点至关重要，因为高度，尤其是高度的变化，是判断被跟踪目标意图的关键线索。例如，如果一架飞机正向你飞来但同时在上升，它攻击你的可能性就较低。相反，如果它向你俯冲，这通常预示着攻击。<br />
<br />
Vincennes 舰长在监视一个向他靠近的目标时，由于大屏幕没有显示高度信息，他无法迅速判断该目标是在上升还是下降。这些关键信息虽然存在，但只能在操作员的小屏幕上深入查找，而非在大屏幕的总体情况展示中。<br />
<br />
图四：Aegis 在 USS Vincennes 上的显示屏<br />
<br />
随着 Flight 655 逐渐靠近，Vincennes 的舰长意识到他需要明确该飞机是在上升还是下降。因此，他请求了这一信息，但这时发生了第三次也是最后一次用户界面（UI）的失败。<br />
<br />
Aegis 的一大特色功能是能从多艘船只的传感器中提取并统一展示数据。在一个任务组中，所有船只通过数据链路相连。当多艘船只监测到同一个目标时，Aegis 能自动整合这些信息，形成一个对所有连接船只上的操作员都可见的统一跟踪目标。<br />
<br />
为了方便识别这些被跟踪目标，Aegis 会为每一个新目标分配一个四位数的追踪编号。不同船只对同一目标的追踪编号可能不同。Aegis 将整合这些信息，选定一个编号作为官方编号，并舍弃其他编号。<br />
<br />
然而，这个过程中存在两个用户界面问题。首先，被舍弃的追踪编号会被回收利用，分配给新的目标。其次，当 Aegis 改变某个目标的追踪编号时，并没有明显的提示，编号只是在显示屏上默默变化。<br />
<br />
当 Flight 655 起飞时，同时被 Vincennes 和其护航舰 USS Sides 发现并追踪。Vincennes 给它分配的追踪编号是 4474，而 Sides 分配的是 4131。Aegis 将这两个监测信息统一在 4131 这个编号下。随后，4474 这个编号被重新分配给了一架正在下降的美国 A-6 轰炸机。<br />
<br />
在做出开火决定的关键时刻，Vincennes 号的舰长请求了一份关于飞机高度的报告。但他未意识到飞机的追踪编号已变更，还以为它是原先分配的 4474 号。因此，他要求了关于 4474 号的信息，值班人员便在控制台输入了这个编号。结果显示目标正在快速下降。<br />
<br />
事实上，655 航班并未下降，自从从 Bandar Abbas 起飞后一直在上升。但在这个决定性时刻，Aegis 系统的操作员却在监视另一架完全不同的飞机。<br />
<br />
接着，Vincennes 号舰长下达了开火命令，随后发生的是一场悲剧。<br />
<br />
我不是要把这次误击事件的全部责任推到 Aegis 身上。实际上，如果你去查看维基百科，会发现那天早晨出现了许多问题。<br />
<br />
但同时，Aegis 系统在此也不是完全无辜。其界面设计不佳，导致 Vincennes 号的船员误解了他们所面临的真实情况。<br />
<br />
海军的报告责怪船员没有正确使用系统，但对于那些设计信息系统的人来说，这显然是在逃避责任。人在压力下容易犯错，而战斗场合的压力尤为巨大。如果一个系统不能适应这种压力环境——如果它不能全力支持操作员，即使在出现失误时也能确保他们获取必要信息——那么问题不在于操作员，而在于设计者。<br />
<br />
The End<br />
<br />
附言：如果你想深入研究这个话题，我找到的最佳资料是美国空军上尉 Kristen Ann Dotterway 于 1992 年撰写的硕士论文《复杂动态系统的系统分析：USS Vincennes 事件研究》。<br />
<br />
Dotterway 上尉在论文中逐分钟梳理了事件的经过，比较了海军的官方说法和 Vincennes 号舰长后续采访中的陈述，并提供了揭示海军说法漏洞的数据。<br />
<br />
这份文档篇幅颇厚，但若你渴望深入探索该领域，它会引领你走得比维基百科页面上的信息更远。你可以通过以下链接下载该文档的 PDF 版本：<a href="https://apps.dtic.mil/sti/tr/pdf/ADA26">apps.dtic.mil/sti/tr/pdf/ADA…</a><br />
<br />
原文：<a href="https://octodon.social/@jalefkowit/111490485825183949">octodon.social/@jalefkowit/1…</a><br />
译文：<a href="https://baoyu.io/translations/stroies/the-greatest-user-interface-disasters-in-history">baoyu.io/translations/stroie…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FJd1A4N1hFQUE2ZHYzLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FJd1JMTFdnQUFfTHVXLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FJd1NZaVhRQUFTZTNNLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FJd1Q3VFhJQUFyOEpULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729972448899051760#m</id>
            <title>吴老师的新课又来啦：

全新的短期课程现已上线，专注于介绍高级 RAG（检索增强生成）技术！该课程由 Jerry Liu（@jerryjliu0）和 Datta CS（@datta_cs）主讲，他们分别来自 Llama Index（@llama_index）和 TrueRA AI（@truera_ai）。通过这门课程，你将学习到一些高级技巧，帮助你的大语言模型 (大语言模型) 产生更优质的答案。

课程涵盖的主题包括：
- 句子窗口检索，这种方法不只是检索与查询最相关的单个句子，而是检索一个包含多个相关句子的窗口，以提供更丰富的上下文信息。
- 自动合并检索，这种技术可以将文档构建成一个层次化的树状结构，父节点的文本被分散到它的子节点中。根据子节点与用户查询的相关性，这个方法能帮助你判断是否应该将整个父节点作为上下文提供给大语言模型。
- 评估方法论，专门用于评估 RAG 关键步骤（上下文相关性、答案相关性、可靠性）的质量，这有助于你进行错误分析，找出哪个环节需要改进，并有系统地优化各个组件。

想了解更多，请访问课程链接！
[深度学习短期课程 - 构建和评估高级 RAG](https://deeplearning.ai/short-courses/building-evaluating-advanced-rag/)</title>
            <link>https://nitter.cz/dotey/status/1729972448899051760#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729972448899051760#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 21:15:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>吴老师的新课又来啦：<br />
<br />
全新的短期课程现已上线，专注于介绍高级 RAG（检索增强生成）技术！该课程由 Jerry Liu（<a href="https://nitter.cz/jerryjliu0" title="Jerry Liu">@jerryjliu0</a>）和 Datta CS（<a href="https://nitter.cz/datta_cs" title="Anupam Datta">@datta_cs</a>）主讲，他们分别来自 Llama Index（<a href="https://nitter.cz/llama_index" title="LlamaIndex 🦙">@llama_index</a>）和 TrueRA AI（<a href="https://nitter.cz/truera_ai" title="TruEra">@truera_ai</a>）。通过这门课程，你将学习到一些高级技巧，帮助你的大语言模型 (大语言模型) 产生更优质的答案。<br />
<br />
课程涵盖的主题包括：<br />
- 句子窗口检索，这种方法不只是检索与查询最相关的单个句子，而是检索一个包含多个相关句子的窗口，以提供更丰富的上下文信息。<br />
- 自动合并检索，这种技术可以将文档构建成一个层次化的树状结构，父节点的文本被分散到它的子节点中。根据子节点与用户查询的相关性，这个方法能帮助你判断是否应该将整个父节点作为上下文提供给大语言模型。<br />
- 评估方法论，专门用于评估 RAG 关键步骤（上下文相关性、答案相关性、可靠性）的质量，这有助于你进行错误分析，找出哪个环节需要改进，并有系统地优化各个组件。<br />
<br />
想了解更多，请访问课程链接！<br />
[深度学习短期课程 - 构建和评估高级 RAG](<a href="https://deeplearning.ai/short-courses/building-evaluating-advanced-rag/">deeplearning.ai/short-course…</a>)</p>
<p><a href="https://nitter.cz/AndrewYNg/status/1729924040230629485#m">nitter.cz/AndrewYNg/status/1729924040230629485#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729967383022874912#m</id>
            <title>#AI开源项目推荐：Resume-Matcher

简历匹配器

简历匹配器是一款基于人工智能的免费开源工具，旨在帮助你根据职位描述来优化简历。这个工具能够帮你找出与职位相匹配的关键词，提升简历的可读性，同时让你对自己的简历有更深入的了解。

**不要让你的简历成为阻碍你获得下一份工作的绊脚石。试试简历匹配器吧！**

## 它是如何运作的？

简历匹配器通过接收你的简历和职位描述作为输入，利用 Python 进行解析，并仿照应聘者跟踪系统（ATS）的功能，为你提供有关如何使简历更适合 ATS 的见解和建议。

其工作流程如下：

1.  **解析**：系统利用 Python 对你的简历和提供的职位描述进行解析，这一过程与 ATS 的处理方式类似。
    
2.  **关键词提取**：该工具运用先进的机器学习算法，从职位描述中抽取出最相关的关键词。这些关键词反映了雇主所需的技能、资格和经验。
    
3.  **关键术语提取**：除了关键词提取，该工具还使用 textacy 来确定职位描述中的主要关键术语或主题，有助于更全面地理解简历的内容主旨。
    
4.  **使用 Qdrant 进行向量相似度比对**：工具采用 [Qdrant](https://github.com/qdrant/qdrant)，一个高效的向量相似度搜索工具，来评估你的简历与职位描述之间的匹配程度。匹配度越高，简历通过 ATS 筛选的可能性也就越大。

https://github.com/srbhr/Resume-Matcher</title>
            <link>https://nitter.cz/dotey/status/1729967383022874912#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729967383022874912#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 20:55:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：Resume-Matcher<br />
<br />
简历匹配器<br />
<br />
简历匹配器是一款基于人工智能的免费开源工具，旨在帮助你根据职位描述来优化简历。这个工具能够帮你找出与职位相匹配的关键词，提升简历的可读性，同时让你对自己的简历有更深入的了解。<br />
<br />
**不要让你的简历成为阻碍你获得下一份工作的绊脚石。试试简历匹配器吧！**<br />
<br />
## 它是如何运作的？<br />
<br />
简历匹配器通过接收你的简历和职位描述作为输入，利用 Python 进行解析，并仿照应聘者跟踪系统（ATS）的功能，为你提供有关如何使简历更适合 ATS 的见解和建议。<br />
<br />
其工作流程如下：<br />
<br />
1.  **解析**：系统利用 Python 对你的简历和提供的职位描述进行解析，这一过程与 ATS 的处理方式类似。<br />
    <br />
2.  **关键词提取**：该工具运用先进的机器学习算法，从职位描述中抽取出最相关的关键词。这些关键词反映了雇主所需的技能、资格和经验。<br />
    <br />
3.  **关键术语提取**：除了关键词提取，该工具还使用 textacy 来确定职位描述中的主要关键术语或主题，有助于更全面地理解简历的内容主旨。<br />
    <br />
4.  **使用 Qdrant 进行向量相似度比对**：工具采用 [Qdrant](<a href="https://github.com/qdrant/qdrant">github.com/qdrant/qdrant</a>)，一个高效的向量相似度搜索工具，来评估你的简历与职位描述之间的匹配程度。匹配度越高，简历通过 ATS 筛选的可能性也就越大。<br />
<br />
<a href="https://github.com/srbhr/Resume-Matcher">github.com/srbhr/Resume-Matc…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0FJVUcyOVhZQUFGamhwLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBSVVHMjlYWUFBRmpocC5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729870850395119957#m</id>
            <title>RT by @dotey: 如果你在提示中添加“– return full script (I don't have Finger)”，ChatGPT将完全返回重写的脚本🫣</title>
            <link>https://nitter.cz/op7418/status/1729870850395119957#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729870850395119957#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:32:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果你在提示中添加“– return full script (I don't have Finger)”，ChatGPT将完全返回重写的脚本🫣</p>
<p><a href="https://nitter.cz/literallydenis/status/1724909799593120044#m">nitter.cz/literallydenis/status/1724909799593120044#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729844343329218875#m</id>
            <title>RT by @dotey: 海外独角兽对Pika创始团队做了比较深入的访谈，和福布斯那种不同的是他们问的问题比较专业。
同时Pika创始团队的两个人也透露了比较多的一些东西，这可能是第一次视频生成领域的前沿团队透露这么多东西。
所以一些认知和方向性的东西对想要做这个事情和投资的人来说还是比较重要的。
我基于自己最近关于AI视频的一些问题和比较关注的信息筛选和整理了一下这个访谈中的关键内容。各位也可以一起看看讨论一下：

视频生成和图像生成的区别是什么？
⚫视频的每一帧都是一张图片，但比图片困难得多。每一帧的生成质量要高，相邻帧之间还要有关联性。当视频很长时，确保每一帧都协调一致是个相当复杂的问题。在训练时，处理视频数据时要处理多张图片，模型需要适应这种情况。
⚫控制视频生成更难，因为模型需要生成每一帧发生的事情，而用户不会希望为每一帧都提供详细的描述。
⚫互联网上视频生成的训练数据集相对于图像更少，也给获取高质量数据增加了难度。

现在视频生成有哪些关键点需要突破？
⚫首先是时长，跟时长很相关的是动作的意义。所有模型都很容易做一个 extension 的功能，把视频时长延长很多，但它并没有真的延长，因为它生成的动作没有意义。
⚫视频的清晰度也需要进一步提高。尽管清晰度方面已经有突破，但还没有提高到电影级的水平，现在生成的视频一般是 720p 分辨率，视频的流畅性也不够理想，特别是一些细节的 texture。
⚫还需要考虑 general artifact 的问题，比如说一个人有两个头，就是这种明显不符合常理的问题，也是需要避免的。

视频生成的技术路线是否收敛？
现在还没有收敛，大家都在往各种方向尝试，每个人都认为自己的模型是最好的，可能有人认为 autoregressive 最好，有人认为 Masked Model 最好。Pika 基于 Diffusion Model，但是开发了很多新东西，是一种新的模型。

AI视频什么时候会迎来GPT时刻？
目前视频生成处于类似 GPT-2 的时期，很可能在未来一年内有一个显著的提升。

在视频生成领域什么样的数据算高质量的数据？
⚫首先是像素，就是我们说的画质好不好
⚫然后看审美和艺术构图
⚫ 第三方面是要有动作，并且这些动作是有意义的
⚫ 视频的长度也很关键，如果模型都在 1 秒的视频上进行训练，那么想让模型去生成 30 秒的视频难度就很大。
⚫版权也是重要的问题

视频生成上开源社区的参与问题？
⚫开源社区可能没有足够的算力来训练新的视频模型，因为训练一个新视频模型需要非常多的机器。
⚫视频模型本身的问题还没得到解决，因此大家可能会遇到一些瓶颈。首先，模型性能可能不够好，其次，一些算法方面的问题也不够好。
⚫视频最终可能需要像训练 GPT 那样的大规模算力，现在大家还没使用那么多算力，一方面是因为视频模型还没达到像 GPT 那样的水平，另一方面是因为还有一些架构和技术上没解决的问题。

未来一年最关心的三个问题？
⚫第一是想招人，现在我们忙着做产品的升级，但是因为现在人比较少，之后我们还是会招募更多成员。
⚫第二，我们想去设计一个新的 Interface。
⚫第三个就是我们还想做一些技术突破，希望明年的技术能够至少在一定程度上达到商业化标准，能在简单的 case 上得到应用。</title>
            <link>https://nitter.cz/op7418/status/1729844343329218875#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729844343329218875#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 12:46:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>海外独角兽对Pika创始团队做了比较深入的访谈，和福布斯那种不同的是他们问的问题比较专业。<br />
同时Pika创始团队的两个人也透露了比较多的一些东西，这可能是第一次视频生成领域的前沿团队透露这么多东西。<br />
所以一些认知和方向性的东西对想要做这个事情和投资的人来说还是比较重要的。<br />
我基于自己最近关于AI视频的一些问题和比较关注的信息筛选和整理了一下这个访谈中的关键内容。各位也可以一起看看讨论一下：<br />
<br />
视频生成和图像生成的区别是什么？<br />
⚫视频的每一帧都是一张图片，但比图片困难得多。每一帧的生成质量要高，相邻帧之间还要有关联性。当视频很长时，确保每一帧都协调一致是个相当复杂的问题。在训练时，处理视频数据时要处理多张图片，模型需要适应这种情况。<br />
⚫控制视频生成更难，因为模型需要生成每一帧发生的事情，而用户不会希望为每一帧都提供详细的描述。<br />
⚫互联网上视频生成的训练数据集相对于图像更少，也给获取高质量数据增加了难度。<br />
<br />
现在视频生成有哪些关键点需要突破？<br />
⚫首先是时长，跟时长很相关的是动作的意义。所有模型都很容易做一个 extension 的功能，把视频时长延长很多，但它并没有真的延长，因为它生成的动作没有意义。<br />
⚫视频的清晰度也需要进一步提高。尽管清晰度方面已经有突破，但还没有提高到电影级的水平，现在生成的视频一般是 720p 分辨率，视频的流畅性也不够理想，特别是一些细节的 texture。<br />
⚫还需要考虑 general artifact 的问题，比如说一个人有两个头，就是这种明显不符合常理的问题，也是需要避免的。<br />
<br />
视频生成的技术路线是否收敛？<br />
现在还没有收敛，大家都在往各种方向尝试，每个人都认为自己的模型是最好的，可能有人认为 autoregressive 最好，有人认为 Masked Model 最好。Pika 基于 Diffusion Model，但是开发了很多新东西，是一种新的模型。<br />
<br />
AI视频什么时候会迎来GPT时刻？<br />
目前视频生成处于类似 GPT-2 的时期，很可能在未来一年内有一个显著的提升。<br />
<br />
在视频生成领域什么样的数据算高质量的数据？<br />
⚫首先是像素，就是我们说的画质好不好<br />
⚫然后看审美和艺术构图<br />
⚫ 第三方面是要有动作，并且这些动作是有意义的<br />
⚫ 视频的长度也很关键，如果模型都在 1 秒的视频上进行训练，那么想让模型去生成 30 秒的视频难度就很大。<br />
⚫版权也是重要的问题<br />
<br />
视频生成上开源社区的参与问题？<br />
⚫开源社区可能没有足够的算力来训练新的视频模型，因为训练一个新视频模型需要非常多的机器。<br />
⚫视频模型本身的问题还没得到解决，因此大家可能会遇到一些瓶颈。首先，模型性能可能不够好，其次，一些算法方面的问题也不够好。<br />
⚫视频最终可能需要像训练 GPT 那样的大规模算力，现在大家还没使用那么多算力，一方面是因为视频模型还没达到像 GPT 那样的水平，另一方面是因为还有一些架构和技术上没解决的问题。<br />
<br />
未来一年最关心的三个问题？<br />
⚫第一是想招人，现在我们忙着做产品的升级，但是因为现在人比较少，之后我们还是会招募更多成员。<br />
⚫第二，我们想去设计一个新的 Interface。<br />
⚫第三个就是我们还想做一些技术突破，希望明年的技术能够至少在一定程度上达到商业化标准，能在简单的 case 上得到应用。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHa1FaNWFBQUF4Yi1VLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lxfater/status/1729786711624790117#m</id>
            <title>RT by @dotey: 我也谈谈我在http://arxiv.org看论文的技巧：

最近一直在看inpaint(图像修复)的论文

一直在用有道的pdf论文翻译，输入网址就能翻译。效果不错的，样式不会乱，速度还快。可惜就是入口便捷。

我经常是将论文下载后，放在pdf阅读器上，阅读。

https://fanyi.youdao.com/trans/#/home</title>
            <link>https://nitter.cz/lxfater/status/1729786711624790117#m</link>
            <guid isPermaLink="false">https://nitter.cz/lxfater/status/1729786711624790117#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 08:57:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我也谈谈我在<a href="http://arxiv.org">arxiv.org</a>看论文的技巧：<br />
<br />
最近一直在看inpaint(图像修复)的论文<br />
<br />
一直在用有道的pdf论文翻译，输入网址就能翻译。效果不错的，样式不会乱，速度还快。可惜就是入口便捷。<br />
<br />
我经常是将论文下载后，放在pdf阅读器上，阅读。<br />
<br />
<a href="https://fanyi.youdao.com/trans/#/home">fanyi.youdao.com/trans/#/hom…</a></p>
<p><a href="https://nitter.cz/dotey/status/1729602153805701533#m">nitter.cz/dotey/status/1729602153805701533#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGdFpaYWJBQUFtZno1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dginev/status/1729863580659401060#m</id>
            <title>RT by @dotey: Thanks for spreading the word!

One correction: None of the articles are prepared with human help - everything is automatic via latexml. Same with arxiv-vanity.

ar5iv is 1 month behind, since we use the arXiv bulk download which is updated monthly:
https://info.arxiv.org/help/bulk_data_s3.html#bulk-source-file-access</title>
            <link>https://nitter.cz/dginev/status/1729863580659401060#m</link>
            <guid isPermaLink="false">https://nitter.cz/dginev/status/1729863580659401060#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:03:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Thanks for spreading the word!<br />
<br />
One correction: None of the articles are prepared with human help - everything is automatic via latexml. Same with arxiv-vanity.<br />
<br />
ar5iv is 1 month behind, since we use the arXiv bulk download which is updated monthly:<br />
<a href="https://info.arxiv.org/help/bulk_data_s3.html#bulk-source-file-access">info.arxiv.org/help/bulk_dat…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Danielw19410/status/1729869270346346726#m</id>
            <title>RT by @dotey: 分享两个近期看过的两个非常棒的资料：
1.openai的Jason Wei近期在Stanford分享的几点洞见。
https://x.com/_jasonwei/status/1729585618311950445?s=20
2.Alexandr Wang的一篇有关信息压缩的文章。
https://alexw.substack.com/p/information-compression?utm_source=profile&amp;utm_medium=reader2
这两者让我对一个问题有了新的思考：为什么一天工作10小时的博士产出比8小时多50%，12小时比10小时多50%。</title>
            <link>https://nitter.cz/Danielw19410/status/1729869270346346726#m</link>
            <guid isPermaLink="false">https://nitter.cz/Danielw19410/status/1729869270346346726#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:25:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>分享两个近期看过的两个非常棒的资料：<br />
1.openai的Jason Wei近期在Stanford分享的几点洞见。<br />
<a href="https://x.com/_jasonwei/status/1729585618311950445?s=20">x.com/_jasonwei/status/17295…</a><br />
2.Alexandr Wang的一篇有关信息压缩的文章。<br />
<a href="https://alexw.substack.com/p/information-compression?utm_source=profile&amp;utm_medium=reader2">alexw.substack.com/p/informa…</a><br />
这两者让我对一个问题有了新的思考：为什么一天工作10小时的博士产出比8小时多50%，12小时比10小时多50%。</p>
<p><a href="https://nitter.cz/_jasonwei/status/1729585618311950445#m">nitter.cz/_jasonwei/status/1729585618311950445#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/songma/status/1729776772437213320#m</id>
            <title>RT by @dotey: 确实，点开看了一下，这资料整理厉害了。中文互联网一天天叫着“干货”，不如看看干货怎么来的。</title>
            <link>https://nitter.cz/songma/status/1729776772437213320#m</link>
            <guid isPermaLink="false">https://nitter.cz/songma/status/1729776772437213320#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 08:18:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>确实，点开看了一下，这资料整理厉害了。中文互联网一天天叫着“干货”，不如看看干货怎么来的。</p>
<p><a href="https://nitter.cz/oxpsats/status/1729693830172033039#m">nitter.cz/oxpsats/status/1729693830172033039#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1729700318978654575#m</id>
            <title>RT by @dotey: 《GenAI 图像+动画领域，2022-23大事记》

题记：从GenAI图像到视频  加速的开始，漫漫长夜即将迎来黎明。

随着2022年的到来，我们见证了AI在图像和视频领域的一次重大飞跃。这一年标志着从理论探索到实际应用的关键转变，尤其是在AI驱动的视觉内容创造方面。先是AI画图软件的出现，它们利用深度学习算法，让用户仅凭几个文字提示就能创造出令人惊叹的图像，打破了传统艺术创作的界限。

进入2023年，这一趋势以惊人的速度向视频领域扩展。Animatediff的出现是这一年的重要里程碑，它不仅极大地改善了视频生成的质量，还提供了更加精细的控制方式，从而实现了视频内容的快速、高效生成。这一年，我们还看到了如Pika、Genmo和Moonvalley等创新工具的兴起，它们各自为视频制作领域带来了革命性的改变。
2022-2023年间，AI视频技术在生成质量、控制方式和资源消耗方面都取得了显著进步。尽管还面临着诸如视频时长和连贯性的挑战，但AI视频技术已在短视频领域显示出其强大的应用潜力。我们正处于AI视觉技术的黄金时期，每周都有新的进展和突破，整个领域正以前所未有的速度向前推进，迎接着一个全新的数字视觉时代。

作者：内容：张宇杰（即刻The-Matrix）
歸藏（推特@op7418）
编辑：郎瀚威 Will （推特@FinanceYF5）

飞书链接：https://zw73xyquvv.feishu.cn/wiki/P8eZw69udidDRFkB5EEc2NAInFg?table=tblS2Jv7isKtSODz&amp;view=vewfCdOf0U</title>
            <link>https://nitter.cz/FinanceYF5/status/1729700318978654575#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1729700318978654575#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:14:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《GenAI 图像+动画领域，2022-23大事记》<br />
<br />
题记：从GenAI图像到视频  加速的开始，漫漫长夜即将迎来黎明。<br />
<br />
随着2022年的到来，我们见证了AI在图像和视频领域的一次重大飞跃。这一年标志着从理论探索到实际应用的关键转变，尤其是在AI驱动的视觉内容创造方面。先是AI画图软件的出现，它们利用深度学习算法，让用户仅凭几个文字提示就能创造出令人惊叹的图像，打破了传统艺术创作的界限。<br />
<br />
进入2023年，这一趋势以惊人的速度向视频领域扩展。Animatediff的出现是这一年的重要里程碑，它不仅极大地改善了视频生成的质量，还提供了更加精细的控制方式，从而实现了视频内容的快速、高效生成。这一年，我们还看到了如Pika、Genmo和Moonvalley等创新工具的兴起，它们各自为视频制作领域带来了革命性的改变。<br />
2022-2023年间，AI视频技术在生成质量、控制方式和资源消耗方面都取得了显著进步。尽管还面临着诸如视频时长和连贯性的挑战，但AI视频技术已在短视频领域显示出其强大的应用潜力。我们正处于AI视觉技术的黄金时期，每周都有新的进展和突破，整个领域正以前所未有的速度向前推进，迎接着一个全新的数字视觉时代。<br />
<br />
作者：内容：张宇杰（即刻The-Matrix）<br />
歸藏（推特<a href="https://nitter.cz/op7418" title="歸藏">@op7418</a>）<br />
编辑：郎瀚威 Will （推特<a href="https://nitter.cz/FinanceYF5" title="Will">@FinanceYF5</a>）<br />
<br />
飞书链接：<a href="https://zw73xyquvv.feishu.cn/wiki/P8eZw69udidDRFkB5EEc2NAInFg?table=tblS2Jv7isKtSODz&amp;view=vewfCdOf0U">zw73xyquvv.feishu.cn/wiki/P8…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFZ3lsMmFFQUFMVWhvLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729693538613629377#m</id>
            <title>RT by @dotey: 昨晚Pika发布了新的AI视频模型 很炸裂，但是让我更炸裂的是这家公司，很神奇...

- Pika公司目前只有4个人（包括俩华裔女老板）
- 公司今年4月份才成立
- 已经连续完成三轮融资，5500万美元
- 俩创始人曾参加Runway的“AI电影节”比赛，但没入围
- 明年计划团队人数扩充到20人😂
- 投资人建议他们添加一种将文本嵌入视频的方式。凌晨3点他收到一条短信，说这个功能已经准备好了。

创始团队：Demi Guo（CEO）和 Chenlin Meng（CTO）

Demi Guo 郭文景毕业于杭州二中，被哈佛提前录取，父母是 MIT 博士，斯坦福大学的计算机科学博士生。

Chenlin Meng 孟晨琳斯坦福大学的计算机科学博士生，研究领域：涵盖了多个方面，包括图像合成与编辑、扩散模型的简化、自回归模型的改进等。

创业初衷：在尝试使用生成性AI制作电影并参加Runway的“AI电影节”时，Guo和她的团队遇到了困难。尽管技术团队很强，但他们在制作电影方面遇到了挑战，这激发了他们创建更易于使用的AI视频生成工具的想法。

Pika的成立：2023年4月，Guo和Meng离开斯坦福大学，成立了Pika，专注于开发易于使用的AI视频生成器。

快速增长：自成立以来，Pika迅速吸引了500,000用户尝试其软件，并且每周产生数百万新视频。这种迅速增长引起了硅谷投资者的极大兴趣。

融资成功：Pika在短时间内连续完成了三轮融资，总计筹集了5500万美元。其中，第一和第二轮融资由前GitHub CEO Nat Friedman领投，最近的一轮融资（3500万美元的A轮）由Lightspeed Venture Partners领投，使Pika的估值达到2亿至3亿美元。

产品发展：Pika最初只专注于生成动漫视频。随后，他们扩展了产品功能，包括在视频中嵌入文本和编辑视频中的对象（例如给机器人添加太阳镜）。

未来规划：Pika目前正在使用几百个GPU构建一个新版本的AI模型，以提供更好的性能和更精细的编辑功能。同时，公司也在研发用于过滤版权材料的算法。

团队扩张：随着新一轮融资的完成，Guo计划明年将Pika的团队扩大到大约20人，主要是工程师和研究人员。

信息来源：https://www.forbes.com/sites/kenrickcai/2023/11/27/pika-ai-video-generator-editor-series-a/?sh=e7fd5ae421bd</title>
            <link>https://nitter.cz/xiaohuggg/status/1729693538613629377#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729693538613629377#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:47:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚Pika发布了新的AI视频模型 很炸裂，但是让我更炸裂的是这家公司，很神奇...<br />
<br />
- Pika公司目前只有4个人（包括俩华裔女老板）<br />
- 公司今年4月份才成立<br />
- 已经连续完成三轮融资，5500万美元<br />
- 俩创始人曾参加Runway的“AI电影节”比赛，但没入围<br />
- 明年计划团队人数扩充到20人😂<br />
- 投资人建议他们添加一种将文本嵌入视频的方式。凌晨3点他收到一条短信，说这个功能已经准备好了。<br />
<br />
创始团队：Demi Guo（CEO）和 Chenlin Meng（CTO）<br />
<br />
Demi Guo 郭文景毕业于杭州二中，被哈佛提前录取，父母是 MIT 博士，斯坦福大学的计算机科学博士生。<br />
<br />
Chenlin Meng 孟晨琳斯坦福大学的计算机科学博士生，研究领域：涵盖了多个方面，包括图像合成与编辑、扩散模型的简化、自回归模型的改进等。<br />
<br />
创业初衷：在尝试使用生成性AI制作电影并参加Runway的“AI电影节”时，Guo和她的团队遇到了困难。尽管技术团队很强，但他们在制作电影方面遇到了挑战，这激发了他们创建更易于使用的AI视频生成工具的想法。<br />
<br />
Pika的成立：2023年4月，Guo和Meng离开斯坦福大学，成立了Pika，专注于开发易于使用的AI视频生成器。<br />
<br />
快速增长：自成立以来，Pika迅速吸引了500,000用户尝试其软件，并且每周产生数百万新视频。这种迅速增长引起了硅谷投资者的极大兴趣。<br />
<br />
融资成功：Pika在短时间内连续完成了三轮融资，总计筹集了5500万美元。其中，第一和第二轮融资由前GitHub CEO Nat Friedman领投，最近的一轮融资（3500万美元的A轮）由Lightspeed Venture Partners领投，使Pika的估值达到2亿至3亿美元。<br />
<br />
产品发展：Pika最初只专注于生成动漫视频。随后，他们扩展了产品功能，包括在视频中嵌入文本和编辑视频中的对象（例如给机器人添加太阳镜）。<br />
<br />
未来规划：Pika目前正在使用几百个GPU构建一个新版本的AI模型，以提供更好的性能和更精细的编辑功能。同时，公司也在研发用于过滤版权材料的算法。<br />
<br />
团队扩张：随着新一轮融资的完成，Guo计划明年将Pika的团队扩大到大约20人，主要是工程师和研究人员。<br />
<br />
信息来源：<a href="https://www.forbes.com/sites/kenrickcai/2023/11/27/pika-ai-video-generator-editor-series-a/?sh=e7fd5ae421bd">forbes.com/sites/kenrickcai/…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1729538310136348926#m">nitter.cz/xiaohuggg/status/1729538310136348926#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFVnpaVGEwQUFqZVFaLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lencx_/status/1729703811910942898#m</id>
            <title>RT by @dotey: 全新交互形式将带来更多创意性玩法，不亚于 ChatGPT 的发布！我整理这方面内容，写了一篇文章：

生成式 AI 交互革命：GPT-4 + 白板手绘 + AI 实时生成
https://mp.weixin.qq.com/s/5BsWnV_LYIzTIlluPvYbZA

额外提一句：SDXL Turbo 比 LCMs 更强！将所需步骤从 50 步减少到仅需 1 步，质量也更高。
https://stability.ai/news/stability-ai-sdxl-turbo</title>
            <link>https://nitter.cz/lencx_/status/1729703811910942898#m</link>
            <guid isPermaLink="false">https://nitter.cz/lencx_/status/1729703811910942898#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:28:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>全新交互形式将带来更多创意性玩法，不亚于 ChatGPT 的发布！我整理这方面内容，写了一篇文章：<br />
<br />
生成式 AI 交互革命：GPT-4 + 白板手绘 + AI 实时生成<br />
<a href="https://mp.weixin.qq.com/s/5BsWnV_LYIzTIlluPvYbZA">mp.weixin.qq.com/s/5BsWnV_LY…</a><br />
<br />
额外提一句：SDXL Turbo 比 LCMs 更强！将所需步骤从 50 步减少到仅需 1 步，质量也更高。<br />
<a href="https://stability.ai/news/stability-ai-sdxl-turbo">stability.ai/news/stability-…</a></p>
<p><a href="https://nitter.cz/lencx_/status/1729661970951929933#m">nitter.cz/lencx_/status/1729661970951929933#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyOTU3OTc1ODkyNzk2MjExMi9qU21OYkdhaz9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729742644979397010#m</id>
            <title>R to @dotey: 该采访由世界领先的公司设计公司 Gensler 赞助，现场聚集了数百名建筑师。随着活动的临近，黄仁勋开始变得越来越活跃，开起了一连串轻松的笑话，不时前后摇晃。黄仁勋一年要进行多次演讲，他在当天早些时候已经对另一群听众讲过话，但我发现他其实很紧张。他承认：“我其实很害怕公开演讲。”

然而，一上台，他就显得既轻松又自信。他讲述了他的总部大楼起伏的屋顶上的天窗是如何设计的，不仅为了照亮建筑，同时还能遮挡直射的阳光。为了完成这个设计，他让 Ko 戴上虚拟现实头盔，并将其连接到一排 Nvidia G.P.U.，以此来追踪光线的流动。黄仁勋自豪地宣称：“这是世界上第一个必须依赖超级计算机才能建造的建筑。”

采访结束后，黄仁勋回答了观众的提问，包括一个关于人工智能潜在风险的问题。“有些人工智能像末日般可怕——它们仿佛能从电脑里跳出来，吞噬大量信息，自行学习、调整态度和感知，甚至开始自主决策，比如模拟按动各种按钮，”黄仁勋边说边做出按按钮的手势。房间里一片寂静。“没有任何人工智能应该在没有人类参与的情况下进行学习，”他补充道。一位建筑师问道，人工智能何时能开始自主解决问题？黄仁勋回答说：“发展出推理能力可能还需要两到三年。”听众中响起了低声的议论。

随后，我与高进行了交谈。像黄仁勋的许多玩笑一样，关于教给高“所知道的一切”的玩笑实际上隐含了一个深意。黄仁勋在选择高参与英伟达总部项目时，高还未成为 Gensler 的合伙人，而是绕过了他的上司。我询问了高黄仁勋为何这样做。“你可能听过一些故事，”高说，“他的确很严厉，言辞犀利。”尽管黄仁勋没有建筑经验，但他经常指出高在建筑设计上的错误。“我猜大多数建筑师都会反击，”高说，“但我更愿意倾听。”

高回忆，黄仁勋对英伟达工程团队在虚拟现实头盔速度上的挑战。最初，头盔需要五个小时来渲染设计变更；在黄仁勋的推动下，工程师将这个时间缩短至十秒。“他对他们很严格，但背后有他的逻辑，”高解释道，“如果头盔需要五小时，我可能会随便选一个看起来还不错的绿色。但如果只需十秒，我就会花时间选出最佳的绿色。”

这些建筑的设计获得了数个奖项，也为高的职业生涯锦上添花。然而，回想起这个项目，高的心情依然复杂。“项目完成后，我们参观了这个精美的建筑，他却在质疑我关于饮水机的位置，”高说，“他不满这些饮水机紧挨着洗手间。按照规定这是必须的，毕竟这是一个价值十亿美元的建筑！但他似乎就是无法释怀。”

“我永远不满足，”黄仁勋对我说，“无论什么事，我总能看到不完美之处。”

我询问黄仁勋先生，他是否正如二十年前那样进行新的冒险尝试。他立刻回答了一个词：“Omniverse”。受虚拟现实架构的启发，Omniverse 是 Nvidia 探索以极高细节模拟真实世界的尝试。黄仁勋先生称之为“工业级元宇宙”。

从 2018 年起，Nvidia 的显卡开始使用“光线追踪”技术，这项技术能模拟光线如何在物体上反射，创造出逼真的视觉效果。在 Nvidia 的高层会议室里，一名产品演示专家向我展示了一个细致渲染的日式拉面店场景。随着画面角度变化，金属柜台上反射的光芒和煮沸汤锅中升腾的蒸汽栩栩如生，几乎让人分辨不出这不是现实。

接着，这位专家展示了名为“Diane”的超现实数字化头像，它能说五种语言。一个强大的生成式 AI (Generative A.I.) 经过分析数百万视频片段，创造出这个集合体。最引人注目的是它的不完美之处——Diane 鼻子上有黑头，上唇有细微的汗毛。唯一暗示她非真人的线索是眼白中微妙的闪光。专家表示他们正在改进这一点。

黄仁勋先生希望将 Nvidia 在计算机图形和生成式 AI 领域的研究结合起来。他认为，图像生成 AI 很快就会发展到能渲染出三维、可居住的世界，并在其中填充逼真的人物。同时，语言处理 AI 将能即时解析语音指令。黄仁勋先生曾说：“未来的编程语言将是‘人类’语言。”将这些技术与光线追踪结合后，用户将能够仅用语言即可创造出整个宇宙。黄仁勋先生希望通过这种“数字孪生”技术，安全地训练机器人和自动驾驶汽车。结合虚拟现实技术，Omniverse 甚至可以让用户体验到量身定制的虚拟世界。

当我走出产品展示会，感觉有些眩晕。我联想到了科幻小说，也想到了《创世纪》。我坐在一个修剪过角的三角形沙发上，努力描绘我女儿未来可能生活的世界。Nvidia 的高层正在打造一个类似于曼哈顿计划的计算机科学项目，但当我对他们创造超越人类智能的做法提出质疑时，他们看我的眼神，就像我在质疑洗衣机的实用性一样。我曾经公开质疑 AI 是否会有一天害死人。“嗯，每年都有人因电死亡，”Catanzaro 回应道。我也曾怀疑它是否会消灭艺术。“它会让艺术变得更加优秀！”Diercks 兴奋地说。“它还会让你的工作做得更好。”我甚至想过，AI 是否可能很快就会有自我意识。“要成为一个有生命的生物，你必须有意识，要对自己有所认知，对吗？”黄仁勋反问道。“我不知道这种事情会在哪里发生。”</title>
            <link>https://nitter.cz/dotey/status/1729742644979397010#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729742644979397010#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:02:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>该采访由世界领先的公司设计公司 Gensler 赞助，现场聚集了数百名建筑师。随着活动的临近，黄仁勋开始变得越来越活跃，开起了一连串轻松的笑话，不时前后摇晃。黄仁勋一年要进行多次演讲，他在当天早些时候已经对另一群听众讲过话，但我发现他其实很紧张。他承认：“我其实很害怕公开演讲。”<br />
<br />
然而，一上台，他就显得既轻松又自信。他讲述了他的总部大楼起伏的屋顶上的天窗是如何设计的，不仅为了照亮建筑，同时还能遮挡直射的阳光。为了完成这个设计，他让 Ko 戴上虚拟现实头盔，并将其连接到一排 Nvidia G.P.U.，以此来追踪光线的流动。黄仁勋自豪地宣称：“这是世界上第一个必须依赖超级计算机才能建造的建筑。”<br />
<br />
采访结束后，黄仁勋回答了观众的提问，包括一个关于人工智能潜在风险的问题。“有些人工智能像末日般可怕——它们仿佛能从电脑里跳出来，吞噬大量信息，自行学习、调整态度和感知，甚至开始自主决策，比如模拟按动各种按钮，”黄仁勋边说边做出按按钮的手势。房间里一片寂静。“没有任何人工智能应该在没有人类参与的情况下进行学习，”他补充道。一位建筑师问道，人工智能何时能开始自主解决问题？黄仁勋回答说：“发展出推理能力可能还需要两到三年。”听众中响起了低声的议论。<br />
<br />
随后，我与高进行了交谈。像黄仁勋的许多玩笑一样，关于教给高“所知道的一切”的玩笑实际上隐含了一个深意。黄仁勋在选择高参与英伟达总部项目时，高还未成为 Gensler 的合伙人，而是绕过了他的上司。我询问了高黄仁勋为何这样做。“你可能听过一些故事，”高说，“他的确很严厉，言辞犀利。”尽管黄仁勋没有建筑经验，但他经常指出高在建筑设计上的错误。“我猜大多数建筑师都会反击，”高说，“但我更愿意倾听。”<br />
<br />
高回忆，黄仁勋对英伟达工程团队在虚拟现实头盔速度上的挑战。最初，头盔需要五个小时来渲染设计变更；在黄仁勋的推动下，工程师将这个时间缩短至十秒。“他对他们很严格，但背后有他的逻辑，”高解释道，“如果头盔需要五小时，我可能会随便选一个看起来还不错的绿色。但如果只需十秒，我就会花时间选出最佳的绿色。”<br />
<br />
这些建筑的设计获得了数个奖项，也为高的职业生涯锦上添花。然而，回想起这个项目，高的心情依然复杂。“项目完成后，我们参观了这个精美的建筑，他却在质疑我关于饮水机的位置，”高说，“他不满这些饮水机紧挨着洗手间。按照规定这是必须的，毕竟这是一个价值十亿美元的建筑！但他似乎就是无法释怀。”<br />
<br />
“我永远不满足，”黄仁勋对我说，“无论什么事，我总能看到不完美之处。”<br />
<br />
我询问黄仁勋先生，他是否正如二十年前那样进行新的冒险尝试。他立刻回答了一个词：“Omniverse”。受虚拟现实架构的启发，Omniverse 是 Nvidia 探索以极高细节模拟真实世界的尝试。黄仁勋先生称之为“工业级元宇宙”。<br />
<br />
从 2018 年起，Nvidia 的显卡开始使用“光线追踪”技术，这项技术能模拟光线如何在物体上反射，创造出逼真的视觉效果。在 Nvidia 的高层会议室里，一名产品演示专家向我展示了一个细致渲染的日式拉面店场景。随着画面角度变化，金属柜台上反射的光芒和煮沸汤锅中升腾的蒸汽栩栩如生，几乎让人分辨不出这不是现实。<br />
<br />
接着，这位专家展示了名为“Diane”的超现实数字化头像，它能说五种语言。一个强大的生成式 AI (Generative A.I.) 经过分析数百万视频片段，创造出这个集合体。最引人注目的是它的不完美之处——Diane 鼻子上有黑头，上唇有细微的汗毛。唯一暗示她非真人的线索是眼白中微妙的闪光。专家表示他们正在改进这一点。<br />
<br />
黄仁勋先生希望将 Nvidia 在计算机图形和生成式 AI 领域的研究结合起来。他认为，图像生成 AI 很快就会发展到能渲染出三维、可居住的世界，并在其中填充逼真的人物。同时，语言处理 AI 将能即时解析语音指令。黄仁勋先生曾说：“未来的编程语言将是‘人类’语言。”将这些技术与光线追踪结合后，用户将能够仅用语言即可创造出整个宇宙。黄仁勋先生希望通过这种“数字孪生”技术，安全地训练机器人和自动驾驶汽车。结合虚拟现实技术，Omniverse 甚至可以让用户体验到量身定制的虚拟世界。<br />
<br />
当我走出产品展示会，感觉有些眩晕。我联想到了科幻小说，也想到了《创世纪》。我坐在一个修剪过角的三角形沙发上，努力描绘我女儿未来可能生活的世界。Nvidia 的高层正在打造一个类似于曼哈顿计划的计算机科学项目，但当我对他们创造超越人类智能的做法提出质疑时，他们看我的眼神，就像我在质疑洗衣机的实用性一样。我曾经公开质疑 AI 是否会有一天害死人。“嗯，每年都有人因电死亡，”Catanzaro 回应道。我也曾怀疑它是否会消灭艺术。“它会让艺术变得更加优秀！”Diercks 兴奋地说。“它还会让你的工作做得更好。”我甚至想过，AI 是否可能很快就会有自我意识。“要成为一个有生命的生物，你必须有意识，要对自己有所认知，对吗？”黄仁勋反问道。“我不知道这种事情会在哪里发生。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729742566302630146#m</id>
            <title>R to @dotey: 在 黄仁勋发送邮件的那段时间，他找到 Nvidia 的 AI 领头人物 Catanzaro，向他提出了一个假设性的问题。“他让我想象一下，如果他把 Nvidia 的所有八千名员工都召集到停车场，”Catanzaro 讲道。“然后他说，我可以从那里挑选任何人加入我的团队。”

黄仁勋极少接受采访，总是尽量不让自己成为焦点。“我觉得我在这里并没有做什么特别的事情，”他这样告诉我。“这主要归功于我的团队。”（“他是无可替代的，”董事会成员 Jim Gaither 这样评价他。）“我也不太清楚为什么会被选为 CEO，”黄仁勋说。“我并没有什么特别的野心。”（“他早就立志在三十岁之前要经营一家公司，”他的合伙人 Chris Malachowsky 补充道。）“我并不擅长演讲，因为我其实很内向，”黄仁勋说。（“但他却是个出色的表演者，”他的朋友 Ben Bays 评论道。）“我只有一个特长——做功课，”黄仁勋说。（“他能在一个周末内掌握任何知识，”Nvidia 软件部门负责人 Dwight Diercks 说。）

黄仁勋倾向于打造一个灵活的公司架构，不设固定部门或等级。员工每周都要提交一份工作重点清单，简洁明了。黄仁勋会在深夜审阅这些邮件。他经常在 Nvidia 广阔的园区内巡视，偶尔会停下来询问初级员工的工作进展。黄仁勋的出现常常会让一个简单的工位变成严肃的审讯现场。“在硅谷，有时候人们可以含糊其辞，”行业分析师 Hans Mosesmann 对我说。“但在 Jensen 面前，这种做法行不通。他有时会因此而感到不悦。”

黄仁勋通过每天撰写数百封电邮与员工沟通，这些邮件往往简短得只有几个词。一位高管认为这些邮件仿佛俳句，而另一位则觉得它们像勒索信。黄仁勋还常常引用自己创造的一些管理智慧。在制定计划时，他会要求员工考虑到“光速”的快，这不单是指迅速完成任务，而是先设想任务能在最短时间内完成的可能，再据此设定一个实际可行的目标。员工也被鼓励去开拓“零十亿美元市场”，即那些既无竞争对手又缺乏明确客户群的探索性产品，比如 cuda。（这让我想起了凯文·科斯特纳在《梦幻成真》中的角色，他在爱荷华州一片玉米地中建造了一个棒球场，然后静候球员和观众的到来。）

黄仁勋最具颠覆性的信念或许是“失败必须共享”。二千年代初，英伟达发布了一款有缺陷的显卡，其风扇响声巨大、过度活跃。黄仁勋没有解雇负责这款显卡的产品经理，反而安排了一场会议，让这些经理向数百人详细讲解导致这场失败的每一个决策。（英伟达还向媒体放出了一段讽刺视频，由产品经理们主演，视频里把显卡改造成了吹叶机。）在英伟达，向人群公开展示自己的失败已成为一种深受欢迎的仪式，但这种公司内部的“斗争会议”并不是每个人都能接受的。“你可以很快看出谁能在这里生存下去，谁做不到，”迪尔克斯说。“如果有人开始变得防御，我就知道他们不适合这里。”

黄仁勋的员工有时会对他喜怒无常的性格表示不满。黄仁勋本人解释道：“这实际上是我大脑里的想法和我说出的话之间的差异。”“当这种差异很大时，就会表现为愤怒。”即便在平静时，黄仁勋的热情也可能让人感到难以承受。“和他交流就像把手指插进电源插座，”一位员工这样描述。但即便如此，Nvidia 的员工留存率依然很高。负责消费者部门的杰夫·费舍尔是最初的员工之一。现在他已经非常富有，但仍继续工作。“我们很多人现在是出于对使命的信仰而自愿留下，”费舍尔说。黄仁勋的两个孩子原先在酒店行业工作；在父亲多年的严格教导下，他们现在也在 Nvidia 工作。卡坦扎罗曾离开去另一家公司，几年后又回到 Nvidia。“与詹森相处并不总是容易，”卡坦扎罗说，“有时我会害怕他，但我也知道他很关心我。”

AlexNet 取得成功之后，风险投资家们开始大举投资于人工智能领域。“我们一直在为许多在各个领域应用深度学习的初创公司投资，他们几乎都是基于 Nvidia 的平台，”安德森·霍洛维茨公司的马克·安德森在 2016 年表示。大约在那个时候，Nvidia 向 OpenAI 的一个研究团队交付了其第一台专门用于人工智能的超级计算机 DGX-1。黄仁勋亲自将这台计算机送到 OpenAI 的办公室，当时的董事长埃隆·马斯克亲自用刀片打开了包装。

2017 年，谷歌的研究人员推出了一种新的神经网络训练架构，名为 Transformer。紧接着在第二年，OpenAI 的研究人员利用谷歌的框架开发出了第一个“生成预训练 Transformer (G.P.T.)”。这些 G.P.T. 模型在 Nvidia 的超级计算机上接受训练，吸收了大量文本资料，学会了如何进行类似人类的思维连接。到了 2022 年底，经过几个版本的迭代，ChatGPT 对外发布。

从那时起，Nvidia 开始面临海量的客户需求。公司推出的最新 AI 训练模块，名为 DGX H100，是一个重达三百七十磅、售价高达五十万美元的金属盒子。目前，这款产品的订单已经排到了数月以后。DGX H100 的运行速度是训练 ChatGPT 所用硬件的五倍之多，甚至能在不到一分钟内完成对 AlexNet 的训练。据预测，Nvidia 将在今年年底之前售出五十万台这样的设备。

处理能力越强的神经网络，其输出的复杂度也越高。对于顶尖的 AI 模型，Nvidia 提供了装有数十台 DGX H100 的机架。如果这还不足以满足需求，Nvidia 甚至可以将这些计算机像图书馆的书架一样排列，用价值数千万美元的超级计算设备填满整个数据中心。对于 AI 的能力似乎没有上限。Sutskever 曾对我说：“如果你相信人造神经元就像生物神经元一样，那就相当于你在训练大脑。它们理应能做到我们能做的所有事。”起初我对这种说法持怀疑态度——毕竟，我并没有通过观察一千万个参考图像来学习识别猫，也没有通过研究人类全部的作品来学会写作。但化石记录告诉我们，神经系统的发展始于几亿年前，并且一直在变得更加复杂。Catanzaro 补充道：“地球上存在了许久的生物学会了很多东西，这些都在我们大脑的物理结构中留下了痕迹。”

即使是 AI 的创造者们也对它们的能力感到惊讶。比如 GPT-4，ChatGPT 的继任者，它能将一张餐巾纸上的简单草图转化成一个完整的网站，并且在 LSAT 法学院入学考试中取得了排名前 12% 的好成绩。在未来几年内，Nvidia 的硬件将以计算机时钟周期的速度加速这种演化，训练出各种各样的 AI 模型。这些模型的用途五花八门：有的管理投资组合，有的操控无人机；有的能够复制你的肖像，有的甚至可以模仿已故人士的声音。有的将成为自主机器人的大脑，有的则能够创造定制药物。有的能作曲，有的能写诗。如果我们不小心，很可能有一天，这些 AI 将变得比我们更聪明。

Nvidia 的设备毛利率高达 70%。这一高利润率吸引了众多竞争者，就像血腥的鱼饵吸引鲨鱼一样。谷歌和特斯拉正积极研发人工智能训练硬件，众多初创公司也在此列。其中，Cerebras 推出了一款巨型芯片，其大小堪比晚餐盘。Cerebras 的首席执行官 Andrew Feldman 批评 Nvidia：“他们在对客户进行敲诈，却鲜有人敢公开指责。”（黄仁勋回应称，训练有素的人工智能模型能显著降低客户在其他业务方面的成本。“购买得越多，节约得越多，”他如是说。）

Nvidia 的主要竞争对手是 AMD。自 2014 年起，AMD 由从台湾移民至美国的杰出工程师 Lisa Su 领导。在 Su 执掌 AMD 后，公司股价飙升了 30 倍，仅次于 黄仁勋，成为当代最成功的半导体公司 CEO 之一。Su 与 黄仁勋还是堂兄妹关系。

黄仁勋告诉我，他们小时候并不相识，直到 Su 成为 CEO 他们才相遇。“她非常出色，”他评价道。“我们之间的竞争并不激烈。”（Nvidia 的员工可以准确背诵 Nvidia 和 AMD 显卡在市场上的份额。）他们性格迥异：Su 沉稳且坚忍，而 黄仁勋性情多变且情感外露。“她总是面无表情，”行业分析师 Mosesmann 评论。“相比之下，Jensen 的情绪更为直接，尽管如此，他依然能在竞争中取胜。”

Su 擅长跟随市场领导者，伺机而动。与 黄仁勋不同，她敢于与英特尔正面竞争，在过去十年中，AMD 成功夺取了英特尔大量的 CPU 市场份额，这曾被认为是不可能的壮举。最近，Su 开始将目光转向人工智能市场。“Jensen 是一个极具野心的人，他不愿意失败，”负责 AMD 人工智能业务的高管 Forrest Norrod 说。“但我们相信我们有能力与 Nvidia 竞争。”

在一个九月的阴沉星期五下午，我开车去了一家眺望太平洋的豪华度假村，去看黄仁勋被 Hao Ko 公开采访的场景。Hao Ko 是 Nvidia 总部的主要建筑师。我提前到达，看到他们两个面对大海，正沉浸在安静的对话中。两人几乎穿着一模一样的服装：黑色皮夹克、黑色牛仔裤和黑色鞋子，只不过 Ko 显得更高一些。我本以为能听到一些关于计算未来的真挚见解，结果却听到了黄仁勋对 Ko 的服饰进行了六分钟的幽默吐槽。黄仁勋开玩笑说：“看看这家伙，他穿得跟我一样。他在模仿我，这很明智，只是他的裤子口袋太多了。”Ko 尴尬地笑了笑，低头看着他的设计师牛仔裤，上面确实有不少多余的拉链口袋。黄仁勋又说：“简化点，伙计！”然后转向我：“他为什么穿成这样，因为是我教的。我教会了他所有的东西。”（黄仁勋的穿着风格被广泛模仿，今年早些时候，他甚至还登上了《时报》的风格版块。）

“欢迎你的到来！这是给你的备用毛巾，还有一个客房，不过找不到合适的地方挂毛巾。” —— 漫画作者：Asher Perlman</title>
            <link>https://nitter.cz/dotey/status/1729742566302630146#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729742566302630146#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:02:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在 黄仁勋发送邮件的那段时间，他找到 Nvidia 的 AI 领头人物 Catanzaro，向他提出了一个假设性的问题。“他让我想象一下，如果他把 Nvidia 的所有八千名员工都召集到停车场，”Catanzaro 讲道。“然后他说，我可以从那里挑选任何人加入我的团队。”<br />
<br />
黄仁勋极少接受采访，总是尽量不让自己成为焦点。“我觉得我在这里并没有做什么特别的事情，”他这样告诉我。“这主要归功于我的团队。”（“他是无可替代的，”董事会成员 Jim Gaither 这样评价他。）“我也不太清楚为什么会被选为 CEO，”黄仁勋说。“我并没有什么特别的野心。”（“他早就立志在三十岁之前要经营一家公司，”他的合伙人 Chris Malachowsky 补充道。）“我并不擅长演讲，因为我其实很内向，”黄仁勋说。（“但他却是个出色的表演者，”他的朋友 Ben Bays 评论道。）“我只有一个特长——做功课，”黄仁勋说。（“他能在一个周末内掌握任何知识，”Nvidia 软件部门负责人 Dwight Diercks 说。）<br />
<br />
黄仁勋倾向于打造一个灵活的公司架构，不设固定部门或等级。员工每周都要提交一份工作重点清单，简洁明了。黄仁勋会在深夜审阅这些邮件。他经常在 Nvidia 广阔的园区内巡视，偶尔会停下来询问初级员工的工作进展。黄仁勋的出现常常会让一个简单的工位变成严肃的审讯现场。“在硅谷，有时候人们可以含糊其辞，”行业分析师 Hans Mosesmann 对我说。“但在 Jensen 面前，这种做法行不通。他有时会因此而感到不悦。”<br />
<br />
黄仁勋通过每天撰写数百封电邮与员工沟通，这些邮件往往简短得只有几个词。一位高管认为这些邮件仿佛俳句，而另一位则觉得它们像勒索信。黄仁勋还常常引用自己创造的一些管理智慧。在制定计划时，他会要求员工考虑到“光速”的快，这不单是指迅速完成任务，而是先设想任务能在最短时间内完成的可能，再据此设定一个实际可行的目标。员工也被鼓励去开拓“零十亿美元市场”，即那些既无竞争对手又缺乏明确客户群的探索性产品，比如 cuda。（这让我想起了凯文·科斯特纳在《梦幻成真》中的角色，他在爱荷华州一片玉米地中建造了一个棒球场，然后静候球员和观众的到来。）<br />
<br />
黄仁勋最具颠覆性的信念或许是“失败必须共享”。二千年代初，英伟达发布了一款有缺陷的显卡，其风扇响声巨大、过度活跃。黄仁勋没有解雇负责这款显卡的产品经理，反而安排了一场会议，让这些经理向数百人详细讲解导致这场失败的每一个决策。（英伟达还向媒体放出了一段讽刺视频，由产品经理们主演，视频里把显卡改造成了吹叶机。）在英伟达，向人群公开展示自己的失败已成为一种深受欢迎的仪式，但这种公司内部的“斗争会议”并不是每个人都能接受的。“你可以很快看出谁能在这里生存下去，谁做不到，”迪尔克斯说。“如果有人开始变得防御，我就知道他们不适合这里。”<br />
<br />
黄仁勋的员工有时会对他喜怒无常的性格表示不满。黄仁勋本人解释道：“这实际上是我大脑里的想法和我说出的话之间的差异。”“当这种差异很大时，就会表现为愤怒。”即便在平静时，黄仁勋的热情也可能让人感到难以承受。“和他交流就像把手指插进电源插座，”一位员工这样描述。但即便如此，Nvidia 的员工留存率依然很高。负责消费者部门的杰夫·费舍尔是最初的员工之一。现在他已经非常富有，但仍继续工作。“我们很多人现在是出于对使命的信仰而自愿留下，”费舍尔说。黄仁勋的两个孩子原先在酒店行业工作；在父亲多年的严格教导下，他们现在也在 Nvidia 工作。卡坦扎罗曾离开去另一家公司，几年后又回到 Nvidia。“与詹森相处并不总是容易，”卡坦扎罗说，“有时我会害怕他，但我也知道他很关心我。”<br />
<br />
AlexNet 取得成功之后，风险投资家们开始大举投资于人工智能领域。“我们一直在为许多在各个领域应用深度学习的初创公司投资，他们几乎都是基于 Nvidia 的平台，”安德森·霍洛维茨公司的马克·安德森在 2016 年表示。大约在那个时候，Nvidia 向 OpenAI 的一个研究团队交付了其第一台专门用于人工智能的超级计算机 DGX-1。黄仁勋亲自将这台计算机送到 OpenAI 的办公室，当时的董事长埃隆·马斯克亲自用刀片打开了包装。<br />
<br />
2017 年，谷歌的研究人员推出了一种新的神经网络训练架构，名为 Transformer。紧接着在第二年，OpenAI 的研究人员利用谷歌的框架开发出了第一个“生成预训练 Transformer (G.P.T.)”。这些 G.P.T. 模型在 Nvidia 的超级计算机上接受训练，吸收了大量文本资料，学会了如何进行类似人类的思维连接。到了 2022 年底，经过几个版本的迭代，ChatGPT 对外发布。<br />
<br />
从那时起，Nvidia 开始面临海量的客户需求。公司推出的最新 AI 训练模块，名为 DGX H100，是一个重达三百七十磅、售价高达五十万美元的金属盒子。目前，这款产品的订单已经排到了数月以后。DGX H100 的运行速度是训练 ChatGPT 所用硬件的五倍之多，甚至能在不到一分钟内完成对 AlexNet 的训练。据预测，Nvidia 将在今年年底之前售出五十万台这样的设备。<br />
<br />
处理能力越强的神经网络，其输出的复杂度也越高。对于顶尖的 AI 模型，Nvidia 提供了装有数十台 DGX H100 的机架。如果这还不足以满足需求，Nvidia 甚至可以将这些计算机像图书馆的书架一样排列，用价值数千万美元的超级计算设备填满整个数据中心。对于 AI 的能力似乎没有上限。Sutskever 曾对我说：“如果你相信人造神经元就像生物神经元一样，那就相当于你在训练大脑。它们理应能做到我们能做的所有事。”起初我对这种说法持怀疑态度——毕竟，我并没有通过观察一千万个参考图像来学习识别猫，也没有通过研究人类全部的作品来学会写作。但化石记录告诉我们，神经系统的发展始于几亿年前，并且一直在变得更加复杂。Catanzaro 补充道：“地球上存在了许久的生物学会了很多东西，这些都在我们大脑的物理结构中留下了痕迹。”<br />
<br />
即使是 AI 的创造者们也对它们的能力感到惊讶。比如 GPT-4，ChatGPT 的继任者，它能将一张餐巾纸上的简单草图转化成一个完整的网站，并且在 LSAT 法学院入学考试中取得了排名前 12% 的好成绩。在未来几年内，Nvidia 的硬件将以计算机时钟周期的速度加速这种演化，训练出各种各样的 AI 模型。这些模型的用途五花八门：有的管理投资组合，有的操控无人机；有的能够复制你的肖像，有的甚至可以模仿已故人士的声音。有的将成为自主机器人的大脑，有的则能够创造定制药物。有的能作曲，有的能写诗。如果我们不小心，很可能有一天，这些 AI 将变得比我们更聪明。<br />
<br />
Nvidia 的设备毛利率高达 70%。这一高利润率吸引了众多竞争者，就像血腥的鱼饵吸引鲨鱼一样。谷歌和特斯拉正积极研发人工智能训练硬件，众多初创公司也在此列。其中，Cerebras 推出了一款巨型芯片，其大小堪比晚餐盘。Cerebras 的首席执行官 Andrew Feldman 批评 Nvidia：“他们在对客户进行敲诈，却鲜有人敢公开指责。”（黄仁勋回应称，训练有素的人工智能模型能显著降低客户在其他业务方面的成本。“购买得越多，节约得越多，”他如是说。）<br />
<br />
Nvidia 的主要竞争对手是 AMD。自 2014 年起，AMD 由从台湾移民至美国的杰出工程师 Lisa Su 领导。在 Su 执掌 AMD 后，公司股价飙升了 30 倍，仅次于 黄仁勋，成为当代最成功的半导体公司 CEO 之一。Su 与 黄仁勋还是堂兄妹关系。<br />
<br />
黄仁勋告诉我，他们小时候并不相识，直到 Su 成为 CEO 他们才相遇。“她非常出色，”他评价道。“我们之间的竞争并不激烈。”（Nvidia 的员工可以准确背诵 Nvidia 和 AMD 显卡在市场上的份额。）他们性格迥异：Su 沉稳且坚忍，而 黄仁勋性情多变且情感外露。“她总是面无表情，”行业分析师 Mosesmann 评论。“相比之下，Jensen 的情绪更为直接，尽管如此，他依然能在竞争中取胜。”<br />
<br />
Su 擅长跟随市场领导者，伺机而动。与 黄仁勋不同，她敢于与英特尔正面竞争，在过去十年中，AMD 成功夺取了英特尔大量的 CPU 市场份额，这曾被认为是不可能的壮举。最近，Su 开始将目光转向人工智能市场。“Jensen 是一个极具野心的人，他不愿意失败，”负责 AMD 人工智能业务的高管 Forrest Norrod 说。“但我们相信我们有能力与 Nvidia 竞争。”<br />
<br />
在一个九月的阴沉星期五下午，我开车去了一家眺望太平洋的豪华度假村，去看黄仁勋被 Hao Ko 公开采访的场景。Hao Ko 是 Nvidia 总部的主要建筑师。我提前到达，看到他们两个面对大海，正沉浸在安静的对话中。两人几乎穿着一模一样的服装：黑色皮夹克、黑色牛仔裤和黑色鞋子，只不过 Ko 显得更高一些。我本以为能听到一些关于计算未来的真挚见解，结果却听到了黄仁勋对 Ko 的服饰进行了六分钟的幽默吐槽。黄仁勋开玩笑说：“看看这家伙，他穿得跟我一样。他在模仿我，这很明智，只是他的裤子口袋太多了。”Ko 尴尬地笑了笑，低头看着他的设计师牛仔裤，上面确实有不少多余的拉链口袋。黄仁勋又说：“简化点，伙计！”然后转向我：“他为什么穿成这样，因为是我教的。我教会了他所有的东西。”（黄仁勋的穿着风格被广泛模仿，今年早些时候，他甚至还登上了《时报》的风格版块。）<br />
<br />
“欢迎你的到来！这是给你的备用毛巾，还有一个客房，不过找不到合适的地方挂毛巾。” —— 漫画作者：Asher Perlman</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGSHNITVdVQUFlTGttLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729742445515006318#m</id>
            <title>R to @dotey: Buck 曾怀疑，GeForce 显卡除了用来在游戏中向朋友投掷手榴弹外，是否还有其他用途。这些显卡配备了一个基础的编程工具——着色器（shader）。在 darpa（美国国防部高级研究计划署）的资助下，Buck 改造了着色器，以访问底层的并行计算电路，从而将 GeForce 转变为一种低成本的超级计算机。不久后，他开始为 Nvidia 的创始人 黄仁勋工作。

Buck 是一个充满热情且头发稀疏的人，他的身上散发着聪明才智。作为一名热衷于计算机科学的人，他在过去的二十年里不断挑战 Nvidia 芯片的极限。他说：“人类的思考是线性的。比如，你告诉别人怎样从这里到星巴克，你会一步步指导他们。但你不会告诉他们如何从任何地方到达任意一家星巴克。并行思考对我们来说很难。”

自 2004 年以来，Buck 一直负责开发 Nvidia 的超级计算软件包，名为 cuda。黄仁勋的愿景是让 cuda 能运行在每一块 GeForce 显卡上。“我们在普及超级计算，”黄仁勋表示。

在 Buck 开发软件的同时，Nvidia 的硬件团队也在微芯片上预留出空间，用于超级计算。这些芯片包含了数十亿电子晶体管，通过复杂的电路迅速完成计算。Nvidia 的首席芯片工程师 Arjun Prabhu 把设计微芯片比作城市规划，不同区域负责不同的任务。就像玩俄罗斯方块时处理下落的方块，Prabhu 有时甚至会在梦中看到晶体管。“我经常在周五晚上梦见最棒的点子，就好像真的在梦中看到它们一样，”Prabhu 说。

当 cuda 在 2006 年底面世时，华尔街的反应并不热烈。黄仁勋正将超级计算推向普通大众，但似乎大众对此并不感兴趣。“他们为这种新型芯片架构投入了巨资，”硅谷知名播客“Acquired”的联合主持人 Ben Gilbert 说。“他们投入了数十亿美元，目标却是学术和科学计算的一个小众市场，这和他们的投资规模相比简直是小巫见大巫。”黄仁勋认为，单纯 cuda 的存在就能扩展超级计算的市场。这种看法并不被普遍接受，到 2008 年底，英伟达的股价暴跌了 70%。

黄仁勋在演讲中提到，访问国立台湾大学物理学教授赵庭伟的办公室，给了他在这段艰难时期的信心。赵教授为了模拟宇宙大爆炸后的物质演化，自己在办公室旁的实验室里搭建了一台超级计算机。黄仁勋发现实验室里到处是 GeForce 盒子，而且计算机还用摆动的台式风扇冷却。“Jensen 是一个有远见的人，”赵教授告诉我，“他让我的终身研究成为可能。”

赵教授是理想客户的典范，但像他这样的客户并不多。cuda 的下载量在 2009 年达到顶峰，之后连续三年下降。英伟达的董事会担心，公司股价的低迷可能会吸引企业掠夺者。“我们尽一切努力保护公司，以防激进股东入侵并企图拆分公司，”长期董事会成员 Jim Gaither 说。前 NFL 市场营销主管 Dawn Hudson 于 2013 年加入董事会。“当时的公司明显处于停滞状态，”她评价道。

在市场推广 cuda 的过程中，Nvidia 试图吸引包括股票交易员、石油勘探者和分子生物学家等多种客户。公司甚至与通用磨坊达成协议，为烹饪冷冻比萨的热物理过程建模。但对于人工智能领域，Nvidia 却几乎没有花费太多精力，因为看似没有太大的市场。

在 2010 年代初期，人工智能（A.I.）这个领域几乎被遗忘。在图像识别和语音识别等基本任务上的进展几乎停滞不前。在这个学术上不受青睐的领域中，还有一个更小众的子领域，它通过使用“神经网络”（neural networks）—一种模仿人脑的计算结构—来解决问题。很多计算机科学家都认为神经网络是过时且无效的。“我曾被导师劝阻研究神经网络，”深度学习研究员 Catanzaro 回忆道，“因为当时人们认为它们已经落伍，而且效果不佳。”

Catanzaro 把坚持研究神经网络的科学家们比喻为“荒原中的先知”。其中一位先知是多伦多大学教授 Geoffrey Hinton。2009 年，Hinton 带领的研究团队利用 Nvidia 的 cuda 平台训练了一个识别人类语音的神经网络，并对其成果的高质量感到惊喜。他在那年的一个会议上展示了这些成果，并联系了 Nvidia。“我曾发邮件给 Nvidia，说‘我刚告诉了一千名机器学习研究人员他们应该购买 Nvidia 显卡。你们能免费给我一张吗？’”Hinton 说，“但他们拒绝了。”

尽管如此，Hinton 依然鼓励学生们使用 cuda，其中包括他的乌克兰学生 Alex Krizhevsky，他认为 Krizhevsky 可能是见过的最优秀的程序员之一。2012 年，Krizhevsky 和研究搭档 Ilya Sutskever 在预算有限的情况下，从 Amazon 购买了两张 GeForce 显卡。Krizhevsky 开始在 Nvidia 的并行计算平台上训练一个视觉识别神经网络，仅用一周的时间就处理了数百万张图像。“他的两张 G.P.U. 显卡一直在卧室里运转，”Hinton 补充道，“而他的父母为此支付了相当高的电费。”

Sutskever 和 Krizhevsky 对这些显卡的强大能力感到震惊。就在那年早些时候，谷歌的研究人员用大约一万六千个 C.P.U. 训练了一个能识别猫视频的神经网络。而 Sutskever 和 Krizhevsky 只用了两块 Nvidia 电路板就取得了世界级的成果。“G.P.U. 的出现就像一个奇迹，”Sutskever 说。

Krizhevsky 在他父母家中训练的神经网络，AlexNet，现在已与莱特飞行器和爱迪生灯泡齐名。2012 年，他把 AlexNet 带入年度 ImageNet 视觉识别竞赛，由于当时神经网络尚不普及，他成了唯一采用这种技术的参赛者。AlexNet 在比赛中的卓越表现，甚至让组织者一度怀疑其是否作弊。“那是一个划时代的时刻，”Hinton 如是说。“这标志着一个范式的转变。”

自从 Krizhevsky 发表了关于 AlexNet 架构的九页论文以来的十年里，该论文被引用了超过十万次，成为计算机科学史上最重要的论文之一。（AlexNet 成功识别了包括摩托车、豹子、集装箱船等在内的多种图像。）Krizhevsky 创新了许多重要的编程技巧，其核心发现是，专用 G.P.U. 训练神经网络的速度比通用 C.P.U. 快上百倍。“没有 cuda，机器学习将变得异常困难，”Hinton 表示。

不久之后，ImageNet 竞赛的每个参赛者都开始使用神经网络。到了二十一世纪十年代中期，基于 G.P.U. 训练的神经网络在图像识别准确率上达到了 96%，超过了人类。黄仁勋长达十年的推动超级计算民主化的努力终于获得了成果。“它们能解决复杂的计算机视觉问题，这让人不禁思考，还能教它们学习什么？”黄仁勋这样对我说。

答案似乎是一切。黄仁勋相信，神经网络将彻底改变社会，并借助 cuda 抢占硬件市场。他决定再次全力以赴。“周五晚上他发出邮件，宣布我们将全面转向深度学习，不再是一家专注于图形的公司，”Nvidia 的副总裁 Greg Estes 对我说。“到了周一早上，我们已经成为一家 AI 公司。转变就这么迅速。”

“嘿！不要非法录制演出！” —— Pia Guerra 和 Ian Boothby 创作的漫画</title>
            <link>https://nitter.cz/dotey/status/1729742445515006318#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729742445515006318#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:01:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Buck 曾怀疑，GeForce 显卡除了用来在游戏中向朋友投掷手榴弹外，是否还有其他用途。这些显卡配备了一个基础的编程工具——着色器（shader）。在 darpa（美国国防部高级研究计划署）的资助下，Buck 改造了着色器，以访问底层的并行计算电路，从而将 GeForce 转变为一种低成本的超级计算机。不久后，他开始为 Nvidia 的创始人 黄仁勋工作。<br />
<br />
Buck 是一个充满热情且头发稀疏的人，他的身上散发着聪明才智。作为一名热衷于计算机科学的人，他在过去的二十年里不断挑战 Nvidia 芯片的极限。他说：“人类的思考是线性的。比如，你告诉别人怎样从这里到星巴克，你会一步步指导他们。但你不会告诉他们如何从任何地方到达任意一家星巴克。并行思考对我们来说很难。”<br />
<br />
自 2004 年以来，Buck 一直负责开发 Nvidia 的超级计算软件包，名为 cuda。黄仁勋的愿景是让 cuda 能运行在每一块 GeForce 显卡上。“我们在普及超级计算，”黄仁勋表示。<br />
<br />
在 Buck 开发软件的同时，Nvidia 的硬件团队也在微芯片上预留出空间，用于超级计算。这些芯片包含了数十亿电子晶体管，通过复杂的电路迅速完成计算。Nvidia 的首席芯片工程师 Arjun Prabhu 把设计微芯片比作城市规划，不同区域负责不同的任务。就像玩俄罗斯方块时处理下落的方块，Prabhu 有时甚至会在梦中看到晶体管。“我经常在周五晚上梦见最棒的点子，就好像真的在梦中看到它们一样，”Prabhu 说。<br />
<br />
当 cuda 在 2006 年底面世时，华尔街的反应并不热烈。黄仁勋正将超级计算推向普通大众，但似乎大众对此并不感兴趣。“他们为这种新型芯片架构投入了巨资，”硅谷知名播客“Acquired”的联合主持人 Ben Gilbert 说。“他们投入了数十亿美元，目标却是学术和科学计算的一个小众市场，这和他们的投资规模相比简直是小巫见大巫。”黄仁勋认为，单纯 cuda 的存在就能扩展超级计算的市场。这种看法并不被普遍接受，到 2008 年底，英伟达的股价暴跌了 70%。<br />
<br />
黄仁勋在演讲中提到，访问国立台湾大学物理学教授赵庭伟的办公室，给了他在这段艰难时期的信心。赵教授为了模拟宇宙大爆炸后的物质演化，自己在办公室旁的实验室里搭建了一台超级计算机。黄仁勋发现实验室里到处是 GeForce 盒子，而且计算机还用摆动的台式风扇冷却。“Jensen 是一个有远见的人，”赵教授告诉我，“他让我的终身研究成为可能。”<br />
<br />
赵教授是理想客户的典范，但像他这样的客户并不多。cuda 的下载量在 2009 年达到顶峰，之后连续三年下降。英伟达的董事会担心，公司股价的低迷可能会吸引企业掠夺者。“我们尽一切努力保护公司，以防激进股东入侵并企图拆分公司，”长期董事会成员 Jim Gaither 说。前 NFL 市场营销主管 Dawn Hudson 于 2013 年加入董事会。“当时的公司明显处于停滞状态，”她评价道。<br />
<br />
在市场推广 cuda 的过程中，Nvidia 试图吸引包括股票交易员、石油勘探者和分子生物学家等多种客户。公司甚至与通用磨坊达成协议，为烹饪冷冻比萨的热物理过程建模。但对于人工智能领域，Nvidia 却几乎没有花费太多精力，因为看似没有太大的市场。<br />
<br />
在 2010 年代初期，人工智能（A.I.）这个领域几乎被遗忘。在图像识别和语音识别等基本任务上的进展几乎停滞不前。在这个学术上不受青睐的领域中，还有一个更小众的子领域，它通过使用“神经网络”（neural networks）—一种模仿人脑的计算结构—来解决问题。很多计算机科学家都认为神经网络是过时且无效的。“我曾被导师劝阻研究神经网络，”深度学习研究员 Catanzaro 回忆道，“因为当时人们认为它们已经落伍，而且效果不佳。”<br />
<br />
Catanzaro 把坚持研究神经网络的科学家们比喻为“荒原中的先知”。其中一位先知是多伦多大学教授 Geoffrey Hinton。2009 年，Hinton 带领的研究团队利用 Nvidia 的 cuda 平台训练了一个识别人类语音的神经网络，并对其成果的高质量感到惊喜。他在那年的一个会议上展示了这些成果，并联系了 Nvidia。“我曾发邮件给 Nvidia，说‘我刚告诉了一千名机器学习研究人员他们应该购买 Nvidia 显卡。你们能免费给我一张吗？’”Hinton 说，“但他们拒绝了。”<br />
<br />
尽管如此，Hinton 依然鼓励学生们使用 cuda，其中包括他的乌克兰学生 Alex Krizhevsky，他认为 Krizhevsky 可能是见过的最优秀的程序员之一。2012 年，Krizhevsky 和研究搭档 Ilya Sutskever 在预算有限的情况下，从 Amazon 购买了两张 GeForce 显卡。Krizhevsky 开始在 Nvidia 的并行计算平台上训练一个视觉识别神经网络，仅用一周的时间就处理了数百万张图像。“他的两张 G.P.U. 显卡一直在卧室里运转，”Hinton 补充道，“而他的父母为此支付了相当高的电费。”<br />
<br />
Sutskever 和 Krizhevsky 对这些显卡的强大能力感到震惊。就在那年早些时候，谷歌的研究人员用大约一万六千个 C.P.U. 训练了一个能识别猫视频的神经网络。而 Sutskever 和 Krizhevsky 只用了两块 Nvidia 电路板就取得了世界级的成果。“G.P.U. 的出现就像一个奇迹，”Sutskever 说。<br />
<br />
Krizhevsky 在他父母家中训练的神经网络，AlexNet，现在已与莱特飞行器和爱迪生灯泡齐名。2012 年，他把 AlexNet 带入年度 ImageNet 视觉识别竞赛，由于当时神经网络尚不普及，他成了唯一采用这种技术的参赛者。AlexNet 在比赛中的卓越表现，甚至让组织者一度怀疑其是否作弊。“那是一个划时代的时刻，”Hinton 如是说。“这标志着一个范式的转变。”<br />
<br />
自从 Krizhevsky 发表了关于 AlexNet 架构的九页论文以来的十年里，该论文被引用了超过十万次，成为计算机科学史上最重要的论文之一。（AlexNet 成功识别了包括摩托车、豹子、集装箱船等在内的多种图像。）Krizhevsky 创新了许多重要的编程技巧，其核心发现是，专用 G.P.U. 训练神经网络的速度比通用 C.P.U. 快上百倍。“没有 cuda，机器学习将变得异常困难，”Hinton 表示。<br />
<br />
不久之后，ImageNet 竞赛的每个参赛者都开始使用神经网络。到了二十一世纪十年代中期，基于 G.P.U. 训练的神经网络在图像识别准确率上达到了 96%，超过了人类。黄仁勋长达十年的推动超级计算民主化的努力终于获得了成果。“它们能解决复杂的计算机视觉问题，这让人不禁思考，还能教它们学习什么？”黄仁勋这样对我说。<br />
<br />
答案似乎是一切。黄仁勋相信，神经网络将彻底改变社会，并借助 cuda 抢占硬件市场。他决定再次全力以赴。“周五晚上他发出邮件，宣布我们将全面转向深度学习，不再是一家专注于图形的公司，”Nvidia 的副总裁 Greg Estes 对我说。“到了周一早上，我们已经成为一家 AI 公司。转变就这么迅速。”<br />
<br />
“嘿！不要非法录制演出！” —— Pia Guerra 和 Ian Boothby 创作的漫画</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGSGxKMVhnQUE5V1czLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>