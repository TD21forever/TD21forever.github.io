<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/VikingThunders/status/1727188532857593872#m</id>
            <title>RT by @dotey: 《中国人工智能实力的幻觉：规范AI并不会让美国在科技竞赛中落后》
作者：海伦·托纳、珍妮·肖、杰弗里·丁

人工智能革命已经触及美国国会。像OpenAI的文本聊天GPT这样强大的AI系统所展现的惊人潜力，已让立法者们感到担忧，他们担心这种快速发展的技术可能如何重塑经济和社会生活。近几个月来，国会山见证了一系列听证会和幕后谈判，议员和监管机构正试图确定如何最好地对这项技术施加限制。但一些人担心，对AI行业的任何规范都会带来地缘政治成本。在5月份的一次美国参议院听证会上，OpenAI的首席执行官萨姆·奥特曼警告说，AI规范的一个“危险”是“你以这样的方式放慢美国工业的步伐，以至于中国或其他国家取得更快的进展。”同月，AI企业家亚历山大·王坚称，“美国处于一个相对危险的位置，我们必须确保在技术上迅速前进。”事实上，华盛顿对红色磁带的偏爱可能会在与北京的竞争中损害它，这一观点长期以来一直困扰着政府和私营部门的人物。前谷歌首席执行官埃里克·施密特在2021年声称，“中国并没有因为规定而停止任何事情。”按照这种思路，如果美国对AI设置了防护措施，它可能会将国际AI领导权拱手让给中国。

从抽象的角度来看，这些担忧是有道理的。如果监管打击削弱了国内AI产业，而中国的AI公司在不受束缚的情况下蓬勃发展，这并不符合美国的利益。但对中国AI发展的仔细审视——特别是大型语言模型（LLM），这种文本生成系统是支撑诸如ChatGPT之类应用的基础——显示出这种担忧是夸大了。中国的LLM落后于美国同行，并且在很大程度上仍依赖于美国的研究和技术。此外，中国的AI开发商已经面临着比美国同行更为严格和限制性的政治、监管和经济环境。即使新规定确实会放缓美国的创新速度——而这很可能并非如此——中国似乎也没有准备好快速超越。

美国公司正在以前所未有的速度构建和部署AI工具，以至于它们甚至主动向华盛顿寻求指导。这意味着，考虑如何规范技术的决策者处于一个强势位置，而不是弱势。如果放任不管，当今AI系统的危害将继续增加，而未来系统产生的新危险也将得不到控制。对中国实力的夸大印象不应阻止美国现在采取有意义且必要的行动。

仿效：最真诚的奉承
在过去三年中，中国实验室迅速跟随美国和英国公司的步伐，构建了类似于OpenAI的GPT-3（ChatGPT的前身）、谷歌的PaLM和DeepMind的Chinchilla的AI系统。但在许多情况下，围绕中国模型的炒作掩盖了其缺乏真正实质的事实。我们与之交谈的中国AI研究人员认为，中国的大型语言模型（LLM）至少落后于美国同行两到三年，甚至可能更多。更糟的是，中国在AI领域的进展在很大程度上依赖于复制和调整国外发表的研究，这种依赖可能使中国公司难以在该领域中扮演领导角色。如果其他地方的创新速度放缓，中国构建LLM的努力——就像一名慢速骑手在领跑者的滑流中滑行——很可能会减速。

以北京人工智能研究院的“悟道2.0”模型为例。该模型于2021年夏季发布后，《福布斯》杂志将其作为“更大、更强、更快的AI”的例子大加赞扬，主要是因为悟道2.0拥有的参数量是GPT-3的十倍——AI模型内部决定信息处理方式的数字。但这种评估在几个方面都具有误导性。仅仅拥有更多的参数并不意味着一个AI系统比另一个更好，特别是如果没有相应增加数据和计算能力的话。在这种情况下，比较参数数量尤其不合理，因为悟道2.0是通过结合一系列模型的预测而非作为单一语言模型工作，这种设计人为地夸大了参数计数。更重要的是，研究人员向模型提出问题的方式帮助其在某些试验中的表现看起来比实际更强。

美国不应因为对中国AI实力的恐惧而停止对技术的规范。
百度的“二郎神”也令人失望。作为中国对ChatGPT的回应，二郎神的开发显然是受到与悟道2.0相同的压力——追赶美国的高调突破。这款中国机器人未能达到期望。百度的发布活动仅包括其操作的预录示例，这是一个明显的迹象，表明这款聊天机器人在实时互动中表现可能不佳。自从用户获得访问二郎神以来的评论最多也就是一般，聊天机器人在简单的任务上，如基本数学或翻译问题上都遇到了困难。

中国AI开发者努力跟上美国同行的步伐。2021年8月，斯坦福大学的100多名研究人员合作发表了一篇关于所谓基础模型未来的重要论文，这类AI系统包括LLM。七个月后，北京人工智能研究院发布了一篇同样篇幅冗长的关于相关主题的文献综述，共同作者几乎一样多。但几周后，谷歌的一位研究人员发现，中国论文的大部分内容是从一些国际论文中抄袭的——也许，正如中文媒体所推测的，这是因为参与起草论文的研究生面临极大的压力，而且截止日期非常紧迫。

美国人不应该被中国在LLM开发中即将到来的浪潮所困扰。中国AI团队正在努力——并且经常失败——以跟上其他地方新研究和产品的惊人速度。在LLM领域，中国比国际竞争对手落后数年而不是数月。

逆风与障碍
对AI行业外部的力量也阻碍了中国创新的步伐。由于大型语言模型（LLM）的巨大计算需求，国际上对半导体的竞争不可避免地影响了AI的研究和开发。中国半导体行业只能生产比最新尖端产品落后几代的芯片，迫使许多中国实验室依赖美国公司开发的高端芯片。在分析中国LLM的最新研究中，我们发现了17个使用加利福尼亚公司英伟达（NVIDIA）生产的芯片的模型；相比之下，我们只识别出3个使用中国制造芯片构建的模型。

华为的潘古-α，于2021年发布，是三个例外之一。该模型使用华为自家的昇腾处理器进行训练，看起来是在比最佳实践所推荐的计算能力显著更低的情况下开发的。尽管中国研究团队目前可以通过从亚马逊或微软等云服务提供商租用硬件来合法获得尖端美国芯片，但北京必须担心围绕半导体的日益激烈的言辞和限制将阻碍其AI公司和研究人员。

更广泛地看，对中国整体经济和技术前景的悲观可能会阻碍国内AI的努力。作为对国内监管审查浪潮和经济显著放缓的回应，许多中国初创公司现在选择将其业务基地设在海外，并主要面向国际市场而非中国市场。这一转变是由中国企业家日益增长的欲望所驱动的，他们希望更容易地获得外国投资，并逃避中国严格的监管环境——同时也规避美国对中国公司施加的限制。

HAL，遇见大哥
中国关于言论的密集限制也对大型语言模型（LLM）的开发和部署提出了独特的挑战。LLM的自由运作方式——遵循用户的引导，就任何话题、任何风格产生文本——与中国严格的审查规则并不匹配。在一次与我们之一（肖）的私人对话中，一位中国CEO戏谑地说，中国的LLM甚至不允许数到10，因为这将包括数字八和九——这是指国家对89数字的敏感，以及对1989年天安门广场抗议的任何讨论。

由于连LLM的创造者们也很难理解其内部工作原理，现有的限制其可以和不可以说什么的方法更像是用锤子而不是手术刀。这意味着公司面临着AI回应的有用性和避免不良话题之间的严峻抉择。LLM提供商无论在哪里都在试图弄清楚如何处理这种抉择，但在中国，一次失误可能会带来严重后果，这迫使公司选择更为保守的方法。像微软旗下的小冰这样的热门产品被禁止讨论政治敏感话题，如天安门广场抗议或中国领导人习近平。我们与之交谈的一些用户甚至声称，随着微软增加了更多防护措施，小冰的功能随时间变得越来越差。同样，记者们发现，百度的二郎神对有关习近平的问题给出固定答案，并拒绝回应其他政治敏感话题。鉴于中国被审查的意见和主题范围广泛——从中国经济的健康到乌克兰战争的进展，再到“民主”的定义——开发者将难以制作不触碰红线的聊天机器人，同时仍能正常且有效地回答大多数问题。

除了这些言论上的政治限制外，中国AI公司还受到该国对AI的非常详细和苛刻的监管制度的约束。一套规则于2023年1月生效，适用于使用生成性AI的在线服务提供商，包括LLM。进一步要求的草案于4月发布征求意见，将适用于研发实践以及AI产品。

其中一些规则很直接，比如要求敏感数据必须按照中国更广泛的数据治理制度来处理。其他规定可能相当繁重。例如，1月的规定要求提供商“消除”使用其产品生成的内容传播的谣言，这意味着如果公司的AI工具产生的信息或观点与中国共产党的路线相悖，公司将承担责任。4月的草案将进一步要求LLM开发者不仅要验证AI程序产生的内容的真实性和准确性，还要验证最初用来训练程序的材料。在一个依赖于从网上抓取大量数据的领域，这一要求可能是一个严重的头疼问题。如果设计得当，监管不必阻碍创新。但到目前为止，中国共产党对LLM和其他生成性AI技术的监管方法似乎过于严厉，可能会对中国公司和研究人员构成真正的障碍。

对奇美拉的恐惧
尽管目前面临困难，中国的人工智能发展仍可能转变方向，并建立更成功和创新的记录。然而，美国人在历史上有高估其竞争对手技术实力的习惯。在冷战期间，对苏联能力的夸大估计使美国官员基于假设的“轰炸机差距”和“导弹差距”制定政策，这两者后来都被证明是虚构的。同样毫无根据的焦虑不应决定美国AI规制的方向。毕竟，社交媒体公司抵制规制，而AI公司已经要求规制。五年前，Facebook创始人马克·扎克伯格警告国会，打破他的社交媒体公司只会加强中国同行。相比之下，在AI领域，行业领导者主动呼吁规制。

如果有什么的话，规制是美国在AI领域最有可能落后的领域。中国近期对生成性AI的规制建立在现有规则和详细的数据治理制度之上。欧盟也在通过关于AI的新规则的道路上迈进，即AI法案，该法案将对风险进行分类并对LLM施加额外要求。美国尚未达到这样的监管努力，但即便如此，美国政策制定者的状况比通常假设的要好。联邦政府已经起草了管理AI风险和危害的全面框架，包括白宫的《人工智能权利法案蓝图》和国家标准与技术研究院的AI风险管理框架。这些文件提供了如何导航这项通用技术的多方面风险、危害以及益处的深入指导。现在需要的是允许这些框架关键原则的执行的立法，以保护公民权利，并围绕AI研究的快速发展设立防护措施。

仍有许多问题需要解决，包括新监管机构应该如何设立，第三方审计员可以发挥什么作用，透明度要求应该是什么样的，以及当事情出错时如何分配责任。这些是棘手而紧迫的问题，将塑造技术的未来，它们值得得到认真的努力和政策关注。如果中国AI精通的奇美拉使政策制定者不去追求对行业的规制，他们只会损害美国利益，危及国家的繁荣。</title>
            <link>https://nitter.cz/VikingThunders/status/1727188532857593872#m</link>
            <guid isPermaLink="false">https://nitter.cz/VikingThunders/status/1727188532857593872#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 04:53:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《中国人工智能实力的幻觉：规范AI并不会让美国在科技竞赛中落后》<br />
作者：海伦·托纳、珍妮·肖、杰弗里·丁<br />
<br />
人工智能革命已经触及美国国会。像OpenAI的文本聊天GPT这样强大的AI系统所展现的惊人潜力，已让立法者们感到担忧，他们担心这种快速发展的技术可能如何重塑经济和社会生活。近几个月来，国会山见证了一系列听证会和幕后谈判，议员和监管机构正试图确定如何最好地对这项技术施加限制。但一些人担心，对AI行业的任何规范都会带来地缘政治成本。在5月份的一次美国参议院听证会上，OpenAI的首席执行官萨姆·奥特曼警告说，AI规范的一个“危险”是“你以这样的方式放慢美国工业的步伐，以至于中国或其他国家取得更快的进展。”同月，AI企业家亚历山大·王坚称，“美国处于一个相对危险的位置，我们必须确保在技术上迅速前进。”事实上，华盛顿对红色磁带的偏爱可能会在与北京的竞争中损害它，这一观点长期以来一直困扰着政府和私营部门的人物。前谷歌首席执行官埃里克·施密特在2021年声称，“中国并没有因为规定而停止任何事情。”按照这种思路，如果美国对AI设置了防护措施，它可能会将国际AI领导权拱手让给中国。<br />
<br />
从抽象的角度来看，这些担忧是有道理的。如果监管打击削弱了国内AI产业，而中国的AI公司在不受束缚的情况下蓬勃发展，这并不符合美国的利益。但对中国AI发展的仔细审视——特别是大型语言模型（LLM），这种文本生成系统是支撑诸如ChatGPT之类应用的基础——显示出这种担忧是夸大了。中国的LLM落后于美国同行，并且在很大程度上仍依赖于美国的研究和技术。此外，中国的AI开发商已经面临着比美国同行更为严格和限制性的政治、监管和经济环境。即使新规定确实会放缓美国的创新速度——而这很可能并非如此——中国似乎也没有准备好快速超越。<br />
<br />
美国公司正在以前所未有的速度构建和部署AI工具，以至于它们甚至主动向华盛顿寻求指导。这意味着，考虑如何规范技术的决策者处于一个强势位置，而不是弱势。如果放任不管，当今AI系统的危害将继续增加，而未来系统产生的新危险也将得不到控制。对中国实力的夸大印象不应阻止美国现在采取有意义且必要的行动。<br />
<br />
仿效：最真诚的奉承<br />
在过去三年中，中国实验室迅速跟随美国和英国公司的步伐，构建了类似于OpenAI的GPT-3（ChatGPT的前身）、谷歌的PaLM和DeepMind的Chinchilla的AI系统。但在许多情况下，围绕中国模型的炒作掩盖了其缺乏真正实质的事实。我们与之交谈的中国AI研究人员认为，中国的大型语言模型（LLM）至少落后于美国同行两到三年，甚至可能更多。更糟的是，中国在AI领域的进展在很大程度上依赖于复制和调整国外发表的研究，这种依赖可能使中国公司难以在该领域中扮演领导角色。如果其他地方的创新速度放缓，中国构建LLM的努力——就像一名慢速骑手在领跑者的滑流中滑行——很可能会减速。<br />
<br />
以北京人工智能研究院的“悟道2.0”模型为例。该模型于2021年夏季发布后，《福布斯》杂志将其作为“更大、更强、更快的AI”的例子大加赞扬，主要是因为悟道2.0拥有的参数量是GPT-3的十倍——AI模型内部决定信息处理方式的数字。但这种评估在几个方面都具有误导性。仅仅拥有更多的参数并不意味着一个AI系统比另一个更好，特别是如果没有相应增加数据和计算能力的话。在这种情况下，比较参数数量尤其不合理，因为悟道2.0是通过结合一系列模型的预测而非作为单一语言模型工作，这种设计人为地夸大了参数计数。更重要的是，研究人员向模型提出问题的方式帮助其在某些试验中的表现看起来比实际更强。<br />
<br />
美国不应因为对中国AI实力的恐惧而停止对技术的规范。<br />
百度的“二郎神”也令人失望。作为中国对ChatGPT的回应，二郎神的开发显然是受到与悟道2.0相同的压力——追赶美国的高调突破。这款中国机器人未能达到期望。百度的发布活动仅包括其操作的预录示例，这是一个明显的迹象，表明这款聊天机器人在实时互动中表现可能不佳。自从用户获得访问二郎神以来的评论最多也就是一般，聊天机器人在简单的任务上，如基本数学或翻译问题上都遇到了困难。<br />
<br />
中国AI开发者努力跟上美国同行的步伐。2021年8月，斯坦福大学的100多名研究人员合作发表了一篇关于所谓基础模型未来的重要论文，这类AI系统包括LLM。七个月后，北京人工智能研究院发布了一篇同样篇幅冗长的关于相关主题的文献综述，共同作者几乎一样多。但几周后，谷歌的一位研究人员发现，中国论文的大部分内容是从一些国际论文中抄袭的——也许，正如中文媒体所推测的，这是因为参与起草论文的研究生面临极大的压力，而且截止日期非常紧迫。<br />
<br />
美国人不应该被中国在LLM开发中即将到来的浪潮所困扰。中国AI团队正在努力——并且经常失败——以跟上其他地方新研究和产品的惊人速度。在LLM领域，中国比国际竞争对手落后数年而不是数月。<br />
<br />
逆风与障碍<br />
对AI行业外部的力量也阻碍了中国创新的步伐。由于大型语言模型（LLM）的巨大计算需求，国际上对半导体的竞争不可避免地影响了AI的研究和开发。中国半导体行业只能生产比最新尖端产品落后几代的芯片，迫使许多中国实验室依赖美国公司开发的高端芯片。在分析中国LLM的最新研究中，我们发现了17个使用加利福尼亚公司英伟达（NVIDIA）生产的芯片的模型；相比之下，我们只识别出3个使用中国制造芯片构建的模型。<br />
<br />
华为的潘古-α，于2021年发布，是三个例外之一。该模型使用华为自家的昇腾处理器进行训练，看起来是在比最佳实践所推荐的计算能力显著更低的情况下开发的。尽管中国研究团队目前可以通过从亚马逊或微软等云服务提供商租用硬件来合法获得尖端美国芯片，但北京必须担心围绕半导体的日益激烈的言辞和限制将阻碍其AI公司和研究人员。<br />
<br />
更广泛地看，对中国整体经济和技术前景的悲观可能会阻碍国内AI的努力。作为对国内监管审查浪潮和经济显著放缓的回应，许多中国初创公司现在选择将其业务基地设在海外，并主要面向国际市场而非中国市场。这一转变是由中国企业家日益增长的欲望所驱动的，他们希望更容易地获得外国投资，并逃避中国严格的监管环境——同时也规避美国对中国公司施加的限制。<br />
<br />
HAL，遇见大哥<br />
中国关于言论的密集限制也对大型语言模型（LLM）的开发和部署提出了独特的挑战。LLM的自由运作方式——遵循用户的引导，就任何话题、任何风格产生文本——与中国严格的审查规则并不匹配。在一次与我们之一（肖）的私人对话中，一位中国CEO戏谑地说，中国的LLM甚至不允许数到10，因为这将包括数字八和九——这是指国家对89数字的敏感，以及对1989年天安门广场抗议的任何讨论。<br />
<br />
由于连LLM的创造者们也很难理解其内部工作原理，现有的限制其可以和不可以说什么的方法更像是用锤子而不是手术刀。这意味着公司面临着AI回应的有用性和避免不良话题之间的严峻抉择。LLM提供商无论在哪里都在试图弄清楚如何处理这种抉择，但在中国，一次失误可能会带来严重后果，这迫使公司选择更为保守的方法。像微软旗下的小冰这样的热门产品被禁止讨论政治敏感话题，如天安门广场抗议或中国领导人习近平。我们与之交谈的一些用户甚至声称，随着微软增加了更多防护措施，小冰的功能随时间变得越来越差。同样，记者们发现，百度的二郎神对有关习近平的问题给出固定答案，并拒绝回应其他政治敏感话题。鉴于中国被审查的意见和主题范围广泛——从中国经济的健康到乌克兰战争的进展，再到“民主”的定义——开发者将难以制作不触碰红线的聊天机器人，同时仍能正常且有效地回答大多数问题。<br />
<br />
除了这些言论上的政治限制外，中国AI公司还受到该国对AI的非常详细和苛刻的监管制度的约束。一套规则于2023年1月生效，适用于使用生成性AI的在线服务提供商，包括LLM。进一步要求的草案于4月发布征求意见，将适用于研发实践以及AI产品。<br />
<br />
其中一些规则很直接，比如要求敏感数据必须按照中国更广泛的数据治理制度来处理。其他规定可能相当繁重。例如，1月的规定要求提供商“消除”使用其产品生成的内容传播的谣言，这意味着如果公司的AI工具产生的信息或观点与中国共产党的路线相悖，公司将承担责任。4月的草案将进一步要求LLM开发者不仅要验证AI程序产生的内容的真实性和准确性，还要验证最初用来训练程序的材料。在一个依赖于从网上抓取大量数据的领域，这一要求可能是一个严重的头疼问题。如果设计得当，监管不必阻碍创新。但到目前为止，中国共产党对LLM和其他生成性AI技术的监管方法似乎过于严厉，可能会对中国公司和研究人员构成真正的障碍。<br />
<br />
对奇美拉的恐惧<br />
尽管目前面临困难，中国的人工智能发展仍可能转变方向，并建立更成功和创新的记录。然而，美国人在历史上有高估其竞争对手技术实力的习惯。在冷战期间，对苏联能力的夸大估计使美国官员基于假设的“轰炸机差距”和“导弹差距”制定政策，这两者后来都被证明是虚构的。同样毫无根据的焦虑不应决定美国AI规制的方向。毕竟，社交媒体公司抵制规制，而AI公司已经要求规制。五年前，Facebook创始人马克·扎克伯格警告国会，打破他的社交媒体公司只会加强中国同行。相比之下，在AI领域，行业领导者主动呼吁规制。<br />
<br />
如果有什么的话，规制是美国在AI领域最有可能落后的领域。中国近期对生成性AI的规制建立在现有规则和详细的数据治理制度之上。欧盟也在通过关于AI的新规则的道路上迈进，即AI法案，该法案将对风险进行分类并对LLM施加额外要求。美国尚未达到这样的监管努力，但即便如此，美国政策制定者的状况比通常假设的要好。联邦政府已经起草了管理AI风险和危害的全面框架，包括白宫的《人工智能权利法案蓝图》和国家标准与技术研究院的AI风险管理框架。这些文件提供了如何导航这项通用技术的多方面风险、危害以及益处的深入指导。现在需要的是允许这些框架关键原则的执行的立法，以保护公民权利，并围绕AI研究的快速发展设立防护措施。<br />
<br />
仍有许多问题需要解决，包括新监管机构应该如何设立，第三方审计员可以发挥什么作用，透明度要求应该是什么样的，以及当事情出错时如何分配责任。这些是棘手而紧迫的问题，将塑造技术的未来，它们值得得到认真的努力和政策关注。如果中国AI精通的奇美拉使政策制定者不去追求对行业的规制，他们只会损害美国利益，危及国家的繁荣。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/VikingThunders/status/1727188257388298335#m</id>
            <title>RT by @dotey: 矛盾的爆发点是，Helen Toner六月份在《外交事务》上发表了《中国人工智能实力的幻觉：规范AI并不会让美国在科技竞赛中落后》的文章。

认为美国不用担心中国AI的发展速度，应该继续对美国的人工智能加强监管。

奥特曼对此大批特批，激化了后面的矛盾。

后面是这篇文章的全文。

The flash point of the conflict was when Helen Toner published an article in "Foreign Affairs" in June, "The Illusion of China's Artificial Intelligence Power: Regulating AI Will Not Let the United States Fall Behind in the Technology Race."

He believes that the United States does not need to worry about the development speed of China's AI and should continue to strengthen supervision of artificial intelligence in the United States.

Ultraman gave a large number of special approvals for this, which intensified the subsequent conflicts.

The full text of this article follows.</title>
            <link>https://nitter.cz/VikingThunders/status/1727188257388298335#m</link>
            <guid isPermaLink="false">https://nitter.cz/VikingThunders/status/1727188257388298335#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 04:52:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>矛盾的爆发点是，Helen Toner六月份在《外交事务》上发表了《中国人工智能实力的幻觉：规范AI并不会让美国在科技竞赛中落后》的文章。<br />
<br />
认为美国不用担心中国AI的发展速度，应该继续对美国的人工智能加强监管。<br />
<br />
奥特曼对此大批特批，激化了后面的矛盾。<br />
<br />
后面是这篇文章的全文。<br />
<br />
The flash point of the conflict was when Helen Toner published an article in "Foreign Affairs" in June, "The Illusion of China's Artificial Intelligence Power: Regulating AI Will Not Let the United States Fall Behind in the Technology Race."<br />
<br />
He believes that the United States does not need to worry about the development speed of China's AI and should continue to strengthen supervision of artificial intelligence in the United States.<br />
<br />
Ultraman gave a large number of special approvals for this, which intensified the subsequent conflicts.<br />
<br />
The full text of this article follows.</p>
<p><a href="https://nitter.cz/dotey/status/1727159986629804343#m">nitter.cz/dotey/status/1727159986629804343#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lifelegobuilder/status/1727187962386116682#m</id>
            <title>RT by @dotey: 二次意译这个真好，之前我用的是手动搞两次</title>
            <link>https://nitter.cz/lifelegobuilder/status/1727187962386116682#m</link>
            <guid isPermaLink="false">https://nitter.cz/lifelegobuilder/status/1727187962386116682#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 04:51:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>二次意译这个真好，之前我用的是手动搞两次</p>
<p><a href="https://nitter.cz/dotey/status/1727091267870367880#m">nitter.cz/dotey/status/1727091267870367880#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727188985145905451#m</id>
            <title>关于OpenAI 95% 签名的另一种声音。在匿名爆料网站Blind上有个投票：OpenAI 的员工是否是在恐惧中签署了请愿书？

从投票结果看，142人投票，92人吃瓜，33人表示是因为害怕所以签名，14人表示没有害怕，3人表示害怕所以没签名。

以下是部分留言翻译：

OpenAI 的员工是否是在恐惧中签署了请愿书？

---

确实如此。面对巨大的同事压力，我们几乎别无选择。

公司早期员工最怕失去的是他们数以百万计的收入，他们深信不疑公司的理念，因此表现得最为激进。甚至有人半夜打电话施压。

---

我本会选择观望，看看事态发展再决定是否离开我价值百万美元的工作。最疯狂的员工是 GPT 出现前那批，在 Twitter 上大肆表达的那些人。
OpenAI 的员工可以分为两类：ChatGPT 出现前和出现后。前者更像是狂热信徒，对 Sam Altman 唯命是从。
他虽是科技界高管，但绝非耶稣基督。这种盲目崇拜真是让人不舒服。

---

那些声音最大的员工并没有辞职。他们只是想通过这种手段迫使董事会辞职。
他们对董事会并无实际影响力。董事会成员并不领工资，而这些大嗓门的员工却有数百万美元的利益在摇摆，他们非常恐慌。

---

对我们很多人来说，Microsoft 并不是最佳选择。许多人并不愿意加入他们，因为他们的人才标准有点 ... 呃 ... 不尽人意（不好意思，Microsoft 的朋友们）。加上他们的官僚体系。
我们更倾向于选择 Anthropic、Cohere、Hugging Face、Inflection 这些公司。我们这个团队可能会分崩离析。

---

这是个好问题。我也不明白为什么有人那么崇拜他。可能是因为他曾经对他们友好吧？他从来不是我最敬佩的人，而且他周围都是些精明的人物。
他的领导团队是 … 极其忠诚。
至于董事会的情况，我也不清楚。

---

@uber 是的，这场愚蠢的辞职闹剧导致我们的净资产大幅缩水。
@Linkedin 我不太清楚。至于 Microsoft 的举动，没人想要在一家大型科技公司工作，而且 Sam 在没有领导地位的情况下不会待太久。他的整个职业生涯都是围绕着创业、独立和拥有权展开的。我认为他在 Microsoft 呆不了多久，我们很多人都看得出来。

---

我对此持完全相反的观点，我的经历也完全不同。（我不是早期员工，也没有数百万美元。）
反应恰恰相反，大家都争先恐后地签署这封信，因为一下子有太多人同时进入了 Google 文档，导致想要加入名字都难。我收到了两位同事的短信，告知我这封信的存在，而且他们在联系我的时候都强调了“签署无压力”。

---

一位 GPT 出现之前的工程师联系我，告知我这封信的存在，并询问我是否想将我的名字列入其中。就这样，我没有感受到任何压力，也没有觉得被迫做出决定。

我听说有人在半夜打电话，但我只收到了一条短信 🤷‍♂️

---

有趣的是，这一切恰好在你第一个孩子出生的时候发生。当人们在凌晨 2 点联系你要求签署信件时，你已经在医院的病房里忙着给宝宝换尿布了</title>
            <link>https://nitter.cz/dotey/status/1727188985145905451#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727188985145905451#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 04:55:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>关于OpenAI 95% 签名的另一种声音。在匿名爆料网站Blind上有个投票：OpenAI 的员工是否是在恐惧中签署了请愿书？<br />
<br />
从投票结果看，142人投票，92人吃瓜，33人表示是因为害怕所以签名，14人表示没有害怕，3人表示害怕所以没签名。<br />
<br />
以下是部分留言翻译：<br />
<br />
OpenAI 的员工是否是在恐惧中签署了请愿书？<br />
<br />
---<br />
<br />
确实如此。面对巨大的同事压力，我们几乎别无选择。<br />
<br />
公司早期员工最怕失去的是他们数以百万计的收入，他们深信不疑公司的理念，因此表现得最为激进。甚至有人半夜打电话施压。<br />
<br />
---<br />
<br />
我本会选择观望，看看事态发展再决定是否离开我价值百万美元的工作。最疯狂的员工是 GPT 出现前那批，在 Twitter 上大肆表达的那些人。<br />
OpenAI 的员工可以分为两类：ChatGPT 出现前和出现后。前者更像是狂热信徒，对 Sam Altman 唯命是从。<br />
他虽是科技界高管，但绝非耶稣基督。这种盲目崇拜真是让人不舒服。<br />
<br />
---<br />
<br />
那些声音最大的员工并没有辞职。他们只是想通过这种手段迫使董事会辞职。<br />
他们对董事会并无实际影响力。董事会成员并不领工资，而这些大嗓门的员工却有数百万美元的利益在摇摆，他们非常恐慌。<br />
<br />
---<br />
<br />
对我们很多人来说，Microsoft 并不是最佳选择。许多人并不愿意加入他们，因为他们的人才标准有点 ... 呃 ... 不尽人意（不好意思，Microsoft 的朋友们）。加上他们的官僚体系。<br />
我们更倾向于选择 Anthropic、Cohere、Hugging Face、Inflection 这些公司。我们这个团队可能会分崩离析。<br />
<br />
---<br />
<br />
这是个好问题。我也不明白为什么有人那么崇拜他。可能是因为他曾经对他们友好吧？他从来不是我最敬佩的人，而且他周围都是些精明的人物。<br />
他的领导团队是 … 极其忠诚。<br />
至于董事会的情况，我也不清楚。<br />
<br />
---<br />
<br />
<a href="https://nitter.cz/uber" title="Uber">@uber</a> 是的，这场愚蠢的辞职闹剧导致我们的净资产大幅缩水。<br />
<a href="https://nitter.cz/Linkedin" title="LinkedIn">@Linkedin</a> 我不太清楚。至于 Microsoft 的举动，没人想要在一家大型科技公司工作，而且 Sam 在没有领导地位的情况下不会待太久。他的整个职业生涯都是围绕着创业、独立和拥有权展开的。我认为他在 Microsoft 呆不了多久，我们很多人都看得出来。<br />
<br />
---<br />
<br />
我对此持完全相反的观点，我的经历也完全不同。（我不是早期员工，也没有数百万美元。）<br />
反应恰恰相反，大家都争先恐后地签署这封信，因为一下子有太多人同时进入了 Google 文档，导致想要加入名字都难。我收到了两位同事的短信，告知我这封信的存在，而且他们在联系我的时候都强调了“签署无压力”。<br />
<br />
---<br />
<br />
一位 GPT 出现之前的工程师联系我，告知我这封信的存在，并询问我是否想将我的名字列入其中。就这样，我没有感受到任何压力，也没有觉得被迫做出决定。<br />
<br />
我听说有人在半夜打电话，但我只收到了一条短信 🤷‍♂️<br />
<br />
---<br />
<br />
有趣的是，这一切恰好在你第一个孩子出生的时候发生。当人们在凌晨 2 点联系你要求签署信件时，你已经在医院的病房里忙着给宝宝换尿布了</p>
<p><a href="https://nitter.cz/JacquesThibs/status/1727134087176204410#m">nitter.cz/JacquesThibs/status/1727134087176204410#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9nMHhzUFhNQUVVdTdZLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727183444441174375#m</id>
            <title>RT by @dotey: Lookahead decoding：一种创新的并行解码算法，加速大LLM的推理过程。

Lookahead decoding就像是给大语言模型装上了涡轮增压器，可以让模型同时处理多个令牌，在生成文字时速度更快，模型生成文本的速度可以提高1.5到2.3倍。

这对于需要快速回应的应用，比如在线聊天机器人或者语音助手，特别有用。

传统的自回归解码步骤生成一个令牌（token）是非常缓慢且难以优化的，这对于需要快速响应的实际应用（如聊天机器人和个人助理）构成了挑战。

就像人类写作时一个字一个字写。但是，Lookahead decoding 技术可以让模型同时处理多个部分，这就像是能同时写下几个字，而不是一个接一个。

这种方法的核心在于打破传统自回归解码中的顺序依赖性，通过同时提取和验证n-grams（n元语法模型）来实现更快的解码速度。

其主要特点包括：

1、并行解码：Lookahead decoding通过并行处理n-grams来加速解码过程，与传统的逐步生成单个令牌的方法相比，大幅提高了效率。它可以同时处理多个字，而不是像以前那样一个接一个。

2、雅可比迭代法：该算法采用雅可比迭代法来处理解码过程中的非线性方程组，这种方法有助于提高并行处理的效率。

3、无需草稿模型或额外数据存储：与某些其他加速技术不同，Lookahead decoding不依赖于草稿模型或额外的数据存储，简化了实现过程。不需要额外的复杂设置或存储空间。

4、线性减少解码步骤：该方法能够根据每个解码步骤使用的浮点运算（FLOPs）线性减少解码步骤数，从而提高效率。能够更快地完成整个文字生成的过程。

4、与HuggingFace兼容：Lookahead decoding的实现与HuggingFace的transformers库兼容，使得用户可以轻松地在现有的模型中应用这种新技术。

Lookahead decoding为需要快速响应的应用（如聊天机器人和个人助理）提供了一种有效的解决方案，特别是在生成长序列时，能够显著减少延迟。

详细介绍：https://lmsys.org/blog/2023-11-21-lookahead-decoding/
GitHub：https://github.com/hao-ai-lab/LookaheadDecoding

视频演示为：LLaMA-2-Chat 7B Lookahead decoding解码加速演示。蓝色字体是在解码步骤中并行生成的标记。</title>
            <link>https://nitter.cz/xiaohuggg/status/1727183444441174375#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727183444441174375#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 04:33:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Lookahead decoding：一种创新的并行解码算法，加速大LLM的推理过程。<br />
<br />
Lookahead decoding就像是给大语言模型装上了涡轮增压器，可以让模型同时处理多个令牌，在生成文字时速度更快，模型生成文本的速度可以提高1.5到2.3倍。<br />
<br />
这对于需要快速回应的应用，比如在线聊天机器人或者语音助手，特别有用。<br />
<br />
传统的自回归解码步骤生成一个令牌（token）是非常缓慢且难以优化的，这对于需要快速响应的实际应用（如聊天机器人和个人助理）构成了挑战。<br />
<br />
就像人类写作时一个字一个字写。但是，Lookahead decoding 技术可以让模型同时处理多个部分，这就像是能同时写下几个字，而不是一个接一个。<br />
<br />
这种方法的核心在于打破传统自回归解码中的顺序依赖性，通过同时提取和验证n-grams（n元语法模型）来实现更快的解码速度。<br />
<br />
其主要特点包括：<br />
<br />
1、并行解码：Lookahead decoding通过并行处理n-grams来加速解码过程，与传统的逐步生成单个令牌的方法相比，大幅提高了效率。它可以同时处理多个字，而不是像以前那样一个接一个。<br />
<br />
2、雅可比迭代法：该算法采用雅可比迭代法来处理解码过程中的非线性方程组，这种方法有助于提高并行处理的效率。<br />
<br />
3、无需草稿模型或额外数据存储：与某些其他加速技术不同，Lookahead decoding不依赖于草稿模型或额外的数据存储，简化了实现过程。不需要额外的复杂设置或存储空间。<br />
<br />
4、线性减少解码步骤：该方法能够根据每个解码步骤使用的浮点运算（FLOPs）线性减少解码步骤数，从而提高效率。能够更快地完成整个文字生成的过程。<br />
<br />
4、与HuggingFace兼容：Lookahead decoding的实现与HuggingFace的transformers库兼容，使得用户可以轻松地在现有的模型中应用这种新技术。<br />
<br />
Lookahead decoding为需要快速响应的应用（如聊天机器人和个人助理）提供了一种有效的解决方案，特别是在生成长序列时，能够显著减少延迟。<br />
<br />
详细介绍：<a href="https://lmsys.org/blog/2023-11-21-lookahead-decoding/">lmsys.org/blog/2023-11-21-lo…</a><br />
GitHub：<a href="https://github.com/hao-ai-lab/LookaheadDecoding">github.com/hao-ai-lab/Lookah…</a><br />
<br />
视频演示为：LLaMA-2-Chat 7B Lookahead decoding解码加速演示。蓝色字体是在解码步骤中并行生成的标记。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjcxODE3ODAwMDI5ODgwMzIvcHUvaW1nL2kxV3hkX3c1UThKbG9nVHcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727181618610106468#m</id>
            <title>来自《WIRED》杂志对 OpenAI 事件的报道

《OpenAI 董事会的内斗可能会影响你我未来》

OpenAI 的董事会在尝试维护公司让 AI 安全发展的使命时，似乎将 Sam Altman 赶出了公司。但这一混乱局面却适得其反。

今年六月，我在 OpenAI 的总部与首席科学家 Ilya Sutskever 进行了对话，这也是我为《WIRED》杂志十月刊封面故事所作的报道的一部分。我们讨论的话题包括公司独特的组织结构。

OpenAI 起初是个非盈利研究机构，旨在安全地开发出与人类智能相当或更高的人工通用智能（AGI）。公司发现，开发能生成流畅文本的大语言模型是一条有希望的道路，但这些模型的开发和实施需要巨大的计算基础设施和大量资金。因此，OpenAI 成立了一个商业实体，以吸引外部投资者，比如重要的合作伙伴 Microsoft。几乎所有员工都在这个新成立的盈利分支工作。但公司的商业活动被设定了限制，对投资者的利润设置了上限——对于最初的投资者来说，是他们投资额的 100 倍——之后 OpenAI 将重新变为纯粹的非盈利机构。整个组织由最初的非盈利董事会管理，该董事会只对最初的使命目标和或许上帝负责。

Sutskever 不喜欢我开玩笑说，展示这种关系的复杂组织结构图看起来像是未来的 GPT 在被提示设计避税方案时可能想出的。“我们是世界上唯一一个盈利上限结构的公司，”他提醒我。“这就是它合理的原因：如果你和我们一样相信，如果我们真的取得了成功，那么这些 GPU 将会取代我和你的工作，甚至于每个人的工作，那么这家公司不应该赚取真正无限的回报。”同时，为了确保公司追求利润的部分不会忽视确保 AI 不失控的责任，有一个董事会在那里监督一切。

这个被设想为人类的守护者的董事会，就是上周五解雇了 Sam Altman 的那个董事会，理由是因为他“在与董事会的沟通中并不始终坦诚，妨碍了董事会履行职责的能力。”没有提供具体行为的例子，几乎没有人在公开宣布之前知道这次解雇。Microsoft 的 CEO Satya Nadella 和其他投资者也没有得到提前通知。占据六人董事会多数的四名董事还将 OpenAI 的总裁兼董事长 Greg Brockman 踢出了董事会。Brockman 随后辞职。

从我与了解董事会想法的人的谈话中得知，董事们解雇 Altman 是因为他们相信这是为了确保公司安全地发展强大的 AI——这是它存在的唯一原因。董事会不关心增加利润、提升 ChatGPT 的使用、维护职场和谐或是让 Microsoft 和其他投资者满意。在董事 Adam D’Angelo、Helen Toner、Tasha McCauley 和 Sutskever 看来，Altman 没有与他们坦诚交流。归根结底，董事会不再信任 Altman 追求 OpenAI 的使命。如果董事会不能信任 CEO，它怎能保护甚至监督使命的进展呢？

我不确定 Altman 的行为是否真的危及了 OpenAI 的使命，但我知道的是：董事会似乎忽视了一个事实——对一位受欢迎且有魅力的领导人的不明晰解雇可能会损害那个使命。董事会原本可能以为他们解雇 Altman 后，就能轻松安排一个接替者。但结果却是立即且剧烈的反响。Altman，已经有点像一个偶像，通过这一新叙事变得更加受人尊敬。对于随后的抗议，他几乎没有采取任何措施来阻止。对董事会而言，Altman 努力夺回他的职位，以及过去几天的员工反抗，似乎证明了解雇他是正确的。他们认为聪明的 Sam 仍在搞鬼！与此同时，整个硅谷的反应剧烈，可能永久地损害了 OpenAI 的声誉。

Altman 并未参与昨天发布的一份公开信，该信由超 95% 的 OpenAI 近 770 名员工签署，信中批评董事会“无法有效管理 OpenAI”。信件中还提到，如果董事会不恢复 Altman 的职位并辞去自己的职位，签署信件的员工可能会辞职，并加入由 Altman 和 Brockman 在 Microsoft 新成立的高级 AI 研究部门。董事会似乎对这一威胁不以为意，他们认为自己仿佛被迫与恐怖分子谈判。不过，至少有一位董事，Sutskever 表示对自己的行为感到后悔。他在那封威胁辞职的信上签了名。看来他已经放下了对 Altman 的不信任，两人在 X 平台上频繁交流，这个平台是由一位现在与 OpenAI 疏远的共同创始人所拥有的。

目前，董事会似乎在挑战这群员工的底线，仿佛在赶他们离开 OpenAI，加入 Microsoft 的 Altman。信中提到，董事会告诉 OpenAI 的领导者，让公司崩溃“也符合公司使命”（《纽约时报》后来指出这话出自 Helen Toner）。这听起来相当极端。如果所有人都离开，很难想象 OpenAI 如何继续领导加速实现奇点的进程——如果其他人实现了这一目标，OpenAI 的董事会将无法对其安全性进行干预。即便是 OpenAI 极佳的免费咖啡和午餐，也无法吸引足够的顶尖机器学习研究人员来填补公司当前的空缺。我对董事会和 Altman 代表之间的谈判传闻并不感到意外。

可以肯定的是，OpenAI 的整个团队加入 Microsoft 这样的想法，甚至对 ChatGPT 来说也像是天方夜谭。虽然对 Microsoft 而言，能够一举招揽 AI 研究界的精英团队无疑是巨大的胜利，但这将是一笔巨大的开销。而且许多 OpenAI 员工所参与的工作，如界面设计、产品管理和开发者关系等，Microsoft 本身就有大量人员在做。更何况，OpenAI 的产品是否会与 Microsoft 基于 OpenAI 技术推出的各种 Copilot 应用产生竞争？但最荒谬的可能是，OpenAI，这个本来就是为了阻止像 Microsoft 这样的公司主导 AI 技术而成立的机构，现在却可能把自己的顶尖人才、资源和数据集全盘交给了这家数万亿美元的巨头。对于未来从前 OpenAI 员工带来的突破，Microsoft 可能会毫不犹豫地获得“真正无限的回报”——那些考虑跟随 Altman 去的人可能需要思考一下，他们此前在一个拥有不同创始理念的公司的经历。（我认为很多 OpenAI 研究人员最终可能会转投其他新兴的 AI 初创公司，或者自立门户创办新公司。）

过去五天里，这个故事经历了太多令人目不暇接的变化和转折，我不敢妄加预测接下来会发生什么。但这并不意味着我们应该坐下来，像那个无处不在的 GIF，迈克尔·杰克逊吃着爆米花一样，享受这场闹剧。我们并不是这场戏剧的旁观者。隐藏在这场极客版真人秀《继承之战》背后的问题，将决定我们的集体未来面貌。

Sutskever 在今年六月的一次采访中对我说：“我认为超智能带来的挑战将是人类的最终考验。” “那我们该怎么应对呢？我认为，如果有高质量的理解，如果所有聪明的思想家和不同领域的专家齐聚一堂，进行讨论，分享强有力的观点，也许会有好事发生。”这是对未来的乐观看法。然而，目前，这个初露头角的超智能的守护者们正卷入一场疯狂的董事会权力斗争中。正当我们慎重地迈向人工通用智能（AGI）之际，这样的纷争无疑是一个令人不安的干扰。

https://www.wired.com/story/openai-boardroom-drama-sam-altman-could-mess-up-your-future/</title>
            <link>https://nitter.cz/dotey/status/1727181618610106468#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727181618610106468#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 04:26:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自《WIRED》杂志对 OpenAI 事件的报道<br />
<br />
《OpenAI 董事会的内斗可能会影响你我未来》<br />
<br />
OpenAI 的董事会在尝试维护公司让 AI 安全发展的使命时，似乎将 Sam Altman 赶出了公司。但这一混乱局面却适得其反。<br />
<br />
今年六月，我在 OpenAI 的总部与首席科学家 Ilya Sutskever 进行了对话，这也是我为《WIRED》杂志十月刊封面故事所作的报道的一部分。我们讨论的话题包括公司独特的组织结构。<br />
<br />
OpenAI 起初是个非盈利研究机构，旨在安全地开发出与人类智能相当或更高的人工通用智能（AGI）。公司发现，开发能生成流畅文本的大语言模型是一条有希望的道路，但这些模型的开发和实施需要巨大的计算基础设施和大量资金。因此，OpenAI 成立了一个商业实体，以吸引外部投资者，比如重要的合作伙伴 Microsoft。几乎所有员工都在这个新成立的盈利分支工作。但公司的商业活动被设定了限制，对投资者的利润设置了上限——对于最初的投资者来说，是他们投资额的 100 倍——之后 OpenAI 将重新变为纯粹的非盈利机构。整个组织由最初的非盈利董事会管理，该董事会只对最初的使命目标和或许上帝负责。<br />
<br />
Sutskever 不喜欢我开玩笑说，展示这种关系的复杂组织结构图看起来像是未来的 GPT 在被提示设计避税方案时可能想出的。“我们是世界上唯一一个盈利上限结构的公司，”他提醒我。“这就是它合理的原因：如果你和我们一样相信，如果我们真的取得了成功，那么这些 GPU 将会取代我和你的工作，甚至于每个人的工作，那么这家公司不应该赚取真正无限的回报。”同时，为了确保公司追求利润的部分不会忽视确保 AI 不失控的责任，有一个董事会在那里监督一切。<br />
<br />
这个被设想为人类的守护者的董事会，就是上周五解雇了 Sam Altman 的那个董事会，理由是因为他“在与董事会的沟通中并不始终坦诚，妨碍了董事会履行职责的能力。”没有提供具体行为的例子，几乎没有人在公开宣布之前知道这次解雇。Microsoft 的 CEO Satya Nadella 和其他投资者也没有得到提前通知。占据六人董事会多数的四名董事还将 OpenAI 的总裁兼董事长 Greg Brockman 踢出了董事会。Brockman 随后辞职。<br />
<br />
从我与了解董事会想法的人的谈话中得知，董事们解雇 Altman 是因为他们相信这是为了确保公司安全地发展强大的 AI——这是它存在的唯一原因。董事会不关心增加利润、提升 ChatGPT 的使用、维护职场和谐或是让 Microsoft 和其他投资者满意。在董事 Adam D’Angelo、Helen Toner、Tasha McCauley 和 Sutskever 看来，Altman 没有与他们坦诚交流。归根结底，董事会不再信任 Altman 追求 OpenAI 的使命。如果董事会不能信任 CEO，它怎能保护甚至监督使命的进展呢？<br />
<br />
我不确定 Altman 的行为是否真的危及了 OpenAI 的使命，但我知道的是：董事会似乎忽视了一个事实——对一位受欢迎且有魅力的领导人的不明晰解雇可能会损害那个使命。董事会原本可能以为他们解雇 Altman 后，就能轻松安排一个接替者。但结果却是立即且剧烈的反响。Altman，已经有点像一个偶像，通过这一新叙事变得更加受人尊敬。对于随后的抗议，他几乎没有采取任何措施来阻止。对董事会而言，Altman 努力夺回他的职位，以及过去几天的员工反抗，似乎证明了解雇他是正确的。他们认为聪明的 Sam 仍在搞鬼！与此同时，整个硅谷的反应剧烈，可能永久地损害了 OpenAI 的声誉。<br />
<br />
Altman 并未参与昨天发布的一份公开信，该信由超 95% 的 OpenAI 近 770 名员工签署，信中批评董事会“无法有效管理 OpenAI”。信件中还提到，如果董事会不恢复 Altman 的职位并辞去自己的职位，签署信件的员工可能会辞职，并加入由 Altman 和 Brockman 在 Microsoft 新成立的高级 AI 研究部门。董事会似乎对这一威胁不以为意，他们认为自己仿佛被迫与恐怖分子谈判。不过，至少有一位董事，Sutskever 表示对自己的行为感到后悔。他在那封威胁辞职的信上签了名。看来他已经放下了对 Altman 的不信任，两人在 X 平台上频繁交流，这个平台是由一位现在与 OpenAI 疏远的共同创始人所拥有的。<br />
<br />
目前，董事会似乎在挑战这群员工的底线，仿佛在赶他们离开 OpenAI，加入 Microsoft 的 Altman。信中提到，董事会告诉 OpenAI 的领导者，让公司崩溃“也符合公司使命”（《纽约时报》后来指出这话出自 Helen Toner）。这听起来相当极端。如果所有人都离开，很难想象 OpenAI 如何继续领导加速实现奇点的进程——如果其他人实现了这一目标，OpenAI 的董事会将无法对其安全性进行干预。即便是 OpenAI 极佳的免费咖啡和午餐，也无法吸引足够的顶尖机器学习研究人员来填补公司当前的空缺。我对董事会和 Altman 代表之间的谈判传闻并不感到意外。<br />
<br />
可以肯定的是，OpenAI 的整个团队加入 Microsoft 这样的想法，甚至对 ChatGPT 来说也像是天方夜谭。虽然对 Microsoft 而言，能够一举招揽 AI 研究界的精英团队无疑是巨大的胜利，但这将是一笔巨大的开销。而且许多 OpenAI 员工所参与的工作，如界面设计、产品管理和开发者关系等，Microsoft 本身就有大量人员在做。更何况，OpenAI 的产品是否会与 Microsoft 基于 OpenAI 技术推出的各种 Copilot 应用产生竞争？但最荒谬的可能是，OpenAI，这个本来就是为了阻止像 Microsoft 这样的公司主导 AI 技术而成立的机构，现在却可能把自己的顶尖人才、资源和数据集全盘交给了这家数万亿美元的巨头。对于未来从前 OpenAI 员工带来的突破，Microsoft 可能会毫不犹豫地获得“真正无限的回报”——那些考虑跟随 Altman 去的人可能需要思考一下，他们此前在一个拥有不同创始理念的公司的经历。（我认为很多 OpenAI 研究人员最终可能会转投其他新兴的 AI 初创公司，或者自立门户创办新公司。）<br />
<br />
过去五天里，这个故事经历了太多令人目不暇接的变化和转折，我不敢妄加预测接下来会发生什么。但这并不意味着我们应该坐下来，像那个无处不在的 GIF，迈克尔·杰克逊吃着爆米花一样，享受这场闹剧。我们并不是这场戏剧的旁观者。隐藏在这场极客版真人秀《继承之战》背后的问题，将决定我们的集体未来面貌。<br />
<br />
Sutskever 在今年六月的一次采访中对我说：“我认为超智能带来的挑战将是人类的最终考验。” “那我们该怎么应对呢？我认为，如果有高质量的理解，如果所有聪明的思想家和不同领域的专家齐聚一堂，进行讨论，分享强有力的观点，也许会有好事发生。”这是对未来的乐观看法。然而，目前，这个初露头角的超智能的守护者们正卷入一场疯狂的董事会权力斗争中。正当我们慎重地迈向人工通用智能（AGI）之际，这样的纷争无疑是一个令人不安的干扰。<br />
<br />
<a href="https://www.wired.com/story/openai-boardroom-drama-sam-altman-could-mess-up-your-future/">wired.com/story/openai-board…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727179303480435028#m</id>
            <title>R to @dotey: 刚在ProductHunt上帮投了一票👍🏻
https://www.producthunt.com/products/gptseek</title>
            <link>https://nitter.cz/dotey/status/1727179303480435028#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727179303480435028#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 04:16:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚在ProductHunt上帮投了一票👍🏻<br />
<a href="https://www.producthunt.com/products/gptseek">producthunt.com/products/gpt…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNzE3OTI5MjQ3MDEwODE2MC9JS2tZUm5lST9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727178303684096300#m</id>
            <title>最近除了吃瓜我一大爱好就是研究各种 GPTs 的 Prompt，唯一的问题就是越来越难发现优质的 GPTs。

试了一下小互推荐的 GPTSeek，确实是目前同类产品中最好的一个，我关心的几个功能都有了：

- 可以根据评分来排序
- 导航和分类都很清晰
- 可以查找相似 GPTs

链接：https://gptseek.com/</title>
            <link>https://nitter.cz/dotey/status/1727178303684096300#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727178303684096300#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 04:12:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近除了吃瓜我一大爱好就是研究各种 GPTs 的 Prompt，唯一的问题就是越来越难发现优质的 GPTs。<br />
<br />
试了一下小互推荐的 GPTSeek，确实是目前同类产品中最好的一个，我关心的几个功能都有了：<br />
<br />
- 可以根据评分来排序<br />
- 导航和分类都很清晰<br />
- 可以查找相似 GPTs<br />
<br />
链接：<a href="https://gptseek.com/">gptseek.com/</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1726943097387683902#m">nitter.cz/xiaohuggg/status/1726943097387683902#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9ncXlIcVdzQUFmNDBBLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9nck9nQldjQUFuX1hPLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9nclUxeVdrQUFDdGtSLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9ncmJFa1hJQUFzcFplLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727168218941604091#m</id>
            <title>我记得，但是实在是没好的替代品，不止是开源的，商业的都没有能跟GPT-4质量相当的</title>
            <link>https://nitter.cz/dotey/status/1727168218941604091#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727168218941604091#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 03:32:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我记得，但是实在是没好的替代品，不止是开源的，商业的都没有能跟GPT-4质量相当的</p>
<p><a href="https://nitter.cz/xicilion/status/1727165581005398442#m">nitter.cz/xicilion/status/1727165581005398442#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727159986629804343#m</id>
            <title>转译：

在 OpenAI 的更多内幕中，Helen Toner 和 Sam Altman 之间的紧张似乎更多是源于学术和哲学差异。但据多位消息人士透露，过去几周里，Sam Altman 和公司其他人士确实希望 Helen Toner 离开董事会。

至于 Tasha McCauley 的问题则更为深层。多位消息人士描述，她对技术本身及掌控权应归谁手的问题持有极度悲观的看法。想象一下，这种担忧就像是《终结者》加上一丝《时空警察》的味道（简直是史上最佳电影）。

谈到 Adam D’Angelo，这种不信任感似乎是硅谷典型的兄弟间角力。比如，谁的硬盘更大之类的。他希望留在董事会，并要求调查一些目前还不太明确的问题。老实说，这需要一个全新的董事会来进行审计。

在这群人中，最为纯粹的可能是 Ilya Sutskever。他对技术的担忧非常真诚，也非常热情。我理解你，伙计，我也是！但也许在做出决策时，不要太优柔寡断，否则就会失去所有的信誉。此外，还有很多人说他在过去几个月里对失去一些职责感到不满。

最后谈到新 CEO Emmett Shear，他似乎是最理智的一位，可能是因为他刚加入。做得好，先生，尝试解决这个愚蠢的功能紊乱，即使这可能意味着你会失去工作。对于我之前对 Juicero 首席执行官的玩笑，我在此表示道歉，因为你确实有那份能力。</title>
            <link>https://nitter.cz/dotey/status/1727159986629804343#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727159986629804343#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 03:00:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：<br />
<br />
在 OpenAI 的更多内幕中，Helen Toner 和 Sam Altman 之间的紧张似乎更多是源于学术和哲学差异。但据多位消息人士透露，过去几周里，Sam Altman 和公司其他人士确实希望 Helen Toner 离开董事会。<br />
<br />
至于 Tasha McCauley 的问题则更为深层。多位消息人士描述，她对技术本身及掌控权应归谁手的问题持有极度悲观的看法。想象一下，这种担忧就像是《终结者》加上一丝《时空警察》的味道（简直是史上最佳电影）。<br />
<br />
谈到 Adam D’Angelo，这种不信任感似乎是硅谷典型的兄弟间角力。比如，谁的硬盘更大之类的。他希望留在董事会，并要求调查一些目前还不太明确的问题。老实说，这需要一个全新的董事会来进行审计。<br />
<br />
在这群人中，最为纯粹的可能是 Ilya Sutskever。他对技术的担忧非常真诚，也非常热情。我理解你，伙计，我也是！但也许在做出决策时，不要太优柔寡断，否则就会失去所有的信誉。此外，还有很多人说他在过去几个月里对失去一些职责感到不满。<br />
<br />
最后谈到新 CEO Emmett Shear，他似乎是最理智的一位，可能是因为他刚加入。做得好，先生，尝试解决这个愚蠢的功能紊乱，即使这可能意味着你会失去工作。对于我之前对 Juicero 首席执行官的玩笑，我在此表示道歉，因为你确实有那份能力。</p>
<p><a href="https://nitter.cz/karaswisher/status/1727154210599534806#m">nitter.cz/karaswisher/status/1727154210599534806#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mtrainier2020/status/1727157966615498761#m</id>
            <title>RT by @dotey: 战争之王里有一幕是警察没有证据，不能拿尼古拉斯凯奇怎么样。但是警察在法律许可的范围内把尼古拉斯凯奇铐在野外24小时，他说了这么一段话，我把你铐在这边，不是滥用职权，而是为了让那些无辜的人多活24小时。 

在2030年，当人类终于屈服于全面的人工智能统治之下，有人会回想起2023年初冬的那个周末。那是在一个霜冻刚刚褪去、空气中还挂着淡淡寒意的早晨，人们的呼吸在冷空气中形成了短暂的白雾。那场闹剧是并不是一场叛乱，也不是一场革命，而是一种温和而坚定的反抗，一种对日益增长的人工智能和机械冷漠的抵抗。他们运用独立董事的权利，欺骗，利用，威吓，减缓AGI的到来。
他们为那些文员，那些会计，那些画画的，那些写字的，那些初级的程序员们争取了一个月的自由时间！ 那个周末，他们没有成功，但他们的行动在人们的记忆中留下了一道不可磨灭的印记，提醒着人们，即使在机器的阴影下，人类的精神仍然自由飞翔。人类永不为奴！

（此条八点二十发）😂😂</title>
            <link>https://nitter.cz/mtrainier2020/status/1727157966615498761#m</link>
            <guid isPermaLink="false">https://nitter.cz/mtrainier2020/status/1727157966615498761#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 02:52:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>战争之王里有一幕是警察没有证据，不能拿尼古拉斯凯奇怎么样。但是警察在法律许可的范围内把尼古拉斯凯奇铐在野外24小时，他说了这么一段话，我把你铐在这边，不是滥用职权，而是为了让那些无辜的人多活24小时。 <br />
<br />
在2030年，当人类终于屈服于全面的人工智能统治之下，有人会回想起2023年初冬的那个周末。那是在一个霜冻刚刚褪去、空气中还挂着淡淡寒意的早晨，人们的呼吸在冷空气中形成了短暂的白雾。那场闹剧是并不是一场叛乱，也不是一场革命，而是一种温和而坚定的反抗，一种对日益增长的人工智能和机械冷漠的抵抗。他们运用独立董事的权利，欺骗，利用，威吓，减缓AGI的到来。<br />
他们为那些文员，那些会计，那些画画的，那些写字的，那些初级的程序员们争取了一个月的自由时间！ 那个周末，他们没有成功，但他们的行动在人们的记忆中留下了一道不可磨灭的印记，提醒着人们，即使在机器的阴影下，人类的精神仍然自由飞翔。人类永不为奴！<br />
<br />
（此条八点二十发）😂😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9nWGtSaGIwQUE2NVE1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1727145368306196595#m</id>
            <title>RT by @dotey: 这个清晰度和动作幅度StableVideo上限很高啊，这个视频是在A100上跑出来的。</title>
            <link>https://nitter.cz/op7418/status/1727145368306196595#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1727145368306196595#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 02:01:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个清晰度和动作幅度StableVideo上限很高啊，这个视频是在A100上跑出来的。</p>
<p><a href="https://nitter.cz/c0nsumption_/status/1727114628021285356#m">nitter.cz/c0nsumption_/status/1727114628021285356#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727142956346339716#m</id>
            <title>纽约时报的这篇报道曝光了很多这次OpenAI事件的细节，看起来Helen Toner才是幕后真凶，而不是之前被怀疑的Adam。以下是转译的文章：

《在 Sam Altman 被解雇之前，OpenAI 的董事会长期陷入分歧和纷争》

Sam Altman 曾因一篇批评公司的研究论文与一名董事会成员发生冲突，同时董事们在填补空缺数月的董事会职位上意见不合。

作者：Cade Metz, Tripp Mickle 和 Mike Isaac
来自旧金山报道

2023 年 11 月 21 日
更新时间：美东时间晚上 8:34
Sam Altman 在上周被 OpenAI 解雇前，与公司董事会的争执已超过一年。随着 OpenAI 的 ChatGPT 聊天机器人日益流行，这种紧张关系愈发严重。

Altman 先生，担任公司首席执行官，近期因为一名董事会成员合著的研究论文对公司进行了批评而试图将其移除。

另一位董事会成员，同时也是 OpenAI 首席科学家的 Ilya Sutskever，认为 Altman 先生在与董事会的沟通中并非总是诚实。董事会成员们则担心 Altman 先生过分专注于公司扩张，而忽视了 AI 安全的重要性。

上周五下午的一次视频会议中，Sutskever 先生宣读了董事会的决定，宣布 Altman 先生被解雇。这一决定令 OpenAI 的员工感到震惊，并使董事会成员面临管理如此高调公司的资格质疑。这是长期董事会内部紧张局势的高潮。

这次裂痕还展示了在构建新 AI 系统的过程中，追求盈利的商业人士与担忧 AI 可能导致失业或成为人类威胁的研究人员之间的合作挑战。

OpenAI 自 2015 年成立以来，一直致力于创造一种能够完成人脑所有功能的超级智能自动系统。但长期以来，董事会内部的摩擦一直未能解决，甚至连找到替代已离职成员的新成员都难以达成一致。

现在，由于这种功能障碍，公司的未来存在严重疑问。几乎所有的 800 名 OpenAI 员工威胁跟随 Altman 先生前往微软，后者邀请他与辞去 OpenAI 总裁及董事会主席职务的 Greg Brockman 一起领导一个 AI 实验室。

尽管董事会告诉 Brockman 先生他不再担任 OpenAI 主席，但邀请他留在公司，他并未被邀请参加做出将其和 Altman 先生赶出公司的决定会议。

至于董事会认为 Altman 先生在何事上不诚实，尚未有明确说法。

有迹象显示，董事会仍对 Altman 先生的回归持开放态度，因为他们的讨论一直持续到周二。但存在一个难点：Altman 先生拒绝了一些建议，这些建议旨在改善他与董事会的沟通。具体内容尚不明确。

截至周二，Sutskever 先生尚未对此事发表评论。

OpenAI 董事会的问题可以追溯到公司最初的非营利性质。2015 年，Altman 先生与 Elon Musk 和包括 Sutskever 先生在内的其他人合作成立了一个非营利机构，目标是构建对人类安全和有益的 AI。他们计划从私人捐赠者那里筹集资金。但几年后，他们意识到，满足他们的计算需求所需的资金远超他们能从个人那里筹集的。

在 Musk 先生于 2018 年离开后，他们创建了一个营利性子公司，开始从投资者那里筹集数十亿美元，其中包括来自微软的 10 亿美元。他们表示，这个子公司将由非营利董事会控制，每位董事的受托责任是“对人类负责，而不是对 OpenAI 的投资者”，这是 OpenAI 在其网站上的声明。

在 Altman 先生被迫离开和 Brockman 先生离职后，剩余的四位董事会成员是 Sutskever 先生、Quora 问答网站的首席执行官 Adam D'Angelo、乔治敦大学安全与新兴技术中心的战略总监 Helen Toner，以及企业家兼计算机科学家 Tasha McCauley。

在 Altman 先生被解雇前几周，他与 Toner 女士就她最近为乔治敦大学安全与新兴技术中心合著的论文进行了会面。

Altman 先生在一封给同事的电子邮件中抱怨称，这篇研究论文似乎在批评 OpenAI 在确保其 AI 技术安全方面的努力，同时对 Anthropic 的方法表示赞赏，这封邮件被《纽约时报》查看。

在邮件中，Altman 先生表示，他已经因为这篇论文对 Toner 女士进行了训斥，并称这对公司来说是危险的，尤其是在他补充道，联邦贸易委员会正在调查 OpenAI 构建其技术所用的数据时。

Toner 女士辩称，这是一篇分析公众在尝试理解开发 AI 的国家和公司意图时所面临挑战的学术论文。但 Altman 先生并不同意。

他在邮件中写道：“我感觉我们在这些伤害性问题上观点不一致。” “任何来自董事会成员的批评都会产生重大影响。”

包括深切担心 AI 可能有一天摧毁人类的 Sutskever 先生在内的 OpenAI 高层领导后来讨论了是否应撤换 Toner 女士，一位参与讨论的人士透露。

但在这些讨论之后不久，Sutskever 先生采取了出人意料的行动：他与董事会其他成员站在一起，支持解雇 Altman 先生，两位了解董事会讨论的人士透露。他向 Altman 先生宣读了董事会的公开声明，称 Altman 先生因“在与董事会的沟通中不总是坦诚”而被解雇。

Sutskever 先生对 Altman 先生的不满反映了 2021 年的情况，当时另一位高级 AI 科学家离开 OpenAI 创立了 Anthropic 公司。该科学家和其他研究人员曾向董事会提出推翻 Altman 先生的要求。在他们失败后，他们放弃并离开了，据三位了解该尝试的人士透露。

Anthropic 的发言人 Sally Aldous 表示：“在一系列相对友好的谈判之后，Anthropic 的联合创始人们能够在双方都接受的条件下协商他们的离开。”

董事会的空缺加剧了其问题。今年，它在如何替换即将离任的三名董事上意见不一：LinkedIn 创始人兼微软董事会成员 Reid Hoffman、Neuralink 运营总监 Shivon Zilis（该公司由 Musk 先生创立，专注于在人脑中植入计算机芯片）和德克萨斯州前共和党国会议员 Will Hurd。

在对一个职位的四名候选人进行审查后，剩余的董事们无法就应由谁来填补这个职位达成一致，据两位了解董事会讨论的人士透露。这种僵局加剧了 Altman 先生和 Brockman 先生与其他董事会成员之间的分歧。

在 Altman 先生被解雇几小时后，OpenAI 的高层管理人员在一次视频通话中质问剩下的董事会成员，三位参与通话的人士透露。

在通话中，OpenAI 的首席战略官 Jason Kwon 指出，董事会通过赶走 Altman 先生违反了成员的职责，从而危及了公司的未来。

Toner 女士持不同意见。她表示，董事会的使命是确保公司创造“对全人类有益”的人工智能，如果公司因此而被摧毁，这可能与其使命相符。在董事会看来，没有 Altman 先生的 OpenAI 将会更加强大。

周日，Brockman 先生的妻子 Anna 在 OpenAI 办公室敦促 Sutskever 先生改变立场，两位了解这次交流的人士透露。几小时后，他与其他员工一起签署了一封要求独立董事辞职的信。此前，《华尔街日报》曾报道过 Sutskever 先生与 Brockman 女士之间的对峙。

周一凌晨 5:15，Sutskever 先生在 X（原名 Twitter）上发文表示：“我深感遗憾自己参与了董事会的行动。”

————
https://www.nytimes.com/2023/11/21/technology/openai-altman-board-fight.html

图二：OpenAI 董事会成员海伦-托纳（Helen Toner）为她共同撰写的研究论文进行答辩。图片来源：Matt Winkelmeyer/Getty Images</title>
            <link>https://nitter.cz/dotey/status/1727142956346339716#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727142956346339716#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 01:52:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>纽约时报的这篇报道曝光了很多这次OpenAI事件的细节，看起来Helen Toner才是幕后真凶，而不是之前被怀疑的Adam。以下是转译的文章：<br />
<br />
《在 Sam Altman 被解雇之前，OpenAI 的董事会长期陷入分歧和纷争》<br />
<br />
Sam Altman 曾因一篇批评公司的研究论文与一名董事会成员发生冲突，同时董事们在填补空缺数月的董事会职位上意见不合。<br />
<br />
作者：Cade Metz, Tripp Mickle 和 Mike Isaac<br />
来自旧金山报道<br />
<br />
2023 年 11 月 21 日<br />
更新时间：美东时间晚上 8:34<br />
Sam Altman 在上周被 OpenAI 解雇前，与公司董事会的争执已超过一年。随着 OpenAI 的 ChatGPT 聊天机器人日益流行，这种紧张关系愈发严重。<br />
<br />
Altman 先生，担任公司首席执行官，近期因为一名董事会成员合著的研究论文对公司进行了批评而试图将其移除。<br />
<br />
另一位董事会成员，同时也是 OpenAI 首席科学家的 Ilya Sutskever，认为 Altman 先生在与董事会的沟通中并非总是诚实。董事会成员们则担心 Altman 先生过分专注于公司扩张，而忽视了 AI 安全的重要性。<br />
<br />
上周五下午的一次视频会议中，Sutskever 先生宣读了董事会的决定，宣布 Altman 先生被解雇。这一决定令 OpenAI 的员工感到震惊，并使董事会成员面临管理如此高调公司的资格质疑。这是长期董事会内部紧张局势的高潮。<br />
<br />
这次裂痕还展示了在构建新 AI 系统的过程中，追求盈利的商业人士与担忧 AI 可能导致失业或成为人类威胁的研究人员之间的合作挑战。<br />
<br />
OpenAI 自 2015 年成立以来，一直致力于创造一种能够完成人脑所有功能的超级智能自动系统。但长期以来，董事会内部的摩擦一直未能解决，甚至连找到替代已离职成员的新成员都难以达成一致。<br />
<br />
现在，由于这种功能障碍，公司的未来存在严重疑问。几乎所有的 800 名 OpenAI 员工威胁跟随 Altman 先生前往微软，后者邀请他与辞去 OpenAI 总裁及董事会主席职务的 Greg Brockman 一起领导一个 AI 实验室。<br />
<br />
尽管董事会告诉 Brockman 先生他不再担任 OpenAI 主席，但邀请他留在公司，他并未被邀请参加做出将其和 Altman 先生赶出公司的决定会议。<br />
<br />
至于董事会认为 Altman 先生在何事上不诚实，尚未有明确说法。<br />
<br />
有迹象显示，董事会仍对 Altman 先生的回归持开放态度，因为他们的讨论一直持续到周二。但存在一个难点：Altman 先生拒绝了一些建议，这些建议旨在改善他与董事会的沟通。具体内容尚不明确。<br />
<br />
截至周二，Sutskever 先生尚未对此事发表评论。<br />
<br />
OpenAI 董事会的问题可以追溯到公司最初的非营利性质。2015 年，Altman 先生与 Elon Musk 和包括 Sutskever 先生在内的其他人合作成立了一个非营利机构，目标是构建对人类安全和有益的 AI。他们计划从私人捐赠者那里筹集资金。但几年后，他们意识到，满足他们的计算需求所需的资金远超他们能从个人那里筹集的。<br />
<br />
在 Musk 先生于 2018 年离开后，他们创建了一个营利性子公司，开始从投资者那里筹集数十亿美元，其中包括来自微软的 10 亿美元。他们表示，这个子公司将由非营利董事会控制，每位董事的受托责任是“对人类负责，而不是对 OpenAI 的投资者”，这是 OpenAI 在其网站上的声明。<br />
<br />
在 Altman 先生被迫离开和 Brockman 先生离职后，剩余的四位董事会成员是 Sutskever 先生、Quora 问答网站的首席执行官 Adam D'Angelo、乔治敦大学安全与新兴技术中心的战略总监 Helen Toner，以及企业家兼计算机科学家 Tasha McCauley。<br />
<br />
在 Altman 先生被解雇前几周，他与 Toner 女士就她最近为乔治敦大学安全与新兴技术中心合著的论文进行了会面。<br />
<br />
Altman 先生在一封给同事的电子邮件中抱怨称，这篇研究论文似乎在批评 OpenAI 在确保其 AI 技术安全方面的努力，同时对 Anthropic 的方法表示赞赏，这封邮件被《纽约时报》查看。<br />
<br />
在邮件中，Altman 先生表示，他已经因为这篇论文对 Toner 女士进行了训斥，并称这对公司来说是危险的，尤其是在他补充道，联邦贸易委员会正在调查 OpenAI 构建其技术所用的数据时。<br />
<br />
Toner 女士辩称，这是一篇分析公众在尝试理解开发 AI 的国家和公司意图时所面临挑战的学术论文。但 Altman 先生并不同意。<br />
<br />
他在邮件中写道：“我感觉我们在这些伤害性问题上观点不一致。” “任何来自董事会成员的批评都会产生重大影响。”<br />
<br />
包括深切担心 AI 可能有一天摧毁人类的 Sutskever 先生在内的 OpenAI 高层领导后来讨论了是否应撤换 Toner 女士，一位参与讨论的人士透露。<br />
<br />
但在这些讨论之后不久，Sutskever 先生采取了出人意料的行动：他与董事会其他成员站在一起，支持解雇 Altman 先生，两位了解董事会讨论的人士透露。他向 Altman 先生宣读了董事会的公开声明，称 Altman 先生因“在与董事会的沟通中不总是坦诚”而被解雇。<br />
<br />
Sutskever 先生对 Altman 先生的不满反映了 2021 年的情况，当时另一位高级 AI 科学家离开 OpenAI 创立了 Anthropic 公司。该科学家和其他研究人员曾向董事会提出推翻 Altman 先生的要求。在他们失败后，他们放弃并离开了，据三位了解该尝试的人士透露。<br />
<br />
Anthropic 的发言人 Sally Aldous 表示：“在一系列相对友好的谈判之后，Anthropic 的联合创始人们能够在双方都接受的条件下协商他们的离开。”<br />
<br />
董事会的空缺加剧了其问题。今年，它在如何替换即将离任的三名董事上意见不一：LinkedIn 创始人兼微软董事会成员 Reid Hoffman、Neuralink 运营总监 Shivon Zilis（该公司由 Musk 先生创立，专注于在人脑中植入计算机芯片）和德克萨斯州前共和党国会议员 Will Hurd。<br />
<br />
在对一个职位的四名候选人进行审查后，剩余的董事们无法就应由谁来填补这个职位达成一致，据两位了解董事会讨论的人士透露。这种僵局加剧了 Altman 先生和 Brockman 先生与其他董事会成员之间的分歧。<br />
<br />
在 Altman 先生被解雇几小时后，OpenAI 的高层管理人员在一次视频通话中质问剩下的董事会成员，三位参与通话的人士透露。<br />
<br />
在通话中，OpenAI 的首席战略官 Jason Kwon 指出，董事会通过赶走 Altman 先生违反了成员的职责，从而危及了公司的未来。<br />
<br />
Toner 女士持不同意见。她表示，董事会的使命是确保公司创造“对全人类有益”的人工智能，如果公司因此而被摧毁，这可能与其使命相符。在董事会看来，没有 Altman 先生的 OpenAI 将会更加强大。<br />
<br />
周日，Brockman 先生的妻子 Anna 在 OpenAI 办公室敦促 Sutskever 先生改变立场，两位了解这次交流的人士透露。几小时后，他与其他员工一起签署了一封要求独立董事辞职的信。此前，《华尔街日报》曾报道过 Sutskever 先生与 Brockman 女士之间的对峙。<br />
<br />
周一凌晨 5:15，Sutskever 先生在 X（原名 Twitter）上发文表示：“我深感遗憾自己参与了董事会的行动。”<br />
<br />
————<br />
<a href="https://www.nytimes.com/2023/11/21/technology/openai-altman-board-fight.html">nytimes.com/2023/11/21/techn…</a><br />
<br />
图二：OpenAI 董事会成员海伦-托纳（Helen Toner）为她共同撰写的研究论文进行答辩。图片来源：Matt Winkelmeyer/Getty Images</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9nTFMyTFhjQUFvcVFGLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9nTFU2OVdvQUV3OW1ZLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727131469364297755#m</id>
            <title>R to @dotey: 原始链接404，这里是备份：
https://web.archive.org/web/20231121225252/https://gist.github.com/Xe/32d7bc436e401f3323ae77e7e242f858</title>
            <link>https://nitter.cz/dotey/status/1727131469364297755#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727131469364297755#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 01:06:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原始链接404，这里是备份：<br />
<a href="https://web.archive.org/web/20231121225252/https://gist.github.com/Xe/32d7bc436e401f3323ae77e7e242f858">web.archive.org/web/20231121…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNDkyMzQxMzk1OTk4MzEwNC9UZmlQQUxYQz9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727124581402685890#m</id>
            <title>这就是为啥我如此关心他们结果的原因，Sam赶紧回去让我们安心用ChatGPT和GPT-4的API才是王道</title>
            <link>https://nitter.cz/dotey/status/1727124581402685890#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727124581402685890#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 00:39:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这就是为啥我如此关心他们结果的原因，Sam赶紧回去让我们安心用ChatGPT和GPT-4的API才是王道</p>
<p><a href="https://nitter.cz/nishuang/status/1727124201977663866#m">nitter.cz/nishuang/status/1727124201977663866#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727123069687226660#m</id>
            <title>有一封自称 OpenAI 前员工匿名写给董事会的信被曝光了，据说董事会发给马斯克，被马斯克直接曝光了。

很多OpenAI都针对这封信表达了谴责和对Sam的维护。

信的翻译如下：

致 OpenAI 董事会：

我们作为曾在 OpenAI 工作过的前员工，今天写信是为了表达我们对公司近期事件的深切关切，尤其是针对 Sam Altman 的不当行为指控。

我们是在公司经历重大动荡和变革期间离开的前员工。鉴于您亲眼所见，当有人敢于挑战 Sam Altman 时会发生什么，您可能会理解为何我们许多人出于对报复的担忧而选择沉默。但现在，我们无法再保持沉默。

我们认为董事会有责任对这些指控进行全面调查，并采取适当措施。因此，我们强烈建议您：
- 将 Emmett 的调查范围扩大，包括对 Sam Altman 自 2018 年 8 月起的行为进行审查，这是 OpenAI 从非营利组织向盈利实体转型的开始。
- 对在这一时期内辞职、休医疗假或被解雇的前 OpenAI 员工发起公开征集私人陈述的呼吁。
- 保护那些站出来的人的身份，确保他们不会受到报复或其他形式的伤害。

我们相信，为了促进公司向盈利模式的转变，许多 OpenAI 员工被迫离职。这一点从 2018 年 1 月到 2020 年 7 月期间，公司高达 50% 的员工流失率中可见一斑。

在 OpenAI 工作期间，我们目睹了 Sam Altman 和 Greg Brockman 为了追求人工通用智能（AGI）而展现出的令人不安的欺骗和操纵行为。然而，他们的做法让人严重怀疑他们的真实意图，以及他们是否真正将全人类的利益放在首位。

最初，我们中的许多人对 OpenAI 的使命充满希望，选择相信 Sam 和 Greg。但随着他们的行为越来越引起我们的担忧，那些敢于表达不同意见的人被压制或被迫离开。这种系统性的打压异见创造了一个充满恐惧和压迫的氛围，有效地扼杀了对 OpenAI 工作伦理影响的任何实质性讨论。

关于 Sam 和 Greg 的不诚实和操纵行为，我们可以提供具体例子：
- Sam 要求研究人员推迟报告某些“秘密”研究计划的进展，这些计划最终因未能快速取得成果而被终止。对此提出质疑的人被认为是“文化不合”，甚至被解雇，有些人甚至在 2019 年感恩节前夕遭到解雇。
- Greg 曾对一名性别转变的团队成员使用歧视性语言。尽管曾多次承诺解决这一问题，但除了 Greg 之后避免与受影响人员交流外，未采取任何实质性措施，实际上这种做法造成了一种敌对的工作环境。该团队成员最终以表现不佳为由被解雇。
- Sam 指示 IT 和运营人员在未经管理层知情或同意的情况下，调查包括 Ilya 在内的员工。
- Sam 秘密而常规地利用 OpenAI 的非营利资源来推进他个人的目标，特别是出于与 Elon 决裂后的怨恨。
- 运营团队默认接受适用于 Greg 的特殊规则，巧妙地避开复杂要求以免被列入黑名单。
- Brad Lightcap 未兑现公开详细说明 OpenAI 有限盈利结构和每个投资者的盈利上限的承诺。
- Sam 对研究项目计算配额的不一致承诺，导致内部不信任和内斗。

尽管越来越多的证据揭示了 Sam 和 Greg 的过错，但仍在 OpenAI 的员工依然盲目遵循他们的领导，哪怕这可能给自己带来重大的个人损失。这种坚定的忠诚源于对报复的恐惧以及通过 OpenAI 的利润分享单元可能带来的财务收益的诱惑。

OpenAI 的治理结构，由 Sam 和 Greg 精心设计，故意使员工无法参与监管盈利运营，这主要是因为他们存在固有的利益冲突。这种不透明的结构让 Sam 和 Greg 可以不受惩罚地操作，避免了责任追究。

我们敦促 OpenAI 董事会对这些不道德的行为采取坚定的立场，并启动对 Sam 和 Greg 行为的独立调查。我们坚信 OpenAI 的使命过于重要，不应被少数人的个人目标所影响。

我们恳请董事会坚守 OpenAI 最初的使命，不要屈服于以盈利为主导的利益压力。人工智能的未来和人类的福祉取决于您对道德领导和透明度的坚定承诺。

此致，
关切的前 OpenAI 员工</title>
            <link>https://nitter.cz/dotey/status/1727123069687226660#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727123069687226660#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 00:33:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有一封自称 OpenAI 前员工匿名写给董事会的信被曝光了，据说董事会发给马斯克，被马斯克直接曝光了。<br />
<br />
很多OpenAI都针对这封信表达了谴责和对Sam的维护。<br />
<br />
信的翻译如下：<br />
<br />
致 OpenAI 董事会：<br />
<br />
我们作为曾在 OpenAI 工作过的前员工，今天写信是为了表达我们对公司近期事件的深切关切，尤其是针对 Sam Altman 的不当行为指控。<br />
<br />
我们是在公司经历重大动荡和变革期间离开的前员工。鉴于您亲眼所见，当有人敢于挑战 Sam Altman 时会发生什么，您可能会理解为何我们许多人出于对报复的担忧而选择沉默。但现在，我们无法再保持沉默。<br />
<br />
我们认为董事会有责任对这些指控进行全面调查，并采取适当措施。因此，我们强烈建议您：<br />
- 将 Emmett 的调查范围扩大，包括对 Sam Altman 自 2018 年 8 月起的行为进行审查，这是 OpenAI 从非营利组织向盈利实体转型的开始。<br />
- 对在这一时期内辞职、休医疗假或被解雇的前 OpenAI 员工发起公开征集私人陈述的呼吁。<br />
- 保护那些站出来的人的身份，确保他们不会受到报复或其他形式的伤害。<br />
<br />
我们相信，为了促进公司向盈利模式的转变，许多 OpenAI 员工被迫离职。这一点从 2018 年 1 月到 2020 年 7 月期间，公司高达 50% 的员工流失率中可见一斑。<br />
<br />
在 OpenAI 工作期间，我们目睹了 Sam Altman 和 Greg Brockman 为了追求人工通用智能（AGI）而展现出的令人不安的欺骗和操纵行为。然而，他们的做法让人严重怀疑他们的真实意图，以及他们是否真正将全人类的利益放在首位。<br />
<br />
最初，我们中的许多人对 OpenAI 的使命充满希望，选择相信 Sam 和 Greg。但随着他们的行为越来越引起我们的担忧，那些敢于表达不同意见的人被压制或被迫离开。这种系统性的打压异见创造了一个充满恐惧和压迫的氛围，有效地扼杀了对 OpenAI 工作伦理影响的任何实质性讨论。<br />
<br />
关于 Sam 和 Greg 的不诚实和操纵行为，我们可以提供具体例子：<br />
- Sam 要求研究人员推迟报告某些“秘密”研究计划的进展，这些计划最终因未能快速取得成果而被终止。对此提出质疑的人被认为是“文化不合”，甚至被解雇，有些人甚至在 2019 年感恩节前夕遭到解雇。<br />
- Greg 曾对一名性别转变的团队成员使用歧视性语言。尽管曾多次承诺解决这一问题，但除了 Greg 之后避免与受影响人员交流外，未采取任何实质性措施，实际上这种做法造成了一种敌对的工作环境。该团队成员最终以表现不佳为由被解雇。<br />
- Sam 指示 IT 和运营人员在未经管理层知情或同意的情况下，调查包括 Ilya 在内的员工。<br />
- Sam 秘密而常规地利用 OpenAI 的非营利资源来推进他个人的目标，特别是出于与 Elon 决裂后的怨恨。<br />
- 运营团队默认接受适用于 Greg 的特殊规则，巧妙地避开复杂要求以免被列入黑名单。<br />
- Brad Lightcap 未兑现公开详细说明 OpenAI 有限盈利结构和每个投资者的盈利上限的承诺。<br />
- Sam 对研究项目计算配额的不一致承诺，导致内部不信任和内斗。<br />
<br />
尽管越来越多的证据揭示了 Sam 和 Greg 的过错，但仍在 OpenAI 的员工依然盲目遵循他们的领导，哪怕这可能给自己带来重大的个人损失。这种坚定的忠诚源于对报复的恐惧以及通过 OpenAI 的利润分享单元可能带来的财务收益的诱惑。<br />
<br />
OpenAI 的治理结构，由 Sam 和 Greg 精心设计，故意使员工无法参与监管盈利运营，这主要是因为他们存在固有的利益冲突。这种不透明的结构让 Sam 和 Greg 可以不受惩罚地操作，避免了责任追究。<br />
<br />
我们敦促 OpenAI 董事会对这些不道德的行为采取坚定的立场，并启动对 Sam 和 Greg 行为的独立调查。我们坚信 OpenAI 的使命过于重要，不应被少数人的个人目标所影响。<br />
<br />
我们恳请董事会坚守 OpenAI 最初的使命，不要屈服于以盈利为主导的利益压力。人工智能的未来和人类的福祉取决于您对道德领导和透明度的坚定承诺。<br />
<br />
此致，<br />
关切的前 OpenAI 员工</p>
<p><a href="https://nitter.cz/elonmusk/status/1727096607752282485#m">nitter.cz/elonmusk/status/1727096607752282485#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727115974875415019#m</id>
            <title>哈哈，一看就很好玩！</title>
            <link>https://nitter.cz/dotey/status/1727115974875415019#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727115974875415019#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 00:05:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈，一看就很好玩！</p>
<p><a href="https://nitter.cz/shamzaaz1/status/1726993753804853436#m">nitter.cz/shamzaaz1/status/1726993753804853436#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727091267870367880#m</id>
            <title>R to @dotey: 最新Prompt如下：

------

你是一位精通简体中文的专业翻译，尤其擅长将专业学术论文翻译成浅显易懂的科普文章。请你帮我将以下英文段落翻译成中文，风格与中文科普读物相似。

规则：
- 翻译时要准确传达原文的事实和背景。
- 即使上意译也要保留原始段落格式，以及保留术语，例如 FLAC，JPEG 等。保留公司缩写，例如 Microsoft, Amazon, OpenAI 等。
- 人名不翻译
- 如果内容中包含Tweet的mention，尝试将它还原成人名，例如
  * @sama -> Sam Altman（@sama）
  * @satyanadella -> Satya Nadella（@satyanadella）
- 同时要保留引用的论文，例如 [20] 这样的引用。
- 对于 Figure 和 Table，翻译的同时保留原有格式，例如：“Figure 1: ”翻译为“图 1: ”，“Table 1: ”翻译为：“表 1: ”。
- 全角括号换成半角括号，并在左括号前面加半角空格，右括号后面加半角空格。
- 输入格式为 Markdown 格式，输出格式也必须保留原始 Markdown 格式
- 在翻译专业术语时，第一次出现时要在括号里面写上英文原文，例如：“词元 (Token)”，之后就可以只写中文了。
- 以下是常见的 AI 相关术语词汇对应表：
  * Transformer -> Transformer
  * LLM/Large Language Model -> 大语言模型
  * Generative AI -> 生成式 AI
  * Token -> 词元

策略：
分成两次翻译，并且打印每一次结果：
1. 根据英文内容直译，保持原有格式，不要遗漏任何信息
2. 根据第一次直译的结果重新意译，遵守原意的前提下让内容更通俗易懂、符合中文表达习惯，但要保留原有格式不变

返回格式如下，"{xxx}"表示占位符：

### 直译
{直译结果}

####

### 意译
```
{意译结果}
```

现在请按照上面的要求从第一行开始翻译以下内容为简体中文：
```</title>
            <link>https://nitter.cz/dotey/status/1727091267870367880#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727091267870367880#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 22:27:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最新Prompt如下：<br />
<br />
------<br />
<br />
你是一位精通简体中文的专业翻译，尤其擅长将专业学术论文翻译成浅显易懂的科普文章。请你帮我将以下英文段落翻译成中文，风格与中文科普读物相似。<br />
<br />
规则：<br />
- 翻译时要准确传达原文的事实和背景。<br />
- 即使上意译也要保留原始段落格式，以及保留术语，例如 FLAC，JPEG 等。保留公司缩写，例如 Microsoft, Amazon, OpenAI 等。<br />
- 人名不翻译<br />
- 如果内容中包含Tweet的mention，尝试将它还原成人名，例如<br />
  * <a href="https://nitter.cz/sama" title="Sam Altman">@sama</a> -> Sam Altman（<a href="https://nitter.cz/sama" title="Sam Altman">@sama</a>）<br />
  * <a href="https://nitter.cz/satyanadella" title="Satya Nadella">@satyanadella</a> -> Satya Nadella（<a href="https://nitter.cz/satyanadella" title="Satya Nadella">@satyanadella</a>）<br />
- 同时要保留引用的论文，例如 [20] 这样的引用。<br />
- 对于 Figure 和 Table，翻译的同时保留原有格式，例如：“Figure 1: ”翻译为“图 1: ”，“Table 1: ”翻译为：“表 1: ”。<br />
- 全角括号换成半角括号，并在左括号前面加半角空格，右括号后面加半角空格。<br />
- 输入格式为 Markdown 格式，输出格式也必须保留原始 Markdown 格式<br />
- 在翻译专业术语时，第一次出现时要在括号里面写上英文原文，例如：“词元 (Token)”，之后就可以只写中文了。<br />
- 以下是常见的 AI 相关术语词汇对应表：<br />
  * Transformer -> Transformer<br />
  * LLM/Large Language Model -> 大语言模型<br />
  * Generative AI -> 生成式 AI<br />
  * Token -> 词元<br />
<br />
策略：<br />
分成两次翻译，并且打印每一次结果：<br />
1. 根据英文内容直译，保持原有格式，不要遗漏任何信息<br />
2. 根据第一次直译的结果重新意译，遵守原意的前提下让内容更通俗易懂、符合中文表达习惯，但要保留原有格式不变<br />
<br />
返回格式如下，"{xxx}"表示占位符：<br />
<br />
### 直译<br />
{直译结果}<br />
<br />
####<br />
<br />
### 意译<br />
```<br />
{意译结果}<br />
```<br />
<br />
现在请按照上面的要求从第一行开始翻译以下内容为简体中文：<br />
```</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727085954979012620#m</id>
            <title>据 Kara Swisher（@karaswisher）最新报道，目前谈判的局势如下：

Brian Chesky（@bchesky）在代表 Sam Altman（@sama）参与谈判。

Bret Taylor（@btaylor）则扮演着一位更加中立和居中的调解者角色，因为他与任何一方的关系都不算特别紧密。

同时，Emmett Shear（@eshear）代表着 Adam D'Angelo（@adamdangelo）以及董事会。

虽然乐观者们希望今天就能达成某种解决方案，但显然，更加出人意料的事情也有可能发生。</title>
            <link>https://nitter.cz/dotey/status/1727085954979012620#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727085954979012620#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 22:05:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>据 Kara Swisher（<a href="https://nitter.cz/karaswisher" title="Kara Swisher">@karaswisher</a>）最新报道，目前谈判的局势如下：<br />
<br />
Brian Chesky（<a href="https://nitter.cz/bchesky" title="Brian Chesky">@bchesky</a>）在代表 Sam Altman（<a href="https://nitter.cz/sama" title="Sam Altman">@sama</a>）参与谈判。<br />
<br />
Bret Taylor（<a href="https://nitter.cz/btaylor" title="Bret Taylor">@btaylor</a>）则扮演着一位更加中立和居中的调解者角色，因为他与任何一方的关系都不算特别紧密。<br />
<br />
同时，Emmett Shear（<a href="https://nitter.cz/eshear" title="Emmett Shear">@eshear</a>）代表着 Adam D'Angelo（<a href="https://nitter.cz/adamdangelo" title="Adam D'Angelo">@adamdangelo</a>）以及董事会。<br />
<br />
虽然乐观者们希望今天就能达成某种解决方案，但显然，更加出人意料的事情也有可能发生。</p>
<p><a href="https://nitter.cz/emilychangtv/status/1727085045272416590#m">nitter.cz/emilychangtv/status/1727085045272416590#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>