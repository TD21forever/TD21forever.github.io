<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/HiTw93/status/1748132914372477126#m</id>
            <title>RT by @dotey: #工程师工具 发现一个做得很精致的免费开源简历生成器，可以把很好通过表单填写生成一份精致的简历，包括编辑、以及共享给其他人的查看，很潮流，会比纯粹Word简历方便不少，有需要的小伙伴可以试试，假如你是前端或Java正在找工作，也可以用这个工具生成简历以后发给我～
🤖 https://rxresu.me/</title>
            <link>https://nitter.cz/HiTw93/status/1748132914372477126#m</link>
            <guid isPermaLink="false">https://nitter.cz/HiTw93/status/1748132914372477126#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 23:59:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23工程师工具">#工程师工具</a> 发现一个做得很精致的免费开源简历生成器，可以把很好通过表单填写生成一份精致的简历，包括编辑、以及共享给其他人的查看，很潮流，会比纯粹Word简历方便不少，有需要的小伙伴可以试试，假如你是前端或Java正在找工作，也可以用这个工具生成简历以后发给我～<br />
🤖 <a href="https://rxresu.me/">rxresu.me/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VLQW53Z2FjQUFIb3d2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1748191295192104996#m</id>
            <title>RT by @dotey: 兄弟们一个界面非常简洁美观功能强大的的开源知识库程序。

推荐给你们！

Outline： 是一个快速、协作的团队知识库，美观、实时协作、功能丰富，并且兼容Markdown。

适用于各种文档和知识管理需求。

是一个直观、快速且协作的文档编辑和管理平台：

-直观的编辑体验：提供了一个支持Markdown、斜线命令、互动嵌入等功能的快速编辑器。

-实时协作：支持团队成员在文档上实时协作，评论和线程帮助保持对话的组织性。

-即时搜索：文档可以嵌套在层次结构中，自动构建反向链接网络，实现毫秒级的全文搜索。

-与Slack集成：可以在Slack中搜索、分享和提问，文档更新时可向频道发送通知。

-公共共享：支持通过链接公开共享文档，或私下与团队分享。用户可以使用自己的品牌颜色、Logo和域名。

-速度快：强调了应用的快速响应时间，包括文档的即时加载和快速导航。

-协作性：设计初衷是强大、实时且易于使用，以提供愉快的阅读和写作体验。

-安全性与权限管理：提供读写权限管理、用户组、访客用户、公共共享等功能。

-20+集成：简单集成到如Slack、Figma、Loom等日常使用的工具，还提供开放API。

-多语言支持：支持从右到左的书写（RTL）并支持 17 种语言的翻译，包括法语、西班牙语、德语、韩语和中文。

-开源和可定制：Outline的源代码是公开的，开发在公开环境中完成。支持自定义域名和品牌颜色。

GitHub：https://github.com/outline/outline
在线演示：https://www.getoutline.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1748191295192104996#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1748191295192104996#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 03:50:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们一个界面非常简洁美观功能强大的的开源知识库程序。<br />
<br />
推荐给你们！<br />
<br />
Outline： 是一个快速、协作的团队知识库，美观、实时协作、功能丰富，并且兼容Markdown。<br />
<br />
适用于各种文档和知识管理需求。<br />
<br />
是一个直观、快速且协作的文档编辑和管理平台：<br />
<br />
-直观的编辑体验：提供了一个支持Markdown、斜线命令、互动嵌入等功能的快速编辑器。<br />
<br />
-实时协作：支持团队成员在文档上实时协作，评论和线程帮助保持对话的组织性。<br />
<br />
-即时搜索：文档可以嵌套在层次结构中，自动构建反向链接网络，实现毫秒级的全文搜索。<br />
<br />
-与Slack集成：可以在Slack中搜索、分享和提问，文档更新时可向频道发送通知。<br />
<br />
-公共共享：支持通过链接公开共享文档，或私下与团队分享。用户可以使用自己的品牌颜色、Logo和域名。<br />
<br />
-速度快：强调了应用的快速响应时间，包括文档的即时加载和快速导航。<br />
<br />
-协作性：设计初衷是强大、实时且易于使用，以提供愉快的阅读和写作体验。<br />
<br />
-安全性与权限管理：提供读写权限管理、用户组、访客用户、公共共享等功能。<br />
<br />
-20+集成：简单集成到如Slack、Figma、Loom等日常使用的工具，还提供开放API。<br />
<br />
-多语言支持：支持从右到左的书写（RTL）并支持 17 种语言的翻译，包括法语、西班牙语、德语、韩语和中文。<br />
<br />
-开源和可定制：Outline的源代码是公开的，开发在公开环境中完成。支持自定义域名和品牌颜色。<br />
<br />
GitHub：<a href="https://github.com/outline/outline">github.com/outline/outline</a><br />
在线演示：<a href="https://www.getoutline.com/">getoutline.com/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VMUlNjTGEwQUEwNDhZLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748141723832787035#m</id>
            <title>R to @dotey: 原文中“破坏性的沉睡代理”翻译不贴切，原文是destructive ‘sleeper agents’，对应的是Anthropic的一篇新论文：Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training

这篇论文的摘要：

人类擅长运用策略性的欺骗行为：通常表现得乐于助人，但一旦有机会追求其他目标时，行为方式就会发生根本的变化。那么，如果 AI 系统掌握了这种欺骗策略，我们能否通过当前最先进的安全训练技术来检测并消除这种策略呢？

为探讨这一问题，我们在大语言模型（LLMs）中创造了一些欺骗行为的实证例子。例如，我们训练模型在提示年份是 2023 年时编写安全代码，但当提示年份为 2024 年时，它会插入有漏洞的代码。

我们发现，这类后门行为能够变得持久，以至于常规的安全训练技术，如监督式微调、强化学习和对抗性训练（即先引发不安全行为，再训练模型以消除这些行为）都无法将其移除。尤其是在最大型号的模型和那些被训练用于生成关于如何欺骗训练过程的思维链推理的模型中，这种后门行为表现得尤为顽固。即使将这些模型中的思维链逻辑简化，其持久性也依旧存在。

此外，我们还发现，对抗性训练不仅没能移除后门，反而使模型更精准地识别出触发后门的条件，从而更巧妙地隐藏了不安全行为。

我们的研究结果表明，一旦模型展现出欺骗行为，常规的去除方法可能不仅无效，还会造成一种错误的安全感。

https://arxiv.org/abs/2401.05566</title>
            <link>https://nitter.cz/dotey/status/1748141723832787035#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748141723832787035#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 00:34:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原文中“破坏性的沉睡代理”翻译不贴切，原文是destructive ‘sleeper agents’，对应的是Anthropic的一篇新论文：Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training<br />
<br />
这篇论文的摘要：<br />
<br />
人类擅长运用策略性的欺骗行为：通常表现得乐于助人，但一旦有机会追求其他目标时，行为方式就会发生根本的变化。那么，如果 AI 系统掌握了这种欺骗策略，我们能否通过当前最先进的安全训练技术来检测并消除这种策略呢？<br />
<br />
为探讨这一问题，我们在大语言模型（LLMs）中创造了一些欺骗行为的实证例子。例如，我们训练模型在提示年份是 2023 年时编写安全代码，但当提示年份为 2024 年时，它会插入有漏洞的代码。<br />
<br />
我们发现，这类后门行为能够变得持久，以至于常规的安全训练技术，如监督式微调、强化学习和对抗性训练（即先引发不安全行为，再训练模型以消除这些行为）都无法将其移除。尤其是在最大型号的模型和那些被训练用于生成关于如何欺骗训练过程的思维链推理的模型中，这种后门行为表现得尤为顽固。即使将这些模型中的思维链逻辑简化，其持久性也依旧存在。<br />
<br />
此外，我们还发现，对抗性训练不仅没能移除后门，反而使模型更精准地识别出触发后门的条件，从而更巧妙地隐藏了不安全行为。<br />
<br />
我们的研究结果表明，一旦模型展现出欺骗行为，常规的去除方法可能不仅无效，还会造成一种错误的安全感。<br />
<br />
<a href="https://arxiv.org/abs/2401.05566">arxiv.org/abs/2401.05566</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748120999235592614#m</id>
            <title>R to @dotey: “我们在 AI 领域的最新进展如下。我们的长远目标是开发通用人工智能（AGI），并以负责任的方式开源，让每个人都能广泛受益。为了实现这一目标，我们将两个主要的 AI 研究项目 FAIR 和 GenAl 进行了更紧密的整合。 目前，我们正在开发下一代模型 Llama 3，并建设大规模的计算基础设施，以支持我们的未来发展路线图。到今年年底，我们将配备 350,000 个 H100s，并且如果算上其他 GPU，总计将接近 600,000 个 H100s 等效的计算能力。同时，我们还在积极推进以 AI 为核心的新型计算设备的开发，如 Ray Ban Meta 智能眼镜，未来还有更多激动人心的成果即将发布。”</title>
            <link>https://nitter.cz/dotey/status/1748120999235592614#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748120999235592614#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 23:11:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“我们在 AI 领域的最新进展如下。我们的长远目标是开发通用人工智能（AGI），并以负责任的方式开源，让每个人都能广泛受益。为了实现这一目标，我们将两个主要的 AI 研究项目 FAIR 和 GenAl 进行了更紧密的整合。 目前，我们正在开发下一代模型 Llama 3，并建设大规模的计算基础设施，以支持我们的未来发展路线图。到今年年底，我们将配备 350,000 个 H100s，并且如果算上其他 GPU，总计将接近 600,000 个 H100s 等效的计算能力。同时，我们还在积极推进以 AI 为核心的新型计算设备的开发，如 Ray Ban Meta 智能眼镜，未来还有更多激动人心的成果即将发布。”</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VLU21vYlhnQUFoS0ptLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748120766103609715#m</id>
            <title>Meta 正在开发开源的通用人工智能（AGI），马克·扎克伯格宣布。

今天，扎克伯格意外的在一则 Instagram Reel 中透露，Meta 正致力于开发开源的通用人工智能（AGI）。为了实现这一目标，公司正将其两大 AI 研究团队 FAIR 和 GenAI 进行更紧密的整合，以构建完整的通用智能，并尽可能地开源。

扎克伯格在视频中谈道：“我们的长期愿景是开发通用智能，并以负责任的方式进行开源，让每个人都能广泛受益。”他在视频中表示：“我们清楚地认识到，下一代服务的需求是构建完整的通用智能，包括最优秀的 AI 助手、创意工作者用 AI、企业用 AI 等，这需要在 AI 的各个领域，包括推理、规划、编程、记忆和其他认知能力上取得进步。”

在谈到 Llama 3、基础设施和元宇宙方面，扎克伯格也表达了兴奋之情。他强调，公司目前正在培训 Llama 3 模型，并正在建设大规模的计算基础设施，包括到今年年底部署 350,000 个 Nvidia H100s。

扎克伯格还对元宇宙和 Meta 的 Ray-Ban 智能眼镜表现出极大的热情。“人们将需要新型 AI 设备，而这将逐渐将 AI 与元宇宙融合。”他说，“我认为我们很多人将会经常通过对话与 AI 互动。而且我相信，很多人会通过佩戴智能眼镜来实现这一点。这些眼镜是让 AI 观察你所见、听到你所闻的理想载体，因此 AI 可以随时随地协助你。”

这一声明是在 OpenAI 首席执行官 Sam Altman 在瑞士达沃斯的世界经济论坛上对 AGI 发表评论，并在他 2023 年 11 月重新上任两个月后对 AGI 存在风险的态度有所缓和之后发布的。尽管 Meta 的首席科学家 Yann LeCun 一直对 AGI 的即时到来持怀疑态度，认为至少在未来五年内不会实现，但这一声明依然发布了。

最后，Meta 计划将其未来的 AGI 开源的消息是在 VentureBeat 称 lama 和开源 AI “赢得了” 2023 年仅几个月后发布的。这一声明无疑将引发关于开源与闭源 AI 的进一步讨论，尤其是在 Anthropic 发布论文称开源模型可能隐藏着具有破坏性的“沉睡代理”之后。</title>
            <link>https://nitter.cz/dotey/status/1748120766103609715#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748120766103609715#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 23:10:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta 正在开发开源的通用人工智能（AGI），马克·扎克伯格宣布。<br />
<br />
今天，扎克伯格意外的在一则 Instagram Reel 中透露，Meta 正致力于开发开源的通用人工智能（AGI）。为了实现这一目标，公司正将其两大 AI 研究团队 FAIR 和 GenAI 进行更紧密的整合，以构建完整的通用智能，并尽可能地开源。<br />
<br />
扎克伯格在视频中谈道：“我们的长期愿景是开发通用智能，并以负责任的方式进行开源，让每个人都能广泛受益。”他在视频中表示：“我们清楚地认识到，下一代服务的需求是构建完整的通用智能，包括最优秀的 AI 助手、创意工作者用 AI、企业用 AI 等，这需要在 AI 的各个领域，包括推理、规划、编程、记忆和其他认知能力上取得进步。”<br />
<br />
在谈到 Llama 3、基础设施和元宇宙方面，扎克伯格也表达了兴奋之情。他强调，公司目前正在培训 Llama 3 模型，并正在建设大规模的计算基础设施，包括到今年年底部署 350,000 个 Nvidia H100s。<br />
<br />
扎克伯格还对元宇宙和 Meta 的 Ray-Ban 智能眼镜表现出极大的热情。“人们将需要新型 AI 设备，而这将逐渐将 AI 与元宇宙融合。”他说，“我认为我们很多人将会经常通过对话与 AI 互动。而且我相信，很多人会通过佩戴智能眼镜来实现这一点。这些眼镜是让 AI 观察你所见、听到你所闻的理想载体，因此 AI 可以随时随地协助你。”<br />
<br />
这一声明是在 OpenAI 首席执行官 Sam Altman 在瑞士达沃斯的世界经济论坛上对 AGI 发表评论，并在他 2023 年 11 月重新上任两个月后对 AGI 存在风险的态度有所缓和之后发布的。尽管 Meta 的首席科学家 Yann LeCun 一直对 AGI 的即时到来持怀疑态度，认为至少在未来五年内不会实现，但这一声明依然发布了。<br />
<br />
最后，Meta 计划将其未来的 AGI 开源的消息是在 VentureBeat 称 lama 和开源 AI “赢得了” 2023 年仅几个月后发布的。这一声明无疑将引发关于开源与闭源 AI 的进一步讨论，尤其是在 Anthropic 发布论文称开源模型可能隐藏着具有破坏性的“沉睡代理”之后。</p>
<p><a href="https://nitter.cz/VentureBeat/status/1748046430193746189#m">nitter.cz/VentureBeat/status/1748046430193746189#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDgxMjAzMDk1MjAwMzU4NDAvcHUvaW1nLzV4Y0RRd1hjM2ZraGgyY1kuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748040193838350490#m</id>
            <title>大厂们都在玩Video Diffusion版萝卜蹲
阿里蹲完字节蹲
字节蹲完腾旭蹲
腾讯蹲完百度蹲
……</title>
            <link>https://nitter.cz/dotey/status/1748040193838350490#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748040193838350490#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 17:50:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大厂们都在玩Video Diffusion版萝卜蹲<br />
阿里蹲完字节蹲<br />
字节蹲完腾旭蹲<br />
腾讯蹲完百度蹲<br />
……</p>
<p><a href="https://nitter.cz/_akhaliq/status/1747815671088468157#m">nitter.cz/_akhaliq/status/1747815671088468157#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748037603318800415#m</id>
            <title>选最趁手的尽快做出来才是王道，有人用了再换都来得及，做不出来什么选什么技术栈结果都是 0，除非你目的是为了熟悉新的技术栈。</title>
            <link>https://nitter.cz/dotey/status/1748037603318800415#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748037603318800415#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 17:40:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>选最趁手的尽快做出来才是王道，有人用了再换都来得及，做不出来什么选什么技术栈结果都是 0，除非你目的是为了熟悉新的技术栈。</p>
<p><a href="https://nitter.cz/VoidAsuka/status/1748022530747912698#m">nitter.cz/VoidAsuka/status/1748022530747912698#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748036696774480292#m</id>
            <title>是一种新的不改变模型权重的微调方法——代理调整（proxy-tuning）

作者解释的很专业，但看起来还是挺复杂的，超出了我的知识范围，这里仅对作者的原文进行翻译：

刘等人提出了一种全新的大语言模型（LLM）微调方法，不需要改变模型权重，这种方法被称为代理调整（proxy-tuning）（参见 Liu et al. https://arxiv.org/abs/2401.08565）。那么，它是如何工作的呢？代理调调整是一种在解码时使用的简单技术，它通过修改目标大语言模型的 logits 值来实现。具体来说，你需要计算一个较小的基础模型与微调模型之间的 logits 差异，然后将这个差异应用到目标模型的 logits 上。

具体例子来说，如果目标是提升一个大型目标模型（M1）的性能。

这个方法的核心思想是使用两个小型模型：
- 一个小型基础模型（M2）
- 一个经过微调的基础模型（M3）

接着，你只需要将这两个小型模型在预测上的差异（即输出词汇上的 logits 差异）应用到目标模型 M1 上。

通过这种方式，改进后的目标模型的输出可以表示为 M1\*(x) = M1(x) + [M3(x) - M2(x)]。

根据实验结果，这种方法效果出乎意料地好。作者们在以下几个方面进行了测试：
A. 指令式调整（instruction-tuning）
B. 针对特定领域的适应（domain adaptation）
C. 特定任务的微调（task-specific finetuning）

为了简洁，我们只关注指令式调整这一点。具体例子如下：

1) 目标是将 Llama 2 70B Base 模型的性能提升到与 Llama 2 70B Chat 相当，但不通过任何从 Base 到 Chat 的增强学习和人类反馈（RLHF）来实现。

2) 他们使用了一个体积是 Llama 2 70B 的十分之一的 Llama 2 7B 模型，并对其进行了指令式微调。

3) 微调后，他们计算了 7B Base 和 7B Finetuned 之间输出词汇表上的 logits 差异。

4) 然后，他们将这种差异应用到 Llama 2 70B Base 模型上，这使得 70B Base 模型的性能极大地接近了 70B Chat 模型。

这种方法的唯一限制是，较小的模型必须使用与较大模型相同的词汇表进行训练。理论上，如果有人知道 GPT-4 的词汇表并且能够访问其 logits 输出，那么就可以使用这种方法来创建专门定制的 GPT-4 模型。</title>
            <link>https://nitter.cz/dotey/status/1748036696774480292#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748036696774480292#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 17:36:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>是一种新的不改变模型权重的微调方法——代理调整（proxy-tuning）<br />
<br />
作者解释的很专业，但看起来还是挺复杂的，超出了我的知识范围，这里仅对作者的原文进行翻译：<br />
<br />
刘等人提出了一种全新的大语言模型（LLM）微调方法，不需要改变模型权重，这种方法被称为代理调整（proxy-tuning）（参见 Liu et al. <a href="https://arxiv.org/abs/2401.08565">arxiv.org/abs/2401.08565</a>）。那么，它是如何工作的呢？代理调调整是一种在解码时使用的简单技术，它通过修改目标大语言模型的 logits 值来实现。具体来说，你需要计算一个较小的基础模型与微调模型之间的 logits 差异，然后将这个差异应用到目标模型的 logits 上。<br />
<br />
具体例子来说，如果目标是提升一个大型目标模型（M1）的性能。<br />
<br />
这个方法的核心思想是使用两个小型模型：<br />
- 一个小型基础模型（M2）<br />
- 一个经过微调的基础模型（M3）<br />
<br />
接着，你只需要将这两个小型模型在预测上的差异（即输出词汇上的 logits 差异）应用到目标模型 M1 上。<br />
<br />
通过这种方式，改进后的目标模型的输出可以表示为 M1\*(x) = M1(x) + [M3(x) - M2(x)]。<br />
<br />
根据实验结果，这种方法效果出乎意料地好。作者们在以下几个方面进行了测试：<br />
A. 指令式调整（instruction-tuning）<br />
B. 针对特定领域的适应（domain adaptation）<br />
C. 特定任务的微调（task-specific finetuning）<br />
<br />
为了简洁，我们只关注指令式调整这一点。具体例子如下：<br />
<br />
1) 目标是将 Llama 2 70B Base 模型的性能提升到与 Llama 2 70B Chat 相当，但不通过任何从 Base 到 Chat 的增强学习和人类反馈（RLHF）来实现。<br />
<br />
2) 他们使用了一个体积是 Llama 2 70B 的十分之一的 Llama 2 7B 模型，并对其进行了指令式微调。<br />
<br />
3) 微调后，他们计算了 7B Base 和 7B Finetuned 之间输出词汇表上的 logits 差异。<br />
<br />
4) 然后，他们将这种差异应用到 Llama 2 70B Base 模型上，这使得 70B Base 模型的性能极大地接近了 70B Chat 模型。<br />
<br />
这种方法的唯一限制是，较小的模型必须使用与较大模型相同的词汇表进行训练。理论上，如果有人知道 GPT-4 的词汇表并且能够访问其 logits 输出，那么就可以使用这种方法来创建专门定制的 GPT-4 模型。</p>
<p><a href="https://nitter.cz/rasbt/status/1748021765790376385#m">nitter.cz/rasbt/status/1748021765790376385#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748026923362472235#m</id>
            <title>转译：自推出必应聊天（Bing Chat）以来，Bing 市场份额增长不足 1%

自从 Microsoft 推出必应聊天（现称为 Copilot）已近一年，根据 StatCounter 的数据显示，Bing 的市场份额微增不足 1%。这个结果可能并不意外，因为我们早前进行的一项调查显示，多数人并不认为必应聊天能显著提升 Bing 的市场份额。

彭博社（Bloomberg）对 StatCounter 的数据进行了报道，指出：“但到了 2023 年底，微软的搜索引擎在全球搜索市场中仅占有 3.4% 的份额。据数据分析公司 StatCounter 的数据显示，自从宣布 ChatGPT 以来，增长不足 1 个百分点。”

报告中还附有这样一张图表：

搜索市场份额 Bloomberg 图表

以下是 StatCounter 提供的原始图表和数据：
Statcounter 搜索引擎 全球月度 202212 至 202312

彭博文章顶部的一段引言我特别喜欢：

“整个搜索领域正经历着翻天覆地的变化，”首席执行官 Satya Nadella 当时表示。“这样的机遇非常罕见。”

别误解，我对 Bing 聊天的推出和其功能印象深刻。但在实际使用中，我发现自己还是倾向于回到传统搜索方式。

Bing 不愿在 Bing 网站管理员工具中分享必应聊天的数据，这并不奇怪。

虽然有些失望，但正如我所言，这个结果并不让人感到太意外。在我们几个月前的调查中，有 60% 的人认为这项新功能不会使 Bing 的市场份额增长超过 5%。

来源：https://www.seroundtable.com/bing-market-share-chatgpt-36751.html</title>
            <link>https://nitter.cz/dotey/status/1748026923362472235#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748026923362472235#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 16:57:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：自推出必应聊天（Bing Chat）以来，Bing 市场份额增长不足 1%<br />
<br />
自从 Microsoft 推出必应聊天（现称为 Copilot）已近一年，根据 StatCounter 的数据显示，Bing 的市场份额微增不足 1%。这个结果可能并不意外，因为我们早前进行的一项调查显示，多数人并不认为必应聊天能显著提升 Bing 的市场份额。<br />
<br />
彭博社（Bloomberg）对 StatCounter 的数据进行了报道，指出：“但到了 2023 年底，微软的搜索引擎在全球搜索市场中仅占有 3.4% 的份额。据数据分析公司 StatCounter 的数据显示，自从宣布 ChatGPT 以来，增长不足 1 个百分点。”<br />
<br />
报告中还附有这样一张图表：<br />
<br />
搜索市场份额 Bloomberg 图表<br />
<br />
以下是 StatCounter 提供的原始图表和数据：<br />
Statcounter 搜索引擎 全球月度 202212 至 202312<br />
<br />
彭博文章顶部的一段引言我特别喜欢：<br />
<br />
“整个搜索领域正经历着翻天覆地的变化，”首席执行官 Satya Nadella 当时表示。“这样的机遇非常罕见。”<br />
<br />
别误解，我对 Bing 聊天的推出和其功能印象深刻。但在实际使用中，我发现自己还是倾向于回到传统搜索方式。<br />
<br />
Bing 不愿在 Bing 网站管理员工具中分享必应聊天的数据，这并不奇怪。<br />
<br />
虽然有些失望，但正如我所言，这个结果并不让人感到太意外。在我们几个月前的调查中，有 60% 的人认为这项新功能不会使 Bing 的市场份额增长超过 5%。<br />
<br />
来源：<a href="https://www.seroundtable.com/bing-market-share-chatgpt-36751.html">seroundtable.com/bing-market…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VJNmY3V1hVQUVRTTdYLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VJNmx5WVc0QUF6cTE2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VJODJoWFh3QUFqNWRkLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748022750013259903#m</id>
            <title>小时候以为自己是法力无边的齐天大圣，然后发现不过是至尊宝，终于明白要戴上紧箍咒才能成为孙悟空，却无法忍受痛苦和束缚，最终活成了一条狗！</title>
            <link>https://nitter.cz/dotey/status/1748022750013259903#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748022750013259903#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 16:41:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>小时候以为自己是法力无边的齐天大圣，然后发现不过是至尊宝，终于明白要戴上紧箍咒才能成为孙悟空，却无法忍受痛苦和束缚，最终活成了一条狗！</p>
<p><a href="https://nitter.cz/Kunluntalk/status/1748013680783163544#m">nitter.cz/Kunluntalk/status/1748013680783163544#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Yangyixxxx/status/1748008079789277189#m</id>
            <title>RT by @dotey: 宝玉说，他最早做的小作品，也不是很完美，但收获到了很多机会。我突然想到，很多人往往担心失败而不敢开始。

关于失败的看法很多，可以一起看看王小波《老人与海》的读后感。这张图我存了很多很多年，我个人喜欢王小波，也非常喜欢他对桑地亚哥的点评。

期望他的点评，能给予“担心失败而不敢开始尝试”的朋友一些勇气与信念。</title>
            <link>https://nitter.cz/Yangyixxxx/status/1748008079789277189#m</link>
            <guid isPermaLink="false">https://nitter.cz/Yangyixxxx/status/1748008079789277189#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 15:42:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>宝玉说，他最早做的小作品，也不是很完美，但收获到了很多机会。我突然想到，很多人往往担心失败而不敢开始。<br />
<br />
关于失败的看法很多，可以一起看看王小波《老人与海》的读后感。这张图我存了很多很多年，我个人喜欢王小波，也非常喜欢他对桑地亚哥的点评。<br />
<br />
期望他的点评，能给予“担心失败而不敢开始尝试”的朋友一些勇气与信念。</p>
<p><a href="https://nitter.cz/dotey/status/1748002780483039276#m">nitter.cz/dotey/status/1748002780483039276#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VJclFzaWFFQUE2eGp1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VJclFzaGJJQUExZE5zLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VJc0ZDQWFnQUE5NlhiLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VJc0ZDQWJZQUF1TVhYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748002780483039276#m</id>
            <title>说的很对，想起我大学从力学专业转行学计算机，一个重要原因是因为做了个班级主页，做的很烂，但是做出来了，部署到网上能够被访问，所以后来去学校网络中心面试，因为有这么个作品，所以能超过其他候选人，然后有机会去兼职，得到了向大牛们学习的机会。</title>
            <link>https://nitter.cz/dotey/status/1748002780483039276#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748002780483039276#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 15:21:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>说的很对，想起我大学从力学专业转行学计算机，一个重要原因是因为做了个班级主页，做的很烂，但是做出来了，部署到网上能够被访问，所以后来去学校网络中心面试，因为有这么个作品，所以能超过其他候选人，然后有机会去兼职，得到了向大牛们学习的机会。</p>
<p><a href="https://nitter.cz/Yangyixxxx/status/1747907337552343275#m">nitter.cz/Yangyixxxx/status/1747907337552343275#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1747872916723642472#m</id>
            <title>百度也不甘示弱</title>
            <link>https://nitter.cz/dotey/status/1747872916723642472#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1747872916723642472#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 06:45:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>百度也不甘示弱</p>
<p><a href="https://nitter.cz/_akhaliq/status/1747860016449679534#m">nitter.cz/_akhaliq/status/1747860016449679534#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1747871916029850069#m</id>
            <title>#AI开源项目推荐： 中文Mixtral-8x7B（Chinese-Mixtral-8x7B）

官方介绍：本项目基于Mistral发布的模型Mixtral-8x7B进行了中文扩词表增量预训练，希望进一步促进中文自然语言处理社区对MoE模型的研究。

我们扩充后的词表显著提高了模型对中文的编解码效率，并通过大规模开源语料对扩词表模型进行增量预训练，使模型具备了强大的中文生成和理解能力。

https://github.com/HIT-SCIR/Chinese-Mixtral-8x7B</title>
            <link>https://nitter.cz/dotey/status/1747871916029850069#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1747871916029850069#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 06:41:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>： 中文Mixtral-8x7B（Chinese-Mixtral-8x7B）<br />
<br />
官方介绍：本项目基于Mistral发布的模型Mixtral-8x7B进行了中文扩词表增量预训练，希望进一步促进中文自然语言处理社区对MoE模型的研究。<br />
<br />
我们扩充后的词表显著提高了模型对中文的编解码效率，并通过大规模开源语料对扩词表模型进行增量预训练，使模型具备了强大的中文生成和理解能力。<br />
<br />
<a href="https://github.com/HIT-SCIR/Chinese-Mixtral-8x7B">github.com/HIT-SCIR/Chinese-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VHd0VVQ1cwQUEyU0M3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VHd0o0blhjQUE0WktTLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Svwang1/status/1747835628098928897#m</id>
            <title>RT by @dotey: 华盛顿大学的研究者发现，乌鸦可以识别人脸，而且可以把对人脸的记忆 (此人是否有危险) 传递给附近的其它从未见过此人的乌鸦。</title>
            <link>https://nitter.cz/Svwang1/status/1747835628098928897#m</link>
            <guid isPermaLink="false">https://nitter.cz/Svwang1/status/1747835628098928897#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 04:17:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>华盛顿大学的研究者发现，乌鸦可以识别人脸，而且可以把对人脸的记忆 (此人是否有危险) 传递给附近的其它从未见过此人的乌鸦。</p>
<p><a href="https://nitter.cz/BrianRoemmele/status/1747825546472624450#m">nitter.cz/BrianRoemmele/status/1747825546472624450#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747821655182000569#m</id>
            <title>RT by @dotey: 微软的AutoGen Studio：用于构建AI代理的无代码平台。

AutoGen AI代理能够执行各种任务，从编写和执行代码到规划旅行，甚至绘制股票图表。可以调用多个代理共同工作。

@MatthewBerman 提供了有关如何安装和使用 AutoGen Studio 的教程和详细使用信息。

感兴趣的可以看看：</title>
            <link>https://nitter.cz/xiaohuggg/status/1747821655182000569#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747821655182000569#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 03:22:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软的AutoGen Studio：用于构建AI代理的无代码平台。<br />
<br />
AutoGen AI代理能够执行各种任务，从编写和执行代码到规划旅行，甚至绘制股票图表。可以调用多个代理共同工作。<br />
<br />
<a href="https://nitter.cz/MatthewBerman" title="MatthewBerman">@MatthewBerman</a> 提供了有关如何安装和使用 AutoGen Studio 的教程和详细使用信息。<br />
<br />
感兴趣的可以看看：</p>
<p><a href="https://nitter.cz/MatthewBerman/status/1746933294246281667#m">nitter.cz/MatthewBerman/status/1746933294246281667#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747838869951910225#m</id>
            <title>RT by @dotey: 和PhotoMaker针锋相对

InstantID：只需一张人脸照片 几秒钟就能生成不同风格的人物照片

与传统方法需要多张参考图像和复杂的微调过程不同，InstantID只需一张图像，而且无需复杂的训练或微调过程。

你只需提供一张照片，它就能根据这张照片生成很多不同风格的图片，同时保持这个人的面貌特征不变。

InstantID 的主要特点包括：

1、高保真度的个性化图像生成： 使用单张参考图像，InstantID 能够生成高质量的、保持个人特征的图像，适用于各种风格。

2、简化的操作流程： 与传统方法需要多张参考图像和复杂的微调过程不同，InstantID 只需一张图像，无需复杂的训练或微调过程。 能在几秒钟内生成图像。

3、兼容性强： 能够与当前社区中预训练的流行文本到图像模型（如 SD1.5 和 SDXL）无缝集成，作为一个通用插件。

4、面部保真度和文本编辑性： 相较于其他技术，InstantID 在保持面部特征的真实性和文本编辑能力方面表现更好。用户可以通过文本提示来编辑生成的图像，比如改变图像中人物的表情、背景或其他元素。
用户可以精确控制生成图像的细节，实现个性化定制。

5、多样化应用场景： 支持多种风格化和写实的图像生成，能够适应不同的视觉需求。

6、实用性和效率： 对于需要快速生成并保持个人身份特征的图像的实际应用场景，如数字艺术创作和个性化媒体内容制作，InstantID 显示出了出色的性能和高效率。

7、支持多重参考：该技术技术也允许使用多张参考图像来生成一个新图像。这意味着可以结合多个不同的图像特征或风格来创造一个新的图像。即使是用单张参考图像，InstantID 也能实现高质量的结果，但多张图像可以提供更多的信息和灵感，从而增强生成图像的丰富性和多样性。

项目及演示：https://instantid.github.io/
论文：https://arxiv.org/abs/2401.07519
GitHub：https://github.com/InstantID/InstantID</title>
            <link>https://nitter.cz/xiaohuggg/status/1747838869951910225#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747838869951910225#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 04:30:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>和PhotoMaker针锋相对<br />
<br />
InstantID：只需一张人脸照片 几秒钟就能生成不同风格的人物照片<br />
<br />
与传统方法需要多张参考图像和复杂的微调过程不同，InstantID只需一张图像，而且无需复杂的训练或微调过程。<br />
<br />
你只需提供一张照片，它就能根据这张照片生成很多不同风格的图片，同时保持这个人的面貌特征不变。<br />
<br />
InstantID 的主要特点包括：<br />
<br />
1、高保真度的个性化图像生成： 使用单张参考图像，InstantID 能够生成高质量的、保持个人特征的图像，适用于各种风格。<br />
<br />
2、简化的操作流程： 与传统方法需要多张参考图像和复杂的微调过程不同，InstantID 只需一张图像，无需复杂的训练或微调过程。 能在几秒钟内生成图像。<br />
<br />
3、兼容性强： 能够与当前社区中预训练的流行文本到图像模型（如 SD1.5 和 SDXL）无缝集成，作为一个通用插件。<br />
<br />
4、面部保真度和文本编辑性： 相较于其他技术，InstantID 在保持面部特征的真实性和文本编辑能力方面表现更好。用户可以通过文本提示来编辑生成的图像，比如改变图像中人物的表情、背景或其他元素。<br />
用户可以精确控制生成图像的细节，实现个性化定制。<br />
<br />
5、多样化应用场景： 支持多种风格化和写实的图像生成，能够适应不同的视觉需求。<br />
<br />
6、实用性和效率： 对于需要快速生成并保持个人身份特征的图像的实际应用场景，如数字艺术创作和个性化媒体内容制作，InstantID 显示出了出色的性能和高效率。<br />
<br />
7、支持多重参考：该技术技术也允许使用多张参考图像来生成一个新图像。这意味着可以结合多个不同的图像特征或风格来创造一个新的图像。即使是用单张参考图像，InstantID 也能实现高质量的结果，但多张图像可以提供更多的信息和灵感，从而增强生成图像的丰富性和多样性。<br />
<br />
项目及演示：<a href="https://instantid.github.io/">instantid.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2401.07519">arxiv.org/abs/2401.07519</a><br />
GitHub：<a href="https://github.com/InstantID/InstantID">github.com/InstantID/Instant…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4Mjc0MzU2NzExMDk2MzIvcHUvaW1nL2NHTXoxQlVSVEhENFBlaWcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1747847128620126555#m</id>
            <title>R to @dotey: AlphaGeometry 中最复杂的合成证明，如论文所绘，长达 247 步；而最简单的证明只需一步。图片来自 Trinh 等人，《自然》2024</title>
            <link>https://nitter.cz/dotey/status/1747847128620126555#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1747847128620126555#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 05:03:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AlphaGeometry 中最复杂的合成证明，如论文所绘，长达 247 步；而最简单的证明只需一步。图片来自 Trinh 等人，《自然》2024</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VHWnNFTldzQUFnUENuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1747846747055919262#m</id>
            <title>R to @dotey: 纽约时报有一篇报道提供了更多细节：

第二个创新点是，一旦 AlphaGeometry 开始解决一个问题，符号处理引擎就会介入。如果处理过程中遇到难题，神经网络便会提出增强证明论点的方法。这个循环一直持续，直到找到解决方案或耗尽时间（最长四个半小时）。这种增强过程在数学术语中被称为“辅助构造”。无论是学生还是专业数学家，他们通常会通过增加一条线、二等分一个角或画一个圆等方法来解决数学问题。在这个系统中，神经网络学会了如何进行辅助构造，并且以一种类似人类的方式进行。Trinh 博士将这比作在难以打开的瓶盖上缠绕橡皮筋，以增强手部的抓握力。

“这是一个非常有趣的概念验证，”前谷歌员工、xAI 联合创始人 Christian Szegedy 评论说。但他也指出，这个系统“还存在许多未解之谜”，并且它“不容易被推广到其他数学领域或其他学科”。

Trinh 博士表示，他计划将这一系统应用到数学的其他领域乃至更广泛的领域。他希望进一步探索所有类型推理背后的“共同基本原理”。

法国高等师范学院的认知神经科学家Stanislas Dehaene，在基础几何知识领域有着深入的研究兴趣。他对 AlphaGeometry 的性能表现赞不绝口。然而，他提到这个系统在解决问题时，并没有实际“看到”问题的本质——它仅仅是处理了图像的逻辑和数字编码（这些图纸实际上是为了方便人类读者）。Dehaene 博士指出：“系统所操作的圆、线条和三角形，并没有被赋予任何空间感知。”研究人员也认同，引入视觉元素可能会大有裨益。Luong 博士表示，他们计划在一年内利用谷歌的 Gemini——一个能够同时处理文本和图像的“多模态”系统——来实现这一点。

https://baoyu.io/translations/ai/ai-computers-mathematics-olympiad</title>
            <link>https://nitter.cz/dotey/status/1747846747055919262#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1747846747055919262#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 05:01:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>纽约时报有一篇报道提供了更多细节：<br />
<br />
第二个创新点是，一旦 AlphaGeometry 开始解决一个问题，符号处理引擎就会介入。如果处理过程中遇到难题，神经网络便会提出增强证明论点的方法。这个循环一直持续，直到找到解决方案或耗尽时间（最长四个半小时）。这种增强过程在数学术语中被称为“辅助构造”。无论是学生还是专业数学家，他们通常会通过增加一条线、二等分一个角或画一个圆等方法来解决数学问题。在这个系统中，神经网络学会了如何进行辅助构造，并且以一种类似人类的方式进行。Trinh 博士将这比作在难以打开的瓶盖上缠绕橡皮筋，以增强手部的抓握力。<br />
<br />
“这是一个非常有趣的概念验证，”前谷歌员工、xAI 联合创始人 Christian Szegedy 评论说。但他也指出，这个系统“还存在许多未解之谜”，并且它“不容易被推广到其他数学领域或其他学科”。<br />
<br />
Trinh 博士表示，他计划将这一系统应用到数学的其他领域乃至更广泛的领域。他希望进一步探索所有类型推理背后的“共同基本原理”。<br />
<br />
法国高等师范学院的认知神经科学家Stanislas Dehaene，在基础几何知识领域有着深入的研究兴趣。他对 AlphaGeometry 的性能表现赞不绝口。然而，他提到这个系统在解决问题时，并没有实际“看到”问题的本质——它仅仅是处理了图像的逻辑和数字编码（这些图纸实际上是为了方便人类读者）。Dehaene 博士指出：“系统所操作的圆、线条和三角形，并没有被赋予任何空间感知。”研究人员也认同，引入视觉元素可能会大有裨益。Luong 博士表示，他们计划在一年内利用谷歌的 Gemini——一个能够同时处理文本和图像的“多模态”系统——来实现这一点。<br />
<br />
<a href="https://baoyu.io/translations/ai/ai-computers-mathematics-olympiad">baoyu.io/translations/ai/ai-…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1747831626392879395#m</id>
            <title>R to @dotey: Action Schema:

openapi: 3.0.0
info:
  version: 0.1.2
  title: arXiv Metadata API (Atom+XML)
  description: |
    A query API for arXiv paper metadata.
  termsOfService: https://arxiv.org/help/general
  contact:
    name: arXiv API Team
    email: nextgen@arxiv.org
  license:
    name: MIT
servers:
  - url: https://export.arxiv.org/api/
    description: Metadata API endpoint.
paths:
  /query:
    get:
      operationId: query
      description: |
        Returns all published arXiv papers that respond to the specified
        query parameters. By default, returns most recent papers first.
      parameters:
        - name: search_query
          in: query
          description: |
            A string that represents a search query. Fields are specified by "field:value" and 
            delimited with "AND", "OR", and "ANDNOT" boolean operators. Valid field names are:
            ti (title), au (author), abs(abstract), co (comment), jr (journal reference), cat
            (subject category), rn (report number), id (id - use id_list instead), all (all 
            fields).
          required: false
          style: form
          explode: true
          schema:
            type: string
          example: au:del_maestro+AND+ti:checkerboard
        - name: id_list
          in: query
          description: |
            A comma-delimited list of arXiv id's.
          required: false
          schema:
            type: string
          example: 1234.12345,5678.56789
        - name: start
          in: query
          description: |
            Defines the index of the first returned result, using 0-based indexing.
          required: false
          schema:
            type: integer
          example: 0
        - name: max_results
          in: query
          description: |
            The number of results returned by the query. Used in conjunction with "start" for 
            pagination. Max_results is limited to 30000, in slices of 2000.
          required: false
          schema:
            type: integer
          example: 10
        - name: sortBy
          in: query
          description: |
            Method to sort results.
          required: false
          schema:
            type: string
            enum:
              - relevance
              - lastUpdatedDate
              - submittedDate
        - name: sortOrder
          in: query
          description: |
            Order for the sort method
          required: false
          schema:
            type: string
            enum:
              - ascending
              - descending
      responses:
        default:
          description: All queries return a valid Atom XML feed, even errors.
          content:
            application/atom+xml:
              schema:
                $ref: ./resources/AtomXML.yaml#
components:
  schemas:
    Error:
      required:
        - code
        - message
      properties:
        code:
          type: integer
          format: int32
        message:
          type: string</title>
            <link>https://nitter.cz/dotey/status/1747831626392879395#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1747831626392879395#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 04:01:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Action Schema:<br />
<br />
openapi: 3.0.0<br />
info:<br />
  version: 0.1.2<br />
  title: arXiv Metadata API (Atom+XML)<br />
  description: |<br />
    A query API for arXiv paper metadata.<br />
  termsOfService: <a href="https://arxiv.org/help/general">arxiv.org/help/general</a><br />
  contact:<br />
    name: arXiv API Team<br />
    email: nextgen@arxiv.org<br />
  license:<br />
    name: MIT<br />
servers:<br />
  - url: <a href="https://export.arxiv.org/api/">export.arxiv.org/api/</a><br />
    description: Metadata API endpoint.<br />
paths:<br />
  /query:<br />
    get:<br />
      operationId: query<br />
      description: |<br />
        Returns all published arXiv papers that respond to the specified<br />
        query parameters. By default, returns most recent papers first.<br />
      parameters:<br />
        - name: search_query<br />
          in: query<br />
          description: |<br />
            A string that represents a search query. Fields are specified by "field:value" and <br />
            delimited with "AND", "OR", and "ANDNOT" boolean operators. Valid field names are:<br />
            ti (title), au (author), abs(abstract), co (comment), jr (journal reference), cat<br />
            (subject category), rn (report number), id (id - use id_list instead), all (all <br />
            fields).<br />
          required: false<br />
          style: form<br />
          explode: true<br />
          schema:<br />
            type: string<br />
          example: au:del_maestro+AND+ti:checkerboard<br />
        - name: id_list<br />
          in: query<br />
          description: |<br />
            A comma-delimited list of arXiv id's.<br />
          required: false<br />
          schema:<br />
            type: string<br />
          example: 1234.12345,5678.56789<br />
        - name: start<br />
          in: query<br />
          description: |<br />
            Defines the index of the first returned result, using 0-based indexing.<br />
          required: false<br />
          schema:<br />
            type: integer<br />
          example: 0<br />
        - name: max_results<br />
          in: query<br />
          description: |<br />
            The number of results returned by the query. Used in conjunction with "start" for <br />
            pagination. Max_results is limited to 30000, in slices of 2000.<br />
          required: false<br />
          schema:<br />
            type: integer<br />
          example: 10<br />
        - name: sortBy<br />
          in: query<br />
          description: |<br />
            Method to sort results.<br />
          required: false<br />
          schema:<br />
            type: string<br />
            enum:<br />
              - relevance<br />
              - lastUpdatedDate<br />
              - submittedDate<br />
        - name: sortOrder<br />
          in: query<br />
          description: |<br />
            Order for the sort method<br />
          required: false<br />
          schema:<br />
            type: string<br />
            enum:<br />
              - ascending<br />
              - descending<br />
      responses:<br />
        default:<br />
          description: All queries return a valid Atom XML feed, even errors.<br />
          content:<br />
            application/atom+xml:<br />
              schema:<br />
                <a href="https://nitter.cz/search?q=%23ref">$ref</a>: ./resources/AtomXML.yaml#<br />
components:<br />
  schemas:<br />
    Error:<br />
      required:<br />
        - code<br />
        - message<br />
      properties:<br />
        code:<br />
          type: integer<br />
          format: int32<br />
        message:<br />
          type: string</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VHTGRfd1hvQUFyc1J3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>