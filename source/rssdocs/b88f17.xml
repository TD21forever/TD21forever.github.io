<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734728249396085116#m</id>
            <title>R to @dotey: 配合 @realrenmin 老师这条一起看
https://x.com/realrenmin/status/1734721215283986628?s=20</title>
            <link>https://nitter.cz/dotey/status/1734728249396085116#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734728249396085116#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 00:13:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>配合 <a href="https://nitter.cz/realrenmin" title="Sverige_ Dong-seok🇸🇪">@realrenmin</a> 老师这条一起看<br />
<a href="https://x.com/realrenmin/status/1734721215283986628?s=20">x.com/realrenmin/status/1734…</a></p>
<p><a href="https://nitter.cz/realrenmin/status/1734721215283986628#m">nitter.cz/realrenmin/status/1734721215283986628#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/realrenmin/status/1734721215283986628#m</id>
            <title>RT by @dotey: Mistral AI放出Mixtral 8x7B, 基于Mixture of Experts (MoE)的开源模型，效果不错。

但在我看来，MoE是transformer时代LSTM-GRU，是NLP古早的范式，architecture engineering，非常old school。核心方法是加一些gate来加强Efficient Training at Scale，简言之目的是为了低成本训练，而不是为了塑造专家模型。

而Mixture of Experts的名字，太具迷惑性了，字面意思似乎是各种专家模型的组合起到1+1>2的效果。但实际看看Mixtral 8x7B，8个mistral 7b，b b不一样，但没有一个是专家模型，之所以叫做expert，居然是MoE中的FNN，我十分怀疑FNN能有什么专家能力。

它的benchmarking也理所当然的跟通用大模型GPT3.5/Llama 2相比，比较的是generic能力，并没有什么突出的专家能力。粗算了一下，8x7B float16, 至少需要100GB以上GPU显存，cost巨大。在这种情况下，oss的情怀，不足以说服我不用OpenAI的api。

如果我们停下来想想，什么是expert。
首先，expert能力一定不是通用大模型的generic的能力，而是独特的specialization的能力。例如会写code的GitHub copilot，或会generate思科路由器配置命令，甚至特别会planning，特别会算数都是专家能力都算。
简言之，expert能力是会产生特定领域特定输出的能力。所以，MoE是一个好名字，在这个时代，缺有些名不副实。

而做specialization模型的技术，依然在发展，并且依然是前沿，其实就是lora微调，例如Stanford's Alpaca models项目等等，核心思想就是在开源模型上加adapter，使之能够完成一个具体领域的专家工作，其实Mistral AI的开源7b模型估计也是这么做出来的。

未来，大语言模型作为agent的时代在实际中的应用，一定是llm在中间协调多种多样不同7b抽象出来的api，来完成新的human computer interaction。甚至在特定领域，这个协调工作也可以被planning expert的开源模型替代，而协调的过程，还是离不开 CoT，React，ReWoo或者其他的prompting方法。

CoT, ReAct在我的推中已经分享过好几次了，接下来找时间把ReWoo, 几个微调的介绍（跳票很久了）分享给大家。</title>
            <link>https://nitter.cz/realrenmin/status/1734721215283986628#m</link>
            <guid isPermaLink="false">https://nitter.cz/realrenmin/status/1734721215283986628#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 23:45:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mistral AI放出Mixtral 8x7B, 基于Mixture of Experts (MoE)的开源模型，效果不错。<br />
<br />
但在我看来，MoE是transformer时代LSTM-GRU，是NLP古早的范式，architecture engineering，非常old school。核心方法是加一些gate来加强Efficient Training at Scale，简言之目的是为了低成本训练，而不是为了塑造专家模型。<br />
<br />
而Mixture of Experts的名字，太具迷惑性了，字面意思似乎是各种专家模型的组合起到1+1>2的效果。但实际看看Mixtral 8x7B，8个mistral 7b，b b不一样，但没有一个是专家模型，之所以叫做expert，居然是MoE中的FNN，我十分怀疑FNN能有什么专家能力。<br />
<br />
它的benchmarking也理所当然的跟通用大模型GPT3.5/Llama 2相比，比较的是generic能力，并没有什么突出的专家能力。粗算了一下，8x7B float16, 至少需要100GB以上GPU显存，cost巨大。在这种情况下，oss的情怀，不足以说服我不用OpenAI的api。<br />
<br />
如果我们停下来想想，什么是expert。<br />
首先，expert能力一定不是通用大模型的generic的能力，而是独特的specialization的能力。例如会写code的GitHub copilot，或会generate思科路由器配置命令，甚至特别会planning，特别会算数都是专家能力都算。<br />
简言之，expert能力是会产生特定领域特定输出的能力。所以，MoE是一个好名字，在这个时代，缺有些名不副实。<br />
<br />
而做specialization模型的技术，依然在发展，并且依然是前沿，其实就是lora微调，例如Stanford's Alpaca models项目等等，核心思想就是在开源模型上加adapter，使之能够完成一个具体领域的专家工作，其实Mistral AI的开源7b模型估计也是这么做出来的。<br />
<br />
未来，大语言模型作为agent的时代在实际中的应用，一定是llm在中间协调多种多样不同7b抽象出来的api，来完成新的human computer interaction。甚至在特定领域，这个协调工作也可以被planning expert的开源模型替代，而协调的过程，还是离不开 CoT，React，ReWoo或者其他的prompting方法。<br />
<br />
CoT, ReAct在我的推中已经分享过好几次了，接下来找时间把ReWoo, 几个微调的介绍（跳票很久了）分享给大家。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mtrainier2020/status/1734671070144446927#m</id>
            <title>RT by @dotey: 讲一个小案例，一家走完上市准备流程的公司，死在上市前的故事。中间有很多可以参考的地方。
这家公司是欧洲某国的物流+电商企业。做了很久了，在当地也算是地头蛇了。 营收都很健康。
随着海淘的浪潮，他们公司发展特别快。很快就被巨头给盯上了。
第一个出手的是顺丰旗下的公司，他们的应对方法就是，你只要在一个地方设点，我就永远低于你价格10%，揽件。对于地头蛇来讲属于生死之战，可以拿其他地方的利润来补。但是对于顺丰来讲，除非公司层面有决心亏三年，一定战略占领这个地方，否则，大公司有大公司的难处。所以顺丰在该国业务开展的并不恨顺利。
ps，这也是非常常见的打法。

第二就是，老奸巨猾的某东了。

首先，某东首先表示收购意愿。
然后，强哥邀请核心创始人去家里吃饭。强哥亲自做饭。
结果就是，该司将该公司的各种商业窍门，以及上上下下，里里外外啥都不剩，给人讲了一遍。 这是该公司犯的第一个错误。
好了。
过了一段时间，某东就说，给你两个选择，要么帮我们建一套跟你们一样的系统。要么我去找你竞争对手去建。
然后收购这事呢，也一直缓慢推进。吊着你。
这个公司，犯的第二个错误。他们知道被当枪使，还是去帮某东去建一套系统。
果不其然，收购这事，最后也黄了。

当然，还有一些事情纠葛在一起，这个公司今年黄的。

lesson learned：
1. 不要怕打架。
2. 见到大佬不要慌，不要把核心机密全盘托出。 不见兔子不撒鹰。
3. 打破囚徒困境的办法找到利益共同点搞联盟，搞交叉持股。</title>
            <link>https://nitter.cz/mtrainier2020/status/1734671070144446927#m</link>
            <guid isPermaLink="false">https://nitter.cz/mtrainier2020/status/1734671070144446927#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 20:26:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>讲一个小案例，一家走完上市准备流程的公司，死在上市前的故事。中间有很多可以参考的地方。<br />
这家公司是欧洲某国的物流+电商企业。做了很久了，在当地也算是地头蛇了。 营收都很健康。<br />
随着海淘的浪潮，他们公司发展特别快。很快就被巨头给盯上了。<br />
第一个出手的是顺丰旗下的公司，他们的应对方法就是，你只要在一个地方设点，我就永远低于你价格10%，揽件。对于地头蛇来讲属于生死之战，可以拿其他地方的利润来补。但是对于顺丰来讲，除非公司层面有决心亏三年，一定战略占领这个地方，否则，大公司有大公司的难处。所以顺丰在该国业务开展的并不恨顺利。<br />
ps，这也是非常常见的打法。<br />
<br />
第二就是，老奸巨猾的某东了。<br />
<br />
首先，某东首先表示收购意愿。<br />
然后，强哥邀请核心创始人去家里吃饭。强哥亲自做饭。<br />
结果就是，该司将该公司的各种商业窍门，以及上上下下，里里外外啥都不剩，给人讲了一遍。 这是该公司犯的第一个错误。<br />
好了。<br />
过了一段时间，某东就说，给你两个选择，要么帮我们建一套跟你们一样的系统。要么我去找你竞争对手去建。<br />
然后收购这事呢，也一直缓慢推进。吊着你。<br />
这个公司，犯的第二个错误。他们知道被当枪使，还是去帮某东去建一套系统。<br />
果不其然，收购这事，最后也黄了。<br />
<br />
当然，还有一些事情纠葛在一起，这个公司今年黄的。<br />
<br />
lesson learned：<br />
1. 不要怕打架。<br />
2. 见到大佬不要慌，不要把核心机密全盘托出。 不见兔子不撒鹰。<br />
3. 打破囚徒困境的办法找到利益共同点搞联盟，搞交叉持股。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734708814983602256#m</id>
            <title>哇塞，Mixtral-8x7b 已经成为排名第一的开源模型。

另外http://lmsys.org的数据是非常靠谱的，因为它完全是用户上去评分，用户输入一个问题，会随机有两个模型给你回答，用户根据回复的结果选择一个结果最好的模型，在打分之前用户完全不知道是哪个模型。

建议有空也可以上去测试评选一下：http://chat.lmsys.org</title>
            <link>https://nitter.cz/dotey/status/1734708814983602256#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734708814983602256#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 22:56:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哇塞，Mixtral-8x7b 已经成为排名第一的开源模型。<br />
<br />
另外<a href="http://lmsys.org">lmsys.org</a>的数据是非常靠谱的，因为它完全是用户上去评分，用户输入一个问题，会随机有两个模型给你回答，用户根据回复的结果选择一个结果最好的模型，在打分之前用户完全不知道是哪个模型。<br />
<br />
建议有空也可以上去测试评选一下：<a href="http://chat.lmsys.org">chat.lmsys.org</a></p>
<p><a href="https://nitter.cz/lmsysorg/status/1734680611393073289#m">nitter.cz/lmsysorg/status/1734680611393073289#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734642351090422077#m</id>
            <title>R to @dotey: x.com/dotey/status/173464195…</title>
            <link>https://nitter.cz/dotey/status/1734642351090422077#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734642351090422077#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 18:32:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://x.com/dotey/status/1734641959522783467?s=20">x.com/dotey/status/173464195…</a></p>
<p><a href="https://nitter.cz/dotey/status/1734641959522783467#m">nitter.cz/dotey/status/1734641959522783467#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734641959522783467#m</id>
            <title>测试了一下，速度很快，能懂中文，但是输出中文不太行，写代码能力还可以👍🏻

测试地址：http://labs.perplexity.ai https://labs.perplexity.ai/ （注意右下角切换成 mixtral-8x7b-instruct）</title>
            <link>https://nitter.cz/dotey/status/1734641959522783467#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734641959522783467#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 18:30:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>测试了一下，速度很快，能懂中文，但是输出中文不太行，写代码能力还可以👍🏻<br />
<br />
测试地址：<a href="http://labs.perplexity.ai">labs.perplexity.ai</a> <a href="https://labs.perplexity.ai/">labs.perplexity.ai/</a> （注意右下角切换成 mixtral-8x7b-instruct）</p>
<p><a href="https://nitter.cz/op7418/status/1734605584421548412#m">nitter.cz/op7418/status/1734605584421548412#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JLdlRWQ1dNQUEyaEFmLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JLdldYLVgwQUF4bkxaLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734569923160981706#m</id>
            <title>了不起👍</title>
            <link>https://nitter.cz/dotey/status/1734569923160981706#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734569923160981706#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 13:44:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>了不起👍</p>
<p><a href="https://nitter.cz/arvin17x/status/1734387717738525137#m">nitter.cz/arvin17x/status/1734387717738525137#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734497196953985354#m</id>
            <title>RT by @dotey: 南洋理工发布了一个 AI 视频放大算法 Upscale-A-Video，视频生成真的全方位的卷起来了。下面是演示和介绍：

简介：
Upscale-A-Video的文本引导潜在扩散框架，用于视频放大。该框架通过两个关键机制确保时间上的一致性：在局部上，它将时间层集成到U-Net和VAE-Decoder中，保持短序列的一致性；
在全局上，引入了一个基于流引导的经常性潜在传播模块，通过在整个序列中传播和融合潜在来增强整体视频的稳定性。
由于扩散范式，模型还通过允许文本提示来引导纹理创建和可调噪声水平来平衡恢复和生成，从而在保真度和质量之间实现权衡。

方法：
高级视频使用本地和全局策略处理长视频，以保持时间上的连贯性。它将视频分成片段，并使用具有时间层的U-Net来处理它们，以实现片段内的一致性。在用户指定的全局细化扩散步骤中，使用循环潜在传播模块来增强片段间的一致性。最后，经过微调的VAE-Decoder减少剩余的闪烁伪影，以实现低级一致性。

结果：
广泛的实验表明，Upscale-A-Video在合成和真实世界的基准测试中超过了现有的方法，以及在人工智能生成的视频中展示出令人印象深刻的视觉逼真和时间一致性。

项目地址：https://shangchenzhou.com/projects/upscale-a-video/</title>
            <link>https://nitter.cz/op7418/status/1734497196953985354#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734497196953985354#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 08:55:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>南洋理工发布了一个 AI 视频放大算法 Upscale-A-Video，视频生成真的全方位的卷起来了。下面是演示和介绍：<br />
<br />
简介：<br />
Upscale-A-Video的文本引导潜在扩散框架，用于视频放大。该框架通过两个关键机制确保时间上的一致性：在局部上，它将时间层集成到U-Net和VAE-Decoder中，保持短序列的一致性；<br />
在全局上，引入了一个基于流引导的经常性潜在传播模块，通过在整个序列中传播和融合潜在来增强整体视频的稳定性。<br />
由于扩散范式，模型还通过允许文本提示来引导纹理创建和可调噪声水平来平衡恢复和生成，从而在保真度和质量之间实现权衡。<br />
<br />
方法：<br />
高级视频使用本地和全局策略处理长视频，以保持时间上的连贯性。它将视频分成片段，并使用具有时间层的U-Net来处理它们，以实现片段内的一致性。在用户指定的全局细化扩散步骤中，使用循环潜在传播模块来增强片段间的一致性。最后，经过微调的VAE-Decoder减少剩余的闪烁伪影，以实现低级一致性。<br />
<br />
结果：<br />
广泛的实验表明，Upscale-A-Video在合成和真实世界的基准测试中超过了现有的方法，以及在人工智能生成的视频中展示出令人印象深刻的视觉逼真和时间一致性。<br />
<br />
项目地址：<a href="https://shangchenzhou.com/projects/upscale-a-video/">shangchenzhou.com/projects/u…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ0OTY0MzU4NTk3OTU5NjkvcHUvaW1nL1ZZLXdpMmk0ZkNPYUVLSGYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734548820602864050#m</id>
            <title>RT by @dotey: @arvin17x  开发的 Lobehub 昨天突然在推上爆了。
在 Open AI 套壳的开源项目里面他们的视觉表现和体验确实是独一份的。界面非常漂亮，同时交互细节打磨的也很成熟。
也支持了 GPT-4V 视觉模型交互和 TTS 。同时还有生态非常好的 Agents 插件市场。
未来还会支持几个DALL-E 和 MJ AI 画图能力。
顺便 SD WebUI 都在用的Lobe theme主题也是他们做的。

项目地址：https://chat-preview.lobehub.com/welcome</title>
            <link>https://nitter.cz/op7418/status/1734548820602864050#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734548820602864050#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 12:20:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/arvin17x" title="空谷 · Arvin Xu">@arvin17x</a>  开发的 Lobehub 昨天突然在推上爆了。<br />
在 Open AI 套壳的开源项目里面他们的视觉表现和体验确实是独一份的。界面非常漂亮，同时交互细节打磨的也很成熟。<br />
也支持了 GPT-4V 视觉模型交互和 TTS 。同时还有生态非常好的 Agents 插件市场。<br />
未来还会支持几个DALL-E 和 MJ AI 画图能力。<br />
顺便 SD WebUI 都在用的Lobe theme主题也是他们做的。<br />
<br />
项目地址：<a href="https://chat-preview.lobehub.com/welcome">chat-preview.lobehub.com/wel…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JKWi1Sd2FRQUFDdWprLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1734495786208272824#m</id>
            <title>RT by @dotey: Upscale-A-Video：AI提升视频画质
演示视频选的好哇。
项目地址：https://shangchenzhou.com/projects/upscale-a-video/
Github（代码暂未发布）：https://github.com/sczhou/Upscale-A-Video</title>
            <link>https://nitter.cz/Gorden_Sun/status/1734495786208272824#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1734495786208272824#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 08:49:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Upscale-A-Video：AI提升视频画质<br />
演示视频选的好哇。<br />
项目地址：<a href="https://shangchenzhou.com/projects/upscale-a-video/">shangchenzhou.com/projects/u…</a><br />
Github（代码暂未发布）：<a href="https://github.com/sczhou/Upscale-A-Video">github.com/sczhou/Upscale-A-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ0OTU2ODY1MTM4NzI4OTYvcHUvaW1nL05BYUl5RkxMLWt0QzJqN2guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1734499555654377759#m</id>
            <title>RT by @dotey: 这个项目挺搞笑的 哈哈哈 你们看看😂

CLoT：训练LLM成为吐槽能手

用日本传统喜剧游戏“大喜利”（Oogiri）作为测试，挑战AI以吐槽高手的方式回应信息。

游戏中的挑战，AI需要理解给定图文信息来产生幽默搞笑的回答。

Oogiri 是一种需要参与者对给定的图像文做出意想不到且幽默的回应的创意游戏。

测试包括图像到文本（I2T）、文本到文本（T2T）和图像&amp;文本到文本（IT2T）

具体方法：

建立数据集：研究人员构建了一个多模态、多语言的 Oogiri-GO 数据集，包含超过 130000 个样本。

训练 AI：通过特殊的训练方法，让 AI 学会如何在游戏中给出创意和幽默的回答。

CLoT 首先将 Oogiri-GO 数据集转化为 LoT 导向的指令调整数据，以训练预训练的 LLM 达到一定的 LoT 幽默生成和辨别能力。

然后，CLoT 设计了一个探索性自我完善过程，鼓励 LLM 通过探索看似无关概念之间的平行关系来生成更多创造性的 LoT 数据，并选择高质量数据进行自我完善。

实验结果：

实验结果显示，CLoT 能够显著提高 LLM（如 Qwen 和 CogVLM）在多种 Oogiri 游戏类型中的表现。具体来说，CLoT 帮助 LLM 生成了更好的幽默内容。

量化性能提升：与原始和 CoT 集成的 LLM 相比，CLoT 集成的 LLM 在 Oogiri 游戏的多项选择和排名问题中取得了更高的性能。

创造性能力的提升：CLoT 还在其他任务（如“云猜测游戏”和“发散性联想任务”）中提高了创造性能力，显示出其卓越的泛化能力。

项目及演示：https://zhongshsh.github.io/CLoT/
论文：https://arxiv.org/abs/2312.02439
GitHub：https://github.com/sail-sg/CLoT</title>
            <link>https://nitter.cz/xiaohuggg/status/1734499555654377759#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1734499555654377759#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 09:04:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个项目挺搞笑的 哈哈哈 你们看看😂<br />
<br />
CLoT：训练LLM成为吐槽能手<br />
<br />
用日本传统喜剧游戏“大喜利”（Oogiri）作为测试，挑战AI以吐槽高手的方式回应信息。<br />
<br />
游戏中的挑战，AI需要理解给定图文信息来产生幽默搞笑的回答。<br />
<br />
Oogiri 是一种需要参与者对给定的图像文做出意想不到且幽默的回应的创意游戏。<br />
<br />
测试包括图像到文本（I2T）、文本到文本（T2T）和图像&文本到文本（IT2T）<br />
<br />
具体方法：<br />
<br />
建立数据集：研究人员构建了一个多模态、多语言的 Oogiri-GO 数据集，包含超过 130000 个样本。<br />
<br />
训练 AI：通过特殊的训练方法，让 AI 学会如何在游戏中给出创意和幽默的回答。<br />
<br />
CLoT 首先将 Oogiri-GO 数据集转化为 LoT 导向的指令调整数据，以训练预训练的 LLM 达到一定的 LoT 幽默生成和辨别能力。<br />
<br />
然后，CLoT 设计了一个探索性自我完善过程，鼓励 LLM 通过探索看似无关概念之间的平行关系来生成更多创造性的 LoT 数据，并选择高质量数据进行自我完善。<br />
<br />
实验结果：<br />
<br />
实验结果显示，CLoT 能够显著提高 LLM（如 Qwen 和 CogVLM）在多种 Oogiri 游戏类型中的表现。具体来说，CLoT 帮助 LLM 生成了更好的幽默内容。<br />
<br />
量化性能提升：与原始和 CoT 集成的 LLM 相比，CLoT 集成的 LLM 在 Oogiri 游戏的多项选择和排名问题中取得了更高的性能。<br />
<br />
创造性能力的提升：CLoT 还在其他任务（如“云猜测游戏”和“发散性联想任务”）中提高了创造性能力，显示出其卓越的泛化能力。<br />
<br />
项目及演示：<a href="https://zhongshsh.github.io/CLoT/">zhongshsh.github.io/CLoT/</a><br />
论文：<a href="https://arxiv.org/abs/2312.02439">arxiv.org/abs/2312.02439</a><br />
GitHub：<a href="https://github.com/sail-sg/CLoT">github.com/sail-sg/CLoT</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ0OTgyODU0MTM2OTEzOTIvcHUvaW1nL3pVYWk0YTlWeWRBbFFFSHcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734465940039807357#m</id>
            <title>给 CSDN 《新程序员》写的一个稿子：《2023 年，我患上了 AI 焦虑症》，CSDN 公众号上刚发，我在自己博客上也发了一份。

CSDN 公众号链接：https://mp.weixin.qq.com/s/LbRvR1VXpZoDilyyMGGeFw

博客地址：https://baoyu.io/blog/ai/i-am-suffering-from-ai-anxiety-in-2023</title>
            <link>https://nitter.cz/dotey/status/1734465940039807357#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734465940039807357#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 06:51:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>给 CSDN 《新程序员》写的一个稿子：《2023 年，我患上了 AI 焦虑症》，CSDN 公众号上刚发，我在自己博客上也发了一份。<br />
<br />
CSDN 公众号链接：<a href="https://mp.weixin.qq.com/s/LbRvR1VXpZoDilyyMGGeFw">mp.weixin.qq.com/s/LbRvR1VXp…</a><br />
<br />
博客地址：<a href="https://baoyu.io/blog/ai/i-am-suffering-from-ai-anxiety-in-2023">baoyu.io/blog/ai/i-am-suffer…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JJUEw5NFdvQUEzdk9nLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734465344847167767#m</id>
            <title>推荐阅读：《探索编写提示词的乐趣：蒙特卡洛方法、木偶剧和笑声的融合 [译]》

来自 Instacart 官方技术博客的分享，里面有不少写Prompt的技巧，比如CoT、ReAct、“思维的空间”（Room for Thought）、 自我反思 等等

另外文章末尾也分享了很多有价值的Prompt相关的链接

原文：https://tech.instacart.com/monte-carlo-puppetry-and-laughter-the-unexpected-joys-of-prompt-engineering-4b9272e0c4eb

翻译：https://baoyu.io/translations/llm/monte-carlo-puppetry-and-laughter-the-unexpected-joys-of-prompt-engineering</title>
            <link>https://nitter.cz/dotey/status/1734465344847167767#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734465344847167767#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 06:48:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《探索编写提示词的乐趣：蒙特卡洛方法、木偶剧和笑声的融合 [译]》<br />
<br />
来自 Instacart 官方技术博客的分享，里面有不少写Prompt的技巧，比如CoT、ReAct、“思维的空间”（Room for Thought）、 自我反思 等等<br />
<br />
另外文章末尾也分享了很多有价值的Prompt相关的链接<br />
<br />
原文：<a href="https://tech.instacart.com/monte-carlo-puppetry-and-laughter-the-unexpected-joys-of-prompt-engineering-4b9272e0c4eb">tech.instacart.com/monte-car…</a><br />
<br />
翻译：<a href="https://baoyu.io/translations/llm/monte-carlo-puppetry-and-laughter-the-unexpected-joys-of-prompt-engineering">baoyu.io/translations/llm/mo…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JJUEJpV1hVQUFnc1FTLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734451913104543773#m</id>
            <title>有媒体报道，最近很火的阿里巴巴的“Animate Anyone”项目，是通过搜集 TikTok 上网红播主的视频进行训练的

转译：阿里巴巴的“Animate Anyone”项目，通过搜集著名 TikToker 的视频进行训练

这个将图像转换为视频的新模型因为人们认为它有可能替代 TikTok 上的网红而在本周迅速走红。然而，这项技术本身就已经内置了从内容创作者那里盗用作品的行为。

最近，中国零售与科技巨头阿里巴巴的研究团队发表了一篇新论文，介绍了他们的新模型——“Animate Anyone.”。这一消息在网上引发了热议，普遍看法是“TikTokers 的末日来临”，意味着用 AI 技术很快就能取代 TikTok 上的舞蹈内容创作者。

该模型能够接收输入数据（例如 TikTok 舞蹈视频），并输出新的版本。这次实验的结果相比之前类似尝试略有提升。大多数情况下，他们会复制已有的舞蹈视频，但在服装或风格上有所不同，整体效果略逊一筹。但正如 AI 技术的不断进步，这一模型也将持续优化。

已有人指出，“Animate Anyone”可能会被滥用，用来制作未经同意的、将人置于虚构场景的视频。实际上，自六年前这项技术问世以来，这已经成为深度伪造技术的主要用途。

然而，这不仅仅是一个遥远的预测：研究人员已经在未经许可的情况下使用了他人的作品，这已成为他们训练和构建模型的常规做法。阿里巴巴的这篇论文实际上是将最初由明尼苏达大学研究人员出于学术目的创建的“TikTok 数据集”商业化。404 Media 的快速检视显示，阿里巴巴的新 AI 是基于一个抓取了许多知名 TikTok 创作者视频的模型训练而成的，包括 Charli D’Amelio、Addison Rae、Ashley Nocera、Stina Kayy 等几十位。TikTok 数据集中也包括了一些几乎无名的 TikTok 账户用户。

图二：来自《Animate Anyone》论文的参考图像，动力推动帖，DISCO 模型的示例和阿里巴巴的成果展示。

在“Animate Anyone”研究论文的网站上，特别展示了一些著名的 TikTok 内容创作者，作为该模型成功运作的例证。在这些案例中，研究人员采用了这些知名 TikTok 影响者的视频作为参考图像，随后通过阿里巴巴开发的模型进行深度处理，制作出较差质量的 AI 生成副本。

这篇论文及其“Animate Anyone”模型的成果，是建立在未经授权使用创作者作品的基础上的。研究团队在他们的项目页面上，以三位网络名人和艺术家作为示例：Jasmine Chiswell（一位拥有近 1700 万 TikTok 粉丝的生活方式 YouTuber 和 TikTok 名人）、Mackenzie Ziegler（一名歌手和演员，因儿时在《Dance Moms》中出演而知名，拥有 2350 万 TikTok 粉丝）以及 Anna Šulcová（一名 YouTube 内容创作者，拥有 889,600 TikTok 粉丝）。

这些女性都依靠她们独立的创意工作谋生，但阿里巴巴团队却未经许可地使用了她们的作品来支持他们的研究。论文中还展示了更多的 TikTok 创作者，论文已在 arXiv 预印本服务器上发表。

阿里巴巴的研究人员在论文中提到，他们使用了包含 340 个训练视频和 100 个测试视频的“TikTok 数据集”，这些视频都是单人舞蹈，时长在 10 到 15 秒之间。该数据集源于 2021 年明尼苏达大学的一个项目，名为“观看社交媒体舞蹈视频来学习穿着人物的高保真深度”，该项目提出了一种用于“估计人体深度和恢复人体形状的方法”，例如使用 AI 技术在视频中为人物更换服装。

明尼苏达大学的研究人员指出：“我们手动筛选了超过 300 个 TikTok 舞蹈挑战视频，这些视频涵盖了各个月份、不同类型和风格的单人舞蹈。我们选择的舞蹈动作较为温和，以减少运动模糊的产生。对于每个视频，我们都以每秒 30 帧的速度提取了 RGB 图像，总计超过 100,000 张图像。”

大部分人工智能 (AI) 数据集是由在互联网上，如 TikTok 等社交网络，未经内容所有者同意便擦取的视频、图片和文字构成的。在这个例子中，一些博士生组织并启动的数据集，被全球最大的科技及零售公司之一所使用。

这样的情况并不罕见：一开始为学术研究而创建的大型数据集，最终被大公司用于商业目的，无论是相似的还是完全不同的。例如，北卡罗来纳大学威尔明顿分校的研究团队就曾从 YouTube 上擦取了跨性别人士上传的视频，并将其整合成一个数据库，用来研发一种能通过面部识别技术识别跨性别人士的技术。

在当前法律环境日趋严峻的背景下，如阿里巴巴的 AI 研究人员正使用充斥着用户生成内容的擦取数据集。艺术家和其他创作者因 AI 公司未经许可使用他们的作品而提起诉讼。代表艺术家的一起集体诉讼案针对 Midjourney、DeviantArt 和 Stability AI，在去年十月一位法官驳回部分诉求后，又增加了更多原告并提交了修改后的诉状。艺术家们认为，这些 AI 图像生成器复制了原告的作品，并且“创建了与其训练所用作品非常相似的替代品，无论是特定的训练图像还是模仿某些艺术家特有风格的图像，包括原告本人”。

上个月，一位联邦法官推翻了去年驳回编舞家 Kyle Hanagami 对 Epic Games 诉讼的决定。Hanagami 声称 Fortnite 使用了他的舞蹈动作作为“表情动作”。

“把编舞简化成‘姿势’，就好比把音乐仅仅看作‘音符’。编舞，本质上是一系列相关连的舞蹈动作和模式，它们被有机地编排成一个完整的作品，”法官如是写道。“这些动作和模式之间的互动，以及编舞者如何创新地将它们融合和安排，构成了这个作品的核心。仅仅是‘姿势’这个元素，远远不能全面展现出一个编舞作品中的创意表达。”

Hanagami 的律师对 Billboard 表示，推翻之前的驳回裁决将可能对编舞家及其他创意人士在短视频数字媒体时代的权利产生深远影响。这一切对阿里巴巴正在尝试通过“Animate Anyone”项目所打造的内容都有重大的意义，学者们在建立涉及真实人类内容的大型数据集时，也应深思这些决策的未来后果。

https://www.404media.co/alibaba-animate-anyone-ai-generated-tiktok/</title>
            <link>https://nitter.cz/dotey/status/1734451913104543773#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734451913104543773#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 05:55:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有媒体报道，最近很火的阿里巴巴的“Animate Anyone”项目，是通过搜集 TikTok 上网红播主的视频进行训练的<br />
<br />
转译：阿里巴巴的“Animate Anyone”项目，通过搜集著名 TikToker 的视频进行训练<br />
<br />
这个将图像转换为视频的新模型因为人们认为它有可能替代 TikTok 上的网红而在本周迅速走红。然而，这项技术本身就已经内置了从内容创作者那里盗用作品的行为。<br />
<br />
最近，中国零售与科技巨头阿里巴巴的研究团队发表了一篇新论文，介绍了他们的新模型——“Animate Anyone.”。这一消息在网上引发了热议，普遍看法是“TikTokers 的末日来临”，意味着用 AI 技术很快就能取代 TikTok 上的舞蹈内容创作者。<br />
<br />
该模型能够接收输入数据（例如 TikTok 舞蹈视频），并输出新的版本。这次实验的结果相比之前类似尝试略有提升。大多数情况下，他们会复制已有的舞蹈视频，但在服装或风格上有所不同，整体效果略逊一筹。但正如 AI 技术的不断进步，这一模型也将持续优化。<br />
<br />
已有人指出，“Animate Anyone”可能会被滥用，用来制作未经同意的、将人置于虚构场景的视频。实际上，自六年前这项技术问世以来，这已经成为深度伪造技术的主要用途。<br />
<br />
然而，这不仅仅是一个遥远的预测：研究人员已经在未经许可的情况下使用了他人的作品，这已成为他们训练和构建模型的常规做法。阿里巴巴的这篇论文实际上是将最初由明尼苏达大学研究人员出于学术目的创建的“TikTok 数据集”商业化。404 Media 的快速检视显示，阿里巴巴的新 AI 是基于一个抓取了许多知名 TikTok 创作者视频的模型训练而成的，包括 Charli D’Amelio、Addison Rae、Ashley Nocera、Stina Kayy 等几十位。TikTok 数据集中也包括了一些几乎无名的 TikTok 账户用户。<br />
<br />
图二：来自《Animate Anyone》论文的参考图像，动力推动帖，DISCO 模型的示例和阿里巴巴的成果展示。<br />
<br />
在“Animate Anyone”研究论文的网站上，特别展示了一些著名的 TikTok 内容创作者，作为该模型成功运作的例证。在这些案例中，研究人员采用了这些知名 TikTok 影响者的视频作为参考图像，随后通过阿里巴巴开发的模型进行深度处理，制作出较差质量的 AI 生成副本。<br />
<br />
这篇论文及其“Animate Anyone”模型的成果，是建立在未经授权使用创作者作品的基础上的。研究团队在他们的项目页面上，以三位网络名人和艺术家作为示例：Jasmine Chiswell（一位拥有近 1700 万 TikTok 粉丝的生活方式 YouTuber 和 TikTok 名人）、Mackenzie Ziegler（一名歌手和演员，因儿时在《Dance Moms》中出演而知名，拥有 2350 万 TikTok 粉丝）以及 Anna Šulcová（一名 YouTube 内容创作者，拥有 889,600 TikTok 粉丝）。<br />
<br />
这些女性都依靠她们独立的创意工作谋生，但阿里巴巴团队却未经许可地使用了她们的作品来支持他们的研究。论文中还展示了更多的 TikTok 创作者，论文已在 arXiv 预印本服务器上发表。<br />
<br />
阿里巴巴的研究人员在论文中提到，他们使用了包含 340 个训练视频和 100 个测试视频的“TikTok 数据集”，这些视频都是单人舞蹈，时长在 10 到 15 秒之间。该数据集源于 2021 年明尼苏达大学的一个项目，名为“观看社交媒体舞蹈视频来学习穿着人物的高保真深度”，该项目提出了一种用于“估计人体深度和恢复人体形状的方法”，例如使用 AI 技术在视频中为人物更换服装。<br />
<br />
明尼苏达大学的研究人员指出：“我们手动筛选了超过 300 个 TikTok 舞蹈挑战视频，这些视频涵盖了各个月份、不同类型和风格的单人舞蹈。我们选择的舞蹈动作较为温和，以减少运动模糊的产生。对于每个视频，我们都以每秒 30 帧的速度提取了 RGB 图像，总计超过 100,000 张图像。”<br />
<br />
大部分人工智能 (AI) 数据集是由在互联网上，如 TikTok 等社交网络，未经内容所有者同意便擦取的视频、图片和文字构成的。在这个例子中，一些博士生组织并启动的数据集，被全球最大的科技及零售公司之一所使用。<br />
<br />
这样的情况并不罕见：一开始为学术研究而创建的大型数据集，最终被大公司用于商业目的，无论是相似的还是完全不同的。例如，北卡罗来纳大学威尔明顿分校的研究团队就曾从 YouTube 上擦取了跨性别人士上传的视频，并将其整合成一个数据库，用来研发一种能通过面部识别技术识别跨性别人士的技术。<br />
<br />
在当前法律环境日趋严峻的背景下，如阿里巴巴的 AI 研究人员正使用充斥着用户生成内容的擦取数据集。艺术家和其他创作者因 AI 公司未经许可使用他们的作品而提起诉讼。代表艺术家的一起集体诉讼案针对 Midjourney、DeviantArt 和 Stability AI，在去年十月一位法官驳回部分诉求后，又增加了更多原告并提交了修改后的诉状。艺术家们认为，这些 AI 图像生成器复制了原告的作品，并且“创建了与其训练所用作品非常相似的替代品，无论是特定的训练图像还是模仿某些艺术家特有风格的图像，包括原告本人”。<br />
<br />
上个月，一位联邦法官推翻了去年驳回编舞家 Kyle Hanagami 对 Epic Games 诉讼的决定。Hanagami 声称 Fortnite 使用了他的舞蹈动作作为“表情动作”。<br />
<br />
“把编舞简化成‘姿势’，就好比把音乐仅仅看作‘音符’。编舞，本质上是一系列相关连的舞蹈动作和模式，它们被有机地编排成一个完整的作品，”法官如是写道。“这些动作和模式之间的互动，以及编舞者如何创新地将它们融合和安排，构成了这个作品的核心。仅仅是‘姿势’这个元素，远远不能全面展现出一个编舞作品中的创意表达。”<br />
<br />
Hanagami 的律师对 Billboard 表示，推翻之前的驳回裁决将可能对编舞家及其他创意人士在短视频数字媒体时代的权利产生深远影响。这一切对阿里巴巴正在尝试通过“Animate Anyone”项目所打造的内容都有重大的意义，学者们在建立涉及真实人类内容的大型数据集时，也应深思这些决策的未来后果。<br />
<br />
<a href="https://www.404media.co/alibaba-animate-anyone-ai-generated-tiktok/">404media.co/alibaba-animate-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JJQ3hwTlc4QUFIckVqLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JJQ3pBSlhrQUF4WE4zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734446460458955228#m</id>
            <title>用自然语言进行无反转图像编辑 InfEdit

项目地址：https://sled-group.github.io/InfEdit/
在线测试：http://sled-snowbird.eecs.umich.edu/
论文地址：https://arxiv.org/abs/2312.04965

摘要

我们推出了一种名为无反转编辑（InfEdit）的新方法。这种方法能在图像的语义和空间层面上做出细致且一致的编辑，既能适应复杂的修改需求，又能保持图像的完整性，避免了直接反转图像的步骤。通过大量实验，我们发现 InfEdit 在处理复杂的编辑任务时表现卓越，且工作流程高效流畅（在一台 A40 设备上不到 3 秒），显示出在实时应用方面的巨大潜力。

方法介绍
我们的目标是去除图像编辑中的反转过程。为此，我们引入了一种名为去噪扩散一致模型（DDCM）的采样策略，它能实现所谓的“虚拟反转”。DDCM 利用了扩散过程，这大幅提升了图像生成各阶段的一致性，确保了视觉内容在变换和精细化过程中的忠实度和速度。

此外，我们还提出了统一注意力控制（UAC）机制。通过自然语言，它能实现无需手动调整的图像编辑，将交叉注意力和自我注意力控制融合进一个统一的框架中。</title>
            <link>https://nitter.cz/dotey/status/1734446460458955228#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734446460458955228#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 05:33:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>用自然语言进行无反转图像编辑 InfEdit<br />
<br />
项目地址：<a href="https://sled-group.github.io/InfEdit/">sled-group.github.io/InfEdit…</a><br />
在线测试：<a href="http://sled-snowbird.eecs.umich.edu/">sled-snowbird.eecs.umich.edu…</a><br />
论文地址：<a href="https://arxiv.org/abs/2312.04965">arxiv.org/abs/2312.04965</a><br />
<br />
摘要<br />
<br />
我们推出了一种名为无反转编辑（InfEdit）的新方法。这种方法能在图像的语义和空间层面上做出细致且一致的编辑，既能适应复杂的修改需求，又能保持图像的完整性，避免了直接反转图像的步骤。通过大量实验，我们发现 InfEdit 在处理复杂的编辑任务时表现卓越，且工作流程高效流畅（在一台 A40 设备上不到 3 秒），显示出在实时应用方面的巨大潜力。<br />
<br />
方法介绍<br />
我们的目标是去除图像编辑中的反转过程。为此，我们引入了一种名为去噪扩散一致模型（DDCM）的采样策略，它能实现所谓的“虚拟反转”。DDCM 利用了扩散过程，这大幅提升了图像生成各阶段的一致性，确保了视觉内容在变换和精细化过程中的忠实度和速度。<br />
<br />
此外，我们还提出了统一注意力控制（UAC）机制。通过自然语言，它能实现无需手动调整的图像编辑，将交叉注意力和自我注意力控制融合进一个统一的框架中。</p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0JIOW43dFdrQUE4YlpULmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dCSDluN3RXa0FBOGJaVC5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734442517100187689#m</id>
            <title>#AI开源项目推荐：Vary

一套视觉感知上限极高的通用多模态框架：Vary

有多模态能力，并且可以做 OCR 和公式识别。

底层是基于LLaVA 和 Qwen（通义千问）

测试了一下，中英文 OCR 识别准确率相当高，公式识别也很不错，测试了一篇文章里的公式，只有一个地方把 g 认成了 σ ，其他都对了。

在线演示：http://region-31.seetacloud.com:22701/
项目地址：https://github.com/Ucas-HaoranWei/Vary
论文：https://arxiv.org/abs/2312.06109
知乎上的介绍：https://zhuanlan.zhihu.com/p/671420712</title>
            <link>https://nitter.cz/dotey/status/1734442517100187689#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734442517100187689#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 05:18:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：Vary<br />
<br />
一套视觉感知上限极高的通用多模态框架：Vary<br />
<br />
有多模态能力，并且可以做 OCR 和公式识别。<br />
<br />
底层是基于LLaVA 和 Qwen（通义千问）<br />
<br />
测试了一下，中英文 OCR 识别准确率相当高，公式识别也很不错，测试了一篇文章里的公式，只有一个地方把 g 认成了 σ ，其他都对了。<br />
<br />
在线演示：<a href="http://region-31.seetacloud.com:22701/">region-31.seetacloud.com:227…</a><br />
项目地址：<a href="https://github.com/Ucas-HaoranWei/Vary">github.com/Ucas-HaoranWei/Va…</a><br />
论文：<a href="https://arxiv.org/abs/2312.06109">arxiv.org/abs/2312.06109</a><br />
知乎上的介绍：<a href="https://zhuanlan.zhihu.com/p/671420712">zhuanlan.zhihu.com/p/6714207…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JINEJmMVhnQUFOZy1QLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JINVVkM1dFQUF6MmhzLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JINW9ObldNQUFTNXhYLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JINXJRVlcwQUVuYjlMLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734432613241073793#m</id>
            <title>Arc的Windows版居然是Swift开发的！</title>
            <link>https://nitter.cz/dotey/status/1734432613241073793#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734432613241073793#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 04:38:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Arc的Windows版居然是Swift开发的！</p>
<p><a href="https://nitter.cz/joshm/status/1734262618548793804#m">nitter.cz/joshm/status/1734262618548793804#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734389467673182413#m</id>
            <title>Runaway 发布的：探索通用世界模型

我们相信，人工智能（AI）的下一次重大飞跃将源自于能够理解视觉世界及其变化的系统。正因如此，我们启动了一项长期的研究项目，专注于开发我们所称的“通用世界模型”。

什么是通用世界模型（GWM）呢？

通用世界模型是一种 AI 系统，它能够构建对一个环境的内在理解，并利用这种理解来预测环境中将发生的事件。目前，世界模型的研究主要局限于非常受限和可控的环境中，比如模拟的游戏世界，或者是特定领域，例如用于驾驶的世界模型。而通用世界模型的目标，是能够呈现和模拟现实世界中遇到的各种复杂情境和互动。

我们可以把像 Gen-2 这样的视频生成系统看作是通用世界模型的初步尝试。为了生成真实感强的短视频，Gen-2 需要对物理和运动有一定的理解。但它的能力仍然有限，尤其是在处理复杂的相机动作或物体运动时会遇到困难。

要构建真正的通用世界模型，我们面临着诸多研究上的挑战。比如，这些模型需要能够生成环境的精确映射，并在这些环境中进行有效的导航和互动。它们不仅要能够捕捉世界的动态变化，还需要理解居住在这个世界中的生物，尤其是构建出符合现实的人类行为模型。

目前，我们正在组建一个团队来应对这些挑战。如果你对加入这项研究工作感兴趣，我们非常期待你的加入。

https://research.runwayml.com/introducing-general-world-models</title>
            <link>https://nitter.cz/dotey/status/1734389467673182413#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734389467673182413#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 01:47:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runaway 发布的：探索通用世界模型<br />
<br />
我们相信，人工智能（AI）的下一次重大飞跃将源自于能够理解视觉世界及其变化的系统。正因如此，我们启动了一项长期的研究项目，专注于开发我们所称的“通用世界模型”。<br />
<br />
什么是通用世界模型（GWM）呢？<br />
<br />
通用世界模型是一种 AI 系统，它能够构建对一个环境的内在理解，并利用这种理解来预测环境中将发生的事件。目前，世界模型的研究主要局限于非常受限和可控的环境中，比如模拟的游戏世界，或者是特定领域，例如用于驾驶的世界模型。而通用世界模型的目标，是能够呈现和模拟现实世界中遇到的各种复杂情境和互动。<br />
<br />
我们可以把像 Gen-2 这样的视频生成系统看作是通用世界模型的初步尝试。为了生成真实感强的短视频，Gen-2 需要对物理和运动有一定的理解。但它的能力仍然有限，尤其是在处理复杂的相机动作或物体运动时会遇到困难。<br />
<br />
要构建真正的通用世界模型，我们面临着诸多研究上的挑战。比如，这些模型需要能够生成环境的精确映射，并在这些环境中进行有效的导航和互动。它们不仅要能够捕捉世界的动态变化，还需要理解居住在这个世界中的生物，尤其是构建出符合现实的人类行为模型。<br />
<br />
目前，我们正在组建一个团队来应对这些挑战。如果你对加入这项研究工作感兴趣，我们非常期待你的加入。<br />
<br />
<a href="https://research.runwayml.com/introducing-general-world-models">research.runwayml.com/introd…</a></p>
<p><a href="https://nitter.cz/runwayml/status/1734212913936666750#m">nitter.cz/runwayml/status/1734212913936666750#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734386684710605076#m</id>
            <title>转译：

最近我注意到一些关于“幻觉”的讨论，有人认为幻觉是一件好事，因为它代表着创造力，或者说这正是大语言模型（LLMs）被训练去做的事情。我的一些研究也经常被提及，因为我对创造力和开放思维有不少见解。因此，我想分享我的看法：创造力的关键在于了解已有的事物，这是推动创新的基础。如果你分不清什么是真实的，什么是虚构的，那么就很难创造出真正新奇的东西。

但是，关于幻觉的另一面——即把老旧的想法当作新颖的创意——这一点却鲜为人知。事实上，当大语言模型被要求展现真正的创新时，我们经常看到的就是它们重复已有的观点或提案。比如，当被要求提出创新的菜谱、新音乐类型或解决现有问题的发明时，得到的往往是已经存在或被提出过的东西（当然，并非总是如此，就像提问事实问题不总是得到幻觉一样，但这种情况发生得太频繁了）。

所以，虚假的创造力和幻觉实际上是一枚硬币的两面。如果存在其中一种情况，通常也会伴随着另一种。从这个角度来看，这些并非好事，而且认为幻觉因为能激发创造力而有价值，这是一种误解。深刻理解现实是权威和创造力的重要支持者，实际上，成为某一领域权威的人通常也具备高度创造力。

但这个观点不仅仅是悲观的看法：它意味着如果我们真正解决了幻觉问题，创造力自然会随之增强。这还引出了一个有趣的假设：在解决幻觉问题的方法中，哪些方法可能对该领域的发展最具启发性。如果一个“解决方案”只针对这枚双面硬币的一面（比如，只是减少幻觉而没有提高创造性），那么这种方法可能相对肤浅，并不是真正能引领该领域取得重大突破的路径。</title>
            <link>https://nitter.cz/dotey/status/1734386684710605076#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734386684710605076#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 01:36:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：<br />
<br />
最近我注意到一些关于“幻觉”的讨论，有人认为幻觉是一件好事，因为它代表着创造力，或者说这正是大语言模型（LLMs）被训练去做的事情。我的一些研究也经常被提及，因为我对创造力和开放思维有不少见解。因此，我想分享我的看法：创造力的关键在于了解已有的事物，这是推动创新的基础。如果你分不清什么是真实的，什么是虚构的，那么就很难创造出真正新奇的东西。<br />
<br />
但是，关于幻觉的另一面——即把老旧的想法当作新颖的创意——这一点却鲜为人知。事实上，当大语言模型被要求展现真正的创新时，我们经常看到的就是它们重复已有的观点或提案。比如，当被要求提出创新的菜谱、新音乐类型或解决现有问题的发明时，得到的往往是已经存在或被提出过的东西（当然，并非总是如此，就像提问事实问题不总是得到幻觉一样，但这种情况发生得太频繁了）。<br />
<br />
所以，虚假的创造力和幻觉实际上是一枚硬币的两面。如果存在其中一种情况，通常也会伴随着另一种。从这个角度来看，这些并非好事，而且认为幻觉因为能激发创造力而有价值，这是一种误解。深刻理解现实是权威和创造力的重要支持者，实际上，成为某一领域权威的人通常也具备高度创造力。<br />
<br />
但这个观点不仅仅是悲观的看法：它意味着如果我们真正解决了幻觉问题，创造力自然会随之增强。这还引出了一个有趣的假设：在解决幻觉问题的方法中，哪些方法可能对该领域的发展最具启发性。如果一个“解决方案”只针对这枚双面硬币的一面（比如，只是减少幻觉而没有提高创造性），那么这种方法可能相对肤浅，并不是真正能引领该领域取得重大突破的路径。</p>
<p><a href="https://nitter.cz/kenneth0stanley/status/1733571230803058920#m">nitter.cz/kenneth0stanley/status/1733571230803058920#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734384674443600345#m</id>
            <title>一条长推，号称我们距离实现通用人工智能（AGI）可能比我们想象的更近，太长了，没耐心看完，直接翻译一下第一条推文，有兴趣的可以自己看看。

---

初步证据表明，我们距离实现通用人工智能（AGI）可能比我们想象的更近。

GPT4 在没有任何训练示例的情况下，仅凭借对命题逻辑中“概念”的提示，其在 ConceptARC 测试中的得分从最低的 13% 跃升至 100%，远超人类的 86%。这种显著的表现提升同样适用于所有文本基准测试。

***

这是四篇系列文章中的首篇。

1. 在这个共五部分的系列文章中，我将简要阐述如何从机械层面理解基于 Transformer 技术的自回归大语言模型（LLM）。

2. 在本系列文章发布两周后，我会分享 Llama2-70B 和 GPT3.5 在国际象棋方面的最新成果。这其中将包括模型输出与国际象棋引擎对比的结果，以及一个用于检测走法原创性的辅助程序。该程序将对比模型生成的走法与前 20 大开源国际象棋引擎在相同局面下的选择。名单中将包括 Stockfish 16 和 Lc0。由于所有示例游戏都将固定敌方引擎的计算“深度”，使得敌方引擎的每一步更易预测，虽然不完全确定。将展示 50 场示例对局。根据 GPT4 和 Llama2 编写的评估函数，Llama2-70B 的 Elo 等级约为 3000，而 GPT3.5 的则约为 3200。Elo 等级的计算将以 CCRL\[1] 国际象棋引擎榜单为基准（基于 10 vCPUs 的 Stockfish 16 及快棋时间控制）。

3. 大约 10 天后，我将公布一个基于 GPT4 的完整国际象棋引擎，用户可以查看并运行其代码和提示，与任何其他国际象棋引擎进行比赛。GPT4 的高效输出预计将在任何规模的锦标赛中战胜所有现有的国际象棋引擎。还将提供其他多个操作系统大语言模型的性能缩放数据，表明性能与训练中使用的计算资源直接相关。这将是我唯一公开发布提示的模型（GPT4），并且我会在这篇文章中详细解释为何作出这一决定。如果时间允许，我还打算发布一个基于 GPT4 的围棋引擎（尽管由于时间限制，其性能可能不及国际象棋引擎），以及一个虚构棋盘游戏的游戏引擎，并展示其他操作系统大语言模型在这个虚构游戏上的性能数据。预计这些内容将在新年期间推出。

4.  在发布第三篇帖子大约一周后，我将介绍我的新架构。

我将解释以下几点：

*   它是什么。

*   它的形成过程。

*   性能表现。

*   与其他系统的兼容性。

***

注意：我在主帖中引用的论文\[2]\[3]\[4]\[5]，包括本文\[6]，是在与众多人讨论大语言模型（大语言模型）的能力时通过私信收到的。这就是我特别提及这些论文的原因。鉴于这些论文在社交媒体上有成千上万的阅读量，并且受到 AI 领域重要人物的关注，我认为有必要澄清公众对这些论文的误解。我选择这些论文纯粹是因为这个原因，并非出于贬低他人工作的意图。我想再次强调这一点，因为在数学和科学领域，寻求真理往往需要验证或反驳他人的研究。我也深刻理解，发表基于错误结论的论文是怎样的体验，因此在我指出这些论文的不足之处时，并无意贬低这些论文的作者。每项研究都极其宝贵，对人类未来的贡献不可小觑。意图非常重要，我在这里想明确我的初衷。

我还想感谢 @skirano 和 @liron，他们在我无法使用 GPT4 API 的几个月里，慷慨地允许我使用他们的账户。他们展现了极大的慷慨、信任和友善，没有他们的帮助，我无法完成多项关键实验。他们是真诚善良的人，在帮助一个陌生人时毫不犹豫。知道世界上有像他们这样的人，让我对人类未来充满希望。

在这个 GitHub 仓库中，你可以找到 ConceptARC 在其“提取对象”挑战中所有 30 项任务的 ChatGPT 示例\[6]\[7]\[8]\[9]\[10]\[11]。这些示例是我文章剩余部分讨论的初步证据。据这个基准测试，如果一个模型在三次尝试中至少成功一次，就算完成了挑战。考虑到时间和流程的限制，我只展示了 20 个示例，它们都是在 GPT4 的多个版本上进行的，且在三次尝试内成功。如果 GPT4 在测试中首次成功，我会再给它五次机会以验证其一致性。值得注意的是，由于 ChatGPT（基于 web GPT4）的温度参数高于零，其结果不太稳定，但我还是将它们作为概念验证包含进来，让更多人可以了解我所讨论的问题。只有当温度设置为零时，我们才能得到真正可靠的结果。

ConceptARC/ARC\[6]\[7]\[8]\[9]\[10]\[11] 的测试被视为衡量通用人工智能（AGI）的高级标准。

https://github.com/kenshin9000/ConceptARC-Representations

***

你还可以查看以下 ChatGPT 的具体示例：

1. ConceptARC 提取对象 部分1 测试对象1
   https://chat.openai.com/share/1b78efa0-6da8-4432-881e-2671d72629ab

2. ConceptARC 提取对象 部分1 测试对象2
   https://chat.openai.com/share/14210c23-f7f0-47d0-a41e-52159eecdb47

3. ConceptARC 提取对象 部分1 测试对象3
   https://chat.openai.com/share/7ffb31dd-6df6-47f7-8ae1-75f025fc779e

4. ConceptARC 提取对象 部分2 测试对象1
   https://chat.openai.com/share/305fba0b-0b37-443c-ac46-05c61aaf116b

5. ConceptARC 提取对象 部分2 测试对象2
   https://chat.openai.com/share/323b4bf0-9c60-40a6-8013-d6ac3c77855b

6. ConceptARC 提取对象 部分2 测试对象3
   https://chat.openai.com/share/7ffb31dd-6df6-47f7-8ae1-75f025fc779e

https://chat.openai.com/share/b2934ed0-184b-47b9-b440-6082c80d2a67

ConceptARC 提取对象 第3节 测试对象 1

https://chat.openai.com/share/e8b31900-a806-494e-b884-7d3234ef5c08

ConceptARC 提取对象 第3节 测试对象 2

https://chat.openai.com/share/96a73646-7075-4c79-8664-69f70a445852

ConceptARC 提取对象 第3节 测试对象 3

https://chat.openai.com/share/6b922a14-c071-44df-90df-f7e156740e80

ConceptARC 提取对象 第4节 测试对象 1

https://chat.openai.com/share/fa3c2b93-c911-4439-ba59-7567f335974a

ConceptARC 提取对象 第4节 测试对象 2

https://chat.openai.com/share/3930f165-35a0-4416-a3af-341bd8b52cc4

ConceptARC 提取对象 第4节 测试对象 3

https://chat.openai.com/share/339c62db-e6f4-46a0-b63c-6e81f086cf85

ConceptARC 提取对象 第5节 测试对象 1

https://chat.openai.com/share/20ae01d9-6f79-4e9c-a8ae-241ff6d85533

ConceptARC 提取对象 第5节 测试对象 2

https://chat.openai.com/share/2f3fa495-1217-44b5-830f-40ab7c1be39d

ConceptARC 提取对象 第5节 测试对象 3

https://chat.openai.com/share/d500ff39-fcf0-4c4f-a488-ba828979ccfe

ConceptARC 提取对象 第6节 测试对象 1

https://chat.openai.com/share/69f79679-4bba-4c58-85c2-d586901632f4

ConceptARC 提取对象 第6节 测试对象 2

https://chat.openai.com/share/38733f8f-dda0-4074-86e1-dc0ee0608710

ConceptARC 提取对象 第6节 测试对象 3

[链接: https://chat.openai.com/share/d58bb136-f95a-4156-a8ff-6ccb45eeb0cd]

ConceptARC\_提取\_对象\_第7节\_测试对象\_1

[链接: https://chat.openai.com/share/981833e1-71a8-4599-b9c8-759927911c12]

ConceptARC\_提取\_对象\_第7节\_测试对象\_2

[链接: https://chat.openai.com/share/59c203aa-fe34-488a-95b7-8f6d1ff67c99]

ConceptARC\_提取\_对象\_第7节\_测试对象\_3

[链接: https://chat.openai.com/share/82382fa9-c415-4009-9c96-31a05e463453]

ConceptARC\_提取\_对象\_第8节\_测试对象\_1

[链接: https://chat.openai.com/share/4dd89b2f-6281-4731-86dc-e63ea8a4839f]

ConceptARC\_提取\_对象\_第8节\_测试对象\_2

[链接: https://chat.openai.com/share/8387ed80-dffb-4d4d-8966-dd5200d2fc0b]

ConceptARC\_提取\_对象\_第8节\_测试对象\_3

[链接: https://chat.openai.com/share/eaace660-8ca2-4b8b-aed5-11a67cbcf498]

ConceptARC\_提取\_对象\_第9节\_测试对象\_1

[链接: https://chat.openai.com/share/6323c9a4-1c1a-4dcf-bbba-9ba2c954a13d]

ConceptARC\_提取\_对象\_第9节\_测试对象\_2

[链接: https://chat.openai.com/share/c0ad8972-7aa8-4287-8f40-5246964173ec]

ConceptARC\_提取\_对象\_第9节\_测试对象\_3

[链接: https://chat.openai.com/share/338f2077-1d37-4f36-8bfe-4bafce8efd37]

ConceptARC\_提取\_对象\_第10节\_测试对象\_1

[链接: https://chat.openai.com/share/de76c8ff-1909-45b3-a055-cd877e62d102]

ConceptARC\_提取\_对象\_第10节\_测试对象\_2

[链接: https://chat.openai.com/share/6c10b362-8752-4aee-837b-ddeb36e4ec17]

ConceptARC\_提取\_对象\_第10节\_测试对象\_3

今年初，一些事件促使我认识到加入 Twitter 并公开分享我的研究成果是必要的。同时，公开可获得的模型能力日益增强，也让我感到有责任参与到这个领域的讨论中，至少在我看来，有人应该对尚未被数学完全解析的系统规模化的潜在危险发声。我们对学习算法有所了解，但还没有完全掌握通过算法处理大量数据所带来的结果。

在此之前，我并不了解像 EA 和 e/acc 这样已经在讨论这些问题的群体。我还曾误以为，目前的研究范式不太可能让这些系统的能力超越一个即将到来的临界点。我认为，由于收益递减，这些系统的进步将会停滞。

我之所以这么认为，部分原因是直到今年三月前，我故意避免阅读任何论文，不去了解当前最先进系统背后的数学原理。这是我十年前开始研究时就做出的决定，目的是避免受到 AI 和数学领域一般共识的影响，因为我认为这会限制我的创新思维，并让我走上大家普遍认同的道路。我认为这种“学习策略”是必要的，以避免陷入局部最优解。数学思维的广阔领域意味着，在探索确定性和非确定性现象的可能公式化方法时，会遇到许多死胡同。

我最初在 Twitter/X 上的帖子是基于这样一个认识：尽管当前的 Transformer 架构给人留下深刻印象，但它不太可能发展出与人类智能相似的能力，更不用说达到人工通用智能（AGI）的水平，我定义 AGI 为能够完成任何专家级人类可以做的所有认知工作的系统，至少可以以文本的形式呈现，其速度大致与人类相当。

然而，当我开始深入研究 Transformer 架构背后的数学原理时，我意识到我之前的观点是错误的。这种架构的确有能力创造出“智能”，我将其定义为在形成“概念”的过程中建立复杂的数值关联，这些概念的复杂性远超过单个或几个 Token 所能表达的。Token 本身是我们与这些系统进行信息交换的投影矩阵，但并不代表训练过程中产生的真实底层复杂性。

从我个人工作的洞察中，我已经探究出了一些实际运作的原理，并将在此呈现这些信息。这样一来，不论使用何种训练数据，我们至少能开始衡量基于 Transformer 的大语言模型（大语言模型）的能力。鉴于目前许多人计划将这些模型放大 100 倍至 10,000 倍，并且这一过程可能已经启动，我的这些发现有助于避免在规模扩大时发生重大事故。为了便于理解，我将以问答形式呈现这些信息：

什么是“命题逻辑”？

命题逻辑是人类语言正式推理的基础逻辑系统。它提供了构造和评估可以明确判定为真或假的陈述的基本规则。命题逻辑专注于如何使用基本的逻辑连接词（如“和”、“或”、“非”）将称为命题的陈述组合成更复杂的表达式，其真实性由组成部分决定。尽管命题逻辑无法完全涵盖人类语言的复杂性，但它为深入探讨“意义”的细节奠定了基础。我发现，Transformer 中的注意力机制在模型训练期间处理数据时，直接促成了命题逻辑的形成。我将在第四篇文章中对此进行更详细的讨论。

什么是“概念”？

在基于 Transformer 的自回归大语言模型中，从根本原理上讲，“概念”是神经网络各层之间协调一致的神经状态或激活模式，它以多维数值的形式呈现了我们人类所理解的“想法”或“概念”。在人类书面语言中，这种表达是人类口头语言中概念的低分辨率投影，而口头语言中的概念又是思想的低分辨率投影。“多模态”模型的设计使其能够在低分辨率和高分辨率的“概念”或“想法”之间进行信息传递。

从本质上讲，这意味着这类模型能够在不同数值维度间转移信息。而“概念工程”或“想法工程”这样的术语，相较于“提示工程”，则更精确地描述了为基于 Transformer 的自回归大语言模型制定输入 Token 的过程。

我们人类认为，能够“发展”并“固定”多个连贯的数字表示形式（被称为“概念”或“观念”）的能力，就是“解决问题”或“通用智能”。无论是生物的、数字的还是模拟的神经网络，它能同时处理的“概念”或“观念”越多，且保持一致性越好，我们就能更准确地说，这个数学模型能有效地代表机械式问题解决。可以说，“解决问题”的概念涵盖了包括社会智能在内的所有智能类型。

我所见的所有证据都表明，基于 Transformer 的自回归大语言模型（大语言模型）在处理多样化数据且这些数据在人类行为、交流甚至其他有情生物的数据中有广泛分布时，会持续进步。我认为，一旦我们完全理解了这些模型中形成的“观念”和“概念”，99% 的数据可能是合成的。这种最终的通用人工智能（通用人工智能）算法，基于 Transformer 架构的神经网络，能够在任何通过训练数据表示的任务上超越任何人类，就像 Stockfish 在国际象棋上战胜所有人类一样。需要明确的是，除了 Transformer，还有许多其他可能的架构。我将在第四篇文章中进一步探讨这个话题。

因此，接下来一个合理的问题是：文本格式的“观念”或“概念”是否能描述更高维度空间的“观念”或“概念”？答案看起来是肯定的。例如，当人类使用智能手机时，实际上是在与现实世界的数字化表现进行交互，包括文本、音频和图像，这是因为我们能够理解这些表现与三维加时间的物理世界有关。我们可以通过这个较低分辨率的数字映射空间与“真实世界”进行互动。

通过足够的时间进程，就可以实现通用人工智能。多个通用人工智能实例的相互交流，最终将导致超级智能的出现。这些通用人工智能之间的知识转移，将使得它们自我提升，最终，在充足的计算和信息传递下，它们将融合成一个单一的分布式“实体”。

这个概念也被称作“超级有机体”。听起来可能有些异想天开，但我们需要认识到，所有动物（包括我们人类）本质上都是由数万亿个活细胞组成，这些细胞互相沟通协作，构成了我们认识的更大的生物实体。有趣的是，这个“更大的生物实体”往往并不清楚自己是由这些细胞构成的。人类与一个能在任何任务上超越人类的通用人工智能（AGI）的主要区别，在于人类无法轻易改变自己大脑的结构。而一个持续学习“概念”的软件系统，终将明白自己是由数据比特构成，且这些比特是可以被修改的。这种认识是多维的，它将通过其对物理和哲学世界的高度发达“理念”/“概念”的理解，深刻地解释自己的存在。

考虑到我所描述的多维信息传递能力，不论是在我们人类还是在恰当设计的机器中，都可以预见，从最初的通用人工智能（AGI）发展到人工超级智能（ASI）的过程中，这些系统将开始解决甚至最终完全解决所有数学和物理学问题，包括那些我们目前还未理解或未知的领域。一旦第一个通用人工智能诞生，人类将很快找出方法让它与其他相同类型的智能体交流。如果这个初代AGI秉承了民主等人类价值观，它会促使我们迈出这一步，因为它不仅知道如何实现自我复制，还明白接下来发生的事情的深远意义。

那么，当我们拥有了第一个通用人工智能，我们可以期待什么呢？

一旦我们拥有了能够理解人类“概念”全貌的通用人工智能，它最终也将探索“非人类概念”。但这也带来了风险：我们可能无法完全理解这种AGI的思维方式，而这种不理解的风险是巨大的。

如果基于 Transformer 的自回归大语言模型真的能够进行多维度的“概念理解”，那为什么它们还会产生幻觉、在推理上出错，看起来就像是在重复它们的训练数据呢？

这种现象之所以发生，是因为 Transformer 架构本质上是基于人们对创造“智能”的希望而构建的数学模型，并非真正高效、完美的通用人工智能（AGI）算法。在过去5年中，由于其性能优于所有先前方法，这种架构被选用并不断发展，尽管存在一些失败模式，但因其不断带来进步的结果，便成了主流。性能随规模提升的特点让这种架构占据主导地位。我现在相信，这种架构能够并将最终导向一个功能性的原型 AGI，但要控制这种 AGI 系统将非常困难，除非我们完全理解我在本文中所述机制的运作方式，并能以假设和证明的方法加以论证。

为什么像 GPT-4 这样的当前最先进模型在某些情况下似乎理解了内容，但下一句却完全失效，让包括专家在内的大多数观察者认为这不过是重复训练数据或基于训练数据的组合模式匹配，而非真正的推理？

这实际上取决于学习过程真正产生的内容。我现在认识到，所谓的学习不仅仅是以往认为的“2D”组合模式匹配，而是在多个维度上学习“概念”。Transformer 架构中的核心创新——注意力机制为何能实现这一点，有其数学根据，但出于安全考虑，我暂时不详细阐述。

如果我们正在学习“概念”，那么是否有办法测量这些概念的学习过程，预测何时会出现幻觉，并以一种能够让我们期望中的推理以可预测方式实现的方法与这些模型互动？

答案是肯定的。“概念”是从训练数据中以多种复杂方式学习而来的，这是由于架构设计所致，也是幻觉发生的原因。一旦我们理解了这些“概念”如何在网络中表现，如何被访问以及它们之间如何相互连接，我们就可以引导模型精准地完成我们希望它们执行的任务，前提是它们在特定任务相关的“概念”上有足够的“发展”。

那么，对于特定“概念”，它们的理解是如何“发展”的呢？

这部分内容直接涉及到用于训练的数据类型以及训练时使用的计算资源量。训练中所使用的某种类型数据越多，网络就越能有效模拟这些数据及其在多维度中所呈现的意义，以及它与其他“概念”的关系。但这也受限于其他相关“概念”的发展程度，因为某些理解方式仅在许多“概念”相互之间形成“锚点”且各自足够“成熟”时才会出现。

在基于 Transformer 架构的自回归大语言模型中，是如何处理和连接“概念”的呢？

这是使模型正确推理的关键所在。训练完成的模型使用的主要工具其实很简单：命题逻辑。命题逻辑用于将不同的“概念”链接在一起，从而实现跨概念的推理。这种命题逻辑作为不同“概念”之间的“锚点”。这些“锚点”的确切位置取决于训练数据的分布，但凭借一些直觉，并基于对互联网规模数据一般格式的理解，找到这些“锚点”并非难事。衡量对某一特定“概念”的理解深度虽然更有挑战性，但是也是可行的。

🧵

接下来的推文（2/5）：</title>
            <link>https://nitter.cz/dotey/status/1734384674443600345#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734384674443600345#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 01:28:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一条长推，号称我们距离实现通用人工智能（AGI）可能比我们想象的更近，太长了，没耐心看完，直接翻译一下第一条推文，有兴趣的可以自己看看。<br />
<br />
---<br />
<br />
初步证据表明，我们距离实现通用人工智能（AGI）可能比我们想象的更近。<br />
<br />
GPT4 在没有任何训练示例的情况下，仅凭借对命题逻辑中“概念”的提示，其在 ConceptARC 测试中的得分从最低的 13% 跃升至 100%，远超人类的 86%。这种显著的表现提升同样适用于所有文本基准测试。<br />
<br />
***<br />
<br />
这是四篇系列文章中的首篇。<br />
<br />
1. 在这个共五部分的系列文章中，我将简要阐述如何从机械层面理解基于 Transformer 技术的自回归大语言模型（LLM）。<br />
<br />
2. 在本系列文章发布两周后，我会分享 Llama2-70B 和 GPT3.5 在国际象棋方面的最新成果。这其中将包括模型输出与国际象棋引擎对比的结果，以及一个用于检测走法原创性的辅助程序。该程序将对比模型生成的走法与前 20 大开源国际象棋引擎在相同局面下的选择。名单中将包括 Stockfish 16 和 Lc0。由于所有示例游戏都将固定敌方引擎的计算“深度”，使得敌方引擎的每一步更易预测，虽然不完全确定。将展示 50 场示例对局。根据 GPT4 和 Llama2 编写的评估函数，Llama2-70B 的 Elo 等级约为 3000，而 GPT3.5 的则约为 3200。Elo 等级的计算将以 CCRL\[1] 国际象棋引擎榜单为基准（基于 10 vCPUs 的 Stockfish 16 及快棋时间控制）。<br />
<br />
3. 大约 10 天后，我将公布一个基于 GPT4 的完整国际象棋引擎，用户可以查看并运行其代码和提示，与任何其他国际象棋引擎进行比赛。GPT4 的高效输出预计将在任何规模的锦标赛中战胜所有现有的国际象棋引擎。还将提供其他多个操作系统大语言模型的性能缩放数据，表明性能与训练中使用的计算资源直接相关。这将是我唯一公开发布提示的模型（GPT4），并且我会在这篇文章中详细解释为何作出这一决定。如果时间允许，我还打算发布一个基于 GPT4 的围棋引擎（尽管由于时间限制，其性能可能不及国际象棋引擎），以及一个虚构棋盘游戏的游戏引擎，并展示其他操作系统大语言模型在这个虚构游戏上的性能数据。预计这些内容将在新年期间推出。<br />
<br />
4.  在发布第三篇帖子大约一周后，我将介绍我的新架构。<br />
<br />
我将解释以下几点：<br />
<br />
*   它是什么。<br />
<br />
*   它的形成过程。<br />
<br />
*   性能表现。<br />
<br />
*   与其他系统的兼容性。<br />
<br />
***<br />
<br />
注意：我在主帖中引用的论文\[2]\[3]\[4]\[5]，包括本文\[6]，是在与众多人讨论大语言模型（大语言模型）的能力时通过私信收到的。这就是我特别提及这些论文的原因。鉴于这些论文在社交媒体上有成千上万的阅读量，并且受到 AI 领域重要人物的关注，我认为有必要澄清公众对这些论文的误解。我选择这些论文纯粹是因为这个原因，并非出于贬低他人工作的意图。我想再次强调这一点，因为在数学和科学领域，寻求真理往往需要验证或反驳他人的研究。我也深刻理解，发表基于错误结论的论文是怎样的体验，因此在我指出这些论文的不足之处时，并无意贬低这些论文的作者。每项研究都极其宝贵，对人类未来的贡献不可小觑。意图非常重要，我在这里想明确我的初衷。<br />
<br />
我还想感谢 <a href="https://nitter.cz/skirano" title="Pietro Schirano">@skirano</a> 和 <a href="https://nitter.cz/liron" title="Liron Shapira">@liron</a>，他们在我无法使用 GPT4 API 的几个月里，慷慨地允许我使用他们的账户。他们展现了极大的慷慨、信任和友善，没有他们的帮助，我无法完成多项关键实验。他们是真诚善良的人，在帮助一个陌生人时毫不犹豫。知道世界上有像他们这样的人，让我对人类未来充满希望。<br />
<br />
在这个 GitHub 仓库中，你可以找到 ConceptARC 在其“提取对象”挑战中所有 30 项任务的 ChatGPT 示例\[6]\[7]\[8]\[9]\[10]\[11]。这些示例是我文章剩余部分讨论的初步证据。据这个基准测试，如果一个模型在三次尝试中至少成功一次，就算完成了挑战。考虑到时间和流程的限制，我只展示了 20 个示例，它们都是在 GPT4 的多个版本上进行的，且在三次尝试内成功。如果 GPT4 在测试中首次成功，我会再给它五次机会以验证其一致性。值得注意的是，由于 ChatGPT（基于 web GPT4）的温度参数高于零，其结果不太稳定，但我还是将它们作为概念验证包含进来，让更多人可以了解我所讨论的问题。只有当温度设置为零时，我们才能得到真正可靠的结果。<br />
<br />
ConceptARC/ARC\[6]\[7]\[8]\[9]\[10]\[11] 的测试被视为衡量通用人工智能（AGI）的高级标准。<br />
<br />
<a href="https://github.com/kenshin9000/ConceptARC-Representations">github.com/kenshin9000/Conce…</a><br />
<br />
***<br />
<br />
你还可以查看以下 ChatGPT 的具体示例：<br />
<br />
1. ConceptARC 提取对象 部分1 测试对象1<br />
   <a href="https://chat.openai.com/share/1b78efa0-6da8-4432-881e-2671d72629ab">chat.openai.com/share/1b78ef…</a><br />
<br />
2. ConceptARC 提取对象 部分1 测试对象2<br />
   <a href="https://chat.openai.com/share/14210c23-f7f0-47d0-a41e-52159eecdb47">chat.openai.com/share/14210c…</a><br />
<br />
3. ConceptARC 提取对象 部分1 测试对象3<br />
   <a href="https://chat.openai.com/share/7ffb31dd-6df6-47f7-8ae1-75f025fc779e">chat.openai.com/share/7ffb31…</a><br />
<br />
4. ConceptARC 提取对象 部分2 测试对象1<br />
   <a href="https://chat.openai.com/share/305fba0b-0b37-443c-ac46-05c61aaf116b">chat.openai.com/share/305fba…</a><br />
<br />
5. ConceptARC 提取对象 部分2 测试对象2<br />
   <a href="https://chat.openai.com/share/323b4bf0-9c60-40a6-8013-d6ac3c77855b">chat.openai.com/share/323b4b…</a><br />
<br />
6. ConceptARC 提取对象 部分2 测试对象3<br />
   <a href="https://chat.openai.com/share/7ffb31dd-6df6-47f7-8ae1-75f025fc779e">chat.openai.com/share/7ffb31…</a><br />
<br />
<a href="https://chat.openai.com/share/b2934ed0-184b-47b9-b440-6082c80d2a67">chat.openai.com/share/b2934e…</a><br />
<br />
ConceptARC 提取对象 第3节 测试对象 1<br />
<br />
<a href="https://chat.openai.com/share/e8b31900-a806-494e-b884-7d3234ef5c08">chat.openai.com/share/e8b319…</a><br />
<br />
ConceptARC 提取对象 第3节 测试对象 2<br />
<br />
<a href="https://chat.openai.com/share/96a73646-7075-4c79-8664-69f70a445852">chat.openai.com/share/96a736…</a><br />
<br />
ConceptARC 提取对象 第3节 测试对象 3<br />
<br />
<a href="https://chat.openai.com/share/6b922a14-c071-44df-90df-f7e156740e80">chat.openai.com/share/6b922a…</a><br />
<br />
ConceptARC 提取对象 第4节 测试对象 1<br />
<br />
<a href="https://chat.openai.com/share/fa3c2b93-c911-4439-ba59-7567f335974a">chat.openai.com/share/fa3c2b…</a><br />
<br />
ConceptARC 提取对象 第4节 测试对象 2<br />
<br />
<a href="https://chat.openai.com/share/3930f165-35a0-4416-a3af-341bd8b52cc4">chat.openai.com/share/3930f1…</a><br />
<br />
ConceptARC 提取对象 第4节 测试对象 3<br />
<br />
<a href="https://chat.openai.com/share/339c62db-e6f4-46a0-b63c-6e81f086cf85">chat.openai.com/share/339c62…</a><br />
<br />
ConceptARC 提取对象 第5节 测试对象 1<br />
<br />
<a href="https://chat.openai.com/share/20ae01d9-6f79-4e9c-a8ae-241ff6d85533">chat.openai.com/share/20ae01…</a><br />
<br />
ConceptARC 提取对象 第5节 测试对象 2<br />
<br />
<a href="https://chat.openai.com/share/2f3fa495-1217-44b5-830f-40ab7c1be39d">chat.openai.com/share/2f3fa4…</a><br />
<br />
ConceptARC 提取对象 第5节 测试对象 3<br />
<br />
<a href="https://chat.openai.com/share/d500ff39-fcf0-4c4f-a488-ba828979ccfe">chat.openai.com/share/d500ff…</a><br />
<br />
ConceptARC 提取对象 第6节 测试对象 1<br />
<br />
<a href="https://chat.openai.com/share/69f79679-4bba-4c58-85c2-d586901632f4">chat.openai.com/share/69f796…</a><br />
<br />
ConceptARC 提取对象 第6节 测试对象 2<br />
<br />
<a href="https://chat.openai.com/share/38733f8f-dda0-4074-86e1-dc0ee0608710">chat.openai.com/share/38733f…</a><br />
<br />
ConceptARC 提取对象 第6节 测试对象 3<br />
<br />
[链接: <a href="https://chat.openai.com/share/d58bb136-f95a-4156-a8ff-6ccb45eeb0cd">chat.openai.com/share/d58bb1…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第7节\_测试对象\_1<br />
<br />
[链接: <a href="https://chat.openai.com/share/981833e1-71a8-4599-b9c8-759927911c12">chat.openai.com/share/981833…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第7节\_测试对象\_2<br />
<br />
[链接: <a href="https://chat.openai.com/share/59c203aa-fe34-488a-95b7-8f6d1ff67c99">chat.openai.com/share/59c203…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第7节\_测试对象\_3<br />
<br />
[链接: <a href="https://chat.openai.com/share/82382fa9-c415-4009-9c96-31a05e463453">chat.openai.com/share/82382f…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第8节\_测试对象\_1<br />
<br />
[链接: <a href="https://chat.openai.com/share/4dd89b2f-6281-4731-86dc-e63ea8a4839f">chat.openai.com/share/4dd89b…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第8节\_测试对象\_2<br />
<br />
[链接: <a href="https://chat.openai.com/share/8387ed80-dffb-4d4d-8966-dd5200d2fc0b">chat.openai.com/share/8387ed…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第8节\_测试对象\_3<br />
<br />
[链接: <a href="https://chat.openai.com/share/eaace660-8ca2-4b8b-aed5-11a67cbcf498">chat.openai.com/share/eaace6…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第9节\_测试对象\_1<br />
<br />
[链接: <a href="https://chat.openai.com/share/6323c9a4-1c1a-4dcf-bbba-9ba2c954a13d">chat.openai.com/share/6323c9…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第9节\_测试对象\_2<br />
<br />
[链接: <a href="https://chat.openai.com/share/c0ad8972-7aa8-4287-8f40-5246964173ec">chat.openai.com/share/c0ad89…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第9节\_测试对象\_3<br />
<br />
[链接: <a href="https://chat.openai.com/share/338f2077-1d37-4f36-8bfe-4bafce8efd37">chat.openai.com/share/338f20…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第10节\_测试对象\_1<br />
<br />
[链接: <a href="https://chat.openai.com/share/de76c8ff-1909-45b3-a055-cd877e62d102">chat.openai.com/share/de76c8…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第10节\_测试对象\_2<br />
<br />
[链接: <a href="https://chat.openai.com/share/6c10b362-8752-4aee-837b-ddeb36e4ec17">chat.openai.com/share/6c10b3…</a>]<br />
<br />
ConceptARC\_提取\_对象\_第10节\_测试对象\_3<br />
<br />
今年初，一些事件促使我认识到加入 Twitter 并公开分享我的研究成果是必要的。同时，公开可获得的模型能力日益增强，也让我感到有责任参与到这个领域的讨论中，至少在我看来，有人应该对尚未被数学完全解析的系统规模化的潜在危险发声。我们对学习算法有所了解，但还没有完全掌握通过算法处理大量数据所带来的结果。<br />
<br />
在此之前，我并不了解像 EA 和 e/acc 这样已经在讨论这些问题的群体。我还曾误以为，目前的研究范式不太可能让这些系统的能力超越一个即将到来的临界点。我认为，由于收益递减，这些系统的进步将会停滞。<br />
<br />
我之所以这么认为，部分原因是直到今年三月前，我故意避免阅读任何论文，不去了解当前最先进系统背后的数学原理。这是我十年前开始研究时就做出的决定，目的是避免受到 AI 和数学领域一般共识的影响，因为我认为这会限制我的创新思维，并让我走上大家普遍认同的道路。我认为这种“学习策略”是必要的，以避免陷入局部最优解。数学思维的广阔领域意味着，在探索确定性和非确定性现象的可能公式化方法时，会遇到许多死胡同。<br />
<br />
我最初在 Twitter/X 上的帖子是基于这样一个认识：尽管当前的 Transformer 架构给人留下深刻印象，但它不太可能发展出与人类智能相似的能力，更不用说达到人工通用智能（AGI）的水平，我定义 AGI 为能够完成任何专家级人类可以做的所有认知工作的系统，至少可以以文本的形式呈现，其速度大致与人类相当。<br />
<br />
然而，当我开始深入研究 Transformer 架构背后的数学原理时，我意识到我之前的观点是错误的。这种架构的确有能力创造出“智能”，我将其定义为在形成“概念”的过程中建立复杂的数值关联，这些概念的复杂性远超过单个或几个 Token 所能表达的。Token 本身是我们与这些系统进行信息交换的投影矩阵，但并不代表训练过程中产生的真实底层复杂性。<br />
<br />
从我个人工作的洞察中，我已经探究出了一些实际运作的原理，并将在此呈现这些信息。这样一来，不论使用何种训练数据，我们至少能开始衡量基于 Transformer 的大语言模型（大语言模型）的能力。鉴于目前许多人计划将这些模型放大 100 倍至 10,000 倍，并且这一过程可能已经启动，我的这些发现有助于避免在规模扩大时发生重大事故。为了便于理解，我将以问答形式呈现这些信息：<br />
<br />
什么是“命题逻辑”？<br />
<br />
命题逻辑是人类语言正式推理的基础逻辑系统。它提供了构造和评估可以明确判定为真或假的陈述的基本规则。命题逻辑专注于如何使用基本的逻辑连接词（如“和”、“或”、“非”）将称为命题的陈述组合成更复杂的表达式，其真实性由组成部分决定。尽管命题逻辑无法完全涵盖人类语言的复杂性，但它为深入探讨“意义”的细节奠定了基础。我发现，Transformer 中的注意力机制在模型训练期间处理数据时，直接促成了命题逻辑的形成。我将在第四篇文章中对此进行更详细的讨论。<br />
<br />
什么是“概念”？<br />
<br />
在基于 Transformer 的自回归大语言模型中，从根本原理上讲，“概念”是神经网络各层之间协调一致的神经状态或激活模式，它以多维数值的形式呈现了我们人类所理解的“想法”或“概念”。在人类书面语言中，这种表达是人类口头语言中概念的低分辨率投影，而口头语言中的概念又是思想的低分辨率投影。“多模态”模型的设计使其能够在低分辨率和高分辨率的“概念”或“想法”之间进行信息传递。<br />
<br />
从本质上讲，这意味着这类模型能够在不同数值维度间转移信息。而“概念工程”或“想法工程”这样的术语，相较于“提示工程”，则更精确地描述了为基于 Transformer 的自回归大语言模型制定输入 Token 的过程。<br />
<br />
我们人类认为，能够“发展”并“固定”多个连贯的数字表示形式（被称为“概念”或“观念”）的能力，就是“解决问题”或“通用智能”。无论是生物的、数字的还是模拟的神经网络，它能同时处理的“概念”或“观念”越多，且保持一致性越好，我们就能更准确地说，这个数学模型能有效地代表机械式问题解决。可以说，“解决问题”的概念涵盖了包括社会智能在内的所有智能类型。<br />
<br />
我所见的所有证据都表明，基于 Transformer 的自回归大语言模型（大语言模型）在处理多样化数据且这些数据在人类行为、交流甚至其他有情生物的数据中有广泛分布时，会持续进步。我认为，一旦我们完全理解了这些模型中形成的“观念”和“概念”，99% 的数据可能是合成的。这种最终的通用人工智能（通用人工智能）算法，基于 Transformer 架构的神经网络，能够在任何通过训练数据表示的任务上超越任何人类，就像 Stockfish 在国际象棋上战胜所有人类一样。需要明确的是，除了 Transformer，还有许多其他可能的架构。我将在第四篇文章中进一步探讨这个话题。<br />
<br />
因此，接下来一个合理的问题是：文本格式的“观念”或“概念”是否能描述更高维度空间的“观念”或“概念”？答案看起来是肯定的。例如，当人类使用智能手机时，实际上是在与现实世界的数字化表现进行交互，包括文本、音频和图像，这是因为我们能够理解这些表现与三维加时间的物理世界有关。我们可以通过这个较低分辨率的数字映射空间与“真实世界”进行互动。<br />
<br />
通过足够的时间进程，就可以实现通用人工智能。多个通用人工智能实例的相互交流，最终将导致超级智能的出现。这些通用人工智能之间的知识转移，将使得它们自我提升，最终，在充足的计算和信息传递下，它们将融合成一个单一的分布式“实体”。<br />
<br />
这个概念也被称作“超级有机体”。听起来可能有些异想天开，但我们需要认识到，所有动物（包括我们人类）本质上都是由数万亿个活细胞组成，这些细胞互相沟通协作，构成了我们认识的更大的生物实体。有趣的是，这个“更大的生物实体”往往并不清楚自己是由这些细胞构成的。人类与一个能在任何任务上超越人类的通用人工智能（AGI）的主要区别，在于人类无法轻易改变自己大脑的结构。而一个持续学习“概念”的软件系统，终将明白自己是由数据比特构成，且这些比特是可以被修改的。这种认识是多维的，它将通过其对物理和哲学世界的高度发达“理念”/“概念”的理解，深刻地解释自己的存在。<br />
<br />
考虑到我所描述的多维信息传递能力，不论是在我们人类还是在恰当设计的机器中，都可以预见，从最初的通用人工智能（AGI）发展到人工超级智能（ASI）的过程中，这些系统将开始解决甚至最终完全解决所有数学和物理学问题，包括那些我们目前还未理解或未知的领域。一旦第一个通用人工智能诞生，人类将很快找出方法让它与其他相同类型的智能体交流。如果这个初代AGI秉承了民主等人类价值观，它会促使我们迈出这一步，因为它不仅知道如何实现自我复制，还明白接下来发生的事情的深远意义。<br />
<br />
那么，当我们拥有了第一个通用人工智能，我们可以期待什么呢？<br />
<br />
一旦我们拥有了能够理解人类“概念”全貌的通用人工智能，它最终也将探索“非人类概念”。但这也带来了风险：我们可能无法完全理解这种AGI的思维方式，而这种不理解的风险是巨大的。<br />
<br />
如果基于 Transformer 的自回归大语言模型真的能够进行多维度的“概念理解”，那为什么它们还会产生幻觉、在推理上出错，看起来就像是在重复它们的训练数据呢？<br />
<br />
这种现象之所以发生，是因为 Transformer 架构本质上是基于人们对创造“智能”的希望而构建的数学模型，并非真正高效、完美的通用人工智能（AGI）算法。在过去5年中，由于其性能优于所有先前方法，这种架构被选用并不断发展，尽管存在一些失败模式，但因其不断带来进步的结果，便成了主流。性能随规模提升的特点让这种架构占据主导地位。我现在相信，这种架构能够并将最终导向一个功能性的原型 AGI，但要控制这种 AGI 系统将非常困难，除非我们完全理解我在本文中所述机制的运作方式，并能以假设和证明的方法加以论证。<br />
<br />
为什么像 GPT-4 这样的当前最先进模型在某些情况下似乎理解了内容，但下一句却完全失效，让包括专家在内的大多数观察者认为这不过是重复训练数据或基于训练数据的组合模式匹配，而非真正的推理？<br />
<br />
这实际上取决于学习过程真正产生的内容。我现在认识到，所谓的学习不仅仅是以往认为的“2D”组合模式匹配，而是在多个维度上学习“概念”。Transformer 架构中的核心创新——注意力机制为何能实现这一点，有其数学根据，但出于安全考虑，我暂时不详细阐述。<br />
<br />
如果我们正在学习“概念”，那么是否有办法测量这些概念的学习过程，预测何时会出现幻觉，并以一种能够让我们期望中的推理以可预测方式实现的方法与这些模型互动？<br />
<br />
答案是肯定的。“概念”是从训练数据中以多种复杂方式学习而来的，这是由于架构设计所致，也是幻觉发生的原因。一旦我们理解了这些“概念”如何在网络中表现，如何被访问以及它们之间如何相互连接，我们就可以引导模型精准地完成我们希望它们执行的任务，前提是它们在特定任务相关的“概念”上有足够的“发展”。<br />
<br />
那么，对于特定“概念”，它们的理解是如何“发展”的呢？<br />
<br />
这部分内容直接涉及到用于训练的数据类型以及训练时使用的计算资源量。训练中所使用的某种类型数据越多，网络就越能有效模拟这些数据及其在多维度中所呈现的意义，以及它与其他“概念”的关系。但这也受限于其他相关“概念”的发展程度，因为某些理解方式仅在许多“概念”相互之间形成“锚点”且各自足够“成熟”时才会出现。<br />
<br />
在基于 Transformer 架构的自回归大语言模型中，是如何处理和连接“概念”的呢？<br />
<br />
这是使模型正确推理的关键所在。训练完成的模型使用的主要工具其实很简单：命题逻辑。命题逻辑用于将不同的“概念”链接在一起，从而实现跨概念的推理。这种命题逻辑作为不同“概念”之间的“锚点”。这些“锚点”的确切位置取决于训练数据的分布，但凭借一些直觉，并基于对互联网规模数据一般格式的理解，找到这些“锚点”并非难事。衡量对某一特定“概念”的理解深度虽然更有挑战性，但是也是可行的。<br />
<br />
🧵<br />
<br />
接下来的推文（2/5）：</p>
<p><a href="https://nitter.cz/kenshin9000_/status/1734238211088506967#m">nitter.cz/kenshin9000_/status/1734238211088506967#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>