<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746415487041294519#m</id>
            <title>R to @dotey: 原文：https://spectrum.ieee.org/global-robotic-brain
译文：https://baoyu.io/translations/robot/the-global-project-to-make-a-general-robotic-brain</title>
            <link>https://nitter.cz/dotey/status/1746415487041294519#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746415487041294519#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 06:14:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原文：<a href="https://spectrum.ieee.org/global-robotic-brain">spectrum.ieee.org/global-rob…</a><br />
译文：<a href="https://baoyu.io/translations/robot/the-global-project-to-make-a-general-robotic-brain">baoyu.io/translations/robot/…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746415313153896511#m</id>
            <title>R to @dotey: 尽管这些任务对人类而言非常基础，但对通用机器人来说却是一大挑战。如果没有明确展示“在……之间”、“靠近”和“在……上方”等概念的机器人演示数据，即使是在众多不同机器人数据上进行训练的系统也难以理解这些指令的含义。通过整合视觉 - 语言模型中的大规模网络知识，我们的整体系统能够解决这类问题。它从网络规模的训练中提取出语义概念（本案例中为空间关系），并从多机器人的 RT-X 数据中学习物理行为（比如拾起和移动物体）。出乎意料的是，我们发现引入多机器人数据使得谷歌机器人在这类任务上的泛化能力提高了三倍。这一结果表明，多机器人 RT-X 数据不仅有助于获取各种物理技能，还能更好地将这些技能与视觉 - 语言模型中的语义和符号知识结合起来。这种结合赋予了机器人一定程度的常识，未来可能使机器人能够理解像“给我拿早餐”这样复杂而微妙的用户指令，并执行相应的行动。

RT-X 的未来步伐
RT-X 项目向我们展示了机器人学习社区齐心协力的巨大潜力。通过这种跨机构合作，我们成功构建了一个包含多样化机器人数据的数据集，并在多个机器人上进行了全面评估——这是任何单独机构所无法实现的。鉴于机器人学社区无法仅靠网络数据进行训练，我们必须自行创造训练数据。我们期待更多研究者能够向 RT-X 数据库 贡献他们的数据，并加入这一合作行列。我们还计划提供工具、模型和基础设施，支持跨不同载体的研究。我们的目标不仅仅是实现实验室间数据的共享，更希望 RT-X 能成为推动数据标准、可复用模型以及新技术和算法发展的协作平台。

我们早期的成果预示着大型跨载体机器人模型将如何革新这一领域。正如大语言模型精通各种基于语言的任务，未来我们或许可以用一个统一的基础模型来处理多种现实世界中的机器人任务。可能通过微调或直接对一个预训练的基础模型进行指令输入，就能实现新的机器人技能。就像你可以直接让 ChatGPT 讲故事而不需要先对其进行特定故事的训练，类似地，你可以让一个机器人在蛋糕上写“生日快乐”，而无需先教它如何使用裱花袋或手写文字的样式。当然，为了让这些模型拥有更广泛的通用能力，我们还需要做更多的研究。目前我们的实验主要集中在单臂、两指夹持器进行的简单操控任务上。

随着更多实验室投身于跨载体研究，我们希望推动单一神经网络控制多种机器人的边界。这些进步可能包括利用来自虚拟环境的多样化模拟数据、处理具有不同手臂或手指数量的机器人、使用各种传感器（如深度相机和触觉感应器）以及整合操控和移动行为。RT-X 已经为这些工作铺平了道路，但最激动人心的技术进展还在前方等待着我们。

这只是开始。我们希望通过这一步，共同开启机器人学的新未来：在这个未来里，通用的机器人大脑能够驱动任何机器人，从全球所有机器人共享的数据中受益。这样，我们将一同塑造一个机器人技术的新纪元，其中高度通用的机器人大脑能为世界各地的各种机器人提供智能支持。</title>
            <link>https://nitter.cz/dotey/status/1746415313153896511#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746415313153896511#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 06:13:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>尽管这些任务对人类而言非常基础，但对通用机器人来说却是一大挑战。如果没有明确展示“在……之间”、“靠近”和“在……上方”等概念的机器人演示数据，即使是在众多不同机器人数据上进行训练的系统也难以理解这些指令的含义。通过整合视觉 - 语言模型中的大规模网络知识，我们的整体系统能够解决这类问题。它从网络规模的训练中提取出语义概念（本案例中为空间关系），并从多机器人的 RT-X 数据中学习物理行为（比如拾起和移动物体）。出乎意料的是，我们发现引入多机器人数据使得谷歌机器人在这类任务上的泛化能力提高了三倍。这一结果表明，多机器人 RT-X 数据不仅有助于获取各种物理技能，还能更好地将这些技能与视觉 - 语言模型中的语义和符号知识结合起来。这种结合赋予了机器人一定程度的常识，未来可能使机器人能够理解像“给我拿早餐”这样复杂而微妙的用户指令，并执行相应的行动。<br />
<br />
RT-X 的未来步伐<br />
RT-X 项目向我们展示了机器人学习社区齐心协力的巨大潜力。通过这种跨机构合作，我们成功构建了一个包含多样化机器人数据的数据集，并在多个机器人上进行了全面评估——这是任何单独机构所无法实现的。鉴于机器人学社区无法仅靠网络数据进行训练，我们必须自行创造训练数据。我们期待更多研究者能够向 RT-X 数据库 贡献他们的数据，并加入这一合作行列。我们还计划提供工具、模型和基础设施，支持跨不同载体的研究。我们的目标不仅仅是实现实验室间数据的共享，更希望 RT-X 能成为推动数据标准、可复用模型以及新技术和算法发展的协作平台。<br />
<br />
我们早期的成果预示着大型跨载体机器人模型将如何革新这一领域。正如大语言模型精通各种基于语言的任务，未来我们或许可以用一个统一的基础模型来处理多种现实世界中的机器人任务。可能通过微调或直接对一个预训练的基础模型进行指令输入，就能实现新的机器人技能。就像你可以直接让 ChatGPT 讲故事而不需要先对其进行特定故事的训练，类似地，你可以让一个机器人在蛋糕上写“生日快乐”，而无需先教它如何使用裱花袋或手写文字的样式。当然，为了让这些模型拥有更广泛的通用能力，我们还需要做更多的研究。目前我们的实验主要集中在单臂、两指夹持器进行的简单操控任务上。<br />
<br />
随着更多实验室投身于跨载体研究，我们希望推动单一神经网络控制多种机器人的边界。这些进步可能包括利用来自虚拟环境的多样化模拟数据、处理具有不同手臂或手指数量的机器人、使用各种传感器（如深度相机和触觉感应器）以及整合操控和移动行为。RT-X 已经为这些工作铺平了道路，但最激动人心的技术进展还在前方等待着我们。<br />
<br />
这只是开始。我们希望通过这一步，共同开启机器人学的新未来：在这个未来里，通用的机器人大脑能够驱动任何机器人，从全球所有机器人共享的数据中受益。这样，我们将一同塑造一个机器人技术的新纪元，其中高度通用的机器人大脑能为世界各地的各种机器人提供智能支持。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746415263950438452#m</id>
            <title>R to @dotey: RT-X 模型利用特定机器人手臂执行不同任务的图像或文本描述，产生一系列具体动作，使任何机器人手臂都能够执行这些任务。我们收集了来自世界各地机器人实验室的众多机器人执行的各种任务数据，构建了一个开源数据集，目的是训练机器人执行通用而有用的任务。CHRIS PHILPOT

为了评估互联网获取的智能与多机器人数据的结合效果，我们使用谷歌的移动操纵机器人对 RT-X 模型进行了测试。我们对其进行了最具挑战性的泛化基准测试。机器人不仅要识别物体并成功操控它们，还要能够理解复杂的文本命令，并通过逻辑推断来响应，这要求综合文本和图像中的信息。这种综合能力是人类成为出色的通用解决者的关键之一。我们是否能赋予机器人至少一些这样的能力？

我们进行了两轮评估。首先，我们使用了一个基准模型，排除了所有不涉及谷歌机器人的泛化多机器人 RT-X 数据。谷歌机器人专用的数据集实际上是 RT-X 数据集中最大的部分，包含超过 100,000 个演示。因此，这些其他多机器人数据是否真的有助于本案例还是一个未知数。随后，我们包含所有这些多机器人数据再次进行了测试。

在最具挑战性的评估场景之一中，谷歌机器人需要完成一个涉及空间关系推理的任务（“把苹果移动到罐头和橙子之间”）；在另一个任务中，它需要解决基本的数学问题（“把一个物体放在写有‘2+3’答案的纸上”）。这些挑战旨在测试机器人的推理能力和得出结论的关键技能。

在这个案例中，推理能力（比如理解“在……之间”和“在……上方”这样的概念）来源于视觉 - 语言模型训练时包含的大规模网络数据。而使得这些推理成果能够在机器人行为上得到应用——也就是发出正确的指令，驱动机器人手臂移动到指定方向——的能力，则是通过在 RT-X 的多机器人数据上训练得来的。例如，在下面的视频中，我们让机器人完成了一个它训练数据中没有包含的任务。</title>
            <link>https://nitter.cz/dotey/status/1746415263950438452#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746415263950438452#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 06:13:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>RT-X 模型利用特定机器人手臂执行不同任务的图像或文本描述，产生一系列具体动作，使任何机器人手臂都能够执行这些任务。我们收集了来自世界各地机器人实验室的众多机器人执行的各种任务数据，构建了一个开源数据集，目的是训练机器人执行通用而有用的任务。CHRIS PHILPOT<br />
<br />
为了评估互联网获取的智能与多机器人数据的结合效果，我们使用谷歌的移动操纵机器人对 RT-X 模型进行了测试。我们对其进行了最具挑战性的泛化基准测试。机器人不仅要识别物体并成功操控它们，还要能够理解复杂的文本命令，并通过逻辑推断来响应，这要求综合文本和图像中的信息。这种综合能力是人类成为出色的通用解决者的关键之一。我们是否能赋予机器人至少一些这样的能力？<br />
<br />
我们进行了两轮评估。首先，我们使用了一个基准模型，排除了所有不涉及谷歌机器人的泛化多机器人 RT-X 数据。谷歌机器人专用的数据集实际上是 RT-X 数据集中最大的部分，包含超过 100,000 个演示。因此，这些其他多机器人数据是否真的有助于本案例还是一个未知数。随后，我们包含所有这些多机器人数据再次进行了测试。<br />
<br />
在最具挑战性的评估场景之一中，谷歌机器人需要完成一个涉及空间关系推理的任务（“把苹果移动到罐头和橙子之间”）；在另一个任务中，它需要解决基本的数学问题（“把一个物体放在写有‘2+3’答案的纸上”）。这些挑战旨在测试机器人的推理能力和得出结论的关键技能。<br />
<br />
在这个案例中，推理能力（比如理解“在……之间”和“在……上方”这样的概念）来源于视觉 - 语言模型训练时包含的大规模网络数据。而使得这些推理成果能够在机器人行为上得到应用——也就是发出正确的指令，驱动机器人手臂移动到指定方向——的能力，则是通过在 RT-X 的多机器人数据上训练得来的。例如，在下面的视频中，我们让机器人完成了一个它训练数据中没有包含的任务。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDY0MTUyMjAwNDAzMDY2ODgvcHUvaW1nLzdRdTNleDhXVTNTcVZxM18uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746415183654752586#m</id>
            <title>R to @dotey: 打造能进行推理的机器人

受到我们成功整合多种机器人类型数据的启发，我们进一步探索了如何把这些数据融入到具备更深层次推理能力的系统中。仅凭机器人数据来学习复杂的语义推理是非常困难的。尽管机器人数据能展现一系列物理能力，但更复杂的任务，比如“把苹果从罐子和橙子之间移开”，还需要理解图像中物体间的语义联系、基本常识，以及其他与机器人物理能力无直接关联的象征性知识。

因此，我们决定加入另一个庞大的数据源：互联网规模的图像和文本数据。我们使用了一种已经擅长理解自然语言与图像之间联系的任务的大型视觉语言模型。这种模型与 ChatGPT 或Bard等公众可用的模型相似。这些模型被训练用来对包含图像的提示做出文本回应，以解决视觉问答、图像标注等开放式视觉理解任务。我们发现，只需将这些模型训练为对机器人指令（如“把香蕉放在盘子上”）作出机器人动作的回应，就能轻松将它们适配到机器人控制中。我们将这种方法应用在了 RT-X 合作项目中的机器人数据上。</title>
            <link>https://nitter.cz/dotey/status/1746415183654752586#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746415183654752586#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 06:13:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>打造能进行推理的机器人<br />
<br />
受到我们成功整合多种机器人类型数据的启发，我们进一步探索了如何把这些数据融入到具备更深层次推理能力的系统中。仅凭机器人数据来学习复杂的语义推理是非常困难的。尽管机器人数据能展现一系列物理能力，但更复杂的任务，比如“把苹果从罐子和橙子之间移开”，还需要理解图像中物体间的语义联系、基本常识，以及其他与机器人物理能力无直接关联的象征性知识。<br />
<br />
因此，我们决定加入另一个庞大的数据源：互联网规模的图像和文本数据。我们使用了一种已经擅长理解自然语言与图像之间联系的任务的大型视觉语言模型。这种模型与 ChatGPT 或Bard等公众可用的模型相似。这些模型被训练用来对包含图像的提示做出文本回应，以解决视觉问答、图像标注等开放式视觉理解任务。我们发现，只需将这些模型训练为对机器人指令（如“把香蕉放在盘子上”）作出机器人动作的回应，就能轻松将它们适配到机器人控制中。我们将这种方法应用在了 RT-X 合作项目中的机器人数据上。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0R5RFVUQVc0QUFzUmZNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746415034161324052#m</id>
            <title>R to @dotey: 如何打造一个全能型机器人

相比之下，人类在这类学习上要更加擅长。我们的大脑只需少量练习，就能适应身体结构的变化，比如当我们使用工具、骑自行车或开车时。换句话说，虽然我们的身体结构发生变化，但大脑能迅速适应。RT-X 正在努力在机器人领域实现类似的目标：使得一个深度学习网络能够控制多种不同的机器人类型，这一能力被称为跨类型控制。关键问题是，一个接受了大量不同机器人数据训练的深度学习网络是否能够掌握“操作”所有这些机器人的技能，哪怕这些机器人在外观、物理特性和能力上有很大差异。如果可行，这种方法可能会大幅提升机器人学习领域对大数据的利用。

RT-X 项目的规模宏大，这是出于必要。该项目的数据集目前已包含近百万次的机器人测试，涵盖了 22 种类型的机器人，包括市场上一些最常用的机械臂。这些机器人能够执行包括拾取放置物体、组装及专门任务如电缆布线在内的多种行为。总共大约有 500 种不同的技能和成千上万种不同物体的交互。这是迄今为止最大的开源真实机器人行为数据集。

出乎意料的是，我们发现可以用相对简单的机器学习方法来处理这些多机器人数据，前提是我们使用了大型的神经网络模型和大规模的数据集。借鉴目前大型语言模型（例如 ChatGPT）所用的类似模型，我们成功训练出了一种机器人控制算法，这种算法不需要为实现跨类型控制而特别设计任何特性。就像人类可以用同一颗大脑驾驶汽车或骑自行车一样，一个在 RT-X 数据集上训练过的模型，能够简单地通过机器人自身相机的观察来识别它正在控制的机器人类型。比如，当模型通过相机看到一个 UR10 工业臂时，它会发送适合 UR10 的指令；而当看到一个成本较低的 WidowX 爱好者臂时，则会做出相应的操作。

为了验证我们模型的能力，参与 RT-X 项目合作的五个实验室各自使用我们的模型，与他们为各自机器人独立开发的最佳控制系统进行了对比测试。每个实验室的测试涉及其研究中使用的任务，例如拾取和移动物品、开门以及通过夹子布线等。令人称奇的是，这个统一的模型在各项任务上的表现都超过了各实验室自行开发的最佳方法，平均成功率高出约 50%。

尽管这个结果可能令人惊讶，但我们发现，RT-X 控制器可以利用其他机器人在不同环境下的丰富经验，来提高在各种设置中的鲁棒性。即使在同一个实验室内，每次机器人执行任务时，都会遇到略有不同的情况，因此借鉴其他机器人在不同情况下的经验，有助于 RT-X 控制器应对自然变化和边缘情况。以下是这些任务范围的几个示例：</title>
            <link>https://nitter.cz/dotey/status/1746415034161324052#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746415034161324052#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 06:12:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如何打造一个全能型机器人<br />
<br />
相比之下，人类在这类学习上要更加擅长。我们的大脑只需少量练习，就能适应身体结构的变化，比如当我们使用工具、骑自行车或开车时。换句话说，虽然我们的身体结构发生变化，但大脑能迅速适应。RT-X 正在努力在机器人领域实现类似的目标：使得一个深度学习网络能够控制多种不同的机器人类型，这一能力被称为跨类型控制。关键问题是，一个接受了大量不同机器人数据训练的深度学习网络是否能够掌握“操作”所有这些机器人的技能，哪怕这些机器人在外观、物理特性和能力上有很大差异。如果可行，这种方法可能会大幅提升机器人学习领域对大数据的利用。<br />
<br />
RT-X 项目的规模宏大，这是出于必要。该项目的数据集目前已包含近百万次的机器人测试，涵盖了 22 种类型的机器人，包括市场上一些最常用的机械臂。这些机器人能够执行包括拾取放置物体、组装及专门任务如电缆布线在内的多种行为。总共大约有 500 种不同的技能和成千上万种不同物体的交互。这是迄今为止最大的开源真实机器人行为数据集。<br />
<br />
出乎意料的是，我们发现可以用相对简单的机器学习方法来处理这些多机器人数据，前提是我们使用了大型的神经网络模型和大规模的数据集。借鉴目前大型语言模型（例如 ChatGPT）所用的类似模型，我们成功训练出了一种机器人控制算法，这种算法不需要为实现跨类型控制而特别设计任何特性。就像人类可以用同一颗大脑驾驶汽车或骑自行车一样，一个在 RT-X 数据集上训练过的模型，能够简单地通过机器人自身相机的观察来识别它正在控制的机器人类型。比如，当模型通过相机看到一个 UR10 工业臂时，它会发送适合 UR10 的指令；而当看到一个成本较低的 WidowX 爱好者臂时，则会做出相应的操作。<br />
<br />
为了验证我们模型的能力，参与 RT-X 项目合作的五个实验室各自使用我们的模型，与他们为各自机器人独立开发的最佳控制系统进行了对比测试。每个实验室的测试涉及其研究中使用的任务，例如拾取和移动物品、开门以及通过夹子布线等。令人称奇的是，这个统一的模型在各项任务上的表现都超过了各实验室自行开发的最佳方法，平均成功率高出约 50%。<br />
<br />
尽管这个结果可能令人惊讶，但我们发现，RT-X 控制器可以利用其他机器人在不同环境下的丰富经验，来提高在各种设置中的鲁棒性。即使在同一个实验室内，每次机器人执行任务时，都会遇到略有不同的情况，因此借鉴其他机器人在不同情况下的经验，有助于 RT-X 控制器应对自然变化和边缘情况。以下是这些任务范围的几个示例：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0R5RE5DelhvQUF1NV9DLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0R5RE5DeVdvQUFUTWZYLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0R5RE5DdldvQUFqdzRWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746414853311377455#m</id>
            <title>ieee 的一篇文章：构建全球通用机器人大脑的宏伟项目——34 个实验室携手共同解决机器人学习难题

生成式 AI 革命 的显著成果体现在 ChatGPT、Midjourney 等工具上。这一革命的核心，是基于这样一个简单的思路：使用一个庞大的神经网络，用互联网上海量的数据进行训练，然后用它来响应广泛的用户需求。大型语言模型（LLM）可以回答问题、编写代码、创作诗歌，而图像生成系统则能够创造出逼真的洞穴壁画或当代艺术作品。

那么，为什么这些令人惊叹的 AI 技术还没有转化为像科幻小说中那样有用且广泛应用的机器人？为什么还没有能够整理桌面、折叠衣服、做早餐的机器人呢？

遗憾的是，成功的生成式 AI 模式——即使用海量互联网数据训练的大型模型——并不容易应用到机器人学领域。互联网上的数据并不像文本和图像那样充满了机器人交互信息。机器人需要基于机器人数据来学习，而这些数据通常是实验室研究人员针对特定任务缓慢且费力地创造的。尽管机器人学习算法取得了巨大进步，但在缺乏充足数据的情况下，我们仍无法让机器人在实验室之外执行真实世界的任务（比如制作早餐）。目前最引人注目的成果，通常只限于在单个实验室、单一机器人上实现，且仅涉及几种行为。

如果每台机器人的能力都受限于手动教授它执行新任务所需的时间和努力，那么如果我们能将多个机器人的经验汇集在一起，让新机器人能够同时从所有机器人那里学习，会怎样呢？我们决定尝试这种方法。2023 年，我们在谷歌和加州大学伯克利分校的实验室联手北美、欧洲和亚洲的其他 32 个机器人学实验室共同启动了RT-X 项目，目标是汇集数据、资源和代码，努力实现通用机器人的梦想。

这是我们从这项努力的第一阶段中学到的经验。</title>
            <link>https://nitter.cz/dotey/status/1746414853311377455#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746414853311377455#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 06:12:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ieee 的一篇文章：构建全球通用机器人大脑的宏伟项目——34 个实验室携手共同解决机器人学习难题<br />
<br />
生成式 AI 革命 的显著成果体现在 ChatGPT、Midjourney 等工具上。这一革命的核心，是基于这样一个简单的思路：使用一个庞大的神经网络，用互联网上海量的数据进行训练，然后用它来响应广泛的用户需求。大型语言模型（LLM）可以回答问题、编写代码、创作诗歌，而图像生成系统则能够创造出逼真的洞穴壁画或当代艺术作品。<br />
<br />
那么，为什么这些令人惊叹的 AI 技术还没有转化为像科幻小说中那样有用且广泛应用的机器人？为什么还没有能够整理桌面、折叠衣服、做早餐的机器人呢？<br />
<br />
遗憾的是，成功的生成式 AI 模式——即使用海量互联网数据训练的大型模型——并不容易应用到机器人学领域。互联网上的数据并不像文本和图像那样充满了机器人交互信息。机器人需要基于机器人数据来学习，而这些数据通常是实验室研究人员针对特定任务缓慢且费力地创造的。尽管机器人学习算法取得了巨大进步，但在缺乏充足数据的情况下，我们仍无法让机器人在实验室之外执行真实世界的任务（比如制作早餐）。目前最引人注目的成果，通常只限于在单个实验室、单一机器人上实现，且仅涉及几种行为。<br />
<br />
如果每台机器人的能力都受限于手动教授它执行新任务所需的时间和努力，那么如果我们能将多个机器人的经验汇集在一起，让新机器人能够同时从所有机器人那里学习，会怎样呢？我们决定尝试这种方法。2023 年，我们在谷歌和加州大学伯克利分校的实验室联手北美、欧洲和亚洲的其他 32 个机器人学实验室共同启动了RT-X 项目，目标是汇集数据、资源和代码，努力实现通用机器人的梦想。<br />
<br />
这是我们从这项努力的第一阶段中学到的经验。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0R5QzhiLVd3QUFrNkFQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746397564943905102#m</id>
            <title>R to @dotey: 官网下架了，公众号还在👍🏻
https://x.com/xuejc1988/status/1746396174272299461?s=20</title>
            <link>https://nitter.cz/dotey/status/1746397564943905102#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746397564943905102#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 05:03:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>官网下架了，公众号还在👍🏻<br />
<a href="https://x.com/xuejc1988/status/1746396174272299461?s=20">x.com/xuejc1988/status/17463…</a></p>
<p><a href="https://nitter.cz/xuejc1988/status/1746396174272299461#m">nitter.cz/xuejc1988/status/1746396174272299461#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746396696597164057#m</id>
            <title>R to @dotey: 电子书的GitHub Repo：
https://github.com/SurviveSJTU/SurviveSJTUManual</title>
            <link>https://nitter.cz/dotey/status/1746396696597164057#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746396696597164057#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 04:59:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>电子书的GitHub Repo：<br />
<a href="https://github.com/SurviveSJTU/SurviveSJTUManual">github.com/SurviveSJTU/Survi…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0NDM5NDA0NDk0MjUyNDQxNi9VTHZYbDVjej9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746386357902012698#m</id>
            <title>三联生活周刊文章｜无助的大学生，自发编了个“生存手册”
作者｜杨璐

《上海交通大学学生生存手册》是一本由上海交大毕业生自发撰写的，62页的小册子。这本册子的内容包括反思应试教育塑造的“失败的思维”、如何确立自己未来的目标和志向、如何看待科研团队和合作伙伴、如何选课、要不要出去打工以及偷懒的旁门左道。

作者告诉师弟师妹们，这本书并不是《逃课手册》《考前突击宝典》，而是希望同学们树立正确的人生观、价值观，帮助有志青年完善自我，实现内心的追求。手册里有很多针对大学生普遍困惑的金句。如：“如果一个人把政策评分作为自己的至高追求，那么他就是这个政策的牺牲品。”它还告诉师弟师妹们务必牢记：“大学四年留给你的是你的人生，在你毕业之时，那一串苍白的分数其实已经作废了。”

注：原文已经下架，只有截图了

《上海交通大学学生生存手册》PDF：http://www.houxiaodi.com/assets/misc/manual.pdf</title>
            <link>https://nitter.cz/dotey/status/1746386357902012698#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746386357902012698#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 04:18:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>三联生活周刊文章｜无助的大学生，自发编了个“生存手册”<br />
作者｜杨璐<br />
<br />
《上海交通大学学生生存手册》是一本由上海交大毕业生自发撰写的，62页的小册子。这本册子的内容包括反思应试教育塑造的“失败的思维”、如何确立自己未来的目标和志向、如何看待科研团队和合作伙伴、如何选课、要不要出去打工以及偷懒的旁门左道。<br />
<br />
作者告诉师弟师妹们，这本书并不是《逃课手册》《考前突击宝典》，而是希望同学们树立正确的人生观、价值观，帮助有志青年完善自我，实现内心的追求。手册里有很多针对大学生普遍困惑的金句。如：“如果一个人把政策评分作为自己的至高追求，那么他就是这个政策的牺牲品。”它还告诉师弟师妹们务必牢记：“大学四年留给你的是你的人生，在你毕业之时，那一串苍白的分数其实已经作废了。”<br />
<br />
注：原文已经下架，只有截图了<br />
<br />
《上海交通大学学生生存手册》PDF：<a href="http://www.houxiaodi.com/assets/misc/manual.pdf">houxiaodi.com/assets/misc/ma…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0R4bzZYeVdNQUlqWUN2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0R4bzdoOFdFQUFXcGFRLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0R4bzhYZFdJQUE3NkJjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746375080056074483#m</id>
            <title>牛逼👍</title>
            <link>https://nitter.cz/dotey/status/1746375080056074483#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746375080056074483#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 03:33:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>牛逼👍</p>
<p><a href="https://nitter.cz/NickADobos/status/1746344507749314904#m">nitter.cz/NickADobos/status/1746344507749314904#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746332978031083647#m</id>
            <title>R to @dotey: 对于能力强的模型，格式并没有那么重要，但是few-shot和CoT（链式思考）的作用无论是能力一般的模型还是能力强的模型，都是很有价值的。

我以前分享过一篇《如何写出高质量的 Prompt？》

将写提示词分成了几个阶段：

一、基础用法，直接输入你希望的指令。
就是你想让 AI 完成什么任务就自然语言写就完了，这基本上可以解决绝大部分问题

二、进阶用法，few-shot
提供一到多个示例，通过示例来让 GPT 按照你期望的格式输出

三、高级用法，链式思考（分多步做）+ 慢思考（打印每一步的结果）
就比如我的翻译Prompt，就是将翻译拆分成2-3步，并且打印每一步结果，得到较好质量的翻译

《如何写出高质量的 Prompt？》https://baoyu.io/blog/prompt-engineering/how-to-write-high-quality-prompt
《我试验了高级 AI 提示词的效果，结论：它们并不值得 [译]》https://baoyu.io/translations/prompt-engineering/premium-ai-prompts</title>
            <link>https://nitter.cz/dotey/status/1746332978031083647#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746332978031083647#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 00:46:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>对于能力强的模型，格式并没有那么重要，但是few-shot和CoT（链式思考）的作用无论是能力一般的模型还是能力强的模型，都是很有价值的。<br />
<br />
我以前分享过一篇《如何写出高质量的 Prompt？》<br />
<br />
将写提示词分成了几个阶段：<br />
<br />
一、基础用法，直接输入你希望的指令。<br />
就是你想让 AI 完成什么任务就自然语言写就完了，这基本上可以解决绝大部分问题<br />
<br />
二、进阶用法，few-shot<br />
提供一到多个示例，通过示例来让 GPT 按照你期望的格式输出<br />
<br />
三、高级用法，链式思考（分多步做）+ 慢思考（打印每一步的结果）<br />
就比如我的翻译Prompt，就是将翻译拆分成2-3步，并且打印每一步结果，得到较好质量的翻译<br />
<br />
《如何写出高质量的 Prompt？》<a href="https://baoyu.io/blog/prompt-engineering/how-to-write-high-quality-prompt">baoyu.io/blog/prompt-enginee…</a><br />
《我试验了高级 AI 提示词的效果，结论：它们并不值得 [译]》<a href="https://baoyu.io/translations/prompt-engineering/premium-ai-prompts">baoyu.io/translations/prompt…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746322853387960570#m</id>
            <title>有意思的实验，对于能力强的模型例如 GPT-4 ，有些格式并非必要的</title>
            <link>https://nitter.cz/dotey/status/1746322853387960570#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746322853387960570#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 00:06:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有意思的实验，对于能力强的模型例如 GPT-4 ，有些格式并非必要的</p>
<p><a href="https://nitter.cz/LuoSays/status/1746321237432049723#m">nitter.cz/LuoSays/status/1746321237432049723#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746226003666514180#m</id>
            <title>很有价值的写prompt建议</title>
            <link>https://nitter.cz/dotey/status/1746226003666514180#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746226003666514180#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Jan 2024 17:41:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>很有价值的写prompt建议</p>
<p><a href="https://nitter.cz/NickADobos/status/1731030992503406684#m">nitter.cz/NickADobos/status/1731030992503406684#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746075852444508213#m</id>
            <title>R to @dotey: 为什么要提倡DevOps？一个重要的原因就是要破除Dev和Ops之间的部门墙！

为什么要微服务？一个重要原因就是让团队变小，并且减少团队之间的依赖，绝大部分事情一个团队内部搞定，减少跨团队协作沟通

https://x.com/ProgramerJohann/status/1746073598283186454?s=20</title>
            <link>https://nitter.cz/dotey/status/1746075852444508213#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746075852444508213#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Jan 2024 07:44:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>为什么要提倡DevOps？一个重要的原因就是要破除Dev和Ops之间的部门墙！<br />
<br />
为什么要微服务？一个重要原因就是让团队变小，并且减少团队之间的依赖，绝大部分事情一个团队内部搞定，减少跨团队协作沟通<br />
<br />
<a href="https://x.com/ProgramerJohann/status/1746073598283186454?s=20">x.com/ProgramerJohann/status…</a></p>
<p><a href="https://nitter.cz/ProgramerJohann/status/1746073598283186454#m">nitter.cz/ProgramerJohann/status/1746073598283186454#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746070738145058949#m</id>
            <title>R to @dotey: 很好的总结，4和5其实就是one-shot或few-shot</title>
            <link>https://nitter.cz/dotey/status/1746070738145058949#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746070738145058949#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Jan 2024 07:24:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>很好的总结，4和5其实就是one-shot或few-shot</p>
<p><a href="https://nitter.cz/jsamtony/status/1746070212561047580#m">nitter.cz/jsamtony/status/1746070212561047580#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746060658242670940#m</id>
            <title>如果我让ChatGPT写代码，一般Prompt是这么写的：

你是一位 {language} staff engineer，现在请写一个函数帮我完成 {Task} 任务，要求：
1. 
2. 
3. 

Example 

Input:
"""
{input example}
"""

Output:
"""
{output example}
"""

（注意我没有手指，请务必输出完整代码，我会给你 $1000 小费）</title>
            <link>https://nitter.cz/dotey/status/1746060658242670940#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746060658242670940#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Jan 2024 06:44:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果我让ChatGPT写代码，一般Prompt是这么写的：<br />
<br />
你是一位 {language} staff engineer，现在请写一个函数帮我完成 {Task} 任务，要求：<br />
1. <br />
2. <br />
3. <br />
<br />
Example <br />
<br />
Input:<br />
"""<br />
{input example}<br />
"""<br />
<br />
Output:<br />
"""<br />
{output example}<br />
"""<br />
<br />
（注意我没有手指，请务必输出完整代码，我会给你 $1000 小费）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/daydayuuup/status/1746012674939367572#m</id>
            <title>RT by @dotey: 宝玉老师的双译法针对科技论文有非常好的适用性，但是我用于管理学和心理学等领域文献时遇到了准确性的问题，例如直译为创造力是对的，但是意译会翻译为创新能力，这其实不符合我的需求。因此基于GPT-4本身很强大的翻译能力和个人要求文献翻译的准确性的基础上，创建了一个直译文献的GPTs。欢迎使用</title>
            <link>https://nitter.cz/daydayuuup/status/1746012674939367572#m</link>
            <guid isPermaLink="false">https://nitter.cz/daydayuuup/status/1746012674939367572#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Jan 2024 03:33:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>宝玉老师的双译法针对科技论文有非常好的适用性，但是我用于管理学和心理学等领域文献时遇到了准确性的问题，例如直译为创造力是对的，但是意译会翻译为创新能力，这其实不符合我的需求。因此基于GPT-4本身很强大的翻译能力和个人要求文献翻译的准确性的基础上，创建了一个直译文献的GPTs。欢迎使用</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746044362910281842#m</id>
            <title>这种事要看屁股，在什么位置用什么方案

位置低，只能从术的层面去解决，主要就是向上沟通
位置高，才能从道的层面去解决，最好是让前后端放在一个小团队，模糊前后端的边界</title>
            <link>https://nitter.cz/dotey/status/1746044362910281842#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746044362910281842#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Jan 2024 05:39:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这种事要看屁股，在什么位置用什么方案<br />
<br />
位置低，只能从术的层面去解决，主要就是向上沟通<br />
位置高，才能从道的层面去解决，最好是让前后端放在一个小团队，模糊前后端的边界</p>
<p><a href="https://nitter.cz/i5ting/status/1746013604825198960#m">nitter.cz/i5ting/status/1746013604825198960#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746041850312503700#m</id>
            <title>虽然故事只是故事，但都是好故事👍🏻</title>
            <link>https://nitter.cz/dotey/status/1746041850312503700#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746041850312503700#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Jan 2024 05:29:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>虽然故事只是故事，但都是好故事👍🏻</p>
<p><a href="https://nitter.cz/Yangyixxxx/status/1746038545385431516#m">nitter.cz/Yangyixxxx/status/1746038545385431516#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1746040753480986648#m</id>
            <title>《繁花》收官特辑！王家卫胡歌唐嫣马伊琍辛芷蕾9分钟解读感情空门！</title>
            <link>https://nitter.cz/dotey/status/1746040753480986648#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1746040753480986648#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Jan 2024 05:25:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《繁花》收官特辑！王家卫胡歌唐嫣马伊琍辛芷蕾9分钟解读感情空门！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDYwNDA0NzI2OTMzMDUzNDQvcHUvaW1nL2FBVmJ3NXMzLWF3WTRGVnkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>