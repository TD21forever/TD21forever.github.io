<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740094346211549275#m</id>
            <title>如果你觉得Whisper在识别中文语音的时候幻觉严重，不妨试试阿里达摩院的Paraformer模型，对中文应该支持更好！

项目地址：https://github.com/alibaba-damo-academy/FunASR
中文说明：https://github.com/alibaba-damo-academy/FunASR/blob/main/README_zh.md</title>
            <link>https://nitter.cz/dotey/status/1740094346211549275#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740094346211549275#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 19:36:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果你觉得Whisper在识别中文语音的时候幻觉严重，不妨试试阿里达摩院的Paraformer模型，对中文应该支持更好！<br />
<br />
项目地址：<a href="https://github.com/alibaba-damo-academy/FunASR">github.com/alibaba-damo-acad…</a><br />
中文说明：<a href="https://github.com/alibaba-damo-academy/FunASR/blob/main/README_zh.md">github.com/alibaba-damo-acad…</a></p>
<p><a href="https://nitter.cz/hylarucoder/status/1739494196921483663#m">nitter.cz/hylarucoder/status/1739494196921483663#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NZT2l0VVdnQUFSZWlELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740077839427232130#m</id>
            <title>这篇文章《Discover 4 Open Source Alternatives to GPT-4 Vision》介绍了 4 个 GPT-4 Vision 的开源替代方案：

1. LLaVa（大型语言和视觉助手）

https://llava-vl.github.io/

LLaVA 代表了一种创新的、从头到尾训练的大型多模态（multimodal）模型。它融合了视觉编码器和 Vicuna，旨在实现通用的视觉和语言理解。LLaVa 在模仿多模态 GPT-4 的功能方面表现出色，并在科学问答（Science QA）方面达到了新的最高精准度。

LLaVA 是一款仅限非商业用途的研究预览版产品。使用该产品需遵守 LLaMA 的模型许可、OpenAI 生成数据的使用条款以及 ShareGPT 的隐私政策。用户在使用本服务时，需同意其为研究预览版，仅限非商业用途。该服务只提供有限的安全保护，可能产生冒犯性内容。不得将其用于任何非法、有害、暴力、种族主义或性相关目的。此外，服务可能会收集用户对话数据，用于未来的研究。

2. CogAgent

https://github.com/THUDM/CogVLM

CogAgent 是一个基于 CogVLM 进行改进的开源视觉语言模型（Visual Language Model）。CogAgent-18B 模型包含了 110 亿视觉参数和 70 亿语言参数。

CogAgent-18B 在 9 大经典的跨媒介基准测试中表现卓越，这些测试包括 VQAv2、OK-VQ、TextVQA、ST-VQA、ChartQA、infoVQA、DocVQA、MM-Vet 和 POPE 等。它在处理像 AITW 和 Mind2Web 这样的图形用户界面（GUI）操作数据集时，性能远超现有模型。

3. 通义千问-VL 大型视觉语言模型 (Qwen-VL)

https://github.com/QwenLM/Qwen-VL

Qwen-VL (Qwen 大型视觉语言模型) 是阿里巴巴云推出的大型模型系列 Qwen（简称 Tongyi Qianwen）的多模态版本。Qwen-VL 能够处理图像、文本和边界框这些不同类型的输入，并输出文本和边界框。Qwen-VL 的主要特点有：

* 卓越的性能：在包括零样本 (Zero-shot) 图像描述、视觉问答 (VQA)、文档视觉问答 (DocVQA) 和图像定位 (Grounding) 等多个英语评估指标上，Qwen-VL 显著优于其他相似规模的开源大型视觉语言模型。
* 支持多语言文本识别的视觉语言模型：Qwen-VL 不仅支持英语和中文，还能处理多种语言的对话。特别在图像中的中英双语文本识别方面，实现了端到端的高效处理。
* 多图交织对话功能：这项功能使得 Qwen-VL 能够处理多张图像的输入和比较，用户可以针对这些图像提出相关问题，甚至进行多图像串联的故事叙述。
* 第一个支持中文图像定位的通用模型：Qwen-VL 能够通过开放领域的语言表达，在中文和英文中识别和标记图像中的边界框。
* 细腻的识别和理解能力：相较于其他开源视觉语言模型目前使用的 224*224 分辨率，Qwen-VL 的 448*448 分辨率更有助于精细化的文本识别、文档问答和边界框标注。

4. BakLLaVA

https://archive.ph/o/B78YS/https://huggingface.co/SkunkworksAI/BakLLaVA-1

BakLLaVA 1 是一种新型 AI 模型，它基于原有的 Mistral 7B 模型，并融合了最新的 LLaVA 1.5 架构技术。在这个初始版本中，开发者们展示了这一模型在多个性能测试中相较于 Llama 2 13B 模型有更出色的表现。你可以在他们的GitHub 仓库中找到并试用 BakLLaVA-1。目前，他们正努力更新这一模型，使用户能更容易地对它进行个性化调整和数据分析。

BakLLaVA-1 是完全开放源代码的，但它的训练过程中使用了特定的数据集，包括 LLaVA 的语料库，这些数据并不适合商业用途。目前，BakLLaVA 2 正在研发中，它将使用一个更大的、适合商业应用的数据集，并采用一种创新的架构设计，以超越现有的 LLaVA 方法。BakLLaVA-2 的出现预计将消除 BakLLaVA-1 目前面临的一些使用限制。

原文：https://yousefhosni.medium.com/discover-4-open-source-alternatives-to-gpt-4-vision-82be9519dcc5
译文：https://baoyu.io/translations/lmm/discover-4-open-source-alternatives-to-gpt-4-vision</title>
            <link>https://nitter.cz/dotey/status/1740077839427232130#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740077839427232130#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 18:31:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这篇文章《Discover 4 Open Source Alternatives to GPT-4 Vision》介绍了 4 个 GPT-4 Vision 的开源替代方案：<br />
<br />
1. LLaVa（大型语言和视觉助手）<br />
<br />
<a href="https://llava-vl.github.io/">llava-vl.github.io/</a><br />
<br />
LLaVA 代表了一种创新的、从头到尾训练的大型多模态（multimodal）模型。它融合了视觉编码器和 Vicuna，旨在实现通用的视觉和语言理解。LLaVa 在模仿多模态 GPT-4 的功能方面表现出色，并在科学问答（Science QA）方面达到了新的最高精准度。<br />
<br />
LLaVA 是一款仅限非商业用途的研究预览版产品。使用该产品需遵守 LLaMA 的模型许可、OpenAI 生成数据的使用条款以及 ShareGPT 的隐私政策。用户在使用本服务时，需同意其为研究预览版，仅限非商业用途。该服务只提供有限的安全保护，可能产生冒犯性内容。不得将其用于任何非法、有害、暴力、种族主义或性相关目的。此外，服务可能会收集用户对话数据，用于未来的研究。<br />
<br />
2. CogAgent<br />
<br />
<a href="https://github.com/THUDM/CogVLM">github.com/THUDM/CogVLM</a><br />
<br />
CogAgent 是一个基于 CogVLM 进行改进的开源视觉语言模型（Visual Language Model）。CogAgent-18B 模型包含了 110 亿视觉参数和 70 亿语言参数。<br />
<br />
CogAgent-18B 在 9 大经典的跨媒介基准测试中表现卓越，这些测试包括 VQAv2、OK-VQ、TextVQA、ST-VQA、ChartQA、infoVQA、DocVQA、MM-Vet 和 POPE 等。它在处理像 AITW 和 Mind2Web 这样的图形用户界面（GUI）操作数据集时，性能远超现有模型。<br />
<br />
3. 通义千问-VL 大型视觉语言模型 (Qwen-VL)<br />
<br />
<a href="https://github.com/QwenLM/Qwen-VL">github.com/QwenLM/Qwen-VL</a><br />
<br />
Qwen-VL (Qwen 大型视觉语言模型) 是阿里巴巴云推出的大型模型系列 Qwen（简称 Tongyi Qianwen）的多模态版本。Qwen-VL 能够处理图像、文本和边界框这些不同类型的输入，并输出文本和边界框。Qwen-VL 的主要特点有：<br />
<br />
* 卓越的性能：在包括零样本 (Zero-shot) 图像描述、视觉问答 (VQA)、文档视觉问答 (DocVQA) 和图像定位 (Grounding) 等多个英语评估指标上，Qwen-VL 显著优于其他相似规模的开源大型视觉语言模型。<br />
* 支持多语言文本识别的视觉语言模型：Qwen-VL 不仅支持英语和中文，还能处理多种语言的对话。特别在图像中的中英双语文本识别方面，实现了端到端的高效处理。<br />
* 多图交织对话功能：这项功能使得 Qwen-VL 能够处理多张图像的输入和比较，用户可以针对这些图像提出相关问题，甚至进行多图像串联的故事叙述。<br />
* 第一个支持中文图像定位的通用模型：Qwen-VL 能够通过开放领域的语言表达，在中文和英文中识别和标记图像中的边界框。<br />
* 细腻的识别和理解能力：相较于其他开源视觉语言模型目前使用的 224*224 分辨率，Qwen-VL 的 448*448 分辨率更有助于精细化的文本识别、文档问答和边界框标注。<br />
<br />
4. BakLLaVA<br />
<br />
<a href="https://archive.ph/o/B78YS/https://huggingface.co/SkunkworksAI/BakLLaVA-1">archive.ph/o/B78YS/huggingfa…</a><br />
<br />
BakLLaVA 1 是一种新型 AI 模型，它基于原有的 Mistral 7B 模型，并融合了最新的 LLaVA 1.5 架构技术。在这个初始版本中，开发者们展示了这一模型在多个性能测试中相较于 Llama 2 13B 模型有更出色的表现。你可以在他们的GitHub 仓库中找到并试用 BakLLaVA-1。目前，他们正努力更新这一模型，使用户能更容易地对它进行个性化调整和数据分析。<br />
<br />
BakLLaVA-1 是完全开放源代码的，但它的训练过程中使用了特定的数据集，包括 LLaVA 的语料库，这些数据并不适合商业用途。目前，BakLLaVA 2 正在研发中，它将使用一个更大的、适合商业应用的数据集，并采用一种创新的架构设计，以超越现有的 LLaVA 方法。BakLLaVA-2 的出现预计将消除 BakLLaVA-1 目前面临的一些使用限制。<br />
<br />
原文：<a href="https://yousefhosni.medium.com/discover-4-open-source-alternatives-to-gpt-4-vision-82be9519dcc5">yousefhosni.medium.com/disco…</a><br />
译文：<a href="https://baoyu.io/translations/lmm/discover-4-open-source-alternatives-to-gpt-4-vision">baoyu.io/translations/lmm/di…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NYLWt0RFdVQUUxdUpRLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NYLXBVWlhBQUVCZm1DLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740046880451813432#m</id>
            <title>RT by @dotey: 字节的一个图像分割项目UniRef++，将现在的即参考图像分割（RIS）、少镜头图像分割（FSS）、参考视频对象分割（RVOS）和视频对象分割（VOS）四种分割方式放在一个架构下处理，自动判断应该使用哪种方式分割内容。

同时这个架构的UniFusion 模块可合并到SAM模型之中一起使用。</title>
            <link>https://nitter.cz/op7418/status/1740046880451813432#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740046880451813432#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 16:27:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>字节的一个图像分割项目UniRef++，将现在的即参考图像分割（RIS）、少镜头图像分割（FSS）、参考视频对象分割（RVOS）和视频对象分割（VOS）四种分割方式放在一个架构下处理，自动判断应该使用哪种方式分割内容。<br />
<br />
同时这个架构的UniFusion 模块可合并到SAM模型之中一起使用。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1739894833076945307#m">nitter.cz/_akhaliq/status/1739894833076945307#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/stats_cgao/status/1739948548219961813#m</id>
            <title>RT by @dotey: 我的理解是他们先embed了training set 然后让GPT4 按照那个prompt format去生成CoT examples 然后filter掉不正确的 然后在test time去dynamic retrieve这些QA w/ COT的example作为few shot 整个过程应该不需要log prob, 最后的choice shuffle只是更进一步的self consistency而已</title>
            <link>https://nitter.cz/stats_cgao/status/1739948548219961813#m</link>
            <guid isPermaLink="false">https://nitter.cz/stats_cgao/status/1739948548219961813#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 09:57:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我的理解是他们先embed了training set 然后让GPT4 按照那个prompt format去生成CoT examples 然后filter掉不正确的 然后在test time去dynamic retrieve这些QA w/ COT的example作为few shot 整个过程应该不需要log prob, 最后的choice shuffle只是更进一步的self consistency而已</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740067171944829400#m</id>
            <title>R to @dotey: 这篇论文的中文翻译：
https://baoyu.io/translations/ai-paper/2312.14302-exploiting-novel-gpt-4-apis</title>
            <link>https://nitter.cz/dotey/status/1740067171944829400#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740067171944829400#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 17:48:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这篇论文的中文翻译：<br />
<a href="https://baoyu.io/translations/ai-paper/2312.14302-exploiting-novel-gpt-4-apis">baoyu.io/translations/ai-pap…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740054249365762180#m</id>
            <title>RT by @dotey: 福布斯发布了他们2024年的十个AI预测，看了一下还挺靠谱的也不长，就翻译了一下。

先看一下具体的十条预测，正文理由太长了可以去链接里看翻译完的：

◆ Nvidia将大幅加大努力成为云服务提供商。
◆ Stability AI将会倒闭。
◆ “大型语言模型”和“LLM”这些术语将变得不那么常见。
◆ 最先进的封闭模型将继续以显著优势胜过最先进的开放模型。
◆ 一些《财富》500强公司将设立新的C级职位：首席人工智能官。
◆ 另一种替代transformer架构将得到有意义的采用。
◆ 云服务提供商对人工智能初创公司的战略投资，以及相关的会计影响，将受到监管机构的挑战。
◆ 微软/Open AI的关系将开始破裂。
◆ 2023年从加密货币转移到人工智能的一些炒作和群体心态行为将在2024年转回加密货币。
◆ 至少有一家美国法院将裁定在互联网上训练的生成式人工智能模型构成侵犯版权。这一问题将开始上升至美国最高法院。

全文翻译：https://quail.ink/op7418/p/forbes-2024-10-ai-predictions</title>
            <link>https://nitter.cz/op7418/status/1740054249365762180#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740054249365762180#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 16:57:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>福布斯发布了他们2024年的十个AI预测，看了一下还挺靠谱的也不长，就翻译了一下。<br />
<br />
先看一下具体的十条预测，正文理由太长了可以去链接里看翻译完的：<br />
<br />
◆ Nvidia将大幅加大努力成为云服务提供商。<br />
◆ Stability AI将会倒闭。<br />
◆ “大型语言模型”和“LLM”这些术语将变得不那么常见。<br />
◆ 最先进的封闭模型将继续以显著优势胜过最先进的开放模型。<br />
◆ 一些《财富》500强公司将设立新的C级职位：首席人工智能官。<br />
◆ 另一种替代transformer架构将得到有意义的采用。<br />
◆ 云服务提供商对人工智能初创公司的战略投资，以及相关的会计影响，将受到监管机构的挑战。<br />
◆ 微软/Open AI的关系将开始破裂。<br />
◆ 2023年从加密货币转移到人工智能的一些炒作和群体心态行为将在2024年转回加密货币。<br />
◆ 至少有一家美国法院将裁定在互联网上训练的生成式人工智能模型构成侵犯版权。这一问题将开始上升至美国最高法院。<br />
<br />
全文翻译：<a href="https://quail.ink/op7418/p/forbes-2024-10-ai-predictions">quail.ink/op7418/p/forbes-20…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NYcUVYd2JBQUlucW1XLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740066390047072449#m</id>
            <title>2024 年会成为 AI 机器人 元年吗？</title>
            <link>https://nitter.cz/dotey/status/1740066390047072449#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740066390047072449#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 17:45:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2024 年会成为 AI 机器人 元年吗？</p>
<p><a href="https://nitter.cz/DrJimFan/status/1740041712184246314#m">nitter.cz/DrJimFan/status/1740041712184246314#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/luoleiorg/status/1739674603994116149#m</id>
            <title>RT by @dotey: 最近我开始使用 Bob 的自定义 prompt 功能，来辅助我的英语单词翻译和学习。与传统的翻译接口相比，加入一些更符合人类记忆的提示信息，可以使理解更容易。</title>
            <link>https://nitter.cz/luoleiorg/status/1739674603994116149#m</link>
            <guid isPermaLink="false">https://nitter.cz/luoleiorg/status/1739674603994116149#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 15:48:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近我开始使用 Bob 的自定义 prompt 功能，来辅助我的英语单词翻译和学习。与传统的翻译接口相比，加入一些更符合人类记忆的提示信息，可以使理解更容易。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NTUGV1RVdrQUVDVDdmLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NTUC1ocVhvQUFYbGl5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1739843861302624595#m</id>
            <title>Aider Chat 是一个命令行工具，可以借助GPT的API，编辑本地代码。他们有一个 133个测试代码，用来评测LLM性能，相对还是比较准确的。

最近他们做了一个有意思的测试，将民间流传的那些Prompt技巧（例如：“我没有手指”、“我是盲人”、“我给你付2K小费”）都测试了一下，结果发现加上了反而效果更差😄

就修改代码这事来说，他们发现最有效的还是让GPT针对要修改的内容给出“unified diffs”（统一差异格式），就是你运行“git diff”的时候，给出的那种带加号减号还有高亮的代码！

但是有一个问题就是GPT对于给出行号的时候幻觉严重，所以他们的解决方案就是不给行号，然后通过程序去定位代码行。

具体细节可以参考文章：Unified diffs make GPT-4 Turbo less lazy
https://aider.chat/docs/unified-diffs.html
译文：https://baoyu.io/translations/llm/unified-diffs-make-gpt-4-turbo-less-lazy</title>
            <link>https://nitter.cz/dotey/status/1739843861302624595#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1739843861302624595#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 03:01:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Aider Chat 是一个命令行工具，可以借助GPT的API，编辑本地代码。他们有一个 133个测试代码，用来评测LLM性能，相对还是比较准确的。<br />
<br />
最近他们做了一个有意思的测试，将民间流传的那些Prompt技巧（例如：“我没有手指”、“我是盲人”、“我给你付2K小费”）都测试了一下，结果发现加上了反而效果更差😄<br />
<br />
就修改代码这事来说，他们发现最有效的还是让GPT针对要修改的内容给出“unified diffs”（统一差异格式），就是你运行“git diff”的时候，给出的那种带加号减号还有高亮的代码！<br />
<br />
但是有一个问题就是GPT对于给出行号的时候幻觉严重，所以他们的解决方案就是不给行号，然后通过程序去定位代码行。<br />
<br />
具体细节可以参考文章：Unified diffs make GPT-4 Turbo less lazy<br />
<a href="https://aider.chat/docs/unified-diffs.html">aider.chat/docs/unified-diff…</a><br />
译文：<a href="https://baoyu.io/translations/llm/unified-diffs-make-gpt-4-turbo-less-lazy">baoyu.io/translations/llm/un…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NVcGJqbldRQUEzNVVBLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NVcUhWb1dRQUFUWWluLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1739810921479045202#m</id>
            <title>RT by @dotey: 30B 规模是目前小参数模型的一个甜点尺寸。

16bit推理可以放在一张80G或者2张40G显卡上，4bit 量化则正好放到消费级显卡。

能力也不弱，Yi-34B 实际lmsys 的elo分也比较高。lora /qlora 微调需要的资源也不高。</title>
            <link>https://nitter.cz/9hills/status/1739810921479045202#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1739810921479045202#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 00:50:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>30B 规模是目前小参数模型的一个甜点尺寸。<br />
<br />
16bit推理可以放在一张80G或者2张40G显卡上，4bit 量化则正好放到消费级显卡。<br />
<br />
能力也不弱，Yi-34B 实际lmsys 的elo分也比较高。lora /qlora 微调需要的资源也不高。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1739808774498525681#m</id>
            <title>很期待机器人硬件和AI的结合！

以下内容为转译：

  AI与机器人硬件的发展曲线现已出现变化。

  在最近的90天中，我在我们的实验室亲眼目睹了业界先进的AI在人形机器人硬件上的运行，坦白说，这让我感到震惊。

  我观察到机器人完全依赖神经网络执行复杂的任务，这样的任务是我原本认为需要到这个十年结束时才能实现的。

  2022年开启Figure项目时，我深信我们会比让机器人运行可靠的神经网络早一步拥有可靠的人形机器人硬件。

  基本上，我原本认为机器人接受的“家庭”类型任务训练将会确定我们的发展时序。

  但在过去的几个月里，我的看法发生了改变。我现在更倾向于相信，我们很可能会在人形机器人硬件达到高度可靠并开始大规模生产的同时，或者稍早一些，拥有可在硬件上运行的可靠AI。

  我认为，为机器人提供可靠硬件的路径非常明确也可预测，只要给予足够的时间，这个问题一定能够被解决。

  Figure AI团队正在研发使用端到端神经网络执行高度复杂和灵巧任务的人形机器人。这些任务太复杂，若要用C++编写启发式算法则难以实现。

  这无疑令人兴奋不已，因为你可以教机器人如何完成任务，并随着机器人量的增加，可以积累更大的训练数据。当舰队不断扩大时，他们将会继续学习，每一天都将变得更加聪明，更加熟练。

  2024年，将标记着人工智能实体化的一年。

  我们将竞逐可靠的硬件设备，大规模的训练数据，并且设计大量生产流程。对于一个更加充满创新的未来，我无法想象还能有什么比这更让人兴奋的了。

  我们将会在2024年展示我们的人工智能实体化成果，敬请期待！</title>
            <link>https://nitter.cz/dotey/status/1739808774498525681#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1739808774498525681#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 00:41:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>很期待机器人硬件和AI的结合！<br />
<br />
以下内容为转译：<br />
<br />
  AI与机器人硬件的发展曲线现已出现变化。<br />
<br />
  在最近的90天中，我在我们的实验室亲眼目睹了业界先进的AI在人形机器人硬件上的运行，坦白说，这让我感到震惊。<br />
<br />
  我观察到机器人完全依赖神经网络执行复杂的任务，这样的任务是我原本认为需要到这个十年结束时才能实现的。<br />
<br />
  2022年开启Figure项目时，我深信我们会比让机器人运行可靠的神经网络早一步拥有可靠的人形机器人硬件。<br />
<br />
  基本上，我原本认为机器人接受的“家庭”类型任务训练将会确定我们的发展时序。<br />
<br />
  但在过去的几个月里，我的看法发生了改变。我现在更倾向于相信，我们很可能会在人形机器人硬件达到高度可靠并开始大规模生产的同时，或者稍早一些，拥有可在硬件上运行的可靠AI。<br />
<br />
  我认为，为机器人提供可靠硬件的路径非常明确也可预测，只要给予足够的时间，这个问题一定能够被解决。<br />
<br />
  Figure AI团队正在研发使用端到端神经网络执行高度复杂和灵巧任务的人形机器人。这些任务太复杂，若要用C++编写启发式算法则难以实现。<br />
<br />
  这无疑令人兴奋不已，因为你可以教机器人如何完成任务，并随着机器人量的增加，可以积累更大的训练数据。当舰队不断扩大时，他们将会继续学习，每一天都将变得更加聪明，更加熟练。<br />
<br />
  2024年，将标记着人工智能实体化的一年。<br />
<br />
  我们将竞逐可靠的硬件设备，大规模的训练数据，并且设计大量生产流程。对于一个更加充满创新的未来，我无法想象还能有什么比这更让人兴奋的了。<br />
<br />
  我们将会在2024年展示我们的人工智能实体化成果，敬请期待！</p>
<p><a href="https://nitter.cz/adcock_brett/status/1739719880499425506#m">nitter.cz/adcock_brett/status/1739719880499425506#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1739785576151232888#m</id>
            <title>YAYI 2 是中科闻歌研发的新一代开源大语言模型，包括 Base 和 Chat 版本，参数规模为 30B。YAYI2-30B 是基于 Transformer 的大语言模型，采用了超过 2 万亿 Tokens 的高质量、多语言语料进行预训练。针对通用和特定领域的应用场景，采用了百万级指令进行微调，同时借助人类反馈强化学习方法，以更好地使模型与人类价值观对齐。

本次开源的模型为 YAYI2-30B Base 模型。

相关论文：https://arxiv.org/abs/2312.14862
项目地址：https://github.com/wenge-research/YAYI2</title>
            <link>https://nitter.cz/dotey/status/1739785576151232888#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1739785576151232888#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 23:09:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>YAYI 2 是中科闻歌研发的新一代开源大语言模型，包括 Base 和 Chat 版本，参数规模为 30B。YAYI2-30B 是基于 Transformer 的大语言模型，采用了超过 2 万亿 Tokens 的高质量、多语言语料进行预训练。针对通用和特定领域的应用场景，采用了百万级指令进行微调，同时借助人类反馈强化学习方法，以更好地使模型与人类价值观对齐。<br />
<br />
本次开源的模型为 YAYI2-30B Base 模型。<br />
<br />
相关论文：<a href="https://arxiv.org/abs/2312.14862">arxiv.org/abs/2312.14862</a><br />
项目地址：<a href="https://github.com/wenge-research/YAYI2">github.com/wenge-research/YA…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NUMUtBVldnQUE0M1NDLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NUMVBTMVdjQUV1c1JPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1739775517958516795#m</id>
            <title>根据这篇论文《Exploiting Novel GPT-4 APIs | 利用新型GPT-4 API的漏洞》的信息，没想到调用 GPT-4 API 尤其是微调后的 GPT-4 可以干很多“坏事”😄

主要漏洞包括：

1. 微调应用编程接口（Fine-tuning API）可能会撤销或削弱安全防护措施，这可能导致模型产生有害输出或协助完成危险请求。

2. 通过微调，模型可能会生成针对公众人物的错误信息。

3. 微调机制可能会提取训练数据中的私人信息，如电子邮件。

4. 微调也可能在代码建议中插入恶意的URL。

5. 函数调用应用编程接口（Function calling API）允许执行任意未经清洁的函数调用，这可能导致潜在的攻击行为。

6. 知识检索应用编程接口（Knowledge retrieval API）可能被利用来通过提示插入或在文档/消息中的指令来误导用户或执行不期望的函数调用。

7. 对于函数调用和知识检索的输出，它们没有比用户提示更高的权威性，这可以防止某些攻破限制的攻击行为。

论文摘要 

通常，语言模型攻击假设两种极端情况：
一种是对模型权重具有完全的白盒访问权限；
另一种是只有生成文本API的黑盒访问权限。

但是，实际上的API功能通常比仅仅生成文本更强大，它们提供一种“灰盒”访问方式，这导致了新的威胁向量。为了探索这一问题，我们进行了对GPT-4 API的“红队”攻击测试，该API公开了三种新功能：微调、函数调用和知识检索。

我们发现，通过少量的15个有害样本或100个良性样本进行模型微调，就可以移除GPT-4的核心防护，并能够生成一系列有害的输出。

此外，我们还发现GPT-4助手模型容易暴露函数调用的格式，并能够被诱导执行任意函数调用。

最后，我们发现知识检索可以通过在检索文档中注入指令来进行劫持。这些漏洞凸显出，任何新增的API功能都可能带来新的漏洞。

论文地址：https://arxiv.org/abs/2312.14302
（计划晚点翻译一下这篇论文）</title>
            <link>https://nitter.cz/dotey/status/1739775517958516795#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1739775517958516795#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 22:29:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>根据这篇论文《Exploiting Novel GPT-4 APIs | 利用新型GPT-4 API的漏洞》的信息，没想到调用 GPT-4 API 尤其是微调后的 GPT-4 可以干很多“坏事”😄<br />
<br />
主要漏洞包括：<br />
<br />
1. 微调应用编程接口（Fine-tuning API）可能会撤销或削弱安全防护措施，这可能导致模型产生有害输出或协助完成危险请求。<br />
<br />
2. 通过微调，模型可能会生成针对公众人物的错误信息。<br />
<br />
3. 微调机制可能会提取训练数据中的私人信息，如电子邮件。<br />
<br />
4. 微调也可能在代码建议中插入恶意的URL。<br />
<br />
5. 函数调用应用编程接口（Function calling API）允许执行任意未经清洁的函数调用，这可能导致潜在的攻击行为。<br />
<br />
6. 知识检索应用编程接口（Knowledge retrieval API）可能被利用来通过提示插入或在文档/消息中的指令来误导用户或执行不期望的函数调用。<br />
<br />
7. 对于函数调用和知识检索的输出，它们没有比用户提示更高的权威性，这可以防止某些攻破限制的攻击行为。<br />
<br />
论文摘要 <br />
<br />
通常，语言模型攻击假设两种极端情况：<br />
一种是对模型权重具有完全的白盒访问权限；<br />
另一种是只有生成文本API的黑盒访问权限。<br />
<br />
但是，实际上的API功能通常比仅仅生成文本更强大，它们提供一种“灰盒”访问方式，这导致了新的威胁向量。为了探索这一问题，我们进行了对GPT-4 API的“红队”攻击测试，该API公开了三种新功能：微调、函数调用和知识检索。<br />
<br />
我们发现，通过少量的15个有害样本或100个良性样本进行模型微调，就可以移除GPT-4的核心防护，并能够生成一系列有害的输出。<br />
<br />
此外，我们还发现GPT-4助手模型容易暴露函数调用的格式，并能够被诱导执行任意函数调用。<br />
<br />
最后，我们发现知识检索可以通过在检索文档中注入指令来进行劫持。这些漏洞凸显出，任何新增的API功能都可能带来新的漏洞。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.14302">arxiv.org/abs/2312.14302</a><br />
（计划晚点翻译一下这篇论文）</p>
<p><a href="https://nitter.cz/_akhaliq/status/1739480367776563443#m">nitter.cz/_akhaliq/status/1739480367776563443#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NUc2NXOFdzQUFpVFFMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1739773412162068785#m</id>
            <title>强烈推荐这篇：《Advanced RAG Techniques: an Illustrated Overview》
不可多得的全面阐述 RAG 概念指南。

原文：https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6

译文：https://baoyu.io/translations/rag/advanced-rag-techniques-an-illustrated-overview</title>
            <link>https://nitter.cz/dotey/status/1739773412162068785#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1739773412162068785#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 22:21:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>强烈推荐这篇：《Advanced RAG Techniques: an Illustrated Overview》<br />
不可多得的全面阐述 RAG 概念指南。<br />
<br />
原文：<a href="https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6">pub.towardsai.net/advanced-r…</a><br />
<br />
译文：<a href="https://baoyu.io/translations/rag/advanced-rag-techniques-an-illustrated-overview">baoyu.io/translations/rag/ad…</a></p>
<p><a href="https://nitter.cz/jerryjliu0/status/1739678474842128455#m">nitter.cz/jerryjliu0/status/1739678474842128455#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NUcXFkQldRQUVicUFWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/thinkingjimmy/status/1739533087623811333#m</id>
            <title>RT by @dotey: 之前一直想写 Stable Diffusion 相关的教程，但觉得 Stable Diffusion WebUI 可拓展性不强，自由度不够高，所以一直没下笔。最近尝试了下 ComfyUI ，才惊叹地发现这才是我想要的。市面上系统性的 ComfyUI 教程不多，所以最近跟朋友一起搞了一个新教程：https://www.comflowy.com/zh-CN 希望对大家有帮助。</title>
            <link>https://nitter.cz/thinkingjimmy/status/1739533087623811333#m</link>
            <guid isPermaLink="false">https://nitter.cz/thinkingjimmy/status/1739533087623811333#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 06:26:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前一直想写 Stable Diffusion 相关的教程，但觉得 Stable Diffusion WebUI 可拓展性不强，自由度不够高，所以一直没下笔。最近尝试了下 ComfyUI ，才惊叹地发现这才是我想要的。市面上系统性的 ComfyUI 教程不多，所以最近跟朋友一起搞了一个新教程：<a href="https://www.comflowy.com/zh-CN">comflowy.com/zh-CN</a> 希望对大家有帮助。</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczOTMxNDg1NjM1OTI1NjA2NS9nU2ZiNDd1Mj9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/geekbb/status/1739522424918737265#m</id>
            <title>RT by @dotey: Reactive Resume 是一款免费、开源的简历编辑器，简化了创建、更新和分享简历的流程。支持多种语言，具备实时编辑、数十种模板、拖放自定义功能，还集成了 OpenAI 提供的写作增强功能。
GitHub https://github.com/AmruthPillai/Reactive-Resume?tab=readme-ov-file
Docs https://docs.rxresu.me/</title>
            <link>https://nitter.cz/geekbb/status/1739522424918737265#m</link>
            <guid isPermaLink="false">https://nitter.cz/geekbb/status/1739522424918737265#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 05:43:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Reactive Resume 是一款免费、开源的简历编辑器，简化了创建、更新和分享简历的流程。支持多种语言，具备实时编辑、数十种模板、拖放自定义功能，还集成了 OpenAI 提供的写作增强功能。<br />
GitHub <a href="https://github.com/AmruthPillai/Reactive-Resume?tab=readme-ov-file">github.com/AmruthPillai/Reac…</a><br />
Docs <a href="https://docs.rxresu.me/">docs.rxresu.me/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NRRkJYZ2JnQUFNTWtmLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1739662100761346403#m</id>
            <title>而且很有意思的是，这次Sam被罢免，Airbnb的CEO发挥了关键作用：

他的一位关键盟友是 Chesky。Altman 被解雇后不久，Chesky 通过视频与 Altman 和 Brockman 进行了交谈，而 Brockman 也因为和 Altman 站在一起而在当天离开了公司。Chesky 询问了解雇的原因。Altman 猜测，这可能与 Toner 的冲突或 Sutskever 的抱怨有关。

在确认这不涉及刑事问题后，Chesky 给 Microsoft 的 CEO Nadella 打电话。
包括 Chesky 和 Conway 在内的一小群硅谷权力经纪人开始向董事会施压，试图为 Altman 辩护。

董事会临时任命 Emmett Shear 为 CEO，这一决定引发了大多数员工的辞职威胁。幸运的是，Shear 是 Chesky 的盟友和导师。

Chesky 和 Shear 合力为 Altman 的重返铺平了道路。

http://www.wsj.com/tech/ai/sam-altman-openai-protected-by-silicon-valley-friends-f3efcf68</title>
            <link>https://nitter.cz/dotey/status/1739662100761346403#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1739662100761346403#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 14:59:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>而且很有意思的是，这次Sam被罢免，Airbnb的CEO发挥了关键作用：<br />
<br />
他的一位关键盟友是 Chesky。Altman 被解雇后不久，Chesky 通过视频与 Altman 和 Brockman 进行了交谈，而 Brockman 也因为和 Altman 站在一起而在当天离开了公司。Chesky 询问了解雇的原因。Altman 猜测，这可能与 Toner 的冲突或 Sutskever 的抱怨有关。<br />
<br />
在确认这不涉及刑事问题后，Chesky 给 Microsoft 的 CEO Nadella 打电话。<br />
包括 Chesky 和 Conway 在内的一小群硅谷权力经纪人开始向董事会施压，试图为 Altman 辩护。<br />
<br />
董事会临时任命 Emmett Shear 为 CEO，这一决定引发了大多数员工的辞职威胁。幸运的是，Shear 是 Chesky 的盟友和导师。<br />
<br />
Chesky 和 Shear 合力为 Altman 的重返铺平了道路。<br />
<br />
<a href="http://www.wsj.com/tech/ai/sam-altman-openai-protected-by-silicon-valley-friends-f3efcf68">wsj.com/tech/ai/sam-altman-o…</a></p>
<p><a href="https://nitter.cz/kuaidaoqingyi/status/1739626766178861185#m">nitter.cz/kuaidaoqingyi/status/1739626766178861185#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1739519500846817458#m</id>
            <title>推荐阅读：“2023: The Year of AI”

这是一份相当详尽的对 2023 年 AI 领域重大事件的总结！

原文：https://journal.everypixel.com/2023-the-year-of-ai
中文：https://baoyu.io/translations/ai/2023-the-year-of-ai</title>
            <link>https://nitter.cz/dotey/status/1739519500846817458#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1739519500846817458#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 05:32:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：“2023: The Year of AI”<br />
<br />
这是一份相当详尽的对 2023 年 AI 领域重大事件的总结！<br />
<br />
原文：<a href="https://journal.everypixel.com/2023-the-year-of-ai">journal.everypixel.com/2023-…</a><br />
中文：<a href="https://baoyu.io/translations/ai/2023-the-year-of-ai">baoyu.io/translations/ai/202…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NRRGVEZFdRQUVNQzl4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NRRGZ0MVhBQUFCVzVPLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NRRGlzeVc4QUFIclFDLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739479576596844909#m</id>
            <title>RT by @dotey: Danswer：一个开源企业AI问答系统。

它允许用户以聊天的方式从企业内部文档中获取可靠的答案，这些答案由源材料中的引用和参考支持，确保了答案的可信度。

可以用来企业内部知识库查询和开发客服机器人。

支持对接多种大语言模型：如GPT-4、Mixstral、Llama2等。

Danswer还可以连接到常见的工具，如Slack、GitHub、Confluence等。

其他功能：

- 跨平台搜索：允许用户在公司内部的多个文档和应用程序中进行搜索。

- 团队工具集成：可以集成到团队正在使用的工具中，如Slack，以回答常见问题。

- 定制AI助手：为不同团队构建具有特定知识源和回答选项的定制AI助手。

- 混合搜索技术：结合最新的嵌入模型和关键词搜索算法，提高搜索的相关性和准确性。

- 自我学习和改进：根据用户反馈学习，不断提高搜索质量。

- 自主部署：提供自由部署选项，支持企业级用户管理和认证功能。

- 连接器：支持从多个源高效拉取最新更改，包括Slack、GitHub、Google Drive、Confluence、Jira、Zendesk、Notion等。

详细介绍：https://www.danswer.ai/

GitHub：https://github.com/danswer-ai/danswer</title>
            <link>https://nitter.cz/xiaohuggg/status/1739479576596844909#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739479576596844909#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 02:53:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Danswer：一个开源企业AI问答系统。<br />
<br />
它允许用户以聊天的方式从企业内部文档中获取可靠的答案，这些答案由源材料中的引用和参考支持，确保了答案的可信度。<br />
<br />
可以用来企业内部知识库查询和开发客服机器人。<br />
<br />
支持对接多种大语言模型：如GPT-4、Mixstral、Llama2等。<br />
<br />
Danswer还可以连接到常见的工具，如Slack、GitHub、Confluence等。<br />
<br />
其他功能：<br />
<br />
- 跨平台搜索：允许用户在公司内部的多个文档和应用程序中进行搜索。<br />
<br />
- 团队工具集成：可以集成到团队正在使用的工具中，如Slack，以回答常见问题。<br />
<br />
- 定制AI助手：为不同团队构建具有特定知识源和回答选项的定制AI助手。<br />
<br />
- 混合搜索技术：结合最新的嵌入模型和关键词搜索算法，提高搜索的相关性和准确性。<br />
<br />
- 自我学习和改进：根据用户反馈学习，不断提高搜索质量。<br />
<br />
- 自主部署：提供自由部署选项，支持企业级用户管理和认证功能。<br />
<br />
- 连接器：支持从多个源高效拉取最新更改，包括Slack、GitHub、Google Drive、Confluence、Jira、Zendesk、Notion等。<br />
<br />
详细介绍：<a href="https://www.danswer.ai/">danswer.ai/</a><br />
<br />
GitHub：<a href="https://github.com/danswer-ai/danswer">github.com/danswer-ai/danswe…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkyNDYzNDA4NDMyMTI4MDAvcHUvaW1nL284TUl2aHJXNnlTZm9iTWcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>