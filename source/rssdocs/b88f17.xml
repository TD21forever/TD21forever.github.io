<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729231976672977016#m</id>
            <title>推荐：《Reading List For Andrej Karpathy’s Intro to Large Language Models Video》 
Andrej Karpathy 大语言模型视频入门的精选阅读清单

作者针对Andrej Karpathy前几天的视频教程，把相关的参考文章、论文都分门别类整理出来了。

原文：https://blog.oxen.ai/reading-list-for-andrej-karpathys-intro-to-large-language-models-video/
译文：https://baoyu.io/translations/llm/reading-list-for-andrej-karpathys-intro-to-large-language-models-video</title>
            <link>https://nitter.cz/dotey/status/1729231976672977016#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729231976672977016#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 20:13:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐：《Reading List For Andrej Karpathy’s Intro to Large Language Models Video》 <br />
Andrej Karpathy 大语言模型视频入门的精选阅读清单<br />
<br />
作者针对Andrej Karpathy前几天的视频教程，把相关的参考文章、论文都分门别类整理出来了。<br />
<br />
原文：<a href="https://blog.oxen.ai/reading-list-for-andrej-karpathys-intro-to-large-language-models-video/">blog.oxen.ai/reading-list-fo…</a><br />
译文：<a href="https://baoyu.io/translations/llm/reading-list-for-andrej-karpathys-intro-to-large-language-models-video">baoyu.io/translations/llm/re…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85MnlJTVdVQUV1NXVFLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85M0hkblhjQUFfUE1wLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85M09xU1hvQUFWX1NoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85M1RzeVhZQUFaYjNrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729228859483054230#m</id>
            <title>黑的漂亮😂</title>
            <link>https://nitter.cz/dotey/status/1729228859483054230#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729228859483054230#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 20:01:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>黑的漂亮😂</p>
<p><a href="https://nitter.cz/milosvete/status/1729203769836212432#m">nitter.cz/milosvete/status/1729203769836212432#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mave99a/status/1729221316165906820#m</id>
            <title>RT by @dotey: 关键是要看什么东西可以 RL （Reinforcement learning） 却不需要 HF（human feedback）。 AI行业和区块链行业（或者整个IT行业）一样有喜欢造词来显得高大上的毛病。 其实RLHF，通俗来说就是给AI 点赞或点踩，这样它能反思提高。 目前语言问题在于需要人工参与这个过程，因此提高缓慢。</title>
            <link>https://nitter.cz/mave99a/status/1729221316165906820#m</link>
            <guid isPermaLink="false">https://nitter.cz/mave99a/status/1729221316165906820#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 19:31:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>关键是要看什么东西可以 RL （Reinforcement learning） 却不需要 HF（human feedback）。 AI行业和区块链行业（或者整个IT行业）一样有喜欢造词来显得高大上的毛病。 其实RLHF，通俗来说就是给AI 点赞或点踩，这样它能反思提高。 目前语言问题在于需要人工参与这个过程，因此提高缓慢。</p>
<p><a href="https://nitter.cz/dotey/status/1729201172232479001#m">nitter.cz/dotey/status/1729201172232479001#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729201172232479001#m</id>
            <title>R to @dotey: 注意这两句：
“7.rlhf 不一定是agi 的必经路径，因 rlhf是 hf部分决定了上限，怎么会通往 agi？
8.但rl是正确的，看好 multi agent，类比阿法狗，可以左脚踩右脚把能力提上去。”</title>
            <link>https://nitter.cz/dotey/status/1729201172232479001#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729201172232479001#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 18:11:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>注意这两句：<br />
“7.rlhf 不一定是agi 的必经路径，因 rlhf是 hf部分决定了上限，怎么会通往 agi？<br />
8.但rl是正确的，看好 multi agent，类比阿法狗，可以左脚踩右脚把能力提上去。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729194209901736340#m</id>
            <title>作者把这个冒险游戏的GPT的Prompt开源了
https://gist.github.com/levelsio/5bc87fd1b1ffbf4a705047bebd9b4790</title>
            <link>https://nitter.cz/dotey/status/1729194209901736340#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729194209901736340#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 17:43:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者把这个冒险游戏的GPT的Prompt开源了<br />
<a href="https://gist.github.com/levelsio/5bc87fd1b1ffbf4a705047bebd9b4790">gist.github.com/levelsio/5bc…</a></p>
<p><a href="https://nitter.cz/levelsio/status/1728951317945868729#m">nitter.cz/levelsio/status/1728951317945868729#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyODMwOTI4NTAyODAyMDIyNC84MzFnbzNucD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729192550836379884#m</id>
            <title>推荐一期播客：OpenAI员工的最新采访 by 宇宙中猫

是在OpenAI罢免CEO风波之后的采访，很有意思。内容摘要小红书上已经有网友“互联网小牛马”整理过了 https://www.xiaohongshu.com/explore/656474b60000000032039445?app_platform=ios&amp;app_version=8.14.3&amp;share_from_user_hidden=true&amp;type=normal&amp;xhsshare=WeixinSession&amp;appuid=56a190f8b8ce1a0b0a953c02&amp;apptime=1701097747&amp;wechatWid=0ddb52dd6a4d2921b20bc73938f352fe&amp;wechatOrigin=menu 。

Apple Podcasts地址：https://podcasts.apple.com/us/podcast/openai%E5%91%98%E5%B7%A5%E7%9A%84%E6%9C%80%E6%96%B0%E9%87%87%E8%AE%BF/id1659350101?i=1000635637754
小宇宙地址：https://www.xiaoyuzhoufm.com/episode/655d835e6b842b8902affc85</title>
            <link>https://nitter.cz/dotey/status/1729192550836379884#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729192550836379884#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 17:36:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一期播客：OpenAI员工的最新采访 by 宇宙中猫<br />
<br />
是在OpenAI罢免CEO风波之后的采访，很有意思。内容摘要小红书上已经有网友“互联网小牛马”整理过了 <a href="https://www.xiaohongshu.com/explore/656474b60000000032039445?app_platform=ios&amp;app_version=8.14.3&amp;share_from_user_hidden=true&amp;type=normal&amp;xhsshare=WeixinSession&amp;appuid=56a190f8b8ce1a0b0a953c02&amp;apptime=1701097747&amp;wechatWid=0ddb52dd6a4d2921b20bc73938f352fe&amp;wechatOrigin=menu">xiaohongshu.com/explore/6564…</a> 。<br />
<br />
Apple Podcasts地址：<a href="https://podcasts.apple.com/us/podcast/openai%E5%91%98%E5%B7%A5%E7%9A%84%E6%9C%80%E6%96%B0%E9%87%87%E8%AE%BF/id1659350101?i=1000635637754">podcasts.apple.com/us/podcas…</a><br />
小宇宙地址：<a href="https://www.xiaoyuzhoufm.com/episode/655d835e6b842b8902affc85">xiaoyuzhoufm.com/episode/655…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85U3VmUlhzQUVWeHpMLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85U3hqQlhRQUFneXJULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729178839191081077#m</id>
            <title>核心就是得做中学</title>
            <link>https://nitter.cz/dotey/status/1729178839191081077#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729178839191081077#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:42:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>核心就是得做中学</p>
<p><a href="https://nitter.cz/gdb/status/1729162836499472734#m">nitter.cz/gdb/status/1729162836499472734#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729172682758054147#m</id>
            <title>RT by @dotey: Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。
将这种方法扩展是否能实现通用人工智能（AGI）？不会。
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</title>
            <link>https://nitter.cz/op7418/status/1729172682758054147#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729172682758054147#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:17:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：<br />
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。<br />
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。<br />
将这种方法扩展是否能实现通用人工智能（AGI）？不会。<br />
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。<br />
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</p>
<p><a href="https://nitter.cz/DrJimFan/status/1729162728072433876#m">nitter.cz/DrJimFan/status/1729162728072433876#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</id>
            <title>RT by @dotey: 建议和这篇《为什么你不该加入 Y Combinator》https://readit.vip/a/e0Bwj  一起阅读。

作者反对保罗这种只以增长为目标的做法。

1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</title>
            <link>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</link>
            <guid isPermaLink="false">https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 13:57:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>建议和这篇《为什么你不该加入 Y Combinator》<a href="https://readit.vip/a/e0Bwj">readit.vip/a/e0Bwj</a>  一起阅读。<br />
<br />
作者反对保罗这种只以增长为目标的做法。<br />
<br />
1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。<br />
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZXRtdmFrQUFMRFBtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZnFEcWJnQUFhMGJ2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Tisoga/status/1729017824092549247#m</id>
            <title>RT by @dotey: 这应该就是做产品最希望收到的评价吧。

另外 http://devv.ai 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。

欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</title>
            <link>https://nitter.cz/Tisoga/status/1729017824092549247#m</link>
            <guid isPermaLink="false">https://nitter.cz/Tisoga/status/1729017824092549247#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:02:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这应该就是做产品最希望收到的评价吧。<br />
<br />
另外 <a href="http://devv.ai">devv.ai</a> 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。<br />
<br />
欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82ejBRVmIwQUFYUDAzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729026599411225075#m</id>
            <title>R to @dotey: 谢谢</title>
            <link>https://nitter.cz/dotey/status/1729026599411225075#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729026599411225075#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:37:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谢谢</p>
<p><a href="https://nitter.cz/Nag1ovo/status/1729018702048493634#m">nitter.cz/Nag1ovo/status/1729018702048493634#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728998748272156761#m</id>
            <title>R to @dotey: 相应的GitHub项目：https://github.com/SurviveSJTU/SJTU-Application</title>
            <link>https://nitter.cz/dotey/status/1728998748272156761#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728998748272156761#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:46:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>相应的GitHub项目：<a href="https://github.com/SurviveSJTU/SJTU-Application">github.com/SurviveSJTU/SJTU-…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNzQ2NzQ2MzM3NjMwMjA4MC9uaEdRYmZRRD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728997603847675923#m</id>
            <title>推荐GitBook：
https://survivesjtu.gitbook.io/survivesjtumanual/

于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</title>
            <link>https://nitter.cz/dotey/status/1728997603847675923#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728997603847675923#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:42:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐GitBook：<上海交通大学生存手册><br />
<a href="https://survivesjtu.gitbook.io/survivesjtumanual/">survivesjtu.gitbook.io/survi…</a><br />
<br />
<上海交通大学生存手册>于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82aUl1SldRQUFwblExLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728976294195429627#m</id>
            <title>R to @dotey: ## Summary so far

构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。

Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。

## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard

在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。

关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选

部分形成最优答案，或者让模型帮助检查工作。

在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</title>
            <link>https://nitter.cz/dotey/status/1728976294195429627#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728976294195429627#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:17:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## Summary so far<br />
<br />
构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。<br />
<br />
Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。<br />
<br />
## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard<br />
<br />
在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。<br />
<br />
关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选<br />
<br />
部分形成最优答案，或者让模型帮助检查工作。<br />
<br />
在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzU3MzY0MTU5MzY1MTMvcHUvaW1nL29uOVlkdzV1WTdGdkx5V2MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728974703895711948#m</id>
            <title>R to @dotey: ## How do they work?

好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。

但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。

我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。

这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。

它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要

相应的复杂评估来处理这些模型，因为它们主要是基于经验的。

## Finetuning into an Assistant

现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。

获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”

接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。

所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。

这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</title>
            <link>https://nitter.cz/dotey/status/1728974703895711948#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728974703895711948#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:11:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## How do they work?<br />
<br />
好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。<br />
<br />
但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。<br />
<br />
我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。<br />
<br />
这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。<br />
<br />
它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要<br />
<br />
相应的复杂评估来处理这些模型，因为它们主要是基于经验的。<br />
<br />
## Finetuning into an Assistant<br />
<br />
现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。<br />
<br />
获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”<br />
<br />
接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。<br />
<br />
所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。<br />
<br />
这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzM4NzQ4MzY5NzE1MjAvcHUvaW1nL0wxZHl1ZFRFTDM5SFB2NmsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</id>
            <title>RT by @dotey: Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章

Loom基于GPT-3，采用了一种独特的树形结构来组织文本。

每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

举例解释：

假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。

1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。

2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。

3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。

4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。

6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。

通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。

Loom的主要特点和功能包括：

1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。

2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。

3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。

4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。

5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。

6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。

5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。

GitHub：https://github.com/socketteer/loom
实例：https://generative.ink/meta/block-multiverse/</title>
            <link>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728963473152045089#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章<br />
<br />
Loom基于GPT-3，采用了一种独特的树形结构来组织文本。<br />
<br />
每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
举例解释：<br />
<br />
假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。<br />
<br />
1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。<br />
<br />
2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。<br />
<br />
3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。<br />
<br />
4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。<br />
<br />
6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。<br />
<br />
通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。<br />
<br />
Loom的主要特点和功能包括：<br />
<br />
1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。<br />
<br />
2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。<br />
<br />
3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。<br />
<br />
4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。<br />
<br />
5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。<br />
<br />
6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。<br />
<br />
5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。<br />
<br />
GitHub：<a href="https://github.com/socketteer/loom">github.com/socketteer/loom</a><br />
实例：<a href="https://generative.ink/meta/block-multiverse/">generative.ink/meta/block-mu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRV2JjQUF6dFY4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRMmJjQUFtSzZILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhReWE0QUFKZ2NLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRd2FjQUFRa2t3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</id>
            <title>RT by @dotey: UIDraw：在手机上画草图，自动生成H5页面
一个SwiftUI项目，使用GPT-4V实现写HTML界面。
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。
Github：https://github.com/jordansinger/UIDraw</title>
            <link>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:25:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>UIDraw：在手机上画草图，自动生成H5页面<br />
一个SwiftUI项目，使用GPT-4V实现写HTML界面。<br />
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。<br />
Github：<a href="https://github.com/jordansinger/UIDraw">github.com/jordansinger/UIDr…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjMxMjg4ODM2MDU1MDQvcHUvaW1nLzRFbEx2WGJEeHlYYUtiUGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728962389830238296#m</id>
            <title>R to @dotey: ## LLM Training

但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。

因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。

你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。

但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。

这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。

那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。

你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个

词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。

所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。

我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。

## LLM Dreams

那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。

可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。

比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。

但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</title>
            <link>https://nitter.cz/dotey/status/1728962389830238296#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728962389830238296#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:22:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## LLM Training<br />
<br />
但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。<br />
<br />
因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。<br />
<br />
你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。<br />
<br />
但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。<br />
<br />
这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。<br />
<br />
那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。<br />
<br />
你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个<br />
<br />
词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。<br />
<br />
所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。<br />
<br />
我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。<br />
<br />
## LLM Dreams<br />
<br />
那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。<br />
<br />
可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。<br />
<br />
比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。<br />
<br />
但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjE4MTc2MjIyNDEyODEvcHUvaW1nL3pCck1GN1Vzenpnc0RNNm8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>