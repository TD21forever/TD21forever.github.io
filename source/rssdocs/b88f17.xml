<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727568964065382411#m</id>
            <title>RT by @dotey: 更多Q*（Q-Star）信息爆料和猜测：

- Q*可能具备自主学习和自我改进的能力。

- Q*模型可进行自主决策，可能已具备轻微自我意识。

- GPT-Zero项目解决了数据问题，自己”生产“数据。

- OpenAI可能正在利用计算机合成数据进行训练。

据Reddit用户爆料和猜测：Q*可能是一种非常先进的具有“可怕数学能力”的模型，已经具备自主学习和自我改进的能力。

该模型能够通过评估其行为的长期后果，在广泛的场景中做出复杂的决策。

Q*可能与强化学习中的Q-learning算法有关，这是一种评估在特定情境下采取特定行动的好坏的方法。还提到了Q-Value和Bellman方程，这些都是强化学习中的重要概念，用于指导AI在不同情境下做出最优决策。

简而言之，Q*似乎是一个高级的人工智能模型，能够在多种情境中学习和做出最优决策，具有自主学习和自我改进的能力。

Reddit原帖：https://www.reddit.com/r/OpenAI/comments/181n8am/what_is_q/

而根据@theinformation 今天的报道，OpenAI的首席科学家 Ilya Sutskever 领衔的一个名叫 GPT-Zero 的项目实现了巨大突破。他们克服了训练数据限制的困难，可以自己合成训练数据。

 据悉，Ilya Sutskever的 GPT-Zero 的项目，帮助 OpenAI 克服了在获取足够高质量数据来训练新模型方面的限制。

此前Ilya在一次采访中说到：

“Without going into details I'll just say the Data Limit can be overcome..."  

“无需详细说明，我只是说数据限制是可以克服的......”  

GPT-Zero项目研究的主要使用计算机生成的数据来训练模型，而不是从互联网上提取的真实世界数据，因为OpenAI已经获得了互联网上能获得的几乎所有的真实文本数据，已经无法再获得足够的数据来进行下一阶段训练。

OpenAI 研究团队利用GPT-Zero这一创新成果，构建了能解决基础数学问题的模型，这一直是现有 AI 模型的难题，无法进行复杂的推理能力。两位顶尖研究人员 Jakub Pachocki 和 Szymon Sidor 运用 Ilya Sutskever 的研究成果，开发出了这个名为 Q*（Q-Star）的模型。

Theinformation报道：https://www.theinformation.com/articles/openai-made-an-ai-breakthrough-before-altman-firing-stoking-excitement-and-concern

而本月奥特曼在接受金融时报采访的时候曾表达：开发 AGI 的最大挑战之一是使这些系统能够进行基本的理解和创新。

他比喻说，就像艾萨克·牛顿（Isaac Newton）发明微积分一样，AI 模型也需要能够超越现有知识，创造新的知识的能力。

种种迹象表明Q*（Q-Star）的模型确实是超越了GPT 4非常多的模型，可以说是直接跨越了几代，具有自主学习和自我改进的能力，甚至就像之前Ilya表达的可能已经表现出了轻微的自我意识能力。

以上内容为综合报道、爆料的可能性猜测总结，不一定准确，请注意分辨！</title>
            <link>https://nitter.cz/xiaohuggg/status/1727568964065382411#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727568964065382411#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 06:05:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>更多Q*（Q-Star）信息爆料和猜测：<br />
<br />
- Q*可能具备自主学习和自我改进的能力。<br />
<br />
- Q*模型可进行自主决策，可能已具备轻微自我意识。<br />
<br />
- GPT-Zero项目解决了数据问题，自己”生产“数据。<br />
<br />
- OpenAI可能正在利用计算机合成数据进行训练。<br />
<br />
据Reddit用户爆料和猜测：Q*可能是一种非常先进的具有“可怕数学能力”的模型，已经具备自主学习和自我改进的能力。<br />
<br />
该模型能够通过评估其行为的长期后果，在广泛的场景中做出复杂的决策。<br />
<br />
Q*可能与强化学习中的Q-learning算法有关，这是一种评估在特定情境下采取特定行动的好坏的方法。还提到了Q-Value和Bellman方程，这些都是强化学习中的重要概念，用于指导AI在不同情境下做出最优决策。<br />
<br />
简而言之，Q*似乎是一个高级的人工智能模型，能够在多种情境中学习和做出最优决策，具有自主学习和自我改进的能力。<br />
<br />
Reddit原帖：<a href="https://teddit.net/r/OpenAI/comments/181n8am/what_is_q/">teddit.net/r/OpenAI/comments…</a><br />
<br />
而根据<a href="https://nitter.cz/theinformation" title="The Information">@theinformation</a> 今天的报道，OpenAI的首席科学家 Ilya Sutskever 领衔的一个名叫 GPT-Zero 的项目实现了巨大突破。他们克服了训练数据限制的困难，可以自己合成训练数据。<br />
<br />
 据悉，Ilya Sutskever的 GPT-Zero 的项目，帮助 OpenAI 克服了在获取足够高质量数据来训练新模型方面的限制。<br />
<br />
此前Ilya在一次采访中说到：<br />
<br />
“Without going into details I'll just say the Data Limit can be overcome..."  <br />
<br />
“无需详细说明，我只是说数据限制是可以克服的......”  <br />
<br />
GPT-Zero项目研究的主要使用计算机生成的数据来训练模型，而不是从互联网上提取的真实世界数据，因为OpenAI已经获得了互联网上能获得的几乎所有的真实文本数据，已经无法再获得足够的数据来进行下一阶段训练。<br />
<br />
OpenAI 研究团队利用GPT-Zero这一创新成果，构建了能解决基础数学问题的模型，这一直是现有 AI 模型的难题，无法进行复杂的推理能力。两位顶尖研究人员 Jakub Pachocki 和 Szymon Sidor 运用 Ilya Sutskever 的研究成果，开发出了这个名为 Q*（Q-Star）的模型。<br />
<br />
Theinformation报道：<a href="https://www.theinformation.com/articles/openai-made-an-ai-breakthrough-before-altman-firing-stoking-excitement-and-concern">theinformation.com/articles/…</a><br />
<br />
而本月奥特曼在接受金融时报采访的时候曾表达：开发 AGI 的最大挑战之一是使这些系统能够进行基本的理解和创新。<br />
<br />
他比喻说，就像艾萨克·牛顿（Isaac Newton）发明微积分一样，AI 模型也需要能够超越现有知识，创造新的知识的能力。<br />
<br />
种种迹象表明Q*（Q-Star）的模型确实是超越了GPT 4非常多的模型，可以说是直接跨越了几代，具有自主学习和自我改进的能力，甚至就像之前Ilya表达的可能已经表现出了轻微的自我意识能力。<br />
<br />
以上内容为综合报道、爆料的可能性猜测总结，不一定准确，请注意分辨！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9tS2RGYWE4QUFQRVdTLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9tT1BPdmJnQUE5Q3UxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/huangyun_122/status/1727360100283896056#m</id>
            <title>RT by @dotey: 这哥们，凭一己之力，硬把 Stable Diffusion 的玩法，都开源了出来

https://stable-diffusion-art.com/sdxl-model/#Download_and_install_SDXL_10_models

实在心疼自己的笔记本，烧到 86°后，最终还是移到 Google Colab 上玩

但，如果不是 G-Colab Pro, 时不时会被 G-Colab 掐掉，导致每次都要重连。

还是付费香，办了会员，把 runtime 拉到最大，效率起来了</title>
            <link>https://nitter.cz/huangyun_122/status/1727360100283896056#m</link>
            <guid isPermaLink="false">https://nitter.cz/huangyun_122/status/1727360100283896056#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 16:15:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这哥们，凭一己之力，硬把 Stable Diffusion 的玩法，都开源了出来<br />
<br />
<a href="https://stable-diffusion-art.com/sdxl-model/#Download_and_install_SDXL_10_models">stable-diffusion-art.com/sdx…</a><br />
<br />
实在心疼自己的笔记本，烧到 86°后，最终还是移到 Google Colab 上玩<br />
<br />
但，如果不是 G-Colab Pro, 时不时会被 G-Colab 掐掉，导致每次都要重连。<br />
<br />
还是付费香，办了会员，把 runtime 拉到最大，效率起来了</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9qUC1VX1hBQUFFU2sxLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9qUXpoOFhvQUFpb3A4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727563974479057028#m</id>
            <title>OpenAI “宫斗”大戏人物关系图</title>
            <link>https://nitter.cz/dotey/status/1727563974479057028#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727563974479057028#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 05:45:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI “宫斗”大戏人物关系图</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9tS1JrRVc0QUFCdGMyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xicilion/status/1727554090987843753#m</id>
            <title>RT by @dotey: Claude 2 有效信息 20k，gpt4 有效信息 64k，超过这个信息量，便会选择性遗忘。</title>
            <link>https://nitter.cz/xicilion/status/1727554090987843753#m</link>
            <guid isPermaLink="false">https://nitter.cz/xicilion/status/1727554090987843753#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 05:06:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Claude 2 有效信息 20k，gpt4 有效信息 64k，超过这个信息量，便会选择性遗忘。</p>
<p><a href="https://nitter.cz/dotey/status/1727454708627808261#m">nitter.cz/dotey/status/1727454708627808261#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727556370507972669#m</id>
            <title>R to @dotey: 斧正：“然而，就在第二天，董事会宣布解雇了 Altman。”之后的内容不属于原文，不小心添加进去无法删除，请注意过滤。</title>
            <link>https://nitter.cz/dotey/status/1727556370507972669#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727556370507972669#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 05:15:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>斧正：“然而，就在第二天，董事会宣布解雇了 Altman。”之后的内容不属于原文，不小心添加进去无法删除，请注意过滤。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727549427278086281#m</id>
            <title>R to @dotey: reddit.com/r/singularity/com…</title>
            <link>https://nitter.cz/dotey/status/1727549427278086281#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727549427278086281#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 04:47:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://teddit.net/r/singularity/comments/181oe7i/openai_made_an_ai_breakthrough_before_altman/">teddit.net/r/singularity/com…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNzUxMDM3MzU3NjkzNzQ3Mi9PR2NTcDZkUD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727549316779094080#m</id>
            <title>R to @dotey: Reddit上的讨论帖：https://www.reddit.com/r/OpenAI/comments/181n8am/what_is_q/</title>
            <link>https://nitter.cz/dotey/status/1727549316779094080#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727549316779094080#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 04:47:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Reddit上的讨论帖：<a href="https://teddit.net/r/OpenAI/comments/181n8am/what_is_q/">teddit.net/r/OpenAI/comments…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNzUwMDA3MDcwNTA0MTQwOC92UERLNlA3Zj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727548654108475558#m</id>
            <title>不知道你们还记不记得当年 Google 的 Alpha Go，就是下围棋超级牛的人工智能，早已经打赢了人类。而且值得一提的是，最开始它是用人类的棋谱训练的，后来在人类的棋谱训练完了后，它开始自己和自己下棋，也就是说是自己生成棋谱自己训练自己。

在GPT-4训练的时候，几乎用到了所有互联网上能用到的文本，很多人都担心GPT-4训练完了后在没有高质量的文本供训练了。

在前面《独家：OpenAI 研究员在 CEO 被撤职前向董事会发出 AI 突破警告 — 据知情人士透露》https://twitter.com/dotey/status/1727510593970561466 那篇文章中，提到了OpenAI的一个神秘项目叫Q-Star，而这个项目背后的一些秘密正在被一点点的揭开神秘面纱。

根据 theinformation《OpenAI Made an AI Breakthrough Before Altman Firing, Stoking Excitement and Concern》的这篇报道中，提到了一个细节：“他们的研究主要使用计算机生成的数据，而不是从互联网上提取的真实世界数据，如文本或图像来训练新模型。”

这意味着他们也像AlphaGo一样，实现了让计算机生成无限的高质量数据，而不需要去互联网上抓取数据！！！

现在还不知道这篇报道的准确性如何，但是结合这些信息，可能性还是相当大的！很期待不久能看到GPT-5的发布！

《OpenAI Made an AI Breakthrough Before Altman Firing, Stoking Excitement and Concern》部分内容翻译：

----

OpenAI 在 Sam Altman 被解雇前夕实现重大 AI 突破，引发期待与忧虑

在 Sam Altman 上周被 OpenAI 董事会解雇的前一天，他曾在 APEC 首席执行官峰会上暗示该公司最近取得了一项技术进展。他表示，这一进展让公司能够揭开无知的面纱，推进知识的边界。这番神秘的言论在公司陷入混乱之际并未引起太多关注。

据知情人士透露，部分 OpenAI 员工认为 Altman 的这番话是在提及公司研究人员今年早些时候的一项创新。这项创新可能使他们能够开发出更强大的人工智能模型。然而，由首席科学家 Ilya Sutskever 领衔的这一技术突破，也引发了一些员工的担忧，他们认为公司在商业化这些高级 AI 模型时可能缺乏适当的安全措施。

据悉，Sutskever 的这一突破帮助 OpenAI 克服了在获取足够高质量数据来训练新模型方面的限制。这一直是开发下一代模型的主要障碍。他们的研究主要使用计算机生成的数据，而不是从互联网上提取的真实世界数据，如文本或图像来训练新模型。

多年来，Sutskever 一直致力于研究如何让像 GPT-4 这样的语言模型解决涉及推理的任务，例如数学或科学问题。2021 年，他启动了一个名为 GPT-Zero 的项目，以向 DeepMind 的 AlphaZero 程序致敬，后者能够下国际象棋、围棋和将棋。

OpenAI 研究团队利用这一创新成果，构建了能解决基础数学问题的系统，这一直是现有 AI 模型的难题。两位顶尖研究人员 Jakub Pachocki 和 Szymon Sidor 运用 Sutskever 的研究成果，开发出了一个名为 Q*（“Q-Star”）的模型。</title>
            <link>https://nitter.cz/dotey/status/1727548654108475558#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727548654108475558#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 04:44:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>不知道你们还记不记得当年 Google 的 Alpha Go，就是下围棋超级牛的人工智能，早已经打赢了人类。而且值得一提的是，最开始它是用人类的棋谱训练的，后来在人类的棋谱训练完了后，它开始自己和自己下棋，也就是说是自己生成棋谱自己训练自己。<br />
<br />
在GPT-4训练的时候，几乎用到了所有互联网上能用到的文本，很多人都担心GPT-4训练完了后在没有高质量的文本供训练了。<br />
<br />
在前面《独家：OpenAI 研究员在 CEO 被撤职前向董事会发出 AI 突破警告 — 据知情人士透露》<a href="https://nitter.cz/dotey/status/1727510593970561466">nitter.cz/dotey/status/172…</a> 那篇文章中，提到了OpenAI的一个神秘项目叫Q-Star，而这个项目背后的一些秘密正在被一点点的揭开神秘面纱。<br />
<br />
根据 theinformation《OpenAI Made an AI Breakthrough Before Altman Firing, Stoking Excitement and Concern》的这篇报道中，提到了一个细节：“他们的研究主要使用计算机生成的数据，而不是从互联网上提取的真实世界数据，如文本或图像来训练新模型。”<br />
<br />
这意味着他们也像AlphaGo一样，实现了让计算机生成无限的高质量数据，而不需要去互联网上抓取数据！！！<br />
<br />
现在还不知道这篇报道的准确性如何，但是结合这些信息，可能性还是相当大的！很期待不久能看到GPT-5的发布！<br />
<br />
《OpenAI Made an AI Breakthrough Before Altman Firing, Stoking Excitement and Concern》部分内容翻译：<br />
<br />
----<br />
<br />
OpenAI 在 Sam Altman 被解雇前夕实现重大 AI 突破，引发期待与忧虑<br />
<br />
在 Sam Altman 上周被 OpenAI 董事会解雇的前一天，他曾在 APEC 首席执行官峰会上暗示该公司最近取得了一项技术进展。他表示，这一进展让公司能够揭开无知的面纱，推进知识的边界。这番神秘的言论在公司陷入混乱之际并未引起太多关注。<br />
<br />
据知情人士透露，部分 OpenAI 员工认为 Altman 的这番话是在提及公司研究人员今年早些时候的一项创新。这项创新可能使他们能够开发出更强大的人工智能模型。然而，由首席科学家 Ilya Sutskever 领衔的这一技术突破，也引发了一些员工的担忧，他们认为公司在商业化这些高级 AI 模型时可能缺乏适当的安全措施。<br />
<br />
据悉，Sutskever 的这一突破帮助 OpenAI 克服了在获取足够高质量数据来训练新模型方面的限制。这一直是开发下一代模型的主要障碍。他们的研究主要使用计算机生成的数据，而不是从互联网上提取的真实世界数据，如文本或图像来训练新模型。<br />
<br />
多年来，Sutskever 一直致力于研究如何让像 GPT-4 这样的语言模型解决涉及推理的任务，例如数学或科学问题。2021 年，他启动了一个名为 GPT-Zero 的项目，以向 DeepMind 的 AlphaZero 程序致敬，后者能够下国际象棋、围棋和将棋。<br />
<br />
OpenAI 研究团队利用这一创新成果，构建了能解决基础数学问题的系统，这一直是现有 AI 模型的难题。两位顶尖研究人员 Jakub Pachocki 和 Szymon Sidor 运用 Sutskever 的研究成果，开发出了一个名为 Q*（“Q-Star”）的模型。</p>
<p><a href="https://nitter.cz/bindureddy/status/1727479646315237784#m">nitter.cz/bindureddy/status/1727479646315237784#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9sOERaR1cwQUFBVUZnLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9sOEtuQ1dVQUF3UDRDLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727530341202563280#m</id>
            <title>刚发现Ilya也转发了，看起来状态还不错，希望他们能继续合作</title>
            <link>https://nitter.cz/dotey/status/1727530341202563280#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727530341202563280#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 03:31:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚发现Ilya也转发了，看起来状态还不错，希望他们能继续合作</p>
<p><a href="https://nitter.cz/ilyasut/status/1727434066411286557#m">nitter.cz/ilyasut/status/1727434066411286557#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727517538722914365#m</id>
            <title>训练过的不算多牛，出个没训练过的就知道了</title>
            <link>https://nitter.cz/dotey/status/1727517538722914365#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727517538722914365#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 02:40:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>训练过的不算多牛，出个没训练过的就知道了</p>
<p><a href="https://nitter.cz/66567848787A/status/1727368263032799512#m">nitter.cz/66567848787A/status/1727368263032799512#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/waylybaye/status/1727510389087433103#m</id>
            <title>RT by @dotey: OpenCat 1.8.3 更新啦，将生成图片的功能带到了 iOS 上 🥳</title>
            <link>https://nitter.cz/waylybaye/status/1727510389087433103#m</link>
            <guid isPermaLink="false">https://nitter.cz/waylybaye/status/1727510389087433103#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 02:12:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenCat 1.8.3 更新啦，将生成图片的功能带到了 iOS 上 🥳</p>
<p><a href="https://nitter.cz/waylybaye/status/1722413580317073702#m">nitter.cz/waylybaye/status/1722413580317073702#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9sWmlvUmE4QUExOTl4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9sWmlvU2JJQUFGT0w4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727510593970561466#m</id>
            <title>转译：**独家：OpenAI 研究员在 CEO 被撤职前向董事会发出 AI 突破警告 — 据知情人士透露**

11 月 22 日（路透社）- 在 OpenAI 首席执行官 Sam Altman 被迫离职前的四天，几位公司研究员向董事会发送了一封紧急信函，警告他们说，他们发现了一种强大的人工智能技术，这种技术可能对人类构成威胁。这一消息是由两位了解内情的人士向路透社透露的。

这封此前未曾报道过的信件和相关的 AI 算法，是董事会决定撤换 Altman 的关键前奏。两位消息来源表示，Altman 被视为生成式 AI 的标志性人物。在他周二晚些时候的华丽归来之前，超过 700 名员工威胁要辞职，并表示将与被解雇的领导者一起支持投资者微软 (MSFT.O)。

这些消息来源指出，这封信只是导致 Altman 被解雇的众多不满之一。路透社未能查看这封信的副本。写信的研究人员并未立即回应置评请求。

据其中一位知情人士透露，资深高管 Mira Murati 上周三向员工提及了一个名为 Q* 的项目，并表示在周末发生的事件之前，已向董事会发送过一封信。

在报道发布后，一位 OpenAI 发言人表示，Murati 告诉员工媒体即将报道的内容，但她并未对报道的准确性发表评论。

制造 ChatGPT 的公司在 Q*（发音为 Q-Star）项目上取得了进展，一些内部人士认为这可能是该初创公司在追求超级智能（也称为人工通用智能，AGI）方向上的重大突破，一位人士告诉路透社。OpenAI 将 AGI 定义为智力超过人类的 AI 系统。

该人士表示，凭借庞大的计算资源，这个新模型能够解决一些数学问题。这位不愿透露姓名的人士说，尽管 Q* 目前的数学运算能力仅限于小学生水平，但它在这些测试中的出色表现让研究人员对其未来的成功充满期望。

路透社无法独立核实研究人员对 Q* 能力的说法。

**超级智能的挑战**
研究人员认为，数学是生成式 AI 发展的新前沿。目前，生成式 AI 在通过统计方法预测下一个词以进行写作和语言翻译方面表现良好，但面对同一个问题可能会有截然不同的答案。然而，掌握了数学运算——在这里只有一个正确答案——意味着 AI 将具备更接近人类的推理能力。AI 研究者相信，这一技术可以应用于创新的科学研究。

与只能执行有限运算的计算器不同，AGI 能够进行泛化学习和理解。

研究人员在给董事会的信中提到了 AI 的强大能力和潜在危险，但消息来源没有具体说明信中提到的安全问题。长期以来，计算机科学家一直在讨论超级智能机器可能带来的风险，比如它们可能会认为摧毁人类符合自身利益。

在这种背景下，Altman 领导着使 ChatGPT 成为史上增长最快的软件应用之一的努力，并从微软那里获得了投资和必要的计算资源，以更接近于实现超级智能或 AGI。

在本月早些时候展示了一系列新工具之后，上周 Altman 在旧金山举行的世界领袖聚会上暗示，他认为 AGI 已经近在眼前。

“在 OpenAI 的历史中，最近一次是在过去几周，我已经四次有幸亲身经历推动认知界限的拓展和发现的前沿，能够参与其中是我职业生涯中的极大荣誉，”他在亚太经济合作组织峰会上说。

然而，就在第二天，董事会宣布解雇了 Altman。

在 AI 安全和人工通用智能（AGI）定义上，存在激烈争议。Microsoft 对 OpenAI 投入巨资，但后者的条款明确规定，不得利用 AGI 追求利益。

OpenAI 宪章指出：无论是与 Microsoft 还是其他商业和知识产权许可协议，AGI 都被明确排除在外。

Sam Altman 意识到，即使是现阶段的原型 AGI，也足以推动公司业绩飙升，带来巨额利润和更多投资。因此，他们推出了 Dev Day、GPT 商店和收入分成模式。

这一做法引起了 OAI 董事会的不满，部分董事仍坚持初衷，认为 AGI 应致力于人类福祉，而非商业利益。他们担忧此举可能导致不安全模型的使用。

目前 AGI 的定义并不明确。若实现重大突破（如 Sam 所述），是否将其归为 AGI 取决于董事会的投票。若获得足够票数宣布其为 AGI，Microsoft 和 OpenAI 将失去数十亿潜在许可收入；反之，他们可以通过授权类似 AGI 技术获利。

几周或几个月前，OpenAI 团队取得重大进展，接近实现 AGI（由此产生的玩笑、泄露、氛围变化等）。然而，Sam 和 Brockman 对此隐瞒了董事会的非员工成员。Ilyas 对此感到不满，认为这应视为 AGI，不应授权给任何人，包括 Microsoft。当 AGI 状态的投票提上日程时，董事们因被蒙在鼓里而愤怒，最终决定开除 Sam 并迫使 Brockman 辞职。

Ilyas 近期声称，现有架构已足够实现 AGI，而 Sam 则坚持认为需要新的突破。在这种情况下，Sam 更倾向于将 AGI 商业化，而 Ilyas 则认为我们已经实现了 AGI。

Sam Altman 想要推迟宣布这一技术为 AGI，因为这样做可以延长盈利时间。相反，Ilya 希望尽快将其定性为 AGI，以便按照公司最初的原则使用，而非追求利润。最终，Ilya 在这场权力争斗中胜出。在 Microsoft 还未来得及干预之前，事情已经尘埃落定，因为 Microsoft 表示他们对这一进展毫不知情，而他们显然会倾向于延迟 AGI 的宣布。

更早宣布 AGI 意味着该技术不能被授权给任何方（因此其带来的利润将更具社会公平性，并迫使研究人员专注于一致性和安全），同时还意味着更多监管。可以想象，“人工通用智能已被发明”的新闻头条将在 /r/WorldNews 上引发轰动，引起全球范围内的恐慌，迫使各国政府召开紧急会议，确保不发生 Skynet 式的灾难，安全派对此表示欢迎。

如果不是这样，情况会有所不同。我们可能会继续推进当前的前沿模型和代理共享计划，而不将其定性为 AGI，这样 OAI 和 Microsoft 将因此获得巨大利益。对于关注安全的群体而言，这意味着 AGI 的发展将受到更少监管，同时被加州原则融入到 ChatGPT 和 DALL-E 的输出中，从而让 OAI 可以宣称“我们确实关心安全！”

Ilya 可能并非有意赶走 Sam，但当收入分享方案被提出，而 Sam 辩称 OAI 所拥有的技术并非 AGI 或类似之物时，这可能促使 Ilya 决定发起政变。OpenAI 当前可能计划很快宣布他们已经拥有 AGI，可能在接下来的 6 到 8 个月内，也许是通过部署 GPT-4.5 或比预期更早发布 GPT-5。或许甚至更早。

这并非源于技术突破；而是基于他们已有的技术。这只是一个围绕是否为了利润而将该技术称为 AGI 的争议和冲突。

https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/</title>
            <link>https://nitter.cz/dotey/status/1727510593970561466#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727510593970561466#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 02:13:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：**独家：OpenAI 研究员在 CEO 被撤职前向董事会发出 AI 突破警告 — 据知情人士透露**<br />
<br />
11 月 22 日（路透社）- 在 OpenAI 首席执行官 Sam Altman 被迫离职前的四天，几位公司研究员向董事会发送了一封紧急信函，警告他们说，他们发现了一种强大的人工智能技术，这种技术可能对人类构成威胁。这一消息是由两位了解内情的人士向路透社透露的。<br />
<br />
这封此前未曾报道过的信件和相关的 AI 算法，是董事会决定撤换 Altman 的关键前奏。两位消息来源表示，Altman 被视为生成式 AI 的标志性人物。在他周二晚些时候的华丽归来之前，超过 700 名员工威胁要辞职，并表示将与被解雇的领导者一起支持投资者微软 (MSFT.O)。<br />
<br />
这些消息来源指出，这封信只是导致 Altman 被解雇的众多不满之一。路透社未能查看这封信的副本。写信的研究人员并未立即回应置评请求。<br />
<br />
据其中一位知情人士透露，资深高管 Mira Murati 上周三向员工提及了一个名为 Q* 的项目，并表示在周末发生的事件之前，已向董事会发送过一封信。<br />
<br />
在报道发布后，一位 OpenAI 发言人表示，Murati 告诉员工媒体即将报道的内容，但她并未对报道的准确性发表评论。<br />
<br />
制造 ChatGPT 的公司在 Q*（发音为 Q-Star）项目上取得了进展，一些内部人士认为这可能是该初创公司在追求超级智能（也称为人工通用智能，AGI）方向上的重大突破，一位人士告诉路透社。OpenAI 将 AGI 定义为智力超过人类的 AI 系统。<br />
<br />
该人士表示，凭借庞大的计算资源，这个新模型能够解决一些数学问题。这位不愿透露姓名的人士说，尽管 Q* 目前的数学运算能力仅限于小学生水平，但它在这些测试中的出色表现让研究人员对其未来的成功充满期望。<br />
<br />
路透社无法独立核实研究人员对 Q* 能力的说法。<br />
<br />
**超级智能的挑战**<br />
研究人员认为，数学是生成式 AI 发展的新前沿。目前，生成式 AI 在通过统计方法预测下一个词以进行写作和语言翻译方面表现良好，但面对同一个问题可能会有截然不同的答案。然而，掌握了数学运算——在这里只有一个正确答案——意味着 AI 将具备更接近人类的推理能力。AI 研究者相信，这一技术可以应用于创新的科学研究。<br />
<br />
与只能执行有限运算的计算器不同，AGI 能够进行泛化学习和理解。<br />
<br />
研究人员在给董事会的信中提到了 AI 的强大能力和潜在危险，但消息来源没有具体说明信中提到的安全问题。长期以来，计算机科学家一直在讨论超级智能机器可能带来的风险，比如它们可能会认为摧毁人类符合自身利益。<br />
<br />
在这种背景下，Altman 领导着使 ChatGPT 成为史上增长最快的软件应用之一的努力，并从微软那里获得了投资和必要的计算资源，以更接近于实现超级智能或 AGI。<br />
<br />
在本月早些时候展示了一系列新工具之后，上周 Altman 在旧金山举行的世界领袖聚会上暗示，他认为 AGI 已经近在眼前。<br />
<br />
“在 OpenAI 的历史中，最近一次是在过去几周，我已经四次有幸亲身经历推动认知界限的拓展和发现的前沿，能够参与其中是我职业生涯中的极大荣誉，”他在亚太经济合作组织峰会上说。<br />
<br />
然而，就在第二天，董事会宣布解雇了 Altman。<br />
<br />
在 AI 安全和人工通用智能（AGI）定义上，存在激烈争议。Microsoft 对 OpenAI 投入巨资，但后者的条款明确规定，不得利用 AGI 追求利益。<br />
<br />
OpenAI 宪章指出：无论是与 Microsoft 还是其他商业和知识产权许可协议，AGI 都被明确排除在外。<br />
<br />
Sam Altman 意识到，即使是现阶段的原型 AGI，也足以推动公司业绩飙升，带来巨额利润和更多投资。因此，他们推出了 Dev Day、GPT 商店和收入分成模式。<br />
<br />
这一做法引起了 OAI 董事会的不满，部分董事仍坚持初衷，认为 AGI 应致力于人类福祉，而非商业利益。他们担忧此举可能导致不安全模型的使用。<br />
<br />
目前 AGI 的定义并不明确。若实现重大突破（如 Sam 所述），是否将其归为 AGI 取决于董事会的投票。若获得足够票数宣布其为 AGI，Microsoft 和 OpenAI 将失去数十亿潜在许可收入；反之，他们可以通过授权类似 AGI 技术获利。<br />
<br />
几周或几个月前，OpenAI 团队取得重大进展，接近实现 AGI（由此产生的玩笑、泄露、氛围变化等）。然而，Sam 和 Brockman 对此隐瞒了董事会的非员工成员。Ilyas 对此感到不满，认为这应视为 AGI，不应授权给任何人，包括 Microsoft。当 AGI 状态的投票提上日程时，董事们因被蒙在鼓里而愤怒，最终决定开除 Sam 并迫使 Brockman 辞职。<br />
<br />
Ilyas 近期声称，现有架构已足够实现 AGI，而 Sam 则坚持认为需要新的突破。在这种情况下，Sam 更倾向于将 AGI 商业化，而 Ilyas 则认为我们已经实现了 AGI。<br />
<br />
Sam Altman 想要推迟宣布这一技术为 AGI，因为这样做可以延长盈利时间。相反，Ilya 希望尽快将其定性为 AGI，以便按照公司最初的原则使用，而非追求利润。最终，Ilya 在这场权力争斗中胜出。在 Microsoft 还未来得及干预之前，事情已经尘埃落定，因为 Microsoft 表示他们对这一进展毫不知情，而他们显然会倾向于延迟 AGI 的宣布。<br />
<br />
更早宣布 AGI 意味着该技术不能被授权给任何方（因此其带来的利润将更具社会公平性，并迫使研究人员专注于一致性和安全），同时还意味着更多监管。可以想象，“人工通用智能已被发明”的新闻头条将在 /r/WorldNews 上引发轰动，引起全球范围内的恐慌，迫使各国政府召开紧急会议，确保不发生 Skynet 式的灾难，安全派对此表示欢迎。<br />
<br />
如果不是这样，情况会有所不同。我们可能会继续推进当前的前沿模型和代理共享计划，而不将其定性为 AGI，这样 OAI 和 Microsoft 将因此获得巨大利益。对于关注安全的群体而言，这意味着 AGI 的发展将受到更少监管，同时被加州原则融入到 ChatGPT 和 DALL-E 的输出中，从而让 OAI 可以宣称“我们确实关心安全！”<br />
<br />
Ilya 可能并非有意赶走 Sam，但当收入分享方案被提出，而 Sam 辩称 OAI 所拥有的技术并非 AGI 或类似之物时，这可能促使 Ilya 决定发起政变。OpenAI 当前可能计划很快宣布他们已经拥有 AGI，可能在接下来的 6 到 8 个月内，也许是通过部署 GPT-4.5 或比预期更早发布 GPT-5。或许甚至更早。<br />
<br />
这并非源于技术突破；而是基于他们已有的技术。这只是一个围绕是否为了利润而将该技术称为 AGI 的争议和冲突。<br />
<br />
<a href="https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/">reuters.com/technology/sam-a…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727489479156318487#m</id>
            <title>1. 你自己要捋清楚其中的成本、收益和风险，也许没必要

2. 要让manager清楚收益远大于成本和风险

3. 要有清晰的计划，让Manager知道不会影响当前项目进展，例如：
-将要重构的模块列出来，加上T恤size
-先补充测试代码不会让重构影响质量
-将所有任务用任务管理跟踪工具跟踪起来
-每个Sprint完成一部分而不需要专门停下来做这事</title>
            <link>https://nitter.cz/dotey/status/1727489479156318487#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727489479156318487#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 00:49:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>1. 你自己要捋清楚其中的成本、收益和风险，也许没必要<br />
<br />
2. 要让manager清楚收益远大于成本和风险<br />
<br />
3. 要有清晰的计划，让Manager知道不会影响当前项目进展，例如：<br />
-将要重构的模块列出来，加上T恤size<br />
-先补充测试代码不会让重构影响质量<br />
-将所有任务用任务管理跟踪工具跟踪起来<br />
-每个Sprint完成一部分而不需要专门停下来做这事</p>
<p><a href="https://nitter.cz/beihuo/status/1727449107005067545#m">nitter.cz/beihuo/status/1727449107005067545#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727468251154620804#m</id>
            <title>#AI开源项目推荐：vscode-ui-sketcher

UI Sketcher是一个VSCode插件，借助GPT-4V的多模态能力，在插件中画出界面草图，就能生成一个基于ReactNative的UI界面。

需要OpenAI的API Key

https://github.com/pAIrprogio/vscode-ui-sketcher</title>
            <link>https://nitter.cz/dotey/status/1727468251154620804#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727468251154620804#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 23:25:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：vscode-ui-sketcher<br />
<br />
UI Sketcher是一个VSCode插件，借助GPT-4V的多模态能力，在插件中画出界面草图，就能生成一个基于ReactNative的UI界面。<br />
<br />
需要OpenAI的API Key<br />
<br />
<a href="https://github.com/pAIrprogio/vscode-ui-sketcher">github.com/pAIrprogio/vscode…</a></p>
<p><a href="https://nitter.cz/taishiyadeee/status/1727175786963300531#m">nitter.cz/taishiyadeee/status/1727175786963300531#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/yumimao/status/1727240174994874805#m</id>
            <title>RT by @dotey: https://www.fal.ai/dynamic 一个简单的在线体验网站</title>
            <link>https://nitter.cz/yumimao/status/1727240174994874805#m</link>
            <guid isPermaLink="false">https://nitter.cz/yumimao/status/1727240174994874805#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 08:18:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://www.fal.ai/dynamic">fal.ai/dynamic</a> 一个简单的在线体验网站</p>
<p><a href="https://nitter.cz/RioJot/status/1727026140802670857#m">nitter.cz/RioJot/status/1727026140802670857#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9oanJpbGJzQUE0TFJ6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727456845646733767#m</id>
            <title>R to @dotey: 我让GPT-4V帮我分析了一下两张图：

----

由于我无法同时访问两张图片，我将分别对每张图片进行解读，然后基于我的解读进行对比分析。

对于第一张图片：

这是一个关于机器学习模型（称为Claude 2.1）的性能测试图。测试的目的是评估模型在不同文档深度和上下文长度下检索信息的准确性。图中的矩阵表格显示了不同的上下文长度（标记为“Context Length (# Tokens)”）和文档深度百分比（从顶部到底部）。颜色代码表示检索准确性，从绿色（更高准确性）到红色（较低准确性）。注释指出，随着上下文长度的增加，Claude 2.1的检索准确性逐渐下降。这表明模型在处理大量数据时可能会遇到困难。

对于第二张图片：

这张图与第一张相似，但针对的是不同的机器学习模型，即GPT-4。测试的目的是评估GPT-4在不同文档深度和上下文长度下的信息检索准确性。这张图同样显示了一个由不同上下文长度和文档深度组成的矩阵，并用颜色代码表示检索准确性。注释指出，当事实被放置在文档深度的10%-50%之间时，GPT-4的检索准确性开始下降，尤其是在大的上下文长度时。

对比分析：

两张图展示了两种不同的模型在不同条件下的性能测试。主要的比较点在于模型处理大量信息时的准确性。Claude 2.1的测试覆盖了更宽的上下文长度范围，而GPT-4的测试似乎集中在更小的数据集上，但进行了更多的样本测试以增加结果的稳定性。两张图表的颜色渐变表明，两个模型都在较大的上下文长度下表现出检索准确性下降的趋势，尽管具体的准确性水平和下降趋势在每个模型中是不同的。这些测试对于理解和改进机器学习模型在处理大规模数据时的性能至关重要。</title>
            <link>https://nitter.cz/dotey/status/1727456845646733767#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727456845646733767#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 22:39:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我让GPT-4V帮我分析了一下两张图：<br />
<br />
----<br />
<br />
由于我无法同时访问两张图片，我将分别对每张图片进行解读，然后基于我的解读进行对比分析。<br />
<br />
对于第一张图片：<br />
<br />
这是一个关于机器学习模型（称为Claude 2.1）的性能测试图。测试的目的是评估模型在不同文档深度和上下文长度下检索信息的准确性。图中的矩阵表格显示了不同的上下文长度（标记为“Context Length (# Tokens)”）和文档深度百分比（从顶部到底部）。颜色代码表示检索准确性，从绿色（更高准确性）到红色（较低准确性）。注释指出，随着上下文长度的增加，Claude 2.1的检索准确性逐渐下降。这表明模型在处理大量数据时可能会遇到困难。<br />
<br />
对于第二张图片：<br />
<br />
这张图与第一张相似，但针对的是不同的机器学习模型，即GPT-4。测试的目的是评估GPT-4在不同文档深度和上下文长度下的信息检索准确性。这张图同样显示了一个由不同上下文长度和文档深度组成的矩阵，并用颜色代码表示检索准确性。注释指出，当事实被放置在文档深度的10%-50%之间时，GPT-4的检索准确性开始下降，尤其是在大的上下文长度时。<br />
<br />
对比分析：<br />
<br />
两张图展示了两种不同的模型在不同条件下的性能测试。主要的比较点在于模型处理大量信息时的准确性。Claude 2.1的测试覆盖了更宽的上下文长度范围，而GPT-4的测试似乎集中在更小的数据集上，但进行了更多的样本测试以增加结果的稳定性。两张图表的颜色渐变表明，两个模型都在较大的上下文长度下表现出检索准确性下降的趋势，尽管具体的准确性水平和下降趋势在每个模型中是不同的。这些测试对于理解和改进机器学习模型在处理大规模数据时的性能至关重要。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9rbzFYT1c4QUVUVVl5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727454708627808261#m</id>
            <title>将Greg Kamradt的两次实验：
- GPT-4-128K https://twitter.com/dotey/status/1727445313261039717
- Claude 2.1 200K：https://twitter.com/dotey/status/1727437625194136060 

两次结果放一起对比，可以看到：

GPT-4-128K
1. 在上下文长度小于 73K Tokens时，不会有信息遗忘
2. 在上下文长度超出 73K 后，位于中间7%-50% 区间的信息可能会被遗忘

Claude-2.1-200K
1. 上下文长度小于24K时效果最好，几乎不会有信息遗忘
2. 上下文长度超过24K就开始变差，90K后，效果很差，一大半信息会遗忘
3. 最头部和最顶部的1%效果最好，不会被遗忘

我的总结
1. GPT-4还是最强的
2. 尽量少一些上下文，长文还是需要手动或者自动分割，GPT-4 的话，不要超过73K（输入输出加一起）
3. System Prompt 放在最前或者最后都可以，放在后面更好
4. 如果System Prompt 放在前面，对于GPT-4来说，不要超过5%，对于Claude来说不要超过1%
4. GPTs的Prompt只能放在最前面，所以不要超过不要超过5%也就是128*0.05 = 6.4 K Tokens比较好</title>
            <link>https://nitter.cz/dotey/status/1727454708627808261#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727454708627808261#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 22:31:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>将Greg Kamradt的两次实验：<br />
- GPT-4-128K <a href="https://nitter.cz/dotey/status/1727445313261039717">nitter.cz/dotey/status/172…</a><br />
- Claude 2.1 200K：<a href="https://nitter.cz/dotey/status/1727437625194136060">nitter.cz/dotey/status/172…</a> <br />
<br />
两次结果放一起对比，可以看到：<br />
<br />
GPT-4-128K<br />
1. 在上下文长度小于 73K Tokens时，不会有信息遗忘<br />
2. 在上下文长度超出 73K 后，位于中间7%-50% 区间的信息可能会被遗忘<br />
<br />
Claude-2.1-200K<br />
1. 上下文长度小于24K时效果最好，几乎不会有信息遗忘<br />
2. 上下文长度超过24K就开始变差，90K后，效果很差，一大半信息会遗忘<br />
3. 最头部和最顶部的1%效果最好，不会被遗忘<br />
<br />
我的总结<br />
1. GPT-4还是最强的<br />
2. 尽量少一些上下文，长文还是需要手动或者自动分割，GPT-4 的话，不要超过73K（输入输出加一起）<br />
3. System Prompt 放在最前或者最后都可以，放在后面更好<br />
4. 如果System Prompt 放在前面，对于GPT-4来说，不要超过5%，对于Claude来说不要超过1%<br />
4. GPTs的Prompt只能放在最前面，所以不要超过不要超过5%也就是128*0.05 = 6.4 K Tokens比较好</p>
<p><a href="https://nitter.cz/dotey/status/1727437625194136060#m">nitter.cz/dotey/status/1727437625194136060#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9rbC1fR1hrQUFLemNmLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9rbUE3U1hJQUFqSUY5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1727439351930638688#m</id>
            <title>RT by @dotey: GPT4 128k 有多强。
这真的不是一般的遥遥领先…</title>
            <link>https://nitter.cz/oran_ge/status/1727439351930638688#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1727439351930638688#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 21:30:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT4 128k 有多强。<br />
这真的不是一般的遥遥领先…</p>
<p><a href="https://nitter.cz/SteveMoraco/status/1727370446788530236#m">nitter.cz/SteveMoraco/status/1727370446788530236#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727445313261039717#m</id>
            <title>顺藤摸瓜找到 Greg Kamradt 对 GPT-4-128K 的 128K Token 上下文回忆能力进行了压力测试。一些关键结论：
1. Prompt 中的开头和结尾是最关键的，尤其是结尾部分；
2 .位于中间 7%-50% 区间的内容效果最差
3. 上下文越少，准确性越高，超过 73K Token 时，GPT-4-128K 的记忆性能开始下降。

以下是作者的原文：

用长篇幅上下文考验 GPT-4-128K 的记忆力

128K Token 的上下文听起来很厉害，但它的实际表现怎样呢？

为了找出答案，我进行了一项“大海捞针”的分析。

发现了一些意料之中和意料之外的结果。

我的发现如下：

**发现：**
* 超过 73K Token 时，GPT-4 的记忆性能开始下降。
* 当需要回忆的信息位于文档深度的 7%-50% 区间时，回忆表现较差。
* 如果信息位于文档开头，无论上下文有多长，它总能被记住。

**那么，这意味着什么？**
* 没有保证 - 你的信息不一定能被检索到。别指望你的应用程序能总是找到它们。
* 更少的上下文等于更高的准确性 - 这是常识，但如果可以的话，减少发送给 GPT-4 的上下文量可以提高其记忆准确性。
* 位置很关键 - 这也是常识，但放在文档开头和后半部分的信息似乎更容易被记住。

**分析过程概述：**
* 以 Paul Graham 的文章作为背景材料。有了 218 篇文章，轻松实现 128K Token。
* 在文档不同深度插入随机陈述。所用事实为：“在阳光明媚的日子里，在多洛雷斯公园吃三明治是在旧金山最佳活动。”
* 让 GPT-4 仅用提供的上下文来回答这个问题。
* 用 LangChainAI 的评估方法，再次用 GPT-4 对其答案进行评估。
* 对 15 种不同文档深度（从文档顶端的 0% 到底部的 100%）和 15 种上下文长度（1K Token 至 128K Token）进行重复测试。

**为了深入研究，接下来可以采取的步骤：**
* 尽管这些分析是均匀分布的，但有人建议用 sigmoid 分布可能会更好（这样可以在文档的开始和结束阶段发现更多细节）。
* 为了更严谨，应该进行键值对检索。但为了增加相关性，我在 Paul Graham 的文章中加入了关于旧金山的描述。

**备注：**
* 虽然我认为这些发现方向上是正确的，但需要更多测试来更深入地了解 GPT-4 的能力。
* 改变提示可能会改变结果。
* 在长上下文中进行了两次测试，以便更深入地挖掘性能。
* 这次测试大约花费了 200 美元用于 API 调用（单次调用 128K 输入 Token 的成本为 1.28 美元）。
* 感谢 Charles 🎉 Frye 提供意见和建议下一步的方向。</title>
            <link>https://nitter.cz/dotey/status/1727445313261039717#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727445313261039717#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 21:53:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>顺藤摸瓜找到 Greg Kamradt 对 GPT-4-128K 的 128K Token 上下文回忆能力进行了压力测试。一些关键结论：<br />
1. Prompt 中的开头和结尾是最关键的，尤其是结尾部分；<br />
2 .位于中间 7%-50% 区间的内容效果最差<br />
3. 上下文越少，准确性越高，超过 73K Token 时，GPT-4-128K 的记忆性能开始下降。<br />
<br />
以下是作者的原文：<br />
<br />
用长篇幅上下文考验 GPT-4-128K 的记忆力<br />
<br />
128K Token 的上下文听起来很厉害，但它的实际表现怎样呢？<br />
<br />
为了找出答案，我进行了一项“大海捞针”的分析。<br />
<br />
发现了一些意料之中和意料之外的结果。<br />
<br />
我的发现如下：<br />
<br />
**发现：**<br />
* 超过 73K Token 时，GPT-4 的记忆性能开始下降。<br />
* 当需要回忆的信息位于文档深度的 7%-50% 区间时，回忆表现较差。<br />
* 如果信息位于文档开头，无论上下文有多长，它总能被记住。<br />
<br />
**那么，这意味着什么？**<br />
* 没有保证 - 你的信息不一定能被检索到。别指望你的应用程序能总是找到它们。<br />
* 更少的上下文等于更高的准确性 - 这是常识，但如果可以的话，减少发送给 GPT-4 的上下文量可以提高其记忆准确性。<br />
* 位置很关键 - 这也是常识，但放在文档开头和后半部分的信息似乎更容易被记住。<br />
<br />
**分析过程概述：**<br />
* 以 Paul Graham 的文章作为背景材料。有了 218 篇文章，轻松实现 128K Token。<br />
* 在文档不同深度插入随机陈述。所用事实为：“在阳光明媚的日子里，在多洛雷斯公园吃三明治是在旧金山最佳活动。”<br />
* 让 GPT-4 仅用提供的上下文来回答这个问题。<br />
* 用 LangChainAI 的评估方法，再次用 GPT-4 对其答案进行评估。<br />
* 对 15 种不同文档深度（从文档顶端的 0% 到底部的 100%）和 15 种上下文长度（1K Token 至 128K Token）进行重复测试。<br />
<br />
**为了深入研究，接下来可以采取的步骤：**<br />
* 尽管这些分析是均匀分布的，但有人建议用 sigmoid 分布可能会更好（这样可以在文档的开始和结束阶段发现更多细节）。<br />
* 为了更严谨，应该进行键值对检索。但为了增加相关性，我在 Paul Graham 的文章中加入了关于旧金山的描述。<br />
<br />
**备注：**<br />
* 虽然我认为这些发现方向上是正确的，但需要更多测试来更深入地了解 GPT-4 的能力。<br />
* 改变提示可能会改变结果。<br />
* 在长上下文中进行了两次测试，以便更深入地挖掘性能。<br />
* 这次测试大约花费了 200 美元用于 API 调用（单次调用 128K 输入 Token 的成本为 1.28 美元）。<br />
* 感谢 Charles 🎉 Frye 提供意见和建议下一步的方向。</p>
<p><a href="https://nitter.cz/GregKamradt/status/1722386725635580292#m">nitter.cz/GregKamradt/status/1722386725635580292#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>