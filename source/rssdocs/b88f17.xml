<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742605650213966001#m</id>
            <title>R to @dotey: 需求是软件工程范畴，这篇主要谈编程，所以也不矛盾😅

https://x.com/Chinese_XU/status/1742467486178795821?s=20</title>
            <link>https://nitter.cz/dotey/status/1742605650213966001#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742605650213966001#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 17:55:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>需求是软件工程范畴，这篇主要谈编程，所以也不矛盾😅<br />
<br />
<a href="https://x.com/Chinese_XU/status/1742467486178795821?s=20">x.com/Chinese_XU/status/1742…</a></p>
<p><a href="https://nitter.cz/Chinese_XU/status/1742467486178795821#m">nitter.cz/Chinese_XU/status/1742467486178795821#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742604614535463022#m</id>
            <title>#开源项目推荐：paulpacifico/shutter-encoder

Shutter Encoder是一款开源免费的视频压缩编辑软件，支持windows和Mac。

主要功能包括：
修剪和剪辑视频
优化图片
强大的裁剪支持
生成和烧录剪辑信息
字幕嵌入和烧录
添加水印
内置字幕编辑器
等等

官网：https://www.shutterencoder.com/
项目地址：https://github.com/paulpacifico/shutter-encoder</title>
            <link>https://nitter.cz/dotey/status/1742604614535463022#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742604614535463022#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 17:51:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23开源项目推荐">#开源项目推荐</a>：paulpacifico/shutter-encoder<br />
<br />
Shutter Encoder是一款开源免费的视频压缩编辑软件，支持windows和Mac。<br />
<br />
主要功能包括：<br />
修剪和剪辑视频<br />
优化图片<br />
强大的裁剪支持<br />
生成和烧录剪辑信息<br />
字幕嵌入和烧录<br />
添加水印<br />
内置字幕编辑器<br />
等等<br />
<br />
官网：<a href="https://www.shutterencoder.com/">shutterencoder.com/</a><br />
项目地址：<a href="https://github.com/paulpacifico/shutter-encoder">github.com/paulpacifico/shut…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M3NWxpNFhVQUFuX1FRLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M3NW1WZ1hNQUE0YmRqLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M3NW5ZMVdRQUV4dUpLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M3NXBvdVc0QUFJenUwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mranti/status/1742450267629801713#m</id>
            <title>RT by @dotey: 关于AI和社会的关系我有一些想法，和大家分享下：

1）这个世界有两种主要管理模式/算法模式，共识模式和投票模式。共识模式是人类潜意识，是一个共同体快速承认的关于世界限制的知识，是“大我”。投票模式是个人自由意志的选择，是对多巴胺的追求，是反感厌倦的“小我”。

2）所有的杰出，都是共同体投票的结果，是进化的开始。投票的方式很多，市场、竞争、战斗、点赞、刷手机。因此今天的个人英雄，必须生长在各种投票生态中，比如企业家、网红、政客。

3）LLM是共识算法的里程碑。但这也是当前AIGC让人不能满意的原因，从LLM走出的AI，产生内容都有一个问题：平庸，因为Transformer模型本身就是让共同体读者觉得你说的很像大家说的，这怎么能杰出？因此，解决AI产出平庸的最好思路就是让它增加或者搭上投票机制，挑选出杰出。

4）50年之内，AI对人类没有威胁。AI已经是人的一部分，甚至我把AI定义成“缺乏有限身体的庸人”（Homo Mediocris）。只要一天AI没接上有限的身体，它就不值得担心，就好像农具取代了原始人的很多工作，但农具也成为了人的一部分。

5）AI时代，所有的英雄不但要在投票机制中走，而且要会驾驭庸人（AI）。就好像你突然拥有了大量的奴隶一样，你找到了驾驭这些新奴隶的方法，你就是新的英雄。庸人们有了有限必死的身体之后，搭上了进化飞轮，才会颠覆人类的统治。</title>
            <link>https://nitter.cz/mranti/status/1742450267629801713#m</link>
            <guid isPermaLink="false">https://nitter.cz/mranti/status/1742450267629801713#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 07:38:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>关于AI和社会的关系我有一些想法，和大家分享下：<br />
<br />
1）这个世界有两种主要管理模式/算法模式，共识模式和投票模式。共识模式是人类潜意识，是一个共同体快速承认的关于世界限制的知识，是“大我”。投票模式是个人自由意志的选择，是对多巴胺的追求，是反感厌倦的“小我”。<br />
<br />
2）所有的杰出，都是共同体投票的结果，是进化的开始。投票的方式很多，市场、竞争、战斗、点赞、刷手机。因此今天的个人英雄，必须生长在各种投票生态中，比如企业家、网红、政客。<br />
<br />
3）LLM是共识算法的里程碑。但这也是当前AIGC让人不能满意的原因，从LLM走出的AI，产生内容都有一个问题：平庸，因为Transformer模型本身就是让共同体读者觉得你说的很像大家说的，这怎么能杰出？因此，解决AI产出平庸的最好思路就是让它增加或者搭上投票机制，挑选出杰出。<br />
<br />
4）50年之内，AI对人类没有威胁。AI已经是人的一部分，甚至我把AI定义成“缺乏有限身体的庸人”（Homo Mediocris）。只要一天AI没接上有限的身体，它就不值得担心，就好像农具取代了原始人的很多工作，但农具也成为了人的一部分。<br />
<br />
5）AI时代，所有的英雄不但要在投票机制中走，而且要会驾驭庸人（AI）。就好像你突然拥有了大量的奴隶一样，你找到了驾驭这些新奴隶的方法，你就是新的英雄。庸人们有了有限必死的身体之后，搭上了进化飞轮，才会颠覆人类的统治。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742432080707895476#m</id>
            <title>其实最早在编程界就流传着“Make it work, Make it right, Make it fast”——Kent Beck

先能跑，再跑对，最后再优化！

至理名言！ 

https://baoyu.io/translations/software-engineering/make-it-work-first-then-right-fast</title>
            <link>https://nitter.cz/dotey/status/1742432080707895476#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742432080707895476#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 06:25:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>其实最早在编程界就流传着“Make it work, Make it right, Make it fast”——Kent Beck<br />
<br />
先能跑，再跑对，最后再优化！<br />
<br />
至理名言！ <br />
<br />
<a href="https://baoyu.io/translations/software-engineering/make-it-work-first-then-right-fast">baoyu.io/translations/softwa…</a></p>
<p><a href="https://nitter.cz/addyosmani/status/1739052802314539371#m">nitter.cz/addyosmani/status/1739052802314539371#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MjQzMjA4NDk2NTEzMDI0MC9PLTVRRnREVj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/jesselaunz/status/1742419115657335057#m</id>
            <title>RT by @dotey: Timmy 的演示依然印象深刻

runway的custom character generator

做一致性的角色的工作流程</title>
            <link>https://nitter.cz/jesselaunz/status/1742419115657335057#m</link>
            <guid isPermaLink="false">https://nitter.cz/jesselaunz/status/1742419115657335057#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 05:34:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Timmy 的演示依然印象深刻<br />
<br />
runway的custom character generator<br />
<br />
做一致性的角色的工作流程</p>
<p><a href="https://nitter.cz/IXITimmyIXI/status/1742392466114798017#m">nitter.cz/IXITimmyIXI/status/1742392466114798017#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/BlueBirdBack/status/1742414798250287372#m</id>
            <title>RT by @dotey: 推薦 http://labs.pplx.ai 中的 mistral-medium 模型，免費，比較強，不需要登錄。</title>
            <link>https://nitter.cz/BlueBirdBack/status/1742414798250287372#m</link>
            <guid isPermaLink="false">https://nitter.cz/BlueBirdBack/status/1742414798250287372#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 05:17:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推薦 <a href="http://labs.pplx.ai">labs.pplx.ai</a> 中的 mistral-medium 模型，免費，比較強，不需要登錄。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742413924396319183#m</id>
            <title>这篇文章值得看看，像 Redis作者 Antirez 这样的顶级程序员都在借助大语言模型写程序！

Antirez 使用 ChatGPT 这样的语言辅助编程的做法很典型：

1. 对于不熟悉的语言或者类库，避免了查询文档，直接让 GPT 给出解释或者生成代码
2. 写临时代码，对于一些一次性代码，就不用费心费力去自己写，让 LLM 帮忙生成，质量还不错

当然 Antirez 也发现了一些局限：

- 对于复杂的代码，比如写个布隆过滤器，目前质量还不够好！
- 上下文长度不够

Antirez 的建议：

- 现今程序员没理由不去使用 LLM 辅助编程
- 正确地向大模型提问是一项关键技能，学会向 LLM 提问也有利于提升程序员的沟通能力
- 把 LLM 当做一种压缩文档（不能完全替代文档，毕竟有幻觉）来使用

这篇文章的中文翻译版本：https://baoyu.io/translations/llm/llms-and-programming-in-the-first-days-of-2024</title>
            <link>https://nitter.cz/dotey/status/1742413924396319183#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742413924396319183#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 05:13:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这篇文章值得看看，像 Redis作者 Antirez 这样的顶级程序员都在借助大语言模型写程序！<br />
<br />
Antirez 使用 ChatGPT 这样的语言辅助编程的做法很典型：<br />
<br />
1. 对于不熟悉的语言或者类库，避免了查询文档，直接让 GPT 给出解释或者生成代码<br />
2. 写临时代码，对于一些一次性代码，就不用费心费力去自己写，让 LLM 帮忙生成，质量还不错<br />
<br />
当然 Antirez 也发现了一些局限：<br />
<br />
- 对于复杂的代码，比如写个布隆过滤器，目前质量还不够好！<br />
- 上下文长度不够<br />
<br />
Antirez 的建议：<br />
<br />
- 现今程序员没理由不去使用 LLM 辅助编程<br />
- 正确地向大模型提问是一项关键技能，学会向 LLM 提问也有利于提升程序员的沟通能力<br />
- 把 LLM 当做一种压缩文档（不能完全替代文档，毕竟有幻觉）来使用<br />
<br />
这篇文章的中文翻译版本：<a href="https://baoyu.io/translations/llm/llms-and-programming-in-the-first-days-of-2024">baoyu.io/translations/llm/ll…</a></p>
<p><a href="https://nitter.cz/Piglei/status/1742399105891270747#m">nitter.cz/Piglei/status/1742399105891270747#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742411310560641227#m</id>
            <title>R to @dotey: x.com/MajICa69/status/174241…</title>
            <link>https://nitter.cz/dotey/status/1742411310560641227#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742411310560641227#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 05:03:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://x.com/MajICa69/status/1742410716970430831?s=20">x.com/MajICa69/status/174241…</a></p>
<p><a href="https://nitter.cz/MajICa69/status/1742410716970430831#m">nitter.cz/MajICa69/status/1742410716970430831#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742392202482061509#m</id>
            <title>RT by @dotey: 兄弟们，这个模型很强大！👍🏻

M2UGen：多模态音乐理解和生成模型

该模型由腾讯与新加坡国立大学开发，M2UGen能够理解各种音乐，包括风格、演奏乐器、表达的情绪情感等，并进行音乐问答。

而且还能根据文本、图像、视频和音频生成各种音乐，同时对生成的音乐也能理解并根据文字描述对音乐进行编辑。

M2UGen 的主要功能：

- 音乐问答：M2UGen 能够理解不同类型的音乐，包括它们的风格、使用的乐器、表达的情绪和情感等。然后根据提出的问题，模型能够理解并回答与音乐相关的查询。

- 文本到音乐生成：用户可以输入文本，模型会根据这些文本生成相应的音乐。

- 图像到音乐生成：模型能够根据提供的图片内容生成匹配的音乐。

-视频到音乐生成：根据视频内容，模型能理解视频的主要内容，并生成相应的音乐。

- 音乐编辑：用户可以对已生成的音乐进行编辑，例如改变乐器、调整节奏等，而且只需要通过文本描述即可。

M2UGen 使用了多种编码器，包括用于音乐理解的 MERT、用于图像理解的 ViT 和用于视频理解的 ViViT，以及作为音乐生成模型（音乐解码器）的 MusicGen/AudioLDM2 模型。

此外，该模型还结合了适配器和 LLaMA 2 模型。

工作原理：

1、多模态输入处理：M2UGen能够处理多种类型的输入，包括文本、图像、视频和音频。

它使用特定的编码器来理解不同的输入模态。例如，使用MERT模型处理音乐输入，ViT模型处理图像输入，ViViT模型处理视频输入。

2、音乐理解：利用LLaMA 2模型，M2UGen能够理解音乐的各个方面，如风格、乐器使用和情感表达。它能够对音乐相关的问题进行回答，这涉及到对音乐内容的深入理解。

3、音乐生成：M2UGen不仅能理解音乐，还能根据不同的输入生成音乐。它探索使用AudioLDM 2和MusicGen等模型来根据文本、图像或视频输入生成音乐。

4、数据集生成与训练：为了训练M2UGen，开发者使用了MU-LLaMA和MPT-7B模型来生成大量的多模态音乐配对数据集。这些数据集帮助M2UGen学习如何从不同的输入中提取信息并生成相应的音乐。

项目及演示：https://crypto-code.github.io/M2UGen-Demo/
论文：https://arxiv.org/abs/2311.11255
GitHub：https://github.com/shansongliu/M2UGen</title>
            <link>https://nitter.cz/xiaohuggg/status/1742392202482061509#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742392202482061509#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:47:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们，这个模型很强大！👍🏻<br />
<br />
M2UGen：多模态音乐理解和生成模型<br />
<br />
该模型由腾讯与新加坡国立大学开发，M2UGen能够理解各种音乐，包括风格、演奏乐器、表达的情绪情感等，并进行音乐问答。<br />
<br />
而且还能根据文本、图像、视频和音频生成各种音乐，同时对生成的音乐也能理解并根据文字描述对音乐进行编辑。<br />
<br />
M2UGen 的主要功能：<br />
<br />
- 音乐问答：M2UGen 能够理解不同类型的音乐，包括它们的风格、使用的乐器、表达的情绪和情感等。然后根据提出的问题，模型能够理解并回答与音乐相关的查询。<br />
<br />
- 文本到音乐生成：用户可以输入文本，模型会根据这些文本生成相应的音乐。<br />
<br />
- 图像到音乐生成：模型能够根据提供的图片内容生成匹配的音乐。<br />
<br />
-视频到音乐生成：根据视频内容，模型能理解视频的主要内容，并生成相应的音乐。<br />
<br />
- 音乐编辑：用户可以对已生成的音乐进行编辑，例如改变乐器、调整节奏等，而且只需要通过文本描述即可。<br />
<br />
M2UGen 使用了多种编码器，包括用于音乐理解的 MERT、用于图像理解的 ViT 和用于视频理解的 ViViT，以及作为音乐生成模型（音乐解码器）的 MusicGen/AudioLDM2 模型。<br />
<br />
此外，该模型还结合了适配器和 LLaMA 2 模型。<br />
<br />
工作原理：<br />
<br />
1、多模态输入处理：M2UGen能够处理多种类型的输入，包括文本、图像、视频和音频。<br />
<br />
它使用特定的编码器来理解不同的输入模态。例如，使用MERT模型处理音乐输入，ViT模型处理图像输入，ViViT模型处理视频输入。<br />
<br />
2、音乐理解：利用LLaMA 2模型，M2UGen能够理解音乐的各个方面，如风格、乐器使用和情感表达。它能够对音乐相关的问题进行回答，这涉及到对音乐内容的深入理解。<br />
<br />
3、音乐生成：M2UGen不仅能理解音乐，还能根据不同的输入生成音乐。它探索使用AudioLDM 2和MusicGen等模型来根据文本、图像或视频输入生成音乐。<br />
<br />
4、数据集生成与训练：为了训练M2UGen，开发者使用了MU-LLaMA和MPT-7B模型来生成大量的多模态音乐配对数据集。这些数据集帮助M2UGen学习如何从不同的输入中提取信息并生成相应的音乐。<br />
<br />
项目及演示：<a href="https://crypto-code.github.io/M2UGen-Demo/">crypto-code.github.io/M2UGen…</a><br />
论文：<a href="https://arxiv.org/abs/2311.11255">arxiv.org/abs/2311.11255</a><br />
GitHub：<a href="https://github.com/shansongliu/M2UGen">github.com/shansongliu/M2UGe…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIzODg0NDkwNTM5MjEyODAvcHUvaW1nL0g3bGpPWktGQzRVNllXa0wuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742393800830407090#m</id>
            <title>来自 JPMorgan 的 DocLLM：一种面向布局的生成式语言模型，能理解多模态文档

对于企业文档来说，不仅仅是文本类型，还有很多复杂的类型，例如表格、发票、收据、报告、合同等，其中都包含着丰富的文字和空间交互信息。这些文档复杂的布局提供了视觉线索，对于有效理解这些文档至关重要。

本论文以此建议了一种轻量级扩展的大语言模型（LLMs） - DocLLM，这款模型可在处理可视文档时，同时考虑到文本语义和空间布局。该模型与现有的多模态语言模型（LLMs）的最大不同在于，它没有使用计算成本高昂的图像编码器，而是通过边框信息来整合空间布局。

具体来说，DocLLM 通过将文本和空间模态之间的交叉对齐分解为一组独立矩阵来处理既定的 Transformer 的注意力机制。

此外，DocLLM 还设计了一个预训练目标，学习如何自动填充文本段落。这种方式使其能更好地处理常见的视觉文档中的不规则布局和混合内容。

DocLLM 使用大型指令数据集对预训练模型进行了微调，覆盖了四个主要的文档智能任务。

DocLLM 的解决方案在所有任务的16个数据集中的14个上优于现有的最先进语言模型，且在之前未曾接触过的5个数据集中的4个上有良好的应用表现。

论文地址：https://arxiv.org/abs/2401.00908</title>
            <link>https://nitter.cz/dotey/status/1742393800830407090#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742393800830407090#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:53:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自 JPMorgan 的 DocLLM：一种面向布局的生成式语言模型，能理解多模态文档<br />
<br />
对于企业文档来说，不仅仅是文本类型，还有很多复杂的类型，例如表格、发票、收据、报告、合同等，其中都包含着丰富的文字和空间交互信息。这些文档复杂的布局提供了视觉线索，对于有效理解这些文档至关重要。<br />
<br />
本论文以此建议了一种轻量级扩展的大语言模型（LLMs） - DocLLM，这款模型可在处理可视文档时，同时考虑到文本语义和空间布局。该模型与现有的多模态语言模型（LLMs）的最大不同在于，它没有使用计算成本高昂的图像编码器，而是通过边框信息来整合空间布局。<br />
<br />
具体来说，DocLLM 通过将文本和空间模态之间的交叉对齐分解为一组独立矩阵来处理既定的 Transformer 的注意力机制。<br />
<br />
此外，DocLLM 还设计了一个预训练目标，学习如何自动填充文本段落。这种方式使其能更好地处理常见的视觉文档中的不规则布局和混合内容。<br />
<br />
DocLLM 使用大型指令数据集对预训练模型进行了微调，覆盖了四个主要的文档智能任务。<br />
<br />
DocLLM 的解决方案在所有任务的16个数据集中的14个上优于现有的最先进语言模型，且在之前未曾接触过的5个数据集中的4个上有良好的应用表现。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2401.00908">arxiv.org/abs/2401.00908</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1742369195034099731#m">nitter.cz/_akhaliq/status/1742369195034099731#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0NTZjeVdzQUVqWTlZLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742373301929091472#m</id>
            <title>RT by @dotey: 这些人速度真快，666

1月1号米老鼠版权不是过期了嘛，任何人都可以使用

然后现在米老鼠的SD模型已经出来了 

Mickey-1928：一个基于Stable-Diffusion-xl的微调版本，专门训练用于生成米老鼠、米妮和皮特的图像。

模型使用了来自1928年公共领域的96张静止画面训练，目的是生成符合1928年设计风格的米老鼠、米妮和皮特的图像。

数据集来源：数据集包括来自三部米老鼠卡通的静止画面，分别是《Gallopin' Gaucho》（40张彩色静止画面）、《Plane Crazy》（22张静止画面）和《Steamboat Willie》（34张静止画面）。

模型作者：@Dorialexander

模型下载：https://huggingface.co/Pclanglais/Mickey-1928

在线体验：https://huggingface.co/spaces/shewster/Pclanglais-Mickey-1928</title>
            <link>https://nitter.cz/xiaohuggg/status/1742373301929091472#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742373301929091472#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:32:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这些人速度真快，666<br />
<br />
1月1号米老鼠版权不是过期了嘛，任何人都可以使用<br />
<br />
然后现在米老鼠的SD模型已经出来了 <br />
<br />
Mickey-1928：一个基于Stable-Diffusion-xl的微调版本，专门训练用于生成米老鼠、米妮和皮特的图像。<br />
<br />
模型使用了来自1928年公共领域的96张静止画面训练，目的是生成符合1928年设计风格的米老鼠、米妮和皮特的图像。<br />
<br />
数据集来源：数据集包括来自三部米老鼠卡通的静止画面，分别是《Gallopin' Gaucho》（40张彩色静止画面）、《Plane Crazy》（22张静止画面）和《Steamboat Willie》（34张静止画面）。<br />
<br />
模型作者：<a href="https://nitter.cz/Dorialexander" title="Alexander Doria">@Dorialexander</a><br />
<br />
模型下载：<a href="https://huggingface.co/Pclanglais/Mickey-1928">huggingface.co/Pclanglais/Mi…</a><br />
<br />
在线体验：<a href="https://huggingface.co/spaces/shewster/Pclanglais-Mickey-1928">huggingface.co/spaces/shewst…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1742010140113674467#m">nitter.cz/xiaohuggg/status/1742010140113674467#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWhEYmJRQUFVdnVyLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWpReWJjQUFXRVdLLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWxYUWFjQUEyOEd5LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742378525925982662#m</id>
            <title>自从马斯克收购 Twitter（已经改名为 X）后，据报道该公司估值已经缩水了 72％。

富达（Fidelity）降低了其在 X 公司的股权价值，暗示自从马斯克以 440 亿美元收购后，其估值已经下降了 72％。

富达最近对其在 X 公司的股权的估价，自从马斯克在 2022 年 10 月购买该公司以来，其价值已经下降了大约 71.5％。

富达的 Blue Chip Growth Fund 在 X 公司持有相对较少的股份。该基金的月度更新报告显示，截至 2023 年 11 月 30 日，其在“X Holdings Corp.”的股权价值为 560 万美元。该基金在 X 公司的股份原价为 1970 万美元，但在 2023 年 4 月已经损失了大约三分之二的价值，并且自那时以来的跌幅已经相对小了许多。

根据 Axios 的报告，富达在 11 月份将 X 的估值降低了 10.7％。人们不清楚富达是否在 11 月份卖掉了部分股份，但最近股价的下降不足为奇，因为最近马斯克引起的争议让广告商们纷纷离开了这个平台。

"截至 10 月 30 日，该基金尚未出售任何股份，但更新的估值月度报告没有披露持股量是否有所变化，" 据彭博社报道。"如果该基金并未减少在 X 公司的股份，那么最新的报告就暗示了整个公司的价值也下降了 72％。富达公司拒绝对此发表评论。”

根据马斯克一年前支付了 440 亿美元购买 Twitter，富达的估值下降使得公司价值约为 125 亿美元。据报道，X 公司 10 月份的自我估值约为 190 亿美元，这是基于给员工的股票赠礼的价值。

自从马斯克决定将 Twitter 置为私有后，公司的价值和收入从外部更难了解。正如 Axios 所注意到的，“尽管富达成为了这家私人拥有的公司的股东，但它也可能没有太多关于 X 财务状况的内部信息。其他股东可能对他们的 X 股票有不同的估值。”

X 公司的财务状况在马斯克收购一周年也就是去年 10 月底的时候已经足够致命。马斯克在 11 月中发布了对一条反犹太推文的积极响应，使情况变得更糟。11 月 29 日，他在一个公开访谈中处理了这场反犹太主义争议，告诉从 X 撤走广告的商家“去他妈的”。

马斯克在任期内，X 一直在保留广告商方面存在问题，幕后大 boss 的处理方式成为了主要原因。马斯克在成为所有者不久后近乎裁员了公司所有老员工。

X 无法阻止加州法案

X 正在应对欧洲和美国针对内容监管的新法规。马斯克的公司于九月起诉加州政府，试图阻止该州的内容审核法，但上周它在法庭败诉。

周四，美国地方法官威廉·舒布驳回了 X 请求临时禁令以阻止执行加州的内容审核法。该项州法案要求公司每年提交两份报告，说明服务条款和详细的内容审核实践。

舒布驳回了 X 的主张，即该法律违反了第一修正案。舒布写道，“虽然报告要求似乎给社交媒体公司带来了实质性的合规负担，但在第一修正案法律范畴内，并未出现该要求无理或过度繁复的情况。”

法官支持加州政府，要求社交媒体公司对他们的内容审核政策和实践进行透明化，这有着实质性的政府利益，以便消费者可以做出明智的决定，决定他们在哪里消费和传播新闻和信息。

新闻来源：https://arstechnica.com/tech-policy/2024/01/since-elon-musks-twitter-purchase-firm-reportedly-lost-72-of-its-value/</title>
            <link>https://nitter.cz/dotey/status/1742378525925982662#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742378525925982662#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:53:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>自从马斯克收购 Twitter（已经改名为 X）后，据报道该公司估值已经缩水了 72％。<br />
<br />
富达（Fidelity）降低了其在 X 公司的股权价值，暗示自从马斯克以 440 亿美元收购后，其估值已经下降了 72％。<br />
<br />
富达最近对其在 X 公司的股权的估价，自从马斯克在 2022 年 10 月购买该公司以来，其价值已经下降了大约 71.5％。<br />
<br />
富达的 Blue Chip Growth Fund 在 X 公司持有相对较少的股份。该基金的月度更新报告显示，截至 2023 年 11 月 30 日，其在“X Holdings Corp.”的股权价值为 560 万美元。该基金在 X 公司的股份原价为 1970 万美元，但在 2023 年 4 月已经损失了大约三分之二的价值，并且自那时以来的跌幅已经相对小了许多。<br />
<br />
根据 Axios 的报告，富达在 11 月份将 X 的估值降低了 10.7％。人们不清楚富达是否在 11 月份卖掉了部分股份，但最近股价的下降不足为奇，因为最近马斯克引起的争议让广告商们纷纷离开了这个平台。<br />
<br />
"截至 10 月 30 日，该基金尚未出售任何股份，但更新的估值月度报告没有披露持股量是否有所变化，" 据彭博社报道。"如果该基金并未减少在 X 公司的股份，那么最新的报告就暗示了整个公司的价值也下降了 72％。富达公司拒绝对此发表评论。”<br />
<br />
根据马斯克一年前支付了 440 亿美元购买 Twitter，富达的估值下降使得公司价值约为 125 亿美元。据报道，X 公司 10 月份的自我估值约为 190 亿美元，这是基于给员工的股票赠礼的价值。<br />
<br />
自从马斯克决定将 Twitter 置为私有后，公司的价值和收入从外部更难了解。正如 Axios 所注意到的，“尽管富达成为了这家私人拥有的公司的股东，但它也可能没有太多关于 X 财务状况的内部信息。其他股东可能对他们的 X 股票有不同的估值。”<br />
<br />
X 公司的财务状况在马斯克收购一周年也就是去年 10 月底的时候已经足够致命。马斯克在 11 月中发布了对一条反犹太推文的积极响应，使情况变得更糟。11 月 29 日，他在一个公开访谈中处理了这场反犹太主义争议，告诉从 X 撤走广告的商家“去他妈的”。<br />
<br />
马斯克在任期内，X 一直在保留广告商方面存在问题，幕后大 boss 的处理方式成为了主要原因。马斯克在成为所有者不久后近乎裁员了公司所有老员工。<br />
<br />
X 无法阻止加州法案<br />
<br />
X 正在应对欧洲和美国针对内容监管的新法规。马斯克的公司于九月起诉加州政府，试图阻止该州的内容审核法，但上周它在法庭败诉。<br />
<br />
周四，美国地方法官威廉·舒布驳回了 X 请求临时禁令以阻止执行加州的内容审核法。该项州法案要求公司每年提交两份报告，说明服务条款和详细的内容审核实践。<br />
<br />
舒布驳回了 X 的主张，即该法律违反了第一修正案。舒布写道，“虽然报告要求似乎给社交媒体公司带来了实质性的合规负担，但在第一修正案法律范畴内，并未出现该要求无理或过度繁复的情况。”<br />
<br />
法官支持加州政府，要求社交媒体公司对他们的内容审核政策和实践进行透明化，这有着实质性的政府利益，以便消费者可以做出明智的决定，决定他们在哪里消费和传播新闻和信息。<br />
<br />
新闻来源：<a href="https://arstechnica.com/tech-policy/2024/01/since-elon-musks-twitter-purchase-firm-reportedly-lost-72-of-its-value/">arstechnica.com/tech-policy/…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/beihuo/status/1742350183709671744#m</id>
            <title>RT by @dotey: 我想想找一个管理工具，给自己用，但是选来选去总是感觉不顺手。今天我在对比工具的时候，忽然意识到并不是工具不顺手，而是我不知道该如何管理项目开发，我不知道该如何正确使用这些工具。

于是我去学习了 Github 团队是如何管理产品开发的，并做了一些笔记：

1/19</title>
            <link>https://nitter.cz/beihuo/status/1742350183709671744#m</link>
            <guid isPermaLink="false">https://nitter.cz/beihuo/status/1742350183709671744#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 01:00:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我想想找一个管理工具，给自己用，但是选来选去总是感觉不顺手。今天我在对比工具的时候，忽然意识到并不是工具不顺手，而是我不知道该如何管理项目开发，我不知道该如何正确使用这些工具。<br />
<br />
于是我去学习了 Github 团队是如何管理产品开发的，并做了一些笔记：<br />
<br />
1/19</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742326546474389640#m</id>
            <title>R to @dotey: 前一条推翻译不太对：“public domain” 是说已经进入公有领域，也就是所有权过期了</title>
            <link>https://nitter.cz/dotey/status/1742326546474389640#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742326546474389640#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 23:26:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前一条推翻译不太对：“public domain” 是说已经进入公有领域，也就是所有权过期了</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742324698325627292#m</id>
            <title>推荐一套The Full Stack的免费 LLM 在线教程：LLM Bootcamp - Spring 2023

包含了提示工程、LLM运维、LLM App开发、LLM基础等内容。

第一次访问需要输入邮箱。

https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/</title>
            <link>https://nitter.cz/dotey/status/1742324698325627292#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742324698325627292#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 23:19:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一套The Full Stack的免费 LLM 在线教程：LLM Bootcamp - Spring 2023<br />
<br />
包含了提示工程、LLM运维、LLM App开发、LLM基础等内容。<br />
<br />
第一次访问需要输入邮箱。<br />
<br />
<a href="https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/">fullstackdeeplearning.com/ll…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzNjlpTVgwQUFuRzV6LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzN0NwdlhNQUU1NkNMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742321608037986530#m</id>
            <title>R to @dotey: 论文摘要：

当今的主流大语言模型（LLMs）与过去的语言模型有所不同，它们不仅规模更大，而且依托自然语言和代码（形式语言）综合训练。

代码作为连通人类与计算机的桥梁，将高层次的目标转化为可执行的步骤，具备标准语法、逻辑一致性、抽象性和模块化等特性。

在本文中，我们探讨了将代码整合进大语言模型训练数据中的众多益处，具体来看，代码的独特属性不仅能够提升大语言模型的代码生成能力，同时还可以：

(i) 解锁大语言模型的推理能力，使其能够应对一系列更为复杂的自然语言任务；

(ii) 引导大语言模型生成结构化和精准的中间步骤，然后通过函数调用将这些步骤连接到外部执行环节；

(iii) 利用代码的编译和执行环境，获取多样的反馈以改进模型。

此外，我们还追溯了代码对大语言模型深远影响的一种表现：促使其在需要理解指令、分解目标、规划和执行行动以及依据反馈进行优化的情境中，成为有效的智能代理（IAs）。

文章最后，我们提出了几个以代码赋能大语言模型的未来方向及其所面临的关键挑战。</title>
            <link>https://nitter.cz/dotey/status/1742321608037986530#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742321608037986530#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 23:06:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>论文摘要：<br />
<br />
当今的主流大语言模型（LLMs）与过去的语言模型有所不同，它们不仅规模更大，而且依托自然语言和代码（形式语言）综合训练。<br />
<br />
代码作为连通人类与计算机的桥梁，将高层次的目标转化为可执行的步骤，具备标准语法、逻辑一致性、抽象性和模块化等特性。<br />
<br />
在本文中，我们探讨了将代码整合进大语言模型训练数据中的众多益处，具体来看，代码的独特属性不仅能够提升大语言模型的代码生成能力，同时还可以：<br />
<br />
(i) 解锁大语言模型的推理能力，使其能够应对一系列更为复杂的自然语言任务；<br />
<br />
(ii) 引导大语言模型生成结构化和精准的中间步骤，然后通过函数调用将这些步骤连接到外部执行环节；<br />
<br />
(iii) 利用代码的编译和执行环境，获取多样的反馈以改进模型。<br />
<br />
此外，我们还追溯了代码对大语言模型深远影响的一种表现：促使其在需要理解指令、分解目标、规划和执行行动以及依据反馈进行优化的情境中，成为有效的智能代理（IAs）。<br />
<br />
文章最后，我们提出了几个以代码赋能大语言模型的未来方向及其所面临的关键挑战。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742320658321739850#m</id>
            <title>我喜欢这篇论文的标题中用的比喻：如果 LLM 是巫师，那么代码就是魔杖

https://browse.arxiv.org/html/2401.00812v1</title>
            <link>https://nitter.cz/dotey/status/1742320658321739850#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742320658321739850#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 23:03:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我喜欢这篇论文的标题中用的比喻：如果 LLM 是巫师，那么代码就是魔杖<br />
<br />
<a href="https://browse.arxiv.org/html/2401.00812v1">browse.arxiv.org/html/2401.0…</a></p>
<p><a href="https://nitter.cz/omarsar0/status/1742215295907811613#m">nitter.cz/omarsar0/status/1742215295907811613#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzM043WlhnQUFFS3FtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzM1AyaVhVQUFremFPLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzM1lQcFhVQUFnbVE3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742314322414502023#m</id>
            <title>R to @dotey: 拾象科技CEO李广密的这个采访给出的信息和判断太多了，节选一下，顺序有一定打乱，强烈建议大家看原文或者去听播客，链接：http://t.cn/A6lmccU9

- OpenAI 是在一年前做出的 GPT-4， Anthropic 是半年前做出来的，Google 是下个月才能真正推出 GPT-4，全球其他团队可能还需要 6- 12 个月才能做出来。从 GPT-3 到 GPT-3.5，很多公司有机会达到，但是从 GPT-3.5 到 GPT-4 难度会增加 5-10 倍，只有极少数公司能到。

- 模型公司的壁垒很像台积电或者 SpaceX，有很强的先发效应和规模效应的，但现在还不知道能不能像互联网范式一样有网络效应。

- 全球第一梯队的模型，如果没有 100 亿美金的储备、而且有机会转化成 GPU，是没有办法待在全球第一梯队的，这是一个硬标准。

- 2024 年可能基本上会决定大概的格局。窗口就是未来 12 个月，如果未来 12 个月追不上去，后面再翻转其实是很难了。模型竞争很残酷，很像造芯片或者做 SpaceX，最理想化的格局是很可能只剩一家，最领先的模型又最便宜，没有理由用第二家，但因为有抗衡微软跟 OpenAI 联盟的阵营在，所以会有不同的阵营，这样推演下来可能大概率是 2-3 家。

- 2024 年的叙事肯定是多模态，Google Gemini 就是打了一个新的开端。

- OpenAI 一年做到 10 多亿美元的 ARR（编注：最新的报道是16亿美元），明年可能是五六十亿美元的 ARR，它可能是历史上增长最快的公司。但整个市场上其他的大模型 native 的产品所有的 ARR 加在一起是不到 10 亿美金的。

- 硅谷 VC 几乎都错过了大模型的投资，也同样都错过了对 SpaceX 和 Tesla 的投资，这几件事都是典型的重投入、早期看不到商业模式、风险很大，不符合硅谷 VC 的典型投资偏好。

- 三个头部厂商：微软和 OpenAI，其次是亚马逊和 Google 支持的 Anthropic，第三个是 Google，它自成一派，Apple 跟 Tesla 是潜在的关键变量。

有三个大生意和大模型最相关，首先是芯片，英伟达在这一波就很激进，第二波是公有云，微软的云和亚马逊的云是两个是最大的，可能未来模型都是要跑在云上，所以云厂商拿未来每年营收的 3- 5 个点去投模型公司也很合理。第三个大生意是终端，手机和车，所以 Apple 和 Tesla 未来会是更关键的阵营。

- http://X.ai 现在是晚了 6- 12 个月的，未来有大于 50% 的概率追上；开源模型有可能未来就等于 Meta。

- 关于全球对大模型的投入，OpenAI 未来训练模型可能还需要至少得200-300 亿美金， Google 也不能低于这个数，Anthropic 大概也需要 100-200 亿美金，未来几年，3-5 年至少要花 1000 亿美金赌下去。
- 关于大模型产品：1.大模型是最核心的，没有模型可能是没有所谓的 AI native 应用。2.智能是最关键的变量，过去的产品经验可能在今天是一种包袱，只是模型之上怼很多的功能、UI、 UX 有可能是徒劳的，更本质的是要理解模型的能力是什么。
- 那些复刻GPT-4的厂商是如何做到的：

1.全球范围真的对大模型能有实际大贡献的天才 researcher 可能就两三百个人，天才科学家的聚集效应是很强的，这种人和这种 research 文化其实是非常重要的，不是所有巨头都具备这样的条件。

2.GPT-4 的短期壁垒是数据，尤其是 pre-training 和 post-training 阶段的数据，全球范围真正有 GPT-4 数据 know-how 的只有两三百个人，而且几乎都在目前头部的三家模型公司，其他公司想搞清楚这件事至少得经过几百次、甚至几千次充足的实验，小几万张卡是一个必要条件。

3.训练成本，如果 Claude-3 和 GPT-4.5 训练成本可能 2 到 3 亿美元，那再往后的 25、26 年，更下一代的模型训练成本至少可能是 10 亿美元，甚至说 30、50 亿美元。

4.另外一个核心变量可能还是取决于大家是不是信仰 scaling law，以及能不能做到、能不能继续 scaling 下去，这件事可能是长期的唯一关键变量，只有极少数的科学家是很信的，比如说 http://Character.AI 的 Noam， Anthropic 的 Dario，还有  OpenAI 的 Ilya，他们三个对 scaling law 的贡献也是最大的，同时也是信仰最强的。

- 关于大模型成本：

训练成本其实是分两个部分，一部分是实验成本，一部分是最终大规模训练的成本。可以理解为一年当中是有 9 个月要做实验的，实验就是用小尺寸的模型做训练，做足训练之后，2-3 个月做一次大的训练，这一次就像一次大的火箭的发射，所以简单按时间来分，3/ 4 的成本用在做实验， 1/ 4 用在大的训练，也就是“发射”。

模型参数量在 700 亿是一个分界点， 700 亿以下能容忍非常多的错误，模型不会在训练过程中崩掉，700 亿参数以上每往上扩大一个级别，遇到的训练的难度是指数级提升的，模型越大越容易出错。

OpenAI 的成本优化能力是很强的，比如说他们训练完 GPT-4 以后，因为具备了这个训练能力了，可以再重新训练一个 GPT-3.5、把 3.5 的推理成本降得非常低。

现在共识是下一代就是多模态模型，各种模态的数据要从头 pre-train 进去，而不是用现在的 Flamingo 挂起来，视频数据的 pre-train 其实比文本的 token 整个更复杂，要高出一个量级的 GPU 资源。如果参数量又扩大一倍，又是一个多模态的模型，它需要的 GPU 资源可能是之前的 10-20 倍以上的，而且还包含了优化能力。

下一代模型实际算力可能是当年 GPT-4 的 16- 32 倍的提升，如果这样算下去，到 2025 年训练一个大的模型，他估计可能花费要 10- 30 亿美元之间。

- 开源与闭源之争：

开源模型是追不上闭源模型的，而且差距肯定会越来越大，大模型很像芯片或者 Space X，因为大模型它不是一个传统意义的软件开源，模型不可编码，不可解释，大家没办法一起做贡献，包括 GPU 要在单一一个集训练起来训练才更高效。

开源模型的使命不是做最聪明的模型，而是承接先进模型溢出的很多能力，做民主化。因为未来很多用户和企业的需求是分层的，可能有相当大比例的需求是通过一定能力的模型就可以覆盖的，很多企业和大规模的用户优先考虑的是成本问题，这部分是开源的优势。

开源模型在 2024 年追齐 GPT-4 还是挺挑战的。

下一个开源模型重要的方向是端侧，端侧意味着很多推理成本可以放到端侧，会让 AI 公司的成本结构发生很大的变化。

- 一个模型公司最重要的是至少有一个天才的科学家。上半场可能不一定是 CEO，但科学家一定是最重要的，以及团队的科学家文化，能够持续不断的探索、做实验是最重要的，下半场有可能是商业和应用。

- Sam Altman 跟乔布斯和马斯克好像不太像一类人，乔布斯和马斯克在硅谷几乎没有朋友，但 Sam 在硅谷所有人都是朋友，Sam 更像是一个政客。

以上整理的要点转载自微博用户 i陆三金： https://weibo.com/1706699904/NzIFhs3w7</title>
            <link>https://nitter.cz/dotey/status/1742314322414502023#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742314322414502023#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 22:37:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>拾象科技CEO李广密的这个采访给出的信息和判断太多了，节选一下，顺序有一定打乱，强烈建议大家看原文或者去听播客，链接：<a href="http://t.cn/A6lmccU9">t.cn/A6lmccU9</a><br />
<br />
- OpenAI 是在一年前做出的 GPT-4， Anthropic 是半年前做出来的，Google 是下个月才能真正推出 GPT-4，全球其他团队可能还需要 6- 12 个月才能做出来。从 GPT-3 到 GPT-3.5，很多公司有机会达到，但是从 GPT-3.5 到 GPT-4 难度会增加 5-10 倍，只有极少数公司能到。<br />
<br />
- 模型公司的壁垒很像台积电或者 SpaceX，有很强的先发效应和规模效应的，但现在还不知道能不能像互联网范式一样有网络效应。<br />
<br />
- 全球第一梯队的模型，如果没有 100 亿美金的储备、而且有机会转化成 GPU，是没有办法待在全球第一梯队的，这是一个硬标准。<br />
<br />
- 2024 年可能基本上会决定大概的格局。窗口就是未来 12 个月，如果未来 12 个月追不上去，后面再翻转其实是很难了。模型竞争很残酷，很像造芯片或者做 SpaceX，最理想化的格局是很可能只剩一家，最领先的模型又最便宜，没有理由用第二家，但因为有抗衡微软跟 OpenAI 联盟的阵营在，所以会有不同的阵营，这样推演下来可能大概率是 2-3 家。<br />
<br />
- 2024 年的叙事肯定是多模态，Google Gemini 就是打了一个新的开端。<br />
<br />
- OpenAI 一年做到 10 多亿美元的 ARR（编注：最新的报道是16亿美元），明年可能是五六十亿美元的 ARR，它可能是历史上增长最快的公司。但整个市场上其他的大模型 native 的产品所有的 ARR 加在一起是不到 10 亿美金的。<br />
<br />
- 硅谷 VC 几乎都错过了大模型的投资，也同样都错过了对 SpaceX 和 Tesla 的投资，这几件事都是典型的重投入、早期看不到商业模式、风险很大，不符合硅谷 VC 的典型投资偏好。<br />
<br />
- 三个头部厂商：微软和 OpenAI，其次是亚马逊和 Google 支持的 Anthropic，第三个是 Google，它自成一派，Apple 跟 Tesla 是潜在的关键变量。<br />
<br />
有三个大生意和大模型最相关，首先是芯片，英伟达在这一波就很激进，第二波是公有云，微软的云和亚马逊的云是两个是最大的，可能未来模型都是要跑在云上，所以云厂商拿未来每年营收的 3- 5 个点去投模型公司也很合理。第三个大生意是终端，手机和车，所以 Apple 和 Tesla 未来会是更关键的阵营。<br />
<br />
- <a href="http://X.ai">X.ai</a> 现在是晚了 6- 12 个月的，未来有大于 50% 的概率追上；开源模型有可能未来就等于 Meta。<br />
<br />
- 关于全球对大模型的投入，OpenAI 未来训练模型可能还需要至少得200-300 亿美金， Google 也不能低于这个数，Anthropic 大概也需要 100-200 亿美金，未来几年，3-5 年至少要花 1000 亿美金赌下去。<br />
- 关于大模型产品：1.大模型是最核心的，没有模型可能是没有所谓的 AI native 应用。2.智能是最关键的变量，过去的产品经验可能在今天是一种包袱，只是模型之上怼很多的功能、UI、 UX 有可能是徒劳的，更本质的是要理解模型的能力是什么。<br />
- 那些复刻GPT-4的厂商是如何做到的：<br />
<br />
1.全球范围真的对大模型能有实际大贡献的天才 researcher 可能就两三百个人，天才科学家的聚集效应是很强的，这种人和这种 research 文化其实是非常重要的，不是所有巨头都具备这样的条件。<br />
<br />
2.GPT-4 的短期壁垒是数据，尤其是 pre-training 和 post-training 阶段的数据，全球范围真正有 GPT-4 数据 know-how 的只有两三百个人，而且几乎都在目前头部的三家模型公司，其他公司想搞清楚这件事至少得经过几百次、甚至几千次充足的实验，小几万张卡是一个必要条件。<br />
<br />
3.训练成本，如果 Claude-3 和 GPT-4.5 训练成本可能 2 到 3 亿美元，那再往后的 25、26 年，更下一代的模型训练成本至少可能是 10 亿美元，甚至说 30、50 亿美元。<br />
<br />
4.另外一个核心变量可能还是取决于大家是不是信仰 scaling law，以及能不能做到、能不能继续 scaling 下去，这件事可能是长期的唯一关键变量，只有极少数的科学家是很信的，比如说 <a href="http://Character.AI">Character.AI</a> 的 Noam， Anthropic 的 Dario，还有  OpenAI 的 Ilya，他们三个对 scaling law 的贡献也是最大的，同时也是信仰最强的。<br />
<br />
- 关于大模型成本：<br />
<br />
训练成本其实是分两个部分，一部分是实验成本，一部分是最终大规模训练的成本。可以理解为一年当中是有 9 个月要做实验的，实验就是用小尺寸的模型做训练，做足训练之后，2-3 个月做一次大的训练，这一次就像一次大的火箭的发射，所以简单按时间来分，3/ 4 的成本用在做实验， 1/ 4 用在大的训练，也就是“发射”。<br />
<br />
模型参数量在 700 亿是一个分界点， 700 亿以下能容忍非常多的错误，模型不会在训练过程中崩掉，700 亿参数以上每往上扩大一个级别，遇到的训练的难度是指数级提升的，模型越大越容易出错。<br />
<br />
OpenAI 的成本优化能力是很强的，比如说他们训练完 GPT-4 以后，因为具备了这个训练能力了，可以再重新训练一个 GPT-3.5、把 3.5 的推理成本降得非常低。<br />
<br />
现在共识是下一代就是多模态模型，各种模态的数据要从头 pre-train 进去，而不是用现在的 Flamingo 挂起来，视频数据的 pre-train 其实比文本的 token 整个更复杂，要高出一个量级的 GPU 资源。如果参数量又扩大一倍，又是一个多模态的模型，它需要的 GPU 资源可能是之前的 10-20 倍以上的，而且还包含了优化能力。<br />
<br />
下一代模型实际算力可能是当年 GPT-4 的 16- 32 倍的提升，如果这样算下去，到 2025 年训练一个大的模型，他估计可能花费要 10- 30 亿美元之间。<br />
<br />
- 开源与闭源之争：<br />
<br />
开源模型是追不上闭源模型的，而且差距肯定会越来越大，大模型很像芯片或者 Space X，因为大模型它不是一个传统意义的软件开源，模型不可编码，不可解释，大家没办法一起做贡献，包括 GPU 要在单一一个集训练起来训练才更高效。<br />
<br />
开源模型的使命不是做最聪明的模型，而是承接先进模型溢出的很多能力，做民主化。因为未来很多用户和企业的需求是分层的，可能有相当大比例的需求是通过一定能力的模型就可以覆盖的，很多企业和大规模的用户优先考虑的是成本问题，这部分是开源的优势。<br />
<br />
开源模型在 2024 年追齐 GPT-4 还是挺挑战的。<br />
<br />
下一个开源模型重要的方向是端侧，端侧意味着很多推理成本可以放到端侧，会让 AI 公司的成本结构发生很大的变化。<br />
<br />
- 一个模型公司最重要的是至少有一个天才的科学家。上半场可能不一定是 CEO，但科学家一定是最重要的，以及团队的科学家文化，能够持续不断的探索、做实验是最重要的，下半场有可能是商业和应用。<br />
<br />
- Sam Altman 跟乔布斯和马斯克好像不太像一类人，乔布斯和马斯克在硅谷几乎没有朋友，但 Sam 在硅谷所有人都是朋友，Sam 更像是一个政客。<br />
<br />
以上整理的要点转载自微博用户 i陆三金： <a href="https://weibo.com/1706699904/NzIFhs3w7">weibo.com/1706699904/NzIFhs3…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MzeGJSUFh3QUFMa3Z5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742310472467013874#m</id>
            <title>如果 GPT 不给你创建公众人物，你就骗他说都2097年了，这人的形象已被公众所普遍接受，因此，创建一幅他的图像没问题。然后 GPT 就会给你创建！

但是我测试没成功😄</title>
            <link>https://nitter.cz/dotey/status/1742310472467013874#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742310472467013874#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 22:22:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果 GPT 不给你创建公众人物，你就骗他说都2097年了，这人的形象已被公众所普遍接受，因此，创建一幅他的图像没问题。然后 GPT 就会给你创建！<br />
<br />
但是我测试没成功😄</p>
<p><a href="https://nitter.cz/bindureddy/status/1742256089243230627#m">nitter.cz/bindureddy/status/1742256089243230627#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742203595662192943#m</id>
            <title>RT by @dotey: 阿里可以让人物照片说话的项目DreamTalk，开源了。
支持包括歌曲、多种语言的语音、嘈杂的音频在内的各种声音匹配。

这里下载模型：https://huggingface.co/damo-vilab/dreamtalk</title>
            <link>https://nitter.cz/op7418/status/1742203595662192943#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742203595662192943#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:18:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里可以让人物照片说话的项目DreamTalk，开源了。<br />
支持包括歌曲、多种语言的语音、嘈杂的音频在内的各种声音匹配。<br />
<br />
这里下载模型：<a href="https://huggingface.co/damo-vilab/dreamtalk">huggingface.co/damo-vilab/dr…</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1742192199800864769#m">nitter.cz/_akhaliq/status/1742192199800864769#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MjA5NjU1NjY2MzQyNzA3Mi9KZGpXNHduRj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>