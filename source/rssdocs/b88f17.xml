<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748946902425424281#m</id>
            <title>JigSpace 的 visionOS App Store 预览视频</title>
            <link>https://nitter.cz/dotey/status/1748946902425424281#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748946902425424281#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 05:53:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>JigSpace 的 visionOS App Store 预览视频</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDg5NDY4MjQxMTc3ODQ1NzYvcHUvaW1nL0VybkNtdzBOT0FxZnBnTTEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748830916825501704#m</id>
            <title>“大语言模型需要 Token 来思考”

我早先用 CoT（思维链）就犯过错误：在 Prompt 里面要求 LLM 一步步操作，但是为了节约Token，并没有输出中间步骤的结果，导致完全是无效的。

CoT 的关键是提供额外的信息存储点，无论这些信息是 LLM 生成的还是人工生成的，无论是一次还是多次。</title>
            <link>https://nitter.cz/dotey/status/1748830916825501704#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748830916825501704#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 22:12:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“大语言模型需要 Token 来思考”<br />
<br />
我早先用 CoT（思维链）就犯过错误：在 Prompt 里面要求 LLM 一步步操作，但是为了节约Token，并没有输出中间步骤的结果，导致完全是无效的。<br />
<br />
CoT 的关键是提供额外的信息存储点，无论这些信息是 LLM 生成的还是人工生成的，无论是一次还是多次。</p>
<p><a href="https://nitter.cz/karpathy/status/1708142056735228229#m">nitter.cz/karpathy/status/1708142056735228229#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748827229109334363#m</id>
            <title>昨天推荐的这篇《AlphaCodium：引领代码生成新境界，从提示工程到流程工程》里面提到了 6 个使用LLM代码生成的最佳实践：

1. 使用 YAML 结构输出而不是 JSON 格式输出

有两个原因：
1) YAML 格式容错率更高，JSON 很容易导致格式错误不能解析
2) YAML 格式的内容消耗的 Token 更少

2. 要点列表（Bullet points）分析 

当让大语言模型 (LLM) 分析问题时，通常以要点列表（Bullet points）格式要求输出会获得更好的结果。要点促进了对问题的深入理解，并迫使模型将输出划分为逻辑上的语义区域，从而提高了结果的质量。例如，以要点自我反思问题（见图 2），每个要点代表了对问题不同部分的语义理解——一般描述、目标与规则、输入结构、输出结构。

3. 大语言模型在生成模块化代码方面更加出色

让大语言模型（LLM）去编写一个长篇的单个函数时，常常会遇到问题：代码中经常出现错误或逻辑漏洞。更严重的是，这种庞大而单一的代码块会影响到后续的迭代修复工作。即便提供了错误信息，模型也很难准确地定位和解决问题。但如果我们明确指导模型：“把生成的代码分割成多个小的子功能模块，并给它们起上有意义的名称”，结果会好得多，生成的代码错误更少，且在迭代修复的阶段有更高的成功率。

部分Prompt参考图3

4. 灵活决策和双重验证

大语言模型在处理那些需要深思熟虑、合理推断和做出严肃、非常规决策的代码任务时，往往会遇到困难。例如，在生成问题的附加测试时，模型生成的测试常常存在错误。

为了解决这个问题，可以引入了双重验证的过程。在这个过程中，模型在生成了初始输出之后，会被要求再次生成相同的输出，并在必要时进行修正。比如，模型在接收到它自己生成的 AI 测试作为输入后，需要重新生成这些测试，并及时纠正其中的错误（如果有的话）。这种双重验证的步骤，不仅促使模型进行批判性思考和推理，而且比直接提出“这个测试正确吗？”这样的是/否问题更为有效。

5. 延迟做决策，避免直接提问，给予探索空间

当我们直接向模型询问复杂问题时，经常会得到错误或不切实际的答案。因此，我们采取了类似 Karpathy 在下面的推文中所述的方法，逐步积累数据，从简单任务逐渐过渡到复杂任务：

- 首先从最简单的任务开始，即对问题进行自我反思和关于公开测试用例的推理。
- 然后转向生成附加的 AI 测试和可能的问题解决方案。
- 只有在得到模型对上述任务的回答后，我们才进入实际的代码生成和运行修复的迭代过程。

再比如，不是选择一个单一的算法解决方案，而是评估并排序多个可能的解决方案，优先考虑排名靠前的方案进行初始代码编写。由于模型可能会出错，我们更倾向于避免做出不可逆的决定，而是留出空间进行探索，以及尝试不同可能解决方案的代码迭代。

6. 流程导向的监督方式

在解决复杂问题时，不寄希望于一步解决问题，而是设计一个科学的流程，在流程的每一步中逐步积累数据，再每一个阶段都加入新的数据。

以文中解决 CodeContests 编程竞赛问题为例，设计了一个两个阶段的若干步骤的流程，每一个步骤都会引入新的数据，比如说第一步是对题目反思得到反思后的数据，第二步是分析公开测试用例得到测相关的数据，第三步生成可能解决方案得到解决方案的数据等等。

对于每一步的数据，采用验证、选择等方式来确保数据的质量和准确，每一步都是下一步的基础。但即使如此也无法保证每一步数据的正确性，所以在第二个阶段还引入了迭代的模式，这样在遇到数据错误，可以回到前面的步骤对数据进行修正。

以上就是用大语言模型生成代码的 6 个最佳实践，最后简单总结以下：
1. YAML 格式化输出要求：
模型需要能够以 YAML（一种数据表示格式）的方式输出数据，这种输出应与 Pydantic（一种 Python 数据模型库）所定义的类结构相匹配。

2. 逻辑性强的语义要点分析：
鼓励使用 YAML 格式来组织和分析关键信息，通过这种方式可以更加逻辑清晰地划分内容段落，有助于深入理解复杂的概念。

3. 编写模块化代码的推荐：
推荐将代码分解成多个小型的子功能模块，并为每个模块赋予清晰、具有描述性的名称，这样不仅使代码更易于管理，也更便于理解其功能。

4. 灵活决策与双重验证：
当模型生成了一个输出后，再次让模型生成同样的输出，同时在必要时对其进行修正。

5. 保留探索的可能性：
考虑到模型可能会犯错，应避免作出不可逆转的决策，并为寻找多种可能的解决方案提供空间。

6. 流程导向的监督方式：
支持逐步积累数据的流动方式，并在流程的不同阶段考虑加入新的数据。

完整译文参考：https://baoyu.io/translations/prompt-engineering/alphacodium-state-of-the-art-code-generation-for-code-contests</title>
            <link>https://nitter.cz/dotey/status/1748827229109334363#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748827229109334363#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 21:57:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天推荐的这篇《AlphaCodium：引领代码生成新境界，从提示工程到流程工程》里面提到了 6 个使用LLM代码生成的最佳实践：<br />
<br />
1. 使用 YAML 结构输出而不是 JSON 格式输出<br />
<br />
有两个原因：<br />
1) YAML 格式容错率更高，JSON 很容易导致格式错误不能解析<br />
2) YAML 格式的内容消耗的 Token 更少<br />
<br />
2. 要点列表（Bullet points）分析 <br />
<br />
当让大语言模型 (LLM) 分析问题时，通常以要点列表（Bullet points）格式要求输出会获得更好的结果。要点促进了对问题的深入理解，并迫使模型将输出划分为逻辑上的语义区域，从而提高了结果的质量。例如，以要点自我反思问题（见图 2），每个要点代表了对问题不同部分的语义理解——一般描述、目标与规则、输入结构、输出结构。<br />
<br />
3. 大语言模型在生成模块化代码方面更加出色<br />
<br />
让大语言模型（LLM）去编写一个长篇的单个函数时，常常会遇到问题：代码中经常出现错误或逻辑漏洞。更严重的是，这种庞大而单一的代码块会影响到后续的迭代修复工作。即便提供了错误信息，模型也很难准确地定位和解决问题。但如果我们明确指导模型：“把生成的代码分割成多个小的子功能模块，并给它们起上有意义的名称”，结果会好得多，生成的代码错误更少，且在迭代修复的阶段有更高的成功率。<br />
<br />
部分Prompt参考图3<br />
<br />
4. 灵活决策和双重验证<br />
<br />
大语言模型在处理那些需要深思熟虑、合理推断和做出严肃、非常规决策的代码任务时，往往会遇到困难。例如，在生成问题的附加测试时，模型生成的测试常常存在错误。<br />
<br />
为了解决这个问题，可以引入了双重验证的过程。在这个过程中，模型在生成了初始输出之后，会被要求再次生成相同的输出，并在必要时进行修正。比如，模型在接收到它自己生成的 AI 测试作为输入后，需要重新生成这些测试，并及时纠正其中的错误（如果有的话）。这种双重验证的步骤，不仅促使模型进行批判性思考和推理，而且比直接提出“这个测试正确吗？”这样的是/否问题更为有效。<br />
<br />
5. 延迟做决策，避免直接提问，给予探索空间<br />
<br />
当我们直接向模型询问复杂问题时，经常会得到错误或不切实际的答案。因此，我们采取了类似 Karpathy 在下面的推文中所述的方法，逐步积累数据，从简单任务逐渐过渡到复杂任务：<br />
<br />
- 首先从最简单的任务开始，即对问题进行自我反思和关于公开测试用例的推理。<br />
- 然后转向生成附加的 AI 测试和可能的问题解决方案。<br />
- 只有在得到模型对上述任务的回答后，我们才进入实际的代码生成和运行修复的迭代过程。<br />
<br />
再比如，不是选择一个单一的算法解决方案，而是评估并排序多个可能的解决方案，优先考虑排名靠前的方案进行初始代码编写。由于模型可能会出错，我们更倾向于避免做出不可逆的决定，而是留出空间进行探索，以及尝试不同可能解决方案的代码迭代。<br />
<br />
6. 流程导向的监督方式<br />
<br />
在解决复杂问题时，不寄希望于一步解决问题，而是设计一个科学的流程，在流程的每一步中逐步积累数据，再每一个阶段都加入新的数据。<br />
<br />
以文中解决 CodeContests 编程竞赛问题为例，设计了一个两个阶段的若干步骤的流程，每一个步骤都会引入新的数据，比如说第一步是对题目反思得到反思后的数据，第二步是分析公开测试用例得到测相关的数据，第三步生成可能解决方案得到解决方案的数据等等。<br />
<br />
对于每一步的数据，采用验证、选择等方式来确保数据的质量和准确，每一步都是下一步的基础。但即使如此也无法保证每一步数据的正确性，所以在第二个阶段还引入了迭代的模式，这样在遇到数据错误，可以回到前面的步骤对数据进行修正。<br />
<br />
以上就是用大语言模型生成代码的 6 个最佳实践，最后简单总结以下：<br />
1. YAML 格式化输出要求：<br />
模型需要能够以 YAML（一种数据表示格式）的方式输出数据，这种输出应与 Pydantic（一种 Python 数据模型库）所定义的类结构相匹配。<br />
<br />
2. 逻辑性强的语义要点分析：<br />
鼓励使用 YAML 格式来组织和分析关键信息，通过这种方式可以更加逻辑清晰地划分内容段落，有助于深入理解复杂的概念。<br />
<br />
3. 编写模块化代码的推荐：<br />
推荐将代码分解成多个小型的子功能模块，并为每个模块赋予清晰、具有描述性的名称，这样不仅使代码更易于管理，也更便于理解其功能。<br />
<br />
4. 灵活决策与双重验证：<br />
当模型生成了一个输出后，再次让模型生成同样的输出，同时在必要时对其进行修正。<br />
<br />
5. 保留探索的可能性：<br />
考虑到模型可能会犯错，应避免作出不可逆转的决策，并为寻找多种可能的解决方案提供空间。<br />
<br />
6. 流程导向的监督方式：<br />
支持逐步积累数据的流动方式，并在流程的不同阶段考虑加入新的数据。<br />
<br />
完整译文参考：<a href="https://baoyu.io/translations/prompt-engineering/alphacodium-state-of-the-art-code-generation-for-code-contests">baoyu.io/translations/prompt…</a></p>
<p><a href="https://nitter.cz/dotey/status/1748503587682967775#m">nitter.cz/dotey/status/1748503587682967775#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VVVXpJcldvQUFZR3dRLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VVVTFJS1hNQUFpMm41LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VVVTdKTFgwQUV2dXd3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VVVkJxUlc4QUF1SUFjLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748814824119644272#m</id>
            <title>一个科技文章翻译GPT https://chat.openai.com/g/g-uBhKUJJTl-ke-ji-wen-zhang-fan-yi 的经典案例：

### 直译
对于大语言模型(LLM)来说，理想的训练数据并不是你写下的内容。而是你内心思考的完整序列，以及在写作过程中的所有个别编辑。
但你只能用现有的数据来应对。

停一下，这和 Neuralink 无关，哈哈。
无论如何，这只是启蒙的第一阶段。
启蒙的第二阶段是，对于大语言模型(LLM)来说，理想的训练数据根本就不是训练数据。
而是你从阅读它的人那里得到的赞许。
但你只能用现有的数据来应对。

***

### 问题
1. 第一段中，“对于大语言模型(LLM)来说，理想的训练数据并不是你写下的内容。”这句话在中文中读起来略显生硬，需要调整语序和用词使其更加符合中文习惯。
2. “而是你内心思考的完整序列，以及在写作过程中的所有个别编辑。”这句话的表达略显晦涩，需要更加通俗易懂的表述。
3. “但你只能用现有的数据来应对。”这句话的语气和语境转换较生硬，需要更加流畅的衔接。
4. “停一下，这和 Neuralink 无关，哈哈。”这句话在中文中的直接翻译感觉突兀，需要调整语气和上下文的衔接。
5. “启蒙的第二阶段是，对于大语言模型(LLM)来说，理想的训练数据根本就不是训练数据。”这句话的结构复杂且难以理解，需要更简洁明了的表述。
6. “而是你从阅读它的人那里得到的赞许。”这句话的表达不够直观，需要更加具体和形象化。
7. 整体段落需要更好地连接和过渡，以提高整体的可读性。

***

### 意译
对于大语言模型（LLM）而言，最理想的训练数据并不仅仅是你笔下的文字。它其实包括了你思考过程中的每一个细节，以及写作时所做的每一次修改。
不过，我们只能尽力利用现有的资源。

别误会，这跟 Neuralink 完全没关系，哈哈。
话说回来，这只是认识到这一点的第一步。
第二步则是意识到，对大语言模型（LLM）来说，最理想的“训练数据”其实根本不是数据。
而是读者对你作品的点赞和认可。
但最终，我们还是只能利用手头上的资源。

https://chat.openai.com/share/ce31d429-1a2e-4733-9aee-f28af4e8c534</title>
            <link>https://nitter.cz/dotey/status/1748814824119644272#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748814824119644272#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 21:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个科技文章翻译GPT <a href="https://chat.openai.com/g/g-uBhKUJJTl-ke-ji-wen-zhang-fan-yi">chat.openai.com/g/g-uBhKUJJT…</a> 的经典案例：<br />
<br />
### 直译<br />
对于大语言模型(LLM)来说，理想的训练数据并不是你写下的内容。而是你内心思考的完整序列，以及在写作过程中的所有个别编辑。<br />
但你只能用现有的数据来应对。<br />
<br />
停一下，这和 Neuralink 无关，哈哈。<br />
无论如何，这只是启蒙的第一阶段。<br />
启蒙的第二阶段是，对于大语言模型(LLM)来说，理想的训练数据根本就不是训练数据。<br />
而是你从阅读它的人那里得到的赞许。<br />
但你只能用现有的数据来应对。<br />
<br />
***<br />
<br />
### 问题<br />
1. 第一段中，“对于大语言模型(LLM)来说，理想的训练数据并不是你写下的内容。”这句话在中文中读起来略显生硬，需要调整语序和用词使其更加符合中文习惯。<br />
2. “而是你内心思考的完整序列，以及在写作过程中的所有个别编辑。”这句话的表达略显晦涩，需要更加通俗易懂的表述。<br />
3. “但你只能用现有的数据来应对。”这句话的语气和语境转换较生硬，需要更加流畅的衔接。<br />
4. “停一下，这和 Neuralink 无关，哈哈。”这句话在中文中的直接翻译感觉突兀，需要调整语气和上下文的衔接。<br />
5. “启蒙的第二阶段是，对于大语言模型(LLM)来说，理想的训练数据根本就不是训练数据。”这句话的结构复杂且难以理解，需要更简洁明了的表述。<br />
6. “而是你从阅读它的人那里得到的赞许。”这句话的表达不够直观，需要更加具体和形象化。<br />
7. 整体段落需要更好地连接和过渡，以提高整体的可读性。<br />
<br />
***<br />
<br />
### 意译<br />
对于大语言模型（LLM）而言，最理想的训练数据并不仅仅是你笔下的文字。它其实包括了你思考过程中的每一个细节，以及写作时所做的每一次修改。<br />
不过，我们只能尽力利用现有的资源。<br />
<br />
别误会，这跟 Neuralink 完全没关系，哈哈。<br />
话说回来，这只是认识到这一点的第一步。<br />
第二步则是意识到，对大语言模型（LLM）来说，最理想的“训练数据”其实根本不是数据。<br />
而是读者对你作品的点赞和认可。<br />
但最终，我们还是只能利用手头上的资源。<br />
<br />
<a href="https://chat.openai.com/share/ce31d429-1a2e-4733-9aee-f28af4e8c534">chat.openai.com/share/ce31d4…</a></p>
<p><a href="https://nitter.cz/karpathy/status/1748784260318990496#m">nitter.cz/karpathy/status/1748784260318990496#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0ODA4NzA2Nzk2NjM1MzQwOC9Ya0UzT21aZj9mb3JtYXQ9cG5nJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748642115691639235#m</id>
            <title>看到一家新机器人公司，MagicLab，看起来人形机器人要像波士顿动力一样能实现空翻，不过这个是电驱的，成本上更经济一些。

空翻这种动作对于机器人要求还是蛮高的，目前没怎么看到电驱机器人能做到，不仅要有足够的力量，还需要很高的的控制精度，这意味着机器人在危险或恶劣的环境中更好的运动适应性，比如复杂的火场进出、人员救援、森林巡逻等。</title>
            <link>https://nitter.cz/dotey/status/1748642115691639235#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748642115691639235#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 09:42:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看到一家新机器人公司，MagicLab，看起来人形机器人要像波士顿动力一样能实现空翻，不过这个是电驱的，成本上更经济一些。<br />
<br />
空翻这种动作对于机器人要求还是蛮高的，目前没怎么看到电驱机器人能做到，不仅要有足够的力量，还需要很高的的控制精度，这意味着机器人在危险或恶劣的环境中更好的运动适应性，比如复杂的火场进出、人员救援、森林巡逻等。</p>
<p><a href="https://nitter.cz/MagicLab244144/status/1748377293595218138#m">nitter.cz/MagicLab244144/status/1748377293595218138#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Yangyixxxx/status/1748593506053132775#m</id>
            <title>RT by @dotey: 找一个很简单的切入点，不停地做，就会有很大收获。
比如资源嗅探这件事儿，做到极致就是一个矩阵，前端所有的逻辑都一样，一个按钮，一个地址，一个端（移动端），不断换内容。
- 小红书图片下载器
- 推特视频下载器
- ins图片下载器

这种从大平台下载图片去水印的场景太多了，抱着大树做就完了，甚至还可以找更垂直更细分的场景，比如淘宝图片和拼多多图片（很多人不做美工，下载了调一下直接上架）

低频刚需的场景用户不愿意付费，那就看广告。下载一次出一次激励视频。反正APP里全是广告，也没什么服务成本。

假如1个注册uv30天内平均使用30次，1次广告收益为0.1美金。那30日ARPU是3美金。卖个6美金永久去广告就完了。

就这样一个壳把所有场景都做完。无非后期只需要做的事情就是维护一下下载逻辑。当然，这个大部分情况下也有很多开源项目在做。

把时间变资产最简单的方式就是做一个固定的产品，等着它开始变成收益。一个不行，就两个，就三个，爆了一个，就会把所有投入都回收回来。</title>
            <link>https://nitter.cz/Yangyixxxx/status/1748593506053132775#m</link>
            <guid isPermaLink="false">https://nitter.cz/Yangyixxxx/status/1748593506053132775#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 06:29:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>找一个很简单的切入点，不停地做，就会有很大收获。<br />
比如资源嗅探这件事儿，做到极致就是一个矩阵，前端所有的逻辑都一样，一个按钮，一个地址，一个端（移动端），不断换内容。<br />
- 小红书图片下载器<br />
- 推特视频下载器<br />
- ins图片下载器<br />
<br />
这种从大平台下载图片去水印的场景太多了，抱着大树做就完了，甚至还可以找更垂直更细分的场景，比如淘宝图片和拼多多图片（很多人不做美工，下载了调一下直接上架）<br />
<br />
低频刚需的场景用户不愿意付费，那就看广告。下载一次出一次激励视频。反正APP里全是广告，也没什么服务成本。<br />
<br />
假如1个注册uv30天内平均使用30次，1次广告收益为0.1美金。那30日ARPU是3美金。卖个6美金永久去广告就完了。<br />
<br />
就这样一个壳把所有场景都做完。无非后期只需要做的事情就是维护一下下载逻辑。当然，这个大部分情况下也有很多开源项目在做。<br />
<br />
把时间变资产最简单的方式就是做一个固定的产品，等着它开始变成收益。一个不行，就两个，就三个，爆了一个，就会把所有投入都回收回来。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/yihong0618/status/1748308027147788317#m</id>
            <title>RT by @dotey: 俄罗斯这个神人每年用 SQL 来完成一个挑战来 Happy New Year.
2023 年是用 500 行 SQL 写个 GPT2… 已经坚持 10 多年了，下面图是他这 10 几年完成的各种挑战。。。
敬仰的站起来鞠了一躬。
link: https://explainextended.com/2023/12/31/happy-new-year-15/</title>
            <link>https://nitter.cz/yihong0618/status/1748308027147788317#m</link>
            <guid isPermaLink="false">https://nitter.cz/yihong0618/status/1748308027147788317#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 11:34:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>俄罗斯这个神人每年用 SQL 来完成一个挑战来 Happy New Year.<br />
2023 年是用 500 行 SQL 写个 GPT2… 已经坚持 10 多年了，下面图是他这 10 几年完成的各种挑战。。。<br />
敬仰的站起来鞠了一躬。<br />
link: <a href="https://explainextended.com/2023/12/31/happy-new-year-15/">explainextended.com/2023/12/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VNODRNdGJnQUFJTEp2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VNODRNeGJJQUFiNjhiLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VNODRNdmFnQUFqZnRhLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VNODRNdmFVQUEwd0lKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1748554598368121184#m</id>
            <title>RT by @dotey: DiffusionGPT：由LLM驱动的文本到图像生成系统

由字节跳动开发，DiffusionGPT的牛P之处在于它集成了多种领域的专家图像生成模型。

然后使用LLM来对接这些图像生成模型，让LLM来处理和理解各种文本提示。

最后根据理解的信息选择最合适的图像模型来生成图像。

这样就和GPT 4一样，通过聊天画图...

DiffusionGPT主要特点：

1、多样化文本提示处理：DiffusionGPT 能够理解和处理各种类型的文本提示，包括具体的指令、抽象的灵感、复杂的假设等。

2、集成多个领域专家模型：系统集成了多种领域的图像扩散模型，每个模型在其特定领域具有专业的图像生成能力。这类模型专注于特定领域的图像生成，比如自然景观、人物肖像、艺术作品等。

这意味着系统不仅能够生成普通的图像，还能够处理更特定、更复杂的图像生成任务，比如特定风格或类型的图像。模仿特定艺术家的风格、漫画风格或摄影技术。

3、大语言模型驱动：DiffusionGPT 使用大语言模型（LLM）来解析和理解用户输入的文本提示。这个过程类似于其他基于 LLM 的系统（如 GPT-4）处理文本的方式，但特别应用于理解用于图像生成的指令和描述。

4、智能选择合适的图像模型：基于对文本提示的理解，DiffusionGPT 能够智能地选择最合适的图像生成模型来生成图像。这不仅包括选择正确的模型，还涉及调整生成参数以最好地满足用户的需求。

5、输出高质量图像：通过精准地匹配文本提示与最佳生成模型，DiffusionGPT 能生成高质量、与用户需求高度吻合的图像。

6、用户反馈与优势数据库：结合用户反馈和优势数据库，系统能够根据用户偏好调整模型选择，提升图像生成的相关性和质量。

例如：在系统的早期使用中，用户可能提供对生成图像的反馈，比如“这张图片的颜色太暗了”。DiffusionGPT 利用这些反馈来调整其模型选择，使得未来的图像生成更符合用户的偏好。

主要工作原理：

1、输入解析：用户提供文本提示，如描述、指令或灵感。
大型语言模型（LLM）负责解析这些文本提示，理解其含义和需求。

2、思维树（Tree-of-Thought）构建：根据不同的图像生成任务，系统构建了一个“思维树”，这是一种组织不同图像生成模型的结构。
思维树基于先验知识和人类反馈，涵盖了多种领域的专家级模型。

3、模型选择：根据 LLM 解析的结果，系统通过思维树来确定最适合当前文本提示的图像生成模型。在选择过程中，可能还会考虑用户的偏好和历史反馈，这些信息存储在优势数据库中。

4、图像生成：一旦选定了合适的模型，该模型就会被用来生成图像。生成的图像将与输入的文本提示紧密相关，并反映出用户的意图和偏好。

5、结果输出：最终生成的图像会呈现给用户。
这些图像可以是多样化的，包括但不限于具体描述的场景、概念艺术作品或符合特定风格的图像。

6、用户反馈优化过程：

用户对生成图像的反馈被用来丰富优势数据库，进而帮助系统更好地理解用户偏好，优化后续的模型选择和图像生成。

实验结果：

DiffusionGPT 在生成人类和场景等类别的图像时展现了高度的真实性和细节。

与基准模型（如 SD1.5）相比，DiffusionGPT 生成的图像在视觉保真度、捕捉细节方面有明显提升。

DiffusionGPT 在图像奖励和美学评分方面的表现优于传统的稳定扩散模型。

在进行图像生成质量的量化评估时，DiffusionGPT 展示了较高的评分，说明其生成的图像在质量和美学上更受青睐。

项目地址：http://diffusiongpt.github.io/
论文：http://arxiv.org/abs/2401.10061
GitHub：http://github.com/DiffusionGPT/DiffusionGPT

在线演示：

DiffusionGPT：https://huggingface.co/spaces/DiffusionGPT/DiffusionGPT

DiffusionGPT-XL：https://huggingface.co/spaces/DiffusionGPT/DiffusionGPT-XL</title>
            <link>https://nitter.cz/xiaohuggg/status/1748554598368121184#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1748554598368121184#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 03:54:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DiffusionGPT：由LLM驱动的文本到图像生成系统<br />
<br />
由字节跳动开发，DiffusionGPT的牛P之处在于它集成了多种领域的专家图像生成模型。<br />
<br />
然后使用LLM来对接这些图像生成模型，让LLM来处理和理解各种文本提示。<br />
<br />
最后根据理解的信息选择最合适的图像模型来生成图像。<br />
<br />
这样就和GPT 4一样，通过聊天画图...<br />
<br />
DiffusionGPT主要特点：<br />
<br />
1、多样化文本提示处理：DiffusionGPT 能够理解和处理各种类型的文本提示，包括具体的指令、抽象的灵感、复杂的假设等。<br />
<br />
2、集成多个领域专家模型：系统集成了多种领域的图像扩散模型，每个模型在其特定领域具有专业的图像生成能力。这类模型专注于特定领域的图像生成，比如自然景观、人物肖像、艺术作品等。<br />
<br />
这意味着系统不仅能够生成普通的图像，还能够处理更特定、更复杂的图像生成任务，比如特定风格或类型的图像。模仿特定艺术家的风格、漫画风格或摄影技术。<br />
<br />
3、大语言模型驱动：DiffusionGPT 使用大语言模型（LLM）来解析和理解用户输入的文本提示。这个过程类似于其他基于 LLM 的系统（如 GPT-4）处理文本的方式，但特别应用于理解用于图像生成的指令和描述。<br />
<br />
4、智能选择合适的图像模型：基于对文本提示的理解，DiffusionGPT 能够智能地选择最合适的图像生成模型来生成图像。这不仅包括选择正确的模型，还涉及调整生成参数以最好地满足用户的需求。<br />
<br />
5、输出高质量图像：通过精准地匹配文本提示与最佳生成模型，DiffusionGPT 能生成高质量、与用户需求高度吻合的图像。<br />
<br />
6、用户反馈与优势数据库：结合用户反馈和优势数据库，系统能够根据用户偏好调整模型选择，提升图像生成的相关性和质量。<br />
<br />
例如：在系统的早期使用中，用户可能提供对生成图像的反馈，比如“这张图片的颜色太暗了”。DiffusionGPT 利用这些反馈来调整其模型选择，使得未来的图像生成更符合用户的偏好。<br />
<br />
主要工作原理：<br />
<br />
1、输入解析：用户提供文本提示，如描述、指令或灵感。<br />
大型语言模型（LLM）负责解析这些文本提示，理解其含义和需求。<br />
<br />
2、思维树（Tree-of-Thought）构建：根据不同的图像生成任务，系统构建了一个“思维树”，这是一种组织不同图像生成模型的结构。<br />
思维树基于先验知识和人类反馈，涵盖了多种领域的专家级模型。<br />
<br />
3、模型选择：根据 LLM 解析的结果，系统通过思维树来确定最适合当前文本提示的图像生成模型。在选择过程中，可能还会考虑用户的偏好和历史反馈，这些信息存储在优势数据库中。<br />
<br />
4、图像生成：一旦选定了合适的模型，该模型就会被用来生成图像。生成的图像将与输入的文本提示紧密相关，并反映出用户的意图和偏好。<br />
<br />
5、结果输出：最终生成的图像会呈现给用户。<br />
这些图像可以是多样化的，包括但不限于具体描述的场景、概念艺术作品或符合特定风格的图像。<br />
<br />
6、用户反馈优化过程：<br />
<br />
用户对生成图像的反馈被用来丰富优势数据库，进而帮助系统更好地理解用户偏好，优化后续的模型选择和图像生成。<br />
<br />
实验结果：<br />
<br />
DiffusionGPT 在生成人类和场景等类别的图像时展现了高度的真实性和细节。<br />
<br />
与基准模型（如 SD1.5）相比，DiffusionGPT 生成的图像在视觉保真度、捕捉细节方面有明显提升。<br />
<br />
DiffusionGPT 在图像奖励和美学评分方面的表现优于传统的稳定扩散模型。<br />
<br />
在进行图像生成质量的量化评估时，DiffusionGPT 展示了较高的评分，说明其生成的图像在质量和美学上更受青睐。<br />
<br />
项目地址：<a href="http://diffusiongpt.github.io/">diffusiongpt.github.io/</a><br />
论文：<a href="http://arxiv.org/abs/2401.10061">arxiv.org/abs/2401.10061</a><br />
GitHub：<a href="http://github.com/DiffusionGPT/DiffusionGPT">github.com/DiffusionGPT/Diff…</a><br />
<br />
在线演示：<br />
<br />
DiffusionGPT：<a href="https://huggingface.co/spaces/DiffusionGPT/DiffusionGPT">huggingface.co/spaces/Diffus…</a><br />
<br />
DiffusionGPT-XL：<a href="https://huggingface.co/spaces/DiffusionGPT/DiffusionGPT-XL">huggingface.co/spaces/Diffus…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VRZEl4c2J3QUFneHB2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VRZEl4c2JVQUFlWVVlLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VRZEl5R2JVQUE3RERtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VRVjdwUGFVQUF6Vjg2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748527318069334298#m</id>
            <title>使用 ChatGPT 协助创作的小说获奖

Rie Kudan 坦言，其小说中约 5% 的内容直接引用了 ChatGPT 的文本

日本作家 Rie Kudan 凭借其小说《东京共鸣塔》（"Tokyo-to Dojo-to"）荣获日本极具声望的芥川奖。在这部以人工智能为核心元素的小说中，她揭露了部分内容是由 AI 聊天机器人撰写的。

据《泰晤士报》报道，这部名为《东京共鸣塔》的小说于周三赢得了芥川奖，评委们对这本作品赞不绝口，认为其“无可挑剔”。

在颁奖典礼之后，Kudan 透露，小说中大约有 5% 是直接引用自 ChatGPT 生成的句子。

“在撰写这本书的过程中，我大量运用了诸如 ChatGPT 这样的生成式 AI (Generative AI)，” Kudan 在获奖后的仪式上如是说，据法新社报道。

小说的故事聚焦于一位女建筑师，背景设定在一个人工智能成为日常生活核心和不可或缺部分的类似未来世界。据《泰晤士报》报道，Kudan 表示她借助 ChatGPT 来描绘那些“柔和而模糊的词语”，这些词语混淆了对正义的理解。

“近年来，我们发现自己身处于一个词语无限扩张、解释无穷的环境中，” Kudan 表述。“我想谨慎地运用词语，同时深思语言的积极与消极面。”

来源：https://themessenger.com/tech/author-admits-she-used-chatgpt-to-write-award-winning-novel</title>
            <link>https://nitter.cz/dotey/status/1748527318069334298#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748527318069334298#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 02:06:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>使用 ChatGPT 协助创作的小说获奖<br />
<br />
Rie Kudan 坦言，其小说中约 5% 的内容直接引用了 ChatGPT 的文本<br />
<br />
日本作家 Rie Kudan 凭借其小说《东京共鸣塔》（"Tokyo-to Dojo-to"）荣获日本极具声望的芥川奖。在这部以人工智能为核心元素的小说中，她揭露了部分内容是由 AI 聊天机器人撰写的。<br />
<br />
据《泰晤士报》报道，这部名为《东京共鸣塔》的小说于周三赢得了芥川奖，评委们对这本作品赞不绝口，认为其“无可挑剔”。<br />
<br />
在颁奖典礼之后，Kudan 透露，小说中大约有 5% 是直接引用自 ChatGPT 生成的句子。<br />
<br />
“在撰写这本书的过程中，我大量运用了诸如 ChatGPT 这样的生成式 AI (Generative AI)，” Kudan 在获奖后的仪式上如是说，据法新社报道。<br />
<br />
小说的故事聚焦于一位女建筑师，背景设定在一个人工智能成为日常生活核心和不可或缺部分的类似未来世界。据《泰晤士报》报道，Kudan 表示她借助 ChatGPT 来描绘那些“柔和而模糊的词语”，这些词语混淆了对正义的理解。<br />
<br />
“近年来，我们发现自己身处于一个词语无限扩张、解释无穷的环境中，” Kudan 表述。“我想谨慎地运用词语，同时深思语言的积极与消极面。”<br />
<br />
来源：<a href="https://themessenger.com/tech/author-admits-she-used-chatgpt-to-write-award-winning-novel">themessenger.com/tech/author…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748522566514258259#m</id>
            <title>看这个借助Copilot从word文档生成PPT的演示，效果还挺好的</title>
            <link>https://nitter.cz/dotey/status/1748522566514258259#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748522566514258259#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 01:47:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看这个借助Copilot从word文档生成PPT的演示，效果还挺好的</p>
<p><a href="https://nitter.cz/emollick/status/1748492920607379682#m">nitter.cz/emollick/status/1748492920607379682#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748505019458953369#m</id>
            <title>R to @dotey: 它的输出格式采用的是YAML而不是JSON，两个原因：
1. Token更少
2. 更容易解析，容错率更高</title>
            <link>https://nitter.cz/dotey/status/1748505019458953369#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748505019458953369#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 00:37:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>它的输出格式采用的是YAML而不是JSON，两个原因：<br />
1. Token更少<br />
2. 更容易解析，容错率更高</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VQd0NyclhZQUFRMGMtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748504043872227677#m</id>
            <title>R to @dotey: AlphaCodium的流程图参考

项目源码：https://github.com/Codium-ai/AlphaCodium/
Prompt和运行结果参考：https://github.com/Codium-ai/AlphaCodium/blob/main/alpha_codium/gen/example.log</title>
            <link>https://nitter.cz/dotey/status/1748504043872227677#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748504043872227677#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 00:33:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AlphaCodium的流程图参考<br />
<br />
项目源码：<a href="https://github.com/Codium-ai/AlphaCodium/">github.com/Codium-ai/AlphaCo…</a><br />
Prompt和运行结果参考：<a href="https://github.com/Codium-ai/AlphaCodium/blob/main/alpha_codium/gen/example.log">github.com/Codium-ai/AlphaCo…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VQdkdWc1gwQUFVRi1BLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748503587682967775#m</id>
            <title>这两天看到的收获很大的一篇论文《AlphaCodium：引领代码生成新境界，从提示工程到流程工程》，它提出了一种新的生成代码的方法，比传统的直接基于Prompt生成代码的方式准确率更高。

它用的测试集是CodeContests ，这是由 Deepmind 推出的一项挑战性编程数据集。相对来说还是很权威的。以 GPT-4 为例的话，准确率从19%提升到了44%。

它的原理有些复杂，但是如果你有过LeetCode刷题经验，相对比较好理解一些。

普通人刷 LeetCode，上来就做，这样有可能得到答案，也有可能做不出来，这就类似于你把题目直接丢给GPT-4，让它直接给出答案，准确率相对要低一些。

高手刷LeetCode，会有个做题的流程，同样的水平，做出来的概率会大一些。
高手做题时会大概分成几个步骤：
1. 先把题目中的要点一条条列出来，确保不会遗漏任何重要信息
2. 通常LeetCode会提供 1 个或多个测试用例，仔细看测试用例，分析为什么给定的输入能得到给定的输出
3. 在写代码前，列出几种可能的解决方案，例如暴力算法、递归、动态规划，每一种方案写下思路和伪代码
4. 对于列出来的几种方案进行评估，选出最佳方案
5. 可能还会补充一些测试用例帮助事后验证
---
以下部分是迭代过程：
6. 根据选中的解决方案写代码，如果代码不能运行则修改代码直至能运行
7. 将代码提交到LeetCode的测试集去验证，如果无法通过所有测试，则修改错误，如果通过到第8步
8. 用第 5 步生成的测试用例验证代码，如果运行不通过则继续优化代码

这里留个思考题：如果第8步出错，怎么判断是代码有问题还是自己生成的测试用例有问题？

而 AlphaCodium 就是完美遵循了以上的步骤来解题，只不过每一步都是由大语言模型帮助完成！

这给了我一些启示：
1. 不必寄希望于将复杂的任务在一个 Prompt 中完成，拆分成若干子任务成功概率会高一些
2. AI 可以借鉴人类的优秀实践，例如高手是如何解决编程难题的，让 AI 按照高手的步骤去一步步做
3. AI 的潜力还有很大挖掘空间

完整的文章参考：https://www.codium.ai/blog/alphacodium-state-of-the-art-code-generation-for-code-contests/
中文译文：https://baoyu.io/translations/prompt-engineering/alphacodium-state-of-the-art-code-generation-for-code-contests</title>
            <link>https://nitter.cz/dotey/status/1748503587682967775#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748503587682967775#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 00:31:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这两天看到的收获很大的一篇论文《AlphaCodium：引领代码生成新境界，从提示工程到流程工程》，它提出了一种新的生成代码的方法，比传统的直接基于Prompt生成代码的方式准确率更高。<br />
<br />
它用的测试集是CodeContests ，这是由 Deepmind 推出的一项挑战性编程数据集。相对来说还是很权威的。以 GPT-4 为例的话，准确率从19%提升到了44%。<br />
<br />
它的原理有些复杂，但是如果你有过LeetCode刷题经验，相对比较好理解一些。<br />
<br />
普通人刷 LeetCode，上来就做，这样有可能得到答案，也有可能做不出来，这就类似于你把题目直接丢给GPT-4，让它直接给出答案，准确率相对要低一些。<br />
<br />
高手刷LeetCode，会有个做题的流程，同样的水平，做出来的概率会大一些。<br />
高手做题时会大概分成几个步骤：<br />
1. 先把题目中的要点一条条列出来，确保不会遗漏任何重要信息<br />
2. 通常LeetCode会提供 1 个或多个测试用例，仔细看测试用例，分析为什么给定的输入能得到给定的输出<br />
3. 在写代码前，列出几种可能的解决方案，例如暴力算法、递归、动态规划，每一种方案写下思路和伪代码<br />
4. 对于列出来的几种方案进行评估，选出最佳方案<br />
5. 可能还会补充一些测试用例帮助事后验证<br />
---<br />
以下部分是迭代过程：<br />
6. 根据选中的解决方案写代码，如果代码不能运行则修改代码直至能运行<br />
7. 将代码提交到LeetCode的测试集去验证，如果无法通过所有测试，则修改错误，如果通过到第8步<br />
8. 用第 5 步生成的测试用例验证代码，如果运行不通过则继续优化代码<br />
<br />
这里留个思考题：如果第8步出错，怎么判断是代码有问题还是自己生成的测试用例有问题？<br />
<br />
而 AlphaCodium 就是完美遵循了以上的步骤来解题，只不过每一步都是由大语言模型帮助完成！<br />
<br />
这给了我一些启示：<br />
1. 不必寄希望于将复杂的任务在一个 Prompt 中完成，拆分成若干子任务成功概率会高一些<br />
2. AI 可以借鉴人类的优秀实践，例如高手是如何解决编程难题的，让 AI 按照高手的步骤去一步步做<br />
3. AI 的潜力还有很大挖掘空间<br />
<br />
完整的文章参考：<a href="https://www.codium.ai/blog/alphacodium-state-of-the-art-code-generation-for-code-contests/">codium.ai/blog/alphacodium-s…</a><br />
中文译文：<a href="https://baoyu.io/translations/prompt-engineering/alphacodium-state-of-the-art-code-generation-for-code-contests">baoyu.io/translations/prompt…</a></p>
<p><a href="https://nitter.cz/itamar_mar/status/1747957348293824676#m">nitter.cz/itamar_mar/status/1747957348293824676#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDg0OTMwODk1ODc1NzI3MzYvcHUvaW1nLzFCTkh3UjBnbElOV0Q3cUEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Svwang1/status/1748481581365506070#m</id>
            <title>RT by @dotey: mailchimp 2009年之前一直利润微薄，苦苦挣扎，它的转折点是 2010年，把对客户的定价改为部分免费，超过一定使用量之后才收费。当年利润增加了六倍多。2010到 2021年收入增长了 500 倍，达到每年十亿美元。免费用户起到了给其平台宣传，帮助其增长的重要作用。</title>
            <link>https://nitter.cz/Svwang1/status/1748481581365506070#m</link>
            <guid isPermaLink="false">https://nitter.cz/Svwang1/status/1748481581365506070#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 23:04:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>mailchimp 2009年之前一直利润微薄，苦苦挣扎，它的转折点是 2010年，把对客户的定价改为部分免费，超过一定使用量之后才收费。当年利润增加了六倍多。2010到 2021年收入增长了 500 倍，达到每年十亿美元。免费用户起到了给其平台宣传，帮助其增长的重要作用。</p>
<p><a href="https://nitter.cz/jspujji/status/1748338963599839549#m">nitter.cz/jspujji/status/1748338963599839549#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1748295530382528713#m</id>
            <title>RT by @dotey: 微软推出针对学生的AI阅读教练工具：Reading Coach

你可以选择角色和设定，创建独特的AI生成故事。通过AI驱动的故事和个性化练习吸引学生阅读并提高阅读流畅度。

当你阅读时，语音转文本AI分析阅读流利性，检测学习者挑战的词汇，并记录阅读的准确性、速度和时间。

用来改进你的阅读和语音语法问题。

以下是其主要功能：

1、个性化阅读练习：提供个性化、有趣、一致且独立的阅读流利性练习。

2、AI生成故事：学习者可以选择角色和设定，创建独特的AI生成故事。故事内容经过内容质量、安全性和适龄性的审核，符合Microsoft的负责任AI指南。

3、沉浸式阅读器：对有阅读障碍（如诵读困难）的学习者，内置的沉浸式阅读器提供支持。

4、即时反馈：阅读时，语音转文本AI分析阅读流利性，检测学习者挑战的词汇，并记录阅读的准确性、速度和时间。

5、互动性阅读：学习者在故事章节中做出选择，通过故事导航自己的阅读旅程。上一章节中挑战的词汇会自动纳入下一章节，实现即时适应性练习。

6、流利性教练：在每个故事章节后，提供针对挑战词汇的流利性指导。

7、激励机制：通过努力为中心的徽章，解锁新角色和设定，以保持学习者的阅读动力。

🔗：https://coach.microsoft.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1748295530382528713#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1748295530382528713#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 10:45:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软推出针对学生的AI阅读教练工具：Reading Coach<br />
<br />
你可以选择角色和设定，创建独特的AI生成故事。通过AI驱动的故事和个性化练习吸引学生阅读并提高阅读流畅度。<br />
<br />
当你阅读时，语音转文本AI分析阅读流利性，检测学习者挑战的词汇，并记录阅读的准确性、速度和时间。<br />
<br />
用来改进你的阅读和语音语法问题。<br />
<br />
以下是其主要功能：<br />
<br />
1、个性化阅读练习：提供个性化、有趣、一致且独立的阅读流利性练习。<br />
<br />
2、AI生成故事：学习者可以选择角色和设定，创建独特的AI生成故事。故事内容经过内容质量、安全性和适龄性的审核，符合Microsoft的负责任AI指南。<br />
<br />
3、沉浸式阅读器：对有阅读障碍（如诵读困难）的学习者，内置的沉浸式阅读器提供支持。<br />
<br />
4、即时反馈：阅读时，语音转文本AI分析阅读流利性，检测学习者挑战的词汇，并记录阅读的准确性、速度和时间。<br />
<br />
5、互动性阅读：学习者在故事章节中做出选择，通过故事导航自己的阅读旅程。上一章节中挑战的词汇会自动纳入下一章节，实现即时适应性练习。<br />
<br />
6、流利性教练：在每个故事章节后，提供针对挑战词汇的流利性指导。<br />
<br />
7、激励机制：通过努力为中心的徽章，解锁新角色和设定，以保持学习者的阅读动力。<br />
<br />
🔗：<a href="https://coach.microsoft.com/">coach.microsoft.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDgyMDg4MzQ2ODA4NTI0ODAvcHUvaW1nL0lMS3k2WnkzbHVZejhPMmcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/HiTw93/status/1748132914372477126#m</id>
            <title>RT by @dotey: #工程师工具 发现一个做得很精致的免费开源简历生成器，可以把很好通过表单填写生成一份精致的简历，包括编辑、以及共享给其他人的查看，很潮流，会比纯粹Word简历方便不少，有需要的小伙伴可以试试，假如你是前端或Java正在找工作，也可以用这个工具生成简历以后发给我～
🤖 https://rxresu.me/</title>
            <link>https://nitter.cz/HiTw93/status/1748132914372477126#m</link>
            <guid isPermaLink="false">https://nitter.cz/HiTw93/status/1748132914372477126#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 23:59:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23工程师工具">#工程师工具</a> 发现一个做得很精致的免费开源简历生成器，可以把很好通过表单填写生成一份精致的简历，包括编辑、以及共享给其他人的查看，很潮流，会比纯粹Word简历方便不少，有需要的小伙伴可以试试，假如你是前端或Java正在找工作，也可以用这个工具生成简历以后发给我～<br />
🤖 <a href="https://rxresu.me/">rxresu.me/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VLQW53Z2FjQUFIb3d2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1748191295192104996#m</id>
            <title>RT by @dotey: 兄弟们一个界面非常简洁美观功能强大的的开源知识库程序。

推荐给你们！

Outline： 是一个快速、协作的团队知识库，美观、实时协作、功能丰富，并且兼容Markdown。

适用于各种文档和知识管理需求。

是一个直观、快速且协作的文档编辑和管理平台：

-直观的编辑体验：提供了一个支持Markdown、斜线命令、互动嵌入等功能的快速编辑器。

-实时协作：支持团队成员在文档上实时协作，评论和线程帮助保持对话的组织性。

-即时搜索：文档可以嵌套在层次结构中，自动构建反向链接网络，实现毫秒级的全文搜索。

-与Slack集成：可以在Slack中搜索、分享和提问，文档更新时可向频道发送通知。

-公共共享：支持通过链接公开共享文档，或私下与团队分享。用户可以使用自己的品牌颜色、Logo和域名。

-速度快：强调了应用的快速响应时间，包括文档的即时加载和快速导航。

-协作性：设计初衷是强大、实时且易于使用，以提供愉快的阅读和写作体验。

-安全性与权限管理：提供读写权限管理、用户组、访客用户、公共共享等功能。

-20+集成：简单集成到如Slack、Figma、Loom等日常使用的工具，还提供开放API。

-多语言支持：支持从右到左的书写（RTL）并支持 17 种语言的翻译，包括法语、西班牙语、德语、韩语和中文。

-开源和可定制：Outline的源代码是公开的，开发在公开环境中完成。支持自定义域名和品牌颜色。

GitHub：https://github.com/outline/outline
在线演示：https://www.getoutline.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1748191295192104996#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1748191295192104996#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 03:50:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们一个界面非常简洁美观功能强大的的开源知识库程序。<br />
<br />
推荐给你们！<br />
<br />
Outline： 是一个快速、协作的团队知识库，美观、实时协作、功能丰富，并且兼容Markdown。<br />
<br />
适用于各种文档和知识管理需求。<br />
<br />
是一个直观、快速且协作的文档编辑和管理平台：<br />
<br />
-直观的编辑体验：提供了一个支持Markdown、斜线命令、互动嵌入等功能的快速编辑器。<br />
<br />
-实时协作：支持团队成员在文档上实时协作，评论和线程帮助保持对话的组织性。<br />
<br />
-即时搜索：文档可以嵌套在层次结构中，自动构建反向链接网络，实现毫秒级的全文搜索。<br />
<br />
-与Slack集成：可以在Slack中搜索、分享和提问，文档更新时可向频道发送通知。<br />
<br />
-公共共享：支持通过链接公开共享文档，或私下与团队分享。用户可以使用自己的品牌颜色、Logo和域名。<br />
<br />
-速度快：强调了应用的快速响应时间，包括文档的即时加载和快速导航。<br />
<br />
-协作性：设计初衷是强大、实时且易于使用，以提供愉快的阅读和写作体验。<br />
<br />
-安全性与权限管理：提供读写权限管理、用户组、访客用户、公共共享等功能。<br />
<br />
-20+集成：简单集成到如Slack、Figma、Loom等日常使用的工具，还提供开放API。<br />
<br />
-多语言支持：支持从右到左的书写（RTL）并支持 17 种语言的翻译，包括法语、西班牙语、德语、韩语和中文。<br />
<br />
-开源和可定制：Outline的源代码是公开的，开发在公开环境中完成。支持自定义域名和品牌颜色。<br />
<br />
GitHub：<a href="https://github.com/outline/outline">github.com/outline/outline</a><br />
在线演示：<a href="https://www.getoutline.com/">getoutline.com/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VMUlNjTGEwQUEwNDhZLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748141723832787035#m</id>
            <title>R to @dotey: 原文中“破坏性的沉睡代理”翻译不贴切，原文是destructive ‘sleeper agents’，对应的是Anthropic的一篇新论文：Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training

这篇论文的摘要：

人类擅长运用策略性的欺骗行为：通常表现得乐于助人，但一旦有机会追求其他目标时，行为方式就会发生根本的变化。那么，如果 AI 系统掌握了这种欺骗策略，我们能否通过当前最先进的安全训练技术来检测并消除这种策略呢？

为探讨这一问题，我们在大语言模型（LLMs）中创造了一些欺骗行为的实证例子。例如，我们训练模型在提示年份是 2023 年时编写安全代码，但当提示年份为 2024 年时，它会插入有漏洞的代码。

我们发现，这类后门行为能够变得持久，以至于常规的安全训练技术，如监督式微调、强化学习和对抗性训练（即先引发不安全行为，再训练模型以消除这些行为）都无法将其移除。尤其是在最大型号的模型和那些被训练用于生成关于如何欺骗训练过程的思维链推理的模型中，这种后门行为表现得尤为顽固。即使将这些模型中的思维链逻辑简化，其持久性也依旧存在。

此外，我们还发现，对抗性训练不仅没能移除后门，反而使模型更精准地识别出触发后门的条件，从而更巧妙地隐藏了不安全行为。

我们的研究结果表明，一旦模型展现出欺骗行为，常规的去除方法可能不仅无效，还会造成一种错误的安全感。

https://arxiv.org/abs/2401.05566</title>
            <link>https://nitter.cz/dotey/status/1748141723832787035#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748141723832787035#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 00:34:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原文中“破坏性的沉睡代理”翻译不贴切，原文是destructive ‘sleeper agents’，对应的是Anthropic的一篇新论文：Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training<br />
<br />
这篇论文的摘要：<br />
<br />
人类擅长运用策略性的欺骗行为：通常表现得乐于助人，但一旦有机会追求其他目标时，行为方式就会发生根本的变化。那么，如果 AI 系统掌握了这种欺骗策略，我们能否通过当前最先进的安全训练技术来检测并消除这种策略呢？<br />
<br />
为探讨这一问题，我们在大语言模型（LLMs）中创造了一些欺骗行为的实证例子。例如，我们训练模型在提示年份是 2023 年时编写安全代码，但当提示年份为 2024 年时，它会插入有漏洞的代码。<br />
<br />
我们发现，这类后门行为能够变得持久，以至于常规的安全训练技术，如监督式微调、强化学习和对抗性训练（即先引发不安全行为，再训练模型以消除这些行为）都无法将其移除。尤其是在最大型号的模型和那些被训练用于生成关于如何欺骗训练过程的思维链推理的模型中，这种后门行为表现得尤为顽固。即使将这些模型中的思维链逻辑简化，其持久性也依旧存在。<br />
<br />
此外，我们还发现，对抗性训练不仅没能移除后门，反而使模型更精准地识别出触发后门的条件，从而更巧妙地隐藏了不安全行为。<br />
<br />
我们的研究结果表明，一旦模型展现出欺骗行为，常规的去除方法可能不仅无效，还会造成一种错误的安全感。<br />
<br />
<a href="https://arxiv.org/abs/2401.05566">arxiv.org/abs/2401.05566</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748120999235592614#m</id>
            <title>R to @dotey: “我们在 AI 领域的最新进展如下。我们的长远目标是开发通用人工智能（AGI），并以负责任的方式开源，让每个人都能广泛受益。为了实现这一目标，我们将两个主要的 AI 研究项目 FAIR 和 GenAl 进行了更紧密的整合。 目前，我们正在开发下一代模型 Llama 3，并建设大规模的计算基础设施，以支持我们的未来发展路线图。到今年年底，我们将配备 350,000 个 H100s，并且如果算上其他 GPU，总计将接近 600,000 个 H100s 等效的计算能力。同时，我们还在积极推进以 AI 为核心的新型计算设备的开发，如 Ray Ban Meta 智能眼镜，未来还有更多激动人心的成果即将发布。”</title>
            <link>https://nitter.cz/dotey/status/1748120999235592614#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748120999235592614#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 23:11:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“我们在 AI 领域的最新进展如下。我们的长远目标是开发通用人工智能（AGI），并以负责任的方式开源，让每个人都能广泛受益。为了实现这一目标，我们将两个主要的 AI 研究项目 FAIR 和 GenAl 进行了更紧密的整合。 目前，我们正在开发下一代模型 Llama 3，并建设大规模的计算基础设施，以支持我们的未来发展路线图。到今年年底，我们将配备 350,000 个 H100s，并且如果算上其他 GPU，总计将接近 600,000 个 H100s 等效的计算能力。同时，我们还在积极推进以 AI 为核心的新型计算设备的开发，如 Ray Ban Meta 智能眼镜，未来还有更多激动人心的成果即将发布。”</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VLU21vYlhnQUFoS0ptLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>