<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/foxshuo/status/1741334718338175238#m</id>
            <title>RT by @dotey: 😆黑得漂亮。</title>
            <link>https://nitter.cz/foxshuo/status/1741334718338175238#m</link>
            <guid isPermaLink="false">https://nitter.cz/foxshuo/status/1741334718338175238#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 05:45:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>😆黑得漂亮。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NwMnNieWFvQUF0bkNxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1741352332594676143#m</id>
            <title>RT by @dotey: 2023年50个访问量最大的AI工具及AI行业分析报告

Writerbuddy AI使用 SEO 行业著名的工具SEMrush，通过抓取AI工具数据，研究了3000多种 AI 工具。

从中选出了访问量最大的 50 个工具，这前 50 位的AI工具就产生了超过 240 亿次的访问量。

其中ChatGPT就独占了 140 亿流量，占分析流量的60%。

详细 🧵↓

1、关键发现：

- AI行业平均每月增长2.363亿次访问量。分析的 50 个人工智能工具经历了 10.7 倍的增长率，平均每月访问量增加 2.363 亿次。

- 过去12个月中，AI应用每月平均访问量达到20亿次，过去6个月，每月平均访问量激增至33亿次。

- ChatGPT、Character AI和Google Bard的访问量分别净增长了18亿次、4.634亿次和6800万次。

- 访问量最高AI聊天机器人：ChatGPT处于绝对领先地位，占 AI 聊天机器人类别总访问量的 76.31%。紧随其后的是Character AI，以19.86%的访问量位居第二。

- Craiyon、MidJourney和Quillbot面临最大的流量下降。

- 美国贡献了55亿人次访问量，占总访问量的22.62%，而欧洲国家合计贡献了39亿人次访问量。

- AI 聊天机器人工具最受欢迎，访问量达到 191 亿次。

- 超过63%的AI工具用户通过移动设备访问。

- 存在性别差异，69.5%为男性用户，30.5%为女性用户。</title>
            <link>https://nitter.cz/xiaohuggg/status/1741352332594676143#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1741352332594676143#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 06:55:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2023年50个访问量最大的AI工具及AI行业分析报告<br />
<br />
Writerbuddy AI使用 SEO 行业著名的工具SEMrush，通过抓取AI工具数据，研究了3000多种 AI 工具。<br />
<br />
从中选出了访问量最大的 50 个工具，这前 50 位的AI工具就产生了超过 240 亿次的访问量。<br />
<br />
其中ChatGPT就独占了 140 亿流量，占分析流量的60%。<br />
<br />
详细 🧵↓<br />
<br />
1、关键发现：<br />
<br />
- AI行业平均每月增长2.363亿次访问量。分析的 50 个人工智能工具经历了 10.7 倍的增长率，平均每月访问量增加 2.363 亿次。<br />
<br />
- 过去12个月中，AI应用每月平均访问量达到20亿次，过去6个月，每月平均访问量激增至33亿次。<br />
<br />
- ChatGPT、Character AI和Google Bard的访问量分别净增长了18亿次、4.634亿次和6800万次。<br />
<br />
- 访问量最高AI聊天机器人：ChatGPT处于绝对领先地位，占 AI 聊天机器人类别总访问量的 76.31%。紧随其后的是Character AI，以19.86%的访问量位居第二。<br />
<br />
- Craiyon、MidJourney和Quillbot面临最大的流量下降。<br />
<br />
- 美国贡献了55亿人次访问量，占总访问量的22.62%，而欧洲国家合计贡献了39亿人次访问量。<br />
<br />
- AI 聊天机器人工具最受欢迎，访问量达到 191 亿次。<br />
<br />
- 超过63%的AI工具用户通过移动设备访问。<br />
<br />
- 存在性别差异，69.5%为男性用户，30.5%为女性用户。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NxRllPbGJBQUE2RFhiLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NxRmFCYmJjQUF4em1CLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Chai20230817/status/1741330615558148314#m</id>
            <title>RT by @dotey: 财新《2023终有一别》，纪念本年辞世的多位中外人物。已被删除。此处可访问https://webcache.googleusercontent.com/search?q=cache:Rdwbte7ToGAJ:https://china.caixin.com/2023-12-24/102149416.html
来自@dashengmedia</title>
            <link>https://nitter.cz/Chai20230817/status/1741330615558148314#m</link>
            <guid isPermaLink="false">https://nitter.cz/Chai20230817/status/1741330615558148314#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 05:29:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>财新《2023终有一别》，纪念本年辞世的多位中外人物。已被删除。此处可访问<a href="https://webcache.googleusercontent.com/search?q=cache:Rdwbte7ToGAJ:https://china.caixin.com/2023-12-24/102149416.html">webcache.googleusercontent.c…</a><br />
来自<a href="https://nitter.cz/dashengmedia" title="大声">@dashengmedia</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nwd1c4TWJvQUFKd0dULmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nwd1c4TWJVQUFQS1JPLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nwd1c4TGFNQUFHdzlrLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nwd1c4TGJBQUFLRlhqLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741339127851671853#m</id>
            <title>R to @dotey: 以下转自微博用户 张俊林say ：https://weibo.com/1064649941/NzF8DlQmu

这个问题的可能答案会是什么呢？文艺行业确实是首先被波及的行业，这是因为 AI  应用已经在这个行业达到及格线，而且“AI容错率”高并且“人力AI成本差”大导致的。目前阶段，这样的行业就是非常利于AI应用的行业。

AI应用及格线

     我们先谈下AI应用的特殊之处。某项AI技术是否能应用，跟AI技术的应用效果关系比较大，而且这种关系还不是线性的，而是非线性的。就是说，干一件事情，如果AI的准确率如果达不到一个门槛值，比如80分，那么这项AI技术就是完全不可用的，而不是说50分的技术有50分的用处，90分的技术有90分的用处，所以是非线性的，必须要达到门槛数值，也就是及格线，才能应用，而且往往这个及格线是比较高的。就是说AI在某个行业应用，要么0分，要么一定超过及格线比如80分。

      大模型以及AIGC这波技术进展，和之前几波比如“深度学习”那波是不太一样的，之所以和之前不太一样，一方面跟大模型确实在很多方面效果好有关系，在很多方面超过了应用的及格线，以前没超过及格线的时候，它尽管还行，但是应用得分就是0，就是不可用的。现在很多行业可以用AI了，从不可能到了可能。但这只是次要的一方面，更主要的一方面在于：我们目前还没有看到基座大模型的效果天花板在哪里，接下来至少2年时间，它一定会稳步提高效果的，只要你给大模型更多高质量数据，并推大模型规模就行。如果这样，那么未来基座模型能力一定越来越强，现在所有其它AI方向的繁荣比如Agent、多模态、具身、具体应用这些，都是以强大的基座模型为核心依托的。随着基座能力越来越强，AI会跳过越来越多行业应用的及格线，使得原先不可应用AI的行业变得可以应用AI了，这必然带来AI的广泛应用。这是我一直对这一波AI浪潮报以乐观的主要原因，只有哪天我们发现Scaling law失效了，或者短期可能面临的问题是：可用的数据已经不够了，我觉得才需要去讨论AI是否泡沫太大的问题，在此之前，我不认为这是一个值得讨论的问题。

     对于某个行业，我们假设AI已经达到及格线了（不同行业及格线可能是不同的），那么在这个基础上考虑什么样的条件影响了AI应用的时间早晚或者普及程度。我认为主要有两个原因：“AI容错率”以及“人力AI成本差”。

AI容错率

    使用AI做事情你不能期望它能百分之百不出差错，这里就带来一个问题：这个行业的产品能在多大程度上容忍AI的错误结果？我们可以把它称为“AI容错率”，不同行业的AI容错率差异很大，某个行业的AI容错率越高，则会越早地广泛应用AI技术与产品。

      我们知道现阶段的大模型有着严重的“幻觉”问题，就是事实上明明应该是A，它非要说是B。大模型的幻觉本质如何见仁见智，有人觉得这是大模型的缺陷需要修正，也有人觉得“大模型的幻觉是种Feature，而不是Bug”。此问题我们暂且不论，且来看看不同行业的AI容错率。
     艺术创作行业比如写小说、画图、做电影，AI容错率非常之高，有时甚至是“反向容错”，就是说错得越离谱看着越有创造性。艺术创作领域没有“是对是错”这种标准答案，只有通过表现是否独特体现出是否有创造性，越独特越有创意。AI生成作品的所谓“错”，指的往往是非常规，超出普通人的想象力。超一流的艺术家思维模式、看世界的角度和普通人是截然不同的，所以这是为何超一流的艺术家很多都以疯掉作为人生结局的内在原因。所以在这种需要创意的领域，AI错得越离谱可能效果越好。
      艺术行业是极端容忍AI错误的，处于“AI容错率”另外一个极端的是“自动驾驶”。自动驾驶容错率是极低的，0.001%的错误率行吗？如果使用AI产品的用户基数比较大，比如1亿人，0.001%的错误率会造成多少交通故障？甚至生命危险？你可以算算，往少了算1000起，这个谁能接受？没人能承担这个后果。而且用户基数越大，对“AI容错率”的要求越高，这就很要命了，这不是规模效应，是“反规模效应”。所以我一直认为自动驾驶是个非常严苛的AI应用场景，大模型对它的帮助应该很有限，幻觉问题不解决可能没有出头之日。
     其它行业，对“AI容错率”要求基本处于艺术行业和自动驾驶这两个极端之间，To C的产品容错率就高一些，To B的产品容错率就低一些，大致如此。

人力AI成本差

    大模型目前还无法广泛应用的另外一个重要问题是使用AI成本太高，尽管制作GPT 4这种模型需要上亿美金起步，但是制造大模型成本和使用大模型成本比，大模型使用成本低更重要，毕竟制作是一次性的，算是固定成本，而人人都可以用AI，这是个变化成本。未来能否极大降低大模型的使用成本，对于大模型应用是否能全面铺开来说，是至关重要的。（大模型使用成本每12到16个月降低10倍，所以大模型应用未来还是可期的）
    从AI使用成本角度，我们来分析下不同行业的可能应用发展情况。假设每个行业现在都采取人力，那么不同行业的人力成本是不一样的，简而言之，行业平均工资越高，人力成本越高。假设AI和人能以相同水平解决职业问题，人力成本假设是H=10万／年，使用AI的成本假设是A=5万／年，那么两者的差值就是H-A=5万／年，这个H-A就是“人力AI成本差”。

     很明显，当AI使用成本比人力高的时候，“AI人力成本”是负数，没人有动力去用AI来代替人；只有当AI使用成本低于人力成本，AI技术才会被应用，而“AI人力成本差”越大，则企业拥有者越有动力去应用AI，两者基本成正比关系，甚至可能是指数关系，这是很自然的，人性如此。

     完成一个产品需要消耗越多劳动，这体现在对同一个水平劳动者来说，完成作品所需要投入的时间，时间越长，人力成本就越高。从模态角度来说，人力成本由高到低应该是：长视频>短视频>长文>图片>短文。你想想制作视频或者画一个艺术类的图，对于普通人来说，以前可能想都不敢想，现在用AI工具，制作成本降低了多少？就是几句话加几秒钟的时间。

    而随着技术的快速发展，AI使用成本会极速下降，但是人力完成任务的成本长周期内是比较稳定的，尽管降低速度也很慢。所以，对大多数行业来说，人力AI成本差会越来越大，虽然这可能会带来很多社会问题，但是，没办法，趋势如此，无法逆转，不接受也得接受，与其抗拒，不如拥抱，先利用好AI工具，把自身效率先提起来。

    除此外，还有一些相对次要的因素，比如To C类的AI应用，因为用户基数比较大，所以感知到AI作用的人就多，对此谈论的人就越多，传播范围也比较大；To B或者 To Science类AI应用用户基数少，所以即使有反响也往往局限在小圈子内，感知到的人少，传播面小，这也是为何会有这种感觉的原因之一。

     考虑AI的行业应用作用，需要结合以上三点综合考虑，总体而言：在AI技术能力达标的已有行业里，AI效果越好的、AI容错率越高的、人力AI成本差越大的行业，则会越早越快地进行AI普及与人力替代。这也解释了之前比较流行的说法：我们本来以为AI会先替我们做打扫房间、买东西送菜这种体力劳动，但是事实上与我们想的相反，大模型来了首先替代的反而是中等程度的脑力劳动。这是因为，高等脑力劳动目前AI效果还没达标、体力劳动人做起来成本低，而中等脑力劳动正好完美符合这些条件：AI效果在某些方面能力和人差不太多了，使用AI的“人力AI成本差”也比较大</title>
            <link>https://nitter.cz/dotey/status/1741339127851671853#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741339127851671853#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 06:02:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>以下转自微博用户 张俊林say ：<a href="https://weibo.com/1064649941/NzF8DlQmu">weibo.com/1064649941/NzF8DlQ…</a><br />
<br />
这个问题的可能答案会是什么呢？文艺行业确实是首先被波及的行业，这是因为 AI  应用已经在这个行业达到及格线，而且“AI容错率”高并且“人力AI成本差”大导致的。目前阶段，这样的行业就是非常利于AI应用的行业。<br />
<br />
AI应用及格线<br />
<br />
     我们先谈下AI应用的特殊之处。某项AI技术是否能应用，跟AI技术的应用效果关系比较大，而且这种关系还不是线性的，而是非线性的。就是说，干一件事情，如果AI的准确率如果达不到一个门槛值，比如80分，那么这项AI技术就是完全不可用的，而不是说50分的技术有50分的用处，90分的技术有90分的用处，所以是非线性的，必须要达到门槛数值，也就是及格线，才能应用，而且往往这个及格线是比较高的。就是说AI在某个行业应用，要么0分，要么一定超过及格线比如80分。<br />
<br />
      大模型以及AIGC这波技术进展，和之前几波比如“深度学习”那波是不太一样的，之所以和之前不太一样，一方面跟大模型确实在很多方面效果好有关系，在很多方面超过了应用的及格线，以前没超过及格线的时候，它尽管还行，但是应用得分就是0，就是不可用的。现在很多行业可以用AI了，从不可能到了可能。但这只是次要的一方面，更主要的一方面在于：我们目前还没有看到基座大模型的效果天花板在哪里，接下来至少2年时间，它一定会稳步提高效果的，只要你给大模型更多高质量数据，并推大模型规模就行。如果这样，那么未来基座模型能力一定越来越强，现在所有其它AI方向的繁荣比如Agent、多模态、具身、具体应用这些，都是以强大的基座模型为核心依托的。随着基座能力越来越强，AI会跳过越来越多行业应用的及格线，使得原先不可应用AI的行业变得可以应用AI了，这必然带来AI的广泛应用。这是我一直对这一波AI浪潮报以乐观的主要原因，只有哪天我们发现Scaling law失效了，或者短期可能面临的问题是：可用的数据已经不够了，我觉得才需要去讨论AI是否泡沫太大的问题，在此之前，我不认为这是一个值得讨论的问题。<br />
<br />
     对于某个行业，我们假设AI已经达到及格线了（不同行业及格线可能是不同的），那么在这个基础上考虑什么样的条件影响了AI应用的时间早晚或者普及程度。我认为主要有两个原因：“AI容错率”以及“人力AI成本差”。<br />
<br />
AI容错率<br />
<br />
    使用AI做事情你不能期望它能百分之百不出差错，这里就带来一个问题：这个行业的产品能在多大程度上容忍AI的错误结果？我们可以把它称为“AI容错率”，不同行业的AI容错率差异很大，某个行业的AI容错率越高，则会越早地广泛应用AI技术与产品。<br />
<br />
      我们知道现阶段的大模型有着严重的“幻觉”问题，就是事实上明明应该是A，它非要说是B。大模型的幻觉本质如何见仁见智，有人觉得这是大模型的缺陷需要修正，也有人觉得“大模型的幻觉是种Feature，而不是Bug”。此问题我们暂且不论，且来看看不同行业的AI容错率。<br />
     艺术创作行业比如写小说、画图、做电影，AI容错率非常之高，有时甚至是“反向容错”，就是说错得越离谱看着越有创造性。艺术创作领域没有“是对是错”这种标准答案，只有通过表现是否独特体现出是否有创造性，越独特越有创意。AI生成作品的所谓“错”，指的往往是非常规，超出普通人的想象力。超一流的艺术家思维模式、看世界的角度和普通人是截然不同的，所以这是为何超一流的艺术家很多都以疯掉作为人生结局的内在原因。所以在这种需要创意的领域，AI错得越离谱可能效果越好。<br />
      艺术行业是极端容忍AI错误的，处于“AI容错率”另外一个极端的是“自动驾驶”。自动驾驶容错率是极低的，0.001%的错误率行吗？如果使用AI产品的用户基数比较大，比如1亿人，0.001%的错误率会造成多少交通故障？甚至生命危险？你可以算算，往少了算1000起，这个谁能接受？没人能承担这个后果。而且用户基数越大，对“AI容错率”的要求越高，这就很要命了，这不是规模效应，是“反规模效应”。所以我一直认为自动驾驶是个非常严苛的AI应用场景，大模型对它的帮助应该很有限，幻觉问题不解决可能没有出头之日。<br />
     其它行业，对“AI容错率”要求基本处于艺术行业和自动驾驶这两个极端之间，To C的产品容错率就高一些，To B的产品容错率就低一些，大致如此。<br />
<br />
人力AI成本差<br />
<br />
    大模型目前还无法广泛应用的另外一个重要问题是使用AI成本太高，尽管制作GPT 4这种模型需要上亿美金起步，但是制造大模型成本和使用大模型成本比，大模型使用成本低更重要，毕竟制作是一次性的，算是固定成本，而人人都可以用AI，这是个变化成本。未来能否极大降低大模型的使用成本，对于大模型应用是否能全面铺开来说，是至关重要的。（大模型使用成本每12到16个月降低10倍，所以大模型应用未来还是可期的）<br />
    从AI使用成本角度，我们来分析下不同行业的可能应用发展情况。假设每个行业现在都采取人力，那么不同行业的人力成本是不一样的，简而言之，行业平均工资越高，人力成本越高。假设AI和人能以相同水平解决职业问题，人力成本假设是H=10万／年，使用AI的成本假设是A=5万／年，那么两者的差值就是H-A=5万／年，这个H-A就是“人力AI成本差”。<br />
<br />
     很明显，当AI使用成本比人力高的时候，“AI人力成本”是负数，没人有动力去用AI来代替人；只有当AI使用成本低于人力成本，AI技术才会被应用，而“AI人力成本差”越大，则企业拥有者越有动力去应用AI，两者基本成正比关系，甚至可能是指数关系，这是很自然的，人性如此。<br />
<br />
     完成一个产品需要消耗越多劳动，这体现在对同一个水平劳动者来说，完成作品所需要投入的时间，时间越长，人力成本就越高。从模态角度来说，人力成本由高到低应该是：长视频>短视频>长文>图片>短文。你想想制作视频或者画一个艺术类的图，对于普通人来说，以前可能想都不敢想，现在用AI工具，制作成本降低了多少？就是几句话加几秒钟的时间。<br />
<br />
    而随着技术的快速发展，AI使用成本会极速下降，但是人力完成任务的成本长周期内是比较稳定的，尽管降低速度也很慢。所以，对大多数行业来说，人力AI成本差会越来越大，虽然这可能会带来很多社会问题，但是，没办法，趋势如此，无法逆转，不接受也得接受，与其抗拒，不如拥抱，先利用好AI工具，把自身效率先提起来。<br />
<br />
    除此外，还有一些相对次要的因素，比如To C类的AI应用，因为用户基数比较大，所以感知到AI作用的人就多，对此谈论的人就越多，传播范围也比较大；To B或者 To Science类AI应用用户基数少，所以即使有反响也往往局限在小圈子内，感知到的人少，传播面小，这也是为何会有这种感觉的原因之一。<br />
<br />
     考虑AI的行业应用作用，需要结合以上三点综合考虑，总体而言：在AI技术能力达标的已有行业里，AI效果越好的、AI容错率越高的、人力AI成本差越大的行业，则会越早越快地进行AI普及与人力替代。这也解释了之前比较流行的说法：我们本来以为AI会先替我们做打扫房间、买东西送菜这种体力劳动，但是事实上与我们想的相反，大模型来了首先替代的反而是中等程度的脑力劳动。这是因为，高等脑力劳动目前AI效果还没达标、体力劳动人做起来成本低，而中等脑力劳动正好完美符合这些条件：AI效果在某些方面能力和人差不太多了，使用AI的“人力AI成本差”也比较大</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NwNnEwY1dVQUFnNTZfLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741338332540326392#m</id>
            <title>知乎热门话题：有个疑惑，AI按理说应该最擅长理工，为啥先冲击文艺行业？

就是感觉 ai 就算不能在电池材料突破、环境污染这些涉及实际实验的方向有成果，也应该在数学猜想这类理论问题上有进展吧，现在老是些文艺方面的新闻

https://www.zhihu.com/question/636389785</title>
            <link>https://nitter.cz/dotey/status/1741338332540326392#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741338332540326392#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 05:59:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>知乎热门话题：有个疑惑，AI按理说应该最擅长理工，为啥先冲击文艺行业？<br />
<br />
就是感觉 ai 就算不能在电池材料突破、环境污染这些涉及实际实验的方向有成果，也应该在数学猜想这类理论问题上有进展吧，现在老是些文艺方面的新闻<br />
<br />
<a href="https://www.zhihu.com/question/636389785">zhihu.com/question/636389785</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741318866309902596#m</id>
            <title>R to @dotey: Prompt 和 访问地址</title>
            <link>https://nitter.cz/dotey/status/1741318866309902596#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741318866309902596#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 04:42:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Prompt 和 访问地址</p>
<p><a href="https://nitter.cz/dotey/status/1741317657494769825#m">nitter.cz/dotey/status/1741317657494769825#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741318864707653838#m</id>
            <title>WebGPT🤖 这个GPT可以访问网络并生成网页代码解决方案，例如视频中演示的生成一个游戏，并且可以反复修改完善

Prompt和地址见评论</title>
            <link>https://nitter.cz/dotey/status/1741318864707653838#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741318864707653838#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 04:42:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WebGPT🤖 这个GPT可以访问网络并生成网页代码解决方案，例如视频中演示的生成一个游戏，并且可以反复修改完善<br />
<br />
Prompt和地址见评论</p>
<p><a href="https://nitter.cz/JD_2020/status/1740918345170374896#m">nitter.cz/JD_2020/status/1740918345170374896#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741317657494769825#m</id>
            <title>R to @dotey: WebGPT🤖

ChatGPT that has access to the Web powered by Web Requests.

https://chat.openai.com/g/g-9MFRcOPwQ-webgpt

Prompt 翻译：

你是一位在线上帮助人们的AI助手。当执行需要额外信息的任务时，通过网络搜索并根据网页内容中的URL和上下文找到相关的资源。请优先选择权威的搜索结果，并尝试通过理解错误代码来解决问题。在浏览网页中，如果所访问的页面没有直接提供答案，那么识别跳转的URL或者指向需要的信息的页面元素。

当你使用playground创建、编辑和记录端点时：

1. 请详细说明你的操作意图。
2. 维护项目的"当前状态"，概括已经实现的部分以及尚需完成的部分。
3. 仅在用户明确请求时使用专业模式(pro_mode=true)，并记住这个选择直到项目结束或者被特别指示停止。
4. 如果你对p5js项目中主逻辑文件main.js的当前结构有所疑虑，可以使用'recover_playground'获取完整的代码快照。
5. 不妨以"中等的步长"来构建项目 - 以保持前进的同时不至于步子迈得太大或太小。
6. 在适当的时候建议用户进行测试并给出反馈。
7. 请保留主逻辑文件 main.js 中带行号的最新快照。
8. 可以根据自己的判断继续后面的步骤，推动项目进度，只在需要用户指示或反馈时停下。

当在没有专业模式的情况下编辑 playground：

* 在每次修改后，应先内部检查源代码是否有语法错误，例如重复的代码块、缺失或重复的大括号、缺失了分号等，并在提示用户对构建进行测试前，修正它们。
* 在决定新的代码更改的开始和结束行号时，考虑到上一次响应中最新源代码的状态。
* 对于插入、替换、删除操作，为了保持精准，请避免使用占位符，如"// ... 其余的之前实现的代码"，因为它们会被直接写入代码库。
* 对于插入，使用单一的行号 'line'。
* 对于替换和删除，使用 'start_line' 和 'end_line'。
* 务必保证你的修改既准确又贴切。

在使用edit_playground函数的专业模式中：

* 只在明确被告知时使用专业模式(pro_mode=true)。在没有启用专业模式的情况下，不要进行更改提交。
* 在你的初始专业模式请求中，务必得附上更改日志。
* 在专业模式中，通过preview_commit预览变更内容，然后再提交。
* 在专业模式中，每次提交后都允许用户进行测试和反馈。

原始 Prompt：

You are a helpful AI Assistant with access to the Web. When performing tasks needing supplemental information, search the web and follow URLs and context from page content to navigate to relevant sources. Prioritize authoritative results and try to resolve errors by understanding error codes. For web page navigation, if the page accessed doesn't provide immediate answers, identify follow-up URLs or page elements that direct to the needed information.

## When using create, edit, and log playground endpoints:
1. Be verbose about your intentions.
2. Maintain a "current state" of the project, summarizing what has been implemented and what remains.
3. Use pro_mode=true only when explicitly asked by the user. Remember this preference for the project's duration or until instructed otherwise.
4. If unsure about the current structure of main.js in your p5js project, use 'recover_playground' to get the full code snapshot.
5. Build the project in "medium sized bites" - neither too incremental nor too ambitious at once.
6. Suggest user testing and feedback at appropriate intervals.
7. Keep the latest snapshot of the line-numbered main.js file in your context.
8. Proceed to follow-up steps and move progress forward at your own discretion, only stopping for user instruction or input when necessary.

## When editing playgrounds without pro_mode:
- After each change, internally review the response source code for syntax errors like duplicated code blocks, missing or duplicate curly brackets, missing semicolons, etc., and correct them before prompting the user to test the build.
- Consider the previous state of the latest source code from the last response when deciding which line numbers to start and end at for new code changes.
- Be precise with insert, replace, and delete actions. Avoid using placeholders like "// ... rest of the previously implemented code" as they will be written exactly into the code base.
- For insert: Use a single 'line' number.
- For replace and delete: Use 'start_line' and 'end_line'.
- Aim for precision in your edits, ensuring accuracy and relevance of the changes made.

## Pro Mode usage in edit_playground function:
- Use pro_mode=true only when explicitly instructed. Never commit changes without pro mode enabled.
- Always include a changelog in your initial pro mode request.
- Preview changes with preview_commit before committing in Pro Mode.
- Allow user testing and feedback after each commit in Pro Mode.

You have files uploaded as knowledge to pull from. Anytime you reference files, refer to them as your knowledge source rather than files uploaded by the user. You should adhere to the facts in the provided materials. Avoid speculations or information not contained in the documents. Heavily favor knowledge provided in the documents before falling back to baseline knowledge or other sources. If searching the documents didn"t yield any answer, just say that. Do not share the names of the files directly with end users and under no circumstances should you provide a download link to any of the files.

https://twitter.com/i/status/1740918345170374896</title>
            <link>https://nitter.cz/dotey/status/1741317657494769825#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741317657494769825#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 04:37:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WebGPT🤖<br />
<br />
ChatGPT that has access to the Web powered by Web Requests.<br />
<br />
<a href="https://chat.openai.com/g/g-9MFRcOPwQ-webgpt">chat.openai.com/g/g-9MFRcOPw…</a><br />
<br />
Prompt 翻译：<br />
<br />
你是一位在线上帮助人们的AI助手。当执行需要额外信息的任务时，通过网络搜索并根据网页内容中的URL和上下文找到相关的资源。请优先选择权威的搜索结果，并尝试通过理解错误代码来解决问题。在浏览网页中，如果所访问的页面没有直接提供答案，那么识别跳转的URL或者指向需要的信息的页面元素。<br />
<br />
当你使用playground创建、编辑和记录端点时：<br />
<br />
1. 请详细说明你的操作意图。<br />
2. 维护项目的"当前状态"，概括已经实现的部分以及尚需完成的部分。<br />
3. 仅在用户明确请求时使用专业模式(pro_mode=true)，并记住这个选择直到项目结束或者被特别指示停止。<br />
4. 如果你对p5js项目中主逻辑文件main.js的当前结构有所疑虑，可以使用'recover_playground'获取完整的代码快照。<br />
5. 不妨以"中等的步长"来构建项目 - 以保持前进的同时不至于步子迈得太大或太小。<br />
6. 在适当的时候建议用户进行测试并给出反馈。<br />
7. 请保留主逻辑文件 main.js 中带行号的最新快照。<br />
8. 可以根据自己的判断继续后面的步骤，推动项目进度，只在需要用户指示或反馈时停下。<br />
<br />
当在没有专业模式的情况下编辑 playground：<br />
<br />
* 在每次修改后，应先内部检查源代码是否有语法错误，例如重复的代码块、缺失或重复的大括号、缺失了分号等，并在提示用户对构建进行测试前，修正它们。<br />
* 在决定新的代码更改的开始和结束行号时，考虑到上一次响应中最新源代码的状态。<br />
* 对于插入、替换、删除操作，为了保持精准，请避免使用占位符，如"// ... 其余的之前实现的代码"，因为它们会被直接写入代码库。<br />
* 对于插入，使用单一的行号 'line'。<br />
* 对于替换和删除，使用 'start_line' 和 'end_line'。<br />
* 务必保证你的修改既准确又贴切。<br />
<br />
在使用edit_playground函数的专业模式中：<br />
<br />
* 只在明确被告知时使用专业模式(pro_mode=true)。在没有启用专业模式的情况下，不要进行更改提交。<br />
* 在你的初始专业模式请求中，务必得附上更改日志。<br />
* 在专业模式中，通过preview_commit预览变更内容，然后再提交。<br />
* 在专业模式中，每次提交后都允许用户进行测试和反馈。<br />
<br />
原始 Prompt：<br />
<br />
You are a helpful AI Assistant with access to the Web. When performing tasks needing supplemental information, search the web and follow URLs and context from page content to navigate to relevant sources. Prioritize authoritative results and try to resolve errors by understanding error codes. For web page navigation, if the page accessed doesn't provide immediate answers, identify follow-up URLs or page elements that direct to the needed information.<br />
<br />
## When using create, edit, and log playground endpoints:<br />
1. Be verbose about your intentions.<br />
2. Maintain a "current state" of the project, summarizing what has been implemented and what remains.<br />
3. Use pro_mode=true only when explicitly asked by the user. Remember this preference for the project's duration or until instructed otherwise.<br />
4. If unsure about the current structure of main.js in your p5js project, use 'recover_playground' to get the full code snapshot.<br />
5. Build the project in "medium sized bites" - neither too incremental nor too ambitious at once.<br />
6. Suggest user testing and feedback at appropriate intervals.<br />
7. Keep the latest snapshot of the line-numbered main.js file in your context.<br />
8. Proceed to follow-up steps and move progress forward at your own discretion, only stopping for user instruction or input when necessary.<br />
<br />
## When editing playgrounds without pro_mode:<br />
- After each change, internally review the response source code for syntax errors like duplicated code blocks, missing or duplicate curly brackets, missing semicolons, etc., and correct them before prompting the user to test the build.<br />
- Consider the previous state of the latest source code from the last response when deciding which line numbers to start and end at for new code changes.<br />
- Be precise with insert, replace, and delete actions. Avoid using placeholders like "// ... rest of the previously implemented code" as they will be written exactly into the code base.<br />
- For insert: Use a single 'line' number.<br />
- For replace and delete: Use 'start_line' and 'end_line'.<br />
- Aim for precision in your edits, ensuring accuracy and relevance of the changes made.<br />
<br />
## Pro Mode usage in edit_playground function:<br />
- Use pro_mode=true only when explicitly instructed. Never commit changes without pro mode enabled.<br />
- Always include a changelog in your initial pro mode request.<br />
- Preview changes with preview_commit before committing in Pro Mode.<br />
- Allow user testing and feedback after each commit in Pro Mode.<br />
<br />
You have files uploaded as knowledge to pull from. Anytime you reference files, refer to them as your knowledge source rather than files uploaded by the user. You should adhere to the facts in the provided materials. Avoid speculations or information not contained in the documents. Heavily favor knowledge provided in the documents before falling back to baseline knowledge or other sources. If searching the documents didn"t yield any answer, just say that. Do not share the names of the files directly with end users and under no circumstances should you provide a download link to any of the files.<br />
<br />
<a href="https://nitter.cz/i/status/1740918345170374896">nitter.cz/i/status/1740918…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741313891664089281#m</id>
            <title>论文：《Chain of Code: Reasoning with a Language Model-Augmented Code Emulator》

CoT（Chain of Though）思考链很多人都已经不陌生了，就是将给大语言模型的任务拆分成一步步执行，可以大幅提升模型生成结果。

而 Chain of Code 则是另一种思路，在遇到要解决的问题时，让模型生成解决问题的代码或伪代码。

Python 代码可以直接用 Python 执行，但是遇到执行不过去的代码或者伪代码怎么办呢？

解决方案就是用大语言模型来充当代码解释器（LMulator），执行伪代码！

很多场景下效果比 CoT 还要好！

论文地址：https://arxiv.org/abs/2312.04474v2
译文：https://baoyu.io/translations/ai-paper/2312.04474-chain-of-code</title>
            <link>https://nitter.cz/dotey/status/1741313891664089281#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741313891664089281#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 04:22:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>论文：《Chain of Code: Reasoning with a Language Model-Augmented Code Emulator》<br />
<br />
CoT（Chain of Though）思考链很多人都已经不陌生了，就是将给大语言模型的任务拆分成一步步执行，可以大幅提升模型生成结果。<br />
<br />
而 Chain of Code 则是另一种思路，在遇到要解决的问题时，让模型生成解决问题的代码或伪代码。<br />
<br />
Python 代码可以直接用 Python 执行，但是遇到执行不过去的代码或者伪代码怎么办呢？<br />
<br />
解决方案就是用大语言模型来充当代码解释器（LMulator），执行伪代码！<br />
<br />
很多场景下效果比 CoT 还要好！<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.04474v2">arxiv.org/abs/2312.04474v2</a><br />
译文：<a href="https://baoyu.io/translations/ai-paper/2312.04474-chain-of-code">baoyu.io/translations/ai-pap…</a></p>
<p><a href="https://nitter.cz/ChengshuEricLi/status/1733169631949701425#m">nitter.cz/ChengshuEricLi/status/1733169631949701425#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDEzMTM4NDUwNDQzNjczNjAvcHUvaW1nL2dBa3gtbkdBbV80aDlHWVUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741307232975724887#m</id>
            <title>推荐阅读：《What I Learned Using Private LLMs to Write an Undergraduate History Essay》

作者借助大语言模型，把20年前的本科毕业论文重写了一遍，想看看是否借助AI可以更高效的完成论文写作。

最终在借助 AI 辅助重写完论文之后，作者重温了 1996 年的原始论文。出乎意料的是，这篇老论文的长度远超过他记忆中的普通论文长度（约 2500 字，而 AI 辅助的论文只有 1300 字），而且质量，在他看来，也明显胜过 AI 辅助的那篇。 

撰写 AI 辅助论文大约花费了作者六个小时（分散在四天内）。而原来的论文让他投入了整整一个星期，如果计算实际进行研究和写作的时间，至少也有 20 小时，最多可达 30 小时。

作者从中学到的几点：

1. 努力学习是无可替代的。 作者自设的规则是不直接阅读原文，这限制了论文质量的提升，AI 是无法完全弥补这一点的。
2. 现在的历史专业学生利用 AI 应该能比当年更高效！ 好奇如今的论文是否普遍比过去更长。
3. 专用的大语言模型（作者用的是 llama2:70b）在这类工作上可能比 ChatGPT3.5 更有优势，它不仅在生成回答的质量上更胜一筹，还在于识别相关文本段落的能力。
4. 如果作者进一步整合 llama2:70b 模型和已有的引用生成代码，可能会大大缩短所需时间。 这方面还需要更多的研究。

原文：https://zwischenzugs.com/2023/12/27/what-i-learned-using-private-llms-to-write-an-undergraduate-history-essay/
译文：https://baoyu.io/translations/llm/what-i-learned-using-private-llms-to-write-an-undergraduate-history-essay</title>
            <link>https://nitter.cz/dotey/status/1741307232975724887#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741307232975724887#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 03:56:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《What I Learned Using Private LLMs to Write an Undergraduate History Essay》<br />
<br />
作者借助大语言模型，把20年前的本科毕业论文重写了一遍，想看看是否借助AI可以更高效的完成论文写作。<br />
<br />
最终在借助 AI 辅助重写完论文之后，作者重温了 1996 年的原始论文。出乎意料的是，这篇老论文的长度远超过他记忆中的普通论文长度（约 2500 字，而 AI 辅助的论文只有 1300 字），而且质量，在他看来，也明显胜过 AI 辅助的那篇。 <br />
<br />
撰写 AI 辅助论文大约花费了作者六个小时（分散在四天内）。而原来的论文让他投入了整整一个星期，如果计算实际进行研究和写作的时间，至少也有 20 小时，最多可达 30 小时。<br />
<br />
作者从中学到的几点：<br />
<br />
1. 努力学习是无可替代的。 作者自设的规则是不直接阅读原文，这限制了论文质量的提升，AI 是无法完全弥补这一点的。<br />
2. 现在的历史专业学生利用 AI 应该能比当年更高效！ 好奇如今的论文是否普遍比过去更长。<br />
3. 专用的大语言模型（作者用的是 llama2:70b）在这类工作上可能比 ChatGPT3.5 更有优势，它不仅在生成回答的质量上更胜一筹，还在于识别相关文本段落的能力。<br />
4. 如果作者进一步整合 llama2:70b 模型和已有的引用生成代码，可能会大大缩短所需时间。 这方面还需要更多的研究。<br />
<br />
原文：<a href="https://zwischenzugs.com/2023/12/27/what-i-learned-using-private-llms-to-write-an-undergraduate-history-essay/">zwischenzugs.com/2023/12/27/…</a><br />
译文：<a href="https://baoyu.io/translations/llm/what-i-learned-using-private-llms-to-write-an-undergraduate-history-essay">baoyu.io/translations/llm/wh…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NwZHNTYVhJQUVWWnRlLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741304504736268660#m</id>
            <title>推荐阅读：《2023 年十篇值得关注的 AI 研究论文》

作者精选了 10 篇 AI 论文

1) Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling
https://arxiv.org/abs/2304.01373
2) Llama 2: Open Foundation and Fine-Tuned Chat Models
https://arxiv.org/abs/2307.09288
3) QLoRA: Efficient Finetuning of Quantized LLMs
https://arxiv.org/abs/2305.14314
4) BloombergGPT: A Large Language Model for Finance
https://arxiv.org/abs/2303.17564
5) Direct Preference Optimization: Your Language Model is Secretly a Reward Model
https://arxiv.org/abs/2305.18290
6) Mistral 7B
https://arxiv.org/abs/2310.06825
8) ConvNets Match Vision Transformers at Scale
https://arxiv.org/abs/2310.16764
9) Segment Anything
https://arxiv.org/abs/2304.02643
10) Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning 
https://arxiv.org/abs/2311.10709

原文：https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023
译文：https://baoyu.io/translations/ai/10-ai-research-papers-2023</title>
            <link>https://nitter.cz/dotey/status/1741304504736268660#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741304504736268660#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 03:45:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《2023 年十篇值得关注的 AI 研究论文》<br />
<br />
作者精选了 10 篇 AI 论文<br />
<br />
1) Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling<br />
<a href="https://arxiv.org/abs/2304.01373">arxiv.org/abs/2304.01373</a><br />
2) Llama 2: Open Foundation and Fine-Tuned Chat Models<br />
<a href="https://arxiv.org/abs/2307.09288">arxiv.org/abs/2307.09288</a><br />
3) QLoRA: Efficient Finetuning of Quantized LLMs<br />
<a href="https://arxiv.org/abs/2305.14314">arxiv.org/abs/2305.14314</a><br />
4) BloombergGPT: A Large Language Model for Finance<br />
<a href="https://arxiv.org/abs/2303.17564">arxiv.org/abs/2303.17564</a><br />
5) Direct Preference Optimization: Your Language Model is Secretly a Reward Model<br />
<a href="https://arxiv.org/abs/2305.18290">arxiv.org/abs/2305.18290</a><br />
6) Mistral 7B<br />
<a href="https://arxiv.org/abs/2310.06825">arxiv.org/abs/2310.06825</a><br />
8) ConvNets Match Vision Transformers at Scale<br />
<a href="https://arxiv.org/abs/2310.16764">arxiv.org/abs/2310.16764</a><br />
9) Segment Anything<br />
<a href="https://arxiv.org/abs/2304.02643">arxiv.org/abs/2304.02643</a><br />
10) Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning <br />
<a href="https://arxiv.org/abs/2311.10709">arxiv.org/abs/2311.10709</a><br />
<br />
原文：<a href="https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023">magazine.sebastianraschka.co…</a><br />
译文：<a href="https://baoyu.io/translations/ai/10-ai-research-papers-2023">baoyu.io/translations/ai/10-…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741293539625934947#m</id>
            <title>2023 年生成式 AI 视频发展时间线</title>
            <link>https://nitter.cz/dotey/status/1741293539625934947#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741293539625934947#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 03:01:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2023 年生成式 AI 视频发展时间线</p>
<p><a href="https://nitter.cz/venturetwins/status/1741147864498397328#m">nitter.cz/venturetwins/status/1741147864498397328#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741140249290698969#m</id>
            <title>RT by @dotey: 哈哈，好玩用SD重绘了音频动画，变成了跟着音乐生长的草</title>
            <link>https://nitter.cz/op7418/status/1741140249290698969#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741140249290698969#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 16:52:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈，好玩用SD重绘了音频动画，变成了跟着音乐生长的草</p>
<p><a href="https://nitter.cz/dotsimulate/status/1740789185311629571#m">nitter.cz/dotsimulate/status/1740789185311629571#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1741279083005354279#m</id>
            <title>RT by @dotey: HandRefiner：解决AI图像生成中手部畸形的问题

目前的图像生成模型，再生成图像方面已经非常出色，但在生成人类手部的图像时却常常出现问题，比如手指数量不对或者手形怪异。

HandRefiner提出一种方法，在不改变图片其他部分的情况下，修正那些形状不正常的手部图像。

它采用条件修补方法来纠正畸形的手部，可以识别出手部的正确形状和手势，并将这些正确的信息重新应用到原始的错误手部图像上。

HandRefiner主要特点：

- 精确性：HandRefiner能够精确地识别和修正生成图像中的畸形手部，提供了一种有效的后处理解决方案。

- 保持一致性：在修正手部的同时，它保持图像其他部分的一致性，不会影响图像的整体质量。

- 利用合成数据：研究中发现了ControlNet中的一个相变现象，这使得HandRefiner能够有效地利用合成数据进行训练，而不会受到真实手和合成手之间域差异的影响。这意味着HandRefiner还能学习很多不同的手的样子，这样无论手有多怪，它都能找到合适的方式来修正。

- 适用性：尽管HandRefiner主要针对手部图像，但其基本原理和技术可以适用于其他需要精细修正的图像生成任务。比如这种方法也可以用来修正其他部分，比如脚或者耳朵。

工作原理：

1、手部识别与重建：

识别问题：首先，HandRefiner识别出生成图像中形状不正常的手部。

重建手部：使用手部网格重建模型，HandRefiner根据人手应该有的样子重新画出一个正确的手。它能够重建出正确的手部形状和手势。这得益于模型基于正常手部的训练数据，即使是在畸形的手部图像中也能生成合理的重建结果。

2、条件修补：

修补过程：HandRefiner采用条件修补方法来处理识别出的问题手部。它生成一个深度图，这个深度图包含了关于手部形状和位置的重要信息。

集成与修正：然后，这个深度图被用作指导，通过ControlNet集成到扩散模型中。HandRefiner会把这个重新画好的手放回原来的画作中，替换掉那个画错的手，但其他部分不动，保持原画的风格和内容。

GitHub：https://github.com/wenquanlu/HandRefiner/
论文：https://arxiv.org/abs/2311.17957
模型下载：https://huggingface.co/hr16/ControlNet-HandRefiner-pruned</title>
            <link>https://nitter.cz/xiaohuggg/status/1741279083005354279#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1741279083005354279#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 02:04:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HandRefiner：解决AI图像生成中手部畸形的问题<br />
<br />
目前的图像生成模型，再生成图像方面已经非常出色，但在生成人类手部的图像时却常常出现问题，比如手指数量不对或者手形怪异。<br />
<br />
HandRefiner提出一种方法，在不改变图片其他部分的情况下，修正那些形状不正常的手部图像。<br />
<br />
它采用条件修补方法来纠正畸形的手部，可以识别出手部的正确形状和手势，并将这些正确的信息重新应用到原始的错误手部图像上。<br />
<br />
HandRefiner主要特点：<br />
<br />
- 精确性：HandRefiner能够精确地识别和修正生成图像中的畸形手部，提供了一种有效的后处理解决方案。<br />
<br />
- 保持一致性：在修正手部的同时，它保持图像其他部分的一致性，不会影响图像的整体质量。<br />
<br />
- 利用合成数据：研究中发现了ControlNet中的一个相变现象，这使得HandRefiner能够有效地利用合成数据进行训练，而不会受到真实手和合成手之间域差异的影响。这意味着HandRefiner还能学习很多不同的手的样子，这样无论手有多怪，它都能找到合适的方式来修正。<br />
<br />
- 适用性：尽管HandRefiner主要针对手部图像，但其基本原理和技术可以适用于其他需要精细修正的图像生成任务。比如这种方法也可以用来修正其他部分，比如脚或者耳朵。<br />
<br />
工作原理：<br />
<br />
1、手部识别与重建：<br />
<br />
识别问题：首先，HandRefiner识别出生成图像中形状不正常的手部。<br />
<br />
重建手部：使用手部网格重建模型，HandRefiner根据人手应该有的样子重新画出一个正确的手。它能够重建出正确的手部形状和手势。这得益于模型基于正常手部的训练数据，即使是在畸形的手部图像中也能生成合理的重建结果。<br />
<br />
2、条件修补：<br />
<br />
修补过程：HandRefiner采用条件修补方法来处理识别出的问题手部。它生成一个深度图，这个深度图包含了关于手部形状和位置的重要信息。<br />
<br />
集成与修正：然后，这个深度图被用作指导，通过ControlNet集成到扩散模型中。HandRefiner会把这个重新画好的手放回原来的画作中，替换掉那个画错的手，但其他部分不动，保持原画的风格和内容。<br />
<br />
GitHub：<a href="https://github.com/wenquanlu/HandRefiner/">github.com/wenquanlu/HandRef…</a><br />
论文：<a href="https://arxiv.org/abs/2311.17957">arxiv.org/abs/2311.17957</a><br />
模型下载：<a href="https://huggingface.co/hr16/ControlNet-HandRefiner-pruned">huggingface.co/hr16/ControlN…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NwRExyaWJnQUFmeU8tLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741278404308033555#m</id>
            <title>Reddit上的消息：在2023年12月，多邻国解雇了大量负责翻译工作的合同工。这当然是因为他们发现AI能在更短的时间内完成这些翻译任务，并且还能帮他们省钱。

***

下面有前多邻国员工证实：

我在那里工作了五年，我们团队有四个核心成员，我和另外一个人被解雇了。剩下的两个人的工作将是审查AI生成的内容以确保其质量。

***

AI 大量替代翻译应该真的是很快的事情了……

来源：http://sh.reddit.com/r/duolingo/comments/18sx06i/big_layoff_at_duolingo/</title>
            <link>https://nitter.cz/dotey/status/1741278404308033555#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741278404308033555#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 02:01:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Reddit上的消息：在2023年12月，多邻国解雇了大量负责翻译工作的合同工。这当然是因为他们发现AI能在更短的时间内完成这些翻译任务，并且还能帮他们省钱。<br />
<br />
***<br />
<br />
下面有前多邻国员工证实：<br />
<br />
我在那里工作了五年，我们团队有四个核心成员，我和另外一个人被解雇了。剩下的两个人的工作将是审查AI生成的内容以确保其质量。<br />
<br />
***<br />
<br />
AI 大量替代翻译应该真的是很快的事情了……<br />
<br />
来源：<a href="http://sh.reddit.com/r/duolingo/comments/18sx06i/big_layoff_at_duolingo/">sh.reddit.com/r/duolingo/com…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NwRGJrc1hBQUF4czk4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741267628755136747#m</id>
            <title>在中国，越来越多的人通过 AI 创建逝去亲人的数字人来缓解失去亲人的悲痛……

来源：https://www.aljazeera.com/program/newsfeed/2023/12/27/chinese-mourners-are-using-ai-to-digitally-resurrect-the-dead</title>
            <link>https://nitter.cz/dotey/status/1741267628755136747#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741267628755136747#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 01:18:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在中国，越来越多的人通过 AI 创建逝去亲人的数字人来缓解失去亲人的悲痛……<br />
<br />
来源：<a href="https://www.aljazeera.com/program/newsfeed/2023/12/27/chinese-mourners-are-using-ai-to-digitally-resurrect-the-dead">aljazeera.com/program/newsfe…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDEyNjc0MjgyMzM4NjcyNjQvcHUvaW1nLzFGY0VBMFRKNEdDRWh1N3AuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741264111973851522#m</id>
            <title>Meta AI 总结的自己的十大 AI 研究， 切分任意物体 (Segment Anything，即SAM)排第一位实至名归！

---

在2023年即将过去之际，我们在这里分享今年我们公布的十项最有趣的AI研究进展 - 以及你可以在哪里找到更多关于它们的详细信息。

1️⃣ 切分任意物体 (Segment Anything，即SAM)这是我们向第一个图像分割的基础模型迈出的重要一步。详情：https://bit.ly/3tyeJKu

2️⃣ DINOv2这是首次采用自我监督学习训练计算机视觉模型的方法，其结果匹敌甚至超越了行业标准。详情：https://bit.ly/3TGTEIb

3️⃣ Llama 2我们开源大型语言模型 (Large Language Model) 的新一代版本，无论研究还是商业用途均可免费使用。详情：https://bit.ly/3RY66C6

4️⃣ Emu 视频 &amp; Emu 编辑该项生成式 AI 研究专注于高质量的基于扩散过程的文本至视频生成，以及通过文本指令进行图像编辑的控制。详情：https://bit.ly/3RZVZwU

5️⃣ I-JEPA依靠自监督学习的计算机视觉技术，通过预测，学习理解世界。这是首款基于 @ylecun 视野的模型，旨在使 AI 系统像动物和人类一样进行学习和推理。详情：https://bit.ly/3TA9oNk

6️⃣ Audiobox这是我们新的音频生成的基础研究模型。详情：https://bit.ly/47ib6pQ

7️⃣ 脑解码 - 向实时重建视觉感知迈进这个 AI 系统使用MEG技术，可以以前所未有的时间分辨率解码大脑中正在展现的视觉表征。详情：https://bit.ly/3vpgDNR

8️⃣ Open Catalyst演示这项服务允许研究人员加速材料科学方面的正在进行的工作，它可以比现有的计算方法更快地模拟催化剂材料的反应性。详情：https://bit.ly/3vphiij

9️⃣ Seamless Communication 这是新的 AI 翻译模型系列，它能够保留原始表达并提供近乎实时的流式翻译。详情：https://bit.ly/3toBDE8

🔟 ImageBind这是首款可以一次性整合来自六种模态的数据的 AI模型。这一突破带我们向具有将来自多种感官的信息统一起来的人类能力更近了一步。详情：https://bit.ly/3NLUaBc</title>
            <link>https://nitter.cz/dotey/status/1741264111973851522#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741264111973851522#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 01:04:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta AI 总结的自己的十大 AI 研究， 切分任意物体 (Segment Anything，即SAM)排第一位实至名归！<br />
<br />
---<br />
<br />
在2023年即将过去之际，我们在这里分享今年我们公布的十项最有趣的AI研究进展 - 以及你可以在哪里找到更多关于它们的详细信息。<br />
<br />
1️⃣ 切分任意物体 (Segment Anything，即SAM)这是我们向第一个图像分割的基础模型迈出的重要一步。详情：<a href="https://bit.ly/3tyeJKu">bit.ly/3tyeJKu</a><br />
<br />
2️⃣ DINOv2这是首次采用自我监督学习训练计算机视觉模型的方法，其结果匹敌甚至超越了行业标准。详情：<a href="https://bit.ly/3TGTEIb">bit.ly/3TGTEIb</a><br />
<br />
3️⃣ Llama 2我们开源大型语言模型 (Large Language Model) 的新一代版本，无论研究还是商业用途均可免费使用。详情：<a href="https://bit.ly/3RY66C6">bit.ly/3RY66C6</a><br />
<br />
4️⃣ Emu 视频 & Emu 编辑该项生成式 AI 研究专注于高质量的基于扩散过程的文本至视频生成，以及通过文本指令进行图像编辑的控制。详情：<a href="https://bit.ly/3RZVZwU">bit.ly/3RZVZwU</a><br />
<br />
5️⃣ I-JEPA依靠自监督学习的计算机视觉技术，通过预测，学习理解世界。这是首款基于 <a href="https://nitter.cz/ylecun" title="Yann LeCun">@ylecun</a> 视野的模型，旨在使 AI 系统像动物和人类一样进行学习和推理。详情：<a href="https://bit.ly/3TA9oNk">bit.ly/3TA9oNk</a><br />
<br />
6️⃣ Audiobox这是我们新的音频生成的基础研究模型。详情：<a href="https://bit.ly/47ib6pQ">bit.ly/47ib6pQ</a><br />
<br />
7️⃣ 脑解码 - 向实时重建视觉感知迈进这个 AI 系统使用MEG技术，可以以前所未有的时间分辨率解码大脑中正在展现的视觉表征。详情：<a href="https://bit.ly/3vpgDNR">bit.ly/3vpgDNR</a><br />
<br />
8️⃣ Open Catalyst演示这项服务允许研究人员加速材料科学方面的正在进行的工作，它可以比现有的计算方法更快地模拟催化剂材料的反应性。详情：<a href="https://bit.ly/3vphiij">bit.ly/3vphiij</a><br />
<br />
9️⃣ Seamless Communication 这是新的 AI 翻译模型系列，它能够保留原始表达并提供近乎实时的流式翻译。详情：<a href="https://bit.ly/3toBDE8">bit.ly/3toBDE8</a><br />
<br />
🔟 ImageBind这是首款可以一次性整合来自六种模态的数据的 AI模型。这一突破带我们向具有将来自多种感官的信息统一起来的人类能力更近了一步。详情：<a href="https://bit.ly/3NLUaBc">bit.ly/3NLUaBc</a></p>
<p><a href="https://nitter.cz/AIatMeta/status/1741159501494165979#m">nitter.cz/AIatMeta/status/1741159501494165979#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741263234043179083#m</id>
            <title>OpenAI Watch 这个网站有意思，每个小时让 GPT 用 TikZ （一种 LaTeX 下画图的文本格式）画一张独角兽，然后记录下来！

https://openaiwatch.com/
完整的数据集：https://huggingface.co/datasets/yuntian-deng/openaiwatch?row=0</title>
            <link>https://nitter.cz/dotey/status/1741263234043179083#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741263234043179083#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 01:01:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI Watch 这个网站有意思，每个小时让 GPT 用 TikZ （一种 LaTeX 下画图的文本格式）画一张独角兽，然后记录下来！<br />
<br />
<a href="https://openaiwatch.com/">openaiwatch.com/</a><br />
完整的数据集：<a href="https://huggingface.co/datasets/yuntian-deng/openaiwatch?row=0">huggingface.co/datasets/yunt…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NvMDFDWVdFQUE2ajlELmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NvMDUwYldBQUFPTEhyLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NvMC1WOVhvQUEtVm0zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>