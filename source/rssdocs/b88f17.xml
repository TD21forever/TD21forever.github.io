<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1745204162978070532#m</id>
            <title>Adobe的 MorphCut 这个技术在剪辑视频时还是蛮实用的，可以让几段剪辑视频之间的过度变的平滑，让人看不出其中的跳帧变化，生成无缝切换的视频结果

https://arxiv.org/abs/2401.04718</title>
            <link>https://nitter.cz/dotey/status/1745204162978070532#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1745204162978070532#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 22:01:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Adobe的 MorphCut 这个技术在剪辑视频时还是蛮实用的，可以让几段剪辑视频之间的过度变的平滑，让人看不出其中的跳帧变化，生成无缝切换的视频结果<br />
<br />
<a href="https://arxiv.org/abs/2401.04718">arxiv.org/abs/2401.04718</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1744943977663488126#m">nitter.cz/_akhaliq/status/1744943977663488126#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDUyMDMyODUzNzg2NjY0OTYvcHUvaW1nL25MeXdmU1Zvd1hoLV9YM28uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1745196224821567947#m</id>
            <title>由于表格数据是一种结构化的数据，有行和列，现阶段LLM对于理解表格数据和基于表格数据推理都比较弱。

这篇新论文：《Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding》提出了个新的思路让 LLM 更好的对表格相关的内容进行推理。

先看个例子（参考图一），假如有一个自行车运动员排名的表格如下：

| 排名 | 自行车运动员     |
|------|-----------------|
| 1    | Alejandro (ESP) |
| 2    | Davide (ITA)    |
| 3    | Paolo (ITA)     |
| 4    | Haimar (ESP)    |

现在需要让 LLM 找出哪个国家有最多的自行车运动员进入前三名？

基于 Chain-of-Table 的思路是这样的，也是分步骤操作：

1. 先将表格扩展成 3 列，新增一个 country 的列，数据从第二列中获取
2. 选择排名前 3 的行（因为题目只关心前三名）
3. 按照 country 分组并计数
4. 对表格进行排序得到新的表格

| 国家 | 数量 |
|------|------|
| ITA  | 2    |
| ESP  | 1    |

最终得到 ITA 就是前三名运动员最多的国家！

这里面有几个要点：

一、为了更好的让大语言模型理解和操作模型，需要对大语言模型进行微调，从而可以：
1. 用Markdown表达表格格式
2. 能支持一组在SQL和DataFrame开发中常用的五个表操作：f_add_column()、f_select_row()、f_select_column()、f_group_by() 和 f_sort_by()

二、由大语言模型根据问题和表格来规划对表格的操作步骤

前面例子中的4个步骤，并不是由人去生成的步骤，而是大语言模型去根据问题和当前状态一步步推理而来

三、每一个步骤由两个操作组成（图二）：动态规划（Dynamic Planning）和参数生成（Argument Generation）

动态规划 是根据原始问题、当前表格内容和可用的表操作（f_add_column、f_select_row 等）来选择下一次操作

参数生成则是根据选择好的操作，找出要传入的参数。

（不太清楚为啥不合并成一次操作）

重复以上步骤一直到找出答案为止。

基于现阶段的 LLM 能力，这确实是一种不错的思路：
为 LLM 提供理解和操作表格的能力，让 LLM 利用自身的推理能力将复杂任务分解成多个步骤，一步步操作表格得到最终结果。

论文地址：https://arxiv.org/abs/2401.04398v1</title>
            <link>https://nitter.cz/dotey/status/1745196224821567947#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1745196224821567947#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 21:29:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>由于表格数据是一种结构化的数据，有行和列，现阶段LLM对于理解表格数据和基于表格数据推理都比较弱。<br />
<br />
这篇新论文：《Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding》提出了个新的思路让 LLM 更好的对表格相关的内容进行推理。<br />
<br />
先看个例子（参考图一），假如有一个自行车运动员排名的表格如下：<br />
<br />
| 排名 | 自行车运动员     |<br />
|------|-----------------|<br />
| 1    | Alejandro (ESP) |<br />
| 2    | Davide (ITA)    |<br />
| 3    | Paolo (ITA)     |<br />
| 4    | Haimar (ESP)    |<br />
<br />
现在需要让 LLM 找出哪个国家有最多的自行车运动员进入前三名？<br />
<br />
基于 Chain-of-Table 的思路是这样的，也是分步骤操作：<br />
<br />
1. 先将表格扩展成 3 列，新增一个 country 的列，数据从第二列中获取<br />
2. 选择排名前 3 的行（因为题目只关心前三名）<br />
3. 按照 country 分组并计数<br />
4. 对表格进行排序得到新的表格<br />
<br />
| 国家 | 数量 |<br />
|------|------|<br />
| ITA  | 2    |<br />
| ESP  | 1    |<br />
<br />
最终得到 ITA 就是前三名运动员最多的国家！<br />
<br />
这里面有几个要点：<br />
<br />
一、为了更好的让大语言模型理解和操作模型，需要对大语言模型进行微调，从而可以：<br />
1. 用Markdown表达表格格式<br />
2. 能支持一组在SQL和DataFrame开发中常用的五个表操作：f_add_column()、f_select_row()、f_select_column()、f_group_by() 和 f_sort_by()<br />
<br />
二、由大语言模型根据问题和表格来规划对表格的操作步骤<br />
<br />
前面例子中的4个步骤，并不是由人去生成的步骤，而是大语言模型去根据问题和当前状态一步步推理而来<br />
<br />
三、每一个步骤由两个操作组成（图二）：动态规划（Dynamic Planning）和参数生成（Argument Generation）<br />
<br />
动态规划 是根据原始问题、当前表格内容和可用的表操作（f_add_column、f_select_row 等）来选择下一次操作<br />
<br />
参数生成则是根据选择好的操作，找出要传入的参数。<br />
<br />
（不太清楚为啥不合并成一次操作）<br />
<br />
重复以上步骤一直到找出答案为止。<br />
<br />
基于现阶段的 LLM 能力，这确实是一种不错的思路：<br />
为 LLM 提供理解和操作表格的能力，让 LLM 利用自身的推理能力将复杂任务分解成多个步骤，一步步操作表格得到最终结果。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2401.04398v1">arxiv.org/abs/2401.04398v1</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RnbzcxVFdBQUFvWC0xLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RncFgzY2FZQUFxeHFBLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1745176249071267997#m</id>
            <title>R to @dotey: 介绍 ChatGPT 团队计划
https://openai.com/blog/introducing-chatgpt-team

我们推出了一款适合各种规模团队的新 ChatGPT 计划。这个计划提供了一个安全的协作工作空间，帮助团队在工作中最大限度地利用 ChatGPT。

几个月前，我们推出了 ChatGPT 企业版。现在，像 Block、Canva、Carlyle、雅诗兰黛公司、PwC 和 Zapier 这样的行业领袖已经开始用它来革新他们的组织运作方式。今天，我们又增添了一项新服务：ChatGPT 团队计划。

ChatGPT 团队计划为用户提供了访问高级模型的权限，比如 GPT-4 和 DALL·E 3，以及高级数据分析等工具。此外，用户还可以得到一个专为团队设计的协作工作空间和一系列团队管理工具。和企业版一样，用户对其商业数据拥有完全控制权——我们不会利用您的商业数据或对话来训练我们的模型，这些模型也不会根据您的使用情况进行学习。关于数据隐私的更多细节，请参阅我们的隐私政策页面和信任门户。

ChatGPT 团队的主要功能包括：

- 访问配备了 32K 上下文窗口的 GPT-4
- 使用 DALL·E 3、GPT-4 视觉版、浏览功能和高级数据分析等工具，且具有更高的消息处理上限
- 不会利用您的商业数据或

对话进行模型训练

- 为您的团队提供安全的工作空间
- 在工作空间内创建和分享定制化的 GPT
- 提供工作空间和团队管理的管理员控制台
- 优先体验新功能和改进版本

立即行动

根据工作类型定制 ChatGPT

我们最近推出了 GPTs，这是一种可以根据具体用途定制的 ChatGPT 版本。它们配备了详细指南、扩展知识库和定制功能，对企业和团队尤为有用。通过 GPTs，您可以无需编程即可根据团队的具体需求和工作流程定制 ChatGPT，并安全地发布到团队工作空间。GPTs 可以帮助完成多种任务，比如项目管理协助、团队入职指导、代码生成、数据分析、在现有系统和工具中安全执行操作，或创建符合品牌调性和声音的市场宣传材料。我们今天还宣布了 GPT 商店的上线，您可以在其中找到工作空间内有用和受欢迎的 GPT。

提升团队效率和工作质量

将 AI 融入日常组织工作流程可以显著提高团队的生产力。根据哈佛商学院最近的一项研究，波士顿咨询集团的员工在获得 GPT-4 使用权限后，完成任务的速度提高了 25%，工作质量比未获得权限的同事高出 40%。[1]
Sourcegraph 的 GTM 战略与运营副总裁 Connor O'Brien 分享他的体验：“我们几乎在业务的每个环节都使用了 ChatGPT，从财务建模的定价和包装，到内外部沟通，再到董事会准备、招聘和记录笔记——这些都极大地加快了我们的工作效率，让我们能够在高水平上快速执行。”

波士顿儿童医院的首席创新官 John Brownstein 博士也谈到了他的体验：“通过使用 ChatGPT 团队版，我们得以试验创新的 GPT，增强了团队的生产力和协作能力。随着我们安全、负责任地将 GPT 整合进内部运营，我们相信这将极大地强化我们的系统，帮助医生、研究人员、学生和行政人员为每一位患者提供卓越的医疗服务。”

ChatGPT 团队版的费用为每用户每月 25 美元（年付），或每用户每月 30 美元（月付）。您可以在 ChatGPT 的设置中查看更多详情或立即开始使用。</title>
            <link>https://nitter.cz/dotey/status/1745176249071267997#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1745176249071267997#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 20:10:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>介绍 ChatGPT 团队计划<br />
<a href="https://openai.com/blog/introducing-chatgpt-team">openai.com/blog/introducing-…</a><br />
<br />
我们推出了一款适合各种规模团队的新 ChatGPT 计划。这个计划提供了一个安全的协作工作空间，帮助团队在工作中最大限度地利用 ChatGPT。<br />
<br />
几个月前，我们推出了 ChatGPT 企业版。现在，像 Block、Canva、Carlyle、雅诗兰黛公司、PwC 和 Zapier 这样的行业领袖已经开始用它来革新他们的组织运作方式。今天，我们又增添了一项新服务：ChatGPT 团队计划。<br />
<br />
ChatGPT 团队计划为用户提供了访问高级模型的权限，比如 GPT-4 和 DALL·E 3，以及高级数据分析等工具。此外，用户还可以得到一个专为团队设计的协作工作空间和一系列团队管理工具。和企业版一样，用户对其商业数据拥有完全控制权——我们不会利用您的商业数据或对话来训练我们的模型，这些模型也不会根据您的使用情况进行学习。关于数据隐私的更多细节，请参阅我们的隐私政策页面和信任门户。<br />
<br />
ChatGPT 团队的主要功能包括：<br />
<br />
- 访问配备了 32K 上下文窗口的 GPT-4<br />
- 使用 DALL·E 3、GPT-4 视觉版、浏览功能和高级数据分析等工具，且具有更高的消息处理上限<br />
- 不会利用您的商业数据或<br />
<br />
对话进行模型训练<br />
<br />
- 为您的团队提供安全的工作空间<br />
- 在工作空间内创建和分享定制化的 GPT<br />
- 提供工作空间和团队管理的管理员控制台<br />
- 优先体验新功能和改进版本<br />
<br />
立即行动<br />
<br />
根据工作类型定制 ChatGPT<br />
<br />
我们最近推出了 GPTs，这是一种可以根据具体用途定制的 ChatGPT 版本。它们配备了详细指南、扩展知识库和定制功能，对企业和团队尤为有用。通过 GPTs，您可以无需编程即可根据团队的具体需求和工作流程定制 ChatGPT，并安全地发布到团队工作空间。GPTs 可以帮助完成多种任务，比如项目管理协助、团队入职指导、代码生成、数据分析、在现有系统和工具中安全执行操作，或创建符合品牌调性和声音的市场宣传材料。我们今天还宣布了 GPT 商店的上线，您可以在其中找到工作空间内有用和受欢迎的 GPT。<br />
<br />
提升团队效率和工作质量<br />
<br />
将 AI 融入日常组织工作流程可以显著提高团队的生产力。根据哈佛商学院最近的一项研究，波士顿咨询集团的员工在获得 GPT-4 使用权限后，完成任务的速度提高了 25%，工作质量比未获得权限的同事高出 40%。[1]<br />
Sourcegraph 的 GTM 战略与运营副总裁 Connor O'Brien 分享他的体验：“我们几乎在业务的每个环节都使用了 ChatGPT，从财务建模的定价和包装，到内外部沟通，再到董事会准备、招聘和记录笔记——这些都极大地加快了我们的工作效率，让我们能够在高水平上快速执行。”<br />
<br />
波士顿儿童医院的首席创新官 John Brownstein 博士也谈到了他的体验：“通过使用 ChatGPT 团队版，我们得以试验创新的 GPT，增强了团队的生产力和协作能力。随着我们安全、负责任地将 GPT 整合进内部运营，我们相信这将极大地强化我们的系统，帮助医生、研究人员、学生和行政人员为每一位患者提供卓越的医疗服务。”<br />
<br />
ChatGPT 团队版的费用为每用户每月 25 美元（年付），或每用户每月 30 美元（月付）。您可以在 ChatGPT 的设置中查看更多详情或立即开始使用。</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0NTEzNjg2MTkyMjkzMDY4OS96aUwwWXVIQT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1745167408984191066#m</id>
            <title>R to @dotey: 如果是月付是 $30，年付才是 $25</title>
            <link>https://nitter.cz/dotey/status/1745167408984191066#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1745167408984191066#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 19:35:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果是月付是 $30，年付才是 $25</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RnVWNvQ1hRQUFrb2U0LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1745161757516030270#m</id>
            <title>ChatGPT 推出了 Team 版，每月 $25 每人，最少需要2个人一起，更高的消息条数上限，可以创建只针对你 Team 的 GPTs。

https://openai.com/blog/introducing-chatgpt-team</title>
            <link>https://nitter.cz/dotey/status/1745161757516030270#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1745161757516030270#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 19:12:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT 推出了 Team 版，每月 $25 每人，最少需要2个人一起，更高的消息条数上限，可以创建只针对你 Team 的 GPTs。<br />
<br />
<a href="https://openai.com/blog/introducing-chatgpt-team">openai.com/blog/introducing-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RnUEk4RlhZQUFQWkZpLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1745160456220635204#m</id>
            <title>OpenAI 已经正式发布了 GPT 商店 http://chat.openai.com/gpts ，通过侧边栏就可以访问，目前还比较简单。

目前还没正式公布如何让开发者获得报酬，看起来是直接根据用户使用 GPT 的情况来分成

以下内容翻译自官方公告 https://openai.com/blog/introducing-the-gpt-store  ：

我们刚刚推出了 GPT 商店，旨在帮助您发现实用且广受欢迎的 ChatGPT 定制版本。

自从两个月前我们宣布 GPTs 的推出以来，用户们已经创建了超过 300 万个 ChatGPT 的定制版本。许多开发者将他们的 GPTs 分享给其他用户。现在，我们正将 GPT 商店推向 ChatGPT Plus、Team 和 Enterprise 用户，让您能够轻松找到实用且广受欢迎的 GPTs。欢迎访问 http://chat.openai.com/gpts 探索更多。

探索商店中的热门趋势

商店内展示了众多由我们的合作伙伴和社区开发的 GPTs。您可以在社区排行榜上浏览各种受欢迎和流行的 GPTs，分类涵盖 DALL·E、写作、研究、编程、教育和生活方式等。

每周新推荐的 GPTs

我们还会重点推介一些实用且具有深远影响的 GPTs。首批推荐的 GPTs 包括：

- 通过 AllTrails 获得个性化的徒步路线推荐
- 使用 Consensus 搜索和汇总 200M 学术论文的结果
- 通过 Khan Academy 的 Code Tutor 提升编程技能
- 利用 Canva 设计演示文稿或社交媒体帖子
- 使用 Books 发现您的下一本书
- 随时随地通过 CK-12 Flexi AI 导师学习数学和科学

将您的 GPT 加入商店

自己构建 GPT 既简单又无需任何编程技能。

如果您想将 GPT 分享到商店中，您需要做以下几步：

- 将您的 GPT 设为“所有人可用”（仅有链接的人无法在商店中看到）。
- 验证您的开发者资料（路径为设置 → 开发者资料 → 启用您的姓名或经过验证的网站）。

请务必查看我们最新的使用政策和 GPT 品牌指南，确保您的 GPT 符合要求。为了保证 GPTs 遵守我们的政策，我们除了在产品中已经实施的安全措施外，还建立了一个新的审查系统。该审查过程包括人工和自动审查，用户也可以举报不合规的 GPTs。

开发者可根据 GPT 使用情况获得收入

我们计划在第一季度启动 GPT 开发者收入计划。作为首步，美国的开发者将根据用户对他们 GPTs 的参与度获得报酬。我们将在接近启动时间时提供详细的支付标准。

Team 和 企业客户可以管理 GPTs

我们今天宣布了适用于各种规模团队的新 ChatGPT Team 计划。Team 客户可以访问 GPT 商店的专属区域，其中包含安全发布到您工作空间的 GPTs。GPT 商店很快也将向 ChatGPT Enterprise 客户开放，并将提供更多管理员控制功能，如选择共享内部 GPTs 的方式以及决定哪些外部 GPTs 可以在企业内使用。和所有在 ChatGPT Team 和 企业上的使用一样，我们不会利用您与 GPTs 的会话记录来改进我们的模型。

想要探索更多 GPTs，请访问 http://chat.openai.com/gpts。</title>
            <link>https://nitter.cz/dotey/status/1745160456220635204#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1745160456220635204#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 19:07:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 已经正式发布了 GPT 商店 <a href="http://chat.openai.com/gpts">chat.openai.com/gpts</a> ，通过侧边栏就可以访问，目前还比较简单。<br />
<br />
目前还没正式公布如何让开发者获得报酬，看起来是直接根据用户使用 GPT 的情况来分成<br />
<br />
以下内容翻译自官方公告 <a href="https://openai.com/blog/introducing-the-gpt-store">openai.com/blog/introducing-…</a>  ：<br />
<br />
我们刚刚推出了 GPT 商店，旨在帮助您发现实用且广受欢迎的 ChatGPT 定制版本。<br />
<br />
自从两个月前我们宣布 GPTs 的推出以来，用户们已经创建了超过 300 万个 ChatGPT 的定制版本。许多开发者将他们的 GPTs 分享给其他用户。现在，我们正将 GPT 商店推向 ChatGPT Plus、Team 和 Enterprise 用户，让您能够轻松找到实用且广受欢迎的 GPTs。欢迎访问 <a href="http://chat.openai.com/gpts">chat.openai.com/gpts</a> 探索更多。<br />
<br />
探索商店中的热门趋势<br />
<br />
商店内展示了众多由我们的合作伙伴和社区开发的 GPTs。您可以在社区排行榜上浏览各种受欢迎和流行的 GPTs，分类涵盖 DALL·E、写作、研究、编程、教育和生活方式等。<br />
<br />
每周新推荐的 GPTs<br />
<br />
我们还会重点推介一些实用且具有深远影响的 GPTs。首批推荐的 GPTs 包括：<br />
<br />
- 通过 AllTrails 获得个性化的徒步路线推荐<br />
- 使用 Consensus 搜索和汇总 200M 学术论文的结果<br />
- 通过 Khan Academy 的 Code Tutor 提升编程技能<br />
- 利用 Canva 设计演示文稿或社交媒体帖子<br />
- 使用 Books 发现您的下一本书<br />
- 随时随地通过 CK-12 Flexi AI 导师学习数学和科学<br />
<br />
将您的 GPT 加入商店<br />
<br />
自己构建 GPT 既简单又无需任何编程技能。<br />
<br />
如果您想将 GPT 分享到商店中，您需要做以下几步：<br />
<br />
- 将您的 GPT 设为“所有人可用”（仅有链接的人无法在商店中看到）。<br />
- 验证您的开发者资料（路径为设置 → 开发者资料 → 启用您的姓名或经过验证的网站）。<br />
<br />
请务必查看我们最新的使用政策和 GPT 品牌指南，确保您的 GPT 符合要求。为了保证 GPTs 遵守我们的政策，我们除了在产品中已经实施的安全措施外，还建立了一个新的审查系统。该审查过程包括人工和自动审查，用户也可以举报不合规的 GPTs。<br />
<br />
开发者可根据 GPT 使用情况获得收入<br />
<br />
我们计划在第一季度启动 GPT 开发者收入计划。作为首步，美国的开发者将根据用户对他们 GPTs 的参与度获得报酬。我们将在接近启动时间时提供详细的支付标准。<br />
<br />
Team 和 企业客户可以管理 GPTs<br />
<br />
我们今天宣布了适用于各种规模团队的新 ChatGPT Team 计划。Team 客户可以访问 GPT 商店的专属区域，其中包含安全发布到您工作空间的 GPTs。GPT 商店很快也将向 ChatGPT Enterprise 客户开放，并将提供更多管理员控制功能，如选择共享内部 GPTs 的方式以及决定哪些外部 GPTs 可以在企业内使用。和所有在 ChatGPT Team 和 企业上的使用一样，我们不会利用您与 GPTs 的会话记录来改进我们的模型。<br />
<br />
想要探索更多 GPTs，请访问 <a href="http://chat.openai.com/gpts">chat.openai.com/gpts</a>。</p>
<p><a href="https://nitter.cz/OpenAI/status/1745141391934828696#m">nitter.cz/OpenAI/status/1745141391934828696#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0NTEzNDUxMDAyOTg3NzI0OC9YaWZpWGdVbj9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744980335182377156#m</id>
            <title>我发现大家对于 ChatGPT 在文档对话支持方面的能力都普遍认为比较差，这篇分析相对比较靠谱：
1. OCR 能力不行，OCR 能力不行那从源头上的文字的输入就是有问题的，后续的召回和对话肯定好不了
2.上下文长度不够长，如果长度不够那么一次输入的信息就不够长，导致输出不够好
3. RAG 本身就是很复杂的技术，即使如 OpenAI 也不是那么多容易做好的

以下内容翻译自原推：
***

与 PDF 对话之难，及 ChatGPT 在此领域的不足 - 原因分析

目前最普遍的 GPT-4 应用之一是“文档/PDF 对话”功能。这被认为是 AI 聊天机器人的一项杀手级应用，因为要读懂内容繁多的文件是很烦人的事 —— 相比之下，直接让大语言模型帮你解析并总结内容显得更加简便。

然而，遗憾的是，当处理超过 10 页的 PDF 文件时，ChatGPT 的表现并不尽如人意。它所提供的总结往往过于简略且笼统，甚至在被要求提供更多细节时会直接拒绝。

造成这一问题的原因之一是，这不是一个简单的应用场景。

OCR - 有效的 OCR 技术是必需的，它需要能够精确解析表格和图像。但目前无论是免费的还是商业的 OCR 技术都难以做到这一点。大量商业和研究用的 PDF 文件中含有众多表格和图像。

上下文 - 尽管我们现在有 128K 上下文长度的大语言模型，但目前尚不清楚 ChatGPT 实际部署了哪种模型。如果你对一篇论文进行 OCR 处理后再输入其文本给 ChatGPT，它经常会出现错误。我怀疑 ChatGPT 服务的是一个上下文长度更小的模型。

快速 RAG - 实施一个简单的 RAG 处理流程，即将文档分块、嵌入、检索结果后再传递给大语言模型，可能是一个有效的解决方法。但目前的聊天机器人尚未具备这样的功能。

突出文档关键部分 - 理想的解决方案应当能够明确展示出答案来源于文档的哪些部分。这将极大地简化验证过程。

理想情况下，与 PDF 对话的功能应包含以上所有特点。似乎，如果一款独立的应用程序能够很好地实现这些功能，即使在应用商店中也能获得可观的收入。不过，我认为这并不适合作为一个获得风险投资支持的创业项目，更像是一个一两人小团队可以经营的小本生意，足以成为一种舒适的生活方式。

简言之，实现一个看似简单的“与 PDF 对话”功能，其实是一个复杂且难以做到极致的任务。</title>
            <link>https://nitter.cz/dotey/status/1744980335182377156#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744980335182377156#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 07:11:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我发现大家对于 ChatGPT 在文档对话支持方面的能力都普遍认为比较差，这篇分析相对比较靠谱：<br />
1. OCR 能力不行，OCR 能力不行那从源头上的文字的输入就是有问题的，后续的召回和对话肯定好不了<br />
2.上下文长度不够长，如果长度不够那么一次输入的信息就不够长，导致输出不够好<br />
3. RAG 本身就是很复杂的技术，即使如 OpenAI 也不是那么多容易做好的<br />
<br />
以下内容翻译自原推：<br />
***<br />
<br />
与 PDF 对话之难，及 ChatGPT 在此领域的不足 - 原因分析<br />
<br />
目前最普遍的 GPT-4 应用之一是“文档/PDF 对话”功能。这被认为是 AI 聊天机器人的一项杀手级应用，因为要读懂内容繁多的文件是很烦人的事 —— 相比之下，直接让大语言模型帮你解析并总结内容显得更加简便。<br />
<br />
然而，遗憾的是，当处理超过 10 页的 PDF 文件时，ChatGPT 的表现并不尽如人意。它所提供的总结往往过于简略且笼统，甚至在被要求提供更多细节时会直接拒绝。<br />
<br />
造成这一问题的原因之一是，这不是一个简单的应用场景。<br />
<br />
OCR - 有效的 OCR 技术是必需的，它需要能够精确解析表格和图像。但目前无论是免费的还是商业的 OCR 技术都难以做到这一点。大量商业和研究用的 PDF 文件中含有众多表格和图像。<br />
<br />
上下文 - 尽管我们现在有 128K 上下文长度的大语言模型，但目前尚不清楚 ChatGPT 实际部署了哪种模型。如果你对一篇论文进行 OCR 处理后再输入其文本给 ChatGPT，它经常会出现错误。我怀疑 ChatGPT 服务的是一个上下文长度更小的模型。<br />
<br />
快速 RAG - 实施一个简单的 RAG 处理流程，即将文档分块、嵌入、检索结果后再传递给大语言模型，可能是一个有效的解决方法。但目前的聊天机器人尚未具备这样的功能。<br />
<br />
突出文档关键部分 - 理想的解决方案应当能够明确展示出答案来源于文档的哪些部分。这将极大地简化验证过程。<br />
<br />
理想情况下，与 PDF 对话的功能应包含以上所有特点。似乎，如果一款独立的应用程序能够很好地实现这些功能，即使在应用商店中也能获得可观的收入。不过，我认为这并不适合作为一个获得风险投资支持的创业项目，更像是一个一两人小团队可以经营的小本生意，足以成为一种舒适的生活方式。<br />
<br />
简言之，实现一个看似简单的“与 PDF 对话”功能，其实是一个复杂且难以做到极致的任务。</p>
<p><a href="https://nitter.cz/bindureddy/status/1744894481999278291#m">nitter.cz/bindureddy/status/1744894481999278291#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744974492764364863#m</id>
            <title>Rabbit R1：一款能代替你使用应用的 AI 小工具

这款售价199美元、由“大动作模型”驱动的 R1 不仅是个聊天机器人，它还能做几乎所有事情，潜力巨大。

Rabbit R1 不是手机，但也不能简单地认为它不是手机。

AI 创业公司 Rabbit 的 CEO 兼创始人 Jesse Lyu 表示，他并不打算立刻取代你的智能手机。他的公司推出了一款新型独立 AI 设备 R1，售价199美元，其雄心勃勃到了令人震惊的程度。Lyu 似乎相信，R1 迟早会取代你的手机，只是时机尚未成熟。

R1 的外形有点类似 Playdate 控制台 或是一种现代版的90年代手持电视。它体积大约是 iPhone 的一半，配备了2.88英寸触摸屏、可旋转摄像头（用于拍照和视频）以及一个滚轮/按钮，用于导航或与设备内置助手交流。其配备2.3GHz MediaTek处理器、4GB内存和128GB存储空间，这一切都被封装在一个由 Teenage Engineering 设计公司合作设计的圆润机身中。Rabbit 只透露电池可以持续“一整天”。

在 Rabbit 的发布会后，我短暂体验了 R1。这是一款令人印象深刻的硬件。在场的设备（仅Lyu的那台）是真正能工作的，但由于酒店 Wi-Fi 信号不佳，其功能受限。R1 意外地轻便，手感比照片中看上去要好。它的按钮触感出色，这对 Teenage Engineering 来说并不意外，整体握持感很好。不过，它容易留下指纹。

R1 的真正亮点在于其内部软件：Rabbit OS操作系统和底层的 AI 技术。Rabbit 表示，与其说 Rabbit OS 是基于类似 ChatGPT 的大语言模型，不如说它是基于“大动作模型”。这可以被看作是一种万能的应用程序控制器。“我们想要找到一个像大语言模型那样的通用解决方案，”Lyu 说。“如何找到一个真正能触发我们服务的通用方案，无论是网站、应用程序还是其他平台？”

从概念上讲，这与 Alexa 或 Google Assistant 相似。Rabbit OS 能控制音乐、预订车辆、购买杂货、发送消息等，全部通过一个界面实现。无需切换应用程序和登录，只需说出你的需求，让设备为你服务。R1 的界面将显示一系列基于类别的卡片，如音乐、交通或视频聊天等，Lyu 说这主要是为了让用户能够亲自确认模型的反馈。

Rabbit 没有创建大量的 API 去说服开发者支持 R1，而是训练其模型自己使用现有应用。这个大动作模型，或 LAM，是通过人类与 Spotify 和 Uber 等应用的互动训练出来的，基本上是向模型展示它们是如何运作的。LAM 学会了识别设置图标、确认订单的时机以及搜索菜单的位置。Lyu 说，这一切都可以应用到任何应用程序上。

R1 还具有一个专用的训练模式，你可以通过它教授设备如何执行特定操作，然后它就能自动重复这一操作。例如，Lyu 描述了一个如何去除水印的教学过程。“你会说，'首先，打开 Photoshop。打开它，然后拿起你的照片，在水印上做个套索，然后点击几下。这就是去除水印的方法。'”Rabbit OS 处理需要30秒，之后它就能自动去除所有水印。

然而，R1 在实际应用中如何运作仍是个未知数。你可以在 R1 本身完成一些操作，并通过一个名为 Rabbit Hole 的网络门户登录到各种服务。如果你想教设备如何使用 Photoshop，你可以启动 Rabbit 的一台虚拟机进行教学，而无需使用你自己的设备和软件。但如何在众多用户、多种设备和平台上实现这一功能，仍然是一个挑战。

ChatGPT 对网络搜索的影响可能与 Rabbit OS 对应用商店的影响相似。Rabbit 采取的方法颇具创新。即使你是科技巨头，让人们支持一个新操作系统也是艰难的，而通过教授模型如何使用应用程序，LAM 方法规避了这一点。更广泛地说，我们正在见证越来越多的 AI 驱动硬件 进入市场，但这些设备通常只是连接到一个聊天机器人。相比之下，Rabbit 更像是一个超级应用——一个可以通过它完成几乎任何事情的单一界面。ChatGPT 可能是网络搜索的未来，而 Rabbit OS 可能是应用商店的未来。当然，实现这个梦想伴随着许多复杂性和挑战，但它是一个令人着迷的愿景。

不过，听 Lyu 谈论 Rabbit OS 和 R1，公司对这个设备的具体愿景似乎还不完全清晰。尽管它可以进行视频通话，并且配备了 SIM 卡插槽，但它还不足以完全取代你的手机。它主要是一个语音助手，但同时配备了屏幕和摄像头。它不仅仅是一个语音助手，但它确实执行了很多语音助手的功能。Rabbit 表示，他们在设计 Rabbit OS 时考虑到了安全性和隐私性，但同时也需要用户通过其界面登录到他们最常用的服务。在 Lyu 看来，R1 既是一个实用的配件，也是几乎所有事物的一体化未来。

R1 目前已开放预订，Lyu 表示该设备将于3月开始发货。他甚至希望能比 Humane 的 AI Pin 更早上市。

新闻来源：https://www.theverge.com/2024/1/9/24030667/rabbit-r1-ai-action-model-price-release-date
Rabbit R1 官网：https://www.rabbit.tech/</title>
            <link>https://nitter.cz/dotey/status/1744974492764364863#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744974492764364863#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 06:48:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Rabbit R1：一款能代替你使用应用的 AI 小工具<br />
<br />
这款售价199美元、由“大动作模型”驱动的 R1 不仅是个聊天机器人，它还能做几乎所有事情，潜力巨大。<br />
<br />
Rabbit R1 不是手机，但也不能简单地认为它不是手机。<br />
<br />
AI 创业公司 Rabbit 的 CEO 兼创始人 Jesse Lyu 表示，他并不打算立刻取代你的智能手机。他的公司推出了一款新型独立 AI 设备 R1，售价199美元，其雄心勃勃到了令人震惊的程度。Lyu 似乎相信，R1 迟早会取代你的手机，只是时机尚未成熟。<br />
<br />
R1 的外形有点类似 Playdate 控制台 或是一种现代版的90年代手持电视。它体积大约是 iPhone 的一半，配备了2.88英寸触摸屏、可旋转摄像头（用于拍照和视频）以及一个滚轮/按钮，用于导航或与设备内置助手交流。其配备2.3GHz MediaTek处理器、4GB内存和128GB存储空间，这一切都被封装在一个由 Teenage Engineering 设计公司合作设计的圆润机身中。Rabbit 只透露电池可以持续“一整天”。<br />
<br />
在 Rabbit 的发布会后，我短暂体验了 R1。这是一款令人印象深刻的硬件。在场的设备（仅Lyu的那台）是真正能工作的，但由于酒店 Wi-Fi 信号不佳，其功能受限。R1 意外地轻便，手感比照片中看上去要好。它的按钮触感出色，这对 Teenage Engineering 来说并不意外，整体握持感很好。不过，它容易留下指纹。<br />
<br />
R1 的真正亮点在于其内部软件：Rabbit OS操作系统和底层的 AI 技术。Rabbit 表示，与其说 Rabbit OS 是基于类似 ChatGPT 的大语言模型，不如说它是基于“大动作模型”。这可以被看作是一种万能的应用程序控制器。“我们想要找到一个像大语言模型那样的通用解决方案，”Lyu 说。“如何找到一个真正能触发我们服务的通用方案，无论是网站、应用程序还是其他平台？”<br />
<br />
从概念上讲，这与 Alexa 或 Google Assistant 相似。Rabbit OS 能控制音乐、预订车辆、购买杂货、发送消息等，全部通过一个界面实现。无需切换应用程序和登录，只需说出你的需求，让设备为你服务。R1 的界面将显示一系列基于类别的卡片，如音乐、交通或视频聊天等，Lyu 说这主要是为了让用户能够亲自确认模型的反馈。<br />
<br />
Rabbit 没有创建大量的 API 去说服开发者支持 R1，而是训练其模型自己使用现有应用。这个大动作模型，或 LAM，是通过人类与 Spotify 和 Uber 等应用的互动训练出来的，基本上是向模型展示它们是如何运作的。LAM 学会了识别设置图标、确认订单的时机以及搜索菜单的位置。Lyu 说，这一切都可以应用到任何应用程序上。<br />
<br />
R1 还具有一个专用的训练模式，你可以通过它教授设备如何执行特定操作，然后它就能自动重复这一操作。例如，Lyu 描述了一个如何去除水印的教学过程。“你会说，'首先，打开 Photoshop。打开它，然后拿起你的照片，在水印上做个套索，然后点击几下。这就是去除水印的方法。'”Rabbit OS 处理需要30秒，之后它就能自动去除所有水印。<br />
<br />
然而，R1 在实际应用中如何运作仍是个未知数。你可以在 R1 本身完成一些操作，并通过一个名为 Rabbit Hole 的网络门户登录到各种服务。如果你想教设备如何使用 Photoshop，你可以启动 Rabbit 的一台虚拟机进行教学，而无需使用你自己的设备和软件。但如何在众多用户、多种设备和平台上实现这一功能，仍然是一个挑战。<br />
<br />
ChatGPT 对网络搜索的影响可能与 Rabbit OS 对应用商店的影响相似。Rabbit 采取的方法颇具创新。即使你是科技巨头，让人们支持一个新操作系统也是艰难的，而通过教授模型如何使用应用程序，LAM 方法规避了这一点。更广泛地说，我们正在见证越来越多的 AI 驱动硬件 进入市场，但这些设备通常只是连接到一个聊天机器人。相比之下，Rabbit 更像是一个超级应用——一个可以通过它完成几乎任何事情的单一界面。ChatGPT 可能是网络搜索的未来，而 Rabbit OS 可能是应用商店的未来。当然，实现这个梦想伴随着许多复杂性和挑战，但它是一个令人着迷的愿景。<br />
<br />
不过，听 Lyu 谈论 Rabbit OS 和 R1，公司对这个设备的具体愿景似乎还不完全清晰。尽管它可以进行视频通话，并且配备了 SIM 卡插槽，但它还不足以完全取代你的手机。它主要是一个语音助手，但同时配备了屏幕和摄像头。它不仅仅是一个语音助手，但它确实执行了很多语音助手的功能。Rabbit 表示，他们在设计 Rabbit OS 时考虑到了安全性和隐私性，但同时也需要用户通过其界面登录到他们最常用的服务。在 Lyu 看来，R1 既是一个实用的配件，也是几乎所有事物的一体化未来。<br />
<br />
R1 目前已开放预订，Lyu 表示该设备将于3月开始发货。他甚至希望能比 Humane 的 AI Pin 更早上市。<br />
<br />
新闻来源：<a href="https://www.theverge.com/2024/1/9/24030667/rabbit-r1-ai-action-model-price-release-date">theverge.com/2024/1/9/240306…</a><br />
Rabbit R1 官网：<a href="https://www.rabbit.tech/">rabbit.tech/</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1744902062306099206#m">nitter.cz/xiaohuggg/status/1744902062306099206#m</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0OTczOTUxMzg4Nzk0ODgwL2ltZy9IT3M2eDlvUU5IMXNZLWFKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744921720073728186#m</id>
            <title>RT by @dotey: Phi 2专家混合模型

它是结合了2 到4 个微调的microsoft/phi-2模型的专家混合体（Mixture of Experts, MoE）

灵感来源于mistralai/Mixtral-8x7B-v0.1架构。性能优于每个专家模型。

🤗 phixtral-2x2_8： https://huggingface.co/mlabonne/phixtral-2x2_8

🤗 phixtral-4x2_8：https://huggingface.co/mlabonne/phixtral-4x2_8</title>
            <link>https://nitter.cz/xiaohuggg/status/1744921720073728186#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744921720073728186#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 03:18:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Phi 2专家混合模型<br />
<br />
它是结合了2 到4 个微调的microsoft/phi-2模型的专家混合体（Mixture of Experts, MoE）<br />
<br />
灵感来源于mistralai/Mixtral-8x7B-v0.1架构。性能优于每个专家模型。<br />
<br />
🤗 phixtral-2x2_8： <a href="https://huggingface.co/mlabonne/phixtral-2x2_8">huggingface.co/mlabonne/phix…</a><br />
<br />
🤗 phixtral-4x2_8：<a href="https://huggingface.co/mlabonne/phixtral-4x2_8">huggingface.co/mlabonne/phix…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1734778292157444479#m">nitter.cz/xiaohuggg/status/1734778292157444479#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744934002367062288#m</id>
            <title>来自字节跳动的文字生成视频技术MagicVideo-V2：多级高美感视频生成器

论文摘要
对于从文字描述生成高质量视频的需求日益增长，推动了该领域的相关重要研究。在这项工作中，我们推出了"MagicVideo-V2"，这是一个全程无缝的视频生成流程，它融合了各种技术模块，包括将文字转化为图像的技术、视频运动创建工具、可供参考的图像嵌入模块，以及帧间补充模块。得益于这些设计，"MagicVideo-V2"能够生成既美观又高分辨率的视频，且画质逼真且播放流畅。在大规模用户评估中，"MagicVideo-V2"的表现优于其他领先的文字转视频系统，如Runway、Pika 1.0、Morph、Moon Valley以及Stable Video Diffusion模型。

论文地址：https://arxiv.org/abs/2401.04468
项目网站：https://magicvideov2.github.io/</title>
            <link>https://nitter.cz/dotey/status/1744934002367062288#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744934002367062288#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 04:07:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自字节跳动的文字生成视频技术MagicVideo-V2：多级高美感视频生成器<br />
<br />
论文摘要<br />
对于从文字描述生成高质量视频的需求日益增长，推动了该领域的相关重要研究。在这项工作中，我们推出了"MagicVideo-V2"，这是一个全程无缝的视频生成流程，它融合了各种技术模块，包括将文字转化为图像的技术、视频运动创建工具、可供参考的图像嵌入模块，以及帧间补充模块。得益于这些设计，"MagicVideo-V2"能够生成既美观又高分辨率的视频，且画质逼真且播放流畅。在大规模用户评估中，"MagicVideo-V2"的表现优于其他领先的文字转视频系统，如Runway、Pika 1.0、Morph、Moon Valley以及Stable Video Diffusion模型。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2401.04468">arxiv.org/abs/2401.04468</a><br />
项目网站：<a href="https://magicvideov2.github.io/">magicvideov2.github.io/</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1744914502703874215#m">nitter.cz/_akhaliq/status/1744914502703874215#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744923217733566943#m</id>
            <title>这个功能好👍</title>
            <link>https://nitter.cz/dotey/status/1744923217733566943#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744923217733566943#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 03:24:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个功能好👍</p>
<p><a href="https://nitter.cz/njukidreborn/status/1744827824094224634#m">nitter.cz/njukidreborn/status/1744827824094224634#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744905292683391463#m</id>
            <title>来自JimFan的揭秘：

Mobile ALOHA 的“遥控操作”系统其实就是一种高级的“远程控制”技术。未来，训练机器人的过程将越来越像是在真实世界中玩游戏。操作者通过一个先进的操纵杆来执行任务和收集数据，必要时还能介入处理安全问题。掌握这种控制器的技巧，就像练习游戏技能一样，需要一段时间的学习。

遥控操作可以有多种实现方式。ALOHA 就是一个成本极低的自主定制系统。这里有几种其他的选择：

动作捕捉（MoCap）：利用好莱坞电影中的 MoCap 系统来捕捉手部关节的细微动作。如果机器人的手也有 5 个手指，就能完美复现人类的动作。例如，操作者可以戴上 CyberGlove（ http://cyberglovesystems.com ）来操控物体。CyberGlove 能实时捕获动作信号和触觉反馈，并将其传输到仿人机器人上。

传统的动作捕捉可能需要穿戴笨重的手套和标记，但有了计算机视觉技术，就可以更自然地进行。NVIDIA 开发的 DexPilot 项目实现了无需标记和手套的数据收集。操作者只需用裸手执行任务，4 个 Intel RealSense 深度摄像头和 2 个 NVIDIA Titan XP GPU（基于 2019 年的技术）会将这些动作转化为精确的运动信号，用于机器人学习。详情请见相关论文（arXiv:1910.03135）：https://arxiv.org/abs/1910.03135

VR 头盔：可以将训练空间变成一个 VR 游戏场景，操作者在其中扮演机器人的角色。这种方式的一个优点是能进行大规模的远程数据收集——全球的贡献者可以在不必亲自到现场的情况下参与项目。例如，我参与的斯坦福大学的 iGibson 家用机器人模拟器项目，就采用了这种 VR 演示技术。详细信息可参考斯坦福虚拟实验室网站。https://svl.stanford.edu/igibson/</title>
            <link>https://nitter.cz/dotey/status/1744905292683391463#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744905292683391463#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:13:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自JimFan的揭秘：<br />
<br />
Mobile ALOHA 的“遥控操作”系统其实就是一种高级的“远程控制”技术。未来，训练机器人的过程将越来越像是在真实世界中玩游戏。操作者通过一个先进的操纵杆来执行任务和收集数据，必要时还能介入处理安全问题。掌握这种控制器的技巧，就像练习游戏技能一样，需要一段时间的学习。<br />
<br />
遥控操作可以有多种实现方式。ALOHA 就是一个成本极低的自主定制系统。这里有几种其他的选择：<br />
<br />
动作捕捉（MoCap）：利用好莱坞电影中的 MoCap 系统来捕捉手部关节的细微动作。如果机器人的手也有 5 个手指，就能完美复现人类的动作。例如，操作者可以戴上 CyberGlove（ <a href="http://cyberglovesystems.com">cyberglovesystems.com</a> ）来操控物体。CyberGlove 能实时捕获动作信号和触觉反馈，并将其传输到仿人机器人上。<br />
<br />
传统的动作捕捉可能需要穿戴笨重的手套和标记，但有了计算机视觉技术，就可以更自然地进行。NVIDIA 开发的 DexPilot 项目实现了无需标记和手套的数据收集。操作者只需用裸手执行任务，4 个 Intel RealSense 深度摄像头和 2 个 NVIDIA Titan XP GPU（基于 2019 年的技术）会将这些动作转化为精确的运动信号，用于机器人学习。详情请见相关论文（arXiv:1910.03135）：<a href="https://arxiv.org/abs/1910.03135">arxiv.org/abs/1910.03135</a><br />
<br />
VR 头盔：可以将训练空间变成一个 VR 游戏场景，操作者在其中扮演机器人的角色。这种方式的一个优点是能进行大规模的远程数据收集——全球的贡献者可以在不必亲自到现场的情况下参与项目。例如，我参与的斯坦福大学的 iGibson 家用机器人模拟器项目，就采用了这种 VR 演示技术。详细信息可参考斯坦福虚拟实验室网站。<a href="https://svl.stanford.edu/igibson/">svl.stanford.edu/igibson/</a></p>
<p><a href="https://nitter.cz/DrJimFan/status/1744786506810900679#m">nitter.cz/DrJimFan/status/1744786506810900679#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744623826510741764#m</id>
            <title>RT by @dotey: 阿里巴巴又整活了！

FaceChain-FACT：无需训练，上传你的照片克隆你自己🤓

你只需要上传一张照片，它就能提取你的面部特征，然后结合不同的风格模板，生成具有你个人特征的虚拟AI肖像。

可以实现让你在任意场景中或者生成各种风格、服装、个性化的你自己！

最牛P的是它可以运行在CPU上！达到秒级生成速度！

FaceChain-FACT的主要亮点：

1、支持零样本肖像生成。无需训练，上传照片即可！

2、训练模型时使用了数百万精美的人类肖像，确保生成肖像的真实性和质量。

3、提供100多种高级定制模板。

4、模型支持在CPU上运行，并实现秒级推理时间，生成速度极快！

5、兼容与ControlNet和LoRA插件，提供了更多的灵活性和创造空间。

技术原理：

现代面部定制在图像生成中面临挑战，尤其是因为人脸的高细节要求。

FaceChain通过训练一个LoRA模型，整合面部信息来生成定制化肖像。然而，由于需要训练用户的LoRA模型，FaceChain的流程分为训练和推理两个阶段，这增加了用户的成本。

因此，提出了一种无需面部LoRA模型训练的零样本版本，即FaceChain-FACT。此外，只需用户的单张照片，即可生成定制化肖像。与现有商业应用相比，生成速度提升了100倍，实现了秒级图像生成速度。

FaceChain-FACT整合了类似于Stable Diffusion的基于变换器的面部特征提取器，并使用了作为面部条件的密集细粒度特征，这些特征具有更好的角色再现能力。FaceChain-FACT与ControlNet和LoRA插件兼容，并支持即插即用。

方法：

该技术采用了一系列图像预处理方法，包括面部分割、裁剪和对齐、手部检测、面部质量筛选等，以筛选和获得训练数据集。

利用基于变换器的面部特征提取器提取特征，并利用倒数第二层的密集细粒度特征作为面部条件。

Stable Diffusion通过FACT-Adapter接收面部条件，并将其与文本嵌入结合，生成肖像图像。通过融合来自FaceChain的各种LoRA模型，可以生成多种风格的肖像。

项目及演示：https://facechain-fact.github.io/

GitHub：https://github.com/modelscope/facechain/tree/main/facechain_adapter（coming soon…）</title>
            <link>https://nitter.cz/xiaohuggg/status/1744623826510741764#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744623826510741764#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 07:35:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里巴巴又整活了！<br />
<br />
FaceChain-FACT：无需训练，上传你的照片克隆你自己🤓<br />
<br />
你只需要上传一张照片，它就能提取你的面部特征，然后结合不同的风格模板，生成具有你个人特征的虚拟AI肖像。<br />
<br />
可以实现让你在任意场景中或者生成各种风格、服装、个性化的你自己！<br />
<br />
最牛P的是它可以运行在CPU上！达到秒级生成速度！<br />
<br />
FaceChain-FACT的主要亮点：<br />
<br />
1、支持零样本肖像生成。无需训练，上传照片即可！<br />
<br />
2、训练模型时使用了数百万精美的人类肖像，确保生成肖像的真实性和质量。<br />
<br />
3、提供100多种高级定制模板。<br />
<br />
4、模型支持在CPU上运行，并实现秒级推理时间，生成速度极快！<br />
<br />
5、兼容与ControlNet和LoRA插件，提供了更多的灵活性和创造空间。<br />
<br />
技术原理：<br />
<br />
现代面部定制在图像生成中面临挑战，尤其是因为人脸的高细节要求。<br />
<br />
FaceChain通过训练一个LoRA模型，整合面部信息来生成定制化肖像。然而，由于需要训练用户的LoRA模型，FaceChain的流程分为训练和推理两个阶段，这增加了用户的成本。<br />
<br />
因此，提出了一种无需面部LoRA模型训练的零样本版本，即FaceChain-FACT。此外，只需用户的单张照片，即可生成定制化肖像。与现有商业应用相比，生成速度提升了100倍，实现了秒级图像生成速度。<br />
<br />
FaceChain-FACT整合了类似于Stable Diffusion的基于变换器的面部特征提取器，并使用了作为面部条件的密集细粒度特征，这些特征具有更好的角色再现能力。FaceChain-FACT与ControlNet和LoRA插件兼容，并支持即插即用。<br />
<br />
方法：<br />
<br />
该技术采用了一系列图像预处理方法，包括面部分割、裁剪和对齐、手部检测、面部质量筛选等，以筛选和获得训练数据集。<br />
<br />
利用基于变换器的面部特征提取器提取特征，并利用倒数第二层的密集细粒度特征作为面部条件。<br />
<br />
Stable Diffusion通过FACT-Adapter接收面部条件，并将其与文本嵌入结合，生成肖像图像。通过融合来自FaceChain的各种LoRA模型，可以生成多种风格的肖像。<br />
<br />
项目及演示：<a href="https://facechain-fact.github.io/">facechain-fact.github.io/</a><br />
<br />
GitHub：<a href="https://github.com/modelscope/facechain/tree/main/facechain_adapter">github.com/modelscope/facech…</a>（coming soon…）</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0NjIzNTUzNDQ4OTUxODA4L2ltZy9kbXVad0p5Z2JJeUhTMVJGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744784191370285161#m</id>
            <title>Go 语言之父 Rob Pike 写的长文：在 Go 语言 14 年的发展历史中，我们做得对的和不对的

基于他去年在悉尼 GopherConAU 会议上所做的闭幕演讲的内容整理补充而成，系统的总结回顾了 Go 的发展过程中的经验教训，例如 Go 语言中并发、接口的设计；Go 语言作为一个开源项目是如何进行项目管理的，其中做的好的和不够的地方。

原文：https://commandcenter.blogspot.com/2024/01/what-we-got-right-what-we-got-wrong.html
译文：https://baoyu.io/translations/software-engineering/what-we-got-right-what-we-got-wrong</title>
            <link>https://nitter.cz/dotey/status/1744784191370285161#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744784191370285161#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 18:12:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Go 语言之父 Rob Pike 写的长文：在 Go 语言 14 年的发展历史中，我们做得对的和不对的<br />
<br />
基于他去年在悉尼 GopherConAU 会议上所做的闭幕演讲的内容整理补充而成，系统的总结回顾了 Go 的发展过程中的经验教训，例如 Go 语言中并发、接口的设计；Go 语言作为一个开源项目是如何进行项目管理的，其中做的好的和不够的地方。<br />
<br />
原文：<a href="https://commandcenter.blogspot.com/2024/01/what-we-got-right-what-we-got-wrong.html">commandcenter.blogspot.com/2…</a><br />
译文：<a href="https://baoyu.io/translations/software-engineering/what-we-got-right-what-we-got-wrong">baoyu.io/translations/softwa…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RhMzN2R1hJQUFBdEFyLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RhMzVweFhjQUFpbXpwLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RhMzh0UFcwQUF5OG1ILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RhMzlQVFdNQUF3aGcyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744754475770712067#m</id>
            <title>R to @dotey: AnyText 的在线测试地址：
https://anytext.pics/</title>
            <link>https://nitter.cz/dotey/status/1744754475770712067#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744754475770712067#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 16:14:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AnyText 的在线测试地址：<br />
<a href="https://anytext.pics/">anytext.pics/</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744754251404918874#m</id>
            <title>AnyText 的在线测试地址：
https://anytext.pics/</title>
            <link>https://nitter.cz/dotey/status/1744754251404918874#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744754251404918874#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 16:13:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AnyText 的在线测试地址：<br />
<a href="https://anytext.pics/">anytext.pics/</a></p>
<p><a href="https://nitter.cz/dotey/status/1741254641407365315#m">nitter.cz/dotey/status/1741254641407365315#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Cydiar404/status/1744685573246521392#m</id>
            <title>RT by @dotey: 其实大家都觉得是号池，这个号池不是一般人能玩的起的，从注册到养号到损耗，一个号池如果要支撑一个大项目，基本需要上百万的资金量，如果OpenAI严控，直接就底儿掉了，这也是概率事件！大厂是收额度号自己直接购买Azure GPT4 个人账户，直接用超强的调用能力，直接调穿！举个例子，之前可以通过海外企业申请2500刀额度号，这个额度是跟着月度消耗阈值走的〈比如120刀〉，但是，如果调用量非常大，直接2500刀就可以调穿了，然后弃掉，其他的需要了解可以继续提问。</title>
            <link>https://nitter.cz/Cydiar404/status/1744685573246521392#m</link>
            <guid isPermaLink="false">https://nitter.cz/Cydiar404/status/1744685573246521392#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 11:40:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>其实大家都觉得是号池，这个号池不是一般人能玩的起的，从注册到养号到损耗，一个号池如果要支撑一个大项目，基本需要上百万的资金量，如果OpenAI严控，直接就底儿掉了，这也是概率事件！大厂是收额度号自己直接购买Azure GPT4 个人账户，直接用超强的调用能力，直接调穿！举个例子，之前可以通过海外企业申请2500刀额度号，这个额度是跟着月度消耗阈值走的〈比如120刀〉，但是，如果调用量非常大，直接2500刀就可以调穿了，然后弃掉，其他的需要了解可以继续提问。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>