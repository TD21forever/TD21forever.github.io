<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729201172232479001#m</id>
            <title>R to @dotey: 注意这两句：
“7.rlhf 不一定是agi 的必经路径，因 rlhf是 hf部分决定了上限，怎么会通往 agi？
8.但rl是正确的，看好 multi agent，类比阿法狗，可以左脚踩右脚把能力提上去。”</title>
            <link>https://nitter.cz/dotey/status/1729201172232479001#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729201172232479001#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 18:11:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>注意这两句：<br />
“7.rlhf 不一定是agi 的必经路径，因 rlhf是 hf部分决定了上限，怎么会通往 agi？<br />
8.但rl是正确的，看好 multi agent，类比阿法狗，可以左脚踩右脚把能力提上去。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729194209901736340#m</id>
            <title>作者把这个冒险游戏的GPT的Prompt开源了
https://gist.github.com/levelsio/5bc87fd1b1ffbf4a705047bebd9b4790</title>
            <link>https://nitter.cz/dotey/status/1729194209901736340#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729194209901736340#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 17:43:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者把这个冒险游戏的GPT的Prompt开源了<br />
<a href="https://gist.github.com/levelsio/5bc87fd1b1ffbf4a705047bebd9b4790">gist.github.com/levelsio/5bc…</a></p>
<p><a href="https://nitter.cz/levelsio/status/1728951317945868729#m">nitter.cz/levelsio/status/1728951317945868729#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyODMwOTI4NTAyODAyMDIyNC84MzFnbzNucD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729192550836379884#m</id>
            <title>推荐一期播客：OpenAI员工的最新采访 by 宇宙中猫

是在OpenAI罢免CEO风波之后的采访，很有意思。内容摘要小红书上已经有网友“互联网小牛马”整理过了 https://www.xiaohongshu.com/explore/656474b60000000032039445?app_platform=ios&amp;app_version=8.14.3&amp;share_from_user_hidden=true&amp;type=normal&amp;xhsshare=WeixinSession&amp;appuid=56a190f8b8ce1a0b0a953c02&amp;apptime=1701097747&amp;wechatWid=0ddb52dd6a4d2921b20bc73938f352fe&amp;wechatOrigin=menu 。

Apple Podcasts地址：https://podcasts.apple.com/us/podcast/openai%E5%91%98%E5%B7%A5%E7%9A%84%E6%9C%80%E6%96%B0%E9%87%87%E8%AE%BF/id1659350101?i=1000635637754
小宇宙地址：https://www.xiaoyuzhoufm.com/episode/655d835e6b842b8902affc85</title>
            <link>https://nitter.cz/dotey/status/1729192550836379884#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729192550836379884#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 17:36:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一期播客：OpenAI员工的最新采访 by 宇宙中猫<br />
<br />
是在OpenAI罢免CEO风波之后的采访，很有意思。内容摘要小红书上已经有网友“互联网小牛马”整理过了 <a href="https://www.xiaohongshu.com/explore/656474b60000000032039445?app_platform=ios&amp;app_version=8.14.3&amp;share_from_user_hidden=true&amp;type=normal&amp;xhsshare=WeixinSession&amp;appuid=56a190f8b8ce1a0b0a953c02&amp;apptime=1701097747&amp;wechatWid=0ddb52dd6a4d2921b20bc73938f352fe&amp;wechatOrigin=menu">xiaohongshu.com/explore/6564…</a> 。<br />
<br />
Apple Podcasts地址：<a href="https://podcasts.apple.com/us/podcast/openai%E5%91%98%E5%B7%A5%E7%9A%84%E6%9C%80%E6%96%B0%E9%87%87%E8%AE%BF/id1659350101?i=1000635637754">podcasts.apple.com/us/podcas…</a><br />
小宇宙地址：<a href="https://www.xiaoyuzhoufm.com/episode/655d835e6b842b8902affc85">xiaoyuzhoufm.com/episode/655…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85U3VmUlhzQUVWeHpMLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85U3hqQlhRQUFneXJULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729178839191081077#m</id>
            <title>核心就是得做中学</title>
            <link>https://nitter.cz/dotey/status/1729178839191081077#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729178839191081077#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:42:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>核心就是得做中学</p>
<p><a href="https://nitter.cz/gdb/status/1729162836499472734#m">nitter.cz/gdb/status/1729162836499472734#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729172682758054147#m</id>
            <title>RT by @dotey: Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。
将这种方法扩展是否能实现通用人工智能（AGI）？不会。
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</title>
            <link>https://nitter.cz/op7418/status/1729172682758054147#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729172682758054147#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:17:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：<br />
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。<br />
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。<br />
将这种方法扩展是否能实现通用人工智能（AGI）？不会。<br />
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。<br />
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</p>
<p><a href="https://nitter.cz/DrJimFan/status/1729162728072433876#m">nitter.cz/DrJimFan/status/1729162728072433876#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</id>
            <title>RT by @dotey: 建议和这篇《为什么你不该加入 Y Combinator》https://readit.vip/a/e0Bwj  一起阅读。

作者反对保罗这种只以增长为目标的做法。

1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</title>
            <link>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</link>
            <guid isPermaLink="false">https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 13:57:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>建议和这篇《为什么你不该加入 Y Combinator》<a href="https://readit.vip/a/e0Bwj">readit.vip/a/e0Bwj</a>  一起阅读。<br />
<br />
作者反对保罗这种只以增长为目标的做法。<br />
<br />
1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。<br />
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZXRtdmFrQUFMRFBtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZnFEcWJnQUFhMGJ2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Tisoga/status/1729017824092549247#m</id>
            <title>RT by @dotey: 这应该就是做产品最希望收到的评价吧。

另外 http://devv.ai 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。

欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</title>
            <link>https://nitter.cz/Tisoga/status/1729017824092549247#m</link>
            <guid isPermaLink="false">https://nitter.cz/Tisoga/status/1729017824092549247#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:02:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这应该就是做产品最希望收到的评价吧。<br />
<br />
另外 <a href="http://devv.ai">devv.ai</a> 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。<br />
<br />
欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82ejBRVmIwQUFYUDAzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729026599411225075#m</id>
            <title>R to @dotey: 谢谢</title>
            <link>https://nitter.cz/dotey/status/1729026599411225075#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729026599411225075#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:37:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谢谢</p>
<p><a href="https://nitter.cz/Nag1ovo/status/1729018702048493634#m">nitter.cz/Nag1ovo/status/1729018702048493634#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728998748272156761#m</id>
            <title>R to @dotey: 相应的GitHub项目：https://github.com/SurviveSJTU/SJTU-Application</title>
            <link>https://nitter.cz/dotey/status/1728998748272156761#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728998748272156761#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:46:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>相应的GitHub项目：<a href="https://github.com/SurviveSJTU/SJTU-Application">github.com/SurviveSJTU/SJTU-…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNzQ2NzQ2MzM3NjMwMjA4MC9uaEdRYmZRRD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728997603847675923#m</id>
            <title>推荐GitBook：
https://survivesjtu.gitbook.io/survivesjtumanual/

于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</title>
            <link>https://nitter.cz/dotey/status/1728997603847675923#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728997603847675923#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:42:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐GitBook：<上海交通大学生存手册><br />
<a href="https://survivesjtu.gitbook.io/survivesjtumanual/">survivesjtu.gitbook.io/survi…</a><br />
<br />
<上海交通大学生存手册>于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82aUl1SldRQUFwblExLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728976294195429627#m</id>
            <title>R to @dotey: ## Summary so far

构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。

Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。

## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard

在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。

关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选

部分形成最优答案，或者让模型帮助检查工作。

在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</title>
            <link>https://nitter.cz/dotey/status/1728976294195429627#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728976294195429627#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:17:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## Summary so far<br />
<br />
构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。<br />
<br />
Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。<br />
<br />
## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard<br />
<br />
在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。<br />
<br />
关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选<br />
<br />
部分形成最优答案，或者让模型帮助检查工作。<br />
<br />
在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzU3MzY0MTU5MzY1MTMvcHUvaW1nL29uOVlkdzV1WTdGdkx5V2MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728974703895711948#m</id>
            <title>R to @dotey: ## How do they work?

好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。

但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。

我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。

这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。

它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要

相应的复杂评估来处理这些模型，因为它们主要是基于经验的。

## Finetuning into an Assistant

现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。

获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”

接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。

所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。

这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</title>
            <link>https://nitter.cz/dotey/status/1728974703895711948#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728974703895711948#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:11:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## How do they work?<br />
<br />
好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。<br />
<br />
但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。<br />
<br />
我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。<br />
<br />
这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。<br />
<br />
它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要<br />
<br />
相应的复杂评估来处理这些模型，因为它们主要是基于经验的。<br />
<br />
## Finetuning into an Assistant<br />
<br />
现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。<br />
<br />
获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”<br />
<br />
接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。<br />
<br />
所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。<br />
<br />
这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzM4NzQ4MzY5NzE1MjAvcHUvaW1nL0wxZHl1ZFRFTDM5SFB2NmsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</id>
            <title>RT by @dotey: Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章

Loom基于GPT-3，采用了一种独特的树形结构来组织文本。

每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

举例解释：

假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。

1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。

2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。

3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。

4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。

6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。

通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。

Loom的主要特点和功能包括：

1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。

2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。

3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。

4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。

5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。

6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。

5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。

GitHub：https://github.com/socketteer/loom
实例：https://generative.ink/meta/block-multiverse/</title>
            <link>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728963473152045089#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章<br />
<br />
Loom基于GPT-3，采用了一种独特的树形结构来组织文本。<br />
<br />
每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
举例解释：<br />
<br />
假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。<br />
<br />
1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。<br />
<br />
2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。<br />
<br />
3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。<br />
<br />
4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。<br />
<br />
6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。<br />
<br />
通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。<br />
<br />
Loom的主要特点和功能包括：<br />
<br />
1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。<br />
<br />
2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。<br />
<br />
3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。<br />
<br />
4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。<br />
<br />
5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。<br />
<br />
6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。<br />
<br />
5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。<br />
<br />
GitHub：<a href="https://github.com/socketteer/loom">github.com/socketteer/loom</a><br />
实例：<a href="https://generative.ink/meta/block-multiverse/">generative.ink/meta/block-mu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRV2JjQUF6dFY4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRMmJjQUFtSzZILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhReWE0QUFKZ2NLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRd2FjQUFRa2t3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</id>
            <title>RT by @dotey: UIDraw：在手机上画草图，自动生成H5页面
一个SwiftUI项目，使用GPT-4V实现写HTML界面。
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。
Github：https://github.com/jordansinger/UIDraw</title>
            <link>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:25:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>UIDraw：在手机上画草图，自动生成H5页面<br />
一个SwiftUI项目，使用GPT-4V实现写HTML界面。<br />
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。<br />
Github：<a href="https://github.com/jordansinger/UIDraw">github.com/jordansinger/UIDr…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjMxMjg4ODM2MDU1MDQvcHUvaW1nLzRFbEx2WGJEeHlYYUtiUGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728962389830238296#m</id>
            <title>R to @dotey: ## LLM Training

但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。

因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。

你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。

但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。

这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。

那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。

你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个

词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。

所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。

我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。

## LLM Dreams

那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。

可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。

比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。

但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</title>
            <link>https://nitter.cz/dotey/status/1728962389830238296#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728962389830238296#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:22:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## LLM Training<br />
<br />
但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。<br />
<br />
因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。<br />
<br />
你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。<br />
<br />
但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。<br />
<br />
这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。<br />
<br />
那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。<br />
<br />
你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个<br />
<br />
词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。<br />
<br />
所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。<br />
<br />
我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。<br />
<br />
## LLM Dreams<br />
<br />
那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。<br />
<br />
可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。<br />
<br />
比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。<br />
<br />
但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjE4MTc2MjIyNDEyODEvcHUvaW1nL3pCck1GN1Vzenpnc0RNNm8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728959646138880026#m</id>
            <title>OpenAI 的大神 Andrej Karpathy 前几天在他的 YouTube 频道讲了一堂课，系统的介绍了大语言模型，内容深入浅出，非常赞，抽空将它翻译成了双语，由于内容较长，我将分批上传，以下是第一部分精校后的双语视频，字幕文稿如下：

Intro: Large Language Model (LLM) talk

大家好。最近，我进行了一场关于大语言模型的 30 分钟入门讲座。遗憾的是，这次讲座没有被录制下来，但许多人在讲座后找到我，他们告诉我非常喜欢那次讲座。因此，我决定重新录制并上传到 YouTube，那么，让我们开始吧，为大家带来“忙碌人士的大语言模型入门”系列，主讲人 Scott。好的，那我们开始吧。

LLM Inference

首先，什么是大语言模型 (Large Language Model) 呢？其实，一个大语言模型就是由两个文件组成的。在这个假设的目录中会有两个文件。

以 Llama 2 70B 模型为例，这是一个由 Meta AI 发布的大语言模型。这是 Llama 系列语言模型的第二代，也是该系列中参数最多的模型，达到了 700 亿。LAMA2 系列包括了多个不同规模的模型，70 亿，130 亿，340 亿，700 亿是最大的一个。

现在很多人喜欢这个模型，因为它可能是目前公开权重最强大的模型。Meta 发布了这款模型的权重、架构和相关论文，所以任何人都可以很轻松地使用这个模型。这与其他一些你可能熟悉的语言模型不同，例如，如果你正在使用 ChatGPT 或类似的东西，其架构并未公开，是 OpenAI 的产权，你只能通过网页界面使用，但你实际上没有访问那个模型的权限。

在这种情况下，Llama 2 70B 模型实际上就是你电脑上的两个文件：一个是存储参数的文件，另一个是运行这些参数的代码。这些参数是神经网络（即语言模型）的权重或参数。我们稍后会详细解释。因为这是一个拥有 700 亿参数的模型，每个参数占用两个字节，因此参数文件的大小为 140 GB，之所以是两个字节，是因为这是 float 16 类型的数据。

除了这些参数，还有一大堆神经网络的参数。你还需要一些能运行神经网络的代码，这些代码被包含在我们所说的运行文件中。这个运行文件可以是 C 语言或 Python，或任何其他编程语言编写的。它可以用任何语言编写，但 C 语言是一种非常简单的语言，只是举个例子。只需大约 500 行 C 语言代码，无需任何其他依赖，就能构建起神经网络架构，并且主要依靠一些参数来运行模型。所以只需要这两个文件。

你只需带上这两个文件和你的 MacBook，就拥有了一个完整的工具包。你不需要连接互联网或其他任何设备。你可以拿着这两个文件，编译你的 C 语言代码。你将得到一个可针对参数运行并与语言模型交互的二进制文件。

比如，你可以让它写一首关于 Scale AI 公司的诗，语言模型就会开始生成文本。在这种情况下，它会按照指示为你创作一首关于 Scale AI 的诗。之所以选用 Scale AI 作为例子，你会在整个演讲中看到，是因为我最初在 Scale AI 举办的活动上介绍过这个话题，所以演讲中会多次提到它，以便内容更具体。这就是我们如何运行模型的方式。只需要两个文件和一台 MacBook。

我在这里稍微有点作弊，因为这并不是在运行一个有 700 亿参数的模型，而是在运行一个有 70 亿参数的模型。一个有 700 亿参数的模型运行速度大约会慢 10 倍。但我想给你们展示一下文本生成的过程，让你们了解它是什么样子。所以运行模型并不需要很多东西。这是一个非常小的程序包，但是当我们需要获取那些参数时，计算的复杂性就真正显现出来了。

那么，这些参数从何而来，我们如何获得它们？因为无论 run.c 文件中的内容是什么，神经网络的架构和前向传播都是算法上明确且公开的。</title>
            <link>https://nitter.cz/dotey/status/1728959646138880026#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728959646138880026#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:11:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 的大神 Andrej Karpathy 前几天在他的 YouTube 频道讲了一堂课，系统的介绍了大语言模型，内容深入浅出，非常赞，抽空将它翻译成了双语，由于内容较长，我将分批上传，以下是第一部分精校后的双语视频，字幕文稿如下：<br />
<br />
Intro: Large Language Model (LLM) talk<br />
<br />
大家好。最近，我进行了一场关于大语言模型的 30 分钟入门讲座。遗憾的是，这次讲座没有被录制下来，但许多人在讲座后找到我，他们告诉我非常喜欢那次讲座。因此，我决定重新录制并上传到 YouTube，那么，让我们开始吧，为大家带来“忙碌人士的大语言模型入门”系列，主讲人 Scott。好的，那我们开始吧。<br />
<br />
LLM Inference<br />
<br />
首先，什么是大语言模型 (Large Language Model) 呢？其实，一个大语言模型就是由两个文件组成的。在这个假设的目录中会有两个文件。<br />
<br />
以 Llama 2 70B 模型为例，这是一个由 Meta AI 发布的大语言模型。这是 Llama 系列语言模型的第二代，也是该系列中参数最多的模型，达到了 700 亿。LAMA2 系列包括了多个不同规模的模型，70 亿，130 亿，340 亿，700 亿是最大的一个。<br />
<br />
现在很多人喜欢这个模型，因为它可能是目前公开权重最强大的模型。Meta 发布了这款模型的权重、架构和相关论文，所以任何人都可以很轻松地使用这个模型。这与其他一些你可能熟悉的语言模型不同，例如，如果你正在使用 ChatGPT 或类似的东西，其架构并未公开，是 OpenAI 的产权，你只能通过网页界面使用，但你实际上没有访问那个模型的权限。<br />
<br />
在这种情况下，Llama 2 70B 模型实际上就是你电脑上的两个文件：一个是存储参数的文件，另一个是运行这些参数的代码。这些参数是神经网络（即语言模型）的权重或参数。我们稍后会详细解释。因为这是一个拥有 700 亿参数的模型，每个参数占用两个字节，因此参数文件的大小为 140 GB，之所以是两个字节，是因为这是 float 16 类型的数据。<br />
<br />
除了这些参数，还有一大堆神经网络的参数。你还需要一些能运行神经网络的代码，这些代码被包含在我们所说的运行文件中。这个运行文件可以是 C 语言或 Python，或任何其他编程语言编写的。它可以用任何语言编写，但 C 语言是一种非常简单的语言，只是举个例子。只需大约 500 行 C 语言代码，无需任何其他依赖，就能构建起神经网络架构，并且主要依靠一些参数来运行模型。所以只需要这两个文件。<br />
<br />
你只需带上这两个文件和你的 MacBook，就拥有了一个完整的工具包。你不需要连接互联网或其他任何设备。你可以拿着这两个文件，编译你的 C 语言代码。你将得到一个可针对参数运行并与语言模型交互的二进制文件。<br />
<br />
比如，你可以让它写一首关于 Scale AI 公司的诗，语言模型就会开始生成文本。在这种情况下，它会按照指示为你创作一首关于 Scale AI 的诗。之所以选用 Scale AI 作为例子，你会在整个演讲中看到，是因为我最初在 Scale AI 举办的活动上介绍过这个话题，所以演讲中会多次提到它，以便内容更具体。这就是我们如何运行模型的方式。只需要两个文件和一台 MacBook。<br />
<br />
我在这里稍微有点作弊，因为这并不是在运行一个有 700 亿参数的模型，而是在运行一个有 70 亿参数的模型。一个有 700 亿参数的模型运行速度大约会慢 10 倍。但我想给你们展示一下文本生成的过程，让你们了解它是什么样子。所以运行模型并不需要很多东西。这是一个非常小的程序包，但是当我们需要获取那些参数时，计算的复杂性就真正显现出来了。<br />
<br />
那么，这些参数从何而来，我们如何获得它们？因为无论 run.c 文件中的内容是什么，神经网络的架构和前向传播都是算法上明确且公开的。</p>
<p><a href="https://nitter.cz/karpathy/status/1727731541781152035#m">nitter.cz/karpathy/status/1727731541781152035#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NTg2NTQ5Nzg2NjI0MDIvcHUvaW1nL096ak1ReDBBU0JqM29IUkYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728913073388368146#m</id>
            <title>转译：人工智能本身并非危险的根源，关键在于掌控它的人

by Kenan Malik

OpenAI 的混乱事件揭示了我们对待科技的矛盾心态

这起事件的发展有时让人联想到 Fawlty Towers，而不是 Succession，更像是一出劳莱和哈代的闹剧，而不是莎士比亚式的悲剧。OpenAI 凭借其知名产品 聊天机器人 ChatGPT 成为当下科技界的焦点。上周，关于 Sam Altman 被撤销 CEO 职位解雇及随后的重新聘用成为全球媒体热议的话题，引发了广泛的惊奇和困惑。

一些人认为这场闹剧反映了董事会的不称职；另一些人则看到了巨大自我间的冲突。更深层次地，这次动荡折射出科技行业的诸多内在矛盾：一方面是技术企业家自封的“颠覆者”形象，另一方面则是他们控制着影响我们每个人生活的价值数十亿美元的巨型产业。同样存在的还有人工智能作为改变人类生活的工具与其可能成为人类生存威胁的双重视角。

在这些矛盾中，几乎没有哪个组织比 OpenAI 更具代表性。Elon Musk、Peter Thiel 等硅谷知名人士于 2015 年创立了这个组织，他们既是人工智能的倡导者，也是对其潜在威胁发出警告的先锋。Elon Musk 曾沉重地宣称：“通过人工智能，我们似乎在召唤一只恶魔。”

科技界巨头们对自己作为未来的征服者的无限自尊，加上对他人和社会深深的悲观情绪，使得他们对世界末日即将降临的恐惧几乎成为了默认状态。其中许多人已经成为了“预备者”，为可能出现的疯狂麦克斯式世界做好了准备。Altman 在 OpenAI 刚成立时向《纽约客》透露：“我有枪械、黄金、碘化钾、抗生素、电池、水、以色列国防军的防毒面具，还有位于 Big Sur 的一大块可以飞去的土地。”他认为，最优秀的企业家，“极度偏执，常常面临生存危机”，当然，对 AI 的担忧也在所难免。

OpenAI 的初衷是作为一个非盈利的慈善组织，旨在开发人工通用智能（AGI），简而言之，就是能够完成或超越人类所有智力任务的机器。但它的目标是以一种道德的方式造福“全人类”。

然后，到了 2019 年，这个慈善机构成立了一个盈利子公司，以筹集更多投资，最终从 Microsoft 那里募集了超过 110 亿美元（约 87 亿英镑）。尽管如此，非盈利的母公司仍然保持着完全的控制权，这就形成了追求利润与对其产品可能带来的世界末日担忧之间的张力。ChatGPT 的巨大成功进一步加剧了这种紧张关系。

两年前，一些 OpenAI 的研究人员离开去创建了一个新机构 Anthropic，因为他们担心自己原公司 AI 的发展速度过快。其中一位后来对记者表示：“在未来十年内，一个失控的 AI 毁灭人类的可能性高达 20%”。似乎是这种同样的恐惧促成了对 Altman 的排挤以及过去一周的董事会混乱。

我们可能会好奇，为什么人类会持续研发可能威胁到人类生命的机器。但讽刺的是，尽管人们对 AI 的恐惧有些夸张，这种恐惧本身却带来了新的危险。对 AI 的过度警惕源于对其能力的高估。ChatGPT 在预测文字序列的下一个词方面表现得非常出色，以至于我们误以为它能像真人一样进行交流。然而，它并不能像人类那样真正理解这些词汇的含义，对现实世界的了解也微乎其微。我们距离实现“人工通用智能 (AGI)”的梦想还有很长的路要走。“AGI 不会在短期内出现”，IBM 软件工程首席科学家 Grady Booch 指出，即使是在我们的后代子孙的一生中也不太可能实现。

对于那些认为 AGI 即将成为现实的硅谷人士来说，他们认为应通过“对齐”来保护人类，即确保 AI 符合人类的价值观和意图。这看似是一种理性的方式，可以减轻 AI 可能带来的伤害。但当我们开始探讨“人类价值”究竟是什么、谁来定义它们，以及在价值观冲突时该如何应对时，问题就变得复杂了。

社会价值观总是众说纷纭，尤其是在当今这个社会共识标准瓦解、普遍不满情绪高涨的时代。我们与技术的关系本身就引发了热烈的讨论。对一些人来说，限制网络仇恨或保护人们免受网络伤害比维护言论自由或隐私权更为重要。这正是英国最新在线安全法案的出发点。这也是许多人对这项法律可能带来的后果感到担忧的原因。

接下来是虚假信息的问题。几乎没人会质疑虚假信息是一个日益严重的问题，它对民主和信任提出了挑战。但如何应对这一问题，依然存在很大争议。尤其是许多管理虚假信息的尝试，最终增强了科技公司监管公众的能力。

同时，算法偏见这一议题也揭示了对“价值对齐”观点的弱点。算法容易对少数群体产生偏见，原因正是它们过于贴合人类价值观。AI 程序是基于充满歧视的人类世界数据训练而成的。这些偏见也渗透到 AI 软件中，不论是在刑事司法系统、医疗保健、面部识别还是招聘等领域。

我们面临的问题并非机器将来可能对人类行使权力——这种看法基于目前的发展是无依据的猜测。真正的问题在于，我们生活在一个少数人利用权力损害多数人的社会，而技术成为了巩固这种权力的工具。对于掌握社会、政治和经济权力的人来说，将问题描绘为技术问题而非社会问题，把问题推到未来而非现在，似乎更合理。

几乎所有对人类有益的工具也可能造成伤害。但它们很少自行造成伤害，更多是因为被人类，尤其是那些掌权者，错误使用。这才是我们讨论 AI 时应当关注的起点，而非那些关于人类灭绝的虚构恐惧。

https://www.theguardian.com/commentisfree/2023/nov/26/artificial-intelligence-harm-worry-about-people-control-openai</title>
            <link>https://nitter.cz/dotey/status/1728913073388368146#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728913073388368146#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 23:06:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：人工智能本身并非危险的根源，关键在于掌控它的人<br />
<br />
by Kenan Malik<br />
<br />
OpenAI 的混乱事件揭示了我们对待科技的矛盾心态<br />
<br />
这起事件的发展有时让人联想到 Fawlty Towers，而不是 Succession，更像是一出劳莱和哈代的闹剧，而不是莎士比亚式的悲剧。OpenAI 凭借其知名产品 聊天机器人 ChatGPT 成为当下科技界的焦点。上周，关于 Sam Altman 被撤销 CEO 职位解雇及随后的重新聘用成为全球媒体热议的话题，引发了广泛的惊奇和困惑。<br />
<br />
一些人认为这场闹剧反映了董事会的不称职；另一些人则看到了巨大自我间的冲突。更深层次地，这次动荡折射出科技行业的诸多内在矛盾：一方面是技术企业家自封的“颠覆者”形象，另一方面则是他们控制着影响我们每个人生活的价值数十亿美元的巨型产业。同样存在的还有人工智能作为改变人类生活的工具与其可能成为人类生存威胁的双重视角。<br />
<br />
在这些矛盾中，几乎没有哪个组织比 OpenAI 更具代表性。Elon Musk、Peter Thiel 等硅谷知名人士于 2015 年创立了这个组织，他们既是人工智能的倡导者，也是对其潜在威胁发出警告的先锋。Elon Musk 曾沉重地宣称：“通过人工智能，我们似乎在召唤一只恶魔。”<br />
<br />
科技界巨头们对自己作为未来的征服者的无限自尊，加上对他人和社会深深的悲观情绪，使得他们对世界末日即将降临的恐惧几乎成为了默认状态。其中许多人已经成为了“预备者”，为可能出现的疯狂麦克斯式世界做好了准备。Altman 在 OpenAI 刚成立时向《纽约客》透露：“我有枪械、黄金、碘化钾、抗生素、电池、水、以色列国防军的防毒面具，还有位于 Big Sur 的一大块可以飞去的土地。”他认为，最优秀的企业家，“极度偏执，常常面临生存危机”，当然，对 AI 的担忧也在所难免。<br />
<br />
OpenAI 的初衷是作为一个非盈利的慈善组织，旨在开发人工通用智能（AGI），简而言之，就是能够完成或超越人类所有智力任务的机器。但它的目标是以一种道德的方式造福“全人类”。<br />
<br />
然后，到了 2019 年，这个慈善机构成立了一个盈利子公司，以筹集更多投资，最终从 Microsoft 那里募集了超过 110 亿美元（约 87 亿英镑）。尽管如此，非盈利的母公司仍然保持着完全的控制权，这就形成了追求利润与对其产品可能带来的世界末日担忧之间的张力。ChatGPT 的巨大成功进一步加剧了这种紧张关系。<br />
<br />
两年前，一些 OpenAI 的研究人员离开去创建了一个新机构 Anthropic，因为他们担心自己原公司 AI 的发展速度过快。其中一位后来对记者表示：“在未来十年内，一个失控的 AI 毁灭人类的可能性高达 20%”。似乎是这种同样的恐惧促成了对 Altman 的排挤以及过去一周的董事会混乱。<br />
<br />
我们可能会好奇，为什么人类会持续研发可能威胁到人类生命的机器。但讽刺的是，尽管人们对 AI 的恐惧有些夸张，这种恐惧本身却带来了新的危险。对 AI 的过度警惕源于对其能力的高估。ChatGPT 在预测文字序列的下一个词方面表现得非常出色，以至于我们误以为它能像真人一样进行交流。然而，它并不能像人类那样真正理解这些词汇的含义，对现实世界的了解也微乎其微。我们距离实现“人工通用智能 (AGI)”的梦想还有很长的路要走。“AGI 不会在短期内出现”，IBM 软件工程首席科学家 Grady Booch 指出，即使是在我们的后代子孙的一生中也不太可能实现。<br />
<br />
对于那些认为 AGI 即将成为现实的硅谷人士来说，他们认为应通过“对齐”来保护人类，即确保 AI 符合人类的价值观和意图。这看似是一种理性的方式，可以减轻 AI 可能带来的伤害。但当我们开始探讨“人类价值”究竟是什么、谁来定义它们，以及在价值观冲突时该如何应对时，问题就变得复杂了。<br />
<br />
社会价值观总是众说纷纭，尤其是在当今这个社会共识标准瓦解、普遍不满情绪高涨的时代。我们与技术的关系本身就引发了热烈的讨论。对一些人来说，限制网络仇恨或保护人们免受网络伤害比维护言论自由或隐私权更为重要。这正是英国最新在线安全法案的出发点。这也是许多人对这项法律可能带来的后果感到担忧的原因。<br />
<br />
接下来是虚假信息的问题。几乎没人会质疑虚假信息是一个日益严重的问题，它对民主和信任提出了挑战。但如何应对这一问题，依然存在很大争议。尤其是许多管理虚假信息的尝试，最终增强了科技公司监管公众的能力。<br />
<br />
同时，算法偏见这一议题也揭示了对“价值对齐”观点的弱点。算法容易对少数群体产生偏见，原因正是它们过于贴合人类价值观。AI 程序是基于充满歧视的人类世界数据训练而成的。这些偏见也渗透到 AI 软件中，不论是在刑事司法系统、医疗保健、面部识别还是招聘等领域。<br />
<br />
我们面临的问题并非机器将来可能对人类行使权力——这种看法基于目前的发展是无依据的猜测。真正的问题在于，我们生活在一个少数人利用权力损害多数人的社会，而技术成为了巩固这种权力的工具。对于掌握社会、政治和经济权力的人来说，将问题描绘为技术问题而非社会问题，把问题推到未来而非现在，似乎更合理。<br />
<br />
几乎所有对人类有益的工具也可能造成伤害。但它们很少自行造成伤害，更多是因为被人类，尤其是那些掌权者，错误使用。这才是我们讨论 AI 时应当关注的起点，而非那些关于人类灭绝的虚构恐惧。<br />
<br />
<a href="https://www.theguardian.com/commentisfree/2023/nov/26/artificial-intelligence-harm-worry-about-people-control-openai">theguardian.com/commentisfre…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl81Vk9pa1hFQUEtUGhSLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1728805500702105959#m</id>
            <title>RT by @dotey: 在测试 Yi-34B-Chat-4Bits，确实能力上秒杀了一众10B模型。

通过vLLM 可以在4090上提供33 tokens/s 生成速度，3 并发稳定生成速度100tokens/s。

从ceval 开发集中挑选最难的数学等，打乱答案顺序后评测。（肯定在训练集中，会高估）

Qwen-14B-4bits 34.5%，yi是 52.7%。</title>
            <link>https://nitter.cz/9hills/status/1728805500702105959#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1728805500702105959#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 15:58:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在测试 Yi-34B-Chat-4Bits，确实能力上秒杀了一众10B模型。<br />
<br />
通过vLLM 可以在4090上提供33 tokens/s 生成速度，3 并发稳定生成速度100tokens/s。<br />
<br />
从ceval 开发集中挑选最难的数学等，打乱答案顺序后评测。（肯定在训练集中，会高估）<br />
<br />
Qwen-14B-4bits 34.5%，yi是 52.7%。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>