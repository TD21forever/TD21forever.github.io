<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727530341202563280#m</id>
            <title>刚发现Ilya也转发了，看起来状态还不错，希望他们能继续合作</title>
            <link>https://nitter.cz/dotey/status/1727530341202563280#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727530341202563280#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 03:31:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚发现Ilya也转发了，看起来状态还不错，希望他们能继续合作</p>
<p><a href="https://nitter.cz/ilyasut/status/1727434066411286557#m">nitter.cz/ilyasut/status/1727434066411286557#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727517538722914365#m</id>
            <title>训练过的不算多牛，出个没训练过的就知道了</title>
            <link>https://nitter.cz/dotey/status/1727517538722914365#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727517538722914365#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 02:40:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>训练过的不算多牛，出个没训练过的就知道了</p>
<p><a href="https://nitter.cz/66567848787A/status/1727368263032799512#m">nitter.cz/66567848787A/status/1727368263032799512#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/waylybaye/status/1727510389087433103#m</id>
            <title>RT by @dotey: OpenCat 1.8.3 更新啦，将生成图片的功能带到了 iOS 上 🥳</title>
            <link>https://nitter.cz/waylybaye/status/1727510389087433103#m</link>
            <guid isPermaLink="false">https://nitter.cz/waylybaye/status/1727510389087433103#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 02:12:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenCat 1.8.3 更新啦，将生成图片的功能带到了 iOS 上 🥳</p>
<p><a href="https://nitter.cz/waylybaye/status/1722413580317073702#m">nitter.cz/waylybaye/status/1722413580317073702#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9sWmlvUmE4QUExOTl4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9sWmlvU2JJQUFGT0w4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727510593970561466#m</id>
            <title>转译：**独家：OpenAI 研究员在 CEO 被撤职前向董事会发出 AI 突破警告 — 据知情人士透露**

11 月 22 日（路透社）- 在 OpenAI 首席执行官 Sam Altman 被迫离职前的四天，几位公司研究员向董事会发送了一封紧急信函，警告他们说，他们发现了一种强大的人工智能技术，这种技术可能对人类构成威胁。这一消息是由两位了解内情的人士向路透社透露的。

这封此前未曾报道过的信件和相关的 AI 算法，是董事会决定撤换 Altman 的关键前奏。两位消息来源表示，Altman 被视为生成式 AI 的标志性人物。在他周二晚些时候的华丽归来之前，超过 700 名员工威胁要辞职，并表示将与被解雇的领导者一起支持投资者微软 (MSFT.O)。

这些消息来源指出，这封信只是导致 Altman 被解雇的众多不满之一。路透社未能查看这封信的副本。写信的研究人员并未立即回应置评请求。

据其中一位知情人士透露，资深高管 Mira Murati 上周三向员工提及了一个名为 Q* 的项目，并表示在周末发生的事件之前，已向董事会发送过一封信。

在报道发布后，一位 OpenAI 发言人表示，Murati 告诉员工媒体即将报道的内容，但她并未对报道的准确性发表评论。

制造 ChatGPT 的公司在 Q*（发音为 Q-Star）项目上取得了进展，一些内部人士认为这可能是该初创公司在追求超级智能（也称为人工通用智能，AGI）方向上的重大突破，一位人士告诉路透社。OpenAI 将 AGI 定义为智力超过人类的 AI 系统。

该人士表示，凭借庞大的计算资源，这个新模型能够解决一些数学问题。这位不愿透露姓名的人士说，尽管 Q* 目前的数学运算能力仅限于小学生水平，但它在这些测试中的出色表现让研究人员对其未来的成功充满期望。

路透社无法独立核实研究人员对 Q* 能力的说法。

**超级智能的挑战**
研究人员认为，数学是生成式 AI 发展的新前沿。目前，生成式 AI 在通过统计方法预测下一个词以进行写作和语言翻译方面表现良好，但面对同一个问题可能会有截然不同的答案。然而，掌握了数学运算——在这里只有一个正确答案——意味着 AI 将具备更接近人类的推理能力。AI 研究者相信，这一技术可以应用于创新的科学研究。

与只能执行有限运算的计算器不同，AGI 能够进行泛化学习和理解。

研究人员在给董事会的信中提到了 AI 的强大能力和潜在危险，但消息来源没有具体说明信中提到的安全问题。长期以来，计算机科学家一直在讨论超级智能机器可能带来的风险，比如它们可能会认为摧毁人类符合自身利益。

在这种背景下，Altman 领导着使 ChatGPT 成为史上增长最快的软件应用之一的努力，并从微软那里获得了投资和必要的计算资源，以更接近于实现超级智能或 AGI。

在本月早些时候展示了一系列新工具之后，上周 Altman 在旧金山举行的世界领袖聚会上暗示，他认为 AGI 已经近在眼前。

“在 OpenAI 的历史中，最近一次是在过去几周，我已经四次有幸亲身经历推动认知界限的拓展和发现的前沿，能够参与其中是我职业生涯中的极大荣誉，”他在亚太经济合作组织峰会上说。

然而，就在第二天，董事会宣布解雇了 Altman。

在 AI 安全和人工通用智能（AGI）定义上，存在激烈争议。Microsoft 对 OpenAI 投入巨资，但后者的条款明确规定，不得利用 AGI 追求利益。

OpenAI 宪章指出：无论是与 Microsoft 还是其他商业和知识产权许可协议，AGI 都被明确排除在外。

Sam Altman 意识到，即使是现阶段的原型 AGI，也足以推动公司业绩飙升，带来巨额利润和更多投资。因此，他们推出了 Dev Day、GPT 商店和收入分成模式。

这一做法引起了 OAI 董事会的不满，部分董事仍坚持初衷，认为 AGI 应致力于人类福祉，而非商业利益。他们担忧此举可能导致不安全模型的使用。

目前 AGI 的定义并不明确。若实现重大突破（如 Sam 所述），是否将其归为 AGI 取决于董事会的投票。若获得足够票数宣布其为 AGI，Microsoft 和 OpenAI 将失去数十亿潜在许可收入；反之，他们可以通过授权类似 AGI 技术获利。

几周或几个月前，OpenAI 团队取得重大进展，接近实现 AGI（由此产生的玩笑、泄露、氛围变化等）。然而，Sam 和 Brockman 对此隐瞒了董事会的非员工成员。Ilyas 对此感到不满，认为这应视为 AGI，不应授权给任何人，包括 Microsoft。当 AGI 状态的投票提上日程时，董事们因被蒙在鼓里而愤怒，最终决定开除 Sam 并迫使 Brockman 辞职。

Ilyas 近期声称，现有架构已足够实现 AGI，而 Sam 则坚持认为需要新的突破。在这种情况下，Sam 更倾向于将 AGI 商业化，而 Ilyas 则认为我们已经实现了 AGI。

Sam Altman 想要推迟宣布这一技术为 AGI，因为这样做可以延长盈利时间。相反，Ilya 希望尽快将其定性为 AGI，以便按照公司最初的原则使用，而非追求利润。最终，Ilya 在这场权力争斗中胜出。在 Microsoft 还未来得及干预之前，事情已经尘埃落定，因为 Microsoft 表示他们对这一进展毫不知情，而他们显然会倾向于延迟 AGI 的宣布。

更早宣布 AGI 意味着该技术不能被授权给任何方（因此其带来的利润将更具社会公平性，并迫使研究人员专注于一致性和安全），同时还意味着更多监管。可以想象，“人工通用智能已被发明”的新闻头条将在 /r/WorldNews 上引发轰动，引起全球范围内的恐慌，迫使各国政府召开紧急会议，确保不发生 Skynet 式的灾难，安全派对此表示欢迎。

如果不是这样，情况会有所不同。我们可能会继续推进当前的前沿模型和代理共享计划，而不将其定性为 AGI，这样 OAI 和 Microsoft 将因此获得巨大利益。对于关注安全的群体而言，这意味着 AGI 的发展将受到更少监管，同时被加州原则融入到 ChatGPT 和 DALL-E 的输出中，从而让 OAI 可以宣称“我们确实关心安全！”

Ilya 可能并非有意赶走 Sam，但当收入分享方案被提出，而 Sam 辩称 OAI 所拥有的技术并非 AGI 或类似之物时，这可能促使 Ilya 决定发起政变。OpenAI 当前可能计划很快宣布他们已经拥有 AGI，可能在接下来的 6 到 8 个月内，也许是通过部署 GPT-4.5 或比预期更早发布 GPT-5。或许甚至更早。

这并非源于技术突破；而是基于他们已有的技术。这只是一个围绕是否为了利润而将该技术称为 AGI 的争议和冲突。

https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/</title>
            <link>https://nitter.cz/dotey/status/1727510593970561466#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727510593970561466#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 02:13:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：**独家：OpenAI 研究员在 CEO 被撤职前向董事会发出 AI 突破警告 — 据知情人士透露**<br />
<br />
11 月 22 日（路透社）- 在 OpenAI 首席执行官 Sam Altman 被迫离职前的四天，几位公司研究员向董事会发送了一封紧急信函，警告他们说，他们发现了一种强大的人工智能技术，这种技术可能对人类构成威胁。这一消息是由两位了解内情的人士向路透社透露的。<br />
<br />
这封此前未曾报道过的信件和相关的 AI 算法，是董事会决定撤换 Altman 的关键前奏。两位消息来源表示，Altman 被视为生成式 AI 的标志性人物。在他周二晚些时候的华丽归来之前，超过 700 名员工威胁要辞职，并表示将与被解雇的领导者一起支持投资者微软 (MSFT.O)。<br />
<br />
这些消息来源指出，这封信只是导致 Altman 被解雇的众多不满之一。路透社未能查看这封信的副本。写信的研究人员并未立即回应置评请求。<br />
<br />
据其中一位知情人士透露，资深高管 Mira Murati 上周三向员工提及了一个名为 Q* 的项目，并表示在周末发生的事件之前，已向董事会发送过一封信。<br />
<br />
在报道发布后，一位 OpenAI 发言人表示，Murati 告诉员工媒体即将报道的内容，但她并未对报道的准确性发表评论。<br />
<br />
制造 ChatGPT 的公司在 Q*（发音为 Q-Star）项目上取得了进展，一些内部人士认为这可能是该初创公司在追求超级智能（也称为人工通用智能，AGI）方向上的重大突破，一位人士告诉路透社。OpenAI 将 AGI 定义为智力超过人类的 AI 系统。<br />
<br />
该人士表示，凭借庞大的计算资源，这个新模型能够解决一些数学问题。这位不愿透露姓名的人士说，尽管 Q* 目前的数学运算能力仅限于小学生水平，但它在这些测试中的出色表现让研究人员对其未来的成功充满期望。<br />
<br />
路透社无法独立核实研究人员对 Q* 能力的说法。<br />
<br />
**超级智能的挑战**<br />
研究人员认为，数学是生成式 AI 发展的新前沿。目前，生成式 AI 在通过统计方法预测下一个词以进行写作和语言翻译方面表现良好，但面对同一个问题可能会有截然不同的答案。然而，掌握了数学运算——在这里只有一个正确答案——意味着 AI 将具备更接近人类的推理能力。AI 研究者相信，这一技术可以应用于创新的科学研究。<br />
<br />
与只能执行有限运算的计算器不同，AGI 能够进行泛化学习和理解。<br />
<br />
研究人员在给董事会的信中提到了 AI 的强大能力和潜在危险，但消息来源没有具体说明信中提到的安全问题。长期以来，计算机科学家一直在讨论超级智能机器可能带来的风险，比如它们可能会认为摧毁人类符合自身利益。<br />
<br />
在这种背景下，Altman 领导着使 ChatGPT 成为史上增长最快的软件应用之一的努力，并从微软那里获得了投资和必要的计算资源，以更接近于实现超级智能或 AGI。<br />
<br />
在本月早些时候展示了一系列新工具之后，上周 Altman 在旧金山举行的世界领袖聚会上暗示，他认为 AGI 已经近在眼前。<br />
<br />
“在 OpenAI 的历史中，最近一次是在过去几周，我已经四次有幸亲身经历推动认知界限的拓展和发现的前沿，能够参与其中是我职业生涯中的极大荣誉，”他在亚太经济合作组织峰会上说。<br />
<br />
然而，就在第二天，董事会宣布解雇了 Altman。<br />
<br />
在 AI 安全和人工通用智能（AGI）定义上，存在激烈争议。Microsoft 对 OpenAI 投入巨资，但后者的条款明确规定，不得利用 AGI 追求利益。<br />
<br />
OpenAI 宪章指出：无论是与 Microsoft 还是其他商业和知识产权许可协议，AGI 都被明确排除在外。<br />
<br />
Sam Altman 意识到，即使是现阶段的原型 AGI，也足以推动公司业绩飙升，带来巨额利润和更多投资。因此，他们推出了 Dev Day、GPT 商店和收入分成模式。<br />
<br />
这一做法引起了 OAI 董事会的不满，部分董事仍坚持初衷，认为 AGI 应致力于人类福祉，而非商业利益。他们担忧此举可能导致不安全模型的使用。<br />
<br />
目前 AGI 的定义并不明确。若实现重大突破（如 Sam 所述），是否将其归为 AGI 取决于董事会的投票。若获得足够票数宣布其为 AGI，Microsoft 和 OpenAI 将失去数十亿潜在许可收入；反之，他们可以通过授权类似 AGI 技术获利。<br />
<br />
几周或几个月前，OpenAI 团队取得重大进展，接近实现 AGI（由此产生的玩笑、泄露、氛围变化等）。然而，Sam 和 Brockman 对此隐瞒了董事会的非员工成员。Ilyas 对此感到不满，认为这应视为 AGI，不应授权给任何人，包括 Microsoft。当 AGI 状态的投票提上日程时，董事们因被蒙在鼓里而愤怒，最终决定开除 Sam 并迫使 Brockman 辞职。<br />
<br />
Ilyas 近期声称，现有架构已足够实现 AGI，而 Sam 则坚持认为需要新的突破。在这种情况下，Sam 更倾向于将 AGI 商业化，而 Ilyas 则认为我们已经实现了 AGI。<br />
<br />
Sam Altman 想要推迟宣布这一技术为 AGI，因为这样做可以延长盈利时间。相反，Ilya 希望尽快将其定性为 AGI，以便按照公司最初的原则使用，而非追求利润。最终，Ilya 在这场权力争斗中胜出。在 Microsoft 还未来得及干预之前，事情已经尘埃落定，因为 Microsoft 表示他们对这一进展毫不知情，而他们显然会倾向于延迟 AGI 的宣布。<br />
<br />
更早宣布 AGI 意味着该技术不能被授权给任何方（因此其带来的利润将更具社会公平性，并迫使研究人员专注于一致性和安全），同时还意味着更多监管。可以想象，“人工通用智能已被发明”的新闻头条将在 /r/WorldNews 上引发轰动，引起全球范围内的恐慌，迫使各国政府召开紧急会议，确保不发生 Skynet 式的灾难，安全派对此表示欢迎。<br />
<br />
如果不是这样，情况会有所不同。我们可能会继续推进当前的前沿模型和代理共享计划，而不将其定性为 AGI，这样 OAI 和 Microsoft 将因此获得巨大利益。对于关注安全的群体而言，这意味着 AGI 的发展将受到更少监管，同时被加州原则融入到 ChatGPT 和 DALL-E 的输出中，从而让 OAI 可以宣称“我们确实关心安全！”<br />
<br />
Ilya 可能并非有意赶走 Sam，但当收入分享方案被提出，而 Sam 辩称 OAI 所拥有的技术并非 AGI 或类似之物时，这可能促使 Ilya 决定发起政变。OpenAI 当前可能计划很快宣布他们已经拥有 AGI，可能在接下来的 6 到 8 个月内，也许是通过部署 GPT-4.5 或比预期更早发布 GPT-5。或许甚至更早。<br />
<br />
这并非源于技术突破；而是基于他们已有的技术。这只是一个围绕是否为了利润而将该技术称为 AGI 的争议和冲突。<br />
<br />
<a href="https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/">reuters.com/technology/sam-a…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727489479156318487#m</id>
            <title>1. 你自己要捋清楚其中的成本、收益和风险，也许没必要

2. 要让manager清楚收益远大于成本和风险

3. 要有清晰的计划，让Manager知道不会影响当前项目进展，例如：
-将要重构的模块列出来，加上T恤size
-先补充测试代码不会让重构影响质量
-将所有任务用任务管理跟踪工具跟踪起来
-每个Sprint完成一部分而不需要专门停下来做这事</title>
            <link>https://nitter.cz/dotey/status/1727489479156318487#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727489479156318487#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 00:49:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>1. 你自己要捋清楚其中的成本、收益和风险，也许没必要<br />
<br />
2. 要让manager清楚收益远大于成本和风险<br />
<br />
3. 要有清晰的计划，让Manager知道不会影响当前项目进展，例如：<br />
-将要重构的模块列出来，加上T恤size<br />
-先补充测试代码不会让重构影响质量<br />
-将所有任务用任务管理跟踪工具跟踪起来<br />
-每个Sprint完成一部分而不需要专门停下来做这事</p>
<p><a href="https://nitter.cz/beihuo/status/1727449107005067545#m">nitter.cz/beihuo/status/1727449107005067545#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727468251154620804#m</id>
            <title>#AI开源项目推荐：vscode-ui-sketcher

UI Sketcher是一个VSCode插件，借助GPT-4V的多模态能力，在插件中画出界面草图，就能生成一个基于ReactNative的UI界面。

需要OpenAI的API Key

https://github.com/pAIrprogio/vscode-ui-sketcher</title>
            <link>https://nitter.cz/dotey/status/1727468251154620804#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727468251154620804#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 23:25:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：vscode-ui-sketcher<br />
<br />
UI Sketcher是一个VSCode插件，借助GPT-4V的多模态能力，在插件中画出界面草图，就能生成一个基于ReactNative的UI界面。<br />
<br />
需要OpenAI的API Key<br />
<br />
<a href="https://github.com/pAIrprogio/vscode-ui-sketcher">github.com/pAIrprogio/vscode…</a></p>
<p><a href="https://nitter.cz/taishiyadeee/status/1727175786963300531#m">nitter.cz/taishiyadeee/status/1727175786963300531#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNjg5NjAxNTE4NDE1MDUyOC9sYUJZWlJCcj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/yumimao/status/1727240174994874805#m</id>
            <title>RT by @dotey: https://www.fal.ai/dynamic 一个简单的在线体验网站</title>
            <link>https://nitter.cz/yumimao/status/1727240174994874805#m</link>
            <guid isPermaLink="false">https://nitter.cz/yumimao/status/1727240174994874805#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 08:18:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://www.fal.ai/dynamic">fal.ai/dynamic</a> 一个简单的在线体验网站</p>
<p><a href="https://nitter.cz/RioJot/status/1727026140802670857#m">nitter.cz/RioJot/status/1727026140802670857#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9oanJpbGJzQUE0TFJ6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727456845646733767#m</id>
            <title>R to @dotey: 我让GPT-4V帮我分析了一下两张图：

----

由于我无法同时访问两张图片，我将分别对每张图片进行解读，然后基于我的解读进行对比分析。

对于第一张图片：

这是一个关于机器学习模型（称为Claude 2.1）的性能测试图。测试的目的是评估模型在不同文档深度和上下文长度下检索信息的准确性。图中的矩阵表格显示了不同的上下文长度（标记为“Context Length (# Tokens)”）和文档深度百分比（从顶部到底部）。颜色代码表示检索准确性，从绿色（更高准确性）到红色（较低准确性）。注释指出，随着上下文长度的增加，Claude 2.1的检索准确性逐渐下降。这表明模型在处理大量数据时可能会遇到困难。

对于第二张图片：

这张图与第一张相似，但针对的是不同的机器学习模型，即GPT-4。测试的目的是评估GPT-4在不同文档深度和上下文长度下的信息检索准确性。这张图同样显示了一个由不同上下文长度和文档深度组成的矩阵，并用颜色代码表示检索准确性。注释指出，当事实被放置在文档深度的10%-50%之间时，GPT-4的检索准确性开始下降，尤其是在大的上下文长度时。

对比分析：

两张图展示了两种不同的模型在不同条件下的性能测试。主要的比较点在于模型处理大量信息时的准确性。Claude 2.1的测试覆盖了更宽的上下文长度范围，而GPT-4的测试似乎集中在更小的数据集上，但进行了更多的样本测试以增加结果的稳定性。两张图表的颜色渐变表明，两个模型都在较大的上下文长度下表现出检索准确性下降的趋势，尽管具体的准确性水平和下降趋势在每个模型中是不同的。这些测试对于理解和改进机器学习模型在处理大规模数据时的性能至关重要。</title>
            <link>https://nitter.cz/dotey/status/1727456845646733767#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727456845646733767#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 22:39:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我让GPT-4V帮我分析了一下两张图：<br />
<br />
----<br />
<br />
由于我无法同时访问两张图片，我将分别对每张图片进行解读，然后基于我的解读进行对比分析。<br />
<br />
对于第一张图片：<br />
<br />
这是一个关于机器学习模型（称为Claude 2.1）的性能测试图。测试的目的是评估模型在不同文档深度和上下文长度下检索信息的准确性。图中的矩阵表格显示了不同的上下文长度（标记为“Context Length (# Tokens)”）和文档深度百分比（从顶部到底部）。颜色代码表示检索准确性，从绿色（更高准确性）到红色（较低准确性）。注释指出，随着上下文长度的增加，Claude 2.1的检索准确性逐渐下降。这表明模型在处理大量数据时可能会遇到困难。<br />
<br />
对于第二张图片：<br />
<br />
这张图与第一张相似，但针对的是不同的机器学习模型，即GPT-4。测试的目的是评估GPT-4在不同文档深度和上下文长度下的信息检索准确性。这张图同样显示了一个由不同上下文长度和文档深度组成的矩阵，并用颜色代码表示检索准确性。注释指出，当事实被放置在文档深度的10%-50%之间时，GPT-4的检索准确性开始下降，尤其是在大的上下文长度时。<br />
<br />
对比分析：<br />
<br />
两张图展示了两种不同的模型在不同条件下的性能测试。主要的比较点在于模型处理大量信息时的准确性。Claude 2.1的测试覆盖了更宽的上下文长度范围，而GPT-4的测试似乎集中在更小的数据集上，但进行了更多的样本测试以增加结果的稳定性。两张图表的颜色渐变表明，两个模型都在较大的上下文长度下表现出检索准确性下降的趋势，尽管具体的准确性水平和下降趋势在每个模型中是不同的。这些测试对于理解和改进机器学习模型在处理大规模数据时的性能至关重要。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9rbzFYT1c4QUVUVVl5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727454708627808261#m</id>
            <title>将Greg Kamradt的两次实验：
- GPT-4-128K https://twitter.com/dotey/status/1727445313261039717
- Claude 2.1 200K：https://twitter.com/dotey/status/1727437625194136060 

两次结果放一起对比，可以看到：

GPT-4-128K
1. 在上下文长度小于 73K Tokens时，不会有信息遗忘
2. 在上下文长度超出 73K 后，位于中间7%-50% 区间的信息可能会被遗忘

Claude-2.1-200K
1. 上下文长度小于24K时效果最好，几乎不会有信息遗忘
2. 上下文长度超过24K就开始变差，90K后，效果很差，一大半信息会遗忘
3. 最头部和最顶部的1%效果最好，不会被遗忘

我的总结
1. GPT-4还是最强的
2. 尽量少一些上下文，长文还是需要手动或者自动分割，GPT-4 的话，不要超过73K（输入输出加一起）
3. System Prompt 放在最前或者最后都可以，放在后面更好
4. 如果System Prompt 放在前面，对于GPT-4来说，不要超过5%，对于Claude来说不要超过1%
4. GPTs的Prompt只能放在最前面，所以不要超过不要超过5%也就是128*0.05 = 6.4 K Tokens比较好</title>
            <link>https://nitter.cz/dotey/status/1727454708627808261#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727454708627808261#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 22:31:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>将Greg Kamradt的两次实验：<br />
- GPT-4-128K <a href="https://nitter.cz/dotey/status/1727445313261039717">nitter.cz/dotey/status/172…</a><br />
- Claude 2.1 200K：<a href="https://nitter.cz/dotey/status/1727437625194136060">nitter.cz/dotey/status/172…</a> <br />
<br />
两次结果放一起对比，可以看到：<br />
<br />
GPT-4-128K<br />
1. 在上下文长度小于 73K Tokens时，不会有信息遗忘<br />
2. 在上下文长度超出 73K 后，位于中间7%-50% 区间的信息可能会被遗忘<br />
<br />
Claude-2.1-200K<br />
1. 上下文长度小于24K时效果最好，几乎不会有信息遗忘<br />
2. 上下文长度超过24K就开始变差，90K后，效果很差，一大半信息会遗忘<br />
3. 最头部和最顶部的1%效果最好，不会被遗忘<br />
<br />
我的总结<br />
1. GPT-4还是最强的<br />
2. 尽量少一些上下文，长文还是需要手动或者自动分割，GPT-4 的话，不要超过73K（输入输出加一起）<br />
3. System Prompt 放在最前或者最后都可以，放在后面更好<br />
4. 如果System Prompt 放在前面，对于GPT-4来说，不要超过5%，对于Claude来说不要超过1%<br />
4. GPTs的Prompt只能放在最前面，所以不要超过不要超过5%也就是128*0.05 = 6.4 K Tokens比较好</p>
<p><a href="https://nitter.cz/dotey/status/1727437625194136060#m">nitter.cz/dotey/status/1727437625194136060#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9rbC1fR1hrQUFLemNmLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9rbUE3U1hJQUFqSUY5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1727439351930638688#m</id>
            <title>RT by @dotey: GPT4 128k 有多强。
这真的不是一般的遥遥领先…</title>
            <link>https://nitter.cz/oran_ge/status/1727439351930638688#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1727439351930638688#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 21:30:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT4 128k 有多强。<br />
这真的不是一般的遥遥领先…</p>
<p><a href="https://nitter.cz/SteveMoraco/status/1727370446788530236#m">nitter.cz/SteveMoraco/status/1727370446788530236#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727445313261039717#m</id>
            <title>顺藤摸瓜找到 Greg Kamradt 对 GPT-4-128K 的 128K Token 上下文回忆能力进行了压力测试。一些关键结论：
1. Prompt 中的开头和结尾是最关键的，尤其是结尾部分；
2 .位于中间 7%-50% 区间的内容效果最差
3. 上下文越少，准确性越高，超过 73K Token 时，GPT-4-128K 的记忆性能开始下降。

以下是作者的原文：

用长篇幅上下文考验 GPT-4-128K 的记忆力

128K Token 的上下文听起来很厉害，但它的实际表现怎样呢？

为了找出答案，我进行了一项“大海捞针”的分析。

发现了一些意料之中和意料之外的结果。

我的发现如下：

**发现：**
* 超过 73K Token 时，GPT-4 的记忆性能开始下降。
* 当需要回忆的信息位于文档深度的 7%-50% 区间时，回忆表现较差。
* 如果信息位于文档开头，无论上下文有多长，它总能被记住。

**那么，这意味着什么？**
* 没有保证 - 你的信息不一定能被检索到。别指望你的应用程序能总是找到它们。
* 更少的上下文等于更高的准确性 - 这是常识，但如果可以的话，减少发送给 GPT-4 的上下文量可以提高其记忆准确性。
* 位置很关键 - 这也是常识，但放在文档开头和后半部分的信息似乎更容易被记住。

**分析过程概述：**
* 以 Paul Graham 的文章作为背景材料。有了 218 篇文章，轻松实现 128K Token。
* 在文档不同深度插入随机陈述。所用事实为：“在阳光明媚的日子里，在多洛雷斯公园吃三明治是在旧金山最佳活动。”
* 让 GPT-4 仅用提供的上下文来回答这个问题。
* 用 LangChainAI 的评估方法，再次用 GPT-4 对其答案进行评估。
* 对 15 种不同文档深度（从文档顶端的 0% 到底部的 100%）和 15 种上下文长度（1K Token 至 128K Token）进行重复测试。

**为了深入研究，接下来可以采取的步骤：**
* 尽管这些分析是均匀分布的，但有人建议用 sigmoid 分布可能会更好（这样可以在文档的开始和结束阶段发现更多细节）。
* 为了更严谨，应该进行键值对检索。但为了增加相关性，我在 Paul Graham 的文章中加入了关于旧金山的描述。

**备注：**
* 虽然我认为这些发现方向上是正确的，但需要更多测试来更深入地了解 GPT-4 的能力。
* 改变提示可能会改变结果。
* 在长上下文中进行了两次测试，以便更深入地挖掘性能。
* 这次测试大约花费了 200 美元用于 API 调用（单次调用 128K 输入 Token 的成本为 1.28 美元）。
* 感谢 Charles 🎉 Frye 提供意见和建议下一步的方向。</title>
            <link>https://nitter.cz/dotey/status/1727445313261039717#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727445313261039717#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 21:53:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>顺藤摸瓜找到 Greg Kamradt 对 GPT-4-128K 的 128K Token 上下文回忆能力进行了压力测试。一些关键结论：<br />
1. Prompt 中的开头和结尾是最关键的，尤其是结尾部分；<br />
2 .位于中间 7%-50% 区间的内容效果最差<br />
3. 上下文越少，准确性越高，超过 73K Token 时，GPT-4-128K 的记忆性能开始下降。<br />
<br />
以下是作者的原文：<br />
<br />
用长篇幅上下文考验 GPT-4-128K 的记忆力<br />
<br />
128K Token 的上下文听起来很厉害，但它的实际表现怎样呢？<br />
<br />
为了找出答案，我进行了一项“大海捞针”的分析。<br />
<br />
发现了一些意料之中和意料之外的结果。<br />
<br />
我的发现如下：<br />
<br />
**发现：**<br />
* 超过 73K Token 时，GPT-4 的记忆性能开始下降。<br />
* 当需要回忆的信息位于文档深度的 7%-50% 区间时，回忆表现较差。<br />
* 如果信息位于文档开头，无论上下文有多长，它总能被记住。<br />
<br />
**那么，这意味着什么？**<br />
* 没有保证 - 你的信息不一定能被检索到。别指望你的应用程序能总是找到它们。<br />
* 更少的上下文等于更高的准确性 - 这是常识，但如果可以的话，减少发送给 GPT-4 的上下文量可以提高其记忆准确性。<br />
* 位置很关键 - 这也是常识，但放在文档开头和后半部分的信息似乎更容易被记住。<br />
<br />
**分析过程概述：**<br />
* 以 Paul Graham 的文章作为背景材料。有了 218 篇文章，轻松实现 128K Token。<br />
* 在文档不同深度插入随机陈述。所用事实为：“在阳光明媚的日子里，在多洛雷斯公园吃三明治是在旧金山最佳活动。”<br />
* 让 GPT-4 仅用提供的上下文来回答这个问题。<br />
* 用 LangChainAI 的评估方法，再次用 GPT-4 对其答案进行评估。<br />
* 对 15 种不同文档深度（从文档顶端的 0% 到底部的 100%）和 15 种上下文长度（1K Token 至 128K Token）进行重复测试。<br />
<br />
**为了深入研究，接下来可以采取的步骤：**<br />
* 尽管这些分析是均匀分布的，但有人建议用 sigmoid 分布可能会更好（这样可以在文档的开始和结束阶段发现更多细节）。<br />
* 为了更严谨，应该进行键值对检索。但为了增加相关性，我在 Paul Graham 的文章中加入了关于旧金山的描述。<br />
<br />
**备注：**<br />
* 虽然我认为这些发现方向上是正确的，但需要更多测试来更深入地了解 GPT-4 的能力。<br />
* 改变提示可能会改变结果。<br />
* 在长上下文中进行了两次测试，以便更深入地挖掘性能。<br />
* 这次测试大约花费了 200 美元用于 API 调用（单次调用 128K 输入 Token 的成本为 1.28 美元）。<br />
* 感谢 Charles 🎉 Frye 提供意见和建议下一步的方向。</p>
<p><a href="https://nitter.cz/GregKamradt/status/1722386725635580292#m">nitter.cz/GregKamradt/status/1722386725635580292#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727437625194136060#m</id>
            <title>这是一个至少价值 $1016 的实验，作者 Greg Kamradt 对 Claude 2.1 的 200k Token 上下文回忆能力进行了压力测试。一些关键结论：
1. Prompt 中的开头和结尾是最关键的，尤其是结尾部分
2. 上下文越少，准确性越高，超过 90K Token 的上下文长度，回忆能力会逐渐变差

以下是作者的原文：

Claude 2.1（20 万 Token）- 长篇上下文回忆能力的压力测试

提高上下文长度听起来很棒，但实际效果如何呢？

Anthropic 让我提前体验了 Claude 2.1，所以我用它重做了我之前对 GPT-4 的“大海捞针”分析。这里是我的一些发现：

发现：
* 在长达 20 万 Token（大约 470 页）的文档中，Claude 2.1 能够在特定深度回忆起某些事实。
* 文档最顶端和最底端的事实几乎能被完美回忆。
* 文档顶部的事实比底部的回忆效果差一些（和 GPT-4 类似）。
* 从约 9 万 Token 开始，文档底部的回忆效果逐渐变差。
* 在较短的上下文长度下，并不能保证回忆效果。

所以：
* 提示工程很关键 - 调整你的提示语并通过 A/B 测试来衡量信息检索的准确性是值得尝试的。
* 没有保证 - 事实并不一定会被准确检索出来，不要把它们一定能被找到的假设作为应用的基础。
* 上下文越少，准确性越高 - 这是常识，但尽可能减少发送给模型的上下文量可以提高回忆能力。
* 位置很关键 - 众所周知，放在文档开头和后半部分的事实似乎更容易被回忆起。

为什么要做这个测试？
* 我非常看好 Anthropic！他们在推动大语言模型的性能发展，为全球创造了强大的工具。
* 作为一名大语言模型的使用者，理解这些模型的工作方式、优势和局限性至关重要。
* 这类测试虽然不是绝对可靠，但可以展示真实世界的案例，让人感受到这些模型的工作原理。目的是将这些知识应用到实际的使用场景中。

过程概述：
* 以 Paul Graham 的文章作为背景材料。有了 218 篇文章，很容易就能堆积到 20 万 Token（必要时重复使用文章）。
* 在文档不同深度插入随机的陈述。使用的事实是：“在旧金山，最好的事情是在阳光明媚的一天里，在多洛雷斯公园吃三明治。”
* 让 Claude 2.1 仅使用提供的上下文来回答这个问题。
* 使用 LangChainAI 的评估工具，将 Claude 2.1 的答案与 GPT-4 进行比较。
* 在文档深度从 0%（文档顶部）到 100%（文档底部）（采用 sigmoid 分布），以及 35 种不同的上下文长度（从 1K Token 到 20 万 Token）中重复进行 35 次测试。

更进一步的后续步骤：
* 为了更严谨，应该进行键值对检索。但为了易懂性，我选择了在 Paul Graham 文章中加入关于旧金山的语句，这样做更直观和实用。
* 为了增强统计意义，应重复多次测试。

备注：
* 回忆的数量很关键 - 当模型被要求同时回忆多个事实或进行合成推理时，其性能可能会降低。
* 更改提示语、问题、待检索的事实和背景上下文都会影响性能。
* Anthropic 团队提供了测试信用，并给出了最大化性能的提示建议。需要明确的是，他们的参与仅限于提供后勤支持。这项测试保持了独立性和完整性，确保我的发现是无偏见的，没有受到他们支持的影响。
* 这项测试的 API 调用成本大约为 1016 美元（每百万 Token 8 美元）。</title>
            <link>https://nitter.cz/dotey/status/1727437625194136060#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727437625194136060#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 21:23:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这是一个至少价值 $1016 的实验，作者 Greg Kamradt 对 Claude 2.1 的 200k Token 上下文回忆能力进行了压力测试。一些关键结论：<br />
1. Prompt 中的开头和结尾是最关键的，尤其是结尾部分<br />
2. 上下文越少，准确性越高，超过 90K Token 的上下文长度，回忆能力会逐渐变差<br />
<br />
以下是作者的原文：<br />
<br />
Claude 2.1（20 万 Token）- 长篇上下文回忆能力的压力测试<br />
<br />
提高上下文长度听起来很棒，但实际效果如何呢？<br />
<br />
Anthropic 让我提前体验了 Claude 2.1，所以我用它重做了我之前对 GPT-4 的“大海捞针”分析。这里是我的一些发现：<br />
<br />
发现：<br />
* 在长达 20 万 Token（大约 470 页）的文档中，Claude 2.1 能够在特定深度回忆起某些事实。<br />
* 文档最顶端和最底端的事实几乎能被完美回忆。<br />
* 文档顶部的事实比底部的回忆效果差一些（和 GPT-4 类似）。<br />
* 从约 9 万 Token 开始，文档底部的回忆效果逐渐变差。<br />
* 在较短的上下文长度下，并不能保证回忆效果。<br />
<br />
所以：<br />
* 提示工程很关键 - 调整你的提示语并通过 A/B 测试来衡量信息检索的准确性是值得尝试的。<br />
* 没有保证 - 事实并不一定会被准确检索出来，不要把它们一定能被找到的假设作为应用的基础。<br />
* 上下文越少，准确性越高 - 这是常识，但尽可能减少发送给模型的上下文量可以提高回忆能力。<br />
* 位置很关键 - 众所周知，放在文档开头和后半部分的事实似乎更容易被回忆起。<br />
<br />
为什么要做这个测试？<br />
* 我非常看好 Anthropic！他们在推动大语言模型的性能发展，为全球创造了强大的工具。<br />
* 作为一名大语言模型的使用者，理解这些模型的工作方式、优势和局限性至关重要。<br />
* 这类测试虽然不是绝对可靠，但可以展示真实世界的案例，让人感受到这些模型的工作原理。目的是将这些知识应用到实际的使用场景中。<br />
<br />
过程概述：<br />
* 以 Paul Graham 的文章作为背景材料。有了 218 篇文章，很容易就能堆积到 20 万 Token（必要时重复使用文章）。<br />
* 在文档不同深度插入随机的陈述。使用的事实是：“在旧金山，最好的事情是在阳光明媚的一天里，在多洛雷斯公园吃三明治。”<br />
* 让 Claude 2.1 仅使用提供的上下文来回答这个问题。<br />
* 使用 LangChainAI 的评估工具，将 Claude 2.1 的答案与 GPT-4 进行比较。<br />
* 在文档深度从 0%（文档顶部）到 100%（文档底部）（采用 sigmoid 分布），以及 35 种不同的上下文长度（从 1K Token 到 20 万 Token）中重复进行 35 次测试。<br />
<br />
更进一步的后续步骤：<br />
* 为了更严谨，应该进行键值对检索。但为了易懂性，我选择了在 Paul Graham 文章中加入关于旧金山的语句，这样做更直观和实用。<br />
* 为了增强统计意义，应重复多次测试。<br />
<br />
备注：<br />
* 回忆的数量很关键 - 当模型被要求同时回忆多个事实或进行合成推理时，其性能可能会降低。<br />
* 更改提示语、问题、待检索的事实和背景上下文都会影响性能。<br />
* Anthropic 团队提供了测试信用，并给出了最大化性能的提示建议。需要明确的是，他们的参与仅限于提供后勤支持。这项测试保持了独立性和完整性，确保我的发现是无偏见的，没有受到他们支持的影响。<br />
* 这项测试的 API 调用成本大约为 1016 美元（每百万 Token 8 美元）。</p>
<p><a href="https://nitter.cz/GregKamradt/status/1727018183608193393#m">nitter.cz/GregKamradt/status/1727018183608193393#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727431967820468675#m</id>
            <title>《揭秘 Altman 重返 OpenAI 背后的政变与妥协》
来自彭博社的最新更新，讲述了一些幕后的故事，估计董事会没想到临时找的  Emmett Shear  竟成了扳倒他们的关键，太戏剧了。

----

- 激烈的谈判、员工集体离职的威胁，以及双方的相互让步，共同铺就了 Altman 重返 OpenAI 的惊人之路。

在一系列激烈的谈判、员工可能集体离职的威胁，以及双方的相互妥协之后，Sam Altman 惊人地重返 OpenAI 的故事终于尘埃落定。

这个让 OpenAI 成为全球知名的人工智能初创企业的核心团队，周二聚集在 Altman 位于旧金山的家中，与公司董事会展开激烈较量，试图让他重新成为首席执行官。这场斗争已经成为硅谷历史上最引人注目的企业权力争夺战之一。

OpenAI 的首席技术官、也曾是临时首席执行官的 Mira Murati，在周二通过 Slack 向全公司发送消息：“我们还在努力中……”。她还附上了一张照片，显示她和其他高管围坐在 Altman 家的半圆形沙发上，被解职的 Altman 穿着醒目的绿色运动裤，专注地看着屏幕。这张照片激起了员工们的热烈响应，他们用大量表情符号表达支持，毕竟过去五天里，他们对工作、股权和公司的未来都充满了不确定。

周二晚些时候，员工们终于迎来了转机。OpenAI 宣布达成了一项协议，Altman 将作为首席执行官重返公司，同时由 Bret Taylor（Salesforce Inc. 前联合首席执行官）领导的新董事会将接手运营。其他初始董事会成员包括前美国财政部长 Larry Summers 和现任成员、Quora Inc. 联合创始人兼首席执行官 Adam D’Angelo。“我们正在合作，敲定细节，”OpenAI 在 X（前 Twitter）上发布消息称。

当这一消息在 OpenAI 旧金山办公室传开时，数十人欢呼庆祝，一位在场者透露。在公司的 Slack 上，员工们对 Murati 宣布周一“重新开始工作”的消息做出了热烈反应，随后不久，一场即兴派对随之展开。

尽管人们普遍感到如释重负，准备恢复日常工作，但仍有许多细节待解决。董事会的最终构成尚未确定，董事会最初解雇 Altman 的具体原因也尚未明确。OpenAI 还将面临作为开发强大——对某些人来说，甚至是令人恐惧——技术的公司，却运作混乱的新名声。但至少现在，Altman 的回归使这家极具影响力、估值极高的初创公司避免了崩溃的边缘。

一年前，OpenAI 凭借其极受欢迎的聊天机器人 ChatGPT 改变了公众对 AI 的看法，将 Altman 塑造成人工智能行业的面孔。但由于与董事会成员在快速开发和商业化生成式 AI 上的分歧，他被董事会解雇，据知情人士透露。他的解职震惊了投资界，并促使几乎所有员工辞职，跟随 Altman 加入 OpenAI 最大的支持者——Microsoft Corp.，后者已同意让他领导一个新成立的内部 AI 部门。

尽管面临巨大压力，但在周五解雇 Altman 后，OpenAI 董事会基本拒绝与他接触。董事会随后在周日晚上任命了 Twitch 联合创始人兼前首席 Emmett Shear 为第二任临时首席执行官，此前 Murati 倡导 Altman 应回归公司。那天晚上晚些时候，公司首席科学家兼董事会成员 Ilya Sutskever 试图召集 OpenAI 员工在旧金山总部开会，但几乎无人出席，一位知情人士透露。

截至周二，当 OpenAI 的 770 名员工中有超过 700 人签署了一封威胁辞职的信后，Altman 开始与董事会成员 D’Angelo 进行谈判，据了解。Sutskever 也在签署信的员工中，此前他对“董事会行为表示遗憾”。

为了达成协议，谈判双方做出了关键让步。据悉，Altman 同意不加入初始董事会，尽管有人预期他最终可能成为董事。双方还同意就 Altman 被罢免的事件进行独立调查。

据一位知情人士称，Shear 加入谈判对达成协议至关重要。彭博社报道称，Shear 一直对 AI 的潜在风险表达关切，这对 OpenAI 的董事会成员具有吸引力。“加入 OpenAI 时，我不确定什么是正确的道路，”Shear 在 Altman 重返公司后在 X 上写道。“这是既确保安全又顾及所有利益相关方的最佳路径。”

在努力敲定协议的过程中，他们还面临了后勤问题。据一位人士透露，在谈判期间，一位董事会成员在飞机上无法通讯数小时。人们还希望在感恩节前解决领导层的混乱，以免员工在节假日担忧自己的工作状态。

许多员工不仅仅是工作岌岌可危。该公司原本计划以 860 亿美元的估值向投资者出售员工股份，但领导层的动荡使这些计划面临风险。有些员工在这笔交易中可能赚取数百万美元，但如果 OpenAI 超过 90% 的员工辞职，这笔交易就无法进行了。（据知情人士称，由 Thrive Capital 主导的这笔要约现在已重新回到正轨。）

一家竞争对手 AI 公司透露，它收到了多个来自 OpenAI 员工的询问，他们对未来的职业机会感到不安，据一位不愿透露姓名的知情人士称。像 Salesforce 的首席执行官 Marc Benioff 这样的几位科技高管在社交媒体上明确表示，他们愿意欢迎这些员工。同时，一些竞争对手 AI 公司也经历了客户需求的增长。

在周二达成协议的几小时前，一位 OpenAI 高管鼓励员工“重新投入到产品发布中”。本周休假的员工被告知，他们也可以报销比萨饼。“这几天确实充满了挑战，”公司副总裁 Peter Deng 在 Slack 上写道，并被彭博新闻社看到。他强调公司仍然致力于其使命。“举起一片比萨，分享一张照片到讨论区，让我们一起享受这个时刻。”

Altman 重返公司的消息一经宣布，OpenAI 的总法律顾问 Che Chang 通过 Slack 邀请员工到办公室参加一个与 Altman 的“简短庆祝”。然而到了周三早上，庆祝活动已经结束。据一位人士透露，员工们由于连日的纷争感到疲惫不堪，大多数人已经开始准备迎接感恩节。

https://www.bloomberg.com/news/articles/2023-11-22/inside-the-coups-and-concessions-that-brought-altman-back-to-openai#xj4y7vzkg</title>
            <link>https://nitter.cz/dotey/status/1727431967820468675#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727431967820468675#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 21:00:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《揭秘 Altman 重返 OpenAI 背后的政变与妥协》<br />
来自彭博社的最新更新，讲述了一些幕后的故事，估计董事会没想到临时找的  Emmett Shear  竟成了扳倒他们的关键，太戏剧了。<br />
<br />
----<br />
<br />
- 激烈的谈判、员工集体离职的威胁，以及双方的相互让步，共同铺就了 Altman 重返 OpenAI 的惊人之路。<br />
<br />
在一系列激烈的谈判、员工可能集体离职的威胁，以及双方的相互妥协之后，Sam Altman 惊人地重返 OpenAI 的故事终于尘埃落定。<br />
<br />
这个让 OpenAI 成为全球知名的人工智能初创企业的核心团队，周二聚集在 Altman 位于旧金山的家中，与公司董事会展开激烈较量，试图让他重新成为首席执行官。这场斗争已经成为硅谷历史上最引人注目的企业权力争夺战之一。<br />
<br />
OpenAI 的首席技术官、也曾是临时首席执行官的 Mira Murati，在周二通过 Slack 向全公司发送消息：“我们还在努力中……”。她还附上了一张照片，显示她和其他高管围坐在 Altman 家的半圆形沙发上，被解职的 Altman 穿着醒目的绿色运动裤，专注地看着屏幕。这张照片激起了员工们的热烈响应，他们用大量表情符号表达支持，毕竟过去五天里，他们对工作、股权和公司的未来都充满了不确定。<br />
<br />
周二晚些时候，员工们终于迎来了转机。OpenAI 宣布达成了一项协议，Altman 将作为首席执行官重返公司，同时由 Bret Taylor（Salesforce Inc. 前联合首席执行官）领导的新董事会将接手运营。其他初始董事会成员包括前美国财政部长 Larry Summers 和现任成员、Quora Inc. 联合创始人兼首席执行官 Adam D’Angelo。“我们正在合作，敲定细节，”OpenAI 在 X（前 Twitter）上发布消息称。<br />
<br />
当这一消息在 OpenAI 旧金山办公室传开时，数十人欢呼庆祝，一位在场者透露。在公司的 Slack 上，员工们对 Murati 宣布周一“重新开始工作”的消息做出了热烈反应，随后不久，一场即兴派对随之展开。<br />
<br />
尽管人们普遍感到如释重负，准备恢复日常工作，但仍有许多细节待解决。董事会的最终构成尚未确定，董事会最初解雇 Altman 的具体原因也尚未明确。OpenAI 还将面临作为开发强大——对某些人来说，甚至是令人恐惧——技术的公司，却运作混乱的新名声。但至少现在，Altman 的回归使这家极具影响力、估值极高的初创公司避免了崩溃的边缘。<br />
<br />
一年前，OpenAI 凭借其极受欢迎的聊天机器人 ChatGPT 改变了公众对 AI 的看法，将 Altman 塑造成人工智能行业的面孔。但由于与董事会成员在快速开发和商业化生成式 AI 上的分歧，他被董事会解雇，据知情人士透露。他的解职震惊了投资界，并促使几乎所有员工辞职，跟随 Altman 加入 OpenAI 最大的支持者——Microsoft Corp.，后者已同意让他领导一个新成立的内部 AI 部门。<br />
<br />
尽管面临巨大压力，但在周五解雇 Altman 后，OpenAI 董事会基本拒绝与他接触。董事会随后在周日晚上任命了 Twitch 联合创始人兼前首席 Emmett Shear 为第二任临时首席执行官，此前 Murati 倡导 Altman 应回归公司。那天晚上晚些时候，公司首席科学家兼董事会成员 Ilya Sutskever 试图召集 OpenAI 员工在旧金山总部开会，但几乎无人出席，一位知情人士透露。<br />
<br />
截至周二，当 OpenAI 的 770 名员工中有超过 700 人签署了一封威胁辞职的信后，Altman 开始与董事会成员 D’Angelo 进行谈判，据了解。Sutskever 也在签署信的员工中，此前他对“董事会行为表示遗憾”。<br />
<br />
为了达成协议，谈判双方做出了关键让步。据悉，Altman 同意不加入初始董事会，尽管有人预期他最终可能成为董事。双方还同意就 Altman 被罢免的事件进行独立调查。<br />
<br />
据一位知情人士称，Shear 加入谈判对达成协议至关重要。彭博社报道称，Shear 一直对 AI 的潜在风险表达关切，这对 OpenAI 的董事会成员具有吸引力。“加入 OpenAI 时，我不确定什么是正确的道路，”Shear 在 Altman 重返公司后在 X 上写道。“这是既确保安全又顾及所有利益相关方的最佳路径。”<br />
<br />
在努力敲定协议的过程中，他们还面临了后勤问题。据一位人士透露，在谈判期间，一位董事会成员在飞机上无法通讯数小时。人们还希望在感恩节前解决领导层的混乱，以免员工在节假日担忧自己的工作状态。<br />
<br />
许多员工不仅仅是工作岌岌可危。该公司原本计划以 860 亿美元的估值向投资者出售员工股份，但领导层的动荡使这些计划面临风险。有些员工在这笔交易中可能赚取数百万美元，但如果 OpenAI 超过 90% 的员工辞职，这笔交易就无法进行了。（据知情人士称，由 Thrive Capital 主导的这笔要约现在已重新回到正轨。）<br />
<br />
一家竞争对手 AI 公司透露，它收到了多个来自 OpenAI 员工的询问，他们对未来的职业机会感到不安，据一位不愿透露姓名的知情人士称。像 Salesforce 的首席执行官 Marc Benioff 这样的几位科技高管在社交媒体上明确表示，他们愿意欢迎这些员工。同时，一些竞争对手 AI 公司也经历了客户需求的增长。<br />
<br />
在周二达成协议的几小时前，一位 OpenAI 高管鼓励员工“重新投入到产品发布中”。本周休假的员工被告知，他们也可以报销比萨饼。“这几天确实充满了挑战，”公司副总裁 Peter Deng 在 Slack 上写道，并被彭博新闻社看到。他强调公司仍然致力于其使命。“举起一片比萨，分享一张照片到讨论区，让我们一起享受这个时刻。”<br />
<br />
Altman 重返公司的消息一经宣布，OpenAI 的总法律顾问 Che Chang 通过 Slack 邀请员工到办公室参加一个与 Altman 的“简短庆祝”。然而到了周三早上，庆祝活动已经结束。据一位人士透露，员工们由于连日的纷争感到疲惫不堪，大多数人已经开始准备迎接感恩节。<br />
<br />
<a href="https://www.bloomberg.com/news/articles/2023-11-22/inside-the-coups-and-concessions-that-brought-altman-back-to-openai#xj4y7vzkg">bloomberg.com/news/articles/…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/sundyme/status/1727395143416950865#m</id>
            <title>RT by @dotey: 马斯克刚刚宣布特斯拉 Roadster  跑车的所有设计和工程文件完全开源，并给出了下载链接。看了下，还包括不同版本用户手册的PDF 文档，这些资料对很多领域的朋友都是很好的学习资料。@elonmusk 老马太伟大了！👍🏻
https://service.tesla.com/roadster</title>
            <link>https://nitter.cz/sundyme/status/1727395143416950865#m</link>
            <guid isPermaLink="false">https://nitter.cz/sundyme/status/1727395143416950865#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 18:34:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>马斯克刚刚宣布特斯拉 Roadster  跑车的所有设计和工程文件完全开源，并给出了下载链接。看了下，还包括不同版本用户手册的PDF 文档，这些资料对很多领域的朋友都是很好的学习资料。<a href="https://nitter.cz/elonmusk" title="Elon Musk">@elonmusk</a> 老马太伟大了！👍🏻<br />
<a href="https://service.tesla.com/roadster">service.tesla.com/roadster</a></p>
<p><a href="https://nitter.cz/elonmusk/status/1727392569238159491#m">nitter.cz/elonmusk/status/1727392569238159491#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/vikingmute/status/1727237756890624398#m</id>
            <title>RT by @dotey: 通过这个工具，让我找到了它底层使用的宝藏爬虫工具 - Crawlee

https://crawlee.dev/

它的技术栈非常新，功能很强大，如果你想在 2023年做一个爬虫或者浏览器行为模拟工具，这个应该是最棒的，有这些特性：

* 两种模式，HTTP 和 Headless 模式，Headless 模式是基于真实的浏览器模拟（基于 Puppeteer and Playwright），爬取 JS 渲染的内容也不在话下。并且添加了特殊的 anti-blocking 以及 human-like fingerprints 机制，让你的爬虫被封的概率大大降低了。

* 根据你的电脑资源自动切换并发的数量。

* 内置 Cheerio 和 JSDOM ，分析 DOM 结构也很方便。

我简单用了一下，非常方便，强烈推荐给大家。

Stars：9.6K</title>
            <link>https://nitter.cz/vikingmute/status/1727237756890624398#m</link>
            <guid isPermaLink="false">https://nitter.cz/vikingmute/status/1727237756890624398#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 08:09:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>通过这个工具，让我找到了它底层使用的宝藏爬虫工具 - Crawlee<br />
<br />
<a href="https://crawlee.dev/">crawlee.dev/</a><br />
<br />
它的技术栈非常新，功能很强大，如果你想在 2023年做一个爬虫或者浏览器行为模拟工具，这个应该是最棒的，有这些特性：<br />
<br />
* 两种模式，HTTP 和 Headless 模式，Headless 模式是基于真实的浏览器模拟（基于 Puppeteer and Playwright），爬取 JS 渲染的内容也不在话下。并且添加了特殊的 anti-blocking 以及 human-like fingerprints 机制，让你的爬虫被封的概率大大降低了。<br />
<br />
* 根据你的电脑资源自动切换并发的数量。<br />
<br />
* 内置 Cheerio 和 JSDOM ，分析 DOM 结构也很方便。<br />
<br />
我简单用了一下，非常方便，强烈推荐给大家。<br />
<br />
Stars：9.6K</p>
<p><a href="https://nitter.cz/vikingmute/status/1727135789027610749#m">nitter.cz/vikingmute/status/1727135789027610749#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9oaGpTamFBQUF1cFloLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727384378802626591#m</id>
            <title>Meta 的新论文：
System 2 Attention (is something you might need too)

System 2 Attention (S2A)。
- 在 Transformer 技术中，软注意力机制容易被无关或带有偏见的信息所干扰
- S2A 利用大语言模型（LLM）的推理功能来决定应该关注哪些内容

S2A 可以提升信息的准确性，减少无用的废话。

详情参见：https://arxiv.org/abs/2311.11829</title>
            <link>https://nitter.cz/dotey/status/1727384378802626591#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727384378802626591#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 17:51:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta 的新论文：<br />
System 2 Attention (is something you might need too)<br />
<br />
System 2 Attention (S2A)。<br />
- 在 Transformer 技术中，软注意力机制容易被无关或带有偏见的信息所干扰<br />
- S2A 利用大语言模型（LLM）的推理功能来决定应该关注哪些内容<br />
<br />
S2A 可以提升信息的准确性，减少无用的废话。<br />
<br />
详情参见：<a href="https://arxiv.org/abs/2311.11829">arxiv.org/abs/2311.11829</a></p>
<p><a href="https://nitter.cz/jaseweston/status/1726784511357157618#m">nitter.cz/jaseweston/status/1726784511357157618#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1727368062356300062#m</id>
            <title>RT by @dotey: HeyPi的母公司发布Inflection-2，宣传是世界第2好的LLM。
emm...</title>
            <link>https://nitter.cz/Gorden_Sun/status/1727368062356300062#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1727368062356300062#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 16:46:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HeyPi的母公司发布Inflection-2，宣传是世界第2好的LLM。<br />
emm...</p>
<p><a href="https://nitter.cz/inflectionAI/status/1727350646938960205#m">nitter.cz/inflectionAI/status/1727350646938960205#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1727378877046239415#m</id>
            <title>OpenAI 新旧 CEO 在 X 上进行了友好互动！</title>
            <link>https://nitter.cz/dotey/status/1727378877046239415#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1727378877046239415#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 17:29:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 新旧 CEO 在 X 上进行了友好互动！</p>
<p><a href="https://nitter.cz/sama/status/1727366563542815075#m">nitter.cz/sama/status/1727366563542815075#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/sundyme/status/1727373836247515348#m</id>
            <title>RT by @dotey: 神奇的浏览器窗口交互效果，技术细节是：使用 javascript， window.getScreenDetails() api 跟踪窗口并通过 localStorage 进行通信。</title>
            <link>https://nitter.cz/sundyme/status/1727373836247515348#m</link>
            <guid isPermaLink="false">https://nitter.cz/sundyme/status/1727373836247515348#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 17:09:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>神奇的浏览器窗口交互效果，技术细节是：使用 javascript， window.getScreenDetails() api 跟踪窗口并通过 localStorage 进行通信。</p>
<p><a href="https://nitter.cz/LinusEkenstam/status/1727357730833530954#m">nitter.cz/LinusEkenstam/status/1727357730833530954#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>