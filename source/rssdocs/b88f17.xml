<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729172682758054147#m</id>
            <title>RT by @dotey: Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。
将这种方法扩展是否能实现通用人工智能（AGI）？不会。
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</title>
            <link>https://nitter.cz/op7418/status/1729172682758054147#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729172682758054147#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:17:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：<br />
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。<br />
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。<br />
将这种方法扩展是否能实现通用人工智能（AGI）？不会。<br />
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。<br />
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</p>
<p><a href="https://nitter.cz/DrJimFan/status/1729162728072433876#m">nitter.cz/DrJimFan/status/1729162728072433876#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</id>
            <title>RT by @dotey: 建议和这篇《为什么你不该加入 Y Combinator》https://readit.vip/a/e0Bwj  一起阅读。

作者反对保罗这种只以增长为目标的做法。

1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</title>
            <link>https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</link>
            <guid isPermaLink="false">https://nitter.cz/OwenYoungZh/status/1729137385890586818#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 13:57:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>建议和这篇《为什么你不该加入 Y Combinator》<a href="https://readit.vip/a/e0Bwj">readit.vip/a/e0Bwj</a>  一起阅读。<br />
<br />
作者反对保罗这种只以增长为目标的做法。<br />
<br />
1.  你投入了你全部的精力在寻找一张彩票，这对广撒网的YC是件好事。<br />
2. 你的企业增长不到10倍，对不起，即使这能让你过上一个滋润的生活，但达不到硅谷的标准，你被淘汰。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZXRtdmFrQUFMRFBtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl84ZnFEcWJnQUFhMGJ2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Tisoga/status/1729017824092549247#m</id>
            <title>RT by @dotey: 这应该就是做产品最希望收到的评价吧。

另外 http://devv.ai 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。

欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</title>
            <link>https://nitter.cz/Tisoga/status/1729017824092549247#m</link>
            <guid isPermaLink="false">https://nitter.cz/Tisoga/status/1729017824092549247#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:02:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这应该就是做产品最希望收到的评价吧。<br />
<br />
另外 <a href="http://devv.ai">devv.ai</a> 背后是一线美元基金支持的公司，所以大家不用担心团队会跑路 or 产品会突然下线，商业化也已经在 roadmap 中了，免费的搜索功能会一直保留。<br />
<br />
欢饮大家多多给我们提建议 or 反馈，如果方便的用户也可以直接和我约 1:1 的线上 meeting 来聊一聊。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82ejBRVmIwQUFYUDAzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729026599411225075#m</id>
            <title>R to @dotey: 谢谢</title>
            <link>https://nitter.cz/dotey/status/1729026599411225075#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729026599411225075#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:37:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谢谢</p>
<p><a href="https://nitter.cz/Nag1ovo/status/1729018702048493634#m">nitter.cz/Nag1ovo/status/1729018702048493634#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728998748272156761#m</id>
            <title>R to @dotey: 相应的GitHub项目：https://github.com/SurviveSJTU/SJTU-Application</title>
            <link>https://nitter.cz/dotey/status/1728998748272156761#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728998748272156761#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:46:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>相应的GitHub项目：<a href="https://github.com/SurviveSJTU/SJTU-Application">github.com/SurviveSJTU/SJTU-…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNzQ2NzQ2MzM3NjMwMjA4MC9uaEdRYmZRRD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728997603847675923#m</id>
            <title>推荐GitBook：
https://survivesjtu.gitbook.io/survivesjtumanual/

于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</title>
            <link>https://nitter.cz/dotey/status/1728997603847675923#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728997603847675923#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:42:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐GitBook：<上海交通大学生存手册><br />
<a href="https://survivesjtu.gitbook.io/survivesjtumanual/">survivesjtu.gitbook.io/survi…</a><br />
<br />
<上海交通大学生存手册>于08年由一群交大本科生写就，12年过去了无数交大学子受益于它，但有些内容可能已经过时，由于原作者团队主要属于出国攻读博士群体，本手册在国内深造、国内就业等方面存在欠缺。本项目旨在将它制作成gitbook发布，并长期维护该项目，希望能给未来的交大在读和入学新生同学带来微小的帮助，尤其感谢本书原版的作者们！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82aUl1SldRQUFwblExLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728976294195429627#m</id>
            <title>R to @dotey: ## Summary so far

构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。

Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。

## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard

在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。

关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选

部分形成最优答案，或者让模型帮助检查工作。

在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</title>
            <link>https://nitter.cz/dotey/status/1728976294195429627#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728976294195429627#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:17:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## Summary so far<br />
<br />
构建像 ChatGPT 这样的模型包括两个主要阶段：预训练和微调。预训练阶段需要从互联网上搜集大量文本资料，使用GPU集群进行处理。这些高性能计算机的成本非常昂贵，通常需要几百万美元的投入。完成后，就得到了基础模型。由于这个过程计算量巨大且成本高昂，公司通常一年或几个月才会做一次。微调阶段相对便宜，需要编写标注指南和雇佣人员进行帮助。例如，可以通过Scale AI等公司进行文档标注。这个阶段需要收集约100,000个高质量的问答回应样本，成本要低得多，可能只需一天就能完成。接下来是进行大量的评估工作，部署模型，并监控和收集任何不当行为。对于每个不当行为，都需要修复并返回第一步重复这个过程。修复方法通常是找到错误回应的对话，然后用正确的回应替换。由于微调成本较低，可以每周或每天进行迭代，许多公司在微调阶段而非预训练阶段会更频繁地进行迭代。<br />
<br />
Meta发布的Llama 2系列包括基础模型和助手模型。基础模型无法直接使用，因为它们无法直接对问题回复正确的答案，而助手模型则可以直接进行问答。Meta已经完成了极其昂贵的预训练阶段，提供了基础模型，允许用户基于这些结果进行自己的微调。此外，还有一个你可以选择进行的第三阶段微调，即人类反馈强化学习（RLHF），主要通过使用比较标签来提升额外性能。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），这其实是一个可选的第三阶段，它能在大语言模型中提升额外性能，主要是通过使用比较标签。例如，OpenAI的InstructGPT项目就是这样的一个例子。<br />
<br />
## Appendix: Comparisons, Labeling docs, RLHF, Synthetic data, Leaderboard<br />
<br />
在第二阶段提到了“和/或对比标注”。对于人类标注员而言，比起自己撰写答案，比较候选答案通常更为简单。例如，对于一个要求写关于回形针的俳句的问题，给标注员提供助手模型生成的候选俳句，让他们挑选出更佳的一首，比自己创作要容易得多。这也是为什么在很多情况下，进行比较比创作来得容易。此外，还有一个第三阶段的微调过程，可以利用这些比较结果来进一步优化模型。在OpenAI，这个过程被称为人类反馈强化学习（RLHF），是通过使用比较标签来提升模型性能的可选第三阶段。<br />
<br />
关于标注文档，尽管可能会长达几十甚至上百页且颇具复杂性，但其核心是要求参与者保持有帮助、真实和无害。随着大语言模型能力的提升，人机协作在创建这些标签中的作用日益增强。例如，可以让模型先生成答案样本，然后由人工挑选<br />
<br />
部分形成最优答案，或者让模型帮助检查工作。<br />
<br />
在市面上领先的大语言模型排行榜上，例如加州大学伯克利分校管理的Chatbot Marina，使用ELO评分对不同的模型进行排名。ELO分数的计算方式与国际象棋类似，基于模型间的对比胜率。顶部的是专有模型，如OpenAI的GPT系列和Antropic的Claude系列，这些模型表现最佳但无法获取其权重，只能通过网络界面访问。其次是公开权重的模型，例如Meta的Llama 2系列和法国Mistral系列的Zephyr 7B Beta。总体上，封闭模型的表现更好，但无法进行微调或下载，只能通过网络界面使用。然后是所有的开源模型和整个开源生态系统，它们的性能相对较差，但可能已经满足某些应用需求。目前，开源生态系统正在努力提升性能，试图追赶专有生态系统。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzU3MzY0MTU5MzY1MTMvcHUvaW1nL29uOVlkdzV1WTdGdkx5V2MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728974703895711948#m</id>
            <title>R to @dotey: ## How do they work?

好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。

但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。

我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。

这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。

它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要

相应的复杂评估来处理这些模型，因为它们主要是基于经验的。

## Finetuning into an Assistant

现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。

获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”

接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。

所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。

这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</title>
            <link>https://nitter.cz/dotey/status/1728974703895711948#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728974703895711948#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:11:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## How do they work?<br />
<br />
好了，让我们换个话题，来看看这个神经网络是怎么运作的？它是如何完成下一个词预测任务的？它内部的运作机制是什么？这里的情况稍微复杂一些。如果我们放大神经网络的简化图，这有点像是神经网络的示意图。这就是我们称之为 Transformer 的神经网络架构，这是它的一个示意图。现在，这个神经网络的一个显著特点是，我们对其架构有着完整的理解。我们清楚地知道在它的各个阶段会发生哪些数学运算。<br />
<br />
但问题在于，这 1000 亿个参数分散在整个神经网络中。因此，基本上，这上千亿个参数散布在整个网络中，我们所了解的只是如何逐步调整这些参数，以使整个网络在下一个词预测的任务上表现得更好。我们知道如何优化这些参数，也知道如何随时间调整它们以获得更佳的下一词预测效果，但我们并不真正清楚这些参数具体是如何工作的。我们可以观察到它在下一个词预测方面的进步，但并不清楚这些参数是如何协同工作以实现这一点的。我们手头有些模型，可以让我们从宏观层面思考网络可能在做的事情。<br />
<br />
我们大致理解，它们构建并维护了某种知识库，但这个数据库却非常奇特、不完美且怪异。最近有一个广为流传的例子，我们称之为“反转诅咒”。比如，如果你和目前最先进的语言模型 GPT-4（ChatGPT 的一部分）对话，你问，谁是汤姆·克鲁斯的母亲？它会告诉你是玛丽·李·菲弗，这是正确的。但如果你问，谁是玛丽·菲弗的儿子，它会告诉你它不知道。这种知识很古怪，它似乎是单向的。这些信息并不是简单存储后就能从各种角度获取，你必须从某个特定的角度去提问。<br />
<br />
这真是既奇怪又令人困惑。归根结底，我们实际上并不真正了解其工作原理，只能大致判断它是否有效，以及有效的可能性有多大。简而言之，可以将大语言模型 (LLM) 视为难以完全解读的产物。它们与你可能在工程学科中建造的任何其他东西都不相似。它们不像汽车，我们了解汽车的每一个部件。<br />
<br />
它们是这些来自长期优化过程的神经网络。我们目前并不完全理解它们是如何工作的，尽管有一个叫做可解释性或机械可解释性的领域，正在尝试研究并理解这些神经网络的每一个部分。目前，我们可以在一定程度上做到这一点，但还未能全面实现。现在，我们主要将它们视为基于经验的产品。我们可以给它们输入一些数据，然后测量输出结果。我们基本上可以测量它们的行为表现。我们可以观察它们在许多不同情况下生成的文本。因此，我认为这需要<br />
<br />
相应的复杂评估来处理这些模型，因为它们主要是基于经验的。<br />
<br />
## Finetuning into an Assistant<br />
<br />
现在，让我们来看看我们如何实际获得一个助手模型。到目前为止，我们只谈论了这些互联网文档生成器，对吧？这是训练的第一阶段，我们称之为预训练。我们现在正在进入训练的第二阶段，我们称之为微调。这一阶段我们会获得所谓的助手模型。因为我们实际上不仅仅需要文档生成器，文档生成器对许多任务帮助不大。我们希望能向某个系统提问，并让它根据这些问题生成答案。所以我们真正需要的是一个助手模型。<br />
<br />
获得这些助手模型的过程主要如下：我们保持优化过程相同，训练方式也相同。这本质上是一个下一步工作预测的任务。但我们将更换训练用的数据集。原本我们是在互联网文档上进行训练，现在我们转而使用手动收集的数据集。我们收集这些数据的方式是通过雇佣大量的人。通常，公司会雇佣人员，给他们标注指南，并要求他们提出问题，再为这些问题写出答案。这里有一个具体示例：它很可能就是你训练集中的一部分。比如，有一个用户提问，内容可能是：“你能简要介绍一下‘垄断买方’这个术语在经济学中的相关性吗？”<br />
<br />
接着，有一个助手角色，同样由人来填写理想的回复应当是什么。理想的回复，以及如何定义它，以及它应该是什么样子，都是根据我们为这些参与者提供的标注文档来确定的。像 OpenAI 或 Anthropic 这样的公司的工程师会制定这些标注文档。现在，预训练阶段主要处理大量的文本，但这些文本可能质量不高，因为它们都是从互联网上获取的，有数十甚至数百 TB 的文本，而且并非所有的都是高质量的。但在第二阶段，我们更看重质量而非数量。所以我们可能只有很少的文档，比如 10 万份，但这些文档都是对话形式，并且都是非常高质量的，由专业人士基于标注指南创建的。<br />
<br />
所以我们现在更换数据集，转而在这些问答形式的文档上进行训练。这个过程被称为微调。完成这些步骤后，我们就能得到所谓的助手型模型。这个助手模型现在遵循它新训练文档的形式。举个例子，如果你问它一个问题，比如：“你能帮我查一下这段代码吗？似乎有个 bug。请打印 hello world。”即使这个问题并不是训练集的一部分，模型在微调后理解它应该以一个有用的助手的风格回答这类问题。它会这样做。它会再次逐字采样，从左到右，从上到下，所有这些词都是对这个问题的回复。<br />
<br />
这是相当了不起的，也有点令人费解，还不完全被理解，这种模型能够改变它们的格式，现在变成了有用的助手，因为它们在微调阶段看到了很多这样的文档，但它们仍然能够访问并以某种方式利用所有在第一阶段（预训练阶段）积累的知识。大致来说，预训练阶段是在海量互联网数据上进行训练，重点是知识积累；而微调阶段则更关注对齐，它是关于给予，即将格式从互联网文档转变为问答形式，就像一个有用的助手一样。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NzM4NzQ4MzY5NzE1MjAvcHUvaW1nL0wxZHl1ZFRFTDM5SFB2NmsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</id>
            <title>RT by @dotey: Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章

Loom基于GPT-3，采用了一种独特的树形结构来组织文本。

每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

举例解释：

假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。

1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。

2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。

3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。

4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。

6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。

通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。

Loom的主要特点和功能包括：

1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。

2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。

3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。

4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。

5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。

6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。

5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。

GitHub：https://github.com/socketteer/loom
实例：https://generative.ink/meta/block-multiverse/</title>
            <link>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728963473152045089#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章<br />
<br />
Loom基于GPT-3，采用了一种独特的树形结构来组织文本。<br />
<br />
每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
举例解释：<br />
<br />
假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。<br />
<br />
1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。<br />
<br />
2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。<br />
<br />
3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。<br />
<br />
4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。<br />
<br />
6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。<br />
<br />
通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。<br />
<br />
Loom的主要特点和功能包括：<br />
<br />
1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。<br />
<br />
2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。<br />
<br />
3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。<br />
<br />
4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。<br />
<br />
5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。<br />
<br />
6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。<br />
<br />
5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。<br />
<br />
GitHub：<a href="https://github.com/socketteer/loom">github.com/socketteer/loom</a><br />
实例：<a href="https://generative.ink/meta/block-multiverse/">generative.ink/meta/block-mu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRV2JjQUF6dFY4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRMmJjQUFtSzZILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhReWE0QUFKZ2NLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRd2FjQUFRa2t3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</id>
            <title>RT by @dotey: UIDraw：在手机上画草图，自动生成H5页面
一个SwiftUI项目，使用GPT-4V实现写HTML界面。
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。
Github：https://github.com/jordansinger/UIDraw</title>
            <link>https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1728963202921500902#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:25:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>UIDraw：在手机上画草图，自动生成H5页面<br />
一个SwiftUI项目，使用GPT-4V实现写HTML界面。<br />
需要自己打包项目，需要替换ContentView.swift里的OpenAI Key。<br />
Github：<a href="https://github.com/jordansinger/UIDraw">github.com/jordansinger/UIDr…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjMxMjg4ODM2MDU1MDQvcHUvaW1nLzRFbEx2WGJEeHlYYUtiUGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728962389830238296#m</id>
            <title>R to @dotey: ## LLM Training

但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。

因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。

你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。

但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。

这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。

那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。

你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个

词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。

所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。

我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。

## LLM Dreams

那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。

可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。

比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。

但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</title>
            <link>https://nitter.cz/dotey/status/1728962389830238296#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728962389830238296#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:22:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>## LLM Training<br />
<br />
但真正的关键在于这些参数，我们如何得到它们？所以，为了获得模型参数，所谓的模型训练过程比我之前展示的模型推断要复杂得多。模型推断只是在 MacBook 上运行模型。而模型训练则是一个计算上极为复杂的过程。简单来说，我们所做的可以被理解为对大量互联网内容的压缩。<br />
<br />
因为 Llama 2 70B 是一个开源模型，我们对其训练方式有相当深入的了解，这得益于 Meta 在论文中公开的信息。以下是一些相关的数据。你需要从互联网上获取大约 10 TB 的文本，通常这些文本来自于对互联网的爬取。想象一下，从各种不同的网站上收集大量的文本，并将它们汇集起来。接下来，你需要获取一大块互联网数据，然后，你需要配置一个 GPU 集群，这些 GPU 是为了处理像神经网络训练这样复杂的计算任务而专门设计的高性能计算机。<br />
<br />
你需要大约 6,000 个 GPU，并且需要运行大约 12 天才能得到一个 Llama 2 7B，整个过程大约需要花费 200 万美元。这个过程基本上就是将这大量的文本压缩成你可以想象的一种 zip 文件。我在早些时候的幻灯片中向你展示的这些参数，可以被理解为互联网的 zip 文件。例如，在这种情况下，最终生成的是 140GB 的参数。大致来说，这里的压缩比率达到了大约 100 倍。<br />
<br />
但这种压缩与 zip 文件不同，因为 zip 文件是无损压缩，而这里是有损压缩。我们只是大致获取了我们训练文本的概念，而不是在这些参数中保留了文本的完整副本。所以，可以把它理解为一种有损压缩方式。另外需要指出的是，按照目前最先进技术的标准，这些数据其实只是入门级别的。如果考虑到像 ChatGPT、Claude 或 Bard 这样的顶尖神经网络，这些数字可能需要增加十倍甚至更多。<br />
<br />
这意味着在实际操作中，我们需要将这些数字大幅上调。这也解释了为什么如今这些神经网络的训练成本高达数千万甚至数亿美元，它们需要庞大的计算集群和大量数据集，而且在获取参数的过程中需要付出巨大努力。一旦获得了这些参数，实际运行神经网络的计算成本就相对较低了。<br />
<br />
那么，这个神经网络到底在做什么呢？正如我之前提到的那些参数，神经网络的主要任务其实是预测文本序列中的下一个词。你可以这样理解：当你输入一连串词语，比如 "cat sat on a"，这些词就会被送入神经网络。神经网络中分布着的这些参数，就是完成这一任务的关键。通过神经元的相互连接和激发，来预测下一个单词。<br />
<br />
你可以这么理解这个过程：输入一段文本后，神经网络会预测下一个词是什么。举个例子，在 "cat sat on a" 这四个<br />
<br />
词的上下文中，神经网络可能会预测下一个词是“mat”，并且给出了 97% 的高概率。这就是神经网络要解决的核心问题。从数学上可以证明，预测与数据压缩之间存在密切联系。这也是为什么我会说，这种神经网络训练在某种意义上是一种数据压缩：因为如果你能够非常准确地预测下一个词，你就可以利用这个能力来压缩数据集。<br />
<br />
所以，这其实是一个专注于预测下一个词的神经网络。你输入一些词，它就会告诉你接下来的词是什么。这种训练的结果之所以显得有些神奇，是因为尽管下一个词预测看似是一个简单的任务，但实际上它是一个非常强大的目标。因为这个目标迫使神经网络在其参数中学习到大量关于世界的信息。<br />
<br />
我举个例子，我在准备这个演讲时随机找了一个网页。这个页面是从维基百科的主页抓取的，讲的是 Ruth Handler 的故事。所以，想象一下你是神经网络，你需要根据给定的词来预测下一个词。在这个例子中，我用红色标出了一些信息量很大的词。例如，如果你的目标是预测下一个词，那么你的参数必须要学习很多这样的知识。你得知道 Ruth Handler 是谁，她何时出生，何时去世，她是谁，她的成就等等。在这个预测下一个词的任务中，你实际上学到了大量关于世界的知识，所有这些知识都被压缩到权重和参数中。<br />
<br />
## LLM Dreams<br />
<br />
那么，我们如何实际使用这些神经网络呢？当我们训练好它们后，我演示了模型推断是个非常简单的过程。我们基本上是生成下一个词，我们从模型中采样，选择一个词，然后我们继续将其反馈进去并得到下一个词，然后继续这样反馈。我们可以重复这个过程，让这个网络仿佛在“梦游”互联网文档。打个比方，如果我们只是运行神经网络，或者说进行推理，我们会得到类似于在网络上浏览的梦境体验。<br />
<br />
可以这么理解：因为这个神经网络是基于网页内容进行训练的，然后它可以自由遨游于其中。例如，在左边，我们可以看到类似于 Java 代码的“梦境”。中间的部分，看起来像是对亚马逊产品描述的“梦境”。而右边，则似乎呈现出一篇维基百科文章的样子。以中间的这个例子为例，标题、作者、ISBN 编号等等，这些内容都是神经网络完全自行创造的。这个网络正在“梦想”出它所训练数据集中的文本类型，它在模仿这些文档，但其实，这些都像是它的幻觉一样。<br />
<br />
比如说 ISBN 号码，这个号码几乎可以肯定是不存在的。网络只是知道在“ISBN:”后面通常会跟着这样长度的数字，然后就随机生成一个。实际上，它只是随意插入看起来合理的内容。因此，它在模仿训练数据集的分布模式。在右边，黑鼻鲑鱼，我查了一下，它实际上是一种鱼。这里的情况是，这段文字在训练集文档中并未原样出现，但如果你真的去查证，会发现对这种鱼的这些描述信息大致上是正确的。因此，这个网络对这种鱼有一定的了解，它知道很多关于这种鱼的信息。它不会完全复制训练集中看到的文档，但它会对互联网的信息进行某种程度的压缩和整合，它能够记住整体的轮廓。它大致掌握了相关知识，然后开始创造。它构建了一种合适的形式，并用自己的知识填充其中。<br />
<br />
但我们永远不能百分之百确定它生成的内容是幻觉、错误的回答，还是正确的回答。所以，它的一部分内容可能是记忆中的，而另一部分则不是，我们无法精确区分。但大多数情况下，这就像是它在梦游或在做关于互联网文本的梦，源于它的数据分布。这种能力使得神经网络能够生成各种文本，从代码到商品描述再到百科全书条目，但它也意味着生成的内容需要谨慎验证和审查，以确保准确性和可信度。这就是模型训练和模型推断的关键过程，它们共同构建了人工智能模型的能力和潜力。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NjE4MTc2MjIyNDEyODEvcHUvaW1nL3pCck1GN1Vzenpnc0RNNm8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728959646138880026#m</id>
            <title>OpenAI 的大神 Andrej Karpathy 前几天在他的 YouTube 频道讲了一堂课，系统的介绍了大语言模型，内容深入浅出，非常赞，抽空将它翻译成了双语，由于内容较长，我将分批上传，以下是第一部分精校后的双语视频，字幕文稿如下：

Intro: Large Language Model (LLM) talk

大家好。最近，我进行了一场关于大语言模型的 30 分钟入门讲座。遗憾的是，这次讲座没有被录制下来，但许多人在讲座后找到我，他们告诉我非常喜欢那次讲座。因此，我决定重新录制并上传到 YouTube，那么，让我们开始吧，为大家带来“忙碌人士的大语言模型入门”系列，主讲人 Scott。好的，那我们开始吧。

LLM Inference

首先，什么是大语言模型 (Large Language Model) 呢？其实，一个大语言模型就是由两个文件组成的。在这个假设的目录中会有两个文件。

以 Llama 2 70B 模型为例，这是一个由 Meta AI 发布的大语言模型。这是 Llama 系列语言模型的第二代，也是该系列中参数最多的模型，达到了 700 亿。LAMA2 系列包括了多个不同规模的模型，70 亿，130 亿，340 亿，700 亿是最大的一个。

现在很多人喜欢这个模型，因为它可能是目前公开权重最强大的模型。Meta 发布了这款模型的权重、架构和相关论文，所以任何人都可以很轻松地使用这个模型。这与其他一些你可能熟悉的语言模型不同，例如，如果你正在使用 ChatGPT 或类似的东西，其架构并未公开，是 OpenAI 的产权，你只能通过网页界面使用，但你实际上没有访问那个模型的权限。

在这种情况下，Llama 2 70B 模型实际上就是你电脑上的两个文件：一个是存储参数的文件，另一个是运行这些参数的代码。这些参数是神经网络（即语言模型）的权重或参数。我们稍后会详细解释。因为这是一个拥有 700 亿参数的模型，每个参数占用两个字节，因此参数文件的大小为 140 GB，之所以是两个字节，是因为这是 float 16 类型的数据。

除了这些参数，还有一大堆神经网络的参数。你还需要一些能运行神经网络的代码，这些代码被包含在我们所说的运行文件中。这个运行文件可以是 C 语言或 Python，或任何其他编程语言编写的。它可以用任何语言编写，但 C 语言是一种非常简单的语言，只是举个例子。只需大约 500 行 C 语言代码，无需任何其他依赖，就能构建起神经网络架构，并且主要依靠一些参数来运行模型。所以只需要这两个文件。

你只需带上这两个文件和你的 MacBook，就拥有了一个完整的工具包。你不需要连接互联网或其他任何设备。你可以拿着这两个文件，编译你的 C 语言代码。你将得到一个可针对参数运行并与语言模型交互的二进制文件。

比如，你可以让它写一首关于 Scale AI 公司的诗，语言模型就会开始生成文本。在这种情况下，它会按照指示为你创作一首关于 Scale AI 的诗。之所以选用 Scale AI 作为例子，你会在整个演讲中看到，是因为我最初在 Scale AI 举办的活动上介绍过这个话题，所以演讲中会多次提到它，以便内容更具体。这就是我们如何运行模型的方式。只需要两个文件和一台 MacBook。

我在这里稍微有点作弊，因为这并不是在运行一个有 700 亿参数的模型，而是在运行一个有 70 亿参数的模型。一个有 700 亿参数的模型运行速度大约会慢 10 倍。但我想给你们展示一下文本生成的过程，让你们了解它是什么样子。所以运行模型并不需要很多东西。这是一个非常小的程序包，但是当我们需要获取那些参数时，计算的复杂性就真正显现出来了。

那么，这些参数从何而来，我们如何获得它们？因为无论 run.c 文件中的内容是什么，神经网络的架构和前向传播都是算法上明确且公开的。</title>
            <link>https://nitter.cz/dotey/status/1728959646138880026#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728959646138880026#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:11:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 的大神 Andrej Karpathy 前几天在他的 YouTube 频道讲了一堂课，系统的介绍了大语言模型，内容深入浅出，非常赞，抽空将它翻译成了双语，由于内容较长，我将分批上传，以下是第一部分精校后的双语视频，字幕文稿如下：<br />
<br />
Intro: Large Language Model (LLM) talk<br />
<br />
大家好。最近，我进行了一场关于大语言模型的 30 分钟入门讲座。遗憾的是，这次讲座没有被录制下来，但许多人在讲座后找到我，他们告诉我非常喜欢那次讲座。因此，我决定重新录制并上传到 YouTube，那么，让我们开始吧，为大家带来“忙碌人士的大语言模型入门”系列，主讲人 Scott。好的，那我们开始吧。<br />
<br />
LLM Inference<br />
<br />
首先，什么是大语言模型 (Large Language Model) 呢？其实，一个大语言模型就是由两个文件组成的。在这个假设的目录中会有两个文件。<br />
<br />
以 Llama 2 70B 模型为例，这是一个由 Meta AI 发布的大语言模型。这是 Llama 系列语言模型的第二代，也是该系列中参数最多的模型，达到了 700 亿。LAMA2 系列包括了多个不同规模的模型，70 亿，130 亿，340 亿，700 亿是最大的一个。<br />
<br />
现在很多人喜欢这个模型，因为它可能是目前公开权重最强大的模型。Meta 发布了这款模型的权重、架构和相关论文，所以任何人都可以很轻松地使用这个模型。这与其他一些你可能熟悉的语言模型不同，例如，如果你正在使用 ChatGPT 或类似的东西，其架构并未公开，是 OpenAI 的产权，你只能通过网页界面使用，但你实际上没有访问那个模型的权限。<br />
<br />
在这种情况下，Llama 2 70B 模型实际上就是你电脑上的两个文件：一个是存储参数的文件，另一个是运行这些参数的代码。这些参数是神经网络（即语言模型）的权重或参数。我们稍后会详细解释。因为这是一个拥有 700 亿参数的模型，每个参数占用两个字节，因此参数文件的大小为 140 GB，之所以是两个字节，是因为这是 float 16 类型的数据。<br />
<br />
除了这些参数，还有一大堆神经网络的参数。你还需要一些能运行神经网络的代码，这些代码被包含在我们所说的运行文件中。这个运行文件可以是 C 语言或 Python，或任何其他编程语言编写的。它可以用任何语言编写，但 C 语言是一种非常简单的语言，只是举个例子。只需大约 500 行 C 语言代码，无需任何其他依赖，就能构建起神经网络架构，并且主要依靠一些参数来运行模型。所以只需要这两个文件。<br />
<br />
你只需带上这两个文件和你的 MacBook，就拥有了一个完整的工具包。你不需要连接互联网或其他任何设备。你可以拿着这两个文件，编译你的 C 语言代码。你将得到一个可针对参数运行并与语言模型交互的二进制文件。<br />
<br />
比如，你可以让它写一首关于 Scale AI 公司的诗，语言模型就会开始生成文本。在这种情况下，它会按照指示为你创作一首关于 Scale AI 的诗。之所以选用 Scale AI 作为例子，你会在整个演讲中看到，是因为我最初在 Scale AI 举办的活动上介绍过这个话题，所以演讲中会多次提到它，以便内容更具体。这就是我们如何运行模型的方式。只需要两个文件和一台 MacBook。<br />
<br />
我在这里稍微有点作弊，因为这并不是在运行一个有 700 亿参数的模型，而是在运行一个有 70 亿参数的模型。一个有 700 亿参数的模型运行速度大约会慢 10 倍。但我想给你们展示一下文本生成的过程，让你们了解它是什么样子。所以运行模型并不需要很多东西。这是一个非常小的程序包，但是当我们需要获取那些参数时，计算的复杂性就真正显现出来了。<br />
<br />
那么，这些参数从何而来，我们如何获得它们？因为无论 run.c 文件中的内容是什么，神经网络的架构和前向传播都是算法上明确且公开的。</p>
<p><a href="https://nitter.cz/karpathy/status/1727731541781152035#m">nitter.cz/karpathy/status/1727731541781152035#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg5NTg2NTQ5Nzg2NjI0MDIvcHUvaW1nL096ak1ReDBBU0JqM29IUkYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728913073388368146#m</id>
            <title>转译：人工智能本身并非危险的根源，关键在于掌控它的人

by Kenan Malik

OpenAI 的混乱事件揭示了我们对待科技的矛盾心态

这起事件的发展有时让人联想到 Fawlty Towers，而不是 Succession，更像是一出劳莱和哈代的闹剧，而不是莎士比亚式的悲剧。OpenAI 凭借其知名产品 聊天机器人 ChatGPT 成为当下科技界的焦点。上周，关于 Sam Altman 被撤销 CEO 职位解雇及随后的重新聘用成为全球媒体热议的话题，引发了广泛的惊奇和困惑。

一些人认为这场闹剧反映了董事会的不称职；另一些人则看到了巨大自我间的冲突。更深层次地，这次动荡折射出科技行业的诸多内在矛盾：一方面是技术企业家自封的“颠覆者”形象，另一方面则是他们控制着影响我们每个人生活的价值数十亿美元的巨型产业。同样存在的还有人工智能作为改变人类生活的工具与其可能成为人类生存威胁的双重视角。

在这些矛盾中，几乎没有哪个组织比 OpenAI 更具代表性。Elon Musk、Peter Thiel 等硅谷知名人士于 2015 年创立了这个组织，他们既是人工智能的倡导者，也是对其潜在威胁发出警告的先锋。Elon Musk 曾沉重地宣称：“通过人工智能，我们似乎在召唤一只恶魔。”

科技界巨头们对自己作为未来的征服者的无限自尊，加上对他人和社会深深的悲观情绪，使得他们对世界末日即将降临的恐惧几乎成为了默认状态。其中许多人已经成为了“预备者”，为可能出现的疯狂麦克斯式世界做好了准备。Altman 在 OpenAI 刚成立时向《纽约客》透露：“我有枪械、黄金、碘化钾、抗生素、电池、水、以色列国防军的防毒面具，还有位于 Big Sur 的一大块可以飞去的土地。”他认为，最优秀的企业家，“极度偏执，常常面临生存危机”，当然，对 AI 的担忧也在所难免。

OpenAI 的初衷是作为一个非盈利的慈善组织，旨在开发人工通用智能（AGI），简而言之，就是能够完成或超越人类所有智力任务的机器。但它的目标是以一种道德的方式造福“全人类”。

然后，到了 2019 年，这个慈善机构成立了一个盈利子公司，以筹集更多投资，最终从 Microsoft 那里募集了超过 110 亿美元（约 87 亿英镑）。尽管如此，非盈利的母公司仍然保持着完全的控制权，这就形成了追求利润与对其产品可能带来的世界末日担忧之间的张力。ChatGPT 的巨大成功进一步加剧了这种紧张关系。

两年前，一些 OpenAI 的研究人员离开去创建了一个新机构 Anthropic，因为他们担心自己原公司 AI 的发展速度过快。其中一位后来对记者表示：“在未来十年内，一个失控的 AI 毁灭人类的可能性高达 20%”。似乎是这种同样的恐惧促成了对 Altman 的排挤以及过去一周的董事会混乱。

我们可能会好奇，为什么人类会持续研发可能威胁到人类生命的机器。但讽刺的是，尽管人们对 AI 的恐惧有些夸张，这种恐惧本身却带来了新的危险。对 AI 的过度警惕源于对其能力的高估。ChatGPT 在预测文字序列的下一个词方面表现得非常出色，以至于我们误以为它能像真人一样进行交流。然而，它并不能像人类那样真正理解这些词汇的含义，对现实世界的了解也微乎其微。我们距离实现“人工通用智能 (AGI)”的梦想还有很长的路要走。“AGI 不会在短期内出现”，IBM 软件工程首席科学家 Grady Booch 指出，即使是在我们的后代子孙的一生中也不太可能实现。

对于那些认为 AGI 即将成为现实的硅谷人士来说，他们认为应通过“对齐”来保护人类，即确保 AI 符合人类的价值观和意图。这看似是一种理性的方式，可以减轻 AI 可能带来的伤害。但当我们开始探讨“人类价值”究竟是什么、谁来定义它们，以及在价值观冲突时该如何应对时，问题就变得复杂了。

社会价值观总是众说纷纭，尤其是在当今这个社会共识标准瓦解、普遍不满情绪高涨的时代。我们与技术的关系本身就引发了热烈的讨论。对一些人来说，限制网络仇恨或保护人们免受网络伤害比维护言论自由或隐私权更为重要。这正是英国最新在线安全法案的出发点。这也是许多人对这项法律可能带来的后果感到担忧的原因。

接下来是虚假信息的问题。几乎没人会质疑虚假信息是一个日益严重的问题，它对民主和信任提出了挑战。但如何应对这一问题，依然存在很大争议。尤其是许多管理虚假信息的尝试，最终增强了科技公司监管公众的能力。

同时，算法偏见这一议题也揭示了对“价值对齐”观点的弱点。算法容易对少数群体产生偏见，原因正是它们过于贴合人类价值观。AI 程序是基于充满歧视的人类世界数据训练而成的。这些偏见也渗透到 AI 软件中，不论是在刑事司法系统、医疗保健、面部识别还是招聘等领域。

我们面临的问题并非机器将来可能对人类行使权力——这种看法基于目前的发展是无依据的猜测。真正的问题在于，我们生活在一个少数人利用权力损害多数人的社会，而技术成为了巩固这种权力的工具。对于掌握社会、政治和经济权力的人来说，将问题描绘为技术问题而非社会问题，把问题推到未来而非现在，似乎更合理。

几乎所有对人类有益的工具也可能造成伤害。但它们很少自行造成伤害，更多是因为被人类，尤其是那些掌权者，错误使用。这才是我们讨论 AI 时应当关注的起点，而非那些关于人类灭绝的虚构恐惧。

https://www.theguardian.com/commentisfree/2023/nov/26/artificial-intelligence-harm-worry-about-people-control-openai</title>
            <link>https://nitter.cz/dotey/status/1728913073388368146#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728913073388368146#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 23:06:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：人工智能本身并非危险的根源，关键在于掌控它的人<br />
<br />
by Kenan Malik<br />
<br />
OpenAI 的混乱事件揭示了我们对待科技的矛盾心态<br />
<br />
这起事件的发展有时让人联想到 Fawlty Towers，而不是 Succession，更像是一出劳莱和哈代的闹剧，而不是莎士比亚式的悲剧。OpenAI 凭借其知名产品 聊天机器人 ChatGPT 成为当下科技界的焦点。上周，关于 Sam Altman 被撤销 CEO 职位解雇及随后的重新聘用成为全球媒体热议的话题，引发了广泛的惊奇和困惑。<br />
<br />
一些人认为这场闹剧反映了董事会的不称职；另一些人则看到了巨大自我间的冲突。更深层次地，这次动荡折射出科技行业的诸多内在矛盾：一方面是技术企业家自封的“颠覆者”形象，另一方面则是他们控制着影响我们每个人生活的价值数十亿美元的巨型产业。同样存在的还有人工智能作为改变人类生活的工具与其可能成为人类生存威胁的双重视角。<br />
<br />
在这些矛盾中，几乎没有哪个组织比 OpenAI 更具代表性。Elon Musk、Peter Thiel 等硅谷知名人士于 2015 年创立了这个组织，他们既是人工智能的倡导者，也是对其潜在威胁发出警告的先锋。Elon Musk 曾沉重地宣称：“通过人工智能，我们似乎在召唤一只恶魔。”<br />
<br />
科技界巨头们对自己作为未来的征服者的无限自尊，加上对他人和社会深深的悲观情绪，使得他们对世界末日即将降临的恐惧几乎成为了默认状态。其中许多人已经成为了“预备者”，为可能出现的疯狂麦克斯式世界做好了准备。Altman 在 OpenAI 刚成立时向《纽约客》透露：“我有枪械、黄金、碘化钾、抗生素、电池、水、以色列国防军的防毒面具，还有位于 Big Sur 的一大块可以飞去的土地。”他认为，最优秀的企业家，“极度偏执，常常面临生存危机”，当然，对 AI 的担忧也在所难免。<br />
<br />
OpenAI 的初衷是作为一个非盈利的慈善组织，旨在开发人工通用智能（AGI），简而言之，就是能够完成或超越人类所有智力任务的机器。但它的目标是以一种道德的方式造福“全人类”。<br />
<br />
然后，到了 2019 年，这个慈善机构成立了一个盈利子公司，以筹集更多投资，最终从 Microsoft 那里募集了超过 110 亿美元（约 87 亿英镑）。尽管如此，非盈利的母公司仍然保持着完全的控制权，这就形成了追求利润与对其产品可能带来的世界末日担忧之间的张力。ChatGPT 的巨大成功进一步加剧了这种紧张关系。<br />
<br />
两年前，一些 OpenAI 的研究人员离开去创建了一个新机构 Anthropic，因为他们担心自己原公司 AI 的发展速度过快。其中一位后来对记者表示：“在未来十年内，一个失控的 AI 毁灭人类的可能性高达 20%”。似乎是这种同样的恐惧促成了对 Altman 的排挤以及过去一周的董事会混乱。<br />
<br />
我们可能会好奇，为什么人类会持续研发可能威胁到人类生命的机器。但讽刺的是，尽管人们对 AI 的恐惧有些夸张，这种恐惧本身却带来了新的危险。对 AI 的过度警惕源于对其能力的高估。ChatGPT 在预测文字序列的下一个词方面表现得非常出色，以至于我们误以为它能像真人一样进行交流。然而，它并不能像人类那样真正理解这些词汇的含义，对现实世界的了解也微乎其微。我们距离实现“人工通用智能 (AGI)”的梦想还有很长的路要走。“AGI 不会在短期内出现”，IBM 软件工程首席科学家 Grady Booch 指出，即使是在我们的后代子孙的一生中也不太可能实现。<br />
<br />
对于那些认为 AGI 即将成为现实的硅谷人士来说，他们认为应通过“对齐”来保护人类，即确保 AI 符合人类的价值观和意图。这看似是一种理性的方式，可以减轻 AI 可能带来的伤害。但当我们开始探讨“人类价值”究竟是什么、谁来定义它们，以及在价值观冲突时该如何应对时，问题就变得复杂了。<br />
<br />
社会价值观总是众说纷纭，尤其是在当今这个社会共识标准瓦解、普遍不满情绪高涨的时代。我们与技术的关系本身就引发了热烈的讨论。对一些人来说，限制网络仇恨或保护人们免受网络伤害比维护言论自由或隐私权更为重要。这正是英国最新在线安全法案的出发点。这也是许多人对这项法律可能带来的后果感到担忧的原因。<br />
<br />
接下来是虚假信息的问题。几乎没人会质疑虚假信息是一个日益严重的问题，它对民主和信任提出了挑战。但如何应对这一问题，依然存在很大争议。尤其是许多管理虚假信息的尝试，最终增强了科技公司监管公众的能力。<br />
<br />
同时，算法偏见这一议题也揭示了对“价值对齐”观点的弱点。算法容易对少数群体产生偏见，原因正是它们过于贴合人类价值观。AI 程序是基于充满歧视的人类世界数据训练而成的。这些偏见也渗透到 AI 软件中，不论是在刑事司法系统、医疗保健、面部识别还是招聘等领域。<br />
<br />
我们面临的问题并非机器将来可能对人类行使权力——这种看法基于目前的发展是无依据的猜测。真正的问题在于，我们生活在一个少数人利用权力损害多数人的社会，而技术成为了巩固这种权力的工具。对于掌握社会、政治和经济权力的人来说，将问题描绘为技术问题而非社会问题，把问题推到未来而非现在，似乎更合理。<br />
<br />
几乎所有对人类有益的工具也可能造成伤害。但它们很少自行造成伤害，更多是因为被人类，尤其是那些掌权者，错误使用。这才是我们讨论 AI 时应当关注的起点，而非那些关于人类灭绝的虚构恐惧。<br />
<br />
<a href="https://www.theguardian.com/commentisfree/2023/nov/26/artificial-intelligence-harm-worry-about-people-control-openai">theguardian.com/commentisfre…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl81Vk9pa1hFQUEtUGhSLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1728805500702105959#m</id>
            <title>RT by @dotey: 在测试 Yi-34B-Chat-4Bits，确实能力上秒杀了一众10B模型。

通过vLLM 可以在4090上提供33 tokens/s 生成速度，3 并发稳定生成速度100tokens/s。

从ceval 开发集中挑选最难的数学等，打乱答案顺序后评测。（肯定在训练集中，会高估）

Qwen-14B-4bits 34.5%，yi是 52.7%。</title>
            <link>https://nitter.cz/9hills/status/1728805500702105959#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1728805500702105959#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 15:58:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在测试 Yi-34B-Chat-4Bits，确实能力上秒杀了一众10B模型。<br />
<br />
通过vLLM 可以在4090上提供33 tokens/s 生成速度，3 并发稳定生成速度100tokens/s。<br />
<br />
从ceval 开发集中挑选最难的数学等，打乱答案顺序后评测。（肯定在训练集中，会高估）<br />
<br />
Qwen-14B-4bits 34.5%，yi是 52.7%。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728820432613052859#m</id>
            <title>杨立昆（Yann LeCun）在《AI: Grappling with a New Kind of Intelligence》上的精彩发言：

这里有一个关键问题。

毫无疑问，未来或许在几十年后，我们将拥有智能与人类媲美的人工智能（AI）系统。这些系统不仅在特定领域专业化，而且在人类擅长的所有领域都可能比人类更聪明。
你可能会担心，这样的系统会不会掌控世界。其实，智能与控制欲之间并无必然联系。以人类为例，虽然有些人有控制欲，但并非所有人都是如此，而且通常不是最聪明的人才有控制欲。国际政治舞台上的种种事件每天都在证明这一点。这背后可能有进化上的原因：不够聪明的人需要依赖他人，因此会试图影响他人；而聪明的人可以独立生存。

再来看第二个观点，我们其实已经习惯了与比自己聪明的人合作。就我个人经验，我曾领导一个研究实验室，而我只雇佣比我聪明的人。与比你更聪明的人共事其实是一种美妙的经历。想象一下未来10到20年，我们会有人工智能助手在日常生活中协助我们，他们可能比我们更聪明。但他们的存在是为了让我们变得更聪明，我们指导它们，它们服务于我们。智能本身并不意味着渴望控制。

这种控制欲其实源于我们作为社会性物种的本性。作为社会性物种，我们需要影响他人，这就产生了控制和服从的概念。我们像黑猩猩、狒狒、狼等其他社会性动物一样，有着等级制的社会组织。这是进化赋予我们的特征。而像猩猩这样的非社会性物种，即便智力接近人类，也没有控制他人的渴望。所以，智能与控制欲是两码事。我们完全可以设计一个极为智能但不具备控制欲的系统。

关于这些系统的设计，它们会非常聪明，也就是说，你给它们一个目标，它们可以帮你实现这个目标。但设定目标的是我们，人类。这些系统会制定子目标，但如何实现这一技术问题还未解决，这仍然是我们对未来的设想。

再想象一下，如果未来我们与数字世界和信息世界的所有互动都通过人工智能代理来完成，这些代理将成为所有人类知识的宝库，类似于一个能进行对话和推理的“超级维基百科”。这将成为一个像现在的互联网一样的公共平台，它必须是开放的，不能是专有的，因为掌握在少数公司手中的超级智能AI将是非常危险的。想象一下，如果少数几家公司控制着这些超级智能AI，他们可以左右每个人的观点、文化等等。或许美国政府会接受这种情况，但全世界的其他政府绝不会同意。他们不会希望自己的文化被美国文化所主导。因此，他们将不得不开发自己的大语言模型（LLM）。

唯一的解决方案是基于开源的基础架构。这就是 Meta 开源 La Maute 2的原因之一，因为它是基础设施的一部分。此前，Meta 还发布了用于构建人工智能系统的软件系统 PyTorch，而 ChatGPT 就是基于 PyTorch 构建的。因此，这些系统必须是开源的，并且它们的训练方式也必须是众包的，以确保它们成为所有人类知识的仓库。这意味着所有人都必须对其做出贡献，而不仅仅是贡献给 openAI、Meta 或其他公司的专有系统。无论这听起来有多危险，这是未来的必然走向。

完整视频：https://www.youtube.com/watch?v=EGDG3hgPNp8</title>
            <link>https://nitter.cz/dotey/status/1728820432613052859#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728820432613052859#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 16:58:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>杨立昆（Yann LeCun）在《AI: Grappling with a New Kind of Intelligence》上的精彩发言：<br />
<br />
这里有一个关键问题。<br />
<br />
毫无疑问，未来或许在几十年后，我们将拥有智能与人类媲美的人工智能（AI）系统。这些系统不仅在特定领域专业化，而且在人类擅长的所有领域都可能比人类更聪明。<br />
你可能会担心，这样的系统会不会掌控世界。其实，智能与控制欲之间并无必然联系。以人类为例，虽然有些人有控制欲，但并非所有人都是如此，而且通常不是最聪明的人才有控制欲。国际政治舞台上的种种事件每天都在证明这一点。这背后可能有进化上的原因：不够聪明的人需要依赖他人，因此会试图影响他人；而聪明的人可以独立生存。<br />
<br />
再来看第二个观点，我们其实已经习惯了与比自己聪明的人合作。就我个人经验，我曾领导一个研究实验室，而我只雇佣比我聪明的人。与比你更聪明的人共事其实是一种美妙的经历。想象一下未来10到20年，我们会有人工智能助手在日常生活中协助我们，他们可能比我们更聪明。但他们的存在是为了让我们变得更聪明，我们指导它们，它们服务于我们。智能本身并不意味着渴望控制。<br />
<br />
这种控制欲其实源于我们作为社会性物种的本性。作为社会性物种，我们需要影响他人，这就产生了控制和服从的概念。我们像黑猩猩、狒狒、狼等其他社会性动物一样，有着等级制的社会组织。这是进化赋予我们的特征。而像猩猩这样的非社会性物种，即便智力接近人类，也没有控制他人的渴望。所以，智能与控制欲是两码事。我们完全可以设计一个极为智能但不具备控制欲的系统。<br />
<br />
关于这些系统的设计，它们会非常聪明，也就是说，你给它们一个目标，它们可以帮你实现这个目标。但设定目标的是我们，人类。这些系统会制定子目标，但如何实现这一技术问题还未解决，这仍然是我们对未来的设想。<br />
<br />
再想象一下，如果未来我们与数字世界和信息世界的所有互动都通过人工智能代理来完成，这些代理将成为所有人类知识的宝库，类似于一个能进行对话和推理的“超级维基百科”。这将成为一个像现在的互联网一样的公共平台，它必须是开放的，不能是专有的，因为掌握在少数公司手中的超级智能AI将是非常危险的。想象一下，如果少数几家公司控制着这些超级智能AI，他们可以左右每个人的观点、文化等等。或许美国政府会接受这种情况，但全世界的其他政府绝不会同意。他们不会希望自己的文化被美国文化所主导。因此，他们将不得不开发自己的大语言模型（LLM）。<br />
<br />
唯一的解决方案是基于开源的基础架构。这就是 Meta 开源 La Maute 2的原因之一，因为它是基础设施的一部分。此前，Meta 还发布了用于构建人工智能系统的软件系统 PyTorch，而 ChatGPT 就是基于 PyTorch 构建的。因此，这些系统必须是开源的，并且它们的训练方式也必须是众包的，以确保它们成为所有人类知识的仓库。这意味着所有人都必须对其做出贡献，而不仅仅是贡献给 openAI、Meta 或其他公司的专有系统。无论这听起来有多危险，这是未来的必然走向。<br />
<br />
完整视频：<a href="https://www.youtube.com/watch?v=EGDG3hgPNp8">youtube.com/watch?v=EGDG3hgP…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg4MjAwMjExMDk5MzYxMjgvcHUvaW1nL0RQOHdLdXpfc29MWHhMbTcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728651529102533076#m</id>
            <title>推荐阅读：一个失败的 AI 女友产品，以及我的教训：来自一位中国开发者的总结

摘录部分内容：

“11Labs 官网会记录语音合成的文字内容，我看到，Dolores 的回复内容通常都是一些成人内容，而且均为女性角色，因此我推测 Dolores 的付费用户主要是男性，对成人角色扮演感兴趣。”

“8 月份，OpenAI 的审查升级了，我收到了检测 Dolores 生成 NSFW 内容的邮件警告：我被强制要求在 2 周内在生成内容前，加入他们（免费的）moderation API，以过滤 NSFW 内容。为了顺利过审，我只能使用 OpenAI 的免费审核 API 提前进行内容过滤，而这一变化让 Dolores 的日均访问量暴跌 70%，电子邮件和 Twitter 上的投诉也纷至沓来。”

“首先，这不是一个个人能开发的产品。我不认为 Dolores 在“意识”层面上比 http://Character.AI 弱，但他们拥有完善的数据埋点、A/B 测试，以及大量用户带来的数据飞轮。

其次，我意识到当前的 AI Friend 会不可避免地变成 AI Girlfriend/Boyfriend，因为你和手机里的角色不对等：她没办法在你摔伤的时候安慰你 (除非你告诉他)，她没办法主动向你表达情绪，而这一切，都是因为她没有外部视觉。所以我认为，即使是 http://Character.AI 这样体量的产品，如果未来不做硬件、角色们都在傻傻地等用户来，最终的结局也不会比 Dolores 好到哪里。

最后，我不反对审查，相反，不经审查的的产品是非常危险的。我不知道是否会有人用它来进行自杀诱导、发泄暴力工具，所以 OpenAI 的 moderation 可能在某种程度帮助了我，但成人性方面的对话也不应该被扼杀。”

https://mp.weixin.qq.com/s/uDUAhxi9AWxt3fSYUmVIzg</title>
            <link>https://nitter.cz/dotey/status/1728651529102533076#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728651529102533076#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 05:46:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：一个失败的 AI 女友产品，以及我的教训：来自一位中国开发者的总结<br />
<br />
摘录部分内容：<br />
<br />
“11Labs 官网会记录语音合成的文字内容，我看到，Dolores 的回复内容通常都是一些成人内容，而且均为女性角色，因此我推测 Dolores 的付费用户主要是男性，对成人角色扮演感兴趣。”<br />
<br />
“8 月份，OpenAI 的审查升级了，我收到了检测 Dolores 生成 NSFW 内容的邮件警告：我被强制要求在 2 周内在生成内容前，加入他们（免费的）moderation API，以过滤 NSFW 内容。为了顺利过审，我只能使用 OpenAI 的免费审核 API 提前进行内容过滤，而这一变化让 Dolores 的日均访问量暴跌 70%，电子邮件和 Twitter 上的投诉也纷至沓来。”<br />
<br />
“首先，这不是一个个人能开发的产品。我不认为 Dolores 在“意识”层面上比 <a href="http://Character.AI">Character.AI</a> 弱，但他们拥有完善的数据埋点、A/B 测试，以及大量用户带来的数据飞轮。<br />
<br />
其次，我意识到当前的 AI Friend 会不可避免地变成 AI Girlfriend/Boyfriend，因为你和手机里的角色不对等：她没办法在你摔伤的时候安慰你 (除非你告诉他)，她没办法主动向你表达情绪，而这一切，都是因为她没有外部视觉。所以我认为，即使是 <a href="http://Character.AI">Character.AI</a> 这样体量的产品，如果未来不做硬件、角色们都在傻傻地等用户来，最终的结局也不会比 Dolores 好到哪里。<br />
<br />
最后，我不反对审查，相反，不经审查的的产品是非常危险的。我不知道是否会有人用它来进行自杀诱导、发泄暴力工具，所以 OpenAI 的 moderation 可能在某种程度帮助了我，但成人性方面的对话也不应该被扼杀。”<br />
<br />
<a href="https://mp.weixin.qq.com/s/uDUAhxi9AWxt3fSYUmVIzg">mp.weixin.qq.com/s/uDUAhxi9A…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8xblpkaVhjQUFVNEJzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728632847999631610#m</id>
            <title>“在那个充满活力的周末结束时，Altman 决定在这家科技巨擘里设立一个新的 AI 部门，好继续与 Nadella 合作，并充分利用 Microsoft 强大的计算资源。不久，成百上千的研究人员准备加入 Altman，投身于一个与众不同、魅力十足的公司。为了支持这些工程师们的研究，Microsoft 准备了一应俱全的资源：LinkedIn 办公楼的一整层、充裕的云计算资源和苹果笔记本电脑。更令人意外的是，这家价值万亿的公司向未来的同事保证，他们甚至不需要使用 Microsoft 的团队沟通应用 Teams。”

能不用 Teams 都成了谈判筹码了😄

以上内容来自华尔街日报：

OpenAI 事件中的最大赢家

作者：Ben Cohen，华尔街日报，2023年11月25日

摘要：微软首席执行官 Satya Nadella 对全球最火爆的 AI 公司 OpenAI 进行了重大投资。尽管这场事件一度将他置于风口浪尖，但现在他与 OpenAI 的领导人 Sam Altman 建立了更加密切的联系。

Satya Nadella 心绪难平。

作为微软的首席执行官，他本应全力以赴，专注于在硅谷历史上最为混乱的周末之一中挽救其珍贵的资产。但他的思绪不断被板球这项运动所吸引。

他无法全神贯注于关注自己祖国印度在板球世界杯中对抗澳大利亚的比赛，因为他发现自己正卷入了另一场更加激烈、风险更高的“游戏”中。即便在紧张的谈判和灾难应对中，Nadella 仍不时检查比分，向对板球不那么狂热的同事报告他最爱运动的最新动态。尽管他的团队处境艰难，但他的公司仍有转机。

这场令他难以忘怀的周末始于上周五。就在 OpenAI 的董事会突然罢免其联合创始人兼首席执行官 Sam Altman 的消息传遍全球前几分钟，Nadella 得知了这一消息。这家推出 ChatGPT 的公司曾寻求达到900亿美元的估值。如此短时间内，很少有董事会的决策能对如此巨大的价值造成如此严重的威胁。

虽然微软已为 OpenAI 的49%股份支付了数十亿美元，并利用其技术开发了一系列新一代软件，微软承诺这些软件将彻底改变工作方式，但作为这家初创公司最大的投资者，微软并未在董事会中占有一席之地。Nadella 几乎与全世界同时得知，他的这一投资——该投资几乎将微软独自推向了人工智能革命的前沿——突然面临困境。

然而，当董事会对 Altman 采取行动时，Altman 立刻联系了 Nadella。在上周五董事会突变的数小时后，他们通过电话讨论了如何让 Altman 重返 OpenAI 或加入微软的方案。如果 Altman 不能重返 OpenAI 的首席执行官职位，这位曾经在 AI 领域最为瞩目的公司的前首席执行官将加盟微软。

在那个充满活力的周末结束时，Altman 决定在这家科技巨擘里设立一个新的 AI 部门，好继续与 Nadella 合作，并充分利用 Microsoft 强大的计算资源。不久，成百上千的研究人员准备加入 Altman，投身于一个与众不同、魅力十足的公司。为了支持这些工程师们的研究，Microsoft 准备了一应俱全的资源：LinkedIn 办公楼的一整层、充裕的云计算资源和苹果笔记本电脑。更令人意外的是，这家价值万亿的公司向未来的同事保证，他们甚至不需要使用 Microsoft 的团队沟通应用 Teams。

然而，对 Microsoft 而言，最理想的结局是让 Altman 回归 OpenAI 担任 CEO。据了解 Nadella 的人士透露，通过向 OpenAI 团队敞开大门，Nadella 增强了 Altman 重回 CEO 位置的筹码，尤其是在 OpenAI 董事会面临人员流失的背景下。Altman 终于在五天紧张的谈判后实现了自己的愿望，重返 CEO 职位。他在 X 平台发布的回归声明中，特别感谢了一个人：Satya Nadella。

Microsoft 如何在硅谷这家最炙手可热的初创企业陷入困境之时，反而成为意外的赢家？

这背后很大程度上得益于 Nadella 的管理和领导风格，以及他对首席技术官 Kevin Scott 的信任，后者是 Microsoft AI 策略的幕后推手。这两位领导人在确保 Altman 重新掌管 OpenAI、保护他们 130 亿美元的投资以及帮助 Microsoft 避免一场可能是自食其果的尴尬失败中发挥了关键作用。

Microsoft 和 OpenAI 之间的非常规合作有时显得有些尴尬。但 Nadella 的高明之举在于，他与 Altman 建立了深厚的联系，五年来一直培养这种关系，成为一个不安分的企业家的重要伙伴。OpenAI 能够继续存在，很大程度上要归功于 Microsoft，其股价本周达到了历史新高。

纳德拉，现年 56 岁，出生并成长于印度海得拉巴。在那里，这位学习成绩平平的他最大的梦想是进入一所小型学院，打板球，并在银行工作。但在印度顶尖大学的入学考试失败后，他选择了在 Manipal 技术学院主修电气工程。他在回忆录《刷新》（2017）中提到，自青少年时期编写第一行代码起，他就对计算机和软件充满了热情。

纳德拉原本并没有计划离开印度，也并不急于这样做。他甚至曾希望自己申请的美国研究生院会拒绝他。然而，事与愿违，他最终来到美国，在威斯康星大学密尔沃基分校攻读计算机科学硕士。在那里，严寒让他不得不戒烟——他简直无法忍受在户外多待一秒。

尽管冬天异常严苛，纳德拉却爱上了他在美国的新生活。他发现这里的环境非常友好，最终甚至成为了美国公民。他在书中写道：“我认为我的故事只有在这里才可能发生。”（他拒绝就本文发表评论。）

1990 年，纳德拉加入了太阳微系统公司，并搬到加利福尼亚。两年后，他接到了来自华盛顿州雷德蒙德的电话，这通电话彻底改变了他的生活轨迹——他即将加入微软。

纳德拉在书中回忆，他在微软的关键时刻之一发生在他成为微软员工之前。在面试过程中，他被问到一个看似简单的问题：如果你在街上看到一个哭泣的婴儿，你会怎么做？他的第一反应是打 911。

然而，面试官指出：“你需要一些同理心。如果一个婴儿躺在街上哭泣，你应该去抱起他。” 纳德拉深刻记住了这个教训。

他在微软的早期岁月中遇到了史蒂夫·鲍尔默，这位未来的 CEO 继任者以热情的高举手式庆祝他的到来。纳德拉在公司的初期，常常携带康柏电脑跨越全国拜访客户，而周末则飞往芝加哥大学攻读商学硕士。

在微软公司步步高升的过程中，他负责监管了公司众多业务部门，例如云计算平台 Azure 和搜索引擎 Bing。目前，Azure 已成为微软整体增长的动力：微软的股价随着 Azure 的业绩而波动。在他的任期内，标普 500 指数增长了 215%，而微软的增长超过了 1,100%。至于 Bing，尽管它仍是 Bing，但在上一财年也创造了 120 亿美元的广告收入，不容小觑。

2014 年 2 月，Nadella 成为微软史上第三位 CEO，与前两任 CEO 截然不同。比尔·盖茨以其火山般的脾气而闻名，而巴尔默则以公开大声发泄而著称。相比之下，Nadella 在商业交往中更为低调。

他在感恩节期间写了一份 10 页的备忘录，以回答董事会关于他对公司未来愿景的看法，并成功地通过了面试。Nadella 强调，他的首要任务是改善公司的内部文化。他在一次高管会议上表示，仅仅发布产品并不足为喜，微软应当根据产品是否受到用户喜爱来衡量成功。

“我们需要更深入地理解客户未被言明和未得到满足的需求，" 他在自己的书中写道。

Nadella 的家庭生活也帮助他培养了更深的同理心。他的第一个孩子 Zain 患有严重的脑瘫，需要特别的照顾。Zain 去年去世，享年 26 岁。“成为一个有特殊需求孩子的父亲，是我生命中的转折点，深刻影响了我今天的为人，" Nadella 曾这样说。他称赞 Zain 是“我们家庭的快乐之源，他的坚强和温暖激励我不断探索技术的可能性。”

在担任微软首席执行官近十年后，员工们已经对纳德拉的管理风格了如指掌。

他是一位清楚认识自身极限，并愿意信任并委派他人的领导者。作为经理，他通常和善，但在必要时会严厉无情。一位前高管透露，纳德拉曾威胁要解雇那些不进步的直接下属。另一位前高管回忆，他曾直截了当地让一个爱炫耀的员工“坐下”。他很少说脏话，但在一次与微软高层的会议上，他明确告诉他们，他们的任务不是抱怨。“作为这家公司的领导者，”他说，“你们的工作是在困境中寻找亮点。”

他通过不断努力来践行这一点。一次，一位员工与他一同前往中国，为了缓解时差，凌晨3点去酒店健身房锻炼，却发现纳德拉已经锻炼完毕，开始了新的一天。

纳德拉也不惧怕果断终止那些无望的项目。他曾取消了将必应搜索引擎引入苹果手表的计划，认为这是浪费时间。“纳德拉独有的才能在于，能将复杂问题简化为核心要点，并且不会让会议室内的任何人感到被忽视，”曾向纳德拉汇报工作的前微软高管黄学东（Xuedong Huang）表示。

而他与前任微软首席执行官最不同的地方不仅仅在于他的行事风格。盖茨以其技术天赋著称，而鲍尔默则以其对商业模式的深刻理解闻名。纳德拉虽是工程师出身，但他的首席执行官任期内更多标志着一系列大规模交易的进行。他花费260亿美元收购了领英（LinkedIn），接着又斥资750亿美元收购动视暴雪（Activision Blizzard）。与此同时，他比前任更倾向于建立合作伙伴关系。鲍尔默曾在一次活动中夸张地从员工手中夺过iPhone，并假装要踩碎它，而纳德拉则平息了这种竞争情绪，在他首次重大产品发布会上推出了iPad版的微软Office套件。

他后来还与亚马逊建立了合作关系，与谷歌达成了脆弱的和平，并向外界宣布微软愿意与包括OpenAI在内的初创公司开展合作。

在一个专为亿万富翁设计的夏令营中，Nadella 和 Altman 的友谊奇遇开始了。2018年，他们在爱达荷州 Sun Valley 的 Allen &amp; Co. 大会上的一次楼梯偶遇，为他们之间的关系拉开了序幕。

Nadella 对 Altman 充满好奇，而 Altman 也对 Nadella 十分钦佩。

离开山区后，Altman 坚信 Microsoft 是唯一能与他的初创公司合作的企业，因为它不仅资金充裕，计算能力强大，而且对人工智能有着深刻的理解。

尽管 Microsoft 投资了高达130亿美元，但在 OpenAI 的董事会中并未获得席位，也无法洞察其内部治理。这是因为 Microsoft 担心自己的过度影响力可能会引发监管机构的警觉。这样一来，Microsoft 就不得不面对 OpenAI 独特结构带来的风险。Altman 的公司作为一个非盈利机构成立，其董事会的首要职责不是为股东创造最大价值，而是开发能“造福全人类”的安全人工智能。因为没有在董事会中占有一席之地，Microsoft 对很多事情都一无所知。同时，Microsoft 还面临着 Altman 可能离开并创立新公司、带走员工的风险，或者在一种原本看似遥不可及、却突然成为现实的情况下，OpenAI 董事会未经最大投资者同意就解雇 Altman。

即便在 OpenAI 危机爆发之前，这笔交易也并非人人欢迎。据知情人士透露，Gates 曾对高管表示，如果不完全收购该公司，Microsoft 支持它是没有意义的。虽然他现在已经对这项投资持积极态度，但他的担忧并非没有根据。Microsoft 必须在保护其投资和确保其持股比例低于50%（以避免监管问题）之间找到微妙的平衡点。

即便 Altman 已经回归，且 OpenAI 实施了更传统的治理结构，Microsoft 的问题仍未解决。Larry Summers 获得了新董事会的席位，但 Microsoft 仍然没有。至于 Nadella 是否想要扮演某种正式角色以防止此类事件重演，目前仍然是个未知数。

但有一人对 Nadella 处理 OpenAI 混乱局面的方式表示赞赏——Nadella 的前任 CEO。

Ballmer 在一封电邮中表示：“作为一个 Microsoft 的股东，也是一个长期支持 Satya 的人，我为他的表现感到欣慰且不感到惊讶。”

要深入了解微软 (Microsoft) 对未来的大胆投资，首先需要了解其 CEO Nadella 的成长经历。

Nadella 的父母曾在他的卧室里挂上 Karl Marx 和印度财富与繁荣女神的海报，但他真正热爱的是板球，特别是海得拉巴的板球明星 M.L. Jaisimha。Nadella 对板球的热情如此深厚，以至于高中时，为了继续打板球，他选择留在国内，而不随父亲出国。甚至在申请微软的工作时，他的简历上也写着自己的板球经历。在微软，不同于其他高管喜欢用棒球作比喻，Nadella 更倾向于用板球来说明问题。

Nadella 认为，他在球场上的经历深刻影响了他的领导风格。他曾参加过一场与强队的比赛，对手的强大让 Nadella 和队友们不禁止步观望，但他们的教练鼓励他们去挑战：“不要只是远观，要勇于竞争！”这段经历让 Nadella 深信，尊重对手固然重要，但更关键的是勇敢面对竞争。

正是这种精神指导了 Nadella 的决策。自2019年起，微软向 OpenAI 投资了30亿美元。到了2022年末，OpenAI 推出了 ChatGPT，这款产品迅速成为技术界的爆款，Nadella 甚至用它来翻译诗歌。到了2023年初，Nadella 再次大举投资，斥资100亿美元，预计这将帮助微软在当年实现1万亿美元的市场价值增长。

但增长也伴随着挑战。AI 技术成本高昂，随着微软加大对计算基础设施的投资，其开支预计将大幅增加。目前还不确定这些前期投资何时能够通过新增收入得到回报。尽管市场上已有证据显示，个人和企业愿意为像 GitHub 的 Copilot 这类 AI 助手支付高价，但微软的其他 AI 工具，例如 Microsoft 365，仍处于初期阶段，且每月每人收费30美元。微软需要现有和新客户为这一投资买单，以实现其增长目标。

Nadella 坚信，OpenAI 的独立性将促进创新，不仅对人类有益，也能助力微软的发展。然而，近期的不确定性事件揭示了一个重要风险点：作为全球最有价值公司之一的微软，将未来的部分掌控权外包给了一个初创公司。

“我不会假装我们的关系完美无瑕，”Altman 上月这样说。但他把 Nadella 形容成朋友而非敌手，强调他们在最关键的 AI（人工智能）问题上有着“高度一致”的看法。本月早些时候，在 OpenAI 的首次开发者大会上，两人同台亮相，Nadella 在 Altman 热情的介绍下轻松走上了舞台。

“微软对这次合作有何看法？”他问。

“我们非常喜欢你们！”Nadella 回答道。

谁也没想到，接下来的两周事件将使他们的关系更加紧密。

至于与 OpenAI 动荡期同步发生的那场板球比赛呢？Nadella 的公司比他支持的印度队表现得更好：印度在本土比赛中败给了澳大利亚。他祝贺澳大利亚队获胜，随后便投身工作，寻求属于自己的胜利。

*本文得到了 Keach Hagey 的贡献。*

https://www.livemint.com/ai/artificial-intelligence/the-biggest-winner-in-the-openai-fiasco-11700902916013.html</title>
            <link>https://nitter.cz/dotey/status/1728632847999631610#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728632847999631610#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 04:32:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“在那个充满活力的周末结束时，Altman 决定在这家科技巨擘里设立一个新的 AI 部门，好继续与 Nadella 合作，并充分利用 Microsoft 强大的计算资源。不久，成百上千的研究人员准备加入 Altman，投身于一个与众不同、魅力十足的公司。为了支持这些工程师们的研究，Microsoft 准备了一应俱全的资源：LinkedIn 办公楼的一整层、充裕的云计算资源和苹果笔记本电脑。更令人意外的是，这家价值万亿的公司向未来的同事保证，他们甚至不需要使用 Microsoft 的团队沟通应用 Teams。”<br />
<br />
能不用 Teams 都成了谈判筹码了😄<br />
<br />
以上内容来自华尔街日报：<br />
<br />
OpenAI 事件中的最大赢家<br />
<br />
作者：Ben Cohen，华尔街日报，2023年11月25日<br />
<br />
摘要：微软首席执行官 Satya Nadella 对全球最火爆的 AI 公司 OpenAI 进行了重大投资。尽管这场事件一度将他置于风口浪尖，但现在他与 OpenAI 的领导人 Sam Altman 建立了更加密切的联系。<br />
<br />
Satya Nadella 心绪难平。<br />
<br />
作为微软的首席执行官，他本应全力以赴，专注于在硅谷历史上最为混乱的周末之一中挽救其珍贵的资产。但他的思绪不断被板球这项运动所吸引。<br />
<br />
他无法全神贯注于关注自己祖国印度在板球世界杯中对抗澳大利亚的比赛，因为他发现自己正卷入了另一场更加激烈、风险更高的“游戏”中。即便在紧张的谈判和灾难应对中，Nadella 仍不时检查比分，向对板球不那么狂热的同事报告他最爱运动的最新动态。尽管他的团队处境艰难，但他的公司仍有转机。<br />
<br />
这场令他难以忘怀的周末始于上周五。就在 OpenAI 的董事会突然罢免其联合创始人兼首席执行官 Sam Altman 的消息传遍全球前几分钟，Nadella 得知了这一消息。这家推出 ChatGPT 的公司曾寻求达到900亿美元的估值。如此短时间内，很少有董事会的决策能对如此巨大的价值造成如此严重的威胁。<br />
<br />
虽然微软已为 OpenAI 的49%股份支付了数十亿美元，并利用其技术开发了一系列新一代软件，微软承诺这些软件将彻底改变工作方式，但作为这家初创公司最大的投资者，微软并未在董事会中占有一席之地。Nadella 几乎与全世界同时得知，他的这一投资——该投资几乎将微软独自推向了人工智能革命的前沿——突然面临困境。<br />
<br />
然而，当董事会对 Altman 采取行动时，Altman 立刻联系了 Nadella。在上周五董事会突变的数小时后，他们通过电话讨论了如何让 Altman 重返 OpenAI 或加入微软的方案。如果 Altman 不能重返 OpenAI 的首席执行官职位，这位曾经在 AI 领域最为瞩目的公司的前首席执行官将加盟微软。<br />
<br />
在那个充满活力的周末结束时，Altman 决定在这家科技巨擘里设立一个新的 AI 部门，好继续与 Nadella 合作，并充分利用 Microsoft 强大的计算资源。不久，成百上千的研究人员准备加入 Altman，投身于一个与众不同、魅力十足的公司。为了支持这些工程师们的研究，Microsoft 准备了一应俱全的资源：LinkedIn 办公楼的一整层、充裕的云计算资源和苹果笔记本电脑。更令人意外的是，这家价值万亿的公司向未来的同事保证，他们甚至不需要使用 Microsoft 的团队沟通应用 Teams。<br />
<br />
然而，对 Microsoft 而言，最理想的结局是让 Altman 回归 OpenAI 担任 CEO。据了解 Nadella 的人士透露，通过向 OpenAI 团队敞开大门，Nadella 增强了 Altman 重回 CEO 位置的筹码，尤其是在 OpenAI 董事会面临人员流失的背景下。Altman 终于在五天紧张的谈判后实现了自己的愿望，重返 CEO 职位。他在 X 平台发布的回归声明中，特别感谢了一个人：Satya Nadella。<br />
<br />
Microsoft 如何在硅谷这家最炙手可热的初创企业陷入困境之时，反而成为意外的赢家？<br />
<br />
这背后很大程度上得益于 Nadella 的管理和领导风格，以及他对首席技术官 Kevin Scott 的信任，后者是 Microsoft AI 策略的幕后推手。这两位领导人在确保 Altman 重新掌管 OpenAI、保护他们 130 亿美元的投资以及帮助 Microsoft 避免一场可能是自食其果的尴尬失败中发挥了关键作用。<br />
<br />
Microsoft 和 OpenAI 之间的非常规合作有时显得有些尴尬。但 Nadella 的高明之举在于，他与 Altman 建立了深厚的联系，五年来一直培养这种关系，成为一个不安分的企业家的重要伙伴。OpenAI 能够继续存在，很大程度上要归功于 Microsoft，其股价本周达到了历史新高。<br />
<br />
纳德拉，现年 56 岁，出生并成长于印度海得拉巴。在那里，这位学习成绩平平的他最大的梦想是进入一所小型学院，打板球，并在银行工作。但在印度顶尖大学的入学考试失败后，他选择了在 Manipal 技术学院主修电气工程。他在回忆录《刷新》（2017）中提到，自青少年时期编写第一行代码起，他就对计算机和软件充满了热情。<br />
<br />
纳德拉原本并没有计划离开印度，也并不急于这样做。他甚至曾希望自己申请的美国研究生院会拒绝他。然而，事与愿违，他最终来到美国，在威斯康星大学密尔沃基分校攻读计算机科学硕士。在那里，严寒让他不得不戒烟——他简直无法忍受在户外多待一秒。<br />
<br />
尽管冬天异常严苛，纳德拉却爱上了他在美国的新生活。他发现这里的环境非常友好，最终甚至成为了美国公民。他在书中写道：“我认为我的故事只有在这里才可能发生。”（他拒绝就本文发表评论。）<br />
<br />
1990 年，纳德拉加入了太阳微系统公司，并搬到加利福尼亚。两年后，他接到了来自华盛顿州雷德蒙德的电话，这通电话彻底改变了他的生活轨迹——他即将加入微软。<br />
<br />
纳德拉在书中回忆，他在微软的关键时刻之一发生在他成为微软员工之前。在面试过程中，他被问到一个看似简单的问题：如果你在街上看到一个哭泣的婴儿，你会怎么做？他的第一反应是打 911。<br />
<br />
然而，面试官指出：“你需要一些同理心。如果一个婴儿躺在街上哭泣，你应该去抱起他。” 纳德拉深刻记住了这个教训。<br />
<br />
他在微软的早期岁月中遇到了史蒂夫·鲍尔默，这位未来的 CEO 继任者以热情的高举手式庆祝他的到来。纳德拉在公司的初期，常常携带康柏电脑跨越全国拜访客户，而周末则飞往芝加哥大学攻读商学硕士。<br />
<br />
在微软公司步步高升的过程中，他负责监管了公司众多业务部门，例如云计算平台 Azure 和搜索引擎 Bing。目前，Azure 已成为微软整体增长的动力：微软的股价随着 Azure 的业绩而波动。在他的任期内，标普 500 指数增长了 215%，而微软的增长超过了 1,100%。至于 Bing，尽管它仍是 Bing，但在上一财年也创造了 120 亿美元的广告收入，不容小觑。<br />
<br />
2014 年 2 月，Nadella 成为微软史上第三位 CEO，与前两任 CEO 截然不同。比尔·盖茨以其火山般的脾气而闻名，而巴尔默则以公开大声发泄而著称。相比之下，Nadella 在商业交往中更为低调。<br />
<br />
他在感恩节期间写了一份 10 页的备忘录，以回答董事会关于他对公司未来愿景的看法，并成功地通过了面试。Nadella 强调，他的首要任务是改善公司的内部文化。他在一次高管会议上表示，仅仅发布产品并不足为喜，微软应当根据产品是否受到用户喜爱来衡量成功。<br />
<br />
“我们需要更深入地理解客户未被言明和未得到满足的需求，" 他在自己的书中写道。<br />
<br />
Nadella 的家庭生活也帮助他培养了更深的同理心。他的第一个孩子 Zain 患有严重的脑瘫，需要特别的照顾。Zain 去年去世，享年 26 岁。“成为一个有特殊需求孩子的父亲，是我生命中的转折点，深刻影响了我今天的为人，" Nadella 曾这样说。他称赞 Zain 是“我们家庭的快乐之源，他的坚强和温暖激励我不断探索技术的可能性。”<br />
<br />
在担任微软首席执行官近十年后，员工们已经对纳德拉的管理风格了如指掌。<br />
<br />
他是一位清楚认识自身极限，并愿意信任并委派他人的领导者。作为经理，他通常和善，但在必要时会严厉无情。一位前高管透露，纳德拉曾威胁要解雇那些不进步的直接下属。另一位前高管回忆，他曾直截了当地让一个爱炫耀的员工“坐下”。他很少说脏话，但在一次与微软高层的会议上，他明确告诉他们，他们的任务不是抱怨。“作为这家公司的领导者，”他说，“你们的工作是在困境中寻找亮点。”<br />
<br />
他通过不断努力来践行这一点。一次，一位员工与他一同前往中国，为了缓解时差，凌晨3点去酒店健身房锻炼，却发现纳德拉已经锻炼完毕，开始了新的一天。<br />
<br />
纳德拉也不惧怕果断终止那些无望的项目。他曾取消了将必应搜索引擎引入苹果手表的计划，认为这是浪费时间。“纳德拉独有的才能在于，能将复杂问题简化为核心要点，并且不会让会议室内的任何人感到被忽视，”曾向纳德拉汇报工作的前微软高管黄学东（Xuedong Huang）表示。<br />
<br />
而他与前任微软首席执行官最不同的地方不仅仅在于他的行事风格。盖茨以其技术天赋著称，而鲍尔默则以其对商业模式的深刻理解闻名。纳德拉虽是工程师出身，但他的首席执行官任期内更多标志着一系列大规模交易的进行。他花费260亿美元收购了领英（LinkedIn），接着又斥资750亿美元收购动视暴雪（Activision Blizzard）。与此同时，他比前任更倾向于建立合作伙伴关系。鲍尔默曾在一次活动中夸张地从员工手中夺过iPhone，并假装要踩碎它，而纳德拉则平息了这种竞争情绪，在他首次重大产品发布会上推出了iPad版的微软Office套件。<br />
<br />
他后来还与亚马逊建立了合作关系，与谷歌达成了脆弱的和平，并向外界宣布微软愿意与包括OpenAI在内的初创公司开展合作。<br />
<br />
在一个专为亿万富翁设计的夏令营中，Nadella 和 Altman 的友谊奇遇开始了。2018年，他们在爱达荷州 Sun Valley 的 Allen & Co. 大会上的一次楼梯偶遇，为他们之间的关系拉开了序幕。<br />
<br />
Nadella 对 Altman 充满好奇，而 Altman 也对 Nadella 十分钦佩。<br />
<br />
离开山区后，Altman 坚信 Microsoft 是唯一能与他的初创公司合作的企业，因为它不仅资金充裕，计算能力强大，而且对人工智能有着深刻的理解。<br />
<br />
尽管 Microsoft 投资了高达130亿美元，但在 OpenAI 的董事会中并未获得席位，也无法洞察其内部治理。这是因为 Microsoft 担心自己的过度影响力可能会引发监管机构的警觉。这样一来，Microsoft 就不得不面对 OpenAI 独特结构带来的风险。Altman 的公司作为一个非盈利机构成立，其董事会的首要职责不是为股东创造最大价值，而是开发能“造福全人类”的安全人工智能。因为没有在董事会中占有一席之地，Microsoft 对很多事情都一无所知。同时，Microsoft 还面临着 Altman 可能离开并创立新公司、带走员工的风险，或者在一种原本看似遥不可及、却突然成为现实的情况下，OpenAI 董事会未经最大投资者同意就解雇 Altman。<br />
<br />
即便在 OpenAI 危机爆发之前，这笔交易也并非人人欢迎。据知情人士透露，Gates 曾对高管表示，如果不完全收购该公司，Microsoft 支持它是没有意义的。虽然他现在已经对这项投资持积极态度，但他的担忧并非没有根据。Microsoft 必须在保护其投资和确保其持股比例低于50%（以避免监管问题）之间找到微妙的平衡点。<br />
<br />
即便 Altman 已经回归，且 OpenAI 实施了更传统的治理结构，Microsoft 的问题仍未解决。Larry Summers 获得了新董事会的席位，但 Microsoft 仍然没有。至于 Nadella 是否想要扮演某种正式角色以防止此类事件重演，目前仍然是个未知数。<br />
<br />
但有一人对 Nadella 处理 OpenAI 混乱局面的方式表示赞赏——Nadella 的前任 CEO。<br />
<br />
Ballmer 在一封电邮中表示：“作为一个 Microsoft 的股东，也是一个长期支持 Satya 的人，我为他的表现感到欣慰且不感到惊讶。”<br />
<br />
要深入了解微软 (Microsoft) 对未来的大胆投资，首先需要了解其 CEO Nadella 的成长经历。<br />
<br />
Nadella 的父母曾在他的卧室里挂上 Karl Marx 和印度财富与繁荣女神的海报，但他真正热爱的是板球，特别是海得拉巴的板球明星 M.L. Jaisimha。Nadella 对板球的热情如此深厚，以至于高中时，为了继续打板球，他选择留在国内，而不随父亲出国。甚至在申请微软的工作时，他的简历上也写着自己的板球经历。在微软，不同于其他高管喜欢用棒球作比喻，Nadella 更倾向于用板球来说明问题。<br />
<br />
Nadella 认为，他在球场上的经历深刻影响了他的领导风格。他曾参加过一场与强队的比赛，对手的强大让 Nadella 和队友们不禁止步观望，但他们的教练鼓励他们去挑战：“不要只是远观，要勇于竞争！”这段经历让 Nadella 深信，尊重对手固然重要，但更关键的是勇敢面对竞争。<br />
<br />
正是这种精神指导了 Nadella 的决策。自2019年起，微软向 OpenAI 投资了30亿美元。到了2022年末，OpenAI 推出了 ChatGPT，这款产品迅速成为技术界的爆款，Nadella 甚至用它来翻译诗歌。到了2023年初，Nadella 再次大举投资，斥资100亿美元，预计这将帮助微软在当年实现1万亿美元的市场价值增长。<br />
<br />
但增长也伴随着挑战。AI 技术成本高昂，随着微软加大对计算基础设施的投资，其开支预计将大幅增加。目前还不确定这些前期投资何时能够通过新增收入得到回报。尽管市场上已有证据显示，个人和企业愿意为像 GitHub 的 Copilot 这类 AI 助手支付高价，但微软的其他 AI 工具，例如 Microsoft 365，仍处于初期阶段，且每月每人收费30美元。微软需要现有和新客户为这一投资买单，以实现其增长目标。<br />
<br />
Nadella 坚信，OpenAI 的独立性将促进创新，不仅对人类有益，也能助力微软的发展。然而，近期的不确定性事件揭示了一个重要风险点：作为全球最有价值公司之一的微软，将未来的部分掌控权外包给了一个初创公司。<br />
<br />
“我不会假装我们的关系完美无瑕，”Altman 上月这样说。但他把 Nadella 形容成朋友而非敌手，强调他们在最关键的 AI（人工智能）问题上有着“高度一致”的看法。本月早些时候，在 OpenAI 的首次开发者大会上，两人同台亮相，Nadella 在 Altman 热情的介绍下轻松走上了舞台。<br />
<br />
“微软对这次合作有何看法？”他问。<br />
<br />
“我们非常喜欢你们！”Nadella 回答道。<br />
<br />
谁也没想到，接下来的两周事件将使他们的关系更加紧密。<br />
<br />
至于与 OpenAI 动荡期同步发生的那场板球比赛呢？Nadella 的公司比他支持的印度队表现得更好：印度在本土比赛中败给了澳大利亚。他祝贺澳大利亚队获胜，随后便投身工作，寻求属于自己的胜利。<br />
<br />
*本文得到了 Keach Hagey 的贡献。*<br />
<br />
<a href="https://www.livemint.com/ai/artificial-intelligence/the-biggest-winner-in-the-openai-fiasco-11700902916013.html">livemint.com/ai/artificial-i…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8xV1Z0WlhnQUVIa1BGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/jesselaunz/status/1728560640082759716#m</id>
            <title>RT by @dotey: 整了一个新的GPT

Free Grammar Checker

用了几个不太直观，自己写一个：

1.支持emoji提示，错误和修改部分

2.最终修改版放code block里，方便拷贝

3.支持多语言

需者点击： https://chat.openai.com/g/g-FmpWpbNpd-free-grammar-checker

视频因X时间限制，只放了中英文版本，

等会做个油管，加上西班牙语和日语演示</title>
            <link>https://nitter.cz/jesselaunz/status/1728560640082759716#m</link>
            <guid isPermaLink="false">https://nitter.cz/jesselaunz/status/1728560640082759716#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 25 Nov 2023 23:45:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整了一个新的GPT<br />
<br />
Free Grammar Checker<br />
<br />
用了几个不太直观，自己写一个：<br />
<br />
1.支持emoji提示，错误和修改部分<br />
<br />
2.最终修改版放code block里，方便拷贝<br />
<br />
3.支持多语言<br />
<br />
需者点击： <a href="https://chat.openai.com/g/g-FmpWpbNpd-free-grammar-checker">chat.openai.com/g/g-FmpWpbNp…</a><br />
<br />
视频因X时间限制，只放了中英文版本，<br />
<br />
等会做个油管，加上西班牙语和日语演示</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg1NjAyOTU5MzU4Njg5MjgvcHUvaW1nL1VlcEF1cERRaTFaOU9feUQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1728564657588224118#m</id>
            <title>Paul Graham这文章写的太好了，我将它全文翻译了：

2023 年 10 月，Paul Graham

当我还是个孩子的时候，我没能理解世界上最重要的一个事实：绩效带来的回报通常是超线性的。

教师和教练总是给我们灌输一种思想：回报与付出是成正比的。他们说，“你得到的和你付出的一样多。”他们是出于好意，但实际情况往往并非如此。如果你的产品质量只有竞争对手的一半，你不会仅仅失去一半的客户。更可能的是，你一名客户都留不住，最后关门大吉。

在商业领域，绩效带来的超线性回报尤其明显。有人认为这是资本主义的缺陷，认为只要改变规则，这种情况就会消失。但事实上，绩效的超线性回报是这个世界的一个特性，而不是我们制定规则的副产品。无论是在名声、权力、军事胜利、知识，还是对人类的贡献方面，我们都能看到这一模式。在所有这些领域，成功者往往会越来越成功。[1]

理解超线性回报的概念对于理解这个世界至关重要。如果你有远大的抱负，那么你更应该理解它，因为这会是你乘风破浪的力量。

虽然似乎有许多情况都存在超线性回报，但归根结底，它们主要源于两个因素：指数增长和阈值。

超线性回报最典型的例子是指数型增长的情况，比如培养细菌。细菌在增长时，其速度是指数级的。但培养它们颇具挑战，因此技术娴熟与否将导致巨大的结果差异。

对于初创公司也是如此，它们也可能实现指数型增长。一些公司成功实现了高增长率，而多数公司却做不到。这导致了截然不同的结果：高增长率的公司可能成长为价值巨大的企业，而增长率低的公司可能连生存都困难。

Y Combinator 倡导创始人更多关注增长率而非绝对数值。这不仅能防止他们在初期因为绝对数值低而气馁，还能帮助他们决定重点关注的领域：通过增长率可以指引公司的发展方向。最重要的是，专注于增长率通常意味着你能实现指数型增长。

虽然 YC 并未直接告诉创始人，增长率与你的投入成正比，但这一说法颇有道理。如果增长率确实与绩效成比例，那么随着时间推移，绩效 p 的回报将与 pt 成比例。

即使在深入思考了数十年后，这个观点仍然让我感到震撼。

当你的绩效依赖于你以往的成就时，就会出现指数级的增长。然而，无论是我们的 DNA 还是习惯都没有为此做好准备。指数增长对任何人来说都不是直观的；比如，孩子们在第一次听到有关一个男人从国王那里第一天要求一粒米，随后每天翻倍的故事时，都会感到惊奇。

我们对于不自然理解的事物，通常会通过发展习俗来应对。但是，关于指数增长的习俗却寥寥无几，因为人类历史中很少出现这样的例子。理论上，放牧动物本可以成为一个例子：你拥有的动物越多，它们的后代就越多。但实际上，放牧地成了限制因素，没有办法实现指数级的增长。

或者更确切地说，并不存在一个普遍适用的策略。过去，有一种方法可以让领土呈指数级扩张：那就是征服。领土越广，军力就越强大，进而征服新土地也就更加轻而易举。这正是历史上层出不穷的帝国背后的逻辑。然而，真正创建或统治帝国的人寥寥无几，他们的经历对一般人的日常生活和习俗影响甚微。对普通人来说，皇帝是一个遥远且可怕的存在，而不是能在日常生活中借鉴的经验教训。

在前工业时代，最常见的指数增长例子可能是学问。你掌握的知识越多，学习新事物就越容易。因此，无论是过去还是现在，总有一些人在特定领域的知识远超其他人。但这种差异也并未对传统习俗造成太大影响。虽然思想的“帝国”可以相互重叠，拥有众多的“皇帝”，但在前工业时代，这类帝国几乎没有实际的影响力。[2]

然而，近几个世纪以来，这种情况发生了翻天覆地的变化。如今，思想的“皇帝”能够设计出能够击败领土“皇帝”的炸弹。但这种现象仍然非常新颖，以至于我们还未能完全理解和吸收它。即便是参与其中的人，很少有人意识到自己正在从指数级增长中受益，或者思考他们能从其他类似情况中学到什么。

“赢者通吃”这一说法揭示了另一个超线性收益的来源。以体育比赛为例，比赛的表现和回报之间呈现一种阶梯式关系：无论胜出的队伍优势多大或仅略胜一筹，他们都只能获得一场胜利。[3]

但这种阶梯效应并非仅源于竞争本身。更关键的是结果中的“阈值”。即使在没有竞争的情况下，比如独自证明一个定理或实现一个目标，也存在这样的阈值。

在很多情况下，一个能带来超线性回报的因素通常伴随着另一个。例如，跨越某个门槛往往能引发指数级增长：在战斗中，赢的一方往往损失更少，这使他们未来更有可能获胜。同样，指数级增长也助于跨越门槛：在一个市场中，如果一个公司快速增长，就能有效排除潜在竞争对手。

名声就是一个典型例子，它结合了两种超线性收益的来源。名声之所以能指数级增长，是因为现有的粉丝会吸引新的粉丝。但名声集中的主要原因在于人们的注意力有限，比如大众心目中的明星名单（A-list）只有那么多位。

学习可能是最重要的结合了这两种超线性回报的例子。知识以指数形式增长，但也存在一些关键门槛，比如学习骑自行车。有些门槛就像机械工具，一旦你学会阅读，其他知识就能更快掌握。但最关键的门槛是新发现。知识在某种意义上像是分形的：深入一个领域的边界时，有时会开辟一个全新领域。像牛顿、杜勒和达尔文这样的大师，正是这样开创新领域并首先探索其中的新知识。

那么，如何找到找到具有超线性回报情况的通用规则呢？一个显而易见的方法是寻找那些可以实现复合增长的工作。

复合增长的工作有两种类型：一种是直接的复合增长，就是说你在上一个周期的优秀表现能让你在下一个周期做得更好。这种情况通常出现在你建设基础设施或者扩大观众群和品牌影响力时。另一种是通过学习实现的复合增长，毕竟学习本身就能带来复合效应。这种情况很有意思，因为在这个过程中，你可能觉得自己做得不够好，甚至没能达成当下的目标。但如果你学到了很多，那你依然在经历着指数级的成长。

这正是硅谷对失败如此宽容的原因之一。硅谷人并非对失败一味宽容，他们只有在看到你从失败中吸取教训时，才会继续支持你。但如果你真的做到了，那么你实际上是个不错的选择：也许你的公司没有像你期望的那样增长，但你个人的成长最终会带来回报。

实际上，不包含学习元素的指数增长往往与学习紧密交织在一起，我们应将这视为常态而非例外。这就衍生出另一个启发式原则：永远保持学习。如果你停止了学习，那么你可能就偏离了通往超线性回报的道路。

但也不要过度追求优化你的学习内容。不要局限于只学习那些已知有价值的知识。毕竟你还在学习阶段，还不确定哪些知识将来会有价值，过于苛刻的标准可能会让你错过一些异常但有潜力的领域。

谈到阶梯函数，我们是否也能找到像“寻找阈值”或“寻找竞争”这样的实用策略呢？这个问题比较棘手。光有阈值并不意味着参与游戏就一定值得。比如，玩一轮俄罗斯轮盘赌，虽然确实存在明显的阈值，但即使在最佳情况下，你的处境也并未改善。同理，“寻找竞争”也不总是有效；如果奖励本身就不吸引人怎么办？相比之下，快速的指数增长不仅保证了收益曲线的形态，还保证了其规模——因为增长得足够快的事物，哪怕起初微不足道，最终也会变得庞大——而阈值仅仅确保了形态。[4]

要想利用阈值，就必须包含一种测试，以确保游戏值得一玩。这里有一个办法：如果你发现某件事物虽平庸但依然受欢迎，那么尝试替换它可能是个不错的选择。比如，一家公司生产的产品虽不受欢迎，但人们还是会购买，那么如果你能制造出一个更好的替代品，他们很可能会转而购买这个新产品。[5]

如果能找到一种方法来发现有潜力的智力阈值就好了。我们怎样才能判断，哪些问题的背后隐藏着全新的研究领域呢？虽然我们可能永远无法完全确定地预测这一点，但鉴于潜在的巨大价值，即便是略胜于随机的预测方法也很有用，而且我们有希望找到这样的方法。我们在一定程度上可以预测哪些研究问题不太可能带来新发现：那些看似合理但却乏味的问题。而那些能够带来新发现的问题通常显得非常神秘，但可能看起来并不重要。（如果它们既神秘又显然重要，那它们就会成为众所周知的重大未解问题，吸引众多研究者的关注。）因此，这里的一个策略是让好奇心而非职业主义驱动自己——放任你的好奇心自由驰骋，而不是仅仅做那些“应该”做的工作。

对于那些有远大志向的人来说，绩效超线性增长的前景是令人兴奋的。而且，这方面的好消息是：这一领域正在不断扩张，无论是在工作类型上，还是在回报本身上。

这种变化有两个原因，尽管它们紧密相连，几乎可以看作是同一个原因：一是技术的飞速进步，二是组织重要性的日渐减弱。

五十年前，想要参与宏伟的项目几乎必须加入某个组织，因为这是获取资源、结交同事、拓宽分发渠道的唯一途径。所以在 1970 年，你的声望往往取决于你所属组织的声望。这种评价方式相当准确，因为不属于任何组织的人很难取得重大成就。当然，也有一些例外，像艺术家和作家这样的独立工作者，他们用廉价的工具创作，并拥有自己的品牌。但他们仍然依赖于组织来触及更广泛的受众。[6]

过去，由组织主导的世界限制了绩效回报的差异。但在我这一生中，这种现象已经显著改变。现在，更多的人能享受到 20 世纪艺术家和作家所拥有的自由。有很多宏伟项目不再需要庞大的初始投资，同时，学习、赚钱、寻找合作伙伴和触及受众的途径也变得更加多样。

尽管旧世界依然存在，但这种变化的速度在历史上是非常惊人的，特别是考虑到其深远的影响。很难想象有什么比业绩回报的变化更根本的改变。

一旦摆脱了机构的限制，结果的多样性将更加显著。这并不意味着每个人都会受益：绩效出色的人会取得更大的成功，而绩效不佳的人可能遭遇更大的失败。这一点非常重要，需要牢记。冒险追求超线性的回报并不适合所有人。对大多数人来说，作为一个整体的一部分会更好。那么，谁应该追求超线性回报呢？有两类人：一类是对自己的实力充满自信，相信在一个变化更大的世界里能够取得更高净收益的人；另一类是可以承担尝试风险的人，特别是年轻人，他们愿意冒险一试，看看能否成功。[7]

摆脱机构束缚的转变并不仅仅意味着当前机构成员的离去。许多新的成功者将是那些过去从未被机构接纳的人。因此，机会的民主化将比机构自行制定的任何方案更广泛、更真实。

不是每个人都对这种释放雄心的转变感到满意。它挑战了一些既得利益和固有的意识形态。 [8] 但如果你是一个有抱负的个人，这无疑是个好消息。那么，你该如何抓住这个机会呢？

要充分利用超线性回报来提升工作效果，最佳的方法就是做出卓越的成果。在成就曲线的顶端，多付出一点点努力就能带来巨大的回报。而且，顶端的竞争相对较少 —— 这不仅仅是因为做出卓越的事情非常困难，还因为人们对此望而却步，鲜少有人真正尝试。这意味着，不仅投入卓越工作本身是一种超值的选择，甚至仅仅是尝试去做也同样如此。

影响你工作成果的因素众多，要想脱颖而出，你几乎需要在所有方面都做到极致。例如，要想把事情做到极致，你必须对它充满兴趣。单纯的勤奋是不够的。因此，在一个超线性回报的世界里，了解自己的兴趣所在并寻找机会去实现它显得尤为重要。[9] 选择适合自己当前生活环境的工作同样重要。例如，如果某种工作本质上需要大量的时间和精力，那么在你年轻、未育有子女的时候去做这类工作会更有价值。

要想做出卓越的成就，技巧至关重要。这不仅仅是努力的问题。我在下面这个段落中尝试提供一个方法。

选择那些你天生擅长且深度感兴趣的工作。培养独立进行个人项目的习惯，项目是什么并不重要，关键是要让你感到充满雄心壮志。尽可能地努力工作，但避免过度劳累，这最终会引领你走到知识的前沿。这些领域看似平坦，但细看却充满缝隙。努力工作，避免过度劳累，这最终会引领你走到知识的前沿。尽可能多地承担风险；如果你从未遭遇失败，那可能意味着你过于保守。寻找最优秀的合作伙伴。培养优雅的品味，向最佳范例学习。保持诚实，特别是对自己。注意运动、饮食和睡眠，远离危险药物。在犹豫不决时，跟随你的好奇心。好奇心永远不会欺骗你，它比你更清楚什么值得关注。[10]

当然，还有一件至关重要的事情：运气。运气在任何时候都是一个不可忽视的因素，特别是当你独立工作，而不是作为组织一员时，它的作用更加凸显。我们常说运气是准备和机遇的结合，但实际上，还有一部分纯粹的偶然性，是我们无法控制的。解决之道在于多次尝试，这也是尽早开始冒险的另一个理由。

科学领域可能是超线性回报的最典型例子。它的增长呈指数级，这种增长不仅是学习的过程，更是在知识边界——人类知识的极限上不断突破。

这种现象导致科学发现的不平等程度远超过最为分化的社会中的财富不平等。可以说，牛顿的发现比他所有同时代人的总和还要伟大。[11]

这个观点虽然看似显而易见，但仍然值得详细说明。超线性回报就意味着不平等存在。回报曲线越陡，成果差异就越大。

实际上，超线性回报与不平等之间的联系如此紧密，以至于我们可以通过一个简单的方法来发现此类工作：寻找那些少数顶尖者远超其他人的领域。在大家绩效差不多的领域，往往不会出现超线性回报。

那么，哪些领域存在着少数人远超其他人的情况呢？一些显而易见的例子包括：体育、政治、艺术、音乐、表演、导演、写作、数学、科学、创业和投资。在体育领域，这种现象是由外部规则决定的；在比赛中，只需比其他人快那么一点点就能夺冠。在政治领域，权力的增长模式和古代皇帝时代相似。在其他一些领域（包括政治），成功往往与名声有关，名声本身也是超线性增长的一种形式。但如果我们排除掉体育、政治和名声的影响，就会发现一个有趣的模式：剩余的这些领域正是那些需要独立思考才能成功的领域 —— 在这些领域中，你的想法不仅要正确，还要有创新。[12]

在科学界，这一点显而易见。你不能只是发表重复他人观点的论文。但在投资领域，情况也相同。只有当大多数其他投资者不看好一家公司时，你对其看好才有意义；如果所有人都认为某公司前景光明，那么它的股价已经反映了这一预期，赚钱的机会就不复存在了。

那么，我们还能从这些领域学到什么呢？无论在哪个领域，最初的努力都是必不可少的。超线性回报一开始看似微不足道，按这个速度， 你可能会想，我怎么也达不到目标。 但是，由于奖励曲线在后期急剧上升，为了达到这个目标，采取特别的措施是非常值得的。

在创业界，这个原则被称为“做那些不可扩展的事情”。如果你能对你的少数初期客户投入极大的关注，理想情况下，你就能通过口碑引发指数级增长。而且，这个原则同样适用于任何以指数形式增长的领域，比如学习。刚开始学习新事物时，你可能会感到很茫然。但是，但为了获得一个立足点，做出最初的努力是值得的，因为随着你学得越多，过程就会变得越来越容易。

在具有超线性回报的领域中，还有一个更深层次的教训：不要把工作等同于一份职业。在 20 世纪大部分时间里，对大多数人来说，这两者是一样的。因此，我们形成了一种习惯，即把生产力等同于拥有一份工作。即便到了现在，对大多数人而言，“你的工作”仍然意味着他们的职业。但对于作家、艺术家或科学家来说，这指的是他们当前正在研究或创作的事物。对这样的人来说，他们的工作是他们从一份职业带到另一份职业的东西，即使他们根本就没有固定工作。这份工作可能是为雇主而做，但它是他们作品集的一部分。

踏入一个领域，面对少数顶尖高手遥遥领先的情况，确实令人望而却步。有人是刻意追求这种竞争，但这并非必要之路。只要你天资聪颖，足够追寻你的好奇心，你自然而然会进入这样的领域。你的好奇心不会允许你停留在平淡无奇的问题上，而那些引人入胜的问题往往会孕育出超线性的回报，即便它们最初并不属于任何领域。

超线性回报的世界并非固定不变。实际上，最巨大的回报往往源于不断扩展这个领域。因此，虽然雄心和好奇心都能引领你进入这片领域，但好奇心或许是更为强大的动力。雄心可能驱使你攀登已知的高峰，但如果你始终紧扣一个足够吸引人的问题，它可能就在你脚下逐渐崛起，成为一座巍峨的山峰。

注释

要精确划分努力、绩效和回报是有挑战的，因为在实际情况中，这些概念本身就没有明确的界限。某个人眼中的回报，可能在另一个人看来只是绩效。虽然这些概念的边界有些模糊，但它们并非毫无意义。我尽力精确地描述了这些概念，力求避免误解。

[1] 进化可能是最广泛的绩效超线性增长实例。然而，由于我们并非受益者，而是其中的一部分，所以我们很难深刻体会这一点。

[2] 当然，在工业革命之前，知识对实际生活已有所影响。例如，农业的发展彻底改变了人类生活方式。但这种改变是渐进的、广泛的技术进步所带来的，而不是少数几个博学者的突破性发现。

[3] 从数学角度来看，将阶跃函数描述为超线性是不准确的。但是，如果一个阶跃函数从零开始，那么在描述理性行为者的努力回报曲线时，它就像超线性函数一样工作。在阶跃之前，回报低于任何线性增长；在阶跃之后，回报必须高于那一点所需的回报，否则没人会去尝试。

[4] 寻找竞争可以是一个有效的策略，因为它激励了一些人。同时，这也指向了一些有前景的问题，因为这意味着其他人也认为这些问题值得关注。但这不是一个完美的指标：往往很多人都在追求同一个问题，最终却被默默致力于其他问题的人超越。

[5] 不过，这个规则也不是绝对的。当一些事物尽管平庸却广受欢迎时，背后往往有隐藏的原因。可能是由于垄断或监管，竞争变得困难；或许是因为消费者的品味问题，或者他们的购买决策流程存在缺陷。因此类原因而存在的平庸之物实在太多。

[6] 二十多岁时，我曾想成为一名艺术家，甚至去学习绘画。主要是因为我热爱艺术，但我选择这条道路也有一个不小的原因：艺术家似乎最不受组织束缚。

[7] 从理论上讲，每个人都在获得超线性回报。学习是一个累积过程，人人都在一生中学习。但实际上，很少有人能把这种日常学习推进到让回报曲线急剧上升的地步。

[8] 关于“公平”的倡导者们具体主张什么，并不完全清楚。他们之间似乎还存在分歧。但无论他们的目标是什么，这个目标可能与一个机构影响力较小、少数杰出者远超其他人的世界相抵触。

这个观念正值全球思潮发生逆转之际出现，看起来似乎是运气不佳，但我认为这并非偶然。我相信它之所以现在出现，一个原因是支持者感觉到自己受到了日益加剧的表现差异的威胁。

[9] 相关论断：那些强迫孩子投身于自己不感兴趣的高声望行业，如医学的父母，其实是在对孩子的未来造成更大的伤害。

[10] 这一段最初是文章“如何做出伟大工作”的初稿。写完之后我意识到，相较于超线性收益，这个话题更加重要。因此，我暂停了当前的论文创作，专注于将这一段发展成一个独立的主题。最终，“如何做出伟大工作”完成后，我基于其重新撰写了这一段，原稿几乎没有保留下来。

[11] 在工业革命之前，人们致富的方式通常是通过占据资源来增强自己的力量，类似于皇帝。而现在，致富可以像科学家那样，通过发现或创造独特而有价值的东西。尽管大多数致富者采用了传统和现代的结合方式，但在最发达的经济体中，过去半个世纪里这种方式已经显著转向创新发现。

[12] 如果独立思维是驱动不平等的主要因素之一，那么对于那些传统思维的人来说，不喜欢不平等就不足为奇了。但问题不仅仅是他们不愿看到别人拥有自己无法拥有的东西。事实上，那些传统思维的人根本无法想象拥有创新想法是怎样的体验。所以，他们认为绩效表现的巨大差异是不自然的，在遇到这种情况时，他们往往认为这是作弊或某种恶意外部因素造成的。

感谢 Trevor Blackwell、Patrick Collison、Tyler Cowen、Jessica Livingston、Harj Taggar 以及 Garry Tan 对本文草稿的审阅。

译文：https://baoyu.io/translations/paulgraham/superlinear
原文：Super Linear http://paulgraham.com/superlinear.html</title>
            <link>https://nitter.cz/dotey/status/1728564657588224118#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1728564657588224118#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 00:01:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Paul Graham这文章写的太好了，我将它全文翻译了：<br />
<br />
2023 年 10 月，Paul Graham<br />
<br />
当我还是个孩子的时候，我没能理解世界上最重要的一个事实：绩效带来的回报通常是超线性的。<br />
<br />
教师和教练总是给我们灌输一种思想：回报与付出是成正比的。他们说，“你得到的和你付出的一样多。”他们是出于好意，但实际情况往往并非如此。如果你的产品质量只有竞争对手的一半，你不会仅仅失去一半的客户。更可能的是，你一名客户都留不住，最后关门大吉。<br />
<br />
在商业领域，绩效带来的超线性回报尤其明显。有人认为这是资本主义的缺陷，认为只要改变规则，这种情况就会消失。但事实上，绩效的超线性回报是这个世界的一个特性，而不是我们制定规则的副产品。无论是在名声、权力、军事胜利、知识，还是对人类的贡献方面，我们都能看到这一模式。在所有这些领域，成功者往往会越来越成功。[1]<br />
<br />
理解超线性回报的概念对于理解这个世界至关重要。如果你有远大的抱负，那么你更应该理解它，因为这会是你乘风破浪的力量。<br />
<br />
虽然似乎有许多情况都存在超线性回报，但归根结底，它们主要源于两个因素：指数增长和阈值。<br />
<br />
超线性回报最典型的例子是指数型增长的情况，比如培养细菌。细菌在增长时，其速度是指数级的。但培养它们颇具挑战，因此技术娴熟与否将导致巨大的结果差异。<br />
<br />
对于初创公司也是如此，它们也可能实现指数型增长。一些公司成功实现了高增长率，而多数公司却做不到。这导致了截然不同的结果：高增长率的公司可能成长为价值巨大的企业，而增长率低的公司可能连生存都困难。<br />
<br />
Y Combinator 倡导创始人更多关注增长率而非绝对数值。这不仅能防止他们在初期因为绝对数值低而气馁，还能帮助他们决定重点关注的领域：通过增长率可以指引公司的发展方向。最重要的是，专注于增长率通常意味着你能实现指数型增长。<br />
<br />
虽然 YC 并未直接告诉创始人，增长率与你的投入成正比，但这一说法颇有道理。如果增长率确实与绩效成比例，那么随着时间推移，绩效 p 的回报将与 pt 成比例。<br />
<br />
即使在深入思考了数十年后，这个观点仍然让我感到震撼。<br />
<br />
当你的绩效依赖于你以往的成就时，就会出现指数级的增长。然而，无论是我们的 DNA 还是习惯都没有为此做好准备。指数增长对任何人来说都不是直观的；比如，孩子们在第一次听到有关一个男人从国王那里第一天要求一粒米，随后每天翻倍的故事时，都会感到惊奇。<br />
<br />
我们对于不自然理解的事物，通常会通过发展习俗来应对。但是，关于指数增长的习俗却寥寥无几，因为人类历史中很少出现这样的例子。理论上，放牧动物本可以成为一个例子：你拥有的动物越多，它们的后代就越多。但实际上，放牧地成了限制因素，没有办法实现指数级的增长。<br />
<br />
或者更确切地说，并不存在一个普遍适用的策略。过去，有一种方法可以让领土呈指数级扩张：那就是征服。领土越广，军力就越强大，进而征服新土地也就更加轻而易举。这正是历史上层出不穷的帝国背后的逻辑。然而，真正创建或统治帝国的人寥寥无几，他们的经历对一般人的日常生活和习俗影响甚微。对普通人来说，皇帝是一个遥远且可怕的存在，而不是能在日常生活中借鉴的经验教训。<br />
<br />
在前工业时代，最常见的指数增长例子可能是学问。你掌握的知识越多，学习新事物就越容易。因此，无论是过去还是现在，总有一些人在特定领域的知识远超其他人。但这种差异也并未对传统习俗造成太大影响。虽然思想的“帝国”可以相互重叠，拥有众多的“皇帝”，但在前工业时代，这类帝国几乎没有实际的影响力。[2]<br />
<br />
然而，近几个世纪以来，这种情况发生了翻天覆地的变化。如今，思想的“皇帝”能够设计出能够击败领土“皇帝”的炸弹。但这种现象仍然非常新颖，以至于我们还未能完全理解和吸收它。即便是参与其中的人，很少有人意识到自己正在从指数级增长中受益，或者思考他们能从其他类似情况中学到什么。<br />
<br />
“赢者通吃”这一说法揭示了另一个超线性收益的来源。以体育比赛为例，比赛的表现和回报之间呈现一种阶梯式关系：无论胜出的队伍优势多大或仅略胜一筹，他们都只能获得一场胜利。[3]<br />
<br />
但这种阶梯效应并非仅源于竞争本身。更关键的是结果中的“阈值”。即使在没有竞争的情况下，比如独自证明一个定理或实现一个目标，也存在这样的阈值。<br />
<br />
在很多情况下，一个能带来超线性回报的因素通常伴随着另一个。例如，跨越某个门槛往往能引发指数级增长：在战斗中，赢的一方往往损失更少，这使他们未来更有可能获胜。同样，指数级增长也助于跨越门槛：在一个市场中，如果一个公司快速增长，就能有效排除潜在竞争对手。<br />
<br />
名声就是一个典型例子，它结合了两种超线性收益的来源。名声之所以能指数级增长，是因为现有的粉丝会吸引新的粉丝。但名声集中的主要原因在于人们的注意力有限，比如大众心目中的明星名单（A-list）只有那么多位。<br />
<br />
学习可能是最重要的结合了这两种超线性回报的例子。知识以指数形式增长，但也存在一些关键门槛，比如学习骑自行车。有些门槛就像机械工具，一旦你学会阅读，其他知识就能更快掌握。但最关键的门槛是新发现。知识在某种意义上像是分形的：深入一个领域的边界时，有时会开辟一个全新领域。像牛顿、杜勒和达尔文这样的大师，正是这样开创新领域并首先探索其中的新知识。<br />
<br />
那么，如何找到找到具有超线性回报情况的通用规则呢？一个显而易见的方法是寻找那些可以实现复合增长的工作。<br />
<br />
复合增长的工作有两种类型：一种是直接的复合增长，就是说你在上一个周期的优秀表现能让你在下一个周期做得更好。这种情况通常出现在你建设基础设施或者扩大观众群和品牌影响力时。另一种是通过学习实现的复合增长，毕竟学习本身就能带来复合效应。这种情况很有意思，因为在这个过程中，你可能觉得自己做得不够好，甚至没能达成当下的目标。但如果你学到了很多，那你依然在经历着指数级的成长。<br />
<br />
这正是硅谷对失败如此宽容的原因之一。硅谷人并非对失败一味宽容，他们只有在看到你从失败中吸取教训时，才会继续支持你。但如果你真的做到了，那么你实际上是个不错的选择：也许你的公司没有像你期望的那样增长，但你个人的成长最终会带来回报。<br />
<br />
实际上，不包含学习元素的指数增长往往与学习紧密交织在一起，我们应将这视为常态而非例外。这就衍生出另一个启发式原则：永远保持学习。如果你停止了学习，那么你可能就偏离了通往超线性回报的道路。<br />
<br />
但也不要过度追求优化你的学习内容。不要局限于只学习那些已知有价值的知识。毕竟你还在学习阶段，还不确定哪些知识将来会有价值，过于苛刻的标准可能会让你错过一些异常但有潜力的领域。<br />
<br />
谈到阶梯函数，我们是否也能找到像“寻找阈值”或“寻找竞争”这样的实用策略呢？这个问题比较棘手。光有阈值并不意味着参与游戏就一定值得。比如，玩一轮俄罗斯轮盘赌，虽然确实存在明显的阈值，但即使在最佳情况下，你的处境也并未改善。同理，“寻找竞争”也不总是有效；如果奖励本身就不吸引人怎么办？相比之下，快速的指数增长不仅保证了收益曲线的形态，还保证了其规模——因为增长得足够快的事物，哪怕起初微不足道，最终也会变得庞大——而阈值仅仅确保了形态。[4]<br />
<br />
要想利用阈值，就必须包含一种测试，以确保游戏值得一玩。这里有一个办法：如果你发现某件事物虽平庸但依然受欢迎，那么尝试替换它可能是个不错的选择。比如，一家公司生产的产品虽不受欢迎，但人们还是会购买，那么如果你能制造出一个更好的替代品，他们很可能会转而购买这个新产品。[5]<br />
<br />
如果能找到一种方法来发现有潜力的智力阈值就好了。我们怎样才能判断，哪些问题的背后隐藏着全新的研究领域呢？虽然我们可能永远无法完全确定地预测这一点，但鉴于潜在的巨大价值，即便是略胜于随机的预测方法也很有用，而且我们有希望找到这样的方法。我们在一定程度上可以预测哪些研究问题不太可能带来新发现：那些看似合理但却乏味的问题。而那些能够带来新发现的问题通常显得非常神秘，但可能看起来并不重要。（如果它们既神秘又显然重要，那它们就会成为众所周知的重大未解问题，吸引众多研究者的关注。）因此，这里的一个策略是让好奇心而非职业主义驱动自己——放任你的好奇心自由驰骋，而不是仅仅做那些“应该”做的工作。<br />
<br />
对于那些有远大志向的人来说，绩效超线性增长的前景是令人兴奋的。而且，这方面的好消息是：这一领域正在不断扩张，无论是在工作类型上，还是在回报本身上。<br />
<br />
这种变化有两个原因，尽管它们紧密相连，几乎可以看作是同一个原因：一是技术的飞速进步，二是组织重要性的日渐减弱。<br />
<br />
五十年前，想要参与宏伟的项目几乎必须加入某个组织，因为这是获取资源、结交同事、拓宽分发渠道的唯一途径。所以在 1970 年，你的声望往往取决于你所属组织的声望。这种评价方式相当准确，因为不属于任何组织的人很难取得重大成就。当然，也有一些例外，像艺术家和作家这样的独立工作者，他们用廉价的工具创作，并拥有自己的品牌。但他们仍然依赖于组织来触及更广泛的受众。[6]<br />
<br />
过去，由组织主导的世界限制了绩效回报的差异。但在我这一生中，这种现象已经显著改变。现在，更多的人能享受到 20 世纪艺术家和作家所拥有的自由。有很多宏伟项目不再需要庞大的初始投资，同时，学习、赚钱、寻找合作伙伴和触及受众的途径也变得更加多样。<br />
<br />
尽管旧世界依然存在，但这种变化的速度在历史上是非常惊人的，特别是考虑到其深远的影响。很难想象有什么比业绩回报的变化更根本的改变。<br />
<br />
一旦摆脱了机构的限制，结果的多样性将更加显著。这并不意味着每个人都会受益：绩效出色的人会取得更大的成功，而绩效不佳的人可能遭遇更大的失败。这一点非常重要，需要牢记。冒险追求超线性的回报并不适合所有人。对大多数人来说，作为一个整体的一部分会更好。那么，谁应该追求超线性回报呢？有两类人：一类是对自己的实力充满自信，相信在一个变化更大的世界里能够取得更高净收益的人；另一类是可以承担尝试风险的人，特别是年轻人，他们愿意冒险一试，看看能否成功。[7]<br />
<br />
摆脱机构束缚的转变并不仅仅意味着当前机构成员的离去。许多新的成功者将是那些过去从未被机构接纳的人。因此，机会的民主化将比机构自行制定的任何方案更广泛、更真实。<br />
<br />
不是每个人都对这种释放雄心的转变感到满意。它挑战了一些既得利益和固有的意识形态。 [8] 但如果你是一个有抱负的个人，这无疑是个好消息。那么，你该如何抓住这个机会呢？<br />
<br />
要充分利用超线性回报来提升工作效果，最佳的方法就是做出卓越的成果。在成就曲线的顶端，多付出一点点努力就能带来巨大的回报。而且，顶端的竞争相对较少 —— 这不仅仅是因为做出卓越的事情非常困难，还因为人们对此望而却步，鲜少有人真正尝试。这意味着，不仅投入卓越工作本身是一种超值的选择，甚至仅仅是尝试去做也同样如此。<br />
<br />
影响你工作成果的因素众多，要想脱颖而出，你几乎需要在所有方面都做到极致。例如，要想把事情做到极致，你必须对它充满兴趣。单纯的勤奋是不够的。因此，在一个超线性回报的世界里，了解自己的兴趣所在并寻找机会去实现它显得尤为重要。[9] 选择适合自己当前生活环境的工作同样重要。例如，如果某种工作本质上需要大量的时间和精力，那么在你年轻、未育有子女的时候去做这类工作会更有价值。<br />
<br />
要想做出卓越的成就，技巧至关重要。这不仅仅是努力的问题。我在下面这个段落中尝试提供一个方法。<br />
<br />
选择那些你天生擅长且深度感兴趣的工作。培养独立进行个人项目的习惯，项目是什么并不重要，关键是要让你感到充满雄心壮志。尽可能地努力工作，但避免过度劳累，这最终会引领你走到知识的前沿。这些领域看似平坦，但细看却充满缝隙。努力工作，避免过度劳累，这最终会引领你走到知识的前沿。尽可能多地承担风险；如果你从未遭遇失败，那可能意味着你过于保守。寻找最优秀的合作伙伴。培养优雅的品味，向最佳范例学习。保持诚实，特别是对自己。注意运动、饮食和睡眠，远离危险药物。在犹豫不决时，跟随你的好奇心。好奇心永远不会欺骗你，它比你更清楚什么值得关注。[10]<br />
<br />
当然，还有一件至关重要的事情：运气。运气在任何时候都是一个不可忽视的因素，特别是当你独立工作，而不是作为组织一员时，它的作用更加凸显。我们常说运气是准备和机遇的结合，但实际上，还有一部分纯粹的偶然性，是我们无法控制的。解决之道在于多次尝试，这也是尽早开始冒险的另一个理由。<br />
<br />
科学领域可能是超线性回报的最典型例子。它的增长呈指数级，这种增长不仅是学习的过程，更是在知识边界——人类知识的极限上不断突破。<br />
<br />
这种现象导致科学发现的不平等程度远超过最为分化的社会中的财富不平等。可以说，牛顿的发现比他所有同时代人的总和还要伟大。[11]<br />
<br />
这个观点虽然看似显而易见，但仍然值得详细说明。超线性回报就意味着不平等存在。回报曲线越陡，成果差异就越大。<br />
<br />
实际上，超线性回报与不平等之间的联系如此紧密，以至于我们可以通过一个简单的方法来发现此类工作：寻找那些少数顶尖者远超其他人的领域。在大家绩效差不多的领域，往往不会出现超线性回报。<br />
<br />
那么，哪些领域存在着少数人远超其他人的情况呢？一些显而易见的例子包括：体育、政治、艺术、音乐、表演、导演、写作、数学、科学、创业和投资。在体育领域，这种现象是由外部规则决定的；在比赛中，只需比其他人快那么一点点就能夺冠。在政治领域，权力的增长模式和古代皇帝时代相似。在其他一些领域（包括政治），成功往往与名声有关，名声本身也是超线性增长的一种形式。但如果我们排除掉体育、政治和名声的影响，就会发现一个有趣的模式：剩余的这些领域正是那些需要独立思考才能成功的领域 —— 在这些领域中，你的想法不仅要正确，还要有创新。[12]<br />
<br />
在科学界，这一点显而易见。你不能只是发表重复他人观点的论文。但在投资领域，情况也相同。只有当大多数其他投资者不看好一家公司时，你对其看好才有意义；如果所有人都认为某公司前景光明，那么它的股价已经反映了这一预期，赚钱的机会就不复存在了。<br />
<br />
那么，我们还能从这些领域学到什么呢？无论在哪个领域，最初的努力都是必不可少的。超线性回报一开始看似微不足道，按这个速度， 你可能会想，我怎么也达不到目标。 但是，由于奖励曲线在后期急剧上升，为了达到这个目标，采取特别的措施是非常值得的。<br />
<br />
在创业界，这个原则被称为“做那些不可扩展的事情”。如果你能对你的少数初期客户投入极大的关注，理想情况下，你就能通过口碑引发指数级增长。而且，这个原则同样适用于任何以指数形式增长的领域，比如学习。刚开始学习新事物时，你可能会感到很茫然。但是，但为了获得一个立足点，做出最初的努力是值得的，因为随着你学得越多，过程就会变得越来越容易。<br />
<br />
在具有超线性回报的领域中，还有一个更深层次的教训：不要把工作等同于一份职业。在 20 世纪大部分时间里，对大多数人来说，这两者是一样的。因此，我们形成了一种习惯，即把生产力等同于拥有一份工作。即便到了现在，对大多数人而言，“你的工作”仍然意味着他们的职业。但对于作家、艺术家或科学家来说，这指的是他们当前正在研究或创作的事物。对这样的人来说，他们的工作是他们从一份职业带到另一份职业的东西，即使他们根本就没有固定工作。这份工作可能是为雇主而做，但它是他们作品集的一部分。<br />
<br />
踏入一个领域，面对少数顶尖高手遥遥领先的情况，确实令人望而却步。有人是刻意追求这种竞争，但这并非必要之路。只要你天资聪颖，足够追寻你的好奇心，你自然而然会进入这样的领域。你的好奇心不会允许你停留在平淡无奇的问题上，而那些引人入胜的问题往往会孕育出超线性的回报，即便它们最初并不属于任何领域。<br />
<br />
超线性回报的世界并非固定不变。实际上，最巨大的回报往往源于不断扩展这个领域。因此，虽然雄心和好奇心都能引领你进入这片领域，但好奇心或许是更为强大的动力。雄心可能驱使你攀登已知的高峰，但如果你始终紧扣一个足够吸引人的问题，它可能就在你脚下逐渐崛起，成为一座巍峨的山峰。<br />
<br />
注释<br />
<br />
要精确划分努力、绩效和回报是有挑战的，因为在实际情况中，这些概念本身就没有明确的界限。某个人眼中的回报，可能在另一个人看来只是绩效。虽然这些概念的边界有些模糊，但它们并非毫无意义。我尽力精确地描述了这些概念，力求避免误解。<br />
<br />
[1] 进化可能是最广泛的绩效超线性增长实例。然而，由于我们并非受益者，而是其中的一部分，所以我们很难深刻体会这一点。<br />
<br />
[2] 当然，在工业革命之前，知识对实际生活已有所影响。例如，农业的发展彻底改变了人类生活方式。但这种改变是渐进的、广泛的技术进步所带来的，而不是少数几个博学者的突破性发现。<br />
<br />
[3] 从数学角度来看，将阶跃函数描述为超线性是不准确的。但是，如果一个阶跃函数从零开始，那么在描述理性行为者的努力回报曲线时，它就像超线性函数一样工作。在阶跃之前，回报低于任何线性增长；在阶跃之后，回报必须高于那一点所需的回报，否则没人会去尝试。<br />
<br />
[4] 寻找竞争可以是一个有效的策略，因为它激励了一些人。同时，这也指向了一些有前景的问题，因为这意味着其他人也认为这些问题值得关注。但这不是一个完美的指标：往往很多人都在追求同一个问题，最终却被默默致力于其他问题的人超越。<br />
<br />
[5] 不过，这个规则也不是绝对的。当一些事物尽管平庸却广受欢迎时，背后往往有隐藏的原因。可能是由于垄断或监管，竞争变得困难；或许是因为消费者的品味问题，或者他们的购买决策流程存在缺陷。因此类原因而存在的平庸之物实在太多。<br />
<br />
[6] 二十多岁时，我曾想成为一名艺术家，甚至去学习绘画。主要是因为我热爱艺术，但我选择这条道路也有一个不小的原因：艺术家似乎最不受组织束缚。<br />
<br />
[7] 从理论上讲，每个人都在获得超线性回报。学习是一个累积过程，人人都在一生中学习。但实际上，很少有人能把这种日常学习推进到让回报曲线急剧上升的地步。<br />
<br />
[8] 关于“公平”的倡导者们具体主张什么，并不完全清楚。他们之间似乎还存在分歧。但无论他们的目标是什么，这个目标可能与一个机构影响力较小、少数杰出者远超其他人的世界相抵触。<br />
<br />
这个观念正值全球思潮发生逆转之际出现，看起来似乎是运气不佳，但我认为这并非偶然。我相信它之所以现在出现，一个原因是支持者感觉到自己受到了日益加剧的表现差异的威胁。<br />
<br />
[9] 相关论断：那些强迫孩子投身于自己不感兴趣的高声望行业，如医学的父母，其实是在对孩子的未来造成更大的伤害。<br />
<br />
[10] 这一段最初是文章“如何做出伟大工作”的初稿。写完之后我意识到，相较于超线性收益，这个话题更加重要。因此，我暂停了当前的论文创作，专注于将这一段发展成一个独立的主题。最终，“如何做出伟大工作”完成后，我基于其重新撰写了这一段，原稿几乎没有保留下来。<br />
<br />
[11] 在工业革命之前，人们致富的方式通常是通过占据资源来增强自己的力量，类似于皇帝。而现在，致富可以像科学家那样，通过发现或创造独特而有价值的东西。尽管大多数致富者采用了传统和现代的结合方式，但在最发达的经济体中，过去半个世纪里这种方式已经显著转向创新发现。<br />
<br />
[12] 如果独立思维是驱动不平等的主要因素之一，那么对于那些传统思维的人来说，不喜欢不平等就不足为奇了。但问题不仅仅是他们不愿看到别人拥有自己无法拥有的东西。事实上，那些传统思维的人根本无法想象拥有创新想法是怎样的体验。所以，他们认为绩效表现的巨大差异是不自然的，在遇到这种情况时，他们往往认为这是作弊或某种恶意外部因素造成的。<br />
<br />
感谢 Trevor Blackwell、Patrick Collison、Tyler Cowen、Jessica Livingston、Harj Taggar 以及 Garry Tan 对本文草稿的审阅。<br />
<br />
译文：<a href="https://baoyu.io/translations/paulgraham/superlinear">baoyu.io/translations/paulgr…</a><br />
原文：Super Linear <a href="http://paulgraham.com/superlinear.html">paulgraham.com/superlinear.h…</a></p>
<p><a href="https://nitter.cz/taoshenga19/status/1728362507155189760#m">nitter.cz/taoshenga19/status/1728362507155189760#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>