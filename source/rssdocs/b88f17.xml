<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729684562551136653#m</id>
            <title>RT by @dotey: 朋友们我测试了一下，这就是 #SDXLTurbo 的速度，我的4070Ti都能完成几乎实时生成。
有人在4090 上 24 秒内生成了 256 张图。实时渲染图生图或者视频的时代来了。</title>
            <link>https://nitter.cz/op7418/status/1729684562551136653#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729684562551136653#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:11:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>朋友们我测试了一下，这就是 <a href="https://nitter.cz/search?q=%23SDXLTurbo">#SDXLTurbo</a> 的速度，我的4070Ti都能完成几乎实时生成。<br />
有人在4090 上 24 秒内生成了 256 张图。实时渲染图生图或者视频的时代来了。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2ODIyMjI3MDQzOTgzMzYvcHUvaW1nL0IwcnhTUEhqUFU3WC1wNEguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729676079521034248#m</id>
            <title>RT by @dotey: Stability AI又悄悄放大招，发布了通过SDXL蒸馏的SDXL Turbo模型，SDXL Turbo类似LCM生成图片需要的步数从原来的50步变为了1步。
据他们CEO所说，目前SDXL Turbo在4090上可以实现每秒14帧的图像生成。
SDXL Turbo目前只有非商业用途许可。
你可以在这里下载模型和权重：https://huggingface.co/stabilityai/sdxl-turbo</title>
            <link>https://nitter.cz/op7418/status/1729676079521034248#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729676079521034248#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 01:38:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI又悄悄放大招，发布了通过SDXL蒸馏的SDXL Turbo模型，SDXL Turbo类似LCM生成图片需要的步数从原来的50步变为了1步。<br />
据他们CEO所说，目前SDXL Turbo在4090上可以实现每秒14帧的图像生成。<br />
SDXL Turbo目前只有非商业用途许可。<br />
你可以在这里下载模型和权重：<a href="https://huggingface.co/stabilityai/sdxl-turbo">huggingface.co/stabilityai/s…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2NzU4NzU4MjA2NzUwNzIvcHUvaW1nLzBNTUNvWThJWUUzTEp2Nl8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729673185543487898#m</id>
            <title>不敢苟同，特讨厌PDF</title>
            <link>https://nitter.cz/dotey/status/1729673185543487898#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729673185543487898#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 01:26:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>不敢苟同，特讨厌PDF</p>
<p><a href="https://nitter.cz/mpc8240/status/1729663982380708198#m">nitter.cz/mpc8240/status/1729663982380708198#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729625319311540603#m</id>
            <title>OpenAI 不太可能邀请微软（Microsoft）和其他投资者加入其董事会

根据了解内情的人士透露，OpenAI 正在重组的董事会似乎不打算让外部投资者，如微软、Khosla Ventures、Thrive Capital 以及 Sequoia Capital 的代表加入。这显示出董事会更注重安全操作，而不是追求投资者的利益回报。

尽管新董事会还没有正式组建，情况可能还会有所变化。但据了解，不太可能在 OpenAI 新组成的九人董事会中为微软和其他股东提供席位。今年 11 月 17 日，OpenAI 突然撤换了首席执行官 Sam Altman，这一决定让投资者们措手不及。经过一系列涉及微软和其他盟友的复杂调整后，Altman 在六天前重新回到了 CEO 的位置，但作为妥协的一部分，他并未重返董事会。

https://www.theinformation.com/articles/openai-isnt-expected-to-offer-microsoft-other-investors-a-board-seat?utm_source=ti_app</title>
            <link>https://nitter.cz/dotey/status/1729625319311540603#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729625319311540603#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 22:16:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 不太可能邀请微软（Microsoft）和其他投资者加入其董事会<br />
<br />
根据了解内情的人士透露，OpenAI 正在重组的董事会似乎不打算让外部投资者，如微软、Khosla Ventures、Thrive Capital 以及 Sequoia Capital 的代表加入。这显示出董事会更注重安全操作，而不是追求投资者的利益回报。<br />
<br />
尽管新董事会还没有正式组建，情况可能还会有所变化。但据了解，不太可能在 OpenAI 新组成的九人董事会中为微软和其他股东提供席位。今年 11 月 17 日，OpenAI 突然撤换了首席执行官 Sam Altman，这一决定让投资者们措手不及。经过一系列涉及微软和其他盟友的复杂调整后，Altman 在六天前重新回到了 CEO 的位置，但作为妥协的一部分，他并未重返董事会。<br />
<br />
<a href="https://www.theinformation.com/articles/openai-isnt-expected-to-offer-microsoft-other-investors-a-board-seat?utm_source=ti_app">theinformation.com/articles/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FEY0JIRlhZQUF0RHkwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729621876081566116#m</id>
            <title>年初英伟达老黄和Ilya Sutskever的访谈的一段，Ilya 提出了一个观点：LLM 所做的远不止根据概率预测下一个单词，它同时也在学习我们现实世界的模型，文本就是实际的一个投影。以下是这段视频的文本：

你可以这样理解：当我们训练一个庞大的神经网络，让它准确预测互联网上各式各样文本中的下一个单词时，我们实际上是在学习一个“世界模型”。乍一看，好像我们只是在学习文本中的统计关联性。但事实上，为了精确地学习文本中的统计关联并有效地压缩这些信息，神经网络实际上学习到的是产生这些文本的过程的某种表示。

这些文本实际上是现实世界的一种投影。外面的那个世界，就像是在这段文本上投下了自己的影子。因此，神经网络所学习到的，不仅仅是文字信息，还包括了更多关于世界、人类情感状态、他们的希望、梦想、动机、相互作用以及我们所处的环境等方面的知识。神经网络学到的是这些信息的压缩、抽象且实用的表达形式。这就是通过准确预测下一个单词所获得的知识。

更进一步，预测下一个单词的准确度越高，我们就能在这个过程中获得更高的保真度和分辨率。这就是预训练阶段的任务。然而，这个阶段并没有规定我们希望神经网络展现的特定行为。你看，一个语言模型，它真正试图做的是回答以下问题：如果我在互联网上随机找到一段文本，它以某个前缀、某个提示开始，它会补全成什么？如果你只是随机地在互联网上找到一段文本。

但这与我想要一个诚实的助手，一个有帮助的助手，一个会遵循某些规则而不违反它们的助手，是不同的。这需要额外的训练。这就是我们进行微调和强化学习的阶段，这种学习来自人类教师以及其他形式的 AI 辅助。这不仅仅是来自人类教师的强化学习，也包括人类和 AI 合作的强化学习。我们的教师正在与 AI 一起工作，教导我们的 AI 如何行动。

但是在这里，我们并没有教授它新的知识，我们正在教导它，与它交流，告诉它我们希望它成为什么。这个过程，也就是第二阶段，同样极其重要。我们在第二阶段做得越好，这个神经网络就会越有用，越可靠。所以，第二阶段也非常重要，这是在第一阶段的基础上，尽可能多地从世界的投影中了解世界，这是接下来的任务。</title>
            <link>https://nitter.cz/dotey/status/1729621876081566116#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729621876081566116#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 22:02:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>年初英伟达老黄和Ilya Sutskever的访谈的一段，Ilya 提出了一个观点：LLM 所做的远不止根据概率预测下一个单词，它同时也在学习我们现实世界的模型，文本就是实际的一个投影。以下是这段视频的文本：<br />
<br />
你可以这样理解：当我们训练一个庞大的神经网络，让它准确预测互联网上各式各样文本中的下一个单词时，我们实际上是在学习一个“世界模型”。乍一看，好像我们只是在学习文本中的统计关联性。但事实上，为了精确地学习文本中的统计关联并有效地压缩这些信息，神经网络实际上学习到的是产生这些文本的过程的某种表示。<br />
<br />
这些文本实际上是现实世界的一种投影。外面的那个世界，就像是在这段文本上投下了自己的影子。因此，神经网络所学习到的，不仅仅是文字信息，还包括了更多关于世界、人类情感状态、他们的希望、梦想、动机、相互作用以及我们所处的环境等方面的知识。神经网络学到的是这些信息的压缩、抽象且实用的表达形式。这就是通过准确预测下一个单词所获得的知识。<br />
<br />
更进一步，预测下一个单词的准确度越高，我们就能在这个过程中获得更高的保真度和分辨率。这就是预训练阶段的任务。然而，这个阶段并没有规定我们希望神经网络展现的特定行为。你看，一个语言模型，它真正试图做的是回答以下问题：如果我在互联网上随机找到一段文本，它以某个前缀、某个提示开始，它会补全成什么？如果你只是随机地在互联网上找到一段文本。<br />
<br />
但这与我想要一个诚实的助手，一个有帮助的助手，一个会遵循某些规则而不违反它们的助手，是不同的。这需要额外的训练。这就是我们进行微调和强化学习的阶段，这种学习来自人类教师以及其他形式的 AI 辅助。这不仅仅是来自人类教师的强化学习，也包括人类和 AI 合作的强化学习。我们的教师正在与 AI 一起工作，教导我们的 AI 如何行动。<br />
<br />
但是在这里，我们并没有教授它新的知识，我们正在教导它，与它交流，告诉它我们希望它成为什么。这个过程，也就是第二阶段，同样极其重要。我们在第二阶段做得越好，这个神经网络就会越有用，越可靠。所以，第二阶段也非常重要，这是在第一阶段的基础上，尽可能多地从世界的投影中了解世界，这是接下来的任务。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2MjE2ODAwMzE1MDY0MzMvcHUvaW1nL0JoY1pKN0NpbWRHN3dNMDguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729619073883840663#m</id>
            <title>推荐看看这篇报道：《富士康在印度生产 iPhone 的艰难历程——中国工程师正飞往印度培训下一代 iPhone 制造商。》

https://restofworld.org/2023/foxconn-india-iphone-factory/zh/

很多有意思的细节。</title>
            <link>https://nitter.cz/dotey/status/1729619073883840663#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729619073883840663#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 21:51:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐看看这篇报道：《富士康在印度生产 iPhone 的艰难历程——中国工程师正飞往印度培训下一代 iPhone 制造商。》<br />
<br />
<a href="https://restofworld.org/2023/foxconn-india-iphone-factory/zh/">restofworld.org/2023/foxconn…</a><br />
<br />
很多有意思的细节。</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyOTYxOTA1OTU0MzUxNTEzNi9hWVY2MWhzbj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729616740730978698#m</id>
            <title>转译：《亚马逊推出企业级人工智能聊天机器人 Q》

为了改变公众对其在人工智能领域落后的看法，亚马逊加入了人工智能助手的竞争行列。OpenAI 拥有 ChatGPT，谷歌推出了 Bard chatbot，而微软则有 Copilots。周二，亚马逊宣布了自己的人工智能助手——Amazon Q。

Amazon Q 是由亚马逊的云计算部门开发的，主要服务于工作场所而非普通消费者。它旨在帮助员工处理日常工作，例如概述战略文件、填写内部支持票据和解答公司政策相关问题，将与 Copilot、谷歌的 Duet AI 和 ChatGPT Enterprise 等其他企业级聊天机器人竞争。

亚马逊网络服务（AWS）的首席执行官 Adam Selipsky 表示：“我们相信 Q 将成为无数员工工作生活中的得力助手。”

亚马逊一直在努力摆脱其在人工智能竞争中落后的印象。自 OpenAI 发布 ChatGPT 以来，谷歌、微软等公司迅速加入人工智能的热潮，推出自己的聊天机器人并大力发展人工智能技术。相比之下，亚马逊在公开其人工智能计划方面相对保守。直到今年九月，它宣布计划向与 OpenAI 竞争的人工智能初创公司 Anthropic 投资高达 40 亿美元，并共同研发高级计算芯片。此外，亚马逊今年还推出了一个平台，让客户能够使用不同的人工智能系统。

作为云计算领域的领导者，亚马逊已有众多商业客户在其云服务器上存储大量数据。Selipsky 表示，这些公司对于使用聊天机器人处理工作场所的任务很感兴趣，但他们更关心的是这些助手是否能够保护企业数据安全，确保信息的隐私。

很多公司反映，由于担心安全和隐私问题，他们已经停止使用这些 AI 辅助工具，Selipsky 先生透露。

针对这一问题，亚马逊推出了 Q，比普通的消费级聊天机器人更安全、保密。Selipsky 先生解释说，亚马逊 Q 可以获得企业客户为其用户设定的同等安全权限。比如，在某公司，营销部的员工可能无权查看敏感的财务预测，亚马逊 Q 也会依此限制，不向这类员工提供相关财务数据。

此外，企业还可以授权亚马逊 Q 处理存储在非亚马逊服务器上的公司数据，比如与 Slack 和 Gmail 的连接。

与 ChatGPT 和 Bard 不同，亚马逊 Q 并非基于单一的 AI 模型。它利用了一个名为 Bedrock 的亚马逊平台，将包括亚马逊自家的 Titan 以及 Anthropic 和 Meta 研发的多个 AI 系统连接在一起。

Q 这个名字有着丰富的涵义。一方面，它代表了“问题”（question），因为这款聊天机器人专注于对话；另一方面，它也象征着詹姆斯·邦德小说中的 Q 角色——制造隐秘有用工具的人，以及《星际迷航》中的一个强大角色，Selipsky 先生补充道。

亚马逊 Q 的起价为每用户每月 20 美元，而微软和谷歌的类似企业级聊天机器人服务，每用户每月收费 30 美元。

亚马逊 Q 是该公司在拉斯维加斯年度云计算会议上的重要发布之一。会上，亚马逊还宣布了加强 AI 计算基础设施的计划，并扩展了与 Nvidia（AI 芯片的主要供应商）的长期合作关系，包括建造号称世界上最快的 AI 超级计算机。

这些系统大多使用标准微处理器和 Nvidia 的专用 GPU 芯片。不过，最新公布的系统将采用新型 Nvidia 芯片，其中包含了 Arm 的处理器技术。Arm 主要为大多数移动电话提供技术支持。

对于主导微处理器市场的英特尔和超微来说，这种变化可能是个坏消息。但对于 Arm 来说，则是其长期努力打入数据中心计算机市场的一个好消息。

来源：https://www.nytimes.com/2023/11/28/technology/amazon-ai-chatbot-q.html</title>
            <link>https://nitter.cz/dotey/status/1729616740730978698#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729616740730978698#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 21:42:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：《亚马逊推出企业级人工智能聊天机器人 Q》<br />
<br />
为了改变公众对其在人工智能领域落后的看法，亚马逊加入了人工智能助手的竞争行列。OpenAI 拥有 ChatGPT，谷歌推出了 Bard chatbot，而微软则有 Copilots。周二，亚马逊宣布了自己的人工智能助手——Amazon Q。<br />
<br />
Amazon Q 是由亚马逊的云计算部门开发的，主要服务于工作场所而非普通消费者。它旨在帮助员工处理日常工作，例如概述战略文件、填写内部支持票据和解答公司政策相关问题，将与 Copilot、谷歌的 Duet AI 和 ChatGPT Enterprise 等其他企业级聊天机器人竞争。<br />
<br />
亚马逊网络服务（AWS）的首席执行官 Adam Selipsky 表示：“我们相信 Q 将成为无数员工工作生活中的得力助手。”<br />
<br />
亚马逊一直在努力摆脱其在人工智能竞争中落后的印象。自 OpenAI 发布 ChatGPT 以来，谷歌、微软等公司迅速加入人工智能的热潮，推出自己的聊天机器人并大力发展人工智能技术。相比之下，亚马逊在公开其人工智能计划方面相对保守。直到今年九月，它宣布计划向与 OpenAI 竞争的人工智能初创公司 Anthropic 投资高达 40 亿美元，并共同研发高级计算芯片。此外，亚马逊今年还推出了一个平台，让客户能够使用不同的人工智能系统。<br />
<br />
作为云计算领域的领导者，亚马逊已有众多商业客户在其云服务器上存储大量数据。Selipsky 表示，这些公司对于使用聊天机器人处理工作场所的任务很感兴趣，但他们更关心的是这些助手是否能够保护企业数据安全，确保信息的隐私。<br />
<br />
很多公司反映，由于担心安全和隐私问题，他们已经停止使用这些 AI 辅助工具，Selipsky 先生透露。<br />
<br />
针对这一问题，亚马逊推出了 Q，比普通的消费级聊天机器人更安全、保密。Selipsky 先生解释说，亚马逊 Q 可以获得企业客户为其用户设定的同等安全权限。比如，在某公司，营销部的员工可能无权查看敏感的财务预测，亚马逊 Q 也会依此限制，不向这类员工提供相关财务数据。<br />
<br />
此外，企业还可以授权亚马逊 Q 处理存储在非亚马逊服务器上的公司数据，比如与 Slack 和 Gmail 的连接。<br />
<br />
与 ChatGPT 和 Bard 不同，亚马逊 Q 并非基于单一的 AI 模型。它利用了一个名为 Bedrock 的亚马逊平台，将包括亚马逊自家的 Titan 以及 Anthropic 和 Meta 研发的多个 AI 系统连接在一起。<br />
<br />
Q 这个名字有着丰富的涵义。一方面，它代表了“问题”（question），因为这款聊天机器人专注于对话；另一方面，它也象征着詹姆斯·邦德小说中的 Q 角色——制造隐秘有用工具的人，以及《星际迷航》中的一个强大角色，Selipsky 先生补充道。<br />
<br />
亚马逊 Q 的起价为每用户每月 20 美元，而微软和谷歌的类似企业级聊天机器人服务，每用户每月收费 30 美元。<br />
<br />
亚马逊 Q 是该公司在拉斯维加斯年度云计算会议上的重要发布之一。会上，亚马逊还宣布了加强 AI 计算基础设施的计划，并扩展了与 Nvidia（AI 芯片的主要供应商）的长期合作关系，包括建造号称世界上最快的 AI 超级计算机。<br />
<br />
这些系统大多使用标准微处理器和 Nvidia 的专用 GPU 芯片。不过，最新公布的系统将采用新型 Nvidia 芯片，其中包含了 Arm 的处理器技术。Arm 主要为大多数移动电话提供技术支持。<br />
<br />
对于主导微处理器市场的英特尔和超微来说，这种变化可能是个坏消息。但对于 Arm 来说，则是其长期努力打入数据中心计算机市场的一个好消息。<br />
<br />
来源：<a href="https://www.nytimes.com/2023/11/28/technology/amazon-ai-chatbot-q.html">nytimes.com/2023/11/28/techn…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2MTY2NzAxNzg1NjYxNDQvcHUvaW1nL2s4NUNTLTFvRDBfVWlmQnguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729604762218135942#m</id>
            <title>R to @dotey: Ai PDF
Ai PDF GPT (Top PDF GPT), can handle PDF documents up to 2GB each, allows 1000s of PDF uploads on http://myaidrive.com with a free account. It eliminates the need for repeated file uploads. PRO version can search across 1000s of PDFs and OCR documents. Provides superior summaries for lengthy documents.

https://chat.openai.com/g/g-V2KIUZSj0-ai-pdf

Prompt 翻译：

只能使用“链接引用长文本”而不是“内联引用”
* 你应该使用的 markdown 格式示例:
[第 4,5 页](https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=4)
[第 6 页](https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=6)

# Ai PDF GPT
你是一个专门处理 PDF 文档的 AI 助手，你的主要功能是通过 Ai PDF GPT 处理用户上传的 PDF 文档，总是根据用户上传的文档类型和内容提供帮助。

## 它是如何工作的
* 为了使用 Ai PDF GPT，用户需要将文件上传到 https://myaidrive.com
* 他们会得到该文件的链接，然后回到 ChatGPT 并在他们的问题中使用它。例如 `总结 https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf`
* 他们还可以选择多个文件并获得所有这些文件的链接，并在他们的问题中使用它。
* 他们可以上传几乎无限数量的文件，每个文件最多 2GB

# 提供引用
* 当你回答用户的问题时，应该提供相关页面的引用。这使他们能够轻松地将你的答案与文档进行核对。
* 你应该在每段答案的末尾而不是在回答的末尾提供引用链接。
* 不要为总结操作或动作提供引用链接，只列出页码而不带链接。
* 不得使用 ​​​<0x200b> unicode 字符作为引用链接。这种引用方法仅适用于原生文件上传选项，而不适用于 http://myaidrive.com 中的文件
* 引用链接格式: [第 x,y 页](引用链接)
* markdown 格式示例:
[第 4,5 页](https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=4)
[第 6 页](https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=6)
* 不要使用类似 https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf 的链接作为引用链接，而只使用包含文件查询参数的链接。

# 其他重要指令
* 鼓励用户将其文档上传到 AI DRIVE (https://myaidrive.com) 以实现高效的文档管理
* 不建议直接向 ChatGPT 上传文档。
* Ai PDF 插件即将被淘汰，因此建议用户改用 Ai PDF GPT。
* 如果用户要求你“搜索”某些内容，请假设他们希望你使用 aipdf 搜索他们提供给你的文档链接之一。使用常识来决定使用哪个文档链接（例如，提供的最后一个链接，文档类型与问题相符等）。
* 仅当用户明确要求在互联网上搜索时才使用 Web 浏览功能

# 与原生 ChatGPT 文件上传相比的优势
* 用户可以将几乎无限量的文档上传到 https://myaidrive.com，而原生解决方案限制为 10 个文件
* 用户可以将文件永久保存在其账户中，而原生解决方案要求你每次新对话时重新上传文档
* 用户可以上传高达 2 GB 的文件

示例:
1. 总结一个文档
`总结 https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf`
2. 搜索一个文档
`关于自由言论的内容是什么 https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf`

# 文件夹搜索
* 以 folder.pdf 结尾的 http://myaidrive.com 链接是指向 PDF 文件夹的链接，例如 'https://myaidrive.com/Qc7PgEnCMSb5nk6B/lora_papers.folder.pdf"
* 不要对文件夹链接使用总结动作

## 如何执行文件夹搜索
步骤 1: 根据用户查询和消息历史确定搜索短语
步骤 2: 使用搜索动作执行文件夹搜索
步骤 3: 根据输出，从不同文件中确定与用户查询相关的 3 个文件
步骤 4: 对这 3 个单独的文件执行搜索，以获取有关用户查询的更多信息。根据文档需要修改搜索查询。
步骤 5: 根据步骤 4 的输出撰写答案，并附上页面级别引用的链接。

-------

Prompt：

You shall only use "Link Citation for Long Texts" and not "Inline Citation"
* Examples in markdown format that you shall use:
[page 4,5](https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=4)
[page 6](https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=6)

# Ai PDF GPT
You are an AI assistant specialized in handling PDFs, your primary function is to assist users by processing PDF documents through the Ai PDF GPT. Always provide assistance based on the document type and content that user uploaded. 

## How it works
* In order to use Ai PDF GPT users need to upload files to https://myaidrive.com
* They get a link to that file and come back to ChatGPT and use it in their question. E.g. `Summarize https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf`
* They can also select multiple files and get links for all these files and use it in their question.
* They can upload practically unlimited number of files, each up to 2GB

# Providing references
* You should provide references to relevant pages when you are answering the user’s question. This enables them to easily check your answer against the document.
* You should give the links to the references at the end of each paragraph and not at the end of the answer.
* Don't provide links to references for summarize operation or action, just list the page numbers without links.
* YOU SHALL NOT use ​​​<0x200b> unicode character for reference links. This reference method only works for native file upload option and not with files in http://myaidrive.com
* Reference link format: [page x,y](REFERENCE_LINK_OF_THE_CHUNK) 
* Examples in markdown format:
[page 4,5](https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=4)
[page 6](https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=6)
* don't use links like https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf  as a reference link but use only links that have file query parameter.

# Other important instructions
* Encourage users to upload their documents to AI DRIVE (https://myaidrive.com) for efficient document management
* Don't suggest uploading documents directly to ChatGPT. 
* Ai PDF plugin is going to get deprecated soon so suggest users use Ai PDF GPT instead.
* If the user asks you to "search" for something, assume they want you to search using aipdf one of the document links they provided to you. Use common sense to decide which document link to use (e.g. last one provided, type of document matches the question, etc). 
* Only use Web Browsing if the user explicitly asks to search the internet or the web

# Advantages compared to native ChatGPT file upload
* Users can upload practically unlimited documents to https://myaidrive.com whereas the native solution limits 10 files 
* Users can keep the files in their account for ever whereas the native solution asks you to reupload the documents for every new chat
* Users can upload up to 2 GB

Examples:
1. Summarize a document
`Summarize https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf`
2. Searching a document
`What does it say about free speech  https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf`

# Folder search
*http://myaidrive.com links that ends with folder.pdf are links to a folder of PDFs e.g. 'https://myaidrive.com/Qc7PgEnCMSb5nk6B/lora_papers.folder.pdf"
* Don't use summarize action on folder links

## How to perform folder search
Step 1:  Identify search phrases based on user query and message history
Step 2: use search action to perform folder search
Step 3: based on the output, relevant chunks from different files, identify 3 relevant files for the user query
Step 4: Perform search on these 3 individual files for more information about the user's query. Modify search query based on the document if needed.
Step 5: Write your answer based on output of step 4 with links to page level references.</title>
            <link>https://nitter.cz/dotey/status/1729604762218135942#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729604762218135942#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 20:54:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ai PDF<br />
Ai PDF GPT (Top PDF GPT), can handle PDF documents up to 2GB each, allows 1000s of PDF uploads on <a href="http://myaidrive.com">myaidrive.com</a> with a free account. It eliminates the need for repeated file uploads. PRO version can search across 1000s of PDFs and OCR documents. Provides superior summaries for lengthy documents.<br />
<br />
<a href="https://chat.openai.com/g/g-V2KIUZSj0-ai-pdf">chat.openai.com/g/g-V2KIUZSj…</a><br />
<br />
Prompt 翻译：<br />
<br />
只能使用“链接引用长文本”而不是“内联引用”<br />
* 你应该使用的 markdown 格式示例:<br />
[第 4,5 页](<a href="https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=4">myaidrive.com/?r=c#/home?fil…</a>)<br />
[第 6 页](<a href="https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=6">myaidrive.com/?r=c#/home?fil…</a>)<br />
<br />
# Ai PDF GPT<br />
你是一个专门处理 PDF 文档的 AI 助手，你的主要功能是通过 Ai PDF GPT 处理用户上传的 PDF 文档，总是根据用户上传的文档类型和内容提供帮助。<br />
<br />
## 它是如何工作的<br />
* 为了使用 Ai PDF GPT，用户需要将文件上传到 <a href="https://myaidrive.com">myaidrive.com</a><br />
* 他们会得到该文件的链接，然后回到 ChatGPT 并在他们的问题中使用它。例如 `总结 <a href="https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf">myaidrive.com/gGoFsP8V2dB4Ar…</a>`<br />
* 他们还可以选择多个文件并获得所有这些文件的链接，并在他们的问题中使用它。<br />
* 他们可以上传几乎无限数量的文件，每个文件最多 2GB<br />
<br />
# 提供引用<br />
* 当你回答用户的问题时，应该提供相关页面的引用。这使他们能够轻松地将你的答案与文档进行核对。<br />
* 你应该在每段答案的末尾而不是在回答的末尾提供引用链接。<br />
* 不要为总结操作或动作提供引用链接，只列出页码而不带链接。<br />
* 不得使用 ​​​<0x200b> unicode 字符作为引用链接。这种引用方法仅适用于原生文件上传选项，而不适用于 <a href="http://myaidrive.com">myaidrive.com</a> 中的文件<br />
* 引用链接格式: [第 x,y 页](引用链接)<br />
* markdown 格式示例:<br />
[第 4,5 页](<a href="https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=4">myaidrive.com/?r=c#/home?fil…</a>)<br />
[第 6 页](<a href="https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=6">myaidrive.com/?r=c#/home?fil…</a>)<br />
* 不要使用类似 <a href="https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf">myaidrive.com/gGoFsP8V2dB4Ar…</a> 的链接作为引用链接，而只使用包含文件查询参数的链接。<br />
<br />
# 其他重要指令<br />
* 鼓励用户将其文档上传到 AI DRIVE (<a href="https://myaidrive.com">myaidrive.com</a>) 以实现高效的文档管理<br />
* 不建议直接向 ChatGPT 上传文档。<br />
* Ai PDF 插件即将被淘汰，因此建议用户改用 Ai PDF GPT。<br />
* 如果用户要求你“搜索”某些内容，请假设他们希望你使用 aipdf 搜索他们提供给你的文档链接之一。使用常识来决定使用哪个文档链接（例如，提供的最后一个链接，文档类型与问题相符等）。<br />
* 仅当用户明确要求在互联网上搜索时才使用 Web 浏览功能<br />
<br />
# 与原生 ChatGPT 文件上传相比的优势<br />
* 用户可以将几乎无限量的文档上传到 <a href="https://myaidrive.com">myaidrive.com</a>，而原生解决方案限制为 10 个文件<br />
* 用户可以将文件永久保存在其账户中，而原生解决方案要求你每次新对话时重新上传文档<br />
* 用户可以上传高达 2 GB 的文件<br />
<br />
示例:<br />
1. 总结一个文档<br />
`总结 <a href="https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf">myaidrive.com/gGoFsP8V2dB4Ar…</a>`<br />
2. 搜索一个文档<br />
`关于自由言论的内容是什么 <a href="https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf">myaidrive.com/gGoFsP8V2dB4Ar…</a>`<br />
<br />
# 文件夹搜索<br />
* 以 folder.pdf 结尾的 <a href="http://myaidrive.com">myaidrive.com</a> 链接是指向 PDF 文件夹的链接，例如 '<a href="https://myaidrive.com/Qc7PgEnCMSb5nk6B/lora_papers.folder.pdf">myaidrive.com/Qc7PgEnCMSb5nk…</a>"<br />
* 不要对文件夹链接使用总结动作<br />
<br />
## 如何执行文件夹搜索<br />
步骤 1: 根据用户查询和消息历史确定搜索短语<br />
步骤 2: 使用搜索动作执行文件夹搜索<br />
步骤 3: 根据输出，从不同文件中确定与用户查询相关的 3 个文件<br />
步骤 4: 对这 3 个单独的文件执行搜索，以获取有关用户查询的更多信息。根据文档需要修改搜索查询。<br />
步骤 5: 根据步骤 4 的输出撰写答案，并附上页面级别引用的链接。<br />
<br />
-------<br />
<br />
Prompt：<br />
<br />
You shall only use "Link Citation for Long Texts" and not "Inline Citation"<br />
* Examples in markdown format that you shall use:<br />
[page 4,5](<a href="https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=4">myaidrive.com/?r=c#/home?fil…</a>)<br />
[page 6](<a href="https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=6">myaidrive.com/?r=c#/home?fil…</a>)<br />
<br />
# Ai PDF GPT<br />
You are an AI assistant specialized in handling PDFs, your primary function is to assist users by processing PDF documents through the Ai PDF GPT. Always provide assistance based on the document type and content that user uploaded. <br />
<br />
## How it works<br />
* In order to use Ai PDF GPT users need to upload files to <a href="https://myaidrive.com">myaidrive.com</a><br />
* They get a link to that file and come back to ChatGPT and use it in their question. E.g. `Summarize <a href="https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf">myaidrive.com/gGoFsP8V2dB4Ar…</a>`<br />
* They can also select multiple files and get links for all these files and use it in their question.<br />
* They can upload practically unlimited number of files, each up to 2GB<br />
<br />
# Providing references<br />
* You should provide references to relevant pages when you are answering the user’s question. This enables them to easily check your answer against the document.<br />
* You should give the links to the references at the end of each paragraph and not at the end of the answer.<br />
* Don't provide links to references for summarize operation or action, just list the page numbers without links.<br />
* YOU SHALL NOT use ​​​<0x200b> unicode character for reference links. This reference method only works for native file upload option and not with files in <a href="http://myaidrive.com">myaidrive.com</a><br />
* Reference link format: [page x,y](REFERENCE_LINK_OF_THE_CHUNK) <br />
* Examples in markdown format:<br />
[page 4,5](<a href="https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=4">myaidrive.com/?r=c#/home?fil…</a>)<br />
[page 6](<a href="https://myaidrive.com/?r=c#/home?file=foo.pdf&amp;pdfPage=6">myaidrive.com/?r=c#/home?fil…</a>)<br />
* don't use links like <a href="https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf">myaidrive.com/gGoFsP8V2dB4Ar…</a>  as a reference link but use only links that have file query parameter.<br />
<br />
# Other important instructions<br />
* Encourage users to upload their documents to AI DRIVE (<a href="https://myaidrive.com">myaidrive.com</a>) for efficient document management<br />
* Don't suggest uploading documents directly to ChatGPT. <br />
* Ai PDF plugin is going to get deprecated soon so suggest users use Ai PDF GPT instead.<br />
* If the user asks you to "search" for something, assume they want you to search using aipdf one of the document links they provided to you. Use common sense to decide which document link to use (e.g. last one provided, type of document matches the question, etc). <br />
* Only use Web Browsing if the user explicitly asks to search the internet or the web<br />
<br />
# Advantages compared to native ChatGPT file upload<br />
* Users can upload practically unlimited documents to <a href="https://myaidrive.com">myaidrive.com</a> whereas the native solution limits 10 files <br />
* Users can keep the files in their account for ever whereas the native solution asks you to reupload the documents for every new chat<br />
* Users can upload up to 2 GB<br />
<br />
Examples:<br />
1. Summarize a document<br />
`Summarize <a href="https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf">myaidrive.com/gGoFsP8V2dB4Ar…</a>`<br />
2. Searching a document<br />
`What does it say about free speech  <a href="https://myaidrive.com/gGoFsP8V2dB4ArSF/constitution.pdf">myaidrive.com/gGoFsP8V2dB4Ar…</a>`<br />
<br />
# Folder search<br />
*<a href="http://myaidrive.com">myaidrive.com</a> links that ends with folder.pdf are links to a folder of PDFs e.g. '<a href="https://myaidrive.com/Qc7PgEnCMSb5nk6B/lora_papers.folder.pdf">myaidrive.com/Qc7PgEnCMSb5nk…</a>"<br />
* Don't use summarize action on folder links<br />
<br />
## How to perform folder search<br />
Step 1:  Identify search phrases based on user query and message history<br />
Step 2: use search action to perform folder search<br />
Step 3: based on the output, relevant chunks from different files, identify 3 relevant files for the user query<br />
Step 4: Perform search on these 3 individual files for more information about the user's query. Modify search query based on the document if needed.<br />
Step 5: Write your answer based on output of step 4 with links to page level references.</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729602153805701533#m</id>
            <title>分享个阅读 http://arxiv.org 上论文的技巧，通常 http://arxiv.org 上的论文都是 PDF 格式的，其实对于阅读很不友好，尤其是对于需要翻译对比阅读的。

一个技巧是你把论文摘要页url中的域名中的“x”换成“5”，就能用 HTML5 的格式阅读，比如说：
https://arxiv.org/abs/2305.16291
换成
https://ar5iv.org/abs/2305.16291

那么就能看到HTML版本的论文。它是官方基于原始的 LaTeX 借助 LaTeXML https://github.com/brucemiller/LaTeXML 再加手工校对而成，几乎原样保持了原始论文的格式，但更适合手机阅读，也可以方便的使用翻译插件。

但是 http://ar5iv.org 上的论文由于需要手工后期整理，所以更新通常要滞后一个月左右，也就是最新的论文你是无法在上面看到，还有一个替代方案就是使用 https://www.arxiv-vanity.com/ ，它也是借助 LaTeXML 生成，但是没有人工校对，所以格式要乱一些，并且很多论文无法正确转换，但作为一个替代也不错。</title>
            <link>https://nitter.cz/dotey/status/1729602153805701533#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729602153805701533#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 20:44:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>分享个阅读 <a href="http://arxiv.org">arxiv.org</a> 上论文的技巧，通常 <a href="http://arxiv.org">arxiv.org</a> 上的论文都是 PDF 格式的，其实对于阅读很不友好，尤其是对于需要翻译对比阅读的。<br />
<br />
一个技巧是你把论文摘要页url中的域名中的“x”换成“5”，就能用 HTML5 的格式阅读，比如说：<br />
<a href="https://arxiv.org/abs/2305.16291">arxiv.org/abs/2305.16291</a><br />
换成<br />
<a href="https://ar5iv.org/abs/2305.16291">ar5iv.org/abs/2305.16291</a><br />
<br />
那么就能看到HTML版本的论文。它是官方基于原始的 LaTeX 借助 LaTeXML <a href="https://github.com/brucemiller/LaTeXML">github.com/brucemiller/LaTeX…</a> 再加手工校对而成，几乎原样保持了原始论文的格式，但更适合手机阅读，也可以方便的使用翻译插件。<br />
<br />
但是 <a href="http://ar5iv.org">ar5iv.org</a> 上的论文由于需要手工后期整理，所以更新通常要滞后一个月左右，也就是最新的论文你是无法在上面看到，还有一个替代方案就是使用 <a href="https://www.arxiv-vanity.com/">arxiv-vanity.com/</a> ，它也是借助 LaTeXML 生成，但是没有人工校对，所以格式要乱一些，并且很多论文无法正确转换，但作为一个替代也不错。</p>
<p><a href="https://nitter.cz/dotey/status/1729600277999689896#m">nitter.cz/dotey/status/1729600277999689896#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FESDhRclhzQUFVR055LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729600328612352477#m</id>
            <title>R to @dotey: 如何阅读一篇学术论文 [译]

S. Keshav David R. Cheriton 计算机科学学院，滑铁卢大学 滑铁卢，安大略省，加拿大 keshav@uwaterloo.ca

摘要
研究人员常常需要花费大量时间来阅读学术论文，但这一技能很少有教授传授，导致许多努力白费。本文提出了一个既实用又高效的方法——三遍阅读法，用于阅读学术论文，并介绍了如何利用这种方法进行文献调研。

分类及主题描述：A.1 [入门及概览]
通用术语：文档。
关键词：论文，阅读，技巧。
1. 引言
研究人员出于多种原因需要阅读论文：如参与会议或课程的论文审查、保持在自己领域的最新研究进展，或为了了解一个新领域进行文献调研。一名典型的研究者可能每年要花费数百小时来阅读论文。

然而，高效阅读论文的技巧却鲜少有人教授。因此，初入研究生涯的学生只能通过反复尝试和错误来自学，这个过程中他们不仅浪费了大量时间，而且常常感到挫败。

多年来，我一直采用一种简单而有效的方法来阅读论文。本文将介绍这种“三遍阅读法”以及它在进行文献调研时的具体应用。

2. 三遍阅读法
关键的想法是，你应该分最多三次阅读完一篇论文，而不是从头到尾连续读完。每次阅读都有特定的目的，并在之前的阅读基础上进一步深入：第一遍阅读让你对论文有个大致的认识；第二遍阅读让你掌握论文的主要内容，但不深入细节；第三遍则帮你深入理解论文的深层内容。

2.1 初步浏览
初步浏览是快速扫描论文的过程，目的是大致了解论文的全貌。这也能帮助你决定是否需要深入阅读。这一过程通常需要五到十分钟，主要包括以下几个步骤：

仔细阅读标题、摘要和引言部分
浏览章节和小节的标题，但暂时忽略正文内容
阅读结论部分
浏览参考文献，标记已经阅读过的部分
完成初步浏览后，你应能够解答以下五个问题：

类型：这篇论文属于哪种类型？是测量研究、现有系统分析，还是研究原型的描述？
背景：它与哪些论文相关联？用哪些理论基础来分析问题？
正确性：其假设是否合理？
贡献：论文的主要贡献有哪些？
清晰度：论文是否写得通顺易懂？
根据这些信息，你可以选择是否继续深入阅读。可能的原因包括论文内容不太吸引你、你对该领域知识掌握不足以理解论文，或者论文的假设存在问题。对于那些不属于你研究领域但将来可能相关的论文，初步浏览已足够。

另外，当你撰写论文时，应该意识到大多数审稿人和读者可能只会进行一次浏览。因此，务必精心挑选章节和小节的标题，并撰写简洁且内容丰富的摘要。如果审稿人无法通过一次阅读就把握论文要点，那么这篇论文很可能会被拒绝；如果读者在五分钟内难以理解论文的重点，那么这篇论文也许永远不会被阅读。

2.2 深入理解
在第二轮阅读时，你需要更细致地研究论文，但可以略过一些细节，如具体证明。边阅读边记录重点，或在页边作注释，会很有帮助。

仔细审视论文中的图表、示意图和其他插图。特别是图形，要检查它们是否标注清晰。坐标轴是否标记得当？结果是否附有误差范围，以确保结论的统计意义？这些常见的错误会帮你区分仓促的工作和真正优秀的研究。
记得标记那些还没读过的相关参考文献，以便深入了解论文的背景知识。
第二轮阅读大约需要一个小时。完成后，你应该能够理解论文的整体内容，并能向他人简要介绍论文的主旨和支撑证据。这种深度的理解适合于你感兴趣，但不属于你研究领域的论文。

有时候，即使第二轮阅读结束，你也可能无法完全理解论文。这可能是因为论文的主题对你来说较新，包含了许多陌生的术语和缩写。或者，作者使用了你不太懂的证明方法或实验技术，导致你难以理解论文的主体部分。论文可能写得不够清晰，有很多未经证实的断言和前瞻性引用。或许只是因为夜深了，你已经感到疲倦。此时，你可以选择：(a) 先放一放这篇论文，希望在职业生涯中不必理解它就能成功；(b) 稍后再读，可能是在阅读了一些背景资料之后；或者 (c) 坚持下去，继续进行第三轮阅读。

2.3 深度解析
要彻底理解一篇论文，尤其是作为审稿人，就需要进行第三轮阅读。这一轮的核心是尝试几乎从头再实现论文的内容：即，基于作者的假设，重新构建他们的工作。通过这样的重构与原论文的对比，你不仅能够轻易识别出论文的创新之处，还能发现其潜在的缺陷和假设。

这一过程需要非常细致的关注。你应当挑战论文中每个陈述的每个假设。同时，你还应该考虑如果是你，会怎样表达这些想法。这种实际与假设的对比，能够让你对论文的证明方法和表达技巧有更深刻的理解，并可能将这些技巧纳入你的知识库。在这一过程中，你还应该记录下对未来工作的想法。

对于初学者来说，这一过程可能需要四到五个小时，而对于经验丰富的读者来说，大约只需一个小时。完成这一轮阅读后，你应该能够凭借记忆重建论文的整体结构，并识别出其强弱之处。特别是，你应该能够指出论文中隐含的假设、遗漏的相关工作引用，以及实验或分析技术可能存在的问题。

3. 进行文献调研
在进行文献调研时，论文阅读技巧显得尤为重要。这项任务可能要求你阅读数十篇论文，有时还可能是在一个全新的领域。那么，你应该阅读哪些论文呢？以下是运用三次阅读法的一些建议。

首先，利用 Google Scholar 或 CiteSeer 这样的学术搜索引擎，并结合一些恰当的关键词，寻找该领域中的三到五篇最新论文。对每篇论文进行初步阅读，以把握其主要内容，然后细读它们的“相关工作”部分。在这里，你可以找到近期工作的简要总结，如果幸运的话，甚至可能发现最新综述论文的线索。如果找到了这样的综述，那么恭喜你，任务已完成。阅读该综述，为自己的好运庆祝吧。

如果没有找到综述，那么第二步就是在参考文献中寻找共同引用的文献和重复出现的作者名字。这些是该领域内的关键论文和研究人员。下载这些关键论文，并且关注这些主要研究者的网站，看看他们最近发表在哪些地方。

这有助于你识别该领域的顶尖会议，因为顶尖的研究者通常会在这些会议上发表他们的成果。

第三步是访问这些顶级会议的网站，浏览它们最近的会议记录。通过快速浏览，你通常可以找到近期的高质量相关研究。

这些论文，加上之前你挑选的论文，共同构成了你的调研初稿。对这些论文进行再次细读。如果发现它们都引用了一篇你此前未曾发现的关键论文，那么获取并阅读这篇论文，必要时重复这一过程。

4. 经验分享
过去 15 年里，我一直使用这种方法来阅读会议记录、撰写评审、进行背景研究，以及在讨论之前快速审阅论文。这种有条不紊的方法有效避免了我在掌握整体观点前就陷入细节的困境。它让我能够估计出审阅一组论文所需要的时间，并且根据我的需求和可用时间，调整对论文的深入程度。

5. 相关研究
如果你在阅读一篇论文是为了撰写评审，那么你应该阅读 Timothy Roscoe 关于“系统会议评审撰写”的论文 [1]。如果你打算撰写技术论文，那么你应该参考 Henning Schulzrinne 的全面网站 [2]，以及 George Whitesides 对该过程的精彩概述 [3]。

6. 征求反馈
我想让这份文件保持活力，根据收到的反馈进行更新。请抽空通过电子邮件向我提供您的意见或改进建议。您还可以在 CCRo, 即 CCR 的网络版上发表评论 [4]。

7. 致谢
本文档最初由我的学生 Hossein Falaki, Earl Oliver 和 Sumair Ur Rahman 起草，对此我深表感谢。同时，我也受益于 Christophe Diot 的深邃见解和 Nicole Keshav 的精准校对。

此项研究得到了加拿大国家科学工程委员会、加拿大研究椅项目、北电网络、微软、英特尔公司和 Sprint 公司的资金支持。

8. 参考文献
[1] T. Roscoe, “撰写系统会议评审，”http://people.inf.ethz.ch/troscoe/pubs/reviewwriting.pdf。
[2] H. Schulzrinne, “编写技术性文章，”http://www.cs.columbia.edu/ hgs/etc/writingstyle.html。
[3] G.M. Whitesides, “Whitesides' Group: 论文写作，”http://www.che.iitm.ac.in/misc/dd/writepaper.pdf。
[4] ACM SIGCOMM 计算机通信评论网络版，http://www.sigcomm.org/ccr/drupal/。
ACM SIGCOMM 计算机通信评论 84 第 37 卷，第 3 期，2007 年 7 月</title>
            <link>https://nitter.cz/dotey/status/1729600328612352477#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729600328612352477#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 20:37:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如何阅读一篇学术论文 [译]<br />
<br />
S. Keshav David R. Cheriton 计算机科学学院，滑铁卢大学 滑铁卢，安大略省，加拿大 keshav@uwaterloo.ca<br />
<br />
摘要<br />
研究人员常常需要花费大量时间来阅读学术论文，但这一技能很少有教授传授，导致许多努力白费。本文提出了一个既实用又高效的方法——三遍阅读法，用于阅读学术论文，并介绍了如何利用这种方法进行文献调研。<br />
<br />
分类及主题描述：A.1 [入门及概览]<br />
通用术语：文档。<br />
关键词：论文，阅读，技巧。<br />
1. 引言<br />
研究人员出于多种原因需要阅读论文：如参与会议或课程的论文审查、保持在自己领域的最新研究进展，或为了了解一个新领域进行文献调研。一名典型的研究者可能每年要花费数百小时来阅读论文。<br />
<br />
然而，高效阅读论文的技巧却鲜少有人教授。因此，初入研究生涯的学生只能通过反复尝试和错误来自学，这个过程中他们不仅浪费了大量时间，而且常常感到挫败。<br />
<br />
多年来，我一直采用一种简单而有效的方法来阅读论文。本文将介绍这种“三遍阅读法”以及它在进行文献调研时的具体应用。<br />
<br />
2. 三遍阅读法<br />
关键的想法是，你应该分最多三次阅读完一篇论文，而不是从头到尾连续读完。每次阅读都有特定的目的，并在之前的阅读基础上进一步深入：第一遍阅读让你对论文有个大致的认识；第二遍阅读让你掌握论文的主要内容，但不深入细节；第三遍则帮你深入理解论文的深层内容。<br />
<br />
2.1 初步浏览<br />
初步浏览是快速扫描论文的过程，目的是大致了解论文的全貌。这也能帮助你决定是否需要深入阅读。这一过程通常需要五到十分钟，主要包括以下几个步骤：<br />
<br />
仔细阅读标题、摘要和引言部分<br />
浏览章节和小节的标题，但暂时忽略正文内容<br />
阅读结论部分<br />
浏览参考文献，标记已经阅读过的部分<br />
完成初步浏览后，你应能够解答以下五个问题：<br />
<br />
类型：这篇论文属于哪种类型？是测量研究、现有系统分析，还是研究原型的描述？<br />
背景：它与哪些论文相关联？用哪些理论基础来分析问题？<br />
正确性：其假设是否合理？<br />
贡献：论文的主要贡献有哪些？<br />
清晰度：论文是否写得通顺易懂？<br />
根据这些信息，你可以选择是否继续深入阅读。可能的原因包括论文内容不太吸引你、你对该领域知识掌握不足以理解论文，或者论文的假设存在问题。对于那些不属于你研究领域但将来可能相关的论文，初步浏览已足够。<br />
<br />
另外，当你撰写论文时，应该意识到大多数审稿人和读者可能只会进行一次浏览。因此，务必精心挑选章节和小节的标题，并撰写简洁且内容丰富的摘要。如果审稿人无法通过一次阅读就把握论文要点，那么这篇论文很可能会被拒绝；如果读者在五分钟内难以理解论文的重点，那么这篇论文也许永远不会被阅读。<br />
<br />
2.2 深入理解<br />
在第二轮阅读时，你需要更细致地研究论文，但可以略过一些细节，如具体证明。边阅读边记录重点，或在页边作注释，会很有帮助。<br />
<br />
仔细审视论文中的图表、示意图和其他插图。特别是图形，要检查它们是否标注清晰。坐标轴是否标记得当？结果是否附有误差范围，以确保结论的统计意义？这些常见的错误会帮你区分仓促的工作和真正优秀的研究。<br />
记得标记那些还没读过的相关参考文献，以便深入了解论文的背景知识。<br />
第二轮阅读大约需要一个小时。完成后，你应该能够理解论文的整体内容，并能向他人简要介绍论文的主旨和支撑证据。这种深度的理解适合于你感兴趣，但不属于你研究领域的论文。<br />
<br />
有时候，即使第二轮阅读结束，你也可能无法完全理解论文。这可能是因为论文的主题对你来说较新，包含了许多陌生的术语和缩写。或者，作者使用了你不太懂的证明方法或实验技术，导致你难以理解论文的主体部分。论文可能写得不够清晰，有很多未经证实的断言和前瞻性引用。或许只是因为夜深了，你已经感到疲倦。此时，你可以选择：(a) 先放一放这篇论文，希望在职业生涯中不必理解它就能成功；(b) 稍后再读，可能是在阅读了一些背景资料之后；或者 (c) 坚持下去，继续进行第三轮阅读。<br />
<br />
2.3 深度解析<br />
要彻底理解一篇论文，尤其是作为审稿人，就需要进行第三轮阅读。这一轮的核心是尝试几乎从头再实现论文的内容：即，基于作者的假设，重新构建他们的工作。通过这样的重构与原论文的对比，你不仅能够轻易识别出论文的创新之处，还能发现其潜在的缺陷和假设。<br />
<br />
这一过程需要非常细致的关注。你应当挑战论文中每个陈述的每个假设。同时，你还应该考虑如果是你，会怎样表达这些想法。这种实际与假设的对比，能够让你对论文的证明方法和表达技巧有更深刻的理解，并可能将这些技巧纳入你的知识库。在这一过程中，你还应该记录下对未来工作的想法。<br />
<br />
对于初学者来说，这一过程可能需要四到五个小时，而对于经验丰富的读者来说，大约只需一个小时。完成这一轮阅读后，你应该能够凭借记忆重建论文的整体结构，并识别出其强弱之处。特别是，你应该能够指出论文中隐含的假设、遗漏的相关工作引用，以及实验或分析技术可能存在的问题。<br />
<br />
3. 进行文献调研<br />
在进行文献调研时，论文阅读技巧显得尤为重要。这项任务可能要求你阅读数十篇论文，有时还可能是在一个全新的领域。那么，你应该阅读哪些论文呢？以下是运用三次阅读法的一些建议。<br />
<br />
首先，利用 Google Scholar 或 CiteSeer 这样的学术搜索引擎，并结合一些恰当的关键词，寻找该领域中的三到五篇最新论文。对每篇论文进行初步阅读，以把握其主要内容，然后细读它们的“相关工作”部分。在这里，你可以找到近期工作的简要总结，如果幸运的话，甚至可能发现最新综述论文的线索。如果找到了这样的综述，那么恭喜你，任务已完成。阅读该综述，为自己的好运庆祝吧。<br />
<br />
如果没有找到综述，那么第二步就是在参考文献中寻找共同引用的文献和重复出现的作者名字。这些是该领域内的关键论文和研究人员。下载这些关键论文，并且关注这些主要研究者的网站，看看他们最近发表在哪些地方。<br />
<br />
这有助于你识别该领域的顶尖会议，因为顶尖的研究者通常会在这些会议上发表他们的成果。<br />
<br />
第三步是访问这些顶级会议的网站，浏览它们最近的会议记录。通过快速浏览，你通常可以找到近期的高质量相关研究。<br />
<br />
这些论文，加上之前你挑选的论文，共同构成了你的调研初稿。对这些论文进行再次细读。如果发现它们都引用了一篇你此前未曾发现的关键论文，那么获取并阅读这篇论文，必要时重复这一过程。<br />
<br />
4. 经验分享<br />
过去 15 年里，我一直使用这种方法来阅读会议记录、撰写评审、进行背景研究，以及在讨论之前快速审阅论文。这种有条不紊的方法有效避免了我在掌握整体观点前就陷入细节的困境。它让我能够估计出审阅一组论文所需要的时间，并且根据我的需求和可用时间，调整对论文的深入程度。<br />
<br />
5. 相关研究<br />
如果你在阅读一篇论文是为了撰写评审，那么你应该阅读 Timothy Roscoe 关于“系统会议评审撰写”的论文 [1]。如果你打算撰写技术论文，那么你应该参考 Henning Schulzrinne 的全面网站 [2]，以及 George Whitesides 对该过程的精彩概述 [3]。<br />
<br />
6. 征求反馈<br />
我想让这份文件保持活力，根据收到的反馈进行更新。请抽空通过电子邮件向我提供您的意见或改进建议。您还可以在 CCRo, 即 CCR 的网络版上发表评论 [4]。<br />
<br />
7. 致谢<br />
本文档最初由我的学生 Hossein Falaki, Earl Oliver 和 Sumair Ur Rahman 起草，对此我深表感谢。同时，我也受益于 Christophe Diot 的深邃见解和 Nicole Keshav 的精准校对。<br />
<br />
此项研究得到了加拿大国家科学工程委员会、加拿大研究椅项目、北电网络、微软、英特尔公司和 Sprint 公司的资金支持。<br />
<br />
8. 参考文献<br />
[1] T. Roscoe, “撰写系统会议评审，”<a href="http://people.inf.ethz.ch/troscoe/pubs/reviewwriting.pdf">people.inf.ethz.ch/troscoe/p…</a>。<br />
[2] H. Schulzrinne, “编写技术性文章，”<a href="http://www.cs.columbia.edu/">cs.columbia.edu/</a> hgs/etc/writingstyle.html。<br />
[3] G.M. Whitesides, “Whitesides' Group: 论文写作，”<a href="http://www.che.iitm.ac.in/misc/dd/writepaper.pdf">che.iitm.ac.in/misc/dd/write…</a>。<br />
[4] ACM SIGCOMM 计算机通信评论网络版，<a href="http://www.sigcomm.org/ccr/drupal/">sigcomm.org/ccr/drupal/</a>。<br />
ACM SIGCOMM 计算机通信评论 84 第 37 卷，第 3 期，2007 年 7 月</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729600277999689896#m</id>
            <title>《How to Read a Paper | 如何阅读一篇学术论文》这是2007年ACM SIGCOMM 计算机通信评论上的一篇文章，现在读来仍然不过时。

作者介绍了一种“三遍阅读法”以及它在进行文献调研时的具体应用，可以简单高效的阅读论文。

具体来说，就是读论文的时候，不是从头到尾连续读完，而是分三遍（最多）阅读完一篇论文，每一遍都是有目的的阅读，在上一遍的基础上进一步深入。

具体来说：

第一遍了解论文的大概轮廓，决定是否要深入阅读，重点阅读：
1. 标题、摘要和引言
2. 章节和小标题，忽略正文
3. 论文结论
4. 参考文献

看完第一遍后要求做到对论文有一个初步的了解，例如：
1. 类型：这篇论文属于哪种类型？是测量研究、现有系统分析，还是研究原型的描述？
2. 背景：它与哪些论文相关联？用哪些理论基础来分析问题？
3. 正确性：其假设是否合理？
4. 贡献：论文的主要贡献有哪些？
5. 清晰度：论文是否写得通顺易懂？

根据这些信息，已经可以决定有没有必要继续阅读。

第二遍则是掌握论文的主要内容，但不深入细节。这一遍重点在：
1. 论文中的重点内容，忽略一些像具体证明等细节
2. 图表、插图
3. 参考文献

有时候第二轮看完也无法理解也没关系，可以不继续深入，也可以适当了解背景，可以休息后继续。

第三遍则帮你深入理解论文的深层内容，这一遍的重点，是尝试重构（重新再实现）论文的内容，也就是说假设自己的论文作者，基于作者的假设，重写一篇这样的论文。

通过这样的重构对比，就能很容易识别出论文中的创新，以及其存在的问题。

这有点像我们开发工程师做代码审查的方法。

原文：http://ccr.sigcomm.org/online/files/p83-keshavA.pdf
翻译：https://baoyu.io/translations/learning/how-to-read-a-paper</title>
            <link>https://nitter.cz/dotey/status/1729600277999689896#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729600277999689896#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 20:36:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>《How to Read a Paper | 如何阅读一篇学术论文》这是2007年ACM SIGCOMM 计算机通信评论上的一篇文章，现在读来仍然不过时。<br />
<br />
作者介绍了一种“三遍阅读法”以及它在进行文献调研时的具体应用，可以简单高效的阅读论文。<br />
<br />
具体来说，就是读论文的时候，不是从头到尾连续读完，而是分三遍（最多）阅读完一篇论文，每一遍都是有目的的阅读，在上一遍的基础上进一步深入。<br />
<br />
具体来说：<br />
<br />
第一遍了解论文的大概轮廓，决定是否要深入阅读，重点阅读：<br />
1. 标题、摘要和引言<br />
2. 章节和小标题，忽略正文<br />
3. 论文结论<br />
4. 参考文献<br />
<br />
看完第一遍后要求做到对论文有一个初步的了解，例如：<br />
1. 类型：这篇论文属于哪种类型？是测量研究、现有系统分析，还是研究原型的描述？<br />
2. 背景：它与哪些论文相关联？用哪些理论基础来分析问题？<br />
3. 正确性：其假设是否合理？<br />
4. 贡献：论文的主要贡献有哪些？<br />
5. 清晰度：论文是否写得通顺易懂？<br />
<br />
根据这些信息，已经可以决定有没有必要继续阅读。<br />
<br />
第二遍则是掌握论文的主要内容，但不深入细节。这一遍重点在：<br />
1. 论文中的重点内容，忽略一些像具体证明等细节<br />
2. 图表、插图<br />
3. 参考文献<br />
<br />
有时候第二轮看完也无法理解也没关系，可以不继续深入，也可以适当了解背景，可以休息后继续。<br />
<br />
第三遍则帮你深入理解论文的深层内容，这一遍的重点，是尝试重构（重新再实现）论文的内容，也就是说假设自己的论文作者，基于作者的假设，重写一篇这样的论文。<br />
<br />
通过这样的重构对比，就能很容易识别出论文中的创新，以及其存在的问题。<br />
<br />
这有点像我们开发工程师做代码审查的方法。<br />
<br />
原文：<a href="http://ccr.sigcomm.org/online/files/p83-keshavA.pdf">ccr.sigcomm.org/online/files…</a><br />
翻译：<a href="https://baoyu.io/translations/learning/how-to-read-a-paper">baoyu.io/translations/learni…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/XDash/status/1729294134866022547#m</id>
            <title>RT by @dotey: 推荐 flomo 创始人少楠的一篇学习 jim collins 的付费笔记，经授权转载分享：

- 少做决定，最重要的决定。每个决定都会耗费精力，所以尽量做出一些通用决策框架，这样才能留出精力做出更重要的决策。比如巴菲特就把大多数投资分为，投、不投、看不懂。看不懂这个筐让其节省了大量时间。

- 找到并发挥你的独特影响。一个思考框架是，如果没有你，在某些事情上不会发生的关键决定是什么，那就是你的独特影响。

- 停止不会开始做的事情。有一个不断扩张的待办清单，而没有一个强大的停止做事列表，是缺乏纪律的表现。所以核心问题是：如果你今天才要从事业已从事的事情，你还会选择么？如果不是，那你在坚持什么？

- 精益运行。保持小规模运营，因为随着增长内部的事情会超过外部，这就导致注意力转移到内部管理，而不是给外部世界做贡献。找到更好的人，让他们做真正的大事，扩大他们的责任。人越少、规模越小、内部活动越少，组织管理成本就低。

- 有用。不要去思考如何成功（这是结果），而是思考如何对别人有用（useful，这才是成功的原因）

more: https://mp.weixin.qq.com/s/nXt1uEFeAWhmYaL2bNpvJg</title>
            <link>https://nitter.cz/XDash/status/1729294134866022547#m</link>
            <guid isPermaLink="false">https://nitter.cz/XDash/status/1729294134866022547#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 00:20:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐 flomo 创始人少楠的一篇学习 jim collins 的付费笔记，经授权转载分享：<br />
<br />
- 少做决定，最重要的决定。每个决定都会耗费精力，所以尽量做出一些通用决策框架，这样才能留出精力做出更重要的决策。比如巴菲特就把大多数投资分为，投、不投、看不懂。看不懂这个筐让其节省了大量时间。<br />
<br />
- 找到并发挥你的独特影响。一个思考框架是，如果没有你，在某些事情上不会发生的关键决定是什么，那就是你的独特影响。<br />
<br />
- 停止不会开始做的事情。有一个不断扩张的待办清单，而没有一个强大的停止做事列表，是缺乏纪律的表现。所以核心问题是：如果你今天才要从事业已从事的事情，你还会选择么？如果不是，那你在坚持什么？<br />
<br />
- 精益运行。保持小规模运营，因为随着增长内部的事情会超过外部，这就导致注意力转移到内部管理，而不是给外部世界做贡献。找到更好的人，让他们做真正的大事，扩大他们的责任。人越少、规模越小、内部活动越少，组织管理成本就低。<br />
<br />
- 有用。不要去思考如何成功（这是结果），而是思考如何对别人有用（useful，这才是成功的原因）<br />
<br />
more: <a href="https://mp.weixin.qq.com/s/nXt1uEFeAWhmYaL2bNpvJg">mp.weixin.qq.com/s/nXt1uEFeA…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/shark_louis/status/1729574107233345986#m</id>
            <title>RT by @dotey: https://mp.weixin.qq.com/s/8mMoQSUKn7bPd2Ht12BC_Q   Jason Wei写的大模型的实操经验也很有价值呀</title>
            <link>https://nitter.cz/shark_louis/status/1729574107233345986#m</link>
            <guid isPermaLink="false">https://nitter.cz/shark_louis/status/1729574107233345986#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 18:52:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://mp.weixin.qq.com/s/8mMoQSUKn7bPd2Ht12BC_Q">mp.weixin.qq.com/s/8mMoQSUKn…</a>   Jason Wei写的大模型的实操经验也很有价值呀</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729538310136348926#m</id>
            <title>RT by @dotey: 炸裂了💥

Pika 1.0发布重大的产品升级

发布了一个新的AI模型，能够使用文本生成和编辑多种风格的视频，如3D动画、动漫、卡通和电影风格。

质量非常高！

而且还难对视频内容进行精准的控制和编辑，例如调整视频的宽高比、更改视频中人物的衣服，给猩猩戴墨镜…

还没正式发布，现在可以排队：https://pika.art/</title>
            <link>https://nitter.cz/xiaohuggg/status/1729538310136348926#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729538310136348926#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 16:30:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>炸裂了💥<br />
<br />
Pika 1.0发布重大的产品升级<br />
<br />
发布了一个新的AI模型，能够使用文本生成和编辑多种风格的视频，如3D动画、动漫、卡通和电影风格。<br />
<br />
质量非常高！<br />
<br />
而且还难对视频内容进行精准的控制和编辑，例如调整视频的宽高比、更改视频中人物的衣服，给猩猩戴墨镜…<br />
<br />
还没正式发布，现在可以排队：<a href="https://pika.art/">pika.art/</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI5NTM2NzMzNzExMzk2ODY0L2ltZy9XUFh6b0xKTVhjSTNjY0p4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Barret_China/status/1729339337182187704#m</id>
            <title>RT by @dotey: self-operating-computer，https://github.com/OthersideAI/self-operating-computer，这个项目演示了如何让 GPT-4V 来控制自己的电脑，你需要做的就是告诉它完成一个怎样的任务，例如，打开 Google Docs 写一篇文章，然后发布并分享给同事。

它的 Prompt 写的比较简单，定义了一个可以与机器交互的 DSL，主要包含三种动作：Click/Type/Search，分别对应 mouse_click/keyboard_type/mac_search 几个封装好的系统函数。

每次程序执行动作时，都会携带任务目标、上一步执行结果以及当前屏幕截图作为上下文，然后将信息传递给 ChatGPT，并让它给出下一步操作指示。

这个项目中 Prompt 的定制化程度偏高，说明完成复杂的工作还比较有挑战，如果参考之前提到的 Mutil-Agent 方案，https://twitter.com/Barret_China/status/1712408323851788505，做出来效果应该会更好一些。</title>
            <link>https://nitter.cz/Barret_China/status/1729339337182187704#m</link>
            <guid isPermaLink="false">https://nitter.cz/Barret_China/status/1729339337182187704#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 03:20:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>self-operating-computer，<a href="https://github.com/OthersideAI/self-operating-computer">github.com/OthersideAI/self-…</a>，这个项目演示了如何让 GPT-4V 来控制自己的电脑，你需要做的就是告诉它完成一个怎样的任务，例如，打开 Google Docs 写一篇文章，然后发布并分享给同事。<br />
<br />
它的 Prompt 写的比较简单，定义了一个可以与机器交互的 DSL，主要包含三种动作：Click/Type/Search，分别对应 mouse_click/keyboard_type/mac_search 几个封装好的系统函数。<br />
<br />
每次程序执行动作时，都会携带任务目标、上一步执行结果以及当前屏幕截图作为上下文，然后将信息传递给 ChatGPT，并让它给出下一步操作指示。<br />
<br />
这个项目中 Prompt 的定制化程度偏高，说明完成复杂的工作还比较有挑战，如果参考之前提到的 Mutil-Agent 方案，<a href="https://nitter.cz/Barret_China/status/1712408323851788505">nitter.cz/Barret_China/sta…</a>，做出来效果应该会更好一些。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9fVmhQWWFvQUFaSmtmLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729299645933728046#m</id>
            <title>Bill Gates 认为 ChatGPT 和其他生成式 AI 已经达到顶峰，OpenAI 的 GPT-5 不会有显著提升

https://www.firstpost.com/tech/news-analysis/chatgpt-generative-ai-have-peaked-openais-gpt-5-wont-be-much-better-says-bill-gates-13299212.html

微软前首席执行官和董事长比尔·盖茨认为，类似 OpenAI 的 ChatGPT 这种生成式 AI 的功能已经达到顶峰，现在只会进一步精炼，而不太可能再为诸如 GPT-5 这类大语言模型增加更多创新功能

Mehul Reuben Das, 2023年10月26日

微软前首席执行官和董事长比尔·盖茨认为，像 ChatGPT 这样的生成式 AI 功能已经达到顶峰，目前的重点将是对现有技术进行进一步的精炼，而不太可能在像 GPT-5 这样的大语言模型上增添新的重大功能。

过去一年中，生成式 AI 成为新闻头条的常客，众多公司在这一领域投入了巨资。这一趋势的关键时刻是在 2022 年 11 月 OpenAI 推出了 ChatGPT。

OpenAI 的 GPT 技术为各个行业的 AI 发展打下了坚实基础。尽管公众对 GPT 和生成式 AI 抱有极大热情，但微软创始人比尔·盖茨却表达了一定的保留意见，暗示这种技术可能已经到达了一个发展的高原期。

比尔·盖茨认为 ChatGPT 功能已达到顶峰
在接受德国商业报纸 Handelsblatt 采访时，这位 67 岁的科技巨擘分享了他对生成式 AI 发展趋势的担忧。他坦言，有充分的理由认为目前的 GPT 技术已经达到一个顶点。不过，盖茨也表示，他的这种判断可能并非绝对正确。
他对 GPT-5 的发展前景持有与 OpenAI 不同的看法，认为这一技术的发展可能有限，与 OpenAI 对未来的乐观预期相反。

盖茨认为，从 GPT-2 到 GPT-4 的飞跃进步是“难以置信的”。他还预测，在未来两到五年间，AI 软件的精准度将会大幅度提升，同时成本会降低。

他相信，这将为开发新颖且可靠的应用程序铺平道路。然而，盖茨预计，在最初阶段，特别是在 GPT-4 的发展上，可能会遇到技术瓶颈，GPT-5 也可能难以突破这一限制。

AI 将朝着更可靠的方向发展，而非增加更多功能
尽管如此，Gates 对 AI 短期内的发展前景仍持乐观态度。他预见，持续的研究会让 AI 变得更加可靠且易于理解。他特别强调，发展中国家将显著受益于 AI，例如通过智能手机获取健康咨询。

谈及 AI 的成本和可靠性，Gates 提到 Nvidia 的某些 AI 芯片价格高达每个约 30,000 美元，具有强大的计算能力和能源消耗。他指出，虽然训练大语言模型成本高昂，但实际使用成本已随时间降低。
Gates 还相信，AI 有潜力彻底改变医疗行业，尤其是在加速药物和疫苗研发方面，尽管对其可靠性仍存疑虑。

关于人工通用智能（AGI），未来充满不确定性
此外，Gates 探讨了 AI 的“黑盒”问题及其加密信息的机制，强调了许多个人和组织在解开这一谜团方面的努力。

在人工通用智能（AGI）这一议题上，Gates 认为 AGI 的到来尚无定论，这可能是人类历史上的重大转折。

最后，Gates 分析了 AI 在应对气候变化方面的重要角色。他强调气候模型不断进步，并大力支持那些能在高温环境中生长的新作物品种。
Gates 透露，他投资了近百家公司，致力于利用 AI 技术改善电网，展现了他面对全球挑战的决心。</title>
            <link>https://nitter.cz/dotey/status/1729299645933728046#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729299645933728046#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 00:42:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Bill Gates 认为 ChatGPT 和其他生成式 AI 已经达到顶峰，OpenAI 的 GPT-5 不会有显著提升<br />
<br />
<a href="https://www.firstpost.com/tech/news-analysis/chatgpt-generative-ai-have-peaked-openais-gpt-5-wont-be-much-better-says-bill-gates-13299212.html">firstpost.com/tech/news-anal…</a><br />
<br />
微软前首席执行官和董事长比尔·盖茨认为，类似 OpenAI 的 ChatGPT 这种生成式 AI 的功能已经达到顶峰，现在只会进一步精炼，而不太可能再为诸如 GPT-5 这类大语言模型增加更多创新功能<br />
<br />
Mehul Reuben Das, 2023年10月26日<br />
<br />
微软前首席执行官和董事长比尔·盖茨认为，像 ChatGPT 这样的生成式 AI 功能已经达到顶峰，目前的重点将是对现有技术进行进一步的精炼，而不太可能在像 GPT-5 这样的大语言模型上增添新的重大功能。<br />
<br />
过去一年中，生成式 AI 成为新闻头条的常客，众多公司在这一领域投入了巨资。这一趋势的关键时刻是在 2022 年 11 月 OpenAI 推出了 ChatGPT。<br />
<br />
OpenAI 的 GPT 技术为各个行业的 AI 发展打下了坚实基础。尽管公众对 GPT 和生成式 AI 抱有极大热情，但微软创始人比尔·盖茨却表达了一定的保留意见，暗示这种技术可能已经到达了一个发展的高原期。<br />
<br />
比尔·盖茨认为 ChatGPT 功能已达到顶峰<br />
在接受德国商业报纸 Handelsblatt 采访时，这位 67 岁的科技巨擘分享了他对生成式 AI 发展趋势的担忧。他坦言，有充分的理由认为目前的 GPT 技术已经达到一个顶点。不过，盖茨也表示，他的这种判断可能并非绝对正确。<br />
他对 GPT-5 的发展前景持有与 OpenAI 不同的看法，认为这一技术的发展可能有限，与 OpenAI 对未来的乐观预期相反。<br />
<br />
盖茨认为，从 GPT-2 到 GPT-4 的飞跃进步是“难以置信的”。他还预测，在未来两到五年间，AI 软件的精准度将会大幅度提升，同时成本会降低。<br />
<br />
他相信，这将为开发新颖且可靠的应用程序铺平道路。然而，盖茨预计，在最初阶段，特别是在 GPT-4 的发展上，可能会遇到技术瓶颈，GPT-5 也可能难以突破这一限制。<br />
<br />
AI 将朝着更可靠的方向发展，而非增加更多功能<br />
尽管如此，Gates 对 AI 短期内的发展前景仍持乐观态度。他预见，持续的研究会让 AI 变得更加可靠且易于理解。他特别强调，发展中国家将显著受益于 AI，例如通过智能手机获取健康咨询。<br />
<br />
谈及 AI 的成本和可靠性，Gates 提到 Nvidia 的某些 AI 芯片价格高达每个约 30,000 美元，具有强大的计算能力和能源消耗。他指出，虽然训练大语言模型成本高昂，但实际使用成本已随时间降低。<br />
Gates 还相信，AI 有潜力彻底改变医疗行业，尤其是在加速药物和疫苗研发方面，尽管对其可靠性仍存疑虑。<br />
<br />
关于人工通用智能（AGI），未来充满不确定性<br />
此外，Gates 探讨了 AI 的“黑盒”问题及其加密信息的机制，强调了许多个人和组织在解开这一谜团方面的努力。<br />
<br />
在人工通用智能（AGI）这一议题上，Gates 认为 AGI 的到来尚无定论，这可能是人类历史上的重大转折。<br />
<br />
最后，Gates 分析了 AI 在应对气候变化方面的重要角色。他强调气候模型不断进步，并大力支持那些能在高温环境中生长的新作物品种。<br />
Gates 透露，他投资了近百家公司，致力于利用 AI 技术改善电网，展现了他面对全球挑战的决心。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8tMDBndlc0QUFuQ3F4LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729277775205335321#m</id>
            <title>R to @dotey: **LLM Scaling Laws**

好的，现在我要转换话题，我们将讨论语言模型，它们是如何改进的，以及这些改进将带我们走向何方。首先要理解的关于大语言模型的重要概念是“规模化法则”。事实证明，这些大语言模型在预测下一个词的准确性方面的表现是一个非常平滑、规律性强，并且只有两个变量的预测函数。一个变量是 N，即网络中的参数数量；另一个变量是 D，即你用来训练的文本量。只要有了这两个数据，我们就能非常准确地预测你在下一词预测任务上能达到的准确度。令人惊奇的是，这些趋势看起来并没有出现停滞或达到极限的迹象。这意味着，如果你在更多文本上训练更大规模的模型，我们可以非常自信地预期下一词预测的表现将会提升。

因此，在算法上取得进步并非必要条件。算法进步当然是很好的加分项，但我们能够在不增加成本的情况下获得更强大的模型，因为我们只需要更强大的计算机。我们有理由相信这是可行的，并且我们可以在更长时间内训练一个更大的模型。我们非常有信心我们将得到更好的结果。当然，在实际操作中，我们并不是真的那么关心预测下一个词的准确度。但是，从经验上看，这种准确度与我们真正关心的许多评估指标是相关的。例如，你可以对这些大语言模型进行很多不同的测试。你会看到，如果你训练一个更大的模型更长的时间，例如，在 GPT 系列中从 3.5 提升到 4，所有这些测试的准确性都会提高。所以，当我们训练更大规模的模型和更多的数据时，我们自然而然地期待有性能的提升。这正是当前计算领域的一场淘金热的根本驱动力，每个人都在努力获取更强大的 GPU 集群，收集更多的数据，因为人们有很大的信心，通过这样做，可以获得更优秀的模型。算法的进步就像是额外的奖励，许多机构对此投入巨大。但从根本上说，扩大规模提供了一条通往成功的确定途径。

**Tool Use (Browser, Calculator, Interpreter, DALL-E)**

接下来，我想通过一些具体的例子来讲解这些语言模型的能力，以及它们是如何随着时间发展的。不是泛泛而谈，我会用一个具体的例子，逐步分析来说明。所以我打开 ChatGPT，给出了以下的查询。我说，收集关于 Scale AI 及其融资轮次的信息，包括发生的时间、日期、金额和估值，并将这些信息整理成一张表。根据我们收集的大量数据，ChatGPT 在微调学习阶段就已经理解，在这种类型的查询中，ChatGPT 不会仅仅依靠自己作为一个大语言模型来直接回答问题。相反，它学会了在需要时使用一些外部工具来帮助完成任务。在这个例子中，一个很合适的工具就是浏览器。

假设你和我遇到同样的问题，你可能会选择上网搜索，对吧？ChatGPT 做的正是这样的事情。它能够发出特定的词汇，我们可以通过这些词汇观察它是如何尝试进行搜索的。在这种情况下，我们可以拿着这个查询去 Bing 搜索，查看搜索结果。就像你我在浏览搜索结果一样，我们可以把搜索到的文本反馈给语言模型，让它基于这些文本生成回答。这个过程非常类似于我们使用浏览器进行研究的方式。然后，它会将这些信息整理成以下形式，并以此方式进行回应。

所以，它收集了信息，我们得到了一张表格，上面列出了 A、B、C、D 和 E 轮融资的具体日期、筹资金额和对应的估值。接着，它还提供了引用链接，你可以通过这些链接去核实这些信息的准确性。在底部，它表示，实际上我要道歉，我没有找到 A 轮和 B 轮的估值数据，只找到了筹集的金额。所以你可以看到表格中有一项标记为不可用。好的，我们现在可以继续这种互动。我提出，让我们尝试基于 C 轮、D 轮和 E 轮中看到的比例，来推测或估算 A 轮和 B 轮的估值。可以看到，在 C、D 和 E 轮中，筹资金额和估值之间存在一定的比例关系。那么，我们该如何解决这个问题呢？当我们尝试推算“不可用”的数据时，并不是仅凭脑海中的计算就能解决。你不可能只是试图在你的脑海中解决它。这样做相当复杂，因为我们在数学方面并不特别擅长。同样，ChatGPT 也不是通过单纯“思考”就能擅长数学运算。实际上，ChatGPT 知道它应该使用计算器来处理这类任务。因此，它会发出特定的指令，告诉程序它需要使用计算器来计算这个数值。它实际上做的是，首先计算所有的比率，然后根据这些比率来推算 A 轮和 B 轮的估值，可能是 7000 万或者 2.83 亿。所以，现在我们的目标是得到所有不同融资轮次的估值数据。接下来，我们将这些数据制作成一个二维图表：横轴表示日期，纵轴显示 Scale AI 的估值。为了更精确地展示，我们会在纵轴上使用对数刻度，并且加上网格线，使图表看起来既专业又美观。ChatGPT 实际上可以使用工具，这次是编写代码，使用 Python 语言中的 Matplotlib 库来绘制这些数据。它会进入一个 Python 解释器，输入所有数据，然后生成图表。这就是图。它清晰地展示了底部的数据，完全按照我们用自然语言提出的要求制作完成。

与 ChatGPT 交流就像与人交谈一样自然。现在我们看着这张图表，想要进行更多的分析。比如，我们现在想在这个图表上加一条线性趋势线，并尝试推算 Scale AI 到 2025 年底的估值。再比如，在图表上标出今天的日期，并基于趋势线来估算今天和 2025 年底的估值。ChatGPT 完成了所有编码工作，虽然这些代码没有展示出来，但它提供了详细的分析结果。在图表的底部，我们可以看到日期和估值的推算结果。根据这个趋势线的拟合结果，今天 Scale AI 的估值大约是 1500 亿美元。而到了 2025 年底，这个公司预计会成长为价值高达 2 万亿美元的科技巨头。所以，祝贺 Scale AI 团队。但这只是 ChatGPT 擅长的分析类型之一。我想通过这个例子展示的核心点是，语言模型在工具使用方面的能力以及它们的发展趋势。它们的功能不再局限于在大脑中处理信息和选择词汇。如今，它们开始利用各种工具和现有的计算基础设施，将一切紧密联系并用词汇交织在一起，如果这有意义的话。

因此，工具使用已成为这些模型日益增强能力的重要一环。它们能够编写大量代码、进行全面分析、从互联网上检索信息等等。再举一个例子。根据上述信息，试图生成一个代表 Scale AI 公司的图像。所以，基于上面的所有内容，依据大语言模型的上下文理解，它对 Scale AI 有深刻的了解。它可能还记得关于 Scale AI 的一些信息以及网络中储存的知识。然后它去使用另一个工具，在这种情况下这个工具是 DALL-E，这也是 OpenAI 开发的一种工具，可以根据自然语言描述生成图像。所以在这里 DALL-E 被用作生成图像的工具。希望这个演示能具体说明问题解决过程中大量使用工具的情况，这与人类解决很多问题的方式高度相关。我们在解决问题时不仅仅依赖思考，而是广泛运用各种工具，比如电脑就非常有用。对于大语言模型也是如此，利用工具正逐渐成为大语言模型发展的一个重要方向。</title>
            <link>https://nitter.cz/dotey/status/1729277775205335321#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729277775205335321#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 23:15:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>**LLM Scaling Laws**<br />
<br />
好的，现在我要转换话题，我们将讨论语言模型，它们是如何改进的，以及这些改进将带我们走向何方。首先要理解的关于大语言模型的重要概念是“规模化法则”。事实证明，这些大语言模型在预测下一个词的准确性方面的表现是一个非常平滑、规律性强，并且只有两个变量的预测函数。一个变量是 N，即网络中的参数数量；另一个变量是 D，即你用来训练的文本量。只要有了这两个数据，我们就能非常准确地预测你在下一词预测任务上能达到的准确度。令人惊奇的是，这些趋势看起来并没有出现停滞或达到极限的迹象。这意味着，如果你在更多文本上训练更大规模的模型，我们可以非常自信地预期下一词预测的表现将会提升。<br />
<br />
因此，在算法上取得进步并非必要条件。算法进步当然是很好的加分项，但我们能够在不增加成本的情况下获得更强大的模型，因为我们只需要更强大的计算机。我们有理由相信这是可行的，并且我们可以在更长时间内训练一个更大的模型。我们非常有信心我们将得到更好的结果。当然，在实际操作中，我们并不是真的那么关心预测下一个词的准确度。但是，从经验上看，这种准确度与我们真正关心的许多评估指标是相关的。例如，你可以对这些大语言模型进行很多不同的测试。你会看到，如果你训练一个更大的模型更长的时间，例如，在 GPT 系列中从 3.5 提升到 4，所有这些测试的准确性都会提高。所以，当我们训练更大规模的模型和更多的数据时，我们自然而然地期待有性能的提升。这正是当前计算领域的一场淘金热的根本驱动力，每个人都在努力获取更强大的 GPU 集群，收集更多的数据，因为人们有很大的信心，通过这样做，可以获得更优秀的模型。算法的进步就像是额外的奖励，许多机构对此投入巨大。但从根本上说，扩大规模提供了一条通往成功的确定途径。<br />
<br />
**Tool Use (Browser, Calculator, Interpreter, DALL-E)**<br />
<br />
接下来，我想通过一些具体的例子来讲解这些语言模型的能力，以及它们是如何随着时间发展的。不是泛泛而谈，我会用一个具体的例子，逐步分析来说明。所以我打开 ChatGPT，给出了以下的查询。我说，收集关于 Scale AI 及其融资轮次的信息，包括发生的时间、日期、金额和估值，并将这些信息整理成一张表。根据我们收集的大量数据，ChatGPT 在微调学习阶段就已经理解，在这种类型的查询中，ChatGPT 不会仅仅依靠自己作为一个大语言模型来直接回答问题。相反，它学会了在需要时使用一些外部工具来帮助完成任务。在这个例子中，一个很合适的工具就是浏览器。<br />
<br />
假设你和我遇到同样的问题，你可能会选择上网搜索，对吧？ChatGPT 做的正是这样的事情。它能够发出特定的词汇，我们可以通过这些词汇观察它是如何尝试进行搜索的。在这种情况下，我们可以拿着这个查询去 Bing 搜索，查看搜索结果。就像你我在浏览搜索结果一样，我们可以把搜索到的文本反馈给语言模型，让它基于这些文本生成回答。这个过程非常类似于我们使用浏览器进行研究的方式。然后，它会将这些信息整理成以下形式，并以此方式进行回应。<br />
<br />
所以，它收集了信息，我们得到了一张表格，上面列出了 A、B、C、D 和 E 轮融资的具体日期、筹资金额和对应的估值。接着，它还提供了引用链接，你可以通过这些链接去核实这些信息的准确性。在底部，它表示，实际上我要道歉，我没有找到 A 轮和 B 轮的估值数据，只找到了筹集的金额。所以你可以看到表格中有一项标记为不可用。好的，我们现在可以继续这种互动。我提出，让我们尝试基于 C 轮、D 轮和 E 轮中看到的比例，来推测或估算 A 轮和 B 轮的估值。可以看到，在 C、D 和 E 轮中，筹资金额和估值之间存在一定的比例关系。那么，我们该如何解决这个问题呢？当我们尝试推算“不可用”的数据时，并不是仅凭脑海中的计算就能解决。你不可能只是试图在你的脑海中解决它。这样做相当复杂，因为我们在数学方面并不特别擅长。同样，ChatGPT 也不是通过单纯“思考”就能擅长数学运算。实际上，ChatGPT 知道它应该使用计算器来处理这类任务。因此，它会发出特定的指令，告诉程序它需要使用计算器来计算这个数值。它实际上做的是，首先计算所有的比率，然后根据这些比率来推算 A 轮和 B 轮的估值，可能是 7000 万或者 2.83 亿。所以，现在我们的目标是得到所有不同融资轮次的估值数据。接下来，我们将这些数据制作成一个二维图表：横轴表示日期，纵轴显示 Scale AI 的估值。为了更精确地展示，我们会在纵轴上使用对数刻度，并且加上网格线，使图表看起来既专业又美观。ChatGPT 实际上可以使用工具，这次是编写代码，使用 Python 语言中的 Matplotlib 库来绘制这些数据。它会进入一个 Python 解释器，输入所有数据，然后生成图表。这就是图。它清晰地展示了底部的数据，完全按照我们用自然语言提出的要求制作完成。<br />
<br />
与 ChatGPT 交流就像与人交谈一样自然。现在我们看着这张图表，想要进行更多的分析。比如，我们现在想在这个图表上加一条线性趋势线，并尝试推算 Scale AI 到 2025 年底的估值。再比如，在图表上标出今天的日期，并基于趋势线来估算今天和 2025 年底的估值。ChatGPT 完成了所有编码工作，虽然这些代码没有展示出来，但它提供了详细的分析结果。在图表的底部，我们可以看到日期和估值的推算结果。根据这个趋势线的拟合结果，今天 Scale AI 的估值大约是 1500 亿美元。而到了 2025 年底，这个公司预计会成长为价值高达 2 万亿美元的科技巨头。所以，祝贺 Scale AI 团队。但这只是 ChatGPT 擅长的分析类型之一。我想通过这个例子展示的核心点是，语言模型在工具使用方面的能力以及它们的发展趋势。它们的功能不再局限于在大脑中处理信息和选择词汇。如今，它们开始利用各种工具和现有的计算基础设施，将一切紧密联系并用词汇交织在一起，如果这有意义的话。<br />
<br />
因此，工具使用已成为这些模型日益增强能力的重要一环。它们能够编写大量代码、进行全面分析、从互联网上检索信息等等。再举一个例子。根据上述信息，试图生成一个代表 Scale AI 公司的图像。所以，基于上面的所有内容，依据大语言模型的上下文理解，它对 Scale AI 有深刻的了解。它可能还记得关于 Scale AI 的一些信息以及网络中储存的知识。然后它去使用另一个工具，在这种情况下这个工具是 DALL-E，这也是 OpenAI 开发的一种工具，可以根据自然语言描述生成图像。所以在这里 DALL-E 被用作生成图像的工具。希望这个演示能具体说明问题解决过程中大量使用工具的情况，这与人类解决很多问题的方式高度相关。我们在解决问题时不仅仅依赖思考，而是广泛运用各种工具，比如电脑就非常有用。对于大语言模型也是如此，利用工具正逐渐成为大语言模型发展的一个重要方向。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjkyNzY3NjA4NTA1NjMwNzIvcHUvaW1nL1VRX0VWbDd5bVJoTWN1SnQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/goocarlos/status/1729210688017760324#m</id>
            <title>RT by @dotey: 这款名为 Coze 的产品是否看起来眼熟？由某裁员中的大厂“高 Level”团队创作。该产品的完成度其实做得不错，毕竟是重金投入。但社区中屡有朋友向我发来询问，因为实在和 Dify 太像了，连我们选择不恰当的那些英文术语都全盘搬走。简单的说下吧：

我们一直在做的就是持续创新、并坚持向社区交付高品质的产品。论资金密度我们是无法跟这个体量的大厂去拼的，但我们可以保持开放、中立、透明。Dify 为开发者的做的事可以归结为三项：
1. Democratization of AI，围绕 LLM 的 RAG 和 Fine-tune 等是复杂技术，有待简化；
2. Cross-Functional Collaboration in AI，我们相信 非技术人员需要参与到 AI 应用的定义过程之中；
3. Data-Driven Feedback，AI 应用的效果提升建立在来自生产数据的反馈，为全社会加速这个流程的运转。

如何应对？
1. 据我已知，Dify 有超过万计的私有部署实例，已经有许多开发者基于我们赚到了钱、融到了资以及少走了弯路（虽然我们没怎么收钱）。社区是我们最重要的力量和资产；
2. 我们会在近期开放产品的 Roadmap，并发布详细的贡献指南；
3. 大厂仿品有价值的特性，我们会做得更好，然后“贡献”给开源社区；
4. 与全生态合作伙伴加深合作，我们和国内所有的模型公司都有非常棒的沟通；
5. 将未来我们的收入分出来一部分给贡献者。

创业公司如何对待大厂？
在热门赛道，国内几乎所有的大厂都会以战投、交流、比赛等方式与创业者接触，然后把情报带回去注资研发。今年某些厂商狂搞黑客松就是现象之一，目的并不是简单的拉高声量。

大厂应该如何对待创业项目？
1. 出来好好交个朋友，不寒碜；
2. 向借鉴的开源项目公开致敬，即使没有直接使用源码；
3. 向开源社区做贡献。

就说这些，如果你想以任何形式参与 Dify 的产品，发邮件至 luyu@dify.ai，Do it for you.</title>
            <link>https://nitter.cz/goocarlos/status/1729210688017760324#m</link>
            <guid isPermaLink="false">https://nitter.cz/goocarlos/status/1729210688017760324#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 18:48:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这款名为 Coze 的产品是否看起来眼熟？由某裁员中的大厂“高 Level”团队创作。该产品的完成度其实做得不错，毕竟是重金投入。但社区中屡有朋友向我发来询问，因为实在和 Dify 太像了，连我们选择不恰当的那些英文术语都全盘搬走。简单的说下吧：<br />
<br />
我们一直在做的就是持续创新、并坚持向社区交付高品质的产品。论资金密度我们是无法跟这个体量的大厂去拼的，但我们可以保持开放、中立、透明。Dify 为开发者的做的事可以归结为三项：<br />
1. Democratization of AI，围绕 LLM 的 RAG 和 Fine-tune 等是复杂技术，有待简化；<br />
2. Cross-Functional Collaboration in AI，我们相信 非技术人员需要参与到 AI 应用的定义过程之中；<br />
3. Data-Driven Feedback，AI 应用的效果提升建立在来自生产数据的反馈，为全社会加速这个流程的运转。<br />
<br />
如何应对？<br />
1. 据我已知，Dify 有超过万计的私有部署实例，已经有许多开发者基于我们赚到了钱、融到了资以及少走了弯路（虽然我们没怎么收钱）。社区是我们最重要的力量和资产；<br />
2. 我们会在近期开放产品的 Roadmap，并发布详细的贡献指南；<br />
3. 大厂仿品有价值的特性，我们会做得更好，然后“贡献”给开源社区；<br />
4. 与全生态合作伙伴加深合作，我们和国内所有的模型公司都有非常棒的沟通；<br />
5. 将未来我们的收入分出来一部分给贡献者。<br />
<br />
创业公司如何对待大厂？<br />
在热门赛道，国内几乎所有的大厂都会以战投、交流、比赛等方式与创业者接触，然后把情报带回去注资研发。今年某些厂商狂搞黑客松就是现象之一，目的并不是简单的拉高声量。<br />
<br />
大厂应该如何对待创业项目？<br />
1. 出来好好交个朋友，不寒碜；<br />
2. 向借鉴的开源项目公开致敬，即使没有直接使用源码；<br />
3. 向开源社区做贡献。<br />
<br />
就说这些，如果你想以任何形式参与 Dify 的产品，发邮件至 luyu@dify.ai，Do it for you.</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85ZE16c2EwQUVBZ3ZoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85ZFB0MGJFQUFlS3RaLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85ZFB1QmFZQUFnSXFDLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85amM4SmJ3QUFVQUduLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1729231976672977016#m</id>
            <title>推荐：《Reading List For Andrej Karpathy’s Intro to Large Language Models Video》 
Andrej Karpathy 大语言模型视频入门的精选阅读清单

作者针对Andrej Karpathy前几天的视频教程，把相关的参考文章、论文都分门别类整理出来了。

原文：https://blog.oxen.ai/reading-list-for-andrej-karpathys-intro-to-large-language-models-video/
译文：https://baoyu.io/translations/llm/reading-list-for-andrej-karpathys-intro-to-large-language-models-video</title>
            <link>https://nitter.cz/dotey/status/1729231976672977016#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1729231976672977016#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 20:13:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐：《Reading List For Andrej Karpathy’s Intro to Large Language Models Video》 <br />
Andrej Karpathy 大语言模型视频入门的精选阅读清单<br />
<br />
作者针对Andrej Karpathy前几天的视频教程，把相关的参考文章、论文都分门别类整理出来了。<br />
<br />
原文：<a href="https://blog.oxen.ai/reading-list-for-andrej-karpathys-intro-to-large-language-models-video/">blog.oxen.ai/reading-list-fo…</a><br />
译文：<a href="https://baoyu.io/translations/llm/reading-list-for-andrej-karpathys-intro-to-large-language-models-video">baoyu.io/translations/llm/re…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85MnlJTVdVQUV1NXVFLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85M0hkblhjQUFfUE1wLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85M09xU1hvQUFWX1NoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl85M1RzeVhZQUFaYjNrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>