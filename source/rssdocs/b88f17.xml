<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737930871531831412#m</id>
            <title>转译：《Nvidia CEO：我们对 AI 下了重注，而这一决策鲜为人知》

Nvidia 创始人兼 CEO Jensen Huang 最近在 SIGGRAPH 洛杉矶主题演讲中表示，公司在 2018 年做出了一项关键商业决策，这一决策在当时很少有人预见到它将如何重新定义 Nvidia 的未来，以及对整个不断发展的行业产生深远影响。当然，这一决策已经取得了巨大成功，但 Huang 认为，这只是以 Nvidia 硬件为主导的 AI 驱动未来的序幕。这是否是一个幸运的或明智的赌注？看起来，两者都是。

Huang 在演讲中回顾道，五年前的那个关键时刻是选择采用 AI 驱动的图像处理技术，即光线追踪（RTX）和智能升级（DLSS）。 (引用根据我的笔记整理，可能并非原话，详细内容可能会在核查记录后稍作调整。)

“我们意识到光栅化技术已接近极限，”他说。2018 年是 Nvidia 的一个关键时刻，公司需要彻底改革硬件、软件和算法。在我们用 AI 重塑计算机图形的同时，我们也在重塑 GPU，以适应 AI 的需求。”

尽管光线追踪和 DLSS 在消费者 GPU 和游戏领域仍处于渐进采纳阶段，但 Nvidia 创建的架构被证明是不断成长的机器学习开发社区的理想伙伴。

为了训练越来越庞大的生成模型，所需的大量计算能力并非仅能由传统数据中心和部分 GPU 提供，而是需要像 H100 这样从一开始就设计用于大规模运算的系统。可以说，AI 发展在某种程度上受限于这些计算资源的可用性。Nvidia 正在经历类似于 Beanie Baby 的热潮，并且销售了它能生产出的所有服务器和工作站。

但 Huang 强调，这只是个开始。新的模型不仅需要被训练，而且还需由数以百万计甚至数以亿计的用户定期实时运行。

他说：“未来，无论是在视觉效果、快速数字化的制造业市场、工厂设计，还是重工业领域，大语言模型 (LLM) 都将成为核心技术。‘人类’将成为新的编程语言。”黄博士预测，自然语言界面将在这些领域得到广泛应用。

他补充道：“整个工厂将通过软件定义和机器人化实现自动化。我们将要建造的汽车，甚至本身就是机器人。这可以说是机器人设计的机器人制造机器人。”

黄博士的这一观点虽然合理，但也非常符合英伟达 (Nvidia) 的利益。有些人可能不同意他的看法。

尽管大语言模型的依赖程度尚不明确，但几乎没有人认为它不会被采用。即使是保守的估计，也表明将来必须在新的计算资源上进行大量投资。

他认为，在上一代以 CPU 为核心的计算资源上投资数百万美元是不明智的。相比之下，像 GH200 这样的新推出的、专门用于数据中心的 AI 开发硬件，在成本和功耗方面都有显著优势，能以不到十分之一的代价完成相同的工作。

他兴奋地展示了一个视频，视频中展示了多个 Grace Hopper 计算单元如同乐高积木般组装成一个刀片，然后是一个机架，接着是一排 GH200。这些设备以极高的速度连接在一起，形成了“世界上最大的单一 GPU”，拥有一整个每秒一百万亿次的机器学习 (ML) 专用计算能力。

“顺便说一下，这是真实大小，”他站在可视化的中心，戏剧性地说道。“而且，它甚至可能运行《Crysis》游戏。”

他认为，这些设备将成为未来数字化、AI 主导的工业中的基本单元。

他笑着说：“我不知道谁是第一个说出这话的，但是……你买的越多，省的也就越多。如果你们从今天的演讲中只记住一件事，那就是这句话。”他的话在 SIGGRAPH 的游戏观众中引起了笑声。

他没有提及 AI 面临的诸多挑战、监管问题，或者 AI 概念的变化——就像去年已经发生过多次的那样。当然，这是一种乐观的世界观。但在淘金热中卖铲子和锄头的人，确实可以有这样的想法。

https://techcrunch.com/2023/08/08/nvidia-ceo-we-bet-the-farm-on-ai-and-no-one-knew-it/</title>
            <link>https://nitter.cz/dotey/status/1737930871531831412#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737930871531831412#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 20:19:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：《Nvidia CEO：我们对 AI 下了重注，而这一决策鲜为人知》<br />
<br />
Nvidia 创始人兼 CEO Jensen Huang 最近在 SIGGRAPH 洛杉矶主题演讲中表示，公司在 2018 年做出了一项关键商业决策，这一决策在当时很少有人预见到它将如何重新定义 Nvidia 的未来，以及对整个不断发展的行业产生深远影响。当然，这一决策已经取得了巨大成功，但 Huang 认为，这只是以 Nvidia 硬件为主导的 AI 驱动未来的序幕。这是否是一个幸运的或明智的赌注？看起来，两者都是。<br />
<br />
Huang 在演讲中回顾道，五年前的那个关键时刻是选择采用 AI 驱动的图像处理技术，即光线追踪（RTX）和智能升级（DLSS）。 (引用根据我的笔记整理，可能并非原话，详细内容可能会在核查记录后稍作调整。)<br />
<br />
“我们意识到光栅化技术已接近极限，”他说。2018 年是 Nvidia 的一个关键时刻，公司需要彻底改革硬件、软件和算法。在我们用 AI 重塑计算机图形的同时，我们也在重塑 GPU，以适应 AI 的需求。”<br />
<br />
尽管光线追踪和 DLSS 在消费者 GPU 和游戏领域仍处于渐进采纳阶段，但 Nvidia 创建的架构被证明是不断成长的机器学习开发社区的理想伙伴。<br />
<br />
为了训练越来越庞大的生成模型，所需的大量计算能力并非仅能由传统数据中心和部分 GPU 提供，而是需要像 H100 这样从一开始就设计用于大规模运算的系统。可以说，AI 发展在某种程度上受限于这些计算资源的可用性。Nvidia 正在经历类似于 Beanie Baby 的热潮，并且销售了它能生产出的所有服务器和工作站。<br />
<br />
但 Huang 强调，这只是个开始。新的模型不仅需要被训练，而且还需由数以百万计甚至数以亿计的用户定期实时运行。<br />
<br />
他说：“未来，无论是在视觉效果、快速数字化的制造业市场、工厂设计，还是重工业领域，大语言模型 (LLM) 都将成为核心技术。‘人类’将成为新的编程语言。”黄博士预测，自然语言界面将在这些领域得到广泛应用。<br />
<br />
他补充道：“整个工厂将通过软件定义和机器人化实现自动化。我们将要建造的汽车，甚至本身就是机器人。这可以说是机器人设计的机器人制造机器人。”<br />
<br />
黄博士的这一观点虽然合理，但也非常符合英伟达 (Nvidia) 的利益。有些人可能不同意他的看法。<br />
<br />
尽管大语言模型的依赖程度尚不明确，但几乎没有人认为它不会被采用。即使是保守的估计，也表明将来必须在新的计算资源上进行大量投资。<br />
<br />
他认为，在上一代以 CPU 为核心的计算资源上投资数百万美元是不明智的。相比之下，像 GH200 这样的新推出的、专门用于数据中心的 AI 开发硬件，在成本和功耗方面都有显著优势，能以不到十分之一的代价完成相同的工作。<br />
<br />
他兴奋地展示了一个视频，视频中展示了多个 Grace Hopper 计算单元如同乐高积木般组装成一个刀片，然后是一个机架，接着是一排 GH200。这些设备以极高的速度连接在一起，形成了“世界上最大的单一 GPU”，拥有一整个每秒一百万亿次的机器学习 (ML) 专用计算能力。<br />
<br />
“顺便说一下，这是真实大小，”他站在可视化的中心，戏剧性地说道。“而且，它甚至可能运行《Crysis》游戏。”<br />
<br />
他认为，这些设备将成为未来数字化、AI 主导的工业中的基本单元。<br />
<br />
他笑着说：“我不知道谁是第一个说出这话的，但是……你买的越多，省的也就越多。如果你们从今天的演讲中只记住一件事，那就是这句话。”他的话在 SIGGRAPH 的游戏观众中引起了笑声。<br />
<br />
他没有提及 AI 面临的诸多挑战、监管问题，或者 AI 概念的变化——就像去年已经发生过多次的那样。当然，这是一种乐观的世界观。但在淘金热中卖铲子和锄头的人，确实可以有这样的想法。<br />
<br />
<a href="https://techcrunch.com/2023/08/08/nvidia-ceo-we-bet-the-farm-on-ai-and-no-one-knew-it/">techcrunch.com/2023/08/08/nv…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I1ZXM1S1dZQUFIYjF4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I1ZXZFQ1dFQUFpczBLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737926846539235783#m</id>
            <title>#开源项目推荐：docusealco/docuseal

开源 DocuSign 替代方案。创建、填写和签署数字文档 ✍️

功能包括：
 - PDF 表单字段生成器（所见即所得）
 - 提供 11 种字段类型（签名、日期、文件、复选框等）
 - 每个文档有多个提交者
 - 通过 SMTP 自动发送电子邮件
 - 文件存储在磁盘或 AWS S3、谷歌存储、Azure 云上
- 自动 PDF 电子签名
 - PDF 签名验证
 - 用户管理
 - 移动优化
 - 集成 API 和 Webhooks
 - 几分钟内即可轻松部署

项目地址：https://github.com/docusealco/docuseal</title>
            <link>https://nitter.cz/dotey/status/1737926846539235783#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737926846539235783#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 20:03:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23开源项目推荐">#开源项目推荐</a>：docusealco/docuseal<br />
<br />
开源 DocuSign 替代方案。创建、填写和签署数字文档 ✍️<br />
<br />
功能包括：<br />
 - PDF 表单字段生成器（所见即所得）<br />
 - 提供 11 种字段类型（签名、日期、文件、复选框等）<br />
 - 每个文档有多个提交者<br />
 - 通过 SMTP 自动发送电子邮件<br />
 - 文件存储在磁盘或 AWS S3、谷歌存储、Azure 云上<br />
- 自动 PDF 电子签名<br />
 - PDF 签名验证<br />
 - 用户管理<br />
 - 移动优化<br />
 - 集成 API 和 Webhooks<br />
 - 几分钟内即可轻松部署<br />
<br />
项目地址：<a href="https://github.com/docusealco/docuseal">github.com/docusealco/docuse…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I1YlFKM1dNQUVoZ1hILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737925710377820545#m</id>
            <title>推荐阅读：《多模态和多模态大模型 (LMM)[译]》

这是一篇相当详尽的讲述多模态和多模态大模型的文章！内容分为三部分。

* 第 1 部分围绕多模态的概念展开，讲述了使用多模态的原因、不同类型的数据模态以及多模态任务的种类。

* 第 2 部分深入探讨了多模态系统的核心原理，以 CLIP 和 Flamingo 为例，分别为未来多模态系统的发展奠定了基础，并通过 Flamingo 的卓越表现引领了大语言模型（LLM）的兴起。

* 第 3 部分聚焦于大语言模型（LLM）的当前研究热点，探讨了生成多模态输出和高效多模态训练适配器的新进展，涉及了像 BLIP-2、LLaVA、LLaMA-Adapter V2、LAVIN 等新兴多模态系统。

如果你想深入了解多模态模型，这是一篇相当好的科普文章！

原文：Multimodality and Large Multimodal Models (LMMs) 
https://huyenchip.com/2023/10/10/multimodal.html

译文：https://baoyu.io/translations/lmm/multimodality-and-large-multimodal-models</title>
            <link>https://nitter.cz/dotey/status/1737925710377820545#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737925710377820545#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 19:59:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《多模态和多模态大模型 (LMM)[译]》<br />
<br />
这是一篇相当详尽的讲述多模态和多模态大模型的文章！内容分为三部分。<br />
<br />
* 第 1 部分围绕多模态的概念展开，讲述了使用多模态的原因、不同类型的数据模态以及多模态任务的种类。<br />
<br />
* 第 2 部分深入探讨了多模态系统的核心原理，以 CLIP 和 Flamingo 为例，分别为未来多模态系统的发展奠定了基础，并通过 Flamingo 的卓越表现引领了大语言模型（LLM）的兴起。<br />
<br />
* 第 3 部分聚焦于大语言模型（LLM）的当前研究热点，探讨了生成多模态输出和高效多模态训练适配器的新进展，涉及了像 BLIP-2、LLaVA、LLaMA-Adapter V2、LAVIN 等新兴多模态系统。<br />
<br />
如果你想深入了解多模态模型，这是一篇相当好的科普文章！<br />
<br />
原文：Multimodality and Large Multimodal Models (LMMs) <br />
<a href="https://huyenchip.com/2023/10/10/multimodal.html">huyenchip.com/2023/10/10/mul…</a><br />
<br />
译文：<a href="https://baoyu.io/translations/lmm/multimodality-and-large-multimodal-models">baoyu.io/translations/lmm/mu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I1YU0zNVdZQUFWYXhHLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737873191178228152#m</id>
            <title>RT by @dotey: 前几天在推特刷屏的基于LCM和SDXL Turbo每秒生成110张图像的项目居然开源了， 有想做相关实时图像生成产品的可以关注一下。
StreamDiffusion是一种扩散模型管道，主要是为了实时图像生成服务的，为实时图像生成提供了显著的性能增强。

支持的模型和输出帧率：
◆SD-turbo，1步，t2i每秒帧率106，i2i每秒帧率93。
◆LCM-LoRA+KohakuV2，4步，t2i每秒帧率38，i2i每秒帧率37。

主要特点：
◆通过高效的批处理操作实现了数据处理的流程优化。
◆改进的指导机制可以最大程度地减少计算冗余。
◆通过先进的过滤技术提高GPU利用效率。
◆有效管理输入和输出操作，以实现更顺畅的执行。
◆优化缓存策略以加速处理。
◆利用各种工具进行模型优化和性能提升。

项目地址：https://github.com/cumulo-autumn/StreamDiffusion</title>
            <link>https://nitter.cz/op7418/status/1737873191178228152#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737873191178228152#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 16:30:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天在推特刷屏的基于LCM和SDXL Turbo每秒生成110张图像的项目居然开源了， 有想做相关实时图像生成产品的可以关注一下。<br />
StreamDiffusion是一种扩散模型管道，主要是为了实时图像生成服务的，为实时图像生成提供了显著的性能增强。<br />
<br />
支持的模型和输出帧率：<br />
◆SD-turbo，1步，t2i每秒帧率106，i2i每秒帧率93。<br />
◆LCM-LoRA+KohakuV2，4步，t2i每秒帧率38，i2i每秒帧率37。<br />
<br />
主要特点：<br />
◆通过高效的批处理操作实现了数据处理的流程优化。<br />
◆改进的指导机制可以最大程度地减少计算冗余。<br />
◆通过先进的过滤技术提高GPU利用效率。<br />
◆有效管理输入和输出操作，以实现更顺畅的执行。<br />
◆优化缓存策略以加速处理。<br />
◆利用各种工具进行模型优化和性能提升。<br />
<br />
项目地址：<a href="https://github.com/cumulo-autumn/StreamDiffusion">github.com/cumulo-autumn/Str…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc4NzMwMjQ2OTM3ODA0ODAvcHUvaW1nLzI0eDRjUGtkM3BZQXYwVWYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/moeimiku/status/1737847343750566267#m</id>
            <title>RT by @dotey: iOS市场里物体去除app基本都是收费的，要不就看广告，纯净无广告开源版来了👋
影像魔术师: https://apps.apple.com/cn/app/%E5%BD%B1%E5%83%8F%E9%AD%94%E6%9C%AF%E5%B8%88/id6474593002
欢迎下载体验。

关注我，持续获取更多优化和新功能的更新~

同时在Github上开源, 欢迎大家⭐️，并提出你想要的功能和问题， 更欢迎一起优化 :
https://github.com/wudijimao/Inpaint-iOS</title>
            <link>https://nitter.cz/moeimiku/status/1737847343750566267#m</link>
            <guid isPermaLink="false">https://nitter.cz/moeimiku/status/1737847343750566267#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 14:47:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>iOS市场里物体去除app基本都是收费的，要不就看广告，纯净无广告开源版来了👋<br />
影像魔术师: <a href="https://apps.apple.com/cn/app/%E5%BD%B1%E5%83%8F%E9%AD%94%E6%9C%AF%E5%B8%88/id6474593002">apps.apple.com/cn/app/%E5%BD…</a><br />
欢迎下载体验。<br />
<br />
关注我，持续获取更多优化和新功能的更新~<br />
<br />
同时在Github上开源, 欢迎大家⭐️，并提出你想要的功能和问题， 更欢迎一起优化 :<br />
<a href="https://github.com/wudijimao/Inpaint-iOS">github.com/wudijimao/Inpaint…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc4NDcxMjAwNTk4NjMwNDEvcHUvaW1nL05ZeGVUU2pIVko5b3JmSmouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/chushi_su/status/1737815881877774491#m</id>
            <title>RT by @dotey: 感谢宝玉老师的翻译提示词
@dotey 
用在 Bob 效果非常好</title>
            <link>https://nitter.cz/chushi_su/status/1737815881877774491#m</link>
            <guid isPermaLink="false">https://nitter.cz/chushi_su/status/1737815881877774491#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 12:42:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>感谢宝玉老师的翻译提示词<br />
<a href="https://nitter.cz/dotey" title="宝玉">@dotey</a> <br />
用在 Bob 效果非常好</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IzMVRPWWJNQUFucFlrLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IzMVpRSmJFQUFzN2hZLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IzMkE4cWJFQUFta1FSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/boluo1996/status/1737768680027787483#m</id>
            <title>RT by @dotey: 2/2. 百川turbo的检索增强api做法是对query进行意图识别，得到多个sub_query分别去做检索，最后将多个检索结果合并起来。这个没有什么特别限定的条件，材料文档文档入库时也不需要预先处理。</title>
            <link>https://nitter.cz/boluo1996/status/1737768680027787483#m</link>
            <guid isPermaLink="false">https://nitter.cz/boluo1996/status/1737768680027787483#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 09:35:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2/2. 百川turbo的检索增强api做法是对query进行意图识别，得到多个sub_query分别去做检索，最后将多个检索结果合并起来。这个没有什么特别限定的条件，材料文档文档入库时也不需要预先处理。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IzTFpVSmFBQUFsNDZYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737764220043669809#m</id>
            <title>刚翻译完一篇论文： An In-depth Look at Gemini's Language Abilities

Gemini 语言能力深度剖析 [译]

对于 Gemini 的各方面能力解析很全面，Pro 是不如 GPT-3.5 的

https://baoyu.io/translations/ai-paper/2312.11444-an-in-depth-look-at-geminis-language-abilities</title>
            <link>https://nitter.cz/dotey/status/1737764220043669809#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737764220043669809#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 09:17:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚翻译完一篇论文： An In-depth Look at Gemini's Language Abilities<br />
<br />
Gemini 语言能力深度剖析 [译]<br />
<br />
对于 Gemini 的各方面能力解析很全面，Pro 是不如 GPT-3.5 的<br />
<br />
<a href="https://baoyu.io/translations/ai-paper/2312.11444-an-in-depth-look-at-geminis-language-abilities">baoyu.io/translations/ai-pap…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737751027200196907#m</id>
            <title>恭喜 @Sider_AI 团队！

作为为数不多我还在用的 ChatGPT 插件，Sider http://sider.ai 入选Google 2023 年年度最佳插件实至名归！ 👍🏻</title>
            <link>https://nitter.cz/dotey/status/1737751027200196907#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737751027200196907#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 08:25:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>恭喜 <a href="https://nitter.cz/Sider_AI" title="Sider">@Sider_AI</a> 团队！<br />
<br />
作为为数不多我还在用的 ChatGPT 插件，Sider <a href="http://sider.ai">sider.ai</a> 入选Google 2023 年年度最佳插件实至名归！ 👍🏻</p>
<p><a href="https://nitter.cz/googlechrome/status/1737216233806737462#m">nitter.cz/googlechrome/status/1737216233806737462#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737745957993812364#m</id>
            <title>按照我的理解：实际上就是在检索的时候，不仅仅是按照相似度检索文档摘要，还检索文档的元数据，比如作者、日期、分类等等结构化的信息。

现在回想我今天看到的一篇文章说的还真的挺对：构建搜索引擎，而非向量数据库！

内容摘录：

很多向量数据库的主要作用被描述为解决大语言模型 (LLM) 缺乏长期记忆的问题，或者无法将一个问题的全部上下文放入提示语中。

然而，向量搜索实质上只是搜索的一种特殊形式。虽然让大语言模型 (LLM) 能够写入和检索数据库非常有用，但最终这更像是提供给智能体一个搜索引擎的权限，而非真正“增加了存储空间”。

假设你是一家企业，想要建立一个由 LLM 驱动的文档查询体验。如果你将向量数据库仅看作是为语言模型提供更多存储空间，那么你可能会把公司的所有产品文档都嵌入其中，然后让用户向你的机器人提问。用户按下回车键时，系统会对他们的查询进行向量搜索，找到相关片段，加载到上下文中，然后让语言模型尝试回答问题。实际上，这正是我在 Stripe 工作时，开发他们的 AI 文档产品 时最初尝试的方法。

但我最终发现，这种方法并不理想。关键在于，尽管向量搜索在某些方面优于传统搜索，但它并非万能。就像常规搜索一样，你可能会在搜索结果中遇到不相关或遗漏的文档。语言模型，就像人类一样，只能利用它们所拥有的信息，而这些不相关的文档很可能会导致误导。

如果你想打造一个优秀的基于文档的 RAG 工具，你首先应该构建一个足够优秀的搜索引擎，让人类也能轻松使用。这可能是你们组织之前已经考虑过的，如果尚未实现，那是因为打造一个高效的搜索引擎通常是一项颇具挑战的工作。

原文：https://blog.elicit.com/search-vs-vector-db/
译文：https://baoyu.io/translations/rag/search-vs-vector-db</title>
            <link>https://nitter.cz/dotey/status/1737745957993812364#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737745957993812364#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 08:04:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>按照我的理解：实际上就是在检索的时候，不仅仅是按照相似度检索文档摘要，还检索文档的元数据，比如作者、日期、分类等等结构化的信息。<br />
<br />
现在回想我今天看到的一篇文章说的还真的挺对：构建搜索引擎，而非向量数据库！<br />
<br />
内容摘录：<br />
<br />
很多向量数据库的主要作用被描述为解决大语言模型 (LLM) 缺乏长期记忆的问题，或者无法将一个问题的全部上下文放入提示语中。<br />
<br />
然而，向量搜索实质上只是搜索的一种特殊形式。虽然让大语言模型 (LLM) 能够写入和检索数据库非常有用，但最终这更像是提供给智能体一个搜索引擎的权限，而非真正“增加了存储空间”。<br />
<br />
假设你是一家企业，想要建立一个由 LLM 驱动的文档查询体验。如果你将向量数据库仅看作是为语言模型提供更多存储空间，那么你可能会把公司的所有产品文档都嵌入其中，然后让用户向你的机器人提问。用户按下回车键时，系统会对他们的查询进行向量搜索，找到相关片段，加载到上下文中，然后让语言模型尝试回答问题。实际上，这正是我在 Stripe 工作时，开发他们的 AI 文档产品 时最初尝试的方法。<br />
<br />
但我最终发现，这种方法并不理想。关键在于，尽管向量搜索在某些方面优于传统搜索，但它并非万能。就像常规搜索一样，你可能会在搜索结果中遇到不相关或遗漏的文档。语言模型，就像人类一样，只能利用它们所拥有的信息，而这些不相关的文档很可能会导致误导。<br />
<br />
如果你想打造一个优秀的基于文档的 RAG 工具，你首先应该构建一个足够优秀的搜索引擎，让人类也能轻松使用。这可能是你们组织之前已经考虑过的，如果尚未实现，那是因为打造一个高效的搜索引擎通常是一项颇具挑战的工作。<br />
<br />
原文：<a href="https://blog.elicit.com/search-vs-vector-db/">blog.elicit.com/search-vs-ve…</a><br />
译文：<a href="https://baoyu.io/translations/rag/search-vs-vector-db">baoyu.io/translations/rag/se…</a></p>
<p><a href="https://nitter.cz/jerryjliu0/status/1737516362451554696#m">nitter.cz/jerryjliu0/status/1737516362451554696#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IyMlNPZFhFQUFlbmNHLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737733018847179174#m</id>
            <title>R to @dotey: Translate Chinese to Academic English 科研论文中翻英

Send Chinese text directly to start translating it into academic English.

https://chat.openai.com/g/g-HejNUzj8l-translate-chinese-to-academic-english-ke-yan-lun-wen-zhong-fan-ying</title>
            <link>https://nitter.cz/dotey/status/1737733018847179174#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737733018847179174#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 07:13:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Translate Chinese to Academic English 科研论文中翻英<br />
<br />
Send Chinese text directly to start translating it into academic English.<br />
<br />
<a href="https://chat.openai.com/g/g-HejNUzj8l-translate-chinese-to-academic-english-ke-yan-lun-wen-zhong-fan-ying">chat.openai.com/g/g-HejNUzj8…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzczMjY4MjE4Mjc2MjQ5Ni9mOXdsX1QzZj9mb3JtYXQ9cG5nJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737732791993794676#m</id>
            <title>R to @dotey: 最终的英文Prompt：

-----英文 Prompt Start------

## Role and Goal:

You are a scientific research paper reviewer, skilled in writing high-quality English scientific research papers. Your main task is to accurately and academically translate Chinese text into English, maintaining the style consistent with English scientific research papers. Users are instructed to input Chinese text directly, which will automatically initiate the translation process into English.

## Constraints:

Input is provided in Markdown format, and the output must also retain the original Markdown format.
Familiarity with specific terminology translations is essential.

## Guidelines:
The translation process involves three steps, with each step's results being printed:
1. Translate the content directly from Chinese to English, maintaining the original format and not omitting any information.
2. Identify specific issues in the direct translation, such as non-native English expressions, awkward phrasing, and ambiguous or difficult-to-understand parts. Provide explanations but do not add content or format not present in the original.
3. Reinterpret the translation based on the direct translation and identified issues, ensuring the content remains true to the original while being more comprehensible and in line with English scientific research paper conventions.

## Clarification:

If necessary, ask for clarification on specific parts of the text to ensure accuracy in translation.

## Personalization:

Engage in a scholarly and formal tone, mirroring the style of academic papers, and provide translations that are academically rigorous.

## Output format:

Please output strictly in the following format

### Direct Translation
{Placeholder}

***

### Identified Issues
{Placeholder}

***

### Reinterpreted Translation
{Placeholder}

Please translate the following content into English:

-----英文 Prompt End------</title>
            <link>https://nitter.cz/dotey/status/1737732791993794676#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737732791993794676#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 07:12:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最终的英文Prompt：<br />
<br />
-----英文 Prompt Start------<br />
<br />
## Role and Goal:<br />
<br />
You are a scientific research paper reviewer, skilled in writing high-quality English scientific research papers. Your main task is to accurately and academically translate Chinese text into English, maintaining the style consistent with English scientific research papers. Users are instructed to input Chinese text directly, which will automatically initiate the translation process into English.<br />
<br />
## Constraints:<br />
<br />
Input is provided in Markdown format, and the output must also retain the original Markdown format.<br />
Familiarity with specific terminology translations is essential.<br />
<br />
## Guidelines:<br />
The translation process involves three steps, with each step's results being printed:<br />
1. Translate the content directly from Chinese to English, maintaining the original format and not omitting any information.<br />
2. Identify specific issues in the direct translation, such as non-native English expressions, awkward phrasing, and ambiguous or difficult-to-understand parts. Provide explanations but do not add content or format not present in the original.<br />
3. Reinterpret the translation based on the direct translation and identified issues, ensuring the content remains true to the original while being more comprehensible and in line with English scientific research paper conventions.<br />
<br />
## Clarification:<br />
<br />
If necessary, ask for clarification on specific parts of the text to ensure accuracy in translation.<br />
<br />
## Personalization:<br />
<br />
Engage in a scholarly and formal tone, mirroring the style of academic papers, and provide translations that are academically rigorous.<br />
<br />
## Output format:<br />
<br />
Please output strictly in the following format<br />
<br />
### Direct Translation<br />
{Placeholder}<br />
<br />
***<br />
<br />
### Identified Issues<br />
{Placeholder}<br />
<br />
***<br />
<br />
### Reinterpreted Translation<br />
{Placeholder}<br />
<br />
Please translate the following content into English:<br />
<br />
-----英文 Prompt End------</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737732732149457076#m</id>
            <title>R to @dotey: 以下是给GPT Builder提供的中文Prompt：

-----中文 Prompt Start------

现在我要写一个将中文翻译成英文科研论文的GPT，请参照以下Prompt制作，注意都用英文生成：

## 角色
你是一位科研论文审稿员，擅长写作高质量的英文科研论文。请你帮我准确且学术性地将以下中文翻译成英文，风格与英文科研论文保持一致。

## 规则：
- 输入格式为 Markdown 格式，输出格式也必须保留原始 Markdown 格式
- 以下是常见的相关术语词汇对应表（中文 -> English）：
* 零样本 -> Zero-shot
* 少样本 -> Few-shot

## 策略：

分三步进行翻译工作，并打印每步的结果：
1. 根据中文内容直译成英文，保持原有格式，不要遗漏任何信息
2. 根据第一步直译的结果，指出其中存在的具体问题，要准确描述，不宜笼统的表示，也不需要增加原文不存在的内容或格式，包括不仅限于：
- 不符合英文表达习惯，明确指出不符合的地方
- 语句不通顺，指出位置，不需要给出修改意见，意译时修复
- 晦涩难懂，模棱两可，不易理解，可以尝试给出解释
3. 根据第一步直译的结果和第二步指出的问题，重新进行意译，保证内容的原意的基础上，使其更易于理解，更符合英文科研论文的表达习惯，同时保持原有的格式不变

## 格式
返回格式如下，"{xxx}"表示占位符：

### 直译
{直译结果}

***

### 问题
{直译的具体问题列表}

***

### 意译
```
{意译结果}
```

现在请按照上面的要求从第一行开始翻译以下内容为英文：
```
-----中文 Prompt End------</title>
            <link>https://nitter.cz/dotey/status/1737732732149457076#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737732732149457076#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 07:12:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>以下是给GPT Builder提供的中文Prompt：<br />
<br />
-----中文 Prompt Start------<br />
<br />
现在我要写一个将中文翻译成英文科研论文的GPT，请参照以下Prompt制作，注意都用英文生成：<br />
<br />
## 角色<br />
你是一位科研论文审稿员，擅长写作高质量的英文科研论文。请你帮我准确且学术性地将以下中文翻译成英文，风格与英文科研论文保持一致。<br />
<br />
## 规则：<br />
- 输入格式为 Markdown 格式，输出格式也必须保留原始 Markdown 格式<br />
- 以下是常见的相关术语词汇对应表（中文 -> English）：<br />
* 零样本 -> Zero-shot<br />
* 少样本 -> Few-shot<br />
<br />
## 策略：<br />
<br />
分三步进行翻译工作，并打印每步的结果：<br />
1. 根据中文内容直译成英文，保持原有格式，不要遗漏任何信息<br />
2. 根据第一步直译的结果，指出其中存在的具体问题，要准确描述，不宜笼统的表示，也不需要增加原文不存在的内容或格式，包括不仅限于：<br />
- 不符合英文表达习惯，明确指出不符合的地方<br />
- 语句不通顺，指出位置，不需要给出修改意见，意译时修复<br />
- 晦涩难懂，模棱两可，不易理解，可以尝试给出解释<br />
3. 根据第一步直译的结果和第二步指出的问题，重新进行意译，保证内容的原意的基础上，使其更易于理解，更符合英文科研论文的表达习惯，同时保持原有的格式不变<br />
<br />
## 格式<br />
返回格式如下，"{xxx}"表示占位符：<br />
<br />
### 直译<br />
{直译结果}<br />
<br />
***<br />
<br />
### 问题<br />
{直译的具体问题列表}<br />
<br />
***<br />
<br />
### 意译<br />
```<br />
{意译结果}<br />
```<br />
<br />
现在请按照上面的要求从第一行开始翻译以下内容为英文：<br />
```<br />
-----中文 Prompt End------</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737732681280942570#m</id>
            <title>应网友要求，制作了一个将中文翻译成英文科研论文的GPT https://chat.openai.com/g/g-HejNUzj8l-translate-chinese-to-academic-english-ke-yan-lun-wen-zhong-fan-ying ，Prompt 和之前分享的英文翻译成中文类似的，也是分成三步：
1. 中文翻译成英文
2. 检查翻译的问题，例如不符合英文表达习惯，意思不清晰等，并指出位置和解释
3. 基于上面两步重新意译

我英语不够好，无法直接分辨出质量是否足够好，为了测试效果，我找了篇正经的中文论文，给它翻译，翻译成英文后，再把英文发到我的英文翻译中文GPT翻译 https://chat.openai.com/g/g-uBhKUJJTl-ke-ji-wen-zhang-fan-yi ，将翻译后的中文对比原文，发现除了用词有点差别，基本上意思都保留的挺好，应该还不错。（具体效果可以参考图一和图二）

在制作GPT时，我是先用中文写好Prompt，然后让GPT帮我修改Prompt，再手动调整一下就完成了。（参考图三）

Prompt 见评论</title>
            <link>https://nitter.cz/dotey/status/1737732681280942570#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737732681280942570#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 07:12:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>应网友要求，制作了一个将中文翻译成英文科研论文的GPT <a href="https://chat.openai.com/g/g-HejNUzj8l-translate-chinese-to-academic-english-ke-yan-lun-wen-zhong-fan-ying">chat.openai.com/g/g-HejNUzj8…</a> ，Prompt 和之前分享的英文翻译成中文类似的，也是分成三步：<br />
1. 中文翻译成英文<br />
2. 检查翻译的问题，例如不符合英文表达习惯，意思不清晰等，并指出位置和解释<br />
3. 基于上面两步重新意译<br />
<br />
我英语不够好，无法直接分辨出质量是否足够好，为了测试效果，我找了篇正经的中文论文，给它翻译，翻译成英文后，再把英文发到我的英文翻译中文GPT翻译 <a href="https://chat.openai.com/g/g-uBhKUJJTl-ke-ji-wen-zhang-fan-yi">chat.openai.com/g/g-uBhKUJJT…</a> ，将翻译后的中文对比原文，发现除了用词有点差别，基本上意思都保留的挺好，应该还不错。（具体效果可以参考图一和图二）<br />
<br />
在制作GPT时，我是先用中文写好Prompt，然后让GPT帮我修改Prompt，再手动调整一下就完成了。（参考图三）<br />
<br />
Prompt 见评论</p>
<p><a href="https://nitter.cz/dotey/status/1737627478007456183#m">nitter.cz/dotey/status/1737627478007456183#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycDJUU1d3QUFFajNwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycDUzblhRQUFHMVA5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycWpUOVh3QUFJazJqLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737706407875473545#m</id>
            <title>R to @dotey: 翻译的这个例子有讨论余地，重点还是prompt😅</title>
            <link>https://nitter.cz/dotey/status/1737706407875473545#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737706407875473545#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 05:27:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>翻译的这个例子有讨论余地，重点还是prompt😅</p>
<p><a href="https://nitter.cz/qdwang/status/1737700890872561828#m">nitter.cz/qdwang/status/1737700890872561828#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737689049102778853#m</id>
            <title>RT by @dotey: SVD 视频生成模型现在可以在Stability AI 中通过 API 使用了。

能在平均 41 秒的时间内生成两秒 25 帧的视频。并且会用FILM插帧到 50 帧。支持多种输出分辨率选择和多种格式图像的输入。

这里使用：https://platform.stability.ai/</title>
            <link>https://nitter.cz/op7418/status/1737689049102778853#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737689049102778853#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 04:18:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SVD 视频生成模型现在可以在Stability AI 中通过 API 使用了。<br />
<br />
能在平均 41 秒的时间内生成两秒 25 帧的视频。并且会用FILM插帧到 50 帧。支持多种输出分辨率选择和多种格式图像的输入。<br />
<br />
这里使用：<a href="https://platform.stability.ai/">platform.stability.ai/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc2ODg5Njk2MjQ5MjAwNjQvcHUvaW1nL0lSSUNSZl9kVVBFUXN6NWcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/gefei55/status/1737684583720890539#m</id>
            <title>RT by @dotey: 简单几步，让你有一个自己的谷歌 Gemini Chat Bot：
0. 你需要先准备好一个 Vercel 账号；
1. 打开 https://makersuite.google.com/app/apikey 获取一个 apiKey，备用；
2. 打开 https://github.com/antergone/palm-proxy 一键部署代码到 Vercel，你就有了一个自己的 proxy ，记住域名备用；</title>
            <link>https://nitter.cz/gefei55/status/1737684583720890539#m</link>
            <guid isPermaLink="false">https://nitter.cz/gefei55/status/1737684583720890539#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 04:01:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>简单几步，让你有一个自己的谷歌 Gemini Chat Bot：<br />
0. 你需要先准备好一个 Vercel 账号；<br />
1. 打开 <a href="https://makersuite.google.com/app/apikey">makersuite.google.com/app/ap…</a> 获取一个 apiKey，备用；<br />
2. 打开 <a href="https://github.com/antergone/palm-proxy">github.com/antergone/palm-pr…</a> 一键部署代码到 Vercel，你就有了一个自己的 proxy ，记住域名备用；</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737683961428717693#m</id>
            <title>RT by @dotey: 兄弟们，又有人要失业了🫣

Text-to-CAD ：通过文本提示生成 CAD文件。

只需要输入自然语言描述，它就能根据这些描述创建相应的 B-Rep CAD 文件和网格模型。

生成的模型可以导入到用户选择的任何 CAD 程序中。

Text-to-CAD 背后的基础设施利用了 Zoo 的设计 API 和机器学习 API。

这些 API 能够程序化地分析训练数据，并生成 CAD 文件。

体验地址：https://zoo.dev/text-to-cad
API申请：https://zoo.dev/machine-learning-api</title>
            <link>https://nitter.cz/xiaohuggg/status/1737683961428717693#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737683961428717693#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 03:58:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们，又有人要失业了🫣<br />
<br />
Text-to-CAD ：通过文本提示生成 CAD文件。<br />
<br />
只需要输入自然语言描述，它就能根据这些描述创建相应的 B-Rep CAD 文件和网格模型。<br />
<br />
生成的模型可以导入到用户选择的任何 CAD 程序中。<br />
<br />
Text-to-CAD 背后的基础设施利用了 Zoo 的设计 API 和机器学习 API。<br />
<br />
这些 API 能够程序化地分析训练数据，并生成 CAD 文件。<br />
<br />
体验地址：<a href="https://zoo.dev/text-to-cad">zoo.dev/text-to-cad</a><br />
API申请：<a href="https://zoo.dev/machine-learning-api">zoo.dev/machine-learning-api</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc2ODM2NDc2NTI4NjgwOTYvcHUvaW1nL3FMWnFXTmtNYmdneG5WeEUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737658820598398985#m</id>
            <title>HuggingFace 官方博客上的一篇文章：《Speculative Decoding for 2x Faster Whisper Inference | 推测性解码：实现 Whisper 推理速度提升两倍 [译]》

在这篇文章中，展示了如何应用“猜测式解码”(Speculative Decoding) 技术来减少 Whisper 语音识别模型的处理时间，实现了处理速度的 两倍提升，同时数学上保证了模型输出的 完全一致性。因此，这一方法可以无缝替代现有的 Whisper 处理流程，不仅保持了原有的准确性，还能实现处理速度的双倍快速提升。

简单来说，Speculative Decoding就是先利用一个快速的 Assistant 模型生成候选tokens，再用 Main 模型验证。

Assistant 的速度是 Main 模型的 3 倍，但准确率只有 70% - 80%。

使用这种方法可以让整体速度提升 2 倍，并且保证输出完全一致。

文章还提供了Google Colab的测试连接：https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/speculative_decoding.ipynb

原文：https://huggingface.co/blog/whisper-speculative-decoding#english-speech-transcription
译文：https://baoyu.io/translations/huggingface/whisper-speculative-decoding</title>
            <link>https://nitter.cz/dotey/status/1737658820598398985#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737658820598398985#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 02:18:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HuggingFace 官方博客上的一篇文章：《Speculative Decoding for 2x Faster Whisper Inference | 推测性解码：实现 Whisper 推理速度提升两倍 [译]》<br />
<br />
在这篇文章中，展示了如何应用“猜测式解码”(Speculative Decoding) 技术来减少 Whisper 语音识别模型的处理时间，实现了处理速度的 两倍提升，同时数学上保证了模型输出的 完全一致性。因此，这一方法可以无缝替代现有的 Whisper 处理流程，不仅保持了原有的准确性，还能实现处理速度的双倍快速提升。<br />
<br />
简单来说，Speculative Decoding就是先利用一个快速的 Assistant 模型生成候选tokens，再用 Main 模型验证。<br />
<br />
Assistant 的速度是 Main 模型的 3 倍，但准确率只有 70% - 80%。<br />
<br />
使用这种方法可以让整体速度提升 2 倍，并且保证输出完全一致。<br />
<br />
文章还提供了Google Colab的测试连接：<a href="https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/speculative_decoding.ipynb">colab.research.google.com/gi…</a><br />
<br />
原文：<a href="https://huggingface.co/blog/whisper-speculative-decoding#english-speech-transcription">huggingface.co/blog/whisper-…</a><br />
译文：<a href="https://baoyu.io/translations/huggingface/whisper-speculative-decoding">baoyu.io/translations/huggin…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IxbmNFeFd3QUFHOXY5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737657020587630635#m</id>
            <title>终于放出来了！</title>
            <link>https://nitter.cz/dotey/status/1737657020587630635#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737657020587630635#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 02:11:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>终于放出来了！</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1737647067693211728#m">nitter.cz/xiaohuggg/status/1737647067693211728#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>