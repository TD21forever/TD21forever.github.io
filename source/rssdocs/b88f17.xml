<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734962114513797468#m</id>
            <title>RT by @dotey: 谷歌Deepmind宣布了他们最先进的图像生成模型Imagen 2。他们通过参考图片和文本生成新图片和局部编辑的效果比较强大。

主要有下面几个特点：

改进的图像描述理解：为了帮助创建更高质量和更准确的图像，更好地符合用户的提示，Imagen 2的训练数据集中添加了更多描述，帮助Imagen 2学习不同的标题风格，并更好地理解广泛的用户提示。

更加真实的图像生成：Imagen 2的数据集和模型进步在许多领域取得了改进，这些领域通常是文本到图像工具所困扰的，包括渲染逼真的手部和人脸，以及保持图像不受干扰的视觉伪影。

Fluid style conditioning：Imagen 2的扩散技术提供了高度的灵活性，使得更容易控制和调整图像的风格。通过提供参考风格图像并结合文本提示，可以训练Imagen 2生成遵循相同风格的新图像。

高级修复和修饰：图像2还支持图像编辑功能，如“修补”和“扩展”。通过提供参考图像和图像蒙版，用户可以使用一种称为修补的技术直接在原始图像中生成新内容，或者使用扩展技术将原始图像延伸到其边界之外

现在可以通过Google Cloud Vertex AI中的Imagen API供开发人员和云客户使用。

来源：https://deepmind.google/technologies/imagen-2/</title>
            <link>https://nitter.cz/op7418/status/1734962114513797468#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734962114513797468#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:42:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌Deepmind宣布了他们最先进的图像生成模型Imagen 2。他们通过参考图片和文本生成新图片和局部编辑的效果比较强大。<br />
<br />
主要有下面几个特点：<br />
<br />
改进的图像描述理解：为了帮助创建更高质量和更准确的图像，更好地符合用户的提示，Imagen 2的训练数据集中添加了更多描述，帮助Imagen 2学习不同的标题风格，并更好地理解广泛的用户提示。<br />
<br />
更加真实的图像生成：Imagen 2的数据集和模型进步在许多领域取得了改进，这些领域通常是文本到图像工具所困扰的，包括渲染逼真的手部和人脸，以及保持图像不受干扰的视觉伪影。<br />
<br />
Fluid style conditioning：Imagen 2的扩散技术提供了高度的灵活性，使得更容易控制和调整图像的风格。通过提供参考风格图像并结合文本提示，可以训练Imagen 2生成遵循相同风格的新图像。<br />
<br />
高级修复和修饰：图像2还支持图像编辑功能，如“修补”和“扩展”。通过提供参考图像和图像蒙版，用户可以使用一种称为修补的技术直接在原始图像中生成新内容，或者使用扩展技术将原始图像延伸到其边界之外<br />
<br />
现在可以通过Google Cloud Vertex AI中的Imagen API供开发人员和云客户使用。<br />
<br />
来源：<a href="https://deepmind.google/technologies/imagen-2/">deepmind.google/technologies…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NjIwNzI3MDUwMTk5MDQvcHUvaW1nL2YxSVJjck5FRU8yWmZhek0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734966078076494075#m</id>
            <title>RT by @dotey: Mixtral 8x7B通过苹果前几天发布的 MLX 已经可以在M3 Max（128G）上运行。</title>
            <link>https://nitter.cz/op7418/status/1734966078076494075#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734966078076494075#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:58:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mixtral 8x7B通过苹果前几天发布的 MLX 已经可以在M3 Max（128G）上运行。</p>
<p><a href="https://nitter.cz/ivanfioravanti/status/1734699499526705314#m">nitter.cz/ivanfioravanti/status/1734699499526705314#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/foxshuo/status/1734941409172680924#m</id>
            <title>RT by @dotey: TikTok的电商业务在印尼遭到强制关停之后用了60天绝境翻盘的过程真是跌宕起伏，从前因后果来看也堪称是中国出海公司应对地缘政治冲突的教科书级操作，非常值得记上一笔。

首先是印尼这个国家，如果不做外贸行业的话，可能不太会有人会感兴趣，但事实上，单论人口规模而言，印尼排在全球第四，仅次于印中美，这个狭长的群岛国家拥有2.8亿的稠密人口。

比人口更关键的，是印尼的社会节奏很慢，国民对于闲暇的重视远胜劳动，被视为全球最懒散的国家之一，由此产生的一个副作用，则是印尼人对社交媒体的依赖度全球居首，人均消费时长甚至高于中国和美国这样的互联网大国。

所以「得印尼者得东南亚」，一直以来都是互联网公司推进国际化时的一个共识，TikTok在印尼的月活跃用户高达1.25亿，仅次于美国，也相当于40%的印尼人口都在用TikTok。

而TikTok Shop（TikTok的电商业务，以直播带货为主）去年拿下了印尼5%的市场份额，而这5%的市场份额换算成GMV，又差不多占到了TikTok东南亚全部电商的60%，你们可以感受一下这两个比例，有多说明印尼市场的重要性。

然后，TikTok在今年10月被迫下线了印尼的全部电商业务，这在当时引起的震动和危机，也可以说是TikTok史上前所未有的，连美国都没有真的成功关掉TikTok的任何业务。

然后才有了接下来精彩纷呈的60天。（1/n）</title>
            <link>https://nitter.cz/foxshuo/status/1734941409172680924#m</link>
            <guid isPermaLink="false">https://nitter.cz/foxshuo/status/1734941409172680924#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 14:20:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>TikTok的电商业务在印尼遭到强制关停之后用了60天绝境翻盘的过程真是跌宕起伏，从前因后果来看也堪称是中国出海公司应对地缘政治冲突的教科书级操作，非常值得记上一笔。<br />
<br />
首先是印尼这个国家，如果不做外贸行业的话，可能不太会有人会感兴趣，但事实上，单论人口规模而言，印尼排在全球第四，仅次于印中美，这个狭长的群岛国家拥有2.8亿的稠密人口。<br />
<br />
比人口更关键的，是印尼的社会节奏很慢，国民对于闲暇的重视远胜劳动，被视为全球最懒散的国家之一，由此产生的一个副作用，则是印尼人对社交媒体的依赖度全球居首，人均消费时长甚至高于中国和美国这样的互联网大国。<br />
<br />
所以「得印尼者得东南亚」，一直以来都是互联网公司推进国际化时的一个共识，TikTok在印尼的月活跃用户高达1.25亿，仅次于美国，也相当于40%的印尼人口都在用TikTok。<br />
<br />
而TikTok Shop（TikTok的电商业务，以直播带货为主）去年拿下了印尼5%的市场份额，而这5%的市场份额换算成GMV，又差不多占到了TikTok东南亚全部电商的60%，你们可以感受一下这两个比例，有多说明印尼市场的重要性。<br />
<br />
然后，TikTok在今年10月被迫下线了印尼的全部电商业务，这在当时引起的震动和危机，也可以说是TikTok史上前所未有的，连美国都没有真的成功关掉TikTok的任何业务。<br />
<br />
然后才有了接下来精彩纷呈的60天。（1/n）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734990364598043058#m</id>
            <title>这次的课程是关于 RLHF 的，人类反馈强化学习</title>
            <link>https://nitter.cz/dotey/status/1734990364598043058#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734990364598043058#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 17:35:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这次的课程是关于 RLHF 的，人类反馈强化学习</p>
<p><a href="https://nitter.cz/AndrewYNg/status/1734960437534347444#m">nitter.cz/AndrewYNg/status/1734960437534347444#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1734873428174458986#m</id>
            <title>RT by @dotey: CopilotKit：一个开源项目，可以在任何基于React的Web应用中构建内嵌的AI聊天机器人和AI驱动的文本区域。

主要特点：

- 内嵌AI聊天机器人：机器人可以理解应用的当前状态，并在应用内执行操作。

- AI驱动的文本区域：提供AI生成和编辑文本的功能，可以替换任何标准的文本输入区域

- 自动上下文感知：根据上下文自动完成建议

- 全面的定制化：允许完全定制提示工程和UI设计

- 支持多种模型：可以与不同的前端和后端SDK结合，支持多种大语言模型。

使用场景：

文本生成和编辑：在应用中提供AI辅助的文本生成和编辑功能，例如自动完成和内容生成。

交互式聊天机器人：创建可以与应用前端和后端以及第三方服务交互的聊天机器人。

总之：CopilotKit 是一个为React开发者提供强大AI集成能力的工具集，通过简化AI功能的集成过程，使得创建交互式和智能的Web应用变得更加容易。

GitHub：https://github.com/CopilotKit/CopilotKit</title>
            <link>https://nitter.cz/xiaohuggg/status/1734873428174458986#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1734873428174458986#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 09:50:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>CopilotKit：一个开源项目，可以在任何基于React的Web应用中构建内嵌的AI聊天机器人和AI驱动的文本区域。<br />
<br />
主要特点：<br />
<br />
- 内嵌AI聊天机器人：机器人可以理解应用的当前状态，并在应用内执行操作。<br />
<br />
- AI驱动的文本区域：提供AI生成和编辑文本的功能，可以替换任何标准的<textarea></textarea>文本输入区域<br />
<br />
- 自动上下文感知：根据上下文自动完成建议<br />
<br />
- 全面的定制化：允许完全定制提示工程和UI设计<br />
<br />
- 支持多种模型：可以与不同的前端和后端SDK结合，支持多种大语言模型。<br />
<br />
使用场景：<br />
<br />
文本生成和编辑：在应用中提供AI辅助的文本生成和编辑功能，例如自动完成和内容生成。<br />
<br />
交互式聊天机器人：创建可以与应用前端和后端以及第三方服务交互的聊天机器人。<br />
<br />
总之：CopilotKit 是一个为React开发者提供强大AI集成能力的工具集，通过简化AI功能的集成过程，使得创建交互式和智能的Web应用变得更加容易。<br />
<br />
GitHub：<a href="https://github.com/CopilotKit/CopilotKit">github.com/CopilotKit/Copilo…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ4MjAwNzk4NDQ2NzE0ODgvcHUvaW1nL3libkVkempJTlNmaWZ4R3MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734989708717891660#m</id>
            <title>当初Sam要是没回去都怀疑永远不会开放了😄</title>
            <link>https://nitter.cz/dotey/status/1734989708717891660#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734989708717891660#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 17:32:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>当初Sam要是没回去都怀疑永远不会开放了😄</p>
<p><a href="https://nitter.cz/sama/status/1734984269586457078#m">nitter.cz/sama/status/1734984269586457078#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1734958068595831011#m</id>
            <title>RT by @dotey: Google宣布Gemini Pro 版本已经向开发者和企业开放，可用于构建 AI 应用。

最重要的是目前完全免费！🆓💰

• 免费使用：目前可以在限制内免费使用，并且未来将提供具有竞争力的定价。

• 特性：支持包括函数调用、嵌入、语义检索、自定义知识基础和聊天功能。

• 语言支持：支持全球 180 多个国家和地区的 38 种语言。

开发者目前可以通过 Google AI Studio 免费访问 Gemini Pro 和 Gemini Pro Vision，适用于大多数应用程序开发需求。

Google计划在明年初推出 Gemini Ultra…

详细：https://blog.google/technology/ai/gemini-api-developers-cloud/?utm_sourc</title>
            <link>https://nitter.cz/xiaohuggg/status/1734958068595831011#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1734958068595831011#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:26:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google宣布Gemini Pro 版本已经向开发者和企业开放，可用于构建 AI 应用。<br />
<br />
最重要的是目前完全免费！🆓💰<br />
<br />
• 免费使用：目前可以在限制内免费使用，并且未来将提供具有竞争力的定价。<br />
<br />
• 特性：支持包括函数调用、嵌入、语义检索、自定义知识基础和聊天功能。<br />
<br />
• 语言支持：支持全球 180 多个国家和地区的 38 种语言。<br />
<br />
开发者目前可以通过 Google AI Studio 免费访问 Gemini Pro 和 Gemini Pro Vision，适用于大多数应用程序开发需求。<br />
<br />
Google计划在明年初推出 Gemini Ultra…<br />
<br />
详细：<a href="https://blog.google/technology/ai/gemini-api-developers-cloud/?utm_sourc">blog.google/technology/ai/ge…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzM0OTU4MDAyNTg1ODY2MjQxL2ltZy9rV21zUHM5dlh2bDVNN2ZKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734986107530473632#m</id>
            <title>R to @dotey: 确实是AI的问题，但在AI还不够强的时候，我们可以尽可能激发它的潜能</title>
            <link>https://nitter.cz/dotey/status/1734986107530473632#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734986107530473632#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 17:18:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>确实是AI的问题，但在AI还不够强的时候，我们可以尽可能激发它的潜能</p>
<p><a href="https://nitter.cz/simaziyu/status/1734875023587111281#m">nitter.cz/simaziyu/status/1734875023587111281#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/fi56622380/status/1734845740349059144#m</id>
            <title>RT by @dotey: https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/

这篇打破LLM涌现概念的论文刚刚拿了NeurIPS 2023最佳paper

确实是意义重大的一篇文章

让我们把时间线拉长时可以不用再考虑AI能力突变AGI这样的神话故事，LLM模型的能力发展更顺滑，可预测性变得更高，这可以让我们更冷静而客观的看待AI的发展速度了

评委们还是识货的</title>
            <link>https://nitter.cz/fi56622380/status/1734845740349059144#m</link>
            <guid isPermaLink="false">https://nitter.cz/fi56622380/status/1734845740349059144#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 08:00:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/">blog.neurips.cc/2023/12/11/a…</a><br />
<br />
这篇打破LLM涌现概念的论文刚刚拿了NeurIPS 2023最佳paper<br />
<br />
确实是意义重大的一篇文章<br />
<br />
让我们把时间线拉长时可以不用再考虑AI能力突变AGI这样的神话故事，LLM模型的能力发展更顺滑，可预测性变得更高，这可以让我们更冷静而客观的看待AI的发展速度了<br />
<br />
评委们还是识货的</p>
<p><a href="https://nitter.cz/fi56622380/status/1654386086746132481#m">nitter.cz/fi56622380/status/1654386086746132481#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/wshuyi/status/1734841751926640791#m</id>
            <title>RT by @dotey: 在 https://labs.perplexity.ai/ 里面调用 Mixtral 8x7B 模型，让 AI 写贪吃蛇游戏。这代码输出速度，太令人震撼了。关键是，还真能直接玩儿 😂 注：本视频没有做过任何速度调整</title>
            <link>https://nitter.cz/wshuyi/status/1734841751926640791#m</link>
            <guid isPermaLink="false">https://nitter.cz/wshuyi/status/1734841751926640791#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 07:44:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在 <a href="https://labs.perplexity.ai/">labs.perplexity.ai/</a> 里面调用 Mixtral 8x7B 模型，让 AI 写贪吃蛇游戏。这代码输出速度，太令人震撼了。关键是，还真能直接玩儿 😂 注：本视频没有做过任何速度调整</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ4NDE0NDAzODYzOTYxNjAvcHUvaW1nLzdibmN5NjJvYnN4N3VnME4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734857030140080225#m</id>
            <title>如果 AI 直译+意译后的效果还不理想该怎么办？

根据我以前分享过的翻译Prompt（参考引用的推文），先直译再意译，确实可以大幅提升翻译质量，但也不总是能得到理想的结果。

比如说我今天在翻译一篇文章《[人工智能辅助程序员的三种类型 [译]](https://baoyu.io/translations/ai/three-types-of-ai-assisted-programmers)》的时候，其中第二段原文是：

“The promised wave of apps built entirely by AI never materialized. I’m trying my best not to gloat about it.”

直译的时候翻译为：
“然而，完全由 AI 构建的应用程序浪潮并未实现。我尽力不去幸灾乐祸。”

意译的时候翻译为：
“但是，那些被承诺完全由 AI 构建的应用波澜壮阔地来临的景象，并没有成为现实。我尽量不去对此幸灾乐祸。”

意译完还是“机翻”效果很明显，其实这句话原始的英文就写的不太好，但结合上一段还是能看懂。

> 补充一下 Google 和 DeepL 的翻译结果
> - Google 翻译结果：“完全由人工智能构建的应用程序浪潮从未实现。我尽力不为此沾沾自喜。”
> - DeepL 翻译结果：“说好的完全由人工智能打造的应用程序浪潮从未实现。我尽力不去幸灾乐祸。”

如果你继续让它意译，并不会让结果提升多少，因为它多半还是基于原始的翻译修辞上改善一下罢了。

在翻译结果不佳的情况下如何改善呢？

我们直接看英文能懂意思，因为我们理解了上下文的意思，知道这句话是在表达：作为程序员，看到 AI 并没有想象中那么强，难免有点幸灾乐祸，但还要克制。

如果告诉 AI 这些上下文，这样它就能输出更好的结果。

但是太麻烦了！

不过 AI 比我们想象的强大，只要稍微“提示（Prompt）”它一下，让它先自己把这句话解释一下，然后基于解释的内容去重新翻译，就不需要去给它上下文，而它自己就可以生成更好的结果。

以下是我在会话下面追加的消息（Prompt）：

```
请先结合上下文解释这句话“The promised wave of apps built entirely by AI never materialized. I’m trying my best not to gloat about it.” 然后结合解释的内容重新意译。
```

于是 ChatGPT 结合上下文给我详细解释了这句话的意思，并且它把自己解释的内容作为上下文，重新翻译了这句话，得到了一个更好的翻译结果：

```
这句话“The promised wave of apps built entirely by AI never materialized. I’m trying my best not to gloat about it.” 的意思是，先前有预期认为将会出现一波完全由人工智能构建的应用程序，但这种预期最终并没有成为现实。作者在这里表示，虽然这个结果验证了他之前的观点，但他尽量避免因此而感到幸灾乐祸或者沾沾自喜。

结合这个解释，我可以对这句话进行重新意译：

"但是，那些承诺中完全由 AI 打造的应用程序大潮并没有真正涌现。对于这个结果，虽然在某种程度上证实了我的看法，但我尽量不去表现出幸灾乐祸的态度。"
```

简单总结一下

如果你想让大语言模型有更好的生成质量，那么就需要给模型提供更多更准确的上下文，但是这个上下文，并不一定需要完全由你自己提供，还可以让大语言模型自己生成上下文，有了充分的上下文后再生成结果，生成质量会更好。

这个技巧不仅仅可以用在翻译上，还可以用在其他地方，比如说写作：如果你上手就让 AI 给你生成内容，那么质量不一定够好，你可以让它先给你列提纲，校对后然后每个章节去填充摘要，校对后再去生成内容，这样质量就会好很多。

示例会话历史：https://chat.openai.com/share/927952b8-c1ae-4e1d-b1c5-3deb09c5816f

博文：https://baoyu.io/blog/prompt-engineering/how-to-improve-translation-quality</title>
            <link>https://nitter.cz/dotey/status/1734857030140080225#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734857030140080225#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 08:45:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果 AI 直译+意译后的效果还不理想该怎么办？<br />
<br />
根据我以前分享过的翻译Prompt（参考引用的推文），先直译再意译，确实可以大幅提升翻译质量，但也不总是能得到理想的结果。<br />
<br />
比如说我今天在翻译一篇文章《[人工智能辅助程序员的三种类型 [译]](<a href="https://baoyu.io/translations/ai/three-types-of-ai-assisted-programmers">baoyu.io/translations/ai/thr…</a>)》的时候，其中第二段原文是：<br />
<br />
“The promised wave of apps built entirely by AI never materialized. I’m trying my best not to gloat about it.”<br />
<br />
直译的时候翻译为：<br />
“然而，完全由 AI 构建的应用程序浪潮并未实现。我尽力不去幸灾乐祸。”<br />
<br />
意译的时候翻译为：<br />
“但是，那些被承诺完全由 AI 构建的应用波澜壮阔地来临的景象，并没有成为现实。我尽量不去对此幸灾乐祸。”<br />
<br />
意译完还是“机翻”效果很明显，其实这句话原始的英文就写的不太好，但结合上一段还是能看懂。<br />
<br />
> 补充一下 Google 和 DeepL 的翻译结果<br />
> - Google 翻译结果：“完全由人工智能构建的应用程序浪潮从未实现。我尽力不为此沾沾自喜。”<br />
> - DeepL 翻译结果：“说好的完全由人工智能打造的应用程序浪潮从未实现。我尽力不去幸灾乐祸。”<br />
<br />
如果你继续让它意译，并不会让结果提升多少，因为它多半还是基于原始的翻译修辞上改善一下罢了。<br />
<br />
在翻译结果不佳的情况下如何改善呢？<br />
<br />
我们直接看英文能懂意思，因为我们理解了上下文的意思，知道这句话是在表达：作为程序员，看到 AI 并没有想象中那么强，难免有点幸灾乐祸，但还要克制。<br />
<br />
如果告诉 AI 这些上下文，这样它就能输出更好的结果。<br />
<br />
但是太麻烦了！<br />
<br />
不过 AI 比我们想象的强大，只要稍微“提示（Prompt）”它一下，让它先自己把这句话解释一下，然后基于解释的内容去重新翻译，就不需要去给它上下文，而它自己就可以生成更好的结果。<br />
<br />
以下是我在会话下面追加的消息（Prompt）：<br />
<br />
```<br />
请先结合上下文解释这句话“The promised wave of apps built entirely by AI never materialized. I’m trying my best not to gloat about it.” 然后结合解释的内容重新意译。<br />
```<br />
<br />
于是 ChatGPT 结合上下文给我详细解释了这句话的意思，并且它把自己解释的内容作为上下文，重新翻译了这句话，得到了一个更好的翻译结果：<br />
<br />
```<br />
这句话“The promised wave of apps built entirely by AI never materialized. I’m trying my best not to gloat about it.” 的意思是，先前有预期认为将会出现一波完全由人工智能构建的应用程序，但这种预期最终并没有成为现实。作者在这里表示，虽然这个结果验证了他之前的观点，但他尽量避免因此而感到幸灾乐祸或者沾沾自喜。<br />
<br />
结合这个解释，我可以对这句话进行重新意译：<br />
<br />
"但是，那些承诺中完全由 AI 打造的应用程序大潮并没有真正涌现。对于这个结果，虽然在某种程度上证实了我的看法，但我尽量不去表现出幸灾乐祸的态度。"<br />
```<br />
<br />
简单总结一下<br />
<br />
如果你想让大语言模型有更好的生成质量，那么就需要给模型提供更多更准确的上下文，但是这个上下文，并不一定需要完全由你自己提供，还可以让大语言模型自己生成上下文，有了充分的上下文后再生成结果，生成质量会更好。<br />
<br />
这个技巧不仅仅可以用在翻译上，还可以用在其他地方，比如说写作：如果你上手就让 AI 给你生成内容，那么质量不一定够好，你可以让它先给你列提纲，校对后然后每个章节去填充摘要，校对后再去生成内容，这样质量就会好很多。<br />
<br />
示例会话历史：<a href="https://chat.openai.com/share/927952b8-c1ae-4e1d-b1c5-3deb09c5816f">chat.openai.com/share/927952…</a><br />
<br />
博文：<a href="https://baoyu.io/blog/prompt-engineering/how-to-improve-translation-quality">baoyu.io/blog/prompt-enginee…</a></p>
<p><a href="https://nitter.cz/dotey/status/1707478347553395105#m">nitter.cz/dotey/status/1707478347553395105#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JOdUlfV1dNQUF5akpQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734834158869123480#m</id>
            <title>RT by @dotey: 阿里期货开源，再发新项目：虚拟服装试穿。只需要一张人物照片和服装照片就可以让那个人穿上这个衣服，对服装行业是个利好。
效果确实很好，但是全是期货开源很容易被当成诈骗啊。
Reddit 有个宣传这个项目的帖子，下面全是在喷，用不到就是不存在。
还可以跟前几天发的Animate-Anyone项目结合生成跳舞视频。

简介：
Outfit Anyone通过利用双流条件扩散模型来解决这些限制，使其能够熟练处理服装变形，从而获得更逼真的结果。它通过可扩展性（调节姿势和身体形状等因素）和广泛适用性（从动漫到野外图像）来区别于其他方法。Outfit Anyone在各种场景中的表现突显了它在实际部署中的实用性和准备就绪性。

实现方法：
核心是条件扩散模型，它处理模特、服装和相关文本提示的图像，以服装图像作为控制因素。在内部，网络分为两个流，独立处理模特和服装数据。这些流在融合网络中汇聚，便于将服装细节嵌入模特的特征表示中。在此基础上，我们建立了Outfit Anyone，包括两个关键元素：用于初始试穿图像的零样本试穿网络，以及用于增强输出图像中服装和皮肤纹理的事后优化器。

项目地址：https://humanaigc.github.io/outfit-anyone/</title>
            <link>https://nitter.cz/op7418/status/1734834158869123480#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734834158869123480#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 07:14:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里期货开源，再发新项目：虚拟服装试穿。只需要一张人物照片和服装照片就可以让那个人穿上这个衣服，对服装行业是个利好。<br />
效果确实很好，但是全是期货开源很容易被当成诈骗啊。<br />
Reddit 有个宣传这个项目的帖子，下面全是在喷，用不到就是不存在。<br />
还可以跟前几天发的Animate-Anyone项目结合生成跳舞视频。<br />
<br />
简介：<br />
Outfit Anyone通过利用双流条件扩散模型来解决这些限制，使其能够熟练处理服装变形，从而获得更逼真的结果。它通过可扩展性（调节姿势和身体形状等因素）和广泛适用性（从动漫到野外图像）来区别于其他方法。Outfit Anyone在各种场景中的表现突显了它在实际部署中的实用性和准备就绪性。<br />
<br />
实现方法：<br />
核心是条件扩散模型，它处理模特、服装和相关文本提示的图像，以服装图像作为控制因素。在内部，网络分为两个流，独立处理模特和服装数据。这些流在融合网络中汇聚，便于将服装细节嵌入模特的特征表示中。在此基础上，我们建立了Outfit Anyone，包括两个关键元素：用于初始试穿图像的零样本试穿网络，以及用于增强输出图像中服装和皮肤纹理的事后优化器。<br />
<br />
项目地址：<a href="https://humanaigc.github.io/outfit-anyone/">humanaigc.github.io/outfit-a…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ4MzM2OTY4ODMzMzEwNzIvcHUvaW1nL3FsaG1TQl9ManRXRkp5V00uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/MoonAtCloud/status/1734765525266485566#m</id>
            <title>RT by @dotey: 天琴座计划 Project Lyra

一个疯狂而伟大的设想

2017年，有一颗太阳系以外的天体（Oumuamua，中文发音叫欧陌陌）闯入太阳系，等到地球上天文学家用望远镜发现它的时候，它已经在快速地离开太阳，奔向深空。

这种太阳系外偶然飞来的物体应该好好研究一下，可是这个家伙的速度特别快，它不仅超出第一宇宙速度（围着地球转不掉下来），也超出第二宇宙速度（逃离地球围着太阳转），甚至超出第三宇宙速度（逃离太阳束缚）。

有人提议发射一颗人造天体追上它去近距离研究研究，哪怕能跟上它拍个照也可以。但是，最佳机会已经错过了，哪怕火箭携带再多再强的化学燃料，甚至是核燃料，直接追，那时万万追不上的。

聪明的人想到了一个绝招，利用万有引力，多次接力加速，就能追上这颗外来者。

这个办法叫做“引力弹弓”。其中的原理就是：让一个物体快速向一颗星球靠近，在坠毁的最后一刻，开动火箭突然加速偏航，致命的下坠速度转化成有用的逃离速度。在速度最快的位置开动火箭加速，也叫Oberth机动。从远处看，就像绕星体运动的物体突然被“弹弓”弹出去一样，弹弓额外得到了力是星球的“引力”。

太阳系大大小小有很多天体，只要相信万有引力，只要相信到时候各种星体一定会出现在该在的地方，只要时间节奏编排得当，就一定能用有限的燃料做引力弹弓（Oberth机动），得到原来不敢想象的速度。

图中太阳是黄色，地球轨道是蓝色，内圈两个白色圆圈是水星和金星的轨道，粉色的圆圈是木星轨道，黄色的曲线是欧陌陌星体在“太阳系一游”的轨道。

天琴座计划的具体方案：

从地球上发射一颗星体，它的轨迹是红线，让它加速到离开地球引力，以椭圆轨道绕太阳运转，三年后再次靠近地球时，启动第一次引力弹弓。利用地球引力，奇妙的加速让它脱离原来的轨道。

现在人造星体的运动方向是两年后木星（这是太阳系里质量最大的行星，它是粉色的轨道）的位置，差不多两年后，它一定会接近木星，在撞上木星之前，它启动了第二次引力弹弓，木星巨大的引力让它加速更快，绕了半圈直接掉头向太阳飞去。

最壮观的是，一年以后，它在太阳附近又启动了第三次引力弹弓。太阳巨大的引力不仅让它拐了个大弯，几乎反向，而且让它开始真正的狂奔。你从红色的轨迹就能看出，新的速度让红线沿着黄线迅速延长，这速度几乎是那颗欧陌陌速度的两倍。

十几年之后，它终于在太阳系边缘追上了欧陌陌，拍到了想要的照片。如何送回来，就是子孙后代考虑的事情了。我们这一代，有天琴座计划就足够骄傲啦。</title>
            <link>https://nitter.cz/MoonAtCloud/status/1734765525266485566#m</link>
            <guid isPermaLink="false">https://nitter.cz/MoonAtCloud/status/1734765525266485566#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 02:41:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>天琴座计划 Project Lyra<br />
<br />
一个疯狂而伟大的设想<br />
<br />
2017年，有一颗太阳系以外的天体（Oumuamua，中文发音叫欧陌陌）闯入太阳系，等到地球上天文学家用望远镜发现它的时候，它已经在快速地离开太阳，奔向深空。<br />
<br />
这种太阳系外偶然飞来的物体应该好好研究一下，可是这个家伙的速度特别快，它不仅超出第一宇宙速度（围着地球转不掉下来），也超出第二宇宙速度（逃离地球围着太阳转），甚至超出第三宇宙速度（逃离太阳束缚）。<br />
<br />
有人提议发射一颗人造天体追上它去近距离研究研究，哪怕能跟上它拍个照也可以。但是，最佳机会已经错过了，哪怕火箭携带再多再强的化学燃料，甚至是核燃料，直接追，那时万万追不上的。<br />
<br />
聪明的人想到了一个绝招，利用万有引力，多次接力加速，就能追上这颗外来者。<br />
<br />
这个办法叫做“引力弹弓”。其中的原理就是：让一个物体快速向一颗星球靠近，在坠毁的最后一刻，开动火箭突然加速偏航，致命的下坠速度转化成有用的逃离速度。在速度最快的位置开动火箭加速，也叫Oberth机动。从远处看，就像绕星体运动的物体突然被“弹弓”弹出去一样，弹弓额外得到了力是星球的“引力”。<br />
<br />
太阳系大大小小有很多天体，只要相信万有引力，只要相信到时候各种星体一定会出现在该在的地方，只要时间节奏编排得当，就一定能用有限的燃料做引力弹弓（Oberth机动），得到原来不敢想象的速度。<br />
<br />
图中太阳是黄色，地球轨道是蓝色，内圈两个白色圆圈是水星和金星的轨道，粉色的圆圈是木星轨道，黄色的曲线是欧陌陌星体在“太阳系一游”的轨道。<br />
<br />
天琴座计划的具体方案：<br />
<br />
从地球上发射一颗星体，它的轨迹是红线，让它加速到离开地球引力，以椭圆轨道绕太阳运转，三年后再次靠近地球时，启动第一次引力弹弓。利用地球引力，奇妙的加速让它脱离原来的轨道。<br />
<br />
现在人造星体的运动方向是两年后木星（这是太阳系里质量最大的行星，它是粉色的轨道）的位置，差不多两年后，它一定会接近木星，在撞上木星之前，它启动了第二次引力弹弓，木星巨大的引力让它加速更快，绕了半圈直接掉头向太阳飞去。<br />
<br />
最壮观的是，一年以后，它在太阳附近又启动了第三次引力弹弓。太阳巨大的引力不仅让它拐了个大弯，几乎反向，而且让它开始真正的狂奔。你从红色的轨迹就能看出，新的速度让红线沿着黄线迅速延长，这速度几乎是那颗欧陌陌速度的两倍。<br />
<br />
十几年之后，它终于在太阳系边缘追上了欧陌陌，拍到了想要的照片。如何送回来，就是子孙后代考虑的事情了。我们这一代，有天琴座计划就足够骄傲啦。</p>
<p><a href="https://nitter.cz/leometric/status/1733858705366470855#m">nitter.cz/leometric/status/1733858705366470855#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734812956494381113#m</id>
            <title>安卓设备的AutoSpill漏洞可能导致1Password、DashLane、LastPass密码泄露

https://www.forbes.com/sites/daveywinder/2023/12/11/android-warning-1password-dashlane-lastpass-and-others-can-leak-passwords/?sh=2867a75a97db</title>
            <link>https://nitter.cz/dotey/status/1734812956494381113#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734812956494381113#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 05:50:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>安卓设备的AutoSpill漏洞可能导致1Password、DashLane、LastPass密码泄露<br />
<br />
<a href="https://www.forbes.com/sites/daveywinder/2023/12/11/android-warning-1password-dashlane-lastpass-and-others-can-leak-passwords/?sh=2867a75a97db">forbes.com/sites/daveywinder…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDE4ODUyOTU3MDE4OTMxMy82ZDJWdC0taj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1734811424348914156#m</id>
            <title>RT by @dotey: 微软研究团队改进了之前的Medprompt提示策略，使GPT-4在MMLU上的表现达到了90.10%，这是迄今为止GPT-4在该测试上取得的最高分数。

超越了不久刚发布的Gemini Ultra的90.04%😅

在微软研究团队开发的Medprompt+策略中，GPT-4模型使用一种特定的策略来决定最终的答案。

这个策略考虑了模型对不同候选答案的置信度，也就是模型认为每个答案正确的可能性。

具体来说，当GPT-4使用Medprompt+策略回答问题时，它不仅生成答案，还评估每个答案的置信度。这个置信度是基于模型内部计算的，反映了模型对自己给出的答案有多确信。

然后，GPT-4根据这些置信度来选择最终答案。如果模型对某个答案的置信度很高，那么这个答案就更有可能被选为最终答案。

这种方法使得GPT-4在回答问题时更加精确，因为它不仅仅是随机选择答案，而是基于对每个可能答案的置信度来做出更加有根据的选择。

这表明，通过系统化的提示工程和策略创新，可以显著提高大型语言模型在复杂任务上的性能。

微软公布了其最新的研究成果和Medprompt+ 仓库。

详细内容：https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/

Medprompt+ 仓库：https://github.com/microsoft/promptbase</title>
            <link>https://nitter.cz/xiaohuggg/status/1734811424348914156#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1734811424348914156#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 05:44:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软研究团队改进了之前的Medprompt提示策略，使GPT-4在MMLU上的表现达到了90.10%，这是迄今为止GPT-4在该测试上取得的最高分数。<br />
<br />
超越了不久刚发布的Gemini Ultra的90.04%😅<br />
<br />
在微软研究团队开发的Medprompt+策略中，GPT-4模型使用一种特定的策略来决定最终的答案。<br />
<br />
这个策略考虑了模型对不同候选答案的置信度，也就是模型认为每个答案正确的可能性。<br />
<br />
具体来说，当GPT-4使用Medprompt+策略回答问题时，它不仅生成答案，还评估每个答案的置信度。这个置信度是基于模型内部计算的，反映了模型对自己给出的答案有多确信。<br />
<br />
然后，GPT-4根据这些置信度来选择最终答案。如果模型对某个答案的置信度很高，那么这个答案就更有可能被选为最终答案。<br />
<br />
这种方法使得GPT-4在回答问题时更加精确，因为它不仅仅是随机选择答案，而是基于对每个可能答案的置信度来做出更加有根据的选择。<br />
<br />
这表明，通过系统化的提示工程和策略创新，可以显著提高大型语言模型在复杂任务上的性能。<br />
<br />
微软公布了其最新的研究成果和Medprompt+ 仓库。<br />
<br />
详细内容：<a href="https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/">microsoft.com/en-us/research…</a><br />
<br />
Medprompt+ 仓库：<a href="https://github.com/microsoft/promptbase">github.com/microsoft/promptb…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1729862138796351499#m">nitter.cz/xiaohuggg/status/1729862138796351499#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1734612479106543703#m</id>
            <title>RT by @dotey: 接着上次LLM inference 的选择，整理了一个repo。

包括了推理框架、推理后端以及性能评测（吞吐、QPS和首token延迟）。

目前评测只更新了2个，会尽快完成全部测试。

https://github.com/ninehills/llm-inference-benchmark</title>
            <link>https://nitter.cz/9hills/status/1734612479106543703#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1734612479106543703#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:33:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>接着上次LLM inference 的选择，整理了一个repo。<br />
<br />
包括了推理框架、推理后端以及性能评测（吞吐、QPS和首token延迟）。<br />
<br />
目前评测只更新了2个，会尽快完成全部测试。<br />
<br />
<a href="https://github.com/ninehills/llm-inference-benchmark">github.com/ninehills/llm-inf…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDYxMjEzMjcxOTkxNTAwOC9fODhDRmNMVj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/aigclab/status/1734782664979452010#m</id>
            <title>RT by @dotey: 确实顶👍

用双曲函数求导检测LLM的“聪明”程度👇
题目：
Find the derivative of sinh𝑥 + cosh𝑦 = 𝑥 + 𝑦. step by step
一步一步地展示dy/dx的求导过程

正确答案：
dy/dx = (1 - cosh(x)) / (sinh(y) - 1)

ChatGPT/GPT4毫无悬念，Gemini官方报告能行，mixtral做对，Claude半对，其他的都是渣渣😅</title>
            <link>https://nitter.cz/aigclab/status/1734782664979452010#m</link>
            <guid isPermaLink="false">https://nitter.cz/aigclab/status/1734782664979452010#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 03:49:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>确实顶👍<br />
<br />
用双曲函数求导检测LLM的“聪明”程度👇<br />
题目：<br />
Find the derivative of sinh𝑥 + cosh𝑦 = 𝑥 + 𝑦. step by step<br />
一步一步地展示dy/dx的求导过程<br />
<br />
正确答案：<br />
dy/dx = (1 - cosh(x)) / (sinh(y) - 1)<br />
<br />
ChatGPT/GPT4毫无悬念，Gemini官方报告能行，mixtral做对，Claude半对，其他的都是渣渣😅</p>
<p><a href="https://nitter.cz/op7418/status/1734760424456024238#m">nitter.cz/op7418/status/1734760424456024238#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JNdm5LMmFZQUF3dURCLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JNdm4xQ2J3QUEyZ002LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JNdm9VSmJJQUExVVl0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JNdm92cGJ3QUFFOXoxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734805589174235416#m</id>
            <title>微软今天发布小模型 Phi-2 的新闻关注度还蛮大的，只有2.7B参数（Llama 2最小的模型都是 7B的），模型越小就对设备要求越低，甚至于移动设备都能运行。但模型的能力又跟模型的训练量和参数量息息相关，数据量越大参数越大能力越强。

微软的解决方案是提升数据质量，通过专注于高质量的“教科书级”数据，训练数据混合了专门为教授模型常识推理和广泛知识（包括科学、日常生活和心理理论等）而设计的合成数据集。此外，还精心挑选了基于教育价值和内容质量筛选的网络数据，进一步丰富了训练语料库。

Phi-2 的训练数据有 1.4 T 个 token，在 96 块 A100 GPU 上训练了 14 天。

Phi-2 是一个基础模型，没有经过人类反馈强化学习（RLHF）的校准，也没有进行过指令式微调。

从能力上来说，据微软自己公布的数据：2.7B 的 Phi-2 超过了目前开源领域表现最好的 Mistral 和 Llama-2 7B 和 13B，编程能力甚至超过了 Llama-2-70B。

至于是不是真的这么强还得看看用户的反馈。

详情可以看官方博客：https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/

也可以看我翻译的版本：《Phi-2：小语言模型的非凡实力 [译]》
https://baoyu.io/translations/microsoft/phi-2-the-surprising-power-of-small-language-models</title>
            <link>https://nitter.cz/dotey/status/1734805589174235416#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734805589174235416#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 05:20:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软今天发布小模型 Phi-2 的新闻关注度还蛮大的，只有2.7B参数（Llama 2最小的模型都是 7B的），模型越小就对设备要求越低，甚至于移动设备都能运行。但模型的能力又跟模型的训练量和参数量息息相关，数据量越大参数越大能力越强。<br />
<br />
微软的解决方案是提升数据质量，通过专注于高质量的“教科书级”数据，训练数据混合了专门为教授模型常识推理和广泛知识（包括科学、日常生活和心理理论等）而设计的合成数据集。此外，还精心挑选了基于教育价值和内容质量筛选的网络数据，进一步丰富了训练语料库。<br />
<br />
Phi-2 的训练数据有 1.4 T 个 token，在 96 块 A100 GPU 上训练了 14 天。<br />
<br />
Phi-2 是一个基础模型，没有经过人类反馈强化学习（RLHF）的校准，也没有进行过指令式微调。<br />
<br />
从能力上来说，据微软自己公布的数据：2.7B 的 Phi-2 超过了目前开源领域表现最好的 Mistral 和 Llama-2 7B 和 13B，编程能力甚至超过了 Llama-2-70B。<br />
<br />
至于是不是真的这么强还得看看用户的反馈。<br />
<br />
详情可以看官方博客：<a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">microsoft.com/en-us/research…</a><br />
<br />
也可以看我翻译的版本：《Phi-2：小语言模型的非凡实力 [译]》<br />
<a href="https://baoyu.io/translations/microsoft/phi-2-the-surprising-power-of-small-language-models">baoyu.io/translations/micros…</a></p>
<p><a href="https://nitter.cz/MSFTResearch/status/1734609807770898674#m">nitter.cz/MSFTResearch/status/1734609807770898674#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>