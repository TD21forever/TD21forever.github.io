<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/Tisoga/status/1743180620183048406#m</id>
            <title>RT by @dotey: . @perplexity_ai just announced a new round of $73 million in Series B funding. As I've been working on my own product, http://devv.ai, recently, I have many thoughts to share randomly:

1. Iceberg Theory

At the end of 2022, when not many people knew about Perplexity, we had implemented a demo version. At that time, we thought, isn't this just another GPT wrapper? (Surely many still think so). However, what our demo didn't achieve was how to make the search speed fast enough and the user experience good enough. 

Only after really working on http://devv.ai did we realize that there's so much to be done behind the scenes. It's not as simple as just hooking up an embedding database to LangChain. Every aspect of RAG has many opportunities for optimization. 

Google Search is just an input box, but hidden beneath the iceberg is a vast complexity of intricate details.

2. UX Matters

Another advantage of Perplexity is its simplicity in UI &amp; UX. 

Over the past 20 years, search engines have ingrained the habit of searching in users, and changing habits is the hardest thing. 

While maintaining the method of searching, Perplexity has made many optimizations in UX, which is much better than the experience of ChatGPT browsing mode (of course, OpenAI's goal is AGI, and making a user-friendly product might be a secondary objective). 

Most users don't need to know the underlying technology.

3. Think Big, Start Small, Iterate

Perplexity's vision is to build the world's best conversational answer engine, but it's impossible to achieve this in one step. 

The initial version was based on the GPT API + Bing API to get things started, and then iterate from there. 

Over the past year, Perplexity has maintained a pace of releasing updates almost every week, and the product's features and technical barriers are visibly thickening.

4. Subscription Might Not Be the Best Monetization Model

The cost of a generative search engine is much higher than that of traditional search engines. Conservatively estimated, the cost of Perplexity's 500 million searches in 2023 is likely in the tens of millions of dollars, and the current ARR probably can't cover this cost. There might be more possibilities for monetization in the future (an advertising platform based on LLMs?).

I'm very pleased to have seen such an excellent product in 2023, and to have learned so much from @AravSrinivas  in my own entrepreneurial journey!</title>
            <link>https://nitter.cz/Tisoga/status/1743180620183048406#m</link>
            <guid isPermaLink="false">https://nitter.cz/Tisoga/status/1743180620183048406#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 08:00:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>. <a href="https://nitter.cz/perplexity_ai" title="Perplexity">@perplexity_ai</a> just announced a new round of $73 million in Series B funding. As I've been working on my own product, <a href="http://devv.ai">devv.ai</a>, recently, I have many thoughts to share randomly:<br />
<br />
1. Iceberg Theory<br />
<br />
At the end of 2022, when not many people knew about Perplexity, we had implemented a demo version. At that time, we thought, isn't this just another GPT wrapper? (Surely many still think so). However, what our demo didn't achieve was how to make the search speed fast enough and the user experience good enough. <br />
<br />
Only after really working on <a href="http://devv.ai">devv.ai</a> did we realize that there's so much to be done behind the scenes. It's not as simple as just hooking up an embedding database to LangChain. Every aspect of RAG has many opportunities for optimization. <br />
<br />
Google Search is just an input box, but hidden beneath the iceberg is a vast complexity of intricate details.<br />
<br />
2. UX Matters<br />
<br />
Another advantage of Perplexity is its simplicity in UI & UX. <br />
<br />
Over the past 20 years, search engines have ingrained the habit of searching in users, and changing habits is the hardest thing. <br />
<br />
While maintaining the method of searching, Perplexity has made many optimizations in UX, which is much better than the experience of ChatGPT browsing mode (of course, OpenAI's goal is AGI, and making a user-friendly product might be a secondary objective). <br />
<br />
Most users don't need to know the underlying technology.<br />
<br />
3. Think Big, Start Small, Iterate<br />
<br />
Perplexity's vision is to build the world's best conversational answer engine, but it's impossible to achieve this in one step. <br />
<br />
The initial version was based on the GPT API + Bing API to get things started, and then iterate from there. <br />
<br />
Over the past year, Perplexity has maintained a pace of releasing updates almost every week, and the product's features and technical barriers are visibly thickening.<br />
<br />
4. Subscription Might Not Be the Best Monetization Model<br />
<br />
The cost of a generative search engine is much higher than that of traditional search engines. Conservatively estimated, the cost of Perplexity's 500 million searches in 2023 is likely in the tens of millions of dollars, and the current ARR probably can't cover this cost. There might be more possibilities for monetization in the future (an advertising platform based on LLMs?).<br />
<br />
I'm very pleased to have seen such an excellent product in 2023, and to have learned so much from <a href="https://nitter.cz/AravSrinivas" title="Aravind Srinivas">@AravSrinivas</a>  in my own entrepreneurial journey!</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Danielw19410/status/1743189389126271163#m</id>
            <title>RT by @dotey: 推荐一个3小时的长视频（播客），视频涉及的主题太多不好总结，我给两个推荐理由：
1.如果你喜欢《马斯克传》，那么你应该也会喜欢这个视频，充满了无数琐碎的故事和真实的细节。

2.国内有关互联网、创投相关的播客没有讲的20%里面，这里面聊了其中的50%。

视频链接：https://www.youtube.com/watch?v=vCzj0Fth_8A&amp;t=6035s</title>
            <link>https://nitter.cz/Danielw19410/status/1743189389126271163#m</link>
            <guid isPermaLink="false">https://nitter.cz/Danielw19410/status/1743189389126271163#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 08:35:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一个3小时的长视频（播客），视频涉及的主题太多不好总结，我给两个推荐理由：<br />
1.如果你喜欢《马斯克传》，那么你应该也会喜欢这个视频，充满了无数琐碎的故事和真实的细节。<br />
<br />
2.国内有关互联网、创投相关的播客没有讲的20%里面，这里面聊了其中的50%。<br />
<br />
视频链接：<a href="https://www.youtube.com/watch?v=vCzj0Fth_8A&amp;t=6035s">youtube.com/watch?v=vCzj0Fth…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MTc2NzY1MDU4NDQ3NzY5Ni95RlZWR0QtVz9mb3JtYXQ9anBnJm5hbWU9ODAweDMyMF8x" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743186449304842390#m</id>
            <title>今天看到一张 Apple 的 Pascal 语法的海报的矢量图重制版，1979 年的海报到现在都很漂亮，而且内容很极客，是 Pascal 语言的语法图！有些人称它为“极客圈的终极海报”。

特地去了解了一下它背后的故事：故事发生在 1979 年，就在几年前 Apple II 发布。那是 Apple 公司历史上的辉煌时刻，乔布斯身边聚集了一群杰出的人才，现代计算机的传奇历史才刚刚拉开序幕。

在 1977 年，Apple II 计算机面市，它被誉为第一台“个人电脑”。不同于采用 BASIC 语言，Apple II 选择了一种新颖、现代且高效的编程语言：Apple Pascal。这是由 Niklaus Wirth 于 1970 年创造的 UCSD Pascal 系统 的发展版本，旨在向 17 世纪发明了机械计算器的法国数学家 Blaise Pascal 致敬。

Apple II 上运行的是由 Bill Atkinson（图二）编写的 Pascal 编译器，他同时也是该编译器最初的也是最重要的程序员。

选择 Pascal 而不是更简单、更原始的 BASIC 并不是一件容易的事：乔布斯最初认为这是一个过于复杂的选择，他觉得 Apple II 使用 BASIC 就足够了，他对计算机附带的实用程序更感兴趣，而不是它所支持的编程语言。

但 Atkinson 最终说服了他，展示了 Pascal 的优势，以及它如何能够为新平台带来巨大的优势，为第三方软件的发展奠定了坚实的基础。正是因为这一选择，才促成了后来第三方软件的兴起。

对于很多老程序员来说，Pascal 是一个起点，它包含了像结构、变量这些现代编程的基础概念，这些概念即使到现在每种编程语言中都重复出现。

其中最著名的跟 Pascal 相关的大神当属 Anders Hejlsberg，曾为 Borland 开发出 Delphi，后来加入微软又主持了 .Net 的开发，现在的 TypeScript 也是他主导的。扯这么多其实只是想说 Delphi 的前身是 Object Pascal 和 Turbo Pascal！

很多人都知道，Mac 之父是 Jef Raskin，当时的 Apple II 及其后的 Macintosh 都是由他负责的，当他在将 Apple Pascal 适配到 Apple 电脑上时发现，传统的编程语言文档与 Atkinson 开发的新编译器在语法上有所不同，因此需要为程序员提供一系列新的参考资料。

Jef 开始设计一系列关于 Apple Pascal 的主要结构和逻辑语法的图解，这些图解是程序员学习和使用 Apple Pascal 时不可或缺的便捷参考，它们被打印出来并在 Apple 公司内部分发。他对这个项目投入了大量精力，简化了当时流行的各种复杂图解，并采用了严格的颜色编码，使内容更加清晰易懂，并选择了海报格式，方便 Apple 公司的每位程序员都能在自己的小隔间中挂上一张。

参考图三，这是 Jef Raskin 在一张老照片中，注意到背景里有一张海报。

当乔布斯第一眼看到 Jef Raskin 的项目时，他马上看出了其市场营销的巨大潜力。对 Jef Raskin 而言，这不过是一个为程序员提供语法参考的普通海报，但乔布斯却在其中看到了一件极具美感的图形作品，或者说，一件充满潜力的艺术品，但他要求专门聘请一位图形设计师重新设计海报，最终 Apple 找到了 Tom Kamifuji，一位当时在旧金山颇有名气的艺术家，并让他对 Jef Raskin 的作品进行改动，使之更具“艺术感”。

Tom Kamifuji 保留了原有的结构和语法，仅仅对图形设计进行了调整，使之更为协调。然而，他所犯的一个错误是彻底改变了色彩方案，原本 Jef Raskin 根据不同的编程结构或特定语法使用了不同的颜色，使整个设计对程序员来说更加易读和易懂。结果最终的额海报五颜六色，Pascal 中的“标识符 (identifier)”被表示为四种不同的颜色：紫色、橙色、绿色和粉色……（参考图四）

对于乔布斯和 Tom Kamifuji 来说，他们只关心海报是否“漂亮”，即使 Jef Raskin 强烈反对，最终的版本还是按照 Tom Kamifuji 的设计印刷的，甚至于最终海报上只有 Tom Kamifuji 的名字而没有 Jef Raskin 的名字。

关于这张传奇海报的印刷数量至今未知。每位 Apple 程序员都有一份，而且还分发给了一些外部程序员。正如乔布斯所期望的那样，这些海报被提供给了经销商，也被送给了 Apple 的顾客以用于推广 Apple Pascal 和 Apple 公司。

高清 PDF 下载：http://www.danamania.com/print/Apple%20Pascal%20Poster/PascalPosterV3%20A1.pdf

苹果 Pascal“语法”海报的历史，1979-80 [译]：https://baoyu.io/translations/apple/the-history-of-apples-pascal-syntax-poster-1979-80

苹果 PASCAL 语法海报：极客圈的传奇作品 [译]：https://baoyu.io/translations/apple/apple-pascal-syntax-poster</title>
            <link>https://nitter.cz/dotey/status/1743186449304842390#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743186449304842390#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 08:23:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天看到一张 Apple 的 Pascal 语法的海报的矢量图重制版，1979 年的海报到现在都很漂亮，而且内容很极客，是 Pascal 语言的语法图！有些人称它为“极客圈的终极海报”。<br />
<br />
特地去了解了一下它背后的故事：故事发生在 1979 年，就在几年前 Apple II 发布。那是 Apple 公司历史上的辉煌时刻，乔布斯身边聚集了一群杰出的人才，现代计算机的传奇历史才刚刚拉开序幕。<br />
<br />
在 1977 年，Apple II 计算机面市，它被誉为第一台“个人电脑”。不同于采用 BASIC 语言，Apple II 选择了一种新颖、现代且高效的编程语言：Apple Pascal。这是由 Niklaus Wirth 于 1970 年创造的 UCSD Pascal 系统 的发展版本，旨在向 17 世纪发明了机械计算器的法国数学家 Blaise Pascal 致敬。<br />
<br />
Apple II 上运行的是由 Bill Atkinson（图二）编写的 Pascal 编译器，他同时也是该编译器最初的也是最重要的程序员。<br />
<br />
选择 Pascal 而不是更简单、更原始的 BASIC 并不是一件容易的事：乔布斯最初认为这是一个过于复杂的选择，他觉得 Apple II 使用 BASIC 就足够了，他对计算机附带的实用程序更感兴趣，而不是它所支持的编程语言。<br />
<br />
但 Atkinson 最终说服了他，展示了 Pascal 的优势，以及它如何能够为新平台带来巨大的优势，为第三方软件的发展奠定了坚实的基础。正是因为这一选择，才促成了后来第三方软件的兴起。<br />
<br />
对于很多老程序员来说，Pascal 是一个起点，它包含了像结构、变量这些现代编程的基础概念，这些概念即使到现在每种编程语言中都重复出现。<br />
<br />
其中最著名的跟 Pascal 相关的大神当属 Anders Hejlsberg，曾为 Borland 开发出 Delphi，后来加入微软又主持了 .Net 的开发，现在的 TypeScript 也是他主导的。扯这么多其实只是想说 Delphi 的前身是 Object Pascal 和 Turbo Pascal！<br />
<br />
很多人都知道，Mac 之父是 Jef Raskin，当时的 Apple II 及其后的 Macintosh 都是由他负责的，当他在将 Apple Pascal 适配到 Apple 电脑上时发现，传统的编程语言文档与 Atkinson 开发的新编译器在语法上有所不同，因此需要为程序员提供一系列新的参考资料。<br />
<br />
Jef 开始设计一系列关于 Apple Pascal 的主要结构和逻辑语法的图解，这些图解是程序员学习和使用 Apple Pascal 时不可或缺的便捷参考，它们被打印出来并在 Apple 公司内部分发。他对这个项目投入了大量精力，简化了当时流行的各种复杂图解，并采用了严格的颜色编码，使内容更加清晰易懂，并选择了海报格式，方便 Apple 公司的每位程序员都能在自己的小隔间中挂上一张。<br />
<br />
参考图三，这是 Jef Raskin 在一张老照片中，注意到背景里有一张海报。<br />
<br />
当乔布斯第一眼看到 Jef Raskin 的项目时，他马上看出了其市场营销的巨大潜力。对 Jef Raskin 而言，这不过是一个为程序员提供语法参考的普通海报，但乔布斯却在其中看到了一件极具美感的图形作品，或者说，一件充满潜力的艺术品，但他要求专门聘请一位图形设计师重新设计海报，最终 Apple 找到了 Tom Kamifuji，一位当时在旧金山颇有名气的艺术家，并让他对 Jef Raskin 的作品进行改动，使之更具“艺术感”。<br />
<br />
Tom Kamifuji 保留了原有的结构和语法，仅仅对图形设计进行了调整，使之更为协调。然而，他所犯的一个错误是彻底改变了色彩方案，原本 Jef Raskin 根据不同的编程结构或特定语法使用了不同的颜色，使整个设计对程序员来说更加易读和易懂。结果最终的额海报五颜六色，Pascal 中的“标识符 (identifier)”被表示为四种不同的颜色：紫色、橙色、绿色和粉色……（参考图四）<br />
<br />
对于乔布斯和 Tom Kamifuji 来说，他们只关心海报是否“漂亮”，即使 Jef Raskin 强烈反对，最终的版本还是按照 Tom Kamifuji 的设计印刷的，甚至于最终海报上只有 Tom Kamifuji 的名字而没有 Jef Raskin 的名字。<br />
<br />
关于这张传奇海报的印刷数量至今未知。每位 Apple 程序员都有一份，而且还分发给了一些外部程序员。正如乔布斯所期望的那样，这些海报被提供给了经销商，也被送给了 Apple 的顾客以用于推广 Apple Pascal 和 Apple 公司。<br />
<br />
高清 PDF 下载：<a href="http://www.danamania.com/print/Apple%20Pascal%20Poster/PascalPosterV3%20A1.pdf">danamania.com/print/Apple%20…</a><br />
<br />
苹果 Pascal“语法”海报的历史，1979-80 [译]：<a href="https://baoyu.io/translations/apple/the-history-of-apples-pascal-syntax-poster-1979-80">baoyu.io/translations/apple/…</a><br />
<br />
苹果 PASCAL 语法海报：极客圈的传奇作品 [译]：<a href="https://baoyu.io/translations/apple/apple-pascal-syntax-poster">baoyu.io/translations/apple/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RFQzB0MVdjQUEtaEJRLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RFRVo4cldzQUFEaTJELmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RFS3FaTldnQUFNUmY4LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RFS3c4X1c0QUFpYkJ5LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743160889069752803#m</id>
            <title>RT by @dotey: 昨天这个利用 SD 生成可以骗过银行之类实名认证系统的手持 ID 照片的推火了。原推 400 万曝光。

👇下面看一下作者写的工作流程：

将两个Lora模型结合在一起（例如： x+y+z=1，通过实验直到达到一致性和审美效果）。其他人提到Faceswap更快，但我还没尝试过。

生成了一组没有Lora的图像，并挑选了一张喜欢的（通过提示种族、发型和长度来保持一致性）。然后回收种子，用Lora和Controlnet来细化面孔。

在卡片上添加文字的流程：SD会生成一张空白纸。你可以在纸上手写想要的文字，纸张的纹理越丰富越好。然后在Photoshop中以强光模式叠加这些文字并进行清理。

在皮肤上添加文字的流程：在Photoshop中使用画笔工具书写。将文字扭曲以适应身体的轮廓。
运行img2img inpaint，提示在皮肤上的画笔，设置重绘幅度，并使用Controlnet Canny。
可能需要先将图像裁剪到512x512像素，再放大文本区域，然后再进行img2img处理以获得更好的效果。
最后，在Photoshop中将图像叠加。

原贴地址：https://www.reddit.com/r/StableDiffusion/comments/18yq5r4/if_youve_been_following_along_this_is_a_3rd_and/</title>
            <link>https://nitter.cz/op7418/status/1743160889069752803#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743160889069752803#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:41:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天这个利用 SD 生成可以骗过银行之类实名认证系统的手持 ID 照片的推火了。原推 400 万曝光。<br />
<br />
👇下面看一下作者写的工作流程：<br />
<br />
将两个Lora模型结合在一起（例如： x+y+z=1，通过实验直到达到一致性和审美效果）。其他人提到Faceswap更快，但我还没尝试过。<br />
<br />
生成了一组没有Lora的图像，并挑选了一张喜欢的（通过提示种族、发型和长度来保持一致性）。然后回收种子，用Lora和Controlnet来细化面孔。<br />
<br />
在卡片上添加文字的流程：SD会生成一张空白纸。你可以在纸上手写想要的文字，纸张的纹理越丰富越好。然后在Photoshop中以强光模式叠加这些文字并进行清理。<br />
<br />
在皮肤上添加文字的流程：在Photoshop中使用画笔工具书写。将文字扭曲以适应身体的轮廓。<br />
运行img2img inpaint，提示在皮肤上的画笔，设置重绘幅度，并使用Controlnet Canny。<br />
可能需要先将图像裁剪到512x512像素，再放大文本区域，然后再进行img2img处理以获得更好的效果。<br />
最后，在Photoshop中将图像叠加。<br />
<br />
原贴地址：<a href="https://teddit.net/r/StableDiffusion/comments/18yq5r4/if_youve_been_following_along_this_is_a_3rd_and/">teddit.net/r/StableDiffusion…</a></p>
<p><a href="https://nitter.cz/venturetwins/status/1742976476432196100#m">nitter.cz/venturetwins/status/1742976476432196100#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REc1puQmJZQUV0YUwyLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REc2IzLWJBQUFreEdwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/samsongli/status/1743146080274149848#m</id>
            <title>RT by @dotey: 我看了华南理工教授的采访视频，他对这个研究成果很谨慎，用了大量时间解释这只是检测超导体的手段之一，并且分析了为何信号比较差。是一个正常的科学工作者的正确作法。</title>
            <link>https://nitter.cz/samsongli/status/1743146080274149848#m</link>
            <guid isPermaLink="false">https://nitter.cz/samsongli/status/1743146080274149848#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 05:43:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我看了华南理工教授的采访视频，他对这个研究成果很谨慎，用了大量时间解释这只是检测超导体的手段之一，并且分析了为何信号比较差。是一个正常的科学工作者的正确作法。</p>
<p><a href="https://nitter.cz/dotey/status/1742813384725205300#m">nitter.cz/dotey/status/1742813384725205300#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743146215666061455#m</id>
            <title>R to @dotey: Awesome-llm-role-playing-with-persona:

以指定角色进行角色扮演的大语言模型资源精选列表

https://github.com/Neph0s/awesome-llm-role-playing-with-persona</title>
            <link>https://nitter.cz/dotey/status/1743146215666061455#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743146215666061455#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 05:43:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Awesome-llm-role-playing-with-persona:<br />
<br />
以指定角色进行角色扮演的大语言模型资源精选列表<br />
<br />
<a href="https://github.com/Neph0s/awesome-llm-role-playing-with-persona">github.com/Neph0s/awesome-ll…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MjY2NDUzNzg4NTYwMTc5Mi9mV2hZcTFoej9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743146214550278231#m</id>
            <title>https://github.com/zjunlp/LLMAgentPapers

大语言模型智能体相关论文列表</title>
            <link>https://nitter.cz/dotey/status/1743146214550278231#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743146214550278231#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 05:43:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://github.com/zjunlp/LLMAgentPapers">github.com/zjunlp/LLMAgentPa…</a><br />
<br />
大语言模型智能体相关论文列表</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MzE0NjA2OTgwMDY4NTU2OC81V3hmNWJHVz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743136004108698079#m</id>
            <title>R to @dotey: 有人直接把这些文档做成了问答机器人：https://collie.ai/epstein2024</title>
            <link>https://nitter.cz/dotey/status/1743136004108698079#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743136004108698079#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 05:03:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有人直接把这些文档做成了问答机器人：<a href="https://collie.ai/epstein2024">collie.ai/epstein2024</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743133367044809167#m</id>
            <title>现在科学期刊开始借助 AI 来检测论文中造假的图片，不知道是不是以后投稿的也会借助 AI 来造假？

《科学期刊将启用AI进行图片欺诈检测》
https://arstechnica.com/science/2024/01/all-science-journals-will-now-do-an-ai-powered-check-for-image-fraud/

AI 只能捕捉到最明显的造假问题，但是这个举措的实施已经刻不容缓。

研究出版机构 Science 近在周四宣布，他们的所有期刊将开始使用商业化的软件，用以自动检测被不适当操控的图片。这个举措来得稍微有些晚，早在几年前，我们就意识到数字数据和出版的进步让研究欺诈通过更改图片变得易如反掌。

这个举步被视为一步重要的起始，但是必须要意识到软件的限制。虽然它能捕捉最明显的捏造修改案例，但那些机灵的欺诈行为者如果了解了软件的工作原理就能轻易避开被检测。遗憾的是，我们不得不详细说明这个问题（如实讲述，开发这款软件的公司确实在他们的网站上详细说明了这个问题）。

如何在茫茫欺诈案例中找到证据

我们见识到的大部分图像欺诈移到的绝大多数科学家面临的一个困境：进行实验并不成问题，但他们收集的数据往往并不是他们想要的。也许只有对照实验起作用，或者可能实验产生的数据与对照并无区别。对不道德之人来说，这并无大碍，因为除了你之外，没有人知道哪些图像的来源。所以，把真实数据的图像展示为其本不该是的非常简单。

我们可以具体看一下一个叫Western blot的程序产生的数据，这个程序通过抗体从已按蛋白质尺寸分离过的复杂混合物中特别鉴定出特定的蛋白质。典型的Western blot数据就如你在右边看见的图片，带子的深色代表在不同条件下存在不同层次的蛋白质。

图二：像这样的Western blot，通过带走大量的单独图像从其原本的上下文中脱离，使其更易于进行研究欺诈。Yu et. al./NIH OpenI

值得注意的是，这些带子相对没有什么特色，它们被从原始数据的更大图像中剪切出来，与原来的上下文毫无关联。这使得我们可以从一个试验中拿走一些带子，然后将它们拼接进一个完全不同实验的图片中，制造出原本并不存在的“证据”。同样的事情也可以用图表、细胞的照片等方式完成。

由于数据困难获得而且欺诈者往往偷懒，因此在许多情况下，原始和伪造图像都来自于为同一篇论文计算的数据。为了隐藏他们走过的痕迹，不道德的研究者常常会对图像进行旋转、放大、裁剪或改变图像的亮度/对比度，然后在同一篇论文中多次使用它们。

并非所有人都那么懒。然而，图片回收还是很常见的，这或许是研究欺诈最令人恼火的形式。所有的证据都在论文中，一旦被指出，通常很容易看到。但是你首次见到它的时候可能会觉得非常难以察觉。

"首次揭示"这个挑战是Science选择使用名为Proofig的服务以便更容易发现问题的原因。

运用AI验明正身

Science在宣布新政策时所用的社论及Proofig的网站都表示，其服务是由AI驱动，尽管这种说法在一定程度上是确实如此。明确地运用AI的一步是，在研究原稿的PDF中识别图片。一旦用户确认系统识别到的对象与论文的图形相对应，软件就会检测全部图形寻找重叠的特征，即使在裁剪或旋转的情况下也是如此。

这个后续过程并不一定需要AI，一些用于任务如识别图片中重复特征的神经网络，并不擅长强调用以识别相似性的细节。与之相反，Proofig的系统会计算不同图片共享的特征的数量，并提供一个图形视图，通过连线来连接这些特征。Proofig并没有清楚的说明它用什么来识别图像特征。（它用AI来检测何时有多个图像拼接成一个单一组合，但不一定用于识别其他细节。）

无论以何种方式完成，最后的结果都是一份报告，其中标注出在不同图形中可能的相似性，并展示了重叠区域的大小。对于发现的任何问题该如何处理，就留给期刊的编辑们来决定。

在Science的情况下，编辑们会首先核实是否真的存在问题。在很多情况下，图像的一部分被放大和剪裁以便清晰查看关键特征。（你可以在我们从关于化石蓝藻细菌的论文中使用的图片上看到其中的一例。）如果这是问题的全部内容，那么在线版本和PDF版本都会加入一份冗长的编辑说明，详细描述了修改后的图像采用的放大和剪裁效果。

在其他情况下，编辑可能需要联络作者以获取原始数据，或者请同行评审人员重新检查论文。这个过程可能要求Science的编辑们做出判断，比如，某一帧图片本来就被设计来显示同样的内容，而它们看起来相似是否就构成了问题。

从过去看未来

Science是否将这个过程描述为涵盖了所有情况，最后还需要看情况。但是，如果这个描述是准确的，那么Proofig系统看起来主要是针对那些在同一篇论文中进行伪造的行为，将不同的图片拼接在一起，然后将这个新的、混合起来的图片当作不同的数据来展示。这将捕获一些最明显的例子，并帮助阻止那些企图对系统进行游戏的人。

但是Proofig或许并不足以防止所有形式的图片欺诈。换言之，如果不道德的研究者花费大量时间和精力制造假图像，那么Proofig恐怕只能对他们束手无策。
这并不是说我们无法找到更好的方法。例如，构建一个数据库，收集已出版的所有科学图像。这将提供更大的挑战，包括巨额的存储需求，数据隐私问题（许多图像来自于医学研究），许多相似图像可能会导致大量的假阳性等。然而它也可能超出了独立为特定群体提供服务的商业公司的范畴。
而且，即使有了上述全部工具，也无法解决掉最直接的替代办法。那就是，如果你打算伪造数据，那就把一个还没有公开发布的图像当作开始。没有任何系统能够识别出与仅存储在实验室一台硬盘上的图像的相似性。

这些问题并不是用来颠覆Proofig建立的系统，或者Science决定采用它们的事实。该系统能够捕获最明显的研究欺诈案例，也即我们应该首先明白的情况。预防研究欺诈是一项难题，任何能够消除某些案例的步骤都非常重要。

此外，《科学》期刊尚未公开其将如何处理旗下已经发现与未发现的数千篇科学论文，这些论文的图像已被认定为似乎被不适当地操控。有一些被指出问题的作者已经提供了需要的解释或数据，但大部分确实存在问题的研究都没有得到解答，部分作者已经很久没有回应了。</title>
            <link>https://nitter.cz/dotey/status/1743133367044809167#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743133367044809167#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 04:52:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在科学期刊开始借助 AI 来检测论文中造假的图片，不知道是不是以后投稿的也会借助 AI 来造假？<br />
<br />
《科学期刊将启用AI进行图片欺诈检测》<br />
<a href="https://arstechnica.com/science/2024/01/all-science-journals-will-now-do-an-ai-powered-check-for-image-fraud/">arstechnica.com/science/2024…</a><br />
<br />
AI 只能捕捉到最明显的造假问题，但是这个举措的实施已经刻不容缓。<br />
<br />
研究出版机构 Science 近在周四宣布，他们的所有期刊将开始使用商业化的软件，用以自动检测被不适当操控的图片。这个举措来得稍微有些晚，早在几年前，我们就意识到数字数据和出版的进步让研究欺诈通过更改图片变得易如反掌。<br />
<br />
这个举步被视为一步重要的起始，但是必须要意识到软件的限制。虽然它能捕捉最明显的捏造修改案例，但那些机灵的欺诈行为者如果了解了软件的工作原理就能轻易避开被检测。遗憾的是，我们不得不详细说明这个问题（如实讲述，开发这款软件的公司确实在他们的网站上详细说明了这个问题）。<br />
<br />
如何在茫茫欺诈案例中找到证据<br />
<br />
我们见识到的大部分图像欺诈移到的绝大多数科学家面临的一个困境：进行实验并不成问题，但他们收集的数据往往并不是他们想要的。也许只有对照实验起作用，或者可能实验产生的数据与对照并无区别。对不道德之人来说，这并无大碍，因为除了你之外，没有人知道哪些图像的来源。所以，把真实数据的图像展示为其本不该是的非常简单。<br />
<br />
我们可以具体看一下一个叫Western blot的程序产生的数据，这个程序通过抗体从已按蛋白质尺寸分离过的复杂混合物中特别鉴定出特定的蛋白质。典型的Western blot数据就如你在右边看见的图片，带子的深色代表在不同条件下存在不同层次的蛋白质。<br />
<br />
图二：像这样的Western blot，通过带走大量的单独图像从其原本的上下文中脱离，使其更易于进行研究欺诈。Yu et. al./NIH OpenI<br />
<br />
值得注意的是，这些带子相对没有什么特色，它们被从原始数据的更大图像中剪切出来，与原来的上下文毫无关联。这使得我们可以从一个试验中拿走一些带子，然后将它们拼接进一个完全不同实验的图片中，制造出原本并不存在的“证据”。同样的事情也可以用图表、细胞的照片等方式完成。<br />
<br />
由于数据困难获得而且欺诈者往往偷懒，因此在许多情况下，原始和伪造图像都来自于为同一篇论文计算的数据。为了隐藏他们走过的痕迹，不道德的研究者常常会对图像进行旋转、放大、裁剪或改变图像的亮度/对比度，然后在同一篇论文中多次使用它们。<br />
<br />
并非所有人都那么懒。然而，图片回收还是很常见的，这或许是研究欺诈最令人恼火的形式。所有的证据都在论文中，一旦被指出，通常很容易看到。但是你首次见到它的时候可能会觉得非常难以察觉。<br />
<br />
"首次揭示"这个挑战是Science选择使用名为Proofig的服务以便更容易发现问题的原因。<br />
<br />
运用AI验明正身<br />
<br />
Science在宣布新政策时所用的社论及Proofig的网站都表示，其服务是由AI驱动，尽管这种说法在一定程度上是确实如此。明确地运用AI的一步是，在研究原稿的PDF中识别图片。一旦用户确认系统识别到的对象与论文的图形相对应，软件就会检测全部图形寻找重叠的特征，即使在裁剪或旋转的情况下也是如此。<br />
<br />
这个后续过程并不一定需要AI，一些用于任务如识别图片中重复特征的神经网络，并不擅长强调用以识别相似性的细节。与之相反，Proofig的系统会计算不同图片共享的特征的数量，并提供一个图形视图，通过连线来连接这些特征。Proofig并没有清楚的说明它用什么来识别图像特征。（它用AI来检测何时有多个图像拼接成一个单一组合，但不一定用于识别其他细节。）<br />
<br />
无论以何种方式完成，最后的结果都是一份报告，其中标注出在不同图形中可能的相似性，并展示了重叠区域的大小。对于发现的任何问题该如何处理，就留给期刊的编辑们来决定。<br />
<br />
在Science的情况下，编辑们会首先核实是否真的存在问题。在很多情况下，图像的一部分被放大和剪裁以便清晰查看关键特征。（你可以在我们从关于化石蓝藻细菌的论文中使用的图片上看到其中的一例。）如果这是问题的全部内容，那么在线版本和PDF版本都会加入一份冗长的编辑说明，详细描述了修改后的图像采用的放大和剪裁效果。<br />
<br />
在其他情况下，编辑可能需要联络作者以获取原始数据，或者请同行评审人员重新检查论文。这个过程可能要求Science的编辑们做出判断，比如，某一帧图片本来就被设计来显示同样的内容，而它们看起来相似是否就构成了问题。<br />
<br />
从过去看未来<br />
<br />
Science是否将这个过程描述为涵盖了所有情况，最后还需要看情况。但是，如果这个描述是准确的，那么Proofig系统看起来主要是针对那些在同一篇论文中进行伪造的行为，将不同的图片拼接在一起，然后将这个新的、混合起来的图片当作不同的数据来展示。这将捕获一些最明显的例子，并帮助阻止那些企图对系统进行游戏的人。<br />
<br />
但是Proofig或许并不足以防止所有形式的图片欺诈。换言之，如果不道德的研究者花费大量时间和精力制造假图像，那么Proofig恐怕只能对他们束手无策。<br />
这并不是说我们无法找到更好的方法。例如，构建一个数据库，收集已出版的所有科学图像。这将提供更大的挑战，包括巨额的存储需求，数据隐私问题（许多图像来自于医学研究），许多相似图像可能会导致大量的假阳性等。然而它也可能超出了独立为特定群体提供服务的商业公司的范畴。<br />
而且，即使有了上述全部工具，也无法解决掉最直接的替代办法。那就是，如果你打算伪造数据，那就把一个还没有公开发布的图像当作开始。没有任何系统能够识别出与仅存储在实验室一台硬盘上的图像的相似性。<br />
<br />
这些问题并不是用来颠覆Proofig建立的系统，或者Science决定采用它们的事实。该系统能够捕获最明显的研究欺诈案例，也即我们应该首先明白的情况。预防研究欺诈是一项难题，任何能够消除某些案例的步骤都非常重要。<br />
<br />
此外，《科学》期刊尚未公开其将如何处理旗下已经发现与未发现的数千篇科学论文，这些论文的图像已被认定为似乎被不适当地操控。有一些被指出问题的作者已经提供了需要的解释或数据，但大部分确实存在问题的研究都没有得到解答，部分作者已经很久没有回应了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REWjNHNlhrQUFFMVliLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REWjZkUlc4QUFrMDJWLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/balconychy/status/1743103140558508307#m</id>
            <title>RT by @dotey: 这机器人的BOM清单已经开源了。
总价32K美金。
https://docs.google.com/document/d/1_3yhWjodSNNYlpxkRCPIlvIAaQ76Nqk2wsqhnEVM6Dc/edit</title>
            <link>https://nitter.cz/balconychy/status/1743103140558508307#m</link>
            <guid isPermaLink="false">https://nitter.cz/balconychy/status/1743103140558508307#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 02:52:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这机器人的BOM清单已经开源了。<br />
总价32K美金。<br />
<a href="https://docs.google.com/document/d/1_3yhWjodSNNYlpxkRCPIlvIAaQ76Nqk2wsqhnEVM6Dc/edit">docs.google.com/document/d/1…</a></p>
<p><a href="https://nitter.cz/zipengfu/status/1742973258528612724#m">nitter.cz/zipengfu/status/1742973258528612724#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDLTladGJnQUFFWXNyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Yangyixxxx/status/1743123960559235121#m</id>
            <title>RT by @dotey: 分享一个独立开发者故事：利用无代码，构建2.5millon收益的创业项目

在一个平凡的小镇，住着一个年轻的创业者，查德·萨康奇克。他的早期创业之路充满了挑战：他白天帮朋友的公司安装维护化粪池，夜晚则在父母家的卧室与海外开发者沟通，努力推进自己的项目。

查德先后创建了几个初创公司，包括一个网站创建平台、一个面向食品车主的应用和一个活动空间平台。他投入了大量资金雇佣开发人员，却发现编码工作耗时耗力，且很难说服人们使用他的应用。这些经历让他意识到，必须有更好的方式来开展业务。

灵感来自于帮助一位律师朋友自动化其业务操作的过程。查德与朋友一起，将成立新公司的时间从3小时缩短到不到10分钟，大幅提高了效率。他们利用无代码工具，仅用一周时间就打造出了BetterLegal的原型。这个初步的成功标志着BetterLegal的诞生。

BetterLegal的第一个版本使用了各种无代码工具，如Asana、Zapier和Formstack。但随着时间的推移，查德发现这些工具也有局限性，尤其是在自定义功能和成本方面。于是他决定转向定制编码，雇佣自由职业者用定制代码从头开始开发新应用。这个决策支撑了BetterLegal五年的发展，但同时也带来了高昂的开发成本和依赖开发者的风险。

2022年，面对运营成本过高的问题，查德在一个30天构建挑战中尝试了Bubble平台，并从中获得了灵感。他利用Bubble重建了BetterLegal，将整个系统建立在这个平台上，并整合了Zapier、Make和Twilio等工具，以降低成本并提高效率。此外，他还用Bubble内部工具替换了之前需要订阅的第三方应用，如Asana和Twilio Flex，进一步节约了费用。

在激烈的法律科技市场竞争中，查德坚信无代码是他们的巨大竞争优势。通过智能地使用技术，BetterLegal不需要太多员工，从而降低了成本，提高了流程灵活性。借助无代码的速度，他们能够以更低的价格为客户提供更好的产品和服务。

经过多年的努力，BetterLegal不仅实现了100万美元的年度复发收入，还达到了250万美元的总收入。最近，他们又推出了一款由人工智能驱动的合同分析工具，帮助用户理解他们签署的合同。查德的故事证明了，通过不断学习和适应，即使在资源有限的情况下，也能在竞争激烈的市场中取得成功。

文章来源：https://www.indiehackers.com/post/a-2-5-million-revenue-startup-built-with-no-code-f18f03b2a7</title>
            <link>https://nitter.cz/Yangyixxxx/status/1743123960559235121#m</link>
            <guid isPermaLink="false">https://nitter.cz/Yangyixxxx/status/1743123960559235121#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 04:15:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>分享一个独立开发者故事：利用无代码，构建2.5millon收益的创业项目<br />
<br />
在一个平凡的小镇，住着一个年轻的创业者，查德·萨康奇克。他的早期创业之路充满了挑战：他白天帮朋友的公司安装维护化粪池，夜晚则在父母家的卧室与海外开发者沟通，努力推进自己的项目。<br />
<br />
查德先后创建了几个初创公司，包括一个网站创建平台、一个面向食品车主的应用和一个活动空间平台。他投入了大量资金雇佣开发人员，却发现编码工作耗时耗力，且很难说服人们使用他的应用。这些经历让他意识到，必须有更好的方式来开展业务。<br />
<br />
灵感来自于帮助一位律师朋友自动化其业务操作的过程。查德与朋友一起，将成立新公司的时间从3小时缩短到不到10分钟，大幅提高了效率。他们利用无代码工具，仅用一周时间就打造出了BetterLegal的原型。这个初步的成功标志着BetterLegal的诞生。<br />
<br />
BetterLegal的第一个版本使用了各种无代码工具，如Asana、Zapier和Formstack。但随着时间的推移，查德发现这些工具也有局限性，尤其是在自定义功能和成本方面。于是他决定转向定制编码，雇佣自由职业者用定制代码从头开始开发新应用。这个决策支撑了BetterLegal五年的发展，但同时也带来了高昂的开发成本和依赖开发者的风险。<br />
<br />
2022年，面对运营成本过高的问题，查德在一个30天构建挑战中尝试了Bubble平台，并从中获得了灵感。他利用Bubble重建了BetterLegal，将整个系统建立在这个平台上，并整合了Zapier、Make和Twilio等工具，以降低成本并提高效率。此外，他还用Bubble内部工具替换了之前需要订阅的第三方应用，如Asana和Twilio Flex，进一步节约了费用。<br />
<br />
在激烈的法律科技市场竞争中，查德坚信无代码是他们的巨大竞争优势。通过智能地使用技术，BetterLegal不需要太多员工，从而降低了成本，提高了流程灵活性。借助无代码的速度，他们能够以更低的价格为客户提供更好的产品和服务。<br />
<br />
经过多年的努力，BetterLegal不仅实现了100万美元的年度复发收入，还达到了250万美元的总收入。最近，他们又推出了一款由人工智能驱动的合同分析工具，帮助用户理解他们签署的合同。查德的故事证明了，通过不断学习和适应，即使在资源有限的情况下，也能在竞争激烈的市场中取得成功。<br />
<br />
文章来源：<a href="https://www.indiehackers.com/post/a-2-5-million-revenue-startup-built-with-no-code-f18f03b2a7">indiehackers.com/post/a-2-5-…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/raycat2021/status/1743053991418945654#m</id>
            <title>RT by @dotey: 一点进展：中学大学同学们开始组织起来出手帮忙，这就好了。</title>
            <link>https://nitter.cz/raycat2021/status/1743053991418945654#m</link>
            <guid isPermaLink="false">https://nitter.cz/raycat2021/status/1743053991418945654#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 23:37:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一点进展：中学大学同学们开始组织起来出手帮忙，这就好了。</p>
<p><a href="https://nitter.cz/raycat2021/status/1742510277449703680#m">nitter.cz/raycat2021/status/1742510277449703680#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDU1hVUGFrQUFOdnp3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDU1hVa2FnQUVZeERKLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDU1hWYmFrQUVyZk4tLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743096092609147238#m</id>
            <title>R to @dotey: 工作原理</title>
            <link>https://nitter.cz/dotey/status/1743096092609147238#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743096092609147238#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 02:24:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>工作原理</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDNGhEVFdrQUFHYTgyLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDNHA4YVhRQUFVLVRELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/ruanyf/status/1743080828786425994#m</id>
            <title>RT by @dotey: 贝佐斯最近上了 Lex Fridman 的播客，接受了两个小时的专访。

有一段对话很有意思，主持人问：“听说你们开会不许用 PPT，而是提交六页的备忘录？”

贝佐斯亲口承认此事，然后谈了禁止使用 PPT 的五点理由。我觉得他说的很有道理，就整理了出来。#科技爱好者周刊（第285期）https://www.ruanyifeng.com/blog/2024/01/weekly-issue-285.html</title>
            <link>https://nitter.cz/ruanyf/status/1743080828786425994#m</link>
            <guid isPermaLink="false">https://nitter.cz/ruanyf/status/1743080828786425994#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 01:23:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>贝佐斯最近上了 Lex Fridman 的播客，接受了两个小时的专访。<br />
<br />
有一段对话很有意思，主持人问：“听说你们开会不许用 PPT，而是提交六页的备忘录？”<br />
<br />
贝佐斯亲口承认此事，然后谈了禁止使用 PPT 的五点理由。我觉得他说的很有道理，就整理了出来。<a href="https://nitter.cz/search?q=%23科技爱好者周刊">#科技爱好者周刊</a>（第285期）<a href="https://www.ruanyifeng.com/blog/2024/01/weekly-issue-285.html">ruanyifeng.com/blog/2024/01/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDcXQtX2FJQUFEUENGLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDcXZMcWFjQUFtYjNhLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743094484357837136#m</id>
            <title>Alter3：一个能够执行 ChatGPT 指令的仿人机器人

东京大学的研究人员成功将仿人机器人 Alter3 与 GPT-4 连接。他们利用指令让这个机器人完成了一系列的人类行为，例如弹吉他、自拍、扮演鬼魂角色，甚至在电影院偷吃别人的爆米花。

这一过程可以看作是一场现代化的“哑剧游戏”：大语言模型 (Large Language Model) 将书面指令转换为可执行的代码，从而让机器人能够模仿出多种人类的动作。

项目地址：https://tnoinkwms.github.io/ALTER-LLM/</title>
            <link>https://nitter.cz/dotey/status/1743094484357837136#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743094484357837136#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 02:18:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Alter3：一个能够执行 ChatGPT 指令的仿人机器人<br />
<br />
东京大学的研究人员成功将仿人机器人 Alter3 与 GPT-4 连接。他们利用指令让这个机器人完成了一系列的人类行为，例如弹吉他、自拍、扮演鬼魂角色，甚至在电影院偷吃别人的爆米花。<br />
<br />
这一过程可以看作是一场现代化的“哑剧游戏”：大语言模型 (Large Language Model) 将书面指令转换为可执行的代码，从而让机器人能够模仿出多种人类的动作。<br />
<br />
项目地址：<a href="https://tnoinkwms.github.io/ALTER-LLM/">tnoinkwms.github.io/ALTER-LL…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDMwOTQzNTQxNTgyMjMzNjAvcHUvaW1nL2EyY3RKd3FGTV9hQ2tKcGcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1743041592712167540#m</id>
            <title>这个绿幕技巧不错</title>
            <link>https://nitter.cz/dotey/status/1743041592712167540#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1743041592712167540#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 22:47:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个绿幕技巧不错</p>
<p><a href="https://nitter.cz/hugovntr/status/1742968850444894217#m">nitter.cz/hugovntr/status/1742968850444894217#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mtrainier2020/status/1743011913980850633#m</id>
            <title>RT by @dotey: 嗯。研究了一下tiktok shop。在这过去的一年内，真的改进非常非常非常大，从原来业务流程都磕磕碰碰，到现在已经开始成型的生态，今年必须要玩玩tiktok了。

另外分享一个码农们挣外快的机会。https://partner.tiktokshop.com/docv2
建议研读tiktok shop的api，做一些me too就能挣钱。
我自己暂时可能不会去做这块的应用所以我愿意分享出来。至于哪些可以做的，就看每个人自己的理解了。</title>
            <link>https://nitter.cz/mtrainier2020/status/1743011913980850633#m</link>
            <guid isPermaLink="false">https://nitter.cz/mtrainier2020/status/1743011913980850633#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 20:49:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>嗯。研究了一下tiktok shop。在这过去的一年内，真的改进非常非常非常大，从原来业务流程都磕磕碰碰，到现在已经开始成型的生态，今年必须要玩玩tiktok了。<br />
<br />
另外分享一个码农们挣外快的机会。<a href="https://partner.tiktokshop.com/docv2">partner.tiktokshop.com/docv2</a><br />
建议研读tiktok shop的api，做一些me too就能挣钱。<br />
我自己暂时可能不会去做这块的应用所以我愿意分享出来。至于哪些可以做的，就看每个人自己的理解了。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/mtrainier2020/status/1742979646864646550#m</id>
            <title>RT by @dotey: 其实这种方法说起来也很简单，我经常拿来去查一些公司的真实情况。比如有的公司曾经吹的非常厉害。我只要查数据，我就知道他厂家在哪里，到底销量怎么样，到底盈利状况怎么样，到底掺了多少水。很多数据你是很难隐藏的。
当然聪明的公司，会做好隐藏。他会这么做，本土供应商—本土proxy -境外proxy -境外销售商。你看到的只是proxy对proxy，这就很难溯源对方的供应链，但是能估算其规模。 但是你很难保证他只有一个proxy。等等。这也是一个攻防。</title>
            <link>https://nitter.cz/mtrainier2020/status/1742979646864646550#m</link>
            <guid isPermaLink="false">https://nitter.cz/mtrainier2020/status/1742979646864646550#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 18:41:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>其实这种方法说起来也很简单，我经常拿来去查一些公司的真实情况。比如有的公司曾经吹的非常厉害。我只要查数据，我就知道他厂家在哪里，到底销量怎么样，到底盈利状况怎么样，到底掺了多少水。很多数据你是很难隐藏的。<br />
当然聪明的公司，会做好隐藏。他会这么做，本土供应商—本土proxy -境外proxy -境外销售商。你看到的只是proxy对proxy，这就很难溯源对方的供应链，但是能估算其规模。 但是你很难保证他只有一个proxy。等等。这也是一个攻防。</p>
<p><a href="https://nitter.cz/mtrainier2020/status/1742975445736513636#m">nitter.cz/mtrainier2020/status/1742975445736513636#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1742988095631597917#m</id>
            <title>新的Mobile ALOHA演示视频，它可以做到：

洗衣服👔👖
自己充电⚡️
用吸尘器洗地
给植物浇水🌳
将碗放到洗碗机或者拿出来
用咖啡机冲咖啡☕️
从冰箱里取出饮料，开瓶啤酒🍺
开门🚪
陪宠物玩🐱
扔垃圾
开关灯💡</title>
            <link>https://nitter.cz/dotey/status/1742988095631597917#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1742988095631597917#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 19:15:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>新的Mobile ALOHA演示视频，它可以做到：<br />
<br />
洗衣服👔👖<br />
自己充电⚡️<br />
用吸尘器洗地<br />
给植物浇水🌳<br />
将碗放到洗碗机或者拿出来<br />
用咖啡机冲咖啡☕️<br />
从冰箱里取出饮料，开瓶啤酒🍺<br />
开门🚪<br />
陪宠物玩🐱<br />
扔垃圾<br />
开关灯💡</p>
<p><a href="https://nitter.cz/zipengfu/status/1742973258528612724#m">nitter.cz/zipengfu/status/1742973258528612724#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Rey100001/status/1698208045460001054#m</id>
            <title>RT by @dotey: 我们这一代人的机会是什么？

1998年前后，搜狐新浪网易、BAT相继成立，中国互联网时代开启，伴随而来的还有风险投资；

1998年事业单位停止福利分房，开启房地产市场化时代；

1998年亚洲金融危机，中国增发特别国债加强基建，开始大规模基础设施建设时代，拉动经济增长的第一辆马车开启；

2001年中国加入世贸组织，开启大出口时代，拉动经济的第二辆马车开启；

这四匹马奔跑了二十年，造就了3亿中产阶级，上千万的富豪，无数的创业机会，梦想是这个时代的主旋律，2010~2020这十年更是人类历史上最繁荣的十年，没有非典与新冠，也没有伊拉克战争与俄乌战争，全球化越来越紧密，移动互联网吞噬一切，中国的房地产以每年20%的速度在增值。

但是今天，互联网不增长了、伴随的VC没地方投钱了、甚至由于中美贸易战，美国VC的钱都撤走了，房子卖不动了、该建设的基建都建设完了、出口也被G7制裁了，这四匹马都瘸了。至于消费这匹马，没有前面这四匹马赚钱，口袋空瘪瘪的，未来预期也不可控，谁还敢消费呢？

这就是我们这一代人的时代背景，我们不禁要问，我们这一代人的机会在哪里？特别是年轻人的机会在哪里？因为年轻人还不能躺平，也没有资本躺平呀。我分析了一些机会点：

1、短视频依然有红利，但那不属于产品人

2020年的短视频会像2010年的移动互联网一样吞噬一切，只要一个领域还没有知名的IP，那个领域就还有机会，说明机会窗口还没有关闭，比如我要在海外办公司，其实我并不知道找谁，因为我不知道谁靠谱，这存在着很大的信息差，我需要一个可信任的人操办这些事情，如果你的短视频能做到让我认识你，我的订单就是你的；再比如我要买保险，我也不知道应该信任谁。比起一个机构，我们更愿意相信一个活生生的人，这是IP的独特价值，如果你有做IP的能力，短视频是一个好的选择。

不过，短视频全是流量运营的事情，里面没有做产品、做技术的机会，2021年我们在抖音做MCN的时候就发现了这一点。现在抖音上唯一可以产品化的就是数据参谋类产品，比如蝉妈妈、考古加。

2、生物科技是硬核科学，也不存在产品定义的机会

都说21世纪是生物科技的时代，我认为是对的，其一是刚需，健康与排除孤独，是人类一直追求，但一直都没有办法解决的问题；其二是AI、大数据与生物科技的结合，提供了一条新的解题路径，很多生物问题可以“计算”出来。

但是，生物科技是硬核科学，他需要的是技术，不是产品定义的能力，产品经理的能力模型跟苹果公司类似，从来不发明任何新技术，只根据用户需求整合需要的技术。

当一个领域在比拼技术的时候，更需要的还是数学家、科学家、工程师，而不是产品经理，我们能把产品做得更高效、更简单、价格更低、体验更好，但我们没有办法将语音识别率从97%提升到99%，将OCR的能力从99.0%提升到99.7%，生物科技同理。

3、如果你不做AI，可能就真的没有机会了

提交YC的项目，70%已经与AI相关，这反映了全球创业的趋势。这还是要回归到用户需求，1994年是世界互联网的元年，2011年是移动互联网的元年，这么多年过去了，该被满足的需求都被满足得差不多了。在未来的日子里，非AI的领域，可能只有社交与游戏还能产生千万DAU、百万DAU的可能性，其他领域都不太可能了。

AI对我们来说，只是一种工具，区块链也是工具，技术其实都是工具，我们武器库里的工具越多，我们解决某个问题就越彻底，可能很多以前没有办法解决的问题，通过AI就能解决得很好，比如妙鸭相机，他是通过AI解决海马体拍证件照很麻烦、价格很贵的问题，如果没有AI，这个问题是解决不了的。

AI的技术已经可用了，目前需要的是洞察，看一些以前没有AI的时候，没法解决的问题，现在能不能通过AI解决，能不能解决得更好。

4、做一个5人小团队，永远都有机会

做小而美的事情，永远都是有机会的，放弃过去的宏大叙事，回归个体户的思维，找到一个极度细分的领域做好、做精、能守得住，当营收多一些，能Cover多一个人工资的时候，那就多增加一个人，不行的时候，就裁掉一个人，永远保持精干的小团队。

优势永远都是一点一滴积累的，打磨一个小而美的产品永远不是一件简单的事情，这样的事情是不会有VC支持的，这就意味着要靠自己，自负盈亏，这就需要你极度有耐心，要做好3年、5年没有正向收入的可能性，最好还是先业余做，等看到希望以后再辞职全力去做，这样的路径是最顺畅的。

5、出海，到竞争还不充分的地方去

“未来已来，只是空间分布不均匀”，美国、中国、其他地方，这是不同的世界，地区与地区之间存在着时间差，移动互联网在中美竞争很充分，但不意味着世界其他地方竞争也很充分，这里就是机会。

我的选择是什么，5＞3＞4。</title>
            <link>https://nitter.cz/Rey100001/status/1698208045460001054#m</link>
            <guid isPermaLink="false">https://nitter.cz/Rey100001/status/1698208045460001054#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 03 Sep 2023 05:35:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我们这一代人的机会是什么？<br />
<br />
1998年前后，搜狐新浪网易、BAT相继成立，中国互联网时代开启，伴随而来的还有风险投资；<br />
<br />
1998年事业单位停止福利分房，开启房地产市场化时代；<br />
<br />
1998年亚洲金融危机，中国增发特别国债加强基建，开始大规模基础设施建设时代，拉动经济增长的第一辆马车开启；<br />
<br />
2001年中国加入世贸组织，开启大出口时代，拉动经济的第二辆马车开启；<br />
<br />
这四匹马奔跑了二十年，造就了3亿中产阶级，上千万的富豪，无数的创业机会，梦想是这个时代的主旋律，2010~2020这十年更是人类历史上最繁荣的十年，没有非典与新冠，也没有伊拉克战争与俄乌战争，全球化越来越紧密，移动互联网吞噬一切，中国的房地产以每年20%的速度在增值。<br />
<br />
但是今天，互联网不增长了、伴随的VC没地方投钱了、甚至由于中美贸易战，美国VC的钱都撤走了，房子卖不动了、该建设的基建都建设完了、出口也被G7制裁了，这四匹马都瘸了。至于消费这匹马，没有前面这四匹马赚钱，口袋空瘪瘪的，未来预期也不可控，谁还敢消费呢？<br />
<br />
这就是我们这一代人的时代背景，我们不禁要问，我们这一代人的机会在哪里？特别是年轻人的机会在哪里？因为年轻人还不能躺平，也没有资本躺平呀。我分析了一些机会点：<br />
<br />
1、短视频依然有红利，但那不属于产品人<br />
<br />
2020年的短视频会像2010年的移动互联网一样吞噬一切，只要一个领域还没有知名的IP，那个领域就还有机会，说明机会窗口还没有关闭，比如我要在海外办公司，其实我并不知道找谁，因为我不知道谁靠谱，这存在着很大的信息差，我需要一个可信任的人操办这些事情，如果你的短视频能做到让我认识你，我的订单就是你的；再比如我要买保险，我也不知道应该信任谁。比起一个机构，我们更愿意相信一个活生生的人，这是IP的独特价值，如果你有做IP的能力，短视频是一个好的选择。<br />
<br />
不过，短视频全是流量运营的事情，里面没有做产品、做技术的机会，2021年我们在抖音做MCN的时候就发现了这一点。现在抖音上唯一可以产品化的就是数据参谋类产品，比如蝉妈妈、考古加。<br />
<br />
2、生物科技是硬核科学，也不存在产品定义的机会<br />
<br />
都说21世纪是生物科技的时代，我认为是对的，其一是刚需，健康与排除孤独，是人类一直追求，但一直都没有办法解决的问题；其二是AI、大数据与生物科技的结合，提供了一条新的解题路径，很多生物问题可以“计算”出来。<br />
<br />
但是，生物科技是硬核科学，他需要的是技术，不是产品定义的能力，产品经理的能力模型跟苹果公司类似，从来不发明任何新技术，只根据用户需求整合需要的技术。<br />
<br />
当一个领域在比拼技术的时候，更需要的还是数学家、科学家、工程师，而不是产品经理，我们能把产品做得更高效、更简单、价格更低、体验更好，但我们没有办法将语音识别率从97%提升到99%，将OCR的能力从99.0%提升到99.7%，生物科技同理。<br />
<br />
3、如果你不做AI，可能就真的没有机会了<br />
<br />
提交YC的项目，70%已经与AI相关，这反映了全球创业的趋势。这还是要回归到用户需求，1994年是世界互联网的元年，2011年是移动互联网的元年，这么多年过去了，该被满足的需求都被满足得差不多了。在未来的日子里，非AI的领域，可能只有社交与游戏还能产生千万DAU、百万DAU的可能性，其他领域都不太可能了。<br />
<br />
AI对我们来说，只是一种工具，区块链也是工具，技术其实都是工具，我们武器库里的工具越多，我们解决某个问题就越彻底，可能很多以前没有办法解决的问题，通过AI就能解决得很好，比如妙鸭相机，他是通过AI解决海马体拍证件照很麻烦、价格很贵的问题，如果没有AI，这个问题是解决不了的。<br />
<br />
AI的技术已经可用了，目前需要的是洞察，看一些以前没有AI的时候，没法解决的问题，现在能不能通过AI解决，能不能解决得更好。<br />
<br />
4、做一个5人小团队，永远都有机会<br />
<br />
做小而美的事情，永远都是有机会的，放弃过去的宏大叙事，回归个体户的思维，找到一个极度细分的领域做好、做精、能守得住，当营收多一些，能Cover多一个人工资的时候，那就多增加一个人，不行的时候，就裁掉一个人，永远保持精干的小团队。<br />
<br />
优势永远都是一点一滴积累的，打磨一个小而美的产品永远不是一件简单的事情，这样的事情是不会有VC支持的，这就意味着要靠自己，自负盈亏，这就需要你极度有耐心，要做好3年、5年没有正向收入的可能性，最好还是先业余做，等看到希望以后再辞职全力去做，这样的路径是最顺畅的。<br />
<br />
5、出海，到竞争还不充分的地方去<br />
<br />
“未来已来，只是空间分布不均匀”，美国、中国、其他地方，这是不同的世界，地区与地区之间存在着时间差，移动互联网在中美竞争很充分，但不意味着世界其他地方竞争也很充分，这里就是机会。<br />
<br />
我的选择是什么，5＞3＞4。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRjVFX05YZmJJQUFvVi05LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>