<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735919965822235043#m</id>
            <title>😲</title>
            <link>https://nitter.cz/dotey/status/1735919965822235043#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735919965822235043#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 07:09:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>😲</p>
<p><a href="https://nitter.cz/WutalkWu/status/1735918653164675505#m">nitter.cz/WutalkWu/status/1735918653164675505#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735878580943335679#m</id>
            <title>字节跳动秘密使用 OpenAI 技术打造竞争产品

“他们只是不想暴露行踪。” 在激烈的生成式 AI 竞赛中，连业界巨头也在寻找捷径。

TikTok 的“为你推荐”功能魅力无比，使得其母公司字节跳动在全球范围内站在了 AI 领导者的位置。然而，现在这家公司在生成式 AI 竞赛中的表现却距离领先有一大段距离，以至于它不得不秘密地运用 OpenAI 的技术，以开发出自家的大语言模型，以此来与市场上的其他大语言模型竞争。

在 AI 界，这样的做法备受非议。这还直接违反了 OpenAI 的服务条款中的一项规定，即禁止将其模型的输出用来“开发与我们的产品和服务有竞争关系的任何人工智能模型。” 字节跳动是通过购买 Microsoft 的 OpenAI 使用权来使用 OpenAI 的，但 Microsoft 也有着同样的规定。尽管如此，字节跳动在与我分享的内部文件中确认，他们有依赖 OpenAI API 在开发其基础大语言模型的各个阶段，包括训练和评估模型，这个模型被代号为 Project Seed。

涉及此事的员工深知其后果；我在字节跳动的内部沟通平台 Lark 上看到了他们讨论如何通过“数据脱敏”来掩盖这一行为的对话。这种滥用程度如此严重，以至于 Project Seed 的员工经常达到他们 API 使用的上限。

在 OpenAI 平台的早期阶段，Project Seed 计划的使用更为大胆。几个月前，字节跳动命令其团队停止在模型开发的任何阶段使用 GPT 生成的文本，这一指示来自内部文件。就在这个时期，该公司在中国获得了监管批准，通过一个叫做 Doubao 的聊天机器人平台发布 Project Seed。

然而，据我了解，这个 API 依旧在违反 OpenAI 和 Microsoft 的服务条款中被使用，其中包括评估字节跳动在 Doubao 背后的模型性能。一位对字节跳动内部情况有直接了解的人表示：“他们声称要确保一切合法，但实际上他们只是不想被发现。”

对于本故事中提及的详细事实，字节跳动的发言人 Jodi Seth 表示，在 Project Seed 的初期开发中，确实使用了 GPT 生成的数据来标注模型，并在今年中期左右将其从训练数据中移除。“字节跳动得到了 Microsoft 的授权，可以使用 GPT API，”她在声明中说。“我们在非中国市场利用 GPT 支持我们的产品和特性，但在中国市场，则是使用我们自研的模型来支持 Doubao。”

“像 Azure OpenAI 服务这样的 Microsoft AI 解决方案属于我们的有限访问框架的一部分，意味着所有客户都必须申请并得到 Microsoft 的批准，”Microsoft 的发言人 Frank Shaw 在一份声明中说。“我们还制定了标准，并提供资源帮助客户负责任地使用这些技术，并符合我们的服务条款。我们有流程来检测滥用，并在发现违反行为准则的公司时，将停止他们的访问权限。”

更新 12月15日，下午6:40东部时间: 在这篇报道发布后，OpenAI 的发言人 Niko Felix 向我确认，字节跳动的账户已被暂停使用：“所有使用我们 API 的客户必须遵守我们的使用政策，确保技术被用于正当目的。尽管字节跳动对我们的 API 使用很少，但我们正在进一步调查期间已暂停他们的账户。如果我们发现他们的使用不符合这些政策，我们将要求他们进行必要的调整，或终止他们的账户。”

虽然鲜少公开讨论，但小型公司普遍利用专有的人工智能模型，尤其是 OpenAI 的模型，来开发与之竞争的产品。由于 OpenAI 和 Microsoft 还没有以某个违规案例为鉴，这种做法目前仍处于法律上的灰色地带。“许多初创企业现在都在冒这个风险，”Databricks 的生成式 AI 副总裁 Naveen Rao 表示。

不过，从我在采访中了解到的情况来看，像 ByteDance 这样规模和资源雄厚的公司采取这种行为是极为罕见的。这似乎表明 Project Seed 团队面临着巨大的压力，必须迅速交付成果。“我经常收到 ByteDance 发来的招聘邮件，”一位在美国大型科技公司的 AI 研究员说，“我通常不予理会。但这件事让我想把这些邮件直接标为垃圾邮件。”

其他公司也遇到了类似的问题，担心自己的 GPT 输出被用来发展竞争对手。比如，Google 有研究员因为一些同事试图利用包含 ChatGPT 对话内容的网站数据而选择辞职。这一事件并未涉及滥用 OpenAI 的 API，但在内部引起了不小的尴尬，涉事员工也受到了轻微的惩戒。

自从大约一年前 ByteDance 启动了 Project Seed，这个项目就成了一个高优先级且高度保密的任务。参与其中的员工需要签署特别的保密协议，项目内部的信息获取也变得愈发隔离。ByteDance 的亿万富翁联合创始人、前 CEO 张一鸣 密切关注项目的进展。

Project Seed 目前主要研发两个产品：Doubao，这是一个已在中国上线的消费者聊天机器人平台（似乎在国外也可以访问）；另一个是针对商业用户的聊天机器人平台，目前正在开发中，计划通过 ByteDance 的云服务部门销售。

虽然告知员工 Project Seed 的目标是为了像 OpenAI 那样，最终发展出通用人工智能（AGI），但其实质目标似乎更倾向于尽快成为中国版的 ChatGPT。该项目团队已被指令在今年年底之前实现与 GPT-3.5 相同的性能，并在 2024 年年中前达到 GPT-4 的水平。目前 Seed 模型的参数大约为 2000 亿，而 GPT-3.5 的参数为 1750 亿。（OpenAI 尚未公布 GPT-4 的参数数量。）

目前，Project Seed 与 TikTok 没有关联，主要在中国服务器上进行开发。团队成员大多位于中国，但也有驻美国的成员。项目的主导者是字节跳动搜索部门负责人 Zhu Wenjia，他向公司高级工程领导 Yang Zhenyuan 汇报工作。项目的其他关键领导人包括 Qiao Mu（隶属于 Wenjia）和负责应用机器学习团队的 Xiang Liang。

据我所知，OpenAI 正在研究如何识别其 API 输出以预防潜在的误用问题，但看来问题已经显露。目前还不清楚 ByteDance 的此类行为是否会加剧美中两国之间已经存在的紧张局势，两国都将 AI 视为国家安全的重要议题。

另一个引人关注的问题是，当大量的大语言模型（LLM）开始参与构建其他 LLM 时，网络信息质量会发生何种变化。由于这些基础模型本身就是在非真实、人工制造的数据上训练的，用它们来构建更多 LLM 可能会进一步放大错误信息的传播。正如 Databricks 的 Rao 向我表述的那样：“这最终可能导致我们与现实世界的脱节。”

https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm</title>
            <link>https://nitter.cz/dotey/status/1735878580943335679#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735878580943335679#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 04:24:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>字节跳动秘密使用 OpenAI 技术打造竞争产品<br />
<br />
“他们只是不想暴露行踪。” 在激烈的生成式 AI 竞赛中，连业界巨头也在寻找捷径。<br />
<br />
TikTok 的“为你推荐”功能魅力无比，使得其母公司字节跳动在全球范围内站在了 AI 领导者的位置。然而，现在这家公司在生成式 AI 竞赛中的表现却距离领先有一大段距离，以至于它不得不秘密地运用 OpenAI 的技术，以开发出自家的大语言模型，以此来与市场上的其他大语言模型竞争。<br />
<br />
在 AI 界，这样的做法备受非议。这还直接违反了 OpenAI 的服务条款中的一项规定，即禁止将其模型的输出用来“开发与我们的产品和服务有竞争关系的任何人工智能模型。” 字节跳动是通过购买 Microsoft 的 OpenAI 使用权来使用 OpenAI 的，但 Microsoft 也有着同样的规定。尽管如此，字节跳动在与我分享的内部文件中确认，他们有依赖 OpenAI API 在开发其基础大语言模型的各个阶段，包括训练和评估模型，这个模型被代号为 Project Seed。<br />
<br />
涉及此事的员工深知其后果；我在字节跳动的内部沟通平台 Lark 上看到了他们讨论如何通过“数据脱敏”来掩盖这一行为的对话。这种滥用程度如此严重，以至于 Project Seed 的员工经常达到他们 API 使用的上限。<br />
<br />
在 OpenAI 平台的早期阶段，Project Seed 计划的使用更为大胆。几个月前，字节跳动命令其团队停止在模型开发的任何阶段使用 GPT 生成的文本，这一指示来自内部文件。就在这个时期，该公司在中国获得了监管批准，通过一个叫做 Doubao 的聊天机器人平台发布 Project Seed。<br />
<br />
然而，据我了解，这个 API 依旧在违反 OpenAI 和 Microsoft 的服务条款中被使用，其中包括评估字节跳动在 Doubao 背后的模型性能。一位对字节跳动内部情况有直接了解的人表示：“他们声称要确保一切合法，但实际上他们只是不想被发现。”<br />
<br />
对于本故事中提及的详细事实，字节跳动的发言人 Jodi Seth 表示，在 Project Seed 的初期开发中，确实使用了 GPT 生成的数据来标注模型，并在今年中期左右将其从训练数据中移除。“字节跳动得到了 Microsoft 的授权，可以使用 GPT API，”她在声明中说。“我们在非中国市场利用 GPT 支持我们的产品和特性，但在中国市场，则是使用我们自研的模型来支持 Doubao。”<br />
<br />
“像 Azure OpenAI 服务这样的 Microsoft AI 解决方案属于我们的有限访问框架的一部分，意味着所有客户都必须申请并得到 Microsoft 的批准，”Microsoft 的发言人 Frank Shaw 在一份声明中说。“我们还制定了标准，并提供资源帮助客户负责任地使用这些技术，并符合我们的服务条款。我们有流程来检测滥用，并在发现违反行为准则的公司时，将停止他们的访问权限。”<br />
<br />
更新 12月15日，下午6:40东部时间: 在这篇报道发布后，OpenAI 的发言人 Niko Felix 向我确认，字节跳动的账户已被暂停使用：“所有使用我们 API 的客户必须遵守我们的使用政策，确保技术被用于正当目的。尽管字节跳动对我们的 API 使用很少，但我们正在进一步调查期间已暂停他们的账户。如果我们发现他们的使用不符合这些政策，我们将要求他们进行必要的调整，或终止他们的账户。”<br />
<br />
虽然鲜少公开讨论，但小型公司普遍利用专有的人工智能模型，尤其是 OpenAI 的模型，来开发与之竞争的产品。由于 OpenAI 和 Microsoft 还没有以某个违规案例为鉴，这种做法目前仍处于法律上的灰色地带。“许多初创企业现在都在冒这个风险，”Databricks 的生成式 AI 副总裁 Naveen Rao 表示。<br />
<br />
不过，从我在采访中了解到的情况来看，像 ByteDance 这样规模和资源雄厚的公司采取这种行为是极为罕见的。这似乎表明 Project Seed 团队面临着巨大的压力，必须迅速交付成果。“我经常收到 ByteDance 发来的招聘邮件，”一位在美国大型科技公司的 AI 研究员说，“我通常不予理会。但这件事让我想把这些邮件直接标为垃圾邮件。”<br />
<br />
其他公司也遇到了类似的问题，担心自己的 GPT 输出被用来发展竞争对手。比如，Google 有研究员因为一些同事试图利用包含 ChatGPT 对话内容的网站数据而选择辞职。这一事件并未涉及滥用 OpenAI 的 API，但在内部引起了不小的尴尬，涉事员工也受到了轻微的惩戒。<br />
<br />
自从大约一年前 ByteDance 启动了 Project Seed，这个项目就成了一个高优先级且高度保密的任务。参与其中的员工需要签署特别的保密协议，项目内部的信息获取也变得愈发隔离。ByteDance 的亿万富翁联合创始人、前 CEO 张一鸣 密切关注项目的进展。<br />
<br />
Project Seed 目前主要研发两个产品：Doubao，这是一个已在中国上线的消费者聊天机器人平台（似乎在国外也可以访问）；另一个是针对商业用户的聊天机器人平台，目前正在开发中，计划通过 ByteDance 的云服务部门销售。<br />
<br />
虽然告知员工 Project Seed 的目标是为了像 OpenAI 那样，最终发展出通用人工智能（AGI），但其实质目标似乎更倾向于尽快成为中国版的 ChatGPT。该项目团队已被指令在今年年底之前实现与 GPT-3.5 相同的性能，并在 2024 年年中前达到 GPT-4 的水平。目前 Seed 模型的参数大约为 2000 亿，而 GPT-3.5 的参数为 1750 亿。（OpenAI 尚未公布 GPT-4 的参数数量。）<br />
<br />
目前，Project Seed 与 TikTok 没有关联，主要在中国服务器上进行开发。团队成员大多位于中国，但也有驻美国的成员。项目的主导者是字节跳动搜索部门负责人 Zhu Wenjia，他向公司高级工程领导 Yang Zhenyuan 汇报工作。项目的其他关键领导人包括 Qiao Mu（隶属于 Wenjia）和负责应用机器学习团队的 Xiang Liang。<br />
<br />
据我所知，OpenAI 正在研究如何识别其 API 输出以预防潜在的误用问题，但看来问题已经显露。目前还不清楚 ByteDance 的此类行为是否会加剧美中两国之间已经存在的紧张局势，两国都将 AI 视为国家安全的重要议题。<br />
<br />
另一个引人关注的问题是，当大量的大语言模型（LLM）开始参与构建其他 LLM 时，网络信息质量会发生何种变化。由于这些基础模型本身就是在非真实、人工制造的数据上训练的，用它们来构建更多 LLM 可能会进一步放大错误信息的传播。正如 Databricks 的 Rao 向我表述的那样：“这最终可能导致我们与现实世界的脱节。”<br />
<br />
<a href="https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm">theverge.com/2023/12/15/2400…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1735876029552718213#m">nitter.cz/xiaohuggg/status/1735876029552718213#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JjVHdFY1hRQUFSMk9zLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735868760957845761#m</id>
            <title>#开源项目推荐：Halo
一个强大易用的开源建站工具。

https://github.com/halo-dev/halo</title>
            <link>https://nitter.cz/dotey/status/1735868760957845761#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735868760957845761#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 03:45:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23开源项目推荐">#开源项目推荐</a>：Halo<br />
一个强大易用的开源建站工具。<br />
<br />
<a href="https://github.com/halo-dev/halo">github.com/halo-dev/halo</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU4Njg2ODA4NjMzNTA3ODQvcHUvaW1nL1JSMVBUTHlHY21JUW95NmguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/realrenmin/status/1735817231601135720#m</id>
            <title>RT by @dotey: 在闭源超大型模型盛行的时代背景下，微软选择了一条不同的道路，专注于开发“小而美”的oss模型，正如phi和Wizard。

昨天，微软放出开源2.7B的phi-2，效果媲美超过自己25倍参数规模的llama-2 70B。事实上，自phi-1和phi-1.5起，phi系列在过去半年中已迭代了三次。phi的卓越表现源于半年前发表的论文 Textbooks Are All You Need，该论文的核心观点是注重数据的质量。

在探索如何提升数据质量的过程中，作者采用了一种富有哲学意味的方法，即将语言模型训练的过程人性化。比如，在我们学习编程时，如果所用的学习材料缺乏清晰的结构大纲，示例代码频繁调用来源不明的外部模块，或者常量与变量的定义混乱且缺乏实际意义，那么学习效率自然会受到影响。

下图展示了高质量数据vs低质量数据。

当前语言模型在预训练阶段所使用的语料普遍存在一些问题，如高噪声、内容模糊不清以及话题分布的不均匀等。作者针对这些问题，有意识地选择并生成高质量数据，力求让数据集像教科书Textbook一样，具备清晰度、独立性、指导性以及话题上的平衡性。这种方法使得即便是小型模型，也能经过精细训练，在特定任务上达到大型模型的效果。

值得注意的是，phi的训练过程中未采用任何指令微调(instruction finetuning)或强化学习(RLHF)。这意味着phi更像是一个纯粹的文本补全模型。因此，在使用提示（prompt）引导phi时，它可能不会完全按照预期执行，例如不会按指令输出JSON格式。这种特性使得phi更适合作为专家模型，用于特定的下游任务。

在微软的另一条expert model路线，Wizard系列也非常出色。

Wizard模型的核心理念同样也蕴含了深刻的哲学思考，特别是它所引入的“Evol-Instruct”概念，这在很大程度上借鉴了演化论的思想。

具体来说，当人们学会基础的概念，比如“1+1=2”之后，随着时间的推移，他们的思维会经历一种深度（In-Depth）和广度（In-Breadth）的演化过程。例如，他们可能会开始思考“在什么情况下1+1不等于2？”或“在真空中光速是多少？”等更深入或更广泛的问题。这种思维的演化过程正是Wizard模型试图模拟的核心要素。

对于语言模型而言，这种深度（In-Depth）和广度（In-Breadth）的指令演化使得模型能够解放思想、与时俱进，并把握遵循事物发展的客观规律，做到了举一反三。这种能力使得模型能够在学习一个概念后应用到其他相关领域，从而能够遵循更加复杂和多样的指令，完成不同的任务。

基于Evol-Instruct理念，Wizard系列的oss模型在大模型任务的三大核心领域——instruction（WizardLM）、math（WizardMath）和code（WizardCoder），都表现出色。值得一提的是，Wizard系列模型都是通过instruction tuning得到的专家模型，所以，在遵循指令方面表现稳定。

此时，从phi和Wizard的发展来看，微软似乎并没有在闭源大型模型领域投入太多，而是在开源的专家（小型）模型上下了大量功夫。微软专注于从文本补全到推理、数学、编程等细分任务的“小而美”发展。这些工作对于我们构建自己的下游专家模型提供了重要的参考和启示。

Textbooks Are All You Need https://arxiv.org/abs/2306.11644
WizardLM、WizardMathWizardCoder
https://huggingface.co/WizardLM</title>
            <link>https://nitter.cz/realrenmin/status/1735817231601135720#m</link>
            <guid isPermaLink="false">https://nitter.cz/realrenmin/status/1735817231601135720#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 00:20:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在闭源超大型模型盛行的时代背景下，微软选择了一条不同的道路，专注于开发“小而美”的oss模型，正如phi和Wizard。<br />
<br />
昨天，微软放出开源2.7B的phi-2，效果媲美超过自己25倍参数规模的llama-2 70B。事实上，自phi-1和phi-1.5起，phi系列在过去半年中已迭代了三次。phi的卓越表现源于半年前发表的论文 Textbooks Are All You Need，该论文的核心观点是注重数据的质量。<br />
<br />
在探索如何提升数据质量的过程中，作者采用了一种富有哲学意味的方法，即将语言模型训练的过程人性化。比如，在我们学习编程时，如果所用的学习材料缺乏清晰的结构大纲，示例代码频繁调用来源不明的外部模块，或者常量与变量的定义混乱且缺乏实际意义，那么学习效率自然会受到影响。<br />
<br />
下图展示了高质量数据vs低质量数据。<br />
<br />
当前语言模型在预训练阶段所使用的语料普遍存在一些问题，如高噪声、内容模糊不清以及话题分布的不均匀等。作者针对这些问题，有意识地选择并生成高质量数据，力求让数据集像教科书Textbook一样，具备清晰度、独立性、指导性以及话题上的平衡性。这种方法使得即便是小型模型，也能经过精细训练，在特定任务上达到大型模型的效果。<br />
<br />
值得注意的是，phi的训练过程中未采用任何指令微调(instruction finetuning)或强化学习(RLHF)。这意味着phi更像是一个纯粹的文本补全模型。因此，在使用提示（prompt）引导phi时，它可能不会完全按照预期执行，例如不会按指令输出JSON格式。这种特性使得phi更适合作为专家模型，用于特定的下游任务。<br />
<br />
在微软的另一条expert model路线，Wizard系列也非常出色。<br />
<br />
Wizard模型的核心理念同样也蕴含了深刻的哲学思考，特别是它所引入的“Evol-Instruct”概念，这在很大程度上借鉴了演化论的思想。<br />
<br />
具体来说，当人们学会基础的概念，比如“1+1=2”之后，随着时间的推移，他们的思维会经历一种深度（In-Depth）和广度（In-Breadth）的演化过程。例如，他们可能会开始思考“在什么情况下1+1不等于2？”或“在真空中光速是多少？”等更深入或更广泛的问题。这种思维的演化过程正是Wizard模型试图模拟的核心要素。<br />
<br />
对于语言模型而言，这种深度（In-Depth）和广度（In-Breadth）的指令演化使得模型能够解放思想、与时俱进，并把握遵循事物发展的客观规律，做到了举一反三。这种能力使得模型能够在学习一个概念后应用到其他相关领域，从而能够遵循更加复杂和多样的指令，完成不同的任务。<br />
<br />
基于Evol-Instruct理念，Wizard系列的oss模型在大模型任务的三大核心领域——instruction（WizardLM）、math（WizardMath）和code（WizardCoder），都表现出色。值得一提的是，Wizard系列模型都是通过instruction tuning得到的专家模型，所以，在遵循指令方面表现稳定。<br />
<br />
此时，从phi和Wizard的发展来看，微软似乎并没有在闭源大型模型领域投入太多，而是在开源的专家（小型）模型上下了大量功夫。微软专注于从文本补全到推理、数学、编程等细分任务的“小而美”发展。这些工作对于我们构建自己的下游专家模型提供了重要的参考和启示。<br />
<br />
Textbooks Are All You Need <a href="https://arxiv.org/abs/2306.11644">arxiv.org/abs/2306.11644</a><br />
WizardLM、WizardMathWizardCoder<br />
<a href="https://huggingface.co/WizardLM">huggingface.co/WizardLM</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiUU9aMVdzQUE0RWQ5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiU1VHVldvQUFycC03LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiU2VLMVc0QUFTM1dTLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiWEZvUFc0QUFrNktQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/goldengrape/status/1735830881972170963#m</id>
            <title>RT by @dotey: 微软前几天提前给出过示例，用prompt+logprobs+n调出了一个高分医学模型
https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/</title>
            <link>https://nitter.cz/goldengrape/status/1735830881972170963#m</link>
            <guid isPermaLink="false">https://nitter.cz/goldengrape/status/1735830881972170963#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 01:15:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软前几天提前给出过示例，用prompt+logprobs+n调出了一个高分医学模型<br />
<a href="https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/">microsoft.com/en-us/research…</a></p>
<p><a href="https://nitter.cz/dotey/status/1735799522792546517#m">nitter.cz/dotey/status/1735799522792546517#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDc1NjI5NjgwNzg2NjM2OC8weGFhR0xaaj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735736967487459833#m</id>
            <title>RT by @dotey: 还能这样？在跟Chatgpt语音聊天的时候也可以调用DALL-E3</title>
            <link>https://nitter.cz/op7418/status/1735736967487459833#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735736967487459833#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 19:01:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还能这样？在跟Chatgpt语音聊天的时候也可以调用DALL-E3</p>
<p><a href="https://nitter.cz/gopatrik/status/1735479721134313934#m">nitter.cz/gopatrik/status/1735479721134313934#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735803702563291451#m</id>
            <title>R to @dotey: 补充个文档截图</title>
            <link>https://nitter.cz/dotey/status/1735803702563291451#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735803702563291451#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 23:27:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>补充个文档截图</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiUVE5Y1hnQUU4NFNGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735802907390284114#m</id>
            <title>R to @dotey: 还有两个变化也要注意：

functions 参数和 function_call 已经改名字了，分别对应的是 tools 参数和 tool_choice，参数结果似乎没明显变化。</title>
            <link>https://nitter.cz/dotey/status/1735802907390284114#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735802907390284114#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 23:23:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还有两个变化也要注意：<br />
<br />
functions 参数和 function_call 已经改名字了，分别对应的是 tools 参数和 tool_choice，参数结果似乎没明显变化。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiUGh0Vlc0QUVldVBBLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735802381240078497#m</id>
            <title>R to @dotey: 另外还有两个参数我以前没注意到，不确认是不是新增的：

n 参数，可以同时返回多个生成结果。比如有时候你可以一次性生成几个不同的结果，让用户选择一个他们觉得最好的结果。（参考图一）

还有一个就是上次开发者大会说到的 seed 参数，这个类似于用 Stable Diffusion 画图的时候用到的 seed 参数，当你每次传入相同的 seed 和其他相同参数时，每次返回的结果会尽可能的保持一致。</title>
            <link>https://nitter.cz/dotey/status/1735802381240078497#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735802381240078497#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 23:21:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另外还有两个参数我以前没注意到，不确认是不是新增的：<br />
<br />
n 参数，可以同时返回多个生成结果。比如有时候你可以一次性生成几个不同的结果，让用户选择一个他们觉得最好的结果。（参考图一）<br />
<br />
还有一个就是上次开发者大会说到的 seed 参数，这个类似于用 Stable Diffusion 画图的时候用到的 seed 参数，当你每次传入相同的 seed 和其他相同参数时，每次返回的结果会尽可能的保持一致。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiT1hlVVdNQUFIMlRNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735799522792546517#m</id>
            <title>OpenAI 的 Chat Completions API 新增了 logprobs，那么这个参数是做什么用的呢？

我们知道 LLM （大语言模型）是概率模型，会根据 Token 出现的概率来决定下一个 Token，但我们通常是无法知道 LLM 在生成的时候，各个 Token 的概率是什么样的，只能看到最终的结果，所以在调试 Prompt 的时候无法直观的看到 Prompt 和参数的设置对生成结果的影响。

新增的 logprobs 参数，默认是 false 的，如果你设置成 true，那么在返回的结果中，会多一个 logprobs 的项，里面会列出来每一个 Token 在生成时的概率。（参见图一）

但这个只是让你看到一种结果。如果你仔细看文档，还可以看到新增了一个 top_logprobs 参数，需要同时将 logprobs 设置为 true 才能生效，这个参数是一个0-5之间的数字，意味着在返回结果的时候，会同时其他显示在生成时，当时最有可能的候选 Token 有哪些，以及各自的概率是多少。

比如我将 top_logprobs 设置成 5，就可以看到在生成第一个词的时候，最有可能得 5 个 Token 是：“How”、“Hello”、“I”、“Great”和“Thank”。

当第一个词选定“How”后，生成第二个词是最有可能的 5 个词分别是：“ can”，“ may”， “ May”， “ Can”， “dy”。

注意前 4 个前面都有空格，而第 5 个没有空格，也就是每一次的 Token 既可能是个独立的单词也可能和前面的组成一个新的单词，比如第 5 个“dy”就可以和前面的“How”组成一个新词“Howdy”。

不过对于普通开发者来说，感觉并没有太大的用处，只有真正的 Prompt Engineer 才可能会用的上。

也欢迎评论补充：你觉得这两个参数可以有哪些实用的应用场景？</title>
            <link>https://nitter.cz/dotey/status/1735799522792546517#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735799522792546517#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 23:10:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 的 Chat Completions API 新增了 logprobs，那么这个参数是做什么用的呢？<br />
<br />
我们知道 LLM （大语言模型）是概率模型，会根据 Token 出现的概率来决定下一个 Token，但我们通常是无法知道 LLM 在生成的时候，各个 Token 的概率是什么样的，只能看到最终的结果，所以在调试 Prompt 的时候无法直观的看到 Prompt 和参数的设置对生成结果的影响。<br />
<br />
新增的 logprobs 参数，默认是 false 的，如果你设置成 true，那么在返回的结果中，会多一个 logprobs 的项，里面会列出来每一个 Token 在生成时的概率。（参见图一）<br />
<br />
但这个只是让你看到一种结果。如果你仔细看文档，还可以看到新增了一个 top_logprobs 参数，需要同时将 logprobs 设置为 true 才能生效，这个参数是一个0-5之间的数字，意味着在返回结果的时候，会同时其他显示在生成时，当时最有可能的候选 Token 有哪些，以及各自的概率是多少。<br />
<br />
比如我将 top_logprobs 设置成 5，就可以看到在生成第一个词的时候，最有可能得 5 个 Token 是：“How”、“Hello”、“I”、“Great”和“Thank”。<br />
<br />
当第一个词选定“How”后，生成第二个词是最有可能的 5 个词分别是：“ can”，“ may”， “ May”， “ Can”， “dy”。<br />
<br />
注意前 4 个前面都有空格，而第 5 个没有空格，也就是每一次的 Token 既可能是个独立的单词也可能和前面的组成一个新的单词，比如第 5 个“dy”就可以和前面的“How”组成一个新词“Howdy”。<br />
<br />
不过对于普通开发者来说，感觉并没有太大的用处，只有真正的 Prompt Engineer 才可能会用的上。<br />
<br />
也欢迎评论补充：你觉得这两个参数可以有哪些实用的应用场景？</p>
<p><a href="https://nitter.cz/OpenAIDevs/status/1735730662362189872#m">nitter.cz/OpenAIDevs/status/1735730662362189872#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiSXp5eVhVQUk1dUs2LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JiS1B0VldRQUE2Sk5CLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735770125704335647#m</id>
            <title>FunSearch 是 Google DeepMind 最近利用大语言模型在数学领域的一个重大成果，甚至于你能从中看出前不久传闻中的 Q* 的影子，因为它本质上是实现了大语言模型自己提出解决数学问题的方案，并自己去验证解决方案。

它有一个前提条件，就是需要将数学问题描述成计算机代码“函数”，这就是 FunSearch 中“Fun”的由来，也就是“Function”。

图一很清楚的描述了 FunSearch 的工作原理。

FunSearch 主要由几个部分组成：
- 大语言模型：根据现有代码，提出创新性的解决方案，生成新的代码
- 评估器：防止错误或虚构的结果，评估生成的结果，选择最好的结果
- 程序池：保存已经生成好的并且评估器评选的最好的代码

FunSearch 是一个循环迭代的过程。在每一轮中：
1. 系统会从现有程序池选取若干程序，交由 LLM 加工。
2. LLM 在这些程序的基础上进行创新，生成新程序，并自动对它们进行评估。
3. 表现最佳的程序将被重新加入程序池，形成一个自我提升的循环。

借助代码和评估器，FunSearch 就类似于 Alpha Go 的训练那样，实现了一套自动训练优化的机制，让 LLM 提出新的解决方案，持续不断地优化解决方案，最终解决问题。

另外如果你记得 @DrJimFan 他们做过的 GPT-4 自动玩 Minecraft 的 Voyager https://twitter.com/DrJimFan/status/1662115266933972993 （图二），原理也是类似的：把 Minecraft 的操作转换成代码，GPT-4 生成技能代码，生成后去 Minecraft 中执行校验，优秀的技能代码最终保存到技能库。思路惊人的相似。

感觉这个（LLM - 代码 - 验证器）框架以后可以有越来越多的有创新的应用场景！

另外原始文章我翻译了一下：https://baoyu.io/translations/google/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models</title>
            <link>https://nitter.cz/dotey/status/1735770125704335647#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735770125704335647#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 21:13:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>FunSearch 是 Google DeepMind 最近利用大语言模型在数学领域的一个重大成果，甚至于你能从中看出前不久传闻中的 Q* 的影子，因为它本质上是实现了大语言模型自己提出解决数学问题的方案，并自己去验证解决方案。<br />
<br />
它有一个前提条件，就是需要将数学问题描述成计算机代码“函数”，这就是 FunSearch 中“Fun”的由来，也就是“Function”。<br />
<br />
图一很清楚的描述了 FunSearch 的工作原理。<br />
<br />
FunSearch 主要由几个部分组成：<br />
- 大语言模型：根据现有代码，提出创新性的解决方案，生成新的代码<br />
- 评估器：防止错误或虚构的结果，评估生成的结果，选择最好的结果<br />
- 程序池：保存已经生成好的并且评估器评选的最好的代码<br />
<br />
FunSearch 是一个循环迭代的过程。在每一轮中：<br />
1. 系统会从现有程序池选取若干程序，交由 LLM 加工。<br />
2. LLM 在这些程序的基础上进行创新，生成新程序，并自动对它们进行评估。<br />
3. 表现最佳的程序将被重新加入程序池，形成一个自我提升的循环。<br />
<br />
借助代码和评估器，FunSearch 就类似于 Alpha Go 的训练那样，实现了一套自动训练优化的机制，让 LLM 提出新的解决方案，持续不断地优化解决方案，最终解决问题。<br />
<br />
另外如果你记得 <a href="https://nitter.cz/DrJimFan" title="Jim Fan">@DrJimFan</a> 他们做过的 GPT-4 自动玩 Minecraft 的 Voyager <a href="https://nitter.cz/DrJimFan/status/1662115266933972993">nitter.cz/DrJimFan/status/…</a> （图二），原理也是类似的：把 Minecraft 的操作转换成代码，GPT-4 生成技能代码，生成后去 Minecraft 中执行校验，优秀的技能代码最终保存到技能库。思路惊人的相似。<br />
<br />
感觉这个（LLM - 代码 - 验证器）框架以后可以有越来越多的有创新的应用场景！<br />
<br />
另外原始文章我翻译了一下：<a href="https://baoyu.io/translations/google/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models">baoyu.io/translations/google…</a></p>
<p><a href="https://nitter.cz/GoogleDeepMind/status/1735332722208284797#m">nitter.cz/GoogleDeepMind/status/1735332722208284797#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JhczlqN1hNQUFPM1RfLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Jhd1hmY1dRQUVJRTVNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735712550212215061#m</id>
            <title>R to @dotey:</title>
            <link>https://nitter.cz/dotey/status/1735712550212215061#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735712550212215061#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 17:24:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<p><a href="https://nitter.cz/goocarlos/status/1729210688017760324#m">nitter.cz/goocarlos/status/1729210688017760324#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735705912008954024#m</id>
            <title>说的很实在，开会的时候发言顺序很重要👍</title>
            <link>https://nitter.cz/dotey/status/1735705912008954024#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735705912008954024#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 16:58:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>说的很实在，开会的时候发言顺序很重要👍</p>
<p><a href="https://nitter.cz/pirrer/status/1735701274866414016#m">nitter.cz/pirrer/status/1735701274866414016#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1735637926493786167#m</id>
            <title>RT by @dotey: mistral 还是厉害，现在lmsys elo 比较高的7B模型，包括openchat、starling、openhermes、zephyr 都是以 mistral 为基座模型。

而且实测用中文prompt 进行sft，也有良好的表现。

目前我们新的7B模型的base，已经全部切换为mistral。</title>
            <link>https://nitter.cz/9hills/status/1735637926493786167#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1735637926493786167#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 12:28:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>mistral 还是厉害，现在lmsys elo 比较高的7B模型，包括openchat、starling、openhermes、zephyr 都是以 mistral 为基座模型。<br />
<br />
而且实测用中文prompt 进行sft，也有良好的表现。<br />
<br />
目前我们新的7B模型的base，已经全部切换为mistral。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735558086297825478#m</id>
            <title>我把 a16z 这篇文章翻译了一下：《2024 年科技领域的重大创新思想 [译]》
https://baoyu.io/translations/ai/big-ideas-in-tech-2024</title>
            <link>https://nitter.cz/dotey/status/1735558086297825478#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735558086297825478#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:11:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我把 a16z 这篇文章翻译了一下：《2024 年科技领域的重大创新思想 [译]》<br />
<a href="https://baoyu.io/translations/ai/big-ideas-in-tech-2024">baoyu.io/translations/ai/big…</a></p>
<p><a href="https://nitter.cz/indigo11/status/1735216254993199204#m">nitter.cz/indigo11/status/1735216254993199204#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTU1ODA4ODI5NDMxMzk4NC9WRlNDekVZZD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1734562244422504844#m</id>
            <title>RT by @dotey: 老铁们 发现一个开源的界面非常漂亮的聊天机器人框架： Lobe Chat

支持TTS语音合成、GPT 4V多模态交互和可扩展的函数调用插件系统，可以联网、画图、爬虫等。

支持一键部署，可在1分钟内完成部署（亲测确实很快🙂），无需复杂的配置过程。一键搭建私人 ChatGPT/LLM 网页应用程序。

主要功能特点：

- 多模态支持：支持最新的GPT 4V模型，具备视觉识别能力。

- 语音会话：支持文字转语音（TTS）和语音转文字（STT）技术，提供清晰的语音输出

- 插件系统：Function Calling插件生态允许实时信息获取和处理，如自动获取最新新闻头条。

- 助手市场：内置多种精心设计的AI助手，用户可以贡献和分享个人开发的助手。

- 采用 PWA 技术：提供接近原生应用体验的网页应用。支持桌面和移动设备，提供优化的用户体验。

- 移动设备适配：针对移动设备进行了优化设计，提升移动体验。正在进行版本迭代，以实现更流畅和直观的交互。

-快速部署：使用 Vercel 平台或者 Docker 镜像，一键部署，可在 1 分钟内完成部署，无需复杂的配置过程。

- 更多特性：包括精致的 UI 设计、流畅的对话体验、数据本地化隐私安全和自定义域名等。

在线体验：https://chat-preview.lobehub.com/welcome
GitHub：https://github.com/lobehub/lobe-chat</title>
            <link>https://nitter.cz/xiaohuggg/status/1734562244422504844#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1734562244422504844#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 13:14:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>老铁们 发现一个开源的界面非常漂亮的聊天机器人框架： Lobe Chat<br />
<br />
支持TTS语音合成、GPT 4V多模态交互和可扩展的函数调用插件系统，可以联网、画图、爬虫等。<br />
<br />
支持一键部署，可在1分钟内完成部署（亲测确实很快🙂），无需复杂的配置过程。一键搭建私人 ChatGPT/LLM 网页应用程序。<br />
<br />
主要功能特点：<br />
<br />
- 多模态支持：支持最新的GPT 4V模型，具备视觉识别能力。<br />
<br />
- 语音会话：支持文字转语音（TTS）和语音转文字（STT）技术，提供清晰的语音输出<br />
<br />
- 插件系统：Function Calling插件生态允许实时信息获取和处理，如自动获取最新新闻头条。<br />
<br />
- 助手市场：内置多种精心设计的AI助手，用户可以贡献和分享个人开发的助手。<br />
<br />
- 采用 PWA 技术：提供接近原生应用体验的网页应用。支持桌面和移动设备，提供优化的用户体验。<br />
<br />
- 移动设备适配：针对移动设备进行了优化设计，提升移动体验。正在进行版本迭代，以实现更流畅和直观的交互。<br />
<br />
-快速部署：使用 Vercel 平台或者 Docker 镜像，一键部署，可在 1 分钟内完成部署，无需复杂的配置过程。<br />
<br />
- 更多特性：包括精致的 UI 设计、流畅的对话体验、数据本地化隐私安全和自定义域名等。<br />
<br />
在线体验：<a href="https://chat-preview.lobehub.com/welcome">chat-preview.lobehub.com/wel…</a><br />
GitHub：<a href="https://github.com/lobehub/lobe-chat">github.com/lobehub/lobe-chat</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ1NTc1MzMzNzE4NzEyMzIvcHUvaW1nL09qSmpoOXdURzZKTkpPbE4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735547248665035146#m</id>
            <title>R to @dotey: 刊误：</title>
            <link>https://nitter.cz/dotey/status/1735547248665035146#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735547248665035146#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:28:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刊误：</p>
<p><a href="https://nitter.cz/Miracle_XYZ/status/1735545849617535133#m">nitter.cz/Miracle_XYZ/status/1735545849617535133#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735539921039839429#m</id>
            <title>微软官方出的 Windows AI Studio，如果你需要：
- 本地测试Phi-2 小模型
- 测试 RAG
- 微调模型
- 针对 Windows 优化模型

并且你是Windows 系统 + NVIDIA 的显卡，可以试试用它 。

官方说明：
Windows AI Studio 通过集成 Azure AI Studio Catalog 和其他类似 Hugging Face 的AI 模型目录中的最新 AI 开发工具和模型，使得开发生成式 AI 应用程序变得更加简单。你可以浏览由 Azure ML 和 Hugging Face 提供动力的 AI 模型目录，下载它们到本地进行微调和测试，然后在你的 Windows 应用中使用它们。因为所有的计算都在你的设备上进行，所以要确保设备的性能能够担负起这个任务。

未来，我们还计划将 ORT/DML 集成进 Windows AI Studio 的工作流程中，这样开发者就能够在任何一款 Windows 设备上进行 AI 模型的运行了。</title>
            <link>https://nitter.cz/dotey/status/1735539921039839429#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735539921039839429#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 05:58:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软官方出的 Windows AI Studio，如果你需要：<br />
- 本地测试Phi-2 小模型<br />
- 测试 RAG<br />
- 微调模型<br />
- 针对 Windows 优化模型<br />
<br />
并且你是Windows 系统 + NVIDIA 的显卡，可以试试用它 。<br />
<br />
官方说明：<br />
Windows AI Studio 通过集成 Azure AI Studio Catalog 和其他类似 Hugging Face 的AI 模型目录中的最新 AI 开发工具和模型，使得开发生成式 AI 应用程序变得更加简单。你可以浏览由 Azure ML 和 Hugging Face 提供动力的 AI 模型目录，下载它们到本地进行微调和测试，然后在你的 Windows 应用中使用它们。因为所有的计算都在你的设备上进行，所以要确保设备的性能能够担负起这个任务。<br />
<br />
未来，我们还计划将 ORT/DML 集成进 Windows AI Studio 的工作流程中，这样开发者就能够在任何一款 Windows 设备上进行 AI 模型的运行了。</p>
<p><a href="https://nitter.cz/osanseviero/status/1735280610329993564#m">nitter.cz/osanseviero/status/1735280610329993564#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYZXR0alhVQUFDWWdaLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYZXZOOVdZQUFRaVNqLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>