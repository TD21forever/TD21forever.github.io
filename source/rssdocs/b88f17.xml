<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/heroooooh/status/1740963704051843296#m</id>
            <title>RT by @dotey: 仰望星空可以，但还是需要脚踏实地。
不要对AIGC有过多的期望，期望越大，失望越大。
能帮你省5%其实都很开心了。
天下难事，必做于易。期望大家都能聚焦到更小更垂直的地方去思考AI如何发挥效用，这样会收获更多惊喜。</title>
            <link>https://nitter.cz/heroooooh/status/1740963704051843296#m</link>
            <guid isPermaLink="false">https://nitter.cz/heroooooh/status/1740963704051843296#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 05:11:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>仰望星空可以，但还是需要脚踏实地。<br />
不要对AIGC有过多的期望，期望越大，失望越大。<br />
能帮你省5%其实都很开心了。<br />
天下难事，必做于易。期望大家都能聚焦到更小更垂直的地方去思考AI如何发挥效用，这样会收获更多惊喜。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nra2gyLWFVQUEtdi1JLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Gorden_Sun/status/1740930168393466246#m</id>
            <title>RT by @dotey: 微软的Copilot出iOS版本了，基本跟之前的Bing Chat差不多，不买ChatGPT Plus的可以考虑用这个。</title>
            <link>https://nitter.cz/Gorden_Sun/status/1740930168393466246#m</link>
            <guid isPermaLink="false">https://nitter.cz/Gorden_Sun/status/1740930168393466246#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 02:57:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软的Copilot出iOS版本了，基本跟之前的Bing Chat差不多，不买ChatGPT Plus的可以考虑用这个。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrR3dWQmJNQUFMX29ILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrR3dVX2FrQUF4RFNpLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrR3dVX2FrQUUzTXJtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/fengbuyou/status/1740945839743467898#m</id>
            <title>RT by @dotey: ChatGPT 手机版左上角可以搜索之前的聊天记录，实测标题和正文都能搜到

今天才知道🤦‍♂️</title>
            <link>https://nitter.cz/fengbuyou/status/1740945839743467898#m</link>
            <guid isPermaLink="false">https://nitter.cz/fengbuyou/status/1740945839743467898#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 04:00:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT 手机版左上角可以搜索之前的聊天记录，实测标题和正文都能搜到<br />
<br />
今天才知道🤦‍♂️</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrVkFoZWFJQUExVEZOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1740687049861292449#m</id>
            <title>RT by @dotey: 基于苹果MLX的 Stable Diffusion WebUI 界面

提供了一个简单的WebUI，可以让你在苹果电脑上使用Stable Diffusion 图像生成功能，界面简单易用，小白用户轻松上手。

支持多种模型，包括 Stable-diffusion-2-1-base、Dreamshaper-8 和 Absolute-reality-1.81。

规范化了 I2I 基础图像强度控制和种子控制。</title>
            <link>https://nitter.cz/xiaohuggg/status/1740687049861292449#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1740687049861292449#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 10:51:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>基于苹果MLX的 Stable Diffusion WebUI 界面<br />
<br />
提供了一个简单的WebUI，可以让你在苹果电脑上使用Stable Diffusion 图像生成功能，界面简单易用，小白用户轻松上手。<br />
<br />
支持多种模型，包括 Stable-diffusion-2-1-base、Dreamshaper-8 和 Absolute-reality-1.81。<br />
<br />
规范化了 I2I 基础图像强度控制和种子控制。</p>
<p><a href="https://nitter.cz/WankyuChoi/status/1740322887515652301#m">nitter.cz/WankyuChoi/status/1740322887515652301#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740863315264336018#m</id>
            <title>#AI开源项目推荐：VoiceStreamAI

VoiceStreamAI 是一个可以自己托管的 Whisper 解决方案，服务端是 Python，客户端是 JS，基于 WebSocket 实时通信，可以做到语音的实时传输和文本转换。

系统内部运用了来自Huggingface的语音活动检测（Voice Activity Detection， VAD）技术，以及来自OpenAI的Whisper模型，从而实现对语音的准确识别和处理。

功能
- 支持WebSocket，实现实时音频流的传输。
- 采用来自Huggingface的VAD技术，对语音活动进行精确检测。
- 利用来自OpenAI的Whisper模型，完成语音转写。
- 可针对音频块进行个性化处理。
- 具备多语言转写功能。

https://github.com/alesaccoia/VoiceStreamAI</title>
            <link>https://nitter.cz/dotey/status/1740863315264336018#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740863315264336018#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 22:32:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：VoiceStreamAI<br />
<br />
VoiceStreamAI 是一个可以自己托管的 Whisper 解决方案，服务端是 Python，客户端是 JS，基于 WebSocket 实时通信，可以做到语音的实时传输和文本转换。<br />
<br />
系统内部运用了来自Huggingface的语音活动检测（Voice Activity Detection， VAD）技术，以及来自OpenAI的Whisper模型，从而实现对语音的准确识别和处理。<br />
<br />
功能<br />
- 支持WebSocket，实现实时音频流的传输。<br />
- 采用来自Huggingface的VAD技术，对语音活动进行精确检测。<br />
- 利用来自OpenAI的Whisper模型，完成语音转写。<br />
- 可针对音频块进行个性化处理。<br />
- 具备多语言转写功能。<br />
<br />
<a href="https://github.com/alesaccoia/VoiceStreamAI">github.com/alesaccoia/VoiceS…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NqSjdYRVhRQUFCVktsLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NqSjhEUld3QUF2NGUwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740858628419059889#m</id>
            <title>赞，Mixtral-8x7B 可以在Google Colab运行了</title>
            <link>https://nitter.cz/dotey/status/1740858628419059889#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740858628419059889#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 22:13:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>赞，Mixtral-8x7B 可以在Google Colab运行了</p>
<p><a href="https://nitter.cz/Yampeleg/status/1740790264925409578#m">nitter.cz/Yampeleg/status/1740790264925409578#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/aigclab/status/1740673568198025630#m</id>
            <title>RT by @dotey: 笑死 AI研究员是如何调试模式参数的😅</title>
            <link>https://nitter.cz/aigclab/status/1740673568198025630#m</link>
            <guid isPermaLink="false">https://nitter.cz/aigclab/status/1740673568198025630#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 09:58:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>笑死 AI研究员是如何调试模式参数的😅</p>
<p><a href="https://nitter.cz/deliprao/status/1740610760219168883#m">nitter.cz/deliprao/status/1740610760219168883#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740857299781165254#m</id>
            <title>推荐教程：构建你自己的 AI 辅助编码助手

介绍如何 DIY 一个端到端（从 IDE 插件、模型选型、数据集构建到模型微调）的 AI 辅助编程工具，类似于 GitHub Copilot、JetBrains AI Assistant、AutoDev 等。

https://github.com/unit-mesh/build-your-ai-coding-assistant</title>
            <link>https://nitter.cz/dotey/status/1740857299781165254#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740857299781165254#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 22:08:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐教程：构建你自己的 AI 辅助编码助手<br />
<br />
介绍如何 DIY 一个端到端（从 IDE 插件、模型选型、数据集构建到模型微调）的 AI 辅助编程工具，类似于 GitHub Copilot、JetBrains AI Assistant、AutoDev 等。<br />
<br />
<a href="https://github.com/unit-mesh/build-your-ai-coding-assistant">github.com/unit-mesh/build-y…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NqRU52M1drQUFXOVVXLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NqRWNSRFhVQUFYQUZULmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NqRWVrRVhZQUV1MDRLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740853419639017595#m</id>
            <title>最开始他们说：“善用 AI 的人会替代那些不会用 AI 的人的工作”
这是真的，但只持续了很短时间，最后大家发现：“AI 替代了所有人的工作”</title>
            <link>https://nitter.cz/dotey/status/1740853419639017595#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740853419639017595#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 21:52:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最开始他们说：“善用 AI 的人会替代那些不会用 AI 的人的工作”<br />
这是真的，但只持续了很短时间，最后大家发现：“AI 替代了所有人的工作”</p>
<p><a href="https://nitter.cz/BasedDinesh/status/1737478868565430360#m">nitter.cz/BasedDinesh/status/1737478868565430360#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740840911687303239#m</id>
            <title>TinyGPT-V：利用小型架构实现高效多模式大型语言模型

论文摘要：

在先进的多模态学习时代，像GPT-4V这样的多模态大型语言模型 (MLLMs) 在联结语言与视觉元素方面取得了巨大进步。然而，源代码的封闭性和强大的计算需求对其的普遍应用和修改带来了不小挑战。

此时，像LLaVA和MiniGPT-4这样的开源MLLMs呈现出了破土而出的成就。虽然取得这些成绩，但计算效率仍然是一个尚未解决的问题，因为像LLaVA-v1.5-13B这样的模型需要大量的资源。

为了解决这些问题，我们推出了TinyGPT-V，一个将卓越性能与常见计算能力结合的新型模型。它只需要24G GPU进行训练，8G的GPU或CPU进行推理即可。基于Phi-2，TinyGPT-V将高效的语言主干和来自BLIP-2或CLIP的预训练的视觉模块结合在一起。

TinyGPT-V拥有28亿的参数，可以经历一种独特的量化过程，非常适合在拥有8G内存的各种设备上进行本地部署和推理任务。我们的工作进一步推动了设计出经济高效、性能优秀的MLLMs的发展，使得它们在更广阔的实际应用场景中具有更大的可能性。

此外，本文还提出了一种新的范例，即通过小型主干实现多模态大型语言模型。

论文地址：https://arxiv.org/abs/2312.16862
项目地址：https://github.com/DLYuanGod/TinyGPT-V
https://huggingface.co/Tyrannosaurus/TinyGPT-V</title>
            <link>https://nitter.cz/dotey/status/1740840911687303239#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740840911687303239#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 21:03:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>TinyGPT-V：利用小型架构实现高效多模式大型语言模型<br />
<br />
论文摘要：<br />
<br />
在先进的多模态学习时代，像GPT-4V这样的多模态大型语言模型 (MLLMs) 在联结语言与视觉元素方面取得了巨大进步。然而，源代码的封闭性和强大的计算需求对其的普遍应用和修改带来了不小挑战。<br />
<br />
此时，像LLaVA和MiniGPT-4这样的开源MLLMs呈现出了破土而出的成就。虽然取得这些成绩，但计算效率仍然是一个尚未解决的问题，因为像LLaVA-v1.5-13B这样的模型需要大量的资源。<br />
<br />
为了解决这些问题，我们推出了TinyGPT-V，一个将卓越性能与常见计算能力结合的新型模型。它只需要24G GPU进行训练，8G的GPU或CPU进行推理即可。基于Phi-2，TinyGPT-V将高效的语言主干和来自BLIP-2或CLIP的预训练的视觉模块结合在一起。<br />
<br />
TinyGPT-V拥有28亿的参数，可以经历一种独特的量化过程，非常适合在拥有8G内存的各种设备上进行本地部署和推理任务。我们的工作进一步推动了设计出经济高效、性能优秀的MLLMs的发展，使得它们在更广阔的实际应用场景中具有更大的可能性。<br />
<br />
此外，本文还提出了一种新的范例，即通过小型主干实现多模态大型语言模型。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.16862">arxiv.org/abs/2312.16862</a><br />
项目地址：<a href="https://github.com/DLYuanGod/TinyGPT-V">github.com/DLYuanGod/TinyGPT…</a><br />
<a href="https://huggingface.co/Tyrannosaurus/TinyGPT-V">huggingface.co/Tyrannosaurus…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NpMWk2RFhjQUFQTjB3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NpMWt1VVc0QUFadVBWLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740835365869519058#m</id>
            <title>MobileVLM：一种快速、可复现且强大的适用于移动设备的视觉语言助手。

论文摘要：

我们向您介绍MobileVLM。这是一款专为移动设备打造的、出色的多模态视觉语言模型（MMVLM）。

MobileVLM混合了各种面向移动设备的架构设计和技术。这其中包括一套从零开始训练的大规模语言模型（参数达到14亿和27亿），一个使用CLIP方法预训练的多模态视觉模型，以及一个高效的投射器，可实现跨模式交互。

我们使用了几种典型的VLM基准测试来评估MobileVLM。结果表明，我们的模型与一些大模型相比，表现相当出色。我们在Qualcomm Snapdragon 888 CPU和NVIDIA Jeston Orin GPU上测量了推理速度。

令人兴奋的是，我们取得了21.5个和65.3个 Token 每秒的推理速度，这在业界属于领先水平。注：这里的“Token”是指模型每秒可以处理的信息量。

论文地址：https://arxiv.org/abs/2312.16886
项目地址：https://github.com/Meituan-AutoML/MobileVLM</title>
            <link>https://nitter.cz/dotey/status/1740835365869519058#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740835365869519058#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 20:41:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MobileVLM：一种快速、可复现且强大的适用于移动设备的视觉语言助手。<br />
<br />
论文摘要：<br />
<br />
我们向您介绍MobileVLM。这是一款专为移动设备打造的、出色的多模态视觉语言模型（MMVLM）。<br />
<br />
MobileVLM混合了各种面向移动设备的架构设计和技术。这其中包括一套从零开始训练的大规模语言模型（参数达到14亿和27亿），一个使用CLIP方法预训练的多模态视觉模型，以及一个高效的投射器，可实现跨模式交互。<br />
<br />
我们使用了几种典型的VLM基准测试来评估MobileVLM。结果表明，我们的模型与一些大模型相比，表现相当出色。我们在Qualcomm Snapdragon 888 CPU和NVIDIA Jeston Orin GPU上测量了推理速度。<br />
<br />
令人兴奋的是，我们取得了21.5个和65.3个 Token 每秒的推理速度，这在业界属于领先水平。注：这里的“Token”是指模型每秒可以处理的信息量。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.16886">arxiv.org/abs/2312.16886</a><br />
项目地址：<a href="https://github.com/Meituan-AutoML/MobileVLM">github.com/Meituan-AutoML/Mo…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Npd0pDWVh3QUFDU0g1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740813574505898026#m</id>
            <title>RT by @dotey: 卧槽，一直想要的东西终于来了，终于可以不用看着Comfyui那个小输入框调整提示词了。

Prompt Composer这个插件可以用更有逻辑和有序的方式通过链接来调整提示词顺序和内容，同时通过滑块调整权重。

这个插件有包括两类节点，第一类是输入提示词不断串联并且可以通过提示词滑块调整权重。
另外一类是效果和样式选择器，可以选择内置的效果和样式提示词包，同意调整权重。
最后会按照连接的顺序生成完整的提示词。

要是有Animatediff的提示词旅行格式的提示词编辑更就好了。

项目地址：https://github.com/florestefano1975/comfyui-prompt-composer</title>
            <link>https://nitter.cz/op7418/status/1740813574505898026#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740813574505898026#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 19:14:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，一直想要的东西终于来了，终于可以不用看着Comfyui那个小输入框调整提示词了。<br />
<br />
Prompt Composer这个插件可以用更有逻辑和有序的方式通过链接来调整提示词顺序和内容，同时通过滑块调整权重。<br />
<br />
这个插件有包括两类节点，第一类是输入提示词不断串联并且可以通过提示词滑块调整权重。<br />
另外一类是效果和样式选择器，可以选择内置的效果和样式提示词包，同意调整权重。<br />
最后会按照连接的顺序生成完整的提示词。<br />
<br />
要是有Animatediff的提示词旅行格式的提示词编辑更就好了。<br />
<br />
项目地址：<a href="https://github.com/florestefano1975/comfyui-prompt-composer">github.com/florestefano1975/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NpYkwtcWFrQUFJb2QzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740686124736262583#m</id>
            <title>RT by @dotey: 一个开源的多模态 LLM Unified-IO 2。
比较离谱的是它可以实现语音理解和动作理解还有图像标记这种任务，还可以理解空间关系。真正的 All in one 。
甚至还可以驱动机器人做对应的操作。

项目简介：
Unified-IO 2，这是第一个能够理解和生成图像、文本、音频和动作的自回归多模态模型。
为了统一不同的模态，我们将输入和输出（图像、文本、音频、动作、框等）进行分词，并将它们置于一个共享的语义空间中，然后使用单个编码器-解码器变换器模型进行处理。由于使用多样的模态进行训练非常困难，我们提出了各种架构改进来稳定模型。
我们从头开始在来自不同来源的大型多模态预训练语料库上训练我们的模型，并采用多模态混合去噪目标。为了学习一系列广泛的技能，比如遵循多模态指令，我们构建并微调了一个包含120个现有数据集的集合，并进行了提示和增强。
通过一个统一的模型，Unified-IO 2在GRIT基准测试中达到了最先进的性能，并在30多个基准测试中取得了强大的结果，包括图像生成和理解、文本理解、视频和音频理解以及机器人操作。我们将所有的模型都发布给研究界。

项目地址：https://unified-io-2.allenai.org/</title>
            <link>https://nitter.cz/op7418/status/1740686124736262583#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740686124736262583#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 10:48:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个开源的多模态 LLM Unified-IO 2。<br />
比较离谱的是它可以实现语音理解和动作理解还有图像标记这种任务，还可以理解空间关系。真正的 All in one 。<br />
甚至还可以驱动机器人做对应的操作。<br />
<br />
项目简介：<br />
Unified-IO 2，这是第一个能够理解和生成图像、文本、音频和动作的自回归多模态模型。<br />
为了统一不同的模态，我们将输入和输出（图像、文本、音频、动作、框等）进行分词，并将它们置于一个共享的语义空间中，然后使用单个编码器-解码器变换器模型进行处理。由于使用多样的模态进行训练非常困难，我们提出了各种架构改进来稳定模型。<br />
我们从头开始在来自不同来源的大型多模态预训练语料库上训练我们的模型，并采用多模态混合去噪目标。为了学习一系列广泛的技能，比如遵循多模态指令，我们构建并微调了一个包含120个现有数据集的集合，并进行了提示和增强。<br />
通过一个统一的模型，Unified-IO 2在GRIT基准测试中达到了最先进的性能，并在30多个基准测试中取得了强大的结果，包括图像生成和理解、文本理解、视频和音频理解以及机器人操作。我们将所有的模型都发布给研究界。<br />
<br />
项目地址：<a href="https://unified-io-2.allenai.org/">unified-io-2.allenai.org/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nnb1ladWFvQUFFNjZnLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nnb2hRWWFBQUVZczl1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nnb3B0RGJ3QUEzWXVFLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nnb3g2SWFFQUFDLThILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/raycat2021/status/1740724732532822035#m</id>
            <title>RT by @dotey: 这两天在搜罗谈AI的书，有几本业界大神如吴恩达、LeCun、马斯克高度认可的经典作品。
一并分享给大家，有时间找来翻翻。我们每个人都该想好AI时代如何安排自己了。

1，《奇点临近》The Singularity I Near (Ray Kurzweil)
作者被比尔-盖茨称为“预测AI最准的未来学家”，这是2005年作品，对业界影响深远。1/</title>
            <link>https://nitter.cz/raycat2021/status/1740724732532822035#m</link>
            <guid isPermaLink="false">https://nitter.cz/raycat2021/status/1740724732532822035#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 13:21:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这两天在搜罗谈AI的书，有几本业界大神如吴恩达、LeCun、马斯克高度认可的经典作品。<br />
一并分享给大家，有时间找来翻翻。我们每个人都该想好AI时代如何安排自己了。<br />
<br />
1，《奇点临近》The Singularity I Near (Ray Kurzweil)<br />
作者被比尔-盖茨称为“预测AI最准的未来学家”，这是2005年作品，对业界影响深远。1/</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NoRHBzaGJZQUFyN2lyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740657169777967504#m</id>
            <title>AI 普及后</title>
            <link>https://nitter.cz/dotey/status/1740657169777967504#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740657169777967504#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 08:53:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI 普及后</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NnT2J3a1d3QUVfdEZjLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740623306477162745#m</id>
            <title>柏林 IT 专家破解特斯拉自动驾驶，揭秘隐藏的“马斯克模式”

三名柏林博士生成功破解了特斯拉的电路板，不仅发现了公司机密和私人数据，还揭露了一个神秘的“马斯克模式”。这究竟是什么？

这三位博士生——Niclas Kühnapfel、Christian Werling 和 Hans-Niklas Jacob，并不是通过编写代码绕开安全系统，而是使用价值 600 欧元的工具巧妙地破解了特斯拉的电路板。据《明镜周刊》报道，他们是利用从美国联系人那里获悉的电路板漏洞实现的。

商业机密与埃隆模式

他们自称揭露了特斯拉的一些商业机密。报告显示，他们能够追踪到特斯拉在实时运行中将哪些自动驾驶数据发送回公司，用于训练其人工智能。

此外，在工作过程中，这三位博士生还在电路板上发现了一个已被删除但尚未完全覆盖的视频。视频展示了一辆在美国行驶的特斯拉，视频中的时间和 GPS 位置也被他们复原了。

另一个惊人的发现是，他们证实了特斯拉存在一个被称为“马斯克模式”的功能。这个模式之前在夏天已被另一名黑客激活过。在该模式下，汽车可以实现自动驾驶，而驾驶者无需时刻将双手放在方向盘上。

对个人用户影响不大

据报道，这些发现对特斯拉的个人用户来说并不构成太大威胁。要渗透这块电路板，潜在的黑客需要直接接触到这个部件，这意味着需要将其拆卸出来。理论上，这种操作只能在维修工作室中进行。

这三位博士生对于能如此轻易地获取特斯拉的商业机密感到惊讶。他们认为，其他竞争对手也可能通过类似方式获取到电动汽车的相关知识。总体而言，他们认为特斯拉的安全措施做得很好，只是对于他们所采用的 Voltage-Glitch（电压故障）攻击，公司似乎尚未做好充分准备。

新闻来源：https://t3n.de/news/tesla-autopilot-hack-geheimer-elon-modus-1598800/</title>
            <link>https://nitter.cz/dotey/status/1740623306477162745#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740623306477162745#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 06:38:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>柏林 IT 专家破解特斯拉自动驾驶，揭秘隐藏的“马斯克模式”<br />
<br />
三名柏林博士生成功破解了特斯拉的电路板，不仅发现了公司机密和私人数据，还揭露了一个神秘的“马斯克模式”。这究竟是什么？<br />
<br />
这三位博士生——Niclas Kühnapfel、Christian Werling 和 Hans-Niklas Jacob，并不是通过编写代码绕开安全系统，而是使用价值 600 欧元的工具巧妙地破解了特斯拉的电路板。据《明镜周刊》报道，他们是利用从美国联系人那里获悉的电路板漏洞实现的。<br />
<br />
商业机密与埃隆模式<br />
<br />
他们自称揭露了特斯拉的一些商业机密。报告显示，他们能够追踪到特斯拉在实时运行中将哪些自动驾驶数据发送回公司，用于训练其人工智能。<br />
<br />
此外，在工作过程中，这三位博士生还在电路板上发现了一个已被删除但尚未完全覆盖的视频。视频展示了一辆在美国行驶的特斯拉，视频中的时间和 GPS 位置也被他们复原了。<br />
<br />
另一个惊人的发现是，他们证实了特斯拉存在一个被称为“马斯克模式”的功能。这个模式之前在夏天已被另一名黑客激活过。在该模式下，汽车可以实现自动驾驶，而驾驶者无需时刻将双手放在方向盘上。<br />
<br />
对个人用户影响不大<br />
<br />
据报道，这些发现对特斯拉的个人用户来说并不构成太大威胁。要渗透这块电路板，潜在的黑客需要直接接触到这个部件，这意味着需要将其拆卸出来。理论上，这种操作只能在维修工作室中进行。<br />
<br />
这三位博士生对于能如此轻易地获取特斯拉的商业机密感到惊讶。他们认为，其他竞争对手也可能通过类似方式获取到电动汽车的相关知识。总体而言，他们认为特斯拉的安全措施做得很好，只是对于他们所采用的 Voltage-Glitch（电压故障）攻击，公司似乎尚未做好充分准备。<br />
<br />
新闻来源：<a href="https://t3n.de/news/tesla-autopilot-hack-geheimer-elon-modus-1598800/">t3n.de/news/tesla-autopilot-…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/monday_chen/status/1740612924740137285#m</id>
            <title>RT by @dotey: 年底了，被动离开 Meta 也半年多了，分享一些在 React 团队工作经历的思考 https://gist.github.com/mondaychen/3c530604e44b9cd15e4f69735d99fef4</title>
            <link>https://nitter.cz/monday_chen/status/1740612924740137285#m</link>
            <guid isPermaLink="false">https://nitter.cz/monday_chen/status/1740612924740137285#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 05:57:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>年底了，被动离开 Meta 也半年多了，分享一些在 React 团队工作经历的思考 <a href="https://gist.github.com/mondaychen/3c530604e44b9cd15e4f69735d99fef4">gist.github.com/mondaychen/3…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MDE0NDQ2MzM2MjU1MTgwOS95SlZSUENOaT9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740602986223513911#m</id>
            <title>猜猜经济学人评选的2023年最出色的 CEO 是谁？

以下内容转译自经济学人的《Who was the best CEO of 2023? We measure up the business world’s top dogs》

在企业高层，2023年充满了挑战。多个市场的缓慢增长迫使领导们在削减成本的同时，应对员工因通胀而要求的大幅加薪。激烈的地缘政治和激进的文化冲突让企业高管们如履薄冰。此外，生成式人工智能 (AI) 的兴起也让他们对未来技术革新感到担忧。

尽管如此，对一些首席执行官而言，2023年却是收获丰富的一年。为了评判谁是最佳，经济学人 对大型上市公司的CEO们进行了绩效考察，这些公司被纳入了 s&amp;p 1200 指数，覆盖了大部分主要经济体（中国和印度除外）。我们剔除了那些任职不足三年的CEO，避免因更换无能的前任而过度赞赏。接着，我们按照他们为股东创造的收益与所在行业平均水平的对比进行了排名。十强中既有广为人知的名字，也有鲜为人知的黑马。

在这十强中，有两位CEO分别来自Cameco（加拿大矿业公司）和PulteGroup（美国住宅建筑商），他们的卓越成绩主要得益于市场大环境（分别是铀价的飙升和现房销售的减少）。我们将他们排除在评选之外。另外，两家收购公司3i和Melrose Industries的CEO也名列其中，但他们的成绩更多归功于他们管理的投资组合公司的表现，而非自身。因此，我们同样将他们排除。最后，我们还排除了 Richard Blickman，他是荷兰半导体设备制造商 be Semiconductor Industries 的CEO，由于他的薪酬被股东否决，这对任何CEO来说都不是好现象。

我们筛选出了2023年五位表现出色的首席执行官（见图二）。他们按照股东回报率从低到高依次是：Eli Lilly的David Ricks，该公司现为全球最具价值的制药企业；巴西新兴银行 Nubank 的David Vélez Osorno，这家银行正迅速扩张其在拉丁美洲的客户群；日本Disco公司的Sekiya Kazuma，该公司专注于制造尖端半导体生产工具；社交媒体巨头Meta公司的Mark Zuckerberg；以及芯片制造商 Nvidia 的Jensen Huang，Nvidia今年的市值突破了1万亿美元。

在假日季，这五位CEO都因为为股东创造了巨大价值而倍感欣慰。但到底谁的一年过得最好？

对这五位中的任何一位来说，都有理由认为他们是年度最佳。Ricks先生带领Eli Lilly紧追其丹麦竞争对手Novo Nordisk，在迅速增长的 抗肥胖药物 市场上取得了显著成就，并在这个对行业来说平平无奇的一年取得了非凡的业绩。几乎没有新型银行能够撼动老牌金融机构的地位，但在Osorno先生的领导下，他于2013年共同创立的Nubank已成为拉丁美洲第五大金融机构，客户数量庞大。Kazuma先生同时负责Disco的研发部门，多年来一直将公司保持在半导体切割和磨削的前沿。Zuckerberg先生在2022年因其对元宇宙的狂热令投资者感到恐慌，但在2023年以其“效率之年”以及Meta公司在 generative AI 领域的探索让他们大为振奋。而Huang先生则进一步巩固了Nvidia作为推动 AI 革命中不可或缺的芯片供应商的地位。

如何做出选择呢？一个方法是听听下属的看法。毕竟，那些能提升股价却让员工不满的CEO，很难长期保持成功。我们从员工评价网站 Glassdoor 收集了数据，这些数据反映了员工对五家公司的CEO以及整体公司的看法。

以 62% 的支持率，Zuckerberg 先生显得格外突出，这似乎表明他的“效率年”对员工来说非常糟糕。Disco 的员工满意度也相对较低（尽管反馈人数较少）。原因之一可能是该公司用于协调工作的独特机制。团队使用一种名为“Will”的虚拟货币来互相支付提供服务的费用。经理们随后将这种货币分配给团队成员，以完成任务，进而决定奖金分配。这听起来对经济学家来说很理想，但可能并不利于团队合作。

激怒客户也不是CEO们的明智之举。今年，包括加利福尼亚州在内的多个美国州对 Eli Lilly 等公司提起诉讼，指控它们对胰岛素（糖尿病患者的必需药物）定价过高。该公司在 3 月决定将胰岛素价格削减 70%，但这几乎没能平息公众的不满。（该公司否认了加利福尼亚州诉讼中的“虚假指控”。）

至于 Osorno 先生，他的战略并非完全成功。尽管 Nubank 总体上盈利（这是许多其他同行未能做到的），但它在墨西哥的亏损情况令人担忧，因为该公司在那里采取的面向无银行账户人群的策略成本高昂。如果 Osorno 先生能够成功，他未来几年可能会获得重大成就。

因此，黄仁勋先生成为了最终的赢家。几乎没有哪位CEO能像 Nvidia 的黄仁勋先生那样在 AI 领域有如此远见。十多年前，黄仁勋先生就意识到他的公司生产的图形处理单元（Graphical Processing Units, GPU）在训练 AI 模型方面也很有用。在接下来的几年里，他通过投资于一个名为 CUDA 的专有软件平台，并收购了 Mellanox 这家网络技术供应商，为 Nvidia 应对 AI 浪潮做好了准备。Mellanox 主要提供连接多个芯片的技术，以实现更强的处理能力。这些投资的回报现在已经显现；Nvidia 控制了超过 80% 的专业 AI 芯片市场。

黄先生的标志性皮夹克，已经成为他公众形象中不可或缺的一部分，正如史蒂夫·乔布斯 (Steve Jobs) 与他的高领衫一般。据悉，他和苹果 (Apple) 创始人一样，对工作充满激情，追求极致的完美。尽管要求严格，但他深受员工喜爱，高达 98% 的好评率证明了这一点。综合考虑，他的 2023 年堪称最为出色。

https://www.economist.com/business/2023/12/28/who-was-the-best-ceo-of-2023</title>
            <link>https://nitter.cz/dotey/status/1740602986223513911#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740602986223513911#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 05:17:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>猜猜经济学人评选的2023年最出色的 CEO 是谁？<br />
<br />
以下内容转译自经济学人的《Who was the best CEO of 2023? We measure up the business world’s top dogs》<br />
<br />
在企业高层，2023年充满了挑战。多个市场的缓慢增长迫使领导们在削减成本的同时，应对员工因通胀而要求的大幅加薪。激烈的地缘政治和激进的文化冲突让企业高管们如履薄冰。此外，生成式人工智能 (AI) 的兴起也让他们对未来技术革新感到担忧。<br />
<br />
尽管如此，对一些首席执行官而言，2023年却是收获丰富的一年。为了评判谁是最佳，经济学人 对大型上市公司的CEO们进行了绩效考察，这些公司被纳入了 s&amp;p 1200 指数，覆盖了大部分主要经济体（中国和印度除外）。我们剔除了那些任职不足三年的CEO，避免因更换无能的前任而过度赞赏。接着，我们按照他们为股东创造的收益与所在行业平均水平的对比进行了排名。十强中既有广为人知的名字，也有鲜为人知的黑马。<br />
<br />
在这十强中，有两位CEO分别来自Cameco（加拿大矿业公司）和PulteGroup（美国住宅建筑商），他们的卓越成绩主要得益于市场大环境（分别是铀价的飙升和现房销售的减少）。我们将他们排除在评选之外。另外，两家收购公司3i和Melrose Industries的CEO也名列其中，但他们的成绩更多归功于他们管理的投资组合公司的表现，而非自身。因此，我们同样将他们排除。最后，我们还排除了 Richard Blickman，他是荷兰半导体设备制造商 be Semiconductor Industries 的CEO，由于他的薪酬被股东否决，这对任何CEO来说都不是好现象。<br />
<br />
我们筛选出了2023年五位表现出色的首席执行官（见图二）。他们按照股东回报率从低到高依次是：Eli Lilly的David Ricks，该公司现为全球最具价值的制药企业；巴西新兴银行 Nubank 的David Vélez Osorno，这家银行正迅速扩张其在拉丁美洲的客户群；日本Disco公司的Sekiya Kazuma，该公司专注于制造尖端半导体生产工具；社交媒体巨头Meta公司的Mark Zuckerberg；以及芯片制造商 Nvidia 的Jensen Huang，Nvidia今年的市值突破了1万亿美元。<br />
<br />
在假日季，这五位CEO都因为为股东创造了巨大价值而倍感欣慰。但到底谁的一年过得最好？<br />
<br />
对这五位中的任何一位来说，都有理由认为他们是年度最佳。Ricks先生带领Eli Lilly紧追其丹麦竞争对手Novo Nordisk，在迅速增长的 抗肥胖药物 市场上取得了显著成就，并在这个对行业来说平平无奇的一年取得了非凡的业绩。几乎没有新型银行能够撼动老牌金融机构的地位，但在Osorno先生的领导下，他于2013年共同创立的Nubank已成为拉丁美洲第五大金融机构，客户数量庞大。Kazuma先生同时负责Disco的研发部门，多年来一直将公司保持在半导体切割和磨削的前沿。Zuckerberg先生在2022年因其对元宇宙的狂热令投资者感到恐慌，但在2023年以其“效率之年”以及Meta公司在 generative AI 领域的探索让他们大为振奋。而Huang先生则进一步巩固了Nvidia作为推动 AI 革命中不可或缺的芯片供应商的地位。<br />
<br />
如何做出选择呢？一个方法是听听下属的看法。毕竟，那些能提升股价却让员工不满的CEO，很难长期保持成功。我们从员工评价网站 Glassdoor 收集了数据，这些数据反映了员工对五家公司的CEO以及整体公司的看法。<br />
<br />
以 62% 的支持率，Zuckerberg 先生显得格外突出，这似乎表明他的“效率年”对员工来说非常糟糕。Disco 的员工满意度也相对较低（尽管反馈人数较少）。原因之一可能是该公司用于协调工作的独特机制。团队使用一种名为“Will”的虚拟货币来互相支付提供服务的费用。经理们随后将这种货币分配给团队成员，以完成任务，进而决定奖金分配。这听起来对经济学家来说很理想，但可能并不利于团队合作。<br />
<br />
激怒客户也不是CEO们的明智之举。今年，包括加利福尼亚州在内的多个美国州对 Eli Lilly 等公司提起诉讼，指控它们对胰岛素（糖尿病患者的必需药物）定价过高。该公司在 3 月决定将胰岛素价格削减 70%，但这几乎没能平息公众的不满。（该公司否认了加利福尼亚州诉讼中的“虚假指控”。）<br />
<br />
至于 Osorno 先生，他的战略并非完全成功。尽管 Nubank 总体上盈利（这是许多其他同行未能做到的），但它在墨西哥的亏损情况令人担忧，因为该公司在那里采取的面向无银行账户人群的策略成本高昂。如果 Osorno 先生能够成功，他未来几年可能会获得重大成就。<br />
<br />
因此，黄仁勋先生成为了最终的赢家。几乎没有哪位CEO能像 Nvidia 的黄仁勋先生那样在 AI 领域有如此远见。十多年前，黄仁勋先生就意识到他的公司生产的图形处理单元（Graphical Processing Units, GPU）在训练 AI 模型方面也很有用。在接下来的几年里，他通过投资于一个名为 CUDA 的专有软件平台，并收购了 Mellanox 这家网络技术供应商，为 Nvidia 应对 AI 浪潮做好了准备。Mellanox 主要提供连接多个芯片的技术，以实现更强的处理能力。这些投资的回报现在已经显现；Nvidia 控制了超过 80% 的专业 AI 芯片市场。<br />
<br />
黄先生的标志性皮夹克，已经成为他公众形象中不可或缺的一部分，正如史蒂夫·乔布斯 (Steve Jobs) 与他的高领衫一般。据悉，他和苹果 (Apple) 创始人一样，对工作充满激情，追求极致的完美。尽管要求严格，但他深受员工喜爱，高达 98% 的好评率证明了这一点。综合考虑，他的 2023 年堪称最为出色。<br />
<br />
<a href="https://www.economist.com/business/2023/12/28/who-was-the-best-ceo-of-2023">economist.com/business/2023/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NmZEo3SFhNQUFfXzRvLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NmZExTMVc0QUExaEd5LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740599902244163937#m</id>
            <title>DL3DV-10K: 针对基于深度学习的3D视觉的大规模场景数据集

基于深度学习的3D视觉领域已经取得了显著的进步，从神经辐射场（NeRF）驱动的3D表示学习到应用于全新视角合成（NVS）。然而，当前的针对基于深度学习的3D视觉的场景级别数据集，不管是只限于虚构环境或者狭窄的现实世界场景的选择，都非常框定。这种局限性限制了我们对现有方法进行全面的基准测试，也限制了在基于深度学习的3D分析中可能探索的领域。

为了填补这个空白，我们提出了DL3DV-10K，一个大规模场景数据集，包含51.2百万帧，从10,510个视频中捕获，涵盖了65种热点（POI）地点，包括有边界和无边界的场景，呈现出不同层次的反射、透明度和光照。

我们对DL3DV-10K进行了全新视角合成（NVS）方法的全面基准测试，揭示出NVS未来研究的宝贵观察。此外，我们利用DL3DV-10K进行的通用化NeRF初步学习研究取得了令人鼓舞的结果，突显了大规模场景级别数据集对于建立学习3D表示的基础模型的重要性。我们的DL3DV-10K数据集，基准测试结果和模型将可在 https://dl3dv-10k.github.io/DL3DV-10K/ 上公开获取。

论文：https://arxiv.org/abs/2312.16256
项目首页：https://dl3dv-10k.github.io/DL3DV-10K/</title>
            <link>https://nitter.cz/dotey/status/1740599902244163937#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740599902244163937#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 05:05:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DL3DV-10K: 针对基于深度学习的3D视觉的大规模场景数据集<br />
<br />
基于深度学习的3D视觉领域已经取得了显著的进步，从神经辐射场（NeRF）驱动的3D表示学习到应用于全新视角合成（NVS）。然而，当前的针对基于深度学习的3D视觉的场景级别数据集，不管是只限于虚构环境或者狭窄的现实世界场景的选择，都非常框定。这种局限性限制了我们对现有方法进行全面的基准测试，也限制了在基于深度学习的3D分析中可能探索的领域。<br />
<br />
为了填补这个空白，我们提出了DL3DV-10K，一个大规模场景数据集，包含51.2百万帧，从10,510个视频中捕获，涵盖了65种热点（POI）地点，包括有边界和无边界的场景，呈现出不同层次的反射、透明度和光照。<br />
<br />
我们对DL3DV-10K进行了全新视角合成（NVS）方法的全面基准测试，揭示出NVS未来研究的宝贵观察。此外，我们利用DL3DV-10K进行的通用化NeRF初步学习研究取得了令人鼓舞的结果，突显了大规模场景级别数据集对于建立学习3D表示的基础模型的重要性。我们的DL3DV-10K数据集，基准测试结果和模型将可在 <a href="https://dl3dv-10k.github.io/DL3DV-10K/">dl3dv-10k.github.io/DL3DV-10…</a> 上公开获取。<br />
<br />
论文：<a href="https://arxiv.org/abs/2312.16256">arxiv.org/abs/2312.16256</a><br />
项目首页：<a href="https://dl3dv-10k.github.io/DL3DV-10K/">dl3dv-10k.github.io/DL3DV-10…</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1740587508608430164#m">nitter.cz/_akhaliq/status/1740587508608430164#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>