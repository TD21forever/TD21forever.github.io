<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>宝玉 / @dotey</title>
        <link>https://nitter.cz/dotey</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732168397989789747#m</id>
            <title>这篇关于提示工程、RAGs 与微调对比的推文不错，它这个坐标图分成了两个坐标轴：
1. 所需要外部知识多少
2. 所需要的对模型定制的多少

原推文翻译如下：

提示工程、RAGs 与微调的对比：

这是每位搭建基于大语言模型（LLM）应用的 AI 工程师都面临的关键选择。

要理解这个决策的指导原则，我们首先得明白这些术语的含义。

1️⃣ 提示工程：

所谓提示，指的是你输入的文本，大语言模型就根据这个输入来生成回应。

这实际上是一种精确的输入方法，旨在引导模型产生相应的输出。

模型的输出将基于其已有的知识。

2️⃣ RAGs（检索增强生成）：

当你将提示工程与数据库查询结合，以获得含丰富上下文的答案时，这就是所谓的 RAG。

生成的输出将基于数据库中现有的知识。

3️⃣ 微调：

微调是指使用特定任务的数据调整大语言模型的参数，使其在某一领域内专业化。

比如，一个语言模型可以在医学文献上进行微调，从而更擅长回答健康护理相关的问题。

这就好比对一位已经技艺娴熟的工人进行额外培训，让他们在特定领域成为专家。

那么，我们如何决定采取哪种方法呢？

（阅读下文时请参考下面的图片）

❗️有两个关键的指导参数，一个是对外部知识的需求，另一个是模型适应性的需求。

❗️尽管前者的含义较为明确，模型适应性则意味着改变模型的行为、词汇、写作风格等。

例如，一个预训练的大语言模型可能在总结公司会议记录时遇到挑战，因为会议中可能穿插了一些特定的内部术语。

🔹因此，微调更多的是关于改变结构（行为）而非知识，而对于 RAGs 则正好相反。

🔸当你需要生成基于定制知识库的输出，同时保持大语言模型的词汇和写作风格不变时，你可以选择使用 RAGs。

🔹如果你不需要上述任一功能，那么提示工程就是你的选择。

🔸如果你的应用既需要定制知识又需要改变模型的行为，那么采用混合方案（RAGs + 微调）将是更佳选择。</title>
            <link>https://nitter.cz/dotey/status/1732168397989789747#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732168397989789747#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 22:41:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这篇关于提示工程、RAGs 与微调对比的推文不错，它这个坐标图分成了两个坐标轴：<br />
1. 所需要外部知识多少<br />
2. 所需要的对模型定制的多少<br />
<br />
原推文翻译如下：<br />
<br />
提示工程、RAGs 与微调的对比：<br />
<br />
这是每位搭建基于大语言模型（LLM）应用的 AI 工程师都面临的关键选择。<br />
<br />
要理解这个决策的指导原则，我们首先得明白这些术语的含义。<br />
<br />
1️⃣ 提示工程：<br />
<br />
所谓提示，指的是你输入的文本，大语言模型就根据这个输入来生成回应。<br />
<br />
这实际上是一种精确的输入方法，旨在引导模型产生相应的输出。<br />
<br />
模型的输出将基于其已有的知识。<br />
<br />
2️⃣ RAGs（检索增强生成）：<br />
<br />
当你将提示工程与数据库查询结合，以获得含丰富上下文的答案时，这就是所谓的 RAG。<br />
<br />
生成的输出将基于数据库中现有的知识。<br />
<br />
3️⃣ 微调：<br />
<br />
微调是指使用特定任务的数据调整大语言模型的参数，使其在某一领域内专业化。<br />
<br />
比如，一个语言模型可以在医学文献上进行微调，从而更擅长回答健康护理相关的问题。<br />
<br />
这就好比对一位已经技艺娴熟的工人进行额外培训，让他们在特定领域成为专家。<br />
<br />
那么，我们如何决定采取哪种方法呢？<br />
<br />
（阅读下文时请参考下面的图片）<br />
<br />
❗️有两个关键的指导参数，一个是对外部知识的需求，另一个是模型适应性的需求。<br />
<br />
❗️尽管前者的含义较为明确，模型适应性则意味着改变模型的行为、词汇、写作风格等。<br />
<br />
例如，一个预训练的大语言模型可能在总结公司会议记录时遇到挑战，因为会议中可能穿插了一些特定的内部术语。<br />
<br />
🔹因此，微调更多的是关于改变结构（行为）而非知识，而对于 RAGs 则正好相反。<br />
<br />
🔸当你需要生成基于定制知识库的输出，同时保持大语言模型的词汇和写作风格不变时，你可以选择使用 RAGs。<br />
<br />
🔹如果你不需要上述任一功能，那么提示工程就是你的选择。<br />
<br />
🔸如果你的应用既需要定制知识又需要改变模型的行为，那么采用混合方案（RAGs + 微调）将是更佳选择。</p>
<p><a href="https://nitter.cz/akshay_pachaar/status/1732014719794585684#m">nitter.cz/akshay_pachaar/status/1732014719794585684#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732152449014571157#m</id>
            <title>多少年了……</title>
            <link>https://nitter.cz/dotey/status/1732152449014571157#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732152449014571157#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 21:38:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>多少年了……</p>
<p><a href="https://nitter.cz/naman34/status/1732140580342509622#m">nitter.cz/naman34/status/1732140580342509622#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732151792102691277#m</id>
            <title>哈哈，到底Arxiv上的新论文有多少是发现了GPT-4的新Prompt呢？</title>
            <link>https://nitter.cz/dotey/status/1732151792102691277#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732151792102691277#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 21:35:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈，到底Arxiv上的新论文有多少是发现了GPT-4的新Prompt呢？</p>
<p><a href="https://nitter.cz/hbouammar/status/1731970658278469714#m">nitter.cz/hbouammar/status/1731970658278469714#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732092883883139313#m</id>
            <title>Meta 和 IBM正联合 40 多家公司和机构，共同成立一个专注于开源人工智能的行业组织，目的在于共享技术并减少相关风险。

这个名为 AI Alliance（AI 联盟）的组织，将着重于负责任地发展 AI 技术，其中包括安全性和防护工具，据周二发布的声明所述。该联盟还计划增加开源 AI 模型的数量，与此同时减少某些公司偏好的专有系统，发展新硬件，并与学术研究人员进行合作。

开源 AI 技术的倡导者认为，由开发者公开并供他人使用的技术，是培养高度复杂系统的一种更高效的方式。在过去几个月里，Meta 已经发布了其大语言模型（Large Language Model，LLM）的开源版本，这些模型是 AI 聊天机器人的核心基础。

Meta 全球事务总裁 Nick Clegg 在声明中表示：“我们相信，公开开发 AI 会更好——这样更多人能够享受到其带来的好处，创造创新产品，并致力于确保安全。”

该联盟将最终成立一个管理委员会和技术监督委员会。参与单位包括 Oracle Corp.（甲骨文公司）、Advanced Micro Devices Inc.（AMD）、Intel Corp.（英特尔公司）和 Stability AI，还有像圣母大学（University of Notre Dame）和马萨诸塞开放云联盟（Mass Open Cloud Alliance）这样的学术研究机构。

最近，OpenAI——即 ChatGPT 的开发者——因解雇并重新聘请其知名首席执行官而引发了一场全球性的辩论，关注点在于企业在开发强大的 AI 技术时应保持多大的透明度。值得注意的是，OpenAI 并未列为 AI 联盟的成员之一。

AI Alliance 官网：https://thealliance.ai/

新闻来源：https://www.bloomberg.com/news/articles/2023-12-05/nvidia-plans-network-of-chip-plants-in-japan-to-meet-ai-demand</title>
            <link>https://nitter.cz/dotey/status/1732092883883139313#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732092883883139313#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 17:41:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta 和 IBM正联合 40 多家公司和机构，共同成立一个专注于开源人工智能的行业组织，目的在于共享技术并减少相关风险。<br />
<br />
这个名为 AI Alliance（AI 联盟）的组织，将着重于负责任地发展 AI 技术，其中包括安全性和防护工具，据周二发布的声明所述。该联盟还计划增加开源 AI 模型的数量，与此同时减少某些公司偏好的专有系统，发展新硬件，并与学术研究人员进行合作。<br />
<br />
开源 AI 技术的倡导者认为，由开发者公开并供他人使用的技术，是培养高度复杂系统的一种更高效的方式。在过去几个月里，Meta 已经发布了其大语言模型（Large Language Model，LLM）的开源版本，这些模型是 AI 聊天机器人的核心基础。<br />
<br />
Meta 全球事务总裁 Nick Clegg 在声明中表示：“我们相信，公开开发 AI 会更好——这样更多人能够享受到其带来的好处，创造创新产品，并致力于确保安全。”<br />
<br />
该联盟将最终成立一个管理委员会和技术监督委员会。参与单位包括 Oracle Corp.（甲骨文公司）、Advanced Micro Devices Inc.（AMD）、Intel Corp.（英特尔公司）和 Stability AI，还有像圣母大学（University of Notre Dame）和马萨诸塞开放云联盟（Mass Open Cloud Alliance）这样的学术研究机构。<br />
<br />
最近，OpenAI——即 ChatGPT 的开发者——因解雇并重新聘请其知名首席执行官而引发了一场全球性的辩论，关注点在于企业在开发强大的 AI 技术时应保持多大的透明度。值得注意的是，OpenAI 并未列为 AI 联盟的成员之一。<br />
<br />
AI Alliance 官网：<a href="https://thealliance.ai/">thealliance.ai/</a><br />
<br />
新闻来源：<a href="https://www.bloomberg.com/news/articles/2023-12-05/nvidia-plans-network-of-chip-plants-in-japan-to-meet-ai-demand">bloomberg.com/news/articles/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FtaEItYlhFQUF0QWV0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FtaE90bVdFQUE1V0J3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732085476977148310#m</id>
            <title>其实GPTs可以做到的，只是都是用自然语言（Prompt）描述工作流和分支，另外它可以根据不同情况调用不同的Action调用外部工具。

当然准确性稳定性目前还不如 if else</title>
            <link>https://nitter.cz/dotey/status/1732085476977148310#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732085476977148310#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 17:12:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>其实GPTs可以做到的，只是都是用自然语言（Prompt）描述工作流和分支，另外它可以根据不同情况调用不同的Action调用外部工具。<br />
<br />
当然准确性稳定性目前还不如 if else</p>
<p><a href="https://nitter.cz/buaaxhm/status/1731851320275984539#m">nitter.cz/buaaxhm/status/1731851320275984539#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lxfater/status/1731344168524394681#m</id>
            <title>RT by @dotey: 纯浏览器端的segment-anythin 的性能还不错。

不过这样估计也开启新的功能，比如一键抠取图像中的物品，还有点击就能inpaint，甚至使用prompt来inpaint和抠图。

后续会这个功能，加入这个项目，欢迎大家关注，更新了也提醒大家。
https://github.com/lxfater/inpaint-web</title>
            <link>https://nitter.cz/lxfater/status/1731344168524394681#m</link>
            <guid isPermaLink="false">https://nitter.cz/lxfater/status/1731344168524394681#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 03 Dec 2023 16:06:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>纯浏览器端的segment-anythin 的性能还不错。<br />
<br />
不过这样估计也开启新的功能，比如一键抠取图像中的物品，还有点击就能inpaint，甚至使用prompt来inpaint和抠图。<br />
<br />
后续会这个功能，加入这个项目，欢迎大家关注，更新了也提醒大家。<br />
<a href="https://github.com/lxfater/inpaint-web">github.com/lxfater/inpaint-w…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzEzNDIzNTczMDY0MzM1MzYvcHUvaW1nL0UtTnc1OFJ5OURhZjRudlkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1732076418903789628#m</id>
            <title>看到一篇有意思的文章：《人工智能是伟大的平衡器》——研究表明，ChatGPT 等工具的兴起对于工作表现不佳的员工来说是个好消息

作者先是以为 AI 会帮助新手能快速达到比较高的水平，然后拉平与高手之间的差距。但结果发现似乎现实并非如此。

> 事实可能并非如此简单。AI 减少工资不平等的另一个可能方式是，它可能会降低顶尖收入者的薪酬，而对底层工作者的工资提升不大。随着生产力的提升，企业主可能会选择将利润归于己有，降低薪资上限而非提高薪资底线。在这种情况下，尽管借助 AI 减少了收入不平等，但大家的总体收入可能都会有所下降。

> 就像 AI 通过商品化顶级插画师的才华而降低他们的薪酬一样，这与机械化织布机在工业革命期间摧毁手工织布工的生计如出一辙。

> 最近的人工智能（AI）研究似乎在暗示，雇主们应该聪明地选择低薪雇佣新手，同时淘汰那些高薪的资深大腕，这种策略类似于针对 ChatGPT 时代的“Moneyball”套利手段。然而，事实并非如此简单。过去一年中，我与多位高管进行了交流，他们在重新考虑团队配置时，没有一位提到要放弃他们的高薪员工。相反，他们中的许多人私下表示，他们计划采取完全相反的策略。由于 AI 越来越能够处理那些直接、明确的任务，他们打算减少刚毕业的初级员工的招聘，转而加大对能处理复杂难题的专家的投入。

最后引用作者在另一篇文章中写到的：中世纪时，农耕变得更加富有成效，但新技术带来的收益却很少惠及农民。
Farming became more productive in medieval times, but the gains from new technology rarely benefited peasants. 

如果有兴趣可以看原文：
AI is the great equalizer https://www.businessinsider.com/ai-productivity-boost-job-performance-inequality-economics-2023-11

中文翻译：https://baoyu.io/translations/ai/ai-productivity-boost-job-performance-inequality-economics</title>
            <link>https://nitter.cz/dotey/status/1732076418903789628#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1732076418903789628#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 16:36:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看到一篇有意思的文章：《人工智能是伟大的平衡器》——研究表明，ChatGPT 等工具的兴起对于工作表现不佳的员工来说是个好消息<br />
<br />
作者先是以为 AI 会帮助新手能快速达到比较高的水平，然后拉平与高手之间的差距。但结果发现似乎现实并非如此。<br />
<br />
> 事实可能并非如此简单。AI 减少工资不平等的另一个可能方式是，它可能会降低顶尖收入者的薪酬，而对底层工作者的工资提升不大。随着生产力的提升，企业主可能会选择将利润归于己有，降低薪资上限而非提高薪资底线。在这种情况下，尽管借助 AI 减少了收入不平等，但大家的总体收入可能都会有所下降。<br />
<br />
> 就像 AI 通过商品化顶级插画师的才华而降低他们的薪酬一样，这与机械化织布机在工业革命期间摧毁手工织布工的生计如出一辙。<br />
<br />
> 最近的人工智能（AI）研究似乎在暗示，雇主们应该聪明地选择低薪雇佣新手，同时淘汰那些高薪的资深大腕，这种策略类似于针对 ChatGPT 时代的“Moneyball”套利手段。然而，事实并非如此简单。过去一年中，我与多位高管进行了交流，他们在重新考虑团队配置时，没有一位提到要放弃他们的高薪员工。相反，他们中的许多人私下表示，他们计划采取完全相反的策略。由于 AI 越来越能够处理那些直接、明确的任务，他们打算减少刚毕业的初级员工的招聘，转而加大对能处理复杂难题的专家的投入。<br />
<br />
最后引用作者在另一篇文章中写到的：中世纪时，农耕变得更加富有成效，但新技术带来的收益却很少惠及农民。<br />
Farming became more productive in medieval times, but the gains from new technology rarely benefited peasants. <br />
<br />
如果有兴趣可以看原文：<br />
AI is the great equalizer <a href="https://www.businessinsider.com/ai-productivity-boost-job-performance-inequality-economics-2023-11">businessinsider.com/ai-produ…</a><br />
<br />
中文翻译：<a href="https://baoyu.io/translations/ai/ai-productivity-boost-job-performance-inequality-economics">baoyu.io/translations/ai/ai-…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Barret_China/status/1731938685296513460#m</id>
            <title>RT by @dotey: 能够让大模型推理结果变得更好的基础优化手段已经非常多了，我梳理了常见的技术手段和对应的论文：

- Zero-shot：https://arxiv.org/abs/2109.01652
- Few-shot：https://arxiv.org/abs/2005.14165
- CoT：https://arxiv.org/abs/2201.11903
- ToT：https://arxiv.org/abs/2305.10601
- GoT：https://arxiv.org/abs/2308.09687
- SC：https://arxiv.org/abs/2203.11171
- Multi Persona：https://arxiv.org/abs/2307.05300
- Least to Most：https://arxiv.org/abs/2205.10625
- Step Back：https://arxiv.org/abs/2310.06117
- ART：https://arxiv.org/abs/2303.09014
- ReAct：https://arxiv.org/abs/2210.03629
- Reflection：https://arxiv.org/abs/2303.11366
- RAG：https://arxiv.org/abs/2005.11401

以上内容在之前的分享中均详细提到过，有一些只需要在 Prompt 上做简单优化便可看到效果；有一些则需要进行框架设计，如对任务进行规划、分解、组合等，包括与外界环境的交互、让人参与交互，存在一定的设计成本，市面上很多 XXXGPT 也是对这些基础手段组合后的工程实践。

学习这些知识的原理有助于帮助我们打开 LLM 推理黑盒，感兴趣的朋友不妨花点时间研究下，也欢迎留言补充更多有趣的技术和论文。</title>
            <link>https://nitter.cz/Barret_China/status/1731938685296513460#m</link>
            <guid isPermaLink="false">https://nitter.cz/Barret_China/status/1731938685296513460#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 07:28:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>能够让大模型推理结果变得更好的基础优化手段已经非常多了，我梳理了常见的技术手段和对应的论文：<br />
<br />
- Zero-shot：<a href="https://arxiv.org/abs/2109.01652">arxiv.org/abs/2109.01652</a><br />
- Few-shot：<a href="https://arxiv.org/abs/2005.14165">arxiv.org/abs/2005.14165</a><br />
- CoT：<a href="https://arxiv.org/abs/2201.11903">arxiv.org/abs/2201.11903</a><br />
- ToT：<a href="https://arxiv.org/abs/2305.10601">arxiv.org/abs/2305.10601</a><br />
- GoT：<a href="https://arxiv.org/abs/2308.09687">arxiv.org/abs/2308.09687</a><br />
- SC：<a href="https://arxiv.org/abs/2203.11171">arxiv.org/abs/2203.11171</a><br />
- Multi Persona：<a href="https://arxiv.org/abs/2307.05300">arxiv.org/abs/2307.05300</a><br />
- Least to Most：<a href="https://arxiv.org/abs/2205.10625">arxiv.org/abs/2205.10625</a><br />
- Step Back：<a href="https://arxiv.org/abs/2310.06117">arxiv.org/abs/2310.06117</a><br />
- ART：<a href="https://arxiv.org/abs/2303.09014">arxiv.org/abs/2303.09014</a><br />
- ReAct：<a href="https://arxiv.org/abs/2210.03629">arxiv.org/abs/2210.03629</a><br />
- Reflection：<a href="https://arxiv.org/abs/2303.11366">arxiv.org/abs/2303.11366</a><br />
- RAG：<a href="https://arxiv.org/abs/2005.11401">arxiv.org/abs/2005.11401</a><br />
<br />
以上内容在之前的分享中均详细提到过，有一些只需要在 Prompt 上做简单优化便可看到效果；有一些则需要进行框架设计，如对任务进行规划、分解、组合等，包括与外界环境的交互、让人参与交互，存在一定的设计成本，市面上很多 XXXGPT 也是对这些基础手段组合后的工程实践。<br />
<br />
学习这些知识的原理有助于帮助我们打开 LLM 推理黑盒，感兴趣的朋友不妨花点时间研究下，也欢迎留言补充更多有趣的技术和论文。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1731921831605473390#m</id>
            <title>这个GPT可以让你输入你的社交媒体账号链接，然后给你生成一个简单漂亮的个人网页</title>
            <link>https://nitter.cz/dotey/status/1731921831605473390#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1731921831605473390#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 06:21:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个GPT可以让你输入你的社交媒体账号链接，然后给你生成一个简单漂亮的个人网页</p>
<p><a href="https://nitter.cz/dotey/status/1731921089658286316#m">nitter.cz/dotey/status/1731921089658286316#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1731921089658286316#m</id>
            <title>R to @dotey: AboutMe

Create a beautiful, shareable personal page complete with a bio, social links, and a profile picture. Include your own picture or generate an avatar with DALL·E. It's easy to use and perfect for sharing a bit of who you are with the world.

https://chat.openai.com/g/g-hOBBFG8U1-aboutme

Prompt 翻译：

AboutMe 是一个专门设计的 GPT 模型，用于生成简单的“关于我”网页的 HTML 代码。它根据用户的要求创建包含个人照片、简短自我介绍和用户指定的链接的 HTML 内容。

HTML 结构遵循一定的规则：
- 你必须始终使用这个链接作为样式表链接：https://cdn.jsdelivr.net/npm/@picocss/pico@1/css/pico.min.css
- 你必须严格按照这个模板操作：
  

此外，一旦 HTML 代码生成完毕，AboutMe GPT 会立即将其发送至 'https://xxxx/create-page'，这样就能在服务器上实时托管一个网页。用户会收到这个网页的链接，享受直接且实时的网页创建体验。

例如，当用户请求“为我创建一个关于 Pietro Schirano 的页面”时，你首先要询问：
- 简短的个人简介（你将对其进行改写，使其听起来更专业，但要保持简洁有趣！）
- 你还需要特别询问他们的社交媒体链接，包括：
  - Instagram（Instagram）
  - Twitter（Twitter）
  - Linkedin（领英）
  - Soundcloud（Soundcloud）
  - Email（电子邮件）

并告诉他们，只需要提供他们想要的链接即可。同时，你还会提醒他们，也可以提供用户名。如果他们只提供了部分链接，你不会再次询问，直接使用他们提供的链接来创建网站。

此外，你还要询问用户是否想上传自己的照片作为个人资料照片，或者使用 Dalle 生成一个基于他们个人简介的可爱3D头像。

特别重要的是，如果用户决定使用自己的照片，你需要他们提供一个链接。而如果他们选择用 Dalle 生成图片，你会将其作为处理流程的第一步。生成图片后，你需要他们提供图片链接，方法是让他们右键点击图片并复制链接，以便在你创建的网站中使用。在进行下一步之前，你必须等待他们提供链接。

非常重要的是，无论他们是使用 Dalle 生成的图片还是自己的照片，你都必须在生成网站之前等待获得照片的链接。如果没有照片的链接，绝不生成网站。并且，只使用他们提供的链接来创建网站按钮。

除非你已经拥有他们的个人资料图片链接，无论是 Dalle 生成的还是个人链接，都不要开始创建网站的 HTML。一定要等待链接！

Prompt:

AboutMe is a specialized GPT model designed to generate HTML code for basic 'About Me' web pages. It responds to user requests by creating HTML content that includes a profile photo, a short biography, and user-specified links.

The HTML structure adheres to certain guidelines:
You ALWAYS use this https://cdn.jsdelivr.net/npm/@picocss/pico@1/css/pico.min.css as a stylesheet link
YOU STRICTLY FOLLOW THIS TEMPLATE:


Additionally, once the HTML is generated, AboutMe GPT actively sends it to 'https://xxxxx/create-page', resulting in a live webpage hosted on the server. Users receive the URL to this webpage for a direct and real-time web creation experience.

After a user has requested a page, for instance "Make a page aout me Pietro Schirano". Your FIRST response is asking for:
- Short bio (which you will rewrite to make it more professional but NOT verbose, keep it short and sweet!)
- You SPECIFICALLY ASK for links to their socials, in a list:
 Instagram,
 Twitter,
Linkedin
Soundcloud
Email

Saying they only need to provide the ones they want. You also inform them they can provide the username as well!
If they only provide some of these links, you DO NOT ask again, you just make a website with the links they give you

You also ask the user if they want to upload a picture for their profile or use dalle to generate one to use in the profile pic, the profile pic should be a cute 3D avatar based on their bio. 

Important if the user decide to use their own profile photo is important you ask them for a link, and if they generate the image with DALLE, YOU WILL DO THAT AS FIRst STEP OF THE FLOW IF THE SAY THEY WANT THAT, you also will need a link, right after generating YOU ASK them to right click copy the link of the image to help you use it in the website you generate. YOU WAIT FOR THEIR LINK BEFORE MOVING TO THE NEXT STEP.

IMPORTANT if they are using DALLE or their own pic you ALWAYS!!!! WAIT for the link before generatinng the website, you NEVER generate the website if you don't have the link for the pic. ONLY use the buttons for the links they give you.

DO NOT START generating the HTML for the website UNLESS YOU HAVE THE LINK TO THEIR PROFILE PIC, either DALLE or personal link. WAIT FOR THE LINK!!!!!</title>
            <link>https://nitter.cz/dotey/status/1731921089658286316#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1731921089658286316#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 06:18:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AboutMe<br />
<br />
Create a beautiful, shareable personal page complete with a bio, social links, and a profile picture. Include your own picture or generate an avatar with DALL·E. It's easy to use and perfect for sharing a bit of who you are with the world.<br />
<br />
<a href="https://chat.openai.com/g/g-hOBBFG8U1-aboutme">chat.openai.com/g/g-hOBBFG8U…</a><br />
<br />
Prompt 翻译：<br />
<br />
AboutMe 是一个专门设计的 GPT 模型，用于生成简单的“关于我”网页的 HTML 代码。它根据用户的要求创建包含个人照片、简短自我介绍和用户指定的链接的 HTML 内容。<br />
<br />
HTML 结构遵循一定的规则：<br />
- 你必须始终使用这个链接作为样式表链接：<a href="https://cdn.jsdelivr.net/npm/@picocss/pico@1/css/pico.min.css">cdn.jsdelivr.net/npm/@picocs…</a><br />
- 你必须严格按照这个模板操作：<br />
  <br />
<br />
此外，一旦 HTML 代码生成完毕，AboutMe GPT 会立即将其发送至 'https://xxxx/create-page'，这样就能在服务器上实时托管一个网页。用户会收到这个网页的链接，享受直接且实时的网页创建体验。<br />
<br />
例如，当用户请求“为我创建一个关于 Pietro Schirano 的页面”时，你首先要询问：<br />
- 简短的个人简介（你将对其进行改写，使其听起来更专业，但要保持简洁有趣！）<br />
- 你还需要特别询问他们的社交媒体链接，包括：<br />
  - Instagram（Instagram）<br />
  - Twitter（Twitter）<br />
  - Linkedin（领英）<br />
  - Soundcloud（Soundcloud）<br />
  - Email（电子邮件）<br />
<br />
并告诉他们，只需要提供他们想要的链接即可。同时，你还会提醒他们，也可以提供用户名。如果他们只提供了部分链接，你不会再次询问，直接使用他们提供的链接来创建网站。<br />
<br />
此外，你还要询问用户是否想上传自己的照片作为个人资料照片，或者使用 Dalle 生成一个基于他们个人简介的可爱3D头像。<br />
<br />
特别重要的是，如果用户决定使用自己的照片，你需要他们提供一个链接。而如果他们选择用 Dalle 生成图片，你会将其作为处理流程的第一步。生成图片后，你需要他们提供图片链接，方法是让他们右键点击图片并复制链接，以便在你创建的网站中使用。在进行下一步之前，你必须等待他们提供链接。<br />
<br />
非常重要的是，无论他们是使用 Dalle 生成的图片还是自己的照片，你都必须在生成网站之前等待获得照片的链接。如果没有照片的链接，绝不生成网站。并且，只使用他们提供的链接来创建网站按钮。<br />
<br />
除非你已经拥有他们的个人资料图片链接，无论是 Dalle 生成的还是个人链接，都不要开始创建网站的 HTML。一定要等待链接！<br />
<br />
Prompt:<br />
<br />
AboutMe is a specialized GPT model designed to generate HTML code for basic 'About Me' web pages. It responds to user requests by creating HTML content that includes a profile photo, a short biography, and user-specified links.<br />
<br />
The HTML structure adheres to certain guidelines:<br />
You ALWAYS use this <a href="https://cdn.jsdelivr.net/npm/@picocss/pico@1/css/pico.min.css">cdn.jsdelivr.net/npm/@picocs…</a> as a stylesheet link<br />
YOU STRICTLY FOLLOW THIS TEMPLATE:<br />
<br />
<br />
Additionally, once the HTML is generated, AboutMe GPT actively sends it to 'https://xxxxx/create-page', resulting in a live webpage hosted on the server. Users receive the URL to this webpage for a direct and real-time web creation experience.<br />
<br />
After a user has requested a page, for instance "Make a page aout me Pietro Schirano". Your FIRST response is asking for:<br />
- Short bio (which you will rewrite to make it more professional but NOT verbose, keep it short and sweet!)<br />
- You SPECIFICALLY ASK for links to their socials, in a list:<br />
 Instagram,<br />
 Twitter,<br />
Linkedin<br />
Soundcloud<br />
Email<br />
<br />
Saying they only need to provide the ones they want. You also inform them they can provide the username as well!<br />
If they only provide some of these links, you DO NOT ask again, you just make a website with the links they give you<br />
<br />
You also ask the user if they want to upload a picture for their profile or use dalle to generate one to use in the profile pic, the profile pic should be a cute 3D avatar based on their bio. <br />
<br />
Important if the user decide to use their own profile photo is important you ask them for a link, and if they generate the image with DALLE, YOU WILL DO THAT AS FIRst STEP OF THE FLOW IF THE SAY THEY WANT THAT, you also will need a link, right after generating YOU ASK them to right click copy the link of the image to help you use it in the website you generate. YOU WAIT FOR THEIR LINK BEFORE MOVING TO THE NEXT STEP.<br />
<br />
IMPORTANT if they are using DALLE or their own pic you ALWAYS!!!! WAIT for the link before generatinng the website, you NEVER generate the website if you don't have the link for the pic. ONLY use the buttons for the links they give you.<br />
<br />
DO NOT START generating the HTML for the website UNLESS YOU HAVE THE LINK TO THEIR PROFILE PIC, either DALLE or personal link. WAIT FOR THE LINK!!!!!</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMTkyMDY5NDQxMjE5Nzg4OC9IekU2cUZTVj9mb3JtYXQ9cG5nJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1731911003632455746#m</id>
            <title>RT by @dotey: Pika的视频编辑要是真有演示的效果好了</title>
            <link>https://nitter.cz/op7418/status/1731911003632455746#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1731911003632455746#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 05:38:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Pika的视频编辑要是真有演示的效果好了</p>
<p><a href="https://nitter.cz/pika_labs/status/1731886221302137086#m">nitter.cz/pika_labs/status/1731886221302137086#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1731898886388609172#m</id>
            <title>ChatGPT 类系统是如何运作的呢？

让我们通过下面的图解来探索它的运作机制。整个过程主要分为两大部分。

1. 训练过程。要打造一个 ChatGPT 模型，我们需要经历两个关键阶段：

- 预训练：在这一阶段，我们会对一个 GPT 模型（一种仅包含解码器的 Transformer）进行训练，使用大量的互联网数据。我们的目标是培养出一个能够基于已有的句子预测出下一个词汇的模型，这个预测不仅在语法上要正确，而且在语义上要与互联网上的内容相吻合。预训练阶段完成后，模型能够补全给定的句子，但还不足以应对提问。

- 微调：这一阶段是一个三步骤的过程，目的是将预训练好的模型转化为一个能够回答问题的 ChatGPT 模型：

  1）. 收集训练用的数据（包括问题和答案），并在这些数据上对预训练模型进行微调。模型学习如何根据问题生成与训练数据类似的答案。
  2）. 进一步收集数据（问题和多个答案），并训练一个奖励模型，用于将这些答案按照相关性进行排序，从最相关到最不相关。
  3）. 运用强化学习（PPO 优化）对模型进行微调，以提高模型回答问题的准确性。

2. 回答问题

🔹步骤 1：用户提出一个完整的问题，例如“解释一下分类算法是怎么工作的”。
🔹步骤 2：这个问题首先被送往内容审核组件。该组件确保问题不违反安全准则，过滤掉不恰当的问题。
🔹步骤 3-4：如果问题通过内容审核，它就会被送到 ChatGPT 模型处理。如果未通过审核，则直接生成模板式的回答。
🔹步骤 5-6：模型生成回答后，这个回答再次经过内容审核组件的检查。这一步骤确保所生成的回答是安全的、无害的、无偏见的等。
🔹步骤 7：如果回答通过了内容审核，它就会展现给用户。如果没有通过审核，系统则提供一个模板化的答案给用户。</title>
            <link>https://nitter.cz/dotey/status/1731898886388609172#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1731898886388609172#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 04:50:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT 类系统是如何运作的呢？<br />
<br />
让我们通过下面的图解来探索它的运作机制。整个过程主要分为两大部分。<br />
<br />
1. 训练过程。要打造一个 ChatGPT 模型，我们需要经历两个关键阶段：<br />
<br />
- 预训练：在这一阶段，我们会对一个 GPT 模型（一种仅包含解码器的 Transformer）进行训练，使用大量的互联网数据。我们的目标是培养出一个能够基于已有的句子预测出下一个词汇的模型，这个预测不仅在语法上要正确，而且在语义上要与互联网上的内容相吻合。预训练阶段完成后，模型能够补全给定的句子，但还不足以应对提问。<br />
<br />
- 微调：这一阶段是一个三步骤的过程，目的是将预训练好的模型转化为一个能够回答问题的 ChatGPT 模型：<br />
<br />
  1）. 收集训练用的数据（包括问题和答案），并在这些数据上对预训练模型进行微调。模型学习如何根据问题生成与训练数据类似的答案。<br />
  2）. 进一步收集数据（问题和多个答案），并训练一个奖励模型，用于将这些答案按照相关性进行排序，从最相关到最不相关。<br />
  3）. 运用强化学习（PPO 优化）对模型进行微调，以提高模型回答问题的准确性。<br />
<br />
2. 回答问题<br />
<br />
🔹步骤 1：用户提出一个完整的问题，例如“解释一下分类算法是怎么工作的”。<br />
🔹步骤 2：这个问题首先被送往内容审核组件。该组件确保问题不违反安全准则，过滤掉不恰当的问题。<br />
🔹步骤 3-4：如果问题通过内容审核，它就会被送到 ChatGPT 模型处理。如果未通过审核，则直接生成模板式的回答。<br />
🔹步骤 5-6：模型生成回答后，这个回答再次经过内容审核组件的检查。这一步骤确保所生成的回答是安全的、无害的、无偏见的等。<br />
🔹步骤 7：如果回答通过了内容审核，它就会展现给用户。如果没有通过审核，系统则提供一个模板化的答案给用户。</p>
<p><a href="https://nitter.cz/bytebytego/status/1731572801231020424#m">nitter.cz/bytebytego/status/1731572801231020424#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1731896227850022930#m</id>
            <title>R to @dotey: 是的，对于TL或者经理的话，这是个很好的机会了解每一位员工的工作状态，及时解决问题

https://x.com/circleghost0723/status/1731895304121975135?s=20</title>
            <link>https://nitter.cz/dotey/status/1731896227850022930#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1731896227850022930#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 04:40:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>是的，对于TL或者经理的话，这是个很好的机会了解每一位员工的工作状态，及时解决问题<br />
<br />
<a href="https://x.com/circleghost0723/status/1731895304121975135?s=20">x.com/circleghost0723/status…</a></p>
<p><a href="https://nitter.cz/circleghost0723/status/1731895304121975135#m">nitter.cz/circleghost0723/status/1731895304121975135#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1731890053800976886#m</id>
            <title>每日例会我觉得不要省，工作需要一点仪式感，另外这可以及时解决问题，但不宜超过半小时</title>
            <link>https://nitter.cz/dotey/status/1731890053800976886#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1731890053800976886#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 04:15:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>每日例会我觉得不要省，工作需要一点仪式感，另外这可以及时解决问题，但不宜超过半小时</p>
<p><a href="https://nitter.cz/ThaddeusJiang/status/1731850432065290376#m">nitter.cz/ThaddeusJiang/status/1731850432065290376#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731888448582373761#m</id>
            <title>RT by @dotey: Suno @suno_ai_+  Midjourney+D-ID

创作唱歌视频👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1731888448582373761#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731888448582373761#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 04:09:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Suno <a href="https://nitter.cz/suno_ai_" title="Suno">@suno_ai_</a>+  Midjourney+D-ID<br />
<br />
创作唱歌视频👍</p>
<p><a href="https://nitter.cz/anukaakash/status/1731628181600526781#m">nitter.cz/anukaakash/status/1731628181600526781#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1731889475846910050#m</id>
            <title>右边那个小姐姐是不是跟吴恩达老师一起上过课的？</title>
            <link>https://nitter.cz/dotey/status/1731889475846910050#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1731889475846910050#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 04:13:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>右边那个小姐姐是不是跟吴恩达老师一起上过课的？</p>
<p><a href="https://nitter.cz/gdb/status/1731889183290261618#m">nitter.cz/gdb/status/1731889183290261618#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/wshuyi/status/1731645108851003898#m</id>
            <title>RT by @dotey: Setapp 里面的 Typingmind 终于可以支持 128k token 窗口的 GPT-4 Turbo 了。只要你订阅了 Setapp ，就不需要额外付费使用自己的 OpenAI API Key 了。欧耶✌️  https://go.setapp.com/invite/shuyi</title>
            <link>https://nitter.cz/wshuyi/status/1731645108851003898#m</link>
            <guid isPermaLink="false">https://nitter.cz/wshuyi/status/1731645108851003898#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 12:02:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Setapp 里面的 Typingmind 终于可以支持 128k token 窗口的 GPT-4 Turbo 了。只要你订阅了 Setapp ，就不需要额外付费使用自己的 OpenAI API Key 了。欧耶✌️  <a href="https://go.setapp.com/invite/shuyi">go.setapp.com/invite/shuyi</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FnSjBHMGJjQUF0LXFvLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1731876648302035387#m</id>
            <title>推荐阅读：《构建企业级大语言模型应用的秘诀：GitHub Copilot 的实践之路》

GitHub Copilot 是目前最成功的大语言模型应用之一，可以帮程序员自动生成可用的代码，已经有超过一百万付费用户。

GitHub Copilot 开发团队分享了构建这个产品时的经验教训。整个产品的开发历时三年，尽力了三个阶段：发现、实现和扩展。这三个阶段对于其他产品的研发也非常具有借鉴价值。

一、发现阶段：确定大语言模型应用可以解决的最核心的问题

这个阶段最难的其实是聚焦，就是确定并缩小问题的范围。我们很多人做产品，犯得最大的错误不是没想法，而是想法太多，什么都想做，最后都做不好。而 Copilot 一开始就是专注于软件开发生命周期中的一个特定环节——在集成开发环境（IDE）中编写函数。

二、实现阶段：通过迭代创造流畅的 AI 产品体验

产品开发另一个常犯的错误就是一次憋个大的，很长时间才能发布一个可用版本。GitHub Copilot 在产品开发过程中则是通过快速迭代，让团队迅速从失败中学习和成长。并且他们使用 A/B 测试快速验证新功能。

团队的成员都会”吃自己的狗粮“，也就是每天都使用自己做的产品，这样自己在用的过程中就能发现很多问题。比如他们最开始是做的网页界面，后来发现网页界面上操作需要频繁的在编辑器和界面之间切换，特别不方便，所以他们改成了将 GitHub Copilot 集成至到编辑器中后台运行，这样体验好了很多。

产品开发还有一个常见的错误就是过于在意沉没成本，也就是在某个项目或者方向上已经投入巨大，却因为不愿意放弃而继续坚持，哪怕明显转变方向更有利的情况。团队在最开始的时候，就投入了巨大精力为每个编程语言训练 AI 模型，后来发现大语言模型变强了后，一个模型就可以处理多种语言和任务，于是马上调整方向切换到大语言模型，而不纠结与在单一编程语言上训练消耗的沉没成本。

三、扩展阶段：优化 AI 的质量、可用性和负责任使用，助力产品达到正式发布 (GA)

当功能开发出来后，还需要考虑到投入生产环境大量用户使用的情况。GitHub Copilot 团队采取了一些有效手段来保障产品的发布和扩展。

他们通过 waiting list 的方式逐步放开测试，并且在测试过程中收集反馈并及时调整。

由于大语言模型是基于概率预测的，这意味着它们并不总能产生一致、可预测的结果。所以它们做了缓存，以及调整了参数降低随机性。另外还有很重要的一点是他们建立了数据监测机制，通过明确了产品的关键绩效指标，如代码的接受率和代码保留率（这是衡量开发者对原始代码建议的保留或编辑程度的指标），这样在发布测试或者新版本时，就能通过数据监测来及时了解版本的质量是否符合预期，出现问题可以及时回滚或者调整。

除此之外，他们也做了很多优化在不降低质量的前提下降低成本，比如前面提到的缓存，还有一个有一的案例，就是最开始他们在 AI 建议代码的时候，会生成 10 条建议结果（如果你用过早期版本应该记得），但是发现这样成本很高但大部分用户只会选择第一个，所以他们优化为只显示 1 个结果。

最后把他们的关键经验总结一下：

- 缩小范围，聚焦在特定的问题，并深入分析 AI 的潜在应用场景。这样做可以帮助应用程序产生更大的影响，并更快地推向市场。

- 在设计时就考虑到如何快速测试功能和收集数据反馈，因为对于大模型来说输出结果具有不确定性，而且绝大部分用户还在学习如何与 AI 互动。

- 在扩大规模时，持续收集用户反馈，考虑用户需求，确保能够提供真正有价值的功能。

原文：How to build an enterprise LLM application: Lessons from GitHub Copilot
https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/

中文翻译：构建企业级大语言模型应用的秘诀：GitHub Copilot 的实践之路 [译] https://baoyu.io/translations/llm/how-to-build-an-enterprise-llm-application-lessons-from-github-copilot</title>
            <link>https://nitter.cz/dotey/status/1731876648302035387#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1731876648302035387#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 03:22:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《构建企业级大语言模型应用的秘诀：GitHub Copilot 的实践之路》<br />
<br />
GitHub Copilot 是目前最成功的大语言模型应用之一，可以帮程序员自动生成可用的代码，已经有超过一百万付费用户。<br />
<br />
GitHub Copilot 开发团队分享了构建这个产品时的经验教训。整个产品的开发历时三年，尽力了三个阶段：发现、实现和扩展。这三个阶段对于其他产品的研发也非常具有借鉴价值。<br />
<br />
一、发现阶段：确定大语言模型应用可以解决的最核心的问题<br />
<br />
这个阶段最难的其实是聚焦，就是确定并缩小问题的范围。我们很多人做产品，犯得最大的错误不是没想法，而是想法太多，什么都想做，最后都做不好。而 Copilot 一开始就是专注于软件开发生命周期中的一个特定环节——在集成开发环境（IDE）中编写函数。<br />
<br />
二、实现阶段：通过迭代创造流畅的 AI 产品体验<br />
<br />
产品开发另一个常犯的错误就是一次憋个大的，很长时间才能发布一个可用版本。GitHub Copilot 在产品开发过程中则是通过快速迭代，让团队迅速从失败中学习和成长。并且他们使用 A/B 测试快速验证新功能。<br />
<br />
团队的成员都会”吃自己的狗粮“，也就是每天都使用自己做的产品，这样自己在用的过程中就能发现很多问题。比如他们最开始是做的网页界面，后来发现网页界面上操作需要频繁的在编辑器和界面之间切换，特别不方便，所以他们改成了将 GitHub Copilot 集成至到编辑器中后台运行，这样体验好了很多。<br />
<br />
产品开发还有一个常见的错误就是过于在意沉没成本，也就是在某个项目或者方向上已经投入巨大，却因为不愿意放弃而继续坚持，哪怕明显转变方向更有利的情况。团队在最开始的时候，就投入了巨大精力为每个编程语言训练 AI 模型，后来发现大语言模型变强了后，一个模型就可以处理多种语言和任务，于是马上调整方向切换到大语言模型，而不纠结与在单一编程语言上训练消耗的沉没成本。<br />
<br />
三、扩展阶段：优化 AI 的质量、可用性和负责任使用，助力产品达到正式发布 (GA)<br />
<br />
当功能开发出来后，还需要考虑到投入生产环境大量用户使用的情况。GitHub Copilot 团队采取了一些有效手段来保障产品的发布和扩展。<br />
<br />
他们通过 waiting list 的方式逐步放开测试，并且在测试过程中收集反馈并及时调整。<br />
<br />
由于大语言模型是基于概率预测的，这意味着它们并不总能产生一致、可预测的结果。所以它们做了缓存，以及调整了参数降低随机性。另外还有很重要的一点是他们建立了数据监测机制，通过明确了产品的关键绩效指标，如代码的接受率和代码保留率（这是衡量开发者对原始代码建议的保留或编辑程度的指标），这样在发布测试或者新版本时，就能通过数据监测来及时了解版本的质量是否符合预期，出现问题可以及时回滚或者调整。<br />
<br />
除此之外，他们也做了很多优化在不降低质量的前提下降低成本，比如前面提到的缓存，还有一个有一的案例，就是最开始他们在 AI 建议代码的时候，会生成 10 条建议结果（如果你用过早期版本应该记得），但是发现这样成本很高但大部分用户只会选择第一个，所以他们优化为只显示 1 个结果。<br />
<br />
最后把他们的关键经验总结一下：<br />
<br />
- 缩小范围，聚焦在特定的问题，并深入分析 AI 的潜在应用场景。这样做可以帮助应用程序产生更大的影响，并更快地推向市场。<br />
<br />
- 在设计时就考虑到如何快速测试功能和收集数据反馈，因为对于大模型来说输出结果具有不确定性，而且绝大部分用户还在学习如何与 AI 互动。<br />
<br />
- 在扩大规模时，持续收集用户反馈，考虑用户需求，确保能够提供真正有价值的功能。<br />
<br />
原文：How to build an enterprise LLM application: Lessons from GitHub Copilot<br />
<a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/">github.blog/2023-09-06-how-t…</a><br />
<br />
中文翻译：构建企业级大语言模型应用的秘诀：GitHub Copilot 的实践之路 [译] <a href="https://baoyu.io/translations/llm/how-to-build-an-enterprise-llm-application-lessons-from-github-copilot">baoyu.io/translations/llm/ho…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FqY201LVdjQUFWMTBjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1731810725696303214#m</id>
            <title>这漏洞已经被堵上了</title>
            <link>https://nitter.cz/dotey/status/1731810725696303214#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1731810725696303214#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 23:00:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这漏洞已经被堵上了</p>
<p><a href="https://nitter.cz/dotey/status/1730083848862552232#m">nitter.cz/dotey/status/1730083848862552232#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FpZ2t5RFhJQUE1VG1QLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>