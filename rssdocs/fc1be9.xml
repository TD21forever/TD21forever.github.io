<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757619736190607858#m</id>
            <title>RT by @op7418: Perplexity的热点推送做得真不错，可以自动整理对应热点信息的所有内容，给出完整的事件经过和背景。还有引用来源。
比如Andrej Karpathy 离职这个事情，还有一个就是你可以直接让他把整理的内容翻译成中文，非常方便。

专题链接在这里：https://www.perplexity.ai/search/Andrej-Karpathy-left-iRRPSPFZSCSC6nvrhCvtWg?s=c</title>
            <link>https://nitter.cz/op7418/status/1757619736190607858#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757619736190607858#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 04:16:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity的热点推送做得真不错，可以自动整理对应热点信息的所有内容，给出完整的事件经过和背景。还有引用来源。<br />
比如Andrej Karpathy 离职这个事情，还有一个就是你可以直接让他把整理的内容翻译成中文，非常方便。<br />
<br />
专题链接在这里：<a href="https://www.perplexity.ai/search/Andrej-Karpathy-left-iRRPSPFZSCSC6nvrhCvtWg?s=c">perplexity.ai/search/Andrej-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dSUjBpamFnQUFrWUthLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dSUjBpZ2FjQUFLN1BDLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757754279463633082#m</id>
            <title>R to @op7418: 一个 A1111 Web UI 上运行Stable Cascade的插件：
https://github.com/blue-pen5805/sdweb-easy-stablecascade-diffusers</title>
            <link>https://nitter.cz/op7418/status/1757754279463633082#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757754279463633082#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 13:10:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个 A1111 Web UI 上运行Stable Cascade的插件：<br />
<a href="https://github.com/blue-pen5805/sdweb-easy-stablecascade-diffusers">github.com/blue-pen5805/sdwe…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc1NzYyMDk2MTY0ODc2Njk3Ni9PUHJIaC1GMD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757754060953010476#m</id>
            <title>R to @op7418: 一个只需要 12G 显存就能运行Stable Cascade的 ComfyUI 插件：
https://github.com/ccvv804/ComfyUI-DiffusersStableCascade-LowVRAM</title>
            <link>https://nitter.cz/op7418/status/1757754060953010476#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757754060953010476#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 13:10:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个只需要 12G 显存就能运行Stable Cascade的 ComfyUI 插件：<br />
<a href="https://github.com/ccvv804/ComfyUI-DiffusersStableCascade-LowVRAM">github.com/ccvv804/ComfyUI-D…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc1Nzc1NDA2MzQ2NTQ1OTcxMy9KeTRST0RYeT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757753898855801119#m</id>
            <title>R to @op7418: 一个使用Stable Cascade的ComfyUI 插件
https://github.com/kijai/ComfyUI-DiffusersStableCascade</title>
            <link>https://nitter.cz/op7418/status/1757753898855801119#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757753898855801119#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 13:09:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个使用Stable Cascade的ComfyUI 插件<br />
<a href="https://github.com/kijai/ComfyUI-DiffusersStableCascade">github.com/kijai/ComfyUI-Dif…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc1NzQzMjMzMzI5NTI4ODMyMC9Jd2VFU0Y4Uz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757753726977368276#m</id>
            <title>开源社区对Stable Cascade的支持非常迅速，不过现在使用Stable Cascade的成本还是有些高的，起码需要 12G 显存。

同时 Comfyui 官方会在本周六前支持Stable Cascade。

这里有其他人的测试图片，👇还有Stable Cascade的各种使用渠道。</title>
            <link>https://nitter.cz/op7418/status/1757753726977368276#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757753726977368276#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 13:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>开源社区对Stable Cascade的支持非常迅速，不过现在使用Stable Cascade的成本还是有些高的，起码需要 12G 显存。<br />
<br />
同时 Comfyui 官方会在本周六前支持Stable Cascade。<br />
<br />
这里有其他人的测试图片，👇还有Stable Cascade的各种使用渠道。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dUTFotR2FzQUFpdnJ4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dUTGZTaGJRQUEweWRlLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dUTGlqTGJRQUFTQzNKLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dUTGxTX2FFQUFfSlV6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757743970371948883#m</id>
            <title>黑神话悟空今天发了龙年贺岁的短片，但是一点游戏画面没有比较可惜，刚好音乐又非常好听。

于是就着音乐整个了 MV，借这个 MV 祝大家，乾坤处处结人缘，大地逍遥游遍。

Midjourney+Runway+Pixverse+CapCut #aivideo</title>
            <link>https://nitter.cz/op7418/status/1757743970371948883#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757743970371948883#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 12:29:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>黑神话悟空今天发了龙年贺岁的短片，但是一点游戏画面没有比较可惜，刚好音乐又非常好听。<br />
<br />
于是就着音乐整个了 MV，借这个 MV 祝大家，乾坤处处结人缘，大地逍遥游遍。<br />
<br />
Midjourney+Runway+Pixverse+CapCut <a href="https://nitter.cz/search?q=%23aivideo">#aivideo</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTc3NDM2MzM4MjA5NTg3MjAvcHUvaW1nL0VMeEx6TjhtUzNPNHk4bEouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757626444258435182#m</id>
            <title>Andrej Karpathy 关于自己从 Open AI离职的声明：

大家好，确实，我昨天刚刚离开了OpenAI。

首先要说的是，这并非因为发生了什么特别的事件或问题，也不涉及任何戏剧性的变故（不过，大家继续提出的各种阴谋论还是挺有趣的:））。

其实，过去大约一年在OpenAI的经历非常棒——团队实力强大，同事们非常棒，而且OpenAI的发展规划也极具吸引力，我相信我们都有很多值得期待的事情。目前，我打算专注于我的个人项目，看看能碰到什么新奇的事。那些一直关注我的朋友，可能对我接下来会做什么已经有所预期了;) 再会！</title>
            <link>https://nitter.cz/op7418/status/1757626444258435182#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757626444258435182#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 04:42:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Andrej Karpathy 关于自己从 Open AI离职的声明：<br />
<br />
大家好，确实，我昨天刚刚离开了OpenAI。<br />
<br />
首先要说的是，这并非因为发生了什么特别的事件或问题，也不涉及任何戏剧性的变故（不过，大家继续提出的各种阴谋论还是挺有趣的:））。<br />
<br />
其实，过去大约一年在OpenAI的经历非常棒——团队实力强大，同事们非常棒，而且OpenAI的发展规划也极具吸引力，我相信我们都有很多值得期待的事情。目前，我打算专注于我的个人项目，看看能碰到什么新奇的事。那些一直关注我的朋友，可能对我接下来会做什么已经有所预期了;) 再会！</p>
<p><a href="https://nitter.cz/karpathy/status/1757600075281547344#m">nitter.cz/karpathy/status/1757600075281547344#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757605863504904635#m</id>
            <title>各位情人节加大年初五快乐啊，不过貌似都在迎财神没人管情人。

跟朋友们做了个情人节小项目，输入图片和想说的话可以生成一张花朵的拍立得照片。

感兴趣可以玩玩。如果觉得不错可以介绍给朋友们试试，生成时间稍微有点长可以耐心等一会。

扫描图片二维码就可以参与。</title>
            <link>https://nitter.cz/op7418/status/1757605863504904635#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757605863504904635#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 03:21:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>各位情人节加大年初五快乐啊，不过貌似都在迎财神没人管情人。<br />
<br />
跟朋友们做了个情人节小项目，输入图片和想说的话可以生成一张花朵的拍立得照片。<br />
<br />
感兴趣可以玩玩。如果觉得不错可以介绍给朋友们试试，生成时间稍微有点长可以耐心等一会。<br />
<br />
扫描图片二维码就可以参与。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dSRk5mWmJZQUFsMmZCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757318955713384723#m</id>
            <title>RT by @op7418: Stability AI产量很高啊，推出了一个新的 AI 图像生成模型Stable Cascade，还会发布对应的微调、ControlNet 和 LoRA 训练的脚本。

这个模型基于Würstchen架构，可以显著降低模型训练的算力成本，比 SD2.1 的算力成本降低了 10 倍左右。另外推理速度会比现有的 SD 模型快一倍左右。

更多功能：

除了标准的文本到图像生成之外，Stable Cascade 还可以执行图像变化和图像到图像生成。

会跟随模型一起发布的 Controlnet：

局部重绘：输入与文本提示附带的蒙版配对的图像。该模型根据提供的文本提示填充图像的遮罩部分。

Canny Edge：通过跟踪输入到模型的现有图像的边缘来生成新图像。该测试也可以从草图进行扩展。

2x超分辨率：也可用于C阶段生成的潜在空间。

了解更多：https://ja.stability.ai/blog/stable-cascade</title>
            <link>https://nitter.cz/op7418/status/1757318955713384723#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757318955713384723#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 08:21:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI产量很高啊，推出了一个新的 AI 图像生成模型Stable Cascade，还会发布对应的微调、ControlNet 和 LoRA 训练的脚本。<br />
<br />
这个模型基于Würstchen架构，可以显著降低模型训练的算力成本，比 SD2.1 的算力成本降低了 10 倍左右。另外推理速度会比现有的 SD 模型快一倍左右。<br />
<br />
更多功能：<br />
<br />
除了标准的文本到图像生成之外，Stable Cascade 还可以执行图像变化和图像到图像生成。<br />
<br />
会跟随模型一起发布的 Controlnet：<br />
<br />
局部重绘：输入与文本提示附带的蒙版配对的图像。该模型根据提供的文本提示填充图像的遮罩部分。<br />
<br />
Canny Edge：通过跟踪输入到模型的现有图像的边缘来生成新图像。该测试也可以从草图进行扩展。<br />
<br />
2x超分辨率：也可用于C阶段生成的潜在空间。<br />
<br />
了解更多：<a href="https://ja.stability.ai/blog/stable-cascade">ja.stability.ai/blog/stable-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dNLU0tZGIwQUF1S0FqLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757325374860787911#m</id>
            <title>RT by @op7418: 试了一下Leiapix 这个可以提取图片深度信息，然后生成运镜视频的产品。

效果还挺好的，自定义选项也很丰富，一些简单的场景运镜视频不用视频生成工具用这个也挺好。

直接上传图片然后再右侧调整选项就行。

这里尝试：https://www.leiapix.com/</title>
            <link>https://nitter.cz/op7418/status/1757325374860787911#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757325374860787911#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 08:46:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>试了一下Leiapix 这个可以提取图片深度信息，然后生成运镜视频的产品。<br />
<br />
效果还挺好的，自定义选项也很丰富，一些简单的场景运镜视频不用视频生成工具用这个也挺好。<br />
<br />
直接上传图片然后再右侧调整选项就行。<br />
<br />
这里尝试：<a href="https://www.leiapix.com/">leiapix.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTczMjUzMjkyMTgyNzMyODAvcHUvaW1nL29oeGpuZ19DeklvTkY1eS0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757340944402440239#m</id>
            <title>RT by @op7418: KREA 发布了他们图像放大功能的 2.0 版本，从演示来看似乎跟 Magnific AI 不相上下了。

可以免费试用，但是需要排队，时长有点离谱，不过整体来看还是比Magnific AI便宜。

这里尝试：https://www.krea.ai/apps/image/enhancer</title>
            <link>https://nitter.cz/op7418/status/1757340944402440239#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757340944402440239#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 09:48:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>KREA 发布了他们图像放大功能的 2.0 版本，从演示来看似乎跟 Magnific AI 不相上下了。<br />
<br />
可以免费试用，但是需要排队，时长有点离谱，不过整体来看还是比Magnific AI便宜。<br />
<br />
这里尝试：<a href="https://www.krea.ai/apps/image/enhancer">krea.ai/apps/image/enhancer</a></p>
<p><a href="https://nitter.cz/krea_ai/status/1757338152933662855#m">nitter.cz/krea_ai/status/1757338152933662855#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757327426747764996#m</id>
            <title>RT by @op7418: ComfyUI ProPost一个非常有意思的节点，可以为你生成的图片添加各种丰富的效果，比如胶片颗粒、暗角、模糊等等，帮助生成图片的质感获得极大的提升。

你还可以对这些效果组合使用，比如下面这张图。

支持的效果有：

胶片颗粒：它可以创建不同的噪声类型和图案，并且可用于创建各种胶片颗粒外观。

晕影效果：使屏幕边缘变暗。

径向模糊：让你模糊图像的边缘。

深度图模糊：允许根据深度图模糊图像。可以将其与现有的深度图节点结合使用。

应用 LUT 滤镜：允许将 3D LUT 应用到图像。目前它仅支持 CUBE 格式的 3D LUT。

项目地址：https://github.com/digitaljohn/comfyui-propost#depth-map-blur</title>
            <link>https://nitter.cz/op7418/status/1757327426747764996#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757327426747764996#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 08:54:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI ProPost一个非常有意思的节点，可以为你生成的图片添加各种丰富的效果，比如胶片颗粒、暗角、模糊等等，帮助生成图片的质感获得极大的提升。<br />
<br />
你还可以对这些效果组合使用，比如下面这张图。<br />
<br />
支持的效果有：<br />
<br />
胶片颗粒：它可以创建不同的噪声类型和图案，并且可用于创建各种胶片颗粒外观。<br />
<br />
晕影效果：使屏幕边缘变暗。<br />
<br />
径向模糊：让你模糊图像的边缘。<br />
<br />
深度图模糊：允许根据深度图模糊图像。可以将其与现有的深度图节点结合使用。<br />
<br />
应用 LUT 滤镜：允许将 3D LUT 应用到图像。目前它仅支持 CUBE 格式的 3D LUT。<br />
<br />
项目地址：<a href="https://github.com/digitaljohn/comfyui-propost#depth-map-blur">github.com/digitaljohn/comfy…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dOSDV0WmE0QUFSUkFyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757540459617149245#m</id>
            <title>英伟达发布了一个可以在 PC 使用的本地 AI 聊天软件Chat with RTX。

可以使用 Chat with RTX 连接到你的内容的自定义聊天机器人。使用 RAG 和 TensorRT-LLM 在 RTX 加速的 PC 上本地进行聊天。</title>
            <link>https://nitter.cz/op7418/status/1757540459617149245#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757540459617149245#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 23:01:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>英伟达发布了一个可以在 PC 使用的本地 AI 聊天软件Chat with RTX。<br />
<br />
可以使用 Chat with RTX 连接到你的内容的自定义聊天机器人。使用 RAG 和 TensorRT-LLM 在 RTX 加速的 PC 上本地进行聊天。</p>
<p><a href="https://nitter.cz/NVIDIAAI/status/1757483567708307657#m">nitter.cz/NVIDIAAI/status/1757483567708307657#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1757513969852452900#m</id>
            <title>RT by @op7418: ChatGPT 增加了记忆功能及控制选项，可以记住你在对话中提到的内容，当然你可以控制打开或者关闭，也可以有无记忆对话的临时聊天选项。

具体是你在与 ChatGPT 的对话中，你可以要求它记住特定的信息，或者让它自动捕获细节。随着使用频率的增加，ChatGPT 的记忆功能将逐渐优化，带来显著的改进。

GPT 的记忆是独立的，和ChatGPT不共享，GPT的作者可以选择是否打开。

具体可以看其博客内容：https://openai.com/blog/memory-and-new-controls-for-chatgpt

***

ChatGPT 新增记忆功能及控制选项

我们正在对 ChatGPT 引入记忆功能进行测试。这项功能能让 ChatGPT 记住你在所有对话中提及的信息，避免你重复输入相同的信息，从而让未来的交流更加高效。

ChatGPT 的记忆功能完全由你控制。你可以直接告诉它需要记住的内容，查询它记住了哪些信息，或是通过对话和设置命令让它忘记某些内容。此外，你还可以选择完全关闭此功能。

我们计划本周开始向部分 ChatGPT 免费及 Plus 用户推出这一功能，以评估其实用性，并将基于反馈计划后续的全面推广。

记忆功能工作原理

在与 ChatGPT 的对话中，你可以要求它记住特定的信息，或者让它自动捕获细节。随着使用频率的增加，ChatGPT 的记忆功能将逐渐优化，带来显著的改进。举例来说：

* 若你指定会议记录需包括标题、要点和底部的行动项总结，ChatGPT 将记住并按此方式整理会议摘要。
* 如果你提到自己拥有一家社区咖啡店，当需要策划庆祝新店开业的社交媒体帖子时，ChatGPT 会知道从何入手。
* 当你提及有一个喜欢水母的幼儿，需要帮助设计她的生日卡时，ChatGPT 会建议一个戴着派对帽的水母设计。
* 作为一名管理25名学生的幼儿园老师，你偏好50分钟的课程加上后续活动，ChatGPT 会在帮助你制定课程计划时记住这一点。

数据控制权在你手中

你可以随时通过设置关闭记忆功能（设置 > 个性化 > 记忆）。关闭后，ChatGPT 将不再创建或调用记忆。

若需让 ChatGPT 忘记某事，只需直接告诉它即可。你还可以在设置中查看、删除特定记忆或清空所有记忆（设置 > 个性化 > 管理记忆）。值得注意的是，ChatGPT 的记忆是基于你的互动逐步构建的，与特定对话无关。删除某个对话不会删除相应的记忆，需要手动清除。更多详情可参见我们的帮助中心。

我们可能会使用你向 ChatGPT 提供的内容，包括记忆信息，来改进我们的模型，以惠及所有用户。如果你选择，可以通过数据控制选项关闭此功能。如同往常，我们不会利用 ChatGPT Team 和企业客户的内容进行模型训练。欲了解更多关于我们如何使用数据改进模型性能的信息，请访问帮助中心。

无记忆对话的临时聊天选项

如果你希望进行一次不留下记忆的对话，可以选择使用临时聊天功能。临时聊天不会被保存在历史记录中，也不会用于模型训练。更多关于临时聊天的信息，请参阅我们的帮助中心。

自定义指令功能增强 ChatGPT 的实用性

自定义指令功能允许你向 ChatGPT 提供具体指南，明确你希望它了解的信息及回应方式。无论是明确的指令还是通过对话共享的信息，ChatGPT 均能记住相关细节，以便更好地为你服务。

记忆功能引入的隐私与安全更新

记忆功能的引入考虑到了额外的隐私和安全因素，比如哪些信息应该被记忆以及如何使用这些信息。我们正采取措施来评估并减轻偏见，指导 ChatGPT 避免主动记住敏感信息，比如你的健康细节，除非你明确请求。

团队和企业用户的高效工作体验

对于企业和团队用户，记忆功能在工作中的应用可大大提高效率。ChatGPT 能够学习并记住你的风格和偏好，并在此基础上提供更加相关和有见地的回答。如：

* ChatGPT 能记住你的写作风格和格式要求，自动应用于博客草稿，无需你重复指导。
* 在编程时，一旦你告知了 ChatGPT 你使用的编程语言和框架，它会记住这些偏好，使后续任务更加高效。
* 在进行月度商业回顾时，你只需将数据安全上传给 ChatGPT，它便能按照你的偏好制作图表，并为每个图表提炼出三个关键点。

正如任何 ChatGPT 功能一样，你完全控制着组织数据的使用。在工作空间中的记忆及其他信息不会被用来训练我们的模型。用户可以自主选择何时以及如何在对话中利用记忆功能。此外，企业账户的所有者可以随时为他们的组织关闭记忆功能。

企业和团队用户在我们广泛推出的过程中，将能够访问记忆功能。

GPT 的记忆是独立的

GPT 将具有其独立的记忆功能。开发者可以选择为他们的 GPT 启用记忆。与你的对话记忆一样，GPT 的记忆不会与开发者共享。为了与启用记忆的 GPT 交互，你也需要开启记忆功能。例如：

* Books GPT 助你发现下一本阅读书籍。开启记忆功能后，它能够记住你的阅读偏好，如最爱的书籍类型或书籍，并据此调整推荐，无需你反复输入。
* 由于每个 GPT 都有自己的记忆，因此你可能需要重复之前已经与 ChatGPT 分享的细节。比如：
*当你使用 Artful Greeting Card GPT 为你女儿制作生日卡时，它不会知道她的年龄或她喜欢水母。你需要告诉它相关细节。

随着我们的广泛推出，GPT 的记忆功能将变得可用。</title>
            <link>https://nitter.cz/dotey/status/1757513969852452900#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1757513969852452900#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 21:15:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT 增加了记忆功能及控制选项，可以记住你在对话中提到的内容，当然你可以控制打开或者关闭，也可以有无记忆对话的临时聊天选项。<br />
<br />
具体是你在与 ChatGPT 的对话中，你可以要求它记住特定的信息，或者让它自动捕获细节。随着使用频率的增加，ChatGPT 的记忆功能将逐渐优化，带来显著的改进。<br />
<br />
GPT 的记忆是独立的，和ChatGPT不共享，GPT的作者可以选择是否打开。<br />
<br />
具体可以看其博客内容：<a href="https://openai.com/blog/memory-and-new-controls-for-chatgpt">openai.com/blog/memory-and-n…</a><br />
<br />
***<br />
<br />
ChatGPT 新增记忆功能及控制选项<br />
<br />
我们正在对 ChatGPT 引入记忆功能进行测试。这项功能能让 ChatGPT 记住你在所有对话中提及的信息，避免你重复输入相同的信息，从而让未来的交流更加高效。<br />
<br />
ChatGPT 的记忆功能完全由你控制。你可以直接告诉它需要记住的内容，查询它记住了哪些信息，或是通过对话和设置命令让它忘记某些内容。此外，你还可以选择完全关闭此功能。<br />
<br />
我们计划本周开始向部分 ChatGPT 免费及 Plus 用户推出这一功能，以评估其实用性，并将基于反馈计划后续的全面推广。<br />
<br />
记忆功能工作原理<br />
<br />
在与 ChatGPT 的对话中，你可以要求它记住特定的信息，或者让它自动捕获细节。随着使用频率的增加，ChatGPT 的记忆功能将逐渐优化，带来显著的改进。举例来说：<br />
<br />
* 若你指定会议记录需包括标题、要点和底部的行动项总结，ChatGPT 将记住并按此方式整理会议摘要。<br />
* 如果你提到自己拥有一家社区咖啡店，当需要策划庆祝新店开业的社交媒体帖子时，ChatGPT 会知道从何入手。<br />
* 当你提及有一个喜欢水母的幼儿，需要帮助设计她的生日卡时，ChatGPT 会建议一个戴着派对帽的水母设计。<br />
* 作为一名管理25名学生的幼儿园老师，你偏好50分钟的课程加上后续活动，ChatGPT 会在帮助你制定课程计划时记住这一点。<br />
<br />
数据控制权在你手中<br />
<br />
你可以随时通过设置关闭记忆功能（设置 > 个性化 > 记忆）。关闭后，ChatGPT 将不再创建或调用记忆。<br />
<br />
若需让 ChatGPT 忘记某事，只需直接告诉它即可。你还可以在设置中查看、删除特定记忆或清空所有记忆（设置 > 个性化 > 管理记忆）。值得注意的是，ChatGPT 的记忆是基于你的互动逐步构建的，与特定对话无关。删除某个对话不会删除相应的记忆，需要手动清除。更多详情可参见我们的帮助中心。<br />
<br />
我们可能会使用你向 ChatGPT 提供的内容，包括记忆信息，来改进我们的模型，以惠及所有用户。如果你选择，可以通过数据控制选项关闭此功能。如同往常，我们不会利用 ChatGPT Team 和企业客户的内容进行模型训练。欲了解更多关于我们如何使用数据改进模型性能的信息，请访问帮助中心。<br />
<br />
无记忆对话的临时聊天选项<br />
<br />
如果你希望进行一次不留下记忆的对话，可以选择使用临时聊天功能。临时聊天不会被保存在历史记录中，也不会用于模型训练。更多关于临时聊天的信息，请参阅我们的帮助中心。<br />
<br />
自定义指令功能增强 ChatGPT 的实用性<br />
<br />
自定义指令功能允许你向 ChatGPT 提供具体指南，明确你希望它了解的信息及回应方式。无论是明确的指令还是通过对话共享的信息，ChatGPT 均能记住相关细节，以便更好地为你服务。<br />
<br />
记忆功能引入的隐私与安全更新<br />
<br />
记忆功能的引入考虑到了额外的隐私和安全因素，比如哪些信息应该被记忆以及如何使用这些信息。我们正采取措施来评估并减轻偏见，指导 ChatGPT 避免主动记住敏感信息，比如你的健康细节，除非你明确请求。<br />
<br />
团队和企业用户的高效工作体验<br />
<br />
对于企业和团队用户，记忆功能在工作中的应用可大大提高效率。ChatGPT 能够学习并记住你的风格和偏好，并在此基础上提供更加相关和有见地的回答。如：<br />
<br />
* ChatGPT 能记住你的写作风格和格式要求，自动应用于博客草稿，无需你重复指导。<br />
* 在编程时，一旦你告知了 ChatGPT 你使用的编程语言和框架，它会记住这些偏好，使后续任务更加高效。<br />
* 在进行月度商业回顾时，你只需将数据安全上传给 ChatGPT，它便能按照你的偏好制作图表，并为每个图表提炼出三个关键点。<br />
<br />
正如任何 ChatGPT 功能一样，你完全控制着组织数据的使用。在工作空间中的记忆及其他信息不会被用来训练我们的模型。用户可以自主选择何时以及如何在对话中利用记忆功能。此外，企业账户的所有者可以随时为他们的组织关闭记忆功能。<br />
<br />
企业和团队用户在我们广泛推出的过程中，将能够访问记忆功能。<br />
<br />
GPT 的记忆是独立的<br />
<br />
GPT 将具有其独立的记忆功能。开发者可以选择为他们的 GPT 启用记忆。与你的对话记忆一样，GPT 的记忆不会与开发者共享。为了与启用记忆的 GPT 交互，你也需要开启记忆功能。例如：<br />
<br />
* Books GPT 助你发现下一本阅读书籍。开启记忆功能后，它能够记住你的阅读偏好，如最爱的书籍类型或书籍，并据此调整推荐，无需你反复输入。<br />
* 由于每个 GPT 都有自己的记忆，因此你可能需要重复之前已经与 ChatGPT 分享的细节。比如：<br />
*当你使用 Artful Greeting Card GPT 为你女儿制作生日卡时，它不会知道她的年龄或她喜欢水母。你需要告诉它相关细节。<br />
<br />
随着我们的广泛推出，GPT 的记忆功能将变得可用。</p>
<p><a href="https://nitter.cz/OpenAI/status/1757469997742666052#m">nitter.cz/OpenAI/status/1757469997742666052#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dQeGd6dFhBQUF3X1NFLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dQeG9wR1hRQUFqbWtDLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757431514214932736#m</id>
            <title>R to @op7418: 这个是Stable Cascade的演示吗？为啥和 Demo 差距这么大。
https://x.com/EMostaque/status/1757431180201242791?s=20</title>
            <link>https://nitter.cz/op7418/status/1757431514214932736#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757431514214932736#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 15:48:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个是Stable Cascade的演示吗？为啥和 Demo 差距这么大。<br />
<a href="https://x.com/EMostaque/status/1757431180201242791?s=20">x.com/EMostaque/status/17574…</a></p>
<p><a href="https://nitter.cz/EMostaque/status/1757431180201242791#m">nitter.cz/EMostaque/status/1757431180201242791#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757427744085065891#m</id>
            <title>R to @op7418: 尝试了一下Stable Cascade，可能是 Demo 的资源问题，现在生成的图片细节非常的差，基本没有纹理，和介绍页面的差距较大。

提示词响应还可以，文字生成真的不错。

这里尝试：https://huggingface.co/spaces/multimodalart/stable-cascade</title>
            <link>https://nitter.cz/op7418/status/1757427744085065891#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757427744085065891#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 15:33:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>尝试了一下Stable Cascade，可能是 Demo 的资源问题，现在生成的图片细节非常的差，基本没有纹理，和介绍页面的差距较大。<br />
<br />
提示词响应还可以，文字生成真的不错。<br />
<br />
这里尝试：<a href="https://huggingface.co/spaces/multimodalart/stable-cascade">huggingface.co/spaces/multim…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dPakk4QmE4QUFGUDlxLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dPakk4QmFZQUEtNUx0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dPakk4QmFBQUU2a191LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757424908970451136#m</id>
            <title>Stable Cascade的模型已经正式放出了，A、B 、C 三个阶段的模型都在里面。

模型页面也有一些新的图片，看起来效果确实比 SDXL 要好一些，尤其是文字部分。

在这里下载：https://huggingface.co/stabilityai/stable-cascade</title>
            <link>https://nitter.cz/op7418/status/1757424908970451136#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757424908970451136#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 15:22:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stable Cascade的模型已经正式放出了，A、B 、C 三个阶段的模型都在里面。<br />
<br />
模型页面也有一些新的图片，看起来效果确实比 SDXL 要好一些，尤其是文字部分。<br />
<br />
在这里下载：<a href="https://huggingface.co/stabilityai/stable-cascade">huggingface.co/stabilityai/s…</a></p>
<p><a href="https://nitter.cz/op7418/status/1757318955713384723#m">nitter.cz/op7418/status/1757318955713384723#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0dPZ1hUaGJvQUE5VUpSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1757222182894424254#m</id>
            <title>RT by @op7418: 黄仁勋最近在迪拜的世界政府峰会上呼吁所有国家开发属于自己的“国家级人工智能”（Sovereign AI）。

换言之，数据就像新时代的黄金，每个国家都需要自主掌控自己的人工智能技术开发。

他强调，“这件事不能让其他人代劳。”</title>
            <link>https://nitter.cz/op7418/status/1757222182894424254#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1757222182894424254#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 Feb 2024 01:56:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>黄仁勋最近在迪拜的世界政府峰会上呼吁所有国家开发属于自己的“国家级人工智能”（Sovereign AI）。<br />
<br />
换言之，数据就像新时代的黄金，每个国家都需要自主掌控自己的人工智能技术开发。<br />
<br />
他强调，“这件事不能让其他人代劳。”</p>
<p><a href="https://nitter.cz/rowancheung/status/1757080008135258258#m">nitter.cz/rowancheung/status/1757080008135258258#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>